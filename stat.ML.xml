<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#20351;&#29992;&#20855;&#26377;&#21487;&#35777;&#26126;&#24615;&#33021;&#20445;&#35777;&#30340;&#24369;&#30417;&#30563;AI&#38169;&#35823;&#20462;&#27491;&#22120;&#26469;&#22788;&#29702;AI&#38169;&#35823;&#12290;&#20462;&#27491;&#22120;&#36890;&#36807;&#25209;&#20934;&#25110;&#25298;&#32477;&#24213;&#23618;&#20998;&#31867;&#22120;&#30340;&#20915;&#31574;&#26469;&#25552;&#21319;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#27010;&#29575;&#30028;&#38480;&#20445;&#35777;&#20854;&#24615;&#33021;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#35757;&#32451;&#25968;&#25454;&#31232;&#32570;&#30340;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#20013;&#25552;&#21319;&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;</title><link>https://rss.arxiv.org/abs/2402.00899</link><description>&lt;p&gt;
&#24369;&#30417;&#30563;&#23398;&#20064;&#22120;&#23454;&#29616;&#20855;&#26377;&#21487;&#35777;&#26126;&#24615;&#33021;&#20445;&#35777;&#30340;AI&#38169;&#35823;&#20462;&#27491;
&lt;/p&gt;
&lt;p&gt;
Weakly Supervised Learners for Correction of AI Errors with Provable Performance Guarantees
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.00899
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#20351;&#29992;&#20855;&#26377;&#21487;&#35777;&#26126;&#24615;&#33021;&#20445;&#35777;&#30340;&#24369;&#30417;&#30563;AI&#38169;&#35823;&#20462;&#27491;&#22120;&#26469;&#22788;&#29702;AI&#38169;&#35823;&#12290;&#20462;&#27491;&#22120;&#36890;&#36807;&#25209;&#20934;&#25110;&#25298;&#32477;&#24213;&#23618;&#20998;&#31867;&#22120;&#30340;&#20915;&#31574;&#26469;&#25552;&#21319;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#27010;&#29575;&#30028;&#38480;&#20445;&#35777;&#20854;&#24615;&#33021;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#35757;&#32451;&#25968;&#25454;&#31232;&#32570;&#30340;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#20013;&#25552;&#21319;&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;AI&#38169;&#35823;&#65292;&#36890;&#36807;&#24341;&#20837;&#20855;&#26377;&#20808;&#39564;&#24615;&#33021;&#20445;&#35777;&#30340;&#24369;&#30417;&#30563;AI&#38169;&#35823;&#20462;&#27491;&#22120;&#12290;&#36825;&#20123;AI&#20462;&#27491;&#22120;&#26159;&#36741;&#21161;&#26144;&#23556;&#65292;&#20854;&#20316;&#29992;&#26159;&#36890;&#36807;&#25209;&#20934;&#25110;&#25298;&#32477;&#20197;&#35843;&#33410;&#20043;&#21069;&#26500;&#24314;&#30340;&#24213;&#23618;&#20998;&#31867;&#22120;&#30340;&#20915;&#31574;&#12290;&#25298;&#32477;&#19968;&#20010;&#20915;&#31574;&#21487;&#20197;&#29992;&#20316;&#24314;&#35758;&#25918;&#24323;&#20570;&#20986;&#20915;&#31574;&#30340;&#20449;&#21495;&#12290;&#35813;&#24037;&#20316;&#30340;&#19968;&#20010;&#20851;&#38190;&#25216;&#26415;&#37325;&#28857;&#26159;&#36890;&#36807;&#23545;&#38169;&#35823;&#20915;&#31574;&#30340;&#27010;&#29575;&#30028;&#38480;&#25552;&#20379;&#36825;&#20123;&#26032;&#30340;AI&#20462;&#27491;&#22120;&#30340;&#24615;&#33021;&#20445;&#35777;&#12290;&#36825;&#20123;&#30028;&#38480;&#26159;&#20998;&#24067;&#19981;&#21487;&#30693;&#30340;&#65292;&#24182;&#19988;&#19981;&#20381;&#36182;&#20110;&#23545;&#25968;&#25454;&#32500;&#24230;&#30340;&#20551;&#35774;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#31034;&#20363;&#35828;&#26126;&#20102;&#35813;&#26694;&#26550;&#22914;&#20309;&#24212;&#29992;&#20110;&#25913;&#21892;&#22312;&#35757;&#32451;&#25968;&#25454;&#31232;&#32570;&#30340;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#20013;&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new methodology for handling AI errors by introducing weakly supervised AI error correctors with a priori performance guarantees. These AI correctors are auxiliary maps whose role is to moderate the decisions of some previously constructed underlying classifier by either approving or rejecting its decisions. The rejection of a decision can be used as a signal to suggest abstaining from making a decision. A key technical focus of the work is in providing performance guarantees for these new AI correctors through bounds on the probabilities of incorrect decisions. These bounds are distribution agnostic and do not rely on assumptions on the data dimension. Our empirical example illustrates how the framework can be applied to improve the performance of an image classifier in a challenging real-world task where training data are scarce.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#21464;&#20998;Shapley&#32593;&#32476;&#65292;&#36890;&#36807;&#27010;&#29575;&#21270;&#30340;&#26041;&#27861;&#31616;&#21270;&#20102;&#35745;&#31639;Shapley&#20540;&#30340;&#36807;&#31243;&#65292;&#24182;&#35299;&#20915;&#20102;&#20272;&#35745;&#27169;&#22411;&#36793;&#38469;&#20540;&#21644;&#22788;&#29702;&#35299;&#37322;&#21487;&#21464;&#24615;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.04211</link><description>&lt;p&gt;
&#21464;&#20998;Shapley&#32593;&#32476;&#65306;&#19968;&#31181;&#27010;&#29575;&#21270;&#30340;&#26041;&#27861;&#29992;&#20110;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#33258;&#35299;&#37322;Shapley&#20540;
&lt;/p&gt;
&lt;p&gt;
Variational Shapley Network: A Probabilistic Approach to Self-Explaining Shapley values with Uncertainty Quantification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04211
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#21464;&#20998;Shapley&#32593;&#32476;&#65292;&#36890;&#36807;&#27010;&#29575;&#21270;&#30340;&#26041;&#27861;&#31616;&#21270;&#20102;&#35745;&#31639;Shapley&#20540;&#30340;&#36807;&#31243;&#65292;&#24182;&#35299;&#20915;&#20102;&#20272;&#35745;&#27169;&#22411;&#36793;&#38469;&#20540;&#21644;&#22788;&#29702;&#35299;&#37322;&#21487;&#21464;&#24615;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Shapley&#20540;&#24050;&#32463;&#25104;&#20026;&#26426;&#22120;&#23398;&#20064;&#20013;&#38416;&#26126;&#27169;&#22411;&#20915;&#31574;&#36807;&#31243;&#30340;&#22522;&#30784;&#24037;&#20855;&#12290;&#23613;&#31649;&#23427;&#20204;&#34987;&#24191;&#27867;&#37319;&#29992;&#24182;&#20855;&#26377;&#28385;&#36275;&#37325;&#35201;&#21487;&#35299;&#37322;&#24615;&#20844;&#29702;&#30340;&#29420;&#29305;&#33021;&#21147;&#65292;&#20294;&#22312;&#20272;&#35745;&#36807;&#31243;&#20013;&#20173;&#28982;&#23384;&#22312;&#35745;&#31639;&#25361;&#25112;&#65292;&#21253;&#25324;&#65288;i&#65289;&#23545;&#27169;&#22411;&#22312;&#25152;&#26377;&#21487;&#33021;&#30340;&#36755;&#20837;&#29305;&#24449;&#32452;&#21512;&#19978;&#36827;&#34892;&#35780;&#20272;&#65292;&#65288;ii&#65289;&#20272;&#35745;&#27169;&#22411;&#30340;&#36793;&#38469;&#20540;&#65292;&#20197;&#21450;&#65288;iii&#65289;&#22788;&#29702;&#35299;&#37322;&#30340;&#21487;&#21464;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#33258;&#35299;&#37322;&#26041;&#27861;&#65292;&#26174;&#33879;&#31616;&#21270;&#20102;Shapley&#20540;&#30340;&#35745;&#31639;&#65292;&#21482;&#38656;&#35201;&#19968;&#27425;&#21069;&#21521;&#20256;&#36882;&#12290;&#37492;&#20110;Shapley&#20540;&#30340;&#30830;&#23450;&#24615;&#22788;&#29702;&#34987;&#35748;&#20026;&#26159;&#19968;&#31181;&#38480;&#21046;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#23558;&#27010;&#29575;&#26694;&#26550;&#32435;&#20837;&#20854;&#20013;&#20197;&#25429;&#25417;&#35299;&#37322;&#20013;&#22266;&#26377;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#19982;&#20854;&#20182;&#26367;&#20195;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#25216;&#26415;&#19981;&#30452;&#25509;&#20381;&#36182;&#20110;&#35266;&#27979;&#25968;&#25454;&#31354;&#38388;&#26469;&#20272;&#35745;&#36793;&#38469;&#20540;&#65307;&#30456;&#21453;&#65292;&#23427;&#20351;&#29992;&#20174;&#28508;&#22312;&#30340;&#12289;&#29305;&#23450;&#20110;&#29305;&#24449;&#30340;&#23884;&#20837;&#31354;&#38388;&#20013;&#27966;&#29983;&#20986;&#30340;&#21487;&#36866;&#24212;&#30340;&#22522;&#32447;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Shapley values have emerged as a foundational tool in machine learning (ML) for elucidating model decision-making processes. Despite their widespread adoption and unique ability to satisfy essential explainability axioms, computational challenges persist in their estimation when ($i$) evaluating a model over all possible subset of input feature combinations, ($ii$) estimating model marginals, and ($iii$) addressing variability in explanations. We introduce a novel, self-explaining method that simplifies the computation of Shapley values significantly, requiring only a single forward pass. Recognizing the deterministic treatment of Shapley values as a limitation, we explore incorporating a probabilistic framework to capture the inherent uncertainty in explanations. Unlike alternatives, our technique does not rely directly on the observed data space to estimate marginals; instead, it uses adaptable baseline values derived from a latent, feature-specific embedding space, generated by a no
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#36716;&#31227;&#23398;&#20064;&#29615;&#22659;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23610;&#24230;&#34892;&#20026;&#65292;&#21457;&#29616;&#24494;&#35843;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#21644;&#39044;&#35757;&#32451;&#25968;&#25454;&#19982;&#19979;&#28216;&#25968;&#25454;&#30340;&#20998;&#24067;&#19968;&#33268;&#24615;&#23545;&#19979;&#28216;&#24615;&#33021;&#26377;&#26174;&#33879;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.04177</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#19979;&#28216;&#20219;&#21153;&#24615;&#33021;&#30340;&#23610;&#24230;&#24459;
&lt;/p&gt;
&lt;p&gt;
Scaling Laws for Downstream Task Performance of Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04177
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#36716;&#31227;&#23398;&#20064;&#29615;&#22659;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23610;&#24230;&#34892;&#20026;&#65292;&#21457;&#29616;&#24494;&#35843;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#21644;&#39044;&#35757;&#32451;&#25968;&#25454;&#19982;&#19979;&#28216;&#25968;&#25454;&#30340;&#20998;&#24067;&#19968;&#33268;&#24615;&#23545;&#19979;&#28216;&#24615;&#33021;&#26377;&#26174;&#33879;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23610;&#24230;&#24459;&#25552;&#20379;&#20102;&#37325;&#35201;&#30340;&#35265;&#35299;&#65292;&#21487;&#20197;&#25351;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#35774;&#35745;&#12290;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#30740;&#31350;&#39044;&#35757;&#32451;&#65288;&#19978;&#28216;&#65289;&#25439;&#22833;&#30340;&#23610;&#24230;&#24459;&#12290;&#28982;&#32780;&#65292;&#22312;&#36716;&#31227;&#23398;&#20064;&#29615;&#22659;&#20013;&#65292;LLM&#20808;&#22312;&#26080;&#30417;&#30563;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#65292;&#28982;&#21518;&#22312;&#19979;&#28216;&#20219;&#21153;&#19978;&#36827;&#34892;&#24494;&#35843;&#65292;&#25105;&#20204;&#36890;&#24120;&#20063;&#20851;&#24515;&#19979;&#28216;&#24615;&#33021;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#36716;&#31227;&#23398;&#20064;&#29615;&#22659;&#20013;&#30340;&#23610;&#24230;&#34892;&#20026;&#65292;&#20854;&#20013;LLM&#34987;&#24494;&#35843;&#29992;&#20110;&#26426;&#22120;&#32763;&#35793;&#20219;&#21153;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#39044;&#35757;&#32451;&#25968;&#25454;&#30340;&#36873;&#25321;&#21644;&#22823;&#23567;&#23545;&#19979;&#28216;&#24615;&#33021;&#65288;&#32763;&#35793;&#36136;&#37327;&#65289;&#30340;&#24433;&#21709;&#65292;&#20351;&#29992;&#20102;&#20004;&#20010;&#35780;&#20215;&#25351;&#26631;&#65306;&#19979;&#28216;&#20132;&#21449;&#29109;&#21644;BLEU&#20998;&#25968;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#24494;&#35843;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#21644;&#39044;&#35757;&#32451;&#25968;&#25454;&#19982;&#19979;&#28216;&#25968;&#25454;&#30340;&#20998;&#24067;&#19968;&#33268;&#24615;&#26174;&#33879;&#24433;&#21709;&#23610;&#24230;&#34892;&#20026;&#12290;&#22312;&#20805;&#20998;&#19968;&#33268;&#24615;&#24773;&#20917;&#19979;&#65292;&#19979;&#28216;&#20132;&#21449;&#29109;&#21644;BLEU&#20998;&#25968;&#37117;&#20250;&#36880;&#28176;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
Scaling laws provide important insights that can guide the design of large language models (LLMs). Existing work has primarily focused on studying scaling laws for pretraining (upstream) loss. However, in transfer learning settings, in which LLMs are pretrained on an unsupervised dataset and then finetuned on a downstream task, we often also care about the downstream performance. In this work, we study the scaling behavior in a transfer learning setting, where LLMs are finetuned for machine translation tasks. Specifically, we investigate how the choice of the pretraining data and its size affect downstream performance (translation quality) as judged by two metrics: downstream cross-entropy and BLEU score. Our experiments indicate that the size of the finetuning dataset and the distribution alignment between the pretraining and downstream data significantly influence the scaling behavior. With sufficient alignment, both downstream cross-entropy and BLEU score improve monotonically with 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#27880;&#24847;&#21147;&#27169;&#22411;&#30340;&#39034;&#24207;&#24314;&#27169;&#33021;&#21147;&#65292;&#29702;&#35770;&#19978;&#21051;&#30011;&#20102;&#21333;&#23618;Transformer&#30340;&#25439;&#22833;&#26223;&#35266;&#24182;&#21457;&#29616;&#20102;&#20840;&#23616;&#26368;&#23567;&#20540;&#21644;&#22351;&#23616;&#37096;&#26368;&#23567;&#20540;&#30340;&#23384;&#22312;&#12290;</title><link>https://arxiv.org/abs/2402.04161</link><description>&lt;p&gt;
&#22522;&#20110;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#27880;&#24847;&#21147;&#27169;&#22411;&#30340;&#35268;&#33539;&#20998;&#26512;&#26694;&#26550;&#65306;&#36890;&#36807;&#39532;&#23572;&#21487;&#22827;&#38142;&#30740;&#31350;Transformer&#30340;&#39034;&#24207;&#24314;&#27169;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Attention with Markov: A Framework for Principled Analysis of Transformers via Markov Chains
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04161
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#27880;&#24847;&#21147;&#27169;&#22411;&#30340;&#39034;&#24207;&#24314;&#27169;&#33021;&#21147;&#65292;&#29702;&#35770;&#19978;&#21051;&#30011;&#20102;&#21333;&#23618;Transformer&#30340;&#25439;&#22833;&#26223;&#35266;&#24182;&#21457;&#29616;&#20102;&#20840;&#23616;&#26368;&#23567;&#20540;&#21644;&#22351;&#23616;&#37096;&#26368;&#23567;&#20540;&#30340;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;Transformer&#22312;&#21253;&#25324;&#33258;&#28982;&#35821;&#35328;&#22312;&#20869;&#30340;&#22810;&#20010;&#39046;&#22495;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#20854;&#20013;&#19968;&#20010;&#20851;&#38190;&#22240;&#32032;&#26159;&#29983;&#25104;&#24335;&#39044;&#35757;&#32451;&#36807;&#31243;&#65292;&#27169;&#22411;&#22312;&#27492;&#36807;&#31243;&#20013;&#36890;&#36807;&#33258;&#22238;&#24402;&#30340;&#26041;&#24335;&#22312;&#22823;&#22411;&#25991;&#26412;&#35821;&#26009;&#24211;&#19978;&#36827;&#34892;&#35757;&#32451;&#12290;&#20026;&#20102;&#25581;&#31034;&#36825;&#19968;&#29616;&#35937;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#35270;&#35282;&#65292;&#20801;&#35768;&#29702;&#35770;&#21644;&#31995;&#32479;&#23454;&#39564;&#26469;&#30740;&#31350;Transformer&#30340;&#39034;&#24207;&#24314;&#27169;&#33021;&#21147;&#12290;&#21463;&#21040;&#33258;&#28982;&#35821;&#35328;&#30340;&#39532;&#23572;&#21487;&#22827;&#24615;&#36136;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#23558;&#25968;&#25454;&#24314;&#27169;&#20026;&#19968;&#20010;&#39532;&#23572;&#21487;&#22827;&#28304;&#65292;&#24182;&#21033;&#29992;&#36825;&#20010;&#26694;&#26550;&#31995;&#32479;&#22320;&#30740;&#31350;&#25968;&#25454;&#20998;&#24067;&#29305;&#24615;&#12289;Transformer&#26550;&#26500;&#12289;&#23398;&#21040;&#30340;&#20998;&#24067;&#21644;&#26368;&#32456;&#27169;&#22411;&#24615;&#33021;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#29702;&#35770;&#19978;&#21051;&#30011;&#20102;&#21333;&#23618;Transformer&#30340;&#25439;&#22833;&#26223;&#35266;&#65292;&#24182;&#23637;&#31034;&#20102;&#20840;&#23616;&#26368;&#23567;&#20540;&#21644;&#22351;&#23616;&#37096;&#26368;&#23567;&#20540;&#30340;&#23384;&#22312;&#65292;&#36825;&#21462;&#20915;&#20110;&#20855;&#20307;&#30340;&#25968;&#25454;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, attention-based transformers have achieved tremendous success across a variety of disciplines including natural languages. A key ingredient behind their success is the generative pretraining procedure, during which these models are trained on a large text corpus in an auto-regressive manner. To shed light on this phenomenon, we propose a new framework that allows both theory and systematic experiments to study the sequential modeling capabilities of transformers through the lens of Markov chains. Inspired by the Markovianity of natural languages, we model the data as a Markovian source and utilize this framework to systematically study the interplay between the data-distributional properties, the transformer architecture, the learnt distribution, and the final model performance. In particular, we theoretically characterize the loss landscape of single-layer transformers and show the existence of global minima and bad local minima contingent upon the specific data chara
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#21464;&#37327;&#39640;&#26031;&#36807;&#31243;&#30340;&#22810;&#28304;&#25968;&#25454;&#34701;&#21512;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22810;&#20010;&#25968;&#25454;&#28304;&#20043;&#38388;&#36136;&#37327;&#21644;&#20840;&#38754;&#24615;&#24046;&#24322;&#32473;&#31995;&#32479;&#20248;&#21270;&#24102;&#26469;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.04146</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#22810;&#28304;&#25968;&#25454;&#34701;&#21512;&#36890;&#36807;&#28508;&#21464;&#37327;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Interpretable Multi-Source Data Fusion Through Latent Variable Gaussian Process
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04146
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#21464;&#37327;&#39640;&#26031;&#36807;&#31243;&#30340;&#22810;&#28304;&#25968;&#25454;&#34701;&#21512;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22810;&#20010;&#25968;&#25454;&#28304;&#20043;&#38388;&#36136;&#37327;&#21644;&#20840;&#38754;&#24615;&#24046;&#24322;&#32473;&#31995;&#32479;&#20248;&#21270;&#24102;&#26469;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#21644;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#30340;&#20986;&#29616;&#65292;&#21508;&#20010;&#31185;&#23398;&#21644;&#24037;&#31243;&#39046;&#22495;&#24050;&#32463;&#21033;&#29992;&#25968;&#25454;&#39537;&#21160;&#30340;&#26367;&#20195;&#27169;&#22411;&#26469;&#24314;&#27169;&#26469;&#33258;&#22823;&#37327;&#20449;&#24687;&#28304;&#65288;&#25968;&#25454;&#65289;&#30340;&#22797;&#26434;&#31995;&#32479;&#12290;&#36825;&#31181;&#22686;&#21152;&#23548;&#33268;&#20102;&#24320;&#21457;&#20986;&#29992;&#20110;&#25191;&#34892;&#29305;&#23450;&#21151;&#33021;&#30340;&#20248;&#36234;&#31995;&#32479;&#25152;&#38656;&#30340;&#25104;&#26412;&#21644;&#26102;&#38388;&#30340;&#26174;&#33879;&#38477;&#20302;&#12290;&#36825;&#26679;&#30340;&#26367;&#20195;&#27169;&#22411;&#24448;&#24448;&#24191;&#27867;&#22320;&#34701;&#21512;&#22810;&#20010;&#25968;&#25454;&#26469;&#28304;&#65292;&#21487;&#33021;&#26159;&#21457;&#34920;&#30340;&#35770;&#25991;&#12289;&#19987;&#21033;&#12289;&#24320;&#25918;&#36164;&#28304;&#24211;&#25110;&#20854;&#20182;&#36164;&#28304;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#24050;&#30693;&#21644;&#26410;&#30693;&#30340;&#20449;&#24687;&#26469;&#28304;&#30340;&#22522;&#30784;&#29289;&#29702;&#21442;&#25968;&#30340;&#36136;&#37327;&#21644;&#20840;&#38754;&#24615;&#30340;&#24046;&#24322;&#65292;&#21487;&#33021;&#23545;&#31995;&#32479;&#20248;&#21270;&#36807;&#31243;&#20135;&#29983;&#21518;&#32493;&#24433;&#21709;&#65292;&#21364;&#27809;&#26377;&#24471;&#21040;&#20805;&#20998;&#30340;&#20851;&#27880;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#21464;&#37327;&#39640;&#26031;&#36807;&#31243;&#65288;LVGP&#65289;&#30340;&#22810;&#28304;&#25968;&#25454;&#34701;&#21512;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the advent of artificial intelligence (AI) and machine learning (ML), various domains of science and engineering communites has leveraged data-driven surrogates to model complex systems from numerous sources of information (data). The proliferation has led to significant reduction in cost and time involved in development of superior systems designed to perform specific functionalities. A high proposition of such surrogates are built extensively fusing multiple sources of data, may it be published papers, patents, open repositories, or other resources. However, not much attention has been paid to the differences in quality and comprehensiveness of the known and unknown underlying physical parameters of the information sources that could have downstream implications during system optimization. Towards resolving this issue, a multi-source data fusion framework based on Latent Variable Gaussian Process (LVGP) is proposed. The individual data sources are tagged as a characteristic cate
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37327;&#21270;&#20102;&#32852;&#37030;&#32447;&#24615;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#20013;&#24322;&#36136;&#24615;&#20559;&#24046;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;SCAFFLSA&#20316;&#20026;&#19968;&#31181;&#25913;&#36827;&#26041;&#27861;&#26469;&#28040;&#38500;&#27492;&#20559;&#24046;&#12290;&#22312;&#32852;&#37030;&#26102;&#38388;&#24046;&#24322;&#23398;&#20064;&#20013;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#31639;&#27861;&#30340;&#22797;&#26434;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.04114</link><description>&lt;p&gt;
SCAFFLSA&#65306;&#37327;&#21270;&#21644;&#28040;&#38500;&#32852;&#37030;&#32447;&#24615;&#38543;&#26426;&#36924;&#36817;&#21644;&#26102;&#38388;&#24046;&#24322;&#23398;&#20064;&#20013;&#30340;&#24322;&#36136;&#24615;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
SCAFFLSA: Quantifying and Eliminating Heterogeneity Bias in Federated Linear Stochastic Approximation and Temporal Difference Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04114
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37327;&#21270;&#20102;&#32852;&#37030;&#32447;&#24615;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#20013;&#24322;&#36136;&#24615;&#20559;&#24046;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;SCAFFLSA&#20316;&#20026;&#19968;&#31181;&#25913;&#36827;&#26041;&#27861;&#26469;&#28040;&#38500;&#27492;&#20559;&#24046;&#12290;&#22312;&#32852;&#37030;&#26102;&#38388;&#24046;&#24322;&#23398;&#20064;&#20013;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#31639;&#27861;&#30340;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#32852;&#37030;&#32447;&#24615;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#65288;FedLSA&#65289;&#36827;&#34892;&#20102;&#38750;&#28176;&#36827;&#20998;&#26512;&#12290;&#25105;&#20204;&#26126;&#30830;&#37327;&#21270;&#20102;&#24322;&#36136;&#20195;&#29702;&#26412;&#22320;&#35757;&#32451;&#24341;&#20837;&#30340;&#20559;&#24046;&#65292;&#24182;&#30740;&#31350;&#20102;&#35813;&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;FedLSA&#30340;&#36890;&#20449;&#22797;&#26434;&#24615;&#19982;&#25152;&#38656;&#31934;&#24230; $\epsilon$ &#21576;&#22810;&#39033;&#24335;&#20851;&#31995;&#65292;&#36825;&#38480;&#21046;&#20102;&#32852;&#37030;&#30340;&#22909;&#22788;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;SCAFFLSA&#65292;&#19968;&#31181;&#26032;&#22411;&#30340;FedLSA&#21464;&#20307;&#65292;&#23427;&#20351;&#29992;&#25511;&#21046;&#21464;&#37327;&#26469;&#26657;&#27491;&#26412;&#22320;&#35757;&#32451;&#30340;&#20559;&#24046;&#65292;&#24182;&#22312;&#19981;&#23545;&#32479;&#35745;&#24322;&#36136;&#24615;&#20570;&#20986;&#20219;&#20309;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#35777;&#26126;&#20102;&#20854;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#23558;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#20855;&#26377;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#32852;&#37030;&#26102;&#38388;&#24046;&#24322;&#23398;&#20064;&#65292;&#24182;&#20998;&#26512;&#20102;&#30456;&#24212;&#30340;&#22797;&#26434;&#24615;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we perform a non-asymptotic analysis of the federated linear stochastic approximation (FedLSA) algorithm. We explicitly quantify the bias introduced by local training with heterogeneous agents, and investigate the sample complexity of the algorithm. We show that the communication complexity of FedLSA scales polynomially with the desired precision $\epsilon$, which limits the benefits of federation. To overcome this, we propose SCAFFLSA, a novel variant of FedLSA, that uses control variates to correct the bias of local training, and prove its convergence without assumptions on statistical heterogeneity. We apply the proposed methodology to federated temporal difference learning with linear function approximation, and analyze the corresponding complexity improvements.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#21487;&#35777;&#23398;&#20064;&#22810;&#22836;&#27880;&#24847;&#21147;&#23618;&#30340;&#30740;&#31350;&#65292;&#24182;&#32473;&#20986;&#20102;&#35813;&#38382;&#39064;&#30340;&#38750;&#24179;&#20961;&#30340;&#19978;&#19979;&#30028;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2402.04084</link><description>&lt;p&gt;
&#21487;&#35777;&#23398;&#20064;&#22810;&#22836;&#27880;&#24847;&#21147;&#23618;
&lt;/p&gt;
&lt;p&gt;
Provably learning a multi-head attention layer
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04084
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#21487;&#35777;&#23398;&#20064;&#22810;&#22836;&#27880;&#24847;&#21147;&#23618;&#30340;&#30740;&#31350;&#65292;&#24182;&#32473;&#20986;&#20102;&#35813;&#38382;&#39064;&#30340;&#38750;&#24179;&#20961;&#30340;&#19978;&#19979;&#30028;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#22836;&#27880;&#24847;&#21147;&#23618;&#26159;&#21464;&#24418;&#22120;&#26550;&#26500;&#30340;&#20851;&#38190;&#32452;&#20214;&#20043;&#19968;&#65292;&#20351;&#20854;&#19982;&#20256;&#32479;&#30340;&#21069;&#39304;&#27169;&#22411;&#26377;&#25152;&#21306;&#21035;&#12290;&#36890;&#36807;&#32473;&#23450;&#24207;&#21015;&#38271;&#24230; $k$&#65292;&#27880;&#24847;&#21147;&#30697;&#38453; $\mathbf{\Theta}_1,\ldots,\mathbf{\Theta}_m\in\mathbb{R}^{d\times d}$&#65292;&#20197;&#21450;&#25237;&#24433;&#30697;&#38453; $\mathbf{W}_1,\ldots,\mathbf{W}_m\in\mathbb{R}^{d\times d}$&#65292;&#30456;&#24212;&#30340;&#22810;&#22836;&#27880;&#24847;&#21147;&#23618; $F: \mathbb{R}^{k\times d}\to \mathbb{R}^{k\times d}$ &#36890;&#36807; $F(\mathbf{X}) \triangleq \sum^m_{i=1} \mathrm{softmax}(\mathbf{X}\mathbf{\Theta}_i\mathbf{X}^\top)\mathbf{X}\mathbf{W}_i$ &#26469;&#36716;&#21270;&#38271;&#24230;&#20026; $k$ &#30340; $d$ &#32500;&#20196;&#29260;&#24207;&#21015; $\mathbf{X}\in\mathbb{R}^{k\times d}$&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24320;&#22987;&#30740;&#31350;&#36890;&#36807;&#38543;&#26426;&#31034;&#20363;&#21487;&#35777;&#23398;&#20064;&#22810;&#22836;&#27880;&#24847;&#21147;&#23618;&#65292;&#24182;&#20026;&#35813;&#38382;&#39064;&#32473;&#20986;&#20102;&#39318;&#20010;&#38750;&#24179;&#20961;&#30340;&#19978;&#19979;&#30028;&#38480;&#21046;&#65306;&#20551;&#35774; $\{\mathbf{W}_i, \mathbf{\Theta}_i\}$ &#28385;&#36275;&#26576;&#20123;&#38750;&#36864;&#21270;&#26465;&#20214;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010; $(dk)^{O(m^3)}$ &#26102;&#38388;&#22797;&#26434;&#24230;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
The multi-head attention layer is one of the key components of the transformer architecture that sets it apart from traditional feed-forward models. Given a sequence length $k$, attention matrices $\mathbf{\Theta}_1,\ldots,\mathbf{\Theta}_m\in\mathbb{R}^{d\times d}$, and projection matrices $\mathbf{W}_1,\ldots,\mathbf{W}_m\in\mathbb{R}^{d\times d}$, the corresponding multi-head attention layer $F: \mathbb{R}^{k\times d}\to \mathbb{R}^{k\times d}$ transforms length-$k$ sequences of $d$-dimensional tokens $\mathbf{X}\in\mathbb{R}^{k\times d}$ via $F(\mathbf{X}) \triangleq \sum^m_{i=1} \mathrm{softmax}(\mathbf{X}\mathbf{\Theta}_i\mathbf{X}^\top)\mathbf{X}\mathbf{W}_i$. In this work, we initiate the study of provably learning a multi-head attention layer from random examples and give the first nontrivial upper and lower bounds for this problem:   - Provided $\{\mathbf{W}_i, \mathbf{\Theta}_i\}$ satisfy certain non-degeneracy conditions, we give a $(dk)^{O(m^3)}$-time algorithm that learns
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23398;&#20064;&#23398;&#20064;&#31639;&#27861;&#65292;&#23454;&#29616;&#26356;&#28789;&#27963;&#30340;PAC-Bayesian&#20803;&#23398;&#20064;&#65292;&#20801;&#35768;&#26356;&#28789;&#27963;&#30340;&#20219;&#21153;&#20043;&#38388;&#30340;&#30693;&#35782;&#36716;&#31227;&#65292;&#25552;&#20379;&#26032;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#21487;&#36866;&#29992;&#20110;&#20998;&#26512;&#21644;&#35774;&#35745;&#21508;&#31181;&#20803;&#23398;&#20064;&#26426;&#21046;&#65292;&#24182;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#25913;&#21892;&#20102;&#39044;&#27979;&#36136;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.04054</link><description>&lt;p&gt;
&#36890;&#36807;&#23398;&#20064;&#23398;&#20064;&#31639;&#27861;&#65292;&#23454;&#29616;&#26356;&#28789;&#27963;&#30340;PAC-Bayesian&#20803;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
More Flexible PAC-Bayesian Meta-Learning by Learning Learning Algorithms
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04054
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23398;&#20064;&#23398;&#20064;&#31639;&#27861;&#65292;&#23454;&#29616;&#26356;&#28789;&#27963;&#30340;PAC-Bayesian&#20803;&#23398;&#20064;&#65292;&#20801;&#35768;&#26356;&#28789;&#27963;&#30340;&#20219;&#21153;&#20043;&#38388;&#30340;&#30693;&#35782;&#36716;&#31227;&#65292;&#25552;&#20379;&#26032;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#21487;&#36866;&#29992;&#20110;&#20998;&#26512;&#21644;&#35774;&#35745;&#21508;&#31181;&#20803;&#23398;&#20064;&#26426;&#21046;&#65292;&#24182;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#25913;&#21892;&#20102;&#39044;&#27979;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#20351;&#29992;PAC-Bayesian&#29702;&#35770;&#30740;&#31350;&#20803;&#23398;&#20064;&#26041;&#27861;&#30340;&#26032;&#26694;&#26550;&#12290;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;&#30456;&#27604;&#65292;&#20854;&#20027;&#35201;&#20248;&#21183;&#22312;&#20110;&#23427;&#20801;&#35768;&#22312;&#20219;&#21153;&#20043;&#38388;&#30340;&#30693;&#35782;&#36716;&#31227;&#20013;&#26356;&#20855;&#28789;&#27963;&#24615;&#12290;&#20197;&#24448;&#30340;&#26041;&#27861;&#21482;&#33021;&#36890;&#36807;&#23398;&#20064;&#27169;&#22411;&#30340;&#20808;&#39564;&#20998;&#24067;&#38388;&#25509;&#21457;&#29983;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#30340;&#26032;&#30340;&#27867;&#21270;&#30028;&#38480;&#26356;&#30452;&#25509;&#22320;&#34920;&#36798;&#20102;&#20803;&#23398;&#20064;&#30340;&#36807;&#31243;&#65292;&#21363;&#23398;&#20064;&#36866;&#29992;&#20110;&#23558;&#26469;&#20219;&#21153;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#30340;&#28789;&#27963;&#24615;&#20351;&#20854;&#36866;&#29992;&#20110;&#20998;&#26512;&#21508;&#31181;&#20803;&#23398;&#20064;&#26426;&#21046;&#29978;&#33267;&#35774;&#35745;&#26032;&#30340;&#26426;&#21046;&#12290;&#38500;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#36129;&#29486;&#22806;&#65292;&#25105;&#20204;&#36824;&#22312;&#23454;&#38469;&#20803;&#23398;&#20064;&#26426;&#21046;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#25552;&#39640;&#20102;&#39044;&#27979;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new framework for studying meta-learning methods using PAC-Bayesian theory. Its main advantage over previous work is that it allows for more flexibility in how the transfer of knowledge between tasks is realized. For previous approaches, this could only happen indirectly, by means of learning prior distributions over models. In contrast, the new generalization bounds that we prove express the process of meta-learning much more directly as learning the learning algorithm that should be used for future tasks. The flexibility of our framework makes it suitable to analyze a wide range of meta-learning mechanisms and even design new mechanisms. Other than our theoretical contributions we also show empirically that our framework improves the prediction quality in practical meta-learning mechanisms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;PAC-Bayesian&#26694;&#26550;&#30340;&#26041;&#27861;&#65292;&#26469;&#30740;&#31350;&#23545;&#25239;&#40065;&#26834;&#24615;&#27867;&#21270;&#30028;&#38480;&#38382;&#39064;&#65292;&#38024;&#23545;&#20004;&#31181;&#27969;&#34892;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#32467;&#26524;&#21457;&#29616;&#22270;&#19978;&#25193;&#25955;&#30697;&#38453;&#30340;&#35889;&#33539;&#25968;&#12289;&#26435;&#37325;&#30340;&#35889;&#33539;&#25968;&#21644;&#25200;&#21160;&#22240;&#23376;&#23545;&#27169;&#22411;&#30340;&#40065;&#26834;&#27867;&#21270;&#30028;&#38480;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.04038</link><description>&lt;p&gt;
PAC-Bayesian Adversarially Robust Generalization Bounds for Graph Neural Network
&lt;/p&gt;
&lt;p&gt;
PAC-Bayesian Adversarially Robust Generalization Bounds for Graph Neural Network
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04038
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;PAC-Bayesian&#26694;&#26550;&#30340;&#26041;&#27861;&#65292;&#26469;&#30740;&#31350;&#23545;&#25239;&#40065;&#26834;&#24615;&#27867;&#21270;&#30028;&#38480;&#38382;&#39064;&#65292;&#38024;&#23545;&#20004;&#31181;&#27969;&#34892;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#32467;&#26524;&#21457;&#29616;&#22270;&#19978;&#25193;&#25955;&#30697;&#38453;&#30340;&#35889;&#33539;&#25968;&#12289;&#26435;&#37325;&#30340;&#35889;&#33539;&#25968;&#21644;&#25200;&#21160;&#22240;&#23376;&#23545;&#27169;&#22411;&#30340;&#40065;&#26834;&#27867;&#21270;&#30028;&#38480;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#22312;&#21508;&#31181;&#19982;&#22270;&#30456;&#20851;&#30340;&#20219;&#21153;&#20013;&#24191;&#21463;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#31867;&#20284;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;GNNs&#20063;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#25915;&#20987;&#12290;&#32463;&#39564;&#30740;&#31350;&#34920;&#26126;&#65292;&#23545;&#25239;&#40065;&#26834;&#24615;&#27867;&#21270;&#22312;&#24314;&#31435;&#26377;&#25928;&#30340;&#25269;&#24481;&#23545;&#25239;&#25915;&#20987;&#30340;&#38450;&#24481;&#31639;&#27861;&#26041;&#38754;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;PAC-Bayesian&#26694;&#26550;&#65292;&#20026;&#20004;&#31181;&#27969;&#34892;&#30340;GNNs&#65292;&#21363;&#22270;&#21367;&#31215;&#32593;&#32476;&#65288;GCN&#65289;&#21644;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#25552;&#20379;&#20102;&#23545;&#25239;&#40065;&#26834;&#27867;&#21270;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25581;&#31034;&#20102;&#22270;&#19978;&#25193;&#25955;&#30697;&#38453;&#30340;&#35889;&#33539;&#25968;&#12289;&#26435;&#37325;&#30340;&#35889;&#33539;&#25968;&#20197;&#21450;&#25200;&#21160;&#22240;&#23376;&#23545;&#20004;&#20010;&#27169;&#22411;&#30340;&#40065;&#26834;&#27867;&#21270;&#30028;&#38480;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#26159;&#65288;Liao&#31561;&#20154;&#65292;2020&#65289;&#20013;&#32467;&#26524;&#30340;&#38750;&#24179;&#20961;&#25512;&#24191;&#65292;&#20174;&#26631;&#20934;&#35774;&#32622;&#25193;&#23637;&#21040;&#23545;&#25239;&#35774;&#32622;&#65292;&#21516;&#26102;&#36991;&#20813;&#20102;&#26368;&#22823;&#33410;&#28857;&#24230;&#30340;&#25351;&#25968;&#20381;&#36182;&#12290;&#20316;&#20026;&#25512;&#35770;&#65292;&#25105;&#20204;&#24471;&#20986;&#26356;&#22909;&#30340;&#30028;&#38480;...
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) have gained popularity for various graph-related tasks. However, similar to deep neural networks, GNNs are also vulnerable to adversarial attacks. Empirical studies have shown that adversarially robust generalization has a pivotal role in establishing effective defense algorithms against adversarial attacks. In this paper, we contribute by providing adversarially robust generalization bounds for two kinds of popular GNNs, graph convolutional network (GCN) and message passing graph neural network, using the PAC-Bayesian framework. Our result reveals that spectral norm of the diffusion matrix on the graph and spectral norm of the weights as well as the perturbation factor govern the robust generalization bounds of both models. Our bounds are nontrivial generalizations of the results developed in (Liao et al., 2020) from the standard setting to adversarial setting while avoiding exponential dependence of the maximum node degree. As corollaries, we derive bette
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21040;&#32039;&#25903;&#25345;&#22522;&#30340;&#26680;&#20998;&#32452;&#30340;&#36890;&#29992;&#29702;&#35770;&#65292;&#35813;&#29702;&#35770;&#21487;&#20197;&#29992;&#20110;&#38477;&#20302;&#39640;&#26031;&#36807;&#31243;&#30340;&#35757;&#32451;&#21644;&#39044;&#27979;&#26102;&#38388;&#65292;&#24182;&#19988;&#36890;&#36807;&#36866;&#24403;&#30340;&#32447;&#24615;&#32452;&#21512;&#20135;&#29983;&#20102;$m$&#20010;&#32039;&#25903;&#25345;&#30340;&#26680;&#20998;&#32452;&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2402.04022</link><description>&lt;p&gt;
&#19968;&#31181;&#20174;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21040;&#32039;&#25903;&#25345;&#22522;&#30340;&#26680;&#20998;&#32452;&#30340;&#36890;&#29992;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
A General Theory for Kernel Packets: from state space model to compactly supported basis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04022
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21040;&#32039;&#25903;&#25345;&#22522;&#30340;&#26680;&#20998;&#32452;&#30340;&#36890;&#29992;&#29702;&#35770;&#65292;&#35813;&#29702;&#35770;&#21487;&#20197;&#29992;&#20110;&#38477;&#20302;&#39640;&#26031;&#36807;&#31243;&#30340;&#35757;&#32451;&#21644;&#39044;&#27979;&#26102;&#38388;&#65292;&#24182;&#19988;&#36890;&#36807;&#36866;&#24403;&#30340;&#32447;&#24615;&#32452;&#21512;&#20135;&#29983;&#20102;$m$&#20010;&#32039;&#25903;&#25345;&#30340;&#26680;&#20998;&#32452;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#30340;&#29366;&#24577;&#31354;&#38388;&#65288;SS&#65289;&#27169;&#22411;&#20844;&#24335;&#21487;&#20197;&#23558;&#20854;&#35757;&#32451;&#21644;&#39044;&#27979;&#26102;&#38388;&#38477;&#20302;&#21040;O&#65288;n&#65289;&#65288;n&#20026;&#25968;&#25454;&#28857;&#20010;&#25968;&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;m&#32500;&#30340;GP&#30340;SS&#27169;&#22411;&#20844;&#24335;&#31561;&#20215;&#20110;&#25105;&#20204;&#24341;&#20837;&#30340;&#19968;&#20010;&#27010;&#24565;&#65292;&#31216;&#20026;&#36890;&#29992;&#21491;&#26680;&#20998;&#32452;&#65288;KP&#65289;&#65306;&#19968;&#31181;&#29992;&#20110;GP&#21327;&#26041;&#24046;&#20989;&#25968;K&#30340;&#21464;&#25442;&#65292;&#20351;&#24471;&#23545;&#20110;&#20219;&#24847;$t \leq t_1$&#65292;$0 \leq j \leq m-1$&#21644;$m+1$&#20010;&#36830;&#32493;&#28857;$t_i$&#65292;&#37117;&#28385;&#36275;$\sum_{i=0}^{m}a_iD_t^{(j)}K(t,t_i)=0$&#65292;&#20854;&#20013;${D}_t^{(j)}f(t)$&#34920;&#31034;&#22312;$t$&#19978;&#20316;&#29992;&#30340;&#31532;j&#38454;&#23548;&#25968;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#24605;&#24819;&#25193;&#23637;&#21040;&#20102;GP&#30340;&#21521;&#21518;SS&#27169;&#22411;&#20844;&#24335;&#65292;&#24471;&#21040;&#20102;&#19979;&#19968;&#20010;$m$&#20010;&#36830;&#32493;&#28857;&#30340;&#24038;&#26680;&#20998;&#32452;&#30340;&#27010;&#24565;&#65306;$\sum_{i=0}^{m}b_i{D}_t^{(j)}K(t,t_{m+i})=0$&#65292;&#23545;&#20110;&#20219;&#24847;$t\geq t_{2m}$&#12290;&#36890;&#36807;&#32467;&#21512;&#24038;&#21491;&#26680;&#20998;&#32452;&#65292;&#21487;&#20197;&#35777;&#26126;&#36825;&#20123;&#21327;&#26041;&#24046;&#20989;&#25968;&#30340;&#36866;&#24403;&#32447;&#24615;&#32452;&#21512;&#20135;&#29983;&#20102;$m$&#20010;&#32039;&#25903;&#25345;&#30340;&#26680;&#20998;&#32452;&#20989;&#25968;&#65306;&#23545;&#20110;&#20219;&#24847;$t\not\in(t_0,t_{2m})$&#21644;$j=0,\cdots,m-1$&#65292;$\phi^{(j)}(t)=0$&#12290;
&lt;/p&gt;
&lt;p&gt;
It is well known that the state space (SS) model formulation of a Gaussian process (GP) can lower its training and prediction time both to O(n) for n data points. We prove that an $m$-dimensional SS model formulation of GP is equivalent to a concept we introduce as the general right Kernel Packet (KP): a transformation for the GP covariance function $K$ such that $\sum_{i=0}^{m}a_iD_t^{(j)}K(t,t_i)=0$ holds for any $t \leq t_1$, 0 $\leq j \leq m-1$, and $m+1$ consecutive points $t_i$, where ${D}_t^{(j)}f(t) $ denotes $j$-th order derivative acting on $t$. We extend this idea to the backward SS model formulation of the GP, leading to the concept of the left KP for next $m$ consecutive points: $\sum_{i=0}^{m}b_i{D}_t^{(j)}K(t,t_{m+i})=0$ for any $t\geq t_{2m}$. By combining both left and right KPs, we can prove that a suitable linear combination of these covariance functions yields $m$ compactly supported KP functions: $\phi^{(j)}(t)=0$ for any $t\not\in(t_0,t_{2m})$ and $j=0,\cdots,m-1$
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#21487;&#29992;&#24615;&#25915;&#20987;&#26041;&#27861;&#65292;&#21487;&#20197;&#21516;&#26102;&#38024;&#23545;&#30417;&#30563;&#23398;&#20064;&#21644;&#23545;&#27604;&#23398;&#20064;&#65292;&#36890;&#36807;&#29983;&#25104;&#38590;&#20197;&#23519;&#35273;&#30340;&#22122;&#38899;&#21644;&#21046;&#36896;&#19981;&#21487;&#23398;&#20064;&#30340;&#31034;&#20363;&#26469;&#38450;&#27490;&#26410;&#32463;&#25480;&#26435;&#20351;&#29992;&#25968;&#25454;&#65292;&#24182;&#23454;&#29616;&#20102;&#30417;&#30563;&#21644;&#23545;&#27604;&#23398;&#20064;&#31639;&#27861;&#30340;&#26368;&#26032;&#26368;&#22351;&#24773;&#20917;&#30340;&#19981;&#21487;&#23398;&#20064;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.04010</link><description>&lt;p&gt;
&#38024;&#23545;&#30417;&#30563;&#21644;&#23545;&#27604;&#23398;&#20064;&#30340;&#39640;&#25928;&#21487;&#29992;&#24615;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Efficient Availability Attacks against Supervised and Contrastive Learning Simultaneously
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04010
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#21487;&#29992;&#24615;&#25915;&#20987;&#26041;&#27861;&#65292;&#21487;&#20197;&#21516;&#26102;&#38024;&#23545;&#30417;&#30563;&#23398;&#20064;&#21644;&#23545;&#27604;&#23398;&#20064;&#65292;&#36890;&#36807;&#29983;&#25104;&#38590;&#20197;&#23519;&#35273;&#30340;&#22122;&#38899;&#21644;&#21046;&#36896;&#19981;&#21487;&#23398;&#20064;&#30340;&#31034;&#20363;&#26469;&#38450;&#27490;&#26410;&#32463;&#25480;&#26435;&#20351;&#29992;&#25968;&#25454;&#65292;&#24182;&#23454;&#29616;&#20102;&#30417;&#30563;&#21644;&#23545;&#27604;&#23398;&#20064;&#31639;&#27861;&#30340;&#26368;&#26032;&#26368;&#22351;&#24773;&#20917;&#30340;&#19981;&#21487;&#23398;&#20064;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#29992;&#24615;&#25915;&#20987;&#21487;&#20197;&#36890;&#36807;&#29983;&#25104;&#38590;&#20197;&#23519;&#35273;&#30340;&#22122;&#38899;&#21644;&#21046;&#36896;&#19981;&#21487;&#23398;&#20064;&#30340;&#31034;&#20363;&#26469;&#38450;&#27490;&#31169;&#20154;&#25968;&#25454;&#21644;&#21830;&#19994;&#25968;&#25454;&#38598;&#30340;&#26410;&#32463;&#25480;&#26435;&#20351;&#29992;&#12290;&#24403;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#22833;&#36133;&#26102;&#65292;&#24694;&#24847;&#30340;&#25968;&#25454;&#25910;&#38598;&#32773;&#21487;&#33021;&#20250;&#36716;&#21521;&#23545;&#27604;&#23398;&#20064;&#31639;&#27861;&#20197;&#32469;&#36807;&#20445;&#25252;&#12290;&#36890;&#36807;&#35780;&#20272;&#65292;&#25105;&#20204;&#21457;&#29616;&#29616;&#26377;&#30340;&#22823;&#22810;&#25968;&#26041;&#27861;&#26080;&#27861;&#21516;&#26102;&#23454;&#29616;&#30417;&#30563;&#21644;&#23545;&#27604;&#30340;&#19981;&#21487;&#23398;&#20064;&#24615;&#65292;&#36825;&#32473;&#25968;&#25454;&#20445;&#25252;&#24102;&#26469;&#20102;&#39118;&#38505;&#12290;&#19982;&#22522;&#20110;&#23545;&#27604;&#35823;&#24046;&#26368;&#23567;&#21270;&#30340;&#26368;&#26032;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#22312;&#30417;&#30563;&#35823;&#24046;&#26368;&#23567;&#21270;&#25110;&#26368;&#22823;&#21270;&#26694;&#26550;&#20013;&#20351;&#29992;&#31867;&#20284;&#23545;&#27604;&#30340;&#25968;&#25454;&#22686;&#24378;&#26469;&#33719;&#24471;&#23545;&#30417;&#30563;&#21644;&#23545;&#27604;&#23398;&#20064;&#22343;&#26377;&#25928;&#30340;&#25915;&#20987;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;AUE&#21644;AAP&#25915;&#20987;&#22312;&#20943;&#23569;&#35745;&#31639;&#28040;&#32791;&#30340;&#21069;&#25552;&#19979;&#65292;&#23454;&#29616;&#20102;&#30417;&#30563;&#21644;&#23545;&#27604;&#23398;&#20064;&#31639;&#27861;&#30340;&#26368;&#26032;&#26368;&#22351;&#24773;&#20917;&#30340;&#19981;&#21487;&#23398;&#20064;&#24615;&#65292;&#23637;&#31034;&#20102;&#26410;&#26469;&#30340;&#21069;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
Availability attacks can prevent the unauthorized use of private data and commercial datasets by generating imperceptible noise and making unlearnable examples before release. Ideally, the obtained unlearnability prevents algorithms from training usable models. When supervised learning (SL) algorithms have failed, a malicious data collector possibly resorts to contrastive learning (CL) algorithms to bypass the protection. Through evaluation, we have found that most of the existing methods are unable to achieve both supervised and contrastive unlearnability, which poses risks to data protection. Different from recent methods based on contrastive error minimization, we employ contrastive-like data augmentations in supervised error minimization or maximization frameworks to obtain attacks effective for both SL and CL. Our proposed AUE and AAP attacks achieve state-of-the-art worst-case unlearnability across SL and CL algorithms with less computation consumption, showcasing prospects in re
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#28176;&#21464;&#33609;&#22270;&#31639;&#27861;&#65292;&#29992;&#20110;&#35757;&#32451;&#25968;&#25454;&#24402;&#22240;&#21644;&#25439;&#22833;&#22320;&#35980;&#30740;&#31350;&#12290;&#20316;&#32773;&#22312;&#19977;&#20010;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.03994</link><description>&lt;p&gt;
&#20351;&#29992;&#28176;&#21464;&#33609;&#22270;&#36827;&#34892;&#35757;&#32451;&#25968;&#25454;&#24402;&#22240;&#21644;&#25439;&#22833;&#22320;&#35980;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Gradient Sketches for Training Data Attribution and Studying the Loss Landscape
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03994
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#28176;&#21464;&#33609;&#22270;&#31639;&#27861;&#65292;&#29992;&#20110;&#35757;&#32451;&#25968;&#25454;&#24402;&#22240;&#21644;&#25439;&#22833;&#22320;&#35980;&#30740;&#31350;&#12290;&#20316;&#32773;&#22312;&#19977;&#20010;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#25237;&#24433;&#25110;&#28176;&#21464;&#21644;Hessian&#21521;&#37327;&#20056;&#31215;&#30340;&#33609;&#22270;&#22312;&#38656;&#35201;&#23384;&#20648;&#35768;&#22810;&#36825;&#20123;&#21521;&#37327;&#24182;&#20445;&#30041;&#20851;&#20110;&#23427;&#20204;&#30340;&#30456;&#23545;&#20960;&#20309;&#20449;&#24687;&#30340;&#24212;&#29992;&#20013;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#20004;&#20010;&#37325;&#35201;&#22330;&#26223;&#26159;&#35757;&#32451;&#25968;&#25454;&#24402;&#22240;&#65288;&#36319;&#36394;&#27169;&#22411;&#23545;&#35757;&#32451;&#25968;&#25454;&#30340;&#34892;&#20026;&#65289;&#65292;&#20854;&#20013;&#38656;&#35201;&#23384;&#20648;&#27599;&#20010;&#35757;&#32451;&#31034;&#20363;&#30340;&#28176;&#21464;&#65292;&#20197;&#21450;Hessian&#30340;&#39057;&#35889;&#30740;&#31350;&#65288;&#20998;&#26512;&#35757;&#32451;&#21160;&#24577;&#65289;&#65292;&#20854;&#20013;&#38656;&#35201;&#23384;&#20648;&#22810;&#20010;Hessian&#21521;&#37327;&#20056;&#31215;&#12290;&#34429;&#28982;&#20351;&#29992;&#23494;&#38598;&#30697;&#38453;&#30340;&#33609;&#22270;&#26131;&#20110;&#23454;&#29616;&#65292;&#20294;&#23427;&#20204;&#21463;&#23384;&#20648;&#38480;&#21046;&#65292;&#19981;&#33021;&#25193;&#23637;&#21040;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#12290;&#22312;&#31070;&#32463;&#32593;&#32476;&#20869;&#22312;&#32500;&#24230;&#30340;&#30740;&#31350;&#24037;&#20316;&#30340;&#25512;&#21160;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;&#21487;&#20280;&#32553;&#33609;&#22270;&#31639;&#27861;&#30340;&#35774;&#35745;&#31354;&#38388;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65306;&#35757;&#32451;&#25968;&#25454;&#24402;&#22240;&#65292;Hessian&#35889;&#20998;&#26512;&#21644;&#24494;&#35843;&#39044;&#20808;&#35757;&#32451;&#26102;&#30340;&#20869;&#22312;&#32500;&#24230;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
Random projections or sketches of gradients and Hessian vector products play an essential role in applications where one needs to store many such vectors while retaining accurate information about their relative geometry. Two important scenarios are training data attribution (tracing a model's behavior to the training data), where one needs to store a gradient for each training example, and the study of the spectrum of the Hessian (to analyze the training dynamics), where one needs to store multiple Hessian vector products. While sketches that use dense matrices are easy to implement, they are memory bound and cannot be scaled to modern neural networks. Motivated by work on the intrinsic dimension of neural networks, we propose and study a design space for scalable sketching algorithms. We demonstrate the efficacy of our approach in three applications: training data attribution, the analysis of the Hessian spectrum and the computation of the intrinsic dimension when fine-tuning pre-tra
&lt;/p&gt;</description></item><item><title>&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#26435;&#37325;&#34928;&#20943;&#21644;&#23567;&#30340;&#31867;&#20869;&#21464;&#21270;&#19982;&#20302;&#31209;&#20559;&#24046;&#29616;&#35937;&#26377;&#20851;</title><link>https://arxiv.org/abs/2402.03991</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#30340;&#26435;&#37325;&#34928;&#20943;&#21644;&#31867;&#20869;&#21464;&#21270;&#23567;&#20250;&#23548;&#33268;&#20302;&#31209;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Neural Rank Collapse: Weight Decay and Small Within-Class Variability Yield Low-Rank Bias
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03991
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#26435;&#37325;&#34928;&#20943;&#21644;&#23567;&#30340;&#31867;&#20869;&#21464;&#21270;&#19982;&#20302;&#31209;&#20559;&#24046;&#29616;&#35937;&#26377;&#20851;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#22312;&#28145;&#24230;&#23398;&#20064;&#39046;&#22495;&#30340;&#30740;&#31350;&#26174;&#31034;&#20102;&#19968;&#20010;&#38544;&#21547;&#30340;&#20302;&#31209;&#20559;&#24046;&#29616;&#35937;&#65306;&#28145;&#24230;&#32593;&#32476;&#20013;&#30340;&#26435;&#37325;&#30697;&#38453;&#24448;&#24448;&#36817;&#20284;&#20026;&#20302;&#31209;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#25110;&#20174;&#24050;&#32463;&#35757;&#32451;&#22909;&#30340;&#27169;&#22411;&#20013;&#21435;&#38500;&#30456;&#23545;&#36739;&#23567;&#30340;&#22855;&#24322;&#20540;&#21487;&#20197;&#26174;&#33879;&#20943;&#23567;&#27169;&#22411;&#22823;&#23567;&#65292;&#21516;&#26102;&#20445;&#25345;&#29978;&#33267;&#25552;&#21319;&#27169;&#22411;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#20302;&#31209;&#20559;&#24046;&#30340;&#29702;&#35770;&#30740;&#31350;&#37117;&#28041;&#21450;&#21040;&#31616;&#21270;&#30340;&#32447;&#24615;&#28145;&#24230;&#32593;&#32476;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#24102;&#26377;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#21644;&#26435;&#37325;&#34928;&#20943;&#21442;&#25968;&#30340;&#36890;&#29992;&#32593;&#32476;&#65292;&#24182;&#23637;&#31034;&#20102;&#19968;&#20010;&#26377;&#36259;&#30340;&#31070;&#32463;&#31209;&#23849;&#28291;&#29616;&#35937;&#65292;&#23427;&#23558;&#35757;&#32451;&#22909;&#30340;&#32593;&#32476;&#30340;&#20302;&#31209;&#20559;&#24046;&#19982;&#32593;&#32476;&#30340;&#31070;&#32463;&#23849;&#28291;&#29305;&#24615;&#32852;&#31995;&#36215;&#26469;&#65306;&#38543;&#30528;&#26435;&#37325;&#34928;&#20943;&#21442;&#25968;&#30340;&#22686;&#21152;&#65292;&#32593;&#32476;&#20013;&#27599;&#19968;&#23618;&#30340;&#31209;&#21576;&#27604;&#20363;&#36882;&#20943;&#65292;&#19982;&#21069;&#38754;&#23618;&#30340;&#38544;&#34255;&#31354;&#38388;&#23884;&#20837;&#30340;&#31867;&#20869;&#21464;&#21270;&#25104;&#21453;&#27604;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#24471;&#21040;&#20102;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work in deep learning has shown strong empirical and theoretical evidence of an implicit low-rank bias: weight matrices in deep networks tend to be approximately low-rank and removing relatively small singular values during training or from available trained models may significantly reduce model size while maintaining or even improving model performance. However, the majority of the theoretical investigations around low-rank bias in neural networks deal with oversimplified deep linear networks. In this work, we consider general networks with nonlinear activations and the weight decay parameter, and we show the presence of an intriguing neural rank collapse phenomenon, connecting the low-rank bias of trained networks with networks' neural collapse properties: as the weight decay parameter grows, the rank of each layer in the network decreases proportionally to the within-class variability of the hidden-space embeddings of the previous layers. Our theoretical findings are supporte
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30740;&#31350;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;DP-SGD&#65289;&#20013;&#30340;&#24635;&#26799;&#24230;&#26041;&#24046;&#65292;&#25105;&#20204;&#21457;&#29616;&#22823;&#25209;&#27425;&#22823;&#23567;&#26377;&#21161;&#20110;&#20943;&#23567;&#21063;&#37319;&#27171;&#24341;&#36215;&#30340;&#26041;&#24046;&#65292;&#20174;&#32780;&#25552;&#39640;&#20248;&#21270;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.03990</link><description>&lt;p&gt;
&#21063;&#37319;&#27171;&#24182;&#19981;&#26159;&#39764;&#27861;: &#22823;&#25209;&#37327;&#22823;&#23567;&#28858;&#20160;&#40636;&#36969;&#29992;&#26044;&#24046;&#20998;&#38577;&#31169;&#38568;&#27231;&#20778;&#21270;
&lt;/p&gt;
&lt;p&gt;
Subsampling is not Magic: Why Large Batch Sizes Work for Differentially Private Stochastic Optimisation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03990
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;DP-SGD&#65289;&#20013;&#30340;&#24635;&#26799;&#24230;&#26041;&#24046;&#65292;&#25105;&#20204;&#21457;&#29616;&#22823;&#25209;&#27425;&#22823;&#23567;&#26377;&#21161;&#20110;&#20943;&#23567;&#21063;&#37319;&#27171;&#24341;&#36215;&#30340;&#26041;&#24046;&#65292;&#20174;&#32780;&#25552;&#39640;&#20248;&#21270;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20497;&#30740;&#31350;&#20102;&#25209;&#27425;&#22823;&#23567;&#23565;&#24046;&#20998;&#38577;&#31169;&#38568;&#27231;&#26799;&#24230;&#19979;&#38477;&#65288;DP-SGD&#65289;&#20013;&#32317;&#26799;&#24230;&#26041;&#24046;&#30340;&#24433;&#38911;&#65292;&#23563;&#27714;&#23565;&#22823;&#25209;&#27425;&#22823;&#23567;&#26377;&#29992;&#24615;&#30340;&#29702;&#35542;&#35299;&#37323;&#12290;&#30001;&#26044;DP-SGD&#26159;&#29694;&#20195;&#24046;&#20998;&#38577;&#31169;&#28145;&#24230;&#23416;&#32722;&#30340;&#22522;&#30990;&#65292;&#20854;&#24615;&#36074;&#24050;&#34987;&#24291;&#27867;&#30740;&#31350;&#65292;&#26368;&#36817;&#30340;&#24037;&#20316;&#22312;&#23526;&#36368;&#20013;&#30332;&#29694;&#22823;&#25209;&#27425;&#22823;&#23567;&#26377;&#30410;&#12290;&#28982;&#32780;&#65292;&#23565;&#26044;&#36889;&#31278;&#22909;&#34389;&#30340;&#29702;&#35542;&#35299;&#37323;&#30446;&#21069;&#26368;&#22810;&#21482;&#33021;&#35498;&#26159;&#21855;&#30332;&#24335;&#30340;&#12290;&#25105;&#20497;&#39318;&#20808;&#35264;&#23519;&#21040;&#65292;&#22312;DP-SGD&#20013;&#65292;&#32317;&#26799;&#24230;&#26041;&#24046;&#21487;&#20197;&#20998;&#35299;&#28858;&#30001;&#21063;&#37319;&#27171;&#21644;&#22122;&#32882;&#24341;&#36215;&#30340;&#26041;&#24046;&#12290;&#28982;&#24460;&#65292;&#25105;&#20497;&#35657;&#26126;&#22312;&#28961;&#38480;&#27425;&#36845;&#20195;&#30340;&#26997;&#38480;&#24773;&#27841;&#19979;&#65292;&#26377;&#25928;&#30340;&#22122;&#32882;&#24341;&#36215;&#30340;&#26041;&#24046;&#23565;&#25209;&#27425;&#22823;&#23567;&#26159;&#19981;&#35722;&#30340;&#12290;&#21097;&#19979;&#30340;&#21063;&#37319;&#27171;&#24341;&#36215;&#30340;&#26041;&#24046;&#38568;&#33879;&#25209;&#27425;&#22823;&#23567;&#30340;&#22686;&#22823;&#32780;&#28187;&#23567;&#65292;&#22240;&#27492;&#22823;&#25209;&#27425;&#22823;&#23567;&#28187;&#23567;&#20102;&#26377;&#25928;&#30340;&#32317;&#26799;&#24230;&#26041;&#24046;&#12290;&#25105;&#20497;&#22312;&#25976;&#20540;&#19978;&#30906;&#35469;&#36889;&#31278;&#28472;&#36914;&#30340;&#24773;&#27841;&#22312;&#23526;&#38555;&#29872;&#22659;&#20013;&#26159;&#30456;&#38364;&#30340;&#65292;&#30070;&#25209;&#27425;&#22823;&#23567;&#19981;&#23567;&#30340;&#26178;&#20505;&#26371;&#36215;&#20316;&#29992;&#65292;&#20006;&#19988;&#30332;&#29694;
&lt;/p&gt;
&lt;p&gt;
We study the effect of the batch size to the total gradient variance in differentially private stochastic gradient descent (DP-SGD), seeking a theoretical explanation for the usefulness of large batch sizes. As DP-SGD is the basis of modern DP deep learning, its properties have been widely studied, and recent works have empirically found large batch sizes to be beneficial. However, theoretical explanations of this benefit are currently heuristic at best. We first observe that the total gradient variance in DP-SGD can be decomposed into subsampling-induced and noise-induced variances. We then prove that in the limit of an infinite number of iterations, the effective noise-induced variance is invariant to the batch size. The remaining subsampling-induced variance decreases with larger batch sizes, so large batches reduce the effective total gradient variance. We confirm numerically that the asymptotic regime is relevant in practical settings when the batch size is not small, and find tha
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#36827;&#34892;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#65292;&#22686;&#21152;&#20102;&#23545;&#20854;&#29702;&#35770;&#29702;&#35299;&#12290;&#23454;&#39564;&#35777;&#26126;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#23545;&#20110;&#39640;&#26041;&#24046;&#30340;&#19979;&#28216;&#39044;&#27979;&#22120;&#29305;&#21035;&#26377;&#30410;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#32463;&#39564;&#27861;&#21017;&#29992;&#20110;&#36873;&#25321;&#36866;&#24403;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#25968;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.03985</link><description>&lt;p&gt;
&#23545;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#38598;&#25104;&#36827;&#34892;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
A Bias-Variance Decomposition for Ensembles over Multiple Synthetic Datasets
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03985
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#36827;&#34892;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#65292;&#22686;&#21152;&#20102;&#23545;&#20854;&#29702;&#35770;&#29702;&#35299;&#12290;&#23454;&#39564;&#35777;&#26126;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#23545;&#20110;&#39640;&#26041;&#24046;&#30340;&#19979;&#28216;&#39044;&#27979;&#22120;&#29305;&#21035;&#26377;&#30410;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#32463;&#39564;&#27861;&#21017;&#29992;&#20110;&#36873;&#25321;&#36866;&#24403;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#24378;&#35843;&#20102;&#20026;&#30417;&#30563;&#23398;&#20064;&#29983;&#25104;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#22909;&#22788;&#65292;&#21253;&#25324;&#22686;&#21152;&#20934;&#30830;&#24615;&#12289;&#26356;&#26377;&#25928;&#30340;&#27169;&#22411;&#36873;&#25321;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#36825;&#20123;&#22909;&#22788;&#22312;&#32463;&#39564;&#19978;&#26377;&#26126;&#30830;&#30340;&#25903;&#25345;&#65292;&#20294;&#23545;&#23427;&#20204;&#30340;&#29702;&#35770;&#29702;&#35299;&#30446;&#21069;&#38750;&#24120;&#26377;&#38480;&#12290;&#25105;&#20204;&#36890;&#36807;&#25512;&#23548;&#20351;&#29992;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#20960;&#31181;&#35774;&#32622;&#30340;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#65292;&#26469;&#22686;&#21152;&#29702;&#35770;&#29702;&#35299;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#39044;&#27979;&#65292;&#23545;&#20110;&#39640;&#26041;&#24046;&#30340;&#19979;&#28216;&#39044;&#27979;&#22120;&#65292;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#23558;&#29305;&#21035;&#26377;&#30410;&#65292;&#24182;&#20026;&#22343;&#26041;&#35823;&#24046;&#21644;Brier&#20998;&#25968;&#30340;&#24773;&#20917;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#32463;&#39564;&#27861;&#21017;&#26469;&#36873;&#25321;&#21512;&#36866;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#25968;&#37327;&#12290;&#25105;&#20204;&#36890;&#36807;&#35780;&#20272;&#19968;&#20010;&#38598;&#25104;&#22312;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#20960;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#20197;&#21450;&#19979;&#28216;&#39044;&#27979;&#22120;&#19978;&#30340;&#24615;&#33021;&#26469;&#30740;&#31350;&#25105;&#20204;&#30340;&#29702;&#35770;&#22312;&#23454;&#36341;&#20013;&#30340;&#25928;&#26524;&#12290;&#32467;&#26524;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#34920;&#26126;&#25105;&#20204;&#30340;&#27934;&#23519;&#20063;&#22312;&#23454;&#36341;&#20013;&#20855;&#26377;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies have highlighted the benefits of generating multiple synthetic datasets for supervised learning, from increased accuracy to more effective model selection and uncertainty estimation. These benefits have clear empirical support, but the theoretical understanding of them is currently very light. We seek to increase the theoretical understanding by deriving bias-variance decompositions for several settings of using multiple synthetic datasets. Our theory predicts multiple synthetic datasets to be especially beneficial for high-variance downstream predictors, and yields a simple rule of thumb to select the appropriate number of synthetic datasets in the case of mean-squared error and Brier score. We investigate how our theory works in practice by evaluating the performance of an ensemble over many synthetic datasets for several real datasets and downstream predictors. The results follow our theory, showing that our insights are also practically relevant.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23485;&#26494;&#20551;&#35774;&#19979;&#30340;&#38543;&#26426;&#20248;&#21270;&#20013;Adam&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#22122;&#22768;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#36825;&#20010;&#27169;&#22411;&#19979;&#65292;Adam&#31639;&#27861;&#21487;&#20197;&#20197;&#36739;&#39640;&#30340;&#27010;&#29575;&#39640;&#25928;&#22320;&#23547;&#25214;&#21040;&#19968;&#20010;&#31283;&#23450;&#28857;&#12290;&#19982;&#20854;&#20182;&#38543;&#26426;&#19968;&#38454;&#31639;&#27861;&#30456;&#27604;&#65292;Adam&#31639;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#33258;&#36866;&#24212;&#24615;&#33021;&#65292;&#26080;&#38656;&#35843;&#25972;&#27493;&#38271;&#21644;&#38382;&#39064;&#21442;&#25968;&#12290;</title><link>https://arxiv.org/abs/2402.03982</link><description>&lt;p&gt;
&#22312;&#23485;&#26494;&#20551;&#35774;&#19979;&#20851;&#20110;&#38543;&#26426;&#20248;&#21270;&#20013;Adam&#25910;&#25947;&#24615;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Convergence of Adam for Stochastic Optimization under Relaxed Assumptions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03982
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23485;&#26494;&#20551;&#35774;&#19979;&#30340;&#38543;&#26426;&#20248;&#21270;&#20013;Adam&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#22122;&#22768;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#36825;&#20010;&#27169;&#22411;&#19979;&#65292;Adam&#31639;&#27861;&#21487;&#20197;&#20197;&#36739;&#39640;&#30340;&#27010;&#29575;&#39640;&#25928;&#22320;&#23547;&#25214;&#21040;&#19968;&#20010;&#31283;&#23450;&#28857;&#12290;&#19982;&#20854;&#20182;&#38543;&#26426;&#19968;&#38454;&#31639;&#27861;&#30456;&#27604;&#65292;Adam&#31639;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#33258;&#36866;&#24212;&#24615;&#33021;&#65292;&#26080;&#38656;&#35843;&#25972;&#27493;&#38271;&#21644;&#38382;&#39064;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36866;&#24212;&#24615;&#21160;&#37327;&#35780;&#20272;&#65288;Adam&#65289;&#31639;&#27861;&#22312;&#35757;&#32451;&#21508;&#31181;&#28145;&#24230;&#23398;&#20064;&#20219;&#21153;&#20013;&#38750;&#24120;&#26377;&#25928;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#22312;&#38750;&#20984;&#20809;&#28369;&#22330;&#26223;&#19979;&#65292;&#29305;&#21035;&#26159;&#22312;&#21487;&#33021;&#23384;&#22312;&#26080;&#30028;&#26799;&#24230;&#21644;&#20223;&#23556;&#26041;&#24046;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#20110;Adam&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#26377;&#38480;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#36825;&#20123;&#20855;&#26377;&#25361;&#25112;&#24615;&#26465;&#20214;&#19979;&#30340;&#26222;&#36890;Adam&#31639;&#27861;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#22122;&#22768;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#25511;&#21046;&#30528;&#20223;&#23556;&#26041;&#24046;&#22122;&#22768;&#12289;&#26377;&#30028;&#22122;&#22768;&#21644;&#27425;&#39640;&#26031;&#22122;&#22768;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#36825;&#20010;&#36890;&#29992;&#22122;&#22768;&#27169;&#22411;&#19979;&#65292;Adam&#31639;&#27861;&#21487;&#20197;&#20197;$\mathcal{O}(\text{poly}(\log T)/\sqrt{T})$&#30340;&#27010;&#29575;&#39640;&#25928;&#22320;&#23547;&#25214;&#21040;&#19968;&#20010;&#31283;&#23450;&#28857;&#65292;&#20854;&#20013;$T$&#34920;&#31034;&#24635;&#36845;&#20195;&#27425;&#25968;&#65292;&#19982;&#38543;&#26426;&#19968;&#38454;&#31639;&#27861;&#30340;&#26356;&#24213;&#25928;&#29575;&#30456;&#21305;&#37197;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#22312;&#30456;&#21516;&#26465;&#20214;&#19979;&#65292;Adam&#31639;&#27861;&#26080;&#38656;&#35843;&#25972;&#27493;&#38271;&#21644;&#20219;&#20309;&#38382;&#39064;&#21442;&#25968;&#65292;&#20855;&#26377;&#27604;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26356;&#22909;&#30340;&#33258;&#36866;&#24212;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Adaptive Momentum Estimation (Adam) algorithm is highly effective in training various deep learning tasks. Despite this, there's limited theoretical understanding for Adam, especially when focusing on its vanilla form in non-convex smooth scenarios with potential unbounded gradients and affine variance noise. In this paper, we study vanilla Adam under these challenging conditions. We introduce a comprehensive noise model which governs affine variance noise, bounded noise and sub-Gaussian noise. We show that Adam can find a stationary point with a $\mathcal{O}(\text{poly}(\log T)/\sqrt{T})$ rate in high probability under this general noise model where $T$ denotes total number iterations, matching the lower rate of stochastic first-order algorithms up to logarithm factors. More importantly, we reveal that Adam is free of tuning step-sizes with any problem-parameters, yielding a better adaptation property than the Stochastic Gradient Descent under the same conditions. We also provide 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#38024;&#23545;&#29616;&#20195;&#22823;&#26679;&#26412;&#21644;&#28151;&#21512;&#31867;&#22411;&#38382;&#21367;&#35843;&#26597;&#30340;&#29305;&#28857;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#24322;&#36136;&#32570;&#22833;&#24773;&#20917;&#19979;&#24674;&#22797;&#22797;&#26434;&#25277;&#26679;&#28151;&#21512;&#30697;&#38453;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20004;&#38454;&#27573;&#30340;&#36807;&#31243;&#65292;&#21033;&#29992;&#36923;&#36753;&#22238;&#24402;&#24314;&#27169;&#32570;&#22833;&#26426;&#21046;&#24182;&#26368;&#22823;&#21270;&#21152;&#26435;&#23545;&#25968;&#20284;&#28982;&#20197;&#23454;&#29616;&#30697;&#38453;&#34917;&#20840;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#20855;&#26377;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.03954</link><description>&lt;p&gt;
&#22312;&#24322;&#36136;&#32570;&#22833;&#19979;&#30340;&#22797;&#26434;&#25277;&#26679;&#28151;&#21512;&#30697;&#38453;&#34917;&#20840;
&lt;/p&gt;
&lt;p&gt;
Mixed Matrix Completion in Complex Survey Sampling under Heterogeneous Missingness
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03954
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#38024;&#23545;&#29616;&#20195;&#22823;&#26679;&#26412;&#21644;&#28151;&#21512;&#31867;&#22411;&#38382;&#21367;&#35843;&#26597;&#30340;&#29305;&#28857;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#24322;&#36136;&#32570;&#22833;&#24773;&#20917;&#19979;&#24674;&#22797;&#22797;&#26434;&#25277;&#26679;&#28151;&#21512;&#30697;&#38453;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20004;&#38454;&#27573;&#30340;&#36807;&#31243;&#65292;&#21033;&#29992;&#36923;&#36753;&#22238;&#24402;&#24314;&#27169;&#32570;&#22833;&#26426;&#21046;&#24182;&#26368;&#22823;&#21270;&#21152;&#26435;&#23545;&#25968;&#20284;&#28982;&#20197;&#23454;&#29616;&#30697;&#38453;&#34917;&#20840;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#20855;&#26377;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#20855;&#26377;&#22823;&#26679;&#26412;&#37327;&#21644;&#19981;&#26029;&#22686;&#38271;&#30340;&#28151;&#21512;&#31867;&#22411;&#38382;&#21367;&#30340;&#35843;&#26597;&#38656;&#35201;&#31283;&#20581;&#19988;&#21487;&#25193;&#23637;&#30340;&#20998;&#26512;&#26041;&#27861;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#36890;&#36807;&#22797;&#26434;&#30340;&#25277;&#26679;&#26041;&#24335;&#33719;&#24471;&#30340;&#28151;&#21512;&#25968;&#25454;&#26694;&#30697;&#38453;&#24674;&#22797;&#38382;&#39064;&#65292;&#20854;&#20013;&#26465;&#30446;&#36981;&#24490;&#19981;&#21516;&#30340;&#25351;&#25968;&#20998;&#24067;&#24182;&#21463;&#21040;&#24322;&#36136;&#32570;&#22833;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#30340;&#26041;&#27861;&#65306;&#22312;&#31532;&#19968;&#38454;&#27573;&#65292;&#25105;&#20204;&#20351;&#29992;&#36923;&#36753;&#22238;&#24402;&#23545;&#26465;&#30446;&#32423;&#32570;&#22833;&#26426;&#21046;&#36827;&#34892;&#24314;&#27169;&#65307;&#22312;&#31532;&#20108;&#38454;&#27573;&#65292;&#25105;&#20204;&#36890;&#36807;&#26368;&#22823;&#21270;&#24102;&#26377;&#20302;&#31209;&#32422;&#26463;&#30340;&#21152;&#26435;&#23545;&#25968;&#20284;&#28982;&#26469;&#23436;&#25104;&#30446;&#26631;&#21442;&#25968;&#30697;&#38453;&#30340;&#34917;&#20840;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#24555;&#36895;&#19988;&#21487;&#25193;&#23637;&#30340;&#20272;&#35745;&#31639;&#27861;&#65292;&#23427;&#23454;&#29616;&#20102;&#27425;&#32447;&#24615;&#25910;&#25947;&#65292;&#24182;&#20005;&#26684;&#25512;&#23548;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#20272;&#35745;&#35823;&#24046;&#19978;&#30028;&#12290;&#23454;&#39564;&#32467;&#26524;&#25903;&#25345;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#24182;&#19988;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#22312;&#19982;&#20854;&#20182;&#29616;&#26377;&#26041;&#27861;&#30340;&#27604;&#36739;&#20013;&#23637;&#29616;&#20102;&#20854;&#20248;&#28857;&#12290;&#35813;&#26041;&#27861;&#34987;&#24212;&#29992;&#20110;&#23545;&#22269;&#23478;&#20581;&#24247;&#19982;...
&lt;/p&gt;
&lt;p&gt;
Modern surveys with large sample sizes and growing mixed-type questionnaires require robust and scalable analysis methods. In this work, we consider recovering a mixed dataframe matrix, obtained by complex survey sampling, with entries following different canonical exponential distributions and subject to heterogeneous missingness. To tackle this challenging task, we propose a two-stage procedure: in the first stage, we model the entry-wise missing mechanism by logistic regression, and in the second stage, we complete the target parameter matrix by maximizing a weighted log-likelihood with a low-rank constraint. We propose a fast and scalable estimation algorithm that achieves sublinear convergence, and the upper bound for the estimation error of the proposed method is rigorously derived. Experimental results support our theoretical claims, and the proposed estimator shows its merits compared to other existing methods. The proposed method is applied to analyze the National Health and N
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#20174;&#30701;&#26399;&#20449;&#21495;&#20013;&#23398;&#20064;&#25351;&#26631;&#65292;&#30452;&#25509;&#26368;&#22823;&#21270;&#25351;&#26631;&#19982;&#21271;&#26497;&#24230;&#37327;&#26631;&#20934;&#20043;&#38388;&#30340;&#32479;&#35745;&#33021;&#21147;&#65292;&#20174;&#32780;&#20943;&#23569;&#22312;&#32447;&#25511;&#21046;&#23454;&#39564;&#30340;&#25104;&#26412;&#12290;</title><link>https://arxiv.org/abs/2402.03915</link><description>&lt;p&gt;
&#23398;&#20064;&#26368;&#22823;&#21270;&#21152;&#36895;A/B&#27979;&#35797;&#30340;&#25351;&#26631;
&lt;/p&gt;
&lt;p&gt;
Learning Metrics that Maximise Power for Accelerated A/B-Tests
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03915
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#20174;&#30701;&#26399;&#20449;&#21495;&#20013;&#23398;&#20064;&#25351;&#26631;&#65292;&#30452;&#25509;&#26368;&#22823;&#21270;&#25351;&#26631;&#19982;&#21271;&#26497;&#24230;&#37327;&#26631;&#20934;&#20043;&#38388;&#30340;&#32479;&#35745;&#33021;&#21147;&#65292;&#20174;&#32780;&#20943;&#23569;&#22312;&#32447;&#25511;&#21046;&#23454;&#39564;&#30340;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25216;&#26415;&#20844;&#21496;&#20013;&#65292;&#22312;&#32447;&#25511;&#21046;&#23454;&#39564;&#26159;&#19968;&#31181;&#37325;&#35201;&#30340;&#24037;&#20855;&#65292;&#21487;&#20197;&#23454;&#29616;&#33258;&#20449;&#30340;&#20915;&#31574;&#12290;&#23450;&#20041;&#20102;&#19968;&#20010;&#21271;&#26497;&#24230;&#37327;&#26631;&#20934;&#65288;&#22914;&#38271;&#26399;&#25910;&#20837;&#25110;&#29992;&#25143;&#20445;&#30041;&#65289;&#65292;&#22312;A/B&#27979;&#35797;&#20013;&#65292;&#33021;&#22815;&#22312;&#36825;&#20010;&#25351;&#26631;&#19978;&#26377;&#32479;&#35745;&#26174;&#33879;&#25552;&#21319;&#30340;&#31995;&#32479;&#21464;&#20307;&#21487;&#20197;&#34987;&#35748;&#20026;&#26159;&#20248;&#36234;&#30340;&#12290;&#28982;&#32780;&#65292;&#21271;&#26497;&#24230;&#37327;&#26631;&#20934;&#36890;&#24120;&#20855;&#26377;&#26102;&#24310;&#21644;&#19981;&#25935;&#24863;&#24615;&#12290;&#22240;&#27492;&#65292;&#23454;&#39564;&#30340;&#25104;&#26412;&#24456;&#39640;&#65306;&#23454;&#39564;&#38656;&#35201;&#38271;&#26102;&#38388;&#36816;&#34892;&#65292;&#21363;&#20351;&#22914;&#27492;&#65292;&#20108;&#31867;&#38169;&#35823;&#65288;&#21363;&#20551;&#38452;&#24615;&#65289;&#20173;&#28982;&#26222;&#36941;&#23384;&#22312;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#30701;&#26399;&#20449;&#21495;&#20013;&#23398;&#20064;&#25351;&#26631;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#25351;&#26631;&#30452;&#25509;&#26368;&#22823;&#21270;&#23427;&#20204;&#30456;&#23545;&#20110;&#21271;&#26497;&#24230;&#37327;&#26631;&#20934;&#25152;&#20855;&#26377;&#30340;&#32479;&#35745;&#33021;&#21147;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#29616;&#26377;&#26041;&#27861;&#23481;&#26131;&#36807;&#25311;&#21512;&#30340;&#38382;&#39064;&#65292;&#21363;&#26356;&#39640;&#30340;&#24179;&#22343;&#24230;&#37327;&#25935;&#24863;&#24615;&#24182;&#19981;&#24847;&#21619;&#30528;&#25913;&#36827;&#20102;&#20108;&#31867;&#38169;&#35823;&#65292;&#25105;&#20204;&#24314;&#35758;&#36890;&#36807;&#26368;&#23567;&#21270;&#25351;&#26631;&#22312;&#36807;&#21435;&#23454;&#39564;&#30340;$log$&#19978;&#20135;&#29983;&#30340;$p$-value&#26469;&#35299;&#20915;&#12290;&#25105;&#20204;&#20174;&#20004;&#20010;&#31038;&#20132;&#23186;&#20307;&#24212;&#29992;&#31243;&#24207;&#20013;&#25910;&#38598;&#20102;&#36825;&#26679;&#30340;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online controlled experiments are a crucial tool to allow for confident decision-making in technology companies. A North Star metric is defined (such as long-term revenue or user retention), and system variants that statistically significantly improve on this metric in an A/B-test can be considered superior. North Star metrics are typically delayed and insensitive. As a result, the cost of experimentation is high: experiments need to run for a long time, and even then, type-II errors (i.e. false negatives) are prevalent.   We propose to tackle this by learning metrics from short-term signals that directly maximise the statistical power they harness with respect to the North Star. We show that existing approaches are prone to overfitting, in that higher average metric sensitivity does not imply improved type-II errors, and propose to instead minimise the $p$-values a metric would have produced on a log of past experiments. We collect such datasets from two social media applications with
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#36890;&#29992;&#39044;&#27979;&#26041;&#38754;&#30340;&#24615;&#33021;&#35780;&#20272;&#65292;&#24341;&#20837;&#20102;&#25209;&#37327;&#36951;&#25022;&#30340;&#27010;&#24565;&#65292;&#24182;&#30740;&#31350;&#20102;&#22312;&#26080;&#35760;&#24518;&#28304;&#21644;&#19968;&#38454;&#39532;&#23572;&#21487;&#22827;&#28304;&#30340;&#24773;&#20917;&#19979;&#30340;&#28176;&#36817;&#20540;&#12290;</title><link>https://arxiv.org/abs/2402.03901</link><description>&lt;p&gt;
&#25209;&#22788;&#29702;&#36890;&#29992;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Batch Universal Prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03901
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#36890;&#29992;&#39044;&#27979;&#26041;&#38754;&#30340;&#24615;&#33021;&#35780;&#20272;&#65292;&#24341;&#20837;&#20102;&#25209;&#37327;&#36951;&#25022;&#30340;&#27010;&#24565;&#65292;&#24182;&#30740;&#31350;&#20102;&#22312;&#26080;&#35760;&#24518;&#28304;&#21644;&#19968;&#38454;&#39532;&#23572;&#21487;&#22827;&#28304;&#30340;&#24773;&#20917;&#19979;&#30340;&#28176;&#36817;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22240;&#20854;&#24778;&#20154;&#30340;&#29983;&#25104;&#31867;&#20284;&#20154;&#31867;&#33521;&#35821;&#21477;&#23376;&#30340;&#33021;&#21147;&#32780;&#36817;&#24180;&#26469;&#22791;&#21463;&#20851;&#27880;&#12290;LLMs&#26412;&#36136;&#19978;&#26159;&#39044;&#27979;&#22120;&#65292;&#36890;&#36807;&#20272;&#35745;&#32473;&#23450;&#36807;&#21435;&#30340;&#21333;&#35789;&#24207;&#21015;&#30340;&#27010;&#29575;&#26469;&#35780;&#20272;&#23427;&#20204;&#30340;&#24615;&#33021;&#12290;&#22240;&#27492;&#65292;&#20174;&#36890;&#29992;&#39044;&#27979;&#30340;&#35282;&#24230;&#35780;&#20272;&#23427;&#20204;&#30340;&#24615;&#33021;&#26159;&#33258;&#28982;&#32780;&#28982;&#30340;&#12290;&#20026;&#20102;&#20844;&#24179;&#22320;&#36827;&#34892;&#35780;&#20272;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#25209;&#37327;&#36951;&#25022;&#30340;&#27010;&#24565;&#20316;&#20026;&#32463;&#20856;&#24179;&#22343;&#36951;&#25022;&#30340;&#20462;&#25913;&#65292;&#24182;&#30740;&#31350;&#20102;&#22312;&#26080;&#35760;&#24518;&#28304;&#21644;&#19968;&#38454;&#39532;&#23572;&#21487;&#22827;&#28304;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#20110;&#22686;&#21152;&#24120;&#25968;&#39044;&#27979;&#22120;&#30340;&#28176;&#36817;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have recently gained much popularity due to their surprising ability at generating human-like English sentences. LLMs are essentially predictors, estimating the probability of a sequence of words given the past. Therefore, it is natural to evaluate their performance from a universal prediction perspective. In order to do that fairly, we introduce the notion of batch regret as a modification of the classical average regret, and we study its asymptotical value for add-constant predictors, in the case of memoryless sources and first-order Markov sources.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#35299;&#20915;&#32422;&#26463;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#30340;&#26694;&#26550;&#65292;&#24182;&#25552;&#20379;&#20102;&#22810;&#31181;&#36229;&#26799;&#24230;&#20272;&#35745;&#31574;&#30053;&#65292;&#24182;&#23545;&#20854;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#35813;&#26694;&#26550;&#19981;&#20165;&#36866;&#29992;&#20110;&#30830;&#23450;&#24615;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#36824;&#36866;&#29992;&#20110;&#38543;&#26426;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#19968;&#33324;&#30340;&#22238;&#36864;&#12290;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#65292;&#35813;&#26694;&#26550;&#37117;&#20855;&#26377;&#24456;&#39640;&#30340;&#23454;&#29992;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.03883</link><description>&lt;p&gt;
&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#36827;&#34892;&#21452;&#23618;&#20248;&#21270;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Framework for Bilevel Optimization on Riemannian Manifolds
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03883
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#35299;&#20915;&#32422;&#26463;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#30340;&#26694;&#26550;&#65292;&#24182;&#25552;&#20379;&#20102;&#22810;&#31181;&#36229;&#26799;&#24230;&#20272;&#35745;&#31574;&#30053;&#65292;&#24182;&#23545;&#20854;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#35813;&#26694;&#26550;&#19981;&#20165;&#36866;&#29992;&#20110;&#30830;&#23450;&#24615;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#36824;&#36866;&#29992;&#20110;&#38543;&#26426;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#19968;&#33324;&#30340;&#22238;&#36864;&#12290;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#65292;&#35813;&#26694;&#26550;&#37117;&#20855;&#26377;&#24456;&#39640;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21452;&#23618;&#20248;&#21270;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#24212;&#29992;&#20013;&#36234;&#26469;&#36234;&#24120;&#35265;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#32422;&#26463;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#21464;&#37327;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20960;&#31181;&#22312;&#27969;&#24418;&#19978;&#30340;&#36229;&#26799;&#24230;&#20272;&#35745;&#31574;&#30053;&#65292;&#24182;&#30740;&#31350;&#20102;&#23427;&#20204;&#30340;&#20272;&#35745;&#35823;&#24046;&#12290;&#25105;&#20204;&#23545;&#27969;&#24418;&#19978;&#30340;&#36229;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#21644;&#22797;&#26434;&#24615;&#20998;&#26512;&#12290;&#25105;&#20204;&#36824;&#23558;&#36825;&#20123;&#30740;&#31350;&#25193;&#23637;&#21040;&#38543;&#26426;&#21452;&#23618;&#20248;&#21270;&#21644;&#20351;&#29992;&#19968;&#33324;&#30340;&#22238;&#36864;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26694;&#26550;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bilevel optimization has seen an increasing presence in various domains of applications. In this work, we propose a framework for solving bilevel optimization problems where variables of both lower and upper level problems are constrained on Riemannian manifolds. We provide several hypergradient estimation strategies on manifolds and study their estimation error. We provide convergence and complexity analysis for the proposed hypergradient descent algorithm on manifolds. We also extend the developments to stochastic bilevel optimization and to the use of general retraction. We showcase the utility of the proposed framework on various applications.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#39640;&#32500;&#32447;&#24615;&#39044;&#27979;&#22120;&#21644;&#23436;&#20840;&#38543;&#26426;&#32570;&#22833;&#25968;&#25454;&#30340;&#32972;&#26223;&#19979;&#65292;&#22825;&#30495;&#25554;&#34917;&#26041;&#27861;&#22312;&#39044;&#27979;&#24615;&#33021;&#19978;&#30340;&#20559;&#24046;&#36739;&#20302;&#65292;&#24182;&#19988;&#22312;&#38750;&#24120;&#20302;&#30340;&#32500;&#24230;&#19979;&#20381;&#28982;&#26159;&#26377;&#25928;&#30340;&#12290;</title><link>https://arxiv.org/abs/2402.03839</link><description>&lt;p&gt;
&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#65306;&#30740;&#31350;&#22825;&#30495;&#25554;&#34917;&#30340;&#25104;&#21151;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Random features models: a way to study the success of naive imputation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03839
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#39640;&#32500;&#32447;&#24615;&#39044;&#27979;&#22120;&#21644;&#23436;&#20840;&#38543;&#26426;&#32570;&#22833;&#25968;&#25454;&#30340;&#32972;&#26223;&#19979;&#65292;&#22825;&#30495;&#25554;&#34917;&#26041;&#27861;&#22312;&#39044;&#27979;&#24615;&#33021;&#19978;&#30340;&#20559;&#24046;&#36739;&#20302;&#65292;&#24182;&#19988;&#22312;&#38750;&#24120;&#20302;&#30340;&#32500;&#24230;&#19979;&#20381;&#28982;&#26159;&#26377;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24120;&#25968;&#65288;&#22825;&#30495;&#65289;&#25554;&#34917;&#20316;&#20026;&#19968;&#31181;&#26368;&#31616;&#21333;&#26131;&#29992;&#30340;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#30340;&#25216;&#26415;&#65292;&#20173;&#28982;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#22312;&#39044;&#27979;&#30446;&#30340;&#19978;&#21487;&#33021;&#20250;&#24341;&#36215;&#24456;&#22823;&#30340;&#20559;&#24046;&#65292;&#22240;&#20026;&#25554;&#34917;&#30340;&#36755;&#20837;&#21487;&#33021;&#19982;&#30495;&#23454;&#30340;&#22522;&#30784;&#25968;&#25454;&#24046;&#24322;&#24456;&#22823;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#39640;&#32500;&#32447;&#24615;&#39044;&#27979;&#22120;&#30340;&#32972;&#26223;&#19979;&#65292;&#24403;&#25968;&#25454;&#34987;&#20551;&#35774;&#20026;&#23436;&#20840;&#38543;&#26426;&#32570;&#22833;&#65288;MCAR&#65289;&#26102;&#65292;&#36825;&#31181;&#20559;&#24046;&#36739;&#20302;&#12290;&#26412;&#25991;&#36890;&#36807;&#30830;&#35748;&#30452;&#35273;&#65292;&#23436;&#21892;&#20102;&#32447;&#24615;&#39044;&#27979;&#22120;&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#22825;&#30495;&#25554;&#34917;&#22312;&#38750;&#24120;&#20302;&#30340;&#32500;&#24230;&#19979;&#20173;&#28982;&#26159;&#26377;&#25928;&#30340;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#29420;&#29305;&#30340;&#22522;&#30784;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#65292;&#36825;&#20010;&#27169;&#22411;&#22312;&#35266;&#23519;&#29305;&#24449;&#30340;&#32500;&#24230;&#21464;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#20026;&#30740;&#31350;&#39044;&#27979;&#24615;&#33021;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#26694;&#26550;&#12290;&#22522;&#20110;&#36825;&#20123;&#29702;&#35770;&#32467;&#26524;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#24212;&#29992;&#20110;&#38646;&#25554;&#34917;&#25968;&#25454;&#30340;&#38543;&#26426;&#26799;&#24230;&#65288;SGD&#65289;&#39044;&#27979;&#22120;&#30340;&#26377;&#38480;&#26679;&#26412;&#30028;&#38480;&#65292;&#19968;&#31181;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Constant (naive) imputation is still widely used in practice as this is a first easy-to-use technique to deal with missing data. Yet, this simple method could be expected to induce a large bias for prediction purposes, as the imputed input may strongly differ from the true underlying data. However, recent works suggest that this bias is low in the context of high-dimensional linear predictors when data is supposed to be missing completely at random (MCAR). This paper completes the picture for linear predictors by confirming the intuition that the bias is negligible  and  that surprisingly naive imputation also remains relevant in very low dimension.To this aim, we consider a unique underlying random features model, which offers a rigorous framework for studying predictive performances, whilst the dimension of the observed features varies.Building on these theoretical results, we establish finite-sample bounds on stochastic gradient (SGD) predictors applied to zero-imputed data, a strat
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377;&#20999;&#29255;Wasserstein Weisfeiler-Lehman&#22270;&#26680;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#26041;&#27861;&#65292;&#22312;&#22788;&#29702;&#22823;&#35268;&#27169;&#31232;&#30095;&#22270;&#24418;&#25968;&#25454;&#38598;&#26102;&#20855;&#26377;&#27491;&#23450;&#24615;&#21644;&#26174;&#33879;&#30340;&#22797;&#26434;&#24230;&#38477;&#20302;&#12290;</title><link>https://arxiv.org/abs/2402.03838</link><description>&lt;p&gt;
&#24102;&#26377;&#20999;&#29255;Wasserstein Weisfeiler-Lehman&#22270;&#26680;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Gaussian process regression with Sliced Wasserstein Weisfeiler-Lehman graph kernels
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03838
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377;&#20999;&#29255;Wasserstein Weisfeiler-Lehman&#22270;&#26680;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#26041;&#27861;&#65292;&#22312;&#22788;&#29702;&#22823;&#35268;&#27169;&#31232;&#30095;&#22270;&#24418;&#25968;&#25454;&#38598;&#26102;&#20855;&#26377;&#27491;&#23450;&#24615;&#21644;&#26174;&#33879;&#30340;&#22797;&#26434;&#24230;&#38477;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30417;&#30563;&#23398;&#20064;&#22312;&#35745;&#31639;&#29289;&#29702;&#39046;&#22495;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#22240;&#20026;&#23427;&#33021;&#22815;&#26377;&#25928;&#22320;&#25552;&#21462;&#22797;&#26434;&#27169;&#24335;&#65292;&#29992;&#20110;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;&#25110;&#39044;&#27979;&#26448;&#26009;&#24615;&#36136;&#31561;&#20219;&#21153;&#12290;&#20256;&#32479;&#19978;&#65292;&#36825;&#31867;&#25968;&#25454;&#38598;&#30001;&#20855;&#26377;&#22823;&#37327;&#33410;&#28857;&#30340;&#32593;&#26684;&#34920;&#31034;&#30340;&#36755;&#20837;&#65288;&#35270;&#20026;&#22270;&#24418;&#65289;&#21644;&#20351;&#29992;&#25968;&#20540;&#27714;&#35299;&#22120;&#33719;&#24471;&#30340;&#30456;&#24212;&#36755;&#20986;&#32452;&#25104;&#12290;&#36825;&#24847;&#21619;&#30528;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#24517;&#39035;&#33021;&#22815;&#22788;&#29702;&#20855;&#26377;&#36830;&#32493;&#33410;&#28857;&#23646;&#24615;&#30340;&#22823;&#35268;&#27169;&#31232;&#30095;&#22270;&#24418;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#65292;&#24341;&#20837;&#20102;&#20999;&#29255;Wasserstein Weisfeiler-Lehman&#65288;SWWL&#65289;&#22270;&#26680;&#12290;&#19982;&#29616;&#26377;&#30340;&#22270;&#26680;&#30456;&#27604;&#65292;&#25152;&#25552;&#20986;&#30340;SWWL&#26680;&#20855;&#26377;&#27491;&#23450;&#24615;&#21644;&#26174;&#33879;&#30340;&#22797;&#26434;&#24230;&#38477;&#20302;&#65292;&#20351;&#20854;&#33021;&#22815;&#22788;&#29702;&#27492;&#21069;&#19981;&#21487;&#22788;&#29702;&#30340;&#25968;&#25454;&#38598;&#12290;&#26032;&#30340;&#26680;&#39318;&#20808;&#22312;&#20998;&#23376;&#22270;&#20998;&#31867;&#20013;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Supervised learning has recently garnered significant attention in the field of computational physics due to its ability to effectively extract complex patterns for tasks like solving partial differential equations, or predicting material properties. Traditionally, such datasets consist of inputs given as meshes with a large number of nodes representing the problem geometry (seen as graphs), and corresponding outputs obtained with a numerical solver. This means the supervised learning model must be able to handle large and sparse graphs with continuous node attributes. In this work, we focus on Gaussian process regression, for which we introduce the Sliced Wasserstein Weisfeiler-Lehman (SWWL) graph kernel. In contrast to existing graph kernels, the proposed SWWL kernel enjoys positive definiteness and a drastic complexity reduction, which  makes it possible to process datasets that were previously impossible to handle. The new kernel is first validated on graph classification for molec
&lt;/p&gt;</description></item><item><title>SMOTE&#26159;&#19968;&#31181;&#22788;&#29702;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#30340;&#24120;&#29992;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#65292;&#23427;&#36890;&#36807;&#22797;&#21046;&#21407;&#22987;&#23569;&#25968;&#26679;&#26412;&#26469;&#37325;&#26032;&#29983;&#25104;&#21407;&#22987;&#20998;&#24067;&#12290;&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;SMOTE&#30340;&#23494;&#24230;&#22312;&#23569;&#25968;&#26679;&#26412;&#20998;&#24067;&#30340;&#36793;&#30028;&#38468;&#36817;&#36880;&#28176;&#20943;&#23567;&#65292;&#20174;&#32780;&#39564;&#35777;&#20102;BorderLine SMOTE&#31574;&#30053;&#30340;&#21512;&#29702;&#24615;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;SMOTE&#30456;&#20851;&#31574;&#30053;&#65292;&#24182;&#19982;&#20854;&#20182;&#37325;&#26032;&#24179;&#34913;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#26368;&#32456;&#21457;&#29616;&#65292;&#22312;&#25968;&#25454;&#38598;&#26497;&#24230;&#19981;&#24179;&#34913;&#30340;&#24773;&#20917;&#19979;&#65292;SMOTE&#12289;&#25552;&#20986;&#30340;&#26041;&#27861;&#25110;&#27424;&#37319;&#26679;&#31243;&#24207;&#26159;&#26368;&#20339;&#30340;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2402.03819</link><description>&lt;p&gt;
SMOTE&#30340;&#29702;&#35770;&#21644;&#23454;&#39564;&#30740;&#31350;&#65306;&#20851;&#20110;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#30340;&#38480;&#21046;&#21644;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Theoretical and experimental study of SMOTE: limitations and comparisons of rebalancing strategies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03819
&lt;/p&gt;
&lt;p&gt;
SMOTE&#26159;&#19968;&#31181;&#22788;&#29702;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#30340;&#24120;&#29992;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#65292;&#23427;&#36890;&#36807;&#22797;&#21046;&#21407;&#22987;&#23569;&#25968;&#26679;&#26412;&#26469;&#37325;&#26032;&#29983;&#25104;&#21407;&#22987;&#20998;&#24067;&#12290;&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;SMOTE&#30340;&#23494;&#24230;&#22312;&#23569;&#25968;&#26679;&#26412;&#20998;&#24067;&#30340;&#36793;&#30028;&#38468;&#36817;&#36880;&#28176;&#20943;&#23567;&#65292;&#20174;&#32780;&#39564;&#35777;&#20102;BorderLine SMOTE&#31574;&#30053;&#30340;&#21512;&#29702;&#24615;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;SMOTE&#30456;&#20851;&#31574;&#30053;&#65292;&#24182;&#19982;&#20854;&#20182;&#37325;&#26032;&#24179;&#34913;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#26368;&#32456;&#21457;&#29616;&#65292;&#22312;&#25968;&#25454;&#38598;&#26497;&#24230;&#19981;&#24179;&#34913;&#30340;&#24773;&#20917;&#19979;&#65292;SMOTE&#12289;&#25552;&#20986;&#30340;&#26041;&#27861;&#25110;&#27424;&#37319;&#26679;&#31243;&#24207;&#26159;&#26368;&#20339;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
SMOTE&#65288;Synthetic Minority Oversampling Technique&#65289;&#26159;&#22788;&#29702;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#24120;&#29992;&#30340;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#28176;&#36827;&#24773;&#20917;&#19979;&#65292;SMOTE&#65288;&#40664;&#35748;&#21442;&#25968;&#65289;&#36890;&#36807;&#31616;&#21333;&#22797;&#21046;&#21407;&#22987;&#23569;&#25968;&#26679;&#26412;&#26469;&#37325;&#26032;&#29983;&#25104;&#21407;&#22987;&#20998;&#24067;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#22312;&#23569;&#25968;&#26679;&#26412;&#20998;&#24067;&#30340;&#25903;&#25345;&#36793;&#30028;&#38468;&#36817;&#65292;SMOTE&#30340;&#23494;&#24230;&#20250;&#20943;&#23567;&#65292;&#20174;&#32780;&#39564;&#35777;&#20102;&#24120;&#35265;&#30340;BorderLine SMOTE&#31574;&#30053;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;SMOTE&#30456;&#20851;&#31574;&#30053;&#65292;&#24182;&#23558;&#23427;&#20204;&#19982;&#29616;&#26377;&#30340;&#37325;&#26032;&#24179;&#34913;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#21482;&#26377;&#24403;&#25968;&#25454;&#38598;&#26497;&#24230;&#19981;&#24179;&#34913;&#26102;&#25165;&#38656;&#35201;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#12290;&#23545;&#20110;&#36825;&#31181;&#25968;&#25454;&#38598;&#65292;SMOTE&#12289;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#25110;&#27424;&#37319;&#26679;&#31243;&#24207;&#26159;&#26368;&#20339;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Synthetic Minority Oversampling Technique (SMOTE) is a common rebalancing strategy for handling imbalanced data sets. Asymptotically, we prove that SMOTE (with default parameter) regenerates the original distribution by simply copying the original minority samples. We also prove that SMOTE density vanishes near the boundary of the support of the minority distribution, therefore justifying the common BorderLine SMOTE strategy. Then we introduce two new SMOTE-related strategies, and compare them with state-of-the-art rebalancing procedures. We show that rebalancing strategies are only required when the data set is highly imbalanced. For such data sets, SMOTE, our proposals, or undersampling procedures are the best strategies.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30340;&#36129;&#29486;&#26159;&#23558;&#21487;&#21152;&#24615;&#21644;&#20027;&#21160;&#23376;&#31354;&#38388;&#19982;&#22810;&#37325;&#30495;&#23454;&#24230;&#31574;&#30053;&#32467;&#21512;&#65292;&#35299;&#20915;&#20102;&#39640;&#32500;&#39640;&#26031;&#36807;&#31243;&#24314;&#27169;&#20013;&#30340;&#32500;&#24230;&#28798;&#38590;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2402.03809</link><description>&lt;p&gt;
&#32467;&#21512;&#21487;&#21152;&#24615;&#21644;&#20027;&#21160;&#23376;&#31354;&#38388;&#29992;&#20110;&#39640;&#32500;&#39640;&#26031;&#36807;&#31243;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Combining additivity and active subspaces for high-dimensional Gaussian process modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03809
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30340;&#36129;&#29486;&#26159;&#23558;&#21487;&#21152;&#24615;&#21644;&#20027;&#21160;&#23376;&#31354;&#38388;&#19982;&#22810;&#37325;&#30495;&#23454;&#24230;&#31574;&#30053;&#32467;&#21512;&#65292;&#35299;&#20915;&#20102;&#39640;&#32500;&#39640;&#26031;&#36807;&#31243;&#24314;&#27169;&#20013;&#30340;&#32500;&#24230;&#28798;&#38590;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#26159;&#19968;&#31181;&#34987;&#24191;&#27867;&#25509;&#21463;&#30340;&#22238;&#24402;&#21644;&#20998;&#31867;&#25216;&#26415;&#65292;&#22240;&#20854;&#33391;&#22909;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12289;&#20998;&#26512;&#21487;&#36861;&#28335;&#24615;&#21644;&#20869;&#32622;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#33021;&#21147;&#32780;&#20493;&#21463;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#24403;&#21464;&#37327;&#25968;&#37327;&#22686;&#21152;&#26102;&#65292;&#23427;&#20204;&#21463;&#21040;&#32500;&#24230;&#28798;&#38590;&#30340;&#22256;&#25200;&#12290;&#36825;&#20010;&#25361;&#25112;&#36890;&#24120;&#36890;&#36807;&#22312;&#38382;&#39064;&#20013;&#20551;&#35774;&#39069;&#22806;&#32467;&#26500;&#26469;&#35299;&#20915;&#65292;&#39318;&#36873;&#36873;&#39033;&#26159;&#21487;&#21152;&#24615;&#25110;&#20302;&#20869;&#22312;&#32500;&#24230;&#12290;&#25105;&#20204;&#22312;&#39640;&#32500;&#39640;&#26031;&#36807;&#31243;&#24314;&#27169;&#20013;&#30340;&#36129;&#29486;&#26159;&#23558;&#23427;&#20204;&#19982;&#22810;&#37325;&#30495;&#23454;&#24230;&#31574;&#30053;&#30456;&#32467;&#21512;&#65292;&#36890;&#36807;&#23545;&#21512;&#25104;&#20989;&#25968;&#21644;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes are a widely embraced technique for regression and classification due to their good prediction accuracy, analytical tractability and built-in capabilities for uncertainty quantification. However, they suffer from the curse of dimensionality whenever the number of variables increases. This challenge is generally addressed by assuming additional structure in theproblem, the preferred options being either additivity or low intrinsic dimensionality. Our contribution for high-dimensional Gaussian process modeling is to combine them with a multi-fidelity strategy, showcasing the advantages through experiments on synthetic functions and datasets.
&lt;/p&gt;</description></item><item><title>EERO &#26159;&#19968;&#31181;&#26089;&#26399;&#36864;&#20986;&#19982;&#25298;&#32477;&#36873;&#39033;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22810;&#20010;&#20998;&#31867;&#22120;&#26469;&#36873;&#25321;&#27599;&#20010;&#23454;&#20363;&#30340;&#36864;&#20986;&#22836;&#65292;&#20197;&#23454;&#29616;&#39640;&#25928;&#20998;&#31867;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#23427;&#21487;&#20197;&#26377;&#25928;&#31649;&#29702;&#39044;&#31639;&#20998;&#37197;&#24182;&#25552;&#39640;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.03779</link><description>&lt;p&gt;
EERO: &#26089;&#26399;&#36864;&#20986;&#19982;&#25298;&#32477;&#36873;&#39033;&#29992;&#20110;&#26377;&#38480;&#39044;&#31639;&#19979;&#30340;&#39640;&#25928;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
EERO: Early Exit with Reject Option for Efficient Classification with limited budget
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03779
&lt;/p&gt;
&lt;p&gt;
EERO &#26159;&#19968;&#31181;&#26089;&#26399;&#36864;&#20986;&#19982;&#25298;&#32477;&#36873;&#39033;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22810;&#20010;&#20998;&#31867;&#22120;&#26469;&#36873;&#25321;&#27599;&#20010;&#23454;&#20363;&#30340;&#36864;&#20986;&#22836;&#65292;&#20197;&#23454;&#29616;&#39640;&#25928;&#20998;&#31867;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#23427;&#21487;&#20197;&#26377;&#25928;&#31649;&#29702;&#39044;&#31639;&#20998;&#37197;&#24182;&#25552;&#39640;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#36827;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#19981;&#26029;&#22797;&#26434;&#21270;&#35201;&#27714;&#21019;&#26032;&#30340;&#26041;&#27861;&#26469;&#26377;&#25928;&#31649;&#29702;&#35745;&#31639;&#36164;&#28304;&#12290;&#20854;&#20013;&#19968;&#31181;&#26041;&#27861;&#26159;&#26089;&#26399;&#36864;&#20986;&#31574;&#30053;&#65292;&#36890;&#36807;&#25552;&#20379;&#32553;&#30701;&#31616;&#21333;&#25968;&#25454;&#23454;&#20363;&#22788;&#29702;&#36335;&#24452;&#30340;&#26426;&#21046;&#65292;&#23454;&#29616;&#33258;&#36866;&#24212;&#35745;&#31639;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;EERO&#65292;&#19968;&#31181;&#23558;&#26089;&#26399;&#36864;&#20986;&#38382;&#39064;&#36716;&#21270;&#20026;&#20351;&#29992;&#20855;&#26377;&#25298;&#32477;&#36873;&#39033;&#30340;&#22810;&#20010;&#20998;&#31867;&#22120;&#38382;&#39064;&#30340;&#26032;&#26041;&#27861;&#65292;&#20197;&#20415;&#26356;&#22909;&#22320;&#36873;&#25321;&#27599;&#20010;&#23454;&#20363;&#30340;&#36864;&#20986;&#22836;&#12290;&#25105;&#20204;&#20351;&#29992;&#25351;&#25968;&#26435;&#37325;&#32858;&#21512;&#26469;&#26657;&#20934;&#19981;&#21516;&#22836;&#37096;&#36864;&#20986;&#30340;&#27010;&#29575;&#65292;&#20197;&#20445;&#35777;&#19968;&#20010;&#22266;&#23450;&#30340;&#39044;&#31639;&#12290;&#25105;&#20204;&#32771;&#34385;&#36125;&#21494;&#26031;&#39118;&#38505;&#12289;&#39044;&#31639;&#32422;&#26463;&#21644;&#22836;&#37096;&#29305;&#23450;&#39044;&#31639;&#28040;&#32791;&#31561;&#22240;&#32032;&#12290;&#36890;&#36807;&#22312;Cifar&#21644;ImageNet&#25968;&#25454;&#38598;&#19978;&#20351;&#29992;ResNet-18&#27169;&#22411;&#21644;ConvNext&#26550;&#26500;&#36827;&#34892;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20165;&#33021;&#26377;&#25928;&#31649;&#29702;&#39044;&#31639;&#20998;&#37197;&#65292;&#36824;&#33021;&#25552;&#39640;&#36807;&#24230;&#32771;&#34385;&#22330;&#26223;&#20013;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The increasing complexity of advanced machine learning models requires innovative approaches to manage computational resources effectively. One such method is the Early Exit strategy, which allows for adaptive computation by providing a mechanism to shorten the processing path for simpler data instances. In this paper, we propose EERO, a new methodology to translate the problem of early exiting to a problem of using multiple classifiers with reject option in order to better select the exiting head for each instance. We calibrate the probabilities of exiting at the different heads using aggregation with exponential weights to guarantee a fixed budget .We consider factors such as Bayesian risk, budget constraints, and head-specific budget consumption. Experimental results, conducted using a ResNet-18 model and a ConvNext architecture on Cifar and ImageNet datasets, demonstrate that our method not only effectively manages budget allocation but also enhances accuracy in overthinking scenar
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;PrivateLASSO&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#38543;&#26426;&#19978;&#19979;&#25991;&#32447;&#24615;&#36172;&#33218;&#38382;&#39064;&#65292;&#24182;&#22312;&#24046;&#20998;&#38544;&#31169;&#30340;&#32422;&#26463;&#19979;&#35777;&#26126;&#20102;&#20854;&#38544;&#31169;&#21644;&#23454;&#29992;&#24615;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.03737</link><description>&lt;p&gt;
&#38754;&#21521;&#39640;&#32500;&#19978;&#19979;&#25991;&#32447;&#24615;&#36172;&#33218;&#38382;&#39064;&#30340;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Differentially Private High Dimensional Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03737
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;PrivateLASSO&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#38543;&#26426;&#19978;&#19979;&#25991;&#32447;&#24615;&#36172;&#33218;&#38382;&#39064;&#65292;&#24182;&#22312;&#24046;&#20998;&#38544;&#31169;&#30340;&#32422;&#26463;&#19979;&#35777;&#26126;&#20102;&#20854;&#38544;&#31169;&#21644;&#23454;&#29992;&#24615;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#21442;&#25968;&#21521;&#37327;&#20026;$s_{0}$-&#31232;&#30095;&#19988;&#20915;&#31574;&#21046;&#23450;&#32773;&#21463;&#21040;&#24046;&#20998;&#38544;&#31169;&#30340;&#20013;&#22830;&#21644;&#26412;&#22320;&#27169;&#22411;&#30340;&#32422;&#26463;&#19979;&#32771;&#34385;&#39640;&#32500;&#38543;&#26426;&#19978;&#19979;&#25991;&#32447;&#24615;&#36172;&#33218;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;PrivateLASSO&#65292;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;LASSO&#36172;&#33218;&#31639;&#27861;&#12290;PrivateLASSO&#22522;&#20110;&#20004;&#20010;&#23376;&#31243;&#24207;&#65306;(i)&#22522;&#20110;&#31232;&#30095;&#30828;&#38408;&#20540;&#30340;&#38544;&#31169;&#26426;&#21046;&#21644;(ii)&#29992;&#20110;&#35782;&#21035;&#21442;&#25968;$\theta$&#25903;&#25345;&#38598;&#30340;&#38408;&#20540;&#35268;&#21017;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;PrivateLASSO&#30340;&#26368;&#23567;&#26368;&#22823;&#31169;&#26377;&#19979;&#30028;&#65292;&#24182;&#22312;&#26631;&#20934;&#20551;&#35774;&#19979;&#24314;&#31435;&#20102;PrivateLASSO&#22312;&#20013;&#22830;&#27169;&#22411;&#19979;&#30340;&#38544;&#31169;&#21644;&#23454;&#29992;&#24615;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a high-dimensional stochastic contextual linear bandit problem when the parameter vector is $s_{0}$-sparse and the decision maker is subject to privacy constraints under both central and local models of differential privacy. We present PrivateLASSO, a differentially private LASSO bandit algorithm. PrivateLASSO is based on two sub-routines: (i) a sparse hard-thresholding-based privacy mechanism and (ii) an episodic thresholding rule for identifying the support of the parameter $\theta$. We prove minimax private lower bounds and establish privacy and utility guarantees for PrivateLASSO for the central model under standard assumptions.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ISAHP&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#20174;&#24322;&#27493;&#12289;&#30456;&#20114;&#20381;&#36182;&#30340;&#22810;&#31867;&#22411;&#20107;&#20214;&#24207;&#21015;&#20013;&#26080;&#30417;&#30563;&#22320;&#23398;&#20064;&#23454;&#20363;&#32423;&#30340;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#12290;&#23427;&#26159;&#31532;&#19968;&#20010;&#28385;&#36275;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#35201;&#27714;&#30340;&#31070;&#32463;&#28857;&#36807;&#31243;&#27169;&#22411;&#65292;&#24182;&#21033;&#29992;&#21464;&#21387;&#22120;&#30340;&#33258;&#25105;&#27880;&#24847;&#26426;&#21046;&#26469;&#23454;&#29616;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#26029;&#12290;</title><link>https://arxiv.org/abs/2402.03726</link><description>&lt;p&gt;
&#20174;&#23454;&#20363;&#32423;&#30340;&#33258;&#25105;&#27880;&#24847;&#21147;Hawkes&#36807;&#31243;&#20013;&#23398;&#20064;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;
&lt;/p&gt;
&lt;p&gt;
Learning Granger Causality from Instance-wise Self-attentive Hawkes Processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03726
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ISAHP&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#20174;&#24322;&#27493;&#12289;&#30456;&#20114;&#20381;&#36182;&#30340;&#22810;&#31867;&#22411;&#20107;&#20214;&#24207;&#21015;&#20013;&#26080;&#30417;&#30563;&#22320;&#23398;&#20064;&#23454;&#20363;&#32423;&#30340;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#12290;&#23427;&#26159;&#31532;&#19968;&#20010;&#28385;&#36275;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#35201;&#27714;&#30340;&#31070;&#32463;&#28857;&#36807;&#31243;&#27169;&#22411;&#65292;&#24182;&#21033;&#29992;&#21464;&#21387;&#22120;&#30340;&#33258;&#25105;&#27880;&#24847;&#26426;&#21046;&#26469;&#23454;&#29616;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#20174;&#24322;&#27493;&#12289;&#30456;&#20114;&#20381;&#36182;&#30340;&#22810;&#31867;&#22411;&#20107;&#20214;&#24207;&#21015;&#20013;&#23398;&#20064;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#30340;&#38382;&#39064;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#23545;&#20197;&#26080;&#30417;&#30563;&#30340;&#26041;&#24335;&#21457;&#29616;&#23454;&#20363;&#32423;&#30340;&#22240;&#26524;&#32467;&#26500;&#24863;&#20852;&#36259;&#12290;&#23454;&#20363;&#32423;&#22240;&#26524;&#20851;&#31995;&#35782;&#21035;&#21333;&#20010;&#20107;&#20214;&#20043;&#38388;&#30340;&#22240;&#26524;&#20851;&#31995;&#65292;&#20026;&#20915;&#31574;&#25552;&#20379;&#20102;&#26356;&#31934;&#32454;&#21270;&#30340;&#20449;&#24687;&#12290;&#29616;&#26377;&#25991;&#29486;&#20013;&#30340;&#24037;&#20316;&#35201;&#20040;&#38656;&#35201;&#24378;&#21152;&#19968;&#20123;&#20551;&#35774;&#65292;&#27604;&#22914;&#24378;&#21152;&#21040;&#24378;&#24230;&#20989;&#25968;&#20013;&#30340;&#32447;&#24615;&#20551;&#35774;&#65292;&#35201;&#20040;&#21551;&#21457;&#24335;&#22320;&#23450;&#20041;&#27169;&#22411;&#21442;&#25968;&#65292;&#36825;&#20123;&#19981;&#19968;&#23450;&#28385;&#36275;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#30340;&#35201;&#27714;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#21363;&#23454;&#20363;&#32423;&#33258;&#25105;&#27880;&#24847;&#21147;Hawkes&#36807;&#31243;&#65288;ISAHP&#65289;&#65292;&#21487;&#20197;&#30452;&#25509;&#25512;&#26029;&#20107;&#20214;&#23454;&#20363;&#32423;&#30340;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#12290;ISAHP&#26159;&#31532;&#19968;&#20010;&#28385;&#36275;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#35201;&#27714;&#30340;&#31070;&#32463;&#28857;&#36807;&#31243;&#27169;&#22411;&#12290;&#23427;&#21033;&#29992;&#20102;&#21464;&#21387;&#22120;&#30340;&#33258;&#25105;&#27880;&#24847;&#26426;&#21046;&#65292;&#19982;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#30340;&#21407;&#29702;&#30456;&#19968;&#33268;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;ISAHP&#30340;&#26377;&#25928;&#24615;&#21644;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We address the problem of learning Granger causality from asynchronous, interdependent, multi-type event sequences. In particular, we are interested in discovering instance-level causal structures in an unsupervised manner. Instance-level causality identifies causal relationships among individual events, providing more fine-grained information for decision-making. Existing work in the literature either requires strong assumptions, such as linearity in the intensity function, or heuristically defined model parameters that do not necessarily meet the requirements of Granger causality. We propose Instance-wise Self-Attentive Hawkes Processes (ISAHP), a novel deep learning framework that can directly infer the Granger causality at the event instance level. ISAHP is the first neural point process model that meets the requirements of Granger causality. It leverages the self-attention mechanism of the transformer to align with the principles of Granger causality. We empirically demonstrate th
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#30340;&#32479;&#35745;&#27979;&#35797;&#26041;&#27861;&#65288;VAE-AD&#27979;&#35797;&#65289;&#65292;&#36890;&#36807;&#37327;&#21270;&#24322;&#24120;&#21306;&#22495;&#30340;&#21487;&#38752;&#24615;&#65292;&#21487;&#20197;&#25511;&#21046;&#35823;&#26816;&#30340;&#27010;&#29575;&#21040;&#25152;&#26399;&#26395;&#30340;&#27700;&#24179;&#12290;</title><link>https://arxiv.org/abs/2402.03724</link><description>&lt;p&gt;
&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#30340;&#32479;&#35745;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Statistical Test for Anomaly Detections by Variational Auto-Encoders
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03724
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#30340;&#32479;&#35745;&#27979;&#35797;&#26041;&#27861;&#65288;VAE-AD&#27979;&#35797;&#65289;&#65292;&#36890;&#36807;&#37327;&#21270;&#24322;&#24120;&#21306;&#22495;&#30340;&#21487;&#38752;&#24615;&#65292;&#21487;&#20197;&#25511;&#21046;&#35823;&#26816;&#30340;&#27010;&#29575;&#21040;&#25152;&#26399;&#26395;&#30340;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#65288;AD&#65289;&#30340;&#21487;&#38752;&#24615;&#35780;&#20272;&#12290;&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#37324;&#65292;&#22522;&#20110;VAE&#30340;AD&#24050;&#32463;&#22312;&#21508;&#20010;&#35282;&#24230;&#36827;&#34892;&#20102;&#31215;&#26497;&#30340;&#30740;&#31350;&#65292;&#20174;&#26041;&#27861;&#24320;&#21457;&#21040;&#24212;&#29992;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#24403;AD&#30340;&#32467;&#26524;&#29992;&#20110;&#39640;&#39118;&#38505;&#30340;&#20915;&#31574;&#26102;&#65292;&#22914;&#21307;&#23398;&#35786;&#26029;&#65292;&#38656;&#35201;&#30830;&#20445;&#26816;&#27979;&#21040;&#30340;&#24322;&#24120;&#30340;&#21487;&#38752;&#24615;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;VAE-AD&#27979;&#35797;&#20316;&#20026;&#22312;&#32479;&#35745;&#26816;&#39564;&#26694;&#26550;&#19979;&#37327;&#21270;&#22522;&#20110;VAE&#30340;AD&#30340;&#32479;&#35745;&#21487;&#38752;&#24615;&#30340;&#26041;&#27861;&#12290;&#21033;&#29992;VAE-AD&#27979;&#35797;&#65292;&#21487;&#20197;&#20197;p&#20540;&#30340;&#24418;&#24335;&#37327;&#21270;VAE&#26816;&#27979;&#21040;&#30340;&#24322;&#24120;&#21306;&#22495;&#30340;&#21487;&#38752;&#24615;&#12290;&#36825;&#24847;&#21619;&#30528;&#65292;&#22914;&#26524;&#22312;p&#20540;&#20302;&#20110;&#26576;&#20010;&#38408;&#20540;&#26102;&#23459;&#24067;&#20026;&#24322;&#24120;&#65292;&#21017;&#21487;&#20197;&#23558;&#35823;&#26816;&#30340;&#27010;&#29575;&#25511;&#21046;&#22312;&#25152;&#26399;&#26395;&#30340;&#27700;&#24179;&#12290;&#30001;&#20110;VAE-AD&#27979;&#35797;&#26159;&#22522;&#20110;&#19968;&#31181;&#31216;&#20026;&#36873;&#25321;&#24615;&#25512;&#29702;&#30340;&#26032;&#32479;&#35745;&#25512;&#26029;&#26694;&#26550;&#26500;&#24314;&#30340;&#65292;&#20854;&#26377;&#25928;&#24615;&#26159;&#30830;&#20445;&#34987;&#35777;&#26126;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this study, we consider the reliability assessment of anomaly detection (AD) using Variational Autoencoder (VAE). Over the last decade, VAE-based AD has been actively studied in various perspective, from method development to applied research. However, when the results of ADs are used in high-stakes decision-making, such as in medical diagnosis, it is necessary to ensure the reliability of the detected anomalies. In this study, we propose the VAE-AD Test as a method for quantifying the statistical reliability of VAE-based AD within the framework of statistical testing. Using the VAE-AD Test, the reliability of the anomaly regions detected by a VAE can be quantified in the form of p-values. This means that if an anomaly is declared when the p-value is below a certain threshold, it is possible to control the probability of false detection to a desired level. Since the VAE-AD Test is constructed based on a new statistical inference framework called selective inference, its validity is 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#21644;&#32479;&#19968;&#31163;&#25955;&#21644;&#36830;&#32493;&#26102;&#38388;&#31163;&#25955;&#21435;&#22122;&#25193;&#25955;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#25968;&#23398;&#31616;&#21270;&#21644;&#25512;&#23548;&#65292;&#20351;&#24471;&#31163;&#25955;&#25193;&#25955;&#30340;&#35757;&#32451;&#26356;&#20934;&#30830;&#26131;&#20248;&#21270;&#65292;&#24182;&#19988;&#23454;&#29616;&#20102;&#31934;&#30830;&#21644;&#21152;&#36895;&#30340;&#37319;&#26679;&#12290;&#21516;&#26102;&#65292;&#25104;&#21151;&#22320;&#32479;&#19968;&#20102;&#31163;&#25955;&#26102;&#38388;&#21644;&#36830;&#32493;&#26102;&#38388;&#31163;&#25955;&#25193;&#25955;&#12290;</title><link>https://arxiv.org/abs/2402.03701</link><description>&lt;p&gt;
&#25913;&#36827;&#21644;&#32479;&#19968;&#31163;&#25955;&#21644;&#36830;&#32493;&#26102;&#38388;&#31163;&#25955;&#21435;&#22122;&#25193;&#25955;
&lt;/p&gt;
&lt;p&gt;
Improving and Unifying Discrete&amp;Continuous-time Discrete Denoising Diffusion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03701
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#21644;&#32479;&#19968;&#31163;&#25955;&#21644;&#36830;&#32493;&#26102;&#38388;&#31163;&#25955;&#21435;&#22122;&#25193;&#25955;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#25968;&#23398;&#31616;&#21270;&#21644;&#25512;&#23548;&#65292;&#20351;&#24471;&#31163;&#25955;&#25193;&#25955;&#30340;&#35757;&#32451;&#26356;&#20934;&#30830;&#26131;&#20248;&#21270;&#65292;&#24182;&#19988;&#23454;&#29616;&#20102;&#31934;&#30830;&#21644;&#21152;&#36895;&#30340;&#37319;&#26679;&#12290;&#21516;&#26102;&#65292;&#25104;&#21151;&#22320;&#32479;&#19968;&#20102;&#31163;&#25955;&#26102;&#38388;&#21644;&#36830;&#32493;&#26102;&#38388;&#31163;&#25955;&#25193;&#25955;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;&#22312;&#33258;&#28982;&#31163;&#25955;&#25968;&#25454;&#22914;&#35821;&#35328;&#21644;&#22270;&#24418;&#19978;&#24471;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#34429;&#28982;&#31163;&#25955;&#26102;&#38388;&#31163;&#25955;&#25193;&#25955;&#24050;&#32463;&#24314;&#31435;&#20102;&#19968;&#27573;&#26102;&#38388;&#65292;&#20294;&#30452;&#21040;&#26368;&#36817;Campbell&#31561;&#20154;&#65288;2022&#65289;&#25165;&#24341;&#20837;&#20102;&#36830;&#32493;&#26102;&#38388;&#31163;&#25955;&#25193;&#25955;&#30340;&#31532;&#19968;&#20010;&#26694;&#26550;&#12290;&#28982;&#32780;&#65292;&#20182;&#20204;&#30340;&#35757;&#32451;&#21644;&#37319;&#26679;&#36807;&#31243;&#19982;&#31163;&#25955;&#26102;&#38388;&#29256;&#26412;&#26377;&#24456;&#22823;&#24046;&#24322;&#65292;&#38656;&#35201;&#38750;&#24179;&#20961;&#30340;&#36817;&#20284;&#25165;&#33021;&#36827;&#34892;&#21487;&#34892;&#24615;&#20998;&#26512;&#12290;&#26412;&#25991;&#39318;&#20808;&#20171;&#32461;&#20102;&#19968;&#31995;&#21015;&#23545;&#21464;&#20998;&#19979;&#30028;&#30340;&#25968;&#23398;&#31616;&#21270;&#65292;&#36825;&#20123;&#31616;&#21270;&#20351;&#31163;&#25955;&#25193;&#25955;&#30340;&#35757;&#32451;&#26356;&#21152;&#20934;&#30830;&#21644;&#26131;&#20110;&#20248;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#21453;&#21521;&#21435;&#22122;&#20844;&#24335;&#65292;&#33021;&#22815;&#23454;&#29616;&#31934;&#30830;&#21644;&#21152;&#36895;&#30340;&#37319;&#26679;&#65292;&#26356;&#37325;&#35201;&#30340;&#26159;&#33021;&#22815;&#20248;&#38597;&#22320;&#32479;&#19968;&#31163;&#25955;&#26102;&#38388;&#21644;&#36830;&#32493;&#26102;&#38388;&#31163;&#25955;&#25193;&#25955;&#12290;&#36890;&#36807;&#26356;&#31616;&#21333;&#30340;&#20998;&#26512;&#20844;&#24335;&#65292;&#21069;&#21521;&#21644;&#29616;&#22312;&#20063;&#21253;&#25324;&#20102;&#21518;&#21521;&#27010;&#29575;&#21487;&#20197;&#28789;&#27963;&#22320;&#36866;&#24212;&#20219;&#20309;&#22122;&#22768;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
Discrete diffusion models have seen a surge of attention with applications on naturally discrete data such as language and graphs. Although discrete-time discrete diffusion has been established for a while, only recently Campbell et al. (2022) introduced the first framework for continuous-time discrete diffusion. However, their training and sampling processes differ significantly from the discrete-time version, necessitating nontrivial approximations for tractability. In this paper, we first present a series of mathematical simplifications of the variational lower bound that enable more accurate and easy-to-optimize training for discrete diffusion. In addition, we derive a simple formulation for backward denoising that enables exact and accelerated sampling, and importantly, an elegant unification of discrete-time and continuous-time discrete diffusion. Thanks to simpler analytical formulations, both forward and now also backward probabilities can flexibly accommodate any noise distrib
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20013;&#20934;&#30830;&#22320;&#27979;&#37327;&#39640;&#36798;1&#20159;&#21442;&#25968;&#30340;&#23616;&#37096;&#23398;&#20064;&#31995;&#25968;(LLC)&#65292;&#24182;&#35777;&#26126;&#20102;&#20272;&#35745;&#24471;&#21040;&#30340;LLC&#20855;&#26377;&#37325;&#32553;&#25918;&#19981;&#21464;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.03698</link><description>&lt;p&gt;
&#22312;&#22823;&#35268;&#27169;&#24773;&#20917;&#19979;&#20272;&#35745;&#23616;&#37096;&#23398;&#20064;&#31995;&#25968;
&lt;/p&gt;
&lt;p&gt;
Estimating the Local Learning Coefficient at Scale
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03698
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20013;&#20934;&#30830;&#22320;&#27979;&#37327;&#39640;&#36798;1&#20159;&#21442;&#25968;&#30340;&#23616;&#37096;&#23398;&#20064;&#31995;&#25968;(LLC)&#65292;&#24182;&#35777;&#26126;&#20102;&#20272;&#35745;&#24471;&#21040;&#30340;LLC&#20855;&#26377;&#37325;&#32553;&#25918;&#19981;&#21464;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23616;&#37096;&#23398;&#20064;&#31995;&#25968;(LLC)&#26159;&#19968;&#31181;&#37327;&#21270;&#27169;&#22411;&#22797;&#26434;&#24615;&#30340;&#21407;&#21017;&#24615;&#26041;&#27861;&#65292;&#26368;&#21021;&#26159;&#22312;&#36125;&#21494;&#26031;&#32479;&#35745;&#20013;&#20351;&#29992;&#22855;&#24322;&#23398;&#20064;&#29702;&#35770;(SLT)&#25512;&#23548;&#20986;&#26469;&#30340;&#12290;&#24050;&#30693;&#26377;&#20960;&#31181;&#25968;&#20540;&#20272;&#35745;&#23616;&#37096;&#23398;&#20064;&#31995;&#25968;&#30340;&#26041;&#27861;&#65292;&#20294;&#36804;&#20170;&#20026;&#27490;&#36825;&#20123;&#26041;&#27861;&#23578;&#26410;&#25193;&#23637;&#21040;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#25110;&#25968;&#25454;&#38598;&#30340;&#35268;&#27169;&#12290;&#36890;&#36807;&#22312;arXiv:2308.12108 [stat.ML]&#20013;&#24320;&#21457;&#30340;&#19968;&#31181;&#26041;&#27861;&#65292;&#25105;&#20204;&#32463;&#39564;&#35777;&#26126;&#21487;&#20197;&#20934;&#30830;&#21644;&#33258;&#27965;&#22320;&#27979;&#37327;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;(DLN)&#20013;&#39640;&#36798;1&#20159;&#21442;&#25968;&#30340;&#23616;&#37096;&#23398;&#20064;&#31995;&#25968;(LLC)&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#20272;&#35745;&#24471;&#21040;&#30340;LLC&#20855;&#26377;&#29702;&#35770;&#25968;&#37327;&#25152;&#20855;&#22791;&#30340;&#37325;&#32553;&#25918;&#19981;&#21464;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The \textit{local learning coefficient} (LLC) is a principled way of quantifying model complexity, originally derived in the context of Bayesian statistics using singular learning theory (SLT). Several methods are known for numerically estimating the local learning coefficient, but so far these methods have not been extended to the scale of modern deep learning architectures or data sets. Using a method developed in {\tt arXiv:2308.12108 [stat.ML]} we empirically show how the LLC may be measured accurately and self-consistently for deep linear networks (DLNs) up to 100M parameters. We also show that the estimated LLC has the rescaling invariance that holds for the theoretical quantity.
&lt;/p&gt;</description></item><item><title>PARD&#26159;&#19968;&#31181;&#23558;&#25193;&#25955;&#27169;&#22411;&#19982;&#33258;&#22238;&#24402;&#26041;&#27861;&#30456;&#32467;&#21512;&#30340;&#32622;&#25442;&#19981;&#21464;&#24615;&#33258;&#22238;&#24402;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;&#22270;&#20013;&#30340;&#37096;&#20998;&#39034;&#24207;&#20197;&#22359;&#36880;&#22359;&#30340;&#33258;&#22238;&#24402;&#26041;&#24335;&#29983;&#25104;&#22270;&#12290;</title><link>https://arxiv.org/abs/2402.03687</link><description>&lt;p&gt;
Pard: &#20855;&#26377;&#32622;&#25442;&#19981;&#21464;&#24615;&#30340;&#33258;&#22238;&#24402;&#25193;&#25955;&#29992;&#20110;&#22270;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Pard: Permutation-Invariant Autoregressive Diffusion for Graph Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03687
&lt;/p&gt;
&lt;p&gt;
PARD&#26159;&#19968;&#31181;&#23558;&#25193;&#25955;&#27169;&#22411;&#19982;&#33258;&#22238;&#24402;&#26041;&#27861;&#30456;&#32467;&#21512;&#30340;&#32622;&#25442;&#19981;&#21464;&#24615;&#33258;&#22238;&#24402;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;&#22270;&#20013;&#30340;&#37096;&#20998;&#39034;&#24207;&#20197;&#22359;&#36880;&#22359;&#30340;&#33258;&#22238;&#24402;&#26041;&#24335;&#29983;&#25104;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#33258;&#22238;&#24402;&#27169;&#22411;&#23545;&#20110;&#22270;&#30340;&#39034;&#24207;&#25935;&#24863;&#65292;&#20294;&#20854;&#31616;&#21333;&#26377;&#25928;&#65292;&#22312;&#22270;&#29983;&#25104;&#39046;&#22495;&#19968;&#30452;&#21344;&#25454;&#20027;&#23548;&#22320;&#20301;&#12290;&#28982;&#32780;&#65292;&#25193;&#25955;&#27169;&#22411;&#22240;&#20854;&#32622;&#25442;&#19981;&#21464;&#24615;&#32780;&#36234;&#26469;&#36234;&#21463;&#20851;&#27880;&#12290;&#30446;&#21069;&#30340;&#22270;&#25193;&#25955;&#27169;&#22411;&#19968;&#27425;&#24615;&#29983;&#25104;&#22270;&#65292;&#20294;&#38656;&#35201;&#39069;&#22806;&#30340;&#29305;&#24449;&#21644;&#25104;&#21315;&#19978;&#19975;&#27493;&#30340;&#21435;&#22122;&#25165;&#33021;&#36798;&#21040;&#26368;&#20339;&#24615;&#33021;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;PARD&#65292;&#19968;&#31181;&#23558;&#25193;&#25955;&#27169;&#22411;&#19982;&#33258;&#22238;&#24402;&#26041;&#27861;&#30456;&#32467;&#21512;&#30340;&#32622;&#25442;&#19981;&#21464;&#24615;&#33258;&#22238;&#24402;&#25193;&#25955;&#27169;&#22411;&#12290;PARD&#21033;&#29992;&#33258;&#22238;&#24402;&#27169;&#22411;&#30340;&#25928;&#26524;&#21644;&#25928;&#29575;&#65292;&#21516;&#26102;&#20445;&#25345;&#32622;&#25442;&#19981;&#21464;&#24615;&#65292;&#26080;&#38656;&#20851;&#27880;&#22270;&#30340;&#39034;&#24207;&#25935;&#24863;&#24615;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#21457;&#29616;&#19982;&#38598;&#21512;&#19981;&#21516;&#65292;&#22270;&#20013;&#30340;&#20803;&#32032;&#24182;&#19981;&#26159;&#23436;&#20840;&#26080;&#24207;&#30340;&#65292;&#33410;&#28857;&#21644;&#36793;&#26377;&#19968;&#20010;&#29420;&#29305;&#30340;&#37096;&#20998;&#39034;&#24207;&#12290;&#21033;&#29992;&#36825;&#20010;&#37096;&#20998;&#39034;&#24207;&#65292;PARD&#20197;&#22359;&#36880;&#22359;&#30340;&#33258;&#22238;&#24402;&#26041;&#24335;&#29983;&#25104;&#22270;&#65292;&#20854;&#20013;&#27599;&#20010;&#22359;&#30340;&#27010;&#29575;&#20026;c&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph generation has been dominated by autoregressive models due to their simplicity and effectiveness, despite their sensitivity to ordering. Yet diffusion models have garnered increasing attention, as they offer comparable performance while being permutation-invariant. Current graph diffusion models generate graphs in a one-shot fashion, but they require extra features and thousands of denoising steps to achieve optimal performance. We introduce PARD, a Permutation-invariant Auto Regressive Diffusion model that integrates diffusion models with autoregressive methods. PARD harnesses the effectiveness and efficiency of the autoregressive model while maintaining permutation invariance without ordering sensitivity. Specifically, we show that contrary to sets, elements in a graph are not entirely unordered and there is a unique partial order for nodes and edges. With this partial order, PARD generates a graph in a block-by-block, autoregressive fashion, where each block's probability is c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#20010;&#22522;&#20110;Frank-Wolfe&#31639;&#27861;&#30340;&#26032;&#30340;&#39640;&#25928;&#27714;&#35299;&#22120;&#26469;&#35299;&#20915;&#20559;&#24046;Gromov-Wasserstein&#38382;&#39064;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;PGW&#38382;&#39064;&#26500;&#25104;&#20102;&#24230;&#37327;&#27979;&#24230;&#31354;&#38388;&#30340;&#24230;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.03664</link><description>&lt;p&gt;
&#39640;&#25928;&#27714;&#35299;&#20559;&#24046;Gromov-Wasserstein&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Efficient Solvers for Partial Gromov-Wasserstein
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03664
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#20010;&#22522;&#20110;Frank-Wolfe&#31639;&#27861;&#30340;&#26032;&#30340;&#39640;&#25928;&#27714;&#35299;&#22120;&#26469;&#35299;&#20915;&#20559;&#24046;Gromov-Wasserstein&#38382;&#39064;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;PGW&#38382;&#39064;&#26500;&#25104;&#20102;&#24230;&#37327;&#27979;&#24230;&#31354;&#38388;&#30340;&#24230;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20559;&#24046;Gromov-Wasserstein&#65288;PGW&#65289;&#38382;&#39064;&#21487;&#20197;&#27604;&#36739;&#20855;&#26377;&#19981;&#22343;&#21248;&#36136;&#37327;&#30340;&#24230;&#37327;&#31354;&#38388;&#20013;&#30340;&#27979;&#24230;&#65292;&#20174;&#32780;&#23454;&#29616;&#36825;&#20123;&#31354;&#38388;&#20043;&#38388;&#30340;&#19981;&#24179;&#34913;&#21644;&#37096;&#20998;&#21305;&#37197;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;PGW&#38382;&#39064;&#21487;&#20197;&#36716;&#21270;&#20026;Gromov-Wasserstein&#38382;&#39064;&#30340;&#19968;&#20010;&#21464;&#31181;&#65292;&#31867;&#20284;&#20110;&#25226;&#20559;&#24046;&#26368;&#20248;&#36816;&#36755;&#38382;&#39064;&#36716;&#21270;&#20026;&#26368;&#20248;&#36816;&#36755;&#38382;&#39064;&#12290;&#36825;&#20010;&#36716;&#21270;&#23548;&#33268;&#20102;&#20004;&#20010;&#26032;&#30340;&#27714;&#35299;&#22120;&#65292;&#22522;&#20110;Frank-Wolfe&#31639;&#27861;&#65292;&#25968;&#23398;&#21644;&#35745;&#31639;&#19978;&#31561;&#20215;&#65292;&#25552;&#20379;&#20102;&#39640;&#25928;&#30340;PGW&#38382;&#39064;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;PGW&#38382;&#39064;&#26500;&#25104;&#20102;&#24230;&#37327;&#27979;&#24230;&#31354;&#38388;&#30340;&#24230;&#37327;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#19982;&#29616;&#26377;&#22522;&#32447;&#26041;&#27861;&#22312;&#24418;&#29366;&#21305;&#37197;&#21644;&#27491;&#26679;&#26412;&#26410;&#26631;&#35760;&#23398;&#20064;&#38382;&#39064;&#19978;&#30340;&#35745;&#31639;&#26102;&#38388;&#21644;&#24615;&#33021;&#27604;&#36739;&#65292;&#39564;&#35777;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#27714;&#35299;&#22120;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The partial Gromov-Wasserstein (PGW) problem facilitates the comparison of measures with unequal masses residing in potentially distinct metric spaces, thereby enabling unbalanced and partial matching across these spaces. In this paper, we demonstrate that the PGW problem can be transformed into a variant of the Gromov-Wasserstein problem, akin to the conversion of the partial optimal transport problem into an optimal transport problem. This transformation leads to two new solvers, mathematically and computationally equivalent, based on the Frank-Wolfe algorithm, that provide efficient solutions to the PGW problem. We further establish that the PGW problem constitutes a metric for metric measure spaces. Finally, we validate the effectiveness of our proposed solvers in terms of computation time and performance on shape-matching and positive-unlabeled learning problems, comparing them against existing baselines.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20248;&#21270;&#26694;&#26550;&#65292;&#20351;&#29992;&#23884;&#22871;&#30340;&#20302;&#31209;&#36817;&#20284;&#26041;&#27861;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#36816;&#31639;&#31526;&#30340;&#22855;&#24322;&#20540;&#20998;&#35299;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#26080;&#32422;&#26463;&#20248;&#21270;&#20844;&#24335;&#38544;&#24335;&#39640;&#25928;&#22320;&#20445;&#25345;&#23398;&#20064;&#20989;&#25968;&#30340;&#27491;&#20132;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.03655</link><description>&lt;p&gt;
&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#36890;&#36807;&#23884;&#22871;&#20302;&#31209;&#36817;&#20284;&#23454;&#29616;&#36816;&#31639;&#31526;&#30340;&#22855;&#24322;&#20540;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
Operator SVD with Neural Networks via Nested Low-Rank Approximation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03655
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20248;&#21270;&#26694;&#26550;&#65292;&#20351;&#29992;&#23884;&#22871;&#30340;&#20302;&#31209;&#36817;&#20284;&#26041;&#27861;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#36816;&#31639;&#31526;&#30340;&#22855;&#24322;&#20540;&#20998;&#35299;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#26080;&#32422;&#26463;&#20248;&#21270;&#20844;&#24335;&#38544;&#24335;&#39640;&#25928;&#22320;&#20445;&#25345;&#23398;&#20064;&#20989;&#25968;&#30340;&#27491;&#20132;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#21644;&#31185;&#23398;&#35745;&#31639;&#38382;&#39064;&#20013;&#65292;&#35745;&#31639;&#32473;&#23450;&#32447;&#24615;&#31639;&#23376;&#30340;&#29305;&#24449;&#20540;&#20998;&#35299;&#65288;EVD&#65289;&#25110;&#25214;&#21040;&#20854;&#20027;&#35201;&#29305;&#24449;&#20540;&#21644;&#29305;&#24449;&#20989;&#25968;&#26159;&#19968;&#39033;&#22522;&#30784;&#20219;&#21153;&#12290;&#23545;&#20110;&#39640;&#32500;&#29305;&#24449;&#20540;&#38382;&#39064;&#65292;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#29305;&#24449;&#20989;&#25968;&#34987;&#35748;&#20026;&#26159;&#20256;&#32479;&#25968;&#20540;&#32447;&#24615;&#20195;&#25968;&#25216;&#26415;&#30340;&#26377;&#24076;&#26395;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20248;&#21270;&#26694;&#26550;&#65292;&#22522;&#20110;&#25130;&#26029;&#22855;&#24322;&#20540;&#20998;&#35299;&#30340;&#20302;&#31209;&#36817;&#20284;&#34920;&#24449;&#65292;&#24182;&#20276;&#38543;&#30528;&#31216;&#20026;&#23884;&#22871;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#27491;&#30830;&#30340;&#39034;&#24207;&#23398;&#20064;&#21069;L&#20010;&#22855;&#24322;&#20540;&#21644;&#22855;&#24322;&#20989;&#25968;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#36890;&#36807;&#26080;&#32422;&#26463;&#20248;&#21270;&#20844;&#24335;&#38544;&#24335;&#39640;&#25928;&#22320;&#20419;&#36827;&#20102;&#23398;&#20064;&#20989;&#25968;&#30340;&#27491;&#20132;&#24615;&#65292;&#36825;&#20010;&#20844;&#24335;&#21487;&#20197;&#24456;&#23481;&#26131;&#22320;&#36890;&#36807;&#29616;&#25104;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#31639;&#27861;&#27714;&#35299;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#20248;&#21270;&#26694;&#26550;&#22312;&#20351;&#29992;&#26696;&#20363;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Computing eigenvalue decomposition (EVD) of a given linear operator, or finding its leading eigenvalues and eigenfunctions, is a fundamental task in many machine learning and scientific computing problems. For high-dimensional eigenvalue problems, training neural networks to parameterize the eigenfunctions is considered as a promising alternative to the classical numerical linear algebra techniques. This paper proposes a new optimization framework based on the low-rank approximation characterization of a truncated singular value decomposition, accompanied by new techniques called nesting for learning the top-$L$ singular values and singular functions in the correct order. The proposed method promotes the desired orthogonality in the learned functions implicitly and efficiently via an unconstrained optimization formulation, which is easy to solve with off-the-shelf gradient-based optimization algorithms. We demonstrate the effectiveness of the proposed optimization framework for use cas
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;VAR&#27169;&#22411;&#65292;&#21033;&#29992;&#20998;&#23618;&#22270;&#20808;&#39564;&#25512;&#26029;&#20108;&#20803;&#26684;&#20848;&#26480;&#22240;&#26524;&#22270;&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;&#30456;&#27604;&#31454;&#20105;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12289;&#36229;&#21442;&#25968;&#25968;&#37327;&#21644;&#31232;&#30095;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#19978;&#37117;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>https://arxiv.org/abs/2402.03614</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#20998;&#35299;&#26684;&#20848;&#26480;&#22240;&#26524;&#22270;&#29992;&#20110;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Bayesian Factorised Granger-Causal Graphs For Multivariate Time-series Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03614
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;VAR&#27169;&#22411;&#65292;&#21033;&#29992;&#20998;&#23618;&#22270;&#20808;&#39564;&#25512;&#26029;&#20108;&#20803;&#26684;&#20848;&#26480;&#22240;&#26524;&#22270;&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;&#30456;&#27604;&#31454;&#20105;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12289;&#36229;&#21442;&#25968;&#25968;&#37327;&#21644;&#31232;&#30095;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#19978;&#37117;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#33258;&#21160;&#21457;&#29616;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#30340;&#38382;&#39064;&#12290;&#30690;&#37327;&#33258;&#22238;&#24402;(VAR)&#27169;&#22411;&#24050;&#32463;&#22312;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#19978;&#32463;&#36807;&#20102;&#26102;&#38388;&#30340;&#32771;&#39564;&#65292;&#21253;&#25324;&#36125;&#21494;&#26031;&#21464;&#31181;&#21644;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#26032;&#21457;&#23637;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;VAR&#26684;&#20848;&#26480;&#22240;&#26524;&#26041;&#27861;&#20351;&#29992;&#31232;&#30095;&#24615;&#35825;&#23548;&#24809;&#32602;/&#20808;&#39564;&#25110;&#20107;&#21518;&#38408;&#20540;&#26469;&#35299;&#37322;&#23427;&#20204;&#30340;&#31995;&#25968;&#20316;&#20026;&#26684;&#20848;&#26480;&#22240;&#26524;&#22270;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#36125;&#21494;&#26031;VAR&#27169;&#22411;&#65292;&#20854;&#20013;&#21253;&#21547;&#20102;&#19968;&#20010;&#20998;&#23618;&#22270;&#20808;&#39564;&#26469;&#34920;&#31034;&#20108;&#20803;&#26684;&#20848;&#26480;&#22240;&#26524;&#22270;&#65292;&#19982;VAR&#31995;&#25968;&#20998;&#24320;&#32771;&#34385;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#31639;&#27861;&#26469;&#25512;&#26029;&#20108;&#20803;&#26684;&#20848;&#26480;&#22240;&#26524;&#22270;&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#36739;&#23569;&#30340;&#36229;&#21442;&#25968;&#65292;&#24182;&#22312;&#31232;&#30095;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#19978;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of automatically discovering Granger causal relations from observational multivariate time-series data. Vector autoregressive (VAR) models have been time-tested for this problem, including Bayesian variants and more recent developments using deep neural networks. Most existing VAR methods for Granger causality use sparsity-inducing penalties/priors or post-hoc thresholds to interpret their coefficients as Granger causal graphs. Instead, we propose a new Bayesian VAR model with a hierarchical graph prior over binary Granger causal graphs, separately from the VAR coefficients. We develop an efficient algorithm to infer the posterior over binary Granger causal graphs. Our method provides better uncertainty quantification, has less hyperparameters, and achieves better performance than competing approaches, especially on sparse multivariate time-series data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19977;&#31181;&#26377;&#25928;&#30340;&#33719;&#21462;&#20989;&#25968;&#29992;&#20110;&#20027;&#21160;&#30456;&#20851;&#32858;&#31867;&#65292;&#20998;&#21035;&#22522;&#20110;&#19981;&#19968;&#33268;&#24615;&#27010;&#24565;&#21644;&#20449;&#24687;&#35770;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.03587</link><description>&lt;p&gt;
&#20027;&#21160;&#30456;&#20851;&#32858;&#31867;&#30340;&#26377;&#25928;&#33719;&#21462;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Effective Acquisition Functions for Active Correlation Clustering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03587
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19977;&#31181;&#26377;&#25928;&#30340;&#33719;&#21462;&#20989;&#25968;&#29992;&#20110;&#20027;&#21160;&#30456;&#20851;&#32858;&#31867;&#65292;&#20998;&#21035;&#22522;&#20110;&#19981;&#19968;&#33268;&#24615;&#27010;&#24565;&#21644;&#20449;&#24687;&#35770;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30456;&#20851;&#32858;&#31867;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#33539;&#20363;&#65292;&#25903;&#25345;&#27491;&#21644;&#36127;&#30340;&#30456;&#20284;&#24615;&#12290;&#26412;&#25991;&#20551;&#35774;&#30456;&#20284;&#24615;&#20107;&#20808;&#26410;&#30693;&#65292;&#32780;&#26159;&#37319;&#29992;&#20027;&#21160;&#23398;&#20064;&#20197;&#19968;&#31181;&#25104;&#26412;&#26377;&#25928;&#30340;&#26041;&#24335;&#36845;&#20195;&#22320;&#26597;&#35810;&#30456;&#20284;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19977;&#31181;&#26377;&#25928;&#30340;&#33719;&#21462;&#20989;&#25968;&#29992;&#20110;&#22312;&#27492;&#35774;&#32622;&#19979;&#20351;&#29992;&#12290;&#20854;&#20013;&#19968;&#31181;&#22522;&#20110;&#19981;&#19968;&#33268;&#24615;&#27010;&#24565;&#65288;&#21363;&#24403;&#30456;&#20284;&#24615;&#36829;&#21453;&#20256;&#36882;&#24615;&#26102;&#65289;&#12290;&#20854;&#20313;&#20004;&#20010;&#22522;&#20110;&#20449;&#24687;&#35770;&#37327;&#65292;&#21363;&#29109;&#21644;&#20449;&#24687;&#22686;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
Correlation clustering is a powerful unsupervised learning paradigm that supports positive and negative similarities. In this paper, we assume the similarities are not known in advance. Instead, we employ active learning to iteratively query similarities in a cost-efficient way. In particular, we develop three effective acquisition functions to be used in this setting. One is based on the notion of inconsistency (i.e., when similarities violate the transitive property). The remaining two are based on information-theoretic quantities, i.e., entropy and information gain.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20197;&#35843;&#33410;&#28216;&#25103;&#20026;&#22522;&#30784;&#30340;&#26694;&#26550;&#65292;&#23558;&#21487;&#20449;&#26426;&#22120;&#23398;&#20064;&#35270;&#20026;&#22810;&#30446;&#26631;&#22810;&#20027;&#20307;&#20248;&#21270;&#38382;&#39064;&#12290;&#36890;&#36807;&#24341;&#20837;ParetoPlay&#31639;&#27861;&#65292;&#23547;&#25214;&#31038;&#20250;&#26368;&#20248;&#30340;&#28216;&#25103;&#35299;&#20915;&#26041;&#26696;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#30830;&#20445;&#20195;&#29702;&#26041;&#22987;&#32456;&#20445;&#25345;&#22312;Pareto&#21069;&#27839;&#19978;&#12290;</title><link>https://arxiv.org/abs/2402.03540</link><description>&lt;p&gt;
&#12298;&#21487;&#20449;&#26426;&#22120;&#23398;&#20064;&#30340;&#35843;&#33410;&#28216;&#25103;&#12299;
&lt;/p&gt;
&lt;p&gt;
Regulation Games for Trustworthy Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03540
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20197;&#35843;&#33410;&#28216;&#25103;&#20026;&#22522;&#30784;&#30340;&#26694;&#26550;&#65292;&#23558;&#21487;&#20449;&#26426;&#22120;&#23398;&#20064;&#35270;&#20026;&#22810;&#30446;&#26631;&#22810;&#20027;&#20307;&#20248;&#21270;&#38382;&#39064;&#12290;&#36890;&#36807;&#24341;&#20837;ParetoPlay&#31639;&#27861;&#65292;&#23547;&#25214;&#31038;&#20250;&#26368;&#20248;&#30340;&#28216;&#25103;&#35299;&#20915;&#26041;&#26696;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#30830;&#20445;&#20195;&#29702;&#26041;&#22987;&#32456;&#20445;&#25345;&#22312;Pareto&#21069;&#27839;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#20851;&#20110;&#21487;&#20449;&#26426;&#22120;&#23398;&#20064;&#30340;&#30740;&#31350;&#24448;&#24448;&#38598;&#20013;&#22312;&#20449;&#20219;&#30340;&#20010;&#21035;&#26041;&#38754;&#65292;&#22914;&#20844;&#24179;&#24615;&#25110;&#38544;&#31169;&#12290;&#27492;&#22806;&#65292;&#35768;&#22810;&#25216;&#26415;&#24573;&#35270;&#20102;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20154;&#21644;&#36127;&#36131;&#35780;&#20272;&#20854;&#21487;&#20449;&#24230;&#30340;&#20154;&#20043;&#38388;&#30340;&#21306;&#21035;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#23558;&#21487;&#20449;&#26426;&#22120;&#23398;&#20064;&#35270;&#20026;&#22810;&#30446;&#26631;&#22810;&#20027;&#20307;&#20248;&#21270;&#38382;&#39064;&#12290;&#36825;&#33258;&#28982;&#22320;&#23548;&#33268;&#20102;&#19968;&#20010;&#31216;&#20026;&#35843;&#33410;&#28216;&#25103;&#30340;&#21338;&#24328;&#35770;&#24418;&#24335;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#29305;&#23450;&#30340;&#28216;&#25103;&#23454;&#20363;&#8212;&#8212;SpecGame&#65292;&#20854;&#20013;&#25105;&#20204;&#24314;&#27169;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26500;&#24314;&#32773;&#19982;&#20844;&#24179;&#24615;&#21644;&#38544;&#31169;&#30417;&#31649;&#32773;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#30417;&#31649;&#32773;&#24076;&#26395;&#35774;&#35745;&#22788;&#32602;&#25514;&#26045;&#26469;&#24378;&#21046;&#25191;&#34892;&#20182;&#20204;&#30340;&#35268;&#33539;&#65292;&#20294;&#19981;&#24076;&#26395;&#38459;&#27490;&#26500;&#24314;&#32773;&#30340;&#21442;&#19982;&#12290;&#20026;&#20102;&#23547;&#25214;&#36825;&#31181;&#31038;&#20250;&#26368;&#20248;&#65288;&#21363;&#23545;&#25152;&#26377;&#20195;&#29702;&#26041;&#37117;&#26377;&#25928;&#65289;&#30340;&#28216;&#25103;&#35299;&#20915;&#26041;&#26696;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;ParetoPlay&#12290;&#36825;&#31181;&#26032;&#22411;&#22343;&#34913;&#25628;&#32034;&#31639;&#27861;&#30830;&#20445;&#20195;&#29702;&#26041;&#22987;&#32456;&#20445;&#25345;&#22312;Pareto&#21069;&#27839;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing work on trustworthy machine learning (ML) often concentrates on individual aspects of trust, such as fairness or privacy. Additionally, many techniques overlook the distinction between those who train ML models and those responsible for assessing their trustworthiness. To address these issues, we propose a framework that views trustworthy ML as a multi-objective multi-agent optimization problem. This naturally lends itself to a game-theoretic formulation we call regulation games. We illustrate a particular game instance, the SpecGame in which we model the relationship between an ML model builder and fairness and privacy regulators. Regulators wish to design penalties that enforce compliance with their specification, but do not want to discourage builders from participation. Seeking such socially optimal (i.e., efficient for all agents) solutions to the game, we introduce ParetoPlay. This novel equilibrium search algorithm ensures that agents remain on the Pareto frontier of th
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#31354;&#38388;&#29615;&#22659;&#20013;&#39564;&#35777;&#39044;&#27979;&#26041;&#27861;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22788;&#29702;&#19981;&#21305;&#37197;&#24773;&#20917;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.03527</link><description>&lt;p&gt;
&#22312;&#31354;&#38388;&#29615;&#22659;&#20013;&#19968;&#33268;&#39564;&#35777;&#39044;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Consistent Validation for Predictive Methods in Spatial Settings
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03527
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#31354;&#38388;&#29615;&#22659;&#20013;&#39564;&#35777;&#39044;&#27979;&#26041;&#27861;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22788;&#29702;&#19981;&#21305;&#37197;&#24773;&#20917;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31354;&#38388;&#39044;&#27979;&#20219;&#21153;&#23545;&#20110;&#22825;&#27668;&#39044;&#25253;&#12289;&#31354;&#27668;&#27745;&#26579;&#30740;&#31350;&#21644;&#20854;&#20182;&#31185;&#23398;&#24037;&#20316;&#33267;&#20851;&#37325;&#35201;&#12290;&#30830;&#23450;&#25105;&#20204;&#23545;&#32479;&#35745;&#25110;&#29289;&#29702;&#26041;&#27861;&#25152;&#20316;&#39044;&#27979;&#30340;&#21487;&#20449;&#24230;&#26159;&#31185;&#23398;&#32467;&#35770;&#30340;&#37325;&#35201;&#38382;&#39064;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#20256;&#32479;&#30340;&#39564;&#35777;&#26041;&#27861;&#26080;&#27861;&#22788;&#29702;&#39564;&#35777;&#20301;&#32622;&#21644;&#25105;&#20204;&#24076;&#26395;&#36827;&#34892;&#39044;&#27979;&#30340;&#65288;&#27979;&#35797;&#65289;&#20301;&#32622;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#12290;&#36825;&#31181;&#19981;&#21305;&#37197;&#36890;&#24120;&#19981;&#26159;&#21327;&#21464;&#37327;&#20559;&#31227;&#30340;&#19968;&#20010;&#23454;&#20363;&#65288;&#24120;&#24120;&#34987;&#24418;&#24335;&#21270;&#65289;&#65292;&#22240;&#20026;&#39564;&#35777;&#21644;&#27979;&#35797;&#20301;&#32622;&#26159;&#22266;&#23450;&#30340;&#65288;&#20363;&#22914;&#65292;&#22312;&#32593;&#26684;&#19978;&#25110;&#36873;&#23450;&#30340;&#28857;&#19978;&#65289;&#65292;&#32780;&#19981;&#26159;&#20174;&#20004;&#20010;&#20998;&#24067;&#20013;&#29420;&#31435;&#21516;&#20998;&#24067;&#22320;&#37319;&#26679;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24418;&#24335;&#21270;&#20102;&#23545;&#39564;&#35777;&#26041;&#27861;&#30340;&#26816;&#26597;&#65306;&#38543;&#30528;&#39564;&#35777;&#25968;&#25454;&#30340;&#23494;&#24230;&#36234;&#26469;&#36234;&#22823;&#65292;&#23427;&#20204;&#33021;&#22815;&#21464;&#24471;&#20219;&#24847;&#31934;&#30830;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20256;&#32479;&#26041;&#27861;&#21644;&#21327;&#21464;&#37327;&#20559;&#31227;&#26041;&#27861;&#21487;&#33021;&#19981;&#28385;&#36275;&#36825;&#20010;&#26816;&#26597;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#23427;&#20511;&#37492;&#20102;&#21327;&#21464;&#37327;&#20559;&#31227;&#25991;&#29486;&#20013;&#30340;&#29616;&#26377;&#24605;&#24819;&#65292;&#20294;&#23545;&#39564;&#35777;&#25968;&#25454;&#36827;&#34892;&#20102;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;
Spatial prediction tasks are key to weather forecasting, studying air pollution, and other scientific endeavors. Determining how much to trust predictions made by statistical or physical methods is essential for the credibility of scientific conclusions. Unfortunately, classical approaches for validation fail to handle mismatch between locations available for validation and (test) locations where we want to make predictions. This mismatch is often not an instance of covariate shift (as commonly formalized) because the validation and test locations are fixed (e.g., on a grid or at select points) rather than i.i.d. from two distributions. In the present work, we formalize a check on validation methods: that they become arbitrarily accurate as validation data becomes arbitrarily dense. We show that classical and covariate-shift methods can fail this check. We instead propose a method that builds from existing ideas in the covariate-shift literature, but adapts them to the validation data 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#23398;&#20064;&#26694;&#26550;SAL&#65288;Separate And Learn&#65289;&#65292;&#36890;&#36807;&#21033;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#21644;&#26631;&#35760;&#25968;&#25454;&#65292;&#20998;&#31163;&#24182;&#35757;&#32451;&#24322;&#24120;&#28857;&#21644;OOD&#20998;&#31867;&#22120;&#65292;&#29702;&#35770;&#19978;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#20445;&#35777;&#21644;&#20005;&#26684;&#30340;&#38169;&#35823;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.03502</link><description>&lt;p&gt;
&#26410;&#26631;&#35760;&#25968;&#25454;&#22914;&#20309;&#22312;&#36229;&#20986;&#20998;&#24067;&#26816;&#27979;&#20013;&#21457;&#25381;&#21487;&#35777;&#26126;&#30340;&#20316;&#29992;&#65311;
&lt;/p&gt;
&lt;p&gt;
How Does Unlabeled Data Provably Help Out-of-Distribution Detection?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03502
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#23398;&#20064;&#26694;&#26550;SAL&#65288;Separate And Learn&#65289;&#65292;&#36890;&#36807;&#21033;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#21644;&#26631;&#35760;&#25968;&#25454;&#65292;&#20998;&#31163;&#24182;&#35757;&#32451;&#24322;&#24120;&#28857;&#21644;OOD&#20998;&#31867;&#22120;&#65292;&#29702;&#35770;&#19978;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#20445;&#35777;&#21644;&#20005;&#26684;&#30340;&#38169;&#35823;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#23545;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#27491;&#21017;&#21270;&#24050;&#32463;&#26174;&#31034;&#20986;&#22312;&#26816;&#27979;&#36229;&#20986;&#20998;&#24067;&#65288;OOD&#65289;&#25968;&#25454;&#26041;&#38754;&#25913;&#36827;&#23433;&#20840;&#24615;&#21644;&#21487;&#38752;&#24615;&#30340;&#28508;&#21147;&#12290;&#21033;&#29992;&#37326;&#22806;&#26410;&#26631;&#35760;&#25968;&#25454;&#30340;&#33021;&#21147;&#26159;&#38750;&#24120;&#22256;&#38590;&#30340;&#65292;&#22240;&#20026;&#20869;&#20998;&#24067;&#65288;ID&#65289;&#21644;OOD&#25968;&#25454;&#30340;&#24322;&#36136;&#24615;&#12290;&#32570;&#20047;&#28165;&#27905;&#30340;OOD&#26679;&#26412;&#38598;&#21512;&#22312;&#23398;&#20064;&#26368;&#20248;OOD&#20998;&#31867;&#22120;&#26041;&#38754;&#23384;&#22312;&#37325;&#22823;&#25361;&#25112;&#12290;&#30446;&#21069;&#65292;&#32570;&#20047;&#23545;&#26410;&#26631;&#35760;&#25968;&#25454;&#22914;&#20309;&#24110;&#21161;OOD&#26816;&#27979;&#30340;&#30740;&#31350;&#12290;&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#23398;&#20064;&#26694;&#26550;SAL&#65288;Separate And Learn&#65289;&#65292;&#22635;&#34917;&#20102;&#36825;&#19968;&#31354;&#30333;&#65292;&#35813;&#26694;&#26550;&#22312;&#29702;&#35770;&#19978;&#20855;&#26377;&#24378;&#22823;&#30340;&#20445;&#35777;&#21644;&#23454;&#35777;&#30340;&#26377;&#25928;&#24615;&#12290;&#35813;&#26694;&#26550;&#23558;&#20505;&#36873;&#24322;&#24120;&#28857;&#20174;&#26410;&#26631;&#35760;&#25968;&#25454;&#20013;&#20998;&#31163;&#20986;&#26469;&#65292;&#24182;&#20351;&#29992;&#20505;&#36873;&#24322;&#24120;&#28857;&#21644;&#26631;&#35760;&#30340;ID&#25968;&#25454;&#35757;&#32451;OOD&#20998;&#31867;&#22120;&#12290;&#20174;&#21487;&#20998;&#31163;&#24615;&#21644;&#21487;&#23398;&#20064;&#24615;&#30340;&#35282;&#24230;&#65292;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#38169;&#35823;&#30028;&#38480;&#65292;&#27491;&#24335;&#35777;&#26126;&#20102;&#25105;&#20204;&#31639;&#27861;&#20013;&#30340;&#20004;&#20010;&#32452;&#25104;&#37096;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
Using unlabeled data to regularize the machine learning models has demonstrated promise for improving safety and reliability in detecting out-of-distribution (OOD) data. Harnessing the power of unlabeled in-the-wild data is non-trivial due to the heterogeneity of both in-distribution (ID) and OOD data. This lack of a clean set of OOD samples poses significant challenges in learning an optimal OOD classifier. Currently, there is a lack of research on formally understanding how unlabeled data helps OOD detection. This paper bridges the gap by introducing a new learning framework SAL (Separate And Learn) that offers both strong theoretical guarantees and empirical effectiveness. The framework separates candidate outliers from the unlabeled data and then trains an OOD classifier using the candidate outliers and the labeled ID data. Theoretically, we provide rigorous error bounds from the lens of separability and learnability, formally justifying the two components in our algorithm. Our the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25968;&#23398;&#26041;&#24335;&#30740;&#31350;&#20102;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26550;&#26500;&#65292;&#27604;&#36739;&#20102;&#20107;&#21518;&#35299;&#37322;&#21644;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#35299;&#37322;&#30340;&#24046;&#24322;&#65292;&#21457;&#29616;&#23613;&#31649;&#26377;&#23616;&#38480;&#24615;&#65292;&#20107;&#21518;&#35299;&#37322;&#26041;&#27861;&#33021;&#22815;&#25429;&#33719;&#27604;&#20165;&#20165;&#26816;&#26597;&#27880;&#24847;&#21147;&#26435;&#37325;&#26356;&#26377;&#29992;&#30340;&#27934;&#23519;&#12290;</title><link>https://arxiv.org/abs/2402.03485</link><description>&lt;p&gt;
&#27880;&#24847;&#21147;&#19982;&#20107;&#21518;&#21487;&#35299;&#37322;&#24615;&#30456;&#36935;&#65306;&#25968;&#23398;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Attention Meets Post-hoc Interpretability: A Mathematical Perspective
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03485
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25968;&#23398;&#26041;&#24335;&#30740;&#31350;&#20102;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26550;&#26500;&#65292;&#27604;&#36739;&#20102;&#20107;&#21518;&#35299;&#37322;&#21644;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#35299;&#37322;&#30340;&#24046;&#24322;&#65292;&#21457;&#29616;&#23613;&#31649;&#26377;&#23616;&#38480;&#24615;&#65292;&#20107;&#21518;&#35299;&#37322;&#26041;&#27861;&#33021;&#22815;&#25429;&#33719;&#27604;&#20165;&#20165;&#26816;&#26597;&#27880;&#24847;&#21147;&#26435;&#37325;&#26356;&#26377;&#29992;&#30340;&#27934;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27880;&#24847;&#21147;&#26426;&#21046;&#22522;&#20110;transformer&#31561;&#26550;&#26500;&#65292;&#25104;&#20026;&#20102;&#25216;&#26415;&#38761;&#21629;&#30340;&#26680;&#24515;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#38500;&#20102;&#24110;&#21161;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#33719;&#24471;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#20043;&#22806;&#65292;&#27880;&#24847;&#21147;&#26426;&#21046;&#26412;&#36523;&#36824;&#25552;&#20379;&#20102;&#20851;&#20110;&#27169;&#22411;&#20869;&#37096;&#34892;&#20026;&#30340;&#26377;&#24847;&#20041;&#27934;&#23519;&#12290;&#36825;&#20123;&#27934;&#23519;&#26159;&#21542;&#21487;&#20197;&#29992;&#20316;&#35299;&#37322;&#65311;&#20851;&#20110;&#27492;&#20105;&#35770;&#19981;&#26029;&#12290;&#26412;&#25991;&#36890;&#36807;&#25968;&#23398;&#26041;&#24335;&#30740;&#31350;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26550;&#26500;&#65292;&#24182;&#20934;&#30830;&#23450;&#20301;&#20102;&#20107;&#21518;&#35299;&#37322;&#21644;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#35299;&#37322;&#20043;&#38388;&#30340;&#21306;&#21035;&#12290;&#25105;&#20204;&#34920;&#26126;&#23427;&#20204;&#25552;&#20379;&#20102;&#30456;&#24403;&#19981;&#21516;&#30340;&#32467;&#26524;&#65292;&#24182;&#19988;&#23613;&#31649;&#26377;&#20854;&#23616;&#38480;&#24615;&#65292;&#20107;&#21518;&#35299;&#37322;&#26041;&#27861;&#33021;&#22815;&#25429;&#33719;&#27604;&#20165;&#20165;&#26816;&#26597;&#27880;&#24847;&#21147;&#26435;&#37325;&#26356;&#26377;&#29992;&#30340;&#27934;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;
Attention-based architectures, in particular transformers, are at the heart of a technological revolution. Interestingly, in addition to helping obtain state-of-the-art results on a wide range of applications, the attention mechanism intrinsically provides meaningful insights on the internal behavior of the model. Can these insights be used as explanations? Debate rages on. In this paper, we mathematically study a simple attention-based architecture and pinpoint the differences between post-hoc and attention-based explanations. We show that they provide quite different results, and that, despite their limitations, post-hoc methods are capable of capturing more useful insights than merely examining the attention weights.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#40654;&#26364;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;RSGD&#65289;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#20462;&#25913;&#27969;&#65288;RSMF&#65289;&#30340;&#25193;&#25955;&#36924;&#36817;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#23545;RSGD&#30340;&#36817;&#20284;&#31934;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.03467</link><description>&lt;p&gt;
&#22522;&#20110;&#38543;&#26426;&#20462;&#25913;&#27969;&#30340;&#40654;&#26364;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;
&lt;/p&gt;
&lt;p&gt;
Stochastic Modified Flows for Riemannian Stochastic Gradient Descent
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03467
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#40654;&#26364;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;RSGD&#65289;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#20462;&#25913;&#27969;&#65288;RSMF&#65289;&#30340;&#25193;&#25955;&#36924;&#36817;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#23545;RSGD&#30340;&#36817;&#20284;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#40654;&#26364;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;RSGD&#65289;&#25910;&#25947;&#36895;&#24230;&#32473;&#20986;&#20102;&#23450;&#37327;&#20272;&#35745;&#65292;&#24182;&#23558;&#20854;&#19982;&#40654;&#26364;&#26799;&#24230;&#27969;&#21644;&#25193;&#25955;&#36807;&#31243;&#8212;&#8212;&#40654;&#26364;&#38543;&#26426;&#20462;&#25913;&#27969;&#65288;RSMF&#65289;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#21033;&#29992;&#38543;&#26426;&#24494;&#20998;&#20960;&#20309;&#24037;&#20855;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#23567;&#23398;&#20064;&#29575;&#33539;&#22260;&#20869;&#65292;RSGD&#21487;&#20197;&#36817;&#20284;&#20026;&#30001;&#26080;&#31351;&#32500;&#32500;&#32435;&#36807;&#31243;&#39537;&#21160;&#30340;RSMF&#30340;&#35299;&#12290;RSMF&#32771;&#34385;&#21040;&#20102;RSGD&#30340;&#38543;&#26426;&#27874;&#21160;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#19982;&#30830;&#23450;&#24615;&#40654;&#26364;&#26799;&#24230;&#27969;&#30340;&#36924;&#36817;&#39034;&#24207;&#12290;RSGD&#20351;&#29992;&#20102;&#37325;&#20256;&#36882;&#26144;&#23556;&#30340;&#27010;&#24565;&#65292;&#21363;&#23545;&#25351;&#25968;&#26144;&#23556;&#30340;&#19968;&#31181;&#25104;&#26412;&#25928;&#30410;&#36817;&#20284;&#65292;&#25105;&#20204;&#23545;&#25193;&#25955;&#36924;&#36817;&#30340;&#24369;&#35823;&#24046;&#36827;&#34892;&#20102;&#23450;&#37327;&#30028;&#23450;&#65292;&#22312;&#37325;&#20256;&#36882;&#26144;&#23556;&#12289;&#27969;&#24418;&#20960;&#20309;&#21644;&#26799;&#24230;&#30340;&#38543;&#26426;&#20272;&#35745;&#30340;&#20551;&#35774;&#19979;&#35777;&#26126;&#20102;&#36825;&#20123;&#30028;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
We give quantitative estimates for the rate of convergence of Riemannian stochastic gradient descent (RSGD) to Riemannian gradient flow and to a diffusion process, the so-called Riemannian stochastic modified flow (RSMF). Using tools from stochastic differential geometry we show that, in the small learning rate regime, RSGD can be approximated by the solution to the RSMF driven by an infinite-dimensional Wiener process. The RSMF accounts for the random fluctuations of RSGD and, thereby, increases the order of approximation compared to the deterministic Riemannian gradient flow. The RSGD is build using the concept of a retraction map, that is, a cost efficient approximation of the exponential map, and we prove quantitative bounds for the weak error of the diffusion approximation under assumptions on the retraction map, the geometry of the manifold, and the random estimators of the gradient.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20998;&#24067;&#24335;&#31070;&#32463;&#35745;&#31639;&#31639;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#26041;&#27861;&#26469;&#20811;&#26381;&#32500;&#24230;&#28798;&#38590;&#65292;&#24182;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#21487;&#20197;&#22312;&#20219;&#24847;&#31934;&#24230;&#19979;&#36924;&#36817;Lipschitz&#20989;&#25968;&#65292;&#22312;&#21442;&#25968;&#37327;&#21644;&#21069;&#21521;&#20256;&#25773;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2402.03460</link><description>&lt;p&gt;
&#29992;&#20998;&#24067;&#24335;&#31070;&#32463;&#35745;&#31639;&#31361;&#30772;&#32500;&#24230;&#28798;&#38590;
&lt;/p&gt;
&lt;p&gt;
Breaking the Curse of Dimensionality with Distributed Neural Computation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03460
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20998;&#24067;&#24335;&#31070;&#32463;&#35745;&#31639;&#31639;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#26041;&#27861;&#26469;&#20811;&#26381;&#32500;&#24230;&#28798;&#38590;&#65292;&#24182;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#21487;&#20197;&#22312;&#20219;&#24847;&#31934;&#24230;&#19979;&#36924;&#36817;Lipschitz&#20989;&#25968;&#65292;&#22312;&#21442;&#25968;&#37327;&#21644;&#21069;&#21521;&#20256;&#25773;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#26041;&#27861;&#65292;&#21033;&#29992;&#20998;&#24067;&#24335;&#31070;&#32463;&#35745;&#31639;&#31639;&#27861;&#26469;&#20811;&#26381;&#32500;&#24230;&#28798;&#38590;&#12290;&#25105;&#20204;&#30340;&#27169;&#22359;&#21270;&#20998;&#24067;&#24335;&#28145;&#24230;&#23398;&#20064;&#33539;&#24335;&#65292;&#31216;&#20026;&#8220;&#31070;&#32463;&#36884;&#24452;&#8221;&#65292;&#21487;&#20197;&#22312;&#22810;&#21488;&#26426;&#22120;&#19978;&#23454;&#29616;&#20219;&#24847;&#31934;&#24230;&#65292;&#21516;&#26102;&#20165;&#21152;&#36733;&#23569;&#37327;&#21442;&#25968;&#21040;GPU VRAM&#20013;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#27599;&#20010;&#35823;&#24046;&#27700;&#24179;$\varepsilon&gt;0$&#21644;&#27599;&#20010;Lipschitz&#20989;&#25968;$f:[0,1]^n\to \mathbb{R}$&#65292;&#25105;&#20204;&#21487;&#20197;&#26500;&#24314;&#19968;&#20010;&#31070;&#32463;&#36884;&#24452;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#22312;$[0,1]^n$&#19978;&#20197;$\varepsilon$&#31934;&#24230;&#22343;&#21248;&#36924;&#36817;$f$&#65292;&#24182;&#19988;&#20165;&#38656;&#35201;&#22312;&#20869;&#23384;&#20013;&#21152;&#36733;$\mathcal{O}(\varepsilon^{-1})$&#20010;&#32593;&#32476;&#21442;&#25968;&#20197;&#21450;&#22312;&#21069;&#21521;&#20256;&#25773;&#26399;&#38388;&#21152;&#36733;$\mathcal{O}(\varepsilon^{-1}\log(\varepsilon^{-1}))$&#20010;&#32593;&#32476;&#21442;&#25968;&#12290;&#36825;&#25913;&#36827;&#20102;&#20256;&#32479;&#38750;&#20998;&#24067;&#24335;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65288;&#21363;ReLU&#22810;&#23618;&#24863;&#30693;&#26426;&#65289;&#30340;&#26368;&#20248;&#30028;&#38480;&#65292;&#21518;&#32773;&#38656;&#35201;$\mathcal{O}(\varepsilon^{-n/2})$&#20010;&#21442;&#25968;&#26469;&#36798;&#21040;&#30456;&#21516;&#30340;&#31934;&#24230;&#12290;&#30446;&#21069;&#21807;&#19968;&#30340;&#20854;&#20182;&#21487;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
We present a theoretical approach to overcome the curse of dimensionality using a neural computation algorithm which can be distributed across several machines. Our modular distributed deep learning paradigm, termed \textit{neural pathways}, can achieve arbitrary accuracy while only loading a small number of parameters into GPU VRAM. Formally, we prove that for every error level $\varepsilon&gt;0$ and every Lipschitz function $f:[0,1]^n\to \mathbb{R}$, one can construct a neural pathways model which uniformly approximates $f$ to $\varepsilon$ accuracy over $[0,1]^n$ while only requiring networks of $\mathcal{O}(\varepsilon^{-1})$ parameters to be loaded in memory and $\mathcal{O}(\varepsilon^{-1}\log(\varepsilon^{-1}))$ to be loaded during the forward pass. This improves the optimal bounds for traditional non-distributed deep learning models, namely ReLU MLPs, which need $\mathcal{O}(\varepsilon^{-n/2})$ parameters to achieve the same accuracy. The only other available deep learning model
&lt;/p&gt;</description></item><item><title>&#21464;&#37327;&#37325;&#35201;&#24615;&#25490;&#24207;&#22312;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#20013;&#24456;&#37325;&#35201;&#65292;&#20294;&#26159;&#29305;&#24449;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#26368;&#36817;&#25552;&#20986;&#20102;&#22522;&#20110;&#29305;&#24449; Knockoffs &#30340;&#25913;&#36827;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#37325;&#28857;&#26159;&#23545;&#36825;&#20123;&#26041;&#27861;&#36827;&#34892;&#35780;&#20272;&#21644;&#35780;&#20272;&#12290;</title><link>https://arxiv.org/abs/2402.03447</link><description>&lt;p&gt;
&#21464;&#37327;&#37325;&#35201;&#24615;&#25490;&#24207;&#22312;&#30456;&#20851;&#24615;&#19979;&#30340;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
Challenges in Variable Importance Ranking Under Correlation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03447
&lt;/p&gt;
&lt;p&gt;
&#21464;&#37327;&#37325;&#35201;&#24615;&#25490;&#24207;&#22312;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#20013;&#24456;&#37325;&#35201;&#65292;&#20294;&#26159;&#29305;&#24449;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#26368;&#36817;&#25552;&#20986;&#20102;&#22522;&#20110;&#29305;&#24449; Knockoffs &#30340;&#25913;&#36827;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#37325;&#28857;&#26159;&#23545;&#36825;&#20123;&#26041;&#27861;&#36827;&#34892;&#35780;&#20272;&#21644;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#37327;&#37325;&#35201;&#24615;&#22312;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#20013;&#36215;&#21040;&#20102;&#20851;&#38190;&#20316;&#29992;&#65292;&#23427;&#24110;&#21161;&#34913;&#37327;&#22240;&#32032;&#23545;&#39044;&#27979;&#27169;&#22411;&#36755;&#20986;&#30340;&#24433;&#21709;&#12290;&#22522;&#20110;&#36890;&#36807;&#25490;&#21015;&#29983;&#25104;&#8220;&#31354;&#8221;&#29305;&#24449;&#30340;&#27169;&#22411;&#26080;&#20851;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#27492;&#12290;&#36825;&#31181;&#20998;&#26512;&#36890;&#24120;&#22312;&#21046;&#33647;&#24212;&#29992;&#20013;&#20351;&#29992;&#65292;&#22240;&#20026;&#23427;&#33021;&#35299;&#37322;&#21253;&#25324;&#22522;&#20110;&#26641;&#30340;&#38598;&#25104;&#27169;&#22411;&#22312;&#20869;&#30340;&#40657;&#30418;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#21464;&#37327;&#37325;&#35201;&#24615;&#20272;&#31639;&#20013;&#23384;&#22312;&#30340;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#21644;&#26174;&#33879;&#24178;&#25200;&#22240;&#32032;&#26159;&#29305;&#24449;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;&#26368;&#36817;&#65292;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#25552;&#20986;&#20102;&#20960;&#31181;&#22522;&#20110;&#29305;&#24449; Knockoffs &#30340;&#36793;&#38469;&#25490;&#21015;&#35843;&#25972;&#65292;&#22914;&#26465;&#20214;&#39044;&#27979;&#24433;&#21709;&#65288;CPI&#65289;&#31561;&#21464;&#37327;&#37325;&#35201;&#24615;&#24230;&#37327;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#37325;&#28857;&#26159;&#23545;&#36825;&#20123;&#26041;&#27861;&#36827;&#34892;&#35780;&#20272;&#21644;&#35780;&#20272;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#39033;&#32508;&#21512;&#27169;&#25311;&#30740;&#31350;&#65292;&#25506;&#35752;&#20102;&#29305;&#24449;&#30456;&#20851;&#24615;&#23545;&#21464;&#37327;&#37325;&#35201;&#24615;&#35780;&#20272;&#30340;&#24433;&#21709;&#12290;&#28982;&#21518;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;...
&lt;/p&gt;
&lt;p&gt;
Variable importance plays a pivotal role in interpretable machine learning as it helps measure the impact of factors on the output of the prediction model. Model agnostic methods based on the generation of "null" features via permutation (or related approaches) can be applied. Such analysis is often utilized in pharmaceutical applications due to its ability to interpret black-box models, including tree-based ensembles. A major challenge and significant confounder in variable importance estimation however is the presence of between-feature correlation. Recently, several adjustments to marginal permutation utilizing feature knockoffs were proposed to address this issue, such as the variable importance measure known as conditional predictive impact (CPI). Assessment and evaluation of such approaches is the focus of our work. We first present a comprehensive simulation study investigating the impact of feature correlation on the assessment of variable importance. We then theoretically prov
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#38646;&#38454;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#20004;&#20010;&#21333;&#24490;&#29615;&#31639;&#27861;&#29992;&#20110;&#27714;&#35299;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#20998;&#21035;&#20026;O(&#949;^(-2))&#21644;O(&#949;^(-4))&#12290;</title><link>https://arxiv.org/abs/2402.03352</link><description>&lt;p&gt;
&#38754;&#21521;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#38646;&#38454;&#21407;&#22987;&#23545;&#20598;&#20132;&#26367;&#25237;&#24433;&#26799;&#24230;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Zeroth-Order primal-dual Alternating Projection Gradient Algorithms for Nonconvex Minimax Problems with Coupled linear Constraints
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03352
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#38646;&#38454;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#20004;&#20010;&#21333;&#24490;&#29615;&#31639;&#27861;&#29992;&#20110;&#27714;&#35299;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#20998;&#21035;&#20026;O(&#949;^(-2))&#21644;O(&#949;^(-4))&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#35774;&#32622;&#19979;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#38646;&#38454;&#31639;&#27861;&#65292;&#36825;&#22312;&#26426;&#22120;&#23398;&#20064;&#12289;&#20449;&#21495;&#22788;&#29702;&#21644;&#20854;&#20182;&#39046;&#22495;&#20013;&#36817;&#24180;&#26469;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#20363;&#22914;&#36164;&#28304;&#20998;&#37197;&#38382;&#39064;&#21644;&#32593;&#32476;&#27969;&#38382;&#39064;&#20013;&#30340;&#23545;&#25239;&#25915;&#20987;&#31561;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#21333;&#24490;&#29615;&#31639;&#27861;&#65292;&#20998;&#21035;&#26159;&#38646;&#38454;&#21407;&#22987;&#23545;&#20598;&#20132;&#26367;&#25237;&#24433;&#26799;&#24230;&#65288;ZO-PDAPG&#65289;&#31639;&#27861;&#21644;&#38646;&#38454;&#27491;&#21017;&#21160;&#37327;&#21407;&#22987;&#23545;&#20598;&#25237;&#24433;&#26799;&#24230;&#31639;&#27861;&#65288;ZO-RMPDPG&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#38750;&#20984;-(&#24378;)&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#12290;&#35777;&#26126;&#20102;&#36825;&#20004;&#20010;&#31639;&#27861;&#33719;&#24471;&#19968;&#20010;&#949;-&#31283;&#23450;&#28857;&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#20998;&#21035;&#20026;O(&#949;^(-2))&#65288;&#23545;&#20110;&#27714;&#35299;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65289;&#21644;O(&#949;^(-4))&#65288;&#23545;&#20110;&#27714;&#35299;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study zeroth-order algorithms for nonconvex minimax problems with coupled linear constraints under the deterministic and stochastic settings, which have attracted wide attention in machine learning, signal processing and many other fields in recent years, e.g., adversarial attacks in resource allocation problems and network flow problems etc. We propose two single-loop algorithms, namely the zero-order primal-dual alternating projected gradient (ZO-PDAPG) algorithm and the zero-order regularized momentum primal-dual projected gradient algorithm (ZO-RMPDPG), for solving deterministic and stochastic nonconvex-(strongly) concave minimax problems with coupled linear constraints. The iteration complexity of the two proposed algorithms to obtain an $\varepsilon$-stationary point are proved to be $\mathcal{O}(\varepsilon ^{-2})$ (resp. $\mathcal{O}(\varepsilon ^{-4})$) for solving nonconvex-strongly concave (resp. nonconvex-concave) minimax problems with coupled linear const
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#22312;MEG&#24212;&#29992;&#20013;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#26032;&#39062;&#39046;&#22495;&#33258;&#36866;&#24212;&#25216;&#26415;&#65292;&#31216;&#20026;&#28151;&#21512;&#27169;&#22411;&#26031;&#33922;&#24343;&#36866;&#24212;&#65288;MSA&#65289;&#65292;&#36890;&#36807;&#21033;&#29992;&#26080;&#26631;&#35760;&#25968;&#25454;&#24314;&#31435;&#20102;&#31561;&#25928;&#20449;&#21495;&#26041;&#24046;&#30340;&#25104;&#23545;&#23545;&#24212;&#20851;&#31995;&#20197;&#30830;&#20445;&#26377;&#25928;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#22312;&#31070;&#32463;&#31185;&#23398;&#38382;&#39064;&#20013;&#65292;MSA&#22312;&#20351;&#29992;&#33041;&#30913;&#22270;&#36827;&#34892;&#33041;&#40836;&#22238;&#24402;&#26102;&#34920;&#29616;&#20248;&#20110;&#26368;&#36817;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.03345</link><description>&lt;p&gt;
&#24369;&#30417;&#30563;&#21327;&#26041;&#24046;&#30697;&#38453;&#23545;&#40784;&#36890;&#36807;&#26031;&#33922;&#24343;&#30697;&#38453;&#20272;&#35745;&#22312;MEG&#24212;&#29992;&#20013;
&lt;/p&gt;
&lt;p&gt;
Weakly supervised covariance matrices alignment through Stiefel matrices estimation for MEG applications
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03345
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#22312;MEG&#24212;&#29992;&#20013;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#26032;&#39062;&#39046;&#22495;&#33258;&#36866;&#24212;&#25216;&#26415;&#65292;&#31216;&#20026;&#28151;&#21512;&#27169;&#22411;&#26031;&#33922;&#24343;&#36866;&#24212;&#65288;MSA&#65289;&#65292;&#36890;&#36807;&#21033;&#29992;&#26080;&#26631;&#35760;&#25968;&#25454;&#24314;&#31435;&#20102;&#31561;&#25928;&#20449;&#21495;&#26041;&#24046;&#30340;&#25104;&#23545;&#23545;&#24212;&#20851;&#31995;&#20197;&#30830;&#20445;&#26377;&#25928;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#22312;&#31070;&#32463;&#31185;&#23398;&#38382;&#39064;&#20013;&#65292;MSA&#22312;&#20351;&#29992;&#33041;&#30913;&#22270;&#36827;&#34892;&#33041;&#40836;&#22238;&#24402;&#26102;&#34920;&#29616;&#20248;&#20110;&#26368;&#36817;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#28151;&#21512;&#27169;&#22411;&#26031;&#33922;&#24343;&#36866;&#24212;&#65288;MSA&#65289;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#39046;&#22495;&#33258;&#36866;&#24212;&#25216;&#24039;&#65292;&#29305;&#21035;&#35299;&#20915;&#20102;&#30446;&#26631;&#25968;&#25454;&#38598;&#20013;&#26377;&#38480;&#26631;&#35760;&#20449;&#21495;&#30340;&#25361;&#25112;&#12290;&#36890;&#36807;&#21033;&#29992;&#39046;&#22495;&#30456;&#20851;&#30340;&#28151;&#21512;&#27169;&#22411;&#21644;&#26368;&#20248;&#20256;&#36755;&#39046;&#22495;&#33258;&#36866;&#24212;&#20551;&#35774;&#65292;&#25105;&#20204;&#21033;&#29992;&#30446;&#26631;&#22495;&#20013;&#20016;&#23500;&#30340;&#26080;&#26631;&#35760;&#25968;&#25454;&#65292;&#36890;&#36807;&#24314;&#31435;&#31561;&#25928;&#20449;&#21495;&#26041;&#24046;&#20043;&#38388;&#30340;&#25104;&#23545;&#23545;&#24212;&#20851;&#31995;&#65292;&#30830;&#20445;&#20102;&#26377;&#25928;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#20026;&#20102;&#20174;&#35266;&#27979;&#20449;&#21495;&#21327;&#26041;&#24046;&#30340;&#40654;&#26364;&#34920;&#31034;&#20013;&#24674;&#22797;&#22522;&#30784;&#20449;&#21495;&#26041;&#24046;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#35782;&#21035;&#20851;&#38190;&#30340;&#26031;&#33922;&#24343;&#30697;&#38453;&#30340;&#29702;&#35770;&#22522;&#30784;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32508;&#21512;&#25104;&#26412;&#20989;&#25968;&#65292;&#21516;&#26102;&#23398;&#20064;&#36825;&#20123;&#30697;&#38453;&#12289;&#25104;&#23545;&#22495;&#20851;&#31995;&#20197;&#21450;&#26681;&#25454;&#20219;&#21153;&#30340;&#39044;&#27979;&#22120;&#12289;&#20998;&#31867;&#22120;&#25110;&#22238;&#24402;&#22120;&#12290;&#24212;&#29992;&#20110;&#31070;&#32463;&#31185;&#23398;&#38382;&#39064;&#20013;&#65292;MSA&#22312;&#20351;&#29992;&#33041;&#30913;&#22270;&#36827;&#34892;&#20219;&#21153;&#21464;&#21270;&#30340;&#33041;&#40836;&#22238;&#24402;&#20013;&#20248;&#20110;&#26368;&#36817;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a novel domain adaptation technique for time series data, called Mixing model Stiefel Adaptation (MSA), specifically addressing the challenge of limited labeled signals in the target dataset. Leveraging a domain-dependent mixing model and the optimal transport domain adaptation assumption, we exploit abundant unlabeled data in the target domain to ensure effective prediction by establishing pairwise correspondence with equivalent signal variances between domains. Theoretical foundations are laid for identifying crucial Stiefel matrices, essential for recovering underlying signal variances from a Riemannian representation of observed signal covariances. We propose an integrated cost function that simultaneously learns these matrices, pairwise domain relationships, and a predictor, classifier, or regressor, depending on the task. Applied to neuroscience problems, MSA outperforms recent methods in brain-age regression with task variations using magnetoencephalography
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#20844;&#24179;&#20998;&#31867;&#26041;&#27861;&#65292;&#36890;&#36807;&#20808;&#22788;&#29702;&#12289;&#20013;&#22788;&#29702;&#21644;&#21518;&#22788;&#29702;&#26469;&#26368;&#23567;&#21270;&#20998;&#31867;&#38169;&#35823;&#65292;&#24182;&#22312;&#32473;&#23450;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20248;&#21270;&#12290;&#35813;&#26041;&#27861;&#24341;&#20837;&#20102;&#32447;&#24615;&#21644;&#21452;&#32447;&#24615;&#24046;&#24322;&#24230;&#37327;&#30340;&#27010;&#24565;&#65292;&#24182;&#25214;&#21040;&#20102;&#36125;&#21494;&#26031;&#26368;&#20248;&#20844;&#24179;&#20998;&#31867;&#22120;&#30340;&#24418;&#24335;&#12290;&#26412;&#26041;&#27861;&#33021;&#22815;&#22788;&#29702;&#22810;&#20010;&#20844;&#24179;&#24615;&#32422;&#26463;&#21644;&#24120;&#35265;&#24773;&#20917;&#12290;</title><link>https://arxiv.org/abs/2402.02817</link><description>&lt;p&gt;
&#22522;&#20110;&#20808;&#22788;&#29702;&#12289;&#20013;&#22788;&#29702;&#21644;&#21518;&#22788;&#29702;&#30340;&#32447;&#24615;&#24046;&#24322;&#32422;&#26463;&#19979;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#20844;&#24179;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Bayes-Optimal Fair Classification with Linear Disparity Constraints via Pre-, In-, and Post-processing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02817
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#20844;&#24179;&#20998;&#31867;&#26041;&#27861;&#65292;&#36890;&#36807;&#20808;&#22788;&#29702;&#12289;&#20013;&#22788;&#29702;&#21644;&#21518;&#22788;&#29702;&#26469;&#26368;&#23567;&#21270;&#20998;&#31867;&#38169;&#35823;&#65292;&#24182;&#22312;&#32473;&#23450;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20248;&#21270;&#12290;&#35813;&#26041;&#27861;&#24341;&#20837;&#20102;&#32447;&#24615;&#21644;&#21452;&#32447;&#24615;&#24046;&#24322;&#24230;&#37327;&#30340;&#27010;&#24565;&#65292;&#24182;&#25214;&#21040;&#20102;&#36125;&#21494;&#26031;&#26368;&#20248;&#20844;&#24179;&#20998;&#31867;&#22120;&#30340;&#24418;&#24335;&#12290;&#26412;&#26041;&#27861;&#33021;&#22815;&#22788;&#29702;&#22810;&#20010;&#20844;&#24179;&#24615;&#32422;&#26463;&#21644;&#24120;&#35265;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21487;&#33021;&#23545;&#21463;&#20445;&#25252;&#30340;&#32676;&#20307;&#20135;&#29983;&#19981;&#20844;&#24179;&#30340;&#24433;&#21709;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#22522;&#20110;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#20844;&#24179;&#20998;&#31867;&#26041;&#27861;&#65292;&#26088;&#22312;&#22312;&#32473;&#23450;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#26368;&#23567;&#21270;&#20998;&#31867;&#38169;&#35823;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#32447;&#24615;&#24046;&#24322;&#24230;&#37327;&#30340;&#27010;&#24565;&#65292;&#23427;&#20204;&#26159;&#27010;&#29575;&#20998;&#31867;&#22120;&#30340;&#32447;&#24615;&#20989;&#25968;&#65307;&#20197;&#21450;&#21452;&#32447;&#24615;&#24046;&#24322;&#24230;&#37327;&#65292;&#23427;&#20204;&#22312;&#32676;&#20307;&#22238;&#24402;&#20989;&#25968;&#26041;&#38754;&#20063;&#26159;&#32447;&#24615;&#30340;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20960;&#31181;&#24120;&#35265;&#30340;&#24046;&#24322;&#24230;&#37327;&#65288;&#22914;&#20154;&#21475;&#24179;&#31561;&#12289;&#26426;&#20250;&#24179;&#31561;&#21644;&#39044;&#27979;&#24179;&#31561;&#65289;&#37117;&#26159;&#21452;&#32447;&#24615;&#30340;&#12290;&#25105;&#20204;&#36890;&#36807;&#25581;&#31034;&#19982;Neyman-Pearson&#24341;&#29702;&#30340;&#36830;&#25509;&#65292;&#25214;&#21040;&#20102;&#22312;&#21333;&#19968;&#32447;&#24615;&#24046;&#24322;&#24230;&#37327;&#19979;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#20844;&#24179;&#20998;&#31867;&#22120;&#30340;&#24418;&#24335;&#12290;&#23545;&#20110;&#21452;&#32447;&#24615;&#24046;&#24322;&#24230;&#37327;&#65292;&#36125;&#21494;&#26031;&#26368;&#20248;&#20844;&#24179;&#20998;&#31867;&#22120;&#21464;&#25104;&#20102;&#32676;&#20307;&#38408;&#20540;&#35268;&#21017;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36824;&#21487;&#20197;&#22788;&#29702;&#22810;&#20010;&#20844;&#24179;&#24615;&#32422;&#26463;&#65288;&#22914;&#24179;&#31561;&#30340;&#20960;&#29575;&#65289;&#21644;&#21463;&#20445;&#25252;&#23646;&#24615;&#24120;&#35265;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning algorithms may have disparate impacts on protected groups. To address this, we develop methods for Bayes-optimal fair classification, aiming to minimize classification error subject to given group fairness constraints. We introduce the notion of \emph{linear disparity measures}, which are linear functions of a probabilistic classifier; and \emph{bilinear disparity measures}, which are also linear in the group-wise regression functions. We show that several popular disparity measures -- the deviations from demographic parity, equality of opportunity, and predictive equality -- are bilinear.   We find the form of Bayes-optimal fair classifiers under a single linear disparity measure, by uncovering a connection with the Neyman-Pearson lemma. For bilinear disparity measures, Bayes-optimal fair classifiers become group-wise thresholding rules. Our approach can also handle multiple fairness constraints (such as equalized odds), and the common scenario when the protected attr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#22806;&#28304;&#21464;&#37327;&#30340;&#20998;&#24067;&#65292;&#25552;&#39640;&#20102;&#32467;&#26500;&#21270;&#22240;&#26524;&#27169;&#22411;&#30340;&#36817;&#20284;&#31934;&#24230;&#65292;&#24182;&#23558;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#25193;&#23637;&#21040;&#26356;&#19968;&#33324;&#30340;&#22240;&#26524;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2402.02277</link><description>&lt;p&gt;
&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#36890;&#36807;&#22806;&#28304;&#20998;&#24067;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Causal Bayesian Optimization via Exogenous Distribution Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02277
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#22806;&#28304;&#21464;&#37327;&#30340;&#20998;&#24067;&#65292;&#25552;&#39640;&#20102;&#32467;&#26500;&#21270;&#22240;&#26524;&#27169;&#22411;&#30340;&#36817;&#20284;&#31934;&#24230;&#65292;&#24182;&#23558;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#25193;&#23637;&#21040;&#26356;&#19968;&#33324;&#30340;&#22240;&#26524;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32467;&#26500;&#21270;&#22240;&#26524;&#27169;&#22411;&#20013;&#65292;&#23558;&#30446;&#26631;&#21464;&#37327;&#26368;&#22823;&#21270;&#20316;&#20026;&#25805;&#20316;&#30446;&#26631;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#38382;&#39064;&#12290;&#29616;&#26377;&#30340;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;CBO&#65289;&#26041;&#27861;&#35201;&#20040;&#20381;&#36182;&#20110;&#25913;&#21464;&#22240;&#26524;&#32467;&#26500;&#20197;&#26368;&#22823;&#21270;&#22870;&#21169;&#30340;&#30828;&#24178;&#39044;&#65292;&#35201;&#20040;&#24341;&#20837;&#21160;&#20316;&#33410;&#28857;&#21040;&#20869;&#29983;&#21464;&#37327;&#20013;&#65292;&#20197;&#35843;&#25972;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#20197;&#23454;&#29616;&#30446;&#26631;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#22806;&#28304;&#21464;&#37327;&#30340;&#20998;&#24067;&#65292;&#36825;&#22312;&#29616;&#26377;&#26041;&#27861;&#20013;&#36890;&#24120;&#34987;&#24573;&#30053;&#25110;&#36890;&#36807;&#26399;&#26395;&#36827;&#34892;&#36793;&#32536;&#21270;&#12290;&#22806;&#28304;&#20998;&#24067;&#23398;&#20064;&#25552;&#39640;&#20102;&#36890;&#24120;&#36890;&#36807;&#26377;&#38480;&#35266;&#27979;&#25968;&#25454;&#35757;&#32451;&#30340;&#20195;&#29702;&#27169;&#22411;&#20013;&#30340;&#32467;&#26500;&#21270;&#22240;&#26524;&#27169;&#22411;&#30340;&#36817;&#20284;&#31934;&#24230;&#12290;&#27492;&#22806;&#65292;&#23398;&#20064;&#21040;&#30340;&#22806;&#28304;&#20998;&#24067;&#23558;&#29616;&#26377;&#30340;CBO&#25193;&#23637;&#21040;&#36229;&#20986;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#65288;ANM&#65289;&#30340;&#19968;&#33324;&#22240;&#26524;&#26041;&#26696;&#12290;&#24674;&#22797;&#22806;&#28304;&#21464;&#37327;&#20351;&#25105;&#20204;&#33021;&#22815;&#20026;&#22122;&#22768;&#25110;&#26410;&#35266;&#27979;&#21040;&#30340;&#38544;&#34255;&#21464;&#37327;&#20351;&#29992;&#26356;&#28789;&#27963;&#30340;&#20808;&#39564;&#12290;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;CBO&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Maximizing a target variable as an operational objective in a structured causal model is an important problem. Existing Causal Bayesian Optimization (CBO) methods either rely on hard interventions that alter the causal structure to maximize the reward; or introduce action nodes to endogenous variables so that the data generation mechanisms are adjusted to achieve the objective. In this paper, a novel method is introduced to learn the distribution of exogenous variables, which is typically ignored or marginalized through expectation by existing methods.   Exogenous distribution learning improves the approximation accuracy of structured causal models in a surrogate model that is usually trained with limited observational data. Moreover, the learned exogenous distribution extends existing CBO to general causal schemes beyond Additive Noise Models (ANM). The recovery of exogenous variables allows us to use a more flexible prior for noise or unobserved hidden variables. A new CBO method is 
&lt;/p&gt;</description></item><item><title>&#12298;&#22312;&#22823;&#35268;&#27169;&#20154;&#24037;&#26234;&#33021;&#26102;&#20195;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#12299;&#36825;&#31687;&#31435;&#22330;&#35770;&#25991;&#25506;&#35752;&#20102;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#22312;&#21508;&#31181;&#19981;&#21516;&#35774;&#32622;&#19979;&#30340;&#20248;&#21183;&#65292;&#24182;&#25351;&#20986;&#20102;&#19982;&#20043;&#30456;&#20851;&#30340;&#25361;&#25112;&#21644;&#26377;&#36259;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;&#26410;&#26469;&#30340;&#30740;&#31350;&#37325;&#28857;&#23558;&#25918;&#22312;&#22914;&#20309;&#23558;&#22823;&#35268;&#27169;&#22522;&#30784;&#27169;&#22411;&#19982;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#20197;&#21457;&#25381;&#23427;&#20204;&#30340;&#20840;&#37096;&#28508;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.00809</link><description>&lt;p&gt;
&#12298;&#22312;&#22823;&#35268;&#27169;&#20154;&#24037;&#26234;&#33021;&#26102;&#20195;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#12299;&#30340;&#31435;&#22330;&#35770;&#25991;
&lt;/p&gt;
&lt;p&gt;
Position Paper: Bayesian Deep Learning in the Age of Large-Scale AI
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00809
&lt;/p&gt;
&lt;p&gt;
&#12298;&#22312;&#22823;&#35268;&#27169;&#20154;&#24037;&#26234;&#33021;&#26102;&#20195;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#12299;&#36825;&#31687;&#31435;&#22330;&#35770;&#25991;&#25506;&#35752;&#20102;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#22312;&#21508;&#31181;&#19981;&#21516;&#35774;&#32622;&#19979;&#30340;&#20248;&#21183;&#65292;&#24182;&#25351;&#20986;&#20102;&#19982;&#20043;&#30456;&#20851;&#30340;&#25361;&#25112;&#21644;&#26377;&#36259;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;&#26410;&#26469;&#30340;&#30740;&#31350;&#37325;&#28857;&#23558;&#25918;&#22312;&#22914;&#20309;&#23558;&#22823;&#35268;&#27169;&#22522;&#30784;&#27169;&#22411;&#19982;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#20197;&#21457;&#25381;&#23427;&#20204;&#30340;&#20840;&#37096;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24403;&#21069;&#30340;&#28145;&#24230;&#23398;&#20064;&#30740;&#31350;&#39046;&#22495;&#20013;&#65292;&#20154;&#20204;&#20027;&#35201;&#20851;&#27880;&#22312;&#28041;&#21450;&#22823;&#35268;&#27169;&#22270;&#20687;&#21644;&#35821;&#35328;&#25968;&#25454;&#38598;&#30340;&#30417;&#30563;&#20219;&#21153;&#20013;&#23454;&#29616;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#26356;&#24191;&#27867;&#30340;&#35270;&#35282;&#25581;&#31034;&#20102;&#35768;&#22810;&#34987;&#24573;&#35270;&#30340;&#24230;&#37327;&#26631;&#20934;&#12289;&#20219;&#21153;&#21644;&#25968;&#25454;&#31867;&#22411;&#65292;&#22914;&#19981;&#30830;&#23450;&#24615;&#12289;&#20027;&#21160;&#21644;&#25345;&#32493;&#23398;&#20064;&#20197;&#21450;&#31185;&#23398;&#25968;&#25454;&#65292;&#36825;&#20123;&#26041;&#38754;&#38656;&#35201;&#20851;&#27880;&#12290;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#65288;BDL&#65289;&#26159;&#19968;&#26465;&#26377;&#21069;&#26223;&#30340;&#36947;&#36335;&#65292;&#21487;&#20197;&#22312;&#36825;&#20123;&#19981;&#21516;&#30340;&#35774;&#32622;&#20013;&#25552;&#20379;&#20248;&#21183;&#12290;&#26412;&#25991;&#35748;&#20026;BDL&#21487;&#20197;&#25552;&#21319;&#28145;&#24230;&#23398;&#20064;&#30340;&#33021;&#21147;&#12290;&#23427;&#37325;&#26032;&#23457;&#35270;&#20102;BDL&#30340;&#20248;&#21183;&#12289;&#25215;&#35748;&#20102;&#29616;&#26377;&#30340;&#25361;&#25112;&#65292;&#24182;&#37325;&#28857;&#20171;&#32461;&#20102;&#19968;&#20123;&#26088;&#22312;&#35299;&#20915;&#36825;&#20123;&#38556;&#30861;&#30340;&#26377;&#36259;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;&#23637;&#26395;&#26410;&#26469;&#65292;&#35752;&#35770;&#38598;&#20013;&#22312;&#21487;&#33021;&#30340;&#26041;&#24335;&#19978;&#65292;&#23558;&#22823;&#35268;&#27169;&#22522;&#30784;&#27169;&#22411;&#19982;BDL&#30456;&#32467;&#21512;&#65292;&#20197;&#20805;&#20998;&#21457;&#25381;&#23427;&#20204;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the current landscape of deep learning research, there is a predominant emphasis on achieving high predictive accuracy in supervised tasks involving large image and language datasets. However, a broader perspective reveals a multitude of overlooked metrics, tasks, and data types, such as uncertainty, active and continual learning, and scientific data, that demand attention. Bayesian deep learning (BDL) constitutes a promising avenue, offering advantages across these diverse settings. This paper posits that BDL can elevate the capabilities of deep learning. It revisits the strengths of BDL, acknowledges existing challenges, and highlights some exciting research avenues aimed at addressing these obstacles. Looking ahead, the discussion focuses on possible ways to combine large-scale foundation models with BDL to unlock their full potential.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#31995;&#32479;&#22320;&#25506;&#35752;&#20102;Transformer&#22312;&#38271;&#24207;&#21015;&#24314;&#27169;&#20013;&#30340;&#36817;&#20284;&#24615;&#36136;&#65292;&#24182;&#30740;&#31350;&#20102;&#20854;&#20851;&#38190;&#32452;&#20214;&#23545;&#34920;&#36798;&#33021;&#21147;&#30340;&#24433;&#21709;&#26426;&#21046;&#12290;&#36825;&#20123;&#21457;&#29616;&#25581;&#31034;&#20102;&#20851;&#38190;&#21442;&#25968;&#23545;Transformer&#30340;&#20316;&#29992;&#65292;&#24182;&#20026;&#26367;&#20195;&#26550;&#26500;&#25552;&#20379;&#20102;&#33258;&#28982;&#24314;&#35758;&#12290;</title><link>https://arxiv.org/abs/2402.00522</link><description>&lt;p&gt;
&#29702;&#35299;Transformer&#22312;&#24207;&#21015;&#24314;&#27169;&#20013;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Understanding the Expressive Power and Mechanisms of Transformer for Sequence Modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00522
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#31995;&#32479;&#22320;&#25506;&#35752;&#20102;Transformer&#22312;&#38271;&#24207;&#21015;&#24314;&#27169;&#20013;&#30340;&#36817;&#20284;&#24615;&#36136;&#65292;&#24182;&#30740;&#31350;&#20102;&#20854;&#20851;&#38190;&#32452;&#20214;&#23545;&#34920;&#36798;&#33021;&#21147;&#30340;&#24433;&#21709;&#26426;&#21046;&#12290;&#36825;&#20123;&#21457;&#29616;&#25581;&#31034;&#20102;&#20851;&#38190;&#21442;&#25968;&#23545;Transformer&#30340;&#20316;&#29992;&#65292;&#24182;&#20026;&#26367;&#20195;&#26550;&#26500;&#25552;&#20379;&#20102;&#33258;&#28982;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;Transformer&#22312;&#38271;&#12289;&#31232;&#30095;&#21644;&#22797;&#26434;&#35760;&#24518;&#30340;&#24207;&#21015;&#24314;&#27169;&#20013;&#30340;&#36817;&#20284;&#24615;&#36136;&#36827;&#34892;&#20102;&#31995;&#32479;&#30740;&#31350;&#12290;&#25105;&#20204;&#35843;&#26597;&#20102;Transformer&#30340;&#19981;&#21516;&#32452;&#20214;&#65288;&#22914;&#28857;&#31215;&#33258;&#27880;&#24847;&#21147;&#12289;&#20301;&#32622;&#32534;&#30721;&#21644;&#21069;&#39304;&#23618;&#65289;&#26159;&#22914;&#20309;&#24433;&#21709;&#20854;&#34920;&#36798;&#33021;&#21147;&#30340;&#26426;&#21046;&#65292;&#24182;&#36890;&#36807;&#24314;&#31435;&#26126;&#30830;&#30340;&#36817;&#20284;&#29575;&#26469;&#30740;&#31350;&#23427;&#20204;&#30340;&#32508;&#21512;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;Transformer&#20013;&#20851;&#38190;&#21442;&#25968;&#65288;&#22914;&#23618;&#25968;&#21644;&#27880;&#24847;&#21147;&#22836;&#25968;&#65289;&#30340;&#20316;&#29992;&#65292;&#24182;&#19988;&#36825;&#20123;&#27934;&#23519;&#36824;&#20026;&#26367;&#20195;&#26550;&#26500;&#25552;&#20379;&#20102;&#33258;&#28982;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
We conduct a systematic study of the approximation properties of Transformer for sequence modeling with long, sparse and complicated memory. We investigate the mechanisms through which different components of Transformer, such as the dot-product self-attention, positional encoding and feed-forward layer, affect its expressive power, and we study their combined effects through establishing explicit approximation rates. Our study reveals the roles of critical parameters in the Transformer, such as the number of layers and the number of attention heads, and these insights also provide natural suggestions for alternative architectures.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#30740;&#31350;&#20102;&#26465;&#20214;&#24615;&#26368;&#20248;&#36755;&#36816;&#65292;&#25552;&#20986;&#20102;&#25551;&#36848;&#26465;&#20214;&#27979;&#24230;&#30340;&#22359;&#19977;&#35282;&#33945;&#29305;&#22320;&#22270;&#20197;&#21450;&#23427;&#20204;&#30340;Kantorovich&#26494;&#24347;&#30340;&#32422;&#26463;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#30340;&#29702;&#35770;&#65292;&#24182;&#22312;&#36125;&#21494;&#26031;&#25512;&#29702;&#38382;&#39064;&#20013;&#24471;&#21040;&#20102;&#26465;&#20214;&#26144;&#23556;&#30340;&#27491;&#21017;&#24615;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2311.05672</link><description>&lt;p&gt;
&#26465;&#20214;&#24615;&#20989;&#25968;&#31354;&#38388;&#19978;&#30340;&#26465;&#20214;&#26368;&#20248;&#36755;&#36816;
&lt;/p&gt;
&lt;p&gt;
Conditional Optimal Transport on Function Spaces
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.05672
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#30740;&#31350;&#20102;&#26465;&#20214;&#24615;&#26368;&#20248;&#36755;&#36816;&#65292;&#25552;&#20986;&#20102;&#25551;&#36848;&#26465;&#20214;&#27979;&#24230;&#30340;&#22359;&#19977;&#35282;&#33945;&#29305;&#22320;&#22270;&#20197;&#21450;&#23427;&#20204;&#30340;Kantorovich&#26494;&#24347;&#30340;&#32422;&#26463;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#30340;&#29702;&#35770;&#65292;&#24182;&#22312;&#36125;&#21494;&#26031;&#25512;&#29702;&#38382;&#39064;&#20013;&#24471;&#21040;&#20102;&#26465;&#20214;&#26144;&#23556;&#30340;&#27491;&#21017;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20174;&#26368;&#20248;&#36755;&#36816;&#30340;&#35270;&#35282;&#65292;&#20197;&#21450;&#23545;&#25674;&#38144;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#32771;&#34385;&#65292;&#31995;&#32479;&#22320;&#30740;&#31350;&#20102;&#20989;&#25968;&#31354;&#38388;&#20013;&#30340;&#26465;&#20214;&#19977;&#35282;&#24418;&#36755;&#36816;&#26144;&#23556;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#21457;&#23637;&#20102;&#19968;&#20010;&#25551;&#36848;&#22359;&#19977;&#35282;&#33945;&#29305;&#22320;&#22270;&#20197;&#21450;&#23427;&#20204;&#30340;Kantorovich&#26494;&#24347;&#30340;&#32422;&#26463;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#30340;&#29702;&#35770;&#65292;&#36825;&#20010;&#29702;&#35770;&#23558;&#26368;&#20248;&#19977;&#35282;&#24418;&#36755;&#36816;&#29702;&#35770;&#25512;&#24191;&#21040;&#24102;&#26377;&#19968;&#33324;&#20195;&#20215;&#20989;&#25968;&#30340;&#21487;&#20998;&#26080;&#38480;&#32500;&#20989;&#25968;&#31354;&#38388;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#26681;&#25454;&#36125;&#21494;&#26031;&#25512;&#29702;&#38382;&#39064;&#30340;&#24773;&#20917;&#35843;&#25972;&#25105;&#20204;&#30340;&#32467;&#26524;&#65292;&#24182;&#33719;&#24471;&#20102;&#20174;&#20808;&#39564;&#21040;&#21518;&#39564;&#30340;&#26465;&#20214;&#26144;&#23556;&#30340;&#27491;&#21017;&#24615;&#20272;&#35745;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25968;&#20540;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#29702;&#35770;&#32467;&#26524;&#22312;&#20989;&#25968;&#21442;&#25968;&#30340;&#25674;&#38144;&#21644;&#26080;&#20284;&#28982;&#25512;&#26029;&#30340;&#35745;&#31639;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a systematic study of conditional triangular transport maps in function spaces from the perspective of optimal transportation and with a view towards amortized Bayesian inference. More specifically, we develop a theory of constrained optimal transport problems that describe block-triangular Monge maps that characterize conditional measures along with their Kantorovich relaxations. This generalizes the theory of optimal triangular transport to separable infinite-dimensional function spaces with general cost functions. We further tailor our results to the case of Bayesian inference problems and obtain regularity estimates on the conditioning maps from the prior to the posterior. Finally, we present numerical experiments that demonstrate the computational applicability of our theoretical results for amortized and likelihood-free inference of functional parameters.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#32508;&#36848;&#20171;&#32461;&#20102;&#31070;&#32463;&#31526;&#21495;&#20154;&#24037;&#26234;&#33021;&#22312;&#30693;&#35782;&#22270;&#35889;&#25512;&#29702;&#26041;&#38754;&#30340;&#30740;&#31350;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#26368;&#36817;&#30340;&#26041;&#27861;&#35797;&#22270;&#23558;&#31526;&#21495;&#25512;&#29702;&#21644;&#28145;&#24230;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#20197;&#29983;&#25104;&#20855;&#26377;&#35299;&#37322;&#24615;&#12289;&#31454;&#20105;&#24615;&#33021;&#21147;&#24182;&#38598;&#25104;&#19987;&#23478;&#30693;&#35782;&#30340;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2302.07200</link><description>&lt;p&gt;
&#30693;&#35782;&#22270;&#35889;&#25512;&#29702;&#30340;&#31070;&#32463;&#31526;&#21495;&#20154;&#24037;&#26234;&#33021;&#65306;&#19968;&#39033;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Neurosymbolic AI for Reasoning over Knowledge Graphs: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.07200
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#32508;&#36848;&#20171;&#32461;&#20102;&#31070;&#32463;&#31526;&#21495;&#20154;&#24037;&#26234;&#33021;&#22312;&#30693;&#35782;&#22270;&#35889;&#25512;&#29702;&#26041;&#38754;&#30340;&#30740;&#31350;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#26368;&#36817;&#30340;&#26041;&#27861;&#35797;&#22270;&#23558;&#31526;&#21495;&#25512;&#29702;&#21644;&#28145;&#24230;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#20197;&#29983;&#25104;&#20855;&#26377;&#35299;&#37322;&#24615;&#12289;&#31454;&#20105;&#24615;&#33021;&#21147;&#24182;&#38598;&#25104;&#19987;&#23478;&#30693;&#35782;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#31526;&#21495;&#20154;&#24037;&#26234;&#33021;&#26159;&#19968;&#20010;&#26085;&#30410;&#27963;&#36291;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#23427;&#23558;&#31526;&#21495;&#25512;&#29702;&#26041;&#27861;&#19982;&#28145;&#24230;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#20197;&#21033;&#29992;&#23427;&#20204;&#30340;&#20114;&#34917;&#20248;&#21183;&#12290;&#38543;&#30528;&#30693;&#35782;&#22270;&#35889;&#25104;&#20026;&#34920;&#31034;&#24322;&#26500;&#21644;&#22810;&#20851;&#31995;&#25968;&#25454;&#30340;&#19968;&#31181;&#27969;&#34892;&#26041;&#24335;&#65292;&#23545;&#22270;&#32467;&#26500;&#36827;&#34892;&#25512;&#29702;&#30340;&#26041;&#27861;&#24320;&#22987;&#36981;&#24490;&#36825;&#31181;&#31070;&#32463;&#31526;&#21495;&#33539;&#24335;&#12290;&#20256;&#32479;&#19978;&#65292;&#36825;&#20123;&#26041;&#27861;&#35201;&#20040;&#21033;&#29992;&#22522;&#20110;&#35268;&#21017;&#30340;&#25512;&#29702;&#65292;&#35201;&#20040;&#29983;&#25104;&#20195;&#34920;&#24615;&#30340;&#25968;&#20540;&#23884;&#20837;&#65292;&#20174;&#20013;&#21487;&#20197;&#25552;&#21462;&#20986;&#27169;&#24335;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#19968;&#20123;&#30740;&#31350;&#23581;&#35797;&#24357;&#21512;&#36825;&#31181;&#20108;&#20803;&#23545;&#31435;&#65292;&#25552;&#20986;&#20102;&#33021;&#22815;&#20419;&#36827;&#21487;&#35299;&#37322;&#24615;&#12289;&#20445;&#25345;&#31454;&#20105;&#24615;&#33021;&#21147;&#24182;&#38598;&#25104;&#19987;&#23478;&#30693;&#35782;&#30340;&#27169;&#22411;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#22312;&#30693;&#35782;&#22270;&#35889;&#19978;&#25191;&#34892;&#31070;&#32463;&#31526;&#21495;&#25512;&#29702;&#20219;&#21153;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#31867;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19977;&#20010;&#20027;&#35201;&#31867;&#21035;&#65306;&#65288;1&#65289;&#36923;&#36753;&#20449;&#24687;&#23884;&#20837;&#26041;&#27861;&#65292;&#65288;2&#65289;&#22522;&#20110;&#23884;&#20837;&#30340;&#26041;&#27861;&#19982;&#36923;&#36753;&#19968;&#33268;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Neurosymbolic AI is an increasingly active area of research that combines symbolic reasoning methods with deep learning to leverage their complementary benefits. As knowledge graphs are becoming a popular way to represent heterogeneous and multi-relational data, methods for reasoning on graph structures have attempted to follow this neurosymbolic paradigm. Traditionally, such approaches have utilized either rule-based inference or generated representative numerical embeddings from which patterns could be extracted. However, several recent studies have attempted to bridge this dichotomy to generate models that facilitate interpretability, maintain competitive performance, and integrate expert knowledge. Therefore, we survey methods that perform neurosymbolic reasoning tasks on knowledge graphs and propose a novel taxonomy by which we can classify them. Specifically, we propose three major categories: (1) logically-informed embedding approaches, (2) embedding approaches with logical cons
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#38750;&#21442;&#25968;&#20808;&#39564;&#22522;&#20110;&#20998;&#25968;&#21518;&#39564;&#20998;&#24067;&#30340;&#36817;&#20284;&#32447;&#24615;&#21322;&#21442;&#25968;&#20989;&#25968;&#65292;&#24314;&#31435;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;Bernstein-von Mises&#23450;&#29702;&#65292;&#25552;&#20986;&#20102;&#21487;&#38752;&#30340;&#21322;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#25913;&#36827;&#30340;&#20998;&#25968;&#21518;&#39564;&#38598;&#35299;&#20915;&#20102;&#21487;&#20449;&#38598;&#22823;&#23567;&#22840;&#22823;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2301.08158</link><description>&lt;p&gt;
&#20351;&#29992;&#20998;&#25968;&#21518;&#39564;&#36827;&#34892;&#21322;&#21442;&#25968;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Semiparametric inference using fractional posteriors
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2301.08158
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#38750;&#21442;&#25968;&#20808;&#39564;&#22522;&#20110;&#20998;&#25968;&#21518;&#39564;&#20998;&#24067;&#30340;&#36817;&#20284;&#32447;&#24615;&#21322;&#21442;&#25968;&#20989;&#25968;&#65292;&#24314;&#31435;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;Bernstein-von Mises&#23450;&#29702;&#65292;&#25552;&#20986;&#20102;&#21487;&#38752;&#30340;&#21322;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#25913;&#36827;&#30340;&#20998;&#25968;&#21518;&#39564;&#38598;&#35299;&#20915;&#20102;&#21487;&#20449;&#38598;&#22823;&#23567;&#22840;&#22823;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#22522;&#20110;&#38750;&#21442;&#25968;&#20808;&#39564;&#30340;&#20998;&#25968;&#21518;&#39564;&#20998;&#24067;&#30340;&#36817;&#20284;&#32447;&#24615;&#21322;&#21442;&#25968;&#20989;&#25968;&#19978;&#24314;&#31435;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;Bernstein-von Mises&#23450;&#29702;&#12290;&#22312;&#35768;&#22810;&#38750;&#21442;&#25968;&#35774;&#32622;&#21644;&#19981;&#21516;&#31867;&#21035;&#30340;&#20808;&#39564;&#20998;&#24067;&#65288;&#21253;&#25324;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#65289;&#20013;&#36827;&#34892;&#20102;&#35828;&#26126;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#20998;&#25968;&#21518;&#39564;&#21487;&#20449;&#38598;&#21487;&#20197;&#25552;&#20379;&#21487;&#38752;&#30340;&#21322;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#20294;&#26159;&#22823;&#23567;&#20250;&#34987;&#22840;&#22823;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#31181;"&#31227;&#21160;&#21644;&#37325;&#26032;&#32553;&#25918;"&#30340;&#20998;&#25968;&#21518;&#39564;&#38598;&#65292;&#23427;&#26159;&#19968;&#20010;&#20855;&#26377;&#26368;&#20248;&#22823;&#23567;&#30340;&#39640;&#25928;&#32622;&#20449;&#38598;&#65292;&#23613;&#31649;&#22312;&#27491;&#21017;&#26465;&#20214;&#19979;&#12290;&#20316;&#20026;&#25105;&#20204;&#35777;&#26126;&#30340;&#19968;&#37096;&#20998;&#65292;&#25105;&#20204;&#36890;&#36807;&#32454;&#21270;&#29575;&#23545;&#20110;&#20998;&#25968;&#25351;&#25968;&#30340;&#20381;&#36182;&#24615;&#65292;&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;&#20998;&#25968;&#21518;&#39564;&#21387;&#32553;&#29575;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We establish a general Bernstein--von Mises theorem for approximately linear semiparametric functionals of fractional posterior distributions based on nonparametric priors. This is illustrated in a number of nonparametric settings and for different classes of prior distributions, including Gaussian process priors. We show that fractional posterior credible sets can provide reliable semiparametric uncertainty quantification, but have inflated size. To remedy this, we further propose a \textit{shifted-and-rescaled} fractional posterior set that is an efficient confidence set having optimal size under regularity conditions. As part of our proofs, we also refine existing contraction rate results for fractional posteriors by sharpening the dependence of the rate on the fractional exponent.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20248;&#21270;&#30340;&#26041;&#27861;&#20013;&#20984;&#27491;&#21017;&#21270;&#30340;&#33021;&#21147;&#21644;&#23616;&#38480;&#24615;&#38382;&#39064;&#65292;&#36890;&#36807;&#30740;&#31350;&#32473;&#23450;&#20998;&#24067;&#24773;&#20917;&#19979;&#65292;&#23545;&#25968;&#25454;&#37319;&#29992;&#20309;&#31181;&#27491;&#21017;&#21270;&#26041;&#27861;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>https://arxiv.org/abs/2212.13597</link><description>&lt;p&gt;
&#36866;&#29992;&#20110;&#25968;&#25454;&#28304;&#30340;&#26368;&#20248;&#27491;&#21017;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Optimal Regularization for a Data Source
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2212.13597
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20248;&#21270;&#30340;&#26041;&#27861;&#20013;&#20984;&#27491;&#21017;&#21270;&#30340;&#33021;&#21147;&#21644;&#23616;&#38480;&#24615;&#38382;&#39064;&#65292;&#36890;&#36807;&#30740;&#31350;&#32473;&#23450;&#20998;&#24067;&#24773;&#20917;&#19979;&#65292;&#23545;&#25968;&#25454;&#37319;&#29992;&#20309;&#31181;&#27491;&#21017;&#21270;&#26041;&#27861;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#20110;&#20248;&#21270;&#30340;&#36870;&#38382;&#39064;&#21644;&#32479;&#35745;&#20272;&#35745;&#20013;&#65292;&#24120;&#24120;&#36890;&#36807;&#21152;&#20837;&#20419;&#20351;&#25968;&#25454;&#20445;&#30495;&#24615;&#30340;&#20934;&#21017;&#21644;&#20419;&#36827;&#35299;&#30340;&#25152;&#38656;&#32467;&#26500;&#24615;&#36136;&#30340;&#27491;&#21017;&#21270;&#39033;&#26469;&#35299;&#20915;&#38382;&#39064;&#12290;&#36873;&#25321;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#32422;&#26463;&#36890;&#24120;&#30001;&#21069;&#39046;&#22495;&#30693;&#35782;&#21644;&#35745;&#31639;&#32771;&#34385;&#20849;&#21516;&#39537;&#21160;&#12290;&#20984;&#27491;&#21017;&#21270;&#39033;&#22312;&#35745;&#31639;&#19978;&#20855;&#26377;&#21560;&#24341;&#21147;&#65292;&#20294;&#22312;&#25552;&#21319;&#32467;&#26500;&#31867;&#22411;&#26041;&#38754;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#38750;&#20984;&#27491;&#21017;&#21270;&#39033;&#22312;&#20419;&#36827;&#32467;&#26500;&#31867;&#22411;&#26041;&#38754;&#26356;&#20855;&#28789;&#27963;&#24615;&#65292;&#24182;&#19988;&#22312;&#26576;&#20123;&#24212;&#29992;&#20013;&#23637;&#31034;&#20986;&#20102;&#24378;&#22823;&#30340;&#23454;&#35777;&#24615;&#33021;&#65292;&#20294;&#21516;&#26102;&#20063;&#24102;&#26469;&#20102;&#35299;&#20915;&#30456;&#20851;&#20248;&#21270;&#38382;&#39064;&#30340;&#35745;&#31639;&#25361;&#25112;&#12290;&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#20197;&#19979;&#38382;&#39064;&#65292;&#23547;&#27714;&#23545;&#20984;&#27491;&#21017;&#21270;&#22312;&#25928;&#33021;&#21644;&#23616;&#38480;&#24615;&#26041;&#38754;&#30340;&#31995;&#32479;&#29702;&#35299;&#65306;&#32473;&#23450;&#19968;&#20010;&#20998;&#24067;&#65292;&#23545;&#20110;&#20174;&#35813;&#20998;&#24067;&#20013;&#25277;&#21462;&#30340;&#25968;&#25454;&#65292;&#20160;&#20040;&#26159;&#26368;&#20248;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65311;
&lt;/p&gt;
&lt;p&gt;
In optimization-based approaches to inverse problems and to statistical estimation, it is common to augment criteria that enforce data fidelity with a regularizer that promotes desired structural properties in the solution. The choice of a suitable regularizer is typically driven by a combination of prior domain information and computational considerations. Convex regularizers are attractive computationally but they are limited in the types of structure they can promote. On the other hand, nonconvex regularizers are more flexible in the forms of structure they can promote and they have showcased strong empirical performance in some applications, but they come with the computational challenge of solving the associated optimization problems. In this paper, we seek a systematic understanding of the power and the limitations of convex regularization by investigating the following questions: Given a distribution, what is the optimal regularizer for data drawn from the distribution? What pro
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26041;&#27861;&#65292;&#31216;&#20026;Hilbert&#26354;&#32447;&#25237;&#24433;(HCP)&#36317;&#31163;&#65292;&#29992;&#20110;&#27979;&#37327;&#20004;&#20010;&#27010;&#29575;&#20998;&#24067;&#20043;&#38388;&#30340;&#36317;&#31163;&#65292;&#24182;&#20855;&#26377;&#20302;&#22797;&#26434;&#24230;&#12290;&#36890;&#36807;Hilbert&#26354;&#32447;&#25237;&#24433;&#21644;&#36816;&#36755;&#36317;&#31163;&#35745;&#31639;&#65292;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#26377;&#30028;&#25903;&#25745;&#30340;&#27010;&#29575;&#27979;&#24230;&#65292;&#24182;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#20855;&#26377;&#36739;&#22909;&#30340;&#25910;&#25947;&#24615;&#33021;&#12290;&#20026;&#20102;&#35299;&#20915;&#32500;&#24230;&#28798;&#38590;&#65292;&#36824;&#24320;&#21457;&#20102;&#20004;&#20010;HCP&#36317;&#31163;&#30340;&#21464;&#20307;&#65292;&#20351;&#29992;&#23376;&#31354;&#38388;&#25237;&#24433;&#12290;</title><link>https://arxiv.org/abs/2205.15059</link><description>&lt;p&gt;
Hilbert&#26354;&#32447;&#25237;&#24433;&#36317;&#31163;&#29992;&#20110;&#20998;&#24067;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Hilbert Curve Projection Distance for Distribution Comparison
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2205.15059
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26041;&#27861;&#65292;&#31216;&#20026;Hilbert&#26354;&#32447;&#25237;&#24433;(HCP)&#36317;&#31163;&#65292;&#29992;&#20110;&#27979;&#37327;&#20004;&#20010;&#27010;&#29575;&#20998;&#24067;&#20043;&#38388;&#30340;&#36317;&#31163;&#65292;&#24182;&#20855;&#26377;&#20302;&#22797;&#26434;&#24230;&#12290;&#36890;&#36807;Hilbert&#26354;&#32447;&#25237;&#24433;&#21644;&#36816;&#36755;&#36317;&#31163;&#35745;&#31639;&#65292;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#26377;&#30028;&#25903;&#25745;&#30340;&#27010;&#29575;&#27979;&#24230;&#65292;&#24182;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#20855;&#26377;&#36739;&#22909;&#30340;&#25910;&#25947;&#24615;&#33021;&#12290;&#20026;&#20102;&#35299;&#20915;&#32500;&#24230;&#28798;&#38590;&#65292;&#36824;&#24320;&#21457;&#20102;&#20004;&#20010;HCP&#36317;&#31163;&#30340;&#21464;&#20307;&#65292;&#20351;&#29992;&#23376;&#31354;&#38388;&#25237;&#24433;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#27604;&#36739;&#22312;&#25968;&#25454;&#20998;&#31867;&#21644;&#29983;&#25104;&#24314;&#27169;&#31561;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#36215;&#30528;&#26680;&#24515;&#20316;&#29992;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26041;&#27861;&#65292;&#31216;&#20026;Hilbert&#26354;&#32447;&#25237;&#24433;(HCP)&#36317;&#31163;&#65292;&#29992;&#20110;&#27979;&#37327;&#20004;&#20010;&#27010;&#29575;&#20998;&#24067;&#20043;&#38388;&#30340;&#36317;&#31163;&#65292;&#24182;&#20855;&#26377;&#20302;&#22797;&#26434;&#24230;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#20351;&#29992;Hilbert&#26354;&#32447;&#23558;&#20004;&#20010;&#39640;&#32500;&#27010;&#29575;&#20998;&#24067;&#25237;&#24433;&#21040;&#19968;&#36215;&#65292;&#24471;&#21040;&#23427;&#20204;&#20043;&#38388;&#30340;&#32806;&#21512;&#65292;&#28982;&#21518;&#26681;&#25454;&#32806;&#21512;&#22312;&#21407;&#22987;&#31354;&#38388;&#20013;&#35745;&#31639;&#36825;&#20004;&#20010;&#20998;&#24067;&#20043;&#38388;&#30340;&#36816;&#36755;&#36317;&#31163;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;HCP&#36317;&#31163;&#26159;&#19968;&#20010;&#36866;&#24403;&#30340;&#24230;&#37327;&#65292;&#24182;&#19988;&#23545;&#20110;&#26377;&#30028;&#25903;&#25745;&#30340;&#27010;&#29575;&#27979;&#24230;&#26159;&#33391;&#23450;&#20041;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#22312;$d$&#32500;&#31354;&#38388;&#20013;&#20855;&#26377;$L_p$&#25104;&#26412;&#30340;&#25913;&#36827;&#32463;&#39564;HCP&#36317;&#31163;&#20197;&#19981;&#36229;&#36807;$O(n^{-1/2\max\{d,p\}})$&#30340;&#36895;&#29575;&#25910;&#25947;&#21040;&#20854;&#24635;&#20307;&#23545;&#24212;&#39033;&#12290;&#20026;&#20102;&#25233;&#21046;&#32500;&#24230;&#28798;&#38590;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#20004;&#20010;HCP&#36317;&#31163;&#30340;&#21464;&#20307;&#65292;&#20351;&#29992;&#65288;&#21487;&#23398;&#20064;&#30340;&#65289;&#23376;&#31354;&#38388;&#25237;&#24433;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distribution comparison plays a central role in many machine learning tasks like data classification and generative modeling. In this study, we propose a novel metric, called Hilbert curve projection (HCP) distance, to measure the distance between two probability distributions with low complexity. In particular, we first project two high-dimensional probability distributions using Hilbert curve to obtain a coupling between them, and then calculate the transport distance between these two distributions in the original space, according to the coupling. We show that HCP distance is a proper metric and is well-defined for probability measures with bounded supports. Furthermore, we demonstrate that the modified empirical HCP distance with the $L_p$ cost in the $d$-dimensional space converges to its population counterpart at a rate of no more than $O(n^{-1/2\max\{d,p\}})$. To suppress the curse-of-dimensionality, we also develop two variants of the HCP distance using (learnable) subspace pro
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#25512;&#23548;&#20986;&#22312;&#32452;&#20844;&#24179;&#24615;&#19979;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#20998;&#31867;&#22120;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FairBayes&#30340;&#22522;&#20110;&#32452;&#30340;&#38408;&#20540;&#26041;&#27861;&#65292;&#21487;&#20197;&#30452;&#25509;&#25511;&#21046;&#19981;&#20844;&#24179;&#29616;&#35937;&#65292;&#23454;&#29616;&#22522;&#26412;&#26368;&#20248;&#30340;&#20844;&#24179;&#24615;-&#20934;&#30830;&#24615;&#26435;&#34913;&#12290;</title><link>https://arxiv.org/abs/2202.09724</link><description>&lt;p&gt;
&#22522;&#20110;&#32452;&#20844;&#24179;&#24615;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#20998;&#31867;&#22120;
&lt;/p&gt;
&lt;p&gt;
Bayes-Optimal Classifiers under Group Fairness
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2202.09724
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#25512;&#23548;&#20986;&#22312;&#32452;&#20844;&#24179;&#24615;&#19979;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#20998;&#31867;&#22120;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FairBayes&#30340;&#22522;&#20110;&#32452;&#30340;&#38408;&#20540;&#26041;&#27861;&#65292;&#21487;&#20197;&#30452;&#25509;&#25511;&#21046;&#19981;&#20844;&#24179;&#29616;&#35937;&#65292;&#23454;&#29616;&#22522;&#26412;&#26368;&#20248;&#30340;&#20844;&#24179;&#24615;-&#20934;&#30830;&#24615;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#27491;&#36234;&#26469;&#36234;&#22810;&#22320;&#34701;&#20837;&#21040;&#39640;&#39118;&#38505;&#20915;&#31574;&#36807;&#31243;&#20013;&#65292;&#20363;&#22914;&#31038;&#20250;&#31119;&#21033;&#38382;&#39064;&#12290;&#30001;&#20110;&#38656;&#35201;&#20943;&#23569;&#31639;&#27861;&#39044;&#27979;&#21487;&#33021;&#36896;&#25104;&#30340;&#19981;&#24179;&#31561;&#24433;&#21709;&#65292;&#35768;&#22810;&#20844;&#24179;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#24050;&#32463;&#34987;&#25552;&#20986;&#12290;&#28982;&#32780;&#65292;&#22312;&#21508;&#31181;&#32452;&#20844;&#24179;&#24615;&#32422;&#26463;&#19979;&#21051;&#30011;&#36125;&#21494;&#26031;&#26368;&#20248;&#20998;&#31867;&#22120;&#30340;&#22522;&#26412;&#38382;&#39064;&#20165;&#22312;&#19968;&#20123;&#29305;&#27530;&#24773;&#20917;&#19979;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#26412;&#25991;&#22522;&#20110;&#32463;&#20856;&#30340;Neyman-Pearson&#20551;&#35774;&#26816;&#39564;&#29702;&#35770;&#65288;Neyman&#21644;Pearson&#65292;1933&#65307;Shao&#65292;2003&#65289;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#26469;&#25512;&#23548;&#22312;&#32452;&#20844;&#24179;&#24615;&#19979;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#20998;&#31867;&#22120;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#32452;&#30340;&#38408;&#20540;&#26041;&#27861;&#65292;&#31216;&#20026;FairBayes&#65292;&#21487;&#20197;&#30452;&#25509;&#25511;&#21046;&#19981;&#20844;&#24179;&#29616;&#35937;&#65292;&#24182;&#23454;&#29616;&#22522;&#26412;&#26368;&#20248;&#30340;&#20844;&#24179;&#24615;-&#20934;&#30830;&#24615;&#26435;&#34913;&#12290;&#36825;&#20123;&#20248;&#21183;&#36890;&#36807;&#20805;&#20998;&#30340;&#23454;&#39564;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning algorithms are becoming integrated into more and more high-stakes decision-making processes, such as in social welfare issues. Due to the need of mitigating the potentially disparate impacts from algorithmic predictions, many approaches have been proposed in the emerging area of fair machine learning. However, the fundamental problem of characterizing Bayes-optimal classifiers under various group fairness constraints has only been investigated in some special cases. Based on the classical Neyman-Pearson argument (Neyman and Pearson, 1933; Shao, 2003) for optimal hypothesis testing, this paper provides a unified framework for deriving Bayes-optimal classifiers under group fairness. This enables us to propose a group-based thresholding method we call FairBayes, that can directly control disparity, and achieve an essentially optimal fairness-accuracy tradeoff. These advantages are supported by thorough experiments.
&lt;/p&gt;</description></item><item><title>NetOTC&#26159;&#19968;&#31181;&#29992;&#20110;&#27604;&#36739;&#21644;&#23545;&#40784;&#20004;&#20010;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#38543;&#26426;&#34892;&#36208;&#30340;&#36716;&#25442;&#32806;&#21512;&#30340;&#26399;&#26395;&#25104;&#26412;&#26469;&#37327;&#21270;&#32593;&#32476;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#24182;&#25552;&#20379;&#39030;&#28857;&#21644;&#36793;&#30340;&#23545;&#40784;&#12290;&#23427;&#25429;&#25417;&#21040;&#20102;&#20851;&#20110;&#32593;&#32476;&#30340;&#23616;&#37096;&#21644;&#20840;&#23616;&#20449;&#24687;&#65292;&#24182;&#20445;&#30041;&#20102;&#36793;&#32536;&#12290;</title><link>https://arxiv.org/abs/2106.07106</link><description>&lt;p&gt;
&#36890;&#36807;&#38543;&#26426;&#34892;&#36208;&#30340;&#36716;&#25442;&#32806;&#21512;&#27604;&#23545;&#21644;&#23545;&#40784;&#26377;&#21521;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Alignment and Comparison of Directed Networks via Transition Couplings of Random Walks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2106.07106
&lt;/p&gt;
&lt;p&gt;
NetOTC&#26159;&#19968;&#31181;&#29992;&#20110;&#27604;&#36739;&#21644;&#23545;&#40784;&#20004;&#20010;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#38543;&#26426;&#34892;&#36208;&#30340;&#36716;&#25442;&#32806;&#21512;&#30340;&#26399;&#26395;&#25104;&#26412;&#26469;&#37327;&#21270;&#32593;&#32476;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#24182;&#25552;&#20379;&#39030;&#28857;&#21644;&#36793;&#30340;&#23545;&#40784;&#12290;&#23427;&#25429;&#25417;&#21040;&#20102;&#20851;&#20110;&#32593;&#32476;&#30340;&#23616;&#37096;&#21644;&#20840;&#23616;&#20449;&#24687;&#65292;&#24182;&#20445;&#30041;&#20102;&#36793;&#32536;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25551;&#36848;&#24182;&#30740;&#31350;&#20102;&#19968;&#31181;&#22522;&#20110;&#20256;&#36755;&#30340;&#36807;&#31243;&#65292;&#31216;&#20026;NetOTC&#65288;&#32593;&#32476;&#20248;&#21270;&#36716;&#25442;&#32806;&#21512;&#65289;&#65292;&#29992;&#20110;&#27604;&#36739;&#21644;&#23545;&#40784;&#20004;&#20010;&#32593;&#32476;&#12290;&#25152;&#30740;&#31350;&#30340;&#32593;&#32476;&#21487;&#20197;&#26159;&#26377;&#21521;&#25110;&#26080;&#21521;&#30340;&#65292;&#24102;&#26435;&#37325;&#25110;&#19981;&#24102;&#26435;&#37325;&#65292;&#24182;&#19988;&#21487;&#33021;&#20855;&#26377;&#19981;&#21516;&#22823;&#23567;&#30340;&#19981;&#21516;&#39030;&#28857;&#38598;&#12290;&#32473;&#23450;&#20004;&#20010;&#32593;&#32476;&#21644;&#19968;&#20010;&#19982;&#23427;&#20204;&#30340;&#39030;&#28857;&#30456;&#20851;&#30340;&#25104;&#26412;&#20989;&#25968;&#65292;NetOTC&#25214;&#21040;&#20854;&#38543;&#26426;&#34892;&#36208;&#30340;&#36716;&#25442;&#32806;&#21512;&#65292;&#20351;&#20854;&#20855;&#26377;&#26368;&#23567;&#30340;&#26399;&#26395;&#25104;&#26412;&#12290;&#26368;&#23567;&#21270;&#30340;&#25104;&#26412;&#37327;&#21270;&#20102;&#32593;&#32476;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#32780;&#26368;&#20339;&#20256;&#36755;&#35745;&#21010;&#26412;&#36523;&#25552;&#20379;&#20102;&#20004;&#20010;&#32593;&#32476;&#30340;&#39030;&#28857;&#21644;&#36793;&#30340;&#23545;&#40784;&#12290;&#36890;&#36807;&#32806;&#21512;&#23436;&#25972;&#30340;&#38543;&#26426;&#34892;&#36208;&#65292;&#32780;&#19981;&#26159;&#23427;&#20204;&#30340;&#36793;&#32536;&#20998;&#24067;&#65292;&#30830;&#20445;NetOTC&#25429;&#25417;&#21040;&#20102;&#20851;&#20110;&#32593;&#32476;&#30340;&#23616;&#37096;&#21644;&#20840;&#23616;&#20449;&#24687;&#65292;&#24182;&#20445;&#30041;&#20102;&#36793;&#32536;&#12290;NetOTC&#27809;&#26377;&#33258;&#30001;&#21442;&#25968;&#65292;&#24182;&#19988;&#19981;&#20381;&#36182;&#38543;&#26426;&#21270;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;NetOTC&#30340;&#19968;&#20123;&#29702;&#35770;&#29305;&#24615;&#65292;&#24182;&#36827;&#34892;&#20102;&#19968;&#20123;&#23454;&#39564;&#35777;&#26126;&#20854;&#23454;&#38469;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We describe and study a transport based procedure called NetOTC (network optimal transition coupling) for the comparison and alignment of two networks. The networks of interest may be directed or undirected, weighted or unweighted, and may have distinct vertex sets of different sizes. Given two networks and a cost function relating their vertices, NetOTC finds a transition coupling of their associated random walks having minimum expected cost. The minimizing cost quantifies the difference between the networks, while the optimal transport plan itself provides alignments of both the vertices and the edges of the two networks. Coupling of the full random walks, rather than their marginal distributions, ensures that NetOTC captures local and global information about the networks, and preserves edges. NetOTC has no free parameters, and does not rely on randomization. We investigate a number of theoretical properties of NetOTC and present experiments establishing its empirical performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;InstaHide&#30340;&#26368;&#26032;&#25915;&#20987;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#26469;&#29702;&#35299;&#21644;&#20998;&#26512;&#36825;&#20123;&#25915;&#20987;&#12290;&#36890;&#36807;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#22312;InstaHide&#25361;&#25112;&#35774;&#32622;&#19979;&#65292;&#20197;&#21487;&#35777;&#26126;&#30340;&#20445;&#35777;&#21644;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#24674;&#22797;&#25152;&#26377;&#31169;&#20154;&#22270;&#29255;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#26816;&#32034;&#25152;&#26377;InstaHide&#22270;&#29255;&#30340;&#35745;&#31639;&#38590;&#24230;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2011.11877</link><description>&lt;p&gt;
InstaHide&#28151;&#21512;&#20004;&#20010;&#31169;&#20154;&#22270;&#29255;&#26102;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
InstaHide's Sample Complexity When Mixing Two Private Images
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2011.11877
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;InstaHide&#30340;&#26368;&#26032;&#25915;&#20987;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#26469;&#29702;&#35299;&#21644;&#20998;&#26512;&#36825;&#20123;&#25915;&#20987;&#12290;&#36890;&#36807;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#22312;InstaHide&#25361;&#25112;&#35774;&#32622;&#19979;&#65292;&#20197;&#21487;&#35777;&#26126;&#30340;&#20445;&#35777;&#21644;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#24674;&#22797;&#25152;&#26377;&#31169;&#20154;&#22270;&#29255;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#26816;&#32034;&#25152;&#26377;InstaHide&#22270;&#29255;&#30340;&#35745;&#31639;&#38590;&#24230;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#36890;&#24120;&#38656;&#35201;&#22823;&#37327;&#30340;&#25935;&#24863;&#35757;&#32451;&#25968;&#25454;&#65292;&#22914;&#20309;&#20445;&#25252;&#35757;&#32451;&#25968;&#25454;&#30340;&#38544;&#31169;&#24050;&#25104;&#20026;&#28145;&#24230;&#23398;&#20064;&#30740;&#31350;&#20013;&#30340;&#37325;&#35201;&#35838;&#39064;&#12290;InstaHide&#26159;&#19968;&#31181;&#26368;&#20808;&#36827;&#30340;&#29992;&#20110;&#20445;&#25252;&#35757;&#32451;&#25968;&#25454;&#38544;&#31169;&#30340;&#26041;&#26696;&#65292;&#23545;&#27979;&#35797;&#20934;&#30830;&#24615;&#21482;&#26377;&#24494;&#23567;&#24433;&#21709;&#65292;&#24182;&#19988;&#20854;&#23433;&#20840;&#24615;&#24050;&#25104;&#20026;&#19968;&#20010;&#31361;&#20986;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#31995;&#32479;&#30740;&#31350;&#20102;&#23545;InstaHide&#30340;&#26368;&#26032;&#25915;&#20987;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#26469;&#29702;&#35299;&#21644;&#20998;&#26512;&#36825;&#20123;&#25915;&#20987;&#12290;&#25105;&#20204;&#21457;&#29616;&#29616;&#26377;&#30340;&#25915;&#20987;&#35201;&#20040;&#27809;&#26377;&#21487;&#35777;&#26126;&#30340;&#20445;&#35777;&#65292;&#35201;&#20040;&#21482;&#33021;&#24674;&#22797;&#19968;&#20010;&#31169;&#20154;&#22270;&#29255;&#12290;&#22312;&#24403;&#21069;&#30340;InstaHide&#25361;&#25112;&#35774;&#32622;&#19979;&#65292;&#27599;&#20010;InstaHide&#22270;&#29255;&#26159;&#20004;&#20010;&#31169;&#20154;&#22270;&#29255;&#30340;&#28151;&#21512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#26469;&#20197;&#21487;&#35777;&#26126;&#30340;&#20445;&#35777;&#21644;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#24674;&#22797;&#25152;&#26377;&#31169;&#20154;&#22270;&#29255;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#20851;&#20110;&#26816;&#32034;&#25152;&#26377;InstaHide&#22270;&#29255;&#30340;&#35745;&#31639;&#38590;&#24230;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;InstaHide&#22312;&#20449;&#24687;&#35770;&#19978;&#24182;&#38750;&#26159;&#23433;&#20840;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training neural networks usually require large numbers of sensitive training data, and how to protect the privacy of training data has thus become a critical topic in deep learning research. InstaHide is a state-of-the-art scheme to protect training data privacy with only minor effects on test accuracy, and its security has become a salient question. In this paper, we systematically study recent attacks on InstaHide and present a unified framework to understand and analyze these attacks. We find that existing attacks either do not have a provable guarantee or can only recover a single private image. On the current InstaHide challenge setup, where each InstaHide image is a mixture of two private images, we present a new algorithm to recover all the private images with a provable guarantee and optimal sample complexity. In addition, we also provide a computational hardness result on retrieving all InstaHide images. Our results demonstrate that InstaHide is not information-theoretically s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#36793;&#38469;&#26426;&#21046;&#21644;&#20266;&#26597;&#35810;&#38598;&#30340;&#36328;&#22495;&#23569;&#26679;&#26412;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#29983;&#25104;&#20266;&#26597;&#35810;&#22270;&#20687;&#65292;&#24182;&#20511;&#37492;&#20154;&#33080;&#35782;&#21035;&#26041;&#27861;&#20013;&#30340;&#22823;&#36793;&#38469;&#26426;&#21046;&#23545;&#29305;&#24449;&#25552;&#21462;&#27169;&#22359;&#36827;&#34892;&#24494;&#35843;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#21508;&#20010;&#39046;&#22495;&#19978;&#37117;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#20248;&#21183;&#65292;&#23637;&#31034;&#20102;&#20854;&#40065;&#26834;&#24615;&#21644;&#36866;&#24212;&#39044;&#35757;&#32451;&#27169;&#22411;&#21040;&#26032;&#39046;&#22495;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2005.09218</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#36793;&#38469;&#26426;&#21046;&#21644;&#20266;&#26597;&#35810;&#38598;&#30340;&#36328;&#22495;&#23569;&#26679;&#26412;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Large Margin Mechanism and Pseudo Query Set on Cross-Domain Few-Shot Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2005.09218
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#36793;&#38469;&#26426;&#21046;&#21644;&#20266;&#26597;&#35810;&#38598;&#30340;&#36328;&#22495;&#23569;&#26679;&#26412;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#29983;&#25104;&#20266;&#26597;&#35810;&#22270;&#20687;&#65292;&#24182;&#20511;&#37492;&#20154;&#33080;&#35782;&#21035;&#26041;&#27861;&#20013;&#30340;&#22823;&#36793;&#38469;&#26426;&#21046;&#23545;&#29305;&#24449;&#25552;&#21462;&#27169;&#22359;&#36827;&#34892;&#24494;&#35843;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#21508;&#20010;&#39046;&#22495;&#19978;&#37117;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#20248;&#21183;&#65292;&#23637;&#31034;&#20102;&#20854;&#40065;&#26834;&#24615;&#21644;&#36866;&#24212;&#39044;&#35757;&#32451;&#27169;&#22411;&#21040;&#26032;&#39046;&#22495;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#23569;&#26679;&#26412;&#23398;&#20064;&#38382;&#39064;&#24341;&#36215;&#20102;&#24191;&#27867;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#20197;&#21069;&#30340;&#26041;&#27861;&#37117;&#26159;&#22312;&#21333;&#19968;&#39046;&#22495;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35757;&#32451;&#21644;&#27979;&#35797;&#65292;&#36328;&#22495;&#23569;&#26679;&#26412;&#23398;&#20064;&#26159;&#23569;&#26679;&#26412;&#23398;&#20064;&#38382;&#39064;&#30340;&#19968;&#20010;&#20840;&#26032;&#20998;&#25903;&#65292;&#20854;&#20013;&#27169;&#22411;&#22312;&#35757;&#32451;&#21644;&#27979;&#35797;&#38454;&#27573;&#22788;&#29702;&#19981;&#21516;&#39046;&#22495;&#30340;&#25968;&#25454;&#38598;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#20026;&#20102;&#35299;&#20915;&#22312;&#21333;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#65288;&#20803;&#35757;&#32451;&#65289;&#32780;&#22312;&#21253;&#25324;&#26222;&#36890;&#29289;&#20307;&#12289;&#21355;&#26143;&#22270;&#20687;&#21644;&#21307;&#23398;&#22270;&#20687;&#22312;&#20869;&#30340;&#22235;&#20010;&#19981;&#21516;&#39046;&#22495;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#24494;&#35843;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22823;&#36793;&#38469;&#24494;&#35843;&#26041;&#27861;&#65288;LMM-PQS&#65289;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#25903;&#25345;&#22270;&#20687;&#29983;&#25104;&#20266;&#26597;&#35810;&#22270;&#20687;&#65292;&#24182;&#20511;&#37492;&#20154;&#33080;&#35782;&#21035;&#26041;&#27861;&#20013;&#30340;&#22823;&#36793;&#38469;&#26426;&#21046;&#23545;&#29305;&#24449;&#25552;&#21462;&#27169;&#22359;&#36827;&#34892;&#24494;&#35843;&#12290;&#26681;&#25454;&#23454;&#39564;&#32467;&#26524;&#65292;LMM-PQS&#22312;&#27604;&#22522;&#20934;&#27169;&#22411;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#20248;&#21183;&#65292;&#24182;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#24182;&#33021;&#22815;&#36731;&#26494;&#22320;&#23558;&#39044;&#35757;&#32451;&#27169;&#22411;&#36866;&#24212;&#26032;&#30340;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, few-shot learning problems have received a lot of attention. While methods in most previous works were trained and tested on datasets in one single domain, cross-domain few-shot learning is a brand-new branch of few-shot learning problems, where models handle datasets in different domains between training and testing phases. In this paper, to solve the problem that the model is pre-trained (meta-trained) on a single dataset while fine-tuned on datasets in four different domains, including common objects, satellite images, and medical images, we propose a novel large margin fine-tuning method (LMM-PQS), which generates pseudo query images from support images and fine-tunes the feature extraction modules with a large margin mechanism inspired by methods in face recognition. According to the experiment results, LMM-PQS surpasses the baseline models by a significant margin and demonstrates that our approach is robust and can easily adapt pre-trained models to new domains w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#24182;&#30740;&#31350;&#20102;&#21033;&#29992;&#26368;&#22823;&#21644;&#24179;&#22343;&#36317;&#31163;&#30456;&#20851;&#24615;&#36827;&#34892;&#39640;&#32500;&#24230;&#29420;&#31435;&#24615;&#26816;&#27979;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#21345;&#26041;&#26816;&#39564;&#30340;&#31243;&#24207;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#27431;&#27663;&#36317;&#31163;&#21644;&#39640;&#26031;&#26680;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#23454;&#35777;&#34920;&#29616;&#21644;&#24191;&#27867;&#30340;&#24212;&#29992;&#22330;&#26223;&#12290;</title><link>https://arxiv.org/abs/2001.01095</link><description>&lt;p&gt;
&#39640;&#32500;&#24230;&#29420;&#31435;&#24615;&#26816;&#27979;: &#36890;&#36807;&#26368;&#22823;&#21644;&#24179;&#22343;&#36317;&#31163;&#30456;&#20851;&#24615;
&lt;/p&gt;
&lt;p&gt;
High-Dimensional Independence Testing via Maximum and Average Distance Correlations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2001.01095
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#24182;&#30740;&#31350;&#20102;&#21033;&#29992;&#26368;&#22823;&#21644;&#24179;&#22343;&#36317;&#31163;&#30456;&#20851;&#24615;&#36827;&#34892;&#39640;&#32500;&#24230;&#29420;&#31435;&#24615;&#26816;&#27979;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#21345;&#26041;&#26816;&#39564;&#30340;&#31243;&#24207;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#27431;&#27663;&#36317;&#31163;&#21644;&#39640;&#26031;&#26680;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#23454;&#35777;&#34920;&#29616;&#21644;&#24191;&#27867;&#30340;&#24212;&#29992;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#24182;&#30740;&#31350;&#20102;&#21033;&#29992;&#26368;&#22823;&#21644;&#24179;&#22343;&#36317;&#31163;&#30456;&#20851;&#24615;&#36827;&#34892;&#22810;&#20803;&#29420;&#31435;&#24615;&#26816;&#27979;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;&#39640;&#32500;&#29615;&#22659;&#20013;&#34920;&#24449;&#20102;&#23427;&#20204;&#30456;&#23545;&#20110;&#36793;&#38469;&#30456;&#20851;&#32500;&#24230;&#25968;&#37327;&#30340;&#19968;&#33268;&#24615;&#29305;&#24615;&#65292;&#35780;&#20272;&#20102;&#27599;&#20010;&#26816;&#39564;&#32479;&#35745;&#37327;&#30340;&#20248;&#21183;&#65292;&#26816;&#26597;&#20102;&#23427;&#20204;&#21508;&#33258;&#30340;&#38646;&#20998;&#24067;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24555;&#36895;&#21345;&#26041;&#26816;&#39564;&#30340;&#26816;&#27979;&#31243;&#24207;&#12290;&#24471;&#20986;&#30340;&#26816;&#39564;&#26159;&#38750;&#21442;&#25968;&#30340;&#65292;&#24182;&#36866;&#29992;&#20110;&#27431;&#27663;&#36317;&#31163;&#21644;&#39640;&#26031;&#26680;&#20316;&#20026;&#24213;&#23618;&#24230;&#37327;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;&#25152;&#25552;&#20986;&#30340;&#27979;&#35797;&#30340;&#23454;&#38469;&#20351;&#29992;&#24773;&#20917;&#65292;&#25105;&#20204;&#22312;&#21508;&#31181;&#22810;&#20803;&#30456;&#20851;&#22330;&#26223;&#20013;&#35780;&#20272;&#20102;&#26368;&#22823;&#36317;&#31163;&#30456;&#20851;&#24615;&#12289;&#24179;&#22343;&#36317;&#31163;&#30456;&#20851;&#24615;&#21644;&#21407;&#22987;&#36317;&#31163;&#30456;&#20851;&#24615;&#30340;&#23454;&#35777;&#34920;&#29616;&#65292;&#21516;&#26102;&#36827;&#34892;&#20102;&#19968;&#20010;&#30495;&#23454;&#25968;&#25454;&#23454;&#39564;&#65292;&#20197;&#26816;&#27979;&#20154;&#31867;&#34880;&#27974;&#20013;&#19981;&#21516;&#30284;&#30151;&#31867;&#22411;&#21644;&#32957;&#27700;&#24179;&#30340;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces and investigates the utilization of maximum and average distance correlations for multivariate independence testing. We characterize their consistency properties in high-dimensional settings with respect to the number of marginally dependent dimensions, assess the advantages of each test statistic, examine their respective null distributions, and present a fast chi-square-based testing procedure. The resulting tests are non-parametric and applicable to both Euclidean distance and the Gaussian kernel as the underlying metric. To better understand the practical use cases of the proposed tests, we evaluate the empirical performance of the maximum distance correlation, average distance correlation, and the original distance correlation across various multivariate dependence scenarios, as well as conduct a real data experiment to test the presence of various cancer types and peptide levels in human plasma.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#27979;&#35797;&#26102;&#24207;&#25968;&#25454;&#20043;&#38388;&#29420;&#31435;&#24615;&#30340;&#26102;&#24207;&#20381;&#36182;&#32479;&#35745;&#26041;&#27861;&#65292;&#24182;&#33021;&#22815;&#20272;&#35745;&#26368;&#20339;&#20381;&#36182;&#28382;&#21518;&#12290;&#35813;&#26041;&#27861;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#38480;&#21046;&#65292;&#24182;&#19988;&#22312;&#27979;&#35797;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#20043;&#38388;&#30340;&#29420;&#31435;&#24615;&#26102;&#28176;&#36817;&#26377;&#25928;&#21644;&#26222;&#36941;&#19968;&#33268;&#65292;&#24182;&#19988;&#19982;&#22810;&#31181;&#20381;&#36182;&#24230;&#37327;&#26041;&#27861;&#20860;&#23481;&#12290;</title><link>https://arxiv.org/abs/1908.06486</link><description>&lt;p&gt;
&#26102;&#24207;&#25968;&#25454;&#30340;&#29420;&#31435;&#24615;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Independence Testing for Temporal Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/1908.06486
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#27979;&#35797;&#26102;&#24207;&#25968;&#25454;&#20043;&#38388;&#29420;&#31435;&#24615;&#30340;&#26102;&#24207;&#20381;&#36182;&#32479;&#35745;&#26041;&#27861;&#65292;&#24182;&#33021;&#22815;&#20272;&#35745;&#26368;&#20339;&#20381;&#36182;&#28382;&#21518;&#12290;&#35813;&#26041;&#27861;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#38480;&#21046;&#65292;&#24182;&#19988;&#22312;&#27979;&#35797;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#20043;&#38388;&#30340;&#29420;&#31435;&#24615;&#26102;&#28176;&#36817;&#26377;&#25928;&#21644;&#26222;&#36941;&#19968;&#33268;&#65292;&#24182;&#19988;&#19982;&#22810;&#31181;&#20381;&#36182;&#24230;&#37327;&#26041;&#27861;&#20860;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#24207;&#25968;&#25454;&#22312;&#29616;&#20195;&#25968;&#25454;&#31185;&#23398;&#20013;&#36234;&#26469;&#36234;&#24120;&#35265;&#12290;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#26159;&#21028;&#26029;&#20004;&#20010;&#26102;&#38388;&#24207;&#21015;&#26159;&#21542;&#30456;&#20851;&#12290;&#29616;&#26377;&#26041;&#27861;&#24120;&#24120;&#23384;&#22312;&#38480;&#21046;&#65292;&#22914;&#20381;&#36182;&#21442;&#25968;&#20551;&#35774;&#12289;&#20165;&#26816;&#27979;&#32447;&#24615;&#20851;&#32852;&#12289;&#38656;&#35201;&#22810;&#20010;&#27979;&#35797;&#21644;&#20462;&#27491;&#31561;&#12290;&#34429;&#28982;&#26368;&#36817;&#25552;&#20986;&#20102;&#35768;&#22810;&#38750;&#21442;&#25968;&#21644;&#26222;&#36941;&#19968;&#33268;&#30340;&#20381;&#36182;&#24230;&#37327;&#26041;&#27861;&#65292;&#20294;&#30452;&#25509;&#24212;&#29992;&#20110;&#26102;&#24207;&#25968;&#25454;&#21487;&#33021;&#23548;&#33268;p&#20540;&#33192;&#32960;&#21644;&#26080;&#25928;&#30340;&#26816;&#39564;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;&#22522;&#20110;&#22359;&#32622;&#25442;&#30340;&#26102;&#24207;&#20381;&#36182;&#32479;&#35745;&#37327;&#26469;&#27979;&#35797;&#26102;&#24207;&#25968;&#25454;&#20043;&#38388;&#30340;&#29420;&#31435;&#24615;&#12290;&#22312;&#36866;&#24403;&#30340;&#20551;&#35774;&#19979;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#27979;&#35797;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#20043;&#38388;&#30340;&#29420;&#31435;&#24615;&#26102;&#26159;&#28176;&#36817;&#26377;&#25928;&#21644;&#26222;&#36941;&#19968;&#33268;&#30340;&#65292;&#24182;&#19988;&#33021;&#22815;&#20272;&#35745;&#26368;&#22823;&#21270;&#20381;&#36182;&#30340;&#26368;&#20339;&#20381;&#36182;&#28382;&#21518;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#23427;&#19982;&#20016;&#23500;&#30340;&#36317;&#31163;&#21644;&#26680;&#24515;&#20381;&#36182;&#24230;&#37327;&#26041;&#27861;&#20860;&#23481;&#65292;&#28040;&#38500;&#20102;
&lt;/p&gt;
&lt;p&gt;
Temporal data are increasingly prevalent in modern data science. A fundamental question is whether two time-series are related or not. Existing approaches often have limitations, such as relying on parametric assumptions, detecting only linear associations, and requiring multiple tests and corrections. While many non-parametric and universally consistent dependence measures have recently been proposed, directly applying them to temporal data can inflate the p-value and result in invalid test. To address these challenges, this paper introduces the temporal dependence statistic with block permutation to test independence between temporal data. Under proper assumptions, the proposed procedure is asymptotically valid and universally consistent for testing independence between stationary time-series, and capable of estimating the optimal dependence lag that maximizes the dependence. Notably, it is compatible with a rich family of distance and kernel based dependence measures, eliminates the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#26680;Fisher-Rao&#27969;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#21333;&#20301;&#26102;&#38388;&#20869;&#20174;&#38750;&#24402;&#19968;&#21270;&#30446;&#26631;&#23494;&#24230;&#25110;&#36125;&#21494;&#26031;&#21518;&#39564;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#26041;&#27861;&#20351;&#29992;&#20102;&#22343;&#22330;ODE&#21644;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#65292;&#26080;&#38656;&#26799;&#24230;&#65292;&#21482;&#38656;&#35201;&#33021;&#22815;&#20174;&#21442;&#32771;&#23494;&#24230;&#20013;&#37319;&#26679;&#24182;&#35745;&#31639;&#30446;&#26631;&#23545;&#21442;&#32771;&#23494;&#24230;&#30340;&#27604;&#29575;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;&#20960;&#20309;&#28151;&#21512;&#30340;&#36335;&#24452;&#19978;&#27839;&#36895;&#24230;&#22330;&#36816;&#36755;&#26679;&#26412;&#65292;&#24452;&#21521;&#36755;&#36816;&#26679;&#26412;&#12290;&#26041;&#27861;&#36890;&#36807;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#27714;&#35299;&#27850;&#26494;&#26041;&#31243;&#65292;&#20351;&#27850;&#26494;&#26041;&#31243;&#30340;&#27714;&#35299;&#21464;&#24471;&#21487;&#34892;&#65292;&#24182;&#23558;&#20854;&#31163;&#25955;&#21270;&#20026;&#26377;&#38480;&#26679;&#26412;&#30340;&#22343;&#22330;ODE&#65292;&#20316;&#20026;&#23454;&#29616;&#31616;&#21333;&#30340;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#12290;&#21516;&#26102;&#65292;&#36825;&#31181;&#26041;&#27861;&#20063;&#21487;&#20197;&#20174;&#31163;&#25955;&#26102;&#38388;&#30340;&#35282;&#24230;&#25512;&#23548;&#20986;&#22343;&#22330;ODE&#65292;&#20316;&#20026;&#33945;&#26480;-&#23433;&#26222;&#23572;&#26041;&#31243;&#36830;&#32493;&#32447;&#24615;&#21270;&#30340;&#26497;&#38480;&#12290;</title><link>http://arxiv.org/abs/2401.03892</link><description>&lt;p&gt;
&#20197;&#26680;Fisher-Rao&#27969;&#36827;&#34892;&#21333;&#20301;&#26102;&#38388;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Sampling in Unit Time with Kernel Fisher-Rao Flow. (arXiv:2401.03892v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03892
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#26680;Fisher-Rao&#27969;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#21333;&#20301;&#26102;&#38388;&#20869;&#20174;&#38750;&#24402;&#19968;&#21270;&#30446;&#26631;&#23494;&#24230;&#25110;&#36125;&#21494;&#26031;&#21518;&#39564;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#26041;&#27861;&#20351;&#29992;&#20102;&#22343;&#22330;ODE&#21644;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#65292;&#26080;&#38656;&#26799;&#24230;&#65292;&#21482;&#38656;&#35201;&#33021;&#22815;&#20174;&#21442;&#32771;&#23494;&#24230;&#20013;&#37319;&#26679;&#24182;&#35745;&#31639;&#30446;&#26631;&#23545;&#21442;&#32771;&#23494;&#24230;&#30340;&#27604;&#29575;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;&#20960;&#20309;&#28151;&#21512;&#30340;&#36335;&#24452;&#19978;&#27839;&#36895;&#24230;&#22330;&#36816;&#36755;&#26679;&#26412;&#65292;&#24452;&#21521;&#36755;&#36816;&#26679;&#26412;&#12290;&#26041;&#27861;&#36890;&#36807;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#27714;&#35299;&#27850;&#26494;&#26041;&#31243;&#65292;&#20351;&#27850;&#26494;&#26041;&#31243;&#30340;&#27714;&#35299;&#21464;&#24471;&#21487;&#34892;&#65292;&#24182;&#23558;&#20854;&#31163;&#25955;&#21270;&#20026;&#26377;&#38480;&#26679;&#26412;&#30340;&#22343;&#22330;ODE&#65292;&#20316;&#20026;&#23454;&#29616;&#31616;&#21333;&#30340;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#12290;&#21516;&#26102;&#65292;&#36825;&#31181;&#26041;&#27861;&#20063;&#21487;&#20197;&#20174;&#31163;&#25955;&#26102;&#38388;&#30340;&#35282;&#24230;&#25512;&#23548;&#20986;&#22343;&#22330;ODE&#65292;&#20316;&#20026;&#33945;&#26480;-&#23433;&#26222;&#23572;&#26041;&#31243;&#36830;&#32493;&#32447;&#24615;&#21270;&#30340;&#26497;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#22343;&#22330;ODE&#21644;&#30456;&#24212;&#30340;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#65292;&#29992;&#20110;&#20174;&#38750;&#24402;&#19968;&#21270;&#30340;&#30446;&#26631;&#23494;&#24230;&#25110;&#36125;&#21494;&#26031;&#21518;&#39564;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#26080;&#38656;&#26799;&#24230;&#65292;&#21487;&#20197;&#38381;&#21512;&#24418;&#24335;&#33719;&#24471;&#65292;&#24182;&#19988;&#21482;&#38656;&#35201;&#33021;&#22815;&#20174;&#21442;&#32771;&#23494;&#24230;&#20013;&#37319;&#26679;&#24182;&#35745;&#31639;&#65288;&#38750;&#24402;&#19968;&#21270;&#30340;&#65289;&#30446;&#26631;&#23545;&#21442;&#32771;&#23494;&#24230;&#30340;&#27604;&#29575;&#12290;&#36890;&#36807;&#27714;&#35299;&#36816;&#36755;&#26679;&#26412;&#27839;&#20004;&#20010;&#23494;&#24230;&#30340;&#20960;&#20309;&#28151;&#21512;&#30340;&#36895;&#24230;&#22330;&#30340;&#27850;&#26494;&#26041;&#31243;&#26469;&#33719;&#24471;&#22343;&#22330;ODE&#65292;&#36825;&#26159;&#19968;&#31181;&#29305;&#23450;&#30340;Fisher-Rao&#26799;&#24230;&#27969;&#30340;&#36335;&#24452;&#12290;&#25105;&#20204;&#37319;&#29992;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26041;&#27861;&#26469;&#33719;&#24471;&#36895;&#24230;&#22330;&#30340;&#27850;&#26494;&#26041;&#31243;&#65292;&#36825;&#20351;&#24471;&#27850;&#26494;&#26041;&#31243;&#21487;&#22788;&#29702;&#65292;&#24182;&#20351;&#25105;&#20204;&#33021;&#22815;&#31163;&#25955;&#21270;&#26377;&#38480;&#26679;&#26412;&#30340;&#32467;&#26524;&#22343;&#22330;ODE&#65292;&#24418;&#25104;&#19968;&#20010;&#31616;&#21333;&#30340;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#12290;&#22343;&#22330;ODE&#36824;&#21487;&#20197;&#36890;&#36807;&#31163;&#25955;&#26102;&#38388;&#35270;&#35282;&#20174;&#33945;&#26480;-&#23433;&#26222;&#23572;&#26041;&#31243;&#30340;&#36830;&#32493;&#32447;&#24615;&#21270;&#30340;&#26497;&#38480;&#20013;&#25512;&#23548;&#20986;&#26469;&#65292;&#36825;&#22312;&#19968;&#20010;&#24050;&#30693;&#30340;&#26694;&#26550;&#20869;&#36827;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new mean-field ODE and corresponding interacting particle systems for sampling from an unnormalized target density or Bayesian posterior. The interacting particle systems are gradient-free, available in closed form, and only require the ability to sample from the reference density and compute the (unnormalized) target-to-reference density ratio. The mean-field ODE is obtained by solving a Poisson equation for a velocity field that transports samples along the geometric mixture of the two densities, which is the path of a particular Fisher-Rao gradient flow. We employ a reproducing kernel Hilbert space ansatz for the velocity field, which makes the Poisson equation tractable and enables us to discretize the resulting mean-field ODE over finite samples, as a simple interacting particle system. The mean-field ODE can be additionally be derived from a discrete-time perspective as the limit of successive linearizations of the Monge-Amp\`ere equations within a framework known 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#25968;&#25454;&#22810;&#26679;&#24615;&#27010;&#24565;&#26469;&#32479;&#19968;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#22522;&#20110;&#29256;&#26412;&#31354;&#38388;&#12289;&#27491;&#21017;&#21270;&#20248;&#21270;&#21644;&#21518;&#39564;&#37319;&#26679;&#30340;&#31639;&#27861;&#22312;&#26631;&#20934;&#20551;&#35774;&#19979;&#36798;&#21040;&#20102;&#21487;&#27604;&#30340;&#26679;&#26412;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2401.03301</link><description>&lt;p&gt;
&#22312;&#26679;&#26412;&#39640;&#25928;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#65306;&#25968;&#25454;&#22810;&#26679;&#24615;&#12289;&#21518;&#39564;&#37319;&#26679;&#65292;&#20197;&#21450;&#26356;&#22810;
&lt;/p&gt;
&lt;p&gt;
On Sample-Efficient Offline Reinforcement Learning: Data Diversity, Posterior Sampling, and Beyond. (arXiv:2401.03301v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03301
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#25968;&#25454;&#22810;&#26679;&#24615;&#27010;&#24565;&#26469;&#32479;&#19968;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#22522;&#20110;&#29256;&#26412;&#31354;&#38388;&#12289;&#27491;&#21017;&#21270;&#20248;&#21270;&#21644;&#21518;&#39564;&#37319;&#26679;&#30340;&#31639;&#27861;&#22312;&#26631;&#20934;&#20551;&#35774;&#19979;&#36798;&#21040;&#20102;&#21487;&#27604;&#30340;&#26679;&#26412;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35797;&#22270;&#29702;&#35299;&#20160;&#20040;&#20419;&#36827;&#20102;&#23545;&#20110;&#24207;&#36125;&#21494;&#26031;&#20915;&#31574;&#30340;&#21382;&#21490;&#25968;&#25454;&#38598;&#36827;&#34892;&#26679;&#26412;&#39640;&#25928;&#23398;&#20064;&#65292;&#36825;&#20010;&#38382;&#39064;&#36890;&#24120;&#34987;&#31216;&#20026;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#20110;&#22312;&#21033;&#29992;&#65288;&#20540;&#65289;&#20989;&#25968;&#36924;&#36817;&#30340;&#21516;&#26102;&#20139;&#21463;&#26679;&#26412;&#25928;&#29575;&#30340;&#31639;&#27861;&#24863;&#20852;&#36259;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#20010;&#21253;&#25324;&#31163;&#32447;RL&#20013;&#35206;&#30422;&#24230;&#37327;&#30340;&#20808;&#21069;&#27010;&#24565;&#30340;&#25968;&#25454;&#22810;&#26679;&#24615;&#27010;&#24565;&#26469;&#35299;&#20915;&#36825;&#20123;&#22522;&#26412;&#38382;&#39064;&#65292;&#24182;&#19988;&#21033;&#29992;&#36825;&#20010;&#27010;&#24565;&#23558;&#22522;&#20110;&#29256;&#26412;&#31354;&#38388;&#65288;VS&#65289;&#12289;&#27491;&#21017;&#21270;&#20248;&#21270;&#65288;RO&#65289;&#21644;&#21518;&#39564;&#37319;&#26679;&#65288;PS&#65289;&#30340;&#19977;&#20010;&#19981;&#21516;&#31867;&#21035;&#30340;&#31163;&#32447;RL&#31639;&#27861;&#36827;&#34892;&#32479;&#19968;&#12290;&#25105;&#20204;&#22312;&#26631;&#20934;&#20551;&#35774;&#19979;&#35777;&#26126;&#65292;&#22522;&#20110;VS&#12289;&#22522;&#20110;RO&#21644;&#22522;&#20110;PS&#30340;&#31639;&#27861;&#36798;&#21040;&#20102;\emph{&#21487;&#27604;}&#30340;&#26679;&#26412;&#25928;&#29575;&#65292;&#36825;&#24674;&#22797;&#20102;&#22312;&#26377;&#38480;&#21644;&#32447;&#24615;&#27169;&#22411;&#31867;&#21035;&#19979;&#30340;&#26368;&#20248;&#24615;&#30340;&#26631;&#20934;&#20551;&#35774;&#30340;&#36793;&#30028;&#12290;&#36825;&#20010;&#32467;&#26524;&#20196;&#20154;&#24778;&#35766;&#65292;&#22240;&#20026;&#20043;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#36825;&#20123;&#31639;&#27861;&#19981;&#20855;&#26377;&#26377;&#21033;&#24615;&#30340;&#26679;&#26412;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We seek to understand what facilitates sample-efficient learning from historical datasets for sequential decision-making, a problem that is popularly known as offline reinforcement learning (RL). Further, we are interested in algorithms that enjoy sample efficiency while leveraging (value) function approximation. In this paper, we address these fundamental questions by (i) proposing a notion of data diversity that subsumes the previous notions of coverage measures in offline RL and (ii) using this notion to {unify} three distinct classes of offline RL algorithms based on version spaces (VS), regularized optimization (RO), and posterior sampling (PS). We establish that VS-based, RO-based, and PS-based algorithms, under standard assumptions, achieve \emph{comparable} sample efficiency, which recovers the state-of-the-art sub-optimality bounds for finite and linear model classes with the standard assumptions. This result is surprising, given that the prior work suggested an unfavorable sa
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26080;&#30028;&#25439;&#22833;&#30340;&#39640;&#27010;&#29575;PAC-Bayes&#21442;&#32771;&#30028;&#38480;&#65292;&#24182;&#36890;&#36807;&#20248;&#21270;&#33258;&#30001;&#21442;&#25968;&#35299;&#20915;&#20102;&#19968;&#20123;&#24320;&#25918;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#28789;&#27963;&#30340;&#20551;&#35774;&#20135;&#29983;&#20102;&#26032;&#30340;&#24191;&#20041;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2401.01148</link><description>&lt;p&gt;
&#26080;&#30028;&#25439;&#22833;&#30340;PAC-Bayes-Chernoff&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
PAC-Bayes-Chernoff bounds for unbounded losses. (arXiv:2401.01148v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01148
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26080;&#30028;&#25439;&#22833;&#30340;&#39640;&#27010;&#29575;PAC-Bayes&#21442;&#32771;&#30028;&#38480;&#65292;&#24182;&#36890;&#36807;&#20248;&#21270;&#33258;&#30001;&#21442;&#25968;&#35299;&#20915;&#20102;&#19968;&#20123;&#24320;&#25918;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#28789;&#27963;&#30340;&#20551;&#35774;&#20135;&#29983;&#20102;&#26032;&#30340;&#24191;&#20041;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#26080;&#30028;&#25439;&#22833;&#30340;&#39640;&#27010;&#29575;PAC-Bayes&#21442;&#32771;&#30028;&#38480;&#12290;&#36825;&#20010;&#32467;&#26524;&#21487;&#20197;&#29702;&#35299;&#20026;Chernoff&#30028;&#38480;&#30340;PAC-Bayes&#29256;&#26412;&#12290;&#35777;&#26126;&#25216;&#24039;&#20381;&#36182;&#20110;&#36890;&#36807;Cram&#233;r&#21464;&#25442;&#23545;&#25439;&#22833;&#36827;&#34892;&#32479;&#19968;&#36793;&#30028;&#30340;&#23614;&#37096;&#38543;&#26426;&#21464;&#37327;&#12290;&#25105;&#20204;&#24378;&#35843;&#20102;&#25105;&#20204;&#20027;&#35201;&#32467;&#26524;&#30340;&#20004;&#20010;&#24212;&#29992;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#30028;&#38480;&#35299;&#20915;&#20102;&#35768;&#22810;PAC-Bayes&#30028;&#38480;&#19978;&#30340;&#33258;&#30001;&#21442;&#25968;&#20248;&#21270;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#22312;&#25439;&#22833;&#20989;&#25968;&#19978;&#36827;&#34892;&#28789;&#27963;&#30340;&#20551;&#35774;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#24191;&#20041;&#20102;&#20043;&#21069;&#30340;&#30028;&#38480;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#26368;&#23567;&#21270;&#26469;&#33719;&#24471;&#31867;&#20284;Gibbs&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new high-probability PAC-Bayes oracle bound for unbounded losses. This result can be understood as a PAC-Bayes version of the Chernoff bound. The proof technique relies on uniformly bounding the tail of certain random variable based on the Cram\'er transform of the loss. We highlight two applications of our main result. First, we show that our bound solves the open problem of optimizing the free parameter on many PAC-Bayes bounds. Finally, we show that our approach allows working with flexible assumptions on the loss function, resulting in novel bounds that generalize previous ones and can be minimized to obtain Gibbs-like posteriors.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#20248;&#21270;&#22312;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#19978;&#23450;&#20041;&#30340;&#38750;&#32447;&#24615;&#27867;&#20989;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#35757;&#32451;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#12289;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#26368;&#23567;&#21270;&#21644;&#26680;&#26031;&#22374;&#24046;&#24322;&#26368;&#23567;&#21270;&#38382;&#39064;&#12290;&#31639;&#27861;&#22522;&#20110;&#22343;&#22330;&#27424;&#38459;&#23612;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#30340;&#26032;&#39062;&#26102;&#31354;&#31163;&#25955;&#21270;&#65292;&#20855;&#26377;&#24555;&#36895;&#28151;&#21512;&#20445;&#35777;&#65292;&#24182;&#19988;&#22312;&#24635;&#21464;&#21270;&#36317;&#31163;&#19979;&#20840;&#23616;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2312.16360</link><description>&lt;p&gt;
&#22343;&#22330;&#27424;&#38459;&#23612;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#21450;&#20854;&#26102;&#31354;&#31163;&#25955;&#21270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Mean-field underdamped Langevin dynamics and its spacetime discretization. (arXiv:2312.16360v3 [stat.CO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.16360
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#20248;&#21270;&#22312;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#19978;&#23450;&#20041;&#30340;&#38750;&#32447;&#24615;&#27867;&#20989;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#35757;&#32451;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#12289;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#26368;&#23567;&#21270;&#21644;&#26680;&#26031;&#22374;&#24046;&#24322;&#26368;&#23567;&#21270;&#38382;&#39064;&#12290;&#31639;&#27861;&#22522;&#20110;&#22343;&#22330;&#27424;&#38459;&#23612;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#30340;&#26032;&#39062;&#26102;&#31354;&#31163;&#25955;&#21270;&#65292;&#20855;&#26377;&#24555;&#36895;&#28151;&#21512;&#20445;&#35777;&#65292;&#24182;&#19988;&#22312;&#24635;&#21464;&#21270;&#36317;&#31163;&#19979;&#20840;&#23616;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;N&#31890;&#23376;&#27424;&#38459;&#23612;&#26391;&#20043;&#19975;&#31639;&#27861;&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#20248;&#21270;&#22312;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#19978;&#23450;&#20041;&#30340;&#19968;&#31867;&#38750;&#32447;&#24615;&#27867;&#20989;&#12290;&#36825;&#31181;&#20844;&#24335;&#30340;&#38382;&#39064;&#31034;&#20363;&#21253;&#25324;&#35757;&#32451;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#12289;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#26368;&#23567;&#21270;&#21644;&#26680;&#26031;&#22374;&#24046;&#24322;&#26368;&#23567;&#21270;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22522;&#20110;&#22343;&#22330;&#27424;&#38459;&#23612;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#30340;&#26032;&#39062;&#26102;&#31354;&#31163;&#25955;&#21270;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#24555;&#36895;&#28151;&#21512;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#24635;&#21464;&#21270;&#36317;&#31163;&#19979;&#20840;&#23616;&#25910;&#25947;&#65292;&#22635;&#34917;&#20102;&#21160;&#21147;&#23398;&#19982;&#23454;&#38469;&#23454;&#26045;&#20043;&#38388;&#30340;&#29702;&#35770;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new method called the N-particle underdamped Langevin algorithm for optimizing a special class of non-linear functionals defined over the space of probability measures. Examples of problems with this formulation include training mean-field neural networks, maximum mean discrepancy minimization and kernel Stein discrepancy minimization. Our algorithm is based on a novel spacetime discretization of the mean-field underdamped Langevin dynamics, for which we provide a new, fast mixing guarantee. In addition, we demonstrate that our algorithm converges globally in total variation distance, bridging the theoretical gap between the dynamics and its practical implementation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26641;&#32467;&#26500;&#19978;&#21033;&#29992;Wasserstein&#36317;&#31163;&#36827;&#34892;&#31616;&#21270;&#34920;&#31034;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;SimCLR&#21644;&#36127;TWD&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#26469;&#20272;&#35745;&#31616;&#21270;&#34920;&#31034;&#65292;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#25214;&#21040;&#20102;&#31283;&#23450;&#30340;&#35757;&#32451;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2310.10143</link><description>&lt;p&gt;
&#29992;Wasserstein&#36317;&#31163;&#36827;&#34892;&#31616;&#21270;&#34920;&#31034;&#23398;&#20064;&#30340;&#23454;&#35777;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
An Empirical Study of Simplicial Representation Learning with Wasserstein Distance. (arXiv:2310.10143v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10143
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26641;&#32467;&#26500;&#19978;&#21033;&#29992;Wasserstein&#36317;&#31163;&#36827;&#34892;&#31616;&#21270;&#34920;&#31034;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;SimCLR&#21644;&#36127;TWD&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#26469;&#20272;&#35745;&#31616;&#21270;&#34920;&#31034;&#65292;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#25214;&#21040;&#20102;&#31283;&#23450;&#30340;&#35757;&#32451;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#26641;&#32467;&#26500;&#19978;&#21033;&#29992;1-Wasserstein&#36317;&#31163;&#36827;&#34892;&#31616;&#21270;&#34920;&#31034;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#26641;- Wasserstein&#36317;&#31163;(TWD)&#23450;&#20041;&#20026;&#20004;&#20010;&#26641;&#23884;&#20837;&#21521;&#37327;&#20043;&#38388;&#30340;L1&#36317;&#31163;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31181;&#22522;&#20110;SimCLR&#21644;&#36127;TWD&#20316;&#20026;&#30456;&#20284;&#24230;&#24230;&#37327;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#26469;&#20272;&#35745;&#31616;&#21270;&#34920;&#31034;&#12290;&#22312;SimCLR&#20013;&#65292;&#36890;&#24120;&#20351;&#29992;&#19982;&#23454;&#21521;&#37327;&#23884;&#20837;&#30340;&#20313;&#24358;&#30456;&#20284;&#24230;&#65292;&#20294;&#26159;&#23578;&#26410;&#23545;&#21033;&#29992;L1&#36317;&#31163;&#19982;&#31616;&#21270;&#23884;&#20837;&#36827;&#34892;&#28145;&#20837;&#30740;&#31350;&#12290;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#26159;&#35757;&#32451;L1&#36317;&#31163;&#22312;&#25968;&#20540;&#19978;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#24182;&#19988;&#24448;&#24448;&#20250;&#20135;&#29983;&#19981;&#20196;&#20154;&#28385;&#24847;&#30340;&#32467;&#26524;&#65292;&#27010;&#29575;&#27169;&#22411;&#30340;&#36873;&#25321;&#20063;&#26377;&#24456;&#22810;&#12290;&#22240;&#27492;&#65292;&#26412;&#30740;&#31350;&#20174;&#23454;&#35777;&#35282;&#24230;&#25506;&#31350;&#20102;&#29992;TWD&#20248;&#21270;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#31574;&#30053;&#65292;&#24182;&#25214;&#21040;&#20102;&#31283;&#23450;&#30340;&#35757;&#32451;&#36807;&#31243;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#20004;&#31181;&#31867;&#22411;TWD&#30340;&#32452;&#21512;&#65288;&#24635; ...
&lt;/p&gt;
&lt;p&gt;
In this paper, we delve into the problem of simplicial representation learning utilizing the 1-Wasserstein distance on a tree structure (a.k.a., Tree-Wasserstein distance (TWD)), where TWD is defined as the L1 distance between two tree-embedded vectors. Specifically, we consider a framework for simplicial representation estimation employing a self-supervised learning approach based on SimCLR with a negative TWD as a similarity measure. In SimCLR, the cosine similarity with real-vector embeddings is often utilized; however, it has not been well studied utilizing L1-based measures with simplicial embeddings. A key challenge is that training the L1 distance is numerically challenging and often yields unsatisfactory outcomes, and there are numerous choices for probability models. Thus, this study empirically investigates a strategy for optimizing self-supervised learning with TWD and find a stable training procedure. More specifically, we evaluate the combination of two types of TWD (total
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#25351;&#25968;&#26426;&#21046;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#24182;&#25552;&#20986;&#20102;Metropolis-Hastings&#31639;&#27861;&#26469;&#20811;&#26381;&#25351;&#25968;&#25628;&#32034;&#31354;&#38388;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#19968;&#23450;&#36793;&#30028;&#26465;&#20214;&#19979;&#33021;&#22815;&#23454;&#29616;&#24378;&#27169;&#22411;&#24674;&#22797;&#24615;&#36136;&#65292;&#24182;&#20855;&#26377;&#22810;&#39033;&#24335;&#28151;&#21512;&#26102;&#38388;&#21644;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2310.07852</link><description>&lt;p&gt;
&#20851;&#20110;&#36890;&#36807;&#25351;&#25968;&#26426;&#21046;&#36827;&#34892;&#39640;&#32500;&#31169;&#26377;&#27169;&#22411;&#36873;&#25321;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Computational Complexity of Private High-dimensional Model Selection via the Exponential Mechanism. (arXiv:2310.07852v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07852
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#25351;&#25968;&#26426;&#21046;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#24182;&#25552;&#20986;&#20102;Metropolis-Hastings&#31639;&#27861;&#26469;&#20811;&#26381;&#25351;&#25968;&#25628;&#32034;&#31354;&#38388;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#19968;&#23450;&#36793;&#30028;&#26465;&#20214;&#19979;&#33021;&#22815;&#23454;&#29616;&#24378;&#27169;&#22411;&#24674;&#22797;&#24615;&#36136;&#65292;&#24182;&#20855;&#26377;&#22810;&#39033;&#24335;&#28151;&#21512;&#26102;&#38388;&#21644;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24046;&#20998;&#38544;&#31169;&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#39640;&#32500;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#24046;&#20998;&#38544;&#31169;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#30340;&#38382;&#39064;&#65292;&#24182;&#30740;&#31350;&#20102;&#20854;&#25928;&#29992;&#20445;&#35777;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#24191;&#20026;&#20154;&#30693;&#30340;&#25351;&#25968;&#26426;&#21046;&#26469;&#36873;&#25321;&#26368;&#20339;&#27169;&#22411;&#65292;&#24182;&#22312;&#19968;&#23450;&#36793;&#30028;&#26465;&#20214;&#19979;&#65292;&#24314;&#31435;&#20102;&#20854;&#24378;&#27169;&#22411;&#24674;&#22797;&#24615;&#36136;&#12290;&#28982;&#32780;&#65292;&#25351;&#25968;&#26426;&#21046;&#30340;&#25351;&#25968;&#25628;&#32034;&#31354;&#38388;&#23548;&#33268;&#20102;&#20005;&#37325;&#30340;&#35745;&#31639;&#29942;&#39048;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Metropolis-Hastings&#31639;&#27861;&#26469;&#36827;&#34892;&#37319;&#26679;&#27493;&#39588;&#65292;&#24182;&#22312;&#38382;&#39064;&#21442;&#25968;$n$&#12289;$p$&#21644;$s$&#20013;&#24314;&#31435;&#20102;&#20854;&#21040;&#31283;&#24577;&#20998;&#24067;&#30340;&#22810;&#39033;&#24335;&#28151;&#21512;&#26102;&#38388;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21033;&#29992;&#20854;&#28151;&#21512;&#24615;&#36136;&#24314;&#31435;&#20102;Metropolis-Hastings&#38543;&#26426;&#34892;&#36208;&#30340;&#26368;&#32456;&#20272;&#35745;&#30340;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#24615;&#36136;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#19968;&#20123;&#35828;&#26126;&#24615;&#27169;&#25311;&#65292;&#21360;&#35777;&#20102;&#25105;&#20204;&#20027;&#35201;&#32467;&#26524;&#30340;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of model selection in a high-dimensional sparse linear regression model under the differential privacy framework. In particular, we consider the problem of differentially private best subset selection and study its utility guarantee. We adopt the well-known exponential mechanism for selecting the best model, and under a certain margin condition, we establish its strong model recovery property. However, the exponential search space of the exponential mechanism poses a serious computational bottleneck. To overcome this challenge, we propose a Metropolis-Hastings algorithm for the sampling step and establish its polynomial mixing time to its stationary distribution in the problem parameters $n,p$, and $s$. Furthermore, we also establish approximate differential privacy for the final estimates of the Metropolis-Hastings random walk using its mixing property. Finally, we also perform some illustrative simulations that echo the theoretical findings of our main results
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28508;&#22312;&#25552;&#31034;Transformer&#27169;&#22411;&#65292;&#29992;&#20110;&#35299;&#20915;&#20998;&#23376;&#35774;&#35745;&#20013;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#35813;&#27169;&#22411;&#21253;&#25324;&#28508;&#22312;&#21521;&#37327;&#12289;&#20998;&#23376;&#29983;&#25104;&#27169;&#22411;&#21644;&#24615;&#36136;&#39044;&#27979;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#29616;&#26377;&#20998;&#23376;&#36827;&#34892;&#35757;&#32451;&#21518;&#36827;&#34892;&#27169;&#22411;&#20998;&#24067;&#30340;&#36880;&#28176;&#36716;&#31227;&#12290;</title><link>http://arxiv.org/abs/2310.03253</link><description>&lt;p&gt;
&#28508;&#22312;&#25552;&#31034;Transformer&#27169;&#22411;&#22312;&#20998;&#23376;&#35774;&#35745;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Molecule Design by Latent Prompt Transformer. (arXiv:2310.03253v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03253
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28508;&#22312;&#25552;&#31034;Transformer&#27169;&#22411;&#65292;&#29992;&#20110;&#35299;&#20915;&#20998;&#23376;&#35774;&#35745;&#20013;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#35813;&#27169;&#22411;&#21253;&#25324;&#28508;&#22312;&#21521;&#37327;&#12289;&#20998;&#23376;&#29983;&#25104;&#27169;&#22411;&#21644;&#24615;&#36136;&#39044;&#27979;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#29616;&#26377;&#20998;&#23376;&#36827;&#34892;&#35757;&#32451;&#21518;&#36827;&#34892;&#27169;&#22411;&#20998;&#24067;&#30340;&#36880;&#28176;&#36716;&#31227;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#20998;&#23376;&#35774;&#35745;&#31561;&#20855;&#26377;&#25361;&#25112;&#24615;&#20248;&#21270;&#38382;&#39064;&#30340;&#28508;&#22312;&#25552;&#31034;Transformer&#27169;&#22411;&#65292;&#20854;&#20013;&#30446;&#26631;&#26159;&#25214;&#21040;&#20855;&#26377;&#30446;&#26631;&#21270;&#23398;&#25110;&#29983;&#29289;&#24615;&#36136;&#26368;&#20248;&#20540;&#30340;&#20998;&#23376;&#65292;&#35813;&#20540;&#21487;&#20197;&#30001;&#29616;&#26377;&#36719;&#20214;&#35745;&#31639;&#24471;&#20986;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#27169;&#22411;&#21253;&#25324;&#19977;&#20010;&#32452;&#20214;&#65306;&#65288;1&#65289;&#28508;&#22312;&#21521;&#37327;&#65292;&#20854;&#20808;&#39564;&#20998;&#24067;&#30001;&#39640;&#26031;&#30333;&#22122;&#22768;&#21521;&#37327;&#30340;Unet&#21464;&#25442;&#24314;&#27169;&#12290;&#65288;2&#65289;&#20998;&#23376;&#29983;&#25104;&#27169;&#22411;&#65292;&#22312;&#65288;1&#65289;&#20013;&#32473;&#23450;&#28508;&#22312;&#21521;&#37327;&#30340;&#26465;&#20214;&#19979;&#29983;&#25104;&#22522;&#20110;&#23383;&#31526;&#20018;&#30340;&#20998;&#23376;&#34920;&#31034;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#20197;&#65288;1&#65289;&#20013;&#30340;&#28508;&#22312;&#21521;&#37327;&#20316;&#20026;&#25552;&#31034;&#30340;&#22240;&#26524;Transformer&#27169;&#22411;&#12290;&#65288;3&#65289;&#24615;&#36136;&#39044;&#27979;&#27169;&#22411;&#65292;&#26681;&#25454;&#65288;1&#65289;&#20013;&#30340;&#28508;&#22312;&#21521;&#37327;&#36827;&#34892;&#38750;&#32447;&#24615;&#22238;&#24402;&#39044;&#27979;&#20998;&#23376;&#30340;&#30446;&#26631;&#24615;&#36136;&#20540;&#12290;&#25105;&#20204;&#31216;&#35813;&#25552;&#20986;&#30340;&#27169;&#22411;&#20026;&#28508;&#22312;&#25552;&#31034;Transformer&#27169;&#22411;&#12290;&#22312;&#23545;&#29616;&#26377;&#20998;&#23376;&#21450;&#20854;&#24615;&#36136;&#20540;&#36827;&#34892;&#21021;&#27493;&#35757;&#32451;&#21518;&#65292;&#25105;&#20204;&#36880;&#28176;&#36716;&#31227;&#27169;&#22411;&#20998;&#24067;&#30340;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a latent prompt Transformer model for solving challenging optimization problems such as molecule design, where the goal is to find molecules with optimal values of a target chemical or biological property that can be computed by an existing software. Our proposed model consists of three components. (1) A latent vector whose prior distribution is modeled by a Unet transformation of a Gaussian white noise vector. (2) A molecule generation model that generates the string-based representation of molecule conditional on the latent vector in (1). We adopt the causal Transformer model that takes the latent vector in (1) as prompt. (3) A property prediction model that predicts the value of the target property of a molecule based on a non-linear regression on the latent vector in (1). We call the proposed model the latent prompt Transformer model. After initial training of the model on existing molecules and their property values, we then gradually shift the model distributi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33021;&#37327;&#23548;&#21521;&#30340;&#26041;&#27861;&#29992;&#20110;&#36817;&#20284;&#35745;&#31639;&#20219;&#24847;OT&#25104;&#26412;&#20989;&#25968;&#30340;&#36830;&#32493;&#29109;OT&#24052;&#27663;&#20013;&#24515;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#20248;&#36234;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#33021;&#19982;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#65288;EBMs&#65289;&#23398;&#20064;&#36807;&#31243;&#26080;&#32541;&#36830;&#25509;&#12290;</title><link>http://arxiv.org/abs/2310.01105</link><description>&lt;p&gt;
&#22522;&#20110;&#33021;&#37327;&#23548;&#21521;&#30340;&#36830;&#32493;&#29109;&#24052;&#27663;&#20013;&#24515;&#20272;&#35745;&#26041;&#27861;&#21450;&#20854;&#22312;&#19968;&#33324;&#25104;&#26412;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Energy-Guided Continuous Entropic Barycenter Estimation for General Costs. (arXiv:2310.01105v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01105
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33021;&#37327;&#23548;&#21521;&#30340;&#26041;&#27861;&#29992;&#20110;&#36817;&#20284;&#35745;&#31639;&#20219;&#24847;OT&#25104;&#26412;&#20989;&#25968;&#30340;&#36830;&#32493;&#29109;OT&#24052;&#27663;&#20013;&#24515;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#20248;&#36234;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#33021;&#19982;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#65288;EBMs&#65289;&#23398;&#20064;&#36807;&#31243;&#26080;&#32541;&#36830;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20248;&#21270;&#36755;&#36816;&#65288;OT&#65289;&#24052;&#27663;&#20013;&#24515;&#26159;&#19968;&#31181;&#22312;&#25429;&#25417;&#27010;&#29575;&#20998;&#24067;&#20960;&#20309;&#29305;&#24615;&#30340;&#21516;&#26102;&#23545;&#20854;&#36827;&#34892;&#24179;&#22343;&#30340;&#25968;&#23398;&#26041;&#27861;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#35745;&#31639;&#20219;&#24847;OT&#25104;&#26412;&#20989;&#25968;&#30340;&#36830;&#32493;&#29109;OT&#24052;&#27663;&#20013;&#24515;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#26368;&#36817;&#22312;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#20013;&#21463;&#21040;&#20851;&#27880;&#30340;&#22522;&#20110;&#24369;OT&#30340;&#36830;&#32493;&#29109;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#30340;&#23545;&#20598;&#37325;&#26500;&#12290;&#38500;&#20102;&#21019;&#26032;&#24615;&#20043;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36824;&#20855;&#26377;&#20197;&#19979;&#33509;&#24178;&#20248;&#21183;&#29305;&#28857;&#65306;&#65288;i&#65289;&#25105;&#20204;&#24314;&#31435;&#20102;&#23545;&#24674;&#22797;&#35299;&#30340;&#36136;&#37327;&#30028;&#38480;&#65307;&#65288;ii&#65289;&#35813;&#26041;&#27861;&#19982;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#65288;EBMs&#65289;&#23398;&#20064;&#36807;&#31243;&#26080;&#32541;&#36830;&#25509;&#65292;&#21487;&#20197;&#20351;&#29992;&#32463;&#36807;&#33391;&#22909;&#35843;&#25972;&#30340;&#31639;&#27861;&#35299;&#20915;&#24863;&#20852;&#36259;&#30340;&#38382;&#39064;&#65307;&#65288;iii&#65289;&#23427;&#25552;&#20379;&#20102;&#19968;&#31181;&#30452;&#35266;&#30340;&#20248;&#21270;&#26041;&#26696;&#65292;&#36991;&#20813;&#20351;&#29992;&#26497;&#23567;-&#26497;&#22823;&#12289;&#24378;&#21270;&#31561;&#22797;&#26434;&#25216;&#24039;&#12290;&#20026;&#20102;&#39564;&#35777;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;s
&lt;/p&gt;
&lt;p&gt;
Optimal transport (OT) barycenters are a mathematically grounded way of averaging probability distributions while capturing their geometric properties. In short, the barycenter task is to take the average of a collection of probability distributions w.r.t. given OT discrepancies. We propose a novel algorithm for approximating the continuous Entropic OT (EOT) barycenter for arbitrary OT cost functions. Our approach is built upon the dual reformulation of the EOT problem based on weak OT, which has recently gained the attention of the ML community. Beyond its novelty, our method enjoys several advantageous properties: (i) we establish quality bounds for the recovered solution; (ii) this approach seemlessly interconnects with the Energy-Based Models (EBMs) learning procedure enabling the use of well-tuned algorithms for the problem of interest; (iii) it provides an intuitive optimization scheme avoiding min-max, reinforce and other intricate technical tricks. For validation, we consider s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22686;&#24378;&#38543;&#26426;&#24179;&#28369;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#30740;&#31350;&#38543;&#26426;&#24179;&#28369;&#24341;&#20837;&#30340;&#26041;&#24046;&#19982;&#20998;&#31867;&#22120;&#30340;Lipschitz&#24120;&#25968;&#21644;&#36793;&#30028;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20197;&#21450;&#37319;&#29992;&#21333;&#32431;&#24418;&#25237;&#24433;&#25216;&#26415;&#26469;&#22686;&#21152;&#35748;&#35777;&#40065;&#26834;&#21322;&#24452;&#12290;</title><link>http://arxiv.org/abs/2309.16883</link><description>&lt;p&gt;
&#22686;&#24378;&#38543;&#26426;&#24179;&#28369;&#30340;Lipschitz-&#26041;&#24046;-&#36793;&#30028;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
The Lipschitz-Variance-Margin Tradeoff for Enhanced Randomized Smoothing. (arXiv:2309.16883v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16883
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22686;&#24378;&#38543;&#26426;&#24179;&#28369;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#30740;&#31350;&#38543;&#26426;&#24179;&#28369;&#24341;&#20837;&#30340;&#26041;&#24046;&#19982;&#20998;&#31867;&#22120;&#30340;Lipschitz&#24120;&#25968;&#21644;&#36793;&#30028;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20197;&#21450;&#37319;&#29992;&#21333;&#32431;&#24418;&#25237;&#24433;&#25216;&#26415;&#26469;&#22686;&#21152;&#35748;&#35777;&#40065;&#26834;&#21322;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38754;&#23545;&#22122;&#22768;&#36755;&#20837;&#21644;&#23545;&#25239;&#24615;&#25915;&#20987;&#26102;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#23454;&#38469;&#24212;&#29992;&#21463;&#21040;&#20854;&#19981;&#31283;&#23450;&#30340;&#39044;&#27979;&#30340;&#38459;&#30861;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#35748;&#35777;&#21322;&#24452;&#26159;&#27169;&#22411;&#40065;&#26834;&#24615;&#30340;&#20851;&#38190;&#25351;&#26631;&#12290;&#28982;&#32780;&#65292;&#22914;&#20309;&#35774;&#35745;&#19968;&#20010;&#20855;&#26377;&#36275;&#22815;&#35748;&#35777;&#21322;&#24452;&#30340;&#39640;&#25928;&#20998;&#31867;&#22120;&#21602;&#65311;&#38543;&#26426;&#24179;&#28369;&#36890;&#36807;&#22312;&#36755;&#20837;&#20013;&#27880;&#20837;&#22122;&#22768;&#26469;&#33719;&#24471;&#24179;&#28369;&#19988;&#26356;&#40065;&#26834;&#30340;&#20998;&#31867;&#22120;&#30340;&#26694;&#26550;&#25552;&#20379;&#20102;&#26377;&#24076;&#26395;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#26412;&#25991;&#39318;&#20808;&#23637;&#31034;&#20102;&#38543;&#26426;&#24179;&#28369;&#24341;&#20837;&#30340;&#26041;&#24046;&#19982;&#20998;&#31867;&#22120;&#30340;&#21478;&#22806;&#20004;&#20010;&#37325;&#35201;&#23646;&#24615;&#65292;&#21363;&#20854;Lipschitz&#24120;&#25968;&#21644;&#36793;&#30028;&#20043;&#38388;&#30340;&#23494;&#20999;&#20851;&#31995;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#24378;&#35843;&#20102;&#22522;&#20998;&#31867;&#22120;&#30340;Lipschitz&#24120;&#25968;&#23545;&#24179;&#28369;&#20998;&#31867;&#22120;&#21644;&#32463;&#39564;&#26041;&#24046;&#30340;&#21452;&#37325;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#22686;&#21152;&#35748;&#35777;&#40065;&#26834;&#21322;&#24452;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#19981;&#21516;&#30340;&#21333;&#32431;&#24418;&#25237;&#24433;&#25216;&#26415;&#65292;&#20197;&#20415;&#36890;&#36807;Bernst&#30340;&#26041;&#24046;-&#36793;&#30028;&#26435;&#34913;&#26469;&#21033;&#29992;&#22522;&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Real-life applications of deep neural networks are hindered by their unsteady predictions when faced with noisy inputs and adversarial attacks. The certified radius is in this context a crucial indicator of the robustness of models. However how to design an efficient classifier with a sufficient certified radius? Randomized smoothing provides a promising framework by relying on noise injection in inputs to obtain a smoothed and more robust classifier. In this paper, we first show that the variance introduced by randomized smoothing closely interacts with two other important properties of the classifier, i.e. its Lipschitz constant and margin. More precisely, our work emphasizes the dual impact of the Lipschitz constant of the base classifier, on both the smoothed classifier and the empirical variance. Moreover, to increase the certified robust radius, we introduce a different simplex projection technique for the base classifier to leverage the variance-margin trade-off thanks to Bernst
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Beta&#25955;&#24230;&#30340;&#28145;&#24230;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#38754;&#37096;&#29305;&#24449;&#25552;&#21462;&#12289;&#25991;&#26723;&#20027;&#39064;&#35782;&#21035;&#21644;&#39640;&#20809;&#35889;&#22270;&#20687;&#26448;&#26009;&#35782;&#21035;&#12290;</title><link>http://arxiv.org/abs/2309.08249</link><description>&lt;p&gt;
&#24102;&#26377;Beta&#25955;&#24230;&#30340;&#28145;&#24230;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
Deep Nonnegative Matrix Factorization with Beta Divergences. (arXiv:2309.08249v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08249
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Beta&#25955;&#24230;&#30340;&#28145;&#24230;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#38754;&#37096;&#29305;&#24449;&#25552;&#21462;&#12289;&#25991;&#26723;&#20027;&#39064;&#35782;&#21035;&#21644;&#39640;&#20809;&#35889;&#22270;&#20687;&#26448;&#26009;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#65288;deep NMF&#65289;&#26368;&#36817;&#25104;&#20026;&#19968;&#31181;&#26377;&#20215;&#20540;&#30340;&#25216;&#26415;&#65292;&#29992;&#20110;&#22312;&#19981;&#21516;&#23610;&#24230;&#19978;&#25552;&#21462;&#22810;&#23618;&#29305;&#24449;&#12290;&#28982;&#32780;&#65292;&#25152;&#26377;&#29616;&#26377;&#30340;&#28145;&#24230;NMF&#27169;&#22411;&#21644;&#31639;&#27861;&#20027;&#35201;&#37117;&#20197;&#26368;&#23567;&#20108;&#20056;&#35823;&#24046;&#20026;&#35780;&#20272;&#26631;&#20934;&#65292;&#36825;&#21487;&#33021;&#19981;&#26159;&#35780;&#20272;&#22810;&#26679;&#21270;&#25968;&#25454;&#38598;&#36817;&#20284;&#36136;&#37327;&#30340;&#26368;&#21512;&#36866;&#25351;&#26631;&#12290;&#20363;&#22914;&#65292;&#24403;&#22788;&#29702;&#38899;&#39057;&#20449;&#21495;&#21644;&#25991;&#26723;&#31561;&#25968;&#25454;&#31867;&#22411;&#26102;&#65292;&#24191;&#27867;&#35748;&#21487;&#30340;&#26159;$\beta$-divergences&#25552;&#20379;&#20102;&#26356;&#36866;&#21512;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;&#26412;&#25991;&#22522;&#20110;$\beta$-divergences&#24320;&#21457;&#20102;&#26032;&#30340;&#28145;&#24230;NMF&#27169;&#22411;&#21644;&#31639;&#27861;&#65292;&#24182;&#23558;&#36825;&#20123;&#25216;&#26415;&#24212;&#29992;&#20110;&#38754;&#37096;&#29305;&#24449;&#25552;&#21462;&#12289;&#25991;&#26723;&#38598;&#21512;&#20013;&#30340;&#20027;&#39064;&#35782;&#21035;&#20197;&#21450;&#39640;&#20809;&#35889;&#22270;&#20687;&#20013;&#26448;&#26009;&#30340;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Nonnegative Matrix Factorization (deep NMF) has recently emerged as a valuable technique for extracting multiple layers of features across different scales. However, all existing deep NMF models and algorithms have primarily centered their evaluation on the least squares error, which may not be the most appropriate metric for assessing the quality of approximations on diverse datasets. For instance, when dealing with data types such as audio signals and documents, it is widely acknowledged that $\beta$-divergences offer a more suitable alternative. In this paper, we develop new models and algorithms for deep NMF using $\beta$-divergences. Subsequently, we apply these techniques to the extraction of facial features, the identification of topics within document collections, and the identification of materials within hyperspectral images.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#31181;&#24050;&#30693;&#30340;UCB&#31867;&#22411;&#26041;&#27861;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#29366;&#24577;&#34920;&#31034;&#65288;PSRs&#65289;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#26032;&#30340;&#22870;&#21169;&#39033;&#26469;&#19978;&#30028;t</title><link>http://arxiv.org/abs/2307.00405</link><description>&lt;p&gt;
&#21487;&#35777;&#26126;&#39640;&#25928;&#30340;UCB&#31867;&#22411;&#31639;&#27861;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#29366;&#24577;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Provably Efficient UCB-type Algorithms For Learning Predictive State Representations. (arXiv:2307.00405v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00405
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#31181;&#24050;&#30693;&#30340;UCB&#31867;&#22411;&#26041;&#27861;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#29366;&#24577;&#34920;&#31034;&#65288;PSRs&#65289;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#26032;&#30340;&#22870;&#21169;&#39033;&#26469;&#19978;&#30028;t
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#33324;&#30340;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#26088;&#22312;&#36890;&#36807;&#22522;&#20110;&#36807;&#21435;&#35266;&#23519;&#21644;&#34892;&#21160;&#30340;&#21382;&#21490;&#26469;&#26368;&#22823;&#21270;&#32047;&#31215;&#22870;&#21169;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22914;&#26524;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#21487;&#20197;&#29992;&#39044;&#27979;&#29366;&#24577;&#34920;&#31034;&#65288;PSRs&#65289;&#24314;&#27169;&#20302;&#31209;&#32467;&#26500;&#65292;&#37027;&#20040;&#23427;&#26159;&#21487;&#32479;&#35745;&#23398;&#20064;&#30340;&#12290;&#23613;&#31649;&#26377;&#36825;&#20123;&#36827;&#23637;&#65292;&#20294;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#38656;&#35201;&#20351;&#29992;&#39044;&#20808;&#35774;&#35745;&#22909;&#30340;&#27493;&#39588;&#25110;&#32773;&#26159;&#35745;&#31639;&#25928;&#29575;&#20302;&#19979;&#30340;&#25110;&#32773;&#26159;&#19981;&#21487;&#35745;&#31639;&#30340;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#19978;&#38480;&#32622;&#20449;&#21306;&#38388;&#65288;UCB&#65289;&#26041;&#27861;&#22312;&#36172;&#21338;&#26426;&#21644;MDPs&#20013;&#34987;&#25104;&#21151;&#22320;&#20316;&#20026;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#26041;&#27861;&#65292;&#20294;&#23545;PSR&#36825;&#31181;&#26356;&#20855;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#36824;&#27809;&#26377;&#36827;&#34892;&#30740;&#31350;&#65292;&#36825;&#26159;&#30001;&#20110;&#22312;&#36825;&#31181;&#26356;&#20855;&#25361;&#25112;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#20048;&#35266;&#22411;&#22870;&#21169;&#30340;&#35774;&#35745;&#21313;&#20998;&#22256;&#38590;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;PSRs&#30340;&#31532;&#19968;&#31181;&#24050;&#30693;&#30340;UCB&#31867;&#22411;&#26041;&#27861;&#65292;&#20854;&#20013;&#21253;&#21547;&#20102;&#19968;&#20010;&#26032;&#30340;&#22870;&#21169;&#39033;&#26469;&#19978;&#30028;t
&lt;/p&gt;
&lt;p&gt;
The general sequential decision-making problem, which includes Markov decision processes (MDPs) and partially observable MDPs (POMDPs) as special cases, aims at maximizing a cumulative reward by making a sequence of decisions based on a history of observations and actions over time. Recent studies have shown that the sequential decision-making problem is statistically learnable if it admits a low-rank structure modeled by predictive state representations (PSRs). Despite these advancements, existing approaches typically involve oracles or steps that are not computationally efficient. On the other hand, the upper confidence bound (UCB) based approaches, which have served successfully as computationally efficient methods in bandits and MDPs, have not been investigated for more general PSRs, due to the difficulty of optimistic bonus design in these more challenging settings. This paper proposes the first known UCB-type approach for PSRs, featuring a novel bonus term that upper bounds the t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#31454;&#20105;&#29615;&#22659;&#19979;&#30340;&#34892;&#20026;&#65292;&#21457;&#29616;&#25552;&#39640;&#25968;&#25454;&#34920;&#31034;&#36136;&#37327;&#21487;&#33021;&#20250;&#23548;&#33268;&#20379;&#24212;&#21830;&#25972;&#20307;&#39044;&#27979;&#20934;&#30830;&#24615;&#38477;&#20302;&#65292;&#20174;&#32780;&#38477;&#20302;&#31038;&#20250;&#31119;&#21033;&#12290;</title><link>http://arxiv.org/abs/2306.14670</link><description>&lt;p&gt;
&#31454;&#20105;&#29615;&#22659;&#19979;&#36125;&#21494;&#26031;&#39118;&#38505;&#30340;&#25552;&#39640;&#21487;&#33021;&#23548;&#33268;&#31038;&#20250;&#31119;&#21033;&#30340;&#38477;&#20302;
&lt;/p&gt;
&lt;p&gt;
Improved Bayes Risk Can Yield Reduced Social Welfare Under Competition. (arXiv:2306.14670v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14670
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#31454;&#20105;&#29615;&#22659;&#19979;&#30340;&#34892;&#20026;&#65292;&#21457;&#29616;&#25552;&#39640;&#25968;&#25454;&#34920;&#31034;&#36136;&#37327;&#21487;&#33021;&#20250;&#23548;&#33268;&#20379;&#24212;&#21830;&#25972;&#20307;&#39044;&#27979;&#20934;&#30830;&#24615;&#38477;&#20302;&#65292;&#20174;&#32780;&#38477;&#20302;&#31038;&#20250;&#31119;&#21033;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#35268;&#27169;&#30340;&#22686;&#38271;&#65292;&#32553;&#25918;&#23450;&#24459;&#31561;&#36235;&#21183;&#39044;&#35745;&#20250;&#23548;&#33268;&#39044;&#27979;&#20934;&#30830;&#24615;&#30340;&#25345;&#32493;&#25913;&#36827;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#36235;&#21183;&#21482;&#32771;&#34385;&#20102;&#21333;&#20010;&#27169;&#22411;&#20379;&#24212;&#21830;&#30340;&#35270;&#35282;&#65292;&#32780;&#23454;&#38469;&#19978;&#20379;&#24212;&#21830;&#20043;&#38388;&#24120;&#24120;&#31454;&#20105;&#29992;&#25143;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;&#31454;&#20105;&#21487;&#20197;&#20174;&#26681;&#26412;&#19978;&#25913;&#21464;&#36825;&#20123;&#32553;&#25918;&#36235;&#21183;&#30340;&#34892;&#20026;&#65292;&#29978;&#33267;&#21487;&#33021;&#36896;&#25104;&#25972;&#20307;&#39044;&#27979;&#20934;&#30830;&#24615;&#38543;&#30528;&#35268;&#27169;&#30340;&#22686;&#22823;&#32780;&#38750;&#21333;&#35843;&#25110;&#38477;&#20302;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#19968;&#20010;&#20998;&#31867;&#20219;&#21153;&#30340;&#31454;&#20105;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;&#25968;&#25454;&#34920;&#31034;&#20316;&#20026;&#30740;&#31350;&#35268;&#27169;&#22686;&#21152;&#30340;&#24433;&#21709;&#30340;&#38236;&#22836;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;&#19968;&#23478;&#24066;&#22330;&#19978;&#65292;&#25913;&#21892;&#25968;&#25454;&#34920;&#31034;&#36136;&#37327;&#65288;&#25353;&#36125;&#21494;&#26031;&#39118;&#38505;&#35745;&#37327;&#65289;&#21487;&#33021;&#20250;&#38477;&#20302;&#31454;&#20105;&#27169;&#22411;&#20379;&#24212;&#21830;&#30340;&#25972;&#20307;&#39044;&#27979;&#20934;&#30830;&#24615;&#65288;&#21363;&#31038;&#20250;&#31119;&#21033;&#65289;&#12290;&#25105;&#20204;&#30340;&#20363;&#23376;&#28085;&#30422;&#20102;&#31616;&#21333;&#35774;&#32622;&#20013;&#30340;&#23553;&#38381;&#24335;&#20844;&#24335;&#21040;&#39044;&#35757;&#32451;&#30340; CIFAR-10 &#27169;&#25311;&#12290;
&lt;/p&gt;
&lt;p&gt;
As the scale of machine learning models increases, trends such as scaling laws anticipate consistent downstream improvements in predictive accuracy. However, these trends take the perspective of a single model-provider in isolation, while in reality providers often compete with each other for users. In this work, we demonstrate that competition can fundamentally alter the behavior of these scaling trends, even causing overall predictive accuracy across users to be non-monotonic or decreasing with scale. We define a model of competition for classification tasks, and use data representations as a lens for studying the impact of increases in scale. We find many settings where improving data representation quality (as measured by Bayes risk) decreases the overall predictive accuracy across users (i.e., social welfare) for a marketplace of competing model-providers. Our examples range from closed-form formulas in simple settings to simulations with pretrained representations on CIFAR-10. At
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312; mini-batch &#20013;&#26174;&#24335;&#22320;&#23398;&#20064;&#35823;&#24046;&#30340;&#24207;&#21015;&#30456;&#20851;&#24615;&#65292;&#26469;&#25552;&#39640;&#28145;&#24230;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;</title><link>http://arxiv.org/abs/2305.17028</link><description>&lt;p&gt;
&#28145;&#24230;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#26356;&#22909;Batch&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Better Batch for Deep Probabilistic Time Series Forecasting. (arXiv:2305.17028v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17028
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312; mini-batch &#20013;&#26174;&#24335;&#22320;&#23398;&#20064;&#35823;&#24046;&#30340;&#24207;&#21015;&#30456;&#20851;&#24615;&#65292;&#26469;&#25552;&#39640;&#28145;&#24230;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#22240;&#20854;&#33021;&#22815;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#32780;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#29616;&#26377;&#27169;&#22411;&#36807;&#20110;&#31616;&#21333;&#21270;&#38382;&#39064;&#65292;&#20551;&#35774;&#35823;&#24046;&#36807;&#31243;&#26159;&#19982;&#26102;&#38388;&#26080;&#20851;&#30340;&#65292;&#20174;&#32780;&#24573;&#30053;&#20102;&#35823;&#24046;&#36807;&#31243;&#20013;&#30340;&#24207;&#21015;&#30456;&#20851;&#24615;&#12290;&#36825;&#21487;&#33021;&#20250;&#38477;&#20302;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#65292;&#20351;&#36825;&#20123;&#27169;&#22411;&#23545;&#20915;&#31574;&#24615;&#20219;&#21153;&#30340;&#26377;&#25928;&#24615;&#20943;&#24369;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#23558;&#35823;&#24046;&#33258;&#30456;&#20851;&#24615;&#32435;&#20837;&#32771;&#34385;&#65292;&#20197;&#22686;&#24378;&#27010;&#29575;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#26500;&#36896;&#19968;&#20010;mini-batch&#65292;&#20316;&#20026;$D$&#20010;&#36830;&#32493;&#26102;&#38388;&#24207;&#21015;&#27573;&#36827;&#34892;&#27169;&#22411;&#35757;&#32451;&#65292;&#24182;&#26174;&#24335;&#22320;&#23398;&#20064;&#19968;&#20010;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#35206;&#30422;&#20102;&#30456;&#37051;&#26102;&#38388;&#27493;&#20043;&#38388;&#30340;&#35823;&#24046;&#30456;&#20851;&#24615;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#21487;&#29992;&#20110;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#21644;&#22686;&#24378;&#19981;&#30830;&#23450;&#24615;&#30340;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep probabilistic time series forecasting has gained significant attention due to its ability to provide valuable uncertainty quantification for decision-making tasks. However, many existing models oversimplify the problem by assuming the error process is time-independent, thereby overlooking the serial correlation in the error process. This oversight can potentially diminish the accuracy of the forecasts, rendering these models less effective for decision-making purposes. To overcome this limitation, we propose an innovative training method that incorporates error autocorrelation to enhance the accuracy of probabilistic forecasting. Our method involves constructing a mini-batch as a collection of $D$ consecutive time series segments for model training and explicitly learning a covariance matrix over each mini-batch that encodes the error correlation among adjacent time steps. The resulting covariance matrix can be used to improve prediction accuracy and enhance uncertainty quantifica
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#23454;&#20102;&#24403;Transformer&#22788;&#29702;&#19968;&#31995;&#21015;token&#26102;&#65292;&#20986;&#29616;&#8220;&#39046;&#23548;&#32773;&#8221;&#30340;&#32463;&#39564;&#35266;&#23519;&#65292;&#21363;&#38543;&#30528;&#26102;&#38388;&#36235;&#20110;&#26080;&#31351;&#22823;&#65292;&#20195;&#34920;token&#30340;&#31890;&#23376;&#20250;&#32858;&#38598;&#22312;&#29305;&#23450;&#30340;&#26497;&#38480;&#23545;&#35937;&#38468;&#36817;&#65292;&#36825;&#21462;&#20915;&#20110;&#20215;&#20540;&#30697;&#38453;&#30340;&#35889;&#12290;</title><link>http://arxiv.org/abs/2305.05465</link><description>&lt;p&gt;
&#33258;&#27880;&#24847;&#21147;&#21160;&#24577;&#20013;&#30340;&#32858;&#31867;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
The emergence of clusters in self-attention dynamics. (arXiv:2305.05465v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05465
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#23454;&#20102;&#24403;Transformer&#22788;&#29702;&#19968;&#31995;&#21015;token&#26102;&#65292;&#20986;&#29616;&#8220;&#39046;&#23548;&#32773;&#8221;&#30340;&#32463;&#39564;&#35266;&#23519;&#65292;&#21363;&#38543;&#30528;&#26102;&#38388;&#36235;&#20110;&#26080;&#31351;&#22823;&#65292;&#20195;&#34920;token&#30340;&#31890;&#23376;&#20250;&#32858;&#38598;&#22312;&#29305;&#23450;&#30340;&#26497;&#38480;&#23545;&#35937;&#38468;&#36817;&#65292;&#36825;&#21462;&#20915;&#20110;&#20215;&#20540;&#30697;&#38453;&#30340;&#35889;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;Transformer&#35270;&#20026;&#30456;&#20114;&#20316;&#29992;&#30340;&#31890;&#23376;&#31995;&#32479;&#65292;&#24403;&#26435;&#37325;&#19981;&#38543;&#26102;&#38388;&#21464;&#21270;&#26102;&#65292;&#26412;&#25991;&#25551;&#36848;&#20102;&#23398;&#20064;&#34920;&#31034;&#30340;&#20960;&#20309;&#24418;&#29366;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20195;&#34920;token&#30340;&#31890;&#23376;&#38543;&#30528;&#26102;&#38388;&#36235;&#20110;&#26080;&#31351;&#22823;&#32780;&#36235;&#21521;&#20110;&#29305;&#23450;&#30340;&#26497;&#38480;&#23545;&#35937;&#12290;&#20986;&#29616;&#30340;&#26497;&#38480;&#23545;&#35937;&#31867;&#22411;&#21462;&#20915;&#20110;&#20215;&#20540;&#30697;&#38453;&#30340;&#35889;&#12290;&#27492;&#22806;&#65292;&#22312;&#19968;&#32500;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#33258;&#25105;&#27880;&#24847;&#21147;&#30697;&#38453;&#25910;&#25947;&#20110;&#20302;&#31209;&#24067;&#23572;&#30697;&#38453;&#12290;&#36825;&#20123;&#32467;&#26524;&#30340;&#32452;&#21512;&#22312;&#25968;&#23398;&#19978;&#35777;&#23454;&#20102;Vaswani&#31561;&#20154;&#30340;&#32463;&#39564;&#35266;&#23519;&#65292;&#21363;Transformer&#22788;&#29702;&#19968;&#31995;&#21015;token&#26102;&#20250;&#20986;&#29616;&#8220;&#39046;&#23548;&#32773;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;
Viewing Transformers as interacting particle systems, we describe the geometry of learned representations when the weights are not time dependent. We show that particles, representing tokens, tend to cluster toward particular limiting objects as time tends to infinity. The type of limiting object that emerges depends on the spectrum of the value matrix. Additionally, in the one-dimensional case we prove that the self-attention matrix converges to a low-rank Boolean matrix. The combination of these results mathematically confirms the empirical observation made by Vaswani et al. \cite{vaswani2017attention} that \emph{leaders} appear in a sequence of tokens when processed by Transformers.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;Kullback-Leibler Maillard Sampling (KL-MS)&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#26377;&#30028;&#22870;&#21169;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#23454;&#29616;KL&#31354;&#38388;&#30340;&#25193;&#23637;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#28176;&#36817;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.14989</link><description>&lt;p&gt;
Kullback-Leibler Maillard&#37319;&#26679;&#22312;&#26377;&#30028;&#22870;&#21169;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Kullback-Leibler Maillard Sampling for Multi-armed Bandits with Bounded Rewards. (arXiv:2304.14989v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14989
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;Kullback-Leibler Maillard Sampling (KL-MS)&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#26377;&#30028;&#22870;&#21169;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#23454;&#29616;KL&#31354;&#38388;&#30340;&#25193;&#23637;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#28176;&#36817;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22870;&#21169;&#20998;&#24067;&#38598;&#20013;&#22312;&#21306;&#38388;$[0,1]$&#20869;&#30340;$K$&#33218;&#25968;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Kullback-Leibler Maillard Sampling (KL-MS)&#30340;&#26032;&#31639;&#27861;&#65292;&#23427;&#26159;Maillard&#37319;&#26679;&#22312;KL&#31354;&#38388;&#30340;&#33258;&#28982;&#25193;&#23637;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;KL-MS&#22312;Bernoulli&#22870;&#21169;&#26102;&#20855;&#26377;&#28176;&#36817;&#26368;&#20248;&#24615;&#33021;&#65292;&#20854;&#26368;&#22351;&#24773;&#20917;&#36951;&#25022;&#24230;&#19978;&#30028;&#20026;$O(\sqrt{\mu^*(1-\mu^*) K T \ln K} + K \ln T)$&#65292;&#20854;&#20013;$\mu^*$&#26159;&#26368;&#20248;&#33218;&#30340;&#26399;&#26395;&#22870;&#21169;&#65292;$T$&#26159;&#26102;&#27573;&#38271;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study $K$-armed bandit problems where the reward distributions of the arms are all supported on the $[0,1]$ interval. It has been a challenge to design regret-efficient randomized exploration algorithms in this setting. Maillard sampling~\cite{maillard13apprentissage}, an attractive alternative to Thompson sampling, has recently been shown to achieve competitive regret guarantees in the sub-Gaussian reward setting~\cite{bian2022maillard} while maintaining closed-form action probabilities, which is useful for offline policy evaluation. In this work, we propose the Kullback-Leibler Maillard Sampling (KL-MS) algorithm, a natural extension of Maillard sampling for achieving KL-style gap-dependent regret bound. We show that KL-MS enjoys the asymptotic optimality when the rewards are Bernoulli and has a worst-case regret bound of the form $O(\sqrt{\mu^*(1-\mu^*) K T \ln K} + K \ln T)$, where $\mu^*$ is the expected reward of the optimal arm, and $T$ is the time horizon length.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22312;&#19981;&#38656;&#35201;&#26356;&#24378;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#21363;&#20351;&#22312;&#21327;&#21464;&#37327;&#26469;&#33258; $L$-&#20122;&#25351;&#25968;&#38543;&#26426;&#21521;&#37327;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;$\ell_1$ -&#24085;&#20271;&#22238;&#24402;&#36827;&#34892;&#32447;&#24615;&#22238;&#24402;&#65292;&#21487;&#20197;&#24471;&#21040;&#19982;&#39640;&#26031;&#38543;&#26426;&#21521;&#37327;&#30456;&#21516;&#65288;&#22312;&#24120;&#25968;&#22240;&#23376;&#19979;&#65289;&#30340;&#35823;&#24046;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2304.11958</link><description>&lt;p&gt;
&#22312; $L$-&#20122;&#25351;&#25968;&#21327;&#21464;&#37327;&#19979;&#30340;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#31995;&#25968;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Estimation of sparse linear regression coefficients under $L$-subexponential covariates. (arXiv:2304.11958v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11958
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22312;&#19981;&#38656;&#35201;&#26356;&#24378;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#21363;&#20351;&#22312;&#21327;&#21464;&#37327;&#26469;&#33258; $L$-&#20122;&#25351;&#25968;&#38543;&#26426;&#21521;&#37327;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;$\ell_1$ -&#24085;&#20271;&#22238;&#24402;&#36827;&#34892;&#32447;&#24615;&#22238;&#24402;&#65292;&#21487;&#20197;&#24471;&#21040;&#19982;&#39640;&#26031;&#38543;&#26426;&#21521;&#37327;&#30456;&#21516;&#65288;&#22312;&#24120;&#25968;&#22240;&#23376;&#19979;&#65289;&#30340;&#35823;&#24046;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21327;&#21464;&#37327;&#26469;&#33258; $L$-&#20122;&#25351;&#25968;&#38543;&#26426;&#21521;&#37327;&#26102;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#22312;&#32447;&#24615;&#22238;&#24402;&#20013;&#20272;&#35745;&#31232;&#30095;&#31995;&#25968;&#30340;&#20219;&#21153;&#65292;&#35813;&#38543;&#26426;&#21521;&#37327;&#23646;&#20110;&#19968;&#31867;&#20855;&#26377;&#27604;&#39640;&#26031;&#38543;&#26426;&#21521;&#37327;&#26356;&#37325;&#30340;&#23614;&#24052;&#30340;&#20998;&#24067;&#12290;&#20197;&#21069;&#30340;&#24037;&#20316;&#36890;&#36807;&#20551;&#35774;&#21327;&#21464;&#37327;&#26469;&#33258; $L$-&#20122;&#25351;&#25968;&#38543;&#26426;&#21521;&#37327;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#24314;&#31435;&#20102;&#31867;&#20284;&#20110;&#23545;&#39640;&#26031;&#38543;&#26426;&#21521;&#37327;&#23548;&#20986;&#30340;&#35823;&#24046;&#30028;&#38480;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#20197;&#21069;&#30340;&#26041;&#27861;&#35201;&#27714;&#26356;&#24378;&#30340;&#26465;&#20214;&#65292;&#20197;&#23548;&#20986;&#19982;&#39640;&#26031;&#38543;&#26426;&#21521;&#37327;&#30456;&#21516;&#30340;&#35823;&#24046;&#30028;&#38480;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22312;&#19981;&#38656;&#35201;&#26356;&#24378;&#30340;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#25552;&#20986;&#20102;&#19982;&#39640;&#26031;&#38543;&#26426;&#21521;&#37327;&#30456;&#21516;&#65288;&#22312;&#24120;&#25968;&#22240;&#23376;&#19979;&#65289;&#65292;&#29978;&#33267;&#24403;&#21327;&#21464;&#37327;&#26469;&#33258; $L$-&#20122;&#25351;&#25968;&#38543;&#26426;&#21521;&#37327;&#26102;&#30340;&#35823;&#24046;&#30028;&#38480;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#21033;&#29992;&#20102; $\ell_1$-&#24085;&#20271;&#22238;&#24402;&#65292;&#35813;&#22238;&#24402;&#22240;&#20854;&#23545;&#37325;&#23614;&#38543;&#26426;&#22122;&#22768;&#30340;&#40065;&#26834;&#24615;&#32780;&#34987;&#35748;&#20026;&#26159;&#37325;&#35201;&#30340;&#65292;&#32780;&#19981;&#26159;&#21327;&#21464;&#37327;&#12290;&#25105;&#20204;&#30456;&#20449;...
&lt;/p&gt;
&lt;p&gt;
We address a task of estimating sparse coefficients in linear regression when the covariates are drawn from an $L$-subexponential random vector, which belongs to a class of distributions having heavier tails than a Gaussian random vector. Prior works have tackled this issue by assuming that the covariates are drawn from an $L$-subexponential random vector and have established error bounds that resemble those derived for Gaussian random vectors. However, these previous methods require stronger conditions to derive error bounds than those employed for Gaussian random vectors. In the present paper, we present an error bound identical to that obtained for Gaussian random vectors, up to constant factors, without requiring stronger conditions, even when the covariates are drawn from an $L$-subexponential random vector. Somewhat interestingly, we utilize an $\ell_1$-penalized Huber regression, that is recognized for its robustness to heavy-tailed random noises, not covariates. We believe that
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25506;&#32034;&#26080;&#30417;&#30563;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#28508;&#22312;&#31354;&#38388;&#26469;&#21457;&#29616;&#25968;&#25454;&#20013;&#26377;&#24847;&#20041;&#30340;&#23646;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26497;&#31471;&#20540;&#22240;&#26524;&#20998;&#31163; (CDEV) &#30340;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#27979;&#35797;&#40120;&#40060;&#36890;&#20449;&#31995;&#32479;&#24182;&#21457;&#29616;&#20854;&#20013;&#23384;&#22312;&#35821;&#27861;&#12290;</title><link>http://arxiv.org/abs/2303.10931</link><description>&lt;p&gt;
&#36890;&#36807;&#28508;&#22312;&#31354;&#38388;&#25506;&#32034;&#21644;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#36924;&#36817;&#26410;&#30693;&#30340;&#36890;&#20449;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Approaching an unknown communication system by latent space exploration and causal inference. (arXiv:2303.10931v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10931
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25506;&#32034;&#26080;&#30417;&#30563;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#28508;&#22312;&#31354;&#38388;&#26469;&#21457;&#29616;&#25968;&#25454;&#20013;&#26377;&#24847;&#20041;&#30340;&#23646;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26497;&#31471;&#20540;&#22240;&#26524;&#20998;&#31163; (CDEV) &#30340;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#27979;&#35797;&#40120;&#40060;&#36890;&#20449;&#31995;&#32479;&#24182;&#21457;&#29616;&#20854;&#20013;&#23384;&#22312;&#35821;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#25506;&#32034;&#26080;&#30417;&#30563;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#28508;&#22312;&#31354;&#38388;&#26469;&#21457;&#29616;&#25968;&#25454;&#20013;&#26377;&#24847;&#20041;&#30340;&#23646;&#24615;&#12290;&#25105;&#20204;&#23558;&#23545;&#21333;&#20010;&#28508;&#22312;&#21464;&#37327;&#30340;&#25805;&#20316;&#19982;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#19968;&#20010;&#31216;&#20026;&#26497;&#31471;&#20540;&#22240;&#26524;&#20998;&#31163; (CDEV) &#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#23545;&#27169;&#22411;&#21487;&#35299;&#37322;&#24615;&#30340;&#27934;&#23519;&#21147;&#12290;&#36890;&#36807;&#27492;&#25216;&#26415;&#65292;&#25105;&#20204;&#21487;&#20197;&#25512;&#26029;&#27169;&#22411;&#23558;&#26410;&#30693;&#25968;&#25454;&#32534;&#30721;&#20026;&#26377;&#24847;&#20041;&#30340;&#23646;&#24615;&#12290;&#25105;&#20204;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#27979;&#35797;&#40120;&#40060;&#30340;&#36890;&#20449;&#31995;&#32479;&#20013;&#23384;&#22312;&#21738;&#20123;&#26377;&#24847;&#20041;&#30340;&#23646;&#24615;&#65292;&#40120;&#40060;&#36890;&#20449;&#26159;&#26368;&#20855;&#26377;&#21560;&#24341;&#21147;&#21644;&#30740;&#31350;&#19981;&#36275;&#30340;&#21160;&#29289;&#36890;&#20449;&#20043;&#19968;&#12290;&#25105;&#20204;&#35757;&#32451;&#20102;&#19968;&#20010;&#32593;&#32476;&#65292;&#35813;&#32593;&#32476;&#24050;&#34987;&#35777;&#26126;&#33021;&#22815;&#23398;&#20064;&#21040;&#26377;&#24847;&#20041;&#30340;&#35821;&#38899;&#34920;&#31034;&#65292;&#24182;&#27979;&#35797;&#26159;&#21542;&#21487;&#20197;&#21033;&#29992;&#36825;&#31181;&#26080;&#30417;&#30563;&#23398;&#20064;&#26469;&#35299;&#26512;&#21478;&#19968;&#20010;&#25105;&#20204;&#27809;&#26377;&#22320;&#38754;&#30495;&#30456;&#30340;&#22768;&#38899;&#36890;&#20449;&#31995;&#32479;&#30340;&#23646;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#25216;&#26415;&#34920;&#26126;&#65292;&#40120;&#40060;&#22312;&#20854;&#22768;&#38899;&#36890;&#20449;&#20013;&#23384;&#22312;&#35821;&#27861;&#65292;&#36825;&#26159;&#20197;&#21069;&#19981;&#30693;&#36947;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a methodology for discovering meaningful properties in data by exploring the latent space of unsupervised deep generative models. We combine manipulation of individual latent variables to extreme values outside the training range with methods inspired by causal inference into an approach we call causal disentanglement with extreme values (CDEV) and show that this approach yields insights for model interpretability. Using this technique, we can infer what properties of unknown data the model encodes as meaningful. We apply the methodology to test what is meaningful in the communication system of sperm whales, one of the most intriguing and understudied animal communication systems. We train a network that has been shown to learn meaningful representations of speech and test whether we can leverage such unsupervised learning to decipher the properties of another vocal communication system for which we have no ground truth. The proposed technique suggests that sperm wh
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#20934;&#31639;&#26415;&#28151;&#21512;&#12289;&#25955;&#24230;&#26368;&#23567;&#21270;&#21644;Bregman&#20449;&#24687;&#30340;&#20840;&#38754;&#20998;&#26512;&#12290;&#36890;&#36807;&#22312;&#23494;&#24230;&#20989;&#25968;&#30340;&#21333;&#35843;&#23884;&#20837;&#19979;&#20351;&#29992;Bregman&#25955;&#24230;&#65292;&#25105;&#20204;&#23558;&#24120;&#35265;&#30340;&#25955;&#24230;&#20989;&#25968;&#19982;&#36864;&#28779;&#36335;&#24452;&#19978;&#30340;&#20013;&#38388;&#23494;&#24230;&#20851;&#32852;&#36215;&#26469;&#12290;</title><link>http://arxiv.org/abs/2209.07481</link><description>&lt;p&gt;
&#20934;&#31639;&#26415;&#28151;&#21512;&#12289;&#25955;&#24230;&#26368;&#23567;&#21270;&#21644;Bregman&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
Quasi-Arithmetic Mixtures, Divergence Minimization, and Bregman Information. (arXiv:2209.07481v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.07481
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#20934;&#31639;&#26415;&#28151;&#21512;&#12289;&#25955;&#24230;&#26368;&#23567;&#21270;&#21644;Bregman&#20449;&#24687;&#30340;&#20840;&#38754;&#20998;&#26512;&#12290;&#36890;&#36807;&#22312;&#23494;&#24230;&#20989;&#25968;&#30340;&#21333;&#35843;&#23884;&#20837;&#19979;&#20351;&#29992;Bregman&#25955;&#24230;&#65292;&#25105;&#20204;&#23558;&#24120;&#35265;&#30340;&#25955;&#24230;&#20989;&#25968;&#19982;&#36864;&#28779;&#36335;&#24452;&#19978;&#30340;&#20013;&#38388;&#23494;&#24230;&#20851;&#32852;&#36215;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#29992;&#20110;&#20174;&#22797;&#26434;&#20998;&#24067;&#20013;&#37319;&#26679;&#21644;&#20272;&#35745;&#24402;&#19968;&#21270;&#24120;&#25968;&#36890;&#24120;&#27169;&#25311;&#27839;&#30528;&#36830;&#25509;&#21487;&#36319;&#36394;&#21021;&#22987;&#20998;&#24067;&#21644;&#30446;&#26631;&#23494;&#24230;&#30340;&#36864;&#28779;&#36335;&#24452;&#30340;&#20013;&#38388;&#20998;&#24067;&#30340;&#26679;&#26412;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#20351;&#29992;&#20934;&#31639;&#26415;&#24179;&#22343;&#26500;&#24314;&#20102;&#36864;&#28779;&#36335;&#24452;&#65292;&#24182;&#35299;&#37322;&#20102;&#30001;&#27492;&#20135;&#29983;&#30340;&#20013;&#38388;&#23494;&#24230;&#26159;&#26368;&#23567;&#21270;&#26399;&#26395;&#25955;&#24230;&#21040;&#31471;&#28857;&#30340;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#23494;&#24230;&#20989;&#25968;&#30340;&#21333;&#35843;&#23884;&#20837;&#19979;&#20351;&#29992;Bregman&#25955;&#24230;&#23545;&#36825;&#20010;&#8220;&#36136;&#24515;&#8221;&#24615;&#36136;&#36827;&#34892;&#20102;&#20840;&#38754;&#20998;&#26512;&#65292;&#20174;&#32780;&#23558;&#24120;&#35265;&#30340;&#25955;&#24230;&#65288;&#22914;Amari&#21644;Renyi&#30340;alpha&#25955;&#24230;&#12289;&#65288;alpha&#65292;beta&#65289;&#25955;&#24230;&#21644;Jensen-Shannon&#25955;&#24230;&#65289;&#19982;&#27839;&#30528;&#36864;&#28779;&#36335;&#24452;&#30340;&#20013;&#38388;&#23494;&#24230;&#20851;&#32852;&#36215;&#26469;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#31361;&#20986;&#20102;&#21442;&#25968;&#21270;&#26063;&#12289;&#20934;&#31639;&#26415;&#24179;&#22343;&#21644;&#25955;&#24230;&#20989;&#25968;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#20351;&#29992;&#20102;Zhang&#30340;rho-tau Bregman&#25955;&#24230;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Markov Chain Monte Carlo methods for sampling from complex distributions and estimating normalization constants often simulate samples from a sequence of intermediate distributions along an annealing path, which bridges between a tractable initial distribution and a target density of interest. Prior work has constructed annealing paths using quasi-arithmetic means, and interpreted the resulting intermediate densities as minimizing an expected divergence to the endpoints. We provide a comprehensive analysis of this 'centroid' property using Bregman divergences under a monotonic embedding of the density function, thereby associating common divergences such as Amari's and Renyi's ${\alpha}$-divergences, ${(\alpha,\beta)}$-divergences, and the Jensen-Shannon divergence with intermediate densities along an annealing path. Our analysis highlights the interplay between parametric families, quasi-arithmetic means, and divergence functions using the rho-tau Bregman divergence framework of Zhang
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#20316;&#20026;&#21442;&#25968;&#20998;&#24067;&#30340;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#39640;&#26031;&#28151;&#21512;&#30340;&#29109;&#36817;&#20284;&#20026;&#21333;&#23792;&#39640;&#26031;&#30340;&#29109;&#20043;&#21644;&#26469;&#35299;&#20915;&#22810;&#23792;&#24615;&#30340;&#38382;&#39064;&#65292;&#24182;&#20174;&#29702;&#35770;&#19978;&#20998;&#26512;&#36817;&#20284;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2202.13059</link><description>&lt;p&gt;
&#29992;&#29109;&#36817;&#20284;&#30340;&#39640;&#26031;&#28151;&#21512;&#21464;&#20998;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Variational Inference with Gaussian Mixture by Entropy Approximation. (arXiv:2202.13059v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.13059
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#20316;&#20026;&#21442;&#25968;&#20998;&#24067;&#30340;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#39640;&#26031;&#28151;&#21512;&#30340;&#29109;&#36817;&#20284;&#20026;&#21333;&#23792;&#39640;&#26031;&#30340;&#29109;&#20043;&#21644;&#26469;&#35299;&#20915;&#22810;&#23792;&#24615;&#30340;&#38382;&#39064;&#65292;&#24182;&#20174;&#29702;&#35770;&#19978;&#20998;&#26512;&#36817;&#20284;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#25512;&#26029;&#26159;&#19968;&#31181;&#29992;&#20110;&#36817;&#20284;&#26080;&#27861;&#22788;&#29702;&#30340;&#21518;&#39564;&#20998;&#24067;&#20197;&#37327;&#21270;&#26426;&#22120;&#23398;&#20064;&#19981;&#30830;&#23450;&#24615;&#30340;&#25216;&#26415;&#12290;&#28982;&#32780;&#65292;&#21333;&#23792;&#30340;&#39640;&#26031;&#20998;&#24067;&#36890;&#24120;&#34987;&#36873;&#25321;&#20316;&#20026;&#21442;&#25968;&#20998;&#24067;&#65292;&#24456;&#38590;&#36924;&#36817;&#22810;&#23792;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#20316;&#20026;&#21442;&#25968;&#20998;&#24067;&#12290;&#20351;&#29992;&#39640;&#26031;&#28151;&#21512;&#36827;&#34892;&#21464;&#20998;&#25512;&#26029;&#30340;&#19968;&#20010;&#20027;&#35201;&#38590;&#28857;&#26159;&#22914;&#20309;&#36817;&#20284;&#39640;&#26031;&#28151;&#21512;&#30340;&#29109;&#12290;&#25105;&#20204;&#23558;&#39640;&#26031;&#28151;&#21512;&#30340;&#29109;&#36817;&#20284;&#20026;&#21333;&#23792;&#39640;&#26031;&#30340;&#29109;&#20043;&#21644;&#65292;&#21487;&#20197;&#36890;&#36807;&#35299;&#26512;&#35745;&#31639;&#24471;&#21040;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#20998;&#26512;&#20102;&#30495;&#23454;&#29109;&#19982;&#36817;&#20284;&#29109;&#20043;&#38388;&#30340;&#36817;&#20284;&#35823;&#24046;&#65292;&#20197;&#20415;&#25581;&#31034;&#25105;&#20204;&#30340;&#36817;&#20284;&#20309;&#26102;&#36215;&#20316;&#29992;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#36817;&#20284;&#35823;&#24046;&#30001;&#39640;&#26031;&#28151;&#21512;&#22343;&#20540;&#20043;&#38388;&#36317;&#31163;&#19982;&#26041;&#24046;&#20043;&#21644;&#30340;&#27604;&#29575;&#25511;&#21046;&#12290;&#27492;&#22806;&#65292;&#24403;&#39640;&#26031;&#28151;&#21512;&#32452;&#20214;&#30340;&#25968;&#37327;&#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#26102;&#65292;&#36817;&#20284;&#35823;&#24046;&#36235;&#36817;&#20110;&#38646;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational inference is a technique for approximating intractable posterior distributions in order to quantify the uncertainty of machine learning. Although the unimodal Gaussian distribution is usually chosen as a parametric distribution, it hardly approximates the multimodality. In this paper, we employ the Gaussian mixture distribution as a parametric distribution. A main difficulty of variational inference with the Gaussian mixture is how to approximate the entropy of the Gaussian mixture. We approximate the entropy of the Gaussian mixture as the sum of the entropy of the unimodal Gaussian, which can be analytically calculated. In addition, we theoretically analyze the approximation error between the true entropy and approximated one in order to reveal when our approximation works well. Specifically, the approximation error is controlled by the ratios of the distances between the means to the sum of the variances of the Gaussian mixture. Furthermore, it converges to zero when the 
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#38750;&#21442;&#25968;&#20202;&#22120;&#21464;&#37327;&#27169;&#22411;&#20013;&#30340;&#32467;&#26500;&#20989;&#25968;&#30340;&#19981;&#31561;&#24335;&#21644;&#31561;&#24335;&#38480;&#21046;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#36866;&#24212;&#26410;&#30693;&#30340;&#24179;&#28369;&#24230;&#21644;&#24037;&#20855;&#24378;&#24230;&#65292;&#24182;&#36798;&#21040;&#20102;&#26368;&#23567;&#20540;&#29575;&#30340;&#33258;&#36866;&#24212;&#26368;&#20248;&#26816;&#39564;&#29575;&#12290;</title><link>http://arxiv.org/abs/2006.09587</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;IV&#27169;&#22411;&#20013;&#30340;&#33258;&#36866;&#24212;&#39640;&#25928;&#20551;&#35774;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Adaptive, Rate-Optimal Hypothesis Testing in Nonparametric IV Models. (arXiv:2006.09587v3 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.09587
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#38750;&#21442;&#25968;&#20202;&#22120;&#21464;&#37327;&#27169;&#22411;&#20013;&#30340;&#32467;&#26500;&#20989;&#25968;&#30340;&#19981;&#31561;&#24335;&#21644;&#31561;&#24335;&#38480;&#21046;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#36866;&#24212;&#26410;&#30693;&#30340;&#24179;&#28369;&#24230;&#21644;&#24037;&#20855;&#24378;&#24230;&#65292;&#24182;&#36798;&#21040;&#20102;&#26368;&#23567;&#20540;&#29575;&#30340;&#33258;&#36866;&#24212;&#26368;&#20248;&#26816;&#39564;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#36866;&#24212;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#38750;&#21442;&#25968;&#20202;&#22120;&#21464;&#37327;&#65288;NPIV&#65289;&#27169;&#22411;&#20013;&#32467;&#26500;&#20989;&#25968;&#30340;&#19981;&#31561;&#24335;&#65288;&#22914;&#21333;&#35843;&#24615;&#12289;&#20984;&#24615;&#65289;&#21644;&#31561;&#24335;&#65288;&#22914;&#21442;&#25968;&#12289;&#21322;&#21442;&#25968;&#65289;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#26816;&#39564;&#32479;&#35745;&#37327;&#22522;&#20110;&#20462;&#25913;&#29256;&#30340;&#30041;&#19968;&#27861;&#26679;&#26412;&#27169;&#25311;&#65292;&#35745;&#31639;&#21463;&#38480;&#21644;&#19981;&#21463;&#38480;&#31579;&#23376;NPIV&#20272;&#35745;&#37327;&#38388;&#30340;&#20108;&#27425;&#36317;&#31163;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#35745;&#31639;&#31616;&#21333;&#12289;&#25968;&#25454;&#39537;&#21160;&#30340;&#31579;&#23376;&#35843;&#21442;&#21644;Bonferroni&#35843;&#25972;&#21345;&#26041;&#20020;&#30028;&#20540;&#30340;&#36873;&#25321;&#12290;&#25105;&#20204;&#30340;&#26816;&#39564;&#36866;&#24212;&#26410;&#30693;&#30340;&#20869;&#29983;&#24615;&#24179;&#28369;&#24230;&#21644;&#24037;&#20855;&#24378;&#24230;&#65292;&#36798;&#21040;&#20102;$L^2$&#26368;&#23567;&#20540;&#29575;&#30340;&#33258;&#36866;&#24212;&#26368;&#20248;&#26816;&#39564;&#29575;&#12290;&#20063;&#23601;&#26159;&#35828;&#65292;&#22312;&#22797;&#21512;&#38646;&#20551;&#35774;&#19979;&#20854;&#31867;&#22411;I&#35823;&#24046;&#30340;&#24635;&#20307;&#21644;&#20854;&#31867;&#22411;II&#35823;&#24046;&#30340;&#24635;&#20307;&#22343;&#19981;&#33021;&#34987;&#20219;&#20309;&#20854;&#20182;NPIV&#27169;&#22411;&#30340;&#20551;&#35774;&#26816;&#39564;&#25152;&#25552;&#39640;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#22522;&#20110;&#25968;&#25454;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new adaptive hypothesis test for inequality (e.g., monotonicity, convexity) and equality (e.g., parametric, semiparametric) restrictions on a structural function in a nonparametric instrumental variables (NPIV) model. Our test statistic is based on a modified leave-one-out sample analog of a quadratic distance between the restricted and unrestricted sieve NPIV estimators. We provide computationally simple, data-driven choices of sieve tuning parameters and Bonferroni adjusted chi-squared critical values. Our test adapts to the unknown smoothness of alternative functions in the presence of unknown degree of endogeneity and unknown strength of the instruments. It attains the adaptive minimax rate of testing in $L^2$.  That is, the sum of its type I error uniformly over the composite null and its type II error uniformly over nonparametric alternative models cannot be improved by any other hypothesis test for NPIV models of unknown regularities. Data-driven confidence sets in 
&lt;/p&gt;</description></item></channel></rss>