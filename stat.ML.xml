<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#20171;&#32461;&#20102;&#22312;&#37327;&#23376;&#20648;&#22791;&#35745;&#31639;&#20013;&#22238;&#22768;&#24577;&#24615;&#36136;&#30340;&#19981;&#21516;&#23618;&#27425;&#65292;&#21253;&#25324;&#38750;&#24179;&#31283;&#24615;ESP&#21644;&#23376;&#31995;&#32479;&#20855;&#26377;ESP&#30340;&#23376;&#31354;&#38388;/&#23376;&#38598;ESP&#12290;&#36827;&#34892;&#20102;&#25968;&#20540;&#28436;&#31034;&#21644;&#35760;&#24518;&#23481;&#37327;&#35745;&#31639;&#20197;&#39564;&#35777;&#36825;&#20123;&#23450;&#20041;&#12290;</title><link>https://arxiv.org/abs/2403.02686</link><description>&lt;p&gt;
&#37327;&#23376;&#20648;&#22791;&#35745;&#31639;&#20013;&#30340;&#22238;&#22768;&#24577;&#24615;&#36136;&#31561;&#32423;
&lt;/p&gt;
&lt;p&gt;
Hierarchy of the echo state property in quantum reservoir computing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02686
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#22312;&#37327;&#23376;&#20648;&#22791;&#35745;&#31639;&#20013;&#22238;&#22768;&#24577;&#24615;&#36136;&#30340;&#19981;&#21516;&#23618;&#27425;&#65292;&#21253;&#25324;&#38750;&#24179;&#31283;&#24615;ESP&#21644;&#23376;&#31995;&#32479;&#20855;&#26377;ESP&#30340;&#23376;&#31354;&#38388;/&#23376;&#38598;ESP&#12290;&#36827;&#34892;&#20102;&#25968;&#20540;&#28436;&#31034;&#21644;&#35760;&#24518;&#23481;&#37327;&#35745;&#31639;&#20197;&#39564;&#35777;&#36825;&#20123;&#23450;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22238;&#22768;&#24577;&#24615;&#36136;&#65288;ESP&#65289;&#20195;&#34920;&#20102;&#20648;&#22791;&#35745;&#31639;&#65288;RC&#65289;&#26694;&#26550;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#27010;&#24565;&#65292;&#36890;&#36807;&#23545;&#21021;&#22987;&#29366;&#24577;&#21644;&#36828;&#26399;&#36755;&#20837;&#19981;&#21152;&#27495;&#35270;&#26469;&#30830;&#20445;&#20648;&#33988;&#32593;&#32476;&#30340;&#20165;&#36755;&#20986;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;ESP&#23450;&#20041;&#24182;&#26410;&#25551;&#36848;&#21487;&#33021;&#28436;&#21464;&#32479;&#35745;&#23646;&#24615;&#30340;&#38750;&#24179;&#31283;&#31995;&#32479;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31867;&#26032;&#30340;ESP&#65306;\textit{&#38750;&#24179;&#31283;ESP}&#65292;&#29992;&#20110;&#28508;&#22312;&#38750;&#24179;&#31283;&#31995;&#32479;&#65292;&#21644;\textit{&#23376;&#31354;&#38388;/&#23376;&#38598;ESP}&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;ESP&#30340;&#23376;&#31995;&#32479;&#30340;&#31995;&#32479;&#12290;&#26681;&#25454;&#36825;&#20123;&#23450;&#20041;&#65292;&#25105;&#20204;&#22312;&#37327;&#23376;&#20648;&#22791;&#35745;&#31639;&#65288;QRC&#65289;&#26694;&#26550;&#20013;&#25968;&#20540;&#28436;&#31034;&#20102;&#38750;&#24179;&#31283;ESP&#19982;&#20856;&#22411;&#21704;&#23494;&#39039;&#21160;&#21147;&#23398;&#21644;&#20351;&#29992;&#38750;&#32447;&#24615;&#33258;&#22238;&#24402;&#31227;&#21160;&#24179;&#22343;&#65288;NARMA&#65289;&#20219;&#21153;&#30340;&#36755;&#20837;&#32534;&#30721;&#26041;&#27861;&#20043;&#38388;&#30340;&#23545;&#24212;&#20851;&#31995;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#35745;&#31639;&#32447;&#24615;/&#38750;&#32447;&#24615;&#35760;&#24518;&#23481;&#37327;&#26469;&#30830;&#35748;&#36825;&#31181;&#23545;&#24212;&#20851;&#31995;&#65292;&#20197;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02686v1 Announce Type: cross  Abstract: The echo state property (ESP) represents a fundamental concept in the reservoir computing (RC) framework that ensures output-only training of reservoir networks by being agnostic to the initial states and far past inputs. However, the traditional definition of ESP does not describe possible non-stationary systems in which statistical properties evolve. To address this issue, we introduce two new categories of ESP: \textit{non-stationary ESP}, designed for potentially non-stationary systems, and \textit{subspace/subset ESP}, designed for systems whose subsystems have ESP. Following the definitions, we numerically demonstrate the correspondence between non-stationary ESP in the quantum reservoir computer (QRC) framework with typical Hamiltonian dynamics and input encoding methods using non-linear autoregressive moving-average (NARMA) tasks. We also confirm the correspondence by computing linear/non-linear memory capacities that quantify 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#20010;&#26631;&#20934;&#36827;&#34892;&#20248;&#21270;&#22120;&#22522;&#20934;&#27979;&#35797;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#27425;&#24207;&#20449;&#24687;&#24182;&#20801;&#35768;&#19981;&#21487;&#27604;&#24615;&#65292;&#36991;&#20813;&#20102;&#32858;&#21512;&#30340;&#32570;&#28857;&#65292;&#21487;&#20197;&#35782;&#21035;&#20135;&#29983;&#20013;&#24515;&#25110;&#31163;&#32676;&#25490;&#24207;&#30340;&#27979;&#35797;&#20989;&#25968;&#65292;&#24182;&#35780;&#20272;&#22522;&#20934;&#27979;&#35797;&#22871;&#20214;&#30340;&#36136;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.16565</link><description>&lt;p&gt;
&#20248;&#21270;&#22120;&#30340;&#37096;&#20998;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
Partial Rankings of Optimizers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16565
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#20010;&#26631;&#20934;&#36827;&#34892;&#20248;&#21270;&#22120;&#22522;&#20934;&#27979;&#35797;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#27425;&#24207;&#20449;&#24687;&#24182;&#20801;&#35768;&#19981;&#21487;&#27604;&#24615;&#65292;&#36991;&#20813;&#20102;&#32858;&#21512;&#30340;&#32570;&#28857;&#65292;&#21487;&#20197;&#35782;&#21035;&#20135;&#29983;&#20013;&#24515;&#25110;&#31163;&#32676;&#25490;&#24207;&#30340;&#27979;&#35797;&#20989;&#25968;&#65292;&#24182;&#35780;&#20272;&#22522;&#20934;&#27979;&#35797;&#22871;&#20214;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26681;&#25454;&#22810;&#20010;&#26631;&#20934;&#22312;&#21508;&#31181;&#27979;&#35797;&#20989;&#25968;&#19978;&#23545;&#20248;&#21270;&#22120;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#30340;&#26694;&#26550;&#12290;&#22522;&#20110;&#26368;&#36817;&#24341;&#20837;&#30340;&#29992;&#20110;&#20559;&#24207;/&#25490;&#24207;&#30340;&#26080;&#38598;&#21512;&#27867;&#20989;&#28145;&#24230;&#20989;&#25968;&#65292;&#23427;&#20805;&#20998;&#21033;&#29992;&#20102;&#27425;&#24207;&#20449;&#24687;&#24182;&#20801;&#35768;&#19981;&#21487;&#27604;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25551;&#36848;&#20102;&#25152;&#26377;&#37096;&#20998;&#39034;&#24207;/&#25490;&#24207;&#30340;&#20998;&#24067;&#65292;&#36991;&#20813;&#20102;&#32858;&#21512;&#30340;&#33261;&#21517;&#26157;&#33879;&#30340;&#32570;&#28857;&#12290;&#36825;&#20801;&#35768;&#35782;&#21035;&#20135;&#29983;&#20248;&#21270;&#22120;&#30340;&#20013;&#24515;&#25110;&#31163;&#32676;&#25490;&#24207;&#30340;&#27979;&#35797;&#20989;&#25968;&#65292;&#24182;&#35780;&#20272;&#22522;&#20934;&#27979;&#35797;&#22871;&#20214;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16565v1 Announce Type: cross  Abstract: We introduce a framework for benchmarking optimizers according to multiple criteria over various test functions. Based on a recently introduced union-free generic depth function for partial orders/rankings, it fully exploits the ordinal information and allows for incomparability. Our method describes the distribution of all partial orders/rankings, avoiding the notorious shortcomings of aggregation. This permits to identify test functions that produce central or outlying rankings of optimizers and to assess the quality of benchmarking suites.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#32452;&#26465;&#20214;&#65292;&#20445;&#35777;&#20102;&#19968;&#31867;&#20272;&#35745;&#31163;&#25955;&#21644;&#36830;&#32493;&#21442;&#25968;&#28151;&#21512;&#30340;&#29305;&#23450;EM&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#20026;&#35299;&#20915;&#28151;&#21512;&#25972;&#25968;&#38750;&#32447;&#24615;&#20248;&#21270;&#38382;&#39064;&#30340;&#36845;&#20195;&#31639;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#25216;&#26415;&#12290;</title><link>https://arxiv.org/abs/2401.17763</link><description>&lt;p&gt;
&#22522;&#20110;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;&#30340;&#26399;&#26395;&#26368;&#22823;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Convergence of Expectation-Maximization Algorithm with Mixed-Integer Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17763
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#32452;&#26465;&#20214;&#65292;&#20445;&#35777;&#20102;&#19968;&#31867;&#20272;&#35745;&#31163;&#25955;&#21644;&#36830;&#32493;&#21442;&#25968;&#28151;&#21512;&#30340;&#29305;&#23450;EM&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#20026;&#35299;&#20915;&#28151;&#21512;&#25972;&#25968;&#38750;&#32447;&#24615;&#20248;&#21270;&#38382;&#39064;&#30340;&#36845;&#20195;&#31639;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26399;&#26395;&#26368;&#22823;&#21270;&#65288;EM&#65289;&#31639;&#27861;&#30340;&#25910;&#25947;&#36890;&#24120;&#38656;&#35201;&#20284;&#28982;&#20989;&#25968;&#23545;&#25152;&#26377;&#26410;&#30693;&#21442;&#25968;&#65288;&#20248;&#21270;&#21464;&#37327;&#65289;&#36830;&#32493;&#12290;&#24403;&#21442;&#25968;&#21253;&#25324;&#31163;&#25955;&#21644;&#36830;&#32493;&#21464;&#37327;&#26102;&#65292;&#36825;&#19968;&#35201;&#27714;&#26080;&#27861;&#28385;&#36275;&#65292;&#23548;&#33268;&#25910;&#25947;&#20998;&#26512;&#38750;&#24120;&#22256;&#38590;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#32452;&#26465;&#20214;&#65292;&#20445;&#35777;&#20102;&#19968;&#31867;&#20272;&#35745;&#31163;&#25955;&#21644;&#36830;&#32493;&#21442;&#25968;&#28151;&#21512;&#30340;&#29305;&#23450;EM&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;&#35299;&#20915;&#28151;&#21512;&#25972;&#25968;&#38750;&#32447;&#24615;&#20248;&#21270;&#38382;&#39064;&#30340;&#36845;&#20195;&#31639;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#25216;&#26415;&#12290;&#20316;&#20026;&#19968;&#20010;&#20855;&#20307;&#30340;&#20363;&#23376;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22522;&#20110;EM&#30340;&#31232;&#30095;&#36125;&#21494;&#26031;&#23398;&#20064;&#31639;&#27861;&#22312;&#20272;&#35745;&#20855;&#26377;&#32852;&#21512;&#31232;&#30095;&#36755;&#20837;&#21644;&#26029;&#32493;&#32570;&#22833;&#35266;&#27979;&#30340;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#29366;&#24577;&#26102;&#30340;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#35777;&#26126;&#20102;[1]&#20013;&#30340;&#31639;&#27861;&#25910;&#25947;&#21040;&#26368;&#22823;&#20284;&#28982;&#20195;&#20215;&#20851;&#20110;&#36830;&#32493;&#20248;&#21270;&#21464;&#37327;&#30340;&#31283;&#23450;&#28857;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
The convergence of expectation-maximization (EM)-based algorithms typically requires continuity of the likelihood function with respect to all the unknown parameters (optimization variables). The requirement is not met when parameters comprise both discrete and continuous variables, making the convergence analysis nontrivial. This paper introduces a set of conditions that ensure the convergence of a specific class of EM algorithms that estimate a mixture of discrete and continuous parameters. Our results offer a new analysis technique for iterative algorithms that solve mixed-integer non-linear optimization problems. As a concrete example, we prove the convergence of the EM-based sparse Bayesian learning algorithm in [1] that estimates the state of a linear dynamical system with jointly sparse inputs and bursty missing observations. Our results establish that the algorithm in [1] converges to the set of stationary points of the maximum likelihood cost with respect to the continuous opt
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#38750;&#20984;&#38543;&#26426;&#26799;&#24230;&#24773;&#20917;&#19979;&#26410;&#35843;&#25972;&#30340;&#24191;&#20041;&#21704;&#23494;&#23572;&#39039;&#33945;&#29305;&#21345;&#32599;&#20013;&#30340;&#21453;&#23556;&#32806;&#21512;&#65292;&#35777;&#26126;&#20102;Wasserstein 1&#36317;&#31163;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#23450;&#37327;&#39640;&#26031;&#38598;&#20013;&#30028;&#38480;&#65292;&#21516;&#26102;&#36824;&#32473;&#20986;&#20102;Wasserstein 2&#36317;&#31163;&#12289;&#24635;&#21464;&#24046;&#21644;&#30456;&#23545;&#29109;&#30340;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.18774</link><description>&lt;p&gt;
&#38750;&#20984;&#38543;&#26426;&#26799;&#24230;&#24773;&#20917;&#19979;&#26410;&#35843;&#25972;&#30340;&#24191;&#20041;&#21704;&#23494;&#23572;&#39039;&#33945;&#29305;&#21345;&#32599;&#20013;&#30340;&#21453;&#23556;&#32806;&#21512;
&lt;/p&gt;
&lt;p&gt;
Reflection coupling for unadjusted generalized Hamiltonian Monte Carlo in the nonconvex stochastic gradient case. (arXiv:2310.18774v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18774
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#38750;&#20984;&#38543;&#26426;&#26799;&#24230;&#24773;&#20917;&#19979;&#26410;&#35843;&#25972;&#30340;&#24191;&#20041;&#21704;&#23494;&#23572;&#39039;&#33945;&#29305;&#21345;&#32599;&#20013;&#30340;&#21453;&#23556;&#32806;&#21512;&#65292;&#35777;&#26126;&#20102;Wasserstein 1&#36317;&#31163;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#23450;&#37327;&#39640;&#26031;&#38598;&#20013;&#30028;&#38480;&#65292;&#21516;&#26102;&#36824;&#32473;&#20986;&#20102;Wasserstein 2&#36317;&#31163;&#12289;&#24635;&#21464;&#24046;&#21644;&#30456;&#23545;&#29109;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21487;&#33021;&#38750;&#20984;&#30340;&#26465;&#20214;&#19979;&#65292;&#24314;&#31435;&#20102;&#20855;&#26377;&#38543;&#26426;&#26799;&#24230;&#30340;&#24191;&#20041;&#21704;&#23494;&#23572;&#39039;&#33945;&#29305;&#21345;&#32599;&#30340;Wasserstein 1&#36317;&#31163;&#30340;&#25910;&#25947;&#24615;&#65292;&#20854;&#20013;&#21253;&#25324;&#21160;&#21147;&#23398;Langevin&#25193;&#25955;&#30340;&#20998;&#35010;&#26041;&#26696;&#31639;&#27861;&#12290;&#20316;&#20026;&#32467;&#26524;&#65292;&#25552;&#20379;&#20102;&#32463;&#39564;&#24179;&#22343;&#20540;&#30340;&#23450;&#37327;&#39640;&#26031;&#38598;&#20013;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#36824;&#32473;&#20986;&#20102;Wasserstein 2&#36317;&#31163;&#12289;&#24635;&#21464;&#24046;&#21644;&#30456;&#23545;&#29109;&#30340;&#25910;&#25947;&#24615;&#65292;&#20197;&#21450;&#25968;&#20540;&#20559;&#24046;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contraction in Wasserstein 1-distance with explicit rates is established for generalized Hamiltonian Monte Carlo with stochastic gradients under possibly nonconvex conditions. The algorithms considered include splitting schemes of kinetic Langevin diffusion. As consequence, quantitative Gaussian concentration bounds are provided for empirical averages. Convergence in Wasserstein 2-distance, total variation and relative entropy are also given, together with numerical bias estimates.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#33258;&#36866;&#24212;Lasso&#21644;&#36716;&#31227;Lasso&#30340;&#29702;&#35770;&#24615;&#36136;&#65292;&#36890;&#36807;&#23545;&#36716;&#31227;Lasso&#30340;&#28176;&#36827;&#24615;&#36136;&#36827;&#34892;&#29702;&#35770;&#30740;&#31350;&#65292;&#20998;&#26512;&#20102;&#23427;&#19982;&#33258;&#36866;&#24212;Lasso&#30340;&#21306;&#21035;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#20004;&#32773;&#30340;&#20248;&#21183;&#36827;&#34892;&#20102;&#34701;&#21512;&#24182;&#34917;&#20607;&#20102;&#20182;&#20204;&#30340;&#24369;&#28857;&#12290;</title><link>http://arxiv.org/abs/2308.15838</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;Lasso&#12289;&#36716;&#31227;Lasso&#21450;&#20854;&#25299;&#23637;&#65306;&#28176;&#36827;&#35270;&#35282;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Adaptive Lasso, Transfer Lasso, and Beyond: An Asymptotic Perspective. (arXiv:2308.15838v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15838
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#33258;&#36866;&#24212;Lasso&#21644;&#36716;&#31227;Lasso&#30340;&#29702;&#35770;&#24615;&#36136;&#65292;&#36890;&#36807;&#23545;&#36716;&#31227;Lasso&#30340;&#28176;&#36827;&#24615;&#36136;&#36827;&#34892;&#29702;&#35770;&#30740;&#31350;&#65292;&#20998;&#26512;&#20102;&#23427;&#19982;&#33258;&#36866;&#24212;Lasso&#30340;&#21306;&#21035;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#20004;&#32773;&#30340;&#20248;&#21183;&#36827;&#34892;&#20102;&#34701;&#21512;&#24182;&#34917;&#20607;&#20102;&#20182;&#20204;&#30340;&#24369;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20840;&#38754;&#25506;&#35752;&#20102;&#33258;&#36866;&#24212;Lasso&#21644;&#36716;&#31227;Lasso&#30340;&#29702;&#35770;&#24615;&#36136;&#12290;&#33258;&#36866;&#24212;Lasso&#26159;&#19968;&#31181;&#25104;&#29087;&#30340;&#26041;&#27861;&#65292;&#37319;&#29992;&#26681;&#25454;&#21021;&#22987;&#20272;&#35745;&#20540;&#36827;&#34892;&#30340;&#27491;&#21017;&#21270;&#65292;&#20855;&#26377;&#28176;&#36827;&#27491;&#24577;&#24615;&#21644;&#21464;&#37327;&#36873;&#25321;&#19968;&#33268;&#24615;&#30340;&#29305;&#28857;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#26368;&#36817;&#25552;&#20986;&#30340;&#36716;&#31227;Lasso&#37319;&#29992;&#26681;&#25454;&#21021;&#22987;&#20272;&#35745;&#20540;&#36827;&#34892;&#30340;&#27491;&#21017;&#21270;&#20943;&#27861;&#65292;&#20855;&#26377;&#20943;&#23569;&#38750;&#28176;&#36827;&#20272;&#35745;&#35823;&#24046;&#30340;&#33021;&#21147;&#12290;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#22240;&#27492;&#20986;&#29616;&#65306;&#37492;&#20110;&#33258;&#36866;&#24212;Lasso&#21644;&#36716;&#31227;Lasso&#22312;&#20351;&#29992;&#21021;&#22987;&#20272;&#35745;&#20540;&#26041;&#38754;&#23384;&#22312;&#30340;&#19981;&#21516;&#26041;&#24335;&#65292;&#36825;&#31181;&#24046;&#24322;&#32473;&#27599;&#31181;&#26041;&#27861;&#24102;&#26469;&#20102;&#20160;&#20040;&#22909;&#22788;&#25110;&#24330;&#31471;&#65311;&#26412;&#25991;&#23545;&#36716;&#31227;Lasso&#30340;&#28176;&#36827;&#24615;&#36136;&#36827;&#34892;&#20102;&#29702;&#35770;&#30740;&#31350;&#65292;&#20174;&#32780;&#38416;&#26126;&#20102;&#23427;&#19982;&#33258;&#36866;&#24212;Lasso&#30340;&#21306;&#21035;&#12290;&#26681;&#25454;&#36825;&#20010;&#20998;&#26512;&#30340;&#32467;&#26524;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#21508;&#33258;&#30340;&#20248;&#21183;&#36827;&#34892;&#20102;&#34701;&#21512;&#24182;&#34917;&#20607;&#20102;&#20182;&#20204;&#30340;&#24369;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a comprehensive exploration of the theoretical properties inherent in the Adaptive Lasso and the Transfer Lasso. The Adaptive Lasso, a well-established method, employs regularization divided by initial estimators and is characterized by asymptotic normality and variable selection consistency. In contrast, the recently proposed Transfer Lasso employs regularization subtracted by initial estimators with the demonstrated capacity to curtail non-asymptotic estimation errors. A pivotal question thus emerges: Given the distinct ways the Adaptive Lasso and the Transfer Lasso employ initial estimators, what benefits or drawbacks does this disparity confer upon each method? This paper conducts a theoretical examination of the asymptotic properties of the Transfer Lasso, thereby elucidating its differentiation from the Adaptive Lasso. Informed by the findings of this analysis, we introduce a novel method, one that amalgamates the strengths and compensates for the weaknesses o
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#24378;&#21270;&#23398;&#20064;&#20013;&#20154;&#31867;&#21453;&#39304;&#26597;&#35810;&#30340;&#26377;&#25928;&#37319;&#26679;&#26041;&#27861;&#65292;&#20197;&#22312;&#26368;&#23569;&#30340;&#20154;&#31867;&#21453;&#39304;&#19979;&#23398;&#20064;&#26368;&#20339;&#31574;&#30053;&#65292;&#24182;&#21487;&#24212;&#29992;&#20110;&#20855;&#26377;&#32447;&#24615;&#21442;&#25968;&#21270;&#21644;&#26410;&#30693;&#36807;&#28193;&#30340;&#20559;&#22909;&#27169;&#22411;&#65292;&#24182;&#24341;&#20837;&#20102;&#22522;&#20110;&#34892;&#21160;&#27604;&#36739;&#21453;&#39304;&#30340;RLHF&#12290;</title><link>http://arxiv.org/abs/2305.18505</link><description>&lt;p&gt;
&#22914;&#20309;&#26377;&#25928;&#22320;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#36827;&#34892;&#20154;&#31867;&#21453;&#39304;&#26597;&#35810;&#65311;
&lt;/p&gt;
&lt;p&gt;
How to Query Human Feedback Efficiently in RL?. (arXiv:2305.18505v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18505
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#24378;&#21270;&#23398;&#20064;&#20013;&#20154;&#31867;&#21453;&#39304;&#26597;&#35810;&#30340;&#26377;&#25928;&#37319;&#26679;&#26041;&#27861;&#65292;&#20197;&#22312;&#26368;&#23569;&#30340;&#20154;&#31867;&#21453;&#39304;&#19979;&#23398;&#20064;&#26368;&#20339;&#31574;&#30053;&#65292;&#24182;&#21487;&#24212;&#29992;&#20110;&#20855;&#26377;&#32447;&#24615;&#21442;&#25968;&#21270;&#21644;&#26410;&#30693;&#36807;&#28193;&#30340;&#20559;&#22909;&#27169;&#22411;&#65292;&#24182;&#24341;&#20837;&#20102;&#22522;&#20110;&#34892;&#21160;&#27604;&#36739;&#21453;&#39304;&#30340;RLHF&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#31867;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;&#65288;RLHF&#65289;&#26159;&#19968;&#31181;&#33539;&#20363;&#65292;&#22312;&#27492;&#33539;&#20363;&#19979;&#65292;RL&#20195;&#29702;&#23398;&#20064;&#20351;&#29992;&#23545;&#36712;&#36857;&#30340;&#25104;&#23545;&#20248;&#20808;&#32423;&#21453;&#39304;&#26469;&#26368;&#20248;&#21270;&#20219;&#21153;&#65292;&#32780;&#19981;&#26159;&#20351;&#29992;&#26126;&#30830;&#30340;&#22870;&#21169;&#20449;&#21495;&#12290;&#23613;&#31649;RLHF&#22312;&#24494;&#35843;&#35821;&#35328;&#27169;&#22411;&#26041;&#38754;&#24050;&#32463;&#21462;&#24471;&#20102;&#23454;&#29992;&#25104;&#21151;&#65292;&#20294;&#29616;&#26377;&#30340;&#23454;&#35777;&#30740;&#31350;&#24182;&#26410;&#35299;&#20915;&#22914;&#20309;&#39640;&#25928;&#37319;&#26679;&#36712;&#36857;&#23545;&#20197;&#26597;&#35810;&#20154;&#31867;&#21453;&#39304;&#30340;&#25361;&#25112;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#37319;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#33719;&#21462;&#25506;&#32034;&#24615;&#36712;&#36857;&#65292;&#22312;&#25910;&#38598;&#20219;&#20309;&#20154;&#31867;&#21453;&#39304;&#20043;&#21069;&#65292;&#20351;&#23398;&#20064;&#38544;&#34255;&#30340;&#22870;&#21169;&#20989;&#25968;&#26356;&#21152;&#20934;&#30830;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#19982;&#29616;&#26377;&#25991;&#29486;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#32447;&#24615;&#21442;&#25968;&#21270;&#21644;&#26410;&#30693;&#36807;&#28193;&#30340;&#22522;&#20110;&#20559;&#22909;&#27169;&#22411;&#19979;&#23398;&#20064;&#26368;&#20248;&#31574;&#30053;&#25152;&#38656;&#30340;&#20154;&#31867;&#21453;&#39304;&#26356;&#23569;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#32435;&#20837;&#32447;&#24615;&#21644;&#20302;&#31209;MDPs&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#22522;&#20110;&#34892;&#21160;&#27604;&#36739;&#30340;&#21453;&#39304;&#30340;RLHF&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#37319;&#26679;&#26041;&#27861;&#65292;&#20197;&#22312;&#20248;&#21270;&#20855;&#26377;&#26377;&#38480;&#21453;&#39304;&#30340;&#20219;&#21153;&#26102;&#33719;&#24471;&#25506;&#32034;&#24615;&#36712;&#36857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning with Human Feedback (RLHF) is a paradigm in which an RL agent learns to optimize a task using pair-wise preference-based feedback over trajectories, rather than explicit reward signals. While RLHF has demonstrated practical success in fine-tuning language models, existing empirical work does not address the challenge of how to efficiently sample trajectory pairs for querying human feedback. In this study, we propose an efficient sampling approach to acquiring exploratory trajectories that enable accurate learning of hidden reward functions before collecting any human feedback. Theoretical analysis demonstrates that our algorithm requires less human feedback for learning the optimal policy under preference-based models with linear parameterization and unknown transitions, compared to the existing literature. Specifically, our framework can incorporate linear and low-rank MDPs. Additionally, we investigate RLHF with action-based comparison feedback and introduce an
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22797;&#26434;&#27169;&#22411;&#20013;&#36827;&#34892;&#21464;&#20998;&#25512;&#26029;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#28982;&#26799;&#24230;&#26356;&#26032;&#21644;&#40654;&#26364;&#27969;&#24418;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#39640;&#26031;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#24182;&#39564;&#35777;&#20102;&#20854;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2210.14598</link><description>&lt;p&gt;
&#30830;&#20999;&#30340;&#27969;&#24418;&#39640;&#26031;&#21464;&#20998;&#36125;&#21494;&#26031;
&lt;/p&gt;
&lt;p&gt;
Exact Manifold Gaussian Variational Bayes. (arXiv:2210.14598v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.14598
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22797;&#26434;&#27169;&#22411;&#20013;&#36827;&#34892;&#21464;&#20998;&#25512;&#26029;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#28982;&#26799;&#24230;&#26356;&#26032;&#21644;&#40654;&#26364;&#27969;&#24418;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#39640;&#26031;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#24182;&#39564;&#35777;&#20102;&#20854;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22797;&#26434;&#27169;&#22411;&#20013;&#21464;&#20998;&#25512;&#26029;&#65288;VI&#65289;&#30340;&#20248;&#21270;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#33258;&#28982;&#26799;&#24230;&#26356;&#26032;&#65292;&#20854;&#20013;&#21464;&#20998;&#31354;&#38388;&#26159;&#19968;&#20010;&#40654;&#26364;&#27969;&#24418;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#39640;&#26031;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#20197;&#38544;&#24335;&#28385;&#36275;&#21464;&#20998;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#27491;&#23450;&#32422;&#26463;&#12290;&#25105;&#20204;&#30340;&#30830;&#20999;&#27969;&#24418;&#39640;&#26031;&#21464;&#20998;&#36125;&#21494;&#26031;&#65288;EMGVB&#65289;&#25552;&#20379;&#20102;&#31934;&#30830;&#20294;&#31616;&#21333;&#30340;&#26356;&#26032;&#35268;&#21017;&#65292;&#24182;&#19988;&#26131;&#20110;&#23454;&#29616;&#12290;&#30001;&#20110;&#20854;&#40657;&#30418;&#24615;&#36136;&#65292;EMGVB&#25104;&#20026;&#22797;&#26434;&#27169;&#22411;&#20013;&#21363;&#25554;&#21363;&#29992;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#36890;&#36807;&#22312;&#19981;&#21516;&#32479;&#35745;&#12289;&#35745;&#37327;&#21644;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#19978;&#20351;&#29992;&#20116;&#20010;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#23545;&#25105;&#20204;&#30340;&#21487;&#34892;&#24615;&#26041;&#27861;&#36827;&#34892;&#20102;&#23454;&#35777;&#39564;&#35777;&#65292;&#24182;&#19982;&#22522;&#20934;&#26041;&#27861;&#36827;&#34892;&#20102;&#24615;&#33021;&#35752;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an optimization algorithm for Variational Inference (VI) in complex models. Our approach relies on natural gradient updates where the variational space is a Riemann manifold. We develop an efficient algorithm for Gaussian Variational Inference that implicitly satisfies the positive definite constraint on the variational covariance matrix. Our Exact manifold Gaussian Variational Bayes (EMGVB) provides exact but simple update rules and is straightforward to implement. Due to its black-box nature, EMGVB stands as a ready-to-use solution for VI in complex models. Over five datasets, we empirically validate our feasible approach on different statistical, econometric, and deep learning models, discussing its performance with respect to baseline methods.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#23558;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#31639;&#27861;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#65292;&#20197;&#25552;&#39640;&#38754;&#26495;&#25968;&#25454;&#20013;&#30340;&#22240;&#26524;&#25512;&#26029;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;&#21508;&#31181;&#24773;&#26223;&#19979;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#20026;&#38754;&#26495;&#25968;&#25454;&#30740;&#31350;&#25552;&#20379;&#20102;&#26032;&#30340;&#26041;&#27861;&#21644;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2208.03489</link><description>&lt;p&gt;
&#38754;&#26495;&#25968;&#25454;&#22240;&#26524;&#25512;&#26029;&#30340;&#39044;&#27979;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Forecasting Algorithms for Causal Inference with Panel Data. (arXiv:2208.03489v2 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.03489
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#23558;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#31639;&#27861;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#65292;&#20197;&#25552;&#39640;&#38754;&#26495;&#25968;&#25454;&#20013;&#30340;&#22240;&#26524;&#25512;&#26029;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;&#21508;&#31181;&#24773;&#26223;&#19979;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#20026;&#38754;&#26495;&#25968;&#25454;&#30740;&#31350;&#25552;&#20379;&#20102;&#26032;&#30340;&#26041;&#27861;&#21644;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31038;&#20250;&#31185;&#23398;&#30740;&#31350;&#20013;&#65292;&#20351;&#29992;&#38754;&#26495;&#25968;&#25454;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#26159;&#19968;&#39033;&#26680;&#24515;&#25361;&#25112;&#12290;&#25105;&#20204;&#23558;&#19968;&#31181;&#28145;&#24230;&#31070;&#32463;&#26550;&#26500;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#65288;N-BEATS&#31639;&#27861;&#65289;&#65292;&#20197;&#26356;&#20934;&#30830;&#22320;&#39044;&#27979;&#22312;&#26410;&#36827;&#34892;&#22788;&#29702;&#30340;&#24773;&#20917;&#19979;&#21463;&#27835;&#30103;&#21333;&#20301;&#30340;&#21453;&#20107;&#23454;&#28436;&#21464;&#12290;&#22312;&#21508;&#31181;&#24773;&#22659;&#19979;&#65292;&#25152;&#24471;&#21040;&#30340;&#20272;&#35745;&#22120;&#65288;&#8220;SyNBEATS&#8221;&#65289;&#22312;&#24615;&#33021;&#19978;&#26126;&#26174;&#20248;&#20110;&#24120;&#29992;&#26041;&#27861;&#65288;&#21512;&#25104;&#23545;&#29031;&#27861;&#12289;&#21452;&#21521;&#22266;&#23450;&#25928;&#24212;&#65289;&#65292;&#24182;&#19988;&#19982;&#26368;&#36817;&#25552;&#20986;&#30340;&#26041;&#27861;&#65288;&#21512;&#25104;&#24046;&#24322;&#27861;&#12289;&#30697;&#38453;&#34917;&#20840;&#65289;&#22312;&#20934;&#30830;&#24615;&#19978;&#36798;&#21040;&#20102;&#30456;&#24403;&#30340;&#27700;&#24179;&#25110;&#26356;&#39640;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#31361;&#26174;&#20102;&#22914;&#20309;&#21033;&#29992;&#39044;&#27979;&#25991;&#29486;&#30340;&#36827;&#23637;&#26469;&#25913;&#21892;&#38754;&#26495;&#25968;&#25454;&#29615;&#22659;&#19979;&#30340;&#22240;&#26524;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conducting causal inference with panel data is a core challenge in social science research. We adapt a deep neural architecture for time series forecasting (the N-BEATS algorithm) to more accurately predict the counterfactual evolution of a treated unit had treatment not occurred. Across a range of settings, the resulting estimator ("SyNBEATS") significantly outperforms commonly employed methods (synthetic controls, two-way fixed effects), and attains comparable or more accurate performance compared to recently proposed methods (synthetic difference-in-differences, matrix completion). Our results highlight how advances in the forecasting literature can be harnessed to improve causal inference in panel data settings.
&lt;/p&gt;</description></item></channel></rss>