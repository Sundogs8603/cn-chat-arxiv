<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#31181;&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#65292;&#20351;&#29992;&#29699;&#35856;&#20989;&#25968;&#20316;&#20026;&#25511;&#21046;&#21464;&#37327;&#26469;&#36817;&#20284;&#35745;&#31639;&#20999;&#29255;&#21326;&#29791;&#26031;&#22374;&#36317;&#31163;&#12290;&#19982;&#33945;&#29305;&#21345;&#32599;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#29702;&#35770;&#24615;&#36136;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01493</link><description>&lt;p&gt;
&#20351;&#29992;&#29699;&#35856;&#20989;&#25968;&#20316;&#20026;&#25511;&#21046;&#21464;&#37327;&#30340;&#20999;&#29255;&#21326;&#29791;&#26031;&#22374;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Sliced-Wasserstein Estimation with Spherical Harmonics as Control Variates
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01493
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31181;&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#65292;&#20351;&#29992;&#29699;&#35856;&#20989;&#25968;&#20316;&#20026;&#25511;&#21046;&#21464;&#37327;&#26469;&#36817;&#20284;&#35745;&#31639;&#20999;&#29255;&#21326;&#29791;&#26031;&#22374;&#36317;&#31163;&#12290;&#19982;&#33945;&#29305;&#21345;&#32599;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#29702;&#35770;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20999;&#29255;&#21326;&#29791;&#26031;&#22374;&#65288;SW&#65289;&#36317;&#31163;&#26159;&#27010;&#29575;&#27979;&#24230;&#20043;&#38388;&#30340;&#21326;&#29791;&#26031;&#22374;&#36317;&#31163;&#30340;&#24179;&#22343;&#20540;&#65292;&#32467;&#26524;&#20026;&#30456;&#20851;&#30340;&#19968;&#32500;&#25237;&#24433;&#30340;&#21326;&#29791;&#26031;&#22374;&#36317;&#31163;&#12290;&#22240;&#27492;&#65292;SW&#36317;&#31163;&#21487;&#20197;&#20889;&#25104;&#23545;&#29699;&#38754;&#19978;&#22343;&#21248;&#27979;&#24230;&#30340;&#31215;&#20998;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#33945;&#29305;&#21345;&#32599;&#26694;&#26550;&#26469;&#35745;&#31639;SW&#36317;&#31163;&#12290;&#29699;&#35856;&#20989;&#25968;&#26159;&#29699;&#38754;&#19978;&#30340;&#22810;&#39033;&#24335;&#65292;&#23427;&#20204;&#26500;&#25104;&#20102;&#29699;&#38754;&#19978;&#21487;&#31215;&#20989;&#25968;&#38598;&#21512;&#30340;&#27491;&#20132;&#22522;&#12290;&#23558;&#36825;&#20004;&#20010;&#20107;&#23454;&#32467;&#21512;&#22312;&#19968;&#36215;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#65292;&#31216;&#20026;&#29699;&#35856;&#25511;&#21046;&#21464;&#37327;&#65288;SHCV&#65289;&#65292;&#29992;&#20110;&#20351;&#29992;&#29699;&#35856;&#20989;&#25968;&#20316;&#20026;&#25511;&#21046;&#21464;&#37327;&#36817;&#20284;&#35745;&#31639;SW&#36317;&#31163;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#33391;&#22909;&#30340;&#29702;&#35770;&#24615;&#36136;&#65292;&#20363;&#22914;&#22312;&#21464;&#37327;&#20043;&#38388;&#23384;&#22312;&#19968;&#23450;&#24418;&#24335;&#30340;&#32447;&#24615;&#20381;&#36182;&#26102;&#65292;&#28151;&#21512;&#39640;&#26031;&#27979;&#24230;&#30340;&#26080;&#35823;&#24046;&#29305;&#24615;&#12290;&#27492;&#22806;&#65292;&#19982;&#33945;&#29305;&#21345;&#32599;&#30456;&#27604;&#65292;&#24471;&#21040;&#20102;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Sliced-Wasserstein (SW) distance between probability measures is defined as the average of the Wasserstein distances resulting for the associated one-dimensional projections. As a consequence, the SW distance can be written as an integral with respect to the uniform measure on the sphere and the Monte Carlo framework can be employed for calculating the SW distance. Spherical harmonics are polynomials on the sphere that form an orthonormal basis of the set of square-integrable functions on the sphere. Putting these two facts together, a new Monte Carlo method, hereby referred to as Spherical Harmonics Control Variates (SHCV), is proposed for approximating the SW distance using spherical harmonics as control variates. The resulting approach is shown to have good theoretical properties, e.g., a no-error property for Gaussian measures under a certain form of linear dependency between the variables. Moreover, an improved rate of convergence, compared to Monte Carlo, is established for g
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#32479;&#35745;&#22240;&#26524;&#25552;&#31034;&#19982;&#30693;&#35782;&#22686;&#24378;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#20351;&#32479;&#35745;&#22240;&#26524;&#21457;&#29616;&#32467;&#26524;&#25509;&#36817;&#30495;&#23454;&#24773;&#20917;&#24182;&#36827;&#19968;&#27493;&#25913;&#36827;&#32467;&#26524;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01454</link><description>&lt;p&gt;
&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;: &#19968;&#31181;&#32479;&#35745;&#22240;&#26524;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01454
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#32479;&#35745;&#22240;&#26524;&#25552;&#31034;&#19982;&#30693;&#35782;&#22686;&#24378;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#20351;&#32479;&#35745;&#22240;&#26524;&#21457;&#29616;&#32467;&#26524;&#25509;&#36817;&#30495;&#23454;&#24773;&#20917;&#24182;&#36827;&#19968;&#27493;&#25913;&#36827;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#30340;&#32479;&#35745;&#22240;&#26524;&#21457;&#29616;&#65288;SCD&#65289;&#20013;&#65292;&#23558;&#39046;&#22495;&#19987;&#23478;&#30693;&#35782;&#20316;&#20026;&#32422;&#26463;&#23884;&#20837;&#21040;&#31639;&#27861;&#20013;&#34987;&#24191;&#27867;&#25509;&#21463;&#65292;&#22240;&#20026;&#36825;&#23545;&#20110;&#21019;&#24314;&#19968;&#33268;&#26377;&#24847;&#20041;&#30340;&#22240;&#26524;&#27169;&#22411;&#26159;&#37325;&#35201;&#30340;&#65292;&#23613;&#31649;&#35782;&#21035;&#32972;&#26223;&#30693;&#35782;&#30340;&#25361;&#25112;&#34987;&#35748;&#21487;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#65292;&#21363;&#36890;&#36807;&#23558;LLM&#30340;&#8220;&#32479;&#35745;&#22240;&#26524;&#25552;&#31034;&#65288;SCP&#65289;&#8221;&#19982;SCD&#26041;&#27861;&#21644;&#22522;&#20110;&#30693;&#35782;&#30340;&#22240;&#26524;&#25512;&#26029;&#65288;KBCI&#65289;&#30456;&#32467;&#21512;&#65292;&#23545;SCD&#36827;&#34892;&#20808;&#39564;&#30693;&#35782;&#22686;&#24378;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;GPT-4&#21487;&#20197;&#20351;LLM-KBCI&#30340;&#36755;&#20986;&#19982;&#24102;&#26377;LLM-KBCI&#30340;&#20808;&#39564;&#30693;&#35782;&#30340;SCD&#32467;&#26524;&#25509;&#36817;&#30495;&#23454;&#24773;&#20917;&#65292;&#22914;&#26524;GPT-4&#32463;&#21382;&#20102;SCP&#65292;&#37027;&#20040;SCD&#30340;&#32467;&#26524;&#36824;&#21487;&#20197;&#36827;&#19968;&#27493;&#25913;&#21892;&#12290;&#32780;&#19988;&#65292;&#21363;&#20351;LLM&#19981;&#21547;&#26377;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#65292;LLM&#20173;&#28982;&#21487;&#20197;&#36890;&#36807;&#20854;&#32972;&#26223;&#30693;&#35782;&#26469;&#25913;&#36827;SCD&#12290;
&lt;/p&gt;
&lt;p&gt;
In practical statistical causal discovery (SCD), embedding domain expert knowledge as constraints into the algorithm is widely accepted as significant for creating consistent meaningful causal models, despite the recognized challenges in systematic acquisition of the background knowledge. To overcome these challenges, this paper proposes a novel methodology for causal inference, in which SCD methods and knowledge based causal inference (KBCI) with a large language model (LLM) are synthesized through "statistical causal prompting (SCP)" for LLMs and prior knowledge augmentation for SCD. Experiments have revealed that GPT-4 can cause the output of the LLM-KBCI and the SCD result with prior knowledge from LLM-KBCI to approach the ground truth, and that the SCD result can be further improved, if GPT-4 undergoes SCP. Furthermore, it has been clarified that an LLM can improve SCD with its background knowledge, even if the LLM does not contain information on the dataset. The proposed approach
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31526;&#21512;&#24615;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#22312;&#32447;&#31526;&#21512;&#24615;&#39044;&#27979;&#25216;&#26415;&#21644;&#35299;&#20915;&#22238;&#24402;&#20013;&#24322;&#26041;&#24046;&#24615;&#30340;&#26041;&#27861;&#65292;&#29983;&#25104;&#20102;&#21516;&#26102;&#39044;&#27979;&#36793;&#30028;&#65292;&#24182;&#33021;&#22815;&#21487;&#38752;&#22320;&#35206;&#30422;&#26032;&#38543;&#26426;&#36712;&#36857;&#30340;&#25972;&#20010;&#36335;&#24452;&#12290;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#26377;&#31934;&#30830;&#30340;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#65292;&#32780;&#19988;&#24448;&#24448;&#27604;&#20043;&#21069;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#20016;&#23500;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.09623</link><description>&lt;p&gt;
&#22810;&#20803;&#36712;&#36857;&#30340;&#31526;&#21512;&#24615;&#33258;&#36866;&#24212;&#39044;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Conformalized Adaptive Forecasting of Heterogeneous Trajectories
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09623
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31526;&#21512;&#24615;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#22312;&#32447;&#31526;&#21512;&#24615;&#39044;&#27979;&#25216;&#26415;&#21644;&#35299;&#20915;&#22238;&#24402;&#20013;&#24322;&#26041;&#24046;&#24615;&#30340;&#26041;&#27861;&#65292;&#29983;&#25104;&#20102;&#21516;&#26102;&#39044;&#27979;&#36793;&#30028;&#65292;&#24182;&#33021;&#22815;&#21487;&#38752;&#22320;&#35206;&#30422;&#26032;&#38543;&#26426;&#36712;&#36857;&#30340;&#25972;&#20010;&#36335;&#24452;&#12290;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#26377;&#31934;&#30830;&#30340;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#65292;&#32780;&#19988;&#24448;&#24448;&#27604;&#20043;&#21069;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#20016;&#23500;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31526;&#21512;&#24615;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#21516;&#26102;&#39044;&#27979;&#36793;&#30028;&#65292;&#20197;&#20855;&#26377;&#36275;&#22815;&#39640;&#30340;&#27010;&#29575;&#35206;&#30422;&#26032;&#38543;&#26426;&#36712;&#36857;&#30340;&#25972;&#20010;&#36335;&#24452;&#12290;&#37492;&#20110;&#22312;&#36816;&#21160;&#35268;&#21010;&#24212;&#29992;&#20013;&#38656;&#35201;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#20854;&#20013;&#19981;&#21516;&#29289;&#20307;&#30340;&#34892;&#20026;&#21487;&#33021;&#26356;&#25110;&#26356;&#23569;&#21487;&#39044;&#27979;&#65292;&#25105;&#20204;&#23558;&#26469;&#33258;&#21333;&#20010;&#21644;&#22810;&#20010;&#26102;&#38388;&#24207;&#21015;&#30340;&#22312;&#32447;&#31526;&#21512;&#24615;&#39044;&#27979;&#25216;&#26415;&#65292;&#20197;&#21450;&#35299;&#20915;&#22238;&#24402;&#20013;&#30340;&#24322;&#26041;&#24046;&#24615;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#34701;&#21512;&#12290;&#35813;&#35299;&#20915;&#26041;&#26696;&#26082;&#26377;&#21407;&#21017;&#24615;&#65292;&#25552;&#20379;&#20102;&#31934;&#30830;&#30340;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#65292;&#21448;&#26377;&#25928;&#65292;&#36890;&#24120;&#27604;&#20808;&#21069;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#20016;&#23500;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09623v1 Announce Type: cross  Abstract: This paper presents a new conformal method for generating simultaneous forecasting bands guaranteed to cover the entire path of a new random trajectory with sufficiently high probability. Prompted by the need for dependable uncertainty estimates in motion planning applications where the behavior of diverse objects may be more or less unpredictable, we blend different techniques from online conformal prediction of single and multiple time series, as well as ideas for addressing heteroscedasticity in regression. This solution is both principled, providing precise finite-sample guarantees, and effective, often leading to more informative predictions than prior methods.
&lt;/p&gt;</description></item><item><title>&#26631;&#20934; Gaussian &#36807;&#31243;&#22312;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#34920;&#29616;&#20248;&#31168;&#65292;&#32463;&#39564;&#35777;&#25454;&#26174;&#31034;&#20854;&#22312;&#20989;&#25968;&#20272;&#35745;&#21644;&#21327;&#26041;&#24046;&#24314;&#27169;&#20013;&#20811;&#26381;&#20102;&#39640;&#32500;&#36755;&#20837;&#22256;&#38590;&#65292;&#27604;&#19987;&#38376;&#20026;&#39640;&#32500;&#20248;&#21270;&#35774;&#35745;&#30340;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>https://arxiv.org/abs/2402.02746</link><description>&lt;p&gt;
&#26631;&#20934; Gaussian &#36807;&#31243;&#22312;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#36275;&#20197;&#24212;&#23545;
&lt;/p&gt;
&lt;p&gt;
Standard Gaussian Process is All You Need for High-Dimensional Bayesian Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02746
&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934; Gaussian &#36807;&#31243;&#22312;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#34920;&#29616;&#20248;&#31168;&#65292;&#32463;&#39564;&#35777;&#25454;&#26174;&#31034;&#20854;&#22312;&#20989;&#25968;&#20272;&#35745;&#21644;&#21327;&#26041;&#24046;&#24314;&#27169;&#20013;&#20811;&#26381;&#20102;&#39640;&#32500;&#36755;&#20837;&#22256;&#38590;&#65292;&#27604;&#19987;&#38376;&#20026;&#39640;&#32500;&#20248;&#21270;&#35774;&#35745;&#30340;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38271;&#26399;&#20197;&#26469;&#65292;&#20154;&#20204;&#26222;&#36941;&#35748;&#20026;&#20351;&#29992;&#26631;&#20934; Gaussian &#36807;&#31243;&#65288;GP&#65289;&#36827;&#34892;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#65292;&#21363;&#26631;&#20934; BO&#65292;&#22312;&#39640;&#32500;&#20248;&#21270;&#38382;&#39064;&#20013;&#25928;&#26524;&#19981;&#20339;&#12290;&#36825;&#31181;&#35266;&#24565;&#21487;&#20197;&#37096;&#20998;&#24402;&#22240;&#20110; Gaussian &#36807;&#31243;&#22312;&#21327;&#26041;&#24046;&#24314;&#27169;&#21644;&#20989;&#25968;&#20272;&#35745;&#20013;&#23545;&#39640;&#32500;&#36755;&#20837;&#30340;&#22256;&#38590;&#12290;&#34429;&#28982;&#36825;&#20123;&#25285;&#24551;&#30475;&#36215;&#26469;&#21512;&#29702;&#65292;&#20294;&#32570;&#20047;&#25903;&#25345;&#36825;&#31181;&#35266;&#28857;&#30340;&#32463;&#39564;&#35777;&#25454;&#12290;&#26412;&#25991;&#31995;&#32479;&#22320;&#30740;&#31350;&#20102;&#22312;&#21508;&#31181;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#22522;&#20934;&#38382;&#39064;&#19978;&#65292;&#20351;&#29992;&#26631;&#20934; GP &#22238;&#24402;&#36827;&#34892;&#39640;&#32500;&#20248;&#21270;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#26631;&#20934; GP &#30340;&#34920;&#29616;&#22987;&#32456;&#20301;&#20110;&#26368;&#20339;&#33539;&#22260;&#20869;&#65292;&#24448;&#24448;&#27604;&#19987;&#38376;&#20026;&#39640;&#32500;&#20248;&#21270;&#35774;&#35745;&#30340;&#29616;&#26377; BO &#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#12290;&#19982;&#21051;&#26495;&#21360;&#35937;&#30456;&#21453;&#65292;&#25105;&#20204;&#21457;&#29616;&#26631;&#20934; GP &#21487;&#20197;&#20316;&#20026;&#23398;&#20064;&#39640;&#32500;&#30446;&#26631;&#20989;&#25968;&#30340;&#33021;&#21147;&#24378;&#22823;&#30340;&#20195;&#29702;&#12290;&#22312;&#27809;&#26377;&#24378;&#32467;&#26500;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#26631;&#20934; GP &#36827;&#34892; BO &#21487;&#20197;&#33719;&#24471;&#38750;&#24120;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
There has been a long-standing and widespread belief that Bayesian Optimization (BO) with standard Gaussian process (GP), referred to as standard BO, is ineffective in high-dimensional optimization problems. This perception may partly stem from the intuition that GPs struggle with high-dimensional inputs for covariance modeling and function estimation. While these concerns seem reasonable, empirical evidence supporting this belief is lacking. In this paper, we systematically investigated BO with standard GP regression across a variety of synthetic and real-world benchmark problems for high-dimensional optimization. Surprisingly, the performance with standard GP consistently ranks among the best, often outperforming existing BO methods specifically designed for high-dimensional optimization by a large margin. Contrary to the stereotype, we found that standard GP can serve as a capable surrogate for learning high-dimensional target functions. Without strong structural assumptions, BO wit
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#20248;&#21270;&#22810;&#20998;&#24067;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#37319;&#26679;&#26469;&#23454;&#29616;&#25968;&#25454;&#39640;&#25928;&#30340;&#23398;&#20064;&#12290;&#38024;&#23545;Vapnik-Chervonenkis (VC)&#32500;&#25968;&#20026;d&#30340;&#20551;&#35774;&#31867;&#65292;&#31639;&#27861;&#21487;&#20197;&#29983;&#25104;&#19968;&#20010;&#949;-&#26368;&#20248;&#38543;&#26426;&#20551;&#35774;&#65292;&#24182;&#19988;&#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#26368;&#20339;&#19979;&#30028;&#20445;&#25345;&#19968;&#33268;&#12290;&#21516;&#26102;&#65292;&#35813;&#31639;&#27861;&#30340;&#24605;&#24819;&#21644;&#29702;&#35770;&#36824;&#34987;&#36827;&#19968;&#27493;&#25193;&#23637;&#20197;&#36866;&#24212;Rademacher&#31867;&#12290;&#26368;&#32456;&#25552;&#20986;&#30340;&#31639;&#27861;&#26159;&#22885;&#25289;&#20811;&#23572;&#39640;&#25928;&#30340;&#65292;&#20165;&#35775;&#38382;&#20551;&#35774;&#31867;&#12290;</title><link>http://arxiv.org/abs/2312.05134</link><description>&lt;p&gt;
&#26368;&#20248;&#21270;&#22810;&#20998;&#24067;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Optimal Multi-Distribution Learning. (arXiv:2312.05134v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.05134
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#20248;&#21270;&#22810;&#20998;&#24067;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#37319;&#26679;&#26469;&#23454;&#29616;&#25968;&#25454;&#39640;&#25928;&#30340;&#23398;&#20064;&#12290;&#38024;&#23545;Vapnik-Chervonenkis (VC)&#32500;&#25968;&#20026;d&#30340;&#20551;&#35774;&#31867;&#65292;&#31639;&#27861;&#21487;&#20197;&#29983;&#25104;&#19968;&#20010;&#949;-&#26368;&#20248;&#38543;&#26426;&#20551;&#35774;&#65292;&#24182;&#19988;&#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#26368;&#20339;&#19979;&#30028;&#20445;&#25345;&#19968;&#33268;&#12290;&#21516;&#26102;&#65292;&#35813;&#31639;&#27861;&#30340;&#24605;&#24819;&#21644;&#29702;&#35770;&#36824;&#34987;&#36827;&#19968;&#27493;&#25193;&#23637;&#20197;&#36866;&#24212;Rademacher&#31867;&#12290;&#26368;&#32456;&#25552;&#20986;&#30340;&#31639;&#27861;&#26159;&#22885;&#25289;&#20811;&#23572;&#39640;&#25928;&#30340;&#65292;&#20165;&#35775;&#38382;&#20551;&#35774;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20998;&#24067;&#23398;&#20064;&#65288;MDL&#65289;&#26088;&#22312;&#23398;&#20064;&#19968;&#20010;&#20849;&#20139;&#27169;&#22411;&#65292;&#20351;&#24471;&#22312;k&#20010;&#19981;&#21516;&#30340;&#25968;&#25454;&#20998;&#24067;&#19979;&#65292;&#26368;&#23567;&#21270;&#26368;&#22351;&#24773;&#20917;&#39118;&#38505;&#65292;&#24050;&#25104;&#20026;&#36866;&#24212;&#20581;&#22766;&#24615;&#12289;&#20844;&#24179;&#24615;&#12289;&#22810;&#32452;&#21512;&#20316;&#31561;&#38656;&#27714;&#30340;&#32479;&#19968;&#26694;&#26550;&#12290;&#23454;&#29616;&#25968;&#25454;&#39640;&#25928;&#30340;MDL&#38656;&#35201;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#36827;&#34892;&#33258;&#36866;&#24212;&#37319;&#26679;&#65292;&#20063;&#31216;&#20026;&#25353;&#38656;&#37319;&#26679;&#12290;&#28982;&#32780;&#65292;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#19978;&#19979;&#30028;&#20043;&#38388;&#23384;&#22312;&#36739;&#22823;&#24046;&#36317;&#12290;&#38024;&#23545;Vapnik-Chervonenkis&#65288;VC&#65289;&#32500;&#25968;&#20026;d&#30340;&#20551;&#35774;&#31867;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#21487;&#29983;&#25104;&#19968;&#20010;&#949;-&#26368;&#20248;&#38543;&#26426;&#20551;&#35774;&#65292;&#20854;&#26679;&#26412;&#22797;&#26434;&#24230;&#25509;&#36817;&#20110;&#65288;d+k&#65289;/&#949;^2&#65288;&#22312;&#26576;&#20123;&#23545;&#25968;&#22240;&#23376;&#20013;&#65289;&#65292;&#19982;&#24050;&#30693;&#30340;&#26368;&#20339;&#19979;&#30028;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#24605;&#24819;&#21644;&#29702;&#35770;&#34987;&#36827;&#19968;&#27493;&#25193;&#23637;&#65292;&#20197;&#36866;&#24212;Rademacher&#31867;&#12290;&#25552;&#20986;&#30340;&#31639;&#27861;&#26159;&#22885;&#25289;&#20811;&#23572;&#39640;&#25928;&#30340;&#65292;&#20165;&#20165;&#35775;&#38382;&#20551;&#35774;&#31867;
&lt;/p&gt;
&lt;p&gt;
Multi-distribution learning (MDL), which seeks to learn a shared model that minimizes the worst-case risk across $k$ distinct data distributions, has emerged as a unified framework in response to the evolving demand for robustness, fairness, multi-group collaboration, etc. Achieving data-efficient MDL necessitates adaptive sampling, also called on-demand sampling, throughout the learning process. However, there exist substantial gaps between the state-of-the-art upper and lower bounds on the optimal sample complexity. Focusing on a hypothesis class of Vapnik-Chervonenkis (VC) dimension $d$, we propose a novel algorithm that yields an $varepsilon$-optimal randomized hypothesis with a sample complexity on the order of $(d+k)/\varepsilon^2$ (modulo some logarithmic factor), matching the best-known lower bound. Our algorithmic ideas and theory have been further extended to accommodate Rademacher classes. The proposed algorithms are oracle-efficient, which access the hypothesis class solely
&lt;/p&gt;</description></item><item><title>MINDE&#26159;&#19968;&#31181;&#22522;&#20110;&#24471;&#20998;&#20989;&#25968;&#25193;&#25955;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#12290;&#35813;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;&#33258;&#19968;&#33268;&#24615;&#27979;&#35797;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#25991;&#29486;&#20013;&#30340;&#20027;&#35201;&#26367;&#20195;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.09031</link><description>&lt;p&gt;
MINDE: &#20114;&#20449;&#24687;&#31070;&#32463;&#25193;&#25955;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
MINDE: Mutual Information Neural Diffusion Estimation. (arXiv:2310.09031v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09031
&lt;/p&gt;
&lt;p&gt;
MINDE&#26159;&#19968;&#31181;&#22522;&#20110;&#24471;&#20998;&#20989;&#25968;&#25193;&#25955;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#12290;&#35813;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;&#33258;&#19968;&#33268;&#24615;&#27979;&#35797;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#25991;&#29486;&#20013;&#30340;&#20027;&#35201;&#26367;&#20195;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#20114;&#20449;&#24687;&#65288;MI&#65289;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;Girsanov&#23450;&#29702;&#30340;&#21407;&#21019;&#35299;&#37322;&#65292;&#20801;&#35768;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#26469;&#20272;&#35745;&#20004;&#20010;&#23494;&#24230;&#20989;&#25968;&#20043;&#38388;&#30340;Kullback-Leibler&#25955;&#24230;&#65292;&#35813;&#20272;&#35745;&#26159;&#23427;&#20204;&#24471;&#20998;&#20989;&#25968;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#20316;&#20026;&#21103;&#20135;&#21697;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36824;&#33021;&#22815;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;&#30340;&#29109;&#12290;&#20511;&#21161;&#36825;&#26679;&#30340;&#26500;&#24314;&#27169;&#22359;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#27979;&#37327;MI&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20998;&#20026;&#20004;&#20010;&#26041;&#21521;&#23637;&#24320;&#65306;&#19968;&#20010;&#20351;&#29992;&#26465;&#20214;&#25193;&#25955;&#36807;&#31243;&#65292;&#21478;&#19968;&#20010;&#20351;&#29992;&#32852;&#21512;&#25193;&#25955;&#36807;&#31243;&#65292;&#21487;&#20197;&#21516;&#26102;&#23545;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;&#36827;&#34892;&#24314;&#27169;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26469;&#33258;&#20110;&#23545;&#25105;&#20204;&#26041;&#27861;&#30340;&#21508;&#31181;&#21464;&#20307;&#36827;&#34892;&#24443;&#24213;&#30340;&#23454;&#39564;&#21327;&#35758;&#65292;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#27604;&#25991;&#29486;&#20013;&#30340;&#20027;&#35201;&#26367;&#20195;&#26041;&#27861;&#26356;&#20934;&#30830;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#20102;MI&#33258;&#19968;&#33268;&#24615;&#27979;&#35797;&#65292;&#21253;&#25324;...
&lt;/p&gt;
&lt;p&gt;
In this work we present a new method for the estimation of Mutual Information (MI) between random variables. Our approach is based on an original interpretation of the Girsanov theorem, which allows us to use score-based diffusion models to estimate the Kullback Leibler divergence between two densities as a difference between their score functions. As a by-product, our method also enables the estimation of the entropy of random variables. Armed with such building blocks, we present a general recipe to measure MI, which unfolds in two directions: one uses conditional diffusion process, whereas the other uses joint diffusion processes that allow simultaneous modelling of two random variables. Our results, which derive from a thorough experimental protocol over all the variants of our approach, indicate that our method is more accurate than the main alternatives from the literature, especially for challenging distributions. Furthermore, our methods pass MI self-consistency tests, includin
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#23637;&#31034;&#20102;&#20351;&#29992;&#20855;&#26377;&#26080;&#38480;&#26041;&#24046;&#30340;&#19981;&#24688;&#24403;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#26469;&#23450;&#20041;&#38745;&#27490;&#20294;&#19981;&#22343;&#20540;&#22238;&#24402;&#36807;&#31243;&#30340;&#21487;&#33021;&#24615;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31867;&#29305;&#27530;&#30340;&#19981;&#24688;&#24403;&#26680;&#20989;&#25968;&#26469;&#23454;&#29616;&#27492;&#30446;&#30340;&#12290;</title><link>http://arxiv.org/abs/2310.02877</link><description>&lt;p&gt;
&#26080;&#22343;&#20540;&#22238;&#24402;&#65306;&#19981;&#24688;&#24403;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#21644;&#19981;&#24688;&#24403;&#26680;
&lt;/p&gt;
&lt;p&gt;
Stationarity without mean reversion: Improper Gaussian process regression and improper kernels. (arXiv:2310.02877v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02877
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#23637;&#31034;&#20102;&#20351;&#29992;&#20855;&#26377;&#26080;&#38480;&#26041;&#24046;&#30340;&#19981;&#24688;&#24403;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#26469;&#23450;&#20041;&#38745;&#27490;&#20294;&#19981;&#22343;&#20540;&#22238;&#24402;&#36807;&#31243;&#30340;&#21487;&#33021;&#24615;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31867;&#29305;&#27530;&#30340;&#19981;&#24688;&#24403;&#26680;&#20989;&#25968;&#26469;&#23454;&#29616;&#27492;&#30446;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#22238;&#24402;&#22312;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#24050;&#32463;&#24191;&#27867;&#27969;&#34892;&#12290;GP&#22238;&#24402;&#30340;&#34892;&#20026;&#21462;&#20915;&#20110;&#21327;&#26041;&#24046;&#20989;&#25968;&#30340;&#36873;&#25321;&#12290;&#22312;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#65292;&#38745;&#27490;&#21327;&#26041;&#24046;&#20989;&#25968;&#26159;&#39318;&#36873;&#12290;&#28982;&#32780;&#65292;&#65288;&#38750;&#21608;&#26399;&#24615;&#30340;&#65289;&#38745;&#27490;&#21327;&#26041;&#24046;&#20989;&#25968;&#24635;&#26159;&#22343;&#20540;&#22238;&#24402;&#30340;&#65292;&#22240;&#27492;&#22312;&#24212;&#29992;&#20110;&#19981;&#36890;&#36807;&#21040;&#22266;&#23450;&#20840;&#23616;&#22343;&#20540;&#20540;&#30340;&#25968;&#25454;&#26102;&#21487;&#33021;&#34920;&#29616;&#20986;&#30149;&#24577;&#34892;&#20026;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#20855;&#26377;&#26080;&#38480;&#26041;&#24046;&#30340;&#19981;&#24688;&#24403;GP&#20808;&#39564;&#26469;&#23450;&#20041;&#38745;&#27490;&#20294;&#19981;&#22343;&#20540;&#22238;&#24402;&#36807;&#31243;&#26159;&#21487;&#33021;&#30340;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#22823;&#31867;&#21482;&#33021;&#22312;&#36825;&#31181;&#19981;&#24688;&#24403;&#30340;&#33539;&#22260;&#20869;&#23450;&#20041;&#30340;&#19981;&#24688;&#24403;&#26680;&#20989;&#25968;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#24179;&#28369;&#34892;&#36208;&#26680;&#65292;&#23427;&#20135;&#29983;&#26080;&#38480;&#24179;&#28369;&#30340;&#26679;&#26412;&#65292;&#20197;&#21450;&#19968;&#31867;&#19981;&#24688;&#24403;&#30340;Matern&#26680;&#65292;&#23427;&#21487;&#20197;&#34987;&#23450;&#20041;&#20026;&#20219;&#24847;&#25972;&#25968;j&#20493;&#21487;&#24494;&#12290;&#25152;&#24471;&#21040;&#30340;&#21518;&#39564;&#20998;&#24067;&#21487;&#20197;&#29992;&#35299;&#26512;&#30340;&#26041;&#24335;&#35745;&#31639;&#20986;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes (GP) regression has gained substantial popularity in machine learning applications. The behavior of a GP regression depends on the choice of covariance function. Stationary covariance functions are favorite in machine learning applications. However, (non-periodic) stationary covariance functions are always mean reverting and can therefore exhibit pathological behavior when applied to data that does not relax to a fixed global mean value. In this paper, we show that it is possible to use improper GP prior with infinite variance to define processes that are stationary but not mean reverting. To this aim, we introduce a large class of improper kernels that can only be defined in this improper regime. Specifically, we introduce the Smooth Walk kernel, which produces infinitely smooth samples, and a family of improper Mat\'ern kernels, which can be defined to be $j$-times differentiable for any integer $j$. The resulting posterior distributions can be computed analyticall
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#22312;&#36941;&#21382;&#25968;&#25454;&#24207;&#21015;&#19978;&#35757;&#32451;&#26102;&#30340;&#26680;&#26497;&#38480;&#65292;&#21033;&#29992;&#25968;&#23398;&#26041;&#27861;&#23545;&#20854;&#28176;&#36817;&#29305;&#24615;&#36827;&#34892;&#20102;&#25551;&#36848;&#65292;&#24182;&#35777;&#26126;&#20102;RNN&#25910;&#25947;&#21040;&#19982;&#38543;&#26426;&#20195;&#25968;&#26041;&#31243;&#30340;&#19981;&#21160;&#28857;&#32806;&#21512;&#30340;&#26080;&#31351;&#32500;ODE&#30340;&#35299;&#12290;&#36825;&#23545;&#20110;&#29702;&#35299;&#21644;&#25913;&#36827;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2308.14555</link><description>&lt;p&gt;
&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#22312;&#36941;&#21382;&#25968;&#25454;&#24207;&#21015;&#19978;&#35757;&#32451;&#30340;&#26680;&#26497;&#38480;
&lt;/p&gt;
&lt;p&gt;
Kernel Limit of Recurrent Neural Networks Trained on Ergodic Data Sequences. (arXiv:2308.14555v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14555
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#22312;&#36941;&#21382;&#25968;&#25454;&#24207;&#21015;&#19978;&#35757;&#32451;&#26102;&#30340;&#26680;&#26497;&#38480;&#65292;&#21033;&#29992;&#25968;&#23398;&#26041;&#27861;&#23545;&#20854;&#28176;&#36817;&#29305;&#24615;&#36827;&#34892;&#20102;&#25551;&#36848;&#65292;&#24182;&#35777;&#26126;&#20102;RNN&#25910;&#25947;&#21040;&#19982;&#38543;&#26426;&#20195;&#25968;&#26041;&#31243;&#30340;&#19981;&#21160;&#28857;&#32806;&#21512;&#30340;&#26080;&#31351;&#32500;ODE&#30340;&#35299;&#12290;&#36825;&#23545;&#20110;&#29702;&#35299;&#21644;&#25913;&#36827;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#25968;&#23398;&#26041;&#27861;&#26469;&#25551;&#36848;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65288;RNN&#65289;&#30340;&#28176;&#36817;&#29305;&#24615;&#65292;&#20854;&#20013;&#38544;&#34255;&#21333;&#20803;&#30340;&#25968;&#37327;&#12289;&#24207;&#21015;&#20013;&#30340;&#25968;&#25454;&#26679;&#26412;&#12289;&#38544;&#34255;&#29366;&#24577;&#30340;&#26356;&#26032;&#21644;&#35757;&#32451;&#27493;&#39588;&#21516;&#26102;&#36235;&#20110;&#26080;&#31351;&#22823;&#12290;&#23545;&#20110;&#20855;&#26377;&#31616;&#21270;&#26435;&#37325;&#30697;&#38453;&#30340;RNN&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;RNN&#25910;&#25947;&#21040;&#19982;&#38543;&#26426;&#20195;&#25968;&#26041;&#31243;&#30340;&#19981;&#21160;&#28857;&#32806;&#21512;&#30340;&#26080;&#31351;&#32500;ODE&#30340;&#35299;&#12290;&#20998;&#26512;&#38656;&#35201;&#35299;&#20915;RNN&#25152;&#29305;&#26377;&#30340;&#20960;&#20010;&#25361;&#25112;&#12290;&#22312;&#20856;&#22411;&#30340;&#22343;&#22330;&#24212;&#29992;&#20013;&#65288;&#20363;&#22914;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#65289;&#65292;&#31163;&#25955;&#30340;&#26356;&#26032;&#37327;&#20026;$\mathcal{O}(\frac{1}{N})$&#65292;&#26356;&#26032;&#30340;&#27425;&#25968;&#20026;$\mathcal{O}(N)$&#12290;&#22240;&#27492;&#65292;&#31995;&#32479;&#21487;&#20197;&#34920;&#31034;&#20026;&#36866;&#24403;ODE/PDE&#30340;Euler&#36924;&#36817;&#65292;&#24403;$N \rightarrow \infty$&#26102;&#25910;&#25947;&#21040;&#35813;ODE/PDE&#12290;&#28982;&#32780;&#65292;RNN&#30340;&#38544;&#34255;&#23618;&#26356;&#26032;&#20026;$\mathcal{O}(1)$&#12290;&#22240;&#27492;&#65292;RNN&#19981;&#33021;&#34920;&#31034;&#20026;ODE/PDE&#30340;&#31163;&#25955;&#21270;&#21644;&#26631;&#20934;&#22343;&#22330;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mathematical methods are developed to characterize the asymptotics of recurrent neural networks (RNN) as the number of hidden units, data samples in the sequence, hidden state updates, and training steps simultaneously grow to infinity. In the case of an RNN with a simplified weight matrix, we prove the convergence of the RNN to the solution of an infinite-dimensional ODE coupled with the fixed point of a random algebraic equation. The analysis requires addressing several challenges which are unique to RNNs. In typical mean-field applications (e.g., feedforward neural networks), discrete updates are of magnitude $\mathcal{O}(\frac{1}{N})$ and the number of updates is $\mathcal{O}(N)$. Therefore, the system can be represented as an Euler approximation of an appropriate ODE/PDE, which it will converge to as $N \rightarrow \infty$. However, the RNN hidden layer updates are $\mathcal{O}(1)$. Therefore, RNNs cannot be represented as a discretization of an ODE/PDE and standard mean-field tec
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#34920;&#26126;&#65292;&#23545;&#20110;&#23398;&#20064;&#26576;&#20123;&#20809;&#28369;&#20989;&#25968;&#31867;&#65292;&#20855;&#26377;&#36866;&#24403;&#26435;&#37325;&#38480;&#21046;&#25110;&#27491;&#21017;&#21270;&#30340;&#36807;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#36798;&#21040;&#26368;&#23567;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;&#20316;&#32773;&#36890;&#36807;&#23545;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#25104;&#21151;&#35777;&#26126;&#22312;&#27973;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#20013;&#20351;&#29992;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#20540;&#26159;&#26368;&#23567;&#21270;&#26368;&#20248;&#30340;&#12290;&#21516;&#26102;&#20316;&#32773;&#36824;&#24471;&#20986;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#26412;&#22320;Rademacher&#22797;&#26434;&#24230;&#30340;&#19968;&#20010;&#26032;&#30340;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2306.08321</link><description>&lt;p&gt;
&#21033;&#29992;&#36807;&#21442;&#25968;&#21270;&#30340;&#27973;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Nonparametric regression using over-parameterized shallow ReLU neural networks. (arXiv:2306.08321v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08321
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#34920;&#26126;&#65292;&#23545;&#20110;&#23398;&#20064;&#26576;&#20123;&#20809;&#28369;&#20989;&#25968;&#31867;&#65292;&#20855;&#26377;&#36866;&#24403;&#26435;&#37325;&#38480;&#21046;&#25110;&#27491;&#21017;&#21270;&#30340;&#36807;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#36798;&#21040;&#26368;&#23567;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;&#20316;&#32773;&#36890;&#36807;&#23545;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#25104;&#21151;&#35777;&#26126;&#22312;&#27973;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#20013;&#20351;&#29992;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#20540;&#26159;&#26368;&#23567;&#21270;&#26368;&#20248;&#30340;&#12290;&#21516;&#26102;&#20316;&#32773;&#36824;&#24471;&#20986;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#26412;&#22320;Rademacher&#22797;&#26434;&#24230;&#30340;&#19968;&#20010;&#26032;&#30340;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#26524;&#26435;&#37325;&#24471;&#21040;&#21512;&#36866;&#30340;&#38480;&#21046;&#25110;&#27491;&#21017;&#21270;&#65292;&#37027;&#20040;&#21487;&#20197;&#35777;&#26126;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#36798;&#21040;&#26576;&#20123;&#20809;&#28369;&#20989;&#25968;&#31867;&#30340;&#23398;&#20064;&#26368;&#23567;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#65288;&#26368;&#22810;&#23545;&#25968;&#22240;&#25968;&#65289;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#27973;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#26469;&#20272;&#35745;&#26410;&#30693;&#30340;$d$&#21464;&#37327;&#20989;&#25968;&#12290;&#20551;&#35774;&#22238;&#24402;&#20989;&#25968;&#26159;&#20174;&#20855;&#26377;&#20809;&#28369;&#24230;$\alpha &lt; (d+3)/2$&#30340;Holder&#31354;&#38388;&#25110;&#23545;&#24212;&#20110;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#21464;&#21270;&#31354;&#38388;&#20013;&#23398;&#20064;&#30340;&#65292;&#21518;&#32773;&#21487;&#20197;&#35270;&#20026;&#26080;&#38480;&#23485;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22522;&#20110;&#20855;&#26377;&#26435;&#37325;&#26576;&#20123;&#33539;&#25968;&#32422;&#26463;&#30340;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#20540;&#26159;&#26368;&#23567;&#21270;&#26368;&#20248;&#30340;&#65292;&#22914;&#26524;&#32593;&#32476;&#23485;&#24230;&#36275;&#22815;&#22823;&#12290;&#20316;&#20026;&#21103;&#20135;&#21697;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#19968;&#20010;&#26032;&#30340;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#26412;&#22320;Rademacher&#22797;&#26434;&#24230;&#26080;&#20851;&#30340;&#19978;&#30028;&#65292;&#36825;&#21487;&#33021;&#26159;&#26377;&#29420;&#31435;&#20852;&#36259;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is shown that over-parameterized neural networks can achieve minimax optimal rates of convergence (up to logarithmic factors) for learning functions from certain smooth function classes, if the weights are suitably constrained or regularized. Specifically, we consider the nonparametric regression of estimating an unknown $d$-variate function by using shallow ReLU neural networks. It is assumed that the regression function is from the H\"older space with smoothness $\alpha&lt;(d+3)/2$ or a variation space corresponding to shallow neural networks, which can be viewed as an infinitely wide neural network. In this setting, we prove that least squares estimators based on shallow neural networks with certain norm constraints on the weights are minimax optimal, if the network width is sufficiently large. As a byproduct, we derive a new size-independent bound for the local Rademacher complexity of shallow ReLU neural networks, which may be of independent interest.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#28145;&#20837;&#30740;&#31350;&#21644;&#25551;&#36848;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#30340;&#20989;&#25968;&#30340;Lipschitz&#34892;&#20026;&#65292;&#22312;&#22810;&#31181;&#35774;&#32622;&#19979;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#65292;&#24182;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#20989;&#25968;Lipschitz&#36830;&#32493;&#24615;&#30340;&#22522;&#26412;&#21644;&#26377;&#36259;&#30340;&#29305;&#24615;&#65292;&#20854;&#20013;&#26368;&#24341;&#20154;&#27880;&#30446;&#30340;&#26159;&#22312;Lipschitz&#24120;&#25968;&#30340;&#19978;&#38480;&#21644;&#19979;&#38480;&#20013;&#35782;&#21035;&#20986;&#20102;&#26126;&#26174;&#30340;&#21452;&#19979;&#38477;&#36235;&#21183;&#12290;</title><link>http://arxiv.org/abs/2302.10886</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20989;&#25968;&#30340;Lipschitz&#36830;&#32493;&#24615;&#30340;&#19968;&#20123;&#22522;&#26412;&#26041;&#38754;
&lt;/p&gt;
&lt;p&gt;
Some Fundamental Aspects about Lipschitz Continuity of Neural Network Functions. (arXiv:2302.10886v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10886
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#28145;&#20837;&#30740;&#31350;&#21644;&#25551;&#36848;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#30340;&#20989;&#25968;&#30340;Lipschitz&#34892;&#20026;&#65292;&#22312;&#22810;&#31181;&#35774;&#32622;&#19979;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#65292;&#24182;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#20989;&#25968;Lipschitz&#36830;&#32493;&#24615;&#30340;&#22522;&#26412;&#21644;&#26377;&#36259;&#30340;&#29305;&#24615;&#65292;&#20854;&#20013;&#26368;&#24341;&#20154;&#27880;&#30446;&#30340;&#26159;&#22312;Lipschitz&#24120;&#25968;&#30340;&#19978;&#38480;&#21644;&#19979;&#38480;&#20013;&#35782;&#21035;&#20986;&#20102;&#26126;&#26174;&#30340;&#21452;&#19979;&#38477;&#36235;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Lipschitz&#36830;&#32493;&#24615;&#26159;&#20219;&#20309;&#39044;&#27979;&#27169;&#22411;&#30340;&#19968;&#20010;&#31616;&#21333;&#20294;&#20851;&#38190;&#30340;&#21151;&#33021;&#24615;&#36136;&#65292;&#23427;&#22788;&#20110;&#27169;&#22411;&#30340;&#31283;&#20581;&#24615;&#12289;&#27867;&#21270;&#24615;&#21644;&#23545;&#25239;&#24615;&#33030;&#24369;&#24615;&#30340;&#26680;&#24515;&#12290;&#26412;&#25991;&#26088;&#22312;&#28145;&#20837;&#30740;&#31350;&#21644;&#25551;&#36848;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#30340;&#20989;&#25968;&#30340;Lipschitz&#34892;&#20026;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#36890;&#36807;&#32791;&#23613;&#26368;&#31616;&#21333;&#21644;&#26368;&#19968;&#33324;&#30340;&#19979;&#38480;&#21644;&#19978;&#38480;&#30340;&#26497;&#38480;&#65292;&#22312;&#21508;&#31181;&#19981;&#21516;&#35774;&#32622;&#19979;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#65288;&#21363;&#65292;&#20307;&#31995;&#32467;&#26500;&#12289;&#25439;&#22833;&#12289;&#20248;&#21270;&#22120;&#12289;&#26631;&#31614;&#22122;&#38899;&#31561;&#65289;&#65292;&#34429;&#28982;&#36825;&#19968;&#36873;&#25321;&#20027;&#35201;&#26159;&#21463;&#35745;&#31639;&#38590;&#24230;&#32467;&#26524;&#30340;&#39537;&#21160;&#65292;&#20294;&#23427;&#20063;&#38750;&#24120;&#20016;&#23500;&#65292;&#24182;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#20989;&#25968;Lipschitz&#36830;&#32493;&#24615;&#30340;&#20960;&#20010;&#22522;&#26412;&#21644;&#26377;&#36259;&#30340;&#29305;&#24615;&#65292;&#25105;&#20204;&#36824;&#34917;&#20805;&#20102;&#36866;&#24403;&#30340;&#29702;&#35770;&#35770;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lipschitz continuity is a simple yet crucial functional property of any predictive model for it lies at the core of the model's robustness, generalisation, as well as adversarial vulnerability. Our aim is to thoroughly investigate and characterise the Lipschitz behaviour of the functions realised by neural networks. Thus, we carry out an empirical investigation in a range of different settings (namely, architectures, losses, optimisers, label noise, and more) by exhausting the limits of the simplest and the most general lower and upper bounds. Although motivated primarily by computational hardness results, this choice nevertheless turns out to be rather resourceful and sheds light on several fundamental and intriguing traits of the Lipschitz continuity of neural network functions, which we also supplement with suitable theoretical arguments. As a highlight of this investigation, we identify a striking double descent trend in both upper and lower bounds to the Lipschitz constant with in
&lt;/p&gt;</description></item></channel></rss>