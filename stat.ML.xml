<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22240;&#26524;&#24402;&#19968;&#21270;&#27969;&#36827;&#34892;&#22240;&#26524;&#25512;&#35770;&#30340;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#22312;&#32473;&#23450;&#22240;&#26524;&#25490;&#24207;&#24773;&#20917;&#19979;&#65292;&#21033;&#29992;&#33258;&#22238;&#24402;&#24402;&#19968;&#21270;&#27969;&#21487;&#20197;&#24674;&#22797;&#22240;&#26524;&#27169;&#22411;&#12290;&#36890;&#36807;&#23454;&#39564;&#21644;&#27604;&#36739;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#22240;&#26524;&#24402;&#19968;&#21270;&#27969;&#21487;&#29992;&#20110;&#35299;&#20915;&#23454;&#38469;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.05415</link><description>&lt;p&gt;
&#22240;&#26524;&#24402;&#19968;&#21270;&#27969;&#65306;&#20174;&#29702;&#35770;&#21040;&#23454;&#36341;
&lt;/p&gt;
&lt;p&gt;
Causal normalizing flows: from theory to practice. (arXiv:2306.05415v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05415
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22240;&#26524;&#24402;&#19968;&#21270;&#27969;&#36827;&#34892;&#22240;&#26524;&#25512;&#35770;&#30340;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#22312;&#32473;&#23450;&#22240;&#26524;&#25490;&#24207;&#24773;&#20917;&#19979;&#65292;&#21033;&#29992;&#33258;&#22238;&#24402;&#24402;&#19968;&#21270;&#27969;&#21487;&#20197;&#24674;&#22797;&#22240;&#26524;&#27169;&#22411;&#12290;&#36890;&#36807;&#23454;&#39564;&#21644;&#27604;&#36739;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#22240;&#26524;&#24402;&#19968;&#21270;&#27969;&#21487;&#29992;&#20110;&#35299;&#20915;&#23454;&#38469;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#28145;&#20837;&#25506;&#35752;&#20102;&#21033;&#29992;&#24402;&#19968;&#21270;&#27969;&#36827;&#34892;&#22240;&#26524;&#25512;&#35770;&#30340;&#24212;&#29992;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#39318;&#20808;&#21033;&#29992;&#38750;&#32447;&#24615;ICA&#30340;&#26368;&#26032;&#32467;&#26524;&#65292;&#26174;&#31034;&#20986;&#22312;&#32473;&#23450;&#22240;&#26524;&#25490;&#24207;&#30340;&#24773;&#20917;&#19979;&#65292;&#22240;&#26524;&#27169;&#22411;&#21487;&#20197;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#37492;&#21035;&#20986;&#26469;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#33258;&#22238;&#24402;&#24402;&#19968;&#21270;&#27969;&#36827;&#34892;&#24674;&#22797;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#29992;&#20110;&#25429;&#25417;&#28508;&#22312;&#22240;&#26524;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#19981;&#21516;&#35774;&#35745;&#21644;&#23398;&#20064;&#36873;&#25321;&#30340;&#22240;&#26524;&#24402;&#19968;&#21270;&#27969;&#12290;&#31532;&#19977;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#22914;&#20309;&#22312;&#22240;&#26524;&#24402;&#19968;&#21270;&#27969;&#20013;&#23454;&#29616;do-operator&#65292;&#20174;&#32780;&#22238;&#31572;&#24178;&#39044;&#21644;&#21453;&#20107;&#23454;&#38382;&#39064;&#12290;&#26368;&#21518;&#65292;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#32508;&#21512;&#23545;&#27604;&#30740;&#31350;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#35774;&#35745;&#21644;&#35757;&#32451;&#36873;&#25321;&#65307;&#23558;&#22240;&#26524;&#24402;&#19968;&#21270;&#27969;&#19982;&#20854;&#20182;&#36924;&#36817;&#22240;&#26524;&#27169;&#22411;&#30340;&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#65307;&#24182;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#35777;&#26126;&#22240;&#26524;&#24402;&#19968;&#21270;&#27969;&#21487;&#29992;&#20110;&#35299;&#20915;&#29616;&#23454;&#19990;&#30028;&#20013;&#23384;&#22312;&#28151;&#21512;&#31163;&#25955;&#36830;&#32493;&#25968;&#25454;&#21644;&#22240;&#26524;&#22270;&#37096;&#20998;&#30693;&#35782;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#30340;&#20195;&#30721;&#21487;&#20197;&#36827;&#34892;&#35775;&#38382;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we deepen on the use of normalizing flows for causal reasoning. Specifically, we first leverage recent results on non-linear ICA to show that causal models are identifiable from observational data given a causal ordering, and thus can be recovered using autoregressive normalizing flows (NFs). Second, we analyze different design and learning choices for causal normalizing flows to capture the underlying causal data-generating process. Third, we describe how to implement the do-operator in causal NFs, and thus, how to answer interventional and counterfactual questions. Finally, in our experiments, we validate our design and training choices through a comprehensive ablation study; compare causal NFs to other approaches for approximating causal models; and empirically demonstrate that causal NFs can be used to address real-world problems, where the presence of mixed discrete-continuous data and partial knowledge on the causal graph is the norm. The code for this work can be f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#22312;&#25991;&#26412;&#25968;&#25454;&#19978;&#23545;&#24615;&#21035;&#27495;&#35270;&#30340;&#20559;&#35265;&#30340;&#24230;&#37327;&#26631;&#20934;&#30340;&#23616;&#38480;&#24615;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2306.05307</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#20844;&#24179;&#24230;&#25351;&#26631;&#35780;&#20272;&#27495;&#35270;&#20559;&#24046;&#26159;&#21542;&#36275;&#22815;&#65311;
&lt;/p&gt;
&lt;p&gt;
Are fairness metric scores enough to assess discrimination biases in machine learning?. (arXiv:2306.05307v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05307
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#22312;&#25991;&#26412;&#25968;&#25454;&#19978;&#23545;&#24615;&#21035;&#27495;&#35270;&#30340;&#20559;&#35265;&#30340;&#24230;&#37327;&#26631;&#20934;&#30340;&#23616;&#38480;&#24615;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#26032;&#30340;&#23454;&#39564;&#65292;&#25581;&#31034;&#20102;&#24403;&#21069;&#29992;&#20110;&#35780;&#20272;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#22312;&#25991;&#26412;&#25968;&#25454;&#19978;&#23545;&#24615;&#21035;&#27495;&#35270;&#30340;&#20559;&#35265;&#30340;&#24230;&#37327;&#26631;&#20934;&#30340;&#23616;&#38480;&#24615;&#12290;&#25105;&#20204;&#20197;Bios&#25968;&#25454;&#38598;&#20026;&#20363;&#65292;&#23398;&#20064;&#39044;&#27979;&#20010;&#20154;&#30340;&#32844;&#19994;&#12290;&#36825;&#31181;&#39044;&#27979;&#20219;&#21153;&#22312;&#21830;&#19994;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#24212;&#29992;&#31243;&#24207;&#20013;&#24456;&#24120;&#35265;&#65292;&#20363;&#22914;&#33258;&#21160;&#24037;&#20316;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents novel experiments shedding light on the shortcomings of current metrics for assessing biases of gender discrimination made by machine learning algorithms on textual data. We focus on the Bios dataset, and our learning task is to predict the occupation of individuals, based on their biography. Such prediction tasks are common in commercial Natural Language Processing (NLP) applications such as automatic job recommendations. We address an important limitation of theoretical discussions dealing with group-wise fairness metrics: they focus on large datasets, although the norm in many industrial NLP applications is to use small to reasonably large linguistic datasets for which the main practical constraint is to get a good prediction accuracy. We then question how reliable are different popular measures of bias when the size of the training set is simply sufficient to learn reasonably accurate predictions. Our experiments sample the Bios dataset and learn more than 200 m
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#36890;&#29992;&#30340;&#22823;&#35268;&#27169;&#21644;&#28508;&#22312;&#26410;&#30693;&#22270;&#19978;&#23450;&#20041;&#20989;&#25968;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#23398;&#20064;&#36866;&#24403;&#30340;&#22270;&#20869;&#26680;&#65292;&#36866;&#24212;&#30446;&#26631;&#20989;&#25968;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2306.05304</link><description>&lt;p&gt;
&#22270;&#19978;&#20989;&#25968;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Bayesian Optimisation of Functions on Graphs. (arXiv:2306.05304v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05304
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#36890;&#29992;&#30340;&#22823;&#35268;&#27169;&#21644;&#28508;&#22312;&#26410;&#30693;&#22270;&#19978;&#23450;&#20041;&#20989;&#25968;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#23398;&#20064;&#36866;&#24403;&#30340;&#22270;&#20869;&#26680;&#65292;&#36866;&#24212;&#30446;&#26631;&#20989;&#25968;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#32467;&#26500;&#25968;&#25454;&#30340;&#19981;&#26029;&#28044;&#29616;&#25512;&#21160;&#20102;&#22312;&#22270;&#33410;&#28857;&#38598;&#19978;&#23450;&#20041;&#20989;&#25968;&#30340;&#20248;&#21270;&#20219;&#21153;&#12290;&#20256;&#32479;&#30340;&#22270;&#25628;&#32034;&#31639;&#27861;&#21487;&#29992;&#20110;&#27492;&#65292;&#20294;&#23427;&#20204;&#21487;&#33021;&#26679;&#26412;&#25928;&#29575;&#20302;&#19979;&#65292;&#24182;&#19988;&#19981;&#21033;&#29992;&#20851;&#20110;&#20989;&#25968;&#20540;&#30340;&#20449;&#24687;&#65307;&#21478;&#19968;&#26041;&#38754;&#65292;&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31867;&#26377;&#21069;&#36884;&#30340;&#40657;&#30418;&#27714;&#35299;&#22120;&#65292;&#20855;&#26377;&#26356;&#39640;&#30340;&#26679;&#26412;&#25928;&#29575;&#65292;&#20294;&#23427;&#24456;&#23569;&#34987;&#24212;&#29992;&#20110;&#36825;&#26679;&#30340;&#26032;&#39062;&#35774;&#32622;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#20248;&#21270;&#22312;&#36890;&#29992;&#65292;&#22823;&#35268;&#27169;&#21644;&#28508;&#22312;&#30340;&#26410;&#30693;&#22270;&#19978;&#23450;&#20041;&#30340;&#20989;&#25968;&#12290;&#36890;&#36807;&#23398;&#20064;&#36866;&#24403;&#30340;&#22270;&#20869;&#26680;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#20855;&#26377;&#36866;&#24212;&#30446;&#26631;&#20989;&#25968;&#34892;&#20026;&#30340;&#20248;&#28857;&#12290;&#23616;&#37096;&#24314;&#27169;&#26041;&#27861;&#36827;&#19968;&#27493;&#20445;&#35777;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#25928;&#29575;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#22270;&#19978;&#30340;&#22823;&#37327;&#23454;&#39564;&#34920;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#20248;&#21270;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The increasing availability of graph-structured data motivates the task of optimising over functions defined on the node set of graphs. Traditional graph search algorithms can be applied in this case, but they may be sample-inefficient and do not make use of information about the function values; on the other hand, Bayesian optimisation is a class of promising black-box solvers with superior sample efficiency, but it has been scarcely been applied to such novel setups. To fill this gap, we propose a novel Bayesian optimisation framework that optimises over functions defined on generic, large-scale and potentially unknown graphs. Through the learning of suitable kernels on graphs, our framework has the advantage of adapting to the behaviour of the target function. The local modelling approach further guarantees the efficiency of our method. Extensive experiments on both synthetic and real-world graphs demonstrate the effectiveness of the proposed optimisation framework.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#29992;&#25143;&#32423;&#24046;&#20998;&#38544;&#31169;&#30340;&#32852;&#37030;&#32447;&#24615;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#65292;&#20026;CDP&#25552;&#20986;&#20102;&#36817;&#20046;&#26368;&#20248;&#30340;&#32852;&#37030;&#31639;&#27861;\robin&#65292;&#22312;LDP&#19979;&#35777;&#26126;&#20102;&#23398;&#20064;&#24517;&#39035;&#25215;&#21463;&#33267;&#23569;&#19968;&#20010;&#36951;&#25022;&#33192;&#32960;&#22240;&#23376;&#12290;</title><link>http://arxiv.org/abs/2306.05275</link><description>&lt;p&gt;
&#24102;&#26377;&#29992;&#25143;&#32423;&#24046;&#20998;&#38544;&#31169;&#30340;&#32852;&#37030;&#32447;&#24615;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Federated Linear Contextual Bandits with User-level Differential Privacy. (arXiv:2306.05275v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05275
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#29992;&#25143;&#32423;&#24046;&#20998;&#38544;&#31169;&#30340;&#32852;&#37030;&#32447;&#24615;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#65292;&#20026;CDP&#25552;&#20986;&#20102;&#36817;&#20046;&#26368;&#20248;&#30340;&#32852;&#37030;&#31639;&#27861;\robin&#65292;&#22312;LDP&#19979;&#35777;&#26126;&#20102;&#23398;&#20064;&#24517;&#39035;&#25215;&#21463;&#33267;&#23569;&#19968;&#20010;&#36951;&#25022;&#33192;&#32960;&#22240;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#29992;&#25143;&#32423;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#27010;&#24565;&#19979;&#30340;&#32852;&#37030;&#32447;&#24615;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#12290;&#25105;&#20204;&#39318;&#20808;&#20171;&#32461;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#32852;&#37030;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#36866;&#24212;&#39034;&#24207;&#20915;&#31574;&#35774;&#32622;&#20013;DP&#30340;&#21508;&#31181;&#23450;&#20041;&#12290;&#28982;&#21518;&#22312;&#32852;&#37030;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#20013;&#27491;&#24335;&#24341;&#20837;&#20102;&#29992;&#25143;&#32423;&#20013;&#24515;DP&#21644;&#26412;&#22320;DP&#65292;&#24182;&#30740;&#31350;&#20102;&#32852;&#37030;&#32447;&#24615;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#20013;&#23398;&#20064;&#36951;&#25022;&#21644;&#30456;&#24212;DP&#20445;&#35777;&#20043;&#38388;&#30340;&#22522;&#26412;&#26435;&#34913;&#12290;&#23545;&#20110;CDP&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;\robin&#30340;&#32852;&#37030;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#25512;&#23548;&#22312;&#28385;&#36275;&#29992;&#25143;&#32423;DP&#26102;&#30340;&#20960;&#20046;&#21305;&#37197;&#30340;&#19978;&#30028;&#21644;&#19979;&#30028;&#36951;&#25022;&#30028;&#65292;&#35777;&#26126;&#20854;&#22312;&#23458;&#25143;&#31471;&#25968;&#37327;$M$&#21644;&#38544;&#31169;&#39044;&#31639;$\varepsilon$&#26041;&#38754;&#26159;&#36817;&#20046;&#26368;&#20248;&#30340;&#12290;&#23545;&#20110;LDP&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#20960;&#20010;&#19979;&#30028;&#65292;&#34920;&#26126;&#22312;&#29992;&#25143;&#32423;$(\varepsilon,\delta)$-LDP&#19979;&#23398;&#20064;&#24517;&#39035;&#33267;&#23569;&#25215;&#21463;&#19968;&#20010;&#36951;&#25022;&#33192;&#32960;&#22240;&#23376;&#33267;&#23569;&#20026;{$\min\{1/\varepsilon,M\}$&#25110;$\min\{1/\sqrt{\varepsilon},\sq
&lt;/p&gt;
&lt;p&gt;
This paper studies federated linear contextual bandits under the notion of user-level differential privacy (DP). We first introduce a unified federated bandits framework that can accommodate various definitions of DP in the sequential decision-making setting. We then formally introduce user-level central DP (CDP) and local DP (LDP) in the federated bandits framework, and investigate the fundamental trade-offs between the learning regrets and the corresponding DP guarantees in a federated linear contextual bandits model. For CDP, we propose a federated algorithm termed as \robin and show that it is near-optimal in terms of the number of clients $M$ and the privacy budget $\varepsilon$ by deriving nearly-matching upper and lower regret bounds when user-level DP is satisfied. For LDP, we obtain several lower bounds, indicating that learning under user-level $(\varepsilon,\delta)$-LDP must suffer a regret blow-up factor at least {$\min\{1/\varepsilon,M\}$ or $\min\{1/\sqrt{\varepsilon},\sq
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#34920;&#36798;&#24418;&#24335;&#65292;&#29992;&#20110;&#25551;&#36848;&#20855;&#26377;&#26230;&#20307;&#23545;&#31216;&#24615;&#30340;&#20989;&#25968;&#12290;&#32447;&#24615;&#34920;&#36798;&#24418;&#24335;&#25552;&#20379;&#20102;&#26230;&#20307;&#23545;&#31216;&#24615;&#19979;&#30340;&#22522;&#20989;&#25968;&#65292;&#32780;&#38750;&#32447;&#24615;&#34920;&#36798;&#23558;&#36712;&#36947;&#31354;&#38388;&#23884;&#20837;&#21040;&#26377;&#38480;&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#36827;&#34892;&#25551;&#36848;&#12290;</title><link>http://arxiv.org/abs/2306.05261</link><description>&lt;p&gt;
&#25551;&#36848;&#21644;&#23398;&#20064;&#26230;&#20307;&#23545;&#31216;&#32676;&#19979;&#19981;&#21464;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Representing and Learning Functions Invariant Under Crystallographic Groups. (arXiv:2306.05261v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05261
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#34920;&#36798;&#24418;&#24335;&#65292;&#29992;&#20110;&#25551;&#36848;&#20855;&#26377;&#26230;&#20307;&#23545;&#31216;&#24615;&#30340;&#20989;&#25968;&#12290;&#32447;&#24615;&#34920;&#36798;&#24418;&#24335;&#25552;&#20379;&#20102;&#26230;&#20307;&#23545;&#31216;&#24615;&#19979;&#30340;&#22522;&#20989;&#25968;&#65292;&#32780;&#38750;&#32447;&#24615;&#34920;&#36798;&#23558;&#36712;&#36947;&#31354;&#38388;&#23884;&#20837;&#21040;&#26377;&#38480;&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#36827;&#34892;&#25551;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26230;&#20307;&#23545;&#31216;&#32676;&#25551;&#36848;&#20102;&#33258;&#28982;&#21644;&#31185;&#23398;&#20013;&#36935;&#21040;&#30340;&#26230;&#20307;&#21644;&#20854;&#20182;&#37325;&#22797;&#32467;&#26500;&#30340;&#23545;&#31216;&#24615;&#12290;&#26412;&#25991;&#25512;&#23548;&#20986;&#20989;&#25968;&#30340;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#34920;&#31034;&#24418;&#24335;&#65292;&#36825;&#20123;&#20989;&#25968;&#21516;&#26102;&#20855;&#26377;&#65288;1&#65289;&#24179;&#28369;&#21644;&#65288;2&#65289;&#22312;&#27492;&#31867;&#32676;&#19979;&#19981;&#21464;&#30340;&#29305;&#24615;&#12290;&#32447;&#24615;&#34920;&#31034;&#23558;&#20613;&#37324;&#21494;&#22522;&#24191;&#20041;&#21270;&#20026;&#20855;&#26377;&#26230;&#20307;&#23545;&#31216;&#24615;&#30340;&#22522;&#20989;&#25968;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#22522;&#20989;&#25968;&#23545;&#20110;&#27599;&#20010;&#26230;&#20307;&#23545;&#31216;&#32676;&#37117;&#23384;&#22312;&#65292;&#23545;&#24212;$L_2$&#31354;&#38388;&#20855;&#26377;&#27491;&#20132;&#24615;&#65292;&#22312;&#32431;&#24179;&#31227;&#32676;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#24674;&#22797;&#20026;&#26631;&#20934;&#20613;&#37324;&#21494;&#22522;&#12290;&#38750;&#32447;&#24615;&#34920;&#31034;&#23558;&#35813;&#32676;&#30340;&#36712;&#36947;&#31354;&#38388;&#23884;&#20837;&#21040;&#26377;&#38480;&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#27599;&#20010;&#26230;&#20307;&#23545;&#31216;&#32676;&#37117;&#23384;&#22312;&#36825;&#26679;&#30340;&#23884;&#20837;&#65292;&#32780;&#19988;&#36825;&#20010;&#23884;&#20837;&#36890;&#36807;&#19968;&#20010;&#31216;&#20026;&#36712;&#31215;&#27969;&#24418;&#30340;&#27969;&#24418;&#30340;&#24191;&#20041;&#21270;&#20989;&#25968;&#22240;&#23376;&#21270;&#12290;&#25105;&#20204;&#36824;&#25551;&#36848;&#20102;&#19968;&#20123;&#31639;&#27861;&#65292;&#21487;&#20197;&#26681;&#25454;&#35813;&#32676;&#30340;&#26631;&#20934;&#25551;&#36848;&#35745;&#31639;&#20986;&#20613;&#37324;&#21494;&#22522;&#21644;&#23884;&#20837;&#26144;&#23556;&#12290;
&lt;/p&gt;
&lt;p&gt;
Crystallographic groups describe the symmetries of crystals and other repetitive structures encountered in nature and the sciences. These groups include the wallpaper and space groups. We derive linear and nonlinear representations of functions that are (1) smooth and (2) invariant under such a group. The linear representation generalizes the Fourier basis to crystallographically invariant basis functions. We show that such a basis exists for each crystallographic group, that it is orthonormal in the relevant $L_2$ space, and recover the standard Fourier basis as a special case for pure shift groups. The nonlinear representation embeds the orbit space of the group into a finite-dimensional Euclidean space. We show that such an embedding exists for every crystallographic group, and that it factors functions through a generalization of a manifold called an orbifold. We describe algorithms that, given a standardized description of the group, compute the Fourier basis and an embedding map.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#36890;&#36807;&#20445;&#24207;&#22238;&#24402;&#36827;&#34892;&#37325;&#26032;&#26657;&#20934;&#20250;&#24341;&#36215;&#20998;&#23618;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#36825;&#21487;&#33021;&#20250;&#23545;&#22522;&#20110;&#31665;&#24335;&#20998;&#24067;&#30340;&#26657;&#20934;&#35823;&#24046;&#32479;&#35745;&#36896;&#25104;&#37325;&#22823;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2306.05180</link><description>&lt;p&gt;
&#36890;&#36807;&#20445;&#24207;&#22238;&#24402;&#37325;&#26032;&#26657;&#20934;&#30340;&#19981;&#30830;&#23450;&#24615;&#20998;&#23618;&#21450;&#20854;&#23545;&#26657;&#20934;&#35823;&#24046;&#32479;&#35745;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Stratification of uncertainties recalibrated by isotonic regression and its impact on calibration error statistics. (arXiv:2306.05180v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05180
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#36890;&#36807;&#20445;&#24207;&#22238;&#24402;&#36827;&#34892;&#37325;&#26032;&#26657;&#20934;&#20250;&#24341;&#36215;&#20998;&#23618;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#36825;&#21487;&#33021;&#20250;&#23545;&#22522;&#20110;&#31665;&#24335;&#20998;&#24067;&#30340;&#26657;&#20934;&#35823;&#24046;&#32479;&#35745;&#36896;&#25104;&#37325;&#22823;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25353;&#29031;&#20445;&#24207;&#22238;&#24402;&#30340;&#26041;&#24335;&#23545;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#38382;&#39064;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#20107;&#21518;&#37325;&#26657;&#20934;&#65292;&#21487;&#33021;&#20250;&#23545;&#22522;&#20110;&#31665;&#24335;&#20998;&#24067;&#30340;&#26657;&#20934;&#35823;&#24046;&#32479;&#35745;&#65288;&#20363;&#22914;ENCE&#65289;&#36896;&#25104;&#38382;&#39064;&#12290;&#20445;&#24207;&#22238;&#24402;&#32463;&#24120;&#20135;&#29983;&#20998;&#23618;&#19981;&#30830;&#23450;&#24615;&#65292;&#21363;&#20855;&#26377;&#30456;&#21516;&#25968;&#20540;&#30340;&#19981;&#30830;&#23450;&#24615;&#23376;&#38598;&#12290;&#23558;&#20998;&#23618;&#25968;&#25454;&#20998;&#25104;&#30456;&#31561;&#22823;&#23567;&#30340;&#31665;&#26102;&#65292;&#23558;&#24341;&#20837;&#19968;&#20010;&#38543;&#26426;&#32452;&#20998;&#26469;&#20272;&#35745;&#22522;&#20110;&#31665;&#24335;&#20998;&#24067;&#30340;&#26657;&#20934;&#32479;&#35745;&#37327;&#12290;&#20998;&#23618;&#25968;&#25454;&#30340;&#31665;&#20998;&#21306;&#21462;&#20915;&#20110;&#25968;&#25454;&#30340;&#39034;&#24207;&#65292;&#36825;&#36890;&#24120;&#26159;&#26657;&#20934;&#27979;&#35797;/&#39564;&#35777;&#38598;&#30340;&#19968;&#20010;&#19981;&#21463;&#25511;&#21046;&#30340;&#23646;&#24615;&#12290;&#29992;&#20110;&#20998;&#27573;&#30340;&#25490;&#24207;&#31639;&#27861;&#30340;&#25554;&#20540;&#26041;&#27861;&#20063;&#21487;&#33021;&#24341;&#20837;&#38543;&#26426;&#32452;&#20998;&#12290;&#25105;&#22312;&#19968;&#20010;&#31034;&#20363;&#20013;&#23637;&#31034;&#20102;&#36825;&#21487;&#33021;&#22914;&#20309;&#26174;&#30528;&#24433;&#21709;&#26657;&#20934;&#35786;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Abstract Post hoc recalibration of prediction uncertainties of machine learning regression problems by isotonic regression might present a problem for bin-based calibration error statistics (e.g. ENCE). Isotonic regression often produces stratified uncertainties, i.e. subsets of uncertainties with identical numerical values. Partitioning of the resulting data into equal-sized bins introduces an aleatoric component to the estimation of bin-based calibration statistics. The partitioning of stratified data into bins depends on the order of the data, which is typically an uncontrolled property of calibration test/validation sets. The tie-braking method of the ordering algorithm used for binning might also introduce an aleatoric component. I show on an example how this might significantly affect the calibration diagnostics.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#20301;&#25968;&#22238;&#24402;&#30340;&#26032;&#22411;&#32852;&#37030;&#21512;&#35268;&#24615;&#39044;&#27979;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#37325;&#35201;&#24615;&#21152;&#26435;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#20195;&#29702;&#20043;&#38388;&#30340;&#26631;&#31614;&#28418;&#31227;&#38382;&#39064;&#65292;&#24182;&#20026;&#39044;&#27979;&#38598;&#30340;&#26377;&#25928;&#35206;&#30422;&#21644;&#24046;&#20998;&#38544;&#31169;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#30446;&#21069;&#30340;&#31454;&#20105;&#23545;&#25163;&#12290;</title><link>http://arxiv.org/abs/2306.05131</link><description>&lt;p&gt;
&#38754;&#21521;&#26631;&#31614;&#28418;&#31227;&#30340;&#32852;&#37030;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#21512;&#35268;&#24615;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Conformal Prediction for Federated Uncertainty Quantification Under Label Shift. (arXiv:2306.05131v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05131
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#20301;&#25968;&#22238;&#24402;&#30340;&#26032;&#22411;&#32852;&#37030;&#21512;&#35268;&#24615;&#39044;&#27979;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#37325;&#35201;&#24615;&#21152;&#26435;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#20195;&#29702;&#20043;&#38388;&#30340;&#26631;&#31614;&#28418;&#31227;&#38382;&#39064;&#65292;&#24182;&#20026;&#39044;&#27979;&#38598;&#30340;&#26377;&#25928;&#35206;&#30422;&#21644;&#24046;&#20998;&#38544;&#31169;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#30446;&#21069;&#30340;&#31454;&#20105;&#23545;&#25163;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#26159;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#35768;&#22810;&#23458;&#25143;&#31471;&#21327;&#20316;&#35757;&#32451;&#27169;&#22411;&#65292;&#21516;&#26102;&#20445;&#25345;&#35757;&#32451;&#25968;&#25454;&#20998;&#25955;&#12290;&#23613;&#31649;&#36817;&#24180;&#26469;&#22312;FL&#26041;&#38754;&#21462;&#24471;&#20102;&#36827;&#23637;&#65292;&#20294;&#26410;&#23545;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#20027;&#39064;&#65288;UQ&#65289;&#36827;&#34892;&#37096;&#20998;&#22788;&#29702;&#12290;&#22312;UQ&#26041;&#27861;&#20013;&#65292;&#21512;&#35268;&#24615;&#39044;&#27979;&#65288;CP&#65289;&#26041;&#27861;&#22312;&#26368;&#23567;&#20551;&#35774;&#19979;&#25552;&#20379;&#26080;&#20998;&#24067;&#20445;&#35777;&#12290;&#25105;&#20204;&#22522;&#20110;&#20998;&#20301;&#25968;&#22238;&#24402;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#32852;&#37030;&#21512;&#35268;&#24615;&#39044;&#27979;&#26041;&#27861;&#65292;&#24182;&#32771;&#34385;&#20102;&#38544;&#31169;&#32422;&#26463;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#37325;&#35201;&#24615;&#21152;&#26435;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#20195;&#29702;&#20043;&#38388;&#30340;&#26631;&#31614;&#28418;&#31227;&#38382;&#39064;&#65292;&#24182;&#20026;&#39044;&#27979;&#38598;&#30340;&#26377;&#25928;&#35206;&#30422;&#21644;&#24046;&#20998;&#38544;&#31169;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#30446;&#21069;&#30340;&#31454;&#20105;&#23545;&#25163;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated Learning (FL) is a machine learning framework where many clients collaboratively train models while keeping the training data decentralized. Despite recent advances in FL, the uncertainty quantification topic (UQ) remains partially addressed. Among UQ methods, conformal prediction (CP) approaches provides distribution-free guarantees under minimal assumptions. We develop a new federated conformal prediction method based on quantile regression and take into account privacy constraints. This method takes advantage of importance weighting to effectively address the label shift between agents and provides theoretical guarantees for both valid coverage of the prediction sets and differential privacy. Extensive experimental studies demonstrate that this method outperforms current competitors.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#35299;&#20266;&#21464;&#24322;&#65292;&#21253;&#25324;&#34394;&#20551;&#24615;&#22270;&#34920;&#21644;&#29702;&#35770;&#26694;&#26550;&#65292;&#33021;&#22815;&#22312;&#30495;&#20551;&#30456;&#20851;&#20851;&#31995;&#19978;&#24110;&#21161;&#21306;&#20998;&#30452;&#25509;&#25928;&#24212;&#21644;&#38388;&#25509;&#25928;&#24212;&#12290;</title><link>http://arxiv.org/abs/2306.05071</link><description>&lt;p&gt;
&#20998;&#35299;&#20266;&#21464;&#24322;&#30340;&#22240;&#26524;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Causal Framework for Decomposing Spurious Variations. (arXiv:2306.05071v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05071
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#35299;&#20266;&#21464;&#24322;&#65292;&#21253;&#25324;&#34394;&#20551;&#24615;&#22270;&#34920;&#21644;&#29702;&#35770;&#26694;&#26550;&#65292;&#33021;&#22815;&#22312;&#30495;&#20551;&#30456;&#20851;&#20851;&#31995;&#19978;&#24110;&#21161;&#21306;&#20998;&#30452;&#25509;&#25928;&#24212;&#21644;&#38388;&#25509;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#31185;&#23398;&#20013;&#19968;&#20010;&#26681;&#26412;&#24615;&#30340;&#25361;&#25112;&#26159;&#35299;&#37322;&#20026;&#20160;&#20040;&#20107;&#24773;&#20197;&#29305;&#23450;&#30340;&#26041;&#24335;&#21457;&#29983;&#65292;&#25110;&#36890;&#36807;&#21738;&#20123;&#26426;&#21046;&#26576;&#20010;&#21464;&#37327;$X$&#23545;&#21478;&#19968;&#20010;&#21464;&#37327;$Y$&#26045;&#21152;&#24433;&#21709;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24418;&#24335;&#21270;&#24037;&#20855;&#65292;&#29992;&#20110;&#22312;&#39532;&#23572;&#21487;&#22827;&#21644;&#21322;&#39532;&#23572;&#21487;&#22827;&#31995;&#32479;&#20013;&#20998;&#35299;&#20266;&#21464;&#24322;&#65292;&#24341;&#20837;&#20102;&#34394;&#20551;&#24615;&#22270;&#34920;&#30340;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#26694;&#26550;&#65292;&#23558;&#20266;&#25928;&#24212;&#20998;&#35299;&#20026;&#30452;&#25509;&#25928;&#24212;&#21644;&#38388;&#25509;&#25928;&#24212;&#65292;&#20197;&#35782;&#21035;&#29983;&#25104;&#36825;&#20123;&#34394;&#20551;&#20851;&#31995;&#30340;&#22522;&#30784;&#22240;&#26524;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the fundamental challenges found throughout the data sciences is to explain why things happen in specific ways, or through which mechanisms a certain variable $X$ exerts influences over another variable $Y$. In statistics and machine learning, significant efforts have been put into developing machinery to estimate correlations across variables efficiently. In causal inference, a large body of literature is concerned with the decomposition of causal effects under the rubric of mediation analysis. However, many variations are spurious in nature, including different phenomena throughout the applied sciences. Despite the statistical power to estimate correlations and the identification power to decompose causal effects, there is still little understanding of the properties of spurious associations and how they can be decomposed in terms of the underlying causal mechanisms. In this manuscript, we develop formal tools for decomposing spurious variations in both Markovian and Semi-Mark
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#29305;&#23450;&#30340;&#20915;&#31574;&#20219;&#21153;&#21483;&#20570;&#32467;&#26524;&#25511;&#21046;&#65292;&#38024;&#23545;&#28041;&#21450;&#21040;&#21009;&#20107;&#21496;&#27861;&#12289;&#31119;&#21033;&#12289;&#20020;&#24202;&#20915;&#31574;&#20197;&#21450;&#20844;&#20849;&#21355;&#29983;&#31561;&#22810;&#20010;&#26041;&#38754;&#65292;&#25552;&#20986;&#20102;&#22240;&#26524;&#20844;&#24179;&#30340;&#27010;&#24565;&#20197;&#21450;&#19968;&#32452;&#22240;&#26524;&#24037;&#20855;&#21644;&#25216;&#26415;&#26469;&#25512;&#26029;&#32467;&#26524;&#25511;&#21046;&#20013;&#30340;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.05066</link><description>&lt;p&gt;
&#32467;&#26524;&#25511;&#21046;&#30340;&#22240;&#26524;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Causal Fairness for Outcome Control. (arXiv:2306.05066v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05066
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#29305;&#23450;&#30340;&#20915;&#31574;&#20219;&#21153;&#21483;&#20570;&#32467;&#26524;&#25511;&#21046;&#65292;&#38024;&#23545;&#28041;&#21450;&#21040;&#21009;&#20107;&#21496;&#27861;&#12289;&#31119;&#21033;&#12289;&#20020;&#24202;&#20915;&#31574;&#20197;&#21450;&#20844;&#20849;&#21355;&#29983;&#31561;&#22810;&#20010;&#26041;&#38754;&#65292;&#25552;&#20986;&#20102;&#22240;&#26524;&#20844;&#24179;&#30340;&#27010;&#24565;&#20197;&#21450;&#19968;&#32452;&#22240;&#26524;&#24037;&#20855;&#21644;&#25216;&#26415;&#26469;&#25512;&#26029;&#32467;&#26524;&#25511;&#21046;&#20013;&#30340;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#31038;&#20250;&#21521;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#20915;&#31574;&#22522;&#30784;&#35774;&#26045;&#30340;&#36807;&#28193;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#26366;&#30001;&#20154;&#31867;&#25511;&#21046;&#30340;&#20915;&#31574;&#29616;&#22312;&#34987;&#22996;&#25176;&#32473;&#20102;&#33258;&#21160;&#21270;&#31995;&#32479;&#12290;&#23613;&#31649;&#36825;&#26679;&#30340;&#21457;&#23637;&#20351;&#31038;&#20250;&#30340;&#21508;&#20010;&#26041;&#38754;&#26356;&#26377;&#25928;&#29575;&#65292;&#20294;&#22823;&#37327;&#30340;&#35777;&#25454;&#34920;&#26126;&#65292;&#38656;&#35201;&#38750;&#24120;&#23567;&#24515;&#22320;&#20351;&#36825;&#31181;&#33258;&#21160;&#21270;&#20915;&#31574;&#31995;&#32479;&#21464;&#24471;&#20844;&#24179;&#21644;&#20844;&#27491;&#65292;&#21363;&#32771;&#34385;&#21040;&#35832;&#22914;&#24615;&#21035;&#12289;&#31181;&#26063;&#21644;&#23447;&#25945;&#31561;&#25935;&#24863;&#23646;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#29305;&#23450;&#30340;&#20915;&#31574;&#20219;&#21153;&#65292;&#31216;&#20026;&#32467;&#26524;&#25511;&#21046;&#65292;&#20854;&#20013;&#33258;&#21160;&#21270;&#31995;&#32479;&#26088;&#22312;&#20248;&#21270;&#19968;&#20010;&#32467;&#26524;&#21464;&#37327;Y&#65292;&#21516;&#26102;&#20445;&#25345;&#20844;&#24179;&#21644;&#20844;&#27491;&#12290;&#23545;&#20110;&#36825;&#26679;&#19968;&#20010;&#35774;&#32622;&#30340;&#20852;&#36259;&#33539;&#22260;&#20174;&#19982;&#21009;&#20107;&#21496;&#27861;&#21644;&#31119;&#21033;&#26377;&#20851;&#30340;&#24178;&#39044;&#25514;&#26045;&#65292;&#19968;&#30452;&#21040;&#20020;&#24202;&#20915;&#31574;&#21644;&#20844;&#20849;&#21355;&#29983;&#12290;&#25105;&#20204;&#36890;&#36807;&#22240;&#26524;&#38236;&#29255;&#39318;&#20808;&#20998;&#26512;&#20102;&#21033;&#30410;&#30340;&#27010;&#24565;&#65292;&#35813;&#27010;&#24565;&#25429;&#25417;&#20102;&#19968;&#20010;&#29305;&#23450;&#20010;&#20307;&#20174;&#31215;&#26497;&#20915;&#31574;&#20013;&#33719;&#24471;&#20102;&#22810;&#23569;&#22909;&#22788;&#65292;&#23545;&#29031;&#20107;&#23454;&#30340;&#20844;&#24179;&#24615;&#65292;&#25429;&#25417;&#20102;&#22914;&#26524;&#28041;&#21450;&#21040;&#19981;&#21516;&#30340;&#25935;&#24863;&#23646;&#24615;&#65292;&#38382;&#39064;&#25152;&#22312;&#65292;&#20197;&#21450;&#20805;&#20998;&#24615;&#30340;&#27010;&#24565;&#65292;&#23427;&#25429;&#25417;&#20102;&#38656;&#35201;&#22810;&#23569;&#24178;&#39044;&#26469;&#25913;&#21892;&#22240;&#26524;&#31995;&#32479;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#32452;&#22240;&#26524;&#24037;&#20855;&#21644;&#25216;&#26415;&#26469;&#25512;&#26029;&#32467;&#26524;&#25511;&#21046;&#20013;&#30340;&#20844;&#24179;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#26696;&#20363;&#30740;&#31350;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#29992;&#24615;&#65292;&#20854;&#20013;&#25105;&#20204;&#25511;&#21046;&#20102;&#36151;&#27454;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#19981;&#20844;&#24179;&#27495;&#35270;&#12290;
&lt;/p&gt;
&lt;p&gt;
As society transitions towards an AI-based decision-making infrastructure, an ever-increasing number of decisions once under control of humans are now delegated to automated systems. Even though such developments make various parts of society more efficient, a large body of evidence suggests that a great deal of care needs to be taken to make such automated decision-making systems fair and equitable, namely, taking into account sensitive attributes such as gender, race, and religion. In this paper, we study a specific decision-making task called outcome control in which an automated system aims to optimize an outcome variable $Y$ while being fair and equitable. The interest in such a setting ranges from interventions related to criminal justice and welfare, all the way to clinical decision-making and public health. In this paper, we first analyze through causal lenses the notion of benefit, which captures how much a specific individual would benefit from a positive decision, counterfac
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#24230;&#30456;&#20284;&#30340;&#21464;&#20998;&#21518;&#39564;&#20998;&#24067;&#21644;&#20808;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#21518;&#39564;&#23849;&#28291;&#29616;&#35937;&#65292;&#29305;&#21035;&#22320;&#65292;&#36890;&#36807;&#23545;&#32447;&#24615;&#26465;&#20214;VAE&#21644;&#20998;&#23618;VAE&#36827;&#34892;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#36825;&#31181;&#29616;&#35937;&#26159;&#30001;&#20110;&#28508;&#22312;&#21464;&#37327;&#23618;&#27425;&#20851;&#31995;&#19981;&#28165;&#26224;&#32780;&#24341;&#36215;&#30340;&#12290;</title><link>http://arxiv.org/abs/2306.05023</link><description>&lt;p&gt;
&#32447;&#24615;&#26465;&#20214;VAE&#21644;&#20998;&#23618;VAE&#20013;&#30340;&#21518;&#39564;&#23849;&#28291;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
Posterior Collapse in Linear Conditional and Hierarchical Variational Autoencoders. (arXiv:2306.05023v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05023
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#24230;&#30456;&#20284;&#30340;&#21464;&#20998;&#21518;&#39564;&#20998;&#24067;&#21644;&#20808;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#21518;&#39564;&#23849;&#28291;&#29616;&#35937;&#65292;&#29305;&#21035;&#22320;&#65292;&#36890;&#36807;&#23545;&#32447;&#24615;&#26465;&#20214;VAE&#21644;&#20998;&#23618;VAE&#36827;&#34892;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#36825;&#31181;&#29616;&#35937;&#26159;&#30001;&#20110;&#28508;&#22312;&#21464;&#37327;&#23618;&#27425;&#20851;&#31995;&#19981;&#28165;&#26224;&#32780;&#24341;&#36215;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#20013;&#65292;&#21518;&#39564;&#23849;&#28291;&#29616;&#35937;&#25351;&#30340;&#26159;&#21464;&#20998;&#21518;&#39564;&#20998;&#24067;&#19982;&#20808;&#39564;&#20998;&#24067;&#30340;&#30456;&#20284;&#24230;&#36807;&#39640;&#65292;&#23548;&#33268;&#32534;&#30721;&#22120;&#25552;&#21462;&#30340;&#28508;&#22312;&#21464;&#37327;&#20445;&#23384;&#30340;&#36755;&#20837;&#25968;&#25454;&#20449;&#24687;&#36739;&#23569;&#65292;&#26080;&#27861;&#20026;&#35299;&#30721;&#22120;&#30340;&#25968;&#25454;&#37325;&#24314;&#36807;&#31243;&#20135;&#29983;&#26377;&#24847;&#20041;&#30340;&#34920;&#31034;&#12290;&#23613;&#31649;&#35813;&#29616;&#35937;&#19968;&#30452;&#26159;VAEs&#24615;&#33021;&#30340;&#30740;&#31350;&#28909;&#28857;&#65292;&#20294;&#26159;&#23545;&#20110;&#21518;&#39564;&#23849;&#28291;&#30340;&#29702;&#35770;&#21364;&#30456;&#23545;&#34180;&#24369;&#65292;&#29305;&#21035;&#26159;&#22312;&#38750;&#26631;&#20934;&#30340;VAEs&#20013;&#12290;&#26412;&#25991;&#36890;&#36807;&#23545;&#20004;&#31867;&#37325;&#35201;&#32780;&#24120;&#35265;&#21448;&#36739;&#23569;&#30740;&#31350;&#30340;VAEs&#36827;&#34892;&#38750;&#24179;&#20961;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#21363;&#20855;&#26377;&#20004;&#20010;&#28508;&#22312;&#21464;&#37327;&#23618;&#27425;&#30340;&#32447;&#24615;&#26465;&#20214;VAE&#21644;&#20998;&#23618;VAE&#65292;&#25552;&#21319;&#20102;&#23545;&#21518;&#39564;&#23849;&#28291;&#30340;&#29702;&#35770;&#35748;&#35782;&#65292;&#35777;&#26126;&#20102;&#20854;&#25104;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;
The posterior collapse phenomenon in variational autoencoders (VAEs), where the variational posterior distribution closely matches the prior distribution, can hinder the quality of the learned latent variables. As a consequence of posterior collapse, the latent variables extracted by the encoder in VAEs preserve less information from the input data and thus fail to produce meaningful representations as input to the reconstruction process in the decoder. While this phenomenon has been an actively addressed topic related to VAEs performance, the theory for posterior collapse remains underdeveloped, especially beyond the standard VAEs. In this work, we advance the theoretical understanding of posterior collapse to two important and prevalent yet less studied classes of VAEs: conditional VAEs and hierarchical VAEs. Specifically, via a non-trivial theoretical analysis of linear conditional VAEs and hierarchical VAEs with two levels of latent, we prove that the cause of posterior collapses i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#19988;&#21487;&#25193;&#23637;&#30340;&#31070;&#32463;&#38544;&#24335;&#37319;&#26679;&#22120;&#65292;&#24182;&#24341;&#20837;&#20102;KL&#35757;&#32451;&#27861;&#21644;Fisher&#35757;&#32451;&#27861;&#26469;&#35757;&#32451;&#23427;&#65292;&#23454;&#29616;&#20102;&#20302;&#35745;&#31639;&#25104;&#26412;&#19979;&#29983;&#25104;&#22823;&#25209;&#37327;&#26679;&#26412;&#12290;</title><link>http://arxiv.org/abs/2306.04952</link><description>&lt;p&gt;
&#22522;&#20110;&#29109;&#30340;&#35757;&#32451;&#26041;&#27861;&#29992;&#20110;&#21487;&#25193;&#23637;&#30340;&#31070;&#32463;&#38544;&#24335;&#37319;&#26679;&#22120;
&lt;/p&gt;
&lt;p&gt;
Entropy-based Training Methods for Scalable Neural Implicit Sampler. (arXiv:2306.04952v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04952
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#19988;&#21487;&#25193;&#23637;&#30340;&#31070;&#32463;&#38544;&#24335;&#37319;&#26679;&#22120;&#65292;&#24182;&#24341;&#20837;&#20102;KL&#35757;&#32451;&#27861;&#21644;Fisher&#35757;&#32451;&#27861;&#26469;&#35757;&#32451;&#23427;&#65292;&#23454;&#29616;&#20102;&#20302;&#35745;&#31639;&#25104;&#26412;&#19979;&#29983;&#25104;&#22823;&#25209;&#37327;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#25928;&#22320;&#20174;&#38750;&#26631;&#20934;&#30446;&#26631;&#20998;&#24067;&#20013;&#37319;&#26679;&#26159;&#31185;&#23398;&#35745;&#31639;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#12290;&#20256;&#32479;&#26041;&#27861;&#22914;&#39532;&#23572;&#31185;&#22827;&#33945;&#29305;&#21345;&#27931;&#65288;MCMC&#65289;&#21487;&#20445;&#35777;&#20174;&#36825;&#20123;&#20998;&#24067;&#20013;&#28176;&#36827;&#26080;&#20559;&#37319;&#26679;&#65292;&#20294;&#22312;&#22788;&#29702;&#39640;&#32500;&#30446;&#26631;&#26102;&#35745;&#31639;&#25928;&#29575;&#20302;&#19979;&#65292;&#38656;&#35201;&#22810;&#27425;&#36845;&#20195;&#29983;&#25104;&#19968;&#25209;&#26679;&#26412;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#19988;&#21487;&#25193;&#23637;&#30340;&#31070;&#32463;&#38544;&#24335;&#37319;&#26679;&#22120;&#65292;&#36890;&#36807;&#21033;&#29992;&#30452;&#25509;&#23558;&#26131;&#20110;&#37319;&#26679;&#30340;&#28508;&#22312;&#21521;&#37327;&#26144;&#23556;&#21040;&#30446;&#26631;&#26679;&#26412;&#30340;&#31070;&#32463;&#21464;&#25442;&#65292;&#21487;&#20197;&#22312;&#20302;&#35745;&#31639;&#25104;&#26412;&#19979;&#29983;&#25104;&#22823;&#25209;&#37327;&#26679;&#26412;&#12290;&#20026;&#20102;&#35757;&#32451;&#31070;&#32463;&#38544;&#24335;&#37319;&#26679;&#22120;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31181;&#26032;&#26041;&#27861;&#65306;KL&#35757;&#32451;&#27861;&#21644;Fisher&#35757;&#32451;&#27861;&#12290;&#21069;&#32773;&#26368;&#23567;&#21270;Kullback-Leibler&#25955;&#24230;&#65292;&#32780;&#21518;&#32773;&#21017;&#26368;&#23567;&#21270;Fisher&#25955;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Efficiently sampling from un-normalized target distributions is a fundamental problem in scientific computing and machine learning. Traditional approaches like Markov Chain Monte Carlo (MCMC) guarantee asymptotically unbiased samples from such distributions but suffer from computational inefficiency, particularly when dealing with high-dimensional targets, as they require numerous iterations to generate a batch of samples. In this paper, we propose an efficient and scalable neural implicit sampler that overcomes these limitations. Our sampler can generate large batches of samples with low computational costs by leveraging a neural transformation that directly maps easily sampled latent vectors to target samples without the need for iterative procedures. To train the neural implicit sampler, we introduce two novel methods: the KL training method and the Fisher training method. The former minimizes the Kullback-Leibler divergence, while the latter minimizes the Fisher divergence. By empl
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20449;&#24687;&#35770;&#26694;&#26550;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#25552;&#31034;&#21644;&#20854;&#20182;&#27169;&#22411;&#21442;&#25968;&#20043;&#38388;&#20114;&#20449;&#24687;&#26469;&#20248;&#21270;&#36719;&#25552;&#31034;&#35843;&#25972;&#65292;&#20174;&#32780;&#24320;&#21457;&#20102;&#26356;&#21152;&#39640;&#25928;&#12289;&#20934;&#30830;&#21644;&#31283;&#20581;&#30340;&#36719;&#25552;&#31034;&#35843;&#25972;&#26041;&#27861;InfoPrompt&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20004;&#20010;&#26032;&#22411;&#25439;&#22833;&#20989;&#25968;&#65292;&#21457;&#29616;&#21512;&#36866;&#30340;&#25552;&#31034;&#21021;&#22987;&#21270;&#65292;&#24182;&#20174;&#25552;&#31034;&#20196;&#29260;&#20013;&#23398;&#20064;&#36275;&#22815;&#30340;&#20219;&#21153;&#30456;&#20851;&#20449;&#24687;&#65292;&#21516;&#26102;&#40723;&#21169;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#36755;&#20986;&#34920;&#31034;&#26356;&#21152;&#20851;&#27880;&#20219;&#21153;&#30456;&#20851;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2306.04933</link><description>&lt;p&gt;
InfoPrompt&#65306;&#29992;&#20449;&#24687;&#35770;&#36719;&#25552;&#31034;&#35843;&#25972;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
InfoPrompt: Information-Theoretic Soft Prompt Tuning for Natural Language Understanding. (arXiv:2306.04933v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04933
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20449;&#24687;&#35770;&#26694;&#26550;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#25552;&#31034;&#21644;&#20854;&#20182;&#27169;&#22411;&#21442;&#25968;&#20043;&#38388;&#20114;&#20449;&#24687;&#26469;&#20248;&#21270;&#36719;&#25552;&#31034;&#35843;&#25972;&#65292;&#20174;&#32780;&#24320;&#21457;&#20102;&#26356;&#21152;&#39640;&#25928;&#12289;&#20934;&#30830;&#21644;&#31283;&#20581;&#30340;&#36719;&#25552;&#31034;&#35843;&#25972;&#26041;&#27861;InfoPrompt&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20004;&#20010;&#26032;&#22411;&#25439;&#22833;&#20989;&#25968;&#65292;&#21457;&#29616;&#21512;&#36866;&#30340;&#25552;&#31034;&#21021;&#22987;&#21270;&#65292;&#24182;&#20174;&#25552;&#31034;&#20196;&#29260;&#20013;&#23398;&#20064;&#36275;&#22815;&#30340;&#20219;&#21153;&#30456;&#20851;&#20449;&#24687;&#65292;&#21516;&#26102;&#40723;&#21169;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#36755;&#20986;&#34920;&#31034;&#26356;&#21152;&#20851;&#27880;&#20219;&#21153;&#30456;&#20851;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36719;&#25552;&#31034;&#35843;&#25972;&#22312;&#24191;&#27867;&#30340;&#23569;&#26679;&#26412;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;&#20294;&#26159;&#65292;&#25552;&#31034;&#35843;&#25972;&#30340;&#24615;&#33021;&#23545;&#21021;&#22987;&#21270;&#30340;&#25552;&#31034;&#38750;&#24120;&#25935;&#24863;&#12290;&#26412;&#25991;&#21457;&#29616;&#65292;&#20256;&#32479;&#30340;&#25552;&#31034;&#35843;&#25972;&#26041;&#27861;&#19981;&#33021;&#20174;&#25552;&#31034;&#20196;&#29260;&#20013;&#32534;&#30721;&#21644;&#23398;&#20064;&#36275;&#22815;&#30340;&#20219;&#21153;&#30456;&#20851;&#20449;&#24687;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#20449;&#24687;&#35770;&#26694;&#26550;&#65292;&#23558;&#36719;&#25552;&#31034;&#35843;&#25972;&#24418;&#24335;&#21270;&#20026;&#26368;&#22823;&#21270;&#25552;&#31034;&#21644;&#20854;&#20182;&#27169;&#22411;&#21442;&#25968;&#65288;&#25110;&#32534;&#30721;&#34920;&#31034;&#65289;&#20043;&#38388;&#20114;&#20449;&#24687;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#36825;&#31181;&#26032;&#39062;&#30340;&#35266;&#28857;&#26377;&#21161;&#20110;&#25105;&#20204;&#24320;&#21457;&#19968;&#20010;&#26356;&#39640;&#25928;&#12289;&#20934;&#30830;&#21644;&#31283;&#20581;&#30340;&#36719;&#25552;&#31034;&#35843;&#25972;&#26041;&#27861;InfoPrompt&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#20004;&#20010;&#22522;&#20110;&#20114;&#20449;&#24687;&#30340;&#26032;&#22411;&#25439;&#22833;&#20989;&#25968;&#65292;&#29992;&#20110;&#65288;i&#65289;&#21457;&#29616;&#19979;&#28216;&#20219;&#21153;&#30340;&#21512;&#36866;&#25552;&#31034;&#21021;&#22987;&#21270;&#65292;&#24182;&#20174;&#25552;&#31034;&#20196;&#29260;&#20013;&#23398;&#20064;&#36275;&#22815;&#30340;&#20219;&#21153;&#30456;&#20851;&#20449;&#24687;&#65292;&#65288;ii&#65289;&#40723;&#21169;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#36755;&#20986;&#34920;&#31034;&#26356;&#21152;&#20851;&#27880;&#20219;&#21153;&#30456;&#20851;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Soft prompt tuning achieves superior performances across a wide range of few-shot tasks. However, the performances of prompt tuning can be highly sensitive to the initialization of the prompts. We also empirically observe that conventional prompt tuning methods cannot encode and learn sufficient task-relevant information from prompt tokens. In this work, we develop an information-theoretic framework that formulates soft prompt tuning as maximizing mutual information between prompts and other model parameters (or encoded representations). This novel view helps us to develop a more efficient, accurate and robust soft prompt tuning method InfoPrompt. With this framework, we develop two novel mutual information based loss functions, to (i) discover proper prompt initialization for the downstream tasks and learn sufficient task-relevant information from prompt tokens and (ii) encourage the output representation from the pretrained language model to be more aware of the task-relevant informa
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#65292;&#25506;&#35752;&#20102;&#22312;&#36890;&#20449;&#21644;&#26412;&#22320;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#19979;&#30340;&#31934;&#30830;&#26368;&#20248;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#21033;&#29992;&#26059;&#36716;&#23545;&#31216;&#30340;&#20849;&#20139;&#38543;&#26426;&#30721;&#20070;&#65292;&#24182;&#36890;&#36807;$k$-closest&#32534;&#30721;&#23454;&#29616;&#20102;&#38543;&#26426;&#26059;&#36716;&#30340;&#21333;&#32431;&#24418;$c$&#30340;&#31934;&#30830;&#26368;&#20248;&#12290;</title><link>http://arxiv.org/abs/2306.04924</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#22343;&#20540;&#20272;&#35745;&#20013;&#30340;&#36890;&#20449;&#38544;&#31169;&#25928;&#29992;&#26435;&#34913;&#30340;&#31934;&#30830;&#26368;&#20248;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Exact Optimality of Communication-Privacy-Utility Tradeoffs in Distributed Mean Estimation. (arXiv:2306.04924v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04924
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#65292;&#25506;&#35752;&#20102;&#22312;&#36890;&#20449;&#21644;&#26412;&#22320;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#19979;&#30340;&#31934;&#30830;&#26368;&#20248;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#21033;&#29992;&#26059;&#36716;&#23545;&#31216;&#30340;&#20849;&#20139;&#38543;&#26426;&#30721;&#20070;&#65292;&#24182;&#36890;&#36807;$k$-closest&#32534;&#30721;&#23454;&#29616;&#20102;&#38543;&#26426;&#26059;&#36716;&#30340;&#21333;&#32431;&#24418;$c$&#30340;&#31934;&#30830;&#26368;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36890;&#20449;&#21644;&#26412;&#22320;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#19979;&#30340;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#12290;&#34429;&#28982;&#20197;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#25552;&#20986;&#20102;&#30456;&#21516;&#38382;&#39064;&#30340;\emph{&#38454;}-&#26368;&#20248;&#31639;&#27861;&#65288;&#21363;&#24403;&#25105;&#20204;&#33457;&#36153;&#26356;&#22810;&#27604;&#29305;&#26102;&#28176;&#36827;&#26368;&#20248;&#65289;&#65292;&#20294;&#22312;&#38750;&#28176;&#36827;&#35774;&#32622;&#19979;&#20173;&#28982;&#27809;&#26377;&#23454;&#29616;\emph{&#31934;&#30830;}&#26368;&#20248;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36808;&#20986;&#20102;&#19968;&#27493;&#65292;&#25551;&#36848;&#20102;&#22312;&#20849;&#20139;&#38543;&#26426;&#24615;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#30340;\emph{&#31934;&#30830;}-&#26368;&#20248;&#26041;&#27861;&#65292;&#24182;&#30830;&#23450;&#20102;&#20960;&#20010;\emph{&#31934;&#30830;}&#26368;&#20248;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20854;&#20013;&#19968;&#20010;&#24517;&#35201;&#26465;&#20214;&#26159;&#21033;&#29992;&#26059;&#36716;&#23545;&#31216;&#30340;&#20849;&#20139;&#38543;&#26426;&#30721;&#20070;&#12290;&#22522;&#20110;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#21270;&#26426;&#21046;&#65292;&#20854;&#20013;&#30721;&#20070;&#26159;&#38543;&#26426;&#26059;&#36716;&#30340;&#21333;&#32431;&#24418;&#8212;&#8212;&#28385;&#36275;\emph{&#31934;&#30830;}-&#26368;&#20248;&#30721;&#20070;&#30340;&#24517;&#35201;&#23646;&#24615;&#12290;&#35813;&#26426;&#21046;&#22522;&#20110;&#25105;&#20204;&#35777;&#26126;&#30340;$k$&#26368;&#36817;&#32534;&#30721;&#65292;&#23545;&#20110;&#38543;&#26426;&#26059;&#36716;&#30340;&#21333;&#32431;&#24418;$c$&#26469;&#35828;&#26159;\emph{&#31934;&#30830;}-&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the mean estimation problem under communication and local differential privacy constraints. While previous work has proposed \emph{order}-optimal algorithms for the same problem (i.e., asymptotically optimal as we spend more bits), \emph{exact} optimality (in the non-asymptotic setting) still has not been achieved. In this work, we take a step towards characterizing the \emph{exact}-optimal approach in the presence of shared randomness (a random variable shared between the server and the user) and identify several necessary conditions for \emph{exact} optimality. We prove that one of the necessary conditions is to utilize a rotationally symmetric shared random codebook. Based on this, we propose a randomization mechanism where the codebook is a randomly rotated simplex -- satisfying the necessary properties of the \emph{exact}-optimal codebook. The proposed mechanism is based on a $k$-closest encoding which we prove to be \emph{exact}-optimal for the randomly rotated simplex c
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#29992;&#20110;&#35299;&#20915;&#26080;&#30028;&#22495;&#21644;&#38750;Lipschitz&#25439;&#22833;&#30340;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#36951;&#25022;&#30340;&#24230;&#37327;&#65292;&#20197;&#34913;&#37327;&#35813;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21033;&#29992;&#35813;&#31639;&#27861;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#38797;&#28857;&#20248;&#21270;&#31639;&#27861;&#65292;&#21363;&#20351;&#22312;&#27809;&#26377;&#26377;&#24847;&#20041;&#30340;&#26354;&#29575;&#30340;&#24773;&#20917;&#19979;&#65292;&#20063;&#33021;&#22815;&#22312;&#26080;&#30028;&#39046;&#22495;&#20013;&#25910;&#25947;&#20110;&#23545;&#20598;&#38388;&#38553;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#22312;&#26080;&#30028;&#22495;&#21644;&#38750;Lipschitz&#25439;&#22833;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#38750;&#24179;&#20961;&#30340;&#21160;&#24577;&#36951;&#25022;&#65292;&#20197;&#21450;&#30456;&#21305;&#37197;&#30340;&#19979;&#30028;&#12290;</title><link>http://arxiv.org/abs/2306.04923</link><description>&lt;p&gt;
&#26080;&#32422;&#26463;&#22312;&#32447;&#23398;&#20064;&#21644;&#26080;&#30028;&#25439;&#22833;&#30340;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Unconstrained Online Learning with Unbounded Losses. (arXiv:2306.04923v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04923
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#29992;&#20110;&#35299;&#20915;&#26080;&#30028;&#22495;&#21644;&#38750;Lipschitz&#25439;&#22833;&#30340;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#36951;&#25022;&#30340;&#24230;&#37327;&#65292;&#20197;&#34913;&#37327;&#35813;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21033;&#29992;&#35813;&#31639;&#27861;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#38797;&#28857;&#20248;&#21270;&#31639;&#27861;&#65292;&#21363;&#20351;&#22312;&#27809;&#26377;&#26377;&#24847;&#20041;&#30340;&#26354;&#29575;&#30340;&#24773;&#20917;&#19979;&#65292;&#20063;&#33021;&#22815;&#22312;&#26080;&#30028;&#39046;&#22495;&#20013;&#25910;&#25947;&#20110;&#23545;&#20598;&#38388;&#38553;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#22312;&#26080;&#30028;&#22495;&#21644;&#38750;Lipschitz&#25439;&#22833;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#38750;&#24179;&#20961;&#30340;&#21160;&#24577;&#36951;&#25022;&#65292;&#20197;&#21450;&#30456;&#21305;&#37197;&#30340;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#36890;&#24120;&#38656;&#35201;&#19968;&#20010;&#25110;&#22810;&#20010;&#26377;&#30028;&#24615;&#20551;&#35774;&#65306;&#21363;&#22495;&#26159;&#26377;&#30028;&#30340;&#65292;&#25439;&#22833;&#26159;Lipschitz&#30340;&#25110;&#20004;&#32773;&#37117;&#26377;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20026;&#20855;&#26377;&#26080;&#30028;&#22495;&#21644;&#38750;Lipschitz&#25439;&#22833;&#30340;&#22312;&#32447;&#23398;&#20064;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#30340;&#35774;&#32622;&#12290;&#38024;&#23545;&#35813;&#22330;&#26223;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#20445;&#35777;&#22312;&#20219;&#20309;&#28385;&#36275;&#23376;&#26799;&#24230;&#28385;&#36275;$\|g_{t}\|\le G+L\|w_{t}\|$&#30340;&#38382;&#39064;&#20013;&#65292;&#20854;&#36951;&#25022;&#30340;&#24230;&#37327;&#20540;$R_{T}(u)\le \tilde O(G\|u\|\sqrt{T}+L\|u\|^{2}\sqrt{T})$&#65292;&#24182;&#19988;&#34920;&#26126;&#38500;&#38750;&#26377;&#36827;&#19968;&#27493; &#20551;&#35774;&#65292;&#21542;&#21017;&#35813;&#30028;&#38480;&#26159;&#19981;&#33021;&#36827;&#19968;&#27493;&#25913;&#36827;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithms for online learning typically require one or more boundedness assumptions: that the domain is bounded, that the losses are Lipschitz, or both. In this paper, we develop a new setting for online learning with unbounded domains and non-Lipschitz losses. For this setting we provide an algorithm which guarantees $R_{T}(u)\le \tilde O(G\|u\|\sqrt{T}+L\|u\|^{2}\sqrt{T})$ regret on any problem where the subgradients satisfy $\|g_{t}\|\le G+L\|w_{t}\|$, and show that this bound is unimprovable without further assumptions. We leverage this algorithm to develop new saddle-point optimization algorithms that converge in duality gap in unbounded domains, even in the absence of meaningful curvature. Finally, we provide the first algorithm achieving non-trivial dynamic regret in an unbounded domain for non-Lipschitz losses, as well as a matching lower bound. The regret of our dynamic regret algorithm automatically improves to a novel $L^{*}$ bound when the losses are smooth.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#26679;&#26412;&#21644;&#29289;&#29702;&#23398;&#30340;&#27491;&#21521;&#27169;&#22411;&#29983;&#25104;&#35757;&#32451;&#25968;&#25454;&#65292;&#24471;&#21040;&#26465;&#20214;Wasserstein&#29983;&#25104;&#24335;&#23545;&#25239;&#32593;&#32476;&#65288;cWGAN&#65289;&#30340;&#27010;&#29575;&#20998;&#24067;&#65292;&#21487;&#29992;&#20110;&#35299;&#20915;&#22256;&#38590;&#30340;&#27010;&#29575;&#21453;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.04895</link><description>&lt;p&gt;
&#20351;&#29992;&#24102;&#26377;&#20840;&#26799;&#24230;&#24809;&#32602;&#30340;&#26465;&#20214;&#29983;&#25104;&#24335;&#23545;&#25239;&#32593;&#32476;&#35299;&#20915;&#22522;&#20110;&#29289;&#29702;&#21453;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Solution of physics-based inverse problems using conditional generative adversarial networks with full gradient penalty. (arXiv:2306.04895v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04895
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#26679;&#26412;&#21644;&#29289;&#29702;&#23398;&#30340;&#27491;&#21521;&#27169;&#22411;&#29983;&#25104;&#35757;&#32451;&#25968;&#25454;&#65292;&#24471;&#21040;&#26465;&#20214;Wasserstein&#29983;&#25104;&#24335;&#23545;&#25239;&#32593;&#32476;&#65288;cWGAN&#65289;&#30340;&#27010;&#29575;&#20998;&#24067;&#65292;&#21487;&#29992;&#20110;&#35299;&#20915;&#22256;&#38590;&#30340;&#27010;&#29575;&#21453;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#20915;&#27010;&#29575;&#21453;&#38382;&#39064;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#29305;&#21035;&#26159;&#24403;&#25512;&#26029;&#21521;&#37327;&#30340;&#32500;&#24230;&#24456;&#22823;&#19988;&#20854;&#20808;&#39564;&#20449;&#24687;&#26159;&#30001;&#19968;&#32452;&#26679;&#26412;&#32452;&#25104;&#26102;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26032;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#35299;&#20915;&#36825;&#31867;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#20174;&#20808;&#39564;&#20998;&#24067;&#20013;&#32472;&#21046;&#30340;&#25512;&#26029;&#21521;&#37327;&#26679;&#26412;&#21644;&#22522;&#20110;&#29289;&#29702;&#30340;&#27491;&#21521;&#27169;&#22411;&#26469;&#29983;&#25104;&#26465;&#20214;Wasserstein&#29983;&#25104;&#24335;&#23545;&#25239;&#32593;&#32476;&#65288;cWGAN&#65289;&#30340;&#35757;&#32451;&#25968;&#25454;&#12290;cWGAN&#23398;&#20064;&#32473;&#23450;&#27979;&#37327;&#30340;&#25512;&#26029;&#21521;&#37327;&#30340;&#27010;&#29575;&#20998;&#24067;&#65292;&#24182;&#29983;&#25104;&#26469;&#33258;&#35813;&#20998;&#24067;&#30340;&#26679;&#26412;&#12290;&#26412;&#25991;&#25152;&#24320;&#21457;&#30340;cWGAN&#19982;&#26089;&#26399;&#29256;&#26412;&#19981;&#21516;&#20043;&#22788;&#22312;&#20110;&#20854;&#35780;&#35770;&#23478;&#24517;&#39035;&#22312;&#25512;&#26029;&#21521;&#37327;&#21644;&#27979;&#37327;&#21521;&#37327;&#26041;&#38754;&#37117;&#26159;1-Lipschitz&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#20010;&#24102;&#26377;&#20840;&#26799;&#24230;&#24809;&#32602;&#30340;&#25439;&#22833;&#39033;&#12290;
&lt;/p&gt;
&lt;p&gt;
The solution of probabilistic inverse problems for which the corresponding forward problem is constrained by physical principles is challenging. This is especially true if the dimension of the inferred vector is large and the prior information about it is in the form of a collection of samples. In this work, a novel deep learning based approach is developed and applied to solving these types of problems. The approach utilizes samples of the inferred vector drawn from the prior distribution and a physics-based forward model to generate training data for a conditional Wasserstein generative adversarial network (cWGAN). The cWGAN learns the probability distribution for the inferred vector conditioned on the measurement and produces samples from this distribution. The cWGAN developed in this work differs from earlier versions in that its critic is required to be 1-Lipschitz with respect to both the inferred and the measurement vectors and not just the former. This leads to a loss term with
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#37319;&#29992;&#21464;&#20998;&#36125;&#21494;&#26031;&#21644;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#39044;&#23450;&#20041;&#30340;&#22522;&#20989;&#25968;&#23383;&#20856;&#20013;&#23398;&#20064;&#30456;&#20851;&#22522;&#26412;&#30693;&#35782;&#65292;&#24182;&#21457;&#29616;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;</title><link>http://arxiv.org/abs/2306.04894</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#20174;&#25968;&#25454;&#23398;&#20064;&#25511;&#21046;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#36125;&#21494;&#26031;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Bayesian Framework for learning governing Partial Differential Equation from Data. (arXiv:2306.04894v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04894
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#37319;&#29992;&#21464;&#20998;&#36125;&#21494;&#26031;&#21644;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#39044;&#23450;&#20041;&#30340;&#22522;&#20989;&#25968;&#23383;&#20856;&#20013;&#23398;&#20064;&#30456;&#20851;&#22522;&#26412;&#30693;&#35782;&#65292;&#24182;&#21457;&#29616;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21457;&#29616;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDE&#65289;&#26159;&#19968;&#39033;&#26082;&#28041;&#21450;&#29702;&#35770;&#21448;&#28041;&#21450;&#23454;&#35777;&#26041;&#27861;&#30340;&#25361;&#25112;&#24615;&#20219;&#21153;&#12290;&#34429;&#28982;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#24050;&#32463;&#34987;&#29992;&#26469;&#35299;&#20915;&#27492;&#38382;&#39064;&#65292;&#20294;&#26159;&#29616;&#26377;&#26041;&#27861;&#24120;&#24120;&#22312;&#23384;&#22312;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#38590;&#20197;&#20934;&#30830;&#22320;&#35782;&#21035;&#28508;&#22312;&#30340;&#26041;&#31243;&#24335;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#21464;&#20998;&#36125;&#21494;&#26031;&#21644;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#30340;&#21457;&#29616;PDE&#30340;&#26032;&#26041;&#27861;&#12290;PDE&#21457;&#29616;&#38382;&#39064;&#34987;&#35270;&#20026;&#20174;&#39044;&#23450;&#20041;&#22522;&#20989;&#25968;&#23383;&#20856;&#20013;&#23398;&#20064;&#30456;&#20851;&#22522;&#30784;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#21152;&#36895;&#25972;&#20010;&#36807;&#31243;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21464;&#20998;&#36125;&#21494;&#26031;&#30340;&#26041;&#27861;&#26469;&#21457;&#29616;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#20026;&#20102;&#30830;&#20445;&#31232;&#30095;&#24615;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#38024;&#23574;&#21644;&#26495;&#26465;&#20808;&#39564;&#12290;&#25105;&#20204;&#22312;&#21253;&#25324;Burgers&#12289;Korteweg-de Vries&#12289;Kuramoto Sivashinsky&#12289;&#27874;&#21160;&#26041;&#31243;&#21644;&#28909;&#26041;&#31243;&#65288;1D&#21644;2D&#65289;&#22312;&#20869;&#30340;&#20960;&#20010;&#31034;&#20363;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#31574;&#30053;&#30340;&#21151;&#25928;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
The discovery of partial differential equations (PDEs) is a challenging task that involves both theoretical and empirical methods. Machine learning approaches have been developed and used to solve this problem; however, it is important to note that existing methods often struggle to identify the underlying equation accurately in the presence of noise. In this study, we present a new approach to discovering PDEs by combining variational Bayes and sparse linear regression. The problem of PDE discovery has been posed as a problem to learn relevant basis from a predefined dictionary of basis functions. To accelerate the overall process, a variational Bayes-based approach for discovering partial differential equations is proposed. To ensure sparsity, we employ a spike and slab prior. We illustrate the efficacy of our strategy in several examples, including Burgers, Korteweg-de Vries, Kuramoto Sivashinsky, wave equation, and heat equation (1D as well as 2D). Our method offers a promising ave
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#20989;&#25968;&#35299;&#37322;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#22120;&#12290;&#37319;&#26679;&#22120;&#34920;&#29616;&#20986;&#20102;&#26368;&#20808;&#36827;&#30340;FID&#24471;&#20998;&#65292;&#24182;&#33021;&#22815;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#12290;</title><link>http://arxiv.org/abs/2306.04848</link><description>&lt;p&gt;
&#21033;&#29992;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#20989;&#25968;&#35299;&#37322;&#21644;&#25913;&#36827;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Interpreting and Improving Diffusion Models Using the Euclidean Distance Function. (arXiv:2306.04848v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04848
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#20989;&#25968;&#35299;&#37322;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#22120;&#12290;&#37319;&#26679;&#22120;&#34920;&#29616;&#20986;&#20102;&#26368;&#20808;&#36827;&#30340;FID&#24471;&#20998;&#65292;&#24182;&#33021;&#22815;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21435;&#22122;&#30452;&#35273;&#19978;&#19982;&#25237;&#24433;&#26377;&#20851;&#12290;&#20107;&#23454;&#19978;&#65292;&#22312;&#27969;&#24418;&#20551;&#35774;&#19979;&#65292;&#28155;&#21152;&#38543;&#26426;&#22122;&#22768;&#36817;&#20284;&#31561;&#20215;&#20110;&#27491;&#20132;&#25200;&#21160;&#12290;&#22240;&#27492;&#65292;&#23398;&#20064;&#21435;&#22122;&#36817;&#20284;&#20110;&#23398;&#20064;&#25237;&#24433;&#12290;&#26412;&#25991;&#21033;&#29992;&#36825;&#19968;&#35266;&#23519;&#32467;&#26524;&#65292;&#23558;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#35299;&#37322;&#20026;&#24212;&#29992;&#20110;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#20989;&#25968;&#30340;&#36817;&#20284;&#26799;&#24230;&#19979;&#38477;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#22522;&#20110;&#23545;&#21435;&#22122;&#22120;&#25237;&#24433;&#35823;&#24046;&#30340;&#31616;&#21333;&#20551;&#35774;&#65292;&#25552;&#20379;DDIM&#65288;Denoising Diffusion Implicit Models&#65289;&#37319;&#26679;&#22120;&#30340;&#31616;&#21333;&#25910;&#25947;&#20998;&#26512;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22522;&#20110;&#29702;&#35770;&#32467;&#26524;&#30340;&#27934;&#35265;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#23545;DDIM&#30340;&#20004;&#20010;&#31616;&#21333;&#20462;&#25913;&#30340;&#26032;&#37319;&#26679;&#22120;&#12290;&#20165;&#38656;&#35201;5-10&#20010;&#20989;&#25968;&#35780;&#20272;&#65292;&#25105;&#20204;&#30340;&#37319;&#26679;&#22120;&#23601;&#33021;&#22312;&#39044;&#35757;&#32451;&#30340;CIFAR-10&#21644;CelebA&#27169;&#22411;&#19978;&#36798;&#21040;&#26368;&#20808;&#36827;&#30340;FID&#24471;&#20998;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#19978;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Denoising is intuitively related to projection. Indeed, under the manifold hypothesis, adding random noise is approximately equivalent to orthogonal perturbation. Hence, learning to denoise is approximately learning to project. In this paper, we use this observation to reinterpret denoising diffusion models as approximate gradient descent applied to the Euclidean distance function. We then provide straight-forward convergence analysis of the DDIM sampler under simple assumptions on the projection-error of the denoiser. Finally, we propose a new sampler based on two simple modifications to DDIM using insights from our theoretical results. In as few as 5-10 function evaluations, our sampler achieves state-of-the-art FID scores on pretrained CIFAR-10 and CelebA models and can generate high quality samples on latent diffusion models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32463;&#20856;&#39564;&#35777;&#37327;&#23376;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#20197;&#20415;&#32463;&#20856;&#23458;&#25143;&#22996;&#25176;&#23398;&#20064;&#32473;&#19981;&#21487;&#20449;&#30340;&#37327;&#23376;&#26381;&#21153;&#22120;&#65292;&#24182;&#25104;&#21151;&#35299;&#20915;&#20102;&#23545;&#20183;&#23398;&#20064;&#22855;&#20598;&#24615;&#21644;&#20613;&#37324;&#21494;&#31232;&#30095;&#20989;&#25968;&#19981;&#21487;&#20449;&#37327;&#23376;&#35777;&#26126;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.04843</link><description>&lt;p&gt;
&#37327;&#23376;&#23398;&#20064;&#30340;&#32463;&#20856;&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;
Classical Verification of Quantum Learning. (arXiv:2306.04843v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04843
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32463;&#20856;&#39564;&#35777;&#37327;&#23376;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#20197;&#20415;&#32463;&#20856;&#23458;&#25143;&#22996;&#25176;&#23398;&#20064;&#32473;&#19981;&#21487;&#20449;&#30340;&#37327;&#23376;&#26381;&#21153;&#22120;&#65292;&#24182;&#25104;&#21151;&#35299;&#20915;&#20102;&#23545;&#20183;&#23398;&#20064;&#22855;&#20598;&#24615;&#21644;&#20613;&#37324;&#21494;&#31232;&#30095;&#20989;&#25968;&#19981;&#21487;&#20449;&#37327;&#23376;&#35777;&#26126;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#25968;&#25454;&#35775;&#38382;&#21644;&#37327;&#23376;&#22788;&#29702;&#21487;&#20197;&#20351;&#26576;&#20123;&#32463;&#20856;&#38590;&#20197;&#22788;&#29702;&#30340;&#23398;&#20064;&#20219;&#21153;&#21464;&#24471;&#21487;&#34892;&#12290;&#28982;&#32780;&#65292;&#37327;&#23376;&#33021;&#21147;&#22312;&#19981;&#20037;&#30340;&#23558;&#26469;&#21482;&#33021;&#25552;&#20379;&#32473;&#23569;&#25968;&#20154;&#20351;&#29992;&#12290;&#22240;&#27492;&#65292;&#38656;&#35201;&#21487;&#38752;&#30340;&#26041;&#26696;&#65292;&#20801;&#35768;&#32463;&#20856;&#23458;&#25143;&#22996;&#25176;&#23398;&#20064;&#32473;&#19981;&#21487;&#20449;&#30340;&#37327;&#23376;&#26381;&#21153;&#22120;&#65292;&#20197;&#20419;&#36827;&#24191;&#27867;&#33719;&#24471;&#37327;&#23376;&#23398;&#20064;&#30340;&#20248;&#21183;&#12290;&#26412;&#25991;&#22522;&#20110;&#26368;&#36817;&#24341;&#20837;&#30340;&#21476;&#20856;&#26426;&#22120;&#23398;&#20064;&#20132;&#20114;&#35777;&#26126;&#31995;&#32479;&#26694;&#26550;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#32463;&#20856;&#39564;&#35777;&#37327;&#23376;&#23398;&#20064;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20123;&#32463;&#20856;&#23398;&#20064;&#32773;&#26080;&#27861;&#33258;&#34892;&#39640;&#25928;&#27714;&#35299;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#20294;&#24403;&#19982;&#19981;&#21487;&#20449;&#30340;&#37327;&#23376;&#35777;&#26126;&#32773;&#20132;&#20114;&#26102;&#65292;&#20182;&#20204;&#21487;&#20197;&#39640;&#25928;&#19988;&#21487;&#38752;&#22320;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20851;&#20110;&#20855;&#26377;&#22343;&#21248;&#36755;&#20837;&#36793;&#32536;&#23494;&#24230;&#30340;&#23545;&#20183;&#23398;&#20064;&#22855;&#20598;&#24615;&#21644;&#20613;&#37324;&#21494;&#31232;&#30095;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#37327;&#23376;&#25968;&#25454;&#35775;&#38382;&#27169;&#22411;&#65292;&#31216;&#20026;&#8220;&#21472;&#21152;&#28151;&#21512;&#37327;&#23376;&#26679;&#20363;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantum data access and quantum processing can make certain classically intractable learning tasks feasible. However, quantum capabilities will only be available to a select few in the near future. Thus, reliable schemes that allow classical clients to delegate learning to untrusted quantum servers are required to facilitate widespread access to quantum learning advantages. Building on a recently introduced framework of interactive proof systems for classical machine learning, we develop a framework for classical verification of quantum learning. We exhibit learning problems that a classical learner cannot efficiently solve on their own, but that they can efficiently and reliably solve when interacting with an untrusted quantum prover. Concretely, we consider the problems of agnostic learning parities and Fourier-sparse functions with respect to distributions with uniform input marginal. We propose a new quantum data access model that we call "mixture-of-superpositions" quantum example
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;$K$&#26368;&#36817;&#37051;&#37325;&#37319;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#31639;&#21382;&#21490;&#25968;&#25454;&#20013;&#30001;&#19981;&#21516;&#31574;&#30053;&#29983;&#25104;&#30340;&#20915;&#31574;&#36807;&#31243;&#30340;&#24615;&#33021;&#65292;&#35299;&#20915;&#20102;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#20013;&#30340;&#21453;&#20107;&#23454;&#20272;&#35745;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.04836</link><description>&lt;p&gt;
$K$&#26368;&#36817;&#37051;&#37325;&#37319;&#26679;&#29992;&#20110;&#38543;&#26426;&#25511;&#21046;&#20013;&#30340;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
$K$-Nearest-Neighbor Resampling for Off-Policy Evaluation in Stochastic Control. (arXiv:2306.04836v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04836
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;$K$&#26368;&#36817;&#37051;&#37325;&#37319;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#31639;&#21382;&#21490;&#25968;&#25454;&#20013;&#30001;&#19981;&#21516;&#31574;&#30053;&#29983;&#25104;&#30340;&#20915;&#31574;&#36807;&#31243;&#30340;&#24615;&#33021;&#65292;&#35299;&#20915;&#20102;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#20013;&#30340;&#21453;&#20107;&#23454;&#20272;&#35745;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;$K$&#26368;&#36817;&#37051;&#37325;&#37319;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#31639;&#21382;&#21490;&#25968;&#25454;&#20013;&#30001;&#19981;&#21516;&#31574;&#30053;&#29983;&#25104;&#30340;&#20915;&#31574;&#36807;&#31243;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#20381;&#36182;&#20110;&#24403;&#21069;&#29366;&#24577;&#30340;&#21453;&#39304;&#31574;&#30053;&#65292;&#36825;&#31181;&#31574;&#30053;&#36866;&#29992;&#20110;&#20855;&#26377;&#36830;&#32493;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#21644;&#25152;&#36873;&#21160;&#20316;&#24433;&#21709;&#19979;&#30340;&#31995;&#32479;&#22266;&#26377;&#38543;&#26426;&#24615;&#30340;&#29615;&#22659;&#12290;&#36825;&#20123;&#35774;&#32622;&#22312;&#35768;&#22810;&#39640;&#39118;&#38505;&#24212;&#29992;&#31243;&#24207;&#20013;&#24456;&#24120;&#35265;&#65292;&#24182;&#22312;&#38543;&#26426;&#25511;&#21046;&#30340;&#19978;&#19979;&#25991;&#20013;&#31215;&#26497;&#30740;&#31350;&#12290;&#25105;&#20204;&#30340;&#36807;&#31243;&#21033;&#29992;&#20102;&#31867;&#20284;&#30340;&#29366;&#24577;/&#21160;&#20316;&#23545;&#65288;&#22312;&#24230;&#37327;&#24847;&#20041;&#19979;&#65289;&#19982;&#31867;&#20284;&#30340;&#22870;&#21169;&#21644;&#29366;&#24577;&#36716;&#25442;&#30456;&#20851;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#30340;&#37325;&#37319;&#26679;&#36807;&#31243;&#36890;&#36807;&#31867;&#20284;&#20110;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#30340;&#36712;&#36857;&#27169;&#25311;&#26469;&#35299;&#20915;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#65288;OPE&#65289;&#20013;&#30340;&#21453;&#20107;&#23454;&#20272;&#35745;&#38382;&#39064;&#12290;&#19982;&#20854;&#20182;OPE&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#19981;&#38656;&#35201;&#20248;&#21270;&#65292;&#21487;&#20197;&#36890;&#36807;&#22522;&#20110;&#26641;&#30340;&#26368;&#36817;&#37051;&#25628;&#32034;&#39640;&#25928;&#23454;&#29616;&#65292;&#24182;&#19988;&#26412;&#36136;&#19978;&#26159;&#21487;&#24182;&#34892;&#21270;&#30340;&#12290;&#25105;&#20204;&#25552;&#20379;&#29702;&#35770;&#24615;&#33021;&#20445;&#35777;&#65292;&#24182;&#22312;&#22522;&#20934;&#29615;&#22659;&#19979;&#23637;&#31034;&#20102;&#25105;&#20204;&#31639;&#27861;&#30340;&#20248;&#36234;&#23454;&#39564;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel $K$-nearest neighbor resampling procedure for estimating the performance of a policy from historical data containing realized episodes of a decision process generated under a different policy. We focus on feedback policies that depend deterministically on the current state in environments with continuous state-action spaces and system-inherent stochasticity effected by chosen actions. Such settings are common in a wide range of high-stake applications and are actively investigated in the context of stochastic control. Our procedure exploits that similar state/action pairs (in a metric sense) are associated with similar rewards and state transitions. This enables our resampling procedure to tackle the counterfactual estimation problem underlying off-policy evaluation (OPE) by simulating trajectories similarly to Monte Carlo methods. Compared to other OPE methods, our algorithm does not require optimization, can be efficiently implemented via tree-based nearest neighbo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36328;&#29366;&#24577;&#30340;&#22270;&#24418;&#30456;&#20284;&#24615;&#39537;&#21160;&#30340;&#27169;&#22359;&#25512;&#29702;&#26694;&#26550;&#65292;&#21487;&#20197;&#21516;&#26102;&#32771;&#34385;&#25968;&#25454;&#20013;&#30340;&#29366;&#24577;&#38388;&#21644;&#29366;&#24577;&#20869;&#20851;&#31995;&#65292;&#24182;&#20801;&#35768;&#29366;&#24577;&#20043;&#38388;&#30340;&#20250;&#35805;&#35745;&#25968;&#21644;&#25345;&#32493;&#26102;&#38388;&#30340;&#24046;&#24322;&#12290;&#23427;&#21487;&#20197;&#25552;&#21462;&#38750;&#27491;&#20132;&#32452;&#20214;&#65292;&#24182;&#19988;&#33021;&#22815;&#35782;&#21035;&#29305;&#23450;&#29366;&#24577;&#19982;&#29366;&#24577;&#38750;&#29305;&#23450;&#27169;&#22359;&#12290;</title><link>http://arxiv.org/abs/2306.04817</link><description>&lt;p&gt;
SiBBlInGS: &#20351;&#29992;&#36328;&#29366;&#24577;&#30340;&#22270;&#24418;&#30456;&#20284;&#24615;&#39537;&#21160;&#27169;&#22359;&#25512;&#29702;&#30340;&#24314;&#27169;&#22359;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
SiBBlInGS: Similarity-driven Building-Block Inference using Graphs across States. (arXiv:2306.04817v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04817
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36328;&#29366;&#24577;&#30340;&#22270;&#24418;&#30456;&#20284;&#24615;&#39537;&#21160;&#30340;&#27169;&#22359;&#25512;&#29702;&#26694;&#26550;&#65292;&#21487;&#20197;&#21516;&#26102;&#32771;&#34385;&#25968;&#25454;&#20013;&#30340;&#29366;&#24577;&#38388;&#21644;&#29366;&#24577;&#20869;&#20851;&#31995;&#65292;&#24182;&#20801;&#35768;&#29366;&#24577;&#20043;&#38388;&#30340;&#20250;&#35805;&#35745;&#25968;&#21644;&#25345;&#32493;&#26102;&#38388;&#30340;&#24046;&#24322;&#12290;&#23427;&#21487;&#20197;&#25552;&#21462;&#38750;&#27491;&#20132;&#32452;&#20214;&#65292;&#24182;&#19988;&#33021;&#22815;&#35782;&#21035;&#29305;&#23450;&#29366;&#24577;&#19982;&#29366;&#24577;&#38750;&#29305;&#23450;&#27169;&#22359;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#22810;&#32500;&#26102;&#38388;&#24207;&#21015;&#26469;&#35828;&#65292;&#25552;&#21462;&#26377;&#24847;&#20041;&#30340;&#27169;&#22359;&#26159;&#21457;&#29616;&#22797;&#26434;&#31995;&#32479;&#20013;&#26377;&#20215;&#20540;&#35265;&#35299;&#30340;&#20851;&#38190;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#24418;&#30456;&#20284;&#24615;&#39537;&#21160;&#30340;&#27169;&#22359;&#25512;&#29702;&#26694;&#26550;(SiBBlInGS)&#65292;&#29992;&#20110;&#21457;&#29616;&#27169;&#22359;&#65292;&#21516;&#26102;&#32771;&#34385;&#21040;&#25968;&#25454;&#20013;&#30340;&#29366;&#24577;&#38388;&#21644;&#29366;&#24577;&#20869;&#20851;&#31995;&#65292;&#33021;&#22815;&#25552;&#21462;&#38750;&#27491;&#20132;&#32452;&#20214;&#65292;&#24182;&#20801;&#35768;&#29366;&#24577;&#20043;&#38388;&#30340;&#20250;&#35805;&#35745;&#25968;&#21644;&#25345;&#32493;&#26102;&#38388;&#24046;&#24322;&#12290;&#27492;&#22806;&#65292;SiBBlInGS&#36824;&#20801;&#35768;&#36328;&#29366;&#24577;&#21464;&#21270;&#27169;&#22359;&#32467;&#26500;&#21644;&#27599;&#27425;&#35797;&#39564;&#30340;&#26102;&#38388;&#21464;&#24322;&#65292;&#24182;&#21487;&#35782;&#21035;&#29305;&#23450;&#29366;&#24577;&#19982;&#29366;&#24577;&#38750;&#29305;&#23450;&#27169;&#22359;&#12290;
&lt;/p&gt;
&lt;p&gt;
Interpretable methods for extracting meaningful building blocks (BBs) underlying multi-dimensional time series are vital for discovering valuable insights in complex systems. Existing techniques, however, encounter limitations that restrict their applicability to real-world systems, like reliance on orthogonality assumptions, inadequate incorporation of inter- and intra-state variability, and incapability to handle sessions of varying duration. Here, we present a framework for Similarity-driven Building Block Inference using Graphs across States (SiBBlInGS). SiBBlInGS employs a graph-based dictionary learning approach for BB discovery, simultaneously considers both inter- and intra-state relationships in the data, can extract non-orthogonal components, and allows for variations in session counts and duration across states. Additionally, SiBBlInGS allows for cross-state variations in BB structure and per-trial temporal variability, can identify state-specific vs state-invariant BBs, and
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#24037;&#20855;--&#20132;&#20114;&#24352;&#37327;&#29992;&#20110;&#36890;&#36807;&#29305;&#24449;&#23545;&#27169;&#22411;&#21644;&#25968;&#25454;&#20043;&#38388;&#30340;&#20132;&#20114;&#36827;&#34892;&#32463;&#39564;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#29305;&#24449;&#23398;&#20064;&#30340;&#27010;&#24565;&#26694;&#26550;&#65292;&#21487;&#20197;&#35299;&#37322;&#19968;&#20123;&#32463;&#39564;&#35266;&#23519;&#29616;&#35937;&#65292;&#34920;&#26126;&#28145;&#24230;&#23398;&#20064;&#21487;&#33021;&#21463;&#30410;&#20110;&#25506;&#32034;&#20256;&#32479;IID&#65288;&#29420;&#31435;&#21516;&#20998;&#24067;&#65289;&#20551;&#35774;&#20043;&#22806;&#30340;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2306.04793</link><description>&lt;p&gt;
&#35770;&#27169;&#22411;&#12289;&#25968;&#25454;&#21644;&#29305;&#24449;&#30340;&#32852;&#21512;&#20132;&#20114;
&lt;/p&gt;
&lt;p&gt;
On the Joint Interaction of Models, Data, and Features. (arXiv:2306.04793v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04793
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#24037;&#20855;--&#20132;&#20114;&#24352;&#37327;&#29992;&#20110;&#36890;&#36807;&#29305;&#24449;&#23545;&#27169;&#22411;&#21644;&#25968;&#25454;&#20043;&#38388;&#30340;&#20132;&#20114;&#36827;&#34892;&#32463;&#39564;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#29305;&#24449;&#23398;&#20064;&#30340;&#27010;&#24565;&#26694;&#26550;&#65292;&#21487;&#20197;&#35299;&#37322;&#19968;&#20123;&#32463;&#39564;&#35266;&#23519;&#29616;&#35937;&#65292;&#34920;&#26126;&#28145;&#24230;&#23398;&#20064;&#21487;&#33021;&#21463;&#30410;&#20110;&#25506;&#32034;&#20256;&#32479;IID&#65288;&#29420;&#31435;&#21516;&#20998;&#24067;&#65289;&#20551;&#35774;&#20043;&#22806;&#30340;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#29305;&#24449;&#26159;&#28145;&#24230;&#23398;&#20064;&#30340;&#19968;&#20010;&#23450;&#20041;&#24615;&#29305;&#24449;&#65292;&#20294;&#26159;&#25105;&#20204;&#23545;&#20110;&#29305;&#24449;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#25152;&#36215;&#30340;&#20316;&#29992;&#30340;&#29702;&#35299;&#20173;&#28982;&#24456;&#26377;&#38480;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#24037;&#20855;&#65292;&#20132;&#20114;&#24352;&#37327;&#65292;&#29992;&#20110;&#36890;&#36807;&#29305;&#24449;&#23545;&#27169;&#22411;&#21644;&#25968;&#25454;&#20043;&#38388;&#30340;&#20132;&#20114;&#36827;&#34892;&#32463;&#39564;&#20998;&#26512;&#12290;&#36890;&#36807;&#20132;&#20114;&#24352;&#37327;&#65292;&#25105;&#20204;&#23545;&#29305;&#24449;&#22312;&#25968;&#25454;&#20013;&#30340;&#20998;&#24067;&#20197;&#21450;&#19981;&#21516;&#38543;&#26426;&#31181;&#23376;&#30340;&#27169;&#22411;&#23398;&#20064;&#19981;&#21516;&#29305;&#24449;&#31561;&#26041;&#38754;&#20570;&#20986;&#20102;&#20960;&#20010;&#20851;&#38190;&#35266;&#23519;&#12290;&#22522;&#20110;&#36825;&#20123;&#35266;&#23519;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29305;&#24449;&#23398;&#20064;&#30340;&#27010;&#24565;&#26694;&#26550;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#19979;&#65292;&#21487;&#20197;&#36890;&#36807;&#38381;&#24335;&#24418;&#24335;&#25512;&#23548;&#20986;&#21333;&#20010;&#20551;&#35774;&#30340;&#26399;&#26395;&#20934;&#30830;&#29575;&#21644;&#19968;&#23545;&#20551;&#35774;&#30340;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#21487;&#20197;&#35299;&#37322;&#19968;&#20123;&#32463;&#39564;&#35266;&#23519;&#29616;&#35937;&#65292;&#21253;&#25324;&#26368;&#36817;&#21457;&#29616;&#30340;&#24191;&#20041;&#21270;&#19981;&#21516;&#31561;&#24335;&#65288;GDE&#65289;&#65292;&#23427;&#21487;&#20197;&#20351;&#29992;&#20165;&#26080;&#26631;&#31614;&#25968;&#25454;&#26469;&#20272;&#35745;&#27867;&#21270;&#35823;&#24046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#29702;&#35770;&#34920;&#26126;&#65292;&#28145;&#24230;&#23398;&#20064;&#21487;&#33021;&#21463;&#30410;&#20110;&#25506;&#32034;&#20256;&#32479;IID&#65288;&#29420;&#31435;&#21516;&#20998;&#24067;&#65289;&#20551;&#35774;&#20043;&#22806;&#30340;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning features from data is one of the defining characteristics of deep learning, but our theoretical understanding of the role features play in deep learning is still rudimentary. To address this gap, we introduce a new tool, the interaction tensor, for empirically analyzing the interaction between data and model through features. With the interaction tensor, we make several key observations about how features are distributed in data and how models with different random seeds learn different features. Based on these observations, we propose a conceptual framework for feature learning. Under this framework, the expected accuracy for a single hypothesis and agreement for a pair of hypotheses can both be derived in closed-form. We demonstrate that the proposed framework can explain empirically observed phenomena, including the recently discovered Generalization Disagreement Equality (GDE) that allows for estimating the generalization error with only unlabeled data. Further, our theory
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#33258;&#25105;&#30417;&#30563;&#30340;&#26041;&#24335;&#20174;&#25968;&#25454;&#28857;&#20013;&#26631;&#35782;&#20449;&#24687;&#37327;&#20016;&#23500;&#30340;&#29305;&#24449;&#65292;&#35774;&#35745;&#20102;&#19968;&#20010;&#27169;&#22411;&#21644;&#38376;&#30697;&#38453;&#26469;&#39044;&#27979;&#21487;&#35299;&#37322;&#30340;&#23454;&#20363;&#21644;&#32858;&#31867;&#32423;&#21035;&#30340;&#32858;&#31867;&#20998;&#37197;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#20013;&#39564;&#35777;&#20102;&#20854;&#21487;&#38752;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.04785</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Interpretable Deep Clustering. (arXiv:2306.04785v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04785
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#33258;&#25105;&#30417;&#30563;&#30340;&#26041;&#24335;&#20174;&#25968;&#25454;&#28857;&#20013;&#26631;&#35782;&#20449;&#24687;&#37327;&#20016;&#23500;&#30340;&#29305;&#24449;&#65292;&#35774;&#35745;&#20102;&#19968;&#20010;&#27169;&#22411;&#21644;&#38376;&#30697;&#38453;&#26469;&#39044;&#27979;&#21487;&#35299;&#37322;&#30340;&#23454;&#20363;&#21644;&#32858;&#31867;&#32423;&#21035;&#30340;&#32858;&#31867;&#20998;&#37197;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#20013;&#39564;&#35777;&#20102;&#20854;&#21487;&#38752;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32858;&#31867;&#26159;&#19968;&#39033;&#24191;&#27867;&#24212;&#29992;&#20110;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#22522;&#30784;&#23398;&#20064;&#20219;&#21153;&#12290;&#20363;&#22914;&#65292;&#29983;&#29289;&#23398;&#23478;&#32463;&#24120;&#20351;&#29992;&#32858;&#31867;&#20998;&#37197;&#26469;&#20998;&#26512;&#22522;&#22240;&#32452;&#24207;&#21015;&#12289;&#21307;&#30103;&#35760;&#24405;&#25110;&#22270;&#20687;&#12290;&#30001;&#20110;&#19979;&#28216;&#20998;&#26512;&#36890;&#24120;&#22312;&#32858;&#31867;&#32423;&#21035;&#19978;&#25191;&#34892;&#65292;&#22240;&#27492;&#20174;&#19994;&#32773;&#23547;&#27714;&#21487;&#38752;&#19988;&#21487;&#35299;&#37322;&#30340;&#32858;&#31867;&#27169;&#22411;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#23427;&#21487;&#20197;&#39044;&#27979;&#21487;&#35299;&#37322;&#30340;&#23454;&#20363;&#21644;&#32858;&#31867;&#32423;&#21035;&#30340;&#32858;&#31867;&#20998;&#37197;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#19968;&#20010;&#33258;&#25105;&#30417;&#30563;&#30340;&#36807;&#31243;&#26469;&#20174;&#27599;&#20010;&#25968;&#25454;&#28857;&#20013;&#26631;&#35782;&#20986;&#19968;&#32452;&#20449;&#24687;&#37327;&#20016;&#23500;&#30340;&#29305;&#24449;&#23376;&#38598;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#27169;&#22411;&#65292;&#29992;&#20110;&#39044;&#27979;&#32858;&#31867;&#20998;&#37197;&#21644;&#19968;&#20010;&#38376;&#30697;&#38453;&#65292;&#29992;&#20110;&#24341;&#23548;&#32858;&#31867;&#32423;&#21035;&#30340;&#29305;&#24449;&#36873;&#25321;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#20351;&#29992;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#21487;&#38752;&#22320;&#39044;&#27979;&#32858;&#31867;&#20998;&#37197;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#21487;&#20197;&#22312;&#23454;&#20363;&#21644;&#32858;&#31867;&#32423;&#21035;&#19978;&#20135;&#29983;&#21487;&#35299;&#37322;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Clustering is a fundamental learning task widely used as a first step in data analysis. For example, biologists often use cluster assignments to analyze genome sequences, medical records, or images. Since downstream analysis is typically performed at the cluster level, practitioners seek reliable and interpretable clustering models. We propose a new deep-learning framework that predicts interpretable cluster assignments at the instance and cluster levels. First, we present a self-supervised procedure to identify a subset of informative features from each data point. Then, we design a model that predicts cluster assignments and a gate matrix that leads to cluster-level feature selection. We show that the proposed method can reliably predict cluster assignments using synthetic and real data. Furthermore, we verify that our model leads to interpretable results at a sample and cluster level.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#19981;&#21464;&#22240;&#26524;&#38598;&#35206;&#30422;&#26426;&#30340;&#31639;&#27861;&#65292;&#23427;&#36991;&#20813;&#20102;&#20135;&#29983;&#34394;&#20551;&#20851;&#32852;&#65292;&#21487;&#20197;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#35782;&#21035;&#24863;&#20852;&#36259;&#21464;&#37327;&#30340;&#22240;&#26524;&#29238;&#33410;&#28857;&#12290;</title><link>http://arxiv.org/abs/2306.04777</link><description>&lt;p&gt;
&#19981;&#21464;&#22240;&#26524;&#38598;&#35206;&#30422;&#26426;
&lt;/p&gt;
&lt;p&gt;
Invariant Causal Set Covering Machines. (arXiv:2306.04777v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04777
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#19981;&#21464;&#22240;&#26524;&#38598;&#35206;&#30422;&#26426;&#30340;&#31639;&#27861;&#65292;&#23427;&#36991;&#20813;&#20102;&#20135;&#29983;&#34394;&#20551;&#20851;&#32852;&#65292;&#21487;&#20197;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#35782;&#21035;&#24863;&#20852;&#36259;&#21464;&#37327;&#30340;&#22240;&#26524;&#29238;&#33410;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#35268;&#21017;&#30340;&#27169;&#22411;&#65292;&#22914;&#20915;&#31574;&#26641;&#65292;&#22240;&#20854;&#21487;&#35299;&#37322;&#30340;&#29305;&#24615;&#21463;&#21040;&#20174;&#19994;&#32773;&#30340;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#20135;&#29983;&#36825;&#31181;&#27169;&#22411;&#30340;&#23398;&#20064;&#31639;&#27861;&#24448;&#24448;&#23481;&#26131;&#21463;&#21040;&#34394;&#20551;&#20851;&#32852;&#30340;&#24433;&#21709;&#65292;&#22240;&#27492;&#19981;&#33021;&#20445;&#35777;&#25552;&#21462;&#30340;&#26159;&#20855;&#26377;&#22240;&#26524;&#20851;&#31995;&#30340;&#27934;&#35265;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20511;&#37492;&#20102;&#19981;&#21464;&#22240;&#26524;&#39044;&#27979;&#25991;&#29486;&#20013;&#30340;&#24605;&#24819;&#65292;&#25552;&#20986;&#20102;&#19981;&#21464;&#30340;&#22240;&#26524;&#38598;&#35206;&#30422;&#26426;&#65292;&#36825;&#26159;&#19968;&#31181;&#32463;&#20856;&#30340;&#38598;&#35206;&#30422;&#26426;&#31639;&#27861;&#30340;&#25193;&#23637;&#65292;&#29992;&#20110;&#20108;&#20540;&#35268;&#21017;&#30340;&#21512;&#21462;/&#26512;&#21462;&#65292;&#21487;&#20197;&#35777;&#26126;&#23427;&#36991;&#20813;&#20102;&#34394;&#20551;&#20851;&#32852;&#12290;&#25105;&#20204;&#29702;&#35770;&#19978;&#21644;&#23454;&#36341;&#19978;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#35782;&#21035;&#24863;&#20852;&#36259;&#21464;&#37327;&#30340;&#22240;&#26524;&#29238;&#33410;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Rule-based models, such as decision trees, appeal to practitioners due to their interpretable nature. However, the learning algorithms that produce such models are often vulnerable to spurious associations and thus, they are not guaranteed to extract causally-relevant insights. In this work, we build on ideas from the invariant causal prediction literature to propose Invariant Causal Set Covering Machines, an extension of the classical Set Covering Machine algorithm for conjunctions/disjunctions of binary-valued rules that provably avoids spurious associations. We demonstrate both theoretically and empirically that our method can identify the causal parents of a variable of interest in polynomial time.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#35266;&#27979;&#20559;&#24046;&#26469;&#25913;&#36827;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#65292;&#25552;&#20986;&#19968;&#20010;&#31616;&#21333;&#30340;&#20004;&#38454;&#27573;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#19982;&#23545;&#26410;&#35266;&#27979;&#21327;&#21464;&#37327;&#30340;&#30417;&#30563;&#23398;&#20064;&#24615;&#33021;&#30456;&#24403;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.04775</link><description>&lt;p&gt;
&#21033;&#29992;&#35266;&#27979;&#20559;&#24046;&#25552;&#39640;&#30697;&#38453;&#34917;&#20840;&#30340;&#26041;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Exploiting Observation Bias to Improve Matrix Completion. (arXiv:2306.04775v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04775
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#35266;&#27979;&#20559;&#24046;&#26469;&#25913;&#36827;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#65292;&#25552;&#20986;&#19968;&#20010;&#31616;&#21333;&#30340;&#20004;&#38454;&#27573;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#19982;&#23545;&#26410;&#35266;&#27979;&#21327;&#21464;&#37327;&#30340;&#30417;&#30563;&#23398;&#20064;&#24615;&#33021;&#30456;&#24403;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31181;&#21464;&#24418;&#30340;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#65292;&#20854;&#20013;&#36755;&#20837;&#25968;&#25454;&#20197;&#20559;&#24046;&#30340;&#26041;&#24335;&#21576;&#29616;&#65292;&#31867;&#20284;&#20110;Ma&#21644;Chen&#25152;&#24341;&#20837;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#21033;&#29992;&#20559;&#24046;&#19982;&#24863;&#20852;&#36259;&#30340;&#32467;&#26524;&#20043;&#38388;&#30340;&#20849;&#20139;&#20449;&#24687;&#26469;&#25913;&#36827;&#39044;&#27979;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#20004;&#38454;&#27573;&#31639;&#27861;&#65306;&#65288;i&#65289;&#23558;&#35266;&#27979;&#27169;&#24335;&#35299;&#37322;&#20026;&#23436;&#20840;&#35266;&#27979;&#30340;&#22122;&#22768;&#30697;&#38453;&#65292;&#25105;&#20204;&#23545;&#35266;&#27979;&#27169;&#24335;&#24212;&#29992;&#20256;&#32479;&#30340;&#30697;&#38453;&#34917;&#20840;&#26041;&#27861;&#26469;&#20272;&#35745;&#28508;&#22312;&#22240;&#32032;&#20043;&#38388;&#30340;&#36317;&#31163;&#65307; (ii)&#25105;&#20204;&#23545;&#24674;&#22797;&#30340;&#29305;&#24449;&#24212;&#29992;&#30417;&#30563;&#23398;&#20064;&#26469;&#22635;&#34917;&#32570;&#22833;&#35266;&#23519;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#29575;&#65292;&#36825;&#20123;&#35823;&#24046;&#29575;&#19982;&#30456;&#24212;&#30340;&#30417;&#30563;&#23398;&#20064;&#21442;&#25968;&#29575;&#30456;&#31454;&#20105;&#65292;&#36825;&#34920;&#26126;&#25105;&#20204;&#30340;&#23398;&#20064;&#24615;&#33021;&#19982;&#20351;&#29992;&#26410;&#35266;&#27979;&#21327;&#21464;&#37327;&#30456;&#24403;&#12290;&#23454;&#35777;&#35780;&#20272;&#20351;&#29992;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#21453;&#26144;&#20102;&#31867;&#20284;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a variant of matrix completion where entries are revealed in a biased manner, adopting a model akin to that introduced by Ma and Chen. Instead of treating this observation bias as a disadvantage, as is typically the case, our goal is to exploit the shared information between the bias and the outcome of interest to improve predictions. Towards this, we propose a simple two-stage algorithm: (i) interpreting the observation pattern as a fully observed noisy matrix, we apply traditional matrix completion methods to the observation pattern to estimate the distances between the latent factors; (ii) we apply supervised learning on the recovered features to impute missing observations. We establish finite-sample error rates that are competitive with the corresponding supervised learning parametric rates, suggesting that our learning performance is comparable to having access to the unobserved covariates. Empirical evaluation using a real-world dataset reflects similar performance g
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36755;&#20986;&#36827;&#34892;&#19979;&#28216;&#32479;&#35745;&#20998;&#26512;&#65292;&#20197;&#23454;&#29616;&#26377;&#25928;&#30340;&#19979;&#28216;&#32479;&#35745;&#25512;&#26029;&#65292;&#24182;&#38477;&#20302;&#26631;&#31614;&#33719;&#21462;&#30340;&#30740;&#31350;&#25104;&#26412;80&#65285;&#65292;&#21516;&#26102;&#20445;&#35777;CSS&#30740;&#31350;&#30340;&#32479;&#35745;&#23646;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.04746</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27880;&#37322;&#36827;&#34892;&#31038;&#20250;&#31185;&#23398;&#20013;&#30340;&#26377;&#25928;&#19979;&#28216;&#32479;&#35745;&#25512;&#26029;: &#22522;&#20110;&#35774;&#35745;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Using Large Language Model Annotations for Valid Downstream Statistical Inference in Social Science: Design-Based Semi-Supervised Learning. (arXiv:2306.04746v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04746
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36755;&#20986;&#36827;&#34892;&#19979;&#28216;&#32479;&#35745;&#20998;&#26512;&#65292;&#20197;&#23454;&#29616;&#26377;&#25928;&#30340;&#19979;&#28216;&#32479;&#35745;&#25512;&#26029;&#65292;&#24182;&#38477;&#20302;&#26631;&#31614;&#33719;&#21462;&#30340;&#30740;&#31350;&#25104;&#26412;80&#65285;&#65292;&#21516;&#26102;&#20445;&#35777;CSS&#30740;&#31350;&#30340;&#32479;&#35745;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35745;&#31639;&#31038;&#20250;&#31185;&#23398;&#65288;CSS&#65289;&#20013;&#65292;&#30740;&#31350;&#20154;&#21592;&#36890;&#36807;&#20998;&#26512;&#25991;&#26723;&#26469;&#35299;&#37322;&#31038;&#20250;&#21644;&#25919;&#27835;&#29616;&#35937;&#12290;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#65292;CSS&#30740;&#31350;&#20154;&#21592;&#39318;&#20808;&#33719;&#21462;&#25991;&#26723;&#30340;&#26631;&#31614;&#65292;&#28982;&#21518;&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#22238;&#24402;&#20998;&#26512;&#26469;&#35299;&#37322;&#26631;&#31614;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26368;&#36817;&#36827;&#23637;&#21487;&#20197;&#36890;&#36807;&#22312;&#35268;&#27169;&#19978;&#20415;&#23452;&#22320;&#27880;&#37322;&#25991;&#26723;&#26469;&#38477;&#20302;CSS&#30740;&#31350;&#25104;&#26412;&#65292;&#20294;&#36825;&#20123;&#26367;&#20195;&#26631;&#31614;&#36890;&#24120;&#26159;&#19981;&#23436;&#32654;&#21644;&#26377;&#20559;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#29992;&#20110;&#20351;&#29992;LLMs&#30340;&#36755;&#20986;&#36827;&#34892;&#19979;&#28216;&#32479;&#35745;&#20998;&#26512;&#65292;&#21516;&#26102;&#20445;&#35777;&#19982;CSS&#30740;&#31350;&#22522;&#26412;&#30456;&#20851;&#30340;&#32479;&#35745;&#23646;&#24615;-&#22914;&#28176;&#36817;&#26080;&#20559;&#24615;&#21644;&#27491;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#30452;&#25509;&#22312;&#19979;&#28216;&#32479;&#35745;&#20998;&#26512;&#20013;&#20351;&#29992;LLM&#39044;&#27979;&#30340;&#26367;&#20195;&#26631;&#31614;&#20250;&#23548;&#33268;&#23454;&#36136;&#24615;&#20559;&#24046;&#21644;&#26080;&#25928;&#32622;&#20449;&#21306;&#38388;&#65292;&#21363;&#20351;&#26367;&#20195;&#20934;&#30830;&#24615;&#39640;&#36798;80-90&#65285;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#22522;&#20110;&#26080;&#20559;&#26426;&#22120;&#23398;&#20064;&#25552;&#20986;&#20102;&#22522;&#20110;&#35774;&#35745;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#65288;D-SSL&#65289;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#23558;LLM&#27880;&#37322;&#19982;&#26377;&#38024;&#23545;&#24615;&#30340;&#37319;&#26679;&#30456;&#32467;&#21512;&#65292;&#20197;&#23454;&#29616;&#26377;&#25928;&#30340;&#19979;&#28216;&#32479;&#35745;&#25512;&#26029;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#23558;&#26631;&#31614;&#33719;&#21462;&#30340;CSS&#30740;&#31350;&#25104;&#26412;&#38477;&#20302;80&#65285;&#65292;&#32780;&#19981;&#24433;&#21709;&#32479;&#35745;&#20998;&#26512;&#30340;&#26377;&#25928;&#24615;&#12290;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#25968;&#25454;&#31034;&#20363;&#34920;&#26126;&#65292;&#19982;&#30452;&#25509;&#20351;&#29992;LLM&#39044;&#27979;&#26631;&#31614;&#30456;&#27604;&#65292;D-SSL&#21487;&#20197;&#23558;&#22238;&#24402;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#25552;&#39640;&#22810;&#36798;40&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;
In computational social science (CSS), researchers analyze documents to explain social and political phenomena. In most scenarios, CSS researchers first obtain labels for documents and then explain labels using interpretable regression analyses in the second step. The recent advancements in large language models (LLMs) can lower costs for CSS research by annotating documents cheaply at scale, but such surrogate labels are often imperfect and biased. We present a new algorithm for using outputs from LLMs for downstream statistical analyses while guaranteeing statistical properties -- like asymptotic unbiasedness and proper uncertainty quantification -- which are fundamental to CSS research. We show that direct use of LLM-predicted surrogate labels in downstream statistical analyses leads to substantial bias and invalid confidence intervals, even with high surrogate accuracy of 80--90\%. To address this, we build on debiased machine learning to propose the design-based semi-supervised le
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#22914;&#20309;&#20351;&#29992;&#26631;&#20934;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#26469;&#39044;&#27979; Kronecker &#31995;&#25968;&#26159;&#21542;&#20026;&#38646;&#65292;&#24182;&#34920;&#26126;&#26426;&#22120;&#21487;&#20197;&#39640;&#31934;&#24230;&#22320;&#25191;&#34892;&#27492;&#20108;&#20803;&#20998;&#31867;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2306.04734</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064; Kronecker &#31995;&#25968;
&lt;/p&gt;
&lt;p&gt;
Machine-Learning Kronecker Coefficients. (arXiv:2306.04734v1 [math.RT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04734
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22914;&#20309;&#20351;&#29992;&#26631;&#20934;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#26469;&#39044;&#27979; Kronecker &#31995;&#25968;&#26159;&#21542;&#20026;&#38646;&#65292;&#24182;&#34920;&#26126;&#26426;&#22120;&#21487;&#20197;&#39640;&#31934;&#24230;&#22320;&#25191;&#34892;&#27492;&#20108;&#20803;&#20998;&#31867;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Kronecker &#31995;&#25968;&#26159;&#23545;&#31216;&#32676;&#30340;&#20004;&#20010;&#19981;&#21487;&#32422;&#34920;&#31034;&#24352;&#37327;&#31215;&#30340;&#20998;&#35299;&#37325;&#25968;&#12290;&#19982; Littlewood-Richardson &#31995;&#25968;&#65288;&#24191;&#20041;&#32447;&#24615;&#32676;&#19978;&#30340;&#31867;&#27604;&#29289;&#65289;&#19981;&#21516;&#65292;&#36824;&#27809;&#26377;&#24050;&#30693;&#30340; Kronecker &#31995;&#25968;&#32452;&#21512;&#25551;&#36848;&#26041;&#24335;&#65292;&#36890;&#36807;&#31639;&#27861;&#21028;&#26029;&#26576;&#20010; Kronecker &#31995;&#25968;&#26159;&#21542;&#20026;&#38646;&#26159; NP-Hard &#38382;&#39064;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#35832;&#22914;&#26368;&#36817;&#37051;&#12289;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#21644;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#20043;&#31867;&#30340;&#26631;&#20934;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#34987;&#35757;&#32451;&#26469;&#39044;&#27979;&#32473;&#23450;&#30340; Kronecker &#31995;&#25968;&#26159;&#21542;&#20026;&#38646;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#35757;&#32451;&#22909;&#30340;&#26426;&#22120;&#21487;&#20197;&#39640;&#31934;&#24230;&#65288;$\approx 0.98$&#65289;&#22320;&#25191;&#34892;&#27492;&#20108;&#20803;&#20998;&#31867;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Kronecker coefficients are the decomposition multiplicities of the tensor product of two irreducible representations of the symmetric group. Unlike the Littlewood--Richardson coefficients, which are the analogues for the general linear group, there is no known combinatorial description of the Kronecker coefficients, and it is an NP-hard problem to decide whether a given Kronecker coefficient is zero or not. In this paper, we show that standard machine-learning algorithms such as Nearest Neighbors, Convolutional Neural Networks and Gradient Boosting Decision Trees may be trained to predict whether a given Kronecker coefficient is zero or not. Our results show that a trained machine can efficiently perform this binary classification with high accuracy ($\approx 0.98$).
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#33258;&#28982;&#38408;&#20540;&#31639;&#27861;&#65292;&#29992;&#20110;&#31232;&#30095;&#20449;&#21495;&#24674;&#22797;&#65292;&#24182;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;&#33258;&#28982;&#38408;&#20540;&#27861;&#65292;&#21487;&#20197;&#25552;&#39640;&#31639;&#27861;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.04730</link><description>&lt;p&gt;
&#38543;&#26426;&#33258;&#28982;&#38408;&#20540;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Stochastic Natural Thresholding Algorithms. (arXiv:2306.04730v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04730
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#33258;&#28982;&#38408;&#20540;&#31639;&#27861;&#65292;&#29992;&#20110;&#31232;&#30095;&#20449;&#21495;&#24674;&#22797;&#65292;&#24182;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;&#33258;&#28982;&#38408;&#20540;&#27861;&#65292;&#21487;&#20197;&#25552;&#39640;&#31639;&#27861;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#20449;&#21495;&#24674;&#22797;&#26159;&#21508;&#31181;&#24212;&#29992;&#20013;&#26368;&#22522;&#26412;&#30340;&#38382;&#39064;&#20043;&#19968;&#65292;&#21253;&#25324;&#21307;&#23398;&#25104;&#20687;&#21644;&#36965;&#24863;&#12290;&#35768;&#22810;&#22522;&#20110;&#30828;&#38408;&#20540;&#31639;&#23376;&#26063;&#30340;&#36138;&#23146;&#31639;&#27861;&#24050;&#34987;&#24320;&#21457;&#29992;&#20110;&#35299;&#20915;&#31232;&#30095;&#20449;&#21495;&#24674;&#22797;&#38382;&#39064;&#12290;&#26368;&#36817;&#65292;&#25552;&#20986;&#20102;&#33258;&#28982;&#38408;&#20540;&#27861;&#65288;NT&#65289;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;NT&#20174;&#24102;&#32447;&#24615;&#27979;&#37327;&#30340;&#30830;&#23450;&#29256;&#26412;&#25193;&#23637;&#21040;&#20855;&#26377;&#19968;&#33324;&#30446;&#26631;&#20989;&#25968;&#30340;&#38543;&#26426;&#29256;&#26412;&#65292;&#25552;&#20986;&#24182;&#35752;&#35770;&#20102;&#38543;&#26426;&#33258;&#28982;&#38408;&#20540;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;&#12290;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#21508;&#31181;&#25968;&#20540;&#23454;&#39564;&#65292;&#23545;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#27979;&#37327;&#36827;&#34892;&#20102;&#28436;&#31034;&#65292;&#20197;&#23637;&#31034;StoNT&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse signal recovery is one of the most fundamental problems in various applications, including medical imaging and remote sensing. Many greedy algorithms based on the family of hard thresholding operators have been developed to solve the sparse signal recovery problem. More recently, Natural Thresholding (NT) has been proposed with improved computational efficiency. This paper proposes and discusses convergence guarantees for stochastic natural thresholding algorithms by extending the NT from the deterministic version with linear measurements to the stochastic version with a general objective function. We also conduct various numerical experiments on linear and nonlinear measurements to demonstrate the performance of StoNT.
&lt;/p&gt;</description></item><item><title>&#31995;&#32479;&#22320;&#30740;&#31350;&#20102;&#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#30340;&#35780;&#20272;&#65292;&#21457;&#29616;&#24120;&#35265;&#30340;&#35780;&#20215;&#25351;&#26631;&#22914;FID&#31561;&#19981;&#33021;&#24456;&#22909;&#22320;&#20307;&#29616;&#25193;&#25955;&#27169;&#22411;&#30340;&#24863;&#30693;&#30495;&#23454;&#24615;&#65292;&#24314;&#35758;&#20351;&#29992;SwAV&#29305;&#24449;&#25552;&#21462;&#22120;&#32467;&#21512;FID&#36827;&#34892;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2306.04675</link><description>&lt;p&gt;
&#25581;&#31034;&#29983;&#25104;&#27169;&#22411;&#35780;&#20215;&#24230;&#37327;&#30340;&#32570;&#38519;&#21450;&#20854;&#19981;&#20844;&#24179;&#23545;&#24453;&#25193;&#25955;&#27169;&#22411;&#30340;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
Exposing flaws of generative model evaluation metrics and their unfair treatment of diffusion models. (arXiv:2306.04675v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04675
&lt;/p&gt;
&lt;p&gt;
&#31995;&#32479;&#22320;&#30740;&#31350;&#20102;&#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#30340;&#35780;&#20272;&#65292;&#21457;&#29616;&#24120;&#35265;&#30340;&#35780;&#20215;&#25351;&#26631;&#22914;FID&#31561;&#19981;&#33021;&#24456;&#22909;&#22320;&#20307;&#29616;&#25193;&#25955;&#27169;&#22411;&#30340;&#24863;&#30693;&#30495;&#23454;&#24615;&#65292;&#24314;&#35758;&#20351;&#29992;SwAV&#29305;&#24449;&#25552;&#21462;&#22120;&#32467;&#21512;FID&#36827;&#34892;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#31995;&#32479;&#22320;&#30740;&#31350;&#20102;&#35768;&#22810;&#31181;&#22522;&#20110;&#22270;&#20687;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#21253;&#25324;&#35821;&#20041;&#22810;&#26679;&#30340;&#25968;&#25454;&#38598;&#65292;&#20197;&#29702;&#35299;&#21644;&#25913;&#36827;&#29992;&#20110;&#35780;&#20272;&#23427;&#20204;&#30340;&#29305;&#24449;&#25552;&#21462;&#22120;&#21644;&#24230;&#37327;&#12290;&#20351;&#29992;&#24515;&#29702;&#29289;&#29702;&#23398;&#30340;&#26368;&#20339;&#23454;&#36341;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#36804;&#20170;&#20026;&#27490;&#26368;&#22823;&#35268;&#27169;&#30340;&#29983;&#25104;&#27169;&#22411;&#35780;&#20272;&#23454;&#39564;&#65292;&#36890;&#36807;&#23545;&#29983;&#25104;&#26679;&#26412;&#36827;&#34892;&#20154;&#31867;&#24863;&#30693;&#22270;&#20687;&#30495;&#23454;&#24615;&#30340;&#27979;&#37327;&#65292;&#21457;&#29616;&#27809;&#26377;&#20219;&#20309;&#29616;&#26377;&#30340;&#24230;&#37327;&#33021;&#19982;&#20154;&#31867;&#35780;&#20272;&#24378;&#30456;&#20851;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#29992;&#20110;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#25972;&#20307;&#24615;&#33021;&#12289;&#20445;&#30495;&#24230;&#12289;&#22810;&#26679;&#24615;&#21644;&#35760;&#24518;&#33021;&#21147;&#30340;16&#20010;&#29616;&#20195;&#25351;&#26631;&#65292;&#21457;&#29616;&#20197;&#20154;&#31867;&#20026;&#22522;&#20934;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#26368;&#20808;&#36827;&#30340;&#24863;&#30693;&#30495;&#23454;&#24615;&#19981;&#21453;&#26144;&#22312;&#24120;&#35265;&#30340;&#24230;&#37327;&#25351;&#26631;&#65292;&#22914;FID&#20013;&#12290;&#36825;&#31181;&#24046;&#24322;&#24182;&#19981;&#33021;&#36890;&#36807;&#29983;&#25104;&#26679;&#26412;&#30340;&#22810;&#26679;&#24615;&#26469;&#35299;&#37322;&#65292;&#23613;&#31649;&#20854;&#20013;&#19968;&#20010;&#21407;&#22240;&#26159;&#36807;&#24230;&#20381;&#36182;&#20110;Inception-V3&#12290;&#36890;&#36807;&#30740;&#31350;&#26367;&#20195;&#30340;&#33258;&#30417;&#30563;&#29305;&#24449;&#25552;&#21462;&#22120;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#36825;&#20123;&#32570;&#38519;&#65292;&#21457;&#29616;&#20010;&#21035;&#24369;Downstream&#20219;&#21153;&#32534;&#30721;&#30340;&#35821;&#20041;&#20449;&#24687;&#26368;&#33021;&#35299;&#37322;&#22270;&#20687;&#30495;&#23454;&#24615;&#65292;&#24314;&#35758;&#22312;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#26102;&#20351;&#29992;SwAV&#29305;&#24449;&#25552;&#21462;&#22120;&#32467;&#21512;FID&#12290;
&lt;/p&gt;
&lt;p&gt;
We systematically study a wide variety of image-based generative models spanning semantically-diverse datasets to understand and improve the feature extractors and metrics used to evaluate them. Using best practices in psychophysics, we measure human perception of image realism for generated samples by conducting the largest experiment evaluating generative models to date, and find that no existing metric strongly correlates with human evaluations. Comparing to 16 modern metrics for evaluating the overall performance, fidelity, diversity, and memorization of generative models, we find that the state-of-the-art perceptual realism of diffusion models as judged by humans is not reflected in commonly reported metrics such as FID. This discrepancy is not explained by diversity in generated samples, though one cause is over-reliance on Inception-V3. We address these flaws through a study of alternative self-supervised feature extractors, find that the semantic information encoded by individu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;Conformal Prediction&#26041;&#27861;&#65292;&#20351;&#29992;&#21487;&#35757;&#32451;&#30340;&#21464;&#37327;&#21464;&#25442;&#37325;&#26032;&#23450;&#20041;&#31526;&#21512;&#24230;&#37327;&#65292;&#20351;&#24471;&#39044;&#27979;&#21306;&#38388;&#22312;&#20445;&#25345;&#36793;&#38469;&#26377;&#25928;&#30340;&#21516;&#26102;&#20855;&#26377;&#23545;&#35937;&#23646;&#24615;&#30456;&#20851;&#30340;&#22823;&#23567;&#12290;&#36890;&#36807;&#35757;&#32451;&#21487;&#26368;&#22823;&#21270;&#38388;&#38548;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.04648</link><description>&lt;p&gt;
&#35770;&#35757;&#32451;&#26412;&#22320;&#33258;&#36866;&#24212;&#30340;&#25490;&#21517;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
On training locally adaptive CP. (arXiv:2306.04648v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04648
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;Conformal Prediction&#26041;&#27861;&#65292;&#20351;&#29992;&#21487;&#35757;&#32451;&#30340;&#21464;&#37327;&#21464;&#25442;&#37325;&#26032;&#23450;&#20041;&#31526;&#21512;&#24230;&#37327;&#65292;&#20351;&#24471;&#39044;&#27979;&#21306;&#38388;&#22312;&#20445;&#25345;&#36793;&#38469;&#26377;&#25928;&#30340;&#21516;&#26102;&#20855;&#26377;&#23545;&#35937;&#23646;&#24615;&#30456;&#20851;&#30340;&#22823;&#23567;&#12290;&#36890;&#36807;&#35757;&#32451;&#21487;&#26368;&#22823;&#21270;&#38388;&#38548;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#20351;&#31526;&#21512;&#24615;&#39044;&#27979;&#65288;CP&#65289;&#38388;&#38548;&#26412;&#22320;&#33258;&#36866;&#24212;&#30340;&#38382;&#39064;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#38598;&#20013;&#20110;&#36890;&#36807;&#21010;&#20998;&#25110;&#37325;&#26032;&#21152;&#26435;&#26657;&#20934;&#38598;&#26469;&#36817;&#20284;&#38388;&#38548;&#30340;&#23545;&#35937;&#26465;&#20214;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#31574;&#30053;&#26159;&#26032;&#30340;&#19988;&#27010;&#24565;&#19978;&#19981;&#21516;&#12290;&#25105;&#20204;&#19981;&#26159;&#37325;&#26032;&#21152;&#26435;&#26657;&#20934;&#25968;&#25454;&#65292;&#32780;&#26159;&#36890;&#36807;&#21487;&#35757;&#32451;&#30340;&#21464;&#37327;&#21464;&#25442;$A \to \phi_X(A)$&#37325;&#26032;&#23450;&#20041;&#31526;&#21512;&#24230;&#37327;&#65292;&#35813;&#21464;&#25442;&#26126;&#30830;&#22320;&#21462;&#20915;&#20110;&#23545;&#35937;&#23646;&#24615;$X$&#12290;&#22312;&#26576;&#20123;&#26465;&#20214;&#19979;&#65292;&#22914;&#26524;$\phi_X$&#23545;&#20110;&#20219;&#20309;$X$&#22312;$A$&#20013;&#26159;&#21333;&#35843;&#30340;&#65292;&#21017;&#21464;&#25442;&#23558;&#29983;&#25104;&#20445;&#35777;&#26159;&#36793;&#38469;&#26377;&#25928;&#19988;&#20855;&#26377;$X$&#30456;&#20851;&#22823;&#23567;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#22914;&#20309;&#23545;$\phi_X$&#36827;&#34892;&#21442;&#25968;&#21270;&#21644;&#35757;&#32451;&#20197;&#26368;&#22823;&#21270;&#38388;&#38548;&#25928;&#29575;&#12290;&#19982;&#20854;&#20182;CP-aware&#35757;&#32451;&#26041;&#27861;&#30456;&#21453;&#65292;&#30446;&#26631;&#20989;&#25968;&#26159;&#24179;&#28369;&#30340;&#65292;&#21487;&#20197;&#36890;&#36807;&#26631;&#20934;&#26799;&#24230;&#26041;&#27861;&#36827;&#34892;&#26368;&#23567;&#21270;&#32780;&#26080;&#38656;&#36827;&#34892;&#36924;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;
We address the problem of making Conformal Prediction (CP) intervals locally adaptive. Most existing methods focus on approximating the object-conditional validity of the intervals by partitioning or re-weighting the calibration set. Our strategy is new and conceptually different. Instead of re-weighting the calibration data, we redefine the conformity measure through a trainable change of variables, $A \to \phi_X(A)$, that depends explicitly on the object attributes, $X$. Under certain conditions and if $\phi_X$ is monotonic in $A$ for any $X$, the transformations produce prediction intervals that are guaranteed to be marginally valid and have $X$-dependent sizes. We describe how to parameterize and train $\phi_X$ to maximize the interval efficiency. Contrary to other CP-aware training methods, the objective function is smooth and can be minimized through standard gradient methods without approximations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#31163;&#25955;&#20248;&#21270;&#26041;&#27861;&#26469;&#35299;&#20915;&#21387;&#32553;&#24863;&#30693;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#22312;&#20108;&#27425;&#38181;&#26494;&#24347;&#19979;&#65292;&#21487;&#20197;&#25214;&#21040;&#26368;&#31232;&#30095;&#30340;&#21521;&#37327;&#65292;&#24471;&#21040;&#20102;&#21487;&#38752;&#30340;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2306.04647</link><description>&lt;p&gt;
&#21387;&#32553;&#24863;&#30693;&#65306;&#31163;&#25955;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Compressed Sensing: A Discrete Optimization Approach. (arXiv:2306.04647v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04647
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#31163;&#25955;&#20248;&#21270;&#26041;&#27861;&#26469;&#35299;&#20915;&#21387;&#32553;&#24863;&#30693;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#22312;&#20108;&#27425;&#38181;&#26494;&#24347;&#19979;&#65292;&#21487;&#20197;&#25214;&#21040;&#26368;&#31232;&#30095;&#30340;&#21521;&#37327;&#65292;&#24471;&#21040;&#20102;&#21487;&#38752;&#30340;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21387;&#32553;&#24863;&#30693;&#38382;&#39064;&#65292;&#21363;&#25214;&#21040;&#26368;&#31232;&#30095;&#30340;&#21521;&#37327;&#65292;&#35813;&#21521;&#37327;&#28385;&#36275;&#19968;&#32452;&#32447;&#24615;&#27979;&#37327;&#65292;&#21516;&#26102;&#36798;&#21040;&#19968;&#23450;&#30340;&#25968;&#20540;&#23481;&#38480;&#12290;&#21387;&#32553;&#24863;&#30693;&#26159;&#32479;&#35745;&#23398;&#12289;&#36816;&#31609;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#26680;&#24515;&#38382;&#39064;&#65292;&#24212;&#29992;&#20110;&#20449;&#21495;&#22788;&#29702;&#12289;&#25968;&#25454;&#21387;&#32553;&#21644;&#22270;&#20687;&#37325;&#24314;&#31561;&#39046;&#22495;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#24102;&#26377;$\ell_2$&#27491;&#21017;&#21270;&#30340;&#21387;&#32553;&#24863;&#30693;&#38382;&#39064;&#65292;&#23558;&#20854;&#20316;&#20026;&#28151;&#21512;&#25972;&#25968;&#20108;&#27425;&#38181;&#35268;&#21010;&#26469;&#37325;&#26032;&#23450;&#20041;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#27492;&#38382;&#39064;&#30340;&#20108;&#27425;&#38181;&#26494;&#24347;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#27491;&#21017;&#21270;&#21442;&#25968;&#30340;&#28201;&#21644;&#38480;&#21046;&#19979;&#65292;&#24471;&#21040;&#30340;&#26494;&#24347;&#31561;&#20215;&#20110;&#28145;&#20837;&#30740;&#31350;&#30340;&#22522;&#30784;&#36861;&#36394;&#21435;&#22122;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21322;&#23450;&#26494;&#24347;&#26469;&#21152;&#24378;&#20108;&#27425;&#38181;&#26494;&#24347;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#23450;&#21046;&#30340;&#20998;&#25903;&#23450;&#30028;&#31639;&#27861;&#65292;&#21033;&#29992;&#25105;&#20204;&#30340;&#20108;&#27425;&#38181;&#26494;&#24347;&#26469;&#35299;&#20915;&#21387;&#32553;&#24863;&#30693;&#38382;&#39064;&#30340;&#23454;&#20363;&#65292;&#20197;&#30830;&#35777;&#30340;&#26368;&#20248;&#35299;&#12290;&#25105;&#20204;&#30340;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20135;&#29983;&#30340;&#35299;&#20915;&#26041;&#26696;&#26159;&#31934;&#30830;&#30340;&#65292;&#24182;&#19988;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the Compressed Sensing (CS) problem, which is the problem of finding the most sparse vector that satisfies a set of linear measurements up to some numerical tolerance. CS is a central problem in Statistics, Operations Research and Machine Learning which arises in applications such as signal processing, data compression and image reconstruction. We introduce an $\ell_2$ regularized formulation of CS which we reformulate as a mixed integer second order cone program. We derive a second order cone relaxation of this problem and show that under mild conditions on the regularization parameter, the resulting relaxation is equivalent to the well studied basis pursuit denoising problem. We present a semidefinite relaxation that strengthens the second order cone relaxation and develop a custom branch-and-bound algorithm that leverages our second order cone relaxation to solve instances of CS to certifiable optimality. Our numerical results show that our approach produces solutions that 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;&#20107;&#23454;&#39044;&#27979;&#38598;&#30340;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#35774;&#35745;&#26041;&#27861;&#65292;&#19981;&#21516;&#20110;&#20256;&#32479;&#30340;&#21333;&#19968;&#26631;&#31614;&#39044;&#27979;&#65292;&#23427;&#20351;&#29992;&#31526;&#21512;&#39044;&#27979;&#22120;&#26500;&#24314;&#39044;&#27979;&#38598;&#65292;&#24182;&#24341;&#23548;&#20154;&#31867;&#19987;&#23478;&#20174;&#20013;&#36873;&#25321;&#26631;&#31614;&#20540;&#12290;</title><link>http://arxiv.org/abs/2306.03928</link><description>&lt;p&gt;
&#20351;&#29992;&#21453;&#20107;&#23454;&#39044;&#27979;&#38598;&#35774;&#35745;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Designing Decision Support Systems Using Counterfactual Prediction Sets. (arXiv:2306.03928v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03928
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;&#20107;&#23454;&#39044;&#27979;&#38598;&#30340;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#35774;&#35745;&#26041;&#27861;&#65292;&#19981;&#21516;&#20110;&#20256;&#32479;&#30340;&#21333;&#19968;&#26631;&#31614;&#39044;&#27979;&#65292;&#23427;&#20351;&#29992;&#31526;&#21512;&#39044;&#27979;&#22120;&#26500;&#24314;&#39044;&#27979;&#38598;&#65292;&#24182;&#24341;&#23548;&#20154;&#31867;&#19987;&#23478;&#20174;&#20013;&#36873;&#25321;&#26631;&#31614;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#31867;&#20219;&#21153;&#30340;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#36890;&#24120;&#34987;&#35774;&#35745;&#29992;&#20110;&#39044;&#27979;&#22320;&#38754;&#23454;&#20917;&#26631;&#31614;&#30340;&#20540;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23427;&#20204;&#30340;&#39044;&#27979;&#24182;&#19981;&#23436;&#32654;&#65292;&#36825;&#20123;&#31995;&#32479;&#36824;&#38656;&#35201;&#35753;&#20154;&#31867;&#19987;&#23478;&#20102;&#35299;&#20309;&#26102;&#20197;&#21450;&#22914;&#20309;&#20351;&#29992;&#36825;&#20123;&#39044;&#27979;&#26469;&#26356;&#26032;&#33258;&#24049;&#30340;&#39044;&#27979;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#34987;&#35777;&#26126;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#26368;&#36817;&#26377;&#20154;&#35748;&#20026;&#65292;&#21478;&#19968;&#31181;&#31867;&#22411;&#30340;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#21487;&#33021;&#20250;&#36991;&#24320;&#36825;&#20010;&#25361;&#25112;&#12290;&#36825;&#20123;&#31995;&#32479;&#19981;&#26159;&#25552;&#20379;&#21333;&#20010;&#26631;&#31614;&#39044;&#27979;&#65292;&#32780;&#26159;&#20351;&#29992;&#31526;&#21512;&#39044;&#27979;&#22120;&#26500;&#24314;&#19968;&#32452;&#26631;&#31614;&#39044;&#27979;&#20540;&#65292;&#21363;&#39044;&#27979;&#38598;&#65292;&#24182;&#24378;&#21046;&#35201;&#27714;&#19987;&#23478;&#20174;&#39044;&#27979;&#38598;&#20013;&#39044;&#27979;&#19968;&#20010;&#26631;&#31614;&#20540;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31995;&#32479;&#30340;&#35774;&#35745;&#21644;&#35780;&#20272;&#36804;&#20170;&#20173;&#20381;&#36182;&#20110;&#26679;&#24335;&#21270;&#30340;&#19987;&#23478;&#27169;&#22411;&#65292;&#36825;&#24341;&#21457;&#20102;&#20154;&#20204;&#23545;&#23427;&#20204;&#30340;&#25215;&#35834;&#30340;&#36136;&#30097;&#12290;&#26412;&#25991;&#20174;&#22312;&#32447;&#23398;&#20064;&#30340;&#35282;&#24230;&#37325;&#26032;&#23457;&#35270;&#20102;&#36825;&#31181;&#31995;&#32479;&#30340;&#35774;&#35745;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#19981;&#38656;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
Decision support systems for classification tasks are predominantly designed to predict the value of the ground truth labels. However, since their predictions are not perfect, these systems also need to make human experts understand when and how to use these predictions to update their own predictions. Unfortunately, this has been proven challenging. In this context, it has been recently argued that an alternative type of decision support systems may circumvent this challenge. Rather than providing a single label prediction, these systems provide a set of label prediction values constructed using a conformal predictor, namely a prediction set, and forcefully ask experts to predict a label value from the prediction set. However, the design and evaluation of these systems have so far relied on stylized expert models, questioning their promise. In this paper, we revisit the design of this type of systems from the perspective of online learning and develop a methodology that does not requi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35821;&#35328;&#20064;&#24471;&#21451;&#22909;&#22411;&#22522;&#20934;&#65292;&#20197;&#26816;&#39564;&#33258;&#25105;&#30417;&#30563;&#21475;&#35821;&#35821;&#35328;&#27169;&#22411;&#22312;&#20799;&#31461;&#35789;&#27719;&#21644;&#21477;&#27861;&#32463;&#21382;&#20013;&#30340;&#34920;&#29616;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#38656;&#35201;&#35299;&#20915;&#30340;&#25361;&#25112;&#65306;&#25991;&#26412;&#21644;&#35821;&#38899;&#20043;&#38388;&#30340;&#24046;&#36317;&#21644;&#24178;&#20928;&#35821;&#38899;&#21644;&#37326;&#22806;&#35821;&#38899;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2306.01506</link><description>&lt;p&gt;
BabySLM: &#33258;&#25105;&#30417;&#30563;&#21475;&#35821;&#35821;&#35328;&#27169;&#22411;&#30340;&#35821;&#35328;&#20064;&#24471;&#21451;&#22909;&#22411;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
BabySLM: language-acquisition-friendly benchmark of self-supervised spoken language models. (arXiv:2306.01506v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01506
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35821;&#35328;&#20064;&#24471;&#21451;&#22909;&#22411;&#22522;&#20934;&#65292;&#20197;&#26816;&#39564;&#33258;&#25105;&#30417;&#30563;&#21475;&#35821;&#35821;&#35328;&#27169;&#22411;&#22312;&#20799;&#31461;&#35789;&#27719;&#21644;&#21477;&#27861;&#32463;&#21382;&#20013;&#30340;&#34920;&#29616;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#38656;&#35201;&#35299;&#20915;&#30340;&#25361;&#25112;&#65306;&#25991;&#26412;&#21644;&#35821;&#38899;&#20043;&#38388;&#30340;&#24046;&#36317;&#21644;&#24178;&#20928;&#35821;&#38899;&#21644;&#37326;&#22806;&#35821;&#38899;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24050;&#32463;&#35777;&#26126;&#65292;&#23398;&#20064;&#35821;&#38899;&#34920;&#31034;&#30340;&#33258;&#25105;&#30417;&#30563;&#25216;&#26415;&#33021;&#22815;&#20174;&#21548;&#21040;&#30340;&#35821;&#38899;&#20013;&#21457;&#23637;&#20986;&#35821;&#35328;&#33021;&#21147;&#65292;&#32780;&#26080;&#38656;&#20154;&#31867;&#26631;&#31614;&#12290;&#20026;&#20102;&#20805;&#20998;&#21457;&#25381;&#36825;&#20123;&#26041;&#27861;&#30340;&#28508;&#21147;&#24182;&#36827;&#19968;&#27493;&#20102;&#35299;&#23156;&#20799;&#23398;&#20064;&#35821;&#35328;&#30340;&#26041;&#24335;&#65292;&#27169;&#25311;&#24517;&#39035;&#32039;&#23494;&#27169;&#20223;&#29616;&#23454;&#24773;&#20917;&#65292;&#36890;&#36807;&#22312;&#24320;&#21457;&#19978;&#31526;&#21512;&#20799;&#31461;&#35821;&#35328;&#32463;&#39564;&#20856;&#22411;&#35789;&#27719;&#24211;&#21644;&#23545;&#24212;&#27979;&#35797;&#38598;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26816;&#27979;&#22312;&#35789;&#27719;&#21644;&#21477;&#27861;&#23618;&#38754;&#19978;&#30340;&#21475;&#35821;&#35821;&#35328;&#27169;&#22411;&#30340;&#35821;&#35328;&#20064;&#24471;&#21451;&#22909;&#22411;&#22522;&#20934;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#27492;&#22522;&#20934;&#65292;&#24182;&#24635;&#32467;&#20102;&#19968;&#31995;&#21015;&#23454;&#39564;&#65292;&#35777;&#26126;&#20854;&#26377;&#29992;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24378;&#35843;&#20102;&#38656;&#35201;&#35299;&#20915;&#30340;&#20004;&#20010;&#25361;&#25112;&#65306;&#22635;&#34917;&#25991;&#26412;&#21644;&#35821;&#38899;&#20043;&#38388;&#20197;&#21450;&#24178;&#20928;&#35821;&#38899;&#21644;&#37326;&#22806;&#35821;&#38899;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-supervised techniques for learning speech representations have been shown to develop linguistic competence from exposure to speech without the need for human labels. In order to fully realize the potential of these approaches and further our understanding of how infants learn language, simulations must closely emulate real-life situations by training on developmentally plausible corpora and benchmarking against appropriate test sets. To this end, we propose a language-acquisition-friendly benchmark to probe spoken language models at the lexical and syntactic levels, both of which are compatible with the vocabulary typical of children's language experiences. This paper introduces the benchmark and summarizes a range of experiments showing its usefulness. In addition, we highlight two exciting challenges that need to be addressed for further progress: bridging the gap between text and speech and between clean speech and in-the-wild speech.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20351;&#29992;GPT-4&#35299;&#20915;&#26356;&#22797;&#26434;&#21644;&#26377;&#25361;&#25112;&#24615;&#30340;&#25968;&#23398;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MathChat&#30340;&#23545;&#35805;&#24335;&#38382;&#39064;&#27714;&#35299;&#26694;&#26550;&#65292;&#24182;&#22312;&#22256;&#38590;&#39640;&#20013;&#31454;&#36187;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2306.01337</link><description>&lt;p&gt;
&#22522;&#20110;GPT-4&#30340;&#22797;&#26434;&#25968;&#23398;&#38382;&#39064;&#27714;&#35299;&#30340;&#23454;&#35777;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
An Empirical Study on Challenging Math Problem Solving with GPT-4. (arXiv:2306.01337v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01337
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20351;&#29992;GPT-4&#35299;&#20915;&#26356;&#22797;&#26434;&#21644;&#26377;&#25361;&#25112;&#24615;&#30340;&#25968;&#23398;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MathChat&#30340;&#23545;&#35805;&#24335;&#38382;&#39064;&#27714;&#35299;&#26694;&#26550;&#65292;&#24182;&#22312;&#22256;&#38590;&#39640;&#20013;&#31454;&#36187;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26469;&#35299;&#20915;&#25968;&#23398;&#38382;&#39064;&#26159;&#19968;&#39033;&#26377;&#36259;&#30340;&#30740;&#31350;&#65292;&#32771;&#34385;&#21040;&#22312;&#21508;&#31181;&#31185;&#23398;&#21644;&#24037;&#31243;&#39046;&#22495;&#20013;&#29992;&#33258;&#28982;&#35821;&#35328;&#34920;&#36798;&#30340;&#25968;&#23398;&#38382;&#39064;&#30340;&#20016;&#23500;&#24615;&#12290;&#34429;&#28982;&#20043;&#21069;&#26377;&#20960;&#39033;&#24037;&#20316;&#30740;&#31350;&#20102;&#20351;&#29992;LLM&#35299;&#20915;&#21021;&#31561;&#25968;&#23398;&#38382;&#39064;&#65292;&#20294;&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#20351;&#29992;GPT-4&#35299;&#20915;&#26356;&#22797;&#26434;&#21644;&#26377;&#25361;&#25112;&#24615;&#30340;&#25968;&#23398;&#38382;&#39064;&#30340;&#21069;&#27839;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#20351;&#29992;GPT-4&#30340;&#21508;&#31181;&#26041;&#27861;&#12290;&#20854;&#20013;&#19968;&#20123;&#26159;&#20174;&#29616;&#26377;&#24037;&#20316;&#20013;&#25913;&#32534;&#32780;&#26469;&#30340;&#65292;&#20854;&#20013;&#19968;&#20010;&#26159;MathChat&#65292;&#36825;&#26159;&#26412;&#30740;&#31350;&#26032;&#25552;&#20986;&#30340;&#19968;&#31181;&#23545;&#35805;&#24335;&#38382;&#39064;&#27714;&#35299;&#26694;&#26550;&#12290;&#25105;&#20204;&#22312;&#26469;&#33258;MATH&#25968;&#25454;&#38598;&#30340;&#22256;&#38590;&#39640;&#20013;&#31454;&#36187;&#38382;&#39064;&#19978;&#36827;&#34892;&#35780;&#20272;&#65292;&#34920;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#23545;&#35805;&#24335;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Employing Large Language Models (LLMs) to address mathematical problems is an intriguing research endeavor, considering the abundance of math problems expressed in natural language across numerous science and engineering fields. While several prior works have investigated solving elementary mathematics using LLMs, this work explores the frontier of using GPT-4 for solving more complex and challenging math problems. We evaluate various ways of using GPT-4. Some of them are adapted from existing work, and one is \MathChat, a conversational problem-solving framework newly proposed in this work. We perform the evaluation on difficult high school competition problems from the MATH dataset, which shows the advantage of the proposed conversational approach.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#19968;&#31181;&#26032;&#30340;&#26657;&#20934;&#39044;&#27979;&#30446;&#26631;&#8212;&#8212;parity&#26657;&#20934;&#65292;&#20854;&#32771;&#34385;&#26102;&#38388;&#24207;&#21015;&#20013;&#26410;&#26469;&#35266;&#27979;&#20540;&#30340;&#22686;&#21152;&#25110;&#20943;&#23569;&#12290;&#25105;&#20204;&#20351;&#29992;&#22312;&#32447;&#20108;&#36827;&#21046;&#26657;&#20934;&#26041;&#27861;&#23454;&#29616;&#20102;parity&#26657;&#20934;&#65292;&#24182;&#22312;&#27969;&#34892;&#30149;&#23398;&#12289;&#22825;&#27668;&#39044;&#25253;&#21644;&#26680;&#32858;&#21464;&#25511;&#21046;&#31561;&#39046;&#22495;&#20013;&#34920;&#26126;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.18655</link><description>&lt;p&gt;
Parity&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Parity Calibration. (arXiv:2305.18655v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18655
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#19968;&#31181;&#26032;&#30340;&#26657;&#20934;&#39044;&#27979;&#30446;&#26631;&#8212;&#8212;parity&#26657;&#20934;&#65292;&#20854;&#32771;&#34385;&#26102;&#38388;&#24207;&#21015;&#20013;&#26410;&#26469;&#35266;&#27979;&#20540;&#30340;&#22686;&#21152;&#25110;&#20943;&#23569;&#12290;&#25105;&#20204;&#20351;&#29992;&#22312;&#32447;&#20108;&#36827;&#21046;&#26657;&#20934;&#26041;&#27861;&#23454;&#29616;&#20102;parity&#26657;&#20934;&#65292;&#24182;&#22312;&#27969;&#34892;&#30149;&#23398;&#12289;&#22825;&#27668;&#39044;&#25253;&#21644;&#26680;&#32858;&#21464;&#25511;&#21046;&#31561;&#39046;&#22495;&#20013;&#34920;&#26126;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24207;&#21015;&#22238;&#24402;&#35774;&#32622;&#20013;&#65292;&#20915;&#31574;&#32773;&#21487;&#33021;&#26356;&#20851;&#27880;&#26410;&#26469;&#35266;&#27979;&#20540;&#26159;&#21542;&#27604;&#24403;&#21069;&#20540;&#22686;&#21152;&#25110;&#20943;&#23569;&#65292;&#32780;&#19981;&#26159;&#26410;&#26469;&#35266;&#27979;&#20540;&#30340;&#23454;&#38469;&#20540;&#12290;&#22312;&#27492;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#24179;&#31561;&#26657;&#20934;&#30340;&#27010;&#24565;&#65292;&#23427;&#25429;&#25417;&#20102;&#26102;&#38388;&#24207;&#21015;&#22686;&#20943;&#20107;&#20214;&#30340;&#26657;&#20934;&#39044;&#27979;&#30446;&#26631;&#12290;&#24179;&#31561;&#27010;&#29575;&#21487;&#20197;&#20174;&#36755;&#20986;&#30340;&#39044;&#27979;&#20998;&#24067;&#20013;&#25552;&#21462;&#65292;&#20294;&#25105;&#20204;&#26174;&#31034;&#36825;&#31181;&#31574;&#30053;&#23548;&#33268;&#29702;&#35770;&#19978;&#30340;&#19981;&#21487;&#39044;&#27979;&#24615;&#21644;&#24046;&#21170;&#30340;&#23454;&#38469;&#24615;&#33021;&#12290;&#28982;&#21518;&#25105;&#20204;&#21457;&#29616;&#65292;&#34429;&#28982;&#21407;&#20219;&#21153;&#26159;&#22238;&#24402;&#65292;&#20294;&#24179;&#31561;&#26657;&#20934;&#21487;&#20197;&#34987;&#34920;&#36798;&#20026;&#20108;&#36827;&#21046;&#26657;&#20934;&#12290;&#22522;&#20110;&#36825;&#31181;&#32852;&#31995;&#65292;&#25105;&#20204;&#20351;&#29992;&#22312;&#32447;&#20108;&#36827;&#21046;&#26657;&#20934;&#26041;&#27861;&#23454;&#29616;&#20102;&#24179;&#31561;&#26657;&#20934;&#12290;&#25105;&#20204;&#36890;&#36807;&#27969;&#34892;&#30149;&#23398;&#12289;&#22825;&#27668;&#39044;&#25253;&#21644;&#22522;&#20110;&#27169;&#22411;&#30340;&#26680;&#32858;&#21464;&#25511;&#21046;&#30340;&#23454;&#38469;&#26696;&#20363;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In a sequential regression setting, a decision-maker may be primarily concerned with whether the future observation will increase or decrease compared to the current one, rather than the actual value of the future observation. In this context, we introduce the notion of parity calibration, which captures the goal of calibrated forecasting for the increase-decrease (or "parity") event in a timeseries. Parity probabilities can be extracted from a forecasted distribution for the output, but we show that such a strategy leads to theoretical unpredictability and poor practical performance. We then observe that although the original task was regression, parity calibration can be expressed as binary calibration. Drawing on this connection, we use an online binary calibration method to achieve parity calibration. We demonstrate the effectiveness of our approach on real-world case studies in epidemiology, weather forecasting, and model-based control in nuclear fusion.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20048;&#35266;&#30340;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#24102;&#26377;&#20840;&#20449;&#24687;&#21453;&#39304;&#30340;&#21608;&#26399;&#24615;&#23545;&#25239;&#24615;&#32447;&#24615;MDP&#65292;&#22312;&#38543;&#26426;&#32447;&#24615;MDP&#21644;&#24102;&#26377;&#20840;&#20449;&#24687;&#30340;&#25932;&#23545;&#32447;&#24615;MDP&#20013;&#65292;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#21518;&#24724;&#36793;&#30028;&#65292;&#24182;&#20855;&#26377;&#26032;&#39062;&#30340;&#22810;&#25209;&#27425;&#26356;&#26032;&#26426;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.08841</link><description>&lt;p&gt;
&#20048;&#35266;&#30340;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#22312;&#32447;&#24615;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#29702;&#35770;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Theoretical Analysis of Optimistic Proximal Policy Optimization in Linear Markov Decision Processes. (arXiv:2305.08841v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08841
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20048;&#35266;&#30340;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#24102;&#26377;&#20840;&#20449;&#24687;&#21453;&#39304;&#30340;&#21608;&#26399;&#24615;&#23545;&#25239;&#24615;&#32447;&#24615;MDP&#65292;&#22312;&#38543;&#26426;&#32447;&#24615;MDP&#21644;&#24102;&#26377;&#20840;&#20449;&#24687;&#30340;&#25932;&#23545;&#32447;&#24615;MDP&#20013;&#65292;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#21518;&#24724;&#36793;&#30028;&#65292;&#24182;&#20855;&#26377;&#26032;&#39062;&#30340;&#22810;&#25209;&#27425;&#26356;&#26032;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#65288;PPO&#65289;&#31639;&#27861;&#26159;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#20013;&#26368;&#25104;&#21151;&#30340;&#26041;&#27861;&#20043;&#19968;&#12290;&#23613;&#31649;PPO&#24456;&#25104;&#21151;&#65292;&#20294;&#26159;&#23545;&#20110;PPO&#21450;&#20854;&#20048;&#35266;&#21464;&#31181;&#26159;&#21542;&#33021;&#26377;&#25928;&#35299;&#20915;&#32447;&#24615;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;(MDPs)&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#19981;&#36275;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20048;&#35266;&#30340;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#24102;&#26377;&#20840;&#20449;&#24687;&#21453;&#39304;&#30340;&#21608;&#26399;&#25932;&#23545;&#32447;&#24615;MDP&#65292;&#24182;&#20026;&#20854;&#24314;&#31435;&#20102;&#19968;&#20010;$\tilde{\mathcal{O}}(d^{3/4}H^2K^{3/4})$&#30340;&#21518;&#24724;&#20540;&#12290;&#20854;&#20013;$d$&#26159;&#32447;&#24615;MDPs&#30340;&#29615;&#22659;&#32500;&#25968;&#65292;$H$&#26159;&#27599;&#20010;&#21608;&#26399;&#30340;&#38271;&#24230;&#65292;$K$&#26159;&#21608;&#26399;&#25968;&#12290;&#19982;&#29616;&#26377;&#30340;&#22522;&#20110;&#31574;&#30053;&#30340;&#31639;&#27861;&#30456;&#27604;&#65292;&#22312;&#38543;&#26426;&#32447;&#24615;MDP&#21644;&#24102;&#26377;&#20840;&#20449;&#24687;&#30340;&#25932;&#23545;&#32447;&#24615;MDP&#20013;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#24403;&#20170;&#26368;&#20808;&#36827;&#30340;&#21518;&#24724;&#36793;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#35774;&#35745;&#20855;&#26377;&#26032;&#39062;&#30340;&#22810;&#25209;&#27425;&#26356;&#26032;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
The proximal policy optimization (PPO) algorithm stands as one of the most prosperous methods in the field of reinforcement learning (RL). Despite its success, the theoretical understanding of PPO remains deficient. Specifically, it is unclear whether PPO or its optimistic variants can effectively solve linear Markov decision processes (MDPs), which are arguably the simplest models in RL with function approximation. To bridge this gap, we propose an optimistic variant of PPO for episodic adversarial linear MDPs with full-information feedback, and establish a $\tilde{\mathcal{O}}(d^{3/4}H^2K^{3/4})$ regret for it. Here $d$ is the ambient dimension of linear MDPs, $H$ is the length of each episode, and $K$ is the number of episodes. Compared with existing policy-based algorithms, we achieve the state-of-the-art regret bound in both stochastic linear MDPs and adversarial linear MDPs with full information. Additionally, our algorithm design features a novel multi-batched updating mechanism
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#34920;&#26126;&#65292;&#20174;&#39640;&#32500;&#24179;&#28369;&#30446;&#26631;&#20998;&#24067;&#37319;&#26679;&#26102;&#65292;Metropolized Hamiltonian Monte Carlo (HMC)&#27604;Metropolis-adjusted Langevin&#31639;&#27861;&#65288;MALA&#65289;&#26356;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2304.04724</link><description>&lt;p&gt;
Metropolized Hamiltonian Monte Carlo&#20309;&#26102;&#33021;&#35777;&#26126;&#20248;&#20110;Metropolis-adjusted Langevin&#31639;&#27861;&#65311;
&lt;/p&gt;
&lt;p&gt;
When does Metropolized Hamiltonian Monte Carlo provably outperform Metropolis-adjusted Langevin algorithm?. (arXiv:2304.04724v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04724
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#34920;&#26126;&#65292;&#20174;&#39640;&#32500;&#24179;&#28369;&#30446;&#26631;&#20998;&#24067;&#37319;&#26679;&#26102;&#65292;Metropolized Hamiltonian Monte Carlo (HMC)&#27604;Metropolis-adjusted Langevin&#31639;&#27861;&#65288;MALA&#65289;&#26356;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;Metropolized Hamiltonian Monte Carlo (HMC)&#30340;&#28151;&#21512;&#26102;&#38388;&#65292;&#20351;&#29992;leapfrog&#31215;&#20998;&#22120;&#20174;$\mathbb{R}^d$&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#35813;&#20998;&#24067;&#30340;&#23545;&#25968;&#23494;&#24230;&#24179;&#28369;&#65292;&#20855;&#26377;Frobenius&#33539;&#25968;&#19978;&#30340;&#26446;&#26222;&#24076;&#33576;&#40657;&#22622;&#65292;&#24182;&#28385;&#36275;&#31561;&#21608;&#24615;&#12290;&#25105;&#20204;&#23558;&#26799;&#24230;&#22797;&#26434;&#24230;&#38480;&#21046;&#20026;&#20174;&#19968;&#20010;&#26262;&#21551;&#21160;&#36798;&#21040;$\epsilon$&#35823;&#24046;&#30340;&#24635;&#21464;&#24322;&#36317;&#31163;&#25152;&#38656;&#30340;$\tilde O(d^{1/4}\text{polylog}(1/\epsilon))$&#65292;&#24182;&#23637;&#31034;&#20102;&#36873;&#25321;&#27604;1&#26356;&#22823;&#30340;leapfrog&#27493;&#25968;&#30340;&#22909;&#22788;&#12290;&#20026;&#20102;&#36229;&#36234;Wu&#31561;&#20154;&#65288;2022&#65289;&#23545;Metropolis-adjusted Langevin algorithm (MALA)&#30340;&#20998;&#26512;&#65292;&#20854;&#22312;&#32500;&#24230;&#20381;&#36182;&#24615;&#19978;&#26159;$\tilde{O}(d^{1/2}\text{polylog}(1/\epsilon))$&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#35777;&#26126;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#29305;&#24449;&#65306;&#36830;&#32493;HMC&#21160;&#24577;&#30340;&#20301;&#32622;&#21644;&#36895;&#24230;&#21464;&#37327;&#30340;&#31163;&#25955;&#21270;&#30340;&#32852;&#21512;&#20998;&#24067;&#36817;&#20284;&#19981;&#21464;&#12290;&#24403;&#36890;&#36807;leapfrog&#27493;&#25968;&#30340;&#24402;&#32435;&#26469;&#23637;&#31034;&#36825;&#20010;&#20851;&#38190;&#29305;&#24449;&#26102;&#65292;&#25105;&#20204;&#33021;&#22815;&#33719;&#24471;&#21508;&#31181;&#37327;&#30340;&#30697;&#30340;&#20272;&#35745;&#65292;&#36825;&#20123;&#37327;&#22312;&#38480;&#21046;Metropolized HMC&#30340;&#28151;&#21512;&#26102;&#38388;&#26102;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#65292;&#32780;&#22312;MALA&#20013;&#24050;&#30693;&#30340;&#31867;&#20284;&#32467;&#26524;&#26159;&#38169;&#35823;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#37319;&#26679;&#39640;&#32500;&#24179;&#28369;&#30446;&#26631;&#20998;&#24067;&#26102;&#65292;&#20351;&#29992;&#20855;&#26377;&#22823;&#37327;leapfrog&#27493;&#39588;&#30340;Metropolized HMC&#21487;&#33021;&#27604;&#20351;&#29992;MALA&#26356;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyze the mixing time of Metropolized Hamiltonian Monte Carlo (HMC) with the leapfrog integrator to sample from a distribution on $\mathbb{R}^d$ whose log-density is smooth, has Lipschitz Hessian in Frobenius norm and satisfies isoperimetry. We bound the gradient complexity to reach $\epsilon$ error in total variation distance from a warm start by $\tilde O(d^{1/4}\text{polylog}(1/\epsilon))$ and demonstrate the benefit of choosing the number of leapfrog steps to be larger than 1. To surpass previous analysis on Metropolis-adjusted Langevin algorithm (MALA) that has $\tilde{O}(d^{1/2}\text{polylog}(1/\epsilon))$ dimension dependency in Wu et al. (2022), we reveal a key feature in our proof that the joint distribution of the location and velocity variables of the discretization of the continuous HMC dynamics stays approximately invariant. This key feature, when shown via induction over the number of leapfrog steps, enables us to obtain estimates on moments of various quantities tha
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#65292;&#22312;&#20809;&#28369;&#21644;&#31561;&#21608;&#26465;&#20214;&#19979;&#65292;MALA&#30340;&#28151;&#21512;&#26102;&#38388;&#20165;&#19982;Hessian&#30697;&#38453;&#30340;trace&#26377;&#20851;&#65292;&#32780;&#19982;&#20854;&#31639;&#23376;&#33539;&#25968;&#21644;log-concave&#27809;&#26377;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2304.04095</link><description>&lt;p&gt;
&#20803;&#21345;&#27931;&#35843;&#25972;&#26391;&#20043;&#19975;(MALA)&#22312;&#20809;&#28369;&#19988;&#31561;&#21608;&#26465;&#20214;&#19979;&#30340;&#28151;&#21512;&#31616;&#21333;&#35777;&#26126;
&lt;/p&gt;
&lt;p&gt;
A Simple Proof of the Mixing of Metropolis-Adjusted Langevin Algorithm under Smoothness and Isoperimetry. (arXiv:2304.04095v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04095
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#65292;&#22312;&#20809;&#28369;&#21644;&#31561;&#21608;&#26465;&#20214;&#19979;&#65292;MALA&#30340;&#28151;&#21512;&#26102;&#38388;&#20165;&#19982;Hessian&#30697;&#38453;&#30340;trace&#26377;&#20851;&#65292;&#32780;&#19982;&#20854;&#31639;&#23376;&#33539;&#25968;&#21644;log-concave&#27809;&#26377;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;$\mathbb{R}^d$&#19978;&#26679;&#26412;&#30446;&#26631;&#23494;&#24230;&#30340;&#20803;&#21345;&#27931;&#35843;&#25972;&#26391;&#20043;&#19975;&#65288;MALA&#65289;&#30340;&#28151;&#21512;&#26102;&#38388;&#12290;&#25105;&#20204;&#20551;&#35774;&#30446;&#26631;&#23494;&#24230;&#28385;&#36275;$\psi_\mu$-&#31561;&#21608;&#21644;&#23427;&#30340;&#40657;&#22622;&#30697;&#38453;&#30340;trace&#21644;&#31639;&#23376;&#33539;&#25968;&#20998;&#21035;&#21463;$L$&#21644;$\Upsilon$&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#35770;&#26159;&#65292;&#20174;&#28909;&#21551;&#21160;&#24320;&#22987;&#65292;&#20026;&#20102;&#36798;&#21040;$\epsilon$&#24635;&#21464;&#24046;&#36317;&#31163;&#65292;MALA&#22312;$O\left(\frac{(L\Upsilon)^{\frac12}}{\psi_\mu^2} \log\left(\frac{1}{\epsilon}\right)\right)$&#27425;&#36845;&#20195;&#20013;&#28151;&#21512;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#35813;&#32467;&#26524;&#19981;&#20165;&#36866;&#29992;&#20110;&#23545;&#25968;&#20985;&#37319;&#26679;&#35774;&#32622;&#65292;&#32780;&#19988;&#28151;&#21512;&#26102;&#38388;&#20165;&#21462;&#20915;&#20110;$\Upsilon$&#65292;&#32780;&#19981;&#26159;&#20854;&#19978;&#30028;$Ld$&#12290;&#22312;$m$-&#24378;&#23545;&#25968;&#20985;&#21644;$L$-&#20809;&#28369;&#37319;&#26679;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#24674;&#22797;&#20102;&#20197;&#21069;&#30340;MALA&#30340;&#26368;&#23567;&#20540;&#28151;&#21512;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the mixing time of Metropolis-Adjusted Langevin algorithm (MALA) for sampling a target density on $\mathbb{R}^d$. We assume that the target density satisfies $\psi_\mu$-isoperimetry and that the operator norm and trace of its Hessian are bounded by $L$ and $\Upsilon$ respectively. Our main result establishes that, from a warm start, to achieve $\epsilon$-total variation distance to the target density, MALA mixes in $O\left(\frac{(L\Upsilon)^{\frac12}}{\psi_\mu^2} \log\left(\frac{1}{\epsilon}\right)\right)$ iterations. Notably, this result holds beyond the log-concave sampling setting and the mixing time depends on only $\Upsilon$ rather than its upper bound $L d$. In the $m$-strongly logconcave and $L$-log-smooth sampling setting, our bound recovers the previous minimax mixing bound of MALA~\cite{wu2021minimax}.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;DP-Fast MH&#31639;&#27861;&#65292;&#29992;&#20110;&#22823;&#35268;&#27169;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#20855;&#26377;&#31934;&#30830;&#12289;&#24555;&#36895;&#21644;&#38544;&#31169;&#20445;&#25252;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2303.06171</link><description>&lt;p&gt;
DP-Fast MH: &#22823;&#35268;&#27169;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#31169;&#26377;&#12289;&#24555;&#36895;&#12289;&#20934;&#30830;&#30340;Metropolis-Hastings&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
DP-Fast MH: Private, Fast, and Accurate Metropolis-Hastings for Large-Scale Bayesian Inference. (arXiv:2303.06171v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06171
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;DP-Fast MH&#31639;&#27861;&#65292;&#29992;&#20110;&#22823;&#35268;&#27169;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#20855;&#26377;&#31934;&#30830;&#12289;&#24555;&#36895;&#21644;&#38544;&#31169;&#20445;&#25252;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a new DP-Fast MH algorithm for large-scale Bayesian inference, which is accurate, fast, and privacy-preserving.
&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#25512;&#26029;&#25552;&#20379;&#20102;&#19968;&#20010;&#20174;&#22797;&#26434;&#25968;&#25454;&#20013;&#23398;&#20064;&#21644;&#22312;&#19981;&#30830;&#23450;&#24615;&#19979;&#25512;&#29702;&#30340;&#21407;&#21017;&#24615;&#26694;&#26550;&#12290;&#23427;&#24050;&#32463;&#24191;&#27867;&#24212;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#22914;&#21307;&#23398;&#35786;&#26029;&#12289;&#33647;&#29289;&#35774;&#35745;&#21644;&#25919;&#31574;&#21046;&#23450;&#12290;&#22312;&#36825;&#20123;&#24120;&#35265;&#24212;&#29992;&#20013;&#65292;&#25968;&#25454;&#21487;&#33021;&#38750;&#24120;&#25935;&#24863;&#12290;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#25552;&#20379;&#20102;&#20855;&#26377;&#24378;&#22823;&#26368;&#22351;&#24773;&#20917;&#38544;&#31169;&#20445;&#35777;&#30340;&#25968;&#25454;&#20998;&#26512;&#24037;&#20855;&#65292;&#24182;&#24050;&#21457;&#23637;&#25104;&#20026;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#20998;&#26512;&#30340;&#20027;&#35201;&#26041;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Metropolis-Hastings&#65288;MH&#65289;&#31639;&#27861;&#65292;&#36825;&#26159;&#26368;&#22522;&#26412;&#30340;MCMC&#26041;&#27861;&#20043;&#19968;&#65292;&#29992;&#20110;&#24046;&#20998;&#38544;&#31169;&#19979;&#30340;&#22823;&#35268;&#27169;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#34429;&#28982;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#31169;&#26377;MCMC&#31639;&#27861;&#20026;&#20102;&#33719;&#24471;&#38544;&#31169;&#32780;&#29306;&#29298;&#20102;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#65292;&#20294;&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#31934;&#30830;&#19988;&#24555;&#36895;&#30340;DP MH&#31639;&#27861;&#65292;&#22823;&#22810;&#25968;&#36845;&#20195;&#20013;&#20165;&#20351;&#29992;&#19968;&#20010;&#23567;&#25209;&#37327;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25581;&#31034;&#20102;&#38544;&#31169;&#12289;&#21487;&#25193;&#23637;&#24615;&#65288;&#21363;&#25209;&#37327;&#22823;&#23567;&#65289;&#21644;&#25928;&#29575;&#65288;&#21363;&#25910;&#25947;&#36895;&#24230;&#65289;&#20043;&#38388;&#30340;&#19977;&#37325;&#26435;&#34913;&#65292;&#20174;&#29702;&#35770;&#19978;&#35828;&#26126;&#20102;&#36825;&#19968;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian inference provides a principled framework for learning from complex data and reasoning under uncertainty. It has been widely applied in machine learning tasks such as medical diagnosis, drug design, and policymaking. In these common applications, the data can be highly sensitive. Differential privacy (DP) offers data analysis tools with powerful worst-case privacy guarantees and has been developed as the leading approach in privacy-preserving data analysis. In this paper, we study Metropolis-Hastings (MH), one of the most fundamental MCMC methods, for large-scale Bayesian inference under differential privacy. While most existing private MCMC algorithms sacrifice accuracy and efficiency to obtain privacy, we provide the first exact and fast DP MH algorithm, using only a minibatch of data in most iterations. We further reveal, for the first time, a three-way trade-off among privacy, scalability (i.e. the batch size), and efficiency (i.e. the convergence rate), theoretically char
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#25216;&#26415;&#65292;&#23558;&#39640;&#32500;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#31169;&#26377;&#21442;&#25968;&#20272;&#35745;&#38382;&#39064;&#38477;&#20302;&#21040;&#38750;&#31169;&#26377;&#31639;&#27861;&#65292;&#20174;&#32780;&#20351;&#29616;&#26377;&#30340;&#38750;&#31169;&#26377;&#31639;&#27861;&#33021;&#22815;&#22312;&#38544;&#31169;&#20445;&#25252;&#30340;&#26465;&#20214;&#19979;&#20351;&#29992;&#65292;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#30340;&#31169;&#26377;&#23398;&#20064;GMMs&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2303.04288</link><description>&lt;p&gt;
&#22810;&#39033;&#24335;&#26102;&#38388;&#21644;&#31169;&#26377;&#23398;&#20064;&#26080;&#38480;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Polynomial Time and Private Learning of Unbounded Gaussian Mixture Models. (arXiv:2303.04288v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.04288
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#25216;&#26415;&#65292;&#23558;&#39640;&#32500;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#31169;&#26377;&#21442;&#25968;&#20272;&#35745;&#38382;&#39064;&#38477;&#20302;&#21040;&#38750;&#31169;&#26377;&#31639;&#27861;&#65292;&#20174;&#32780;&#20351;&#29616;&#26377;&#30340;&#38750;&#31169;&#26377;&#31639;&#27861;&#33021;&#22815;&#22312;&#38544;&#31169;&#20445;&#25252;&#30340;&#26465;&#20214;&#19979;&#20351;&#29992;&#65292;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#30340;&#31169;&#26377;&#23398;&#20064;GMMs&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;$k$&#20010;&#32452;&#20214;&#21644;$d$&#32500;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;(GMMs)&#31169;&#19979;&#20272;&#35745;&#21442;&#25968;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#25216;&#26415;&#65292;&#23558;&#27492;&#38382;&#39064;&#20943;&#23569;&#21040;&#38750;&#31169;&#26377;&#31639;&#27861;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#20197;&#40657;&#30418;&#26041;&#24335;&#31169;&#26377;&#21270;&#29616;&#26377;&#30340;&#38750;&#31169;&#26377;&#31639;&#27861;&#65292;&#21516;&#26102;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#21644;&#36816;&#34892;&#26102;&#38388;&#26041;&#38754;&#20165;&#20135;&#29983;&#23569;&#37327;&#24320;&#38144;&#12290;&#20316;&#20026;&#25105;&#20204;&#26694;&#26550;&#30340;&#20027;&#35201;&#24212;&#29992;&#65292;&#25105;&#20204;&#20351;&#29992;Moitra&#21644;Valiant [MV10]&#30340;&#38750;&#31169;&#26377;&#31639;&#27861;&#24320;&#21457;&#20102;&#19968;&#20010;$(\varepsilon, \delta)$-&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#26469;&#23398;&#20064;GMMs&#12290;&#32467;&#26524;&#65292;&#36825;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#19981;&#23545;&#21442;&#25968;&#36827;&#34892;&#20219;&#20309;&#26377;&#30028;&#24615;&#20551;&#35774;&#30340;&#31169;&#26377;&#23398;&#20064;GMMs&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#19978;&#30028;&#21644;&#31532;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#12290;&#20316;&#20026;&#25105;&#20204;&#20998;&#26512;&#30340;&#19968;&#37096;&#20998;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#39640;&#32500;&#39640;&#26031;&#20998;&#24067;&#30340;&#24635;&#21464;&#24046;&#36317;&#31163;&#30340;&#32039;&#23494;(&#39640;&#36798;&#24120;&#25968;&#22240;&#23376;)&#19979;&#30028;&#65292;&#36825;&#21487;&#20197;&#29420;&#31435;&#22320;&#24471;&#21040;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of privately estimating the parameters of $d$-dimensional Gaussian Mixture Models (GMMs) with $k$ components. For this, we develop a technique to reduce the problem to its non-private counterpart. This allows us to privatize existing non-private algorithms in a blackbox manner, while incurring only a small overhead in the sample complexity and running time. As the main application of our framework, we develop an $(\varepsilon, \delta)$-differentially private algorithm to learn GMMs using the non-private algorithm of Moitra and Valiant [MV10] as a blackbox. Consequently, this gives the first sample complexity upper bound and first polynomial time algorithm for privately learning GMMs without any boundedness assumptions on the parameters. As part of our analysis, we prove a tight (up to a constant factor) lower bound on the total variation distance of high-dimensional Gaussians which can be of independent interest.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33021;&#37327;&#25193;&#25955;&#27169;&#22411;&#21644;MCMC&#30340;&#32452;&#21512;&#29983;&#25104;&#26041;&#27861;&#65292;&#26088;&#22312;&#35299;&#20915;&#29616;&#26377;&#25216;&#26415;&#22312;&#32452;&#21512;&#29983;&#25104;&#20013;&#30340;&#22833;&#36133;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#25104;&#21151;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2302.11552</link><description>&lt;p&gt;
&#20943;&#23569;&#12289;&#37325;&#22797;&#21033;&#29992;&#12289;&#22238;&#25910;&#65306;&#22522;&#20110;&#33021;&#37327;&#25193;&#25955;&#27169;&#22411;&#21644;MCMC&#30340;&#32452;&#21512;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Reduce, Reuse, Recycle: Compositional Generation with Energy-Based Diffusion Models and MCMC. (arXiv:2302.11552v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.11552
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33021;&#37327;&#25193;&#25955;&#27169;&#22411;&#21644;MCMC&#30340;&#32452;&#21512;&#29983;&#25104;&#26041;&#27861;&#65292;&#26088;&#22312;&#35299;&#20915;&#29616;&#26377;&#25216;&#26415;&#22312;&#32452;&#21512;&#29983;&#25104;&#20013;&#30340;&#22833;&#36133;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#25104;&#21151;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#20174;&#25193;&#25955;&#27169;&#22411;&#38382;&#19990;&#20197;&#26469;&#65292;&#23427;&#22312;&#35768;&#22810;&#39046;&#22495;&#20013;&#24050;&#32463;&#36805;&#36895;&#25104;&#20026;&#29983;&#25104;&#27169;&#22411;&#30340;&#20027;&#35201;&#26041;&#27861;&#12290;&#23427;&#20204;&#21487;&#20197;&#34987;&#35299;&#37322;&#20026;&#23398;&#20064;&#19968;&#31995;&#21015;&#26102;&#21464;&#30340;&#23545;&#25968;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#30340;&#26799;&#24230;&#12290;&#36825;&#31181;&#35299;&#37322;&#24050;&#32463;&#28608;&#21457;&#20102;&#22522;&#20110;&#20998;&#31867;&#22120;&#21644;&#26080;&#20998;&#31867;&#22120;&#25351;&#23548;&#30340;&#24605;&#24819;&#25104;&#20026;&#21518;&#32493;&#25511;&#21046;&#25193;&#25955;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#22312;&#36825;&#20123;&#24819;&#27861;&#30340;&#22522;&#30784;&#19978;&#65292;&#21033;&#29992;&#25193;&#25955;&#27169;&#22411;&#30340;&#20998;&#25968;-based&#35299;&#37322;&#65292;&#25506;&#32034;&#20102;&#29992;&#20110;&#28041;&#21450;&#32452;&#21512;&#29983;&#25104;&#21644;&#25351;&#23548;&#30340;&#26465;&#20214;&#12289;&#20462;&#25913;&#21644;&#37325;&#22797;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#20026;&#20160;&#20040;&#26576;&#20123;&#31867;&#22411;&#30340;&#32452;&#21512;&#20351;&#29992;&#24403;&#21069;&#25216;&#26415;&#22833;&#36133;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#20123;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65292;&#37319;&#26679;&#32773;(&#32780;&#19981;&#26159;&#27169;&#22411;)&#23545;&#27492;&#22833;&#36133;&#36127;&#26377;&#36131;&#20219;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#37319;&#26679;&#22120;&#65292;&#21463;MCMC&#30340;&#21551;&#21457;&#65292;&#20351;&#32452;&#21512;&#29983;&#25104;&#25104;&#21151;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33021;&#37327;&#30340;&#25193;&#25955;&#27169;&#22411;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#23427;&#20351;&#24471;&#36924;&#36817;&#30446;&#26631;&#20998;&#24067;&#26356;&#21152;&#23481;&#26131;&#12290;
&lt;/p&gt;
&lt;p&gt;
Since their introduction, diffusion models have quickly become the prevailing approach to generative modeling in many domains. They can be interpreted as learning the gradients of a time-varying sequence of log-probability density functions. This interpretation has motivated classifier-based and classifier-free guidance as methods for post-hoc control of diffusion models. In this work, we build upon these ideas using the score-based interpretation of diffusion models, and explore alternative ways to condition, modify, and reuse diffusion models for tasks involving compositional generation and guidance. In particular, we investigate why certain types of composition fail using current techniques and present a number of solutions. We conclude that the sampler (not the model) is responsible for this failure and propose new samplers, inspired by MCMC, which enable successful compositional generation. Further, we propose an energy-based parameterization of diffusion models which enables the 
&lt;/p&gt;</description></item><item><title>BLiE&#26159;&#19968;&#31181;&#29992;&#20110;&#36229;&#21442;&#25968;&#20248;&#21270;&#30340;&#31639;&#27861;&#65292;&#21482;&#20551;&#35774;&#30446;&#26631;&#20989;&#25968;&#20855;&#26377;Lipschitz&#36830;&#32493;&#24615;&#12290;&#29702;&#35770;&#21644;&#23454;&#39564;&#35777;&#26126;BLiE&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#65292;&#24182;&#19988;&#21487;&#20197;&#24212;&#29992;&#20110;&#25628;&#32034;&#25193;&#25955;&#27169;&#22411;&#30340;&#22122;&#22768;&#35843;&#24230;&#12290;</title><link>http://arxiv.org/abs/2302.01539</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#36830;&#32493;&#36229;&#21442;&#25968;&#20248;&#21270;&#30340;Lipschitz&#20048;&#35266;&#31574;&#30053;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Lipschitz Bandits Approach for Continuous Hyperparameter Optimization. (arXiv:2302.01539v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.01539
&lt;/p&gt;
&lt;p&gt;
BLiE&#26159;&#19968;&#31181;&#29992;&#20110;&#36229;&#21442;&#25968;&#20248;&#21270;&#30340;&#31639;&#27861;&#65292;&#21482;&#20551;&#35774;&#30446;&#26631;&#20989;&#25968;&#20855;&#26377;Lipschitz&#36830;&#32493;&#24615;&#12290;&#29702;&#35770;&#21644;&#23454;&#39564;&#35777;&#26126;BLiE&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#65292;&#24182;&#19988;&#21487;&#20197;&#24212;&#29992;&#20110;&#25628;&#32034;&#25193;&#25955;&#27169;&#22411;&#30340;&#22122;&#22768;&#35843;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#36229;&#21442;&#25968;&#20248;&#21270;&#65288;HPO&#65289;&#26159;&#26368;&#20851;&#38190;&#30340;&#38382;&#39064;&#20043;&#19968;&#65292;&#22240;&#20026;&#36229;&#21442;&#25968;&#30340;&#36873;&#25321;&#23545;&#26368;&#32456;&#27169;&#22411;&#30340;&#24615;&#33021;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#34429;&#28982;&#26377;&#35768;&#22810;HPO&#31639;&#27861;&#65292;&#20294;&#23427;&#20204;&#35201;&#20040;&#27809;&#26377;&#29702;&#35770;&#20445;&#35777;&#65292;&#35201;&#20040;&#38656;&#35201;&#24378;&#30340;&#20551;&#35774;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;BLiE&#8212;&#8212;&#19968;&#31181;&#22522;&#20110;Lipschitz&#20048;&#35266;&#31574;&#30053;&#30340;HPO&#31639;&#27861;&#65292;&#23427;&#21482;&#20551;&#35774;&#30446;&#26631;&#20989;&#25968;&#20855;&#26377;Lipschitz&#36830;&#32493;&#24615;&#12290;BLiE&#21033;&#29992;&#30446;&#26631;&#20989;&#25968;&#30340;&#26223;&#35266;&#20197;&#33258;&#36866;&#24212;&#22320;&#25628;&#32034;&#36229;&#21442;&#25968;&#31354;&#38388;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;$(i)$ BLiE&#21457;&#29616;&#20855;&#26377;$O(\frac{1}{\epsilon})^{d_z+\beta}$&#20010;&#24635;&#39044;&#31639;&#30340;$\epsilon$&#26368;&#20248;&#36229;&#21442;&#25968;&#65292;&#20854;&#20013;$d_z$&#21644;$\beta$&#26159;&#38382;&#39064;&#20869;&#22312;&#30340;&#65307;$(ii)$ BLiE&#20855;&#26377;&#39640;&#24230;&#21487;&#24182;&#34892;&#24615;&#12290;&#23454;&#39564;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;BLiE&#22312;&#22522;&#20934;&#20219;&#21153;&#19978;&#20248;&#20110;&#29616;&#26377;&#30340;HPO&#31639;&#27861;&#12290;&#25105;&#20204;&#36824;&#24212;&#29992;BLiE&#25628;&#32034;&#25193;&#25955;&#27169;&#22411;&#30340;&#22122;&#22768;&#35843;&#24230;&#12290;&#19982;&#40664;&#35748;&#35843;&#24230;&#30456;&#27604;&#36739;&#65292;BLiE&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the most critical problems in machine learning is HyperParameter Optimization (HPO), since choice of hyperparameters has a significant impact on final model performance. Although there are many HPO algorithms, they either have no theoretical guarantees or require strong assumptions. To this end, we introduce BLiE -- a Lipschitz-bandit-based algorithm for HPO that only assumes Lipschitz continuity of the objective function. BLiE exploits the landscape of the objective function to adaptively search over the hyperparameter space. Theoretically, we show that $(i)$ BLiE finds an $\epsilon$-optimal hyperparameter with $O \left( \frac{1}{\epsilon} \right)^{d_z + \beta}$ total budgets, where $d_z$ and $\beta$ are problem intrinsic; $(ii)$ BLiE is highly parallelizable. Empirically, we demonstrate that BLiE outperforms the state-of-the-art HPO algorithms on benchmark tasks. We also apply BLiE to search for noise schedule of diffusion models. Comparison with the default schedule shows tha
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#29992;&#20110;&#40065;&#26834;&#30340;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#65292;&#24182;&#22312;&#21463;&#27745;&#26579;&#30340;&#25968;&#25454;&#27969;&#20013;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#34920;&#29616;&#20248;&#24322;&#65292;&#21516;&#26102;&#30830;&#20445;&#20102;&#31283;&#23450;&#24615;&#24182;&#20943;&#23569;&#24322;&#24120;&#20540;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2302.00422</link><description>&lt;p&gt;
&#40065;&#26834;&#30340;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Robust online active learning. (arXiv:2302.00422v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00422
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#29992;&#20110;&#40065;&#26834;&#30340;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#65292;&#24182;&#22312;&#21463;&#27745;&#26579;&#30340;&#25968;&#25454;&#27969;&#20013;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#34920;&#29616;&#20248;&#24322;&#65292;&#21516;&#26102;&#30830;&#20445;&#20102;&#31283;&#23450;&#24615;&#24182;&#20943;&#23569;&#24322;&#24120;&#20540;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24037;&#19994;&#24212;&#29992;&#20013;&#65292;&#33719;&#24471;&#26631;&#35760;&#30340;&#35266;&#27979;&#25968;&#25454;&#24182;&#19981;&#31616;&#21333;&#65292;&#36890;&#24120;&#38656;&#35201;&#20154;&#24037;&#19987;&#23478;&#24178;&#39044;&#25110;&#20351;&#29992;&#26114;&#36149;&#30340;&#27979;&#35797;&#35774;&#22791;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20027;&#21160;&#23398;&#20064;&#21487;&#20197;&#22823;&#22823;&#25552;&#39640;&#25311;&#21512;&#27169;&#22411;&#26102;&#26368;&#20449;&#24687;&#25968;&#25454;&#28857;&#30340;&#24314;&#35758;&#12290;&#20943;&#23569;&#27169;&#22411;&#24320;&#21457;&#25152;&#38656;&#30340;&#35266;&#27979;&#25968;&#25454;&#25968;&#37327;&#21487;&#20197;&#20943;&#36731;&#35757;&#32451;&#25152;&#38656;&#30340;&#35745;&#31639;&#36127;&#25285;&#21644;&#26631;&#35760;&#30456;&#20851;&#30340;&#25805;&#20316;&#25903;&#20986;&#12290;&#29305;&#21035;&#26159;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#65292;&#22312;&#38656;&#35201;&#22312;&#26497;&#30701;&#26102;&#38388;&#20869;&#20915;&#23450;&#26159;&#21542;&#33719;&#21462;&#25968;&#25454;&#28857;&#26631;&#35760;&#30340;&#39640;&#23481;&#37327;&#29983;&#20135;&#36807;&#31243;&#20013;&#38750;&#24120;&#26377;&#29992;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#26368;&#36817;&#33268;&#21147;&#20110;&#24320;&#21457;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;&#65292;&#20294;&#22312;&#23384;&#22312;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#36825;&#20123;&#26041;&#27861;&#30340;&#34892;&#20026;&#20173;&#26410;&#24471;&#21040;&#24443;&#24213;&#30740;&#31350;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#22312;&#32447;&#20027;&#21160;&#32447;&#24615;&#22238;&#24402;&#22312;&#21463;&#27745;&#26579;&#30340;&#25968;&#25454;&#27969;&#20013;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#29992;&#20110;&#40065;&#26834;&#30340;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#65292;&#21516;&#26102;&#20445;&#35777;&#31283;&#23450;&#24615;&#24182;&#20943;&#23569;&#24322;&#24120;&#20540;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many industrial applications, obtaining labeled observations is not straightforward as it often requires the intervention of human experts or the use of expensive testing equipment. In these circumstances, active learning can be highly beneficial in suggesting the most informative data points to be used when fitting a model. Reducing the number of observations needed for model development alleviates both the computational burden required for training and the operational expenses related to labeling. Online active learning, in particular, is useful in high-volume production processes where the decision about the acquisition of the label for a data point needs to be taken within an extremely short time frame. However, despite the recent efforts to develop online active learning strategies, the behavior of these methods in the presence of outliers has not been thoroughly examined. In this work, we investigate the performance of online active linear regression in contaminated data strea
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#22240;&#26524;&#22270;&#26410;&#30693;&#30340;&#24773;&#20917;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22240;&#26524;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#20351;&#29992;&#21407;&#23376;&#24178;&#39044;&#25214;&#21040;&#22870;&#21169;&#33410;&#28857;&#29238;&#33410;&#28857;&#30340;&#26377;&#25928;&#31639;&#27861;&#65292;&#24182;&#25193;&#23637;&#33267;&#22870;&#21169;&#33410;&#28857;&#20855;&#26377;&#22810;&#20010;&#29238;&#33410;&#28857;&#30340;&#24773;&#20917;&#12290;&#21516;&#26102;&#65292;&#36824;&#24471;&#20986;&#20102;&#31639;&#27861;&#25191;&#34892;&#26399;&#26395;&#24178;&#39044;&#27425;&#25968;&#30340;&#31934;&#30830;&#26041;&#31243;&#65292;&#24182;&#35777;&#26126;&#22312;&#29305;&#23450;&#22270;&#24418;&#26465;&#20214;&#19979;&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#24555;&#36895;&#25191;&#34892;&#23545;&#25968;&#12290;</title><link>http://arxiv.org/abs/2301.11401</link><description>&lt;p&gt;
&#26080;&#38656;&#22270;&#24418;&#23398;&#20064;&#30340;&#22240;&#26524;&#36172;&#21338;&#26426;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Causal Bandits without Graph Learning. (arXiv:2301.11401v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11401
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#22240;&#26524;&#22270;&#26410;&#30693;&#30340;&#24773;&#20917;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22240;&#26524;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#20351;&#29992;&#21407;&#23376;&#24178;&#39044;&#25214;&#21040;&#22870;&#21169;&#33410;&#28857;&#29238;&#33410;&#28857;&#30340;&#26377;&#25928;&#31639;&#27861;&#65292;&#24182;&#25193;&#23637;&#33267;&#22870;&#21169;&#33410;&#28857;&#20855;&#26377;&#22810;&#20010;&#29238;&#33410;&#28857;&#30340;&#24773;&#20917;&#12290;&#21516;&#26102;&#65292;&#36824;&#24471;&#20986;&#20102;&#31639;&#27861;&#25191;&#34892;&#26399;&#26395;&#24178;&#39044;&#27425;&#25968;&#30340;&#31934;&#30830;&#26041;&#31243;&#65292;&#24182;&#35777;&#26126;&#22312;&#29305;&#23450;&#22270;&#24418;&#26465;&#20214;&#19979;&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#24555;&#36895;&#25191;&#34892;&#23545;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#24403;&#22240;&#26524;&#22270;&#19981;&#30693;&#36947;&#30340;&#24773;&#20917;&#19979;&#30340;&#22240;&#26524;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#20351;&#29992;&#21407;&#23376;&#24178;&#39044;&#25214;&#21040;&#22870;&#21169;&#33410;&#28857;&#30340;&#29238;&#33410;&#28857;&#30340;&#26377;&#25928;&#31639;&#27861;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#31639;&#27861;&#25191;&#34892;&#30340;&#26399;&#26395;&#24178;&#39044;&#27425;&#25968;&#30340;&#31934;&#30830;&#26041;&#31243;&#65292;&#24182;&#34920;&#26126;&#65292;&#22312;&#26576;&#20123;&#22270;&#24418;&#26465;&#20214;&#19979;&#65292;&#23427;&#21487;&#20197;&#24555;&#36895;&#25191;&#34892;&#23545;&#25968;&#65292;&#25110;&#32773;&#22312;&#26356;&#19968;&#33324;&#30340;&#20551;&#35774;&#19979;&#65292;&#25191;&#34892;&#26356;&#24930;&#20294;&#20173;&#28982;&#26159;&#21464;&#37327;&#25968;&#30340;&#20122;&#32447;&#24615;&#32423;&#21035;&#12290;&#25105;&#20204;&#27491;&#24335;&#34920;&#26126;&#25105;&#20204;&#30340;&#31639;&#27861;&#26159;&#26368;&#20248;&#30340;&#65292;&#22240;&#20026;&#23427;&#31526;&#21512;&#25105;&#20204;&#20026;&#25191;&#34892;&#21407;&#23376;&#24178;&#39044;&#30340;&#20219;&#20309;&#31639;&#27861;&#24314;&#31435;&#30340;&#36890;&#29992;&#19979;&#30028;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#31639;&#27861;&#25193;&#23637;&#21040;&#22870;&#21169;&#33410;&#28857;&#20855;&#26377;&#22810;&#20010;&#29238;&#33410;&#28857;&#30340;&#24773;&#20917;&#12290;&#20351;&#29992;&#36825;&#20010;&#31639;&#27861;&#21644;&#26469;&#33258;&#36172;&#21338;&#25991;&#29486;&#30340;&#26631;&#20934;&#31639;&#27861;&#21487;&#20197;&#23548;&#33268;&#25913;&#36827;&#30340;&#36951;&#25022;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the causal bandit problem when the causal graph is unknown and develop an efficient algorithm for finding the parent node of the reward node using atomic interventions. We derive the exact equation for the expected number of interventions performed by the algorithm and show that under certain graphical conditions it could perform either logarithmically fast or, under more general assumptions, slower but still sublinearly in the number of variables. We formally show that our algorithm is optimal as it meets the universal lower bound we establish for any algorithm that performs atomic interventions. Finally, we extend our algorithm to the case when the reward node has multiple parents. Using this algorithm together with a standard algorithm from bandit literature leads to improved regret bounds.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#23398;&#26694;&#26550;&#65292;&#24688;&#24403;&#22320;&#34920;&#24449;&#20102;&#34987;&#35757;&#32451;&#23545;&#25968;&#25454;&#25311;&#21512;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#21151;&#33021;&#23646;&#24615;&#12290;&#36825;&#20010;&#26694;&#26550;&#35299;&#37322;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#19968;&#20123;&#20248;&#31168;&#24615;&#33021;&#12289;&#32593;&#32476;&#20307;&#31995;&#32467;&#26500;&#20013;&#36339;&#36291;&#36830;&#25509;&#21644;&#20302;&#31209;&#26435;&#37325;&#30697;&#38453;&#30340;&#20351;&#29992;&#12289;&#31232;&#30095;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20316;&#29992;&#20197;&#21450;&#20026;&#20160;&#20040;&#31070;&#32463;&#32593;&#32476;&#21487;&#20316;&#20026;&#20248;&#31168;&#30340;&#29305;&#24449;&#25552;&#21462;&#22120;&#12290;</title><link>http://arxiv.org/abs/2301.09554</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#19982;&#31232;&#30095;&#27491;&#21017;&#21270;&#65306;&#20449;&#21495;&#22788;&#29702;&#30340;&#35266;&#28857;
&lt;/p&gt;
&lt;p&gt;
Deep Learning Meets Sparse Regularization: A Signal Processing Perspective. (arXiv:2301.09554v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.09554
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#23398;&#26694;&#26550;&#65292;&#24688;&#24403;&#22320;&#34920;&#24449;&#20102;&#34987;&#35757;&#32451;&#23545;&#25968;&#25454;&#25311;&#21512;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#21151;&#33021;&#23646;&#24615;&#12290;&#36825;&#20010;&#26694;&#26550;&#35299;&#37322;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#19968;&#20123;&#20248;&#31168;&#24615;&#33021;&#12289;&#32593;&#32476;&#20307;&#31995;&#32467;&#26500;&#20013;&#36339;&#36291;&#36830;&#25509;&#21644;&#20302;&#31209;&#26435;&#37325;&#30697;&#38453;&#30340;&#20351;&#29992;&#12289;&#31232;&#30095;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20316;&#29992;&#20197;&#21450;&#20026;&#20160;&#20040;&#31070;&#32463;&#32593;&#32476;&#21487;&#20316;&#20026;&#20248;&#31168;&#30340;&#29305;&#24449;&#25552;&#21462;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#65292;&#22823;&#22810;&#25968;&#26368;&#20808;&#36827;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#37117;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#12290;&#28982;&#32780;&#65292;&#32570;&#20047;&#19968;&#20010;&#20005;&#26684;&#30340;&#25968;&#23398;&#29702;&#35770;&#65292;&#33021;&#22815;&#20805;&#20998;&#35299;&#37322;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24778;&#20154;&#24615;&#33021;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#30456;&#23545;&#36739;&#26032;&#30340;&#25968;&#23398;&#26694;&#26550;&#65292;&#25552;&#20379;&#20102;&#23545;&#28145;&#24230;&#23398;&#20064;&#30340;&#26356;&#28145;&#20837;&#29702;&#35299;&#30340;&#24320;&#31471;&#12290;&#36825;&#20010;&#26694;&#26550;&#24688;&#24403;&#22320;&#34920;&#24449;&#20102;&#34987;&#35757;&#32451;&#23545;&#25968;&#25454;&#25311;&#21512;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#21151;&#33021;&#23646;&#24615;&#12290;&#25903;&#25345;&#36825;&#20010;&#26694;&#26550;&#30340;&#20851;&#38190;&#25968;&#23398;&#24037;&#20855;&#21253;&#25324;&#21464;&#25442;&#22495;&#31232;&#30095;&#27491;&#21017;&#21270;&#12289;&#35745;&#31639;&#26426;&#26029;&#23618;&#25668;&#24433;&#30340;Radon&#21464;&#25442;&#21644;&#36924;&#36817;&#29702;&#35770;&#65292;&#36825;&#20123;&#25216;&#26415;&#37117;&#28145;&#28145;&#26681;&#26893;&#20110;&#20449;&#21495;&#22788;&#29702;&#12290;&#36825;&#20010;&#26694;&#26550;&#35299;&#37322;&#20102;&#21152;&#26435;&#34928;&#20943;&#27491;&#21017;&#21270;&#22312;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#20013;&#30340;&#20316;&#29992;&#65292;&#32593;&#32476;&#20307;&#31995;&#32467;&#26500;&#20013;&#36339;&#36291;&#36830;&#25509;&#21644;&#20302;&#31209;&#26435;&#37325;&#30697;&#38453;&#30340;&#20351;&#29992;&#65292;&#31232;&#30095;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20316;&#29992;&#65292;&#24182;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#31070;&#32463;&#32593;&#32476;&#21487;&#20316;&#20026;&#20248;&#31168;&#30340;&#29305;&#24449;&#25552;&#21462;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning has been wildly successful in practice and most state-of-the-art machine learning methods are based on neural networks. Lacking, however, is a rigorous mathematical theory that adequately explains the amazing performance of deep neural networks. In this article, we present a relatively new mathematical framework that provides the beginning of a deeper understanding of deep learning. This framework precisely characterizes the functional properties of neural networks that are trained to fit to data. The key mathematical tools which support this framework include transform-domain sparse regularization, the Radon transform of computed tomography, and approximation theory, which are all techniques deeply rooted in signal processing. This framework explains the effect of weight decay regularization in neural network training, the use of skip connections and low-rank weight matrices in network architectures, the role of sparsity in neural networks, and explains why neural networ
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20114;&#20449;&#24687;&#30340;&#21160;&#24577;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#20351;&#29992;&#25674;&#38144;&#20248;&#21270;&#36827;&#34892;&#23398;&#20064;&#12290;&#22312;&#23454;&#39564;&#20013;&#21462;&#24471;&#20102;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#22909;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2301.00557</link><description>&lt;p&gt;
&#23398;&#20064;&#26368;&#22823;&#21270;&#20114;&#20449;&#24687;&#29992;&#20110;&#21160;&#24577;&#29305;&#24449;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Learning to Maximize Mutual Information for Dynamic Feature Selection. (arXiv:2301.00557v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.00557
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20114;&#20449;&#24687;&#30340;&#21160;&#24577;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#20351;&#29992;&#25674;&#38144;&#20248;&#21270;&#36827;&#34892;&#23398;&#20064;&#12290;&#22312;&#23454;&#39564;&#20013;&#21462;&#24471;&#20102;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#22909;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#36873;&#25321;&#26377;&#21161;&#20110;&#20943;&#23569;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#25968;&#25454;&#37319;&#38598;&#25104;&#26412;&#65292;&#20294;&#26631;&#20934;&#26041;&#27861;&#26159;&#20351;&#29992;&#38745;&#24577;&#29305;&#24449;&#23376;&#38598;&#26469;&#35757;&#32451;&#27169;&#22411;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#21160;&#24577;&#29305;&#24449;&#36873;&#25321;&#65288;DFS&#65289;&#38382;&#39064;&#65292;&#21363;&#27169;&#22411;&#26681;&#25454;&#29616;&#26377;&#20449;&#24687;&#39034;&#24207;&#26597;&#35810;&#29305;&#24449;&#12290;DFS&#36890;&#24120;&#37319;&#29992;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22788;&#29702;&#65292;&#20294;&#26412;&#25991;&#25506;&#32034;&#20102;&#19968;&#31181;&#26356;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#21363;&#22522;&#20110;&#26465;&#20214;&#20114;&#20449;&#24687;&#36138;&#23146;&#22320;&#36873;&#25321;&#29305;&#24449;&#12290;&#34429;&#28982;&#36825;&#31181;&#26041;&#27861;&#22312;&#29702;&#35770;&#19978;&#21313;&#20998;&#26377;&#21560;&#24341;&#21147;&#65292;&#20294;&#38656;&#35201;&#23545;&#25968;&#25454;&#20998;&#24067;&#36827;&#34892;&#23436;&#20840;&#35775;&#38382;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25674;&#38144;&#20248;&#21270;&#30340;&#23398;&#20064;&#26041;&#27861;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#35757;&#32451;&#21040;&#26368;&#20248;&#29366;&#24577;&#21518;&#21487;&#20197;&#24674;&#22797;&#36138;&#24515;&#31574;&#30053;&#65292;&#24182;&#19988;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#20248;&#20110;&#35768;&#22810;&#29616;&#26377;&#30340;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#20174;&#32780;&#39564;&#35777;&#20854;&#20316;&#20026;&#36825;&#20010;&#38382;&#39064;&#30340;&#31616;&#21333;&#32780;&#24378;&#22823;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Feature selection helps reduce data acquisition costs in ML, but the standard approach is to train models with static feature subsets. Here, we consider the dynamic feature selection (DFS) problem where a model sequentially queries features based on the presently available information. DFS is often addressed with reinforcement learning, but we explore a simpler approach of greedily selecting features based on their conditional mutual information. This method is theoretically appealing but requires oracle access to the data distribution, so we develop a learning approach based on amortized optimization. The proposed method is shown to recover the greedy policy when trained to optimality, and it outperforms numerous existing feature selection methods in our experiments, thus validating it as a simple but powerful approach for this problem.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#38598;&#21512;&#32534;&#30721;&#26041;&#27861;UMBC&#65292;&#21487;&#20197;&#19982;&#20219;&#24847;&#38750;MBC&#32452;&#20214;&#30456;&#32467;&#21512;&#65292;&#21516;&#26102;&#20173;&#28385;&#36275;MBC&#65307;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;MBC&#35757;&#32451;&#31639;&#27861;&#65292;&#21487;&#20197;&#20026;&#20219;&#20309;&#38598;&#21512;&#22823;&#23567;&#22312;&#35757;&#32451;&#21644;&#27979;&#35797;&#26102;&#37117;&#20855;&#26377;&#24658;&#23450;&#30340;&#20869;&#23384;&#24320;&#38144;&#65292;&#32473;&#20986;&#23436;&#25972;&#38598;&#21512;&#26799;&#24230;&#30340;&#26080;&#20559;&#36817;&#20284;&#12290;</title><link>http://arxiv.org/abs/2208.12401</link><description>&lt;p&gt;
&#20855;&#26377;&#36890;&#29992;&#36855;&#20320;&#25209;&#37327;&#19968;&#33268;&#24615;&#21644;&#26080;&#20559;&#23436;&#20840;&#38598;&#21512;&#26799;&#24230;&#36817;&#20284;&#30340;&#21487;&#25193;&#23637;&#38598;&#21512;&#32534;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
Scalable Set Encoding with Universal Mini-Batch Consistency and Unbiased Full Set Gradient Approximation. (arXiv:2208.12401v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.12401
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#38598;&#21512;&#32534;&#30721;&#26041;&#27861;UMBC&#65292;&#21487;&#20197;&#19982;&#20219;&#24847;&#38750;MBC&#32452;&#20214;&#30456;&#32467;&#21512;&#65292;&#21516;&#26102;&#20173;&#28385;&#36275;MBC&#65307;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;MBC&#35757;&#32451;&#31639;&#27861;&#65292;&#21487;&#20197;&#20026;&#20219;&#20309;&#38598;&#21512;&#22823;&#23567;&#22312;&#35757;&#32451;&#21644;&#27979;&#35797;&#26102;&#37117;&#20855;&#26377;&#24658;&#23450;&#30340;&#20869;&#23384;&#24320;&#38144;&#65292;&#32473;&#20986;&#23436;&#25972;&#38598;&#21512;&#26799;&#24230;&#30340;&#26080;&#20559;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#65292;&#20851;&#20110;&#38598;&#21512;&#20989;&#25968;&#30340;&#23567;&#25209;&#37327;&#19968;&#33268;&#24615;(MBC)&#30340;&#30740;&#31350;&#24341;&#36215;&#20102;&#20154;&#20204;&#23545;&#20110;&#20445;&#35777;&#23558;&#19968;&#20010;&#20998;&#21106;&#30340;&#38598;&#21512;&#30340;&#37096;&#20998;&#39034;&#24207;&#22788;&#29702;&#21644;&#32858;&#21512;&#65292;&#32780;&#20445;&#35777;&#25152;&#26377;&#20998;&#21106;&#30340;&#36755;&#20986;&#30456;&#21516;&#30340;&#38656;&#27714;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;MBC&#26550;&#26500;&#30340;&#38480;&#21046;&#23548;&#33268;&#20102;&#20855;&#26377;&#26377;&#38480;&#34920;&#36798;&#33021;&#21147;&#30340;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#27809;&#26377;&#35299;&#20915;&#22312;&#38656;&#35201;&#23436;&#25972;&#38598;&#21512;&#26799;&#24230;&#30340;&#24773;&#20917;&#19979;&#22914;&#20309;&#22788;&#29702;&#35757;&#32451;&#20013;&#30340;&#22823;&#22411;&#38598;&#21512;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#29992;&#20110;&#20219;&#24847;&#38750;-MBC&#32452;&#20214;&#30456;&#32467;&#21512;&#30340;&#36890;&#29992;MBC (UMBC) &#31867;&#38598;&#21512;&#20989;&#25968;&#65292;&#21516;&#26102;&#20173;&#28385;&#36275;MBC&#65292;&#20351;&#24471;MBC&#35774;&#32622;&#20013;&#21487;&#20197;&#20351;&#29992;&#26356;&#24191;&#27867;&#30340;&#21151;&#33021;&#31867;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;MBC&#35757;&#32451;&#31639;&#27861;&#65292;&#23427;&#33021;&#22815;&#20026;&#20219;&#20309;&#38598;&#21512;&#22823;&#23567;&#22312;&#35757;&#32451;&#21644;&#27979;&#35797;&#26102;&#37117;&#20855;&#26377;&#24658;&#23450;&#30340;&#20869;&#23384;&#24320;&#38144;&#65292;&#32473;&#20986;&#23436;&#25972;&#38598;&#21512;&#26799;&#24230;&#30340;&#26080;&#20559;&#36817;&#20284;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#39564;&#65292;&#21253;&#25324;&#22270;&#20687;&#23436;&#25104;&#12289;&#25991;&#26412;&#20998;&#31867;&#12289;&#26080;&#30417;&#30563;&#32858;&#31867;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work on mini-batch consistency (MBC) for set functions has brought attention to the need for sequentially processing and aggregating chunks of a partitioned set while guaranteeing the same output for all partitions. However, existing constraints on MBC architectures lead to models with limited expressive power. Additionally, prior work has not addressed how to deal with large sets during training when the full set gradient is required. To address these issues, we propose a Universally MBC (UMBC) class of set functions which can be used in conjunction with arbitrary non-MBC components while still satisfying MBC, enabling a wider range of function classes to be used in MBC settings. Furthermore, we propose an efficient MBC training algorithm which gives an unbiased approximation of the full set gradient and has a constant memory overhead for any set size for both train- and test-time. We conduct extensive experiments including image completion, text classification, unsupervised cl
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27604;&#24050;&#26377;&#36845;&#20195;&#31639;&#27861;&#36816;&#34892;&#36895;&#24230;&#24555;100&#20493;&#30340;&#22522;&#20110;&#25104;&#23545;&#27604;&#36739;&#30340;&#25490;&#21517;&#39640;&#25928;&#35745;&#31639;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2207.00076</link><description>&lt;p&gt;
&#22522;&#20110;&#25104;&#23545;&#27604;&#36739;&#30340;&#25490;&#21517;&#39640;&#25928;&#35745;&#31639;
&lt;/p&gt;
&lt;p&gt;
Efficient computation of rankings from pairwise comparisons. (arXiv:2207.00076v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.00076
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27604;&#24050;&#26377;&#36845;&#20195;&#31639;&#27861;&#36816;&#34892;&#36895;&#24230;&#24555;100&#20493;&#30340;&#22522;&#20110;&#25104;&#23545;&#27604;&#36739;&#30340;&#25490;&#21517;&#39640;&#25928;&#35745;&#31639;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;Bradley-Terry&#27169;&#22411;&#36890;&#36807;&#20010;&#20307;&#12289;&#22242;&#38431;&#25110;&#23545;&#35937;&#20043;&#38388;&#30340;&#25104;&#23545;&#27604;&#36739;&#26469;&#30830;&#23450;&#25490;&#21517;&#12290;&#35813;&#27169;&#22411;&#20013;&#25490;&#21517;&#30340;&#20272;&#35745;&#36890;&#24120;&#20351;&#29992;Zermelo&#36817;&#19968;&#30334;&#24180;&#21069;&#39318;&#27425;&#24341;&#20837;&#30340;&#31616;&#21333;&#36845;&#20195;&#31639;&#27861;&#36827;&#34892;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#19988;&#21516;&#26679;&#31616;&#21333;&#30340;&#36845;&#20195;&#26041;&#27861;&#65292;&#21487;&#35777;&#26126;&#23427;&#36820;&#22238;&#30340;&#32467;&#26524;&#26159;&#30456;&#21516;&#30340;&#65292;&#20294;&#36895;&#24230;&#26356;&#24555;&#12290;&#22312;&#19968;&#20123;&#24773;&#20917;&#19979;&#65292;&#36895;&#24230;&#21487;&#33021;&#24555;&#20102;&#19968;&#30334;&#20493;&#12290;&#25105;&#20204;&#36890;&#36807;&#24212;&#29992;&#20110;&#19968;&#31995;&#21015;&#31034;&#20363;&#25968;&#25454;&#38598;&#26469;&#28436;&#31034;&#35813;&#31639;&#27861;&#65292;&#24182;&#23548;&#20986;&#26377;&#20851;&#20854;&#25910;&#25947;&#24615;&#30340;&#35768;&#22810;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the ranking of individuals, teams, or objects, based on pairwise comparisons between them, using the Bradley-Terry model. Estimates of rankings within this model are commonly made using a simple iterative algorithm first introduced by Zermelo almost a century ago. Here we describe an alternative and similarly simple iteration that provably returns identical results but does so much faster -- over a hundred times faster in some cases. We demonstrate this algorithm with applications to a range of example data sets and derive a number of results regarding its convergence.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22810;&#20219;&#21153;&#23398;&#20064;&#20197;&#21450;Bandits&#26041;&#27861;&#30340;&#20581;&#22766;&#32479;&#35745;&#23398;&#23454;&#29616;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20004;&#38454;&#27573;&#22810;&#20219;&#21153;&#23398;&#20064;&#20272;&#35745;&#22120;&#65292;&#35813;&#20272;&#35745;&#22120;&#20197;&#19968;&#31181;&#26679;&#26412;&#39640;&#25928;&#30340;&#26041;&#24335;&#21033;&#29992;&#20849;&#20139;&#20840;&#23616;&#21442;&#25968;&#21644;&#31232;&#30095;&#23454;&#20363;&#29305;&#23450;&#26415;&#35821;&#30340;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2112.14233</link><description>&lt;p&gt;
&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;Bandits&#36890;&#36807;&#20581;&#22766;&#32479;&#35745;&#23398;
&lt;/p&gt;
&lt;p&gt;
Multitask Learning and Bandits via Robust Statistics. (arXiv:2112.14233v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.14233
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22810;&#20219;&#21153;&#23398;&#20064;&#20197;&#21450;Bandits&#26041;&#27861;&#30340;&#20581;&#22766;&#32479;&#35745;&#23398;&#23454;&#29616;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20004;&#38454;&#27573;&#22810;&#20219;&#21153;&#23398;&#20064;&#20272;&#35745;&#22120;&#65292;&#35813;&#20272;&#35745;&#22120;&#20197;&#19968;&#31181;&#26679;&#26412;&#39640;&#25928;&#30340;&#26041;&#24335;&#21033;&#29992;&#20849;&#20139;&#20840;&#23616;&#21442;&#25968;&#21644;&#31232;&#30095;&#23454;&#20363;&#29305;&#23450;&#26415;&#35821;&#30340;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20915;&#31574;&#32773;&#32463;&#24120;&#21516;&#26102;&#38754;&#23545;&#35768;&#22810;&#30456;&#20851;&#20294;&#24322;&#36136;&#30340;&#23398;&#20064;&#38382;&#39064;&#12290;&#22312;&#27492;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#33258;&#28982;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#27599;&#20010;&#23398;&#20064;&#23454;&#20363;&#20013;&#30340;&#26410;&#30693;&#21442;&#25968;&#21487;&#20197;&#20998;&#35299;&#20026;&#20849;&#20139;&#20840;&#23616;&#21442;&#25968;&#21152;&#19978;&#31232;&#30095;&#30340;&#23454;&#20363;&#29305;&#23450;&#26415;&#35821;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20004;&#38454;&#27573;&#22810;&#20219;&#21153;&#23398;&#20064;&#20272;&#35745;&#22120;&#65292;&#20197;&#19968;&#31181;&#26679;&#26412;&#39640;&#25928;&#30340;&#26041;&#24335;&#21033;&#29992;&#36825;&#31181;&#32467;&#26500;&#65292;&#20351;&#29992;&#20581;&#22766;&#32479;&#35745;&#23398;&#65288;&#22312;&#30456;&#20284;&#23454;&#20363;&#19978;&#23398;&#20064;&#65289;&#21644;LASSO&#22238;&#24402;&#65288;&#21435;&#20559;&#24046;&#32467;&#26524;&#65289;&#30340;&#29420;&#29305;&#32452;&#21512;&#12290;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#25552;&#20379;&#20102;&#25913;&#36827;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Decision-makers often simultaneously face many related but heterogeneous learning problems. For instance, a large retailer may wish to learn product demand at different stores to solve pricing or inventory problems, making it desirable to learn jointly for stores serving similar customers; alternatively, a hospital network may wish to learn patient risk at different providers to allocate personalized interventions, making it desirable to learn jointly for hospitals serving similar patient populations. Motivated by real datasets, we study a natural setting where the unknown parameter in each learning instance can be decomposed into a shared global parameter plus a sparse instance-specific term. We propose a novel two-stage multitask learning estimator that exploits this structure in a sample-efficient way, using a unique combination of robust statistics (to learn across similar instances) and LASSO regression (to debias the results). Our estimator yields improved sample complexity bound
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#20855;&#26377;&#26410;&#30693;&#22343;&#20540;&#21644;&#26410;&#30693;&#21327;&#26041;&#24046;&#30340;$k\geq2$&#30340;&#39640;&#26031;&#32452;&#20998;&#28151;&#21512;&#29289;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20934;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#21487;&#38752;&#21306;&#20998;&#35813;&#28151;&#21512;&#29289;&#19982;&#32431;&#39640;&#26031;&#20998;&#24067;&#30340;&#31639;&#27861;&#65292;&#24182;&#19988;&#35813;&#31639;&#27861;&#20165;&#38656;&#35201;&#22312;&#22810;&#39033;&#24335;&#19979;&#30028;&#28151;&#21512;&#37325;&#37327;&#30340;&#24773;&#20917;&#19979;&#36816;&#34892;&#12290;</title><link>http://arxiv.org/abs/2112.05445</link><description>&lt;p&gt;
&#36229;&#36234;&#24179;&#34892;&#24179;&#38754;&#65306;&#38750;&#29699;&#24418;&#39640;&#26031;&#28151;&#21512;&#30340;&#20934;&#22810;&#39033;&#24335;&#26102;&#38388;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Beyond Parallel Pancakes: Quasi-Polynomial Time Guarantees for Non-Spherical Gaussian Mixtures. (arXiv:2112.05445v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.05445
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#20855;&#26377;&#26410;&#30693;&#22343;&#20540;&#21644;&#26410;&#30693;&#21327;&#26041;&#24046;&#30340;$k\geq2$&#30340;&#39640;&#26031;&#32452;&#20998;&#28151;&#21512;&#29289;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20934;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#21487;&#38752;&#21306;&#20998;&#35813;&#28151;&#21512;&#29289;&#19982;&#32431;&#39640;&#26031;&#20998;&#24067;&#30340;&#31639;&#27861;&#65292;&#24182;&#19988;&#35813;&#31639;&#27861;&#20165;&#38656;&#35201;&#22312;&#22810;&#39033;&#24335;&#19979;&#30028;&#28151;&#21512;&#37325;&#37327;&#30340;&#24773;&#20917;&#19979;&#36816;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20855;&#26377;&#26410;&#30693;&#21017;&#21644;&#26410;&#30693;&#26041;&#24046;&#65288;&#23545;&#20110;&#25152;&#26377;&#32452;&#20998;&#37117;&#30456;&#21516;&#65289;&#30340;$k\geq2$&#20010;&#39640;&#26031;&#32452;&#20998;&#28151;&#21512;&#29289;&#65292;&#36825;&#20123;&#32452;&#20998;&#26159;&#33391;&#22909;&#20998;&#31163;&#30340;&#65292;&#21363;&#19981;&#21516;&#32452;&#20998;&#30340;&#32479;&#35745;&#37325;&#21472;&#26368;&#22810;&#20026;$k^{-C}$&#65292;&#20854;&#20013;$C\geq1$&#20026;&#36275;&#22815;&#22823;&#30340;&#24120;&#25968;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21482;&#26377;&#22312;&#20801;&#35768;&#28151;&#21512;&#26435;&#20026;&#25351;&#25968;&#32423;&#23567;&#25968;&#26102;&#25165;&#20250;&#20986;&#29616;&#36825;&#31181;&#38590;&#24230;&#65292;&#24182;&#19988;&#23545;&#20110;&#22810;&#39033;&#24335;&#19979;&#30028;&#28151;&#21512;&#37325;&#37327;&#65292;&#20934;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#21487;&#20197;&#23454;&#29616;&#38750;&#24179;&#20961;&#31639;&#27861;&#20445;&#35777;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#24179;&#26041;&#21644;&#26041;&#27861;&#30340;&#31639;&#27861;&#65292;&#20854;&#36816;&#34892;&#26102;&#38388;&#20934;&#22810;&#39033;&#24335;&#65292;&#24182;&#19988;&#21487;&#38752;&#22320;&#21306;&#20998;&#19968;&#20010;&#30001;$k\geq2$&#20010;&#33391;&#22909;&#20998;&#31163;&#30340;&#39640;&#26031;&#32452;&#20998;&#28151;&#21512;&#29289;&#21644;&#19968;&#20010;&#32431;&#39640;&#26031;&#20998;&#24067;&#12290;&#20316;&#20026;&#35777;&#20070;&#65292;&#35813;&#31639;&#27861;&#36755;&#20986;&#27492;&#21306;&#20998;&#30340;&#19968;&#20010;&#31526;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider mixtures of $k\geq 2$ Gaussian components with unknown means and unknown covariance (identical for all components) that are well-separated, i.e., distinct components have statistical overlap at most $k^{-C}$ for a large enough constant $C\ge 1$. Previous statistical-query [DKS17] and lattice-based [BRST21, GVV22] lower bounds give formal evidence that even distinguishing such mixtures from (pure) Gaussians may be exponentially hard (in $k$).  We show that this kind of hardness can only appear if mixing weights are allowed to be exponentially small, and that for polynomially lower bounded mixing weights non-trivial algorithmic guarantees are possible in quasi-polynomial time. Concretely, we develop an algorithm based on the sum-of-squares method with running time quasi-polynomial in the minimum mixing weight. The algorithm can reliably distinguish between a mixture of $k\ge 2$ well-separated Gaussian components and a (pure) Gaussian distribution. As a certificate, the algori
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29420;&#29305;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20174;&#33267;&#23569; $3B$ &#20010; bispectrum &#27979;&#37327;&#32467;&#26524;&#20013;&#21807;&#19968;&#22320;&#24674;&#22797;&#24102;&#38480;&#20449;&#21495;&#65292;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#26102;&#38480;&#20449;&#21495;&#65292;&#24182;&#36890;&#36807;&#26368;&#23567;&#21270;&#38750;&#20984;&#30446;&#26631;&#20989;&#25968;&#26469;&#36827;&#34892;&#20248;&#21270;&#12290;</title><link>http://arxiv.org/abs/2111.06479</link><description>&lt;p&gt;
&#20855;&#26377;&#26377;&#38480;&#26102;&#39057;&#25903;&#25345;&#20449;&#21495;&#30340;&#29420;&#29305;&#19977;&#27425;&#30456;&#20851;&#35889;&#21453;&#28436;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Unique Bispectrum Inversion for Signals with Finite Spectral/Temporal Support. (arXiv:2111.06479v3 [eess.SP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.06479
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29420;&#29305;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20174;&#33267;&#23569; $3B$ &#20010; bispectrum &#27979;&#37327;&#32467;&#26524;&#20013;&#21807;&#19968;&#22320;&#24674;&#22797;&#24102;&#38480;&#20449;&#21495;&#65292;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#26102;&#38480;&#20449;&#21495;&#65292;&#24182;&#36890;&#36807;&#26368;&#23567;&#21270;&#38750;&#20984;&#30446;&#26631;&#20989;&#25968;&#26469;&#36827;&#34892;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#20449;&#21495;&#22788;&#29702;&#38382;&#39064;&#20013;&#65292;&#20174;&#19977;&#27425;&#30456;&#20851;&#35889;&#65288;&#20063;&#31216;&#20026; bispectrum&#65289;&#20013;&#24674;&#22797;&#20449;&#21495;&#26159;&#19968;&#39033;&#37325;&#35201;&#30340;&#20219;&#21153;&#12290;&#28982;&#32780;&#20256;&#32479;&#26041;&#27861;&#24182;&#19981;&#33021;&#20934;&#30830;&#22320;&#20174; bispectrum &#21453;&#28436;&#20986;&#24213;&#23618;&#20449;&#21495;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#33021;&#22815;&#20174;&#33267;&#23569; $3B$ &#20010; bispectrum &#27979;&#37327;&#32467;&#26524;&#65288;&#20854;&#20013; $B$ &#26159;&#20449;&#21495;&#30340;&#24102;&#23485;&#65289;&#20013;&#21807;&#19968;&#22320;&#24674;&#22797;&#24102;&#38480;&#20449;&#21495;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20063;&#36866;&#29992;&#20110;&#26102;&#38480;&#20449;&#21495;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#27493;&#20449;&#36182;&#22495;&#31639;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#19968;&#20010;&#38750;&#20984;&#30446;&#26631;&#20989;&#25968;&#26469;&#36827;&#34892;&#20248;&#21270;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#36890;&#36807;&#35889;&#31639;&#27861;&#23545;&#20449;&#21495;&#36827;&#34892;&#36817;&#20284;&#65292;&#28982;&#21518;&#26681;&#25454;&#19968;&#31995;&#21015;&#26799;&#24230;&#36845;&#20195;&#26469;&#25913;&#36827;&#25152;&#24471;&#21040;&#30340;&#21021;&#22987;&#21270;&#32467;&#26524;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#20174;&#23436;&#25972;&#25110;&#27424;&#37319;&#26679;&#30340; bispectrum &#35266;&#27979;&#32467;&#26524;&#20013;&#20272;&#35745;&#24102;&#38480;&#25110;&#26102;&#38480;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Retrieving a signal from its triple correlation spectrum, also called bispectrum, arises in a wide range of signal processing problems. Conventional methods do not provide an accurate inversion of bispectrum to the underlying signal. In this paper, we present an approach that uniquely recovers signals with finite spectral support (band-limited signals) from at least $3B$ measurements of its bispectrum function (BF), where $B$ is the signal's bandwidth. Our approach also extends to time-limited signals. We propose a two-step trust region algorithm that minimizes a non-convex objective function. First, we approximate the signal by a spectral algorithm and then refine the attained initialization based on a sequence of gradient iterations. Numerical experiments suggest that our proposed algorithm is able to estimate band-/time-limited signals from its BF for both complete and undersampled observations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ABSGD&#30340;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#25968;&#25454;&#19981;&#24179;&#34913;&#25110;&#26631;&#31614;&#22122;&#22768;&#38382;&#39064;&#12290;&#25105;&#20204;&#20026;&#27599;&#20010;&#26679;&#26412;&#20998;&#37197;&#19968;&#20010;&#20010;&#21035;&#37325;&#35201;&#24615;&#26435;&#37325;&#65292;&#35813;&#26435;&#37325;&#31995;&#32479;&#22320;&#19982;&#25968;&#25454;&#30340;&#25439;&#22833;&#20540;&#25104;&#27604;&#20363;&#65292;&#24182;&#19988;&#21487;&#20197;&#25429;&#25417;&#21040;&#27599;&#20010;&#31867;&#20013;&#20010;&#21035;&#31034;&#20363;&#20043;&#38388;&#30340;&#22810;&#26679;&#24615;&#12290;&#19982;&#29616;&#26377;&#30340;&#21152;&#26435;&#26041;&#26696;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20943;&#36731;&#35745;&#31639;&#36127;&#25285;&#24182;&#22312;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270; (DRO) &#26694;&#26550;&#20013;&#35299;&#37322;&#20026;&#27491;&#21017;&#21270;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2012.06951</link><description>&lt;p&gt;
&#27880;&#24847;&#21147;&#20559;&#21521;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;
&lt;/p&gt;
&lt;p&gt;
Attentional-Biased Stochastic Gradient Descent. (arXiv:2012.06951v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2012.06951
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ABSGD&#30340;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#25968;&#25454;&#19981;&#24179;&#34913;&#25110;&#26631;&#31614;&#22122;&#22768;&#38382;&#39064;&#12290;&#25105;&#20204;&#20026;&#27599;&#20010;&#26679;&#26412;&#20998;&#37197;&#19968;&#20010;&#20010;&#21035;&#37325;&#35201;&#24615;&#26435;&#37325;&#65292;&#35813;&#26435;&#37325;&#31995;&#32479;&#22320;&#19982;&#25968;&#25454;&#30340;&#25439;&#22833;&#20540;&#25104;&#27604;&#20363;&#65292;&#24182;&#19988;&#21487;&#20197;&#25429;&#25417;&#21040;&#27599;&#20010;&#31867;&#20013;&#20010;&#21035;&#31034;&#20363;&#20043;&#38388;&#30340;&#22810;&#26679;&#24615;&#12290;&#19982;&#29616;&#26377;&#30340;&#21152;&#26435;&#26041;&#26696;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20943;&#36731;&#35745;&#31639;&#36127;&#25285;&#24182;&#22312;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270; (DRO) &#26694;&#26550;&#20013;&#35299;&#37322;&#20026;&#27491;&#21017;&#21270;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ABSGD&#30340;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#25968;&#25454;&#19981;&#24179;&#34913;&#25110;&#26631;&#31614;&#22122;&#22768;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#23545;&#21160;&#37327;SGD&#30340;&#31616;&#21333;&#20462;&#25913;&#65292;&#22312;&#23567;&#25209;&#37327;&#20013;&#20026;&#27599;&#20010;&#26679;&#26412;&#20998;&#37197;&#19968;&#20010;&#20010;&#21035;&#37325;&#35201;&#24615;&#26435;&#37325;&#12290;&#26679;&#26412;&#25968;&#25454;&#30340;&#20010;&#20307;&#32423;&#21035;&#26435;&#37325;&#31995;&#32479;&#22320;&#19982;&#25968;&#25454;&#30340;&#32553;&#25918;&#25439;&#22833;&#20540;&#30340;&#25351;&#25968;&#25104;&#27604;&#20363;&#65292;&#20854;&#20013;&#32553;&#25918;&#22240;&#23376;&#22312;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270; (DRO) &#26694;&#26550;&#20013;&#34987;&#35299;&#37322;&#20026;&#27491;&#21017;&#21270;&#21442;&#25968;&#12290;&#26681;&#25454;&#32553;&#25918;&#22240;&#23376;&#26159;&#27491;&#36824;&#26159;&#36127;&#65292;ABSGD&#20445;&#35777;&#25910;&#25947;&#21040;&#20449;&#24687;&#27491;&#21017;&#21270;&#30340;&#26368;&#23567;&#20540;&#26368;&#22823;&#20540;&#25110;&#26368;&#23567;&#20540;&#26368;&#23567;&#20540; DRO &#38382;&#39064;&#30340;&#38745;&#24577;&#28857;&#12290;&#19982;&#29616;&#26377;&#30340;&#31867;&#32423;&#21152;&#26435;&#26041;&#26696;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#25429;&#25417;&#21040;&#27599;&#20010;&#31867;&#20013;&#20010;&#21035;&#31034;&#20363;&#20043;&#38388;&#30340;&#22810;&#26679;&#24615;&#12290;&#19982;&#38656;&#35201;&#19977;&#27425;&#21453;&#21521;&#20256;&#25773;&#30340;&#20803;&#23398;&#20064;&#20351;&#29992;&#30340;&#29616;&#26377;&#20010;&#20307;&#32423;&#21152;&#26435;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20943;&#36731;&#35745;&#31639;&#36127;&#25285;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present a simple yet effective provable method (named ABSGD) for addressing the data imbalance or label noise problem in deep learning. Our method is a simple modification to momentum SGD where we assign an individual importance weight to each sample in the mini-batch. The individual-level weight of sampled data is systematically proportional to the exponential of a scaled loss value of the data, where the scaling factor is interpreted as the regularization parameter in the framework of distributionally robust optimization (DRO). Depending on whether the scaling factor is positive or negative, ABSGD is guaranteed to converge to a stationary point of an information-regularized min-max or min-min DRO problem, respectively. Compared with existing class-level weighting schemes, our method can capture the diversity between individual examples within each class. Compared with existing individual-level weighting methods using meta-learning that require three backward propaga
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#24050;&#32463;&#36890;&#36807;&#20223;&#30495;&#30740;&#31350;&#39564;&#35777;&#20102;&#20854;&#21487;&#34892;&#24615;&#65292;&#21487;&#20197;&#32531;&#35299;&#32500;&#25968;&#35781;&#21650;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2009.07055</link><description>&lt;p&gt;
&#21033;&#29992;&#20855;&#26377;&#22810;&#20010;&#28151;&#28102;&#22240;&#32032;&#30340;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#19968;&#33324;&#27835;&#30103;&#25928;&#26524;&#30340;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Causal Inference of General Treatment Effects using Neural Networks with A Diverging Number of Confounders. (arXiv:2009.07055v6 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2009.07055
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#24050;&#32463;&#36890;&#36807;&#20223;&#30495;&#30740;&#31350;&#39564;&#35777;&#20102;&#20854;&#21487;&#34892;&#24615;&#65292;&#21487;&#20197;&#32531;&#35299;&#32500;&#25968;&#35781;&#21650;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#25928;&#24212;&#30340;&#20272;&#31639;&#26159;&#34892;&#20026;&#31185;&#23398;&#12289;&#31038;&#20250;&#31185;&#23398;&#12289;&#32463;&#27982;&#23398;&#21644;&#29983;&#29289;&#21307;&#23398;&#31185;&#23398;&#30340;&#20027;&#35201;&#30446;&#26631;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#31181;&#24191;&#20041;&#20248;&#21270;&#26694;&#26550;&#65292;&#20351;&#29992;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#65288;ANNs&#65289;&#26377;&#25928;&#20272;&#35745;&#19968;&#33324;&#27835;&#30103;&#25928;&#26524;&#65292;&#21363;&#20351;&#21327;&#21464;&#37327;&#30340;&#25968;&#37327;&#21487;&#20197;&#38543;&#30528;&#26679;&#26412;&#25968;&#37327;&#30340;&#22686;&#21152;&#32780;&#22686;&#21152;&#12290;&#25105;&#20204;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#26469;&#20272;&#31639;&#24178;&#25200;&#20989;&#25968;&#65292;&#24182;&#20026;ANN&#36817;&#20284;&#22120;&#24314;&#31435;&#20102;&#19968;&#20010;&#26032;&#30340;&#36817;&#20284;&#35823;&#24046;&#30028;&#38480;&#65292;&#24403;&#24178;&#25200;&#20989;&#25968;&#23646;&#20110;&#28151;&#21512;Sobolev&#31354;&#38388;&#26102;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;ANN&#21487;&#20197;&#32531;&#35299;&#32500;&#25968;&#35781;&#21650;&#38382;&#39064;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#24314;&#31435;&#20102;&#25152;&#25552;&#20986;&#30340;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#37327;&#30340;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24120;&#24615;&#65292;&#24182;&#24212;&#29992;&#20102;&#19968;&#20010;&#21152;&#26435;&#33258;&#21161;&#27861;&#36827;&#34892;&#25512;&#26029;&#12290;&#20223;&#30495;&#30740;&#31350;&#23637;&#31034;&#20102;&#36825;&#20123;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The estimation of causal effects is a primary goal of behavioral, social, economic and biomedical sciences. Under the unconfoundedness condition, adjustment for confounders requires estimating the nuisance functions relating outcome and/or treatment to confounders. This paper considers a generalized optimization framework for efficient estimation of general treatment effects using feedforward artificial neural networks (ANNs) when the number of covariates is allowed to increase with the sample size. We estimate the nuisance function by ANNs, and develop a new approximation error bound for the ANNs approximators when the nuisance function belongs to a mixed Sobolev space. We show that the ANNs can alleviate the curse of dimensionality under this circumstance. We further establish the consistency and asymptotic normality of the proposed treatment effects estimators, and apply a weighted bootstrap procedure for conducting inference. The proposed methods are illustrated via simulation stud
&lt;/p&gt;</description></item></channel></rss>