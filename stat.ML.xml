<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>survex&#26159;&#19968;&#20010;R&#36719;&#20214;&#21253;&#65292;&#36890;&#36807;&#24212;&#29992;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#36830;&#36143;&#30340;&#26694;&#26550;&#26469;&#35299;&#37322;&#20219;&#20309;&#29983;&#23384;&#27169;&#22411;&#65292;&#21487;&#20197;&#25913;&#36827;&#27169;&#22411;&#65292;&#25552;&#39640;&#36879;&#26126;&#24230;&#21644;&#36131;&#20219;&#24863;&#12290;</title><link>http://arxiv.org/abs/2308.16113</link><description>&lt;p&gt;
survex&#65306;&#29992;&#20110;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#29983;&#23384;&#27169;&#22411;&#30340;R&#36719;&#20214;&#21253;
&lt;/p&gt;
&lt;p&gt;
survex: an R package for explaining machine learning survival models. (arXiv:2308.16113v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16113
&lt;/p&gt;
&lt;p&gt;
survex&#26159;&#19968;&#20010;R&#36719;&#20214;&#21253;&#65292;&#36890;&#36807;&#24212;&#29992;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#36830;&#36143;&#30340;&#26694;&#26550;&#26469;&#35299;&#37322;&#20219;&#20309;&#29983;&#23384;&#27169;&#22411;&#65292;&#21487;&#20197;&#25913;&#36827;&#27169;&#22411;&#65292;&#25552;&#39640;&#36879;&#26126;&#24230;&#21644;&#36131;&#20219;&#24863;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#28789;&#27963;&#24615;&#21644;&#20986;&#33394;&#24615;&#33021;&#65292;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#32463;&#24120;&#29992;&#20110;&#34917;&#20805;&#21644;&#36229;&#36234;&#20256;&#32479;&#30340;&#32479;&#35745;&#29983;&#23384;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#24191;&#27867;&#24212;&#29992;&#21463;&#21040;&#32570;&#20047;&#29992;&#25143;&#21451;&#22909;&#30340;&#24037;&#20855;&#26469;&#35299;&#37322;&#20854;&#20869;&#37096;&#25805;&#20316;&#21644;&#39044;&#27979;&#21407;&#29702;&#30340;&#38480;&#21046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;survex R&#36719;&#20214;&#21253;&#65292;&#36890;&#36807;&#24212;&#29992;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#36830;&#36143;&#30340;&#26694;&#26550;&#26469;&#35299;&#37322;&#20219;&#20309;&#29983;&#23384;&#27169;&#22411;&#12290;&#25152;&#25552;&#36719;&#20214;&#30340;&#21151;&#33021;&#21253;&#25324;&#29702;&#35299;&#21644;&#35786;&#26029;&#29983;&#23384;&#27169;&#22411;&#65292;&#20174;&#32780;&#21487;&#20197;&#25913;&#36827;&#23427;&#20204;&#12290;&#36890;&#36807;&#25581;&#31034;&#21464;&#37327;&#25928;&#24212;&#21644;&#37325;&#35201;&#24615;&#31561;&#20915;&#31574;&#36807;&#31243;&#30340;&#35265;&#35299;&#65292;survex&#33021;&#22815;&#35780;&#20272;&#27169;&#22411;&#30340;&#21487;&#38752;&#24615;&#24182;&#26816;&#27979;&#20559;&#24046;&#12290;&#22240;&#27492;&#65292;&#22312;&#29983;&#29289;&#21307;&#23398;&#30740;&#31350;&#21644;&#21307;&#30103;&#24212;&#29992;&#31561;&#25935;&#24863;&#39046;&#22495;&#21487;&#20197;&#20419;&#36827;&#36879;&#26126;&#24230;&#21644;&#36131;&#20219;&#12290;
&lt;/p&gt;
&lt;p&gt;
Due to their flexibility and superior performance, machine learning models frequently complement and outperform traditional statistical survival models. However, their widespread adoption is hindered by a lack of user-friendly tools to explain their internal operations and prediction rationales. To tackle this issue, we introduce the survex R package, which provides a cohesive framework for explaining any survival model by applying explainable artificial intelligence techniques. The capabilities of the proposed software encompass understanding and diagnosing survival models, which can lead to their improvement. By revealing insights into the decision-making process, such as variable effects and importances, survex enables the assessment of model reliability and the detection of biases. Thus, transparency and responsibility may be promoted in sensitive areas, such as biomedical research and healthcare applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#33258;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#65292;&#31216;&#20026;TSDiff&#12290;&#35813;&#27169;&#22411;&#19981;&#38656;&#35201;&#36741;&#21161;&#32593;&#32476;&#25110;&#35757;&#32451;&#36807;&#31243;&#30340;&#25913;&#21464;&#65292;&#22312;&#39044;&#27979;&#12289;&#25913;&#36827;&#21644;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#31561;&#26102;&#38388;&#24207;&#21015;&#20219;&#21153;&#19978;&#23637;&#29616;&#20986;&#20102;&#31454;&#20105;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.11494</link><description>&lt;p&gt;
&#39044;&#27979;&#12289;&#25913;&#36827;&#12289;&#21512;&#25104;&#65306;&#38754;&#21521;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#33258;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Predict, Refine, Synthesize: Self-Guiding Diffusion Models for Probabilistic Time Series Forecasting. (arXiv:2307.11494v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11494
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#33258;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#65292;&#31216;&#20026;TSDiff&#12290;&#35813;&#27169;&#22411;&#19981;&#38656;&#35201;&#36741;&#21161;&#32593;&#32476;&#25110;&#35757;&#32451;&#36807;&#31243;&#30340;&#25913;&#21464;&#65292;&#22312;&#39044;&#27979;&#12289;&#25913;&#36827;&#21644;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#31561;&#26102;&#38388;&#24207;&#21015;&#20219;&#21153;&#19978;&#23637;&#29616;&#20986;&#20102;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#29983;&#25104;&#24314;&#27169;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#20043;&#21069;&#20851;&#20110;&#26102;&#38388;&#24207;&#21015;&#25193;&#25955;&#27169;&#22411;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#24320;&#21457;&#38024;&#23545;&#29305;&#23450;&#39044;&#27979;&#25110;&#22635;&#34917;&#20219;&#21153;&#30340;&#26465;&#20214;&#27169;&#22411;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#38754;&#21521;&#22810;&#31181;&#26102;&#38388;&#24207;&#21015;&#24212;&#29992;&#30340;&#20219;&#21153;&#19981;&#21487;&#30693;&#26465;&#20214;&#19979;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;TSDiff&#65292;&#19968;&#31181;&#38754;&#21521;&#26102;&#38388;&#24207;&#21015;&#30340;&#26080;&#26465;&#20214;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#33258;&#24341;&#23548;&#26426;&#21046;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#20351;&#24471;TSDiff&#33021;&#22815;&#20026;&#19979;&#28216;&#20219;&#21153;&#36827;&#34892;&#26465;&#20214;&#35774;&#32622;&#65292;&#32780;&#26080;&#38656;&#36741;&#21161;&#32593;&#32476;&#25110;&#25913;&#21464;&#35757;&#32451;&#36807;&#31243;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#19981;&#21516;&#30340;&#26102;&#38388;&#24207;&#21015;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65306;&#39044;&#27979;&#12289;&#25913;&#36827;&#21644;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#34920;&#26126;TSDiff&#19982;&#20960;&#31181;&#20219;&#21153;&#29305;&#23450;&#30340;&#26465;&#20214;&#39044;&#27979;&#26041;&#27861;&#30456;&#31454;&#20105;&#65288;&#39044;&#27979;&#65289;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#21033;&#29992;TSDiff&#23398;&#21040;&#30340;&#38544;&#24615;&#27010;&#29575;&#23494;&#24230;&#26469;&#36845;&#20195;&#22320;&#25913;&#36827;p
&lt;/p&gt;
&lt;p&gt;
Diffusion models have achieved state-of-the-art performance in generative modeling tasks across various domains. Prior works on time series diffusion models have primarily focused on developing conditional models tailored to specific forecasting or imputation tasks. In this work, we explore the potential of task-agnostic, unconditional diffusion models for several time series applications. We propose TSDiff, an unconditionally trained diffusion model for time series. Our proposed self-guidance mechanism enables conditioning TSDiff for downstream tasks during inference, without requiring auxiliary networks or altering the training procedure. We demonstrate the effectiveness of our method on three different time series tasks: forecasting, refinement, and synthetic data generation. First, we show that TSDiff is competitive with several task-specific conditional forecasting methods (predict). Second, we leverage the learned implicit probability density of TSDiff to iteratively refine the p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21457;&#29616;&#32593;&#32476;&#26435;&#37325;&#30340;&#26041;&#24046;&#21644;&#22823;&#26435;&#37325;&#30340;&#31354;&#38388;&#38598;&#20013;&#26159;&#24433;&#21709;&#31070;&#32463;&#25345;&#20037;&#24615;&#30340;&#20027;&#35201;&#22240;&#32032;&#65292;&#24182;&#25552;&#20986;&#20102;&#23558;&#31070;&#32463;&#25345;&#20037;&#24615;&#25193;&#23637;&#21040;&#25972;&#20010;&#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#22270;&#25345;&#20037;&#24615;&#27979;&#37327;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.10865</link><description>&lt;p&gt;
&#36890;&#36807;&#28145;&#24230;&#22270;&#30340;&#25345;&#20037;&#24615;&#35299;&#20915;&#31070;&#32463;&#25345;&#20037;&#24615;&#30340;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Addressing caveats of neural persistence with deep graph persistence. (arXiv:2307.10865v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10865
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21457;&#29616;&#32593;&#32476;&#26435;&#37325;&#30340;&#26041;&#24046;&#21644;&#22823;&#26435;&#37325;&#30340;&#31354;&#38388;&#38598;&#20013;&#26159;&#24433;&#21709;&#31070;&#32463;&#25345;&#20037;&#24615;&#30340;&#20027;&#35201;&#22240;&#32032;&#65292;&#24182;&#25552;&#20986;&#20102;&#23558;&#31070;&#32463;&#25345;&#20037;&#24615;&#25193;&#23637;&#21040;&#25972;&#20010;&#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#22270;&#25345;&#20037;&#24615;&#27979;&#37327;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#25345;&#20037;&#24615;&#26159;&#19968;&#31181;&#29992;&#20110;&#37327;&#21270;&#31070;&#32463;&#32593;&#32476;&#22797;&#26434;&#24615;&#30340;&#37325;&#35201;&#25351;&#26631;&#65292;&#25552;&#20986;&#20110;&#28145;&#24230;&#23398;&#20064;&#20013;&#26032;&#20852;&#30340;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#22312;&#29702;&#35770;&#21644;&#23454;&#35777;&#19978;&#25105;&#20204;&#21457;&#29616;&#65292;&#32593;&#32476;&#26435;&#37325;&#30340;&#26041;&#24046;&#21644;&#22823;&#26435;&#37325;&#30340;&#31354;&#38388;&#38598;&#20013;&#26159;&#24433;&#21709;&#31070;&#32463;&#25345;&#20037;&#24615;&#30340;&#20027;&#35201;&#22240;&#32032;&#12290;&#34429;&#28982;&#36825;&#23545;&#20110;&#32447;&#24615;&#20998;&#31867;&#22120;&#26377;&#29992;&#30340;&#20449;&#24687;&#65292;&#20294;&#25105;&#20204;&#21457;&#29616;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#21518;&#20960;&#23618;&#20013;&#27809;&#26377;&#30456;&#20851;&#30340;&#31354;&#38388;&#32467;&#26500;&#65292;&#20351;&#24471;&#31070;&#32463;&#25345;&#20037;&#24615;&#22823;&#33268;&#31561;&#20110;&#26435;&#37325;&#30340;&#26041;&#24046;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#25152;&#25552;&#20986;&#30340;&#23618;&#38388;&#24179;&#22343;&#36807;&#31243;&#27809;&#26377;&#32771;&#34385;&#23618;&#38388;&#30340;&#20132;&#20114;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#31070;&#32463;&#25345;&#20037;&#24615;&#22522;&#30784;&#32467;&#26500;&#30340;&#25193;&#23637;&#65292;&#20174;&#21333;&#23618;&#25913;&#20026;&#25972;&#20010;&#31070;&#32463;&#32593;&#32476;&#65292;&#36825;&#30456;&#24403;&#20110;&#22312;&#19968;&#20010;&#29305;&#23450;&#30697;&#38453;&#19978;&#35745;&#31639;&#31070;&#32463;&#25345;&#20037;&#24615;&#12290;&#36825;&#24471;&#21040;&#20102;&#25105;&#20204;&#30340;&#28145;&#24230;&#22270;&#25345;&#20037;&#24615;&#27979;&#37327;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural Persistence is a prominent measure for quantifying neural network complexity, proposed in the emerging field of topological data analysis in deep learning. In this work, however, we find both theoretically and empirically that the variance of network weights and spatial concentration of large weights are the main factors that impact neural persistence. Whilst this captures useful information for linear classifiers, we find that no relevant spatial structure is present in later layers of deep neural networks, making neural persistence roughly equivalent to the variance of weights. Additionally, the proposed averaging procedure across layers for deep neural networks does not consider interaction between layers. Based on our analysis, we propose an extension of the filtration underlying neural persistence to the whole neural network instead of single layers, which is equivalent to calculating neural persistence on one particular matrix. This yields our deep graph persistence measur
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24809;&#32602;&#21270;&#21644;&#38408;&#20540;&#21270;&#20272;&#35745;&#30340;&#27169;&#24335;&#24674;&#22797;&#26041;&#27861;&#65292;&#24182;&#23450;&#20041;&#20102;&#27169;&#24335;&#21644;&#24674;&#22797;&#26465;&#20214;&#12290;&#23545;&#20110;LASSO&#65292;&#26080;&#22122;&#22768;&#24674;&#22797;&#26465;&#20214;&#21644;&#20114;&#19981;&#34920;&#31034;&#26465;&#20214;&#36215;&#21040;&#20102;&#30456;&#21516;&#30340;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2307.10158</link><description>&lt;p&gt;
&#24809;&#32602;&#21270;&#21644;&#38408;&#20540;&#21270;&#20272;&#35745;&#20013;&#30340;&#27169;&#24335;&#24674;&#22797;&#21450;&#20854;&#20960;&#20309;
&lt;/p&gt;
&lt;p&gt;
Pattern Recovery in Penalized and Thresholded Estimation and its Geometry. (arXiv:2307.10158v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10158
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24809;&#32602;&#21270;&#21644;&#38408;&#20540;&#21270;&#20272;&#35745;&#30340;&#27169;&#24335;&#24674;&#22797;&#26041;&#27861;&#65292;&#24182;&#23450;&#20041;&#20102;&#27169;&#24335;&#21644;&#24674;&#22797;&#26465;&#20214;&#12290;&#23545;&#20110;LASSO&#65292;&#26080;&#22122;&#22768;&#24674;&#22797;&#26465;&#20214;&#21644;&#20114;&#19981;&#34920;&#31034;&#26465;&#20214;&#36215;&#21040;&#20102;&#30456;&#21516;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#24809;&#32602;&#20272;&#35745;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#24809;&#32602;&#39033;&#30001;&#23454;&#20540;&#30340;&#22810;&#38754;&#20307;&#35268;&#33539;&#32473;&#20986;&#65292;&#20854;&#20013;&#21253;&#25324;&#35832;&#22914;LASSO&#65288;&#20197;&#21450;&#20854;&#35768;&#22810;&#21464;&#20307;&#22914;&#24191;&#20041;LASSO&#65289;&#12289;SLOPE&#12289;OSCAR&#12289;PACS&#31561;&#26041;&#27861;&#12290;&#27599;&#20010;&#20272;&#35745;&#22120;&#21487;&#20197;&#25581;&#31034;&#26410;&#30693;&#21442;&#25968;&#21521;&#37327;&#30340;&#19981;&#21516;&#32467;&#26500;&#25110;&#8220;&#27169;&#24335;&#8221;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#22522;&#20110;&#27425;&#24494;&#20998;&#30340;&#27169;&#24335;&#30340;&#19968;&#33324;&#27010;&#24565;&#65292;&#24182;&#24418;&#24335;&#21270;&#20102;&#19968;&#31181;&#34913;&#37327;&#20854;&#22797;&#26434;&#24615;&#30340;&#26041;&#27861;&#12290;&#23545;&#20110;&#27169;&#24335;&#24674;&#22797;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#29305;&#23450;&#27169;&#24335;&#20197;&#27491;&#27010;&#29575;&#34987;&#35813;&#36807;&#31243;&#26816;&#27979;&#21040;&#30340;&#26368;&#23567;&#26465;&#20214;&#65292;&#21363;&#25152;&#35859;&#30340;&#21487;&#36798;&#24615;&#26465;&#20214;&#12290;&#21033;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#26356;&#24378;&#30340;&#26080;&#22122;&#22768;&#24674;&#22797;&#26465;&#20214;&#12290;&#23545;&#20110;LASSO&#65292;&#20247;&#25152;&#21608;&#30693;&#65292;&#20114;&#19981;&#34920;&#31034;&#26465;&#20214;&#26159;&#20351;&#27169;&#24335;&#24674;&#22797;&#30340;&#27010;&#29575;&#22823;&#20110;1/2&#25152;&#24517;&#38656;&#30340;&#65292;&#24182;&#19988;&#25105;&#20204;&#23637;&#31034;&#20102;&#26080;&#22122;&#22768;&#24674;&#22797;&#36215;&#21040;&#20102;&#23436;&#20840;&#30456;&#21516;&#30340;&#20316;&#29992;&#65292;&#20174;&#32780;&#25193;&#23637;&#21644;&#32479;&#19968;&#20102;&#20114;&#19981;&#34920;&#31034;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the framework of penalized estimation where the penalty term is given by a real-valued polyhedral gauge, which encompasses methods such as LASSO (and many variants thereof such as the generalized LASSO), SLOPE, OSCAR, PACS and others. Each of these estimators can uncover a different structure or ``pattern'' of the unknown parameter vector. We define a general notion of patterns based on subdifferentials and formalize an approach to measure their complexity. For pattern recovery, we provide a minimal condition for a particular pattern to be detected by the procedure with positive probability, the so-called accessibility condition. Using our approach, we also introduce the stronger noiseless recovery condition. For the LASSO, it is well known that the irrepresentability condition is necessary for pattern recovery with probability larger than $1/2$ and we show that the noiseless recovery plays exactly the same role, thereby extending and unifying the irrepresentability conditi
&lt;/p&gt;</description></item><item><title>&#21453;&#20107;&#23454;&#25968;&#25454;&#22686;&#24378;&#26159;&#19968;&#31181;&#32531;&#35299;&#25968;&#25454;&#20013;&#28151;&#28102;&#20559;&#24046;&#30340;&#26041;&#27861;&#65292;&#26412;&#25991;&#20174;&#22240;&#26524;&#30340;&#35282;&#24230;&#20998;&#26512;&#20102;&#28151;&#28102;&#20559;&#24046;&#23545;&#20998;&#31867;&#22120;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#21435;&#38500;&#28151;&#28102;&#20559;&#24046;&#30340;&#25163;&#27573;&#65292;&#26377;&#21161;&#20110;&#22312;&#35266;&#23519;&#21040;&#30340;&#25968;&#25454;&#20998;&#24067;&#20043;&#22806;&#36827;&#34892;&#27867;&#21270;&#12290;&#20316;&#32773;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#31639;&#27861;&#29992;&#20110;&#29983;&#25104;&#21453;&#20107;&#23454;&#22270;&#20687;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.18183</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#28151;&#28102;&#19979;&#30340;&#21453;&#20107;&#23454;&#25968;&#25454;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Rethinking Counterfactual Data Augmentation Under Confounding. (arXiv:2305.18183v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18183
&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#25968;&#25454;&#22686;&#24378;&#26159;&#19968;&#31181;&#32531;&#35299;&#25968;&#25454;&#20013;&#28151;&#28102;&#20559;&#24046;&#30340;&#26041;&#27861;&#65292;&#26412;&#25991;&#20174;&#22240;&#26524;&#30340;&#35282;&#24230;&#20998;&#26512;&#20102;&#28151;&#28102;&#20559;&#24046;&#23545;&#20998;&#31867;&#22120;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#21435;&#38500;&#28151;&#28102;&#20559;&#24046;&#30340;&#25163;&#27573;&#65292;&#26377;&#21161;&#20110;&#22312;&#35266;&#23519;&#21040;&#30340;&#25968;&#25454;&#20998;&#24067;&#20043;&#22806;&#36827;&#34892;&#27867;&#21270;&#12290;&#20316;&#32773;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#31639;&#27861;&#29992;&#20110;&#29983;&#25104;&#21453;&#20107;&#23454;&#22270;&#20687;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#25968;&#25454;&#22686;&#24378;&#26368;&#36817;&#34987;&#25552;&#20986;&#26469;&#20316;&#20026;&#32531;&#35299;&#35757;&#32451;&#25968;&#25454;&#20013;&#28151;&#28102;&#20559;&#24046;&#30340;&#19968;&#31181;&#26041;&#27861;&#12290;&#36825;&#20123;&#20559;&#24046;&#65292;&#27604;&#22914;&#34394;&#20551;&#30340;&#20851;&#32852;&#65292;&#26159;&#30001;&#20110;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20013;&#21508;&#31181;&#35266;&#23519;&#21040;&#30340;&#21644;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#21464;&#37327;&#24341;&#36215;&#30340;&#12290;&#26412;&#25991;&#27491;&#24335;&#20998;&#26512;&#20102;&#28151;&#28102;&#20559;&#24046;&#22914;&#20309;&#24433;&#21709;&#19979;&#28216;&#20998;&#31867;&#22120;&#65292;&#24182;&#20174;&#22240;&#26524;&#30340;&#35282;&#24230;&#25506;&#35752;&#22522;&#20110;&#21453;&#20107;&#23454;&#25968;&#25454;&#22686;&#24378;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#25506;&#35752;&#22914;&#20309;&#21435;&#38500;&#28151;&#28102;&#20559;&#24046;&#20316;&#20026;&#23398;&#20064;&#19981;&#21464;&#29305;&#24449;&#30340;&#25163;&#27573;&#65292;&#26368;&#32456;&#26377;&#21161;&#20110;&#22312;&#35266;&#23519;&#21040;&#30340;&#25968;&#25454;&#20998;&#24067;&#20043;&#22806;&#36827;&#34892;&#27867;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#20294;&#24378;&#22823;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#21453;&#20107;&#23454;&#22270;&#20687;&#65292;&#26377;&#25928;&#22320;&#32531;&#35299;&#28151;&#28102;&#25928;&#24212;&#23545;&#19979;&#28216;&#20998;&#31867;&#22120;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#22312;MNIST&#21464;&#20307;&#21644;CelebA&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactual data augmentation has recently emerged as a method to mitigate confounding biases in the training data for a machine learning model. These biases, such as spurious correlations, arise due to various observed and unobserved confounding variables in the data generation process. In this paper, we formally analyze how confounding biases impact downstream classifiers and present a causal viewpoint to the solutions based on counterfactual data augmentation. We explore how removing confounding biases serves as a means to learn invariant features, ultimately aiding in generalization beyond the observed data distribution. Additionally, we present a straightforward yet powerful algorithm for generating counterfactual images, which effectively mitigates the influence of confounding effects on downstream classifiers. Through experiments on MNIST variants and the CelebA datasets, we demonstrate the effectiveness and practicality of our approach.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#23558;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#36716;&#21270;&#20026;&#19968;&#32452;&#21333;&#30446;&#26631;&#38382;&#39064;&#36827;&#34892;&#35299;&#20915;&#65292;&#24182;&#20171;&#32461;&#20102;R2&#25928;&#29992;&#20989;&#25968;&#20316;&#20026;&#36866;&#24403;&#30340;&#30446;&#26631;&#20989;&#25968;&#12290;&#35813;&#25928;&#29992;&#20989;&#25968;&#21333;&#35843;&#19988;&#27425;&#27169;&#65292;&#21487;&#20197;&#20351;&#29992;&#36138;&#24515;&#20248;&#21270;&#31639;&#27861;&#35745;&#31639;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2305.11774</link><description>&lt;p&gt;
&#20351;&#29992;R2&#25928;&#29992;&#30340;&#22810;&#30446;&#26631;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Multi-Objective Optimization Using the R2 Utility. (arXiv:2305.11774v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11774
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#23558;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#36716;&#21270;&#20026;&#19968;&#32452;&#21333;&#30446;&#26631;&#38382;&#39064;&#36827;&#34892;&#35299;&#20915;&#65292;&#24182;&#20171;&#32461;&#20102;R2&#25928;&#29992;&#20989;&#25968;&#20316;&#20026;&#36866;&#24403;&#30340;&#30446;&#26631;&#20989;&#25968;&#12290;&#35813;&#25928;&#29992;&#20989;&#25968;&#21333;&#35843;&#19988;&#27425;&#27169;&#65292;&#21487;&#20197;&#20351;&#29992;&#36138;&#24515;&#20248;&#21270;&#31639;&#27861;&#35745;&#31639;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#30446;&#26631;&#20248;&#21270;&#30340;&#30446;&#26631;&#26159;&#30830;&#23450;&#25551;&#36848;&#22810;&#30446;&#26631;&#20043;&#38388;&#26368;&#20339;&#26435;&#34913;&#30340;&#28857;&#38598;&#21512;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#30690;&#37327;&#20540;&#20248;&#21270;&#38382;&#39064;&#65292;&#20174;&#19994;&#32773;&#24120;&#24120;&#20351;&#29992;&#26631;&#37327;&#21270;&#20989;&#25968;&#23558;&#22810;&#30446;&#26631;&#38382;&#39064;&#36716;&#21270;&#20026;&#19968;&#32452;&#21333;&#30446;&#26631;&#38382;&#39064;&#12290;&#36825;&#32452;&#26631;&#37327;&#21270;&#38382;&#39064;&#21487;&#20197;&#20351;&#29992;&#20256;&#32479;&#30340;&#21333;&#30446;&#26631;&#20248;&#21270;&#25216;&#26415;&#26469;&#35299;&#20915;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#32422;&#23450;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#36890;&#29992;&#30340;&#25968;&#23398;&#26694;&#26550;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#31574;&#30053;&#22914;&#20309;&#26377;&#25928;&#22320;&#23558;&#21407;&#22987;&#30340;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#37325;&#26032;&#36716;&#21270;&#20026;&#23450;&#20041;&#22312;&#38598;&#21512;&#19978;&#30340;&#21333;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#12290;&#38024;&#23545;&#36825;&#20010;&#26032;&#38382;&#39064;&#30340;&#36866;&#24403;&#31867;&#21035;&#30340;&#30446;&#26631;&#20989;&#25968;&#26159;R2&#25928;&#29992;&#20989;&#25968;&#65292;&#23427;&#34987;&#23450;&#20041;&#20026;&#26631;&#37327;&#21270;&#20248;&#21270;&#38382;&#39064;&#30340;&#21152;&#26435;&#31215;&#20998;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20010;&#25928;&#29992;&#20989;&#25968;&#26159;&#21333;&#35843;&#30340;&#21644;&#27425;&#27169;&#30340;&#38598;&#21512;&#20989;&#25968;&#65292;&#21487;&#20197;&#36890;&#36807;&#36138;&#24515;&#20248;&#21270;&#31639;&#27861;&#26377;&#25928;&#22320;&#35745;&#31639;&#20986;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
The goal of multi-objective optimization is to identify a collection of points which describe the best possible trade-offs between the multiple objectives. In order to solve this vector-valued optimization problem, practitioners often appeal to the use of scalarization functions in order to transform the multi-objective problem into a collection of single-objective problems. This set of scalarized problems can then be solved using traditional single-objective optimization techniques. In this work, we formalise this convention into a general mathematical framework. We show how this strategy effectively recasts the original multi-objective optimization problem into a single-objective optimization problem defined over sets. An appropriate class of objective functions for this new problem is the R2 utility function, which is defined as a weighted integral over the scalarized optimization problems. We show that this utility function is a monotone and submodular set function, which can be op
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#38750;&#20984;&#38750;&#20809;&#28369;&#38382;&#39064;&#30340;&#38750;&#31934;&#30830;&#32447;&#24615;&#21270;&#36817;&#31471;&#31639;&#27861;&#65292;&#24182;&#24212;&#29992;&#20110;&#40065;&#26834;&#20998;&#35299;&#20013;&#30340;&#20004;&#20010;&#38382;&#39064;&#65292;&#24471;&#21040;&#20102;&#26377;&#25928;&#30340;&#25968;&#20540;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2303.16822</link><description>&lt;p&gt;
&#19968;&#31867;DC&#22797;&#21512;&#20248;&#21270;&#38382;&#39064;&#30340;&#38750;&#31934;&#30830;&#32447;&#24615;&#36817;&#20284;&#36817;&#31471;&#31639;&#27861;&#21450;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
An inexact linearized proximal algorithm for a class of DC composite optimization problems and applications. (arXiv:2303.16822v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16822
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#38750;&#20984;&#38750;&#20809;&#28369;&#38382;&#39064;&#30340;&#38750;&#31934;&#30830;&#32447;&#24615;&#21270;&#36817;&#31471;&#31639;&#27861;&#65292;&#24182;&#24212;&#29992;&#20110;&#40065;&#26834;&#20998;&#35299;&#20013;&#30340;&#20004;&#20010;&#38382;&#39064;&#65292;&#24471;&#21040;&#20102;&#26377;&#25928;&#30340;&#25968;&#20540;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;DC&#22797;&#21512;&#20248;&#21270;&#38382;&#39064;&#12290;&#36825;&#31867;&#38382;&#39064;&#36890;&#24120;&#30001;&#20302;&#31209;&#30697;&#38453;&#24674;&#22797;&#30340;&#40065;&#26834;&#20998;&#35299;&#27169;&#22411;&#25512;&#23548;&#32780;&#26469;&#65292;&#26159;&#20984;&#22797;&#21512;&#20248;&#21270;&#38382;&#39064;&#21644;&#20855;&#26377;&#38750;&#20809;&#28369;&#20998;&#37327;&#30340;DC&#35268;&#21010;&#30340;&#25193;&#23637;&#12290;&#38024;&#23545;&#36825;&#31867;&#38750;&#20984;&#21644;&#38750;&#20809;&#28369;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#31934;&#30830;&#32447;&#24615;&#21270;&#36817;&#31471;&#31639;&#27861;&#65288;iLPA&#65289;&#12290;&#31639;&#27861;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#30446;&#26631;&#20989;&#25968;&#30340;&#37096;&#20998;&#32447;&#24615;&#21270;&#65292;&#35745;&#31639;&#24378;&#20984;&#20027;&#23548;&#30340;&#38750;&#31934;&#30830;&#26368;&#23567;&#21270;&#20540;&#12290;&#36845;&#20195;&#24207;&#21015;&#30340;&#29983;&#25104;&#25910;&#25947;&#20110;&#28508;&#22312;&#20989;&#25968;&#30340;Kurdyka-{\L}ojasiewicz&#65288;KL&#65289;&#24615;&#36136;&#65292;&#22914;&#26524;&#28508;&#22312;&#20989;&#25968;&#22312;&#26497;&#38480;&#28857;&#22788;&#20855;&#26377;KL&#25351;&#25968;$1/2$&#30340;KL&#24615;&#36136;&#65292;&#21017;&#25910;&#25947;&#20855;&#26377;&#23616;&#37096;R&#32447;&#24615;&#36895;&#29575;&#12290;&#23545;&#20110;&#21518;&#19968;&#31181;&#20551;&#35774;&#65292;&#25105;&#20204;&#21033;&#29992;&#22797;&#21512;&#32467;&#26500;&#25552;&#20379;&#20102;&#19968;&#20010;&#21487;&#39564;&#35777;&#30340;&#26465;&#20214;&#65292;&#24182;&#38416;&#26126;&#20102;&#19982;&#20984;&#22797;&#21512;&#20248;&#21270;&#25152;&#20351;&#29992;&#30340;&#27491;&#21017;&#24615;&#30340;&#20851;&#31995;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#25152;&#25552;&#20986;&#30340;&#38750;&#31934;&#30830;&#32447;&#24615;&#36817;&#31471;&#31639;&#27861;&#24212;&#29992;&#20110;&#35299;&#20915;&#40065;&#26834;&#20998;&#35299;&#20013;&#30340;&#20004;&#20010;&#37325;&#35201;&#38382;&#39064;&#65306;&#24352;&#37327;&#40065;&#26834;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;TRPCA&#65289;&#21644;&#24352;&#37327;&#40065;&#26834;&#20302;&#31209;&#24352;&#37327;&#23436;&#25104;&#65288;TRLRTC&#65289;&#12290;&#23545;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#30340;&#25968;&#20540;&#32467;&#26524;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#30456;&#23545;&#20110;&#29616;&#26377;&#26368;&#26032;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is concerned with a class of DC composite optimization problems which, as an extension of the convex composite optimization problem and the DC program with nonsmooth components, often arises from robust factorization models of low-rank matrix recovery. For this class of nonconvex and nonsmooth problems, we propose an inexact linearized proximal algorithm (iLPA) which in each step computes an inexact minimizer of a strongly convex majorization constructed by the partial linearization of their objective functions. The generated iterate sequence is shown to be convergent under the Kurdyka-{\L}ojasiewicz (KL) property of a potential function, and the convergence admits a local R-linear rate if the potential function has the KL property of exponent $1/2$ at the limit point. For the latter assumption, we provide a verifiable condition by leveraging the composite structure, and clarify its relation with the regularity used for the convex composite optimization. Finally, the propose
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#25968;&#25454;&#31232;&#30095;&#21270;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#24456;&#22810;&#20998;&#24067;&#31867;&#22411;&#65292;&#21253;&#25324;&#39640;&#26031;&#20998;&#24067;&#12289;&#27850;&#26494;&#20998;&#24067;&#12289;&#36127;&#20108;&#39033;&#20998;&#24067;&#12289;&#20285;&#29595;&#20998;&#24067;&#21644;&#20108;&#39033;&#20998;&#24067;&#31561;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#65292;&#22914;&#22312;&#20132;&#21449;&#39564;&#35777;&#26041;&#38754;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#33021;&#26377;&#25928;&#39564;&#35777;&#26080;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#30340;&#21487;&#38752;&#24615;&#12290;</title><link>http://arxiv.org/abs/2301.07276</link><description>&lt;p&gt;
&#25968;&#25454;&#31232;&#30095;&#21270;&#25216;&#26415;&#29992;&#20110;&#21367;&#31215;&#23553;&#38381;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Data thinning for convolution-closed distributions. (arXiv:2301.07276v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.07276
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#25968;&#25454;&#31232;&#30095;&#21270;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#24456;&#22810;&#20998;&#24067;&#31867;&#22411;&#65292;&#21253;&#25324;&#39640;&#26031;&#20998;&#24067;&#12289;&#27850;&#26494;&#20998;&#24067;&#12289;&#36127;&#20108;&#39033;&#20998;&#24067;&#12289;&#20285;&#29595;&#20998;&#24067;&#21644;&#20108;&#39033;&#20998;&#24067;&#31561;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#65292;&#22914;&#22312;&#20132;&#21449;&#39564;&#35777;&#26041;&#38754;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#33021;&#26377;&#25928;&#39564;&#35777;&#26080;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#25968;&#25454;&#31232;&#30095;&#21270;&#30340;&#26041;&#27861;&#65292;&#23558;&#19968;&#20010;&#35266;&#27979;&#20540;&#20998;&#25104;&#20004;&#20010;&#25110;&#26356;&#22810;&#20010;&#20114;&#30456;&#29420;&#31435;&#30340;&#37096;&#20998;&#65292;&#36825;&#20123;&#37096;&#20998;&#37117;&#21152;&#36215;&#26469;&#31561;&#20110;&#21407;&#22987;&#25968;&#25454;&#65292;&#24182;&#19988;&#19982;&#21407;&#22987;&#35266;&#27979;&#20540;&#30456;&#21516;&#30340;&#20998;&#24067;&#65292;&#21482;&#26159;&#32463;&#36807;&#19968;&#20010;&#24050;&#30693;&#21442;&#25968;&#35843;&#25972;&#12290;&#36825;&#20010;&#38750;&#24120;&#26222;&#36866;&#30340;&#26041;&#27861;&#36866;&#29992;&#20110;&#20219;&#20309;&#21367;&#31215;&#23553;&#38381;&#20998;&#24067;&#65292;&#21253;&#25324;&#39640;&#26031;&#20998;&#24067;&#12289;&#27850;&#26494;&#20998;&#24067;&#12289;&#36127;&#20108;&#39033;&#20998;&#24067;&#12289;&#20285;&#29595;&#20998;&#24067;&#21644;&#20108;&#39033;&#20998;&#24067;&#31561;&#12290;&#25968;&#25454;&#31232;&#30095;&#21270;&#22312;&#27169;&#22411;&#36873;&#25321;&#12289;&#35780;&#20215;&#21644;&#25512;&#29702;&#26041;&#38754;&#26377;&#22810;&#31181;&#24212;&#29992;&#12290;&#20363;&#22914;&#65292;&#36890;&#36807;&#25968;&#25454;&#31232;&#30095;&#21270;&#30340;&#20132;&#21449;&#39564;&#35777;&#25552;&#20379;&#20102;&#19968;&#31181;&#21560;&#24341;&#20154;&#30340;&#26367;&#20195;&#26041;&#27861;&#26469;&#36827;&#34892;&#20132;&#21449;&#39564;&#35777;&#65292;&#29305;&#21035;&#26159;&#22312;&#26080;&#30417;&#30563;&#30340;&#24773;&#20917;&#19979;&#65292;&#20256;&#32479;&#26041;&#27861;&#30340;&#26679;&#26412;&#21010;&#20998;&#19981;&#36866;&#29992;&#12290;&#25105;&#20204;&#22312;&#27169;&#25311;&#21644;&#24212;&#29992;&#20110;&#21333;&#32454;&#32990;RNA&#27979;&#24207;&#25968;&#25454;&#30340;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#25968;&#25454;&#31232;&#30095;&#21270;&#30340;&#26222;&#36941;&#24615;&#65292;&#21487;&#20197;&#29992;&#20110;&#39564;&#35777;&#26080;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#30340;&#32467;&#26524;&#65292;&#22914;k-means&#32858;&#31867;&#21644;&#20027;&#25104;&#20998;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose data thinning, an approach for splitting an observation into two or more independent parts that sum to the original observation, and that follow the same distribution as the original observation, up to a (known) scaling of a parameter. This very general proposal is applicable to any convolution-closed distribution, a class that includes the Gaussian, Poisson, negative binomial, gamma, and binomial distributions, among others. Data thinning has a number of applications to model selection, evaluation, and inference. For instance, cross-validation via data thinning provides an attractive alternative to the usual approach of cross-validation via sample splitting, especially in unsupervised settings in which the latter is not applicable. In simulations and in an application to single-cell RNA-sequencing data, we show that data thinning can be used to validate the results of unsupervised learning approaches, such as k-means clustering and principal components analysis.
&lt;/p&gt;</description></item></channel></rss>