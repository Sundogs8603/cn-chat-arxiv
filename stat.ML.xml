<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#20351;&#29992;&#26032;&#20852;&#30340;&#32479;&#35745;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#23545;&#32654;&#22269;&#22478;&#24066;&#30340;&#26497;&#31471;&#27668;&#28201;&#36827;&#34892;&#20102;&#20840;&#38754;&#20998;&#26512;&#65292;&#21457;&#29616;&#22810;&#23618;&#24863;&#30693;&#22120;&#26159;&#26368;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#35813;&#26041;&#27861;&#23545;&#26410;&#26469;&#26497;&#31471;&#27668;&#28201;&#36827;&#34892;&#20102;&#39044;&#27979;&#21644;&#20551;&#35774;&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2307.14285</link><description>&lt;p&gt;
&#26032;&#20852;&#30340;&#32479;&#35745;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#22312;&#32654;&#22269;&#22478;&#24066;&#30340;&#26497;&#31471;&#27668;&#28201;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Emerging Statistical Machine Learning Techniques for Extreme Temperature Forecasting in U.S. Cities. (arXiv:2307.14285v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14285
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#26032;&#20852;&#30340;&#32479;&#35745;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#23545;&#32654;&#22269;&#22478;&#24066;&#30340;&#26497;&#31471;&#27668;&#28201;&#36827;&#34892;&#20102;&#20840;&#38754;&#20998;&#26512;&#65292;&#21457;&#29616;&#22810;&#23618;&#24863;&#30693;&#22120;&#26159;&#26368;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#35813;&#26041;&#27861;&#23545;&#26410;&#26469;&#26497;&#31471;&#27668;&#28201;&#36827;&#34892;&#20102;&#39044;&#27979;&#21644;&#20551;&#35774;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#26032;&#20852;&#30340;&#32479;&#35745;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#23545;&#26497;&#31471;&#27668;&#28201;&#27169;&#24335;&#36827;&#34892;&#20102;&#20840;&#38754;&#20998;&#26512;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#37325;&#28857;&#26159;&#25506;&#32034;&#21644;&#27604;&#36739;&#21508;&#31181;&#32479;&#35745;&#27169;&#22411;&#22312;&#27668;&#20505;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#25152;&#32771;&#34385;&#30340;&#27169;&#22411;&#21253;&#25324;&#33258;&#22238;&#24402;&#32508;&#21512;&#31227;&#21160;&#24179;&#22343;&#12289;&#25351;&#25968;&#24179;&#28369;&#12289;&#22810;&#23618;&#24863;&#30693;&#22120;&#21644;&#39640;&#26031;&#36807;&#31243;&#12290;&#25105;&#20204;&#24212;&#29992;&#36825;&#20123;&#26041;&#27861;&#20110;&#32654;&#22269;&#20116;&#20010;&#20154;&#21475;&#26368;&#22810;&#30340;&#22478;&#24066;&#30340;&#27668;&#20505;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#21033;&#29992;Python&#21644;Julia&#26469;&#23637;&#31034;&#32479;&#35745;&#35745;&#31639;&#22312;&#29702;&#35299;&#27668;&#20505;&#21464;&#21270;&#21450;&#20854;&#24433;&#21709;&#20013;&#30340;&#20316;&#29992;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#31361;&#20986;&#20102;&#32479;&#35745;&#26041;&#27861;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#24182;&#30830;&#23450;&#20102;&#22810;&#23618;&#24863;&#30693;&#22120;&#20316;&#20026;&#26368;&#26377;&#25928;&#30340;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;&#36825;&#20010;&#26368;&#20339;&#26041;&#27861;&#23545;&#26410;&#26469;&#30340;&#26497;&#31471;&#27668;&#28201;&#36827;&#34892;&#20102;&#39044;&#27979;&#65292;&#32771;&#23519;&#28201;&#24230;&#21464;&#21270;&#26159;&#21542;&#22823;&#20110;&#38646;&#65292;&#20174;&#32780;&#27979;&#35797;&#20102;&#19968;&#20010;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present a comprehensive analysis of extreme temperature patterns using emerging statistical machine learning techniques. Our research focuses on exploring and comparing the effectiveness of various statistical models for climate time series forecasting. The models considered include Auto-Regressive Integrated Moving Average, Exponential Smoothing, Multilayer Perceptrons, and Gaussian Processes. We apply these methods to climate time series data from five most populated U.S. cities, utilizing Python and Julia to demonstrate the role of statistical computing in understanding climate change and its impacts. Our findings highlight the differences between the statistical methods and identify Multilayer Perceptrons as the most effective approach. Additionally, we project extreme temperatures using this best-performing method, up to 2030, and examine whether the temperature changes are greater than zero, thereby testing a hypothesis.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26367;&#25442;&#26631;&#20934;&#30340;&#39640;&#26031;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#20351;&#29992;&#23450;&#21046;&#30340;&#20998;&#31867;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#25105;&#20204;&#21457;&#29616;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#30340;&#24213;&#23618;&#32593;&#26684;&#32467;&#26500;&#21487;&#20197;&#26377;&#25928;&#32531;&#35299;&#35299;&#31163;&#34920;&#31034;&#20013;&#30340;&#26059;&#36716;&#19981;&#21464;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#20248;&#21270;&#35299;&#31163;&#34920;&#31034;&#30340;&#26080;&#30417;&#30563;&#27169;&#22411;&#36873;&#25321;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2307.14151</link><description>&lt;p&gt;
&#23398;&#20064;&#35299;&#31163;&#30340;&#31163;&#25955;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Learning Disentangled Discrete Representations. (arXiv:2307.14151v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14151
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26367;&#25442;&#26631;&#20934;&#30340;&#39640;&#26031;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#20351;&#29992;&#23450;&#21046;&#30340;&#20998;&#31867;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#25105;&#20204;&#21457;&#29616;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#30340;&#24213;&#23618;&#32593;&#26684;&#32467;&#26500;&#21487;&#20197;&#26377;&#25928;&#32531;&#35299;&#35299;&#31163;&#34920;&#31034;&#20013;&#30340;&#26059;&#36716;&#19981;&#21464;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#20248;&#21270;&#35299;&#31163;&#34920;&#31034;&#30340;&#26080;&#30417;&#30563;&#27169;&#22411;&#36873;&#25321;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22312;&#22270;&#20687;&#29983;&#25104;&#12289;&#22522;&#20110;&#27169;&#22411;&#30340;&#22686;&#24378;&#23398;&#20064;&#21644;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#26041;&#38754;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#36825;&#20123;&#37117;&#35777;&#26126;&#20102;&#31163;&#25955;&#28508;&#22312;&#34920;&#31034;&#30340;&#32463;&#39564;&#20248;&#21183;&#65292;&#23613;&#31649;&#20854;&#32972;&#21518;&#30340;&#21407;&#22240;&#23578;&#19981;&#28165;&#26970;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#26631;&#20934;&#30340;&#39640;&#26031;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#26367;&#25442;&#20026;&#23450;&#21046;&#30340;&#20998;&#31867;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#25506;&#32034;&#20102;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#21644;&#35299;&#31163;&#34920;&#31034;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#26174;&#31034;&#20998;&#31867;&#20998;&#24067;&#30340;&#24213;&#23618;&#32593;&#26684;&#32467;&#26500;&#20943;&#36731;&#20102;&#19982;&#22810;&#21464;&#37327;&#39640;&#26031;&#20998;&#24067;&#30456;&#20851;&#30340;&#26059;&#36716;&#19981;&#21464;&#24615;&#38382;&#39064;&#65292;&#20316;&#20026;&#35299;&#31163;&#34920;&#31034;&#30340;&#39640;&#25928;&#24402;&#32435;&#20808;&#39564;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20998;&#26512;&#21644;&#23454;&#35777;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#31163;&#25955;VAE&#22312;&#23398;&#20064;&#35299;&#31163;&#34920;&#31034;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31532;&#19968;&#20010;&#25903;&#25345;&#35299;&#31163;&#34920;&#31034;&#30340;&#26080;&#30417;&#30563;&#27169;&#22411;&#36873;&#25321;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent successes in image generation, model-based reinforcement learning, and text-to-image generation have demonstrated the empirical advantages of discrete latent representations, although the reasons behind their benefits remain unclear. We explore the relationship between discrete latent spaces and disentangled representations by replacing the standard Gaussian variational autoencoder (VAE) with a tailored categorical variational autoencoder. We show that the underlying grid structure of categorical distributions mitigates the problem of rotational invariance associated with multivariate Gaussian distributions, acting as an efficient inductive prior for disentangled representations. We provide both analytical and empirical findings that demonstrate the advantages of discrete VAEs for learning disentangled representations. Furthermore, we introduce the first unsupervised model selection strategy that favors disentangled representations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#22914;&#20309;&#35774;&#35745;&#19968;&#20010;&#33021;&#22815;&#25903;&#25345;&#38750;&#19987;&#23478;&#24037;&#31243;&#24072;&#24320;&#21457;&#20027;&#21160;&#25512;&#29702;&#20195;&#29702;&#30340;&#36719;&#20214;&#24037;&#20855;&#31665;&#65292;&#20197;&#23454;&#29616;&#22312;&#36793;&#32536;&#35774;&#22791;&#19978;&#36816;&#34892;&#30340;&#26377;&#25928;&#20195;&#29702;&#12290;&#26088;&#22312;&#21152;&#36895;&#20027;&#21160;&#25512;&#29702;&#20195;&#29702;&#30340;&#27665;&#20027;&#21270;&#36827;&#31243;&#12290;</title><link>http://arxiv.org/abs/2307.14145</link><description>&lt;p&gt;
&#36890;&#36807;&#20961;&#20154;&#35774;&#35745;&#21512;&#25104;&#20027;&#21160;&#25512;&#29702;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
Toward Design of Synthetic Active Inference Agents by Mere Mortals. (arXiv:2307.14145v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14145
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#22914;&#20309;&#35774;&#35745;&#19968;&#20010;&#33021;&#22815;&#25903;&#25345;&#38750;&#19987;&#23478;&#24037;&#31243;&#24072;&#24320;&#21457;&#20027;&#21160;&#25512;&#29702;&#20195;&#29702;&#30340;&#36719;&#20214;&#24037;&#20855;&#31665;&#65292;&#20197;&#23454;&#29616;&#22312;&#36793;&#32536;&#35774;&#22791;&#19978;&#36816;&#34892;&#30340;&#26377;&#25928;&#20195;&#29702;&#12290;&#26088;&#22312;&#21152;&#36895;&#20027;&#21160;&#25512;&#29702;&#20195;&#29702;&#30340;&#27665;&#20027;&#21270;&#36827;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#21160;&#25512;&#29702;&#20195;&#29702;&#30340;&#29702;&#35770;&#29305;&#24615;&#26159;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#65292;&#20294;&#26159;&#25105;&#20204;&#22914;&#20309;&#22312;&#36793;&#32536;&#35774;&#22791;&#19978;&#23454;&#29616;&#26377;&#25928;&#30340;&#30828;&#20214;&#21644;&#36719;&#20214;&#20195;&#29702;&#21602;&#65311;&#36825;&#26159;&#19968;&#20010;&#26377;&#36259;&#30340;&#38382;&#39064;&#65292;&#22240;&#20026;&#31574;&#30053;&#25506;&#32034;&#30340;&#35745;&#31639;&#36127;&#33655;&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#65292;&#32780;&#36793;&#32536;&#35774;&#22791;&#30340;&#35745;&#31639;&#36164;&#28304;&#38750;&#24120;&#26377;&#38480;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#19968;&#20010;&#25903;&#25345;&#38750;&#19987;&#23478;&#24037;&#31243;&#24072;&#24320;&#21457;&#26377;&#25928;&#20027;&#21160;&#25512;&#29702;&#20195;&#29702;&#30340;&#36719;&#20214;&#24037;&#20855;&#31665;&#25152;&#24517;&#38656;&#30340;&#29305;&#24615;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#27491;&#22312;&#24320;&#21457;&#20013;&#30340;&#24037;&#20855;&#31665;&#65292;&#26088;&#22312;&#21152;&#36895;&#20027;&#21160;&#25512;&#29702;&#20195;&#29702;&#30340;&#27665;&#20027;&#21270;&#36827;&#31243;&#65292;&#23601;&#20687;TensorFlow&#25512;&#21160;&#20102;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#30340;&#24212;&#29992;&#19968;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;
The theoretical properties of active inference agents are impressive, but how do we realize effective agents in working hardware and software on edge devices? This is an interesting problem because the computational load for policy exploration explodes exponentially, while the computational resources are very limited for edge devices. In this paper, we discuss the necessary features for a software toolbox that supports a competent non-expert engineer to develop working active inference agents. We introduce a toolbox-in-progress that aims to accelerate the democratization of active inference agents in a similar way as TensorFlow propelled applications of deep learning technology.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#20855;&#26377;&#22240;&#26524;&#20851;&#31995;&#22870;&#21169;&#30340;&#20998;&#27573;&#31283;&#23450;&#32452;&#21512;&#21322;&#24378;&#30423;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19978;&#30028;&#32622;&#20449;&#24230;&#31639;&#27861;&#20197;&#24212;&#23545;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#30340;&#25361;&#25112;&#12290;&#27492;&#22806;&#65292;&#24341;&#20837;&#20102;&#32452;&#37325;&#21551;&#30340;&#27010;&#24565;&#20316;&#20026;&#32467;&#26500;&#21270;&#29615;&#22659;&#20013;&#30340;&#22791;&#20221;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2307.14138</link><description>&lt;p&gt;
&#20998;&#27573;&#31283;&#23450;&#32452;&#21512;&#21322;&#24378;&#30423;&#38382;&#39064;&#21450;&#22240;&#26524;&#20851;&#31995;&#22870;&#21169;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Piecewise-Stationary Combinatorial Semi-Bandit with Causally Related Rewards. (arXiv:2307.14138v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14138
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#20855;&#26377;&#22240;&#26524;&#20851;&#31995;&#22870;&#21169;&#30340;&#20998;&#27573;&#31283;&#23450;&#32452;&#21512;&#21322;&#24378;&#30423;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19978;&#30028;&#32622;&#20449;&#24230;&#31639;&#27861;&#20197;&#24212;&#23545;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#30340;&#25361;&#25112;&#12290;&#27492;&#22806;&#65292;&#24341;&#20837;&#20102;&#32452;&#37325;&#21551;&#30340;&#27010;&#24565;&#20316;&#20026;&#32467;&#26500;&#21270;&#29615;&#22659;&#20013;&#30340;&#22791;&#20221;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#22240;&#26524;&#20851;&#31995;&#22870;&#21169;&#30340;&#20998;&#27573;&#31283;&#23450;&#32452;&#21512;&#21322;&#24378;&#30423;&#38382;&#39064;&#12290;&#22312;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#65292;&#22522;&#26412;&#33218;&#30340;&#20998;&#24067;&#21464;&#21270;&#12289;&#22870;&#21169;&#20043;&#38388;&#30340;&#22240;&#26524;&#20851;&#31995;&#65292;&#25110;&#32773;&#20004;&#32773;&#21516;&#26102;&#25913;&#21464;&#22870;&#21169;&#29983;&#25104;&#36807;&#31243;&#12290;&#22312;&#36825;&#26679;&#30340;&#29615;&#22659;&#20013;&#65292;&#26368;&#20248;&#30340;&#20915;&#31574;&#32773;&#24517;&#39035;&#36319;&#38543;&#36825;&#20004;&#20010;&#21464;&#21270;&#28304;&#65292;&#24182;&#30456;&#24212;&#22320;&#36827;&#34892;&#36866;&#24212;&#12290;&#22312;&#32452;&#21512;&#21322;&#24378;&#30423;&#35774;&#32622;&#20013;&#65292;&#38382;&#39064;&#21464;&#24471;&#26356;&#21152;&#20005;&#37325;&#65292;&#22240;&#20026;&#20915;&#31574;&#32773;&#21482;&#35266;&#23519;&#21040;&#25152;&#36873;&#33218;&#32452;&#21512;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#31574;&#30053;&#26680;&#24515;&#26159;&#19978;&#30028;&#32622;&#20449;&#24230;&#65288;Upper Confidence Bound, UCB&#65289;&#31639;&#27861;&#12290;&#25105;&#20204;&#20551;&#35774;&#20195;&#29702;&#20381;&#38752;&#33258;&#36866;&#24212;&#30340;&#26041;&#27861;&#26469;&#24212;&#23545;&#36825;&#19968;&#25361;&#25112;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#23427;&#20351;&#29992;&#22522;&#20110;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#30340;&#21464;&#28857;&#26816;&#27979;&#22120;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#32452;&#37325;&#21551;&#30340;&#27010;&#24565;&#20316;&#20026;&#32467;&#26500;&#21270;&#29615;&#22659;&#20013;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#26032;&#22411;&#22791;&#20221;&#31574;&#30053;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#25972;&#21512;&#20102;&#19968;&#20010;&#36319;&#36394;&#26426;&#21046;&#20197;&#36861;&#36394;
&lt;/p&gt;
&lt;p&gt;
We study the piecewise stationary combinatorial semi-bandit problem with causally related rewards. In our nonstationary environment, variations in the base arms' distributions, causal relationships between rewards, or both, change the reward generation process. In such an environment, an optimal decision-maker must follow both sources of change and adapt accordingly. The problem becomes aggravated in the combinatorial semi-bandit setting, where the decision-maker only observes the outcome of the selected bundle of arms. The core of our proposed policy is the Upper Confidence Bound (UCB) algorithm. We assume the agent relies on an adaptive approach to overcome the challenge. More specifically, it employs a change-point detector based on the Generalized Likelihood Ratio (GLR) test. Besides, we introduce the notion of group restart as a new alternative restarting strategy in the decision making process in structured environments. Finally, our algorithm integrates a mechanism to trace the 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20805;&#28385;&#22242;&#22270;&#30340;&#27010;&#24565;&#65292;&#24182;&#19988;&#21457;&#29616;&#22312;&#31616;&#21333;&#22270;&#20013;&#65292;&#20805;&#28385;&#22242;&#22270;&#30340;&#26368;&#22823;&#25968;&#37327;&#21462;&#20915;&#20110;&#39281;&#21644;&#22797;&#21512;&#20805;&#28385;&#22242;&#22270;&#12290;&#36890;&#36807;&#20855;&#20307;&#35745;&#31639;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#22312;n&#20010;&#39030;&#28857;&#19978;&#20855;&#26377;&#26368;&#22810;&#26368;&#22823;&#22242;&#25968;&#37327;&#30340;&#22270;&#24418;&#24335;&#34920;&#36798;&#24335;&#12290;</title><link>http://arxiv.org/abs/2307.14120</link><description>&lt;p&gt;
&#20316;&#20026;&#35745;&#31639;&#31616;&#21333;&#22270;&#30340;&#26368;&#22823;&#22242;&#30340;&#26368;&#22823;&#25968;&#37327;&#30340;&#25163;&#27573;&#30340;&#20805;&#28385;&#22242;&#22270;
&lt;/p&gt;
&lt;p&gt;
Cliqueful graphs as a means of calculating the maximal number of maximum cliques of simple graphs. (arXiv:2307.14120v1 [math.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14120
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20805;&#28385;&#22242;&#22270;&#30340;&#27010;&#24565;&#65292;&#24182;&#19988;&#21457;&#29616;&#22312;&#31616;&#21333;&#22270;&#20013;&#65292;&#20805;&#28385;&#22242;&#22270;&#30340;&#26368;&#22823;&#25968;&#37327;&#21462;&#20915;&#20110;&#39281;&#21644;&#22797;&#21512;&#20805;&#28385;&#22242;&#22270;&#12290;&#36890;&#36807;&#20855;&#20307;&#35745;&#31639;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#22312;n&#20010;&#39030;&#28857;&#19978;&#20855;&#26377;&#26368;&#22810;&#26368;&#22823;&#22242;&#25968;&#37327;&#30340;&#22270;&#24418;&#24335;&#34920;&#36798;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#20010;&#31616;&#21333;&#22270;&#22312;n&#20010;&#39030;&#28857;&#19978;&#21487;&#33021;&#21253;&#21547;&#35768;&#22810;&#26368;&#22823;&#22242;&#12290;&#20294;&#23427;&#21487;&#33021;&#21253;&#21547;&#22810;&#23569;&#20010;&#21602;&#65311;&#25105;&#20204;&#23558;&#23637;&#31034;&#26368;&#22823;&#22242;&#30340;&#26368;&#22823;&#25968;&#37327;&#21462;&#20915;&#20110;&#25152;&#35859;&#30340;&#20805;&#28385;&#22242;&#22270;&#65292;&#20855;&#20307;&#22320;&#35828;&#65292;&#22914;&#26524;n&#8805;15&#65292;&#25105;&#20204;&#23558;&#23637;&#31034;&#23427;&#21462;&#20915;&#20110;&#39281;&#21644;&#22797;&#21512;&#20805;&#28385;&#22242;&#22270;&#12290;&#21033;&#29992;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#23558;&#23637;&#31034;&#21253;&#21547;3^{&#8970;n/3&#8971;}c&#20010;&#26368;&#22823;&#22242;&#30340;&#22270;&#22312;n&#20010;&#39030;&#28857;&#19978;&#20855;&#26377;&#26368;&#22810;&#30340;&#26368;&#22823;&#22242;&#25968;&#37327;&#65292;&#20854;&#20013;c&#8712;{1,4/3,2}&#65292;&#21462;&#20915;&#20110;n&#27169;3&#30340;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
A simple graph on $n$ vertices may contain a lot of maximum cliques. But how many can it potentially contain? We will show that the maximum number of maximum cliques is taken over so-called cliqueful graphs, more specifically, later we will show that it is taken over saturated composite cliqueful graphs, if $n \ge 15$. Using this we will show that the graph that contains $3^{\lfloor n/3 \rfloor}c$ maxcliques has the most number of maxcliques on $n$ vertices, where $c\in\{1,\frac{4}{3},2\}$, depending on $n \text{ mod } 3$.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#37327;&#21270;&#26031;&#22374;&#20811;&#20271;&#26684;&#22343;&#34913;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#30465;&#26679;&#26412;&#37327;&#30340;&#22312;&#32447;&#21644;&#31163;&#32447;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#25512;&#26029;&#36861;&#38543;&#32773;&#30340;&#34892;&#21160;&#26469;&#23398;&#20064;&#37327;&#21270;&#21709;&#24212;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2307.14085</link><description>&lt;p&gt;
&#34892;&#21160;&#32988;&#20110;&#35328;&#36766;&#65306;&#35777;&#26126;&#20102;&#20174;&#31574;&#30053;&#21453;&#39304;&#20013;&#30465;&#26679;&#26412;&#37327;&#30340;&#37327;&#21270;&#26031;&#22374;&#20811;&#20271;&#26684;&#22343;&#34913;&#30340;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Actions Speak What You Want: Provably Sample-Efficient Reinforcement Learning of the Quantal Stackelberg Equilibrium from Strategic Feedbacks. (arXiv:2307.14085v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14085
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#37327;&#21270;&#26031;&#22374;&#20811;&#20271;&#26684;&#22343;&#34913;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#30465;&#26679;&#26412;&#37327;&#30340;&#22312;&#32447;&#21644;&#31163;&#32447;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#25512;&#26029;&#36861;&#38543;&#32773;&#30340;&#34892;&#21160;&#26469;&#23398;&#20064;&#37327;&#21270;&#21709;&#24212;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20855;&#26377;&#39046;&#23548;&#32773;-&#36861;&#38543;&#32773;&#32467;&#26500;&#30340;&#24773;&#22659;&#39532;&#23572;&#31185;&#22827;&#21338;&#24328;&#20013;&#23398;&#20064;&#37327;&#21270;&#26031;&#22374;&#20811;&#20271;&#26684;&#22343;&#34913;&#65288;QSE&#65289;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#12290;&#22312;&#28216;&#25103;&#24320;&#22987;&#26102;&#65292;&#39046;&#23548;&#32773;&#23459;&#24067;&#22905;&#30340;&#31574;&#30053;&#24182;&#25215;&#35834;&#25191;&#34892;&#12290;&#36861;&#38543;&#32773;&#35266;&#23519;&#39046;&#23548;&#32773;&#30340;&#31574;&#30053;&#65292;&#28982;&#21518;&#37319;&#21462;&#37327;&#21270;&#21709;&#24212;&#31574;&#30053;&#65292;&#36890;&#36807;&#35299;&#20915;&#30001;&#39046;&#23548;&#32773;&#31574;&#30053;&#24341;&#21457;&#30340;&#29109;&#27491;&#21017;&#21270;&#31574;&#30053;&#20248;&#21270;&#38382;&#39064;&#26469;&#30830;&#23450;&#12290;&#39046;&#23548;&#32773;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#19982;&#36861;&#38543;&#32773;&#30340;&#20132;&#20114;&#24182;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#65292;&#25214;&#21040;&#33258;&#24049;&#30340;&#26368;&#20248;&#31574;&#30053;&#65292;&#20174;&#32780;&#33719;&#24471;&#26368;&#20248;&#30340;&#39044;&#26399;&#24635;&#22238;&#25253;&#12290;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#26159;&#39046;&#23548;&#32773;&#26080;&#27861;&#35266;&#23519;&#21040;&#36861;&#38543;&#32773;&#30340;&#22870;&#21169;&#65292;&#24182;&#19988;&#38656;&#35201;&#20174;&#36861;&#38543;&#32773;&#23545;&#25239;&#39046;&#23548;&#32773;&#31574;&#30053;&#30340;&#34892;&#21160;&#20013;&#25512;&#26029;&#20986;&#36861;&#38543;&#32773;&#30340;&#37327;&#21270;&#21709;&#24212;&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;&#20989;&#25968;&#36924;&#36817;&#30340;&#32972;&#26223;&#19979;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#22312;&#32447;&#21644;&#31163;&#32447;&#35774;&#32622;&#30340;&#26679;&#26412;&#25928;&#29575;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22522;&#20110;&#65288;i&#65289;&#36890;&#36807;&#26368;&#22823;&#20284;&#28982;&#23398;&#20064;&#37327;&#21270;&#21709;&#24212;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
We study reinforcement learning (RL) for learning a Quantal Stackelberg Equilibrium (QSE) in an episodic Markov game with a leader-follower structure. In specific, at the outset of the game, the leader announces her policy to the follower and commits to it. The follower observes the leader's policy and, in turn, adopts a quantal response policy by solving an entropy-regularized policy optimization problem induced by leader's policy. The goal of the leader is to find her optimal policy, which yields the optimal expected total return, by interacting with the follower and learning from data. A key challenge of this problem is that the leader cannot observe the follower's reward, and needs to infer the follower's quantal response model from his actions against leader's policies. We propose sample-efficient algorithms for both the online and offline settings, in the context of function approximation. Our algorithms are based on (i) learning the quantal response model via maximum likelihood 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#25299;&#25169;&#27491;&#21017;&#21270;&#30340;&#22810;&#23454;&#20363;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#32597;&#35265;&#36139;&#34880;&#30142;&#30149;&#30340;&#32418;&#32454;&#32990;&#20998;&#31867;&#12290;&#36890;&#36807;&#20174;&#21333;&#20010;&#32418;&#32454;&#32990;&#22270;&#20687;&#20013;&#25552;&#21462;&#22810;&#23610;&#24230;&#30340;&#25299;&#25169;&#29305;&#24449;&#26469;&#36827;&#34892;&#27169;&#22411;&#27491;&#21017;&#21270;&#65292;&#20197;&#20445;&#25345;&#25968;&#25454;&#30340;&#29305;&#24449;&#25299;&#25169;&#23646;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#26159;&#26377;&#25928;&#30340;&#12290;</title><link>http://arxiv.org/abs/2307.14025</link><description>&lt;p&gt;
&#22522;&#20110;&#25299;&#25169;&#27491;&#21017;&#21270;&#30340;&#22810;&#23454;&#20363;&#23398;&#20064;&#29992;&#20110;&#32418;&#32454;&#32990;&#30142;&#30149;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Topologically-Regularized Multiple Instance Learning for Red Blood Cell Disease Classification. (arXiv:2307.14025v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14025
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#25299;&#25169;&#27491;&#21017;&#21270;&#30340;&#22810;&#23454;&#20363;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#32597;&#35265;&#36139;&#34880;&#30142;&#30149;&#30340;&#32418;&#32454;&#32990;&#20998;&#31867;&#12290;&#36890;&#36807;&#20174;&#21333;&#20010;&#32418;&#32454;&#32990;&#22270;&#20687;&#20013;&#25552;&#21462;&#22810;&#23610;&#24230;&#30340;&#25299;&#25169;&#29305;&#24449;&#26469;&#36827;&#34892;&#27169;&#22411;&#27491;&#21017;&#21270;&#65292;&#20197;&#20445;&#25345;&#25968;&#25454;&#30340;&#29305;&#24449;&#25299;&#25169;&#23646;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#26159;&#26377;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#26174;&#24494;&#22270;&#20687;&#35786;&#26029;&#32597;&#35265;&#30340;&#36139;&#34880;&#30142;&#30149;&#23545;&#20110;&#29087;&#32451;&#30340;&#19987;&#23478;&#21644;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#26469;&#35828;&#37117;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#30001;&#20110;&#22312;&#21333;&#20010;&#34880;&#26679;&#20013;&#26377;&#25968;&#21315;&#20010;&#19982;&#30142;&#30149;&#30456;&#20851;&#30340;&#32454;&#32990;&#65292;&#36825;&#26500;&#25104;&#20102;&#19968;&#20010;&#22797;&#26434;&#30340;&#22810;&#23454;&#20363;&#23398;&#20064;&#65288;MIL&#65289;&#38382;&#39064;&#12290;&#34429;&#28982;&#32418;&#32454;&#32990;&#30340;&#31354;&#38388;&#37051;&#22495;&#26412;&#36523;&#24182;&#19981;&#37325;&#35201;&#65292;&#20294;&#25972;&#20010;&#34880;&#26679;&#30340;&#25299;&#25169;&#32467;&#26500;&#65292;&#21363;&#25968;&#25454;&#30340;&#20960;&#20309;&#24615;&#36136;&#65292;&#21253;&#21547;&#20102;&#26377;&#30410;&#30340;&#29305;&#24449;&#65292;&#20197;&#35299;&#20915;&#20856;&#22411;&#30340;MIL&#38382;&#39064;&#65292;&#22914;&#26799;&#24230;&#28040;&#22833;&#21644;&#22312;&#26377;&#38480;&#25968;&#25454;&#19978;&#35757;&#32451;&#26102;&#30340;&#36807;&#25311;&#21512;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#25299;&#25169;&#30340;&#26041;&#27861;&#65292;&#20174;&#21333;&#20010;&#32418;&#32454;&#32990;&#22270;&#20687;&#30340;&#21253;&#20013;&#25552;&#21462;&#22810;&#23610;&#24230;&#30340;&#25299;&#25169;&#29305;&#24449;&#12290;&#36825;&#20123;&#25299;&#25169;&#29305;&#24449;&#34987;&#29992;&#26469;&#23545;&#27169;&#22411;&#36827;&#34892;&#27491;&#21017;&#21270;&#65292;&#24378;&#21046;&#20445;&#25345;&#25968;&#25454;&#30340;&#29305;&#24449;&#25299;&#25169;&#23646;&#24615;&#12290;&#22312;&#21253;&#21547;71&#20010;&#32597;&#35265;&#36139;&#34880;&#30142;&#30149;&#24739;&#32773;&#30340;&#25968;&#25454;&#38598;&#19978;&#65292;&#21253;&#25324;521&#24352;&#32418;&#32454;&#32990;&#26174;&#24494;&#22270;&#20687;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#25299;&#25169;&#27491;&#21017;&#21270;&#26159;&#19968;&#20010;&#26377;&#25928;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diagnosing rare anemia disorders using microscopic images is challenging for skilled specialists and machine-learning methods alike. Due to thousands of disease-relevant cells in a single blood sample, this constitutes a complex multiple-instance learning (MIL) problem. While the spatial neighborhood of red blood cells is not meaningful per se, the topology, i.e., the geometry of blood samples as a whole, contains informative features to remedy typical MIL issues, such as vanishing gradients and overfitting when training on limited data. We thus develop a topology-based approach that extracts multi-scale topological features from bags of single red blood cell images. The topological features are used to regularize the model, enforcing the preservation of characteristic topological properties of the data. Applied to a dataset of 71 patients suffering from rare anemia disorders with 521 microscopic images of red blood cells, our experiments show that topological regularization is an effe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#27491;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20351;&#20854;&#33021;&#22815;&#19982;&#21508;&#31181;MCMC&#26041;&#27861;&#32467;&#21512;&#65292;&#20174;&#32780;&#23454;&#29616;&#27169;&#22411;&#32452;&#21512;&#21644;&#36827;&#34892;&#26356;&#22909;&#30340;&#37319;&#26679;&#12290;</title><link>http://arxiv.org/abs/2307.14012</link><description>&lt;p&gt;
MCMC-&#20462;&#27491;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#29992;&#20110;&#27169;&#22411;&#32452;&#21512;
&lt;/p&gt;
&lt;p&gt;
MCMC-Correction of Score-Based Diffusion Models for Model Composition. (arXiv:2307.14012v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14012
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#27491;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20351;&#20854;&#33021;&#22815;&#19982;&#21508;&#31181;MCMC&#26041;&#27861;&#32467;&#21512;&#65292;&#20174;&#32780;&#23454;&#29616;&#27169;&#22411;&#32452;&#21512;&#21644;&#36827;&#34892;&#26356;&#22909;&#30340;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#21487;&#20197;&#29992;&#24471;&#20998;&#25110;&#33021;&#37327;&#20989;&#25968;&#26469;&#21442;&#25968;&#21270;&#12290;&#33021;&#37327;&#21442;&#25968;&#21270;&#20855;&#26377;&#26356;&#22909;&#30340;&#29702;&#35770;&#29305;&#24615;&#65292;&#20027;&#35201;&#26159;&#23427;&#21487;&#20197;&#36890;&#36807;&#22312;&#25552;&#35758;&#26679;&#26412;&#20013;&#24635;&#33021;&#37327;&#30340;&#21464;&#21270;&#22522;&#20110;Metropolis-Hastings&#20462;&#27491;&#27493;&#39588;&#26469;&#36827;&#34892;&#25193;&#23637;&#37319;&#26679;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#23427;&#20284;&#20046;&#20135;&#29983;&#20102;&#31245;&#24494;&#36739;&#24046;&#30340;&#24615;&#33021;&#65292;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#30001;&#20110;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#26222;&#36941;&#27969;&#34892;&#65292;&#29616;&#26377;&#30340;&#39044;&#35757;&#32451;&#33021;&#37327;&#21442;&#25968;&#21270;&#27169;&#22411;&#30340;&#21487;&#29992;&#24615;&#21463;&#21040;&#38480;&#21046;&#12290;&#36825;&#31181;&#38480;&#21046;&#21066;&#24369;&#20102;&#27169;&#22411;&#32452;&#21512;&#30340;&#30446;&#30340;&#65292;&#21363;&#23558;&#39044;&#35757;&#32451;&#27169;&#22411;&#32452;&#21512;&#36215;&#26469;&#20174;&#26032;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#30340;&#25552;&#35758;&#24314;&#35758;&#20445;&#30041;&#24471;&#20998;&#21442;&#25968;&#21270;&#65292;&#32780;&#26159;&#36890;&#36807;&#23545;&#24471;&#20998;&#20989;&#25968;&#36827;&#34892;&#32447;&#31215;&#20998;&#26469;&#35745;&#31639;&#22522;&#20110;&#33021;&#37327;&#30340;&#25509;&#21463;&#27010;&#29575;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#37325;&#29992;&#29616;&#26377;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#24182;&#23558;&#21453;&#21521;&#36807;&#31243;&#19982;&#21508;&#31181;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#65288;MCMC&#65289;&#26041;&#27861;&#32452;&#21512;&#36215;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models can be parameterised in terms of either a score or an energy function. The energy parameterisation has better theoretical properties, mainly that it enables an extended sampling procedure with a Metropolis--Hastings correction step, based on the change in total energy in the proposed samples. However, it seems to yield slightly worse performance, and more importantly, due to the widespread popularity of score-based diffusion, there are limited availability of off-the-shelf pre-trained energy-based ones. This limitation undermines the purpose of model composition, which aims to combine pre-trained models to sample from new distributions. Our proposal, however, suggests retaining the score parameterization and instead computing the energy-based acceptance probability through line integration of the score function. This allows us to re-use existing diffusion models and still combine the reverse process with various Markov-Chain Monte Carlo (MCMC) methods. We evaluate our 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#24515;&#34880;&#31649;&#27169;&#22411;&#30340;&#36870;&#38382;&#39064;&#20316;&#20026;&#32479;&#35745;&#25512;&#29702;&#36827;&#34892;&#35299;&#20915;&#65292;&#22312;&#20307;&#22806;&#36827;&#34892;&#20102;&#20116;&#20010;&#29983;&#29289;&#26631;&#35760;&#29289;&#30340;&#19981;&#30830;&#23450;&#24615;&#20998;&#26512;&#65292;&#23637;&#31034;&#20102;&#27169;&#25311;&#25512;&#29702;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.13918</link><description>&lt;p&gt;
&#22522;&#20110;&#27169;&#25311;&#30340;&#25512;&#29702;&#29992;&#20110;&#24515;&#34880;&#31649;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Simulation-based Inference for Cardiovascular Models. (arXiv:2307.13918v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13918
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#24515;&#34880;&#31649;&#27169;&#22411;&#30340;&#36870;&#38382;&#39064;&#20316;&#20026;&#32479;&#35745;&#25512;&#29702;&#36827;&#34892;&#35299;&#20915;&#65292;&#22312;&#20307;&#22806;&#36827;&#34892;&#20102;&#20116;&#20010;&#29983;&#29289;&#26631;&#35760;&#29289;&#30340;&#19981;&#30830;&#23450;&#24615;&#20998;&#26512;&#65292;&#23637;&#31034;&#20102;&#27169;&#25311;&#25512;&#29702;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#30340;&#20960;&#21313;&#24180;&#20013;&#65292;&#34880;&#27969;&#21160;&#21147;&#23398;&#27169;&#25311;&#22120;&#19981;&#26029;&#21457;&#23637;&#65292;&#24050;&#25104;&#20026;&#30740;&#31350;&#20307;&#22806;&#24515;&#34880;&#31649;&#31995;&#32479;&#30340;&#39318;&#36873;&#24037;&#20855;&#12290;&#34429;&#28982;&#36825;&#26679;&#30340;&#24037;&#20855;&#36890;&#24120;&#29992;&#20110;&#20174;&#29983;&#29702;&#21442;&#25968;&#27169;&#25311;&#20840;&#36523;&#34880;&#27969;&#21160;&#21147;&#23398;&#65292;&#20294;&#35299;&#20915;&#23558;&#27874;&#24418;&#26144;&#23556;&#22238;&#21512;&#29702;&#30340;&#29983;&#29702;&#21442;&#25968;&#30340;&#36870;&#38382;&#39064;&#20173;&#28982;&#26377;&#24456;&#22823;&#30340;&#28508;&#21147;&#21644;&#25361;&#25112;&#12290;&#21463;&#27169;&#25311;&#25512;&#29702;&#65288;SBI&#65289;&#30340;&#36827;&#23637;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#36870;&#38382;&#39064;&#20316;&#20026;&#32479;&#35745;&#25512;&#29702;&#26469;&#22788;&#29702;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#19981;&#21516;&#65292;SBI&#20026;&#24863;&#20852;&#36259;&#30340;&#21442;&#25968;&#25552;&#20379;&#20102;&#21518;&#39564;&#20998;&#24067;&#65292;&#25552;&#20379;&#20102;&#20851;&#20110;&#20010;&#20307;&#27979;&#37327;&#30340;&#19981;&#30830;&#23450;&#24615;&#30340;&#22810;&#32500;&#34920;&#31034;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#27604;&#20960;&#31181;&#27979;&#37327;&#27169;&#24577;&#26469;&#23637;&#31034;&#36825;&#31181;&#33021;&#21147;&#65292;&#36827;&#34892;&#20102;&#20116;&#20010;&#20020;&#24202;&#24863;&#20852;&#36259;&#30340;&#29983;&#29289;&#26631;&#24535;&#29289;&#30340;&#20307;&#22806;&#19981;&#30830;&#23450;&#24615;&#20998;&#26512;&#12290;&#38500;&#20102;&#30830;&#35748;&#24050;&#30693;&#20107;&#23454;&#65292;&#27604;&#22914;&#20272;&#35745;&#24515;&#29575;&#30340;&#21487;&#34892;&#24615;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#36824;&#31361;&#20986;&#20102;&#8230;
&lt;/p&gt;
&lt;p&gt;
Over the past decades, hemodynamics simulators have steadily evolved and have become tools of choice for studying cardiovascular systems in-silico. While such tools are routinely used to simulate whole-body hemodynamics from physiological parameters, solving the corresponding inverse problem of mapping waveforms back to plausible physiological parameters remains both promising and challenging. Motivated by advances in simulation-based inference (SBI), we cast this inverse problem as statistical inference. In contrast to alternative approaches, SBI provides \textit{posterior distributions} for the parameters of interest, providing a \textit{multi-dimensional} representation of uncertainty for \textit{individual} measurements. We showcase this ability by performing an in-silico uncertainty analysis of five biomarkers of clinical interest comparing several measurement modalities. Beyond the corroboration of known facts, such as the feasibility of estimating heart rate, our study highlight
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#22312;&#39044;&#27979;&#19978;&#19979;&#25991;&#20013;&#30340;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#23558;&#32463;&#20856;&#32479;&#35745;&#23398;&#20013;&#30340;&#27979;&#37327;&#35823;&#24046;&#27169;&#22411;&#25512;&#24191;&#21040;&#22312;&#32447;&#20915;&#31574;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#20855;&#26377;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#22312;&#32447;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.13916</link><description>&lt;p&gt;
&#22312;&#39044;&#27979;&#19978;&#19979;&#25991;&#20013;&#30340;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Online learning in bandits with predicted context. (arXiv:2307.13916v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13916
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#22312;&#39044;&#27979;&#19978;&#19979;&#25991;&#20013;&#30340;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#23558;&#32463;&#20856;&#32479;&#35745;&#23398;&#20013;&#30340;&#27979;&#37327;&#35823;&#24046;&#27169;&#22411;&#25512;&#24191;&#21040;&#22312;&#32447;&#20915;&#31574;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#20855;&#26377;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#22312;&#32447;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#27599;&#20010;&#26102;&#21051;&#65292;&#20195;&#29702;&#21482;&#33021;&#35775;&#38382;&#21040;&#19978;&#19979;&#25991;&#30340;&#19968;&#20010;&#24102;&#22122;&#22768;&#30340;&#29256;&#26412;&#20197;&#21450;&#35823;&#24046;&#26041;&#24046;&#65288;&#25110;&#32773;&#36825;&#20010;&#26041;&#24046;&#30340;&#19968;&#20010;&#20272;&#35745;&#65289;&#12290;&#36825;&#19968;&#35774;&#32622;&#21463;&#21040;&#20102;&#35768;&#22810;&#24212;&#29992;&#30340;&#21551;&#21457;&#65292;&#22312;&#36825;&#20123;&#24212;&#29992;&#20013;&#65292;&#29992;&#20110;&#20915;&#31574;&#30340;&#30495;&#23454;&#19978;&#19979;&#25991;&#26159;&#19981;&#21487;&#35266;&#27979;&#30340;&#65292;&#32780;&#21482;&#26377;&#19968;&#20010;&#30001;&#21487;&#33021;&#22797;&#26434;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#39044;&#27979;&#20986;&#30340;&#19978;&#19979;&#25991;&#12290;&#24403;&#19978;&#19979;&#25991;&#35823;&#24046;&#26159;&#38750;&#34928;&#20943;&#30340;&#26102;&#20505;&#65292;&#32463;&#20856;&#30340;bandit&#31639;&#27861;&#26080;&#27861;&#36798;&#21040;&#27425;&#32447;&#24615;&#30340;&#21518;&#24724;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#36825;&#19968;&#35774;&#32622;&#19979;&#65292;&#31532;&#19968;&#20010;&#20855;&#26377;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#24182;&#19982;&#36866;&#24403;&#30340;&#22522;&#20934;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#20851;&#38190;&#30340;&#24605;&#24819;&#26159;&#23558;&#32463;&#20856;&#32479;&#35745;&#23398;&#20013;&#30340;&#27979;&#37327;&#35823;&#24046;&#27169;&#22411;&#25512;&#24191;&#21040;&#22312;&#32447;&#20915;&#31574;&#35774;&#32622;&#20013;&#65292;&#36825;&#26159;&#38750;&#24179;&#20961;&#30340;&#65292;&#22240;&#20026;&#31574;&#30053;&#20381;&#36182;&#20110;&#26377;&#22122;&#22768;&#30340;&#19978;&#19979;&#25991;&#35266;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the contextual bandit problem where at each time, the agent only has access to a noisy version of the context and the error variance (or an estimator of this variance). This setting is motivated by a wide range of applications where the true context for decision-making is unobserved, and only a prediction of the context by a potentially complex machine learning algorithm is available. When the context error is non-diminishing, classical bandit algorithms fail to achieve sublinear regret. We propose the first online algorithm in this setting with sublinear regret compared to the appropriate benchmark. The key idea is to extend the measurement error model in classical statistics to the online decision-making setting, which is nontrivial due to the policy being dependent on the noisy context observations.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#20855;&#26377;&#34987;&#31713;&#25913;&#30340;&#20108;&#36827;&#21046;&#20449;&#21495;&#30340;Lipschitz&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#33104;&#36133;&#40065;&#26834;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#22312;&#19981;&#21516;&#25439;&#22833;&#20989;&#25968;&#19979;&#23454;&#29616;&#20102;&#19981;&#21516;&#31243;&#24230;&#30340;&#21518;&#24724;&#12290;</title><link>http://arxiv.org/abs/2307.13903</link><description>&lt;p&gt;
&#33104;&#36133;&#40065;&#26834;&#30340;Lipschitz&#19978;&#19979;&#25991;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
Corruption-Robust Lipschitz Contextual Search. (arXiv:2307.13903v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13903
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#20855;&#26377;&#34987;&#31713;&#25913;&#30340;&#20108;&#36827;&#21046;&#20449;&#21495;&#30340;Lipschitz&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#33104;&#36133;&#40065;&#26834;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#22312;&#19981;&#21516;&#25439;&#22833;&#20989;&#25968;&#19979;&#23454;&#29616;&#20102;&#19981;&#21516;&#31243;&#24230;&#30340;&#21518;&#24724;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#30740;&#31350;&#20102;&#23398;&#20064;&#20855;&#26377;&#34987;&#31713;&#25913;&#30340;&#20108;&#36827;&#21046;&#20449;&#21495;&#30340;Lipschitz&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#23398;&#20064;&#32773;&#35797;&#22270;&#23398;&#20064;&#19968;&#20010;&#30001;&#23545;&#25163;&#36873;&#25321;&#30340;Lipschitz&#20989;&#25968;$f$&#12290;&#22312;&#27599;&#19968;&#36718;&#20013;&#65292;&#23545;&#25163;&#22312;&#36755;&#20837;&#31354;&#38388;&#20013;&#36873;&#25321;&#19968;&#20010;&#19978;&#19979;&#25991;&#21521;&#37327;$x_t$&#65292;&#23398;&#20064;&#32773;&#23545;&#30495;&#23454;&#20989;&#25968;&#20540;$f(x_t)$&#36827;&#34892;&#29468;&#27979;&#65292;&#24182;&#25509;&#25910;&#19968;&#20010;&#25351;&#31034;&#29468;&#27979;&#26159;&#39640;&#36824;&#26159;&#20302;&#30340;&#20108;&#36827;&#21046;&#20449;&#21495;&#12290;&#22312;&#24635;&#20849;$C$&#36718;&#20013;&#65292;&#20449;&#21495;&#21487;&#33021;&#34987;&#31713;&#25913;&#65292;&#20294;&#23398;&#20064;&#32773;&#19981;&#30693;&#36947;$C$&#30340;&#20540;&#12290;&#23398;&#20064;&#32773;&#30340;&#30446;&#26631;&#26159;&#36896;&#25104;&#23567;&#30340;&#32047;&#31215;&#25439;&#22833;&#12290;&#25105;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#28982;&#32780;&#24378;&#22823;&#30340;&#25216;&#26415;&#39564;&#35777;&#65292;&#23545;&#35774;&#35745;&#33104;&#36133;&#40065;&#26834;&#31639;&#27861;&#38750;&#24120;&#26377;&#29992;&#12290;&#25105;&#35774;&#35745;&#20102;&#19968;&#20123;&#31639;&#27861;&#65288;&#23558;Lipschitz&#21442;&#25968;$L$&#35270;&#20026;&#24120;&#25968;&#65289;&#65306;&#23545;&#20110;&#23545;&#31216;&#25439;&#22833;&#65292;&#23398;&#20064;&#32773;&#22312;$d=1$&#26102;&#36798;&#21040;&#21518;&#24724;$O(C\log T)$&#65292;&#22312;$d&gt;1$&#26102;&#36798;&#21040;&#21518;&#24724;$O_d(C\log T + T^{(d-1)/d})$&#65307;&#23545;&#20110;&#35745;&#20215;&#25439;&#22833;&#65292;&#23398;&#20064;&#32773;&#22312;$d/(d+1)$&#26102;&#36798;&#21040;&#21518;&#24724;$\widetilde{O}(T^{d/(d+1)} + C\cdot T^{1/(d+1)})$&#12290;
&lt;/p&gt;
&lt;p&gt;
I study the problem of learning a Lipschitz function with corrupted binary signals. The learner tries to learn a Lipschitz function $f$ that the adversary chooses. In each round, the adversary selects a context vector $x_t$ in the input space, and the learner makes a guess to the true function value $f(x_t)$ and receives a binary signal indicating whether the guess was high or low. In a total of $C$ rounds, the signal may be corrupted, though the value of $C$ is unknown to the learner. The learner's goal is to incur a small cumulative loss. I present a natural yet powerful technique sanity check, which proves useful in designing corruption-robust algorithms. I design algorithms which (treating the Lipschitz parameter $L$ as constant): for the symmetric loss, the learner achieves regret $O(C\log T)$ with $d = 1$ and $O_d(C\log T + T^{(d-1)/d})$ with $d &gt; 1$; for the pricing loss the learner achieves regret $\widetilde{O} (T^{d/(d+1)} + C\cdot T^{1/(d+1)})$.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#35266;&#27979;&#30740;&#31350;&#30340;&#26041;&#27861;&#65292;&#23558;&#22240;&#26524;&#20272;&#35745;&#27867;&#21270;&#21040;&#20219;&#24847;&#32500;&#24230;&#25110;&#21487;&#27979;&#31354;&#38388;&#30340;&#32467;&#26524;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#21517;&#20041;&#21464;&#37327;&#30340;&#22240;&#26524;&#20559;&#24046;&#27979;&#35797;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#30456;&#27604;&#29616;&#26377;&#31574;&#30053;&#22312;&#26377;&#38480;&#26679;&#26412;&#26377;&#25928;&#24615;&#21644;&#21151;&#29575;&#26041;&#38754;&#26377;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2307.13868</link><description>&lt;p&gt;
&#20174;&#39640;&#32500;&#35266;&#27979;&#30740;&#31350;&#20013;&#23398;&#20064;&#21464;&#24322;&#28304;
&lt;/p&gt;
&lt;p&gt;
Learning sources of variability from high-dimensional observational studies. (arXiv:2307.13868v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13868
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#35266;&#27979;&#30740;&#31350;&#30340;&#26041;&#27861;&#65292;&#23558;&#22240;&#26524;&#20272;&#35745;&#27867;&#21270;&#21040;&#20219;&#24847;&#32500;&#24230;&#25110;&#21487;&#27979;&#31354;&#38388;&#30340;&#32467;&#26524;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#21517;&#20041;&#21464;&#37327;&#30340;&#22240;&#26524;&#20559;&#24046;&#27979;&#35797;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#30456;&#27604;&#29616;&#26377;&#31574;&#30053;&#22312;&#26377;&#38480;&#26679;&#26412;&#26377;&#25928;&#24615;&#21644;&#21151;&#29575;&#26041;&#38754;&#26377;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#25512;&#26029;&#30740;&#31350;&#26159;&#21542;&#23384;&#22312;&#19968;&#20010;&#21464;&#37327;&#24433;&#21709;&#35266;&#27979;&#32467;&#26524;&#12290;&#36890;&#36807;&#35832;&#22914;&#8220;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#8221;&#31561;&#37327;&#21270;&#25351;&#26631;&#65292;&#36825;&#19968;&#33539;&#24335;&#22312;&#35768;&#22810;&#29983;&#29289;&#39046;&#22495;&#20013;&#34987;&#37319;&#29992;&#65292;&#20174;&#30123;&#33495;&#21644;&#33647;&#29289;&#24320;&#21457;&#21040;&#25919;&#31574;&#24178;&#39044;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#22823;&#22810;&#25968;&#26041;&#27861;&#36890;&#24120;&#20165;&#38480;&#20110;&#21333;&#21464;&#37327;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#23558;&#22240;&#26524;&#20272;&#35745;&#27867;&#21270;&#21040;&#20219;&#24847;&#32500;&#24230;&#25110;&#21487;&#27979;&#31354;&#38388;&#30340;&#32467;&#26524;&#65292;&#24182;&#23558;&#20256;&#32479;&#30340;&#22240;&#26524;&#20272;&#35745;&#24418;&#24335;&#21270;&#20026;&#21517;&#20041;&#21464;&#37327;&#30340;&#22240;&#26524;&#20559;&#24046;&#27979;&#35797;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#25216;&#26415;&#26469;&#35843;&#25972;&#19968;&#33268;&#24615;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20123;&#27979;&#35797;&#26159;&#19968;&#33268;&#24615;&#22240;&#26524;&#20559;&#24046;&#27979;&#35797;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#19982;&#29616;&#26377;&#31574;&#30053;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;Causal CDcorr&#22312;&#26377;&#38480;&#26679;&#26412;&#26377;&#25928;&#24615;&#21644;&#21151;&#29575;&#26041;&#38754;&#22343;&#26377;&#25913;&#36827;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#37117;&#26159;&#24320;&#28304;&#30340;&#65292;&#21487;&#22312;github.com/ebridge2/cdcorr&#19978;&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal inference studies whether the presence of a variable influences an observed outcome. As measured by quantities such as the "average treatment effect," this paradigm is employed across numerous biological fields, from vaccine and drug development to policy interventions. Unfortunately, the majority of these methods are often limited to univariate outcomes. Our work generalizes causal estimands to outcomes with any number of dimensions or any measurable space, and formulates traditional causal estimands for nominal variables as causal discrepancy tests. We propose a simple technique for adjusting universally consistent conditional independence tests and prove that these tests are universally consistent causal discrepancy tests. Numerical experiments illustrate that our method, Causal CDcorr, leads to improvements in both finite sample validity and power when compared to existing strategies. Our methods are all open source and available at github.com/ebridge2/cdcorr.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#22312;&#23384;&#22312;&#27169;&#22411;EMA&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20248;&#21270;&#30340;&#32553;&#25918;&#35268;&#21017;&#65292;&#20197;&#20445;&#25345;&#35757;&#32451;&#21160;&#24577;&#30340;&#19968;&#33268;&#24615;&#12290;&#36825;&#23545;&#20110;&#23454;&#38469;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#26435;&#34913;&#25209;&#37327;&#22823;&#23567;&#21644;&#22681;&#38047;&#26102;&#38388;&#38750;&#24120;&#37325;&#35201;&#12290;&#27169;&#22411;EMA&#33021;&#22815;&#25552;&#39640;&#27169;&#22411;&#30340;&#24615;&#33021;&#20197;&#21450;&#31283;&#23450;&#35757;&#32451;&#36807;&#31243;&#65292;&#24182;&#20026;&#33258;&#30417;&#30563;&#23398;&#20064;&#25552;&#20379;&#23398;&#20064;&#20449;&#21495;&#12290;</title><link>http://arxiv.org/abs/2307.13813</link><description>&lt;p&gt;
&#22914;&#20309;&#25193;&#23637;&#24744;&#30340;EMA&#65288;arXiv:2307.13813v1 [stat.ML]&#65289;
&lt;/p&gt;
&lt;p&gt;
How to Scale Your EMA. (arXiv:2307.13813v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13813
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#22312;&#23384;&#22312;&#27169;&#22411;EMA&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20248;&#21270;&#30340;&#32553;&#25918;&#35268;&#21017;&#65292;&#20197;&#20445;&#25345;&#35757;&#32451;&#21160;&#24577;&#30340;&#19968;&#33268;&#24615;&#12290;&#36825;&#23545;&#20110;&#23454;&#38469;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#26435;&#34913;&#25209;&#37327;&#22823;&#23567;&#21644;&#22681;&#38047;&#26102;&#38388;&#38750;&#24120;&#37325;&#35201;&#12290;&#27169;&#22411;EMA&#33021;&#22815;&#25552;&#39640;&#27169;&#22411;&#30340;&#24615;&#33021;&#20197;&#21450;&#31283;&#23450;&#35757;&#32451;&#36807;&#31243;&#65292;&#24182;&#20026;&#33258;&#30417;&#30563;&#23398;&#20064;&#25552;&#20379;&#23398;&#20064;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#20445;&#25345;&#35757;&#32451;&#21160;&#24577;&#22312;&#25209;&#37327;&#22823;&#23567;&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#26159;&#19968;&#31181;&#37325;&#35201;&#24037;&#20855;&#65292;&#23427;&#33021;&#22815;&#22312;&#25209;&#37327;&#22823;&#23567;&#21644;&#22681;&#38047;&#26102;&#38388;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#12290;&#36825;&#31181;&#26435;&#34913;&#36890;&#24120;&#36890;&#36807;&#19968;&#20010;&#32553;&#25918;&#35268;&#21017;&#26469;&#23454;&#29616;&#65292;&#20363;&#22914;&#65292;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#65292;&#24212;&#35813;&#23558;&#23398;&#20064;&#29575;&#19982;&#25209;&#37327;&#22823;&#23567;&#21576;&#32447;&#24615;&#20851;&#31995;&#12290;&#21478;&#19968;&#20010;&#23454;&#38469;&#26426;&#22120;&#23398;&#20064;&#30340;&#37325;&#35201;&#24037;&#20855;&#26159;&#27169;&#22411;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#65288;EMA&#65289;&#65292;&#23427;&#26159;&#19968;&#20010;&#19981;&#25509;&#25910;&#26799;&#24230;&#20449;&#24687;&#30340;&#27169;&#22411;&#21103;&#26412;&#65292;&#32780;&#26159;&#20197;&#19968;&#23450;&#30340;&#21160;&#37327;&#36319;&#38543;&#20854;&#30446;&#26631;&#27169;&#22411;&#12290;&#36825;&#20010;&#27169;&#22411;EMA&#21487;&#20197;&#25552;&#39640;&#30417;&#30563;&#23398;&#20064;&#30340;&#31283;&#20581;&#24615;&#21644;&#27867;&#21270;&#24615;&#33021;&#65292;&#31283;&#23450;&#20266;&#26631;&#35760;&#65292;&#20026;&#33258;&#30417;&#30563;&#23398;&#20064;&#25552;&#20379;&#23398;&#20064;&#20449;&#21495;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#23558;&#27169;&#22411;EMA&#19982;&#20248;&#21270;&#20998;&#24320;&#22788;&#29702;&#65292;&#23548;&#33268;&#25209;&#37327;&#22823;&#23567;&#20043;&#38388;&#23384;&#22312;&#19981;&#21516;&#30340;&#35757;&#32451;&#21160;&#24577;&#21644;&#36739;&#20302;&#30340;&#27169;&#22411;&#24615;&#33021;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#22312;&#23384;&#22312;&#27169;&#22411;EMA&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20248;&#21270;&#30340;&#32553;&#25918;&#35268;&#21017;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Preserving training dynamics across batch sizes is an important tool for practical machine learning as it enables the trade-off between batch size and wall-clock time. This trade-off is typically enabled by a scaling rule, for example, in stochastic gradient descent, one should scale the learning rate linearly with the batch size. Another important tool for practical machine learning is the model Exponential Moving Average (EMA), which is a model copy that does not receive gradient information, but instead follows its target model with some momentum. This model EMA can improve the robustness and generalization properties of supervised learning, stabilize pseudo-labeling, and provide a learning signal for Self-Supervised Learning (SSL). Prior works have treated the model EMA separately from optimization, leading to different training dynamics across batch sizes and lower model performance. In this work, we provide a scaling rule for optimization in the presence of model EMAs and demonst
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28304;&#26465;&#20214;&#21452;&#31283;&#20581;&#25512;&#26029;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#32447;&#24615;&#36870;&#38382;&#39064;&#35299;&#30340;&#32447;&#24615;&#20989;&#25968;&#21442;&#25968;&#65292;&#26080;&#38656;&#30693;&#36947;&#21738;&#20010;&#36870;&#38382;&#39064;&#26356;&#33391;&#22909;&#65292;&#35813;&#26041;&#27861;&#33021;&#30830;&#20445;&#23545;&#24863;&#20852;&#36259;&#30340;&#21442;&#25968;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#36845;&#20195;Tikhonov&#27491;&#21017;&#21270;&#23545;&#25239;&#20272;&#35745;&#22120;&#30340;&#26032;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2307.13793</link><description>&lt;p&gt;
&#36870;&#38382;&#39064;&#20989;&#25968;&#30340;&#28304;&#26465;&#20214;&#21452;&#31283;&#20581;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Source Condition Double Robust Inference on Functionals of Inverse Problems. (arXiv:2307.13793v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13793
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28304;&#26465;&#20214;&#21452;&#31283;&#20581;&#25512;&#26029;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#32447;&#24615;&#36870;&#38382;&#39064;&#35299;&#30340;&#32447;&#24615;&#20989;&#25968;&#21442;&#25968;&#65292;&#26080;&#38656;&#30693;&#36947;&#21738;&#20010;&#36870;&#38382;&#39064;&#26356;&#33391;&#22909;&#65292;&#35813;&#26041;&#27861;&#33021;&#30830;&#20445;&#23545;&#24863;&#20852;&#36259;&#30340;&#21442;&#25968;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#36845;&#20195;Tikhonov&#27491;&#21017;&#21270;&#23545;&#25239;&#20272;&#35745;&#22120;&#30340;&#26032;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#32447;&#24615;&#36870;&#38382;&#39064;&#35299;&#30340;&#32447;&#24615;&#20989;&#25968;&#21442;&#25968;&#30340;&#20272;&#35745;&#12290;&#20219;&#20309;&#36825;&#26679;&#30340;&#21442;&#25968;&#37117;&#26377;&#19968;&#20010;&#21452;&#31283;&#20581;&#34920;&#31034;&#65292;&#35813;&#34920;&#31034;&#20381;&#36182;&#20110;&#23545;&#20598;&#32447;&#24615;&#36870;&#38382;&#39064;&#30340;&#35299;&#65292;&#20854;&#20013;&#23545;&#20598;&#35299;&#21487;&#20197;&#34987;&#35270;&#20026;&#36870;&#20542;&#21521;&#20989;&#25968;&#30340;&#25512;&#24191;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#28304;&#26465;&#20214;&#21452;&#31283;&#20581;&#25512;&#26029;&#26041;&#27861;&#65292;&#21482;&#35201;&#21407;&#22987;&#25110;&#23545;&#20598;&#36870;&#38382;&#39064;&#36275;&#22815;&#33391;&#22909;&#65292;&#26080;&#38656;&#30693;&#36947;&#21738;&#20010;&#36870;&#38382;&#39064;&#26356;&#33391;&#22909;&#65292;&#23601;&#33021;&#30830;&#20445;&#23545;&#24863;&#20852;&#36259;&#30340;&#21442;&#25968;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26159;&#36890;&#36807;&#23545;&#32447;&#24615;&#36870;&#38382;&#39064;&#30340;&#36845;&#20195;Tikhonov&#27491;&#21017;&#21270;&#23545;&#25239;&#20272;&#35745;&#22120;&#22312;&#19968;&#33324;&#20551;&#35774;&#31354;&#38388;&#19978;&#30340;&#26032;&#30340;&#20445;&#35777;&#32780;&#23454;&#29616;&#30340;&#65292;&#36825;&#26159;&#19968;&#20010;&#29420;&#31435;&#21457;&#23637;&#30340;&#21033;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider estimation of parameters defined as linear functionals of solutions to linear inverse problems. Any such parameter admits a doubly robust representation that depends on the solution to a dual linear inverse problem, where the dual solution can be thought as a generalization of the inverse propensity function. We provide the first source condition double robust inference method that ensures asymptotic normality around the parameter of interest as long as either the primal or the dual inverse problem is sufficiently well-posed, without knowledge of which inverse problem is the more well-posed one. Our result is enabled by novel guarantees for iterated Tikhonov regularized adversarial estimators for linear inverse problems, over general hypothesis spaces, which are developments of independent interest.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#22522;&#20110;&#27491;&#21017;&#21270;&#23494;&#24230;&#30340; Sobolev &#33539;&#25968;&#65292;&#36890;&#36807;&#36866;&#24403;&#30340;&#21021;&#22987;&#21270;&#21644;&#20351;&#29992;&#33258;&#28982;&#26799;&#24230;&#65292;&#21487;&#20197;&#24471;&#21040;&#24615;&#33021;&#33391;&#22909;&#30340;&#35299;&#65292;&#35813;&#26041;&#27861;&#22312; Anomaly Detection benchmark &#20013;&#25490;&#21517;&#31532;&#20108;&#12290;</title><link>http://arxiv.org/abs/2307.13763</link><description>&lt;p&gt;
&#38544;&#24335;&#24402;&#19968;&#21270;&#26174;&#24335;&#27491;&#21017;&#21270;&#23494;&#24230;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Implicitly Normalized Explicitly Regularized Density Estimation. (arXiv:2307.13763v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13763
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#22522;&#20110;&#27491;&#21017;&#21270;&#23494;&#24230;&#30340; Sobolev &#33539;&#25968;&#65292;&#36890;&#36807;&#36866;&#24403;&#30340;&#21021;&#22987;&#21270;&#21644;&#20351;&#29992;&#33258;&#28982;&#26799;&#24230;&#65292;&#21487;&#20197;&#24471;&#21040;&#24615;&#33021;&#33391;&#22909;&#30340;&#35299;&#65292;&#35813;&#26041;&#27861;&#22312; Anomaly Detection benchmark &#20013;&#25490;&#21517;&#31532;&#20108;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26159;&#22522;&#20110;&#27491;&#21017;&#21270;&#23494;&#24230;&#30340; Sobolev &#33539;&#25968;&#12290;&#36825;&#31181;&#26041;&#27861;&#19982;&#26680;&#23494;&#24230;&#20272;&#35745;&#26377;&#26126;&#26174;&#24046;&#24322;&#65292;&#21487;&#20197;&#28165;&#26224;&#35299;&#37322;&#27169;&#22411;&#30340;&#20559;&#24046;&#12290;&#34429;&#28982;&#25105;&#20204;&#26080;&#27861;&#24471;&#21040;&#30456;&#20851;&#26680;&#20989;&#25968;&#30340;&#38381;&#21512;&#35299;&#26512;&#24418;&#24335;&#65292;&#20294;&#25105;&#20204;&#35777;&#26126;&#21487;&#20197;&#36890;&#36807;&#37319;&#26679;&#36827;&#34892;&#36817;&#20284;&#12290;&#20915;&#23450;&#23494;&#24230;&#30340;&#20248;&#21270;&#38382;&#39064;&#26159;&#38750;&#20984;&#30340;&#65292;&#26631;&#20934;&#30340;&#26799;&#24230;&#26041;&#27861;&#25928;&#26524;&#19981;&#22909;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#36866;&#24403;&#30340;&#21021;&#22987;&#21270;&#21644;&#20351;&#29992;&#33258;&#28982;&#26799;&#24230;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#24471;&#21040;&#24615;&#33021;&#33391;&#22909;&#30340;&#35299;&#12290;&#26368;&#21518;&#65292;&#34429;&#28982;&#35813;&#26041;&#27861;&#25552;&#20379;&#30340;&#26159;&#38750;&#24402;&#19968;&#21270;&#30340;&#23494;&#24230;&#65292;&#26080;&#27861;&#20351;&#29992;&#23545;&#25968;&#20284;&#28982;&#36827;&#34892;&#20132;&#21449;&#39564;&#35777;&#65292;&#20294;&#25105;&#20204;&#35777;&#26126;&#21487;&#20197;&#37319;&#29992;&#22522;&#20110; Fisher &#25955;&#24230;&#30340;&#20998;&#25968;&#21305;&#37197;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;&#26368;&#36817;&#30340;&#24322;&#24120;&#26816;&#27979;&#22522;&#20934;&#22871;&#20214; ADBench &#19978;&#35780;&#20272;&#20102;&#24471;&#21040;&#30340;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#23427;&#22312;&#36229;&#36807;15&#20010;&#31639;&#27861;&#20013;&#25490;&#21517;&#31532;&#20108;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new approach to non-parametric density estimation, that is based on regularizing a Sobolev norm of the density. This method is provably different from Kernel Density Estimation, and makes the bias of the model clear and interpretable. While there is no closed analytic form for the associated kernel, we show that one can approximate it using sampling. The optimization problem needed to determine the density is non-convex, and standard gradient methods do not perform well. However, we show that with an appropriate initialization and using natural gradients, one can obtain well performing solutions. Finally, while the approach provides unnormalized densities, which prevents the use of log-likelihood for cross validation, we show that one can instead adapt Fisher Divergence based Score Matching methods for this task. We evaluate the resulting method on the comprehensive recent Anomaly Detection benchmark suite, ADBench, and find that it ranks second best, among more than 15 al
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31867;&#31216;&#20026;&#27969;&#24418;&#28388;&#27874;-&#32452;&#21512;&#32593;&#32476;&#30340;&#22823;&#22411;&#27969;&#24418;&#31070;&#32463;&#32593;&#32476;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26500;&#24314;&#25968;&#25454;&#39537;&#21160;&#22270;&#30340;&#26041;&#27861;&#26469;&#23454;&#29616;&#36825;&#31181;&#32593;&#32476;&#65292;&#24182;&#25552;&#20379;&#20102;&#25910;&#25947;&#21040;&#36830;&#32493;&#26497;&#38480;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#20854;&#25910;&#25947;&#36895;&#24230;&#19981;&#20381;&#36182;&#20110;&#28388;&#27874;&#22120;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2307.04056</link><description>&lt;p&gt;
&#27969;&#24418;&#28388;&#27874;-&#32452;&#21512;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Manifold Filter-Combine Networks. (arXiv:2307.04056v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04056
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31867;&#31216;&#20026;&#27969;&#24418;&#28388;&#27874;-&#32452;&#21512;&#32593;&#32476;&#30340;&#22823;&#22411;&#27969;&#24418;&#31070;&#32463;&#32593;&#32476;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26500;&#24314;&#25968;&#25454;&#39537;&#21160;&#22270;&#30340;&#26041;&#27861;&#26469;&#23454;&#29616;&#36825;&#31181;&#32593;&#32476;&#65292;&#24182;&#25552;&#20379;&#20102;&#25910;&#25947;&#21040;&#36830;&#32493;&#26497;&#38480;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#20854;&#25910;&#25947;&#36895;&#24230;&#19981;&#20381;&#36182;&#20110;&#28388;&#27874;&#22120;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31867;&#22823;&#22411;&#27969;&#24418;&#31070;&#32463;&#32593;&#32476;(MNNs)&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#27969;&#24418;&#28388;&#27874;-&#32452;&#21512;&#32593;&#32476;&#12290;&#36825;&#20010;&#31867;&#21035;&#21253;&#25324;&#20102;Wang&#12289;Ruiz&#21644;Ribeiro&#20043;&#21069;&#30340;&#30740;&#31350;&#20013;&#32771;&#34385;&#30340;MNNs&#65292;&#27969;&#24418;&#25955;&#23556;&#21464;&#25442;(&#19968;&#31181;&#22522;&#20110;&#23567;&#27874;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;)&#65292;&#20197;&#21450;&#20854;&#20182;&#26377;&#36259;&#30340;&#20043;&#21069;&#22312;&#25991;&#29486;&#20013;&#26410;&#32771;&#34385;&#30340;&#31034;&#20363;&#65292;&#22914;Kipf&#21644;Welling&#30340;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#27969;&#24418;&#31561;&#25928;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31181;&#22522;&#20110;&#26500;&#24314;&#25968;&#25454;&#39537;&#21160;&#22270;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#27809;&#26377;&#23545;&#27969;&#24418;&#26377;&#20840;&#23616;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#36825;&#26679;&#30340;&#32593;&#32476;&#65292;&#32780;&#21482;&#33021;&#35775;&#38382;&#26377;&#38480;&#25968;&#37327;&#30340;&#26679;&#26412;&#28857;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#32593;&#32476;&#22312;&#26679;&#26412;&#28857;&#25968;&#36235;&#20110;&#26080;&#31351;&#22823;&#26102;&#33021;&#22815;&#20445;&#35777;&#25910;&#25947;&#21040;&#20854;&#36830;&#32493;&#26497;&#38480;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;(&#20027;&#35201;&#20851;&#27880;&#29305;&#23450;&#30340;MNN&#32467;&#26500;&#21644;&#22270;&#26500;&#24314;)&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#25910;&#25947;&#36895;&#24230;&#24182;&#19981;&#20381;&#36182;&#20110;&#20351;&#29992;&#30340;&#28388;&#27874;&#22120;&#25968;&#37327;&#12290;&#32780;&#19988;&#65292;&#23427;&#34920;&#29616;&#20986;&#32447;&#24615;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a large class of manifold neural networks (MNNs) which we call Manifold Filter-Combine Networks. This class includes as special cases, the MNNs considered in previous work by Wang, Ruiz, and Ribeiro, the manifold scattering transform (a wavelet-based model of neural networks), and other interesting examples not previously considered in the literature such as the manifold equivalent of Kipf and Welling's graph convolutional network. We then consider a method, based on building a data-driven graph, for implementing such networks when one does not have global knowledge of the manifold, but merely has access to finitely many sample points. We provide sufficient conditions for the network to provably converge to its continuum limit as the number of sample points tends to infinity. Unlike previous work (which focused on specific MNN architectures and graph constructions), our rate of convergence does not explicitly depend on the number of filters used. Moreover, it exhibits line
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#30340;&#26032;&#29702;&#35770;&#35299;&#37322;&#21644;&#35777;&#26126;&#65292;&#21363;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#21487;&#20197;&#36890;&#36807;&#36830;&#32493;&#26041;&#24335;&#38544;&#24335;&#20248;&#21270;&#30830;&#23450;&#24615;&#31574;&#30053;&#65292;&#24182;&#25351;&#20986;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#25506;&#32034;&#30340;&#23454;&#36136;&#26159;&#35745;&#31639;&#24403;&#21069;&#31574;&#30053;&#25910;&#30410;&#30340;&#36830;&#32493;&#20989;&#25968;&#65292;&#31574;&#30053;&#30340;&#26041;&#24046;&#24212;&#35813;&#26159;&#21382;&#21490;&#20381;&#36182;&#24615;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2305.06851</link><description>&lt;p&gt;
&#36890;&#36807;&#36830;&#32493;&#26041;&#24335;&#38544;&#24335;&#20248;&#21270;&#30340;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Policy Gradient Algorithms Implicitly Optimize by Continuation. (arXiv:2305.06851v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06851
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#30340;&#26032;&#29702;&#35770;&#35299;&#37322;&#21644;&#35777;&#26126;&#65292;&#21363;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#21487;&#20197;&#36890;&#36807;&#36830;&#32493;&#26041;&#24335;&#38544;&#24335;&#20248;&#21270;&#30830;&#23450;&#24615;&#31574;&#30053;&#65292;&#24182;&#25351;&#20986;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#25506;&#32034;&#30340;&#23454;&#36136;&#26159;&#35745;&#31639;&#24403;&#21069;&#31574;&#30053;&#25910;&#30410;&#30340;&#36830;&#32493;&#20989;&#25968;&#65292;&#31574;&#30053;&#30340;&#26041;&#24046;&#24212;&#35813;&#26159;&#21382;&#21490;&#20381;&#36182;&#24615;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#30452;&#25509;&#31574;&#30053;&#20248;&#21270;&#36890;&#24120;&#36890;&#36807;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#35299;&#20915;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19978;&#21319;&#20248;&#21270;&#31574;&#30053;&#21442;&#25968;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#29702;&#35770;&#35299;&#37322;&#21644;&#35777;&#26126;&#36825;&#20123;&#31639;&#27861;&#30340;&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23558;&#30452;&#25509;&#31574;&#30053;&#20248;&#21270;&#38382;&#39064;&#24314;&#31435;&#22312;&#20248;&#21270;&#36830;&#32493;&#26694;&#26550;&#19979;&#12290;&#21518;&#32773;&#26159;&#19968;&#31181;&#29992;&#20110;&#20248;&#21270;&#38750;&#20984;&#20989;&#25968;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#20197;&#36830;&#32493;&#30340;&#26367;&#20195;&#30446;&#26631;&#20989;&#25968;&#24207;&#21015;&#20026;&#22522;&#30784;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20248;&#21270;&#20223;&#23556;&#39640;&#26031;&#31574;&#30053;&#24182;&#25191;&#34892;&#29109;&#27491;&#21017;&#21270;&#21487;&#20197;&#35299;&#37322;&#20026;&#36890;&#36807;&#36830;&#32493;&#38544;&#24335;&#22320;&#20248;&#21270;&#30830;&#23450;&#24615;&#31574;&#30053;&#12290;&#22522;&#20110;&#36825;&#20123;&#29702;&#35770;&#32467;&#26524;&#65292;&#25105;&#20204;&#35748;&#20026;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#20013;&#30340;&#25506;&#32034;&#21253;&#25324;&#35745;&#31639;&#24403;&#21069;&#30340;&#31574;&#30053;&#25910;&#30410;&#30340;&#36830;&#32493;&#20989;&#25968;&#65292;&#31574;&#30053;&#30340;&#26041;&#24046;&#24212;&#35813;&#26159;&#21382;&#21490;&#20381;&#36182;&#24615;&#20989;&#25968;&#65292;&#20197;&#36991;&#20813;&#23616;&#37096;&#26368;&#20540;&#32780;&#19981;&#26159;&#20165;&#20165;&#26368;&#22823;&#21270;&#25919;&#31574;&#30340;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
Direct policy optimization in reinforcement learning is usually solved with policy-gradient algorithms, which optimize policy parameters via stochastic gradient ascent. This paper provides a new theoretical interpretation and justification of these algorithms. First, we formulate direct policy optimization in the optimization by continuation framework. The latter is a framework for optimizing nonconvex functions where a sequence of surrogate objective functions, called continuations, are locally optimized. Second, we show that optimizing affine Gaussian policies and performing entropy regularization can be interpreted as implicitly optimizing deterministic policies by continuation. Based on these theoretical results, we argue that exploration in policy-gradient algorithms consists in computing a continuation of the return of the policy at hand, and that the variance of policies should be history-dependent functions adapted to avoid local extrema rather than to maximize the return of th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;Kullback-Leibler Maillard Sampling (KL-MS)&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#26377;&#30028;&#22870;&#21169;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#23454;&#29616;KL&#31354;&#38388;&#30340;&#25193;&#23637;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#28176;&#36817;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.14989</link><description>&lt;p&gt;
Kullback-Leibler Maillard&#37319;&#26679;&#22312;&#26377;&#30028;&#22870;&#21169;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Kullback-Leibler Maillard Sampling for Multi-armed Bandits with Bounded Rewards. (arXiv:2304.14989v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14989
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;Kullback-Leibler Maillard Sampling (KL-MS)&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#26377;&#30028;&#22870;&#21169;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#23454;&#29616;KL&#31354;&#38388;&#30340;&#25193;&#23637;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#28176;&#36817;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22870;&#21169;&#20998;&#24067;&#38598;&#20013;&#22312;&#21306;&#38388;$[0,1]$&#20869;&#30340;$K$&#33218;&#25968;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Kullback-Leibler Maillard Sampling (KL-MS)&#30340;&#26032;&#31639;&#27861;&#65292;&#23427;&#26159;Maillard&#37319;&#26679;&#22312;KL&#31354;&#38388;&#30340;&#33258;&#28982;&#25193;&#23637;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;KL-MS&#22312;Bernoulli&#22870;&#21169;&#26102;&#20855;&#26377;&#28176;&#36817;&#26368;&#20248;&#24615;&#33021;&#65292;&#20854;&#26368;&#22351;&#24773;&#20917;&#36951;&#25022;&#24230;&#19978;&#30028;&#20026;$O(\sqrt{\mu^*(1-\mu^*) K T \ln K} + K \ln T)$&#65292;&#20854;&#20013;$\mu^*$&#26159;&#26368;&#20248;&#33218;&#30340;&#26399;&#26395;&#22870;&#21169;&#65292;$T$&#26159;&#26102;&#27573;&#38271;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study $K$-armed bandit problems where the reward distributions of the arms are all supported on the $[0,1]$ interval. It has been a challenge to design regret-efficient randomized exploration algorithms in this setting. Maillard sampling~\cite{maillard13apprentissage}, an attractive alternative to Thompson sampling, has recently been shown to achieve competitive regret guarantees in the sub-Gaussian reward setting~\cite{bian2022maillard} while maintaining closed-form action probabilities, which is useful for offline policy evaluation. In this work, we propose the Kullback-Leibler Maillard Sampling (KL-MS) algorithm, a natural extension of Maillard sampling for achieving KL-style gap-dependent regret bound. We show that KL-MS enjoys the asymptotic optimality when the rewards are Bernoulli and has a worst-case regret bound of the form $O(\sqrt{\mu^*(1-\mu^*) K T \ln K} + K \ln T)$, where $\mu^*$ is the expected reward of the optimal arm, and $T$ is the time horizon length.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32479;&#35745;&#20272;&#35745;&#38382;&#39064;&#20013;&#23545;&#37325;&#23614;&#25968;&#25454;&#30340;&#37327;&#21270;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25130;&#26029;&#21644;&#36866;&#24403;&#25238;&#21160;&#30340;&#26041;&#26696;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#26696;&#21487;&#20197;&#23454;&#29616;&#65288;&#36817;&#20046;&#65289;&#26368;&#23567;&#21270;&#30340;&#20272;&#35745;&#35823;&#24046;&#36895;&#29575;&#12290;&#20855;&#20307;&#24212;&#29992;&#21253;&#25324;&#21327;&#26041;&#24046;&#20272;&#35745;&#12289;&#21387;&#32553;&#24863;&#30693;&#21644;&#30697;&#38453;&#34917;&#20840;&#65292;&#32467;&#26524;&#34920;&#26126;&#37327;&#21270;&#23545;&#20056;&#27861;&#22240;&#23376;&#30340;&#24433;&#21709;&#36739;&#23567;&#12290;&#22312;&#21516;&#26102;&#23545;&#21327;&#21464;&#37327;&#21644;&#21709;&#24212;&#36827;&#34892;&#37327;&#21270;&#30340;&#21387;&#32553;&#24863;&#30693;&#38382;&#39064;&#20013;&#65292;&#34429;&#28982;&#24674;&#22797;&#31243;&#24207;&#26159;&#38750;&#20984;&#30340;&#65292;&#20294;&#25152;&#26377;&#23616;&#37096;&#26497;&#23567;&#20540;&#37117;&#26377;&#36817;&#20046;&#26368;&#20248;&#30340;&#35823;&#24046;&#30028;&#12290;</title><link>http://arxiv.org/abs/2212.14562</link><description>&lt;p&gt;
&#23545;&#32479;&#35745;&#20272;&#35745;&#20013;&#37325;&#23614;&#25968;&#25454;&#30340;&#37327;&#21270;&#65306;&#65288;&#36817;&#20046;&#65289;&#26368;&#23567;&#21270;&#36895;&#29575;&#65292;&#21327;&#21464;&#37327;&#37327;&#21270;&#21644;&#19968;&#33268;&#24674;&#22797;
&lt;/p&gt;
&lt;p&gt;
Quantizing Heavy-tailed Data in Statistical Estimation: (Near) Minimax Rates, Covariate Quantization, and Uniform Recovery. (arXiv:2212.14562v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.14562
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32479;&#35745;&#20272;&#35745;&#38382;&#39064;&#20013;&#23545;&#37325;&#23614;&#25968;&#25454;&#30340;&#37327;&#21270;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25130;&#26029;&#21644;&#36866;&#24403;&#25238;&#21160;&#30340;&#26041;&#26696;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#26696;&#21487;&#20197;&#23454;&#29616;&#65288;&#36817;&#20046;&#65289;&#26368;&#23567;&#21270;&#30340;&#20272;&#35745;&#35823;&#24046;&#36895;&#29575;&#12290;&#20855;&#20307;&#24212;&#29992;&#21253;&#25324;&#21327;&#26041;&#24046;&#20272;&#35745;&#12289;&#21387;&#32553;&#24863;&#30693;&#21644;&#30697;&#38453;&#34917;&#20840;&#65292;&#32467;&#26524;&#34920;&#26126;&#37327;&#21270;&#23545;&#20056;&#27861;&#22240;&#23376;&#30340;&#24433;&#21709;&#36739;&#23567;&#12290;&#22312;&#21516;&#26102;&#23545;&#21327;&#21464;&#37327;&#21644;&#21709;&#24212;&#36827;&#34892;&#37327;&#21270;&#30340;&#21387;&#32553;&#24863;&#30693;&#38382;&#39064;&#20013;&#65292;&#34429;&#28982;&#24674;&#22797;&#31243;&#24207;&#26159;&#38750;&#20984;&#30340;&#65292;&#20294;&#25152;&#26377;&#23616;&#37096;&#26497;&#23567;&#20540;&#37117;&#26377;&#36817;&#20046;&#26368;&#20248;&#30340;&#35823;&#24046;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#19968;&#20123;&#22522;&#26412;&#32479;&#35745;&#20272;&#35745;&#38382;&#39064;&#20013;&#23545;&#37325;&#23614;&#25968;&#25454;&#30340;&#37327;&#21270;&#65292;&#20854;&#20013;&#24213;&#23618;&#20998;&#24067;&#20855;&#26377;&#19968;&#23450;&#38454;&#25968;&#30340;&#26377;&#30028;&#30697;&#12290;&#25105;&#20204;&#25552;&#20986;&#22312;&#22343;&#21248;&#37327;&#21270;&#20043;&#21069;&#23545;&#25968;&#25454;&#36827;&#34892;&#25130;&#26029;&#21644;&#36866;&#24403;&#25238;&#21160;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#35266;&#28857;&#26159;&#65292;&#36890;&#36807;&#25152;&#25552;&#20986;&#30340;&#26041;&#26696;&#20135;&#29983;&#30340;&#37327;&#21270;&#25968;&#25454;&#20165;&#38656;&#23454;&#29616;&#65288;&#36817;&#20046;&#65289;&#26368;&#23567;&#21270;&#30340;&#20272;&#35745;&#35823;&#24046;&#36895;&#29575;&#12290;&#29305;&#21035;&#22320;&#65292;&#23545;&#21327;&#26041;&#24046;&#20272;&#35745;&#12289;&#21387;&#32553;&#24863;&#30693;&#21644;&#30697;&#38453;&#34917;&#20840;&#36827;&#34892;&#20102;&#20855;&#20307;&#30340;&#32467;&#26524;&#25512;&#23548;&#65292;&#25152;&#26377;&#32467;&#26524;&#37117;&#34920;&#26126;&#37327;&#21270;&#20165;&#20351;&#20056;&#27861;&#22240;&#23376;&#31245;&#24494;&#24694;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#21516;&#26102;&#23545;&#21327;&#21464;&#37327;&#65288;&#21363;&#24863;&#30693;&#21521;&#37327;&#65289;&#21644;&#21709;&#24212;&#36827;&#34892;&#37327;&#21270;&#30340;&#21387;&#32553;&#24863;&#30693;&#38382;&#39064;&#12290;&#22312;&#21327;&#21464;&#37327;&#37327;&#21270;&#19979;&#65292;&#23613;&#31649;&#25105;&#20204;&#30340;&#24674;&#22797;&#31243;&#24207;&#26159;&#38750;&#20984;&#30340;&#65292;&#22240;&#20026;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#20540;&#32570;&#20047;&#27491;&#21322;&#23450;&#24615;&#65292;&#20294;&#25152;&#26377;&#23616;&#37096;&#26497;&#23567;&#20540;&#37117;&#34987;&#35777;&#26126;&#20855;&#26377;&#36817;&#20046;&#26368;&#20248;&#30340;&#35823;&#24046;&#30028;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#20056;&#31215;&#36807;&#31243;&#30340;&#38598;&#20013;&#19981;&#31561;&#24335;
&lt;/p&gt;
&lt;p&gt;
This paper studies the quantization of heavy-tailed data in some fundamental statistical estimation problems, where the underlying distributions have bounded moments of some order. We propose to truncate and properly dither the data prior to a uniform quantization. Our major standpoint is that (near) minimax rates of estimation error are achievable merely from the quantized data produced by the proposed scheme. In particular, concrete results are worked out for covariance estimation, compressed sensing, and matrix completion, all agreeing that the quantization only slightly worsens the multiplicative factor. Besides, we study compressed sensing where both covariate (i.e., sensing vector) and response are quantized. Under covariate quantization, although our recovery program is non-convex because the covariance matrix estimator lacks positive semi-definiteness, all local minimizers are proved to enjoy near optimal error bound. Moreover, by the concentration inequality of product process
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24314;&#31435;&#20102;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#19982;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#25512;&#23548;&#20102;&#29992;&#20110;&#25511;&#21046;&#28508;&#22312;SDE&#36793;&#38469;&#23494;&#24230;&#28436;&#21270;&#30340;&#27721;&#23494;&#23572;&#39039;-&#38597;&#21487;&#27604;-&#36125;&#23572;&#26364;&#26041;&#31243;&#65292;&#24182;&#23558;&#29983;&#25104;&#24314;&#27169;&#34920;&#36848;&#20026;&#23545;&#21512;&#36866;&#24230;&#37327;&#20043;&#38388;Kullback-Leibler&#25955;&#24230;&#30340;&#26368;&#23567;&#21270;&#12290;&#27492;&#22806;&#65292;&#20316;&#32773;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#22411;&#25193;&#25955;&#26041;&#27861;&#29992;&#20110;&#37319;&#26679;&#38750;&#24402;&#19968;&#21270;&#23494;&#24230;&#12290;</title><link>http://arxiv.org/abs/2211.01364</link><description>&lt;p&gt;
&#23545;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#26368;&#20248;&#25511;&#21046;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
An optimal control perspective on diffusion-based generative modeling. (arXiv:2211.01364v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.01364
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24314;&#31435;&#20102;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#19982;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#25512;&#23548;&#20102;&#29992;&#20110;&#25511;&#21046;&#28508;&#22312;SDE&#36793;&#38469;&#23494;&#24230;&#28436;&#21270;&#30340;&#27721;&#23494;&#23572;&#39039;-&#38597;&#21487;&#27604;-&#36125;&#23572;&#26364;&#26041;&#31243;&#65292;&#24182;&#23558;&#29983;&#25104;&#24314;&#27169;&#34920;&#36848;&#20026;&#23545;&#21512;&#36866;&#24230;&#37327;&#20043;&#38388;Kullback-Leibler&#25955;&#24230;&#30340;&#26368;&#23567;&#21270;&#12290;&#27492;&#22806;&#65292;&#20316;&#32773;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#22411;&#25193;&#25955;&#26041;&#27861;&#29992;&#20110;&#37319;&#26679;&#38750;&#24402;&#19968;&#21270;&#23494;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24314;&#31435;&#20102;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#19982;&#22522;&#20110;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#30340;&#29983;&#25104;&#27169;&#22411;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#20363;&#22914;&#26368;&#36817;&#21457;&#23637;&#36215;&#26469;&#30340;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#19968;&#20010;&#27721;&#23494;&#23572;&#39039;-&#38597;&#21487;&#27604;-&#36125;&#23572;&#26364;&#26041;&#31243;&#65292;&#29992;&#20110;&#25511;&#21046;&#28508;&#22312;&#30340;SDE&#36793;&#38469;&#23494;&#24230;&#30340;&#28436;&#21270;&#12290;&#36825;&#20010;&#35270;&#35282;&#20801;&#35768;&#23558;&#26368;&#20248;&#25511;&#21046;&#29702;&#35770;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#29983;&#25104;&#24314;&#27169;&#20013;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35777;&#25454;&#19979;&#30028;&#26159;&#25511;&#21046;&#29702;&#35770;&#20013;&#24191;&#20026;&#20154;&#30693;&#30340;&#39564;&#35777;&#23450;&#29702;&#30340;&#30452;&#25509;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21487;&#20197;&#23558;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#24314;&#27169;&#34920;&#36848;&#20026;&#36335;&#24452;&#31354;&#38388;&#20013;&#21512;&#36866;&#24230;&#37327;&#20043;&#38388;&#30340;Kullback-Leibler&#25955;&#24230;&#30340;&#26368;&#23567;&#21270;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#20174;&#38750;&#24402;&#19968;&#21270;&#23494;&#24230;&#20013;&#36827;&#34892;&#37319;&#26679;&#30340;&#26032;&#22411;&#25193;&#25955;&#26041;&#27861;&#65292;&#36825;&#22312;&#32479;&#35745;&#23398;&#21644;&#35745;&#31639;&#31185;&#23398;&#20013;&#32463;&#24120;&#20986;&#29616;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26102;&#24207;&#21453;&#21521;&#25193;&#25955;&#37319;&#26679;&#22120;&#65288;DIS&#65289;&#21487;&#20197;&#32988;&#36807;&#20854;&#20182;&#22522;&#20110;&#25193;&#25955;&#30340;&#37319;&#26679;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We establish a connection between stochastic optimal control and generative models based on stochastic differential equations (SDEs), such as recently developed diffusion probabilistic models. In particular, we derive a Hamilton-Jacobi-Bellman equation that governs the evolution of the log-densities of the underlying SDE marginals. This perspective allows to transfer methods from optimal control theory to generative modeling. First, we show that the evidence lower bound is a direct consequence of the well-known verification theorem from control theory. Further, we can formulate diffusion-based generative modeling as a minimization of the Kullback-Leibler divergence between suitable measures in path space. Finally, we develop a novel diffusion-based method for sampling from unnormalized densities -- a problem frequently occurring in statistics and computational sciences. We demonstrate that our time-reversed diffusion sampler (DIS) can outperform other diffusion-based sampling approache
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#36890;&#36807;&#35843;&#25972;&#36229;&#21442;&#25968;&#21487;&#20197;&#25552;&#39640;&#36793;&#38469;&#20284;&#28982;&#65292;&#20294;&#20132;&#21449;&#39564;&#35777;&#24230;&#37327;&#34920;&#29616;&#20986;&#21452;&#19979;&#38477;&#29616;&#35937;&#12290;</title><link>http://arxiv.org/abs/2210.07612</link><description>&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#20013;&#30340;&#21333;&#35843;&#24615;&#21644;&#21452;&#19979;&#38477;&#29616;&#35937;&#22312;&#39640;&#26031;&#36807;&#31243;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Monotonicity and Double Descent in Uncertainty Estimation with Gaussian Processes. (arXiv:2210.07612v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.07612
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#36890;&#36807;&#35843;&#25972;&#36229;&#21442;&#25968;&#21487;&#20197;&#25552;&#39640;&#36793;&#38469;&#20284;&#28982;&#65292;&#20294;&#20132;&#21449;&#39564;&#35777;&#24230;&#37327;&#34920;&#29616;&#20986;&#21452;&#19979;&#38477;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#35780;&#20272;&#39044;&#27979;&#30340;&#21487;&#38752;&#24615;&#38750;&#24120;&#37325;&#35201;&#65292;&#20294;&#23545;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65288;UQ&#65289;&#25351;&#26631;&#30452;&#21040;&#26368;&#36817;&#25165;&#24320;&#22987;&#24471;&#21040;&#20005;&#26684;&#30340;&#34920;&#24449;&#12290;&#19968;&#20010;&#26174;&#33879;&#38382;&#39064;&#26159;&#32500;&#24230;&#35781;&#21650;&#65306;&#26222;&#36941;&#35748;&#20026;&#36793;&#32536;&#20284;&#28982;&#24212;&#35813;&#19982;&#20132;&#21449;&#39564;&#35777;&#24230;&#37327;&#31867;&#20284;&#65292;&#24182;&#19988;&#20004;&#32773;&#22312;&#36755;&#20837;&#32500;&#24230;&#36739;&#22823;&#26102;&#37117;&#20250;&#24694;&#21270;&#12290;&#25105;&#20204;&#35777;&#26126;&#36890;&#36807;&#35843;&#25972;&#36229;&#21442;&#25968;&#20197;&#26368;&#22823;&#21270;&#36793;&#38469;&#20284;&#28982;&#65288;&#32463;&#39564;&#36125;&#21494;&#26031;&#36807;&#31243;&#65289;&#65292;&#24615;&#33021;&#65288;&#20197;&#36793;&#38469;&#20284;&#28982;&#27979;&#37327;&#65289;&#38543;&#30528;&#36755;&#20837;&#32500;&#24230;&#30340;&#22686;&#21152;&#21333;&#35843;&#25913;&#21892;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#25105;&#20204;&#35777;&#26126;&#20132;&#21449;&#39564;&#35777;&#24230;&#37327;&#34920;&#29616;&#20986;&#19981;&#21516;&#30340;&#34892;&#20026;&#29305;&#24449;&#65292;&#21363;&#21452;&#19979;&#38477;&#29616;&#35937;&#12290;&#26368;&#36817;&#22240;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#24615;&#33021;&#25552;&#39640;&#32780;&#21463;&#21040;&#20851;&#27880;&#30340;&#20919;&#24577;&#21518;&#39564;&#20284;&#20046;&#21152;&#21095;&#20102;&#36825;&#20123;&#29616;&#35937;&#12290;&#25105;&#20204;&#32463;&#39564;&#35777;&#23454;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#22312;&#30495;&#23454;&#25968;&#25454;&#19978;&#25104;&#31435;&#65292;&#36229;&#20986;&#25105;&#20204;&#32771;&#34385;&#30340;&#20551;&#35774;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite their importance for assessing reliability of predictions, uncertainty quantification (UQ) measures for machine learning models have only recently begun to be rigorously characterized. One prominent issue is the curse of dimensionality: it is commonly believed that the marginal likelihood should be reminiscent of cross-validation metrics and that both should deteriorate with larger input dimensions. We prove that by tuning hyperparameters to maximize marginal likelihood (the empirical Bayes procedure), the performance, as measured by the marginal likelihood, improves monotonically} with the input dimension. On the other hand, we prove that cross-validation metrics exhibit qualitatively different behavior that is characteristic of double descent. Cold posteriors, which have recently attracted interest due to their improved performance in certain settings, appear to exacerbate these phenomena. We verify empirically that our results hold for real data, beyond our considered assump
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#21464;&#37327;&#25968;&#37327;&#36828;&#22823;&#20110;&#26679;&#26412;&#22823;&#23567;&#30340;&#24773;&#20917;&#19979;&#65292;&#20934;&#30830;&#22320;&#20272;&#35745;&#22823;&#35268;&#27169;&#22240;&#26524;&#22810;&#26641;&#32467;&#26500;&#65292;&#32780;&#20960;&#20046;&#19981;&#38656;&#35201;&#20219;&#20309;&#20998;&#24067;&#25110;&#24314;&#27169;&#30340;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2209.07028</link><description>&lt;p&gt;
&#20174;&#23567;&#26679;&#26412;&#20013;&#20272;&#35745;&#22823;&#30340;&#22240;&#26524;&#22810;&#26641;
&lt;/p&gt;
&lt;p&gt;
Estimating large causal polytrees from small samples. (arXiv:2209.07028v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.07028
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#21464;&#37327;&#25968;&#37327;&#36828;&#22823;&#20110;&#26679;&#26412;&#22823;&#23567;&#30340;&#24773;&#20917;&#19979;&#65292;&#20934;&#30830;&#22320;&#20272;&#35745;&#22823;&#35268;&#27169;&#22240;&#26524;&#22810;&#26641;&#32467;&#26500;&#65292;&#32780;&#20960;&#20046;&#19981;&#38656;&#35201;&#20219;&#20309;&#20998;&#24067;&#25110;&#24314;&#27169;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#30456;&#23545;&#36739;&#23567;&#30340;&#29420;&#31435;&#21516;&#20998;&#24067;&#26679;&#26412;&#20013;&#20272;&#35745;&#22823;&#30340;&#22240;&#26524;&#22810;&#26641;&#30340;&#38382;&#39064;&#12290;&#36825;&#26159;&#22312;&#21464;&#37327;&#25968;&#37327;&#19982;&#26679;&#26412;&#22823;&#23567;&#30456;&#27604;&#38750;&#24120;&#22823;&#30340;&#24773;&#20917;&#19979;&#30830;&#23450;&#22240;&#26524;&#32467;&#26500;&#30340;&#38382;&#39064;&#65292;&#20363;&#22914;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20197;&#39640;&#20934;&#30830;&#24230;&#24674;&#22797;&#26641;&#24418;&#32467;&#26500;&#12290;&#35813;&#31639;&#27861;&#38500;&#20102;&#19968;&#20123;&#28201;&#21644;&#30340;&#38750;&#36864;&#21270;&#26465;&#20214;&#22806;&#65292;&#22522;&#26412;&#19981;&#38656;&#35201;&#20998;&#24067;&#25110;&#24314;&#27169;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of estimating a large causal polytree from a relatively small i.i.d. sample. This is motivated by the problem of determining causal structure when the number of variables is very large compared to the sample size, such as in gene regulatory networks. We give an algorithm that recovers the tree with high accuracy in such settings. The algorithm works under essentially no distributional or modeling assumptions other than some mild non-degeneracy conditions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26799;&#24230;&#19979;&#38477;&#23545;&#20110;&#38750;Lipschitz&#26799;&#24230;&#30340;&#25439;&#22833;&#20989;&#25968;&#30340;&#25910;&#25947;&#24615;&#65292;&#21457;&#29616;&#22312;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#20013;&#65292;&#23613;&#31649;&#23384;&#22312;&#23616;&#37096;&#19981;&#31283;&#23450;&#24615;&#21644;&#25391;&#33633;&#34892;&#20026;&#65292;&#26799;&#24230;&#19979;&#38477;&#20173;&#28982;&#33021;&#22815;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2206.04172</link><description>&lt;p&gt;
&#36890;&#36807;&#20004;&#27493;&#26799;&#24230;&#26356;&#26032;&#36229;&#36234;&#31283;&#23450;&#36793;&#30028;
&lt;/p&gt;
&lt;p&gt;
Beyond the Edge of Stability via Two-step Gradient Updates. (arXiv:2206.04172v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.04172
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26799;&#24230;&#19979;&#38477;&#23545;&#20110;&#38750;Lipschitz&#26799;&#24230;&#30340;&#25439;&#22833;&#20989;&#25968;&#30340;&#25910;&#25947;&#24615;&#65292;&#21457;&#29616;&#22312;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#20013;&#65292;&#23613;&#31649;&#23384;&#22312;&#23616;&#37096;&#19981;&#31283;&#23450;&#24615;&#21644;&#25391;&#33633;&#34892;&#20026;&#65292;&#26799;&#24230;&#19979;&#38477;&#20173;&#28982;&#33021;&#22815;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#26159;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24378;&#22823;&#24037;&#20855;&#65292;&#22240;&#20854;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#25928;&#29575;&#32780;&#38395;&#21517;&#12290;&#23545;&#20110;&#20855;&#26377;Lipschitz&#26799;&#24230;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;GD&#21482;&#33021;&#25214;&#21040;&#23616;&#37096;&#26497;&#23567;&#20540;&#28857;&#65292;&#21487;&#20197;&#30475;&#20316;&#26159;&#28508;&#22312;&#26799;&#24230;&#27969;&#30340;&#8220;&#30495;&#23454;&#8221;&#31163;&#25955;&#21270;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#28041;&#21450;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#30340;&#26426;&#22120;&#23398;&#20064;&#35774;&#32622;&#24182;&#19981;&#23646;&#20110;&#36825;&#20010;&#38382;&#39064;&#31867;&#21035;&#65292;&#36825;&#20419;&#20351;&#30740;&#31350;&#36229;&#36234;&#25152;&#35859;&#30340;&#8220;&#31283;&#23450;&#36793;&#30028;&#8221;&#65288;Edge of Stability&#65292;EoS&#65289;&#65292;&#20854;&#20013;&#27493;&#38271;&#36234;&#36807;&#19982;Lipschitz&#24120;&#25968;&#25104;&#21453;&#27604;&#30340;&#21487;&#20801;&#35768;&#38408;&#20540;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#32463;&#39564;&#35777;&#26126;&#23613;&#31649;&#23384;&#22312;&#23616;&#37096;&#19981;&#31283;&#23450;&#24615;&#21644;&#25391;&#33633;&#34892;&#20026;&#65292;GD&#20173;&#28982;&#25910;&#25947;&#12290;&#23545;&#36825;&#19968;&#29616;&#35937;&#30340;&#21021;&#27493;&#29702;&#35770;&#20998;&#26512;&#20027;&#35201;&#38598;&#20013;&#22312;&#36807;&#21442;&#25968;&#21270;&#30340;&#33539;&#22260;&#20869;&#65292;&#22312;&#27492;&#33539;&#22260;&#20869;&#36873;&#25321;&#36739;&#22823;&#30340;&#23398;&#20064;&#29575;&#21487;&#33021;&#19982;&#22312;&#26368;&#23567;&#21270;&#22120;&#27969;&#24418;&#20869;&#38544;&#21547;&#30340;&#8220;&#23574;&#24230;&#26368;&#23567;&#21270;&#8221;&#27491;&#21017;&#21270;&#30456;&#20851;&#65292;&#35831;&#35814;&#35265;&#35770;&#25991;&#20102;&#35299;&#26356;&#22810;&#32454;&#33410;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gradient Descent (GD) is a powerful workhorse of modern machine learning thanks to its scalability and efficiency in high-dimensional spaces. Its ability to find local minimisers is only guaranteed for losses with Lipschitz gradients, where it can be seen as a `bona-fide' discretisation of an underlying gradient flow. Yet, many ML setups involving overparametrised models do not fall into this problem class, which has motivated research beyond the so-called ``Edge of Stability'' (EoS), where the step-size crosses the admissibility threshold inversely proportional to the Lipschitz constant above. Perhaps surprisingly, GD has been empirically observed to still converge regardless of local instability and oscillatory behavior.  The incipient theoretical analysis of this phenomena has mainly focused in the overparametrised regime, where the effect of choosing a large learning rate may be associated to a `Sharpness-Minimisation' implicit regularisation within the manifold of minimisers, unde
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#29992;&#25143;&#25351;&#21335;&#20171;&#32461;&#20102;&#26426;&#22120;&#23398;&#20064;&#21644;&#31934;&#31639;&#23454;&#36341;&#20013;&#19968;&#33268;&#24615;&#35780;&#20998;&#20989;&#25968;&#30340;&#27604;&#36739;&#21644;&#26657;&#20934;&#35780;&#20272;&#25216;&#26415;&#65292;&#24182;&#24378;&#35843;&#20102;&#20107;&#20808;&#30830;&#23450;&#30446;&#26631;&#39044;&#27979;&#20989;&#25968;&#21644;&#36873;&#25321;&#30456;&#24212;&#35780;&#20998;&#20989;&#25968;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2202.12780</link><description>&lt;p&gt;
&#27169;&#22411;&#27604;&#36739;&#21644;&#26657;&#20934;&#35780;&#20272;&#65306;&#26426;&#22120;&#23398;&#20064;&#21644;&#31934;&#31639;&#23454;&#36341;&#20013;&#19968;&#33268;&#24615;&#35780;&#20998;&#20989;&#25968;&#30340;&#29992;&#25143;&#25351;&#21335;
&lt;/p&gt;
&lt;p&gt;
Model Comparison and Calibration Assessment: User Guide for Consistent Scoring Functions in Machine Learning and Actuarial Practice. (arXiv:2202.12780v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.12780
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#29992;&#25143;&#25351;&#21335;&#20171;&#32461;&#20102;&#26426;&#22120;&#23398;&#20064;&#21644;&#31934;&#31639;&#23454;&#36341;&#20013;&#19968;&#33268;&#24615;&#35780;&#20998;&#20989;&#25968;&#30340;&#27604;&#36739;&#21644;&#26657;&#20934;&#35780;&#20272;&#25216;&#26415;&#65292;&#24182;&#24378;&#35843;&#20102;&#20107;&#20808;&#30830;&#23450;&#30446;&#26631;&#39044;&#27979;&#20989;&#25968;&#21644;&#36873;&#25321;&#30456;&#24212;&#35780;&#20998;&#20989;&#25968;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31934;&#31639;&#24072;&#21644;&#25968;&#25454;&#31185;&#23398;&#23478;&#20027;&#35201;&#30340;&#20219;&#21153;&#20043;&#19968;&#26159;&#26500;&#24314;&#36866;&#29992;&#20110;&#20445;&#38505;&#39046;&#22495;&#20013;&#35832;&#22914;&#32034;&#36180;&#37329;&#39069;&#25110;&#32034;&#36180;&#25968;&#37327;&#31561;&#29616;&#35937;&#30340;&#26377;&#25928;&#39044;&#27979;&#27169;&#22411;&#12290;&#36825;&#20123;&#27169;&#22411;&#29702;&#24819;&#24773;&#20917;&#19979;&#21033;&#29992;&#32473;&#23450;&#30340;&#29305;&#24449;&#20449;&#24687;&#26469;&#25552;&#39640;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#12290;&#26412;&#29992;&#25143;&#25351;&#21335;&#37325;&#26032;&#23457;&#35270;&#21644;&#26126;&#30830;&#20102;&#29992;&#20110;&#35780;&#20272;&#27169;&#22411;&#26657;&#20934;&#24615;&#25110;&#36866;&#24403;&#24615;&#30340;&#32479;&#35745;&#25216;&#26415;&#65292;&#20197;&#21450;&#27604;&#36739;&#21644;&#25490;&#21517;&#19981;&#21516;&#27169;&#22411;&#30340;&#25216;&#26415;&#12290;&#22312;&#36825;&#26679;&#20570;&#26102;&#65292;&#24378;&#35843;&#20102;&#20107;&#20808;&#26126;&#30830;&#25351;&#23450;&#30446;&#26631;&#39044;&#27979;&#20989;&#25968;&#65288;&#22914;&#24179;&#22343;&#20540;&#25110;&#20998;&#20301;&#25968;&#65289;&#20197;&#21450;&#36873;&#25321;&#19982;&#27492;&#30446;&#26631;&#20989;&#25968;&#19968;&#33268;&#30340;&#35780;&#20998;&#20989;&#25968;&#22312;&#27169;&#22411;&#27604;&#36739;&#20013;&#30340;&#37325;&#35201;&#24615;&#12290;&#25552;&#20379;&#20102;&#23454;&#38469;&#36873;&#25321;&#35780;&#20998;&#20989;&#25968;&#30340;&#25351;&#23548;&#12290;&#33268;&#21147;&#20110;&#22635;&#34917;&#31185;&#23398;&#19982;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#24046;&#36317;&#65292;&#20027;&#35201;&#19987;&#27880;&#20110;&#29616;&#26377;&#32467;&#26524;&#21644;&#26368;&#20339;&#23454;&#36341;&#30340;&#25945;&#23398;&#23637;&#31034;&#65292;&#24182;&#36890;&#36807;&#20004;&#20010;&#30495;&#23454;&#25968;&#25454;&#26696;&#20363;&#36827;&#34892;&#20102;&#35828;&#26126;&#21644;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the main tasks of actuaries and data scientists is to build good predictive models for certain phenomena such as the claim size or the number of claims in insurance. These models ideally exploit given feature information to enhance the accuracy of prediction. This user guide revisits and clarifies statistical techniques to assess the calibration or adequacy of a model on the one hand, and to compare and rank different models on the other hand. In doing so, it emphasises the importance of specifying the prediction target functional at hand a priori (e.g. the mean or a quantile) and of choosing the scoring function in model comparison in line with this target functional. Guidance for the practical choice of the scoring function is provided. Striving to bridge the gap between science and daily practice in application, it focuses mainly on the pedagogical presentation of existing results and of best practice. The results are accompanied and illustrated by two real data case studies 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#36125;&#21494;&#26031;&#26368;&#20248;&#33218;&#35782;&#21035;&#30340;&#36895;&#29575;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#26131;&#34892;&#30340;&#31639;&#27861;&#65292;&#20854;&#21305;&#37197;&#20102;&#19979;&#30028;&#65292;&#21482;&#24046;&#19968;&#20010;&#24120;&#25968;&#22240;&#23376;&#12290;</title><link>http://arxiv.org/abs/2111.09885</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#26368;&#20248;&#33218;&#35782;&#21035;&#20013;&#30340;&#26368;&#20248;&#31616;&#21333;&#36951;&#25022;
&lt;/p&gt;
&lt;p&gt;
Optimal Simple Regret in Bayesian Best Arm Identification. (arXiv:2111.09885v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.09885
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#36125;&#21494;&#26031;&#26368;&#20248;&#33218;&#35782;&#21035;&#30340;&#36895;&#29575;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#26131;&#34892;&#30340;&#31639;&#27861;&#65292;&#20854;&#21305;&#37197;&#20102;&#19979;&#30028;&#65292;&#21482;&#24046;&#19968;&#20010;&#24120;&#25968;&#22240;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#30340;&#26368;&#20248;&#33218;&#35782;&#21035;&#12290;&#22312;&#20808;&#39564;&#26465;&#20214;&#20855;&#26377;&#19968;&#23450;&#30340;&#36830;&#32493;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#34920;&#24449;&#20102;&#36125;&#21494;&#26031;&#31616;&#21333;&#36951;&#25022;&#30340;&#36895;&#29575;&#12290;&#19982;&#36125;&#21494;&#26031;&#36951;&#25022;&#26368;&#23567;&#21270;&#19981;&#21516;&#65292;&#36125;&#21494;&#26031;&#31616;&#21333;&#36951;&#25022;&#30340;&#20027;&#23548;&#39033;&#26469;&#28304;&#20110;&#26368;&#20248;&#33218;&#21644;&#27425;&#20248;&#33218;&#20043;&#38388;&#38388;&#38553;&#23567;&#20110;$\sqrt{\frac{\log T}{T}}$&#30340;&#21306;&#22495;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#26131;&#34892;&#30340;&#35745;&#31639;&#31639;&#27861;&#65292;&#20854;&#20027;&#23548;&#39033;&#21305;&#37197;&#20102;&#19979;&#30028;&#65292;&#21482;&#24046;&#19968;&#20010;&#24120;&#25968;&#22240;&#23376;&#65307;&#27169;&#25311;&#32467;&#26524;&#25903;&#25345;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider best arm identification in the multi-armed bandit problem. Assuming certain continuity conditions of the prior, we characterize the rate of the Bayesian simple regret. Differing from Bayesian regret minimization (Lai, 1987), the leading term in the Bayesian simple regret derives from the region where the gap between optimal and suboptimal arms is smaller than $\sqrt{\frac{\log T}{T}}$. We propose a simple and easy-to-compute algorithm with its leading term matching with the lower bound up to a constant factor; simulation results support our theoretical findings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377;&#31232;&#30095;&#20381;&#36182;&#32467;&#26500;&#30340;&#21487;&#21387;&#32553;&#39057;&#35889;&#28151;&#21512;&#26680;&#29992;&#20110;&#39640;&#26031;&#36807;&#31243;&#65292;&#36890;&#36807;&#25913;&#36827;&#21407;&#22987;&#26680;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#20855;&#20307;&#26041;&#27861;&#21253;&#25324;&#36890;&#36807;&#20132;&#21449;&#21327;&#26041;&#24046;&#21644;&#20132;&#21449;&#21367;&#31215;&#27867;&#21270;&#20381;&#36182;&#32467;&#26500;&#65292;&#20197;&#21450;&#36890;&#36807;&#21442;&#25968;&#21270;&#26102;&#38388;&#21644;&#30456;&#20301;&#24310;&#36831;&#25552;&#39640;&#20381;&#36182;&#32467;&#26500;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/1808.00560</link><description>&lt;p&gt;
&#24102;&#26377;&#31232;&#30095;&#20381;&#36182;&#32467;&#26500;&#30340;&#21487;&#21387;&#32553;&#39057;&#35889;&#28151;&#21512;&#26680;&#29992;&#20110;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Compressible Spectral Mixture Kernels with Sparse Dependency Structures for Gaussian Processes. (arXiv:1808.00560v9 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1808.00560
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377;&#31232;&#30095;&#20381;&#36182;&#32467;&#26500;&#30340;&#21487;&#21387;&#32553;&#39057;&#35889;&#28151;&#21512;&#26680;&#29992;&#20110;&#39640;&#26031;&#36807;&#31243;&#65292;&#36890;&#36807;&#25913;&#36827;&#21407;&#22987;&#26680;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#20855;&#20307;&#26041;&#27861;&#21253;&#25324;&#36890;&#36807;&#20132;&#21449;&#21327;&#26041;&#24046;&#21644;&#20132;&#21449;&#21367;&#31215;&#27867;&#21270;&#20381;&#36182;&#32467;&#26500;&#65292;&#20197;&#21450;&#36890;&#36807;&#21442;&#25968;&#21270;&#26102;&#38388;&#21644;&#30456;&#20301;&#24310;&#36831;&#25552;&#39640;&#20381;&#36182;&#32467;&#26500;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39057;&#35889;&#28151;&#21512;&#65288;SM&#65289;&#26680;&#26159;&#19968;&#31181;&#25551;&#36848;&#22797;&#26434;&#27169;&#24335;&#30340;&#36890;&#29992;&#20869;&#26680;&#31867;&#29992;&#20110;&#39640;&#26031;&#36807;&#31243;&#65288;GPs&#65289;&#12290;&#26412;&#25991;&#36890;&#36807;&#27169;&#22411;&#21387;&#32553;&#21644;&#26102;&#38388;&#30456;&#20301;&#65288;TP&#65289;&#35843;&#21046;&#20381;&#36182;&#32467;&#26500;&#65292;&#25913;&#36827;&#20102;&#21407;&#22987;&#30340;&#65288;SM&#65289;&#26680;&#20351;&#20854;&#20855;&#26377;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#36890;&#36807;&#37319;&#29992;Bienaym&#233;s&#24658;&#31561;&#24335;&#65292;&#25105;&#20204;&#36890;&#36807;SM&#32452;&#20214;&#20043;&#38388;&#30340;&#20132;&#21449;&#21327;&#26041;&#24046;&#26469;&#27867;&#21270;&#20381;&#36182;&#32467;&#26500;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24102;&#26377;&#20381;&#36182;&#32467;&#26500;&#65288;SMD&#65289;&#30340;SM&#26680;&#65292;&#36890;&#36807;SM&#32452;&#20214;&#20043;&#38388;&#30340;&#20132;&#21449;&#21367;&#31215;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#21442;&#25968;&#21270;&#26102;&#38388;&#21644;&#30456;&#20301;&#24310;&#36831;&#26469;&#25913;&#21892;&#20381;&#36182;&#32467;&#26500;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;&#35813;&#20381;&#36182;&#32467;&#26500;&#22312;&#39057;&#35889;&#23494;&#24230;&#12289;&#21327;&#26041;&#24046;&#34892;&#20026;&#21644;&#37319;&#26679;&#36335;&#24452;&#26041;&#38754;&#20855;&#26377;&#28165;&#26224;&#30340;&#35299;&#37322;&#12290;&#20026;&#20102;&#20016;&#23500;SMD&#30340;&#26377;&#25928;&#36229;&#21442;&#25968;&#21021;&#22987;&#21270;&#12289;&#21487;&#21387;&#32553;&#30340;SM&#26680;&#32452;&#20214;&#21644;&#31232;&#30095;&#30340;&#20381;&#36182;&#32467;&#26500;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#32467;&#26500;&#36866;&#24212;&#65288;SA&#65289;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Spectral mixture (SM) kernels comprise a powerful class of generalized kernels for Gaussian processes (GPs) to describe complex patterns. This paper introduces model compression and time- and phase (TP) modulated dependency structures to the original (SM) kernel for improved generalization of GPs. Specifically, by adopting Bienaym\'es identity, we generalize the dependency structure through cross-covariance between the SM components. Then, we propose a novel SM kernel with a dependency structure (SMD) by using cross-convolution between the SM components. Furthermore, we ameliorate the expressiveness of the dependency structure by parameterizing it with time and phase delays. The dependency structure has clear interpretations in terms of spectral density, covariance behavior, and sampling path. To enrich the SMD with effective hyperparameter initialization, compressible SM kernel components, and sparse dependency structures, we introduce a novel structure adaptation (SA) algorithm in th
&lt;/p&gt;</description></item></channel></rss>