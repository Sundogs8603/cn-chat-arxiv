<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#35299;&#20915;&#20855;&#26377;&#38543;&#26426;&#30446;&#26631;&#21644;&#32422;&#26463;&#30340;&#38750;&#32447;&#24615;&#35268;&#21010;&#38382;&#39064;&#20013;&#21333;&#24490;&#29615;&#20108;&#27425;&#32602;&#20989;&#25968;&#21644;&#22686;&#24191;Lagrangian&#31639;&#27861;&#30340;&#22797;&#26434;&#24615;&#65292;&#30740;&#31350;&#20102;&#19977;&#31181;&#20855;&#26377;&#19981;&#21516;&#32422;&#26463;&#24615;&#36136;&#30340;&#24773;&#20917;&#12290;&#32467;&#26524;&#34920;&#26126;&#20854;&#20013;&#30340;&#20004;&#31181;&#24773;&#20917;&#26159;&#39318;&#20010;&#37319;&#29992;&#21333;&#24490;&#29615;&#31639;&#27861;&#24182;&#20855;&#26377;&#19968;&#23450;&#22797;&#26434;&#24230;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2311.00678</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#35268;&#21010;&#20013;&#20855;&#26377;&#38543;&#26426;&#30446;&#26631;&#21644;&#32422;&#26463;&#30340;&#21333;&#24490;&#29615;&#31639;&#27861;&#30340;&#22797;&#26434;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Complexity of Single Loop Algorithms for Nonlinear Programming with Stochastic Objective and Constraints. (arXiv:2311.00678v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00678
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#35299;&#20915;&#20855;&#26377;&#38543;&#26426;&#30446;&#26631;&#21644;&#32422;&#26463;&#30340;&#38750;&#32447;&#24615;&#35268;&#21010;&#38382;&#39064;&#20013;&#21333;&#24490;&#29615;&#20108;&#27425;&#32602;&#20989;&#25968;&#21644;&#22686;&#24191;Lagrangian&#31639;&#27861;&#30340;&#22797;&#26434;&#24615;&#65292;&#30740;&#31350;&#20102;&#19977;&#31181;&#20855;&#26377;&#19981;&#21516;&#32422;&#26463;&#24615;&#36136;&#30340;&#24773;&#20917;&#12290;&#32467;&#26524;&#34920;&#26126;&#20854;&#20013;&#30340;&#20004;&#31181;&#24773;&#20917;&#26159;&#39318;&#20010;&#37319;&#29992;&#21333;&#24490;&#29615;&#31639;&#27861;&#24182;&#20855;&#26377;&#19968;&#23450;&#22797;&#26434;&#24230;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#20102;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#21151;&#33021;&#31561;&#24335;&#32422;&#26463;&#30340;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#30340;&#21333;&#24490;&#29615;&#20108;&#27425;&#32602;&#20989;&#25968;&#21644;&#22686;&#24191;Lagrangian&#31639;&#27861;&#30340;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19977;&#31181;&#24773;&#20917;&#65292;&#22312;&#25152;&#26377;&#24773;&#20917;&#19979;&#65292;&#30446;&#26631;&#20989;&#25968;&#37117;&#26159;&#38543;&#26426;&#19988;&#24179;&#28369;&#30340;&#65292;&#21363;&#23545;&#26410;&#30693;&#20998;&#24067;&#36827;&#34892;&#37319;&#26679;&#30340;&#26399;&#26395;&#12290;&#19977;&#31181;&#24773;&#20917;&#19979;&#31561;&#24335;&#32422;&#26463;&#30340;&#24615;&#36136;&#26377;&#25152;&#19981;&#21516;&#65306;&#31532;&#19968;&#31181;&#24773;&#20917;&#19979;&#30830;&#23450;&#24615;&#21644;&#32447;&#24615;&#65292;&#31532;&#20108;&#31181;&#24773;&#20917;&#19979;&#30830;&#23450;&#24615;&#12289;&#24179;&#28369;&#21644;&#38750;&#32447;&#24615;&#65292;&#31532;&#19977;&#31181;&#24773;&#20917;&#19979;&#38543;&#26426;&#12289;&#24179;&#28369;&#21644;&#38750;&#32447;&#24615;&#12290;&#21033;&#29992;&#26041;&#24046;&#20943;&#23567;&#25216;&#26415;&#25913;&#21892;&#22797;&#26434;&#24615;&#12290;&#20026;&#20102;&#25214;&#21040;&#28385;&#36275;&#949;&#36817;&#20284;&#19968;&#38454;&#26465;&#20214;&#30340;&#28857;&#65292;&#25105;&#20204;&#22312;&#31532;&#19968;&#31181;&#24773;&#20917;&#19979;&#38656;&#35201;&#22797;&#26434;&#24230;&#20026;$\widetilde{O}(\varepsilon^{-3})$&#65292;&#31532;&#20108;&#31181;&#24773;&#20917;&#19979;&#38656;&#35201;&#22797;&#26434;&#24230;&#20026;$\widetilde{O}(\varepsilon^{-4})$&#65292;&#31532;&#19977;&#31181;&#24773;&#20917;&#19979;&#38656;&#35201;&#22797;&#26434;&#24230;&#20026;$\widetilde{O}(\varepsilon^{-5})$&#12290;&#23545;&#20110;&#31532;&#19968;&#31181;&#21644;&#31532;&#19977;&#31181;&#24773;&#20917;&#65292;&#36825;&#26159;&#31532;&#19968;&#31181;&#8220;&#21333;&#24490;&#29615;&#8221;&#31867;&#22411;&#30340;&#31639;&#27861;&#65288;&#21516;&#26102;&#20063;&#20351;&#29992;$O$
&lt;/p&gt;
&lt;p&gt;
We analyze the complexity of single-loop quadratic penalty and augmented Lagrangian algorithms for solving nonconvex optimization problems with functional equality constraints. We consider three cases, in all of which the objective is stochastic and smooth, that is, an expectation over an unknown distribution that is accessed by sampling. The nature of the equality constraints differs among the three cases: deterministic and linear in the first case, deterministic, smooth and nonlinear in the second case, and stochastic, smooth and nonlinear in the third case. Variance reduction techniques are used to improve the complexity. To find a point that satisfies $\varepsilon$-approximate first-order conditions, we require $\widetilde{O}(\varepsilon^{-3})$ complexity in the first case, $\widetilde{O}(\varepsilon^{-4})$ in the second case, and $\widetilde{O}(\varepsilon^{-5})$ in the third case. For the first and third cases, they are the first algorithms of "single loop" type (that also use $O
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;Cholesky&#20998;&#35299;&#24674;&#22797;&#20855;&#26377;&#28508;&#21464;&#37327;&#30340;&#32447;&#24615;&#22240;&#26524;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#36895;&#24230;&#21644;&#24615;&#33021;&#19978;&#36229;&#36807;&#20102;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#24182;&#20855;&#26377;&#31934;&#30830;&#24674;&#22797;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2311.00674</link><description>&lt;p&gt;
&#36890;&#36807;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;Cholesky&#20998;&#35299;&#24674;&#22797;&#20855;&#26377;&#28508;&#21464;&#37327;&#30340;&#32447;&#24615;&#22240;&#26524;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Recovering Linear Causal Models with Latent Variables via Cholesky Factorization of Covariance Matrix. (arXiv:2311.00674v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00674
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;Cholesky&#20998;&#35299;&#24674;&#22797;&#20855;&#26377;&#28508;&#21464;&#37327;&#30340;&#32447;&#24615;&#22240;&#26524;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#36895;&#24230;&#21644;&#24615;&#33021;&#19978;&#36229;&#36807;&#20102;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#24182;&#20855;&#26377;&#31934;&#30830;&#24674;&#22797;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#24674;&#22797;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#32467;&#26500;&#26469;&#21457;&#29616;&#22240;&#26524;&#20851;&#31995;&#26159;&#19968;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#12290;&#24403;&#23384;&#22312;&#28508;&#21464;&#37327;&#26102;&#65292;&#35813;&#38382;&#39064;&#21464;&#24471;&#26356;&#21152;&#22256;&#38590;&#12290;&#26412;&#25991;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35266;&#27979;&#25968;&#25454;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;Cholesky&#20998;&#35299;&#30340;DAG&#32467;&#26500;&#24674;&#22797;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#24555;&#36895;&#26131;&#23454;&#29616;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#20445;&#35777;&#20102;&#31934;&#30830;&#24674;&#22797;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#65292;&#35813;&#31639;&#27861;&#27604;&#20043;&#21069;&#30340;&#26041;&#27861;&#24555;&#24471;&#22810;&#65292;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#22312;&#31561;&#35823;&#24046;&#26041;&#24046;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#23558;&#20248;&#21270;&#36807;&#31243;&#19982;&#22522;&#20110;Cholesky&#20998;&#35299;&#30340;&#31639;&#27861;&#32467;&#21512;&#36215;&#26469;&#65292;&#22788;&#29702;&#20855;&#26377;&#28508;&#21464;&#37327;&#30340;DAG&#24674;&#22797;&#38382;&#39064;&#12290;&#25968;&#20540;&#27169;&#25311;&#34920;&#26126;&#65292;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#65292;&#20462;&#27491;&#30340;&#8220;Cholesky + &#20248;&#21270;&#8221;&#31639;&#27861;&#33021;&#22815;&#24674;&#22797;&#20986;&#30495;&#23454;&#30340;&#22270;&#65292;&#24182;&#19988;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Discovering the causal relationship via recovering the directed acyclic graph (DAG) structure from the observed data is a well-known challenging combinatorial problem. When there are latent variables, the problem becomes even more difficult. In this paper, we first propose a DAG structure recovering algorithm, which is based on the Cholesky factorization of the covariance matrix of the observed data. The algorithm is fast and easy to implement and has theoretical grantees for exact recovery. On synthetic and real-world datasets, the algorithm is significantly faster than previous methods and achieves the state-of-the-art performance. Furthermore, under the equal error variances assumption, we incorporate an optimization procedure into the Cholesky factorization based algorithm to handle the DAG recovering problem with latent variables. Numerical simulations show that the modified "Cholesky + optimization" algorithm is able to recover the ground truth graph in most cases and outperforms
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#23558;&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;&#21644;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#24212;&#29992;&#20110;&#35299;&#20915;&#32447;&#24615;&#36870;&#38382;&#39064;&#65292;&#22312;&#22810;&#31181;&#30149;&#24577;&#31243;&#24230;&#30340;&#36870;&#38382;&#39064;&#20013;&#33719;&#24471;&#20102;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2311.00663</link><description>&lt;p&gt;
&#21464;&#20998;&#39640;&#26031;&#36807;&#31243;&#29992;&#20110;&#32447;&#24615;&#36870;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Variational Gaussian Processes For Linear Inverse Problems. (arXiv:2311.00663v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00663
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#23558;&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;&#21644;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#24212;&#29992;&#20110;&#35299;&#20915;&#32447;&#24615;&#36870;&#38382;&#39064;&#65292;&#22312;&#22810;&#31181;&#30149;&#24577;&#31243;&#24230;&#30340;&#36870;&#38382;&#39064;&#20013;&#33719;&#24471;&#20102;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#65292;&#36125;&#21494;&#26031;&#26041;&#27861;&#22312;&#35299;&#20915;&#36870;&#38382;&#39064;&#26041;&#38754;&#24050;&#32463;&#25104;&#20026;&#24120;&#35268;&#23454;&#36341;&#12290;&#22312;&#36870;&#38382;&#39064;&#20013;&#65292;&#20851;&#27880;&#30340;&#21442;&#25968;&#25110;&#20449;&#21495;&#21482;&#33021;&#20197;&#32473;&#23450;&#22320;&#22270;&#30340;&#22270;&#20687;&#26041;&#24335;&#38388;&#25509;&#35266;&#23519;&#21040;&#65292;&#24182;&#19988;&#35266;&#27979;&#36890;&#24120;&#21463;&#21040;&#22122;&#22768;&#30340;&#24433;&#21709;&#12290;&#36125;&#21494;&#26031;&#25552;&#20379;&#20102;&#36890;&#36807;&#20808;&#39564;&#20998;&#24067;&#23545;&#36825;&#20123;&#38382;&#39064;&#36827;&#34892;&#27491;&#21017;&#21270;&#30340;&#33258;&#28982;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#27010;&#29575;&#35299;&#65292;&#37327;&#21270;&#38382;&#39064;&#20013;&#21097;&#20313;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#28982;&#32780;&#65292;&#26631;&#20934;&#30340;&#22522;&#20110;&#26679;&#26412;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#22312;&#36825;&#31181;&#22797;&#26434;&#27169;&#22411;&#20013;&#30340;&#35745;&#31639;&#25104;&#26412;&#21487;&#33021;&#20250;&#36807;&#39640;&#12290;&#22240;&#27492;&#65292;&#21464;&#20998;&#36125;&#21494;&#26031;&#22312;&#23454;&#36341;&#20013;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#23545;&#36825;&#20123;&#26041;&#27861;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#30456;&#23545;&#26377;&#38480;&#65292;&#29305;&#21035;&#26159;&#22312;&#36870;&#38382;&#39064;&#30340;&#32972;&#26223;&#19979;&#12290;&#22312;&#25105;&#20204;&#30340;&#20998;&#26512;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#29992;&#20110;&#35299;&#20915;&#32447;&#24615;&#36870;&#38382;&#39064;&#30340;&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;&#21644;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#36731;&#24230;&#21644;&#20005;&#37325;&#30149;&#24577;&#36870;&#38382;&#39064;&#65292;&#24182;&#19982;&#27969;&#34892;&#30340;&#24341;&#21457;&#21464;&#37327;&#26041;&#27861;&#21512;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
By now Bayesian methods are routinely used in practice for solving inverse problems. In inverse problems the parameter or signal of interest is observed only indirectly, as an image of a given map, and the observations are typically further corrupted with noise. Bayes offers a natural way to regularize these problems via the prior distribution and provides a probabilistic solution, quantifying the remaining uncertainty in the problem. However, the computational costs of standard, sampling based Bayesian approaches can be overly large in such complex models. Therefore, in practice variational Bayes is becoming increasingly popular. Nevertheless, the theoretical understanding of these methods is still relatively limited, especially in context of inverse problems. In our analysis we investigate variational Bayesian methods for Gaussian process priors to solve linear inverse problems. We consider both mildly and severely ill-posed inverse problems and work with the popular inducing variabl
&lt;/p&gt;</description></item><item><title>&#26412;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#20811;&#32599;&#20869;&#20811;&#36817;&#20284;&#26354;&#29575;&#31639;&#27861;&#65292;&#21487;&#20197;&#21152;&#36895;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#21644;&#20943;&#23569;&#35745;&#31639;&#25104;&#26412;&#12290;&#20316;&#32773;&#21457;&#29616;&#20102;&#20004;&#31181;&#20855;&#26377;&#32447;&#24615;&#26435;&#37325;&#20849;&#20139;&#23618;&#19981;&#21516;&#35774;&#32622;&#65292;&#24182;&#35777;&#26126;&#20102;&#30456;&#24212;&#35774;&#32622;&#19979;&#30340;K-FAC&#31639;&#27861;&#30340;&#31934;&#30830;&#24615;&#12290;K-FAC-reduce&#36890;&#24120;&#27604;K-FAC-expand&#26356;&#24555;&#65292;&#21487;&#20197;&#29992;&#20110;&#21152;&#36895;&#33258;&#21160;&#36229;&#21442;&#25968;&#36873;&#25321;&#12290;</title><link>http://arxiv.org/abs/2311.00636</link><description>&lt;p&gt;
Kronecker-Factored Approximate Curvature for Modern Neural Network Architectures&#65288;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#20811;&#32599;&#20869;&#20811;&#36817;&#20284;&#26354;&#29575;&#65289;
&lt;/p&gt;
&lt;p&gt;
Kronecker-Factored Approximate Curvature for Modern Neural Network Architectures. (arXiv:2311.00636v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00636
&lt;/p&gt;
&lt;p&gt;
&#26412;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#20811;&#32599;&#20869;&#20811;&#36817;&#20284;&#26354;&#29575;&#31639;&#27861;&#65292;&#21487;&#20197;&#21152;&#36895;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#21644;&#20943;&#23569;&#35745;&#31639;&#25104;&#26412;&#12290;&#20316;&#32773;&#21457;&#29616;&#20102;&#20004;&#31181;&#20855;&#26377;&#32447;&#24615;&#26435;&#37325;&#20849;&#20139;&#23618;&#19981;&#21516;&#35774;&#32622;&#65292;&#24182;&#35777;&#26126;&#20102;&#30456;&#24212;&#35774;&#32622;&#19979;&#30340;K-FAC&#31639;&#27861;&#30340;&#31934;&#30830;&#24615;&#12290;K-FAC-reduce&#36890;&#24120;&#27604;K-FAC-expand&#26356;&#24555;&#65292;&#21487;&#20197;&#29992;&#20110;&#21152;&#36895;&#33258;&#21160;&#36229;&#21442;&#25968;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#26680;&#24515;&#32452;&#20214;&#65292;&#22914;transformers&#12289;&#21367;&#31215;&#25110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20197;&#34920;&#36798;&#20026;&#20855;&#26377;&#8220;&#26435;&#37325;&#20849;&#20139;&#8221;&#30340;&#32447;&#24615;&#23618;&#12290;&#20811;&#32599;&#20869;&#20811;&#36817;&#20284;&#26354;&#29575;&#65288;K-FAC&#65289;&#26159;&#19968;&#31181;&#20108;&#38454;&#20248;&#21270;&#26041;&#27861;&#65292;&#24050;&#26174;&#31034;&#20986;&#21152;&#36895;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#24182;&#20943;&#23569;&#35745;&#31639;&#25104;&#26412;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#36824;&#27809;&#26377;&#23558;&#20854;&#24212;&#29992;&#20110;&#36890;&#29992;&#30340;&#26550;&#26500;&#30340;&#26694;&#26550;&#65292;&#29305;&#21035;&#26159;&#20855;&#26377;&#32447;&#24615;&#26435;&#37325;&#20849;&#20139;&#23618;&#30340;&#26550;&#26500;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#20855;&#26377;&#32447;&#24615;&#26435;&#37325;&#20849;&#20139;&#23618;&#30340;&#20004;&#31181;&#19981;&#21516;&#35774;&#32622;&#65292;&#36825;&#20419;&#20351;&#20102;&#20004;&#31181;K-FAC&#30340;&#21464;&#20307;&#8212;&#8212;&#8220;&#25193;&#23637;&#8221;&#21644;&#8220;&#20943;&#23569;&#8221;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#23545;&#20110;&#20855;&#26377;&#30456;&#24212;&#35774;&#32622;&#30340;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#65292;&#23427;&#20204;&#26159;&#31934;&#30830;&#30340;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;K-FAC-reduce&#36890;&#24120;&#27604;K-FAC-expand&#26356;&#24555;&#65292;&#25105;&#20204;&#21033;&#29992;&#23427;&#26469;&#21152;&#36895;&#36890;&#36807;&#20248;&#21270;Wide ResNet&#30340;&#36793;&#38469;&#20284;&#28982;&#26469;&#36873;&#25321;&#33258;&#21160;&#36229;&#21442;&#25968;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#22312;
&lt;/p&gt;
&lt;p&gt;
The core components of many modern neural network architectures, such as transformers, convolutional, or graph neural networks, can be expressed as linear layers with $\textit{weight-sharing}$. Kronecker-Factored Approximate Curvature (K-FAC), a second-order optimisation method, has shown promise to speed up neural network training and thereby reduce computational costs. However, there is currently no framework to apply it to generic architectures, specifically ones with linear weight-sharing layers. In this work, we identify two different settings of linear weight-sharing layers which motivate two flavours of K-FAC -- $\textit{expand}$ and $\textit{reduce}$. We show that they are exact for deep linear networks with weight-sharing in their respective setting. Notably, K-FAC-reduce is generally faster than K-FAC-expand, which we leverage to speed up automatic hyperparameter selection via optimising the marginal likelihood for a Wide ResNet. Finally, we observe little difference between 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28789;&#27963;&#30340;&#23614;&#37096;&#36716;&#25442;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#24402;&#19968;&#21270;&#27969;&#26469;&#36817;&#20284;&#37329;&#34701;&#22238;&#25253;&#30340;&#37325;&#23614;&#20998;&#24067;&#65292;&#33021;&#22815;&#25429;&#25417;&#21487;&#33021;&#20986;&#29616;&#22312;&#25968;&#25454;&#20013;&#30340;&#26497;&#31471;&#20914;&#20987;&#12290;</title><link>http://arxiv.org/abs/2311.00580</link><description>&lt;p&gt;
&#28789;&#27963;&#30340;&#23614;&#37096;&#29992;&#20110;&#24402;&#19968;&#21270;&#27969;&#65292;&#24212;&#29992;&#20110;&#37329;&#34701;&#22238;&#25253;&#25968;&#25454;&#30340;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Flexible Tails for Normalising Flows, with Application to the Modelling of Financial Return Data. (arXiv:2311.00580v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00580
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28789;&#27963;&#30340;&#23614;&#37096;&#36716;&#25442;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#24402;&#19968;&#21270;&#27969;&#26469;&#36817;&#20284;&#37329;&#34701;&#22238;&#25253;&#30340;&#37325;&#23614;&#20998;&#24067;&#65292;&#33021;&#22815;&#25429;&#25417;&#21487;&#33021;&#20986;&#29616;&#22312;&#25968;&#25454;&#20013;&#30340;&#26497;&#31471;&#20914;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#25913;&#21464;&#20998;&#24067;&#23614;&#37096;&#29305;&#24615;&#30340;&#36716;&#25442;&#26041;&#27861;&#65292;&#21463;&#21040;&#26497;&#20540;&#29702;&#35770;&#30340;&#21551;&#21457;&#65292;&#21487;&#20197;&#20316;&#20026;&#24402;&#19968;&#21270;&#27969;&#20013;&#30340;&#19968;&#23618;&#65292;&#26469;&#36817;&#20284;&#22810;&#21464;&#37327;&#37325;&#23614;&#20998;&#24067;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#26041;&#27861;&#24212;&#29992;&#20110;&#37329;&#34701;&#22238;&#25253;&#24314;&#27169;&#65292;&#25429;&#25417;&#21487;&#33021;&#20986;&#29616;&#22312;&#27492;&#31867;&#25968;&#25454;&#20013;&#30340;&#26497;&#31471;&#20914;&#20987;&#12290;&#35757;&#32451;&#22909;&#30340;&#27169;&#22411;&#21487;&#20197;&#30452;&#25509;&#29992;&#20110;&#29983;&#25104;&#21487;&#33021;&#30340;&#26497;&#31471;&#22238;&#25253;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a transformation capable of altering the tail properties of a distribution, motivated by extreme value theory, which can be used as a layer in a normalizing flow to approximate multivariate heavy tailed distributions. We apply this approach to model financial returns, capturing potentially extreme shocks that arise in such data. The trained models can be used directly to generate new synthetic sets of potentially extreme returns
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20010;&#24615;&#21270;&#20998;&#37197;&#33267;&#22810;&#20010;&#27835;&#30103;&#32452;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27491;&#21017;&#21270;&#21644;&#32858;&#31867;&#20248;&#21270;&#27835;&#30103;&#20998;&#37197;&#65292;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#25928;&#26524;&#20272;&#35745;&#21644;&#20010;&#24615;&#21270;&#25928;&#30410;&#12290;</title><link>http://arxiv.org/abs/2311.00577</link><description>&lt;p&gt;
&#36890;&#36807;&#27491;&#21017;&#21270;&#21644;&#32858;&#31867;&#32852;&#21512;&#20998;&#37197;&#26862;&#26519;&#36827;&#34892;&#20010;&#24615;&#21270;&#20998;&#37197;&#33267;&#22810;&#20010;&#27835;&#30103;&#32452;
&lt;/p&gt;
&lt;p&gt;
Personalized Assignment to One of Many Treatment Arms via Regularized and Clustered Joint Assignment Forests. (arXiv:2311.00577v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00577
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20010;&#24615;&#21270;&#20998;&#37197;&#33267;&#22810;&#20010;&#27835;&#30103;&#32452;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27491;&#21017;&#21270;&#21644;&#32858;&#31867;&#20248;&#21270;&#27835;&#30103;&#20998;&#37197;&#65292;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#25928;&#26524;&#20272;&#35745;&#21644;&#20010;&#24615;&#21270;&#25928;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#20013;&#23398;&#20064;&#20010;&#24615;&#21270;&#30340;&#20998;&#37197;&#33267;&#22810;&#20010;&#27835;&#30103;&#32452;&#12290;&#30001;&#20110;&#36807;&#22810;&#30340;&#26041;&#24046;&#65292;&#23545;&#20110;&#27599;&#20010;&#27835;&#30103;&#32452;&#20998;&#21035;&#20272;&#35745;&#24322;&#36136;&#27835;&#30103;&#25928;&#26524;&#30340;&#26631;&#20934;&#26041;&#27861;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#21487;&#33021;&#34920;&#29616;&#19981;&#20339;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#27719;&#24635;&#27835;&#30103;&#32452;&#20449;&#24687;&#30340;&#26041;&#27861;&#65306;&#39318;&#20808;&#65292;&#25105;&#20204;&#32771;&#34385;&#22522;&#20110;&#36138;&#23146;&#36882;&#24402;&#20998;&#21306;&#30340;&#27491;&#21017;&#21270;&#26862;&#26519;&#20998;&#37197;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21487;&#32553;&#23567;&#19981;&#21516;&#27835;&#30103;&#32452;&#20043;&#38388;&#30340;&#25928;&#26524;&#20272;&#35745;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#36890;&#36807;&#32858;&#31867;&#26041;&#26696;&#23558;&#27835;&#30103;&#32452;&#19982;&#20855;&#26377;&#19968;&#33268;&#30456;&#20284;&#32467;&#26524;&#30340;&#32452;&#21512;&#36215;&#26469;&#65292;&#22686;&#24378;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#12290;&#22312;&#27169;&#25311;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#26041;&#27861;&#19982;&#20998;&#21035;&#39044;&#27979;&#27599;&#20010;&#27835;&#30103;&#32452;&#32467;&#26524;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#24182;&#35760;&#24405;&#20102;&#36890;&#36807;&#27491;&#21017;&#21270;&#21644;&#32858;&#31867;&#30452;&#25509;&#20248;&#21270;&#27835;&#30103;&#20998;&#37197;&#24102;&#26469;&#30340;&#25910;&#30410;&#12290;&#22312;&#19968;&#20010;&#29702;&#35770;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#35828;&#26126;&#27835;&#30103;&#32452;&#25968;&#37327;&#36739;&#22810;&#26102;&#25214;&#21040;&#26368;&#20339;&#32452;&#30340;&#22256;&#38590;&#65292;&#32780;&#36890;&#36807;&#27491;&#21017;&#21270;&#21644;&#32858;&#31867;&#21487;&#20197;&#23454;&#29616;&#20010;&#24615;&#21270;&#30340;&#26126;&#26174;&#25928;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider learning personalized assignments to one of many treatment arms from a randomized controlled trial. Standard methods that estimate heterogeneous treatment effects separately for each arm may perform poorly in this case due to excess variance. We instead propose methods that pool information across treatment arms: First, we consider a regularized forest-based assignment algorithm based on greedy recursive partitioning that shrinks effect estimates across arms. Second, we augment our algorithm by a clustering scheme that combines treatment arms with consistently similar outcomes. In a simulation study, we compare the performance of these approaches to predicting arm-wise outcomes separately, and document gains of directly optimizing the treatment assignment with regularization and clustering. In a theoretical model, we illustrate how a high number of treatment arms makes finding the best arm hard, while we can achieve sizable utility gains from personalization by regularized 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#21644;&#28789;&#27963;&#30340;&#26435;&#37325;&#26041;&#27861;&#65292;&#22312;&#20840;&#22269;&#33539;&#22260;&#20869;&#30340;&#35266;&#23519;&#24615;&#30740;&#31350;&#20013;&#24212;&#29992;&#20110;&#21307;&#38498;&#30408;&#21033;&#29366;&#20917;&#21644;&#24515;&#33039;&#30149;&#21457;&#20316;&#32467;&#26524;&#12290;&#36825;&#31181;&#26041;&#27861;&#21033;&#29992;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;&#22522;&#20989;&#25968;&#25193;&#23637;&#21644;&#20984;&#20248;&#21270;&#25216;&#26415;&#65292;&#35299;&#20915;&#20102;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#20013;&#24179;&#34913;&#22522;&#20989;&#25968;&#20998;&#24067;&#30340;&#23454;&#38469;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2311.00568</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;&#26680;&#24179;&#34913;&#26435;&#37325;&#22312;&#20840;&#22269;&#33539;&#22260;&#20869;&#21307;&#38498;&#30408;&#21033;&#29366;&#20917;&#21644;&#24515;&#33039;&#30149;&#21457;&#20316;&#32467;&#26524;&#30340;&#35266;&#23519;&#24615;&#30740;&#31350;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Scalable kernel balancing weights in a nationwide observational study of hospital profit status and heart attack outcomes. (arXiv:2311.00568v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00568
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#21644;&#28789;&#27963;&#30340;&#26435;&#37325;&#26041;&#27861;&#65292;&#22312;&#20840;&#22269;&#33539;&#22260;&#20869;&#30340;&#35266;&#23519;&#24615;&#30740;&#31350;&#20013;&#24212;&#29992;&#20110;&#21307;&#38498;&#30408;&#21033;&#29366;&#20917;&#21644;&#24515;&#33039;&#30149;&#21457;&#20316;&#32467;&#26524;&#12290;&#36825;&#31181;&#26041;&#27861;&#21033;&#29992;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;&#22522;&#20989;&#25968;&#25193;&#23637;&#21644;&#20984;&#20248;&#21270;&#25216;&#26415;&#65292;&#35299;&#20915;&#20102;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#20013;&#24179;&#34913;&#22522;&#20989;&#25968;&#20998;&#24067;&#30340;&#23454;&#38469;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26435;&#37325;&#26159;&#19968;&#31181;&#24120;&#29992;&#30340;&#32479;&#35745;&#35843;&#25972;&#26041;&#27861;&#12290;&#26435;&#37325;&#20855;&#26377;&#20004;&#20010;&#30446;&#26631;&#65306;&#39318;&#20808;&#65292;&#24179;&#34913;&#21327;&#21464;&#37327;&#20998;&#24067;&#65307;&#20854;&#27425;&#65292;&#30830;&#20445;&#26435;&#37325;&#30340;&#26368;&#23567;&#20998;&#25955;&#24615;&#65292;&#20174;&#32780;&#20135;&#29983;&#26356;&#31283;&#23450;&#30340;&#20272;&#35745;&#32467;&#26524;&#12290;&#26368;&#36817;&#65292;&#19968;&#31181;&#36234;&#26469;&#36234;&#24120;&#35265;&#30340;&#26041;&#27861;&#30452;&#25509;&#20248;&#21270;&#26435;&#37325;&#20197;&#23454;&#29616;&#36825;&#20004;&#20010;&#30446;&#26631;&#12290;&#28982;&#32780;&#65292;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#20013;&#65292;&#24403;&#30740;&#31350;&#32773;&#24076;&#26395;&#22312;&#25193;&#23637;&#30340;&#29305;&#24449;&#31354;&#38388;&#20013;&#28789;&#27963;&#24179;&#34913;&#19968;&#33324;&#22522;&#20989;&#25968;&#26102;&#65292;&#36825;&#31181;&#26041;&#27861;&#23578;&#19981;&#21487;&#34892;&#12290;&#20363;&#22914;&#65292;&#35768;&#22810;&#24179;&#34913;&#26041;&#27861;&#26080;&#27861;&#25193;&#23637;&#21040;&#20840;&#22269;&#32423;&#30340;&#20581;&#24247;&#26381;&#21153;&#30740;&#31350;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#23454;&#38469;&#38382;&#39064;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#21644;&#28789;&#27963;&#30340;&#26435;&#37325;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23558;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#22522;&#20989;&#25968;&#25193;&#23637;&#19982;&#26368;&#20808;&#36827;&#30340;&#20984;&#20248;&#21270;&#25216;&#26415;&#32467;&#21512;&#36215;&#26469;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#38480;&#21046;&#31209;&#30340;Nystr&#246;m&#26041;&#27861;&#26469;&#39640;&#25928;&#22320;&#35745;&#31639;&#29992;&#20110;&#24179;&#34913;&#30340;&#26680;&#22522;&#20989;&#25968;&#65292;&#26368;&#32456;&#23454;&#29616;&#20102;&#36817;&#32447;&#24615;&#30340;&#26102;&#38388;&#21644;&#31354;&#38388;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Weighting is a general and often-used method for statistical adjustment. Weighting has two objectives: first, to balance covariate distributions, and second, to ensure that the weights have minimal dispersion and thus produce a more stable estimator. A recent, increasingly common approach directly optimizes the weights toward these two objectives. However, this approach has not yet been feasible in large-scale datasets when investigators wish to flexibly balance general basis functions in an extended feature space. For example, many balancing approaches cannot scale to national-level health services research studies. To address this practical problem, we describe a scalable and flexible approach to weighting that integrates a basis expansion in a reproducing kernel Hilbert space with state-of-the-art convex optimization techniques. Specifically, we use the rank-restricted Nystr\"{o}m method to efficiently compute a kernel basis for balancing in {nearly} linear time and space, and then 
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25972;&#20307;-&#23616;&#37096;&#23610;&#24230;&#32467;&#26500;&#30340;&#36125;&#21494;&#26031;&#23398;&#29983;-t&#36807;&#31243;&#28151;&#21512;&#27169;&#22411;&#65292;&#21487;&#29992;&#20110;&#24314;&#27169;&#38750;&#24179;&#31283;&#25968;&#25454;&#65292;&#36890;&#36807;&#23454;&#26102;&#25509;&#25910;&#25968;&#25454;&#36827;&#34892;&#22312;&#32447;&#25512;&#26029;&#12290;&#22312;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#23545;&#27604;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.00564</link><description>&lt;p&gt;
&#22312;&#24314;&#27169;&#38750;&#24179;&#31283;&#25968;&#25454;&#26102;&#21033;&#29992;&#25972;&#20307;-&#23616;&#37096;&#23610;&#24230;&#32467;&#26500;&#30340;&#22312;&#32447;&#23398;&#29983;-t&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Online Student-$t$ Processes with an Overall-local Scale Structure for Modelling Non-stationary Data. (arXiv:2311.00564v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00564
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25972;&#20307;-&#23616;&#37096;&#23610;&#24230;&#32467;&#26500;&#30340;&#36125;&#21494;&#26031;&#23398;&#29983;-t&#36807;&#31243;&#28151;&#21512;&#27169;&#22411;&#65292;&#21487;&#29992;&#20110;&#24314;&#27169;&#38750;&#24179;&#31283;&#25968;&#25454;&#65292;&#36890;&#36807;&#23454;&#26102;&#25509;&#25910;&#25968;&#25454;&#36827;&#34892;&#22312;&#32447;&#25512;&#26029;&#12290;&#22312;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#23545;&#27604;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#30456;&#20851;&#30340;&#25968;&#25454;&#36890;&#24120;&#34920;&#29616;&#20986;&#38750;&#24179;&#31283;&#24615;&#21644;&#37325;&#23614;&#35823;&#24046;&#31561;&#29305;&#24449;&#65292;&#36825;&#20123;&#29305;&#24449;&#19981;&#36866;&#21512;&#37319;&#29992;&#24120;&#35265;&#27169;&#22411;&#25152;&#20351;&#29992;&#30340;&#20551;&#35774;&#36827;&#34892;&#24314;&#27169;&#12290;&#22240;&#27492;&#65292;&#38656;&#35201;&#26356;&#28789;&#27963;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#36825;&#20123;&#38382;&#39064;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#23398;&#29983;-t&#36807;&#31243;&#28151;&#21512;&#27169;&#22411;&#65292;&#20854;&#21327;&#26041;&#24046;&#20855;&#26377;&#25972;&#20307;-&#23616;&#37096;&#23610;&#24230;&#32467;&#26500;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#65288;SMC&#65289;&#37319;&#26679;&#22120;&#36827;&#34892;&#22312;&#32447;&#25512;&#26029;&#65292;&#20197;&#23454;&#26102;&#25509;&#25910;&#25968;&#25454;&#12290;&#36890;&#36807;&#22312;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30456;&#23545;&#20110;&#20856;&#22411;&#30340;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#30340;&#27169;&#22411;&#30340;&#21331;&#36234;&#24615;&#33021;&#65292;&#20197;&#35777;&#26126;&#20351;&#29992;&#23398;&#29983;-t&#36807;&#31243;&#28151;&#21512;&#27169;&#22411;&#30340;&#24517;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Time-dependent data often exhibit characteristics, such as non-stationarity and heavy-tailed errors, that would be inappropriate to model with the typical assumptions used in popular models. Thus, more flexible approaches are required to be able to accommodate such issues. To this end, we propose a Bayesian mixture of student-$t$ processes with an overall-local scale structure for the covariance. Moreover, we use a sequential Monte Carlo (SMC) sampler in order to perform online inference as data arrive in real-time. We demonstrate the superiority of our proposed approach compared to typical Gaussian process-based models on real-world data sets in order to prove the necessity of using mixtures of student-$t$ processes.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#24102;&#26377;&#22266;&#26377;&#22122;&#22768;&#21644;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#30340;&#38543;&#26426;&#35745;&#31639;&#27169;&#22411;&#30340;&#22810;&#39033;&#24335;&#28151;&#27788;&#20195;&#29702;&#26500;&#24314;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2311.00553</link><description>&lt;p&gt;
&#38024;&#23545;&#24102;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#30340;&#38543;&#26426;&#22330;&#30340;&#22810;&#39033;&#24335;&#28151;&#27788;&#20195;&#29702;&#26500;&#24314;
&lt;/p&gt;
&lt;p&gt;
Polynomial Chaos Surrogate Construction for Random Fields with Parametric Uncertainty. (arXiv:2311.00553v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00553
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#24102;&#26377;&#22266;&#26377;&#22122;&#22768;&#21644;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#30340;&#38543;&#26426;&#35745;&#31639;&#27169;&#22411;&#30340;&#22810;&#39033;&#24335;&#28151;&#27788;&#20195;&#29702;&#26500;&#24314;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24037;&#31243;&#21644;&#24212;&#29992;&#31185;&#23398;&#20381;&#38752;&#35745;&#31639;&#23454;&#39564;&#26469;&#20005;&#35880;&#22320;&#30740;&#31350;&#29289;&#29702;&#31995;&#32479;&#12290;&#29992;&#20110;&#25506;&#31350;&#36825;&#20123;&#31995;&#32479;&#30340;&#25968;&#23398;&#27169;&#22411;&#38750;&#24120;&#22797;&#26434;&#65292;&#32780;&#19988;&#37319;&#26679;&#23494;&#38598;&#30340;&#30740;&#31350;&#36890;&#24120;&#38656;&#35201;&#22823;&#37327;&#27169;&#25311;&#20197;&#33719;&#24471;&#21487;&#25509;&#21463;&#30340;&#20934;&#30830;&#24615;&#12290;&#20195;&#29702;&#27169;&#22411;&#20026;&#36991;&#20813;&#37319;&#26679;&#36825;&#20123;&#22797;&#26434;&#27169;&#22411;&#30340;&#39640;&#35745;&#31639;&#24320;&#38144;&#25552;&#20379;&#20102;&#19968;&#31181;&#26041;&#27861;&#12290;&#23588;&#20854;&#26159;&#65292;&#22312;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#20026;&#20027;&#35201;&#19981;&#30830;&#23450;&#22240;&#32032;&#30340;&#30830;&#23450;&#24615;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30740;&#31350;&#20013;&#65292;&#22810;&#39033;&#24335;&#28151;&#27788;&#23637;&#24320;&#65288;PCEs&#65289;&#24050;&#32463;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#19968;&#31181;&#23545;&#20256;&#32479;&#30340;PCE&#20195;&#29702;&#27169;&#22411;&#30340;&#25193;&#23637;&#65292;&#20197;&#23454;&#29616;&#23545;&#20855;&#26377;&#22266;&#26377;&#22122;&#22768;&#21644;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#30340;&#38543;&#26426;&#35745;&#31639;&#27169;&#22411;&#30340;&#20195;&#29702;&#26500;&#24314;&#12290;&#25105;&#20204;&#36890;&#36807;Rosenblatt&#21464;&#25442;&#22312;&#22266;&#26377;&#21644;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#30340;&#32852;&#21512;&#31354;&#38388;&#19978;&#24320;&#21457;&#20102;&#19968;&#20010;PCE&#20195;&#29702;&#65292;&#28982;&#21518;&#36890;&#36807;Karhunen-Loeve&#23637;&#24320;&#23558;&#20854;&#25193;&#23637;&#21040;&#38543;&#26426;&#22330;&#25968;&#25454;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
Engineering and applied science rely on computational experiments to rigorously study physical systems. The mathematical models used to probe these systems are highly complex, and sampling-intensive studies often require prohibitively many simulations for acceptable accuracy. Surrogate models provide a means of circumventing the high computational expense of sampling such complex models. In particular, polynomial chaos expansions (PCEs) have been successfully used for uncertainty quantification studies of deterministic models where the dominant source of uncertainty is parametric. We discuss an extension to conventional PCE surrogate modeling to enable surrogate construction for stochastic computational models that have intrinsic noise in addition to parametric uncertainty. We develop a PCE surrogate on a joint space of intrinsic and parametric uncertainty, enabled by Rosenblatt transformations, and then extend the construction to random field data via the Karhunen-Loeve expansion. We 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#31232;&#30095;&#32447;&#24615;bandit&#20013;&#30340;&#22266;&#23450;&#39044;&#31639;&#26465;&#20214;&#19979;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#35774;&#35745;&#20102;&#22522;&#20110;Lasso&#21644;&#26368;&#20248;&#35774;&#35745;&#30340;&#20004;&#38454;&#27573;&#31639;&#27861;&#65292;&#36890;&#36807;&#36866;&#24403;&#36873;&#25321;&#36229;&#21442;&#25968;&#21644;&#24179;&#34913;&#20004;&#20010;&#38454;&#27573;&#30340;&#38169;&#35823;&#27010;&#29575;&#65292;&#24471;&#21040;&#20102;Lasso-OD&#30340;&#38750;&#28176;&#36817;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2311.00481</link><description>&lt;p&gt;
&#22312;&#31232;&#30095;&#32447;&#24615;bandit&#20013;&#30340;&#22266;&#23450;&#39044;&#31639;&#19979;&#65292;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Fixed-Budget Best-Arm Identification in Sparse Linear Bandits. (arXiv:2311.00481v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00481
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#31232;&#30095;&#32447;&#24615;bandit&#20013;&#30340;&#22266;&#23450;&#39044;&#31639;&#26465;&#20214;&#19979;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#35774;&#35745;&#20102;&#22522;&#20110;Lasso&#21644;&#26368;&#20248;&#35774;&#35745;&#30340;&#20004;&#38454;&#27573;&#31639;&#27861;&#65292;&#36890;&#36807;&#36866;&#24403;&#36873;&#25321;&#36229;&#21442;&#25968;&#21644;&#24179;&#34913;&#20004;&#20010;&#38454;&#27573;&#30340;&#38169;&#35823;&#27010;&#29575;&#65292;&#24471;&#21040;&#20102;Lasso-OD&#30340;&#38750;&#28176;&#36817;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#31232;&#30095;&#32447;&#24615;bandit&#20013;&#30340;&#22266;&#23450;&#39044;&#31639;&#26465;&#20214;&#19979;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#22312;&#31232;&#30095;&#32447;&#24615;bandit&#20013;&#65292;&#26410;&#30693;&#29305;&#24449;&#21521;&#37327;&#952;*&#21487;&#33021;&#20855;&#26377;&#24456;&#22823;&#30340;&#32500;&#24230;d&#65292;&#20294;&#21482;&#26377;&#19968;&#23567;&#37096;&#20998;&#29305;&#24449;&#65288;&#27604;&#22914;s&#20010;&#65289;&#20855;&#26377;&#38750;&#38646;&#20540;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#30340;&#31639;&#27861;&#65292;&#21363;&#22522;&#20110;Lasso&#21644;&#26368;&#20248;&#35774;&#35745;(Lasso-OD)&#30340;&#32447;&#24615;&#26368;&#20339;&#33218;&#35782;&#21035;&#12290;Lasso-OD&#30340;&#31532;&#19968;&#38454;&#27573;&#21033;&#29992;&#20102;&#29305;&#24449;&#21521;&#37327;&#30340;&#31232;&#30095;&#24615;&#65292;&#36890;&#36807;&#24212;&#29992;Zhou&#65288;2009&#65289;&#24341;&#20837;&#30340;&#38408;&#20540;&#21270;Lasso&#65292;&#21033;&#29992;&#25152;&#36873;&#25321;&#30340;&#33218;&#30340;&#22238;&#25253;&#21644;&#21512;&#29702;&#36873;&#25321;&#30340;&#35774;&#35745;&#30697;&#38453;&#26469;&#39640;&#27010;&#29575;&#22320;&#27491;&#30830;&#20272;&#35745;&#952;*&#30340;&#25903;&#25345;&#38598;&#12290;Lasso-OD&#30340;&#31532;&#20108;&#38454;&#27573;&#22312;&#20272;&#35745;&#24471;&#21040;&#30340;&#25903;&#25345;&#38598;&#19978;&#24212;&#29992;&#20102;Yang&#21644;Tan&#65288;2022&#65289;&#25552;&#20986;&#30340;OD-LinBAI&#31639;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#31934;&#24515;&#36873;&#25321;&#36229;&#21442;&#25968;&#65288;&#22914;Lasso&#30340;&#27491;&#21017;&#21270;&#21442;&#25968;&#65289;&#21644;&#24179;&#34913;&#20004;&#20010;&#38454;&#27573;&#30340;&#38169;&#35823;&#27010;&#29575;&#65292;&#25512;&#23548;&#20102;Lasso-OD&#30340;&#38750;&#28176;&#36817;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the best-arm identification problem in sparse linear bandits under the fixed-budget setting. In sparse linear bandits, the unknown feature vector $\theta^*$ may be of large dimension $d$, but only a few, say $s \ll d$ of these features have non-zero values. We design a two-phase algorithm, Lasso and Optimal-Design- (Lasso-OD) based linear best-arm identification. The first phase of Lasso-OD leverages the sparsity of the feature vector by applying the thresholded Lasso introduced by Zhou (2009), which estimates the support of $\theta^*$ correctly with high probability using rewards from the selected arms and a judicious choice of the design matrix. The second phase of Lasso-OD applies the OD-LinBAI algorithm by Yang and Tan (2022) on that estimated support. We derive a non-asymptotic upper bound on the error probability of Lasso-OD by carefully choosing hyperparameters (such as Lasso's regularization parameter) and balancing the error probabilities of both phases. For fixed spa
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25193;&#25955;&#27169;&#22411;&#21464;&#20998;&#25512;&#26029;&#65288;DMVI&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#20013;&#36827;&#34892;&#33258;&#21160;&#36817;&#20284;&#25512;&#26029;&#12290;DMVI&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#36827;&#34892;&#21518;&#39564;&#25512;&#26029;&#65292;&#32780;&#19988;&#26131;&#20110;&#23454;&#29616;&#21644;&#20351;&#29992;&#65292;&#23545;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#27809;&#26377;&#20219;&#20309;&#32422;&#26463;&#12290;</title><link>http://arxiv.org/abs/2311.00474</link><description>&lt;p&gt;
&#27010;&#29575;&#32534;&#31243;&#30340;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Diffusion models for probabilistic programming. (arXiv:2311.00474v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00474
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25193;&#25955;&#27169;&#22411;&#21464;&#20998;&#25512;&#26029;&#65288;DMVI&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#20013;&#36827;&#34892;&#33258;&#21160;&#36817;&#20284;&#25512;&#26029;&#12290;DMVI&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#36827;&#34892;&#21518;&#39564;&#25512;&#26029;&#65292;&#32780;&#19988;&#26131;&#20110;&#23454;&#29616;&#21644;&#20351;&#29992;&#65292;&#23545;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#27809;&#26377;&#20219;&#20309;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#25193;&#25955;&#27169;&#22411;&#21464;&#20998;&#25512;&#26029;&#65288;DMVI&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#22312;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#65288;PPL&#65289;&#20013;&#36827;&#34892;&#33258;&#21160;&#36817;&#20284;&#25512;&#26029;&#30340;&#26032;&#26041;&#27861;&#12290;DMVI&#21033;&#29992;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#23545;&#30495;&#23454;&#21518;&#39564;&#20998;&#24067;&#30340;&#21464;&#20998;&#36817;&#20284;&#65292;&#36890;&#36807;&#23548;&#20986;&#36125;&#21494;&#26031;&#24314;&#27169;&#20013;&#20351;&#29992;&#30340;&#36793;&#38469;&#20284;&#28982;&#30446;&#26631;&#30340;&#26032;&#32422;&#26463;&#12290;DMVI&#26131;&#20110;&#23454;&#29616;&#65292;&#22312;PPL&#20013;&#36827;&#34892;&#26080;&#38556;&#30861;&#25512;&#26029;&#65292;&#19981;&#20687;&#20351;&#29992;&#24402;&#19968;&#21270;&#27969;&#30340;&#21464;&#20998;&#25512;&#26029;&#37027;&#26679;&#20855;&#26377;&#32570;&#28857;&#65292;&#24182;&#19988;&#23545;&#22522;&#30784;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#19981;&#20570;&#20219;&#20309;&#32422;&#26463;&#12290;&#25105;&#20204;&#22312;&#19968;&#32452;&#24120;&#35265;&#30340;&#36125;&#21494;&#26031;&#27169;&#22411;&#19978;&#35780;&#20272;&#20102;DMVI&#65292;&#24182;&#34920;&#26126;&#23427;&#30340;&#21518;&#39564;&#25512;&#26029;&#19968;&#33324;&#27604;PPL&#20013;&#20351;&#29992;&#30340;&#29616;&#20195;&#26041;&#27861;&#26356;&#20934;&#30830;&#65292;&#21516;&#26102;&#20855;&#26377;&#31867;&#20284;&#30340;&#35745;&#31639;&#25104;&#26412;&#24182;&#19988;&#38656;&#35201;&#36739;&#23569;&#30340;&#25163;&#21160;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose Diffusion Model Variational Inference (DMVI), a novel method for automated approximate inference in probabilistic programming languages (PPLs). DMVI utilizes diffusion models as variational approximations to the true posterior distribution by deriving a novel bound to the marginal likelihood objective used in Bayesian modelling. DMVI is easy to implement, allows hassle-free inference in PPLs without the drawbacks of, e.g., variational inference using normalizing flows, and does not make any constraints on the underlying neural network model. We evaluate DMVI on a set of common Bayesian models and show that its posterior inferences are in general more accurate than those of contemporary methods used in PPLs while having a similar computational cost and requiring less manual tuning.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20581;&#22766;&#21644;&#20849;&#36717;&#30340;&#39640;&#26031;&#36807;&#31243;&#65288;RCGP&#65289;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#27867;&#21270;&#36125;&#21494;&#26031;&#25512;&#26029;&#23454;&#29616;&#20102;&#21487;&#38752;&#30340;&#38381;&#24335;&#26356;&#26032;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#23454;&#38469;&#24212;&#29992;&#22330;&#26223;&#12290;</title><link>http://arxiv.org/abs/2311.00463</link><description>&lt;p&gt;
&#20581;&#22766;&#21644;&#20849;&#36717;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Robust and Conjugate Gaussian Process Regression. (arXiv:2311.00463v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00463
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20581;&#22766;&#21644;&#20849;&#36717;&#30340;&#39640;&#26031;&#36807;&#31243;&#65288;RCGP&#65289;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#27867;&#21270;&#36125;&#21494;&#26031;&#25512;&#26029;&#23454;&#29616;&#20102;&#21487;&#38752;&#30340;&#38381;&#24335;&#26356;&#26032;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#23454;&#38469;&#24212;&#29992;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#23454;&#29616;&#38381;&#24335;&#26465;&#20214;&#65292;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#22238;&#24402;&#30340;&#24120;&#35265;&#20551;&#35774;&#26159;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#39640;&#26031;&#35266;&#27979;&#22122;&#22768;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#24378;&#20551;&#35774;&#22312;&#23454;&#38469;&#20013;&#32463;&#24120;&#34987;&#36829;&#21453;&#65292;&#23548;&#33268;&#19981;&#21487;&#38752;&#30340;&#25512;&#26029;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#27867;&#21270;&#36125;&#21494;&#26031;&#25512;&#26029;&#20197;&#20960;&#20046;&#27809;&#26377;&#39069;&#22806;&#20195;&#20215;&#23454;&#29616;&#21487;&#38752;&#21644;&#20849;&#36717;&#30340;&#39640;&#26031;&#36807;&#31243;&#65288;RCGP&#65289;&#22238;&#24402;&#12290;RCGP&#20855;&#26377;&#24456;&#39640;&#30340;&#28789;&#27963;&#24615;&#65292;&#21487;&#20197;&#22312;&#26631;&#20934;GP&#36866;&#29992;&#30340;&#25152;&#26377;&#24773;&#20917;&#19979;&#36827;&#34892;&#31934;&#30830;&#30340;&#20849;&#36717;&#38381;&#24335;&#26356;&#26032;&#12290;&#20026;&#20102;&#23637;&#31034;&#20854;&#24378;&#22823;&#30340;&#23454;&#35777;&#24615;&#33021;&#65292;&#25105;&#20204;&#23558;RCGP&#24212;&#29992;&#20110;&#20174;&#36125;&#21494;&#26031;&#20248;&#21270;&#21040;&#31232;&#30095;&#21464;&#20998;&#39640;&#26031;&#36807;&#31243;&#30340;&#21508;&#31181;&#38382;&#39064;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
To enable closed form conditioning, a common assumption in Gaussian process (GP) regression is independent and identically distributed Gaussian observation noise. This strong and simplistic assumption is often violated in practice, which leads to unreliable inferences and uncertainty quantification. Unfortunately, existing methods for robustifying GPs break closed-form conditioning, which makes them less attractive to practitioners and significantly more computationally expensive. In this paper, we demonstrate how to perform provably robust and conjugate Gaussian process (RCGP) regression at virtually no additional cost using generalised Bayesian inference. RCGP is particularly versatile as it enables exact conjugate closed form updates in all settings where standard GPs admit them. To demonstrate its strong empirical performance, we deploy RCGP for problems ranging from Bayesian optimisation to sparse variational Gaussian processes.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#23558;&#25991;&#26412;&#25551;&#36848;&#36716;&#25442;&#20026;&#26126;&#20195;&#22253;&#26519;&#32472;&#30011;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#23398;&#20064;&#20174;&#25551;&#36848;&#25991;&#26412;&#21040;&#22253;&#26519;&#32472;&#30011;&#30340;&#26144;&#23556;&#65292;&#24182;&#20197;&#21513;&#26124;&#22253;&#30340;&#25991;&#26412;&#25551;&#36848;&#20026;&#24341;&#23548;&#65292;&#29983;&#25104;&#26032;&#30340;&#22253;&#26519;&#32472;&#30011;&#12290;&#29983;&#25104;&#30340;&#22270;&#20687;&#30340;&#35780;&#20272;&#26631;&#20934;&#26159;&#19982;&#24341;&#23548;&#25991;&#26412;&#30340;&#20313;&#24358;&#30456;&#20284;&#24230;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#20351;&#29992;&#20302;&#31209;&#36866;&#24212;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#25968;&#25454;&#36827;&#34892;&#24494;&#35843;&#12290;&#29983;&#25104;&#30340;&#22270;&#20687;&#36824;&#21487;&#20197;&#36716;&#25442;&#20026;&#20840;&#26223;&#22270;&#12290;</title><link>http://arxiv.org/abs/2311.00339</link><description>&lt;p&gt;
&#31354;&#38388;&#21465;&#36848;&#65306;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#20174;&#25991;&#26412;&#29983;&#25104;&#20013;&#22269;&#22253;&#26519;&#30340;&#22270;&#20687;&#21644;3D&#22330;&#26223;
&lt;/p&gt;
&lt;p&gt;
Space Narrative: Generating Images and 3D Scenes of Chinese Garden from Text using Deep Learning. (arXiv:2311.00339v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00339
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#23558;&#25991;&#26412;&#25551;&#36848;&#36716;&#25442;&#20026;&#26126;&#20195;&#22253;&#26519;&#32472;&#30011;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#23398;&#20064;&#20174;&#25551;&#36848;&#25991;&#26412;&#21040;&#22253;&#26519;&#32472;&#30011;&#30340;&#26144;&#23556;&#65292;&#24182;&#20197;&#21513;&#26124;&#22253;&#30340;&#25991;&#26412;&#25551;&#36848;&#20026;&#24341;&#23548;&#65292;&#29983;&#25104;&#26032;&#30340;&#22253;&#26519;&#32472;&#30011;&#12290;&#29983;&#25104;&#30340;&#22270;&#20687;&#30340;&#35780;&#20272;&#26631;&#20934;&#26159;&#19982;&#24341;&#23548;&#25991;&#26412;&#30340;&#20313;&#24358;&#30456;&#20284;&#24230;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#20351;&#29992;&#20302;&#31209;&#36866;&#24212;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#25968;&#25454;&#36827;&#34892;&#24494;&#35843;&#12290;&#29983;&#25104;&#30340;&#22270;&#20687;&#36824;&#21487;&#20197;&#36716;&#25442;&#20026;&#20840;&#26223;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#20256;&#32479;&#20013;&#22269;&#22253;&#26519;&#30340;&#30740;&#31350;&#21644;&#20462;&#22797;&#65292;&#23558;&#35799;&#27468;&#26144;&#23556;&#21040;&#32472;&#30011;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#28982;&#32780;&#65292;&#32570;&#20047;&#31532;&#19968;&#25163;&#36164;&#26009;&#23545;&#20110;&#37325;&#24314;&#24037;&#20316;&#26159;&#19968;&#20010;&#24040;&#22823;&#30340;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#26681;&#25454;&#25991;&#26412;&#25551;&#36848;&#29983;&#25104;&#22253;&#26519;&#32472;&#30011;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#22270;&#20687;-&#25991;&#26412;&#37197;&#23545;&#25968;&#25454;&#38598;&#21253;&#21547;&#20102;&#19968;&#21315;&#22810;&#24352;&#26126;&#20195;&#22253;&#26519;&#32472;&#30011;&#21450;&#20854;&#38125;&#25991;&#21644;&#21518;&#35760;&#12290;&#36890;&#36807;&#28508;&#22312;&#30340;&#25991;&#26412;&#21040;&#22270;&#20687;&#25193;&#25955;&#27169;&#22411;&#65292;&#23398;&#20064;&#20102;&#20174;&#25551;&#36848;&#25991;&#26412;&#21040;&#26126;&#20195;&#22253;&#26519;&#32472;&#30011;&#30340;&#26144;&#23556;&#65292;&#24182;&#19988;&#22522;&#20110;&#21513;&#26124;&#22253;&#30340;&#25991;&#26412;&#25551;&#36848;&#65292;&#24341;&#23548;&#27169;&#22411;&#29983;&#25104;&#26032;&#30340;&#22253;&#26519;&#32472;&#30011;&#12290;&#29983;&#25104;&#30340;&#22270;&#20687;&#19982;&#24341;&#23548;&#25991;&#26412;&#20043;&#38388;&#30340;&#20313;&#24358;&#30456;&#20284;&#24230;&#34987;&#29992;&#20316;&#29983;&#25104;&#22270;&#20687;&#30340;&#35780;&#20272;&#26631;&#20934;&#12290;&#25105;&#20204;&#20351;&#29992;&#20302;&#31209;&#36866;&#24212;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LoRA&#65289;&#30340;&#39044;&#35757;&#32451;&#25193;&#25955;&#27169;&#22411;&#23545;&#25968;&#25454;&#38598;&#36827;&#34892;&#24494;&#35843;&#12290;&#25105;&#20204;&#36824;&#23558;&#29983;&#25104;&#30340;&#22270;&#20687;&#36716;&#25442;&#20026;&#20840;&#26223;&#22270;&#65292;&#24182;&#19988;...
&lt;/p&gt;
&lt;p&gt;
The consistent mapping from poems to paintings is essential for the research and restoration of traditional Chinese gardens. But the lack of firsthand ma-terial is a great challenge to the reconstruction work. In this paper, we pro-pose a method to generate garden paintings based on text descriptions using deep learning method. Our image-text pair dataset consists of more than one thousand Ming Dynasty Garden paintings and their inscriptions and post-scripts. A latent text-to-image diffusion model learns the mapping from de-scriptive texts to garden paintings of the Ming Dynasty, and then the text description of Jichang Garden guides the model to generate new garden paintings. The cosine similarity between the guide text and the generated image is the evaluation criterion for the generated images. Our dataset is used to fine-tune the pre-trained diffusion model using Low-Rank Adapta-tion of Large Language Models (LoRA). We also transformed the generated images into a panorama and creat
&lt;/p&gt;</description></item><item><title>&#22312;&#39640;&#32500;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32447;&#24615;&#35889;&#32479;&#35745;&#30340;&#27979;&#35797;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#35745;&#31639;&#19978;&#38750;&#24120;&#39640;&#25928;&#65292;&#24182;&#19988;&#22312;&#25152;&#26377;&#35745;&#31639;&#19978;&#39640;&#25928;&#30340;&#27979;&#35797;&#20013;&#65292;&#23454;&#29616;&#20102;&#31867;&#22411; I &#21644;&#31867;&#22411; II &#38169;&#35823;&#29575;&#20043;&#38388;&#30340;&#26368;&#20339;&#26435;&#34913;&#26354;&#32447;&#12290;</title><link>http://arxiv.org/abs/2311.00289</link><description>&lt;p&gt;
&#39640;&#25928;&#27979;&#35797;&#30340;&#31934;&#30830;&#38169;&#35823;&#29575;
&lt;/p&gt;
&lt;p&gt;
Precise Error Rates for Computationally Efficient Testing. (arXiv:2311.00289v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00289
&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32447;&#24615;&#35889;&#32479;&#35745;&#30340;&#27979;&#35797;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#35745;&#31639;&#19978;&#38750;&#24120;&#39640;&#25928;&#65292;&#24182;&#19988;&#22312;&#25152;&#26377;&#35745;&#31639;&#19978;&#39640;&#25928;&#30340;&#27979;&#35797;&#20013;&#65292;&#23454;&#29616;&#20102;&#31867;&#22411; I &#21644;&#31867;&#22411; II &#38169;&#35823;&#29575;&#20043;&#38388;&#30340;&#26368;&#20339;&#26435;&#34913;&#26354;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#31616;&#21333;&#19982;&#31616;&#21333;&#20551;&#35774;&#26816;&#39564;&#30340;&#22522;&#26412;&#38382;&#39064;&#65292;&#29305;&#21035;&#20851;&#27880;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#22240;&#20026;&#22312;&#39640;&#32500;&#35774;&#32622;&#20013;&#65292;&#32479;&#35745;&#19978;&#26368;&#20248;&#30340;&#20284;&#28982;&#27604;&#26816;&#39564;&#36890;&#24120;&#26159;&#35745;&#31639;&#19978;&#38590;&#20197;&#22788;&#29702;&#30340;&#12290;&#22312;&#32463;&#20856;&#30340;&#23574;&#23792;&#32500;&#26684;&#32435;&#27169;&#22411;&#65288;&#20855;&#26377;&#19968;&#33324;&#24615; i.i.d. &#23574;&#23792;&#20808;&#39564;&#65289;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#22522;&#20110;&#32447;&#24615;&#35889;&#32479;&#35745;&#30340;&#29616;&#26377;&#27979;&#35797;&#23454;&#29616;&#20102;&#22312;&#35745;&#31639;&#19978;&#39640;&#25928;&#27979;&#35797;&#20043;&#38388;&#30340;&#26368;&#20339;&#26435;&#34913;&#26354;&#32447;&#65292;&#21363;&#20351;&#23384;&#22312;&#26356;&#22909;&#30340;&#25351;&#25968;&#26102;&#38388;&#27979;&#35797;&#12290;&#36825;&#20010;&#32467;&#26524;&#26159;&#22312;&#19968;&#20010;&#36866;&#24403;&#22797;&#26434;&#24615;&#29702;&#35770;&#30340;&#29468;&#24819;&#26465;&#20214;&#19979;&#24471;&#21040;&#30340;&#65292;&#21363;&#19968;&#20010;&#33258;&#28982;&#21152;&#24378;&#24050;&#32463;&#24314;&#31435;&#30340;&#20302;&#27425;&#25968;&#29468;&#24819;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#35889;&#26159;&#35745;&#31639;&#21463;&#38480;&#30340;&#27979;&#35797;&#30340;&#20805;&#20998;&#32479;&#35745;&#37327;&#65288;&#20294;&#19981;&#26159;&#25152;&#26377;&#27979;&#35797;&#30340;&#20805;&#20998;&#32479;&#35745;&#37327;&#65289;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#39318;&#20010;&#29992;&#20110;&#25512;&#29702;&#20851;&#20110;&#26377;&#25928;&#35745;&#31639;&#25152;&#33021;&#23454;&#29616;&#30340;&#31934;&#30830;&#28176;&#36817;&#27979;&#35797;&#35823;&#24046;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
We revisit the fundamental question of simple-versus-simple hypothesis testing with an eye towards computational complexity, as the statistically optimal likelihood ratio test is often computationally intractable in high-dimensional settings. In the classical spiked Wigner model (with a general i.i.d. spike prior) we show that an existing test based on linear spectral statistics achieves the best possible tradeoff curve between type I and type II error rates among all computationally efficient tests, even though there are exponential-time tests that do better. This result is conditional on an appropriate complexity-theoretic conjecture, namely a natural strengthening of the well-established low-degree conjecture. Our result shows that the spectrum is a sufficient statistic for computationally bounded tests (but not for all tests).  To our knowledge, our approach gives the first tool for reasoning about the precise asymptotic testing error achievable with efficient computation. The main
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#22312;&#38750;&#20984;&#35774;&#32622;&#20013;&#20351;&#29992;&#26631;&#31614;&#22122;&#22768;&#23545;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#36827;&#34892;&#20102;&#27867;&#21270;&#38169;&#35823;&#30028;&#38480;&#30340;&#30740;&#31350;&#65292;&#21033;&#29992;&#31639;&#27861;&#31283;&#23450;&#24615;&#26694;&#26550;&#24471;&#21040;&#20102;&#26102;&#38388;&#26080;&#20851;&#30340;&#27867;&#21270;&#38169;&#35823;&#30028;&#38480;&#65292;&#24182;&#19988;&#22312;&#21442;&#25968;&#32500;&#24230;&#21644;&#26679;&#26412;&#22823;&#23567;&#30340;&#36895;&#29575;&#20197;&#21450;&#29305;&#23450;&#23398;&#20064;&#29575;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#22810;&#39033;&#24335;&#30340;&#38169;&#35823;&#30028;&#38480;&#12290;&#35813;&#20998;&#26512;&#25552;&#20379;&#20102;&#20851;&#20110;&#26631;&#31614;&#22122;&#22768;&#24433;&#21709;&#30340;&#37327;&#21270;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2311.00274</link><description>&lt;p&gt;
&#26631;&#31614;&#22122;&#22768;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#27867;&#21270;&#30028;
&lt;/p&gt;
&lt;p&gt;
Generalization Bounds for Label Noise Stochastic Gradient Descent. (arXiv:2311.00274v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00274
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#22312;&#38750;&#20984;&#35774;&#32622;&#20013;&#20351;&#29992;&#26631;&#31614;&#22122;&#22768;&#23545;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#36827;&#34892;&#20102;&#27867;&#21270;&#38169;&#35823;&#30028;&#38480;&#30340;&#30740;&#31350;&#65292;&#21033;&#29992;&#31639;&#27861;&#31283;&#23450;&#24615;&#26694;&#26550;&#24471;&#21040;&#20102;&#26102;&#38388;&#26080;&#20851;&#30340;&#27867;&#21270;&#38169;&#35823;&#30028;&#38480;&#65292;&#24182;&#19988;&#22312;&#21442;&#25968;&#32500;&#24230;&#21644;&#26679;&#26412;&#22823;&#23567;&#30340;&#36895;&#29575;&#20197;&#21450;&#29305;&#23450;&#23398;&#20064;&#29575;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#22810;&#39033;&#24335;&#30340;&#38169;&#35823;&#30028;&#38480;&#12290;&#35813;&#20998;&#26512;&#25552;&#20379;&#20102;&#20851;&#20110;&#26631;&#31614;&#22122;&#22768;&#24433;&#21709;&#30340;&#37327;&#21270;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#38750;&#20984;&#35774;&#32622;&#20013;&#65292;&#22522;&#20110;&#22343;&#21248;&#32791;&#25955;&#21644;&#24179;&#28369;&#26465;&#20214;&#65292;&#20026;&#20855;&#26377;&#26631;&#31614;&#22122;&#22768;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#24320;&#21457;&#20102;&#27867;&#21270;&#38169;&#35823;&#30028;&#38480;&#12290;&#22312;&#36866;&#24403;&#36873;&#25321;&#30340;&#21322;&#24230;&#37327;&#19979;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19982;&#21442;&#25968;&#32500;&#24230;$d$&#22810;&#39033;&#24335;&#30456;&#20851;&#30340;&#26631;&#31614;&#22122;&#22768;&#38543;&#26426;&#26799;&#24230;&#27969;&#30340;Wasserstein&#36317;&#31163;&#25910;&#32553;&#12290;&#21033;&#29992;&#31639;&#27861;&#31283;&#23450;&#24615;&#26694;&#26550;&#65292;&#25105;&#20204;&#20026;&#31163;&#25955;&#21270;&#31639;&#27861;&#25512;&#23548;&#20102;&#29420;&#31435;&#20110;&#26102;&#38388;&#30340;&#27867;&#21270;&#38169;&#35823;&#30028;&#38480;&#65292;&#24182;&#20351;&#29992;&#22266;&#23450;&#23398;&#20064;&#29575;&#12290;&#25105;&#20204;&#23454;&#29616;&#30340;&#38169;&#35823;&#30028;&#38480;&#19982;$d$&#21644;&#26679;&#26412;&#22823;&#23567;$n$&#30340;&#36895;&#29575;&#20197;&#21450;$n^{-2/3}$&#26377;&#22810;&#39033;&#24335;&#30340;&#20851;&#31995;&#12290;&#36825;&#20010;&#36895;&#29575;&#22312;&#19982;&#31867;&#20284;&#26465;&#20214;&#19979;&#20351;&#29992;&#21442;&#25968;&#26080;&#20851;&#39640;&#26031;&#22122;&#22768;&#30340;&#38543;&#26426;&#26799;&#24230;Langevin&#21160;&#21147;&#23398;&#65288;SGLD&#65289;&#20013;&#65292;&#20854;&#26368;&#20339;&#24050;&#30693;&#36895;&#29575;$n^{-1/2}$&#35201;&#22909;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25552;&#20379;&#20102;&#20851;&#20110;&#26631;&#31614;&#22122;&#22768;&#24433;&#21709;&#30340;&#37327;&#21270;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop generalization error bounds for stochastic gradient descent (SGD) with label noise in non-convex settings under uniform dissipativity and smoothness conditions. Under a suitable choice of semimetric, we establish a contraction in Wasserstein distance of the label noise stochastic gradient flow that depends polynomially on the parameter dimension $d$. Using the framework of algorithmic stability, we derive time-independent generalisation error bounds for the discretized algorithm with a constant learning rate. The error bound we achieve scales polynomially with $d$ and with the rate of $n^{-2/3}$, where $n$ is the sample size. This rate is better than the best-known rate of $n^{-1/2}$ established for stochastic gradient Langevin dynamics (SGLD) -which employs parameter-independent Gaussian noise -- under similar conditions. Our analysis offers quantitative insights into the effect of label noise.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20351;&#29992;&#21453;&#21521;&#35823;&#24046;&#20998;&#26512;&#35745;&#31639;&#20102;&#22810;&#20219;&#21153;&#21644;&#36830;&#32493;&#23398;&#20064;&#35774;&#32622;&#19979;&#31070;&#32463;&#32593;&#32476;&#30340;&#38544;&#24335;&#35757;&#32451;&#20559;&#24046;&#12290;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#36890;&#36807;&#24341;&#20837;&#20462;&#25913;&#25439;&#22833;&#20989;&#25968;&#65292;&#38544;&#24335;&#26368;&#23567;&#21270;&#20102;&#21407;&#22987;&#25439;&#22833;&#12289;&#24341;&#20837;&#20102;&#38544;&#24335;&#24179;&#22374;&#27491;&#21017;&#39033;&#21644;&#20914;&#31361;&#39033;&#12290;&#22312;&#22810;&#20219;&#21153;&#20013;&#65292;&#20914;&#31361;&#39033;&#34913;&#37327;&#20102;&#20219;&#21153;&#26799;&#24230;&#20043;&#38388;&#30340;&#23545;&#40784;&#24615;&#65307;&#32780;&#22312;&#36830;&#32493;&#23398;&#20064;&#20013;&#65292;&#20914;&#31361;&#39033;&#26159;&#28145;&#24230;&#23398;&#20064;&#20248;&#21270;&#20013;&#30340;&#19968;&#20010;&#26032;&#27010;&#24565;&#65292;&#23427;&#36890;&#36807;&#20219;&#21153;&#26799;&#24230;&#20043;&#38388;&#30340;&#26446;&#25324;&#21495;&#26469;&#34913;&#37327;&#12290;</title><link>http://arxiv.org/abs/2311.00235</link><description>&lt;p&gt;
&#20174;&#21453;&#21521;&#35823;&#24046;&#20998;&#26512;&#35282;&#24230;&#30475;&#22810;&#20219;&#21153;&#21644;&#36830;&#32493;&#23398;&#20064;&#20013;&#30340;&#38544;&#24335;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Implicit biases in multitask and continual learning from a backward error analysis perspective. (arXiv:2311.00235v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00235
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20351;&#29992;&#21453;&#21521;&#35823;&#24046;&#20998;&#26512;&#35745;&#31639;&#20102;&#22810;&#20219;&#21153;&#21644;&#36830;&#32493;&#23398;&#20064;&#35774;&#32622;&#19979;&#31070;&#32463;&#32593;&#32476;&#30340;&#38544;&#24335;&#35757;&#32451;&#20559;&#24046;&#12290;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#36890;&#36807;&#24341;&#20837;&#20462;&#25913;&#25439;&#22833;&#20989;&#25968;&#65292;&#38544;&#24335;&#26368;&#23567;&#21270;&#20102;&#21407;&#22987;&#25439;&#22833;&#12289;&#24341;&#20837;&#20102;&#38544;&#24335;&#24179;&#22374;&#27491;&#21017;&#39033;&#21644;&#20914;&#31361;&#39033;&#12290;&#22312;&#22810;&#20219;&#21153;&#20013;&#65292;&#20914;&#31361;&#39033;&#34913;&#37327;&#20102;&#20219;&#21153;&#26799;&#24230;&#20043;&#38388;&#30340;&#23545;&#40784;&#24615;&#65307;&#32780;&#22312;&#36830;&#32493;&#23398;&#20064;&#20013;&#65292;&#20914;&#31361;&#39033;&#26159;&#28145;&#24230;&#23398;&#20064;&#20248;&#21270;&#20013;&#30340;&#19968;&#20010;&#26032;&#27010;&#24565;&#65292;&#23427;&#36890;&#36807;&#20219;&#21153;&#26799;&#24230;&#20043;&#38388;&#30340;&#26446;&#25324;&#21495;&#26469;&#34913;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#21453;&#21521;&#35823;&#24046;&#20998;&#26512;&#65292;&#25105;&#20204;&#35745;&#31639;&#20102;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;&#22810;&#20219;&#21153;&#21644;&#36830;&#32493;&#23398;&#20064;&#35774;&#32622;&#20013;&#30340;&#38544;&#24335;&#35757;&#32451;&#20559;&#24046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#38544;&#21547;&#22320;&#26368;&#23567;&#21270;&#30340;&#20462;&#25913;&#25439;&#22833;&#20989;&#25968;&#12290;&#23427;&#20204;&#21253;&#25324;&#19977;&#20010;&#39033;&#65306;&#21407;&#22987;&#25439;&#22833;&#20989;&#25968;&#65288;&#32771;&#34385;&#25910;&#25947;&#24615;&#65289;&#65292;&#19982;&#23398;&#20064;&#29575;&#25104;&#27491;&#27604;&#30340;&#38544;&#24335;&#24179;&#22374;&#27491;&#21017;&#39033;&#20197;&#21450;&#26368;&#21518;&#19968;&#20010;&#39033;&#8212;&#8212;&#20914;&#31361;&#39033;&#65292;&#35813;&#39033;&#22312;&#29702;&#35770;&#19978;&#23545;&#25910;&#25947;&#24615;&#21644;&#38544;&#24335;&#27491;&#21017;&#21270;&#37117;&#21487;&#33021;&#26377;&#23475;&#12290;&#22312;&#22810;&#20219;&#21153;&#20013;&#65292;&#20914;&#31361;&#39033;&#26159;&#19968;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#37327;&#65292;&#29992;&#20110;&#34913;&#37327;&#20219;&#21153;&#20043;&#38388;&#30340;&#26799;&#24230;&#23545;&#40784;&#24615;&#65292;&#32780;&#22312;&#36830;&#32493;&#23398;&#20064;&#20013;&#65292;&#20914;&#31361;&#39033;&#26159;&#28145;&#24230;&#23398;&#20064;&#20248;&#21270;&#20013;&#30340;&#19968;&#20010;&#26032;&#37327;&#65292;&#23613;&#31649;&#22312;&#24494;&#20998;&#20960;&#20309;&#20013;&#26159;&#19968;&#20010;&#22522;&#26412;&#24037;&#20855;&#65306;&#20219;&#21153;&#26799;&#24230;&#20043;&#38388;&#30340;&#26446;&#25324;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Using backward error analysis, we compute implicit training biases in multitask and continual learning settings for neural networks trained with stochastic gradient descent. In particular, we derive modified losses that are implicitly minimized during training. They have three terms: the original loss, accounting for convergence, an implicit flatness regularization term proportional to the learning rate, and a last term, the conflict term, which can theoretically be detrimental to both convergence and implicit regularization. In multitask, the conflict term is a well-known quantity, measuring the gradient alignment between the tasks, while in continual learning the conflict term is a new quantity in deep learning optimization, although a basic tool in differential geometry: The Lie bracket between the task gradients.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23637;&#31034;&#20102;&#19968;&#31867;&#22522;&#20110;&#21152;&#26435;&#25289;&#26222;&#25289;&#26031;&#29305;&#24449;&#22270;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#26041;&#27861;&#30340;&#33258;&#36866;&#24212;&#21644;&#38750;&#33258;&#36866;&#24212;&#26497;&#23567;&#26497;&#22823;&#25910;&#25947;&#36895;&#29575;&#65292;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#30495;&#23454;&#22238;&#24402;&#20989;&#25968;&#23646;&#20110;Sobolev&#31354;&#38388;&#19988;&#37319;&#26679;&#23494;&#24230;&#22312;&#19978;&#19979;&#26377;&#30028;&#30340;&#24773;&#20917;&#19979;&#65292;&#25193;&#23637;&#20102;&#20043;&#21069;&#38024;&#23545;&#29305;&#23450;&#24402;&#19968;&#21270;&#22270;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#30340;&#32467;&#26524;&#21040;&#23454;&#38469;&#20013;&#20351;&#29992;&#30340;&#24191;&#27867;&#30340;&#21152;&#26435;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#31867;&#12290;</title><link>http://arxiv.org/abs/2311.00140</link><description>&lt;p&gt;
&#22522;&#20110;&#21152;&#26435;&#25289;&#26222;&#25289;&#26031;&#29305;&#24449;&#22270;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#33258;&#36866;&#24212;&#21644;&#38750;&#33258;&#36866;&#24212;&#26497;&#23567;&#26497;&#22823;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Adaptive and non-adaptive minimax rates for weighted Laplacian-eigenmap based nonparametric regression. (arXiv:2311.00140v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00140
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;&#19968;&#31867;&#22522;&#20110;&#21152;&#26435;&#25289;&#26222;&#25289;&#26031;&#29305;&#24449;&#22270;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#26041;&#27861;&#30340;&#33258;&#36866;&#24212;&#21644;&#38750;&#33258;&#36866;&#24212;&#26497;&#23567;&#26497;&#22823;&#25910;&#25947;&#36895;&#29575;&#65292;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#30495;&#23454;&#22238;&#24402;&#20989;&#25968;&#23646;&#20110;Sobolev&#31354;&#38388;&#19988;&#37319;&#26679;&#23494;&#24230;&#22312;&#19978;&#19979;&#26377;&#30028;&#30340;&#24773;&#20917;&#19979;&#65292;&#25193;&#23637;&#20102;&#20043;&#21069;&#38024;&#23545;&#29305;&#23450;&#24402;&#19968;&#21270;&#22270;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#30340;&#32467;&#26524;&#21040;&#23454;&#38469;&#20013;&#20351;&#29992;&#30340;&#24191;&#27867;&#30340;&#21152;&#26435;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#30495;&#23454;&#22238;&#24402;&#20989;&#25968;&#23646;&#20110;Sobolev&#31354;&#38388;&#19988;&#37319;&#26679;&#23494;&#24230;&#22312;&#19978;&#19979;&#26377;&#30028;&#30340;&#24773;&#20917;&#19979;&#65292;&#23637;&#31034;&#20102;&#19968;&#31867;&#22522;&#20110;&#21152;&#26435;&#25289;&#26222;&#25289;&#26031;&#29305;&#24449;&#22270;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#26041;&#27861;&#30340;&#33258;&#36866;&#24212;&#21644;&#38750;&#33258;&#36866;&#24212;&#26497;&#23567;&#26497;&#22823;&#25910;&#25947;&#36895;&#29575;&#12290;&#25105;&#20204;&#30340;&#33258;&#36866;&#24212;&#26041;&#27861;&#22522;&#20110;Lepski&#26041;&#27861;&#30340;&#25193;&#23637;&#65292;&#21516;&#26102;&#36866;&#29992;&#20110;&#24179;&#28369;&#21442;&#25968;&#65288;$s\in\mathbb{N}_{+}$&#65289;&#21644;&#33539;&#25968;&#21442;&#25968;&#65288;$M&gt;0$&#65289;&#26469;&#30830;&#23450;Sobolev&#31354;&#38388;&#30340;&#32422;&#26463;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#23558;\cite{green2021minimax}&#20013;&#38024;&#23545;&#29305;&#23450;&#24402;&#19968;&#21270;&#22270;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#30340;&#38750;&#33258;&#36866;&#24212;&#32467;&#26524;&#25193;&#23637;&#21040;&#23454;&#38469;&#20013;&#20351;&#29992;&#30340;&#24191;&#27867;&#30340;&#21152;&#26435;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#31867;&#65292;&#21253;&#25324;&#38750;&#24402;&#19968;&#21270;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#21644;&#38543;&#26426;&#28216;&#36208;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show both adaptive and non-adaptive minimax rates of convergence for a family of weighted Laplacian-Eigenmap based nonparametric regression methods, when the true regression function belongs to a Sobolev space and the sampling density is bounded from above and below. The adaptation methodology is based on extensions of Lepski's method and is over both the smoothness parameter ($s\in\mathbb{N}_{+}$) and the norm parameter ($M&gt;0$) determining the constraints on the Sobolev space. Our results extend the non-adaptive result in \cite{green2021minimax}, established for a specific normalized graph Laplacian, to a wide class of weighted Laplacian matrices used in practice, including the unnormalized Laplacian and random walk Laplacian.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25552;&#21462;&#33041;&#21160;&#21147;&#23398;&#22810;&#23610;&#24230;&#22240;&#26524;&#39592;&#26550;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23545;&#21512;&#25104;&#25968;&#25454;&#21644;&#38745;&#24687;&#24577;fMRI&#25968;&#25454;&#30340;&#23454;&#39564;&#35777;&#26126;&#20854;&#20248;&#36234;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#22240;&#26524;&#21160;&#21147;&#22312;&#19981;&#21516;&#39057;&#29575;&#19979;&#21463;&#19981;&#21516;&#33041;&#21306;&#39537;&#21160;&#65292;&#36825;&#20026;&#29702;&#35299;&#33041;&#21151;&#33021;&#25552;&#20379;&#20102;&#26032;&#30340;&#35270;&#35282;&#12290;</title><link>http://arxiv.org/abs/2311.00118</link><description>&lt;p&gt;
&#25552;&#21462;&#33041;&#21160;&#21147;&#23398;&#30340;&#22810;&#23610;&#24230;&#22240;&#26524;&#39592;&#26550;
&lt;/p&gt;
&lt;p&gt;
Extracting the Multiscale Causal Backbone of Brain Dynamics. (arXiv:2311.00118v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00118
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25552;&#21462;&#33041;&#21160;&#21147;&#23398;&#22810;&#23610;&#24230;&#22240;&#26524;&#39592;&#26550;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23545;&#21512;&#25104;&#25968;&#25454;&#21644;&#38745;&#24687;&#24577;fMRI&#25968;&#25454;&#30340;&#23454;&#39564;&#35777;&#26126;&#20854;&#20248;&#36234;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#22240;&#26524;&#21160;&#21147;&#22312;&#19981;&#21516;&#39057;&#29575;&#19979;&#21463;&#19981;&#21516;&#33041;&#21306;&#39537;&#21160;&#65292;&#36825;&#20026;&#29702;&#35299;&#33041;&#21151;&#33021;&#25552;&#20379;&#20102;&#26032;&#30340;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#37096;&#20998;&#20851;&#20110;&#33041;&#36830;&#25509;&#24615;&#30340;&#30740;&#31350;&#38598;&#20013;&#22312;&#33041;&#21306;&#20043;&#38388;&#30340;&#32479;&#35745;&#20851;&#32852;&#19978;&#65292;&#36825;&#19982;&#32479;&#27835;&#33041;&#21160;&#21147;&#23398;&#30340;&#22240;&#26524;&#26426;&#21046;&#19981;&#30452;&#25509;&#30456;&#20851;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22810;&#23610;&#24230;&#22240;&#26524;&#39592;&#26550;&#65288;MCB&#65289;&#65292;&#23427;&#26159;&#22312;&#22810;&#20010;&#26102;&#38388;&#23610;&#24230;&#19978;&#20849;&#20139;&#30340;&#19968;&#32452;&#20010;&#20307;&#30340;&#33041;&#21160;&#21147;&#23398;&#29305;&#24449;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#26377;&#21407;&#21017;&#30340;&#26041;&#27861;&#26469;&#25552;&#21462;&#23427;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;&#22810;&#23610;&#24230;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24182;&#20248;&#21270;&#20102;&#27169;&#22411;&#25311;&#21512;&#19982;&#22797;&#26434;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#23545;&#21512;&#25104;&#25968;&#25454;&#30340;&#23454;&#35777;&#35780;&#20272;&#26174;&#31034;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#22522;&#20110;&#35268;&#33539;&#21151;&#33021;&#36830;&#25509;&#32593;&#32476;&#30340;&#22522;&#32447;&#12290;&#24403;&#24212;&#29992;&#20110;&#38745;&#24687;&#24577;fMRI&#25968;&#25454;&#26102;&#65292;&#25105;&#20204;&#21457;&#29616;&#24038;&#21491;&#33041;&#21322;&#29699;&#37117;&#26377;&#31232;&#30095;&#30340;MCB&#12290;&#30001;&#20110;&#20854;&#22810;&#23610;&#24230;&#30340;&#29305;&#24615;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#34920;&#26126;&#22312;&#20302;&#39057;&#24102;&#19978;&#65292;&#22240;&#26524;&#21160;&#21147;&#26469;&#33258;&#19982;&#39640;&#32423;&#35748;&#30693;&#21151;&#33021;&#30456;&#20851;&#30340;&#33041;&#21306;&#65307;&#32780;&#22312;&#26356;&#39640;&#30340;&#39057;&#29575;&#19978;&#65292;&#30001;nod&#20135;&#29983;&#12290;
&lt;/p&gt;
&lt;p&gt;
The bulk of the research effort on brain connectivity revolves around statistical associations among brain regions, which do not directly relate to the causal mechanisms governing brain dynamics. Here we propose the multiscale causal backbone (MCB) of brain dynamics shared by a set of individuals across multiple temporal scales, and devise a principled methodology to extract it.  Our approach leverages recent advances in multiscale causal structure learning and optimizes the trade-off between the model fitting and its complexity. Empirical assessment on synthetic data shows the superiority of our methodology over a baseline based on canonical functional connectivity networks. When applied to resting-state fMRI data, we find sparse MCBs for both the left and right brain hemispheres. Thanks to its multiscale nature, our approach shows that at low-frequency bands, causal dynamics are driven by brain regions associated with high-level cognitive functions; at higher frequencies instead, nod
&lt;/p&gt;</description></item><item><title>FairWASP&#26159;&#19968;&#31181;&#24555;&#36895;&#21644;&#26368;&#20248;&#30340;&#20844;&#24179;Wasserstein&#39044;&#22788;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#37325;&#26032;&#21152;&#26435;&#25968;&#25454;&#38598;&#26469;&#20943;&#23569;&#20998;&#31867;&#25968;&#25454;&#38598;&#20013;&#30340;&#19981;&#24179;&#31561;&#24615;&#65292;&#21516;&#26102;&#28385;&#36275;&#20154;&#21475;&#24179;&#31561;&#24615;&#20934;&#21017;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#26500;&#24314;&#21487;&#20197;&#36755;&#20837;&#20219;&#20309;&#20998;&#31867;&#26041;&#27861;&#30340;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2311.00109</link><description>&lt;p&gt;
FairWASP&#65306;&#24555;&#36895;&#21644;&#26368;&#20248;&#30340;&#20844;&#24179;Wasserstein&#39044;&#22788;&#29702;
&lt;/p&gt;
&lt;p&gt;
FairWASP: Fast and Optimal Fair Wasserstein Pre-processing. (arXiv:2311.00109v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00109
&lt;/p&gt;
&lt;p&gt;
FairWASP&#26159;&#19968;&#31181;&#24555;&#36895;&#21644;&#26368;&#20248;&#30340;&#20844;&#24179;Wasserstein&#39044;&#22788;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#37325;&#26032;&#21152;&#26435;&#25968;&#25454;&#38598;&#26469;&#20943;&#23569;&#20998;&#31867;&#25968;&#25454;&#38598;&#20013;&#30340;&#19981;&#24179;&#31561;&#24615;&#65292;&#21516;&#26102;&#28385;&#36275;&#20154;&#21475;&#24179;&#31561;&#24615;&#20934;&#21017;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#26500;&#24314;&#21487;&#20197;&#36755;&#20837;&#20219;&#20309;&#20998;&#31867;&#26041;&#27861;&#30340;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#24555;&#36895;&#21457;&#23637;&#26088;&#22312;&#20943;&#23569;&#19981;&#21516;&#23376;&#32676;&#20307;&#20043;&#38388;&#27169;&#22411;&#36755;&#20986;&#30340;&#19981;&#24179;&#31561;&#24615;&#12290;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#35757;&#32451;&#25968;&#25454;&#21487;&#33021;&#20250;&#34987;&#19981;&#21516;&#29992;&#25143;&#22312;&#22810;&#20010;&#19979;&#28216;&#24212;&#29992;&#20013;&#20351;&#29992;&#65292;&#36825;&#24847;&#21619;&#30528;&#23545;&#35757;&#32451;&#25968;&#25454;&#26412;&#36523;&#36827;&#34892;&#24178;&#39044;&#21487;&#33021;&#26159;&#26368;&#26377;&#25928;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39044;&#22788;&#29702;&#26041;&#27861;FairWASP&#65292;&#26088;&#22312;&#20943;&#23569;&#20998;&#31867;&#25968;&#25454;&#38598;&#20013;&#30340;&#19981;&#24179;&#31561;&#24615;&#65292;&#32780;&#19981;&#20250;&#20462;&#25913;&#21407;&#22987;&#25968;&#25454;&#12290;FairWASP&#36820;&#22238;&#26679;&#26412;&#32423;&#26435;&#37325;&#65292;&#20351;&#37325;&#26032;&#21152;&#26435;&#30340;&#25968;&#25454;&#38598;&#26368;&#23567;&#21270;&#19982;&#21407;&#22987;&#25968;&#25454;&#38598;&#30340;Wasserstein&#36317;&#31163;&#65292;&#21516;&#26102;&#28385;&#36275;&#65288;&#32463;&#39564;&#29256;&#26412;&#30340;&#65289;&#20154;&#21475;&#24179;&#31561;&#24615;&#65292;&#36825;&#26159;&#19968;&#31181;&#24120;&#29992;&#30340;&#20844;&#24179;&#24615;&#20934;&#21017;&#12290;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#25972;&#25968;&#26435;&#37325;&#30340;&#26368;&#20248;&#24615;&#65292;&#36825;&#24847;&#21619;&#30528;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#31561;&#21516;&#22320;&#29702;&#35299;&#20026;&#22797;&#21046;&#25110;&#21024;&#38500;&#26679;&#26412;&#12290;&#22240;&#27492;&#65292;FairWASP&#21487;&#29992;&#20110;&#26500;&#24314;&#21487;&#20197;&#36755;&#20837;&#20219;&#20309;&#20998;&#31867;&#26041;&#27861;&#30340;&#25968;&#25454;&#38598;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#25509;&#21463;&#26679;&#26412;&#26435;&#37325;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent years have seen a surge of machine learning approaches aimed at reducing disparities in model outputs across different subgroups. In many settings, training data may be used in multiple downstream applications by different users, which means it may be most effective to intervene on the training data itself. In this work, we present FairWASP, a novel pre-processing approach designed to reduce disparities in classification datasets without modifying the original data. FairWASP returns sample-level weights such that the reweighted dataset minimizes the Wasserstein distance to the original dataset while satisfying (an empirical version of) demographic parity, a popular fairness criterion. We show theoretically that integer weights are optimal, which means our method can be equivalently understood as duplicating or eliminating samples. FairWASP can therefore be used to construct datasets which can be fed into any classification method, not just methods which accept sample weights. Ou
&lt;/p&gt;</description></item><item><title>NoMoPy&#26159;&#19968;&#20010;&#29992;&#20110;&#25311;&#21512;&#12289;&#20998;&#26512;&#21644;&#29983;&#25104;&#22122;&#22768;&#30340;Python&#20195;&#30721;&#65292;&#21487;&#20197;&#23558;&#22122;&#22768;&#24314;&#27169;&#20026;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#25110;&#22240;&#23376;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#12290;&#23427;&#23454;&#29616;&#20102;&#36817;&#20284;&#21644;&#31934;&#30830;&#30340;&#26399;&#26395;&#26368;&#22823;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#12289;&#27169;&#22411;&#36873;&#25321;&#21644;&#21442;&#25968;&#32622;&#20449;&#21306;&#38388;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2311.00084</link><description>&lt;p&gt;
NoMoPy: Python&#20013;&#30340;&#22122;&#22768;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
NoMoPy: Noise Modeling in Python. (arXiv:2311.00084v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00084
&lt;/p&gt;
&lt;p&gt;
NoMoPy&#26159;&#19968;&#20010;&#29992;&#20110;&#25311;&#21512;&#12289;&#20998;&#26512;&#21644;&#29983;&#25104;&#22122;&#22768;&#30340;Python&#20195;&#30721;&#65292;&#21487;&#20197;&#23558;&#22122;&#22768;&#24314;&#27169;&#20026;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#25110;&#22240;&#23376;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#12290;&#23427;&#23454;&#29616;&#20102;&#36817;&#20284;&#21644;&#31934;&#30830;&#30340;&#26399;&#26395;&#26368;&#22823;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#12289;&#27169;&#22411;&#36873;&#25321;&#21644;&#21442;&#25968;&#32622;&#20449;&#21306;&#38388;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
NoMoPy&#26159;&#19968;&#20010;&#29992;&#20110;&#25311;&#21512;&#12289;&#20998;&#26512;&#21644;&#29983;&#25104;&#22122;&#22768;&#30340;&#20195;&#30721;&#65292;&#23558;&#22122;&#22768;&#24314;&#27169;&#20026;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#65288;HMM&#65289;&#25110;&#26356;&#19968;&#33324;&#30340;&#22240;&#23376;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#65288;FHMM&#65289;&#12290;&#36825;&#20010;&#29992;Python&#32534;&#20889;&#30340;&#20195;&#30721;&#23454;&#29616;&#20102;&#36817;&#20284;&#21644;&#31934;&#30830;&#30340;&#26399;&#26395;&#26368;&#22823;&#21270;&#65288;EM&#65289;&#31639;&#27861;&#65292;&#29992;&#20110;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#36807;&#31243;&#12289;&#36890;&#36807;&#20132;&#21449;&#39564;&#35777;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#31243;&#24207;&#20197;&#21450;&#21442;&#25968;&#32622;&#20449;&#21306;&#38388;&#20272;&#35745;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#35814;&#32454;&#25551;&#36848;&#20102;NoMoPy&#20013;&#23454;&#29616;&#30340;&#21151;&#33021;&#65292;&#24182;&#25552;&#20379;&#20102;&#22312;&#31034;&#20363;&#38382;&#39064;&#19978;&#30340;&#20351;&#29992;&#21644;&#24615;&#33021;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
NoMoPy is a code for fitting, analyzing, and generating noise modeled as a hidden Markov model (HMM) or, more generally, factorial hidden Markov model (FHMM). This code, written in Python, implements approximate and exact expectation maximization (EM) algorithms for performing the parameter estimation process, model selection procedures via cross-validation, and parameter confidence region estimation. Here, we describe in detail the functionality implemented in NoMoPy and provide examples of its use and performance on example problems.
&lt;/p&gt;</description></item><item><title>Kolmogorov&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#21487;&#20197;&#31934;&#30830;&#22320;&#34920;&#31034;&#36830;&#32493;&#20989;&#25968;&#12289;&#26377;&#30028;&#19981;&#36830;&#32493;&#20989;&#25968;&#21644;&#25152;&#26377;&#26080;&#30028;&#22810;&#20803;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2311.00049</link><description>&lt;p&gt;
&#20851;&#20110; Kolmogorov &#31070;&#32463;&#32593;&#32476;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Kolmogorov neural networks. (arXiv:2311.00049v1 [cs.NE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00049
&lt;/p&gt;
&lt;p&gt;
Kolmogorov&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#21487;&#20197;&#31934;&#30830;&#22320;&#34920;&#31034;&#36830;&#32493;&#20989;&#25968;&#12289;&#26377;&#30028;&#19981;&#36830;&#32493;&#20989;&#25968;&#21644;&#25152;&#26377;&#26080;&#30028;&#22810;&#20803;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102; Kolmogorov &#20004;&#20010;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#19968;&#20010;&#36830;&#32493;&#12289;&#19981;&#36830;&#32493;&#26377;&#30028;&#25110;&#32773;&#26080;&#30028;&#28608;&#27963;&#20989;&#25968;&#22312;&#31532;&#20108;&#20010;&#38544;&#34255;&#23618;&#26469;&#31934;&#30830;&#22320;&#34920;&#31034;&#36830;&#32493;&#20989;&#25968;&#12289;&#26377;&#30028;&#19981;&#36830;&#32493;&#20989;&#25968;&#21644;&#25152;&#26377;&#26080;&#30028;&#22810;&#20803;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we show that the Kolmogorov two hidden layer neural network model with a continuous, discontinuous bounded or unbounded activation function in the second hidden layer can precisely represent continuous, discontinuous bounded and all unbounded multivariate functions, respectively.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;$f$-&#24046;&#20998;&#38544;&#31169;&#26041;&#27861;&#25913;&#36827;&#20102;&#27927;&#29260;&#27169;&#22411;&#21644;DP-GD&#20013;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#38544;&#31169;&#36793;&#30028;&#65292;&#25240;&#34935;&#20989;&#25968;&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#20248;&#20110;$(\epsilon,\delta)$-DP&#30340;&#32467;&#26524;&#65292;&#24182;&#19988;&#38543;&#26426;&#21021;&#22987;&#21270;&#21487;&#20197;&#22686;&#24378;DP-GD&#30340;&#38544;&#31169;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.19973</link><description>&lt;p&gt;
&#36890;&#36807;$f$-&#24046;&#20998;&#38544;&#31169;&#32479;&#19968;&#22686;&#24378;&#28151;&#21512;&#26426;&#21046;&#30340;&#38544;&#31169;&#36793;&#30028;
&lt;/p&gt;
&lt;p&gt;
Unified Enhancement of Privacy Bounds for Mixture Mechanisms via $f$-Differential Privacy. (arXiv:2310.19973v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19973
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;$f$-&#24046;&#20998;&#38544;&#31169;&#26041;&#27861;&#25913;&#36827;&#20102;&#27927;&#29260;&#27169;&#22411;&#21644;DP-GD&#20013;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#38544;&#31169;&#36793;&#30028;&#65292;&#25240;&#34935;&#20989;&#25968;&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#20248;&#20110;$(\epsilon,\delta)$-DP&#30340;&#32467;&#26524;&#65292;&#24182;&#19988;&#38543;&#26426;&#21021;&#22987;&#21270;&#21487;&#20197;&#22686;&#24378;DP-GD&#30340;&#38544;&#31169;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#20250;&#20135;&#29983;&#35768;&#22810;&#38543;&#26426;&#24615;&#65292;&#22914;&#38543;&#26426;&#21021;&#22987;&#21270;&#12289;&#38543;&#26426;&#25209;&#27425;&#25277;&#26679;&#21644;&#27927;&#29260;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#36825;&#20123;&#38543;&#26426;&#24615;&#20250;&#23548;&#33268;&#38590;&#20197;&#20998;&#26512;&#30340;&#28151;&#21512;&#20998;&#24067;&#65292;&#25152;&#20197;&#22312;&#35777;&#26126;&#24046;&#20998;&#38544;&#31169;&#36793;&#30028;&#26102;&#24456;&#38590;&#23558;&#20854;&#32435;&#20837;&#32771;&#34385;&#12290;&#26412;&#25991;&#26088;&#22312;&#25913;&#36827;&#27927;&#29260;&#27169;&#22411;&#21644;&#19968;&#27425;&#36845;&#20195;&#30340;&#24046;&#20998;&#38544;&#31169;&#26799;&#24230;&#19979;&#38477;&#65288;DP-GD&#65289;&#20013;&#29992;&#20110;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#38544;&#31169;&#36793;&#30028;&#65292;&#37319;&#29992;$f$-DP&#26041;&#27861;&#12290;&#25105;&#20204;&#23548;&#20986;&#20102;&#27927;&#29260;&#27169;&#22411;&#30340;&#25240;&#34935;&#20989;&#25968;&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#65292;&#20248;&#20110;&#22522;&#20110;$(\epsilon,\delta)$-DP&#30340;&#26368;&#26032;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23545;&#38543;&#26426;&#21021;&#22987;&#21270;&#23545;&#19968;&#27425;&#36845;&#20195;&#30340;DP-GD&#30340;&#38544;&#31169;&#24615;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#25105;&#20204;&#23545;&#25240;&#34935;&#20989;&#25968;&#30340;&#25968;&#20540;&#35745;&#31639;&#34920;&#26126;&#65292;&#38543;&#26426;&#21021;&#22987;&#21270;&#21487;&#20197;&#22686;&#24378;DP-GD&#30340;&#38544;&#31169;&#24615;&#12290;&#25105;&#20204;&#23545;&#36825;&#20123;&#28151;&#21512;&#26426;&#21046;&#30340;$f$-DP&#20445;&#35777;&#30340;&#20998;&#26512;&#20381;&#36182;&#20110;&#19968;&#31181;&#19981;&#31561;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differentially private (DP) machine learning algorithms incur many sources of randomness, such as random initialization, random batch subsampling, and shuffling. However, such randomness is difficult to take into account when proving differential privacy bounds because it induces mixture distributions for the algorithm's output that are difficult to analyze. This paper focuses on improving privacy bounds for shuffling models and one-iteration differentially private gradient descent (DP-GD) with random initializations using $f$-DP. We derive a closed-form expression of the trade-off function for shuffling models that outperforms the most up-to-date results based on $(\epsilon,\delta)$-DP. Moreover, we investigate the effects of random initialization on the privacy of one-iteration DP-GD. Our numerical computations of the trade-off function indicate that random initialization can enhance the privacy of DP-GD. Our analysis of $f$-DP guarantees for these mixture mechanisms relies on an ine
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#38750;&#21442;&#25968;&#38656;&#27714;&#23398;&#20064;&#21644;&#24179;&#28369;&#33258;&#36866;&#24212;&#30340;&#21160;&#24577;&#23450;&#20215;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#30456;&#20284;&#26465;&#20214;&#23454;&#29616;&#20102;&#26368;&#23567;&#21270;&#26497;&#38480;&#36951;&#25022;&#12290;</title><link>http://arxiv.org/abs/2310.07558</link><description>&lt;p&gt;
&#20855;&#26377;&#38750;&#21442;&#25968;&#38656;&#27714;&#23398;&#20064;&#30340;&#24179;&#28369;&#33258;&#36866;&#24212;&#21160;&#24577;&#23450;&#20215;
&lt;/p&gt;
&lt;p&gt;
Smootheness-Adaptive Dynamic Pricing with Nonparametric Demand Learning. (arXiv:2310.07558v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07558
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#38750;&#21442;&#25968;&#38656;&#27714;&#23398;&#20064;&#21644;&#24179;&#28369;&#33258;&#36866;&#24212;&#30340;&#21160;&#24577;&#23450;&#20215;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#30456;&#20284;&#26465;&#20214;&#23454;&#29616;&#20102;&#26368;&#23567;&#21270;&#26497;&#38480;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#38656;&#27714;&#20989;&#25968;&#20026;&#38750;&#21442;&#25968;&#21644;Holder&#24179;&#28369;&#30340;&#21160;&#24577;&#23450;&#20215;&#38382;&#39064;&#65292;&#24182;&#19988;&#25105;&#20204;&#19987;&#27880;&#20110;&#36866;&#24212;&#26410;&#30693;&#30340;Holder&#24179;&#28369;&#21442;&#25968;&#946;&#30340;&#33021;&#21147;&#12290;&#20256;&#32479;&#19978;&#65292;&#26368;&#20248;&#30340;&#21160;&#24577;&#23450;&#20215;&#31639;&#27861;&#20005;&#37325;&#20381;&#36182;&#20110;&#23545;&#946;&#30340;&#20102;&#35299;&#65292;&#20197;&#36798;&#21040;&#19968;&#20010;&#26368;&#23567;&#21270;&#26497;&#38480;&#36951;&#25022;&#30340;&#25928;&#26524;&#65292;&#21363;O(T^((&#946;+1)/(2&#946;+1)))&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#36890;&#36807;&#35777;&#26126;&#27809;&#26377;&#23450;&#20215;&#31574;&#30053;&#33021;&#22815;&#22312;&#19981;&#30693;&#36947;&#946;&#30340;&#24773;&#20917;&#19979;&#33258;&#36866;&#24212;&#22320;&#36798;&#21040;&#36825;&#20010;&#26368;&#23567;&#21270;&#26497;&#38480;&#36951;&#25022;&#65292;&#31361;&#26174;&#20102;&#36825;&#20010;&#21160;&#24577;&#23450;&#20215;&#38382;&#39064;&#30340;&#36866;&#24212;&#24615;&#25361;&#25112;&#12290;&#21463;&#21040;&#19981;&#21487;&#33021;&#24615;&#32467;&#26524;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#30456;&#20284;&#26465;&#20214;&#26469;&#23454;&#29616;&#36866;&#24212;&#24615;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#33258;&#30456;&#20284;&#26465;&#20214;&#19981;&#20250;&#25439;&#23475;&#38382;&#39064;&#26412;&#36523;&#30340;&#22797;&#26434;&#24615;&#65292;&#22240;&#20026;&#23427;&#20445;&#25345;&#20102;&#28176;&#36817;&#36951;&#25022;&#19979;&#30028;&#937;(T^((&#946;+1)/(2&#946;+1)))&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#24179;&#28369;&#33258;&#36866;&#24212;&#30340;&#21160;&#24577;&#23450;&#20215;&#31639;&#27861;&#65292;&#24182;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the dynamic pricing problem where the demand function is nonparametric and H\"older smooth, and we focus on adaptivity to the unknown H\"older smoothness parameter $\beta$ of the demand function. Traditionally the optimal dynamic pricing algorithm heavily relies on the knowledge of $\beta$ to achieve a minimax optimal regret of $\widetilde{O}(T^{\frac{\beta+1}{2\beta+1}})$. However, we highlight the challenge of adaptivity in this dynamic pricing problem by proving that no pricing policy can adaptively achieve this minimax optimal regret without knowledge of $\beta$. Motivated by the impossibility result, we propose a self-similarity condition to enable adaptivity. Importantly, we show that the self-similarity condition does not compromise the problem's inherent complexity since it preserves the regret lower bound $\Omega(T^{\frac{\beta+1}{2\beta+1}})$. Furthermore, we develop a smoothness-adaptive dynamic pricing algorithm and theoretically prove that the algorithm achieves t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38544;&#21464;&#20998;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#31070;&#32463;&#37319;&#26679;&#22120;&#25351;&#23450;&#38544;&#21547;&#20998;&#24067;&#65292;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#36817;&#20284;&#22797;&#26434;&#30340;&#22810;&#23792;&#21644;&#30456;&#20851;&#21518;&#39564;&#20998;&#24067;&#12290;&#36890;&#36807;&#24341;&#20837;&#23616;&#37096;&#32447;&#24615;&#21270;&#30340;&#32422;&#26463;&#65292;&#36991;&#20813;&#20102;&#20381;&#36182;&#39069;&#22806;&#30340;&#32593;&#32476;&#21644;&#19981;&#31283;&#23450;&#23545;&#25239;&#30446;&#26631;&#30340;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#22120;&#26550;&#26500;&#65292;&#39318;&#27425;&#23454;&#29616;&#20102;&#23545;&#25968;&#30334;&#19975;&#20010;&#28508;&#21464;&#37327;&#30340;&#38544;&#21547;&#20998;&#24067;&#12290;&#23454;&#35777;&#20998;&#26512;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#24674;&#22797;&#22823;&#22411;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20013;&#23618;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#36825;&#23545;&#20110;&#32593;&#32476;&#30340;&#24615;&#33021;&#33267;&#20851;&#37325;&#35201;&#12290;</title><link>http://arxiv.org/abs/2310.06643</link><description>&lt;p&gt;
&#39640;&#32500;&#21518;&#39564;&#25512;&#26029;&#30340;&#38544;&#21464;&#20998;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Implicit Variational Inference for High-Dimensional Posteriors. (arXiv:2310.06643v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06643
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38544;&#21464;&#20998;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#31070;&#32463;&#37319;&#26679;&#22120;&#25351;&#23450;&#38544;&#21547;&#20998;&#24067;&#65292;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#36817;&#20284;&#22797;&#26434;&#30340;&#22810;&#23792;&#21644;&#30456;&#20851;&#21518;&#39564;&#20998;&#24067;&#12290;&#36890;&#36807;&#24341;&#20837;&#23616;&#37096;&#32447;&#24615;&#21270;&#30340;&#32422;&#26463;&#65292;&#36991;&#20813;&#20102;&#20381;&#36182;&#39069;&#22806;&#30340;&#32593;&#32476;&#21644;&#19981;&#31283;&#23450;&#23545;&#25239;&#30446;&#26631;&#30340;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#22120;&#26550;&#26500;&#65292;&#39318;&#27425;&#23454;&#29616;&#20102;&#23545;&#25968;&#30334;&#19975;&#20010;&#28508;&#21464;&#37327;&#30340;&#38544;&#21547;&#20998;&#24067;&#12290;&#23454;&#35777;&#20998;&#26512;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#24674;&#22797;&#22823;&#22411;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20013;&#23618;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#36825;&#23545;&#20110;&#32593;&#32476;&#30340;&#24615;&#33021;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21464;&#20998;&#25512;&#26029;&#20013;&#65292;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#22909;&#22788;&#22312;&#20110;&#20934;&#30830;&#25429;&#25417;&#30495;&#23454;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#25351;&#23450;&#38544;&#21547;&#20998;&#24067;&#30340;&#31070;&#32463;&#37319;&#26679;&#22120;&#65292;&#36825;&#23545;&#20110;&#36817;&#20284;&#39640;&#32500;&#31354;&#38388;&#20013;&#22797;&#26434;&#22810;&#23792;&#21644;&#30456;&#20851;&#21518;&#39564;&#20998;&#24067;&#38750;&#24120;&#36866;&#29992;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#23616;&#37096;&#32447;&#24615;&#21270;&#31070;&#32463;&#37319;&#26679;&#22120;&#24341;&#20837;&#26032;&#30340;&#32422;&#26463;&#65292;&#36825;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#65292;&#29616;&#26377;&#26041;&#27861;&#20381;&#36182;&#20110;&#39069;&#22806;&#30340;&#37492;&#21035;&#22120;&#32593;&#32476;&#21644;&#19981;&#31283;&#23450;&#30340;&#23545;&#25239;&#30446;&#26631;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#22120;&#26550;&#26500;&#65292;&#39318;&#27425;&#23454;&#29616;&#20102;&#23545;&#25968;&#30334;&#19975;&#20010;&#28508;&#21464;&#37327;&#30340;&#38544;&#21547;&#20998;&#24067;&#65292;&#36890;&#36807;&#20351;&#29992;&#21487;&#24494;&#20998;&#30340;&#25968;&#20540;&#36817;&#20284;&#26469;&#35299;&#20915;&#35745;&#31639;&#19978;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#20998;&#26512;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#22312;&#22823;&#22411;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20013;&#24674;&#22797;&#23618;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#36825;&#26159;&#32593;&#32476;&#24615;&#33021;&#20851;&#38190;&#20294;&#33261;&#21517;&#26157;&#33879;&#30340;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In variational inference, the benefits of Bayesian models rely on accurately capturing the true posterior distribution. We propose using neural samplers that specify implicit distributions, which are well-suited for approximating complex multimodal and correlated posteriors in high-dimensional spaces. Our approach advances inference using implicit distributions by introducing novel bounds that come about by locally linearising the neural sampler. This is distinct from existing methods that rely on additional discriminator networks and unstable adversarial objectives. Furthermore, we present a new sampler architecture that, for the first time, enables implicit distributions over millions of latent variables, addressing computational concerns by using differentiable numerical approximations. Our empirical analysis indicates our method is capable of recovering correlations across layers in large Bayesian neural networks, a property that is crucial for a network's performance but notorious
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#21270;&#30340;&#26102;&#31354;&#31070;&#32463;&#28857;&#36807;&#31243;&#31215;&#20998;&#26041;&#27861;(AutoSTPP)&#65292;&#25193;&#23637;&#20102;AutoInt&#26041;&#27861;&#29992;&#20110;&#19977;&#32500;&#26102;&#31354;&#28857;&#36807;&#31243;(STPP)&#30340;&#35745;&#31639;&#65292;&#20855;&#26377;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.06179</link><description>&lt;p&gt;
&#33258;&#21160;&#21270;&#30340;&#26102;&#31354;&#31070;&#32463;&#28857;&#36807;&#31243;&#31215;&#20998;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Automatic Integration for Spatiotemporal Neural Point Processes. (arXiv:2310.06179v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06179
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#21270;&#30340;&#26102;&#31354;&#31070;&#32463;&#28857;&#36807;&#31243;&#31215;&#20998;&#26041;&#27861;(AutoSTPP)&#65292;&#25193;&#23637;&#20102;AutoInt&#26041;&#27861;&#29992;&#20110;&#19977;&#32500;&#26102;&#31354;&#28857;&#36807;&#31243;(STPP)&#30340;&#35745;&#31639;&#65292;&#20855;&#26377;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#36830;&#32493;&#26102;&#38388;&#30340;&#28857;&#36807;&#31243;&#23545;&#20110;&#35768;&#22810;&#31163;&#25955;&#20107;&#20214;&#39044;&#27979;&#20219;&#21153;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#26102;&#31354;&#28857;&#36807;&#31243;&#65288;STPPs&#65289;&#30340;&#31215;&#20998;&#38382;&#39064;&#26159;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#65292;&#22240;&#20026;&#23427;&#28041;&#21450;&#21040;&#23545;&#31354;&#38388;&#21644;&#26102;&#38388;&#36827;&#34892;&#19977;&#37325;&#31215;&#20998;&#35745;&#31639;&#12290;&#29616;&#26377;&#30340;STPP&#31215;&#20998;&#26041;&#27861;&#35201;&#20040;&#20551;&#35774;&#24378;&#24230;&#20989;&#25968;&#20855;&#26377;&#21442;&#25968;&#24418;&#24335;&#65292;&#36825;&#32570;&#20047;&#28789;&#27963;&#24615;&#65307;&#35201;&#20040;&#29992;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#26469;&#36817;&#20284;&#24378;&#24230;&#65292;&#36825;&#24341;&#20837;&#20102;&#25968;&#20540;&#35823;&#24046;&#12290;Omi&#31561;&#20154;&#26368;&#36817;&#30340;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#21160;&#31215;&#20998;&#26041;&#27861;AutoInt&#65292;&#29992;&#20110;&#39640;&#25928;&#22320;&#31215;&#20998;&#28789;&#27963;&#30340;&#24378;&#24230;&#20989;&#25968;&#65292;&#20294;&#35813;&#26041;&#27861;&#21482;&#20851;&#27880;1D&#26102;&#38388;&#28857;&#36807;&#31243;&#12290;&#26412;&#25991;&#23558;AutoInt&#26041;&#27861;&#25193;&#23637;&#33267;3D STPP&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33539;&#24335;&#65306;AutoSTPP&#65288;&#33258;&#21160;&#21270;&#30340;&#26102;&#31354;&#31070;&#32463;&#28857;&#36807;&#31243;&#31215;&#20998;&#26041;&#27861;&#65289;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#30452;&#25509;&#25193;&#23637;&#20043;&#21069;&#30340;&#24037;&#20316;&#20250;&#36807;&#20110;&#32422;&#26463;&#24378;&#24230;&#20989;&#25968;&#65292;&#23548;&#33268;&#24615;&#33021;&#19981;&#20339;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21508;&#31181;&#23454;&#39564;&#20013;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning continuous-time point processes is essential to many discrete event forecasting tasks. However, integration poses a major challenge, particularly for spatiotemporal point processes (STPPs), as it involves calculating the likelihood through triple integrals over space and time. Existing methods for integrating STPP either assume a parametric form of the intensity function, which lacks flexibility; or approximating the intensity with Monte Carlo sampling, which introduces numerical errors. Recent work by Omi et al. [2019] proposes a dual network or AutoInt approach for efficient integration of flexible intensity function. However, the method only focuses on the 1D temporal point process. In this paper, we introduce a novel paradigm: AutoSTPP (Automatic Integration for Spatiotemporal Neural Point Processes) that extends the AutoInt approach to 3D STPP. We show that direct extension of the previous work overly constrains the intensity function, leading to poor performance. We prov
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25903;&#25745;&#40065;&#26834;&#25512;&#26029;&#30340;&#20984;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#20984;&#35268;&#21010;&#25552;&#20379;&#31574;&#30053;&#20215;&#20540;&#30340;&#31934;&#30830;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#35813;&#26041;&#27861;&#36824;&#21487;&#20197;&#36827;&#34892;&#22810;&#31181;&#25193;&#23637;&#65292;&#24182;&#19988;&#20855;&#26377;&#24378;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2309.12450</link><description>&lt;p&gt;
&#25903;&#25745;&#40065;&#26834;&#25512;&#26029;&#30340;&#20984;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Convex Framework for Confounding Robust Inference. (arXiv:2309.12450v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12450
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25903;&#25745;&#40065;&#26834;&#25512;&#26029;&#30340;&#20984;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#20984;&#35268;&#21010;&#25552;&#20379;&#31574;&#30053;&#20215;&#20540;&#30340;&#31934;&#30830;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#35813;&#26041;&#27861;&#36824;&#21487;&#20197;&#36827;&#34892;&#22810;&#31181;&#25193;&#23637;&#65292;&#24182;&#19988;&#20855;&#26377;&#24378;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#21463;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#24433;&#21709;&#30340;&#31163;&#32447;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#12290;&#20256;&#32479;&#30340;&#25935;&#24863;&#24615;&#20998;&#26512;&#26041;&#27861;&#24120;&#34987;&#29992;&#26469;&#22312;&#32473;&#23450;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#19978;&#20272;&#35745;&#22312;&#26368;&#22351;&#28151;&#28102;&#24773;&#20917;&#19979;&#30340;&#31574;&#30053;&#20215;&#20540;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#24037;&#20316;&#36890;&#24120;&#20026;&#20102;&#21487;&#34892;&#24615;&#32780;&#37319;&#29992;&#19968;&#20123;&#31895;&#31961;&#30340;&#26494;&#24347;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#30340;&#26041;&#27861;&#65292;&#23548;&#33268;&#23545;&#31574;&#30053;&#20215;&#20540;&#30340;&#20272;&#35745;&#36807;&#20110;&#20445;&#23432;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#20272;&#35745;&#22120;&#65292;&#21033;&#29992;&#20984;&#35268;&#21010;&#25552;&#20379;&#20102;&#31574;&#30053;&#20215;&#20540;&#30340;&#19968;&#20010;&#36739;&#20026;&#31934;&#30830;&#30340;&#19979;&#30028;&#12290;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#30340;&#24191;&#27867;&#36866;&#29992;&#24615;&#20351;&#24471;&#20854;&#33021;&#22815;&#36827;&#34892;&#22810;&#31181;&#25193;&#23637;&#65292;&#20363;&#22914;&#22522;&#20110;f-&#20998;&#27495;&#30340;&#25935;&#24863;&#24615;&#20998;&#26512;&#12289;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#21644;&#20449;&#24687;&#20934;&#21017;&#30340;&#27169;&#22411;&#36873;&#25321;&#20197;&#21450;&#21033;&#29992;&#19978;&#30028;&#36827;&#34892;&#40065;&#26834;&#31574;&#30053;&#23398;&#20064;&#31561;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#26041;&#27861;&#21487;&#20197;&#36890;&#36807;&#24378;&#23545;&#20598;&#24615;&#37325;&#26032;&#34920;&#36848;&#20026;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#20174;&#32780;&#21033;&#29992;M&#25216;&#26415;&#25552;&#20379;&#20102;&#23545;&#25152;&#25552;&#20986;&#20272;&#35745;&#22120;&#30340;&#24378;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study policy evaluation of offline contextual bandits subject to unobserved confounders. Sensitivity analysis methods are commonly used to estimate the policy value under the worst-case confounding over a given uncertainty set. However, existing work often resorts to some coarse relaxation of the uncertainty set for the sake of tractability, leading to overly conservative estimation of the policy value. In this paper, we propose a general estimator that provides a sharp lower bound of the policy value using convex programming. The generality of our estimator enables various extensions such as sensitivity analysis with f-divergence, model selection with cross validation and information criterion, and robust policy learning with the sharp lower bound. Furthermore, our estimation method can be reformulated as an empirical risk minimization problem thanks to the strong duality, which enables us to provide strong theoretical guarantees of the proposed estimator using techniques of the M-
&lt;/p&gt;</description></item><item><title>&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#26159;&#19968;&#20010;&#30740;&#31350;&#39046;&#22495;&#65292;&#20294;&#30446;&#21069;&#23384;&#22312;&#32452;&#32455;&#19981;&#22815;&#26377;&#24207;&#21644;&#35780;&#20272;&#21327;&#35758;&#26377;&#32570;&#38519;&#30340;&#38382;&#39064;&#12290;&#25991;&#31456;&#35780;&#20272;&#20102;&#35768;&#22810;&#26368;&#36817;&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#24182;&#25351;&#20986;&#20102;&#38024;&#23545;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#30340;&#35780;&#20272;&#21327;&#35758;&#23384;&#22312;&#30340;&#38382;&#39064;&#21450;&#22914;&#20309;&#32531;&#35299;&#36825;&#20123;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.13068</link><description>&lt;p&gt;
&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;: &#28843;&#37239;&#31639;&#27861;&#21644;&#26377;&#32570;&#38519;&#30340;&#35780;&#20272;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Multivariate Time Series Anomaly Detection: Fancy Algorithms and Flawed Evaluation Methodology. (arXiv:2308.13068v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13068
&lt;/p&gt;
&lt;p&gt;
&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#26159;&#19968;&#20010;&#30740;&#31350;&#39046;&#22495;&#65292;&#20294;&#30446;&#21069;&#23384;&#22312;&#32452;&#32455;&#19981;&#22815;&#26377;&#24207;&#21644;&#35780;&#20272;&#21327;&#35758;&#26377;&#32570;&#38519;&#30340;&#38382;&#39064;&#12290;&#25991;&#31456;&#35780;&#20272;&#20102;&#35768;&#22810;&#26368;&#36817;&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#24182;&#25351;&#20986;&#20102;&#38024;&#23545;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#30340;&#35780;&#20272;&#21327;&#35758;&#23384;&#22312;&#30340;&#38382;&#39064;&#21450;&#22914;&#20309;&#32531;&#35299;&#36825;&#20123;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#65288;MVTS&#65289;&#30340;&#24322;&#24120;&#26816;&#27979;&#26159;&#19968;&#20010;&#38271;&#26399;&#23384;&#22312;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#30740;&#31350;&#35838;&#39064;&#65292;&#36817;&#24180;&#26469;&#21560;&#24341;&#20102;&#24037;&#19994;&#30028;&#21644;&#23398;&#26415;&#30028;&#30340;&#22823;&#37327;&#30740;&#31350;&#21162;&#21147;&#12290;&#28982;&#32780;&#65292;&#23545;&#25991;&#29486;&#30340;&#20180;&#32454;&#30740;&#31350;&#35753;&#25105;&#20204;&#24847;&#35782;&#21040;&#65306;1&#65289;&#35813;&#39046;&#22495;&#30340;&#31038;&#21306;&#27963;&#36291;&#65292;&#20294;&#24182;&#19981;&#20687;&#35745;&#31639;&#26426;&#35270;&#35273;&#65288;CV&#65289;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#31561;&#20854;&#20182;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#37027;&#26679;&#32452;&#32455;&#26377;&#24207;&#65307;2&#65289;&#22823;&#22810;&#25968;&#25552;&#20986;&#30340;&#35299;&#20915;&#26041;&#26696;&#20351;&#29992;&#19981;&#21512;&#36866;&#25110;&#23384;&#22312;&#26126;&#26174;&#32570;&#38519;&#30340;&#35780;&#20272;&#21327;&#35758;&#36827;&#34892;&#35780;&#20272;&#65292;&#32570;&#20047;&#31185;&#23398;&#22522;&#30784;&#12290;&#20854;&#20013;&#19968;&#20010;&#38750;&#24120;&#27969;&#34892;&#30340;&#21327;&#35758;&#65292;&#21363;&#25152;&#35859;&#30340; \pa &#21327;&#35758;&#65292;&#26159;&#22914;&#27492;&#26377;&#32570;&#38519;&#65292;&#20197;&#33267;&#20110;&#38543;&#26426;&#29468;&#27979;&#21487;&#20197;&#26174;&#31034;&#31995;&#32479;&#22320;&#20248;&#20110;&#36804;&#20170;&#20026;&#27490;&#24320;&#21457;&#30340;\emph{&#25152;&#26377;}&#31639;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#26356;&#20581;&#22766;&#30340;&#21327;&#35758;&#23545;&#35768;&#22810;&#26368;&#36817;&#30340;&#31639;&#27861;&#36827;&#34892;&#22238;&#39038;&#21644;&#35780;&#20272;&#65292;&#24182;&#35752;&#35770;&#22312;MVTS&#24322;&#24120;&#26816;&#27979;&#30340;&#32972;&#26223;&#19979;&#65292;&#19968;&#20010;&#26412;&#26469;&#24456;&#22909;&#30340;&#21327;&#35758;&#21487;&#33021;&#23384;&#22312;&#30340;&#38382;&#39064;&#20197;&#21450;&#22914;&#20309;&#20943;&#36731;&#36825;&#20123;&#38382;&#39064;&#12290;&#25105;&#20204;&#36824;&#23545;&#22522;&#20934;&#25968;&#25454;&#38598;&#34920;&#36798;&#20102;&#20851;&#20999;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multivariate Time Series (MVTS) anomaly detection is a long-standing and challenging research topic that has attracted tremendous research effort from both industry and academia recently. However, a careful study of the literature makes us realize that 1) the community is active but not as organized as other sibling machine learning communities such as Computer Vision (CV) and Natural Language Processing (NLP), and 2) most proposed solutions are evaluated using either inappropriate or highly flawed protocols, with an apparent lack of scientific foundation. So flawed is one very popular protocol, the so-called \pa protocol, that a random guess can be shown to systematically outperform \emph{all} algorithms developed so far. In this paper, we review and evaluate many recent algorithms using more robust protocols and discuss how a normally good protocol may have weaknesses in the context of MVTS anomaly detection and how to mitigate them. We also share our concerns about benchmark dataset
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#22312;&#39044;&#27979;&#19978;&#19979;&#25991;&#20013;&#30340;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#23558;&#32463;&#20856;&#32479;&#35745;&#23398;&#20013;&#30340;&#27979;&#37327;&#35823;&#24046;&#27169;&#22411;&#25512;&#24191;&#21040;&#22312;&#32447;&#20915;&#31574;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#20855;&#26377;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#22312;&#32447;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.13916</link><description>&lt;p&gt;
&#22312;&#39044;&#27979;&#19978;&#19979;&#25991;&#20013;&#30340;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Online learning in bandits with predicted context. (arXiv:2307.13916v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13916
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#22312;&#39044;&#27979;&#19978;&#19979;&#25991;&#20013;&#30340;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#23558;&#32463;&#20856;&#32479;&#35745;&#23398;&#20013;&#30340;&#27979;&#37327;&#35823;&#24046;&#27169;&#22411;&#25512;&#24191;&#21040;&#22312;&#32447;&#20915;&#31574;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#20855;&#26377;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#22312;&#32447;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#27599;&#20010;&#26102;&#21051;&#65292;&#20195;&#29702;&#21482;&#33021;&#35775;&#38382;&#21040;&#19978;&#19979;&#25991;&#30340;&#19968;&#20010;&#24102;&#22122;&#22768;&#30340;&#29256;&#26412;&#20197;&#21450;&#35823;&#24046;&#26041;&#24046;&#65288;&#25110;&#32773;&#36825;&#20010;&#26041;&#24046;&#30340;&#19968;&#20010;&#20272;&#35745;&#65289;&#12290;&#36825;&#19968;&#35774;&#32622;&#21463;&#21040;&#20102;&#35768;&#22810;&#24212;&#29992;&#30340;&#21551;&#21457;&#65292;&#22312;&#36825;&#20123;&#24212;&#29992;&#20013;&#65292;&#29992;&#20110;&#20915;&#31574;&#30340;&#30495;&#23454;&#19978;&#19979;&#25991;&#26159;&#19981;&#21487;&#35266;&#27979;&#30340;&#65292;&#32780;&#21482;&#26377;&#19968;&#20010;&#30001;&#21487;&#33021;&#22797;&#26434;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#39044;&#27979;&#20986;&#30340;&#19978;&#19979;&#25991;&#12290;&#24403;&#19978;&#19979;&#25991;&#35823;&#24046;&#26159;&#38750;&#34928;&#20943;&#30340;&#26102;&#20505;&#65292;&#32463;&#20856;&#30340;bandit&#31639;&#27861;&#26080;&#27861;&#36798;&#21040;&#27425;&#32447;&#24615;&#30340;&#21518;&#24724;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#36825;&#19968;&#35774;&#32622;&#19979;&#65292;&#31532;&#19968;&#20010;&#20855;&#26377;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#24182;&#19982;&#36866;&#24403;&#30340;&#22522;&#20934;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#20851;&#38190;&#30340;&#24605;&#24819;&#26159;&#23558;&#32463;&#20856;&#32479;&#35745;&#23398;&#20013;&#30340;&#27979;&#37327;&#35823;&#24046;&#27169;&#22411;&#25512;&#24191;&#21040;&#22312;&#32447;&#20915;&#31574;&#35774;&#32622;&#20013;&#65292;&#36825;&#26159;&#38750;&#24179;&#20961;&#30340;&#65292;&#22240;&#20026;&#31574;&#30053;&#20381;&#36182;&#20110;&#26377;&#22122;&#22768;&#30340;&#19978;&#19979;&#25991;&#35266;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the contextual bandit problem where at each time, the agent only has access to a noisy version of the context and the error variance (or an estimator of this variance). This setting is motivated by a wide range of applications where the true context for decision-making is unobserved, and only a prediction of the context by a potentially complex machine learning algorithm is available. When the context error is non-diminishing, classical bandit algorithms fail to achieve sublinear regret. We propose the first online algorithm in this setting with sublinear regret compared to the appropriate benchmark. The key idea is to extend the measurement error model in classical statistics to the online decision-making setting, which is nontrivial due to the policy being dependent on the noisy context observations.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#24322;&#26500;&#29305;&#24449;&#38598;&#25104;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#24615;&#22238;&#24402;&#35774;&#32622;&#20013;&#26500;&#24314;&#30340;&#23725;&#22238;&#24402;&#38598;&#25104;&#30340;&#23398;&#20064;&#26354;&#32447;&#65292;&#32467;&#26524;&#34920;&#26126;&#24322;&#26500;&#29305;&#24449;&#38598;&#25104;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.03176</link><description>&lt;p&gt;
&#24322;&#26500;&#29305;&#24449;&#23376;&#37319;&#26679;&#30340;Ridge Ensemble&#30340;&#23398;&#20064;&#26354;&#32447;
&lt;/p&gt;
&lt;p&gt;
Learning Curves for Heterogeneous Feature-Subsampled Ridge Ensembles. (arXiv:2307.03176v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03176
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#24322;&#26500;&#29305;&#24449;&#38598;&#25104;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#24615;&#22238;&#24402;&#35774;&#32622;&#20013;&#26500;&#24314;&#30340;&#23725;&#22238;&#24402;&#38598;&#25104;&#30340;&#23398;&#20064;&#26354;&#32447;&#65292;&#32467;&#26524;&#34920;&#26126;&#24322;&#26500;&#29305;&#24449;&#38598;&#25104;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#21253;&#35013;&#26159;&#19968;&#31181;&#26088;&#22312;&#36890;&#36807;&#22312;&#38543;&#26426;&#23376;&#26679;&#26412;&#25110;&#29305;&#24449;&#25237;&#24433;&#19978;&#35757;&#32451;&#20272;&#35745;&#22120;&#26469;&#20943;&#23569;&#39044;&#27979;&#26041;&#24046;&#30340;&#25104;&#29087;&#38598;&#25104;&#26041;&#27861;&#12290;&#36890;&#24120;&#65292;&#38598;&#25104;&#36873;&#25321;&#26159;&#21516;&#36136;&#30340;&#65292;&#21363;&#20272;&#35745;&#22120;&#21487;&#29992;&#30340;&#29305;&#24449;&#32500;&#25968;&#22312;&#25972;&#20010;&#38598;&#25104;&#20013;&#26159;&#22343;&#21248;&#30340;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#24322;&#26500;&#29305;&#24449;&#38598;&#25104;&#26041;&#27861;&#65292;&#20854;&#20013;&#30340;&#20272;&#35745;&#22120;&#22522;&#20110;&#21464;&#21160;&#30340;&#29305;&#24449;&#32500;&#25968;&#65292;&#24182;&#30740;&#31350;&#20854;&#22312;&#32447;&#24615;&#22238;&#24402;&#35774;&#32622;&#20013;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#32447;&#24615;&#39044;&#27979;&#22120;&#30340;&#38598;&#25104;&#65292;&#27599;&#20010;&#39044;&#27979;&#22120;&#20351;&#29992;&#37096;&#20998;&#21487;&#29992;&#29305;&#24449;&#36827;&#34892;&#23725;&#22238;&#24402;&#25311;&#21512;&#12290;&#25105;&#20204;&#20801;&#35768;&#36825;&#20123;&#23376;&#38598;&#20013;&#21253;&#21547;&#30340;&#29305;&#24449;&#25968;&#37327;&#26377;&#25152;&#21464;&#21270;&#12290;&#21033;&#29992;&#32479;&#35745;&#29289;&#29702;&#20013;&#30340;&#22797;&#21046;&#25216;&#24039;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#20855;&#26377;&#30830;&#23450;&#24615;&#32447;&#24615;&#25513;&#27169;&#30340;&#23725;&#22238;&#24402;&#38598;&#25104;&#30340;&#23398;&#20064;&#26354;&#32447;&#12290;&#23545;&#20110;&#20855;&#26377;&#21508;&#21521;&#21516;&#24615;&#29305;&#24449;&#22122;&#22768;&#30340;&#31561;&#30456;&#30456;&#20851;&#25968;&#25454;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#23398;&#20064;&#26354;&#32447;&#30340;&#26174;&#24335;&#34920;&#36798;&#24335;&#12290;&#21033;&#29992;&#36825;&#20123;&#25512;&#23548;&#34920;&#36798;&#24335;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38598;&#25104;&#22312;&#19981;&#21516;&#29305;&#24449;&#32500;&#25968;&#19979;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Feature bagging is a well-established ensembling method which aims to reduce prediction variance by training estimators in an ensemble on random subsamples or projections of features. Typically, ensembles are chosen to be homogeneous, in the sense the the number of feature dimensions available to an estimator is uniform across the ensemble. Here, we introduce heterogeneous feature ensembling, with estimators built on varying number of feature dimensions, and consider its performance in a linear regression setting. We study an ensemble of linear predictors, each fit using ridge regression on a subset of the available features. We allow the number of features included in these subsets to vary. Using the replica trick from statistical physics, we derive learning curves for ridge ensembles with deterministic linear masks. We obtain explicit expressions for the learning curves in the case of equicorrelated data with an isotropic feature noise. Using the derived expressions, we investigate t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#20855;&#26377;&#22810;&#23618;&#30340;&#36229;&#22270;&#946;&#27169;&#22411;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#25512;&#23548;&#20102;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#29575;&#21644;&#26497;&#38480;&#20998;&#24067;&#65292;&#24182;&#26500;&#24314;&#20102;&#27169;&#22411;&#21442;&#25968;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;&#36229;&#22270;&#946;&#27169;&#22411;&#20013;&#20284;&#28982;&#27604;&#26816;&#39564;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.02818</link><description>&lt;p&gt;
&#39640;&#38454;&#32593;&#32476;&#20013;&#30340;&#24230;&#24322;&#36136;&#24615;&#65306;&#36229;&#22270;&#946;&#27169;&#22411;&#30340;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Degree Heterogeneity in Higher-Order Networks: Inference in the Hypergraph $\boldsymbol{\beta}$-Model. (arXiv:2307.02818v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02818
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#20855;&#26377;&#22810;&#23618;&#30340;&#36229;&#22270;&#946;&#27169;&#22411;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#25512;&#23548;&#20102;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#29575;&#21644;&#26497;&#38480;&#20998;&#24067;&#65292;&#24182;&#26500;&#24314;&#20102;&#27169;&#22411;&#21442;&#25968;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;&#36229;&#22270;&#946;&#27169;&#22411;&#20013;&#20284;&#28982;&#27604;&#26816;&#39564;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#22270;&#20013;&#30340;&#946;&#27169;&#22411;&#36890;&#24120;&#29992;&#20110;&#34920;&#31034;&#20855;&#26377;&#24230;&#24322;&#36136;&#24615;&#30340;&#32593;&#32476;&#20013;&#30340;&#37197;&#23545;&#20132;&#20114;&#12290;&#36229;&#22270;&#946;&#27169;&#22411;&#36229;&#36234;&#20102;&#37197;&#23545;&#20132;&#20114;&#65292;Stasi&#31561;&#20154;&#20110;2014&#24180;&#24341;&#20837;&#20102;&#36229;&#22270;&#946;&#27169;&#22411;&#65292;&#29992;&#20110;&#25429;&#25417;&#20855;&#26377;&#39640;&#38454;&#65288;&#22810;&#21521;&#65289;&#20132;&#20114;&#30340;&#32593;&#32476;&#20013;&#30340;&#24230;&#24322;&#36136;&#24615;&#12290;&#26412;&#25991;&#39318;&#27425;&#23545;&#20855;&#26377;&#22810;&#23618;&#30340;&#36229;&#22270;&#946;&#27169;&#22411;&#36827;&#34892;&#20102;&#20005;&#26684;&#30740;&#31350;&#65292;&#23427;&#20801;&#35768;&#22312;&#19981;&#21516;&#23618;&#27425;&#20013;&#23384;&#22312;&#19981;&#21516;&#22823;&#23567;&#30340;&#36229;&#36793;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#26368;&#22823;&#20284;&#28982;&#65288;ML&#65289;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#30830;&#23450;&#20102;&#23427;&#20204;&#30340;&#26368;&#23567;&#26497;&#23567;&#36895;&#29575;&#12290;&#25105;&#20204;&#36824;&#25512;&#23548;&#20102;ML&#20272;&#35745;&#30340;&#26497;&#38480;&#20998;&#24067;&#65292;&#24182;&#26500;&#24314;&#20102;&#27169;&#22411;&#21442;&#25968;&#30340;&#28176;&#36817;&#26377;&#25928;&#32622;&#20449;&#21306;&#38388;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#36229;&#22270;&#946;&#27169;&#22411;&#20013;&#30340;&#25311;&#21512;&#20248;&#24230;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22312;&#38646;&#20551;&#35774;&#19979;&#24314;&#31435;&#20102;&#20284;&#28982;&#27604;&#65288;LR&#65289;&#26816;&#39564;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The $\boldsymbol{\beta}$-model for random graphs is commonly used for representing pairwise interactions in a network with degree heterogeneity. Going beyond pairwise interactions, Stasi et al. (2014) introduced the hypergraph $\boldsymbol{\beta}$-model for capturing degree heterogeneity in networks with higher-order (multi-way) interactions. In this paper we initiate the rigorous study of the hypergraph $\boldsymbol{\beta}$-model with multiple layers, which allows for hyperedges of different sizes across the layers. To begin with, we derive the rates of convergence of the maximum likelihood (ML) estimate and establish their minimax rate optimality. We also derive the limiting distribution of the ML estimate and construct asymptotically valid confidence intervals for the model parameters. Next, we consider the goodness-of-fit problem in the hypergraph $\boldsymbol{\beta}$-model. Specifically, we establish the asymptotic normality of the likelihood ratio (LR) test under the null hypothe
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#27874;&#27573;&#21453;&#39304;&#30340;&#22312;&#32447;&#20803;&#23398;&#20064;&#65292;&#24182;&#35774;&#35745;&#20102;&#29992;&#20110;&#22810;&#33218;&#36172;&#21338;&#26426;&#21644;&#36172;&#21338;&#32447;&#24615;&#20248;&#21270;&#30340;&#20803;&#31639;&#27861;&#12290;&#23545;&#20110;&#22810;&#33218;&#36172;&#21338;&#26426;&#65292;&#31639;&#27861;&#20351;&#29992;&#20102;Tsallis-&#29109;&#30340;&#27867;&#21270;Exp3&#65292;&#24182;&#19988;&#20219;&#21153;&#24179;&#22343;&#36951;&#25022;&#20250;&#38543;&#30528;&#26368;&#20248;&#35299;&#30340;&#29109;&#30340;&#20943;&#23567;&#32780;&#25913;&#21892;&#12290;&#23545;&#20110;&#36172;&#21338;&#32447;&#24615;&#20248;&#21270;&#65292;&#31639;&#27861;&#20351;&#29992;&#20102;&#33258;&#21327;&#35843;&#38556;&#30861;&#27491;&#21017;&#21270;&#22120;&#21021;&#22987;&#21270;&#21644;&#35843;&#25972;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#65292;&#24182;&#19988;&#20219;&#21153;&#24179;&#22343;&#36951;&#25022;&#19982;&#21160;&#20316;&#31354;&#38388;&#30456;&#20851;&#30340;&#24230;&#37327;&#30452;&#25509;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2307.02295</link><description>&lt;p&gt;
&#20803;&#23398;&#20064;&#23545;&#25239;&#27874;&#27573;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Meta-Learning Adversarial Bandit Algorithms. (arXiv:2307.02295v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02295
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#27874;&#27573;&#21453;&#39304;&#30340;&#22312;&#32447;&#20803;&#23398;&#20064;&#65292;&#24182;&#35774;&#35745;&#20102;&#29992;&#20110;&#22810;&#33218;&#36172;&#21338;&#26426;&#21644;&#36172;&#21338;&#32447;&#24615;&#20248;&#21270;&#30340;&#20803;&#31639;&#27861;&#12290;&#23545;&#20110;&#22810;&#33218;&#36172;&#21338;&#26426;&#65292;&#31639;&#27861;&#20351;&#29992;&#20102;Tsallis-&#29109;&#30340;&#27867;&#21270;Exp3&#65292;&#24182;&#19988;&#20219;&#21153;&#24179;&#22343;&#36951;&#25022;&#20250;&#38543;&#30528;&#26368;&#20248;&#35299;&#30340;&#29109;&#30340;&#20943;&#23567;&#32780;&#25913;&#21892;&#12290;&#23545;&#20110;&#36172;&#21338;&#32447;&#24615;&#20248;&#21270;&#65292;&#31639;&#27861;&#20351;&#29992;&#20102;&#33258;&#21327;&#35843;&#38556;&#30861;&#27491;&#21017;&#21270;&#22120;&#21021;&#22987;&#21270;&#21644;&#35843;&#25972;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#65292;&#24182;&#19988;&#20219;&#21153;&#24179;&#22343;&#36951;&#25022;&#19982;&#21160;&#20316;&#31354;&#38388;&#30456;&#20851;&#30340;&#24230;&#37327;&#30452;&#25509;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20855;&#26377;&#27874;&#27573;&#21453;&#39304;&#30340;&#22312;&#32447;&#20803;&#23398;&#20064;&#65292;&#30446;&#26631;&#26159;&#22312;&#22810;&#20010;&#20219;&#21153;&#20043;&#38388;&#25913;&#21892;&#24615;&#33021;&#65292;&#22914;&#26524;&#23427;&#20204;&#26681;&#25454;&#26576;&#20010;&#33258;&#28982;&#30340;&#30456;&#20284;&#24615;&#24230;&#37327;&#26159;&#30456;&#20284;&#30340;&#12290;&#20316;&#20026;&#38024;&#23545;&#25932;&#23545;&#30340;&#22312;&#32447;&#37096;&#20998;&#20449;&#24687;&#35774;&#32622;&#30340;&#39318;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#20803;&#31639;&#27861;&#65292;&#23558;&#22806;&#23618;&#23398;&#20064;&#22120;&#32467;&#21512;&#22312;&#19968;&#36215;&#65292;&#21516;&#26102;&#20026;&#20004;&#31181;&#37325;&#35201;&#24773;&#20917;&#35843;&#25972;&#20869;&#37096;&#23398;&#20064;&#22120;&#30340;&#21021;&#22987;&#21270;&#21644;&#20854;&#20182;&#36229;&#21442;&#25968;&#65306;&#22810;&#33218;&#36172;&#21338;&#26426;&#65288;MAB&#65289;&#21644;&#36172;&#21338;&#32447;&#24615;&#20248;&#21270;&#65288;BLO&#65289;&#12290;&#23545;&#20110;MAB&#65292;&#20803;&#23398;&#20064;&#22120;&#20351;&#29992;Tsallis-&#29109;&#30340;&#27867;&#21270;Exp3&#30340;&#21021;&#22987;&#21270;&#21644;&#35774;&#32622;&#36229;&#21442;&#25968;&#65292;&#22914;&#26524;&#21518;&#35265;&#20043;&#39640;&#23792;&#30340;&#29109;&#23567;&#65292;&#21017;&#20219;&#21153;&#24179;&#22343;&#36951;&#25022;&#25913;&#21892;&#12290;&#23545;&#20110;BLO&#65292;&#25105;&#20204;&#23398;&#20250;&#20102;&#20351;&#29992;&#33258;&#21327;&#35843;&#38556;&#30861;&#27491;&#21017;&#21270;&#22120;&#21021;&#22987;&#21270;&#21644;&#35843;&#25972;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#65288;OMD&#65289;&#65292;&#34920;&#26126;&#20219;&#21153;&#24179;&#22343;&#36951;&#25022;&#19982;&#20854;&#24341;&#36215;&#30340;&#21160;&#20316;&#31354;&#38388;&#30456;&#20851;&#30340;&#24230;&#37327;&#30452;&#25509;&#21464;&#21270;&#12290;&#25105;&#20204;&#30340;&#20445;&#35777;&#22522;&#20110;&#35777;&#26126;&#26080;&#27491;&#35268;&#21270;&#36319;&#38543;&#32773;&#19982;&#20004;&#20010;&#8230;
&lt;/p&gt;
&lt;p&gt;
We study online meta-learning with bandit feedback, with the goal of improving performance across multiple tasks if they are similar according to some natural similarity measure. As the first to target the adversarial online-within-online partial-information setting, we design meta-algorithms that combine outer learners to simultaneously tune the initialization and other hyperparameters of an inner learner for two important cases: multi-armed bandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners initialize and set hyperparameters of the Tsallis-entropy generalization of Exp3, with the task-averaged regret improving if the entropy of the optima-in-hindsight is small. For BLO, we learn to initialize and tune online mirror descent (OMD) with self-concordant barrier regularizers, showing that task-averaged regret varies directly with an action space-dependent measure they induce. Our guarantees rely on proving that unregularized follow-the-leader combined with two 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#65292;&#36890;&#36807;&#31561;&#20215;&#30340;&#30446;&#26631;&#20989;&#25968;&#24418;&#24335;&#21644;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#25105;&#20204;&#19981;&#20165;&#21487;&#20197;&#20351;&#29992;&#20854;&#20182;&#24809;&#32602;&#26041;&#27861;&#65292;&#36824;&#33021;&#22815;&#20174;&#26799;&#24230;&#19979;&#38477;&#30340;&#35282;&#24230;&#30740;&#31350;&#26680;&#23725;&#22238;&#24402;&#12290;&#36890;&#36807;&#25552;&#21069;&#20572;&#27490;&#30340;&#27491;&#21017;&#21270;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#38381;&#21512;&#35299;&#65292;&#21363;&#26680;&#26799;&#24230;&#27969;&#65288;KGF&#65289;&#65292;&#24182;&#35777;&#26126;&#20102;KGF&#21644;KRR&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#25105;&#20204;&#36824;&#23558;KRR&#27867;&#21270;&#65292;&#20351;&#29992;$\ell_1$&#21644;$\ell_\infty$&#24809;&#32602;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#20351;&#29992;&#36825;&#20123;&#26041;&#27861;&#24471;&#21040;&#30340;&#35299;&#19982;&#21069;&#21521;&#20998;&#27493;&#22238;&#24402;&#21644;&#31526;&#21495;&#26799;&#24230;&#19979;&#38477;&#32467;&#21512;&#25552;&#21069;&#20572;&#27490;&#24471;&#21040;&#30340;&#35299;&#38750;&#24120;&#30456;&#20284;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#20943;&#23569;&#20102;&#35745;&#31639;&#22797;&#26434;&#24230;&#37325;&#30340;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2306.16838</link><description>&lt;p&gt;
&#29992;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#26041;&#27861;&#35299;&#20915;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Solving Kernel Ridge Regression with Gradient-Based Optimization Methods. (arXiv:2306.16838v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16838
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#65292;&#36890;&#36807;&#31561;&#20215;&#30340;&#30446;&#26631;&#20989;&#25968;&#24418;&#24335;&#21644;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#25105;&#20204;&#19981;&#20165;&#21487;&#20197;&#20351;&#29992;&#20854;&#20182;&#24809;&#32602;&#26041;&#27861;&#65292;&#36824;&#33021;&#22815;&#20174;&#26799;&#24230;&#19979;&#38477;&#30340;&#35282;&#24230;&#30740;&#31350;&#26680;&#23725;&#22238;&#24402;&#12290;&#36890;&#36807;&#25552;&#21069;&#20572;&#27490;&#30340;&#27491;&#21017;&#21270;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#38381;&#21512;&#35299;&#65292;&#21363;&#26680;&#26799;&#24230;&#27969;&#65288;KGF&#65289;&#65292;&#24182;&#35777;&#26126;&#20102;KGF&#21644;KRR&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#25105;&#20204;&#36824;&#23558;KRR&#27867;&#21270;&#65292;&#20351;&#29992;$\ell_1$&#21644;$\ell_\infty$&#24809;&#32602;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#20351;&#29992;&#36825;&#20123;&#26041;&#27861;&#24471;&#21040;&#30340;&#35299;&#19982;&#21069;&#21521;&#20998;&#27493;&#22238;&#24402;&#21644;&#31526;&#21495;&#26799;&#24230;&#19979;&#38477;&#32467;&#21512;&#25552;&#21069;&#20572;&#27490;&#24471;&#21040;&#30340;&#35299;&#38750;&#24120;&#30456;&#20284;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#20943;&#23569;&#20102;&#35745;&#31639;&#22797;&#26434;&#24230;&#37325;&#30340;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#23725;&#22238;&#24402;&#65288;KRR&#65289;&#26159;&#32447;&#24615;&#23725;&#22238;&#24402;&#30340;&#38750;&#32447;&#24615;&#25512;&#24191;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;KRR&#30446;&#26631;&#20989;&#25968;&#30340;&#31561;&#20215;&#24418;&#24335;&#65292;&#20026;&#20351;&#29992;&#20854;&#20182;&#24809;&#32602;&#26041;&#27861;&#21644;&#20174;&#26799;&#24230;&#19979;&#38477;&#30340;&#35282;&#24230;&#30740;&#31350;&#26680;&#23725;&#22238;&#24402;&#25171;&#24320;&#20102;&#21487;&#33021;&#12290;&#36890;&#36807;&#36830;&#32493;&#26102;&#38388;&#30340;&#35270;&#35282;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#38381;&#21512;&#35299;&#8212;&#8212;&#26680;&#26799;&#24230;&#27969;&#65288;KGF&#65289;&#65292;&#36890;&#36807;&#25552;&#21069;&#20572;&#27490;&#30340;&#27491;&#21017;&#21270;&#65292;&#35753;&#25105;&#20204;&#33021;&#22815;&#22312;KGF&#21644;KRR&#20043;&#38388;&#29702;&#35770;&#19978;&#30028;&#23450;&#24046;&#24322;&#12290;&#25105;&#20204;&#29992;$\ell_1$&#21644;$\ell_\infty$&#24809;&#32602;&#26041;&#27861;&#23558;KRR&#27867;&#21270;&#65292;&#24182;&#21033;&#29992;&#31867;&#20284;KGF&#21644;KRR&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#20351;&#29992;&#36825;&#20123;&#24809;&#32602;&#26041;&#27861;&#24471;&#21040;&#30340;&#35299;&#19982;&#20351;&#29992;&#21069;&#21521;&#20998;&#27493;&#22238;&#24402;&#65288;&#20063;&#31216;&#20026;&#22352;&#26631;&#19979;&#38477;&#65289;&#21644;&#31526;&#21495;&#26799;&#24230;&#19979;&#38477;&#32467;&#21512;&#25552;&#21069;&#20572;&#27490;&#24471;&#21040;&#30340;&#35299;&#38750;&#24120;&#30456;&#20284;&#12290;&#22240;&#27492;&#65292;&#20943;&#23569;&#20102;&#35745;&#31639;&#22797;&#26434;&#24230;&#37325;&#30340;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernel ridge regression, KRR, is a non-linear generalization of linear ridge regression. Here, we introduce an equivalent formulation of the objective function of KRR, opening up both for using other penalties than the ridge penalty and for studying kernel ridge regression from the perspective of gradient descent. Using a continuous-time perspective, we derive a closed-form solution, kernel gradient flow, KGF, with regularization through early stopping, which allows us to theoretically bound the differences between KGF and KRR. We generalize KRR by replacing the ridge penalty with the $\ell_1$ and $\ell_\infty$ penalties and utilize the fact that analogously to the similarities between KGF and KRR, the solutions obtained when using these penalties are very similar to those obtained from forward stagewise regression (also known as coordinate descent) and sign gradient descent in combination with early stopping. Thus the need for computationally heavy proximal gradient descent algorithms
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#37325;&#21551;&#8221;&#30340;&#26032;&#22411;&#37319;&#26679;&#31639;&#27861;&#65292;&#20197;&#26356;&#22909;&#22320;&#24179;&#34913;&#31163;&#25955;&#21270;&#35823;&#24046;&#21644;&#25910;&#32553;&#65292;&#21487;&#20197;&#20248;&#21270;&#29983;&#25104;&#36807;&#31243;&#20013;&#30340;&#37319;&#26679;&#36895;&#24230;&#21644;&#26679;&#26412;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2306.14878</link><description>&lt;p&gt;
&#37325;&#21551;&#37319;&#26679;&#20197;&#25552;&#39640;&#29983;&#25104;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Restart Sampling for Improving Generative Processes. (arXiv:2306.14878v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14878
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#37325;&#21551;&#8221;&#30340;&#26032;&#22411;&#37319;&#26679;&#31639;&#27861;&#65292;&#20197;&#26356;&#22909;&#22320;&#24179;&#34913;&#31163;&#25955;&#21270;&#35823;&#24046;&#21644;&#25910;&#32553;&#65292;&#21487;&#20197;&#20248;&#21270;&#29983;&#25104;&#36807;&#31243;&#20013;&#30340;&#37319;&#26679;&#36895;&#24230;&#21644;&#26679;&#26412;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#36807;&#31243;&#20013;&#35299;&#20915;&#24494;&#20998;&#26041;&#31243;&#30340;&#36807;&#31243;&#65292;&#22914;&#25193;&#25955;&#27169;&#22411;&#65292;&#38656;&#35201;&#24179;&#34913;&#36895;&#24230;&#21644;&#36136;&#37327;&#12290;&#22522;&#20110;ODE&#30340;&#37319;&#26679;&#22120;&#36895;&#24230;&#24555;&#20294;&#24615;&#33021;&#24179;&#31283;&#65292;&#32780;&#22522;&#20110;SDE&#30340;&#37319;&#26679;&#22120;&#25552;&#20379;&#26356;&#39640;&#30340;&#26679;&#26412;&#36136;&#37327;&#20294;&#38656;&#35201;&#26356;&#38271;&#30340;&#37319;&#26679;&#26102;&#38388;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#24046;&#24322;&#24402;&#22240;&#20110;&#37319;&#26679;&#35823;&#24046;&#65306;ODE&#37319;&#26679;&#22120;&#28041;&#21450;&#26356;&#23567;&#30340;&#31163;&#25955;&#21270;&#35823;&#24046;&#65292;&#32780;SDE&#30340;&#38543;&#26426;&#24615;&#20250;&#20351;&#32047;&#31215;&#35823;&#24046;&#32553;&#23567;&#12290;&#22522;&#20110;&#36825;&#20123;&#21457;&#29616;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#37325;&#21551;&#30340;&#26032;&#22411;&#37319;&#26679;&#31639;&#27861;&#65292;&#20197;&#26356;&#22909;&#22320;&#24179;&#34913;&#31163;&#25955;&#21270;&#35823;&#24046;&#21644;&#25910;&#32553;&#12290;&#35813;&#37319;&#26679;&#26041;&#27861;&#22312;&#39069;&#22806;&#21069;&#21521;&#27493;&#39588;&#20013;&#20132;&#26367;&#28155;&#21152;&#22823;&#37327;&#22122;&#22768;&#21644;&#20005;&#26684;&#36981;&#24490;&#21518;&#21521;ODE&#12290;&#32463;&#39564;&#35777;&#65292;&#37325;&#21551;&#37319;&#26679;&#22120;&#22312;&#36895;&#24230;&#21644;&#20934;&#30830;&#24615;&#26041;&#38754;&#22343;&#20248;&#20110;&#20808;&#21069;&#30340;SDE&#21644;ODE&#37319;&#26679;&#22120;&#12290;&#22312;CIFAR-10/ImageNet $64 \times 64$&#19978;&#65292;&#37325;&#21551;&#19981;&#20165;&#20248;&#20110;&#20808;&#21069;&#30340;&#26368;&#20339;SDE&#32467;&#26524;&#65292;&#32780;&#19988;&#21152;&#24555;&#20102;&#37319;&#26679;&#36895;&#24230;&#65292;&#20998;&#21035;&#20026;10&#20493;/2&#20493;&#12290;&#27492;&#22806;&#65292;&#23427;&#22312;&#36827;&#34892;&#22270;&#20687;&#29983;&#25104;&#26102;&#36824;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#26679;&#26412;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative processes that involve solving differential equations, such as diffusion models, frequently necessitate balancing speed and quality. ODE-based samplers are fast but plateau in performance while SDE-based samplers deliver higher sample quality at the cost of increased sampling time. We attribute this difference to sampling errors: ODE-samplers involve smaller discretization errors while stochasticity in SDE contracts accumulated errors. Based on these findings, we propose a novel sampling algorithm called Restart in order to better balance discretization errors and contraction. The sampling method alternates between adding substantial noise in additional forward steps and strictly following a backward ODE. Empirically, Restart sampler surpasses previous SDE and ODE samplers in both speed and accuracy. Restart not only outperforms the previous best SDE results, but also accelerates the sampling speed by 10-fold / 2-fold on CIFAR-10 / ImageNet $64 \times 64$. In addition, it at
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Caus-Modens&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#35843;&#21046;&#38598;&#21512;&#26469;&#25551;&#36848;&#22240;&#26524;&#32467;&#26524;&#21306;&#38388;&#65292;&#30456;&#27604;&#31526;&#21512;&#24615;&#39044;&#27979;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#23454;&#36341;&#20013;&#32473;&#20986;&#26356;&#32039;&#23494;&#30340;&#32467;&#26524;&#21306;&#38388;&#12290;</title><link>http://arxiv.org/abs/2306.09520</link><description>&lt;p&gt;
&#38024;&#23545;&#28508;&#22312;&#28151;&#28102;&#19979;&#30340;&#22240;&#26524;&#32467;&#26524;&#30340;&#26356;&#32039;&#23494;&#39044;&#27979;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;
Tighter Prediction Intervals for Causal Outcomes Under Hidden Confounding. (arXiv:2306.09520v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09520
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Caus-Modens&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#35843;&#21046;&#38598;&#21512;&#26469;&#25551;&#36848;&#22240;&#26524;&#32467;&#26524;&#21306;&#38388;&#65292;&#30456;&#27604;&#31526;&#21512;&#24615;&#39044;&#27979;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#23454;&#36341;&#20013;&#32473;&#20986;&#26356;&#32039;&#23494;&#30340;&#32467;&#26524;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23384;&#22312;&#38544;&#34255;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#30830;&#20999;&#20010;&#20307;&#27835;&#30103;&#32467;&#26524;&#30340;&#22240;&#26524;&#25512;&#26029;&#24456;&#23569;&#21487;&#33021;&#12290;&#22240;&#27492;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#25913;&#36827;&#20102;&#31526;&#21512;&#24615;&#39044;&#27979;&#26041;&#27861;&#65292;&#20197;&#20135;&#29983;&#32467;&#26524;&#21306;&#38388;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#31867;&#26041;&#27861;&#24448;&#24448;&#36807;&#20110;&#20445;&#23432;&#65292;&#26377;&#26102;&#20250;&#32473;&#20986;&#26080;&#20449;&#24687;&#37327;&#30340;&#21306;&#38388;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#21478;&#31867;&#26041;&#27861;Caus-Modens&#65292;&#29992;&#20110;&#36890;&#36807;&#35843;&#21046;&#38598;&#21512;&#26469;&#25551;&#36848;&#22240;&#26524;&#32467;&#26524;&#21306;&#38388;&#12290;&#21463;&#21040;&#36125;&#21494;&#26031;&#32479;&#35745;&#21644;&#38598;&#25104;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#21551;&#21457;&#65292;Caus-Modens&#22312;&#23454;&#36341;&#20013;&#32473;&#20986;&#26356;&#32039;&#23494;&#30340;&#32467;&#26524;&#21306;&#38388;&#65292;&#24182;&#36890;&#36807;&#19977;&#20010;&#20998;&#31163;&#22522;&#20934;&#27979;&#35797;&#30340;&#24517;&#35201;&#21306;&#38388;&#22823;&#23567;&#26469;&#23454;&#29616;&#36275;&#22815;&#30340;&#35206;&#30422;&#29575;&#12290;&#26368;&#21518;&#19968;&#20010;&#22522;&#20934;&#26159;&#20351;&#29992;&#26410;&#30693;&#20294;&#21487;&#25506;&#26126;&#30340;&#22522;&#30784;&#20107;&#23454;&#24320;&#23637;&#35266;&#23519;&#23454;&#39564;&#30340;GPT-4&#30340;&#26032;&#22411;&#29992;&#36884;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal inference of exact individual treatment outcomes in the presence of hidden confounders is rarely possible. Instead, recent work has adapted conformal prediction to produce outcome intervals. Unfortunately this family of methods tends to be overly conservative, sometimes giving uninformative intervals. We introduce an alternative approach termed Caus-Modens, for characterizing causal outcome intervals by modulated ensembles. Motivated from Bayesian statistics and ensembled uncertainty quantification, Caus-Modens gives tighter outcome intervals in practice, measured by the necessary interval size to achieve sufficient coverage on three separate benchmarks. The last benchmark is a novel usage of GPT-4 for observational experiments with unknown but probeable ground truth.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#8220;&#25239;&#24178;&#25200;&#32422;&#26463;&#23398;&#20064;&#8221;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#22312;&#37096;&#32626;&#26426;&#22120;&#23398;&#20064;&#35299;&#20915;&#26041;&#26696;&#26102;&#38656;&#35201;&#28385;&#36275;&#38500;&#20102;&#20934;&#30830;&#24615;&#20197;&#22806;&#30340;&#22810;&#20010;&#35201;&#27714;&#65292;&#24182;&#20197;&#24179;&#34913;&#20174;&#25918;&#23485;&#20013;&#33719;&#24471;&#30340;&#24615;&#33021;&#22686;&#30410;&#19982;&#29992;&#25143;&#23450;&#20041;&#30340;&#25918;&#23485;&#25104;&#26412;&#20043;&#38388;&#30340;&#20851;&#31995;&#30340;&#26041;&#24335;&#25918;&#26494;&#23398;&#20064;&#32422;&#26463;&#12290;</title><link>http://arxiv.org/abs/2306.02426</link><description>&lt;p&gt;
&#25239;&#24178;&#25200;&#32422;&#26463;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Resilient Constrained Learning. (arXiv:2306.02426v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02426
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#8220;&#25239;&#24178;&#25200;&#32422;&#26463;&#23398;&#20064;&#8221;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#22312;&#37096;&#32626;&#26426;&#22120;&#23398;&#20064;&#35299;&#20915;&#26041;&#26696;&#26102;&#38656;&#35201;&#28385;&#36275;&#38500;&#20102;&#20934;&#30830;&#24615;&#20197;&#22806;&#30340;&#22810;&#20010;&#35201;&#27714;&#65292;&#24182;&#20197;&#24179;&#34913;&#20174;&#25918;&#23485;&#20013;&#33719;&#24471;&#30340;&#24615;&#33021;&#22686;&#30410;&#19982;&#29992;&#25143;&#23450;&#20041;&#30340;&#25918;&#23485;&#25104;&#26412;&#20043;&#38388;&#30340;&#20851;&#31995;&#30340;&#26041;&#24335;&#25918;&#26494;&#23398;&#20064;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#37096;&#32626;&#26426;&#22120;&#23398;&#20064;&#35299;&#20915;&#26041;&#26696;&#26102;&#65292;&#38500;&#20102;&#20934;&#30830;&#24615;&#20043;&#22806;&#65292;&#23427;&#20204;&#24517;&#39035;&#28385;&#36275;&#22810;&#20010;&#35201;&#27714;&#65292;&#22914;&#20844;&#24179;&#24615;&#12289;&#40065;&#26834;&#24615;&#25110;&#23433;&#20840;&#24615;&#12290;&#36825;&#20123;&#35201;&#27714;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#24809;&#32602;&#26469;&#38544;&#24335;&#22320;&#26045;&#21152;&#65292;&#25110;&#32773;&#36890;&#36807;&#22522;&#20110;Lagrangian&#23545;&#20598;&#30340;&#32422;&#26463;&#20248;&#21270;&#26041;&#27861;&#26469;&#26174;&#24335;&#22320;&#26045;&#21152;&#12290;&#26080;&#35770;&#21738;&#31181;&#26041;&#24335;&#65292;&#25351;&#23450;&#35201;&#27714;&#37117;&#21463;&#21040;&#22949;&#21327;&#21644;&#26377;&#38480;&#30340;&#26377;&#20851;&#25968;&#25454;&#30340;&#20808;&#21069;&#30693;&#35782;&#30340;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#36890;&#24120;&#21482;&#33021;&#36890;&#36807;&#23454;&#38469;&#35299;&#20915;&#23398;&#20064;&#38382;&#39064;&#26469;&#35780;&#20272;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32422;&#26463;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#21516;&#26102;&#35299;&#20915;&#23398;&#20064;&#20219;&#21153;&#30340;&#21516;&#26102;&#35843;&#25972;&#35201;&#27714;&#12290;&#20026;&#27492;&#65292;&#23427;&#20197;&#24179;&#34913;&#20174;&#25918;&#23485;&#20013;&#33719;&#24471;&#30340;&#24615;&#33021;&#22686;&#30410;&#19982;&#29992;&#25143;&#23450;&#20041;&#30340;&#25918;&#23485;&#25104;&#26412;&#20043;&#38388;&#30340;&#20851;&#31995;&#30340;&#26041;&#24335;&#25918;&#26494;&#20102;&#23398;&#20064;&#32422;&#26463;&#12290;&#25105;&#20204;&#23558;&#27492;&#26041;&#27861;&#31216;&#20026;&#20855;&#26377;&#24377;&#24615;&#30340;&#32422;&#26463;&#23398;&#20064;&#65292;&#36825;&#26159;&#23545;&#29992;&#20110;&#25551;&#36848;&#29983;&#24577;&#31995;&#32479;&#30340;&#26415;&#35821;&#30340;&#19968;&#31181;&#20511;&#37492;&#12290;
&lt;/p&gt;
&lt;p&gt;
When deploying machine learning solutions, they must satisfy multiple requirements beyond accuracy, such as fairness, robustness, or safety. These requirements are imposed during training either implicitly, using penalties, or explicitly, using constrained optimization methods based on Lagrangian duality. Either way, specifying requirements is hindered by the presence of compromises and limited prior knowledge about the data. Furthermore, their impact on performance can often only be evaluated by actually solving the learning problem. This paper presents a constrained learning approach that adapts the requirements while simultaneously solving the learning task. To do so, it relaxes the learning constraints in a way that contemplates how much they affect the task at hand by balancing the performance gains obtained from the relaxation against a user-defined cost of that relaxation. We call this approach resilient constrained learning after the term used to describe ecological systems tha
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#8220;&#21021;&#22987;&#29468;&#27979;&#20559;&#24046;&#8221;&#29616;&#35937;&#65292;&#21363;&#22312;&#26410;&#32463;&#36807;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#30001;&#20110;&#26550;&#26500;&#36873;&#25321;&#30340;&#24433;&#21709;&#65292;&#27169;&#22411;&#24448;&#24448;&#20250;&#23558;&#25152;&#26377;&#39044;&#27979;&#25351;&#21521;&#21516;&#19968;&#20010;&#31867;&#21035;&#12290;&#35813;&#29616;&#35937;&#23545;&#26550;&#26500;&#36873;&#25321;&#21644;&#21021;&#22987;&#21270;&#26377;&#23454;&#38469;&#25351;&#23548;&#24847;&#20041;&#65292;&#24182;&#20855;&#26377;&#29702;&#35770;&#21518;&#26524;&#65292;&#20363;&#22914;&#33410;&#28857;&#32622;&#25442;&#23545;&#31216;&#24615;&#30340;&#23849;&#28291;&#21644;&#28145;&#24230;&#24102;&#26469;&#30340;&#38750;&#24179;&#20961;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2306.00809</link><description>&lt;p&gt;
&#21021;&#22987;&#29468;&#27979;&#20559;&#24046;&#65306;&#26410;&#32463;&#36807;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#20542;&#21521;&#20110;&#26576;&#20123;&#31867;&#21035;
&lt;/p&gt;
&lt;p&gt;
Initial Guessing Bias: How Untrained Networks Favor Some Classes. (arXiv:2306.00809v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00809
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#8220;&#21021;&#22987;&#29468;&#27979;&#20559;&#24046;&#8221;&#29616;&#35937;&#65292;&#21363;&#22312;&#26410;&#32463;&#36807;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#30001;&#20110;&#26550;&#26500;&#36873;&#25321;&#30340;&#24433;&#21709;&#65292;&#27169;&#22411;&#24448;&#24448;&#20250;&#23558;&#25152;&#26377;&#39044;&#27979;&#25351;&#21521;&#21516;&#19968;&#20010;&#31867;&#21035;&#12290;&#35813;&#29616;&#35937;&#23545;&#26550;&#26500;&#36873;&#25321;&#21644;&#21021;&#22987;&#21270;&#26377;&#23454;&#38469;&#25351;&#23548;&#24847;&#20041;&#65292;&#24182;&#20855;&#26377;&#29702;&#35770;&#21518;&#26524;&#65292;&#20363;&#22914;&#33410;&#28857;&#32622;&#25442;&#23545;&#31216;&#24615;&#30340;&#23849;&#28291;&#21644;&#28145;&#24230;&#24102;&#26469;&#30340;&#38750;&#24179;&#20961;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#30340;&#21021;&#22987;&#29366;&#24577;&#22312;&#35843;&#33410;&#21518;&#32493;&#30340;&#35757;&#32451;&#36807;&#31243;&#20013;&#25198;&#28436;&#37325;&#35201;&#35282;&#33394;&#12290;&#22312;&#20998;&#31867;&#38382;&#39064;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#35777;&#26126;&#31070;&#32463;&#32593;&#32476;&#30340;&#32467;&#26500;&#21487;&#20197;&#22312;&#35757;&#32451;&#20043;&#21069;&#65292;&#29978;&#33267;&#22312;&#19981;&#23384;&#22312;&#26174;&#24335;&#20559;&#24046;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#27169;&#22411;&#23558;&#25152;&#26377;&#39044;&#27979;&#37117;&#25351;&#21521;&#21516;&#19968;&#20010;&#31867;&#21035;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#29616;&#35937;&#30340;&#23384;&#22312;&#65292;&#31216;&#20026;&#8220;&#21021;&#22987;&#29468;&#27979;&#20559;&#24046;&#8221;&#65288;Initial Guessing Bias&#65292;IGB&#65289;&#65292;&#36825;&#21462;&#20915;&#20110;&#26550;&#26500;&#36873;&#25321;&#65292;&#20363;&#22914;&#28608;&#27963;&#20989;&#25968;&#12289;&#26368;&#22823;&#27744;&#21270;&#23618;&#21644;&#32593;&#32476;&#28145;&#24230;&#12290;&#25105;&#20204;&#23545;IGB&#36827;&#34892;&#30340;&#20998;&#26512;&#20855;&#26377;&#23454;&#38469;&#24847;&#20041;&#65292;&#21487;&#20197;&#25351;&#23548;&#26550;&#26500;&#30340;&#36873;&#25321;&#21644;&#21021;&#22987;&#21270;&#12290;&#25105;&#20204;&#36824;&#24378;&#35843;&#29702;&#35770;&#21518;&#26524;&#65292;&#20363;&#22914;&#33410;&#28857;&#32622;&#25442;&#23545;&#31216;&#24615;&#30340;&#23849;&#28291;&#12289;&#33258;&#24179;&#22343;&#30340;&#30772;&#22351;&#12289;&#26576;&#20123;&#22343;&#22330;&#36817;&#20284;&#30340;&#26377;&#25928;&#24615;&#20197;&#21450;&#28145;&#24230;&#24102;&#26469;&#30340;&#38750;&#24179;&#20961;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
The initial state of neural networks plays a central role in conditioning the subsequent training dynamics. In the context of classification problems, we provide a theoretical analysis demonstrating that the structure of a neural network can condition the model to assign all predictions to the same class, even before the beginning of training, and in the absence of explicit biases. We show that the presence of this phenomenon, which we call "Initial Guessing Bias" (IGB), depends on architectural choices such as activation functions, max-pooling layers, and network depth. Our analysis of IGB has practical consequences, in that it guides architecture selection and initialization. We also highlight theoretical consequences, such as the breakdown of node-permutation symmetry, the violation of self-averaging, the validity of some mean-field approximations, and the non-trivial differences arising with depth.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#22522;&#20110;&#26680;&#30340;&#21452;&#37325;&#31283;&#20581;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#26816;&#39564;&#27835;&#30103;&#30340;&#20998;&#24067;&#25928;&#24212;&#65292;&#20445;&#35777;&#20102;&#19968;&#31867;&#38169;&#35823;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.13237</link><description>&lt;p&gt;
&#19968;&#31181;&#26377;&#25928;&#30340;&#21452;&#37325;&#31283;&#20581;&#26680;&#22788;&#29702;&#25928;&#24212;&#26816;&#39564;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Efficient Doubly-Robust Test for the Kernel Treatment Effect. (arXiv:2304.13237v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13237
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#22522;&#20110;&#26680;&#30340;&#21452;&#37325;&#31283;&#20581;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#26816;&#39564;&#27835;&#30103;&#30340;&#20998;&#24067;&#25928;&#24212;&#65292;&#20445;&#35777;&#20102;&#19968;&#31867;&#38169;&#35823;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20108;&#20998;&#27835;&#30103;&#19979;&#30340;&#39044;&#26399;&#21453;&#20107;&#23454;&#24046;&#24322;&#26159;&#22240;&#26524;&#25512;&#26029;&#20013;&#26368;&#21463;&#27426;&#36814;&#30340;&#30446;&#26631;&#25928;&#24212;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#27835;&#30103;&#21487;&#33021;&#20855;&#26377;&#36229;&#20986;&#24179;&#22343;&#20540;&#30340;&#25928;&#24212;&#65292;&#20363;&#22914;&#38477;&#20302;&#25110;&#25552;&#39640;&#26041;&#24046;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#26680;&#30340;&#27835;&#30103;&#25928;&#24212;&#20998;&#24067;&#26816;&#39564;&#26041;&#27861;&#12290;&#26412;&#25991;&#30340;&#26041;&#27861;&#26159;&#22522;&#20110;&#26680;&#30340;&#12289;&#31283;&#20581;&#30340;&#65292;&#20445;&#35777;&#20102;&#19968;&#31867;&#38169;&#35823;&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#26159;&#39640;&#25928;&#30340;&#65292;&#36991;&#20813;&#20102;&#32622;&#25442;&#30340;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
The average treatment effect, which is the difference in expectation of the counterfactuals, is probably the most popular target effect in causal inference with binary treatments. However, treatments may have effects beyond the mean, for instance decreasing or increasing the variance. We propose a new kernel-based test for distributional effects of the treatment. It is, to the best of our knowledge, the first kernel-based, doubly-robust test with provably valid type-I error. Furthermore, our proposed algorithm is efficient, avoiding the use of permutations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#38750;&#32447;&#24615;&#20989;&#25968;&#26500;&#24314;&#20132;&#21449;&#30456;&#20851;&#22120;&#30340;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;Price&#23450;&#29702;&#21644;&#20998;&#27573;&#32447;&#24615;&#20998;&#35299;&#25552;&#20986;&#20102;&#19968;&#20010;&#25968;&#23398;&#26694;&#26550;&#26469;&#20998;&#26512;&#36825;&#31181;&#20132;&#21449;&#30456;&#20851;&#22120;&#12290;</title><link>http://arxiv.org/abs/2304.09242</link><description>&lt;p&gt;
&#20351;&#29992;Price&#23450;&#29702;&#21644;&#20998;&#27573;&#32447;&#24615;&#20998;&#35299;&#20998;&#26512;&#22312;&#32447;&#20132;&#21449;&#30456;&#20851;&#22120;&#30340;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Framework for Analyzing Online Cross-correlators using Price's Theorem and Piecewise-Linear Decomposition. (arXiv:2304.09242v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09242
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#38750;&#32447;&#24615;&#20989;&#25968;&#26500;&#24314;&#20132;&#21449;&#30456;&#20851;&#22120;&#30340;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;Price&#23450;&#29702;&#21644;&#20998;&#27573;&#32447;&#24615;&#20998;&#35299;&#25552;&#20986;&#20102;&#19968;&#20010;&#25968;&#23398;&#26694;&#26550;&#26469;&#20998;&#26512;&#36825;&#31181;&#20132;&#21449;&#30456;&#20851;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31934;&#30830;&#20272;&#35745;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#30340;&#20132;&#21449;&#30456;&#20851;&#25110;&#30456;&#20284;&#24230;&#26159;&#20449;&#21495;&#26816;&#27979;&#12289;&#39640;&#32500;&#35745;&#31639;&#12289;&#32852;&#24819;&#35760;&#24518;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#26680;&#24515;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#26500;&#24314;&#20855;&#26377;&#26356;&#39640;&#20449;&#22122;&#27604;&#65288;SNR&#65289;&#30340;&#20132;&#21449;&#30456;&#20851;&#22120;&#30340;&#22823;&#37327;&#31616;&#21333;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;Price&#23450;&#29702;&#21644;&#20998;&#27573;&#32447;&#24615;&#20998;&#35299;&#25552;&#20986;&#20102;&#19968;&#20010;&#25968;&#23398;&#26694;&#26550;&#65292;&#20197;&#20998;&#26512;&#20351;&#29992;&#28151;&#21512;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#26500;&#24314;&#30340;&#20132;&#21449;&#30456;&#20851;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Precise estimation of cross-correlation or similarity between two random variables lies at the heart of signal detection, hyperdimensional computing, associative memories, and neural networks. Although a vast literature exists on different methods for estimating cross-correlations, the question what is the best and simplest method to estimate cross-correlations using finite samples ? is still not clear. In this paper, we first argue that the standard empirical approach might not be the optimal method even though the estimator exhibits uniform convergence to the true cross-correlation. Instead, we show that there exists a large class of simple non-linear functions that can be used to construct cross-correlators with a higher signal-to-noise ratio (SNR). To demonstrate this, we first present a general mathematical framework using Price's Theorem that allows us to analyze cross-correlators constructed using a mixture of piece-wise linear functions. Using this framework and high-dimensiona
&lt;/p&gt;</description></item><item><title>&#25991;&#31456;&#25506;&#35752;&#20102;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#20013;&#25214;&#21040;&#22240;&#26524;&#39034;&#24207;&#30340;&#26041;&#27861;&#12290;&#20316;&#32773;&#21457;&#29616;&#38500;&#20102;&#26041;&#24046;&#25490;&#24207;&#22806;&#65292;&#21464;&#37327;&#30340;&#20915;&#23450;&#31995;&#25968;$R^2$&#25490;&#24207;&#20063;&#21487;&#29992;&#20110;&#21305;&#37197;&#24050;&#26377;&#26041;&#27861;&#30340;&#34920;&#29616;&#65292;&#19988;&#19981;&#21463;&#25968;&#25454;&#32553;&#25918;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2303.18211</link><description>&lt;p&gt;
&#31616;&#21333;&#30340;&#25490;&#24207;&#26631;&#20934;&#26377;&#21161;&#20110;&#22312;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#20013;&#25214;&#21040;&#22240;&#26524;&#39034;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;
Simple Sorting Criteria Help Find the Causal Order in Additive Noise Models. (arXiv:2303.18211v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.18211
&lt;/p&gt;
&lt;p&gt;
&#25991;&#31456;&#25506;&#35752;&#20102;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#20013;&#25214;&#21040;&#22240;&#26524;&#39034;&#24207;&#30340;&#26041;&#27861;&#12290;&#20316;&#32773;&#21457;&#29616;&#38500;&#20102;&#26041;&#24046;&#25490;&#24207;&#22806;&#65292;&#21464;&#37327;&#30340;&#20915;&#23450;&#31995;&#25968;$R^2$&#25490;&#24207;&#20063;&#21487;&#29992;&#20110;&#21305;&#37197;&#24050;&#26377;&#26041;&#27861;&#30340;&#34920;&#29616;&#65292;&#19988;&#19981;&#21463;&#25968;&#25454;&#32553;&#25918;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#65288;ANM&#65289;&#26159;&#19968;&#31181;&#24120;&#35265;&#30340;&#21151;&#33021;&#20551;&#35774;&#65292;&#21487;&#20197;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#23398;&#20064;&#22240;&#26524;&#32467;&#26500;&#12290;&#30001;&#20110;&#32570;&#20047;&#31526;&#21512;&#20551;&#35774;&#30340;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#65292;&#21512;&#25104;ANM&#25968;&#25454;&#32463;&#24120;&#29992;&#20110;&#35780;&#20272;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#12290;Reisach&#31561;&#20154;&#65288;2021&#65289;&#34920;&#26126;&#65292;&#23545;&#20110;&#24120;&#35265;&#30340;&#27169;&#25311;&#21442;&#25968;&#65292;&#25353;&#22686;&#22823;&#26041;&#24046;&#30340;&#39034;&#24207;&#21464;&#37327;&#25490;&#21015;&#19982;&#22240;&#26524;&#39034;&#24207;&#23494;&#20999;&#30456;&#20851;&#65292;&#24182;&#24341;&#20837;&#21464;&#24322;&#24615;&#21487;&#25490;&#24207;&#24615;&#26469;&#37327;&#21270;&#36825;&#31181;&#23545;&#40784;&#31243;&#24230;&#12290;&#26412;&#25991;&#36824;&#34920;&#26126;&#65292;&#38500;&#20102;&#26041;&#24046;&#65292;&#36824;&#26377;&#21464;&#37327;&#30340;&#26041;&#24046;&#34987;&#25152;&#26377;&#20854;&#20182;&#21464;&#37327;&#35299;&#37322;&#30340;&#27604;&#20363;&#65288;&#30001;&#20915;&#23450;&#31995;&#25968;$R^2$&#25429;&#33719;&#65289;&#20542;&#21521;&#20110;&#27839;&#30528;&#22240;&#26524;&#39034;&#24207;&#22686;&#21152;&#12290;&#31616;&#21333;&#30340;&#22522;&#20934;&#31639;&#27861;&#21487;&#20197;&#20351;&#29992;$R^2$-sortability&#26469;&#21305;&#37197;&#24050;&#26377;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#30001;&#20110;$R^2$&#21487;&#25490;&#24207;&#24615;&#19981;&#21463;&#25968;&#25454;&#32553;&#25918;&#30340;&#24433;&#21709;&#65292;&#36825;&#20123;&#31639;&#27861;&#22312;&#26631;&#20934;&#21270;&#25110;&#37325;&#26032;&#32553;&#25918;&#30340;&#25968;&#25454;&#19978;&#34920;&#29616;&#21516;&#26679;&#20986;&#33394;&#65292;&#35299;&#20915;&#20102;&#21033;&#29992;&#21464;&#24322;&#24615;&#21487;&#25490;&#24207;&#24615;&#30340;&#31639;&#27861;&#30340;&#19968;&#20010;&#20851;&#38190;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Additive Noise Models (ANM) encode a popular functional assumption that enables learning causal structure from observational data. Due to a lack of real-world data meeting the assumptions, synthetic ANM data are often used to evaluate causal discovery algorithms. Reisach et al. (2021) show that, for common simulation parameters, a variable ordering by increasing variance is closely aligned with a causal order and introduce var-sortability to quantify the alignment. Here, we show that not only variance, but also the fraction of a variable's variance explained by all others, as captured by the coefficient of determination $R^2$, tends to increase along the causal order. Simple baseline algorithms can use $R^2$-sortability to match the performance of established methods. Since $R^2$-sortability is invariant under data rescaling, these algorithms perform equally well on standardized or rescaled data, addressing a key limitation of algorithms exploiting var-sortability. We characterize and 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#34920;&#26126;&#65292;&#25511;&#21046;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#30340;&#33539;&#25968;&#21487;&#20197;&#33719;&#24471;&#33391;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#23545;&#31070;&#32463;&#32593;&#32476;&#20013;&#20559;&#24046;&#39033;&#30340;&#33539;&#25968;&#36827;&#34892;&#24809;&#32602;&#21487;&#20197;&#23454;&#29616;&#31232;&#30095;&#20272;&#35745;&#37327;&#12290;</title><link>http://arxiv.org/abs/2303.01353</link><description>&lt;p&gt;
&#23545;&#27491;&#21017;&#21270;&#20013;&#30340;&#20559;&#24046;&#36827;&#34892;&#24809;&#32602;&#23558;&#20351;&#31232;&#30095;&#21270;
&lt;/p&gt;
&lt;p&gt;
Penalising the biases in norm regularisation enforces sparsity. (arXiv:2303.01353v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.01353
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#34920;&#26126;&#65292;&#25511;&#21046;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#30340;&#33539;&#25968;&#21487;&#20197;&#33719;&#24471;&#33391;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#23545;&#31070;&#32463;&#32593;&#32476;&#20013;&#20559;&#24046;&#39033;&#30340;&#33539;&#25968;&#36827;&#34892;&#24809;&#32602;&#21487;&#20197;&#23454;&#29616;&#31232;&#30095;&#20272;&#35745;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26102;&#65292;&#36890;&#36807;&#25511;&#21046;&#21442;&#25968;&#30340;&#33539;&#25968;&#24448;&#24448;&#21487;&#20197;&#33719;&#24471;&#33391;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#27491;&#21017;&#21270;&#21442;&#25968;&#30340;&#33539;&#25968;&#21644;&#25152;&#24471;&#20272;&#35745;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#22312;&#29702;&#35770;&#19978;&#23578;&#26410;&#23436;&#20840;&#29702;&#35299;&#12290;&#26412;&#25991;&#38024;&#23545;&#20855;&#26377;&#21333;&#19968;&#38544;&#34255;&#23618;&#21644;&#19968;&#32500;&#25968;&#25454;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#23637;&#31034;&#20102;&#34920;&#31034;&#20989;&#25968;&#25152;&#38656;&#30340;&#21442;&#25968;&#33539;&#25968;&#30001;&#20854;&#20108;&#38454;&#23548;&#25968;&#30340;&#24635;&#21464;&#24046;&#21152;&#26435;&#24471;&#21040;&#65292;&#20854;&#20013;&#25152;&#21152;&#26435;&#30340;&#22240;&#23376;&#20026;$\sqrt{1+x^2}$&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#24403;&#19981;&#23545;&#20559;&#24046;&#39033;&#30340;&#33539;&#25968;&#36827;&#34892;&#27491;&#21017;&#21270;&#26102;&#65292;&#36825;&#20010;&#21152;&#26435;&#22240;&#23376;&#20250;&#28040;&#22833;&#12290;&#36825;&#20010;&#39069;&#22806;&#30340;&#21152;&#26435;&#22240;&#23376;&#30340;&#23384;&#22312;&#38750;&#24120;&#37325;&#35201;&#65292;&#22240;&#20026;&#23427;&#34987;&#35777;&#26126;&#21487;&#20197;&#24378;&#21046;&#23454;&#29616;&#26368;&#23567;&#33539;&#25968;&#20869;&#25554;&#22120;&#30340;&#21807;&#19968;&#24615;&#21644;&#31232;&#30095;&#24615;&#65288;&#22312;&#25296;&#28857;&#25968;&#37327;&#19978;&#65289;&#12290;&#30456;&#21453;&#65292;&#30465;&#30053;&#20559;&#24046;&#30340;&#33539;&#25968;&#21017;&#20250;&#23548;&#33268;&#38750;&#31232;&#30095;&#35299;&#12290;&#22240;&#27492;&#65292;&#22312;&#27491;&#21017;&#21270;&#20013;&#23545;&#20559;&#24046;&#39033;&#36827;&#34892;&#24809;&#32602;&#65292;&#26080;&#35770;&#26159;&#26174;&#24335;&#36824;&#26159;&#38544;&#24335;&#22320;&#65292;&#37117;&#20250;&#23548;&#33268;&#31232;&#30095;&#20272;&#35745;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Controlling the parameters' norm often yields good generalisation when training neural networks. Beyond simple intuitions, the relation between regularising parameters' norm and obtained estimators remains theoretically misunderstood. For one hidden ReLU layer networks with unidimensional data, this work shows the parameters' norm required to represent a function is given by the total variation of its second derivative, weighted by a $\sqrt{1+x^2}$ factor. Notably, this weighting factor disappears when the norm of bias terms is not regularised. The presence of this additional weighting factor is of utmost significance as it is shown to enforce the uniqueness and sparsity (in the number of kinks) of the minimal norm interpolator. Conversely, omitting the bias' norm allows for non-sparse solutions. Penalising the bias terms in the regularisation, either explicitly or implicitly, thus leads to sparse estimators.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#32467;&#26500;&#30340;&#22810;&#26679;&#21270;&#20998;&#24067;&#36716;&#25442;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#38024;&#23545;&#24615;&#22320;&#35774;&#35745;&#20102;&#25968;&#25454;&#38598;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#36825;&#20123;&#20998;&#24067;&#36716;&#25442;&#23545;&#20110;&#29616;&#26377;&#30340;&#22270;&#27169;&#22411;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.13875</link><description>&lt;p&gt;
&#22312;&#32467;&#26500;&#20998;&#24067;&#20559;&#31227;&#26465;&#20214;&#19979;&#35780;&#20272;&#22270;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Evaluating Robustness and Uncertainty of Graph Models Under Structural Distributional Shifts. (arXiv:2302.13875v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.13875
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#32467;&#26500;&#30340;&#22810;&#26679;&#21270;&#20998;&#24067;&#36716;&#25442;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#38024;&#23545;&#24615;&#22320;&#35774;&#35745;&#20102;&#25968;&#25454;&#38598;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#36825;&#20123;&#20998;&#24067;&#36716;&#25442;&#23545;&#20110;&#29616;&#26377;&#30340;&#22270;&#27169;&#22411;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#21487;&#38752;&#20915;&#31574;&#31995;&#32479;&#20013;&#65292;&#27169;&#22411;&#24517;&#39035;&#23545;&#20998;&#24067;&#20559;&#31227;&#20855;&#26377;&#40065;&#26834;&#24615;&#25110;&#25552;&#20379;&#20854;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#22312;&#22270;&#23398;&#20064;&#30340;&#33410;&#28857;&#32423;&#38382;&#39064;&#20013;&#65292;&#20998;&#24067;&#20559;&#31227;&#21487;&#33021;&#23588;&#20026;&#22797;&#26434;&#65292;&#22240;&#20026;&#26679;&#26412;&#26159;&#30456;&#20114;&#20381;&#36182;&#30340;&#12290;&#20026;&#20102;&#35780;&#20272;&#22270;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#37325;&#35201;&#30340;&#26159;&#22312;&#21508;&#31181;&#26377;&#24847;&#20041;&#30340;&#20998;&#24067;&#20559;&#31227;&#19979;&#23545;&#23427;&#20204;&#36827;&#34892;&#27979;&#35797;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#32771;&#34385;&#33410;&#28857;&#32423;&#20998;&#24067;&#20559;&#31227;&#30340;&#22270;&#22522;&#20934;&#20027;&#35201;&#20851;&#27880;&#33410;&#28857;&#29305;&#24449;&#65292;&#32780;&#32467;&#26500;&#23646;&#24615;&#23545;&#22270;&#38382;&#39064;&#20063;&#24456;&#37325;&#35201;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#32467;&#26500;&#24341;&#20986;&#22810;&#26679;&#21270;&#20998;&#24067;&#20559;&#31227;&#30340;&#36890;&#29992;&#26041;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#31181;&#26041;&#27861;&#26681;&#25454;&#20960;&#20010;&#33410;&#28857;&#30340;&#32467;&#26500;&#23646;&#24615;&#65306;&#27969;&#34892;&#24230;&#12289;&#23616;&#37096;&#24615;&#21644;&#23494;&#24230;&#26469;&#21019;&#24314;&#25968;&#25454;&#20998;&#21106;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#20840;&#38754;&#35780;&#20272;&#20102;&#25152;&#25552;&#20986;&#30340;&#20998;&#24067;&#20559;&#31227;&#65292;&#24182;&#34920;&#26126;&#23427;&#20204;&#23545;&#20110;&#29616;&#26377;&#30340;&#22270;&#27169;&#22411;&#21487;&#33021;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#36824;&#20462;&#35746;&#20102;&#19968;&#20123;&#20851;&#20110;&#22522;&#20934;&#27979;&#35797;&#22270;&#27169;&#22411;&#30340;&#20808;&#21069;&#24037;&#20316;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#32452;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#32771;&#34385;&#20102;&#32467;&#26500;&#20998;&#24067;&#20559;&#31227;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
In reliable decision-making systems based on machine learning, models have to be robust to distributional shifts or provide the uncertainty of their predictions. In node-level problems of graph learning, distributional shifts can be especially complex since the samples are interdependent. To evaluate the performance of graph models, it is important to test them on diverse and meaningful distributional shifts. However, most graph benchmarks considering distributional shifts for node-level problems focus mainly on node features, while structural properties are also essential for graph problems. In this work, we propose a general approach for inducing diverse distributional shifts based on graph structure. We use this approach to create data splits according to several structural node properties: popularity, locality, and density. In our experiments, we thoroughly evaluate the proposed distributional shifts and show that they can be quite challenging for existing graph models. We also rev
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#27880;&#24847;&#21147;&#26426;&#21046;&#12289;&#33021;&#37327;&#27169;&#22411;&#21644;&#32852;&#24819;&#35760;&#24518;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26550;&#26500;&#8212;&#8212;&#33021;&#37327;&#21464;&#25442;&#22120;&#65288;ET&#65289;&#65292;&#23427;&#36890;&#36807;&#29305;&#24847;&#35774;&#35745;&#30340;&#27880;&#24847;&#21147;&#23618;&#20197;&#26368;&#23567;&#21270;&#33021;&#37327;&#20989;&#25968;&#65292;&#29992;&#20110;&#34920;&#31034;&#26631;&#35760;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2302.07253</link><description>&lt;p&gt;
&#33021;&#37327;&#21464;&#25442;&#22120;
&lt;/p&gt;
&lt;p&gt;
Energy Transformer. (arXiv:2302.07253v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07253
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#27880;&#24847;&#21147;&#26426;&#21046;&#12289;&#33021;&#37327;&#27169;&#22411;&#21644;&#32852;&#24819;&#35760;&#24518;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26550;&#26500;&#8212;&#8212;&#33021;&#37327;&#21464;&#25442;&#22120;&#65288;ET&#65289;&#65292;&#23427;&#36890;&#36807;&#29305;&#24847;&#35774;&#35745;&#30340;&#27880;&#24847;&#21147;&#23618;&#20197;&#26368;&#23567;&#21270;&#33021;&#37327;&#20989;&#25968;&#65292;&#29992;&#20110;&#34920;&#31034;&#26631;&#35760;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30340;&#24037;&#20316;&#23558;&#27880;&#24847;&#21147;&#26426;&#21046;&#12289;&#33021;&#37327;&#27169;&#22411;&#21644;&#32852;&#24819;&#35760;&#24518;&#19977;&#31181;&#28508;&#21147;&#24040;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#33539;&#24335;&#32467;&#21512;&#36215;&#26469;&#12290;&#27880;&#24847;&#21147;&#26159;&#25512;&#21160;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#25104;&#21151;&#30340;&#21160;&#21147;&#28304;&#65292;&#20294;&#23427;&#32570;&#20047;&#26126;&#30830;&#30340;&#29702;&#35770;&#22522;&#30784;&#12290;&#33021;&#37327;&#27169;&#22411;&#20801;&#35768;&#22312;&#21028;&#21035;&#21644;&#29983;&#25104;&#20219;&#21153;&#19978;&#37319;&#29992;&#26377;&#21407;&#21017;&#30340;&#26041;&#27861;&#65292;&#20294;&#33021;&#37327;&#20989;&#25968;&#30340;&#35774;&#35745;&#24182;&#19981;&#30452;&#35266;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#31264;&#23494;&#32852;&#24819;&#35760;&#24518;&#27169;&#22411;&#25110;&#29616;&#20195;&#38669;&#26222;&#33778;&#23572;&#24503;&#32593;&#32476;&#20855;&#26377;&#33391;&#22909;&#30340;&#29702;&#35770;&#22522;&#30784;&#65292;&#24182;&#19988;&#20801;&#35768;&#33021;&#37327;&#20989;&#25968;&#30340;&#30452;&#35266;&#35774;&#35745;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26550;&#26500;&#65292;&#31216;&#20026;&#33021;&#37327;&#21464;&#25442;&#22120;&#65288;&#31616;&#31216;ET&#65289;&#65292;&#23427;&#20351;&#29992;&#19968;&#31995;&#21015;&#32463;&#36807;&#29305;&#24847;&#35774;&#35745;&#20197;&#26368;&#23567;&#21270;&#29305;&#27530;&#35774;&#35745;&#30340;&#33021;&#37327;&#20989;&#25968;&#30340;&#27880;&#24847;&#21147;&#23618;&#65292;&#35813;&#20989;&#25968;&#36127;&#36131;&#34920;&#31034;&#26631;&#35760;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;ET&#30340;&#29702;&#35770;&#22522;&#30784;&#65292;&#36890;&#36807;&#20351;&#29992;&#22270;&#20687;&#34917;&#20840;&#25216;&#26415;&#25506;&#32034;&#20102;&#23427;&#30340;&#32463;&#39564;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Our work combines aspects of three promising paradigms in machine learning, namely, attention mechanism, energy-based models, and associative memory. Attention is the power-house driving modern deep learning successes, but it lacks clear theoretical foundations. Energy-based models allow a principled approach to discriminative and generative tasks, but the design of the energy functional is not straightforward. At the same time, Dense Associative Memory models or Modern Hopfield Networks have a well-established theoretical foundation, and allow an intuitive design of the energy function. We propose a novel architecture, called the Energy Transformer (or ET for short), that uses a sequence of attention layers that are purposely designed to minimize a specifically engineered energy function, which is responsible for representing the relationships between the tokens. In this work, we introduce the theoretical foundations of ET, explore its empirical capabilities using the image completion
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20998;&#25968;&#30340;&#26465;&#20214;&#27169;&#22411;&#20013;&#23398;&#20064;&#34920;&#31034;&#30340;&#32467;&#26500;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#25968;&#23398;&#24418;&#24335;&#21270;&#34920;&#36798;&#27010;&#24565;&#34987;&#32534;&#30721;&#20026;&#34920;&#31034;&#31354;&#38388;&#23376;&#31354;&#38388;&#30340;&#24605;&#24819;&#12290;&#21033;&#29992;&#36825;&#20010;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#32473;&#23450;&#27010;&#24565;&#23545;&#24212;&#30340;&#34920;&#31034;&#37096;&#20998;&#65292;&#24182;&#36890;&#36807;&#20195;&#25968;&#25805;&#20316;&#25805;&#32437;&#27169;&#22411;&#25152;&#34920;&#36798;&#30340;&#27010;&#24565;&#12290;</title><link>http://arxiv.org/abs/2302.03693</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#30340;&#26465;&#20214;&#27169;&#22411;&#30340;&#27010;&#24565;&#20195;&#25968;
&lt;/p&gt;
&lt;p&gt;
Concept Algebra for Score-Based Conditional Models. (arXiv:2302.03693v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03693
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20998;&#25968;&#30340;&#26465;&#20214;&#27169;&#22411;&#20013;&#23398;&#20064;&#34920;&#31034;&#30340;&#32467;&#26500;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#25968;&#23398;&#24418;&#24335;&#21270;&#34920;&#36798;&#27010;&#24565;&#34987;&#32534;&#30721;&#20026;&#34920;&#31034;&#31354;&#38388;&#23376;&#31354;&#38388;&#30340;&#24605;&#24819;&#12290;&#21033;&#29992;&#36825;&#20010;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#32473;&#23450;&#27010;&#24565;&#23545;&#24212;&#30340;&#34920;&#31034;&#37096;&#20998;&#65292;&#24182;&#36890;&#36807;&#20195;&#25968;&#25805;&#20316;&#25805;&#32437;&#27169;&#22411;&#25152;&#34920;&#36798;&#30340;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25991;&#26412;&#24341;&#23548;&#29983;&#25104;&#27169;&#22411;&#20013;&#23398;&#20064;&#34920;&#31034;&#30340;&#32467;&#26500;&#65292;&#37325;&#28857;&#20851;&#27880;&#22522;&#20110;&#20998;&#25968;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#32858;&#28966;&#20110;&#27010;&#24565;&#34987;&#32534;&#30721;&#20026;&#26576;&#31181;&#34920;&#31034;&#31354;&#38388;&#30340;&#23376;&#31354;&#38388;&#65288;&#25110;&#26041;&#21521;&#65289;&#30340;&#24605;&#24819;&#65292;&#24182;&#24320;&#21457;&#20102;&#36825;&#20010;&#24605;&#24819;&#30340;&#25968;&#23398;&#24418;&#24335;&#21270;&#12290;&#21033;&#29992;&#36825;&#20010;&#24418;&#24335;&#21270;&#26041;&#27861;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26377;&#19968;&#20010;&#33258;&#28982;&#30340;&#34920;&#31034;&#36873;&#25321;&#20855;&#26377;&#36825;&#31181;&#24615;&#36136;&#65292;&#24182;&#19988;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#19982;&#32473;&#23450;&#27010;&#24565;&#23545;&#24212;&#30340;&#34920;&#31034;&#37096;&#20998;&#12290;&#29305;&#21035;&#26159;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#23545;&#34920;&#31034;&#30340;&#20195;&#25968;&#25805;&#20316;&#26469;&#25805;&#32437;&#27169;&#22411;&#25152;&#34920;&#36798;&#30340;&#27010;&#24565;&#12290;&#25105;&#20204;&#20351;&#29992;&#31283;&#23450;&#25193;&#25955;&#22312;&#25991;&#26412;&#24341;&#23548;&#22270;&#20687;&#29983;&#25104;&#30340;&#31034;&#20363;&#20013;&#28436;&#31034;&#20102;&#36825;&#20010;&#24605;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper concerns the structure of learned representations in text-guided generative models, focusing on score-based models. Here, we focus on the idea that concepts are encoded as subspaces (or directions) of some representation space. We develop a mathematical formalization of this idea.Using this formalism, we show there's a natural choice of representation with this property, and we develop a simple method for identifying the part of the representation corresponding to a given concept. In particular, this allows us to manipulate the concepts expressed by the model through algebraic manipulation of the representation. We demonstrate the idea with examples text-guided image generation, using Stable Diffusion.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#24517;&#35201;&#21644;&#20805;&#20998;&#22240;&#26524;&#22270;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#21457;&#29616;&#19982;&#24863;&#20852;&#36259;&#32467;&#26524;&#30456;&#20851;&#30340;&#22240;&#26524;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2301.12389</link><description>&lt;p&gt;
&#23398;&#20064;&#24517;&#35201;&#21644;&#20805;&#20998;&#22240;&#26524;&#22270;
&lt;/p&gt;
&lt;p&gt;
On Learning Necessary and Sufficient Causal Graphs. (arXiv:2301.12389v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12389
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#24517;&#35201;&#21644;&#20805;&#20998;&#22240;&#26524;&#22270;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#21457;&#29616;&#19982;&#24863;&#20852;&#36259;&#32467;&#26524;&#30456;&#20851;&#30340;&#22240;&#26524;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#38761;&#21629;&#28608;&#21457;&#20102;&#23545;&#21508;&#20010;&#39046;&#22495;&#20013;&#22797;&#26434;&#20851;&#31995;&#30340;&#20852;&#36259;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#26088;&#22312;&#22312;&#22797;&#26434;&#30340;&#22823;&#35268;&#27169;&#22270;&#20013;&#21457;&#29616;&#25152;&#26377;&#21464;&#37327;&#20043;&#38388;&#30340;&#22240;&#26524;&#20851;&#31995;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#22270;&#20013;&#20165;&#26377;&#30340;&#19968;&#23567;&#37096;&#20998;&#21464;&#37327;&#19982;&#24863;&#20852;&#36259;&#30340;&#32467;&#26524;&#30456;&#20851;&#12290;&#22240;&#27492;&#65292;&#20351;&#29992;&#23436;&#25972;&#30340;&#22240;&#26524;&#22270;&#36827;&#34892;&#22240;&#26524;&#20272;&#35745;&#65292;&#29305;&#21035;&#26159;&#22312;&#25968;&#25454;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#22823;&#37327;&#38169;&#35823;&#21457;&#29616;&#30340;&#34394;&#20551;&#21464;&#37327;&#65292;&#36825;&#20123;&#34394;&#20551;&#21464;&#37327;&#19982;&#30446;&#26631;&#32467;&#26524;&#39640;&#24230;&#30456;&#20851;&#65292;&#20294;&#23545;&#30446;&#26631;&#32467;&#26524;&#27809;&#26377;&#22240;&#26524;&#24433;&#21709;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#24517;&#35201;&#21644;&#20805;&#20998;&#22240;&#26524;&#22270; (NSCG) &#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#19987;&#38376;&#30001;&#19982;&#24863;&#20852;&#36259;&#32467;&#26524;&#22240;&#26524;&#30456;&#20851;&#30340;&#21464;&#37327;&#32452;&#25104;&#65292;&#25105;&#20204;&#23558;&#20854;&#31216;&#20026;&#22240;&#26524;&#29305;&#24449;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#21033;&#29992;&#22240;&#26524;&#27010;&#29575;&#31995;&#32479;&#22320;&#35780;&#20272;&#22240;&#26524;&#22270;&#20013;&#29305;&#24449;&#30340;&#37325;&#35201;&#24615;&#65292;&#20174;&#32780;&#24110;&#21161;&#25105;&#20204;&#30830;&#23450;&#19982;&#24863;&#20852;&#36259;&#30340;&#32467;&#26524;&#30456;&#20851;&#30340;&#23376;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;
The causal revolution has stimulated interest in understanding complex relationships in various fields. Most of the existing methods aim to discover causal relationships among all variables within a complex large-scale graph. However, in practice, only a small subset of variables in the graph are relevant to the outcomes of interest. Consequently, causal estimation with the full causal graph -- particularly given limited data -- could lead to numerous falsely discovered, spurious variables that exhibit high correlation with, but exert no causal impact on, the target outcome. In this paper, we propose learning a class of necessary and sufficient causal graphs (NSCG) that exclusively comprises causally relevant variables for an outcome of interest, which we term causal features. The key idea is to employ probabilities of causation to systematically evaluate the importance of features in the causal graph, allowing us to identify a subgraph relevant to the outcome of interest. To learn NSC
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24555;&#36895;&#30340;&#22810;&#36724;&#39640;&#26031;&#22270;&#24418;&#27169;&#22411;&#65292;&#29992;&#20110;&#26500;&#24314;&#31232;&#30095;&#22270;&#24418;&#34920;&#31034;&#12290;&#30456;&#27604;&#20808;&#21069;&#24037;&#20316;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#27599;&#20010;&#36724;&#19978;&#20165;&#20351;&#29992;&#19968;&#27425;&#29305;&#24449;&#20998;&#35299;&#65292;&#23454;&#29616;&#20102;&#25968;&#37327;&#32423;&#30340;&#21152;&#36895;&#12290;&#35813;&#27169;&#22411;&#21487;&#20197;&#24212;&#29992;&#20110;&#22823;&#22411;&#22810;&#27169;&#24577;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#21333;&#32454;&#32990;&#22810;&#32452;&#23398;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2211.02920</link><description>&lt;p&gt;
GmGM: &#19968;&#31181;&#24555;&#36895;&#30340;&#22810;&#36724;&#39640;&#26031;&#22270;&#24418;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
GmGM: a Fast Multi-Axis Gaussian Graphical Model. (arXiv:2211.02920v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.02920
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24555;&#36895;&#30340;&#22810;&#36724;&#39640;&#26031;&#22270;&#24418;&#27169;&#22411;&#65292;&#29992;&#20110;&#26500;&#24314;&#31232;&#30095;&#22270;&#24418;&#34920;&#31034;&#12290;&#30456;&#27604;&#20808;&#21069;&#24037;&#20316;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#27599;&#20010;&#36724;&#19978;&#20165;&#20351;&#29992;&#19968;&#27425;&#29305;&#24449;&#20998;&#35299;&#65292;&#23454;&#29616;&#20102;&#25968;&#37327;&#32423;&#30340;&#21152;&#36895;&#12290;&#35813;&#27169;&#22411;&#21487;&#20197;&#24212;&#29992;&#20110;&#22823;&#22411;&#22810;&#27169;&#24577;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#21333;&#32454;&#32990;&#22810;&#32452;&#23398;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#26031;&#22810;&#22270;&#24418;&#27169;&#22411;&#65292;&#29992;&#20110;&#26500;&#24314;&#30697;&#38453;&#21644;&#24352;&#37327;&#21464;&#37327;&#25968;&#25454;&#30340;&#31232;&#30095;&#22270;&#24418;&#34920;&#31034;&#12290;&#25105;&#20204;&#36890;&#36807;&#21516;&#26102;&#23398;&#20064;&#22810;&#20010;&#20849;&#20139;&#36724;&#30340;&#24352;&#37327;&#19978;&#30340;&#34920;&#31034;&#26469;&#25512;&#24191;&#35813;&#39046;&#22495;&#30340;&#20808;&#21069;&#24037;&#20316;&#65292;&#36825;&#23545;&#20110;&#20998;&#26512;&#22810;&#27169;&#24577;&#25968;&#25454;&#38598;&#65288;&#22914;&#22810;&#32452;&#23398;&#20013;&#36935;&#21040;&#30340;&#25968;&#25454;&#38598;&#65289;&#26159;&#24517;&#35201;&#30340;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#27599;&#20010;&#36724;&#19978;&#20165;&#20351;&#29992;&#19968;&#27425;&#29305;&#24449;&#20998;&#35299;&#65292;&#30456;&#23545;&#20110;&#38750;&#24191;&#20041;&#24773;&#20917;&#19979;&#30340;&#20808;&#21069;&#24037;&#20316;&#23454;&#29616;&#20102;&#25968;&#37327;&#32423;&#30340;&#21152;&#36895;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#21253;&#25324;&#21333;&#32454;&#32990;&#22810;&#32452;&#23398;&#25968;&#25454;&#22312;&#20869;&#30340;&#22823;&#22411;&#22810;&#27169;&#24577;&#25968;&#25454;&#38598;&#65292;&#36825;&#22312;&#20043;&#21069;&#30340;&#26041;&#27861;&#20013;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#20116;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces the Gaussian multi-Graphical Model, a model to construct sparse graph representations of matrix- and tensor-variate data. We generalize prior work in this area by simultaneously learning this representation across several tensors that share axes, which is necessary to allow the analysis of multimodal datasets such as those encountered in multi-omics. Our algorithm uses only a single eigendecomposition per axis, achieving an order of magnitude speedup over prior work in the ungeneralized case. This allows the use of our methodology on large multi-modal datasets such as single-cell multi-omics data, which was challenging with previous approaches. We validate our model on synthetic data and five real-world datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#38024;&#23545;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#26080;&#23548;&#25968;&#20132;&#26367;&#25237;&#24433;&#31639;&#27861;&#65292;&#21253;&#25324;&#20809;&#28369;&#38382;&#39064;&#30340;&#20132;&#26367;&#38543;&#26426;&#26799;&#24230;&#25237;&#24433;&#31639;&#27861;&#65288;ZO-AGP&#65289;&#65292;&#20197;&#21450;&#22359;&#29366;&#38750;&#20809;&#28369;&#38382;&#39064;&#30340;&#20998;&#22359;&#20132;&#26367;&#38543;&#26426;&#36817;&#31471;&#26799;&#24230;&#31639;&#27861;&#65288;ZO-BAPG&#65289;&#12290;&#36825;&#20123;&#31639;&#27861;&#20855;&#26377;&#36739;&#23569;&#30340;&#20989;&#25968;&#20540;&#20272;&#35745;&#21644;&#36739;&#39640;&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2108.00473</link><description>&lt;p&gt;
&#38024;&#23545;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#26080;&#23548;&#25968;&#20132;&#26367;&#25237;&#24433;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Derivative-free Alternating Projection Algorithms for General Nonconvex-Concave Minimax Problems. (arXiv:2108.00473v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.00473
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#38024;&#23545;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#26080;&#23548;&#25968;&#20132;&#26367;&#25237;&#24433;&#31639;&#27861;&#65292;&#21253;&#25324;&#20809;&#28369;&#38382;&#39064;&#30340;&#20132;&#26367;&#38543;&#26426;&#26799;&#24230;&#25237;&#24433;&#31639;&#27861;&#65288;ZO-AGP&#65289;&#65292;&#20197;&#21450;&#22359;&#29366;&#38750;&#20809;&#28369;&#38382;&#39064;&#30340;&#20998;&#22359;&#20132;&#26367;&#38543;&#26426;&#36817;&#31471;&#26799;&#24230;&#31639;&#27861;&#65288;ZO-BAPG&#65289;&#12290;&#36825;&#20123;&#31639;&#27861;&#20855;&#26377;&#36739;&#23569;&#30340;&#20989;&#25968;&#20540;&#20272;&#35745;&#21644;&#36739;&#39640;&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#38646;&#38454;&#31639;&#27861;&#65292;&#36825;&#31867;&#38382;&#39064;&#36817;&#24180;&#22312;&#26426;&#22120;&#23398;&#20064;&#12289;&#20449;&#21495;&#22788;&#29702;&#31561;&#39046;&#22495;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#38454;&#20132;&#26367;&#38543;&#26426;&#26799;&#24230;&#25237;&#24433;&#65288;ZO-AGP&#65289;&#31639;&#27861;&#26469;&#35299;&#20915;&#20809;&#28369;&#30340;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#20854;&#36845;&#20195;&#22797;&#26434;&#24230;&#20026; $\mathcal{O}(\varepsilon^{-4})$&#65292;&#27599;&#27425;&#36845;&#20195;&#30340;&#20989;&#25968;&#20540;&#20272;&#35745;&#27425;&#25968;&#20026; $\mathcal{O}(d_{x}+d_{y})$&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#38454;&#20998;&#22359;&#20132;&#26367;&#38543;&#26426;&#36817;&#31471;&#26799;&#24230;&#31639;&#27861;&#65288;ZO-BAPG&#65289;&#26469;&#35299;&#20915;&#22359;&#29366;&#38750;&#20809;&#28369;&#30340;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#36845;&#20195;&#22797;&#26434;&#24230;&#20026; $\mathcal{O}(\varepsilon^{-4})$&#65292;&#27599;&#27425;&#36845;&#20195;&#30340;&#20989;&#25968;&#20540;&#20272;&#35745;&#27425;&#25968;&#20026; $\mathcal{O}(K d_{x}+d_{y})$&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#39318;&#27425;&#25552;&#20986;&#36825;&#20123;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study zeroth-order algorithms for nonconvex-concave minimax problems, which have attracted widely attention in machine learning, signal processing and many other fields in recent years. We propose a zeroth-order alternating randomized gradient projection (ZO-AGP) algorithm for smooth nonconvex-concave minimax problems, and its iteration complexity to obtain an $\varepsilon$-stationary point is bounded by $\mathcal{O}(\varepsilon^{-4})$, and the number of function value estimation is bounded by $\mathcal{O}(d_{x}+d_{y})$ per iteration. Moreover, we propose a zeroth-order block alternating randomized proximal gradient algorithm (ZO-BAPG) for solving block-wise nonsmooth nonconvex-concave minimax optimization problems, and the iteration complexity to obtain an $\varepsilon$-stationary point is bounded by $\mathcal{O}(\varepsilon^{-4})$ and the number of function value estimation per iteration is bounded by $\mathcal{O}(K d_{x}+d_{y})$. To the best of our knowledge, this 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#26080;&#20284;&#28982;&#20551;&#35774;&#19979;&#30340;&#39057;&#29575;&#23398;&#27966;&#25512;&#26029;&#65288;LF2I&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#32463;&#20856;&#32479;&#35745;&#21644;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#65292;&#23454;&#29616;&#20102;&#26500;&#24314;&#20855;&#26377;&#27491;&#30830;&#26465;&#20214;&#35206;&#30422;&#30340;&#32622;&#20449;&#21306;&#38388;&#30340;&#23454;&#29992;&#31243;&#24207;&#21644;&#35786;&#26029;&#26041;&#27861;&#65292;&#22312;&#21253;&#25324;&#23431;&#23449;&#23398;&#21442;&#25968;&#25512;&#26029;&#22312;&#20869;&#30340;&#22810;&#20010;&#20363;&#23376;&#20013;&#37117;&#23454;&#29616;&#20102;&#35206;&#30422;&#24615;&#36136;&#24471;&#21040;&#22823;&#24133;&#25913;&#21892;&#12290;</title><link>http://arxiv.org/abs/2107.03920</link><description>&lt;p&gt;
&#26080;&#20284;&#28982;&#20551;&#35774;&#19979;&#22522;&#20110;&#39057;&#29575;&#23398;&#27966;&#25512;&#26029;&#65306;&#20855;&#26377;&#27491;&#30830;&#26465;&#20214;&#35206;&#30422;&#30340;&#32622;&#20449;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;
Likelihood-Free Frequentist Inference: Confidence Sets with Correct Conditional Coverage. (arXiv:2107.03920v6 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.03920
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#26080;&#20284;&#28982;&#20551;&#35774;&#19979;&#30340;&#39057;&#29575;&#23398;&#27966;&#25512;&#26029;&#65288;LF2I&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#32463;&#20856;&#32479;&#35745;&#21644;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#65292;&#23454;&#29616;&#20102;&#26500;&#24314;&#20855;&#26377;&#27491;&#30830;&#26465;&#20214;&#35206;&#30422;&#30340;&#32622;&#20449;&#21306;&#38388;&#30340;&#23454;&#29992;&#31243;&#24207;&#21644;&#35786;&#26029;&#26041;&#27861;&#65292;&#22312;&#21253;&#25324;&#23431;&#23449;&#23398;&#21442;&#25968;&#25512;&#26029;&#22312;&#20869;&#30340;&#22810;&#20010;&#20363;&#23376;&#20013;&#37117;&#23454;&#29616;&#20102;&#35206;&#30422;&#24615;&#36136;&#24471;&#21040;&#22823;&#24133;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#31185;&#23398;&#39046;&#22495;&#37117;&#24191;&#27867;&#20351;&#29992;&#35745;&#31639;&#26426;&#27169;&#25311;&#22120;&#20197;&#38544;&#21547;&#22797;&#26434;&#31995;&#32479;&#30340;&#20284;&#28982;&#20989;&#25968;&#12290;&#20256;&#32479;&#30340;&#32479;&#35745;&#26041;&#27861;&#24182;&#19981;&#36866;&#29992;&#20110;&#36825;&#20123;&#31216;&#20026;&#26080;&#20284;&#28982;&#20551;&#35774;&#19979;&#25512;&#26029;&#65288;LFI&#65289;&#30340;&#24773;&#20917;&#65292;&#23588;&#20854;&#26159;&#22312;&#28176;&#36817;&#21644;&#20302;&#32500;&#30340;&#26465;&#20214;&#19979;&#12290;&#34429;&#28982;&#26032;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#22914;&#24402;&#19968;&#21270;&#27969;&#65292;&#24050;&#32463;&#38761;&#26032;&#20102;LFI&#26041;&#27861;&#30340;&#26679;&#26412;&#25928;&#29575;&#21644;&#23481;&#37327;&#65292;&#20294;&#23427;&#20204;&#26159;&#21542;&#33021;&#20026;&#23567;&#26679;&#26412;&#22823;&#23567;&#20135;&#29983;&#20855;&#26377;&#27491;&#30830;&#26465;&#20214;&#35206;&#30422;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#12290;&#26412;&#25991;&#23558;&#32463;&#20856;&#32479;&#35745;&#21644;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#65288;i&#65289;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#21517;&#20041;&#35206;&#30422;&#30340;&#20869;&#26364;&#21306;&#38388;&#24314;&#35774;&#30340;&#23454;&#29992;&#31243;&#24207;&#65292;&#20197;&#21450;&#65288;ii&#65289;&#20272;&#35745;&#25972;&#20010;&#21442;&#25968;&#31354;&#38388;&#30340;&#26465;&#20214;&#35206;&#30422;&#30340;&#35786;&#26029;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26694;&#26550;&#31216;&#20026;&#26080;&#20284;&#28982;&#20551;&#35774;&#19979;&#30340;&#39057;&#29575;&#23398;&#27966;&#25512;&#26029;&#65288;LF2I&#65289;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#20351;&#29992;&#23450;&#20041;&#27979;&#35797;&#32479;&#35745;&#37327;&#30340;&#20219;&#20309;&#26041;&#27861;&#65292;&#22914;&#20284;&#28982;&#27604;&#65292;&#22240;&#27492;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#20960;&#20010;&#21512;&#25104;&#21644;&#23454;&#38469;&#30340;&#20363;&#23376;&#65292;&#21253;&#25324;&#23431;&#23449;&#23398;&#21442;&#25968;&#25512;&#26029;&#65292;&#24182;&#35777;&#26126;&#19982;&#29616;&#26377;&#30340;LFI&#26041;&#27861;&#30456;&#27604;&#65292;&#35206;&#30422;&#24615;&#36136;&#24471;&#21040;&#20102;&#22823;&#24133;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many areas of science make extensive use of computer simulators that implicitly encode likelihood functions of complex systems. Classical statistical methods are poorly suited for these so-called likelihood-free inference (LFI) settings, particularly outside asymptotic and low-dimensional regimes. Although new machine learning methods, such as normalizing flows, have revolutionized the sample efficiency and capacity of LFI methods, it remains an open question whether they produce confidence sets with correct conditional coverage for small sample sizes. This paper unifies classical statistics with modern machine learning to present (i) a practical procedure for the Neyman construction of confidence sets with finite-sample guarantees of nominal coverage, and (ii) diagnostics that estimate conditional coverage over the entire parameter space. We refer to our framework as likelihood-free frequentist inference (LF2I). Any method that defines a test statistic, like the likelihood ratio, can 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#22312;&#22870;&#21169;&#21644;&#36716;&#31227;&#27010;&#29575;&#20004;&#26041;&#38754;&#23384;&#22312;&#30340;&#23545;&#25239;&#24615;&#33104;&#36133;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#35299;&#20915;&#33104;&#36133;&#38382;&#39064;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27809;&#26377;&#33104;&#36133;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#25509;&#36817;&#26368;&#20248;&#30340;&#21518;&#24724;&#65292;&#24182;&#19988;&#33021;&#22815;&#36866;&#24212;&#26410;&#30693;&#27700;&#24179;&#30340;&#33104;&#36133;&#12290;</title><link>http://arxiv.org/abs/1911.08689</link><description>&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20013;&#23545;&#25239;&#24615;&#33104;&#36133;&#30340;&#40065;&#26834;&#25506;&#32034;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Corruption-robust exploration in episodic reinforcement learning. (arXiv:1911.08689v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1911.08689
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#22312;&#22870;&#21169;&#21644;&#36716;&#31227;&#27010;&#29575;&#20004;&#26041;&#38754;&#23384;&#22312;&#30340;&#23545;&#25239;&#24615;&#33104;&#36133;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#35299;&#20915;&#33104;&#36133;&#38382;&#39064;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27809;&#26377;&#33104;&#36133;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#25509;&#36817;&#26368;&#20248;&#30340;&#21518;&#24724;&#65292;&#24182;&#19988;&#33021;&#22815;&#36866;&#24212;&#26410;&#30693;&#27700;&#24179;&#30340;&#33104;&#36133;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#22810;&#38454;&#27573;&#24378;&#21270;&#23398;&#20064;&#22312;&#22870;&#21169;&#21644;&#36716;&#31227;&#27010;&#29575;&#20004;&#26041;&#38754;&#30340;&#23545;&#25239;&#24615;&#33104;&#36133;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#25193;&#23637;&#20102;&#26368;&#36817;&#23545;&#38543;&#26426;&#36172;&#21338;&#26426;&#29305;&#20363;&#30340;&#30740;&#31350;&#32467;&#26524;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#8220;&#20048;&#35266;&#38754;&#23545;&#19981;&#30830;&#23450;&#24615;&#8221;&#30340;&#29616;&#26377;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#25506;&#32034;&#24615;&#25913;&#36827;&#65292;&#24182;&#32467;&#21512;&#8220;&#21160;&#20316;&#28120;&#27760;&#8221;&#21407;&#21017;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#22312;&#24378;&#21270;&#23398;&#20064;&#29615;&#22659;&#20013;&#26420;&#32032;&#24212;&#29992;&#21160;&#20316;&#28120;&#27760;&#25152;&#38754;&#20020;&#30340;&#20027;&#35201;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#25552;&#20379;&#20102;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;(a)&#22312;&#27809;&#26377;&#33104;&#36133;&#26102;&#23454;&#29616;&#25509;&#36817;&#26368;&#20248;&#30340;&#21518;&#24724;&#65292;&#24182;&#19988;(b)&#33021;&#22815;&#36866;&#24212;&#26410;&#30693;&#27700;&#24179;&#30340;&#33104;&#36133;&#65292;&#22312;&#24635;&#33104;&#36133;&#24773;&#20917;&#19979;&#21518;&#24724;&#31243;&#24230;&#36880;&#28176;&#38477;&#20302;&#12290;&#20026;&#20102;&#23637;&#31034;&#25105;&#20204;&#26041;&#27861;&#30340;&#24191;&#27867;&#36866;&#29992;&#24615;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#34920;&#26684;&#35774;&#32622;&#19979;&#30340;&#32467;&#26524;&#65288;&#20854;&#20013;&#28041;&#21450;&#29366;&#24577;&#21644;&#34892;&#20026;&#65289;&#20197;&#21450;&#36890;&#29992;&#20989;&#25968;&#36924;&#36817;&#35774;&#32622;&#19979;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We initiate the study of multi-stage episodic reinforcement learning under adversarial corruptions in both the rewards and the transition probabilities of the underlying system extending recent results for the special case of stochastic bandits. We provide a framework which modifies the aggressive exploration enjoyed by existing reinforcement learning approaches based on "optimism in the face of uncertainty", by complementing them with principles from "action elimination". Importantly, our framework circumvents the major challenges posed by naively applying action elimination in the RL setting, as formalized by a lower bound we demonstrate. Our framework yields efficient algorithms which (a) attain near-optimal regret in the absence of corruptions and (b) adapt to unknown levels corruption, enjoying regret guarantees which degrade gracefully in the total corruption encountered. To showcase the generality of our approach, we derive results for both tabular settings (where states and act
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#23545;&#30495;&#23454;&#27169;&#22411;&#21442;&#25968;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#19968;&#33268;&#20272;&#35745;&#22120;&#26469;&#33719;&#24471;SGD&#30340;&#24179;&#22343;&#36845;&#20195;&#30340;&#28176;&#36817;&#21327;&#26041;&#24046;&#65292;&#21516;&#26102;&#20063;&#26500;&#24314;&#20102;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#30340;&#21435;&#20559;&#32622;&#20272;&#35745;&#22120;&#12290;</title><link>http://arxiv.org/abs/1610.08637</link><description>&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#27169;&#22411;&#21442;&#25968;&#30340;&#32479;&#35745;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Statistical Inference for Model Parameters in Stochastic Gradient Descent. (arXiv:1610.08637v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1610.08637
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#23545;&#30495;&#23454;&#27169;&#22411;&#21442;&#25968;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#19968;&#33268;&#20272;&#35745;&#22120;&#26469;&#33719;&#24471;SGD&#30340;&#24179;&#22343;&#36845;&#20195;&#30340;&#28176;&#36817;&#21327;&#26041;&#24046;&#65292;&#21516;&#26102;&#20063;&#26500;&#24314;&#20102;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#30340;&#21435;&#20559;&#32622;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#31639;&#27861;&#30001;&#20110;&#20854;&#35745;&#31639;&#21644;&#20869;&#23384;&#25928;&#29575;&#32780;&#24191;&#27867;&#24212;&#29992;&#20110;&#22823;&#35268;&#27169;&#25968;&#25454;&#30340;&#32479;&#35745;&#20272;&#35745;&#20013;&#12290;&#23613;&#31649;&#22823;&#22810;&#25968;&#29616;&#26377;&#24037;&#20316;&#27880;&#37325;&#30446;&#26631;&#20989;&#25968;&#30340;&#25910;&#25947;&#24615;&#25110;&#25152;&#24471;&#35299;&#30340;&#35823;&#24046;&#65292;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#20154;&#21475;&#25439;&#22833;&#20989;&#25968;&#24378;&#20984;&#19988;&#28385;&#36275;&#19968;&#23450;&#20809;&#28369;&#24615;&#26465;&#20214;&#26102;&#65292;&#22522;&#20110;SGD&#36827;&#34892;&#30495;&#23454;&#27169;&#22411;&#21442;&#25968;&#30340;&#32479;&#35745;&#25512;&#26029;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26377;&#20004;&#20010;&#26041;&#38754;&#12290;&#39318;&#20808;&#65292;&#22312;&#22266;&#23450;&#32500;&#25968;&#35774;&#32622;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#19968;&#33268;&#20272;&#35745;&#22120;&#20197;&#33719;&#24471;SGD&#30340;&#24179;&#22343;&#36845;&#20195;&#30340;&#28176;&#36817;&#21327;&#26041;&#24046;&#65306;&#65288;1&#65289;&#25554;&#20540;&#20272;&#35745;&#22120;&#21644;&#65288;2&#65289;&#25209;&#22343;&#20540;&#20272;&#35745;&#22120;&#65292;&#21518;&#32773;&#22312;&#35745;&#31639;&#19978;&#26356;&#39640;&#25928;&#65292;&#21482;&#20351;&#29992;SGD&#30340;&#36845;&#20195;&#32467;&#26524;&#12290;&#36825;&#20004;&#20010;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#37117;&#20801;&#35768;&#25105;&#20204;&#26500;&#24314;&#28176;&#36817;&#31934;&#30830;&#30340;&#32622;&#20449;&#21306;&#38388;&#21644;&#20551;&#35774;&#26816;&#39564;&#12290;&#20854;&#27425;&#65292;&#22312;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;SGD&#31639;&#27861;&#30340;&#21464;&#31181;&#26500;&#24314;&#20102;&#19968;&#20010;&#21435;&#20559;&#32622;&#30340;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
The stochastic gradient descent (SGD) algorithm has been widely used in statistical estimation for large-scale data due to its computational and memory efficiency. While most existing works focus on the convergence of the objective function or the error of the obtained solution, we investigate the problem of statistical inference of true model parameters based on SGD when the population loss function is strongly convex and satisfies certain smoothness conditions. Our main contributions are two-fold. First, in the fixed dimension setup, we propose two consistent estimators of the asymptotic covariance of the average iterate from SGD: (1) a plug-in estimator, and (2) a batch-means estimator, which is computationally more efficient and only uses the iterates from SGD. Both proposed estimators allow us to construct asymptotically exact confidence intervals and hypothesis tests. Second, for high-dimensional linear regression, using a variant of the SGD algorithm, we construct a debiased est
&lt;/p&gt;</description></item></channel></rss>