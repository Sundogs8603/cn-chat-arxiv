<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#39033;&#30740;&#31350;&#20351;&#29992;&#23646;&#24615;&#24341;&#23548;&#26041;&#27861;&#26469;&#25506;&#32034;&#25439;&#22833;&#20989;&#25968;&#21644;&#27491;&#21017;&#21270;&#20989;&#25968;&#19982;&#26368;&#20248;&#20915;&#31574;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#29305;&#21035;&#26159;&#22312;&#20844;&#24179;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#23427;&#25552;&#20379;&#20102;&#25439;&#22833;&#20989;&#25968;&#21644;&#27491;&#21017;&#21270;&#20989;&#25968;&#25104;&#23545;&#26102;&#23646;&#24615;&#25913;&#21464;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#20915;&#31574;&#19982;&#25968;&#25454;&#20998;&#24067;&#21464;&#21270;&#21644;&#32422;&#26463;&#38590;&#24230;&#30340;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.11343</link><description>&lt;p&gt;
&#20351;&#29992;&#23646;&#24615;&#24341;&#23548;&#26041;&#27861;&#26469;&#29702;&#35299;&#20844;&#24179;&#24615;&#32422;&#26463;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Using Property Elicitation to Understand the Impacts of Fairness Constraints. (arXiv:2309.11343v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11343
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20351;&#29992;&#23646;&#24615;&#24341;&#23548;&#26041;&#27861;&#26469;&#25506;&#32034;&#25439;&#22833;&#20989;&#25968;&#21644;&#27491;&#21017;&#21270;&#20989;&#25968;&#19982;&#26368;&#20248;&#20915;&#31574;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#29305;&#21035;&#26159;&#22312;&#20844;&#24179;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#23427;&#25552;&#20379;&#20102;&#25439;&#22833;&#20989;&#25968;&#21644;&#27491;&#21017;&#21270;&#20989;&#25968;&#25104;&#23545;&#26102;&#23646;&#24615;&#25913;&#21464;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#20915;&#31574;&#19982;&#25968;&#25454;&#20998;&#24067;&#21464;&#21270;&#21644;&#32422;&#26463;&#38590;&#24230;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#31639;&#27861;&#36890;&#24120;&#36890;&#36807;&#20248;&#21270;&#26576;&#20010;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#35757;&#32451;&#65292;&#24182;&#28155;&#21152;&#27491;&#21017;&#21270;&#20989;&#25968;&#26469;&#26045;&#21152;&#36829;&#21453;&#32422;&#26463;&#30340;&#24809;&#32602;&#12290;&#39044;&#26399;&#22320;&#65292;&#28155;&#21152;&#36825;&#26679;&#30340;&#27491;&#21017;&#21270;&#20989;&#25968;&#21487;&#20197;&#25913;&#21464;&#30446;&#26631;&#20989;&#25968;&#30340;&#26368;&#23567;&#21270;&#20540;&#12290;&#30446;&#21069;&#36824;&#19981;&#28165;&#26970;&#21738;&#20123;&#27491;&#21017;&#21270;&#20989;&#25968;&#20250;&#25913;&#21464;&#25439;&#22833;&#20989;&#25968;&#30340;&#26368;&#23567;&#21270;&#20540;&#65292;&#20197;&#21450;&#24403;&#26368;&#23567;&#21270;&#20540;&#21457;&#29983;&#21464;&#21270;&#26102;&#65292;&#23427;&#20250;&#22914;&#20309;&#21464;&#21270;&#12290;&#25105;&#20204;&#20351;&#29992;&#23646;&#24615;&#24341;&#23548;&#26041;&#27861;&#26469;&#21021;&#27493;&#20102;&#35299;&#25439;&#22833;&#20989;&#25968;&#21644;&#27491;&#21017;&#21270;&#20989;&#25968;&#19982;&#32473;&#23450;&#38382;&#39064;&#23454;&#20363;&#30340;&#26368;&#20248;&#20915;&#31574;&#20043;&#38388;&#30340;&#32852;&#21512;&#20851;&#31995;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#25439;&#22833;&#20989;&#25968;&#21644;&#27491;&#21017;&#21270;&#20989;&#25968;&#25104;&#23545;&#26102;&#65292;&#23646;&#24615;&#25913;&#21464;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#30740;&#31350;&#20102;&#19968;&#20123;&#28385;&#36275;&#36825;&#20010;&#26465;&#20214;&#30340;&#27491;&#21017;&#21270;&#20989;&#25968;&#22312;&#20844;&#24179;&#26426;&#22120;&#23398;&#20064;&#25991;&#29486;&#20013;&#30340;&#26631;&#20934;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#20915;&#31574;&#22914;&#20309;&#38543;&#30528;&#25968;&#25454;&#20998;&#24067;&#30340;&#21464;&#21270;&#21644;&#32422;&#26463;&#30340;&#38590;&#24230;&#32780;&#25913;&#21464;&#12290;
&lt;/p&gt;
&lt;p&gt;
Predictive algorithms are often trained by optimizing some loss function, to which regularization functions are added to impose a penalty for violating constraints. As expected, the addition of such regularization functions can change the minimizer of the objective. It is not well-understood which regularizers change the minimizer of the loss, and, when the minimizer does change, how it changes. We use property elicitation to take first steps towards understanding the joint relationship between the loss and regularization functions and the optimal decision for a given problem instance. In particular, we give a necessary and sufficient condition on loss and regularizer pairs for when a property changes with the addition of the regularizer, and examine some regularizers satisfying this condition standard in the fair machine learning literature. We empirically demonstrate how algorithmic decision-making changes as a function of both data distribution changes and hardness of the constraint
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#28145;&#24230;&#23398;&#20064;&#32593;&#32476;&#32467;&#26500;&#30340;&#20960;&#20309;&#35299;&#37322;&#65292;&#24182;&#19988;&#26500;&#24314;&#20102;&#20840;&#23616;&#26368;&#23567;&#21270;&#22120;&#26063;&#65292;&#35813;&#26063;&#33021;&#22815;&#20840;&#23616;&#26368;&#23567;&#21270;&#25104;&#26412;&#20989;&#25968;&#12290;&#27492;&#22806;&#65292;&#36824;&#30830;&#23450;&#20102;&#21508;&#31181;&#36864;&#21270;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;</title><link>http://arxiv.org/abs/2309.10639</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#32593;&#32476;&#30340;&#20960;&#20309;&#32467;&#26500;&#21644;&#20840;&#23616;${\mathcal L}^2$&#26368;&#23567;&#21270;&#22120;&#30340;&#26500;&#24314;
&lt;/p&gt;
&lt;p&gt;
Geometric structure of Deep Learning networks and construction of global ${\mathcal L}^2$ minimizers. (arXiv:2309.10639v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10639
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#28145;&#24230;&#23398;&#20064;&#32593;&#32476;&#32467;&#26500;&#30340;&#20960;&#20309;&#35299;&#37322;&#65292;&#24182;&#19988;&#26500;&#24314;&#20102;&#20840;&#23616;&#26368;&#23567;&#21270;&#22120;&#26063;&#65292;&#35813;&#26063;&#33021;&#22815;&#20840;&#23616;&#26368;&#23567;&#21270;&#25104;&#26412;&#20989;&#25968;&#12290;&#27492;&#22806;&#65292;&#36824;&#30830;&#23450;&#20102;&#21508;&#31181;&#36864;&#21270;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#32593;&#32476;&#32467;&#26500;&#30340;&#20960;&#20309;&#35299;&#37322;&#65292;&#35813;&#32593;&#32476;&#20855;&#26377;$L$&#20010;&#38544;&#34255;&#23618;&#65292;&#26012;&#22369;&#28608;&#27963;&#20989;&#25968;&#65292;${\mathcal L}^2$ Schatten&#31867;&#65288;&#25110;Hilbert-Schmidt&#65289;&#25104;&#26412;&#20989;&#25968;&#65292;&#20197;&#21450;&#30456;&#31561;&#32500;&#24230;$Q\geq1$&#30340;&#36755;&#20837;&#21644;&#36755;&#20986;&#31354;&#38388;${\mathbb R}^Q$&#12290;&#38544;&#34255;&#23618;&#20063;&#23450;&#20041;&#22312;${\mathbb R}^{Q}$&#30340;&#31354;&#38388;&#19978;&#12290;&#25105;&#20204;&#21033;&#29992;&#25105;&#20204;&#26368;&#26032;&#30340;&#20851;&#20110;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#32467;&#26524;&#65292;&#22312;$L\geq Q$&#30340;&#24773;&#20917;&#19979;&#26500;&#36896;&#20102;&#19968;&#20010;&#26126;&#30830;&#30340;&#26368;&#23567;&#21270;&#22120;&#26063;&#65292;&#35813;&#26063;&#33021;&#22815;&#20840;&#23616;&#26368;&#23567;&#21270;&#25104;&#26412;&#20989;&#25968;&#65292;&#24182;&#19988;&#25105;&#20204;&#35777;&#26126;&#36825;&#20010;&#26063;&#26159;&#36864;&#21270;&#30340;&#12290;&#22312;&#36825;&#37324;&#25552;&#21040;&#30340;&#19978;&#19979;&#25991;&#20013;&#65292;DL&#32593;&#32476;&#30340;&#38544;&#34255;&#23618;&#36890;&#36807;&#23545;&#35757;&#32451;&#36755;&#20837;&#30340;&#36882;&#24402;&#25130;&#26029;&#26144;&#23556;&#30340;&#24212;&#29992;&#26469;&#8220;&#25972;&#29702;&#8221;&#35757;&#32451;&#36755;&#20837;&#65292;&#20197;&#26368;&#23567;&#21270;&#22122;&#22768;&#19982;&#20449;&#21495;&#30340;&#27604;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;$2^Q-1$&#20010;&#19981;&#21516;&#30340;&#36864;&#21270;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we provide a geometric interpretation of the structure of Deep Learning (DL) networks, characterized by $L$ hidden layers, a ramp activation function, an ${\mathcal L}^2$ Schatten class (or Hilbert-Schmidt) cost function, and input and output spaces ${\mathbb R}^Q$ with equal dimension $Q\geq1$. The hidden layers are defined on spaces ${\mathbb R}^{Q}$, as well. We apply our recent results on shallow neural networks to construct an explicit family of minimizers for the global minimum of the cost function in the case $L\geq Q$, which we show to be degenerate. In the context presented here, the hidden layers of the DL network "curate" the training inputs by recursive application of a truncation map that minimizes the noise to signal ratio of the training inputs. Moreover, we determine a set of $2^Q-1$ distinct degenerate local minima of the cost function.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35843;&#26597;&#20102;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#20998;&#23376;&#22270;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#26367;&#25442;&#22270;&#29983;&#25104;&#27169;&#22411;&#30340;&#22522;&#30784;GNN&#26469;&#36827;&#34892;&#23454;&#39564;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#20351;&#29992;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;GNN&#21487;&#20197;&#25913;&#21892;&#29983;&#25104;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.11978</link><description>&lt;p&gt;
&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#29983;&#25104;&#20219;&#21153;&#20013;&#26159;&#21542;&#26356;&#22909;&#65311;
&lt;/p&gt;
&lt;p&gt;
Will More Expressive Graph Neural Networks do Better on Generative Tasks?. (arXiv:2308.11978v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11978
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35843;&#26597;&#20102;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#20998;&#23376;&#22270;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#26367;&#25442;&#22270;&#29983;&#25104;&#27169;&#22411;&#30340;&#22522;&#30784;GNN&#26469;&#36827;&#34892;&#23454;&#39564;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#20351;&#29992;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;GNN&#21487;&#20197;&#25913;&#21892;&#29983;&#25104;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#29983;&#25104;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#25361;&#25112;&#65292;&#23427;&#28041;&#21450;&#26681;&#25454;&#32473;&#23450;&#30340;&#26631;&#31614;&#39044;&#27979;&#19968;&#20010;&#23436;&#25972;&#30340;&#20855;&#26377;&#22810;&#20010;&#33410;&#28857;&#21644;&#36793;&#30340;&#22270;&#12290;&#36825;&#20010;&#20219;&#21153;&#23545;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#38750;&#24120;&#37325;&#35201;&#65292;&#21253;&#25324;&#33647;&#29289;&#21644;&#20998;&#23376;&#35774;&#35745;&#12290;&#36817;&#24180;&#26469;&#65292;&#22312;&#22270;&#29983;&#25104;&#39046;&#22495;&#20986;&#29616;&#20102;&#20960;&#31181;&#25104;&#21151;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#23384;&#22312;&#20004;&#20010;&#37325;&#22823;&#38382;&#39064;&#65306;(1) &#36825;&#20123;&#26041;&#27861;&#20013;&#20351;&#29992;&#30340;&#22522;&#30784;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26550;&#26500;&#24448;&#24448;&#26410;&#32463;&#28145;&#20837;&#25506;&#32034;&#65307;(2) &#36825;&#20123;&#26041;&#27861;&#24448;&#24448;&#21482;&#22312;&#26377;&#38480;&#30340;&#25351;&#26631;&#19978;&#36827;&#34892;&#35780;&#20272;&#12290;&#20026;&#22635;&#34917;&#36825;&#20010;&#31354;&#30333;&#65292;&#25105;&#20204;&#36890;&#36807;&#23558;&#22270;&#29983;&#25104;&#27169;&#22411;&#30340;&#22522;&#30784;GNN&#26367;&#25442;&#20026;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;GNN&#65292;&#30740;&#31350;&#20102;GNN&#22312;&#20998;&#23376;&#22270;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#33021;&#21147;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#20004;&#31181;&#19981;&#21516;&#29983;&#25104;&#26694;&#26550;&#65288;GCPN&#21644;GraphAF&#65289;&#20013;&#20845;&#31181;GNN&#22312;&#20845;&#20010;&#19981;&#21516;&#30340;&#20998;&#23376;&#29983;&#25104;&#30446;&#26631;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph generation poses a significant challenge as it involves predicting a complete graph with multiple nodes and edges based on simply a given label. This task also carries fundamental importance to numerous real-world applications, including de-novo drug and molecular design. In recent years, several successful methods have emerged in the field of graph generation. However, these approaches suffer from two significant shortcomings: (1) the underlying Graph Neural Network (GNN) architectures used in these methods are often underexplored; and (2) these methods are often evaluated on only a limited number of metrics. To fill this gap, we investigate the expressiveness of GNNs under the context of the molecular graph generation task, by replacing the underlying GNNs of graph generative models with more expressive GNNs. Specifically, we analyse the performance of six GNNs in two different generative frameworks (GCPN and GraphAF), on six different molecular generative objectives on the ZIN
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#36866;&#24212;&#24615;&#39044;&#27979;&#38598;&#30340;&#26399;&#26395;&#22823;&#23567;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#37327;&#21270;&#26041;&#27861;&#20197;&#21450;&#28857;&#20272;&#35745;&#21644;&#39640;&#27010;&#29575;&#21306;&#38388;&#65292;&#24182;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;&#20854;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.07254</link><description>&lt;p&gt;
&#20851;&#20110;&#36866;&#24212;&#24615;&#39044;&#27979;&#38598;&#26399;&#26395;&#22823;&#23567;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Expected Size of Conformal Prediction Sets. (arXiv:2306.07254v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07254
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#36866;&#24212;&#24615;&#39044;&#27979;&#38598;&#30340;&#26399;&#26395;&#22823;&#23567;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#37327;&#21270;&#26041;&#27861;&#20197;&#21450;&#28857;&#20272;&#35745;&#21644;&#39640;&#27010;&#29575;&#21306;&#38388;&#65292;&#24182;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;&#20854;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#36866;&#24212;&#24615;&#39044;&#27979;&#22120;&#22312;&#35823;&#24046;&#39057;&#29575;&#26041;&#38754;&#20855;&#26377;&#20005;&#26684;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#20294;&#20854;&#39044;&#27979;&#38598;&#22823;&#23567;&#23545;&#20854;&#23454;&#38469;&#25928;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#30446;&#21069;&#32570;&#20047;&#26377;&#38480;&#26679;&#26412;&#20998;&#26512;&#21644;&#39044;&#27979;&#38598;&#22823;&#23567;&#30340;&#20445;&#35777;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#22312;&#20998;&#35010;&#36866;&#24212;&#24615;&#39044;&#27979;&#26694;&#26550;&#19979;&#29702;&#35770;&#37327;&#21270;&#39044;&#27979;&#38598;&#30340;&#26399;&#26395;&#22823;&#23567;&#12290;&#22240;&#20026;&#36825;&#31181;&#31934;&#30830;&#30340;&#35745;&#31639;&#36890;&#24120;&#26080;&#27861;&#30452;&#25509;&#35745;&#31639;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25512;&#23548;&#20986;&#21487;&#36731;&#26494;&#35745;&#31639;&#30340;&#28857;&#20272;&#35745;&#21644;&#39640;&#27010;&#29575;&#21306;&#38388;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#25551;&#36848;&#27979;&#35797;&#21644;&#26657;&#20934;&#25968;&#25454;&#19981;&#21516;&#21487;&#33021;&#23454;&#29616;&#30340;&#26399;&#26395;&#39044;&#27979;&#38598;&#22823;&#23567;&#30340;&#23454;&#29992;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#23545;&#22238;&#24402;&#21644;&#20998;&#31867;&#38382;&#39064;&#30340;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#39564;&#35777;&#23454;&#20102;&#25105;&#20204;&#32467;&#26524;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
While conformal predictors reap the benefits of rigorous statistical guarantees for their error frequency, the size of their corresponding prediction sets is critical to their practical utility. Unfortunately, there is currently a lack of finite-sample analysis and guarantees for their prediction set sizes. To address this shortfall, we theoretically quantify the expected size of the prediction set under the split conformal prediction framework. As this precise formulation cannot usually be calculated directly, we further derive point estimates and high probability intervals that can be easily computed, providing a practical method for characterizing the expected prediction set size across different possible realizations of the test and calibration data. Additionally, we corroborate the efficacy of our results with experiments on real-world datasets, for both regression and classification problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#20808;&#21069;&#24037;&#20316;&#24369;&#19968;&#31867;&#38382;&#39064;&#36827;&#34892;&#25512;&#24191;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#38750;&#32447;&#24615;&#28151;&#21512;&#19979;&#30340;&#24178;&#39044;&#20013;&#23398;&#20064;&#32447;&#24615;&#22240;&#26524;&#34920;&#31034;&#30340;&#24378;&#21487;&#35782;&#21035;&#24615;&#31639;&#27861;&#65292;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#22312;&#23454;&#36341;&#20013;&#35782;&#21035;&#28508;&#22312;&#21464;&#37327;&#30340;&#23545;&#27604;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.02235</link><description>&lt;p&gt;
&#20174;&#38750;&#32447;&#24615;&#28151;&#21512;&#19979;&#30340;&#24178;&#39044;&#20013;&#23398;&#20064;&#32447;&#24615;&#22240;&#26524;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Learning Linear Causal Representations from Interventions under General Nonlinear Mixing. (arXiv:2306.02235v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02235
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#20808;&#21069;&#24037;&#20316;&#24369;&#19968;&#31867;&#38382;&#39064;&#36827;&#34892;&#25512;&#24191;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#38750;&#32447;&#24615;&#28151;&#21512;&#19979;&#30340;&#24178;&#39044;&#20013;&#23398;&#20064;&#32447;&#24615;&#22240;&#26524;&#34920;&#31034;&#30340;&#24378;&#21487;&#35782;&#21035;&#24615;&#31639;&#27861;&#65292;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#22312;&#23454;&#36341;&#20013;&#35782;&#21035;&#28508;&#22312;&#21464;&#37327;&#30340;&#23545;&#27604;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#28151;&#21512;&#20989;&#25968;&#23436;&#20840;&#36890;&#29992;&#30340;&#19968;&#33324;&#35774;&#32622;&#19979;&#65292;&#20174;&#26410;&#30693;&#30340;&#28508;&#22312;&#24178;&#39044;&#20013;&#23398;&#20064;&#22240;&#26524;&#34920;&#31034;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#28508;&#22312;&#20998;&#24067;&#26159;&#39640;&#26031;&#20998;&#24067;&#12290; &#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#21333;&#33410;&#28857;&#26410;&#30693;&#24178;&#39044;&#65288;&#21363;&#27809;&#26377;&#24178;&#39044;&#30446;&#26631;&#30340;&#24773;&#20917;&#19979;&#65289;&#32473;&#20986;&#24378;&#21487;&#35782;&#21035;&#24615;&#32467;&#26524;&#12290;&#36825;&#25512;&#24191;&#20102;&#20808;&#21069;&#30340;&#24037;&#20316;&#65292;&#20808;&#21069;&#30340;&#24037;&#20316;&#30528;&#37325;&#20110;&#26356;&#24369;&#30340;&#31867;&#21035;&#65292;&#20363;&#22914;&#32447;&#24615;&#26144;&#23556;&#25110;&#25104;&#23545;&#30340;&#21453;&#20107;&#23454;&#25968;&#25454;&#12290;&#36825;&#20063;&#26159;&#39318;&#27425;&#20174;&#38750;&#37197;&#23545;&#24178;&#39044;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23884;&#20837;&#20013;&#33719;&#24471;&#22240;&#26524;&#21487;&#35782;&#21035;&#24615;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#20381;&#36182;&#20110;&#20180;&#32454;&#25581;&#31034;&#32463;&#36807;&#38750;&#32447;&#24615;&#23494;&#24230;&#36716;&#25442;&#21518;&#25968;&#25454;&#20998;&#24067;&#20013;&#23384;&#22312;&#30340;&#39640;&#32500;&#20960;&#20309;&#32467;&#26500;&#65292;&#25105;&#20204;&#36890;&#36807;&#20998;&#26512;&#28508;&#22312;&#20998;&#24067;&#30340;&#31934;&#24230;&#30697;&#38453;&#30340;&#20108;&#27425;&#24418;&#24335;&#26469;&#25429;&#25417;&#36825;&#31181;&#32467;&#26500;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#27604;&#31639;&#27861;&#26469;&#23454;&#38469;&#35782;&#21035;&#28508;&#22312;&#21464;&#37327;&#65292;&#24182;&#35780;&#20272;&#20854;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of learning causal representations from unknown, latent interventions in a general setting, where the latent distribution is Gaussian but the mixing function is completely general. We prove strong identifiability results given unknown single-node interventions, i.e., without having access to the intervention targets. This generalizes prior works which have focused on weaker classes, such as linear maps or paired counterfactual data. This is also the first instance of causal identifiability from non-paired interventions for deep neural network embeddings. Our proof relies on carefully uncovering the high-dimensional geometric structure present in the data distribution after a non-linear density transformation, which we capture by analyzing quadratic forms of precision matrices of the latent distributions. Finally, we propose a contrastive algorithm to identify the latent variables in practice and evaluate its performance on various tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23558;NeSy&#27169;&#22411;&#20013;&#20986;&#29616;&#30340;&#25512;&#29702;&#24555;&#25463;&#26041;&#24335;&#23450;&#20041;&#20026;&#23398;&#20064;&#30446;&#26631;&#30340;&#24847;&#22806;&#26368;&#20248;&#35299;&#65292;&#24182;&#30830;&#23450;&#20854;&#21457;&#29983;&#30340;&#22235;&#20010;&#20851;&#38190;&#26465;&#20214;&#65292;&#25552;&#20986;&#20102;&#20960;&#31181;&#21487;&#34892;&#30340;&#32531;&#35299;&#31574;&#30053;&#24182;&#23545;&#20854;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#26174;&#31034;&#25512;&#29702;&#24555;&#25463;&#26041;&#24335;&#38590;&#20197;&#22788;&#29702;&#12290;</title><link>http://arxiv.org/abs/2305.19951</link><description>&lt;p&gt;
&#19981;&#26159;&#25152;&#26377;&#31070;&#32463;&#31526;&#21495;&#27010;&#24565;&#37117;&#26159;&#24179;&#31561;&#30340;&#65306; &#25512;&#29702;&#24555;&#25463;&#26041;&#24335;&#30340;&#20998;&#26512;&#21644;&#32531;&#35299;
&lt;/p&gt;
&lt;p&gt;
Not All Neuro-Symbolic Concepts Are Created Equal: Analysis and Mitigation of Reasoning Shortcuts. (arXiv:2305.19951v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19951
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23558;NeSy&#27169;&#22411;&#20013;&#20986;&#29616;&#30340;&#25512;&#29702;&#24555;&#25463;&#26041;&#24335;&#23450;&#20041;&#20026;&#23398;&#20064;&#30446;&#26631;&#30340;&#24847;&#22806;&#26368;&#20248;&#35299;&#65292;&#24182;&#30830;&#23450;&#20854;&#21457;&#29983;&#30340;&#22235;&#20010;&#20851;&#38190;&#26465;&#20214;&#65292;&#25552;&#20986;&#20102;&#20960;&#31181;&#21487;&#34892;&#30340;&#32531;&#35299;&#31574;&#30053;&#24182;&#23545;&#20854;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#26174;&#31034;&#25512;&#29702;&#24555;&#25463;&#26041;&#24335;&#38590;&#20197;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#31526;&#21495;&#65288;NeSy&#65289;&#39044;&#27979;&#27169;&#22411;&#25215;&#35834;&#20855;&#26377;&#25913;&#36827;&#30340;&#32422;&#26463;&#36981;&#20174;&#24615;&#65292;&#31995;&#32479;&#21270;&#27867;&#21270;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#22240;&#20026;&#23427;&#20204;&#20801;&#35768;&#36890;&#36807;&#23545;&#20174;&#23376;&#31526;&#21495;&#36755;&#20837;&#20013;&#25552;&#21462;&#20986;&#30340;&#39640;&#32423;&#27010;&#24565;&#36827;&#34892;&#25512;&#29702;&#26469;&#25512;&#26029;&#19982;&#26576;&#20123;&#20808;&#39564;&#30693;&#35782;&#19968;&#33268;&#30340;&#26631;&#31614;&#12290;&#26368;&#36817;&#26174;&#31034;NeSy&#39044;&#27979;&#22120;&#21463;&#21040;&#25512;&#29702;&#24555;&#25463;&#26041;&#24335;&#30340;&#24433;&#21709;&#65306;&#23427;&#20204;&#21487;&#20197;&#36890;&#36807;&#21033;&#29992;&#20855;&#26377;&#24847;&#22806;&#35821;&#20041;&#30340;&#27010;&#24565;&#36798;&#21040;&#39640;&#31934;&#24230;&#65292;&#20174;&#32780;&#30701;&#20110;&#20854;&#25215;&#35834;&#30340;&#20248;&#21183;&#12290;&#20294;&#26159;&#65292;&#32570;&#23569;&#23545;&#25512;&#29702;&#24555;&#25463;&#26041;&#24335;&#21450;&#20854;&#28508;&#22312;&#32531;&#35299;&#31574;&#30053;&#30340;&#31995;&#32479;&#25551;&#36848;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#20854;&#34920;&#24449;&#20026;&#23398;&#20064;&#30446;&#26631;&#30340;&#24847;&#22806;&#26368;&#20248;&#35299;&#65292;&#24182;&#30830;&#23450;&#20854;&#21457;&#29983;&#32972;&#21518;&#30340;&#22235;&#20010;&#20851;&#38190;&#26465;&#20214;&#26469;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#22522;&#20110;&#27492;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20960;&#31181;&#33258;&#28982;&#30340;&#32531;&#35299;&#31574;&#30053;&#65292;&#24182;&#20174;&#29702;&#35770;&#21644;&#23454;&#35777;&#35282;&#24230;&#20998;&#26512;&#23427;&#20204;&#30340;&#21151;&#25928;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#26174;&#31034;&#65292;&#25512;&#29702;&#24555;&#25463;&#26041;&#24335;&#24456;&#38590;&#22788;&#29702;&#65292;&#36825;&#23545;&#20110;&#20449;&#20219;&#23427;&#20204;&#30340;&#21512;&#29702;&#24615;&#20135;&#29983;&#20102;&#30097;&#38382;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neuro-Symbolic (NeSy) predictive models hold the promise of improved compliance with given constraints, systematic generalization, and interpretability, as they allow to infer labels that are consistent with some prior knowledge by reasoning over high-level concepts extracted from sub-symbolic inputs. It was recently shown that NeSy predictors are affected by reasoning shortcuts: they can attain high accuracy but by leveraging concepts with unintended semantics, thus coming short of their promised advantages. Yet, a systematic characterization of reasoning shortcuts and of potential mitigation strategies is missing. This work fills this gap by characterizing them as unintended optima of the learning objective and identifying four key conditions behind their occurrence. Based on this, we derive several natural mitigation strategies, and analyze their efficacy both theoretically and empirically. Our analysis shows reasoning shortcuts are difficult to deal with, casting doubts on the trus
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#21450;&#20854;&#26465;&#20214;&#65292;&#35777;&#26126;&#20102;&#21160;&#24577;&#19979;&#26799;&#24230;&#19979;&#38477;&#21487;&#20197;&#36890;&#36807;&#26377;&#38480;&#25968;&#37327;&#30340;&#22823;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#26469;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#65292;&#24182;&#25214;&#21040;&#20102;&#22810;&#20010;&#21644;&#21333;&#19968;&#26041;&#21521;&#30340;&#26368;&#20339;&#25209;&#37327;&#22823;&#23567;&#65292;&#26377;&#21161;&#20110;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#21644;&#26041;&#21521;&#30340;&#19987;&#19994;&#21270;&#12290;</title><link>http://arxiv.org/abs/2305.18270</link><description>&lt;p&gt;
&#23398;&#20064;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#65306;&#19968;&#27425;(&#24040;&#22823;)&#30340;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning Two-Layer Neural Networks, One (Giant) Step at a Time. (arXiv:2305.18270v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18270
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#21450;&#20854;&#26465;&#20214;&#65292;&#35777;&#26126;&#20102;&#21160;&#24577;&#19979;&#26799;&#24230;&#19979;&#38477;&#21487;&#20197;&#36890;&#36807;&#26377;&#38480;&#25968;&#37327;&#30340;&#22823;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#26469;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#65292;&#24182;&#25214;&#21040;&#20102;&#22810;&#20010;&#21644;&#21333;&#19968;&#26041;&#21521;&#30340;&#26368;&#20339;&#25209;&#37327;&#22823;&#23567;&#65292;&#26377;&#21161;&#20110;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#21644;&#26041;&#21521;&#30340;&#19987;&#19994;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#30740;&#31350;&#20102;&#26377;&#38480;&#25968;&#37327;&#30340;&#22823;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#26377;&#21161;&#20110;&#22312;&#26680;&#24515;&#33539;&#22260;&#20043;&#22806;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#30340;&#26465;&#20214;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#25209;&#37327;&#22823;&#23567;&#21644;&#22810;&#20010;(&#20294;&#26377;&#38480;&#30340;)&#27493;&#39588;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#21333;&#27493;&#39588;&#36807;&#31243;&#65292;&#21457;&#29616;&#25209;&#37327;&#22823;&#23567;&#20026;$n=O(d)$&#21487;&#20197;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#65292;&#20294;&#21482;&#36866;&#21512;&#23398;&#20064;&#21333;&#19968;&#26041;&#21521;&#25110;&#21333;&#32034;&#24341;&#27169;&#22411;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;$n=O(d^2)$&#23545;&#20110;&#23398;&#20064;&#22810;&#20010;&#26041;&#21521;&#21644;&#19987;&#19994;&#21270;&#33267;&#20851;&#37325;&#35201;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#8220;&#30828;&#8221;&#26041;&#21521;&#32570;&#20047;&#21069;$\ell$&#20010;Hermite&#31995;&#25968;&#65292;&#20173;&#26410;&#34987;&#21457;&#29616;&#65292;&#24182;&#19988;&#38656;&#35201;&#25209;&#37327;&#22823;&#23567;&#20026;$n=O(d^\ell)$&#25165;&#33021;&#34987;&#26799;&#24230;&#19979;&#38477;&#25429;&#33719;&#12290;&#32463;&#36807;&#20960;&#27425;&#36845;&#20195;&#65292;&#24773;&#20917;&#21457;&#29983;&#21464;&#21270;&#65306;&#25209;&#37327;&#22823;&#23567;&#20026;$n=O(d)$&#36275;&#20197;&#23398;&#20064;&#26032;&#30340;&#30446;&#26631;&#26041;&#21521;&#65292;&#36825;&#20123;&#26041;&#21521;&#22312;Hermite&#22522;&#30784;&#19978;&#32447;&#24615;&#36830;&#25509;&#21040;&#20043;&#21069;&#23398;&#20064;&#30340;&#26041;&#21521;&#25152;&#28085;&#30422;&#30340;&#23376;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the training dynamics of shallow neural networks, investigating the conditions under which a limited number of large batch gradient descent steps can facilitate feature learning beyond the kernel regime. We compare the influence of batch size and that of multiple (but finitely many) steps. Our analysis of a single-step process reveals that while a batch size of $n = O(d)$ enables feature learning, it is only adequate for learning a single direction, or a single-index model. In contrast, $n = O(d^2)$ is essential for learning multiple directions and specialization. Moreover, we demonstrate that ``hard'' directions, which lack the first $\ell$ Hermite coefficients, remain unobserved and require a batch size of $n = O(d^\ell)$ for being captured by gradient descent. Upon iterating a few steps, the scenario changes: a batch-size of $n = O(d)$ is enough to learn new target directions spanning the subspace linearly connected in the Hermite basis to the previously learned directions,
&lt;/p&gt;</description></item><item><title>GLOBE-CE&#26159;&#19968;&#31181;&#29992;&#20110;&#20840;&#29699;&#22240;&#26524;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#36229;&#36234;&#23616;&#37096;&#35299;&#37322;&#65292;&#25552;&#20379;&#26356;&#26377;&#25928;&#21644;&#20132;&#20114;&#24335;&#30340;&#35299;&#37322;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2305.17021</link><description>&lt;p&gt;
GLOBE-CE&#65306;&#19968;&#31181;&#29992;&#20110;&#20840;&#29699;&#22240;&#26524;&#35299;&#37322;&#30340;&#22522;&#20110;&#32763;&#35793;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
GLOBE-CE: A Translation-Based Approach for Global Counterfactual Explanations. (arXiv:2305.17021v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17021
&lt;/p&gt;
&lt;p&gt;
GLOBE-CE&#26159;&#19968;&#31181;&#29992;&#20110;&#20840;&#29699;&#22240;&#26524;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#36229;&#36234;&#23616;&#37096;&#35299;&#37322;&#65292;&#25552;&#20379;&#26356;&#26377;&#25928;&#21644;&#20132;&#20114;&#24335;&#30340;&#35299;&#37322;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#35299;&#37322;&#22312;&#21487;&#35299;&#37322;&#24615;&#26041;&#38754;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#20844;&#24179;&#24615;&#12289;&#36861;&#32034;&#26435;&#21644;&#27169;&#22411;&#29702;&#35299;&#31561;&#39046;&#22495;&#30340;&#24212;&#29992;&#20381;&#36182;&#20110;&#19968;&#31995;&#21015;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#26368;&#22823;&#30340;&#32570;&#28857;&#26159;&#26080;&#27861;&#25552;&#20379;&#36229;&#36234;&#23616;&#37096;&#25110;&#23454;&#20363;&#32423;&#21035;&#30340;&#35299;&#37322;&#12290;&#23613;&#31649;&#35768;&#22810;&#20316;&#21697;&#28041;&#21450;&#20840;&#23616;&#35299;&#37322;&#30340;&#27010;&#24565;&#65292;&#36890;&#24120;&#24314;&#35758;&#32858;&#21512;&#22823;&#37327;&#23616;&#37096;&#35299;&#37322;&#20197;&#30830;&#23450;&#20840;&#23616;&#23646;&#24615;&#65292;&#20294;&#24456;&#23569;&#25552;&#20379;&#21487;&#38752;&#19988;&#35745;&#31639;&#21487;&#34892;&#30340;&#26694;&#26550;&#12290;&#21516;&#26102;&#65292;&#23454;&#36341;&#32773;&#38656;&#35201;&#26356;&#26377;&#25928;&#21644;&#20132;&#20114;&#24335;&#30340;&#21487;&#35299;&#37322;&#24615;&#24037;&#20855;&#12290;&#25105;&#20204;&#20511;&#27492;&#26426;&#20250;&#25552;&#20986;&#20102;&#20840;&#23616;&#19988;&#26377;&#25928;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#26694;&#26550;(GLOBE-CE)&#65292;&#36825;&#26159;&#19968;&#20010;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#24403;&#21069;&#26368;&#20808;&#36827;&#26694;&#26550;&#22312;&#39640;&#32500;&#25968;&#25454;&#38598;&#21644;&#36830;&#32493;&#29305;&#24449;&#23384;&#22312;&#30340;&#21487;&#38752;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#29420;&#29305;&#30340;&#25968;&#23398;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactual explanations have been widely studied in explainability, with a range of application dependent methods prominent in fairness, recourse and model understanding. The major shortcoming associated with these methods, however, is their inability to provide explanations beyond the local or instance-level. While many works touch upon the notion of a global explanation, typically suggesting to aggregate masses of local explanations in the hope of ascertaining global properties, few provide frameworks that are both reliable and computationally tractable. Meanwhile, practitioners are requesting more efficient and interactive explainability tools. We take this opportunity to propose Global &amp; Efficient Counterfactual Explanations (GLOBE-CE), a flexible framework that tackles the reliability and scalability issues associated with current state-of-the-art, particularly on higher dimensional datasets and in the presence of continuous features. Furthermore, we provide a unique mathemati
&lt;/p&gt;</description></item><item><title>ZeroSCROLLS&#26159;&#19968;&#20010;&#29992;&#20110;&#38271;&#25991;&#26412;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#30340;&#38646;Shot&#22522;&#20934;&#27979;&#35797;&#65292;&#21253;&#25324;&#20845;&#20010;&#20219;&#21153;&#21644;&#22235;&#20010;&#25968;&#25454;&#38598;&#65292;&#33021;&#22815;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#24403;&#21069;&#65292;GPT-4&#30340;&#24179;&#22343;&#24471;&#20998;&#26368;&#39640;&#65292;&#20294;&#22312;&#32858;&#21512;&#20219;&#21153;&#31561;&#22810;&#20010;&#25361;&#25112;&#19978;&#65292;&#20173;&#26377;&#25913;&#36827;&#30340;&#31354;&#38388;&#12290;</title><link>http://arxiv.org/abs/2305.14196</link><description>&lt;p&gt;
ZeroSCROLLS&#65306;&#19968;&#20010;&#29992;&#20110;&#38271;&#25991;&#26412;&#29702;&#35299;&#30340;&#38646;Shot&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding. (arXiv:2305.14196v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14196
&lt;/p&gt;
&lt;p&gt;
ZeroSCROLLS&#26159;&#19968;&#20010;&#29992;&#20110;&#38271;&#25991;&#26412;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#30340;&#38646;Shot&#22522;&#20934;&#27979;&#35797;&#65292;&#21253;&#25324;&#20845;&#20010;&#20219;&#21153;&#21644;&#22235;&#20010;&#25968;&#25454;&#38598;&#65292;&#33021;&#22815;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#24403;&#21069;&#65292;GPT-4&#30340;&#24179;&#22343;&#24471;&#20998;&#26368;&#39640;&#65292;&#20294;&#22312;&#32858;&#21512;&#20219;&#21153;&#31561;&#22810;&#20010;&#25361;&#25112;&#19978;&#65292;&#20173;&#26377;&#25913;&#36827;&#30340;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102; ZeroSCROLLS&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#38271;&#25991;&#26412;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#30340;&#38646;Shot&#22522;&#20934;&#27979;&#35797;&#65292;&#20165;&#21253;&#21547;&#27979;&#35797;&#38598;&#32780;&#27809;&#26377;&#35757;&#32451;&#25110;&#24320;&#21457;&#25968;&#25454;&#12290;&#25105;&#20204;&#20174;SCROLLS&#22522;&#20934;&#27979;&#35797;&#20013;&#36866;&#24212;&#20102;&#20845;&#20010;&#20219;&#21153;&#65292;&#24182;&#28155;&#21152;&#20102;&#22235;&#20010;&#26032;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#20004;&#20010;&#26032;&#30340;&#20449;&#24687;&#34701;&#21512;&#20219;&#21153;&#65292;&#20363;&#22914;&#32858;&#21512;&#27491;&#38754;&#35780;&#20215;&#30340;&#30334;&#20998;&#27604;&#12290;&#20351;&#29992;ZeroSCROLLS&#65292;&#25105;&#20204;&#23545;&#24320;&#28304;&#21644;&#38381;&#28304;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#20840;&#38754;&#35780;&#20272;&#65292;&#21457;&#29616;Claude&#20248;&#20110;ChatGPT&#65292;&#24182;&#19988;GPT-4&#33719;&#24471;&#20102;&#26368;&#39640;&#30340;&#24179;&#22343;&#20998;&#25968;&#12290;&#28982;&#32780;&#65292;&#22312;ZeroSCROLLS&#30340;&#22810;&#20010;&#24320;&#25918;&#25361;&#25112;&#26041;&#38754;&#65288;&#20363;&#22914;&#65292;&#32858;&#21512;&#20219;&#21153;&#65289;&#65292;&#36824;&#26377;&#25913;&#36827;&#30340;&#31354;&#38388;&#65292;&#22240;&#20026;&#27169;&#22411;&#24456;&#38590;&#36890;&#36807;&#26420;&#32032;&#30340;&#22522;&#20934;&#27979;&#35797;&#12290;&#30001;&#20110;&#26368;&#20808;&#36827;&#30340;&#25216;&#26415;&#36824;&#22312;&#19981;&#26029;&#26356;&#26032;&#65292;&#25105;&#20204;&#36992;&#35831;&#30740;&#31350;&#20154;&#21592;&#22312;&#23454;&#26102;&#30340;ZeroSCROLLS&#25490;&#34892;&#27036;&#19978;&#35780;&#20272;&#20182;&#20204;&#30340;&#24819;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce ZeroSCROLLS, a zero-shot benchmark for natural language understanding over long texts, which contains only test sets, without training or development data. We adapt six tasks from the SCROLLS benchmark, and add four new datasets, including two novel information fusing tasks, such as aggregating the percentage of positive reviews. Using ZeroSCROLLS, we conduct a comprehensive evaluation of both open-source and closed large language models, finding that Claude outperforms ChatGPT, and that GPT-4 achieves the highest average score. However, there is still room for improvement on multiple open challenges in ZeroSCROLLS, such as aggregation tasks, where models struggle to pass the naive baseline. As the state of the art is a moving target, we invite researchers to evaluate their ideas on the live ZeroSCROLLS leaderboard
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;&#23558;&#28040;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#24212;&#29992;&#20110;&#31232;&#30095;&#22270;&#30340;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#26159;&#28176;&#36817;&#26412;&#22320;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29616;&#26368;&#20248;&#20998;&#31867;&#22120;&#30340;&#31639;&#27861;&#65292;&#24182;&#23558;&#26368;&#20248;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#29702;&#35770;&#19978;&#19982;&#29616;&#26377;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2305.10391</link><description>&lt;p&gt;
&#31232;&#30095;&#22270;&#30340;&#28040;&#24687;&#20256;&#36882;&#26550;&#26500;&#30340;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
Optimality of Message-Passing Architectures for Sparse Graphs. (arXiv:2305.10391v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10391
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;&#23558;&#28040;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#24212;&#29992;&#20110;&#31232;&#30095;&#22270;&#30340;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#26159;&#28176;&#36817;&#26412;&#22320;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29616;&#26368;&#20248;&#20998;&#31867;&#22120;&#30340;&#31639;&#27861;&#65292;&#24182;&#23558;&#26368;&#20248;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#29702;&#35770;&#19978;&#19982;&#29616;&#26377;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#29305;&#24449;&#35013;&#39280;&#22270;&#19978;&#30340;&#33410;&#28857;&#20998;&#31867;&#38382;&#39064;&#65292;&#22312;&#31232;&#30095;&#35774;&#32622;&#19979;&#65292;&#21363;&#33410;&#28857;&#30340;&#39044;&#26399;&#24230;&#25968;&#20026;&#33410;&#28857;&#25968;&#30340;O(1)&#26102;&#12290;&#36825;&#26679;&#30340;&#22270;&#36890;&#24120;&#34987;&#31216;&#20026;&#26412;&#22320;&#26641;&#29366;&#22270;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21483;&#20570;&#28176;&#36817;&#26412;&#22320;&#36125;&#21494;&#26031;&#26368;&#20248;&#24615;&#30340;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#24615;&#27010;&#24565;&#65292;&#24182;&#26681;&#25454;&#36825;&#20010;&#26631;&#20934;&#35745;&#31639;&#20102;&#20855;&#26377;&#20219;&#24847;&#33410;&#28857;&#29305;&#24449;&#21644;&#36793;&#36830;&#25509;&#20998;&#24067;&#30340;&#30456;&#24403;&#19968;&#33324;&#30340;&#32479;&#35745;&#25968;&#25454;&#27169;&#22411;&#30340;&#26368;&#20248;&#20998;&#31867;&#22120;&#12290;&#35813;&#26368;&#20248;&#20998;&#31867;&#22120;&#21487;&#20197;&#20351;&#29992;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#23454;&#29616;&#12290;&#28982;&#21518;&#25105;&#20204;&#35745;&#31639;&#20102;&#35813;&#20998;&#31867;&#22120;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#24182;&#22312;&#19968;&#20010;&#24050;&#32463;&#30740;&#31350;&#20805;&#20998;&#30340;&#32479;&#35745;&#27169;&#22411;&#19978;&#20174;&#29702;&#35770;&#19978;&#19982;&#29616;&#26377;&#30340;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#20302;&#22270;&#20449;&#21495;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20339;&#28040;&#24687;&#20256;&#36882;&#26550;&#26500;&#25554;&#20540;&#20110;&#26631;&#20934;MLP&#21644;&#19968;&#31181;&#20856;&#22411;&#30340;c&#26550;&#26500;&#20043;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the node classification problem on feature-decorated graphs in the sparse setting, i.e., when the expected degree of a node is $O(1)$ in the number of nodes. Such graphs are typically known to be locally tree-like. We introduce a notion of Bayes optimality for node classification tasks, called asymptotic local Bayes optimality, and compute the optimal classifier according to this criterion for a fairly general statistical data model with arbitrary distributions of the node features and edge connectivity. The optimal classifier is implementable using a message-passing graph neural network architecture. We then compute the generalization error of this classifier and compare its performance against existing learning methods theoretically on a well-studied statistical model with naturally identifiable signal-to-noise ratios (SNRs) in the data. We find that the optimal message-passing architecture interpolates between a standard MLP in the regime of low graph signal and a typical c
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;&#25512;&#24191;&#32447;&#24615;&#30697;&#38453;&#19981;&#31561;&#24335;&#26694;&#26550;&#30340;&#22522;&#30784;&#19978;&#65292;&#30740;&#31350;&#20102;&#24494;&#20998;&#26041;&#31243;&#21644;&#20248;&#21270;&#31639;&#27861;&#30340;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#38024;&#23545;&#19968;&#20010;&#20004;&#21442;&#25968;Nesterov&#20248;&#21270;&#26041;&#27861;&#23478;&#26063;&#26032;&#30340;&#26446;&#20122;&#26222;&#35834;&#22827;&#20989;&#25968;&#24182;&#34920;&#24449;&#20854;&#25910;&#25947;&#36895;&#24230;&#65292;&#22312;&#27492;&#22522;&#30784;&#19978;&#35777;&#26126;&#20102;&#26377;&#26174;&#33879;&#25913;&#36827;&#30340;Nesterov&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#30830;&#23450;&#20986;&#20135;&#29983;&#26368;&#20339;&#36895;&#24230;&#30340;&#31995;&#25968;&#36873;&#25321;&#12290;</title><link>http://arxiv.org/abs/2305.08658</link><description>&lt;p&gt;
&#20851;&#20110;&#20248;&#21270;&#31639;&#27861;&#12289;&#26446;&#20122;&#26222;&#35834;&#22827;&#20989;&#25968;&#21644;&#24494;&#20998;&#26041;&#31243;&#30340;&#32852;&#31995;&#65306;&#29702;&#35770;&#19982;&#27934;&#35265;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the connections between optimization algorithms, Lyapunov functions, and differential equations: theory and insights. (arXiv:2305.08658v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08658
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#25512;&#24191;&#32447;&#24615;&#30697;&#38453;&#19981;&#31561;&#24335;&#26694;&#26550;&#30340;&#22522;&#30784;&#19978;&#65292;&#30740;&#31350;&#20102;&#24494;&#20998;&#26041;&#31243;&#21644;&#20248;&#21270;&#31639;&#27861;&#30340;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#38024;&#23545;&#19968;&#20010;&#20004;&#21442;&#25968;Nesterov&#20248;&#21270;&#26041;&#27861;&#23478;&#26063;&#26032;&#30340;&#26446;&#20122;&#26222;&#35834;&#22827;&#20989;&#25968;&#24182;&#34920;&#24449;&#20854;&#25910;&#25947;&#36895;&#24230;&#65292;&#22312;&#27492;&#22522;&#30784;&#19978;&#35777;&#26126;&#20102;&#26377;&#26174;&#33879;&#25913;&#36827;&#30340;Nesterov&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#30830;&#23450;&#20986;&#20135;&#29983;&#26368;&#20339;&#36895;&#24230;&#30340;&#31995;&#25968;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#25512;&#24191;Fazylab&#31561;&#20154;&#22312;2018&#24180;&#21457;&#23637;&#30340;&#32447;&#24615;&#30697;&#38453;&#19981;&#31561;&#24335;&#26694;&#26550;&#65292;&#30740;&#31350;&#20102;&#29992;&#26446;&#20122;&#26222;&#35834;&#22827;&#20989;&#25968;&#30740;&#31350;$m$-&#24378;&#20984;&#21644;$L$-&#20809;&#28369;&#20989;&#25968;&#30340;&#24494;&#20998;&#26041;&#31243;&#21644;&#20248;&#21270;&#31639;&#27861;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;&#20351;&#29992;&#26032;&#26694;&#26550;&#65292;&#25105;&#20204;&#38024;&#23545;&#19968;&#20010;&#20004;&#21442;&#25968;Nesterov&#20248;&#21270;&#26041;&#27861;&#23478;&#26063;&#30340;&#26032;&#22411;&#65288;&#31163;&#25955;&#65289;&#26446;&#20122;&#26222;&#35834;&#22827;&#20989;&#25968;&#36827;&#34892;&#20102;&#35299;&#26512;&#25512;&#23548;&#65292;&#24182;&#34920;&#24449;&#20102;&#20854;&#25910;&#25947;&#36895;&#24230;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#35777;&#26126;&#23545;&#20110;&#26631;&#20934;&#31995;&#25968;&#30340;Nesterov&#26041;&#27861;&#30340;&#20808;&#21069;&#35777;&#26126;&#36895;&#24230;&#26377;&#20102;&#26126;&#26174;&#25913;&#36827;&#65292;&#24182;&#19988;&#34920;&#24449;&#20102;&#20135;&#29983;&#26368;&#20339;&#36895;&#24230;&#30340;&#31995;&#25968;&#36873;&#25321;&#12290;&#25105;&#20204;&#20026;Polyak ODE&#33719;&#24471;&#20102;&#26032;&#30340;&#26446;&#20122;&#26222;&#35834;&#22827;&#20989;&#25968;&#65292;&#24182;&#37325;&#26032;&#23457;&#35270;&#20102;&#27492;ODE&#19982;Nesterov&#31639;&#27861;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;&#27492;&#22806;&#65292;&#35752;&#35770;&#20102;&#23558;Nesterov&#26041;&#27861;&#35299;&#37322;&#20026;&#21152;&#24615;Runge-Kutta&#31163;&#25955;&#21270;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#35299;&#37322;&#20102;&#31163;&#25955;&#21270;Polyak&#26041;&#31243;&#30340;&#32467;&#26500;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study connections between differential equations and optimization algorithms for $m$-strongly and $L$-smooth convex functions through the use of Lyapunov functions by generalizing the Linear Matrix Inequality framework developed by Fazylab et al. in 2018. Using the new framework we derive analytically a new (discrete) Lyapunov function for a two-parameter family of Nesterov optimization methods and characterize their convergence rate. This allows us to prove a convergence rate that improves substantially on the previously proven rate of Nesterov's method for the standard choice of coefficients, as well as to characterize the choice of coefficients that yields the optimal rate. We obtain a new Lyapunov function for the Polyak ODE and revisit the connection between this ODE and the Nesterov's algorithms. In addition discuss a new interpretation of Nesterov method as an additive Runge-Kutta discretization and explain the structural conditions that discretizations of the Polyak equation
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#40654;&#26364;&#23376;&#31354;&#38388;&#19979;&#38477;&#31639;&#27861;&#30340;&#23545;&#31216;&#27491;&#23450;&#27969;&#24418;&#19978;&#30340;&#20989;&#25968;&#26368;&#23567;&#21270;&#26041;&#27861;&#65292;&#20854;&#20855;&#26377;&#20302;&#22797;&#26434;&#24230;&#21644;&#36991;&#20813;&#26114;&#36149;&#30697;&#38453;&#25805;&#20316;&#21644;&#35745;&#31639;&#40654;&#26364;&#26799;&#24230;&#30340;&#20248;&#28857;&#12290;</title><link>http://arxiv.org/abs/2305.02041</link><description>&lt;p&gt;
&#23545;&#31216;&#27491;&#23450;&#27969;&#24418;&#19978;&#20302;&#22797;&#26434;&#24230;&#30340;&#23376;&#31354;&#38388;&#19979;&#38477;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Low-complexity subspace-descent over symmetric positive definite manifold. (arXiv:2305.02041v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02041
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#40654;&#26364;&#23376;&#31354;&#38388;&#19979;&#38477;&#31639;&#27861;&#30340;&#23545;&#31216;&#27491;&#23450;&#27969;&#24418;&#19978;&#30340;&#20989;&#25968;&#26368;&#23567;&#21270;&#26041;&#27861;&#65292;&#20854;&#20855;&#26377;&#20302;&#22797;&#26434;&#24230;&#21644;&#36991;&#20813;&#26114;&#36149;&#30697;&#38453;&#25805;&#20316;&#21644;&#35745;&#31639;&#40654;&#26364;&#26799;&#24230;&#30340;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20302;&#22797;&#26434;&#24230;&#30340;&#40654;&#26364;&#23376;&#31354;&#38388;&#19979;&#38477;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#23545;&#31216;&#27491;&#23450;&#65288;SPD&#65289;&#27969;&#24418;&#19978;&#23545;&#20989;&#25968;&#36827;&#34892;&#26368;&#23567;&#21270;&#12290;&#19982;&#29616;&#26377;&#30340;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#21464;&#20307;&#19981;&#21516;&#30340;&#26159;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21033;&#29992; carefully chosen &#30340;&#23376;&#31354;&#38388;&#65292;&#20351;&#24471;&#26356;&#26032;&#21487;&#20197;&#20889;&#25104;&#36845;&#20195;&#30340; Cholesky &#22240;&#23376;&#21644;&#19968;&#20010;&#31232;&#30095;&#30697;&#38453;&#30340;&#20056;&#31215;&#24418;&#24335;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#26356;&#26032;&#36991;&#20813;&#20102;&#26114;&#36149;&#30340;&#30697;&#38453;&#25805;&#20316;&#65292;&#22914;&#30697;&#38453;&#25351;&#25968;&#21644;&#23494;&#38598;&#30697;&#38453;&#20056;&#27861;&#65292;&#36825;&#20123;&#25805;&#20316;&#36890;&#24120;&#22312;&#20960;&#20046;&#25152;&#26377;&#20854;&#20182; Riemannian &#20248;&#21270;&#31639;&#27861;&#20013;&#37117;&#26159;&#24517;&#38656;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work puts forth low-complexity Riemannian subspace descent algorithms for the minimization of functions over the symmetric positive definite (SPD) manifold. Different from the existing Riemannian gradient descent variants, the proposed approach utilizes carefully chosen subspaces that allow the update to be written as a product of the Cholesky factor of the iterate and a sparse matrix. The resulting updates avoid the costly matrix operations like matrix exponentiation and dense matrix multiplication, which are generally required in almost all other Riemannian optimization algorithms on SPD manifold. We further identify a broad class of functions, arising in diverse applications, such as kernel matrix learning, covariance estimation of Gaussian distributions, maximum likelihood parameter estimation of elliptically contoured distributions, and parameter estimation in Gaussian mixture model problems, over which the Riemannian gradients can be calculated efficiently. The proposed uni-
&lt;/p&gt;</description></item><item><title>&#36830;&#32493;&#26102;&#38388;&#21151;&#33021;&#25193;&#25955;&#36807;&#31243;&#24341;&#20837;&#20102;&#21151;&#33021;&#25193;&#25955;&#36807;&#31243;&#65288;FDPs&#65289;&#65292;&#23558;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#25512;&#24191;&#21040;&#26080;&#38480;&#32500;&#20989;&#25968;&#31354;&#38388;&#12290;&#36890;&#36807;&#20351;&#29992;&#26032;&#30340;&#25968;&#23398;&#26694;&#26550;&#21644;&#25193;&#23637;&#65292;FDPs&#21487;&#20197;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#26500;&#24314;&#26032;&#22411;&#29983;&#25104;&#27169;&#22411;&#65292;&#22312;&#22788;&#29702;&#36830;&#32493;&#25968;&#25454;&#26102;&#33021;&#22815;&#23454;&#29616;&#39640;&#36136;&#37327;&#30340;&#22270;&#20687;&#29983;&#25104;&#65292;&#25152;&#38656;&#21442;&#25968;&#25968;&#37327;&#27604;&#29616;&#26377;&#27169;&#22411;&#20302;&#20960;&#20010;&#25968;&#37327;&#32423;&#12290;</title><link>http://arxiv.org/abs/2303.00800</link><description>&lt;p&gt;
&#36830;&#32493;&#26102;&#38388;&#21151;&#33021;&#25193;&#25955;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Continuous-Time Functional Diffusion Processes. (arXiv:2303.00800v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.00800
&lt;/p&gt;
&lt;p&gt;
&#36830;&#32493;&#26102;&#38388;&#21151;&#33021;&#25193;&#25955;&#36807;&#31243;&#24341;&#20837;&#20102;&#21151;&#33021;&#25193;&#25955;&#36807;&#31243;&#65288;FDPs&#65289;&#65292;&#23558;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#25512;&#24191;&#21040;&#26080;&#38480;&#32500;&#20989;&#25968;&#31354;&#38388;&#12290;&#36890;&#36807;&#20351;&#29992;&#26032;&#30340;&#25968;&#23398;&#26694;&#26550;&#21644;&#25193;&#23637;&#65292;FDPs&#21487;&#20197;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#26500;&#24314;&#26032;&#22411;&#29983;&#25104;&#27169;&#22411;&#65292;&#22312;&#22788;&#29702;&#36830;&#32493;&#25968;&#25454;&#26102;&#33021;&#22815;&#23454;&#29616;&#39640;&#36136;&#37327;&#30340;&#22270;&#20687;&#29983;&#25104;&#65292;&#25152;&#38656;&#21442;&#25968;&#25968;&#37327;&#27604;&#29616;&#26377;&#27169;&#22411;&#20302;&#20960;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#21151;&#33021;&#25193;&#25955;&#36807;&#31243;&#65288;FDPs&#65289;&#65292;&#23558;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#25512;&#24191;&#21040;&#26080;&#38480;&#32500;&#20989;&#25968;&#31354;&#38388;&#12290; FDPs&#38656;&#35201;&#19968;&#31181;&#26032;&#30340;&#25968;&#23398;&#26694;&#26550;&#26469;&#25551;&#36848;&#21069;&#21521;&#21644;&#21453;&#21521;&#21160;&#21147;&#23398;&#65292;&#24182;&#36827;&#34892;&#22810;&#20010;&#25193;&#23637;&#20197;&#24471;&#20986;&#23454;&#38469;&#30340;&#35757;&#32451;&#30446;&#26631;&#12290;&#36825;&#20123;&#25193;&#23637;&#21253;&#25324;Girsanov&#23450;&#29702;&#30340;&#26080;&#38480;&#32500;&#29256;&#26412;&#65292;&#20197;&#20415;&#33021;&#22815;&#35745;&#31639;ELBO&#65292;&#20197;&#21450;&#37319;&#26679;&#23450;&#29702;&#30340;&#26080;&#38480;&#32500;&#29256;&#26412;&#65292;&#20197;&#30830;&#20445;&#21487;&#25968;&#20010;&#28857;&#19978;&#30340;&#20989;&#25968;&#35780;&#20272;&#31561;&#20215;&#20110;&#26080;&#38480;&#32500;&#20989;&#25968;&#12290;&#25105;&#20204;&#20351;&#29992;FDPs&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#26500;&#24314;&#20102;&#19968;&#31181;&#26032;&#22411;&#29983;&#25104;&#27169;&#22411;&#65292;&#19981;&#38656;&#35201;&#19987;&#38376;&#30340;&#32593;&#32476;&#26550;&#26500;&#65292;&#24182;&#19988;&#21487;&#20197;&#22788;&#29702;&#20219;&#20309;&#31867;&#22411;&#30340;&#36830;&#32493;&#25968;&#25454;&#12290;&#25105;&#20204;&#22312;&#30495;&#23454;&#25968;&#25454;&#19978;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;&#20351;&#29992;&#31616;&#21333;&#30340;&#22810;&#23618;&#24863;&#30693;&#26426;&#65288;MLP&#65289;&#32467;&#26500;&#65292;FDPs&#23454;&#29616;&#20102;&#39640;&#36136;&#37327;&#30340;&#22270;&#20687;&#29983;&#25104;&#65292;&#25152;&#38656;&#30340;&#21442;&#25968;&#25968;&#37327;&#27604;&#29616;&#26377;&#30340;&#25193;&#25955;&#27169;&#22411;&#20302;&#20960;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce Functional Diffusion Processes (FDPs), which generalize score-based diffusion models to infinite-dimensional function spaces. FDPs require a new mathematical framework to describe the forward and backward dynamics, and several extensions to derive practical training objectives. These include infinite-dimensional versions of Girsanov theorem, in order to be able to compute an ELBO, and of the sampling theorem, in order to guarantee that functional evaluations in a countable set of points are equivalent to infinite-dimensional functions. We use FDPs to build a new breed of generative models in function spaces, which do not require specialized network architectures, and that can work with any kind of continuous data. Our results on real data show that FDPs achieve high-quality image generation, using a simple MLP architecture with orders of magnitude fewer parameters than existing diffusion models.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ECV&#30340;&#20132;&#21449;&#39564;&#35777;&#26041;&#27861;&#65292;&#29992;&#20110;&#35843;&#25972;&#38543;&#26426;&#38598;&#25104;&#20013;&#30340;&#38598;&#25104;&#21644;&#23376;&#26679;&#26412;&#22823;&#23567;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;Out-of-Bag&#38169;&#35823;&#21644;&#21033;&#29992;&#39044;&#27979;&#39118;&#38505;&#20998;&#35299;&#32467;&#26500;&#30340;&#26032;&#22411;&#39118;&#38505;&#22806;&#25512;&#25216;&#26415;&#65292;&#33021;&#22815;&#20135;&#29983;$\delta$-&#26368;&#20248;&#65288;&#20851;&#20110;Oracle&#35843;&#25972;&#39118;&#38505;&#65289;&#30340;&#38598;&#25104;&#12290;</title><link>http://arxiv.org/abs/2302.13511</link><description>&lt;p&gt;
&#38024;&#23545;&#38543;&#26426;&#38598;&#25104;&#30340;&#22806;&#25512;&#20132;&#21449;&#39564;&#35777;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Extrapolated cross-validation for randomized ensembles. (arXiv:2302.13511v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.13511
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ECV&#30340;&#20132;&#21449;&#39564;&#35777;&#26041;&#27861;&#65292;&#29992;&#20110;&#35843;&#25972;&#38543;&#26426;&#38598;&#25104;&#20013;&#30340;&#38598;&#25104;&#21644;&#23376;&#26679;&#26412;&#22823;&#23567;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;Out-of-Bag&#38169;&#35823;&#21644;&#21033;&#29992;&#39044;&#27979;&#39118;&#38505;&#20998;&#35299;&#32467;&#26500;&#30340;&#26032;&#22411;&#39118;&#38505;&#22806;&#25512;&#25216;&#26415;&#65292;&#33021;&#22815;&#20135;&#29983;$\delta$-&#26368;&#20248;&#65288;&#20851;&#20110;Oracle&#35843;&#25972;&#39118;&#38505;&#65289;&#30340;&#38598;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38598;&#25104;&#26041;&#27861;&#65292;&#22914;Bagging&#21644;&#38543;&#26426;&#26862;&#26519;&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#38543;&#22788;&#21487;&#35265;&#65292;&#20174;&#37329;&#34701;&#21040;&#22522;&#22240;&#32452;&#23398;&#12290;&#23613;&#31649;&#23427;&#20204;&#24456;&#24120;&#35265;&#65292;&#20294;&#20851;&#20110;&#26377;&#25928;&#35843;&#25972;&#38598;&#25104;&#21442;&#25968;&#30340;&#38382;&#39064;&#21364;&#21463;&#21040;&#30456;&#23545;&#36739;&#23569;&#30340;&#20851;&#27880;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20132;&#21449;&#39564;&#35777;&#26041;&#27861;&#65292;&#21363;ECV&#65288;&#22806;&#25512;&#20132;&#21449;&#39564;&#35777;&#65289;&#65292;&#29992;&#20110;&#35843;&#25972;&#38543;&#26426;&#38598;&#25104;&#20013;&#30340;&#38598;&#25104;&#21644;&#23376;&#26679;&#26412;&#22823;&#23567;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#20004;&#20010;&#20027;&#35201;&#22240;&#32032;: &#20351;&#29992;Out-of-Bag&#38169;&#35823;&#26469;&#33719;&#21462;&#23567;&#22411;&#38598;&#25104;&#30340;&#21021;&#27493;&#20272;&#35745;&#20540;&#21644;&#19968;&#31181;&#21033;&#29992;&#39044;&#27979;&#39118;&#38505;&#20998;&#35299;&#32467;&#26500;&#30340;&#26032;&#22411;&#39118;&#38505;&#22806;&#25512;&#25216;&#26415;&#12290;&#36890;&#36807;&#35777;&#26126;&#25105;&#20204;&#30340;&#39118;&#38505;&#22806;&#25512;&#25216;&#26415;&#22312;&#38598;&#25104;&#21644;&#23376;&#26679;&#26412;&#22823;&#23567;&#19978;&#20855;&#26377;&#32479;&#19968;&#30340;&#19968;&#33268;&#24615;&#65292;&#25105;&#20204;&#34920;&#26126;ECV&#23545;&#20110;&#24179;&#26041;&#39044;&#27979;&#39118;&#38505;&#33021;&#22815;&#20135;&#29983;$\delta$-&#26368;&#20248;&#65288;&#20851;&#20110;Oracle&#35843;&#25972;&#39118;&#38505;&#65289;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#36866;&#29992;&#20110;&#19968;&#33324;&#30340;&#38598;&#25104;&#39044;&#27979;&#22120;&#65292;&#21482;&#38656;&#35201;&#28201;&#21644;&#30340;&#30697;&#20551;&#35774;&#65292;&#24182;&#20801;&#35768;&#20855;&#26377;&#39640;&#32500;&#24230;&#29305;&#24449;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ensemble methods such as bagging and random forests are ubiquitous in various fields, from finance to genomics. Despite their prevalence, the question of the efficient tuning of ensemble parameters has received relatively little attention. This paper introduces a cross-validation method, ECV (Extrapolated Cross-Validation), for tuning the ensemble and subsample sizes in randomized ensembles. Our method builds on two primary ingredients: initial estimators for small ensemble sizes using out-of-bag errors and a novel risk extrapolation technique that leverages the structure of prediction risk decomposition. By establishing uniform consistency of our risk extrapolation technique over ensemble and subsample sizes, we show that ECV yields $\delta$-optimal (with respect to the oracle-tuned risk) ensembles for squared prediction risk. Our theory accommodates general ensemble predictors, only requires mild moment assumptions, and allows for high-dimensional regimes where the feature dimension 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#31616;&#21270;&#65292;&#25552;&#20986;&#20102;&#40654;&#26364;&#27491;&#24120;&#22352;&#26631;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#21487;&#29992;&#20110;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#30340;&#23376;&#27969;&#24418;&#20248;&#21270;&#65292;&#24182;&#20026;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#65292;&#26080;&#38656;&#26174;&#24335;&#30697;&#38453;&#27714;&#36870;&#12290;</title><link>http://arxiv.org/abs/2302.09738</link><description>&lt;p&gt;
&#31616;&#21270;&#22522;&#20110;&#21160;&#37327;&#30340;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Simplifying Momentum-based Riemannian Submanifold Optimization. (arXiv:2302.09738v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09738
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#31616;&#21270;&#65292;&#25552;&#20986;&#20102;&#40654;&#26364;&#27491;&#24120;&#22352;&#26631;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#21487;&#29992;&#20110;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#30340;&#23376;&#27969;&#24418;&#20248;&#21270;&#65292;&#24182;&#20026;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#65292;&#26080;&#38656;&#26174;&#24335;&#30697;&#38453;&#27714;&#36870;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24102;&#26377;&#21160;&#37327;&#30340;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;&#22312;&#35745;&#31639;&#19978;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#30830;&#20445;&#36845;&#20195;&#20445;&#25345;&#22312;&#23376;&#27969;&#24418;&#19978;&#36890;&#24120;&#38656;&#35201;&#35299;&#20915;&#22256;&#38590;&#30340;&#24494;&#20998;&#26041;&#31243;&#12290;&#26412;&#25991;&#38024;&#23545;&#20855;&#26377;&#20223;&#23556;&#19981;&#21464;&#24230;&#37327;&#30340;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#30340;&#23376;&#27969;&#24418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#31616;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#40654;&#26364;&#27491;&#24120;&#22352;&#26631;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#21487;&#20197;&#23558;&#38382;&#39064;&#21160;&#24577;&#22320;&#31616;&#21270;&#20026;&#27431;&#20960;&#37324;&#24471;&#26080;&#32422;&#26463;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#26469;&#35299;&#37322;&#21644;&#31616;&#21270;&#29616;&#26377;&#30340;&#32467;&#26500;&#21270;&#21327;&#26041;&#24046;&#26041;&#27861;&#65292;&#24182;&#20026;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#65292;&#32780;&#26080;&#38656;&#26174;&#24335;&#30697;&#38453;&#27714;&#36870;&#12290;
&lt;/p&gt;
&lt;p&gt;
Riemannian submanifold optimization with momentum is computationally challenging because ensuring iterates remain on the submanifold often requires solving difficult differential equations. We simplify such optimization algorithms for the submanifold of symmetric positive-definite matrices with the affine invariant metric. We propose a generalized version of the Riemannian normal coordinates which dynamically trivializes the problem into a Euclidean unconstrained problem. We use our approach to explain and simplify existing approaches for structured covariances and develop efficient second-order optimizers for deep learning without explicit matrix inverses.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#30452;&#25509;&#19981;&#30830;&#23450;&#37327;&#21270;&#65288;DirectUQ&#65289;&#26041;&#27861;&#65292;&#23427;&#33021;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#30452;&#25509;&#36755;&#20986;&#22343;&#20540;&#21644;&#26041;&#24046;&#65292;&#21516;&#26102;&#32467;&#21512;&#20102;&#20256;&#32479;&#31070;&#32463;&#32593;&#32476;&#21644;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#28857;&#65292;&#26377;&#21161;&#20110;&#25913;&#36827;&#27169;&#22411;&#30340;&#27491;&#21017;&#21270;&#22120;&#21644;&#39118;&#38505;&#36793;&#30028;&#31561;&#26041;&#38754;&#12290;</title><link>http://arxiv.org/abs/2302.02420</link><description>&lt;p&gt;
&#30452;&#25509;&#19981;&#30830;&#23450;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Direct Uncertainty Quantification. (arXiv:2302.02420v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02420
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#30452;&#25509;&#19981;&#30830;&#23450;&#37327;&#21270;&#65288;DirectUQ&#65289;&#26041;&#27861;&#65292;&#23427;&#33021;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#30452;&#25509;&#36755;&#20986;&#22343;&#20540;&#21644;&#26041;&#24046;&#65292;&#21516;&#26102;&#32467;&#21512;&#20102;&#20256;&#32479;&#31070;&#32463;&#32593;&#32476;&#21644;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#28857;&#65292;&#26377;&#21161;&#20110;&#25913;&#36827;&#27169;&#22411;&#30340;&#27491;&#21017;&#21270;&#22120;&#21644;&#39118;&#38505;&#36793;&#30028;&#31561;&#26041;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#31070;&#32463;&#32593;&#32476;&#26131;&#20110;&#35757;&#32451;&#65292;&#20294;&#20250;&#20135;&#29983;&#36807;&#20110;&#33258;&#20449;&#30340;&#39044;&#27979;&#65307;&#32780;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#25552;&#20379;&#20102;&#33391;&#22909;&#30340;&#19981;&#30830;&#23450;&#37327;&#21270;&#65292;&#20294;&#20248;&#21270;&#23427;&#20204;&#38656;&#35201;&#32791;&#36153;&#26102;&#38388;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#8212;&#8212;&#8220;&#30452;&#25509;&#19981;&#30830;&#23450;&#37327;&#21270;&#8221;&#65288;DirectUQ&#65289;&#65292;&#23427;&#32467;&#21512;&#20102;&#23427;&#20204;&#30340;&#20248;&#28857;&#65292;&#20854;&#20013;&#31070;&#32463;&#32593;&#32476;&#30452;&#25509;&#36755;&#20986;&#26368;&#21518;&#19968;&#23618;&#30340;&#22343;&#20540;&#21644;&#26041;&#24046;&#12290;DirectUQ&#21487;&#20197;&#23548;&#20986;&#20026;&#19968;&#20010;&#26367;&#20195;&#30340;&#21464;&#20998;&#19979;&#30028;&#65292;&#22240;&#27492;&#20174;&#33853;&#21333;&#21464;&#20998;&#25512;&#29702;&#20013;&#33719;&#30410;&#65292;&#25552;&#20379;&#20102;&#25913;&#36827;&#30340;&#27491;&#21017;&#21270;&#22120;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#20687;&#38750;&#27010;&#29575;&#27169;&#22411;&#19968;&#26679;&#65292;DirectUQ&#20855;&#26377;&#31616;&#21333;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;&#29992;Rademacher&#22797;&#26434;&#24615;&#20026;&#27169;&#22411;&#25552;&#20379;&#39118;&#38505;&#36793;&#30028;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;DirectUQ&#21644;DirectUQ&#38598;&#25104;&#25552;&#20379;&#20102;&#26102;&#38388;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#38754;&#30340;&#33391;&#22909;&#24179;&#34913;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#20998;&#24067;&#20043;&#22806;&#30340;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Traditional neural networks are simple to train but they produce overconfident predictions, while Bayesian neural networks provide good uncertainty quantification but optimizing them is time consuming. This paper introduces a new approach, direct uncertainty quantification (DirectUQ), that combines their advantages where the neural network directly outputs the mean and variance of the last layer. DirectUQ can be derived as an alternative variational lower bound, and hence benefits from collapsed variational inference that provides improved regularizers. On the other hand, like non-probabilistic models, DirectUQ enjoys simple training and one can use Rademacher complexity to provide risk bounds for the model. Experiments show that DirectUQ and ensembles of DirectUQ provide a good tradeoff in terms of run time and uncertainty quantification, especially for out of distribution data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;GAMI-Tree&#65292;&#20351;&#29992;&#22522;&#20110;&#27169;&#22411;&#30340;&#26641;&#20197;&#21450;&#26032;&#30340;&#20132;&#20114;&#36807;&#28388;&#26041;&#27861;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#25311;&#21512;&#24213;&#23618;&#20132;&#20114;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#21644;&#26356;&#39640;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2207.06950</link><description>&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;&#27169;&#22411;&#30340;&#26641;&#21644;&#25552;&#21319;&#26041;&#27861;&#25311;&#21512;&#20302;&#38454;&#20989;&#25968;ANOVA&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Using Model-Based Trees with Boosting to Fit Low-Order Functional ANOVA Models. (arXiv:2207.06950v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.06950
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;GAMI-Tree&#65292;&#20351;&#29992;&#22522;&#20110;&#27169;&#22411;&#30340;&#26641;&#20197;&#21450;&#26032;&#30340;&#20132;&#20114;&#36807;&#28388;&#26041;&#27861;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#25311;&#21512;&#24213;&#23618;&#20132;&#20114;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#21644;&#26356;&#39640;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#38454;&#20989;&#25968;ANOVA&#27169;&#22411;&#24050;&#32463;&#34987;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#37325;&#26032;&#21457;&#29616;&#65292;&#24182;&#31216;&#20043;&#20026;&#20869;&#22312;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;GAMI-Tree&#65292;&#31867;&#20284;&#20110;EBM&#65292;&#20294;&#20855;&#26377;&#19968;&#20123;&#36235;&#21521;&#26356;&#22909;&#24615;&#33021;&#30340;&#29305;&#24615;&#12290;&#25105;&#20204;&#37319;&#29992;&#27169;&#22411;&#20026;&#22522;&#30784;&#30340;&#26641;&#65292;&#24182;&#34701;&#20837;&#19968;&#31181;&#26032;&#30340;&#20132;&#20114;&#36807;&#28388;&#26041;&#27861;&#65292;&#25552;&#39640;&#20102;&#23545;&#24213;&#23618;&#20132;&#20114;&#30340;&#25429;&#25417;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#36845;&#20195;&#35757;&#32451;&#26041;&#27861;&#25910;&#25947;&#20110;&#20855;&#26377;&#26356;&#22909;&#39044;&#27979;&#24615;&#33021;&#30340;&#27169;&#22411;&#65292;&#24182;&#30830;&#20445;&#30456;&#20114;&#20316;&#29992;&#22312;&#20998;&#23618;&#24847;&#20041;&#19978;&#27491;&#20132;&#20110;&#20027;&#25928;&#24212;&#12290;&#35813;&#31639;&#27861;&#19981;&#38656;&#35201;&#24191;&#27867;&#30340;&#35843;&#25972;&#65292;&#24182;&#19988;&#23454;&#29616;&#24555;&#36895;&#39640;&#25928;&#12290;&#25105;&#20204;&#20351;&#29992;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Low-order functional ANOVA (fANOVA) models have been rediscovered in the machine learning (ML) community under the guise of inherently interpretable machine learning. Explainable Boosting Machines or EBM (Lou et al. 2013) and GAMI-Net (Yang et al. 2021) are two recently proposed ML algorithms for fitting functional main effects and second-order interactions. We propose a new algorithm, called GAMI-Tree, that is similar to EBM, but has a number of features that lead to better performance. It uses model-based trees as base learners and incorporates a new interaction filtering method that is better at capturing the underlying interactions. In addition, our iterative training method converges to a model with better predictive performance, and the embedded purification ensures that interactions are hierarchically orthogonal to main effects. The algorithm does not need extensive tuning, and our implementation is fast and efficient. We use simulated and real datasets to compare the performanc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20004;&#27493;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#31216;&#20026;&#28145;&#24230;&#29305;&#24449;&#31579;&#36873;&#65288;DeepFS&#65289;&#65292;&#21487;&#20197;&#20811;&#26381;&#39640;&#32500;&#12289;&#20302;&#26679;&#26412;&#25968;&#25454;&#19978;&#30340;&#22256;&#38590;&#21644;&#25361;&#25112;&#65292;&#24182;&#23545;&#36229;&#39640;&#32500;&#12289;&#20302;&#26679;&#26412;&#25968;&#25454;&#36827;&#34892;&#39640;&#31934;&#24230;&#30340;&#29305;&#24449;&#31579;&#36873;&#12290;</title><link>http://arxiv.org/abs/2204.01682</link><description>&lt;p&gt;
&#28145;&#24230;&#29305;&#24449;&#31579;&#36873;&#65306;&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#36229;&#39640;&#32500;&#25968;&#25454;&#30340;&#29305;&#24449;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Deep Feature Screening: Feature Selection for Ultra High-Dimensional Data via Deep Neural Networks. (arXiv:2204.01682v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.01682
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20004;&#27493;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#31216;&#20026;&#28145;&#24230;&#29305;&#24449;&#31579;&#36873;&#65288;DeepFS&#65289;&#65292;&#21487;&#20197;&#20811;&#26381;&#39640;&#32500;&#12289;&#20302;&#26679;&#26412;&#25968;&#25454;&#19978;&#30340;&#22256;&#38590;&#21644;&#25361;&#25112;&#65292;&#24182;&#23545;&#36229;&#39640;&#32500;&#12289;&#20302;&#26679;&#26412;&#25968;&#25454;&#36827;&#34892;&#39640;&#31934;&#24230;&#30340;&#29305;&#24449;&#31579;&#36873;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a novel two-step nonparametric approach called Deep Feature Screening (DeepFS) that can overcome the challenges of high-dimensional, low-sample-size data and identify significant features with high precision for ultra high-dimensional, low-sample-size data.
&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#32479;&#35745;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#22312;&#39640;&#32500;&#12289;&#20302;&#26679;&#26412;&#25968;&#25454;&#19978;&#30340;&#24212;&#29992;&#32463;&#24120;&#36935;&#21040;&#22256;&#38590;&#21644;&#25361;&#25112;&#65292;&#22914;&#36807;&#25311;&#21512;&#12289;&#32500;&#25968;&#28798;&#38590;&#12289;&#35745;&#31639;&#19981;&#21487;&#34892;&#21644;&#24378;&#27169;&#22411;&#20551;&#35774;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20004;&#27493;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#31216;&#20026;&#28145;&#24230;&#29305;&#24449;&#31579;&#36873;&#65288;DeepFS&#65289;&#65292;&#21487;&#20197;&#20811;&#26381;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#23545;&#36229;&#39640;&#32500;&#12289;&#20302;&#26679;&#26412;&#25968;&#25454;&#36827;&#34892;&#39640;&#31934;&#24230;&#30340;&#29305;&#24449;&#31579;&#36873;&#12290;&#35813;&#26041;&#27861;&#39318;&#20808;&#25552;&#21462;&#36755;&#20837;&#25968;&#25454;&#30340;&#20302;&#32500;&#34920;&#31034;&#65292;&#28982;&#21518;&#24212;&#29992;&#22522;&#20110;Deb&#21644;Sen&#65288;2021&#65289;&#26368;&#36817;&#24320;&#21457;&#30340;&#22810;&#20803;&#31209;&#36317;&#30456;&#20851;&#24615;&#30340;&#29305;&#24449;&#31579;&#36873;&#12290;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#29305;&#24449;&#31579;&#36873;&#30340;&#20248;&#28857;&#65292;&#38500;&#20102;&#22788;&#29702;&#20855;&#26377;&#23569;&#37327;&#26679;&#26412;&#30340;&#36229;&#39640;&#32500;&#25968;&#25454;&#30340;&#33021;&#21147;&#22806;&#65292;&#36824;&#20855;&#26377;&#20197;&#19979;&#21560;&#24341;&#20154;&#30340;&#29305;&#28857;&#65306;&#65288;1&#65289;&#23427;&#26159;&#27169;&#22411;&#33258;&#30001;&#21644;&#20998;&#24067;&#33258;&#30001;&#30340;&#65307;&#65288;2&#65289;&#23427;&#21487;&#20197;
&lt;/p&gt;
&lt;p&gt;
The applications of traditional statistical feature selection methods to high-dimension, low sample-size data often struggle and encounter challenging problems, such as overfitting, curse of dimensionality, computational infeasibility, and strong model assumption. In this paper, we propose a novel two-step nonparametric approach called Deep Feature Screening (DeepFS) that can overcome these problems and identify significant features with high precision for ultra high-dimensional, low-sample-size data. This approach first extracts a low-dimensional representation of input data and then applies feature screening based on multivariate rank distance correlation recently developed by Deb and Sen (2021). This approach combines the strengths of both deep neural networks and feature screening, and thereby has the following appealing features in addition to its ability of handling ultra high-dimensional data with small number of samples: (1) it is model free and distribution free; (2) it can be
&lt;/p&gt;</description></item></channel></rss>