<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20174;&#22810;&#20219;&#21153;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#20013;&#24674;&#22797;&#32447;&#24615;&#25805;&#20316;&#31526;&#30340;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#29616;&#26377;&#30340;&#21508;&#21521;&#21516;&#24615;&#26080;&#20851;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#20250;&#23545;&#34920;&#31034;&#26356;&#26032;&#36896;&#25104;&#20559;&#24046;&#65292;&#38480;&#21046;&#20102;&#34920;&#31034;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#20026;&#27492;&#65292;&#24341;&#20837;&#20102;&#21435;&#20559;&#24046;&#21644;&#29305;&#24449;&#30333;&#21270;&#30340;&#36866;&#24212;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.04428</link><description>&lt;p&gt;
&#20174;&#22810;&#20219;&#21153;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#20013;&#20803;&#23398;&#20064;&#25805;&#20316;&#31526;&#21040;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
Meta-Learning Operators to Optimality from Multi-Task Non-IID Data. (arXiv:2308.04428v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04428
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20174;&#22810;&#20219;&#21153;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#20013;&#24674;&#22797;&#32447;&#24615;&#25805;&#20316;&#31526;&#30340;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#29616;&#26377;&#30340;&#21508;&#21521;&#21516;&#24615;&#26080;&#20851;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#20250;&#23545;&#34920;&#31034;&#26356;&#26032;&#36896;&#25104;&#20559;&#24046;&#65292;&#38480;&#21046;&#20102;&#34920;&#31034;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#20026;&#27492;&#65292;&#24341;&#20837;&#20102;&#21435;&#20559;&#24046;&#21644;&#29305;&#24449;&#30333;&#21270;&#30340;&#36866;&#24212;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#36817;&#21462;&#24471;&#36827;&#23637;&#30340;&#19968;&#20010;&#24378;&#22823;&#27010;&#24565;&#26159;&#20174;&#24322;&#26500;&#26469;&#28304;&#25110;&#20219;&#21153;&#30340;&#25968;&#25454;&#20013;&#25552;&#21462;&#20849;&#21516;&#29305;&#24449;&#12290;&#30452;&#35266;&#22320;&#35828;&#65292;&#23558;&#25152;&#26377;&#25968;&#25454;&#29992;&#20110;&#23398;&#20064;&#20849;&#21516;&#30340;&#34920;&#31034;&#20989;&#25968;&#65292;&#26082;&#26377;&#21161;&#20110;&#35745;&#31639;&#25928;&#29575;&#65292;&#21448;&#26377;&#21161;&#20110;&#32479;&#35745;&#27867;&#21270;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#20943;&#23569;&#35201;&#22312;&#32473;&#23450;&#20219;&#21153;&#19978;&#36827;&#34892;&#24494;&#35843;&#30340;&#21442;&#25968;&#25968;&#37327;&#12290;&#20026;&#20102;&#22312;&#29702;&#35770;&#19978;&#20570;&#20986;&#36825;&#20123;&#20248;&#28857;&#30340;&#26681;&#28304;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20174;&#22122;&#22768;&#21521;&#37327;&#27979;&#37327;$y = Mx + w$&#20013;&#22238;&#22797;&#32447;&#24615;&#25805;&#20316;&#31526;$M$&#30340;&#19968;&#33324;&#27169;&#22411;&#12290;&#20854;&#20013;&#65292;&#21327;&#21464;&#37327;$x$&#26082;&#21487;&#20197;&#26159;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65292;&#20063;&#21487;&#20197;&#26159;&#38750;&#21508;&#21521;&#21516;&#24615;&#30340;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#29616;&#26377;&#30340;&#21508;&#21521;&#21516;&#24615;&#26080;&#20851;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#20250;&#23545;&#34920;&#31034;&#26356;&#26032;&#36896;&#25104;&#20559;&#24046;&#65292;&#36825;&#23548;&#33268;&#22122;&#22768;&#39033;&#30340;&#32553;&#25918;&#19981;&#20877;&#26377;&#21033;&#20110;&#28304;&#20219;&#21153;&#25968;&#37327;&#12290;&#36825;&#21453;&#36807;&#26469;&#20250;&#23548;&#33268;&#34920;&#31034;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#21463;&#21040;&#21333;&#20219;&#21153;&#25968;&#25454;&#35268;&#27169;&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#31216;&#20026;&#21435;&#20559;&#24046;&#21644;&#29305;&#24449;&#30333;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
A powerful concept behind much of the recent progress in machine learning is the extraction of common features across data from heterogeneous sources or tasks. Intuitively, using all of one's data to learn a common representation function benefits both computational effort and statistical generalization by leaving a smaller number of parameters to fine-tune on a given task. Toward theoretically grounding these merits, we propose a general setting of recovering linear operators $M$ from noisy vector measurements $y = Mx + w$, where the covariates $x$ may be both non-i.i.d. and non-isotropic. We demonstrate that existing isotropy-agnostic meta-learning approaches incur biases on the representation update, which causes the scaling of the noise terms to lose favorable dependence on the number of source tasks. This in turn can cause the sample complexity of representation learning to be bottlenecked by the single-task data size. We introduce an adaptation, $\texttt{De-bias &amp; Feature-Whiten}
&lt;/p&gt;</description></item><item><title>SLEM&#26159;&#19968;&#31181;&#36335;&#24452;&#24314;&#27169;&#25216;&#26415;&#65292;&#36890;&#36807;&#38598;&#25104;&#26426;&#22120;&#23398;&#20064;&#36229;&#32423;&#23398;&#20064;&#32773;&#65292;&#23454;&#29616;&#20102;&#19968;&#33268;&#19988;&#26080;&#20559;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#65292;&#24182;&#22312;&#22788;&#29702;&#38750;&#32447;&#24615;&#20851;&#31995;&#26102;&#36229;&#36807;&#20102;&#20256;&#32479;&#30340;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2308.04365</link><description>&lt;p&gt;
SLEM&#65306;&#26426;&#22120;&#23398;&#20064;&#29992;&#20110;&#36335;&#24452;&#24314;&#27169;&#21644;&#22240;&#26524;&#25512;&#26029;&#30340;&#36229;&#32423;&#23398;&#20064;&#32773;&#26041;&#31243;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling. (arXiv:2308.04365v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04365
&lt;/p&gt;
&lt;p&gt;
SLEM&#26159;&#19968;&#31181;&#36335;&#24452;&#24314;&#27169;&#25216;&#26415;&#65292;&#36890;&#36807;&#38598;&#25104;&#26426;&#22120;&#23398;&#20064;&#36229;&#32423;&#23398;&#20064;&#32773;&#65292;&#23454;&#29616;&#20102;&#19968;&#33268;&#19988;&#26080;&#20559;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#65292;&#24182;&#22312;&#22788;&#29702;&#38750;&#32447;&#24615;&#20851;&#31995;&#26102;&#36229;&#36807;&#20102;&#20256;&#32479;&#30340;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#25512;&#26029;&#26159;&#31185;&#23398;&#30340;&#20851;&#38190;&#30446;&#26631;&#65292;&#20351;&#30740;&#31350;&#20154;&#21592;&#33021;&#22815;&#36890;&#36807;&#35266;&#23519;&#25968;&#25454;&#24471;&#20986;&#20851;&#20110;&#23545;&#20551;&#23450;&#24178;&#39044;&#30340;&#39044;&#27979;&#30340;&#26377;&#24847;&#20041;&#30340;&#32467;&#35770;&#12290;&#36335;&#24452;&#27169;&#22411;&#12289;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;(SEMs)&#20197;&#21450;&#26356;&#19968;&#33324;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;(DAGs)&#33021;&#22815;&#26126;&#30830;&#22320;&#25351;&#23450;&#20851;&#20110;&#29616;&#35937;&#32972;&#21518;&#30340;&#22240;&#26524;&#32467;&#26500;&#30340;&#20551;&#35774;&#12290;&#19982;DAGs&#19981;&#21516;&#65292;SEMs&#20551;&#35774;&#32447;&#24615;&#20851;&#31995;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#20989;&#25968;&#38169;&#35823;&#35268;&#33539;&#65292;&#20174;&#32780;&#38459;&#30861;&#30740;&#31350;&#20154;&#21592;&#36827;&#34892;&#21487;&#38752;&#30340;&#25928;&#26524;&#22823;&#23567;&#20272;&#35745;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36229;&#32423;&#23398;&#20064;&#32773;&#26041;&#31243;&#27169;&#22411;&#65288;SLEM&#65289;&#65292;&#19968;&#31181;&#38598;&#25104;&#20102;&#26426;&#22120;&#23398;&#20064;&#36229;&#32423;&#23398;&#20064;&#32773;&#38598;&#25104;&#30340;&#36335;&#24452;&#24314;&#27169;&#25216;&#26415;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;SLEM&#33021;&#22815;&#25552;&#20379;&#19968;&#33268;&#19988;&#26080;&#20559;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#65292;&#22312;&#19982;SEMs&#36827;&#34892;&#32447;&#24615;&#27169;&#22411;&#27604;&#36739;&#26102;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#65292;&#24182;&#19988;&#22312;&#22788;&#29702;&#38750;&#32447;&#24615;&#20851;&#31995;&#26102;&#20248;&#20110;SEMs&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal inference is a crucial goal of science, enabling researchers to arrive at meaningful conclusions regarding the predictions of hypothetical interventions using observational data. Path models, Structural Equation Models (SEMs), and, more generally, Directed Acyclic Graphs (DAGs), provide a means to unambiguously specify assumptions regarding the causal structure underlying a phenomenon. Unlike DAGs, which make very few assumptions about the functional and parametric form, SEM assumes linearity. This can result in functional misspecification which prevents researchers from undertaking reliable effect size estimation. In contrast, we propose Super Learner Equation Modeling, a path modeling technique integrating machine learning Super Learner ensembles. We empirically demonstrate its ability to provide consistent and unbiased estimates of causal effects, its competitive performance for linear models when compared with SEM, and highlight its superiority over SEM when dealing with non
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21512;&#20316;&#36172;&#21338;&#26426;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#26368;&#20339;&#30340;&#20010;&#20307;&#36951;&#25022;&#21644;&#24658;&#23450;&#30340;&#36890;&#20449;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2308.04314</link><description>&lt;p&gt;
&#21512;&#20316;&#24335;&#22810;&#26234;&#33021;&#20307;&#36172;&#21338;&#26426;&#65306;&#20855;&#26377;&#26368;&#20339;&#20010;&#20307;&#36951;&#25022;&#21644;&#24658;&#23450;&#36890;&#20449;&#25104;&#26412;&#30340;&#20998;&#24067;&#24335;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Cooperative Multi-agent Bandits: Distributed Algorithms with Optimal Individual Regret and Constant Communication Costs. (arXiv:2308.04314v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04314
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21512;&#20316;&#36172;&#21338;&#26426;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#26368;&#20339;&#30340;&#20010;&#20307;&#36951;&#25022;&#21644;&#24658;&#23450;&#30340;&#36890;&#20449;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#23545;&#21512;&#20316;&#24335;&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#36172;&#21338;&#26426;&#36827;&#34892;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#20854;&#20013;&#19968;&#32452;&#20998;&#24067;&#24335;&#26234;&#33021;&#20307;&#21512;&#20316;&#29609;&#30456;&#21516;&#30340;&#22810;&#33218;&#36172;&#21338;&#28216;&#25103;&#12290;&#30446;&#26631;&#26159;&#24320;&#21457;&#20855;&#26377;&#26368;&#20339;&#32676;&#20307;&#21644;&#20010;&#20307;&#36951;&#25022;&#20197;&#21450;&#26234;&#33021;&#20307;&#20043;&#38388;&#36890;&#20449;&#25104;&#26412;&#20302;&#30340;&#36172;&#21338;&#26426;&#31639;&#27861;&#12290;&#22312;&#21069;&#26399;&#24037;&#20316;&#20013;&#65292;&#20351;&#29992;&#20102;&#20004;&#31181;&#33539;&#24335;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65306;&#39046;&#23548;&#32773;-&#36319;&#38543;&#32773;&#21644;&#23436;&#20840;&#20998;&#24067;&#24335;&#31639;&#27861;&#12290;&#22312;&#36825;&#20004;&#31181;&#33539;&#24335;&#20013;&#65292;&#20197;&#21069;&#30340;&#31639;&#27861;&#37117;&#33021;&#36798;&#21040;&#26368;&#20339;&#32676;&#20307;&#36951;&#25022;&#12290;&#39046;&#23548;&#32773;-&#36319;&#38543;&#32773;&#31639;&#27861;&#23454;&#29616;&#20102;&#24658;&#23450;&#30340;&#36890;&#20449;&#25104;&#26412;&#65292;&#20294;&#26410;&#33021;&#36798;&#21040;&#26368;&#20339;&#20010;&#20307;&#36951;&#25022;&#12290;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;&#23436;&#20840;&#20998;&#24067;&#24335;&#31639;&#27861;&#23454;&#29616;&#20102;&#26368;&#20339;&#20010;&#20307;&#36951;&#25022;&#65292;&#20294;&#26410;&#33021;&#23454;&#29616;&#24658;&#23450;&#30340;&#36890;&#20449;&#25104;&#26412;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#36890;&#20449;&#31574;&#30053;&#65292;&#24182;&#23558;&#20854;&#25972;&#21512;&#21040;&#21512;&#20316;&#36172;&#21338;&#26426;&#30340;&#23398;&#20064;&#31639;&#27861;&#20013;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#21516;&#26102;&#23454;&#29616;&#20102;&#20004;&#31181;&#33539;&#24335;&#30340;&#26368;&#20248;&#20010;&#20307;&#36951;&#25022;&#21644;&#24658;&#23450;&#36890;&#20449;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, there has been extensive study of cooperative multi-agent multi-armed bandits where a set of distributed agents cooperatively play the same multi-armed bandit game. The goal is to develop bandit algorithms with the optimal group and individual regrets and low communication between agents. The prior work tackled this problem using two paradigms: leader-follower and fully distributed algorithms. Prior algorithms in both paradigms achieve the optimal group regret. The leader-follower algorithms achieve constant communication costs but fail to achieve optimal individual regrets. The state-of-the-art fully distributed algorithms achieve optimal individual regrets but fail to achieve constant communication costs. This paper presents a simple yet effective communication policy and integrates it into a learning algorithm for cooperative bandits. Our algorithm achieves the best of both paradigms: optimal individual regret and constant communication costs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;KNN-&#22522;&#20110;LASSO&#30340;&#26041;&#27861;&#65292;&#22312;&#20581;&#24247;&#32467;&#26524;&#30740;&#31350;&#20013;&#24314;&#31435;&#20102;&#21160;&#24577;&#27169;&#22411;&#65292;&#33021;&#22815;&#20934;&#30830;&#25429;&#25417;&#20581;&#24247;&#32467;&#26524;&#21644;&#21361;&#38505;&#22240;&#32032;&#20043;&#38388;&#30340;&#24180;&#40836;&#30456;&#20851;&#20851;&#32852;&#12290;</title><link>http://arxiv.org/abs/2308.04212</link><description>&lt;p&gt;
&#22522;&#20110;KNN-&#22522;&#20110;LASSO&#30340;&#21306;&#22495;&#20998;&#20301;&#25968;&#21464;&#31995;&#25968;&#27169;&#22411;&#22312;&#20581;&#24247;&#32467;&#26524;&#30740;&#31350;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Varying-coefficients for regional quantile via KNN-based LASSO with applications to health outcome study. (arXiv:2308.04212v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04212
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;KNN-&#22522;&#20110;LASSO&#30340;&#26041;&#27861;&#65292;&#22312;&#20581;&#24247;&#32467;&#26524;&#30740;&#31350;&#20013;&#24314;&#31435;&#20102;&#21160;&#24577;&#27169;&#22411;&#65292;&#33021;&#22815;&#20934;&#30830;&#25429;&#25417;&#20581;&#24247;&#32467;&#26524;&#21644;&#21361;&#38505;&#22240;&#32032;&#20043;&#38388;&#30340;&#24180;&#40836;&#30456;&#20851;&#20851;&#32852;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20581;&#24247;&#32467;&#26524;&#65292;&#22914;&#36523;&#20307;&#36136;&#37327;&#25351;&#25968;&#21644;&#32966;&#22266;&#37255;&#27700;&#24179;&#65292;&#24050;&#30693;&#20381;&#36182;&#20110;&#24180;&#40836;&#65292;&#24182;&#34920;&#29616;&#20986;&#19982;&#20854;&#30456;&#20851;&#21361;&#38505;&#22240;&#32032;&#30340;&#21464;&#21270;&#24433;&#21709;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;K&#26368;&#36817;&#37051;(Lasso)&#22522;&#20110;&#21306;&#22495;&#20998;&#20301;&#25968;&#22238;&#24402;&#26469;&#21160;&#24577;&#24314;&#27169;&#20581;&#24247;&#32467;&#26524;&#21644;&#21361;&#38505;&#22240;&#32032;&#20043;&#38388;&#30340;&#20851;&#32852;&#65292;&#20197;&#25429;&#25417;&#24180;&#40836;&#30340;&#26102;&#21464;&#25928;&#24212;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20855;&#26377;&#24378;&#22823;&#30340;&#29702;&#35770;&#24615;&#36136;&#65292;&#21253;&#25324;&#32039;&#23494;&#30340;&#20272;&#35745;&#35823;&#24046;&#30028;&#38480;&#21644;&#22312;&#26576;&#20123;&#27491;&#21017;&#26465;&#20214;&#19979;&#26816;&#27979;&#31934;&#30830;&#30340;&#32858;&#31867;&#27169;&#24335;&#30340;&#33021;&#21147;&#12290;&#20026;&#20102;&#39640;&#25928;&#35299;&#20915;&#25152;&#24471;&#21040;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#20132;&#26367;&#26041;&#21521;&#20056;&#27861;&#22120;(ADMM)&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#22815;&#25429;&#25417;&#20581;&#24247;&#32467;&#26524;&#21644;&#20854;&#39118;&#38505;&#22240;&#32032;&#20043;&#38388;&#22797;&#26434;&#30340;&#24180;&#40836;&#30456;&#20851;&#20851;&#32852;&#12290;
&lt;/p&gt;
&lt;p&gt;
Health outcomes, such as body mass index and cholesterol levels, are known to be dependent on age and exhibit varying effects with their associated risk factors. In this paper, we propose a novel framework for dynamic modeling of the associations between health outcomes and risk factors using varying-coefficients (VC) regional quantile regression via K-nearest neighbors (KNN) fused Lasso, which captures the time-varying effects of age. The proposed method has strong theoretical properties, including a tight estimation error bound and the ability to detect exact clustered patterns under certain regularity conditions. To efficiently solve the resulting optimization problem, we develop an alternating direction method of multipliers (ADMM) algorithm. Our empirical results demonstrate the efficacy of the proposed method in capturing the complex age-dependent associations between health outcomes and their risk factors.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#22810;&#20219;&#21153;Hebbian&#32593;&#32476;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#33021;&#22815;&#33258;&#28982;&#22320;&#23454;&#29616;&#24182;&#34892;&#23398;&#20064;&#65292;&#24182;&#22788;&#29702;&#21508;&#31181;&#27169;&#24335;&#30340;&#20449;&#21495;&#24133;&#24230;&#20998;&#24067;&#12290;&#36825;&#23545;&#20110;&#20154;&#24037;&#26234;&#33021;&#20013;&#23398;&#20064;&#22810;&#20010;&#27169;&#24335;&#30340;&#25361;&#25112;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2308.04106</link><description>&lt;p&gt;
&#24182;&#34892;&#23398;&#20064;&#30340;&#22810;&#20219;&#21153;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Parallel Learning by Multitasking Neural Networks. (arXiv:2308.04106v1 [cond-mat.dis-nn])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04106
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#22810;&#20219;&#21153;Hebbian&#32593;&#32476;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#33021;&#22815;&#33258;&#28982;&#22320;&#23454;&#29616;&#24182;&#34892;&#23398;&#20064;&#65292;&#24182;&#22788;&#29702;&#21508;&#31181;&#27169;&#24335;&#30340;&#20449;&#21495;&#24133;&#24230;&#20998;&#24067;&#12290;&#36825;&#23545;&#20110;&#20154;&#24037;&#26234;&#33021;&#20013;&#23398;&#20064;&#22810;&#20010;&#27169;&#24335;&#30340;&#25361;&#25112;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#30340;&#19968;&#20010;&#29616;&#20195;&#25361;&#25112;&#26159;&#21516;&#26102;&#23398;&#20064;&#22810;&#31181;&#27169;&#24335;&#65288;&#21363;&#24182;&#34892;&#23398;&#20064;&#65289;&#12290;&#26412;&#25991;&#20013;&#25105;&#20204;&#23637;&#31034;&#20102;&#22810;&#20219;&#21153;Hebbian&#32593;&#32476;&#65288;&#22312;&#31232;&#30095;&#25968;&#25454;&#38598;&#19978;&#24037;&#20316;&#30340;Hopfield&#27169;&#22411;&#21464;&#20307;&#65289;&#22914;&#20309;&#33258;&#28982;&#22320;&#25191;&#34892;&#36825;&#19968;&#22797;&#26434;&#20219;&#21153;&#12290;&#25105;&#20204;&#20851;&#27880;&#30340;&#26159;&#24182;&#34892;&#22788;&#29702;&#26377;&#38480;&#25968;&#37327;&#65288;&#19982;&#32593;&#32476;&#22823;&#23567;&#30340;&#23545;&#25968;&#22686;&#38271;&#30456;&#23545;&#24212;&#65289;&#27169;&#24335;&#30340;&#31995;&#32479;&#65292;&#31867;&#20284;&#20110;&#26631;&#20934;&#20851;&#32852;&#31070;&#32463;&#32593;&#32476;&#22312;&#27169;&#24335;&#35782;&#21035;&#20013;&#30340;&#20302;&#23384;&#20648;&#27700;&#24179;&#12290;&#23545;&#20110;&#27169;&#24335;&#30340;&#36731;&#24230;&#31232;&#37322;&#65292;&#32593;&#32476;&#20197;&#23618;&#27425;&#26041;&#24335;&#22788;&#29702;&#23427;&#20204;&#65292;&#26681;&#25454;&#20854;&#20449;&#24687;&#20869;&#23481;&#20197;&#24130;&#24459;&#20998;&#24067;&#20854;&#20449;&#21495;&#30340;&#24133;&#24230;&#65288;&#23618;&#27425;&#21046;&#24230;&#65289;&#65292;&#32780;&#23545;&#20110;&#24378;&#31232;&#37322;&#65292;&#25152;&#26377;&#19982;&#25152;&#26377;&#27169;&#24335;&#30456;&#20851;&#30340;&#20449;&#21495;&#22343;&#20855;&#26377;&#30456;&#21516;&#30340;&#24378;&#24230;&#65288;&#24182;&#34892;&#21046;&#24230;&#65289;&#12290;&#27492;&#22806;&#65292;&#20165;&#38480;&#20110;&#20302;&#23384;&#20648;&#35774;&#32622;&#65288;&#21363;&#36828;&#31163;&#33258;&#26059;&#29627;&#29827;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
A modern challenge of Artificial Intelligence is learning multiple patterns at once (i.e.parallel learning). While this can not be accomplished by standard Hebbian associative neural networks, in this paper we show how the Multitasking Hebbian Network (a variation on theme of the Hopfield model working on sparse data-sets) is naturally able to perform this complex task. We focus on systems processing in parallel a finite (up to logarithmic growth in the size of the network) amount of patterns, mirroring the low-storage level of standard associative neural networks at work with pattern recognition. For mild dilution in the patterns, the network handles them hierarchically, distributing the amplitudes of their signals as power-laws w.r.t. their information content (hierarchical regime), while, for strong dilution, all the signals pertaining to all the patterns are raised with the same strength (parallel regime). Further, confined to the low-storage setting (i.e., far from the spin glass 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;K-Means&#32858;&#31867;&#26041;&#27861;&#65292;&#21021;&#27493;&#30740;&#31350;&#20102;&#26032;&#35199;&#20848;&#20799;&#31461;&#31119;&#21033;&#31995;&#32479;&#30340;&#39044;&#27979;&#39118;&#38505;&#24314;&#27169;&#65292;&#21457;&#29616;&#20102;&#19968;&#20123;&#29305;&#24449;&#24182;&#20102;&#35299;&#20102;&#20854;&#23545;&#24403;&#21069;&#39118;&#38505;&#24314;&#27169;&#26694;&#26550;&#30340;&#28508;&#22312;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2308.04060</link><description>&lt;p&gt;
&#25913;&#36827;&#21033;&#29992;&#32858;&#31867;&#26041;&#27861;&#36827;&#34892;&#26032;&#35199;&#20848;&#20799;&#31461;&#31119;&#21033;&#31995;&#32479;&#30340;&#39044;&#27979;&#39118;&#38505;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Toward Improving Predictive Risk Modelling for New Zealand's Child Welfare System Using Clustering Methods. (arXiv:2308.04060v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04060
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;K-Means&#32858;&#31867;&#26041;&#27861;&#65292;&#21021;&#27493;&#30740;&#31350;&#20102;&#26032;&#35199;&#20848;&#20799;&#31461;&#31119;&#21033;&#31995;&#32479;&#30340;&#39044;&#27979;&#39118;&#38505;&#24314;&#27169;&#65292;&#21457;&#29616;&#20102;&#19968;&#20123;&#29305;&#24449;&#24182;&#20102;&#35299;&#20102;&#20854;&#23545;&#24403;&#21069;&#39118;&#38505;&#24314;&#27169;&#26694;&#26550;&#30340;&#28508;&#22312;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20020;&#24202;&#21028;&#26029;&#21644;&#39044;&#27979;&#39118;&#38505;&#27169;&#22411;&#30340;&#32467;&#21512;&#23545;&#31038;&#24037;&#22312;&#21010;&#20998;&#22788;&#20110;&#34384;&#24453;&#39118;&#38505;&#20013;&#30340;&#20799;&#31461;&#24182;&#20915;&#23450;&#20309;&#26102;&#37319;&#21462;&#24178;&#39044;&#25514;&#26045;&#33267;&#20851;&#37325;&#35201;&#12290;&#25919;&#24220;&#31119;&#21033;&#26426;&#26500;&#21033;&#29992;&#34892;&#25919;&#25968;&#25454;&#21644;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#24050;&#32463;&#24320;&#22987;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#39044;&#27979;&#39118;&#38505;&#24314;&#27169;&#24037;&#20316;&#12290;&#34429;&#28982;&#20197;&#24448;&#30340;&#30740;&#31350;&#24050;&#32463;&#35843;&#26597;&#20102;&#19982;&#20799;&#31461;&#34384;&#24453;&#26377;&#20851;&#30340;&#39118;&#38505;&#22240;&#32032;&#65292;&#20294;&#20173;&#23384;&#22312;&#24456;&#22810;&#31354;&#30333;&#65292;&#23578;&#19981;&#28165;&#26970;&#36825;&#20123;&#39118;&#38505;&#22240;&#32032;&#22914;&#20309;&#30456;&#20114;&#20316;&#29992;&#20197;&#21450;&#39044;&#27979;&#39118;&#38505;&#27169;&#22411;&#22312;&#20855;&#26377;&#19981;&#21516;&#29305;&#24449;&#30340;&#20799;&#31461;&#20013;&#26159;&#21542;&#34920;&#29616;&#19981;&#21516;&#12290;&#26412;&#25991;&#36890;&#36807;&#25972;&#21512;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;K-Means&#32858;&#31867;&#65292;&#21021;&#27493;&#21457;&#29616;&#20102;&#25105;&#20204;&#22312;&#30830;&#23450;&#36825;&#20123;&#29305;&#24449;&#21450;&#20854;&#23545;&#24403;&#21069;&#39118;&#38505;&#24314;&#27169;&#26694;&#26550;&#30340;&#28508;&#22312;&#24433;&#21709;&#30340;&#24037;&#20316;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#23545;&#26032;&#35199;&#20848;&#65288;NZ&#65289;&#34987;&#25253;&#21578;&#26377;&#25252;&#29702;&#21644;&#20445;&#25252;&#38382;&#39064;&#30340;&#20799;&#31461;&#30340;&#29616;&#23384;&#12289;&#23578;&#26410;&#30830;&#23450;&#30340;&#32858;&#31867;&#36827;&#34892;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
The combination of clinical judgement and predictive risk models crucially assist social workers to segregate children at risk of maltreatment and decide when authorities should intervene. Predictive risk modelling to address this matter has been initiated by several governmental welfare authorities worldwide involving administrative data and machine learning algorithms. While previous studies have investigated risk factors relating to child maltreatment, several gaps remain as to understanding how such risk factors interact and whether predictive risk models perform differently for children with different features. By integrating Principal Component Analysis and K-Means clustering, this paper presents initial findings of our work on the identification of such features as well as their potential effect on current risk modelling frameworks. This approach allows examining existent, unidentified yet, clusters of New Zealand (NZ) children reported with care and protection concerns, as well
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24418;&#29366;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#38477;&#20302;&#35774;&#35745;&#31354;&#38388;&#32500;&#24230;&#21644;&#24314;&#27169;&#25968;&#25454;&#30340;&#29983;&#25104;&#36807;&#31243;&#65292;&#23454;&#29616;&#20102;&#25552;&#39640;&#20840;&#23616;&#20248;&#21270;&#31639;&#27861;&#25928;&#29575;&#21644;&#29983;&#25104;&#26080;&#20960;&#20309;&#24322;&#24120;&#30340;&#39640;&#36136;&#37327;&#35774;&#35745;&#12290;</title><link>http://arxiv.org/abs/2308.04051</link><description>&lt;p&gt;
&#24418;&#29366;&#20248;&#21270;&#20013;&#30340;&#24322;&#24120;&#26816;&#27979;&#21644;&#35774;&#35745;&#31354;&#38388;&#32500;&#24230;&#38477;&#20302;&#30340;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Generative Models for Anomaly Detection and Design-Space Dimensionality Reduction in Shape Optimization. (arXiv:2308.04051v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04051
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24418;&#29366;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#38477;&#20302;&#35774;&#35745;&#31354;&#38388;&#32500;&#24230;&#21644;&#24314;&#27169;&#25968;&#25454;&#30340;&#29983;&#25104;&#36807;&#31243;&#65292;&#23454;&#29616;&#20102;&#25552;&#39640;&#20840;&#23616;&#20248;&#21270;&#31639;&#27861;&#25928;&#29575;&#21644;&#29983;&#25104;&#26080;&#20960;&#20309;&#24322;&#24120;&#30340;&#39640;&#36136;&#37327;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30340;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24418;&#29366;&#20248;&#21270;&#26041;&#27861;&#65292;&#20854;&#20004;&#20010;&#30446;&#26631;&#26159;&#25552;&#39640;&#20840;&#23616;&#20248;&#21270;&#31639;&#27861;&#30340;&#25928;&#29575;&#65292;&#21516;&#26102;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#29983;&#25104;&#27809;&#26377;&#20960;&#20309;&#24322;&#24120;&#30340;&#39640;&#36136;&#37327;&#35774;&#35745;&#12290;&#36890;&#36807;&#20943;&#23569;&#23450;&#20041;&#26032;&#30340;&#20943;&#23569;&#23376;&#31354;&#38388;&#30340;&#21407;&#22987;&#35774;&#35745;&#21464;&#37327;&#30340;&#25968;&#37327;&#65292;&#24182;&#20351;&#29992;&#27010;&#29575;&#32447;&#24615;&#28508;&#21464;&#37327;&#27169;&#22411;&#26469;&#24314;&#27169;&#25968;&#25454;&#30340;&#24213;&#23618;&#29983;&#25104;&#36807;&#31243;&#65292;&#22914;&#22240;&#23376;&#20998;&#26512;&#21644;&#27010;&#29575;&#20027;&#25104;&#20998;&#20998;&#26512;&#65292;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#24418;&#29366;&#20462;&#25913;&#26041;&#27861;&#26159;&#32447;&#24615;&#30340;&#19988;&#35774;&#35745;&#21464;&#37327;&#22312;&#22343;&#21248;&#38543;&#26426;&#37319;&#26679;&#26102;&#65292;&#25968;&#25454;&#36817;&#20284;&#26381;&#20174;&#39640;&#26031;&#20998;&#24067;&#65292;&#36825;&#26159;&#30001;&#20110;&#30452;&#25509;&#24212;&#29992;&#20102;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;&#21033;&#29992;&#39532;&#27663;&#36317;&#31163;&#26469;&#34913;&#37327;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#19988;&#35770;&#25991;&#35777;&#26126;&#24322;&#24120;&#35774;&#35745;&#24448;&#24448;&#20855;&#26377;&#36739;&#39640;&#30340;&#35813;&#24230;&#37327;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Our work presents a novel approach to shape optimization, that has the twofold objective to improve the efficiency of global optimization algorithms while promoting the generation of high-quality designs during the optimization process free of geometrical anomalies. This is accomplished by reducing the number of the original design variables defining a new reduced subspace where the geometrical variance is maximized and modeling the underlying generative process of the data via probabilistic linear latent variable models such as Factor Analysis and Probabilistic Principal Component Analysis. We show that the data follows approximately a Gaussian distribution when the shape modification method is linear and the design variables are sampled uniformly at random, due to the direct application of the central limit theorem. The model uncertainty is measured in terms of Mahalanobis distance, and the paper demonstrates that anomalous designs tend to exhibit a high value of this metric. This en
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DCMAP&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#23545;&#20855;&#26377;&#20381;&#36182;&#25104;&#26412;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#36827;&#34892;&#26368;&#20248;&#20998;&#21306;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#20248;&#21270;&#22522;&#20110;DAG&#21644;&#38598;&#32676;&#26144;&#23556;&#30340;&#25104;&#26412;&#20989;&#25968;&#26469;&#23547;&#25214;&#25152;&#26377;&#26368;&#20248;&#38598;&#32676;&#65292;&#24182;&#22312;&#36884;&#20013;&#36820;&#22238;&#25509;&#36817;&#26368;&#20248;&#35299;&#12290;&#23454;&#39564;&#35777;&#26126;&#22312;&#22797;&#26434;&#31995;&#32479;&#30340;DBN&#27169;&#22411;&#20013;&#65292;&#35813;&#31639;&#27861;&#20855;&#26377;&#26102;&#38388;&#25928;&#29575;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.03970</link><description>&lt;p&gt;
&#23545;&#20855;&#26377;&#20381;&#36182;&#25104;&#26412;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#36827;&#34892;&#26368;&#20248;&#20998;&#21306;
&lt;/p&gt;
&lt;p&gt;
Optimal partitioning of directed acyclic graphs with dependent costs between clusters. (arXiv:2308.03970v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03970
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DCMAP&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#23545;&#20855;&#26377;&#20381;&#36182;&#25104;&#26412;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#36827;&#34892;&#26368;&#20248;&#20998;&#21306;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#20248;&#21270;&#22522;&#20110;DAG&#21644;&#38598;&#32676;&#26144;&#23556;&#30340;&#25104;&#26412;&#20989;&#25968;&#26469;&#23547;&#25214;&#25152;&#26377;&#26368;&#20248;&#38598;&#32676;&#65292;&#24182;&#22312;&#36884;&#20013;&#36820;&#22238;&#25509;&#36817;&#26368;&#20248;&#35299;&#12290;&#23454;&#39564;&#35777;&#26126;&#22312;&#22797;&#26434;&#31995;&#32479;&#30340;DBN&#27169;&#22411;&#20013;&#65292;&#35813;&#31639;&#27861;&#20855;&#26377;&#26102;&#38388;&#25928;&#29575;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#32479;&#35745;&#25512;&#26029;&#22330;&#26223;&#65292;&#21253;&#25324;&#36125;&#21494;&#26031;&#32593;&#32476;&#12289;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#21644;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#65292;&#21487;&#20197;&#36890;&#36807;&#23558;&#22522;&#30784;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#21010;&#20998;&#25104;&#38598;&#32676;&#26469;&#25903;&#25345;&#12290;&#28982;&#32780;&#65292;&#22312;&#32479;&#35745;&#25512;&#26029;&#20013;&#65292;&#26368;&#20248;&#21010;&#20998;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#35201;&#20248;&#21270;&#30340;&#25104;&#26412;&#21462;&#20915;&#20110;&#38598;&#32676;&#20869;&#30340;&#33410;&#28857;&#20197;&#21450;&#36890;&#36807;&#29238;&#33410;&#28857;&#21644;/&#25110;&#23376;&#33410;&#28857;&#36830;&#25509;&#30340;&#38598;&#32676;&#20043;&#38388;&#30340;&#26144;&#23556;&#65292;&#25105;&#20204;&#23558;&#20854;&#31216;&#20026;&#20381;&#36182;&#38598;&#32676;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DCMAP&#30340;&#26032;&#31639;&#27861;&#65292;&#29992;&#20110;&#20855;&#26377;&#20381;&#36182;&#38598;&#32676;&#30340;&#26368;&#20248;&#38598;&#32676;&#26144;&#23556;&#12290;&#22312;&#22522;&#20110;DAG&#21644;&#38598;&#32676;&#26144;&#23556;&#30340;&#20219;&#24847;&#23450;&#20041;&#30340;&#27491;&#25104;&#26412;&#20989;&#25968;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;DCMAP&#25910;&#25947;&#20110;&#25214;&#21040;&#25152;&#26377;&#26368;&#20248;&#38598;&#32676;&#65292;&#24182;&#22312;&#36884;&#20013;&#36820;&#22238;&#25509;&#36817;&#26368;&#20248;&#35299;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#31639;&#27861;&#23545;&#20351;&#29992;&#35745;&#31639;&#25104;&#26412;&#20989;&#25968;&#30340;&#19968;&#20010;&#28023;&#33609;&#22797;&#26434;&#31995;&#32479;&#30340;DBN&#27169;&#22411;&#20855;&#26377;&#26102;&#38388;&#25928;&#29575;&#24615;&#12290;&#23545;&#20110;&#19968;&#20010;25&#20010;&#21644;50&#20010;&#33410;&#28857;&#30340;DBN&#65292;&#25628;&#32034;&#31354;&#38388;&#22823;&#23567;&#20998;&#21035;&#20026;$9.91\times 10^9$&#21644;$1.5$
&lt;/p&gt;
&lt;p&gt;
Many statistical inference contexts, including Bayesian Networks (BNs), Markov processes and Hidden Markov Models (HMMS) could be supported by partitioning (i.e.~mapping) the underlying Directed Acyclic Graph (DAG) into clusters. However, optimal partitioning is challenging, especially in statistical inference as the cost to be optimised is dependent on both nodes within a cluster, and the mapping of clusters connected via parent and/or child nodes, which we call dependent clusters. We propose a novel algorithm called DCMAP for optimal cluster mapping with dependent clusters. Given an arbitrarily defined, positive cost function based on the DAG and cluster mappings, we show that DCMAP converges to find all optimal clusters, and returns near-optimal solutions along the way. Empirically, we find that the algorithm is time-efficient for a DBN model of a seagrass complex system using a computation cost function. For a 25 and 50-node DBN, the search space size was $9.91\times 10^9$ and $1.5
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22238;&#39038;&#20102;&#29616;&#26377;&#30340;&#32858;&#31867;&#39564;&#35777;&#26041;&#27861;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#26080;&#30417;&#30563;&#20998;&#31867;&#31639;&#27861;&#22312;&#19981;&#21516;&#31867;&#22411;&#30340;&#25968;&#25454;&#20013;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2308.03894</link><description>&lt;p&gt;
&#19968;&#31181;&#35780;&#20272;&#20869;&#37096;&#32858;&#31867;&#39564;&#35777;&#25351;&#26631;&#30340;&#26032;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A new approach for evaluating internal cluster validation indices. (arXiv:2308.03894v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03894
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22238;&#39038;&#20102;&#29616;&#26377;&#30340;&#32858;&#31867;&#39564;&#35777;&#26041;&#27861;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#26080;&#30417;&#30563;&#20998;&#31867;&#31639;&#27861;&#22312;&#19981;&#21516;&#31867;&#22411;&#30340;&#25968;&#25454;&#20013;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#20998;&#31867;&#26377;&#24456;&#22810;&#19981;&#21516;&#30340;&#26041;&#27861;&#21487;&#20379;&#36873;&#25321;&#12290;&#30001;&#20110;&#27809;&#26377;&#19968;&#20010;&#31639;&#27861;&#21644;&#21442;&#25968;&#35774;&#32622;&#22312;&#25152;&#26377;&#31867;&#22411;&#30340;&#25968;&#25454;&#20013;&#34920;&#29616;&#26368;&#20339;&#65292;&#22240;&#27492;&#38656;&#35201;&#36827;&#34892;&#32858;&#31867;&#39564;&#35777;&#26469;&#36873;&#25321;&#30495;&#27491;&#34920;&#29616;&#26368;&#22909;&#30340;&#31639;&#27861;&#12290;&#20026;&#27492;&#65292;&#25552;&#20986;&#20102;&#20960;&#31181;&#19981;&#20351;&#29992;&#20219;&#20309;&#39069;&#22806;&#65288;&#22806;&#37096;&#65289;&#20449;&#24687;&#30340;&#20869;&#37096;&#39564;&#35777;&#25351;&#26631;&#12290;&#21487;&#20197;&#36890;&#36807;&#23558;&#23427;&#20204;&#24212;&#29992;&#20110;&#20855;&#26377;&#24050;&#30693;&#32858;&#31867;&#32467;&#26500;&#30340;&#25968;&#25454;&#38598;&#30340;&#20998;&#31867;&#26469;&#35780;&#20272;&#36825;&#20123;&#20869;&#37096;&#39564;&#35777;&#25351;&#26631;&#12290;&#35780;&#20272;&#26041;&#27861;&#22312;&#22914;&#20309;&#20351;&#29992;&#30495;&#23454;&#20998;&#31867;&#20449;&#24687;&#26041;&#38754;&#23384;&#22312;&#24046;&#24322;&#12290;&#26412;&#25991;&#22238;&#39038;&#20102;&#36825;&#20123;&#26041;&#27861;&#65292;&#32771;&#34385;&#20102;&#23427;&#20204;&#30340;&#20248;&#21183;&#21644;&#21155;&#21183;&#65292;&#28982;&#21518;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
A vast number of different methods are available for unsupervised classification. Since no algorithm and parameter setting performs best in all types of data, there is a need for cluster validation to select the actually best-performing algorithm. Several indices were proposed for this purpose without using any additional (external) information. These internal validation indices can be evaluated by applying them to classifications of datasets with a known cluster structure. Evaluation approaches differ in how they use the information on the ground-truth classification. This paper reviews these approaches, considering their advantages and disadvantages, and then suggests a new approach.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26410;&#35265;&#29366;&#24577;&#22686;&#24378;&#30340;&#31574;&#30053;&#65292;&#22312;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#36890;&#36807;&#22522;&#20110;&#20215;&#20540;&#30340;&#25200;&#21160;&#21644;&#36807;&#28388;&#65292;&#23454;&#29616;&#20102;&#23545;&#31163;&#32447;&#25968;&#25454;&#20043;&#22806;&#30340;&#29366;&#24577;&#30340;&#21033;&#29992;&#21644;&#27867;&#21270;&#12290;</title><link>http://arxiv.org/abs/2308.03882</link><description>&lt;p&gt;
&#36890;&#36807;&#26410;&#35265;&#36807;&#30340;&#29366;&#24577;&#22686;&#24378;&#21033;&#29992;&#24191;&#20041;&#21270;&#22312;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;
&lt;/p&gt;
&lt;p&gt;
Exploiting Generalization in Offline Reinforcement Learning via Unseen State Augmentations. (arXiv:2308.03882v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03882
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26410;&#35265;&#29366;&#24577;&#22686;&#24378;&#30340;&#31574;&#30053;&#65292;&#22312;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#36890;&#36807;&#22522;&#20110;&#20215;&#20540;&#30340;&#25200;&#21160;&#21644;&#36807;&#28388;&#65292;&#23454;&#29616;&#20102;&#23545;&#31163;&#32447;&#25968;&#25454;&#20043;&#22806;&#30340;&#29366;&#24577;&#30340;&#21033;&#29992;&#21644;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#36890;&#36807;&#23545;&#26410;&#35265;&#36807;&#30340;&#29366;&#24577;&#21644;&#21160;&#20316;&#36827;&#34892;&#20445;&#23432;&#20215;&#20540;&#35780;&#20272;&#26469;&#24179;&#34913;&#25506;&#32034;&#21644;&#21033;&#29992;&#12290;&#26080;&#27169;&#22411;&#26041;&#27861;&#20250;&#23545;&#25152;&#26377;&#26410;&#35265;&#36807;&#30340;&#21160;&#20316;&#36827;&#34892;&#24809;&#32602;&#65292;&#32780;&#26377;&#27169;&#22411;&#26041;&#27861;&#21487;&#20197;&#36827;&#19968;&#27493;&#36890;&#36807;&#27169;&#22411;&#23637;&#24320;&#23545;&#26410;&#35265;&#36807;&#30340;&#29366;&#24577;&#36827;&#34892;&#21033;&#29992;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20004;&#20010;&#22240;&#32032;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#25214;&#21040;&#31163;&#32447;&#25968;&#25454;&#20043;&#22806;&#30340;&#26410;&#35265;&#36807;&#30340;&#29366;&#24577;&#26102;&#23384;&#22312;&#22256;&#38590;&#65306;(a)&#30001;&#20110;&#32423;&#32852;&#27169;&#22411;&#35823;&#24046;&#65292;&#27169;&#22411;&#30340;&#23637;&#24320;&#33539;&#22260;&#38750;&#24120;&#30701;&#65292;(b)&#27169;&#22411;&#23637;&#24320;&#20165;&#20197;&#31163;&#32447;&#25968;&#25454;&#20013;&#35266;&#23519;&#21040;&#30340;&#29366;&#24577;&#20026;&#36215;&#28857;&#12290;&#25105;&#20204;&#25918;&#23485;&#20102;&#31532;&#20108;&#20010;&#20551;&#35774;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26410;&#35265;&#36807;&#29366;&#24577;&#22686;&#24378;&#31574;&#30053;&#65292;&#20197;&#20801;&#35768;&#23398;&#24471;&#30340;&#27169;&#22411;&#21644;&#20215;&#20540;&#20272;&#35745;&#22312;&#26410;&#35265;&#29366;&#24577;&#20013;&#27867;&#21270;&#12290;&#25105;&#20204;&#30340;&#31574;&#30053;&#36890;&#36807;&#23545;&#35266;&#23519;&#21040;&#30340;&#29366;&#24577;&#36827;&#34892;&#22522;&#20110;&#20215;&#20540;&#30340;&#25200;&#21160;&#26469;&#25214;&#21040;&#26410;&#35265;&#36807;&#30340;&#29366;&#24577;&#65292;&#28982;&#21518;&#36890;&#36807;&#36807;&#28388;&#20855;&#26377;&#36807;&#39640;&#30340;&#21551;&#21457;&#24615;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65288;&#39640;&#35823;&#24046;&#65289;&#25110;&#36807;&#20302;&#30340;&#65288;&#36807;&#20110;&#30456;&#20284;&#65289;
&lt;/p&gt;
&lt;p&gt;
Offline reinforcement learning (RL) methods strike a balance between exploration and exploitation by conservative value estimation -- penalizing values of unseen states and actions. Model-free methods penalize values at all unseen actions, while model-based methods are able to further exploit unseen states via model rollouts. However, such methods are handicapped in their ability to find unseen states far away from the available offline data due to two factors -- (a) very short rollout horizons in models due to cascading model errors, and (b) model rollouts originating solely from states observed in offline data. We relax the second assumption and present a novel unseen state augmentation strategy to allow exploitation of unseen states where the learned model and value estimates generalize. Our strategy finds unseen states by value-informed perturbations of seen states followed by filtering out states with epistemic uncertainty estimates too high (high error) or too low (too similar to
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#27809;&#26377;&#25935;&#24863;&#30340;&#31181;&#26063;&#21644;&#26063;&#35028;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#20195;&#29702;&#27169;&#22411;&#36827;&#34892;&#31181;&#26063;&#39044;&#27979;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#32773;&#35757;&#32451;&#20102;&#19968;&#20010;&#21452;&#21521;&#38271;&#30701;&#26102;&#35760;&#24518;&#65288;BiLSTM&#65289;&#27169;&#22411;&#65292;&#24182;&#21019;&#24314;&#20102;&#19968;&#20010;&#38598;&#25104;&#27169;&#22411;&#65292;&#20854;&#22312;&#22806;&#26679;&#26412;&#65288;OOS&#65289;F1&#24471;&#20998;&#19978;&#27604;&#25991;&#29486;&#20013;&#34920;&#29616;&#26368;&#22909;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#39640;&#20986;36.8%&#12290;&#27492;&#22806;&#65292;&#36824;&#26500;&#24314;&#20102;&#32654;&#22269;&#26368;&#20840;&#38754;&#30340;&#22995;&#27663;&#21644;&#21517;&#23383;&#20998;&#24067;&#25968;&#25454;&#24211;&#65292;&#24182;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#39640;&#36136;&#37327;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#20197;&#20844;&#27491;&#27604;&#36739;&#29616;&#26377;&#27169;&#22411;&#65292;&#24182;&#24110;&#21161;&#26410;&#26469;&#30340;&#27169;&#22411;&#24320;&#21457;&#32773;&#12290;</title><link>http://arxiv.org/abs/2307.08496</link><description>&lt;p&gt;
&#25105;&#20204;&#33021;&#30456;&#20449;&#31181;&#26063;&#39044;&#27979;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can We Trust Race Prediction?. (arXiv:2307.08496v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08496
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#27809;&#26377;&#25935;&#24863;&#30340;&#31181;&#26063;&#21644;&#26063;&#35028;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#20195;&#29702;&#27169;&#22411;&#36827;&#34892;&#31181;&#26063;&#39044;&#27979;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#32773;&#35757;&#32451;&#20102;&#19968;&#20010;&#21452;&#21521;&#38271;&#30701;&#26102;&#35760;&#24518;&#65288;BiLSTM&#65289;&#27169;&#22411;&#65292;&#24182;&#21019;&#24314;&#20102;&#19968;&#20010;&#38598;&#25104;&#27169;&#22411;&#65292;&#20854;&#22312;&#22806;&#26679;&#26412;&#65288;OOS&#65289;F1&#24471;&#20998;&#19978;&#27604;&#25991;&#29486;&#20013;&#34920;&#29616;&#26368;&#22909;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#39640;&#20986;36.8%&#12290;&#27492;&#22806;&#65292;&#36824;&#26500;&#24314;&#20102;&#32654;&#22269;&#26368;&#20840;&#38754;&#30340;&#22995;&#27663;&#21644;&#21517;&#23383;&#20998;&#24067;&#25968;&#25454;&#24211;&#65292;&#24182;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#39640;&#36136;&#37327;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#20197;&#20844;&#27491;&#27604;&#36739;&#29616;&#26377;&#27169;&#22411;&#65292;&#24182;&#24110;&#21161;&#26410;&#26469;&#30340;&#27169;&#22411;&#24320;&#21457;&#32773;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27809;&#26377;&#25935;&#24863;&#30340;&#31181;&#26063;&#21644;&#26063;&#35028;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#30740;&#31350;&#20154;&#21592;&#12289;&#30417;&#31649;&#26426;&#26500;&#21644;&#20844;&#21496;&#37117;&#20511;&#21161;&#20195;&#29702;&#27169;&#22411;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20351;&#29992;&#26469;&#33258;&#32654;&#22269;50&#20010;&#24030;&#30340;&#36873;&#27665;&#27880;&#20876;&#25968;&#25454;&#35757;&#32451;&#20102;&#19968;&#20010;&#21452;&#21521;&#38271;&#30701;&#26102;&#35760;&#24518;&#65288;BiLSTM&#65289;&#27169;&#22411;&#65292;&#24182;&#21019;&#24314;&#20102;&#19968;&#20010;&#38598;&#25104;&#27169;&#22411;&#65292;&#20854;&#22312;&#22806;&#26679;&#26412;&#65288;OOS&#65289;F1&#24471;&#20998;&#19978;&#27604;&#25991;&#29486;&#20013;&#34920;&#29616;&#26368;&#22909;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#39640;&#20986;36.8%&#12290;&#27492;&#22806;&#65292;&#25105;&#26500;&#24314;&#20102;&#32654;&#22269;&#26368;&#20840;&#38754;&#30340;&#22995;&#27663;&#21644;&#21517;&#23383;&#20998;&#24067;&#25968;&#25454;&#24211;&#65292;&#20197;&#25913;&#36827;&#36125;&#21494;&#26031;&#25913;&#36827;&#22995;&#27663;&#22320;&#29702;&#32534;&#30721;&#65288;BISG&#65289;&#21644;&#36125;&#21494;&#26031;&#25913;&#36827;&#21517;&#23383;&#22995;&#27663;&#22320;&#29702;&#32534;&#30721;&#65288;BIFSG&#65289;&#30340;&#35206;&#30422;&#21644;&#20934;&#30830;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#39640;&#36136;&#37327;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#20197;&#20844;&#27491;&#27604;&#36739;&#29616;&#26377;&#27169;&#22411;&#65292;&#24182;&#24110;&#21161;&#26410;&#26469;&#30340;&#27169;&#22411;&#24320;&#21457;&#32773;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the absence of sensitive race and ethnicity data, researchers, regulators, and firms alike turn to proxies. In this paper, I train a Bidirectional Long Short-Term Memory (BiLSTM) model on a novel dataset of voter registration data from all 50 US states and create an ensemble that achieves up to 36.8% higher out of sample (OOS) F1 scores than the best performing machine learning models in the literature. Additionally, I construct the most comprehensive database of first and surname distributions in the US in order to improve the coverage and accuracy of Bayesian Improved Surname Geocoding (BISG) and Bayesian Improved Firstname Surname Geocoding (BIFSG). Finally, I provide the first high-quality benchmark dataset in order to fairly compare existing models and aid future model developers.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#29992;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#31232;&#30095;&#27491;&#21017;&#21270;&#20013;&#36827;&#34892;&#24179;&#28369;&#20248;&#21270;&#65292;&#19982;&#20027;&#27969;&#30340;&#19968;&#38454;&#20248;&#21270;&#26041;&#27861;&#20860;&#23481;&#65292;&#24182;&#19988;&#33021;&#22815;&#24471;&#21040;&#21305;&#37197;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#21644;&#31561;&#20215;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;</title><link>http://arxiv.org/abs/2307.03571</link><description>&lt;p&gt;
&#24179;&#28369;&#36793;&#32536;&#65306;&#21033;&#29992;Hadamard&#36229;&#21442;&#25968;&#21270;&#22312;&#31232;&#30095;&#27491;&#21017;&#21270;&#30340;&#24179;&#28369;&#20248;&#21270;&#20013;&#30340;&#19968;&#33324;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Smoothing the Edges: A General Framework for Smooth Optimization in Sparse Regularization using Hadamard Overparametrization. (arXiv:2307.03571v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03571
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#29992;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#31232;&#30095;&#27491;&#21017;&#21270;&#20013;&#36827;&#34892;&#24179;&#28369;&#20248;&#21270;&#65292;&#19982;&#20027;&#27969;&#30340;&#19968;&#38454;&#20248;&#21270;&#26041;&#27861;&#20860;&#23481;&#65292;&#24182;&#19988;&#33021;&#22815;&#24471;&#21040;&#21305;&#37197;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#21644;&#31561;&#20215;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#65288;&#32467;&#26500;&#21270;&#65289;&#31232;&#30095;&#27491;&#21017;&#21270;&#38382;&#39064;&#20013;&#30340;$\ell_q$&#21644;$\ell_{p,q}$&#27491;&#21017;&#21270;&#30340;&#24179;&#28369;&#26041;&#27861;&#12290;&#36825;&#20123;&#38750;&#24179;&#28369;&#19988;&#21487;&#33021;&#38750;&#20984;&#30340;&#38382;&#39064;&#30340;&#20248;&#21270;&#36890;&#24120;&#20381;&#36182;&#20110;&#19987;&#38376;&#30340;&#36807;&#31243;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#25105;&#20204;&#30340;&#19968;&#33324;&#26694;&#26550;&#19982;&#20027;&#27969;&#30340;&#19968;&#38454;&#20248;&#21270;&#26041;&#27861;&#65288;&#22914;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#21644;&#21152;&#36895;&#21464;&#20307;&#65289;&#20860;&#23481;&#65292;&#26080;&#38656;&#20219;&#20309;&#20462;&#25913;&#12290;&#36825;&#26159;&#36890;&#36807;&#24179;&#28369;&#20248;&#21270;&#36716;&#31227;&#23454;&#29616;&#30340;&#65292;&#20854;&#20013;&#36873;&#23450;&#27169;&#22411;&#21442;&#25968;&#30340;&#36229;&#21442;&#25968;&#21270;&#20351;&#29992;Hadamard&#20056;&#31215;&#21644;&#24809;&#32602;&#30340;&#25913;&#21464;&#12290;&#22312;&#36229;&#21442;&#25968;&#38382;&#39064;&#20013;&#65292;&#36890;&#36807;&#29992;&#26367;&#20195;&#21442;&#25968;&#36827;&#34892;&#24179;&#28369;&#21644;&#20984;&#24615;&#30340;$\ell_2$&#27491;&#21017;&#21270;&#65292;&#33021;&#22815;&#22312;&#21407;&#22987;&#21442;&#25968;&#21270;&#20013;&#24341;&#20837;&#38750;&#24179;&#28369;&#21644;&#38750;&#20984;&#24615;&#30340;$\ell_q$&#25110;$\ell_{p,q}$&#27491;&#21017;&#21270;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20165;&#33021;&#22815;&#24471;&#21040;&#21305;&#37197;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#65292;&#36824;&#33021;&#24471;&#21040;&#31561;&#20215;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;&#36825;&#22312;&#38750;&#20984;&#31232;&#30095;&#27491;&#21017;&#21270;&#20013;&#23588;&#20854;&#26377;&#29992;&#65292;&#22240;&#20026;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#25214;&#21040;&#20840;&#23616;&#26368;&#23567;&#20540;&#38750;&#24120;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a smooth method for (structured) sparsity in $\ell_q$ and $\ell_{p,q}$ regularized optimization problems. Optimization of these non-smooth and possibly non-convex problems typically relies on specialized procedures. In contrast, our general framework is compatible with prevalent first-order optimization methods like Stochastic Gradient Descent and accelerated variants without any required modifications. This is accomplished through a smooth optimization transfer, comprising an overparametrization of selected model parameters using Hadamard products and a change of penalties. In the overparametrized problem, smooth and convex $\ell_2$ regularization of the surrogate parameters induces non-smooth and non-convex $\ell_q$ or $\ell_{p,q}$ regularization in the original parametrization. We show that our approach yields not only matching global minima but also equivalent local minima. This is particularly useful in non-convex sparse regularization, where finding global m
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#20801;&#35768;&#20219;&#24847;&#25968;&#25454;&#25490;&#24207;&#30340;&#26222;&#36890;SGD&#31639;&#27861;,&#24182;&#34920;&#26126;&#22312;&#38750;&#20984;&#20989;&#25968;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#21644;&#21333;&#27425;&#27927;&#29260;&#30340;SGD&#27604;&#32463;&#20856;&#26367;&#25442;&#30340;SGD&#26356;&#24555;&#25110;&#33267;&#23569;&#19982;&#20854;&#19968;&#26679;&#22909;&#65292;&#26080;&#35770;&#36845;&#20195;&#27425;&#25968;&#22914;&#20309;&#12290;</title><link>http://arxiv.org/abs/2305.19259</link><description>&lt;p&gt;
Shuffle SGD&#24635;&#26159;&#27604;SGD&#26356;&#22909;&#65306;&#23545;&#20855;&#26377;&#20219;&#24847;&#25968;&#25454;&#39034;&#24207;&#30340;SGD&#36827;&#34892;&#25913;&#36827;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Shuffle SGD is Always Better than SGD: Improved Analysis of SGD with Arbitrary Data Orders. (arXiv:2305.19259v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19259
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#20801;&#35768;&#20219;&#24847;&#25968;&#25454;&#25490;&#24207;&#30340;&#26222;&#36890;SGD&#31639;&#27861;,&#24182;&#34920;&#26126;&#22312;&#38750;&#20984;&#20989;&#25968;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#21644;&#21333;&#27425;&#27927;&#29260;&#30340;SGD&#27604;&#32463;&#20856;&#26367;&#25442;&#30340;SGD&#26356;&#24555;&#25110;&#33267;&#23569;&#19982;&#20854;&#19968;&#26679;&#22909;&#65292;&#26080;&#35770;&#36845;&#20195;&#27425;&#25968;&#22914;&#20309;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#31639;&#27861;&#34987;&#24191;&#27867;&#29992;&#20110;&#20248;&#21270;&#31070;&#32463;&#32593;&#32476;&#65292;&#38543;&#26426;&#37325;&#25490;&#65288;RR&#65289;&#21644;&#21333;&#27425;&#27927;&#29260;&#65288;SS&#65289;&#26159;&#36890;&#36807;&#24490;&#29615;&#36941;&#21382;&#35757;&#32451;&#25968;&#25454;&#30340;&#38543;&#26426;&#25110;&#21333;&#20010;&#25490;&#21015;&#30340;&#24120;&#35265;&#36873;&#25321;&#65292;&#28982;&#32780;&#36825;&#20123;&#31639;&#27861;&#22312;&#38750;&#20984;&#24773;&#20917;&#19979;&#30340;&#25910;&#25947;&#24615;&#36136;&#23578;&#26410;&#23436;&#20840;&#29702;&#35299;&#12290;&#29616;&#26377;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#23454;&#38469;&#30340;&#35757;&#32451;&#22330;&#26223;&#20013;&#65292;&#24403;&#26102;&#20195;&#30340;&#25968;&#37327;&#23567;&#20110;&#35757;&#32451;&#38598;&#22823;&#23567;&#26102;&#65292;RR&#21487;&#33021;&#34920;&#29616;&#19981;&#22914;SGD&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#19968;&#31181;&#20801;&#35768;&#20219;&#24847;&#25968;&#25454;&#25490;&#24207;&#30340;&#26222;&#36890;SGD&#31639;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#38750;&#20984;&#20989;&#25968;&#24773;&#20917;&#19979;&#30340;&#25913;&#36827;&#25910;&#25947;&#36895;&#24230;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#38543;&#26426;&#21644;&#21333;&#27425;&#27927;&#29260;&#30340;SGD&#27604;&#32463;&#20856;&#26367;&#25442;&#30340;SGD&#26356;&#24555;&#25110;&#33267;&#23569;&#19982;&#20854;&#19968;&#26679;&#22909;&#65292;&#26080;&#35770;&#36845;&#20195;&#27425;&#25968;&#22914;&#20309;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#20984;&#26174;&#20102;&#20351;&#29992;&#38543;&#26426;/&#21333;&#27425;&#27927;&#29260;&#30340;SGD&#30340;&#22909;&#22788;&#65292;&#24182;&#20026;&#20854;&#38750;&#20984;&#25910;&#25947;&#24615;&#36136;&#25552;&#20379;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic Gradient Descent (SGD) algorithms are widely used in optimizing neural networks, with Random Reshuffling (RR) and Single Shuffle (SS) being popular choices for cycling through random or single permutations of the training data. However, the convergence properties of these algorithms in the non-convex case are not fully understood. Existing results suggest that, in realistic training scenarios where the number of epochs is smaller than the training set size, RR may perform worse than SGD.  In this paper, we analyze a general SGD algorithm that allows for arbitrary data orderings and show improved convergence rates for non-convex functions. Specifically, our analysis reveals that SGD with random and single shuffling is always faster or at least as good as classical SGD with replacement, regardless of the number of iterations. Overall, our study highlights the benefits of using SGD with random/single shuffling and provides new insights into its convergence properties for non-co
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#33609;&#22270;&#25216;&#26415;&#23558;&#31890;&#23376;&#26041;&#27861;&#21644;&#24352;&#37327;&#32593;&#32476;&#26041;&#27861;&#32467;&#21512;&#30340;&#26041;&#27861;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#36825;&#31181;&#26041;&#27861;&#21253;&#25324;&#31890;&#23376;&#27169;&#25311;&#21644;&#24352;&#37327;&#32593;&#32476;&#37325;&#26032;&#20272;&#35745;&#65292;&#24182;&#21487;&#29992;&#20316;&#31890;&#23376;&#25968;&#25511;&#21046;&#30340;&#21487;&#26367;&#20195;&#26041;&#27861;&#12290;&#22312;&#27169;&#25311;Fokker-Planck&#26041;&#31243;&#21644;&#37327;&#23376;&#34394;&#26102;&#38388;&#28436;&#21270;&#26041;&#38754;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#36890;&#29992;&#24615;&#21644;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.17884</link><description>&lt;p&gt;
&#36890;&#36807;&#33609;&#22270;&#25216;&#26415;&#65292;&#23558;&#31890;&#23376;&#26041;&#27861;&#21644;&#24352;&#37327;&#32593;&#32476;&#26041;&#27861;&#32467;&#21512;&#29992;&#20110;&#20559;&#24494;&#20998;&#26041;&#31243;&#27714;&#35299;
&lt;/p&gt;
&lt;p&gt;
Combining Particle and Tensor-network Methods for Partial Differential Equations via Sketching. (arXiv:2305.17884v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17884
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#33609;&#22270;&#25216;&#26415;&#23558;&#31890;&#23376;&#26041;&#27861;&#21644;&#24352;&#37327;&#32593;&#32476;&#26041;&#27861;&#32467;&#21512;&#30340;&#26041;&#27861;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#36825;&#31181;&#26041;&#27861;&#21253;&#25324;&#31890;&#23376;&#27169;&#25311;&#21644;&#24352;&#37327;&#32593;&#32476;&#37325;&#26032;&#20272;&#35745;&#65292;&#24182;&#21487;&#29992;&#20316;&#31890;&#23376;&#25968;&#25511;&#21046;&#30340;&#21487;&#26367;&#20195;&#26041;&#27861;&#12290;&#22312;&#27169;&#25311;Fokker-Planck&#26041;&#31243;&#21644;&#37327;&#23376;&#34394;&#26102;&#38388;&#28436;&#21270;&#26041;&#38754;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#36890;&#29992;&#24615;&#21644;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#24352;&#37327;&#32593;&#32476;&#26694;&#26550;&#65292;&#20854;&#20013;&#25105;&#20204;&#37319;&#29992;&#31890;&#23376;&#27169;&#25311;&#26356;&#26032;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#20351;&#29992;&#26368;&#36817;&#25552;&#20986;&#30340;&#24352;&#37327;&#21015;&#36710;&#33609;&#22270;&#25216;&#26415;&#23558;&#26032;&#35299;&#20915;&#26041;&#26696;&#37325;&#26032;&#20272;&#35745;&#20026;&#24352;&#37327;&#32593;&#32476;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36824;&#21487;&#20197;&#34987;&#35299;&#37322;&#20026;&#36890;&#36807;&#20551;&#35774;&#31890;&#23376;&#26469;&#33258;&#24213;&#23618;&#24352;&#37327;&#32593;&#32476;&#26469;&#25191;&#34892;&#31890;&#23376;&#25968;&#25511;&#21046;&#30340;&#21487;&#26367;&#20195;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#20854;&#24212;&#29992;&#20110;&#20004;&#31181;&#29305;&#23450;&#30340;&#24773;&#26223;&#26469;&#23637;&#31034;&#25105;&#20204;&#26041;&#27861;&#30340;&#36890;&#29992;&#24615;&#21644;&#28789;&#27963;&#24615;&#65306;&#36890;&#36807;Langevin&#21160;&#21147;&#23398;&#27169;&#25311;Fokker-Planck&#26041;&#31243;&#21644;&#36890;&#36807;&#36741;&#21161;&#22330;&#37327;&#23376;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#37327;&#23376;&#34394;&#26102;&#38388;&#28436;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a general framework for solving high-dimensional partial differential equations with tensor networks. Our approach offers a comprehensive solution methodology, wherein we employ a combination of particle simulations to update the solution and re-estimations of the new solution as a tensor-network using a recently proposed tensor train sketching technique. Our method can also be interpreted as an alternative approach for performing particle number control by assuming the particles originate from an underlying tensor network. We demonstrate the versatility and flexibility of our approach by applying it to two specific scenarios: simulating the Fokker-Planck equation through Langevin dynamics and quantum imaginary time evolution via auxiliary-field quantum Monte Carlo.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31354;&#38388;&#20809;&#35843;&#21046;&#30340;SPBM&#35745;&#31639;&#27169;&#22411;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35299;&#20915;&#20219;&#20309;&#20234;&#36763;&#38382;&#39064;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#20855;&#26377;&#20302;&#31209;&#30456;&#20114;&#20316;&#29992;&#30697;&#38453;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#20855;&#26377;&#23398;&#20064;&#12289;&#20998;&#31867;&#21644;&#37319;&#26679;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2303.14993</link><description>&lt;p&gt;
&#31354;&#38388;-&#20809;&#23376;Boltzmann&#26426;&#65306;&#21033;&#29992;&#31354;&#38388;&#20809;&#35843;&#21046;&#36827;&#34892;&#20302;&#31209;&#32452;&#21512;&#20248;&#21270;&#21644;&#32479;&#35745;&#23398;&#20064;&#65288;arXiv:2303.14993v1 [cond-mat.dis-nn] CROSS LISTED&#65289;
&lt;/p&gt;
&lt;p&gt;
Spatial-photonic Boltzmann machines: low-rank combinatorial optimization and statistical learning by spatial light modulation. (arXiv:2303.14993v1 [cond-mat.dis-nn] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14993
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31354;&#38388;&#20809;&#35843;&#21046;&#30340;SPBM&#35745;&#31639;&#27169;&#22411;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35299;&#20915;&#20219;&#20309;&#20234;&#36763;&#38382;&#39064;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#20855;&#26377;&#20302;&#31209;&#30456;&#20114;&#20316;&#29992;&#30697;&#38453;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#20855;&#26377;&#23398;&#20064;&#12289;&#20998;&#31867;&#21644;&#37319;&#26679;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31354;&#38388;-&#20809;&#23376;&#20234;&#36763;&#26426;&#65288;SPIM&#65289;[D. Pierangeli et al., Phys. Rev. Lett. 122, 213902 (2019)]&#26159;&#19968;&#31181;&#20351;&#29992;&#31354;&#38388;&#20809;&#35843;&#21046;&#26377;&#25928;&#35299;&#20915;&#22823;&#35268;&#27169;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#30340;&#20809;&#23398;&#26550;&#26500;&#12290;&#28982;&#32780;&#65292;SPIM&#20165;&#33021;&#23481;&#32435;&#20855;&#26377;&#31209;&#20026;&#19968;&#30340;&#30456;&#20114;&#20316;&#29992;&#30697;&#38453;&#30340;&#20234;&#36763;&#38382;&#39064;&#65292;&#36825;&#38480;&#21046;&#20102;&#20854;&#22312;&#21508;&#31181;&#23454;&#38469;&#38382;&#39064;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;SPIM&#35745;&#31639;&#27169;&#22411;&#65292;&#21487;&#20197;&#22312;&#19981;&#25913;&#21464;&#20854;&#20809;&#23398;&#23454;&#29616;&#30340;&#24773;&#20917;&#19979;&#23481;&#32435;&#20219;&#20309;&#20234;&#36763;&#38382;&#39064;&#12290;&#35813;&#27169;&#22411;&#23545;&#20110;&#20855;&#26377;&#20302;&#31209;&#30456;&#20114;&#20316;&#29992;&#30697;&#38453;&#30340;&#20234;&#36763;&#38382;&#39064;&#65288;&#22914;&#32972;&#21253;&#38382;&#39064;&#65289;&#29305;&#21035;&#26377;&#25928;&#12290;&#27492;&#22806;&#65292;&#35813;&#27169;&#22411;&#20855;&#26377;&#23398;&#20064;&#33021;&#21147;&#65292;&#22240;&#27492;&#21487;&#20197;&#34987;&#31216;&#20026;&#31354;&#38388;&#20809;&#23376;Boltzmann&#26426;&#65288;SPBM&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20351;&#29992;&#20855;&#26377;&#20302;&#31209;&#30456;&#20114;&#20316;&#29992;&#30340;SPBM&#26377;&#25928;&#22320;&#23454;&#29616;&#20102;MNIST&#25163;&#20889;&#25968;&#23383;&#22270;&#20687;&#30340;&#23398;&#20064;&#12289;&#20998;&#31867;&#21644;&#37319;&#26679;&#12290;&#22240;&#27492;&#65292;&#25152;&#25552;&#20986;&#30340;SPBM&#27169;&#22411;&#34920;&#29616;&#20986;&#26356;&#39640;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The spatial-photonic Ising machine (SPIM) [D. Pierangeli et al., Phys. Rev. Lett. 122, 213902 (2019)] is a promising optical architecture utilizing spatial light modulation for solving large-scale combinatorial optimization problems efficiently. However, the SPIM can accommodate Ising problems with only rank-one interaction matrices, which limits its applicability to various real-world problems. In this Letter, we propose a new computing model for the SPIM that can accommodate any Ising problem without changing its optical implementation. The proposed model is particularly efficient for Ising problems with low-rank interaction matrices, such as knapsack problems. Moreover, the model acquires learning ability and can thus be termed a spatial-photonic Boltzmann machine (SPBM). We demonstrate that learning, classification, and sampling of the MNIST handwritten digit images are achieved efficiently using SPBMs with low-rank interactions. Thus, the proposed SPBM model exhibits higher practi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27604;&#36739;&#20102;&#35768;&#22810;&#20986;&#29616;&#22312;&#25991;&#29486;&#20013;&#30340;&#22240;&#26524;&#21059;&#20992;&#65292;&#24182;&#29305;&#21035;&#30740;&#31350;&#20102;&#22312;&#22810;&#39033;&#24335;&#22240;&#26524;&#27169;&#22411;&#20013;&#19981;&#22826;&#21463;&#27426;&#36814;&#30340;&#22240;&#26524;&#21059;&#20992;&#8212;&#8212;&#21442;&#25968;&#26368;&#23567;&#24615;&#12290;&#36923;&#36753;&#32467;&#26524;&#25581;&#31034;&#20102;&#36873;&#25321;&#21512;&#29702;&#24471;&#20998;&#26631;&#20934;&#26102;&#30340;&#22256;&#22659;&#12290;</title><link>http://arxiv.org/abs/2302.10331</link><description>&lt;p&gt;
&#22240;&#26524;&#21059;&#20992;
&lt;/p&gt;
&lt;p&gt;
Causal Razors. (arXiv:2302.10331v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10331
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27604;&#36739;&#20102;&#35768;&#22810;&#20986;&#29616;&#22312;&#25991;&#29486;&#20013;&#30340;&#22240;&#26524;&#21059;&#20992;&#65292;&#24182;&#29305;&#21035;&#30740;&#31350;&#20102;&#22312;&#22810;&#39033;&#24335;&#22240;&#26524;&#27169;&#22411;&#20013;&#19981;&#22826;&#21463;&#27426;&#36814;&#30340;&#22240;&#26524;&#21059;&#20992;&#8212;&#8212;&#21442;&#25968;&#26368;&#23567;&#24615;&#12290;&#36923;&#36753;&#32467;&#26524;&#25581;&#31034;&#20102;&#36873;&#25321;&#21512;&#29702;&#24471;&#20998;&#26631;&#20934;&#26102;&#30340;&#22256;&#22659;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#26102;&#65292;&#24517;&#39035;&#23545;&#30495;&#23454;&#22240;&#26524;&#26426;&#21046;&#22914;&#20309;&#19982;&#24213;&#23618;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#30456;&#23545;&#24212;&#20570;&#20986;&#20551;&#35774;&#12290;&#26412;&#25991;&#23558;&#36825;&#20123;&#20551;&#35774;&#31216;&#20026;&#22240;&#26524;&#21059;&#20992;&#12290;&#25105;&#20204;&#22238;&#39038;&#20102;&#35768;&#22810;&#20986;&#29616;&#22312;&#25991;&#29486;&#20013;&#30340;&#22240;&#26524;&#21059;&#20992;&#65292;&#23545;&#23427;&#20204;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#36923;&#36753;&#27604;&#36739;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23545;&#22312;&#22810;&#39033;&#24335;&#22240;&#26524;&#27169;&#22411;&#20013;&#19981;&#22826;&#21463;&#27426;&#36814;&#30340;&#22240;&#26524;&#21059;&#20992;&#8212;&#8212;&#21442;&#25968;&#26368;&#23567;&#24615;&#36827;&#34892;&#20102;&#28145;&#20837;&#30340;&#30740;&#31350;&#65292;&#24182;&#30740;&#31350;&#20102;&#23427;&#19982;&#20854;&#20182;&#24191;&#27867;&#30740;&#31350;&#30340;&#22240;&#26524;&#21059;&#20992;&#20043;&#38388;&#30340;&#36923;&#36753;&#20851;&#31995;&#12290;&#25105;&#20204;&#30340;&#36923;&#36753;&#32467;&#26524;&#22312;&#20026;&#22522;&#20110;&#20998;&#25968;&#30340;&#22240;&#26524;&#25628;&#32034;&#31639;&#27861;&#36873;&#25321;&#21512;&#29702;&#24471;&#20998;&#26631;&#20934;&#26102;&#25552;&#20986;&#20102;&#22256;&#22659;&#12290;
&lt;/p&gt;
&lt;p&gt;
When performing causal discovery, assumptions have to be made on how the true causal mechanism corresponds to the underlying joint probability distribution. These assumptions are labeled as causal razors in this work. We review numerous causal razors that appeared in the literature, and offer a comprehensive logical comparison of them. In particular, we scrutinize an unpopular causal razor, namely parameter minimality, in multinomial causal models and its logical relations with other well-studied causal razors. Our logical result poses a dilemma in selecting a reasonable scoring criterion for score-based casual search algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;GAN&#29983;&#25104;&#24314;&#27169;&#26694;&#26550;MonoFlow&#65292;&#36890;&#36807;Wasserstein&#26799;&#24230;&#27969;&#33719;&#24471;&#29702;&#35770;&#27934;&#35265;&#21644;&#31639;&#27861;&#21551;&#31034;&#12290;&#35813;&#26694;&#26550;&#20351;&#29992;&#23494;&#24230;&#27604;&#20363;&#30340;&#21333;&#35843;&#36882;&#22686;&#26144;&#23556;&#37325;&#26032;&#32553;&#25918;&#31890;&#23376;&#28436;&#21270;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#37492;&#21035;&#22120;&#33719;&#24471;MonoFlow&#30340;&#21521;&#37327;&#22330;&#65292;&#21033;&#29992;&#30456;&#24212;&#30340;&#21521;&#37327;&#22330;&#36827;&#34892;&#31890;&#23376;&#27969;&#30340;&#29983;&#25104;&#12290;</title><link>http://arxiv.org/abs/2302.01075</link><description>&lt;p&gt;
MonoFlow: &#20174;Wasserstein&#26799;&#24230;&#27969;&#30340;&#35282;&#24230;&#37325;&#26032;&#24605;&#32771;Divergence GANs
&lt;/p&gt;
&lt;p&gt;
MonoFlow: Rethinking Divergence GANs via the Perspective of Wasserstein Gradient Flows. (arXiv:2302.01075v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.01075
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;GAN&#29983;&#25104;&#24314;&#27169;&#26694;&#26550;MonoFlow&#65292;&#36890;&#36807;Wasserstein&#26799;&#24230;&#27969;&#33719;&#24471;&#29702;&#35770;&#27934;&#35265;&#21644;&#31639;&#27861;&#21551;&#31034;&#12290;&#35813;&#26694;&#26550;&#20351;&#29992;&#23494;&#24230;&#27604;&#20363;&#30340;&#21333;&#35843;&#36882;&#22686;&#26144;&#23556;&#37325;&#26032;&#32553;&#25918;&#31890;&#23376;&#28436;&#21270;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#37492;&#21035;&#22120;&#33719;&#24471;MonoFlow&#30340;&#21521;&#37327;&#22330;&#65292;&#21033;&#29992;&#30456;&#24212;&#30340;&#21521;&#37327;&#22330;&#36827;&#34892;&#31890;&#23376;&#27969;&#30340;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#19978;&#65292;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#30340;&#23545;&#25239;&#35757;&#32451;&#26159;&#36890;&#36807;&#21028;&#21035;&#22120;&#26469;&#20272;&#35745;&#31163;&#25955;&#24230;&#65292;&#29983;&#25104;&#22120;&#23398;&#20064;&#26368;&#23567;&#21270;&#36825;&#20010;&#31163;&#25955;&#24230;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#23613;&#31649;&#35768;&#22810;GANs&#21464;&#20307;&#37117;&#26159;&#25353;&#29031;&#36825;&#20010;&#33539;&#20363;&#24320;&#21457;&#30340;&#65292;&#20294;&#24403;&#21069;GANs&#30340;&#29702;&#35770;&#29702;&#35299;&#21644;&#23454;&#38469;&#31639;&#27861;&#26159;&#19981;&#19968;&#33268;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#36890;&#36807;&#21033;&#29992;&#23637;&#31034;&#20102;&#26679;&#26412;&#31354;&#38388;&#20869;&#31890;&#23376;&#28436;&#21270;&#30340;Wasserstein&#26799;&#24230;&#27969;&#26469;&#33719;&#24471;GANs&#30340;&#29702;&#35770;&#27934;&#35265;&#21644;&#31639;&#27861;&#21551;&#31034;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#29983;&#25104;&#24314;&#27169;&#26694;&#26550;MonoFlow&#65306;&#31890;&#23376;&#28436;&#21270;&#36890;&#36807;&#23494;&#24230;&#27604;&#20363;&#30340;&#21333;&#35843;&#36882;&#22686;&#26144;&#23556;&#36827;&#34892;&#37325;&#26032;&#32553;&#25918;&#12290;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#19979;&#65292;&#23545;&#25239;&#24615;&#35757;&#32451;&#21487;&#20197;&#34987;&#35270;&#20026;&#19968;&#20010;&#36807;&#31243;&#65292;&#39318;&#20808;&#36890;&#36807;&#35757;&#32451;&#37492;&#21035;&#22120;&#33719;&#24471;MonoFlow&#30340;&#21521;&#37327;&#22330;&#65292;&#28982;&#21518;&#29983;&#25104;&#22120;&#23398;&#20064;&#30001;&#30456;&#24212;&#21521;&#37327;&#22330;&#25152;&#23450;&#20041;&#30340;&#31890;&#23376;&#27969;&#12290;
&lt;/p&gt;
&lt;p&gt;
The conventional understanding of adversarial training in generative adversarial networks (GANs) is that the discriminator is trained to estimate a divergence, and the generator learns to minimize this divergence. We argue that despite the fact that many variants of GANs were developed following this paradigm, the current theoretical understanding of GANs and their practical algorithms are inconsistent. In this paper, we leverage Wasserstein gradient flows which characterize the evolution of particles in the sample space, to gain theoretical insights and algorithmic inspiration of GANs. We introduce a unified generative modeling framework - MonoFlow: the particle evolution is rescaled via a monotonically increasing mapping of the log density ratio. Under our framework, adversarial training can be viewed as a procedure first obtaining MonoFlow's vector field via training the discriminator and the generator learns to draw the particle flow defined by the corresponding vector field. We al
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38544;&#24335;&#24352;&#37327;&#20998;&#35299;&#30697;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#20272;&#35745;&#26465;&#20214;&#29420;&#31435;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#26080;&#38656;&#23545;&#20998;&#24067;&#36827;&#34892;&#21442;&#25968;&#21270;&#65292;&#36890;&#36807;&#24320;&#21457;&#39640;&#25928;&#30340;&#26080;&#24352;&#37327;&#25805;&#20316;&#65292;&#23454;&#29616;&#20102;&#35745;&#31639;&#19978;&#30340;&#21487;&#34892;&#24615;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#31454;&#20105;&#24615;&#33021;&#65292;&#24182;&#24314;&#31435;&#20102;&#28151;&#21512;&#29289;&#30340;&#21487;&#35782;&#21035;&#24615;&#12290;</title><link>http://arxiv.org/abs/2210.14386</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;&#28151;&#21512;&#27169;&#22411;&#30340;&#38544;&#24335;&#24352;&#37327;&#20998;&#35299;&#30697;&#20272;&#35745;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Moment Estimation for Nonparametric Mixture Models Through Implicit Tensor Decomposition. (arXiv:2210.14386v2 [math.NA] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.14386
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38544;&#24335;&#24352;&#37327;&#20998;&#35299;&#30697;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#20272;&#35745;&#26465;&#20214;&#29420;&#31435;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#26080;&#38656;&#23545;&#20998;&#24067;&#36827;&#34892;&#21442;&#25968;&#21270;&#65292;&#36890;&#36807;&#24320;&#21457;&#39640;&#25928;&#30340;&#26080;&#24352;&#37327;&#25805;&#20316;&#65292;&#23454;&#29616;&#20102;&#35745;&#31639;&#19978;&#30340;&#21487;&#34892;&#24615;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#31454;&#20105;&#24615;&#33021;&#65292;&#24182;&#24314;&#31435;&#20102;&#28151;&#21512;&#29289;&#30340;&#21487;&#35782;&#21035;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20132;&#26367;&#26368;&#23567;&#20108;&#20056;&#22411;&#30340;&#25968;&#20540;&#20248;&#21270;&#26041;&#26696;&#29992;&#20110;&#22312; $\mathbb{R}^n$ &#20013;&#20272;&#35745;&#26465;&#20214;&#29420;&#31435;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#26080;&#38656;&#23545;&#20998;&#24067;&#36827;&#34892;&#21442;&#25968;&#21270;&#12290;&#26681;&#25454;&#30697;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#19968;&#20010;&#19981;&#23436;&#25972;&#30340;&#24352;&#37327;&#20998;&#35299;&#38382;&#39064;&#20197;&#23398;&#20064;&#28151;&#21512;&#26435;&#37325;&#21644;&#21508;&#20998;&#37327;&#30340;&#22343;&#20540;&#12290;&#28982;&#21518;&#65292;&#36890;&#36807;&#32447;&#24615;&#27714;&#35299;&#65292;&#35745;&#31639;&#20998;&#37327;&#20998;&#24067;&#30340;&#32047;&#31215;&#20998;&#24067;&#20989;&#25968;&#12289;&#39640;&#38454;&#30697;&#21644;&#20854;&#20182;&#32479;&#35745;&#37327;&#12290;&#36890;&#36807;&#24320;&#21457;&#39640;&#25928;&#30340;&#26080;&#24352;&#37327;&#25805;&#20316;&#65292;&#36991;&#20813;&#20102;&#39640;&#38454;&#24352;&#37327;&#25152;&#24102;&#26469;&#30340;&#39640;&#25104;&#26412;&#38382;&#39064;&#65292;&#20351;&#24471;&#35745;&#31639;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#26356;&#21152;&#21487;&#34892;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#30340;&#31454;&#20105;&#24615;&#33021;&#65292;&#24182;&#19988;&#23427;&#36866;&#29992;&#20110;&#35768;&#22810;&#27169;&#22411;&#21644;&#24212;&#29992;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#20174;&#28151;&#21512;&#29289;&#30340;&#20302;&#38454;&#30697;&#20013;&#24314;&#31435;&#20102;&#21487;&#35782;&#21035;&#24615;&#65292;&#24182;&#20445;&#35777;&#20102; ALS &#31639;&#27861;&#30340;&#23616;&#37096;&#32447;&#24615;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present an alternating least squares type numerical optimization scheme to estimate conditionally-independent mixture models in $\mathbb{R}^n$, without parameterizing the distributions. Following the method of moments, we tackle an incomplete tensor decomposition problem to learn the mixing weights and componentwise means. Then we compute the cumulative distribution functions, higher moments and other statistics of the component distributions through linear solves. Crucially for computations in high dimensions, the steep costs associated with high-order tensors are evaded, via the development of efficient tensor-free operations. Numerical experiments demonstrate the competitive performance of the algorithm, and its applicability to many models and applications. Furthermore we provide theoretical analyses, establishing identifiability from low-order moments of the mixture and guaranteeing local linear convergence of the ALS algorithm.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#35299;&#20915;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22797;&#21512;&#26816;&#39564;&#38382;&#39064;&#65292;&#20854;&#26680;&#24515;&#24605;&#24819;&#26159;&#22312;&#27491;&#30830;&#30340;&#27169;&#22411;&#35268;&#33539;&#30340;&#38646;&#20551;&#35774;&#19979;&#65292;&#38750;&#21442;&#25968;&#22320;&#20272;&#35745;&#21442;&#25968;&#65288;&#25110;&#27169;&#25311;&#22120;&#65289;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2111.10275</link><description>&lt;p&gt;
&#24102;&#26377;&#26680;&#30340;&#22797;&#21512;&#36866;&#21512;&#24615;&#26816;&#39564;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Composite Goodness-of-fit Tests with Kernels. (arXiv:2111.10275v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.10275
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#35299;&#20915;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22797;&#21512;&#26816;&#39564;&#38382;&#39064;&#65292;&#20854;&#26680;&#24515;&#24605;&#24819;&#26159;&#22312;&#27491;&#30830;&#30340;&#27169;&#22411;&#35268;&#33539;&#30340;&#38646;&#20551;&#35774;&#19979;&#65292;&#38750;&#21442;&#25968;&#22320;&#20272;&#35745;&#21442;&#25968;&#65288;&#25110;&#27169;&#25311;&#22120;&#65289;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#38169;&#35823;&#35828;&#26126;&#21487;&#33021;&#20250;&#23545;&#27010;&#29575;&#27169;&#22411;&#30340;&#23454;&#29616;&#36896;&#25104;&#37325;&#22823;&#25361;&#25112;&#65292;&#36825;&#20419;&#20351;&#24320;&#21457;&#20986;&#19968;&#20123;&#30452;&#25509;&#35299;&#20915;&#27492;&#38382;&#39064;&#30340;&#40065;&#26834;&#26041;&#27861;&#12290;&#20294;&#26159;&#65292;&#36825;&#20123;&#26356;&#20026;&#22797;&#26434;&#30340;&#26041;&#27861;&#26159;&#21542;&#38656;&#35201;&#21462;&#20915;&#20110;&#27169;&#22411;&#26159;&#21542;&#30495;&#30340;&#38169;&#35823;&#65292;&#30446;&#21069;&#32570;&#20047;&#36890;&#29992;&#30340;&#26041;&#27861;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#26680;&#30340;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22797;&#21512;&#26816;&#39564;&#38382;&#39064;&#65292;&#21363;&#25105;&#20204;&#26159;&#21542;&#24863;&#20852;&#36259;&#30340;&#25968;&#25454;&#26469;&#33258;&#26576;&#20123;&#21442;&#25968;&#27169;&#22411;&#26063;&#20013;&#30340;&#20219;&#20309;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#27979;&#35797;&#21033;&#29992;&#22522;&#20110;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#21644;&#26680;Stein&#24046;&#24322;&#30340;&#26368;&#23567;&#36317;&#31163;&#20272;&#35745;&#22120;&#12290;&#23427;&#20204;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#65292;&#21253;&#25324;&#24403;&#21442;&#25968;&#27169;&#22411;&#30340;&#23494;&#24230;&#24050;&#30693;&#38500;&#26631;&#20934;&#21270;&#24120;&#25968;&#22806;&#65292;&#25110;&#32773;&#22914;&#26524;&#27169;&#22411;&#37319;&#29992;&#27169;&#25311;&#22120;&#24418;&#24335;&#12290;&#20316;&#20026;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#27491;&#30830;&#30340;&#27169;&#22411;&#35268;&#33539;&#30340;&#38646;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#33021;&#22815;&#38750;&#21442;&#25968;&#22320;&#20272;&#35745;&#21442;&#25968;&#65288;&#25110;&#27169;&#25311;&#22120;&#65289;&#20998;&#24067;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#24314;&#31435;&#25105;&#20204;&#26041;&#27861;&#26377;&#25928;&#24615;&#30340;&#29702;&#35770;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#21644;&#24322;&#24120;&#26816;&#27979;&#24212;&#29992;&#26696;&#20363;&#28436;&#31034;&#20102;&#20854;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model misspecification can create significant challenges for the implementation of probabilistic models, and this has led to development of a range of robust methods which directly account for this issue. However, whether these more involved methods are required will depend on whether the model is really misspecified, and there is a lack of generally applicable methods to answer this question. In this paper, we propose one such method. More precisely, we propose kernel-based hypothesis tests for the challenging composite testing problem, where we are interested in whether the data comes from any distribution in some parametric family. Our tests make use of minimum distance estimators based on the maximum mean discrepancy and the kernel Stein discrepancy. They are widely applicable, including whenever the density of the parametric model is known up to normalisation constant, or if the model takes the form of a simulator. As our main result, we show that we are able to estimate the param
&lt;/p&gt;</description></item><item><title>&#39640;&#26031;&#36807;&#31243;&#25554;&#20540;&#20013;&#30340;&#21442;&#25968;&#36873;&#25321;&#26159;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65292;&#26412;&#25991;&#36890;&#36807;&#35780;&#20998;&#35268;&#21017;&#21644;&#25193;&#23637;&#20284;&#28982;&#26631;&#20934;&#30340;&#26694;&#26550;&#30740;&#31350;&#20102;&#36873;&#25321;&#36866;&#24403;&#30340;&#27169;&#22411;&#26063;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2107.06006</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#25554;&#20540;&#20013;&#30340;&#21442;&#25968;&#36873;&#25321;&#65306;&#36873;&#25321;&#26631;&#20934;&#30340;&#23454;&#35777;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Parameter selection in Gaussian process interpolation: an empirical study of selection criteria. (arXiv:2107.06006v5 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.06006
&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#25554;&#20540;&#20013;&#30340;&#21442;&#25968;&#36873;&#25321;&#26159;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65292;&#26412;&#25991;&#36890;&#36807;&#35780;&#20998;&#35268;&#21017;&#21644;&#25193;&#23637;&#20284;&#28982;&#26631;&#20934;&#30340;&#26694;&#26550;&#30740;&#31350;&#20102;&#36873;&#25321;&#36866;&#24403;&#30340;&#27169;&#22411;&#26063;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#32771;&#34385;&#20102;&#39640;&#26031;&#36807;&#31243;&#25554;&#20540;&#20013;&#30340;&#21442;&#25968;&#36873;&#25321;&#38382;&#39064;&#12290;&#36890;&#36807;&#22312;&#21442;&#25968;&#21270;&#26063;&#20013;&#36873;&#25321;&#39640;&#26031;&#36807;&#31243;&#30340;&#22343;&#20540;&#21644;&#21327;&#26041;&#24046;&#20989;&#25968;&#65292;&#29992;&#25143;&#21487;&#20197;&#33719;&#24471;&#19968;&#26063;&#36125;&#21494;&#26031;&#31243;&#24207;&#65292;&#29992;&#20110;&#23545;&#26410;&#30693;&#20989;&#25968;&#36827;&#34892;&#39044;&#27979;&#65292;&#24182;&#19988;&#24517;&#39035;&#36873;&#25321;&#19968;&#20010;&#24076;&#26395;&#33021;&#22815;&#25552;&#20379;&#33391;&#22909;&#39044;&#27979;&#24615;&#33021;&#30340;&#25104;&#21592;&#12290;&#25105;&#20204;&#22522;&#20110;&#35780;&#20998;&#35268;&#21017;&#30340;&#22522;&#26412;&#27010;&#24565;&#36827;&#34892;&#30740;&#31350;&#65292;&#22312;&#24314;&#31435;&#30041;&#19968;&#27861;&#36873;&#25321;&#21644;&#39564;&#35777;&#26631;&#20934;&#20197;&#21450;&#22522;&#20110;Fasshauer&#31561;&#20154;&#22312;2009&#24180;&#25552;&#20986;&#30340;&#24605;&#24819;&#30340;&#25193;&#23637;&#20284;&#28982;&#26631;&#20934;&#30340;&#26377;&#25928;&#26694;&#26550;&#19978;&#65292;&#24674;&#22797;&#20102;&#35832;&#22914;&#24191;&#20041;&#20132;&#21449;&#39564;&#35777;&#20934;&#21017;&#20043;&#31867;&#30340;&#26631;&#20934;&#36873;&#25321;&#26631;&#20934;&#12290;&#22312;&#36825;&#20010;&#35774;&#23450;&#19979;&#65292;&#25105;&#20204;&#36890;&#36807;&#23545;&#25991;&#29486;&#20013;&#30340;&#20960;&#20010;&#27979;&#35797;&#38382;&#39064;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#36873;&#25321;&#36866;&#24403;&#30340;&#27169;&#22411;&#26063;&#24448;&#24448;&#27604;&#36873;&#25321;&#29305;&#23450;&#30340;&#36873;&#25321;&#20934;&#21017;&#26356;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article revisits the fundamental problem of parameter selection for Gaussian process interpolation. By choosing the mean and the covariance functions of a Gaussian process within parametric families, the user obtains a family of Bayesian procedures to perform predictions about the unknown function, and must choose a member of the family that will hopefully provide good predictive performances. We base our study on the general concept of scoring rules, which provides an effective framework for building leave-one-out selection and validation criteria, and a notion of extended likelihood criteria based on an idea proposed by Fasshauer and co-authors in 2009, which makes it possible to recover standard selection criteria such as, for instance, the generalized cross-validation criterion. Under this setting, we empirically show on several test problems of the literature that the choice of an appropriate family of models is often more important than the choice of a particular selection c
&lt;/p&gt;</description></item><item><title>&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#25552;&#20379;&#20102;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#20294;&#20854;&#36125;&#21494;&#26031;&#24615;&#36136;&#38480;&#21046;&#20102;&#20854;&#22312;&#26576;&#20123;&#37325;&#35201;&#24212;&#29992;&#20013;&#30340;&#20351;&#29992;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23454;&#29992;&#19988;&#20005;&#26684;&#30340;&#19981;&#30830;&#23450;&#24615;&#30028;&#38480;&#65292;&#30456;&#27604;&#29616;&#26377;&#32467;&#26524;&#26356;&#20934;&#30830;&#65292;&#24182;&#19988;&#23545;&#27169;&#22411;&#20559;&#24046;&#26377;&#20248;&#38597;&#30340;&#36864;&#21270;&#12290;</title><link>http://arxiv.org/abs/2105.02796</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#23454;&#29992;&#19988;&#20005;&#26684;&#30340;&#19981;&#30830;&#23450;&#24615;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Practical and Rigorous Uncertainty Bounds for Gaussian Process Regression. (arXiv:2105.02796v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.02796
&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#25552;&#20379;&#20102;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#20294;&#20854;&#36125;&#21494;&#26031;&#24615;&#36136;&#38480;&#21046;&#20102;&#20854;&#22312;&#26576;&#20123;&#37325;&#35201;&#24212;&#29992;&#20013;&#30340;&#20351;&#29992;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23454;&#29992;&#19988;&#20005;&#26684;&#30340;&#19981;&#30830;&#23450;&#24615;&#30028;&#38480;&#65292;&#30456;&#27604;&#29616;&#26377;&#32467;&#26524;&#26356;&#20934;&#30830;&#65292;&#24182;&#19988;&#23545;&#27169;&#22411;&#20559;&#24046;&#26377;&#20248;&#38597;&#30340;&#36864;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#26159;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#21407;&#29702;&#30340;&#27969;&#34892;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#26041;&#27861;&#65292;&#21487;&#20197;&#25552;&#20379;&#20854;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#20272;&#35745;&#26159;&#36125;&#21494;&#26031;&#24615;&#36136;&#30340;&#65292;&#23545;&#20110;&#19968;&#20123;&#37325;&#35201;&#30340;&#24212;&#29992;&#65292;&#22914;&#20855;&#26377;&#23433;&#20840;&#20445;&#35777;&#30340;&#22522;&#20110;&#23398;&#20064;&#30340;&#25511;&#21046;&#65292;&#38656;&#35201;&#39057;&#29575;&#30340;&#19981;&#30830;&#23450;&#24615;&#30028;&#38480;&#12290;&#23613;&#31649;&#23545;&#20110;&#39640;&#26031;&#36807;&#31243;&#65292;&#36825;&#26679;&#20005;&#26684;&#30340;&#30028;&#38480;&#26377;&#21487;&#29992;&#65292;&#20294;&#23427;&#20204;&#36807;&#20110;&#20445;&#23432;&#65292;&#22312;&#24212;&#29992;&#20013;&#27809;&#26377;&#29992;&#22788;&#12290;&#36825;&#36890;&#24120;&#23548;&#33268;&#23454;&#36341;&#32773;&#29992;&#21551;&#21457;&#24335;&#26041;&#27861;&#26367;&#20195;&#36825;&#20123;&#30028;&#38480;&#65292;&#20174;&#32780;&#30772;&#22351;&#20102;&#25152;&#26377;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#30028;&#38480;&#65292;&#26082;&#20005;&#26684;&#21448;&#23454;&#29992;&#12290;&#29305;&#21035;&#22320;&#65292;&#36825;&#20123;&#30028;&#38480;&#21487;&#20197;&#26126;&#30830;&#22320;&#35780;&#20272;&#65292;&#24182;&#19988;&#27604;&#29616;&#26377;&#32467;&#26524;&#35201;&#20445;&#23432;&#24471;&#22810;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#26576;&#20123;&#27169;&#22411;&#20559;&#24046;&#21482;&#20250;&#24341;&#36215;&#20248;&#38597;&#30340;&#36864;&#21270;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#20248;&#21183;&#20197;&#21450;&#25105;&#20204;&#32467;&#26524;&#22312;&#22522;&#20110;&#23398;&#20064;&#30340;&#25511;&#21046;&#20013;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian Process Regression is a popular nonparametric regression method based on Bayesian principles that provides uncertainty estimates for its predictions. However, these estimates are of a Bayesian nature, whereas for some important applications, like learning-based control with safety guarantees, frequentist uncertainty bounds are required. Although such rigorous bounds are available for Gaussian Processes, they are too conservative to be useful in applications. This often leads practitioners to replacing these bounds by heuristics, thus breaking all theoretical guarantees. To address this problem, we introduce new uncertainty bounds that are rigorous, yet practically useful at the same time. In particular, the bounds can be explicitly evaluated and are much less conservative than state of the art results. Furthermore, we show that certain model misspecifications lead to only graceful degradation. We demonstrate these advantages and the usefulness of our results for learning-based
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#36125;&#21494;&#26031;&#32593;&#32476;&#32467;&#26500;&#23398;&#20064;&#30340;&#27169;&#25311;&#36864;&#28779;&#26426;&#22120;&#26041;&#27861;&#65292;&#36890;&#36807;&#20808;&#36827;&#30340;&#20505;&#36873;&#29238;&#33410;&#28857;&#38598;&#21512;&#30340;&#30830;&#23450;&#21644;&#20998;&#35299;&#65292;&#20197;&#21450;&#25972;&#25968;&#35268;&#21010;&#38382;&#39064;&#30340;&#35299;&#20915;&#65292;&#33021;&#22815;&#22312;&#27604;&#29305;&#23481;&#37327;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#39640;&#25928;&#22320;&#35299;&#20915;&#22522;&#20110;&#35780;&#20998;&#30340;&#23398;&#20064;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2006.06926</link><description>&lt;p&gt;
&#29992;&#27169;&#25311;&#36864;&#28779;&#26426;&#22120;&#23398;&#20064;&#36125;&#21494;&#26031;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Learning Bayesian Networks with Annealing Machine. (arXiv:2006.06926v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.06926
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#36125;&#21494;&#26031;&#32593;&#32476;&#32467;&#26500;&#23398;&#20064;&#30340;&#27169;&#25311;&#36864;&#28779;&#26426;&#22120;&#26041;&#27861;&#65292;&#36890;&#36807;&#20808;&#36827;&#30340;&#20505;&#36873;&#29238;&#33410;&#28857;&#38598;&#21512;&#30340;&#30830;&#23450;&#21644;&#20998;&#35299;&#65292;&#20197;&#21450;&#25972;&#25968;&#35268;&#21010;&#38382;&#39064;&#30340;&#35299;&#20915;&#65292;&#33021;&#22815;&#22312;&#27604;&#29305;&#23481;&#37327;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#39640;&#25928;&#22320;&#35299;&#20915;&#22522;&#20110;&#35780;&#20998;&#30340;&#23398;&#20064;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#27169;&#25311;&#36864;&#28779;&#26426;&#22120;&#33021;&#22815;&#39640;&#31934;&#24230;&#22320;&#35299;&#20915;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#12290;&#27169;&#25311;&#36864;&#28779;&#26426;&#22120;&#26377;&#28508;&#21147;&#29992;&#20110;&#22522;&#20110;&#35780;&#20998;&#30340;&#36125;&#21494;&#26031;&#32593;&#32476;&#32467;&#26500;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#27169;&#25311;&#36864;&#28779;&#26426;&#22120;&#30340;&#27604;&#29305;&#23481;&#37327;&#30446;&#21069;&#26377;&#38480;&#12290;&#20026;&#20102;&#21033;&#29992;&#27169;&#25311;&#36864;&#28779;&#25216;&#26415;&#65292;&#38656;&#35201;&#23558;&#22522;&#20110;&#35780;&#20998;&#30340;&#23398;&#20064;&#38382;&#39064;&#36716;&#21270;&#20026;&#22312;&#27604;&#29305;&#23481;&#37327;&#20869;&#30340;&#20108;&#27425;&#26080;&#32422;&#26463;&#20108;&#20803;&#20248;&#21270;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#36716;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#20808;&#36827;&#30340;&#20505;&#36873;&#29238;&#33410;&#28857;&#38598;&#21512;&#30340;&#30830;&#23450;&#21644;&#20854;&#20998;&#35299;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#25972;&#25968;&#35268;&#21010;&#38382;&#39064;&#65292;&#20197;&#25214;&#21040;&#26368;&#23567;&#21270;&#25152;&#38656;&#27604;&#29305;&#25968;&#30340;&#20998;&#35299;&#12290;&#22312;&#21253;&#21547;&#21464;&#37327;&#20174;75&#21040;223&#30340;7&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25152;&#38656;&#30340;&#27604;&#29305;&#25968;&#27604;&#22235;&#20195;&#23500;&#22763;&#36890;&#25968;&#23383;&#36864;&#28779;&#22120;&#65288;&#19968;&#31181;&#37319;&#29992;&#21322;&#23548;&#20307;&#25216;&#26415;&#24320;&#21457;&#30340;&#20840;&#32806;&#21512;&#27169;&#25311;&#36864;&#28779;&#26426;&#22120;&#65289;&#30340;100K&#27604;&#29305;&#23481;&#37327;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies have reported that annealing machines are capable of solving combinatorial optimization problems with high accuracy. Annealing machines can potentially be applied to score-based Bayesian network structure learning. However, the bit capacity of an annealing machine is currently limited. To utilize the annealing technology, converting score-based learning problems into quadratic unconstrained binary optimizations within the bit capacity is necessary. In this paper, we propose an efficient conversion method with the advanced identification of candidate parent sets and their decomposition. We also provide an integer programming problem to find the decomposition that minimizes the number of required bits. Experimental results on $7$ benchmark datasets with variables from $75$ to $223$ show that our approach requires less bits than the $100$K bit capacity of the fourth-generation Fujitsu Digital Annealer, a fully coupled annealing machine developed with semiconductor technolog
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#21028;&#21035;&#22120;&#20248;&#21270;&#36807;&#31243;&#22914;&#20309;&#22686;&#21152;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#20013;Wasserstein&#36317;&#31163;&#30340;&#23545;&#20598;&#20195;&#20215;&#20989;&#25968;&#30340;&#19979;&#38480;&#65292;&#20174;&#32780;&#20351;&#35757;&#32451;&#22909;&#30340;&#21028;&#21035;&#22120;&#33021;&#22815;&#36817;&#20284;&#26368;&#20248;&#36755;&#36816;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#21028;&#21035;&#22120;&#26368;&#20248;&#36755;&#36816;&#65288;DOT&#65289;&#26041;&#26696;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#30340;&#29983;&#25104;&#22270;&#20687;&#36136;&#37327;&#26377;&#25152;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/1910.06832</link><description>&lt;p&gt;
&#21028;&#21035;&#22120;&#26368;&#20248;&#36755;&#36816;
&lt;/p&gt;
&lt;p&gt;
Discriminator optimal transport. (arXiv:1910.06832v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1910.06832
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#21028;&#21035;&#22120;&#20248;&#21270;&#36807;&#31243;&#22914;&#20309;&#22686;&#21152;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#20013;Wasserstein&#36317;&#31163;&#30340;&#23545;&#20598;&#20195;&#20215;&#20989;&#25968;&#30340;&#19979;&#38480;&#65292;&#20174;&#32780;&#20351;&#35757;&#32451;&#22909;&#30340;&#21028;&#21035;&#22120;&#33021;&#22815;&#36817;&#20284;&#26368;&#20248;&#36755;&#36816;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#21028;&#21035;&#22120;&#26368;&#20248;&#36755;&#36816;&#65288;DOT&#65289;&#26041;&#26696;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#30340;&#29983;&#25104;&#22270;&#20687;&#36136;&#37327;&#26377;&#25152;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24191;&#27867;&#30340;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21028;&#21035;&#22120;&#20248;&#21270;&#36807;&#31243;&#22686;&#21152;&#20102;&#30446;&#26631;&#20998;&#24067;$p$&#21644;&#29983;&#25104;&#22120;&#20998;&#24067;$p_G$&#20043;&#38388;Wasserstein&#36317;&#31163;&#30340;&#23545;&#20598;&#20195;&#20215;&#20989;&#25968;&#30340;&#19979;&#38480;&#12290;&#36825;&#24847;&#21619;&#30528;&#35757;&#32451;&#22909;&#30340;&#21028;&#21035;&#22120;&#21487;&#20197;&#36817;&#20284;&#20174;$p_G$&#21040;$p$&#30340;&#26368;&#20248;&#36755;&#36816;&#12290;&#22522;&#20110;&#19968;&#20123;&#23454;&#39564;&#21644;&#19968;&#28857;&#36755;&#36816;&#29702;&#35770;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21028;&#21035;&#22120;&#26368;&#20248;&#36755;&#36816;&#65288;DOT&#65289;&#26041;&#26696;&#26469;&#25913;&#36827;&#29983;&#25104;&#30340;&#22270;&#20687;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#23427;&#22312;CIFAR-10&#12289;STL-10&#21644;&#19968;&#20010;&#20197;ImageNet&#20026;&#26465;&#20214;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#35757;&#32451;&#30340;&#26080;&#26465;&#20214;GAN&#35745;&#31639;&#30340;&#20869;&#28085;&#20998;&#25968;&#21644;FID&#19978;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Within a broad class of generative adversarial networks, we show that discriminator optimization process increases a lower bound of the dual cost function for the Wasserstein distance between the target distribution $p$ and the generator distribution $p_G$. It implies that the trained discriminator can approximate optimal transport (OT) from $p_G$ to $p$.Based on some experiments and a bit of OT theory, we propose a discriminator optimal transport (DOT) scheme to improve generated images. We show that it improves inception score and FID calculated by un-conditional GAN trained by CIFAR-10, STL-10 and a public pre-trained model of conditional GAN by ImageNet.
&lt;/p&gt;</description></item></channel></rss>