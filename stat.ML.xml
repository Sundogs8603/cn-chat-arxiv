<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#29983;&#25104;&#29109;&#31070;&#32463;&#26368;&#20248;&#20256;&#36755;&#22312;&#27979;&#24230;&#21040;&#27979;&#24230;&#26144;&#23556;&#20013;&#30340;&#24212;&#29992;&#65292;&#35299;&#20915;&#20102;&#22788;&#29702;&#38750;&#24179;&#26041;&#27431;&#27663;&#36317;&#31163;&#25104;&#26412;&#12289;&#30830;&#23450;&#24615;&#33945;&#26684;&#26144;&#23556;&#12289;&#26144;&#23556;&#36328;&#19981;&#21487;&#27604;&#36739;&#31354;&#38388;&#21644;&#36136;&#37327;&#23432;&#24658;&#32422;&#26463;&#31561;&#23454;&#38469;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2310.09254</link><description>&lt;p&gt;
&#29983;&#25104;&#29109;&#31070;&#32463;&#26368;&#20248;&#20256;&#36755;&#22312;&#31354;&#38388;&#20869;&#22806;&#26144;&#23556;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Generative Entropic Neural Optimal Transport To Map Within and Across Spaces. (arXiv:2310.09254v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09254
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#29983;&#25104;&#29109;&#31070;&#32463;&#26368;&#20248;&#20256;&#36755;&#22312;&#27979;&#24230;&#21040;&#27979;&#24230;&#26144;&#23556;&#20013;&#30340;&#24212;&#29992;&#65292;&#35299;&#20915;&#20102;&#22788;&#29702;&#38750;&#24179;&#26041;&#27431;&#27663;&#36317;&#31163;&#25104;&#26412;&#12289;&#30830;&#23450;&#24615;&#33945;&#26684;&#26144;&#23556;&#12289;&#26144;&#23556;&#36328;&#19981;&#21487;&#27604;&#36739;&#31354;&#38388;&#21644;&#36136;&#37327;&#23432;&#24658;&#32422;&#26463;&#31561;&#23454;&#38469;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#27979;&#24230;&#21040;&#27979;&#24230;&#30340;&#26144;&#23556;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#20219;&#21153;&#65292;&#23588;&#20854;&#22312;&#29983;&#25104;&#24314;&#27169;&#20013;&#21344;&#25454;&#37325;&#35201;&#22320;&#20301;&#12290;&#36817;&#24180;&#26469;&#65292;&#21463;&#26368;&#20248;&#20256;&#36755;&#29702;&#35770;&#21551;&#21457;&#30340;&#25216;&#26415;&#19981;&#26029;&#28044;&#29616;&#12290;&#32467;&#21512;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#36825;&#20123;&#26041;&#27861;&#32479;&#31216;&#20026;"&#31070;&#32463;&#26368;&#20248;&#20256;&#36755;"&#65292;&#23558;&#26368;&#20248;&#20256;&#36755;&#20316;&#20026;&#24402;&#32435;&#20559;&#22909;&#65306;&#36825;&#20123;&#26144;&#23556;&#24212;&#35813;&#38024;&#23545;&#32473;&#23450;&#30340;&#25104;&#26412;&#20989;&#25968;&#26159;&#26368;&#20248;&#30340;&#65292;&#33021;&#20197;&#33410;&#32422;&#30340;&#26041;&#24335;&#65288;&#36890;&#36807;&#26368;&#23567;&#21270;&#20301;&#31227;&#65289;&#22312;&#31354;&#38388;&#20869;&#25110;&#31354;&#38388;&#38388;&#31227;&#21160;&#28857;&#12290;&#36825;&#19968;&#21407;&#21017;&#22312;&#30452;&#35266;&#19978;&#26159;&#21512;&#29702;&#30340;&#65292;&#20294;&#24448;&#24448;&#38754;&#20020;&#20960;&#20010;&#23454;&#38469;&#25361;&#25112;&#65292;&#38656;&#35201;&#35843;&#25972;&#26368;&#20248;&#20256;&#36755;&#24037;&#20855;&#31665;&#65306;&#22788;&#29702;&#20854;&#20182;&#38750;&#24179;&#26041;&#27431;&#27663;&#36317;&#31163;&#25104;&#26412;&#30340;&#25361;&#25112;&#65292;&#30830;&#23450;&#24615;&#29366;&#20917;&#19979;&#30340;&#33945;&#26684;&#26144;&#23556;&#20844;&#24335;&#20250;&#38480;&#21046;&#28789;&#27963;&#24615;&#65292;&#26144;&#23556;&#22312;&#19981;&#21487;&#27604;&#36739;&#30340;&#31354;&#38388;&#20013;&#20250;&#24102;&#26469;&#22810;&#20010;&#25361;&#25112;&#65292;&#26368;&#20248;&#20256;&#36755;&#22266;&#26377;&#30340;&#36136;&#37327;&#23432;&#24658;&#32422;&#26463;&#21487;&#33021;&#23545;&#24322;&#24120;&#25968;&#25454;&#32473;&#20104;&#36807;&#22810;&#30340;&#37325;&#35270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning measure-to-measure mappings is a crucial task in machine learning, featured prominently in generative modeling. Recent years have witnessed a surge of techniques that draw inspiration from optimal transport (OT) theory. Combined with neural network models, these methods collectively known as \textit{Neural OT} use optimal transport as an inductive bias: such mappings should be optimal w.r.t. a given cost function, in the sense that they are able to move points in a thrifty way, within (by minimizing displacements) or across spaces (by being isometric). This principle, while intuitive, is often confronted with several practical challenges that require adapting the OT toolbox: cost functions other than the squared-Euclidean cost can be challenging to handle, the deterministic formulation of Monge maps leaves little flexibility, mapping across incomparable spaces raises multiple challenges, while the mass conservation constraint inherent to OT can provide too much credit to outli
&lt;/p&gt;</description></item><item><title>&#22312;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#20998;&#31867;&#27169;&#22411;&#38598;&#21512;&#20013;&#65292;&#23545;&#20110;&#27491;&#30830;&#20998;&#31867;&#30340;&#26679;&#26412;&#28857;&#65292;&#20559;&#24046;&#21644;&#26041;&#24046;&#22312;&#26679;&#26412;&#32423;&#21035;&#19978;&#26159;&#23545;&#40784;&#30340;&#12290;</title><link>http://arxiv.org/abs/2310.09250</link><description>&lt;p&gt;
&#23427;&#26159;&#19968;&#31181;&#23545;&#40784;&#65292;&#32780;&#19981;&#26159;&#26435;&#34913;&#65306;&#37325;&#26032;&#23457;&#35270;&#28145;&#24230;&#27169;&#22411;&#20013;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;
&lt;/p&gt;
&lt;p&gt;
It's an Alignment, Not a Trade-off: Revisiting Bias and Variance in Deep Models. (arXiv:2310.09250v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09250
&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#20998;&#31867;&#27169;&#22411;&#38598;&#21512;&#20013;&#65292;&#23545;&#20110;&#27491;&#30830;&#20998;&#31867;&#30340;&#26679;&#26412;&#28857;&#65292;&#20559;&#24046;&#21644;&#26041;&#24046;&#22312;&#26679;&#26412;&#32423;&#21035;&#19978;&#26159;&#23545;&#40784;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#26234;&#24935;&#35748;&#20026;&#27867;&#21270;&#35823;&#24046;&#21487;&#20197;&#20998;&#35299;&#20026;&#20559;&#24046;&#21644;&#26041;&#24046;&#65292;&#24182;&#19988;&#36825;&#20004;&#20010;&#26415;&#35821;&#20043;&#38388;&#23384;&#22312;&#30528;"&#26435;&#34913;"&#12290;&#28982;&#32780;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#20998;&#31867;&#27169;&#22411;&#38598;&#21512;&#20013;&#65292;&#20559;&#24046;&#21644;&#26041;&#24046;&#22312;&#26679;&#26412;&#32423;&#21035;&#19978;&#26159;"&#23545;&#40784;"&#30340;&#65292;&#20854;&#20013;&#23545;&#20110;&#27491;&#30830;&#20998;&#31867;&#30340;&#26679;&#26412;&#28857;&#65292;&#22343;&#26041;&#20559;&#24046;&#22823;&#32422;&#31561;&#20110;&#26041;&#24046;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#32463;&#39564;&#35777;&#25454;&#26469;&#35777;&#23454;&#36825;&#19968;&#29616;&#35937;&#22312;&#21508;&#31181;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#20013;&#23384;&#22312;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20174;&#26657;&#20934;&#21644;&#31070;&#32463;&#23849;&#28291;&#30340;&#20004;&#20010;&#29702;&#35770;&#35270;&#35282;&#30740;&#31350;&#20102;&#35813;&#29616;&#35937;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#29702;&#35770;&#19978;&#35777;&#26126;&#22312;&#27169;&#22411;&#33391;&#22909;&#26657;&#20934;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#21487;&#20197;&#35266;&#23519;&#21040;&#20559;&#24046;-&#26041;&#24046;&#30340;&#23545;&#40784;&#12290;&#20854;&#27425;&#65292;&#22312;&#31070;&#32463;&#23849;&#28291;&#29702;&#35770;&#25552;&#20379;&#30340;&#22270;&#26223;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20559;&#24046;&#21644;&#26041;&#24046;&#20043;&#38388;&#30340;&#36817;&#20284;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classical wisdom in machine learning holds that the generalization error can be decomposed into bias and variance, and these two terms exhibit a \emph{trade-off}. However, in this paper, we show that for an ensemble of deep learning based classification models, bias and variance are \emph{aligned} at a sample level, where squared bias is approximately \emph{equal} to variance for correctly classified sample points. We present empirical evidence confirming this phenomenon in a variety of deep learning models and datasets. Moreover, we study this phenomenon from two theoretical perspectives: calibration and neural collapse. We first show theoretically that under the assumption that the models are well calibrated, we can observe the bias-variance alignment. Second, starting from the picture provided by the neural collapse theory, we show an approximate correlation between bias and variance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#25214;&#21040;&#20809;&#28369;&#30446;&#26631;&#20989;&#25968;&#30340;&#36817;&#20284;&#31283;&#23450;&#28857;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#21644;&#26597;&#35810;&#22797;&#26434;&#24615;&#65292;&#24182;&#32473;&#20986;&#20102;&#30456;&#24212;&#30340;&#32467;&#26524;&#12290;&#23545;&#20110;$d=2$&#30340;&#24773;&#20917;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#38646;&#38454;&#31639;&#27861;&#65292;&#21482;&#38656;&#35201;&#23569;&#37327;&#30340;&#20989;&#25968;&#20540;&#26597;&#35810;&#21363;&#21487;&#25214;&#21040;$\varepsilon$-&#36817;&#20284;&#31283;&#23450;&#28857;&#12290;</title><link>http://arxiv.org/abs/2310.09157</link><description>&lt;p&gt;
&#23547;&#25214;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#31283;&#23450;&#28857;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
The Computational Complexity of Finding Stationary Points in Non-Convex Optimization. (arXiv:2310.09157v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09157
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#25214;&#21040;&#20809;&#28369;&#30446;&#26631;&#20989;&#25968;&#30340;&#36817;&#20284;&#31283;&#23450;&#28857;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#21644;&#26597;&#35810;&#22797;&#26434;&#24615;&#65292;&#24182;&#32473;&#20986;&#20102;&#30456;&#24212;&#30340;&#32467;&#26524;&#12290;&#23545;&#20110;$d=2$&#30340;&#24773;&#20917;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#38646;&#38454;&#31639;&#27861;&#65292;&#21482;&#38656;&#35201;&#23569;&#37327;&#30340;&#20989;&#25968;&#20540;&#26597;&#35810;&#21363;&#21487;&#25214;&#21040;$\varepsilon$-&#36817;&#20284;&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23547;&#25214;&#38750;&#20984;&#20294;&#20809;&#28369;&#30446;&#26631;&#20989;&#25968;$f$&#22312;&#26080;&#38480;&#21046;&#30340;$d$&#32500;&#22495;&#19978;&#30340;&#36817;&#20284;&#31283;&#23450;&#28857;&#65292;&#21363;&#26799;&#24230;&#36817;&#20284;&#20026;&#38646;&#30340;&#28857;&#65292;&#26159;&#32463;&#20856;&#38750;&#20984;&#20248;&#21270;&#20013;&#26368;&#22522;&#26412;&#30340;&#38382;&#39064;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#24403;&#38382;&#39064;&#30340;&#32500;&#24230;$d$&#19982;&#36817;&#20284;&#35823;&#24046;&#29420;&#31435;&#26102;&#65292;&#36825;&#20010;&#38382;&#39064;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#21644;&#26597;&#35810;&#22797;&#26434;&#24615;&#20173;&#19981;&#21313;&#20998;&#28165;&#26970;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20197;&#19979;&#35745;&#31639;&#22797;&#26434;&#24615;&#21644;&#26597;&#35810;&#22797;&#26434;&#24615;&#32467;&#26524;&#65306;1.&#22312;&#26080;&#38480;&#21046;&#30340;&#22495;&#20013;&#23547;&#25214;&#36817;&#20284;&#31283;&#23450;&#28857;&#30340;&#38382;&#39064;&#26159;PLS&#23436;&#20840;&#38382;&#39064;&#12290;2.&#23545;&#20110;$d=2$&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#38646;&#38454;&#31639;&#27861;&#65292;&#29992;&#20110;&#23547;&#25214;$\varepsilon$-&#36817;&#20284;&#31283;&#23450;&#28857;&#65292;&#21482;&#38656;&#35201;&#23545;&#30446;&#26631;&#20989;&#25968;&#36827;&#34892;&#26368;&#22810;$O(1/\varepsilon)$&#27425;&#20989;&#25968;&#20540;&#26597;&#35810;&#12290;3.&#25105;&#20204;&#35777;&#26126;&#24403;$d=2$&#26102;&#65292;&#20219;&#20309;&#31639;&#27861;&#33267;&#23569;&#38656;&#35201;$\Omega(1/\varepsilon)$&#27425;&#23545;&#30446;&#26631;&#20989;&#25968;&#21644;/&#25110;&#26799;&#24230;&#30340;&#26597;&#35810;&#26469;&#25214;&#21040;$\varepsilon$-&#36817;&#20284;&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Finding approximate stationary points, i.e., points where the gradient is approximately zero, of non-convex but smooth objective functions $f$ over unrestricted $d$-dimensional domains is one of the most fundamental problems in classical non-convex optimization. Nevertheless, the computational and query complexity of this problem are still not well understood when the dimension $d$ of the problem is independent of the approximation error. In this paper, we show the following computational and query complexity results:  1. The problem of finding approximate stationary points over unrestricted domains is PLS-complete.  2. For $d = 2$, we provide a zero-order algorithm for finding $\varepsilon$-approximate stationary points that requires at most $O(1/\varepsilon)$ value queries to the objective function.  3. We show that any algorithm needs at least $\Omega(1/\varepsilon)$ queries to the objective function and/or its gradient to find $\varepsilon$-approximate stationary points when $d=2$.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;Wasserstein&#31354;&#38388;&#20013;&#36890;&#36807;&#31163;&#25955;&#21644;&#20998;&#27573;&#24120;&#25968;&#27979;&#24230;&#36827;&#34892;&#30340;&#32467;&#26500;&#36924;&#36817;&#26041;&#27861;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#23545;&#20110;&#28385;&#31209;&#30340;&#26684;&#28857;&#25353;&#27604;&#20363;&#32553;&#25918;&#21518;&#24471;&#21040;&#30340;Voronoi&#20998;&#21106;&#36924;&#36817;&#30340;&#27979;&#24230;&#35823;&#24046;&#26159;$O(h)$&#65292;&#36924;&#36817;&#30340;$N$&#39033;&#35823;&#24046;&#20026;$O(N^{-\frac1d})$&#65292;&#24182;&#19988;&#21487;&#20197;&#25512;&#24191;&#21040;&#38750;&#32039;&#25903;&#25745;&#27979;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.09149</link><description>&lt;p&gt;
&#24494;&#20998;&#27700;&#24179;&#31354;&#38388;&#20013;&#30340;&#26684;&#28857;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Lattice Approximations in Wasserstein Space. (arXiv:2310.09149v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09149
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;Wasserstein&#31354;&#38388;&#20013;&#36890;&#36807;&#31163;&#25955;&#21644;&#20998;&#27573;&#24120;&#25968;&#27979;&#24230;&#36827;&#34892;&#30340;&#32467;&#26500;&#36924;&#36817;&#26041;&#27861;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#23545;&#20110;&#28385;&#31209;&#30340;&#26684;&#28857;&#25353;&#27604;&#20363;&#32553;&#25918;&#21518;&#24471;&#21040;&#30340;Voronoi&#20998;&#21106;&#36924;&#36817;&#30340;&#27979;&#24230;&#35823;&#24046;&#26159;$O(h)$&#65292;&#36924;&#36817;&#30340;$N$&#39033;&#35823;&#24046;&#20026;$O(N^{-\frac1d})$&#65292;&#24182;&#19988;&#21487;&#20197;&#25512;&#24191;&#21040;&#38750;&#32039;&#25903;&#25745;&#27979;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;Wasserstein&#31354;&#38388;$W_p(\mathbb{R}^d)$&#20013;&#36890;&#36807;&#31163;&#25955;&#21644;&#20998;&#27573;&#24120;&#25968;&#27979;&#24230;&#26469;&#23545;&#27979;&#24230;&#36827;&#34892;&#32467;&#26500;&#36924;&#36817;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22914;&#26524;&#19968;&#20010;&#28385;&#31209;&#30340;&#26684;&#28857;$\Lambda$&#25353;&#29031;$h\in(0,1]$&#30340;&#27604;&#20363;&#36827;&#34892;&#32553;&#25918;&#65292;&#37027;&#20040;&#22522;&#20110;$h\Lambda$&#30340;Voronoi&#20998;&#21106;&#24471;&#21040;&#30340;&#27979;&#24230;&#36924;&#36817;&#26159;$O(h)$&#65292;&#19981;&#35770;$d$&#25110;$p$&#30340;&#21462;&#20540;&#12290;&#20043;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#35206;&#30422;&#35770;&#35777;&#35777;&#26126;&#65292;&#23545;&#20110;&#32039;&#25903;&#25745;&#30340;&#27979;&#24230;&#30340;$N$&#39033;&#36924;&#36817;&#26159;$O(N^{-\frac1d})$&#65292;&#36825;&#19982;&#26368;&#20248;&#37327;&#21270;&#22120;&#21644;&#32463;&#39564;&#27979;&#24230;&#36924;&#36817;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#24050;&#30693;&#30340;&#36895;&#29575;&#30456;&#21305;&#37197;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#32467;&#26524;&#25512;&#24191;&#21040;&#38750;&#32039;&#25903;&#25745;&#27979;&#24230;&#65292;&#35201;&#27714;&#20854;&#20855;&#26377;&#36275;&#22815;&#30340;&#34928;&#20943;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider structured approximation of measures in Wasserstein space $W_p(\mathbb{R}^d)$ for $p\in[1,\infty)$ by discrete and piecewise constant measures based on a scaled Voronoi partition of $\mathbb{R}^d$. We show that if a full rank lattice $\Lambda$ is scaled by a factor of $h\in(0,1]$, then approximation of a measure based on the Voronoi partition of $h\Lambda$ is $O(h)$ regardless of $d$ or $p$. We then use a covering argument to show that $N$-term approximations of compactly supported measures is $O(N^{-\frac1d})$ which matches known rates for optimal quantizers and empirical measure approximation in most instances. Finally, we extend these results to noncompactly supported measures with sufficient decay.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20351;&#29992;&#27169;&#25311;&#29615;&#22659;&#30340;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#30452;&#25509;&#20248;&#21270;&#29992;&#25143;&#28385;&#24847;&#24230;&#25351;&#26631;&#65292;&#23454;&#29616;&#20010;&#24615;&#21270;&#38899;&#20048;&#25773;&#25918;&#21015;&#34920;&#30340;&#33258;&#21160;&#29983;&#25104;&#12290;&#25105;&#20204;&#20351;&#29992;&#20462;&#25913;&#29256;&#30340;&#28145;&#24230;Q&#32593;&#32476;&#35757;&#32451;&#20986;&#30340;&#31574;&#30053;&#33021;&#22815;&#20174;&#22823;&#22411;&#21644;&#21160;&#24577;&#30340;&#20505;&#36873;&#39033;&#30446;&#38598;&#20013;&#36827;&#34892;&#25512;&#33616;&#65292;&#20197;&#26368;&#22823;&#21270;&#28040;&#36153;&#25351;&#26631;&#12290;</title><link>http://arxiv.org/abs/2310.09123</link><description>&lt;p&gt;
&#22522;&#20110;&#27169;&#25311;&#30340;&#24378;&#21270;&#23398;&#20064;&#33258;&#21160;&#29983;&#25104;&#38899;&#20048;&#25773;&#25918;&#21015;&#34920;
&lt;/p&gt;
&lt;p&gt;
Automatic Music Playlist Generation via Simulation-based Reinforcement Learning. (arXiv:2310.09123v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09123
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20351;&#29992;&#27169;&#25311;&#29615;&#22659;&#30340;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#30452;&#25509;&#20248;&#21270;&#29992;&#25143;&#28385;&#24847;&#24230;&#25351;&#26631;&#65292;&#23454;&#29616;&#20010;&#24615;&#21270;&#38899;&#20048;&#25773;&#25918;&#21015;&#34920;&#30340;&#33258;&#21160;&#29983;&#25104;&#12290;&#25105;&#20204;&#20351;&#29992;&#20462;&#25913;&#29256;&#30340;&#28145;&#24230;Q&#32593;&#32476;&#35757;&#32451;&#20986;&#30340;&#31574;&#30053;&#33021;&#22815;&#20174;&#22823;&#22411;&#21644;&#21160;&#24577;&#30340;&#20505;&#36873;&#39033;&#30446;&#38598;&#20013;&#36827;&#34892;&#25512;&#33616;&#65292;&#20197;&#26368;&#22823;&#21270;&#28040;&#36153;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#38899;&#20048;&#25773;&#25918;&#21015;&#34920;&#26159;&#38899;&#20048;&#27969;&#23186;&#20307;&#26381;&#21153;&#20013;&#24120;&#35265;&#30340;&#21151;&#33021;&#65292;&#20294;&#20256;&#32479;&#30340;&#25216;&#26415;&#65292;&#22914;&#21327;&#21516;&#36807;&#28388;&#65292;&#20381;&#36182;&#20110;&#23545;&#20869;&#23481;&#36136;&#37327;&#30340;&#26126;&#30830;&#20551;&#35774;&#65292;&#20197;&#23398;&#20064;&#22914;&#20309;&#36827;&#34892;&#25512;&#33616;&#12290;&#36825;&#20123;&#20551;&#35774;&#24448;&#24448;&#23548;&#33268;&#31163;&#32447;&#27169;&#22411;&#30446;&#26631;&#21644;&#22312;&#32447;&#29992;&#25143;&#28385;&#24847;&#24230;&#25351;&#26631;&#20043;&#38388;&#30340;&#19981;&#19968;&#33268;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#27169;&#25311;&#30340;&#25773;&#25918;&#21015;&#34920;&#29983;&#25104;&#29615;&#22659;&#30452;&#25509;&#20248;&#21270;&#29992;&#25143;&#28385;&#24847;&#24230;&#25351;&#26631;&#65292;&#35299;&#20915;&#20102;&#36825;&#20123;&#38480;&#21046;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#20010;&#27169;&#25311;&#22120;&#24320;&#21457;&#21644;&#35757;&#32451;&#20102;&#19968;&#20010;&#20462;&#25913;&#29256;&#30340;&#28145;&#24230;Q&#32593;&#32476;&#65292;&#31216;&#20026;AH-DQN&#65292;&#22312;&#22788;&#29702;&#25105;&#20204;&#30340;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#22823;&#29366;&#24577;&#21644;&#21160;&#20316;&#31354;&#38388;&#26102;&#33021;&#22815;&#35299;&#20915;&#25361;&#25112;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#31574;&#30053;&#33021;&#22815;&#20174;&#22823;&#22411;&#21644;&#21160;&#24577;&#30340;&#20505;&#36873;&#39033;&#30446;&#38598;&#20013;&#36827;&#34892;&#25512;&#33616;&#65292;&#20197;&#26368;&#22823;&#21270;&#28040;&#36153;&#25351;&#26631;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#29615;&#22659;&#27169;&#25311;&#36827;&#34892;&#31163;&#32447;&#35780;&#20272;&#21644;&#20998;&#26512;&#20195;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Personalization of playlists is a common feature in music streaming services, but conventional techniques, such as collaborative filtering, rely on explicit assumptions regarding content quality to learn how to make recommendations. Such assumptions often result in misalignment between offline model objectives and online user satisfaction metrics. In this paper, we present a reinforcement learning framework that solves for such limitations by directly optimizing for user satisfaction metrics via the use of a simulated playlist-generation environment. Using this simulator we develop and train a modified Deep Q-Network, the action head DQN (AH-DQN), in a manner that addresses the challenges imposed by the large state and action space of our RL formulation. The resulting policy is capable of making recommendations from large and dynamic sets of candidate items with the expectation of maximizing consumption metrics. We analyze and evaluate agents offline via simulations that use environmen
&lt;/p&gt;</description></item><item><title>MINDE&#26159;&#19968;&#31181;&#22522;&#20110;&#24471;&#20998;&#20989;&#25968;&#25193;&#25955;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#12290;&#35813;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;&#33258;&#19968;&#33268;&#24615;&#27979;&#35797;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#25991;&#29486;&#20013;&#30340;&#20027;&#35201;&#26367;&#20195;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.09031</link><description>&lt;p&gt;
MINDE: &#20114;&#20449;&#24687;&#31070;&#32463;&#25193;&#25955;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
MINDE: Mutual Information Neural Diffusion Estimation. (arXiv:2310.09031v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09031
&lt;/p&gt;
&lt;p&gt;
MINDE&#26159;&#19968;&#31181;&#22522;&#20110;&#24471;&#20998;&#20989;&#25968;&#25193;&#25955;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#12290;&#35813;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;&#33258;&#19968;&#33268;&#24615;&#27979;&#35797;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#25991;&#29486;&#20013;&#30340;&#20027;&#35201;&#26367;&#20195;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#20114;&#20449;&#24687;&#65288;MI&#65289;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;Girsanov&#23450;&#29702;&#30340;&#21407;&#21019;&#35299;&#37322;&#65292;&#20801;&#35768;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#26469;&#20272;&#35745;&#20004;&#20010;&#23494;&#24230;&#20989;&#25968;&#20043;&#38388;&#30340;Kullback-Leibler&#25955;&#24230;&#65292;&#35813;&#20272;&#35745;&#26159;&#23427;&#20204;&#24471;&#20998;&#20989;&#25968;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#20316;&#20026;&#21103;&#20135;&#21697;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36824;&#33021;&#22815;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;&#30340;&#29109;&#12290;&#20511;&#21161;&#36825;&#26679;&#30340;&#26500;&#24314;&#27169;&#22359;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#27979;&#37327;MI&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20998;&#20026;&#20004;&#20010;&#26041;&#21521;&#23637;&#24320;&#65306;&#19968;&#20010;&#20351;&#29992;&#26465;&#20214;&#25193;&#25955;&#36807;&#31243;&#65292;&#21478;&#19968;&#20010;&#20351;&#29992;&#32852;&#21512;&#25193;&#25955;&#36807;&#31243;&#65292;&#21487;&#20197;&#21516;&#26102;&#23545;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;&#36827;&#34892;&#24314;&#27169;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26469;&#33258;&#20110;&#23545;&#25105;&#20204;&#26041;&#27861;&#30340;&#21508;&#31181;&#21464;&#20307;&#36827;&#34892;&#24443;&#24213;&#30340;&#23454;&#39564;&#21327;&#35758;&#65292;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#27604;&#25991;&#29486;&#20013;&#30340;&#20027;&#35201;&#26367;&#20195;&#26041;&#27861;&#26356;&#20934;&#30830;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#20102;MI&#33258;&#19968;&#33268;&#24615;&#27979;&#35797;&#65292;&#21253;&#25324;...
&lt;/p&gt;
&lt;p&gt;
In this work we present a new method for the estimation of Mutual Information (MI) between random variables. Our approach is based on an original interpretation of the Girsanov theorem, which allows us to use score-based diffusion models to estimate the Kullback Leibler divergence between two densities as a difference between their score functions. As a by-product, our method also enables the estimation of the entropy of random variables. Armed with such building blocks, we present a general recipe to measure MI, which unfolds in two directions: one uses conditional diffusion process, whereas the other uses joint diffusion processes that allow simultaneous modelling of two random variables. Our results, which derive from a thorough experimental protocol over all the variants of our approach, indicate that our method is more accurate than the main alternatives from the literature, especially for challenging distributions. Furthermore, our methods pass MI self-consistency tests, includin
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#23569;&#26679;&#26412;&#23398;&#20064;&#30340;&#23376;&#31354;&#38388;&#36866;&#24212;&#20808;&#39564;&#31639;&#27861;&#65292;&#36890;&#36807;&#21516;&#26102;&#23398;&#20064;&#21021;&#22987;&#21270;&#21442;&#25968;&#21644;&#21442;&#25968;&#23376;&#31354;&#38388;&#65292;&#21487;&#20197;&#22522;&#20110;&#20219;&#21153;&#20998;&#24067;&#20915;&#23450;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#35843;&#25972;&#21738;&#20123;&#25805;&#20316;&#23376;&#38598;&#65292;&#20174;&#32780;&#25552;&#39640;&#23398;&#20064;&#25928;&#29575;&#24182;&#38477;&#20302;&#36807;&#25311;&#21512;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2310.09028</link><description>&lt;p&gt;
&#23569;&#26679;&#26412;&#23398;&#20064;&#30340;&#23376;&#31354;&#38388;&#36866;&#24212;&#20808;&#39564;
&lt;/p&gt;
&lt;p&gt;
Subspace Adaptation Prior for Few-Shot Learning. (arXiv:2310.09028v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09028
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#23569;&#26679;&#26412;&#23398;&#20064;&#30340;&#23376;&#31354;&#38388;&#36866;&#24212;&#20808;&#39564;&#31639;&#27861;&#65292;&#36890;&#36807;&#21516;&#26102;&#23398;&#20064;&#21021;&#22987;&#21270;&#21442;&#25968;&#21644;&#21442;&#25968;&#23376;&#31354;&#38388;&#65292;&#21487;&#20197;&#22522;&#20110;&#20219;&#21153;&#20998;&#24067;&#20915;&#23450;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#35843;&#25972;&#21738;&#20123;&#25805;&#20316;&#23376;&#38598;&#65292;&#20174;&#32780;&#25552;&#39640;&#23398;&#20064;&#25928;&#29575;&#24182;&#38477;&#20302;&#36807;&#25311;&#21512;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26799;&#24230;&#22522;&#20110;&#30340;&#20803;&#23398;&#20064;&#25216;&#26415;&#26088;&#22312;&#20174;&#19968;&#31995;&#21015;&#35757;&#32451;&#20219;&#21153;&#20013;&#25552;&#21462;&#26377;&#29992;&#30340;&#20808;&#39564;&#30693;&#35782;&#65292;&#20197;&#20415;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#26356;&#39640;&#25928;&#22320;&#23398;&#20064;&#26032;&#20219;&#21153;&#12290;&#23613;&#31649;&#36825;&#20123;&#26041;&#27861;&#22312;&#21508;&#31181;&#24773;&#20917;&#19979;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#22312;&#23398;&#20064;&#26032;&#20219;&#21153;&#26102;&#36866;&#24212;&#21487;&#35757;&#32451;&#23618;&#30340;&#25152;&#26377;&#21442;&#25968;&#12290;&#36825;&#24573;&#30053;&#20102;&#23545;&#20110;&#32473;&#23450;&#20219;&#21153;&#20998;&#24067;&#26469;&#35828;&#21487;&#33021;&#26356;&#39640;&#25928;&#30340;&#23398;&#20064;&#31574;&#30053;&#65292;&#24182;&#19988;&#21487;&#33021;&#23481;&#26131;&#36807;&#25311;&#21512;&#65292;&#29305;&#21035;&#26159;&#22312;&#23569;&#26679;&#26412;&#23398;&#20064;&#20013;&#65292;&#20854;&#20013;&#24517;&#39035;&#20174;&#26377;&#38480;&#25968;&#37327;&#30340;&#31034;&#20363;&#20013;&#23398;&#20064;&#20219;&#21153;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23376;&#31354;&#38388;&#36866;&#24212;&#20808;&#39564;(SAP)&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#20803;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#21516;&#26102;&#23398;&#20064;&#33391;&#22909;&#30340;&#21021;&#22987;&#21270;&#21442;&#25968;(&#20808;&#39564;&#30693;&#35782;)&#21644;&#21442;&#25968;&#23376;&#31354;&#38388;&#65292;&#20197;&#25805;&#20316;&#23376;&#38598;&#30340;&#24418;&#24335;&#34920;&#31034;&#24212;&#35813;&#26159;&#21487;&#36866;&#24212;&#30340;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;SAP&#21487;&#20197;&#26681;&#25454;&#28508;&#22312;&#30340;&#20219;&#21153;&#20998;&#24067;&#23398;&#20064;&#24212;&#35813;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#35843;&#25972;&#30340;&#25805;&#20316;&#23376;&#38598;&#65292;&#21516;&#26102;&#38477;&#20302;&#36807;&#25311;&#21512;&#30340;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gradient-based meta-learning techniques aim to distill useful prior knowledge from a set of training tasks such that new tasks can be learned more efficiently with gradient descent. While these methods have achieved successes in various scenarios, they commonly adapt all parameters of trainable layers when learning new tasks. This neglects potentially more efficient learning strategies for a given task distribution and may be susceptible to overfitting, especially in few-shot learning where tasks must be learned from a limited number of examples. To address these issues, we propose Subspace Adaptation Prior (SAP), a novel gradient-based meta-learning algorithm that jointly learns good initialization parameters (prior knowledge) and layer-wise parameter subspaces in the form of operation subsets that should be adaptable. In this way, SAP can learn which operation subsets to adjust with gradient descent based on the underlying task distribution, simultaneously decreasing the risk of over
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20108;&#27425;Lasso&#37325;&#26500;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#29992;&#20110;&#26368;&#20248;&#35774;&#35745;&#30340;&#24555;&#36895;&#31579;&#36873;&#35268;&#21017;&#65292;&#21487;&#20197;&#21160;&#24577;&#22320;&#22312;&#20219;&#20309;&#36845;&#20195;&#27714;&#35299;&#22120;&#20013;&#20351;&#29992;&#12290;&#36825;&#20123;&#35268;&#21017;&#33021;&#22815;&#24555;&#36895;&#35745;&#31639;&#65292;&#24182;&#19988;&#22312;&#38382;&#39064;&#28041;&#21450;&#39640;&#32500;&#21442;&#25968;&#31354;&#38388;&#26102;&#23588;&#20026;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2310.08939</link><description>&lt;p&gt;
&#36890;&#36807;&#20108;&#27425;Lasso&#37325;&#26500;&#65292;&#29992;&#20110;&#26368;&#20248;&#35774;&#35745;&#30340;&#24555;&#36895;&#31579;&#36873;&#35268;&#21017;
&lt;/p&gt;
&lt;p&gt;
Fast Screening Rules for Optimal Design via Quadratic Lasso Reformulation. (arXiv:2310.08939v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08939
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20108;&#27425;Lasso&#37325;&#26500;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#29992;&#20110;&#26368;&#20248;&#35774;&#35745;&#30340;&#24555;&#36895;&#31579;&#36873;&#35268;&#21017;&#65292;&#21487;&#20197;&#21160;&#24577;&#22320;&#22312;&#20219;&#20309;&#36845;&#20195;&#27714;&#35299;&#22120;&#20013;&#20351;&#29992;&#12290;&#36825;&#20123;&#35268;&#21017;&#33021;&#22815;&#24555;&#36895;&#35745;&#31639;&#65292;&#24182;&#19988;&#22312;&#38382;&#39064;&#28041;&#21450;&#39640;&#32500;&#21442;&#25968;&#31354;&#38388;&#26102;&#23588;&#20026;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Lasso&#22238;&#24402;&#21644;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#37117;&#20855;&#26377;&#19968;&#20010;&#37325;&#35201;&#29305;&#24615;&#65306;&#23427;&#20204;&#30340;&#26368;&#20248;&#35299;&#36890;&#24120;&#26159;"&#31232;&#30095;&#30340;"&#65292;&#21363;&#21482;&#26377;&#24456;&#23569;&#19968;&#37096;&#20998;&#21464;&#37327;&#26159;&#38750;&#38646;&#30340;&#12290;&#22240;&#27492;&#65292;&#30830;&#23450;&#26368;&#20248;&#35299;&#30340;&#25903;&#25345;&#38598;&#20250;&#38477;&#20302;&#38382;&#39064;&#30340;&#32500;&#24230;&#24182;&#19988;&#33021;&#22815;&#22823;&#22823;&#31616;&#21270;&#35745;&#31639;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#20351;&#29992;"&#24179;&#26041;"&#30340;$\ell_1$-&#33539;&#25968;&#32602;&#39033;&#30340;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#31561;&#20215;&#20110;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#12290;&#26412;&#25991;&#21033;&#29992;&#36825;&#31181;&#31561;&#20215;&#20851;&#31995;&#65292;&#25512;&#23548;&#20986;&#21487;&#20197;&#29992;&#20110;&#25490;&#38500;&#26080;&#20851;&#26679;&#26412;&#30340;&#23433;&#20840;&#31579;&#36873;&#35268;&#21017;&#12290;&#19982;&#20808;&#21069;&#23384;&#22312;&#30340;&#35268;&#21017;&#30456;&#27604;&#65292;&#26032;&#30340;&#27979;&#35797;&#26041;&#27861;&#35745;&#31639;&#36895;&#24230;&#26356;&#24555;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#28041;&#21450;&#39640;&#32500;&#21442;&#25968;&#31354;&#38388;&#30340;&#38382;&#39064;&#65292;&#24182;&#21487;&#20197;&#22312;&#20219;&#20309;&#36845;&#20195;&#27714;&#35299;&#22120;&#20013;&#21160;&#24577;&#20351;&#29992;&#65292;&#19988;&#35745;&#31639;&#24320;&#38144;&#24456;&#23567;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#29616;&#26377;&#30340;&#36335;&#24452;&#36861;&#36394;&#31639;&#27861;&#26469;&#35745;&#31639;&#27491;&#21017;&#21270;&#21442;&#25968;&#20540;&#30340;&#36335;&#24452;&#65292;&#24182;&#36827;&#34892;&#20102;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The problems of Lasso regression and optimal design of experiments share a critical property: their optimal solutions are typically \emph{sparse}, i.e., only a small fraction of the optimal variables are non-zero. Therefore, the identification of the support of an optimal solution reduces the dimensionality of the problem and can yield a substantial simplification of the calculations. It has recently been shown that linear regression with a \emph{squared} $\ell_1$-norm sparsity-inducing penalty is equivalent to an optimal experimental design problem. In this work, we use this equivalence to derive safe screening rules that can be used to discard inessential samples. Compared to previously existing rules, the new tests are much faster to compute, especially for problems involving a parameter space of high dimension, and can be used dynamically within any iterative solver, with negligible computational overhead. Moreover, we show how an existing homotopy algorithm to compute the regulari
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#24191;&#27867;&#30340;Adam-family&#26041;&#27861;&#22312;&#35757;&#32451;&#38750;&#20809;&#28369;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#25910;&#25947;&#24615;&#36136;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20998;&#31163;&#26435;&#37325;&#34928;&#20943;&#30340;&#26032;&#26694;&#26550;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#25910;&#25947;&#24615;&#12290;&#35813;&#26694;&#26550;&#21253;&#21547;&#20102;&#35768;&#22810;&#24050;&#30693;&#30340;Adam-family&#26041;&#27861;&#65292;&#24182;&#23545;&#36825;&#20123;&#26041;&#27861;&#22312;&#35757;&#32451;&#38750;&#20809;&#28369;&#31070;&#32463;&#32593;&#32476;&#26102;&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.08858</link><description>&lt;p&gt;
&#20351;&#29992;&#20998;&#31163;&#26435;&#37325;&#34928;&#20943;&#30340;Adam-family&#26041;&#27861;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;
&lt;/p&gt;
&lt;p&gt;
Adam-family Methods with Decoupled Weight Decay in Deep Learning. (arXiv:2310.08858v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08858
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#24191;&#27867;&#30340;Adam-family&#26041;&#27861;&#22312;&#35757;&#32451;&#38750;&#20809;&#28369;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#25910;&#25947;&#24615;&#36136;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20998;&#31163;&#26435;&#37325;&#34928;&#20943;&#30340;&#26032;&#26694;&#26550;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#25910;&#25947;&#24615;&#12290;&#35813;&#26694;&#26550;&#21253;&#21547;&#20102;&#35768;&#22810;&#24050;&#30693;&#30340;Adam-family&#26041;&#27861;&#65292;&#24182;&#23545;&#36825;&#20123;&#26041;&#27861;&#22312;&#35757;&#32451;&#38750;&#20809;&#28369;&#31070;&#32463;&#32593;&#32476;&#26102;&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#24191;&#27867;&#30340;Adam-family&#26041;&#27861;&#22312;&#26368;&#23567;&#21270;&#20108;&#27425;&#27491;&#21017;&#21270;&#38750;&#20809;&#28369;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#25910;&#25947;&#24615;&#36136;&#65292;&#29305;&#21035;&#26159;&#22312;&#35757;&#32451;&#20855;&#26377;&#26435;&#37325;&#34928;&#20943;&#30340;&#38750;&#20809;&#28369;&#31070;&#32463;&#32593;&#32476;&#30340;&#24773;&#20917;&#19979;&#12290;&#21463;&#21040;AdamW&#26041;&#27861;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20998;&#31163;&#26435;&#37325;&#34928;&#20943;&#30340;Adam-family&#26041;&#27861;&#30340;&#26032;&#26694;&#26550;&#12290;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20869;&#65292;&#38543;&#26426;&#23376;&#26799;&#24230;&#30340;&#19968;&#38454;&#21644;&#20108;&#38454;&#30697;&#20272;&#35745;&#20998;&#21035;&#29420;&#31435;&#20110;&#26435;&#37325;&#34928;&#20943;&#39033;&#36827;&#34892;&#26356;&#26032;&#12290;&#22312;&#21512;&#29702;&#30340;&#20551;&#35774;&#19979;&#65292;&#24182;&#19988;&#22312;&#26356;&#26032;&#20027;&#35201;&#20248;&#21270;&#21464;&#37327;&#26102;&#37319;&#29992;&#38750;&#36882;&#20943;&#27493;&#38271;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#30340;&#25910;&#25947;&#24615;&#36136;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#21253;&#21547;&#20102;&#35768;&#22810;&#20247;&#25152;&#21608;&#30693;&#30340;Adam-family&#26041;&#27861;&#65292;&#20174;&#32780;&#20026;&#36825;&#20123;&#26041;&#27861;&#22312;&#35757;&#32451;&#38750;&#20809;&#28369;&#31070;&#32463;&#32593;&#32476;&#26102;&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#20445;&#35777;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#28176;&#36817;&#36817;&#20284;&#20102;&#19968;&#31867;&#27425;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we investigate the convergence properties of a wide class of Adam-family methods for minimizing quadratically regularized nonsmooth nonconvex optimization problems, especially in the context of training nonsmooth neural networks with weight decay. Motivated by the AdamW method, we propose a novel framework for Adam-family methods with decoupled weight decay. Within our framework, the estimators for the first-order and second-order moments of stochastic subgradients are updated independently of the weight decay term. Under mild assumptions and with non-diminishing stepsizes for updating the primary optimization variables, we establish the convergence properties of our proposed framework. In addition, we show that our proposed framework encompasses a wide variety of well-known Adam-family methods, hence offering convergence guarantees for these methods in the training of nonsmooth neural networks. More importantly, we show that our proposed framework asymptotically approxi
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#26368;&#20248;&#36755;&#36816;&#22870;&#21169;&#26631;&#31614;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#31163;&#32447;&#24773;&#20917;&#19979;&#20998;&#37197;&#22870;&#21169;&#32473;&#36712;&#36857;&#65292;&#20174;&#32780;&#20943;&#23569;&#23545;&#36164;&#28304;&#23494;&#38598;&#22411;&#23454;&#26102;&#20132;&#20114;&#30340;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2310.08841</link><description>&lt;p&gt;
&#22312;&#22806;&#31185;&#26426;&#22120;&#20154;&#29615;&#22659;&#20013;&#21033;&#29992;&#26368;&#20248;&#36755;&#36816;&#22686;&#24378;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Leveraging Optimal Transport for Enhanced Offline Reinforcement Learning in Surgical Robotic Environments. (arXiv:2310.08841v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08841
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#26368;&#20248;&#36755;&#36816;&#22870;&#21169;&#26631;&#31614;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#31163;&#32447;&#24773;&#20917;&#19979;&#20998;&#37197;&#22870;&#21169;&#32473;&#36712;&#36857;&#65292;&#20174;&#32780;&#20943;&#23569;&#23545;&#36164;&#28304;&#23494;&#38598;&#22411;&#23454;&#26102;&#20132;&#20114;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#36890;&#24120;&#22312;&#20027;&#21160;&#23398;&#20064;&#29615;&#22659;&#20013;&#36827;&#34892;&#30740;&#31350;&#65292;&#20195;&#29702;&#30452;&#25509;&#19982;&#29615;&#22659;&#20114;&#21160;&#65292;&#35266;&#23519;&#34892;&#21160;&#32467;&#26524;&#65292;&#24182;&#36890;&#36807;&#35797;&#38169;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#20801;&#35768;&#37096;&#20998;&#35757;&#32451;&#20195;&#29702;&#19982;&#30495;&#23454;&#29289;&#29702;&#31995;&#32479;&#20132;&#20114;&#20250;&#24102;&#26469;&#26174;&#33879;&#30340;&#25361;&#25112;&#65292;&#21253;&#25324;&#39640;&#25104;&#26412;&#12289;&#23433;&#20840;&#39118;&#38505;&#21644;&#38656;&#35201;&#25345;&#32493;&#30417;&#30563;&#12290;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#36890;&#36807;&#21033;&#29992;&#29616;&#26377;&#25968;&#25454;&#38598;&#24182;&#20943;&#23569;&#23545;&#36164;&#28304;&#23494;&#38598;&#22411;&#23454;&#26102;&#20132;&#20114;&#30340;&#38656;&#27714;&#26469;&#35299;&#20915;&#36825;&#20123;&#25104;&#26412;&#21644;&#23433;&#20840;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#19968;&#20010;&#37325;&#35201;&#30340;&#25361;&#25112;&#22312;&#20110;&#38656;&#35201;&#31934;&#24515;&#27880;&#37322;&#36825;&#20123;&#25968;&#25454;&#38598;&#30340;&#22870;&#21169;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#31639;&#27861;&#65292;&#21363;&#26368;&#20248;&#36755;&#36816;&#22870;&#21169;&#65288;OTR&#65289;&#26631;&#31614;&#65292;&#29992;&#20110;&#23545;&#31163;&#32447;&#36712;&#36857;&#20998;&#37197;&#22870;&#21169;&#65292;&#20351;&#29992;&#23569;&#37327;&#39640;&#36136;&#37327;&#30340;&#19987;&#23478;&#28436;&#31034;&#12290;OTR&#30340;&#26680;&#24515;&#21407;&#29702;&#26159;&#21033;&#29992;&#26368;&#20248;&#36755;&#36816;&#35745;&#31639;&#26080;&#26631;&#31614;&#36712;&#36857;&#19982;&#19987;&#23478;&#28436;&#31034;&#20043;&#38388;&#30340;&#26368;&#20248;&#23545;&#40784;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most Reinforcement Learning (RL) methods are traditionally studied in an active learning setting, where agents directly interact with their environments, observe action outcomes, and learn through trial and error. However, allowing partially trained agents to interact with real physical systems poses significant challenges, including high costs, safety risks, and the need for constant supervision. Offline RL addresses these cost and safety concerns by leveraging existing datasets and reducing the need for resource-intensive real-time interactions. Nevertheless, a substantial challenge lies in the demand for these datasets to be meticulously annotated with rewards. In this paper, we introduce Optimal Transport Reward (OTR) labelling, an innovative algorithm designed to assign rewards to offline trajectories, using a small number of high-quality expert demonstrations. The core principle of OTR involves employing Optimal Transport (OT) to calculate an optimal alignment between an unlabele
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35299;&#20915;&#20102;&#23545;&#20110;&#22343;&#21248;&#25910;&#25947;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#38271;&#26399;&#24179;&#22343;&#22870;&#21169;&#26368;&#22823;&#21270;&#31574;&#30053;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#38382;&#39064;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#20010;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\widetilde O(|S||A|t_{\text{mix}}\epsilon^{-2})$&#30340;&#20248;&#21270;&#31574;&#30053;&#20272;&#35745;&#22120;&#12290;</title><link>http://arxiv.org/abs/2310.08833</link><description>&lt;p&gt;
&#24179;&#22343;&#22870;&#21169;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
Optimal Sample Complexity for Average Reward Markov Decision Processes. (arXiv:2310.08833v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08833
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35299;&#20915;&#20102;&#23545;&#20110;&#22343;&#21248;&#25910;&#25947;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#38271;&#26399;&#24179;&#22343;&#22870;&#21169;&#26368;&#22823;&#21270;&#31574;&#30053;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#38382;&#39064;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#20010;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\widetilde O(|S||A|t_{\text{mix}}\epsilon^{-2})$&#30340;&#20248;&#21270;&#31574;&#30053;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#20551;&#35774;&#26377;&#19968;&#20010;&#29983;&#25104;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#35299;&#20915;&#20102;&#19982;&#22343;&#21248;&#25910;&#25947;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30456;&#20851;&#30340;&#38271;&#26399;&#24179;&#22343;&#22870;&#21169;&#30340;&#31574;&#30053;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#38382;&#39064;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#29616;&#26377;&#30340;&#25991;&#29486;&#25552;&#20379;&#20102;&#19968;&#20010;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#19978;&#30028;&#65292;$ \widetilde O(|S||A|t_{\text{mix}}^2 \epsilon^{-2})$&#65292;&#21644;&#19968;&#20010;&#19979;&#30028;&#65292;$\Omega(|S||A|t_{\text{mix}} \epsilon^{-2})$&#12290;&#22312;&#36825;&#20123;&#34920;&#36798;&#24335;&#20013;&#65292;$|S|$&#21644;$|A|$&#20998;&#21035;&#34920;&#31034;&#29366;&#24577;&#31354;&#38388;&#21644;&#21160;&#20316;&#31354;&#38388;&#30340;&#21183;&#65292;$t_{\text{mix}}$&#20316;&#20026;&#24635;&#21464;&#24322;&#28151;&#21512;&#26102;&#38388;&#30340;&#32479;&#19968;&#19978;&#38480;&#65292;$\epsilon$&#34920;&#31034;&#35823;&#24046;&#23481;&#24525;&#24230;&#12290;&#22240;&#27492;&#65292;$t_{\text{mix}}$&#20173;&#28982;&#23384;&#22312;&#19968;&#20010;&#26174;&#30528;&#30340;&#24046;&#36317;&#38656;&#35201;&#22635;&#34917;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#24314;&#31435;&#19968;&#20010;&#20248;&#21270;&#31574;&#30053;&#30340;&#20272;&#35745;&#22120;&#65292;&#20854;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\widetilde O(|S||A|t_{\text{mix}}\epsilon^{-2})$&#65292;&#26377;&#25928;&#22320;&#36798;&#21040;&#20102;&#25991;&#29486;&#20013;&#30340;&#19979;&#30028;&#12290;&#36825;&#26159;&#36890;&#36807;&#32467;&#21512;&#31639;&#27861;&#24605;&#24819;&#23454;&#29616;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We settle the sample complexity of policy learning for the maximization of the long run average reward associated with a uniformly ergodic Markov decision process (MDP), assuming a generative model. In this context, the existing literature provides a sample complexity upper bound of $\widetilde O(|S||A|t_{\text{mix}}^2 \epsilon^{-2})$ and a lower bound of $\Omega(|S||A|t_{\text{mix}} \epsilon^{-2})$. In these expressions, $|S|$ and $|A|$ denote the cardinalities of the state and action spaces respectively, $t_{\text{mix}}$ serves as a uniform upper limit for the total variation mixing times, and $\epsilon$ signifies the error tolerance. Therefore, a notable gap of $t_{\text{mix}}$ still remains to be bridged. Our primary contribution is to establish an estimator for the optimal policy of average reward MDPs with a sample complexity of $\widetilde O(|S||A|t_{\text{mix}}\epsilon^{-2})$, effectively reaching the lower bound in the literature. This is achieved by combining algorithmic idea
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#37319;&#29992;&#36793;&#38469;&#28789;&#25935;&#24230;&#27169;&#22411;&#26469;&#35299;&#20915;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#21512;&#20316;&#20013;&#26410;&#34987;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#38382;&#39064;&#30340;&#26032;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#21644;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#32479;&#35745;&#24314;&#27169;&#65292;&#20197;&#25511;&#21046;&#28508;&#22312;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#24433;&#21709;&#65292;&#24182;&#36890;&#36807;&#25512;&#36831;&#21512;&#20316;&#31995;&#32479;&#26469;&#21033;&#29992;&#19981;&#21516;&#20915;&#31574;&#32773;&#30340;&#19987;&#19994;&#30693;&#35782;&#12290;</title><link>http://arxiv.org/abs/2310.08824</link><description>&lt;p&gt;
&#24102;&#26377;&#20154;&#24037;&#26234;&#33021;&#22242;&#38431;&#30340;&#28151;&#28102;&#40065;&#26834;&#30340;&#31574;&#30053;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
Confounding-Robust Policy Improvement with Human-AI Teams. (arXiv:2310.08824v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08824
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#37319;&#29992;&#36793;&#38469;&#28789;&#25935;&#24230;&#27169;&#22411;&#26469;&#35299;&#20915;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#21512;&#20316;&#20013;&#26410;&#34987;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#38382;&#39064;&#30340;&#26032;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#21644;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#32479;&#35745;&#24314;&#27169;&#65292;&#20197;&#25511;&#21046;&#28508;&#22312;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#24433;&#21709;&#65292;&#24182;&#36890;&#36807;&#25512;&#36831;&#21512;&#20316;&#31995;&#32479;&#26469;&#21033;&#29992;&#19981;&#21516;&#20915;&#31574;&#32773;&#30340;&#19987;&#19994;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#30340;&#21512;&#20316;&#26377;&#21487;&#33021;&#36890;&#36807;&#20805;&#20998;&#21457;&#25381;&#20154;&#31867;&#19987;&#23478;&#21644;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#30456;&#20114;&#34917;&#20805;&#20248;&#21183;&#26469;&#25913;&#21464;&#21508;&#20010;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#26410;&#34987;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#21487;&#33021;&#20250;&#30772;&#22351;&#36825;&#31181;&#21512;&#20316;&#30340;&#26377;&#25928;&#24615;&#65292;&#23548;&#33268;&#20559;&#35265;&#21644;&#19981;&#21487;&#38752;&#30340;&#32467;&#26524;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#21512;&#20316;&#20013;&#26410;&#34987;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#38382;&#39064;&#30340;&#26032;&#26041;&#27861;&#65292;&#21363;&#37319;&#29992;&#36793;&#38469;&#28789;&#25935;&#24230;&#27169;&#22411;&#65288;MSM&#65289;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#19982;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#32479;&#35745;&#24314;&#27169;&#30456;&#32467;&#21512;&#65292;&#20197;&#32771;&#34385;&#28508;&#22312;&#30340;&#21487;&#33021;&#20250;&#38544;&#34255;&#30340;&#28151;&#28102;&#22240;&#32032;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25512;&#36831;&#21512;&#20316;&#26694;&#26550;&#65292;&#23558;&#36793;&#38469;&#28789;&#25935;&#24230;&#27169;&#22411;&#32435;&#20837;&#35266;&#27979;&#25968;&#25454;&#20013;&#30340;&#31574;&#30053;&#23398;&#20064;&#65292;&#20351;&#31995;&#32479;&#33021;&#22815;&#25511;&#21046;&#26410;&#34987;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20010;&#24615;&#21270;&#30340;&#25512;&#36831;&#21512;&#20316;&#31995;&#32479;&#65292;&#20197;&#21033;&#29992;&#19981;&#21516;&#20154;&#31867;&#20915;&#31574;&#32773;&#30340;&#22810;&#26679;&#21270;&#19987;&#19994;&#30693;&#35782;&#12290;&#36890;&#36807;&#35843;&#25972;&#28508;&#22312;&#30340;&#20559;&#35265;&#65292;&#25105;&#20204;&#30340;&#35299;&#20915;&#26041;&#26696;&#33021;&#22815;&#25552;&#39640;&#21512;&#20316;&#32467;&#26524;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Human-AI collaboration has the potential to transform various domains by leveraging the complementary strengths of human experts and Artificial Intelligence (AI) systems. However, unobserved confounding can undermine the effectiveness of this collaboration, leading to biased and unreliable outcomes. In this paper, we propose a novel solution to address unobserved confounding in human-AI collaboration by employing the marginal sensitivity model (MSM). Our approach combines domain expertise with AI-driven statistical modeling to account for potential confounders that may otherwise remain hidden. We present a deferral collaboration framework for incorporating the MSM into policy learning from observational data, enabling the system to control for the influence of unobserved confounding factors. In addition, we propose a personalized deferral collaboration system to leverage the diverse expertise of different human decision-makers. By adjusting for potential biases, our proposed solution e
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#31232;&#30095;&#21033;&#29992;&#30340;&#37325;&#26032;&#25490;&#24207;&#31639;&#27861;&#26469;&#26816;&#27979;&#24352;&#37327;&#30340;&#20381;&#36182;&#32467;&#26500;&#25913;&#21464;&#65292;&#24182;&#24212;&#29992;&#20110;&#20004;&#20010;&#26679;&#26412;&#30340;&#30456;&#20851;&#24615;/&#20559;&#30456;&#20851;&#24615;&#27604;&#36739;&#65292;&#20197;&#25552;&#39640;&#27979;&#35797;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.08798</link><description>&lt;p&gt;
&#36890;&#36807;&#31232;&#30095;&#21033;&#29992;&#30340;&#37325;&#26032;&#25490;&#24207;&#31639;&#27861;&#26816;&#27979;&#24352;&#37327;&#20381;&#36182;&#32467;&#26500;&#30340;&#25913;&#21464;
&lt;/p&gt;
&lt;p&gt;
Alteration Detection of Tensor Dependence Structure via Sparsity-Exploited Reranking Algorithm. (arXiv:2310.08798v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08798
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#31232;&#30095;&#21033;&#29992;&#30340;&#37325;&#26032;&#25490;&#24207;&#31639;&#27861;&#26469;&#26816;&#27979;&#24352;&#37327;&#30340;&#20381;&#36182;&#32467;&#26500;&#25913;&#21464;&#65292;&#24182;&#24212;&#29992;&#20110;&#20004;&#20010;&#26679;&#26412;&#30340;&#30456;&#20851;&#24615;/&#20559;&#30456;&#20851;&#24615;&#27604;&#36739;&#65292;&#20197;&#25552;&#39640;&#27979;&#35797;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24352;&#37327;&#20540;&#25968;&#25454;&#32463;&#24120;&#20986;&#29616;&#22312;&#21508;&#31181;&#31185;&#23398;&#24212;&#29992;&#20013;&#65292;&#20854;&#20013;&#35768;&#22810;&#21487;&#20197;&#36716;&#21270;&#20026;&#24352;&#37327;&#20381;&#36182;&#32467;&#26500;&#30340;&#25913;&#21464;&#26816;&#27979;&#38382;&#39064;&#12290;&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#27969;&#34892;&#30340;&#24352;&#37327;&#27491;&#24577;&#20998;&#24067;&#26469;&#21046;&#23450;&#38382;&#39064;&#65292;&#24182;&#26088;&#22312;&#27604;&#36739;&#24352;&#37327;&#35266;&#27979;&#20540;&#30340;&#20004;&#20010;&#26679;&#26412;&#30340;&#30456;&#20851;&#24615;/&#20559;&#30456;&#20851;&#24615;&#12290;&#36890;&#36807;&#21435;&#30456;&#20851;&#21644;&#20013;&#24515;&#21270;&#65292;&#37319;&#29992;&#21487;&#20998;&#31163;&#30340;&#21327;&#26041;&#24046;&#32467;&#26500;&#26469;&#27719;&#38598;&#26469;&#33258;&#19981;&#21516;&#24352;&#37327;&#27169;&#24335;&#30340;&#26679;&#26412;&#20449;&#24687;&#65292;&#20197;&#22686;&#24378;&#27979;&#35797;&#30340;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31232;&#30095;&#21033;&#29992;&#30340;&#37325;&#26032;&#25490;&#24207;&#31639;&#27861;(SERA)&#26469;&#36827;&#19968;&#27493;&#25552;&#39640;&#22810;&#37325;&#26816;&#39564;&#25928;&#29575;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#37325;&#26032;&#25490;&#24207;&#20174;&#20027;&#35201;&#27979;&#35797;&#32479;&#35745;&#37327;&#20013;&#23548;&#20986;&#30340;p&#20540;&#26469;&#23454;&#29616;&#65292;&#36890;&#36807;&#24341;&#20837;&#31934;&#24515;&#26500;&#36896;&#30340;&#36741;&#21161;&#24352;&#37327;&#24207;&#21015;&#12290;&#38500;&#20102;&#24352;&#37327;&#26694;&#26550;&#22806;&#65292;SERA&#36824;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#20004;&#20010;&#26679;&#26412;&#22823;&#35268;&#27169;&#25512;&#26029;&#38382;&#39064;&#19982;&#31232;&#30095;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tensor-valued data arise frequently from a wide variety of scientific applications, and many among them can be translated into an alteration detection problem of tensor dependence structures. In this article, we formulate the problem under the popularly adopted tensor-normal distributions and aim at two-sample correlation/partial correlation comparisons of tensor-valued observations. Through decorrelation and centralization, a separable covariance structure is employed to pool sample information from different tensor modes to enhance the power of the test. Additionally, we propose a novel Sparsity-Exploited Reranking Algorithm (SERA) to further improve the multiple testing efficiency. The algorithm is approached through reranking of the p-values derived from the primary test statistics, by incorporating a carefully constructed auxiliary tensor sequence. Besides the tensor framework, SERA is also generally applicable to a wide range of two-sample large-scale inference problems with spar
&lt;/p&gt;</description></item><item><title>PhyloGFN&#26159;&#19968;&#31181;&#22522;&#20110;&#29983;&#25104;&#27969;&#32593;&#32476;&#30340;&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#37319;&#26679;&#22797;&#26434;&#30340;&#32452;&#21512;&#32467;&#26500;&#65292;&#33021;&#22815;&#20135;&#29983;&#22810;&#26679;&#19988;&#39640;&#36136;&#37327;&#30340;&#36827;&#21270;&#20551;&#35774;&#65292;&#24182;&#22312;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#26041;&#38754;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.08774</link><description>&lt;p&gt;
PhyloGFN: &#22522;&#20110;&#29983;&#25104;&#27969;&#32593;&#32476;&#30340;&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
PhyloGFN: Phylogenetic inference with generative flow networks. (arXiv:2310.08774v1 [q-bio.PE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08774
&lt;/p&gt;
&lt;p&gt;
PhyloGFN&#26159;&#19968;&#31181;&#22522;&#20110;&#29983;&#25104;&#27969;&#32593;&#32476;&#30340;&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#37319;&#26679;&#22797;&#26434;&#30340;&#32452;&#21512;&#32467;&#26500;&#65292;&#33021;&#22815;&#20135;&#29983;&#22810;&#26679;&#19988;&#39640;&#36136;&#37327;&#30340;&#36827;&#21270;&#20551;&#35774;&#65292;&#24182;&#22312;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#26041;&#38754;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31995;&#32479;&#21457;&#32946;&#23398;&#26159;&#35745;&#31639;&#29983;&#29289;&#23398;&#30340;&#19968;&#20010;&#20998;&#25903;&#65292;&#30740;&#31350;&#29983;&#29289;&#23454;&#20307;&#20043;&#38388;&#30340;&#36827;&#21270;&#20851;&#31995;&#12290;&#23613;&#31649;&#26377;&#30528;&#24736;&#20037;&#30340;&#21382;&#21490;&#21644;&#20247;&#22810;&#24212;&#29992;&#65292;&#20294;&#20174;&#24207;&#21015;&#25968;&#25454;&#25512;&#26029;&#31995;&#32479;&#21457;&#32946;&#26641;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65306;&#26641;&#31354;&#38388;&#30340;&#39640;&#22797;&#26434;&#24615;&#23545;&#24403;&#21069;&#30340;&#32452;&#21512;&#21644;&#27010;&#29575;&#25216;&#26415;&#26500;&#25104;&#20102;&#37325;&#35201;&#38556;&#30861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#29983;&#25104;&#27969;&#32593;&#32476;&#65288;GFlowNets&#65289;&#30340;&#26694;&#26550;&#26469;&#35299;&#20915;&#31995;&#32479;&#21457;&#32946;&#23398;&#20013;&#30340;&#20004;&#20010;&#26680;&#24515;&#38382;&#39064;&#65306;&#22522;&#20110;&#26368;&#31616;&#21407;&#21017;&#30340;&#21644;&#36125;&#21494;&#26031;&#30340;&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;&#12290;&#30001;&#20110;GFlowNets&#36866;&#29992;&#20110;&#37319;&#26679;&#22797;&#26434;&#30340;&#32452;&#21512;&#32467;&#26500;&#65292;&#23427;&#20204;&#26159;&#25506;&#32034;&#21644;&#37319;&#26679;&#26641;&#25299;&#25169;&#21644;&#36827;&#21270;&#36317;&#31163;&#30340;&#22810;&#27169;&#24577;&#21518;&#39564;&#20998;&#24067;&#30340;&#33258;&#28982;&#36873;&#25321;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#25674;&#36824;&#21518;&#39564;&#37319;&#26679;&#22120;PhyloGFN&#22312;&#30495;&#23454;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#20135;&#29983;&#22810;&#26679;&#19988;&#39640;&#36136;&#37327;&#30340;&#36827;&#21270;&#20551;&#35774;&#12290;PhyloGFN&#22312;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#26041;&#38754;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;&#30456;&#27604;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Phylogenetics is a branch of computational biology that studies the evolutionary relationships among biological entities. Its long history and numerous applications notwithstanding, inference of phylogenetic trees from sequence data remains challenging: the high complexity of tree space poses a significant obstacle for the current combinatorial and probabilistic techniques. In this paper, we adopt the framework of generative flow networks (GFlowNets) to tackle two core problems in phylogenetics: parsimony-based and Bayesian phylogenetic inference. Because GFlowNets are well-suited for sampling complex combinatorial structures, they are a natural choice for exploring and sampling from the multimodal posterior distribution over tree topologies and evolutionary distances. We demonstrate that our amortized posterior sampler, PhyloGFN, produces diverse and high-quality evolutionary hypotheses on real benchmark datasets. PhyloGFN is competitive with prior works in marginal likelihood estimat
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;EEG&#20998;&#31867;&#20013;&#20351;&#29992;&#26032;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#20943;&#23569;&#20102;&#22312;&#26410;&#35265;&#27979;&#35797;&#23545;&#35937;&#19978;&#30340;&#24615;&#33021;&#19979;&#38477;&#12290;&#36890;&#36807;&#35774;&#35745;&#27491;&#21017;&#21270;&#24809;&#32602;&#21644;&#21457;&#25955;&#20272;&#35745;&#31639;&#27861;&#65292;&#25105;&#20204;&#25104;&#21151;&#22320;&#22312;&#27169;&#22411;&#35757;&#32451;&#20013;&#24378;&#21046;&#25191;&#34892;&#20102;&#32479;&#35745;&#20851;&#31995;&#65292;&#24182;&#22312;&#22823;&#37327;&#35745;&#31639;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.08762</link><description>&lt;p&gt;
EEG&#20998;&#31867;&#20013;&#37319;&#29992;&#21457;&#25955;&#20272;&#35745;&#31283;&#23450;&#20027;&#20307;&#36801;&#31227;
&lt;/p&gt;
&lt;p&gt;
Stabilizing Subject Transfer in EEG Classification with Divergence Estimation. (arXiv:2310.08762v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08762
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;EEG&#20998;&#31867;&#20013;&#20351;&#29992;&#26032;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#20943;&#23569;&#20102;&#22312;&#26410;&#35265;&#27979;&#35797;&#23545;&#35937;&#19978;&#30340;&#24615;&#33021;&#19979;&#38477;&#12290;&#36890;&#36807;&#35774;&#35745;&#27491;&#21017;&#21270;&#24809;&#32602;&#21644;&#21457;&#25955;&#20272;&#35745;&#31639;&#27861;&#65292;&#25105;&#20204;&#25104;&#21151;&#22320;&#22312;&#27169;&#22411;&#35757;&#32451;&#20013;&#24378;&#21046;&#25191;&#34892;&#20102;&#32479;&#35745;&#20851;&#31995;&#65292;&#24182;&#22312;&#22823;&#37327;&#35745;&#31639;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30005;encephalogram(EEG)&#25968;&#25454;&#30340;&#20998;&#31867;&#27169;&#22411;&#22312;&#26410;&#35265;&#27979;&#35797;&#23545;&#35937;&#19978;&#30340;&#34920;&#29616;&#22823;&#24133;&#19979;&#38477;&#12290;&#25105;&#20204;&#36890;&#36807;&#26032;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#20943;&#23569;&#24615;&#33021;&#19979;&#38477;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#20010;&#22270;&#27169;&#22411;&#26469;&#25551;&#36848;EEG&#20998;&#31867;&#20219;&#21153;&#12290;&#20174;&#27599;&#20010;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#22312;&#29702;&#24819;&#30340;&#35757;&#32451;&#22330;&#26223;&#19979;&#65288;&#20855;&#26377;&#26080;&#38480;&#25968;&#25454;&#21644;&#20840;&#23616;&#26368;&#20248;&#27169;&#22411;&#65289;&#65292;&#24212;&#35813;&#25104;&#31435;&#20294;&#22312;&#23454;&#36341;&#20013;&#21487;&#33021;&#19981;&#25104;&#31435;&#30340;&#32479;&#35745;&#20851;&#31995;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#27491;&#21017;&#21270;&#24809;&#32602;&#26469;&#24378;&#21046;&#25191;&#34892;&#36825;&#20123;&#20851;&#31995;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#36866;&#29992;&#20316;&#20026;&#20195;&#29702;&#25968;&#37327;&#30340;&#21512;&#36866;&#30340;&#21457;&#25955;&#65288;&#22914;&#20114;&#20449;&#24687;&#21644;Wasserstein-1&#65289;&#65292;&#21487;&#20197;&#29992;&#26469;&#27979;&#37327;&#32479;&#35745;&#29420;&#31435;&#21644;&#30456;&#20851;&#20851;&#31995;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20351;&#29992;&#20108;&#27425;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#39640;&#25928;&#20272;&#35745;&#36825;&#20123;&#25968;&#37327;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;&#22823;&#22411;&#22522;&#20934;EEG&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#22823;&#37327;&#30340;&#35745;&#31639;&#23454;&#39564;&#65292;&#27604;&#36739;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classification models for electroencephalogram (EEG) data show a large decrease in performance when evaluated on unseen test sub jects. We reduce this performance decrease using new regularization techniques during model training. We propose several graphical models to describe an EEG classification task. From each model, we identify statistical relationships that should hold true in an idealized training scenario (with infinite data and a globally-optimal model) but that may not hold in practice. We design regularization penalties to enforce these relationships in two stages. First, we identify suitable proxy quantities (divergences such as Mutual Information and Wasserstein-1) that can be used to measure statistical independence and dependence relationships. Second, we provide algorithms to efficiently estimate these quantities during training using secondary neural network models. We conduct extensive computational experiments using a large benchmark EEG dataset, comparing our propo
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#30340;&#38598;&#21512;&#28388;&#27874;&#22120;&#65292;&#33021;&#22815;&#22788;&#29702;&#37325;&#23614;&#20998;&#24067;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#35843;&#33410;&#33192;&#32960;&#21644;&#23450;&#20301;&#21442;&#25968;&#12290;&#36825;&#20010;&#28388;&#27874;&#22120;&#36890;&#36807;&#23558;&#20808;&#39564;&#21644;&#21518;&#39564;&#26356;&#26032;&#19982;t-&#20998;&#24067;&#30340;&#31934;&#30830;&#25512;&#26029;&#30456;&#32467;&#21512;&#65292;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#21644;&#23545;&#31163;&#32676;&#35266;&#27979;&#20540;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.08741</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#38598;&#21512;&#28388;&#27874;&#22120;&#23545;&#37325;&#23614;&#20998;&#24067;&#30340;&#24212;&#29992;&#65306;&#20813;&#35843;&#33410;&#33192;&#32960;&#21644;&#23450;&#20301;
&lt;/p&gt;
&lt;p&gt;
An adaptive ensemble filter for heavy-tailed distributions: tuning-free inflation and localization. (arXiv:2310.08741v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08741
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#30340;&#38598;&#21512;&#28388;&#27874;&#22120;&#65292;&#33021;&#22815;&#22788;&#29702;&#37325;&#23614;&#20998;&#24067;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#35843;&#33410;&#33192;&#32960;&#21644;&#23450;&#20301;&#21442;&#25968;&#12290;&#36825;&#20010;&#28388;&#27874;&#22120;&#36890;&#36807;&#23558;&#20808;&#39564;&#21644;&#21518;&#39564;&#26356;&#26032;&#19982;t-&#20998;&#24067;&#30340;&#31934;&#30830;&#25512;&#26029;&#30456;&#32467;&#21512;&#65292;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#21644;&#23545;&#31163;&#32676;&#35266;&#27979;&#20540;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37325;&#23614;&#20998;&#24067;&#26159;&#30001;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#21644;&#35266;&#27979;&#36807;&#31243;&#20197;&#21450;&#29289;&#29702;&#20256;&#24863;&#22120;&#30340;&#19981;&#30830;&#23450;&#24615;&#36896;&#25104;&#30340;&#28388;&#27874;&#20998;&#24067;&#30340;&#24120;&#35265;&#29305;&#24449;&#12290;&#22312;&#36825;&#20123;&#24773;&#20917;&#19979;&#65292;&#22522;&#20110;&#39640;&#26031;&#20551;&#35774;&#30340;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#21450;&#20854;&#38598;&#21512;&#29256;&#26412; - &#38598;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120; (EnKF) - &#30340;&#24615;&#33021;&#20250;&#19979;&#38477;&#12290;t-&#20998;&#24067;&#26159;&#19968;&#20010;&#21442;&#25968;&#21270;&#30340;&#20998;&#24067;&#26063;&#65292;&#20854;&#23614;&#37096;&#37325;&#24230;&#30001;&#33258;&#30001;&#24230; $\nu$ &#35843;&#21046;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;Cauchy&#20998;&#24067;&#21644;&#39640;&#26031;&#20998;&#24067;&#20998;&#21035;&#23545;&#24212;&#20110; $\nu = 1$ &#21644; $\nu = \infty$ &#30340;t-&#20998;&#24067;&#30340;&#26497;&#31471;&#24773;&#20917;&#12290;&#20511;&#21161;&#20110;&#27979;&#37327;&#20256;&#36755;&#30340;&#24037;&#20855; (Spantini et al., SIAM Review, 2022)&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;EnKF&#30340;&#19968;&#33324;&#21270;&#29256;&#26412;&#65292;&#20854;&#20808;&#39564;&#21040;&#21518;&#39564;&#26356;&#26032;&#33021;&#22815;&#23545;t-&#20998;&#24067;&#36827;&#34892;&#31934;&#30830;&#25512;&#26029;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#36825;&#20010;&#28388;&#27874;&#22120;&#23545;&#30001;&#35266;&#27979;&#27169;&#22411;&#29983;&#25104;&#30340;&#31163;&#32676;&#21512;&#25104;&#35266;&#27979;&#20540;&#30340;&#25935;&#24863;&#24615;&#36739;&#23567;&#65292;&#23588;&#20854;&#22312;&#36739;&#23567;&#30340; $\nu$ &#20540;&#19979;&#12290;&#27492;&#22806;&#65292;&#23427;&#24674;&#22797;&#20102;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Heavy tails is a common feature of filtering distributions that results from the nonlinear dynamical and observation processes as well as the uncertainty from physical sensors. In these settings, the Kalman filter and its ensemble version - the ensemble Kalman filter (EnKF) - that have been designed under Gaussian assumptions result in degraded performance. t-distributions are a parametric family of distributions whose tail-heaviness is modulated by a degree of freedom $\nu$. Interestingly, Cauchy and Gaussian distributions correspond to the extreme cases of a t-distribution for $\nu = 1$ and $\nu = \infty$, respectively. Leveraging tools from measure transport (Spantini et al., SIAM Review, 2022), we present a generalization of the EnKF whose prior-to-posterior update leads to exact inference for t-distributions. We demonstrate that this filter is less sensitive to outlying synthetic observations generated by the observation model for small $\nu$. Moreover, it recovers the Kalman filt
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#23398;&#29983;&#36827;&#34892;&#22240;&#26524;&#19982;&#39044;&#27979;&#24615;&#23450;&#20301;&#30340;&#27604;&#36739;&#65292;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#23398;&#29983;&#21161;&#23398;&#37329;&#32493;&#31614;&#39046;&#22495;&#23454;&#39564;&#20013;&#40723;&#21169;&#23545;&#35937;&#36873;&#25321;&#30340;&#20215;&#20540;&#12290;&#36825;&#39033;&#22823;&#35268;&#27169;&#23454;&#22320;&#23454;&#39564;&#25581;&#31034;&#20102;&#23450;&#20301;&#24178;&#39044;&#23545;&#20110;&#19981;&#21516;&#23398;&#29983;&#30340;&#25928;&#26524;&#65292;&#20026;&#24178;&#39044;&#31574;&#30053;&#30340;&#20248;&#21270;&#25552;&#20379;&#20102;&#21442;&#32771;&#12290;</title><link>http://arxiv.org/abs/2310.08672</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#40723;&#21169;&#23545;&#35937;&#36873;&#25321;&#65306;&#22312;&#23398;&#29983;&#21161;&#23398;&#37329;&#32493;&#31614;&#39046;&#22495;&#23454;&#39564;&#20013;&#30340;&#22240;&#26524;&#19982;&#39044;&#27979;&#24615;&#30446;&#26631;&#23450;&#20301;
&lt;/p&gt;
&lt;p&gt;
Machine Learning Who to Nudge: Causal vs Predictive Targeting in a Field Experiment on Student Financial Aid Renewal. (arXiv:2310.08672v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08672
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#23398;&#29983;&#36827;&#34892;&#22240;&#26524;&#19982;&#39044;&#27979;&#24615;&#23450;&#20301;&#30340;&#27604;&#36739;&#65292;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#23398;&#29983;&#21161;&#23398;&#37329;&#32493;&#31614;&#39046;&#22495;&#23454;&#39564;&#20013;&#40723;&#21169;&#23545;&#35937;&#36873;&#25321;&#30340;&#20215;&#20540;&#12290;&#36825;&#39033;&#22823;&#35268;&#27169;&#23454;&#22320;&#23454;&#39564;&#25581;&#31034;&#20102;&#23450;&#20301;&#24178;&#39044;&#23545;&#20110;&#19981;&#21516;&#23398;&#29983;&#30340;&#25928;&#26524;&#65292;&#20026;&#24178;&#39044;&#31574;&#30053;&#30340;&#20248;&#21270;&#25552;&#20379;&#20102;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24773;&#22659;&#19979;&#65292;&#24178;&#39044;&#21487;&#33021;&#23545;&#26576;&#20123;&#20154;&#27604;&#20854;&#20182;&#20154;&#26356;&#26377;&#25928;&#65292;&#22240;&#27492;&#23450;&#20301;&#24178;&#39044;&#21487;&#33021;&#26159;&#26377;&#30410;&#30340;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#35268;&#27169;&#24222;&#22823;&#30340;&#23454;&#22320;&#23454;&#39564;&#65288;&#36229;&#36807;53,000&#21517;&#22823;&#23398;&#29983;&#65289;&#26469;&#20998;&#26512;&#22312;&#23398;&#29983;&#21161;&#23398;&#37329;&#32493;&#31614;&#21069;&#20351;&#29992;&#8220;&#40723;&#21169;&#8221;&#31574;&#30053;&#30340;&#20215;&#20540;&#12290;&#25105;&#20204;&#39318;&#20808;&#20351;&#29992;&#22522;&#32447;&#26041;&#27861;&#36827;&#34892;&#23450;&#20301;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#22522;&#20110;&#19968;&#20010;&#20272;&#35745;&#24322;&#36136;&#22788;&#29702;&#25928;&#24212;&#30340;&#22240;&#26524;&#26862;&#26519;&#36827;&#34892;&#23450;&#20301;&#65292;&#24182;&#26681;&#25454;&#20272;&#35745;&#20986;&#30340;&#25317;&#26377;&#26368;&#39640;&#22788;&#29702;&#25928;&#24212;&#30340;&#23398;&#29983;&#26469;&#36827;&#34892;&#22788;&#29702;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#35780;&#20272;&#20004;&#31181;&#26367;&#20195;&#30340;&#23450;&#20301;&#31574;&#30053;&#65292;&#19968;&#31181;&#26159;&#38024;&#23545;&#22312;&#27809;&#26377;&#24178;&#39044;&#30340;&#24773;&#20917;&#19979;&#39044;&#27979;&#21040;&#20302;&#21161;&#23398;&#37329;&#32493;&#31614;&#27010;&#29575;&#30340;&#23398;&#29983;&#65292;&#21478;&#19968;&#31181;&#26159;&#38024;&#23545;&#39044;&#27979;&#21040;&#39640;&#27010;&#29575;&#30340;&#23398;&#29983;&#12290;&#39044;&#27979;&#30340;&#22522;&#32447;&#32467;&#26524;&#24182;&#19981;&#26159;&#23450;&#20301;&#30340;&#29702;&#24819;&#26631;&#20934;&#65292;&#32780;&#19988;&#22312;&#20808;&#39564;&#19978;&#20063;&#19981;&#28165;&#26970;&#26159;&#20248;&#20808;&#32771;&#34385;&#20302;&#12289;&#39640;&#36824;&#26159;&#20013;&#38388;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many settings, interventions may be more effective for some individuals than others, so that targeting interventions may be beneficial. We analyze the value of targeting in the context of a large-scale field experiment with over 53,000 college students, where the goal was to use "nudges" to encourage students to renew their financial-aid applications before a non-binding deadline. We begin with baseline approaches to targeting. First, we target based on a causal forest that estimates heterogeneous treatment effects and then assigns students to treatment according to those estimated to have the highest treatment effects. Next, we evaluate two alternative targeting policies, one targeting students with low predicted probability of renewing financial aid in the absence of the treatment, the other targeting those with high probability. The predicted baseline outcome is not the ideal criterion for targeting, nor is it a priori clear whether to prioritize low, high, or intermediate predic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26102;&#38388;&#21521;&#37327;&#21270;&#30340;&#25968;&#20540;&#31215;&#20998;&#26041;&#27861;&#65292;&#29992;&#20110;&#31215;&#20998;&#21018;&#24615;&#24120;&#24494;&#20998;&#26041;&#31243;&#32452;&#65292;&#24182;&#36890;&#36807;&#20276;&#38543;&#26041;&#27861;&#35745;&#31639;&#21442;&#25968;&#26799;&#24230;&#12290;&#35813;&#26041;&#27861;&#22312;&#29420;&#31435;&#26102;&#38388;&#24207;&#21015;&#21644;&#36830;&#32493;&#26102;&#38388;&#27493;&#39588;&#30340;&#25209;&#27425;&#19978;&#36827;&#34892;&#21521;&#37327;&#21270;&#65292;&#25552;&#20379;&#20102;&#26356;&#39640;&#30340;&#35745;&#31639;&#24102;&#23485;&#65292;&#33021;&#22815;&#20805;&#20998;&#21033;&#29992;&#29616;&#20195;GPU&#24182;&#23454;&#29616;&#36229;&#36807;100&#20493;&#30340;&#21152;&#36895;&#12290;</title><link>http://arxiv.org/abs/2310.08649</link><description>&lt;p&gt;
&#26102;&#38388;&#21521;&#37327;&#21270;&#25968;&#20540;&#31215;&#20998;&#29992;&#20110;ODE&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Time-vectorized numerical integration for systems of ODEs. (arXiv:2310.08649v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08649
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26102;&#38388;&#21521;&#37327;&#21270;&#30340;&#25968;&#20540;&#31215;&#20998;&#26041;&#27861;&#65292;&#29992;&#20110;&#31215;&#20998;&#21018;&#24615;&#24120;&#24494;&#20998;&#26041;&#31243;&#32452;&#65292;&#24182;&#36890;&#36807;&#20276;&#38543;&#26041;&#27861;&#35745;&#31639;&#21442;&#25968;&#26799;&#24230;&#12290;&#35813;&#26041;&#27861;&#22312;&#29420;&#31435;&#26102;&#38388;&#24207;&#21015;&#21644;&#36830;&#32493;&#26102;&#38388;&#27493;&#39588;&#30340;&#25209;&#27425;&#19978;&#36827;&#34892;&#21521;&#37327;&#21270;&#65292;&#25552;&#20379;&#20102;&#26356;&#39640;&#30340;&#35745;&#31639;&#24102;&#23485;&#65292;&#33021;&#22815;&#20805;&#20998;&#21033;&#29992;&#29616;&#20195;GPU&#24182;&#23454;&#29616;&#36229;&#36807;100&#20493;&#30340;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31185;&#23398;&#38382;&#39064;&#20013;&#65292;&#21018;&#24615;&#30340;&#24120;&#24494;&#20998;&#26041;&#31243;&#32452;&#21644;&#31232;&#30095;&#35757;&#32451;&#25968;&#25454;&#26159;&#24456;&#24120;&#35265;&#30340;&#12290;&#26412;&#25991;&#25551;&#36848;&#20102;&#29992;&#20110;&#31215;&#20998;&#21018;&#24615;&#24120;&#24494;&#20998;&#26041;&#31243;&#32452;&#30340;&#39640;&#25928;&#38544;&#24335;&#21521;&#37327;&#21270;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#20276;&#38543;&#26041;&#27861;&#35745;&#31639;&#21442;&#25968;&#26799;&#24230;&#12290;&#20027;&#35201;&#21019;&#26032;&#26159;&#22312;&#29420;&#31435;&#26102;&#38388;&#24207;&#21015;&#30340;&#25968;&#37327;&#21644;&#36830;&#32493;&#26102;&#38388;&#27493;&#39588;&#30340;&#25209;&#27425;&#25110;&#8220;&#22359;&#8221;&#19978;&#21521;&#37327;&#21270;&#38382;&#39064;&#65292;&#20174;&#32780;&#26377;&#25928;&#22320;&#21521;&#37327;&#21270;&#38544;&#24335;ODE&#31995;&#32479;&#30340;&#32452;&#35013;&#12290;&#21518;&#21521;Euler&#26041;&#27861;&#30340;&#32447;&#24615;&#21270;&#38544;&#24335;&#31995;&#32479;&#30340;&#22359;&#21452;&#23545;&#35282;&#32467;&#26500;&#20801;&#35768;&#36827;&#19968;&#27493;&#20351;&#29992;&#24182;&#34892;&#24490;&#29615;&#32422;&#21270;&#65288;PCR&#65289;&#36827;&#34892;&#21521;&#37327;&#21270;&#12290;&#22312;&#36755;&#20837;&#25968;&#25454;&#30340;&#20004;&#20010;&#36724;&#19978;&#36827;&#34892;&#21521;&#37327;&#21270;&#65292;&#20026;&#35745;&#31639;&#35774;&#22791;&#25552;&#20379;&#20102;&#26356;&#39640;&#30340;&#35745;&#31639;&#24102;&#23485;&#65292;&#20351;&#24471;&#21363;&#20351;&#26159;&#30456;&#23545;&#31232;&#30095;&#30340;&#38382;&#39064;&#20063;&#33021;&#20805;&#20998;&#21033;&#29992;&#29616;&#20195;GPU&#65292;&#24182;&#23454;&#29616;&#20102;&#36229;&#36807;100&#20493;&#30340;&#21152;&#36895;&#65292;&#19982;&#26631;&#20934;&#30340;&#39034;&#24207;&#26102;&#38388;&#31215;&#20998;&#30456;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stiff systems of ordinary differential equations (ODEs) and sparse training data are common in scientific problems. This paper describes efficient, implicit, vectorized methods for integrating stiff systems of ordinary differential equations through time and calculating parameter gradients with the adjoint method. The main innovation is to vectorize the problem both over the number of independent times series and over a batch or "chunk" of sequential time steps, effectively vectorizing the assembly of the implicit system of ODEs. The block-bidiagonal structure of the linearized implicit system for the backward Euler method allows for further vectorization using parallel cyclic reduction (PCR). Vectorizing over both axes of the input data provides a higher bandwidth of calculations to the computing device, allowing even problems with comparatively sparse data to fully utilize modern GPUs and achieving speed ups of greater than 100x, compared to standard, sequential time integration. We 
&lt;/p&gt;</description></item><item><title>SmoothLLM&#26159;&#31532;&#19968;&#20010;&#29992;&#20110;&#20943;&#36731;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19978;&#36234;&#29425;&#25915;&#20987;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#36755;&#20837;&#25552;&#31034;&#19978;&#38543;&#26426;&#25200;&#21160;&#24182;&#27719;&#24635;&#39044;&#27979;&#32467;&#26524;&#26469;&#26816;&#27979;&#23545;&#25239;&#24615;&#36755;&#20837;&#65292;&#23558;&#25915;&#20987;&#25104;&#21151;&#29575;&#38477;&#20302;&#33267;&#19981;&#21040;&#19968;&#20010;&#30334;&#20998;&#28857;&#65292;&#24182;&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#30340;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.03684</link><description>&lt;p&gt;
SmoothLLM&#65306;&#38450;&#24481;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20813;&#21463;&#36234;&#29425;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks. (arXiv:2310.03684v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03684
&lt;/p&gt;
&lt;p&gt;
SmoothLLM&#26159;&#31532;&#19968;&#20010;&#29992;&#20110;&#20943;&#36731;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19978;&#36234;&#29425;&#25915;&#20987;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#36755;&#20837;&#25552;&#31034;&#19978;&#38543;&#26426;&#25200;&#21160;&#24182;&#27719;&#24635;&#39044;&#27979;&#32467;&#26524;&#26469;&#26816;&#27979;&#23545;&#25239;&#24615;&#36755;&#20837;&#65292;&#23558;&#25915;&#20987;&#25104;&#21151;&#29575;&#38477;&#20302;&#33267;&#19981;&#21040;&#19968;&#20010;&#30334;&#20998;&#28857;&#65292;&#24182;&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#21162;&#21147;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#20445;&#25345;&#19968;&#33268;&#65292;&#20294;&#24191;&#27867;&#20351;&#29992;&#30340;LLM&#65288;&#22914;GPT&#12289;Llama&#12289;Claude&#21644;PaLM&#65289;&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#36234;&#29425;&#25915;&#20987;&#65292;&#21363;&#23545;&#30446;&#26631;LLM&#36827;&#34892;&#27450;&#39575;&#65292;&#20197;&#29983;&#25104;&#19981;&#21512;&#36866;&#30340;&#20869;&#23481;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#28431;&#27934;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;SmoothLLM&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#26088;&#22312;&#20943;&#36731;LLM&#19978;&#30340;&#36234;&#29425;&#25915;&#20987;&#30340;&#31639;&#27861;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#23545;&#25239;&#24615;&#29983;&#25104;&#30340;&#25552;&#31034;&#23545;&#23383;&#31526;&#32423;&#21035;&#30340;&#25913;&#21464;&#24456;&#33030;&#24369;&#65292;&#25105;&#20204;&#30340;&#38450;&#24481;&#39318;&#20808;&#38543;&#26426;&#25200;&#21160;&#32473;&#23450;&#36755;&#20837;&#25552;&#31034;&#30340;&#22810;&#20010;&#21103;&#26412;&#65292;&#28982;&#21518;&#27719;&#24635;&#30456;&#24212;&#30340;&#39044;&#27979;&#32467;&#26524;&#26469;&#26816;&#27979;&#23545;&#25239;&#24615;&#36755;&#20837;&#12290;SmoothLLM&#23558;&#20247;&#22810;&#28909;&#38376;LLM&#30340;&#25915;&#20987;&#25104;&#21151;&#29575;&#38477;&#20302;&#33267;&#19981;&#21040;&#19968;&#20010;&#30334;&#20998;&#28857;&#65292;&#36991;&#20813;&#20102;&#19981;&#24517;&#35201;&#30340;&#20445;&#23432;&#24615;&#65292;&#24182;&#23545;&#25915;&#20987;&#32531;&#35299;&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#30340;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#38450;&#24481;&#20351;&#29992;&#30340;&#26597;&#35810;&#25968;&#37327;&#27604;&#29616;&#26377;&#30340;&#25915;&#20987;&#26041;&#27861;&#23569;&#24471;&#22810;&#65292;&#24182;&#19988;&#19982;&#20219;&#20309;LLM&#20860;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite efforts to align large language models (LLMs) with human values, widely-used LLMs such as GPT, Llama, Claude, and PaLM are susceptible to jailbreaking attacks, wherein an adversary fools a targeted LLM into generating objectionable content. To address this vulnerability, we propose SmoothLLM, the first algorithm designed to mitigate jailbreaking attacks on LLMs. Based on our finding that adversarially-generated prompts are brittle to character-level changes, our defense first randomly perturbs multiple copies of a given input prompt, and then aggregates the corresponding predictions to detect adversarial inputs. SmoothLLM reduces the attack success rate on numerous popular LLMs to below one percentage point, avoids unnecessary conservatism, and admits provable guarantees on attack mitigation. Moreover, our defense uses exponentially fewer queries than existing attacks and is compatible with any LLM.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#38598;&#25104;&#24046;&#20998;&#36827;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#27169;&#25311;&#28151;&#21512;&#21644;&#33258;&#36866;&#24212;&#26426;&#21046;&#26469;&#35299;&#20915;&#19981;&#30830;&#23450;&#26465;&#20214;&#19979;&#30340;&#24211;&#23384;&#31649;&#29702;&#38382;&#39064;&#12290;&#23454;&#35777;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#24211;&#23384;&#31649;&#29702;&#30340;&#36130;&#21153;&#32489;&#25928;&#21644;&#20248;&#21270;&#22823;&#25628;&#32034;&#31354;&#38388;&#12290;</title><link>http://arxiv.org/abs/2309.12852</link><description>&lt;p&gt;
&#22522;&#20110;&#27169;&#25311;&#28151;&#21512;&#21644;&#33258;&#36866;&#24212;&#30340;&#38598;&#25104;&#24046;&#20998;&#36827;&#21270;&#31639;&#27861;&#29992;&#20110;&#19981;&#30830;&#23450;&#26465;&#20214;&#19979;&#30340;&#24211;&#23384;&#31649;&#29702;
&lt;/p&gt;
&lt;p&gt;
Ensemble Differential Evolution with Simulation-Based Hybridization and Self-Adaptation for Inventory Management Under Uncertainty. (arXiv:2309.12852v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12852
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#38598;&#25104;&#24046;&#20998;&#36827;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#27169;&#25311;&#28151;&#21512;&#21644;&#33258;&#36866;&#24212;&#26426;&#21046;&#26469;&#35299;&#20915;&#19981;&#30830;&#23450;&#26465;&#20214;&#19979;&#30340;&#24211;&#23384;&#31649;&#29702;&#38382;&#39064;&#12290;&#23454;&#35777;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#24211;&#23384;&#31649;&#29702;&#30340;&#36130;&#21153;&#32489;&#25928;&#21644;&#20248;&#21270;&#22823;&#25628;&#32034;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#25311;&#28151;&#21512;&#21644;&#33258;&#36866;&#24212;&#30340;&#38598;&#25104;&#24046;&#20998;&#36827;&#21270;&#31639;&#27861;&#65288;EDESH-SA&#65289;&#26469;&#35299;&#20915;&#19981;&#30830;&#23450;&#26465;&#20214;&#19979;&#30340;&#24211;&#23384;&#31649;&#29702;&#38382;&#39064;&#12290;&#35813;&#31639;&#27861;&#23558;&#24046;&#20998;&#36827;&#21270;&#31639;&#27861;&#19982;&#27169;&#25311;&#28151;&#21512;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#24182;&#36890;&#36807;&#33258;&#36866;&#24212;&#26426;&#21046;&#21160;&#24577;&#22320;&#25913;&#21464;&#21464;&#24322;&#29575;&#21644;&#20132;&#21449;&#29575;&#12290;&#30001;&#20110;&#20854;&#36866;&#24212;&#24615;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#22788;&#29702;&#24211;&#23384;&#31649;&#29702;&#20013;&#30340;&#22797;&#26434;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#12290;&#36890;&#36807;&#20351;&#29992;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#65288;MCS&#65289;&#65292;&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#36830;&#32493;&#23457;&#26597;&#65288;CR&#65289;&#24211;&#23384;&#31574;&#30053;&#65292;&#24182;&#32771;&#34385;&#20102;&#38543;&#26426;&#24615;&#21644;&#19981;&#21516;&#30340;&#38656;&#27714;&#24773;&#26223;&#12290;&#36825;&#31181;&#22522;&#20110;&#27169;&#25311;&#30340;&#26041;&#27861;&#21487;&#20197;&#30495;&#23454;&#22320;&#35780;&#20272;&#25152;&#25552;&#31639;&#27861;&#22312;&#23454;&#38469;&#29615;&#22659;&#20013;&#35299;&#20915;&#24211;&#23384;&#31649;&#29702;&#25361;&#25112;&#30340;&#36866;&#29992;&#24615;&#12290;&#23454;&#35777;&#30740;&#31350;&#30340;&#32467;&#26524;&#26174;&#31034;&#20102;&#25152;&#25552;&#26041;&#27861;&#22312;&#25552;&#39640;&#24211;&#23384;&#31649;&#29702;&#30340;&#36130;&#21153;&#32489;&#25928;&#21644;&#20248;&#21270;&#22823;&#25628;&#32034;&#31354;&#38388;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study proposes an Ensemble Differential Evolution with Simula-tion-Based Hybridization and Self-Adaptation (EDESH-SA) approach for inven-tory management (IM) under uncertainty. In this study, DE with multiple runs is combined with a simulation-based hybridization method that includes a self-adaptive mechanism that dynamically alters mutation and crossover rates based on the success or failure of each iteration. Due to its adaptability, the algorithm is able to handle the complexity and uncertainty present in IM. Utilizing Monte Carlo Simulation (MCS), the continuous review (CR) inventory strategy is ex-amined while accounting for stochasticity and various demand scenarios. This simulation-based approach enables a realistic assessment of the proposed algo-rithm's applicability in resolving the challenges faced by IM in practical settings. The empirical findings demonstrate the potential of the proposed method to im-prove the financial performance of IM and optimize large search spa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26412;&#22320;&#33258;&#36866;&#24212;&#21487;&#24494;&#22238;&#24402;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#23616;&#37096;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#21152;&#26435;&#24179;&#22343;&#65292;&#22312;&#19981;&#21516;&#26412;&#22320;&#21306;&#22495;&#22788;&#29702;&#25968;&#25454;&#26102;&#20855;&#26377;&#31454;&#20105;&#21147;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#23454;&#29616;&#26356;&#24555;&#30340;&#32479;&#35745;&#25910;&#25947;&#20197;&#21450;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#25913;&#21892;&#20102;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.07418</link><description>&lt;p&gt;
&#26412;&#22320;&#33258;&#36866;&#24212;&#21487;&#24494;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Locally Adaptive and Differentiable Regression. (arXiv:2308.07418v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07418
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26412;&#22320;&#33258;&#36866;&#24212;&#21487;&#24494;&#22238;&#24402;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#23616;&#37096;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#21152;&#26435;&#24179;&#22343;&#65292;&#22312;&#19981;&#21516;&#26412;&#22320;&#21306;&#22495;&#22788;&#29702;&#25968;&#25454;&#26102;&#20855;&#26377;&#31454;&#20105;&#21147;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#23454;&#29616;&#26356;&#24555;&#30340;&#32479;&#35745;&#25910;&#25947;&#20197;&#21450;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#25913;&#21892;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#24230;&#21442;&#25968;&#21270;&#27169;&#22411;&#65292;&#22914;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#38543;&#26426;&#26862;&#26519;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#21464;&#24471;&#38750;&#24120;&#21463;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#22312;&#29616;&#20195;&#36229;&#21442;&#25968;&#21270;&#30340;&#26412;&#22320;&#33258;&#36866;&#24212;&#27169;&#22411;&#20013;&#65292;&#24120;&#35265;&#30340;&#36830;&#32493;&#24615;&#21644;&#21487;&#24494;&#24615;&#30446;&#26631;&#24448;&#24448;&#34987;&#24573;&#35270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;&#23545;&#24212;&#30340;&#26412;&#22320;&#21306;&#22495;&#20013;&#23545;&#23616;&#37096;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#21152;&#26435;&#24179;&#22343;&#26469;&#26500;&#24314;&#20840;&#23616;&#36830;&#32493;&#21487;&#24494;&#27169;&#22411;&#12290;&#35813;&#27169;&#22411;&#22312;&#22788;&#29702;&#20855;&#26377;&#19981;&#21516;&#23494;&#24230;&#25110;&#19981;&#21516;&#26412;&#22320;&#21306;&#22495;&#20013;&#30340;&#20989;&#25968;&#20540;&#23610;&#24230;&#30340;&#25968;&#25454;&#26102;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#24403;&#25105;&#20204;&#22312;&#26412;&#22320;&#27169;&#22411;&#20013;&#28151;&#21512;&#20351;&#29992;&#26680;&#23725;&#21644;&#22810;&#39033;&#24335;&#22238;&#24402;&#39033;&#65292;&#24182;&#23545;&#23427;&#20204;&#36827;&#34892;&#36830;&#32493;&#25340;&#25509;&#26102;&#65292;&#22312;&#29702;&#35770;&#19978;&#23454;&#29616;&#26356;&#24555;&#30340;&#32479;&#35745;&#25910;&#25947;&#65292;&#24182;&#22312;&#21508;&#31181;&#23454;&#38469;&#29615;&#22659;&#20013;&#23454;&#29616;&#25913;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Over-parameterized models like deep nets and random forests have become very popular in machine learning. However, the natural goals of continuity and differentiability, common in regression models, are now often ignored in modern overparametrized, locally-adaptive models. We propose a general framework to construct a global continuous and differentiable model based on a weighted average of locally learned models in corresponding local regions. This model is competitive in dealing with data with different densities or scales of function values in different local regions. We demonstrate that when we mix kernel ridge and polynomial regression terms in the local models, and stitch them together continuously, we achieve faster statistical convergence in theory and improved performance in various practical settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;OpenDataVal&#30340;&#22522;&#20934;&#27979;&#35797;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#25972;&#21512;&#20102;&#22810;&#31181;&#25968;&#25454;&#38598;&#21644;&#20061;&#31181;&#26368;&#20808;&#36827;&#30340;&#25968;&#25454;&#20272;&#20540;&#31639;&#27861;&#23454;&#29616;&#65292;&#24182;&#25552;&#20379;&#20102;&#22235;&#20010;&#19979;&#28216;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#26469;&#35780;&#20272;&#25968;&#25454;&#20215;&#20540;&#30340;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2306.10577</link><description>&lt;p&gt;
OpenDataVal&#65306;&#19968;&#31181;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#30340;&#32479;&#19968;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
OpenDataVal: a Unified Benchmark for Data Valuation. (arXiv:2306.10577v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10577
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;OpenDataVal&#30340;&#22522;&#20934;&#27979;&#35797;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#25972;&#21512;&#20102;&#22810;&#31181;&#25968;&#25454;&#38598;&#21644;&#20061;&#31181;&#26368;&#20808;&#36827;&#30340;&#25968;&#25454;&#20272;&#20540;&#31639;&#27861;&#23454;&#29616;&#65292;&#24182;&#25552;&#20379;&#20102;&#22235;&#20010;&#19979;&#28216;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#26469;&#35780;&#20272;&#25968;&#25454;&#20215;&#20540;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#21333;&#20010;&#25968;&#25454;&#28857;&#30340;&#36136;&#37327;&#21644;&#24433;&#21709;&#23545;&#20110;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#21644;&#20943;&#36731;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#19981;&#33391;&#20559;&#24046;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#20960;&#20010;&#25968;&#25454;&#20272;&#20540;&#31639;&#27861;&#26469;&#37327;&#21270;&#25968;&#25454;&#36136;&#37327;&#65292;&#20294;&#36824;&#32570;&#20047;&#19968;&#20010;&#31995;&#32479;&#21270;&#21644;&#26631;&#20934;&#21270;&#30340;&#25968;&#25454;&#20272;&#20540;&#22522;&#20934;&#27979;&#35797;&#31995;&#32479;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;OpenDataVal&#65292;&#19968;&#31181;&#26131;&#20110;&#20351;&#29992;&#21644;&#32479;&#19968;&#30340;&#22522;&#20934;&#27979;&#35797;&#26694;&#26550;&#65292;&#20351;&#30740;&#31350;&#20154;&#21592;&#21644;&#20174;&#19994;&#32773;&#33021;&#22815;&#24212;&#29992;&#21644;&#27604;&#36739;&#21508;&#31181;&#25968;&#25454;&#20272;&#20540;&#31639;&#27861;&#12290;OpenDataVal&#25552;&#20379;&#20102;&#19968;&#20010;&#32508;&#21512;&#29615;&#22659;&#65292;&#21253;&#25324;&#65288;i&#65289;&#21508;&#31181;&#22270;&#20687;&#65292;&#33258;&#28982;&#35821;&#35328;&#21644;&#34920;&#26684;&#25968;&#25454;&#38598;&#65292;&#65288;ii&#65289;&#20061;&#31181;&#19981;&#21516;&#30340;&#26368;&#20808;&#36827;&#30340;&#25968;&#25454;&#20272;&#20540;&#31639;&#27861;&#30340;&#23454;&#29616;&#65292;&#20197;&#21450;&#65288;iii&#65289;&#21487;&#20197;&#23548;&#20837;&#20219;&#20309;scikit-learn&#27169;&#22411;&#30340;&#39044;&#27979;&#27169;&#22411;API&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22235;&#20010;&#19979;&#28216;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#29992;&#20110;&#35780;&#20272;&#25968;&#25454;&#20540;&#30340;&#36136;&#37327;&#12290;&#25105;&#20204;&#20351;&#29992;OpenDataVal&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#20998;&#26512;&#65292;&#37327;&#21270;&#24182;&#27604;&#36739;&#19981;&#21516;&#25968;&#25454;&#20272;&#20540;&#31639;&#27861;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Assessing the quality and impact of individual data points is critical for improving model performance and mitigating undesirable biases within the training dataset. Several data valuation algorithms have been proposed to quantify data quality, however, there lacks a systemic and standardized benchmarking system for data valuation. In this paper, we introduce OpenDataVal, an easy-to-use and unified benchmark framework that empowers researchers and practitioners to apply and compare various data valuation algorithms. OpenDataVal provides an integrated environment that includes (i) a diverse collection of image, natural language, and tabular datasets, (ii) implementations of nine different state-of-the-art data valuation algorithms, and (iii) a prediction model API that can import any models in scikit-learn. Furthermore, we propose four downstream machine learning tasks for evaluating the quality of data values. We perform benchmarking analysis using OpenDataVal, quantifying and comparin
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25581;&#31034;&#20102;&#28145;&#24230;&#23398;&#20064;&#31070;&#32463;&#32593;&#36335;&#23398;&#20064;&#36755;&#20837;&#20302;&#32500;&#24230;&#34920;&#31034;&#21644;&#26368;&#23567;&#21270;&#29305;&#24449;&#26144;&#23556;&#20013;&#30340;&#22797;&#26434;&#24615;/&#19981;&#35268;&#21017;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#25511;&#21046;&#20102;&#35268;&#24459;&#24615;&#65292;&#24182;&#21033;&#29992;&#29702;&#35770;&#24037;&#20855;&#35777;&#26126;&#20102;&#29942;&#39048;&#32467;&#26500;&#30340;&#23384;&#22312;&#12290;</title><link>http://arxiv.org/abs/2305.19008</link><description>&lt;p&gt;
&#23398;&#20064;&#29305;&#24449;&#20013;&#30340;&#29942;&#39048;&#32467;&#26500;&#65306;&#20302;&#32500;&#24230;&#19982;&#35268;&#24459;&#24615;&#30340;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
Bottleneck Structure in Learned Features: Low-Dimension vs Regularity Tradeoff. (arXiv:2305.19008v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19008
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25581;&#31034;&#20102;&#28145;&#24230;&#23398;&#20064;&#31070;&#32463;&#32593;&#36335;&#23398;&#20064;&#36755;&#20837;&#20302;&#32500;&#24230;&#34920;&#31034;&#21644;&#26368;&#23567;&#21270;&#29305;&#24449;&#26144;&#23556;&#20013;&#30340;&#22797;&#26434;&#24615;/&#19981;&#35268;&#21017;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#25511;&#21046;&#20102;&#35268;&#24459;&#24615;&#65292;&#24182;&#21033;&#29992;&#29702;&#35770;&#24037;&#20855;&#35777;&#26126;&#20102;&#29942;&#39048;&#32467;&#26500;&#30340;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#30740;&#31350;&#34920;&#26126;&#65292;&#20855;&#26377;&#22823;&#28145;&#24230;$L$&#21644;$L_{2}$&#27491;&#21017;&#21270;&#30340;DNN&#20559;&#21521;&#20110;&#23398;&#20064;&#36755;&#20837;&#30340;&#20302;&#32500;&#34920;&#31034;&#65292;&#21487;&#20197;&#35299;&#37322;&#20026;&#26368;&#23567;&#21270;&#23398;&#20064;&#20989;&#25968;$f$&#30340;&#31209;$R^{(0)}(f)$&#30340;&#27010;&#24565;&#65292;&#20854;&#34987;&#25512;&#27979;&#20026;&#29942;&#39048;&#31209;&#12290;&#25105;&#20204;&#35745;&#31639;&#20102;&#36825;&#20010;&#32467;&#26524;&#30340;&#26377;&#38480;&#28145;&#24230;&#20462;&#27491;&#65292;&#25581;&#31034;&#20102;&#19968;&#20010;&#24230;&#37327;$R^{(1)}$&#30340;&#35268;&#24459;&#24615;&#65292;&#23427;&#25511;&#21046;&#20102;&#38597;&#21487;&#27604;&#30697;&#38453;$\left|Jf(x)\right|_{+}$&#30340;&#20266;&#34892;&#21015;&#24335;&#24182;&#22312;&#32452;&#21512;&#21644;&#21152;&#27861;&#19979;&#26159;&#27425;&#21487;&#21152;&#30340;&#12290;&#36825;&#20351;&#24471;&#32593;&#32476;&#21487;&#20197;&#22312;&#23398;&#20064;&#20302;&#32500;&#34920;&#31034;&#21644;&#26368;&#23567;&#21270;&#29305;&#24449;&#26144;&#23556;&#20013;&#30340;&#22797;&#26434;&#24615;/&#19981;&#35268;&#21017;&#24615;&#20043;&#38388;&#20445;&#25345;&#24179;&#34913;&#65292;&#20174;&#32780;&#23398;&#20064;&#8220;&#27491;&#30830;&#8221;&#30340;&#20869;&#37096;&#23610;&#23544;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22823;&#23398;&#20064;&#36895;&#29575;&#22914;&#20309;&#25511;&#21046;&#23398;&#20064;&#20989;&#25968;&#30340;&#35268;&#24459;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#36825;&#20123;&#29702;&#35770;&#24037;&#20855;&#35777;&#26126;&#20102;&#29942;&#39048;&#32467;&#26500;&#22312;$L\to\infty$&#26102;&#22312;&#23398;&#20064;&#29305;&#24449;&#20013;&#30340;&#29468;&#24819;&#65306;&#23545;&#20110;&#22823;&#28145;&#24230;&#65292;&#20960;&#20046;&#25152;&#26377;&#30340;&#38544;&#34255;&#34920;&#31034;&#37117;&#38598;&#20013;&#22312;...
&lt;/p&gt;
&lt;p&gt;
Previous work has shown that DNNs with large depth $L$ and $L_{2}$-regularization are biased towards learning low-dimensional representations of the inputs, which can be interpreted as minimizing a notion of rank $R^{(0)}(f)$ of the learned function $f$, conjectured to be the Bottleneck rank. We compute finite depth corrections to this result, revealing a measure $R^{(1)}$ of regularity which bounds the pseudo-determinant of the Jacobian $\left|Jf(x)\right|_{+}$ and is subadditive under composition and addition. This formalizes a balance between learning low-dimensional representations and minimizing complexity/irregularity in the feature maps, allowing the network to learn the `right' inner dimension. We also show how large learning rates also control the regularity of the learned function. Finally, we use these theoretical tools to prove the conjectured bottleneck structure in the learned features as $L\to\infty$: for large depths, almost all hidden representations concentrates aroun
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26102;&#38388;&#21464;&#37327;&#22788;&#29702;&#24773;&#20917;&#19979;&#30340;&#21453;&#20107;&#23454;&#29983;&#25104;&#27169;&#22411;&#65292;&#33021;&#22815;&#25429;&#25417;&#25972;&#20010;&#21453;&#20107;&#23454;&#20998;&#24067;&#65292;&#24182;&#19988;&#33021;&#22815;&#26377;&#25928;&#25512;&#26029;&#21453;&#20107;&#23454;&#20998;&#24067;&#30340;&#26576;&#20123;&#32479;&#35745;&#37327;&#65292;&#36866;&#29992;&#20110;&#21307;&#30103;&#20445;&#20581;&#21644;&#20844;&#20849;&#25919;&#31574;&#21046;&#23450;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2305.15742</link><description>&lt;p&gt;
&#26102;&#38388;&#21464;&#21270;&#22788;&#29702;&#30340;&#21453;&#20107;&#23454;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Counterfactual Generative Models for Time-Varying Treatments. (arXiv:2305.15742v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15742
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26102;&#38388;&#21464;&#37327;&#22788;&#29702;&#24773;&#20917;&#19979;&#30340;&#21453;&#20107;&#23454;&#29983;&#25104;&#27169;&#22411;&#65292;&#33021;&#22815;&#25429;&#25417;&#25972;&#20010;&#21453;&#20107;&#23454;&#20998;&#24067;&#65292;&#24182;&#19988;&#33021;&#22815;&#26377;&#25928;&#25512;&#26029;&#21453;&#20107;&#23454;&#20998;&#24067;&#30340;&#26576;&#20123;&#32479;&#35745;&#37327;&#65292;&#36866;&#29992;&#20110;&#21307;&#30103;&#20445;&#20581;&#21644;&#20844;&#20849;&#25919;&#31574;&#21046;&#23450;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20272;&#35745;&#24179;&#22343;&#22240;&#26524;&#25928;&#24212;&#26159;&#27979;&#35797;&#26032;&#30103;&#27861;&#30340;&#24120;&#29992;&#20570;&#27861;&#12290;&#28982;&#32780;&#65292;&#24179;&#22343;&#25928;&#24212;&#20250;&#25513;&#30422;&#21453;&#20107;&#23454;&#20998;&#24067;&#20013;&#37325;&#35201;&#30340;&#20010;&#20307;&#29305;&#24449;&#65292;&#21487;&#33021;&#20250;&#24341;&#36215;&#23433;&#20840;&#12289;&#20844;&#24179;&#21644;&#36947;&#24503;&#26041;&#38754;&#30340;&#25285;&#24551;&#12290;&#36825;&#20010;&#38382;&#39064;&#22312;&#26102;&#38388;&#35774;&#32622;&#20013;&#26356;&#21152;&#20005;&#37325;&#65292;&#22240;&#20026;&#22788;&#29702;&#26159;&#26102;&#24207;&#30340;&#21644;&#26102;&#21464;&#30340;&#65292;&#23545;&#21453;&#20107;&#23454;&#20998;&#24067;&#20135;&#29983;&#20102;&#38169;&#32508;&#22797;&#26434;&#30340;&#24433;&#21709;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26465;&#20214;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#65292;&#20197;&#25429;&#33719;&#25972;&#20010;&#21453;&#20107;&#23454;&#20998;&#24067;&#65292;&#20801;&#35768;&#23545;&#21453;&#20107;&#23454;&#20998;&#24067;&#30340;&#26576;&#20123;&#32479;&#35745;&#37327;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#12290;&#36825;&#20351;&#24471;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#23588;&#20854;&#36866;&#29992;&#20110;&#21307;&#30103;&#20445;&#20581;&#21644;&#20844;&#20849;&#25919;&#31574;&#21046;&#23450;&#39046;&#22495;&#12290;&#25105;&#20204;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#36890;&#36807;&#36793;&#38469;&#32467;&#26500;&#27169;&#22411;&#35880;&#24910;&#22320;&#35299;&#20915;&#20102;&#35266;&#23519;&#25968;&#25454;&#21644;&#30446;&#26631;&#21453;&#20107;&#23454;&#20998;&#24067;&#20043;&#38388;&#30340;&#20998;&#24067;&#19981;&#21305;&#37197;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#32447;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating average causal effects is a common practice to test new treatments. However, the average effect ''masks'' important individual characteristics in the counterfactual distribution, which may lead to safety, fairness, and ethical concerns. This issue is exacerbated in the temporal setting, where the treatment is sequential and time-varying, leading to an intricate influence on the counterfactual distribution. In this paper, we propose a novel conditional generative modeling approach to capture the whole counterfactual distribution, allowing efficient inference on certain statistics of the counterfactual distribution. This makes the proposed approach particularly suitable for healthcare and public policy making. Our generative modeling approach carefully tackles the distribution mismatch in the observed data and the targeted counterfactual distribution via a marginal structural model. Our method outperforms state-of-the-art baselines on both synthetic and real data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32771;&#34385;&#20102;&#39640;&#24230;&#36807;&#21442;&#25968;&#21270;&#30340;&#22240;&#26524;&#25512;&#26029;&#27169;&#22411;&#65292;&#25506;&#35752;&#20102;&#22810;&#20010;&#25511;&#21046;&#21333;&#20803;&#30340;&#39640;&#32500;&#21512;&#25104;&#25511;&#21046;&#20272;&#35745;&#24615;&#33021;&#65292;&#21457;&#29616;&#22686;&#21152;&#25511;&#21046;&#21333;&#20803;&#21487;&#20197;&#24110;&#21161;&#25552;&#39640;&#22635;&#20805;&#24615;&#33021;&#65292;&#29978;&#33267;&#36229;&#36807;&#20102;&#39044;&#22788;&#29702;&#25311;&#21512;&#23436;&#32654;&#30340;&#28857;&#12290;</title><link>http://arxiv.org/abs/2305.00700</link><description>&lt;p&gt;
&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#21452;&#37325;&#21644;&#21333;&#19968;&#19979;&#38477;&#29616;&#35937;&#65292;&#21450;&#20854;&#22312;&#39640;&#32500;&#21512;&#25104;&#25511;&#21046;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Double and Single Descent in Causal Inference with an Application to High-Dimensional Synthetic Control. (arXiv:2305.00700v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00700
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#39640;&#24230;&#36807;&#21442;&#25968;&#21270;&#30340;&#22240;&#26524;&#25512;&#26029;&#27169;&#22411;&#65292;&#25506;&#35752;&#20102;&#22810;&#20010;&#25511;&#21046;&#21333;&#20803;&#30340;&#39640;&#32500;&#21512;&#25104;&#25511;&#21046;&#20272;&#35745;&#24615;&#33021;&#65292;&#21457;&#29616;&#22686;&#21152;&#25511;&#21046;&#21333;&#20803;&#21487;&#20197;&#24110;&#21161;&#25552;&#39640;&#22635;&#20805;&#24615;&#33021;&#65292;&#29978;&#33267;&#36229;&#36807;&#20102;&#39044;&#22788;&#29702;&#25311;&#21512;&#23436;&#32654;&#30340;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#21452;&#37325;&#19979;&#38477;&#29616;&#35937;&#65292;&#32771;&#34385;&#20102;&#39640;&#24230;&#36807;&#21442;&#25968;&#21270;&#30340;&#22240;&#26524;&#25512;&#26029;&#27169;&#22411;&#65292;&#21253;&#25324;&#22810;&#20010;&#25511;&#21046;&#21333;&#20803;&#30340;&#21512;&#25104;&#25511;&#21046;&#12290;&#22312;&#36825;&#31181;&#27169;&#22411;&#20013;&#65292;&#21487;&#33021;&#23384;&#22312;&#22826;&#22810;&#30340;&#33258;&#30001;&#21442;&#25968;&#65292;&#20197;&#33267;&#20110;&#27169;&#22411;&#21487;&#20197;&#23436;&#32654;&#22320;&#25311;&#21512;&#35757;&#32451;&#25968;&#25454;&#12290;&#26412;&#25991;&#39318;&#20808;&#20197;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20026;&#20363;&#65292;&#30740;&#31350;&#34218;&#36164;&#25968;&#25454;&#30340;&#22635;&#20805;&#65292;&#21457;&#29616;&#27604;&#31616;&#21333;&#27169;&#22411;&#26356;&#22810;&#30340;&#21327;&#21464;&#37327;&#23545;&#20110;&#27169;&#22411;&#24615;&#33021;&#30340;&#25552;&#21319;&#24456;&#26377;&#25928;&#12290;&#26412;&#25991;&#30340;&#20027;&#35201;&#36129;&#29486;&#22312;&#20110;&#25506;&#35752;&#20102;&#22810;&#20010;&#25511;&#21046;&#21333;&#20803;&#30340;&#39640;&#32500;&#21512;&#25104;&#25511;&#21046;&#20272;&#35745;&#24615;&#33021;&#65292;&#21457;&#29616;&#22686;&#21152;&#25511;&#21046;&#21333;&#20803;&#21487;&#20197;&#24110;&#21161;&#25552;&#39640;&#22635;&#20805;&#24615;&#33021;&#65292;&#29978;&#33267;&#36229;&#36807;&#20102;&#39044;&#22788;&#29702;&#25311;&#21512;&#23436;&#32654;&#30340;&#28857;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#32479;&#19968;&#30340;&#29702;&#35770;&#35270;&#35282;&#26469;&#35299;&#37322;&#36825;&#20123;&#39640;&#32500;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#21363;&#23558;&#26356;&#22797;&#26434;&#30340;&#27169;&#22411;&#35270;&#20026;&#23545;&#31616;&#21333;&#27169;&#22411;&#30340;&#27169;&#22411;&#24179;&#22343;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by a recent literature on the double-descent phenomenon in machine learning, we consider highly over-parametrized models in causal inference, including synthetic control with many control units. In such models, there may be so many free parameters that the model fits the training data perfectly. As a motivating example, we first investigate high-dimensional linear regression for imputing wage data, where we find that models with many more covariates than sample size can outperform simple ones. As our main contribution, we document the performance of high-dimensional synthetic control estimators with many control units. We find that adding control units can help improve imputation performance even beyond the point where the pre-treatment fit is perfect. We then provide a unified theoretical perspective on the performance of these high-dimensional models. Specifically, we show that more complex models can be interpreted as model-averaging estimators over simpler ones, which we 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;DP-Fast MH&#31639;&#27861;&#65292;&#29992;&#20110;&#22823;&#35268;&#27169;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#20855;&#26377;&#31934;&#30830;&#12289;&#24555;&#36895;&#21644;&#38544;&#31169;&#20445;&#25252;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2303.06171</link><description>&lt;p&gt;
DP-Fast MH: &#22823;&#35268;&#27169;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#31169;&#26377;&#12289;&#24555;&#36895;&#12289;&#20934;&#30830;&#30340;Metropolis-Hastings&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
DP-Fast MH: Private, Fast, and Accurate Metropolis-Hastings for Large-Scale Bayesian Inference. (arXiv:2303.06171v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06171
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;DP-Fast MH&#31639;&#27861;&#65292;&#29992;&#20110;&#22823;&#35268;&#27169;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#20855;&#26377;&#31934;&#30830;&#12289;&#24555;&#36895;&#21644;&#38544;&#31169;&#20445;&#25252;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a new DP-Fast MH algorithm for large-scale Bayesian inference, which is accurate, fast, and privacy-preserving.
&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#25512;&#26029;&#25552;&#20379;&#20102;&#19968;&#20010;&#20174;&#22797;&#26434;&#25968;&#25454;&#20013;&#23398;&#20064;&#21644;&#22312;&#19981;&#30830;&#23450;&#24615;&#19979;&#25512;&#29702;&#30340;&#21407;&#21017;&#24615;&#26694;&#26550;&#12290;&#23427;&#24050;&#32463;&#24191;&#27867;&#24212;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#22914;&#21307;&#23398;&#35786;&#26029;&#12289;&#33647;&#29289;&#35774;&#35745;&#21644;&#25919;&#31574;&#21046;&#23450;&#12290;&#22312;&#36825;&#20123;&#24120;&#35265;&#24212;&#29992;&#20013;&#65292;&#25968;&#25454;&#21487;&#33021;&#38750;&#24120;&#25935;&#24863;&#12290;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#25552;&#20379;&#20102;&#20855;&#26377;&#24378;&#22823;&#26368;&#22351;&#24773;&#20917;&#38544;&#31169;&#20445;&#35777;&#30340;&#25968;&#25454;&#20998;&#26512;&#24037;&#20855;&#65292;&#24182;&#24050;&#21457;&#23637;&#25104;&#20026;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#20998;&#26512;&#30340;&#20027;&#35201;&#26041;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Metropolis-Hastings&#65288;MH&#65289;&#31639;&#27861;&#65292;&#36825;&#26159;&#26368;&#22522;&#26412;&#30340;MCMC&#26041;&#27861;&#20043;&#19968;&#65292;&#29992;&#20110;&#24046;&#20998;&#38544;&#31169;&#19979;&#30340;&#22823;&#35268;&#27169;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#34429;&#28982;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#31169;&#26377;MCMC&#31639;&#27861;&#20026;&#20102;&#33719;&#24471;&#38544;&#31169;&#32780;&#29306;&#29298;&#20102;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#65292;&#20294;&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#31934;&#30830;&#19988;&#24555;&#36895;&#30340;DP MH&#31639;&#27861;&#65292;&#22823;&#22810;&#25968;&#36845;&#20195;&#20013;&#20165;&#20351;&#29992;&#19968;&#20010;&#23567;&#25209;&#37327;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25581;&#31034;&#20102;&#38544;&#31169;&#12289;&#21487;&#25193;&#23637;&#24615;&#65288;&#21363;&#25209;&#37327;&#22823;&#23567;&#65289;&#21644;&#25928;&#29575;&#65288;&#21363;&#25910;&#25947;&#36895;&#24230;&#65289;&#20043;&#38388;&#30340;&#19977;&#37325;&#26435;&#34913;&#65292;&#20174;&#29702;&#35770;&#19978;&#35828;&#26126;&#20102;&#36825;&#19968;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian inference provides a principled framework for learning from complex data and reasoning under uncertainty. It has been widely applied in machine learning tasks such as medical diagnosis, drug design, and policymaking. In these common applications, the data can be highly sensitive. Differential privacy (DP) offers data analysis tools with powerful worst-case privacy guarantees and has been developed as the leading approach in privacy-preserving data analysis. In this paper, we study Metropolis-Hastings (MH), one of the most fundamental MCMC methods, for large-scale Bayesian inference under differential privacy. While most existing private MCMC algorithms sacrifice accuracy and efficiency to obtain privacy, we provide the first exact and fast DP MH algorithm, using only a minibatch of data in most iterations. We further reveal, for the first time, a three-way trade-off among privacy, scalability (i.e. the batch size), and efficiency (i.e. the convergence rate), theoretically char
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24322;&#36136;&#20998;&#24067;&#20559;&#31227;&#19979;&#30340;&#32479;&#35745;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#30740;&#31350;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;(ERM)&#22312;&#19981;&#21516;&#31867;&#21035;&#30340;&#22797;&#26434;&#24615;&#19979;&#30340;&#34920;&#29616;&#65292;&#25105;&#20204;&#21457;&#29616;&#24403;&#31867;&#21035;$F$&#30456;&#27604;&#31867;&#21035;$G$&#26356;&#8220;&#31616;&#21333;&#8221;&#26102;&#65292;&#25105;&#20204;&#30340;&#39044;&#27979;&#22120;&#23545;&#20110;&#21327;&#21464;&#37327;&#20559;&#31227;&#20855;&#26377;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#65292;&#23588;&#20854;&#22312;$\textbf{y}$&#30340;&#20559;&#31227;&#36828;&#23567;&#20110;$\textbf{x}$&#30340;&#24773;&#20917;&#19979;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#21457;&#29616;ERM&#30340;&#34892;&#20026;&#19982;&#27491;&#20132;&#26426;&#22120;&#23398;&#20064;&#20855;&#26377;&#31867;&#20284;&#30340;&#29305;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.13934</link><description>&lt;p&gt;
&#24322;&#36136;&#20998;&#24067;&#20559;&#31227;&#19979;&#30340;&#32479;&#35745;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Statistical Learning under Heterogenous Distribution Shift. (arXiv:2302.13934v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.13934
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24322;&#36136;&#20998;&#24067;&#20559;&#31227;&#19979;&#30340;&#32479;&#35745;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#30740;&#31350;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;(ERM)&#22312;&#19981;&#21516;&#31867;&#21035;&#30340;&#22797;&#26434;&#24615;&#19979;&#30340;&#34920;&#29616;&#65292;&#25105;&#20204;&#21457;&#29616;&#24403;&#31867;&#21035;$F$&#30456;&#27604;&#31867;&#21035;$G$&#26356;&#8220;&#31616;&#21333;&#8221;&#26102;&#65292;&#25105;&#20204;&#30340;&#39044;&#27979;&#22120;&#23545;&#20110;&#21327;&#21464;&#37327;&#20559;&#31227;&#20855;&#26377;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#65292;&#23588;&#20854;&#22312;$\textbf{y}$&#30340;&#20559;&#31227;&#36828;&#23567;&#20110;$\textbf{x}$&#30340;&#24773;&#20917;&#19979;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#21457;&#29616;ERM&#30340;&#34892;&#20026;&#19982;&#27491;&#20132;&#26426;&#22120;&#23398;&#20064;&#20855;&#26377;&#31867;&#20284;&#30340;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#38543;&#26426;&#21464;&#37327;&#23545;$(\mathbf{x},\mathbf{y})$&#20013;&#39044;&#27979;&#30446;&#26631;$\mathbf{z}$, &#20854;&#20013;&#30495;&#23454;&#30340;&#39044;&#27979;&#22120;&#26159;&#21152;&#27861;&#30340;$\mathbb{E}[\mathbf{z} \mid \mathbf{x},\mathbf{y}] = f_\star(\mathbf{x}) +g_{\star}(\mathbf{y})$&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32473;&#23450;&#35757;&#32451;&#20998;&#24067;&#19978;&#25311;&#21512;&#30340;&#20989;&#25968;$f+g$, $f \in F$&#21644;$g \in G$&#19978;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;(ERM)&#22312;&#34920;&#29616;&#19978;&#30340;&#24046;&#24322;&#65292;&#20294;&#22312;&#27979;&#35797;&#20998;&#24067;&#19978;&#24471;&#21040;&#35780;&#20272;&#26102;&#20250;&#26174;&#31034;&#20986;&#21327;&#21464;&#37327;&#20559;&#31227;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#24403;&#31867;&#21035;$F$&#27604;$G$&#26356;&#8220;&#31616;&#21333;&#8221;&#65288;&#20363;&#22914;&#65292;&#20197;&#24230;&#37327;&#29109;&#20026;&#34913;&#37327;&#26631;&#20934;&#65289;&#26102;&#65292;&#25105;&#20204;&#30340;&#39044;&#27979;&#22120;&#23545;&#20110;&#21327;&#21464;&#37327;&#20559;&#31227;&#30340;&#25239;&#24178;&#25200;&#33021;&#21147;&#26356;&#24378;&#65292;&#20854;&#20013;$\textbf{y}$&#30340;&#20559;&#31227;&#35201;&#36828;&#23567;&#20110;$\textbf{x}$&#30340;&#20559;&#31227;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;ERM&#30340;&#34892;&#20026;&#19982;&#27491;&#20132;&#26426;&#22120;&#23398;&#20064;$\textbf{ qualitatively similarly}$&#65306;ERM&#24674;&#22797;&#39044;&#27979;&#22120;&#20013;&#30340;$f$&#25104;&#20998;&#30340;&#36895;&#29575;&#20165;&#23545;&#20110;&#31867;&#21035;$G$&#30340;&#22797;&#26434;&#24615;&#20855;&#26377;&#36739;&#20302;&#38454;&#30340;&#20381;&#36182;&#24615;&#65292;&#35843;&#25972;&#21518;...
&lt;/p&gt;
&lt;p&gt;
This paper studies the prediction of a target $\mathbf{z}$ from a pair of random variables $(\mathbf{x},\mathbf{y})$, where the ground-truth predictor is additive $\mathbb{E}[\mathbf{z} \mid \mathbf{x},\mathbf{y}] = f_\star(\mathbf{x}) +g_{\star}(\mathbf{y})$. We study the performance of empirical risk minimization (ERM) over functions $f+g$, $f \in F$ and $g \in G$, fit on a given training distribution, but evaluated on a test distribution which exhibits covariate shift. We show that, when the class $F$ is "simpler" than $G$ (measured, e.g., in terms of its metric entropy), our predictor is more resilient to $\textbf{heterogenous covariate shifts}$ in which the shift in $\mathbf{x}$ is much greater than that in $\mathbf{y}$. Our analysis proceeds by demonstrating that ERM behaves $\textbf{qualitatively similarly to orthogonal machine learning}$: the rate at which ERM recovers the $f$-component of the predictor has only a lower-order dependence on the complexity of the class $G$, adjus
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#36807;&#31243;&#35889;&#23494;&#24230;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#25512;&#26029;&#32570;&#22833;&#30340;&#20449;&#21495;&#20540;&#21644;&#36827;&#34892;&#20449;&#21495;&#25554;&#20540;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#20854;&#22312;&#26102;&#38388;-&#39030;&#28857;&#20449;&#21495;&#20272;&#35745;&#38382;&#39064;&#20013;&#20855;&#26377;&#39640;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.06887</link><description>&lt;p&gt;
&#20174;&#26102;&#38388;-&#39030;&#28857;&#35889;&#23398;&#20064;&#22270;ARMA&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Learning Graph ARMA Processes from Time-Vertex Spectra. (arXiv:2302.06887v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06887
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#36807;&#31243;&#35889;&#23494;&#24230;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#25512;&#26029;&#32570;&#22833;&#30340;&#20449;&#21495;&#20540;&#21644;&#36827;&#34892;&#20449;&#21495;&#25554;&#20540;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#20854;&#22312;&#26102;&#38388;-&#39030;&#28857;&#20449;&#21495;&#20272;&#35745;&#38382;&#39064;&#20013;&#20855;&#26377;&#39640;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#26102;&#38388;&#21464;&#21270;&#30340;&#22270;&#20449;&#21495;&#24314;&#27169;&#20026;&#31283;&#24577;&#26102;&#38388;-&#39030;&#28857;&#38543;&#26426;&#36807;&#31243;&#65292;&#21487;&#20197;&#36890;&#36807;&#26377;&#25928;&#22320;&#21033;&#29992;&#36807;&#31243;&#22312;&#19981;&#21516;&#22270;&#33410;&#28857;&#21644;&#26102;&#38388;&#30636;&#38388;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#27169;&#24335;&#26469;&#25512;&#26029;&#32570;&#22833;&#30340;&#20449;&#21495;&#20540;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#29992;&#20110;&#22522;&#20110;&#23398;&#20064;&#36807;&#31243;&#30340;&#19981;&#23436;&#25972;&#23454;&#29616;&#30340;&#32852;&#21512;&#26102;&#38388;-&#39030;&#28857;&#21151;&#29575;&#35889;&#23494;&#24230;&#26469;&#35745;&#31639;&#22270;&#33258;&#22238;&#24402;&#31227;&#21160;&#24179;&#22343;&#65288;&#22270;ARMA&#65289;&#36807;&#31243;&#65292;&#20197;&#29992;&#20110;&#20449;&#21495;&#25554;&#20540;&#20219;&#21153;&#12290;&#25105;&#20204;&#30340;&#35299;&#20915;&#26041;&#26696;&#39318;&#20808;&#36890;&#36807;&#37096;&#20998;&#35266;&#23519;&#21040;&#30340;&#23454;&#29616;&#31895;&#30053;&#20272;&#35745;&#36807;&#31243;&#30340;&#32852;&#21512;&#35889;&#65292;&#28982;&#21518;&#36890;&#36807;&#20984;&#26494;&#24347;&#23558;&#20854;&#25237;&#24433;&#21040;&#22270;ARMA&#36807;&#31243;&#30340;&#35889;&#27969;&#24418;&#19978;&#26469;&#25913;&#36827;&#36825;&#20010;&#20272;&#35745;&#12290;&#28982;&#21518;&#65292;&#22522;&#20110;&#23398;&#20064;&#30340;&#27169;&#22411;&#20272;&#35745;&#26368;&#21021;&#32570;&#22833;&#30340;&#20449;&#21495;&#20540;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#26102;&#38388;-&#39030;&#28857;&#20449;&#21495;&#20272;&#35745;&#38382;&#39064;&#20013;&#36798;&#21040;&#20102;&#24456;&#39640;&#30340;&#20934;&#30830;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
The modeling of time-varying graph signals as stationary time-vertex stochastic processes permits the inference of missing signal values by efficiently employing the correlation patterns of the process across different graph nodes and time instants. In this study, we propose an algorithm for computing graph autoregressive moving average (graph ARMA) processes based on learning the joint time-vertex power spectral density of the process from its incomplete realizations for the task of signal interpolation. Our solution relies on first roughly estimating the joint spectrum of the process from partially observed realizations and then refining this estimate by projecting it onto the spectrum manifold of the graph ARMA process through convex relaxations. The initially missing signal values are then estimated based on the learnt model. Experimental results show that the proposed approach achieves high accuracy in time-vertex signal estimation problems.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25552;&#20986;&#22270;&#24418;&#26631;&#20934;&#21644;&#27169;&#22411;&#26080;&#20851;&#26694;&#26550;CIP&#65292;&#25105;&#20204;&#33021;&#22815;&#23398;&#20064;&#21453;&#20107;&#23454;&#19981;&#21464;&#30340;&#39044;&#27979;&#22120;&#65292;&#20197;&#23454;&#29616;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#20844;&#24179;&#24615;&#12289;&#24378;&#20581;&#24615;&#21644;&#26222;&#36866;&#24615;&#12290;</title><link>http://arxiv.org/abs/2207.09768</link><description>&lt;p&gt;
&#23398;&#20064;&#21453;&#20107;&#23454;&#19981;&#21464;&#30340;&#39044;&#27979;&#22120;
&lt;/p&gt;
&lt;p&gt;
Learning Counterfactually Invariant Predictors. (arXiv:2207.09768v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.09768
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20986;&#22270;&#24418;&#26631;&#20934;&#21644;&#27169;&#22411;&#26080;&#20851;&#26694;&#26550;CIP&#65292;&#25105;&#20204;&#33021;&#22815;&#23398;&#20064;&#21453;&#20107;&#23454;&#19981;&#21464;&#30340;&#39044;&#27979;&#22120;&#65292;&#20197;&#23454;&#29616;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#20844;&#24179;&#24615;&#12289;&#24378;&#20581;&#24615;&#21644;&#26222;&#36866;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#19981;&#21464;&#24615;&#65288;CI&#65289;&#30340;&#27010;&#24565;&#23545;&#20110;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#20844;&#24179;&#12289;&#24378;&#20581;&#21644;&#20855;&#26377;&#26222;&#36866;&#24615;&#30340;&#39044;&#27979;&#22120;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22270;&#24418;&#26631;&#20934;&#65292;&#23427;&#20197;&#35266;&#27979;&#20998;&#24067;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#20316;&#20026;&#39044;&#27979;&#22120;&#21453;&#20107;&#23454;&#19981;&#21464;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#20026;&#20102;&#23398;&#20064;&#36825;&#26679;&#30340;&#39044;&#27979;&#22120;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026;Counterfactually Invariant Prediction&#65288;CIP&#65289;&#30340;&#27169;&#22411;&#26080;&#20851;&#26694;&#26550;&#65292;&#22522;&#20110;Hilbert-Schmidt&#26465;&#20214;&#29420;&#31435;&#20934;&#21017;&#65288;HSCIC&#65289;&#65292;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#26465;&#20214;&#20381;&#36182;&#24230;&#37327;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#22312;&#21253;&#25324;&#26631;&#37327;&#21644;&#22810;&#21464;&#37327;&#35774;&#32622;&#22312;&#20869;&#30340;&#21508;&#31181;&#27169;&#25311;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#35777;&#26126;&#20102;CIP&#22312;&#24378;&#21046;&#21453;&#20107;&#23454;&#19981;&#21464;&#24615;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Notions of counterfactual invariance (CI) have proven essential for predictors that are fair, robust, and generalizable in the real world. We propose graphical criteria that yield a sufficient condition for a predictor to be counterfactually invariant in terms of a conditional independence in the observational distribution. In order to learn such predictors, we propose a model-agnostic framework, called Counterfactually Invariant Prediction (CIP), building on the Hilbert-Schmidt Conditional Independence Criterion (HSCIC), a kernel-based conditional dependence measure. Our experimental results demonstrate the effectiveness of CIP in enforcing counterfactual invariance across various simulated and real-world datasets including scalar and multi-variate settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37325;&#23457;&#20102;&#36229;&#21442;&#25968;&#27169;&#22411;&#20013;&#30340;&#26368;&#23567;&#25551;&#36848;&#38271;&#24230;&#22797;&#26434;&#24230;&#12290;&#36890;&#36807;&#23450;&#20041;&#19968;&#20010;&#26032;&#30340;&#22522;&#20110;MDL&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#25105;&#20204;&#21457;&#29616;&#22797;&#26434;&#24230;&#19981;&#20165;&#21462;&#20915;&#20110;&#21442;&#25968;&#25968;&#37327;&#65292;&#36824;&#19982;&#35774;&#35745;&#30697;&#38453;&#25110;&#26680;&#30697;&#38453;&#30340;&#22855;&#24322;&#20540;&#21644;&#20449;&#22122;&#27604;&#26377;&#20851;&#12290;</title><link>http://arxiv.org/abs/2006.10189</link><description>&lt;p&gt;
&#37325;&#23457;&#36229;&#21442;&#25968;&#27169;&#22411;&#20013;&#30340;&#26368;&#23567;&#25551;&#36848;&#38271;&#24230;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
Revisiting minimum description length complexity in overparameterized models. (arXiv:2006.10189v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.10189
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#23457;&#20102;&#36229;&#21442;&#25968;&#27169;&#22411;&#20013;&#30340;&#26368;&#23567;&#25551;&#36848;&#38271;&#24230;&#22797;&#26434;&#24230;&#12290;&#36890;&#36807;&#23450;&#20041;&#19968;&#20010;&#26032;&#30340;&#22522;&#20110;MDL&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#25105;&#20204;&#21457;&#29616;&#22797;&#26434;&#24230;&#19981;&#20165;&#21462;&#20915;&#20110;&#21442;&#25968;&#25968;&#37327;&#65292;&#36824;&#19982;&#35774;&#35745;&#30697;&#38453;&#25110;&#26680;&#30697;&#38453;&#30340;&#22855;&#24322;&#20540;&#21644;&#20449;&#22122;&#27604;&#26377;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22797;&#26434;&#24230;&#26159;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#27010;&#24565;&#65292;&#26088;&#22312;&#25552;&#20379;&#26377;&#20851;&#27867;&#21270;&#24615;&#33021;&#30340;&#20449;&#24687;&#12290;&#22312;&#20302;&#32500;&#24230;&#24773;&#20917;&#19979;&#65292;&#21442;&#25968;&#25968;&#37327;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#26159;&#25104;&#21151;&#30340;&#65292;&#20294;&#22312;&#36229;&#21442;&#25968;&#27169;&#22411;&#20013;&#65292;&#24403;&#21442;&#25968;&#25968;&#37327;&#36229;&#36807;&#35757;&#32451;&#26679;&#26412;&#25968;&#37327;&#26102;&#65292;&#20854;&#21512;&#29702;&#24615;&#19981;&#36275;&#12290;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#22522;&#20110;Rissanen&#26368;&#23567;&#25551;&#36848;&#38271;&#24230;&#65288;MDL&#65289;&#21407;&#29702;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#24182;&#23450;&#20041;&#20102;&#19968;&#31181;&#26032;&#30340;&#36866;&#29992;&#20110;&#36229;&#21442;&#25968;&#27169;&#22411;&#30340;&#22522;&#20110;MDL&#30340;&#22797;&#26434;&#24230;&#65288;MDL-COMP&#65289;&#12290;MDL-COMP&#36890;&#36807;&#23545;&#19968;&#20010;&#33391;&#22909;&#30340;Ridge&#20272;&#35745;&#31867;&#25152;&#24341;&#36215;&#30340;&#32534;&#30721;&#32780;&#23450;&#20041;&#20986;&#26469;&#30340;&#26368;&#20248;&#24615;&#20934;&#21017;&#12290;&#25105;&#20204;&#23545;&#32447;&#24615;&#27169;&#22411;&#21644;&#26680;&#26041;&#27861;&#30340;MDL-COMP&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#29702;&#35770;&#21051;&#30011;&#65292;&#24182;&#34920;&#26126;&#23427;&#19981;&#20165;&#26159;&#21442;&#25968;&#25968;&#37327;&#30340;&#20989;&#25968;&#65292;&#32780;&#26159;&#35774;&#35745;&#25110;&#26680;&#30697;&#38453;&#30340;&#22855;&#24322;&#20540;&#21644;&#20449;&#22122;&#27604;&#30340;&#20989;&#25968;&#12290;&#23545;&#20110;&#20855;&#26377;n&#20010;&#35266;&#27979;&#20540;&#65292;d&#20010;&#21442;&#25968;&#21644;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#39640;&#26031;&#39044;&#27979;&#22240;&#23376;&#30340;&#32447;&#24615;&#27169;&#22411;&#65292;MDL-COMP&#30340;&#23610;&#24230;&#26159;&#32447;&#24615;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Complexity is a fundamental concept underlying statistical learning theory that aims to inform generalization performance. Parameter count, while successful in low-dimensional settings, is not well-justified for overparameterized settings when the number of parameters is more than the number of training samples. We revisit complexity measures based on Rissanen's principle of minimum description length (MDL) and define a novel MDL-based complexity (MDL-COMP) that remains valid for overparameterized models. MDL-COMP is defined via an optimality criterion over the encodings induced by a good Ridge estimator class. We provide an extensive theoretical characterization of MDL-COMP for linear models and kernel methods and show that it is not just a function of parameter count, but rather a function of the singular values of the design or the kernel matrix and the signal-to-noise ratio. For a linear model with $n$ observations, $d$ parameters, and i.i.d. Gaussian predictors, MDL-COMP scales li
&lt;/p&gt;</description></item></channel></rss>