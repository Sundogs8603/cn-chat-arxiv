<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#38024;&#23545;&#24037;&#31243;&#35774;&#35745;&#20013;&#23384;&#22312;&#30340;&#28151;&#21512;&#21464;&#37327;&#38382;&#39064;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#20803;&#27169;&#22411;&#30340;&#28151;&#21512;&#21464;&#37327;&#20840;&#23616;&#25935;&#24863;&#24615;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#25968;&#20540;&#26696;&#20363;&#30740;&#31350;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.15124</link><description>&lt;p&gt;
&#28151;&#21512;&#21464;&#37327;&#20840;&#23616;&#25935;&#24863;&#24615;&#20998;&#26512;&#29992;&#20110;&#30693;&#35782;&#21457;&#29616;&#21644;&#39640;&#25928;&#30340;&#32452;&#21512;&#26448;&#26009;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Mixed-Variable Global Sensitivity Analysis For Knowledge Discovery And Efficient Combinatorial Materials Design. (arXiv:2310.15124v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15124
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#38024;&#23545;&#24037;&#31243;&#35774;&#35745;&#20013;&#23384;&#22312;&#30340;&#28151;&#21512;&#21464;&#37327;&#38382;&#39064;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#20803;&#27169;&#22411;&#30340;&#28151;&#21512;&#21464;&#37327;&#20840;&#23616;&#25935;&#24863;&#24615;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#25968;&#20540;&#26696;&#20363;&#30740;&#31350;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20840;&#23616;&#25935;&#24863;&#24615;&#20998;&#26512;&#65288;GSA&#65289;&#26159;&#30740;&#31350;&#20219;&#20309;&#32473;&#23450;&#36755;&#20837;&#23545;&#27169;&#22411;&#36755;&#20986;&#30340;&#24433;&#21709;&#30340;&#30740;&#31350;&#12290;&#22312;&#24037;&#31243;&#35774;&#35745;&#30340;&#32972;&#26223;&#19979;&#65292;GSA&#24050;&#34987;&#24191;&#27867;&#29992;&#20110;&#29702;&#35299;&#35774;&#35745;&#21464;&#37327;&#23545;&#35774;&#35745;&#30446;&#26631;&#30340;&#21333;&#20010;&#21644;&#38598;&#20307;&#36129;&#29486;&#12290;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#20840;&#23616;&#25935;&#24863;&#24615;&#30740;&#31350;&#36890;&#24120;&#23616;&#38480;&#20110;&#21482;&#26377;&#23450;&#37327;&#65288;&#25968;&#23383;&#65289;&#35774;&#35745;&#21464;&#37327;&#30340;&#35774;&#35745;&#31354;&#38388;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#24037;&#31243;&#31995;&#32479;&#38500;&#20102;&#23450;&#37327;&#35774;&#35745;&#21464;&#37327;&#22806;&#65292;&#36824;&#21253;&#21547;&#26377;&#36136;&#37327;&#65288;&#20998;&#31867;&#65289;&#35774;&#35745;&#21464;&#37327;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#28508;&#21464;&#37327;&#39640;&#26031;&#36807;&#31243;&#65288;LVGP&#65289;&#19982;Sobol&#20998;&#26512;&#30456;&#32467;&#21512;&#65292;&#24320;&#21457;&#20102;&#31532;&#19968;&#20010;&#22522;&#20110;&#20803;&#27169;&#22411;&#30340;&#28151;&#21512;&#21464;&#37327;GSA&#26041;&#27861;&#12290;&#36890;&#36807;&#25968;&#20540;&#26696;&#20363;&#30740;&#31350;&#65292;&#25105;&#20204;&#39564;&#35777;&#21644;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#28151;&#21512;&#21464;&#37327;&#38382;&#39064;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#34429;&#28982;&#25152;&#25552;&#20986;&#30340;GSA&#26041;&#27861;&#36275;&#22815;&#36890;&#29992;&#65292;&#21487;&#20197;&#29992;&#20110;&#21508;&#31181;&#24037;&#31243;&#35774;&#35745;&#24212;&#29992;&#65292;&#20294;&#25105;&#20204;&#23558;&#20854;&#19982;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#26041;&#27861;&#30456;&#32467;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Global Sensitivity Analysis (GSA) is the study of the influence of any given inputs on the outputs of a model. In the context of engineering design, GSA has been widely used to understand both individual and collective contributions of design variables on the design objectives. So far, global sensitivity studies have often been limited to design spaces with only quantitative (numerical) design variables. However, many engineering systems also contain, if not only, qualitative (categorical) design variables in addition to quantitative design variables. In this paper, we integrate Latent Variable Gaussian Process (LVGP) with Sobol' analysis to develop the first metamodel-based mixed-variable GSA method. Through numerical case studies, we validate and demonstrate the effectiveness of our proposed method for mixed-variable problems. Furthermore, while the proposed GSA method is general enough to benefit various engineering design applications, we integrate it with multi-objective Bayesian 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#22312;&#38750;&#26631;&#20934;&#29615;&#22659;&#20013;&#35780;&#20272;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20934;&#21017;&#21644;&#26041;&#27861;&#65292;&#21253;&#25324;&#32858;&#31867;&#25968;&#25454;&#12289;&#31354;&#38388;&#25968;&#25454;&#12289;&#19981;&#22343;&#21248;&#37319;&#26679;&#27010;&#29575;&#12289;&#27010;&#24565;&#28418;&#31227;&#21644;&#23618;&#27425;&#32467;&#26500;&#21270;&#32467;&#26524;&#12290;&#20854;&#20013;&#30340;&#32479;&#19968;&#21407;&#21017;&#26159;&#22312;&#37325;&#37319;&#26679;&#36807;&#31243;&#20013;&#20351;&#29992;&#30340;&#27979;&#35797;&#25968;&#25454;&#24212;&#21453;&#26144;&#20986;&#27169;&#22411;&#23558;&#35201;&#24212;&#29992;&#30340;&#26032;&#35266;&#27979;&#25968;&#25454;&#65292;&#32780;&#35757;&#32451;&#25968;&#25454;&#24212;&#20195;&#34920;&#25972;&#20010;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2310.15108</link><description>&lt;p&gt;
&#22312;&#38750;&#26631;&#20934;&#29615;&#22659;&#20013;&#35780;&#20272;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65306;&#32508;&#36848;&#19982;&#26032;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Evaluating machine learning models in non-standard settings: An overview and new findings. (arXiv:2310.15108v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15108
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#22312;&#38750;&#26631;&#20934;&#29615;&#22659;&#20013;&#35780;&#20272;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20934;&#21017;&#21644;&#26041;&#27861;&#65292;&#21253;&#25324;&#32858;&#31867;&#25968;&#25454;&#12289;&#31354;&#38388;&#25968;&#25454;&#12289;&#19981;&#22343;&#21248;&#37319;&#26679;&#27010;&#29575;&#12289;&#27010;&#24565;&#28418;&#31227;&#21644;&#23618;&#27425;&#32467;&#26500;&#21270;&#32467;&#26524;&#12290;&#20854;&#20013;&#30340;&#32479;&#19968;&#21407;&#21017;&#26159;&#22312;&#37325;&#37319;&#26679;&#36807;&#31243;&#20013;&#20351;&#29992;&#30340;&#27979;&#35797;&#25968;&#25454;&#24212;&#21453;&#26144;&#20986;&#27169;&#22411;&#23558;&#35201;&#24212;&#29992;&#30340;&#26032;&#35266;&#27979;&#25968;&#25454;&#65292;&#32780;&#35757;&#32451;&#25968;&#25454;&#24212;&#20195;&#34920;&#25972;&#20010;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20272;&#35745;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#27867;&#21270;&#35823;&#24046;&#26159;&#22522;&#26412;&#30340;&#65292;&#37319;&#29992;&#37325;&#37319;&#26679;&#26041;&#27861;&#26159;&#26368;&#24120;&#35265;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#22312;&#38750;&#26631;&#20934;&#29615;&#22659;&#20013;&#65292;&#29305;&#21035;&#26159;&#35266;&#27979;&#20540;&#19981;&#26159;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#31616;&#21333;&#30340;&#38543;&#26426;&#25968;&#25454;&#21010;&#20998;&#36827;&#34892;&#37325;&#37319;&#26679;&#21487;&#33021;&#23548;&#33268;&#20559;&#20506;&#30340;&#27867;&#21270;&#35823;&#24046;&#20272;&#35745;&#12290;&#26412;&#25991;&#26088;&#22312;&#25552;&#20379;&#22312;&#21508;&#31181;&#38750;&#26631;&#20934;&#29615;&#22659;&#20013;&#36827;&#34892;&#27867;&#21270;&#35823;&#24046;&#20272;&#35745;&#30340;&#21487;&#38752;&#20934;&#21017;&#65306;&#32858;&#31867;&#25968;&#25454;&#12289;&#31354;&#38388;&#25968;&#25454;&#12289;&#19981;&#22343;&#21248;&#37319;&#26679;&#27010;&#29575;&#12289;&#27010;&#24565;&#28418;&#31227;&#21644;&#23618;&#27425;&#32467;&#26500;&#21270;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#32508;&#36848;&#23558;&#24050;&#24314;&#31435;&#30340;&#26041;&#27861;&#19982;&#25105;&#20204;&#25152;&#30693;&#30340;&#20854;&#20182;&#22312;&#36825;&#20123;&#29305;&#23450;&#24773;&#26223;&#20013;&#36739;&#23569;&#34987;&#32771;&#34385;&#30340;&#26041;&#27861;&#30456;&#32467;&#21512;&#12290;&#36825;&#20123;&#25216;&#26415;&#20043;&#38388;&#30340;&#19968;&#20010;&#32479;&#19968;&#21407;&#21017;&#26159;&#65292;&#22312;&#37325;&#37319;&#26679;&#36807;&#31243;&#30340;&#27599;&#27425;&#36845;&#20195;&#20013;&#20351;&#29992;&#30340;&#27979;&#35797;&#25968;&#25454;&#24212;&#21453;&#26144;&#20986;&#27169;&#22411;&#23558;&#35201;&#24212;&#29992;&#30340;&#26032;&#35266;&#27979;&#25968;&#25454;&#65292;&#32780;&#35757;&#32451;&#25968;&#25454;&#24212;&#20195;&#34920;&#25972;&#20010;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating the generalization error (GE) of machine learning models is fundamental, with resampling methods being the most common approach. However, in non-standard settings, particularly those where observations are not independently and identically distributed, resampling using simple random data divisions may lead to biased GE estimates. This paper strives to present well-grounded guidelines for GE estimation in various such non-standard settings: clustered data, spatial data, unequal sampling probabilities, concept drift, and hierarchically structured outcomes. Our overview combines well-established methodologies with other existing methods that, to our knowledge, have not been frequently considered in these particular settings. A unifying principle among these techniques is that the test data used in each iteration of the resampling procedure should reflect the new observations to which the model will be applied, while the training data should be representative of the entire data 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#30340;&#20108;&#22836;&#21367;&#31215;&#33258;&#32534;&#30721;&#22120;&#29992;&#20110;&#21387;&#32553;&#19977;&#32500;&#26102;&#38388;&#25237;&#24433;&#23460;&#25968;&#25454;&#65292;&#22312;&#21387;&#32553;&#29575;&#21644;&#37325;&#24314;&#31934;&#24230;&#26041;&#38754;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.15026</link><description>&lt;p&gt;
&#24555;&#36895;&#20108;&#22836;&#21367;&#31215;&#33258;&#32534;&#30721;&#22120;&#29992;&#20110;&#21387;&#32553;3D&#26102;&#38388;&#25237;&#24433;&#23460;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Fast 2D Bicephalous Convolutional Autoencoder for Compressing 3D Time Projection Chamber Data. (arXiv:2310.15026v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15026
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#30340;&#20108;&#22836;&#21367;&#31215;&#33258;&#32534;&#30721;&#22120;&#29992;&#20110;&#21387;&#32553;&#19977;&#32500;&#26102;&#38388;&#25237;&#24433;&#23460;&#25968;&#25454;&#65292;&#22312;&#21387;&#32553;&#29575;&#21644;&#37325;&#24314;&#31934;&#24230;&#26041;&#38754;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#33021;&#22823;&#22411;&#31890;&#23376;&#23545;&#25758;&#26426;&#22312;&#26680;&#29289;&#29702;&#39046;&#22495;&#20197;&#27599;&#31186;1TB&#30340;&#36895;&#24230;&#20135;&#29983;&#25968;&#25454;&#65292;&#22312;&#39640;&#33021;&#29289;&#29702;&#39046;&#22495;&#20197;&#27599;&#31186;PB&#30340;&#36895;&#24230;&#20135;&#29983;&#25968;&#25454;&#12290;&#24320;&#21457;&#23454;&#26102;&#25968;&#25454;&#21387;&#32553;&#31639;&#27861;&#20197;&#20943;&#23567;&#25968;&#25454;&#37327;&#20197;&#36866;&#24212;&#27704;&#20037;&#23384;&#20648;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#22312;&#30456;&#23545;&#35770;&#37325;&#31163;&#23376;&#23545;&#25758;&#26426;&#65288;RHIC&#65289;&#30340;&#26032;&#24314;sPHENIX&#23454;&#39564;&#20013;&#65292;&#26102;&#38388;&#25237;&#24433;&#23460;&#34987;&#29992;&#20316;&#20027;&#35201;&#36319;&#36394;&#25506;&#27979;&#22120;&#65292;&#35760;&#24405;&#20102;&#19977;&#32500;&#65288;3D&#65289;&#22278;&#26609;&#20307;&#20869;&#30340;&#31890;&#23376;&#36712;&#36857;&#12290;&#32467;&#26524;&#25968;&#25454;&#36890;&#24120;&#38750;&#24120;&#31232;&#30095;&#65292;&#21344;&#25454;&#29575;&#32422;&#20026;10.8%&#12290;&#36825;&#26679;&#30340;&#31232;&#30095;&#24615;&#23545;&#20110;&#20256;&#32479;&#30340;&#26080;&#25439;&#23398;&#20064;&#21387;&#32553;&#31639;&#27861;&#65288;&#22914;SZ&#12289;ZFP&#21644;MGARD&#65289;&#25552;&#20986;&#20102;&#25361;&#25112;&#12290;&#22522;&#20110;3D&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#30340;&#26041;&#27861;&#65292;&#21363;&#20108;&#22836;&#21367;&#31215;&#33258;&#32534;&#30721;&#22120;&#65288;BCAE&#65289;&#65292;&#22312;&#21387;&#32553;&#29575;&#21644;&#37325;&#24314;&#31934;&#24230;&#26041;&#38754;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#12290;BCAE&#36824;&#21487;&#20197;&#21033;&#29992;&#35745;&#31639;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
High-energy large-scale particle colliders produce data at high speed in the order of 1 terabytes per second in nuclear physics and petabytes per second in high-energy physics. Developing real-time data compression algorithms to reduce such data at high throughput to fit permanent storage has drawn increasing attention. Specifically, at the newly constructed sPHENIX experiment at the Relativistic Heavy Ion Collider (RHIC), a time projection chamber is used as the main tracking detector, which records particle trajectories in a volume of a three-dimensional (3D) cylinder. The resulting data are usually very sparse with occupancy around 10.8%. Such sparsity presents a challenge to conventional learning-free lossy compression algorithms, such as SZ, ZFP, and MGARD. The 3D convolutional neural network (CNN)-based approach, Bicephalous Convolutional Autoencoder (BCAE), outperforms traditional methods both in compression rate and reconstruction accuracy. BCAE can also utilize the computation
&lt;/p&gt;</description></item><item><title>&#22312;&#36125;&#21494;&#26031;&#20027;&#21160;&#20803;&#23398;&#20064;&#20013;&#65292;&#36138;&#23146;&#36861;&#27714;&#21487;&#36716;&#31227;&#30693;&#35782;&#21487;&#33021;&#20250;&#25439;&#23475;&#23545;&#21487;&#36716;&#31227;&#21442;&#25968;&#30340;&#20272;&#35745;&#65292;&#23398;&#20064;&#32773;&#38754;&#20020;&#20219;&#21153;&#35782;&#21035;&#21644;&#21487;&#36716;&#31227;&#30693;&#35782;&#33719;&#21462;&#20043;&#38388;&#30340;&#22256;&#22659;&#12290;</title><link>http://arxiv.org/abs/2310.14968</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#20027;&#21160;&#20803;&#23398;&#20064;&#30340;&#22522;&#26412;&#22256;&#22659;
&lt;/p&gt;
&lt;p&gt;
The Fundamental Dilemma of Bayesian Active Meta-learning. (arXiv:2310.14968v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14968
&lt;/p&gt;
&lt;p&gt;
&#22312;&#36125;&#21494;&#26031;&#20027;&#21160;&#20803;&#23398;&#20064;&#20013;&#65292;&#36138;&#23146;&#36861;&#27714;&#21487;&#36716;&#31227;&#30693;&#35782;&#21487;&#33021;&#20250;&#25439;&#23475;&#23545;&#21487;&#36716;&#31227;&#21442;&#25968;&#30340;&#20272;&#35745;&#65292;&#23398;&#20064;&#32773;&#38754;&#20020;&#20219;&#21153;&#35782;&#21035;&#21644;&#21487;&#36716;&#31227;&#30693;&#35782;&#33719;&#21462;&#20043;&#38388;&#30340;&#22256;&#22659;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#24212;&#29992;&#38656;&#35201;&#20272;&#35745;&#22312;&#22810;&#20010;&#19981;&#21516;&#20294;&#30456;&#20851;&#30340;&#25968;&#25454;&#31232;&#32570;&#20219;&#21153;&#29615;&#22659;&#20013;&#25512;&#24191;&#30340;&#21442;&#25968;&#12290;&#36125;&#21494;&#26031;&#20027;&#21160;&#20803;&#23398;&#20064;&#26159;&#19968;&#31181;&#39034;&#24207;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#30340;&#24418;&#24335;&#65292;&#20026;&#35299;&#20915;&#36825;&#31867;&#38382;&#39064;&#25552;&#20379;&#20102;&#19968;&#20010;&#26694;&#26550;&#12290;&#20027;&#21160;&#20803;&#23398;&#20064;&#32773;&#30340;&#30446;&#26631;&#26159;&#22312;&#24403;&#21069;&#20219;&#21153;&#30340;&#29305;&#27530;&#29305;&#24449;&#65288;&#20219;&#21153;&#29305;&#23450;&#21442;&#25968;&#65289;&#30340;&#24773;&#20917;&#19979;&#33719;&#24471;&#21487;&#36716;&#31227;&#30340;&#30693;&#35782;&#65288;&#20272;&#35745;&#21487;&#36716;&#31227;&#30340;&#21442;&#25968;&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#36138;&#23146;&#36861;&#27714;&#36825;&#20010;&#30446;&#26631;&#23454;&#38469;&#19978;&#21487;&#33021;&#20250;&#25439;&#23475;&#23545;&#21487;&#36716;&#31227;&#21442;&#25968;&#30340;&#20272;&#35745;&#65288;&#24341;&#36215;&#25152;&#35859;&#30340;&#36127;&#36801;&#31227;&#65289;&#12290;&#23398;&#20064;&#32773;&#38754;&#20020;&#30528;&#19968;&#20010;&#31867;&#20284;&#20294;&#19981;&#21516;&#20110;&#21208;&#25506;-&#21033;&#29992;&#22256;&#22659;&#30340;&#22256;&#22659;&#65306;&#20182;&#20204;&#24212;&#35813;&#33457;&#36153;&#20182;&#20204;&#30340;&#33719;&#21462;&#39044;&#31639;&#26469;&#36861;&#27714;&#21487;&#36716;&#31227;&#30340;&#30693;&#35782;&#65292;&#36824;&#26159;&#29992;&#26469;&#30830;&#23450;&#24403;&#21069;&#20219;&#21153;&#29305;&#23450;&#30340;&#21442;&#25968;&#65311;&#25105;&#20204;&#29702;&#35770;&#19978;&#35777;&#26126;&#65292;&#19968;&#20123;&#20219;&#21153;&#23384;&#22312;&#19981;&#21487;&#36991;&#20813;&#19988;&#20219;&#24847;&#22823;&#30340;&#36127;&#36801;&#31227;&#23041;&#32961;&#65292;&#20219;&#21153;&#30340;&#35782;&#21035;&#23545;&#20110;&#37325;&#26032;&#23547;&#25214;&#21487;&#36801;&#31227;&#21442;&#25968;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many applications involve estimation of parameters that generalize across multiple diverse, but related, data-scarce task environments. Bayesian active meta-learning, a form of sequential optimal experimental design, provides a framework for solving such problems. The active meta-learner's goal is to gain transferable knowledge (estimate the transferable parameters) in the presence of idiosyncratic characteristics of the current task (task-specific parameters). We show that in such a setting, greedy pursuit of this goal can actually hurt estimation of the transferable parameters (induce so-called negative transfer). The learner faces a dilemma akin to but distinct from the exploration--exploitation dilemma: should they spend their acquisition budget pursuing transferable knowledge, or identifying the current task-specific parameters? We show theoretically that some tasks pose an inevitable and arbitrarily large threat of negative transfer, and that task identification is critical to re
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;AdamQLR&#65292;&#23427;&#26159;&#19968;&#20010;&#36890;&#36807;&#23558;K-FAC&#20013;&#30340;&#25216;&#26415;&#19982;Adam&#30340;&#26356;&#26032;&#26041;&#27861;&#30456;&#32467;&#21512;&#30340;&#20248;&#21270;&#22120;&#65292;&#36890;&#36807;&#32771;&#34385;&#20108;&#38454;&#25968;&#25454;&#19978;&#30340;Adam&#34892;&#20026;&#32780;&#24471;&#21040;&#21551;&#21457;&#12290;&#22312;&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#32467;&#26524;&#26174;&#31034;AdamQLR&#22312;&#36816;&#34892;&#26102;&#38388;&#21644;&#25512;&#24191;&#24615;&#33021;&#26041;&#38754;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#31454;&#20105;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.14963</link><description>&lt;p&gt;
&#36890;&#36807;&#20108;&#38454;&#36879;&#38236;&#30475;Adam
&lt;/p&gt;
&lt;p&gt;
Adam through a Second-Order Lens. (arXiv:2310.14963v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14963
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;AdamQLR&#65292;&#23427;&#26159;&#19968;&#20010;&#36890;&#36807;&#23558;K-FAC&#20013;&#30340;&#25216;&#26415;&#19982;Adam&#30340;&#26356;&#26032;&#26041;&#27861;&#30456;&#32467;&#21512;&#30340;&#20248;&#21270;&#22120;&#65292;&#36890;&#36807;&#32771;&#34385;&#20108;&#38454;&#25968;&#25454;&#19978;&#30340;Adam&#34892;&#20026;&#32780;&#24471;&#21040;&#21551;&#21457;&#12290;&#22312;&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#32467;&#26524;&#26174;&#31034;AdamQLR&#22312;&#36816;&#34892;&#26102;&#38388;&#21644;&#25512;&#24191;&#24615;&#33021;&#26041;&#38754;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#20248;&#21270;&#30740;&#31350;&#23384;&#22312;&#19968;&#31181;&#32039;&#24352;&#29366;&#24577;&#65292;&#21363;&#31532;&#19968;&#38454;&#26799;&#24230;&#27861;&#65288;&#22914;SGD&#21644;Adam&#65289;&#30340;&#35745;&#31639;&#25928;&#29575;&#19982;&#31532;&#20108;&#38454;&#26354;&#29575;&#27861;&#65288;&#22914;&#25311;&#29275;&#39039;&#26041;&#27861;&#21644;K-FAC&#65289;&#30340;&#29702;&#35770;&#25928;&#29575;&#20043;&#38388;&#30340;&#32039;&#24352;&#20851;&#31995;&#12290;&#25105;&#20204;&#35797;&#22270;&#23558;&#36825;&#20004;&#31181;&#26041;&#27861;&#30340;&#20248;&#28857;&#32467;&#21512;&#21040;&#19968;&#20010;&#35745;&#31639;&#19978;&#39640;&#25928;&#30340;&#31639;&#27861;&#20013;&#12290;&#27880;&#24847;&#21040;&#20108;&#38454;&#26041;&#27861;&#36890;&#24120;&#20381;&#36182;&#20110;&#31283;&#23450;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#65288;&#22914;Levenberg-Marquardt&#38459;&#23612;&#65289;&#65292;&#25105;&#20204;&#25552;&#20986;AdamQLR&#65306;&#19968;&#20010;&#23558;K-FAC&#20013;&#30340;&#38459;&#23612;&#21644;&#23398;&#20064;&#29575;&#36873;&#25321;&#25216;&#26415;&#19982;Adam&#25552;&#20986;&#30340;&#26356;&#26032;&#26041;&#21521;&#30456;&#32467;&#21512;&#30340;&#20248;&#21270;&#22120;&#65292;&#36890;&#36807;&#32771;&#34385;Adam&#22312;&#20108;&#38454;&#25968;&#25454;&#19978;&#30340;&#34920;&#29616;&#32780;&#24471;&#21040;&#21551;&#21457;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#35268;&#27169;&#30340;&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#19978;&#35780;&#20272;&#20102;AdamQLR&#65292;&#22312;&#36816;&#34892;&#26102;&#38388;&#19982;&#31454;&#20105;&#24615;&#25512;&#24191;&#24615;&#33021;&#20043;&#38388;&#21462;&#24471;&#20102;&#31454;&#20105;&#24615;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Research into optimisation for deep learning is characterised by a tension between the computational efficiency of first-order, gradient-based methods (such as SGD and Adam) and the theoretical efficiency of second-order, curvature-based methods (such as quasi-Newton methods and K-FAC). We seek to combine the benefits of both approaches into a single computationally-efficient algorithm. Noting that second-order methods often depend on stabilising heuristics (such as Levenberg-Marquardt damping), we propose AdamQLR: an optimiser combining damping and learning rate selection techniques from K-FAC (Martens and Grosse, 2015) with the update directions proposed by Adam, inspired by considering Adam through a second-order lens. We evaluate AdamQLR on a range of regression and classification tasks at various scales, achieving competitive generalisation performance vs runtime.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20197;Hessian-Vector&#20056;&#31215;&#31995;&#21015;&#20026;&#22522;&#30784;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#24179;&#26041;&#26681;&#21644;&#27714;&#36870;&#25805;&#20316;&#23454;&#29616;&#20102;&#39640;&#25928;&#21487;&#20280;&#32553;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#24182;&#30456;&#23545;&#20110;&#20854;&#20182;&#19968;&#38454;&#21644;&#20108;&#38454;&#20248;&#21270;&#26041;&#27861;&#22312;&#36816;&#34892;&#26102;&#38388;&#21644;&#24615;&#33021;&#19978;&#20855;&#26377;&#21487;&#27604;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.14901</link><description>&lt;p&gt;
&#21487;&#34892;&#30340;&#26080;&#38797;&#29275;&#39039;&#20248;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;Hessian-Vector&#20056;&#31215;&#31995;&#21015;
&lt;/p&gt;
&lt;p&gt;
Series of Hessian-Vector Products for Tractable Saddle-Free Newton Optimisation of Neural Networks. (arXiv:2310.14901v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14901
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20197;Hessian-Vector&#20056;&#31215;&#31995;&#21015;&#20026;&#22522;&#30784;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#24179;&#26041;&#26681;&#21644;&#27714;&#36870;&#25805;&#20316;&#23454;&#29616;&#20102;&#39640;&#25928;&#21487;&#20280;&#32553;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#24182;&#30456;&#23545;&#20110;&#20854;&#20182;&#19968;&#38454;&#21644;&#20108;&#38454;&#20248;&#21270;&#26041;&#27861;&#22312;&#36816;&#34892;&#26102;&#38388;&#21644;&#24615;&#33021;&#19978;&#20855;&#26377;&#21487;&#27604;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#25311;&#29275;&#39039;&#26041;&#27861;&#22312;&#36830;&#32493;&#20248;&#21270;&#39046;&#22495;&#38750;&#24120;&#21463;&#27426;&#36814;&#65292;&#20294;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#24212;&#29992;&#20173;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;Hessian&#30697;&#38453;&#30340;&#35268;&#27169;&#36807;&#22823;&#12290;&#36890;&#36807;&#20462;&#25913;Hessian&#30340;&#29305;&#24449;&#20540;&#26469;&#22788;&#29702;&#38750;&#20984;&#24615;&#65292;&#22914;&#26080;&#38797;&#29275;&#39039;&#26041;&#27861;&#65292;&#36827;&#19968;&#27493;&#22686;&#21152;&#20102;&#35745;&#31639;&#36127;&#25285;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21516;&#26102;&#35299;&#20915;&#36825;&#20004;&#20010;&#38382;&#39064;&#30340;&#20248;&#21270;&#31639;&#27861;-&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#39318;&#20010;&#21487;&#20197;&#28176;&#36817;&#22320;&#20351;&#29992;&#31934;&#30830;&#65288;&#29305;&#24449;&#20540;&#20462;&#25913;&#21518;&#30340;&#65289;&#36870;Hessian&#30340;&#39640;&#25928;&#21487;&#20280;&#32553;&#20248;&#21270;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#38382;&#39064;&#34920;&#36848;&#20026;&#19968;&#20010;&#20027;&#35201;&#23545;Hessian&#36827;&#34892;&#24179;&#26041;&#26681;&#21644;&#27714;&#36870;&#30340;&#32423;&#25968;&#65292;&#28982;&#21518;&#29992;&#23427;&#26469;&#39044;&#22788;&#29702;&#26799;&#24230;&#21521;&#37327;&#65292;&#32780;&#26080;&#38656;&#26174;&#24335;&#35745;&#31639;&#25110;&#36827;&#34892;&#29305;&#24449;&#20998;&#35299;&#12290;&#23545;&#35813;&#26080;&#38480;&#32423;&#25968;&#30340;&#25130;&#26029;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#21487;&#20280;&#32553;&#20248;&#21270;&#31639;&#27861;&#65292;&#20854;&#36816;&#34892;&#26102;&#38388;&#21644;&#20248;&#21270;&#24615;&#33021;&#19982;&#20854;&#20182;&#19968;&#38454;&#21644;&#20108;&#38454;&#20248;&#21270;&#26041;&#27861;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite their popularity in the field of continuous optimisation, second-order quasi-Newton methods are challenging to apply in machine learning, as the Hessian matrix is intractably large. This computational burden is exacerbated by the need to address non-convexity, for instance by modifying the Hessian's eigenvalues as in Saddle-Free Newton methods. We propose an optimisation algorithm which addresses both of these concerns - to our knowledge, the first efficiently-scalable optimisation algorithm to asymptotically use the exact (eigenvalue-modified) inverse Hessian. Our method frames the problem as a series which principally square-roots and inverts the squared Hessian, then uses it to precondition a gradient vector, all without explicitly computing or eigendecomposing the Hessian. A truncation of this infinite series provides a new optimisation algorithm which is scalable and comparable to other first- and second-order optimisation methods in both runtime and optimisation performan
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Boosting&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#20445;&#35777;&#26368;&#24046;&#31867;&#21035;&#35757;&#32451;&#35823;&#24046;&#30340;&#19978;&#30028;&#65292;&#24182;&#38477;&#20302;&#20102;&#26368;&#24046;&#31867;&#21035;&#30340;&#27979;&#35797;&#35823;&#24046;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.14890</link><description>&lt;p&gt;
Boosting&#29992;&#20110;&#30028;&#23450;&#26368;&#24046;&#20998;&#31867;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
Boosting for Bounding the Worst-class Error. (arXiv:2310.14890v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14890
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Boosting&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#20445;&#35777;&#26368;&#24046;&#31867;&#21035;&#35757;&#32451;&#35823;&#24046;&#30340;&#19978;&#30028;&#65292;&#24182;&#38477;&#20302;&#20102;&#26368;&#24046;&#31867;&#21035;&#30340;&#27979;&#35797;&#35823;&#24046;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#26368;&#24046;&#31867;&#21035;&#35823;&#24046;&#29575;&#30340;&#38382;&#39064;&#65292;&#32780;&#19981;&#26159;&#38024;&#23545;&#25152;&#26377;&#31867;&#21035;&#30340;&#26631;&#20934;&#35823;&#24046;&#29575;&#30340;&#24179;&#22343;&#12290;&#20363;&#22914;&#65292;&#19968;&#20010;&#19977;&#31867;&#21035;&#20998;&#31867;&#20219;&#21153;&#65292;&#20854;&#20013;&#21508;&#31867;&#21035;&#30340;&#35823;&#24046;&#29575;&#20998;&#21035;&#20026;10&#65285;&#65292;10&#65285;&#21644;40&#65285;&#65292;&#20854;&#26368;&#24046;&#31867;&#21035;&#35823;&#24046;&#29575;&#20026;40&#65285;&#65292;&#32780;&#22312;&#31867;&#21035;&#24179;&#34913;&#26465;&#20214;&#19979;&#30340;&#24179;&#22343;&#35823;&#24046;&#29575;&#20026;20&#65285;&#12290;&#26368;&#24046;&#31867;&#21035;&#38169;&#35823;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#24456;&#37325;&#35201;&#12290;&#20363;&#22914;&#65292;&#22312;&#21307;&#23398;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;&#23545;&#20110;&#24694;&#24615;&#32959;&#30244;&#31867;&#21035;&#20855;&#26377;40&#65285;&#30340;&#38169;&#35823;&#29575;&#32780;&#33391;&#24615;&#21644;&#20581;&#24247;&#31867;&#21035;&#20855;&#26377;10&#65285;&#30340;&#38169;&#35823;&#29575;&#26159;&#19981;&#33021;&#34987;&#25509;&#21463;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20445;&#35777;&#26368;&#24046;&#31867;&#21035;&#35757;&#32451;&#35823;&#24046;&#19978;&#30028;&#30340;&#25552;&#21319;&#31639;&#27861;&#65292;&#24182;&#25512;&#23548;&#20986;&#20854;&#27867;&#21270;&#30028;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#31639;&#27861;&#38477;&#20302;&#20102;&#26368;&#24046;&#31867;&#21035;&#30340;&#27979;&#35797;&#35823;&#24046;&#29575;&#65292;&#21516;&#26102;&#36991;&#20813;&#20102;&#23545;&#35757;&#32451;&#38598;&#30340;&#36807;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper tackles the problem of the worst-class error rate, instead of the standard error rate averaged over all classes. For example, a three-class classification task with class-wise error rates of 10\%, 10\%, and 40\% has a worst-class error rate of 40\%, whereas the average is 20\% under the class-balanced condition. The worst-class error is important in many applications. For example, in a medical image classification task, it would not be acceptable for the malignant tumor class to have a 40\% error rate, while the benign and healthy classes have 10\% error rates.We propose a boosting algorithm that guarantees an upper bound of the worst-class training error and derive its generalization bound. Experimental results show that the algorithm lowers worst-class test error rates while avoiding overfitting to the training set.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#20010;&#22312;&#31232;&#26377;&#31867;&#27010;&#29575;&#36235;&#36817;&#20110;&#38646;&#30340;&#24773;&#20917;&#19979;&#30340;&#26032;&#36129;&#29486;&#65292;&#20998;&#21035;&#26159;&#19968;&#31181;&#38750;&#28176;&#36817;&#24555;&#36895;&#29575;&#27010;&#29575;&#30028;&#38480;&#21644;&#19968;&#31181;&#19968;&#33268;&#19978;&#30028;&#20272;&#35745;&#26041;&#27861;&#65292;&#36825;&#20123;&#21457;&#29616;&#20026;&#22312;&#23454;&#38469;&#24773;&#20917;&#19979;&#30340;&#31867;&#21035;&#21152;&#26435;&#25552;&#20379;&#20102;&#26356;&#28165;&#26224;&#30340;&#29702;&#35299;&#65292;&#20026;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#26032;&#30340;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2310.14826</link><description>&lt;p&gt;
&#38024;&#23545;&#19981;&#24179;&#34913;&#20998;&#31867;&#30340;&#23574;&#38160;&#35823;&#24046;&#30028;&#65306;&#23569;&#25968;&#31867;&#20013;&#26377;&#22810;&#23569;&#26679;&#26412;&#65311;
&lt;/p&gt;
&lt;p&gt;
Sharp error bounds for imbalanced classification: how many examples in the minority class?. (arXiv:2310.14826v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14826
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#20010;&#22312;&#31232;&#26377;&#31867;&#27010;&#29575;&#36235;&#36817;&#20110;&#38646;&#30340;&#24773;&#20917;&#19979;&#30340;&#26032;&#36129;&#29486;&#65292;&#20998;&#21035;&#26159;&#19968;&#31181;&#38750;&#28176;&#36817;&#24555;&#36895;&#29575;&#27010;&#29575;&#30028;&#38480;&#21644;&#19968;&#31181;&#19968;&#33268;&#19978;&#30028;&#20272;&#35745;&#26041;&#27861;&#65292;&#36825;&#20123;&#21457;&#29616;&#20026;&#22312;&#23454;&#38469;&#24773;&#20917;&#19979;&#30340;&#31867;&#21035;&#21152;&#26435;&#25552;&#20379;&#20102;&#26356;&#28165;&#26224;&#30340;&#29702;&#35299;&#65292;&#20026;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#26032;&#30340;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22788;&#29702;&#19981;&#24179;&#34913;&#20998;&#31867;&#25968;&#25454;&#26102;&#65292;&#37325;&#26032;&#21152;&#26435;&#25439;&#22833;&#20989;&#25968;&#26159;&#19968;&#31181;&#26631;&#20934;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#39118;&#38505;&#24230;&#37327;&#20013;&#24179;&#34913;&#30495;&#27491;&#30340;&#27491;&#20363;&#29575;&#21644;&#30495;&#27491;&#30340;&#36127;&#20363;&#29575;&#12290;&#23613;&#31649;&#22312;&#36825;&#20010;&#39046;&#22495;&#26377;&#37325;&#35201;&#30340;&#29702;&#35770;&#24037;&#20316;&#65292;&#20294;&#29616;&#26377;&#30340;&#32467;&#26524;&#24182;&#27809;&#26377;&#20805;&#20998;&#35299;&#20915;&#19981;&#24179;&#34913;&#20998;&#31867;&#26694;&#26550;&#20013;&#30340;&#20027;&#35201;&#25361;&#25112;&#65292;&#21363;&#30456;&#23545;&#20110;&#25972;&#20010;&#26679;&#26412;&#22823;&#23567;&#26469;&#35828;&#19968;&#20010;&#31867;&#30340;&#21487;&#24573;&#30053;&#30340;&#22823;&#23567;&#20197;&#21450;&#38656;&#35201;&#36890;&#36807;&#36235;&#36817;&#20110;&#38646;&#30340;&#27010;&#29575;&#26469;&#37325;&#26032;&#35843;&#25972;&#39118;&#38505;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#22312;&#31232;&#26377;&#31867;&#27010;&#29575;&#36235;&#36817;&#20110;&#38646;&#30340;&#24773;&#20917;&#19979;&#25552;&#20986;&#20102;&#20004;&#20010;&#26032;&#30340;&#36129;&#29486;&#65306;&#65288;1&#65289;&#29992;&#20110;&#32422;&#26463;&#24179;&#34913;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#38750;&#28176;&#36817;&#24555;&#36895;&#29575;&#27010;&#29575;&#30028;&#38480;&#65292;&#20197;&#21450;&#65288;2&#65289;&#29992;&#20110;&#24179;&#34913;&#26368;&#36817;&#37051;&#20272;&#35745;&#30340;&#19968;&#33268;&#19978;&#30028;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#26356;&#28165;&#26970;&#22320;&#35828;&#26126;&#20102;&#31867;&#21035;&#21152;&#26435;&#22312;&#23454;&#38469;&#24773;&#20917;&#19979;&#30340;&#30410;&#22788;&#65292;&#20026;&#36825;&#20010;&#39046;&#22495;&#30340;&#36827;&#19968;&#27493;&#30740;&#31350;&#24320;&#36767;&#20102;&#26032;&#30340;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
When dealing with imbalanced classification data, reweighting the loss function is a standard procedure allowing to equilibrate between the true positive and true negative rates within the risk measure. Despite significant theoretical work in this area, existing results do not adequately address a main challenge within the imbalanced classification framework, which is the negligible size of one class in relation to the full sample size and the need to rescale the risk function by a probability tending to zero. To address this gap, we present two novel contributions in the setting where the rare class probability approaches zero: (1) a non asymptotic fast rate probability bound for constrained balanced empirical risk minimization, and (2) a consistent upper bound for balanced nearest neighbors estimates. Our findings provide a clearer understanding of the benefits of class-weighting in realistic settings, opening new avenues for further research in this field.
&lt;/p&gt;</description></item><item><title>&#36807;&#21435;13&#24180;&#20013;&#30340;&#25968;&#25454;&#31185;&#23398;&#35789;&#27719;&#20351;&#29992;&#24773;&#20917;&#36827;&#34892;&#20102;&#20840;&#38754;&#32771;&#23519;&#65292;&#30740;&#31350;&#21457;&#29616;&#20102;&#24341;&#20837;&#26032;&#35789;&#27719;&#30340;&#25991;&#29486;&#65292;&#24182;&#25506;&#32034;&#20102;&#36825;&#20123;&#35789;&#27719;&#22914;&#20309;&#34987;&#32435;&#20837;&#31185;&#23398;&#25991;&#29486;&#20013;&#12290;&#21516;&#26102;&#20998;&#26512;&#20102;&#27801;&#29305;&#38463;&#25289;&#20271;&#30340;&#31185;&#23398;&#20986;&#29256;&#29289;&#19982;&#25972;&#20307;&#32467;&#26524;&#20043;&#38388;&#30340;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2310.14808</link><description>&lt;p&gt;
&#25968;&#25454;&#31185;&#23398;&#30340;&#28436;&#21464;&#19982;&#27801;&#29305;&#38463;&#25289;&#20271;&#26696;&#20363;&#8212;&#8212;13&#24180;&#26469;&#25105;&#20204;&#21457;&#29983;&#20102;&#22810;&#22823;&#30340;&#21464;&#21270;&#65311;
&lt;/p&gt;
&lt;p&gt;
The evolving of Data Science and the Saudi Arabia case. How much have we changed in 13 years?. (arXiv:2310.14808v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14808
&lt;/p&gt;
&lt;p&gt;
&#36807;&#21435;13&#24180;&#20013;&#30340;&#25968;&#25454;&#31185;&#23398;&#35789;&#27719;&#20351;&#29992;&#24773;&#20917;&#36827;&#34892;&#20102;&#20840;&#38754;&#32771;&#23519;&#65292;&#30740;&#31350;&#21457;&#29616;&#20102;&#24341;&#20837;&#26032;&#35789;&#27719;&#30340;&#25991;&#29486;&#65292;&#24182;&#25506;&#32034;&#20102;&#36825;&#20123;&#35789;&#27719;&#22914;&#20309;&#34987;&#32435;&#20837;&#31185;&#23398;&#25991;&#29486;&#20013;&#12290;&#21516;&#26102;&#20998;&#26512;&#20102;&#27801;&#29305;&#38463;&#25289;&#20271;&#30340;&#31185;&#23398;&#20986;&#29256;&#29289;&#19982;&#25972;&#20307;&#32467;&#26524;&#20043;&#38388;&#30340;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#36807;&#21435;13&#24180;&#20013;&#25968;&#25454;&#31185;&#23398;&#35789;&#27719;&#30340;&#20351;&#29992;&#24773;&#20917;&#36827;&#34892;&#20102;&#20840;&#38754;&#32771;&#23519;&#12290;&#30740;&#31350;&#20174;&#19968;&#20010;&#21253;&#21547;16,018&#20010;&#25688;&#35201;&#30340;&#25968;&#25454;&#38598;&#24320;&#22987;&#65292;&#36825;&#20123;&#25688;&#35201;&#20013;&#20986;&#29616;&#20102;&#8220;&#25968;&#25454;&#31185;&#23398;&#8221;&#19968;&#35789;&#65292;&#26080;&#35770;&#26159;&#26631;&#39064;&#12289;&#25688;&#35201;&#36824;&#26159;&#20851;&#38190;&#35789;&#12290;&#30740;&#31350;&#21253;&#25324;&#35782;&#21035;&#24341;&#20837;&#26032;&#35789;&#27719;&#30340;&#25991;&#29486;&#65292;&#24182;&#36827;&#19968;&#27493;&#25506;&#32034;&#36825;&#20123;&#35789;&#27719;&#22914;&#20309;&#34987;&#32435;&#20837;&#31185;&#23398;&#25991;&#29486;&#20013;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20123;&#30446;&#26631;&#65292;&#25105;&#37319;&#29992;&#20102;&#25506;&#32034;&#24615;&#25968;&#25454;&#20998;&#26512;&#12289;&#28508;&#22312;&#35821;&#20041;&#20998;&#26512;&#12289;&#28508;&#22312;&#29380;&#21033;&#20811;&#38647;&#20998;&#26512;&#21644;N-gram&#20998;&#26512;&#31561;&#25216;&#26415;&#12290;&#25991;&#31456;&#36824;&#23637;&#31034;&#20102;&#25972;&#20307;&#32467;&#26524;&#21644;&#27801;&#29305;&#38463;&#25289;&#20271;&#29305;&#23450;&#32467;&#26524;&#20043;&#38388;&#30340;&#31185;&#23398;&#20986;&#29256;&#29289;&#27604;&#36739;&#12290;&#26681;&#25454;&#35789;&#27719;&#30340;&#20351;&#29992;&#26041;&#24335;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#20195;&#34920;&#24615;&#25991;&#31456;&#12290;
&lt;/p&gt;
&lt;p&gt;
A comprehensive examination of data science vocabulary usage over the past 13 years in this work is conducted. The investigation commences with a dataset comprising 16,018 abstracts that feature the term "data science" in either the title, abstract, or keywords. The study involves the identification of documents that introduce novel vocabulary and subsequently explores how this vocabulary has been incorporated into scientific literature. To achieve these objectives, I employ techniques such as Exploratory Data Analysis, Latent Semantic Analysis, Latent Dirichlet Analysis, and N-grams Analysis. A comparison of scientific publications between overall results and those specific to Saudi Arabia is presented. Based on how the vocabulary is utilized, representative articles are identified.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#30740;&#31350;&#20102;&#22810;&#20010;&#19987;&#23478;&#23398;&#20064;&#25512;&#36831;&#38382;&#39064;&#30340;&#20195;&#29702;&#25439;&#22833;&#21644;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20123;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#20855;&#26377;&#24378;H&#19968;&#33268;&#24615;&#30028;&#38480;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20960;&#20010;&#23454;&#38469;&#24212;&#29992;&#30340;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#65292;&#24182;&#35774;&#35745;&#20102;&#22522;&#20110;&#26368;&#23567;&#21270;&#36825;&#20123;&#25439;&#22833;&#20989;&#25968;&#30340;&#26032;&#30340;&#23398;&#20064;&#25512;&#36831;&#31639;&#27861;&#12290;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#22312;SVHN&#21644;CIFAR-10&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#12290;</title><link>http://arxiv.org/abs/2310.14774</link><description>&lt;p&gt;
&#22810;&#20010;&#19987;&#23478;&#23398;&#20064;&#25512;&#36831;&#30340;&#21407;&#21017;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Principled Approaches for Learning to Defer with Multiple Experts. (arXiv:2310.14774v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14774
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22810;&#20010;&#19987;&#23478;&#23398;&#20064;&#25512;&#36831;&#38382;&#39064;&#30340;&#20195;&#29702;&#25439;&#22833;&#21644;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20123;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#20855;&#26377;&#24378;H&#19968;&#33268;&#24615;&#30028;&#38480;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20960;&#20010;&#23454;&#38469;&#24212;&#29992;&#30340;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#65292;&#24182;&#35774;&#35745;&#20102;&#22522;&#20110;&#26368;&#23567;&#21270;&#36825;&#20123;&#25439;&#22833;&#20989;&#25968;&#30340;&#26032;&#30340;&#23398;&#20064;&#25512;&#36831;&#31639;&#27861;&#12290;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#22312;SVHN&#21644;CIFAR-10&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#39033;&#20851;&#20110;&#20351;&#29992;&#22810;&#20010;&#19987;&#23478;&#23398;&#20064;&#25512;&#36831;&#38382;&#39064;&#30340;&#20195;&#29702;&#25439;&#22833;&#21644;&#31639;&#27861;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#39318;&#20808;&#24341;&#20837;&#20102;&#19968;&#31867;&#19987;&#38376;&#38024;&#23545;&#22810;&#19987;&#23478;&#35774;&#32622;&#30340;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#65292;&#20854;&#20013;&#39044;&#27979;&#21644;&#25512;&#36831;&#20989;&#25968;&#21516;&#26102;&#23398;&#20064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#21463;&#30410;&#20110;&#24378;H&#19968;&#33268;&#24615;&#30028;&#38480;&#12290;&#25105;&#20204;&#36890;&#36807;&#20960;&#20010;&#23454;&#38469;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#30340;&#31034;&#20363;&#23637;&#31034;&#20102;&#25105;&#20204;&#20998;&#26512;&#30340;&#24212;&#29992;&#65292;&#24182;&#32473;&#20986;&#20102;&#26126;&#30830;&#30340;&#20445;&#35777;&#12290;&#36825;&#20123;&#25439;&#22833;&#20989;&#25968;&#30452;&#25509;&#23548;&#33268;&#20102;&#22522;&#20110;&#23427;&#20204;&#26368;&#23567;&#21270;&#30340;&#26032;&#30340;&#23398;&#20064;&#25512;&#36831;&#31639;&#27861;&#30340;&#35774;&#35745;&#12290;&#34429;&#28982;&#26412;&#24037;&#20316;&#30340;&#20027;&#35201;&#37325;&#28857;&#26159;&#29702;&#35770;&#20998;&#26512;&#65292;&#20294;&#25105;&#20204;&#36824;&#25253;&#21578;&#20102;&#22312;SVHN&#21644;CIFAR-10&#25968;&#25454;&#38598;&#19978;&#30340;&#22810;&#20010;&#23454;&#39564;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a study of surrogate losses and algorithms for the general problem of learning to defer with multiple experts. We first introduce a new family of surrogate losses specifically tailored for the multiple-expert setting, where the prediction and deferral functions are learned simultaneously. We then prove that these surrogate losses benefit from strong $H$-consistency bounds. We illustrate the application of our analysis through several examples of practical surrogate losses, for which we give explicit guarantees. These loss functions readily lead to the design of new learning to defer algorithms based on their minimization. While the main focus of this work is a theoretical analysis, we also report the results of several experiments on SVHN and CIFAR-10 datasets.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#30740;&#31350;&#20102;&#22810;&#31867;&#21035;&#20998;&#31867;&#35774;&#32622;&#20013;&#30340;&#23398;&#20064;&#19982;&#25918;&#24323;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#26032;&#30340;&#29702;&#35770;&#21644;&#31639;&#27861;&#32467;&#26524;&#65292;&#35299;&#20915;&#20102;&#20004;&#20010;&#29616;&#23384;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;&#36825;&#20123;&#20445;&#35777;&#20026;&#22522;&#20110;&#26368;&#23567;&#21270;&#25918;&#24323;&#25439;&#22833;&#30340;&#26032;&#30340;&#22810;&#31867;&#21035;&#25918;&#24323;&#31639;&#27861;&#25552;&#20379;&#20102;&#21551;&#31034;&#12290;</title><link>http://arxiv.org/abs/2310.14772</link><description>&lt;p&gt;
&#39044;&#27979;-&#25298;&#32477;&#22810;&#31867;&#25918;&#24323;&#65306;&#29702;&#35770;&#20998;&#26512;&#21644;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Predictor-Rejector Multi-Class Abstention: Theoretical Analysis and Algorithms. (arXiv:2310.14772v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14772
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22810;&#31867;&#21035;&#20998;&#31867;&#35774;&#32622;&#20013;&#30340;&#23398;&#20064;&#19982;&#25918;&#24323;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#26032;&#30340;&#29702;&#35770;&#21644;&#31639;&#27861;&#32467;&#26524;&#65292;&#35299;&#20915;&#20102;&#20004;&#20010;&#29616;&#23384;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;&#36825;&#20123;&#20445;&#35777;&#20026;&#22522;&#20110;&#26368;&#23567;&#21270;&#25918;&#24323;&#25439;&#22833;&#30340;&#26032;&#30340;&#22810;&#31867;&#21035;&#25918;&#24323;&#31639;&#27861;&#25552;&#20379;&#20102;&#21551;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22810;&#31867;&#21035;&#20998;&#31867;&#35774;&#32622;&#20013;&#30340;&#23398;&#20064;&#19982;&#25918;&#24323;&#26694;&#26550;&#12290;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#65292;&#23398;&#20064;&#32773;&#21487;&#20197;&#36873;&#25321;&#20197;&#19968;&#23450;&#30340;&#39044;&#23450;&#20041;&#25104;&#26412;&#25918;&#24323;&#36827;&#34892;&#39044;&#27979;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#26032;&#30340;&#29702;&#35770;&#21644;&#31639;&#27861;&#32467;&#26524;&#65292;&#35299;&#20915;&#20102;&#39044;&#27979;-&#25298;&#32477;&#26694;&#26550;&#19979;&#30340;&#23398;&#20064;&#38382;&#39064;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#20960;&#20010;&#26032;&#30340;&#26367;&#20195;&#25439;&#22833;&#20989;&#25968;&#23478;&#26063;&#65292;&#35777;&#26126;&#20102;&#24378;&#38750;&#28176;&#36827;&#21644;&#20551;&#35774;&#38598;&#29305;&#23450;&#30340;&#19968;&#33268;&#24615;&#20445;&#35777;&#65292;&#20174;&#32780;&#31215;&#26497;&#22320;&#35299;&#20915;&#20102;&#20004;&#20010;&#29616;&#23384;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;&#36825;&#20123;&#20445;&#35777;&#25552;&#20379;&#20102;&#25918;&#24323;&#25439;&#22833;&#20989;&#25968;&#30340;&#20272;&#35745;&#35823;&#24046;&#30340;&#19978;&#30028;&#65292;&#19982;&#26367;&#20195;&#25439;&#22833;&#30340;&#35823;&#24046;&#30456;&#20851;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#21516;&#26102;&#23398;&#20064;&#39044;&#27979;&#22120;&#21644;&#25298;&#32477;&#22120;&#30340;&#21333;&#38454;&#27573;&#35774;&#32622;&#65292;&#20197;&#21450;&#22312;&#24212;&#29992;&#20013;&#33267;&#20851;&#37325;&#35201;&#30340;&#20004;&#38454;&#27573;&#35774;&#32622;&#65292;&#22312;&#31532;&#19968;&#38454;&#27573;&#20351;&#29992;&#26631;&#20934;&#26367;&#20195;&#25439;&#22833;&#20989;&#25968;&#22914;&#20132;&#21449;&#29109;&#26469;&#23398;&#20064;&#39044;&#27979;&#22120;&#12290;&#36825;&#20123;&#20445;&#35777;&#20026;&#22522;&#20110;&#26368;&#23567;&#21270;&#25918;&#24323;&#25439;&#22833;&#30340;&#26032;&#30340;&#22810;&#31867;&#21035;&#25918;&#24323;&#31639;&#27861;&#25552;&#20379;&#20102;&#21551;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the key framework of learning with abstention in the multi-class classification setting. In this setting, the learner can choose to abstain from making a prediction with some pre-defined cost. We present a series of new theoretical and algorithmic results for this learning problem in the predictor-rejector framework. We introduce several new families of surrogate losses for which we prove strong non-asymptotic and hypothesis set-specific consistency guarantees, thereby resolving positively two existing open questions. These guarantees provide upper bounds on the estimation error of the abstention loss function in terms of that of the surrogate loss. We analyze both a single-stage setting where the predictor and rejector are learned simultaneously and a two-stage setting crucial in applications, where the predictor is learned in a first stage using a standard surrogate loss such as cross-entropy. These guarantees suggest new multi-class abstention algorithms based on minimizing
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#20998;&#25968;&#30340;&#22810;&#31867;&#25918;&#24323;&#30340;&#29702;&#35770;&#22522;&#30784;&#25439;&#22833;&#20989;&#25968;&#21644;&#31639;&#27861;&#65292;&#21253;&#25324;&#24341;&#20837;&#20102;&#26032;&#30340;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#26063;&#32676;&#20197;&#21450;&#35777;&#26126;&#20102;&#36825;&#20123;&#20195;&#29702;&#25439;&#22833;&#30340;&#19968;&#33268;&#24615;&#20445;&#35777;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#31639;&#27861;&#30340;&#23454;&#38469;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2310.14770</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#30340;&#22810;&#31867;&#25918;&#24323;&#30340;&#29702;&#35770;&#22522;&#30784;&#25439;&#22833;&#20989;&#25968;&#21644;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Theoretically Grounded Loss Functions and Algorithms for Score-Based Multi-Class Abstention. (arXiv:2310.14770v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14770
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#20998;&#25968;&#30340;&#22810;&#31867;&#25918;&#24323;&#30340;&#29702;&#35770;&#22522;&#30784;&#25439;&#22833;&#20989;&#25968;&#21644;&#31639;&#27861;&#65292;&#21253;&#25324;&#24341;&#20837;&#20102;&#26032;&#30340;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#26063;&#32676;&#20197;&#21450;&#35777;&#26126;&#20102;&#36825;&#20123;&#20195;&#29702;&#25439;&#22833;&#30340;&#19968;&#33268;&#24615;&#20445;&#35777;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#31639;&#27861;&#30340;&#23454;&#38469;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#20013;&#30340;&#25918;&#24323;&#26159;&#19968;&#31181;&#37325;&#35201;&#30340;&#22330;&#26223;&#65292;&#23398;&#20064;&#32773;&#21487;&#20197;&#36873;&#25321;&#22312;&#26576;&#20010;&#20195;&#20215;&#19979;&#25918;&#24323;&#36827;&#34892;&#39044;&#27979;&#12290;&#26412;&#25991;&#22312;&#22810;&#31867;&#21035;&#20998;&#31867;&#30340;&#35774;&#32622;&#19979;&#20998;&#26512;&#20102;&#22522;&#20110;&#20998;&#25968;&#30340;&#23398;&#20064;&#20013;&#30340;&#25918;&#24323;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#25918;&#24323;&#25439;&#22833;&#20989;&#25968;&#30340;&#26032;&#20195;&#29702;&#25439;&#22833;&#26063;&#32676;&#65292;&#20854;&#20013;&#21253;&#25324;&#21333;&#38454;&#27573;&#35774;&#32622;&#20013;&#26368;&#20808;&#36827;&#30340;&#20195;&#29702;&#25439;&#22833;&#20197;&#21450;&#20108;&#38454;&#27573;&#35774;&#32622;&#20013;&#30340;&#26032;&#22411;&#25439;&#22833;&#20989;&#25968;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#20195;&#29702;&#25439;&#22833;&#30340;&#24378;&#38750;&#28176;&#36817;&#21644;&#20551;&#35774;&#38598;&#29305;&#23450;&#30340;&#19968;&#33268;&#24615;&#20445;&#35777;&#65292;&#36825;&#20123;&#20445;&#35777;&#19978;&#30028;&#20102;&#25918;&#24323;&#25439;&#22833;&#20989;&#25968;&#30340;&#20272;&#35745;&#35823;&#24046;&#65292;&#19982;&#20195;&#29702;&#25439;&#22833;&#30340;&#20272;&#35745;&#35823;&#24046;&#30456;&#20851;&#12290;&#25105;&#20204;&#30340;&#19978;&#30028;&#21487;&#20197;&#24110;&#21161;&#27604;&#36739;&#19981;&#21516;&#30340;&#22522;&#20110;&#20998;&#25968;&#30340;&#20195;&#29702;&#25439;&#22833;&#65292;&#25351;&#23548;&#36890;&#36807;&#26368;&#23567;&#21270;&#25552;&#20986;&#30340;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#26469;&#35774;&#35745;&#26032;&#30340;&#25918;&#24323;&#31639;&#27861;&#12290;&#25105;&#20204;&#22312;CIFAR-10&#12289;CIFAR-100&#21644;SVHN&#25968;&#25454;&#38598;&#19978;&#23545;&#25105;&#20204;&#30340;&#26032;&#31639;&#27861;&#36827;&#34892;&#20102;&#23454;&#39564;&#35780;&#20272;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26032;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#30340;&#23454;&#38469;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning with abstention is a key scenario where the learner can abstain from making a prediction at some cost. In this paper, we analyze the score-based formulation of learning with abstention in the multi-class classification setting. We introduce new families of surrogate losses for the abstention loss function, which include the state-of-the-art surrogate losses in the single-stage setting and a novel family of loss functions in the two-stage setting. We prove strong non-asymptotic and hypothesis set-specific consistency guarantees for these surrogate losses, which upper-bound the estimation error of the abstention loss function in terms of the estimation error of the surrogate loss. Our bounds can help compare different score-based surrogates and guide the design of novel abstention algorithms by minimizing the proposed surrogate losses. We experimentally evaluate our new algorithms on CIFAR-10, CIFAR-100, and SVHN datasets and the practical significance of our new surrogate losse
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#35797;&#39564;&#21644;&#35266;&#23519;&#25968;&#25454;&#30340;&#22806;&#37096;&#26377;&#25928;&#31574;&#30053;&#35780;&#20272;&#26041;&#27861;&#65292;&#21033;&#29992;&#35797;&#39564;&#25968;&#25454;&#23545;&#30446;&#26631;&#20154;&#32676;&#19978;&#30340;&#25919;&#31574;&#32467;&#26524;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#65292;&#24182;&#32473;&#20986;&#20102;&#21487;&#39564;&#35777;&#30340;&#35780;&#20272;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.14763</link><description>&lt;p&gt;
&#22806;&#37096;&#39564;&#35777;&#31574;&#30053;&#35780;&#20272;&#32467;&#21512;&#35797;&#39564;&#21644;&#35266;&#23519;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Externally Valid Policy Evaluation Combining Trial and Observational Data. (arXiv:2310.14763v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14763
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#35797;&#39564;&#21644;&#35266;&#23519;&#25968;&#25454;&#30340;&#22806;&#37096;&#26377;&#25928;&#31574;&#30053;&#35780;&#20272;&#26041;&#27861;&#65292;&#21033;&#29992;&#35797;&#39564;&#25968;&#25454;&#23545;&#30446;&#26631;&#20154;&#32676;&#19978;&#30340;&#25919;&#31574;&#32467;&#26524;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#65292;&#24182;&#32473;&#20986;&#20102;&#21487;&#39564;&#35777;&#30340;&#35780;&#20272;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#35797;&#39564;&#34987;&#24191;&#27867;&#35748;&#20026;&#26159;&#35780;&#20272;&#20915;&#31574;&#31574;&#30053;&#24433;&#21709;&#30340;&#37329; standard&#12290;&#28982;&#32780;&#65292;&#35797;&#39564;&#25968;&#25454;&#26469;&#33258;&#21487;&#33021;&#19982;&#30446;&#26631;&#20154;&#32676;&#19981;&#21516;&#30340;&#20154;&#32676;&#65292;&#36825;&#24341;&#21457;&#20102;&#22806;&#37096;&#25928;&#24230;&#65288;&#20063;&#31216;&#20026;&#27867;&#21270;&#33021;&#21147;&#65289;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35797;&#22270;&#21033;&#29992;&#35797;&#39564;&#25968;&#25454;&#23545;&#30446;&#26631;&#20154;&#32676;&#19978;&#30340;&#25919;&#31574;&#32467;&#26524;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#12290;&#30446;&#26631;&#20154;&#32676;&#30340;&#39069;&#22806;&#21327;&#21464;&#37327;&#25968;&#25454;&#29992;&#20110;&#27169;&#25311;&#35797;&#39564;&#30740;&#31350;&#20013;&#20010;&#20307;&#30340;&#25277;&#26679;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22312;&#20219;&#20309;&#25351;&#23450;&#30340;&#27169;&#22411;&#26410;&#26657;&#20934;&#33539;&#22260;&#20869;&#20135;&#29983;&#21487;&#39564;&#35777;&#30340;&#22522;&#20110;&#35797;&#39564;&#30340;&#25919;&#31574;&#35780;&#20272;&#12290;&#35813;&#26041;&#27861;&#26159;&#38750;&#21442;&#25968;&#30340;&#65292;&#21363;&#20351;&#26679;&#26412;&#26159;&#26377;&#38480;&#30340;&#65292;&#26377;&#25928;&#24615;&#20063;&#24471;&#21040;&#20445;&#35777;&#12290;&#20351;&#29992;&#27169;&#25311;&#21644;&#23454;&#38469;&#25968;&#25454;&#35828;&#26126;&#20102;&#35748;&#35777;&#30340;&#25919;&#31574;&#35780;&#20272;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Randomized trials are widely considered as the gold standard for evaluating the effects of decision policies. Trial data is, however, drawn from a population which may differ from the intended target population and this raises a problem of external validity (aka. generalizability). In this paper we seek to use trial data to draw valid inferences about the outcome of a policy on the target population. Additional covariate data from the target population is used to model the sampling of individuals in the trial study. We develop a method that yields certifiably valid trial-based policy evaluations under any specified range of model miscalibrations. The method is nonparametric and the validity is assured even with finite samples. The certified policy evaluations are illustrated using both simulated and real data.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;EDAIn&#30340;&#25193;&#23637;&#28145;&#24230;&#33258;&#36866;&#24212;&#36755;&#20837;&#35268;&#33539;&#21270;&#23618;&#65292;&#36890;&#36807;&#20197;&#31471;&#21040;&#31471;&#30340;&#26041;&#24335;&#23398;&#20064;&#22914;&#20309;&#36866;&#24403;&#22320;&#35268;&#33539;&#21270;&#26102;&#24207;&#25968;&#25454;&#65292;&#32780;&#19981;&#26159;&#20351;&#29992;&#22266;&#23450;&#30340;&#35268;&#33539;&#21270;&#26041;&#26696;&#65292;&#26469;&#25552;&#39640;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#26102;&#24207;&#39044;&#27979;&#21644;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#37117;&#21462;&#24471;&#20102;&#33391;&#22909;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.14720</link><description>&lt;p&gt;
&#25193;&#23637;&#28145;&#24230;&#33258;&#36866;&#24212;&#36755;&#20837;&#35268;&#33539;&#21270;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#23545;&#26102;&#24207;&#25968;&#25454;&#30340;&#39044;&#22788;&#29702;
&lt;/p&gt;
&lt;p&gt;
Extended Deep Adaptive Input Normalization for Preprocessing Time Series Data for Neural Networks. (arXiv:2310.14720v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14720
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;EDAIn&#30340;&#25193;&#23637;&#28145;&#24230;&#33258;&#36866;&#24212;&#36755;&#20837;&#35268;&#33539;&#21270;&#23618;&#65292;&#36890;&#36807;&#20197;&#31471;&#21040;&#31471;&#30340;&#26041;&#24335;&#23398;&#20064;&#22914;&#20309;&#36866;&#24403;&#22320;&#35268;&#33539;&#21270;&#26102;&#24207;&#25968;&#25454;&#65292;&#32780;&#19981;&#26159;&#20351;&#29992;&#22266;&#23450;&#30340;&#35268;&#33539;&#21270;&#26041;&#26696;&#65292;&#26469;&#25552;&#39640;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#26102;&#24207;&#39044;&#27979;&#21644;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#37117;&#21462;&#24471;&#20102;&#33391;&#22909;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#39044;&#22788;&#29702;&#26159;&#20219;&#20309;&#26426;&#22120;&#23398;&#20064;&#27969;&#31243;&#20013;&#33267;&#20851;&#37325;&#35201;&#30340;&#19968;&#37096;&#20998;&#65292;&#23427;&#23545;&#24615;&#33021;&#21644;&#35757;&#32451;&#25928;&#29575;&#37117;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#24403;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#26102;&#24207;&#39044;&#27979;&#21644;&#20998;&#31867;&#26102;&#65292;&#36825;&#19968;&#28857;&#23588;&#20026;&#26126;&#26174;&#65306;&#30495;&#23454;&#19990;&#30028;&#30340;&#26102;&#24207;&#25968;&#25454;&#36890;&#24120;&#34920;&#29616;&#20986;&#22810;&#26679;&#24615;&#12289;&#20559;&#26012;&#21644;&#24322;&#24120;&#20540;&#31561;&#19981;&#35268;&#21017;&#29305;&#24449;&#65292;&#22914;&#26524;&#19981;&#20805;&#20998;&#22788;&#29702;&#36825;&#20123;&#29305;&#24449;&#65292;&#27169;&#22411;&#24615;&#33021;&#24456;&#24555;&#20250;&#19979;&#38477;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;EDAIN&#65288;&#25193;&#23637;&#28145;&#24230;&#33258;&#36866;&#24212;&#36755;&#20837;&#35268;&#33539;&#21270;&#65289;&#23618;&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#33258;&#36866;&#24212;&#31070;&#32463;&#23618;&#65292;&#23427;&#33021;&#22815;&#20197;&#31471;&#21040;&#31471;&#30340;&#26041;&#24335;&#23398;&#20064;&#22914;&#20309;&#36866;&#24403;&#22320;&#35268;&#33539;&#21270;&#19981;&#35268;&#21017;&#30340;&#26102;&#24207;&#25968;&#25454;&#65292;&#32780;&#19981;&#26159;&#20351;&#29992;&#22266;&#23450;&#30340;&#35268;&#33539;&#21270;&#26041;&#26696;&#12290;&#36825;&#36890;&#36807;&#20351;&#29992;&#21453;&#21521;&#20256;&#25773;&#31639;&#27861;&#65292;&#21516;&#26102;&#20248;&#21270;&#20854;&#26410;&#30693;&#21442;&#25968;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26469;&#23454;&#29616;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#19968;&#26041;&#27861;&#22312;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#12289;&#20449;&#29992;&#36829;&#32422;&#39044;&#27979;&#25968;&#25454;&#38598;&#21644;&#22823;&#35268;&#27169;&#38480;&#20215;&#21333;&#31807;&#22522;&#20934;&#25968;&#25454;&#38598;&#26102;&#37117;&#21462;&#24471;&#20102;&#33391;&#22909;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data preprocessing is a crucial part of any machine learning pipeline, and it can have a significant impact on both performance and training efficiency. This is especially evident when using deep neural networks for time series prediction and classification: real-world time series data often exhibit irregularities such as multi-modality, skewness and outliers, and the model performance can degrade rapidly if these characteristics are not adequately addressed. In this work, we propose the EDAIN (Extended Deep Adaptive Input Normalization) layer, a novel adaptive neural layer that learns how to appropriately normalize irregular time series data for a given task in an end-to-end fashion, instead of using a fixed normalization scheme. This is achieved by optimizing its unknown parameters simultaneously with the deep neural network using back-propagation. Our experiments, conducted using synthetic data, a credit default prediction dataset, and a large-scale limit order book benchmark datase
&lt;/p&gt;</description></item><item><title>&#38024;&#23545;&#39640;&#32500;&#24230;&#20302;&#26679;&#26412;(HDLSS)&#20998;&#31867;&#38382;&#39064;&#65292;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#26862;&#26519;&#30456;&#20284;&#24230;&#30340;&#23398;&#20064;&#39044;&#35745;&#31639;SVM&#26680;&#26041;&#27861;(RFSVM)&#65292;&#36890;&#36807;&#22312;40&#20010;&#20844;&#20849;HDLSS&#20998;&#31867;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;HDLSS&#38382;&#39064;&#19978;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#24182;&#19988;&#20445;&#25345;&#20102;&#38750;&#24120;&#19968;&#33268;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.14710</link><description>&lt;p&gt;
&#39640;&#32500;&#24230;&#20302;&#26679;&#26412;&#20998;&#31867;&#30340;&#38543;&#26426;&#26862;&#26519;&#24046;&#24322;&#24615;
&lt;/p&gt;
&lt;p&gt;
Random Forest Dissimilarity for High-Dimension Low Sample Size Classification. (arXiv:2310.14710v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14710
&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#39640;&#32500;&#24230;&#20302;&#26679;&#26412;(HDLSS)&#20998;&#31867;&#38382;&#39064;&#65292;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#26862;&#26519;&#30456;&#20284;&#24230;&#30340;&#23398;&#20064;&#39044;&#35745;&#31639;SVM&#26680;&#26041;&#27861;(RFSVM)&#65292;&#36890;&#36807;&#22312;40&#20010;&#20844;&#20849;HDLSS&#20998;&#31867;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;HDLSS&#38382;&#39064;&#19978;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#24182;&#19988;&#20445;&#25345;&#20102;&#38750;&#24120;&#19968;&#33268;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#24230;&#20302;&#26679;&#26412;(HDLSS)&#38382;&#39064;&#22312;&#26426;&#22120;&#23398;&#20064;&#30340;&#23454;&#38469;&#24212;&#29992;&#20013;&#24456;&#24120;&#35265;&#12290;&#20174;&#21307;&#23398;&#24433;&#20687;&#21040;&#25991;&#26412;&#22788;&#29702;&#65292;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#36890;&#24120;&#26080;&#27861;&#20174;&#36825;&#26679;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#21040;&#26368;&#20339;&#30340;&#27010;&#24565;&#12290;&#25105;&#20204;&#22312;&#20043;&#21069;&#30340;&#24037;&#20316;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24046;&#24322;&#24615;&#30340;&#22810;&#35270;&#35282;&#20998;&#31867;&#26041;&#27861;&#65292;&#21363;&#38543;&#26426;&#26862;&#26519;&#24046;&#24322;&#24615;(RFD)&#65292;&#35813;&#26041;&#27861;&#22312;&#36825;&#31867;&#38382;&#39064;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23558;&#35813;&#26041;&#27861;&#30340;&#26680;&#24515;&#21407;&#21017;&#36716;&#21270;&#20026;&#35299;&#20915;HDLSS&#20998;&#31867;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#26862;&#26519;&#30456;&#20284;&#24230;&#20316;&#20026;&#23398;&#20064;&#30340;&#39044;&#35745;&#31639;SVM&#26680;(RFSVM)&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#26679;&#30340;&#23398;&#20064;&#30456;&#20284;&#24230;&#24230;&#37327;&#22312;&#36825;&#31181;&#20998;&#31867;&#19978;&#29305;&#21035;&#36866;&#29992;&#21644;&#20934;&#30830;&#12290;&#36890;&#36807;&#23545;40&#20010;&#20844;&#20849;HDLSS&#20998;&#31867;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#23454;&#39564;&#65292;&#37197;&#21512;&#20005;&#26684;&#30340;&#32479;&#35745;&#20998;&#26512;&#65292;&#32467;&#26524;&#26174;&#31034;RFSVM&#26041;&#27861;&#22312;&#22823;&#22810;&#25968;HDLSS&#38382;&#39064;&#19978;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#24182;&#19988;&#21516;&#26102;&#38750;&#24120;&#36830;&#36143;&#12290;
&lt;/p&gt;
&lt;p&gt;
High dimension, low sample size (HDLSS) problems are numerous among real-world applications of machine learning. From medical images to text processing, traditional machine learning algorithms are usually unsuccessful in learning the best possible concept from such data. In a previous work, we proposed a dissimilarity-based approach for multi-view classification, the Random Forest Dissimilarity (RFD), that perfoms state-of-the-art results for such problems. In this work, we transpose the core principle of this approach to solving HDLSS classification problems, by using the RF similarity measure as a learned precomputed SVM kernel (RFSVM). We show that such a learned similarity measure is particularly suited and accurate for this classification context. Experiments conducted on 40 public HDLSS classification datasets, supported by rigorous statistical analyses, show that the RFSVM method outperforms existing methods for the majority of HDLSS problems and remains at the same time very co
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#24320;&#25918;&#33719;&#21462;&#30340;&#21355;&#26143;&#22270;&#20687;&#21644;GEDI&#28608;&#20809;&#38647;&#36798;&#25968;&#25454;&#65292;&#37319;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#22312;&#27861;&#22269;&#30340;&#22823;&#33539;&#22260;&#20869;&#20272;&#35745;&#20102;&#26862;&#26519;&#39640;&#24230;&#21644;&#29983;&#29289;&#37327;&#65292;&#24182;&#29983;&#25104;&#20102;2020&#24180;&#30340;&#39640;&#20998;&#36776;&#29575;&#22320;&#22270;&#12290;</title><link>http://arxiv.org/abs/2310.14662</link><description>&lt;p&gt;
&#20351;&#29992;&#24320;&#25918;&#33719;&#21462;&#30340;&#22810;&#20256;&#24863;&#22120;&#21355;&#26143;&#22270;&#20687;&#21644;GEDI&#28608;&#20809;&#38647;&#36798;&#25968;&#25454;&#20272;&#35745;&#26862;&#26519;&#39640;&#24230;&#21644;&#29983;&#29289;&#37327;&#65306;&#27861;&#22269;&#22478;&#24066;&#22320;&#21306;&#30340;&#39640;&#20998;&#36776;&#29575;&#22320;&#22270;
&lt;/p&gt;
&lt;p&gt;
Estimation of forest height and biomass from open-access multi-sensor satellite imagery and GEDI Lidar data: high-resolution maps of metropolitan France. (arXiv:2310.14662v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14662
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#24320;&#25918;&#33719;&#21462;&#30340;&#21355;&#26143;&#22270;&#20687;&#21644;GEDI&#28608;&#20809;&#38647;&#36798;&#25968;&#25454;&#65292;&#37319;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#22312;&#27861;&#22269;&#30340;&#22823;&#33539;&#22260;&#20869;&#20272;&#35745;&#20102;&#26862;&#26519;&#39640;&#24230;&#21644;&#29983;&#29289;&#37327;&#65292;&#24182;&#29983;&#25104;&#20102;2020&#24180;&#30340;&#39640;&#20998;&#36776;&#29575;&#22320;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26144;&#23556;&#26862;&#26519;&#36164;&#28304;&#21644;&#30899;&#20648;&#37327;&#23545;&#20110;&#25913;&#21892;&#26862;&#26519;&#31649;&#29702;&#24182;&#23454;&#29616;&#30899;&#20648;&#23384;&#21644;&#29615;&#22659;&#20445;&#25252;&#30446;&#26631;&#38750;&#24120;&#37325;&#35201;&#12290;&#33322;&#22825;&#36965;&#24863;&#26041;&#27861;&#22312;&#25552;&#20379;&#22823;&#33539;&#22260;&#39640;&#31354;&#38388;&#20998;&#36776;&#29575;&#30340;&#37325;&#22797;&#35266;&#27979;&#26041;&#38754;&#20855;&#26377;&#37325;&#35201;&#28508;&#21147;&#26469;&#25903;&#25345;&#26862;&#26519;&#39640;&#24230;&#30417;&#27979;&#12290;&#26412;&#30740;&#31350;&#21033;&#29992;&#20808;&#21069;&#24320;&#21457;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#22312;&#27861;&#22269;&#22269;&#23478;&#33539;&#22260;&#31561;&#26356;&#22823;&#27604;&#20363;&#19978;&#25512;&#24191;&#20102;&#35813;&#26041;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;GEDI&#28608;&#20809;&#38647;&#36798;&#20219;&#21153;&#20316;&#20026;&#21442;&#32771;&#39640;&#24230;&#25968;&#25454;&#65292;&#21033;&#29992;Sentinel-1&#12289;Sentinel-2&#21644;ALOS-2 PALSA-2&#21355;&#26143;&#22270;&#20687;&#20272;&#35745;&#26862;&#26519;&#39640;&#24230;&#24182;&#20135;&#29983;2020&#24180;&#30340;&#27861;&#22269;&#22320;&#22270;&#12290;&#28982;&#21518;&#65292;&#21033;&#29992;&#36890;&#29992;&#26041;&#31243;&#23558;&#39640;&#24230;&#22270;&#36716;&#21270;&#20026;&#20307;&#31215;&#21644;&#22320;&#19978;&#29983;&#29289;&#37327;&#65288;AGB&#65289;&#12290;&#21033;&#29992;ALS&#25968;&#25454;&#30340;&#26412;&#22320;&#22320;&#22270;&#39564;&#35777;&#20102;&#39640;&#24230;&#22270;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mapping forest resources and carbon is important for improving forest management and meeting the objectives of storing carbon and preserving the environment. Spaceborne remote sensing approaches have considerable potential to support forest height monitoring by providing repeated observations at high spatial resolution over large areas. This study uses a machine learning approach that was previously developed to produce local maps of forest parameters (basal area, height, diameter, etc.). The aim of this paper is to present the extension of the approach to much larger scales such as the French national coverage. We used the GEDI Lidar mission as reference height data, and the satellite images from Sentinel-1, Sentinel-2 and ALOS-2 PALSA-2 to estimate forest height and produce a map of France for the year 2020. The height map is then derived into volume and aboveground biomass (AGB) using allometric equations. The validation of the height map with local maps from ALS data shows an accur
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#32431;&#24046;&#20998;&#38544;&#31169;&#21644;&#39640;&#26031;&#24046;&#20998;&#38544;&#31169;&#30340;&#21487;&#35745;&#31639;MCMC&#31169;&#26377;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#36817;&#20284;&#37319;&#26679;&#25200;&#21160;&#31639;&#27861;&#65292;&#32467;&#21512;Metropolis-Hastings&#31639;&#27861;&#21644;&#23616;&#37096;&#21270;&#27493;&#39588;&#65292;&#23454;&#29616;&#20102;&#23545;&#38544;&#31169;&#30340;&#20445;&#25252;&#24182;&#33719;&#24471;&#20102;&#36739;&#22909;&#30340;&#25910;&#25947;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.14661</link><description>&lt;p&gt;
&#22522;&#20110;&#32431;&#24046;&#20998;&#38544;&#31169;&#21644;&#39640;&#26031;&#24046;&#20998;&#38544;&#31169;&#30340;&#21487;&#35745;&#31639;MCMC&#31169;&#26377;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tractable MCMC for Private Learning with Pure and Gaussian Differential Privacy. (arXiv:2310.14661v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14661
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#32431;&#24046;&#20998;&#38544;&#31169;&#21644;&#39640;&#26031;&#24046;&#20998;&#38544;&#31169;&#30340;&#21487;&#35745;&#31639;MCMC&#31169;&#26377;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#36817;&#20284;&#37319;&#26679;&#25200;&#21160;&#31639;&#27861;&#65292;&#32467;&#21512;Metropolis-Hastings&#31639;&#27861;&#21644;&#23616;&#37096;&#21270;&#27493;&#39588;&#65292;&#23454;&#29616;&#20102;&#23545;&#38544;&#31169;&#30340;&#20445;&#25252;&#24182;&#33719;&#24471;&#20102;&#36739;&#22909;&#30340;&#25910;&#25947;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21518;&#39564;&#37319;&#26679;&#21363;&#20174;&#21518;&#39564;&#20998;&#24067;&#20013;&#37319;&#26679;&#30340;&#25351;&#25968;&#26426;&#21046;&#65292;&#25552;&#20379;&#949;-&#32431;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#20445;&#35777;&#65292;&#24182;&#19981;&#21463;&#65288;&#949;&#65292;&#948;&#65289;-&#36817;&#20284;DP&#24341;&#20837;&#30340;&#28508;&#22312;&#26080;&#30028;&#38544;&#31169;&#27844;&#28431;&#30340;&#24433;&#21709;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#38656;&#35201;&#24212;&#29992;&#36817;&#20284;&#37319;&#26679;&#26041;&#27861;&#65292;&#22914;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#65288;MCMC&#65289;&#65292;&#20174;&#32780;&#37325;&#26032;&#24341;&#20837;&#20102;&#23545;&#38544;&#31169;&#20445;&#35777;&#30340;&#948;-&#36817;&#20284;&#35823;&#24046;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36817;&#20284;&#37319;&#26679;&#25200;&#21160;&#65288;&#21363;ASAP&#65289;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#19982;&#28385;&#36275;&#32431;DP&#25110;&#32431;&#39640;&#26031;DP&#65288;&#21363;&#948;=0&#65289;&#30340;&#21442;&#32771;&#20998;&#24067;&#26377;&#30028;Wasserstein&#26080;&#31351;&#36317;&#31163;&#30340;MCMC&#26679;&#26412;&#21152;&#22122;&#22768;&#12290;&#28982;&#21518;&#21033;&#29992;Metropolis-Hastings&#31639;&#27861;&#29983;&#25104;&#26679;&#26412;&#24182;&#35777;&#26126;&#31639;&#27861;&#22312;W$_\infty$&#36317;&#31163;&#19978;&#25910;&#25947;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#23558;&#25105;&#20204;&#30340;&#26032;&#25216;&#26415;&#19982;&#32454;&#33268;&#30340;&#23616;&#37096;&#21270;&#27493;&#39588;&#30456;&#32467;&#21512;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#31532;&#19968;&#20010;&#21487;&#35745;&#31639;MCMC&#31169;&#26377;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Posterior sampling, i.e., exponential mechanism to sample from the posterior distribution, provides $\varepsilon$-pure differential privacy (DP) guarantees and does not suffer from potentially unbounded privacy breach introduced by $(\varepsilon,\delta)$-approximate DP. In practice, however, one needs to apply approximate sampling methods such as Markov chain Monte Carlo (MCMC), thus re-introducing the unappealing $\delta$-approximation error into the privacy guarantees. To bridge this gap, we propose the Approximate SAample Perturbation (abbr. ASAP) algorithm which perturbs an MCMC sample with noise proportional to its Wasserstein-infinity ($W_\infty$) distance from a reference distribution that satisfies pure DP or pure Gaussian DP (i.e., $\delta=0$). We then leverage a Metropolis-Hastings algorithm to generate the sample and prove that the algorithm converges in W$_\infty$ distance. We show that by combining our new techniques with a careful localization step, we obtain the first ne
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;CAD-DA&#26041;&#27861;&#65292;&#21487;&#22312;&#39046;&#22495;&#36866;&#24212;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#21487;&#25511;&#24322;&#24120;&#26816;&#27979;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#21033;&#29992;&#26465;&#20214;&#36873;&#25321;&#24615;&#25512;&#26029;&#26469;&#22788;&#29702;&#39046;&#22495;&#36866;&#24212;&#30340;&#24433;&#21709;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2310.14608</link><description>&lt;p&gt;
CAD-DA&#65306;&#32479;&#35745;&#25512;&#26029;&#19979;&#39046;&#22495;&#36866;&#24212;&#21518;&#21487;&#25511;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
CAD-DA: Controllable Anomaly Detection after Domain Adaptation by Statistical Inference. (arXiv:2310.14608v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14608
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;CAD-DA&#26041;&#27861;&#65292;&#21487;&#22312;&#39046;&#22495;&#36866;&#24212;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#21487;&#25511;&#24322;&#24120;&#26816;&#27979;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#21033;&#29992;&#26465;&#20214;&#36873;&#25321;&#24615;&#25512;&#26029;&#26469;&#22788;&#29702;&#39046;&#22495;&#36866;&#24212;&#30340;&#24433;&#21709;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#32479;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#39046;&#22495;&#36866;&#24212;&#19979;&#27979;&#35797;&#24322;&#24120;&#26816;&#27979;&#65288;AD&#65289;&#30340;&#32467;&#26524;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;CAD-DA-&#21487;&#25511;&#24322;&#24120;&#26816;&#27979;&#19979;&#30340;&#39046;&#22495;&#36866;&#24212;&#12290;CAD-DA&#30340;&#20248;&#21183;&#22312;&#20110;&#33021;&#22815;&#25511;&#21046;&#22312;&#39044;&#20808;&#25351;&#23450;&#30340;&#27700;&#24179;$\alpha$&#65288;&#20363;&#22914;0.05&#65289;&#19979;&#35823;&#35782;&#21035;&#24322;&#24120;&#30340;&#27010;&#29575;&#12290;&#22312;&#36825;&#20010;&#39046;&#22495;&#36866;&#24212;&#30340;&#35774;&#23450;&#20013;&#65292;&#25361;&#25112;&#22312;&#20110;&#24517;&#39035;&#32771;&#34385;&#39046;&#22495;&#36866;&#24212;&#30340;&#24433;&#21709;&#65292;&#20197;&#30830;&#20445;&#25512;&#26029;&#32467;&#26524;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#35299;&#20915;&#26041;&#26696;&#21033;&#29992;&#26465;&#20214;&#36873;&#25321;&#24615;&#25512;&#26029;&#30340;&#27010;&#24565;&#26469;&#22788;&#29702;&#39046;&#22495;&#36866;&#24212;&#30340;&#24433;&#21709;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#33021;&#22815;&#22312;&#39046;&#22495;&#36866;&#24212;&#30340;&#32972;&#26223;&#19979;&#36827;&#34892;&#26377;&#25928;&#32479;&#35745;&#25512;&#26029;&#30340;&#24037;&#20316;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;CAD-DA&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel statistical method for testing the results of anomaly detection (AD) under domain adaptation (DA), which we call CAD-DA -controllable AD under DA. The distinct advantage of the CAD-DA lies in its ability to control the probability of misidentifying anomalies under a pre-specified level $\alpha$ (e.g., 0.05). The challenge within this DA setting is the necessity to account for the influence of DA to ensure the validity of the inference results. Our solution to this challenge leverages the concept of conditional Selective Inference to handle the impact of DA. To our knowledge, this is the first work capable of conducting a valid statistical inference within the context of DA. We evaluate the performance of the CAD-DA method on both synthetic and real-world datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19977;&#35282;&#31215;&#20998;&#20613;&#37324;&#21494;&#29305;&#24449;&#65288;TQFF&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#29305;&#23450;&#20110;&#25152;&#38656;&#20613;&#37324;&#21494;&#21464;&#25442;&#30340;&#26032;&#39062;&#38750;&#39640;&#26031;&#31215;&#20998;&#35268;&#21017;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#20613;&#37324;&#21494;&#29305;&#24449;&#36924;&#36817;&#26041;&#27861;&#30340;&#24615;&#33021;&#38480;&#21046;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#30456;&#23545;&#20110;&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;&#65288;RFF&#65289;&#21644;&#39640;&#26031;&#31215;&#20998;&#20613;&#37324;&#21494;&#29305;&#24449;&#65288;QFF&#65289;&#30340;&#25913;&#36827;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.14544</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#20013;&#30340;&#19977;&#35282;&#31215;&#20998;&#20613;&#37324;&#21494;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Trigonometric Quadrature Fourier Features for Scalable Gaussian Process Regression. (arXiv:2310.14544v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14544
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19977;&#35282;&#31215;&#20998;&#20613;&#37324;&#21494;&#29305;&#24449;&#65288;TQFF&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#29305;&#23450;&#20110;&#25152;&#38656;&#20613;&#37324;&#21494;&#21464;&#25442;&#30340;&#26032;&#39062;&#38750;&#39640;&#26031;&#31215;&#20998;&#35268;&#21017;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#20613;&#37324;&#21494;&#29305;&#24449;&#36924;&#36817;&#26041;&#27861;&#30340;&#24615;&#33021;&#38480;&#21046;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#30456;&#23545;&#20110;&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;&#65288;RFF&#65289;&#21644;&#39640;&#26031;&#31215;&#20998;&#20613;&#37324;&#21494;&#29305;&#24449;&#65288;QFF&#65289;&#30340;&#25913;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20613;&#37324;&#21494;&#29305;&#24449;&#36924;&#36817;&#24050;&#32463;&#25104;&#21151;&#24212;&#29992;&#20110;&#21487;&#25193;&#23637;&#30340;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#22238;&#24402;&#20013;&#12290;&#23588;&#20854;&#26159;&#22522;&#20110;&#39640;&#26031;&#31215;&#20998;&#35268;&#21017;&#30340;&#31215;&#20998;&#20613;&#37324;&#21494;&#29305;&#24449;&#65288;QFF&#65289;&#36817;&#24180;&#26469;&#22240;&#20854;&#25913;&#36827;&#30340;&#36817;&#20284;&#31934;&#24230;&#21644;&#26356;&#22909;&#30340;&#26657;&#20934;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#32780;&#21463;&#21040;&#20851;&#27880;&#65292;&#30456;&#36739;&#20110;&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;&#65288;RFF&#65289;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;QFF&#30340;&#19968;&#20010;&#20851;&#38190;&#38480;&#21046;&#26159;&#20854;&#24615;&#33021;&#21463;&#21040;&#19982;&#39640;&#39057;&#25391;&#33633;&#30340;&#31215;&#20998;&#30456;&#20851;&#30340;&#24050;&#30693;&#30149;&#24577;&#30340;&#24433;&#21709;&#65292;&#23548;&#33268;&#36817;&#20284;&#31934;&#24230;&#26377;&#38480;&#30340;&#29305;&#24449;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#31181;&#26032;&#30340;&#19977;&#35282;&#31215;&#20998;&#20613;&#37324;&#21494;&#29305;&#24449;&#65288;TQFF&#65289;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#20851;&#38190;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#20102;&#19968;&#31181;&#29305;&#21035;&#36866;&#29992;&#20110;&#25152;&#38656;&#20613;&#37324;&#21494;&#21464;&#25442;&#30340;&#26032;&#39062;&#38750;&#39640;&#26031;&#31215;&#20998;&#35268;&#21017;&#12290;&#25105;&#20204;&#23548;&#20986;&#20102;TQFF&#30340;&#31934;&#30830;&#31215;&#20998;&#35268;&#21017;&#65292;&#24182;&#32473;&#20986;&#20102;&#23545;&#24212;&#29305;&#24449;&#26144;&#23556;&#30340;&#26680;&#36924;&#36817;&#35823;&#24046;&#30028;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#23545;&#20110;RFF&#21644;&#39640;&#26031;QFF&#30340;&#25913;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fourier feature approximations have been successfully applied in the literature for scalable Gaussian Process (GP) regression. In particular, Quadrature Fourier Features (QFF) derived from Gaussian quadrature rules have gained popularity in recent years due to their improved approximation accuracy and better calibrated uncertainty estimates compared to Random Fourier Feature (RFF) methods. However, a key limitation of QFF is that its performance can suffer from well-known pathologies related to highly oscillatory quadrature, resulting in mediocre approximation with limited features. We address this critical issue via a new Trigonometric Quadrature Fourier Feature (TQFF) method, which uses a novel non-Gaussian quadrature rule specifically tailored for the desired Fourier transform. We derive an exact quadrature rule for TQFF, along with kernel approximation error bounds for the resulting feature map. We then demonstrate the improved performance of our method over RFF and Gaussian QFF in
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38024;&#23545;AI&#20998;&#31867;&#22120;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#24230;&#37327;&#30340;&#23384;&#22312;&#24615;&#12289;&#21807;&#19968;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#65292;&#25552;&#20986;&#20102;&#21487;&#20197;&#39564;&#35777;&#30340;&#25968;&#23398;&#26465;&#20214;&#65292;&#24182;&#22312;&#21512;&#25104;&#22522;&#20934;&#27979;&#35797;&#21644;&#29983;&#29289;&#21307;&#23398;&#24212;&#29992;&#20013;&#36827;&#34892;&#20102;&#23454;&#38469;&#35745;&#31639;&#21644;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2310.14421</link><description>&lt;p&gt;
&#23545;AI&#20998;&#31867;&#22120;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#24230;&#37327;&#30340;&#23384;&#22312;&#24615;&#65292;&#21807;&#19968;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On existence, uniqueness and scalability of adversarial robustness measures for AI classifiers. (arXiv:2310.14421v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14421
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38024;&#23545;AI&#20998;&#31867;&#22120;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#24230;&#37327;&#30340;&#23384;&#22312;&#24615;&#12289;&#21807;&#19968;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#65292;&#25552;&#20986;&#20102;&#21487;&#20197;&#39564;&#35777;&#30340;&#25968;&#23398;&#26465;&#20214;&#65292;&#24182;&#22312;&#21512;&#25104;&#22522;&#20934;&#27979;&#35797;&#21644;&#29983;&#29289;&#21307;&#23398;&#24212;&#29992;&#20013;&#36827;&#34892;&#20102;&#23454;&#38469;&#35745;&#31639;&#21644;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#24182;&#35777;&#26126;&#20102;&#38024;&#23545;&#65288;&#23616;&#37096;&#65289;&#21807;&#19968;&#21487;&#36870;&#20998;&#31867;&#22120;&#12289;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;GLM&#65289;&#21644;&#29109;AI&#65288;EAI&#65289;&#20855;&#26377;&#26368;&#23567;&#23545;&#25239;&#36335;&#24452;&#65288;MAP&#65289;&#21644;&#26368;&#23567;&#23545;&#25239;&#36317;&#31163;&#65288;MAD&#65289;&#30340;&#23384;&#22312;&#24615;&#12289;&#21807;&#19968;&#24615;&#21644;&#26126;&#30830;&#30340;&#20998;&#26512;&#35745;&#31639;&#30340;&#31616;&#21333;&#21487;&#39564;&#35777;&#30340;&#25968;&#23398;&#26465;&#20214;&#12290;&#22312;&#24120;&#35265;&#30340;&#21512;&#25104;&#22522;&#20934;&#27979;&#35797;&#25968;&#25454;&#38598;&#19978;&#65292;&#38024;&#23545;&#31070;&#32463;&#32593;&#32476;&#12289;&#25552;&#21319;&#38543;&#26426;&#26862;&#26519;&#12289;GLM&#21644;EAI&#31561;&#21508;&#31867;AI&#24037;&#20855;&#36827;&#34892;MAP&#21644;MAD&#30340;&#23454;&#38469;&#35745;&#31639;&#12289;&#27604;&#36739;&#21644;&#35299;&#37322;&#65292;&#21253;&#25324;&#21452;&#21367;&#29366;&#34746;&#26059;&#32447;&#21450;&#20854;&#25193;&#23637;&#20197;&#21450;&#20004;&#20010;&#29983;&#29289;&#21307;&#23398;&#25968;&#25454;&#38382;&#39064;&#65288;&#29992;&#20110;&#20581;&#24247;&#20445;&#38505;&#29702;&#36180;&#39044;&#27979;&#21644;&#24515;&#33039;&#30149;&#21457;&#20316;&#33268;&#27515;&#29575;&#20998;&#31867;&#65289;&#12290;&#22312;&#29983;&#29289;&#21307;&#23398;&#24212;&#29992;&#20013;&#65292;&#23637;&#31034;&#20102;MAP&#22914;&#20309;&#22312;&#39044;&#23450;&#20041;&#30340;&#21487;&#35775;&#38382;&#25511;&#21046;&#21464;&#37327;&#23376;&#38598;&#20013;&#25552;&#20379;&#21807;&#19968;&#30340;&#26368;&#23567;&#24739;&#32773;&#29305;&#23450;&#39118;&#38505;&#32531;&#35299;&#24178;&#39044;&#25514;&#26045;&#12290;
&lt;/p&gt;
&lt;p&gt;
Simply-verifiable mathematical conditions for existence, uniqueness and explicit analytical computation of minimal adversarial paths (MAP) and minimal adversarial distances (MAD) for (locally) uniquely-invertible classifiers, for generalized linear models (GLM), and for entropic AI (EAI) are formulated and proven. Practical computation of MAP and MAD, their comparison and interpretations for various classes of AI tools (for neuronal networks, boosted random forests, GLM and EAI) are demonstrated on the common synthetic benchmarks: on a double Swiss roll spiral and its extensions, as well as on the two biomedical data problems (for the health insurance claim predictions, and for the heart attack lethality classification). On biomedical applications it is demonstrated how MAP provides unique minimal patient-specific risk-mitigating interventions in the predefined subsets of accessible control variables.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#25955;&#30340;&#23433;&#20840;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27809;&#26377;&#20013;&#22830;&#25511;&#21046;&#22120;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#37051;&#23621;&#36890;&#20449;&#26469;&#26368;&#22823;&#21270;&#32047;&#31215;&#22870;&#21169;&#24635;&#21644;&#65292;&#24182;&#21516;&#26102;&#28385;&#36275;&#27599;&#20010;&#26234;&#33021;&#20307;&#30340;&#23433;&#20840;&#32422;&#26463;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2310.14348</link><description>&lt;p&gt;
DePAint&#65306;&#32771;&#34385;&#23792;&#20540;&#21644;&#24179;&#22343;&#38480;&#21046;&#30340;&#20998;&#25955;&#23433;&#20840;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
DePAint: A Decentralized Safe Multi-Agent Reinforcement Learning Algorithm considering Peak and Average Constraints. (arXiv:2310.14348v1 [cs.MA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14348
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#25955;&#30340;&#23433;&#20840;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27809;&#26377;&#20013;&#22830;&#25511;&#21046;&#22120;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#37051;&#23621;&#36890;&#20449;&#26469;&#26368;&#22823;&#21270;&#32047;&#31215;&#22870;&#21169;&#24635;&#21644;&#65292;&#24182;&#21516;&#26102;&#28385;&#36275;&#27599;&#20010;&#26234;&#33021;&#20307;&#30340;&#23433;&#20840;&#32422;&#26463;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23433;&#20840;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#65292;&#23613;&#31649;&#22312;&#26080;&#20154;&#26426;&#25237;&#36882;&#21644;&#36710;&#36742;&#33258;&#21160;&#21270;&#31561;&#21508;&#20010;&#39046;&#22495;&#20855;&#26377;&#28508;&#22312;&#24212;&#29992;&#65292;&#20294;&#20173;&#28982;&#30456;&#23545;&#26410;&#34987;&#25506;&#32034;&#12290;&#22312;&#35757;&#32451;&#26234;&#33021;&#20307;&#23398;&#20064;&#26368;&#20248;&#31574;&#30053;&#20197;&#26368;&#22823;&#21270;&#22870;&#21169;&#30340;&#21516;&#26102;&#32771;&#34385;&#29305;&#23450;&#38480;&#21046;&#65292;&#29305;&#21035;&#26159;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#26080;&#27861;&#26377;&#20013;&#22830;&#25511;&#21046;&#22120;&#21327;&#35843;&#26234;&#33021;&#20307;&#30340;&#22330;&#26223;&#20013;&#65292;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#38024;&#23545;&#20998;&#25955;&#29615;&#22659;&#19979;&#30340;&#22810;&#26234;&#33021;&#20307;&#31574;&#30053;&#20248;&#21270;&#38382;&#39064;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#20854;&#20013;&#26234;&#33021;&#20307;&#36890;&#36807;&#19982;&#37051;&#23621;&#36890;&#20449;&#20197;&#26368;&#22823;&#21270;&#20854;&#32047;&#31215;&#22870;&#21169;&#24635;&#21644;&#30340;&#21516;&#26102;&#28385;&#36275;&#27599;&#20010;&#26234;&#33021;&#20307;&#30340;&#23433;&#20840;&#32422;&#26463;&#12290;&#25105;&#20204;&#21516;&#26102;&#32771;&#34385;&#20102;&#23792;&#20540;&#21644;&#24179;&#22343;&#38480;&#21046;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#27809;&#26377;&#20013;&#22830;&#25511;&#21046;&#22120;&#21327;&#35843;&#26234;&#33021;&#20307;&#65292;&#22870;&#21169;&#21644;&#32422;&#26463;&#21482;&#22312;&#27599;&#20010;&#26234;&#33021;&#20307;&#26412;&#22320;/&#31169;&#26377;&#21487;&#30693;&#12290;&#25105;&#20204;&#23558;&#38382;&#39064;&#24418;&#24335;&#21270;&#20026;&#20998;&#25955;&#32422;&#26463;&#30340;&#22810;&#26234;&#33021;&#20307;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The field of safe multi-agent reinforcement learning, despite its potential applications in various domains such as drone delivery and vehicle automation, remains relatively unexplored. Training agents to learn optimal policies that maximize rewards while considering specific constraints can be challenging, particularly in scenarios where having a central controller to coordinate the agents during the training process is not feasible. In this paper, we address the problem of multi-agent policy optimization in a decentralized setting, where agents communicate with their neighbors to maximize the sum of their cumulative rewards while also satisfying each agent's safety constraints. We consider both peak and average constraints. In this scenario, there is no central controller coordinating the agents and both the rewards and constraints are only known to each agent locally/privately. We formulate the problem as a decentralized constrained multi-agent Markov Decision Problem and propose a 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26102;&#38388;&#24046;&#24322;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#31574;&#30053;&#35780;&#20272;&#65292;&#22312;&#22312;&#32447;&#25512;&#26029;&#20013;&#33719;&#24471;&#20102;&#25509;&#36817;&#26368;&#20248;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#24212;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2310.14286</link><description>&lt;p&gt;
&#26102;&#38388;&#24046;&#24322;&#23398;&#20064;&#30340;&#26377;&#38480;&#26679;&#26412;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Finite-Sample Analysis of the Temporal Difference Learning. (arXiv:2310.14286v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14286
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26102;&#38388;&#24046;&#24322;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#31574;&#30053;&#35780;&#20272;&#65292;&#22312;&#22312;&#32447;&#25512;&#26029;&#20013;&#33719;&#24471;&#20102;&#25509;&#36817;&#26368;&#20248;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#24212;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#22312;&#32447;&#31574;&#30053;&#35780;&#20272;&#20013;&#20351;&#29992;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#26102;&#38388;&#24046;&#24322;(TD)&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#36890;&#29992;&#19988;&#19982;&#23454;&#20363;&#26080;&#20851;&#30340;&#27493;&#38271;&#21644;Polyak-Ruppert&#23614;&#24179;&#22343;&#65292;&#21487;&#20197;&#33719;&#24471;&#25509;&#36817;&#26368;&#20248;&#30340;&#26041;&#24046;&#21644;&#20559;&#24046;&#39033;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#30456;&#24212;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#25216;&#24039;&#22522;&#20110;&#32447;&#24615;&#38543;&#26426;&#36924;&#36817;&#30340;&#31934;&#30830;&#35823;&#24046;&#30028;&#38480;&#20197;&#21450;TD&#31867;&#22411;&#36882;&#24402;&#20135;&#29983;&#30340;&#38543;&#26426;&#30697;&#38453;&#20056;&#31215;&#30340;&#26032;&#31283;&#23450;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we consider the problem of obtaining sharp bounds for the performance of temporal difference (TD) methods with linear functional approximation for policy evaluation in discounted Markov Decision Processes. We show that a simple algorithm with a universal and instance-independent step size together with Polyak-Ruppert tail averaging is sufficient to obtain near-optimal variance and bias terms. We also provide the respective sample complexity bounds. Our proof technique is based on refined error bounds for linear stochastic approximation together with the novel stability result for the product of random matrices that arise from the TD-type recurrence.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#29702;&#35770;&#65292;&#29992;&#20110;&#30740;&#31350;Softmax Gating Multinomial Logistic Mixture of Experts&#27169;&#22411;&#12290;&#36890;&#36807;&#24314;&#31435;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#25581;&#31034;&#20102;softmax gating&#21644;&#19987;&#23478;&#20989;&#25968;&#20043;&#38388;&#23384;&#22312;&#30340;&#20114;&#20316;&#29992;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#21518;&#30340;softmax gating&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2310.14188</link><description>&lt;p&gt;
&#19968;&#31181;Softmax Gating Multinomial Logistic Mixture of Experts&#30340;&#36890;&#29992;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
A General Theory for Softmax Gating Multinomial Logistic Mixture of Experts. (arXiv:2310.14188v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14188
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#29702;&#35770;&#65292;&#29992;&#20110;&#30740;&#31350;Softmax Gating Multinomial Logistic Mixture of Experts&#27169;&#22411;&#12290;&#36890;&#36807;&#24314;&#31435;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#25581;&#31034;&#20102;softmax gating&#21644;&#19987;&#23478;&#20989;&#25968;&#20043;&#38388;&#23384;&#22312;&#30340;&#20114;&#20316;&#29992;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#21518;&#30340;softmax gating&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Mixture-of-experts&#65288;MoE&#65289;&#27169;&#22411;&#36890;&#36807;&#38376;&#25511;&#20989;&#25968;&#23558;&#22810;&#20010;&#23376;&#27169;&#22411;&#30340;&#33021;&#21147;&#32467;&#21512;&#36215;&#26469;&#65292;&#22312;&#35768;&#22810;&#22238;&#24402;&#21644;&#20998;&#31867;&#24212;&#29992;&#20013;&#23454;&#29616;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;&#34429;&#28982;&#20043;&#21069;&#24050;&#32463;&#23581;&#35797;&#36890;&#36807;&#39640;&#26031;MoE&#27169;&#22411;&#20013;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#26469;&#29702;&#35299;&#35813;&#27169;&#22411;&#22312;&#22238;&#24402;&#35774;&#32622;&#19979;&#30340;&#34892;&#20026;&#65292;&#20294;&#22312;&#20998;&#31867;&#38382;&#39064;&#30340;&#35774;&#32622;&#19979;&#32570;&#20047;&#30456;&#20851;&#20998;&#26512;&#12290;&#25105;&#20204;&#36890;&#36807;&#24314;&#31435;softmax gating multinomial logistic MoE&#27169;&#22411;&#30340;&#23494;&#24230;&#20272;&#35745;&#21644;&#21442;&#25968;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#24230;&#26469;&#24357;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#24403;&#37096;&#20998;&#19987;&#23478;&#21442;&#25968;&#28040;&#22833;&#26102;&#65292;&#30001;&#20110;softmax gating&#21644;&#19987;&#23478;&#20989;&#25968;&#20043;&#38388;&#23384;&#22312;&#22266;&#26377;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#20114;&#20316;&#29992;&#65292;&#36825;&#20123;&#25910;&#25947;&#36895;&#24230;&#27604;&#22810;&#39033;&#24335;&#36895;&#24230;&#26356;&#24930;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#20462;&#25913;softmax gating&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mixture-of-experts (MoE) model incorporates the power of multiple submodels via gating functions to achieve greater performance in numerous regression and classification applications. From a theoretical perspective, while there have been previous attempts to comprehend the behavior of that model under the regression settings through the convergence analysis of maximum likelihood estimation in the Gaussian MoE model, such analysis under the setting of a classification problem has remained missing in the literature. We close this gap by establishing the convergence rates of density estimation and parameter estimation in the softmax gating multinomial logistic MoE model. Notably, when part of the expert parameters vanish, these rates are shown to be slower than polynomial rates owing to an inherent interaction between the softmax gating and expert functions via partial differential equations. To address this issue, we propose using a novel class of modified softmax gating functions which 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#37325;&#26032;&#32771;&#23519;&#20102;&#20351;&#29992;LSTM&#36827;&#34892;&#23569;&#26679;&#26412;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#22312;&#31616;&#21333;&#30340;&#22238;&#24402;&#38382;&#39064;&#19978;&#34920;&#29616;&#20248;&#20110;&#27969;&#34892;&#30340;&#20803;&#23398;&#20064;&#25216;&#26415;MAML&#65292;&#20294;&#22312;&#22797;&#26434;&#30340;&#22270;&#20687;&#20998;&#31867;&#38382;&#39064;&#19978;&#19981;&#21450;&#39044;&#26399;&#12290;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;OP-LSTM&#30340;&#26032;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2310.14139</link><description>&lt;p&gt;
LSTM&#23545;&#20110;&#23569;&#26679;&#26412;&#23398;&#20064;&#26159;&#21542;&#26377;&#25928;&#65311;
&lt;/p&gt;
&lt;p&gt;
Are LSTMs Good Few-Shot Learners?. (arXiv:2310.14139v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14139
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#37325;&#26032;&#32771;&#23519;&#20102;&#20351;&#29992;LSTM&#36827;&#34892;&#23569;&#26679;&#26412;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#22312;&#31616;&#21333;&#30340;&#22238;&#24402;&#38382;&#39064;&#19978;&#34920;&#29616;&#20248;&#20110;&#27969;&#34892;&#30340;&#20803;&#23398;&#20064;&#25216;&#26415;MAML&#65292;&#20294;&#22312;&#22797;&#26434;&#30340;&#22270;&#20687;&#20998;&#31867;&#38382;&#39064;&#19978;&#19981;&#21450;&#39044;&#26399;&#12290;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;OP-LSTM&#30340;&#26032;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#38656;&#35201;&#22823;&#37327;&#25968;&#25454;&#26469;&#24456;&#22909;&#22320;&#23398;&#20064;&#26032;&#20219;&#21153;&#65292;&#36825;&#38480;&#21046;&#20102;&#20854;&#22312;&#25968;&#25454;&#36739;&#23569;&#30340;&#39046;&#22495;&#30340;&#24212;&#29992;&#12290;&#20803;&#23398;&#20064;&#36890;&#36807;&#23398;&#20064;&#22914;&#20309;&#23398;&#20064;&#26469;&#20811;&#26381;&#36825;&#19968;&#38480;&#21046;&#12290;2001&#24180;&#65292;Hochreiter&#31561;&#20154;&#23637;&#31034;&#20102;&#19968;&#20010;&#32463;&#36807;&#19981;&#21516;&#20219;&#21153;&#19978;&#30340;&#21453;&#21521;&#20256;&#25773;&#35757;&#32451;&#30340;LSTM&#33021;&#22815;&#36827;&#34892;&#20803;&#23398;&#20064;&#12290;&#23613;&#31649;&#35813;&#26041;&#27861;&#22312;&#23567;&#38382;&#39064;&#19978;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#65292;&#24182;&#19988;&#26368;&#36817;&#22312;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#19978;&#20063;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#22312;&#26377;&#30417;&#30563;&#30340;&#23569;&#26679;&#26412;&#23398;&#20064;&#35774;&#32622;&#20013;&#65292;&#35813;&#26041;&#27861;&#21364;&#21463;&#21040;&#20102;&#36739;&#23569;&#30340;&#20851;&#27880;&#12290;&#25105;&#20204;&#37325;&#26032;&#32771;&#23519;&#20102;&#36825;&#20010;&#26041;&#27861;&#65292;&#24182;&#22312;&#29616;&#20195;&#23569;&#26679;&#26412;&#23398;&#20064;&#22522;&#20934;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;LSTM&#22312;&#19968;&#20010;&#31616;&#21333;&#30340;&#23569;&#26679;&#26412;&#27491;&#24358;&#27874;&#22238;&#24402;&#22522;&#20934;&#19978;&#34920;&#29616;&#20248;&#20110;&#27969;&#34892;&#30340;&#20803;&#23398;&#20064;&#25216;&#26415;MAML&#65292;&#20294;&#22312;&#26356;&#22797;&#26434;&#30340;&#23569;&#26679;&#26412;&#22270;&#20687;&#20998;&#31867;&#22522;&#20934;&#19978;&#19981;&#21450;&#39044;&#26399;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#20004;&#20010;&#28508;&#22312;&#21407;&#22240;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Outer Product LSTM (OP-LSTM)&#30340;&#26032;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#26174;&#31034;&#20986;&#26174;&#33879;&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning requires large amounts of data to learn new tasks well, limiting its applicability to domains where such data is available. Meta-learning overcomes this limitation by learning how to learn. In 2001, Hochreiter et al. showed that an LSTM trained with backpropagation across different tasks is capable of meta-learning. Despite promising results of this approach on small problems, and more recently, also on reinforcement learning problems, the approach has received little attention in the supervised few-shot learning setting. We revisit this approach and test it on modern few-shot learning benchmarks. We find that LSTM, surprisingly, outperform the popular meta-learning technique MAML on a simple few-shot sine wave regression benchmark, but that LSTM, expectedly, fall short on more complex few-shot image classification benchmarks. We identify two potential causes and propose a new method called Outer Product LSTM (OP-LSTM) that resolves these issues and displays substantial p
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#26368;&#20339;&#25209;&#22788;&#29702;&#27494;&#22120;&#35782;&#21035;&#38382;&#39064;&#65292;&#22312;&#28176;&#36817;&#21644;&#38750;&#28176;&#36817;&#35774;&#32622;&#20013;&#25552;&#20986;&#20102;Tri-BBAI&#21644;Opt-BBAI&#31639;&#27861;&#65292;&#20998;&#21035;&#23454;&#29616;&#20102;&#26368;&#20248;&#21644;&#20960;&#20046;&#26368;&#20248;&#30340;&#26679;&#26412;&#21644;&#25209;&#22788;&#29702;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.14129</link><description>&lt;p&gt;
&#26368;&#20339;&#27494;&#22120;&#35782;&#21035;&#30340;&#26368;&#20339;&#25209;&#22788;&#29702;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Optimal Batched Best Arm Identification. (arXiv:2310.14129v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14129
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#26368;&#20339;&#25209;&#22788;&#29702;&#27494;&#22120;&#35782;&#21035;&#38382;&#39064;&#65292;&#22312;&#28176;&#36817;&#21644;&#38750;&#28176;&#36817;&#35774;&#32622;&#20013;&#25552;&#20986;&#20102;Tri-BBAI&#21644;Opt-BBAI&#31639;&#27861;&#65292;&#20998;&#21035;&#23454;&#29616;&#20102;&#26368;&#20248;&#21644;&#20960;&#20046;&#26368;&#20248;&#30340;&#26679;&#26412;&#21644;&#25209;&#22788;&#29702;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26368;&#20339;&#25209;&#22788;&#29702;&#27494;&#22120;&#35782;&#21035;&#65288;BBAI&#65289;&#38382;&#39064;&#65292;&#20854;&#20013;&#23398;&#20064;&#32773;&#30340;&#30446;&#26631;&#26159;&#22312;&#23613;&#37327;&#23569;&#22320;&#26356;&#25442;&#31574;&#30053;&#30340;&#21516;&#26102;&#35782;&#21035;&#20986;&#26368;&#20339;&#27494;&#22120;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20197;&#27010;&#29575;$1-\delta$&#25214;&#21040;&#26368;&#20339;&#27494;&#22120;&#65292;&#20854;&#20013;$\delta&gt;0$&#26159;&#19968;&#20010;&#23567;&#24120;&#25968;&#65292;&#21516;&#26102;&#26368;&#23567;&#21270;&#26679;&#26412;&#22797;&#26434;&#24230;&#65288;&#27494;&#22120;&#25289;&#21462;&#30340;&#24635;&#25968;&#65289;&#21644;&#25209;&#22788;&#29702;&#22797;&#26434;&#24230;&#65288;&#25209;&#22788;&#29702;&#30340;&#24635;&#25968;&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19977;&#25209;&#27425;&#26368;&#20339;&#27494;&#22120;&#35782;&#21035;&#65288;Tri-BBAI&#65289;&#31639;&#27861;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#28176;&#36817;&#35774;&#32622;&#65288;&#21363;$\delta\rightarrow0$&#65289;&#20013;&#23454;&#29616;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#19988;&#20165;&#22312;&#26368;&#22810;&#19977;&#20010;&#25209;&#27425;&#20013;&#36816;&#34892;&#30340;&#25209;&#22788;&#29702;&#31639;&#27861;&#12290;&#22522;&#20110;Tri-BBAI&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#20960;&#20046;&#26368;&#20248;&#30340;&#25209;&#22788;&#29702;&#26368;&#20339;&#27494;&#22120;&#35782;&#21035;&#65288;Opt-BBAI&#65289;&#31639;&#27861;&#65292;&#22312;&#38750;&#28176;&#36817;&#35774;&#32622;&#65288;&#21363;$\delta&gt;0$&#26159;&#20219;&#24847;&#22266;&#23450;&#30340;&#65289;&#20013;&#23454;&#29616;&#36817;&#20284;&#26368;&#20248;&#30340;&#26679;&#26412;&#21644;&#25209;&#22788;&#29702;&#22797;&#26434;&#24230;&#65292;&#21516;&#26102;&#22312;$\delta$&#36235;&#20110;&#38646;&#26102;&#20139;&#21463;&#19982;Tri-BBAI&#30456;&#21516;&#30340;&#25209;&#22788;&#29702;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the batched best arm identification (BBAI) problem, where the learner's goal is to identify the best arm while switching the policy as less as possible. In particular, we aim to find the best arm with probability $1-\delta$ for some small constant $\delta&gt;0$ while minimizing both the sample complexity (total number of arm pulls) and the batch complexity (total number of batches). We propose the three-batch best arm identification (Tri-BBAI) algorithm, which is the first batched algorithm that achieves the optimal sample complexity in the asymptotic setting (i.e., $\delta\rightarrow 0$) and runs only in at most $3$ batches. Based on Tri-BBAI, we further propose the almost optimal batched best arm identification (Opt-BBAI) algorithm, which is the first algorithm that achieves the near-optimal sample and batch complexity in the non-asymptotic setting (i.e., $\delta&gt;0$ is arbitrarily fixed), while enjoying the same batch and sample complexity as Tri-BBAI when $\delta$ tends to zer
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#26088;&#22312;&#25552;&#39640;&#23545;&#28145;&#24230;&#23398;&#20064;&#20248;&#21270;&#21644;&#27169;&#22411;&#27491;&#21017;&#21270;&#30340;&#29702;&#35299;&#65292;&#30740;&#31350;&#20102;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#21160;&#21147;&#23398;&#29305;&#24615;&#21644;&#31163;&#25955;&#28418;&#31227;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.14036</link><description>&lt;p&gt;
&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#20013;&#30340;&#31163;&#25955;&#28418;&#31227;&#21644;&#24179;&#28369;&#27491;&#21017;&#21270;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On discretisation drift and smoothness regularisation in neural network training. (arXiv:2310.14036v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14036
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#25552;&#39640;&#23545;&#28145;&#24230;&#23398;&#20064;&#20248;&#21270;&#21644;&#27169;&#22411;&#27491;&#21017;&#21270;&#30340;&#29702;&#35299;&#65292;&#30740;&#31350;&#20102;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#21160;&#21147;&#23398;&#29305;&#24615;&#21644;&#31163;&#25955;&#28418;&#31227;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#29616;&#23454;&#19990;&#30028;&#38382;&#39064;&#36716;&#21270;&#20026;&#25968;&#23398;&#20248;&#21270;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#26041;&#27861;&#26469;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#24050;&#34987;&#35777;&#26126;&#26159;&#26377;&#25928;&#30340;&#12290;&#28982;&#32780;&#65292;&#28145;&#24230;&#23398;&#20064;&#30340;&#20855;&#20307;&#24037;&#20316;&#21407;&#29702;&#30340;&#29702;&#35299;&#33853;&#21518;&#20110;&#20854;&#23454;&#38469;&#24847;&#20041;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#22312;&#20248;&#21270;&#21644;&#27169;&#22411;&#27491;&#21017;&#21270;&#26041;&#38754;&#36808;&#20986;&#25913;&#36827;&#30340;&#27493;&#20240;&#12290;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#20102;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#65292;&#36825;&#26159;&#22823;&#22810;&#25968;&#27969;&#34892;&#30340;&#28145;&#24230;&#23398;&#20064;&#20248;&#21270;&#31639;&#27861;&#30340;&#31163;&#25955;&#26102;&#38388;&#31639;&#27861;&#30340;&#22522;&#30784;&#12290;&#29702;&#35299;GD&#30340;&#21160;&#21147;&#23398;&#29305;&#24615;&#19968;&#30452;&#21463;&#21040;&#31163;&#25955;&#28418;&#31227;&#30340;&#38459;&#30861;&#65292;&#21363;GD&#19982;&#20854;&#24120;&#24120;&#30740;&#31350;&#30340;&#36830;&#32493;&#26102;&#38388;&#23545;&#24212;&#29289;&#8212;&#8212;&#36127;&#26799;&#24230;&#27969;&#65288;NGF&#65289;&#20043;&#38388;&#30340;&#25968;&#20540;&#31215;&#20998;&#35823;&#24046;&#12290;&#20026;&#20102;&#25193;&#23637;&#30740;&#31350;GD&#30340;&#24037;&#20855;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#32771;&#34385;&#31163;&#25955;&#28418;&#31227;&#30340;&#26032;&#22411;&#36830;&#32493;&#26102;&#38388;&#27969;&#21160;&#12290;&#19982;NGF&#19981;&#21516;&#65292;&#36825;&#20123;&#26032;&#30340;&#27969;&#21160;&#21487;&#20197;&#29992;&#26469;&#25551;&#36848;&#31163;&#25955;&#28418;&#31227;&#12290;
&lt;/p&gt;
&lt;p&gt;
The deep learning recipe of casting real-world problems as mathematical optimisation and tackling the optimisation by training deep neural networks using gradient-based optimisation has undoubtedly proven to be a fruitful one. The understanding behind why deep learning works, however, has lagged behind its practical significance. We aim to make steps towards an improved understanding of deep learning with a focus on optimisation and model regularisation. We start by investigating gradient descent (GD), a discrete-time algorithm at the basis of most popular deep learning optimisation algorithms. Understanding the dynamics of GD has been hindered by the presence of discretisation drift, the numerical integration error between GD and its often studied continuous-time counterpart, the negative gradient flow (NGF). To add to the toolkit available to study GD, we derive novel continuous-time flows that account for discretisation drift. Unlike the NGF, these new flows can be used to describe 
&lt;/p&gt;</description></item><item><title>ASBART&#26159;&#22522;&#20110;&#36125;&#21494;&#26031;&#21152;&#27861;&#22238;&#24402;&#26641;&#65288;BART&#65289;&#30340;&#19968;&#31181;&#21152;&#36895;&#36719;&#20214;&#65292;&#30456;&#36739;&#20110;&#20256;&#32479;&#30340;&#36719;BART&#26041;&#27861;&#65292;&#22312;&#20445;&#25345;&#20934;&#30830;&#24230;&#30340;&#24773;&#20917;&#19979;&#25552;&#39640;&#20102;&#35745;&#31639;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.13975</link><description>&lt;p&gt;
ASBART: &#21152;&#36895;&#36719;&#36125;&#21494;&#26031;&#21152;&#27861;&#22238;&#24402;&#26641;
&lt;/p&gt;
&lt;p&gt;
ASBART:Accelerated Soft Bayes Additive Regression Trees. (arXiv:2310.13975v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13975
&lt;/p&gt;
&lt;p&gt;
ASBART&#26159;&#22522;&#20110;&#36125;&#21494;&#26031;&#21152;&#27861;&#22238;&#24402;&#26641;&#65288;BART&#65289;&#30340;&#19968;&#31181;&#21152;&#36895;&#36719;&#20214;&#65292;&#30456;&#36739;&#20110;&#20256;&#32479;&#30340;&#36719;BART&#26041;&#27861;&#65292;&#22312;&#20445;&#25345;&#20934;&#30830;&#24230;&#30340;&#24773;&#20917;&#19979;&#25552;&#39640;&#20102;&#35745;&#31639;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#21152;&#27861;&#22238;&#24402;&#26641;&#65288;BART&#65289;&#26159;&#19968;&#31181;&#38750;&#21442;&#25968;&#22238;&#24402;&#27169;&#22411;&#65292;&#30001;&#20110;&#20854;&#28789;&#27963;&#24615;&#21644;&#39640;&#20934;&#30830;&#24230;&#30340;&#20272;&#35745;&#65292;&#36817;&#24180;&#26469;&#22312;&#32479;&#35745;&#21644;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#24191;&#21463;&#27426;&#36814;&#12290;&#36719;BART&#26159;BART&#30340;&#19968;&#31181;&#21464;&#31181;&#65292;&#20174;&#23454;&#38469;&#21644;&#29702;&#35770;&#19978;&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;&#36125;&#21494;&#26031;&#26641;&#24635;&#21644;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#36719;BART&#30340;&#19968;&#20010;&#29942;&#39048;&#26159;&#22312;&#38271;&#30340;MCMC&#24490;&#29615;&#20013;&#36895;&#24230;&#36739;&#24930;&#12290;&#19982;BART&#30456;&#27604;&#65292;&#23427;&#20351;&#29992;&#30340;&#35745;&#31639;&#26102;&#38388;&#40664;&#35748;&#24773;&#20917;&#19979;&#22810;&#20102;&#22823;&#32422;20&#20493;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21152;&#36895;&#36719;BART&#65288;ASBART&#65289;&#30340;BART&#21464;&#20307;&#12290;&#27169;&#25311;&#30740;&#31350;&#34920;&#26126;&#65292;&#35813;&#26032;&#26041;&#27861;&#27604;&#20855;&#26377;&#21487;&#27604;&#20934;&#30830;&#24230;&#30340;&#36719;BART&#24555;&#32422;10&#20493;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#26159;&#24320;&#28304;&#30340;&#65292;&#21487;&#22312;https://github.com/richael008/XSBART&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayes additive regression trees(BART) is a nonparametric regression model which has gained wide-spread popularity in recent years due to its flexibility and high accuracy of estimation. Soft BART,one variation of BART,improves both practically and heoretically on existing Bayesian sum-of-trees models. One bottleneck for Soft BART is its slow speed in the long MCMC loop. Compared to BART,it use more than about 20 times to complete the calculation with the default setting. We proposed a variant of BART named accelerate Soft BART(ASBART). Simulation studies show that the new method is about 10 times faster than the Soft BART with comparable accuracy. Our code is open-source and available at https://github.com/richael008/XSBART.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#22823;&#35268;&#27169;&#32452;&#21512;&#25968;&#25454;&#20013;&#30340;&#20998;&#24067;&#24335;&#31232;&#30095;&#24809;&#32602;&#32447;&#24615;&#23545;&#27604;&#27169;&#22411;&#30340;&#20004;&#31181;&#20998;&#24067;&#24335;&#20248;&#21270;&#25216;&#26415;&#65292;&#20998;&#21035;&#37319;&#29992;&#38598;&#20013;&#24335;&#21644;&#20998;&#25955;&#24335;&#25299;&#25169;&#32467;&#26500;&#65292;&#20197;&#33719;&#24471;&#20855;&#26377;&#36739;&#20302;&#36890;&#20449;&#24320;&#38144;&#30340;&#27491;&#21017;&#21270;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2310.13969</link><description>&lt;p&gt;
&#20855;&#26377;&#32452;&#21512;&#21327;&#21464;&#37327;&#30340;&#20998;&#24067;&#24335;&#32447;&#24615;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Distributed Linear Regression with Compositional Covariates. (arXiv:2310.13969v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13969
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#22823;&#35268;&#27169;&#32452;&#21512;&#25968;&#25454;&#20013;&#30340;&#20998;&#24067;&#24335;&#31232;&#30095;&#24809;&#32602;&#32447;&#24615;&#23545;&#27604;&#27169;&#22411;&#30340;&#20004;&#31181;&#20998;&#24067;&#24335;&#20248;&#21270;&#25216;&#26415;&#65292;&#20998;&#21035;&#37319;&#29992;&#38598;&#20013;&#24335;&#21644;&#20998;&#25955;&#24335;&#25299;&#25169;&#32467;&#26500;&#65292;&#20197;&#33719;&#24471;&#20855;&#26377;&#36739;&#20302;&#36890;&#20449;&#24320;&#38144;&#30340;&#27491;&#21017;&#21270;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#30340;&#21487;&#29992;&#24615;&#65292;&#35299;&#20915;&#20998;&#24067;&#24335;&#32479;&#35745;&#26041;&#27861;&#21644;&#35745;&#31639;&#38382;&#39064;&#21464;&#24471;&#22312;&#22823;&#25968;&#25454;&#39046;&#22495;&#26085;&#30410;&#20851;&#38190;&#12290;&#26412;&#25991;&#38024;&#23545;&#22823;&#35268;&#27169;&#32452;&#21512;&#25968;&#25454;&#20013;&#30340;&#20998;&#24067;&#24335;&#31232;&#30095;&#24809;&#32602;&#32447;&#24615;&#23545;&#27604;&#27169;&#22411;&#36827;&#34892;&#30740;&#31350;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#19981;&#21516;&#32422;&#26463;&#20984;&#20248;&#21270;&#38382;&#39064;&#30340;&#20998;&#24067;&#24335;&#20248;&#21270;&#25216;&#26415;&#65292;&#20998;&#21035;&#37319;&#29992;&#38598;&#20013;&#24335;&#21644;&#20998;&#25955;&#24335;&#25299;&#25169;&#32467;&#26500;&#12290;&#36825;&#20004;&#20010;&#31639;&#27861;&#37117;&#26159;&#22522;&#20110;&#20132;&#26367;&#26041;&#21521;&#20056;&#23376;&#26041;&#27861;&#65288;ADMM&#65289;&#21644;&#22352;&#26631;&#19979;&#38477;&#26041;&#27861;&#30340;&#26694;&#26550;&#12290;&#20540;&#24471;&#24378;&#35843;&#30340;&#26159;&#65292;&#22312;&#20998;&#25955;&#24335;&#25299;&#25169;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#22522;&#20110;&#20998;&#32452;ADMM&#65288;GADMM&#65289;&#30340;&#20998;&#24067;&#24335;&#22352;&#26631;&#19979;&#38477;&#31639;&#27861;&#65292;&#20197;&#33719;&#24471;&#20855;&#26377;&#36739;&#20302;&#36890;&#20449;&#24320;&#38144;&#30340;&#27491;&#21017;&#21270;&#20272;&#35745;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#23545;&#20110;&#27599;&#20010;&#21464;&#37327;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#36866;&#24212;GADMM&#30340;&#21327;&#35843;&#19979;&#38477;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the availability of extraordinarily huge data sets, solving the problems of distributed statistical methodology and computing for such data sets has become increasingly crucial in the big data area. In this paper, we focus on the distributed sparse penalized linear log-contrast model in massive compositional data. In particular, two distributed optimization techniques under centralized and decentralized topologies are proposed for solving the two different constrained convex optimization problems. Both two proposed algorithms are based on the frameworks of Alternating Direction Method of Multipliers (ADMM) and Coordinate Descent Method of Multipliers(CDMM, Lin et al., 2014, Biometrika). It is worth emphasizing that, in the decentralized topology, we introduce a distributed coordinate-wise descent algorithm based on Group ADMM(GADMM, Elgabli et al., 2020, Journal of Machine Learning Research) for obtaining a communication-efficient regularized estimation. Correspondingly, the conve
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#20102;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#20256;&#36882;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#24773;&#20917;&#19979;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#24182;&#20998;&#21035;&#32473;&#20986;&#20102;&#32479;&#35745;&#24615;&#36136;&#21644;&#26368;&#20248;&#24615;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.13966</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#26368;&#20248;&#26497;&#23567;&#21270;&#20256;&#36882;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Minimax Optimal Transfer Learning for Kernel-based Nonparametric Regression. (arXiv:2310.13966v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13966
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#20102;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#20256;&#36882;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#24773;&#20917;&#19979;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#24182;&#20998;&#21035;&#32473;&#20986;&#20102;&#32479;&#35745;&#24615;&#36136;&#21644;&#26368;&#20248;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20256;&#36882;&#23398;&#20064;&#22312;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#20013;&#21463;&#21040;&#20102;&#24456;&#22823;&#20851;&#27880;&#12290;&#23427;&#33021;&#22815;&#21033;&#29992;&#30456;&#20851;&#30740;&#31350;&#30340;&#30693;&#35782;&#26469;&#25552;&#39640;&#30446;&#26631;&#30740;&#31350;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#20351;&#20854;&#20855;&#26377;&#24456;&#39640;&#30340;&#21560;&#24341;&#21147;&#12290;&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#20256;&#36882;&#23398;&#20064;&#38382;&#39064;&#65292;&#30446;&#30340;&#26159;&#32553;&#23567;&#23454;&#38469;&#25928;&#26524;&#19982;&#29702;&#35770;&#20445;&#35777;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#20855;&#20307;&#32771;&#34385;&#20102;&#20004;&#31181;&#24773;&#20917;&#65306;&#24050;&#30693;&#21487;&#20256;&#36882;&#30340;&#26469;&#28304;&#21644;&#26410;&#30693;&#30340;&#24773;&#20917;&#12290;&#23545;&#20110;&#24050;&#30693;&#21487;&#20256;&#36882;&#30340;&#26469;&#28304;&#24773;&#20917;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#27493;&#26680;&#20272;&#35745;&#22120;&#65292;&#20165;&#20351;&#29992;&#26680;&#23725;&#22238;&#24402;&#12290;&#23545;&#20110;&#26410;&#30693;&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#25928;&#32858;&#21512;&#31639;&#27861;&#30340;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#33258;&#21160;&#26816;&#27979;&#24182;&#20943;&#36731;&#36127;&#38754;&#26469;&#28304;&#30340;&#24433;&#21709;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#25152;&#38656;&#20272;&#35745;&#22120;&#30340;&#32479;&#35745;&#24615;&#36136;&#65292;&#24182;&#24314;&#31435;&#20102;&#35813;&#26041;&#27861;&#30340;&#26368;&#20248;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, transfer learning has garnered significant attention in the machine learning community. Its ability to leverage knowledge from related studies to improve generalization performance in a target study has made it highly appealing. This paper focuses on investigating the transfer learning problem within the context of nonparametric regression over a reproducing kernel Hilbert space. The aim is to bridge the gap between practical effectiveness and theoretical guarantees. We specifically consider two scenarios: one where the transferable sources are known and another where they are unknown. For the known transferable source case, we propose a two-step kernel-based estimator by solely using kernel ridge regression. For the unknown case, we develop a novel method based on an efficient aggregation algorithm, which can automatically detect and alleviate the effects of negative sources. This paper provides the statistical properties of the desired estimators and establishes the 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#20943;&#23567;&#20559;&#24046;&#21644;&#26041;&#24046;&#30340;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#35889;&#39118;&#38505;&#21644;$f$-&#25955;&#24230;&#32602;&#39033;&#26469;&#35299;&#20915;&#39118;&#38505;&#25935;&#24863;&#23398;&#20064;&#38382;&#39064;&#12290;&#25552;&#20986;&#30340;Prospect&#31639;&#27861;&#21482;&#38656;&#35843;&#33410;&#19968;&#20010;&#23398;&#20064;&#29575;&#36229;&#21442;&#25968;&#65292;&#24182;&#35777;&#26126;&#22312;&#24179;&#28369;&#27491;&#21017;&#21270;&#25439;&#22833;&#24773;&#20917;&#19979;&#20855;&#26377;&#32447;&#24615;&#25910;&#25947;&#24615;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;Prospect&#31639;&#27861;&#22312;&#20998;&#24067;&#20559;&#31227;&#21644;&#20844;&#24179;&#24615;&#22522;&#20934;&#19978;&#33021;&#20197;2-3&#20493;&#30340;&#36895;&#24230;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2310.13863</link><description>&lt;p&gt;
&#20855;&#26377;&#20559;&#24046;&#21644;&#26041;&#24046;&#20943;&#23567;&#30340;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Distributionally Robust Optimization with Bias and Variance Reduction. (arXiv:2310.13863v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13863
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#20943;&#23567;&#20559;&#24046;&#21644;&#26041;&#24046;&#30340;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#35889;&#39118;&#38505;&#21644;$f$-&#25955;&#24230;&#32602;&#39033;&#26469;&#35299;&#20915;&#39118;&#38505;&#25935;&#24863;&#23398;&#20064;&#38382;&#39064;&#12290;&#25552;&#20986;&#30340;Prospect&#31639;&#27861;&#21482;&#38656;&#35843;&#33410;&#19968;&#20010;&#23398;&#20064;&#29575;&#36229;&#21442;&#25968;&#65292;&#24182;&#35777;&#26126;&#22312;&#24179;&#28369;&#27491;&#21017;&#21270;&#25439;&#22833;&#24773;&#20917;&#19979;&#20855;&#26377;&#32447;&#24615;&#25910;&#25947;&#24615;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;Prospect&#31639;&#27861;&#22312;&#20998;&#24067;&#20559;&#31227;&#21644;&#20844;&#24179;&#24615;&#22522;&#20934;&#19978;&#33021;&#20197;2-3&#20493;&#30340;&#36895;&#24230;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#35889;&#39118;&#38505;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#38598;&#21644;$f$-&#25955;&#24230;&#32602;&#39033;&#30340;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;(DRO)&#38382;&#39064;&#12290;&#36825;&#20010;&#38382;&#39064;&#21253;&#25324;&#24120;&#35265;&#30340;&#39118;&#38505;&#25935;&#24863;&#23398;&#20064;&#30446;&#26631;&#65292;&#22914;&#27491;&#21017;&#21270;&#26465;&#20214;&#39118;&#38505;&#20215;&#20540;(Conditional Value-at-Risk, CVaR)&#21644;&#24179;&#22343;top-$k$&#25439;&#22833;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;Prospect&#65292;&#19968;&#31181;&#20165;&#38656;&#35843;&#33410;&#21333;&#20010;&#23398;&#20064;&#29575;&#36229;&#21442;&#25968;&#30340;&#38543;&#26426;&#26799;&#24230;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#22312;&#24179;&#28369;&#27491;&#21017;&#21270;&#25439;&#22833;&#24773;&#20917;&#19979;&#65292;&#23427;&#20855;&#26377;&#32447;&#24615;&#25910;&#25947;&#24615;&#12290;&#36825;&#19982;&#20043;&#21069;&#30340;&#31639;&#27861;&#24418;&#25104;&#20102;&#23545;&#27604;&#65292;&#36825;&#20123;&#31639;&#27861;&#35201;&#20040;&#38656;&#35201;&#35843;&#33410;&#22810;&#20010;&#36229;&#21442;&#25968;&#65292;&#35201;&#20040;&#30001;&#20110;&#26799;&#24230;&#20272;&#35745;&#23384;&#22312;&#20559;&#24046;&#25110;&#19981;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#32780;&#23548;&#33268;&#22833;&#36133;&#12290;&#22312;&#23454;&#35777;&#26041;&#38754;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;Prospect&#22312;&#36328;&#34920;&#26684;&#12289;&#35270;&#35273;&#21644;&#35821;&#35328;&#39046;&#22495;&#30340;&#20998;&#24067;&#20559;&#31227;&#21644;&#20844;&#24179;&#24615;&#22522;&#20934;&#19978;&#33021;&#20197;2-3&#20493;&#30340;&#36895;&#24230;&#25910;&#25947;&#65292;&#27604;&#22522;&#32447;&#26041;&#27861;&#22914;&#38543;&#26426;&#26799;&#24230;&#21644;&#38543;&#26426;&#38797;&#28857;&#26041;&#27861;&#24555;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the distributionally robust optimization (DRO) problem with spectral risk-based uncertainty set and $f$-divergence penalty. This formulation includes common risk-sensitive learning objectives such as regularized condition value-at-risk (CVaR) and average top-$k$ loss. We present Prospect, a stochastic gradient-based algorithm that only requires tuning a single learning rate hyperparameter, and prove that it enjoys linear convergence for smooth regularized losses. This contrasts with previous algorithms that either require tuning multiple hyperparameters or potentially fail to converge due to biased gradient estimates or inadequate regularization. Empirically, we show that Prospect can converge 2-3$\times$ faster than baselines such as stochastic gradient and stochastic saddle-point methods on distribution shift and fairness benchmarks spanning tabular, vision, and language domains.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28176;&#36827;&#22495;&#33258;&#36866;&#24212;&#20013;&#30340;&#28176;&#36827;&#33258;&#35757;&#32451;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#25913;&#36827;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#25351;&#20986;&#20102;&#20013;&#38388;&#22495;&#22312;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#20043;&#38388;&#22343;&#21248;&#25918;&#32622;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.13852</link><description>&lt;p&gt;
&#28176;&#36827;&#22495;&#33258;&#36866;&#24212;&#65306;&#29702;&#35770;&#19982;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Gradual Domain Adaptation: Theory and Algorithms. (arXiv:2310.13852v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13852
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28176;&#36827;&#22495;&#33258;&#36866;&#24212;&#20013;&#30340;&#28176;&#36827;&#33258;&#35757;&#32451;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#25913;&#36827;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#25351;&#20986;&#20102;&#20013;&#38388;&#22495;&#22312;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#20043;&#38388;&#22343;&#21248;&#25918;&#32622;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#22495;&#33258;&#36866;&#24212;&#65288;UDA&#65289;&#26159;&#23558;&#27169;&#22411;&#20174;&#26377;&#26631;&#35760;&#30340;&#28304;&#22495;&#36866;&#24212;&#21040;&#26080;&#26631;&#35760;&#30340;&#30446;&#26631;&#22495;&#30340;&#19968;&#31181;&#19968;&#27425;&#24615;&#26041;&#27861;&#12290;&#23613;&#31649;&#34987;&#24191;&#27867;&#24212;&#29992;&#65292;&#20294;&#24403;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#20043;&#38388;&#30340;&#20998;&#24067;&#20559;&#31227;&#36739;&#22823;&#26102;&#65292;UDA&#38754;&#20020;&#24040;&#22823;&#25361;&#25112;&#12290;&#28176;&#36827;&#22495;&#33258;&#36866;&#24212;&#65288;GDA&#65289;&#36890;&#36807;&#20351;&#29992;&#20013;&#38388;&#22495;&#36880;&#28176;&#20174;&#28304;&#22495;&#36866;&#24212;&#21040;&#30446;&#26631;&#22495;&#26469;&#32531;&#35299;&#36825;&#20010;&#38480;&#21046;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#20174;&#29702;&#35770;&#19978;&#20998;&#26512;&#20102;&#19968;&#31181;&#24120;&#35265;&#30340;GDA&#31639;&#27861;&#8212;&#8212;&#28176;&#36827;&#33258;&#35757;&#32451;&#65292;&#24182;&#25552;&#20379;&#20102;&#19982;Kumar&#31561;&#20154;&#65288;2020&#65289;&#30456;&#27604;&#26174;&#33879;&#25913;&#36827;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#24471;&#20986;&#19968;&#20010;&#26377;&#36259;&#30340;&#35266;&#28857;&#65306;&#20026;&#20102;&#26368;&#23567;&#21270;&#30446;&#26631;&#22495;&#19978;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#20013;&#38388;&#22495;&#30340;&#39034;&#24207;&#24212;&#35813;&#22343;&#21248;&#22320;&#25918;&#32622;&#22312;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#20043;&#38388;&#30340;Wasserstein&#27979;&#22320;&#32447;&#19978;&#12290;&#36825;&#20010;&#35266;&#28857;&#22312;&#20013;&#38388;&#22495;&#32570;&#22833;&#25110;&#31232;&#32570;&#30340;&#24773;&#20917;&#19979;&#23588;&#20854;&#26377;&#29992;&#65292;&#32780;&#36825;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#20013;&#32463;&#24120;&#20986;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised domain adaptation (UDA) adapts a model from a labeled source domain to an unlabeled target domain in a one-off way. Though widely applied, UDA faces a great challenge whenever the distribution shift between the source and the target is large. Gradual domain adaptation (GDA) mitigates this limitation by using intermediate domains to gradually adapt from the source to the target domain. In this work, we first theoretically analyze gradual self-training, a popular GDA algorithm, and provide a significantly improved generalization bound compared with Kumar et al. (2020). Our theoretical analysis leads to an interesting insight: to minimize the generalization error on the target domain, the sequence of intermediate domains should be placed uniformly along the Wasserstein geodesic between the source and target domains. The insight is particularly useful under the situation where intermediate domains are missing or scarce, which is often the case in real-world applications. Based
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#27491;&#21487;&#20998;&#35299;&#26680;&#30340;&#20960;&#20309;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;RKKS&#20013;&#23398;&#20064;&#32780;&#19981;&#38656;&#35201;&#35775;&#38382;&#26680;&#30340;&#20998;&#35299;&#65292;&#20026;&#38750;&#27431;&#20960;&#37324;&#24503;&#25968;&#25454;&#30340;&#26680;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#26465;&#36335;&#24452;&#65292;&#24182;&#20026;RKKS&#26041;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2310.13821</link><description>&lt;p&gt;
&#20351;&#29992;&#27491;&#21487;&#20998;&#35299;&#26680;&#30340;&#20960;&#20309;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Geometric Learning with Positively Decomposable Kernels. (arXiv:2310.13821v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13821
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#27491;&#21487;&#20998;&#35299;&#26680;&#30340;&#20960;&#20309;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;RKKS&#20013;&#23398;&#20064;&#32780;&#19981;&#38656;&#35201;&#35775;&#38382;&#26680;&#30340;&#20998;&#35299;&#65292;&#20026;&#38750;&#27431;&#20960;&#37324;&#24503;&#25968;&#25454;&#30340;&#26680;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#26465;&#36335;&#24452;&#65292;&#24182;&#20026;RKKS&#26041;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#26041;&#27861;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#24378;&#22823;&#30340;&#24037;&#20855;&#12290;&#32463;&#20856;&#30340;&#26680;&#26041;&#27861;&#22522;&#20110;&#27491;&#23450;&#26680;&#65292;&#23558;&#25968;&#25454;&#31354;&#38388;&#26144;&#23556;&#21040;&#37325;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;(RKHS)&#12290;&#23545;&#20110;&#38750;&#27431;&#20960;&#37324;&#24503;&#25968;&#25454;&#31354;&#38388;&#65292;&#24456;&#38590;&#25214;&#21040;&#27491;&#23450;&#26680;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#22522;&#20110;&#37325;&#29616;&#26680;&#25511;&#21046;&#31354;&#38388;(RKKS)&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#21482;&#38656;&#35201;&#20855;&#26377;&#27491;&#20998;&#35299;&#30340;&#26680;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;RKKS&#20013;&#23398;&#20064;&#26102;&#65292;&#24182;&#19981;&#38656;&#35201;&#35775;&#38382;&#36825;&#20010;&#20998;&#35299;&#12290;&#28982;&#21518;&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#26680;&#27491;&#21487;&#20998;&#35299;&#30340;&#26465;&#20214;&#12290;&#25105;&#20204;&#35777;&#26126;&#22312;&#21487;&#22788;&#29702;&#30340;&#27491;&#21017;&#24615;&#20551;&#35774;&#19979;&#65292;&#19981;&#21464;&#26680;&#22312;&#40784;&#27425;&#31354;&#38388;&#19978;&#20801;&#35768;&#27491;&#20998;&#35299;&#12290;&#36825;&#20351;&#24471;&#23427;&#20204;&#27604;&#27491;&#23450;&#26680;&#26356;&#23481;&#26131;&#26500;&#36896;&#65292;&#20026;&#38750;&#27431;&#20960;&#37324;&#24503;&#25968;&#25454;&#30340;&#26680;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#26465;&#36335;&#24452;&#12290;&#21516;&#26679;&#65292;&#36825;&#20026;RKKS&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#33324;&#30340;&#29702;&#35770;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernel methods are powerful tools in machine learning. Classical kernel methods are based on positive-definite kernels, which map data spaces into reproducing kernel Hilbert spaces (RKHS). For non-Euclidean data spaces, positive-definite kernels are difficult to come by. In this case, we propose the use of reproducing kernel Krein space (RKKS) based methods, which require only kernels that admit a positive decomposition. We show that one does not need to access this decomposition in order to learn in RKKS. We then investigate the conditions under which a kernel is positively decomposable. We show that invariant kernels admit a positive decomposition on homogeneous spaces under tractable regularity assumptions. This makes them much easier to construct than positive-definite kernels, providing a route for learning with kernels for non-Euclidean data. By the same token, this provides theoretical foundations for RKKS-based methods in general.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19978;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#21253;&#25324;&#25512;&#23548;&#20102;&#25928;&#26524;&#21644;&#25104;&#21151;&#29575;&#30340;&#32479;&#35745;&#37327;&#65292;&#24182;&#25552;&#20379;&#20102;&#20960;&#31181;&#24773;&#20917;&#19979;&#30340;&#30028;&#38480;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#26681;&#25454;&#26679;&#26412;&#25968;&#37327;&#21644;&#20854;&#20182;&#32467;&#26500;&#21442;&#25968;&#25512;&#26029;&#28508;&#22312;&#25915;&#20987;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.13786</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#30340;&#22522;&#26412;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
Fundamental Limits of Membership Inference Attacks on Machine Learning Models. (arXiv:2310.13786v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13786
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19978;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#21253;&#25324;&#25512;&#23548;&#20102;&#25928;&#26524;&#21644;&#25104;&#21151;&#29575;&#30340;&#32479;&#35745;&#37327;&#65292;&#24182;&#25552;&#20379;&#20102;&#20960;&#31181;&#24773;&#20917;&#19979;&#30340;&#30028;&#38480;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#26681;&#25454;&#26679;&#26412;&#25968;&#37327;&#21644;&#20854;&#20182;&#32467;&#26500;&#21442;&#25968;&#25512;&#26029;&#28508;&#22312;&#25915;&#20987;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#65288;MIA&#65289;&#21487;&#20197;&#25581;&#31034;&#29305;&#23450;&#25968;&#25454;&#28857;&#26159;&#21542;&#26159;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#19968;&#37096;&#20998;&#65292;&#21487;&#33021;&#26292;&#38706;&#20010;&#20154;&#30340;&#25935;&#24863;&#20449;&#24687;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#20851;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19978;MIA&#30340;&#22522;&#26412;&#32479;&#35745;&#38480;&#21046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#25512;&#23548;&#20102;&#32479;&#35745;&#37327;&#65292;&#35813;&#32479;&#35745;&#37327;&#20915;&#23450;&#20102;&#36825;&#31181;&#25915;&#20987;&#30340;&#26377;&#25928;&#24615;&#21644;&#25104;&#21151;&#29575;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20960;&#31181;&#24773;&#20917;&#65292;&#24182;&#23545;&#36825;&#20010;&#24863;&#20852;&#36259;&#30340;&#32479;&#35745;&#37327;&#25552;&#20379;&#20102;&#30028;&#38480;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#26681;&#25454;&#26679;&#26412;&#25968;&#37327;&#21644;&#23398;&#20064;&#27169;&#22411;&#30340;&#20854;&#20182;&#32467;&#26500;&#21442;&#25968;&#25512;&#26029;&#28508;&#22312;&#25915;&#20987;&#30340;&#20934;&#30830;&#24615;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#21487;&#20197;&#30452;&#25509;&#20174;&#25968;&#25454;&#38598;&#20013;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Membership inference attacks (MIA) can reveal whether a particular data point was part of the training dataset, potentially exposing sensitive information about individuals. This article explores the fundamental statistical limitations associated with MIAs on machine learning models. More precisely, we first derive the statistical quantity that governs the effectiveness and success of such attacks. Then, we investigate several situations for which we provide bounds on this quantity of interest. This allows us to infer the accuracy of potential attacks as a function of the number of samples and other structural parameters of learning models, which in some cases can be directly estimated from the dataset.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32452;&#21512;&#28145;&#24230;&#27010;&#29575;&#27169;&#22411;DEL-Compose&#65292;&#29992;&#20110;&#23545;DNA&#32534;&#30721;&#24211;&#30340;&#25968;&#25454;&#36827;&#34892;&#24314;&#27169;&#21644;&#20998;&#26512;&#65292;&#20197;&#21457;&#29616;&#28508;&#22312;&#30340;&#32467;&#26500;&#21644;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#25913;&#36827;&#35266;&#23519;&#27169;&#22411;&#26469;&#26356;&#22909;&#22320;&#22788;&#29702;&#25968;&#25454;&#22122;&#22768;&#12290;</title><link>http://arxiv.org/abs/2310.13769</link><description>&lt;p&gt;
DNA&#32534;&#30721;&#24211;&#30340;&#32452;&#21512;&#28145;&#24230;&#27010;&#29575;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Compositional Deep Probabilistic Models of DNA Encoded Libraries. (arXiv:2310.13769v1 [q-bio.QM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13769
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32452;&#21512;&#28145;&#24230;&#27010;&#29575;&#27169;&#22411;DEL-Compose&#65292;&#29992;&#20110;&#23545;DNA&#32534;&#30721;&#24211;&#30340;&#25968;&#25454;&#36827;&#34892;&#24314;&#27169;&#21644;&#20998;&#26512;&#65292;&#20197;&#21457;&#29616;&#28508;&#22312;&#30340;&#32467;&#26500;&#21644;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#25913;&#36827;&#35266;&#23519;&#27169;&#22411;&#26469;&#26356;&#22909;&#22320;&#22788;&#29702;&#25968;&#25454;&#22122;&#22768;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
DNA&#32534;&#30721;&#24211;&#65288;DEL&#65289;&#24050;&#34987;&#35777;&#26126;&#26159;&#19968;&#31181;&#21033;&#29992;&#32452;&#21512;&#26500;&#24314;&#30340;&#23567;&#20998;&#23376;&#36827;&#34892;&#39640;&#25928;&#31579;&#36873;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#36825;&#20123;&#36873;&#25321;&#23454;&#39564;&#28041;&#21450;&#22810;&#20010;&#38454;&#27573;&#30340;&#27927;&#28068;&#12289;&#27927;&#33073;&#65292;&#24182;&#36890;&#36807;&#21807;&#19968;&#30340;DNA&#26465;&#24418;&#30721;&#37492;&#23450;&#20986;&#24378;&#25928;&#32467;&#21512;&#29289;&#36136;&#65292;&#24448;&#24448;&#20135;&#29983;&#22797;&#26434;&#30340;&#25968;&#25454;&#12290;&#36825;&#31181;&#22797;&#26434;&#24615;&#21487;&#33021;&#25513;&#30422;&#20102;&#28508;&#22312;&#30340;&#20449;&#21495;&#65292;&#22240;&#27492;&#38656;&#35201;&#24212;&#29992;&#26426;&#22120;&#23398;&#20064;&#31561;&#35745;&#31639;&#24037;&#20855;&#26469;&#21457;&#29616;&#26377;&#20215;&#20540;&#30340;&#35265;&#35299;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;DEL&#25968;&#25454;&#30340;&#32452;&#21512;&#28145;&#24230;&#27010;&#29575;&#27169;&#22411;DEL-Compose&#65292;&#23427;&#23558;&#20998;&#23376;&#34920;&#31034;&#20998;&#35299;&#20026;&#23427;&#20204;&#30340;&#21333;&#21512;&#23376;&#12289;&#20108;&#21512;&#23376;&#21644;&#19977;&#21512;&#23376;&#26500;&#24314;&#22359;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#23884;&#20837;&#21512;&#25104;&#29289;&#20043;&#38388;&#30340;&#28508;&#22312;&#21453;&#24212;&#26469;&#21033;&#29992;&#36825;&#20123;&#20998;&#23376;&#30340;&#20869;&#22312;&#20998;&#23618;&#32467;&#26500;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#25913;&#36827;DEL&#35745;&#25968;&#25968;&#25454;&#30340;&#35266;&#23519;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#22914;&#25972;&#21512;&#21327;&#21464;&#22240;&#23376;&#20197;&#26356;&#26377;&#25928;&#22320;&#35299;&#37322;&#25968;&#25454;&#22122;&#22768;&#12290;
&lt;/p&gt;
&lt;p&gt;
DNA-Encoded Library (DEL) has proven to be a powerful tool that utilizes combinatorially constructed small molecules to facilitate highly-efficient screening assays. These selection experiments, involving multiple stages of washing, elution, and identification of potent binders via unique DNA barcodes, often generate complex data. This complexity can potentially mask the underlying signals, necessitating the application of computational tools such as machine learning to uncover valuable insights. We introduce a compositional deep probabilistic model of DEL data, DEL-Compose, which decomposes molecular representations into their mono-synthon, di-synthon, and tri-synthon building blocks and capitalizes on the inherent hierarchical structure of these molecules by modeling latent reactions between embedded synthons. Additionally, we investigate methods to improve the observation models for DEL count data such as integrating covariate factors to more effectively account for data noise. Acro
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#29983;&#25104;&#27969;&#32593;&#32476;&#30340;&#23398;&#20064;&#20219;&#21153;&#37325;&#26032;&#23450;&#20041;&#20026;&#20855;&#26377;&#29305;&#23450;&#22870;&#21169;&#21644;&#27491;&#21017;&#21270;&#22120;&#32467;&#26500;&#30340;&#29109;&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#29109;&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#29983;&#25104;&#27969;&#32593;&#32476;&#35757;&#32451;&#20013;&#20855;&#26377;&#23454;&#38469;&#25928;&#29575;&#21644;&#31454;&#20105;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.12934</link><description>&lt;p&gt;
&#29983;&#25104;&#27969;&#32593;&#32476;&#20316;&#20026;&#29109;&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Generative Flow Networks as Entropy-Regularized RL. (arXiv:2310.12934v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12934
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#29983;&#25104;&#27969;&#32593;&#32476;&#30340;&#23398;&#20064;&#20219;&#21153;&#37325;&#26032;&#23450;&#20041;&#20026;&#20855;&#26377;&#29305;&#23450;&#22870;&#21169;&#21644;&#27491;&#21017;&#21270;&#22120;&#32467;&#26500;&#30340;&#29109;&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#29109;&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#29983;&#25104;&#27969;&#32593;&#32476;&#35757;&#32451;&#20013;&#20855;&#26377;&#23454;&#38469;&#25928;&#29575;&#21644;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#25552;&#20986;&#30340;&#29983;&#25104;&#27969;&#32593;&#32476;(GFlowNets)&#26159;&#19968;&#31181;&#35757;&#32451;&#31574;&#30053;&#20197;&#20415;&#26679;&#26412;&#20855;&#26377;&#19982;&#32473;&#23450;&#22870;&#21169;&#25104;&#27604;&#20363;&#30340;&#32452;&#21512;&#31163;&#25955;&#23545;&#35937;&#30340;&#27010;&#29575;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#19968;&#31995;&#21015;&#30340;&#21160;&#20316;&#12290; GFlowNets&#21033;&#29992;&#38382;&#39064;&#30340;&#24207;&#21015;&#24615;&#36136;&#65292;&#19982;&#24378;&#21270;&#23398;&#20064;(RL)&#36827;&#34892;&#31867;&#27604;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#23558;RL&#21644;GFlowNets&#20043;&#38388;&#30340;&#32852;&#31995;&#25193;&#23637;&#21040;&#20102;&#19968;&#33324;&#24773;&#20917;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#22914;&#20309;&#23558;&#23398;&#20064;&#29983;&#25104;&#27969;&#32593;&#32476;&#30340;&#20219;&#21153;&#39640;&#25928;&#22320;&#37325;&#26032;&#23450;&#20041;&#20026;&#20855;&#26377;&#29305;&#23450;&#22870;&#21169;&#21644;&#27491;&#21017;&#21270;&#22120;&#32467;&#26500;&#30340;&#29109;&#27491;&#21017;&#21270;RL&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#23558;&#26631;&#20934;&#30340;&#36719;RL&#31639;&#27861;&#24212;&#29992;&#20110;&#20960;&#20010;&#27010;&#29575;&#24314;&#27169;&#20219;&#21153;&#30340;GFlowNet&#35757;&#32451;&#65292;&#26469;&#35828;&#26126;&#36825;&#31181;&#37325;&#23450;&#20041;&#30340;&#23454;&#38469;&#25928;&#29575;&#12290;&#19982;&#20808;&#21069;&#25253;&#36947;&#30340;&#32467;&#26524;&#30456;&#21453;&#65292;&#25105;&#20204;&#34920;&#26126;&#29109;&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#19982;&#24050;&#26377;&#30340;GFlowNet&#35757;&#32451;&#26041;&#27861;&#31454;&#20105;&#20013;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;&#36825;&#20010;&#35266;&#28857;&#20026;&#23558;&#24378;&#21270;&#23398;&#20064;&#21407;&#21017;&#34701;&#20837;&#23454;&#38469;&#38382;&#39064;&#25552;&#20379;&#20102;&#30452;&#25509;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recently proposed generative flow networks (GFlowNets) are a method of training a policy to sample compositional discrete objects with probabilities proportional to a given reward via a sequence of actions. GFlowNets exploit the sequential nature of the problem, drawing parallels with reinforcement learning (RL). Our work extends the connection between RL and GFlowNets to a general case. We demonstrate how the task of learning a generative flow network can be efficiently redefined as an entropy-regularized RL problem with a specific reward and regularizer structure. Furthermore, we illustrate the practical efficiency of this reformulation by applying standard soft RL algorithms to GFlowNet training across several probabilistic modeling tasks. Contrary to previously reported results, we show that entropic RL approaches can be competitive against established GFlowNet training methods. This perspective opens a direct path for integrating reinforcement learning principles into the real
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25935;&#24863;&#24615;&#24863;&#30693;&#30340;&#25674;&#38144;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#26435;&#37325;&#20849;&#20139;&#21644;&#31070;&#32463;&#32593;&#32476;&#26469;&#36827;&#34892;&#20284;&#28982;&#21644;&#20808;&#39564;&#35268;&#33539;&#30340;&#35757;&#32451;&#65292;&#20197;&#21450;&#23545;&#25968;&#25454;&#25200;&#21160;&#21644;&#39044;&#22788;&#29702;&#31243;&#24207;&#30340;&#25935;&#24863;&#24615;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2310.11122</link><description>&lt;p&gt;
&#25935;&#24863;&#24615;&#24863;&#30693;&#30340;&#25674;&#38144;&#36125;&#21494;&#26031;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Sensitivity-Aware Amortized Bayesian Inference. (arXiv:2310.11122v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11122
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25935;&#24863;&#24615;&#24863;&#30693;&#30340;&#25674;&#38144;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#26435;&#37325;&#20849;&#20139;&#21644;&#31070;&#32463;&#32593;&#32476;&#26469;&#36827;&#34892;&#20284;&#28982;&#21644;&#20808;&#39564;&#35268;&#33539;&#30340;&#35757;&#32451;&#65292;&#20197;&#21450;&#23545;&#25968;&#25454;&#25200;&#21160;&#21644;&#39044;&#22788;&#29702;&#31243;&#24207;&#30340;&#25935;&#24863;&#24615;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#25512;&#26029;&#26159;&#22312;&#19981;&#30830;&#23450;&#24615;&#19979;&#36827;&#34892;&#27010;&#29575;&#25512;&#29702;&#21644;&#20915;&#31574;&#30340;&#24378;&#22823;&#26694;&#26550;&#12290;&#29616;&#20195;&#36125;&#21494;&#26031;&#24037;&#20316;&#27969;&#31243;&#20013;&#30340;&#22522;&#26412;&#36873;&#25321;&#28041;&#21450;&#20284;&#28982;&#20989;&#25968;&#21644;&#20808;&#39564;&#20998;&#24067;&#30340;&#35268;&#33539;&#12289;&#21518;&#39564;&#36924;&#36817;&#22120;&#21644;&#25968;&#25454;&#12290;&#27599;&#20010;&#36873;&#25321;&#37117;&#21487;&#20197;&#26174;&#30528;&#24433;&#21709;&#22522;&#20110;&#27169;&#22411;&#30340;&#25512;&#26029;&#21644;&#21518;&#32493;&#20915;&#31574;&#65292;&#22240;&#27492;&#38656;&#35201;&#36827;&#34892;&#25935;&#24863;&#24615;&#20998;&#26512;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#26041;&#38754;&#30340;&#26041;&#27861;&#65292;&#23558;&#25935;&#24863;&#24615;&#20998;&#26512;&#25972;&#21512;&#21040;&#25674;&#38144;&#36125;&#21494;&#26031;&#25512;&#26029;&#65288;ABI&#65292;&#21363;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#27169;&#25311;&#25512;&#26029;&#65289;&#20013;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#21033;&#29992;&#26435;&#37325;&#20849;&#20139;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#32534;&#30721;&#26367;&#20195;&#20284;&#28982;&#21644;&#20808;&#39564;&#35268;&#33539;&#20043;&#38388;&#30340;&#32467;&#26500;&#30456;&#20284;&#24615;&#65292;&#20197;&#26368;&#23567;&#30340;&#35745;&#31639;&#24320;&#38144;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#24555;&#36895;&#25512;&#26029;&#26469;&#35780;&#20272;&#23545;&#21508;&#31181;&#25968;&#25454;&#25200;&#21160;&#25110;&#39044;&#22788;&#29702;&#31243;&#24207;&#30340;&#25935;&#24863;&#24615;&#12290;&#19982;&#22823;&#22810;&#25968;&#20854;&#20182;&#36125;&#21494;&#26031;&#26041;&#27861;&#30456;&#27604;&#65292;&#36825;&#20004;&#20010;&#27493;&#39588;&#37117;&#36991;&#20813;&#20102;&#26114;&#36149;&#30340;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian inference is a powerful framework for making probabilistic inferences and decisions under uncertainty. Fundamental choices in modern Bayesian workflows concern the specification of the likelihood function and prior distributions, the posterior approximator, and the data. Each choice can significantly influence model-based inference and subsequent decisions, thereby necessitating sensitivity analysis. In this work, we propose a multifaceted approach to integrate sensitivity analyses into amortized Bayesian inference (ABI, i.e., simulation-based inference with neural networks). First, we utilize weight sharing to encode the structural similarities between alternative likelihood and prior specifications in the training process with minimal computational overhead. Second, we leverage the rapid inference of neural networks to assess sensitivity to various data perturbations or pre-processing procedures. In contrast to most other Bayesian approaches, both steps circumvent the costly
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#26234;&#33021;&#20256;&#24863;&#22120;&#32593;&#32476;&#30340;&#20998;&#24067;&#24335;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#21487;&#20197;&#35299;&#20915;&#36830;&#32493;&#21464;&#37327;&#12289;&#22823;&#35268;&#27169;&#23454;&#26102;&#25968;&#25454;&#21644;&#38590;&#20197;&#22788;&#29702;&#30340;&#21518;&#39564;&#27010;&#29575;&#30340;&#25512;&#26029;&#38382;&#39064;&#12290;&#36890;&#36807;&#25512;&#23548;&#20986;&#21487;&#20998;&#31163;&#30340;&#36739;&#20302;&#19979;&#30028;&#65292;&#23454;&#29616;&#20102;&#22312;&#20256;&#24863;&#22120;&#32593;&#32476;&#20013;&#36827;&#34892;&#19968;&#36339;&#36890;&#20449;&#30340;&#20998;&#24067;&#24335;&#21464;&#20998;&#25512;&#26029;&#65292;&#24182;&#25552;&#20986;&#20102;&#22788;&#29702;&#20108;&#36827;&#21046;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.02606</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#21464;&#20998;&#25512;&#26029;&#29992;&#20110;&#22312;&#32447;&#30417;&#30563;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Distributed Variational Inference for Online Supervised Learning. (arXiv:2309.02606v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02606
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#26234;&#33021;&#20256;&#24863;&#22120;&#32593;&#32476;&#30340;&#20998;&#24067;&#24335;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#21487;&#20197;&#35299;&#20915;&#36830;&#32493;&#21464;&#37327;&#12289;&#22823;&#35268;&#27169;&#23454;&#26102;&#25968;&#25454;&#21644;&#38590;&#20197;&#22788;&#29702;&#30340;&#21518;&#39564;&#27010;&#29575;&#30340;&#25512;&#26029;&#38382;&#39064;&#12290;&#36890;&#36807;&#25512;&#23548;&#20986;&#21487;&#20998;&#31163;&#30340;&#36739;&#20302;&#19979;&#30028;&#65292;&#23454;&#29616;&#20102;&#22312;&#20256;&#24863;&#22120;&#32593;&#32476;&#20013;&#36827;&#34892;&#19968;&#36339;&#36890;&#20449;&#30340;&#20998;&#24067;&#24335;&#21464;&#20998;&#25512;&#26029;&#65292;&#24182;&#25552;&#20986;&#20102;&#22788;&#29702;&#20108;&#36827;&#21046;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26234;&#33021;&#20256;&#24863;&#22120;&#32593;&#32476;&#20013;&#24320;&#21457;&#39640;&#25928;&#30340;&#25512;&#26029;&#38382;&#39064;&#35299;&#20915;&#26041;&#26696;&#23545;&#20110;&#19979;&#19968;&#20195;&#23450;&#20301;&#12289;&#36319;&#36394;&#21644;&#22320;&#22270;&#26381;&#21153;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#36830;&#32493;&#21464;&#37327;&#12289;&#38590;&#20197;&#22788;&#29702;&#30340;&#21518;&#39564;&#27010;&#29575;&#21644;&#22823;&#35268;&#27169;&#23454;&#26102;&#25968;&#25454;&#30340;&#21487;&#25193;&#23637;&#20998;&#24067;&#24335;&#27010;&#29575;&#25512;&#26029;&#31639;&#27861;&#12290;&#22312;&#38598;&#20013;&#24335;&#35774;&#32622;&#20013;&#65292;&#21464;&#20998;&#25512;&#26029;&#26159;&#19968;&#31181;&#25191;&#34892;&#36817;&#20284;&#36125;&#21494;&#26031;&#20272;&#35745;&#30340;&#22522;&#26412;&#25216;&#26415;&#65292;&#20854;&#20013;&#23558;&#38590;&#20197;&#22788;&#29702;&#30340;&#21518;&#39564;&#23494;&#24230;&#29992;&#21442;&#25968;&#21270;&#23494;&#24230;&#26469;&#36817;&#20284;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#22312;&#20110;&#25512;&#23548;&#20986;&#19968;&#20010;&#21487;&#20998;&#31163;&#30340;&#36739;&#20302;&#19979;&#30028;&#65292;&#29992;&#20110;&#38598;&#20013;&#24335;&#20272;&#35745;&#30446;&#26631;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#22312;&#20256;&#24863;&#22120;&#32593;&#32476;&#20013;&#36827;&#34892;&#19968;&#36339;&#36890;&#20449;&#30340;&#20998;&#24067;&#24335;&#21464;&#20998;&#25512;&#26029;&#12290;&#25105;&#20204;&#30340;&#20998;&#24067;&#24335;&#35777;&#25454;&#36739;&#20302;&#19979;&#30028; (DELBO) &#21253;&#25324;&#35266;&#27979;&#20284;&#28982;&#21644;&#36317;&#31163;&#20808;&#39564;&#23494;&#24230;&#30340;&#24046;&#20540;&#30340;&#21152;&#26435;&#21644;&#65292;&#20854;&#19982;&#27979;&#37327;&#35777;&#25454;&#30340;&#24046;&#36317;&#26159;&#30001;&#20110;&#20849;&#35782;&#21644;&#24314;&#27169;&#35823;&#24046;&#36896;&#25104;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#20108;&#36827;&#21046;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Developing efficient solutions for inference problems in intelligent sensor networks is crucial for the next generation of location, tracking, and mapping services. This paper develops a scalable distributed probabilistic inference algorithm that applies to continuous variables, intractable posteriors and large-scale real-time data in sensor networks. In a centralized setting, variational inference is a fundamental technique for performing approximate Bayesian estimation, in which an intractable posterior density is approximated with a parametric density. Our key contribution lies in the derivation of a separable lower bound on the centralized estimation objective, which enables distributed variational inference with one-hop communication in a sensor network. Our distributed evidence lower bound (DELBO) consists of a weighted sum of observation likelihood and divergence to prior densities, and its gap to the measurement evidence is due to consensus and modeling errors. To solve binary 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#26399;&#21464;&#20998;&#25512;&#26029;&#20316;&#20026;&#36817;&#20284;&#21518;&#39564;&#25512;&#26029;&#30340;&#19968;&#31181;&#36890;&#29992;&#26367;&#20195;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#20309;&#26102;&#33021;&#22815;&#36798;&#21040;&#19982;&#20256;&#32479;&#30340;&#22240;&#23376;&#21270;&#21464;&#20998;&#25512;&#26029;&#30456;&#21516;&#30340;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2307.11018</link><description>&lt;p&gt;
&#20998;&#26399;&#21464;&#20998;&#25512;&#26029;&#65306;&#20309;&#26102;&#20197;&#21450;&#20026;&#20160;&#20040;&#20351;&#29992;&#65311;
&lt;/p&gt;
&lt;p&gt;
Amortized Variational Inference: When and Why?. (arXiv:2307.11018v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11018
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#26399;&#21464;&#20998;&#25512;&#26029;&#20316;&#20026;&#36817;&#20284;&#21518;&#39564;&#25512;&#26029;&#30340;&#19968;&#31181;&#36890;&#29992;&#26367;&#20195;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#20309;&#26102;&#33021;&#22815;&#36798;&#21040;&#19982;&#20256;&#32479;&#30340;&#22240;&#23376;&#21270;&#21464;&#20998;&#25512;&#26029;&#30456;&#21516;&#30340;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#26399;&#21464;&#20998;&#25512;&#26029;&#65288;A-VI&#65289;&#26159;&#19968;&#31181;&#36817;&#20284;&#22788;&#29702;&#27010;&#29575;&#27169;&#22411;&#20013;&#30340;&#38590;&#20197;&#35745;&#31639;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;&#26041;&#27861;&#12290;A-VI&#30340;&#23450;&#20041;&#29305;&#28857;&#26159;&#23398;&#20064;&#19968;&#20010;&#20840;&#23616;&#25512;&#26029;&#20989;&#25968;&#65292;&#23558;&#27599;&#20010;&#35266;&#23519;&#26144;&#23556;&#21040;&#20854;&#23616;&#37096;&#28508;&#21464;&#37327;&#30340;&#36817;&#20284;&#21518;&#39564;&#20998;&#24067;&#12290;&#36825;&#19982;&#26356;&#20256;&#32479;&#30340;&#20998;&#35299;&#65288;&#25110;&#22343;&#22330;&#65289;&#21464;&#20998;&#25512;&#26029;&#65288;F-VI&#65289;&#24418;&#25104;&#23545;&#27604;&#65292;&#21518;&#32773;&#30452;&#25509;&#23398;&#20064;&#27599;&#20010;&#28508;&#21464;&#37327;&#30340;&#36817;&#20284;&#20998;&#24067;&#30340;&#21442;&#25968;&#12290;&#22312;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#20013;&#65292;A-VI&#29992;&#20316;&#21152;&#36895;&#23616;&#37096;&#28508;&#21464;&#37327;&#25512;&#26029;&#30340;&#35745;&#31639;&#25216;&#24039;&#12290;&#26412;&#25991;&#30740;&#31350;A-VI&#20316;&#20026;&#36817;&#20284;&#21518;&#39564;&#25512;&#26029;&#30340;&#19968;&#31181;&#36890;&#29992;&#26367;&#20195;&#26041;&#27861;&#12290;&#30001;&#20110;&#20998;&#26399;&#23478;&#26063;&#26159;&#20998;&#35299;&#23478;&#26063;&#30340;&#23376;&#38598;&#65292;A-VI&#26080;&#27861;&#20135;&#29983;&#27604;F-VI&#26368;&#20248;&#35299;&#26356;&#20302;&#30340;Kullback-Leibler&#25955;&#24230;&#30340;&#36817;&#20284;&#20540;&#12290;&#22240;&#27492;&#65292;&#19968;&#20010;&#26680;&#24515;&#30340;&#29702;&#35770;&#38382;&#39064;&#26159;&#21051;&#30011;A-VI&#20309;&#26102;&#20173;&#28982;&#36798;&#21040;F-VI&#30340;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Amortized variational inference (A-VI) is a method for approximating the intractable posterior distributions that arise in probabilistic models. The defining feature of A-VI is that it learns a global inference function that maps each observation to its local latent variable's approximate posterior. This stands in contrast to the more classical factorized (or mean-field) variational inference (F-VI), which directly learns the parameters of the approximating distribution for each latent variable. In deep generative models, A-VI is used as a computational trick to speed up inference for local latent variables. In this paper, we study A-VI as a general alternative to F-VI for approximate posterior inference. A-VI cannot produce an approximation with a lower Kullback-Leibler divergence than F-VI's optimal solution, because the amortized family is a subset of the factorized family. Thus a central theoretical problem is to characterize when A-VI still attains F-VI's optimal solution. We deri
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#30340;&#21464;&#20998;&#19981;&#24179;&#34913;&#22238;&#24402;&#65288;VIR&#65289;&#27169;&#22411;&#36890;&#36807;&#24341;&#20837;Probabilistic Reweighting&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#24179;&#34913;&#22238;&#24402;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#33258;&#28982;&#20135;&#29983;&#21512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2306.06599</link><description>&lt;p&gt;
&#21464;&#20998;&#19981;&#24179;&#34913;&#22238;&#24402;(Variational Imbalanced Regression)
&lt;/p&gt;
&lt;p&gt;
Variational Imbalanced Regression. (arXiv:2306.06599v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06599
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#30340;&#21464;&#20998;&#19981;&#24179;&#34913;&#22238;&#24402;&#65288;VIR&#65289;&#27169;&#22411;&#36890;&#36807;&#24341;&#20837;Probabilistic Reweighting&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#24179;&#34913;&#22238;&#24402;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#33258;&#28982;&#20135;&#29983;&#21512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#26631;&#31614;&#20998;&#24067;&#19981;&#24179;&#34913;&#26102;&#65292;&#29616;&#26377;&#30340;&#22238;&#24402;&#27169;&#22411;&#24448;&#24448;&#22312;&#20934;&#30830;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26041;&#38754;&#34920;&#29616;&#19981;&#20339;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#29575;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#8212;&#8212;&#21464;&#20998;&#19981;&#24179;&#34913;&#22238;&#24402;&#65288;VIR&#65289;&#65292;&#23427;&#19981;&#20165;&#22312;&#19981;&#24179;&#34913;&#22238;&#24402;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#32780;&#19988;&#33258;&#28982;&#22320;&#20135;&#29983;&#21512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#19982;&#20856;&#22411;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#20551;&#35774;I.I.D.&#34920;&#31034;&#65288;&#25968;&#25454;&#28857;&#30340;&#34920;&#31034;&#19981;&#30452;&#25509;&#21463;&#20854;&#20182;&#25968;&#25454;&#28857;&#30340;&#24433;&#21709;&#65289;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;VIR&#20511;&#29992;&#20855;&#26377;&#31867;&#20284;&#22238;&#24402;&#26631;&#31614;&#30340;&#25968;&#25454;&#26469;&#35745;&#31639;&#28508;&#22312;&#34920;&#31034;&#30340;&#21464;&#20998;&#20998;&#24067;&#65307;&#27492;&#22806;&#65292;&#19981;&#21516;&#20110;&#20135;&#29983;&#28857;&#20272;&#35745;&#30340;&#30830;&#23450;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292; VIR&#39044;&#27979;&#25972;&#20010;&#27491;&#24577;&#21453;-&#20285;&#29595;&#20998;&#24067;&#24182;&#35843;&#33410;&#30456;&#20851;&#32852;&#30340;&#20849;&#36717;&#20998;&#24067;&#65292;&#23545;&#19981;&#24179;&#34913;&#25968;&#25454;&#26045;&#21152;&#27010;&#29575;&#37325;&#26032;&#21152;&#26435;&#65292;&#20174;&#32780;&#25552;&#20379;&#26356;&#22909;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#22312;&#20960;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing regression models tend to fall short in both accuracy and uncertainty estimation when the label distribution is imbalanced. In this paper, we propose a probabilistic deep learning model, dubbed variational imbalanced regression (VIR), which not only performs well in imbalanced regression but naturally produces reasonable uncertainty estimation as a byproduct. Different from typical variational autoencoders assuming I.I.D. representations (a data point's representation is not directly affected by other data points), our VIR borrows data with similar regression labels to compute the latent representation's variational distribution; furthermore, different from deterministic regression models producing point estimates, VIR predicts the entire normal-inverse-gamma distributions and modulates the associated conjugate distributions to impose probabilistic reweighting on the imbalanced data, thereby providing better uncertainty estimation. Experiments in several real-world datasets sh
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#28508;&#22312;&#37327;&#21270;&#30340;&#26041;&#24335;&#23454;&#29616;&#20102;&#35299;&#32544;&#34920;&#31034;&#23398;&#20064;&#65292;&#24182;&#36890;&#36807;&#20005;&#26684;&#30340;&#20132;&#27969;&#29942;&#39048;&#21644;&#24378;&#22823;&#30340;&#27169;&#22411;&#35268;&#33539;&#21270;&#25104;&#21151;&#23558;&#25968;&#25454;&#36827;&#34892;&#20102;&#32452;&#21512;&#32534;&#30721;&#21644;&#35299;&#30721;&#65292;&#26368;&#32456;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#35299;&#32544;&#24615;&#33021;&#65292;&#24182;&#25552;&#39640;&#20102;&#26631;&#20934;VAE&#27169;&#22411;&#23398;&#20064;&#34920;&#24449;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.18378</link><description>&lt;p&gt;
&#36890;&#36807;&#28508;&#22312;&#37327;&#21270;&#36827;&#34892;&#35299;&#32544;
&lt;/p&gt;
&lt;p&gt;
Disentanglement via Latent Quantization. (arXiv:2305.18378v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18378
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#28508;&#22312;&#37327;&#21270;&#30340;&#26041;&#24335;&#23454;&#29616;&#20102;&#35299;&#32544;&#34920;&#31034;&#23398;&#20064;&#65292;&#24182;&#36890;&#36807;&#20005;&#26684;&#30340;&#20132;&#27969;&#29942;&#39048;&#21644;&#24378;&#22823;&#30340;&#27169;&#22411;&#35268;&#33539;&#21270;&#25104;&#21151;&#23558;&#25968;&#25454;&#36827;&#34892;&#20102;&#32452;&#21512;&#32534;&#30721;&#21644;&#35299;&#30721;&#65292;&#26368;&#32456;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#35299;&#32544;&#24615;&#33021;&#65292;&#24182;&#25552;&#39640;&#20102;&#26631;&#20934;VAE&#27169;&#22411;&#23398;&#20064;&#34920;&#24449;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35299;&#32544;&#34920;&#31034;&#23398;&#20064;&#20013;&#65292;&#27169;&#22411;&#38656;&#35201;&#23558;&#25968;&#25454;&#38598;&#30340;&#22522;&#30784;&#21464;&#21270;&#22240;&#32032;&#20998;&#24320;&#24182;&#29420;&#31435;&#22320;&#34920;&#31034;&#20986;&#26469;&#65292;&#32780;&#27169;&#22411;&#24182;&#27809;&#26377;&#25552;&#20379;&#26377;&#20851;&#36825;&#20123;&#22240;&#32032;&#30340;&#30495;&#23454;&#20449;&#24687;&#65292;&#24402;&#32435;&#20559;&#35265;&#22312;&#23454;&#29616;&#35299;&#32544;&#26041;&#38754;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#26045;&#21152;&#20005;&#26684;&#30340;&#20132;&#27969;&#29942;&#39048;&#21644;&#24378;&#22823;&#30340;&#27169;&#22411;&#35268;&#33539;&#21270;&#65292;&#26500;&#24314;&#20102;&#19968;&#31181;&#26397;&#30528;&#32452;&#21512;&#32534;&#30721;&#21644;&#35299;&#30721;&#25968;&#25454;&#30340;&#24402;&#32435;&#20559;&#35265;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23545;&#28508;&#22312;&#32500;&#24230;&#36827;&#34892;&#21487;&#23398;&#20064;&#30340;&#31163;&#25955;&#32534;&#30721;&#65292;&#24182;&#20026;&#27599;&#20010;&#32500;&#24230;&#24212;&#29992;&#19968;&#20010;&#21333;&#29420;&#30340;&#26631;&#37327;&#30721;&#20070;&#12290;&#28508;&#22312;&#37327;&#21270;&#36843;&#20351;&#32534;&#30721;&#22120;&#22312;&#35768;&#22810;&#25968;&#25454;&#28857;&#19978;&#20351;&#29992;&#23569;&#37327;&#28508;&#22312;&#20540;&#65292;&#20174;&#32780;&#20351;&#35299;&#30721;&#22120;&#33021;&#22815;&#20026;&#27599;&#20010;&#20540;&#20998;&#37197;&#19968;&#33268;&#30340;&#21547;&#20041;&#12290;&#35268;&#33539;&#21270;&#26377;&#21161;&#20110;&#23558;&#27169;&#22411;&#24341;&#21521;&#36825;&#31181;&#31616;&#26126;&#31574;&#30053;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#24191;&#27867;&#24212;&#29992;&#24615;&#65292;&#24182;&#19988;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;&#19968;&#31995;&#21015;&#26631;&#20934;VAE&#27169;&#22411;&#23398;&#20064;&#30340;&#34920;&#24449;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In disentangled representation learning, a model is asked to tease apart a dataset's underlying sources of variation and represent them independently of one another. Since the model is provided with no ground truth information about these sources, inductive biases take a paramount role in enabling disentanglement. In this work, we construct an inductive bias towards compositionally encoding and decoding data by enforcing a harsh communication bottleneck. Concretely, we do this by (i) quantizing the latent space into learnable discrete codes with a separate scalar codebook per dimension and (ii) applying strong model regularization via an unusually high weight decay. Intuitively, the quantization forces the encoder to use a small number of latent values across many datapoints, which in turn enables the decoder to assign a consistent meaning to each value. Regularization then serves to drive the model towards this parsimonious strategy. We demonstrate the broad applicability of this appr
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#30340;Sharpness-Aware Minimization&#31639;&#27861;&#22823;&#22823;&#25552;&#39640;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#32780;&#20854;&#20013;&#35268;&#33539;&#21270;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#65292;&#36890;&#36807;&#31283;&#23450;&#31639;&#27861;&#21644;&#20351;&#20854;&#28418;&#31227;&#27839;&#30528;&#19968;&#31995;&#21015;&#26497;&#23567;&#20540;&#25552;&#21319;&#24615;&#33021;&#65292;&#24182;&#20351;&#31639;&#27861;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.15287</link><description>&lt;p&gt;
&#35268;&#33539;&#21270;&#22312;Sharpness-Aware Minimization&#20013;&#30340;&#20851;&#38190;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
The Crucial Role of Normalization in Sharpness-Aware Minimization. (arXiv:2305.15287v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15287
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#30340;Sharpness-Aware Minimization&#31639;&#27861;&#22823;&#22823;&#25552;&#39640;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#32780;&#20854;&#20013;&#35268;&#33539;&#21270;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#65292;&#36890;&#36807;&#31283;&#23450;&#31639;&#27861;&#21644;&#20351;&#20854;&#28418;&#31227;&#27839;&#30528;&#19968;&#31995;&#21015;&#26497;&#23567;&#20540;&#25552;&#21319;&#24615;&#33021;&#65292;&#24182;&#20351;&#31639;&#27861;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Sharpness-Aware Minimization&#65288;SAM&#65289;&#26159;&#19968;&#31181;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#22120;&#65292;&#26497;&#22823;&#22320;&#25552;&#39640;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;SAM&#26356;&#26032;&#20013;&#35268;&#33539;&#21270;&#36825;&#19968;&#20851;&#38190;&#32452;&#20214;&#30340;&#20316;&#29992;&#65292;&#20174;&#29702;&#35770;&#21644;&#23454;&#39564;&#20004;&#26041;&#38754;&#20998;&#26512;&#20102;&#35268;&#33539;&#21270;&#22312;SAM&#20013;&#23545;&#20984;&#20989;&#25968;&#21644;&#38750;&#20984;&#20989;&#25968;&#30340;&#24433;&#21709;&#65292;&#25581;&#31034;&#20102;&#35268;&#33539;&#21270;&#21457;&#25381;&#30340;&#20004;&#20010;&#20851;&#38190;&#20316;&#29992;&#65306;i&#65289;&#23427;&#26377;&#21161;&#20110;&#31283;&#23450;&#31639;&#27861;&#65307;ii&#65289;&#23427;&#20351;&#31639;&#27861;&#33021;&#22815;&#27839;&#30528;&#19968;&#31995;&#21015;&#26497;&#23567;&#20540;&#65288;&#27969;&#24418;&#65289;&#28418;&#31227;&#65292;&#36825;&#26159;&#26368;&#36817;&#19968;&#20123;&#29702;&#35770;&#24037;&#20316;&#30830;&#23450;&#30340;&#24615;&#33021;&#25552;&#21319;&#20851;&#38190;&#24615;&#36136;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35748;&#20026;&#65292;&#36825;&#20004;&#20010;&#27491;&#24120;&#21270;&#30340;&#23646;&#24615;&#20351;SAM&#23545;&#36229;&#21442;&#25968;&#30340;&#36873;&#25321;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#35777;&#23454;&#20102;SAM&#30340;&#23454;&#29992;&#24615;&#12290;&#21508;&#31181;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sharpness-Aware Minimization (SAM) is a recently proposed gradient-based optimizer (Foret et al., ICLR 2021) that greatly improves the prediction performance of deep neural networks. Consequently, there has been a surge of interest in explaining its empirical success. We focus, in particular, on understanding the role played by normalization, a key component of the SAM updates. We theoretically and empirically study the effect of normalization in SAM for both convex and non-convex functions, revealing two key roles played by normalization: i) it helps in stabilizing the algorithm; and ii) it enables the algorithm to drift along a continuum (manifold) of minima -- a property identified by recent theoretical works that is the key to better performance. We further argue that these two properties of normalization make SAM robust against the choice of hyper-parameters, supporting the practicality of SAM. Our conclusions are backed by various experiments.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#24314;&#31435;&#20102;&#28145;&#24230;&#23398;&#20064;&#22312;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#20013;&#25152;&#20351;&#29992;&#30340;&#28145;&#24230;&#38598;&#25104;&#21644;&#65288;&#21464;&#20998;&#65289;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#32479;&#19968;&#29702;&#35770;&#65292;&#36890;&#36807;&#23558;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#36716;&#21270;&#20026;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#19978;&#30340;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#19968;&#26063;&#20132;&#20114;&#24335;&#28145;&#24230;&#38598;&#25104;&#26041;&#26696;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.15027</link><description>&lt;p&gt;
&#28145;&#24230;&#38598;&#25104;&#19982;&#65288;&#21464;&#20998;&#65289;&#36125;&#21494;&#26031;&#26041;&#27861;&#20043;&#38388;&#30340;&#20005;&#26684;&#32852;&#31995;
&lt;/p&gt;
&lt;p&gt;
A Rigorous Link between Deep Ensembles and (Variational) Bayesian Methods. (arXiv:2305.15027v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15027
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#24314;&#31435;&#20102;&#28145;&#24230;&#23398;&#20064;&#22312;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#20013;&#25152;&#20351;&#29992;&#30340;&#28145;&#24230;&#38598;&#25104;&#21644;&#65288;&#21464;&#20998;&#65289;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#32479;&#19968;&#29702;&#35770;&#65292;&#36890;&#36807;&#23558;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#36716;&#21270;&#20026;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#19978;&#30340;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#19968;&#26063;&#20132;&#20114;&#24335;&#28145;&#24230;&#38598;&#25104;&#26041;&#26696;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#39318;&#27425;&#22312;&#25968;&#23398;&#19978;&#24314;&#31435;&#20102;&#36125;&#21494;&#26031;&#12289;&#21464;&#20998;&#36125;&#21494;&#26031;&#21644;&#38598;&#25104;&#26041;&#27861;&#20043;&#38388;&#30340;&#20005;&#26684;&#32852;&#31995;&#12290;&#20854;&#20851;&#38190;&#27493;&#39588;&#26159;&#23558;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#36890;&#24120;&#36935;&#21040;&#30340;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#37325;&#26032;&#34920;&#36848;&#20026;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#20013;&#30340;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#22312;&#25216;&#26415;&#23618;&#38754;&#19978;&#65292;&#25105;&#20204;&#30340;&#36129;&#29486;&#26159;&#36890;&#36807;Wasserstein&#26799;&#24230;&#27969;&#30340;&#36879;&#38236;&#30740;&#31350;&#24191;&#20041;&#21464;&#20998;&#25512;&#26029;&#12290;&#32467;&#26524;&#26159;&#19968;&#20010;&#32479;&#19968;&#30340;&#29702;&#35770;&#65292;&#28085;&#30422;&#22810;&#31181;&#30475;&#20284;&#26080;&#20851;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#29992;&#20110;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#21253;&#25324;&#28145;&#24230;&#38598;&#25104;&#21644;&#65288;&#21464;&#20998;&#65289;&#36125;&#21494;&#26031;&#26041;&#27861;&#12290;&#36825;&#20026;&#28145;&#24230;&#38598;&#25104;&#32988;&#36807;&#22522;&#20110;&#21442;&#25968;&#21270;&#21464;&#20998;&#25512;&#26029;&#30340;&#31243;&#24207;&#32972;&#21518;&#30340;&#21407;&#22240;&#25552;&#20379;&#20102;&#26032;&#30340;&#35270;&#35282;&#65292;&#24182;&#20801;&#35768;&#25512;&#23548;&#20855;&#26377;&#25910;&#25947;&#20445;&#35777;&#30340;&#26032;&#38598;&#25104;&#26041;&#26696;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#26063;&#20855;&#26377;&#30452;&#25509;&#31867;&#27604;&#20110;&#29289;&#29702;&#23398;&#20013;&#31890;&#23376;&#31995;&#32479;&#20132;&#20114;&#30340;&#20132;&#20114;&#24335;&#28145;&#24230;&#38598;&#25104;&#26469;&#23637;&#31034;&#36825;&#19968;&#28857;&#65292;&#24182;&#25552;&#20379;&#19968;&#31995;&#21015;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We establish the first mathematically rigorous link between Bayesian, variational Bayesian, and ensemble methods. A key step towards this it to reformulate the non-convex optimisation problem typically encountered in deep learning as a convex optimisation in the space of probability measures. On a technical level, our contribution amounts to studying generalised variational inference through the lense of Wasserstein gradient flows. The result is a unified theory of various seemingly disconnected approaches that are commonly used for uncertainty quantification in deep learning -- including deep ensembles and (variational) Bayesian methods. This offers a fresh perspective on the reasons behind the success of deep ensembles over procedures based on parameterised variational inference, and allows the derivation of new ensembling schemes with convergence guarantees. We showcase this by proposing a family of interacting deep ensembles with direct parallels to the interactions of particle sys
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22810;&#31181;&#22686;&#24378;&#27169;&#25311;&#31934;&#30830;&#24230;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#22312;&#27169;&#25311;&#38142;&#30340;&#26411;&#23614;&#36827;&#34892;&#24178;&#39044;&#12289;&#22312;&#27169;&#25311;&#38142;&#30340;&#24320;&#22836;&#36827;&#34892;&#24178;&#39044;&#21644;&#28508;&#31354;&#38388;&#32454;&#21270;&#65292;&#36890;&#36807; W+jets&#30697;&#38453;&#20803;&#20195;&#29702;&#27169;&#25311;&#20197;&#21450;&#20351;&#29992;&#27491;&#21017;&#27969;&#21644;&#29983;&#25104;&#27169;&#22411;&#31561;&#31574;&#30053;&#36827;&#34892;&#30740;&#31350;&#65292;&#23454;&#39564;&#35777;&#26126;&#36825;&#20123;&#26041;&#27861;&#33021;&#26174;&#33879;&#25552;&#39640;&#31934;&#30830;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.07696</link><description>&lt;p&gt;
ELSA -- &#25552;&#39640;&#30896;&#25758;&#27169;&#25311;&#31934;&#30830;&#24230;&#30340;&#22686;&#24378;&#28508;&#31354;&#38388;
&lt;/p&gt;
&lt;p&gt;
ELSA -- Enhanced latent spaces for improved collider simulations. (arXiv:2305.07696v1 [hep-ph] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07696
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22810;&#31181;&#22686;&#24378;&#27169;&#25311;&#31934;&#30830;&#24230;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#22312;&#27169;&#25311;&#38142;&#30340;&#26411;&#23614;&#36827;&#34892;&#24178;&#39044;&#12289;&#22312;&#27169;&#25311;&#38142;&#30340;&#24320;&#22836;&#36827;&#34892;&#24178;&#39044;&#21644;&#28508;&#31354;&#38388;&#32454;&#21270;&#65292;&#36890;&#36807; W+jets&#30697;&#38453;&#20803;&#20195;&#29702;&#27169;&#25311;&#20197;&#21450;&#20351;&#29992;&#27491;&#21017;&#27969;&#21644;&#29983;&#25104;&#27169;&#22411;&#31561;&#31574;&#30053;&#36827;&#34892;&#30740;&#31350;&#65292;&#23454;&#39564;&#35777;&#26126;&#36825;&#20123;&#26041;&#27861;&#33021;&#26174;&#33879;&#25552;&#39640;&#31934;&#30830;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#25311;&#22312;&#30896;&#25758;&#29289;&#29702;&#20013;&#20855;&#26377;&#20851;&#38190;&#20316;&#29992;&#12290;&#25105;&#20204;&#25506;&#32034;&#26426;&#22120;&#23398;&#20064;&#22686;&#24378;&#27169;&#25311;&#31934;&#30830;&#24230;&#30340;&#21508;&#31181;&#26041;&#27861;&#65292;&#21253;&#25324;&#22312;&#27169;&#25311;&#38142;&#30340;&#26411;&#23614;&#36827;&#34892;&#24178;&#39044;&#65288;&#37325;&#26032;&#21152;&#26435;&#65289;&#12289;&#22312;&#27169;&#25311;&#38142;&#30340;&#24320;&#22836;&#36827;&#34892;&#24178;&#39044;&#65288;&#39044;&#22788;&#29702;&#65289;&#20197;&#21450;&#22312;&#26411;&#23614;&#21644;&#24320;&#22836;&#20043;&#38388;&#24314;&#31435;&#32852;&#31995;&#65288;&#28508;&#31354;&#38388;&#32454;&#21270;&#65289;&#12290;&#20026;&#20102;&#28165;&#26224;&#22320;&#35828;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#27491;&#21017;&#27969;&#30340;W+jets&#30697;&#38453;&#20803;&#20195;&#29702;&#27169;&#25311;&#20316;&#20026;&#21407;&#22411;&#31034;&#20363;&#12290;&#39318;&#20808;&#65292;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#22312;&#25968;&#25454;&#31354;&#38388;&#20013;&#30830;&#23450;&#26435;&#37325;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#25968;&#25454;&#31354;&#38388;&#26435;&#37325;&#22238;&#25512;&#21040;&#28508;&#31354;&#38388;&#20197;&#20135;&#29983;&#26080;&#26435;&#37325;&#30340;&#26679;&#26412;&#65292;&#24182;&#20351;&#29992;&#21704;&#23494;&#39039;&#33945;&#29305;&#21345;&#32599;&#20351;&#29992;&#28508;&#31354;&#38388;&#32454;&#21270;&#65288;LASER&#65289;&#21327;&#35758;&#12290;&#21478;&#19968;&#31181;&#26041;&#27861;&#26159;&#22686;&#24378;&#27491;&#21017;&#27969;&#65292;&#35813;&#26041;&#27861;&#20801;&#35768;&#22312;&#28508;&#31354;&#38388;&#21644;&#30446;&#26631;&#31354;&#38388;&#20013;&#20855;&#26377;&#19981;&#21516;&#30340;&#32500;&#24230;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#21508;&#31181;&#39044;&#22788;&#29702;&#31574;&#30053;&#65292;&#21253;&#25324;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#22686;&#24378;&#26679;&#26412;&#30340;&#26032;&#30340;&#36890;&#29992;&#26041;&#27861;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20123;&#26041;&#27861;&#26174;&#30528;&#25552;&#39640;&#20102;W+jets&#30697;&#38453;&#20803;&#27169;&#25311;&#30340;&#31934;&#30830;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Simulations play a key role for inference in collider physics. We explore various approaches for enhancing the precision of simulations using machine learning, including interventions at the end of the simulation chain (reweighting), at the beginning of the simulation chain (pre-processing), and connections between the end and beginning (latent space refinement). To clearly illustrate our approaches, we use W+jets matrix element surrogate simulations based on normalizing flows as a prototypical example. First, weights in the data space are derived using machine learning classifiers. Then, we pull back the data-space weights to the latent space to produce unweighted examples and employ the Latent Space Refinement (LASER) protocol using Hamiltonian Monte Carlo. An alternative approach is an augmented normalizing flow, which allows for different dimensions in the latent and target spaces. These methods are studied for various pre-processing strategies, including a new and general method f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#30340;&#26032;&#29702;&#35770;&#35299;&#37322;&#21644;&#35777;&#26126;&#65292;&#21363;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#21487;&#20197;&#36890;&#36807;&#36830;&#32493;&#26041;&#24335;&#38544;&#24335;&#20248;&#21270;&#30830;&#23450;&#24615;&#31574;&#30053;&#65292;&#24182;&#25351;&#20986;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#25506;&#32034;&#30340;&#23454;&#36136;&#26159;&#35745;&#31639;&#24403;&#21069;&#31574;&#30053;&#25910;&#30410;&#30340;&#36830;&#32493;&#20989;&#25968;&#65292;&#31574;&#30053;&#30340;&#26041;&#24046;&#24212;&#35813;&#26159;&#21382;&#21490;&#20381;&#36182;&#24615;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2305.06851</link><description>&lt;p&gt;
&#36890;&#36807;&#36830;&#32493;&#26041;&#24335;&#38544;&#24335;&#20248;&#21270;&#30340;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Policy Gradient Algorithms Implicitly Optimize by Continuation. (arXiv:2305.06851v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06851
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#30340;&#26032;&#29702;&#35770;&#35299;&#37322;&#21644;&#35777;&#26126;&#65292;&#21363;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#21487;&#20197;&#36890;&#36807;&#36830;&#32493;&#26041;&#24335;&#38544;&#24335;&#20248;&#21270;&#30830;&#23450;&#24615;&#31574;&#30053;&#65292;&#24182;&#25351;&#20986;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#25506;&#32034;&#30340;&#23454;&#36136;&#26159;&#35745;&#31639;&#24403;&#21069;&#31574;&#30053;&#25910;&#30410;&#30340;&#36830;&#32493;&#20989;&#25968;&#65292;&#31574;&#30053;&#30340;&#26041;&#24046;&#24212;&#35813;&#26159;&#21382;&#21490;&#20381;&#36182;&#24615;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#30452;&#25509;&#31574;&#30053;&#20248;&#21270;&#36890;&#24120;&#36890;&#36807;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#35299;&#20915;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19978;&#21319;&#20248;&#21270;&#31574;&#30053;&#21442;&#25968;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#29702;&#35770;&#35299;&#37322;&#21644;&#35777;&#26126;&#36825;&#20123;&#31639;&#27861;&#30340;&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23558;&#30452;&#25509;&#31574;&#30053;&#20248;&#21270;&#38382;&#39064;&#24314;&#31435;&#22312;&#20248;&#21270;&#36830;&#32493;&#26694;&#26550;&#19979;&#12290;&#21518;&#32773;&#26159;&#19968;&#31181;&#29992;&#20110;&#20248;&#21270;&#38750;&#20984;&#20989;&#25968;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#20197;&#36830;&#32493;&#30340;&#26367;&#20195;&#30446;&#26631;&#20989;&#25968;&#24207;&#21015;&#20026;&#22522;&#30784;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20248;&#21270;&#20223;&#23556;&#39640;&#26031;&#31574;&#30053;&#24182;&#25191;&#34892;&#29109;&#27491;&#21017;&#21270;&#21487;&#20197;&#35299;&#37322;&#20026;&#36890;&#36807;&#36830;&#32493;&#38544;&#24335;&#22320;&#20248;&#21270;&#30830;&#23450;&#24615;&#31574;&#30053;&#12290;&#22522;&#20110;&#36825;&#20123;&#29702;&#35770;&#32467;&#26524;&#65292;&#25105;&#20204;&#35748;&#20026;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#20013;&#30340;&#25506;&#32034;&#21253;&#25324;&#35745;&#31639;&#24403;&#21069;&#30340;&#31574;&#30053;&#25910;&#30410;&#30340;&#36830;&#32493;&#20989;&#25968;&#65292;&#31574;&#30053;&#30340;&#26041;&#24046;&#24212;&#35813;&#26159;&#21382;&#21490;&#20381;&#36182;&#24615;&#20989;&#25968;&#65292;&#20197;&#36991;&#20813;&#23616;&#37096;&#26368;&#20540;&#32780;&#19981;&#26159;&#20165;&#20165;&#26368;&#22823;&#21270;&#25919;&#31574;&#30340;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
Direct policy optimization in reinforcement learning is usually solved with policy-gradient algorithms, which optimize policy parameters via stochastic gradient ascent. This paper provides a new theoretical interpretation and justification of these algorithms. First, we formulate direct policy optimization in the optimization by continuation framework. The latter is a framework for optimizing nonconvex functions where a sequence of surrogate objective functions, called continuations, are locally optimized. Second, we show that optimizing affine Gaussian policies and performing entropy regularization can be interpreted as implicitly optimizing deterministic policies by continuation. Based on these theoretical results, we argue that exploration in policy-gradient algorithms consists in computing a continuation of the return of the policy at hand, and that the variance of policies should be history-dependent functions adapted to avoid local extrema rather than to maximize the return of th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#23545;&#20110;&#25968;&#25454;&#29420;&#31435;&#30340;&#25209;&#22788;&#29702;&#26041;&#26696;&#65292;&#20960;&#20046;&#25152;&#26377;&#23567;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#37117;&#33021;&#22815;&#20248;&#21270;&#65292;&#20854;&#20013;&#21253;&#25324;&#25152;&#26377;&#30340;&#30830;&#23450;&#24615;&#26041;&#26696;&#21644;&#38543;&#26426;&#26041;&#26696;&#12290;&#27492;&#22806;&#65292;&#25152;&#26377;&#36825;&#26679;&#30340;&#25209;&#37327;&#35843;&#24230;&#37117;&#33021;&#36798;&#21040;&#26368;&#20248;&#30340;&#19968;&#33324;&#21270;&#35823;&#24046;&#19979;&#38480;&#12290;</title><link>http://arxiv.org/abs/2305.02247</link><description>&lt;p&gt;
&#27627;&#19981;&#30031;&#24807;&#22320;&#36873;&#25321;&#65306;&#20960;&#20046;&#25152;&#26377;&#30340;&#23567;&#25209;&#37327;&#35757;&#32451;&#26041;&#26696;&#37117;&#33021;&#22815;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Select without Fear: Almost All Mini-Batch Schedules Generalize Optimally. (arXiv:2305.02247v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02247
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#23545;&#20110;&#25968;&#25454;&#29420;&#31435;&#30340;&#25209;&#22788;&#29702;&#26041;&#26696;&#65292;&#20960;&#20046;&#25152;&#26377;&#23567;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#37117;&#33021;&#22815;&#20248;&#21270;&#65292;&#20854;&#20013;&#21253;&#25324;&#25152;&#26377;&#30340;&#30830;&#23450;&#24615;&#26041;&#26696;&#21644;&#38543;&#26426;&#26041;&#26696;&#12290;&#27492;&#22806;&#65292;&#25152;&#26377;&#36825;&#26679;&#30340;&#25209;&#37327;&#35843;&#24230;&#37117;&#33021;&#36798;&#21040;&#26368;&#20248;&#30340;&#19968;&#33324;&#21270;&#35823;&#24046;&#19979;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#24102;&#26377;&#30830;&#23450;&#24615;&#25110;&#38543;&#26426;&#24615;&#12289;&#25968;&#25454;&#29420;&#31435;&#30340;&#23567;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#21305;&#37197;&#19978;&#19979;&#19968;&#33324;&#21270;&#35823;&#24046;&#30028;&#38480;&#65292;&#20294;&#25209;&#37327;&#36873;&#25321;&#35268;&#21017;&#26159;&#20219;&#24847;&#30340;&#12290;&#25105;&#20204;&#32771;&#34385;&#20809;&#28369;&#30340;Lipschitz-&#20984;&#24615;/&#38750;&#20984;&#24615;/&#24378;&#20984;&#24615;&#25439;&#22833;&#20989;&#25968;&#65292;&#24182;&#35777;&#26126;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#32463;&#20856;&#19978;&#38480;&#30028;&#38480;&#20063;&#36866;&#29992;&#20110;&#36825;&#26679;&#20219;&#24847;&#30340;&#38750;&#33258;&#36866;&#24212;&#25209;&#37327;&#35843;&#24230;&#65292;&#21253;&#25324;&#25152;&#26377;&#30830;&#23450;&#24615;&#30340;&#35843;&#24230;&#26041;&#26696;&#12290;&#36827;&#19968;&#27493;&#22320;&#65292;&#23545;&#20110;&#20984;&#21644;&#24378;&#20984;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#25105;&#20204;&#30452;&#25509;&#35777;&#26126;&#20102;&#22312;&#19978;&#36848;&#25209;&#37327;&#35843;&#24230;&#31867;&#19978;&#19968;&#33268;&#30340;&#19968;&#33324;&#21270;&#35823;&#24046;&#19979;&#30340;&#21305;&#37197;&#19979;&#38480;&#30028;&#38480;&#65292;&#34920;&#26126;&#25152;&#26377;&#36825;&#26679;&#30340;&#25209;&#37327;&#35843;&#24230;&#37117;&#33021;&#36798;&#21040;&#26368;&#20248;&#30340;&#19968;&#33324;&#21270;&#12290;&#26368;&#21518;&#65292;&#23545;&#20110;&#20809;&#28369;&#30340;&#65288;&#38750;Lipschitz&#65289;&#38750;&#20984;&#24615;&#25439;&#22833;&#20989;&#25968;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#25152;&#32771;&#34385;&#30340;&#31867;&#21035;&#20869;&#65292;&#21253;&#25324;&#25152;&#26377;&#38543;&#26426;&#25209;&#22788;&#29702;&#26041;&#26696;&#65292;&#20840;&#25209;&#37327;&#65288;&#30830;&#23450;&#24615;&#65289;&#26799;&#24230;&#19979;&#38477;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We establish matching upper and lower generalization error bounds for mini-batch Gradient Descent (GD) training with either deterministic or stochastic, data-independent, but otherwise arbitrary batch selection rules. We consider smooth Lipschitz-convex/nonconvex/strongly-convex loss functions, and show that classical upper bounds for Stochastic GD (SGD) also hold verbatim for such arbitrary nonadaptive batch schedules, including all deterministic ones. Further, for convex and strongly-convex losses we prove matching lower bounds directly on the generalization error uniform over the aforementioned class of batch schedules, showing that all such batch schedules generalize optimally. Lastly, for smooth (non-Lipschitz) nonconvex losses, we show that full-batch (deterministic) GD is essentially optimal, among all possible batch schedules within the considered class, including all stochastic ones.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#38024;&#23545;&#28145;&#24230;&#39640;&#26031;&#27169;&#22411;&#30340;&#29305;&#24449;&#21508;&#21521;&#24322;&#24615;&#23637;&#24320;&#30740;&#31350;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#31532;&#19968;&#23618;&#29305;&#24449;&#34892;&#20043;&#38388;&#20801;&#35768;&#23384;&#22312;&#30456;&#20851;&#24615;&#21487;&#20197;&#20419;&#36827;&#27867;&#21270;&#65292;&#32780;&#21518;&#32493;&#23618;&#30340;&#32467;&#26500;&#36890;&#24120;&#26159;&#19981;&#21033;&#30340;&#12290;</title><link>http://arxiv.org/abs/2303.00564</link><description>&lt;p&gt;
&#28145;&#24230;&#32467;&#26500;&#39640;&#26031;&#29305;&#24449;&#27169;&#22411;&#30340;&#23398;&#20064;&#26354;&#32447;
&lt;/p&gt;
&lt;p&gt;
Learning curves for deep structured Gaussian feature models. (arXiv:2303.00564v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.00564
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#38024;&#23545;&#28145;&#24230;&#39640;&#26031;&#27169;&#22411;&#30340;&#29305;&#24449;&#21508;&#21521;&#24322;&#24615;&#23637;&#24320;&#30740;&#31350;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#31532;&#19968;&#23618;&#29305;&#24449;&#34892;&#20043;&#38388;&#20801;&#35768;&#23384;&#22312;&#30456;&#20851;&#24615;&#21487;&#20197;&#20419;&#36827;&#27867;&#21270;&#65292;&#32780;&#21518;&#32493;&#23618;&#30340;&#32467;&#26500;&#36890;&#24120;&#26159;&#19981;&#21033;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#28145;&#24230;&#23398;&#20064;&#29702;&#35770;&#20013;&#23545;&#20110;&#22810;&#23618;&#39640;&#26031;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#30340;&#27867;&#21270;&#24615;&#33021;&#20998;&#26512;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#24456;&#23569;&#26377;&#30740;&#31350;&#32771;&#34385;&#29305;&#24449;&#21508;&#21521;&#24322;&#24615;&#30340;&#24433;&#21709;&#65307;&#22823;&#22810;&#25968;&#27169;&#22411;&#37117;&#20551;&#35774;&#29305;&#24449;&#26159;&#20351;&#29992;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#39640;&#26031;&#26435;&#37325;&#29983;&#25104;&#30340;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#20026;&#20855;&#26377;&#35768;&#22810;&#23618;&#32467;&#26500;&#39640;&#26031;&#29305;&#24449;&#30340;&#27169;&#22411;&#23548;&#20986;&#20102;&#23398;&#20064;&#26354;&#32447;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#20801;&#35768;&#31532;&#19968;&#23618;&#29305;&#24449;&#30340;&#34892;&#20043;&#38388;&#23384;&#22312;&#30456;&#20851;&#24615;&#21487;&#20419;&#36827;&#27867;&#21270;&#65292;&#32780;&#21518;&#32493;&#23618;&#30340;&#32467;&#26500;&#36890;&#24120;&#26159;&#19981;&#21033;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25581;&#31034;&#20102;&#26435;&#37325;&#32467;&#26500;&#22914;&#20309;&#24433;&#21709;&#21487;&#35299;&#27169;&#22411;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, significant attention in deep learning theory has been devoted to analyzing the generalization performance of models with multiple layers of Gaussian random features. However, few works have considered the effect of feature anisotropy; most assume that features are generated using independent and identically distributed Gaussian weights. Here, we derive learning curves for models with many layers of structured Gaussian features. We show that allowing correlations between the rows of the first layer of features can aid generalization, while structure in later layers is generally detrimental. Our results shed light on how weight structure affects generalization in a simple class of solvable models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#31616;&#21270;&#65292;&#25552;&#20986;&#20102;&#40654;&#26364;&#27491;&#24120;&#22352;&#26631;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#21487;&#29992;&#20110;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#30340;&#23376;&#27969;&#24418;&#20248;&#21270;&#65292;&#24182;&#20026;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#65292;&#26080;&#38656;&#26174;&#24335;&#30697;&#38453;&#27714;&#36870;&#12290;</title><link>http://arxiv.org/abs/2302.09738</link><description>&lt;p&gt;
&#31616;&#21270;&#22522;&#20110;&#21160;&#37327;&#30340;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Simplifying Momentum-based Riemannian Submanifold Optimization. (arXiv:2302.09738v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09738
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#31616;&#21270;&#65292;&#25552;&#20986;&#20102;&#40654;&#26364;&#27491;&#24120;&#22352;&#26631;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#21487;&#29992;&#20110;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#30340;&#23376;&#27969;&#24418;&#20248;&#21270;&#65292;&#24182;&#20026;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#65292;&#26080;&#38656;&#26174;&#24335;&#30697;&#38453;&#27714;&#36870;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24102;&#26377;&#21160;&#37327;&#30340;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;&#22312;&#35745;&#31639;&#19978;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#30830;&#20445;&#36845;&#20195;&#20445;&#25345;&#22312;&#23376;&#27969;&#24418;&#19978;&#36890;&#24120;&#38656;&#35201;&#35299;&#20915;&#22256;&#38590;&#30340;&#24494;&#20998;&#26041;&#31243;&#12290;&#26412;&#25991;&#38024;&#23545;&#20855;&#26377;&#20223;&#23556;&#19981;&#21464;&#24230;&#37327;&#30340;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#30340;&#23376;&#27969;&#24418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#31616;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#40654;&#26364;&#27491;&#24120;&#22352;&#26631;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#21487;&#20197;&#23558;&#38382;&#39064;&#21160;&#24577;&#22320;&#31616;&#21270;&#20026;&#27431;&#20960;&#37324;&#24471;&#26080;&#32422;&#26463;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#26469;&#35299;&#37322;&#21644;&#31616;&#21270;&#29616;&#26377;&#30340;&#32467;&#26500;&#21270;&#21327;&#26041;&#24046;&#26041;&#27861;&#65292;&#24182;&#20026;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#65292;&#32780;&#26080;&#38656;&#26174;&#24335;&#30697;&#38453;&#27714;&#36870;&#12290;
&lt;/p&gt;
&lt;p&gt;
Riemannian submanifold optimization with momentum is computationally challenging because ensuring iterates remain on the submanifold often requires solving difficult differential equations. We simplify such optimization algorithms for the submanifold of symmetric positive-definite matrices with the affine invariant metric. We propose a generalized version of the Riemannian normal coordinates which dynamically trivializes the problem into a Euclidean unconstrained problem. We use our approach to explain and simplify existing approaches for structured covariances and develop efficient second-order optimizers for deep learning without explicit matrix inverses.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#37325;&#21442;&#25968;&#21270;&#19979;&#30340;&#19981;&#21464;&#24615;&#65292;&#22914;&#26524;&#26174;&#24335;&#22320;&#34920;&#31034;&#24230;&#37327;&#24182;&#20351;&#29992;&#27491;&#30830;&#30340;&#30456;&#20851;&#21464;&#25442;&#35268;&#21017;&#65292;&#21017;&#19981;&#21464;&#24615;&#26159;&#20219;&#20309;&#31070;&#32463;&#32593;&#32476;&#30340;&#22266;&#26377;&#23646;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.07384</link><description>&lt;p&gt;
&#37325;&#21442;&#25968;&#21270;&#19979;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#31354;&#38388;&#30340;&#20960;&#20309;&#23398;
&lt;/p&gt;
&lt;p&gt;
The Geometry of Neural Nets' Parameter Spaces Under Reparametrization. (arXiv:2302.07384v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07384
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#37325;&#21442;&#25968;&#21270;&#19979;&#30340;&#19981;&#21464;&#24615;&#65292;&#22914;&#26524;&#26174;&#24335;&#22320;&#34920;&#31034;&#24230;&#37327;&#24182;&#20351;&#29992;&#27491;&#30830;&#30340;&#30456;&#20851;&#21464;&#25442;&#35268;&#21017;&#65292;&#21017;&#19981;&#21464;&#24615;&#26159;&#20219;&#20309;&#31070;&#32463;&#32593;&#32476;&#30340;&#22266;&#26377;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#37325;&#21442;&#25968;&#21270;&#26159;&#25913;&#21892;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#30340;&#19968;&#31181;&#27969;&#34892;&#26041;&#27861;&#65292;&#20294;&#20063;&#21487;&#33021;&#23384;&#22312;&#38382;&#39064;&#65292;&#22914;&#22312;Hessian&#24179;&#22374;&#24230;&#27979;&#37327;&#12289;&#20248;&#21270;&#36712;&#36857;&#21644;&#27010;&#29575;&#23494;&#24230;&#27169;&#24335;&#31561;&#26041;&#38754;&#24341;&#20837;&#19981;&#19968;&#33268;&#24615;&#12290;&#36825;&#20351;&#24471;&#19979;&#28216;&#20998;&#26512;&#21464;&#24471;&#26356;&#20026;&#22797;&#26434;&#65306;&#20363;&#22914;&#65292;&#30001;&#20110;&#20219;&#24847;&#30340;&#37325;&#21442;&#25968;&#21270;&#37117;&#21487;&#20197;&#25913;&#21464;&#20108;&#32773;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#22240;&#27492;&#26080;&#27861;&#26126;&#30830;&#22320;&#23558;&#24179;&#22374;&#24230;&#19982;&#27867;&#21270;&#32852;&#31995;&#36215;&#26469;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#40654;&#26364;&#20960;&#20309;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#37325;&#21442;&#25968;&#21270;&#19979;&#30340;&#19981;&#21464;&#24615;&#12290;&#20174;&#36825;&#20010;&#35282;&#24230;&#26469;&#30475;&#65292;&#22914;&#26524;&#25105;&#20204;&#26174;&#24335;&#22320;&#34920;&#31034;&#24230;&#37327;&#24182;&#20351;&#29992;&#27491;&#30830;&#30340;&#30456;&#20851;&#21464;&#25442;&#35268;&#21017;&#65292;&#37027;&#20040;&#19981;&#21464;&#24615;&#26159;&#20219;&#20309;&#31070;&#32463;&#32593;&#32476;&#30340;&#22266;&#26377;&#23646;&#24615;&#12290;&#36825;&#19968;&#28857;&#24456;&#37325;&#35201;&#65292;&#22240;&#20026;&#23613;&#31649;&#24230;&#37327;&#22987;&#32456;&#23384;&#22312;&#65292;&#20294;&#36890;&#24120;&#34987;&#38544;&#24335;&#22320;&#20551;&#23450;&#20026;&#21333;&#20301;&#30697;&#38453;&#65292;&#24182;&#22240;&#27492;&#20174;&#31526;&#21495;&#20013;&#30465;&#30053;&#65292;&#28982;&#21518;&#22312;&#37325;&#21442;&#25968;&#21270;&#19979;&#20002;&#22833;&#20102;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#34913;&#37327;&#24179;&#22374;&#24230;&#25152;&#24102;&#26469;&#30340;&#21551;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model reparametrization, which follows the change-of-variable rule of calculus, is a popular way to improve the training of neural nets. But it can also be problematic since it can induce inconsistencies in, e.g., Hessian-based flatness measures, optimization trajectories, and modes of probability densities. This complicates downstream analyses: e.g. one cannot definitively relate flatness with generalization since arbitrary reparametrization changes their relationship. In this work, we study the invariance of neural nets under reparametrization from the perspective of Riemannian geometry. From this point of view, invariance is an inherent property of any neural net if one explicitly represents the metric and uses the correct associated transformation rules. This is important since although the metric is always present, it is often implicitly assumed as identity, and thus dropped from the notation, then lost under reparametrization. We discuss implications for measuring the flatness of
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20998;&#25968;&#30340;&#26465;&#20214;&#27169;&#22411;&#20013;&#23398;&#20064;&#34920;&#31034;&#30340;&#32467;&#26500;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#25968;&#23398;&#24418;&#24335;&#21270;&#34920;&#36798;&#27010;&#24565;&#34987;&#32534;&#30721;&#20026;&#34920;&#31034;&#31354;&#38388;&#23376;&#31354;&#38388;&#30340;&#24605;&#24819;&#12290;&#21033;&#29992;&#36825;&#20010;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#32473;&#23450;&#27010;&#24565;&#23545;&#24212;&#30340;&#34920;&#31034;&#37096;&#20998;&#65292;&#24182;&#36890;&#36807;&#20195;&#25968;&#25805;&#20316;&#25805;&#32437;&#27169;&#22411;&#25152;&#34920;&#36798;&#30340;&#27010;&#24565;&#12290;</title><link>http://arxiv.org/abs/2302.03693</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#30340;&#26465;&#20214;&#27169;&#22411;&#30340;&#27010;&#24565;&#20195;&#25968;
&lt;/p&gt;
&lt;p&gt;
Concept Algebra for Score-Based Conditional Models. (arXiv:2302.03693v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03693
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20998;&#25968;&#30340;&#26465;&#20214;&#27169;&#22411;&#20013;&#23398;&#20064;&#34920;&#31034;&#30340;&#32467;&#26500;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#25968;&#23398;&#24418;&#24335;&#21270;&#34920;&#36798;&#27010;&#24565;&#34987;&#32534;&#30721;&#20026;&#34920;&#31034;&#31354;&#38388;&#23376;&#31354;&#38388;&#30340;&#24605;&#24819;&#12290;&#21033;&#29992;&#36825;&#20010;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#32473;&#23450;&#27010;&#24565;&#23545;&#24212;&#30340;&#34920;&#31034;&#37096;&#20998;&#65292;&#24182;&#36890;&#36807;&#20195;&#25968;&#25805;&#20316;&#25805;&#32437;&#27169;&#22411;&#25152;&#34920;&#36798;&#30340;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25991;&#26412;&#24341;&#23548;&#29983;&#25104;&#27169;&#22411;&#20013;&#23398;&#20064;&#34920;&#31034;&#30340;&#32467;&#26500;&#65292;&#37325;&#28857;&#20851;&#27880;&#22522;&#20110;&#20998;&#25968;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#32858;&#28966;&#20110;&#27010;&#24565;&#34987;&#32534;&#30721;&#20026;&#26576;&#31181;&#34920;&#31034;&#31354;&#38388;&#30340;&#23376;&#31354;&#38388;&#65288;&#25110;&#26041;&#21521;&#65289;&#30340;&#24605;&#24819;&#65292;&#24182;&#24320;&#21457;&#20102;&#36825;&#20010;&#24605;&#24819;&#30340;&#25968;&#23398;&#24418;&#24335;&#21270;&#12290;&#21033;&#29992;&#36825;&#20010;&#24418;&#24335;&#21270;&#26041;&#27861;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26377;&#19968;&#20010;&#33258;&#28982;&#30340;&#34920;&#31034;&#36873;&#25321;&#20855;&#26377;&#36825;&#31181;&#24615;&#36136;&#65292;&#24182;&#19988;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#19982;&#32473;&#23450;&#27010;&#24565;&#23545;&#24212;&#30340;&#34920;&#31034;&#37096;&#20998;&#12290;&#29305;&#21035;&#26159;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#23545;&#34920;&#31034;&#30340;&#20195;&#25968;&#25805;&#20316;&#26469;&#25805;&#32437;&#27169;&#22411;&#25152;&#34920;&#36798;&#30340;&#27010;&#24565;&#12290;&#25105;&#20204;&#20351;&#29992;&#31283;&#23450;&#25193;&#25955;&#22312;&#25991;&#26412;&#24341;&#23548;&#22270;&#20687;&#29983;&#25104;&#30340;&#31034;&#20363;&#20013;&#28436;&#31034;&#20102;&#36825;&#20010;&#24605;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper concerns the structure of learned representations in text-guided generative models, focusing on score-based models. Here, we focus on the idea that concepts are encoded as subspaces (or directions) of some representation space. We develop a mathematical formalization of this idea.Using this formalism, we show there's a natural choice of representation with this property, and we develop a simple method for identifying the part of the representation corresponding to a given concept. In particular, this allows us to manipulate the concepts expressed by the model through algebraic manipulation of the representation. We demonstrate the idea with examples text-guided image generation, using Stable Diffusion.
&lt;/p&gt;</description></item><item><title>ResMem&#26159;&#19968;&#31181;&#36890;&#36807;&#26174;&#24335;&#35760;&#24518;&#26469;&#25913;&#21892;&#27169;&#22411;&#27867;&#21270;&#33021;&#21147;&#30340;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#25311;&#21512;&#27169;&#22411;&#30340;&#27531;&#24046;&#26469;&#23454;&#29616;&#12290;&#22312;&#21508;&#31181;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;ResMem&#19968;&#33268;&#22320;&#25913;&#21892;&#20102;&#21407;&#22987;&#39044;&#27979;&#27169;&#22411;&#30340;&#27979;&#35797;&#38598;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2302.01576</link><description>&lt;p&gt;
ResMem&#65306;&#23398;&#20064;&#21487;&#20197;&#30340;&#65292;&#35760;&#20303;&#21097;&#19979;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
ResMem: Learn what you can and memorize the rest. (arXiv:2302.01576v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.01576
&lt;/p&gt;
&lt;p&gt;
ResMem&#26159;&#19968;&#31181;&#36890;&#36807;&#26174;&#24335;&#35760;&#24518;&#26469;&#25913;&#21892;&#27169;&#22411;&#27867;&#21270;&#33021;&#21147;&#30340;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#25311;&#21512;&#27169;&#22411;&#30340;&#27531;&#24046;&#26469;&#23454;&#29616;&#12290;&#22312;&#21508;&#31181;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;ResMem&#19968;&#33268;&#22320;&#25913;&#21892;&#20102;&#21407;&#22987;&#39044;&#27979;&#27169;&#22411;&#30340;&#27979;&#35797;&#38598;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#25152;&#23637;&#29616;&#20986;&#30340;&#20196;&#20154;&#30633;&#30446;&#30340;&#27867;&#21270;&#24615;&#33021;&#37096;&#20998;&#24402;&#21151;&#20110;&#20854;&#38544;&#24335;&#35760;&#24518;&#22797;&#26434;&#30340;&#35757;&#32451;&#27169;&#24335;&#30340;&#33021;&#21147;&#12290;&#21463;&#27492;&#21551;&#21457;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#19968;&#31181;&#25913;&#36827;&#27169;&#22411;&#27867;&#21270;&#33021;&#21147;&#30340;&#26032;&#26426;&#21046;&#65292;&#36890;&#36807;&#26174;&#24335;&#35760;&#24518;&#26469;&#23454;&#29616;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#27531;&#24046;&#35760;&#24518;&#65288;ResMem&#65289;&#31639;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#36890;&#36807;&#29992;&#22522;&#20110;$k$&#26368;&#36817;&#37051;&#30340;&#22238;&#24402;&#22120;&#25311;&#21512;&#27169;&#22411;&#30340;&#27531;&#24046;&#26469;&#22686;&#21152;&#29616;&#26377;&#39044;&#27979;&#27169;&#22411;&#65288;&#20363;&#22914;&#31070;&#32463;&#32593;&#32476;&#65289;&#30340;&#26041;&#27861;&#12290;&#26368;&#32456;&#39044;&#27979;&#26159;&#21407;&#22987;&#27169;&#22411;&#21644;&#25311;&#21512;&#30340;&#27531;&#24046;&#22238;&#24402;&#22120;&#30340;&#21644;&#12290;&#36890;&#36807;&#26500;&#36896;&#65292;ResMem&#21487;&#20197;&#26174;&#24335;&#22320;&#35760;&#20303;&#35757;&#32451;&#26631;&#31614;&#12290;&#23454;&#35777;&#19978;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;ResMem&#22312;&#21508;&#31181;&#26631;&#20934;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#22522;&#20934;&#27979;&#35797;&#20013;&#19968;&#33268;&#22320;&#25913;&#21892;&#20102;&#21407;&#22987;&#39044;&#27979;&#27169;&#22411;&#30340;&#27979;&#35797;&#38598;&#27867;&#21270;&#33021;&#21147;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#31616;&#21270;&#30340;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#65292;&#24182;&#20005;&#26684;&#35777;&#26126;&#20102;ResMem&#30456;&#23545;&#20110;&#22522;&#26412;&#39044;&#27979;&#27169;&#22411;&#20855;&#26377;&#26356;&#26377;&#21033;&#30340;&#27979;&#35797;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;
The impressive generalization performance of modern neural networks is attributed in part to their ability to implicitly memorize complex training patterns. Inspired by this, we explore a novel mechanism to improve model generalization via explicit memorization. Specifically, we propose the residual-memorization (ResMem) algorithm, a new method that augments an existing prediction model (e.g. a neural network) by fitting the model's residuals with a $k$-nearest neighbor based regressor. The final prediction is then the sum of the original model and the fitted residual regressor. By construction, ResMem can explicitly memorize the training labels. Empirically, we show that ResMem consistently improves the test set generalization of the original prediction model across various standard vision and natural language processing benchmarks. Theoretically, we formulate a stylized linear regression problem and rigorously show that ResMem results in a more favorable test risk over the base predi
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#38543;&#26426;&#32852;&#37030;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#65292;&#32771;&#34385;&#20102;&#20855;&#26377;&#21452;&#37325;&#23545;&#25239;&#24615;&#30340;&#35774;&#32622;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20219;&#20309;&#32852;&#37030;&#36172;&#21338;&#31639;&#27861;&#30340;&#36951;&#25022;&#19979;&#30028;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#25509;&#36817;&#26368;&#20248;&#30340;&#31639;&#27861;FEDEXP3&#12290;&#35813;&#31639;&#27861;&#35299;&#20915;&#20102;&#20043;&#21069;&#30340;&#24320;&#25918;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2301.09223</link><description>&lt;p&gt;
&#21452;&#37325;&#23545;&#25239;&#24615;&#32852;&#37030;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Doubly Adversarial Federated Bandits. (arXiv:2301.09223v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.09223
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#38543;&#26426;&#32852;&#37030;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#65292;&#32771;&#34385;&#20102;&#20855;&#26377;&#21452;&#37325;&#23545;&#25239;&#24615;&#30340;&#35774;&#32622;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20219;&#20309;&#32852;&#37030;&#36172;&#21338;&#31639;&#27861;&#30340;&#36951;&#25022;&#19979;&#30028;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#25509;&#36817;&#26368;&#20248;&#30340;&#31639;&#27861;FEDEXP3&#12290;&#35813;&#31639;&#27861;&#35299;&#20915;&#20102;&#20043;&#21069;&#30340;&#24320;&#25918;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#38543;&#26426;&#32852;&#37030;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#65292;&#22810;&#20010;&#20195;&#29702;&#36890;&#36807;&#36890;&#20449;&#32593;&#32476;&#36827;&#34892;&#21327;&#20316;&#12290;&#33218;&#30340;&#25439;&#22833;&#30001;&#19968;&#20010;&#26080;&#24847;&#35782;&#30340;&#23545;&#25163;&#20998;&#37197;&#65292;&#35813;&#23545;&#25163;&#19981;&#20165;&#25351;&#23450;&#27599;&#20010;&#26102;&#38388;&#27493;&#21644;&#27599;&#20010;&#20195;&#29702;&#30340;&#27599;&#20010;&#33218;&#30340;&#25439;&#22833;&#65292;&#36824;&#20855;&#26377;&#8220;&#21452;&#37325;&#23545;&#25239;&#24615;&#8221;&#12290;&#22312;&#36825;&#31181;&#35774;&#32622;&#19979;&#65292;&#19981;&#21516;&#30340;&#20195;&#29702;&#21487;&#33021;&#22312;&#21516;&#19968;&#26102;&#38388;&#27493;&#36873;&#25321;&#30456;&#21516;&#30340;&#33218;&#65292;&#20294;&#35266;&#23519;&#21040;&#19981;&#21516;&#30340;&#21453;&#39304;&#12290;&#27599;&#20010;&#20195;&#29702;&#30340;&#30446;&#26631;&#26159;&#25214;&#21040;&#19968;&#20010;&#20840;&#23616;&#26368;&#22909;&#30340;&#33218;&#65292;&#20351;&#24471;&#22312;&#25152;&#26377;&#20195;&#29702;&#19978;&#24179;&#22343;&#32047;&#31215;&#25439;&#22833;&#26368;&#20302;&#65292;&#36825;&#38656;&#35201;&#20195;&#29702;&#20043;&#38388;&#30340;&#36890;&#20449;&#12290;&#25105;&#20204;&#38024;&#23545;&#19981;&#21516;&#35774;&#32622;&#25552;&#20379;&#20102;&#20219;&#20309;&#32852;&#37030;&#36172;&#21338;&#31639;&#27861;&#30340;&#36951;&#25022;&#19979;&#30028;&#65292;&#24403;&#20195;&#29702;&#26377;&#23436;&#20840;&#20449;&#24687;&#21453;&#39304;&#25110;&#36172;&#21338;&#21453;&#39304;&#26102;&#12290;&#23545;&#20110;&#36172;&#21338;&#21453;&#39304;&#35774;&#32622;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25509;&#36817;&#26368;&#20248;&#30340;&#32852;&#37030;&#36172;&#21338;&#31639;&#27861;&#31216;&#20026;FEDEXP3&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#23545;Cesa-Bianchi&#31561;&#20154;&#65288;2016&#65289;&#25552;&#20986;&#30340;&#19968;&#20010;&#24320;&#25918;&#24615;&#38382;&#39064;&#32473;&#20986;&#20102;&#27491;&#38754;&#31572;&#26696;&#65306;FEDEXP3&#21487;&#20197;&#20445;&#35777;...
&lt;/p&gt;
&lt;p&gt;
We study a new non-stochastic federated multi-armed bandit problem with multiple agents collaborating via a communication network. The losses of the arms are assigned by an oblivious adversary that specifies the loss of each arm not only for each time step but also for each agent, which we call ``doubly adversarial". In this setting, different agents may choose the same arm in the same time step but observe different feedback. The goal of each agent is to find a globally best arm in hindsight that has the lowest cumulative loss averaged over all agents, which necessities the communication among agents. We provide regret lower bounds for any federated bandit algorithm under different settings, when agents have access to full-information feedback, or the bandit feedback. For the bandit feedback setting, we propose a near-optimal federated bandit algorithm called FEDEXP3. Our algorithm gives a positive answer to an open question proposed in Cesa-Bianchi et al. (2016): FEDEXP3 can guarante
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#36755;&#20986;&#20989;&#25968;&#31867;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22810;&#36755;&#20986;&#20989;&#25968;&#31867;&#23398;&#20064;&#30340;&#29305;&#24449;&#21270;&#21028;&#21035;&#26631;&#20934;&#65292;&#21363;&#27599;&#20010;&#21333;&#36755;&#20986;&#23376;&#31867;&#21487;&#23398;&#20064;&#26102;&#22810;&#36755;&#20986;&#20989;&#25968;&#31867;&#25165;&#21487;&#23398;&#20064;&#65292;&#22312;&#22810;&#26631;&#35760;&#20998;&#31867;&#21644;&#22810;&#36755;&#20986;&#22238;&#24402;&#39046;&#22495;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#12290;</title><link>http://arxiv.org/abs/2301.02729</link><description>&lt;p&gt;
&#22810;&#36755;&#20986;&#21487;&#23398;&#20064;&#24615;&#30340;&#29305;&#24449;&#21270;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Characterization of Multioutput Learnability. (arXiv:2301.02729v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.02729
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#36755;&#20986;&#20989;&#25968;&#31867;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22810;&#36755;&#20986;&#20989;&#25968;&#31867;&#23398;&#20064;&#30340;&#29305;&#24449;&#21270;&#21028;&#21035;&#26631;&#20934;&#65292;&#21363;&#27599;&#20010;&#21333;&#36755;&#20986;&#23376;&#31867;&#21487;&#23398;&#20064;&#26102;&#22810;&#36755;&#20986;&#20989;&#25968;&#31867;&#25165;&#21487;&#23398;&#20064;&#65292;&#22312;&#22810;&#26631;&#35760;&#20998;&#31867;&#21644;&#22810;&#36755;&#20986;&#22238;&#24402;&#39046;&#22495;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#25209;&#22788;&#29702;&#21644;&#22312;&#32447;&#23398;&#20064;&#20013;&#30340;&#22810;&#36755;&#20986;&#20989;&#25968;&#31867;&#23398;&#20064;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#24403;&#19988;&#20165;&#24403;&#20989;&#25968;&#31867;&#30340;&#27599;&#20010;&#21333;&#36755;&#20986;&#23376;&#31867;&#37117;&#21487;&#23398;&#20064;&#26102;&#65292;&#22810;&#36755;&#20986;&#20989;&#25968;&#31867;&#25165;&#26159;&#21487;&#23398;&#20064;&#30340;&#12290;&#36825;&#25552;&#20379;&#20102;&#22810;&#26631;&#35760;&#20998;&#31867;&#21644;&#22810;&#36755;&#20986;&#22238;&#24402;&#22312;&#25209;&#22788;&#29702;&#21644;&#22312;&#32447;&#23398;&#20064;&#20013;&#21487;&#23398;&#20064;&#24615;&#30340;&#23436;&#25972;&#29305;&#24449;&#21270;&#12290;&#20316;&#20026;&#25193;&#23637;&#65292;&#25105;&#20204;&#36824;&#32771;&#34385;&#20102;&#22312;&#36172;&#21338;&#21453;&#39304;&#29615;&#22659;&#19979;&#30340;&#22810;&#26631;&#35760;&#23398;&#20064;&#65292;&#24182;&#23637;&#31034;&#20102;&#19982;&#23436;&#20840;&#21453;&#39304;&#29615;&#22659;&#19979;&#31867;&#20284;&#30340;&#29305;&#24449;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning multioutput function classes in batch and online settings. In both settings, we show that a multioutput function class is learnable if and only if each single-output restriction of the function class is learnable. This provides a complete characterization of the learnability of multilabel classification and multioutput regression in both batch and online settings. As an extension, we also consider multilabel learnability in the bandit feedback setting and show a similar characterization as in the full-feedback setting.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24191;&#20041;&#26799;&#24230;&#27969;&#31639;&#27861;&#65292;&#23427;&#33021;&#22815;&#22312;&#22266;&#23450;&#26102;&#38388;&#20869;&#25910;&#25947;&#21040;&#38750;&#20984;&#20989;&#25968;&#30340;&#26368;&#20248;&#35299;&#65292;&#24182;&#19988;&#33021;&#22815;&#24555;&#36895;&#36867;&#36920;&#38750;&#36864;&#21270;&#38797;&#28857;&#12290;</title><link>http://arxiv.org/abs/2212.03765</link><description>&lt;p&gt;
&#21487;&#35777;&#26126;&#22266;&#23450;&#26102;&#38388;&#25910;&#25947;&#21644;&#24555;&#36895;&#36867;&#36920;&#38750;&#36864;&#21270;&#38797;&#28857;&#30340;&#24191;&#20041;&#26799;&#24230;&#27969;
&lt;/p&gt;
&lt;p&gt;
Generalized Gradient Flows with Provable Fixed-Time Convergence and Fast Evasion of Non-Degenerate Saddle Points. (arXiv:2212.03765v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.03765
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24191;&#20041;&#26799;&#24230;&#27969;&#31639;&#27861;&#65292;&#23427;&#33021;&#22815;&#22312;&#22266;&#23450;&#26102;&#38388;&#20869;&#25910;&#25947;&#21040;&#38750;&#20984;&#20989;&#25968;&#30340;&#26368;&#20248;&#35299;&#65292;&#24182;&#19988;&#33021;&#22815;&#24555;&#36895;&#36867;&#36920;&#38750;&#36864;&#21270;&#38797;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#26799;&#24230;&#30340;&#19968;&#38454;&#20984;&#20248;&#21270;&#31639;&#27861;&#22312;&#21508;&#31181;&#39046;&#22495;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#30340;&#24212;&#29992;&#65292;&#21253;&#25324;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#12290;&#21463;&#36830;&#32493;&#26102;&#38388;&#21160;&#21147;&#31995;&#32479;&#22266;&#23450;&#26102;&#38388;&#31283;&#23450;&#24615;&#29702;&#35770;&#30340;&#26368;&#26032;&#36827;&#23637;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#24191;&#20041;&#26694;&#26550;&#65292;&#29992;&#20110;&#35774;&#35745;&#20855;&#26377;&#26368;&#24378;&#25910;&#25947;&#24615;&#20445;&#35777;&#30340;&#21152;&#36895;&#20248;&#21270;&#31639;&#27861;&#65292;&#36825;&#20123;&#31639;&#27861;&#36827;&#19968;&#27493;&#36866;&#29992;&#20110;&#38750;&#20984;&#20989;&#25968;&#30340;&#23376;&#31867;&#12290;&#25105;&#20204;&#29305;&#21035;&#20171;&#32461;&#20102;GenFlow&#31639;&#27861;&#21450;&#20854;&#21160;&#37327;&#21464;&#20307;&#65292;&#23427;&#20204;&#21487;&#35777;&#26126;&#22312;&#22266;&#23450;&#26102;&#38388;&#20869;&#25910;&#25947;&#21040;&#28385;&#36275;Polyak-Lojasiewicz (PL)&#19981;&#31561;&#24335;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;&#26368;&#20248;&#35299;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#20855;&#26377;&#38750;&#36864;&#21270;&#38797;&#28857;&#30340;&#20989;&#25968;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#25552;&#20986;&#30340;GenFlow&#31639;&#27861;&#65292;&#36530;&#36991;&#36825;&#20123;&#38797;&#28857;&#25152;&#38656;&#30340;&#26102;&#38388;&#22312;&#25152;&#26377;&#21021;&#22987;&#26465;&#20214;&#19979;&#37117;&#26377;&#19968;&#33268;&#30340;&#19978;&#30028;&#12290;&#26368;&#21518;&#65292;&#23545;&#20110;&#26368;&#20248;&#35299;&#20026;&#38797;&#28857;&#30340;&#24378;&#20984;-&#24378;&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#31867;&#20284;&#30340;&#26041;&#26696;&#34987;&#35777;&#26126;&#21487;&#20197;&#36798;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gradient-based first-order convex optimization algorithms find widespread applicability in a variety of domains, including machine learning tasks. Motivated by the recent advances in fixed-time stability theory of continuous-time dynamical systems, we introduce a generalized framework for designing accelerated optimization algorithms with strongest convergence guarantees that further extend to a subclass of non-convex functions. In particular, we introduce the GenFlow algorithm and its momentum variant that provably converge to the optimal solution of objective functions satisfying the Polyak-{\L}ojasiewicz (PL) inequality in a fixed time. Moreover, for functions that admit non-degenerate saddle-points, we show that for the proposed GenFlow algorithm, the time required to evade these saddle-points is uniformly bounded for all initial conditions. Finally, for strongly convex-strongly concave minimax problems whose optimal solution is a saddle point, a similar scheme is shown to arrive a
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#20855;&#26377;&#24310;&#36831;&#36890;&#20449;&#32593;&#32476;&#30340;&#21512;&#20316;&#38750;&#38543;&#26426;&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#65292;&#22312;&#21512;&#36866;&#30340;&#27491;&#21017;&#21270;&#22120;&#21644;&#36890;&#20449;&#21327;&#35758;&#19979;&#65292;&#37319;&#29992;"FTRL"&#31639;&#27861;&#21487;&#20197;&#36798;&#21040;&#20010;&#20307;&#21518;&#24724;&#30340;&#26368;&#23567;&#21270;&#65292;&#19988;&#20855;&#26377;&#21518;&#24724;&#26368;&#20248;&#24615;&#12290;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#24182;&#23637;&#31034;&#20102;&#31639;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.17154</link><description>&lt;p&gt;
&#20851;&#20110;&#21518;&#24724;&#26368;&#23567;&#30340;&#21512;&#20316;&#38750;&#38543;&#26426;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
On Regret-optimal Cooperative Nonstochastic Multi-armed Bandits. (arXiv:2211.17154v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.17154
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#20855;&#26377;&#24310;&#36831;&#36890;&#20449;&#32593;&#32476;&#30340;&#21512;&#20316;&#38750;&#38543;&#26426;&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#65292;&#22312;&#21512;&#36866;&#30340;&#27491;&#21017;&#21270;&#22120;&#21644;&#36890;&#20449;&#21327;&#35758;&#19979;&#65292;&#37319;&#29992;"FTRL"&#31639;&#27861;&#21487;&#20197;&#36798;&#21040;&#20010;&#20307;&#21518;&#24724;&#30340;&#26368;&#23567;&#21270;&#65292;&#19988;&#20855;&#26377;&#21518;&#24724;&#26368;&#20248;&#24615;&#12290;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#24182;&#23637;&#31034;&#20102;&#31639;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#20855;&#26377;&#24310;&#36831;&#36890;&#20449;&#32593;&#32476;&#30340;&#21512;&#20316;&#38750;&#38543;&#26426;&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#26377;&#26234;&#33021;&#20307;&#30340;&#20010;&#20307;&#21518;&#24724;&#30340;&#19979;&#30028;&#12290;&#25105;&#20204;&#35777;&#26126;&#24403;&#33218;&#30340;&#25968;&#37327;&#30456;&#23545;&#20110;&#36890;&#20449;&#22270;&#20013;&#26234;&#33021;&#20307;&#30340;&#24230;&#25968;&#36275;&#22815;&#22823;&#26102;&#65292;&#37319;&#29992;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#22120;&#21644;&#36890;&#20449;&#21327;&#35758;&#65292;&#21512;&#20316;&#22810;&#20010;&#26234;&#33021;&#20307;&#30340;"FTRL"&#31639;&#27861;&#30340;&#20010;&#20307;&#21518;&#24724;&#19978;&#30028;&#19982;&#19979;&#30028;&#30456;&#21305;&#37197;&#65292;&#26368;&#22810;&#20165;&#30456;&#24046;&#19968;&#20010;&#24120;&#25968;&#22240;&#23376;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#19968;&#20010;&#20855;&#26377;&#36866;&#24403;&#27491;&#21017;&#21270;&#22120;&#30340;"FTRL"&#31639;&#27861;&#30456;&#23545;&#20110;&#36793;&#24310;&#36831;&#21442;&#25968;&#30340;&#32553;&#25918;&#20855;&#26377;&#21518;&#24724;&#26368;&#20248;&#24615;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25968;&#20540;&#23454;&#39564;&#26469;&#39564;&#35777;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#20248;&#20110;&#20808;&#21069;&#25552;&#20986;&#30340;&#31639;&#27861;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the nonstochastic multi-agent multi-armed bandit problem with agents collaborating via a communication network with delays. We show a lower bound for individual regret of all agents. We show that with suitable regularizers and communication protocols, a collaborative multi-agent \emph{follow-the-regularized-leader} (FTRL) algorithm has an individual regret upper bound that matches the lower bound up to a constant factor when the number of arms is large enough relative to degrees of agents in the communication graph. We also show that an FTRL algorithm with a suitable regularizer is regret optimal with respect to the scaling with the edge-delay parameter. We present numerical experiments validating our theoretical results and demonstrate cases when our algorithms outperform previously proposed algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;GNN&#27169;&#25311;&#39030;&#28857;&#38388;&#30456;&#20114;&#20316;&#29992;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#19968;&#20010;&#34987;&#31216;&#20026;&#20998;&#31163;&#31209;&#30340;&#24230;&#37327;&#26631;&#20934;&#26469;&#37327;&#21270;&#36825;&#31181;&#33021;&#21147;&#65292;&#32467;&#26524;&#34920;&#26126;&#27169;&#25311;&#30456;&#20114;&#20316;&#29992;&#30340;&#33021;&#21147;&#20027;&#35201;&#21462;&#20915;&#20110;&#20998;&#21306;&#30340;&#34892;&#36208;&#25351;&#25968;&#65292;&#21363;&#20174;&#20998;&#30028;&#32447;&#24320;&#22987;&#30340;&#34892;&#36208;&#25968;&#37327;&#65292;&#21516;&#26102;&#35774;&#35745;&#20102;&#19968;&#31181;&#21517;&#20026;WISA&#30340;&#36793;&#31232;&#30095;&#21270;&#31639;&#27861;&#20197;&#25552;&#39640;GNNs&#30340;&#22788;&#29702;&#25928;&#29575;&#21644;&#34920;&#36798;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2211.16494</link><description>&lt;p&gt;
&#20851;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#25311;&#39030;&#28857;&#38388;&#30456;&#20114;&#20316;&#29992;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Ability of Graph Neural Networks to Model Interactions Between Vertices. (arXiv:2211.16494v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.16494
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;GNN&#27169;&#25311;&#39030;&#28857;&#38388;&#30456;&#20114;&#20316;&#29992;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#19968;&#20010;&#34987;&#31216;&#20026;&#20998;&#31163;&#31209;&#30340;&#24230;&#37327;&#26631;&#20934;&#26469;&#37327;&#21270;&#36825;&#31181;&#33021;&#21147;&#65292;&#32467;&#26524;&#34920;&#26126;&#27169;&#25311;&#30456;&#20114;&#20316;&#29992;&#30340;&#33021;&#21147;&#20027;&#35201;&#21462;&#20915;&#20110;&#20998;&#21306;&#30340;&#34892;&#36208;&#25351;&#25968;&#65292;&#21363;&#20174;&#20998;&#30028;&#32447;&#24320;&#22987;&#30340;&#34892;&#36208;&#25968;&#37327;&#65292;&#21516;&#26102;&#35774;&#35745;&#20102;&#19968;&#31181;&#21517;&#20026;WISA&#30340;&#36793;&#31232;&#30095;&#21270;&#31639;&#27861;&#20197;&#25552;&#39640;GNNs&#30340;&#22788;&#29702;&#25928;&#29575;&#21644;&#34920;&#36798;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;(GNNs)&#34987;&#24191;&#27867;&#29992;&#20110;&#24314;&#27169;&#30001;&#22270;&#20013;&#39030;&#28857;&#34920;&#31034;&#30340;&#23454;&#20307;&#20043;&#38388;&#30340;&#22797;&#26434;&#20114;&#21160;&#12290;&#23613;&#31649;&#26368;&#36817;&#26377;&#19968;&#20123;&#29702;&#35770;&#20998;&#26512;GNNs&#34920;&#36798;&#33021;&#21147;&#30340;&#21162;&#21147;&#65292;&#20294;&#23545;&#20854;&#27169;&#25311;&#30456;&#20114;&#20316;&#29992;&#30340;&#33021;&#21147;&#32570;&#20047;&#19968;&#20010;&#27491;&#24335;&#30340;&#25551;&#36848;&#12290;&#26412;&#25991;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#36890;&#36807;&#19968;&#20010;&#24050;&#30693;&#30340;&#24230;&#37327;&#26631;&#20934;&#8212;&#8212;&#20998;&#31163;&#31209;(separation rank)&#26469;&#35268;&#33539;&#21270;&#30456;&#20114;&#20316;&#29992;&#30340;&#24378;&#24230;&#65292;&#25105;&#20204;&#37327;&#21270;&#20102;&#26576;&#20123;GNNs&#27169;&#25311;&#32473;&#23450;&#39030;&#28857;&#23376;&#38598;&#21450;&#20854;&#34917;&#38598;&#20043;&#38388;&#20132;&#20114;&#30340;&#33021;&#21147;&#65292;&#21363;&#36755;&#20837;&#39030;&#28857;&#32452;&#25104;&#30340;&#32473;&#23450;&#20998;&#21306;&#30340;&#20004;&#20391;&#20043;&#38388;&#30340;&#20114;&#21160;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#27169;&#25311;&#30456;&#20114;&#20316;&#29992;&#30340;&#33021;&#21147;&#20027;&#35201;&#21462;&#20915;&#20110;&#20998;&#21306;&#30340;&#34892;&#36208;&#25351;&#25968;(walk index)&#8212;&#8212;&#19968;&#20010;&#30001;&#20998;&#30028;&#32447;&#24320;&#22987;&#30340;&#34892;&#36208;&#25968;&#37327;&#23450;&#20041;&#30340;&#22270;&#24418;&#29305;&#24449;&#12290;&#24120;&#35265;GNN&#26550;&#26500;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#19968;&#21457;&#29616;&#12290;&#20316;&#20026;&#25105;&#20204;&#29702;&#35770;&#30340;&#23454;&#38469;&#24212;&#29992;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#21517;&#20026;Walk Indexed Sparsification Algorithm (WISA)&#30340;&#36793;&#31232;&#30095;&#21270;&#31639;&#27861;&#65292;&#21033;&#29992;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#25552;&#39640;&#22788;&#29702;&#22823;&#35268;&#27169;&#22270;&#24418;&#30340;GNNs&#25928;&#29575;&#21516;&#26102;&#20445;&#25345;&#23427;&#20204;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) are widely used for modeling complex interactions between entities represented as vertices of a graph. Despite recent efforts to theoretically analyze the expressive power of GNNs, a formal characterization of their ability to model interactions is lacking. The current paper aims to address this gap. Formalizing strength of interactions through an established measure known as separation rank, we quantify the ability of certain GNNs to model interaction between a given subset of vertices and its complement, i.e. between the sides of a given partition of input vertices. Our results reveal that the ability to model interaction is primarily determined by the partition's walk index -- a graph-theoretical characteristic defined by the number of walks originating from the boundary of the partition. Experiments with common GNN architectures corroborate this finding. As a practical application of our theory, we design an edge sparsification algorithm named Walk Inde
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#34701;&#21512;&#22270;&#26469;&#35774;&#35745;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#32452;&#20214;&#65292;&#20026;&#35299;&#20915;&#28041;&#21450;&#20840;&#23616;&#31354;&#38388;&#21644;&#32622;&#25442;&#23545;&#31216;&#24615;&#30340;&#23398;&#20064;&#20219;&#21153;&#25552;&#20379;&#20102;&#19968;&#31181;&#22270;&#24418;&#21270;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2211.07482</link><description>&lt;p&gt;
&#29992;&#24352;&#37327;&#32593;&#32476;&#24418;&#24335;&#32479;&#19968;O(3)&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Unifying O(3) Equivariant Neural Networks Design with Tensor-Network Formalism. (arXiv:2211.07482v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.07482
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#34701;&#21512;&#22270;&#26469;&#35774;&#35745;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#32452;&#20214;&#65292;&#20026;&#35299;&#20915;&#28041;&#21450;&#20840;&#23616;&#31354;&#38388;&#21644;&#32622;&#25442;&#23545;&#31216;&#24615;&#30340;&#23398;&#20064;&#20219;&#21153;&#25552;&#20379;&#20102;&#19968;&#31181;&#22270;&#24418;&#21270;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#23398;&#20064;&#20219;&#21153;&#65292;&#21253;&#25324;&#20174;&#20174;&#31532;&#19968;&#21407;&#29702;&#35745;&#31639;&#20013;&#23398;&#20064;&#21183;&#33021;&#38754;&#65292;&#28041;&#21450;&#21040;&#20840;&#23616;&#31354;&#38388;&#23545;&#31216;&#24615;&#21644;&#21407;&#23376;&#25110;&#19968;&#33324;&#31890;&#23376;&#20043;&#38388;&#30340;&#32622;&#25442;&#23545;&#31216;&#24615;&#12290;&#31561;&#21464;&#22270;&#31070;&#32463;&#32593;&#32476;&#26159;&#35299;&#20915;&#36825;&#31867;&#38382;&#39064;&#30340;&#26631;&#20934;&#26041;&#27861;&#20043;&#19968;&#65292;&#20854;&#20013;&#26368;&#25104;&#21151;&#30340;&#26041;&#27861;&#20043;&#19968;&#26159;&#20351;&#29992;&#22312;&#31354;&#38388;&#32676;&#19979;&#21464;&#25442;&#30340;&#21508;&#31181;&#24352;&#37327;&#20043;&#38388;&#30340;&#24352;&#37327;&#31215;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#19981;&#21516;&#24352;&#37327;&#30340;&#25968;&#37327;&#21644;&#23427;&#20204;&#20043;&#38388;&#20851;&#31995;&#30340;&#22797;&#26434;&#24615;&#22686;&#21152;&#65292;&#20445;&#25345;&#31616;&#27905;&#21644;&#31561;&#21464;&#24615;&#21464;&#24471;&#36234;&#26469;&#36234;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#34701;&#21512;&#22270;&#65292;&#19968;&#31181;&#24191;&#27867;&#29992;&#20110;&#27169;&#25311;SU(2)&#23545;&#31216;&#37327;&#23376;&#22810;&#20307;&#38382;&#39064;&#30340;&#25216;&#26415;&#65292;&#26469;&#20026;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#35774;&#35745;&#26032;&#30340;&#31561;&#21464;&#32452;&#20214;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#30340;&#26041;&#27861;&#26469;&#26500;&#24314;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#12290;&#24403;&#24212;&#29992;&#20110;&#32473;&#23450;&#23616;&#37096;&#37051;&#22495;&#20013;&#30340;&#31890;&#23376;&#26102;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#8220;&#34701;&#21512;&#22359;&#8221;&#30340;&#32467;&#26524;&#32452;&#20214;&#36215;&#21040;&#20102;
&lt;/p&gt;
&lt;p&gt;
Many learning tasks, including learning potential energy surfaces from ab initio calculations, involve global spatial symmetries and permutational symmetry between atoms or general particles. Equivariant graph neural networks are a standard approach to such problems, with one of the most successful methods employing tensor products between various tensors that transform under the spatial group. However, as the number of different tensors and the complexity of relationships between them increase, maintaining parsimony and equivariance becomes increasingly challenging. In this paper, we propose using fusion diagrams, a technique widely employed in simulating SU($2$)-symmetric quantum many-body problems, to design new equivariant components for equivariant neural networks. This results in a diagrammatic approach to constructing novel neural network architectures. When applied to particles within a given local neighborhood, the resulting components, which we term "fusion blocks," serve as 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#22312;&#20984;&#23494;&#24230;&#31867;&#19978;&#36827;&#34892;&#23494;&#24230;&#20272;&#35745;&#30340;&#26497;&#23567;&#26497;&#22823;&#36895;&#29575;&#65292;&#25193;&#23637;&#20102;&#24050;&#26377;&#32467;&#26524;&#65292;&#30830;&#23450;&#20102;&#20219;&#20309;&#20984;&#23494;&#24230;&#31867;&#30340;&#31934;&#30830;&#26497;&#23567;&#26497;&#22823;&#36895;&#29575;&#65292;&#24182;&#19988;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#20272;&#35745;&#22120;&#12290;</title><link>http://arxiv.org/abs/2210.11436</link><description>&lt;p&gt;
&#37325;&#26032;&#32771;&#34385;Le Cam&#26041;&#31243;&#65306;&#20984;&#23494;&#24230;&#31867;&#30340;&#31934;&#30830;&#26497;&#23567;&#26497;&#22823;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Revisiting Le Cam's Equation: Exact Minimax Rates over Convex Density Classes. (arXiv:2210.11436v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.11436
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#22312;&#20984;&#23494;&#24230;&#31867;&#19978;&#36827;&#34892;&#23494;&#24230;&#20272;&#35745;&#30340;&#26497;&#23567;&#26497;&#22823;&#36895;&#29575;&#65292;&#25193;&#23637;&#20102;&#24050;&#26377;&#32467;&#26524;&#65292;&#30830;&#23450;&#20102;&#20219;&#20309;&#20984;&#23494;&#24230;&#31867;&#30340;&#31934;&#30830;&#26497;&#23567;&#26497;&#22823;&#36895;&#29575;&#65292;&#24182;&#19988;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#20984;&#23494;&#24230;&#31867;&#19978;&#36827;&#34892;&#23494;&#24230;&#20272;&#35745;&#30340;&#26497;&#23567;&#26497;&#22823;&#36895;&#29575;&#30340;&#32463;&#20856;&#38382;&#39064;&#12290;&#22312;Le Cam&#65288;1973&#65289;&#12289;Birge&#65288;1983, 1986&#65289;&#12289;Wong&#21644;Shen&#65288;1995&#65289;&#20197;&#21450;Yang&#21644;Barron&#65288;1999&#65289;&#30340;&#24320;&#21019;&#24615;&#24037;&#20316;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#20219;&#20309;&#20984;&#23494;&#24230;&#31867;&#30340;&#31934;&#30830;&#65288;&#20165;&#19982;&#24120;&#25968;&#30456;&#20851;&#65289;&#26497;&#23567;&#26497;&#22823;&#36895;&#29575;&#12290;&#36825;&#39033;&#24037;&#20316;&#36890;&#36807;&#35777;&#26126;&#23494;&#24230;&#31867;&#30340;&#23616;&#37096;&#24230;&#37327;&#29109;&#24635;&#26159;&#25429;&#25417;&#21040;&#36825;&#20123;&#35774;&#32622;&#19979;&#30340;&#26497;&#23567;&#26497;&#22823;&#26368;&#20248;&#36895;&#29575;&#65292;&#20174;&#32780;&#25193;&#23637;&#20102;&#36825;&#20123;&#24050;&#30693;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#22312;&#27604;&#20197;&#21069;&#32771;&#34385;&#30340;&#23494;&#24230;&#31867;&#30340;&#20016;&#23500;&#24615;&#26041;&#38754;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#35270;&#35282;&#65292;&#36866;&#29992;&#20110;&#21442;&#25968;&#21270;&#21644;&#38750;&#21442;&#25968;&#21270;&#30340;&#20984;&#23494;&#24230;&#31867;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#8220;&#22810;&#38454;&#27573;&#31579;&#8221;MLE&#36866;&#29992;&#20110;&#20219;&#20309;&#36825;&#26679;&#30340;&#20984;&#23494;&#24230;&#31867;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#36825;&#20010;&#20272;&#35745;&#22120;&#23545;&#30495;&#23454;&#30340;&#28508;&#22312;&#23494;&#24230;&#26159;&#33258;&#36866;&#24212;&#30340;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#39118;&#38505;&#30028;&#24212;&#29992;&#20110;&#37325;&#26032;&#23548;&#20986;&#24050;&#30693;&#30340;&#26497;&#23567;&#26497;&#22823;&#36895;&#29575;&#65292;&#21253;&#25324;&#26377;&#30028;&#24635;&#21464;&#24046;&#21644;Holder&#23494;&#24230;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the classical problem of deriving minimax rates for density estimation over convex density classes. Building on the pioneering work of Le Cam (1973), Birge (1983, 1986), Wong and Shen (1995), Yang and Barron (1999), we determine the exact (up to constants) minimax rate over any convex density class. This work thus extends these known results by demonstrating that the local metric entropy of the density class always captures the minimax optimal rates under such settings. Our bounds provide a unifying perspective across both parametric and nonparametric convex density classes, under weaker assumptions on the richness of the density class than previously considered. Our proposed `multistage sieve' MLE applies to any such convex density class. We further demonstrate that this estimator is also adaptive to the true underlying density of interest. We apply our risk bounds to rederive known minimax rates including bounded total variation, and Holder density classes. We further illust
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39640;&#25928;&#30340;&#24102;&#26377;&#22806;&#37096;&#36755;&#20837;&#30340;MDPs&#31639;&#27861;&#65292;&#21517;&#20026;&#36861;&#28335;&#23398;&#20064;&#65288;HL&#65289;&#12290;HL&#31639;&#27861;&#36890;&#36807;&#21033;&#29992;&#22806;&#37096;&#21464;&#37327;&#26679;&#26412;&#20351;&#24471;&#36807;&#21435;&#30340;&#20915;&#31574;&#22312;&#22238;&#28335;&#20013;&#21487;&#20197;&#21152;&#36895;&#31574;&#30053;&#25913;&#36827;&#65292;&#22312;&#36164;&#28304;&#31649;&#29702;&#38382;&#39064;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2207.06272</link><description>&lt;p&gt;
&#24102;&#22806;&#37096;&#36755;&#20837;&#30340;MDPs&#30340;&#36861;&#28335;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Hindsight Learning for MDPs with Exogenous Inputs. (arXiv:2207.06272v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.06272
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39640;&#25928;&#30340;&#24102;&#26377;&#22806;&#37096;&#36755;&#20837;&#30340;MDPs&#31639;&#27861;&#65292;&#21517;&#20026;&#36861;&#28335;&#23398;&#20064;&#65288;HL&#65289;&#12290;HL&#31639;&#27861;&#36890;&#36807;&#21033;&#29992;&#22806;&#37096;&#21464;&#37327;&#26679;&#26412;&#20351;&#24471;&#36807;&#21435;&#30340;&#20915;&#31574;&#22312;&#22238;&#28335;&#20013;&#21487;&#20197;&#21152;&#36895;&#31574;&#30053;&#25913;&#36827;&#65292;&#22312;&#36164;&#28304;&#31649;&#29702;&#38382;&#39064;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#36164;&#28304;&#31649;&#29702;&#38382;&#39064;&#38656;&#35201;&#22312;&#19981;&#30830;&#23450;&#24615;&#19979;&#20570;&#20986;&#36845;&#20195;&#20915;&#31574;&#65292;&#20854;&#20013;&#24433;&#21709;&#20915;&#31574;&#32467;&#26524;&#30340;&#21807;&#19968;&#19981;&#30830;&#23450;&#24615;&#26159;&#20915;&#31574;&#32773;&#25511;&#21046;&#20043;&#22806;&#30340;&#22806;&#37096;&#21464;&#37327;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#38382;&#39064;&#24314;&#27169;&#20026;&#24102;&#26377;&#22806;&#37096;&#36755;&#20837;&#30340;MDPs&#65288;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65289;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31867;&#21517;&#20026;&#36861;&#28335;&#23398;&#20064;&#65288;HL&#65289;&#30340;&#25968;&#25454;&#39640;&#25928;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;HL&#31639;&#27861;&#36890;&#36807;&#21033;&#29992;&#19968;&#20010;&#20851;&#38190;&#27934;&#35265;&#23454;&#29616;&#20102;&#25968;&#25454;&#25928;&#29575;&#65306;&#36890;&#36807;&#22806;&#37096;&#21464;&#37327;&#30340;&#26679;&#26412;&#65292;&#36807;&#21435;&#30340;&#20915;&#31574;&#21487;&#20197;&#22312;&#22238;&#28335;&#20013;&#37325;&#26032;&#23457;&#35270;&#65292;&#20197;&#25512;&#26029;&#20986;&#21487;&#20197;&#21152;&#36895;&#31574;&#30053;&#25913;&#36827;&#30340;&#21453;&#20107;&#23454;&#21518;&#26524;&#12290;&#25105;&#20204;&#23558;HL&#19982;&#22810;&#20010;&#22522;&#32447;&#31639;&#27861;&#22312;&#22810;&#20010;&#27979;&#35797;&#26696;&#20363;&#20013;&#36827;&#34892;&#27604;&#36739;&#65292;&#21253;&#25324;&#22810;&#31192;&#20070;&#21644;&#33322;&#31354;&#20844;&#21496;&#25910;&#30410;&#31649;&#29702;&#38382;&#39064;&#12290;&#25105;&#20204;&#36824;&#23558;&#25105;&#20204;&#30340;&#31639;&#27861;&#25193;&#23637;&#21040;&#19994;&#21153;&#20851;&#38190;&#30340;&#20113;&#36164;&#28304;&#31649;&#29702;&#38382;&#39064;&#8212;&#8212;&#23558;&#34394;&#25311;&#26426;&#65288;VM&#65289;&#20998;&#37197;&#21040;&#29289;&#29702;&#26426;&#22120;&#19978;&#65292;&#24182;&#20351;&#29992;&#26469;&#33258;&#22823;&#22411;&#20844;&#20849;&#20113;&#25552;&#20379;&#21830;&#30340;&#30495;&#23454;&#25968;&#25454;&#38598;&#27169;&#25311;&#20854;&#24615;&#33021;&#12290;&#25105;&#20204;&#21457;&#29616;HL&#31639;&#27861;&#20248;&#20110;&#22522;&#20934;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many resource management problems require sequential decision-making under uncertainty, where the only uncertainty affecting the decision outcomes are exogenous variables outside the control of the decision-maker. We model these problems as Exo-MDPs (Markov Decision Processes with Exogenous Inputs) and design a class of data-efficient algorithms for them termed Hindsight Learning (HL). Our HL algorithms achieve data efficiency by leveraging a key insight: having samples of the exogenous variables, past decisions can be revisited in hindsight to infer counterfactual consequences that can accelerate policy improvements. We compare HL against classic baselines in the multi-secretary and airline revenue management problems. We also scale our algorithms to a business-critical cloud resource management problem -- allocating Virtual Machines (VMs) to physical machines, and simulate their performance with real datasets from a large public cloud provider. We find that HL algorithms outperform d
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#29305;&#24449;&#36873;&#25321;&#31639;&#27861;&#26469;&#30830;&#23450;&#31867;&#39118;&#28287;&#24615;&#20851;&#33410;&#28814;&#23567;&#40736;&#27169;&#22411;&#30340;&#20813;&#30123;&#29366;&#24577;&#12290;&#30740;&#31350;&#30446;&#26631;&#26159;&#36890;&#36807;&#35843;&#33410;&#20813;&#30123;&#29366;&#24577;&#20013;&#30340;&#35843;&#33410;&#20316;&#29992;&#22240;&#23376;&#65292;&#20851;&#38381;&#33258;&#36523;&#20813;&#30123;&#21453;&#24212;&#20013;&#30340;&#33258;&#36523;&#20813;&#30123;&#36890;&#36335;&#12290;&#36890;&#36807;&#32771;&#34385;&#33014;&#21407;&#35825;&#23548;&#24615;&#20851;&#33410;&#28814;&#23567;&#40736;&#27169;&#22411;&#36827;&#34892;&#23454;&#39564;&#65292;&#20316;&#32773;&#25506;&#32034;&#20102;&#22914;&#20309;&#30830;&#23450;&#31995;&#32479;&#29366;&#24577;&#20197;&#25552;&#39640;&#20813;&#30123;&#30103;&#27861;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2207.05882</link><description>&lt;p&gt;
&#20351;&#29992;&#29305;&#24449;&#36873;&#25321;&#31639;&#27861;&#30830;&#23450;&#31867;&#39118;&#28287;&#24615;&#20851;&#33410;&#28814;&#23567;&#40736;&#27169;&#22411;&#30340;&#20813;&#30123;&#29366;&#24577;
&lt;/p&gt;
&lt;p&gt;
Employing Feature Selection Algorithms to Determine the Immune State of a Mouse Model of Rheumatoid Arthritis. (arXiv:2207.05882v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.05882
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#29305;&#24449;&#36873;&#25321;&#31639;&#27861;&#26469;&#30830;&#23450;&#31867;&#39118;&#28287;&#24615;&#20851;&#33410;&#28814;&#23567;&#40736;&#27169;&#22411;&#30340;&#20813;&#30123;&#29366;&#24577;&#12290;&#30740;&#31350;&#30446;&#26631;&#26159;&#36890;&#36807;&#35843;&#33410;&#20813;&#30123;&#29366;&#24577;&#20013;&#30340;&#35843;&#33410;&#20316;&#29992;&#22240;&#23376;&#65292;&#20851;&#38381;&#33258;&#36523;&#20813;&#30123;&#21453;&#24212;&#20013;&#30340;&#33258;&#36523;&#20813;&#30123;&#36890;&#36335;&#12290;&#36890;&#36807;&#32771;&#34385;&#33014;&#21407;&#35825;&#23548;&#24615;&#20851;&#33410;&#28814;&#23567;&#40736;&#27169;&#22411;&#36827;&#34892;&#23454;&#39564;&#65292;&#20316;&#32773;&#25506;&#32034;&#20102;&#22914;&#20309;&#30830;&#23450;&#31995;&#32479;&#29366;&#24577;&#20197;&#25552;&#39640;&#20813;&#30123;&#30103;&#27861;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20813;&#30123;&#21453;&#24212;&#26159;&#19968;&#20010;&#21160;&#24577;&#36807;&#31243;&#65292;&#36890;&#36807;&#35813;&#36807;&#31243;&#65292;&#26426;&#20307;&#30830;&#23450;&#25239;&#21407;&#26159;&#33258;&#36523;&#36824;&#26159;&#38750;&#33258;&#36523;&#12290;&#36825;&#20010;&#21160;&#24577;&#36807;&#31243;&#30340;&#29366;&#24577;&#30001;&#32452;&#25104;&#20915;&#31574;&#36807;&#31243;&#30340;&#28814;&#30151;&#21644;&#35843;&#33410;&#20316;&#29992;&#22240;&#23376;&#30340;&#30456;&#23545;&#24179;&#34913;&#21644;&#31181;&#32676;&#23450;&#20041;&#12290;&#20813;&#30123;&#30103;&#27861;&#24212;&#29992;&#20110;&#31867;&#39118;&#28287;&#24615;&#20851;&#33410;&#28814;&#31561;&#65292;&#20854;&#30446;&#26631;&#26159;&#23558;&#20813;&#30123;&#29366;&#24577;&#20559;&#21521;&#35843;&#33410;&#20316;&#29992;&#22240;&#23376;&#65292;&#20174;&#32780;&#20851;&#38381;&#33258;&#36523;&#20813;&#30123;&#21453;&#24212;&#20013;&#30340;&#33258;&#36523;&#20813;&#30123;&#36890;&#36335;&#12290;&#34429;&#28982;&#24050;&#30693;&#26377;&#20960;&#31181;&#20813;&#30123;&#30103;&#27861;&#26041;&#27861;&#65292;&#20294;&#35813;&#30103;&#27861;&#30340;&#26377;&#25928;&#24615;&#21462;&#20915;&#20110;&#35813;&#24178;&#39044;&#22914;&#20309;&#25913;&#21464;&#35813;&#29366;&#24577;&#30340;&#28436;&#21464;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#20010;&#36807;&#31243;&#19981;&#20165;&#30001;&#36807;&#31243;&#30340;&#21160;&#24577;&#24615;&#30830;&#23450;&#65292;&#36824;&#30001;&#24178;&#39044;&#26102;&#31995;&#32479;&#30340;&#29366;&#24577;&#30830;&#23450;&#65292;&#32780;&#24178;&#39044;&#21069;&#24456;&#38590;&#29978;&#33267;&#19981;&#21487;&#33021;&#30830;&#23450;&#31995;&#32479;&#30340;&#29366;&#24577;&#12290;&#20026;&#20102;&#30830;&#23450;&#36825;&#31181;&#29366;&#24577;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#31867;&#39118;&#28287;&#24615;&#20851;&#33410;&#28814;&#23567;&#40736;&#27169;&#22411;&#65288;&#33014;&#21407;&#35825;&#23548;&#24615;&#20851;&#33410;&#28814;&#65289;&#65292;&#36827;&#34892;&#20102;&#20813;&#30123;&#30103;&#27861;&#65307;&#25910;&#38598;&#20102;&#39640;&#37327;&#32423;&#12290;&#12290;&#12290;
&lt;/p&gt;
&lt;p&gt;
The immune response is a dynamic process by which the body determines whether an antigen is self or nonself. The state of this dynamic process is defined by the relative balance and population of inflammatory and regulatory actors which comprise this decision making process. The goal of immunotherapy as applied to, e.g. Rheumatoid Arthritis (RA), then, is to bias the immune state in favor of the regulatory actors - thereby shutting down autoimmune pathways in the response. While there are several known approaches to immunotherapy, the effectiveness of the therapy will depend on how this intervention alters the evolution of this state. Unfortunately, this process is determined not only by the dynamics of the process, but the state of the system at the time of intervention - a state which is difficult if not impossible to determine prior to application of the therapy. To identify such states we consider a mouse model of RA (Collagen-Induced Arthritis (CIA)) immunotherapy; collect high di
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;&#19981;&#30830;&#23450;&#29615;&#22659;&#19979;&#22522;&#20110;&#21160;&#24577;&#26102;&#38388;&#35268;&#25972;&#31639;&#27861;&#30340;&#26102;&#38388;&#24207;&#21015;&#30456;&#20284;&#24615;/&#36317;&#31163;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25552;&#20379;&#26377;&#25928;&#30340;p&#20540;&#65292;&#23545;&#20110;&#24322;&#24120;&#26102;&#38388;&#24207;&#21015;&#26816;&#27979;&#31561;&#39640;&#39118;&#38505;&#20915;&#31574;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2202.06593</link><description>&lt;p&gt;
&#21160;&#24577;&#26102;&#38388;&#35268;&#25972;&#36317;&#31163;&#30340;&#32479;&#35745;&#25512;&#26029;&#21450;&#20854;&#22312;&#24322;&#24120;&#26102;&#38388;&#24207;&#21015;&#26816;&#27979;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Statistical Inference for the Dynamic Time Warping Distance, with Application to Abnormal Time-Series Detection. (arXiv:2202.06593v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.06593
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;&#19981;&#30830;&#23450;&#29615;&#22659;&#19979;&#22522;&#20110;&#21160;&#24577;&#26102;&#38388;&#35268;&#25972;&#31639;&#27861;&#30340;&#26102;&#38388;&#24207;&#21015;&#30456;&#20284;&#24615;/&#36317;&#31163;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25552;&#20379;&#26377;&#25928;&#30340;p&#20540;&#65292;&#23545;&#20110;&#24322;&#24120;&#26102;&#38388;&#24207;&#21015;&#26816;&#27979;&#31561;&#39640;&#39118;&#38505;&#20915;&#31574;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#22312;&#19981;&#30830;&#23450;&#29615;&#22659;&#19979;&#22522;&#20110;&#21160;&#24577;&#26102;&#38388;&#35268;&#25972;&#65288;DTW&#65289;&#31639;&#27861;&#30340;&#20004;&#20010;&#26102;&#38388;&#24207;&#21015;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;/&#36317;&#31163;&#30340;&#32479;&#35745;&#25512;&#26029;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#12290;&#30001;&#20110;DTW&#36317;&#31163;&#26159;&#22522;&#20110;DTW&#31639;&#27861;&#30340;&#35299;&#24471;&#21040;&#30340;&#65292;&#20854;&#37319;&#26679;&#20998;&#24067;&#24456;&#38590;&#35745;&#31639;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26465;&#20214;&#36873;&#25321;&#25512;&#26029;&#26694;&#26550;&#65292;&#33021;&#22815;&#25512;&#23548;&#20986;&#19968;&#31181;&#23545;DTW&#36317;&#31163;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#30340;&#26041;&#27861;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#31181;&#33021;&#22815;&#25552;&#20379;&#26377;&#25928;p&#20540;&#26469;&#37327;&#21270;DTW&#36317;&#31163;&#30340;&#32479;&#35745;&#26174;&#33879;&#24615;&#30340;&#26041;&#27861;&#65292;&#23545;&#20110;&#20687;&#24322;&#24120;&#26102;&#38388;&#24207;&#21015;&#26816;&#27979;&#31561;&#39640;&#39118;&#38505;&#20915;&#31574;&#38750;&#24120;&#26377;&#24110;&#21161;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25152;&#25552;&#20986;&#30340;&#25512;&#26029;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study statistical inference on the similarity/distance between two time-series under uncertain environment by considering a statistical hypothesis test on the distance obtained from Dynamic Time Warping (DTW) algorithm. The sampling distribution of the DTW distance is too difficult to derive because it is obtained based on the solution of the DTW algorithm, which is complicated. To circumvent this difficulty, we propose to employ the conditional selective inference framework, which enables us to derive a valid inference method on the DTW distance. To our knowledge, this is the first method that can provide a valid p-value to quantify the statistical significance of the DTW distance, which is helpful for high-stake decision making such as abnormal time-series detection problems. We evaluate the performance of the proposed inference method on both synthetic and real-world datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#32447;&#24615;&#22238;&#24402;&#24773;&#20917;&#30340;&#36801;&#31227;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#23558;&#26032;&#25968;&#25454;&#19982;&#21382;&#21490;&#25968;&#25454;&#30456;&#32467;&#21512;&#65292;&#29305;&#21035;&#22312;&#26032;&#25968;&#25454;&#31232;&#32570;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#30410;&#22788;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#39564;&#35777;&#20013;&#34920;&#29616;&#20986;&#23545;&#36127;&#36801;&#31227;&#23398;&#20064;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2202.05069</link><description>&lt;p&gt;
&#19981;&#21516;&#36755;&#20837;&#32500;&#24230;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#36801;&#31227;&#23398;&#20064;&#65306;&#32447;&#24615;&#22238;&#24402;&#24773;&#20917;&#19979;&#30340;&#31639;&#27861;&#21644;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Transfer-Learning Across Datasets with Different Input Dimensions: An Algorithm and Analysis for the Linear Regression Case. (arXiv:2202.05069v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.05069
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#32447;&#24615;&#22238;&#24402;&#24773;&#20917;&#30340;&#36801;&#31227;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#23558;&#26032;&#25968;&#25454;&#19982;&#21382;&#21490;&#25968;&#25454;&#30456;&#32467;&#21512;&#65292;&#29305;&#21035;&#22312;&#26032;&#25968;&#25454;&#31232;&#32570;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#30410;&#22788;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#39564;&#35777;&#20013;&#34920;&#29616;&#20986;&#23545;&#36127;&#36801;&#31227;&#23398;&#20064;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26032;&#20256;&#24863;&#22120;&#21644;&#30417;&#27979;&#35774;&#22791;&#30340;&#21457;&#23637;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#25968;&#25454;&#28304;&#21487;&#20197;&#20316;&#20026;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#36755;&#20837;&#12290;&#36825;&#20123;&#25968;&#25454;&#26082;&#21487;&#20197;&#24110;&#21161;&#25552;&#39640;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#65292;&#20294;&#23558;&#36825;&#20123;&#26032;&#36755;&#20837;&#19982;&#21382;&#21490;&#25968;&#25454;&#30456;&#32467;&#21512;&#20173;&#28982;&#26159;&#19968;&#20010;&#23578;&#26410;&#35814;&#32454;&#30740;&#31350;&#30340;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36801;&#31227;&#23398;&#20064;&#31639;&#27861;&#65292;&#23558;&#26032;&#25968;&#25454;&#21644;&#21382;&#21490;&#25968;&#25454;&#32467;&#21512;&#36215;&#26469;&#65292;&#29305;&#21035;&#22312;&#26032;&#25968;&#25454;&#31232;&#32570;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#30410;&#22788;&#12290;&#25105;&#20204;&#23558;&#37325;&#28857;&#25918;&#22312;&#32447;&#24615;&#22238;&#24402;&#24773;&#20917;&#19979;&#65292;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#23545;&#35813;&#26041;&#27861;&#30340;&#30410;&#22788;&#36827;&#34892;&#20005;&#26684;&#30340;&#29702;&#35770;&#30740;&#31350;&#12290;&#25105;&#20204;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#23545;&#36127;&#36801;&#31227;&#23398;&#20064;&#26159;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#65292;&#24182;&#36890;&#36807;&#30495;&#23454;&#21644;&#27169;&#25311;&#25968;&#25454;&#36827;&#34892;&#20102;&#23454;&#35777;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the development of new sensors and monitoring devices, more sources of data become available to be used as inputs for machine learning models. These can on the one hand help to improve the accuracy of a model. On the other hand however, combining these new inputs with historical data remains a challenge that has not yet been studied in enough detail. In this work, we propose a transfer-learning algorithm that combines the new and the historical data, that is especially beneficial when the new data is scarce. We focus the approach on the linear regression case, which allows us to conduct a rigorous theoretical study on the benefits of the approach. We show that our approach is robust against negative transfer-learning, and we confirm this result empirically with real and simulated data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#32467;&#26524;&#25277;&#26679;&#30340;&#22240;&#26524;&#25512;&#26029;&#65292;&#21457;&#29616;&#24378;&#26080;&#20559;&#24615;&#19981;&#24635;&#26159;&#20687;&#38543;&#26426;&#25277;&#26679;&#19979;&#37027;&#26679;&#24378;&#22823;&#65292;&#24182;&#19988;&#26576;&#20123;&#21333;&#35843;&#24615;&#20551;&#35774;&#22312;&#38160;&#21033;&#35782;&#21035;&#38388;&#38548;&#26041;&#38754;&#20135;&#29983;&#21487;&#27604;&#36739;&#30340;&#32467;&#26524;&#12290; &#36890;&#36807;&#31639;&#27861;&#25512;&#26029;&#20986;&#21442;&#25968;&#24182;&#29992;&#23454;&#35777;&#20363;&#23376;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2004.08318</link><description>&lt;p&gt;
&#22522;&#20110;&#32467;&#26524;&#25277;&#26679;&#30340;&#22240;&#26524;&#25512;&#26029;&#21644;&#21333;&#35843;&#24615;&#20551;&#35774;
&lt;/p&gt;
&lt;p&gt;
Causal Inference under Outcome-Based Sampling with Monotonicity Assumptions. (arXiv:2004.08318v5 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2004.08318
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#32467;&#26524;&#25277;&#26679;&#30340;&#22240;&#26524;&#25512;&#26029;&#65292;&#21457;&#29616;&#24378;&#26080;&#20559;&#24615;&#19981;&#24635;&#26159;&#20687;&#38543;&#26426;&#25277;&#26679;&#19979;&#37027;&#26679;&#24378;&#22823;&#65292;&#24182;&#19988;&#26576;&#20123;&#21333;&#35843;&#24615;&#20551;&#35774;&#22312;&#38160;&#21033;&#35782;&#21035;&#38388;&#38548;&#26041;&#38754;&#20135;&#29983;&#21487;&#27604;&#36739;&#30340;&#32467;&#26524;&#12290; &#36890;&#36807;&#31639;&#27861;&#25512;&#26029;&#20986;&#21442;&#25968;&#24182;&#29992;&#23454;&#35777;&#20363;&#23376;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26681;&#25454;&#26696;&#20363;&#25511;&#21046;&#21644;&#26696;&#20363;&#32676;&#20307;&#21462;&#26679;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#30340;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20851;&#27880;&#20108;&#20803;&#32467;&#26524;&#21644;&#20108;&#20803;&#27835;&#30103;&#30340;&#24773;&#20917;&#65292;&#20854;&#20013;&#24863;&#20852;&#36259;&#30340;&#21442;&#25968;&#26159;&#36890;&#36807;&#28508;&#22312;&#32467;&#26524;&#26694;&#26550;&#23450;&#20041;&#30340;&#22240;&#26524;&#30456;&#23545;&#21644;&#21487;&#24402;&#22240;&#39118;&#38505;&#12290;&#25105;&#20204;&#21457;&#29616;&#24378;&#26080;&#20559;&#24615;&#19981;&#24635;&#26159;&#20687;&#38543;&#26426;&#25277;&#26679;&#19979;&#37027;&#26679;&#24378;&#22823;&#65292;&#24182;&#19988;&#26576;&#20123;&#21333;&#35843;&#24615;&#20551;&#35774;&#22312;&#38160;&#21033;&#35782;&#21035;&#38388;&#38548;&#26041;&#38754;&#20135;&#29983;&#21487;&#27604;&#36739;&#30340;&#32467;&#26524;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#36890;&#24120;&#30340;&#27604;&#20540;&#27604;&#22312;&#21333;&#35843;&#27835;&#30103;&#21453;&#24212;&#21644;&#21333;&#35843;&#27835;&#30103;&#36873;&#25321;&#20551;&#35774;&#19979;&#34987;&#35777;&#26126;&#26159;&#22240;&#26524;&#30456;&#23545;&#39118;&#38505;&#30340;&#38160;&#21033;&#35782;&#21035;&#19978;&#30028;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#32858;&#21512;&#22312;&#21327;&#21464;&#37327;&#30340;&#30495;&#23454;&#20154;&#21475;&#20998;&#24067;&#19978;&#30340;&#22240;&#26524;&#21442;&#25968;&#25512;&#26029;&#31639;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#30740;&#31350;&#19977;&#20010;&#23454;&#35777;&#20363;&#23376;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#29992;&#24615;&#65306;&#22312;&#24052;&#22522;&#26031;&#22374;&#36827;&#20837;&#33879;&#21517;&#22823;&#23398;&#30340;&#31169;&#31435;&#23398;&#26657;&#21463;&#30410;&#38382;&#39064;&#19978;&#65307;&#22312;&#30041;&#22312;&#23398;&#26657;&#21644;&#25918;&#24323;&#23398;&#26657;&#26089;&#26399;&#30340;&#20851;&#31995;&#38382;&#39064;&#19978;&#65307;&#22312;&#39044;&#27979;&#23703;&#20301;&#22521;&#35757;&#25928;&#26524;&#38382;&#39064;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study causal inference under case-control and case-population sampling. Specifically, we focus on the binary-outcome and binary-treatment case, where the parameters of interest are causal relative and attributable risks defined via the potential outcome framework. It is shown that strong ignorability is not always as powerful as it is under random sampling and that certain monotonicity assumptions yield comparable results in terms of sharp identified intervals. Specifically, the usual odds ratio is shown to be a sharp identified upper bound on causal relative risk under the monotone treatment response and monotone treatment selection assumptions. We offer algorithms for inference on the causal parameters that are aggregated over the true population distribution of the covariates. We show the usefulness of our approach by studying three empirical examples: the benefit of attending private school for entering a prestigious university in Pakistan; the relationship between staying in sc
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Pani&#30340;&#36890;&#29992;&#27491;&#21017;&#21270;&#22120;&#65292;&#23427;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#36827;&#34892;&#38750;&#23616;&#37096;&#34920;&#31034;&#65292;&#24182;&#23558;&#37051;&#22495;&#34917;&#19969;&#29305;&#24449;&#36827;&#34892;&#32447;&#24615;&#25554;&#20540;&#65292;&#20174;&#32780;&#26500;&#24314;&#20102;&#19968;&#31181;&#36890;&#29992;&#19988;&#26377;&#25928;&#30340;&#27491;&#21017;&#21270;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/1911.09307</link><description>&lt;p&gt;
Patch-level Neighborhood Interpolation: &#19968;&#31181;&#36890;&#29992;&#19988;&#26377;&#25928;&#30340;&#22522;&#20110;&#22270;&#30340;&#27491;&#21017;&#21270;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Patch-level Neighborhood Interpolation: A General and Effective Graph-based Regularization Strategy. (arXiv:1911.09307v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1911.09307
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Pani&#30340;&#36890;&#29992;&#27491;&#21017;&#21270;&#22120;&#65292;&#23427;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#36827;&#34892;&#38750;&#23616;&#37096;&#34920;&#31034;&#65292;&#24182;&#23558;&#37051;&#22495;&#34917;&#19969;&#29305;&#24449;&#36827;&#34892;&#32447;&#24615;&#25554;&#20540;&#65292;&#20174;&#32780;&#26500;&#24314;&#20102;&#19968;&#31181;&#36890;&#29992;&#19988;&#26377;&#25928;&#30340;&#27491;&#21017;&#21270;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;&#21017;&#21270;&#23545;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#23588;&#20854;&#26159;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#38750;&#24120;&#37325;&#35201;&#12290;&#29616;&#26377;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#20027;&#35201;&#20381;&#36182;&#20110;&#29420;&#31435;&#21516;&#20998;&#24067;&#20551;&#35774;&#65292;&#24182;&#19988;&#20165;&#32771;&#34385;&#24403;&#21069;&#26679;&#26412;&#30340;&#30693;&#35782;&#65292;&#27809;&#26377;&#21033;&#29992;&#26679;&#26412;&#20043;&#38388;&#30340;&#37051;&#23621;&#20851;&#31995;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;Patch-level Neighborhood Interpolation&#65288;Pani&#65289;&#8221;&#30340;&#36890;&#29992;&#27491;&#21017;&#21270;&#22120;&#65292;&#22312;&#32593;&#32476;&#35745;&#31639;&#20013;&#36827;&#34892;&#38750;&#23616;&#37096;&#34920;&#31034;&#12290;&#25105;&#20204;&#30340;&#25552;&#35758;&#26126;&#30830;&#22320;&#26500;&#24314;&#20102;&#19981;&#21516;&#23618;&#27425;&#30340;&#34917;&#19969;&#32423;&#22270;&#65292;&#28982;&#21518;&#32447;&#24615;&#25554;&#20540;&#37051;&#22495;&#34917;&#19969;&#29305;&#24449;&#65292;&#20316;&#20026;&#19968;&#31181;&#36890;&#29992;&#19988;&#26377;&#25928;&#30340;&#27491;&#21017;&#21270;&#31574;&#30053;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#23450;&#21046;&#20026;&#20004;&#31181;&#27969;&#34892;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#21363;&#34394;&#25311;&#23545;&#25239;&#35757;&#32451;&#65288;VAT&#65289;&#21644;MixUp&#20197;&#21450;&#20854;&#21464;&#20307;&#12290;&#39318;&#20808;&#27966;&#29983;&#30340;&#8220;Pani VAT&#8221;&#36890;&#36807;&#20351;&#29992;&#34917;&#19969;&#32423;&#25554;&#20540;&#25200;&#21160;&#26500;&#24314;&#38750;&#23616;&#37096;&#23545;&#25239;&#24179;&#28369;&#24230;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Regularization plays a crucial role in machine learning models, especially for deep neural networks. The existing regularization techniques mainly rely on the i.i.d. assumption and only consider the knowledge from the current sample, without the leverage of the neighboring relationship between samples. In this work, we propose a general regularizer called \textbf{Patch-level Neighborhood Interpolation~(Pani)} that conducts a non-local representation in the computation of networks. Our proposal explicitly constructs patch-level graphs in different layers and then linearly interpolates neighborhood patch features, serving as a general and effective regularization strategy. Further, we customize our approach into two kinds of popular regularization methods, namely Virtual Adversarial Training (VAT) and MixUp as well as its variants. The first derived \textbf{Pani VAT} presents a novel way to construct non-local adversarial smoothness by employing patch-level interpolated perturbations. Th
&lt;/p&gt;</description></item><item><title>TimbreTron&#26159;&#19968;&#31181;&#29992;&#20110;&#38899;&#20048;&#38899;&#33394;&#36716;&#25442;&#30340;&#26041;&#27861;&#65292;&#23558;&#22270;&#20687;&#39046;&#22495;&#30340;&#39118;&#26684;&#36716;&#25442;&#24212;&#29992;&#21040;&#38899;&#39057;&#20449;&#21495;&#30340;&#26102;&#39057;&#34920;&#31034;&#19978;&#65292;&#28982;&#21518;&#20351;&#29992;&#26465;&#20214;WaveNet&#21512;&#25104;&#22120;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#27874;&#24418;&#12290;&#36890;&#36807;&#20154;&#31867;&#24863;&#30693;&#35780;&#20272;&#65292;&#35777;&#23454;&#20102;&#20854;&#21487;&#34892;&#24615;&#12290;</title><link>http://arxiv.org/abs/1811.09620</link><description>&lt;p&gt;
TimbreTron&#65306;&#29992;&#20110;&#38899;&#20048;&#38899;&#33394;&#36716;&#25442;&#30340;WaveNet&#65288;CycleGAN&#65288;CQT&#65288;Audio&#65289;&#65289;&#65289;&#27969;&#27700;&#32447;
&lt;/p&gt;
&lt;p&gt;
TimbreTron: A WaveNet(CycleGAN(CQT(Audio))) Pipeline for Musical Timbre Transfer. (arXiv:1811.09620v3 [cs.SD] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1811.09620
&lt;/p&gt;
&lt;p&gt;
TimbreTron&#26159;&#19968;&#31181;&#29992;&#20110;&#38899;&#20048;&#38899;&#33394;&#36716;&#25442;&#30340;&#26041;&#27861;&#65292;&#23558;&#22270;&#20687;&#39046;&#22495;&#30340;&#39118;&#26684;&#36716;&#25442;&#24212;&#29992;&#21040;&#38899;&#39057;&#20449;&#21495;&#30340;&#26102;&#39057;&#34920;&#31034;&#19978;&#65292;&#28982;&#21518;&#20351;&#29992;&#26465;&#20214;WaveNet&#21512;&#25104;&#22120;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#27874;&#24418;&#12290;&#36890;&#36807;&#20154;&#31867;&#24863;&#30693;&#35780;&#20272;&#65292;&#35777;&#23454;&#20102;&#20854;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35299;&#20915;&#20102;&#38899;&#20048;&#38899;&#33394;&#36716;&#25442;&#30340;&#38382;&#39064;&#65292;&#30446;&#26631;&#26159;&#23558;&#19968;&#20010;&#20048;&#22120;&#30340;&#22768;&#38899;&#26679;&#26412;&#30340;&#38899;&#33394;&#36716;&#25442;&#20026;&#21478;&#19968;&#20010;&#20048;&#22120;&#30340;&#38899;&#33394;&#65292;&#21516;&#26102;&#20445;&#30041;&#20854;&#20182;&#38899;&#20048;&#20869;&#23481;&#65292;&#22914;&#38899;&#39640;&#12289;&#33410;&#22863;&#21644;&#38899;&#37327;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;TimbreTron&#65292;&#19968;&#31181;&#38899;&#20048;&#38899;&#33394;&#36716;&#25442;&#26041;&#27861;&#65292;&#23427;&#23558;&#8220;&#22270;&#20687;&#8221;&#39046;&#22495;&#30340;&#39118;&#26684;&#36716;&#25442;&#24212;&#29992;&#21040;&#38899;&#39057;&#20449;&#21495;&#30340;&#26102;&#39057;&#34920;&#31034;&#19978;&#65292;&#28982;&#21518;&#20351;&#29992;&#26465;&#20214;WaveNet&#21512;&#25104;&#22120;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#27874;&#24418;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;Constant Q Transform&#65288;CQT&#65289;&#34920;&#31034;&#29305;&#21035;&#36866;&#21512;&#21367;&#31215;&#32467;&#26500;&#65292;&#22240;&#20854;&#36817;&#20284;&#30340;&#38899;&#39640;&#31561;&#21464;&#24615;&#12290;&#22522;&#20110;&#20154;&#31867;&#24863;&#30693;&#35780;&#20272;&#65292;&#25105;&#20204;&#30830;&#35748;TimbreTron&#21487;&#20197;&#34987;&#35782;&#21035;&#20986;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we address the problem of musical timbre transfer, where the goal is to manipulate the timbre of a sound sample from one instrument to match another instrument while preserving other musical content, such as pitch, rhythm, and loudness. In principle, one could apply image-based style transfer techniques to a time-frequency representation of an audio signal, but this depends on having a representation that allows independent manipulation of timbre as well as high-quality waveform generation. We introduce TimbreTron, a method for musical timbre transfer which applies "image" domain style transfer to a time-frequency representation of the audio signal, and then produces a high-quality waveform using a conditional WaveNet synthesizer. We show that the Constant Q Transform (CQT) representation is particularly well-suited to convolutional architectures due to its approximate pitch equivariance. Based on human perceptual evaluations, we confirmed that TimbreTron recognizably tra
&lt;/p&gt;</description></item></channel></rss>