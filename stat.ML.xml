<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>NECO&#26159;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#22349;&#22604;&#30340;&#26032;&#39062;&#30340;&#36229;&#20986;&#20998;&#24067;&#26816;&#27979;&#26041;&#27861;&#65292;&#21033;&#29992;&#20960;&#20309;&#23646;&#24615;&#21644;&#20027;&#25104;&#20998;&#31354;&#38388;&#35782;&#21035;OOD&#25968;&#25454;&#65292;&#22312;&#23567;&#35268;&#27169;&#21644;&#22823;&#35268;&#27169;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.06823</link><description>&lt;p&gt;
NECO: &#22522;&#20110;&#31070;&#32463;&#22349;&#22604;&#30340;&#36229;&#20986;&#20998;&#24067;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
NECO: NEural Collapse Based Out-of-distribution detection. (arXiv:2310.06823v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06823
&lt;/p&gt;
&lt;p&gt;
NECO&#26159;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#22349;&#22604;&#30340;&#26032;&#39062;&#30340;&#36229;&#20986;&#20998;&#24067;&#26816;&#27979;&#26041;&#27861;&#65292;&#21033;&#29992;&#20960;&#20309;&#23646;&#24615;&#21644;&#20027;&#25104;&#20998;&#31354;&#38388;&#35782;&#21035;OOD&#25968;&#25454;&#65292;&#22312;&#23567;&#35268;&#27169;&#21644;&#22823;&#35268;&#27169;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#27169;&#22411;&#36807;&#20110;&#33258;&#20449;&#24182;&#19988;&#27809;&#26377;&#24847;&#35782;&#21040;&#20854;&#35748;&#35782;&#35770;&#38480;&#21046;&#65292;&#26816;&#27979;&#36229;&#20986;&#20998;&#24067;&#65288;OOD&#65289;&#25968;&#25454;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#12290;&#25105;&#20204;&#20551;&#35774;&#8220;&#31070;&#32463;&#22349;&#22604;&#8221;&#65292;&#19968;&#31181;&#24433;&#21709;&#36229;&#20986;&#20998;&#24067;&#25968;&#25454;&#30340;&#29616;&#35937;&#65292;&#20063;&#20250;&#24433;&#21709;&#36229;&#20986;&#20998;&#24067;&#25968;&#25454;&#12290;&#20026;&#20102;&#20174;&#36825;&#31181;&#30456;&#20114;&#20316;&#29992;&#20013;&#21463;&#30410;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;NECO&#65292;&#19968;&#31181;&#29992;&#20110;OOD&#26816;&#27979;&#30340;&#26032;&#39062;&#30340;&#20107;&#21518;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#8220;&#31070;&#32463;&#22349;&#22604;&#8221;&#21644;&#20027;&#25104;&#20998;&#31354;&#38388;&#30340;&#20960;&#20309;&#23646;&#24615;&#26469;&#35782;&#21035;OOD&#25968;&#25454;&#12290;&#25105;&#20204;&#30340;&#22823;&#37327;&#23454;&#39564;&#34920;&#26126;&#65292;NECO&#22312;&#23567;&#35268;&#27169;&#21644;&#22823;&#35268;&#27169;OOD&#26816;&#27979;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#22312;&#19981;&#21516;&#30340;&#32593;&#32476;&#26550;&#26500;&#19978;&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;OOD&#26816;&#27979;&#20013;&#30340;&#26377;&#25928;&#24615;&#25552;&#20379;&#20102;&#29702;&#35770;&#35299;&#37322;&#12290;&#25105;&#20204;&#35745;&#21010;&#22312;&#21311;&#21517;&#26399;&#32467;&#26463;&#21518;&#21457;&#24067;&#20195;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
Detecting out-of-distribution (OOD) data is a critical challenge in machine learning due to model overconfidence, often without awareness of their epistemological limits. We hypothesize that ``neural collapse'', a phenomenon affecting in-distribution data for models trained beyond loss convergence, also influences OOD data. To benefit from this interplay, we introduce NECO, a novel post-hoc method for OOD detection, which leverages the geometric properties of ``neural collapse'' and of principal component spaces to identify OOD data. Our extensive experiments demonstrate that NECO achieves state-of-the-art results on both small and large-scale OOD detection tasks while exhibiting strong generalization capabilities across different network architectures. Furthermore, we provide a theoretical explanation for the effectiveness of our method in OOD detection. We plan to release the code after the anonymity period.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20302;&#31209;&#32467;&#26500;&#19979;&#30340;&#30697;&#38453;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#39057;&#35889;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#20272;&#35745;&#22855;&#24322;&#23376;&#31354;&#38388;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#24182;&#19988;&#33021;&#22815;&#23454;&#29616;&#20960;&#20046;&#26368;&#23567;&#30340;&#36880;&#20803;&#32032;&#35823;&#24046;&#12290;&#36825;&#20123;&#26032;&#32467;&#26524;&#20026;&#20805;&#20998;&#21033;&#29992;&#20302;&#31209;&#32467;&#26500;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#35774;&#35745;&#25552;&#20379;&#20102;&#21487;&#33021;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.06793</link><description>&lt;p&gt;
&#20302;&#31209;&#24378;&#21270;&#23398;&#20064;&#30340;&#39057;&#35889;&#36880;&#20803;&#32032;&#30697;&#38453;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Spectral Entry-wise Matrix Estimation for Low-Rank Reinforcement Learning. (arXiv:2310.06793v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06793
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20302;&#31209;&#32467;&#26500;&#19979;&#30340;&#30697;&#38453;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#39057;&#35889;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#20272;&#35745;&#22855;&#24322;&#23376;&#31354;&#38388;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#24182;&#19988;&#33021;&#22815;&#23454;&#29616;&#20960;&#20046;&#26368;&#23567;&#30340;&#36880;&#20803;&#32032;&#35823;&#24046;&#12290;&#36825;&#20123;&#26032;&#32467;&#26524;&#20026;&#20805;&#20998;&#21033;&#29992;&#20302;&#31209;&#32467;&#26500;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#35774;&#35745;&#25552;&#20379;&#20102;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#24378;&#21270;&#23398;&#20064;&#20013;&#20986;&#29616;&#30340;&#20302;&#31209;&#32467;&#26500;&#30340;&#30697;&#38453;&#20272;&#35745;&#38382;&#39064;&#12290;&#22312;&#20302;&#31209;&#36172;&#21338;&#26426;&#20013;&#65292;&#38656;&#35201;&#24674;&#22797;&#30340;&#30697;&#38453;&#25351;&#23450;&#20102;&#39044;&#26399;&#30340;&#33218;&#22870;&#21169;&#65292;&#32780;&#22312;&#20302;&#31209;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;(MDP)&#20013;&#65292;&#23427;&#21487;&#20197;&#25551;&#36848;MDP&#30340;&#36716;&#25442;&#26680;&#12290;&#22312;&#36825;&#20004;&#31181;&#24773;&#20917;&#19979;&#65292;&#30697;&#38453;&#30340;&#27599;&#20010;&#20803;&#32032;&#37117;&#25215;&#36733;&#37325;&#35201;&#20449;&#24687;&#65292;&#25105;&#20204;&#23547;&#27714;&#20855;&#26377;&#20302;&#36880;&#20803;&#32032;&#35823;&#24046;&#30340;&#20272;&#35745;&#26041;&#27861;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#36825;&#20123;&#26041;&#27861;&#36824;&#38656;&#35201;&#36866;&#24212;&#21487;&#29992;&#25968;&#25454;&#20013;&#30340;&#22266;&#26377;&#30456;&#20851;&#24615;&#65288;&#20363;&#22914;&#65292;&#23545;&#20110;MDPs&#65292;&#25968;&#25454;&#30001;&#31995;&#32479;&#36712;&#36857;&#32452;&#25104;&#65289;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#31616;&#21333;&#30340;&#22522;&#20110;&#39057;&#35889;&#30340;&#30697;&#38453;&#20272;&#35745;&#26041;&#27861;&#30340;&#24615;&#33021;&#65306;&#25105;&#20204;&#23637;&#31034;&#20102;&#23427;&#20204;&#26377;&#25928;&#22320;&#24674;&#22797;&#20102;&#30697;&#38453;&#30340;&#22855;&#24322;&#23376;&#31354;&#38388;&#65292;&#24182;&#19988;&#20855;&#26377;&#20960;&#20046;&#26368;&#23567;&#30340;&#36880;&#20803;&#32032;&#35823;&#24046;&#12290;&#36825;&#20123;&#20851;&#20110;&#20302;&#31209;&#30697;&#38453;&#20272;&#35745;&#30340;&#26032;&#32467;&#26524;&#20351;&#24471;&#35774;&#35745;&#23436;&#20840;&#21033;&#29992;&#24213;&#23618;&#20302;&#31209;&#32467;&#26500;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#25104;&#20026;&#21487;&#33021;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#20010;&#36825;&#26679;&#30340;&#31639;&#27861;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study matrix estimation problems arising in reinforcement learning (RL) with low-rank structure. In low-rank bandits, the matrix to be recovered specifies the expected arm rewards, and for low-rank Markov Decision Processes (MDPs), it may for example characterize the transition kernel of the MDP. In both cases, each entry of the matrix carries important information, and we seek estimation methods with low entry-wise error. Importantly, these methods further need to accommodate for inherent correlations in the available data (e.g. for MDPs, the data consists of system trajectories). We investigate the performance of simple spectral-based matrix estimation approaches: we show that they efficiently recover the singular subspaces of the matrix and exhibit nearly-minimal entry-wise error. These new results on low-rank matrix estimation make it possible to devise reinforcement learning algorithms that fully exploit the underlying low-rank structure. We provide two examples of such algorit
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22240;&#26524;&#35268;&#21017;&#23398;&#20064;&#65292;&#25105;&#20204;&#21487;&#20197;&#21033;&#29992;&#21152;&#26435;&#22240;&#26524;&#35268;&#21017;&#26469;&#20272;&#35745;&#21644;&#21152;&#24378;&#23545;&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;&#30340;&#29702;&#35299;&#12290;</title><link>http://arxiv.org/abs/2310.06746</link><description>&lt;p&gt;
&#22240;&#26524;&#35268;&#21017;&#23398;&#20064;&#65306;&#36890;&#36807;&#21152;&#26435;&#22240;&#26524;&#35268;&#21017;&#22686;&#24378;&#23545;&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;&#30340;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Causal Rule Learning: Enhancing the Understanding of Heterogeneous Treatment Effect via Weighted Causal Rules. (arXiv:2310.06746v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06746
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22240;&#26524;&#35268;&#21017;&#23398;&#20064;&#65292;&#25105;&#20204;&#21487;&#20197;&#21033;&#29992;&#21152;&#26435;&#22240;&#26524;&#35268;&#21017;&#26469;&#20272;&#35745;&#21644;&#21152;&#24378;&#23545;&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#37322;&#24615;&#26159;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20272;&#35745;&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;&#26102;&#30340;&#20851;&#38190;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#21307;&#30103;&#24212;&#29992;&#26469;&#35828;&#65292;&#24120;&#24120;&#38656;&#35201;&#20570;&#20986;&#39640;&#39118;&#38505;&#20915;&#31574;&#12290;&#21463;&#21040;&#35299;&#37322;&#24615;&#30340;&#39044;&#27979;&#24615;&#12289;&#25551;&#36848;&#24615;&#12289;&#30456;&#20851;&#24615;&#26694;&#26550;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22240;&#26524;&#35268;&#21017;&#23398;&#20064;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#25214;&#21040;&#25551;&#36848;&#28508;&#22312;&#23376;&#32676;&#30340;&#31934;&#32454;&#22240;&#26524;&#35268;&#21017;&#38598;&#26469;&#20272;&#35745;&#21644;&#22686;&#24378;&#25105;&#20204;&#23545;&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;&#30340;&#29702;&#35299;&#12290;&#22240;&#26524;&#35268;&#21017;&#23398;&#20064;&#21253;&#25324;&#19977;&#20010;&#38454;&#27573;&#65306;&#35268;&#21017;&#21457;&#29616;&#12289;&#35268;&#21017;&#36873;&#25321;&#21644;&#35268;&#21017;&#20998;&#26512;&#12290;&#22312;&#35268;&#21017;&#21457;&#29616;&#38454;&#27573;&#65292;&#25105;&#20204;&#21033;&#29992;&#22240;&#26524;&#26862;&#26519;&#29983;&#25104;&#19968;&#32452;&#20855;&#26377;&#30456;&#24212;&#23376;&#32676;&#24179;&#22343;&#27835;&#30103;&#25928;&#24212;&#30340;&#22240;&#26524;&#35268;&#21017;&#27744;&#12290;&#36873;&#25321;&#38454;&#27573;&#20351;&#29992;D-&#23398;&#20064;&#26041;&#27861;&#20174;&#36825;&#20123;&#35268;&#21017;&#20013;&#36873;&#25321;&#23376;&#38598;&#65292;&#23558;&#20010;&#20307;&#27700;&#24179;&#30340;&#27835;&#30103;&#25928;&#24212;&#20316;&#20026;&#23376;&#32676;&#27700;&#24179;&#25928;&#24212;&#30340;&#32447;&#24615;&#32452;&#21512;&#36827;&#34892;&#35299;&#26500;&#12290;&#36825;&#26377;&#21161;&#20110;&#22238;&#31572;&#20043;&#21069;&#25991;&#29486;&#24573;&#35270;&#30340;&#38382;&#39064;&#65306;&#22914;&#26524;&#19968;&#20010;&#20010;&#20307;&#21516;&#26102;&#23646;&#20110;&#22810;&#20010;&#19981;&#21516;&#30340;&#27835;&#30103;&#23376;&#32676;&#65292;&#20250;&#24590;&#20040;&#26679;&#21602;&#65311;
&lt;/p&gt;
&lt;p&gt;
Interpretability is a key concern in estimating heterogeneous treatment effects using machine learning methods, especially for healthcare applications where high-stake decisions are often made. Inspired by the Predictive, Descriptive, Relevant framework of interpretability, we propose causal rule learning which finds a refined set of causal rules characterizing potential subgroups to estimate and enhance our understanding of heterogeneous treatment effects. Causal rule learning involves three phases: rule discovery, rule selection, and rule analysis. In the rule discovery phase, we utilize a causal forest to generate a pool of causal rules with corresponding subgroup average treatment effects. The selection phase then employs a D-learning method to select a subset of these rules to deconstruct individual-level treatment effects as a linear combination of the subgroup-level effects. This helps to answer an ignored question by previous literature: what if an individual simultaneously bel
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35299;&#26512;&#20102;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#30561;&#30496;&#38454;&#27573;&#20998;&#31867;&#27169;&#22411;&#30340;&#35774;&#35745;&#31354;&#38388;&#65292;&#25214;&#21040;&#20102;&#36866;&#29992;&#20110;&#19981;&#21516;&#36755;&#20837;&#34920;&#31034;&#30340;&#31283;&#20581;&#26550;&#26500;&#65292;&#24182;&#22312;&#30561;&#30496;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2310.06715</link><description>&lt;p&gt;
S4Sleep: &#35299;&#26512;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#30561;&#30496;&#38454;&#27573;&#20998;&#31867;&#27169;&#22411;&#30340;&#35774;&#35745;&#31354;&#38388;
&lt;/p&gt;
&lt;p&gt;
S4Sleep: Elucidating the design space of deep-learning-based sleep stage classification models. (arXiv:2310.06715v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06715
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35299;&#26512;&#20102;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#30561;&#30496;&#38454;&#27573;&#20998;&#31867;&#27169;&#22411;&#30340;&#35774;&#35745;&#31354;&#38388;&#65292;&#25214;&#21040;&#20102;&#36866;&#29992;&#20110;&#19981;&#21516;&#36755;&#20837;&#34920;&#31034;&#30340;&#31283;&#20581;&#26550;&#26500;&#65292;&#24182;&#22312;&#30561;&#30496;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#22810;&#36890;&#36947;&#30561;&#30496;&#33041;&#30005;&#22270;&#35760;&#24405;&#36827;&#34892;&#30561;&#30496;&#38454;&#27573;&#25171;&#20998;&#26159;&#19968;&#39033;&#32791;&#26102;&#19988;&#23384;&#22312;&#26174;&#33879;&#30340;&#35780;&#20998;&#20154;&#21592;&#20043;&#38388;&#24046;&#24322;&#30340;&#20219;&#21153;&#12290;&#22240;&#27492;&#65292;&#24212;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#24102;&#26469;&#24456;&#22823;&#30340;&#30410;&#22788;&#12290;&#34429;&#28982;&#24050;&#32463;&#20026;&#27492;&#25552;&#20986;&#20102;&#35768;&#22810;&#31639;&#27861;&#65292;&#20294;&#26576;&#20123;&#20851;&#38190;&#30340;&#26550;&#26500;&#20915;&#31574;&#24182;&#26410;&#24471;&#21040;&#31995;&#32479;&#24615;&#30340;&#25506;&#32034;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35814;&#32454;&#35843;&#26597;&#20102;&#24191;&#27867;&#30340;&#32534;&#30721;&#22120;-&#39044;&#27979;&#22120;&#26550;&#26500;&#33539;&#30068;&#20869;&#30340;&#36825;&#20123;&#35774;&#35745;&#36873;&#25321;&#12290;&#25105;&#20204;&#25214;&#21040;&#20102;&#36866;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#21644;&#22768;&#35889;&#22270;&#36755;&#20837;&#34920;&#31034;&#30340;&#31283;&#20581;&#26550;&#26500;&#12290;&#36825;&#20123;&#26550;&#26500;&#23558;&#32467;&#26500;&#21270;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#20316;&#20026;&#32452;&#25104;&#37096;&#20998;&#65292;&#23545;&#24191;&#27867;&#30340;SHHS&#25968;&#25454;&#38598;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#32479;&#35745;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;&#36825;&#20123;&#25913;&#36827;&#36890;&#36807;&#32479;&#35745;&#21644;&#31995;&#32479;&#35823;&#24046;&#20272;&#35745;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#25105;&#20204;&#39044;&#35745;&#65292;&#20174;&#26412;&#30740;&#31350;&#20013;&#33719;&#24471;&#30340;&#26550;&#26500;&#27934;&#23519;&#19981;&#20165;&#23545;&#26410;&#26469;&#30340;&#30561;&#30496;&#20998;&#26399;&#30740;&#31350;&#26377;&#20215;&#20540;&#65292;&#32780;&#19988;&#23545;&#25972;&#20307;&#30561;&#30496;&#30740;&#31350;&#37117;&#26377;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Scoring sleep stages in polysomnography recordings is a time-consuming task plagued by significant inter-rater variability. Therefore, it stands to benefit from the application of machine learning algorithms. While many algorithms have been proposed for this purpose, certain critical architectural decisions have not received systematic exploration. In this study, we meticulously investigate these design choices within the broad category of encoder-predictor architectures. We identify robust architectures applicable to both time series and spectrogram input representations. These architectures incorporate structured state space models as integral components, leading to statistically significant advancements in performance on the extensive SHHS dataset. These improvements are assessed through both statistical and systematic error estimations. We anticipate that the architectural insights gained from this study will not only prove valuable for future research in sleep staging but also hol
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38544;&#21464;&#20998;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#31070;&#32463;&#37319;&#26679;&#22120;&#25351;&#23450;&#38544;&#21547;&#20998;&#24067;&#65292;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#36817;&#20284;&#22797;&#26434;&#30340;&#22810;&#23792;&#21644;&#30456;&#20851;&#21518;&#39564;&#20998;&#24067;&#12290;&#36890;&#36807;&#24341;&#20837;&#23616;&#37096;&#32447;&#24615;&#21270;&#30340;&#32422;&#26463;&#65292;&#36991;&#20813;&#20102;&#20381;&#36182;&#39069;&#22806;&#30340;&#32593;&#32476;&#21644;&#19981;&#31283;&#23450;&#23545;&#25239;&#30446;&#26631;&#30340;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#22120;&#26550;&#26500;&#65292;&#39318;&#27425;&#23454;&#29616;&#20102;&#23545;&#25968;&#30334;&#19975;&#20010;&#28508;&#21464;&#37327;&#30340;&#38544;&#21547;&#20998;&#24067;&#12290;&#23454;&#35777;&#20998;&#26512;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#24674;&#22797;&#22823;&#22411;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20013;&#23618;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#36825;&#23545;&#20110;&#32593;&#32476;&#30340;&#24615;&#33021;&#33267;&#20851;&#37325;&#35201;&#12290;</title><link>http://arxiv.org/abs/2310.06643</link><description>&lt;p&gt;
&#39640;&#32500;&#21518;&#39564;&#25512;&#26029;&#30340;&#38544;&#21464;&#20998;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Implicit Variational Inference for High-Dimensional Posteriors. (arXiv:2310.06643v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06643
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38544;&#21464;&#20998;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#31070;&#32463;&#37319;&#26679;&#22120;&#25351;&#23450;&#38544;&#21547;&#20998;&#24067;&#65292;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#36817;&#20284;&#22797;&#26434;&#30340;&#22810;&#23792;&#21644;&#30456;&#20851;&#21518;&#39564;&#20998;&#24067;&#12290;&#36890;&#36807;&#24341;&#20837;&#23616;&#37096;&#32447;&#24615;&#21270;&#30340;&#32422;&#26463;&#65292;&#36991;&#20813;&#20102;&#20381;&#36182;&#39069;&#22806;&#30340;&#32593;&#32476;&#21644;&#19981;&#31283;&#23450;&#23545;&#25239;&#30446;&#26631;&#30340;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#22120;&#26550;&#26500;&#65292;&#39318;&#27425;&#23454;&#29616;&#20102;&#23545;&#25968;&#30334;&#19975;&#20010;&#28508;&#21464;&#37327;&#30340;&#38544;&#21547;&#20998;&#24067;&#12290;&#23454;&#35777;&#20998;&#26512;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#24674;&#22797;&#22823;&#22411;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20013;&#23618;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#36825;&#23545;&#20110;&#32593;&#32476;&#30340;&#24615;&#33021;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21464;&#20998;&#25512;&#26029;&#20013;&#65292;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#22909;&#22788;&#22312;&#20110;&#20934;&#30830;&#25429;&#25417;&#30495;&#23454;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#25351;&#23450;&#38544;&#21547;&#20998;&#24067;&#30340;&#31070;&#32463;&#37319;&#26679;&#22120;&#65292;&#36825;&#23545;&#20110;&#36817;&#20284;&#39640;&#32500;&#31354;&#38388;&#20013;&#22797;&#26434;&#22810;&#23792;&#21644;&#30456;&#20851;&#21518;&#39564;&#20998;&#24067;&#38750;&#24120;&#36866;&#29992;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#23616;&#37096;&#32447;&#24615;&#21270;&#31070;&#32463;&#37319;&#26679;&#22120;&#24341;&#20837;&#26032;&#30340;&#32422;&#26463;&#65292;&#36825;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#65292;&#29616;&#26377;&#26041;&#27861;&#20381;&#36182;&#20110;&#39069;&#22806;&#30340;&#37492;&#21035;&#22120;&#32593;&#32476;&#21644;&#19981;&#31283;&#23450;&#30340;&#23545;&#25239;&#30446;&#26631;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#22120;&#26550;&#26500;&#65292;&#39318;&#27425;&#23454;&#29616;&#20102;&#23545;&#25968;&#30334;&#19975;&#20010;&#28508;&#21464;&#37327;&#30340;&#38544;&#21547;&#20998;&#24067;&#65292;&#36890;&#36807;&#20351;&#29992;&#21487;&#24494;&#20998;&#30340;&#25968;&#20540;&#36817;&#20284;&#26469;&#35299;&#20915;&#35745;&#31639;&#19978;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#20998;&#26512;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#22312;&#22823;&#22411;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20013;&#24674;&#22797;&#23618;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#36825;&#26159;&#32593;&#32476;&#24615;&#33021;&#20851;&#38190;&#20294;&#33261;&#21517;&#26157;&#33879;&#30340;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In variational inference, the benefits of Bayesian models rely on accurately capturing the true posterior distribution. We propose using neural samplers that specify implicit distributions, which are well-suited for approximating complex multimodal and correlated posteriors in high-dimensional spaces. Our approach advances inference using implicit distributions by introducing novel bounds that come about by locally linearising the neural sampler. This is distinct from existing methods that rely on additional discriminator networks and unstable adversarial objectives. Furthermore, we present a new sampler architecture that, for the first time, enables implicit distributions over millions of latent variables, addressing computational concerns by using differentiable numerical approximations. Our empirical analysis indicates our method is capable of recovering correlations across layers in large Bayesian neural networks, a property that is crucial for a network's performance but notorious
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20351;&#29992;XAI&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26089;&#26399;&#20316;&#29289;&#20998;&#31867;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#35782;&#21035;&#37325;&#35201;&#30340;&#26102;&#38388;&#27493;&#39588;&#65292;&#24182;&#30830;&#23450;&#26368;&#30701;&#20998;&#31867;&#26102;&#38388;&#33539;&#22260;&#30340;&#36793;&#30028;&#21306;&#22495;&#12290;&#22312;&#20934;&#30830;&#24615;&#21644;&#26089;&#26399;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2310.06574</link><description>&lt;p&gt;
XAI&#29992;&#20110;&#26089;&#26399;&#20316;&#29289;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
XAI for Early Crop Classification. (arXiv:2310.06574v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06574
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;XAI&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26089;&#26399;&#20316;&#29289;&#20998;&#31867;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#35782;&#21035;&#37325;&#35201;&#30340;&#26102;&#38388;&#27493;&#39588;&#65292;&#24182;&#30830;&#23450;&#26368;&#30701;&#20998;&#31867;&#26102;&#38388;&#33539;&#22260;&#30340;&#36793;&#30028;&#21306;&#22495;&#12290;&#22312;&#20934;&#30830;&#24615;&#21644;&#26089;&#26399;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20351;&#29992;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#26041;&#27861;&#35782;&#21035;&#37325;&#35201;&#26102;&#38388;&#27493;&#39588;&#30340;&#26089;&#26399;&#20316;&#29289;&#20998;&#31867;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21253;&#25324;&#35757;&#32451;&#19968;&#20010;&#22522;&#20934;&#30340;&#20316;&#29289;&#20998;&#31867;&#27169;&#22411;&#36827;&#34892;&#23618;&#32423;&#30456;&#20851;&#20256;&#25773;&#65288;LRP&#65289;&#65292;&#20197;&#20415;&#21487;&#20197;&#30830;&#23450;&#26174;&#33879;&#30340;&#26102;&#38388;&#27493;&#39588;&#12290;&#25105;&#20204;&#36873;&#25321;&#20102;&#19968;&#23450;&#25968;&#37327;&#30340;&#37325;&#35201;&#26102;&#38388;&#32034;&#24341;&#26469;&#21019;&#24314;&#26368;&#30701;&#20998;&#31867;&#26102;&#38388;&#33539;&#22260;&#30340;&#36793;&#30028;&#21306;&#22495;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;2019&#24180;4&#26376;21&#26085;&#33267;2019&#24180;8&#26376;9&#26085;&#26399;&#38388;&#22312;&#20934;&#30830;&#24615;&#21644;&#26089;&#26399;&#24615;&#26041;&#38754;&#20855;&#26377;&#26368;&#22909;&#30340;&#26435;&#34913;&#12290;&#19982;&#20351;&#29992;&#23436;&#25972;&#26102;&#38388;&#24207;&#21015;&#30456;&#27604;&#65292;&#36825;&#20010;&#26102;&#38388;&#33539;&#22260;&#21482;&#25439;&#22833;&#20102;0.75&#65285;&#30340;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#30001;LRP&#23548;&#20986;&#30340;&#37325;&#35201;&#26102;&#38388;&#27493;&#39588;&#36824;&#31361;&#20986;&#20102;&#36755;&#20837;&#20540;&#20013;&#21306;&#20998;&#19981;&#21516;&#31867;&#21035;&#30340;&#32454;&#33410;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an approach for early crop classification through identifying important timesteps with eXplainable AI (XAI) methods. Our approach consists of training a baseline crop classification model to carry out layer-wise relevance propagation (LRP) so that the salient time step can be identified. We chose a selected number of such important time indices to create the bounding region of the shortest possible classification timeframe. We identified the period 21st April 2019 to 9th August 2019 as having the best trade-off in terms of accuracy and earliness. This timeframe only suffers a 0.75% loss in accuracy as compared to using the full timeseries. We observed that the LRP-derived important timesteps also highlight small details in input values that differentiates between different classes and
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36317;&#31163;&#30340;&#20840;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#26032;&#24320;&#21457;&#30340;&#24037;&#20855;&#35780;&#20272;&#20102;&#20854;&#39118;&#38505;-&#25928;&#29992;&#29305;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.06571</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#36317;&#31163;&#30340;&#20840;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#26041;&#27861;&#30340;&#32479;&#35745;&#24615;&#36136;&#21644;&#38544;&#31169;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Statistical properties and privacy guarantees of an original distance-based fully synthetic data generation method. (arXiv:2310.06571v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06571
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36317;&#31163;&#30340;&#20840;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#26032;&#24320;&#21457;&#30340;&#24037;&#20855;&#35780;&#20272;&#20102;&#20854;&#39118;&#38505;-&#25928;&#29992;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24341;&#35328;&#65306;&#21407;&#22987;&#30740;&#31350;&#29983;&#25104;&#30340;&#25968;&#25454;&#37327;&#21576;&#25351;&#25968;&#22686;&#38271;&#12290;&#20026;&#20102;&#36981;&#23432;&#24320;&#25918;&#31185;&#23398;&#21407;&#21017;&#65292;&#24314;&#35758;&#23558;&#20854;&#20844;&#24320;&#21457;&#24067;&#12290;&#28982;&#32780;&#65292;&#20174;&#20154;&#31867;&#21442;&#19982;&#32773;&#25910;&#38598;&#30340;&#25968;&#25454;&#19981;&#33021;&#30452;&#25509;&#21457;&#24067;&#65292;&#22240;&#20026;&#20250;&#28041;&#21450;&#38544;&#31169;&#38382;&#39064;&#12290;&#23436;&#20840;&#21512;&#25104;&#25968;&#25454;&#26159;&#23545;&#27492;&#25361;&#25112;&#30340;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#27861;&#22269;&#20154;&#21475;&#27969;&#34892;&#30149;&#23398;&#19982;&#20581;&#24247;&#30740;&#31350;&#20013;&#24515;&#25506;&#32034;&#20102;&#36825;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#22522;&#20110;&#20998;&#31867;&#21644;&#22238;&#24402;&#26641;&#20197;&#21450;&#19968;&#31181;&#21407;&#22987;&#30340;&#22522;&#20110;&#36317;&#31163;&#30340;&#36807;&#28388;&#26041;&#27861;&#26500;&#24314;&#20102;&#19968;&#20010;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#26694;&#26550;&#12290;&#26412;&#30740;&#31350;&#30340;&#30446;&#26631;&#26159;&#24320;&#21457;&#36825;&#20010;&#26694;&#26550;&#30340;&#25913;&#36827;&#29256;&#26412;&#65292;&#24182;&#20351;&#29992;&#32463;&#39564;&#21644;&#24418;&#24335;&#24037;&#20855;&#35780;&#20272;&#20854;&#39118;&#38505;-&#25928;&#29992;&#29305;&#24615;&#65292;&#21253;&#25324;&#20026;&#27492;&#35780;&#20272;&#32780;&#24320;&#21457;&#30340;&#26032;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
Introduction: The amount of data generated by original research is growing exponentially. Publicly releasing them is recommended to comply with the Open Science principles. However, data collected from human participants cannot be released as-is without raising privacy concerns. Fully synthetic data represent a promising answer to this challenge. This approach is explored by the French Centre de Recherche en {\'E}pid{\'e}miologie et Sant{\'e} des Populations in the form of a synthetic data generation framework based on Classification and Regression Trees and an original distance-based filtering. The goal of this work was to develop a refined version of this framework and to assess its risk-utility profile with empirical and formal tools, including novel ones developed for the purpose of this evaluation.Materials and Methods: Our synthesis framework consists of four successive steps, each of which is designed to prevent specific risks of disclosure. We assessed its performance by applyi
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25552;&#20986;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#25105;&#20204;&#21487;&#20197;&#35299;&#37322;&#26377;&#20851;&#20381;&#36182;&#36755;&#20837;&#30340;&#40657;&#31665;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19968;&#20123;&#21512;&#29702;&#30340;&#20551;&#35774;&#19979;&#65292;&#38750;&#32447;&#24615;&#20989;&#25968;&#21487;&#20197;&#21807;&#19968;&#20998;&#35299;&#20026;&#27599;&#20010;&#21487;&#33021;&#23376;&#38598;&#30340;&#20989;&#25968;&#20043;&#21644;&#12290;&#36825;&#20010;&#26694;&#26550;&#26377;&#25928;&#22320;&#25512;&#24191;&#20102;Hoeffding&#20998;&#35299;&#65292;&#24182;&#25552;&#20379;&#20102;&#26032;&#39062;&#30340;&#21487;&#35299;&#37322;&#24615;&#25351;&#26631;&#12290;</title><link>http://arxiv.org/abs/2310.06567</link><description>&lt;p&gt;
&#36890;&#36807;Hoeffding&#20998;&#35299;&#30340;&#25512;&#24191;&#65292;&#29702;&#35299;&#26377;&#20851;&#20381;&#36182;&#36755;&#20837;&#30340;&#40657;&#31665;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Understanding black-box models with dependent inputs through a generalization of Hoeffding's decomposition. (arXiv:2310.06567v1 [math.FA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06567
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20986;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#25105;&#20204;&#21487;&#20197;&#35299;&#37322;&#26377;&#20851;&#20381;&#36182;&#36755;&#20837;&#30340;&#40657;&#31665;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19968;&#20123;&#21512;&#29702;&#30340;&#20551;&#35774;&#19979;&#65292;&#38750;&#32447;&#24615;&#20989;&#25968;&#21487;&#20197;&#21807;&#19968;&#20998;&#35299;&#20026;&#27599;&#20010;&#21487;&#33021;&#23376;&#38598;&#30340;&#20989;&#25968;&#20043;&#21644;&#12290;&#36825;&#20010;&#26694;&#26550;&#26377;&#25928;&#22320;&#25512;&#24191;&#20102;Hoeffding&#20998;&#35299;&#65292;&#24182;&#25552;&#20379;&#20102;&#26032;&#39062;&#30340;&#21487;&#35299;&#37322;&#24615;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#37322;&#40657;&#31665;&#27169;&#22411;&#30340;&#20027;&#35201;&#25361;&#25112;&#20043;&#19968;&#26159;&#33021;&#22815;&#23558;&#38750;&#20114;&#19981;&#30456;&#20851;&#38543;&#26426;&#36755;&#20837;&#30340;&#24179;&#26041;&#21487;&#31215;&#20989;&#25968;&#21807;&#19968;&#20998;&#35299;&#20026;&#27599;&#20010;&#21487;&#33021;&#23376;&#38598;&#30340;&#20989;&#25968;&#20043;&#21644;&#12290;&#28982;&#32780;&#65292;&#22788;&#29702;&#36755;&#20837;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#21487;&#33021;&#24456;&#22797;&#26434;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#26469;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#65292;&#23558;&#19977;&#20010;&#25968;&#23398;&#39046;&#22495;&#32852;&#31995;&#36215;&#26469;&#65306;&#27010;&#29575;&#35770;&#12289;&#20989;&#25968;&#20998;&#26512;&#21644;&#32452;&#21512;&#25968;&#23398;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312;&#36755;&#20837;&#19978;&#30340;&#20004;&#20010;&#21512;&#29702;&#20551;&#35774;&#19979;&#65288;&#38750;&#23436;&#32654;&#30340;&#20989;&#25968;&#20381;&#36182;&#24615;&#21644;&#38750;&#36864;&#21270;&#30340;&#38543;&#26426;&#20381;&#36182;&#24615;&#65289;&#65292;&#24635;&#26159;&#21487;&#20197;&#21807;&#19968;&#20998;&#35299;&#36825;&#26679;&#19968;&#20010;&#20989;&#25968;&#12290;&#36825;&#31181;&#8220;&#35268;&#33539;&#20998;&#35299;&#8221;&#30456;&#23545;&#30452;&#35266;&#65292;&#25581;&#31034;&#20102;&#38750;&#32447;&#24615;&#30456;&#20851;&#36755;&#20837;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#32447;&#24615;&#29305;&#24615;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20013;&#65292;&#25105;&#20204;&#26377;&#25928;&#22320;&#25512;&#24191;&#20102;&#20247;&#25152;&#21608;&#30693;&#30340;Hoeffding&#20998;&#35299;&#65292;&#21487;&#20197;&#30475;&#20316;&#26159;&#19968;&#20010;&#29305;&#27530;&#24773;&#20917;&#12290;&#40657;&#31665;&#27169;&#22411;&#30340;&#26012;&#25237;&#24433;&#20026;&#26032;&#39062;&#30340;&#21487;&#35299;&#37322;&#24615;&#25351;&#26631;&#25552;&#20379;&#20102;&#21487;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the main challenges for interpreting black-box models is the ability to uniquely decompose square-integrable functions of non-mutually independent random inputs into a sum of functions of every possible subset of variables. However, dealing with dependencies among inputs can be complicated. We propose a novel framework to study this problem, linking three domains of mathematics: probability theory, functional analysis, and combinatorics. We show that, under two reasonable assumptions on the inputs (non-perfect functional dependence and non-degenerate stochastic dependence), it is always possible to decompose uniquely such a function. This ``canonical decomposition'' is relatively intuitive and unveils the linear nature of non-linear functions of non-linearly dependent inputs. In this framework, we effectively generalize the well-known Hoeffding decomposition, which can be seen as a particular case. Oblique projections of the black-box model allow for novel interpretability indic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#21464;&#37327;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#25968;&#25454;&#32423;&#28151;&#21512;&#31574;&#30053;&#36873;&#25321;&#26041;&#27861;&#65292;&#36890;&#36807;&#24179;&#34913;&#30913;&#30424;SMART&#25968;&#25454;&#38598;&#24182;&#32467;&#21512;&#36951;&#20256;&#31639;&#27861;&#65292;&#25552;&#39640;&#30913;&#30424;&#25925;&#38556;&#20998;&#31867;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.06537</link><description>&lt;p&gt;
&#22522;&#20110;&#22810;&#21464;&#37327;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#30913;&#30424;&#25925;&#38556;&#39044;&#27979;&#27169;&#22411;&#30340;&#25968;&#25454;&#32423;&#28151;&#21512;&#31574;&#30053;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Data-level hybrid strategy selection for disk fault prediction model based on multivariate GAN. (arXiv:2310.06537v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06537
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#21464;&#37327;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#25968;&#25454;&#32423;&#28151;&#21512;&#31574;&#30053;&#36873;&#25321;&#26041;&#27861;&#65292;&#36890;&#36807;&#24179;&#34913;&#30913;&#30424;SMART&#25968;&#25454;&#38598;&#24182;&#32467;&#21512;&#36951;&#20256;&#31639;&#27861;&#65292;&#25552;&#39640;&#30913;&#30424;&#25925;&#38556;&#20998;&#31867;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#31867;&#21035;&#19981;&#24179;&#34913;&#26159;&#20998;&#31867;&#38382;&#39064;&#20013;&#24120;&#35265;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#23569;&#25968;&#31867;&#26679;&#26412;&#22312;&#20998;&#31867;&#20219;&#21153;&#20013;&#24448;&#24448;&#26356;&#37325;&#35201;&#19988;&#26356;&#23481;&#26131;&#34987;&#35823;&#20998;&#31867;&#12290;&#22240;&#27492;&#65292;&#35299;&#20915;&#25968;&#25454;&#31867;&#21035;&#19981;&#24179;&#34913;&#30340;&#20998;&#31867;&#38382;&#39064;&#38750;&#24120;&#37325;&#35201;&#12290;SMART&#25968;&#25454;&#38598;&#26159;&#19968;&#20010;&#26126;&#26174;&#23384;&#22312;&#31867;&#21035;&#19981;&#24179;&#34913;&#30340;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#22823;&#37327;&#20581;&#24247;&#26679;&#26412;&#21644;&#30456;&#23545;&#36739;&#23569;&#30340;&#32570;&#38519;&#26679;&#26412;&#12290;&#35813;&#25968;&#25454;&#38598;&#21487;&#20316;&#20026;&#30913;&#30424;&#20581;&#24247;&#29366;&#20917;&#30340;&#21487;&#38752;&#25351;&#26631;&#12290;&#26412;&#25991;&#36890;&#36807;&#28151;&#21512;&#24182;&#25972;&#21512;&#22810;&#21464;&#37327;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;(GAN)&#21512;&#25104;&#30340;&#25968;&#25454;&#65292;&#20197;&#22312;&#25968;&#25454;&#32423;&#21035;&#19978;&#24179;&#34913;&#30913;&#30424;SMART&#25968;&#25454;&#38598;&#65307;&#20877;&#32467;&#21512;&#36951;&#20256;&#31639;&#27861;&#65292;&#25552;&#39640;&#29305;&#23450;&#20998;&#31867;&#27169;&#22411;&#19978;&#30340;&#30913;&#30424;&#25925;&#38556;&#20998;&#31867;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data class imbalance is a common problem in classification problems, where minority class samples are often more important and more costly to misclassify in a classification task. Therefore, it is very important to solve the data class imbalance classification problem. The SMART dataset exhibits an evident class imbalance, comprising a substantial quantity of healthy samples and a comparatively limited number of defective samples. This dataset serves as a reliable indicator of the disc's health status. In this paper, we obtain the best balanced disk SMART dataset for a specific classification model by mixing and integrating the data synthesised by multivariate generative adversarial networks (GAN) to balance the disk SMART dataset at the data level; and combine it with genetic algorithms to obtain higher disk fault classification prediction accuracy on a specific classification model.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#23618;&#22495;&#36866;&#24212;&#23398;&#20064;&#25216;&#26415;&#30340;&#30828;&#30424;&#25925;&#38556;&#39044;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#28304;&#39046;&#22495;&#21644;&#30446;&#26631;&#39046;&#22495;&#20043;&#38388;&#30340;&#23545;&#27604;&#65292;&#25104;&#21151;&#25552;&#39640;&#20102;&#23545;&#20855;&#26377;&#23569;&#37327;&#25925;&#38556;&#26679;&#26412;&#30340;&#30828;&#30424;&#25968;&#25454;&#36827;&#34892;&#25925;&#38556;&#39044;&#27979;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.06534</link><description>&lt;p&gt;
&#22522;&#20110;&#22810;&#23618;&#22495;&#36866;&#24212;&#23398;&#20064;&#30340;&#30828;&#30424;&#25925;&#38556;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Disk failure prediction based on multi-layer domain adaptive learning. (arXiv:2310.06534v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06534
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#23618;&#22495;&#36866;&#24212;&#23398;&#20064;&#25216;&#26415;&#30340;&#30828;&#30424;&#25925;&#38556;&#39044;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#28304;&#39046;&#22495;&#21644;&#30446;&#26631;&#39046;&#22495;&#20043;&#38388;&#30340;&#23545;&#27604;&#65292;&#25104;&#21151;&#25552;&#39640;&#20102;&#23545;&#20855;&#26377;&#23569;&#37327;&#25925;&#38556;&#26679;&#26412;&#30340;&#30828;&#30424;&#25968;&#25454;&#36827;&#34892;&#25925;&#38556;&#39044;&#27979;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#25968;&#25454;&#23384;&#20648;&#23481;&#26131;&#21457;&#29983;&#25925;&#38556;&#12290;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20381;&#36182;&#20110;&#21382;&#21490;&#25968;&#25454;&#36827;&#34892;&#39044;&#27979;&#65292;&#22312;&#30828;&#30424;&#25925;&#38556;&#39044;&#27979;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#23618;&#22495;&#36866;&#24212;&#23398;&#20064;&#25216;&#26415;&#30340;&#30828;&#30424;&#25925;&#38556;&#39044;&#27979;&#26032;&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#36873;&#25321;&#23384;&#22312;&#22823;&#37327;&#25925;&#38556;&#30340;&#30828;&#30424;&#25968;&#25454;&#20316;&#20026;&#28304;&#39046;&#22495;&#65292;&#36873;&#25321;&#23384;&#22312;&#36739;&#23569;&#25925;&#38556;&#30340;&#30828;&#30424;&#25968;&#25454;&#20316;&#20026;&#30446;&#26631;&#39046;&#22495;&#12290;&#36890;&#36807;&#36873;&#25321;&#30340;&#28304;&#39046;&#22495;&#21644;&#30446;&#26631;&#39046;&#22495;&#36827;&#34892;&#29305;&#24449;&#25552;&#21462;&#32593;&#32476;&#30340;&#35757;&#32451;&#12290;&#36890;&#36807;&#28304;&#39046;&#22495;&#21644;&#30446;&#26631;&#39046;&#22495;&#20043;&#38388;&#30340;&#23545;&#27604;&#65292;&#20419;&#36827;&#20102;&#35786;&#26029;&#30693;&#35782;&#20174;&#28304;&#39046;&#22495;&#21521;&#30446;&#26631;&#39046;&#22495;&#30340;&#36716;&#31227;&#12290;&#26681;&#25454;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#25216;&#26415;&#33021;&#22815;&#29983;&#25104;&#21487;&#38752;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#24182;&#25552;&#39640;&#23545;&#20855;&#26377;&#23569;&#37327;&#25925;&#38556;&#26679;&#26412;&#30340;&#30828;&#30424;&#25968;&#25454;&#36827;&#34892;&#25925;&#38556;&#39044;&#27979;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large scale data storage is susceptible to failure. As disks are damaged and replaced, traditional machine learning models, which rely on historical data to make predictions, struggle to accurately predict disk failures. This paper presents a novel method for predicting disk failures by leveraging multi-layer domain adaptive learning techniques. First, disk data with numerous faults is selected as the source domain, and disk data with fewer faults is selected as the target domain. A training of the feature extraction network is performed with the selected origin and destination domains. The contrast between the two domains facilitates the transfer of diagnostic knowledge from the domain of source and target. According to the experimental findings, it has been demonstrated that the proposed technique can generate a reliable prediction model and improve the ability to predict failures on disk data with few failure samples.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20154;&#31867;&#20803;&#38899;&#30340;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#65292;&#37325;&#28857;&#25506;&#35752;&#20102;&#20449;&#21495;&#34920;&#31034;&#30340;&#36873;&#25321;&#23545;&#32467;&#26524;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.06508</link><description>&lt;p&gt;
&#20154;&#31867;&#20803;&#38899;&#30340;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#65306;&#36328;&#34920;&#31034;&#31354;&#38388;&#30340;&#25345;&#32493;&#21516;&#35843;
&lt;/p&gt;
&lt;p&gt;
Topological data analysis of human vowels: Persistent homologies across representation spaces. (arXiv:2310.06508v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06508
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20154;&#31867;&#20803;&#38899;&#30340;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#65292;&#37325;&#28857;&#25506;&#35752;&#20102;&#20449;&#21495;&#34920;&#31034;&#30340;&#36873;&#25321;&#23545;&#32467;&#26524;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#65288;TDA&#65289;&#22312;&#20449;&#21495;/&#22270;&#20687;&#22788;&#29702;&#20013;&#24050;&#34987;&#25104;&#21151;&#24212;&#29992;&#20110;&#21508;&#31181;&#20219;&#21153;&#65292;&#21253;&#25324;&#21487;&#35270;&#21270;&#21644;&#30417;&#30563;/&#26080;&#30417;&#30563;&#20998;&#31867;&#12290;&#36890;&#24120;&#65292;&#25299;&#25169;&#29305;&#24449;&#26159;&#20174;&#25345;&#32493;&#21516;&#35843;&#29702;&#35770;&#20013;&#33719;&#24471;&#30340;&#12290;&#26631;&#20934;&#30340;TDA&#27969;&#31243;&#20174;&#21407;&#22987;&#20449;&#21495;&#25968;&#25454;&#25110;&#20854;&#34920;&#31034;&#24320;&#22987;&#65292;&#28982;&#21518;&#22522;&#20110;&#39044;&#23450;&#20041;&#30340;&#36807;&#28388;&#26500;&#24314;&#22810;&#23610;&#24230;&#25299;&#25169;&#32467;&#26500;&#65292;&#26368;&#21518;&#35745;&#31639;&#29992;&#20110;&#36827;&#19968;&#27493;&#21033;&#29992;&#30340;&#25299;&#25169;&#26631;&#35760;&#12290;&#24120;&#29992;&#30340;&#25299;&#25169;&#26631;&#35760;&#26159;&#25345;&#32493;&#22270;&#65288;&#25110;&#20854;&#21464;&#25442;&#65289;&#12290;&#24403;&#21069;&#30340;&#30740;&#31350;&#35752;&#35770;&#20102;&#21033;&#29992;&#25299;&#25169;&#26631;&#35760;&#30340;&#22810;&#31181;&#26041;&#24335;&#30340;&#21518;&#26524;&#65292;&#20294;&#24456;&#23569;&#35752;&#35770;&#36807;&#36807;&#28388;&#30340;&#36873;&#25321;&#65292;&#25105;&#20204;&#25152;&#30693;&#36947;&#30340;&#65292;&#23545;&#20449;&#21495;&#34920;&#31034;&#30340;&#36873;&#25321;&#23578;&#26410;&#25104;&#20026;&#30740;&#31350;&#30340;&#23545;&#35937;&#12290;&#26412;&#25991;&#23581;&#35797;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25910;&#38598;&#20102;&#30495;&#23454;&#30340;&#38899;&#39057;&#25968;&#25454;&#24182;&#24314;
&lt;/p&gt;
&lt;p&gt;
Topological Data Analysis (TDA) has been successfully used for various tasks in signal/image processing, from visualization to supervised/unsupervised classification. Often, topological characteristics are obtained from persistent homology theory. The standard TDA pipeline starts from the raw signal data or a representation of it. Then, it consists in building a multiscale topological structure on the top of the data using a pre-specified filtration, and finally to compute the topological signature to be further exploited. The commonly used topological signature is a persistent diagram (or transformations of it). Current research discusses the consequences of the many ways to exploit topological signatures, much less often the choice of the filtration, but to the best of our knowledge, the choice of the representation of a signal has not been the subject of any study yet. This paper attempts to provide some answers on the latter problem. To this end, we collected real audio data and bu
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20048;&#39640;&#31215;&#26408;&#65292;&#36890;&#36807;&#38598;&#25104;&#23616;&#37096;&#29305;&#24449;&#20016;&#23500;&#21644;&#20840;&#23616;&#20869;&#23481;&#21327;&#35843;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#19988;&#21487;&#33258;&#36866;&#24212;&#30340;&#36845;&#20195;&#32454;&#21270;&#25193;&#25955;&#24314;&#27169;&#12290;&#36825;&#20123;&#31215;&#26408;&#21487;&#20197;&#22534;&#21472;&#22312;&#19968;&#36215;&#65292;&#29992;&#20110;&#22312;&#27979;&#35797;&#26102;&#26681;&#25454;&#38656;&#35201;&#36827;&#34892;&#37325;&#26500;&#65292;&#20174;&#32780;&#20943;&#23569;&#37319;&#26679;&#25104;&#26412;&#24182;&#29983;&#25104;&#39640;&#20998;&#36776;&#29575;&#22270;&#20687;&#12290;</title><link>http://arxiv.org/abs/2310.06389</link><description>&lt;p&gt;
&#23398;&#20064;&#21487;&#22534;&#21472;&#21644;&#21487;&#36339;&#36807;&#30340;&#20048;&#39640;&#31215;&#26408;&#20197;&#23454;&#29616;&#39640;&#25928;&#12289;&#21487;&#37325;&#26500;&#21644;&#21487;&#21464;&#20998;&#36776;&#29575;&#30340;&#25193;&#25955;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Learning Stackable and Skippable LEGO Bricks for Efficient, Reconfigurable, and Variable-Resolution Diffusion Modeling. (arXiv:2310.06389v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06389
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20048;&#39640;&#31215;&#26408;&#65292;&#36890;&#36807;&#38598;&#25104;&#23616;&#37096;&#29305;&#24449;&#20016;&#23500;&#21644;&#20840;&#23616;&#20869;&#23481;&#21327;&#35843;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#19988;&#21487;&#33258;&#36866;&#24212;&#30340;&#36845;&#20195;&#32454;&#21270;&#25193;&#25955;&#24314;&#27169;&#12290;&#36825;&#20123;&#31215;&#26408;&#21487;&#20197;&#22534;&#21472;&#22312;&#19968;&#36215;&#65292;&#29992;&#20110;&#22312;&#27979;&#35797;&#26102;&#26681;&#25454;&#38656;&#35201;&#36827;&#34892;&#37325;&#26500;&#65292;&#20174;&#32780;&#20943;&#23569;&#37319;&#26679;&#25104;&#26412;&#24182;&#29983;&#25104;&#39640;&#20998;&#36776;&#29575;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#29983;&#25104;&#30495;&#23454;&#24863;&#22270;&#20687;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#35757;&#32451;&#21644;&#37319;&#26679;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#23613;&#31649;&#26377;&#21508;&#31181;&#25216;&#26415;&#26469;&#35299;&#20915;&#36825;&#20123;&#35745;&#31639;&#25361;&#25112;&#65292;&#20294;&#19968;&#20010;&#36739;&#23569;&#25506;&#32034;&#30340;&#38382;&#39064;&#26159;&#35774;&#35745;&#19968;&#20010;&#39640;&#25928;&#19988;&#36866;&#24212;&#24615;&#24378;&#30340;&#32593;&#32476;&#39592;&#24178;&#65292;&#29992;&#20110;&#36845;&#20195;&#32454;&#21270;&#12290;&#24403;&#21069;&#30340;&#36873;&#39033;&#22914;U-Net&#21644;Vision Transformer&#36890;&#24120;&#20381;&#36182;&#20110;&#36164;&#28304;&#23494;&#38598;&#22411;&#30340;&#28145;&#24230;&#32593;&#32476;&#65292;&#32570;&#20047;&#22312;&#21464;&#37327;&#20998;&#36776;&#29575;&#19979;&#29983;&#25104;&#22270;&#20687;&#25110;&#20351;&#29992;&#27604;&#35757;&#32451;&#20013;&#26356;&#23567;&#30340;&#32593;&#32476;&#25152;&#38656;&#30340;&#28789;&#27963;&#24615;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#20048;&#39640;&#31215;&#26408;&#65292;&#23427;&#20204;&#26080;&#32541;&#38598;&#25104;&#20102;&#23616;&#37096;&#29305;&#24449;&#20016;&#23500;&#21644;&#20840;&#23616;&#20869;&#23481;&#21327;&#35843;&#12290;&#36825;&#20123;&#31215;&#26408;&#21487;&#20197;&#22534;&#21472;&#22312;&#19968;&#36215;&#65292;&#21019;&#24314;&#19968;&#20010;&#27979;&#35797;&#26102;&#21487;&#37325;&#26500;&#30340;&#25193;&#25955;&#39592;&#24178;&#65292;&#20801;&#35768;&#36873;&#25321;&#24615;&#36339;&#36807;&#31215;&#26408;&#20197;&#20943;&#23569;&#37319;&#26679;&#25104;&#26412;&#65292;&#24182;&#29983;&#25104;&#27604;&#35757;&#32451;&#25968;&#25454;&#26356;&#39640;&#20998;&#36776;&#29575;&#30340;&#22270;&#20687;&#12290;&#20048;&#39640;&#31215;&#26408;&#36890;&#36807;MLP&#23545;&#23616;&#37096;&#21306;&#22495;&#36827;&#34892;&#20016;&#23500;&#65292;&#24182;&#20351;&#29992;Transformer&#22359;&#36827;&#34892;&#21464;&#25442;&#65292;&#21516;&#26102;&#20445;&#25345;&#19968;&#33268;&#30340;&#20840;&#20998;&#36776;&#29575;
&lt;/p&gt;
&lt;p&gt;
Diffusion models excel at generating photo-realistic images but come with significant computational costs in both training and sampling. While various techniques address these computational challenges, a less-explored issue is designing an efficient and adaptable network backbone for iterative refinement. Current options like U-Net and Vision Transformer often rely on resource-intensive deep networks and lack the flexibility needed for generating images at variable resolutions or with a smaller network than used in training. This study introduces LEGO bricks, which seamlessly integrate Local-feature Enrichment and Global-content Orchestration. These bricks can be stacked to create a test-time reconfigurable diffusion backbone, allowing selective skipping of bricks to reduce sampling costs and generate higher-resolution images than the training data. LEGO bricks enrich local regions with an MLP and transform them using a Transformer block while maintaining a consistent full-resolution i
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#23398;&#20064;&#24050;&#30693;&#39592;&#26550;&#30340;&#26377;&#30028;&#24230;&#22810;&#26641;&#30340;&#31639;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#20869;&#30340;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#12290;&#36825;&#23545;&#20110;&#22797;&#26434;&#27010;&#29575;&#20998;&#24067;&#30340;&#23398;&#20064;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2310.06333</link><description>&lt;p&gt;
&#23398;&#20064;&#20855;&#26377;&#24050;&#30693;&#39592;&#26550;&#30340;&#26377;&#30028;&#24230;&#22810;&#26641;
&lt;/p&gt;
&lt;p&gt;
Learning bounded-degree polytrees with known skeleton. (arXiv:2310.06333v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06333
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#23398;&#20064;&#24050;&#30693;&#39592;&#26550;&#30340;&#26377;&#30028;&#24230;&#22810;&#26641;&#30340;&#31639;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#20869;&#30340;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#12290;&#36825;&#23545;&#20110;&#22797;&#26434;&#27010;&#29575;&#20998;&#24067;&#30340;&#23398;&#20064;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20026;&#39640;&#32500;&#27010;&#29575;&#20998;&#24067;&#30340;&#19968;&#31867;&#20016;&#23500;&#30340;&#22810;&#26641;&#65288;polytrees&#65289;&#8212;&#8212;&#26377;&#30028;&#24230;&#22810;&#26641;&#65292;&#24314;&#31435;&#20102;&#39640;&#25928;&#36866;&#24403;&#23398;&#20064;&#30340;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#12290;&#26377;&#30028;&#24230;&#22810;&#26641;&#26159;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#23376;&#31867;&#65292;&#36125;&#21494;&#26031;&#32593;&#32476;&#26159;&#19968;&#31181;&#24191;&#27867;&#30740;&#31350;&#30340;&#22270;&#27169;&#22411;&#31867;&#22411;&#12290;&#26368;&#36817;&#65292;Bhattacharyya&#31561;&#20154;&#65288;2021&#65289;&#36890;&#36807;&#25552;&#20379;&#19968;&#31181;&#39640;&#25928;&#31639;&#27861;&#65292;&#22312;&#24050;&#30693;&#26080;&#21521;&#22270;&#65288;&#39592;&#26550;&#65289;&#30340;&#24773;&#20917;&#19979;&#65292;&#20026;1-&#22810;&#26641;&#24674;&#22797;&#20102;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#12290;&#25105;&#20204;&#36890;&#36807;&#25193;&#23637;&#20182;&#20204;&#30340;&#32467;&#26524;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#39640;&#25928;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#20869;&#23398;&#20064;&#20219;&#20309;&#26377;&#30028;&#24230;&#30340;$d$-&#22810;&#26641;&#12290;&#25105;&#20204;&#23558;&#31639;&#27861;&#19982;&#20449;&#24687;&#35770;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#19979;&#30028;&#32467;&#21512;&#36215;&#26469;&#65292;&#34920;&#26126;&#23545;&#32500;&#24230;&#21644;&#30446;&#26631;&#31934;&#24230;&#21442;&#25968;&#30340;&#20381;&#36182;&#20960;&#20046;&#26159;&#32039;&#33268;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We establish finite-sample guarantees for efficient proper learning of bounded-degree polytrees, a rich class of high-dimensional probability distributions and a subclass of Bayesian networks, a widely-studied type of graphical model. Recently, Bhattacharyya et al. (2021) obtained finite-sample guarantees for recovering tree-structured Bayesian networks, i.e., 1-polytrees. We extend their results by providing an efficient algorithm which learns $d$-polytrees in polynomial time and sample complexity for any bounded $d$ when the underlying undirected graph (skeleton) is known. We complement our algorithm with an information-theoretic sample complexity lower bound, showing that the dependence on the dimension and target accuracy parameters are nearly tight.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#21457;&#29616;&#28151;&#21512;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25512;&#26029;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#20197;&#21450;&#27599;&#20010;&#26679;&#26412;&#23646;&#20110;&#29305;&#23450;&#28151;&#21512;&#25104;&#20998;&#30340;&#27010;&#29575;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#22240;&#26524;&#21457;&#29616;&#20219;&#21153;&#20013;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.06312</link><description>&lt;p&gt;
&#20174;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#21457;&#29616;&#28151;&#21512;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Discovering Mixtures of Structural Causal Models from Time Series Data. (arXiv:2310.06312v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06312
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#21457;&#29616;&#28151;&#21512;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25512;&#26029;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#20197;&#21450;&#27599;&#20010;&#26679;&#26412;&#23646;&#20110;&#29305;&#23450;&#28151;&#21512;&#25104;&#20998;&#30340;&#27010;&#29575;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#22240;&#26524;&#21457;&#29616;&#20219;&#21153;&#20013;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#37329;&#34701;&#12289;&#27668;&#20505;&#31185;&#23398;&#21644;&#31070;&#32463;&#31185;&#23398;&#31561;&#39046;&#22495;&#65292;&#20174;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#25512;&#26029;&#22240;&#26524;&#20851;&#31995;&#26159;&#19968;&#20010;&#24040;&#22823;&#30340;&#25361;&#25112;&#12290;&#23613;&#31649;&#29616;&#20195;&#25216;&#26415;&#21487;&#20197;&#22788;&#29702;&#21464;&#37327;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#20851;&#31995;&#21644;&#28789;&#27963;&#30340;&#22122;&#22768;&#20998;&#24067;&#65292;&#20294;&#23427;&#20204;&#20381;&#36182;&#20110;&#31616;&#21270;&#20551;&#35774;&#65292;&#21363;&#25968;&#25454;&#26469;&#33258;&#30456;&#21516;&#30340;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25918;&#26494;&#20102;&#36825;&#20010;&#20551;&#35774;&#65292;&#20174;&#26469;&#28304;&#20110;&#19981;&#21516;&#22240;&#26524;&#27169;&#22411;&#28151;&#21512;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#36827;&#34892;&#22240;&#26524;&#21457;&#29616;&#12290;&#25105;&#20204;&#25512;&#26029;&#20102;&#28508;&#22312;&#30340;&#32467;&#26500;&#24615;&#22240;&#26524;&#27169;&#22411;&#65292;&#20197;&#21450;&#27599;&#20010;&#26679;&#26412;&#23646;&#20110;&#29305;&#23450;&#28151;&#21512;&#25104;&#20998;&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#37319;&#29992;&#20102;&#19968;&#20010;&#31471;&#23545;&#31471;&#30340;&#35757;&#32451;&#36807;&#31243;&#65292;&#26368;&#22823;&#21270;&#20102;&#25968;&#25454;&#20284;&#28982;&#30340;&#35777;&#25454;&#19979;&#30028;&#12290;&#36890;&#36807;&#23545;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#30340;&#24191;&#27867;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22240;&#26524;&#21457;&#29616;&#20219;&#21153;&#20013;&#36229;&#36234;&#20102;&#26368;&#20808;&#36827;&#30340;&#22522;&#20934;&#26041;&#27861;&#65292;&#23588;&#20854;&#26159;&#24403;&#25968;&#25454;&#26469;&#33258;&#19981;&#21516;&#30340;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#26102;&#12290;
&lt;/p&gt;
&lt;p&gt;
In fields such as finance, climate science, and neuroscience, inferring causal relationships from time series data poses a formidable challenge. While contemporary techniques can handle nonlinear relationships between variables and flexible noise distributions, they rely on the simplifying assumption that data originates from the same underlying causal model. In this work, we relax this assumption and perform causal discovery from time series data originating from mixtures of different causal models. We infer both the underlying structural causal models and the posterior probability for each sample belonging to a specific mixture component. Our approach employs an end-to-end training process that maximizes an evidence-lower bound for data likelihood. Through extensive experimentation on both synthetic and real-world datasets, we demonstrate that our method surpasses state-of-the-art benchmarks in causal discovery tasks, particularly when the data emanates from diverse underlying causal
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#21046;&#36896;&#19994;&#30340;AI&#23413;&#21270;&#30340;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#38598;&#25104;&#27963;&#36291;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#32447;&#26356;&#26032;AI&#27169;&#22411;&#30340;&#26041;&#24335;&#26469;&#25345;&#32493;&#25913;&#36827;&#20915;&#31574;&#12290;&#30740;&#31350;&#37319;&#29992;&#20102;&#19968;&#31181;&#21517;&#20026;CBEAL&#30340;&#38598;&#25104;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#22320;&#25351;&#23548;&#25968;&#25454;&#33719;&#21462;&#65292;&#23454;&#29616;&#20102;&#25968;&#25454;&#25928;&#26524;&#30340;&#26368;&#23567;&#21270;&#12290;</title><link>http://arxiv.org/abs/2310.06306</link><description>&lt;p&gt;
&#38754;&#21521;&#21046;&#36896;&#19994;&#30340;AI&#23413;&#21270;&#30340;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#38598;&#25104;&#27963;&#36291;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Ensemble Active Learning by Contextual Bandits for AI Incubation in Manufacturing. (arXiv:2310.06306v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06306
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#21046;&#36896;&#19994;&#30340;AI&#23413;&#21270;&#30340;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#38598;&#25104;&#27963;&#36291;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#32447;&#26356;&#26032;AI&#27169;&#22411;&#30340;&#26041;&#24335;&#26469;&#25345;&#32493;&#25913;&#36827;&#20915;&#31574;&#12290;&#30740;&#31350;&#37319;&#29992;&#20102;&#19968;&#31181;&#21517;&#20026;CBEAL&#30340;&#38598;&#25104;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#22320;&#25351;&#23548;&#25968;&#25454;&#33719;&#21462;&#65292;&#23454;&#29616;&#20102;&#25968;&#25454;&#25928;&#26524;&#30340;&#26368;&#23567;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24037;&#19994;&#29289;&#32852;&#32593;&#31995;&#32479;&#20013;&#30340;&#22312;&#32447;&#24863;&#30693;&#21644;&#35745;&#31639;&#36164;&#28304;&#20419;&#36827;&#20102;&#22522;&#20110;AI&#30340;&#20915;&#31574;&#12290;&#28982;&#32780;&#65292;&#25968;&#25454;&#36136;&#37327;&#38382;&#39064;&#65292;&#22914;&#31867;&#21035;&#19981;&#24179;&#34913;&#65292;&#38459;&#30861;&#20102;&#31163;&#32447;&#35757;&#32451;&#30340;AI&#27169;&#22411;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;AI&#27169;&#22411;&#20250;&#36890;&#36807;&#27969;&#24335;&#25968;&#25454;&#36827;&#34892;&#22312;&#32447;&#26356;&#26032;&#20197;&#25345;&#32493;&#25913;&#36827;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#27880;&#37322;&#32422;&#26463;&#65292;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#22312;&#36873;&#25321;&#29992;&#20110;&#26356;&#26032;&#30340;&#20248;&#36136;&#27969;&#24335;&#26679;&#26412;&#26041;&#38754;&#38754;&#20020;&#25361;&#25112;&#12290;&#25991;&#29486;&#20013;&#30340;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#36890;&#36807;&#20851;&#27880;&#19981;&#36275;&#25110;&#36807;&#24230;&#34920;&#31034;&#30340;&#21306;&#22495;&#26469;&#25552;&#20379;&#35299;&#20915;&#26041;&#26696;&#12290;&#22312;&#19981;&#26029;&#21464;&#21270;&#30340;&#21046;&#36896;&#32972;&#26223;&#19979;&#24179;&#34913;&#36825;&#20123;&#31574;&#30053;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;AI&#23398;&#20064;&#21040;&#30340;&#19968;&#20123;&#33719;&#21462;&#20934;&#21017;&#21487;&#20197;&#21160;&#24577;&#36866;&#24212;&#65292;&#20294;&#21487;&#33021;&#26080;&#27861;&#22987;&#32456;&#22788;&#29702;&#39057;&#32321;&#30340;&#21464;&#21270;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#38598;&#25104;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;CBEAL&#65292;&#19987;&#38376;&#21033;&#29992;&#20027;&#21160;&#23398;&#20064;&#20195;&#29702;&#36827;&#34892;&#25506;&#32034;&#25110;&#21033;&#29992;&#12290;&#20195;&#29702;&#30340;&#26435;&#37325;&#26681;&#25454;&#20915;&#31574;&#26377;&#25928;&#24615;&#36827;&#34892;&#35843;&#25972;&#12290;CBEAL&#21487;&#20197;&#20248;&#21270;&#22320;&#25351;&#23548;&#25968;&#25454;&#33719;&#21462;&#65292;&#23454;&#29616;&#25968;&#25454;&#25928;&#26524;&#30340;&#26368;&#23567;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online sensing and computational resources in Industrial Cyber-physical Systems (ICPS) facilitate AI-driven decision-making. Yet, issues with data quality, such as imbalanced classes, hinder AI models trained offline. To address this, AI models are updated online with streaming data for continuous improvement. Supervised learning models, however, face challenges in selecting quality streaming samples for updates due to annotation constraints. Active learning methods in literature offer solutions by focusing on under-represented or well-represented regions. Balancing these strategies in changing manufacturing contexts is challenging. Some acquisition criteria learned by AI dynamically adapt but may not consistently handle frequent changes. We introduce an ensemble active learning method, CBEAL, employing active learning agents specifically for exploration or exploitation. Weights of agents are adjusted based on agent decision effectiveness. CBEAL optimally guides data acquisition, minim
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35762;&#36848;&#20102;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#23545;&#32467;&#26500;&#21270;&#39640;&#32500;&#25968;&#25454;&#30340;&#27934;&#23519;&#21644;&#39044;&#27979;&#35268;&#21017;&#65292;&#36890;&#36807;&#20351;&#29992;&#22810;&#23618;&#21322;&#20223;&#23556;&#36755;&#20837;&#36716;&#25442;&#26469;&#25552;&#20379;&#39044;&#27979;&#35268;&#21017;&#24182;&#25214;&#21040;&#29305;&#24449;&#12290;</title><link>http://arxiv.org/abs/2310.06251</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#65306;&#19968;&#31687;&#25945;&#31243;
&lt;/p&gt;
&lt;p&gt;
Deep Learning: A Tutorial. (arXiv:2310.06251v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06251
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35762;&#36848;&#20102;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#23545;&#32467;&#26500;&#21270;&#39640;&#32500;&#25968;&#25454;&#30340;&#27934;&#23519;&#21644;&#39044;&#27979;&#35268;&#21017;&#65292;&#36890;&#36807;&#20351;&#29992;&#22810;&#23618;&#21322;&#20223;&#23556;&#36755;&#20837;&#36716;&#25442;&#26469;&#25552;&#20379;&#39044;&#27979;&#35268;&#21017;&#24182;&#25214;&#21040;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#25552;&#20379;&#23545;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#30340;&#22238;&#39038;&#65292;&#20197;&#25581;&#31034;&#23545;&#32467;&#26500;&#21270;&#39640;&#32500;&#25968;&#25454;&#30340;&#27934;&#23519;&#12290;&#19982;&#22823;&#22810;&#25968;&#32479;&#35745;&#27169;&#22411;&#24120;&#29992;&#30340;&#27973;&#23618;&#21152;&#24615;&#32467;&#26500;&#19981;&#21516;&#65292;&#28145;&#24230;&#23398;&#20064;&#20351;&#29992;&#22810;&#23618;&#21322;&#20223;&#23556;&#36755;&#20837;&#36716;&#25442;&#26469;&#25552;&#20379;&#39044;&#27979;&#35268;&#21017;&#12290;&#24212;&#29992;&#36825;&#20123;&#36716;&#25442;&#23618;&#23548;&#33268;&#19968;&#32452;&#23646;&#24615;&#65288;&#25110;&#29305;&#24449;&#65289;&#65292;&#21487;&#20197;&#24212;&#29992;&#27010;&#29575;&#32479;&#35745;&#26041;&#27861;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#21487;&#20197;&#21516;&#26102;&#36798;&#21040;&#21487;&#25193;&#23637;&#30340;&#39044;&#27979;&#35268;&#21017;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#20854;&#20013;&#31232;&#30095;&#27491;&#21017;&#21270;&#25214;&#21040;&#20102;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Our goal is to provide a review of deep learning methods which provide insight into structured high-dimensional data. Rather than using shallow additive architectures common to most statistical models, deep learning uses layers of semi-affine input transformations to provide a predictive rule. Applying these layers of transformations leads to a set of attributes (or, features) to which probabilistic statistical methods can be applied. Thus, the best of both worlds can be achieved: scalable prediction rules fortified with uncertainty quantification, where sparse regularization finds the features.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31232;&#30095;&#36125;&#21494;&#26031;&#26041;&#27861;&#20174;&#26377;&#38480;&#25968;&#25454;&#20013;&#23398;&#20064;&#21487;&#35299;&#37322;&#30340;&#25289;&#26684;&#26391;&#26085;&#25551;&#36848;&#29289;&#29702;&#31995;&#32479;&#30340;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#21202;&#35753;&#24503;&#21464;&#25442;&#33258;&#21160;&#25552;&#21462;&#21704;&#23494;&#39039;&#25551;&#36848;&#12290;</title><link>http://arxiv.org/abs/2310.06241</link><description>&lt;p&gt;
&#20174;&#25968;&#25454;&#20013;&#21457;&#29616;&#21487;&#35299;&#37322;&#30340;&#21160;&#21147;&#23398;&#31995;&#32479;&#30340;&#25289;&#26684;&#26391;&#26085;&#36125;&#21494;&#26031;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Bayesian framework for discovering interpretable Lagrangian of dynamical systems from data. (arXiv:2310.06241v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06241
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31232;&#30095;&#36125;&#21494;&#26031;&#26041;&#27861;&#20174;&#26377;&#38480;&#25968;&#25454;&#20013;&#23398;&#20064;&#21487;&#35299;&#37322;&#30340;&#25289;&#26684;&#26391;&#26085;&#25551;&#36848;&#29289;&#29702;&#31995;&#32479;&#30340;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#21202;&#35753;&#24503;&#21464;&#25442;&#33258;&#21160;&#25552;&#21462;&#21704;&#23494;&#39039;&#25551;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#21644;&#39044;&#27979;&#29289;&#29702;&#31995;&#32479;&#30340;&#21160;&#21147;&#23398;&#38656;&#35201;&#23545;&#22522;&#26412;&#29289;&#29702;&#23450;&#24459;&#26377;&#28145;&#20837;&#30340;&#29702;&#35299;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#23558;&#26041;&#31243;&#21457;&#29616;&#30340;&#26694;&#26550;&#25512;&#24191;&#21040;&#29289;&#29702;&#31995;&#32479;&#30340;&#21704;&#23494;&#39039;&#21644;&#25289;&#26684;&#26391;&#26085;&#30340;&#21457;&#29616;&#12290;&#34429;&#28982;&#29616;&#26377;&#30340;&#26041;&#27861;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#23545;&#25289;&#26684;&#26391;&#26085;&#36827;&#34892;&#21442;&#25968;&#21270;&#65292;&#20294;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31232;&#30095;&#36125;&#21494;&#26031;&#26041;&#27861;&#20174;&#26377;&#38480;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#21487;&#35299;&#37322;&#30340;&#25289;&#26684;&#26391;&#26085;&#25551;&#36848;&#29289;&#29702;&#31995;&#32479;&#30340;&#26367;&#20195;&#26694;&#26550;&#12290;&#19982;&#29616;&#26377;&#30340;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#19981;&#21516;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;(a)&#24471;&#21040;&#20102;&#21487;&#35299;&#37322;&#30340;&#25289;&#26684;&#26391;&#26085;&#25551;&#36848;&#65292;(b)&#21033;&#29992;&#36125;&#21494;&#26031;&#23398;&#20064;&#26469;&#37327;&#21270;&#30001;&#20110;&#26377;&#38480;&#25968;&#25454;&#32780;&#23548;&#33268;&#30340;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#65292;(c)&#36890;&#36807;&#21202;&#35753;&#24503;&#21464;&#25442;&#33258;&#21160;&#25552;&#21462;&#20174;&#23398;&#20064;&#21040;&#30340;&#25289;&#26684;&#26391;&#26085;&#24471;&#21040;&#30340;&#21704;&#23494;&#39039;&#25551;&#36848;&#65292;(d)&#25552;&#20379;&#22522;&#20110;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#21644;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDE&#65289;&#30340;&#35266;&#27979;&#31995;&#32479;&#25551;&#36848;&#12290;&#28041;&#21450;&#20845;&#20010;&#19981;&#21516;&#30340;&#20363;&#23376;&#65292;&#21253;&#25324;&#20004;&#31181;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning and predicting the dynamics of physical systems requires a profound understanding of the underlying physical laws. Recent works on learning physical laws involve generalizing the equation discovery frameworks to the discovery of Hamiltonian and Lagrangian of physical systems. While the existing methods parameterize the Lagrangian using neural networks, we propose an alternate framework for learning interpretable Lagrangian descriptions of physical systems from limited data using the sparse Bayesian approach. Unlike existing neural network-based approaches, the proposed approach (a) yields an interpretable description of Lagrangian, (b) exploits Bayesian learning to quantify the epistemic uncertainty due to limited data, (c) automates the distillation of Hamiltonian from the learned Lagrangian using Legendre transformation, and (d) provides ordinary (ODE) and partial differential equation (PDE) based descriptions of the observed systems. Six different examples involving both di
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#21270;&#30340;&#26102;&#31354;&#31070;&#32463;&#28857;&#36807;&#31243;&#31215;&#20998;&#26041;&#27861;(AutoSTPP)&#65292;&#25193;&#23637;&#20102;AutoInt&#26041;&#27861;&#29992;&#20110;&#19977;&#32500;&#26102;&#31354;&#28857;&#36807;&#31243;(STPP)&#30340;&#35745;&#31639;&#65292;&#20855;&#26377;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.06179</link><description>&lt;p&gt;
&#33258;&#21160;&#21270;&#30340;&#26102;&#31354;&#31070;&#32463;&#28857;&#36807;&#31243;&#31215;&#20998;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Automatic Integration for Spatiotemporal Neural Point Processes. (arXiv:2310.06179v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06179
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#21270;&#30340;&#26102;&#31354;&#31070;&#32463;&#28857;&#36807;&#31243;&#31215;&#20998;&#26041;&#27861;(AutoSTPP)&#65292;&#25193;&#23637;&#20102;AutoInt&#26041;&#27861;&#29992;&#20110;&#19977;&#32500;&#26102;&#31354;&#28857;&#36807;&#31243;(STPP)&#30340;&#35745;&#31639;&#65292;&#20855;&#26377;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#36830;&#32493;&#26102;&#38388;&#30340;&#28857;&#36807;&#31243;&#23545;&#20110;&#35768;&#22810;&#31163;&#25955;&#20107;&#20214;&#39044;&#27979;&#20219;&#21153;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#26102;&#31354;&#28857;&#36807;&#31243;&#65288;STPPs&#65289;&#30340;&#31215;&#20998;&#38382;&#39064;&#26159;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#65292;&#22240;&#20026;&#23427;&#28041;&#21450;&#21040;&#23545;&#31354;&#38388;&#21644;&#26102;&#38388;&#36827;&#34892;&#19977;&#37325;&#31215;&#20998;&#35745;&#31639;&#12290;&#29616;&#26377;&#30340;STPP&#31215;&#20998;&#26041;&#27861;&#35201;&#20040;&#20551;&#35774;&#24378;&#24230;&#20989;&#25968;&#20855;&#26377;&#21442;&#25968;&#24418;&#24335;&#65292;&#36825;&#32570;&#20047;&#28789;&#27963;&#24615;&#65307;&#35201;&#20040;&#29992;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#26469;&#36817;&#20284;&#24378;&#24230;&#65292;&#36825;&#24341;&#20837;&#20102;&#25968;&#20540;&#35823;&#24046;&#12290;Omi&#31561;&#20154;&#26368;&#36817;&#30340;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#21160;&#31215;&#20998;&#26041;&#27861;AutoInt&#65292;&#29992;&#20110;&#39640;&#25928;&#22320;&#31215;&#20998;&#28789;&#27963;&#30340;&#24378;&#24230;&#20989;&#25968;&#65292;&#20294;&#35813;&#26041;&#27861;&#21482;&#20851;&#27880;1D&#26102;&#38388;&#28857;&#36807;&#31243;&#12290;&#26412;&#25991;&#23558;AutoInt&#26041;&#27861;&#25193;&#23637;&#33267;3D STPP&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33539;&#24335;&#65306;AutoSTPP&#65288;&#33258;&#21160;&#21270;&#30340;&#26102;&#31354;&#31070;&#32463;&#28857;&#36807;&#31243;&#31215;&#20998;&#26041;&#27861;&#65289;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#30452;&#25509;&#25193;&#23637;&#20043;&#21069;&#30340;&#24037;&#20316;&#20250;&#36807;&#20110;&#32422;&#26463;&#24378;&#24230;&#20989;&#25968;&#65292;&#23548;&#33268;&#24615;&#33021;&#19981;&#20339;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21508;&#31181;&#23454;&#39564;&#20013;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning continuous-time point processes is essential to many discrete event forecasting tasks. However, integration poses a major challenge, particularly for spatiotemporal point processes (STPPs), as it involves calculating the likelihood through triple integrals over space and time. Existing methods for integrating STPP either assume a parametric form of the intensity function, which lacks flexibility; or approximating the intensity with Monte Carlo sampling, which introduces numerical errors. Recent work by Omi et al. [2019] proposes a dual network or AutoInt approach for efficient integration of flexible intensity function. However, the method only focuses on the 1D temporal point process. In this paper, we introduce a novel paradigm: AutoSTPP (Automatic Integration for Spatiotemporal Neural Point Processes) that extends the AutoInt approach to 3D STPP. We show that direct extension of the previous work overly constrains the intensity function, leading to poor performance. We prov
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#40723;&#21169;&#28145;&#24230;&#27169;&#22411;&#21033;&#29992;&#26356;&#22810;&#26679;&#30340;&#29305;&#24449;&#36827;&#34892;&#39044;&#27979;&#65292;&#20197;&#20943;&#36731;&#31616;&#21333;&#24615;&#20559;&#24046;&#24102;&#26469;&#30340;OOD&#25512;&#24191;&#38382;&#39064;&#65292;&#24182;&#22312;&#21508;&#31181;&#38382;&#39064;&#21644;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.06161</link><description>&lt;p&gt;
&#20943;&#36731;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#31616;&#21333;&#24615;&#20559;&#24046;&#20197;&#25913;&#21892;OOD&#25512;&#24191;&#21644;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Mitigating Simplicity Bias in Deep Learning for Improved OOD Generalization and Robustness. (arXiv:2310.06161v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06161
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#40723;&#21169;&#28145;&#24230;&#27169;&#22411;&#21033;&#29992;&#26356;&#22810;&#26679;&#30340;&#29305;&#24449;&#36827;&#34892;&#39044;&#27979;&#65292;&#20197;&#20943;&#36731;&#31616;&#21333;&#24615;&#20559;&#24046;&#24102;&#26469;&#30340;OOD&#25512;&#24191;&#38382;&#39064;&#65292;&#24182;&#22312;&#21508;&#31181;&#38382;&#39064;&#21644;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#24050;&#30693;&#23384;&#22312;&#31616;&#21333;&#24615;&#20559;&#24046;&#65292;&#21363;&#23427;&#20204;&#20542;&#21521;&#20110;&#23398;&#20064;&#8220;&#31616;&#21333;&#8221;&#29305;&#24449;&#32780;&#19981;&#26159;&#26356;&#8220;&#22797;&#26434;&#8221;&#30340;&#29305;&#24449;&#65292;&#21363;&#20351;&#21518;&#32773;&#21487;&#33021;&#26356;&#20855;&#20449;&#24687;&#37327;&#12290;&#31616;&#21333;&#24615;&#20559;&#24046;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#20570;&#20986;&#20855;&#26377;&#36739;&#24046;&#30340;OOD&#25512;&#24191;&#30340;&#20559;&#35265;&#24615;&#39044;&#27979;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#40723;&#21169;&#27169;&#22411;&#20351;&#29992;&#26356;&#22810;&#26679;&#30340;&#29305;&#24449;&#36827;&#34892;&#39044;&#27979;&#12290;&#25105;&#20204;&#39318;&#20808;&#35757;&#32451;&#19968;&#20010;&#31616;&#21333;&#27169;&#22411;&#65292;&#28982;&#21518;&#20351;&#29992;&#26465;&#20214;&#20114;&#20449;&#24687;&#23545;&#20854;&#36827;&#34892;&#27491;&#21017;&#21270;&#65292;&#24471;&#21040;&#26368;&#32456;&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#38382;&#39064;&#35774;&#32622;&#21644;&#30495;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#36825;&#20010;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#65292;&#35777;&#26126;&#23427;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#31616;&#21333;&#24615;&#20559;&#24046;&#65292;&#20419;&#20351;&#26356;&#22810;&#29305;&#24449;&#34987;&#20351;&#29992;&#65292;&#22686;&#24378;&#20102;OOD&#25512;&#24191;&#65292;&#24182;&#25552;&#39640;&#20102;&#23376;&#32452;&#40065;&#26834;&#24615;&#21644;&#20844;&#24179;&#24615;&#12290;&#25105;&#20204;&#34917;&#20805;&#36825;&#20123;&#32467;&#26524;&#19982;&#23545;&#27491;&#21017;&#21270;&#25928;&#26524;&#21450;&#20854;OOD&#25512;&#24191;&#29305;&#24615;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural networks (NNs) are known to exhibit simplicity bias where they tend to prefer learning 'simple' features over more 'complex' ones, even when the latter may be more informative. Simplicity bias can lead to the model making biased predictions which have poor out-of-distribution (OOD) generalization. To address this, we propose a framework that encourages the model to use a more diverse set of features to make predictions. We first train a simple model, and then regularize the conditional mutual information with respect to it to obtain the final model. We demonstrate the effectiveness of this framework in various problem settings and real-world applications, showing that it effectively addresses simplicity bias and leads to more features being used, enhances OOD generalization, and improves subgroup robustness and fairness. We complement these results with theoretical analyses of the effect of the regularization and its OOD generalization properties.
&lt;/p&gt;</description></item><item><title>&#26412;&#31456;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#32553;&#25918;&#26799;&#24230;&#19979;&#38477;&#65288;ScaledGD&#65289;&#30340;&#26032;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#24658;&#23450;&#36895;&#29575;&#19979;&#25910;&#25947;&#65292;&#32780;&#19981;&#21463;&#20302;&#31209;&#23545;&#35937;&#26465;&#20214;&#25968;&#30340;&#24433;&#21709;&#65292;&#24182;&#19988;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#20855;&#26377;&#20302;&#36845;&#20195;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2310.06159</link><description>&lt;p&gt;
&#32463;&#36807;&#32553;&#25918;&#26799;&#24230;&#19979;&#38477;&#27861;&#30340;&#65292;&#29978;&#33267;&#36807;&#21442;&#25968;&#21270;&#30340;&#21487;&#35777;&#26126;&#21152;&#36895;&#30340;&#30149;&#24577;&#20302;&#31209;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Provably Accelerating Ill-Conditioned Low-rank Estimation via Scaled Gradient Descent, Even with Overparameterization. (arXiv:2310.06159v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06159
&lt;/p&gt;
&lt;p&gt;
&#26412;&#31456;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#32553;&#25918;&#26799;&#24230;&#19979;&#38477;&#65288;ScaledGD&#65289;&#30340;&#26032;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#24658;&#23450;&#36895;&#29575;&#19979;&#25910;&#25947;&#65292;&#32780;&#19981;&#21463;&#20302;&#31209;&#23545;&#35937;&#26465;&#20214;&#25968;&#30340;&#24433;&#21709;&#65292;&#24182;&#19988;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#20855;&#26377;&#20302;&#36845;&#20195;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#36935;&#21040;&#30340;&#35768;&#22810;&#38382;&#39064;&#21487;&#20197;&#24402;&#32435;&#20026;&#20174;&#19981;&#23436;&#25972;&#19988;&#21487;&#33021;&#25439;&#22351;&#30340;&#32447;&#24615;&#27979;&#37327;&#20013;&#20272;&#35745;&#20302;&#31209;&#23545;&#35937;&#65288;&#20363;&#22914;&#30697;&#38453;&#21644;&#24352;&#37327;&#65289;&#12290;&#36890;&#36807;&#30697;&#38453;&#21644;&#24352;&#37327;&#20998;&#35299;&#30340;&#35270;&#35282;&#65292;&#20854;&#20013;&#19968;&#31181;&#26368;&#27969;&#34892;&#30340;&#26041;&#27861;&#26159;&#20351;&#29992;&#31616;&#21333;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#22914;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#30452;&#25509;&#24674;&#22797;&#20302;&#31209;&#22240;&#23376;&#65292;&#36825;&#26679;&#21487;&#20197;&#23454;&#29616;&#23567;&#20869;&#23384;&#21644;&#35745;&#31639;&#24320;&#38144;&#12290;&#28982;&#32780;&#65292;GD&#30340;&#25910;&#25947;&#36895;&#29575;&#32447;&#24615;&#22320;&#20381;&#36182;&#20110;&#20302;&#31209;&#23545;&#35937;&#30340;&#26465;&#20214;&#25968;&#65292;&#26377;&#26102;&#29978;&#33267;&#26159;&#20108;&#27425;&#30340;&#65292;&#22240;&#27492;&#24403;&#38382;&#39064;&#30149;&#24577;&#26102;&#65292;GD&#30340;&#25910;&#25947;&#38750;&#24120;&#32531;&#24930;&#12290;&#26412;&#31456;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#26041;&#27861;&#65292;&#31216;&#20026;&#32553;&#25918;&#26799;&#24230;&#19979;&#38477;&#27861;&#65288;ScaledGD&#65289;&#65292;&#23427;&#33021;&#22815;&#20197;&#24658;&#23450;&#36895;&#29575;&#32447;&#24615;&#22320;&#25910;&#25947;&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#20302;&#31209;&#23545;&#35937;&#30340;&#26465;&#20214;&#25968;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#26799;&#24230;&#19979;&#38477;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#30340;&#27599;&#27425;&#36845;&#20195;&#25104;&#26412;&#36739;&#20302;&#65292;&#21253;&#25324;&#24863;&#30693;&#12289;&#40065;&#26834;&#20027;&#25104;&#20998;&#20272;&#35745;&#31561;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many problems encountered in science and engineering can be formulated as estimating a low-rank object (e.g., matrices and tensors) from incomplete, and possibly corrupted, linear measurements. Through the lens of matrix and tensor factorization, one of the most popular approaches is to employ simple iterative algorithms such as gradient descent (GD) to recover the low-rank factors directly, which allow for small memory and computation footprints. However, the convergence rate of GD depends linearly, and sometimes even quadratically, on the condition number of the low-rank object, and therefore, GD slows down painstakingly when the problem is ill-conditioned. This chapter introduces a new algorithmic approach, dubbed scaled gradient descent (ScaledGD), that provably converges linearly at a constant rate independent of the condition number of the low-rank object, while maintaining the low per-iteration cost of gradient descent for a variety of tasks including sensing, robust principal c
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#21033;&#29992;&#27979;&#22320;&#32447;&#21644;&#27969;&#21160;&#26469;&#25551;&#36848;&#21487;&#24494;&#27969;&#24418;&#19978;&#30340;&#36317;&#31163;&#21644;&#38271;&#24230;&#26368;&#23567;&#21270;&#26354;&#32447;&#12290;&#36825;&#20026;&#22312;&#19981;&#21516;iable&#27969;&#24418;&#19978;&#36827;&#34892;&#32479;&#35745;&#21644;&#38477;&#38454;&#24314;&#27169;&#25552;&#20379;&#20102;&#26426;&#20250;&#12290;</title><link>http://arxiv.org/abs/2310.06157</link><description>&lt;p&gt;
&#22522;&#20110;&#27969;&#24418;&#30340;Eikonal&#26041;&#31243;&#65306;&#21487;&#24494;&#27969;&#24418;&#19978;&#30340;&#27979;&#22320;&#36317;&#31163;&#21644;&#27969;&#21160;
&lt;/p&gt;
&lt;p&gt;
Manifold-augmented Eikonal Equations: Geodesic Distances and Flows on Differentiable Manifolds. (arXiv:2310.06157v1 [cs.CG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06157
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#21033;&#29992;&#27979;&#22320;&#32447;&#21644;&#27969;&#21160;&#26469;&#25551;&#36848;&#21487;&#24494;&#27969;&#24418;&#19978;&#30340;&#36317;&#31163;&#21644;&#38271;&#24230;&#26368;&#23567;&#21270;&#26354;&#32447;&#12290;&#36825;&#20026;&#22312;&#19981;&#21516;iable&#27969;&#24418;&#19978;&#36827;&#34892;&#32479;&#35745;&#21644;&#38477;&#38454;&#24314;&#27169;&#25552;&#20379;&#20102;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21457;&#29616;&#30340;&#27969;&#24418;&#25552;&#20379;&#20102;&#24213;&#23618;&#25968;&#25454;&#30340;&#32039;&#20945;&#34920;&#31034;&#12290;&#36825;&#20123;&#27969;&#24418;&#19978;&#30340;&#27979;&#22320;&#32447;&#23450;&#20041;&#20102;&#23616;&#37096;&#38271;&#24230;&#26368;&#23567;&#21270;&#26354;&#32447;&#65292;&#24182;&#25552;&#20379;&#20102;&#36317;&#31163;&#30340;&#27010;&#24565;&#65292;&#36825;&#23545;&#20110;&#38477;&#38454;&#24314;&#27169;&#12289;&#32479;&#35745;&#25512;&#26029;&#21644;&#25554;&#20540;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#21442;&#25968;&#21270;&#26041;&#27861;&#26469;&#34920;&#31034;&#27969;&#24418;&#19978;&#30340;&#36317;&#31163;&#22330;&#21644;&#27979;&#22320;&#27969;&#21160;&#65292;&#21033;&#29992;&#25193;&#23637;&#30340;Eikonal&#26041;&#31243;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#27969;&#24418;&#30340;&#20960;&#20309;&#29305;&#24615;&#22914;&#20309;&#24433;&#21709;&#36317;&#31163;&#22330;&#65292;&#24182;&#21033;&#29992;&#27979;&#22320;&#27969;&#21160;&#30452;&#25509;&#33719;&#24471;&#20840;&#23616;&#38271;&#24230;&#26368;&#23567;&#21270;&#26354;&#32447;&#12290;&#36825;&#39033;&#24037;&#20316;&#20026;&#22312;&#21487;&#24494;&#27969;&#24418;&#19978;&#36827;&#34892;&#32479;&#35745;&#21644;&#38477;&#38454;&#24314;&#27169;&#25552;&#20379;&#20102;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;
Manifolds discovered by machine learning models provide a compact representation of the underlying data. Geodesics on these manifolds define locally length-minimising curves and provide a notion of distance, which are key for reduced-order modelling, statistical inference, and interpolation. In this work, we propose a model-based parameterisation for distance fields and geodesic flows on manifolds, exploiting solutions of a manifold-augmented Eikonal equation. We demonstrate how the geometry of the manifold impacts the distance field, and exploit the geodesic flow to obtain globally length-minimising curves directly. This work opens opportunities for statistics and reduced-order modelling on differentiable manifolds.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24494;&#35843;&#12289;MAML&#21644;Reptile&#22312;&#36801;&#31227;&#23398;&#20064;&#21644;&#20803;&#23398;&#20064;&#39046;&#22495;&#30340;&#24615;&#33021;&#24046;&#24322;&#65292;&#21457;&#29616;&#24403;&#22312;&#19982;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#19981;&#21516;&#30340;&#20219;&#21153;&#19978;&#36827;&#34892;&#35780;&#20272;&#26102;&#65292;&#20165;&#23545;&#39044;&#35757;&#32451;&#32593;&#32476;&#36827;&#34892;&#24494;&#35843;&#30340;&#22522;&#20934;&#32447;&#21487;&#33021;&#27604;&#26356;&#22797;&#26434;&#30340;&#20803;&#23398;&#20064;&#25216;&#26415;&#26356;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2310.06148</link><description>&lt;p&gt;
&#29702;&#35299;&#36801;&#31227;&#23398;&#20064;&#21644;&#22522;&#20110;&#26799;&#24230;&#30340;&#20803;&#23398;&#20064;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Understanding Transfer Learning and Gradient-Based Meta-Learning Techniques. (arXiv:2310.06148v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06148
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24494;&#35843;&#12289;MAML&#21644;Reptile&#22312;&#36801;&#31227;&#23398;&#20064;&#21644;&#20803;&#23398;&#20064;&#39046;&#22495;&#30340;&#24615;&#33021;&#24046;&#24322;&#65292;&#21457;&#29616;&#24403;&#22312;&#19982;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#19981;&#21516;&#30340;&#20219;&#21153;&#19978;&#36827;&#34892;&#35780;&#20272;&#26102;&#65292;&#20165;&#23545;&#39044;&#35757;&#32451;&#32593;&#32476;&#36827;&#34892;&#24494;&#35843;&#30340;&#22522;&#20934;&#32447;&#21487;&#33021;&#27604;&#26356;&#22797;&#26434;&#30340;&#20803;&#23398;&#20064;&#25216;&#26415;&#26356;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#21487;&#20197;&#21462;&#24471;&#33391;&#22909;&#30340;&#24615;&#33021;&#65292;&#20294;&#36890;&#24120;&#38656;&#35201;&#22823;&#37327;&#30340;&#25968;&#25454;&#26469;&#35757;&#32451;&#12290;&#20803;&#23398;&#20064;&#20316;&#20026;&#19968;&#31181;&#25552;&#39640;&#36825;&#20123;&#32593;&#32476;&#20174;&#26377;&#38480;&#25968;&#25454;&#20013;&#27867;&#21270;&#33021;&#21147;&#30340;&#26041;&#27861;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;&#34429;&#28982;&#20803;&#23398;&#20064;&#25216;&#26415;&#22312;&#21508;&#31181;&#22330;&#26223;&#19979;&#34987;&#35777;&#26126;&#26159;&#25104;&#21151;&#30340;&#65292;&#20294;&#26368;&#36817;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#35780;&#20272;&#19982;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#19981;&#21516;&#30340;&#20219;&#21153;&#26102;&#65292;&#19982;&#22797;&#26434;&#30340;&#20803;&#23398;&#20064;&#25216;&#26415;&#65288;&#22914;MAML&#65289;&#30456;&#27604;&#65292;&#20165;&#23545;&#39044;&#35757;&#32451;&#32593;&#32476;&#36827;&#34892;&#24494;&#35843;&#30340;&#22522;&#20934;&#32447;&#21487;&#33021;&#26356;&#26377;&#25928;&#12290;&#36825;&#19968;&#28857;&#20196;&#20154;&#24778;&#35766;&#65292;&#22240;&#20026;MAML&#30340;&#23398;&#20064;&#34892;&#20026;&#19982;&#24494;&#35843;&#30340;&#34892;&#20026;&#31867;&#20284;&#65306;&#20004;&#32773;&#37117;&#20381;&#36182;&#20110;&#37325;&#22797;&#20351;&#29992;&#24050;&#23398;&#20064;&#30340;&#29305;&#24449;&#12290;&#25105;&#20204;&#35843;&#26597;&#20102;&#24494;&#35843;&#12289;MAML&#21644;&#21478;&#19968;&#31181;&#21517;&#20026;Reptile&#30340;&#20803;&#23398;&#20064;&#25216;&#26415;&#20043;&#38388;&#35266;&#23519;&#21040;&#30340;&#24615;&#33021;&#24046;&#24322;&#65292;&#24182;&#23637;&#31034;&#20102;MAML&#21644;Reptile&#22312;&#20302;&#25968;&#25454;&#24773;&#20917;&#19979;&#30340;&#24555;&#36895;&#36866;&#24212;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks can yield good performance on various tasks but often require large amounts of data to train them. Meta-learning received considerable attention as one approach to improve the generalization of these networks from a limited amount of data. Whilst meta-learning techniques have been observed to be successful at this in various scenarios, recent results suggest that when evaluated on tasks from a different data distribution than the one used for training, a baseline that simply finetunes a pre-trained network may be more effective than more complicated meta-learning techniques such as MAML, which is one of the most popular meta-learning techniques. This is surprising as the learning behaviour of MAML mimics that of finetuning: both rely on re-using learned features. We investigate the observed performance differences between finetuning, MAML, and another meta-learning technique called Reptile, and show that MAML and Reptile specialize for fast adaptation in low-data r
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26799;&#24230;&#33258;&#21160;&#23398;&#20064;&#23618;&#38388;&#31561;&#21464;&#24615;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25913;&#36827;&#36719;&#31561;&#21464;&#24615;&#30340;&#21442;&#25968;&#21270;&#21644;&#20248;&#21270;&#36793;&#32536;&#20284;&#28982;&#26469;&#23454;&#29616;&#23618;&#38388;&#23545;&#31216;&#24615;&#30340;&#33258;&#21160;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2310.06131</link><description>&lt;p&gt;
&#20351;&#29992;&#26799;&#24230;&#33258;&#21160;&#23398;&#20064;&#23618;&#38388;&#31561;&#21464;&#24615;
&lt;/p&gt;
&lt;p&gt;
Learning Layer-wise Equivariances Automatically using Gradients. (arXiv:2310.06131v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06131
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26799;&#24230;&#33258;&#21160;&#23398;&#20064;&#23618;&#38388;&#31561;&#21464;&#24615;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25913;&#36827;&#36719;&#31561;&#21464;&#24615;&#30340;&#21442;&#25968;&#21270;&#21644;&#20248;&#21270;&#36793;&#32536;&#20284;&#28982;&#26469;&#23454;&#29616;&#23618;&#38388;&#23545;&#31216;&#24615;&#30340;&#33258;&#21160;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21367;&#31215;&#23558;&#31561;&#21464;&#24615;&#23545;&#31216;&#24615;&#32534;&#30721;&#21040;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#27867;&#21270;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#23545;&#31216;&#24615;&#25552;&#20379;&#20102;&#32593;&#32476;&#21487;&#20197;&#34920;&#31034;&#30340;&#20989;&#25968;&#30340;&#22266;&#23450;&#30828;&#32422;&#26463;&#65292;&#38656;&#35201;&#20107;&#20808;&#25351;&#23450;&#65292;&#24182;&#19988;&#19981;&#33021;&#36866;&#24212;&#25913;&#21464;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20801;&#35768;&#28789;&#27963;&#30340;&#23545;&#31216;&#24615;&#32422;&#26463;&#65292;&#21487;&#20197;&#36890;&#36807;&#26799;&#24230;&#33258;&#21160;&#22320;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#12290;&#20174;&#22836;&#24320;&#22987;&#23398;&#20064;&#23545;&#31216;&#24615;&#21644;&#30456;&#20851;&#30340;&#26435;&#37325;&#36830;&#25509;&#32467;&#26500;&#26377;&#20004;&#20010;&#22256;&#38590;&#12290;&#39318;&#20808;&#65292;&#23427;&#38656;&#35201;&#26377;&#25928;&#28789;&#27963;&#30340;&#23618;&#38388;&#31561;&#21464;&#24615;&#21442;&#25968;&#21270;&#12290;&#20854;&#27425;&#65292;&#23545;&#31216;&#24615;&#20316;&#20026;&#32422;&#26463;&#65292;&#22240;&#27492;&#19981;&#20250;&#34987;&#35757;&#32451;&#25439;&#22833;&#20989;&#25968;&#40723;&#21169;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;&#36719;&#31561;&#21464;&#24615;&#30340;&#21442;&#25968;&#21270;&#65292;&#24182;&#36890;&#36807;&#20248;&#21270;&#36793;&#32536;&#20284;&#28982;&#26469;&#23398;&#20064;&#23618;&#38388;&#31561;&#21464;&#24615;&#30340;&#25968;&#37327;&#65292;&#20854;&#20013;&#36793;&#32536;&#20284;&#28982;&#26159;&#20351;&#29992;&#21487;&#24494;&#20998;&#30340;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#20272;&#35745;&#30340;&#12290;&#36825;&#20010;&#30446;&#26631;&#24179;&#34913;&#20102;&#25968;&#25454;&#25311;&#21512;&#21644;&#27169;&#22411;&#22797;&#26434;&#24615;&#65292;&#20351;&#23618;&#38388;&#23545;&#31216;&#24615;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#34987;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Convolutions encode equivariance symmetries into neural networks leading to better generalisation performance. However, symmetries provide fixed hard constraints on the functions a network can represent, need to be specified in advance, and can not be adapted. Our goal is to allow flexible symmetry constraints that can automatically be learned from data using gradients. Learning symmetry and associated weight connectivity structures from scratch is difficult for two reasons. First, it requires efficient and flexible parameterisations of layer-wise equivariances. Secondly, symmetries act as constraints and are therefore not encouraged by training losses measuring data fit. To overcome these challenges, we improve parameterisations of soft equivariance and learn the amount of equivariance in layers by optimising the marginal likelihood, estimated using differentiable Laplace approximations. The objective balances data fit and model complexity enabling layer-wise symmetry discovery in dee
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#19981;&#21487;&#30693;&#30340;PAC&#24378;&#21270;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;&#36328;&#36234;&#23481;&#37327;&#36825;&#20010;&#26032;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#24182;&#21457;&#29616;&#20102;&#22312;&#29983;&#25104;&#21644;&#22312;&#32447;&#35775;&#38382;&#27169;&#22411;&#20043;&#38388;&#20197;&#21450;&#22312;&#32447;&#35775;&#38382;&#19979;&#30340;&#30830;&#23450;&#21644;&#38543;&#26426;MDP&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2310.06113</link><description>&lt;p&gt;
&#20160;&#20040;&#26102;&#20505;&#26159;&#22522;&#20110;&#19981;&#21487;&#30693;&#28608;&#21169;&#24378;&#21270;&#23398;&#20064;&#30340;&#32479;&#35745;&#21487;&#22788;&#29702;&#24615;&#65311;
&lt;/p&gt;
&lt;p&gt;
When is Agnostic Reinforcement Learning Statistically Tractable?. (arXiv:2310.06113v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06113
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#19981;&#21487;&#30693;&#30340;PAC&#24378;&#21270;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;&#36328;&#36234;&#23481;&#37327;&#36825;&#20010;&#26032;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#24182;&#21457;&#29616;&#20102;&#22312;&#29983;&#25104;&#21644;&#22312;&#32447;&#35775;&#38382;&#27169;&#22411;&#20043;&#38388;&#20197;&#21450;&#22312;&#32447;&#35775;&#38382;&#19979;&#30340;&#30830;&#23450;&#21644;&#38543;&#26426;MDP&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#19981;&#21487;&#30693;&#30340;PAC&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#30340;&#38382;&#39064;&#65306;&#32473;&#23450;&#19968;&#20010;&#31574;&#30053;&#31867;&#21035;&#928;&#65292;&#38656;&#35201;&#21644;&#19968;&#20010;&#26410;&#30693;&#30340;&#26377;&#21487;&#33021;&#26377;&#22823;&#29366;&#24577;&#21644;&#21160;&#20316;&#31354;&#38388;&#30340;MDP&#36827;&#34892;&#22810;&#23569;&#36718;&#20114;&#21160;&#26469;&#23398;&#20064;&#19968;&#20010;&#20851;&#20110;&#928;&#30340;&#949;-&#27425;&#20248;&#31574;&#30053;&#65311;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#31216;&#20026;&#8220;&#36328;&#36234;&#23481;&#37327;&#8221;&#65292;&#23427;&#20165;&#20381;&#36182;&#20110;&#31574;&#30053;&#31867;&#21035;&#928;&#65292;&#24182;&#19988;&#19982;MDP&#30340;&#21160;&#24577;&#26080;&#20851;&#12290;&#36890;&#36807;&#19968;&#20010;&#29983;&#25104;&#27169;&#22411;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20219;&#20309;&#31574;&#30053;&#31867;&#21035;&#928;&#65292;&#26377;&#30028;&#30340;&#36328;&#36234;&#23481;&#37327;&#21487;&#20197;&#21051;&#30011;PAC&#21487;&#23398;&#20064;&#24615;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#22312;&#32447;RL&#26469;&#35828;&#65292;&#24773;&#20917;&#26356;&#21152;&#24494;&#22937;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23384;&#22312;&#19968;&#20010;&#20855;&#26377;&#26377;&#30028;&#36328;&#36234;&#23481;&#37327;&#30340;&#31574;&#30053;&#31867;&#21035;&#928;&#65292;&#38656;&#35201;&#36229;&#22810;&#39033;&#24335;&#25968;&#37327;&#30340;&#26679;&#26412;&#25165;&#33021;&#23398;&#20064;&#12290;&#36825;&#25581;&#31034;&#20102;&#22312;&#19981;&#21516;&#29983;&#25104;&#21644;&#22312;&#32447;&#35775;&#38382;&#27169;&#22411;&#20043;&#38388;&#20197;&#21450;&#22312;&#32447;&#35775;&#38382;&#19979;&#30340;&#30830;&#23450;/&#38543;&#26426;MDP&#20043;&#38388;&#30340;&#19981;&#30830;&#23450;&#21487;&#23398;&#20064;&#24615;&#20043;&#38388;&#30340;&#20986;&#20046;&#24847;&#26009;&#30340;&#24046;&#24322;&#12290;&#22312;&#31215;&#26497;&#30340;&#26041;&#38754;&#65292;&#25105;&#20204;&#35782;&#21035;&#20986;&#19968;&#20010;&#39069;&#22806;&#30340;&#8220;&#22826;&#38451;&#8221;
&lt;/p&gt;
&lt;p&gt;
We study the problem of agnostic PAC reinforcement learning (RL): given a policy class $\Pi$, how many rounds of interaction with an unknown MDP (with a potentially large state and action space) are required to learn an $\epsilon$-suboptimal policy with respect to $\Pi$? Towards that end, we introduce a new complexity measure, called the \emph{spanning capacity}, that depends solely on the set $\Pi$ and is independent of the MDP dynamics. With a generative model, we show that for any policy class $\Pi$, bounded spanning capacity characterizes PAC learnability. However, for online RL, the situation is more subtle. We show there exists a policy class $\Pi$ with a bounded spanning capacity that requires a superpolynomial number of samples to learn. This reveals a surprising separation for agnostic learnability between generative access and online access models (as well as between deterministic/stochastic MDPs under online access). On the positive side, we identify an additional \emph{sunf
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#29702;&#35770;&#20998;&#26512;&#20102;&#23485;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#36807;&#25311;&#21512;&#29616;&#35937;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Adv-NTK&#30340;AT&#31639;&#27861;&#26469;&#22686;&#24378;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.06112</link><description>&lt;p&gt;
&#23485;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#36807;&#25311;&#21512;&#30340;&#29702;&#35770;&#20998;&#26512;&#65306;&#19968;&#31181;NTK&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Theoretical Analysis of Robust Overfitting for Wide DNNs: An NTK Approach. (arXiv:2310.06112v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06112
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#29702;&#35770;&#20998;&#26512;&#20102;&#23485;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#36807;&#25311;&#21512;&#29616;&#35937;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Adv-NTK&#30340;AT&#31639;&#27861;&#26469;&#22686;&#24378;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#35757;&#32451;(AT)&#26159;&#22686;&#24378;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#40065;&#26834;&#24615;&#30340;&#32463;&#20856;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#23454;&#39564;&#35777;&#26126;&#23427;&#23384;&#22312;&#40065;&#26834;&#36807;&#25311;&#21512;&#29616;&#35937;&#65292;&#21363;&#38271;&#26102;&#38388;&#30340;AT&#21487;&#33021;&#23545;DNNs&#30340;&#40065;&#26834;&#24615;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#12290;&#26412;&#25991;&#23545;DNNs&#30340;&#40065;&#26834;&#36807;&#25311;&#21512;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#35299;&#37322;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;&#31070;&#32463;&#20999;&#21521;&#26680;(NTK)&#29702;&#35770;&#38750;&#24179;&#20961;&#22320;&#25193;&#23637;&#21040;AT&#65292;&#24182;&#35777;&#26126;&#20102;&#36890;&#36807;AT&#35757;&#32451;&#30340;&#23485;DNN&#21487;&#20197;&#24456;&#22909;&#22320;&#36817;&#20284;&#20026;&#19968;&#20010;&#32447;&#24615;&#21270;&#30340;DNN&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#24179;&#26041;&#25439;&#22833;&#65292;&#21487;&#20197;&#25512;&#23548;&#20986;&#32447;&#24615;&#21270;DNN&#30340;&#38381;&#24335;AT&#21160;&#21147;&#23398;&#65292;&#25581;&#31034;&#20102;&#19968;&#31181;&#26032;&#30340;AT&#36864;&#21270;&#29616;&#35937;&#65306;&#38271;&#26399;&#30340;AT&#23558;&#23548;&#33268;&#23485;DNN&#36864;&#21270;&#20026;&#27809;&#26377;AT&#30340;DNN&#65292;&#20174;&#32780;&#24341;&#36215;&#40065;&#26834;&#36807;&#25311;&#21512;&#12290;&#26681;&#25454;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35774;&#35745;&#20102;&#19968;&#31181;&#21517;&#20026;Adv-NTK&#30340;&#26041;&#27861;&#65292;&#36825;&#26159;&#31532;&#19968;&#31181;&#38024;&#23545;&#26080;&#38480;&#23485;&#30340;DNNs&#30340;AT&#31639;&#27861;&#12290;&#22312;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;Adv-NTK&#21487;&#20197;&#24110;&#21161;&#26080;&#38480;&#23485;&#30340;DNNs&#25552;&#21319;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial training (AT) is a canonical method for enhancing the robustness of deep neural networks (DNNs). However, recent studies empirically demonstrated that it suffers from robust overfitting, i.e., a long time AT can be detrimental to the robustness of DNNs. This paper presents a theoretical explanation of robust overfitting for DNNs. Specifically, we non-trivially extend the neural tangent kernel (NTK) theory to AT and prove that an adversarially trained wide DNN can be well approximated by a linearized DNN. Moreover, for squared loss, closed-form AT dynamics for the linearized DNN can be derived, which reveals a new AT degeneration phenomenon: a long-term AT will result in a wide DNN degenerates to that obtained without AT and thus cause robust overfitting. Based on our theoretical results, we further design a method namely Adv-NTK, the first AT algorithm for infinite-width DNNs. Experiments on real-world datasets show that Adv-NTK can help infinite-width DNNs enhance comparab
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#27934;&#23519;&#29616;&#35937;&#21487;&#33021;&#26159;&#30001;&#31070;&#32463;&#32593;&#32476;&#20174;&#25042;&#24816;&#35757;&#32451;&#21160;&#24577;&#36807;&#28193;&#21040;&#20016;&#23500;&#30340;&#29305;&#24449;&#23398;&#20064;&#27169;&#24335;&#30340;&#32467;&#26524;&#65292;&#36890;&#36807;&#36319;&#36394;&#36275;&#22815;&#30340;&#32479;&#35745;&#37327;&#65292;&#21457;&#29616;&#27934;&#23519;&#26159;&#22312;&#32593;&#32476;&#39318;&#20808;&#23581;&#35797;&#25311;&#21512;&#26680;&#22238;&#24402;&#35299;&#20915;&#26041;&#26696;&#21518;&#65292;&#36827;&#34892;&#21518;&#26399;&#29305;&#24449;&#23398;&#20064;&#25214;&#21040;&#36890;&#29992;&#35299;&#20915;&#26041;&#26696;&#20043;&#21518;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.06110</link><description>&lt;p&gt;
&#20174;&#25042;&#24816;&#21040;&#20016;&#23500;&#35757;&#32451;&#21160;&#24577;&#30340;&#27934;&#23519;&#21147;
&lt;/p&gt;
&lt;p&gt;
Grokking as the Transition from Lazy to Rich Training Dynamics. (arXiv:2310.06110v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06110
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#27934;&#23519;&#29616;&#35937;&#21487;&#33021;&#26159;&#30001;&#31070;&#32463;&#32593;&#32476;&#20174;&#25042;&#24816;&#35757;&#32451;&#21160;&#24577;&#36807;&#28193;&#21040;&#20016;&#23500;&#30340;&#29305;&#24449;&#23398;&#20064;&#27169;&#24335;&#30340;&#32467;&#26524;&#65292;&#36890;&#36807;&#36319;&#36394;&#36275;&#22815;&#30340;&#32479;&#35745;&#37327;&#65292;&#21457;&#29616;&#27934;&#23519;&#26159;&#22312;&#32593;&#32476;&#39318;&#20808;&#23581;&#35797;&#25311;&#21512;&#26680;&#22238;&#24402;&#35299;&#20915;&#26041;&#26696;&#21518;&#65292;&#36827;&#34892;&#21518;&#26399;&#29305;&#24449;&#23398;&#20064;&#25214;&#21040;&#36890;&#29992;&#35299;&#20915;&#26041;&#26696;&#20043;&#21518;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#27934;&#23519;&#29616;&#35937;&#65292;&#21363;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#25439;&#22833;&#22312;&#27979;&#35797;&#25439;&#22833;&#20043;&#21069;&#22823;&#24133;&#19979;&#38477;&#65292;&#21487;&#33021;&#26159;&#30001;&#20110;&#31070;&#32463;&#32593;&#32476;&#20174;&#25042;&#24816;&#30340;&#35757;&#32451;&#21160;&#24577;&#36716;&#21464;&#20026;&#20016;&#23500;&#30340;&#29305;&#24449;&#23398;&#20064;&#27169;&#24335;&#12290;&#20026;&#20102;&#35828;&#26126;&#36825;&#19968;&#26426;&#21046;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#27809;&#26377;&#27491;&#21017;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;Vanilla&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#22312;&#22810;&#39033;&#24335;&#22238;&#24402;&#38382;&#39064;&#19978;&#36827;&#34892;&#30340;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#65292;&#35813;&#35757;&#32451;&#23637;&#29616;&#20102;&#26080;&#27861;&#29992;&#29616;&#26377;&#29702;&#35770;&#35299;&#37322;&#30340;&#27934;&#23519;&#29616;&#35937;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#35813;&#32593;&#32476;&#27979;&#35797;&#25439;&#22833;&#30340;&#36275;&#22815;&#32479;&#35745;&#37327;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#36319;&#36394;&#36825;&#20123;&#32479;&#35745;&#37327;&#25581;&#31034;&#20102;&#27934;&#23519;&#29616;&#35937;&#30340;&#21457;&#29983;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#32593;&#32476;&#39318;&#20808;&#23581;&#35797;&#20351;&#29992;&#21021;&#22987;&#29305;&#24449;&#25311;&#21512;&#26680;&#22238;&#24402;&#35299;&#20915;&#26041;&#26696;&#65292;&#25509;&#30528;&#22312;&#35757;&#32451;&#25439;&#22833;&#24050;&#32463;&#24456;&#20302;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#21518;&#26399;&#29305;&#24449;&#23398;&#20064;&#65292;&#20174;&#32780;&#25214;&#21040;&#20102;&#19968;&#20010;&#33021;&#22815;&#27867;&#21270;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#27934;&#23519;&#20135;&#29983;&#30340;&#20851;&#38190;&#22240;&#32032;&#26159;&#29305;&#24449;&#23398;&#20064;&#30340;&#36895;&#29575;&#65292;&#36825;&#21487;&#20197;&#36890;&#36807;&#32553;&#25918;&#32593;&#32476;&#21442;&#25968;&#26469;&#31934;&#30830;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose that the grokking phenomenon, where the train loss of a neural network decreases much earlier than its test loss, can arise due to a neural network transitioning from lazy training dynamics to a rich, feature learning regime. To illustrate this mechanism, we study the simple setting of vanilla gradient descent on a polynomial regression problem with a two layer neural network which exhibits grokking without regularization in a way that cannot be explained by existing theories. We identify sufficient statistics for the test loss of such a network, and tracking these over training reveals that grokking arises in this setting when the network first attempts to fit a kernel regression solution with its initial features, followed by late-time feature learning where a generalizing solution is identified after train loss is already low. We find that the key determinants of grokking are the rate of feature learning -- which can be controlled precisely by parameters that scale the ne
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#23398;&#26694;&#26550;&#26469;&#37327;&#21270;&#22522;&#20110;&#39118;&#38505;&#20915;&#31574;&#30340;&#28145;&#24230;&#23398;&#20064;&#20998;&#31867;&#20013;&#31163;&#25955;&#36755;&#20837;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#26377;&#21161;&#20110;&#22312;&#20915;&#31574;&#36807;&#31243;&#20013;&#20943;&#36731;&#30456;&#20851;&#39118;&#38505;&#65292;&#24182;&#19988;&#21487;&#20197;&#36866;&#29992;&#20110;&#22788;&#29702;&#28041;&#21450;&#20998;&#31867;&#21644;&#31163;&#25955;&#29305;&#24449;&#21464;&#37327;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.06105</link><description>&lt;p&gt;
&#29992;&#20110;&#22522;&#20110;&#39118;&#38505;&#20915;&#31574;&#30340;&#28145;&#24230;&#23398;&#20064;&#20998;&#31867;&#20013;&#31163;&#25955;&#36755;&#20837;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Quantifying Uncertainty in Deep Learning Classification with Noise in Discrete Inputs for Risk-Based Decision Making. (arXiv:2310.06105v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06105
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#23398;&#26694;&#26550;&#26469;&#37327;&#21270;&#22522;&#20110;&#39118;&#38505;&#20915;&#31574;&#30340;&#28145;&#24230;&#23398;&#20064;&#20998;&#31867;&#20013;&#31163;&#25955;&#36755;&#20837;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#26377;&#21161;&#20110;&#22312;&#20915;&#31574;&#36807;&#31243;&#20013;&#20943;&#36731;&#30456;&#20851;&#39118;&#38505;&#65292;&#24182;&#19988;&#21487;&#20197;&#36866;&#29992;&#20110;&#22788;&#29702;&#28041;&#21450;&#20998;&#31867;&#21644;&#31163;&#25955;&#29305;&#24449;&#21464;&#37327;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#27169;&#22411;&#22312;&#22522;&#20110;&#39118;&#38505;&#20915;&#31574;&#20013;&#30340;&#24212;&#29992;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#22312;&#21307;&#30103;&#12289;&#37329;&#34701;&#12289;&#21046;&#36896;&#21644;&#36136;&#37327;&#25511;&#21046;&#31561;&#39046;&#22495;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;&#20026;&#20102;&#22312;&#20915;&#31574;&#36807;&#31243;&#20013;&#20943;&#36731;&#30456;&#20851;&#39118;&#38505;&#65292;&#39044;&#27979;&#30340;&#32622;&#20449;&#24230;&#25110;&#19981;&#30830;&#23450;&#24615;&#24212;&#35813;&#19982;&#31639;&#27861;&#30340;&#25972;&#20307;&#24615;&#33021;&#19968;&#36215;&#36827;&#34892;&#35780;&#20272;&#12290;&#26368;&#36817;&#20851;&#20110;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#30340;&#30740;&#31350;&#26377;&#21161;&#20110;&#37327;&#21270;&#28304;&#20110;&#36755;&#20837;&#22122;&#22768;&#21644;&#27169;&#22411;&#21442;&#25968;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#20013;&#23545;&#36755;&#20837;&#22122;&#22768;&#30340;&#27491;&#24577;&#24615;&#20551;&#35774;&#38480;&#21046;&#20102;&#20854;&#36866;&#29992;&#20110;&#28041;&#21450;&#20998;&#31867;&#21644;&#31163;&#25955;&#29305;&#24449;&#21464;&#37327;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25968;&#23398;&#26694;&#26550;&#26469;&#37327;&#21270;DNN&#27169;&#22411;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#12290;&#36825;&#31181;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#28304;&#20110;&#36981;&#24490;&#24050;&#30693;&#26377;&#38480;&#31163;&#25955;&#20998;&#24067;&#30340;&#39044;&#27979;&#22120;&#35823;&#24046;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#35813;&#26694;&#26550;&#36827;&#34892;&#20102;&#19968;&#20010;&#26696;&#20363;&#30740;&#31350;&#65292;&#39044;&#27979;&#32467;&#26680;&#30149;&#24739;&#32773;&#27835;&#30103;&#32467;&#26524;&#30340;&#36807;&#31243;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The use of Deep Neural Network (DNN) models in risk-based decision-making has attracted extensive attention with broad applications in medical, finance, manufacturing, and quality control. To mitigate prediction-related risks in decision making, prediction confidence or uncertainty should be assessed alongside the overall performance of algorithms. Recent studies on Bayesian deep learning helps quantify prediction uncertainty arises from input noises and model parameters. However, the normality assumption of input noise in these models limits their applicability to problems involving categorical and discrete feature variables in tabular datasets. In this paper, we propose a mathematical framework to quantify prediction uncertainty for DNN models. The prediction uncertainty arises from errors in predictors that follow some known finite discrete distribution. We then conducted a case study using the framework to predict treatment outcome for tuberculosis patients during their course of t
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#22240;&#26524;&#25512;&#26029;&#30340;&#21464;&#20998;&#32972;&#38376;&#35843;&#25972;&#25216;&#26415;&#65292;&#33021;&#22815;&#22788;&#29702;&#39640;&#32500;&#27835;&#30103;&#21644;&#28151;&#26434;&#22240;&#32032;&#65292;&#24182;&#25104;&#21151;&#24212;&#29992;&#20110;&#21307;&#30103;&#25968;&#25454;&#20013;&#12290;</title><link>http://arxiv.org/abs/2310.06100</link><description>&lt;p&gt;
&#20351;&#29992;&#21464;&#20998;&#32972;&#38376;&#35843;&#25972;&#36827;&#34892;&#39640;&#32500;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
High Dimensional Causal Inference with Variational Backdoor Adjustment. (arXiv:2310.06100v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06100
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#22240;&#26524;&#25512;&#26029;&#30340;&#21464;&#20998;&#32972;&#38376;&#35843;&#25972;&#25216;&#26415;&#65292;&#33021;&#22815;&#22788;&#29702;&#39640;&#32500;&#27835;&#30103;&#21644;&#28151;&#26434;&#22240;&#32032;&#65292;&#24182;&#25104;&#21151;&#24212;&#29992;&#20110;&#21307;&#30103;&#25968;&#25454;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32972;&#38376;&#35843;&#25972;&#26159;&#19968;&#31181;&#22240;&#26524;&#25512;&#26029;&#25216;&#26415;&#65292;&#29992;&#20110;&#20174;&#32431;&#35266;&#23519;&#25968;&#25454;&#20013;&#20272;&#35745;&#24178;&#39044;&#25968;&#37327;&#12290;&#22312;&#21307;&#30103;&#29615;&#22659;&#20013;&#65292;&#32972;&#38376;&#35843;&#25972;&#21487;&#29992;&#20110;&#25511;&#21046;&#28151;&#26434;&#22240;&#32032;&#24182;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;&#12290;&#28982;&#32780;&#65292;&#39640;&#32500;&#27835;&#30103;&#21644;&#28151;&#26434;&#22240;&#32032;&#21487;&#33021;&#24341;&#21457;&#19968;&#31995;&#21015;&#28508;&#22312;&#38382;&#39064;&#65306;&#21487;&#35745;&#31639;&#24615;&#12289;&#21487;&#36776;&#35782;&#24615;&#12289;&#20248;&#21270;&#31561;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#26469;&#35299;&#20915;&#39640;&#32500;&#27835;&#30103;&#21644;&#28151;&#26434;&#22240;&#32032;&#30340;&#32972;&#38376;&#35843;&#25972;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#32972;&#38376;&#35843;&#25972;&#35270;&#20026;&#19968;&#31181;&#21464;&#20998;&#25512;&#26029;&#20248;&#21270;&#38382;&#39064;&#65292;&#26080;&#38656;&#20381;&#36182;&#20195;&#29702;&#21464;&#37327;&#21644;&#38544;&#34255;&#28151;&#26434;&#22240;&#32032;&#12290;&#23454;&#39564;&#19978;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#22312;&#21508;&#31181;&#39640;&#32500;&#29615;&#22659;&#20013;&#20272;&#35745;&#24178;&#39044;&#27010;&#29575;&#65292;&#21253;&#25324;&#21322;&#21512;&#25104;X&#20809;&#21307;&#30103;&#25968;&#25454;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#32972;&#38376;&#35843;&#25972;&#30340;&#39318;&#27425;&#24212;&#29992;&#65292;&#20854;&#20013;&#25152;&#26377;&#30456;&#20851;&#21464;&#37327;&#37117;&#26159;&#39640;&#32500;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Backdoor adjustment is a technique in causal inference for estimating interventional quantities from purely observational data. For example, in medical settings, backdoor adjustment can be used to control for confounding and estimate the effectiveness of a treatment. However, high dimensional treatments and confounders pose a series of potential pitfalls: tractability, identifiability, optimization. In this work, we take a generative modeling approach to backdoor adjustment for high dimensional treatments and confounders. We cast backdoor adjustment as an optimization problem in variational inference without reliance on proxy variables and hidden confounders. Empirically, our method is able to estimate interventional likelihood in a variety of high dimensional settings, including semi-synthetic X-ray medical data. To the best of our knowledge, this is the first application of backdoor adjustment in which all the relevant variables are high dimensional.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#24191;&#27867;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#21363;Ito&#38142;&#30340;Ito&#25193;&#25955;&#36924;&#36817;&#12290;&#19982;&#22823;&#22810;&#25968;&#30456;&#20851;&#35770;&#25991;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#38142;&#20855;&#26377;&#21508;&#21521;&#21516;&#24615;&#21644;&#29366;&#24577;&#30456;&#20851;&#30340;&#22122;&#22768;&#65292;&#24182;&#21487;&#20197;&#36866;&#29992;&#20110;&#22810;&#31181;&#24212;&#29992;&#22330;&#26223;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;Ito&#38142;&#19982;&#23545;&#24212;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20043;&#38388;&#30340;W2-&#36317;&#31163;&#30340;&#19978;&#30028;&#12290;&#36825;&#20123;&#32467;&#26524;&#25913;&#36827;&#20102;&#24050;&#26377;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#24182;&#22312;&#26576;&#20123;&#29305;&#27530;&#24773;&#20917;&#19979;&#25552;&#20379;&#20102;&#39318;&#27425;&#30340;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2310.06081</link><description>&lt;p&gt;
&#29992;&#20110;&#37319;&#26679;&#12289;&#20248;&#21270;&#21644;&#25552;&#21319;&#30340;&#36890;&#29992;Ito&#38142;&#30340;Ito&#25193;&#25955;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Ito Diffusion Approximation of Universal Ito Chains for Sampling, Optimization and Boosting. (arXiv:2310.06081v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06081
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#24191;&#27867;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#21363;Ito&#38142;&#30340;Ito&#25193;&#25955;&#36924;&#36817;&#12290;&#19982;&#22823;&#22810;&#25968;&#30456;&#20851;&#35770;&#25991;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#38142;&#20855;&#26377;&#21508;&#21521;&#21516;&#24615;&#21644;&#29366;&#24577;&#30456;&#20851;&#30340;&#22122;&#22768;&#65292;&#24182;&#21487;&#20197;&#36866;&#29992;&#20110;&#22810;&#31181;&#24212;&#29992;&#22330;&#26223;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;Ito&#38142;&#19982;&#23545;&#24212;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20043;&#38388;&#30340;W2-&#36317;&#31163;&#30340;&#19978;&#30028;&#12290;&#36825;&#20123;&#32467;&#26524;&#25913;&#36827;&#20102;&#24050;&#26377;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#24182;&#22312;&#26576;&#20123;&#29305;&#27530;&#24773;&#20917;&#19979;&#25552;&#20379;&#20102;&#39318;&#27425;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#31867;&#30456;&#24403;&#19968;&#33324;&#21644;&#24191;&#27867;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#21363;Ito&#38142;&#65292;&#20854;&#31867;&#20284;&#20110;&#26576;&#20123;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;Euler-Maruyama&#31163;&#25955;&#21270;&#12290;&#25105;&#20204;&#30740;&#31350;&#30340;&#38142;&#26159;&#19968;&#20010;&#32479;&#19968;&#30340;&#29702;&#35770;&#20998;&#26512;&#26694;&#26550;&#12290;&#19982;&#22823;&#22810;&#25968;&#30456;&#20851;&#35770;&#25991;&#20013;&#30340;&#27491;&#24577;&#21644;&#29366;&#24577;&#29420;&#31435;&#22122;&#22768;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#38142;&#20855;&#26377;&#20960;&#20046;&#20219;&#24847;&#21508;&#21521;&#21516;&#24615;&#21644;&#29366;&#24577;&#30456;&#20851;&#22122;&#22768;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#38142;&#30340;&#28418;&#31227;&#21644;&#25193;&#25955;&#31995;&#25968;&#21487;&#20197;&#26159;&#31934;&#30830;&#30340;&#65292;&#20197;&#28085;&#30422;&#35832;&#22914;&#38543;&#26426;&#26799;&#24230;Langevin&#21160;&#21147;&#23398;&#12289;&#37319;&#26679;&#12289;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#25110;&#38543;&#26426;&#26799;&#24230;&#25552;&#21319;&#31561;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;Ito&#38142;&#19982;&#23545;&#24212;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20043;&#38388;&#30340;W2-&#36317;&#31163;&#30340;&#19968;&#20010;&#19978;&#30028;&#12290;&#36825;&#20123;&#32467;&#26524;&#25913;&#36827;&#25110;&#35206;&#30422;&#20102;&#22823;&#37096;&#20998;&#24050;&#30693;&#30340;&#20272;&#35745;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#26576;&#20123;&#29305;&#27530;&#24773;&#20917;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#26159;&#31532;&#19968;&#20010;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work considers a rather general and broad class of Markov chains, Ito chains that look like Euler-Maryama discretization of some Stochastic Differential Equation. The chain we study is a unified framework for theoretical analysis. It comes with almost arbitrary isotropic and state-dependent noise instead of normal and state-independent one, as in most related papers. Moreover, our chain's drift and diffusion coefficient can be inexact to cover a wide range of applications such as Stochastic Gradient Langevin Dynamics, sampling, Stochastic Gradient Descent, or Stochastic Gradient Boosting. We prove an upper bound for $W_{2}$-distance between laws of the Ito chain and the corresponding Stochastic Differential Equation. These results improve or cover most of the known estimates. Moreover, for some particular cases, our analysis is the first.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#38382;&#39064;&#65306;&#26159;&#21542;&#23384;&#22312;&#19968;&#31181;&#33021;&#22815;&#21516;&#26102;&#36827;&#34892;&#26368;&#20248;&#25506;&#32034;&#21644;&#21482;&#38656;&#35201;&#30456;&#21516;&#35745;&#31639;&#25805;&#20316;&#30340;&#31639;&#27861;&#65311;</title><link>http://arxiv.org/abs/2310.06069</link><description>&lt;p&gt;
&#26368;&#20248;&#25506;&#32034;&#19981;&#27604;&#27748;&#26222;&#26862;&#37319;&#26679;&#26356;&#22256;&#38590;
&lt;/p&gt;
&lt;p&gt;
Optimal Exploration is no harder than Thompson Sampling. (arXiv:2310.06069v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06069
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#38382;&#39064;&#65306;&#26159;&#21542;&#23384;&#22312;&#19968;&#31181;&#33021;&#22815;&#21516;&#26102;&#36827;&#34892;&#26368;&#20248;&#25506;&#32034;&#21644;&#21482;&#38656;&#35201;&#30456;&#21516;&#35745;&#31639;&#25805;&#20316;&#30340;&#31639;&#27861;&#65311;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32473;&#23450;&#19968;&#32452;&#33218;$\mathcal{Z}\subset \mathbb{R}^d$&#21644;&#26410;&#30693;&#21442;&#25968;&#21521;&#37327;$\theta_\ast\in\mathbb{R}^d$&#30340;&#24773;&#20917;&#19979;&#65292;&#32431;&#25506;&#32034;&#32447;&#24615;&#33218;&#38382;&#39064;&#26088;&#22312;&#36890;&#36807;&#23545;$x^{\top}\theta_{\ast}$&#30340;&#22122;&#22768;&#27979;&#37327;&#65292;&#36820;&#22238;$\arg\max_{z\in \mathcal{Z}} z^{\top}\theta_{\ast}$&#65292;&#24182;&#20197;&#39640;&#27010;&#29575;&#25214;&#21040;&#27491;&#30830;&#35299;&#12290;&#29616;&#26377;&#30340;&#65288;&#28176;&#36817;&#65289;&#26368;&#20248;&#26041;&#27861;&#35201;&#27714;&#35201;&#20040;&#20026;&#27599;&#20010;&#33218;$z\in \mathcal{Z}$&#36827;&#34892;&#28508;&#22312;&#26114;&#36149;&#30340;&#25237;&#24433;&#65292;&#35201;&#20040;&#22312;&#27599;&#20010;&#26102;&#38388;&#28857;&#26126;&#30830;&#22320;&#32500;&#25252;&#19968;&#37096;&#20998;&#27491;&#22312;&#32771;&#34385;&#30340;$\mathcal{Z}$&#12290;&#36825;&#31181;&#22797;&#26434;&#24615;&#19982;&#27969;&#34892;&#19988;&#31616;&#21333;&#30340;&#27748;&#26222;&#26862;&#37319;&#26679;&#31639;&#27861;&#29992;&#20110;&#26368;&#23567;&#21270;&#21518;&#24724;&#30340;&#24773;&#20917;&#23436;&#20840;&#30456;&#21453;&#65292;&#21518;&#32773;&#21482;&#38656;&#35201;&#35775;&#38382;&#21518;&#39564;&#37319;&#26679;&#21644;argmax oracle&#65292;&#24182;&#19988;&#22312;&#20219;&#20309;&#26102;&#38388;&#28857;&#37117;&#19981;&#38656;&#35201;&#26522;&#20030;$\mathcal{Z}$&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#24050;&#30693;&#27748;&#26222;&#26862;&#37319;&#26679;&#23545;&#20110;&#32431;&#25506;&#32034;&#26159;&#27425;&#20248;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#28982;&#30340;&#38382;&#39064;&#65306;&#26159;&#21542;&#23384;&#22312;&#19968;&#31181;&#31639;&#27861;&#33021;&#22815;&#36827;&#34892;&#26368;&#20248;&#25506;&#32034;&#65292;&#32780;&#19988;&#21482;&#38656;&#35201;&#30456;&#21516;&#30340;&#35745;&#31639;&#25805;&#20316;&#65311;
&lt;/p&gt;
&lt;p&gt;
Given a set of arms $\mathcal{Z}\subset \mathbb{R}^d$ and an unknown parameter vector $\theta_\ast\in\mathbb{R}^d$, the pure exploration linear bandit problem aims to return $\arg\max_{z\in \mathcal{Z}} z^{\top}\theta_{\ast}$, with high probability through noisy measurements of $x^{\top}\theta_{\ast}$ with $x\in \mathcal{X}\subset \mathbb{R}^d$. Existing (asymptotically) optimal methods require either a) potentially costly projections for each arm $z\in \mathcal{Z}$ or b) explicitly maintaining a subset of $\mathcal{Z}$ under consideration at each time. This complexity is at odds with the popular and simple Thompson Sampling algorithm for regret minimization, which just requires access to a posterior sampling and argmax oracle, and does not need to enumerate $\mathcal{Z}$ at any point. Unfortunately, Thompson sampling is known to be sub-optimal for pure exploration. In this work, we pose a natural question: is there an algorithm that can explore optimally and only needs the same comput
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#23558;&#25903;&#25345;&#21521;&#37327;&#26426;&#36716;&#21270;&#20026;&#25104;&#26412;&#25935;&#24863;&#30340;&#27010;&#29575;&#20998;&#31867;&#22120;&#65292;&#24182;&#20805;&#20998;&#21033;&#29992;&#20102;&#27491;&#21017;&#21270;&#21442;&#25968;&#30340;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2310.05997</link><description>&lt;p&gt;
&#25104;&#26412;&#25935;&#24863;&#30340;&#25903;&#25345;&#21521;&#37327;&#26426;&#30340;&#27010;&#29575;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Cost-sensitive probabilistic predictions for support vector machines. (arXiv:2310.05997v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05997
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#23558;&#25903;&#25345;&#21521;&#37327;&#26426;&#36716;&#21270;&#20026;&#25104;&#26412;&#25935;&#24863;&#30340;&#27010;&#29575;&#20998;&#31867;&#22120;&#65292;&#24182;&#20805;&#20998;&#21033;&#29992;&#20102;&#27491;&#21017;&#21270;&#21442;&#25968;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#26159;&#26368;&#21463;&#20851;&#27880;&#21644;&#20351;&#29992;&#30340;&#20108;&#20803;&#20998;&#31867;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20043;&#19968;&#12290;SVM&#30340;&#20998;&#31867;&#26159;&#22522;&#20110;&#24471;&#20998;&#36807;&#31243;&#30340;&#65292;&#24471;&#21040;&#30340;&#26159;&#30830;&#23450;&#24615;&#30340;&#20998;&#31867;&#35268;&#21017;&#65292;&#21487;&#20197;&#36716;&#21270;&#20026;&#27010;&#29575;&#35268;&#21017;&#65288;&#22312;&#29616;&#25104;&#30340;SVM&#24211;&#20013;&#23454;&#29616;&#65289;&#65292;&#20294;&#26412;&#36136;&#19978;&#24182;&#19981;&#26159;&#27010;&#29575;&#24615;&#30340;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;SVM&#20013;&#27491;&#21017;&#21270;&#21442;&#25968;&#30340;&#35843;&#20248;&#34987;&#35748;&#20026;&#38656;&#35201;&#24456;&#39640;&#30340;&#35745;&#31639;&#37327;&#65292;&#24182;&#19988;&#29983;&#25104;&#30340;&#20449;&#24687;&#27809;&#26377;&#20805;&#20998;&#21033;&#29992;&#65292;&#27809;&#26377;&#29992;&#20110;&#26500;&#24314;&#27010;&#29575;&#20998;&#31867;&#35268;&#21017;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#26469;&#29983;&#25104;SVM&#30340;&#27010;&#29575;&#36755;&#20986;&#12290;&#26032;&#26041;&#27861;&#20855;&#26377;&#20197;&#19979;&#19977;&#20010;&#29305;&#28857;&#12290;&#39318;&#20808;&#65292;&#23427;&#26159;&#35774;&#35745;&#20026;&#25104;&#26412;&#25935;&#24863;&#30340;&#65292;&#22240;&#27492;&#21487;&#20197;&#24456;&#23481;&#26131;&#22320;&#36866;&#24212;&#25935;&#24863;&#24615;&#65288;&#25110;&#30495;&#27491;&#20363;&#29575;&#65292;TPR&#65289;&#21644;&#29305;&#24322;&#24615;&#65288;&#30495;&#36127;&#20363;&#29575;&#65292;TNR&#65289;&#30340;&#19981;&#21516;&#37325;&#35201;&#24615;&#12290;&#32467;&#26524;&#65292;&#27169;&#22411;&#33021;&#22815;&#22788;&#29702;&#25104;&#26412;&#25935;&#24863;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Support vector machines (SVMs) are widely used and constitute one of the best examined and used machine learning models for two-class classification. Classification in SVM is based on a score procedure, yielding a deterministic classification rule, which can be transformed into a probabilistic rule (as implemented in off-the-shelf SVM libraries), but is not probabilistic in nature. On the other hand, the tuning of the regularization parameters in SVM is known to imply a high computational effort and generates pieces of information that are not fully exploited, not being used to build a probabilistic classification rule. In this paper we propose a novel approach to generate probabilistic outputs for the SVM. The new method has the following three properties. First, it is designed to be cost-sensitive, and thus the different importance of sensitivity (or true positive rate, TPR) and specificity (true negative rate, TNR) is readily accommodated in the model. As a result, the model can dea
&lt;/p&gt;</description></item><item><title>&#31526;&#21512;&#20915;&#31574;&#29702;&#35770;&#26159;&#19968;&#31181;&#26694;&#26550;&#65292;&#21487;&#20197;&#36890;&#36807;&#19981;&#23436;&#32654;&#30340;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#20135;&#29983;&#23433;&#20840;&#30340;&#33258;&#20027;&#20915;&#31574;&#12290;&#35813;&#29702;&#35770;&#30340;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#21487;&#20197;&#22312;&#27809;&#26377;&#23545;&#19990;&#30028;&#27169;&#22411;&#20570;&#20986;&#20219;&#20309;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#20855;&#26377;&#20302;&#39118;&#38505;&#30340;&#32479;&#35745;&#20445;&#35777;&#30340;&#20915;&#31574;&#12290;</title><link>http://arxiv.org/abs/2310.05921</link><description>&lt;p&gt;
&#31526;&#21512;&#20915;&#31574;&#29702;&#35770;: &#36890;&#36807;&#19981;&#23436;&#32654;&#30340;&#39044;&#27979;&#20135;&#29983;&#23433;&#20840;&#30340;&#33258;&#20027;&#20915;&#31574;
&lt;/p&gt;
&lt;p&gt;
Conformal Decision Theory: Safe Autonomous Decisions from Imperfect Predictions. (arXiv:2310.05921v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05921
&lt;/p&gt;
&lt;p&gt;
&#31526;&#21512;&#20915;&#31574;&#29702;&#35770;&#26159;&#19968;&#31181;&#26694;&#26550;&#65292;&#21487;&#20197;&#36890;&#36807;&#19981;&#23436;&#32654;&#30340;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#20135;&#29983;&#23433;&#20840;&#30340;&#33258;&#20027;&#20915;&#31574;&#12290;&#35813;&#29702;&#35770;&#30340;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#21487;&#20197;&#22312;&#27809;&#26377;&#23545;&#19990;&#30028;&#27169;&#22411;&#20570;&#20986;&#20219;&#20309;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#20855;&#26377;&#20302;&#39118;&#38505;&#30340;&#32479;&#35745;&#20445;&#35777;&#30340;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#31526;&#21512;&#20915;&#31574;&#29702;&#35770;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#19981;&#23436;&#32654;&#30340;&#24773;&#20917;&#19979;&#20135;&#29983;&#23433;&#20840;&#30340;&#33258;&#20027;&#20915;&#31574;&#12290;&#36825;&#31181;&#20915;&#31574;&#30340;&#20363;&#23376;&#26159;&#26222;&#36941;&#23384;&#22312;&#30340;&#65292;&#20174;&#20381;&#36182;&#20110;&#34892;&#20154;&#39044;&#27979;&#30340;&#26426;&#22120;&#20154;&#35268;&#21010;&#31639;&#27861;&#65292;&#21040;&#26657;&#20934;&#33258;&#21160;&#21270;&#21046;&#36896;&#20197;&#23454;&#29616;&#39640;&#21534;&#21520;&#37327;&#21644;&#20302;&#38169;&#35823;&#29575;&#65292;&#20877;&#21040;&#22312;&#36816;&#34892;&#26102;&#36873;&#25321;&#20449;&#20219;&#21517;&#20041;&#31574;&#30053;&#36824;&#26159;&#20999;&#25442;&#21040;&#23433;&#20840;&#22791;&#20221;&#31574;&#30053;&#12290;&#25105;&#20204;&#31639;&#27861;&#20135;&#29983;&#30340;&#20915;&#31574;&#22312;&#32479;&#35745;&#20445;&#35777;&#30340;&#24773;&#20917;&#19979;&#26159;&#23433;&#20840;&#30340;&#65292;&#26080;&#38656;&#23545;&#19990;&#30028;&#27169;&#22411;&#20316;&#20986;&#20219;&#20309;&#20551;&#35774;&#65307;&#35266;&#27979;&#25968;&#25454;&#21487;&#20197;&#19981;&#28385;&#36275;&#29420;&#31435;&#21516;&#20998;&#24067;(I.I.D.)&#30340;&#26465;&#20214;&#65292;&#29978;&#33267;&#21487;&#33021;&#26159;&#23545;&#25239;&#24615;&#30340;&#12290;&#35813;&#29702;&#35770;&#23558;&#31526;&#21512;&#39044;&#27979;&#30340;&#32467;&#26524;&#25193;&#23637;&#21040;&#30452;&#25509;&#26657;&#20934;&#20915;&#31574;&#65292;&#32780;&#19981;&#38656;&#35201;&#26500;&#24314;&#39044;&#27979;&#38598;&#21512;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#22312;&#22260;&#32469;&#20154;&#31867;&#36827;&#34892;&#26426;&#22120;&#20154;&#36816;&#21160;&#35268;&#21010;&#12289;&#33258;&#21160;&#32929;&#31080;&#20132;&#26131;&#21644;&#26426;&#22120;&#20154;&#21046;&#36896;&#26041;&#38754;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce Conformal Decision Theory, a framework for producing safe autonomous decisions despite imperfect machine learning predictions. Examples of such decisions are ubiquitous, from robot planning algorithms that rely on pedestrian predictions, to calibrating autonomous manufacturing to exhibit high throughput and low error, to the choice of trusting a nominal policy versus switching to a safe backup policy at run-time. The decisions produced by our algorithms are safe in the sense that they come with provable statistical guarantees of having low risk without any assumptions on the world model whatsoever; the observations need not be I.I.D. and can even be adversarial. The theory extends results from conformal prediction to calibrate decisions directly, without requiring the construction of prediction sets. Experiments demonstrate the utility of our approach in robot motion planning around humans, automated stock trading, and robot manufacturin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20934;&#33945;&#29305;&#21345;&#32599;&#26426;&#21046;&#65292;&#31216;&#20026;&#25490;&#26021;&#38543;&#26426;&#28216;&#36208;&#65292;&#36890;&#36807;&#25913;&#36827;&#22270;&#30340;&#37319;&#26679;&#65292;&#25552;&#39640;&#20102;&#32479;&#35745;&#20272;&#35745;&#22120;&#30340;&#38598;&#20013;&#24230;&#12290;&#35813;&#26426;&#21046;&#22312;&#20272;&#35745;&#22270;&#20869;&#26680;&#12289;PageRank&#21521;&#37327;&#21644;&#22270;&#24418;&#27987;&#24230;&#31561;&#26041;&#38754;&#23637;&#31034;&#20102;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.04859</link><description>&lt;p&gt;
&#36890;&#29992;&#22270;&#38543;&#26426;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Universal Graph Random Features. (arXiv:2310.04859v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04859
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20934;&#33945;&#29305;&#21345;&#32599;&#26426;&#21046;&#65292;&#31216;&#20026;&#25490;&#26021;&#38543;&#26426;&#28216;&#36208;&#65292;&#36890;&#36807;&#25913;&#36827;&#22270;&#30340;&#37319;&#26679;&#65292;&#25552;&#39640;&#20102;&#32479;&#35745;&#20272;&#35745;&#22120;&#30340;&#38598;&#20013;&#24230;&#12290;&#35813;&#26426;&#21046;&#22312;&#20272;&#35745;&#22270;&#20869;&#26680;&#12289;PageRank&#21521;&#37327;&#21644;&#22270;&#24418;&#27987;&#24230;&#31561;&#26041;&#38754;&#23637;&#31034;&#20102;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20934;&#33945;&#29305;&#21345;&#32599;&#26426;&#21046;&#65292;&#31216;&#20026;&#25490;&#26021;&#38543;&#26426;&#28216;&#36208;&#65292;&#20197;&#25913;&#36827;&#22522;&#20110;&#22270;&#30340;&#37319;&#26679;&#12290;&#36890;&#36807;&#22312;&#30456;&#20114;&#20316;&#29992;&#38598;&#21512;&#30340;&#36712;&#36857;&#20043;&#38388;&#24341;&#20837;&#30456;&#20851;&#24615;&#65292;&#20351;&#23427;&#20204;&#30340;&#36793;&#38469;&#36716;&#31227;&#27010;&#29575;&#20445;&#25345;&#19981;&#21464;&#65292;&#25105;&#20204;&#33021;&#22815;&#26356;&#39640;&#25928;&#22320;&#25506;&#32034;&#22270;&#24418;&#65292;&#25552;&#39640;&#32479;&#35745;&#20272;&#35745;&#22120;&#30340;&#38598;&#20013;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;&#23427;&#20204;&#30340;&#26080;&#20559;&#24615;&#12290;&#35813;&#26426;&#21046;&#21487;&#20197;&#36731;&#26494;&#22320;&#23454;&#29616;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#20272;&#35745;&#22270;&#20869;&#26680;&#12289;PageRank&#21521;&#37327;&#21644;&#22270;&#24418;&#27987;&#24230;&#31561;&#21508;&#31181;&#24773;&#20917;&#19979;&#65292;&#25490;&#26021;&#38543;&#26426;&#28216;&#36208;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#35814;&#32454;&#30340;&#23454;&#39564;&#35780;&#20272;&#21644;&#40065;&#26834;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25490;&#26021;&#38543;&#26426;&#28216;&#36208;&#26159;&#31532;&#19968;&#20010;&#22312;&#22270;&#19978;&#30456;&#20851;&#27493;&#34892;&#32773;&#26041;&#21521;&#36827;&#34892;&#20005;&#26684;&#30740;&#31350;&#30340;&#20934;&#33945;&#29305;&#21345;&#32599;&#26041;&#26696;&#65292;&#20026;&#36825;&#20010;&#20196;&#20154;&#20852;&#22859;&#30340;&#26032;&#20852;&#39046;&#22495;&#24102;&#26469;&#20102;&#26032;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel quasi-Monte Carlo mechanism to improve graph-based sampling, coined repelling random walks. By inducing correlations between the trajectories of an interacting ensemble such that their marginal transition probabilities are unmodified, we are able to explore the graph more efficiently, improving the concentration of statistical estimators whilst leaving them unbiased. The mechanism has a trivial drop-in implementation. We showcase the effectiveness of repelling random walks in a range of settings including estimation of graph kernels, the PageRank vector and graphlet concentrations. We provide detailed experimental evaluation and robust theoretical guarantees. To our knowledge, repelling random walks constitute the first rigorously studied quasi-Monte Carlo scheme correlating the directions of walkers on a graph, inviting new research in this exciting nascent domain.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24310;&#36831;MLMC&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#37325;&#22797;&#21033;&#29992;&#20043;&#21069;&#27493;&#39588;&#20013;&#35745;&#31639;&#36807;&#30340;&#26799;&#24230;&#20998;&#37327;&#65292;&#22823;&#22823;&#38477;&#20302;&#20102;MLMC&#30340;&#24182;&#34892;&#22797;&#26434;&#24615;&#65292;&#24182;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#20854;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#20855;&#26377;&#26356;&#22909;&#30340;&#24182;&#34892;&#22797;&#26434;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.02402</link><description>&lt;p&gt;
&#20851;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#22810;&#23618;&#33945;&#29305;&#21345;&#27931;&#30340;&#24182;&#34892;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Parallel Complexity of Multilevel Monte Carlo in Stocahstic Gradient Descent. (arXiv:2310.02402v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02402
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24310;&#36831;MLMC&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#37325;&#22797;&#21033;&#29992;&#20043;&#21069;&#27493;&#39588;&#20013;&#35745;&#31639;&#36807;&#30340;&#26799;&#24230;&#20998;&#37327;&#65292;&#22823;&#22823;&#38477;&#20302;&#20102;MLMC&#30340;&#24182;&#34892;&#22797;&#26434;&#24615;&#65292;&#24182;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#20854;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#20855;&#26377;&#26356;&#22909;&#30340;&#24182;&#34892;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29992;&#20110;&#39034;&#24207;&#27169;&#25311;&#65288;&#22914;&#31070;&#32463;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65289;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#20013;&#65292;&#22810;&#23618;&#33945;&#29305;&#21345;&#27931;&#65288;MLMC&#65289;&#26041;&#27861;&#24050;&#34987;&#35777;&#26126;&#22312;&#29702;&#35770;&#35745;&#31639;&#22797;&#26434;&#24615;&#26041;&#38754;&#20248;&#20110;&#26420;&#32032;&#30340;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#12290;&#28982;&#32780;&#22312;&#23454;&#36341;&#20013;&#65292;MLMC&#22312;&#29616;&#20195;GPU&#31561;&#22823;&#35268;&#27169;&#24182;&#34892;&#35745;&#31639;&#24179;&#21488;&#19978;&#30340;&#21487;&#25193;&#23637;&#24615;&#36739;&#24046;&#65292;&#22240;&#20026;&#20854;&#24182;&#34892;&#22797;&#26434;&#24615;&#19982;&#26420;&#32032;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#30456;&#24403;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24310;&#36831;MLMC&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#37325;&#22797;&#21033;&#29992;&#20043;&#21069;&#27493;&#39588;&#20013;&#35745;&#31639;&#36807;&#30340;&#26799;&#24230;&#20998;&#37327;&#65292;&#22823;&#22823;&#38477;&#20302;MLMC&#30340;&#24182;&#34892;&#22797;&#26434;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#33021;&#22815;&#35777;&#26126;&#38477;&#20302;&#24179;&#22343;&#24182;&#34892;&#22797;&#26434;&#24615;&#65292;&#20294;&#20195;&#20215;&#26159;&#31245;&#24046;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;&#22312;&#25105;&#20204;&#30340;&#25968;&#20540;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#28145;&#24230;&#23545;&#20914;&#30340;&#31034;&#20363;&#26469;&#35777;&#26126;&#19982;&#26631;&#20934;MLMC&#22312;SGD&#20013;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#24182;&#34892;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the stochastic gradient descent (SGD) for sequential simulations such as the neural stochastic differential equations, the Multilevel Monte Carlo (MLMC) method is known to offer better theoretical computational complexity compared to the naive Monte Carlo approach. However, in practice, MLMC scales poorly on massively parallel computing platforms such as modern GPUs, because of its large parallel complexity which is equivalent to that of the naive Monte Carlo method. To cope with this issue, we propose the delayed MLMC gradient estimator that drastically reduces the parallel complexity of MLMC by recycling previously computed gradient components from earlier steps of SGD. The proposed estimator provably reduces the average parallel complexity per iteration at the cost of a slightly worse per-iteration convergence rate. In our numerical experiments, we use an example of deep hedging to demonstrate the superior parallel complexity of our method compared to the standard MLMC in SGD.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#21644;&#38598;&#25104;&#26041;&#27861;&#30340;&#20117;&#19979;&#29305;&#24615;&#34920;&#24449;&#26041;&#27861;&#12290;&#36890;&#36807;&#32467;&#21512;WGAN-GP&#21644;ES-MDA&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#20934;&#30830;&#19988;&#39640;&#25928;&#30340;K&#22330;&#20272;&#35745;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#20960;&#20010;&#20117;&#19979;&#23454;&#20363;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#26410;&#30693;K&#23383;&#27573;&#30340;&#20027;&#35201;&#29305;&#24449;&#12290;</title><link>http://arxiv.org/abs/2310.00839</link><description>&lt;p&gt;
&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#22522;&#20110;&#38598;&#25104;&#26041;&#27861;&#30340;&#20117;&#19979;&#29305;&#24615;&#34920;&#24449;
&lt;/p&gt;
&lt;p&gt;
Subsurface Characterization using Ensemble-based Approaches with Deep Generative Models. (arXiv:2310.00839v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00839
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#21644;&#38598;&#25104;&#26041;&#27861;&#30340;&#20117;&#19979;&#29305;&#24615;&#34920;&#24449;&#26041;&#27861;&#12290;&#36890;&#36807;&#32467;&#21512;WGAN-GP&#21644;ES-MDA&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#20934;&#30830;&#19988;&#39640;&#25928;&#30340;K&#22330;&#20272;&#35745;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#20960;&#20010;&#20117;&#19979;&#23454;&#20363;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#26410;&#30693;K&#23383;&#27573;&#30340;&#20027;&#35201;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20272;&#35745;&#22914;&#27700;&#21147;&#20256;&#23548;&#29575;&#65288;K&#65289;&#31561;&#31354;&#38388;&#20998;&#24067;&#23646;&#24615;&#26159;&#20117;&#19979;&#29305;&#24615;&#34920;&#24449;&#20013;&#30340;&#37325;&#22823;&#25361;&#25112;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#35745;&#31639;&#25104;&#26412;&#39640;&#21644;&#31232;&#30095;&#25968;&#25454;&#38598;&#30340;&#39044;&#27979;&#31934;&#24230;&#20302;&#65292;&#36870;&#21521;&#24314;&#27169;&#22312;&#19981;&#36866;&#23450;&#30340;&#39640;&#32500;&#24212;&#29992;&#20013;&#21463;&#38480;&#12290;&#26412;&#25991;&#23558;Wasserstein&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#19982;&#26799;&#24230;&#24809;&#32602;&#65288;WGAN-GP&#65289;&#21644;&#22522;&#20110;&#38598;&#25104;&#30340;&#22810;&#20803;&#25968;&#25454;&#21516;&#21270;&#65288;ES-MDA&#65289;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#20934;&#30830;&#19988;&#39640;&#25928;&#30340;&#20117;&#19979;&#29305;&#24615;&#34920;&#24449;&#12290;WGAN-GP&#36890;&#36807;&#35757;&#32451;&#20174;&#20302;&#32500;&#28508;&#21464;&#37327;&#31354;&#38388;&#29983;&#25104;&#39640;&#32500;K&#22330;&#65292;ES-MDA&#36890;&#36807;&#21516;&#21270;&#21487;&#29992;&#27979;&#37327;&#32467;&#26524;&#26469;&#26356;&#26032;&#28508;&#21464;&#37327;&#12290;&#21033;&#29992;&#20960;&#20010;&#20117;&#19979;&#23454;&#20363;&#35780;&#20272;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#65292;&#20197;&#21450;&#26410;&#30693;K&#23383;&#27573;&#30340;&#20027;&#35201;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating spatially distributed properties such as hydraulic conductivity (K) from available sparse measurements is a great challenge in subsurface characterization. However, the use of inverse modeling is limited for ill-posed, high-dimensional applications due to computational costs and poor prediction accuracy with sparse datasets. In this paper, we combine Wasserstein Generative Adversarial Network with Gradient Penalty (WGAN-GP), a deep generative model that can accurately capture complex subsurface structure, and Ensemble Smoother with Multiple Data Assimilation (ES-MDA), an ensemble-based inversion method, for accurate and accelerated subsurface characterization. WGAN-GP is trained to generate high-dimensional K fields from a low-dimensional latent space and ES-MDA then updates the latent variables by assimilating available measurements. Several subsurface examples are used to evaluate the accuracy and efficiency of the proposed method and the main features of the unknown K fie
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#32479;&#35745;&#20272;&#35745;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65292;&#20027;&#35201;&#20851;&#27880;Wasserstein&#20998;&#24067;&#20559;&#31227;&#65292;&#25552;&#20986;&#20102;&#32852;&#21512;&#20998;&#24067;&#20559;&#31227;&#27010;&#24565;&#65292;&#24182;&#20998;&#26512;&#20102;&#20960;&#20010;&#32479;&#35745;&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;&#35770;&#25991;&#21457;&#29616;&#20102;&#26368;&#20248;&#30340;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;&#21644;&#26368;&#19981;&#21033;&#30340;&#25200;&#21160;&#65292;&#24182;&#35777;&#26126;&#20102;&#26679;&#26412;&#22343;&#20540;&#21644;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#37327;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.01853</link><description>&lt;p&gt;
&#32479;&#35745;&#20272;&#35745;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;: Wasserstein&#25200;&#21160;&#19982;&#26497;&#23567;&#26497;&#22823;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Statistical Estimation Under Distribution Shift: Wasserstein Perturbations and Minimax Theory. (arXiv:2308.01853v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01853
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#32479;&#35745;&#20272;&#35745;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65292;&#20027;&#35201;&#20851;&#27880;Wasserstein&#20998;&#24067;&#20559;&#31227;&#65292;&#25552;&#20986;&#20102;&#32852;&#21512;&#20998;&#24067;&#20559;&#31227;&#27010;&#24565;&#65292;&#24182;&#20998;&#26512;&#20102;&#20960;&#20010;&#32479;&#35745;&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;&#35770;&#25991;&#21457;&#29616;&#20102;&#26368;&#20248;&#30340;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;&#21644;&#26368;&#19981;&#21033;&#30340;&#25200;&#21160;&#65292;&#24182;&#35777;&#26126;&#20102;&#26679;&#26412;&#22343;&#20540;&#21644;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#37327;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#20559;&#31227;&#26159;&#29616;&#20195;&#32479;&#35745;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20005;&#37325;&#38382;&#39064;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#20197;&#23558;&#25968;&#25454;&#30340;&#29305;&#24615;&#20174;&#30495;&#23454;&#24773;&#20917;&#20013;&#31995;&#32479;&#22320;&#25913;&#21464;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;Wasserstein&#20998;&#24067;&#20559;&#31227;&#65292;&#20854;&#20013;&#27599;&#20010;&#25968;&#25454;&#28857;&#21487;&#33021;&#20250;&#21457;&#29983;&#36731;&#24494;&#25200;&#21160;&#65292;&#32780;&#19981;&#26159;Huber&#27745;&#26579;&#27169;&#22411;&#65292;&#20854;&#20013;&#19968;&#37096;&#20998;&#35266;&#27979;&#20540;&#26159;&#24322;&#24120;&#20540;&#12290;&#25105;&#20204;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;&#36229;&#20986;&#29420;&#31435;&#25200;&#21160;&#30340;&#20559;&#31227;&#65292;&#25506;&#32034;&#20102;&#32852;&#21512;&#20998;&#24067;&#20559;&#31227;&#65292;&#20854;&#20013;&#27599;&#20010;&#35266;&#27979;&#28857;&#30340;&#25200;&#21160;&#21487;&#20197;&#21327;&#35843;&#36827;&#34892;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#20960;&#20010;&#37325;&#35201;&#30340;&#32479;&#35745;&#38382;&#39064;&#65292;&#21253;&#25324;&#20301;&#32622;&#20272;&#35745;&#12289;&#32447;&#24615;&#22238;&#24402;&#21644;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#12290;&#22312;&#22343;&#20540;&#20272;&#35745;&#21644;&#32447;&#24615;&#22238;&#24402;&#30340;&#39044;&#27979;&#35823;&#24046;&#26041;&#24046;&#19979;&#65292;&#25105;&#20204;&#25214;&#21040;&#20102;&#31934;&#30830;&#30340;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;&#12289;&#26368;&#19981;&#21033;&#30340;&#25200;&#21160;&#65292;&#24182;&#35777;&#26126;&#20102;&#26679;&#26412;&#22343;&#20540;&#21644;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#37327;&#20998;&#21035;&#26159;&#26368;&#20248;&#30340;&#12290;&#36825;&#36866;&#29992;&#20110;&#29420;&#31435;&#21644;&#32852;&#21512;&#20559;&#31227;&#65292;&#20294;&#26368;&#19981;&#21033;&#30340;&#25200;&#21160;&#21644;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;&#26159;&#19981;&#21516;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distribution shifts are a serious concern in modern statistical learning as they can systematically change the properties of the data away from the truth. We focus on Wasserstein distribution shifts, where every data point may undergo a slight perturbation, as opposed to the Huber contamination model where a fraction of observations are outliers. We formulate and study shifts beyond independent perturbations, exploring Joint Distribution Shifts, where the per-observation perturbations can be coordinated. We analyze several important statistical problems, including location estimation, linear regression, and non-parametric density estimation. Under a squared loss for mean estimation and prediction error in linear regression, we find the exact minimax risk, a least favorable perturbation, and show that the sample mean and least squares estimators are respectively optimal. This holds for both independent and joint shifts, but the least favorable perturbations and minimax risks differ. For
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26680;&#21270;&#24402;&#19968;&#21270;&#27969;&#33539;&#24335;&#65292;&#31216;&#20026;Ferumal&#27969;&#65292;&#23427;&#23558;&#26680;&#20989;&#25968;&#38598;&#25104;&#21040;&#24402;&#19968;&#21270;&#27969;&#30340;&#26694;&#26550;&#20013;&#12290;&#30456;&#23545;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#27969;&#65292;&#26680;&#21270;&#27969;&#21487;&#20197;&#22312;&#20302;&#25968;&#25454;&#29615;&#22659;&#20013;&#20135;&#29983;&#31454;&#20105;&#21147;&#25110;&#20248;&#36234;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#20445;&#25345;&#21442;&#25968;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2307.14839</link><description>&lt;p&gt;
&#26680;&#21270;&#24402;&#19968;&#21270;&#27969;
&lt;/p&gt;
&lt;p&gt;
Kernelised Normalising Flows. (arXiv:2307.14839v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14839
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26680;&#21270;&#24402;&#19968;&#21270;&#27969;&#33539;&#24335;&#65292;&#31216;&#20026;Ferumal&#27969;&#65292;&#23427;&#23558;&#26680;&#20989;&#25968;&#38598;&#25104;&#21040;&#24402;&#19968;&#21270;&#27969;&#30340;&#26694;&#26550;&#20013;&#12290;&#30456;&#23545;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#27969;&#65292;&#26680;&#21270;&#27969;&#21487;&#20197;&#22312;&#20302;&#25968;&#25454;&#29615;&#22659;&#20013;&#20135;&#29983;&#31454;&#20105;&#21147;&#25110;&#20248;&#36234;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#20445;&#25345;&#21442;&#25968;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24402;&#19968;&#21270;&#27969;&#26159;&#20197;&#20854;&#21487;&#36870;&#30340;&#26550;&#26500;&#32780;&#34987;&#25551;&#36848;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#21487;&#36870;&#24615;&#35201;&#27714;&#23545;&#20854;&#34920;&#36798;&#33021;&#21147;&#26045;&#21152;&#38480;&#21046;&#65292;&#38656;&#35201;&#22823;&#37327;&#30340;&#21442;&#25968;&#21644;&#21019;&#26032;&#30340;&#26550;&#26500;&#35774;&#35745;&#26469;&#36798;&#21040;&#28385;&#24847;&#30340;&#32467;&#26524;&#12290;&#34429;&#28982;&#22522;&#20110;&#27969;&#30340;&#27169;&#22411;&#20027;&#35201;&#20381;&#36182;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#36716;&#25442;&#26469;&#23454;&#29616;&#34920;&#36798;&#33021;&#21147;&#65292;&#20294;&#26367;&#20195;&#30340;&#36716;&#25442;&#26041;&#27861;&#21364;&#21463;&#21040;&#20102;&#26377;&#38480;&#30340;&#20851;&#27880;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26680;&#21270;&#24402;&#19968;&#21270;&#27969;&#33539;&#24335;&#65292;&#31216;&#20026;Ferumal&#27969;&#65292;&#23427;&#23558;&#26680;&#20989;&#25968;&#38598;&#25104;&#21040;&#26694;&#26550;&#20013;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#27604;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#27969;&#65292;&#26680;&#21270;&#27969;&#21487;&#20197;&#20135;&#29983;&#26377;&#31454;&#20105;&#21147;&#25110;&#20248;&#36234;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#20445;&#25345;&#21442;&#25968;&#25928;&#29575;&#12290;&#26680;&#21270;&#27969;&#22312;&#20302;&#25968;&#25454;&#29615;&#22659;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#21487;&#20197;&#22312;&#25968;&#25454;&#31232;&#32570;&#30340;&#24212;&#29992;&#20013;&#36827;&#34892;&#28789;&#27963;&#30340;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Normalising Flows are generative models characterised by their invertible architecture. However, the requirement of invertibility imposes constraints on their expressiveness, necessitating a large number of parameters and innovative architectural designs to achieve satisfactory outcomes. Whilst flow-based models predominantly rely on neural-network-based transformations for expressive designs, alternative transformation methods have received limited attention. In this work, we present Ferumal flow, a novel kernelised normalising flow paradigm that integrates kernels into the framework. Our results demonstrate that a kernelised flow can yield competitive or superior results compared to neural network-based flows whilst maintaining parameter efficiency. Kernelised flows excel especially in the low-data regime, enabling flexible non-parametric density estimation in applications with sparse data availability.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; L-C2ST &#30340;&#22522;&#20110;&#26412;&#22320;&#35786;&#26029;&#23454;&#29616;&#27169;&#25311;&#25512;&#26029;&#20013;&#21518;&#39564;&#36817;&#20284;&#30340;&#26032;&#26041;&#27861;&#65292;&#20854;&#21487;&#20197;&#22312;&#20219;&#20309;&#32473;&#23450;&#30340;&#35266;&#27979;&#19979;&#26412;&#22320;&#35780;&#20272;&#21518;&#39564;&#20272;&#35745;&#22120;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#30446;&#21069;&#35780;&#20272;&#21518;&#39564;&#20272;&#35745;&#22120;&#38480;&#21046;&#35299;&#20915;&#26041;&#27861;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.03580</link><description>&lt;p&gt;
L-C2ST: &#22522;&#20110;&#26412;&#22320;&#35786;&#26029;&#23454;&#29616;&#27169;&#25311;&#25512;&#26029;&#20013;&#21518;&#39564;&#36817;&#20284;
&lt;/p&gt;
&lt;p&gt;
L-C2ST: Local Diagnostics for Posterior Approximations in Simulation-Based Inference. (arXiv:2306.03580v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03580
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; L-C2ST &#30340;&#22522;&#20110;&#26412;&#22320;&#35786;&#26029;&#23454;&#29616;&#27169;&#25311;&#25512;&#26029;&#20013;&#21518;&#39564;&#36817;&#20284;&#30340;&#26032;&#26041;&#27861;&#65292;&#20854;&#21487;&#20197;&#22312;&#20219;&#20309;&#32473;&#23450;&#30340;&#35266;&#27979;&#19979;&#26412;&#22320;&#35780;&#20272;&#21518;&#39564;&#20272;&#35745;&#22120;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#30446;&#21069;&#35780;&#20272;&#21518;&#39564;&#20272;&#35745;&#22120;&#38480;&#21046;&#35299;&#20915;&#26041;&#27861;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#35768;&#22810;&#27169;&#25311;&#25512;&#26029;&#65288;SBI&#65289;&#30340;&#24037;&#20316;&#37117;&#20381;&#36182;&#20110;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#26469;&#36817;&#20284;&#22797;&#26434;&#12289;&#39640;&#32500;&#24230;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#28982;&#32780;&#65292;&#35780;&#20272;&#36825;&#20123;&#36817;&#20284;&#26159;&#21542;&#21487;&#20449;&#20173;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#22823;&#22810;&#25968;&#26041;&#27861;&#20165;&#22312;&#35266;&#27979;&#31354;&#38388;&#26399;&#26395;&#19979;&#35780;&#20272;&#21518;&#39564;&#20272;&#35745;&#22120;&#12290;&#36825;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#19981;&#33021;&#36275;&#22815;&#22320;&#30830;&#23450;&#21738;&#20123;&#35266;&#27979;&#32467;&#26524;&#21487;&#20197;&#20449;&#20219;&#36825;&#20123;&#36817;&#20284;&#25110;&#24212;&#35813;&#25913;&#36827;&#12290;&#25105;&#20204;&#22522;&#20110;&#33879;&#21517;&#30340;&#20998;&#31867;&#22120;&#20004;&#26679;&#26412;&#26816;&#39564; (C2ST)&#65292;&#24341;&#20837; L-C2ST&#65292;&#19968;&#20010;&#26032;&#26041;&#27861;&#65292;&#20801;&#35768;&#22312;&#20219;&#20309;&#32473;&#23450;&#30340;&#35266;&#27979;&#19979;&#26412;&#22320;&#35780;&#20272;&#21518;&#39564;&#20272;&#35745;&#22120;&#12290;&#23427;&#25552;&#20379;&#26377;&#29702;&#35770;&#22522;&#30784;&#21644;&#26131;&#20110;&#35299;&#37322;&#30340;&#65292;&#22914;&#22270;&#31034;&#35786;&#26029;&#12290;&#19982; C2ST &#19981;&#21516;&#30340;&#26159;&#65292;L-C2ST &#19981;&#38656;&#35201;&#35775;&#38382;&#30495;&#23454;&#21518;&#39564;&#30340;&#26679;&#26412;&#12290;&#23545;&#20110;&#22522;&#20110;&#24402;&#19968;&#21270;&#27969;&#30340;&#21518;&#39564;&#20272;&#35745;&#22120;&#65292;L-C2ST &#21487;&#20197;&#19987;&#38376;&#25552;&#20379;&#26356;&#22909;&#30340;&#32479;&#35745;&#21151;&#29575;&#65292;&#21516;&#26102;&#35745;&#31639;&#25928;&#29575;&#26356;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many recent works in simulation-based inference (SBI) rely on deep generative models to approximate complex, high-dimensional posterior distributions. However, evaluating whether or not these approximations can be trusted remains a challenge. Most approaches evaluate the posterior estimator only in expectation over the observation space. This limits their interpretability and is not sufficient to identify for which observations the approximation can be trusted or should be improved. Building upon the well-known classifier two-sample test (C2ST), we introduce L-C2ST, a new method that allows for a local evaluation of the posterior estimator at any given observation. It offers theoretically grounded and easy to interpret - e.g. graphical - diagnostics, and unlike C2ST, does not require access to samples from the true posterior. In the case of normalizing flow-based posterior estimators, L-C2ST can be specialized to offer better statistical power, while being computationally more efficien
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;In-Context Learning&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#30740;&#31350;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#31639;&#27861;&#26469;&#38544;&#24335;&#22320;&#23454;&#29616;ICL&#20272;&#35745;&#37327;&#65292;&#24182;&#37319;&#29992;&#22312;&#32447;&#23398;&#20064;&#30340;&#35282;&#24230;&#26469;&#20998;&#26512;ICL&#24615;&#33021;&#65292;&#24314;&#31435;&#21518;&#24724;&#30028;&#38480;&#65292;&#24182;&#36890;&#36807;&#20851;&#27880;&#26426;&#21046;&#36817;&#20284;&#21442;&#25968;&#21270;&#12290;</title><link>http://arxiv.org/abs/2305.19420</link><description>&lt;p&gt;
In-Context Learning&#23398;&#20064;&#20102;&#20160;&#20040;&#20197;&#21450;&#22914;&#20309;&#23398;&#20064;&#65311;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#12289;&#21442;&#25968;&#21270;&#21644;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
What and How does In-Context Learning Learn? Bayesian Model Averaging, Parameterization, and Generalization. (arXiv:2305.19420v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19420
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;In-Context Learning&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#30740;&#31350;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#31639;&#27861;&#26469;&#38544;&#24335;&#22320;&#23454;&#29616;ICL&#20272;&#35745;&#37327;&#65292;&#24182;&#37319;&#29992;&#22312;&#32447;&#23398;&#20064;&#30340;&#35282;&#24230;&#26469;&#20998;&#26512;ICL&#24615;&#33021;&#65292;&#24314;&#31435;&#21518;&#24724;&#30028;&#38480;&#65292;&#24182;&#36890;&#36807;&#20851;&#27880;&#26426;&#21046;&#36817;&#20284;&#21442;&#25968;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#22238;&#31572;&#20960;&#20010;&#24320;&#25918;&#24615;&#38382;&#39064;&#65292;&#23545;In-Context Learning&#65288;ICL&#65289;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#30740;&#31350;&#65306;(a)&#22312;&#35821;&#35328;&#27169;&#22411;&#20013;&#23398;&#20064;&#30340;&#26159;&#20160;&#20040;&#31867;&#22411;&#30340;ICL&#20272;&#35745;&#37327;&#65311;(b)&#36866;&#21512;&#35780;&#20272;ICL&#30340;&#24615;&#33021;&#24230;&#37327;&#26159;&#20160;&#20040;&#65292;&#24182;&#19988;&#38169;&#35823;&#29575;&#26159;&#22810;&#23569;&#65311;(c)Transformer&#26550;&#26500;&#22914;&#20309;&#23454;&#29616;ICL&#65311;&#20026;&#20102;&#22238;&#31572;(a)&#65292;&#25105;&#20204;&#37319;&#21462;&#20102;&#36125;&#21494;&#26031;&#35266;&#28857;&#65292;&#24182;&#35777;&#26126;ICL&#38544;&#21547;&#23454;&#29616;&#20102;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#31639;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20010;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#31639;&#27861;&#21487;&#20197;&#36890;&#36807;&#20851;&#27880;&#26426;&#21046;&#36817;&#20284;&#21442;&#25968;&#21270;&#12290;(b)&#20174;&#22312;&#32447;&#23398;&#20064;&#30340;&#35282;&#24230;&#20998;&#26512;ICL&#24615;&#33021;&#65292;&#24314;&#31435;&#19968;&#20010;&#21518;&#24724;&#30028;&#38480; $\mathcal{O}(1/T)$&#65292;&#20854;&#20013;$T$&#26159;ICL&#36755;&#20837;&#24207;&#21015;&#38271;&#24230;&#12290;(c)&#38500;&#20102;&#22312;&#20851;&#27880;&#20013;&#32534;&#30721;&#30340;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#31639;&#27861;&#65292;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#22312;&#28041;&#21450;&#26399;&#38388;&#65292;&#23398;&#20064;&#27169;&#22411;&#21644;&#21517;&#20041;&#27169;&#22411;&#20043;&#38388;&#30340;&#24635;&#21464;&#20998;&#36317;&#31163;&#34987;&#19968;&#20010;&#36817;&#20284;&#35823;&#24046;&#21644;&#19968;&#20010;&#27867;&#21270;&#35823;&#24046;&#20043;&#21644;&#25152;&#30028;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we conduct a comprehensive study of In-Context Learning (ICL) by addressing several open questions: (a) What type of ICL estimator is learned within language models? (b) What are suitable performance metrics to evaluate ICL accurately and what are the error rates? (c) How does the transformer architecture enable ICL? To answer (a), we take a Bayesian view and demonstrate that ICL implicitly implements the Bayesian model averaging algorithm. This Bayesian model averaging algorithm is proven to be approximately parameterized by the attention mechanism. For (b), we analyze the ICL performance from an online learning perspective and establish a regret bound $\mathcal{O}(1/T)$, where $T$ is the ICL input sequence length. To address (c), in addition to the encoded Bayesian model averaging algorithm in attention, we show that during pertaining, the total variation distance between the learned model and the nominal model is bounded by a sum of an approximation error and a genera
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;SAL&#21644;SCoreBO&#20004;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#25552;&#39640;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#36229;&#21442;&#25968;&#36873;&#25321;&#21644;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2304.11005</link><description>&lt;p&gt;
&#36890;&#36807;&#36125;&#21494;&#26031;&#20027;&#21160;&#23398;&#20064;&#23454;&#29616;&#33258;&#26657;&#27491;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Self-Correcting Bayesian Optimization through Bayesian Active Learning. (arXiv:2304.11005v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11005
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;SAL&#21644;SCoreBO&#20004;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#25552;&#39640;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#36229;&#21442;&#25968;&#36873;&#25321;&#21644;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#24050;&#25104;&#20026;&#36125;&#21494;&#26031;&#20248;&#21270;&#21644;&#20027;&#21160;&#23398;&#20064;&#20013;&#30340;&#39318;&#36873;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#39640;&#26031;&#36807;&#31243;&#30340;&#23436;&#20840;&#21457;&#25381;&#38656;&#35201;&#24039;&#22937;&#36873;&#25321;&#36229;&#21442;&#25968;&#65292;&#32780;&#22312;&#25991;&#29486;&#20013;&#24456;&#23569;&#26377;&#20851;&#20110;&#25214;&#21040;&#27491;&#30830;&#36229;&#21442;&#25968;&#30340;&#21162;&#21147;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#36873;&#25321;&#22909;&#30340;&#36229;&#21442;&#25968;&#23545;&#20110;&#39640;&#26031;&#36807;&#31243;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#26126;&#30830;&#20248;&#20808;&#32771;&#34385;&#27492;&#30446;&#26631;&#30340;&#25910;&#36141;&#20989;&#25968;&#12290;&#32479;&#35745;&#36317;&#31163;&#20027;&#21160;&#23398;&#20064;&#65288;SAL&#65289;&#32771;&#34385;&#21518;&#39564;&#26679;&#26412;&#30340;&#24179;&#22343;&#19981;&#19968;&#33268;&#24615;&#65292;&#30001;&#32479;&#35745;&#36317;&#31163;&#27979;&#37327;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#22312;&#35768;&#22810;&#27979;&#35797;&#20989;&#25968;&#19978;&#65292;&#23427;&#32988;&#36807;&#20102;&#36125;&#21494;&#26031;&#20027;&#21160;&#23398;&#20064;&#30340;&#26368;&#26032;&#32467;&#26524;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#33258;&#26657;&#27491;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;SCoreBO&#65289;&#65292;&#23427;&#23558;SAL&#25193;&#23637;&#21040;&#21516;&#26102;&#25191;&#34892;&#36125;&#21494;&#26031;&#20248;&#21270;&#21644;&#20027;&#21160;&#36229;&#21442;&#25968;&#23398;&#20064;&#12290;&#30456;&#27604;&#20256;&#32479;BO&#65292;SCoreBO&#20197;&#25913;&#36827;&#30340;&#36895;&#24230;&#23398;&#20064;&#27169;&#22411;&#36229;&#21442;&#25968;&#65292;&#21516;&#26102;&#22312;&#26368;&#26032;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#25628;&#32034;&#20013;&#21462;&#24471;&#26356;&#22909;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes are cemented as the model of choice in Bayesian optimization and active learning. Yet, they are severely dependent on cleverly chosen hyperparameters to reach their full potential, and little effort is devoted to finding the right hyperparameters in the literature. We demonstrate the impact of selecting good hyperparameters for GPs and present two acquisition functions that explicitly prioritize this goal. Statistical distance-based Active Learning (SAL) considers the average disagreement among samples from the posterior, as measured by a statistical distance. It is shown to outperform the state-of-the-art in Bayesian active learning on a number of test functions. We then introduce Self-Correcting Bayesian Optimization (SCoreBO), which extends SAL to perform Bayesian optimization and active hyperparameter learning simultaneously. SCoreBO learns the model hyperparameters at improved rates compared to vanilla BO, while outperforming the latest Bayesian optimization met
&lt;/p&gt;</description></item><item><title>StepMix&#26159;&#19968;&#20010;&#29992;&#20110;&#22806;&#37096;&#21464;&#37327;&#24191;&#20041;&#28151;&#21512;&#27169;&#22411;&#30340;&#20266;&#20284;&#28982;&#20272;&#35745;&#30340;Python&#21253;&#65292;&#25552;&#20379;&#20102;&#21333;&#27493;&#21644;&#36880;&#27493;&#20272;&#35745;&#26041;&#27861;&#65292;&#24110;&#21161;&#20174;&#19994;&#20154;&#21592;&#36827;&#34892;&#27169;&#22411;&#20272;&#35745;&#12289;&#36873;&#25321;&#21644;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2304.03853</link><description>&lt;p&gt;
StepMix: &#19968;&#20010;&#29992;&#20110;&#22806;&#37096;&#21464;&#37327;&#24191;&#20041;&#28151;&#21512;&#27169;&#22411;&#30340;&#20266;&#20284;&#28982;&#20272;&#35745;&#30340;Python&#21253;
&lt;/p&gt;
&lt;p&gt;
StepMix: A Python Package for Pseudo-Likelihood Estimation of Generalized Mixture Models with External Variables. (arXiv:2304.03853v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03853
&lt;/p&gt;
&lt;p&gt;
StepMix&#26159;&#19968;&#20010;&#29992;&#20110;&#22806;&#37096;&#21464;&#37327;&#24191;&#20041;&#28151;&#21512;&#27169;&#22411;&#30340;&#20266;&#20284;&#28982;&#20272;&#35745;&#30340;Python&#21253;&#65292;&#25552;&#20379;&#20102;&#21333;&#27493;&#21644;&#36880;&#27493;&#20272;&#35745;&#26041;&#27861;&#65292;&#24110;&#21161;&#20174;&#19994;&#20154;&#21592;&#36827;&#34892;&#27169;&#22411;&#20272;&#35745;&#12289;&#36873;&#25321;&#21644;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
StepMix&#26159;&#19968;&#20010;&#29992;&#20110;&#24191;&#20041;&#26377;&#38480;&#28151;&#21512;&#27169;&#22411;(&#28508;&#22312;&#21078;&#38754;&#21644;&#28508;&#22312;&#31867;&#20998;&#26512;)&#19982;&#22806;&#37096;&#21464;&#37327;(&#21327;&#21464;&#37327;&#21644;&#36828;&#31243;&#32467;&#26524;)&#30340;&#20266;&#20284;&#28982;&#20272;&#35745;(&#21333;&#27493;&#12289;&#20004;&#27493;&#21644;&#19977;&#27493;&#26041;&#27861;)&#30340;&#24320;&#28304;&#36719;&#20214;&#21253;&#12290;&#22312;&#35768;&#22810;&#31038;&#20250;&#31185;&#23398;&#30340;&#24212;&#29992;&#20013;&#65292;&#20027;&#35201;&#30446;&#26631;&#19981;&#20165;&#26159;&#23558;&#20010;&#20307;&#32858;&#31867;&#25104;&#28508;&#22312;&#31867;&#21035;&#65292;&#36824;&#21253;&#25324;&#20351;&#29992;&#36825;&#20123;&#31867;&#21035;&#26469;&#24320;&#21457;&#26356;&#22797;&#26434;&#30340;&#32479;&#35745;&#27169;&#22411;&#12290;&#36825;&#20123;&#27169;&#22411;&#36890;&#24120;&#20998;&#20026;&#19968;&#20010;&#23558;&#28508;&#22312;&#31867;&#21035;&#19982;&#35266;&#23519;&#25351;&#26631;&#30456;&#20851;&#32852;&#30340;&#27979;&#37327;&#27169;&#22411;&#21644;&#19968;&#20010;&#23558;&#21327;&#21464;&#37327;&#21644;&#32467;&#26524;&#21464;&#37327;&#19982;&#28508;&#22312;&#31867;&#21035;&#30456;&#20851;&#32852;&#30340;&#32467;&#26500;&#27169;&#22411;&#12290;&#27979;&#37327;&#21644;&#32467;&#26500;&#27169;&#22411;&#21487;&#20197;&#20351;&#29992;&#25152;&#35859;&#30340;&#19968;&#27493;&#27861;&#20849;&#21516;&#20272;&#35745;&#65292;&#20063;&#21487;&#20197;&#20351;&#29992;&#36880;&#27493;&#26041;&#27861;&#36880;&#27493;&#20272;&#35745;&#65292;&#23545;&#20110;&#20174;&#19994;&#20154;&#21592;&#26469;&#35828;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#20272;&#35745;&#28508;&#22312;&#31867;&#21035;&#30340;&#21487;&#35299;&#37322;&#24615;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#20248;&#21183;&#12290;&#38500;&#20102;&#19968;&#27493;&#27861;&#65292;StepMix&#36824;&#23454;&#29616;&#20102;&#25991;&#29486;&#20013;&#25552;&#20986;&#30340;&#26368;&#37325;&#35201;&#30340;&#36880;&#27493;&#20272;&#35745;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#29992;&#25143;&#21451;&#22909;&#30340;&#30028;&#38754;&#65292;&#26041;&#20415;&#27169;&#22411;&#30340;&#20272;&#35745;&#12289;&#36873;&#25321;&#21644;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
StepMix is an open-source software package for the pseudo-likelihood estimation (one-, two- and three-step approaches) of generalized finite mixture models (latent profile and latent class analysis) with external variables (covariates and distal outcomes). In many applications in social sciences, the main objective is not only to cluster individuals into latent classes, but also to use these classes to develop more complex statistical models. These models generally divide into a measurement model that relates the latent classes to observed indicators, and a structural model that relates covariates and outcome variables to the latent classes. The measurement and structural models can be estimated jointly using the so-called one-step approach or sequentially using stepwise methods, which present significant advantages for practitioners regarding the interpretability of the estimated latent classes. In addition to the one-step approach, StepMix implements the most important stepwise estim
&lt;/p&gt;</description></item><item><title>Eryn&#26159;&#19968;&#20010;&#22810;&#21151;&#33021;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#37319;&#26679;&#22120;&#65292;&#36890;&#36807;&#38598;&#25104;&#22810;&#31181;&#27010;&#24565;&#21644;&#31639;&#27861;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#21333;&#29420;&#30340;MCMC&#21253;&#65292;&#29992;&#20110;&#35299;&#20915;&#29289;&#29702;&#23398;&#20013;&#30340;&#21442;&#25968;&#20272;&#35745;&#21644;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2303.02164</link><description>&lt;p&gt;
Eryn: &#19968;&#31181;&#22810;&#21151;&#33021;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#37319;&#26679;&#22120;
&lt;/p&gt;
&lt;p&gt;
Eryn : A multi-purpose sampler for Bayesian inference. (arXiv:2303.02164v2 [astro-ph.IM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.02164
&lt;/p&gt;
&lt;p&gt;
Eryn&#26159;&#19968;&#20010;&#22810;&#21151;&#33021;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#37319;&#26679;&#22120;&#65292;&#36890;&#36807;&#38598;&#25104;&#22810;&#31181;&#27010;&#24565;&#21644;&#31639;&#27861;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#21333;&#29420;&#30340;MCMC&#21253;&#65292;&#29992;&#20110;&#35299;&#20915;&#29289;&#29702;&#23398;&#20013;&#30340;&#21442;&#25968;&#20272;&#35745;&#21644;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#22312;&#29289;&#29702;&#23398;&#30340;&#35768;&#22810;&#19981;&#21516;&#38382;&#39064;&#20013;&#34987;&#24191;&#27867;&#24212;&#29992;&#65292;&#20854;&#20013;&#26816;&#27979;&#21644;&#34920;&#24449;&#26159;&#24517;&#35201;&#30340;&#12290;&#24341;&#21147;&#27874;&#22825;&#25991;&#23398;&#20013;&#30340;&#25968;&#25454;&#20998;&#26512;&#23601;&#26159;&#19968;&#20010;&#20856;&#22411;&#30340;&#20363;&#23376;&#12290;&#36125;&#21494;&#26031;&#25512;&#26029;&#38750;&#24120;&#25104;&#21151;&#65292;&#22240;&#20026;&#35813;&#25216;&#26415;&#25552;&#20379;&#20102;&#21442;&#25968;&#30340;&#21518;&#39564;&#27010;&#29575;&#20998;&#24067;&#34920;&#31034;&#65292;&#19981;&#30830;&#23450;&#24615;&#30001;&#23454;&#39564;&#27979;&#37327;&#30340;&#31934;&#30830;&#24230;&#25552;&#20379;&#20449;&#24687;&#12290;&#22312;&#36807;&#21435;&#30340;&#20960;&#21313;&#24180;&#20013;&#65292;&#35768;&#22810;&#20855;&#20307;&#30340;&#36827;&#23637;&#24050;&#32463;&#34987;&#25552;&#20986;&#24182;&#24212;&#29992;&#20110;&#35299;&#20915;&#21508;&#31181;&#19981;&#21516;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#65288;MCMC&#65289;&#31639;&#27861;&#65292;&#23558;&#36825;&#20123;&#27010;&#24565;&#38598;&#25104;&#21040;&#19968;&#20010;&#21333;&#29420;&#30340;MCMC&#21253;&#20013;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#29992;&#25143;&#21451;&#22909;&#19988;&#22810;&#21151;&#33021;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#24037;&#20855;&#31665;Eryn&#65292;&#21487;&#29992;&#20110;&#35299;&#20915;&#21442;&#25968;&#20272;&#35745;&#21644;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#65292;&#20174;&#31616;&#21333;&#30340;&#25512;&#26029;&#38382;&#39064;&#21040;&#22797;&#26434;&#30340;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, methods for Bayesian inference have been widely used in many different problems in physics where detection and characterization are necessary. Data analysis in gravitational-wave astronomy is a prime example of such a case. Bayesian inference has been very successful because this technique provides a representation of the parameters as a posterior probability distribution, with uncertainties informed by the precision of the experimental measurements. During the last couple of decades, many specific advances have been proposed and employed in order to solve a large variety of different problems. In this work, we present a Markov Chain Monte Carlo (MCMC) algorithm that integrates many of those concepts into a single MCMC package. For this purpose, we have built {\tt Eryn}, a user-friendly and multipurpose toolbox for Bayesian inference, which can be utilized for solving parameter estimation and model selection problems, ranging from simple inference questions, to those w
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30740;&#31350;&#23398;&#20064;&#21333;&#20010;&#31070;&#32463;&#20803;&#30340;&#36807;&#24230;&#21442;&#25968;&#21270;&#35774;&#32622;&#65292;&#26412;&#30740;&#31350;&#21457;&#29616;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#20250;&#20197;&#25351;&#25968;&#32423;&#20943;&#24930;&#65292;&#26159;&#39318;&#20010;&#32473;&#20986;&#35813;&#38382;&#39064;&#20840;&#23616;&#25910;&#25947;&#32467;&#26524;&#30340;&#30740;&#31350;&#12290;&#36890;&#36807;&#35777;&#26126;&#19978;&#19979;&#30028;&#65292;&#25105;&#20204;&#31934;&#30830;&#21051;&#30011;&#20986;&#20102;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#25351;&#20986;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#23545;&#20110;&#25910;&#25947;&#36895;&#24230;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2302.10034</link><description>&lt;p&gt;
&#36807;&#24230;&#21442;&#25968;&#21270;&#20250;&#23548;&#33268;&#26799;&#24230;&#19979;&#38477;&#22312;&#23398;&#20064;&#21333;&#20010;&#31070;&#32463;&#20803;&#26102;&#30340;&#25910;&#25947;&#36895;&#24230;&#25351;&#25968;&#32423;&#20943;&#24930;
&lt;/p&gt;
&lt;p&gt;
Over-Parameterization Exponentially Slows Down Gradient Descent for Learning a Single Neuron. (arXiv:2302.10034v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10034
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#23398;&#20064;&#21333;&#20010;&#31070;&#32463;&#20803;&#30340;&#36807;&#24230;&#21442;&#25968;&#21270;&#35774;&#32622;&#65292;&#26412;&#30740;&#31350;&#21457;&#29616;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#20250;&#20197;&#25351;&#25968;&#32423;&#20943;&#24930;&#65292;&#26159;&#39318;&#20010;&#32473;&#20986;&#35813;&#38382;&#39064;&#20840;&#23616;&#25910;&#25947;&#32467;&#26524;&#30340;&#30740;&#31350;&#12290;&#36890;&#36807;&#35777;&#26126;&#19978;&#19979;&#30028;&#65292;&#25105;&#20204;&#31934;&#30830;&#21051;&#30011;&#20986;&#20102;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#25351;&#20986;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#23545;&#20110;&#25910;&#25947;&#36895;&#24230;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#22312;&#20855;&#26377;ReLU&#28608;&#27963;&#20989;&#25968;&#21644;&#26041;&#24418;&#25439;&#22833;&#30340;&#39640;&#26031;&#36755;&#20837;&#19979;&#23398;&#20064;&#21333;&#20010;&#31070;&#32463;&#20803;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#29305;&#21035;&#20851;&#27880;&#23398;&#29983;&#32593;&#32476;&#20855;&#26377;n&#8805;2&#20010;&#31070;&#32463;&#20803;&#30340;&#36807;&#24230;&#21442;&#25968;&#21270;&#35774;&#32622;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#20197;O(T^-3)&#30340;&#36895;&#24230;&#20840;&#23616;&#25910;&#25947;&#12290;&#36825;&#26159;&#23545;&#20110;&#35813;&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#36229;&#36807;&#31934;&#30830;&#21442;&#25968;&#21270;&#35774;&#32622;(n=1)&#30340;&#20840;&#23616;&#25910;&#25947;&#32467;&#26524;&#65292;&#20854;&#20013;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#21576;&#29616;&#20986;exp(-&#937;(T))&#30340;&#36895;&#24230;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#22312;&#36807;&#24230;&#21442;&#25968;&#21270;&#35774;&#32622;&#20013;&#65292;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#26799;&#24230;&#27969;&#31639;&#27861;&#30340;&#19979;&#30028;&#26159;&#937;(T^-3)&#12290;&#36825;&#20004;&#20010;&#19979;&#30028;&#20849;&#21516;&#32473;&#20986;&#20102;&#25910;&#25947;&#36895;&#24230;&#30340;&#31934;&#30830;&#21051;&#30011;&#65292;&#24182;&#39318;&#27425;&#26263;&#31034;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#20250;&#20351;&#25910;&#25947;&#36895;&#24230;&#25351;&#25968;&#32423;&#20943;&#24930;&#12290;&#20026;&#20102;&#35777;&#26126;&#20840;&#23616;&#25910;&#25947;&#65292;&#25105;&#20204;&#38656;&#35201;&#22788;&#29702;&#26799;&#24230;&#19979;&#38477;&#21160;&#21147;&#23398;&#20013;&#23398;&#29983;&#31070;&#32463;&#20803;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#36825;&#22312;&#31934;&#30830;&#21442;&#25968;&#21270;&#35774;&#32622;&#20013;&#19981;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;
We revisit the problem of learning a single neuron with ReLU activation under Gaussian input with square loss. We particularly focus on the over-parameterization setting where the student network has $n\ge 2$ neurons. We prove the global convergence of randomly initialized gradient descent with a $O\left(T^{-3}\right)$ rate. This is the first global convergence result for this problem beyond the exact-parameterization setting ($n=1$) in which the gradient descent enjoys an $\exp(-\Omega(T))$ rate. Perhaps surprisingly, we further present an $\Omega\left(T^{-3}\right)$ lower bound for randomly initialized gradient flow in the over-parameterization setting. These two bounds jointly give an exact characterization of the convergence rate and imply, for the first time, that over-parameterization can exponentially slow down the convergence rate. To prove the global convergence, we need to tackle the interactions among student neurons in the gradient descent dynamics, which are not present in
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#36890;&#36807;&#30740;&#31350;&#37327;&#23376;&#23398;&#20064;&#29702;&#35770;&#25299;&#23637;&#20102;&#25209;&#22788;&#29702;&#22810;&#31867;&#23398;&#20064;&#12289;&#22312;&#32447;&#24067;&#23572;&#23398;&#20064;&#21644;&#22312;&#32447;&#22810;&#31867;&#23398;&#20064;&#65292;&#24182;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#20855;&#26377;&#37327;&#23376;&#31034;&#20363;&#30340;&#22312;&#32447;&#23398;&#20064;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2302.07409</link><description>&lt;p&gt;
&#12298;&#36229;&#36234;&#25209;&#22788;&#29702;&#20108;&#20803;&#20998;&#31867;&#30340;&#37327;&#23376;&#23398;&#20064;&#29702;&#35770;&#12299;
&lt;/p&gt;
&lt;p&gt;
Quantum Learning Theory Beyond Batch Binary Classification. (arXiv:2302.07409v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07409
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#36890;&#36807;&#30740;&#31350;&#37327;&#23376;&#23398;&#20064;&#29702;&#35770;&#25299;&#23637;&#20102;&#25209;&#22788;&#29702;&#22810;&#31867;&#23398;&#20064;&#12289;&#22312;&#32447;&#24067;&#23572;&#23398;&#20064;&#21644;&#22312;&#32447;&#22810;&#31867;&#23398;&#20064;&#65292;&#24182;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#20855;&#26377;&#37327;&#23376;&#31034;&#20363;&#30340;&#22312;&#32447;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Arunachalam&#21644;de Wolf&#65288;2018&#65289;&#35777;&#26126;&#20102;&#22312;&#21487;&#23454;&#29616;&#21644;&#31946;&#28034;&#35774;&#32622;&#19979;&#65292;&#37327;&#23376;&#25209;&#22788;&#29702;&#23398;&#20064;&#24067;&#23572;&#20989;&#25968;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#19982;&#30456;&#24212;&#30340;&#32463;&#20856;&#26679;&#26412;&#22797;&#26434;&#24615;&#20855;&#26377;&#30456;&#21516;&#30340;&#24418;&#24335;&#21644;&#25968;&#37327;&#32423;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#26126;&#26174;&#20196;&#20154;&#24778;&#35766;&#30340;&#32467;&#26524;&#25512;&#24191;&#21040;&#20102;&#25209;&#22788;&#29702;&#22810;&#31867;&#23398;&#20064;&#12289;&#22312;&#32447;&#24067;&#23572;&#23398;&#20064;&#21644;&#22312;&#32447;&#22810;&#31867;&#23398;&#20064;&#12290;&#23545;&#20110;&#25105;&#20204;&#30340;&#22312;&#32447;&#23398;&#20064;&#32467;&#26524;&#65292;&#25105;&#20204;&#39318;&#20808;&#32771;&#34385;&#20102;Dawid&#21644;Tewari&#65288;2022&#65289;&#32463;&#20856;&#27169;&#22411;&#30340;&#33258;&#36866;&#24212;&#23545;&#25163;&#21464;&#20307;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31532;&#19968;&#20010;&#65288;&#25454;&#25105;&#20204;&#25152;&#30693;&#65289;&#20855;&#26377;&#37327;&#23376;&#31034;&#20363;&#30340;&#22312;&#32447;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Arunachalam and de Wolf (2018) showed that the sample complexity of quantum batch learning of boolean functions, in the realizable and agnostic settings, has the same form and order as the corresponding classical sample complexities. In this paper, we extend this, ostensibly surprising, message to batch multiclass learning, online boolean learning, and online multiclass learning. For our online learning results, we first consider an adaptive adversary variant of the classical model of Dawid and Tewari (2022). Then, we introduce the first (to the best of our knowledge) model of online learning with quantum examples.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23618;&#32423;&#22686;&#24378;&#23398;&#20064;&#20013;&#30340;&#30693;&#35782;&#20256;&#36755;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#27809;&#26377;&#20808;&#39564;&#30693;&#35782;&#30340;&#20219;&#21153;&#30456;&#20284;&#24615;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#24378;&#22823;&#30340;&#30693;&#35782;&#20256;&#36755;&#12290;</title><link>http://arxiv.org/abs/2302.05534</link><description>&lt;p&gt;
&#24378;&#22823;&#30340;&#23618;&#32423;&#22686;&#24378;&#23398;&#20064;&#20013;&#30340;&#30693;&#35782;&#20256;&#36755;
&lt;/p&gt;
&lt;p&gt;
Robust Knowledge Transfer in Tiered Reinforcement Learning. (arXiv:2302.05534v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05534
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23618;&#32423;&#22686;&#24378;&#23398;&#20064;&#20013;&#30340;&#30693;&#35782;&#20256;&#36755;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#27809;&#26377;&#20808;&#39564;&#30693;&#35782;&#30340;&#20219;&#21153;&#30456;&#20284;&#24615;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#24378;&#22823;&#30340;&#30693;&#35782;&#20256;&#36755;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23618;&#32423;&#22686;&#24378;&#23398;&#20064;&#35774;&#32622;&#65292;&#36825;&#26159;&#19968;&#20010;&#24182;&#34892;&#20256;&#36755;&#23398;&#20064;&#26694;&#26550;&#65292;&#22312;&#36825;&#20010;&#26694;&#26550;&#20013;&#65292;&#30446;&#26631;&#26159;&#23558;&#30693;&#35782;&#20174;&#20302;&#23618;&#65288;&#28304;&#65289;&#20219;&#21153;&#20256;&#36755;&#21040;&#39640;&#23618;&#65288;&#30446;&#26631;&#65289;&#20219;&#21153;&#65292;&#20197;&#20943;&#23569;&#21518;&#32773;&#30340;&#25506;&#32034;&#39118;&#38505;&#65292;&#21516;&#26102;&#24182;&#34892;&#35299;&#20915;&#36825;&#20004;&#20010;&#20219;&#21153;&#12290;&#19982;&#20808;&#21069;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#25105;&#20204;&#19981;&#20551;&#35774;&#20302;&#23618;&#21644;&#39640;&#23618;&#20219;&#21153;&#20849;&#20139;&#30456;&#21516;&#30340;&#21160;&#24577;&#25110;&#22870;&#21169;&#20989;&#25968;&#65292;&#24182;&#19988;&#19987;&#27880;&#20110;&#22312;&#27809;&#26377;&#20808;&#39564;&#30693;&#35782;&#30340;&#20219;&#21153;&#30456;&#20284;&#24615;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#24378;&#22823;&#30340;&#30693;&#35782;&#20256;&#36755;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#19968;&#20010;&#31216;&#20026;&#8220;&#26368;&#20248;&#20540;&#25903;&#37197;&#8221;&#30340;&#33258;&#28982;&#32780;&#24517;&#35201;&#30340;&#26465;&#20214;&#65292;&#36866;&#29992;&#20110;&#25105;&#20204;&#30340;&#30446;&#26631;&#12290;&#22312;&#36825;&#20010;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#20351;&#24471;&#23545;&#20110;&#39640;&#23618;&#20219;&#21153;&#65292;&#22312;&#37096;&#20998;&#29366;&#24577;&#19978;&#21487;&#20197;&#23454;&#29616;&#24658;&#23450;&#30340;&#36951;&#25022;&#65292;&#36825;&#21462;&#20915;&#20110;&#20219;&#21153;&#30456;&#20284;&#24615;&#65292;&#24182;&#22312;&#20004;&#20010;&#20219;&#21153;&#19981;&#30456;&#20284;&#26102;&#20445;&#25345;&#25509;&#36817;&#26368;&#20248;&#36951;&#25022;&#65307;&#32780;&#23545;&#20110;&#20302;&#23618;&#20219;&#21153;&#65292;&#23427;&#21487;&#20197;&#22312;&#19981;&#20570;&#20986;&#29306;&#29298;&#30340;&#24773;&#20917;&#19979;&#20445;&#25345;&#25509;&#36817;&#26368;&#20248;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#30740;&#31350;&#20102;&#20855;&#26377;&#22810;&#20010;&#20302;&#23618;&#20219;&#21153;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the Tiered Reinforcement Learning setting, a parallel transfer learning framework, where the goal is to transfer knowledge from the low-tier (source) task to the high-tier (target) task to reduce the exploration risk of the latter while solving the two tasks in parallel. Unlike previous work, we do not assume the low-tier and high-tier tasks share the same dynamics or reward functions, and focus on robust knowledge transfer without prior knowledge on the task similarity. We identify a natural and necessary condition called the ``Optimal Value Dominance'' for our objective. Under this condition, we propose novel online learning algorithms such that, for the high-tier task, it can achieve constant regret on partial states depending on the task similarity and retain near-optimal regret when the two tasks are dissimilar, while for the low-tier task, it can keep near-optimal without making sacrifice. Moreover, we further study the setting with multiple low-tier tasks
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#31070;&#32463;&#32593;&#32476;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#36924;&#36817;&#36830;&#32493;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#24182;&#23545;&#29702;&#35770;&#19982;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#36827;&#34892;&#20102;&#32553;&#23567;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;Johnson-Lindenstrauss&#23884;&#20837;&#30340;&#35266;&#23519;&#65292;&#36890;&#36807;&#23558;&#39640;&#32500;&#38598;&#21512;&#23884;&#20837;&#21040;&#20302;&#32500;&#31354;&#38388;&#20013;&#65292;&#20351;&#24471;&#36739;&#23567;&#30340;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#26377;&#25928;&#36924;&#36817;&#39640;&#32500;&#36830;&#32493;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2208.13305</link><description>&lt;p&gt;
&#22312;&#39640;&#32500;&#24230;&#20013;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#36830;&#32493;&#20989;&#25968;&#65292;&#24182;&#24212;&#29992;&#20110;&#36870;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Neural Network Approximation of Continuous Functions in High Dimensions with Applications to Inverse Problems. (arXiv:2208.13305v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.13305
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#31070;&#32463;&#32593;&#32476;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#36924;&#36817;&#36830;&#32493;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#24182;&#23545;&#29702;&#35770;&#19982;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#36827;&#34892;&#20102;&#32553;&#23567;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;Johnson-Lindenstrauss&#23884;&#20837;&#30340;&#35266;&#23519;&#65292;&#36890;&#36807;&#23558;&#39640;&#32500;&#38598;&#21512;&#23884;&#20837;&#21040;&#20302;&#32500;&#31354;&#38388;&#20013;&#65292;&#20351;&#24471;&#36739;&#23567;&#30340;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#26377;&#25928;&#36924;&#36817;&#39640;&#32500;&#36830;&#32493;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#20013;&#65292;&#31070;&#32463;&#32593;&#32476;&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#30340;&#36870;&#38382;&#39064;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#36825;&#25512;&#21160;&#20102;&#23427;&#20204;&#22312;&#21307;&#23398;&#24433;&#20687;&#21040;&#22320;&#38663;&#20998;&#26512;&#31561;&#39046;&#22495;&#30340;&#37319;&#29992;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#36870;&#38382;&#39064;&#30340;&#39640;&#32500;&#24230;&#20351;&#24471;&#29616;&#26377;&#29702;&#35770;&#26080;&#27861;&#35299;&#37322;&#22312;&#23454;&#36341;&#20013;&#20026;&#20160;&#20040;&#20351;&#29992;&#30475;&#20284;&#36739;&#23567;&#30340;&#32593;&#32476;&#20063;&#33021;&#24471;&#21040;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;&#20026;&#20102;&#32553;&#23567;&#29702;&#35770;&#19982;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#26041;&#27861;&#26469;&#30028;&#23450;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#39640;&#32500;&#38598;&#21512;&#19978;&#30340;H\"older&#65288;&#25110;&#22343;&#21248;&#65289;&#36830;&#32493;&#20989;&#25968;&#25152;&#38656;&#30340;&#22797;&#26434;&#24230;&#12290;&#36825;&#31181;&#26041;&#27861;&#22522;&#20110;&#19968;&#20010;&#35266;&#23519;&#65306;&#32473;&#23450;&#19968;&#20010;&#39640;&#32500;&#38598;&#21512;$S\subset\mathbb{R}^D$&#65292;&#22914;&#26524;&#23384;&#22312;&#19968;&#20010;Johnson-Lindenstrauss&#23884;&#20837;$A\in\mathbb{R}^{d\times D}$&#65292;&#20854;&#20013;$d$&#36739;&#23567;&#65292;&#23558;$S$&#23884;&#20837;&#21040;&#19968;&#20010;&#20302;&#32500;&#31435;&#26041;&#20307;$[-M,M]^d$&#20013;&#65292;&#37027;&#20040;&#23545;&#20110;&#20219;&#20309;H\"o
&lt;/p&gt;
&lt;p&gt;
The remarkable successes of neural networks in a huge variety of inverse problems have fueled their adoption in disciplines ranging from medical imaging to seismic analysis over the past decade. However, the high dimensionality of such inverse problems has simultaneously left current theory, which predicts that networks should scale exponentially in the dimension of the problem, unable to explain why the seemingly small networks used in these settings work as well as they do in practice. To reduce this gap between theory and practice, we provide a general method for bounding the complexity required for a neural network to approximate a H\"older (or uniformly) continuous function defined on a high-dimensional set with a low-complexity structure. The approach is based on the observation that the existence of a Johnson-Lindenstrauss embedding $A\in\mathbb{R}^{d\times D}$ of a given high-dimensional set $S\subset\mathbb{R}^D$ into a low dimensional cube $[-M,M]^d$ implies that for any H\"o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#23398;&#20064;&#20013;&#30340;&#21452;&#19979;&#38477;&#29616;&#35937;&#65292;&#24182;&#22312;&#22810;&#32452;&#20998;&#39044;&#27979;&#27169;&#22411;&#20013;&#36827;&#19968;&#27493;&#25506;&#31350;&#20102;&#22810;&#27425;&#19979;&#38477;&#29616;&#35937;&#12290;&#36890;&#36807;&#29702;&#35770;&#35745;&#31639;&#21644;&#23454;&#39564;&#35777;&#23454;&#65292;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#30340;&#39118;&#38505;&#26354;&#32447;&#21487;&#20197;&#21576;&#29616;&#20986;&#19977;&#27425;&#19979;&#38477;&#12290;</title><link>http://arxiv.org/abs/2208.09897</link><description>&lt;p&gt;
&#22810;&#20010;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#20013;&#30340;&#22810;&#27425;&#19979;&#38477;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
Multiple Descent in the Multiple Random Feature Model. (arXiv:2208.09897v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.09897
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#23398;&#20064;&#20013;&#30340;&#21452;&#19979;&#38477;&#29616;&#35937;&#65292;&#24182;&#22312;&#22810;&#32452;&#20998;&#39044;&#27979;&#27169;&#22411;&#20013;&#36827;&#19968;&#27493;&#25506;&#31350;&#20102;&#22810;&#27425;&#19979;&#38477;&#29616;&#35937;&#12290;&#36890;&#36807;&#29702;&#35770;&#35745;&#31639;&#21644;&#23454;&#39564;&#35777;&#23454;&#65292;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#30340;&#39118;&#38505;&#26354;&#32447;&#21487;&#20197;&#21576;&#29616;&#20986;&#19977;&#27425;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#36807;&#24230;&#21442;&#25968;&#21270;&#23398;&#20064;&#20013;&#23384;&#22312;&#21452;&#19979;&#38477;&#29616;&#35937;&#12290;&#23613;&#31649;&#36825;&#19968;&#29616;&#35937;&#24050;&#32463;&#24471;&#21040;&#20102;&#30740;&#31350;&#65292;&#20294;&#22312;&#29702;&#35770;&#19978;&#23578;&#26410;&#23436;&#20840;&#29702;&#35299;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#32452;&#20998;&#39044;&#27979;&#27169;&#22411;&#20013;&#30340;&#22810;&#27425;&#19979;&#38477;&#29616;&#35937;&#12290;&#39318;&#20808;&#32771;&#34385;&#19968;&#20010;&#8220;&#21452;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#8221; (DRFM)&#65292;&#23427;&#36830;&#25509;&#20102;&#20004;&#31181;&#31867;&#22411;&#30340;&#38543;&#26426;&#29305;&#24449;&#65292;&#24182;&#30740;&#31350;&#20102;DRFM&#22312;&#23725;&#22238;&#24402;&#20013;&#23454;&#29616;&#30340;&#36807;&#24230;&#39118;&#38505;&#12290;&#25105;&#20204;&#35745;&#31639;&#20102;&#39640;&#32500;&#26694;&#26550;&#19979;&#65292;&#24403;&#35757;&#32451;&#26679;&#26412;&#37327;&#12289;&#25968;&#25454;&#32500;&#24230;&#21644;&#38543;&#26426;&#29305;&#24449;&#32500;&#24230;&#36235;&#21521;&#20110;&#26080;&#31351;&#22823;&#26102;&#65292;&#36807;&#24230;&#39118;&#38505;&#30340;&#31934;&#30830;&#26497;&#38480;&#12290;&#22522;&#20110;&#36825;&#20010;&#35745;&#31639;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;DRFM&#30340;&#39118;&#38505;&#26354;&#32447;&#21487;&#33021;&#21576;&#29616;&#20986;&#19977;&#27425;&#19979;&#38477;&#12290;&#28982;&#21518;&#25105;&#20204;&#36827;&#34892;&#20102;&#28145;&#20837;&#30340;&#23454;&#39564;&#30740;&#31350;&#65292;&#20197;&#39564;&#35777;&#25105;&#20204;&#30340;&#29702;&#35770;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#30740;&#31350;&#25193;&#23637;&#21040;&#8220;&#22810;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#8221; (MRFM)&#65292;&#24182;&#23637;&#31034;&#20102;MRFMs&#38598;&#25104;K&#31181;&#31867;&#22411;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent works have demonstrated a double descent phenomenon in over-parameterized learning. Although this phenomenon has been investigated by recent works, it has not been fully understood in theory. In this paper, we investigate the multiple descent phenomenon in a class of multi-component prediction models. We first consider a ''double random feature model'' (DRFM) concatenating two types of random features, and study the excess risk achieved by the DRFM in ridge regression. We calculate the precise limit of the excess risk under the high dimensional framework where the training sample size, the dimension of data, and the dimension of random features tend to infinity proportionally. Based on the calculation, we further theoretically demonstrate that the risk curves of DRFMs can exhibit triple descent. We then provide a thorough experimental study to verify our theory. At last, we extend our study to the ''multiple random feature model'' (MRFM), and show that MRFMs ensembling $K$ types
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#23545;&#25239;&#29615;&#22659;&#20013;&#65292;&#20351;&#29992;&#23545;&#25968;&#27744;&#21270;&#26041;&#27861;&#23398;&#20064;&#19987;&#23478;&#26435;&#37325;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#20197;&#36798;&#21040;&#26080;&#36951;&#25022;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2202.11219</link><description>&lt;p&gt;
&#26080;&#36951;&#25022;&#23398;&#20064;&#19982;&#26080;&#30028;&#25439;&#22833;&#65306;&#23545;&#25968;&#27744;&#21270;&#30340;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
No-Regret Learning with Unbounded Losses: The Case of Logarithmic Pooling. (arXiv:2202.11219v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.11219
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#23545;&#25239;&#29615;&#22659;&#20013;&#65292;&#20351;&#29992;&#23545;&#25968;&#27744;&#21270;&#26041;&#27861;&#23398;&#20064;&#19987;&#23478;&#26435;&#37325;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#20197;&#36798;&#21040;&#26080;&#36951;&#25022;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#38271;$T$&#20013;&#65292;$m$&#20010;&#19987;&#23478;&#25253;&#21578;&#20102;&#20851;&#20110;$n$&#20010;&#32467;&#26524;&#30340;&#27010;&#29575;&#20998;&#24067;&#65307;&#25105;&#20204;&#24076;&#26395;&#23398;&#20064;&#19968;&#31181;&#32858;&#21512;&#36825;&#20123;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#20197;&#36798;&#21040;&#26080;&#36951;&#25022;&#20445;&#35777;&#12290;&#25105;&#20204;&#20851;&#27880;&#19968;&#31181;&#34987;&#31216;&#20026;&#23545;&#25968;&#27744;&#21270;&#30340;&#22522;&#26412;&#21644;&#23454;&#29992;&#30340;&#32858;&#21512;&#26041;&#27861;&#8212;&#8212;log odds &#30340;&#21152;&#26435;&#24179;&#22343;&#65292;&#23427;&#22312;&#26576;&#31181;&#24847;&#20041;&#19978;&#26159;&#19968;&#31181;&#26368;&#20248;&#30340;&#27744;&#21270;&#26041;&#27861;&#36873;&#25321;&#65292;&#22914;&#26524;&#25105;&#20204;&#24076;&#26395;&#26368;&#23567;&#21270; log &#25439;&#22833;&#65288;&#20316;&#20026;&#25105;&#20204;&#30340;&#25439;&#22833;&#20989;&#25968;&#65289;&#12290;&#25105;&#20204;&#32771;&#34385;&#22312;&#32447;&#23545;&#25239;&#29615;&#22659;&#20013;&#23398;&#20064;&#26368;&#20339;&#21442;&#25968;&#38598;&#65288;&#21363;&#19987;&#23478;&#26435;&#37325;&#65289;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#20551;&#35774;&#65288;&#24517;&#35201;&#26465;&#20214;&#19979;&#65289;&#65292;&#23545;&#25239;&#36873;&#25321;&#30340;&#32467;&#26524;&#21644;&#39044;&#27979;&#26159;&#19968;&#33268;&#30340;&#65292;&#20063;&#23601;&#26159;&#35828;&#19987;&#23478;&#25253;&#21578;&#20102;&#32463;&#36807;&#26657;&#20934;&#30340;&#39044;&#27979;&#12290;&#26045;&#21152;&#36825;&#20010;&#32422;&#26463;&#26465;&#20214;&#21019;&#24314;&#20102;&#19968;&#20010;&#65288;&#25454;&#25105;&#20204;&#25152;&#30693;&#65289;&#26032;&#39062;&#30340;&#21322;&#23545;&#25239;&#35774;&#32622;&#65292;&#20854;&#20013;&#23545;&#25163;&#20445;&#30041;&#20102;&#22823;&#37327;&#30340;&#28789;&#27963;&#24615;&#12290;&#22312;&#36825;&#20010;&#35774;&#32622;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#30340;&#31639;&#27861;&#65292;&#20197;&#19968;&#31181;&#23398;&#20064;&#19987;&#23478;&#26435;&#37325;&#30340;&#26041;&#24335;&#65292;&#23454;&#29616;&#20102;$O(\s
&lt;/p&gt;
&lt;p&gt;
For each of $T$ time steps, $m$ experts report probability distributions over $n$ outcomes; we wish to learn to aggregate these forecasts in a way that attains a no-regret guarantee. We focus on the fundamental and practical aggregation method known as logarithmic pooling -- a weighted average of log odds -- which is in a certain sense the optimal choice of pooling method if one is interested in minimizing log loss (as we take to be our loss function). We consider the problem of learning the best set of parameters (i.e. expert weights) in an online adversarial setting. We assume (by necessity) that the adversarial choices of outcomes and forecasts are consistent, in the sense that experts report calibrated forecasts. Imposing this constraint creates a (to our knowledge) novel semi-adversarial setting in which the adversary retains a large amount of flexibility. In this setting, we present an algorithm based on online mirror descent that learns expert weights in a way that attains $O(\s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#20849;&#35782;&#20998;&#25955;&#21152;&#36895;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#26368;&#20248;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;&#25509;&#36817;&#26368;&#20248;&#30340;&#36890;&#20449;&#22797;&#26434;&#24230;&#12290;&#31639;&#27861;&#30340;&#32447;&#24615;&#25910;&#25947;&#20165;&#21462;&#20915;&#20110;&#20840;&#23616;&#30446;&#26631;&#30340;&#24378;&#20984;&#24615;&#65292;&#24182;&#19981;&#35201;&#27714;&#23616;&#37096;&#20989;&#25968;&#26159;&#20984;&#20989;&#25968;&#12290;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#36229;&#36234;&#20854;&#20182;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2005.00797</link><description>&lt;p&gt;
&#22810;&#20849;&#35782;&#20998;&#25955;&#21152;&#36895;&#26799;&#24230;&#19979;&#38477;
&lt;/p&gt;
&lt;p&gt;
Multi-consensus Decentralized Accelerated Gradient Descent. (arXiv:2005.00797v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2005.00797
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#20849;&#35782;&#20998;&#25955;&#21152;&#36895;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#26368;&#20248;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;&#25509;&#36817;&#26368;&#20248;&#30340;&#36890;&#20449;&#22797;&#26434;&#24230;&#12290;&#31639;&#27861;&#30340;&#32447;&#24615;&#25910;&#25947;&#20165;&#21462;&#20915;&#20110;&#20840;&#23616;&#30446;&#26631;&#30340;&#24378;&#20984;&#24615;&#65292;&#24182;&#19981;&#35201;&#27714;&#23616;&#37096;&#20989;&#25968;&#26159;&#20984;&#20989;&#25968;&#12290;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#36229;&#36234;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#20998;&#25955;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#22312;&#22823;&#35268;&#27169;&#26426;&#22120;&#23398;&#20064;&#12289;&#20256;&#24863;&#22120;&#32593;&#32476;&#21644;&#25511;&#21046;&#29702;&#35770;&#31561;&#39046;&#22495;&#26377;&#24191;&#27867;&#24212;&#29992;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#26368;&#20248;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;&#25509;&#36817;&#26368;&#20248;&#30340;&#36890;&#20449;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#23545;&#20110;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#32473;&#20986;&#20102;&#32943;&#23450;&#30340;&#31572;&#26696;&#65292;&#21363;&#26159;&#21542;&#23384;&#22312;&#19968;&#31181;&#31639;&#27861;&#21487;&#20197;&#23454;&#29616;&#19982;&#20840;&#23616;&#26465;&#20214;&#25968;&#30456;&#20851;&#32780;&#19981;&#26159;&#23616;&#37096;&#26465;&#20214;&#25968;&#30456;&#20851;&#30340;&#36890;&#20449;&#22797;&#26434;&#24230;&#30340;(lower bound)&#30456;&#21305;&#37197;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#30340;&#32447;&#24615;&#25910;&#25947;&#20165;&#21462;&#20915;&#20110;&#20840;&#23616;&#30446;&#26631;&#30340;&#24378;&#20984;&#24615;&#65292;&#24182;&#19981;&#35201;&#27714;&#23616;&#37096;&#20989;&#25968;&#26159;&#20984;&#20989;&#25968;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#35774;&#35745;&#20381;&#36182;&#20110;Nesterov &#21152;&#36895;&#12289;&#22810;&#20849;&#35782;&#21644;&#26799;&#24230;&#36861;&#36394;&#31561;&#20247;&#25152;&#21608;&#30693;&#30340;&#25216;&#26415;&#30340;&#21019;&#26032;&#25972;&#21512;&#12290;&#23454;&#35777;&#30740;&#31350;&#26174;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper considers the decentralized convex optimization problem, which has a wide range of applications in large-scale machine learning, sensor networks, and control theory. We propose novel algorithms that achieve optimal computation complexity and near optimal communication complexity. Our theoretical results give affirmative answers to the open problem on whether there exists an algorithm that can achieve a communication complexity (nearly) matching the lower bound depending on the global condition number instead of the local one. Furthermore, the linear convergence of our algorithms only depends on the strong convexity of global objective and it does \emph{not} require the local functions to be convex. The design of our methods relies on a novel integration of well-known techniques including Nesterov's acceleration, multi-consensus and gradient-tracking. Empirical studies show the outperformance of our methods for machine learning applications.
&lt;/p&gt;</description></item></channel></rss>