<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#20351;&#29992;&#33258;&#21160;&#32534;&#30721;&#22120;&#21644;&#25193;&#25955;&#27169;&#22411;&#32467;&#21512;&#30340;AutoDiff&#27169;&#22411;&#21487;&#20197;&#26377;&#25928;&#22320;&#29983;&#25104;&#21512;&#25104;&#30340;&#34920;&#26684;&#25968;&#25454;&#65292;&#20811;&#26381;&#20102;&#34920;&#26684;&#25968;&#25454;&#20013;&#30340;&#24322;&#26500;&#29305;&#24449;&#21644;&#29305;&#24449;&#38388;&#30456;&#20851;&#24615;&#30340;&#25361;&#25112;&#65292;&#29983;&#25104;&#30340;&#25968;&#25454;&#19982;&#30495;&#23454;&#25968;&#25454;&#22312;&#32479;&#35745;&#19978;&#38750;&#24120;&#30456;&#20284;&#65292;&#24182;&#22312;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>http://arxiv.org/abs/2310.15479</link><description>&lt;p&gt;
AutoDiff:&#32467;&#21512;&#33258;&#21160;&#32534;&#30721;&#22120;&#21644;&#25193;&#25955;&#27169;&#22411;&#29992;&#20110;&#34920;&#26684;&#25968;&#25454;&#21512;&#25104;
&lt;/p&gt;
&lt;p&gt;
AutoDiff: combining Auto-encoder and Diffusion model for tabular data synthesizing. (arXiv:2310.15479v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15479
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#33258;&#21160;&#32534;&#30721;&#22120;&#21644;&#25193;&#25955;&#27169;&#22411;&#32467;&#21512;&#30340;AutoDiff&#27169;&#22411;&#21487;&#20197;&#26377;&#25928;&#22320;&#29983;&#25104;&#21512;&#25104;&#30340;&#34920;&#26684;&#25968;&#25454;&#65292;&#20811;&#26381;&#20102;&#34920;&#26684;&#25968;&#25454;&#20013;&#30340;&#24322;&#26500;&#29305;&#24449;&#21644;&#29305;&#24449;&#38388;&#30456;&#20851;&#24615;&#30340;&#25361;&#25112;&#65292;&#29983;&#25104;&#30340;&#25968;&#25454;&#19982;&#30495;&#23454;&#25968;&#25454;&#22312;&#32479;&#35745;&#19978;&#38750;&#24120;&#30456;&#20284;&#65292;&#24182;&#22312;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#24050;&#25104;&#20026;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#35768;&#22810;&#23376;&#39046;&#22495;&#20013;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#30340;&#20027;&#35201;&#33539;&#24335;&#65292;&#21253;&#25324;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#35821;&#35328;&#27169;&#22411;&#25110;&#35821;&#38899;&#21512;&#25104;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#25193;&#25955;&#27169;&#22411;&#30340;&#21147;&#37327;&#26469;&#29983;&#25104;&#21512;&#25104;&#30340;&#34920;&#26684;&#25968;&#25454;&#12290;&#34920;&#26684;&#25968;&#25454;&#20013;&#30340;&#24322;&#26500;&#29305;&#24449;&#19968;&#30452;&#26159;&#34920;&#26684;&#25968;&#25454;&#21512;&#25104;&#30340;&#20027;&#35201;&#38556;&#30861;&#65292;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#26550;&#26500;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#19982;&#26368;&#20808;&#36827;&#30340;&#34920;&#26684;&#21512;&#25104;&#22120;&#30456;&#27604;&#65292;&#25105;&#20204;&#27169;&#22411;&#29983;&#25104;&#30340;&#21512;&#25104;&#34920;&#26684;&#22312;&#32479;&#35745;&#19978;&#19982;&#30495;&#23454;&#25968;&#25454;&#38750;&#24120;&#30456;&#20284;&#65292;&#24182;&#22312;&#26426;&#22120;&#23398;&#20064;&#24037;&#20855;&#30340;&#19979;&#28216;&#20219;&#21153;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;&#25105;&#20204;&#22312;15&#20010;&#20844;&#24320;&#21487;&#29992;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#28789;&#27963;&#22320;&#25429;&#25417;&#20102;&#29305;&#24449;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#36825;&#26159;&#34920;&#26684;&#25968;&#25454;&#21512;&#25104;&#20013;&#38271;&#26399;&#23384;&#22312;&#30340;&#25361;&#25112;&#12290;&#22914;&#33509;&#25509;&#32435;&#20102;&#35770;&#25991;&#65292;&#25105;&#20204;&#30340;&#20195;&#30721;&#23558;&#26681;&#25454;&#35201;&#27714;&#25552;&#20379;&#65292;&#24182;&#19988;&#23558;&#20844;&#24320;&#21457;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion model has become a main paradigm for synthetic data generation in many subfields of modern machine learning, including computer vision, language model, or speech synthesis. In this paper, we leverage the power of diffusion model for generating synthetic tabular data. The heterogeneous features in tabular data have been main obstacles in tabular data synthesis, and we tackle this problem by employing the auto-encoder architecture. When compared with the state-of-the-art tabular synthesizers, the resulting synthetic tables from our model show nice statistical fidelities to the real data, and perform well in downstream tasks for machine learning utilities. We conducted the experiments over 15 publicly available datasets. Notably, our model adeptly captures the correlations among features, which has been a long-standing challenge in tabular data synthesis. Our code is available upon request and will be publicly released if paper is accepted.
&lt;/p&gt;</description></item><item><title>&#38024;&#23545;&#39640;&#32500;&#24230;&#20302;&#26679;&#26412;(HDLSS)&#20998;&#31867;&#38382;&#39064;&#65292;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#26862;&#26519;&#30456;&#20284;&#24230;&#30340;&#23398;&#20064;&#39044;&#35745;&#31639;SVM&#26680;&#26041;&#27861;(RFSVM)&#65292;&#36890;&#36807;&#22312;40&#20010;&#20844;&#20849;HDLSS&#20998;&#31867;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;HDLSS&#38382;&#39064;&#19978;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#24182;&#19988;&#20445;&#25345;&#20102;&#38750;&#24120;&#19968;&#33268;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.14710</link><description>&lt;p&gt;
&#39640;&#32500;&#24230;&#20302;&#26679;&#26412;&#20998;&#31867;&#30340;&#38543;&#26426;&#26862;&#26519;&#24046;&#24322;&#24615;
&lt;/p&gt;
&lt;p&gt;
Random Forest Dissimilarity for High-Dimension Low Sample Size Classification. (arXiv:2310.14710v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14710
&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#39640;&#32500;&#24230;&#20302;&#26679;&#26412;(HDLSS)&#20998;&#31867;&#38382;&#39064;&#65292;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#26862;&#26519;&#30456;&#20284;&#24230;&#30340;&#23398;&#20064;&#39044;&#35745;&#31639;SVM&#26680;&#26041;&#27861;(RFSVM)&#65292;&#36890;&#36807;&#22312;40&#20010;&#20844;&#20849;HDLSS&#20998;&#31867;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;HDLSS&#38382;&#39064;&#19978;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#24182;&#19988;&#20445;&#25345;&#20102;&#38750;&#24120;&#19968;&#33268;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#24230;&#20302;&#26679;&#26412;(HDLSS)&#38382;&#39064;&#22312;&#26426;&#22120;&#23398;&#20064;&#30340;&#23454;&#38469;&#24212;&#29992;&#20013;&#24456;&#24120;&#35265;&#12290;&#20174;&#21307;&#23398;&#24433;&#20687;&#21040;&#25991;&#26412;&#22788;&#29702;&#65292;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#36890;&#24120;&#26080;&#27861;&#20174;&#36825;&#26679;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#21040;&#26368;&#20339;&#30340;&#27010;&#24565;&#12290;&#25105;&#20204;&#22312;&#20043;&#21069;&#30340;&#24037;&#20316;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24046;&#24322;&#24615;&#30340;&#22810;&#35270;&#35282;&#20998;&#31867;&#26041;&#27861;&#65292;&#21363;&#38543;&#26426;&#26862;&#26519;&#24046;&#24322;&#24615;(RFD)&#65292;&#35813;&#26041;&#27861;&#22312;&#36825;&#31867;&#38382;&#39064;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23558;&#35813;&#26041;&#27861;&#30340;&#26680;&#24515;&#21407;&#21017;&#36716;&#21270;&#20026;&#35299;&#20915;HDLSS&#20998;&#31867;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#26862;&#26519;&#30456;&#20284;&#24230;&#20316;&#20026;&#23398;&#20064;&#30340;&#39044;&#35745;&#31639;SVM&#26680;(RFSVM)&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#26679;&#30340;&#23398;&#20064;&#30456;&#20284;&#24230;&#24230;&#37327;&#22312;&#36825;&#31181;&#20998;&#31867;&#19978;&#29305;&#21035;&#36866;&#29992;&#21644;&#20934;&#30830;&#12290;&#36890;&#36807;&#23545;40&#20010;&#20844;&#20849;HDLSS&#20998;&#31867;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#23454;&#39564;&#65292;&#37197;&#21512;&#20005;&#26684;&#30340;&#32479;&#35745;&#20998;&#26512;&#65292;&#32467;&#26524;&#26174;&#31034;RFSVM&#26041;&#27861;&#22312;&#22823;&#22810;&#25968;HDLSS&#38382;&#39064;&#19978;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#24182;&#19988;&#21516;&#26102;&#38750;&#24120;&#36830;&#36143;&#12290;
&lt;/p&gt;
&lt;p&gt;
High dimension, low sample size (HDLSS) problems are numerous among real-world applications of machine learning. From medical images to text processing, traditional machine learning algorithms are usually unsuccessful in learning the best possible concept from such data. In a previous work, we proposed a dissimilarity-based approach for multi-view classification, the Random Forest Dissimilarity (RFD), that perfoms state-of-the-art results for such problems. In this work, we transpose the core principle of this approach to solving HDLSS classification problems, by using the RF similarity measure as a learned precomputed SVM kernel (RFSVM). We show that such a learned similarity measure is particularly suited and accurate for this classification context. Experiments conducted on 40 public HDLSS classification datasets, supported by rigorous statistical analyses, show that the RFSVM method outperforms existing methods for the majority of HDLSS problems and remains at the same time very co
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#29983;&#25104;&#25193;&#25955;&#27169;&#22411;&#35299;&#37322;&#20026;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#65292;&#35777;&#26126;&#20854;&#22312;&#35757;&#32451;&#31163;&#25955;&#27169;&#24335;&#26102;&#19982;&#29616;&#20195;Hopfield&#32593;&#32476;&#30340;&#33021;&#37327;&#20989;&#25968;&#31561;&#25928;&#12290;&#36825;&#31181;&#31561;&#25928;&#24615;&#20351;&#24471;&#25105;&#20204;&#21487;&#20197;&#23558;&#25193;&#25955;&#27169;&#22411;&#30340;&#26377;&#30417;&#30563;&#35757;&#32451;&#35299;&#37322;&#20026;&#22312;&#26435;&#37325;&#32467;&#26500;&#20013;&#32534;&#30721;&#29616;&#20195;Hopfield&#32593;&#32476;&#30340;&#20851;&#32852;&#21160;&#21147;&#23398;&#30340;&#31361;&#35302;&#23398;&#20064;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2309.17290</link><description>&lt;p&gt;
&#25628;&#32034;&#20998;&#25955;&#30340;&#35760;&#24518;&#65306;&#29983;&#25104;&#25193;&#25955;&#27169;&#22411;&#26159;&#20851;&#32852;&#35760;&#24518;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
In search of dispersed memories: Generative diffusion models are associative memory networks. (arXiv:2309.17290v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.17290
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#29983;&#25104;&#25193;&#25955;&#27169;&#22411;&#35299;&#37322;&#20026;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#65292;&#35777;&#26126;&#20854;&#22312;&#35757;&#32451;&#31163;&#25955;&#27169;&#24335;&#26102;&#19982;&#29616;&#20195;Hopfield&#32593;&#32476;&#30340;&#33021;&#37327;&#20989;&#25968;&#31561;&#25928;&#12290;&#36825;&#31181;&#31561;&#25928;&#24615;&#20351;&#24471;&#25105;&#20204;&#21487;&#20197;&#23558;&#25193;&#25955;&#27169;&#22411;&#30340;&#26377;&#30417;&#30563;&#35757;&#32451;&#35299;&#37322;&#20026;&#22312;&#26435;&#37325;&#32467;&#26500;&#20013;&#32534;&#30721;&#29616;&#20195;Hopfield&#32593;&#32476;&#30340;&#20851;&#32852;&#21160;&#21147;&#23398;&#30340;&#31361;&#35302;&#23398;&#20064;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Hopfield&#32593;&#32476;&#34987;&#24191;&#27867;&#29992;&#20316;&#31070;&#32463;&#31185;&#23398;&#20013;&#30340;&#31616;&#21270;&#29702;&#35770;&#27169;&#22411;&#65292;&#29992;&#20110;&#29983;&#29289;&#20851;&#32852;&#35760;&#24518;&#12290;&#21407;&#22987;&#30340;Hopfield&#32593;&#32476;&#36890;&#36807;&#32534;&#30721;&#20108;&#20803;&#20851;&#32852;&#27169;&#24335;&#26469;&#23384;&#20648;&#35760;&#24518;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#19968;&#31181;&#31216;&#20026;Hebbian&#23398;&#20064;&#35268;&#21017;&#30340;&#31361;&#35302;&#23398;&#20064;&#26426;&#21046;&#12290;&#29616;&#20195;&#30340;Hopfield&#32593;&#32476;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#33021;&#37327;&#20989;&#25968;&#26469;&#23454;&#29616;&#25351;&#25968;&#32423;&#23481;&#37327;&#25193;&#23637;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26032;&#27169;&#22411;&#30340;&#33021;&#37327;&#20989;&#25968;&#19981;&#33021;&#30452;&#25509;&#21387;&#32553;&#20026;&#20108;&#20803;&#31361;&#35302;&#32806;&#21512;&#65292;&#24182;&#19988;&#20063;&#19981;&#33021;&#30452;&#25509;&#25552;&#20379;&#26032;&#30340;&#31361;&#35302;&#23398;&#20064;&#35268;&#21017;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#29983;&#25104;&#25193;&#25955;&#27169;&#22411;&#21487;&#20197;&#34987;&#35299;&#37322;&#20026;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#65292;&#24182;&#19988;&#22312;&#35757;&#32451;&#31163;&#25955;&#27169;&#24335;&#26102;&#65292;&#23427;&#20204;&#30340;&#33021;&#37327;&#20989;&#25968;&#19982;&#29616;&#20195;&#30340;Hopfield&#32593;&#32476;&#30456;&#31561;&#12290;&#36825;&#31181;&#31561;&#20215;&#24615;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#25193;&#25955;&#27169;&#22411;&#30340;&#26377;&#30417;&#30563;&#35757;&#32451;&#35299;&#37322;&#20026;&#22312;&#26435;&#37325;&#32467;&#26500;&#20013;&#32534;&#30721;&#29616;&#20195;Hopfield&#32593;&#32476;&#30340;&#20851;&#32852;&#21160;&#21147;&#23398;&#30340;&#31361;&#35302;&#23398;&#20064;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hopfield networks are widely used in neuroscience as simplified theoretical models of biological associative memory. The original Hopfield networks store memories by encoding patterns of binary associations, which result in a synaptic learning mechanism known as Hebbian learning rule. Modern Hopfield networks can achieve exponential capacity scaling by using highly non-linear energy functions. However, the energy function of these newer models cannot be straightforwardly compressed into binary synaptic couplings and it does not directly provide new synaptic learning rules. In this work we show that generative diffusion models can be interpreted as energy-based models and that, when trained on discrete patterns, their energy function is equivalent to that of modern Hopfield networks. This equivalence allows us to interpret the supervised training of diffusion models as a synaptic learning process that encodes the associative dynamics of a modern Hopfield network in the weight structure 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20851;&#27880;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30340;&#20027;&#21160;&#23545;&#31216;&#24615;&#65292;&#36890;&#36807;&#32771;&#34385;&#20449;&#21495;&#22312;&#22266;&#23450;&#22270;&#19978;&#30340;&#23398;&#20064;&#35774;&#32622;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#30340;&#23545;&#31216;&#24615;&#27010;&#24565;&#65292;&#36890;&#36807;&#22270;&#31895;&#21270;&#23454;&#29616;&#12290;&#36825;&#31687;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#20559;&#24046;-&#26041;&#24046;&#20844;&#24335;&#26469;&#34913;&#37327;&#36817;&#20284;&#23545;&#31216;&#24615;...</title><link>http://arxiv.org/abs/2308.10436</link><description>&lt;p&gt;
&#36817;&#20284;&#31561;&#21464;&#22270;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Approximately Equivariant Graph Networks. (arXiv:2308.10436v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10436
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30340;&#20027;&#21160;&#23545;&#31216;&#24615;&#65292;&#36890;&#36807;&#32771;&#34385;&#20449;&#21495;&#22312;&#22266;&#23450;&#22270;&#19978;&#30340;&#23398;&#20064;&#35774;&#32622;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#30340;&#23545;&#31216;&#24615;&#27010;&#24565;&#65292;&#36890;&#36807;&#22270;&#31895;&#21270;&#23454;&#29616;&#12290;&#36825;&#31687;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#20559;&#24046;-&#26041;&#24046;&#20844;&#24335;&#26469;&#34913;&#37327;&#36817;&#20284;&#23545;&#31216;&#24615;...
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#36890;&#24120;&#34987;&#25551;&#36848;&#20026;&#23545;&#22270;&#20013;&#30340;&#33410;&#28857;&#37325;&#26032;&#25490;&#24207;&#20855;&#26377;&#32622;&#25442;&#31561;&#21464;&#24615;&#12290;GNNs&#30340;&#36825;&#31181;&#23545;&#31216;&#24615;&#24120;&#34987;&#19982;&#27431;&#20960;&#37324;&#24471;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNNs&#65289;&#30340;&#24179;&#31227;&#31561;&#21464;&#24615;&#27604;&#36739;&#12290;&#28982;&#32780;&#65292;&#36825;&#20004;&#31181;&#23545;&#31216;&#24615;&#26412;&#36136;&#19978;&#26159;&#19981;&#21516;&#30340;&#65306;CNNs&#30340;&#24179;&#31227;&#31561;&#21464;&#24615;&#23545;&#24212;&#20110;&#20316;&#29992;&#20110;&#22270;&#20687;&#20449;&#21495;&#30340;&#22266;&#23450;&#22495;&#30340;&#23545;&#31216;&#24615;&#65288;&#26377;&#26102;&#31216;&#20026;&#20027;&#21160;&#23545;&#31216;&#24615;&#65289;&#65292;&#32780;&#22312;GNNs&#20013;&#65292;&#20219;&#20309;&#32622;&#25442;&#37117;&#20316;&#29992;&#20110;&#22270;&#20449;&#21495;&#21644;&#22270;&#22495;&#65288;&#26377;&#26102;&#25551;&#36848;&#20026;&#34987;&#21160;&#23545;&#31216;&#24615;&#65289;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32858;&#28966;&#20110;GNNs&#30340;&#20027;&#21160;&#23545;&#31216;&#24615;&#65292;&#32771;&#34385;&#20449;&#21495;&#22312;&#19968;&#20010;&#22266;&#23450;&#22270;&#19978;&#36827;&#34892;&#23398;&#20064;&#30340;&#24773;&#20917;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;GNNs&#30340;&#33258;&#28982;&#23545;&#31216;&#24615;&#26159;&#22270;&#30340;&#33258;&#21516;&#26500;&#12290;&#30001;&#20110;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#22270;&#24448;&#24448;&#26159;&#38750;&#23545;&#31216;&#30340;&#65292;&#25105;&#20204;&#36890;&#36807;&#24418;&#24335;&#21270;&#22270;&#31895;&#21270;&#26469;&#25918;&#26494;&#23545;&#31216;&#24615;&#30340;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#20559;&#24046;-&#26041;&#24046;&#20844;&#24335;&#26469;&#34913;&#37327;...
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) are commonly described as being permutation equivariant with respect to node relabeling in the graph. This symmetry of GNNs is often compared to the translation equivariance symmetry of Euclidean convolution neural networks (CNNs). However, these two symmetries are fundamentally different: The translation equivariance of CNNs corresponds to symmetries of the fixed domain acting on the image signal (sometimes known as active symmetries), whereas in GNNs any permutation acts on both the graph signals and the graph domain (sometimes described as passive symmetries). In this work, we focus on the active symmetries of GNNs, by considering a learning setting where signals are supported on a fixed graph. In this case, the natural symmetries of GNNs are the automorphisms of the graph. Since real-world graphs tend to be asymmetric, we relax the notion of symmetries by formalizing approximate symmetries via graph coarsening. We present a bias-variance formula that qu
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DCMAP&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#23545;&#20855;&#26377;&#20381;&#36182;&#25104;&#26412;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#36827;&#34892;&#26368;&#20248;&#20998;&#21306;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#20248;&#21270;&#22522;&#20110;DAG&#21644;&#38598;&#32676;&#26144;&#23556;&#30340;&#25104;&#26412;&#20989;&#25968;&#26469;&#23547;&#25214;&#25152;&#26377;&#26368;&#20248;&#38598;&#32676;&#65292;&#24182;&#22312;&#36884;&#20013;&#36820;&#22238;&#25509;&#36817;&#26368;&#20248;&#35299;&#12290;&#23454;&#39564;&#35777;&#26126;&#22312;&#22797;&#26434;&#31995;&#32479;&#30340;DBN&#27169;&#22411;&#20013;&#65292;&#35813;&#31639;&#27861;&#20855;&#26377;&#26102;&#38388;&#25928;&#29575;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.03970</link><description>&lt;p&gt;
&#23545;&#20855;&#26377;&#20381;&#36182;&#25104;&#26412;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#36827;&#34892;&#26368;&#20248;&#20998;&#21306;
&lt;/p&gt;
&lt;p&gt;
Optimal partitioning of directed acyclic graphs with dependent costs between clusters. (arXiv:2308.03970v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03970
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DCMAP&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#23545;&#20855;&#26377;&#20381;&#36182;&#25104;&#26412;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#36827;&#34892;&#26368;&#20248;&#20998;&#21306;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#20248;&#21270;&#22522;&#20110;DAG&#21644;&#38598;&#32676;&#26144;&#23556;&#30340;&#25104;&#26412;&#20989;&#25968;&#26469;&#23547;&#25214;&#25152;&#26377;&#26368;&#20248;&#38598;&#32676;&#65292;&#24182;&#22312;&#36884;&#20013;&#36820;&#22238;&#25509;&#36817;&#26368;&#20248;&#35299;&#12290;&#23454;&#39564;&#35777;&#26126;&#22312;&#22797;&#26434;&#31995;&#32479;&#30340;DBN&#27169;&#22411;&#20013;&#65292;&#35813;&#31639;&#27861;&#20855;&#26377;&#26102;&#38388;&#25928;&#29575;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#32479;&#35745;&#25512;&#26029;&#22330;&#26223;&#65292;&#21253;&#25324;&#36125;&#21494;&#26031;&#32593;&#32476;&#12289;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#21644;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#65292;&#21487;&#20197;&#36890;&#36807;&#23558;&#22522;&#30784;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#21010;&#20998;&#25104;&#38598;&#32676;&#26469;&#25903;&#25345;&#12290;&#28982;&#32780;&#65292;&#22312;&#32479;&#35745;&#25512;&#26029;&#20013;&#65292;&#26368;&#20248;&#21010;&#20998;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#35201;&#20248;&#21270;&#30340;&#25104;&#26412;&#21462;&#20915;&#20110;&#38598;&#32676;&#20869;&#30340;&#33410;&#28857;&#20197;&#21450;&#36890;&#36807;&#29238;&#33410;&#28857;&#21644;/&#25110;&#23376;&#33410;&#28857;&#36830;&#25509;&#30340;&#38598;&#32676;&#20043;&#38388;&#30340;&#26144;&#23556;&#65292;&#25105;&#20204;&#23558;&#20854;&#31216;&#20026;&#20381;&#36182;&#38598;&#32676;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DCMAP&#30340;&#26032;&#31639;&#27861;&#65292;&#29992;&#20110;&#20855;&#26377;&#20381;&#36182;&#38598;&#32676;&#30340;&#26368;&#20248;&#38598;&#32676;&#26144;&#23556;&#12290;&#22312;&#22522;&#20110;DAG&#21644;&#38598;&#32676;&#26144;&#23556;&#30340;&#20219;&#24847;&#23450;&#20041;&#30340;&#27491;&#25104;&#26412;&#20989;&#25968;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;DCMAP&#25910;&#25947;&#20110;&#25214;&#21040;&#25152;&#26377;&#26368;&#20248;&#38598;&#32676;&#65292;&#24182;&#22312;&#36884;&#20013;&#36820;&#22238;&#25509;&#36817;&#26368;&#20248;&#35299;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#31639;&#27861;&#23545;&#20351;&#29992;&#35745;&#31639;&#25104;&#26412;&#20989;&#25968;&#30340;&#19968;&#20010;&#28023;&#33609;&#22797;&#26434;&#31995;&#32479;&#30340;DBN&#27169;&#22411;&#20855;&#26377;&#26102;&#38388;&#25928;&#29575;&#24615;&#12290;&#23545;&#20110;&#19968;&#20010;25&#20010;&#21644;50&#20010;&#33410;&#28857;&#30340;DBN&#65292;&#25628;&#32034;&#31354;&#38388;&#22823;&#23567;&#20998;&#21035;&#20026;$9.91\times 10^9$&#21644;$1.5$
&lt;/p&gt;
&lt;p&gt;
Many statistical inference contexts, including Bayesian Networks (BNs), Markov processes and Hidden Markov Models (HMMS) could be supported by partitioning (i.e.~mapping) the underlying Directed Acyclic Graph (DAG) into clusters. However, optimal partitioning is challenging, especially in statistical inference as the cost to be optimised is dependent on both nodes within a cluster, and the mapping of clusters connected via parent and/or child nodes, which we call dependent clusters. We propose a novel algorithm called DCMAP for optimal cluster mapping with dependent clusters. Given an arbitrarily defined, positive cost function based on the DAG and cluster mappings, we show that DCMAP converges to find all optimal clusters, and returns near-optimal solutions along the way. Empirically, we find that the algorithm is time-efficient for a DBN model of a seagrass complex system using a computation cost function. For a 25 and 50-node DBN, the search space size was $9.91\times 10^9$ and $1.5
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21457;&#29616;&#32593;&#32476;&#26435;&#37325;&#30340;&#26041;&#24046;&#21644;&#22823;&#26435;&#37325;&#30340;&#31354;&#38388;&#38598;&#20013;&#26159;&#24433;&#21709;&#31070;&#32463;&#25345;&#20037;&#24615;&#30340;&#20027;&#35201;&#22240;&#32032;&#65292;&#24182;&#25552;&#20986;&#20102;&#23558;&#31070;&#32463;&#25345;&#20037;&#24615;&#25193;&#23637;&#21040;&#25972;&#20010;&#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#22270;&#25345;&#20037;&#24615;&#27979;&#37327;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.10865</link><description>&lt;p&gt;
&#36890;&#36807;&#28145;&#24230;&#22270;&#30340;&#25345;&#20037;&#24615;&#35299;&#20915;&#31070;&#32463;&#25345;&#20037;&#24615;&#30340;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Addressing caveats of neural persistence with deep graph persistence. (arXiv:2307.10865v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10865
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21457;&#29616;&#32593;&#32476;&#26435;&#37325;&#30340;&#26041;&#24046;&#21644;&#22823;&#26435;&#37325;&#30340;&#31354;&#38388;&#38598;&#20013;&#26159;&#24433;&#21709;&#31070;&#32463;&#25345;&#20037;&#24615;&#30340;&#20027;&#35201;&#22240;&#32032;&#65292;&#24182;&#25552;&#20986;&#20102;&#23558;&#31070;&#32463;&#25345;&#20037;&#24615;&#25193;&#23637;&#21040;&#25972;&#20010;&#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#22270;&#25345;&#20037;&#24615;&#27979;&#37327;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#25345;&#20037;&#24615;&#26159;&#19968;&#31181;&#29992;&#20110;&#37327;&#21270;&#31070;&#32463;&#32593;&#32476;&#22797;&#26434;&#24615;&#30340;&#37325;&#35201;&#25351;&#26631;&#65292;&#25552;&#20986;&#20110;&#28145;&#24230;&#23398;&#20064;&#20013;&#26032;&#20852;&#30340;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#22312;&#29702;&#35770;&#21644;&#23454;&#35777;&#19978;&#25105;&#20204;&#21457;&#29616;&#65292;&#32593;&#32476;&#26435;&#37325;&#30340;&#26041;&#24046;&#21644;&#22823;&#26435;&#37325;&#30340;&#31354;&#38388;&#38598;&#20013;&#26159;&#24433;&#21709;&#31070;&#32463;&#25345;&#20037;&#24615;&#30340;&#20027;&#35201;&#22240;&#32032;&#12290;&#34429;&#28982;&#36825;&#23545;&#20110;&#32447;&#24615;&#20998;&#31867;&#22120;&#26377;&#29992;&#30340;&#20449;&#24687;&#65292;&#20294;&#25105;&#20204;&#21457;&#29616;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#21518;&#20960;&#23618;&#20013;&#27809;&#26377;&#30456;&#20851;&#30340;&#31354;&#38388;&#32467;&#26500;&#65292;&#20351;&#24471;&#31070;&#32463;&#25345;&#20037;&#24615;&#22823;&#33268;&#31561;&#20110;&#26435;&#37325;&#30340;&#26041;&#24046;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#25152;&#25552;&#20986;&#30340;&#23618;&#38388;&#24179;&#22343;&#36807;&#31243;&#27809;&#26377;&#32771;&#34385;&#23618;&#38388;&#30340;&#20132;&#20114;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#31070;&#32463;&#25345;&#20037;&#24615;&#22522;&#30784;&#32467;&#26500;&#30340;&#25193;&#23637;&#65292;&#20174;&#21333;&#23618;&#25913;&#20026;&#25972;&#20010;&#31070;&#32463;&#32593;&#32476;&#65292;&#36825;&#30456;&#24403;&#20110;&#22312;&#19968;&#20010;&#29305;&#23450;&#30697;&#38453;&#19978;&#35745;&#31639;&#31070;&#32463;&#25345;&#20037;&#24615;&#12290;&#36825;&#24471;&#21040;&#20102;&#25105;&#20204;&#30340;&#28145;&#24230;&#22270;&#25345;&#20037;&#24615;&#27979;&#37327;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural Persistence is a prominent measure for quantifying neural network complexity, proposed in the emerging field of topological data analysis in deep learning. In this work, however, we find both theoretically and empirically that the variance of network weights and spatial concentration of large weights are the main factors that impact neural persistence. Whilst this captures useful information for linear classifiers, we find that no relevant spatial structure is present in later layers of deep neural networks, making neural persistence roughly equivalent to the variance of weights. Additionally, the proposed averaging procedure across layers for deep neural networks does not consider interaction between layers. Based on our analysis, we propose an extension of the filtration underlying neural persistence to the whole neural network instead of single layers, which is equivalent to calculating neural persistence on one particular matrix. This yields our deep graph persistence measur
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#38454; Langevin &#21160;&#21147;&#23398;&#30340;&#31639;&#27861;&#65292;&#21487;&#26356;&#39640;&#25928;&#22320;&#37319;&#26679;&#26410;&#30693;&#21464;&#37327;&#21518;&#39564;&#20998;&#24067;&#65292;&#21516;&#26102;&#21152;&#20837;&#28140;&#28779;&#36807;&#31243;&#65292;&#33021;&#24212;&#29992;&#20110;&#31163;&#25955;&#26410;&#30693;&#21464;&#37327;&#24773;&#20917;&#65292;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#22312;&#22810;&#20010;&#20219;&#21153;&#20013;&#30456;&#23545;&#31454;&#20105;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.05014</link><description>&lt;p&gt;
&#20351;&#29992;&#39640;&#38454;&#28140;&#28779;&#38543;&#26426;&#28418;&#31227;&#35299;&#20915;&#32447;&#24615;&#21453;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Solving Linear Inverse Problems using Higher-Order Annealed Langevin Diffusion. (arXiv:2305.05014v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05014
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#38454; Langevin &#21160;&#21147;&#23398;&#30340;&#31639;&#27861;&#65292;&#21487;&#26356;&#39640;&#25928;&#22320;&#37319;&#26679;&#26410;&#30693;&#21464;&#37327;&#21518;&#39564;&#20998;&#24067;&#65292;&#21516;&#26102;&#21152;&#20837;&#28140;&#28779;&#36807;&#31243;&#65292;&#33021;&#24212;&#29992;&#20110;&#31163;&#25955;&#26410;&#30693;&#21464;&#37327;&#24773;&#20917;&#65292;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#22312;&#22810;&#20010;&#20219;&#21153;&#20013;&#30456;&#23545;&#31454;&#20105;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#38454; Langevin &#28418;&#31227;&#30340;&#32447;&#24615;&#21453;&#38382;&#39064;&#35299;&#20915;&#26041;&#26696;&#12290;&#26356;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#39044;&#22788;&#29702;&#30340;&#20108;&#38454;&#21644;&#19977;&#38454; Langevin &#21160;&#21147;&#23398;&#65292;&#36825;&#20123;&#21160;&#21147;&#23398;&#26126;&#26174;&#22320;&#20174;&#25105;&#20204;&#24863;&#20852;&#36259;&#30340;&#26410;&#30693;&#21464;&#37327;&#30340;&#21518;&#39564;&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#21516;&#26102;&#27604;&#20854;&#19968;&#38454;&#23545;&#24212;&#29289;&#21644;&#20004;&#31181;&#21160;&#21147;&#23398;&#30340;&#38750;&#39044;&#22788;&#29702;&#29256;&#26412;&#26356;&#20855;&#35745;&#31639;&#25928;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20004;&#31181;&#39044;&#22788;&#29702;&#21160;&#21147;&#23398;&#26159;&#33391;&#23450;&#20041;&#30340;&#65292;&#24182;&#19988;&#20855;&#26377;&#19982;&#38750;&#39044;&#22788;&#29702;&#24773;&#20917;&#30456;&#21516;&#30340;&#21807;&#19968;&#19981;&#21464;&#20998;&#24067;&#12290;&#25105;&#20204;&#36824;&#21152;&#20837;&#20102;&#19968;&#20010;&#28140;&#28779;&#36807;&#31243;&#65292;&#36825;&#20855;&#26377;&#21452;&#37325;&#20248;&#28857;&#65292;&#19968;&#26041;&#38754;&#36827;&#19968;&#27493;&#21152;&#36895;&#20102;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#21478;&#19968;&#26041;&#38754;&#65292;&#20801;&#35768;&#25105;&#20204;&#36866;&#24212;&#26410;&#30693;&#21464;&#37327;&#20026;&#31163;&#25955;&#30340;&#24773;&#20917;&#12290;&#22312;&#20004;&#20010;&#19981;&#21516;&#30340;&#20219;&#21153;&#65288;MIMO &#31526;&#21495;&#26816;&#27979;&#21644;&#36890;&#36947;&#20272;&#35745;&#65289;&#30340;&#25968;&#20540;&#23454;&#39564;&#20013;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#36890;&#29992;&#24615;&#65292;&#24182;&#35828;&#26126;&#20102;&#30456;&#23545;&#20110;&#31454;&#20105;&#26041;&#27861;&#65288;&#21253;&#25324;&#22522;&#20110;&#23398;&#20064;&#30340;&#26041;&#27861;&#65289;&#25152;&#23454;&#29616;&#30340;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a solution for linear inverse problems based on higher-order Langevin diffusion. More precisely, we propose pre-conditioned second-order and third-order Langevin dynamics that provably sample from the posterior distribution of our unknown variables of interest while being computationally more efficient than their first-order counterpart and the non-conditioned versions of both dynamics. Moreover, we prove that both pre-conditioned dynamics are well-defined and have the same unique invariant distributions as the non-conditioned cases. We also incorporate an annealing procedure that has the double benefit of further accelerating the convergence of the algorithm and allowing us to accommodate the case where the unknown variables are discrete. Numerical experiments in two different tasks (MIMO symbol detection and channel estimation) showcase the generality of our method and illustrate the high performance achieved relative to competing approaches (including learning-based ones)
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#19981;&#30830;&#23450;&#22810;&#21464;&#37327;&#31995;&#32479;&#34892;&#20026;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#25512;&#26029;&#30697;&#25551;&#36848;&#20998;&#24067;&#39044;&#35745;&#22914;&#20309;&#21709;&#24212;&#26032;&#20449;&#24687;&#65292;&#29305;&#21035;&#20851;&#27880;&#25512;&#26029;&#20559;&#24046;&#65292;&#20197;&#25913;&#21892;&#24773;&#22659;&#24863;&#30693;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2305.01841</link><description>&lt;p&gt;
&#19981;&#30830;&#23450;&#22810;&#21464;&#37327;&#31995;&#32479;&#30340;&#25512;&#26029;&#30697;
&lt;/p&gt;
&lt;p&gt;
Inferential Moments of Uncertain Multivariable Systems. (arXiv:2305.01841v1 [physics.data-an])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01841
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#19981;&#30830;&#23450;&#22810;&#21464;&#37327;&#31995;&#32479;&#34892;&#20026;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#25512;&#26029;&#30697;&#25551;&#36848;&#20998;&#24067;&#39044;&#35745;&#22914;&#20309;&#21709;&#24212;&#26032;&#20449;&#24687;&#65292;&#29305;&#21035;&#20851;&#27880;&#25512;&#26029;&#20559;&#24046;&#65292;&#20197;&#25913;&#21892;&#24773;&#22659;&#24863;&#30693;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31216;&#20026;&#8220;&#25512;&#26029;&#30697;&#8221;&#30340;&#19968;&#32452;&#37327;&#26469;&#20998;&#26512;&#19981;&#30830;&#23450;&#22810;&#21464;&#37327;&#31995;&#32479;&#34892;&#20026;&#30340;&#26032;&#33539;&#24335;&#12290;&#36793;&#32536;&#21270;&#26159;&#19968;&#31181;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#36807;&#31243;&#65292;&#23427;&#36890;&#36807;&#24179;&#22343;&#26465;&#20214;&#27010;&#29575;&#26469;&#37327;&#21270;&#25152;&#20851;&#27880;&#27010;&#29575;&#30340;&#26399;&#26395;&#20540;&#12290;&#25512;&#26029;&#30697;&#26159;&#25551;&#36848;&#20998;&#24067;&#39044;&#35745;&#22914;&#20309;&#21709;&#24212;&#26032;&#20449;&#24687;&#30340;&#39640;&#38454;&#26465;&#20214;&#27010;&#29575;&#30697;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#25512;&#26029;&#20559;&#24046;&#65292;&#23427;&#26159;&#26399;&#26395;&#30340;&#27010;&#29575;&#27874;&#21160;&#65292;&#38543;&#30528;&#25512;&#26029;&#26356;&#26032;&#21478;&#19968;&#20010;&#21464;&#37327;&#32780;&#21457;&#29983;&#21464;&#21270;&#12290;&#25105;&#20204;&#20197;&#25512;&#26029;&#30697;&#30340;&#24418;&#24335;&#25214;&#21040;&#20102;&#20114;&#20449;&#24687;&#30340;&#24130;&#32423;&#25968;&#23637;&#24320;&#24335;&#65292;&#36825;&#24847;&#21619;&#30528;&#25512;&#26029;&#30697;&#36923;&#36753;&#21487;&#33021;&#23545;&#36890;&#24120;&#20351;&#29992;&#20449;&#24687;&#35770;&#24037;&#20855;&#25191;&#34892;&#30340;&#20219;&#21153;&#26377;&#29992;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#24212;&#29992;&#20013;&#25506;&#35752;&#20102;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#25512;&#26029;&#20559;&#24046;&#65292;&#20197;&#25913;&#21892;&#24773;&#22659;&#24863;&#30693;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article offers a new paradigm for analyzing the behavior of uncertain multivariable systems using a set of quantities we call \emph{inferential moments}. Marginalization is an uncertainty quantification process that averages conditional probabilities to quantify the \emph{expected value} of a probability of interest. Inferential moments are higher order conditional probability moments that describe how a distribution is expected to respond to new information. Of particular interest in this article is the \emph{inferential deviation}, which is the expected fluctuation of the probability of one variable in response to an inferential update of another. We find a power series expansion of the Mutual Information in terms of inferential moments, which implies that inferential moment logic may be useful for tasks typically performed with information theoretic tools. We explore this in two applications that analyze the inferential deviations of a Bayesian Network to improve situational aw
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#26377;&#25928;&#32780;&#20934;&#30830;&#22320;&#36817;&#20284;&#31232;&#30095;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;&#65288;GAMs&#65289;&#30340;Rashomon&#38598;&#30340;&#25216;&#26415;&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;&#36817;&#20284;&#27169;&#22411;&#26469;&#35299;&#20915;&#23454;&#38469;&#24212;&#29992;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2303.16047</link><description>&lt;p&gt;
&#29702;&#35299;&#21644;&#25506;&#32034;&#31232;&#30095;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;&#30340;&#25972;&#20010;&#20248;&#31168;&#38598;&#21512;
&lt;/p&gt;
&lt;p&gt;
Understanding and Exploring the Whole Set of Good Sparse Generalized Additive Models. (arXiv:2303.16047v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16047
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#26377;&#25928;&#32780;&#20934;&#30830;&#22320;&#36817;&#20284;&#31232;&#30095;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;&#65288;GAMs&#65289;&#30340;Rashomon&#38598;&#30340;&#25216;&#26415;&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;&#36817;&#20284;&#27169;&#22411;&#26469;&#35299;&#20915;&#23454;&#38469;&#24212;&#29992;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19982;&#39046;&#22495;&#19987;&#23478;&#20043;&#38388;&#30340;&#20132;&#20114;&#33267;&#20851;&#37325;&#35201;&#65307;&#28982;&#32780;&#65292;&#36890;&#24120;&#21482;&#29983;&#25104;&#21333;&#20010;&#27169;&#22411;&#30340;&#32463;&#20856;&#26426;&#22120;&#23398;&#20064;&#33539;&#24335;&#19981;&#21033;&#20110;&#27492;&#31867;&#20132;&#20114;&#12290;&#36817;&#20284;&#21644;&#25506;&#32034;Rashomon&#38598;&#65292;&#21363;&#25152;&#26377;&#36817;&#20046;&#26368;&#20248;&#27169;&#22411;&#30340;&#38598;&#21512;&#65292;&#36890;&#36807;&#25552;&#20379;&#29992;&#25143;&#21487;&#25628;&#32034;&#30340;&#31354;&#38388;&#21253;&#21547;&#22810;&#26679;&#24615;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#36825;&#19968;&#23454;&#38469;&#25361;&#25112;&#65292;&#39046;&#22495;&#19987;&#23478;&#21487;&#20197;&#20174;&#20013;&#36873;&#25321;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#32780;&#20934;&#30830;&#22320;&#36817;&#20284;&#31232;&#30095;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;&#65288;GAMs&#65289;&#30340;Rashomon&#38598;&#30340;&#25216;&#26415;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29992;&#20110;&#36817;&#20284;&#20855;&#26377;&#22266;&#23450;&#25903;&#25345;&#38598;&#30340;GAMs&#30340;Rashomon&#38598;&#30340;&#26925;&#29699;&#24418;&#31639;&#27861;&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;&#26925;&#29699;&#24418;&#36817;&#20284;&#20102;&#35768;&#22810;&#19981;&#21516;&#25903;&#25345;&#38598;&#30340;Rashomon&#38598;&#12290;&#36817;&#20284;&#30340;Rashomon&#38598;&#20026;&#35299;&#20915;&#23454;&#38469;&#25361;&#25112;&#65292;&#20363;&#22914;&#65288;1&#65289;&#30740;&#31350;&#27169;&#22411;&#31867;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#65307;&#65288;2&#65289;&#22312;&#29992;&#25143;&#25351;&#23450;&#32422;&#26463;&#26465;&#20214;&#19979;&#26597;&#25214;&#27169;&#22411;&#65292;&#25552;&#20379;&#20102;&#37325;&#35201;&#30340;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
In real applications, interaction between machine learning model and domain experts is critical; however, the classical machine learning paradigm that usually produces only a single model does not facilitate such interaction. Approximating and exploring the Rashomon set, i.e., the set of all near-optimal models, addresses this practical challenge by providing the user with a searchable space containing a diverse set of models from which domain experts can choose. We present a technique to efficiently and accurately approximate the Rashomon set of sparse, generalized additive models (GAMs). We present algorithms to approximate the Rashomon set of GAMs with ellipsoids for fixed support sets and use these ellipsoids to approximate Rashomon sets for many different support sets. The approximated Rashomon set serves as a cornerstone to solve practical challenges such as (1) studying the variable importance for the model class; (2) finding models under user-specified constraints (monotonicity
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#24050;&#32463;&#36890;&#36807;&#20223;&#30495;&#30740;&#31350;&#39564;&#35777;&#20102;&#20854;&#21487;&#34892;&#24615;&#65292;&#21487;&#20197;&#32531;&#35299;&#32500;&#25968;&#35781;&#21650;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2009.07055</link><description>&lt;p&gt;
&#21033;&#29992;&#20855;&#26377;&#22810;&#20010;&#28151;&#28102;&#22240;&#32032;&#30340;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#19968;&#33324;&#27835;&#30103;&#25928;&#26524;&#30340;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Causal Inference of General Treatment Effects using Neural Networks with A Diverging Number of Confounders. (arXiv:2009.07055v6 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2009.07055
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#24050;&#32463;&#36890;&#36807;&#20223;&#30495;&#30740;&#31350;&#39564;&#35777;&#20102;&#20854;&#21487;&#34892;&#24615;&#65292;&#21487;&#20197;&#32531;&#35299;&#32500;&#25968;&#35781;&#21650;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#25928;&#24212;&#30340;&#20272;&#31639;&#26159;&#34892;&#20026;&#31185;&#23398;&#12289;&#31038;&#20250;&#31185;&#23398;&#12289;&#32463;&#27982;&#23398;&#21644;&#29983;&#29289;&#21307;&#23398;&#31185;&#23398;&#30340;&#20027;&#35201;&#30446;&#26631;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#31181;&#24191;&#20041;&#20248;&#21270;&#26694;&#26550;&#65292;&#20351;&#29992;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#65288;ANNs&#65289;&#26377;&#25928;&#20272;&#35745;&#19968;&#33324;&#27835;&#30103;&#25928;&#26524;&#65292;&#21363;&#20351;&#21327;&#21464;&#37327;&#30340;&#25968;&#37327;&#21487;&#20197;&#38543;&#30528;&#26679;&#26412;&#25968;&#37327;&#30340;&#22686;&#21152;&#32780;&#22686;&#21152;&#12290;&#25105;&#20204;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#26469;&#20272;&#31639;&#24178;&#25200;&#20989;&#25968;&#65292;&#24182;&#20026;ANN&#36817;&#20284;&#22120;&#24314;&#31435;&#20102;&#19968;&#20010;&#26032;&#30340;&#36817;&#20284;&#35823;&#24046;&#30028;&#38480;&#65292;&#24403;&#24178;&#25200;&#20989;&#25968;&#23646;&#20110;&#28151;&#21512;Sobolev&#31354;&#38388;&#26102;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;ANN&#21487;&#20197;&#32531;&#35299;&#32500;&#25968;&#35781;&#21650;&#38382;&#39064;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#24314;&#31435;&#20102;&#25152;&#25552;&#20986;&#30340;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#37327;&#30340;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24120;&#24615;&#65292;&#24182;&#24212;&#29992;&#20102;&#19968;&#20010;&#21152;&#26435;&#33258;&#21161;&#27861;&#36827;&#34892;&#25512;&#26029;&#12290;&#20223;&#30495;&#30740;&#31350;&#23637;&#31034;&#20102;&#36825;&#20123;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The estimation of causal effects is a primary goal of behavioral, social, economic and biomedical sciences. Under the unconfoundedness condition, adjustment for confounders requires estimating the nuisance functions relating outcome and/or treatment to confounders. This paper considers a generalized optimization framework for efficient estimation of general treatment effects using feedforward artificial neural networks (ANNs) when the number of covariates is allowed to increase with the sample size. We estimate the nuisance function by ANNs, and develop a new approximation error bound for the ANNs approximators when the nuisance function belongs to a mixed Sobolev space. We show that the ANNs can alleviate the curse of dimensionality under this circumstance. We further establish the consistency and asymptotic normality of the proposed treatment effects estimators, and apply a weighted bootstrap procedure for conducting inference. The proposed methods are illustrated via simulation stud
&lt;/p&gt;</description></item></channel></rss>