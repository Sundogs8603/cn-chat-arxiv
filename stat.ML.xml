<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#25972;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#21644;&#20998;&#26512;&#26354;&#32447;&#38754;&#31215;&#30340;&#26041;&#27861;&#26469;&#22686;&#24378;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292;&#20197;&#26368;&#23567;&#21270;&#25439;&#22833;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26469;&#24320;&#21457;&#26368;&#20248;&#30340;&#32447;&#24615;&#22238;&#24402;&#26041;&#31243;&#36827;&#34892;&#26435;&#37325;&#26356;&#26032;&#65292;&#36991;&#20813;&#20102;&#24120;&#37327;&#26435;&#37325;&#26356;&#26032;&#21644;&#22788;&#29702;&#37096;&#20998;&#25968;&#25454;&#38598;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2308.12280</link><description>&lt;p&gt;
&#25193;&#23637;&#32447;&#24615;&#22238;&#24402;&#65306;&#19968;&#31181;&#36890;&#36807;&#26354;&#32447;&#19979;&#38754;&#31215;&#26469;&#20943;&#23567;&#25439;&#22833;&#30340;&#21345;&#23572;&#26364;&#28388;&#27874;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Extended Linear Regression: A Kalman Filter Approach for Minimizing Loss via Area Under the Curve. (arXiv:2308.12280v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12280
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#25972;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#21644;&#20998;&#26512;&#26354;&#32447;&#38754;&#31215;&#30340;&#26041;&#27861;&#26469;&#22686;&#24378;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292;&#20197;&#26368;&#23567;&#21270;&#25439;&#22833;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26469;&#24320;&#21457;&#26368;&#20248;&#30340;&#32447;&#24615;&#22238;&#24402;&#26041;&#31243;&#36827;&#34892;&#26435;&#37325;&#26356;&#26032;&#65292;&#36991;&#20813;&#20102;&#24120;&#37327;&#26435;&#37325;&#26356;&#26032;&#21644;&#22788;&#29702;&#37096;&#20998;&#25968;&#25454;&#38598;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#25972;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#21644;&#20998;&#26512;&#26354;&#32447;&#38754;&#31215;&#26469;&#22686;&#24378;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292;&#20197;&#26368;&#23567;&#21270;&#25439;&#22833;&#12290;&#30446;&#26631;&#26159;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#26469;&#24320;&#21457;&#26368;&#20248;&#30340;&#32447;&#24615;&#22238;&#24402;&#26041;&#31243;&#36827;&#34892;&#26435;&#37325;&#26356;&#26032;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#19968;&#20010;&#36880;&#27493;&#36807;&#31243;&#65292;&#20174;&#29992;&#25143;&#23450;&#20041;&#30340;&#21442;&#25968;&#24320;&#22987;&#12290;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20351;&#29992;SGD&#36827;&#34892;&#35757;&#32451;&#65292;&#20998;&#21035;&#36319;&#36394;&#26435;&#37325;&#21644;&#25439;&#22833;&#65292;&#24182;&#26368;&#32456;&#36827;&#34892;&#21387;&#32553;&#12290;&#28982;&#21518;&#65292;&#22522;&#20110;&#26435;&#37325;&#21644;&#25439;&#22833;&#25968;&#32452;&#35757;&#32451;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#20197;&#39044;&#27979;&#19979;&#19968;&#20010;&#21512;&#24182;&#21518;&#30340;&#26435;&#37325;&#12290;&#39044;&#27979;&#32467;&#26524;&#26159;&#23558;&#36755;&#20837;&#22343;&#20540;&#19982;&#26435;&#37325;&#30456;&#20056;&#65292;&#32463;&#36807;&#25439;&#22833;&#35780;&#20272;&#21518;&#24418;&#25104;&#26435;&#37325;&#19982;&#25439;&#22833;&#30340;&#26354;&#32447;&#12290;&#20351;&#29992;&#20004;&#28857;&#20844;&#24335;&#25512;&#23548;&#20986;&#26354;&#32447;&#30340;&#26041;&#31243;&#65292;&#24182;&#36890;&#36807;&#31215;&#20998;&#35745;&#31639;&#26354;&#32447;&#19979;&#38754;&#31215;&#12290;&#20855;&#26377;&#26368;&#23567;&#38754;&#31215;&#30340;&#32447;&#24615;&#22238;&#24402;&#26041;&#31243;&#25104;&#20026;&#26368;&#20339;&#39044;&#27979;&#26354;&#32447;&#12290;&#20248;&#28857;&#21253;&#25324;&#36991;&#20813;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#36827;&#34892;&#24120;&#37327;&#26435;&#37325;&#26356;&#26032;&#65292;&#24182;&#19988;&#21487;&#20197;&#22788;&#29702;&#37096;&#20998;&#25968;&#25454;&#38598;&#65292;&#19981;&#20687;&#20854;&#20182;&#38656;&#35201;&#23436;&#25972;&#25968;&#25454;&#38598;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This research enhances linear regression models by integrating a Kalman filter and analysing curve areas to minimize loss. The goal is to develop an optimal linear regression equation using stochastic gradient descent (SGD) for weight updating. Our approach involves a stepwise process, starting with user-defined parameters. The linear regression model is trained using SGD, tracking weights and loss separately and zipping them finally. A Kalman filter is then trained based on weight and loss arrays to predict the next consolidated weights. Predictions result from multiplying input averages with weights, evaluated for loss to form a weight-versus-loss curve. The curve's equation is derived using the two-point formula, and area under the curve is calculated via integration. The linear regression equation with minimum area becomes the optimal curve for prediction. Benefits include avoiding constant weight updates via gradient descent and working with partial datasets, unlike methods needin
&lt;/p&gt;</description></item><item><title>&#26080;&#26089;&#20572;&#30340;&#20998;&#25968;&#25193;&#25955;&#27169;&#22411;&#19981;&#38656;&#35201;&#24471;&#20998;&#20989;&#25968;&#30340;Lipschitz&#22343;&#21248;&#26465;&#20214;&#65292;&#21482;&#38656;&#35201;&#26377;&#38480;&#30340;&#36153;&#33293;&#23572;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2308.12240</link><description>&lt;p&gt;
&#26080;&#26089;&#20572;&#30340;&#20998;&#25968;&#25193;&#25955;&#27169;&#22411;&#65306;&#26377;&#38480;&#36153;&#33293;&#23572;&#20449;&#24687;&#23601;&#36275;&#22815;&#20102;
&lt;/p&gt;
&lt;p&gt;
Score diffusion models without early stopping: finite Fisher information is all you need. (arXiv:2308.12240v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12240
&lt;/p&gt;
&lt;p&gt;
&#26080;&#26089;&#20572;&#30340;&#20998;&#25968;&#25193;&#25955;&#27169;&#22411;&#19981;&#38656;&#35201;&#24471;&#20998;&#20989;&#25968;&#30340;Lipschitz&#22343;&#21248;&#26465;&#20214;&#65292;&#21482;&#38656;&#35201;&#26377;&#38480;&#30340;&#36153;&#33293;&#23572;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#25968;&#25193;&#25955;&#27169;&#22411;&#26159;&#19968;&#31181;&#22260;&#32469;&#30528;&#19982;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30456;&#20851;&#30340;&#24471;&#20998;&#20989;&#25968;&#20272;&#35745;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#22312;&#33719;&#24471;&#36817;&#20284;&#30340;&#24471;&#20998;&#20989;&#25968;&#20043;&#21518;&#65292;&#21033;&#29992;&#23427;&#26469;&#27169;&#25311;&#30456;&#24212;&#30340;&#26102;&#38388;&#36870;&#36807;&#31243;&#65292;&#26368;&#32456;&#23454;&#29616;&#36817;&#20284;&#25968;&#25454;&#26679;&#26412;&#30340;&#29983;&#25104;&#12290;&#23613;&#31649;&#36825;&#20123;&#27169;&#22411;&#20855;&#26377;&#26174;&#33879;&#30340;&#23454;&#38469;&#24847;&#20041;&#65292;&#20294;&#22312;&#28041;&#21450;&#38750;&#24120;&#35268;&#24471;&#20998;&#21644;&#20272;&#35745;&#22120;&#30340;&#24773;&#20917;&#19979;&#65292;&#20173;&#23384;&#22312;&#19968;&#20010;&#26174;&#33879;&#30340;&#25361;&#25112;&#65292;&#21363;&#32570;&#20047;&#20840;&#38754;&#30340;&#23450;&#37327;&#32467;&#26524;&#12290;&#22312;&#20960;&#20046;&#25152;&#26377;&#30340;Kullback Leibler&#25955;&#24230;&#30340;&#30456;&#20851;&#32467;&#26524;&#20013;&#65292;&#37117;&#20551;&#35774;&#24471;&#20998;&#20989;&#25968;&#25110;&#20854;&#36817;&#20284;&#22312;&#26102;&#38388;&#19978;&#26159;Lipschitz&#22343;&#21248;&#30340;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#36825;&#20010;&#26465;&#20214;&#38750;&#24120;&#20005;&#26684;&#65292;&#25110;&#32773;&#24456;&#38590;&#24314;&#31435;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#20027;&#35201;&#26159;&#20851;&#27880;&#20998;&#25968;&#25193;&#25955;&#27169;&#22411;&#30340;&#26089;&#20572;&#29256;&#26412;&#22312;KL&#25955;&#24230;&#19978;&#30340;&#25910;&#25947;&#30028;&#38480;&#65292;&#24182;&#19988;...
&lt;/p&gt;
&lt;p&gt;
Diffusion models are a new class of generative models that revolve around the estimation of the score function associated with a stochastic differential equation. Subsequent to its acquisition, the approximated score function is then harnessed to simulate the corresponding time-reversal process, ultimately enabling the generation of approximate data samples. Despite their evident practical significance these models carry, a notable challenge persists in the form of a lack of comprehensive quantitative results, especially in scenarios involving non-regular scores and estimators. In almost all reported bounds in Kullback Leibler (KL) divergence, it is assumed that either the score function or its approximation is Lipschitz uniformly in time. However, this condition is very restrictive in practice or appears to be difficult to establish.  To circumvent this issue, previous works mainly focused on establishing convergence bounds in KL for an early stopped version of the diffusion model and
&lt;/p&gt;</description></item><item><title>&#21363;&#20351;&#22312;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20013;&#20063;&#23384;&#22312;&#20851;&#38190;&#23398;&#20064;&#26399;&#65292;&#36825;&#20123;&#20851;&#38190;&#23398;&#20064;&#26399;&#21462;&#20915;&#20110;&#27169;&#22411;&#30340;&#28145;&#24230;&#21644;&#25968;&#25454;&#20998;&#24067;&#30340;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2308.12221</link><description>&lt;p&gt;
&#21363;&#20351;&#22312;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20013;&#20063;&#23384;&#22312;&#20851;&#38190;&#23398;&#20064;&#26399;
&lt;/p&gt;
&lt;p&gt;
Critical Learning Periods Emerge Even in Deep Linear Networks. (arXiv:2308.12221v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12221
&lt;/p&gt;
&lt;p&gt;
&#21363;&#20351;&#22312;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20013;&#20063;&#23384;&#22312;&#20851;&#38190;&#23398;&#20064;&#26399;&#65292;&#36825;&#20123;&#20851;&#38190;&#23398;&#20064;&#26399;&#21462;&#20915;&#20110;&#27169;&#22411;&#30340;&#28145;&#24230;&#21644;&#25968;&#25454;&#20998;&#24067;&#30340;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20851;&#38190;&#23398;&#20064;&#26399;&#26159;&#25351;&#22312;&#21457;&#32946;&#26089;&#26399;&#65292;&#26242;&#26102;&#30340;&#24863;&#30693;&#32570;&#38519;&#20250;&#23545;&#34892;&#20026;&#21644;&#23398;&#20064;&#34920;&#31034;&#20135;&#29983;&#27704;&#20037;&#24433;&#21709;&#30340;&#26102;&#38388;&#27573;&#12290;&#23613;&#31649;&#29983;&#29289;&#32593;&#32476;&#21644;&#20154;&#24037;&#32593;&#32476;&#20043;&#38388;&#23384;&#22312;&#26681;&#26412;&#24615;&#30340;&#24046;&#24322;&#65292;&#20294;&#20851;&#38190;&#23398;&#20064;&#26399;&#22312;&#20004;&#20010;&#31995;&#32479;&#20013;&#37117;&#26377;&#32463;&#39564;&#35266;&#23519;&#21040;&#12290;&#36825;&#34920;&#26126;&#20851;&#38190;&#23398;&#20064;&#26399;&#21487;&#33021;&#26159;&#23398;&#20064;&#30340;&#22522;&#26412;&#35201;&#32032;&#65292;&#32780;&#19981;&#26159;&#29983;&#29289;&#23398;&#19978;&#30340;&#20598;&#28982;&#29616;&#35937;&#12290;&#28982;&#32780;&#65292;&#20026;&#20160;&#20040;&#20851;&#38190;&#23398;&#20064;&#26399;&#20250;&#22312;&#28145;&#24230;&#32593;&#32476;&#20013;&#20986;&#29616;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20043;&#35868;&#65292;&#23588;&#20854;&#26159;&#19981;&#28165;&#26970;&#22312;&#20004;&#20010;&#31995;&#32479;&#20013;&#35266;&#23519;&#21040;&#30340;&#20851;&#38190;&#23398;&#20064;&#26399;&#26159;&#21542;&#20381;&#36182;&#20110;&#29305;&#23450;&#30340;&#26550;&#26500;&#25110;&#20248;&#21270;&#32454;&#33410;&#12290;&#20026;&#20102;&#30830;&#23450;&#20851;&#38190;&#30340;&#22522;&#26412;&#22240;&#32032;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#27169;&#22411;&#65292;&#24182;&#23637;&#31034;&#20102;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#36825;&#26679;&#30340;&#32593;&#32476;&#20063;&#26174;&#31034;&#20986;&#29983;&#29289;&#23398;&#21644;&#20154;&#24037;&#32593;&#32476;&#20013;&#35266;&#23519;&#21040;&#30340;&#35768;&#22810;&#34892;&#20026;&#65292;&#21516;&#26102;&#36824;&#21487;&#20197;&#36827;&#34892;&#20998;&#26512;&#22788;&#29702;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20851;&#38190;&#23398;&#20064;&#26399;&#21462;&#20915;&#20110;&#27169;&#22411;&#30340;&#28145;&#24230;&#21644;&#25968;&#25454;&#20998;&#24067;&#30340;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Critical learning periods are periods early in development where temporary sensory deficits can have a permanent effect on behavior and learned representations. Despite the radical differences between biological and artificial networks, critical learning periods have been empirically observed in both systems. This suggests that critical periods may be fundamental to learning and not an accident of biology. Yet, why exactly critical periods emerge in deep networks is still an open question, and in particular it is unclear whether the critical periods observed in both systems depend on particular architectural or optimization details. To isolate the key underlying factors, we focus on deep linear network models, and show that, surprisingly, such networks also display much of the behavior seen in biology and artificial networks, while being amenable to analytical treatment. We show that critical periods depend on the depth of the model and structure of the data distribution. We also show 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31471;&#21040;&#31471;&#30340;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;L2GMOM&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#23398;&#20064;&#37329;&#34701;&#32593;&#32476;&#21644;&#20248;&#21270;&#32593;&#32476;&#21160;&#37327;&#31574;&#30053;&#30340;&#20132;&#26131;&#20449;&#21495;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#26041;&#27861;&#20381;&#36182;&#26114;&#36149;&#25968;&#25454;&#24211;&#21644;&#37329;&#34701;&#19987;&#19994;&#30693;&#35782;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#39640;&#24230;&#21487;&#35299;&#37322;&#30340;&#21069;&#21521;&#20256;&#25773;&#26550;&#26500;&#12290;</title><link>http://arxiv.org/abs/2308.12212</link><description>&lt;p&gt;
&#23398;&#20064;&#23398;&#20064;&#37329;&#34701;&#32593;&#32476;&#20197;&#20248;&#21270;&#21160;&#21147;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Learning to Learn Financial Networks for Optimising Momentum Strategies. (arXiv:2308.12212v1 [q-fin.PM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12212
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31471;&#21040;&#31471;&#30340;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;L2GMOM&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#23398;&#20064;&#37329;&#34701;&#32593;&#32476;&#21644;&#20248;&#21270;&#32593;&#32476;&#21160;&#37327;&#31574;&#30053;&#30340;&#20132;&#26131;&#20449;&#21495;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#26041;&#27861;&#20381;&#36182;&#26114;&#36149;&#25968;&#25454;&#24211;&#21644;&#37329;&#34701;&#19987;&#19994;&#30693;&#35782;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#39640;&#24230;&#21487;&#35299;&#37322;&#30340;&#21069;&#21521;&#20256;&#25773;&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#21160;&#37327;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#39118;&#38505;&#28322;&#20215;&#65292;&#23427;&#21033;&#29992;&#37329;&#34701;&#32593;&#32476;&#20013;&#36164;&#20135;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#32852;&#26469;&#39044;&#27979;&#26410;&#26469;&#30340;&#22238;&#25253;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#26500;&#24314;&#37329;&#34701;&#32593;&#32476;&#30340;&#36807;&#31243;&#20381;&#36182;&#20110;&#26114;&#36149;&#30340;&#25968;&#25454;&#24211;&#21644;&#37329;&#34701;&#19987;&#19994;&#30693;&#35782;&#65292;&#38480;&#21046;&#20102;&#23567;&#22411;&#21644;&#23398;&#26415;&#26426;&#26500;&#30340;&#21487;&#35775;&#38382;&#24615;&#12290;&#27492;&#22806;&#65292;&#20256;&#32479;&#26041;&#27861;&#23558;&#32593;&#32476;&#26500;&#24314;&#21644;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;&#35270;&#20026;&#21333;&#29420;&#30340;&#20219;&#21153;&#65292;&#21487;&#33021;&#20250;&#24433;&#21709;&#26368;&#20248;&#25237;&#36164;&#32452;&#21512;&#30340;&#34920;&#29616;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;L2GMOM&#65292;&#19968;&#20010;&#31471;&#21040;&#31471;&#30340;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#21516;&#26102;&#23398;&#20064;&#37329;&#34701;&#32593;&#32476;&#21644;&#20248;&#21270;&#32593;&#32476;&#21160;&#37327;&#31574;&#30053;&#30340;&#20132;&#26131;&#20449;&#21495;&#12290;L2GMOM&#27169;&#22411;&#26159;&#19968;&#20010;&#20855;&#26377;&#39640;&#24230;&#21487;&#35299;&#37322;&#21069;&#21521;&#20256;&#25773;&#26550;&#26500;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#23427;&#26159;&#20174;&#31639;&#27861;&#23637;&#24320;&#20013;&#25512;&#23548;&#20986;&#26469;&#30340;&#12290;L2GMOM&#20855;&#26377;&#28789;&#27963;&#24615;&#65292;&#24182;&#21487;&#20197;&#20351;&#29992;&#19981;&#21516;&#30340;&#25237;&#36164;&#32452;&#21512;&#32489;&#25928;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#35757;&#32451;&#65292;&#20363;&#22914;&#36127;&#22799;&#26222;&#27604;&#29575;&#12290;&#22312;&#22238;&#27979;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Network momentum provides a novel type of risk premium, which exploits the interconnections among assets in a financial network to predict future returns. However, the current process of constructing financial networks relies heavily on expensive databases and financial expertise, limiting accessibility for small-sized and academic institutions. Furthermore, the traditional approach treats network construction and portfolio optimisation as separate tasks, potentially hindering optimal portfolio performance. To address these challenges, we propose L2GMOM, an end-to-end machine learning framework that simultaneously learns financial networks and optimises trading signals for network momentum strategies. The model of L2GMOM is a neural network with a highly interpretable forward propagation architecture, which is derived from algorithm unrolling. The L2GMOM is flexible and can be trained with diverse loss functions for portfolio performance, e.g. the negative Sharpe ratio. Backtesting on 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#23398;&#20064;&#31995;&#25968;&#30340;&#37327;&#65292;&#29992;&#20110;&#31934;&#30830;&#37327;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#36864;&#21270;&#31243;&#24230;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#21306;&#20998;&#19981;&#21516;&#21442;&#25968;&#21306;&#22495;&#30340;&#36864;&#21270;&#39034;&#24207;&#65292;&#24182;&#25581;&#31034;&#20102;&#38543;&#26426;&#20248;&#21270;&#22120;&#23545;&#20020;&#30028;&#28857;&#30340;&#24402;&#32435;&#20559;&#22909;&#12290;</title><link>http://arxiv.org/abs/2308.12108</link><description>&lt;p&gt;
&#36890;&#36807;&#23398;&#20064;&#31995;&#25968;&#37327;&#21270;&#22855;&#24322;&#27169;&#22411;&#20013;&#30340;&#36864;&#21270;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
Quantifying degeneracy in singular models via the learning coefficient. (arXiv:2308.12108v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12108
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#23398;&#20064;&#31995;&#25968;&#30340;&#37327;&#65292;&#29992;&#20110;&#31934;&#30830;&#37327;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#36864;&#21270;&#31243;&#24230;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#21306;&#20998;&#19981;&#21516;&#21442;&#25968;&#21306;&#22495;&#30340;&#36864;&#21270;&#39034;&#24207;&#65292;&#24182;&#25581;&#31034;&#20102;&#38543;&#26426;&#20248;&#21270;&#22120;&#23545;&#20020;&#30028;&#28857;&#30340;&#24402;&#32435;&#20559;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#26159;&#20855;&#26377;&#22797;&#26434;&#36864;&#21270;&#30340;&#22855;&#24322;&#32479;&#35745;&#27169;&#22411;&#12290;&#26412;&#25991;&#38416;&#36848;&#20102;&#19968;&#31181;&#31216;&#20026;&#23398;&#20064;&#31995;&#25968;&#30340;&#37327;&#65292;&#23427;&#22312;&#22855;&#24322;&#23398;&#20064;&#29702;&#35770;&#20013;&#31934;&#30830;&#22320;&#37327;&#21270;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36864;&#21270;&#31243;&#24230;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#23558;&#35777;&#26126;DNN&#20013;&#30340;&#36864;&#21270;&#19981;&#33021;&#20165;&#36890;&#36807;&#35745;&#31639;&#8220;&#24179;&#22374;&#8221;&#26041;&#21521;&#30340;&#25968;&#37327;&#26469;&#35299;&#37322;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#26799;&#24230; Langevin &#21160;&#21147;&#23398;&#30340;&#23616;&#37096;&#23398;&#20064;&#31995;&#25968;&#30340;&#35745;&#31639;&#21487;&#25193;&#23637;&#36817;&#20284;&#26041;&#27861;&#12290;&#20026;&#20102;&#39564;&#35777;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#22312;&#24050;&#30693;&#29702;&#35770;&#20540;&#30340;&#20302;&#32500;&#27169;&#22411;&#19978;&#28436;&#31034;&#20102;&#20854;&#20934;&#30830;&#24615;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#23616;&#37096;&#23398;&#20064;&#31995;&#25968;&#33021;&#22815;&#27491;&#30830;&#24674;&#22797;&#24863;&#20852;&#36259;&#21442;&#25968;&#21306;&#22495;&#20043;&#38388;&#36864;&#21270;&#30340;&#39034;&#24207;&#12290;&#23545;MNIST&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#23616;&#37096;&#23398;&#20064;&#31995;&#25968;&#21487;&#20197;&#25581;&#31034;&#38543;&#26426;&#20248;&#21270;&#22120;&#23545;&#26356;&#36864;&#21270;&#25110;&#19981;&#22826;&#36864;&#21270;&#30340;&#20020;&#30028;&#28857;&#30340;&#24402;&#32435;&#20559;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks (DNN) are singular statistical models which exhibit complex degeneracies. In this work, we illustrate how a quantity known as the \emph{learning coefficient} introduced in singular learning theory quantifies precisely the degree of degeneracy in deep neural networks. Importantly, we will demonstrate that degeneracy in DNN cannot be accounted for by simply counting the number of "flat" directions. We propose a computationally scalable approximation of a localized version of the learning coefficient using stochastic gradient Langevin dynamics. To validate our approach, we demonstrate its accuracy in low-dimensional models with known theoretical values. Importantly, the local learning coefficient can correctly recover the ordering of degeneracy between various parameter regions of interest. An experiment on MNIST shows the local learning coefficient can reveal the inductive bias of stochastic opitmizers for more or less degenerate critical points.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#30446;&#26631;&#24310;&#32493;&#26041;&#27861;&#65292;&#29992;&#20110;&#35745;&#31639;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27491;&#21017;&#21270;&#36335;&#24452;&#65292;&#20197;&#35299;&#20915;DNNs&#20013;&#31232;&#30095;&#24615;&#21644;&#25968;&#20540;&#25928;&#29575;&#20043;&#38388;&#30340;&#20914;&#31361;&#12290;</title><link>http://arxiv.org/abs/2308.12044</link><description>&lt;p&gt;
&#29992;&#20110;&#35745;&#31639;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#27491;&#21017;&#21270;&#36335;&#24452;&#30340;&#22810;&#30446;&#26631;&#24310;&#32493;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A multiobjective continuation method to compute the regularization path of deep neural networks. (arXiv:2308.12044v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12044
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#30446;&#26631;&#24310;&#32493;&#26041;&#27861;&#65292;&#29992;&#20110;&#35745;&#31639;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27491;&#21017;&#21270;&#36335;&#24452;&#65292;&#20197;&#35299;&#20915;DNNs&#20013;&#31232;&#30095;&#24615;&#21644;&#25968;&#20540;&#25928;&#29575;&#20043;&#38388;&#30340;&#20914;&#31361;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#24615;&#26159;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#20013;&#38750;&#24120;&#29702;&#24819;&#30340;&#29305;&#24449;&#65292;&#22240;&#20026;&#23427;&#30830;&#20445;&#20102;&#25968;&#20540;&#25928;&#29575;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;(&#30001;&#20110;&#30456;&#20851;&#29305;&#24449;&#30340;&#25968;&#37327;&#36739;&#23569;)&#21644;&#40065;&#26834;&#24615;&#12290;&#22312;&#22522;&#20110;&#32447;&#24615;&#27169;&#22411;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20013;&#65292;&#20247;&#25152;&#21608;&#30693;&#22312;$\ell^1$&#33539;&#25968;(&#21363;&#38646;&#26435;&#37325;)&#30340;&#26368;&#31232;&#30095;&#35299;&#21644;&#38750;&#27491;&#21017;&#21270;&#35299;&#20043;&#38388;&#23384;&#22312;&#19968;&#26465;&#36830;&#25509;&#36335;&#24452;&#65292;&#36825;&#26465;&#36335;&#24452;&#34987;&#31216;&#20026;&#27491;&#21017;&#21270;&#36335;&#24452;&#12290;&#26368;&#36817;&#65292;&#36890;&#36807;&#23558;&#32463;&#39564;&#25439;&#22833;&#21644;&#31232;&#30095;&#24615;($\ell^1$&#33539;&#25968;)&#20316;&#20026;&#20004;&#20010;&#20914;&#31361;&#30340;&#26631;&#20934;&#65292;&#24182;&#35299;&#20915;&#30001;&#27492;&#20135;&#29983;&#30340;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#65292;&#39318;&#27425;&#23581;&#35797;&#23558;&#27491;&#21017;&#21270;&#36335;&#24452;&#30340;&#27010;&#24565;&#25193;&#23637;&#21040;DNNs&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;$\ell^1$&#33539;&#25968;&#30340;&#19981;&#20809;&#28369;&#24615;&#21644;&#21442;&#25968;&#25968;&#37327;&#30340;&#39640;&#24230;&#65292;&#20174;&#35745;&#31639;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#36825;&#31181;&#26041;&#27861;&#24182;&#19981;&#26159;&#24456;&#26377;&#25928;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#36817;&#20284;&#35745;&#31639;&#25972;&#20010;&#24085;&#32047;&#25176;&#26354;&#32447;
&lt;/p&gt;
&lt;p&gt;
Sparsity is a highly desired feature in deep neural networks (DNNs) since it ensures numerical efficiency, improves the interpretability of models (due to the smaller number of relevant features), and robustness. In machine learning approaches based on linear models, it is well known that there exists a connecting path between the sparsest solution in terms of the $\ell^1$ norm (i.e., zero weights) and the non-regularized solution, which is called the regularization path. Very recently, there was a first attempt to extend the concept of regularization paths to DNNs by means of treating the empirical loss and sparsity ($\ell^1$ norm) as two conflicting criteria and solving the resulting multiobjective optimization problem. However, due to the non-smoothness of the $\ell^1$ norm and the high number of parameters, this approach is not very efficient from a computational perspective. To overcome this limitation, we present an algorithm that allows for the approximation of the entire Pareto
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#26680;&#23398;&#20064;&#30340;&#25903;&#25345;&#21521;&#37327;&#26426;&#26694;&#26550;(MKL-$L_{0/1}$-SVM)&#65292;&#36890;&#36807;&#24320;&#21457;&#24555;&#36895;&#30340;ADMM&#27714;&#35299;&#22120;&#22788;&#29702;&#38750;&#20984;&#38750;&#20809;&#28369;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#19982;&#39046;&#20808;&#26041;&#27861;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.12016</link><description>&lt;p&gt;
MKL-$L_{0/1}$-SVM: &#19968;&#31181;&#22810;&#26680;&#23398;&#20064;&#30340;&#25903;&#25345;&#21521;&#37327;&#26426;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
MKL-$L_{0/1}$-SVM. (arXiv:2308.12016v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12016
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#26680;&#23398;&#20064;&#30340;&#25903;&#25345;&#21521;&#37327;&#26426;&#26694;&#26550;(MKL-$L_{0/1}$-SVM)&#65292;&#36890;&#36807;&#24320;&#21457;&#24555;&#36895;&#30340;ADMM&#27714;&#35299;&#22120;&#22788;&#29702;&#38750;&#20984;&#38750;&#20809;&#28369;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#19982;&#39046;&#20808;&#26041;&#27861;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;$(0, 1)$&#25439;&#22833;&#20989;&#25968;&#30340;&#25903;&#25345;&#21521;&#37327;&#26426;&#30340;&#22810;&#26680;&#23398;&#20064;&#65288;MKL&#65289;&#26694;&#26550;&#12290;&#39318;&#20808;&#32473;&#20986;&#20102;&#19968;&#38454;&#26368;&#20248;&#24615;&#26465;&#20214;&#65292;&#28982;&#21518;&#21033;&#29992;&#23427;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#24555;&#36895;&#30340;ADMM&#27714;&#35299;&#22120;&#26469;&#22788;&#29702;&#38750;&#20984;&#38750;&#20809;&#28369;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#35814;&#32454;&#30340;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;MKL-$L_{0/1}$-SVM&#30340;&#24615;&#33021;&#19982;&#19968;&#31181;&#21517;&#20026;SimpleMKL&#30340;&#39046;&#20808;&#26041;&#27861;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a Multiple Kernel Learning (abbreviated as MKL) framework for the Support Vector Machine (SVM) with the $(0, 1)$ loss function. Some first-order optimality conditions are given and then exploited to develop a fast ADMM solver to deal with the nonconvex and nonsmooth optimization problem. Extensive numerical experiments on synthetic and real datasets show that the performance of our MKL-$L_{0/1}$-SVM is comparable with the one of the leading approaches called SimpleMKL developed by Rakotomamonjy, Bach, Canu, and Grandvalet [Journal of Machine Learning Research, vol. 9, pp. 2491-2521, 2008].
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19977;&#31181;&#37327;&#23376;&#22122;&#22768;&#39537;&#21160;&#30340;&#29983;&#25104;&#25193;&#25955;&#27169;&#22411;&#65292;&#21033;&#29992;&#20102;&#37327;&#23376;&#29305;&#24615;&#20197;&#20811;&#26381;&#20256;&#32479;&#27169;&#22411;&#30340;&#20027;&#35201;&#35745;&#31639;&#22256;&#38590;&#65292;&#24182;&#24314;&#35758;&#23558;&#37327;&#23376;&#22122;&#22768;&#35270;&#20026;&#21487;&#21033;&#29992;&#30340;&#29305;&#24615;&#32780;&#38750;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.12013</link><description>&lt;p&gt;
&#37327;&#23376;&#22122;&#22768;&#39537;&#21160;&#30340;&#29983;&#25104;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Quantum-Noise-driven Generative Diffusion Models. (arXiv:2308.12013v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12013
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19977;&#31181;&#37327;&#23376;&#22122;&#22768;&#39537;&#21160;&#30340;&#29983;&#25104;&#25193;&#25955;&#27169;&#22411;&#65292;&#21033;&#29992;&#20102;&#37327;&#23376;&#29305;&#24615;&#20197;&#20811;&#26381;&#20256;&#32479;&#27169;&#22411;&#30340;&#20027;&#35201;&#35745;&#31639;&#22256;&#38590;&#65292;&#24182;&#24314;&#35758;&#23558;&#37327;&#23376;&#22122;&#22768;&#35270;&#20026;&#21487;&#21033;&#29992;&#30340;&#29305;&#24615;&#32780;&#38750;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#23454;&#29616;&#30340;&#29983;&#25104;&#27169;&#22411;&#26159;&#20174;&#26377;&#38480;&#30340;&#35757;&#32451;&#26679;&#26412;&#20013;&#25512;&#26029;&#20986;&#22797;&#26434;&#21644;&#26410;&#30693;&#25968;&#25454;&#20998;&#24067;&#24182;&#20135;&#29983;&#26032;&#30340;&#21512;&#25104;&#25968;&#25454;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#25193;&#25955;&#27169;&#22411;&#26159;&#19968;&#31181;&#26032;&#20852;&#30340;&#26694;&#26550;&#65292;&#26368;&#36817;&#22312;&#21019;&#24314;&#21512;&#25104;&#25991;&#26412;&#21644;&#39640;&#36136;&#37327;&#22270;&#20687;&#26041;&#38754;&#24050;&#32463;&#36229;&#36234;&#20102;&#29983;&#25104;&#23545;&#25239;&#24615;&#32593;&#32476;&#30340;&#24615;&#33021;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#35752;&#35770;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#37327;&#23376;&#25512;generalization&#65292;&#21363;&#19977;&#31181;&#21487;&#33021;&#22312;&#23454;&#38469;&#37327;&#23376;&#31995;&#32479;&#19978;&#36827;&#34892;&#23454;&#39564;&#30340;&#37327;&#23376;&#22122;&#22768;&#39537;&#21160;&#30340;&#29983;&#25104;&#25193;&#25955;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#24819;&#27861;&#26159;&#21033;&#29992;&#29420;&#29305;&#30340;&#37327;&#23376;&#29305;&#24615;&#65292;&#29305;&#21035;&#26159;&#30446;&#21069;&#21487;&#29992;&#30340;&#26377;&#22122;&#22768;&#37327;&#23376;&#22788;&#29702;&#22120;&#19981;&#21487;&#36991;&#20813;&#22320;&#21463;&#21040;&#30340;&#30456;&#24178;&#24615;&#12289;&#32416;&#32544;&#24615;&#21644;&#22122;&#22768;&#20043;&#38388;&#30340;&#38750;&#24179;&#20961;&#30456;&#20114;&#20316;&#29992;&#65292;&#20197;&#20811;&#26381;&#20256;&#32479;&#25193;&#25955;&#27169;&#22411;&#22312;&#25512;&#26029;&#36807;&#31243;&#20013;&#30340;&#20027;&#35201;&#35745;&#31639;&#36127;&#25285;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24314;&#35758;&#23558;&#37327;&#23376;&#22122;&#22768;&#19981;&#20316;&#20026;&#38656;&#35201;&#26816;&#27979;&#21644;&#35299;&#20915;&#30340;&#38382;&#39064;&#65292;&#32780;&#26159;&#20316;&#20026;&#19968;&#31181;&#21487;&#21033;&#29992;&#30340;&#29305;&#24615;&#65292;&#20351;&#24471;&#25193;&#25955;&#27169;&#22411;&#33021;&#22815;&#26356;&#22909;&#22320;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative models realized with machine learning techniques are powerful tools to infer complex and unknown data distributions from a finite number of training samples in order to produce new synthetic data. Diffusion models are an emerging framework that have recently overcome the performance of the generative adversarial networks in creating synthetic text and high-quality images. Here, we propose and discuss the quantum generalization of diffusion models, i.e., three quantum-noise-driven generative diffusion models that could be experimentally tested on real quantum systems. The idea is to harness unique quantum features, in particular the non-trivial interplay among coherence, entanglement and noise that the currently available noisy quantum processors do unavoidably suffer from, in order to overcome the main computational burdens of classical diffusion models during inference. Hence, we suggest to exploit quantum noise not as an issue to be detected and solved but instead as a ver
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#39044;&#31639;&#30340;&#38543;&#26426;&#20108;&#33218;&#36172;&#21338;&#26426;&#20013;&#36827;&#34892;&#26368;&#20339;&#33218;&#36873;&#25321;&#30340;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#19981;&#23384;&#22312;&#27604;&#31561;&#27010;&#29575;&#37319;&#26679;&#31639;&#27861;&#26356;&#22909;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#33268;&#31283;&#23450;&#31639;&#27861;&#30340;&#27010;&#24565;&#65292;&#24182;&#35777;&#26126;&#20219;&#20309;&#22312;&#25152;&#26377;&#24773;&#20917;&#19979;&#19982;&#31561;&#27010;&#29575;&#37319;&#26679;&#31639;&#27861;&#34920;&#29616;&#19968;&#26679;&#22909;&#30340;&#31639;&#27861;&#24517;&#39035;&#23646;&#20110;&#36825;&#20010;&#31867;&#21035;&#12290;&#36825;&#19968;&#32467;&#26524;&#35299;&#20915;&#20102;&#20043;&#21069;&#30340;&#20004;&#20010;&#26410;&#35299;&#20043;&#35868;&#12290;</title><link>http://arxiv.org/abs/2308.12000</link><description>&lt;p&gt;
&#26377;&#20851;&#22312;&#26377;&#38480;&#39044;&#31639;&#20108;&#33218;&#36172;&#21338;&#26426;&#20013;&#36827;&#34892;&#26368;&#20339;&#33218;&#36873;&#25321;&#30340;&#32479;&#19968;&#26368;&#20248;&#31639;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Uniformly Optimal Algorithms for Best Arm Identification in Two-Armed Bandits with Fixed Budget. (arXiv:2308.12000v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12000
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#39044;&#31639;&#30340;&#38543;&#26426;&#20108;&#33218;&#36172;&#21338;&#26426;&#20013;&#36827;&#34892;&#26368;&#20339;&#33218;&#36873;&#25321;&#30340;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#19981;&#23384;&#22312;&#27604;&#31561;&#27010;&#29575;&#37319;&#26679;&#31639;&#27861;&#26356;&#22909;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#33268;&#31283;&#23450;&#31639;&#27861;&#30340;&#27010;&#24565;&#65292;&#24182;&#35777;&#26126;&#20219;&#20309;&#22312;&#25152;&#26377;&#24773;&#20917;&#19979;&#19982;&#31561;&#27010;&#29575;&#37319;&#26679;&#31639;&#27861;&#34920;&#29616;&#19968;&#26679;&#22909;&#30340;&#31639;&#27861;&#24517;&#39035;&#23646;&#20110;&#36825;&#20010;&#31867;&#21035;&#12290;&#36825;&#19968;&#32467;&#26524;&#35299;&#20915;&#20102;&#20043;&#21069;&#30340;&#20004;&#20010;&#26410;&#35299;&#20043;&#35868;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20855;&#26377;&#20271;&#21162;&#21033;&#22870;&#21169;&#30340;&#38543;&#26426;&#20108;&#33218;&#36172;&#21338;&#26426;&#20013;&#65292;&#20351;&#29992;&#26377;&#38480;&#39044;&#31639;&#36827;&#34892;&#26368;&#20339;&#33218;&#36873;&#25321;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#19981;&#23384;&#22312;&#19968;&#20010;&#31639;&#27861;&#21487;&#20197;&#22312;&#25152;&#26377;&#24773;&#20917;&#19979;&#19982;&#31561;&#27010;&#29575;&#37319;&#26679;&#31639;&#27861;&#34920;&#29616;&#19968;&#26679;&#22909;&#65288;&#35813;&#31639;&#27861;&#34987;&#31216;&#20026;&#8220;&#22343;&#21248;&#37319;&#26679;&#8221;&#31639;&#27861;&#65289;&#65292;&#24182;&#19988;&#22312;&#33267;&#23569;&#19968;&#20010;&#24773;&#20917;&#19979;&#26126;&#26174;&#20248;&#20110;&#35813;&#31639;&#27861;&#12290;&#31616;&#32780;&#35328;&#20043;&#65292;&#19981;&#23384;&#22312;&#27604;&#22343;&#21248;&#37319;&#26679;&#31639;&#27861;&#26356;&#22909;&#30340;&#31639;&#27861;&#12290;&#20026;&#20102;&#35777;&#26126;&#36825;&#19968;&#32467;&#26524;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#8220;&#19968;&#33268;&#8221;&#21644;&#8220;&#31283;&#23450;&#8221;&#31639;&#27861;&#30340;&#33258;&#28982;&#31867;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#20219;&#20309;&#31639;&#27861;&#35201;&#22312;&#25152;&#26377;&#24773;&#20917;&#19979;&#19982;&#22343;&#21248;&#37319;&#26679;&#31639;&#27861;&#34920;&#29616;&#19968;&#26679;&#22909;&#65292;&#24517;&#39035;&#23646;&#20110;&#36825;&#20010;&#31867;&#21035;&#12290;&#36890;&#36807;&#23548;&#20986;&#28385;&#36275;&#20219;&#20309;&#19968;&#33268;&#19988;&#31283;&#23450;&#31639;&#27861;&#30340;&#38169;&#35823;&#29575;&#30340;&#19979;&#30028;&#65292;&#24182;&#35777;&#26126;&#22343;&#21248;&#37319;&#26679;&#31639;&#27861;&#19982;&#27492;&#19979;&#30028;&#30456;&#21305;&#37197;&#65292;&#25105;&#20204;&#23436;&#25104;&#20102;&#35777;&#26126;&#36807;&#31243;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#35299;&#20915;&#20102;\cite{qin2022open}&#20013;&#25552;&#20986;&#30340;&#20004;&#20010;&#26410;&#35299;&#20043;&#35868;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of best-arm identification with fixed budget in stochastic two-arm bandits with Bernoulli rewards. We prove that surprisingly, there is no algorithm that (i) performs as well as the algorithm sampling each arm equally (this algorithm is referred to as the {\it uniform sampling} algorithm) on all instances, and that (ii) strictly outperforms this algorithm on at least one instance. In short, there is no algorithm better than the uniform sampling algorithm. Towards this result, we introduce the natural class of {\it consistent} and {\it stable} algorithms, and show that any algorithm that performs as well as the uniform sampling algorithm on all instances belongs to this class. The proof is completed by deriving a lower bound on the error rate satisfied by any consistent and stable algorithm, and by showing that the uniform sampling algorithm matches this lower bound. Our results provide a solution to the two open problems presented in \cite{qin2022open}.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35843;&#26597;&#20102;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#20998;&#23376;&#22270;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#26367;&#25442;&#22270;&#29983;&#25104;&#27169;&#22411;&#30340;&#22522;&#30784;GNN&#26469;&#36827;&#34892;&#23454;&#39564;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#20351;&#29992;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;GNN&#21487;&#20197;&#25913;&#21892;&#29983;&#25104;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.11978</link><description>&lt;p&gt;
&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#29983;&#25104;&#20219;&#21153;&#20013;&#26159;&#21542;&#26356;&#22909;&#65311;
&lt;/p&gt;
&lt;p&gt;
Will More Expressive Graph Neural Networks do Better on Generative Tasks?. (arXiv:2308.11978v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11978
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35843;&#26597;&#20102;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#20998;&#23376;&#22270;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#26367;&#25442;&#22270;&#29983;&#25104;&#27169;&#22411;&#30340;&#22522;&#30784;GNN&#26469;&#36827;&#34892;&#23454;&#39564;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#20351;&#29992;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;GNN&#21487;&#20197;&#25913;&#21892;&#29983;&#25104;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#29983;&#25104;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#25361;&#25112;&#65292;&#23427;&#28041;&#21450;&#26681;&#25454;&#32473;&#23450;&#30340;&#26631;&#31614;&#39044;&#27979;&#19968;&#20010;&#23436;&#25972;&#30340;&#20855;&#26377;&#22810;&#20010;&#33410;&#28857;&#21644;&#36793;&#30340;&#22270;&#12290;&#36825;&#20010;&#20219;&#21153;&#23545;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#38750;&#24120;&#37325;&#35201;&#65292;&#21253;&#25324;&#33647;&#29289;&#21644;&#20998;&#23376;&#35774;&#35745;&#12290;&#36817;&#24180;&#26469;&#65292;&#22312;&#22270;&#29983;&#25104;&#39046;&#22495;&#20986;&#29616;&#20102;&#20960;&#31181;&#25104;&#21151;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#23384;&#22312;&#20004;&#20010;&#37325;&#22823;&#38382;&#39064;&#65306;(1) &#36825;&#20123;&#26041;&#27861;&#20013;&#20351;&#29992;&#30340;&#22522;&#30784;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26550;&#26500;&#24448;&#24448;&#26410;&#32463;&#28145;&#20837;&#25506;&#32034;&#65307;(2) &#36825;&#20123;&#26041;&#27861;&#24448;&#24448;&#21482;&#22312;&#26377;&#38480;&#30340;&#25351;&#26631;&#19978;&#36827;&#34892;&#35780;&#20272;&#12290;&#20026;&#22635;&#34917;&#36825;&#20010;&#31354;&#30333;&#65292;&#25105;&#20204;&#36890;&#36807;&#23558;&#22270;&#29983;&#25104;&#27169;&#22411;&#30340;&#22522;&#30784;GNN&#26367;&#25442;&#20026;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;GNN&#65292;&#30740;&#31350;&#20102;GNN&#22312;&#20998;&#23376;&#22270;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#33021;&#21147;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#20004;&#31181;&#19981;&#21516;&#29983;&#25104;&#26694;&#26550;&#65288;GCPN&#21644;GraphAF&#65289;&#20013;&#20845;&#31181;GNN&#22312;&#20845;&#20010;&#19981;&#21516;&#30340;&#20998;&#23376;&#29983;&#25104;&#30446;&#26631;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph generation poses a significant challenge as it involves predicting a complete graph with multiple nodes and edges based on simply a given label. This task also carries fundamental importance to numerous real-world applications, including de-novo drug and molecular design. In recent years, several successful methods have emerged in the field of graph generation. However, these approaches suffer from two significant shortcomings: (1) the underlying Graph Neural Network (GNN) architectures used in these methods are often underexplored; and (2) these methods are often evaluated on only a limited number of metrics. To fill this gap, we investigate the expressiveness of GNNs under the context of the molecular graph generation task, by replacing the underlying GNNs of graph generative models with more expressive GNNs. Specifically, we analyse the performance of six GNNs in two different generative frameworks (GCPN and GraphAF), on six different molecular generative objectives on the ZIN
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#35745;&#31639;&#25104;&#26412;&#36739;&#20302;&#30340;&#22238;&#24402;&#27169;&#22411;&#26469;&#36817;&#20284;&#35780;&#20998;&#35299;&#37322;&#25216;&#26415;&#65292;&#24182;&#37319;&#29992;&#24402;&#32435;&#24335;&#31526;&#21512;&#39044;&#27979;&#26694;&#26550;&#25552;&#20379;&#36817;&#20284;&#20540;&#30340;&#26377;&#25928;&#24615;&#20445;&#35777;&#12290;&#23454;&#35777;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#35813;&#26041;&#27861;&#33021;&#26174;&#33879;&#25552;&#21319;&#25191;&#34892;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2308.11975</link><description>&lt;p&gt;
&#20351;&#29992;&#31526;&#21512;&#22238;&#24402;&#26041;&#27861;&#36817;&#20284;&#35780;&#20998;&#35299;&#37322;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Approximating Score-based Explanation Techniques Using Conformal Regression. (arXiv:2308.11975v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11975
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#35745;&#31639;&#25104;&#26412;&#36739;&#20302;&#30340;&#22238;&#24402;&#27169;&#22411;&#26469;&#36817;&#20284;&#35780;&#20998;&#35299;&#37322;&#25216;&#26415;&#65292;&#24182;&#37319;&#29992;&#24402;&#32435;&#24335;&#31526;&#21512;&#39044;&#27979;&#26694;&#26550;&#25552;&#20379;&#36817;&#20284;&#20540;&#30340;&#26377;&#25928;&#24615;&#20445;&#35777;&#12290;&#23454;&#35777;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#35813;&#26041;&#27861;&#33021;&#26174;&#33879;&#25552;&#21319;&#25191;&#34892;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#35780;&#20998;&#30340;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#32463;&#24120;&#34987;&#29992;&#26469;&#29702;&#35299;&#40657;&#30418;&#27169;&#22411;&#32972;&#21518;&#30340;&#36923;&#36753;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#35299;&#37322;&#25216;&#26415;&#36890;&#24120;&#35745;&#31639;&#25104;&#26412;&#39640;&#26114;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#26102;&#38388;&#20851;&#38190;&#29615;&#22659;&#20013;&#30340;&#24212;&#29992;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;&#20351;&#29992;&#35745;&#31639;&#25104;&#26412;&#36739;&#20302;&#30340;&#22238;&#24402;&#27169;&#22411;&#26469;&#36817;&#20284;&#35780;&#20998;&#35299;&#37322;&#25216;&#26415;&#65288;&#22914;SHAP&#65289;&#30340;&#36755;&#20986;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#37319;&#29992;&#24402;&#32435;&#24335;&#31526;&#21512;&#39044;&#27979;&#26694;&#26550;&#25552;&#20379;&#20102;&#36817;&#20284;&#20540;&#30340;&#26377;&#25928;&#24615;&#20445;&#35777;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#20010;&#38750;&#31526;&#21512;&#24230;&#24230;&#37327;&#65292;&#26088;&#22312;&#21516;&#26102;&#32771;&#34385;&#36817;&#20284;&#35299;&#37322;&#30340;&#38590;&#24230;&#21644;&#35745;&#31639;&#25104;&#26412;&#30340;&#20302;&#24265;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#35268;&#27169;&#30340;&#23454;&#35777;&#30740;&#31350;&#65292;&#35780;&#20272;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#27169;&#22411;&#29983;&#25104;&#30340;&#36817;&#20284;&#35299;&#37322;&#30340;&#25928;&#29575;&#65288;&#21306;&#38388;&#22823;&#23567;&#65289;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#26174;&#33879;&#25913;&#21892;&#25191;&#34892;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based explainable machine-learning techniques are often used to understand the logic behind black-box models. However, such explanation techniques are often computationally expensive, which limits their application in time-critical contexts. Therefore, we propose and investigate the use of computationally less costly regression models for approximating the output of score-based explanation techniques, such as SHAP. Moreover, validity guarantees for the approximated values are provided by the employed inductive conformal prediction framework. We propose several non-conformity measures designed to take the difficulty of approximating the explanations into account while keeping the computational cost low. We present results from a large-scale empirical investigation, in which the approximate explanations generated by our proposed models are evaluated with respect to efficiency (interval size). The results indicate that the proposed method can significantly improve execution time com
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26657;&#20934;&#30340;&#22522;&#20934;&#30740;&#31350;&#65292;&#21033;&#29992;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#31354;&#38388;&#25506;&#32034;&#20102;&#27169;&#22411;&#26657;&#20934;&#23646;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#27169;&#22411;&#26657;&#20934;&#21487;&#20197;&#22312;&#19981;&#21516;&#20219;&#21153;&#20013;&#27867;&#21270;&#65292;&#24182;&#21487;&#20197;&#21516;&#26102;&#20860;&#39038;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#26657;&#20934;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.11838</link><description>&lt;p&gt;
&#19968;&#20010;&#20851;&#20110;&#26657;&#20934;&#30340;&#22522;&#20934;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Benchmark Study on Calibration. (arXiv:2308.11838v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11838
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26657;&#20934;&#30340;&#22522;&#20934;&#30740;&#31350;&#65292;&#21033;&#29992;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#31354;&#38388;&#25506;&#32034;&#20102;&#27169;&#22411;&#26657;&#20934;&#23646;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#27169;&#22411;&#26657;&#20934;&#21487;&#20197;&#22312;&#19981;&#21516;&#20219;&#21153;&#20013;&#27867;&#21270;&#65292;&#24182;&#21487;&#20197;&#21516;&#26102;&#20860;&#39038;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#26657;&#20934;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#36234;&#26469;&#36234;&#24191;&#27867;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#36825;&#20123;&#27169;&#22411;&#22797;&#26434;&#24615;&#30340;&#22686;&#21152;&#65292;&#23427;&#20204;&#24448;&#24448;&#38754;&#20020;&#26657;&#20934;&#38382;&#39064;&#65292;&#23613;&#31649;&#39044;&#27979;&#20934;&#30830;&#24615;&#26377;&#25152;&#25552;&#39640;&#12290;&#35768;&#22810;&#30740;&#31350;&#36890;&#36807;&#25968;&#25454;&#39044;&#22788;&#29702;&#12289;&#20351;&#29992;&#29305;&#23450;&#25439;&#22833;&#20989;&#25968;&#21644;&#35757;&#32451;&#26694;&#26550;&#26469;&#25913;&#21892;&#26657;&#20934;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#23545;&#26657;&#20934;&#23646;&#24615;&#30340;&#30740;&#31350;&#26377;&#28857;&#34987;&#24573;&#35270;&#20102;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21033;&#29992;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#65288;NAS&#65289;&#25628;&#32034;&#31354;&#38388;&#65292;&#22312;&#20840;&#38754;&#25506;&#32034;&#26657;&#20934;&#23646;&#24615;&#30340;&#27169;&#22411;&#26550;&#26500;&#31354;&#38388;&#20013;&#25552;&#20379;&#20102;&#19968;&#20010;&#35814;&#23613;&#30340;&#27169;&#22411;&#26550;&#26500;&#31354;&#38388;&#12290;&#25105;&#20204;&#29305;&#21035;&#21019;&#24314;&#20102;&#19968;&#20010;&#27169;&#22411;&#26657;&#20934;&#25968;&#25454;&#38598;&#12290;&#35813;&#25968;&#25454;&#38598;&#22312;&#24191;&#27867;&#20351;&#29992;&#30340;NATS-Bench&#25628;&#32034;&#31354;&#38388;&#20013;&#35780;&#20272;&#20102;90&#20010;&#22522;&#20110;&#21306;&#38388;&#30340;&#26657;&#20934;&#24230;&#37327;&#21644;12&#20010;&#20854;&#20182;&#26657;&#20934;&#24230;&#37327;&#65292;&#28085;&#30422;&#20102;117,702&#20010;&#29420;&#29305;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#26088;&#22312;&#36890;&#36807;&#25105;&#20204;&#25552;&#20986;&#30340;&#25968;&#25454;&#38598;&#22238;&#31572;&#35813;&#39046;&#22495;&#19968;&#20123;&#38271;&#26399;&#23384;&#22312;&#30340;&#38382;&#39064;&#65306;&#65288;i&#65289;&#27169;&#22411;&#26657;&#20934;&#33021;&#21542;&#22312;&#19981;&#21516;&#20219;&#21153;&#20013;&#27867;&#21270;&#65311;&#65288;ii&#65289;&#33021;&#21542;&#21516;&#26102;&#20860;&#39038;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#26657;&#20934;&#24615;&#33021;&#65311;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks are increasingly utilized in various machine learning tasks. However, as these models grow in complexity, they often face calibration issues, despite enhanced prediction accuracy. Many studies have endeavored to improve calibration performance through data preprocessing, the use of specific loss functions, and training frameworks. Yet, investigations into calibration properties have been somewhat overlooked. Our study leverages the Neural Architecture Search (NAS) search space, offering an exhaustive model architecture space for thorough calibration properties exploration. We specifically create a model calibration dataset. This dataset evaluates 90 bin-based and 12 additional calibration measurements across 117,702 unique neural networks within the widely employed NATS-Bench search space. Our analysis aims to answer several longstanding questions in the field, using our proposed dataset: (i) Can model calibration be generalized across different tasks? (ii) Can rob
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#36866;&#24212;&#25968;&#25454;&#20998;&#24067;&#28418;&#31227;&#30340;&#36830;&#32493;&#23398;&#20064;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#21033;&#29992;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26469;&#20943;&#36731;&#28798;&#38590;&#24615;&#36951;&#24536;&#12290;&#36890;&#36807;&#20256;&#25773;&#20998;&#24067;&#30340;&#21069;&#20004;&#20010;&#30697;&#26469;&#20248;&#21270;&#38381;&#24335;ELBO&#30446;&#26631;&#65292;&#20174;&#32780;&#36817;&#20284;&#39044;&#27979;&#20998;&#24067;&#12290;&#36825;&#31181;&#26041;&#27861;&#28040;&#38500;&#20102;Monte Carlo&#37319;&#26679;&#30340;&#38656;&#35201;&#65292;&#26377;&#25928;&#24809;&#32602;&#27169;&#22411;&#20284;&#28982;&#24615;&#30340;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2308.11801</link><description>&lt;p&gt;
&#21464;&#20998;&#23494;&#24230;&#20256;&#25773;&#36830;&#32493;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Variational Density Propagation Continual Learning. (arXiv:2308.11801v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11801
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#36866;&#24212;&#25968;&#25454;&#20998;&#24067;&#28418;&#31227;&#30340;&#36830;&#32493;&#23398;&#20064;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#21033;&#29992;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26469;&#20943;&#36731;&#28798;&#38590;&#24615;&#36951;&#24536;&#12290;&#36890;&#36807;&#20256;&#25773;&#20998;&#24067;&#30340;&#21069;&#20004;&#20010;&#30697;&#26469;&#20248;&#21270;&#38381;&#24335;ELBO&#30446;&#26631;&#65292;&#20174;&#32780;&#36817;&#20284;&#39044;&#27979;&#20998;&#24067;&#12290;&#36825;&#31181;&#26041;&#27861;&#28040;&#38500;&#20102;Monte Carlo&#37319;&#26679;&#30340;&#38656;&#35201;&#65292;&#26377;&#25928;&#24809;&#32602;&#27169;&#22411;&#20284;&#28982;&#24615;&#30340;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#37096;&#32626;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#32463;&#24120;&#38754;&#20020;&#26469;&#33258;&#20998;&#24067;&#22806;&#65288;OoD&#65289;&#25968;&#25454;&#12289;&#21508;&#31181;&#31867;&#22411;&#30340;&#22122;&#22768;&#21644;&#27010;&#24565;&#30446;&#26631;&#30340;&#21464;&#21270;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#24212;&#22522;&#20934;&#36830;&#32493;&#23398;&#20064;&#25968;&#25454;&#38598;&#24314;&#27169;&#30340;&#25968;&#25454;&#20998;&#24067;&#28418;&#31227;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#24320;&#21457;&#21644;&#35780;&#20272;&#20102;&#19968;&#31181;&#21033;&#29992;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26469;&#20943;&#36731;&#28798;&#38590;&#24615;&#36951;&#24536;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#28040;&#38500;&#27169;&#22411;&#26435;&#37325;&#30340;Monte Carlo&#37319;&#26679;&#26469;&#37319;&#26679;&#39044;&#27979;&#20998;&#24067;&#65292;&#25193;&#23637;&#20102;&#20043;&#21069;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#25152;&#26377;&#32593;&#32476;&#23618;&#20013;&#20256;&#25773;&#20998;&#24067;&#30340;&#21069;&#20004;&#20010;&#30697;&#65288;&#21363;&#22343;&#20540;&#21644;&#21327;&#26041;&#24046;&#65289;&#26469;&#20248;&#21270;&#38381;&#24335;&#35777;&#25454;&#19979;&#30028;&#65288;ELBO&#65289;&#30446;&#26631;&#65292;&#20174;&#32780;&#36817;&#20284;&#39044;&#27979;&#20998;&#24067;&#12290;&#36890;&#36807;&#20351;&#29992;&#38381;&#24335;ELBO&#26469;&#36817;&#20284;&#26368;&#23567;&#25551;&#36848;&#38271;&#24230;&#65288;MDL&#65289;&#21407;&#21017;&#26469;&#32531;&#35299;&#28798;&#38590;&#24615;&#36951;&#24536;&#65292;&#20174;&#32780;&#24809;&#32602;&#27169;&#22411;&#20284;&#28982;&#24615;&#30340;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Neural Networks (DNNs) deployed to the real world are regularly subject to out-of-distribution (OoD) data, various types of noise, and shifting conceptual objectives. This paper proposes a framework for adapting to data distribution drift modeled by benchmark Continual Learning datasets. We develop and evaluate a method of Continual Learning that leverages uncertainty quantification from Bayesian Inference to mitigate catastrophic forgetting. We expand on previous approaches by removing the need for Monte Carlo sampling of the model weights to sample the predictive distribution. We optimize a closed-form Evidence Lower Bound (ELBO) objective approximating the predictive distribution by propagating the first two moments of a distribution, i.e. mean and covariance, through all network layers. Catastrophic forgetting is mitigated by using the closed-form ELBO to approximate the Minimum Description Length (MDL) Principle, inherently penalizing changes in the model likelihood by minimi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#24191;&#20041;&#30340;Sinkhorn&#31639;&#27861;&#65292;&#36890;&#36807;&#23545;&#19981;&#23450;&#31526;&#21495;&#30340;&#22810;&#32500;&#25968;&#32452;&#36827;&#34892;&#26356;&#26032;&#65292;&#20351;&#20854;&#19982;&#32473;&#23450;&#30340;&#36793;&#38469;&#19968;&#33268;&#65292;&#20174;&#32780;&#26657;&#20934;&#24102;&#31526;&#21495;&#30340;&#25968;&#25454;&#38598;&#12290;&#36825;&#20010;&#31639;&#27861;&#22312;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2308.11791</link><description>&lt;p&gt;
&#25968;&#25454;&#21516;&#21270;&#30340;&#24191;&#20041;Sinkhorn&#31639;&#27861;: &#38024;&#23545;&#19981;&#23450;&#31526;&#21495;&#20808;&#39564;&#30340;&#25299;&#23637;
&lt;/p&gt;
&lt;p&gt;
Data Assimilation for Sign-indefinite Priors: A generalization of Sinkhorn's algorithm. (arXiv:2308.11791v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11791
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#24191;&#20041;&#30340;Sinkhorn&#31639;&#27861;&#65292;&#36890;&#36807;&#23545;&#19981;&#23450;&#31526;&#21495;&#30340;&#22810;&#32500;&#25968;&#32452;&#36827;&#34892;&#26356;&#26032;&#65292;&#20351;&#20854;&#19982;&#32473;&#23450;&#30340;&#36793;&#38469;&#19968;&#33268;&#65292;&#20174;&#32780;&#26657;&#20934;&#24102;&#31526;&#21495;&#30340;&#25968;&#25454;&#38598;&#12290;&#36825;&#20010;&#31639;&#27861;&#22312;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#21457;&#23637;&#19968;&#20010;&#26694;&#26550;&#65292;&#36890;&#36807;&#36866;&#24403;&#25193;&#23637;Schr\"odinger-Fortet-Sinkhorn&#27169;&#22411;&#65292;&#26657;&#20934;&#24102;&#31526;&#21495;&#30340;&#25968;&#25454;&#38598;&#65292;&#20351;&#20854;&#19982;&#25351;&#23450;&#30340;&#36793;&#38469;&#19968;&#33268;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35797;&#22270;&#20197;&#19982;&#25351;&#23450;&#36793;&#38469;&#19968;&#33268;&#30340;&#26041;&#24335;&#20462;&#25913;&#19981;&#23450;&#31526;&#21495;&#30340;&#22810;&#32500;&#25968;&#32452;&#20013;&#30340;&#20540;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36981;&#24490;Schr\"odinger&#38382;&#39064;&#20013;&#30340;&#24605;&#36335;&#65292;&#26088;&#22312;&#23558;&#8220;&#20808;&#39564;&#8221;&#27010;&#29575;&#27979;&#24230;&#26356;&#26032;&#20026;&#19982;&#36793;&#38469;&#20998;&#24067;&#19968;&#33268;&#12290;&#33879;&#21517;&#30340;Sinkhorn&#31639;&#27861;&#65288;&#30001;R.\ Fortet&#26089;&#26399;&#24314;&#31435;&#65289;&#26366;&#22312;&#32479;&#35745;&#23398;&#20013;&#26657;&#20934;&#21015;&#32852;&#34920;&#21644;&#26368;&#36817;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#26368;&#20248;&#36816;&#36755;&#20013;&#30340;&#22810;&#36793;&#38469;&#38382;&#39064;&#20013;&#24471;&#21040;&#24212;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20551;&#35774;&#19968;&#20010;&#20197;&#22810;&#32500;&#25968;&#32452;&#24418;&#24335;&#30340;&#19981;&#23450;&#31526;&#21495;&#20808;&#39564;&#65292;&#24182;&#25552;&#20986;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#26469;&#36866;&#24403;&#26356;&#26032;&#35813;&#20808;&#39564;&#65292;&#20197;&#30830;&#20445;&#19982;&#32473;&#23450;&#36793;&#38469;&#19968;&#33268;&#12290;&#25152;&#24471;&#31639;&#27861;&#32473;&#20986;&#20102;Sinkhorn&#31639;&#27861;&#30340;&#25512;&#24191;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
The purpose of this work is to develop a framework to calibrate signed datasets so as to be consistent with specified marginals by suitably extending the Schr\"odinger-Fortet-Sinkhorn paradigm. Specifically, we seek to revise sign-indefinite multi-dimensional arrays in a way that the updated values agree with specified marginals. Our approach follows the rationale in Schr\"odinger's problem, aimed at updating a "prior" probability measure to agree with marginal distributions. The celebrated Sinkhorn's algorithm (established earlier by R.\ Fortet) that solves Schr\"odinger's problem found early applications in calibrating contingency tables in statistics and, more recently, multi-marginal problems in machine learning and optimal transport. Herein, we postulate a sign-indefinite prior in the form of a multi-dimensional array, and propose an optimization problem to suitably update this prior to ensure consistency with given marginals. The resulting algorithm generalizes the Sinkhorn algor
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#20998;&#26512;&#20998;&#31867;&#22120;&#30340;Hessian&#30697;&#38453;&#21644;&#26799;&#24230;&#22312;&#39046;&#22495;&#27867;&#21270;&#20013;&#30340;&#20316;&#29992;&#65292;&#21457;&#29616;&#20102;&#36328;&#39046;&#22495;&#30340;Hessian&#30697;&#38453;&#20043;&#38388;&#30340;&#35889;&#33539;&#25968;&#26159;&#20256;&#36755;&#24230;&#37327;&#30340;&#19978;&#30028;&#65292;&#24182;&#20998;&#26512;&#20102;&#22312;&#40723;&#21169;Hessian&#21644;&#26799;&#24230;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#26102;&#30340;&#25152;&#26377;&#23545;&#40784;&#23646;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.11778</link><description>&lt;p&gt;
&#29702;&#35299;Hessian&#23545;&#39046;&#22495;&#27867;&#21270;&#30340;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Understanding Hessian Alignment for Domain Generalization. (arXiv:2308.11778v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11778
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#20998;&#26512;&#20998;&#31867;&#22120;&#30340;Hessian&#30697;&#38453;&#21644;&#26799;&#24230;&#22312;&#39046;&#22495;&#27867;&#21270;&#20013;&#30340;&#20316;&#29992;&#65292;&#21457;&#29616;&#20102;&#36328;&#39046;&#22495;&#30340;Hessian&#30697;&#38453;&#20043;&#38388;&#30340;&#35889;&#33539;&#25968;&#26159;&#20256;&#36755;&#24230;&#37327;&#30340;&#19978;&#30028;&#65292;&#24182;&#20998;&#26512;&#20102;&#22312;&#40723;&#21169;Hessian&#21644;&#26799;&#24230;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#26102;&#30340;&#25152;&#26377;&#23545;&#40784;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;&#21253;&#25324;&#21307;&#30103;&#20445;&#20581;&#21644;&#33258;&#21160;&#39550;&#39542;&#65292;&#36229;&#20986;&#20998;&#24067;&#65288;OOD&#65289;&#27867;&#21270;&#26159;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#20851;&#38190;&#33021;&#21147;&#12290;&#26368;&#36817;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#19981;&#21516;&#30340;&#25216;&#26415;&#26469;&#25913;&#36827;OOD&#27867;&#21270;&#12290;&#22312;&#36825;&#20123;&#26041;&#27861;&#20013;&#65292;&#22522;&#20110;&#26799;&#24230;&#30340;&#27491;&#21017;&#21270;&#22120;&#19982;&#20854;&#20182;&#31454;&#20105;&#23545;&#25163;&#30456;&#27604;&#26174;&#31034;&#20986;&#26377;&#24076;&#26395;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#36825;&#26679;&#30340;&#25104;&#21151;&#65292;&#25105;&#20204;&#23545;Hessian&#21644;&#26799;&#24230;&#23545;&#39046;&#22495;&#27867;&#21270;&#30340;&#20316;&#29992;&#30340;&#35748;&#35782;&#20173;&#28982;&#26377;&#38480;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#32570;&#28857;&#65292;&#25105;&#20204;&#20351;&#29992;&#26368;&#36817;&#30340;OOD&#36716;&#31227;&#24615;&#29702;&#35770;&#20998;&#26512;&#20102;&#20998;&#31867;&#22120;&#22836;&#37096;Hessian&#30697;&#38453;&#21644;&#26799;&#24230;&#22312;&#39046;&#22495;&#27867;&#21270;&#20013;&#30340;&#20316;&#29992;&#12290;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#36328;&#39046;&#22495;&#30340;&#20998;&#31867;&#22120;&#22836;&#37096;Hessian&#30697;&#38453;&#20043;&#38388;&#30340;&#35889;&#33539;&#25968;&#26159;&#20256;&#36755;&#24230;&#37327;&#30340;&#19978;&#30028;&#65292;&#20256;&#36755;&#24230;&#37327;&#26159;&#30446;&#26631;&#39046;&#22495;&#21644;&#28304;&#39046;&#22495;&#20043;&#38388;&#30340;&#36317;&#31163;&#30340;&#27010;&#24565;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#22312;&#40723;&#21169;Hessian&#21644;&#26799;&#24230;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#26102;&#25152;&#26377;&#30340;&#23545;&#40784;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Out-of-distribution (OOD) generalization is a critical ability for deep learning models in many real-world scenarios including healthcare and autonomous vehicles. Recently, different techniques have been proposed to improve OOD generalization. Among these methods, gradient-based regularizers have shown promising performance compared with other competitors. Despite this success, our understanding of the role of Hessian and gradient alignment in domain generalization is still limited. To address this shortcoming, we analyze the role of the classifier's head Hessian matrix and gradient in domain generalization using recent OOD theory of transferability. Theoretically, we show that spectral norm between the classifier's head Hessian matrices across domains is an upper bound of the transfer measure, a notion of distance between target and source domains. Furthermore, we analyze all the attributes that get aligned when we encourage similarity between Hessians and gradients. Our analysis expl
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20223;&#30495;&#30340;&#20808;&#39564;&#30693;&#35782;&#24341;&#23548;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#39046;&#22495;&#19987;&#23478;&#30340;&#30693;&#35782;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#21046;&#23450;&#19982;&#19987;&#23478;&#39044;&#26399;&#19968;&#33268;&#30340;&#27169;&#22411;&#21442;&#25968;&#20808;&#39564;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2308.11672</link><description>&lt;p&gt;
&#22522;&#20110;&#20223;&#30495;&#30340;&#20808;&#39564;&#30693;&#35782;&#24341;&#23548;&#21442;&#25968;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Simulation-Based Prior Knowledge Elicitation for Parametric Bayesian Models. (arXiv:2308.11672v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11672
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20223;&#30495;&#30340;&#20808;&#39564;&#30693;&#35782;&#24341;&#23548;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#39046;&#22495;&#19987;&#23478;&#30340;&#30693;&#35782;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#21046;&#23450;&#19982;&#19987;&#23478;&#39044;&#26399;&#19968;&#33268;&#30340;&#27169;&#22411;&#21442;&#25968;&#20808;&#39564;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#32479;&#35745;&#23398;&#30340;&#19968;&#20010;&#20851;&#38190;&#29305;&#28857;&#26159;&#33021;&#22815;&#23558;&#20808;&#39564;&#30693;&#35782;&#19968;&#33268;&#22320;&#32435;&#20837;&#21508;&#31181;&#24314;&#27169;&#36807;&#31243;&#20013;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20851;&#27880;&#23558;&#39046;&#22495;&#19987;&#23478;&#30693;&#35782;&#36716;&#21270;&#20026;&#30456;&#24212;&#30340;&#27169;&#22411;&#21442;&#25968;&#20808;&#39564;&#20998;&#24067;&#30340;&#36807;&#31243;&#65292;&#21363;&#20808;&#39564;&#24341;&#23548;&#12290;&#19987;&#23478;&#30693;&#35782;&#21487;&#20197;&#20855;&#20307;&#34920;&#29616;&#20026;&#21407;&#22987;&#25968;&#25454;&#12289;&#25688;&#35201;&#32479;&#35745;&#20449;&#24687;&#25110;&#27169;&#22411;&#21442;&#25968;&#30340;&#20449;&#24687;&#31561;&#22810;&#31181;&#26684;&#24335;&#12290;&#29616;&#26377;&#30340;&#24341;&#23548;&#26041;&#27861;&#38754;&#20020;&#30340;&#20027;&#35201;&#25361;&#25112;&#26159;&#22914;&#20309;&#26377;&#25928;&#22320;&#21033;&#29992;&#25152;&#26377;&#36825;&#20123;&#19981;&#21516;&#30340;&#26684;&#24335;&#65292;&#20197;&#21046;&#23450;&#19982;&#19987;&#23478;&#39044;&#26399;&#19968;&#33268;&#30340;&#20808;&#39564;&#20998;&#24067;&#65292;&#32780;&#19981;&#21463;&#27169;&#22411;&#32467;&#26500;&#30340;&#24433;&#21709;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#20223;&#30495;&#30340;&#24341;&#23548;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20174;&#24191;&#27867;&#30340;&#19987;&#23478;&#30693;&#35782;&#20013;&#23398;&#20064;&#21487;&#33021;&#30340;&#20219;&#20309;&#21442;&#25968;&#21270;&#20808;&#39564;&#20998;&#24067;&#30340;&#36229;&#21442;&#25968;&#12290;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#24341;&#23548;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
A central characteristic of Bayesian statistics is the ability to consistently incorporate prior knowledge into various modeling processes. In this paper, we focus on translating domain expert knowledge into corresponding prior distributions over model parameters, a process known as prior elicitation. Expert knowledge can manifest itself in diverse formats, including information about raw data, summary statistics, or model parameters. A major challenge for existing elicitation methods is how to effectively utilize all of these different formats in order to formulate prior distributions that align with the expert's expectations, regardless of the model structure. To address these challenges, we develop a simulation-based elicitation method that can learn the hyperparameters of potentially any parametric prior distribution from a wide spectrum of expert knowledge using stochastic gradient descent. We validate the effectiveness and robustness of our elicitation method in four representati
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#31163;&#25955;&#20248;&#21270;&#26041;&#27861;&#26469;&#35299;&#20915;&#21387;&#32553;&#24863;&#30693;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#22312;&#20108;&#27425;&#38181;&#26494;&#24347;&#19979;&#65292;&#21487;&#20197;&#25214;&#21040;&#26368;&#31232;&#30095;&#30340;&#21521;&#37327;&#65292;&#24471;&#21040;&#20102;&#21487;&#38752;&#30340;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2306.04647</link><description>&lt;p&gt;
&#21387;&#32553;&#24863;&#30693;&#65306;&#31163;&#25955;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Compressed Sensing: A Discrete Optimization Approach. (arXiv:2306.04647v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04647
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#31163;&#25955;&#20248;&#21270;&#26041;&#27861;&#26469;&#35299;&#20915;&#21387;&#32553;&#24863;&#30693;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#22312;&#20108;&#27425;&#38181;&#26494;&#24347;&#19979;&#65292;&#21487;&#20197;&#25214;&#21040;&#26368;&#31232;&#30095;&#30340;&#21521;&#37327;&#65292;&#24471;&#21040;&#20102;&#21487;&#38752;&#30340;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21387;&#32553;&#24863;&#30693;&#38382;&#39064;&#65292;&#21363;&#25214;&#21040;&#26368;&#31232;&#30095;&#30340;&#21521;&#37327;&#65292;&#35813;&#21521;&#37327;&#28385;&#36275;&#19968;&#32452;&#32447;&#24615;&#27979;&#37327;&#65292;&#21516;&#26102;&#36798;&#21040;&#19968;&#23450;&#30340;&#25968;&#20540;&#23481;&#38480;&#12290;&#21387;&#32553;&#24863;&#30693;&#26159;&#32479;&#35745;&#23398;&#12289;&#36816;&#31609;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#26680;&#24515;&#38382;&#39064;&#65292;&#24212;&#29992;&#20110;&#20449;&#21495;&#22788;&#29702;&#12289;&#25968;&#25454;&#21387;&#32553;&#21644;&#22270;&#20687;&#37325;&#24314;&#31561;&#39046;&#22495;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#24102;&#26377;$\ell_2$&#27491;&#21017;&#21270;&#30340;&#21387;&#32553;&#24863;&#30693;&#38382;&#39064;&#65292;&#23558;&#20854;&#20316;&#20026;&#28151;&#21512;&#25972;&#25968;&#20108;&#27425;&#38181;&#35268;&#21010;&#26469;&#37325;&#26032;&#23450;&#20041;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#27492;&#38382;&#39064;&#30340;&#20108;&#27425;&#38181;&#26494;&#24347;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#27491;&#21017;&#21270;&#21442;&#25968;&#30340;&#28201;&#21644;&#38480;&#21046;&#19979;&#65292;&#24471;&#21040;&#30340;&#26494;&#24347;&#31561;&#20215;&#20110;&#28145;&#20837;&#30740;&#31350;&#30340;&#22522;&#30784;&#36861;&#36394;&#21435;&#22122;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21322;&#23450;&#26494;&#24347;&#26469;&#21152;&#24378;&#20108;&#27425;&#38181;&#26494;&#24347;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#23450;&#21046;&#30340;&#20998;&#25903;&#23450;&#30028;&#31639;&#27861;&#65292;&#21033;&#29992;&#25105;&#20204;&#30340;&#20108;&#27425;&#38181;&#26494;&#24347;&#26469;&#35299;&#20915;&#21387;&#32553;&#24863;&#30693;&#38382;&#39064;&#30340;&#23454;&#20363;&#65292;&#20197;&#30830;&#35777;&#30340;&#26368;&#20248;&#35299;&#12290;&#25105;&#20204;&#30340;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20135;&#29983;&#30340;&#35299;&#20915;&#26041;&#26696;&#26159;&#31934;&#30830;&#30340;&#65292;&#24182;&#19988;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the Compressed Sensing (CS) problem, which is the problem of finding the most sparse vector that satisfies a set of linear measurements up to some numerical tolerance. CS is a central problem in Statistics, Operations Research and Machine Learning which arises in applications such as signal processing, data compression and image reconstruction. We introduce an $\ell_2$ regularized formulation of CS which we reformulate as a mixed integer second order cone program. We derive a second order cone relaxation of this problem and show that under mild conditions on the regularization parameter, the resulting relaxation is equivalent to the well studied basis pursuit denoising problem. We present a semidefinite relaxation that strengthens the second order cone relaxation and develop a custom branch-and-bound algorithm that leverages our second order cone relaxation to solve instances of CS to certifiable optimality. Our numerical results show that our approach produces solutions that 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#22312;&#23384;&#22312;&#38750;&#39640;&#26031;&#22122;&#22768;&#24773;&#20917;&#19979;&#22833;&#25928;&#30340;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21363;&#36890;&#36807;&#21516;&#26102;&#35757;&#32451;&#19968;&#20010;&#33021;&#37327;&#27169;&#22411;&#26469;&#23398;&#20064;&#27491;&#30830;&#30340;&#22122;&#22768;&#20998;&#24067;&#12290;&#36890;&#36807;&#22810;&#20010;&#20363;&#23376;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#25913;&#36827;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2211.15498</link><description>&lt;p&gt;
&#20855;&#26377;&#26410;&#30693;&#27979;&#37327;&#22122;&#22768;&#30340;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Physics-informed neural networks with unknown measurement noise. (arXiv:2211.15498v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.15498
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#22312;&#23384;&#22312;&#38750;&#39640;&#26031;&#22122;&#22768;&#24773;&#20917;&#19979;&#22833;&#25928;&#30340;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21363;&#36890;&#36807;&#21516;&#26102;&#35757;&#32451;&#19968;&#20010;&#33021;&#37327;&#27169;&#22411;&#26469;&#23398;&#20064;&#27491;&#30830;&#30340;&#22122;&#22768;&#20998;&#24067;&#12290;&#36890;&#36807;&#22810;&#20010;&#20363;&#23376;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#25913;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;(PINNs)&#26159;&#19968;&#31181;&#26082;&#33021;&#25214;&#21040;&#35299;&#20915;&#26041;&#26696;&#21448;&#33021;&#35782;&#21035;&#20559;&#24494;&#20998;&#26041;&#31243;&#21442;&#25968;&#30340;&#28789;&#27963;&#26041;&#27861;&#12290;&#22823;&#22810;&#25968;&#30456;&#20851;&#30340;&#30740;&#31350;&#37117;&#20551;&#35774;&#25968;&#25454;&#26159;&#26080;&#22122;&#22768;&#30340;&#65292;&#25110;&#32773;&#26159;&#21463;&#24369;&#39640;&#26031;&#22122;&#22768;&#27745;&#26579;&#30340;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26631;&#20934;PINN&#26694;&#26550;&#22312;&#38750;&#39640;&#26031;&#22122;&#22768;&#24773;&#20917;&#19979;&#22833;&#25928;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#36825;&#20010;&#26681;&#26412;&#24615;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21363;&#21516;&#26102;&#35757;&#32451;&#19968;&#20010;&#33021;&#37327;&#27169;&#22411;(Energy-Based Model, EBM)&#26469;&#23398;&#20064;&#27491;&#30830;&#30340;&#22122;&#22768;&#20998;&#24067;&#12290;&#25105;&#20204;&#36890;&#36807;&#22810;&#20010;&#20363;&#23376;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#25913;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Physics-informed neural networks (PINNs) constitute a flexible approach to both finding solutions and identifying parameters of partial differential equations. Most works on the topic assume noiseless data, or data contaminated by weak Gaussian noise. We show that the standard PINN framework breaks down in case of non-Gaussian noise. We give a way of resolving this fundamental issue and we propose to jointly train an energy-based model (EBM) to learn the correct noise distribution. We illustrate the improved performance of our approach using multiple examples.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22797;&#26434;&#27169;&#22411;&#20013;&#36827;&#34892;&#21464;&#20998;&#25512;&#26029;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#28982;&#26799;&#24230;&#26356;&#26032;&#21644;&#40654;&#26364;&#27969;&#24418;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#39640;&#26031;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#24182;&#39564;&#35777;&#20102;&#20854;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2210.14598</link><description>&lt;p&gt;
&#30830;&#20999;&#30340;&#27969;&#24418;&#39640;&#26031;&#21464;&#20998;&#36125;&#21494;&#26031;
&lt;/p&gt;
&lt;p&gt;
Exact Manifold Gaussian Variational Bayes. (arXiv:2210.14598v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.14598
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22797;&#26434;&#27169;&#22411;&#20013;&#36827;&#34892;&#21464;&#20998;&#25512;&#26029;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#28982;&#26799;&#24230;&#26356;&#26032;&#21644;&#40654;&#26364;&#27969;&#24418;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#39640;&#26031;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#24182;&#39564;&#35777;&#20102;&#20854;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22797;&#26434;&#27169;&#22411;&#20013;&#21464;&#20998;&#25512;&#26029;&#65288;VI&#65289;&#30340;&#20248;&#21270;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#33258;&#28982;&#26799;&#24230;&#26356;&#26032;&#65292;&#20854;&#20013;&#21464;&#20998;&#31354;&#38388;&#26159;&#19968;&#20010;&#40654;&#26364;&#27969;&#24418;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#39640;&#26031;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#20197;&#38544;&#24335;&#28385;&#36275;&#21464;&#20998;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#27491;&#23450;&#32422;&#26463;&#12290;&#25105;&#20204;&#30340;&#30830;&#20999;&#27969;&#24418;&#39640;&#26031;&#21464;&#20998;&#36125;&#21494;&#26031;&#65288;EMGVB&#65289;&#25552;&#20379;&#20102;&#31934;&#30830;&#20294;&#31616;&#21333;&#30340;&#26356;&#26032;&#35268;&#21017;&#65292;&#24182;&#19988;&#26131;&#20110;&#23454;&#29616;&#12290;&#30001;&#20110;&#20854;&#40657;&#30418;&#24615;&#36136;&#65292;EMGVB&#25104;&#20026;&#22797;&#26434;&#27169;&#22411;&#20013;&#21363;&#25554;&#21363;&#29992;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#36890;&#36807;&#22312;&#19981;&#21516;&#32479;&#35745;&#12289;&#35745;&#37327;&#21644;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#19978;&#20351;&#29992;&#20116;&#20010;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#23545;&#25105;&#20204;&#30340;&#21487;&#34892;&#24615;&#26041;&#27861;&#36827;&#34892;&#20102;&#23454;&#35777;&#39564;&#35777;&#65292;&#24182;&#19982;&#22522;&#20934;&#26041;&#27861;&#36827;&#34892;&#20102;&#24615;&#33021;&#35752;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an optimization algorithm for Variational Inference (VI) in complex models. Our approach relies on natural gradient updates where the variational space is a Riemann manifold. We develop an efficient algorithm for Gaussian Variational Inference that implicitly satisfies the positive definite constraint on the variational covariance matrix. Our Exact manifold Gaussian Variational Bayes (EMGVB) provides exact but simple update rules and is straightforward to implement. Due to its black-box nature, EMGVB stands as a ready-to-use solution for VI in complex models. Over five datasets, we empirically validate our feasible approach on different statistical, econometric, and deep learning models, discussing its performance with respect to baseline methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#30340;ProtoBandit&#31639;&#27861;&#36890;&#36807;&#22810;&#33218;&#36172;&#21338;&#26426;&#26041;&#27861;&#23454;&#29616;&#39640;&#25928;&#30340;&#21407;&#22411;&#36873;&#25321;&#65292;&#36991;&#20813;&#20102;&#22312;&#22823;&#35268;&#27169;&#35774;&#32622;&#19979;&#36827;&#34892;&#30456;&#20284;&#24615;&#27604;&#36739;&#30340;&#26114;&#36149;&#24615;&#65292;&#33021;&#22815;&#35782;&#21035;&#20986;&#19968;&#32452;&#32039;&#20945;&#30340;&#21407;&#22411;&#23454;&#20363;&#65292;&#26377;&#25928;&#20195;&#34920;&#32473;&#23450;&#30340;&#30446;&#26631;&#38598;&#12290;</title><link>http://arxiv.org/abs/2210.01860</link><description>&lt;p&gt;
ProtoBandit: &#36890;&#36807;&#22810;&#33218;&#36172;&#21338;&#26426;&#23454;&#29616;&#39640;&#25928;&#21407;&#22411;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
ProtoBandit: Efficient Prototype Selection via Multi-Armed Bandits. (arXiv:2210.01860v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.01860
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#30340;ProtoBandit&#31639;&#27861;&#36890;&#36807;&#22810;&#33218;&#36172;&#21338;&#26426;&#26041;&#27861;&#23454;&#29616;&#39640;&#25928;&#30340;&#21407;&#22411;&#36873;&#25321;&#65292;&#36991;&#20813;&#20102;&#22312;&#22823;&#35268;&#27169;&#35774;&#32622;&#19979;&#36827;&#34892;&#30456;&#20284;&#24615;&#27604;&#36739;&#30340;&#26114;&#36149;&#24615;&#65292;&#33021;&#22815;&#35782;&#21035;&#20986;&#19968;&#32452;&#32039;&#20945;&#30340;&#21407;&#22411;&#23454;&#20363;&#65292;&#26377;&#25928;&#20195;&#34920;&#32473;&#23450;&#30340;&#30446;&#26631;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#20174;&#28304;&#25968;&#25454;&#38598;S&#20013;&#35782;&#21035;&#19968;&#32452;&#32039;&#20945;&#30340;&#20449;&#24687;&#25968;&#25454;&#23454;&#20363;&#65288;&#21363;&#21407;&#22411;&#65289;&#65292;&#20197;&#26368;&#22909;&#22320;&#20195;&#34920;&#32473;&#23450;&#30340;&#30446;&#26631;&#38598;T&#12290;&#32473;&#23450;&#25968;&#25454;&#38598;&#30340;&#21407;&#22411;&#31034;&#20363;&#25552;&#20379;&#20102;&#23545;&#24213;&#23618;&#25968;&#25454;&#20998;&#24067;&#30340;&#21487;&#35299;&#37322;&#24615;&#27934;&#23519;&#65292;&#24182;&#22312;&#22522;&#20110;&#23454;&#20363;&#30340;&#25512;&#29702;&#20013;&#36215;&#21040;&#36741;&#21161;&#20316;&#29992;&#65292;&#20174;&#32780;&#24433;&#21709;&#20154;&#31867;&#20915;&#31574;&#30340;&#21508;&#20010;&#39046;&#22495;&#12290;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#21407;&#22411;&#36873;&#25321;&#26041;&#27861;&#38656;&#35201;&#22312;&#28304;&#25968;&#25454;&#28857;&#21644;&#30446;&#26631;&#25968;&#25454;&#28857;&#20043;&#38388;&#36827;&#34892;O&#65288;|S| |T|&#65289;&#30340;&#30456;&#20284;&#24615;&#27604;&#36739;&#65292;&#23545;&#20110;&#22823;&#35268;&#27169;&#35774;&#32622;&#26469;&#35828;&#26174;&#24471;&#38590;&#20197;&#25215;&#21463;&#12290;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#22312;&#21407;&#22411;&#31034;&#20363;&#31354;&#38388;&#20013;&#37319;&#29992;&#38543;&#26426;&#36138;&#23146;&#25628;&#32034;&#21644;&#22810;&#33218;&#36172;&#21338;&#26426;&#26469;&#20943;&#23569;&#30456;&#20284;&#24615;&#27604;&#36739;&#30340;&#25968;&#37327;&#26469;&#32531;&#35299;&#36825;&#20010;&#23616;&#38480;&#24615;&#12290;&#25105;&#20204;&#30340;&#38543;&#26426;&#31639;&#27861;ProtoBandit&#33021;&#22815;&#22312;&#20135;&#29983;O&#65288;k^3 |S|&#65289;&#30340;&#30456;&#20284;&#24615;&#27604;&#36739;&#30340;&#24773;&#20917;&#19979;&#35782;&#21035;&#20986;&#19968;&#32452;k&#20010;&#21407;&#22411;&#65292;&#36825;&#19982;&#30446;&#26631;&#38598;&#30340;&#22823;&#23567;&#26080;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we propose a multi-armed bandit-based framework for identifying a compact set of informative data instances (i.e., the prototypes) from a source dataset $S$ that best represents a given target set $T$. Prototypical examples of a given dataset offer interpretable insights into the underlying data distribution and assist in example-based reasoning, thereby influencing every sphere of human decision-making. Current state-of-the-art prototype selection approaches require $O(|S||T|)$ similarity comparisons between source and target data points, which becomes prohibitively expensive for large-scale settings. We propose to mitigate this limitation by employing stochastic greedy search in the space of prototypical examples and multi-armed bandits for reducing the number of similarity comparisons. Our randomized algorithm, ProtoBandit, identifies a set of $k$ prototypes incurring $O(k^3|S|)$ similarity comparisons, which is independent of the size of the target set. An interesting
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#26631;&#37327;&#36755;&#20837;&#21644;&#20989;&#25968;&#36755;&#20986;&#20043;&#38388;&#22238;&#24402;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#20989;&#25968;&#21709;&#24212;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#22823;&#37327;&#39044;&#27979;&#21464;&#37327;&#25110;&#38750;&#32447;&#24615;&#20851;&#31995;&#65292;&#24182;&#21487;&#20197;&#25511;&#21046;&#39044;&#27979;&#26354;&#32447;&#30340;&#24179;&#28369;&#31243;&#24230;&#12290;&#22312;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2208.05776</link><description>&lt;p&gt;
&#26631;&#37327;&#36755;&#20837;&#21644;&#20989;&#25968;&#36755;&#20986;&#30340;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Neural Networks for Scalar Input and Functional Output. (arXiv:2208.05776v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.05776
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#26631;&#37327;&#36755;&#20837;&#21644;&#20989;&#25968;&#36755;&#20986;&#20043;&#38388;&#22238;&#24402;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#20989;&#25968;&#21709;&#24212;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#22823;&#37327;&#39044;&#27979;&#21464;&#37327;&#25110;&#38750;&#32447;&#24615;&#20851;&#31995;&#65292;&#24182;&#21487;&#20197;&#25511;&#21046;&#39044;&#27979;&#26354;&#32447;&#30340;&#24179;&#28369;&#31243;&#24230;&#12290;&#22312;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19968;&#32452;&#26631;&#37327;&#39044;&#27979;&#21464;&#37327;&#19978;&#22238;&#24402;&#20989;&#25968;&#21709;&#24212;&#21487;&#20197;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#29305;&#21035;&#26159;&#24403;&#26377;&#22823;&#37327;&#39044;&#27979;&#21464;&#37327;&#25110;&#32773;&#39044;&#27979;&#21464;&#37327;&#19982;&#21709;&#24212;&#20043;&#38388;&#30340;&#20851;&#31995;&#26159;&#38750;&#32447;&#24615;&#30340;&#26102;&#20505;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#35299;&#20915;&#26041;&#26696;&#65306;&#20351;&#29992;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#39044;&#27979;&#26631;&#37327;&#36755;&#20837;&#19979;&#30340;&#20989;&#25968;&#21709;&#24212;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23558;&#20989;&#25968;&#21709;&#24212;&#36716;&#21270;&#20026;&#26377;&#38480;&#32500;&#24230;&#34920;&#31034;&#65292;&#24182;&#26500;&#24314;&#19968;&#20010;&#36755;&#20986;&#35813;&#34920;&#31034;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#30446;&#26631;&#20989;&#25968;&#20462;&#25913;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20986;&#65292;&#24182;&#24341;&#20837;&#19981;&#21516;&#30340;&#30446;&#26631;&#20989;&#25968;&#26469;&#36827;&#34892;&#32593;&#32476;&#35757;&#32451;&#12290;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#36866;&#29992;&#20110;&#22343;&#21248;&#21644;&#19981;&#22343;&#21248;&#38388;&#38548;&#30340;&#25968;&#25454;&#65292;&#24182;&#21487;&#20197;&#36827;&#19968;&#27493;&#24212;&#29992;&#24179;&#28369;&#24809;&#32602;&#39033;&#26469;&#25511;&#21046;&#39044;&#27979;&#26354;&#32447;&#30340;&#24179;&#28369;&#31243;&#24230;&#12290;&#23454;&#29616;&#36825;&#20123;&#29305;&#24615;&#30340;&#22256;&#38590;&#22312;&#20110;&#23450;&#20041;&#21487;&#20197;&#36827;&#34892;&#21453;&#21521;&#20256;&#25773;&#30340;&#30446;&#26631;&#20989;&#25968;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The regression of a functional response on a set of scalar predictors can be a challenging task, especially if there is a large number of predictors, or the relationship between those predictors and the response is nonlinear. In this work, we propose a solution to this problem: a feed-forward neural network (NN) designed to predict a functional response using scalar inputs. First, we transform the functional response to a finite-dimensional representation and construct an NN that outputs this representation. Then, we propose to modify the output of an NN via the objective function and introduce different objective functions for network training. The proposed models are suited for both regularly and irregularly spaced data, and a roughness penalty can be further applied to control the smoothness of the predicted curve. The difficulty in implementing both those features lies in the definition of objective functions that can be back-propagated. In our experiments, we demonstrate that our 
&lt;/p&gt;</description></item><item><title>&#21033;&#29992;Fused Unbalanced Gromov-Wasserstein&#26041;&#27861;&#36827;&#34892;&#20010;&#20307;&#33041;&#23545;&#40784;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#26368;&#20248;&#36755;&#36816;&#23545;&#22823;&#33041;&#30382;&#23618;&#34920;&#38754;&#21151;&#33021;&#29305;&#24449;&#30456;&#20284;&#24615;&#36827;&#34892;&#23545;&#40784;&#65292;&#19988;&#33021;&#22788;&#29702;&#21151;&#33021;&#21306;&#22495;&#22823;&#23567;&#21464;&#21270;&#65292;&#26174;&#33879;&#25552;&#39640;&#20010;&#20307;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2206.09398</link><description>&lt;p&gt;
&#20351;&#29992;&#34701;&#21512;&#19981;&#24179;&#34913;Gromov-Wasserstein&#26041;&#27861;&#36827;&#34892;&#20010;&#20307;&#33041;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Aligning individual brains with Fused Unbalanced Gromov-Wasserstein. (arXiv:2206.09398v3 [q-bio.NC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.09398
&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;Fused Unbalanced Gromov-Wasserstein&#26041;&#27861;&#36827;&#34892;&#20010;&#20307;&#33041;&#23545;&#40784;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#26368;&#20248;&#36755;&#36816;&#23545;&#22823;&#33041;&#30382;&#23618;&#34920;&#38754;&#21151;&#33021;&#29305;&#24449;&#30456;&#20284;&#24615;&#36827;&#34892;&#23545;&#40784;&#65292;&#19988;&#33021;&#22788;&#29702;&#21151;&#33021;&#21306;&#22495;&#22823;&#23567;&#21464;&#21270;&#65292;&#26174;&#33879;&#25552;&#39640;&#20010;&#20307;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#20307;&#33041;&#22312;&#35299;&#21078;&#32467;&#26500;&#21644;&#21151;&#33021;&#32452;&#32455;&#19978;&#23384;&#22312;&#24046;&#24322;&#65292;&#29978;&#33267;&#22312;&#21516;&#19968;&#29289;&#31181;&#20869;&#20063;&#26159;&#22914;&#27492;&#12290;&#20010;&#20307;&#38388;&#30340;&#21464;&#24322;&#24615;&#26159;&#22312;&#23545;&#19968;&#32452;&#21463;&#35797;&#32773;&#36827;&#34892;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#25910;&#38598;&#26102;&#38590;&#20197;&#24471;&#20986;&#19968;&#33324;&#24615;&#32467;&#35770;&#30340;&#20027;&#35201;&#38556;&#30861;&#12290;&#30446;&#21069;&#30340;&#37197;&#20934;&#36807;&#31243;&#20381;&#36182;&#20110;&#26377;&#38480;&#30340;&#25968;&#25454;&#65292;&#22240;&#27492;&#23548;&#33268;&#31895;&#31961;&#30340;&#20010;&#20307;&#38388;&#23545;&#40784;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#20248;&#36755;&#36816;&#30340;&#20010;&#20307;&#38388;&#23545;&#40784;&#26041;&#27861;&#65292;&#31216;&#20026;Fused Unbalanced Gromov-Wasserstein&#65288;FUGW&#65289;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#23545;&#22823;&#33041;&#30382;&#23618;&#34920;&#38754;&#22312;&#19981;&#21516;&#21050;&#28608;&#24773;&#20917;&#19979;&#30340;&#21151;&#33021;&#29305;&#24449;&#30456;&#20284;&#24615;&#36827;&#34892;&#23545;&#40784;&#65292;&#21516;&#26102;&#24809;&#32602;&#20010;&#20307;&#30340;&#25299;&#25169;&#32452;&#32455;&#22823;&#21464;&#24418;&#12290;&#25105;&#20204;&#35777;&#26126;FUGW&#38750;&#24120;&#36866;&#29992;&#20110;&#25972;&#20010;&#22823;&#33041;&#26080;&#26631;&#24535;&#28857;&#30340;&#23545;&#40784;&#12290;&#19981;&#24179;&#34913;&#29305;&#24615;&#20801;&#35768;&#22788;&#29702;&#21151;&#33021;&#21306;&#22495;&#22312;&#19981;&#21516;&#21463;&#35797;&#32773;&#20013;&#30340;&#22823;&#23567;&#21464;&#21270;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;FUGW&#23545;&#40784;&#26174;&#33879;&#25552;&#39640;&#20102;&#20010;&#20307;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Individual brains vary in both anatomy and functional organization, even within a given species. Inter-individual variability is a major impediment when trying to draw generalizable conclusions from neuroimaging data collected on groups of subjects. Current co-registration procedures rely on limited data, and thus lead to very coarse inter-subject alignments. In this work, we present a novel method for inter-subject alignment based on Optimal Transport, denoted as Fused Unbalanced Gromov Wasserstein (FUGW). The method aligns cortical surfaces based on the similarity of their functional signatures in response to a variety of stimulation settings, while penalizing large deformations of individual topographic organization. We demonstrate that FUGW is well-suited for whole-brain landmark-free alignment. The unbalanced feature allows to deal with the fact that functional areas vary in size across subjects. Our results show that FUGW alignment significantly increases between-subject correlat
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#30740;&#31350;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#26381;&#21153;&#30340;&#21442;&#19982;&#21644;&#37325;&#26032;&#35757;&#32451;&#21160;&#24577;&#65292;&#21457;&#29616;&#24403;&#23398;&#20064;&#32773;&#21644;&#29992;&#25143;&#23376;&#32676;&#20855;&#26377;&#39118;&#38505;&#20943;&#23569;&#24615;&#36136;&#26102;&#65292;&#21807;&#19968;&#30340;&#31283;&#23450;&#22343;&#34913;&#26159;&#32454;&#20998;&#30340;&#65292;&#23558;&#23376;&#32676;&#20998;&#37197;&#32473;&#21333;&#20010;&#23398;&#20064;&#32773;&#12290;&#21151;&#21033;&#20027;&#20041;&#31038;&#20250;&#26368;&#20248;&#26159;&#19968;&#20010;&#31283;&#23450;&#22343;&#34913;&#12290;</title><link>http://arxiv.org/abs/2206.02667</link><description>&lt;p&gt;
&#20174;&#21442;&#19982;&#24230;&#21160;&#24577;&#21644;&#22810;&#23398;&#20064;&#32773;&#37325;&#26032;&#35757;&#32451;&#20013;&#20135;&#29983;&#30340;&#32039;&#24613;&#32454;&#20998;
&lt;/p&gt;
&lt;p&gt;
Emergent segmentation from participation dynamics and multi-learner retraining. (arXiv:2206.02667v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.02667
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#30740;&#31350;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#26381;&#21153;&#30340;&#21442;&#19982;&#21644;&#37325;&#26032;&#35757;&#32451;&#21160;&#24577;&#65292;&#21457;&#29616;&#24403;&#23398;&#20064;&#32773;&#21644;&#29992;&#25143;&#23376;&#32676;&#20855;&#26377;&#39118;&#38505;&#20943;&#23569;&#24615;&#36136;&#26102;&#65292;&#21807;&#19968;&#30340;&#31283;&#23450;&#22343;&#34913;&#26159;&#32454;&#20998;&#30340;&#65292;&#23558;&#23376;&#32676;&#20998;&#37197;&#32473;&#21333;&#20010;&#23398;&#20064;&#32773;&#12290;&#21151;&#21033;&#20027;&#20041;&#31038;&#20250;&#26368;&#20248;&#26159;&#19968;&#20010;&#31283;&#23450;&#22343;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#26381;&#21153;&#20013;&#36873;&#25321;&#21442;&#19982;&#65292;&#24448;&#24448;&#22522;&#20110;&#35813;&#26381;&#21153;&#30340;&#36136;&#37327;&#65292;&#24433;&#21709;&#20102;&#26381;&#21153;&#23398;&#20064;&#21644;&#25913;&#36827;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#24403;&#23398;&#20064;&#32773;&#21644;&#29992;&#25143;&#23376;&#32676;&#37117;&#20855;&#26377;&#39118;&#38505;&#20943;&#23569;&#24615;&#36136;&#26102;&#65292;&#21442;&#19982;&#21644;&#37325;&#26032;&#35757;&#32451;&#30340;&#21160;&#24577;&#29983;&#25104;&#30340;&#24773;&#20917;&#65292;&#20854;&#20013;&#21253;&#25324;&#20102;&#26799;&#24230;&#19979;&#38477;&#12289;&#20056;&#27861;&#26435;&#37325;&#31561;&#24191;&#27867;&#30340;&#26356;&#26032;&#26041;&#27861;&#12290;&#20030;&#20010;&#20363;&#23376;&#65292;&#20551;&#35774;&#20010;&#20307;&#36873;&#25321;&#22312;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#19978;&#33457;&#36153;&#26102;&#38388;&#30340;&#27604;&#20363;&#19982;&#27599;&#20010;&#24179;&#21488;&#23545;&#20182;&#20204;&#30340;&#24037;&#20316;&#25928;&#26524;&#25104;&#27604;&#20363;&#12290;&#27599;&#20010;&#24179;&#21488;&#36824;&#20250;&#25910;&#38598;&#20854;&#27963;&#36291;&#29992;&#25143;&#30340;&#25968;&#25454;&#65292;&#24182;&#29992;&#26799;&#24230;&#27493;&#39588;&#26356;&#26032;&#21442;&#25968;&#12290;&#23545;&#20110;&#36825;&#20010;&#20363;&#23376;&#21644;&#25105;&#20204;&#30340;&#19968;&#33324;&#21160;&#24577;&#31867;&#21035;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21807;&#19968;&#30340;&#28176;&#36817;&#31283;&#23450;&#22343;&#34913;&#26159;&#32454;&#20998;&#30340;&#65292;&#23558;&#23376;&#32676;&#20998;&#37197;&#32473;&#21333;&#20010;&#23398;&#20064;&#32773;&#12290;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#21151;&#21033;&#20027;&#20041;&#31038;&#20250;&#26368;&#20248;&#26159;&#19968;&#20010;&#31283;&#23450;&#22343;&#34913;&#12290;&#19982;&#20808;&#21069;&#30340;&#24037;&#20316;&#30456;&#21453;&#65292;&#20808;&#21069;&#30340;&#24037;&#20316;&#26174;&#31034;&#37325;&#22797;&#30340;&#39118;&#38505;&#26368;&#23567;&#21270;&#21487;&#33021;&#19981;&#20250;&#23545;&#38887;&#24615;&#21644;&#21033;&#30410;&#36827;&#34892;&#20219;&#20309;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
The choice to participate in a data-driven service, often made on the basis of quality of that service, influences the ability of the service to learn and improve. We study the participation and retraining dynamics that arise when both the learners and sub-populations of users are \emph{risk-reducing}, which cover a broad class of updates including gradient descent, multiplicative weights, etc. Suppose, for example, that individuals choose to spend their time amongst social media platforms proportionally to how well each platform works for them. Each platform also gathers data about its active users, which it uses to update parameters with a gradient step. For this example and for our general class of dynamics, we show that the only asymptotically stable equilibria are segmented, with sub-populations allocated to a single learner. Under mild assumptions, the utilitarian social optimum is a stable equilibrium. In contrast to previous work, which shows that repeated risk minimization can
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22238;&#24402;&#27169;&#22411;&#20013;&#35780;&#20272;&#21024;&#38500;&#21644;&#25554;&#20837;&#27979;&#35797;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#30830;&#23450;&#35299;&#37322;&#24615;&#20154;&#24037;&#26234;&#33021;&#20013;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#12290;&#25105;&#20204;&#36890;&#36807;&#27604;&#36739;&#19981;&#21516;&#31639;&#27861;&#35745;&#31639;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#65292;&#21457;&#29616;Kernel SHAP&#22312;&#32508;&#21512;&#24615;&#33021;&#26041;&#38754;&#34920;&#29616;&#26368;&#20339;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#26356;&#24555;&#36895;&#30340;&#26367;&#20195;&#25351;&#26631;&#65292;&#36866;&#29992;&#20110;&#22238;&#24402;&#35774;&#32622;&#12290;</title><link>http://arxiv.org/abs/2205.12423</link><description>&lt;p&gt;
&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#21024;&#38500;&#21644;&#25554;&#20837;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Deletion and Insertion Tests in Regression Models. (arXiv:2205.12423v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.12423
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22238;&#24402;&#27169;&#22411;&#20013;&#35780;&#20272;&#21024;&#38500;&#21644;&#25554;&#20837;&#27979;&#35797;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#30830;&#23450;&#35299;&#37322;&#24615;&#20154;&#24037;&#26234;&#33021;&#20013;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#12290;&#25105;&#20204;&#36890;&#36807;&#27604;&#36739;&#19981;&#21516;&#31639;&#27861;&#35745;&#31639;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#65292;&#21457;&#29616;Kernel SHAP&#22312;&#32508;&#21512;&#24615;&#33021;&#26041;&#38754;&#34920;&#29616;&#26368;&#20339;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#26356;&#24555;&#36895;&#30340;&#26367;&#20195;&#25351;&#26631;&#65292;&#36866;&#29992;&#20110;&#22238;&#24402;&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#37322;&#24615;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#20219;&#21153;&#26159;&#30830;&#23450;&#40657;&#30418;&#20989;&#25968;$f$&#39044;&#27979;&#32972;&#21518;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#12290;Petsiuk&#31561;&#20154;&#65288;2018&#65289;&#30340;&#25554;&#20837;&#21644;&#21024;&#38500;&#27979;&#35797;&#21487;&#20197;&#29992;&#26469;&#35780;&#21028;&#23545;&#20110;&#20998;&#31867;&#20013;&#20687;&#32032;&#20174;&#37325;&#35201;&#21040;&#19981;&#37325;&#35201;&#36827;&#34892;&#25490;&#24207;&#30340;&#31639;&#27861;&#30340;&#36136;&#37327;&#12290;&#22312;&#22238;&#24402;&#38382;&#39064;&#19978;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#20844;&#24335;&#65292;&#20197;$f$&#30340;&#20027;&#25928;&#24212;&#21644;&#20132;&#20114;&#20316;&#29992;&#26469;&#34913;&#37327;&#20854;&#26354;&#32447;&#19979;&#38754;&#31215;&#65288;AUC&#65289;&#30340;&#26631;&#20934;&#12290;&#25105;&#20204;&#25214;&#21040;&#20102;&#22312;&#36755;&#20837;&#38543;&#26426;&#39034;&#24207;&#19979;AUC&#30340;&#26399;&#26395;&#20540;&#30340;&#34920;&#36798;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#22238;&#24402;&#35774;&#32622;&#30340;&#30452;&#32447;&#19978;&#26041;&#38754;&#31215;&#30340;&#26367;&#20195;&#25351;&#26631;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#20010;&#25351;&#26631;&#23558;&#38598;&#25104;&#26799;&#24230;&#65288;IG&#65289;&#35745;&#31639;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#19982;Kernel SHAP&#65288;KS&#65289;&#12289;LIME&#12289;DeepLIFT&#12289;vanilla gradient&#21644;input$\times$gradient&#26041;&#27861;&#35745;&#31639;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#36827;&#34892;&#27604;&#36739;&#12290;&#22312;&#25105;&#20204;&#32771;&#34385;&#30340;&#20004;&#20010;&#25968;&#25454;&#38598;&#20013;&#65292;KS&#30340;&#25972;&#20307;&#34920;&#29616;&#26368;&#22909;&#65292;&#20294;&#35745;&#31639;&#20195;&#20215;&#24456;&#39640;&#12290;&#25105;&#20204;&#21457;&#29616;IG&#22312;&#19968;&#20123;&#25968;&#25454;&#38598;&#19978;&#21644;KS&#34920;&#29616;&#30456;&#36817;&#65292;&#20294;&#35745;&#31639;&#26356;&#24555;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;
A basic task in explainable AI (XAI) is to identify the most important features behind a prediction made by a black box function $f$. The insertion and deletion tests of Petsiuk et al. (2018) can be used to judge the quality of algorithms that rank pixels from most to least important for a classification. Motivated by regression problems we establish a formula for their area under the curve (AUC) criteria in terms of certain main effects and interactions in an anchored decomposition of $f$. We find an expression for the expected value of the AUC under a random ordering of inputs to $f$ and propose an alternative area above a straight line for the regression setting. We use this criterion to compare feature importances computed by integrated gradients (IG) to those computed by Kernel SHAP (KS) as well as LIME, DeepLIFT, vanilla gradient and input$\times$gradient methods. KS has the best overall performance in two datasets we consider but it is very expensive to compute. We find that IG 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#27969;&#24418;&#19978;&#30340;min-max&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;Riemannian Hamiltonian&#26041;&#27861;&#20316;&#20026;&#20854;&#20195;&#29702;&#26041;&#27861;&#12290;&#36890;&#36807;&#26368;&#23567;&#21270;Hamiltonian&#20989;&#25968;&#65292;&#21487;&#20197;&#24471;&#21040;&#25152;&#38656;&#30340;min-max&#38797;&#28857;&#12290;&#35813;&#26041;&#27861;&#22312;geodesic-bilinear&#20248;&#21270;&#38382;&#39064;&#20013;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#20294;&#36890;&#36807;&#35299;&#20915;&#20195;&#29702;&#38382;&#39064;&#21487;&#20197;&#24471;&#21040;&#20840;&#23616;&#26368;&#20248;&#25628;&#32034;&#26041;&#21521;&#12290;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2204.11418</link><description>&lt;p&gt;
&#27969;&#24418;&#19978;&#30340;Riemannian Hamiltonian&#26041;&#27861;&#29992;&#20110;min-max&#20248;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Riemannian Hamiltonian methods for min-max optimization on manifolds. (arXiv:2204.11418v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.11418
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27969;&#24418;&#19978;&#30340;min-max&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;Riemannian Hamiltonian&#26041;&#27861;&#20316;&#20026;&#20854;&#20195;&#29702;&#26041;&#27861;&#12290;&#36890;&#36807;&#26368;&#23567;&#21270;Hamiltonian&#20989;&#25968;&#65292;&#21487;&#20197;&#24471;&#21040;&#25152;&#38656;&#30340;min-max&#38797;&#28857;&#12290;&#35813;&#26041;&#27861;&#22312;geodesic-bilinear&#20248;&#21270;&#38382;&#39064;&#20013;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#20294;&#36890;&#36807;&#35299;&#20915;&#20195;&#29702;&#38382;&#39064;&#21487;&#20197;&#24471;&#21040;&#20840;&#23616;&#26368;&#20248;&#25628;&#32034;&#26041;&#21521;&#12290;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27969;&#24418;&#19978;&#30340;min-max&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;Riemannian Hamiltonian&#20989;&#25968;&#65292;&#20854;&#26368;&#23567;&#21270;&#20316;&#20026;&#35299;&#20915;&#21407;&#22987;min-max&#38382;&#39064;&#30340;&#20195;&#29702;&#12290;&#22312;Riemannian Polyak-{\L}ojasiewicz&#26465;&#20214;&#19979;&#65292;&#20854;&#26368;&#23567;&#20540;&#23545;&#24212;&#20110;&#25152;&#38656;&#30340;min-max&#38797;&#28857;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#28385;&#36275;&#27492;&#26465;&#20214;&#30340;&#24773;&#20917;&#12290;&#29305;&#21035;&#26159;&#23545;&#20110;geodesic-bilinear&#20248;&#21270;&#65292;&#22312;&#35299;&#20915;&#20195;&#29702;&#38382;&#39064;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#24471;&#21040;&#27491;&#30830;&#30340;&#20840;&#23616;&#26368;&#20248;&#25628;&#32034;&#26041;&#21521;&#65292;&#32780;&#22312;min-max&#24418;&#24335;&#21270;&#20013;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#26368;&#23567;&#21270;Hamiltonian&#20989;&#25968;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Riemannian Hamiltonian&#26041;&#27861;&#65288;RHM&#65289;&#24182;&#25552;&#20986;&#20102;&#23427;&#20204;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;&#25105;&#20204;&#23558;RHM&#25193;&#23637;&#21040;&#21253;&#25324;&#20849;&#35782;&#27491;&#21017;&#21270;&#21644;&#38543;&#26426;&#35774;&#32622;&#12290;&#25105;&#20204;&#36890;&#36807;&#24212;&#29992;&#22914;&#23376;&#31354;&#38388;&#40065;&#26834;Wasserstein&#36317;&#31163;&#12289;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#35757;&#32451;&#21644;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#31561;&#26469;&#35828;&#26126;&#25152;&#25552;&#20986;&#30340;RHM&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study min-max optimization problems on Riemannian manifolds. We introduce a Riemannian Hamiltonian function, minimization of which serves as a proxy for solving the original min-max problems. Under the Riemannian Polyak--{\L}ojasiewicz condition on the Hamiltonian function, its minimizer corresponds to the desired min-max saddle point. We also provide cases where this condition is satisfied. For geodesic-bilinear optimization in particular, solving the proxy problem leads to the correct search direction towards global optimality, which becomes challenging with the min-max formulation. To minimize the Hamiltonian function, we propose Riemannian Hamiltonian methods (RHM) and present their convergence analyses. We extend RHM to include consensus regularization and to the stochastic setting. We illustrate the efficacy of the proposed RHM in applications such as subspace robust Wasserstein distance, robust training of neural networks, and generative adversarial networks.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#21098;&#26525;&#20013;&#39044;&#35757;&#32451;&#30340;&#25968;&#37327;&#23545;&#21098;&#26525;&#21518;&#32593;&#32476;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#29702;&#35770;&#30028;&#38480;&#65292;&#35813;&#30028;&#38480;&#20197;&#25968;&#25454;&#38598;&#22823;&#23567;&#30340;&#23545;&#25968;&#20851;&#31995;&#20915;&#23450;&#20102;&#39044;&#35757;&#32451;&#30340;&#36845;&#20195;&#27425;&#25968;&#12290;</title><link>http://arxiv.org/abs/2108.00259</link><description>&lt;p&gt;
&#29992;&#22810;&#23569;&#39044;&#35757;&#32451;&#36275;&#20197;&#21457;&#29616;&#19968;&#20010;&#22909;&#30340;&#23376;&#32593;&#32476;&#65311;
&lt;/p&gt;
&lt;p&gt;
How much pre-training is enough to discover a good subnetwork?. (arXiv:2108.00259v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.00259
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#21098;&#26525;&#20013;&#39044;&#35757;&#32451;&#30340;&#25968;&#37327;&#23545;&#21098;&#26525;&#21518;&#32593;&#32476;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#29702;&#35770;&#30028;&#38480;&#65292;&#35813;&#30028;&#38480;&#20197;&#25968;&#25454;&#38598;&#22823;&#23567;&#30340;&#23545;&#25968;&#20851;&#31995;&#20915;&#23450;&#20102;&#39044;&#35757;&#32451;&#30340;&#36845;&#20195;&#27425;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#21098;&#26525;&#23545;&#20110;&#22312;&#39044;&#35757;&#32451;&#30340;&#23494;&#38598;&#32593;&#32476;&#32467;&#26500;&#20013;&#21457;&#29616;&#39640;&#25928;&#12289;&#39640;&#24615;&#33021;&#30340;&#23376;&#32593;&#32476;&#38750;&#24120;&#26377;&#29992;&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#23427;&#28041;&#21450;&#21040;&#19968;&#20010;&#19977;&#27493;&#36807;&#31243;&#8212;&#8212;&#39044;&#35757;&#32451;&#12289;&#21098;&#26525;&#21644;&#37325;&#26032;&#35757;&#32451;&#65292;&#36825;&#22312;&#35745;&#31639;&#19978;&#26159;&#26114;&#36149;&#30340;&#65292;&#22240;&#20026;&#23494;&#38598;&#27169;&#22411;&#24517;&#39035;&#23436;&#20840;&#39044;&#35757;&#32451;&#12290;&#34429;&#28982;&#20808;&#21069;&#30340;&#24037;&#20316;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#39044;&#35757;&#32451;&#30340;&#25968;&#37327;&#19982;&#21098;&#26525;&#32593;&#32476;&#24615;&#33021;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20294;&#23545;&#20110;&#36825;&#31181;&#20381;&#36182;&#20851;&#31995;&#30340;&#29702;&#35770;&#25551;&#36848;&#20173;&#28982;&#32570;&#22833;&#12290;&#20026;&#20102;&#25968;&#23398;&#20998;&#26512;&#23494;&#38598;&#32593;&#32476;&#39044;&#35757;&#32451;&#25152;&#38656;&#30340;&#25968;&#37327;&#65292;&#20197;&#20415;&#21098;&#26525;&#21518;&#30340;&#32593;&#32476;&#33021;&#22815;&#34920;&#29616;&#33391;&#22909;&#65292;&#25105;&#20204;&#22312;&#20108;&#23618;&#20840;&#36830;&#25509;&#32593;&#32476;&#19978;&#21457;&#29616;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#29702;&#35770;&#30028;&#38480;&#65292;&#36229;&#36807;&#36825;&#20010;&#30028;&#38480;&#65292;&#36890;&#36807;&#36138;&#23146;&#21069;&#21521;&#36873;&#25321;&#30340;&#21098;&#26525;&#21487;&#20197;&#36798;&#21040;&#33391;&#22909;&#30340;&#35757;&#32451;&#35823;&#24046;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#36825;&#20010;&#38408;&#20540;&#34987;&#35777;&#26126;&#19982;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#21576;&#23545;&#25968;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural network pruning is useful for discovering efficient, high-performing subnetworks within pre-trained, dense network architectures. More often than not, it involves a three-step process -- pre-training, pruning, and re-training -- that is computationally expensive, as the dense model must be fully pre-trained. While previous work has revealed through experiments the relationship between the amount of pre-training and the performance of the pruned network, a theoretical characterization of such dependency is still missing. Aiming to mathematically analyze the amount of dense network pre-training needed for a pruned network to perform well, we discover a simple theoretical bound in the number of gradient descent pre-training iterations on a two-layer, fully-connected network, beyond which pruning via greedy forward selection [61] yields a subnetwork that achieves good training error. Interestingly, this threshold is shown to be logarithmically dependent upon the size of the dataset,
&lt;/p&gt;</description></item></channel></rss>