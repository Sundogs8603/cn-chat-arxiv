<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#32463;&#39564;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#30340;&#32479;&#35745;&#34920;&#29616;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#36981;&#24490;&#20302;&#22797;&#26434;&#24230;&#36866;&#24212;&#21407;&#21017;&#65292;&#25512;&#23548;&#20986;&#20102;&#20854;&#32479;&#35745;&#30028;&#38480;&#21450;&#21442;&#25968;&#21270;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.13580</link><description>&lt;p&gt;
&#32463;&#39564;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#30340;&#20302;&#22797;&#26434;&#24230;&#36866;&#24212;&#24615;
&lt;/p&gt;
&lt;p&gt;
Lower Complexity Adaptation for Empirical Entropic Optimal Transport. (arXiv:2306.13580v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13580
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32463;&#39564;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#30340;&#32479;&#35745;&#34920;&#29616;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#36981;&#24490;&#20302;&#22797;&#26434;&#24230;&#36866;&#24212;&#21407;&#21017;&#65292;&#25512;&#23548;&#20986;&#20102;&#20854;&#32479;&#35745;&#30028;&#38480;&#21450;&#21442;&#25968;&#21270;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32463;&#39564;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816; (EOT) &#26159;&#20248;&#21270;&#36755;&#36816; (OT) &#30340;&#19968;&#31181;&#26377;&#25928;&#19988;&#35745;&#31639;&#21487;&#34892;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#23545;&#22823;&#35268;&#27169;&#25968;&#25454;&#20998;&#26512;&#26377;&#30528;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;&#26412;&#25991;&#25512;&#23548;&#20986;&#20102; EOT &#25104;&#26412;&#30340;&#26032;&#30340;&#32479;&#35745;&#30028;&#38480;&#65292;&#24182;&#26174;&#31034;&#23427;&#20204;&#22312;&#29109;&#27491;&#21017;&#21270;&#21442;&#25968; $\epsilon$ &#21644;&#26679;&#26412;&#22823;&#23567; $n$ &#30340;&#32479;&#35745;&#24615;&#33021;&#20165;&#21462;&#20915;&#20110;&#20004;&#20010;&#27010;&#29575;&#27979;&#24230;&#20043;&#20013;&#36739;&#31616;&#21333;&#30340;&#37027;&#20010;&#12290;&#20363;&#22914;&#65292;&#22312;&#20805;&#20998;&#24179;&#28369;&#30340;&#25104;&#26412;&#19979;&#65292;&#36825;&#20250;&#20135;&#29983;&#20855;&#26377;$\epsilon^{-d/2}$&#22240;&#23376;&#30340;&#21442;&#25968;&#21270;&#36895;&#29575;$n^{-1/2}$&#65292;&#20854;&#20013;$d$&#26159;&#20004;&#20010;&#24635;&#20307;&#27979;&#24230;&#30340;&#26368;&#23567;&#32500;&#24230;&#12290;&#36825;&#30830;&#35748;&#20102;&#32463;&#39564;EOT&#20063;&#36981;&#24490;&#20102;&#26368;&#36817;&#25165;&#20026;&#26410;&#35268;&#21017;&#21270;OT&#30830;&#35748;&#30340;&#20302;&#22797;&#26434;&#24230;&#36866;&#24212;&#21407;&#21017;&#30340;&#26631;&#24535;&#24615;&#29305;&#24449;&#12290;&#26681;&#25454;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#19978;&#30340;&#27979;&#24230;&#30340;&#32463;&#39564;&#29109;Gromov-Wasserstein&#36317;&#31163;&#21450;&#20854;&#26410;&#35268;&#21017;&#21270;&#29256;&#26412;&#20063;&#36981;&#24490;&#27492;&#21407;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;
Entropic optimal transport (EOT) presents an effective and computationally viable alternative to unregularized optimal transport (OT), offering diverse applications for large-scale data analysis. In this work, we derive novel statistical bounds for empirical plug-in estimators of the EOT cost and show that their statistical performance in the entropy regularization parameter $\epsilon$ and the sample size $n$ only depends on the simpler of the two probability measures. For instance, under sufficiently smooth costs this yields the parametric rate $n^{-1/2}$ with factor $\epsilon^{-d/2}$, where $d$ is the minimum dimension of the two population measures. This confirms that empirical EOT also adheres to the lower complexity adaptation principle, a hallmark feature only recently identified for unregularized OT. As a consequence of our theory, we show that the empirical entropic Gromov-Wasserstein distance and its unregularized version for measures on Euclidean spaces also obey this princip
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#8220;&#23433;&#20840;&#27169;&#24335;&#20462;&#21098;&#8221;&#26041;&#27861;&#35299;&#20915;&#39044;&#27979;&#27169;&#24335;&#25366;&#25496;&#20013;&#27169;&#24335;&#25968;&#37327;&#22686;&#38271;&#30340;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#32467;&#26500;&#21270;&#25968;&#25454;&#30340;&#22238;&#24402;&#21644;&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.13561</link><description>&lt;p&gt;
&#23433;&#20840;&#27169;&#24335;&#20462;&#21098;&#19979;&#30340;&#39044;&#27979;&#27169;&#24335;&#25366;&#25496;&#27169;&#22411;&#39640;&#25928;&#36873;&#21462;
&lt;/p&gt;
&lt;p&gt;
Efficient Model Selection for Predictive Pattern Mining Model by Safe Pattern Pruning. (arXiv:2306.13561v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13561
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#8220;&#23433;&#20840;&#27169;&#24335;&#20462;&#21098;&#8221;&#26041;&#27861;&#35299;&#20915;&#39044;&#27979;&#27169;&#24335;&#25366;&#25496;&#20013;&#27169;&#24335;&#25968;&#37327;&#22686;&#38271;&#30340;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#32467;&#26500;&#21270;&#25968;&#25454;&#30340;&#22238;&#24402;&#21644;&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#27169;&#24335;&#25366;&#25496;&#26159;&#19968;&#31181;&#29992;&#20110;&#26500;&#24314;&#39044;&#27979;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24403;&#36755;&#20837;&#34987;&#34920;&#31034;&#20026;&#32467;&#26500;&#21270;&#25968;&#25454;&#65288;&#20363;&#22914;&#38598;&#21512;&#12289;&#22270;&#21644;&#24207;&#21015;&#65289;&#26102;&#65292;&#35813;&#26041;&#27861;&#36866;&#29992;&#12290;&#39044;&#27979;&#27169;&#24335;&#25366;&#25496;&#30340;&#20027;&#35201;&#24605;&#24819;&#26159;&#36890;&#36807;&#32771;&#34385;&#32467;&#26500;&#21270;&#25968;&#25454;&#20013;&#30340;&#23376;&#32467;&#26500;&#65288;&#20363;&#22914;&#23376;&#38598;&#12289;&#23376;&#22270;&#21644;&#23376;&#24207;&#21015;&#65292;&#31216;&#20026;&#27169;&#24335;&#65289;&#20316;&#20026;&#27169;&#22411;&#30340;&#29305;&#24449;&#26469;&#26500;&#24314;&#39044;&#27979;&#27169;&#22411;&#12290;&#39044;&#27979;&#27169;&#24335;&#25366;&#25496;&#38754;&#20020;&#30340;&#20027;&#35201;&#25361;&#25112;&#22312;&#20110;&#38543;&#30528;&#32467;&#26500;&#21270;&#25968;&#25454;&#30340;&#22797;&#26434;&#24615;&#22686;&#21152;&#65292;&#27169;&#24335;&#25968;&#37327;&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23433;&#20840;&#27169;&#24335;&#20462;&#21098;&#65288;SPP&#65289;&#26041;&#27861;&#26469;&#35299;&#20915;&#39044;&#27979;&#27169;&#24335;&#25366;&#25496;&#20013;&#27169;&#24335;&#25968;&#29190;&#28856;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#22914;&#20309;&#22312;&#23454;&#38469;&#25968;&#25454;&#20998;&#26512;&#30340;&#25972;&#20010;&#27169;&#22411;&#26500;&#24314;&#36807;&#31243;&#20013;&#26377;&#25928;&#22320;&#24212;&#29992;&#23427;&#12290;&#20026;&#20102;&#35777;&#26126;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#22312;&#28041;&#21450;&#38598;&#21512;&#12289;&#22270;&#21644;&#24207;&#21015;&#30340;&#22238;&#24402;&#21644;&#20998;&#31867;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#25968;&#20540;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Predictive pattern mining is an approach used to construct prediction models when the input is represented by structured data, such as sets, graphs, and sequences. The main idea behind predictive pattern mining is to build a prediction model by considering substructures, such as subsets, subgraphs, and subsequences (referred to as patterns), present in the structured data as features of the model. The primary challenge in predictive pattern mining lies in the exponential growth of the number of patterns with the complexity of the structured data. In this study, we propose the Safe Pattern Pruning (SPP) method to address the explosion of pattern numbers in predictive pattern mining. We also discuss how it can be effectively employed throughout the entire model building process in practical data analysis. To demonstrate the effectiveness of the proposed method, we conduct numerical experiments on regression and classification problems involving sets, graphs, and sequences.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#29702;&#35770;&#25512;&#23548;&#21644;&#23454;&#39564;&#39564;&#35777;&#65292;&#21457;&#29616;&#39640;&#26031;&#21270;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#23545;&#20110;&#32500;&#25968;&#22686;&#21152;&#21576;&#29616;&#20986;&#32447;&#24615;&#20851;&#31995;&#65292;&#21407;&#22240;&#26159;&#27169;&#22411;&#26080;&#27861;&#25429;&#25417;&#32500;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.13520</link><description>&lt;p&gt;
&#20851;&#20110;&#38543;&#26426;&#26059;&#36716;&#39640;&#26031;&#21270;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
On the Convergence Rate of Gaussianization with Random Rotations. (arXiv:2306.13520v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13520
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#29702;&#35770;&#25512;&#23548;&#21644;&#23454;&#39564;&#39564;&#35777;&#65292;&#21457;&#29616;&#39640;&#26031;&#21270;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#23545;&#20110;&#32500;&#25968;&#22686;&#21152;&#21576;&#29616;&#20986;&#32447;&#24615;&#20851;&#31995;&#65292;&#21407;&#22240;&#26159;&#27169;&#22411;&#26080;&#27861;&#25429;&#25417;&#32500;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#21270;&#26159;&#19968;&#31181;&#31616;&#21333;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#21487;&#20197;&#22312;&#27809;&#26377;&#21453;&#21521;&#20256;&#25773;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#35757;&#32451;&#12290;&#23427;&#22312;&#20302;&#32500;&#25968;&#25454;&#19978;&#34920;&#29616;&#20986;&#20102;&#24378;&#22823;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#32500;&#24230;&#30340;&#22686;&#21152;&#65292;&#35266;&#23519;&#21040;&#20854;&#25910;&#25947;&#36895;&#24230;&#21464;&#24930;&#12290;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#65292;&#23545;&#20110;&#39640;&#26031;&#36755;&#20837;&#65292;&#25152;&#38656;&#30340;&#23618;&#25968;&#19982;&#32500;&#25968;&#25104;&#32447;&#24615;&#20851;&#31995;&#12290;&#25105;&#20204;&#35748;&#20026;&#36825;&#26159;&#22240;&#20026;&#35813;&#27169;&#22411;&#26080;&#27861;&#25429;&#25417;&#32500;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussianization is a simple generative model that can be trained without backpropagation. It has shown compelling performance on low dimensional data. As the dimension increases, however, it has been observed that the convergence speed slows down. We show analytically that the number of required layers scales linearly with the dimension for Gaussian input. We argue that this is because the model is unable to capture dependencies between dimensions. Empirically, we find the same linear increase in cost for arbitrary input $p(x)$, but observe favorable scaling for some distributions. We explore potential speed-ups and formulate challenges for further research.
&lt;/p&gt;</description></item><item><title>&#26412;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26041;&#27861;&#26469;&#36827;&#34892;&#22522;&#20110;&#20998;&#24067;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;&#65292;&#36890;&#36807;&#26041;&#24046;&#26368;&#22823;&#21270;&#21407;&#29702;&#21644;&#37325;&#26500;&#35823;&#24046;&#26368;&#23567;&#21270;&#20004;&#31181;&#26041;&#27861;&#25512;&#23548;&#24471;&#38381;&#21512;&#35299;&#12290;</title><link>http://arxiv.org/abs/2306.13503</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#24067;&#25968;&#25454;&#38598;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#20004;&#31181;&#25512;&#23548;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Two derivations of Principal Component Analysis on datasets of distributions. (arXiv:2306.13503v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13503
&lt;/p&gt;
&lt;p&gt;
&#26412;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26041;&#27861;&#26469;&#36827;&#34892;&#22522;&#20110;&#20998;&#24067;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;&#65292;&#36890;&#36807;&#26041;&#24046;&#26368;&#22823;&#21270;&#21407;&#29702;&#21644;&#37325;&#26500;&#35823;&#24046;&#26368;&#23567;&#21270;&#20004;&#31181;&#26041;&#27861;&#25512;&#23548;&#24471;&#38381;&#21512;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#30701;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#24212;&#29992;&#20110;&#30001;&#20854;&#20301;&#32622;&#21644;&#21327;&#26041;&#24046;&#21051;&#30011;&#30340;&#20998;&#24067;&#25968;&#25454;&#38598;&#65292;&#32780;&#38750;&#28857;&#25968;&#25454;&#38598;&#12290;&#19982;&#28857;&#25968;&#25454;&#38598;&#19978;&#30340;&#24120;&#35268;PCA&#21487;&#20197;&#31561;&#25928;&#22320;&#36890;&#36807;&#26041;&#24046;&#26368;&#22823;&#21270;&#21407;&#29702;&#21644;&#37325;&#26500;error&#26368;&#23567;&#21270;&#20004;&#31181;&#26041;&#27861;&#25512;&#23548;&#20986;&#19968;&#26679;&#65292;&#25105;&#20204;&#20174;&#36825;&#20004;&#20010;&#26041;&#38754;&#25512;&#23548;&#20986;&#20102;&#20998;&#24067;PCA&#30340;&#38381;&#21512;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this brief note, we formulate Principal Component Analysis (PCA) over datasets consisting not of points but of distributions, characterized by their location and covariance. Just like the usual PCA on points can be equivalently derived via a variance-maximization principle and via a minimization of reconstruction error, we derive a closed-form solution for distributional PCA from both of these perspectives.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36816;&#29992;RPM&#22312;&#22270;&#20687;&#35266;&#27979;&#25968;&#25454;&#20013;&#35782;&#21035;&#20302;&#32500;&#31163;&#25955;&#38544;&#21464;&#37327;&#65292;&#24182;&#19988;&#22312;&#28508;&#22312;&#21464;&#37327;&#20998;&#24067;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#36866;&#24403;&#22320;&#39044;&#27979;&#30446;&#26631;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.13472</link><description>&lt;p&gt;
&#22522;&#20110;&#39640;&#32500;&#35266;&#27979;&#25968;&#25454;&#30340;&#28508;&#22312;&#23376;&#32676;&#36716;&#25442;&#19979;&#30340;&#39044;&#27979;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Prediction under Latent Subgroup Shifts with High-Dimensional Observations. (arXiv:2306.13472v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13472
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36816;&#29992;RPM&#22312;&#22270;&#20687;&#35266;&#27979;&#25968;&#25454;&#20013;&#35782;&#21035;&#20302;&#32500;&#31163;&#25955;&#38544;&#21464;&#37327;&#65292;&#24182;&#19988;&#22312;&#28508;&#22312;&#21464;&#37327;&#20998;&#24067;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#36866;&#24403;&#22320;&#39044;&#27979;&#30446;&#26631;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#22270;&#24418;&#27169;&#22411;&#20013;&#30340;&#39044;&#27979;&#26041;&#27861;&#65292;&#33021;&#22815;&#36866;&#24212;&#28508;&#22312;&#21464;&#37327;&#19981;&#21516;&#20998;&#24067;&#19979;&#30340;&#36716;&#25442;&#65292;&#21363;&#28304;&#29615;&#22659;&#21644;&#30446;&#26631;&#29615;&#22659;&#20013;&#30340;&#28508;&#22312;&#21464;&#37327;&#20998;&#24067;&#19981;&#21516;&#12290;&#26412;&#30740;&#31350;&#36816;&#29992;&#35782;&#21035;&#21442;&#25968;&#27169;&#22411;&#65288;RPM&#65289;&#22312;&#22270;&#20687;&#35266;&#27979;&#25968;&#25454;&#20013;&#35782;&#21035;&#20302;&#32500;&#31163;&#25955;&#38544;&#21464;&#37327;&#65292;&#24182;&#19988;&#22312;&#20855;&#20307;&#38382;&#39064;&#20013;&#36866;&#24403;&#22320;&#39044;&#27979;&#30446;&#26631;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new approach to prediction in graphical models with latent-shift adaptation, i.e., where source and target environments differ in the distribution of an unobserved confounding latent variable. Previous work has shown that as long as "concept" and "proxy" variables with appropriate dependence are observed in the source environment, the latent-associated distributional changes can be identified, and target predictions adapted accurately. However, practical estimation methods do not scale well when the observations are complex and high-dimensional, even if the confounding latent is categorical. Here we build upon a recently proposed probabilistic unsupervised learning framework, the recognition-parametrised model (RPM), to recover low-dimensional, discrete latents from image observations. Applied to the problem of latent shifts, our novel form of RPM identifies causal latent structure in the source environment, and adapts properly to predict in the target. We demonstrate re
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23454;&#39564;&#35748;&#20026;&#65292;&#20256;&#32479;&#26041;&#27861;&#26080;&#27861;&#35299;&#37322;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#21482;&#20351;&#29992;&#23569;&#37327;&#25968;&#25454;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#34920;&#29616;&#20986;&#25104;&#21151;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#20934;&#30830;&#25311;&#21512;&#38543;&#26426;&#29366;&#24577;&#21450;&#38543;&#26426;&#26631;&#35760;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#36825;&#31181;&#35760;&#24518;&#38543;&#26426;&#25968;&#25454;&#30340;&#33021;&#21147;&#36829;&#21453;&#20102;&#24403;&#21069;&#23567;&#27867;&#21270;&#35823;&#24046;&#30340;&#27010;&#24565;&#65292;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#26500;&#24314;&#34917;&#20805;&#23454;&#35777;&#32467;&#26524;&#65292;&#34920;&#26126;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#21487;&#23558;&#20219;&#24847;&#26631;&#35760;&#25311;&#21512;&#21040;&#37327;&#23376;&#29366;&#24577;&#19978;&#65292;&#26263;&#31034;&#20102;&#23427;&#20204;&#30340;&#35760;&#24518;&#33021;&#21147;&#65292;&#36825;&#20123;&#32467;&#26524;&#25490;&#38500;&#20102;&#21333;&#21333;&#22522;&#20110;&#32463;&#20856;&#22797;&#26434;&#24230;&#24230;&#37327;&#30340;&#25152;&#26377;&#21487;&#33021;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.13461</link><description>&lt;p&gt;
&#29702;&#35299;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#38656;&#35201;&#37325;&#26032;&#24605;&#32771;&#27867;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Understanding quantum machine learning also requires rethinking generalization. (arXiv:2306.13461v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13461
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23454;&#39564;&#35748;&#20026;&#65292;&#20256;&#32479;&#26041;&#27861;&#26080;&#27861;&#35299;&#37322;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#21482;&#20351;&#29992;&#23569;&#37327;&#25968;&#25454;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#34920;&#29616;&#20986;&#25104;&#21151;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#20934;&#30830;&#25311;&#21512;&#38543;&#26426;&#29366;&#24577;&#21450;&#38543;&#26426;&#26631;&#35760;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#36825;&#31181;&#35760;&#24518;&#38543;&#26426;&#25968;&#25454;&#30340;&#33021;&#21147;&#36829;&#21453;&#20102;&#24403;&#21069;&#23567;&#27867;&#21270;&#35823;&#24046;&#30340;&#27010;&#24565;&#65292;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#26500;&#24314;&#34917;&#20805;&#23454;&#35777;&#32467;&#26524;&#65292;&#34920;&#26126;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#21487;&#23558;&#20219;&#24847;&#26631;&#35760;&#25311;&#21512;&#21040;&#37327;&#23376;&#29366;&#24577;&#19978;&#65292;&#26263;&#31034;&#20102;&#23427;&#20204;&#30340;&#35760;&#24518;&#33021;&#21147;&#65292;&#36825;&#20123;&#32467;&#26524;&#25490;&#38500;&#20102;&#21333;&#21333;&#22522;&#20110;&#32463;&#20856;&#22797;&#26434;&#24230;&#24230;&#37327;&#30340;&#25152;&#26377;&#21487;&#33021;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#21482;&#29992;&#23569;&#37327;&#25968;&#25454;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#20063;&#33021;&#34920;&#29616;&#20986;&#25104;&#21151;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#26412;&#25991;&#36890;&#36807;&#31995;&#32479;&#30340;&#38543;&#26426;&#21270;&#23454;&#39564;&#65292;&#23637;&#31034;&#20256;&#32479;&#30340;&#29702;&#35299;&#27867;&#21270;&#30340;&#26041;&#27861;&#26080;&#27861;&#35299;&#37322;&#36825;&#20123;&#37327;&#23376;&#27169;&#22411;&#30340;&#34892;&#20026;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#25581;&#31034;&#20102;&#26368;&#20808;&#36827;&#30340;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#20934;&#30830;&#22320;&#25311;&#21512;&#38543;&#26426;&#29366;&#24577;&#21644;&#38543;&#26426;&#35757;&#32451;&#25968;&#25454;&#30340;&#26631;&#35760;&#12290;&#36825;&#31181;&#35760;&#24518;&#38543;&#26426;&#25968;&#25454;&#30340;&#33021;&#21147;&#36829;&#21453;&#20102;&#24403;&#21069;&#23567;&#27867;&#21270;&#35823;&#24046;&#30340;&#27010;&#24565;&#65292;&#20351;&#24471;&#24314;&#31435;&#22312;VC&#32500;&#12289;Rademacher&#22797;&#26434;&#24230;&#21644;&#25152;&#26377;&#22343;&#21248;&#30456;&#20851;&#24615;&#24230;&#37327;&#22522;&#30784;&#19978;&#30340;&#26041;&#27861;&#26377;&#20123;&#26840;&#25163;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#29702;&#35770;&#26500;&#24314;&#34917;&#20805;&#20102;&#25105;&#20204;&#30340;&#23454;&#35777;&#32467;&#26524;&#65292;&#34920;&#26126;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#23558;&#20219;&#24847;&#26631;&#35760;&#25311;&#21512;&#21040;&#37327;&#23376;&#29366;&#24577;&#19978;&#65292;&#26263;&#31034;&#20102;&#23427;&#20204;&#30340;&#35760;&#24518;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#24182;&#19981;&#25490;&#38500;&#21482;&#29992;&#23569;&#37327;&#35757;&#32451;&#25968;&#25454;&#23601;&#33021;&#33719;&#24471;&#33391;&#22909;&#27867;&#21270;&#30340;&#21487;&#33021;&#24615;&#65292;&#20294;&#26159;&#25490;&#38500;&#20102;&#21333;&#21333;&#22522;&#20110;&#32463;&#20856;&#22797;&#26434;&#24230;&#24230;&#37327;&#30340;&#25152;&#26377;&#21487;&#33021;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantum machine learning models have shown successful generalization performance even when trained with few data. In this work, through systematic randomization experiments, we show that traditional approaches to understanding generalization fail to explain the behavior of such quantum models. Our experiments reveal that state-of-the-art quantum neural networks accurately fit random states and random labeling of training data. This ability to memorize random data defies current notions of small generalization error, problematizing approaches that build on complexity measures such as the VC dimension, the Rademacher complexity, and all their uniform relatives. We complement our empirical results with a theoretical construction showing that quantum neural networks can fit arbitrary labels to quantum states, hinting at their memorization ability. Our results do not preclude the possibility of good generalization with few training data but rather rule out any possible guarantees based only
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36319;&#36394;&#26102;&#38388;&#21464;&#21270;&#36793;&#30028;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#35299;&#20915;&#20102;&#22312;&#32447;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#38382;&#39064;&#12290;&#36825;&#31181;&#26041;&#27861;&#26377;&#21161;&#20110;&#22788;&#29702;&#39044;&#27979;&#26377;&#36793;&#30028;&#26102;&#38388;&#24207;&#21015;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.13428</link><description>&lt;p&gt;
&#20851;&#20110;&#36319;&#36394;&#39044;&#27979;&#26377;&#36793;&#30028;&#26102;&#38388;&#24207;&#21015;&#26102;&#30340;&#21487;&#21464;&#36793;&#30028;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
On tracking varying bounds when forecasting bounded time series. (arXiv:2306.13428v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13428
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36319;&#36394;&#26102;&#38388;&#21464;&#21270;&#36793;&#30028;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#35299;&#20915;&#20102;&#22312;&#32447;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#38382;&#39064;&#12290;&#36825;&#31181;&#26041;&#27861;&#26377;&#21161;&#20110;&#22788;&#29702;&#39044;&#27979;&#26377;&#36793;&#30028;&#26102;&#38388;&#24207;&#21015;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#36830;&#32493;&#20294;&#26377;&#30028;&#30340;&#38543;&#26426;&#21464;&#37327;&#20855;&#26377;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#26410;&#35266;&#27979;&#36793;&#30028;&#12290;&#22312;&#21333;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#36793;&#30028;&#35270;&#20026;&#26377;&#30028;&#38543;&#26426;&#21464;&#37327;&#20998;&#24067;&#30340;&#21442;&#25968;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#25193;&#23637;&#30340;&#23545;&#25968;&#20284;&#28982;&#20272;&#35745;&#65292;&#24182;&#35774;&#35745;&#20102;&#31639;&#27861;&#26469;&#36890;&#36807;&#22312;&#32447;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#26469;&#36319;&#36394;&#36793;&#30028;&#12290;&#30001;&#20110;&#24471;&#21040;&#30340;&#20248;&#21270;&#38382;&#39064;&#19981;&#26159;&#20984;&#30340;&#65292;&#25105;&#20204;&#21033;&#29992;&#20102;&#26368;&#36817;&#20851;&#20110;&#20934;&#20984;&#20248;&#21270;&#30340;&#24402;&#19968;&#21270;&#26799;&#24230;&#19979;&#38477;&#65288;NGD&#65289;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#26368;&#32456;&#24471;&#21040;&#20102;&#19968;&#31181;&#22312;&#32447;&#24402;&#19968;&#21270;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#12290;&#25105;&#20204;&#22522;&#20110;&#27169;&#25311;&#30740;&#31350;&#21644;&#19968;&#20010;&#30495;&#23454;&#30340;&#39118;&#21147;&#21457;&#30005;&#39044;&#27979;&#38382;&#39064;&#26469;&#35828;&#26126;&#21644;&#35752;&#35770;&#25105;&#20204;&#26041;&#27861;&#30340;&#24037;&#20316;&#21407;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a new framework where a continuous, though bounded, random variable has unobserved bounds that vary over time. In the context of univariate time series, we look at the bounds as parameters of the distribution of the bounded random variable. We introduce an extended log-likelihood estimation and design algorithms to track the bound through online maximum likelihood estimation. Since the resulting optimization problem is not convex, we make use of recent theoretical results on Normalized Gradient Descent (NGD) for quasiconvex optimization, to eventually derive an Online Normalized Gradient Descent algorithm. We illustrate and discuss the workings of our approach based on both simulation studies and a real-world wind power forecasting problem.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; V-CPDC &#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#36816;&#34892;&#26102;&#22495;&#22833;&#30495;&#30340;&#24773;&#20917;&#19979;&#65292;&#23558;&#22240;&#26524;&#39044;&#27979;&#23376;&#32435;&#20837;&#22495;&#33258;&#36866;&#24212;&#30340;&#27010;&#24565;&#20013;&#65292;&#20197;&#20351;&#20854;&#33021;&#22815;&#22312;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#20013;&#20855;&#26377;&#36739;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2306.13271</link><description>&lt;p&gt;
&#36816;&#34892;&#26102;&#22495;&#22833;&#30495;&#19979;&#30340;&#21464;&#20998;&#21453;&#20107;&#23454;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Variational Counterfactual Prediction under Runtime Domain Corruption. (arXiv:2306.13271v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13271
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; V-CPDC &#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#36816;&#34892;&#26102;&#22495;&#22833;&#30495;&#30340;&#24773;&#20917;&#19979;&#65292;&#23558;&#22240;&#26524;&#39044;&#27979;&#23376;&#32435;&#20837;&#22495;&#33258;&#36866;&#24212;&#30340;&#27010;&#24565;&#20013;&#65292;&#20197;&#20351;&#20854;&#33021;&#22815;&#22312;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#20013;&#20855;&#26377;&#36739;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#22522;&#20110;&#35266;&#23519;&#25968;&#25454;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#30340;&#31070;&#32463;&#26041;&#27861;&#65292;&#20854;&#20013;&#19968;&#20010;&#40664;&#35748;&#20551;&#35774;&#26159;&#22312;&#35757;&#32451;&#21644;&#25512;&#29702;&#65288;&#21363;&#36816;&#34892;&#26102;&#65289;&#38454;&#27573;&#21464;&#37327;&#30340;&#30456;&#21516;&#20998;&#24067;&#21644;&#21487;&#29992;&#24615;&#12290;&#28982;&#32780;&#65292;&#22312;&#36816;&#34892;&#26102;&#21487;&#33021;&#20250;&#21457;&#29983;&#20998;&#24067;&#20559;&#31227;&#65288;&#21363;&#22495;&#20559;&#31227;&#65289;&#65292;&#32780;&#21464;&#37327;&#38590;&#20197;&#35775;&#38382;&#24102;&#26469;&#30340;&#25361;&#25112;&#26356;&#22823;&#12290;&#36825;&#36890;&#24120;&#26159;&#30001;&#20110;&#19981;&#26029;&#22686;&#21152;&#30340;&#38544;&#31169;&#21644;&#20262;&#29702;&#38382;&#39064;&#36896;&#25104;&#30340;&#65292;&#36825;&#21487;&#33021;&#20351;&#24471;&#25972;&#20010;&#36816;&#34892;&#26102;&#25968;&#25454;&#20013;&#30340;&#20219;&#24847;&#21464;&#37327;&#19981;&#21487;&#29992;&#19988;&#26080;&#27861;&#22635;&#34917;&#12290;&#25105;&#20204;&#31216;&#22495;&#36716;&#31227;&#21644;&#19981;&#21487;&#35775;&#38382;&#21464;&#37327;&#30340;&#20849;&#21516;&#21457;&#29983;&#20026;&#36816;&#34892;&#26102;&#22495;&#22833;&#30495;&#65292;&#36825;&#20005;&#37325;&#24433;&#21709;&#20102;&#35757;&#32451;&#21518;&#21453;&#20107;&#23454;&#39044;&#27979;&#22120;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#20026;&#20102;&#23545;&#25239;&#36816;&#34892;&#26102;&#22495;&#22833;&#30495;&#65292;&#25105;&#20204;&#23558;&#21453;&#20107;&#23454;&#39044;&#27979;&#23376;&#32435;&#20837;&#22495;&#33258;&#36866;&#24212;&#30340;&#27010;&#24565;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#28304;&#22495;&#35823;&#24046;&#21644;&#22495;&#38388;&#24046;&#24322;&#20043;&#21644;&#26469;&#19978;&#38480;&#30446;&#26631;&#22495;&#65288;&#21363;&#36816;&#34892;&#26102;&#21327;&#21464;&#37327;&#65289;&#30340;&#35823;&#24046;&#12290;&#25105;&#20204;&#23558;&#21453;&#20107;&#23454;&#39044;&#27979;&#34920;&#36848;&#20026;&#19968;&#20010;&#20989;&#25968;&#31354;&#38388;&#25628;&#32034;&#38382;&#39064;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#24102;&#26377;&#22495;&#22833;&#30495;&#30340;&#21464;&#20998;&#21453;&#20107;&#23454;&#39044;&#27979;&#23376;&#30340;&#26032;&#26041;&#27861;&#65288;V-CPDC&#65289;&#65292;&#35813;&#26041;&#27861;&#30452;&#25509;&#20248;&#21270;&#19978;&#30028;&#65292;&#24182;&#26088;&#22312;&#22312;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#20013;&#37117;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#23545;&#22235;&#20010;&#23454;&#38469;&#25968;&#25454;&#38598;&#30340;&#24191;&#27867;&#23454;&#39564;&#34920;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#21508;&#31181;&#36816;&#34892;&#26102;&#22495;&#22833;&#30495;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
To date, various neural methods have been proposed for causal effect estimation based on observational data, where a default assumption is the same distribution and availability of variables at both training and inference (i.e., runtime) stages. However, distribution shift (i.e., domain shift) could happen during runtime, and bigger challenges arise from the impaired accessibility of variables. This is commonly caused by increasing privacy and ethical concerns, which can make arbitrary variables unavailable in the entire runtime data and imputation impractical. We term the co-occurrence of domain shift and inaccessible variables runtime domain corruption, which seriously impairs the generalizability of a trained counterfactual predictor. To counter runtime domain corruption, we subsume counterfactual prediction under the notion of domain adaptation. Specifically, we upper-bound the error w.r.t. the target domain (i.e., runtime covariates) by the sum of source domain error and inter-dom
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#26031;&#21327;&#21464;&#37327;&#19979;&#30340;&#36807;&#21442;&#25968;&#21270;&#32447;&#24615;&#27169;&#22411;&#22312;&#22810;&#31867;&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;&#20043;&#21069;&#30340;&#29468;&#24819;&#65292;&#24182;&#25552;&#20986;&#30340;&#26032;&#19979;&#30028;&#20855;&#26377;&#20449;&#24687;&#35770;&#20013;&#30340;&#24378;&#23545;&#20598;&#23450;&#29702;&#30340;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2306.13255</link><description>&lt;p&gt;
&#36807;&#21442;&#25968;&#21270;&#32447;&#24615;&#27169;&#22411;&#19979;&#22810;&#31867;&#20998;&#31867;&#30340;&#28176;&#36827;&#27867;&#21270;&#31934;&#24230;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Precise Asymptotic Generalization for Multiclass Classification with Overparameterized Linear Models. (arXiv:2306.13255v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13255
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#26031;&#21327;&#21464;&#37327;&#19979;&#30340;&#36807;&#21442;&#25968;&#21270;&#32447;&#24615;&#27169;&#22411;&#22312;&#22810;&#31867;&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;&#20043;&#21069;&#30340;&#29468;&#24819;&#65292;&#24182;&#25552;&#20986;&#30340;&#26032;&#19979;&#30028;&#20855;&#26377;&#20449;&#24687;&#35770;&#20013;&#30340;&#24378;&#23545;&#20598;&#23450;&#29702;&#30340;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20855;&#26377;&#39640;&#26031;&#21327;&#21464;&#37327;&#21452;&#23618;&#27169;&#22411;&#19979;&#65292;&#36807;&#21442;&#25968;&#21270;&#32447;&#24615;&#27169;&#22411;&#22312;&#22810;&#31867;&#20998;&#31867;&#20013;&#30340;&#28176;&#36827;&#27867;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#25968;&#25454;&#28857;&#25968;&#12289;&#29305;&#24449;&#21644;&#31867;&#21035;&#25968;&#37117;&#21516;&#26102;&#22686;&#38271;&#12290;&#25105;&#20204;&#23436;&#20840;&#35299;&#20915;&#20102;Subramanian&#31561;&#20154;&#22312;'22&#24180;&#25152;&#25552;&#20986;&#30340;&#29468;&#24819;&#65292;&#19982;&#39044;&#27979;&#30340;&#27867;&#21270;&#21306;&#38388;&#30456;&#21305;&#37197;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26032;&#30340;&#19979;&#30028;&#31867;&#20284;&#20110;&#20449;&#24687;&#35770;&#20013;&#30340;&#24378;&#23545;&#20598;&#23450;&#29702;&#65306;&#23427;&#20204;&#33021;&#22815;&#30830;&#31435;&#35823;&#20998;&#31867;&#29575;&#36880;&#28176;&#36235;&#36817;&#20110;0&#25110;1.&#25105;&#20204;&#32039;&#23494;&#30340;&#32467;&#26524;&#30340;&#19968;&#20010;&#20196;&#20154;&#24778;&#35766;&#30340;&#32467;&#26524;&#26159;&#65292;&#26368;&#23567;&#33539;&#25968;&#25554;&#20540;&#20998;&#31867;&#22120;&#22312;&#26368;&#23567;&#33539;&#25968;&#25554;&#20540;&#22238;&#24402;&#22120;&#26368;&#20248;&#30340;&#33539;&#22260;&#20869;&#65292;&#21487;&#20197;&#22312;&#28176;&#36827;&#19978;&#27425;&#20248;&#12290;&#25105;&#20204;&#20998;&#26512;&#30340;&#20851;&#38190;&#22312;&#20110;&#19968;&#31181;&#26032;&#30340;Hanson-Wright&#19981;&#31561;&#24335;&#21464;&#20307;&#65292;&#35813;&#21464;&#20307;&#22312;&#20855;&#26377;&#31232;&#30095;&#26631;&#31614;&#30340;&#22810;&#31867;&#38382;&#39064;&#20013;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#12290;&#20316;&#20026;&#24212;&#29992;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#30456;&#21516;&#31867;&#22411;&#20998;&#26512;&#22312;&#20960;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#20998;&#31867;&#27169;&#22411;&#19978;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the asymptotic generalization of an overparameterized linear model for multiclass classification under the Gaussian covariates bi-level model introduced in Subramanian et al.~'22, where the number of data points, features, and classes all grow together. We fully resolve the conjecture posed in Subramanian et al.~'22, matching the predicted regimes for generalization. Furthermore, our new lower bounds are akin to an information-theoretic strong converse: they establish that the misclassification rate goes to 0 or 1 asymptotically. One surprising consequence of our tight results is that the min-norm interpolating classifier can be asymptotically suboptimal relative to noninterpolating classifiers in the regime where the min-norm interpolating regressor is known to be optimal.  The key to our tight analysis is a new variant of the Hanson-Wright inequality which is broadly useful for multiclass problems with sparse labels. As an application, we show that the same type of analysis 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#22312;&#24369;&#28151;&#28102;&#19979;&#35782;&#21035;&#22240;&#26524;&#25928;&#24212;&#30340;&#19978;&#38480;&#21644;&#19979;&#38480;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#35745;&#31639;&#25928;&#29575;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#22810;&#39033;&#24335;&#31243;&#24207;&#12290;</title><link>http://arxiv.org/abs/2306.13242</link><description>&lt;p&gt;
&#24369;&#28151;&#28102;&#19979;&#30340;&#36817;&#20284;&#22240;&#26524;&#25928;&#24212;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Approximate Causal Effect Identification under Weak Confounding. (arXiv:2306.13242v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13242
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#22312;&#24369;&#28151;&#28102;&#19979;&#35782;&#21035;&#22240;&#26524;&#25928;&#24212;&#30340;&#19978;&#38480;&#21644;&#19979;&#38480;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#35745;&#31639;&#25928;&#29575;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#22810;&#39033;&#24335;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21482;&#26377;&#35266;&#27979;&#25968;&#25454;&#21487;&#29992;&#26102;&#65292;&#35768;&#22810;&#30740;&#31350;&#20154;&#21592;&#30740;&#31350;&#20102;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#38382;&#39064;&#12290;&#38024;&#23545;&#21487;&#35782;&#21035;&#22240;&#26524;&#26597;&#35810;&#30340;&#28857;&#20272;&#35745;&#65292;&#24050;&#32463;&#24320;&#21457;&#20986;&#20102;&#27491;&#30830;&#23436;&#22791;&#30340;&#31639;&#27861;&#12290;&#23545;&#20110;&#19981;&#21487;&#35782;&#21035;&#30340;&#22240;&#26524;&#26597;&#35810;&#65292;&#30740;&#31350;&#20154;&#21592;&#24320;&#21457;&#20102;&#22810;&#39033;&#24335;&#31243;&#24207;&#65292;&#20197;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#30340;&#32039;&#23494;&#30028;&#38480;&#12290;&#20294;&#23545;&#20110;&#25903;&#25345;&#22823;&#23567;&#36739;&#22823;&#30340;&#21464;&#37327;&#65292;&#20248;&#21270;&#36825;&#20123;&#22810;&#39033;&#24335;&#31243;&#24207;&#22312;&#35745;&#31639;&#19978;&#24456;&#22256;&#38590;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#8220;&#24369;&#28151;&#28102;&#8221;&#23545;&#22240;&#26524;&#20272;&#35745;&#30340;&#24433;&#21709;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#22312;&#26410;&#35266;&#27979;&#21040;&#30340;&#28151;&#28102;&#21464;&#37327;&#30340;&#29109;&#24456;&#23567;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#32447;&#24615;&#35268;&#21010;&#26041;&#27861;&#26469;&#23548;&#20986;&#22240;&#26524;&#25928;&#24212;&#30340;&#19978;&#38480;&#21644;&#19979;&#38480;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#30028;&#38480;&#26159;&#19968;&#33268;&#30340;&#65292;&#20063;&#23601;&#26159;&#35828;&#65292;&#24403;&#26410;&#35266;&#27979;&#28151;&#28102;&#21464;&#37327;&#30340;&#29109;&#36235;&#36817;&#20110;&#38646;&#26102;&#65292;&#19978;&#38480;&#21644;&#19979;&#38480;&#20043;&#38388;&#30340;&#24046;&#24322;&#20250;&#28040;&#22833;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#27169;&#25311;&#65292;&#20197;&#27604;&#36739;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#26368;&#20808;&#36827;&#30340;&#22810;&#39033;&#24335;&#31243;&#24207;&#24471;&#21040;&#30340;&#30028;&#38480;&#65292;&#24182;&#35777;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#35745;&#31639;&#19978;&#26356;&#21152;&#39640;&#25928;&#65292;&#24615;&#33021;&#20063;&#21487;&#20197;&#36798;&#21040;&#31867;&#20284;&#30340;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal effect estimation has been studied by many researchers when only observational data is available. Sound and complete algorithms have been developed for pointwise estimation of identifiable causal queries. For non-identifiable causal queries, researchers developed polynomial programs to estimate tight bounds on causal effect. However, these are computationally difficult to optimize for variables with large support sizes. In this paper, we analyze the effect of "weak confounding" on causal estimands. More specifically, under the assumption that the unobserved confounders that render a query non-identifiable have small entropy, we propose an efficient linear program to derive the upper and lower bounds of the causal effect. We show that our bounds are consistent in the sense that as the entropy of unobserved confounders goes to zero, the gap between the upper and lower bound vanishes. Finally, we conduct synthetic and real data simulations to compare our bounds with the bounds obta
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;KD-&#26641;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104; $\epsilon $-&#24046;&#20998;&#38544;&#31169;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#20854;&#26680;&#23494;&#24230;&#31867;&#20284;&#20110;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#26680;&#23494;&#24230;&#12290;&#35813;&#26041;&#27861;&#20811;&#26381;&#20102;&#32500;&#24230;&#28798;&#38590;&#65292;&#26159;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.13211</link><description>&lt;p&gt;
&#20351;&#29992;KD-&#26641;&#30340;&#24046;&#20998;&#38544;&#31169;&#21512;&#25104;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Synthetic Data Using KD-Trees. (arXiv:2306.13211v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13211
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;KD-&#26641;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104; $\epsilon $-&#24046;&#20998;&#38544;&#31169;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#20854;&#26680;&#23494;&#24230;&#31867;&#20284;&#20110;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#26680;&#23494;&#24230;&#12290;&#35813;&#26041;&#27861;&#20811;&#26381;&#20102;&#32500;&#24230;&#28798;&#38590;&#65292;&#26159;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21019;&#24314;&#19968;&#20010;&#24544;&#23454;&#22320;&#20195;&#34920;&#25968;&#25454;&#20998;&#24067;&#24182;&#21516;&#26102;&#20445;&#25252;&#38544;&#31169;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#26159;&#19968;&#39033;&#37325;&#35201;&#30340;&#30740;&#31350;&#25361;&#25112;&#12290;&#36817;&#24180;&#26469;&#20986;&#29616;&#20102;&#35768;&#22810;&#22522;&#20110;&#31354;&#38388;&#20998;&#21106;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20197;&#24046;&#20998;&#38544;&#31169;&#30340;&#26041;&#24335;&#22238;&#31572;&#32479;&#35745;&#26597;&#35810;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#38382;&#39064;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#19978;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#25105;&#20204;&#21033;&#29992;&#20102;&#31354;&#38388;&#20998;&#21106;&#25216;&#26415;&#21644;&#22122;&#22768;&#25200;&#21160;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#30452;&#35266;&#36879;&#26126;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#25968;&#25454;&#29420;&#31435;&#21644;&#25968;&#25454;&#30456;&#20851;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104; $\epsilon $-&#24046;&#20998;&#38544;&#31169;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#20854;&#26680;&#23494;&#24230;&#31867;&#20284;&#20110;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#26680;&#23494;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#26377;&#20851;&#23454;&#29992;&#24615;&#21644;&#38544;&#31169;&#26435;&#21033;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#25968;&#25454;&#30456;&#20851;&#26041;&#27861;&#22914;&#20309;&#20811;&#26381;&#32500;&#24230;&#28798;&#38590;&#24182;&#23548;&#33268;&#21487;&#25193;&#23637;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#30456;&#23545;&#20110;&#20043;&#21069;&#30340;&#24037;&#20316;&#30340;&#23454;&#29992;&#25913;&#36827;&#65292;&#24182;&#35752;&#35770;&#20102;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Creation of a synthetic dataset that faithfully represents the data distribution and simultaneously preserves privacy is a major research challenge. Many space partitioning based approaches have emerged in recent years for answering statistical queries in a differentially private manner. However, for synthetic data generation problem, recent research has been mainly focused on deep generative models. In contrast, we exploit space partitioning techniques together with noise perturbation and thus achieve intuitive and transparent algorithms. We propose both data independent and data dependent algorithms for $\epsilon$-differentially private synthetic data generation whose kernel density resembles that of the real dataset. Additionally, we provide theoretical results on the utility-privacy trade-offs and show how our data dependent approach overcomes the curse of dimensionality and leads to a scalable algorithm. We show empirical utility improvements over the prior work, and discuss perfo
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#24179;&#26041;&#26681;Lipschitz&#25439;&#22833;&#30340;&#19968;&#33268;&#25910;&#25947;&#24615;&#65292;&#23545;&#19968;&#33324;&#30340;&#39640;&#26031;&#25968;&#25454;&#24314;&#31435;&#20102;&#20445;&#35777;&#65292;&#20801;&#35768;&#22788;&#29702;&#24191;&#27867;&#30340;&#25439;&#22833;&#31867;&#21035;&#65292;&#24182;&#37325;&#26032;&#25512;&#23548;&#21644;&#26356;&#22909;&#22320;&#29702;&#35299;&#8220;&#20048;&#35266;&#29575;&#8221;&#30340;&#23398;&#20064;&#20445;&#35777;&#21644;&#25554;&#20540;&#12290;</title><link>http://arxiv.org/abs/2306.13188</link><description>&lt;p&gt;
&#24179;&#26041;&#26681;Lipschitz&#25439;&#22833;&#30340;&#19968;&#33268;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Uniform Convergence with Square-Root Lipschitz Loss. (arXiv:2306.13188v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13188
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#24179;&#26041;&#26681;Lipschitz&#25439;&#22833;&#30340;&#19968;&#33268;&#25910;&#25947;&#24615;&#65292;&#23545;&#19968;&#33324;&#30340;&#39640;&#26031;&#25968;&#25454;&#24314;&#31435;&#20102;&#20445;&#35777;&#65292;&#20801;&#35768;&#22788;&#29702;&#24191;&#27867;&#30340;&#25439;&#22833;&#31867;&#21035;&#65292;&#24182;&#37325;&#26032;&#25512;&#23548;&#21644;&#26356;&#22909;&#22320;&#29702;&#35299;&#8220;&#20048;&#35266;&#29575;&#8221;&#30340;&#23398;&#20064;&#20445;&#35777;&#21644;&#25554;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#20551;&#35774;&#31867;&#30340;Rademacher&#22797;&#26434;&#24230;&#21644;&#26631;&#37327;&#25439;&#22833;&#20989;&#25968;&#30340;&#24179;&#26041;&#26681;&#30340;Lipschitz&#24120;&#25968;&#65292;&#22312;&#39640;&#26031;&#25968;&#25454;&#26041;&#38754;&#24314;&#31435;&#20102;&#19968;&#33324;&#30340;&#19968;&#33268;&#25910;&#25947;&#24615;&#20445;&#35777;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#20445;&#35777;&#22914;&#20309;&#22823;&#22823;&#27010;&#25324;&#20102;&#22522;&#20110;&#24179;&#28369;&#24615;(&#23548;&#25968;&#30340;Lipschitz&#24120;&#25968;)&#30340;&#20808;&#21069;&#32467;&#26524;&#65292;&#24182;&#20351;&#25105;&#20204;&#33021;&#22815;&#22788;&#29702;&#26356;&#24191;&#27867;&#30340;&#24179;&#26041;&#26681;Lipschitz&#25439;&#22833;&#31867;&#21035;&#65292;&#20854;&#20013;&#21253;&#25324;&#36866;&#29992;&#20110;&#30740;&#31350;&#30456;&#20301;&#24674;&#22797;&#21644;ReLU&#22238;&#24402;&#30340;&#38750;&#24179;&#28369;&#25439;&#22833;&#20989;&#25968;&#65292;&#20197;&#21450;&#37325;&#26032;&#25512;&#23548;&#21644;&#26356;&#22909;&#22320;&#29702;&#35299;&#8220;&#20048;&#35266;&#29575;&#8221;&#30340;&#23398;&#20064;&#20445;&#35777;&#21644;&#25554;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
We establish generic uniform convergence guarantees for Gaussian data in terms of the Rademacher complexity of the hypothesis class and the Lipschitz constant of the square root of the scalar loss function. We show how these guarantees substantially generalize previous results based on smoothness (Lipschitz constant of the derivative), and allow us to handle the broader class of square-root-Lipschitz losses, which includes also non-smooth loss functions appropriate for studying phase retrieval and ReLU regression, as well as rederive and better understand "optimistic rate" and interpolation learning guarantees.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26680;&#23725;&#22238;&#24402;&#20013;&#36807;&#25311;&#21512;&#25104;&#26412;&#65292;&#37319;&#29992;&#8220;&#19981;&#21487;&#30693;&#8221;&#30340;&#35266;&#28857;&#65292;&#20197;&#20998;&#26512;&#26679;&#26412;&#37327;&#21644;&#20219;&#21153;&#29305;&#24449;&#32467;&#26500;&#23545;&#25104;&#26412;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#20998;&#26512;&#25552;&#20379;&#20102;&#26356;&#32454;&#33268;&#30340;&#36807;&#24230;&#25311;&#21512;&#34920;&#24449;&#12290;</title><link>http://arxiv.org/abs/2306.13185</link><description>&lt;p&gt;
(&#26680;) &#23725;&#22238;&#24402;&#20013;&#36807;&#24230;&#25311;&#21512;&#25104;&#26412;&#30340;&#19981;&#21487;&#30693;&#35266;&#23519;
&lt;/p&gt;
&lt;p&gt;
An Agnostic View on the Cost of Overfitting in (Kernel) Ridge Regression. (arXiv:2306.13185v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13185
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26680;&#23725;&#22238;&#24402;&#20013;&#36807;&#25311;&#21512;&#25104;&#26412;&#65292;&#37319;&#29992;&#8220;&#19981;&#21487;&#30693;&#8221;&#30340;&#35266;&#28857;&#65292;&#20197;&#20998;&#26512;&#26679;&#26412;&#37327;&#21644;&#20219;&#21153;&#29305;&#24449;&#32467;&#26500;&#23545;&#25104;&#26412;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#20998;&#26512;&#25552;&#20379;&#20102;&#26356;&#32454;&#33268;&#30340;&#36807;&#24230;&#25311;&#21512;&#34920;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#26377;&#22122;&#22768;&#30340;&#26680;&#23725;&#22238;&#24402; (KRR) &#20013;&#36807;&#25311;&#21512;&#30340;&#25104;&#26412;&#65292;&#25105;&#20204;&#23558;&#20854;&#23450;&#20041;&#20026;&#25554;&#20540;&#26080;&#23725;&#27169;&#22411;&#30340;&#27979;&#35797;&#35823;&#24046;&#19982;&#26368;&#20248;&#35843;&#33410;&#27169;&#22411;&#30340;&#27979;&#35797;&#35823;&#24046;&#20043;&#27604;&#12290;&#25105;&#20204;&#37319;&#29992;&#8220;&#19981;&#21487;&#30693;&#8221;&#30340;&#35266;&#28857;&#65292;&#21363;&#23545;&#20110;&#20219;&#20309;&#30446;&#26631;&#20989;&#25968;&#65292;&#21363;&#20351;&#26679;&#26412;&#37327;&#19981;&#36275;&#20197;&#36798;&#21040;&#19968;&#33268;&#24615;&#25110;&#30446;&#26631;&#20989;&#25968;&#19981;&#22312; RKHS &#20013;&#65292;&#25105;&#20204;&#20063;&#23558;&#25104;&#26412;&#30475;&#20316;&#26679;&#26412;&#37327;&#30340;&#20989;&#25968;&#12290;&#20351;&#29992;&#26368;&#36817;&#25512;&#23548;&#20986;&#30340;&#65288;&#38750;&#20005;&#26684;&#30340;&#65289;&#39118;&#38505;&#35780;&#20272;&#65292;&#20197;&#20219;&#21153;&#29305;&#24449;&#32467;&#26500;&#20026;&#22522;&#30784;&#65292;&#21033;&#29992;&#39640;&#26031;&#26222;&#36866;&#24615;&#20551;&#35774;&#20998;&#26512;&#36807;&#24230;&#25311;&#21512;&#25104;&#26412;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25552;&#20379;&#20102;&#33391;&#24615;&#12289;&#32531;&#21644;&#21644;&#28798;&#38590;&#24615;&#36807;&#24230;&#25311;&#21512;&#65288;&#21442;&#35265; Mallinar &#31561;&#20154; 2022&#65289;&#30340;&#26356;&#31934;&#32454;&#30340;&#34920;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the cost of overfitting in noisy kernel ridge regression (KRR), which we define as the ratio between the test error of the interpolating ridgeless model and the test error of the optimally-tuned model. We take an "agnostic" view in the following sense: we consider the cost as a function of sample size for any target function, even if the sample size is not large enough for consistency or the target is outside the RKHS. We analyze the cost of overfitting under a Gaussian universality ansatz using recently derived (non-rigorous) risk estimates in terms of the task eigenstructure. Our analysis provides a more refined characterization of benign, tempered and catastrophic overfitting (qv Mallinar et al. 2022).
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#39034;&#24207;&#39044;&#27979;&#30340;&#27169;&#22411;&#65292;&#20801;&#35768;&#22312;&#19981;&#23545;&#23545;&#25239;&#24615;&#26679;&#20363;&#36827;&#34892;&#39044;&#27979;&#30340;&#24773;&#20917;&#19979;&#25552;&#39640;&#31639;&#27861;&#25239;&#23545;&#25239;&#25915;&#20987;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2306.13119</link><description>&lt;p&gt;
&#36890;&#36807;&#24323;&#26435;&#23454;&#29616;&#39034;&#24207;&#39044;&#27979;&#20013;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Adversarial Resilience in Sequential Prediction via Abstention. (arXiv:2306.13119v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13119
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#39034;&#24207;&#39044;&#27979;&#30340;&#27169;&#22411;&#65292;&#20801;&#35768;&#22312;&#19981;&#23545;&#23545;&#25239;&#24615;&#26679;&#20363;&#36827;&#34892;&#39044;&#27979;&#30340;&#24773;&#20917;&#19979;&#25552;&#39640;&#31639;&#27861;&#25239;&#23545;&#25239;&#25915;&#20987;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#24102;&#26377;&#20801;&#35768;&#27880;&#20837;&#24178;&#20928;&#26631;&#31614;&#23545;&#25239;&#24615;&#65288;&#25110;&#36229;&#20986;&#20998;&#24067;&#65289;&#31034;&#20363;&#30340;&#23545;&#25239;&#32773;&#30340;&#24773;&#20917;&#19979;&#65292;&#22312;&#38543;&#26426;&#35774;&#32622;&#19979;&#30340;&#39034;&#24207;&#39044;&#27979;&#38382;&#39064;&#12290;&#38024;&#23545;&#32431;&#38543;&#26426;&#25968;&#25454;&#30340;&#31639;&#27861;&#22312;&#23384;&#22312;&#27492;&#31867;&#23545;&#25239;&#24615;&#31034;&#20363;&#30340;&#24773;&#20917;&#19979;&#24448;&#24448;&#22833;&#36133;&#65292;&#20174;&#32780;&#23548;&#33268;&#38169;&#35823;&#30340;&#39044;&#27979;&#12290;&#36825;&#22312;&#35768;&#22810;&#39640;&#39118;&#38505;&#24212;&#29992;&#20013;&#26159;&#19981;&#21487;&#21462;&#30340;&#65292;&#20363;&#22914;&#21307;&#23398;&#24314;&#35758;&#65292;&#36825;&#37324;&#24323;&#26435;&#19981;&#36827;&#34892;&#23545;&#25239;&#24615;&#31034;&#20363;&#30340;&#39044;&#27979;&#20248;&#20110;&#35823;&#20998;&#31867;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#20551;&#35774;&#23436;&#20840;&#23545;&#25239;&#24615;&#25968;&#25454;&#23548;&#33268;&#38750;&#24120;&#24754;&#35266;&#30340;&#30028;&#38480;&#65292;&#22312;&#23454;&#36341;&#20013;&#24448;&#24448;&#26159;&#31354;&#27934;&#30340;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39034;&#24207;&#39044;&#27979;&#27169;&#22411;&#65292;&#23427;&#20301;&#20110;&#32431;&#38543;&#26426;&#21644;&#23436;&#20840;&#23545;&#25239;&#24615;&#35774;&#32622;&#20043;&#38388;&#65292;&#36890;&#36807;&#20801;&#35768;&#23398;&#20064;&#22120;&#22312;&#23545;&#25239;&#26679;&#20363;&#19978;&#26080;&#20195;&#20215;&#22320;&#25918;&#24323;&#36827;&#34892;&#39044;&#27979;&#26469;&#23454;&#29616;&#12290;&#20551;&#35774;&#35775;&#38382;&#38750;&#23545;&#25239;&#26679;&#20363;&#30340;&#36793;&#38469;&#20998;&#24067;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#23398;&#20064;&#22120;&#65292;&#20854;&#35823;&#24046;&#38543;&#30528;VC&#32500;&#30340;&#21464;&#21270;&#32780;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of sequential prediction in the stochastic setting with an adversary that is allowed to inject clean-label adversarial (or out-of-distribution) examples. Algorithms designed to handle purely stochastic data tend to fail in the presence of such adversarial examples, often leading to erroneous predictions. This is undesirable in many high-stakes applications such as medical recommendations, where abstaining from predictions on adversarial examples is preferable to misclassification. On the other hand, assuming fully adversarial data leads to very pessimistic bounds that are often vacuous in practice.  To capture this motivation, we propose a new model of sequential prediction that sits between the purely stochastic and fully adversarial settings by allowing the learner to abstain from making a prediction at no cost on adversarial examples. Assuming access to the marginal distribution on the non-adversarial examples, we design a learner whose error scales with the VC 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;Bayesian&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#26469;&#21387;&#32553;&#25968;&#25454;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270; $\beta$-ELBO &#30452;&#25509;&#20248;&#21270;&#30721;-&#22833;&#30495;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#35843;&#25972; $\beta$ &#26469;&#38024;&#23545;&#32473;&#23450;&#30340;&#32593;&#32476;&#32467;&#26500;&#23454;&#29616;&#19981;&#21516;&#30340;&#30721;-&#22833;&#30495;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2305.19185</link><description>&lt;p&gt;
Bayesian&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#19979;&#30340;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
Compression with Bayesian Implicit Neural Representations. (arXiv:2305.19185v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19185
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;Bayesian&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#26469;&#21387;&#32553;&#25968;&#25454;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270; $\beta$-ELBO &#30452;&#25509;&#20248;&#21270;&#30721;-&#22833;&#30495;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#35843;&#25972; $\beta$ &#26469;&#38024;&#23545;&#32473;&#23450;&#30340;&#32593;&#32476;&#32467;&#26500;&#23454;&#29616;&#19981;&#21516;&#30340;&#30721;-&#22833;&#30495;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#24120;&#35265;&#31867;&#22411;&#30340;&#25968;&#25454;&#21487;&#20197;&#34920;&#31034;&#20026;&#23558;&#22352;&#26631;&#26144;&#23556;&#21040;&#20449;&#21495;&#20540;&#30340;&#20989;&#25968;&#65292;&#20363;&#22914;&#22270;&#20687;&#20013;&#30340;&#20687;&#32032;&#20301;&#32622;&#21040;RGB&#20540;&#12290;&#22522;&#20110;&#36825;&#20010;&#35266;&#28857;&#65292;&#21487;&#20197;&#36890;&#36807;&#23545;&#25968;&#25454;&#30340;&#21151;&#33021;&#34920;&#31034;&#36827;&#34892;&#36229;&#25311;&#21512;&#65292;&#28982;&#21518;&#32534;&#30721;&#32593;&#32476;&#26435;&#37325;&#26469;&#21387;&#32553;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#24403;&#21069;&#30340;&#35299;&#20915;&#26041;&#26696;&#37117;&#25928;&#29575;&#20302;&#19979;&#65292;&#22240;&#20026;&#23558;&#31934;&#24230;&#37327;&#21270;&#21040;&#20302;&#27604;&#29305;&#20250;&#22823;&#24133;&#38477;&#20302;&#37325;&#26500;&#36136;&#37327;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36807;&#24230;&#25311;&#21512;&#21464;&#20998;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26469;&#21387;&#32553;&#36817;&#20284;&#21518;&#39564;&#26435;&#37325;&#26679;&#26412;&#65292;&#32780;&#19981;&#26159;&#37327;&#21270;&#21644;&#29109;&#32534;&#30721;&#23427;&#12290;&#35813;&#31574;&#30053;&#36890;&#36807;&#26368;&#23567;&#21270; $\beta$-ELBO &#30452;&#25509;&#20248;&#21270;&#30721;-&#22833;&#30495;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#35843;&#25972; $\beta$ &#26469;&#38024;&#23545;&#32473;&#23450;&#30340;&#32593;&#32476;&#32467;&#26500;&#23454;&#29616;&#19981;&#21516;&#30340;&#30721;-&#22833;&#30495;&#24179;&#34913;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#23398;&#20064;&#20808;&#39564;&#26435;&#37325;&#20998;&#24067;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#24182;&#37319;&#29992;&#20027;&#21160;&#23610;&#23544;&#35843;&#25972;&#26469;&#36827;&#19968;&#27493;&#25552;&#39640;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many common types of data can be represented as functions that map coordinates to signal values, such as pixel locations to RGB values in the case of an image. Based on this view, data can be compressed by overfitting a compact neural network to its functional representation and then encoding the network weights. However, most current solutions for this are inefficient, as quantization to low-bit precision substantially degrades the reconstruction quality. To address this issue, we propose overfitting variational Bayesian neural networks to the data and compressing an approximate posterior weight sample using relative entropy coding instead of quantizing and entropy coding it. This strategy enables direct optimization of the rate-distortion performance by minimizing the $\beta$-ELBO, and target different rate-distortion trade-offs for a given network architecture by adjusting $\beta$. Moreover, we introduce an iterative algorithm for learning prior weight distributions and employ a pro
&lt;/p&gt;</description></item><item><title>COCKATIEL&#26159;&#19968;&#31181;&#36830;&#32493;&#27010;&#24565;&#25490;&#21517;&#24102;&#24402;&#22240;&#24615;&#35299;&#37322;&#30340;&#25216;&#26415;&#65292;&#22522;&#20110;&#27010;&#24565;&#65292;&#29992;&#20110;&#20174;NLP&#20998;&#31867;&#20219;&#21153;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#26368;&#21518;&#19968;&#23618;&#20013;&#29983;&#25104;&#26377;&#24847;&#20041;&#30340;&#35299;&#37322;&#65292;&#19988;&#19981;&#20250;&#24433;&#21709;&#20934;&#30830;&#24615;&#25110;&#38656;&#35201;&#26032;&#27169;&#22411;&#65292;&#24050;&#35777;&#26126;&#27604;&#29616;&#26377;&#26041;&#27861;&#20135;&#29983;&#26356;&#26377;&#20449;&#24687;&#37327;&#21644;&#21487;&#38752;&#30340;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2305.06754</link><description>&lt;p&gt;
COCKATIEL:&#29992;&#21487;&#35299;&#37322;&#20803;&#32032;&#23545;NLP&#20219;&#21153;&#20013;&#30340;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#36827;&#34892;&#36830;&#32493;&#27010;&#24565;&#25490;&#21517;&#24102;&#24402;&#22240;&#24615;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
COCKATIEL: COntinuous Concept ranKed ATtribution with Interpretable ELements for explaining neural net classifiers on NLP tasks. (arXiv:2305.06754v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06754
&lt;/p&gt;
&lt;p&gt;
COCKATIEL&#26159;&#19968;&#31181;&#36830;&#32493;&#27010;&#24565;&#25490;&#21517;&#24102;&#24402;&#22240;&#24615;&#35299;&#37322;&#30340;&#25216;&#26415;&#65292;&#22522;&#20110;&#27010;&#24565;&#65292;&#29992;&#20110;&#20174;NLP&#20998;&#31867;&#20219;&#21153;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#26368;&#21518;&#19968;&#23618;&#20013;&#29983;&#25104;&#26377;&#24847;&#20041;&#30340;&#35299;&#37322;&#65292;&#19988;&#19981;&#20250;&#24433;&#21709;&#20934;&#30830;&#24615;&#25110;&#38656;&#35201;&#26032;&#27169;&#22411;&#65292;&#24050;&#35777;&#26126;&#27604;&#29616;&#26377;&#26041;&#27861;&#20135;&#29983;&#26356;&#26377;&#20449;&#24687;&#37327;&#21644;&#21487;&#38752;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#32467;&#26500;&#22797;&#26434;&#65292;&#20854;&#22312;NLP&#20013;&#30340;&#20351;&#29992;&#34429;&#28982;&#21462;&#24471;&#20102;&#35768;&#22810;&#25104;&#21151;&#65292;&#20294;&#20854;&#21487;&#35299;&#37322;&#24615;&#25110;&#21487;&#35299;&#37322;&#24615;&#36739;&#20026;&#26840;&#25163;&#12290;&#26368;&#36817;&#30340;&#20105;&#35770;&#34920;&#26126;&#65292;&#27880;&#24847;&#21147;&#22270;&#21644;&#24402;&#22240;&#26041;&#27861;&#19981;&#21487;&#38752;&#65292;&#32780;&#25105;&#20204;&#22312;&#26412;&#25991;&#20013;&#20171;&#32461;&#20102;&#20854;&#20013;&#19968;&#20123;&#23616;&#38480;&#24615;&#65292;&#21516;&#26102;&#20171;&#32461;&#20102;COCKATIEL&#36825;&#19968;&#26032;&#22411;&#30340;&#27169;&#22411;&#26080;&#20851;&#30340;&#21487;&#35299;&#37322;&#24615;&#25216;&#26415;&#65292;&#23427;&#26159;&#19968;&#31181;&#21518;&#26399;&#26041;&#27861;&#65292;&#22522;&#20110;&#27010;&#24565;&#65292;&#29992;&#20110;&#20174;&#32463;&#36807;NLP&#20998;&#31867;&#20219;&#21153;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#26368;&#21518;&#19968;&#23618;&#20013;&#29983;&#25104;&#26377;&#24847;&#20041;&#30340;&#35299;&#37322;&#65292;&#36890;&#36807;&#20351;&#29992;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;(NMF)&#26469;&#21457;&#29616;&#27169;&#22411;&#21033;&#29992;&#26469;&#36827;&#34892;&#39044;&#27979;&#30340;&#27010;&#24565;&#65292;&#24182;&#21033;&#29992;&#25935;&#24863;&#24615;&#20998;&#26512;&#26469;&#20934;&#30830;&#20272;&#35745;&#27599;&#20010;&#27010;&#24565;&#23545;&#27169;&#22411;&#30340;&#37325;&#35201;&#24615;&#65292;&#32780;&#19981;&#20250;&#24433;&#21709;&#24213;&#23618;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#25110;&#38656;&#35201;&#35757;&#32451;&#26032;&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;&#21333;&#19968;&#21644;&#22810;&#26041;&#38754;&#30340;&#24773;&#24863;&#20998;&#26512;&#20013;&#36827;&#34892;&#23454;&#39564;&#65292;&#35777;&#26126;COCKATIEL&#27604;&#29616;&#26377;&#26041;&#27861;&#20135;&#29983;&#26356;&#26377;&#20449;&#24687;&#37327;&#21644;&#21487;&#38752;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformer architectures are complex and their use in NLP, while it has engendered many successes, makes their interpretability or explainability challenging. Recent debates have shown that attention maps and attribution methods are unreliable (Pruthi et al., 2019; Brunner et al., 2019). In this paper, we present some of their limitations and introduce COCKATIEL, which successfully addresses some of them. COCKATIEL is a novel, post-hoc, concept-based, model-agnostic XAI technique that generates meaningful explanations from the last layer of a neural net model trained on an NLP classification task by using Non-Negative Matrix Factorization (NMF) to discover the concepts the model leverages to make predictions and by exploiting a Sensitivity Analysis to estimate accurately the importance of each of these concepts for the model. It does so without compromising the accuracy of the underlying model or requiring a new one to be trained. We conduct experiments in single and multi-aspect sent
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#25209;&#37327;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;STEEL&#65292;&#22312;&#20855;&#26377;&#36830;&#32493;&#29366;&#24577;&#21644;&#34892;&#21160;&#30340;&#26080;&#38480;&#26102;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#65292;&#19981;&#20381;&#36182;&#20110;&#32477;&#23545;&#36830;&#32493;&#20551;&#35774;&#65292;&#36890;&#36807;&#26368;&#22823;&#22343;&#20540;&#20559;&#24046;&#21644;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30830;&#20445;&#24322;&#24120;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2301.13152</link><description>&lt;p&gt;
STEEL: &#22855;&#24322;&#24615;&#24863;&#30693;&#30340;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
STEEL: Singularity-aware Reinforcement Learning. (arXiv:2301.13152v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13152
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#25209;&#37327;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;STEEL&#65292;&#22312;&#20855;&#26377;&#36830;&#32493;&#29366;&#24577;&#21644;&#34892;&#21160;&#30340;&#26080;&#38480;&#26102;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#65292;&#19981;&#20381;&#36182;&#20110;&#32477;&#23545;&#36830;&#32493;&#20551;&#35774;&#65292;&#36890;&#36807;&#26368;&#22823;&#22343;&#20540;&#20559;&#24046;&#21644;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30830;&#20445;&#24322;&#24120;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25209;&#37327;&#24378;&#21270;&#23398;&#20064;&#26088;&#22312;&#21033;&#29992;&#39044;&#20808;&#25910;&#38598;&#30340;&#25968;&#25454;&#65292;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#65292;&#20197;&#26368;&#22823;&#21270;&#26399;&#26395;&#24635;&#22238;&#25253;&#12290;&#28982;&#32780;&#65292;&#20960;&#20046;&#25152;&#26377;&#29616;&#26377;&#31639;&#27861;&#37117;&#20381;&#36182;&#20110;&#30446;&#26631;&#31574;&#30053;&#35825;&#23548;&#30340;&#20998;&#24067;&#32477;&#23545;&#36830;&#32493;&#20551;&#35774;&#65292;&#20197;&#20415;&#36890;&#36807;&#21464;&#25442;&#27979;&#24230;&#20351;&#29992;&#25209;&#37327;&#25968;&#25454;&#26469;&#26657;&#20934;&#30446;&#26631;&#31574;&#30053;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25209;&#37327;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#19981;&#38656;&#35201;&#22312;&#20855;&#26377;&#36830;&#32493;&#29366;&#24577;&#21644;&#34892;&#21160;&#30340;&#26080;&#38480;&#26102;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#32477;&#23545;&#36830;&#32493;&#24615;&#20551;&#35774;&#12290;&#25105;&#20204;&#31216;&#36825;&#20010;&#31639;&#27861;&#20026;STEEL&#65306;SingulariTy-awarE rEinforcement Learning&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#21463;&#21040;&#20851;&#20110;&#31163;&#32447;&#35780;&#20272;&#30340;&#26032;&#35823;&#24046;&#20998;&#26512;&#30340;&#21551;&#21457;&#65292;&#20854;&#20013;&#25105;&#20204;&#20351;&#29992;&#20102;&#26368;&#22823;&#22343;&#20540;&#20559;&#24046;&#65292;&#20197;&#21450;&#24102;&#26377;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30340;&#31574;&#30053;&#23450;&#21521;&#35823;&#24046;&#35780;&#20272;&#26041;&#27861;&#65292;&#20197;&#30830;&#20445;&#24322;&#24120;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22788;&#29702;&#22855;&#24322;&#24773;&#20917;&#30340;&#23450;&#21521;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Batch reinforcement learning (RL) aims at leveraging pre-collected data to find an optimal policy that maximizes the expected total rewards in a dynamic environment. Nearly all existing algorithms rely on the absolutely continuous assumption on the distribution induced by target policies with respect to the data distribution, so that the batch data can be used to calibrate target policies via the change of measure. However, the absolute continuity assumption could be violated in practice (e.g., no-overlap support), especially when the state-action space is large or continuous. In this paper, we propose a new batch RL algorithm without requiring absolute continuity in the setting of an infinite-horizon Markov decision process with continuous states and actions. We call our algorithm STEEL: SingulariTy-awarE rEinforcement Learning. Our algorithm is motivated by a new error analysis on off-policy evaluation, where we use maximum mean discrepancy, together with distributionally robust opti
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20351;&#29992;&#22270;&#24418;&#26354;&#29575;&#25551;&#36848;&#31526;&#21644;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#26032;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#20197;&#33719;&#24471;&#29992;&#20110;&#35780;&#20272;&#22270;&#24418;&#29983;&#25104;&#27169;&#22411;&#30340;&#31283;&#20581;&#12289;&#34920;&#36798;&#24615;&#30340;&#25551;&#36848;&#31526;&#12290;</title><link>http://arxiv.org/abs/2301.12906</link><description>&lt;p&gt;
&#22270;&#24418;&#29983;&#25104;&#27169;&#22411;&#35780;&#20272;&#30340;&#26354;&#29575;&#28388;&#27874;&#22120;
&lt;/p&gt;
&lt;p&gt;
Curvature Filtrations for Graph Generative Model Evaluation. (arXiv:2301.12906v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12906
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20351;&#29992;&#22270;&#24418;&#26354;&#29575;&#25551;&#36848;&#31526;&#21644;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#26032;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#20197;&#33719;&#24471;&#29992;&#20110;&#35780;&#20272;&#22270;&#24418;&#29983;&#25104;&#27169;&#22411;&#30340;&#31283;&#20581;&#12289;&#34920;&#36798;&#24615;&#30340;&#25551;&#36848;&#31526;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#24418;&#29983;&#25104;&#27169;&#22411;&#35780;&#20272;&#38656;&#35201;&#20102;&#35299;&#20998;&#24067;&#32423;&#21035;&#19978;&#30340;&#22270;&#24418;&#24046;&#24322;&#65292;&#36825;&#38656;&#35201;&#33021;&#22815;&#20197;&#26377;&#25928;&#30340;&#26041;&#24335;&#21033;&#29992;&#22270;&#24418;&#30340;&#26174;&#33879;&#23646;&#24615;&#12290;&#26354;&#29575;&#26159;&#22270;&#24418;&#30340;&#19968;&#31181;&#23646;&#24615;&#65292;&#26368;&#36817;&#24320;&#22987;&#35777;&#26126;&#20854;&#22312;&#25551;&#36848;&#22270;&#24418;&#26041;&#38754;&#24456;&#26377;&#29992;&#12290;&#28982;&#32780;&#65292;&#20854;&#34920;&#36798;&#24615;&#36136;&#12289;&#31283;&#23450;&#24615;&#21644;&#22312;&#27169;&#22411;&#35780;&#20272;&#20013;&#30340;&#23454;&#38469;&#25928;&#29992;&#20173;&#28982;&#24456;&#23569;&#34987;&#25506;&#32034;&#12290;&#25105;&#20204;&#23558;&#22270;&#24418;&#26354;&#29575;&#25551;&#36848;&#31526;&#19982;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#26032;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#20197;&#33719;&#24471;&#29992;&#20110;&#35780;&#20272;&#22270;&#24418;&#29983;&#25104;&#27169;&#22411;&#30340;&#31283;&#20581;&#12289;&#34920;&#36798;&#24615;&#30340;&#25551;&#36848;&#31526;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph generative model evaluation necessitates understanding differences between graphs on the distributional level. This entails being able to harness salient attributes of graphs in an efficient manner. Curvature constitutes one such property of graphs, and has recently started to prove useful in characterising graphs. Its expressive properties, stability, and practical utility in model evaluation remain largely unexplored, however. We combine graph curvature descriptors with emerging methods from topological data analysis to obtain robust, expressive descriptors for evaluating graph generative models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#26469;&#23454;&#29616;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#26368;&#20339;&#33218;&#35782;&#21035;&#65292;&#23427;&#26082;&#20855;&#26377;&#26368;&#20248;&#24615;&#33021;&#21448;&#35745;&#31639;&#19978;&#39640;&#25928;&#12290;</title><link>http://arxiv.org/abs/2301.03785</link><description>&lt;p&gt;
&#38543;&#26426;&#36172;&#21338;&#26426;&#20013;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;: &#36229;&#36234;$\beta-$&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
Best Arm Identification in Stochastic Bandits: Beyond $\beta-$optimality. (arXiv:2301.03785v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.03785
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#26469;&#23454;&#29616;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#26368;&#20339;&#33218;&#35782;&#21035;&#65292;&#23427;&#26082;&#20855;&#26377;&#26368;&#20248;&#24615;&#33021;&#21448;&#35745;&#31639;&#19978;&#39640;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22266;&#23450;&#32622;&#20449;&#27700;&#24179;&#19979;&#65292;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;BAI&#65289;&#30340;&#19968;&#20010;&#26410;&#26366;&#35299;&#20915;&#30340;&#26041;&#38754;&#12290;&#35780;&#20272;&#36172;&#21338;&#31639;&#27861;&#30340;&#20004;&#20010;&#20851;&#38190;&#25351;&#26631;&#26159;&#35745;&#31639;&#25928;&#29575;&#21644;&#24615;&#33021;&#26368;&#20248;&#24615;&#65288;&#20363;&#22914;&#37319;&#26679;&#22797;&#26434;&#24230;&#65289;&#12290;&#22312;&#38543;&#26426;BAI&#25991;&#29486;&#20013;&#65292;&#24050;&#32463;&#26377;&#20102;&#35774;&#35745;&#31639;&#27861;&#20197;&#23454;&#29616;&#26368;&#20248;&#24615;&#33021;&#30340;&#36827;&#23637;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#35745;&#31639;&#19978;&#26114;&#36149;&#65288;&#20363;&#22914;&#22522;&#20110;&#20248;&#21270;&#30340;&#26041;&#27861;&#65289;&#12290;&#20063;&#23384;&#22312;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#26041;&#27861;&#65292;&#20294;&#23427;&#20204;&#19982;&#26368;&#20248;&#24615;&#33021;&#20043;&#38388;&#23384;&#22312;&#21487;&#35777;&#26126;&#30340;&#24046;&#36317;&#65288;&#20363;&#22914;&#65292;&#21069;&#20004;&#31181;&#26041;&#27861;&#20013;&#30340;$\beta$-&#26368;&#20248;&#26041;&#27861;&#65289;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;BAI&#26694;&#26550;&#21644;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#19968;&#32452;&#35745;&#31639;&#19978;&#39640;&#25928;&#30340;&#20915;&#31574;&#35268;&#21017;&#23454;&#29616;&#20102;&#26368;&#20248;&#24615;&#33021;&#12290;&#23454;&#29616;&#36825;&#19968;&#28857;&#30340;&#20013;&#24515;&#27969;&#31243;&#26159;&#19968;&#20010;&#25353;&#39034;&#24207;&#20272;&#35745;&#26368;&#20339;&#20998;&#37197;&#30340;&#20363;&#31243;&#65292;&#30452;&#21040;&#36275;&#22815;&#20934;&#30830;&#22320;&#20272;&#35745;&#20026;&#27490;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#36825;&#20123;&#20272;&#35745;&#26159;&#20934;&#30830;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates a hitherto unaddressed aspect of best arm identification (BAI) in stochastic multi-armed bandits in the fixed-confidence setting. Two key metrics for assessing bandit algorithms are computational efficiency and performance optimality (e.g., in sample complexity). In stochastic BAI literature, there have been advances in designing algorithms to achieve optimal performance, but they are generally computationally expensive to implement (e.g., optimization-based methods). There also exist approaches with high computational efficiency, but they have provable gaps to the optimal performance (e.g., the $\beta$-optimal approaches in top-two methods). This paper introduces a framework and an algorithm for BAI that achieves optimal performance with a computationally efficient set of decision rules. The central process that facilitates this is a routine for sequentially estimating the optimal allocations up to sufficient fidelity. Specifically, these estimates are accurate
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;SPRT&#26694;&#26550;&#35774;&#35745;&#30340;BAI&#31639;&#27861;&#24182;&#36816;&#29992;&#20110;&#25351;&#25968;&#26063;&#36172;&#21338;&#26426;&#65292;&#35813;&#31639;&#27861;&#20855;&#26377;&#26679;&#26412;&#22797;&#26434;&#24230;&#28176;&#36817;&#26368;&#20248;&#21644;$\delta-$PAC&#20445;&#35777;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2207.11158</link><description>&lt;p&gt;
&#22522;&#20110;SPRT&#30340;&#38543;&#26426;&#36172;&#21338;&#26426;&#20013;&#30340;&#26368;&#20339;&#33218;&#36776;&#35782;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
SPRT-based Efficient Best Arm Identification in Stochastic Bandits. (arXiv:2207.11158v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.11158
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;SPRT&#26694;&#26550;&#35774;&#35745;&#30340;BAI&#31639;&#27861;&#24182;&#36816;&#29992;&#20110;&#25351;&#25968;&#26063;&#36172;&#21338;&#26426;&#65292;&#35813;&#31639;&#27861;&#20855;&#26377;&#26679;&#26412;&#22797;&#26434;&#24230;&#28176;&#36817;&#26368;&#20248;&#21644;$\delta-$PAC&#20445;&#35777;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#26426;&#22312;&#22266;&#23450;&#32622;&#20449;&#24230;&#22330;&#26223;&#19979;&#30340;&#26368;&#20339;&#33218;&#36776;&#35782;&#38382;&#39064;&#12290;&#32771;&#34385;&#21040;&#24191;&#20041;&#25351;&#25968;&#26063;&#36172;&#21338;&#26426;&#30340;&#31867;&#21035;&#12290;&#29616;&#26377;&#30340;&#25351;&#25968;&#26063;&#36172;&#21338;&#26426;&#31639;&#27861;&#38754;&#20020;&#35745;&#31639;&#25361;&#25112;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20123;&#25361;&#25112;&#65292;&#26368;&#20339;&#33218;&#36776;&#35782;&#38382;&#39064;&#34987;&#35270;&#20026;&#24207;&#36143;&#22797;&#21512;&#20551;&#35774;&#26816;&#39564;&#20219;&#21153;&#36827;&#34892;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26694;&#26550;&#65292;&#37319;&#29992;&#22522;&#20110;&#20284;&#28982;&#27604;&#30340;&#27979;&#35797;&#65292;&#36825;&#31181;&#27979;&#35797;&#24050;&#32463;&#35777;&#26126;&#23545;&#20110;&#24207;&#21015;&#27979;&#35797;&#26159;&#26377;&#25928;&#30340;&#12290;&#22522;&#20110;&#36825;&#20010;&#26816;&#39564;&#32479;&#35745;&#37327;&#65292;&#35774;&#35745;&#20102;&#19968;&#31181;BAI&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#20102;&#32463;&#20856;&#30340;&#24207;&#36143;&#27010;&#29575;&#27604;&#27979;&#35797;&#36827;&#34892;&#33218;&#30340;&#36873;&#25321;&#65292;&#24182;&#19988;&#26131;&#20110;&#20998;&#26512;&#25351;&#25968;&#26063;&#36172;&#21338;&#26426;&#12290;&#35813;&#31639;&#27861;&#20855;&#26377;&#20004;&#20010;&#20851;&#38190;&#29305;&#28857;&#65306;&#65288;1&#65289;&#23427;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#26159;&#28176;&#36817;&#26368;&#20248;&#30340;&#65292;&#65288;2&#65289;&#23427;&#20445;&#35777;&#26159;$\delta-$PAC&#30340;&#12290;&#29616;&#26377;&#30340;&#26377;&#25928;&#26041;&#27861;&#38598;&#20013;&#22312;&#39640;&#26031;&#26465;&#20214;&#19979;&#65292;&#24182;&#35201;&#27714;&#23545;&#34987;&#35748;&#20026;&#26159;&#26368;&#20339;&#33218;&#30340;&#33218;&#20351;&#29992;Thompson&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates the best arm identification (BAI) problem in stochastic multi-armed bandits in the fixed confidence setting. The general class of the exponential family of bandits is considered. The existing algorithms for the exponential family of bandits face computational challenges. To mitigate these challenges, the BAI problem is viewed and analyzed as a sequential composite hypothesis testing task, and a framework is proposed that adopts the likelihood ratio-based tests known to be effective for sequential testing. Based on this test statistic, a BAI algorithm is designed that leverages the canonical sequential probability ratio tests for arm selection and is amenable to tractable analysis for the exponential family of bandits. This algorithm has two key features: (1) its sample complexity is asymptotically optimal, and (2) it is guaranteed to be $\delta-$PAC. Existing efficient approaches focus on the Gaussian setting and require Thompson sampling for the arm deemed the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#27969;&#30340;&#26080;&#20284;&#28982;&#35757;&#32451;&#65292;&#25552;&#20986;&#20102;&#33021;&#37327;&#30446;&#26631;&#65292;&#25903;&#25345;&#21322;&#33258;&#22238;&#24402;&#33021;&#37327;&#27969;&#31561;&#28789;&#27963;&#30340;&#27169;&#22411;&#26550;&#26500;&#65292;&#24182;&#30456;&#23545;&#20110;&#22522;&#20110;&#20284;&#28982;&#24615;&#30340;&#27969;&#34920;&#29616;&#20986;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#65292;&#36136;&#30097;&#20102;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#20013;&#20197;&#26368;&#22823;&#20284;&#28982;&#20316;&#20026;&#30446;&#26631;&#25110;&#25351;&#26631;&#30340;&#20351;&#29992;&#65292;&#20026;&#29983;&#25104;&#24314;&#27169;&#30340;&#30740;&#31350;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2206.06672</link><description>&lt;p&gt;
&#21322;&#33258;&#22238;&#24402;&#33021;&#37327;&#27969;&#65306;&#25506;&#32034;&#27491;&#21017;&#21270;&#27969;&#30340;&#26080;&#20284;&#28982;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
Semi-Autoregressive Energy Flows: Exploring Likelihood-Free Training of Normalizing Flows. (arXiv:2206.06672v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.06672
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#27969;&#30340;&#26080;&#20284;&#28982;&#35757;&#32451;&#65292;&#25552;&#20986;&#20102;&#33021;&#37327;&#30446;&#26631;&#65292;&#25903;&#25345;&#21322;&#33258;&#22238;&#24402;&#33021;&#37327;&#27969;&#31561;&#28789;&#27963;&#30340;&#27169;&#22411;&#26550;&#26500;&#65292;&#24182;&#30456;&#23545;&#20110;&#22522;&#20110;&#20284;&#28982;&#24615;&#30340;&#27969;&#34920;&#29616;&#20986;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#65292;&#36136;&#30097;&#20102;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#20013;&#20197;&#26368;&#22823;&#20284;&#28982;&#20316;&#20026;&#30446;&#26631;&#25110;&#25351;&#26631;&#30340;&#20351;&#29992;&#65292;&#20026;&#29983;&#25104;&#24314;&#27169;&#30340;&#30740;&#31350;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#27491;&#21017;&#21270;&#27969;&#29983;&#25104;&#27169;&#22411;&#26102;&#65292;&#30001;&#20110;&#38656;&#35201;&#35745;&#31639;Jacobian&#34892;&#21015;&#24335;&#65292;&#22240;&#27492;&#20250;&#38754;&#20020;&#35745;&#31639;&#36127;&#25285;&#36739;&#37325;&#30340;&#25361;&#25112;&#12290;&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#27969;&#30340;&#26080;&#20284;&#28982;&#35757;&#32451;&#65292;&#24182;&#25552;&#20986;&#20102;&#33021;&#37327;&#30446;&#26631;&#65292;&#19968;&#31181;&#22522;&#20110;&#36866;&#24403;&#24471;&#20998;&#35268;&#21017;&#30340;&#26367;&#20195;&#22522;&#20110;&#26679;&#26412;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#33021;&#37327;&#30446;&#26631;&#26159;&#19981;&#38656;&#35201;&#34892;&#21015;&#24335;&#30340;&#65292;&#24182;&#25903;&#25345;&#28789;&#27963;&#30340;&#27169;&#22411;&#26550;&#26500;&#65292;&#36825;&#20123;&#26550;&#26500;&#19981;&#23481;&#26131;&#19982;&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#20860;&#23481;&#65292;&#21253;&#25324;&#21322;&#33258;&#22238;&#24402;&#33021;&#37327;&#27969;&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;&#26063;&#65292;&#21487;&#20197;&#25554;&#20540;&#20026;&#20840;&#33258;&#22238;&#24402;&#21644;&#38750;&#33258;&#22238;&#24402;&#27169;&#22411;&#20043;&#38388;&#12290;&#30456;&#23545;&#20110;&#22522;&#20110;&#20284;&#28982;&#24615;&#30340;&#27969;&#65292;&#33021;&#37327;&#27969;&#20855;&#26377;&#31454;&#20105;&#24615;&#30340;&#26679;&#26412;&#36136;&#37327;&#12289;&#21518;&#39564;&#25512;&#26029;&#21644;&#29983;&#25104;&#36895;&#24230;&#31561;&#24615;&#33021;&#65307;&#35813;&#24615;&#33021;&#19982;&#23545;&#25968;&#20284;&#28982;&#24230;&#37327;&#30340;&#36136;&#37327;&#36890;&#24120;&#38750;&#24120;&#24046;&#30340;&#36136;&#37327;&#26080;&#20851;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#23545;&#26368;&#22823;&#20284;&#28982;&#20316;&#20026;&#30446;&#26631;&#25110;&#25351;&#26631;&#30340;&#20351;&#29992;&#25552;&#20986;&#20102;&#36136;&#30097;&#65292;&#24182;&#26377;&#21161;&#20110;&#23545;&#20854;&#22312;&#29983;&#25104;&#24314;&#27169;&#20013;&#25152;&#36215;&#30340;&#20316;&#29992;&#36827;&#34892;&#31185;&#23398;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training normalizing flow generative models can be challenging due to the need to calculate computationally expensive determinants of Jacobians. This paper studies the likelihood-free training of flows and proposes the energy objective, an alternative sample-based loss based on proper scoring rules. The energy objective is determinant-free and supports flexible model architectures that are not easily compatible with maximum likelihood training, including semi-autoregressive energy flows, a novel model family that interpolates between fully autoregressive and non-autoregressive models. Energy flows feature competitive sample quality, posterior inference, and generation speed relative to likelihood-based flows; this performance is decorrelated from the quality of log-likelihood estimates, which are generally very poor. Our findings question the use of maximum likelihood as an objective or a metric, and contribute to a scientific study of its role in generative modeling.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#29992;&#20110;&#21463;&#38480;&#38750;&#20984;&#20248;&#21270;&#20013;&#30456;&#20851;&#25968;&#25454;&#37319;&#26679;&#30340;&#19968;&#38454;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#37319;&#29992;&#26356;&#21152;&#28201;&#21644;&#30340;&#28151;&#21512;&#26465;&#20214;&#65292;&#23558;&#22797;&#26434;&#24230;&#20174;$\tilde{O}(\varepsilon^{-8})$&#25552;&#21319;&#33267;$\tilde{O}(\varepsilon^{-4})$&#12290;</title><link>http://arxiv.org/abs/2203.15797</link><description>&lt;p&gt;
&#21463;&#38480;&#38750;&#20984;&#20248;&#21270;&#20013;&#20855;&#26377;&#30456;&#20851;&#25968;&#25454;&#30340;&#19968;&#38454;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Convergence of First-Order Methods for Constrained Nonconvex Optimization with Dependent Data. (arXiv:2203.15797v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.15797
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#29992;&#20110;&#21463;&#38480;&#38750;&#20984;&#20248;&#21270;&#20013;&#30456;&#20851;&#25968;&#25454;&#37319;&#26679;&#30340;&#19968;&#38454;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#37319;&#29992;&#26356;&#21152;&#28201;&#21644;&#30340;&#28151;&#21512;&#26465;&#20214;&#65292;&#23558;&#22797;&#26434;&#24230;&#20174;$\tilde{O}(\varepsilon^{-8})$&#25552;&#21319;&#33267;$\tilde{O}(\varepsilon^{-4})$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#21463;&#38480;&#20809;&#28369;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#20998;&#26512;&#20102;&#22312;&#19968;&#33324;&#30340;&#30456;&#20851;&#25968;&#25454;&#37319;&#26679;&#26041;&#26696;&#19979;&#30340;&#32463;&#20856;&#38543;&#26426;&#25237;&#24433;&#26799;&#24230;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#21033;&#29992;Moreau&#21253;&#32476;&#21644;&#26799;&#24230;&#26144;&#23556;&#33539;&#25968;&#23454;&#29616;$\varepsilon$-&#36817;&#20284;&#31283;&#23450;&#28857;&#30340;&#26368;&#22351;&#24773;&#20917;&#25910;&#25947;&#36895;&#29575;&#20026;$\tilde{O}(t^{-1/4})$&#65292;&#22797;&#26434;&#24230;&#20026;$\tilde{O}(\varepsilon^{-4})$&#12290;&#20256;&#32479;&#30340;&#25910;&#25947;&#20445;&#35777;&#38656;&#35201;&#20174;&#30446;&#26631;&#20998;&#24067;&#20013;&#36827;&#34892;i.i.d.&#25968;&#25454;&#37319;&#26679;&#65292;&#32780;&#25105;&#20204;&#21482;&#38656;&#35201;&#23545;&#26465;&#20214;&#20998;&#24067;&#36827;&#34892;&#19968;&#31181;&#36739;&#28201;&#21644;&#30340;&#28151;&#21512;&#26465;&#20214;&#21363;&#21487;&#65292;&#35813;&#26465;&#20214;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#37319;&#26679;&#31639;&#27861;&#12290;&#30456;&#36739;&#20110;&#29616;&#26377;&#30340;&#21463;&#38480;&#20809;&#28369;&#38750;&#20984;&#20248;&#21270;&#21644;&#30456;&#20851;&#25968;&#25454;&#30340;&#22797;&#26434;&#24230;&#20026;$\tilde{O}(\varepsilon^{-8})$&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#32463;&#36807;&#31616;&#21270;&#20998;&#26512;&#21518;&#22797;&#26434;&#24230;&#20026;$\tilde{O}(\varepsilon^{-4})$&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;&#30456;&#20851;&#25968;&#25454;&#24773;&#20917;&#19979;&#38543;&#26426;&#36817;&#31471;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We focus on analyzing the classical stochastic projected gradient methods under a general dependent data sampling scheme for constrained smooth nonconvex optimization. We show the worst-case rate of convergence $\tilde{O}(t^{-1/4})$ and complexity $\tilde{O}(\varepsilon^{-4})$ for achieving an $\varepsilon$-near stationary point in terms of the norm of the gradient of Moreau envelope and gradient mapping. While classical convergence guarantee requires i.i.d. data sampling from the target distribution, we only require a mild mixing condition of the conditional distribution, which holds for a wide class of Markov chain sampling algorithms. This improves the existing complexity for the constrained smooth nonconvex optimization with dependent data from $\tilde{O}(\varepsilon^{-8})$ to $\tilde{O}(\varepsilon^{-4})$ with a significantly simpler analysis. We illustrate the generality of our approach by deriving convergence results with dependent data for stochastic proximal gradient methods, 
&lt;/p&gt;</description></item></channel></rss>