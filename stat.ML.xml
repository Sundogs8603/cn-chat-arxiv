<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#22312;&#20809;&#28369;&#12289;&#24378;&#20984;&#29615;&#22659;&#20013;&#38543;&#26426;&#37325;&#21147;&#29699;&#21160;&#37327;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#24403;&#25209;&#37327;&#22823;&#23567;&#22823;&#20110;&#26576;&#20010;&#38408;&#20540;&#26102;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#21152;&#36895;&#25910;&#25947;&#36895;&#24230;&#12290;&#38024;&#23545;&#24378;&#20984;&#20108;&#27425;&#20989;&#25968;&#65292;&#25105;&#20204;&#24314;&#35758;&#20102;&#19968;&#31181;&#22122;&#22768;&#33258;&#36866;&#24212;&#30340;&#22810;&#38454;&#27573;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;&#25910;&#25947;&#36895;&#24230;&#36827;&#19968;&#27493;&#25552;&#39640;&#12290;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.06738</link><description>&lt;p&gt;
&#22122;&#22768;&#33258;&#36866;&#24212;&#65288;&#21152;&#36895;&#65289;&#38543;&#26426;&#37325;&#21147;&#29699;&#21160;&#37327;
&lt;/p&gt;
&lt;p&gt;
Noise-adaptive (Accelerated) Stochastic Heavy-Ball Momentum. (arXiv:2401.06738v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06738
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#22312;&#20809;&#28369;&#12289;&#24378;&#20984;&#29615;&#22659;&#20013;&#38543;&#26426;&#37325;&#21147;&#29699;&#21160;&#37327;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#24403;&#25209;&#37327;&#22823;&#23567;&#22823;&#20110;&#26576;&#20010;&#38408;&#20540;&#26102;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#21152;&#36895;&#25910;&#25947;&#36895;&#24230;&#12290;&#38024;&#23545;&#24378;&#20984;&#20108;&#27425;&#20989;&#25968;&#65292;&#25105;&#20204;&#24314;&#35758;&#20102;&#19968;&#31181;&#22122;&#22768;&#33258;&#36866;&#24212;&#30340;&#22810;&#38454;&#27573;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;&#25910;&#25947;&#36895;&#24230;&#36827;&#19968;&#27493;&#25552;&#39640;&#12290;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#20102;&#22312;&#20809;&#28369;&#65292;&#24378;&#20984;&#29615;&#22659;&#20013;&#38543;&#26426;&#37325;&#21147;&#29699;&#21160;&#37327;&#65288;SHB&#65289;&#30340;&#25910;&#25947;&#24615;&#12290;Kidambi&#31561;&#20154;&#65288;2018&#65289;&#34920;&#26126;&#65292;&#23545;&#20110;&#20108;&#27425;&#20989;&#25968;&#65292;SHB&#65288;&#24102;&#26377;&#23567;&#25209;&#37327;&#65289;&#26080;&#27861;&#36798;&#21040;&#21152;&#36895;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#29468;&#24819;SHB&#30340;&#23454;&#38469;&#25910;&#30410;&#26159;&#23567;&#25209;&#37327;&#30340;&#21103;&#20135;&#21697;&#12290;&#25105;&#20204;&#36890;&#36807;&#23637;&#31034;&#24403;&#25209;&#37327;&#22823;&#23567;&#22823;&#20110;&#19968;&#23450;&#38408;&#20540;&#26102;&#65292;SHB&#21487;&#20197;&#33719;&#24471;&#21152;&#36895;&#30340;&#25910;&#25947;&#36895;&#24230;&#26469;&#35777;&#23454;&#36825;&#19968;&#35266;&#28857;&#12290;&#29305;&#21035;&#22320;&#65292;&#23545;&#20110;&#26465;&#20214;&#25968;&#20026;$\kappa$&#30340;&#24378;&#20984;&#20108;&#27425;&#20989;&#25968;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20351;&#29992;&#26631;&#20934;&#27493;&#38271;&#21644;&#21160;&#37327;&#21442;&#25968;&#30340;SHB&#20855;&#26377;$O\left(\exp(-\frac{T}{\sqrt{\kappa}}) + \sigma \right)$&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#20854;&#20013;$T$&#20026;&#36845;&#20195;&#27425;&#25968;&#65292;$\sigma^2$&#20026;&#38543;&#26426;&#26799;&#24230;&#30340;&#26041;&#24046;&#12290;&#20026;&#30830;&#20445;&#25910;&#25947;&#21040;&#26497;&#23567;&#20540;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#38454;&#27573;&#26041;&#27861;&#65292;&#32467;&#26524;&#26159;&#22122;&#22768;&#33258;&#36866;&#24212;&#30340;$O\left(\exp\left(-\frac{T}{\sqrt{\kappa}} \right) + \frac{\sigma}{T}\right)$&#36895;&#24230;&#12290;&#23545;&#20110;&#19968;&#33324;&#30340;&#24378;&#20984;&#20989;&#25968;&#65292;&#25105;&#20204;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyze the convergence of stochastic heavy ball (SHB) momentum in the smooth, strongly-convex setting. Kidambi et al. (2018) show that SHB (with small mini-batches) cannot attain an accelerated rate of convergence even for quadratics, and conjecture that the practical gain of SHB is a by-product of mini-batching. We substantiate this claim by showing that SHB can obtain an accelerated rate when the mini-batch size is larger than some threshold. In particular, for strongly-convex quadratics with condition number $\kappa$, we prove that SHB with the standard step-size and momentum parameters results in an $O\left(\exp(-\frac{T}{\sqrt{\kappa}}) + \sigma \right)$ convergence rate, where $T$ is the number of iterations and $\sigma^2$ is the variance in the stochastic gradients. To ensure convergence to the minimizer, we propose a multi-stage approach that results in a noise-adaptive $O\left(\exp\left(-\frac{T}{\sqrt{\kappa}} \right) + \frac{\sigma}{T}\right)$ rate. For general strongly-
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#25552;&#20986;&#19981;&#30830;&#23450;&#24615;&#21306;&#38388;&#65292;&#23454;&#29616;&#20102;&#22312;&#23384;&#22312;&#26410;&#35266;&#27979;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#21644;&#39640;&#32500;&#24230;&#24178;&#25200;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#30340;&#26377;&#25928;&#21322;&#21442;&#25968;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2401.06564</link><description>&lt;p&gt;
&#22312;&#39640;&#32500;&#24230;&#35774;&#32622;&#20013;&#22788;&#29702;&#26410;&#35266;&#27979;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#26377;&#25928;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Valid causal inference with unobserved confounding in high-dimensional settings. (arXiv:2401.06564v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06564
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#25552;&#20986;&#19981;&#30830;&#23450;&#24615;&#21306;&#38388;&#65292;&#23454;&#29616;&#20102;&#22312;&#23384;&#22312;&#26410;&#35266;&#27979;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#21644;&#39640;&#32500;&#24230;&#24178;&#25200;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#30340;&#26377;&#25928;&#21322;&#21442;&#25968;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#24050;&#25552;&#20986;&#20102;&#21508;&#31181;&#26041;&#27861;&#26469;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#36890;&#36807;&#21518;&#27169;&#22411;&#36873;&#25321;&#25110;&#26426;&#22120;&#23398;&#20064;&#20272;&#35745;&#22120;&#23545;&#39640;&#32500;&#24230;&#24178;&#25200;&#27169;&#22411;&#36827;&#34892;&#20272;&#35745;&#65292;&#20174;&#32780;&#33719;&#24471;&#32479;&#19968;&#26377;&#25928;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#35201;&#27714;&#35266;&#27979;&#21040;&#25152;&#26377;&#28151;&#28102;&#22240;&#32032;&#20197;&#30830;&#20445;&#25928;&#26524;&#30340;&#35782;&#21035;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#22312;&#20110;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#23384;&#22312;&#26410;&#35266;&#27979;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#21644;&#39640;&#32500;&#24230;&#24178;&#25200;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#33719;&#24471;&#26377;&#25928;&#30340;&#21322;&#21442;&#25968;&#25512;&#26029;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19981;&#30830;&#23450;&#24615;&#21306;&#38388;&#65292;&#20801;&#35768;&#23384;&#22312;&#26410;&#35266;&#27979;&#21040;&#30340;&#28151;&#28102;&#65292;&#24182;&#19988;&#24403;&#26410;&#35266;&#27979;&#21040;&#30340;&#28151;&#28102;&#30456;&#23545;&#20110;&#26679;&#26412;&#37327;&#24456;&#23567;&#26102;&#65292;&#32467;&#26524;&#25512;&#26029;&#26159;&#26377;&#25928;&#30340;&#65307;&#21518;&#32773;&#29992;&#25910;&#25947;&#36895;&#29575;&#26469;&#24418;&#24335;&#21270;&#12290;&#36890;&#36807;&#20223;&#30495;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#21306;&#38388;&#30340;&#26377;&#38480;&#26679;&#26412;&#24615;&#36136;&#65292;&#24182;&#30740;&#31350;&#20102;&#19968;&#31181;&#25913;&#36827;&#21306;&#38388;&#30340;&#32463;&#39564;&#35206;&#30422;&#29575;&#30340;&#26367;&#20195;&#31243;&#24207;&#65292;&#24403;&#26410;&#35266;&#27979;&#21040;&#30340;&#28151;&#28102;&#30340;&#25968;&#37327;&#36739;&#22823;&#26102;&#65292;&#21487;&#20197;&#25552;&#39640;&#21306;&#38388;&#30340;&#35206;&#30422;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Various methods have recently been proposed to estimate causal effects with confidence intervals that are uniformly valid over a set of data generating processes when high-dimensional nuisance models are estimated by post-model-selection or machine learning estimators. These methods typically require that all the confounders are observed to ensure identification of the effects. We contribute by showing how valid semiparametric inference can be obtained in the presence of unobserved confounders and high-dimensional nuisance models. We propose uncertainty intervals which allow for unobserved confounding, and show that the resulting inference is valid when the amount of unobserved confounding is small relative to the sample size; the latter is formalized in terms of convergence rates. Simulation experiments illustrate the finite sample properties of the proposed intervals and investigate an alternative procedure that improves the empirical coverage of the intervals when the amount of unob
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25552;&#21319;&#26041;&#27861;&#30340;&#23398;&#20064;&#21152;&#27861;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#31867;&#35780;&#20998;&#20989;&#25968;&#21644;&#36880;&#20998;&#37327;&#26799;&#24230;&#19979;&#38477;&#30340;&#31574;&#30053;&#26469;&#30830;&#23450;&#21464;&#37327;&#38388;&#30340;&#22240;&#26524;&#39034;&#24207;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#39640;&#32500;&#25968;&#25454;&#38598;&#20013;&#20855;&#26377;&#31454;&#20105;&#21147;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.06523</link><description>&lt;p&gt;
&#25552;&#21319;&#22240;&#26524;&#21152;&#27861;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Boosting Causal Additive Models. (arXiv:2401.06523v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06523
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25552;&#21319;&#26041;&#27861;&#30340;&#23398;&#20064;&#21152;&#27861;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#31867;&#35780;&#20998;&#20989;&#25968;&#21644;&#36880;&#20998;&#37327;&#26799;&#24230;&#19979;&#38477;&#30340;&#31574;&#30053;&#26469;&#30830;&#23450;&#21464;&#37327;&#38388;&#30340;&#22240;&#26524;&#39034;&#24207;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#39640;&#32500;&#25968;&#25454;&#38598;&#20013;&#20855;&#26377;&#31454;&#20105;&#21147;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25552;&#21319;&#26041;&#27861;&#30340;&#23398;&#20064;&#21152;&#27861;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;(SEMs)&#30340;&#26041;&#27861;&#65292;&#37325;&#28857;&#20851;&#27880;&#30830;&#23450;&#21464;&#37327;&#38388;&#22240;&#26524;&#39034;&#24207;&#30340;&#29702;&#35770;&#26041;&#38754;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31867;&#22522;&#20110;&#20219;&#24847;&#22238;&#24402;&#25216;&#26415;&#30340;&#35780;&#20998;&#20989;&#25968;&#65292;&#20026;&#20854;&#24314;&#31435;&#20102;&#19968;&#33268;&#22320;&#25903;&#25345;&#30495;&#23454;&#22240;&#26524;&#39034;&#24207;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#25552;&#21319;&#26041;&#27861;&#19982;&#25552;&#21069;&#20572;&#27490;&#31526;&#21512;&#36825;&#20123;&#26465;&#20214;&#65292;&#20174;&#32780;&#20026;&#22240;&#26524;&#39034;&#24207;&#25552;&#20379;&#20102;&#19968;&#33268;&#30340;&#35780;&#20998;&#20989;&#25968;&#12290;&#20026;&#20102;&#24212;&#23545;&#39640;&#32500;&#25968;&#25454;&#38598;&#24102;&#26469;&#30340;&#25361;&#25112;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#21152;&#27861;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#31354;&#38388;&#20013;&#36827;&#34892;&#36880;&#20998;&#37327;&#26799;&#24230;&#19979;&#38477;&#26469;&#25913;&#36827;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#27169;&#25311;&#30740;&#31350;&#24378;&#35843;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#22312;&#36739;&#20302;&#32500;&#24230;&#19979;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#39640;&#32500;&#36866;&#24212;&#26041;&#27861;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#30456;&#24403;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23545;&#20110;&#36229;&#21442;&#25968;&#30340;&#36873;&#25321;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#20351;&#24471;&#31243;&#24207;&#26131;&#20110;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a boosting-based method to learn additive Structural Equation Models (SEMs) from observational data, with a focus on the theoretical aspects of determining the causal order among variables. We introduce a family of score functions based on arbitrary regression techniques, for which we establish necessary conditions to consistently favor the true causal ordering. Our analysis reveals that boosting with early stopping meets these criteria and thus offers a consistent score function for causal orderings. To address the challenges posed by high-dimensional data sets, we adapt our approach through a component-wise gradient descent in the space of additive SEMs. Our simulation study underlines our theoretical results for lower dimensions and demonstrates that our high-dimensional adaptation is competitive with state-of-the-art methods. In addition, it exhibits robustness with respect to the choice of the hyperparameters making the procedure easy to tune.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#32508;&#21512;&#30340;&#22810;&#20445;&#30495;&#24230;&#20195;&#29702;&#24314;&#27169;&#26694;&#26550;&#65292;&#33021;&#22815;&#23558;&#40657;&#30418;&#27169;&#22411;&#21644;&#30333;&#30418;&#27169;&#22411;&#30340;&#20449;&#24687;&#32467;&#21512;&#36215;&#26469;&#65292;&#24182;&#33021;&#22815;&#22788;&#29702;&#22122;&#22768;&#27745;&#26579;&#30340;&#25968;&#25454;&#65292;&#24182;&#20272;&#35745;&#20986;&#26080;&#22122;&#22768;&#30340;&#39640;&#20445;&#30495;&#24230;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2401.06447</link><description>&lt;p&gt;
&#19968;&#20010;&#32508;&#21512;&#30340;&#22810;&#20445;&#30495;&#24230;&#20195;&#29702;&#24314;&#27169;&#26694;&#26550;&#65292;&#24102;&#26377;&#22122;&#22768;&#25968;&#25454;&#65306;&#20174;&#28784;&#30418;&#30340;&#35282;&#24230;&#26469;&#30475;
&lt;/p&gt;
&lt;p&gt;
A comprehensive framework for multi-fidelity surrogate modeling with noisy data: a gray-box perspective. (arXiv:2401.06447v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06447
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#32508;&#21512;&#30340;&#22810;&#20445;&#30495;&#24230;&#20195;&#29702;&#24314;&#27169;&#26694;&#26550;&#65292;&#33021;&#22815;&#23558;&#40657;&#30418;&#27169;&#22411;&#21644;&#30333;&#30418;&#27169;&#22411;&#30340;&#20449;&#24687;&#32467;&#21512;&#36215;&#26469;&#65292;&#24182;&#33021;&#22815;&#22788;&#29702;&#22122;&#22768;&#27745;&#26579;&#30340;&#25968;&#25454;&#65292;&#24182;&#20272;&#35745;&#20986;&#26080;&#22122;&#22768;&#30340;&#39640;&#20445;&#30495;&#24230;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35745;&#31639;&#26426;&#27169;&#25311;&#65288;&#21363;&#30333;&#30418;&#27169;&#22411;&#65289;&#22312;&#27169;&#25311;&#22797;&#26434;&#24037;&#31243;&#31995;&#32479;&#26041;&#38754;&#27604;&#20197;&#24448;&#20219;&#20309;&#26102;&#20505;&#37117;&#26356;&#21152;&#24517;&#19981;&#21487;&#23569;&#12290;&#28982;&#32780;&#65292;&#20165;&#20973;&#35745;&#31639;&#27169;&#22411;&#24448;&#24448;&#26080;&#27861;&#23436;&#20840;&#25429;&#25417;&#29616;&#23454;&#30340;&#22797;&#26434;&#24615;&#12290;&#24403;&#29289;&#29702;&#23454;&#39564;&#21487;&#34892;&#26102;&#65292;&#22686;&#24378;&#35745;&#31639;&#27169;&#22411;&#25552;&#20379;&#30340;&#19981;&#23436;&#25972;&#20449;&#24687;&#21464;&#24471;&#38750;&#24120;&#37325;&#35201;&#12290;&#28784;&#30418;&#24314;&#27169;&#28041;&#21450;&#21040;&#23558;&#25968;&#25454;&#39537;&#21160;&#27169;&#22411;&#65288;&#21363;&#40657;&#30418;&#27169;&#22411;&#65289;&#21644;&#30333;&#30418;&#27169;&#22411;&#65288;&#21363;&#22522;&#20110;&#29289;&#29702;&#30340;&#27169;&#22411;&#65289;&#30340;&#20449;&#24687;&#34701;&#21512;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#22810;&#20445;&#30495;&#24230;&#20195;&#29702;&#27169;&#22411;&#65288;MFSMs&#65289;&#26469;&#25191;&#34892;&#36825;&#20010;&#20219;&#21153;&#12290;MFSM&#23558;&#19981;&#21516;&#35745;&#31639;&#20445;&#30495;&#24230;&#30340;&#27169;&#22411;&#30340;&#20449;&#24687;&#38598;&#25104;&#21040;&#19968;&#20010;&#26032;&#30340;&#20195;&#29702;&#27169;&#22411;&#20013;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#22810;&#20445;&#30495;&#24230;&#20195;&#29702;&#24314;&#27169;&#26694;&#26550;&#33021;&#22815;&#22788;&#29702;&#34987;&#22122;&#22768;&#27745;&#26579;&#30340;&#25968;&#25454;&#65292;&#24182;&#33021;&#22815;&#20272;&#35745;&#24213;&#23618;&#26080;&#22122;&#22768;&#30340;&#39640;&#20445;&#30495;&#24230;&#20989;&#25968;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#24378;&#35843;&#20197;&#32622;&#20449;&#24230;&#30340;&#24418;&#24335;&#25552;&#20379;&#20854;&#39044;&#27979;&#20013;&#19981;&#30830;&#23450;&#24615;&#30340;&#31934;&#30830;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Computer simulations (a.k.a. white-box models) are more indispensable than ever to model intricate engineering systems. However, computational models alone often fail to fully capture the complexities of reality. When physical experiments are accessible though, it is of interest to enhance the incomplete information offered by computational models. Gray-box modeling is concerned with the problem of merging information from data-driven (a.k.a. black-box) models and white-box (i.e., physics-based) models. In this paper, we propose to perform this task by using multi-fidelity surrogate models (MFSMs). A MFSM integrates information from models with varying computational fidelity into a new surrogate model. The multi-fidelity surrogate modeling framework we propose handles noise-contaminated data and is able to estimate the underlying noise-free high-fidelity function. Our methodology emphasizes on delivering precise estimates of the uncertainty in its predictions in the form of confidence 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#39640;&#25928;&#30340;&#22522;&#20110;&#25193;&#25955;&#30340;&#33945;&#29305;&#21345;&#32599;&#37319;&#26679;&#31639;&#27861;RS-DMC&#65292;&#36890;&#36807;&#25913;&#36827;&#35780;&#20998;&#20272;&#35745;&#26041;&#27861;&#26469;&#35299;&#20915;&#21407;&#22987;DMC&#31639;&#27861;&#30340;&#26799;&#24230;&#22797;&#26434;&#24615;&#38382;&#39064;&#12290;&#35813;&#31639;&#27861;&#23558;&#25972;&#20010;&#25193;&#25955;&#36807;&#31243;&#21010;&#20998;&#20026;&#22810;&#20010;&#27573;&#33853;&#65292;&#24182;&#20351;&#29992;&#36882;&#24402;&#35780;&#20998;&#20272;&#35745;&#23454;&#29616;&#26356;&#24555;&#30340;&#37319;&#26679;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2401.06325</link><description>&lt;p&gt;
&#36890;&#36807;&#22522;&#20110;&#25193;&#25955;&#30340;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#23454;&#29616;&#26356;&#24555;&#30340;&#37319;&#26679;&#32780;&#26080;&#38656;&#31561;&#28201;&#24615;  (arXiv:2401.06325v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
Faster Sampling without Isoperimetry via Diffusion-based Monte Carlo. (arXiv:2401.06325v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06325
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#39640;&#25928;&#30340;&#22522;&#20110;&#25193;&#25955;&#30340;&#33945;&#29305;&#21345;&#32599;&#37319;&#26679;&#31639;&#27861;RS-DMC&#65292;&#36890;&#36807;&#25913;&#36827;&#35780;&#20998;&#20272;&#35745;&#26041;&#27861;&#26469;&#35299;&#20915;&#21407;&#22987;DMC&#31639;&#27861;&#30340;&#26799;&#24230;&#22797;&#26434;&#24615;&#38382;&#39064;&#12290;&#35813;&#31639;&#27861;&#23558;&#25972;&#20010;&#25193;&#25955;&#36807;&#31243;&#21010;&#20998;&#20026;&#22810;&#20010;&#27573;&#33853;&#65292;&#24182;&#20351;&#29992;&#36882;&#24402;&#35780;&#20998;&#20272;&#35745;&#23454;&#29616;&#26356;&#24555;&#30340;&#37319;&#26679;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#20174;&#19968;&#33324;&#30340;&#30446;&#26631;&#20998;&#24067;$p_*\propto e^{-f_*}$&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#36229;&#36234;&#31561;&#28201;&#26465;&#20214;&#65292;Huang&#31561;&#20154;&#65288;2023&#65289;&#25552;&#20986;&#20102;&#36890;&#36807;&#21453;&#21521;&#25193;&#25955;&#36827;&#34892;&#37319;&#26679;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#22522;&#20110;&#25193;&#25955;&#30340;&#33945;&#29305;&#21345;&#32599;&#65288;DMC&#65289;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;DMC&#36981;&#24490;&#25193;&#25955;&#36807;&#31243;&#30340;&#21453;&#21521;SDE&#65292;&#23558;&#30446;&#26631;&#20998;&#24067;&#36716;&#21270;&#20026;&#26631;&#20934;&#39640;&#26031;&#20998;&#24067;&#65292;&#24182;&#21033;&#29992;&#38750;&#21442;&#25968;&#35780;&#20998;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#21407;&#22987;&#30340;DMC&#31639;&#27861;&#36935;&#21040;&#20102;&#39640;&#26799;&#24230;&#22797;&#26434;&#24615;&#30340;&#38382;&#39064;&#65292;&#23548;&#33268;&#23545;&#33719;&#24471;&#30340;&#26679;&#26412;&#30340;&#35823;&#24046;&#23481;&#24046;$\epsilon$&#30340;&#20381;&#36182;&#25104;&#25351;&#25968;&#22686;&#38271;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;DMC&#30340;&#39640;&#22797;&#26434;&#24615;&#28304;&#20110;&#20854;&#20887;&#20313;&#30340;&#35780;&#20998;&#20272;&#35745;&#35774;&#35745;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;RS-DMC&#65292;&#22522;&#20110;&#19968;&#31181;&#26032;&#39062;&#30340;&#36882;&#24402;&#35780;&#20998;&#20272;&#35745;&#26041;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#39318;&#20808;&#23558;&#25972;&#20010;&#25193;&#25955;&#36807;&#31243;&#21010;&#20998;&#20026;&#22810;&#20010;&#27573;&#33853;&#65292;&#28982;&#21518;&#23558;&#35780;&#20998;&#20272;&#35745;&#27493;&#39588;&#65288;&#22312;&#20219;&#20309;&#26102;&#38388;&#27493;&#39588;&#65289;&#24418;&#24335;&#21270;&#20026;&#19968;&#31995;&#21015;&#30456;&#20114;&#36830;&#25509;&#30340;&#22343;&#20540;&#20272;&#35745;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;
To sample from a general target distribution $p_*\propto e^{-f_*}$ beyond the isoperimetric condition, Huang et al. (2023) proposed to perform sampling through reverse diffusion, giving rise to Diffusion-based Monte Carlo (DMC). Specifically, DMC follows the reverse SDE of a diffusion process that transforms the target distribution to the standard Gaussian, utilizing a non-parametric score estimation. However, the original DMC algorithm encountered high gradient complexity, resulting in an exponential dependency on the error tolerance $\epsilon$ of the obtained samples. In this paper, we demonstrate that the high complexity of DMC originates from its redundant design of score estimation, and proposed a more efficient algorithm, called RS-DMC, based on a novel recursive score estimation method. In particular, we first divide the entire diffusion process into multiple segments and then formulate the score estimation step (at any time step) as a series of interconnected mean estimation an
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26641;&#30340;&#21487;&#21464;&#31995;&#25968;&#27169;&#22411;&#65292;&#20351;&#29992;&#24490;&#29615;&#26799;&#24230;&#25552;&#21319;&#26426;&#36827;&#34892;&#24314;&#27169;&#65292;&#23454;&#29616;&#20102;&#36880;&#32500;&#26089;&#20572;&#21644;&#29305;&#24449;&#37325;&#35201;&#24615;&#35780;&#20998;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#20135;&#29983;&#19982;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;VCM&#30456;&#24403;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.05982</link><description>&lt;p&gt;
&#22522;&#20110;&#26641;&#30340;&#21487;&#21464;&#31995;&#25968;&#27169;&#22411;&#20171;&#32461;
&lt;/p&gt;
&lt;p&gt;
A tree-based varying coefficient model. (arXiv:2401.05982v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05982
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26641;&#30340;&#21487;&#21464;&#31995;&#25968;&#27169;&#22411;&#65292;&#20351;&#29992;&#24490;&#29615;&#26799;&#24230;&#25552;&#21319;&#26426;&#36827;&#34892;&#24314;&#27169;&#65292;&#23454;&#29616;&#20102;&#36880;&#32500;&#26089;&#20572;&#21644;&#29305;&#24449;&#37325;&#35201;&#24615;&#35780;&#20998;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#20135;&#29983;&#19982;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;VCM&#30456;&#24403;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26641;&#30340;&#21487;&#21464;&#31995;&#25968;&#27169;&#22411;(VCM)&#65292;&#20854;&#20013;&#21487;&#21464;&#31995;&#25968;&#20351;&#29992;Delong&#31561;&#20154;(2023)&#30340;&#24490;&#29615;&#26799;&#24230;&#25552;&#21319;&#26426;(CGBM)&#36827;&#34892;&#24314;&#27169;&#12290;&#20351;&#29992;CGBM&#23545;&#31995;&#25968;&#20989;&#25968;&#36827;&#34892;&#24314;&#27169;&#65292;&#21487;&#20197;&#36827;&#34892;&#36880;&#32500;&#26089;&#20572;&#21644;&#29305;&#24449;&#37325;&#35201;&#24615;&#35780;&#20998;&#12290;&#36880;&#32500;&#26089;&#20572;&#19981;&#20165;&#21487;&#20197;&#20943;&#23569;&#32500;&#24230;&#29305;&#23450;&#30340;&#36807;&#25311;&#21512;&#39118;&#38505;&#65292;&#36824;&#21487;&#20197;&#25581;&#31034;&#32500;&#24230;&#20043;&#38388;&#27169;&#22411;&#22797;&#26434;&#24615;&#30340;&#24046;&#24322;&#12290;&#20351;&#29992;&#29305;&#24449;&#37325;&#35201;&#24615;&#35780;&#20998;&#21487;&#20197;&#36827;&#34892;&#31616;&#21333;&#30340;&#29305;&#24449;&#36873;&#25321;&#21644;&#26131;&#20110;&#35299;&#37322;&#30340;&#27169;&#22411;&#35299;&#37322;&#12290;&#35813;&#27169;&#22411;&#22312;Richman&#21644;W&#252;thrich&#65288;2023&#65289;&#20351;&#29992;&#30340;&#30456;&#21516;&#30340;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#31034;&#20363;&#19978;&#36827;&#34892;&#35780;&#20272;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#23427;&#22312;&#26679;&#26412;&#22806;&#25439;&#22833;&#26041;&#38754;&#20135;&#29983;&#20102;&#19982;&#20182;&#20204;&#30340;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;VCM LocalGLMnet&#30456;&#24403;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
The paper introduces a tree-based varying coefficient model (VCM) where the varying coefficients are modelled using the cyclic gradient boosting machine (CGBM) from Delong et al. (2023). Modelling the coefficient functions using a CGBM allows for dimension-wise early stopping and feature importance scores. The dimension-wise early stopping not only reduces the risk of dimension-specific overfitting, but also reveals differences in model complexity across dimensions. The use of feature importance scores allows for simple feature selection and easy model interpretation. The model is evaluated on the same simulated and real data examples as those used in Richman and W\"uthrich (2023), and the results show that it produces results in terms of out of sample loss that are comparable to those of their neural network-based VCM called LocalGLMnet.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#24635;&#25351;&#25968;&#36827;&#34892;&#22240;&#23376;&#37325;&#35201;&#24615;&#25490;&#21517;&#21644;&#36873;&#25321;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#19981;&#20381;&#36182;&#20110;&#29305;&#23450;&#30340;&#39044;&#27979;&#31639;&#27861;&#65292;&#21487;&#20197;&#30452;&#25509;&#20174;&#26377;&#22122;&#22768;&#30340;&#25968;&#25454;&#20013;&#20272;&#35745;&#22240;&#23376;&#30340;&#39044;&#27979;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2401.00800</link><description>&lt;p&gt;
&#20351;&#29992;&#24635;&#25351;&#25968;&#36827;&#34892;&#22240;&#23376;&#37325;&#35201;&#24615;&#25490;&#21517;&#21644;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Factor Importance Ranking and Selection using Total Indices. (arXiv:2401.00800v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.00800
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#24635;&#25351;&#25968;&#36827;&#34892;&#22240;&#23376;&#37325;&#35201;&#24615;&#25490;&#21517;&#21644;&#36873;&#25321;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#19981;&#20381;&#36182;&#20110;&#29305;&#23450;&#30340;&#39044;&#27979;&#31639;&#27861;&#65292;&#21487;&#20197;&#30452;&#25509;&#20174;&#26377;&#22122;&#22768;&#30340;&#25968;&#25454;&#20013;&#20272;&#35745;&#22240;&#23376;&#30340;&#39044;&#27979;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#23376;&#37325;&#35201;&#24615;&#34913;&#37327;&#20102;&#27599;&#20010;&#29305;&#24449;&#23545;&#36755;&#20986;&#39044;&#27979;&#20934;&#30830;&#24615;&#30340;&#24433;&#21709;&#12290;&#35768;&#22810;&#29616;&#26377;&#30340;&#30740;&#31350;&#20851;&#27880;&#22522;&#20110;&#27169;&#22411;&#30340;&#37325;&#35201;&#24615;&#65292;&#20294;&#19968;&#20010;&#23398;&#20064;&#31639;&#27861;&#20013;&#30340;&#37325;&#35201;&#29305;&#24449;&#22312;&#21478;&#19968;&#20010;&#27169;&#22411;&#20013;&#21487;&#33021;&#27809;&#26377;&#22810;&#22823;&#24847;&#20041;&#12290;&#22240;&#27492;&#65292;&#19968;&#20010;&#22240;&#23376;&#37325;&#35201;&#24615;&#24230;&#37327;&#24212;&#35813;&#22312;&#19981;&#20381;&#36182;&#20110;&#29305;&#23450;&#39044;&#27979;&#31639;&#27861;&#30340;&#24773;&#20917;&#19979;&#34920;&#24449;&#29305;&#24449;&#30340;&#39044;&#27979;&#28508;&#21147;&#12290;&#35813;&#31639;&#27861;&#26080;&#20851;&#30340;&#37325;&#35201;&#24615;&#34987;&#31216;&#20026;&#20869;&#22312;&#37325;&#35201;&#24615;&#12290;&#20026;&#20102;&#32469;&#36807;&#24314;&#27169;&#36807;&#31243;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#39044;&#27979;&#28508;&#21147;&#19982;&#20840;&#23616;&#25935;&#24863;&#24615;&#20998;&#26512;&#20013;&#30340;&#24635;Sobol'&#25351;&#25968;&#20043;&#38388;&#30340;&#31561;&#20215;&#24615;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#19968;&#33268;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#30452;&#25509;&#20174;&#26377;&#22122;&#22768;&#30340;&#25968;&#25454;&#20013;&#20272;&#35745;&#12290;&#32467;&#21512;&#27491;&#21521;&#36873;&#25321;&#21644;&#21453;&#21521;&#28040;&#38500;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;FIRST&#65292;&#21363;&#20351;&#29992;&#24635;&#65288;Sobol'&#65289;&#25351;&#25968;&#36827;&#34892;&#22240;&#23376;&#37325;&#35201;&#24615;&#25490;&#21517;&#21644;&#36873;&#25321;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#22823;&#37327;&#30340;&#20223;&#30495;&#23454;&#39564;&#26469;&#35777;&#26126;FIRST&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Factor importance measures the impact of each feature on output prediction accuracy. Many existing works focus on the model-based importance, but an important feature in one learning algorithm may hold little significance in another model. Hence, a factor importance measure ought to characterize the feature's predictive potential without relying on a specific prediction algorithm. Such algorithm-agnostic importance is termed as intrinsic importance in Williamson et al. (2023), but their estimator again requires model fitting. To bypass the modeling step, we present the equivalence between predictiveness potential and total Sobol' indices from global sensitivity analysis, and introduce a novel consistent estimator that can be directly estimated from noisy data. Integrating with forward selection and backward elimination gives rise to FIRST, Factor Importance Ranking and Selection using Total (Sobol') indices. Extensive simulations are provided to demonstrate the effectiveness of FIRST o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#27867;&#21270;&#23646;&#24615;&#36827;&#34892;&#20102;&#29702;&#35770;&#30740;&#31350;&#65292;&#24314;&#31435;&#20102;&#22522;&#20110;&#35780;&#20998;&#27861;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#35757;&#32451;&#21160;&#24577;&#20013;&#27867;&#21270;&#24046;&#36317;&#30340;&#29702;&#35770;&#20272;&#35745;&#65292;&#24182;&#22312;&#20572;&#27490;&#35757;&#32451;&#26102;&#21487;&#20197;&#36991;&#20813;&#32500;&#24230;&#35781;&#21650;&#12290;&#36827;&#19968;&#27493;&#23558;&#23450;&#37327;&#20998;&#26512;&#25193;&#23637;&#21040;&#20102;&#25968;&#25454;&#20381;&#36182;&#30340;&#24773;&#26223;&#12290;</title><link>http://arxiv.org/abs/2311.01797</link><description>&lt;p&gt;
&#20851;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#27867;&#21270;&#23646;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Generalization Properties of Diffusion Models. (arXiv:2311.01797v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01797
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#27867;&#21270;&#23646;&#24615;&#36827;&#34892;&#20102;&#29702;&#35770;&#30740;&#31350;&#65292;&#24314;&#31435;&#20102;&#22522;&#20110;&#35780;&#20998;&#27861;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#35757;&#32451;&#21160;&#24577;&#20013;&#27867;&#21270;&#24046;&#36317;&#30340;&#29702;&#35770;&#20272;&#35745;&#65292;&#24182;&#22312;&#20572;&#27490;&#35757;&#32451;&#26102;&#21487;&#20197;&#36991;&#20813;&#32500;&#24230;&#35781;&#21650;&#12290;&#36827;&#19968;&#27493;&#23558;&#23450;&#37327;&#20998;&#26512;&#25193;&#23637;&#21040;&#20102;&#25968;&#25454;&#20381;&#36182;&#30340;&#24773;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#26159;&#19968;&#31867;&#29983;&#25104;&#27169;&#22411;&#65292;&#29992;&#20110;&#24314;&#31435;&#19968;&#20010;&#38543;&#26426;&#20256;&#36755;&#26144;&#23556;&#65292;&#23558;&#32463;&#39564;&#35266;&#27979;&#21040;&#30340;&#20294;&#26410;&#30693;&#30340;&#30446;&#26631;&#20998;&#24067;&#19982;&#24050;&#30693;&#30340;&#20808;&#39564;&#20998;&#24067;&#32852;&#31995;&#36215;&#26469;&#12290;&#23613;&#31649;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#20294;&#23545;&#20854;&#27867;&#21270;&#33021;&#21147;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#26410;&#20805;&#20998;&#21457;&#23637;&#12290;&#26412;&#25991;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#27867;&#21270;&#23646;&#24615;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#29702;&#35770;&#30740;&#31350;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#22522;&#20110;&#35780;&#20998;&#27861;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#35757;&#32451;&#21160;&#24577;&#20013;&#27867;&#21270;&#24046;&#36317;&#30340;&#29702;&#35770;&#20272;&#35745;&#65292;&#34920;&#26126;&#22312;&#26679;&#26412;&#22823;&#23567;$n$&#21644;&#27169;&#22411;&#23481;&#37327;$m$&#19978;&#37117;&#23384;&#22312;&#22810;&#39033;&#24335;&#23567;&#30340;&#27867;&#21270;&#35823;&#24046;($O(n^{-2/5}+m^{-4/5})$)&#65292;&#22312;&#20572;&#27490;&#35757;&#32451;&#26102;&#21487;&#20197;&#36991;&#20813;&#32500;&#24230;&#35781;&#21650;&#65288;&#21363;&#25968;&#25454;&#32500;&#24230;&#19981;&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#65289;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#23450;&#37327;&#20998;&#26512;&#25193;&#23637;&#21040;&#20102;&#19968;&#20010;&#25968;&#25454;&#20381;&#36182;&#30340;&#24773;&#26223;&#65292;&#20854;&#20013;&#30446;&#26631;&#20998;&#24067;&#34987;&#25551;&#32472;&#20026;&#19968;&#31995;&#21015;&#30340;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models are a class of generative models that serve to establish a stochastic transport map between an empirically observed, yet unknown, target distribution and a known prior. Despite their remarkable success in real-world applications, a theoretical understanding of their generalization capabilities remains underdeveloped. This work embarks on a comprehensive theoretical exploration of the generalization attributes of diffusion models. We establish theoretical estimates of the generalization gap that evolves in tandem with the training dynamics of score-based diffusion models, suggesting a polynomially small generalization error ($O(n^{-2/5}+m^{-4/5})$) on both the sample size $n$ and the model capacity $m$, evading the curse of dimensionality (i.e., not exponentially large in the data dimension) when early-stopped. Furthermore, we extend our quantitative analysis to a data-dependent scenario, wherein target distributions are portrayed as a succession of densities with progr
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20005;&#26684;&#25512;&#24191;&#30340;&#20256;&#32479;&#26368;&#20248;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#21363;&#20013;&#20171;&#21453;&#39304;&#19979;&#30340;&#26368;&#20248;&#33218;&#35782;&#21035;&#65288;BAI-MF&#65289;&#65292;&#36890;&#36807;&#24341;&#20837;&#20013;&#20171;&#32773;&#26469;&#27169;&#25311;&#19968;&#20123;&#23454;&#38469;&#20915;&#31574;&#38382;&#39064;&#65292;&#22914;&#31163;&#32447;&#23398;&#20064;&#12289;&#37096;&#20998;&#21487;&#25511;&#29615;&#22659;&#21644;&#20154;&#31867;&#21453;&#39304;&#12290;</title><link>http://arxiv.org/abs/2308.15552</link><description>&lt;p&gt;
&#32431;&#25506;&#32034;&#19979;&#30340;&#20013;&#20171;&#21453;&#39304;
&lt;/p&gt;
&lt;p&gt;
Pure Exploration under Mediators' Feedback. (arXiv:2308.15552v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15552
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20005;&#26684;&#25512;&#24191;&#30340;&#20256;&#32479;&#26368;&#20248;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#21363;&#20013;&#20171;&#21453;&#39304;&#19979;&#30340;&#26368;&#20248;&#33218;&#35782;&#21035;&#65288;BAI-MF&#65289;&#65292;&#36890;&#36807;&#24341;&#20837;&#20013;&#20171;&#32773;&#26469;&#27169;&#25311;&#19968;&#20123;&#23454;&#38469;&#20915;&#31574;&#38382;&#39064;&#65292;&#22914;&#31163;&#32447;&#23398;&#20064;&#12289;&#37096;&#20998;&#21487;&#25511;&#29615;&#22659;&#21644;&#20154;&#31867;&#21453;&#39304;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#26426;&#26159;&#19968;&#31181;&#39034;&#24207;&#20915;&#31574;&#26694;&#26550;&#65292;&#27599;&#19968;&#27493;&#20132;&#20114;&#20013;&#23398;&#20064;&#32773;&#36873;&#25321;&#19968;&#20010;&#33218;&#24182;&#35266;&#23519;&#19968;&#20010;&#38543;&#26426;&#22238;&#25253;&#12290;&#22312;&#26368;&#20248;&#33218;&#35782;&#21035;&#65288;BAI&#65289;&#38382;&#39064;&#30340;&#32972;&#26223;&#19979;&#65292;&#23398;&#20064;&#32773;&#30340;&#30446;&#26631;&#26159;&#23613;&#21487;&#33021;&#20934;&#30830;&#21644;&#39640;&#25928;&#22320;&#25214;&#21040;&#26368;&#20248;&#33218;&#65292;&#21363;&#20855;&#26377;&#26368;&#39640;&#26399;&#26395;&#22238;&#25253;&#30340;&#33218;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;BAI&#38382;&#39064;&#30340;&#39034;&#24207;&#20132;&#20114;&#21327;&#35758;&#65292;&#21363;&#23398;&#20064;&#32773;&#22312;&#27599;&#19968;&#36718;&#20013;&#23545;&#36873;&#25321;&#30340;&#33218;&#20855;&#26377;&#23436;&#20840;&#25511;&#21046;&#26435;&#65292;&#26080;&#27861;&#26377;&#25928;&#22320;&#27169;&#25311;&#19968;&#20123;&#20540;&#24471;&#20851;&#27880;&#30340;&#20915;&#31574;&#38382;&#39064;&#65288;&#20363;&#22914;&#65292;&#31163;&#32447;&#23398;&#20064;&#65292;&#37096;&#20998;&#21487;&#25511;&#29615;&#22659;&#21644;&#20154;&#31867;&#21453;&#39304;&#65289;&#12290;&#22240;&#27492;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20005;&#26684;&#25512;&#24191;&#30340;&#20256;&#32479;BAI&#38382;&#39064;&#65292;&#31216;&#20043;&#20026;&#20013;&#20171;&#21453;&#39304;&#19979;&#30340;&#26368;&#20248;&#33218;&#35782;&#21035;&#65288;BAI-MF&#65289;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#23398;&#20064;&#32773;&#21487;&#20197;&#35775;&#38382;&#19968;&#32452;&#20013;&#20171;&#32773;&#30340;&#24773;&#20917;&#65292;&#27599;&#20010;&#20013;&#20171;&#32773;&#37117;&#36873;&#25321;&#35201;&#25289;&#21160;&#30340;&#33218;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic multi-armed bandits are a sequential-decision-making framework, where, at each interaction step, the learner selects an arm and observes a stochastic reward. Within the context of best-arm identification (BAI) problems, the goal of the agent lies in finding the optimal arm, i.e., the one with highest expected reward, as accurately and efficiently as possible. Nevertheless, the sequential interaction protocol of classical BAI problems, where the agent has complete control over the arm being pulled at each round, does not effectively model several decision-making problems of interest (e.g., off-policy learning, partially controllable environments, and human feedback). For this reason, in this work, we propose a novel strict generalization of the classical BAI problem that we refer to as best-arm identification under mediators' feedback (BAI-MF). More specifically, we consider the scenario in which the learner has access to a set of mediators, each of which selects the arms on 
&lt;/p&gt;</description></item><item><title>&#38750;&#32447;&#24615;&#20803;&#23398;&#20064;&#21487;&#20197;&#20445;&#35777;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2307.10870</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#20803;&#23398;&#20064;&#21487;&#20197;&#20445;&#35777;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;
&lt;/p&gt;
&lt;p&gt;
Nonlinear Meta-Learning Can Guarantee Faster Rates. (arXiv:2307.10870v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10870
&lt;/p&gt;
&lt;p&gt;
&#38750;&#32447;&#24615;&#20803;&#23398;&#20064;&#21487;&#20197;&#20445;&#35777;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#35768;&#22810;&#20851;&#20110;&#20803;&#23398;&#20064;&#30340;&#29702;&#35770;&#30740;&#31350;&#26088;&#22312;&#21033;&#29992;&#30456;&#20851;&#20219;&#21153;&#20013;&#30340;&#30456;&#20284;&#34920;&#31034;&#32467;&#26500;&#26469;&#31616;&#21270;&#30446;&#26631;&#20219;&#21153;&#65292;&#24182;&#23454;&#29616;&#25910;&#25947;&#36895;&#29575;&#30340;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#34920;&#31034;&#24448;&#24448;&#26159;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#65292;&#24341;&#20837;&#20102;&#27599;&#20010;&#20219;&#21153;&#20013;&#19981;&#21487;&#31616;&#21333;&#24179;&#22343;&#30340;&#38750;&#24179;&#20961;&#20559;&#24046;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#38750;&#32447;&#24615;&#34920;&#31034;&#25512;&#23548;&#20986;&#20803;&#23398;&#20064;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many recent theoretical works on \emph{meta-learning} aim to achieve guarantees in leveraging similar representational structures from related tasks towards simplifying a target task. Importantly, the main aim in theory works on the subject is to understand the extent to which convergence rates -- in learning a common representation -- \emph{may scale with the number $N$ of tasks} (as well as the number of samples per task). First steps in this setting demonstrate this property when both the shared representation amongst tasks, and task-specific regression functions, are linear. This linear setting readily reveals the benefits of aggregating tasks, e.g., via averaging arguments. In practice, however, the representation is often highly nonlinear, introducing nontrivial biases in each task that cannot easily be averaged out as in the linear case. In the present work, we derive theoretical guarantees for meta-learning with nonlinear representations. In particular, assuming the shared nonl
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#23545;&#24120;&#35265;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#27979;&#35797;&#22522;&#20934;&#20013;155&#20010;MDP&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#20998;&#26512;&#65292;&#21457;&#29616;&#24403;&#26368;&#39640;Q&#20540;&#30340;&#21160;&#20316;&#22312;&#38543;&#26426;&#31574;&#30053;&#19979;Q&#20540;&#26368;&#39640;&#26102;&#65292;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#24448;&#24448;&#20250;&#25104;&#21151;&#65307;&#21453;&#20043;&#65292;&#21017;&#22833;&#36133;&#30340;&#21487;&#33021;&#24615;&#36739;&#39640;&#12290;</title><link>http://arxiv.org/abs/2304.09853</link><description>&lt;p&gt;
&#29992;&#26377;&#25928;&#30340;&#35270;&#37326;&#36830;&#25509;&#24378;&#21270;&#23398;&#20064;&#29702;&#35770;&#21644;&#23454;&#36341;
&lt;/p&gt;
&lt;p&gt;
Bridging RL Theory and Practice with the Effective Horizon. (arXiv:2304.09853v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09853
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#23545;&#24120;&#35265;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#27979;&#35797;&#22522;&#20934;&#20013;155&#20010;MDP&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#20998;&#26512;&#65292;&#21457;&#29616;&#24403;&#26368;&#39640;Q&#20540;&#30340;&#21160;&#20316;&#22312;&#38543;&#26426;&#31574;&#30053;&#19979;Q&#20540;&#26368;&#39640;&#26102;&#65292;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#24448;&#24448;&#20250;&#25104;&#21151;&#65307;&#21453;&#20043;&#65292;&#21017;&#22833;&#36133;&#30340;&#21487;&#33021;&#24615;&#36739;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#22312;&#26576;&#20123;&#29615;&#22659;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#20854;&#20182;&#29615;&#22659;&#20013;&#21364;&#22833;&#36133;&#24471;&#38750;&#24120;&#20005;&#37325;&#12290;&#29702;&#24819;&#24773;&#20917;&#19979;&#65292;&#24378;&#21270;&#23398;&#20064;&#29702;&#35770;&#24212;&#35813;&#33021;&#22815;&#35299;&#37322;&#36825;&#31181;&#29616;&#35937;&#65292;&#25552;&#20379;&#39044;&#27979;&#23454;&#38469;&#24615;&#33021;&#30340;&#30028;&#38480;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#24403;&#21069;&#30340;&#29702;&#35770;&#36824;&#27809;&#26377;&#36825;&#31181;&#33021;&#21147;&#12290;&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#21253;&#21547;155&#20010;MDP&#30340;&#26032;&#25968;&#25454;&#38598;BRIDGE&#65292;&#23558;&#26631;&#20934;&#30340;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#19982;&#20043;&#21069;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20808;&#21069;&#30028;&#36827;&#34892;&#27604;&#36739;&#65292;&#24182;&#21457;&#29616;&#20102;&#19968;&#20010;&#24847;&#24819;&#19981;&#21040;&#30340;&#24615;&#36136;&#65306;&#24403;&#26368;&#39640;Q&#20540;&#30340;&#21160;&#20316;&#22312;&#38543;&#26426;&#31574;&#30053;&#19979;&#30340;Q&#20540;&#20063;&#26159;&#26368;&#39640;&#30340;&#26102;&#65292;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#24448;&#24448;&#20250;&#25104;&#21151;&#65307;&#21453;&#20043;&#65292;&#22833;&#36133;&#30340;&#21487;&#33021;&#24615;&#36739;&#39640;&#12290;&#22522;&#20110;&#36825;&#19968;&#24615;&#36136;&#65292;&#25105;&#20204;&#23558;&#20854;&#27010;&#25324;&#20026;&#19968;&#20010;&#26032;&#30340;MDP&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#31216;&#20026;&#26377;&#25928;&#30340;&#35270;&#37326;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep reinforcement learning (RL) works impressively in some environments and fails catastrophically in others. Ideally, RL theory should be able to provide an understanding of why this is, i.e. bounds predictive of practical performance. Unfortunately, current theory does not quite have this ability. We compare standard deep RL algorithms to prior sample complexity prior bounds by introducing a new dataset, BRIDGE. It consists of 155 MDPs from common deep RL benchmarks, along with their corresponding tabular representations, which enables us to exactly compute instance-dependent bounds. We find that prior bounds do not correlate well with when deep RL succeeds vs. fails, but discover a surprising property that does. When actions with the highest Q-values under the random policy also have the highest Q-values under the optimal policy, deep RL tends to succeed; when they don't, deep RL tends to fail. We generalize this property into a new complexity measure of an MDP that we call the eff
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; OKRidge &#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#30830;&#23450;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#31232;&#30095;&#25511;&#21046;&#26041;&#31243;&#65292;&#24182;&#36890;&#36807;&#27714;&#35299;&#31232;&#30095;&#23725;&#22238;&#24402;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#21487;&#25193;&#23637;&#24615;&#21644;&#24555;&#36895;&#24615;&#65292;&#21644;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#26377;&#30528;&#26356;&#39640;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2304.06686</link><description>&lt;p&gt;
OKRidge: &#29992;&#20110;&#23398;&#20064;&#21160;&#24577;&#31995;&#32479;&#30340;&#21487;&#25193;&#23637; k &#31232;&#30095;&#23725;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
OKRidge: Scalable Optimal k-Sparse Ridge Regression for Learning Dynamical Systems. (arXiv:2304.06686v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06686
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; OKRidge &#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#30830;&#23450;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#31232;&#30095;&#25511;&#21046;&#26041;&#31243;&#65292;&#24182;&#36890;&#36807;&#27714;&#35299;&#31232;&#30095;&#23725;&#22238;&#24402;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#21487;&#25193;&#23637;&#24615;&#21644;&#24555;&#36895;&#24615;&#65292;&#21644;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#26377;&#30528;&#26356;&#39640;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#31185;&#23398;&#21457;&#29616;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65292;&#21363;&#65292;&#30830;&#23450;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#31232;&#30095;&#25511;&#21046;&#26041;&#31243;&#65292;&#36890;&#36807;&#27714;&#35299;&#31232;&#30095;&#23725;&#22238;&#24402;&#38382;&#39064;&#21487;&#20197;&#35777;&#26126;&#26368;&#20248;&#24615;&#65292;&#20197;&#30830;&#23450;&#39537;&#21160;&#22522;&#30784;&#21160;&#24577;&#30340;&#39033;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026; OKRidge &#30340;&#24555;&#36895;&#31639;&#27861;&#65292;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#19979;&#30028;&#35745;&#31639;&#26041;&#27861;&#65292;&#28041;&#21450;&#38797;&#28857;&#20844;&#24335;&#65292;&#28982;&#21518;&#20351;&#29992;&#32447;&#24615;&#31995;&#32479;&#25110;&#22522;&#20110; ADMM &#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#65292;&#20854;&#20013;&#21487;&#20197;&#36890;&#36807;&#35299;&#20915;&#21478;&#19968;&#20010;&#32447;&#24615;&#31995;&#32479;&#21644;&#21333;&#35843;&#22238;&#24402;&#38382;&#39064;&#26469;&#26377;&#25928;&#22320;&#35745;&#31639;&#36817;&#31471;&#31639;&#23376;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#21551;&#21160;&#25105;&#20204;&#27714;&#35299;&#22120;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#20102;&#27874;&#26463;&#25628;&#32034;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36798;&#21040;&#21487;&#35777;&#26126;&#30340;&#26368;&#20248;&#24615;&#65292;&#24182;&#19988;&#36816;&#34892;&#26102;&#38388;&#27604;&#21830;&#19994;&#27714;&#35299;&#22120; Gurobi &#35299;&#20915;&#30340;&#29616;&#26377; MIP&#20844;&#24335;&#36816;&#34892;&#26102;&#38388;&#24555;&#20960;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider an important problem in scientific discovery, identifying sparse governing equations for nonlinear dynamical systems. This involves solving sparse ridge regression problems to provable optimality in order to determine which terms drive the underlying dynamics. We propose a fast algorithm, OKRidge, for sparse ridge regression, using a novel lower bound calculation involving, first, a saddle point formulation, and from there, either solving (i) a linear system or (ii) using an ADMM-based approach, where the proximal operators can be efficiently evaluated by solving another linear system and an isotonic regression problem. We also propose a method to warm-start our solver, which leverages a beam search. Experimentally, our methods attain provable optimality with run times that are orders of magnitude faster than those of the existing MIP formulations solved by the commercial solver Gurobi.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#24046;&#20998;&#38544;&#31169;&#21644;&#24230;&#37327;&#38544;&#31169;&#23398;&#20064;&#22120;&#22312;&#23545;&#25239;&#32773;&#37325;&#26500;&#38169;&#35823;&#26041;&#38754;&#30340;&#40065;&#26834;&#24615;&#65292;&#24471;&#20986;&#20102;&#38750;&#28176;&#36827;&#24615;&#19979;&#30028;&#65292;&#35206;&#30422;&#20102;&#39640;&#32500;&#24773;&#20917;&#65292;&#19988;&#25193;&#23637;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#38544;&#31169;&#20998;&#26512;</title><link>http://arxiv.org/abs/2303.16372</link><description>&lt;p&gt;
&#35757;&#32451;&#25968;&#25454;&#37325;&#26500;&#30340;&#38750;&#28176;&#36827;&#24615;&#19979;&#30028;
&lt;/p&gt;
&lt;p&gt;
Non-Asymptotic Lower Bounds For Training Data Reconstruction. (arXiv:2303.16372v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16372
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#24046;&#20998;&#38544;&#31169;&#21644;&#24230;&#37327;&#38544;&#31169;&#23398;&#20064;&#22120;&#22312;&#23545;&#25239;&#32773;&#37325;&#26500;&#38169;&#35823;&#26041;&#38754;&#30340;&#40065;&#26834;&#24615;&#65292;&#24471;&#20986;&#20102;&#38750;&#28176;&#36827;&#24615;&#19979;&#30028;&#65292;&#35206;&#30422;&#20102;&#39640;&#32500;&#24773;&#20917;&#65292;&#19988;&#25193;&#23637;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#38544;&#31169;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19987;&#19994;&#23545;&#25163;&#36827;&#34892;&#35757;&#32451;&#25968;&#25454;&#37325;&#26500;&#25915;&#20987;&#26102;&#31169;&#26377;&#23398;&#20064;&#31639;&#27861;&#30340;&#35821;&#20041;&#20445;&#35777;&#24378;&#24230;&#12290;&#25105;&#20204;&#36890;&#36807;&#23548;&#20986;&#38750;&#28176;&#36827;&#37327;&#32423;&#19979;&#30028;&#26469;&#30740;&#31350;&#20102;&#28385;&#36275;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#21644;&#24230;&#37327;&#38544;&#31169;&#65288;mDP&#65289;&#30340;&#23398;&#20064;&#22120;&#23545;&#25239;&#32773;&#37325;&#26500;&#38169;&#35823;&#30340;&#40065;&#26834;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#25105;&#20204;&#23545;mDP&#30340;&#20998;&#26512;&#35206;&#30422;&#20102;&#39640;&#32500;&#24773;&#20917;&#12290;&#26412;&#25991;&#36827;&#19968;&#27493;&#23545;&#27969;&#34892;&#30340;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#65292;&#22914;DP-SGD&#21644;Projected Noisy SGD&#36827;&#34892;&#20102;&#24230;&#37327;&#24046;&#20998;&#38544;&#31169;&#30340;&#25193;&#23637;&#38544;&#31169;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate semantic guarantees of private learning algorithms for their resilience to training Data Reconstruction Attacks (DRAs) by informed adversaries. To this end, we derive non-asymptotic minimax lower bounds on the adversary's reconstruction error against learners that satisfy differential privacy (DP) and metric differential privacy (mDP). Furthermore, we demonstrate that our lower bound analysis for the latter also covers the high dimensional regime, wherein, the input data dimensionality may be larger than the adversary's query budget. Motivated by the theoretical improvements conferred by metric DP, we extend the privacy analysis of popular deep learning algorithms such as DP-SGD and Projected Noisy SGD to cover the broader notion of metric differential privacy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;Score matching&#30340;&#20056;&#31215;Jacobi-Theta Boltzmann&#26426;&#22120;&#65288;pJTBM&#65289;&#65292;&#23427;&#27604;&#21407;&#22987;&#30340;RTBM&#26356;&#39640;&#25928;&#22320;&#25311;&#21512;&#27010;&#29575;&#23494;&#24230;&#12290;</title><link>http://arxiv.org/abs/2303.05910</link><description>&lt;p&gt;
&#20351;&#29992;Score matching&#30340;&#20056;&#31215;Jacobi-Theta Boltzmann&#26426;&#22120;
&lt;/p&gt;
&lt;p&gt;
Product Jacobi-Theta Boltzmann machines with score matching. (arXiv:2303.05910v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.05910
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;Score matching&#30340;&#20056;&#31215;Jacobi-Theta Boltzmann&#26426;&#22120;&#65288;pJTBM&#65289;&#65292;&#23427;&#27604;&#21407;&#22987;&#30340;RTBM&#26356;&#39640;&#25928;&#22320;&#25311;&#21512;&#27010;&#29575;&#23494;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20272;&#35745;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#26159;&#19968;&#20010;&#19981;&#23481;&#26131;&#30340;&#20219;&#21153;&#65292;&#22312;&#36807;&#21435;&#20960;&#24180;&#20013;&#65292;&#20154;&#20204;&#24050;&#32463;&#24320;&#22987;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#20511;&#37492;Boltzmann&#26426;&#22120;&#30340;&#26550;&#26500;&#65292;&#21487;&#20197;&#24471;&#21040;&#25104;&#21151;&#30340;&#24212;&#29992;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#20056;&#31215;Jacobi-Theta Boltzmann&#26426;&#22120;&#65288;pJTBM&#65289;&#30340;&#27169;&#22411;&#65292;&#23427;&#26159;Riemann-Theta Boltzmann&#26426;&#22120;&#65288;RTBM&#65289;&#30340;&#21463;&#38480;&#29256;&#26412;&#65292;&#20855;&#26377;&#23545;&#35282;&#38544;&#34255;&#37096;&#20998;&#36830;&#25509;&#30697;&#38453;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22522;&#20110;Fisher&#25955;&#24230;&#30340;Score matching&#21487;&#20197;&#29992;&#26469;&#27604;&#21407;&#22987;&#30340;RTBM&#26356;&#39640;&#25928;&#22320;&#25311;&#21512;pJTBM&#30340;&#27010;&#29575;&#23494;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
The estimation of probability density functions is a non trivial task that over the last years has been tackled with machine learning techniques. Successful applications can be obtained using models inspired by the Boltzmann machine (BM) architecture. In this manuscript, the product Jacobi-Theta Boltzmann machine (pJTBM) is introduced as a restricted version of the Riemann-Theta Boltzmann machine (RTBM) with diagonal hidden sector connection matrix. We show that score matching, based on the Fisher divergence, can be used to fit probability densities with the pJTBM more efficiently than with the original RTBM.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#26680;&#26031;&#22374;&#31163;&#24046;&#65288;KSD&#65289;&#25511;&#21046;&#24615;&#36136;&#65292;&#21457;&#29616;&#26631;&#20934;KSD&#26080;&#27861;&#25511;&#21046;&#30697;&#30340;&#25910;&#25947;&#65292;&#25552;&#20986;&#20102;&#21487;&#25511;&#21046;&#30697;&#21644;&#24369;&#25910;&#25947;&#30340;&#19979;&#28216;&#25193;&#25955;KSD&#65292;&#24182;&#19988;&#21457;&#23637;&#20102;&#21487;&#20197;&#20934;&#30830;&#25551;&#36848;$q$-Wasserstein&#25910;&#25947;&#30340;KSD&#12290;</title><link>http://arxiv.org/abs/2211.05408</link><description>&lt;p&gt;
&#29992;&#26680;&#26031;&#22374;&#31163;&#24046;&#25511;&#21046;&#30697;
&lt;/p&gt;
&lt;p&gt;
Controlling Moments with Kernel Stein Discrepancies. (arXiv:2211.05408v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.05408
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#26680;&#26031;&#22374;&#31163;&#24046;&#65288;KSD&#65289;&#25511;&#21046;&#24615;&#36136;&#65292;&#21457;&#29616;&#26631;&#20934;KSD&#26080;&#27861;&#25511;&#21046;&#30697;&#30340;&#25910;&#25947;&#65292;&#25552;&#20986;&#20102;&#21487;&#25511;&#21046;&#30697;&#21644;&#24369;&#25910;&#25947;&#30340;&#19979;&#28216;&#25193;&#25955;KSD&#65292;&#24182;&#19988;&#21457;&#23637;&#20102;&#21487;&#20197;&#20934;&#30830;&#25551;&#36848;$q$-Wasserstein&#25910;&#25947;&#30340;KSD&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#26031;&#22374;&#31163;&#24046;&#65288;KSD&#65289;&#29992;&#20110;&#34913;&#37327;&#20998;&#24067;&#36924;&#36817;&#30340;&#36136;&#37327;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#30446;&#26631;&#23494;&#24230;&#20855;&#26377;&#19981;&#21487;&#35745;&#31639;&#30340;&#24402;&#19968;&#21270;&#24120;&#25968;&#26102;&#35745;&#31639;&#12290;&#26174;&#33879;&#30340;&#24212;&#29992;&#21253;&#25324;&#35786;&#26029;&#36817;&#20284;MCMC&#37319;&#26679;&#22120;&#21644;&#38750;&#24402;&#19968;&#21270;&#32479;&#35745;&#27169;&#22411;&#30340;&#36866;&#37197;&#24230;&#26816;&#39564;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;KSD&#30340;&#25910;&#25947;&#25511;&#21046;&#24615;&#36136;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#29992;&#20110;&#24369;&#25910;&#25947;&#25511;&#21046;&#30340;&#26631;&#20934;KSD&#26080;&#27861;&#25511;&#21046;&#30697;&#30340;&#25910;&#25947;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#32452;&#20805;&#20998;&#26465;&#20214;&#65292;&#19979;&#28216;&#25193;&#25955;KSD&#21487;&#20197;&#21516;&#26102;&#25511;&#21046;&#30697;&#21644;&#24369;&#25910;&#25947;&#12290;&#20316;&#20026;&#19968;&#20010;&#30452;&#25509;&#30340;&#32467;&#26524;&#65292;&#25105;&#20204;&#21457;&#23637;&#20102;&#23545;&#20110;&#27599;&#20010;$q&gt;0$&#65292;&#31532;&#19968;&#32452;&#24050;&#30693;&#21487;&#20197;&#20934;&#30830;&#25551;&#36848;$q$-Wasserstein&#25910;&#25947;&#30340;KSD&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernel Stein discrepancies (KSDs) measure the quality of a distributional approximation and can be computed even when the target density has an intractable normalizing constant. Notable applications include the diagnosis of approximate MCMC samplers and goodness-of-fit tests for unnormalized statistical models. The present work analyzes the convergence control properties of KSDs. We first show that standard KSDs used for weak convergence control fail to control moment convergence. To address this limitation, we next provide sufficient conditions under which alternative diffusion KSDs control both moment and weak convergence. As an immediate consequence we develop, for each $q &gt; 0$, the first KSDs known to exactly characterize $q$-Wasserstein convergence.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#33021;&#32791;&#24863;&#30693;&#30340;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#34920;&#26684;&#22522;&#20934; EC-NAS&#65292;&#35813;&#22522;&#20934;&#36890;&#36807;&#28155;&#21152;&#33021;&#32791;&#21644;&#30899;&#36275;&#36857;&#20449;&#24687;&#65292;&#25903;&#25345;&#35774;&#35745;&#33021;&#25928;&#39640;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#38477;&#20302;&#24635;&#33021;&#32791;&#12290;</title><link>http://arxiv.org/abs/2210.06015</link><description>&lt;p&gt;
EC-NAS: &#38754;&#21521;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#30340;&#33021;&#32791;&#24863;&#30693;&#34920;&#26684;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
EC-NAS: Energy Consumption Aware Tabular Benchmarks for Neural Architecture Search. (arXiv:2210.06015v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.06015
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#33021;&#32791;&#24863;&#30693;&#30340;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#34920;&#26684;&#22522;&#20934; EC-NAS&#65292;&#35813;&#22522;&#20934;&#36890;&#36807;&#28155;&#21152;&#33021;&#32791;&#21644;&#30899;&#36275;&#36857;&#20449;&#24687;&#65292;&#25903;&#25345;&#35774;&#35745;&#33021;&#25928;&#39640;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#38477;&#20302;&#24635;&#33021;&#32791;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#36873;&#25321;&#12289;&#35757;&#32451;&#21644;&#37096;&#32626;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#25152;&#38656;&#30340;&#33021;&#37327;&#28040;&#32791;&#19981;&#26029;&#22686;&#21152;&#12290;&#26412;&#25991;&#26088;&#22312;&#25903;&#25345;&#35774;&#35745;&#33021;&#25928;&#39640;&#12289;&#35757;&#32451;&#36164;&#28304;&#28040;&#32791;&#36739;&#20302;&#12289;&#36866;&#29992;&#20110;&#23454;&#38469;&#36793;&#32536;/&#31227;&#21160;&#35745;&#31639;&#29615;&#22659;&#24182;&#20855;&#26377;&#29615;&#22659;&#21487;&#25345;&#32493;&#24615;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#23558;&#33021;&#25928;&#20316;&#20026;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034; (NAS) &#30340;&#19968;&#39033;&#39069;&#22806;&#24615;&#33021;&#25351;&#26631;&#65292;&#24182;&#36890;&#36807;&#28155;&#21152;&#19981;&#21516;&#26550;&#26500;&#30340;&#33021;&#32791;&#21644;&#30899;&#36275;&#36857;&#20449;&#24687;&#65292;&#25552;&#20379;&#26356;&#26032;&#30340;&#34920;&#26684;&#22522;&#20934; EC-NAS &#20197;&#22312;&#36739;&#20302;&#35745;&#31639;&#25104;&#26412;&#19979;&#35780;&#20272; NAS &#31574;&#30053;&#12290;EC-NAS &#36824;&#21253;&#25324;&#29992;&#20110;&#39044;&#27979;&#33021;&#32791;&#30340;&#20195;&#29702;&#27169;&#22411;&#65292;&#24182;&#26377;&#21161;&#20110;&#38477;&#20302;&#24635;&#33021;&#32791;&#12290;
&lt;/p&gt;
&lt;p&gt;
Energy consumption from selecting, training and deploying deep learning models has continued to increase over the past few years. Our goal in this work is to support the design of energy-efficient deep learning models that are easier to train with lower compute resources, practical to deploy in real-world edge/mobile computing settings and environmentally sustainable. Tabular benchmarks for neural architecture search (NAS) allow the evaluation of NAS strategies at lower computational cost by providing pre-computed performance statistics. In this work, we suggest including energy efficiency as an additional performance criterion to NAS and present an updated tabular benchmark by including information on energy consumption and carbon footprint for different architectures. The benchmark called EC-NAS is made available open-source to support energy consumption-aware NAS research. EC-NAS also includes a surrogate model for predicting energy consumption, and helps us reduce the overall energ
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#23725;&#20989;&#25968;&#20272;&#35745;&#20013;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#29616;&#35937;&#65292;&#24182;&#22312;&#26377;&#38480;&#32500;&#24230;&#24773;&#20917;&#19979;&#23545;&#32447;&#24615;&#27169;&#22411;&#36827;&#34892;&#20102;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2007.12882</link><description>&lt;p&gt;
&#23725;&#20989;&#25968;&#20272;&#35745;&#20013;&#33391;&#24615;&#36807;&#25311;&#21512;&#29616;&#35937;&#30340;&#26377;&#38480;&#26679;&#26412;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A finite sample analysis of the benign overfitting phenomenon for ridge function estimation. (arXiv:2007.12882v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2007.12882
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#23725;&#20989;&#25968;&#20272;&#35745;&#20013;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#29616;&#35937;&#65292;&#24182;&#22312;&#26377;&#38480;&#32500;&#24230;&#24773;&#20917;&#19979;&#23545;&#32447;&#24615;&#27169;&#22411;&#36827;&#34892;&#20102;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22312;&#22823;&#35268;&#27169;&#26426;&#22120;&#23398;&#20064;&#20013;&#36827;&#34892;&#30340;&#24191;&#27867;&#25968;&#20540;&#23454;&#39564;&#25581;&#31034;&#20102;&#19968;&#20010;&#30456;&#24403;&#21453;&#30452;&#35273;&#30340;&#30456;&#21464;&#29616;&#35937;&#65292;&#21363;&#26679;&#26412;&#22823;&#23567;&#19982;&#27169;&#22411;&#21442;&#25968;&#25968;&#37327;&#20043;&#27604;&#30340;&#20989;&#25968;&#20851;&#31995;&#12290;&#24403;&#21442;&#25968;&#25968;&#37327;$p$&#25509;&#36817;&#26679;&#26412;&#22823;&#23567;$n$&#26102;&#65292;&#27867;&#21270;&#35823;&#24046;&#22686;&#21152;&#65292;&#20294;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#24403;$p&gt;n$&#26102;&#23427;&#20877;&#27425;&#24320;&#22987;&#20943;&#23567;&#12290;&#36825;&#19968;&#29616;&#35937;&#22312;\cite{belkin2019reconciling}&#20013;&#24341;&#36215;&#20102;&#29702;&#35770;&#30028;&#30340;&#20851;&#27880;&#65292;&#26368;&#36817;&#24050;&#32463;&#36827;&#34892;&#20102;&#28145;&#20837;&#30740;&#31350;&#65292;&#29305;&#21035;&#26159;&#38024;&#23545;&#27604;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26356;&#31616;&#21333;&#30340;&#27169;&#22411;&#65292;&#20363;&#22914;&#32447;&#24615;&#27169;&#22411;&#20013;&#21442;&#25968;&#21462;&#26368;&#23567;&#33539;&#25968;&#35299;&#30340;&#24773;&#20917;&#12290;&#39318;&#20808;&#22312;&#24403;$p$&#21644;$n$&#36235;&#20110;&#26080;&#31351;&#22823;&#30340;&#28176;&#36817;&#24773;&#20917;&#19979;&#36827;&#34892;&#30740;&#31350;&#65288;&#21442;&#35265;\cite{hastie2019surprises}&#65289;&#65292;&#28982;&#21518;&#22312;&#26377;&#38480;&#32500;&#24773;&#20917;&#19979;&#26356;&#20855;&#20307;&#22320;&#38024;&#23545;&#32447;&#24615;&#27169;&#22411;&#36827;&#34892;&#30740;&#31350;&#65288;&#21442;&#35265;\cite{bartlett2020benign}&#65292;\cite{tsigler2020benign}&#65292;\cite{lecue2022geometrical}&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent extensive numerical experiments in high scale machine learning have allowed to uncover a quite counterintuitive phase transition, as a function of the ratio between the sample size and the number of parameters in the model. As the number of parameters $p$ approaches the sample size $n$, the generalisation error increases, but surprisingly, it starts decreasing again past the threshold $p=n$. This phenomenon, brought to the theoretical community attention in \cite{belkin2019reconciling}, has been thoroughly investigated lately, more specifically for simpler models than deep neural networks, such as the linear model when the parameter is taken to be the minimum norm solution to the least-squares problem, firstly in the asymptotic regime when $p$ and $n$ tend to infinity, see e.g. \cite{hastie2019surprises}, and recently in the finite dimensional regime and more specifically for linear models \cite{bartlett2020benign}, \cite{tsigler2020benign}, \cite{lecue2022geometrical}. In the p
&lt;/p&gt;</description></item></channel></rss>