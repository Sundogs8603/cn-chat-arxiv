<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21464;&#20998;&#25512;&#26029;&#26694;&#26550;&#65292;&#29992;&#20110;&#39537;&#21160;&#20998;&#25968;&#22122;&#22768;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65292;&#24182;&#24314;&#31435;&#20102;&#29992;&#20110;&#39640;&#25928;&#25512;&#26029;&#30340;&#35777;&#25454;&#19979;&#30028;&#12290;</title><link>http://arxiv.org/abs/2310.12975</link><description>&lt;p&gt;
&#20998;&#25968;&#22122;&#22768;&#39537;&#21160;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#21464;&#20998;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Variational Inference for SDEs Driven by Fractional Noise. (arXiv:2310.12975v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12975
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21464;&#20998;&#25512;&#26029;&#26694;&#26550;&#65292;&#29992;&#20110;&#39537;&#21160;&#20998;&#25968;&#22122;&#22768;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65292;&#24182;&#24314;&#31435;&#20102;&#29992;&#20110;&#39640;&#25928;&#25512;&#26029;&#30340;&#35777;&#25454;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21464;&#20998;&#26694;&#26550;&#65292;&#29992;&#20110;&#23545;&#30001;&#39532;&#23572;&#31185;&#22827;&#36817;&#20284;&#30340;&#20998;&#25968;&#24067;&#26391;&#36816;&#21160;&#39537;&#21160;&#30340;&#65288;&#31070;&#32463;&#65289;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDEs&#65289;&#36827;&#34892;&#25512;&#26029;&#12290;SDEs&#26159;&#19968;&#31181;&#27169;&#25311;&#20855;&#26377;&#22266;&#26377;&#22122;&#22768;&#21644;&#38543;&#26426;&#24615;&#30340;&#29616;&#23454;&#36830;&#32493;&#26102;&#38388;&#21160;&#24577;&#31995;&#32479;&#30340;&#22810;&#21151;&#33021;&#24037;&#20855;&#12290;&#23558;SDEs&#19982;&#21464;&#20998;&#26041;&#27861;&#30340;&#24378;&#22823;&#25512;&#26029;&#33021;&#21147;&#30456;&#32467;&#21512;&#65292;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#20195;&#34920;&#24615;&#20989;&#25968;&#20998;&#24067;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;SDEs&#36890;&#24120;&#20551;&#35774;&#24213;&#23618;&#22122;&#22768;&#36981;&#24490;&#24067;&#26391;&#36816;&#21160;&#65288;BM&#65289;&#65292;&#36825;&#38480;&#21046;&#20102;&#23427;&#20204;&#25429;&#25417;&#38271;&#26399;&#30456;&#20851;&#24615;&#30340;&#33021;&#21147;&#12290;&#30456;&#21453;&#65292;&#20998;&#25968;&#24067;&#26391;&#36816;&#21160;&#65288;fBM&#65289;&#23558;BM&#25193;&#23637;&#21040;&#21253;&#25324;&#38750;&#39532;&#23572;&#31185;&#22827;&#21160;&#21147;&#23398;&#65292;&#20294;&#29616;&#26377;&#30340;&#25512;&#26029;fBM&#21442;&#25968;&#30340;&#26041;&#27861;&#35201;&#20040;&#35745;&#31639;&#27714;&#35299;&#22797;&#26434;&#65292;&#35201;&#20040;&#22312;&#32479;&#35745;&#19978;&#20302;&#25928;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22522;&#20110;fBM&#30340;&#39532;&#23572;&#31185;&#22827;&#36817;&#20284;&#65292;&#25512;&#23548;&#20986;&#29992;&#20110;&#39640;&#25928;&#21464;&#20998;&#25512;&#26029;&#30340;&#35777;&#25454;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel variational framework for performing inference in (neural) stochastic differential equations (SDEs) driven by Markov-approximate fractional Brownian motion (fBM). SDEs offer a versatile tool for modeling real-world continuous-time dynamic systems with inherent noise and randomness. Combining SDEs with the powerful inference capabilities of variational methods, enables the learning of representative function distributions through stochastic gradient descent. However, conventional SDEs typically assume the underlying noise to follow a Brownian motion (BM), which hinders their ability to capture long-term dependencies. In contrast, fractional Brownian motion (fBM) extends BM to encompass non-Markovian dynamics, but existing methods for inferring fBM parameters are either computationally demanding or statistically inefficient. In this paper, building upon the Markov approximation of fBM, we derive the evidence lower bound essential for efficient variational inference of 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20272;&#35745;&#30446;&#26631;&#22495;&#20013;&#21508;&#31867;&#21035;&#30340;&#39044;&#27979;&#27010;&#29575;&#21644;&#28151;&#28102;&#30697;&#38453;&#65292;&#28982;&#21518;&#20256;&#25773;&#19981;&#30830;&#23450;&#24615;&#24182;&#35745;&#31639;&#37325;&#35201;&#26435;&#37325;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#26631;&#31614;&#20559;&#31227;&#35774;&#32622;&#19979;&#26500;&#24314;&#20855;&#26377;PAC&#20445;&#35777;&#30340;&#39044;&#27979;&#38598;&#30340;&#26032;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.12964</link><description>&lt;p&gt;
PAC&#39044;&#27979;&#38598;&#22312;&#26631;&#31614;&#20559;&#31227;&#19979;&#30340;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
PAC Prediction Sets Under Label Shift. (arXiv:2310.12964v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12964
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20272;&#35745;&#30446;&#26631;&#22495;&#20013;&#21508;&#31867;&#21035;&#30340;&#39044;&#27979;&#27010;&#29575;&#21644;&#28151;&#28102;&#30697;&#38453;&#65292;&#28982;&#21518;&#20256;&#25773;&#19981;&#30830;&#23450;&#24615;&#24182;&#35745;&#31639;&#37325;&#35201;&#26435;&#37325;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#26631;&#31614;&#20559;&#31227;&#35774;&#32622;&#19979;&#26500;&#24314;&#20855;&#26377;PAC&#20445;&#35777;&#30340;&#39044;&#27979;&#38598;&#30340;&#26032;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#38598;&#36890;&#36807;&#39044;&#27979;&#19968;&#32452;&#26631;&#31614;&#32780;&#19981;&#26159;&#20010;&#21035;&#26631;&#31614;&#26469;&#25429;&#25417;&#19981;&#30830;&#23450;&#24615;&#65292;&#20351;&#19979;&#28216;&#20915;&#31574;&#33021;&#22815;&#20445;&#23432;&#32771;&#34385;&#25152;&#26377;&#21487;&#33021;&#30340;&#32467;&#26524;&#12290;&#31526;&#21512;&#24615;&#25512;&#26029;&#31639;&#27861;&#26500;&#24314;&#39044;&#27979;&#38598;&#65292;&#20445;&#35777;&#20197;&#39640;&#27010;&#29575;&#21253;&#21547;&#30495;&#23454;&#26631;&#31614;&#12290;&#36825;&#20123;&#20445;&#35777;&#22312;&#38754;&#23545;&#20998;&#24067;&#20559;&#31227;&#26102;&#22833;&#25928;&#65292;&#32780;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#23588;&#20026;&#26377;&#29992;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#22312;&#26631;&#31614;&#20559;&#31227;&#35774;&#32622;&#20013;&#26500;&#24314;&#20855;&#26377;PAC&#20445;&#35777;&#30340;&#39044;&#27979;&#38598;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20272;&#35745;&#30446;&#26631;&#22495;&#20013;&#21508;&#31867;&#21035;&#30340;&#39044;&#27979;&#27010;&#29575;&#21644;&#28151;&#28102;&#30697;&#38453;&#65292;&#28982;&#21518;&#36890;&#36807;&#39640;&#26031;&#28040;&#20803;&#31639;&#27861;&#20256;&#25773;&#36825;&#20123;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#35745;&#31639;&#37325;&#35201;&#26435;&#37325;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#26368;&#21518;&#65292;&#20351;&#29992;&#36825;&#20123;&#21306;&#38388;&#26500;&#24314;&#39044;&#27979;&#38598;&#12290;&#25105;&#20204;&#22312;&#20116;&#20010;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65306;CIFAR-10&#65292;ChestX-Ray&#21644;Entity-13&#22270;&#20687;&#25968;&#25454;&#38598;&#65292;&#20197;&#21450;&#34920;CDC Heart dat&#12290;
&lt;/p&gt;
&lt;p&gt;
Prediction sets capture uncertainty by predicting sets of labels rather than individual labels, enabling downstream decisions to conservatively account for all plausible outcomes. Conformal inference algorithms construct prediction sets guaranteed to contain the true label with high probability. These guarantees fail to hold in the face of distribution shift, which is precisely when reliable uncertainty quantification can be most useful. We propose a novel algorithm for constructing prediction sets with PAC guarantees in the label shift setting. This method estimates the predicted probabilities of the classes in a target domain, as well as the confusion matrix, then propagates uncertainty in these estimates through a Gaussian elimination algorithm to compute confidence intervals for importance weights. Finally, it uses these intervals to construct prediction sets. We evaluate our approach on five datasets: the CIFAR-10, ChestX-Ray and Entity-13 image datasets, the tabular CDC Heart dat
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#29983;&#25104;&#27969;&#32593;&#32476;&#30340;&#23398;&#20064;&#20219;&#21153;&#37325;&#26032;&#23450;&#20041;&#20026;&#20855;&#26377;&#29305;&#23450;&#22870;&#21169;&#21644;&#27491;&#21017;&#21270;&#22120;&#32467;&#26500;&#30340;&#29109;&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#29109;&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#29983;&#25104;&#27969;&#32593;&#32476;&#35757;&#32451;&#20013;&#20855;&#26377;&#23454;&#38469;&#25928;&#29575;&#21644;&#31454;&#20105;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.12934</link><description>&lt;p&gt;
&#29983;&#25104;&#27969;&#32593;&#32476;&#20316;&#20026;&#29109;&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Generative Flow Networks as Entropy-Regularized RL. (arXiv:2310.12934v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12934
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#29983;&#25104;&#27969;&#32593;&#32476;&#30340;&#23398;&#20064;&#20219;&#21153;&#37325;&#26032;&#23450;&#20041;&#20026;&#20855;&#26377;&#29305;&#23450;&#22870;&#21169;&#21644;&#27491;&#21017;&#21270;&#22120;&#32467;&#26500;&#30340;&#29109;&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#29109;&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#29983;&#25104;&#27969;&#32593;&#32476;&#35757;&#32451;&#20013;&#20855;&#26377;&#23454;&#38469;&#25928;&#29575;&#21644;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#25552;&#20986;&#30340;&#29983;&#25104;&#27969;&#32593;&#32476;(GFlowNets)&#26159;&#19968;&#31181;&#35757;&#32451;&#31574;&#30053;&#20197;&#20415;&#26679;&#26412;&#20855;&#26377;&#19982;&#32473;&#23450;&#22870;&#21169;&#25104;&#27604;&#20363;&#30340;&#32452;&#21512;&#31163;&#25955;&#23545;&#35937;&#30340;&#27010;&#29575;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#19968;&#31995;&#21015;&#30340;&#21160;&#20316;&#12290; GFlowNets&#21033;&#29992;&#38382;&#39064;&#30340;&#24207;&#21015;&#24615;&#36136;&#65292;&#19982;&#24378;&#21270;&#23398;&#20064;(RL)&#36827;&#34892;&#31867;&#27604;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#23558;RL&#21644;GFlowNets&#20043;&#38388;&#30340;&#32852;&#31995;&#25193;&#23637;&#21040;&#20102;&#19968;&#33324;&#24773;&#20917;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#22914;&#20309;&#23558;&#23398;&#20064;&#29983;&#25104;&#27969;&#32593;&#32476;&#30340;&#20219;&#21153;&#39640;&#25928;&#22320;&#37325;&#26032;&#23450;&#20041;&#20026;&#20855;&#26377;&#29305;&#23450;&#22870;&#21169;&#21644;&#27491;&#21017;&#21270;&#22120;&#32467;&#26500;&#30340;&#29109;&#27491;&#21017;&#21270;RL&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#23558;&#26631;&#20934;&#30340;&#36719;RL&#31639;&#27861;&#24212;&#29992;&#20110;&#20960;&#20010;&#27010;&#29575;&#24314;&#27169;&#20219;&#21153;&#30340;GFlowNet&#35757;&#32451;&#65292;&#26469;&#35828;&#26126;&#36825;&#31181;&#37325;&#23450;&#20041;&#30340;&#23454;&#38469;&#25928;&#29575;&#12290;&#19982;&#20808;&#21069;&#25253;&#36947;&#30340;&#32467;&#26524;&#30456;&#21453;&#65292;&#25105;&#20204;&#34920;&#26126;&#29109;&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#19982;&#24050;&#26377;&#30340;GFlowNet&#35757;&#32451;&#26041;&#27861;&#31454;&#20105;&#20013;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;&#36825;&#20010;&#35266;&#28857;&#20026;&#23558;&#24378;&#21270;&#23398;&#20064;&#21407;&#21017;&#34701;&#20837;&#23454;&#38469;&#38382;&#39064;&#25552;&#20379;&#20102;&#30452;&#25509;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recently proposed generative flow networks (GFlowNets) are a method of training a policy to sample compositional discrete objects with probabilities proportional to a given reward via a sequence of actions. GFlowNets exploit the sequential nature of the problem, drawing parallels with reinforcement learning (RL). Our work extends the connection between RL and GFlowNets to a general case. We demonstrate how the task of learning a generative flow network can be efficiently redefined as an entropy-regularized RL problem with a specific reward and regularizer structure. Furthermore, we illustrate the practical efficiency of this reformulation by applying standard soft RL algorithms to GFlowNet training across several probabilistic modeling tasks. Contrary to previously reported results, we show that entropic RL approaches can be competitive against established GFlowNet training methods. This perspective opens a direct path for integrating reinforcement learning principles into the real
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24207;&#21015;&#25193;&#23637;&#30340;Gibbs&#20808;&#39564;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#24182;&#33719;&#24471;&#20102;&#20851;&#20110;&#20271;&#24681;&#26031;&#22374;-&#20911;&#183;&#23494;&#26031;&#23450;&#29702;&#22312;&#27969;&#24418;&#19978;&#30340;&#26032;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.12882</link><description>&lt;p&gt;
&#24102;&#26377;&#24207;&#21015;Gibbs&#20808;&#39564;&#30340;&#36129;&#29486;&#20110;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Sequential Gibbs Posteriors with Applications to Principal Component Analysis. (arXiv:2310.12882v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12882
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24207;&#21015;&#25193;&#23637;&#30340;Gibbs&#20808;&#39564;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#24182;&#33719;&#24471;&#20102;&#20851;&#20110;&#20271;&#24681;&#26031;&#22374;-&#20911;&#183;&#23494;&#26031;&#23450;&#29702;&#22312;&#27969;&#24418;&#19978;&#30340;&#26032;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Gibbs&#20808;&#39564;&#19982;&#20808;&#39564;&#20998;&#24067;&#20056;&#20197;&#25351;&#25968;&#25439;&#22833;&#20989;&#25968;&#25104;&#27604;&#20363;&#65292;&#20854;&#20013;&#20851;&#38190;&#35843;&#25972;&#21442;&#25968;&#22312;&#25439;&#22833;&#19982;&#20808;&#39564;&#20013;&#26435;&#37325;&#20449;&#24687;&#65292;&#24182;&#25552;&#20379;&#25511;&#21046;&#21518;&#39564;&#19981;&#30830;&#23450;&#24615;&#30340;&#33021;&#21147;&#12290;Gibbs&#20808;&#39564;&#20026;&#26080;&#20284;&#28982;&#36125;&#21494;&#26031;&#25512;&#29702;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#21407;&#21017;&#30340;&#26694;&#26550;&#65292;&#20294;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#21333;&#19968;&#35843;&#25972;&#21442;&#25968;&#20250;&#23548;&#33268;&#36739;&#24046;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24207;&#21015;&#25193;&#23637;&#30340;Gibbs&#20808;&#39564;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#24207;&#21015;&#21518;&#39564;&#23637;&#31034;&#20102;&#38598;&#20013;&#24615;&#21644;&#19968;&#20010;&#20271;&#24681;&#26031;&#22374;-&#20911;&#183;&#23494;&#26031;&#23450;&#29702;&#65292;&#35813;&#23450;&#29702;&#22312;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#21644;&#27969;&#24418;&#19978;&#26131;&#20110;&#39564;&#35777;&#30340;&#26465;&#20214;&#19979;&#25104;&#31435;&#12290;&#20316;&#20026;&#21103;&#20135;&#21697;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#20256;&#32479;&#22522;&#20110;&#20284;&#28982;&#30340;&#36125;&#21494;&#26031;&#21518;&#39564;&#22312;&#27969;&#24418;&#19978;&#30340;&#31532;&#19968;&#20010;&#20271;&#24681;&#26031;&#22374;-&#20911;&#183;&#23494;&#26031;&#23450;&#29702;&#12290;&#25152;&#26377;&#26041;&#27861;&#37117;&#26377;&#31034;&#20363;&#35828;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gibbs posteriors are proportional to a prior distribution multiplied by an exponentiated loss function, with a key tuning parameter weighting information in the loss relative to the prior and providing a control of posterior uncertainty. Gibbs posteriors provide a principled framework for likelihood-free Bayesian inference, but in many situations, including a single tuning parameter inevitably leads to poor uncertainty quantification. In particular, regardless of the value of the parameter, credible regions have far from the nominal frequentist coverage even in large samples. We propose a sequential extension to Gibbs posteriors to address this problem. We prove the proposed sequential posterior exhibits concentration and a Bernstein-von Mises theorem, which holds under easy to verify conditions in Euclidean space and on manifolds. As a byproduct, we obtain the first Bernstein-von Mises theorem for traditional likelihood-based Bayesian posteriors on manifolds. All methods are illustrat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29109;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25193;&#23637;&#29616;&#26377;&#30340;&#35299;&#37322;&#24615;&#26041;&#27861;&#65292;&#21487;&#20197;&#29702;&#35299;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#27169;&#22411;&#20013;&#30340;&#39044;&#27979;&#26469;&#28304;&#21644;&#32622;&#20449;&#24230;&#65292;&#24182;&#21033;&#29992;&#25913;&#32534;&#21518;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#12289;&#37096;&#20998;&#20381;&#36182;&#22270;&#21644;&#20010;&#20307;&#26465;&#20214;&#26399;&#26395;&#22270;&#31561;&#26041;&#27861;&#26469;&#27979;&#37327;&#29305;&#24449;&#23545;&#39044;&#27979;&#20998;&#24067;&#30340;&#29109;&#21644;&#22522;&#20110;&#30495;&#23454;&#26631;&#31614;&#30340;&#23545;&#25968;&#20284;&#28982;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.12842</link><description>&lt;p&gt;
&#38024;&#23545;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#27169;&#22411;&#26080;&#20851;&#21464;&#37327;&#37325;&#35201;&#24615;&#65306;&#19968;&#31181;&#22522;&#20110;&#29109;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Model-agnostic variable importance for predictive uncertainty: an entropy-based approach. (arXiv:2310.12842v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12842
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29109;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25193;&#23637;&#29616;&#26377;&#30340;&#35299;&#37322;&#24615;&#26041;&#27861;&#65292;&#21487;&#20197;&#29702;&#35299;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#27169;&#22411;&#20013;&#30340;&#39044;&#27979;&#26469;&#28304;&#21644;&#32622;&#20449;&#24230;&#65292;&#24182;&#21033;&#29992;&#25913;&#32534;&#21518;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#12289;&#37096;&#20998;&#20381;&#36182;&#22270;&#21644;&#20010;&#20307;&#26465;&#20214;&#26399;&#26395;&#22270;&#31561;&#26041;&#27861;&#26469;&#27979;&#37327;&#29305;&#24449;&#23545;&#39044;&#27979;&#20998;&#24067;&#30340;&#29109;&#21644;&#22522;&#20110;&#30495;&#23454;&#26631;&#31614;&#30340;&#23545;&#25968;&#20284;&#28982;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#30456;&#20449;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#39044;&#27979;&#32467;&#26524;&#65292;&#24517;&#39035;&#29702;&#35299;&#23548;&#33268;&#36825;&#20123;&#39044;&#27979;&#30340;&#22240;&#32032;&#12290;&#23545;&#20110;&#27010;&#29575;&#21644;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#27169;&#22411;&#26469;&#35828;&#65292;&#19981;&#20165;&#38656;&#35201;&#29702;&#35299;&#39044;&#27979;&#26412;&#36523;&#30340;&#21407;&#22240;&#65292;&#36824;&#35201;&#29702;&#35299;&#27169;&#22411;&#23545;&#36825;&#20123;&#39044;&#27979;&#30340;&#32622;&#20449;&#24230;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#29616;&#26377;&#30340;&#35299;&#37322;&#24615;&#26041;&#27861;&#25193;&#23637;&#21040;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#27169;&#22411;&#65292;&#24182;&#22914;&#20309;&#21033;&#29992;&#36825;&#20123;&#25193;&#23637;&#26469;&#29702;&#35299;&#27169;&#22411;&#39044;&#27979;&#20998;&#24067;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#12290;&#29305;&#21035;&#26159;&#36890;&#36807;&#25913;&#32534;&#25490;&#21015;&#29305;&#24449;&#37325;&#35201;&#24615;&#12289;&#37096;&#20998;&#20381;&#36182;&#22270;&#21644;&#20010;&#20307;&#26465;&#20214;&#26399;&#26395;&#22270;&#65292;&#25105;&#20204;&#35777;&#26126;&#21487;&#20197;&#33719;&#24471;&#23545;&#27169;&#22411;&#34892;&#20026;&#30340;&#26032;&#35265;&#35299;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#36825;&#20123;&#26041;&#27861;&#26469;&#34913;&#37327;&#29305;&#24449;&#23545;&#39044;&#27979;&#20998;&#24067;&#30340;&#29109;&#21644;&#22522;&#20110;&#35813;&#20998;&#24067;&#30340;&#30495;&#23454;&#26631;&#31614;&#30340;&#23545;&#25968;&#20284;&#28982;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#20351;&#29992;&#20004;&#20010;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In order to trust the predictions of a machine learning algorithm, it is necessary to understand the factors that contribute to those predictions. In the case of probabilistic and uncertainty-aware models, it is necessary to understand not only the reasons for the predictions themselves, but also the model's level of confidence in those predictions. In this paper, we show how existing methods in explainability can be extended to uncertainty-aware models and how such extensions can be used to understand the sources of uncertainty in a model's predictive distribution. In particular, by adapting permutation feature importance, partial dependence plots, and individual conditional expectation plots, we demonstrate that novel insights into model behaviour may be obtained and that these methods can be used to measure the impact of features on both the entropy of the predictive distribution and the log-likelihood of the ground truth labels under that distribution. With experiments using both s
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25968;&#23398;&#20248;&#21270;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;&#38598;&#20307;&#21453;&#20107;&#23454;&#35299;&#37322;&#65292;&#20026;&#39640;&#39118;&#38505;&#20915;&#31574;&#22330;&#26223;&#20013;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#25552;&#20379;&#20102;&#35299;&#37322;&#24037;&#20855;&#12290;&#19982;&#20256;&#32479;&#30340;&#21333;&#23454;&#20363;&#35299;&#37322;&#19981;&#21516;&#65292;&#35813;&#26041;&#27861;&#38024;&#23545;&#19968;&#32452;&#23454;&#20363;&#25552;&#20379;&#35299;&#37322;&#65292;&#24182;&#36890;&#36807;&#26368;&#23567;&#21270;&#25200;&#21160;&#30340;&#24635;&#25104;&#26412;&#26469;&#25552;&#20379;&#26368;&#20248;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2310.12822</link><description>&lt;p&gt;
&#36890;&#36807;&#25968;&#23398;&#20248;&#21270;&#22312;&#22522;&#20110;&#35780;&#20998;&#30340;&#20998;&#31867;&#20013;&#29983;&#25104;&#38598;&#20307;&#21453;&#20107;&#23454;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Generating collective counterfactual explanations in score-based classification via mathematical optimization. (arXiv:2310.12822v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12822
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25968;&#23398;&#20248;&#21270;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;&#38598;&#20307;&#21453;&#20107;&#23454;&#35299;&#37322;&#65292;&#20026;&#39640;&#39118;&#38505;&#20915;&#31574;&#22330;&#26223;&#20013;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#25552;&#20379;&#20102;&#35299;&#37322;&#24037;&#20855;&#12290;&#19982;&#20256;&#32479;&#30340;&#21333;&#23454;&#20363;&#35299;&#37322;&#19981;&#21516;&#65292;&#35813;&#26041;&#27861;&#38024;&#23545;&#19968;&#32452;&#23454;&#20363;&#25552;&#20379;&#35299;&#37322;&#65292;&#24182;&#36890;&#36807;&#26368;&#23567;&#21270;&#25200;&#21160;&#30340;&#24635;&#25104;&#26412;&#26469;&#25552;&#20379;&#26368;&#20248;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#39640;&#39118;&#38505;&#20915;&#31574;&#22330;&#26223;&#20013;&#30340;&#22686;&#21152;&#20351;&#29992;&#65292;&#20102;&#35299;&#27169;&#22411;&#22914;&#20309;&#20570;&#20986;&#20915;&#31574;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#22312;&#32463;&#36807;&#35757;&#32451;&#30340;&#30417;&#30563;&#20998;&#31867;&#27169;&#22411;&#20013;&#65292;&#21487;&#20197;&#36890;&#36807;&#21453;&#20107;&#23454;&#20998;&#26512;&#33719;&#24471;&#35299;&#37322;&#65306;&#19968;&#20010;&#23454;&#20363;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#25351;&#31034;&#24212;&#35813;&#22914;&#20309;&#26368;&#23567;&#31243;&#24230;&#22320;&#20462;&#25913;&#36825;&#20010;&#23454;&#20363;&#65292;&#20351;&#24471;&#34987;&#25200;&#21160;&#30340;&#23454;&#20363;&#22312;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#34987;&#20998;&#31867;&#21040;&#25152;&#26399;&#26395;&#30340;&#31867;&#21035;&#20013;&#12290;&#22823;&#37096;&#20998;&#21453;&#20107;&#23454;&#20998;&#26512;&#25991;&#29486;&#38598;&#20013;&#22312;&#21333;&#23454;&#20363;&#21333;&#21453;&#20107;&#23454;&#30340;&#24773;&#20917;&#19979;&#65292;&#21363;&#38024;&#23545;&#19968;&#20010;&#21333;&#19968;&#23454;&#20363;&#26469;&#25552;&#20379;&#19968;&#20010;&#21333;&#19968;&#35299;&#37322;&#12290;&#20174;&#21033;&#30410;&#30456;&#20851;&#32773;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#22312;&#26412;&#25991;&#20013;&#25105;&#20204;&#20171;&#32461;&#20102;&#25152;&#35859;&#30340;&#38598;&#20307;&#21453;&#20107;&#23454;&#35299;&#37322;&#12290;&#36890;&#36807;&#26032;&#39062;&#30340;&#25968;&#23398;&#20248;&#21270;&#27169;&#22411;&#65292;&#25105;&#20204;&#20026;&#24863;&#20852;&#36259;&#30340;&#19968;&#32452;&#23454;&#20363;&#25552;&#20379;&#21453;&#20107;&#23454;&#35299;&#37322;&#65292;&#20197;&#20351;&#25200;&#21160;&#30340;&#24635;&#25104;&#26412;&#26368;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
Due to the increasing use of Machine Learning models in high stakes decision making settings, it has become increasingly important to have tools to understand how models arrive at decisions. Assuming a trained Supervised Classification model, explanations can be obtained via counterfactual analysis: a counterfactual explanation of an instance indicates how this instance should be minimally modified so that the perturbed instance is classified in the desired class by the Machine Learning classification model. Most of the Counterfactual Analysis literature focuses on the single-instance single-counterfactual setting, in which the analysis is done for one single instance to provide one single explanation. Taking a stakeholder's perspective, in this paper we introduce the so-called collective counterfactual explanations. By means of novel Mathematical Optimization models, we provide a counterfactual explanation for each instance in a group of interest, so that the total cost of the perturb
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#32858;&#31867;&#21487;&#20998;&#31163;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#26088;&#22312;&#37327;&#21270;&#31867;&#38388;&#20998;&#31163;&#21644;&#31867;&#20869;&#36830;&#36890;&#24615;&#65292;&#23545;&#20110;&#23494;&#24230;&#32858;&#31867;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2310.12806</link><description>&lt;p&gt;
DCSI -- &#22522;&#20110;&#20998;&#31163;&#21644;&#36830;&#36890;&#24615;&#30340;&#25913;&#36827;&#30340;&#32858;&#31867;&#21487;&#20998;&#31163;&#24615;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
DCSI -- An improved measure of cluster separability based on separation and connectedness. (arXiv:2310.12806v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12806
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#32858;&#31867;&#21487;&#20998;&#31163;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#26088;&#22312;&#37327;&#21270;&#31867;&#38388;&#20998;&#31163;&#21644;&#31867;&#20869;&#36830;&#36890;&#24615;&#65292;&#23545;&#20110;&#23494;&#24230;&#32858;&#31867;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30830;&#23450;&#32473;&#23450;&#25968;&#25454;&#38598;&#20013;&#30340;&#31867;&#21035;&#26631;&#31614;&#26159;&#21542;&#23545;&#24212;&#20110;&#26377;&#24847;&#20041;&#30340;&#32858;&#31867;&#23545;&#20110;&#20351;&#29992;&#30495;&#23454;&#25968;&#25454;&#38598;&#35780;&#20272;&#32858;&#31867;&#31639;&#27861;&#33267;&#20851;&#37325;&#35201;&#12290;&#36825;&#20010;&#29305;&#24615;&#21487;&#20197;&#36890;&#36807;&#21487;&#20998;&#31163;&#24615;&#24230;&#37327;&#26469;&#37327;&#21270;&#12290;&#29616;&#26377;&#25991;&#29486;&#30340;&#32508;&#36848;&#26174;&#31034;&#65292;&#26082;&#26377;&#30340;&#22522;&#20110;&#20998;&#31867;&#30340;&#22797;&#26434;&#24615;&#24230;&#37327;&#26041;&#27861;&#21644;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#26631; (CVIs) &#37117;&#27809;&#26377;&#20805;&#20998;&#34701;&#20837;&#22522;&#20110;&#23494;&#24230;&#30340;&#32858;&#31867;&#30340;&#26680;&#24515;&#29305;&#24449;&#65306;&#31867;&#38388;&#20998;&#31163;&#21644;&#31867;&#20869;&#36830;&#36890;&#24615;&#12290;&#19968;&#31181;&#26032;&#24320;&#21457;&#30340;&#24230;&#37327;&#26041;&#27861; (&#23494;&#24230;&#32858;&#31867;&#21487;&#20998;&#31163;&#24615;&#25351;&#25968;, DCSI) &#26088;&#22312;&#37327;&#21270;&#36825;&#20004;&#20010;&#29305;&#24449;&#65292;&#24182;&#19988;&#20063;&#21487;&#29992;&#20316; CVI&#12290;&#23545;&#21512;&#25104;&#25968;&#25454;&#30340;&#24191;&#27867;&#23454;&#39564;&#34920;&#26126;&#65292;DCSI &#19982;&#36890;&#36807;&#35843;&#25972;&#20848;&#24503;&#25351;&#25968; (ARI) &#27979;&#37327;&#30340;DBSCAN&#30340;&#24615;&#33021;&#20043;&#38388;&#26377;&#24456;&#24378;&#30340;&#30456;&#20851;&#24615;&#65292;&#20294;&#22312;&#23545;&#22810;&#31867;&#25968;&#25454;&#38598;&#36827;&#34892;&#23494;&#24230;&#32858;&#31867;&#19981;&#36866;&#24403;&#30340;&#37325;&#21472;&#31867;&#21035;&#26102;&#32570;&#20047;&#40065;&#26834;&#24615;&#12290;&#23545;&#32463;&#24120;&#20351;&#29992;&#30340;&#30495;&#23454;&#25968;&#25454;&#38598;&#36827;&#34892;&#35814;&#32454;&#35780;&#20272;&#26174;&#31034;&#65292;DCSI &#33021;&#22815;&#26356;&#22909;&#22320;&#21306;&#20998;&#23494;&#24230;&#32858;&#31867;&#30340;&#21487;&#20998;&#31163;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Whether class labels in a given data set correspond to meaningful clusters is crucial for the evaluation of clustering algorithms using real-world data sets. This property can be quantified by separability measures. A review of the existing literature shows that neither classification-based complexity measures nor cluster validity indices (CVIs) adequately incorporate the central aspects of separability for density-based clustering: between-class separation and within-class connectedness. A newly developed measure (density cluster separability index, DCSI) aims to quantify these two characteristics and can also be used as a CVI. Extensive experiments on synthetic data indicate that DCSI correlates strongly with the performance of DBSCAN measured via the adjusted rand index (ARI) but lacks robustness when it comes to multi-class data sets with overlapping classes that are ill-suited for density-based hard clustering. Detailed evaluation on frequently used real-world data sets shows that
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#20013;&#36827;&#34892;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#31070;&#32463;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#22120;&#26469;&#36817;&#20284;&#27169;&#22411;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#22312;&#32479;&#35745;&#20998;&#26512;&#36807;&#31243;&#20013;&#21482;&#33021;&#35775;&#38382;&#31169;&#26377;&#21270;&#25968;&#25454;&#23548;&#33268;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#22686;&#21152;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.12781</link><description>&lt;p&gt;
&#20174;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#20013;&#36827;&#34892;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Conditional Density Estimations from Privacy-Protected Data. (arXiv:2310.12781v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12781
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#20013;&#36827;&#34892;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#31070;&#32463;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#22120;&#26469;&#36817;&#20284;&#27169;&#22411;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#22312;&#32479;&#35745;&#20998;&#26512;&#36807;&#31243;&#20013;&#21482;&#33021;&#35775;&#38382;&#31169;&#26377;&#21270;&#25968;&#25454;&#23548;&#33268;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#22686;&#21152;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#29616;&#20195;&#32479;&#35745;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#38656;&#35201;&#22312;&#25935;&#24863;&#29992;&#25143;&#25968;&#25454;&#19978;&#36827;&#34892;&#27169;&#22411;&#35757;&#32451;&#12290;&#24046;&#20998;&#38544;&#31169;&#25552;&#20379;&#20102;&#19968;&#31181;&#27491;&#24335;&#30340;&#20445;&#35777;&#65292;&#21363;&#20010;&#20307;&#29992;&#25143;&#20449;&#24687;&#19981;&#20250;&#27844;&#38706;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#19979;&#65292;&#38543;&#26426;&#31639;&#27861;&#21521;&#20445;&#23494;&#25968;&#25454;&#27880;&#20837;&#26657;&#20934;&#30340;&#22122;&#22768;&#65292;&#20174;&#32780;&#20135;&#29983;&#38544;&#31169;&#20445;&#25252;&#30340;&#25968;&#25454;&#38598;&#25110;&#26597;&#35810;&#12290;&#28982;&#32780;&#65292;&#22312;&#32479;&#35745;&#20998;&#26512;&#36807;&#31243;&#20013;&#21482;&#33021;&#35775;&#38382;&#31169;&#26377;&#21270;&#25968;&#25454;&#20250;&#23548;&#33268;&#35745;&#31639;&#22797;&#26434;&#24230;&#22686;&#21152;&#65292;&#38590;&#20197;&#23545;&#22522;&#30784;&#26426;&#23494;&#25968;&#25454;&#30340;&#21442;&#25968;&#36827;&#34892;&#26377;&#25928;&#30340;&#25512;&#29702;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#38598;&#30340;&#22522;&#20110;&#27169;&#25311;&#30340;&#25512;&#29702;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20351;&#29992;&#31070;&#32463;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#22120;&#20316;&#20026;&#19968;&#32452;&#28789;&#27963;&#30340;&#20998;&#24067;&#26469;&#36817;&#20284;&#32473;&#23450;&#35266;&#27979;&#21040;&#30340;&#31169;&#26377;&#26597;&#35810;&#32467;&#26524;&#30340;&#27169;&#22411;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#25105;&#20204;&#22312;&#20256;&#26579;&#30149;&#27169;&#22411;&#19979;&#30340;&#31163;&#25955;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20197;&#21450;&#26222;&#36890;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#19978;&#35828;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many modern statistical analysis and machine learning applications require training models on sensitive user data. Differential privacy provides a formal guarantee that individual-level information about users does not leak. In this framework, randomized algorithms inject calibrated noise into the confidential data, resulting in privacy-protected datasets or queries. However, restricting access to only the privatized data during statistical analysis makes it computationally challenging to perform valid inferences on parameters underlying the confidential data. In this work, we propose simulation-based inference methods from privacy-protected datasets. Specifically, we use neural conditional density estimators as a flexible family of distributions to approximate the posterior distribution of model parameters given the observed private query results. We illustrate our methods on discrete time-series data under an infectious disease model and on ordinary linear regression models. Illustra
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#35268;&#33539;&#21270;&#27491;&#24577;&#27969;&#26041;&#27861;&#65292;&#29992;&#20110;&#27969;&#24418;&#23398;&#20064;&#12290;&#36890;&#36807;&#21487;&#23398;&#20064;&#30340;&#21487;&#36870;&#21464;&#25442;&#23558;&#25968;&#25454;&#23884;&#20837;&#21040;&#39640;&#32500;&#31354;&#38388;&#20013;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#22312;&#27969;&#24418;&#19978;&#35745;&#31639;&#27010;&#29575;&#23494;&#24230;&#24182;&#20248;&#21270;&#32593;&#32476;&#21442;&#25968;&#30340;&#30446;&#26631;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#26041;&#27861;&#22312;&#23398;&#20064;&#21040;&#30340;&#27969;&#24418;&#34920;&#31034;&#20013;&#23384;&#22312;&#30528;&#19982;&#27969;&#24418;&#20851;&#32852;&#19988;&#36864;&#21270;&#30340;&#20869;&#22312;&#22522;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.12743</link><description>&lt;p&gt;
&#27969;&#24418;&#23398;&#20064;&#30340;&#35268;&#33539;&#21270;&#27491;&#24577;&#27969;
&lt;/p&gt;
&lt;p&gt;
Canonical normalizing flows for manifold learning. (arXiv:2310.12743v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12743
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#35268;&#33539;&#21270;&#27491;&#24577;&#27969;&#26041;&#27861;&#65292;&#29992;&#20110;&#27969;&#24418;&#23398;&#20064;&#12290;&#36890;&#36807;&#21487;&#23398;&#20064;&#30340;&#21487;&#36870;&#21464;&#25442;&#23558;&#25968;&#25454;&#23884;&#20837;&#21040;&#39640;&#32500;&#31354;&#38388;&#20013;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#22312;&#27969;&#24418;&#19978;&#35745;&#31639;&#27010;&#29575;&#23494;&#24230;&#24182;&#20248;&#21270;&#32593;&#32476;&#21442;&#25968;&#30340;&#30446;&#26631;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#26041;&#27861;&#22312;&#23398;&#20064;&#21040;&#30340;&#27969;&#24418;&#34920;&#31034;&#20013;&#23384;&#22312;&#30528;&#19982;&#27969;&#24418;&#20851;&#32852;&#19988;&#36864;&#21270;&#30340;&#20869;&#22312;&#22522;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27969;&#24418;&#23398;&#20064;&#27969;&#26159;&#19968;&#31867;&#29983;&#25104;&#24314;&#27169;&#25216;&#26415;&#65292;&#20551;&#35774;&#25968;&#25454;&#20855;&#26377;&#20302;&#32500;&#27969;&#24418;&#25551;&#36848;&#12290;&#36890;&#36807;&#21487;&#23398;&#20064;&#30340;&#21487;&#36870;&#21464;&#25442;&#23558;&#36825;&#31181;&#27969;&#24418;&#23884;&#20837;&#21040;&#25968;&#25454;&#30340;&#39640;&#32500;&#31354;&#38388;&#20013;&#12290;&#22240;&#27492;&#65292;&#19968;&#26086;&#36890;&#36807;&#37325;&#26500;&#25439;&#22833;&#27491;&#30830;&#23545;&#40784;&#27969;&#24418;&#65292;&#27969;&#24418;&#19978;&#30340;&#27010;&#29575;&#23494;&#24230;&#23601;&#26159;&#21487;&#35745;&#31639;&#30340;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#26368;&#22823;&#20284;&#28982;&#26469;&#20248;&#21270;&#32593;&#32476;&#21442;&#25968;&#12290;&#33258;&#28982;&#22320;&#65292;&#25968;&#25454;&#30340;&#20302;&#32500;&#34920;&#31034;&#38656;&#35201;&#26159;&#21333;&#23556;&#26144;&#23556;&#12290;&#26368;&#36817;&#30340;&#26041;&#27861;&#33021;&#22815;&#22312;&#24314;&#27169;&#30340;&#27969;&#24418;&#19978;&#23545;&#23494;&#24230;&#36827;&#34892;&#23545;&#20934;&#65292;&#24182;&#22312;&#23884;&#20837;&#21040;&#39640;&#32500;&#31354;&#38388;&#26102;&#39640;&#25928;&#35745;&#31639;&#23494;&#24230;&#20307;&#31215;&#21464;&#21270;&#39033;&#12290;&#28982;&#32780;&#65292;&#38500;&#38750;&#21333;&#23556;&#26144;&#23556;&#22312;&#35299;&#26512;&#19978;&#39044;&#23450;&#20041;&#65292;&#21542;&#21017;&#23398;&#20064;&#21040;&#30340;&#27969;&#24418;&#19981;&#19968;&#23450;&#26159;&#25968;&#25454;&#30340;&#26377;&#25928;&#34920;&#31034;&#12290;&#20063;&#23601;&#26159;&#35828;&#65292;&#36825;&#31181;&#27169;&#22411;&#30340;&#28508;&#22312;&#32500;&#24230;&#32463;&#24120;&#20250;&#23398;&#20064;&#21040;&#19982;&#27969;&#24418;&#30456;&#20851;&#24182;&#19988;&#36864;&#21270;&#30340;&#20869;&#22312;&#22522;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Manifold learning flows are a class of generative modelling techniques that assume a low-dimensional manifold description of the data. The embedding of such manifold into the high-dimensional space of the data is achieved via learnable invertible transformations. Therefore, once the manifold is properly aligned via a reconstruction loss, the probability density is tractable on the manifold and maximum likelihood can be used optimize the network parameters. Naturally, the lower-dimensional representation of the data requires an injective-mapping. Recent approaches were able to enforce that density aligns with the modelled manifold, while efficiently calculating the density volume-change term when embedding to the higher-dimensional space. However, unless the injective-mapping is analytically predefined, the learned manifold is not necessarily an efficient representation of the data. Namely, the latent dimensions of such models frequently learn an entangled intrinsic basis with degenerat
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;Cosmos&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23545;&#35937;&#20026;&#20013;&#24515;&#30340;&#19990;&#30028;&#24314;&#27169;&#65292;&#36890;&#36807;&#20351;&#29992;&#31070;&#32463;&#31526;&#21495;&#21270;&#22522;&#30784;&#21644;&#35270;&#35273;-&#35821;&#35328;&#22522;&#30784;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#22312;&#26410;&#35265;&#36807;&#30340;&#36755;&#20837;&#22330;&#26223;&#19978;&#30340;&#39640;&#24615;&#33021;&#32452;&#21512;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.12690</link><description>&lt;p&gt;
&#31070;&#32463;&#31526;&#21495;&#21270;&#22522;&#30784;&#19978;&#30340;&#32452;&#21512;&#24335;&#19990;&#30028;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Neurosymbolic Grounding for Compositional World Models. (arXiv:2310.12690v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12690
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;Cosmos&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23545;&#35937;&#20026;&#20013;&#24515;&#30340;&#19990;&#30028;&#24314;&#27169;&#65292;&#36890;&#36807;&#20351;&#29992;&#31070;&#32463;&#31526;&#21495;&#21270;&#22522;&#30784;&#21644;&#35270;&#35273;-&#35821;&#35328;&#22522;&#30784;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#22312;&#26410;&#35265;&#36807;&#30340;&#36755;&#20837;&#22330;&#26223;&#19978;&#30340;&#39640;&#24615;&#33021;&#32452;&#21512;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;Cosmos&#65292;&#19968;&#20010;&#38024;&#23545;&#32452;&#21512;&#27867;&#21270;&#65288;CG&#65289;&#35774;&#35745;&#30340;&#20197;&#23545;&#35937;&#20026;&#20013;&#24515;&#30340;&#19990;&#30028;&#24314;&#27169;&#26694;&#26550;&#65292;&#21363;&#22312;&#36890;&#36807;&#24050;&#30693;&#30340;&#35270;&#35273;&#8220;&#21407;&#23376;&#8221;&#32452;&#21512;&#33719;&#24471;&#30340;&#26410;&#35265;&#36807;&#30340;&#36755;&#20837;&#22330;&#26223;&#19978;&#20855;&#26377;&#39640;&#24615;&#33021;&#12290;Cosmos&#30340;&#26680;&#24515;&#27934;&#23519;&#21147;&#26159;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#31070;&#32463;&#31526;&#21495;&#21270;&#22522;&#30784;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#35813;&#26694;&#26550;&#24341;&#20837;&#20102;&#20004;&#20010;&#26032;&#24037;&#20855;&#65306;&#65288;i&#65289;&#31070;&#32463;&#31526;&#21495;&#21270;&#22330;&#26223;&#32534;&#30721;&#65292;&#20351;&#29992;&#31070;&#32463;&#32534;&#30721;&#22120;&#35745;&#31639;&#27599;&#20010;&#22330;&#26223;&#20013;&#30340;&#23454;&#20307;&#30340;&#23454;&#21521;&#37327;&#34920;&#31034;&#65292;&#24182;&#20351;&#29992;&#25551;&#36848;&#23454;&#20307;&#23646;&#24615;&#30340;&#21487;&#32452;&#21512;&#31526;&#21495;&#21521;&#37327;&#65292;&#20197;&#21450;&#65288;ii&#65289;&#31070;&#32463;&#31526;&#21495;&#21270;&#27880;&#24847;&#26426;&#21046;&#65292;&#23558;&#36825;&#20123;&#23454;&#20307;&#19982;&#23398;&#20064;&#21040;&#30340;&#20132;&#20114;&#35268;&#21017;&#32465;&#23450;&#36215;&#26469;&#12290;Cosmos&#26159;&#31471;&#21040;&#31471;&#21487;&#24494;&#20998;&#30340;&#65307;&#27492;&#22806;&#65292;&#19982;&#20256;&#32479;&#30340;&#31070;&#32463;&#31526;&#21495;&#21270;&#26041;&#27861;&#38656;&#35201;&#25163;&#21160;&#23558;&#34920;&#31034;&#26144;&#23556;&#20026;&#31526;&#21495;&#19981;&#21516;&#65292;&#23427;&#20351;&#29992;&#35270;&#35273;-&#35821;&#35328;&#22522;&#30784;&#27169;&#22411;&#35745;&#31639;&#23454;&#20307;&#30340;&#31526;&#21495;&#23646;&#24615;&#12290;&#36890;&#36807;&#23545;&#24050;&#24314;&#31435;&#30340;blocks&#22330;&#26223;&#36827;&#34892;&#20004;&#31181;&#19981;&#21516;&#24418;&#24335;&#30340;CG&#35780;&#20272;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;Cosmos&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce Cosmos, a framework for object-centric world modeling that is designed for compositional generalization (CG), i.e., high performance on unseen input scenes obtained through the composition of known visual "atoms." The central insight behind Cosmos is the use of a novel form of neurosymbolic grounding. Specifically, the framework introduces two new tools: (i) neurosymbolic scene encodings, which represent each entity in a scene using a real vector computed using a neural encoder, as well as a vector of composable symbols describing attributes of the entity, and (ii) a neurosymbolic attention mechanism that binds these entities to learned rules of interaction. Cosmos is end-to-end differentiable; also, unlike traditional neurosymbolic methods that require representations to be manually mapped to symbols, it computes an entity's symbolic attributes using vision-language foundation models. Through an evaluation that considers two different forms of CG on an established blocks-
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Rank-Tuning&#30340;&#35757;&#32451;&#21518;&#31209;&#36873;&#25321;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#20013;&#39640;&#25928;&#21387;&#32553;&#27169;&#22411;&#65292;&#24182;&#22312;&#20960;&#20046;&#27809;&#26377;&#24615;&#33021;&#38477;&#20302;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#39640;&#21387;&#32553;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.12688</link><description>&lt;p&gt;
&#20351;&#29992;&#30697;&#38453;&#22240;&#24335;&#20998;&#35299;&#21387;&#32553;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Compression of Recurrent Neural Networks using Matrix Factorization. (arXiv:2310.12688v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12688
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Rank-Tuning&#30340;&#35757;&#32451;&#21518;&#31209;&#36873;&#25321;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#20013;&#39640;&#25928;&#21387;&#32553;&#27169;&#22411;&#65292;&#24182;&#22312;&#20960;&#20046;&#27809;&#26377;&#24615;&#33021;&#38477;&#20302;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#39640;&#21387;&#32553;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#26102;&#25110;&#23884;&#20837;&#24335;&#24212;&#29992;&#20013;&#37096;&#32626;&#27169;&#22411;&#26102;&#65292;&#21387;&#32553;&#31070;&#32463;&#32593;&#32476;&#26159;&#19968;&#20010;&#20851;&#38190;&#27493;&#39588;&#12290;&#20351;&#29992;&#20302;&#31209;&#36817;&#20284;&#23545;&#27169;&#22411;&#30340;&#30697;&#38453;&#36827;&#34892;&#20998;&#35299;&#26159;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#21387;&#32553;&#26041;&#27861;&#12290;&#34429;&#28982;&#22312;&#35757;&#32451;&#20043;&#21069;&#21487;&#20197;&#35774;&#32622;&#31209;&#65292;&#20294;&#36825;&#31181;&#26041;&#27861;&#26082;&#19981;&#28789;&#27963;&#20063;&#19981;&#26368;&#20248;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Rank-Tuning&#30340;&#35757;&#32451;&#21518;&#31209;&#36873;&#25321;&#26041;&#27861;&#65292;&#21487;&#20197;&#20026;&#27599;&#20010;&#30697;&#38453;&#36873;&#25321;&#19981;&#21516;&#30340;&#31209;&#12290;&#32467;&#21512;&#35757;&#32451;&#36866;&#24212;&#24615;&#30340;&#20351;&#29992;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20960;&#20046;&#27809;&#26377;&#24615;&#33021;&#38477;&#20302;&#25110;&#32773;&#26377;&#24456;&#23569;&#24615;&#33021;&#38477;&#20302;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#39640;&#21387;&#32553;&#29575;&#12290;&#25105;&#20204;&#22312;&#20449;&#21495;&#22788;&#29702;&#20219;&#21153;&#19978;&#30340;&#25968;&#20540;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#25105;&#20204;&#21487;&#20197;&#23558;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#21387;&#32553;&#33267;&#26368;&#22810;14&#20493;&#65292;&#19988;&#30456;&#23545;&#24615;&#33021;&#38477;&#20302;&#26368;&#22810;&#20026;1.4%&#12290;
&lt;/p&gt;
&lt;p&gt;
Compressing neural networks is a key step when deploying models for real-time or embedded applications. Factorizing the model's matrices using low-rank approximations is a promising method for achieving compression. While it is possible to set the rank before training, this approach is neither flexible nor optimal. In this work, we propose a post-training rank-selection method called Rank-Tuning that selects a different rank for each matrix. Used in combination with training adaptations, our method achieves high compression rates with no or little performance degradation. Our numerical experiments on signal processing tasks show that we can compress recurrent neural networks up to 14x with at most 1.4% relative performance reduction.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22810;&#22836;&#27880;&#24847;&#21147;&#22312;&#20248;&#21270;&#21644;&#27867;&#21270;&#26041;&#38754;&#30340;&#20248;&#21183;&#65292;&#25512;&#23548;&#20102;&#21333;&#23618;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#27169;&#22411;&#30340;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#25910;&#25947;&#24615;&#21644;&#27867;&#21270;&#20445;&#35777;&#65292;&#24182;&#35777;&#26126;&#20102;&#23545;&#20110;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#35789;&#28151;&#21512;&#27169;&#22411;&#65292;&#21021;&#22987;&#21270;&#26465;&#20214;&#28385;&#36275;&#21487;&#23454;&#29616;&#24615;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2310.12680</link><description>&lt;p&gt;
&#20851;&#20110;&#22810;&#22836;&#27880;&#24847;&#21147;&#30340;&#20248;&#21270;&#19982;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
On the Optimization and Generalization of Multi-head Attention. (arXiv:2310.12680v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12680
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22810;&#22836;&#27880;&#24847;&#21147;&#22312;&#20248;&#21270;&#21644;&#27867;&#21270;&#26041;&#38754;&#30340;&#20248;&#21183;&#65292;&#25512;&#23548;&#20102;&#21333;&#23618;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#27169;&#22411;&#30340;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#25910;&#25947;&#24615;&#21644;&#27867;&#21270;&#20445;&#35777;&#65292;&#24182;&#35777;&#26126;&#20102;&#23545;&#20110;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#35789;&#28151;&#21512;&#27169;&#22411;&#65292;&#21021;&#22987;&#21270;&#26465;&#20214;&#28385;&#36275;&#21487;&#23454;&#29616;&#24615;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#26680;&#24515;&#26426;&#21046;&#8212;&#8212;Attention&#26426;&#21046;&#30340;&#35757;&#32451;&#21644;&#27867;&#21270;&#21160;&#24577;&#20173;&#26410;&#28145;&#20837;&#30740;&#31350;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#20998;&#26512;&#20027;&#35201;&#38598;&#20013;&#22312;&#21333;&#22836;&#27880;&#24847;&#21147;&#19978;&#12290;&#21463;&#21040;&#20840;&#36830;&#25509;&#32593;&#32476;&#35757;&#32451;&#26102;&#36807;&#21442;&#25968;&#21270;&#30340;&#30410;&#22788;&#21551;&#21457;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#22810;&#22836;&#27880;&#24847;&#21147;&#30340;&#28508;&#22312;&#20248;&#21270;&#21644;&#27867;&#21270;&#20248;&#21183;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#22312;&#25968;&#25454;&#30340;&#36866;&#24403;&#21487;&#23454;&#29616;&#24615;&#26465;&#20214;&#19979;&#65292;&#25512;&#23548;&#20986;&#21333;&#23618;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#27169;&#22411;&#30340;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#25910;&#25947;&#24615;&#21644;&#27867;&#21270;&#20445;&#35777;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24314;&#31435;&#36215;&#21021;&#22987;&#21270;&#26102;&#30830;&#20445;&#21487;&#23454;&#29616;&#24615;&#24471;&#21040;&#28385;&#36275;&#30340;&#22522;&#26412;&#26465;&#20214;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#26465;&#20214;&#36866;&#29992;&#20110;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#35789;&#28151;&#21512;&#27169;&#22411;&#12290;&#25105;&#20204;&#26399;&#26395;&#36825;&#20010;&#20998;&#26512;&#21487;&#20197;&#25193;&#23637;&#21040;&#21508;&#31181;&#25968;&#25454;&#27169;&#22411;&#21644;&#26550;&#26500;&#21464;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;
The training and generalization dynamics of the Transformer's core mechanism, namely the Attention mechanism, remain under-explored. Besides, existing analyses primarily focus on single-head attention. Inspired by the demonstrated benefits of overparameterization when training fully-connected networks, we investigate the potential optimization and generalization advantages of using multiple attention heads. Towards this goal, we derive convergence and generalization guarantees for gradient-descent training of a single-layer multi-head self-attention model, under a suitable realizability condition on the data. We then establish primitive conditions on the initialization that ensure realizability holds. Finally, we demonstrate that these conditions are satisfied for a simple tokenized-mixture model. We expect the analysis can be extended to various data-model and architecture variations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;STANLEY&#30340;&#31639;&#27861;&#29992;&#20110;&#37319;&#26679;&#39640;&#32500;&#25968;&#25454;&#65292;&#25913;&#21892;&#20102;&#33021;&#37327;&#27169;&#22411;&#23398;&#20064;&#31639;&#27861;&#30340;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2310.12667</link><description>&lt;p&gt;
STANLEY&#65306;&#29992;&#20110;&#23398;&#20064;&#33021;&#37327;&#27169;&#22411;&#30340;&#38543;&#26426;&#26799;&#24230;&#24322;&#21521;&#25289;&#26684;&#26391;&#26085;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
STANLEY: Stochastic Gradient Anisotropic Langevin Dynamics for Learning Energy-Based Models. (arXiv:2310.12667v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12667
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;STANLEY&#30340;&#31639;&#27861;&#29992;&#20110;&#37319;&#26679;&#39640;&#32500;&#25968;&#25454;&#65292;&#25913;&#21892;&#20102;&#33021;&#37327;&#27169;&#22411;&#23398;&#20064;&#31639;&#27861;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;STANLEY&#30340;&#38543;&#26426;&#26799;&#24230;&#24322;&#21521;&#25289;&#26684;&#26391;&#26085;&#21160;&#21147;&#23398;&#31639;&#27861;&#65292;&#29992;&#20110;&#37319;&#26679;&#39640;&#32500;&#25968;&#25454;&#12290;&#36890;&#36807;&#22686;&#24378;&#33021;&#37327;&#27169;&#22411;&#65288;EBM&#65289;&#30340;&#23398;&#20064;&#31639;&#27861;&#26469;&#25913;&#21892;&#37319;&#26679;&#25968;&#25454;&#28857;&#30340;&#36136;&#37327;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;EBM&#30340;&#31471;&#21040;&#31471;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20063;&#34987;&#31216;&#20026;&#38750;&#24402;&#19968;&#21270;&#27010;&#29575;&#24314;&#27169;&#12290;&#30001;&#20110;EBMs&#30340;&#26410;&#30693;&#24402;&#19968;&#21270;&#24120;&#25968;&#23548;&#33268;&#35757;&#32451;&#36807;&#31243;&#38590;&#20197;&#22788;&#29702;&#65292;&#37319;&#29992;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#65288;MCMC&#65289;&#36890;&#24120;&#26159;&#21487;&#34892;&#30340;&#36873;&#25321;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39640;&#32500;&#37319;&#26679;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#32454;&#20998;&#38543;&#26426;&#36807;&#31243;&#30340;&#24322;&#21521;&#27493;&#38271;&#21644;&#26799;&#24230;&#20449;&#24687;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#12290;&#25105;&#20204;&#36890;&#36807;&#35770;&#35777;&#39532;&#23572;&#31185;&#22827;&#38142;&#20013;&#36127;&#26679;&#26412;&#30340;&#24322;&#21521;&#26356;&#26032;&#30340;&#24517;&#35201;&#24615;&#26469;&#35299;&#37322;&#20102;MCMC&#22312;EBM&#35757;&#32451;&#20013;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose in this paper, STANLEY, a STochastic gradient ANisotropic LangEvin dYnamics, for sampling high dimensional data. With the growing efficacy and potential of Energy-Based modeling, also known as non-normalized probabilistic modeling, for modeling a generative process of different natures of high dimensional data observations, we present an end-to-end learning algorithm for Energy-Based models (EBM) with the purpose of improving the quality of the resulting sampled data points. While the unknown normalizing constant of EBMs makes the training procedure intractable, resorting to Markov Chain Monte Carlo (MCMC) is in general a viable option. Realizing what MCMC entails for the EBM training, we propose in this paper, a novel high dimensional sampling method, based on an anisotropic stepsize and a gradient-informed covariance matrix, embedded into a discretized Langevin diffusion. We motivate the necessity for an anisotropic update of the negative samples in the Markov Chain by the
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#35889;&#26041;&#27861;&#30340;&#20248;&#21270;&#26041;&#26696;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;&#38750;&#20984;&#24615;&#38382;&#39064;&#19979;&#23398;&#29983;&#32593;&#32476;&#19982;&#25945;&#24072;&#32593;&#32476;&#20043;&#38388;&#23384;&#22312;&#30340;&#19981;&#21464;&#23376;&#32593;&#32476;&#30340;&#35782;&#21035;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.12612</link><description>&lt;p&gt;
&#23398;&#29983;&#22914;&#20309;&#25104;&#20026;&#25945;&#24072;&#65306;&#36890;&#36807;&#35889;&#26041;&#27861;&#23398;&#20064;&#21644;&#36951;&#24536;
&lt;/p&gt;
&lt;p&gt;
How a student becomes a teacher: learning and forgetting through Spectral methods. (arXiv:2310.12612v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12612
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#35889;&#26041;&#27861;&#30340;&#20248;&#21270;&#26041;&#26696;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;&#38750;&#20984;&#24615;&#38382;&#39064;&#19979;&#23398;&#29983;&#32593;&#32476;&#19982;&#25945;&#24072;&#32593;&#32476;&#20043;&#38388;&#23384;&#22312;&#30340;&#19981;&#21464;&#23376;&#32593;&#32476;&#30340;&#35782;&#21035;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29702;&#35770;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#23398;&#29983;-&#25945;&#24072;&#27169;&#22411;&#24120;&#34987;&#29992;&#20316;&#29616;&#23454;&#29983;&#27963;&#20013;&#25945;&#23398;&#30340;&#26377;&#25928;&#38544;&#21947;&#12290;&#24403;&#23398;&#29983;&#32593;&#32476;&#30456;&#23545;&#20110;&#25945;&#24072;&#32593;&#32476;&#36807;&#24230;&#21442;&#25968;&#21270;&#26102;&#65292;&#19978;&#36848;&#27169;&#22411;&#23588;&#20026;&#30456;&#20851;&#12290;&#22312;&#36825;&#31181;&#25805;&#20316;&#26465;&#20214;&#19979;&#65292;&#24456;&#23481;&#26131;&#25512;&#27979;&#23398;&#29983;&#22788;&#29702;&#32473;&#23450;&#20219;&#21153;&#30340;&#33021;&#21147;&#26368;&#32456;&#21487;&#33021;&#20648;&#23384;&#22312;&#25972;&#20010;&#32593;&#32476;&#30340;&#19968;&#20010;&#23376;&#37096;&#20998;&#20013;&#12290;&#26681;&#25454;&#36866;&#24403;&#30340;&#25351;&#26631;&#65292;&#36825;&#20010;&#23376;&#37096;&#20998;&#24212;&#35813;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#31867;&#20284;&#20110;&#20923;&#32467;&#30340;&#25945;&#24072;&#32467;&#26500;&#65292;&#24182;&#19988;&#22312;&#23398;&#29983;&#20505;&#36873;&#32593;&#32476;&#30340;&#19981;&#21516;&#26550;&#26500;&#19979;&#36817;&#20284;&#19981;&#21464;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#25152;&#30740;&#31350;&#38382;&#39064;&#30340;&#22266;&#26377;&#38750;&#20984;&#24615;&#31243;&#24230;&#65292;&#26368;&#26032;&#30340;&#20256;&#32479;&#23398;&#20064;&#25216;&#26415;&#26080;&#27861;&#35782;&#21035;&#36825;&#26679;&#19968;&#20010;&#19981;&#21464;&#23376;&#32593;&#32476;&#30340;&#23384;&#22312;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#37319;&#21462;&#20102;&#19968;&#20010;&#26681;&#26412;&#19981;&#21516;&#30340;&#20248;&#21270;&#26041;&#26696;&#65292;&#35813;&#26041;&#26696;&#24314;&#31435;&#22312;&#35889;&#34920;&#31034;&#30340;&#22522;&#30784;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
In theoretical ML, the teacher-student paradigm is often employed as an effective metaphor for real-life tuition. The above scheme proves particularly relevant when the student network is overparameterized as compared to the teacher network. Under these operating conditions, it is tempting to speculate that the student ability to handle the given task could be eventually stored in a sub-portion of the whole network. This latter should be to some extent reminiscent of the frozen teacher structure, according to suitable metrics, while being approximately invariant across different architectures of the student candidate network. Unfortunately, state-of-the-art conventional learning techniques could not help in identifying the existence of such an invariant subnetwork, due to the inherent degree of non-convexity that characterizes the examined problem. In this work, we take a leap forward by proposing a radically different optimization scheme which builds on a spectral representation of th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22240;&#26524;&#30456;&#20284;&#24615;&#30340;&#20998;&#23618;&#36125;&#21494;&#26031;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#22914;&#20309;&#20174;&#20855;&#26377;&#30456;&#20284;&#22240;&#26524;&#26426;&#21046;&#30340;&#35757;&#32451;&#20219;&#21153;&#20013;&#27719;&#38598;&#25968;&#25454;&#26469;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#23545;&#26032;&#20219;&#21153;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.12595</link><description>&lt;p&gt;
&#22522;&#20110;&#22240;&#26524;&#30456;&#20284;&#24615;&#30340;&#20998;&#23618;&#36125;&#21494;&#26031;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Causal Similarity-Based Hierarchical Bayesian Models. (arXiv:2310.12595v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12595
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22240;&#26524;&#30456;&#20284;&#24615;&#30340;&#20998;&#23618;&#36125;&#21494;&#26031;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#22914;&#20309;&#20174;&#20855;&#26377;&#30456;&#20284;&#22240;&#26524;&#26426;&#21046;&#30340;&#35757;&#32451;&#20219;&#21153;&#20013;&#27719;&#38598;&#25968;&#25454;&#26469;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#23545;&#26032;&#20219;&#21153;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#30340;&#20851;&#38190;&#25361;&#25112;&#26159;&#23545;&#26032;&#25968;&#25454;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#23545;&#30001;&#30456;&#20851;&#20219;&#21153;&#32452;&#25104;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#27867;&#21270;&#30340;&#38382;&#39064;&#65292;&#36825;&#20123;&#20219;&#21153;&#21487;&#33021;&#22312;&#22240;&#26524;&#26426;&#21046;&#19978;&#23384;&#22312;&#24046;&#24322;&#12290;&#20363;&#22914;&#65292;&#22797;&#26434;&#30142;&#30149;&#30340;&#35266;&#23519;&#24615;&#21307;&#23398;&#25968;&#25454;&#22312;&#19981;&#21516;&#24739;&#32773;&#38388;&#20855;&#26377;&#30142;&#30149;&#22240;&#26524;&#26426;&#21046;&#30340;&#24322;&#36136;&#24615;&#65292;&#36825;&#32473;&#38656;&#35201;&#23545;&#35757;&#32451;&#25968;&#25454;&#38598;&#20043;&#22806;&#30340;&#26032;&#24739;&#32773;&#36827;&#34892;&#27867;&#21270;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#24102;&#26469;&#20102;&#25361;&#25112;&#12290;&#24120;&#29992;&#30340;&#22788;&#29702;&#24322;&#36136;&#24615;&#25968;&#25454;&#38598;&#30340;&#26041;&#27861;&#21253;&#25324;&#20026;&#25972;&#20010;&#25968;&#25454;&#38598;&#23398;&#20064;&#19968;&#20010;&#20840;&#23616;&#27169;&#22411;&#65292;&#20026;&#27599;&#20010;&#20219;&#21153;&#30340;&#25968;&#25454;&#23398;&#20064;&#26412;&#22320;&#27169;&#22411;&#65292;&#25110;&#32773;&#21033;&#29992;&#20998;&#23618;&#12289;&#20803;&#23398;&#20064;&#21644;&#22810;&#20219;&#21153;&#23398;&#20064;&#26041;&#27861;&#20174;&#27719;&#38598;&#30340;&#22810;&#20010;&#20219;&#21153;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#27867;&#21270;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#22240;&#26524;&#30456;&#20284;&#24615;&#30340;&#20998;&#23618;&#36125;&#21494;&#26031;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#22914;&#20309;&#20174;&#20855;&#26377;&#30456;&#20284;&#22240;&#26524;&#26426;&#21046;&#30340;&#35757;&#32451;&#20219;&#21153;&#20013;&#27719;&#38598;&#25968;&#25454;&#26469;&#25552;&#39640;&#23545;&#26032;&#20219;&#21153;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#24212;&#29992;&#36825;&#31181;&#36890;&#29992;&#24314;&#27169;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
The key challenge underlying machine learning is generalisation to new data. This work studies generalisation for datasets consisting of related tasks that may differ in causal mechanisms. For example, observational medical data for complex diseases suffers from heterogeneity in causal mechanisms of disease across patients, creating challenges for machine learning algorithms that need to generalise to new patients outside of the training dataset. Common approaches for learning supervised models with heterogeneous datasets include learning a global model for the entire dataset, learning local models for each tasks' data, or utilising hierarchical, meta-learning and multi-task learning approaches to learn how to generalise from data pooled across multiple tasks. In this paper we propose causal similarity-based hierarchical Bayesian models to improve generalisation to new tasks by learning how to pool data from training tasks with similar causal mechanisms. We apply this general modelling
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36817;&#20284;&#20449;&#24687;&#26368;&#22823;&#21270;&#30340;&#24378;&#30423;&#28216;&#25103;&#31639;&#27861;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#20851;&#38190;&#21464;&#37327;&#30340;&#20449;&#24687;&#36817;&#20284;&#20540;&#26469;&#36827;&#34892;&#20248;&#21270;&#65292;&#22312;&#20256;&#32479;&#24378;&#30423;&#35774;&#32622;&#20013;&#34920;&#29616;&#20986;&#24456;&#24378;&#30340;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#23545;&#20110;&#20004;&#33218;&#24378;&#30423;&#38382;&#39064;&#30340;&#28176;&#36817;&#26368;&#20248;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.12563</link><description>&lt;p&gt;
&#36866;&#29992;&#20110;&#24378;&#30423;&#28216;&#25103;&#30340;&#36817;&#20284;&#20449;&#24687;&#26368;&#22823;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Approximate information maximization for bandit games. (arXiv:2310.12563v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12563
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36817;&#20284;&#20449;&#24687;&#26368;&#22823;&#21270;&#30340;&#24378;&#30423;&#28216;&#25103;&#31639;&#27861;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#20851;&#38190;&#21464;&#37327;&#30340;&#20449;&#24687;&#36817;&#20284;&#20540;&#26469;&#36827;&#34892;&#20248;&#21270;&#65292;&#22312;&#20256;&#32479;&#24378;&#30423;&#35774;&#32622;&#20013;&#34920;&#29616;&#20986;&#24456;&#24378;&#30340;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#23545;&#20110;&#20004;&#33218;&#24378;&#30423;&#38382;&#39064;&#30340;&#28176;&#36817;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29109;&#26368;&#22823;&#21270;&#21644;&#33258;&#30001;&#33021;&#26368;&#23567;&#21270;&#26159;&#29992;&#20110;&#27169;&#25311;&#21508;&#31181;&#29289;&#29702;&#31995;&#32479;&#21160;&#24577;&#30340;&#19968;&#33324;&#29289;&#29702;&#21407;&#29702;&#12290;&#20854;&#20013;&#21253;&#25324;&#20351;&#29992;&#33258;&#30001;&#33021;&#21407;&#29702;&#23545;&#22823;&#33041;&#20869;&#30340;&#20915;&#31574;&#36827;&#34892;&#24314;&#27169;&#65292;&#20351;&#29992;&#20449;&#24687;&#29942;&#39048;&#21407;&#29702;&#23545;&#35775;&#38382;&#38544;&#34255;&#21464;&#37327;&#26102;&#20248;&#21270;&#20934;&#30830;&#24615;&#21644;&#22797;&#26434;&#24615;&#30340;&#26435;&#34913;&#65292;&#20197;&#21450;&#20351;&#29992;&#20449;&#24687;&#26368;&#22823;&#21270;&#36827;&#34892;&#38543;&#26426;&#29615;&#22659;&#23548;&#33322;&#12290;&#22522;&#20110;&#36825;&#19968;&#21407;&#29702;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24378;&#30423;&#31639;&#27861;&#31867;&#21035;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#31995;&#32479;&#20013;&#19968;&#20010;&#20851;&#38190;&#21464;&#37327;&#30340;&#20449;&#24687;&#36817;&#20284;&#26469;&#36827;&#34892;&#20248;&#21270;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22522;&#20110;&#29289;&#29702;&#30340;&#36817;&#20284;&#20998;&#26512;&#29109;&#30340;&#34920;&#31034;&#26041;&#27861;&#65292;&#20197;&#39044;&#27979;&#27599;&#20010;&#21160;&#20316;&#30340;&#20449;&#24687;&#22686;&#30410;&#65292;&#24182;&#36138;&#23146;&#22320;&#36873;&#25321;&#20449;&#24687;&#22686;&#30410;&#26368;&#22823;&#30340;&#21160;&#20316;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#20256;&#32479;&#24378;&#30423;&#35774;&#32622;&#20013;&#34920;&#29616;&#20986;&#24456;&#24378;&#30340;&#24615;&#33021;&#12290;&#21463;&#21040;&#20854;&#32463;&#39564;&#24615;&#25104;&#21151;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20854;&#23545;&#20110;&#20004;&#33218;&#24378;&#30423;&#38382;&#39064;&#30340;&#28176;&#36817;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Entropy maximization and free energy minimization are general physical principles for modeling the dynamics of various physical systems. Notable examples include modeling decision-making within the brain using the free-energy principle, optimizing the accuracy-complexity trade-off when accessing hidden variables with the information bottleneck principle (Tishby et al., 2000), and navigation in random environments using information maximization (Vergassola et al., 2007). Built on this principle, we propose a new class of bandit algorithms that maximize an approximation to the information of a key variable within the system. To this end, we develop an approximated analytical physics-based representation of an entropy to forecast the information gain of each action and greedily choose the one with the largest information gain. This method yields strong performances in classical bandit settings. Motivated by its empirical success, we prove its asymptotic optimality for the two-armed bandit
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#25554;&#20837;/&#21024;&#38500;&#25351;&#26631;&#24863;&#30693;&#30340;&#22522;&#20110;&#35299;&#37322;&#30340;&#20248;&#21270;(ID-ExpO)&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#21487;&#21306;&#20998;&#30340;&#39044;&#27979;&#22120;&#26469;&#25552;&#39640;&#35299;&#37322;&#30340;&#25554;&#20837;&#21644;&#21024;&#38500;&#24471;&#20998;&#65292;&#24182;&#20445;&#25345;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;ID-ExpO&#33021;&#22815;&#20351;&#27969;&#34892;&#30340;&#20107;&#21518;&#35299;&#37322;&#22120;&#20135;&#29983;&#26356;&#24544;&#23454;&#30340;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2310.12553</link><description>&lt;p&gt;
&#21033;&#29992;&#21487;&#21306;&#20998;&#25554;&#20837;/&#21024;&#38500;&#25351;&#26631;&#24863;&#30693;&#27491;&#21017;&#21270;&#36827;&#34892;&#35299;&#37322;&#24615;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Explanation-Based Training with Differentiable Insertion/Deletion Metric-Aware Regularizers. (arXiv:2310.12553v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12553
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#25554;&#20837;/&#21024;&#38500;&#25351;&#26631;&#24863;&#30693;&#30340;&#22522;&#20110;&#35299;&#37322;&#30340;&#20248;&#21270;(ID-ExpO)&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#21487;&#21306;&#20998;&#30340;&#39044;&#27979;&#22120;&#26469;&#25552;&#39640;&#35299;&#37322;&#30340;&#25554;&#20837;&#21644;&#21024;&#38500;&#24471;&#20998;&#65292;&#24182;&#20445;&#25345;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;ID-ExpO&#33021;&#22815;&#20351;&#27969;&#34892;&#30340;&#20107;&#21518;&#35299;&#37322;&#22120;&#20135;&#29983;&#26356;&#24544;&#23454;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22797;&#26434;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#22120;&#30340;&#35299;&#37322;&#36136;&#37327;&#36890;&#24120;&#20351;&#29992;&#25554;&#20837;&#21644;&#21024;&#38500;&#25351;&#26631;&#36827;&#34892;&#34913;&#37327;&#65292;&#36825;&#20123;&#25351;&#26631;&#35780;&#20272;&#35299;&#37322;&#30340;&#24544;&#23454;&#24230;&#65292;&#21363;&#35299;&#37322;&#27491;&#30830;&#22320;&#21453;&#26144;&#20102;&#39044;&#27979;&#22120;&#30340;&#34892;&#20026;&#31243;&#24230;&#12290;&#20026;&#20102;&#25552;&#39640;&#24544;&#23454;&#24230;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#25554;&#20837;/&#21024;&#38500;&#25351;&#26631;&#24863;&#30693;&#30340;&#22522;&#20110;&#35299;&#37322;&#30340;&#20248;&#21270;&#65288;ID-ExpO&#65289;&#65292;&#35813;&#20248;&#21270;&#33021;&#22815;&#25913;&#21892;&#35299;&#37322;&#30340;&#25554;&#20837;&#21644;&#21024;&#38500;&#24471;&#20998;&#65292;&#21516;&#26102;&#20445;&#25345;&#20854;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#30001;&#20110;&#21407;&#22987;&#30340;&#25554;&#20837;&#21644;&#21024;&#38500;&#25351;&#26631;&#23545;&#20110;&#35299;&#37322;&#26469;&#35828;&#26159;&#19981;&#21487;&#21306;&#20998;&#30340;&#65292;&#24182;&#19988;&#26080;&#27861;&#30452;&#25509;&#36827;&#34892;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#36825;&#20123;&#25351;&#26631;&#20197;&#20351;&#20854;&#21487;&#21306;&#20998;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#24418;&#24335;&#21270;&#25554;&#20837;&#21644;&#21024;&#38500;&#25351;&#26631;&#30340;&#27491;&#21017;&#21270;&#12290;&#22312;&#22270;&#20687;&#21644;&#34920;&#26684;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;ID-ExpO&#36827;&#34892;&#24494;&#35843;&#30340;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#39044;&#27979;&#22120;&#33021;&#22815;&#20351;&#27969;&#34892;&#30340;&#20107;&#21518;&#35299;&#37322;&#22120;&#20135;&#29983;&#26356;&#24544;&#23454;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
The quality of explanations for the predictions of complex machine learning predictors is often measured using insertion and deletion metrics, which assess the faithfulness of the explanations, i.e., how correctly the explanations reflect the predictor's behavior. To improve the faithfulness, we propose insertion/deletion metric-aware explanation-based optimization (ID-ExpO), which optimizes differentiable predictors to improve both insertion and deletion scores of the explanations while keeping their predictive accuracy. Since the original insertion and deletion metrics are indifferentiable with respect to the explanations and directly unavailable for gradient-based optimization, we extend the metrics to be differentiable and use them to formalize insertion and deletion metric-based regularizers. The experimental results on image and tabular datasets show that the deep neural networks-based predictors fine-tuned using ID-ExpO enable popular post-hoc explainers to produce more faithful
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26500;&#24314;&#20102;&#25972;&#25968;&#20540;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#31070;&#32463;&#20284;&#28982;&#36817;&#20284;&#26041;&#27861;&#65292;&#20351;&#29992;&#22240;&#26524;&#21367;&#31215;&#24182;&#34892;&#35780;&#20272;&#25972;&#20010;&#26102;&#38388;&#24207;&#21015;&#30340;&#20284;&#28982;&#65292;&#23454;&#29616;&#20102;&#23545;&#29983;&#24577;&#23398;&#21644;&#27969;&#34892;&#30149;&#23398;&#27169;&#22411;&#36827;&#34892;&#20934;&#30830;&#25512;&#26029;&#24182;&#26174;&#33879;&#21152;&#24555;&#35745;&#31639;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.12544</link><description>&lt;p&gt;
&#25972;&#25968;&#20540;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#31070;&#32463;&#20284;&#28982;&#36817;&#20284;
&lt;/p&gt;
&lt;p&gt;
Neural Likelihood Approximation for Integer Valued Time Series Data. (arXiv:2310.12544v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12544
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26500;&#24314;&#20102;&#25972;&#25968;&#20540;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#31070;&#32463;&#20284;&#28982;&#36817;&#20284;&#26041;&#27861;&#65292;&#20351;&#29992;&#22240;&#26524;&#21367;&#31215;&#24182;&#34892;&#35780;&#20272;&#25972;&#20010;&#26102;&#38388;&#24207;&#21015;&#30340;&#20284;&#28982;&#65292;&#23454;&#29616;&#20102;&#23545;&#29983;&#24577;&#23398;&#21644;&#27969;&#34892;&#30149;&#23398;&#27169;&#22411;&#36827;&#34892;&#20934;&#30830;&#25512;&#26029;&#24182;&#26174;&#33879;&#21152;&#24555;&#35745;&#31639;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29289;&#29702;&#21644;&#29983;&#29289;&#31185;&#23398;&#20013;&#65292;&#23450;&#20041;&#22312;&#25972;&#25968;&#20540;&#29366;&#24577;&#31354;&#38388;&#19978;&#30340;&#38543;&#26426;&#36807;&#31243;&#24456;&#24120;&#35265;&#12290;&#36825;&#20123;&#27169;&#22411;&#29992;&#20110;&#25429;&#25417;&#23567;&#31995;&#32479;&#30340;&#21160;&#21147;&#23398;&#65292;&#20854;&#20013;&#20010;&#20307;&#32676;&#20307;&#30340;&#20010;&#20307;&#23646;&#24615;&#19981;&#33021;&#34987;&#24573;&#35270;&#65292;&#38543;&#26426;&#25928;&#24212;&#24456;&#37325;&#35201;&#12290;&#30001;&#20110;&#20284;&#28982;&#30340;&#22797;&#26434;&#24615;&#65292;&#20174;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#25512;&#26029;&#36825;&#20123;&#27169;&#22411;&#30340;&#21442;&#25968;&#26159;&#22256;&#38590;&#30340;&#65307;&#30446;&#21069;&#30340;&#26041;&#27861;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;&#27169;&#25311;&#65292;&#35745;&#31639;&#25104;&#26412;&#38750;&#24120;&#39640;&#26114;&#65292;&#20197;&#33267;&#20110;&#38590;&#20197;&#23454;&#29616;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#22240;&#26524;&#21367;&#31215;&#26500;&#24314;&#20102;&#29992;&#20110;&#25972;&#25968;&#20540;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#31070;&#32463;&#20284;&#28982;&#36817;&#20284;&#26041;&#27861;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#24182;&#34892;&#35780;&#20272;&#25972;&#20010;&#26102;&#38388;&#24207;&#21015;&#30340;&#20284;&#28982;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#19968;&#20123;&#29983;&#24577;&#23398;&#21644;&#27969;&#34892;&#30149;&#23398;&#27169;&#22411;&#36827;&#34892;&#25512;&#26029;&#26469;&#28436;&#31034;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#32467;&#26524;&#26174;&#31034;&#25105;&#20204;&#33021;&#22815;&#20934;&#30830;&#22320;&#36817;&#20284;&#30495;&#23454;&#30340;&#21518;&#39564;&#27010;&#29575;&#65292;&#21516;&#26102;&#22312;&#24403;&#21069;&#26041;&#27861;&#21463;&#38480;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#26174;&#33879;&#30340;&#35745;&#31639;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic processes defined on integer valued state spaces are popular within the physical and biological sciences. These models are necessary for capturing the dynamics of small systems where the individual nature of the populations cannot be ignored and stochastic effects are important. The inference of the parameters of such models, from time series data, is difficult due to intractability of the likelihood; current methods, based on simulations of the underlying model, can be so computationally expensive as to be prohibitive. In this paper we construct a neural likelihood approximation for integer valued time series data using causal convolutions, which allows us to evaluate the likelihood of the whole time series in parallel. We demonstrate our method by performing inference on a number of ecological and epidemiological models, showing that we can accurately approximate the true posterior while achieving significant computational speed ups in situations where current methods stru
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27880;&#24847;&#21147;&#26435;&#37325;&#21644;&#36755;&#20986;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#29992;&#20110;&#24674;&#22797;Transformer&#27169;&#22411;&#20013;&#30340;&#36755;&#20837;&#25968;&#25454;&#12290;&#30740;&#31350;&#32467;&#26524;&#26263;&#31034;&#27169;&#22411;&#35774;&#35745;&#23384;&#22312;&#28508;&#22312;&#30340;&#28431;&#27934;&#12290;</title><link>http://arxiv.org/abs/2310.12462</link><description>&lt;p&gt;
&#25581;&#31034;Transformer&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65306;&#22522;&#20110;&#27880;&#24847;&#21147;&#26435;&#37325;&#30340;&#25968;&#25454;&#24674;&#22797;&#30340;&#29702;&#35770;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Unmasking Transformers: A Theoretical Approach to Data Recovery via Attention Weights. (arXiv:2310.12462v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12462
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27880;&#24847;&#21147;&#26435;&#37325;&#21644;&#36755;&#20986;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#29992;&#20110;&#24674;&#22797;Transformer&#27169;&#22411;&#20013;&#30340;&#36755;&#20837;&#25968;&#25454;&#12290;&#30740;&#31350;&#32467;&#26524;&#26263;&#31034;&#27169;&#22411;&#35774;&#35745;&#23384;&#22312;&#28508;&#22312;&#30340;&#28431;&#27934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28145;&#24230;&#23398;&#20064;&#39046;&#22495;&#20013;&#65292;Transformer&#24050;&#32463;&#25104;&#20026;&#20102;&#19968;&#31181;&#20027;&#23548;&#30340;&#26550;&#26500;&#65292;&#29305;&#21035;&#26159;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#23427;&#20204;&#30340;&#24191;&#27867;&#24212;&#29992;&#65292;&#26377;&#20851;&#36825;&#20123;&#27169;&#22411;&#22788;&#29702;&#25968;&#25454;&#30340;&#23433;&#20840;&#24615;&#21644;&#38544;&#31169;&#24615;&#30340;&#38382;&#39064;&#24050;&#32463;&#24341;&#36215;&#20102;&#20851;&#27880;&#12290;&#26412;&#25991;&#38024;&#23545;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#36827;&#34892;&#20102;&#30740;&#31350;&#65306;&#26159;&#21542;&#21487;&#20197;&#20351;&#29992;Transformer&#30340;&#27880;&#24847;&#21147;&#26435;&#37325;&#21644;&#36755;&#20986;&#26469;&#24674;&#22797;&#36755;&#20837;&#25968;&#25454;&#65311;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#26088;&#22312;&#36890;&#36807;&#26368;&#23567;&#21270;&#25439;&#22833;&#20989;&#25968;$L(X)$&#20174;&#32473;&#23450;&#30340;&#27880;&#24847;&#21147;&#26435;&#37325;$W = QK^\top$&#21644;&#36755;&#20986;$B$&#20013;&#24674;&#22797;&#36755;&#20837;&#25968;&#25454;$X$&#65292;&#20854;&#20013;$X \in \mathbb{R}^{d \times n}$&#65292;$W \in \mathbb{R}^{d \times d}$&#65292;$B \in \mathbb{R}^{n \times n}$&#12290;&#36825;&#20010;&#25439;&#22833;&#20989;&#25968;&#25429;&#25417;&#20102;&#39044;&#26399;&#36755;&#20986;&#19982;&#23454;&#38469;&#36755;&#20986;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#23545;&#20110;&#23616;&#37096;&#21270;&#20998;&#23618;&#26426;&#21046;&#65288;Localized Layer-wise Mechanism&#65292;LLM&#65289;&#20855;&#26377;&#37325;&#35201;&#30340;&#24433;&#21709;&#65292;&#34920;&#26126;&#27169;&#22411;&#35774;&#35745;&#23384;&#22312;&#28508;&#22312;&#30340;&#28431;&#27934;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the realm of deep learning, transformers have emerged as a dominant architecture, particularly in natural language processing tasks. However, with their widespread adoption, concerns regarding the security and privacy of the data processed by these models have arisen. In this paper, we address a pivotal question: Can the data fed into transformers be recovered using their attention weights and outputs? We introduce a theoretical framework to tackle this problem. Specifically, we present an algorithm that aims to recover the input data $X \in \mathbb{R}^{d \times n}$ from given attention weights $W = QK^\top \in \mathbb{R}^{d \times d}$ and output $B \in \mathbb{R}^{n \times n}$ by minimizing the loss function $L(X)$. This loss function captures the discrepancy between the expected output and the actual output of the transformer. Our findings have significant implications for the Localized Layer-wise Mechanism (LLM), suggesting potential vulnerabilities in the model's design from a s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#20248;&#20256;&#36755;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#38750;&#21442;&#25968;&#21270;&#30340;&#20998;&#24067;&#32422;&#26463;&#26435;&#37325;&#65292;&#24182;&#21033;&#29992;&#26368;&#22823;&#29109;&#21407;&#29702;&#21644;&#26368;&#20248;&#20256;&#36755;&#24037;&#20855;&#35774;&#35745;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#20197;&#23454;&#29616;&#23545;&#35266;&#27979;&#25968;&#25454;&#30340;&#26368;&#20248;&#26435;&#37325;&#35843;&#25972;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#19981;&#21516;&#30340;&#24212;&#29992;&#22330;&#26223;&#20013;&#23637;&#29616;&#20102;&#28789;&#27963;&#24615;&#21644;&#22810;&#21151;&#33021;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.12447</link><description>&lt;p&gt;
&#32422;&#26463;&#37325;&#21152;&#26435;&#20998;&#24067;&#65306;&#19968;&#31181;&#26368;&#20248;&#20256;&#36755;&#26041;&#27861;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Constrained Reweighting of Distributions: an Optimal Transport Approach. (arXiv:2310.12447v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12447
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#20248;&#20256;&#36755;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#38750;&#21442;&#25968;&#21270;&#30340;&#20998;&#24067;&#32422;&#26463;&#26435;&#37325;&#65292;&#24182;&#21033;&#29992;&#26368;&#22823;&#29109;&#21407;&#29702;&#21644;&#26368;&#20248;&#20256;&#36755;&#24037;&#20855;&#35774;&#35745;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#20197;&#23454;&#29616;&#23545;&#35266;&#27979;&#25968;&#25454;&#30340;&#26368;&#20248;&#26435;&#37325;&#35843;&#25972;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#19981;&#21516;&#30340;&#24212;&#29992;&#22330;&#26223;&#20013;&#23637;&#29616;&#20102;&#28789;&#27963;&#24615;&#21644;&#22810;&#21151;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32463;&#24120;&#36935;&#21040;&#30340;&#38382;&#39064;&#26159;&#35201;&#35782;&#21035;&#20986;&#31526;&#21512;&#39044;&#23450;&#20041;&#30340;&#26435;&#37325;&#32422;&#26463;&#26465;&#20214;&#30340;&#35266;&#27979;&#25968;&#25454;&#30340;&#32463;&#39564;&#20998;&#24067;&#30340;&#26368;&#20248;&#35843;&#25972;&#29256;&#26412;&#12290;&#36825;&#20123;&#32422;&#26463;&#36890;&#24120;&#34920;&#29616;&#20026;&#23545;&#26435;&#37325;&#30340;&#30697;&#12289;&#23614;&#37096;&#34892;&#20026;&#12289;&#24418;&#29366;&#12289;&#27169;&#24335;&#25968;&#37327;&#31561;&#30340;&#38480;&#21046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#38750;&#21442;&#25968;&#21270;&#30340;&#20998;&#24067;&#32422;&#26463;&#26435;&#37325;&#24182;&#21033;&#29992;&#26368;&#22823;&#29109;&#21407;&#29702;&#21644;&#26368;&#20248;&#20256;&#36755;&#24037;&#20855;&#24320;&#21457;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#20174;&#32780;&#22823;&#22823;&#25552;&#39640;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#28789;&#27963;&#24615;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#30830;&#20445;&#35266;&#27979;&#25968;&#25454;&#30340;&#26368;&#22823;&#29109;&#26435;&#37325;&#35843;&#25972;&#32463;&#39564;&#20998;&#24067;&#19982;&#39044;&#23450;&#30340;&#27010;&#29575;&#20998;&#24067;&#22312;&#26368;&#20248;&#20256;&#36755;&#24230;&#37327;&#19979;&#25509;&#36817;&#65292;&#24182;&#20801;&#35768;&#32454;&#24494;&#30340;&#20559;&#24046;&#12290;&#35813;&#26694;&#26550;&#30340;&#22810;&#21151;&#33021;&#24615;&#22312;&#19977;&#20010;&#19981;&#21516;&#30340;&#24212;&#29992;&#22330;&#26223;&#20013;&#24471;&#21040;&#20102;&#35777;&#26126;&#65292;&#20854;&#20013;&#25968;&#25454;&#37325;&#21152;&#26435;&#26159;&#21512;&#29702;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We commonly encounter the problem of identifying an optimally weight adjusted version of the empirical distribution of observed data, adhering to predefined constraints on the weights. Such constraints often manifest as restrictions on the moments, tail behaviour, shapes, number of modes, etc., of the resulting weight adjusted empirical distribution. In this article, we substantially enhance the flexibility of such methodology by introducing a nonparametrically imbued distributional constraints on the weights, and developing a general framework leveraging the maximum entropy principle and tools from optimal transport. The key idea is to ensure that the maximum entropy weight adjusted empirical distribution of the observed data is close to a pre-specified probability distribution in terms of the optimal transport metric while allowing for subtle departures. The versatility of the framework is demonstrated in the context of three disparate applications where data re-weighting is warrante
&lt;/p&gt;</description></item><item><title>&#23545;&#20110;$p$-&#33539;&#25968;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#19978;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#21487;&#23454;&#29616;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;$O(d)$&#20010;&#26679;&#26412;&#23601;&#36275;&#22815;&#31934;&#30830;&#22320;&#24674;&#22797;&#30446;&#26631;&#20540;&#65292;&#24182;&#19988;&#22312;&#20854;&#20182;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#30340;&#39640;&#27010;&#29575;&#36229;&#20986;&#39118;&#38505;&#30028;&#12290;</title><link>http://arxiv.org/abs/2310.12437</link><description>&lt;p&gt;
&#22312;$p$-&#33539;&#25968;&#32447;&#24615;&#22238;&#24402;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#20013;&#30340;&#26368;&#20248;&#36229;&#20986;&#39118;&#38505;&#30028;
&lt;/p&gt;
&lt;p&gt;
Optimal Excess Risk Bounds for Empirical Risk Minimization on $p$-norm Linear Regression. (arXiv:2310.12437v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12437
&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;$p$-&#33539;&#25968;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#19978;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#21487;&#23454;&#29616;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;$O(d)$&#20010;&#26679;&#26412;&#23601;&#36275;&#22815;&#31934;&#30830;&#22320;&#24674;&#22797;&#30446;&#26631;&#20540;&#65292;&#24182;&#19988;&#22312;&#20854;&#20182;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#30340;&#39640;&#27010;&#29575;&#36229;&#20986;&#39118;&#38505;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;$p$-&#33539;&#25968;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#19978;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#21487;&#23454;&#29616;&#30340;&#24773;&#20917;&#19979;&#65292;&#22312;&#27809;&#26377;&#30697;&#30340;&#20551;&#35774;&#19979;&#65292;&#36890;&#36807;$O(d)$&#20010;&#26679;&#26412;&#23601;&#36275;&#22815;&#31934;&#30830;&#22320;&#24674;&#22797;&#30446;&#26631;&#20540;&#65292;&#30456;&#24212;&#24615;&#21270;&#24120;&#25968;&#26377;&#20851;&#12290;&#21542;&#21017;&#65292;&#23545;&#20110;$p \in [2, \infty)$&#24182;&#19988;&#23545;&#30446;&#26631;&#21644;&#21327;&#21464;&#37327;&#20855;&#26377;&#36739;&#24369;&#30340;&#30697;&#20551;&#35774;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#39640;&#27010;&#29575;&#36229;&#20986;&#39118;&#38505;&#30028;&#65292;&#20854;&#20013;&#20027;&#35201;&#39033;&#19982;&#28176;&#36817;&#31934;&#30830;&#29575;&#21305;&#37197;&#65292;&#24120;&#25968;&#20165;&#20381;&#36182;&#20110;$p$&#12290;&#22312;&#20445;&#35777;&#39118;&#38505;&#20989;&#25968;&#22312;&#20854;&#26368;&#23567;&#21270;&#28857;&#19978;&#23384;&#22312;Hessian&#30697;&#38453;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23558;&#27492;&#32467;&#26524;&#25193;&#23637;&#21040;$p \in (1, 2)$&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the performance of empirical risk minimization on the $p$-norm linear regression problem for $p \in (1, \infty)$. We show that, in the realizable case, under no moment assumptions, and up to a distribution-dependent constant, $O(d)$ samples are enough to exactly recover the target. Otherwise, for $p \in [2, \infty)$, and under weak moment assumptions on the target and the covariates, we prove a high probability excess risk bound on the empirical risk minimizer whose leading term matches, up to a constant that depends only on $p$, the asymptotically exact rate. We extend this result to the case $p \in (1, 2)$ under mild assumptions that guarantee the existence of the Hessian of the risk at its minimizer.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#38543;&#26426;&#26862;&#26519;&#27169;&#22411;&#30340;&#29305;&#24449;&#31354;&#38388;&#20013;&#30340;&#37051;&#36817;&#24615;&#26469;&#35299;&#37322;&#27169;&#22411;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#20026;&#27169;&#22411;&#39044;&#27979;&#25552;&#20379;&#20102;&#23616;&#37096;&#30340;&#35299;&#37322;&#24615;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#36741;&#30456;&#25104;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#22312;&#20538;&#21048;&#23450;&#20215;&#27169;&#22411;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.12428</link><description>&lt;p&gt;
&#23454;&#29616;&#38543;&#26426;&#26862;&#26519;&#30340;&#23616;&#37096;&#21487;&#35299;&#37322;&#24615;&#22686;&#24378;&#65306;&#22522;&#20110;&#37051;&#36817;&#24615;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Towards Enhanced Local Explainability of Random Forests: a Proximity-Based Approach. (arXiv:2310.12428v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12428
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#38543;&#26426;&#26862;&#26519;&#27169;&#22411;&#30340;&#29305;&#24449;&#31354;&#38388;&#20013;&#30340;&#37051;&#36817;&#24615;&#26469;&#35299;&#37322;&#27169;&#22411;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#20026;&#27169;&#22411;&#39044;&#27979;&#25552;&#20379;&#20102;&#23616;&#37096;&#30340;&#35299;&#37322;&#24615;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#36741;&#30456;&#25104;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#22312;&#20538;&#21048;&#23450;&#20215;&#27169;&#22411;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#35299;&#37322;&#38543;&#26426;&#26862;&#26519;&#65288;RF&#65289;&#27169;&#22411;&#30340;&#26679;&#26412;&#22806;&#24615;&#33021;&#65292;&#21033;&#29992;&#20102;&#20219;&#20309;RF&#37117;&#21487;&#20197;&#34987;&#34920;&#36848;&#20026;&#33258;&#36866;&#24212;&#21152;&#26435;K&#26368;&#36817;&#37051;&#65288;KNN&#65289;&#27169;&#22411;&#30340;&#20107;&#23454;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#21033;&#29992;RF&#22312;&#29305;&#24449;&#31354;&#38388;&#20013;&#23398;&#21040;&#30340;&#28857;&#20043;&#38388;&#30340;&#37051;&#36817;&#24615;&#65292;&#23558;&#38543;&#26426;&#26862;&#26519;&#30340;&#39044;&#27979;&#37325;&#20889;&#20026;&#35757;&#32451;&#25968;&#25454;&#28857;&#30446;&#26631;&#26631;&#31614;&#30340;&#21152;&#26435;&#24179;&#22343;&#20540;&#12290;&#36825;&#31181;&#32447;&#24615;&#24615;&#36136;&#26377;&#21161;&#20110;&#22312;&#35757;&#32451;&#38598;&#35266;&#27979;&#20013;&#20026;&#20219;&#20309;&#27169;&#22411;&#39044;&#27979;&#29983;&#25104;&#23646;&#24615;&#65292;&#20174;&#32780;&#20026;RF&#39044;&#27979;&#25552;&#20379;&#20102;&#23616;&#37096;&#30340;&#35299;&#37322;&#24615;&#65292;&#34917;&#20805;&#20102;SHAP&#31561;&#24050;&#26377;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#21017;&#20026;&#29305;&#24449;&#31354;&#38388;&#32500;&#24230;&#19978;&#30340;&#27169;&#22411;&#39044;&#27979;&#29983;&#25104;&#23646;&#24615;&#12290;&#25105;&#20204;&#22312;&#35757;&#32451;&#20110;&#32654;&#22269;&#20844;&#21496;&#20538;&#21048;&#20132;&#26131;&#25968;&#25454;&#30340;&#20538;&#21048;&#23450;&#20215;&#27169;&#22411;&#20013;&#28436;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#65292;&#24182;&#23558;&#20854;&#19982;&#21508;&#31181;&#29616;&#26377;&#30340;&#27169;&#22411;&#35299;&#37322;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
We initiate a novel approach to explain the out of sample performance of random forest (RF) models by exploiting the fact that any RF can be formulated as an adaptive weighted K nearest-neighbors model. Specifically, we use the proximity between points in the feature space learned by the RF to re-write random forest predictions exactly as a weighted average of the target labels of training data points. This linearity facilitates a local notion of explainability of RF predictions that generates attributions for any model prediction across observations in the training set, and thereby complements established methods like SHAP, which instead generates attributions for a model prediction across dimensions of the feature space. We demonstrate this approach in the context of a bond pricing model trained on US corporate bond trades, and compare our approach to various existing approaches to model explainability.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38381;&#24335;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#26174;&#24335;&#24179;&#28369;&#30340;&#38381;&#24335;&#24471;&#20998;&#20989;&#25968;&#26469;&#29983;&#25104;&#26032;&#26679;&#26412;&#65292;&#26080;&#38656;&#35757;&#32451;&#65292;&#19988;&#22312;&#28040;&#36153;&#32423;CPU&#19978;&#33021;&#22815;&#23454;&#29616;&#19982;&#31070;&#32463;SGMs&#30456;&#31454;&#20105;&#30340;&#37319;&#26679;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.12395</link><description>&lt;p&gt;
&#38381;&#24335;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Closed-Form Diffusion Models. (arXiv:2310.12395v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12395
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38381;&#24335;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#26174;&#24335;&#24179;&#28369;&#30340;&#38381;&#24335;&#24471;&#20998;&#20989;&#25968;&#26469;&#29983;&#25104;&#26032;&#26679;&#26412;&#65292;&#26080;&#38656;&#35757;&#32451;&#65292;&#19988;&#22312;&#28040;&#36153;&#32423;CPU&#19978;&#33021;&#22815;&#23454;&#29616;&#19982;&#31070;&#32463;SGMs&#30456;&#31454;&#20105;&#30340;&#37319;&#26679;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;(SGMs)&#36890;&#36807;&#36845;&#20195;&#22320;&#20351;&#29992;&#25200;&#21160;&#30446;&#26631;&#20989;&#25968;&#30340;&#24471;&#20998;&#20989;&#25968;&#26469;&#20174;&#30446;&#26631;&#20998;&#24067;&#20013;&#37319;&#26679;&#12290;&#23545;&#20110;&#20219;&#20309;&#26377;&#38480;&#30340;&#35757;&#32451;&#38598;&#65292;&#21487;&#20197;&#38381;&#24335;&#22320;&#35780;&#20272;&#36825;&#20010;&#24471;&#20998;&#20989;&#25968;&#65292;&#20294;&#30001;&#27492;&#24471;&#21040;&#30340;SGMs&#20250;&#35760;&#24518;&#20854;&#35757;&#32451;&#25968;&#25454;&#65292;&#19981;&#33021;&#29983;&#25104;&#26032;&#26679;&#26412;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#21487;&#20197;&#36890;&#36807;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26469;&#36817;&#20284;&#24471;&#20998;&#20989;&#25968;&#65292;&#20294;&#36825;&#31181;&#36817;&#20284;&#30340;&#35823;&#24046;&#26377;&#21161;&#20110;&#25512;&#24191;&#65292;&#28982;&#32780;&#31070;&#32463;SGMs&#30340;&#35757;&#32451;&#21644;&#37319;&#26679;&#20195;&#20215;&#39640;&#65292;&#32780;&#19988;&#23545;&#20110;&#36825;&#31181;&#35823;&#24046;&#25552;&#20379;&#30340;&#26377;&#25928;&#27491;&#21017;&#21270;&#26041;&#27861;&#22312;&#29702;&#35770;&#19978;&#23578;&#19981;&#28165;&#26970;&#12290;&#22240;&#27492;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#26174;&#24335;&#24179;&#28369;&#30340;&#38381;&#24335;&#24471;&#20998;&#26469;&#33719;&#24471;&#19968;&#20010;&#29983;&#25104;&#26032;&#26679;&#26412;&#30340;SGMs&#65292;&#32780;&#26080;&#38656;&#35757;&#32451;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#26368;&#36817;&#37051;&#30340;&#39640;&#25928;&#24471;&#20998;&#20989;&#25968;&#20272;&#35745;&#22120;&#12290;&#21033;&#29992;&#36825;&#20010;&#20272;&#35745;&#22120;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#28040;&#36153;&#32423;CPU&#19978;&#36816;&#34892;&#26102;&#33021;&#22815;&#36798;&#21040;&#19982;&#31070;&#32463;SGMs&#30456;&#31454;&#20105;&#30340;&#37319;&#26679;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based generative models (SGMs) sample from a target distribution by iteratively transforming noise using the score function of the perturbed target. For any finite training set, this score function can be evaluated in closed form, but the resulting SGM memorizes its training data and does not generate novel samples. In practice, one approximates the score by training a neural network via score-matching. The error in this approximation promotes generalization, but neural SGMs are costly to train and sample, and the effective regularization this error provides is not well-understood theoretically. In this work, we instead explicitly smooth the closed-form score to obtain an SGM that generates novel samples without training. We analyze our model and propose an efficient nearest-neighbor-based estimator of its score function. Using this estimator, our method achieves sampling times competitive with neural SGMs while running on consumer-grade CPUs.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#20351;&#29992;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#36827;&#34892;&#24494;&#35843;&#30340;&#26041;&#27861;&#65292;&#20197;&#26356;&#22909;&#22320;&#19982;&#21270;&#23398;&#23478;&#30340;&#20559;&#22909;&#23545;&#40784;&#29983;&#25104;&#30340;&#20998;&#23376;&#12290;&#36825;&#31181;&#26041;&#27861;&#31616;&#21333;&#12289;&#39640;&#25928;&#65292;&#19988;&#38750;&#24120;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2310.12304</link><description>&lt;p&gt;
&#20998;&#23376;&#35821;&#35328;&#27169;&#22411;&#30340;&#20559;&#22909;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Preference Optimization for Molecular Language Models. (arXiv:2310.12304v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12304
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#20351;&#29992;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#36827;&#34892;&#24494;&#35843;&#30340;&#26041;&#27861;&#65292;&#20197;&#26356;&#22909;&#22320;&#19982;&#21270;&#23398;&#23478;&#30340;&#20559;&#22909;&#23545;&#40784;&#29983;&#25104;&#30340;&#20998;&#23376;&#12290;&#36825;&#31181;&#26041;&#27861;&#31616;&#21333;&#12289;&#39640;&#25928;&#65292;&#19988;&#38750;&#24120;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#23376;&#35821;&#35328;&#24314;&#27169;&#26159;&#19968;&#31181;&#29983;&#25104;&#26032;&#39062;&#21270;&#23398;&#32467;&#26500;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#19981;&#20250;\emph{&#20808;&#39564;&#22320;}&#32534;&#30721;&#21270;&#23398;&#23478;&#21487;&#33021;&#26399;&#26395;&#30340;&#26576;&#20123;&#20559;&#22909;&#12290;&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#20351;&#29992;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#36827;&#34892;&#24494;&#35843;&#30340;&#26041;&#27861;&#65292;&#20197;&#26356;&#22909;&#22320;&#19982;&#21270;&#23398;&#23478;&#30340;&#20559;&#22909;&#23545;&#40784;&#29983;&#25104;&#30340;&#20998;&#23376;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#34920;&#26126;&#65292;&#36825;&#31181;&#26041;&#27861;&#31616;&#21333;&#12289;&#39640;&#25928;&#65292;&#19988;&#38750;&#24120;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
Molecular language modeling is an effective approach to generating novel chemical structures. However, these models do not \emph{a priori} encode certain preferences a chemist may desire. We investigate the use of fine-tuning using Direct Preference Optimization to better align generated molecules with chemist preferences. Our findings suggest that this approach is simple, efficient, and highly effective.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#32500;&#32447;&#24615;&#28151;&#21512;&#27169;&#22411;&#30340;&#20998;&#21306;&#32463;&#39564;Bayes ECM&#31639;&#27861;&#65292;&#20855;&#26377;&#24555;&#36895;&#21487;&#25193;&#23637;&#30340;&#35745;&#31639;&#33021;&#21147;&#21644;&#26356;&#39640;&#30340;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.12285</link><description>&lt;p&gt;
&#31232;&#30095;&#39640;&#32500;&#32447;&#24615;&#28151;&#21512;&#27169;&#22411;&#30340;&#20998;&#21306;&#32463;&#39564;Bayes ECM&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sparse high-dimensional linear mixed modeling with a partitioned empirical Bayes ECM algorithm. (arXiv:2310.12285v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12285
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#32500;&#32447;&#24615;&#28151;&#21512;&#27169;&#22411;&#30340;&#20998;&#21306;&#32463;&#39564;Bayes ECM&#31639;&#27861;&#65292;&#20855;&#26377;&#24555;&#36895;&#21487;&#25193;&#23637;&#30340;&#35745;&#31639;&#33021;&#21147;&#21644;&#26356;&#39640;&#30340;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#32437;&#21521;&#25968;&#25454;&#22312;&#21508;&#31181;&#31185;&#23398;&#30740;&#31350;&#20013;&#30340;&#24212;&#29992;&#26085;&#30410;&#22686;&#22810;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#39640;&#32500;&#32447;&#24615;&#28151;&#21512;&#27169;&#22411;(LMMs)&#65292;&#30446;&#21069;&#21482;&#26377;&#23569;&#25968;&#32479;&#35745;&#26041;&#27861;&#21487;&#29992;&#65292;&#22240;&#20026;&#22823;&#22810;&#25968;&#36125;&#21494;&#26031;&#21464;&#37327;&#36873;&#25321;&#25110;&#32602;&#20989;&#25968;&#26041;&#27861;&#26159;&#38024;&#23545;&#29420;&#31435;&#35266;&#27979;&#35774;&#35745;&#30340;&#12290;&#27492;&#22806;&#65292;&#30446;&#21069;&#23569;&#25968;&#21487;&#29992;&#30340;&#39640;&#32500;LMMs&#36719;&#20214;&#21253;&#23384;&#22312;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#20934;&#30830;&#30340;&#39640;&#32500;LMMs&#36125;&#21494;&#26031;&#26694;&#26550;&#12290;&#25105;&#20204;&#20351;&#29992;&#32463;&#39564;Bayes&#20272;&#35745;&#22120;&#30340;&#36229;&#21442;&#25968;&#26469;&#22686;&#21152;&#28789;&#27963;&#24615;&#65292;&#24182;&#20351;&#29992;Expectation-Conditional-Minimization (ECM)&#31639;&#27861;&#26469;&#35745;&#31639;&#21442;&#25968;&#30340;&#26368;&#22823;&#21518;&#39564;&#27010;&#29575;(MAP)&#20272;&#35745;&#65292;&#20174;&#32780;&#23454;&#29616;&#39640;&#25928;&#30340;&#35745;&#31639;&#12290;&#36825;&#31181;&#26041;&#27861;&#30340;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#20854;&#20998;&#21306;&#21644;&#21442;&#25968;&#25193;&#23637;&#65292;&#20197;&#21450;&#20854;&#24555;&#36895;&#21644;&#21487;&#25193;&#23637;&#30340;&#35745;&#31639;&#12290;&#25105;&#20204;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#20013;&#30340;&#22266;&#23450;&#25928;&#24212;&#21644;&#38543;&#26426;&#25928;&#24212;&#20272;&#35745;&#23637;&#31034;&#20102;&#32447;&#24615;&#28151;&#21512;&#27169;&#22411;&#32467;&#21512;&#20998;&#21306;&#32463;&#39564;Bayes ECM (LMM-PROBE)&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
High-dimensional longitudinal data is increasingly used in a wide range of scientific studies. However, there are few statistical methods for high-dimensional linear mixed models (LMMs), as most Bayesian variable selection or penalization methods are designed for independent observations. Additionally, the few available software packages for high-dimensional LMMs suffer from scalability issues. This work presents an efficient and accurate Bayesian framework for high-dimensional LMMs. We use empirical Bayes estimators of hyperparameters for increased flexibility and an Expectation-Conditional-Minimization (ECM) algorithm for computationally efficient maximum a posteriori probability (MAP) estimation of parameters. The novelty of the approach lies in its partitioning and parameter expansion as well as its fast and scalable computation. We illustrate Linear Mixed Modeling with PaRtitiOned empirical Bayes ECM (LMM-PROBE) in simulation studies evaluating fixed and random effects estimation 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#35745;&#31639;&#26694;&#26550;&#65292;&#36890;&#36807;&#25289;&#26684;&#26391;&#26085;&#23545;&#20598;&#24418;&#24335;&#22788;&#29702;&#19981;&#21516;&#30340;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#65292;&#19981;&#38656;&#35201;&#27169;&#25311;&#36712;&#36857;&#25110;&#35775;&#38382;&#26368;&#20248;&#32806;&#21512;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.10649</link><description>&lt;p&gt;
&#29992;&#20110;&#27714;&#35299;Wasserstein Lagrangian&#27969;&#30340;&#35745;&#31639;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Computational Framework for Solving Wasserstein Lagrangian Flows. (arXiv:2310.10649v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10649
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#35745;&#31639;&#26694;&#26550;&#65292;&#36890;&#36807;&#25289;&#26684;&#26391;&#26085;&#23545;&#20598;&#24418;&#24335;&#22788;&#29702;&#19981;&#21516;&#30340;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#65292;&#19981;&#38656;&#35201;&#27169;&#25311;&#36712;&#36857;&#25110;&#35775;&#38382;&#26368;&#20248;&#32806;&#21512;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#36873;&#25321;&#19981;&#21516;&#30340;&#22522;&#30784;&#20960;&#20309;&#65288;&#21160;&#33021;&#65289;&#21644;&#23494;&#24230;&#36335;&#24452;&#30340;&#27491;&#21017;&#21270;&#65288;&#21183;&#33021;&#65289;&#65292;&#21487;&#20197;&#23545;&#26368;&#20248;&#36755;&#36816;&#30340;&#21160;&#21147;&#23398;&#24418;&#24335;&#36827;&#34892;&#25512;&#24191;&#12290;&#36825;&#20123;&#32452;&#21512;&#20135;&#29983;&#19981;&#21516;&#30340;&#21464;&#20998;&#38382;&#39064;&#65288;Lagrangians&#65289;&#65292;&#28085;&#30422;&#20102;&#35768;&#22810;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#30340;&#21464;&#20307;&#65292;&#22914;Schr&#246;dinger&#26725;&#12289;&#19981;&#24179;&#34913;&#26368;&#20248;&#36755;&#36816;&#21644;&#24102;&#26377;&#29289;&#29702;&#32422;&#26463;&#30340;&#26368;&#20248;&#36755;&#36816;&#31561;&#12290;&#19968;&#33324;&#32780;&#35328;&#65292;&#26368;&#20248;&#23494;&#24230;&#36335;&#24452;&#26159;&#26410;&#30693;&#30340;&#65292;&#35299;&#20915;&#36825;&#20123;&#21464;&#20998;&#38382;&#39064;&#22312;&#35745;&#31639;&#19978;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20511;&#21161;&#25289;&#26684;&#26391;&#26085;&#23545;&#20598;&#24418;&#24335;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#20174;&#32479;&#19968;&#30340;&#35282;&#24230;&#22788;&#29702;&#25152;&#26377;&#36825;&#20123;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#38656;&#35201;&#27169;&#25311;&#25110;&#21453;&#21521;&#20256;&#25773;&#23398;&#20064;&#21160;&#21147;&#23398;&#30340;&#36712;&#36857;&#65292;&#20063;&#19981;&#38656;&#35201;&#35775;&#38382;&#26368;&#20248;&#32806;&#21512;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#26694;&#26550;&#30340;&#22810;&#21151;&#33021;&#24615;&#65292;&#36890;&#36807;&#36229;&#36234;&#20102;&#20854;&#20182;&#26041;&#27861;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
The dynamical formulation of the optimal transport can be extended through various choices of the underlying geometry ($\textit{kinetic energy}$), and the regularization of density paths ($\textit{potential energy}$). These combinations yield different variational problems ($\textit{Lagrangians}$), encompassing many variations of the optimal transport problem such as the Schr\"odinger bridge, unbalanced optimal transport, and optimal transport with physical constraints, among others. In general, the optimal density path is unknown, and solving these variational problems can be computationally challenging. Leveraging the dual formulation of the Lagrangians, we propose a novel deep learning based framework approaching all of these problems from a unified perspective. Our method does not require simulating or backpropagating through the trajectories of the learned dynamics, and does not need access to optimal couplings. We showcase the versatility of the proposed framework by outperformin
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#21327;&#21464;&#37327;&#28418;&#31227;&#19979;&#23545;&#19968;&#33324;&#38750;&#21442;&#25968;&#26041;&#27861;&#36827;&#34892;&#32479;&#19968;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24314;&#31435;&#25910;&#25947;&#36895;&#24230;&#20026;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2310.08237</link><description>&lt;p&gt;
&#22312;&#21327;&#21464;&#37327;&#28418;&#31227;&#19979;&#22522;&#20110;&#26680;&#26041;&#27861;&#30340;&#32479;&#19968;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Towards a Unified Analysis of Kernel-based Methods Under Covariate Shift. (arXiv:2310.08237v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08237
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#21327;&#21464;&#37327;&#28418;&#31227;&#19979;&#23545;&#19968;&#33324;&#38750;&#21442;&#25968;&#26041;&#27861;&#36827;&#34892;&#32479;&#19968;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24314;&#31435;&#25910;&#25947;&#36895;&#24230;&#20026;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#21327;&#21464;&#37327;&#28418;&#31227;&#26159;&#26222;&#36941;&#23384;&#22312;&#30340;&#65292;&#21363;&#28304;&#25968;&#25454;&#21644;&#30446;&#26631;&#25968;&#25454;&#30340;&#36755;&#20837;&#20998;&#24067;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#12290;&#23613;&#31649;&#22312;&#21508;&#31181;&#23398;&#20064;&#38382;&#39064;&#20013;&#20855;&#26377;&#23454;&#38469;&#37325;&#35201;&#24615;&#65292;&#20294;&#29616;&#26377;&#30340;&#22823;&#22810;&#25968;&#26041;&#27861;&#21482;&#20851;&#27880;&#20110;&#19968;&#20123;&#29305;&#23450;&#30340;&#23398;&#20064;&#20219;&#21153;&#65292;&#24182;&#27809;&#26377;&#22312;&#29702;&#35770;&#19978;&#21644;&#25968;&#20540;&#19978;&#24471;&#21040;&#24456;&#22909;&#30340;&#39564;&#35777;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#21327;&#21464;&#37327;&#28418;&#31227;&#19979;&#23545;&#19968;&#33324;&#38750;&#21442;&#25968;&#26041;&#27861;&#36827;&#34892;&#32479;&#19968;&#20998;&#26512;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#36866;&#29992;&#20110;&#23646;&#20110;&#19968;&#20010;&#20016;&#23500;&#30340;&#25439;&#22833;&#20989;&#25968;&#23478;&#26063;&#30340;&#19968;&#33324;&#25439;&#22833;&#65292;&#20854;&#20013;&#21253;&#25324;&#35768;&#22810;&#24120;&#29992;&#30340;&#26041;&#27861;&#65292;&#22914;&#22343;&#20540;&#22238;&#24402;&#12289;&#20998;&#20301;&#25968;&#22238;&#24402;&#12289;&#22522;&#20110;&#20284;&#28982;&#30340;&#20998;&#31867;&#21644;&#22522;&#20110;&#36793;&#32536;&#30340;&#20998;&#31867;&#12290;&#26412;&#25991;&#37325;&#28857;&#30740;&#31350;&#20102;&#20004;&#31867;&#21327;&#21464;&#37327;&#28418;&#31227;&#38382;&#39064;&#65292;&#24182;&#20026;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#24314;&#31435;&#20102;&#23574;&#38160;&#30340;&#25910;&#25947;&#36895;&#24230;&#20197;&#25552;&#20379;&#19968;&#20010;&#32479;&#19968;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#35813;&#32467;&#26524;&#19982;&#25991;&#29486;&#20013;&#30340;&#26368;&#20248;&#32467;&#26524;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
Covariate shift occurs prevalently in practice, where the input distributions of the source and target data are substantially different. Despite its practical importance in various learning problems, most of the existing methods only focus on some specific learning tasks and are not well validated theoretically and numerically. To tackle this problem, we propose a unified analysis of general nonparametric methods in a reproducing kernel Hilbert space (RKHS) under covariate shift. Our theoretical results are established for a general loss belonging to a rich loss function family, which includes many commonly used methods as special cases, such as mean regression, quantile regression, likelihood-based classification, and margin-based classification. Two types of covariate shift problems are the focus of this paper and the sharp convergence rates are established for a general loss function to provide a unified theoretical analysis, which concurs with the optimal results in literature wher
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#36866;&#29992;&#20110;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#30340;&#36335;&#24452;&#33539;&#25968;&#24037;&#20855;&#21253;&#65292;&#21487;&#20197;&#21253;&#25324;&#20855;&#26377;&#20559;&#24046;&#12289;&#36339;&#36291;&#36830;&#25509;&#21644;&#26368;&#22823;&#27744;&#21270;&#30340;&#36890;&#29992;DAG ReLU&#32593;&#32476;&#12290;&#36825;&#20010;&#24037;&#20855;&#21253;&#24674;&#22797;&#25110;&#36229;&#36234;&#20102;&#24050;&#30693;&#30340;&#36335;&#24452;&#33539;&#25968;&#30028;&#38480;&#65292;&#24182;&#25361;&#25112;&#20102;&#22522;&#20110;&#36335;&#24452;&#33539;&#25968;&#30340;&#19968;&#20123;&#20855;&#20307;&#25215;&#35834;&#12290;</title><link>http://arxiv.org/abs/2310.01225</link><description>&lt;p&gt;
&#19968;&#31181;&#36866;&#29992;&#20110;&#29616;&#20195;&#32593;&#32476;&#30340;&#36335;&#24452;&#33539;&#25968;&#24037;&#20855;&#21253;&#65306;&#24433;&#21709;&#12289;&#21069;&#26223;&#21644;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
A path-norm toolkit for modern networks: consequences, promises and challenges. (arXiv:2310.01225v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01225
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#36866;&#29992;&#20110;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#30340;&#36335;&#24452;&#33539;&#25968;&#24037;&#20855;&#21253;&#65292;&#21487;&#20197;&#21253;&#25324;&#20855;&#26377;&#20559;&#24046;&#12289;&#36339;&#36291;&#36830;&#25509;&#21644;&#26368;&#22823;&#27744;&#21270;&#30340;&#36890;&#29992;DAG ReLU&#32593;&#32476;&#12290;&#36825;&#20010;&#24037;&#20855;&#21253;&#24674;&#22797;&#25110;&#36229;&#36234;&#20102;&#24050;&#30693;&#30340;&#36335;&#24452;&#33539;&#25968;&#30028;&#38480;&#65292;&#24182;&#25361;&#25112;&#20102;&#22522;&#20110;&#36335;&#24452;&#33539;&#25968;&#30340;&#19968;&#20123;&#20855;&#20307;&#25215;&#35834;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#31532;&#19968;&#20010;&#23436;&#20840;&#33021;&#22815;&#21253;&#25324;&#20855;&#26377;&#20559;&#24046;&#12289;&#36339;&#36291;&#36830;&#25509;&#21644;&#26368;&#22823;&#27744;&#21270;&#30340;&#36890;&#29992;DAG ReLU&#32593;&#32476;&#30340;&#36335;&#24452;&#33539;&#25968;&#24037;&#20855;&#21253;&#12290;&#36825;&#20010;&#24037;&#20855;&#21253;&#19981;&#20165;&#36866;&#29992;&#20110;&#26368;&#24191;&#27867;&#30340;&#22522;&#20110;&#36335;&#24452;&#33539;&#25968;&#30340;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#65292;&#36824;&#21487;&#20197;&#24674;&#22797;&#25110;&#36229;&#36234;&#24050;&#30693;&#30340;&#27492;&#31867;&#33539;&#25968;&#30340;&#26368;&#23574;&#38160;&#30028;&#38480;&#12290;&#36825;&#20123;&#25193;&#23637;&#30340;&#36335;&#24452;&#33539;&#25968;&#36824;&#20139;&#26377;&#36335;&#24452;&#33539;&#25968;&#30340;&#24120;&#35268;&#20248;&#28857;&#65306;&#35745;&#31639;&#31616;&#20415;&#12289;&#23545;&#32593;&#32476;&#30340;&#23545;&#31216;&#24615;&#20855;&#26377;&#19981;&#21464;&#24615;&#65292;&#22312;&#21069;&#39304;&#32593;&#32476;&#19978;&#27604;&#25805;&#20316;&#31526;&#33539;&#25968;&#30340;&#20056;&#31215;&#65288;&#21478;&#19968;&#31181;&#24120;&#29992;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65289;&#20855;&#26377;&#26356;&#22909;&#30340;&#38160;&#24230;&#12290;&#24037;&#20855;&#21253;&#30340;&#22810;&#21151;&#33021;&#24615;&#21644;&#26131;&#20110;&#23454;&#26045;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#25968;&#20540;&#35780;&#20272;&#22312;ImageNet&#19978;&#23545;ResNet&#30340;&#26368;&#23574;&#38160;&#30028;&#38480;&#26469;&#25361;&#25112;&#22522;&#20110;&#36335;&#24452;&#33539;&#25968;&#30340;&#20855;&#20307;&#25215;&#35834;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work introduces the first toolkit around path-norms that is fully able to encompass general DAG ReLU networks with biases, skip connections and max pooling. This toolkit notably allows us to establish generalization bounds for real modern neural networks that are not only the most widely applicable path-norm based ones, but also recover or beat the sharpest known bounds of this type. These extended path-norms further enjoy the usual benefits of path-norms: ease of computation, invariance under the symmetries of the network, and improved sharpness on feedforward networks compared to the product of operators' norms, another complexity measure most commonly used.  The versatility of the toolkit and its ease of implementation allow us to challenge the concrete promises of path-norm-based generalization bounds, by numerically evaluating the sharpest known bounds for ResNets on ImageNet.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26680;&#23494;&#24230;&#31215;&#20998;&#36716;&#25442;&#20316;&#20026;&#29305;&#24449;&#39044;&#22788;&#29702;&#27493;&#39588;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#26367;&#20195;&#32447;&#24615;&#26368;&#23567;&#26368;&#22823;&#32553;&#25918;&#21644;&#20998;&#20301;&#25968;&#36716;&#25442;&#65292;&#24182;&#36890;&#36807;&#35843;&#25972;&#36229;&#21442;&#25968;&#20248;&#21270;&#24615;&#33021;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#32479;&#35745;&#25968;&#25454;&#20998;&#26512;&#20013;&#20855;&#26377;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2309.10194</link><description>&lt;p&gt;
&#26680;&#23494;&#24230;&#31215;&#20998;&#36716;&#25442;
&lt;/p&gt;
&lt;p&gt;
The Kernel Density Integral Transformation. (arXiv:2309.10194v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10194
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26680;&#23494;&#24230;&#31215;&#20998;&#36716;&#25442;&#20316;&#20026;&#29305;&#24449;&#39044;&#22788;&#29702;&#27493;&#39588;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#26367;&#20195;&#32447;&#24615;&#26368;&#23567;&#26368;&#22823;&#32553;&#25918;&#21644;&#20998;&#20301;&#25968;&#36716;&#25442;&#65292;&#24182;&#36890;&#36807;&#35843;&#25972;&#36229;&#21442;&#25968;&#20248;&#21270;&#24615;&#33021;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#32479;&#35745;&#25968;&#25454;&#20998;&#26512;&#20013;&#20855;&#26377;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24212;&#29992;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#26041;&#27861;&#20110;&#34920;&#26684;&#25968;&#25454;&#26102;&#65292;&#29305;&#24449;&#39044;&#22788;&#29702;&#32487;&#32493;&#21457;&#25381;&#20851;&#38190;&#20316;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#29992;&#26680;&#23494;&#24230;&#31215;&#20998;&#36716;&#25442;&#20316;&#20026;&#29305;&#24449;&#39044;&#22788;&#29702;&#27493;&#39588;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#32508;&#21512;&#20102;&#20004;&#31181;&#20027;&#35201;&#30340;&#29305;&#24449;&#39044;&#22788;&#29702;&#26041;&#27861;&#20316;&#20026;&#26497;&#38480;&#24773;&#20917;&#65306;&#32447;&#24615;&#26368;&#23567;&#26368;&#22823;&#32553;&#25918;&#21644;&#20998;&#20301;&#25968;&#36716;&#25442;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#22312;&#19981;&#35843;&#25972;&#36229;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#26680;&#23494;&#24230;&#31215;&#20998;&#36716;&#25442;&#21487;&#20197;&#20316;&#20026;&#36825;&#20004;&#31181;&#26041;&#27861;&#30340;&#31616;&#21333;&#26367;&#20195;&#26041;&#27861;&#65292;&#23545;&#27599;&#31181;&#26041;&#27861;&#30340;&#24369;&#28857;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#21478;&#22806;&#65292;&#36890;&#36807;&#35843;&#25972;&#19968;&#20010;&#36830;&#32493;&#36229;&#21442;&#25968;&#65292;&#25105;&#20204;&#32463;&#24120;&#20248;&#20110;&#36825;&#20004;&#31181;&#26041;&#27861;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#34920;&#26126;&#26680;&#23494;&#24230;&#36716;&#25442;&#21487;&#20197;&#26377;&#30410;&#22320;&#24212;&#29992;&#20110;&#32479;&#35745;&#25968;&#25454;&#20998;&#26512;&#65292;&#29305;&#21035;&#26159;&#22312;&#30456;&#20851;&#24615;&#20998;&#26512;&#21644;&#21333;&#21464;&#37327;&#32858;&#31867;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
Feature preprocessing continues to play a critical role when applying machine learning and statistical methods to tabular data. In this paper, we propose the use of the kernel density integral transformation as a feature preprocessing step. Our approach subsumes the two leading feature preprocessing methods as limiting cases: linear min-max scaling and quantile transformation. We demonstrate that, without hyperparameter tuning, the kernel density integral transformation can be used as a simple drop-in replacement for either method, offering robustness to the weaknesses of each. Alternatively, with tuning of a single continuous hyperparameter, we frequently outperform both of these methods. Finally, we show that the kernel density transformation can be profitably applied to statistical data analysis, particularly in correlation analysis and univariate clustering.
&lt;/p&gt;</description></item><item><title>URL&#22522;&#20934;&#26159;&#19968;&#20010;&#35780;&#20272;&#39044;&#35757;&#32451;&#27169;&#22411;&#21487;&#36716;&#31227;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#26041;&#24335;&#65292;&#30740;&#31350;&#21457;&#29616;&#19987;&#27880;&#20110;&#34920;&#31034;&#26412;&#36523;&#19981;&#30830;&#23450;&#24615;&#25110;&#30452;&#25509;&#20272;&#35745;&#39044;&#27979;&#39118;&#38505;&#30340;&#26041;&#27861;&#25928;&#26524;&#20248;&#20110;&#22522;&#20110;&#27010;&#29575;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.03810</link><description>&lt;p&gt;
URL&#65306;&#19968;&#31181;&#21487;&#36716;&#31227;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#34920;&#31034;&#23398;&#20064;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
URL: A Representation Learning Benchmark for Transferable Uncertainty Estimates. (arXiv:2307.03810v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03810
&lt;/p&gt;
&lt;p&gt;
URL&#22522;&#20934;&#26159;&#19968;&#20010;&#35780;&#20272;&#39044;&#35757;&#32451;&#27169;&#22411;&#21487;&#36716;&#31227;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#26041;&#24335;&#65292;&#30740;&#31350;&#21457;&#29616;&#19987;&#27880;&#20110;&#34920;&#31034;&#26412;&#36523;&#19981;&#30830;&#23450;&#24615;&#25110;&#30452;&#25509;&#20272;&#35745;&#39044;&#27979;&#39118;&#38505;&#30340;&#26041;&#27861;&#25928;&#26524;&#20248;&#20110;&#22522;&#20110;&#27010;&#29575;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34920;&#31034;&#23398;&#20064;&#26174;&#33879;&#25512;&#21160;&#20102;&#35813;&#39046;&#22495;&#21457;&#23637;&#20986;&#33021;&#22815;&#20316;&#20026;&#20174;&#38646;&#24320;&#22987;&#36801;&#31227;&#21040;&#26032;&#25968;&#25454;&#38598;&#26102;&#30340;&#26377;&#20215;&#20540;&#36215;&#28857;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#12290;&#38543;&#30528;&#23545;&#21487;&#38752;&#26426;&#22120;&#23398;&#20064;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#38656;&#27714;&#19981;&#26029;&#22686;&#21152;&#65292;&#38656;&#35201;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#19981;&#20165;&#33021;&#25552;&#20379;&#23884;&#20837;&#21521;&#37327;&#65292;&#36824;&#33021;&#25552;&#20379;&#21487;&#36716;&#31227;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#20026;&#20102;&#24341;&#23548;&#36825;&#26679;&#30340;&#27169;&#22411;&#30340;&#24320;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;URL&#65288;Uncertainty-aware Representation Learning&#65289;&#22522;&#20934;&#12290;&#38500;&#20102;&#34920;&#31034;&#30340;&#21487;&#36716;&#31227;&#24615;&#20043;&#22806;&#65292;&#23427;&#36824;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#24230;&#37327;&#26631;&#20934;&#26469;&#27979;&#37327;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#38646;&#26679;&#26412;&#21487;&#36716;&#31227;&#24615;&#12290;&#25105;&#20204;&#24212;&#29992;URL&#26469;&#35780;&#20272;11&#31181;&#22312;ImageNet&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#24182;&#36716;&#31227;&#21040;8&#20010;&#19979;&#28216;&#25968;&#25454;&#38598;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#22120;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#30528;&#37325;&#20110;&#34920;&#31034;&#26412;&#36523;&#30340;&#19981;&#30830;&#23450;&#24615;&#25110;&#30452;&#25509;&#20272;&#35745;&#39044;&#27979;&#39118;&#38505;&#30340;&#26041;&#27861;&#20248;&#20110;&#22522;&#20110;&#19978;&#28216;&#31867;&#21035;&#30340;&#27010;&#29575;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#23454;&#29616;&#21487;&#36716;&#31227;&#30340;&#19981;&#30830;&#23450;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Representation learning has significantly driven the field to develop pretrained models that can act as a valuable starting point when transferring to new datasets. With the rising demand for reliable machine learning and uncertainty quantification, there is a need for pretrained models that not only provide embeddings but also transferable uncertainty estimates. To guide the development of such models, we propose the Uncertainty-aware Representation Learning (URL) benchmark. Besides the transferability of the representations, it also measures the zero-shot transferability of the uncertainty estimate using a novel metric. We apply URL to evaluate eleven uncertainty quantifiers that are pretrained on ImageNet and transferred to eight downstream datasets. We find that approaches that focus on the uncertainty of the representation itself or estimate the prediction risk directly outperform those that are based on the probabilities of upstream classes. Yet, achieving transferable uncertaint
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#19968;&#33268;&#24615;&#26816;&#26597;&#35780;&#20272;&#36229;&#20154;&#27169;&#22411;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#21457;&#29616;&#20915;&#31574;&#21046;&#23450;&#20013;&#30340;&#36923;&#36753;&#19981;&#19968;&#33268;&#24615;&#65292;&#21363;&#20351;&#23545;&#20110;&#36229;&#20154;&#27169;&#22411;&#30340;&#20915;&#31574;&#27491;&#30830;&#24615;&#21487;&#33021;&#26159;&#19981;&#21487;&#33021;&#35780;&#20272;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2306.09983</link><description>&lt;p&gt;
&#29992;&#19968;&#33268;&#24615;&#26816;&#26597;&#35780;&#20272;&#36229;&#20154;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Evaluating Superhuman Models with Consistency Checks. (arXiv:2306.09983v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09983
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#19968;&#33268;&#24615;&#26816;&#26597;&#35780;&#20272;&#36229;&#20154;&#27169;&#22411;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#21457;&#29616;&#20915;&#31574;&#21046;&#23450;&#20013;&#30340;&#36923;&#36753;&#19981;&#19968;&#33268;&#24615;&#65292;&#21363;&#20351;&#23545;&#20110;&#36229;&#20154;&#27169;&#22411;&#30340;&#20915;&#31574;&#27491;&#30830;&#24615;&#21487;&#33021;&#26159;&#19981;&#21487;&#33021;&#35780;&#20272;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#26524;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#21508;&#31181;&#25512;&#29702;&#25110;&#20915;&#31574;&#20219;&#21153;&#19978;&#23454;&#29616;&#20102;&#36229;&#20154;&#33021;&#21147;&#65292;&#37027;&#20040;&#25105;&#20204;&#35813;&#22914;&#20309;&#35780;&#20272;&#36825;&#20123;&#27169;&#22411;&#65292;&#32771;&#34385;&#21040;&#20154;&#31867;&#20195;&#29702;&#20250;&#20135;&#29983;&#20559;&#24046;? &#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#19968;&#33268;&#24615;&#26816;&#26597;&#35780;&#20272;&#36229;&#20154;&#27169;&#22411;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#21069;&#25552;&#26159;&#65292;&#34429;&#28982;&#35780;&#20272;&#36229;&#20154;&#20915;&#31574;&#30340;&#27491;&#30830;&#24615;&#21487;&#33021;&#26159;&#19981;&#21487;&#33021;&#30340;&#65292;&#20294;&#26159;&#22914;&#26524;&#27169;&#22411;&#30340;&#20915;&#31574;&#26410;&#33021;&#28385;&#36275;&#26576;&#20123;&#36923;&#36753;&#19978;&#12289;&#21487;&#35299;&#37322;&#30340;&#35268;&#21017;&#65292;&#25105;&#20204;&#20173;&#28982;&#21487;&#20197;&#21457;&#29616;&#38169;&#35823;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26694;&#26550;&#23454;&#29616;&#22312;&#19977;&#20010;&#20219;&#21153;&#19978;&#65292;&#36825;&#20123;&#20219;&#21153;&#30340;&#20915;&#31574;&#27491;&#30830;&#24615;&#30001;&#20110;&#36229;&#20154;&#27169;&#22411;&#33021;&#21147;&#25110;&#20854;&#20182;&#32570;&#20047;&#22522;&#26412;&#20107;&#23454;&#32780;&#38590;&#20197;&#35780;&#20272;&#65306;&#35780;&#20272;&#22269;&#38469;&#35937;&#26827;&#23616;&#38754;&#12289;&#39044;&#27979;&#26410;&#26469;&#20107;&#20214;&#21644;&#20316;&#20986;&#27861;&#24459;&#21028;&#26029;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#26080;&#35770;&#27169;&#22411;&#22312;&#36825;&#20123;&#20219;&#21153;&#19978;&#30340;&#34920;&#29616;&#22914;&#20309;(&#21487;&#33021;&#26159;&#36229;&#20154;&#30340;)&#65292;&#25105;&#20204;&#37117;&#33021;&#21457;&#29616;&#20915;&#31574;&#21046;&#23450;&#20013;&#30340;&#36923;&#36753;&#19981;&#19968;&#33268;&#24615;&#12290;&#20363;&#22914;&#65306;&#22269;&#38469;&#35937;&#26827;&#24341;&#25806;&#32473;&#20986;&#23545;&#23616;&#20013;&#26827;&#23376;&#30456;&#23545;&#20272;&#20540;&#30340;&#19981;&#21516;&#25490;&#21015;&#12290;
&lt;/p&gt;
&lt;p&gt;
If machine learning models were to achieve superhuman abilities at various reasoning or decision-making tasks, how would we go about evaluating such models, given that humans would necessarily be poor proxies for ground truth? In this paper, we propose a framework for evaluating superhuman models via consistency checks. Our premise is that while the correctness of superhuman decisions may be impossible to evaluate, we can still surface mistakes if the model's decisions fail to satisfy certain logical, human-interpretable rules. We instantiate our framework on three tasks where correctness of decisions is hard to evaluate due to either superhuman model abilities, or to otherwise missing ground truth: evaluating chess positions, forecasting future events, and making legal judgments. We show that regardless of a model's (possibly superhuman) performance on these tasks, we can discover logical inconsistencies in decision making. For example: a chess engine assigning opposing valuations to 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#30340;&#21464;&#20998;&#19981;&#24179;&#34913;&#22238;&#24402;&#65288;VIR&#65289;&#27169;&#22411;&#36890;&#36807;&#24341;&#20837;Probabilistic Reweighting&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#24179;&#34913;&#22238;&#24402;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#33258;&#28982;&#20135;&#29983;&#21512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2306.06599</link><description>&lt;p&gt;
&#21464;&#20998;&#19981;&#24179;&#34913;&#22238;&#24402;(Variational Imbalanced Regression)
&lt;/p&gt;
&lt;p&gt;
Variational Imbalanced Regression. (arXiv:2306.06599v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06599
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#30340;&#21464;&#20998;&#19981;&#24179;&#34913;&#22238;&#24402;&#65288;VIR&#65289;&#27169;&#22411;&#36890;&#36807;&#24341;&#20837;Probabilistic Reweighting&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#24179;&#34913;&#22238;&#24402;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#33258;&#28982;&#20135;&#29983;&#21512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#26631;&#31614;&#20998;&#24067;&#19981;&#24179;&#34913;&#26102;&#65292;&#29616;&#26377;&#30340;&#22238;&#24402;&#27169;&#22411;&#24448;&#24448;&#22312;&#20934;&#30830;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26041;&#38754;&#34920;&#29616;&#19981;&#20339;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#29575;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#8212;&#8212;&#21464;&#20998;&#19981;&#24179;&#34913;&#22238;&#24402;&#65288;VIR&#65289;&#65292;&#23427;&#19981;&#20165;&#22312;&#19981;&#24179;&#34913;&#22238;&#24402;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#32780;&#19988;&#33258;&#28982;&#22320;&#20135;&#29983;&#21512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#19982;&#20856;&#22411;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#20551;&#35774;I.I.D.&#34920;&#31034;&#65288;&#25968;&#25454;&#28857;&#30340;&#34920;&#31034;&#19981;&#30452;&#25509;&#21463;&#20854;&#20182;&#25968;&#25454;&#28857;&#30340;&#24433;&#21709;&#65289;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;VIR&#20511;&#29992;&#20855;&#26377;&#31867;&#20284;&#22238;&#24402;&#26631;&#31614;&#30340;&#25968;&#25454;&#26469;&#35745;&#31639;&#28508;&#22312;&#34920;&#31034;&#30340;&#21464;&#20998;&#20998;&#24067;&#65307;&#27492;&#22806;&#65292;&#19981;&#21516;&#20110;&#20135;&#29983;&#28857;&#20272;&#35745;&#30340;&#30830;&#23450;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292; VIR&#39044;&#27979;&#25972;&#20010;&#27491;&#24577;&#21453;-&#20285;&#29595;&#20998;&#24067;&#24182;&#35843;&#33410;&#30456;&#20851;&#32852;&#30340;&#20849;&#36717;&#20998;&#24067;&#65292;&#23545;&#19981;&#24179;&#34913;&#25968;&#25454;&#26045;&#21152;&#27010;&#29575;&#37325;&#26032;&#21152;&#26435;&#65292;&#20174;&#32780;&#25552;&#20379;&#26356;&#22909;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#22312;&#20960;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing regression models tend to fall short in both accuracy and uncertainty estimation when the label distribution is imbalanced. In this paper, we propose a probabilistic deep learning model, dubbed variational imbalanced regression (VIR), which not only performs well in imbalanced regression but naturally produces reasonable uncertainty estimation as a byproduct. Different from typical variational autoencoders assuming I.I.D. representations (a data point's representation is not directly affected by other data points), our VIR borrows data with similar regression labels to compute the latent representation's variational distribution; furthermore, different from deterministic regression models producing point estimates, VIR predicts the entire normal-inverse-gamma distributions and modulates the associated conjugate distributions to impose probabilistic reweighting on the imbalanced data, thereby providing better uncertainty estimation. Experiments in several real-world datasets sh
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#40065;&#26834;&#30340;&#33258;&#36866;&#24212; $\tau$-Lasso &#20272;&#35745;&#22120;&#65292;&#21516;&#26102;&#37319;&#29992;&#33258;&#36866;&#24212; $\ell_1$-&#33539;&#25968;&#24809;&#32602;&#39033;&#20197;&#38477;&#20302;&#30495;&#23454;&#22238;&#24402;&#31995;&#25968;&#30340;&#20559;&#24046;&#12290;&#23427;&#20855;&#26377;&#21464;&#37327;&#36873;&#25321;&#19968;&#33268;&#24615;&#21644;&#30495;&#23454;&#25903;&#25345;&#19979;&#22238;&#24402;&#21521;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#30340;&#26368;&#20248;&#24615;&#36136;&#65292;&#20551;&#23450;&#24050;&#30693;&#30495;&#23454;&#22238;&#24402;&#21521;&#37327;&#30340;&#25903;&#25345;&#12290;</title><link>http://arxiv.org/abs/2304.09310</link><description>&lt;p&gt;
&#33258;&#36866;&#24212; $\tau$-Lasso&#65306;&#20854;&#20581;&#22766;&#24615;&#21644;&#26368;&#20248;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Adaptive $\tau$-Lasso: Its Robustness and Oracle Properties. (arXiv:2304.09310v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09310
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#40065;&#26834;&#30340;&#33258;&#36866;&#24212; $\tau$-Lasso &#20272;&#35745;&#22120;&#65292;&#21516;&#26102;&#37319;&#29992;&#33258;&#36866;&#24212; $\ell_1$-&#33539;&#25968;&#24809;&#32602;&#39033;&#20197;&#38477;&#20302;&#30495;&#23454;&#22238;&#24402;&#31995;&#25968;&#30340;&#20559;&#24046;&#12290;&#23427;&#20855;&#26377;&#21464;&#37327;&#36873;&#25321;&#19968;&#33268;&#24615;&#21644;&#30495;&#23454;&#25903;&#25345;&#19979;&#22238;&#24402;&#21521;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#30340;&#26368;&#20248;&#24615;&#36136;&#65292;&#20551;&#23450;&#24050;&#30693;&#30495;&#23454;&#22238;&#24402;&#21521;&#37327;&#30340;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#20998;&#26512;&#39640;&#32500;&#25968;&#25454;&#38598;&#30340;&#26032;&#22411;&#27491;&#21017;&#21270;&#40065;&#26834; $\tau$-&#22238;&#24402;&#20272;&#35745;&#22120;&#65292;&#20197;&#24212;&#23545;&#21709;&#24212;&#21464;&#37327;&#21644;&#21327;&#21464;&#37327;&#30340;&#20005;&#37325;&#27745;&#26579;&#12290;&#25105;&#20204;&#31216;&#36825;&#31181;&#20272;&#35745;&#22120;&#20026;&#33258;&#36866;&#24212; $\tau$-Lasso&#65292;&#23427;&#23545;&#24322;&#24120;&#20540;&#21644;&#39640;&#26464;&#26438;&#28857;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#21516;&#26102;&#37319;&#29992;&#33258;&#36866;&#24212; $\ell_1$-&#33539;&#25968;&#24809;&#32602;&#39033;&#26469;&#20943;&#23569;&#30495;&#23454;&#22238;&#24402;&#31995;&#25968;&#30340;&#20559;&#24046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#33258;&#36866;&#24212; $\ell_1$-&#33539;&#25968;&#24809;&#32602;&#39033;&#20026;&#27599;&#20010;&#22238;&#24402;&#31995;&#25968;&#20998;&#37197;&#19968;&#20010;&#26435;&#37325;&#12290;&#23545;&#20110;&#22266;&#23450;&#25968;&#37327;&#30340;&#39044;&#27979;&#21464;&#37327; $p$&#65292;&#25105;&#20204;&#26174;&#31034;&#20986;&#33258;&#36866;&#24212; $\tau$-Lasso &#20855;&#26377;&#21464;&#37327;&#36873;&#25321;&#19968;&#33268;&#24615;&#21644;&#30495;&#23454;&#25903;&#25345;&#19979;&#22238;&#24402;&#21521;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#30340;&#26368;&#20248;&#24615;&#36136;&#65292;&#20551;&#23450;&#24050;&#30693;&#30495;&#23454;&#22238;&#24402;&#21521;&#37327;&#30340;&#25903;&#25345;&#12290;&#28982;&#21518;&#25105;&#20204;&#36890;&#36807;&#26377;&#38480;&#26679;&#26412;&#26029;&#28857;&#21644;&#24433;&#21709;&#20989;&#25968;&#26469;&#34920;&#24449;&#20854;&#20581;&#22766;&#24615;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#27169;&#25311;&#26469;&#27604;&#36739;&#19981;&#21516;&#30340;&#20272;&#35745;&#22120;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a new regularized version of the robust $\tau$-regression estimator for analyzing high-dimensional data sets subject to gross contamination in the response variables and covariates. We call the resulting estimator adaptive $\tau$-Lasso that is robust to outliers and high-leverage points and simultaneously employs adaptive $\ell_1$-norm penalty term to reduce the bias associated with large true regression coefficients. More specifically, this adaptive $\ell_1$-norm penalty term assigns a weight to each regression coefficient. For a fixed number of predictors $p$, we show that the adaptive $\tau$-Lasso has the oracle property with respect to variable-selection consistency and asymptotic normality for the regression vector corresponding to the true support, assuming knowledge of the true regression vector support. We then characterize its robustness via the finite-sample breakdown point and the influence function. We carry-out extensive simulations to compare the per
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#29289;&#29702;&#21551;&#21457;&#30340;&#31070;&#32463;&#32593;&#32476;&#24212;&#29992;&#20110;&#37325;&#24314;&#27969;&#20307;&#21147;&#23398;&#27169;&#25311;&#20013;&#65292;&#36890;&#36807;&#23558;&#29702;&#35770;&#30693;&#35782;&#27880;&#20837;&#27169;&#22411;&#25439;&#22833;&#20989;&#25968;&#24182;&#32467;&#21512;&#26032;&#30340;&#24615;&#33021;&#35780;&#20272;&#25351;&#26631;&#65292;&#25104;&#21151;&#23454;&#29616;&#20102;&#23545;&#37325;&#23376;&#25955;&#23556;&#30340;&#37325;&#24314;&#12290;</title><link>http://arxiv.org/abs/2303.14090</link><description>&lt;p&gt;
&#29289;&#29702;&#21551;&#21457;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;&#21033;&#29992;&#26263;&#29289;&#36136;&#37325;&#24314;&#27969;&#20307;&#21147;&#23398;&#27169;&#25311;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Physics-informed neural networks in the recreation of hydrodynamic simulations from dark matter. (arXiv:2303.14090v1 [astro-ph.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14090
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#29289;&#29702;&#21551;&#21457;&#30340;&#31070;&#32463;&#32593;&#32476;&#24212;&#29992;&#20110;&#37325;&#24314;&#27969;&#20307;&#21147;&#23398;&#27169;&#25311;&#20013;&#65292;&#36890;&#36807;&#23558;&#29702;&#35770;&#30693;&#35782;&#27880;&#20837;&#27169;&#22411;&#25439;&#22833;&#20989;&#25968;&#24182;&#32467;&#21512;&#26032;&#30340;&#24615;&#33021;&#35780;&#20272;&#25351;&#26631;&#65292;&#25104;&#21151;&#23454;&#29616;&#20102;&#23545;&#37325;&#23376;&#25955;&#23556;&#30340;&#37325;&#24314;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29289;&#29702;&#21551;&#21457;&#30340;&#31070;&#32463;&#32593;&#32476;&#24050;&#32463;&#25104;&#20026;&#19968;&#20010;&#21512;&#29702;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#26500;&#24314;&#23558;&#32479;&#35745;&#27169;&#24335;&#19982;&#39046;&#22495;&#30693;&#35782;&#30456;&#32467;&#21512;&#30340;&#39044;&#27979;&#27169;&#22411;&#12290;&#20854;&#22522;&#26412;&#29702;&#24565;&#26159;&#36890;&#36807;&#24050;&#30693;&#20851;&#31995;&#26469;&#20016;&#23500;&#20248;&#21270;&#25439;&#22833;&#20989;&#25968;&#20197;&#38480;&#21046;&#21487;&#33021;&#35299;&#20915;&#26041;&#26696;&#30340;&#31354;&#38388;&#12290;&#27700;&#21160;&#21147;&#23398;&#27169;&#25311;&#26159;&#29616;&#20195;&#23431;&#23449;&#23398;&#30340;&#26680;&#24515;&#32452;&#25104;&#37096;&#20998;&#65292;&#32780;&#25152;&#38656;&#30340;&#35745;&#31639;&#26082;&#26114;&#36149;&#21448;&#32791;&#26102;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#24555;&#36895;&#27169;&#25311;&#26263;&#29289;&#36136;&#38656;&#35201;&#26356;&#23569;&#30340;&#36164;&#28304;&#65292;&#36825;&#23548;&#33268;&#20102;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#25104;&#20026;&#30740;&#31350;&#30340;&#19968;&#20010;&#27963;&#36291;&#39046;&#22495;;&#22312;&#36825;&#37324;&#65292;&#37325;&#24314;&#27969;&#20307;&#21147;&#23398;&#27169;&#25311;&#20013;&#21457;&#29616;&#30340;&#25955;&#23556;&#26159;&#19968;&#20010;&#25345;&#32493;&#30340;&#25361;&#25112;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#23558;&#29289;&#29702;&#21551;&#21457;&#30340;&#31070;&#32463;&#32593;&#32476;&#24212;&#29992;&#20110;&#37325;&#24314;&#27969;&#20307;&#21147;&#23398;&#27169;&#25311;&#20013;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#32467;&#21512;&#20102;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#36827;&#27493;&#21644;&#29289;&#29702;&#32422;&#26463;&#65292;&#23558;&#20851;&#20110;&#37325;&#23376;&#36716;&#21270;&#25928;&#29575;&#30340;&#29702;&#35770;&#27880;&#20837;&#27169;&#22411;&#25439;&#22833;&#20989;&#25968;&#12290;&#25105;&#20204;&#36824;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#24615;&#33021;&#35780;&#20272;&#25351;&#26631;&#65292;&#22522;&#20110;&#32467;&#26524;&#22270;&#20687;&#20013;&#21160;&#21147;&#23398;&#21151;&#29575;&#35889;&#20013;&#30340;&#35823;&#24046;&#65292;&#36825;&#20351;&#24471;&#21487;&#20197;&#37327;&#21270;&#32593;&#32476;&#23545;&#23431;&#23449;&#23398;&#21442;&#25968;&#25512;&#26029;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Physics-informed neural networks have emerged as a coherent framework for building predictive models that combine statistical patterns with domain knowledge. The underlying notion is to enrich the optimization loss function with known relationships to constrain the space of possible solutions. Hydrodynamic simulations are a core constituent of modern cosmology, while the required computations are both expensive and time-consuming. At the same time, the comparatively fast simulation of dark matter requires fewer resources, which has led to the emergence of machine learning algorithms for baryon inpainting as an active area of research; here, recreating the scatter found in hydrodynamic simulations is an ongoing challenge. This paper presents the first application of physics-informed neural networks to baryon inpainting by combining advances in neural network architectures with physical constraints, injecting theory on baryon conversion efficiency into the model loss function. We also in
&lt;/p&gt;</description></item><item><title>EDGI&#26159;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#21644;&#35268;&#21010;&#31639;&#27861;&#65292;&#36890;&#36807;&#31561;&#21464;&#25193;&#25955;&#22788;&#29702;&#20869;&#22312;&#23545;&#31216;&#24615;&#65292;&#20855;&#26377;&#26356;&#39640;&#25928;&#30340;&#37319;&#26679;&#21644;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#20869;&#22312;&#23545;&#31216;&#24615;&#30340;&#26426;&#22120;&#20154;&#25805;&#20316;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2303.12410</link><description>&lt;p&gt;
EDGI: &#20869;&#22312;&#23545;&#31216;&#24615;&#35268;&#21010;&#30340;&#31561;&#21464;&#25193;&#25955;
&lt;/p&gt;
&lt;p&gt;
EDGI: Equivariant Diffusion for Planning with Embodied Agents. (arXiv:2303.12410v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12410
&lt;/p&gt;
&lt;p&gt;
EDGI&#26159;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#21644;&#35268;&#21010;&#31639;&#27861;&#65292;&#36890;&#36807;&#31561;&#21464;&#25193;&#25955;&#22788;&#29702;&#20869;&#22312;&#23545;&#31216;&#24615;&#65292;&#20855;&#26377;&#26356;&#39640;&#25928;&#30340;&#37319;&#26679;&#21644;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#20869;&#22312;&#23545;&#31216;&#24615;&#30340;&#26426;&#22120;&#20154;&#25805;&#20316;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20869;&#22312;&#23545;&#31216;&#24615;&#26159;&#26102;&#31354;&#21644;&#25490;&#21015;&#19978;&#30340;&#65292;&#22823;&#22810;&#25968;&#35745;&#21010;&#21644;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#27809;&#26377;&#32771;&#34385;&#36825;&#31181;&#20016;&#23500;&#30340;&#20960;&#20309;&#32467;&#26500;&#65292;&#23548;&#33268;&#37319;&#26679;&#25928;&#29575;&#20302;&#21644;&#27867;&#21270;&#33021;&#21147;&#24369;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20869;&#22312;&#23545;&#31216;&#24615;&#35268;&#21010;&#30340;&#31561;&#21464;&#25193;&#25955;&#31639;&#27861;(EDGI), &#21487;&#29992;&#20110;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#21644;&#35268;&#21010;&#65292;&#24182;&#24341;&#20837;&#19968;&#31181;&#26032;&#30340;&#25903;&#25345;&#22810;&#31181;&#34920;&#31034;&#24418;&#24335;&#30340;&#25193;&#25955;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Embodied agents operate in a structured world, often solving tasks with spatial, temporal, and permutation symmetries. Most algorithms for planning and model-based reinforcement learning (MBRL) do not take this rich geometric structure into account, leading to sample inefficiency and poor generalization. We introduce the Equivariant Diffuser for Generating Interactions (EDGI), an algorithm for MBRL and planning that is equivariant with respect to the product of the spatial symmetry group $\mathrm{SE(3)}$, the discrete-time translation group $\mathbb{Z}$, and the object permutation group $\mathrm{S}_n$. EDGI follows the Diffuser framework (Janner et al. 2022) in treating both learning a world model and planning in it as a conditional generative modeling problem, training a diffusion model on an offline trajectory dataset. We introduce a new $\mathrm{SE(3)} \times \mathbb{Z} \times \mathrm{S}_n$-equivariant diffusion model that supports multiple representations. We integrate this model i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#20998;&#27573;&#30830;&#23450;&#24615;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#25512;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#33258;&#36866;&#24212;&#31232;&#30095;&#26041;&#26696;&#65292;&#23454;&#29616;&#20102;&#23545;&#22256;&#38590;&#37319;&#26679;&#38382;&#39064;&#30340;&#21152;&#36895;&#22788;&#29702;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#35745;&#31639;&#19978;&#21487;&#34892;&#65292;&#24182;&#33021;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12289;MCMC&#28151;&#21512;&#24615;&#33021;&#65292;&#24182;&#25552;&#20379;&#26356;&#26377;&#20449;&#24687;&#37327;&#30340;&#19981;&#30830;&#23450;&#24615;&#27979;&#37327;&#12290;</title><link>http://arxiv.org/abs/2302.08724</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#27573;&#30830;&#23450;&#24615;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Piecewise Deterministic Markov Processes for Bayesian Neural Networks. (arXiv:2302.08724v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08724
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#20998;&#27573;&#30830;&#23450;&#24615;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#25512;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#33258;&#36866;&#24212;&#31232;&#30095;&#26041;&#26696;&#65292;&#23454;&#29616;&#20102;&#23545;&#22256;&#38590;&#37319;&#26679;&#38382;&#39064;&#30340;&#21152;&#36895;&#22788;&#29702;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#35745;&#31639;&#19978;&#21487;&#34892;&#65292;&#24182;&#33021;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12289;MCMC&#28151;&#21512;&#24615;&#33021;&#65292;&#24182;&#25552;&#20379;&#26356;&#26377;&#20449;&#24687;&#37327;&#30340;&#19981;&#30830;&#23450;&#24615;&#27979;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNNs&#65289;&#30340;&#25512;&#29702;&#36890;&#24120;&#20381;&#36182;&#20110;&#21464;&#20998;&#25512;&#26029;&#22788;&#29702;&#65292;&#36825;&#35201;&#27714;&#36829;&#21453;&#20102;&#29420;&#31435;&#24615;&#21644;&#21518;&#39564;&#24418;&#24335;&#30340;&#20551;&#35774;&#12290;&#20256;&#32479;&#30340;MCMC&#26041;&#27861;&#36991;&#20813;&#20102;&#36825;&#20123;&#20551;&#35774;&#65292;&#20294;&#30001;&#20110;&#26080;&#27861;&#36866;&#24212;&#20284;&#28982;&#30340;&#23376;&#37319;&#26679;&#65292;&#23548;&#33268;&#35745;&#31639;&#37327;&#22686;&#21152;&#12290;&#26032;&#30340;&#20998;&#27573;&#30830;&#23450;&#24615;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#65288;PDMP&#65289;&#37319;&#26679;&#22120;&#20801;&#35768;&#23376;&#37319;&#26679;&#65292;&#20294;&#24341;&#20837;&#20102;&#27169;&#22411;&#29305;&#23450;&#30340;&#19981;&#22343;&#21248;&#27850;&#26494;&#36807;&#31243;&#65288;IPPs&#65289;&#65292;&#20174;&#20013;&#37319;&#26679;&#22256;&#38590;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#36890;&#29992;&#33258;&#36866;&#24212;&#31232;&#30095;&#26041;&#26696;&#65292;&#29992;&#20110;&#20174;&#36825;&#20123;IPPs&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#21152;&#36895;&#23558;PDMPs&#24212;&#29992;&#20110;BNNs&#25512;&#29702;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#20351;&#29992;&#36825;&#20123;&#26041;&#27861;&#36827;&#34892;&#25512;&#29702;&#22312;&#35745;&#31639;&#19978;&#26159;&#21487;&#34892;&#30340;&#65292;&#21487;&#20197;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12289;MCMC&#28151;&#21512;&#24615;&#33021;&#65292;&#24182;&#19982;&#20854;&#20182;&#36817;&#20284;&#25512;&#29702;&#26041;&#26696;&#30456;&#27604;&#65292;&#25552;&#20379;&#26356;&#26377;&#20449;&#24687;&#37327;&#30340;&#19981;&#30830;&#23450;&#24615;&#27979;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inference on modern Bayesian Neural Networks (BNNs) often relies on a variational inference treatment, imposing violated assumptions of independence and the form of the posterior. Traditional MCMC approaches avoid these assumptions at the cost of increased computation due to its incompatibility to subsampling of the likelihood. New Piecewise Deterministic Markov Process (PDMP) samplers permit subsampling, though introduce a model specific inhomogenous Poisson Process (IPPs) which is difficult to sample from. This work introduces a new generic and adaptive thinning scheme for sampling from these IPPs, and demonstrates how this approach can accelerate the application of PDMPs for inference in BNNs. Experimentation illustrates how inference with these methods is computationally feasible, can improve predictive accuracy, MCMC mixing performance, and provide informative uncertainty measurements when compared against other approximate inference schemes.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#32447;&#24615;&#36125;&#21494;&#26031;&#20998;&#23618;&#27169;&#22411;&#30340;Riemann&#27969;&#24418;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#30340;&#24230;&#37327;&#24352;&#37327;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#23545;&#25968;&#23494;&#24230;&#26799;&#24230;&#21327;&#26041;&#24046;&#30697;&#38453;&#26500;&#36896;&#24230;&#37327;&#24352;&#37327;&#65292;&#21487;&#20197;&#20174;&#20219;&#24847;&#22797;&#26434;&#30340;&#38750;&#32447;&#24615;&#20808;&#39564;/&#28508;&#21464;&#37327;&#32467;&#26500;&#20013;&#26500;&#24314;&#24230;&#37327;&#24352;&#37327;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#33258;&#21160;&#21270;&#30340;&#29305;&#28857;&#24182;&#20801;&#35768;&#21033;&#29992;&#27169;&#22411;&#30340;&#31232;&#30095;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.01746</link><description>&lt;p&gt;
&#23545;&#20110;Riemann&#27969;&#24418;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#30340;&#23545;&#25968;&#23494;&#24230;&#26799;&#24230;&#21327;&#26041;&#24046;&#21644;&#33258;&#21160;&#24230;&#37327;&#24352;&#37327;&#30340;&#25552;&#20986;
&lt;/p&gt;
&lt;p&gt;
Log-density gradient covariance and automatic metric tensors for Riemann manifold Monte Carlo methods. (arXiv:2211.01746v2 [stat.CO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.01746
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#32447;&#24615;&#36125;&#21494;&#26031;&#20998;&#23618;&#27169;&#22411;&#30340;Riemann&#27969;&#24418;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#30340;&#24230;&#37327;&#24352;&#37327;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#23545;&#25968;&#23494;&#24230;&#26799;&#24230;&#21327;&#26041;&#24046;&#30697;&#38453;&#26500;&#36896;&#24230;&#37327;&#24352;&#37327;&#65292;&#21487;&#20197;&#20174;&#20219;&#24847;&#22797;&#26434;&#30340;&#38750;&#32447;&#24615;&#20808;&#39564;/&#28508;&#21464;&#37327;&#32467;&#26500;&#20013;&#26500;&#24314;&#24230;&#37327;&#24352;&#37327;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#33258;&#21160;&#21270;&#30340;&#29305;&#28857;&#24182;&#20801;&#35768;&#21033;&#29992;&#27169;&#22411;&#30340;&#31232;&#30095;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#32447;&#24615;&#36125;&#21494;&#26031;&#20998;&#23618;&#27169;&#22411;&#30340;Riemann&#27969;&#24418;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#30340;&#24230;&#37327;&#24352;&#37327;&#12290;&#35813;&#24230;&#37327;&#24352;&#37327;&#30001;&#23545;&#31216;&#27491;&#21322;&#23450;&#30340;&#23545;&#25968;&#23494;&#24230;&#26799;&#24230;&#21327;&#26041;&#24046;&#65288;LGC&#65289;&#30697;&#38453;&#26500;&#24314;&#65292;&#26412;&#25991;&#36824;&#23545;&#20854;&#36827;&#34892;&#20102;&#36827;&#19968;&#27493;&#30340;&#25506;&#32034;&#12290;LGC&#21487;&#20197;&#36890;&#36807;&#27979;&#37327;&#38543;&#26426;&#21464;&#37327;&#21644;&#35813;&#21464;&#37327;&#30340;&#21442;&#25968;&#20043;&#38388;&#30340;&#32852;&#21512;&#20449;&#24687;&#20869;&#23481;&#21644;&#20381;&#36182;&#32467;&#26500;&#26469;&#25512;&#24191;&#36153;&#33293;&#23572;&#20449;&#24687;&#30697;&#38453;&#12290;&#22240;&#27492;&#65292;&#21487;&#20197;&#20174;&#35266;&#27979;&#20284;&#28982;&#20989;&#25968;&#26500;&#36896;&#27491;&#23450;&#30340;&#22522;&#20110;&#36153;&#33293;&#23572;/LGC&#30340;&#24230;&#37327;&#24352;&#37327;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#20687;&#30446;&#21069;&#30340;&#20570;&#27861;&#37027;&#26679;&#20165;&#20174;&#35266;&#27979;&#20284;&#28982;&#20989;&#25968;&#26500;&#36896;&#12290;&#21516;&#26102;&#65292;&#21482;&#35201;&#21487;&#20197;&#20026;&#29992;&#20110;&#26500;&#36896;&#36825;&#20123;&#32467;&#26500;&#30340;&#27599;&#20010;&#26465;&#20214;&#20998;&#24067;&#23548;&#20986;LGC&#65292;&#35813;&#26041;&#27861;&#23601;&#20855;&#26377;&#39640;&#24230;&#33258;&#21160;&#21270;&#30340;&#29305;&#28857;&#65292;&#24182;&#19988;&#20801;&#35768;&#21033;&#29992;&#19982;&#29305;&#23450;&#27169;&#22411;&#30456;&#20851;&#32852;&#30340;&#20219;&#20309;&#31232;&#30095;&#24615;&#12290;&#35813;&#26041;&#27861;&#19982;Riemann&#27969;&#24418;&#21464;&#20307;&#30340;&#32467;&#21512;&#23454;&#29616;&#26102;&#65292;&#21487;&#20197;&#26356;&#39640;&#25928;&#22320;&#36817;&#20284;&#27969;&#24418;&#19978;&#30340;&#27010;&#29575;&#23494;&#24230;&#65292;&#24182;&#25552;&#39640;&#37319;&#26679;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
A metric tensor for Riemann manifold Monte Carlo particularly suited for non-linear Bayesian hierarchical models is proposed. The metric tensor is built from symmetric positive semidefinite log-density gradient covariance (LGC) matrices, which are also proposed and further explored here. The LGCs generalize the Fisher information matrix by measuring the joint information content and dependence structure of both a random variable and the parameters of said variable. Consequently, positive definite Fisher/LGC-based metric tensors may be constructed not only from the observation likelihoods as is current practice, but also from arbitrarily complicated non-linear prior/latent variable structures, provided the LGC may be derived for each conditional distribution used to construct said structures. The proposed methodology is highly automatic and allows for exploitation of any sparsity associated with the model in question. When implemented in conjunction with a Riemann manifold variant of th
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#33324;&#29702;&#35770;&#26469;&#38480;&#23450;POMDP&#19982;&#20854;&#30456;&#24212;&#30340;&#26377;&#38480;&#26679;&#26412;&#31890;&#23376;&#20449;&#24565;MDP(PB-MDP)&#36924;&#36817;&#20043;&#38388;&#30340;&#35823;&#24046;&#65292;&#24182;&#23558;&#20219;&#20309;&#37319;&#26679;MDP&#31639;&#27861;&#36866;&#24212;&#21040;POMDP&#20013;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#35299;&#20915;&#20855;&#26377;&#22823;&#30340;&#25110;&#36830;&#32493;&#29366;&#24577;&#31354;&#38388;&#30340;POMDP&#30340;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2210.05015</link><description>&lt;p&gt;
&#31890;&#23376;&#20449;&#24565;&#36817;&#20284;POMDP&#30340;&#26368;&#20248;&#24615;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Optimality Guarantees for Particle Belief Approximation of POMDPs. (arXiv:2210.05015v3 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.05015
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#33324;&#29702;&#35770;&#26469;&#38480;&#23450;POMDP&#19982;&#20854;&#30456;&#24212;&#30340;&#26377;&#38480;&#26679;&#26412;&#31890;&#23376;&#20449;&#24565;MDP(PB-MDP)&#36924;&#36817;&#20043;&#38388;&#30340;&#35823;&#24046;&#65292;&#24182;&#23558;&#20219;&#20309;&#37319;&#26679;MDP&#31639;&#27861;&#36866;&#24212;&#21040;POMDP&#20013;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#35299;&#20915;&#20855;&#26377;&#22823;&#30340;&#25110;&#36830;&#32493;&#29366;&#24577;&#31354;&#38388;&#30340;POMDP&#30340;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;(POMDP)&#25552;&#20379;&#20102;&#29616;&#23454;&#20915;&#31574;&#21644;&#25511;&#21046;&#38382;&#39064;&#30340;&#28789;&#27963;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;POMDP&#30340;&#27714;&#35299;&#38750;&#24120;&#22256;&#38590;&#65292;&#29305;&#21035;&#26159;&#24403;&#29366;&#24577;&#21644;&#35266;&#27979;&#31354;&#38388;&#26159;&#36830;&#32493;&#25110;&#28151;&#21512;&#30340;&#26102;&#20505;&#65292;&#36825;&#22312;&#29289;&#29702;&#31995;&#32479;&#20013;&#32463;&#24120;&#21457;&#29983;&#12290;&#23613;&#31649;&#26368;&#36817;&#20351;&#29992;&#35266;&#27979;&#20284;&#28982;&#26435;&#37325;&#31574;&#21010;&#30340;&#22312;&#32447;&#37319;&#26679;POMDP&#31639;&#27861;&#34920;&#29616;&#20986;&#20102;&#23454;&#29992;&#30340;&#26377;&#25928;&#24615;&#65292;&#20294;&#20808;&#21069;&#24182;&#27809;&#26377;&#25552;&#20986;&#19968;&#33324;&#29702;&#35770;&#26469;&#21051;&#30011;&#36825;&#20123;&#31639;&#27861;&#20351;&#29992;&#30340;&#31890;&#23376;&#28388;&#27874;&#25216;&#26415;&#30340;&#36924;&#36817;&#35823;&#24046;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#38480;&#23450;&#20219;&#20309;POMDP&#19982;&#20854;&#30456;&#24212;&#30340;&#26377;&#38480;&#26679;&#26412;&#31890;&#23376;&#20449;&#24565;MDP(PB-MDP)&#36924;&#36817;&#20043;&#38388;&#30340;&#35823;&#24046;&#12290;&#36825;&#31181;PB-MDP&#21644;POMDP&#20043;&#38388;&#30340;&#22522;&#30784;&#26725;&#26753;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#35299;&#20915;&#30456;&#24212;&#30340;&#31890;&#23376;&#20449;&#24565;MDP&#23558;&#20219;&#20309;&#37319;&#26679;MDP&#31639;&#27861;&#36866;&#24212;&#21040;POMDP&#20013;&#65292;&#20174;&#32780;&#23558;MDP&#31639;&#27861;&#30340;&#25910;&#25947;&#20445;&#35777;&#25193;&#23637;&#21040;POMDP&#20013;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#36825;&#21487;&#20197;&#25552;&#39640;&#22312;&#35299;&#20915;&#20855;&#26377;&#22823;&#30340;&#25110;&#36830;&#32493;&#29366;&#24577;&#31354;&#38388;&#30340;POMDP&#26102;&#30340;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Partially observable Markov decision processes (POMDPs) provide a flexible representation for real-world decision and control problems. However, POMDPs are notoriously difficult to solve, especially when the state and observation spaces are continuous or hybrid, which is often the case for physical systems. While recent online sampling-based POMDP algorithms that plan with observation likelihood weighting have shown practical effectiveness, a general theory characterizing the approximation error of the particle filtering techniques that these algorithms use has not previously been proposed. Our main contribution is bounding the error between any POMDP and its corresponding finite sample particle belief MDP (PB-MDP) approximation. This fundamental bridge between PB-MDPs and POMDPs allows us to adapt any sampling-based MDP algorithm to a POMDP by solving the corresponding particle belief MDP, thereby extending the convergence guarantees of the MDP algorithm to the POMDP. Practically, thi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;-&#32858;&#31867;&#65292;&#24182;&#28145;&#20837;&#25551;&#36848;&#20102;&#26368;&#24120;&#29992;&#30340;&#32858;&#31867;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#26377;&#20851;&#21442;&#25968;&#36873;&#25321;&#21644;&#21021;&#22987;&#21270;&#30340;&#25351;&#23548;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#27604;&#36739;&#19977;&#20010;&#25968;&#25454;&#38598;&#30340;&#32858;&#31867;&#25928;&#29575;&#65292;&#25581;&#31034;&#20102;&#19981;&#21516;&#31639;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;&#22797;&#26434;&#24615;&#26041;&#38754;&#30340;&#20248;&#21155;&#12290;</title><link>http://arxiv.org/abs/2207.06949</link><description>&lt;p&gt;
&#23547;&#27714;&#25968;&#25454;&#32972;&#21518;&#30340;&#30495;&#30456;&#65306;&#19968;&#31181;&#26080;&#30417;&#30563;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Seeking the Truth Beyond the Data. An Unsupervised Machine Learning Approach. (arXiv:2207.06949v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.06949
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;-&#32858;&#31867;&#65292;&#24182;&#28145;&#20837;&#25551;&#36848;&#20102;&#26368;&#24120;&#29992;&#30340;&#32858;&#31867;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#26377;&#20851;&#21442;&#25968;&#36873;&#25321;&#21644;&#21021;&#22987;&#21270;&#30340;&#25351;&#23548;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#27604;&#36739;&#19977;&#20010;&#25968;&#25454;&#38598;&#30340;&#32858;&#31867;&#25928;&#29575;&#65292;&#25581;&#31034;&#20102;&#19981;&#21516;&#31639;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;&#22797;&#26434;&#24615;&#26041;&#38754;&#30340;&#20248;&#21155;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32858;&#31867;&#26159;&#19968;&#31181;&#26080;&#30417;&#30563;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#26410;&#26631;&#35760;&#30340;&#20803;&#32032;/&#23545;&#35937;&#20998;&#32452;&#65292;&#26088;&#22312;&#26500;&#24314;&#33391;&#22909;&#24314;&#31435;&#30340;&#32858;&#31867;&#65292;&#20854;&#20013;&#20803;&#32032;&#26681;&#25454;&#23427;&#20204;&#30340;&#30456;&#20284;&#24615;&#36827;&#34892;&#20998;&#31867;&#12290;&#35813;&#36807;&#31243;&#30340;&#30446;&#26631;&#26159;&#20026;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#26377;&#29992;&#30340;&#24110;&#21161;&#65292;&#24110;&#21161;&#20182;&#20204;&#35782;&#21035;&#25968;&#25454;&#20013;&#30340;&#27169;&#24335;&#12290;&#22788;&#29702;&#22823;&#22411;&#25968;&#25454;&#24211;&#26102;&#65292;&#36825;&#20123;&#27169;&#24335;&#21487;&#33021;&#19981;&#23481;&#26131;&#22312;&#27809;&#26377;&#32858;&#31867;&#31639;&#27861;&#30340;&#36129;&#29486;&#19979;&#26816;&#27979;&#21040;&#12290;&#26412;&#25991;&#28145;&#20837;&#25551;&#36848;&#20102;&#26368;&#24120;&#29992;&#30340;&#32858;&#31867;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#26377;&#20851;&#36866;&#24403;&#21442;&#25968;&#36873;&#25321;&#21644;&#21021;&#22987;&#21270;&#30340;&#26377;&#29992;&#20171;&#32461;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#19981;&#20165;&#26159;&#19968;&#31687;&#35780;&#35770;&#65292;&#31361;&#20986;&#20102;&#25152;&#26816;&#26597;&#30340;&#32858;&#31867;&#25216;&#26415;&#30340;&#20027;&#35201;&#35201;&#32032;&#65292;&#36824;&#36890;&#36807;&#23545;3&#20010;&#25968;&#25454;&#38598;&#30340;&#22522;&#20110;&#20934;&#30830;&#24615;&#21644;&#22797;&#26434;&#24615;&#30340;&#32858;&#31867;&#25928;&#29575;&#27604;&#36739;&#65292;&#25581;&#31034;&#20102;&#23427;&#20204;&#30340;&#29616;&#26377;&#24369;&#28857;&#21644;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Clustering is an unsupervised machine learning methodology where unlabeled elements/objects are grouped together aiming to the construction of well-established clusters that their elements are classified according to their similarity. The goal of this process is to provide a useful aid to the researcher that will help her/him to identify patterns among the data. Dealing with large databases, such patterns may not be easily detectable without the contribution of a clustering algorithm. This article provides a deep description of the most widely used clustering methodologies accompanied by useful presentations concerning suitable parameter selection and initializations. Simultaneously, this article not only represents a review highlighting the major elements of examined clustering techniques but emphasizes the comparison of these algorithms' clustering efficiency based on 3 datasets, revealing their existing weaknesses and capabilities through accuracy and complexity, during the confront
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#23558;&#21028;&#21035;&#32593;&#32476;&#36716;&#25442;&#20026;&#29983;&#25104;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#29992;&#39640;&#26031;&#26680;&#26367;&#25442;&#22810;&#38754;&#20307;&#20013;&#30340;&#20223;&#23556;&#20989;&#25968;&#26469;&#29983;&#25104;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#20869;&#37096;&#21644;&#22806;&#37096;&#25968;&#25454;&#26657;&#20934;&#38382;&#39064;&#65292;&#24182;&#22312; CIFAR-10&#65292;CIFAR-100 &#21644; SVHN &#31561;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#27979;&#35797;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2201.13001</link><description>&lt;p&gt;
&#28145;&#24230;&#21028;&#21035;&#21040;&#26680;&#29983;&#25104;&#32593;&#32476;&#30340;&#23450;&#26631;&#25512;&#26029;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Deep Discriminative to Kernel Generative Networks for Calibrated Inference. (arXiv:2201.13001v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.13001
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#23558;&#21028;&#21035;&#32593;&#32476;&#36716;&#25442;&#20026;&#29983;&#25104;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#29992;&#39640;&#26031;&#26680;&#26367;&#25442;&#22810;&#38754;&#20307;&#20013;&#30340;&#20223;&#23556;&#20989;&#25968;&#26469;&#29983;&#25104;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#20869;&#37096;&#21644;&#22806;&#37096;&#25968;&#25454;&#26657;&#20934;&#38382;&#39064;&#65292;&#24182;&#22312; CIFAR-10&#65292;CIFAR-100 &#21644; SVHN &#31561;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#27979;&#35797;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21028;&#21035;&#19982;&#29983;&#25104;&#32593;&#32476;&#22312;&#20154;&#24037;&#26234;&#33021;&#21644;&#33258;&#28982;&#26234;&#33021;&#30340;&#30740;&#31350;&#20013;&#37117;&#26377;&#20854;&#37325;&#35201;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#20108;&#32773;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#23558;&#28145;&#24230;&#21028;&#21035;&#32593;&#32476;&#36716;&#25442;&#20026;&#26680;&#29983;&#25104;&#32593;&#32476;&#12290;&#25105;&#20204;&#23558;&#28145;&#24230;&#27169;&#22411;&#35270;&#20026;&#24191;&#20041;&#30340;&#21010;&#20998;&#35268;&#21017;&#65292;&#24182;&#20351;&#29992;&#39640;&#26031;&#26680;&#26367;&#25442;&#30001;&#35757;&#32451;&#25968;&#25454;&#26500;&#25104;&#30340;&#22810;&#38754;&#20307;&#20013;&#30340;&#20223;&#23556;&#20989;&#25968;&#65292;&#26469;&#33719;&#24471;&#29983;&#25104;&#27169;&#22411;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The fight between discriminative versus generative goes deep, in both the study of artificial and natural intelligence. In our view, both camps have complementary values. So, we sought to synergistically combine them. Here, we propose a methodology to convert deep discriminative networks to kernel generative networks. We leveraged the fact that deep models, including both random forests and deep networks, learn internal representations which are unions of polytopes with affine activation functions to conceptualize them both as generalized partitioning rules. We replace the affine function in each polytope populated by the training data with Gaussian kernel that results in a generative model. Theoretically, we derive the conditions under which our generative models are a consistent estimator of the corresponding class conditional density. Moreover, our proposed models obtain well calibrated posteriors for in-distribution, and extrapolate beyond the training data to handle out-of-distrib
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#35774;&#22791;&#19978;&#39640;&#25928;&#36890;&#20449;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#32852;&#37030;&#33976;&#39311;&#21644;&#22686;&#24378;&#35299;&#20915;&#20102;&#27169;&#22411;&#22823;&#23567;&#21644;&#38750;IID&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20256;&#32479;&#30340;&#32852;&#37030;&#23398;&#20064;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#22312;&#20943;&#23569;&#36890;&#20449;&#24320;&#38144;&#30340;&#21516;&#26102;&#65292;&#20173;&#33021;&#36798;&#21040;&#36739;&#39640;&#30340;&#27979;&#35797;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/1811.11479</link><description>&lt;p&gt;
&#22312;&#35774;&#22791;&#19978;&#39640;&#25928;&#36890;&#20449;&#30340;&#26426;&#22120;&#23398;&#20064;&#65306;&#38750;IID&#31169;&#26377;&#25968;&#25454;&#19979;&#30340;&#32852;&#37030;&#33976;&#39311;&#19982;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Communication-Efficient On-Device Machine Learning: Federated Distillation and Augmentation under Non-IID Private Data. (arXiv:1811.11479v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1811.11479
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#35774;&#22791;&#19978;&#39640;&#25928;&#36890;&#20449;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#32852;&#37030;&#33976;&#39311;&#21644;&#22686;&#24378;&#35299;&#20915;&#20102;&#27169;&#22411;&#22823;&#23567;&#21644;&#38750;IID&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20256;&#32479;&#30340;&#32852;&#37030;&#23398;&#20064;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#22312;&#20943;&#23569;&#36890;&#20449;&#24320;&#38144;&#30340;&#21516;&#26102;&#65292;&#20173;&#33021;&#36798;&#21040;&#36739;&#39640;&#30340;&#27979;&#35797;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35774;&#22791;&#19978;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#20351;&#35757;&#32451;&#36807;&#31243;&#33021;&#22815;&#21033;&#29992;&#22823;&#37327;&#29992;&#25143;&#29983;&#25104;&#30340;&#31169;&#26377;&#25968;&#25454;&#26679;&#26412;&#12290;&#20026;&#20102;&#20139;&#21463;&#36825;&#19968;&#20248;&#21183;&#65292;&#24212;&#35813;&#23613;&#37327;&#20943;&#23569;&#35774;&#22791;&#38388;&#30340;&#36890;&#20449;&#24320;&#38144;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#32852;&#37030;&#33976;&#39311;&#65288;FD&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#20998;&#24067;&#24335;&#27169;&#22411;&#35757;&#32451;&#31639;&#27861;&#65292;&#20854;&#36890;&#20449;&#36127;&#36733;&#22823;&#23567;&#36828;&#23567;&#20110;&#22522;&#20934;&#26041;&#26696;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#65292;&#29305;&#21035;&#26159;&#24403;&#27169;&#22411;&#22823;&#23567;&#24456;&#22823;&#26102;&#12290;&#27492;&#22806;&#65292;&#29992;&#25143;&#29983;&#25104;&#30340;&#25968;&#25454;&#26679;&#26412;&#22312;&#35774;&#22791;&#20043;&#38388;&#24448;&#24448;&#19981;&#26159;&#29420;&#31435;&#21516;&#20998;&#24067;&#65288;IID&#65289;&#65292;&#36825;&#24120;&#24120;&#38477;&#20302;&#24615;&#33021;&#19982;IID&#25968;&#25454;&#38598;&#30456;&#27604;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#32852;&#37030;&#22686;&#24378;&#65288;FAug&#65289;&#65292;&#22312;&#36825;&#31181;&#26041;&#27861;&#20013;&#65292;&#27599;&#20010;&#35774;&#22791;&#37117;&#20849;&#21516;&#35757;&#32451;&#19968;&#20010;&#29983;&#25104;&#27169;&#22411;&#65292;&#20174;&#32780;&#22686;&#24378;&#20854;&#26412;&#22320;&#25968;&#25454;&#20197;&#20135;&#29983;IID&#25968;&#25454;&#38598;&#12290;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;FD&#19982;FAug&#30456;&#27604;FL&#65292;&#36890;&#20449;&#24320;&#38144;&#20943;&#23569;&#20102;&#32422;26&#20493;&#65292;&#21516;&#26102;&#23454;&#29616;&#20102;95-98%&#30340;&#27979;&#35797;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
On-device machine learning (ML) enables the training process to exploit a massive amount of user-generated private data samples. To enjoy this benefit, inter-device communication overhead should be minimized. With this end, we propose federated distillation (FD), a distributed model training algorithm whose communication payload size is much smaller than a benchmark scheme, federated learning (FL), particularly when the model size is large. Moreover, user-generated data samples are likely to become non-IID across devices, which commonly degrades the performance compared to the case with an IID dataset. To cope with this, we propose federated augmentation (FAug), where each device collectively trains a generative model, and thereby augments its local data towards yielding an IID dataset. Empirical studies demonstrate that FD with FAug yields around 26x less communication overhead while achieving 95-98% test accuracy compared to FL.
&lt;/p&gt;</description></item></channel></rss>