<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#23376;&#31354;&#38388;&#35782;&#21035;&#29702;&#35770;&#30340;&#22810;&#28304;&#22495;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#22495;&#20043;&#38388;&#30340;&#20559;&#31227;&#23545;&#19981;&#21464;&#21464;&#37327;&#30340;&#24433;&#21709;&#65292;&#23454;&#29616;&#20102;&#28304;&#22495;&#30340;&#30693;&#35782;&#36716;&#31227;&#21040;&#30446;&#26631;&#22495;&#12290;&#35813;&#26041;&#27861;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#26356;&#21152;&#28789;&#27963;&#65292;&#19981;&#38656;&#35201;&#28385;&#36275;&#20005;&#26684;&#30340;&#20551;&#35774;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2310.04723</link><description>&lt;p&gt;
&#22810;&#28304;&#22495;&#33258;&#36866;&#24212;&#30340;&#23376;&#31354;&#38388;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Subspace Identification for Multi-Source Domain Adaptation. (arXiv:2310.04723v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04723
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#23376;&#31354;&#38388;&#35782;&#21035;&#29702;&#35770;&#30340;&#22810;&#28304;&#22495;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#22495;&#20043;&#38388;&#30340;&#20559;&#31227;&#23545;&#19981;&#21464;&#21464;&#37327;&#30340;&#24433;&#21709;&#65292;&#23454;&#29616;&#20102;&#28304;&#22495;&#30340;&#30693;&#35782;&#36716;&#31227;&#21040;&#30446;&#26631;&#22495;&#12290;&#35813;&#26041;&#27861;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#26356;&#21152;&#28789;&#27963;&#65292;&#19981;&#38656;&#35201;&#28385;&#36275;&#20005;&#26684;&#30340;&#20551;&#35774;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#28304;&#22495;&#33258;&#36866;&#24212;&#65288;MSDA&#65289;&#26041;&#27861;&#26088;&#22312;&#23558;&#22810;&#20010;&#26377;&#26631;&#31614;&#30340;&#28304;&#22495;&#30340;&#30693;&#35782;&#36716;&#31227;&#21040;&#19968;&#20010;&#26080;&#26631;&#31614;&#30340;&#30446;&#26631;&#22495;&#20013;&#12290;&#23613;&#31649;&#24403;&#21069;&#30340;&#26041;&#27861;&#36890;&#36807;&#22312;&#22495;&#20043;&#38388;&#26045;&#21152;&#26368;&#23567;&#30340;&#21464;&#21270;&#26469;&#23454;&#29616;&#30446;&#26631;&#32852;&#21512;&#20998;&#24067;&#30340;&#21487;&#36776;&#35782;&#24615;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#38656;&#35201;&#20005;&#26684;&#30340;&#26465;&#20214;&#65292;&#22914;&#36275;&#22815;&#25968;&#37327;&#30340;&#22495;&#12289;&#28508;&#22312;&#21464;&#37327;&#30340;&#21333;&#35843;&#21464;&#25442;&#21644;&#19981;&#21464;&#30340;&#26631;&#31614;&#20998;&#24067;&#12290;&#36825;&#20123;&#35201;&#27714;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#24456;&#38590;&#28385;&#36275;&#12290;&#20026;&#20102;&#20943;&#36731;&#23545;&#36825;&#20123;&#20005;&#26684;&#20551;&#35774;&#30340;&#38656;&#27714;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23376;&#31354;&#38388;&#35782;&#21035;&#29702;&#35770;&#65292;&#23427;&#22312;&#20851;&#20110;&#22495;&#25968;&#37327;&#21644;&#21464;&#25442;&#29305;&#24615;&#26041;&#38754;&#20855;&#26377;&#36739;&#23485;&#26494;&#30340;&#32422;&#26463;&#26465;&#20214;&#65292;&#20174;&#32780;&#36890;&#36807;&#26368;&#23567;&#21270;&#22495;&#20043;&#38388;&#30340;&#20559;&#31227;&#23545;&#19981;&#21464;&#21464;&#37327;&#30340;&#24433;&#21709;&#26469;&#20419;&#36827;&#22495;&#33258;&#36866;&#24212;&#12290;&#22522;&#20110;&#36825;&#20010;&#29702;&#35770;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#21033;&#29992;&#21464;&#20998;&#25512;&#26029;&#30340;&#23376;&#31354;&#38388;&#35782;&#21035;&#20445;&#35777;&#65288;SIG&#65289;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-source domain adaptation (MSDA) methods aim to transfer knowledge from multiple labeled source domains to an unlabeled target domain. Although current methods achieve target joint distribution identifiability by enforcing minimal changes across domains, they often necessitate stringent conditions, such as an adequate number of domains, monotonic transformation of latent variables, and invariant label distributions. These requirements are challenging to satisfy in real-world applications. To mitigate the need for these strict assumptions, we propose a subspace identification theory that guarantees the disentanglement of domain-invariant and domain-specific variables under less restrictive constraints regarding domain numbers and transformation properties, thereby facilitating domain adaptation by minimizing the impact of domain shifts on invariant variables. Based on this theory, we develop a Subspace Identification Guarantee (SIG) model that leverages variational inference. Furth
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25193;&#23637;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#20351;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;BDCM&#65292;&#21487;&#20197;&#22312;&#23384;&#22312;&#26080;&#27861;&#27979;&#37327;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#26356;&#20934;&#30830;&#22320;&#22238;&#31572;&#22240;&#26524;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.03669</link><description>&lt;p&gt;
&#26080;&#27861;&#27979;&#37327;&#28151;&#28102;&#22240;&#32032;&#19979;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Diffusion Model in Causal Inference with Unmeasured Confounders. (arXiv:2308.03669v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03669
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25193;&#23637;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#20351;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;BDCM&#65292;&#21487;&#20197;&#22312;&#23384;&#22312;&#26080;&#27861;&#27979;&#37327;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#26356;&#20934;&#30830;&#22320;&#22238;&#31572;&#22240;&#26524;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22914;&#20309;&#22312;&#26080;&#27861;&#27979;&#37327;&#30340;&#28151;&#28102;&#22240;&#32032;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#25193;&#23637;&#25193;&#25955;&#27169;&#22411;&#30340;&#20351;&#29992;&#65292;&#20197;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#22238;&#31572;&#22240;&#26524;&#38382;&#39064;&#12290;&#22312;Pearl&#30340;&#20351;&#29992;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#25429;&#25417;&#22240;&#26524;&#24178;&#39044;&#30340;&#26694;&#26550;&#20013;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#22240;&#26524;&#27169;&#22411;&#65288;DCM&#65289;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#22238;&#31572;&#22240;&#26524;&#38382;&#39064;&#65292;&#20551;&#35774;&#25152;&#26377;&#28151;&#28102;&#22240;&#32032;&#37117;&#26159;&#21487;&#20197;&#35266;&#23519;&#21040;&#30340;&#12290;&#28982;&#32780;&#65292;&#23454;&#38469;&#20013;&#23384;&#22312;&#26080;&#27861;&#27979;&#37327;&#30340;&#28151;&#28102;&#22240;&#32032;&#65292;&#36825;&#20351;&#24471;DCM&#26080;&#27861;&#24212;&#29992;&#12290;&#20026;&#20102;&#32531;&#35299;DCM&#30340;&#36825;&#19968;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25193;&#23637;&#27169;&#22411;&#65292;&#31216;&#20026;&#22522;&#20110;&#21453;&#38376;&#20934;&#21017;&#30340;DCM&#65288;BDCM&#65289;&#65292;&#20854;&#24605;&#24819;&#26681;&#26893;&#20110;&#22312;DAG&#20013;&#25214;&#21040;&#35201;&#21253;&#25324;&#22312;&#25193;&#25955;&#27169;&#22411;&#35299;&#30721;&#36807;&#31243;&#20013;&#30340;&#21464;&#37327;&#30340;&#21453;&#38376;&#20934;&#21017;&#65292;&#36825;&#26679;&#25105;&#20204;&#21487;&#20197;&#23558;DCM&#25193;&#23637;&#21040;&#23384;&#22312;&#26080;&#27861;&#27979;&#37327;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#12290;&#21512;&#25104;&#25968;&#25454;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#27169;&#22411;&#22312;&#26080;&#27861;&#27979;&#37327;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#26356;&#31934;&#30830;&#22320;&#25429;&#25417;&#21040;&#20102;&#21453;&#20107;&#23454;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study how to extend the use of the diffusion model to answer the causal question from the observational data under the existence of unmeasured confounders. In Pearl's framework of using a Directed Acyclic Graph (DAG) to capture the causal intervention, a Diffusion-based Causal Model (DCM) was proposed incorporating the diffusion model to answer the causal questions more accurately, assuming that all of the confounders are observed. However, unmeasured confounders in practice exist, which hinders DCM from being applicable. To alleviate this limitation of DCM, we propose an extended model called Backdoor Criterion based DCM (BDCM), whose idea is rooted in the Backdoor criterion to find the variables in DAG to be included in the decoding process of the diffusion model so that we can extend DCM to the case with unmeasured confounders. Synthetic data experiment demonstrates that our proposed model captures the counterfactual distribution more precisely than DCM under the unmeasured confo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20855;&#26377;&#22823;&#21160;&#20316;&#31354;&#38388;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#30340;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#65288;MDR&#65289;&#12290;&#19982;&#29616;&#26377;&#30340;&#22522;&#20934;&#20272;&#35745;&#22120;&#30456;&#27604;&#65292;MDR&#33021;&#22815;&#22312;&#20943;&#23567;&#26041;&#24046;&#30340;&#21516;&#26102;&#20445;&#25345;&#26080;&#20559;&#24615;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#23454;&#20102;MDR&#30456;&#23545;&#20110;&#29616;&#26377;&#20272;&#35745;&#22120;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.03443</link><description>&lt;p&gt;
&#29992;&#20110;&#20855;&#26377;&#22823;&#21160;&#20316;&#31354;&#38388;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#30340;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
Doubly Robust Estimator for Off-Policy Evaluation with Large Action Spaces. (arXiv:2308.03443v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03443
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20855;&#26377;&#22823;&#21160;&#20316;&#31354;&#38388;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#30340;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#65288;MDR&#65289;&#12290;&#19982;&#29616;&#26377;&#30340;&#22522;&#20934;&#20272;&#35745;&#22120;&#30456;&#27604;&#65292;MDR&#33021;&#22815;&#22312;&#20943;&#23567;&#26041;&#24046;&#30340;&#21516;&#26102;&#20445;&#25345;&#26080;&#20559;&#24615;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#23454;&#20102;MDR&#30456;&#23545;&#20110;&#29616;&#26377;&#20272;&#35745;&#22120;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20855;&#26377;&#22823;&#21160;&#20316;&#31354;&#38388;&#30340;&#32972;&#26223;&#19979;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#65288;OPE&#65289;&#12290;&#29616;&#26377;&#30340;&#22522;&#20934;&#20272;&#35745;&#22120;&#23384;&#22312;&#20005;&#37325;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#25240;&#34935;&#38382;&#39064;&#12290;&#21442;&#25968;&#21270;&#26041;&#27861;&#30001;&#20110;&#24456;&#38590;&#30830;&#23450;&#27491;&#30830;&#30340;&#27169;&#22411;&#32780;&#23548;&#33268;&#20559;&#24046;&#65292;&#32780;&#37325;&#35201;&#24615;&#21152;&#26435;&#26041;&#27861;&#30001;&#20110;&#26041;&#24046;&#32780;&#20135;&#29983;&#38382;&#39064;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#21028;&#21035;&#24335;&#30340;&#19981;&#33391;&#34892;&#20026;&#25233;&#21046;&#22120;&#65288;MIPS&#65289;&#26469;&#36890;&#36807;&#23545;&#21160;&#20316;&#30340;&#23884;&#20837;&#26469;&#20943;&#23567;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#12290;&#20026;&#20102;&#20351;&#20272;&#35745;&#22120;&#26356;&#20934;&#30830;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;MIPS&#30340;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#8212;&#8212;&#36793;&#38469;&#21270;&#21452;&#37325;&#31283;&#20581;&#65288;MDR&#65289;&#20272;&#35745;&#22120;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#22312;&#27604;MIPS&#26356;&#24369;&#30340;&#20551;&#35774;&#19979;&#26159;&#26080;&#20559;&#30340;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#23545;IPS&#30340;&#26041;&#24046;&#20943;&#23567;&#65292;&#36825;&#26159;MIPS&#30340;&#20027;&#35201;&#20248;&#21183;&#12290;&#32463;&#39564;&#23454;&#39564;&#35777;&#23454;&#20102;MDR&#30456;&#23545;&#20110;&#29616;&#26377;&#20272;&#35745;&#22120;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study Off-Policy Evaluation (OPE) in contextual bandit settings with large action spaces. The benchmark estimators suffer from severe bias and variance tradeoffs. Parametric approaches suffer from bias due to difficulty specifying the correct model, whereas ones with importance weight suffer from variance. To overcome these limitations, Marginalized Inverse Propensity Scoring (MIPS) was proposed to mitigate the estimator's variance via embeddings of an action. To make the estimator more accurate, we propose the doubly robust estimator of MIPS called the Marginalized Doubly Robust (MDR) estimator. Theoretical analysis shows that the proposed estimator is unbiased under weaker assumptions than MIPS while maintaining variance reduction against IPS, which was the main advantage of MIPS. The empirical experiment verifies the supremacy of MDR against existing estimators.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22823;&#25968;&#25454;-&#20379;&#24212;&#38142;&#31649;&#29702;&#26694;&#26550;&#65292;&#36890;&#36807;&#25968;&#25454;&#39044;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#23454;&#29616;&#20379;&#24212;&#38142;&#39044;&#27979;&#65292;&#20248;&#21270;&#25805;&#20316;&#31649;&#29702;&#12289;&#36879;&#26126;&#24230;&#65292;&#24182;&#35752;&#35770;&#20102;&#24187;&#24433;&#24211;&#23384;&#23545;&#39044;&#27979;&#30340;&#19981;&#21033;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2307.12971</link><description>&lt;p&gt;
&#22823;&#25968;&#25454;-&#20379;&#24212;&#38142;&#31649;&#29702;&#26694;&#26550;&#30340;&#39044;&#27979;&#65306;&#25968;&#25454;&#39044;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Big Data - Supply Chain Management Framework for Forecasting: Data Preprocessing and Machine Learning Techniques. (arXiv:2307.12971v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12971
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22823;&#25968;&#25454;-&#20379;&#24212;&#38142;&#31649;&#29702;&#26694;&#26550;&#65292;&#36890;&#36807;&#25968;&#25454;&#39044;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#23454;&#29616;&#20379;&#24212;&#38142;&#39044;&#27979;&#65292;&#20248;&#21270;&#25805;&#20316;&#31649;&#29702;&#12289;&#36879;&#26126;&#24230;&#65292;&#24182;&#35752;&#35770;&#20102;&#24187;&#24433;&#24211;&#23384;&#23545;&#39044;&#27979;&#30340;&#19981;&#21033;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#31995;&#32479;&#22320;&#35782;&#21035;&#21644;&#27604;&#36739;&#20998;&#26512;&#26368;&#20808;&#36827;&#30340;&#20379;&#24212;&#38142;&#39044;&#27979;&#31574;&#30053;&#21644;&#25216;&#26415;&#12290;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#23558;&#22823;&#25968;&#25454;&#20998;&#26512;&#24212;&#29992;&#20110;&#20379;&#24212;&#38142;&#31649;&#29702;&#20013;&#65292;&#21253;&#25324;&#38382;&#39064;&#35782;&#21035;&#12289;&#25968;&#25454;&#26469;&#28304;&#12289;&#25506;&#32034;&#24615;&#25968;&#25454;&#20998;&#26512;&#12289;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#35757;&#32451;&#12289;&#36229;&#21442;&#25968;&#35843;&#20248;&#12289;&#24615;&#33021;&#35780;&#20272;&#21644;&#20248;&#21270;&#65292;&#20197;&#21450;&#39044;&#27979;&#23545;&#20154;&#21147;&#12289;&#24211;&#23384;&#21644;&#25972;&#20010;&#20379;&#24212;&#38142;&#30340;&#24433;&#21709;&#12290;&#39318;&#20808;&#35752;&#35770;&#20102;&#26681;&#25454;&#20379;&#24212;&#38142;&#31574;&#30053;&#25910;&#38598;&#25968;&#25454;&#30340;&#38656;&#27714;&#20197;&#21450;&#22914;&#20309;&#25910;&#38598;&#25968;&#25454;&#12290;&#25991;&#31456;&#35752;&#35770;&#20102;&#26681;&#25454;&#21608;&#26399;&#25110;&#20379;&#24212;&#38142;&#30446;&#26631;&#38656;&#35201;&#19981;&#21516;&#31867;&#22411;&#30340;&#39044;&#27979;&#12290;&#25512;&#33616;&#20351;&#29992;&#20379;&#24212;&#38142;&#32489;&#25928;&#25351;&#26631;&#21644;&#35823;&#24046;&#27979;&#37327;&#31995;&#32479;&#26469;&#20248;&#21270;&#34920;&#29616;&#26368;&#20339;&#30340;&#27169;&#22411;&#12290;&#36824;&#35752;&#35770;&#20102;&#24187;&#24433;&#24211;&#23384;&#23545;&#39044;&#27979;&#30340;&#19981;&#21033;&#24433;&#21709;&#20197;&#21450;&#31649;&#29702;&#20915;&#31574;&#20381;&#36182;&#20379;&#24212;&#38142;&#32489;&#25928;&#25351;&#26631;&#26469;&#30830;&#23450;&#27169;&#22411;&#24615;&#33021;&#21442;&#25968;&#21644;&#25913;&#36827;&#36816;&#33829;&#31649;&#29702;&#12289;&#36879;&#26126;&#24230;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article intends to systematically identify and comparatively analyze state-of-the-art supply chain (SC) forecasting strategies and technologies. A novel framework has been proposed incorporating Big Data Analytics in SC Management (problem identification, data sources, exploratory data analysis, machine-learning model training, hyperparameter tuning, performance evaluation, and optimization), forecasting effects on human-workforce, inventory, and overall SC. Initially, the need to collect data according to SC strategy and how to collect them has been discussed. The article discusses the need for different types of forecasting according to the period or SC objective. The SC KPIs and the error-measurement systems have been recommended to optimize the top-performing model. The adverse effects of phantom inventory on forecasting and the dependence of managerial decisions on the SC KPIs for determining model performance parameters and improving operations management, transparency, and 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;LFlows&#27169;&#22411;&#65292;&#23427;&#20351;&#29992;&#21487;&#24494;&#21644;&#21487;&#36870;&#30340;&#21464;&#25442;&#65292;&#22312;&#26102;&#38388;&#19978;&#35268;&#23450;&#21442;&#25968;&#21270;&#30340;&#24494;&#20998;&#21516;&#32986;&#21464;&#25442;&#26469;&#23545;&#22522;&#30784;&#23494;&#24230;&#36827;&#34892;&#36716;&#25442;&#65292;&#20197;&#36830;&#32493;&#22320;&#24314;&#27169;&#27969;&#20307;&#23494;&#24230;&#21644;&#36895;&#24230;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;&#20854;&#20248;&#21183;&#22312;&#20110;&#36895;&#24230;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#24635;&#26159;&#19982;&#23494;&#24230;&#20445;&#25345;&#19968;&#33268;&#65292;&#26080;&#38656;&#26114;&#36149;&#30340;&#25968;&#20540;&#27714;&#35299;&#22120;&#65292;&#20063;&#26080;&#38656;&#20351;&#29992;&#24809;&#32602;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.16846</link><description>&lt;p&gt;
&#25289;&#26684;&#26391;&#26085;&#27969;&#32593;&#32476;&#29992;&#20110;&#23432;&#24658;&#23450;&#24459;
&lt;/p&gt;
&lt;p&gt;
Lagrangian Flow Networks for Conservation Laws. (arXiv:2305.16846v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16846
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;LFlows&#27169;&#22411;&#65292;&#23427;&#20351;&#29992;&#21487;&#24494;&#21644;&#21487;&#36870;&#30340;&#21464;&#25442;&#65292;&#22312;&#26102;&#38388;&#19978;&#35268;&#23450;&#21442;&#25968;&#21270;&#30340;&#24494;&#20998;&#21516;&#32986;&#21464;&#25442;&#26469;&#23545;&#22522;&#30784;&#23494;&#24230;&#36827;&#34892;&#36716;&#25442;&#65292;&#20197;&#36830;&#32493;&#22320;&#24314;&#27169;&#27969;&#20307;&#23494;&#24230;&#21644;&#36895;&#24230;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;&#20854;&#20248;&#21183;&#22312;&#20110;&#36895;&#24230;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#24635;&#26159;&#19982;&#23494;&#24230;&#20445;&#25345;&#19968;&#33268;&#65292;&#26080;&#38656;&#26114;&#36149;&#30340;&#25968;&#20540;&#27714;&#35299;&#22120;&#65292;&#20063;&#26080;&#38656;&#20351;&#29992;&#24809;&#32602;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#25289;&#26684;&#26391;&#26085;&#27969;&#32593;&#32476;&#65288;LFlows&#65289;&#65292;&#29992;&#20110;&#36830;&#32493;&#22320;&#24314;&#27169;&#27969;&#20307;&#23494;&#24230;&#21644;&#36895;&#24230;&#12290;&#25152;&#25552;&#20986;&#30340;LFlows&#22522;&#20110;&#36830;&#32493;&#26041;&#31243;&#30340;&#35299;&#65292;&#20854;&#20013;&#36830;&#32493;&#26041;&#31243;&#26159;&#25551;&#36848;&#19981;&#21516;&#24418;&#24335;&#30340;&#36136;&#37327;&#23432;&#24658;&#24615;&#36136;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#22522;&#20110;&#36825;&#26679;&#30340;&#24605;&#36335;&#65306;&#36830;&#32493;&#26041;&#31243;&#30340;&#35299;&#21487;&#20197;&#36890;&#36807;&#21487;&#24494;&#21644;&#21487;&#36870;&#30340;&#21464;&#25442;&#34920;&#31034;&#20026;&#26102;&#38388;&#20381;&#36182;&#30340;&#23494;&#24230;&#21464;&#25442;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#26102;&#38388;&#19978;&#35268;&#23450;&#21442;&#25968;&#21270;&#30340;&#24494;&#20998;&#21516;&#32986;&#21464;&#25442;&#26469;&#23545;&#22522;&#30784;&#23494;&#24230;&#36827;&#34892;&#36716;&#25442;&#20197;&#24314;&#27169;&#27969;&#20307;&#23494;&#24230;&#12290;&#19982;&#20381;&#36182;&#20110;Neural-ODE&#25110;PINNs&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;&#20851;&#38190;&#30340;&#20248;&#21183;&#22312;&#20110;&#36895;&#24230;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#22987;&#32456;&#19982;&#23494;&#24230;&#20445;&#25345;&#19968;&#33268;&#12290;&#27492;&#22806;&#65292;&#26080;&#38656;&#26114;&#36149;&#30340;&#25968;&#20540;&#27714;&#35299;&#22120;&#65292;&#20063;&#26080;&#38656;&#20351;&#29992;&#24809;&#32602;&#26041;&#27861;&#26469;&#23454;&#26045;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#25289;&#26684;&#26391;&#26085;&#27969;&#32593;&#32476;&#22312;&#21512;&#25104;&#23494;&#24230;&#25968;&#25454;&#19978;&#26174;&#31034;&#20986;&#20102;&#26356;&#39640;&#30340;&#39044;&#27979;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce Lagrangian Flow Networks (LFlows) for modeling fluid densities and velocities continuously in space and time. The proposed LFlows satisfy by construction the continuity equation, a PDE describing mass conservation in its differentiable form. Our model is based on the insight that solutions to the continuity equation can be expressed as time-dependent density transformations via differentiable and invertible maps. This follows from classical theory of existence and uniqueness of Lagrangian flows for smooth vector fields. Hence, we model fluid densities by transforming a base density with parameterized diffeomorphisms conditioned on time. The key benefit compared to methods relying on Neural-ODE or PINNs is that the analytic expression of the velocity is always consistent with the density. Furthermore, there is no need for expensive numerical solvers, nor for enforcing the PDE with penalty methods. Lagrangian Flow Networks show improved predictive accuracy on synthetic densi
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#23558;&#20998;&#26512;&#21644;&#25968;&#20540;&#25512;&#23548;&#32467;&#21512;&#65292;&#22312;&#22522;&#20110;&#24191;&#20041; Potts &#27169;&#22411;&#30340;&#25968;&#25454;&#19978;&#65292;&#23545;&#32463;&#36807;&#25913;&#36827;&#36866;&#24212;&#36825;&#31181;&#27169;&#22411;&#30340;self-attention&#26426;&#21046;&#36827;&#34892;&#35757;&#32451;&#65292;&#21457;&#29616;&#32463;&#36807;&#20462;&#25913;&#30340;self-attention&#26426;&#21046;&#21487;&#20197;&#22312;&#26497;&#38480;&#37319;&#26679;&#19979;&#20934;&#30830;&#23398;&#20064;Potts&#27169;&#22411;&#12290;&#36825;&#20010;&#8220;&#20998;&#35299;&#8221;&#27880;&#24847;&#21147;&#26426;&#21046;&#36890;&#36807;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#30456;&#20851;&#23646;&#24615;&#65292;&#21487;&#20197;&#25552;&#39640;Transformer&#30340;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.07235</link><description>&lt;p&gt;
&#21033;&#29992;&#20998;&#35299;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#21333;&#23618;Transformer&#23545;&#24191;&#20041;Potts&#27169;&#22411;&#36827;&#34892;&#26368;&#20248;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Optimal inference of a generalised Potts model by single-layer transformers with factored attention. (arXiv:2304.07235v1 [cond-mat.dis-nn])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07235
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#20998;&#26512;&#21644;&#25968;&#20540;&#25512;&#23548;&#32467;&#21512;&#65292;&#22312;&#22522;&#20110;&#24191;&#20041; Potts &#27169;&#22411;&#30340;&#25968;&#25454;&#19978;&#65292;&#23545;&#32463;&#36807;&#25913;&#36827;&#36866;&#24212;&#36825;&#31181;&#27169;&#22411;&#30340;self-attention&#26426;&#21046;&#36827;&#34892;&#35757;&#32451;&#65292;&#21457;&#29616;&#32463;&#36807;&#20462;&#25913;&#30340;self-attention&#26426;&#21046;&#21487;&#20197;&#22312;&#26497;&#38480;&#37319;&#26679;&#19979;&#20934;&#30830;&#23398;&#20064;Potts&#27169;&#22411;&#12290;&#36825;&#20010;&#8220;&#20998;&#35299;&#8221;&#27880;&#24847;&#21147;&#26426;&#21046;&#36890;&#36807;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#30456;&#20851;&#23646;&#24615;&#65292;&#21487;&#20197;&#25552;&#39640;Transformer&#30340;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer &#26159;&#19968;&#31181;&#38761;&#21629;&#24615;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#34507;&#30333;&#36136;&#31185;&#23398;&#26041;&#38754;&#21462;&#24471;&#20102;&#23454;&#36341;&#19978;&#30340;&#25104;&#21151;&#12290;&#23427;&#20204;&#30340;&#20851;&#38190;&#26500;&#24314;&#22359;&#26159;&#19968;&#20010;&#21483;&#20570;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26426;&#21046;&#65292;&#23427;&#34987;&#35757;&#32451;&#29992;&#20110;&#39044;&#27979;&#21477;&#23376;&#20013;&#32570;&#22833;&#30340;&#35789;&#12290;&#23613;&#31649;Transformer&#22312;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#23454;&#36341;&#19978;&#30340;&#25104;&#21151;&#65292;&#20294;&#26159;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#31350;&#31455;&#20174;&#25968;&#25454;&#20013;&#23398;&#21040;&#20102;&#20160;&#20040;&#20197;&#21450;&#23427;&#26159;&#24590;&#20040;&#20570;&#21040;&#30340;&#36824;&#19981;&#26159;&#24456;&#28165;&#26970;&#12290;&#26412;&#25991;&#38024;&#23545;&#20174;&#20855;&#26377;&#30456;&#20114;&#20316;&#29992;&#30340;&#20301;&#32622;&#21644; Potts &#39068;&#33394;&#20013;&#25552;&#21462;&#30340;&#25968;&#25454;&#22312;&#35757;&#32451;&#30340;Transformer&#19978;&#32473;&#20986;&#20102;&#31934;&#30830;&#30340;&#20998;&#26512;&#21644;&#25968;&#20540;&#21051;&#30011;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#34429;&#28982;&#19968;&#33324;&#30340;transformer&#38656;&#35201;&#22810;&#23618;&#23398;&#20064;&#25165;&#33021;&#20934;&#30830;&#23398;&#20064;&#36825;&#20010;&#20998;&#24067;&#65292;&#20294;&#26159;&#32463;&#36807;&#23567;&#25913;&#36827;&#30340;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#22312;&#26080;&#38480;&#37319;&#26679;&#30340;&#26497;&#38480;&#19979;&#21487;&#20197;&#23436;&#32654;&#22320;&#23398;&#20064;Potts&#27169;&#22411;&#12290;&#25105;&#20204;&#36824;&#35745;&#31639;&#20102;&#36825;&#20010;&#20462;&#25913;&#21518;&#30340;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#25152;&#35859;&#8220;&#20998;&#35299;&#8221;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#25968;&#20540;&#28436;&#31034;&#20102;&#25105;&#20204;&#30340;&#21457;&#29616;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;&#35299;&#37322;Transformer&#30340;&#20869;&#22312;&#24037;&#20316;&#21407;&#29702;&#20197;&#21450;&#25552;&#39640;&#20854;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#25552;&#20379;&#20102;&#26032;&#30340;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformers are the type of neural networks that has revolutionised natural language processing and protein science. Their key building block is a mechanism called self-attention which is trained to predict missing words in sentences. Despite the practical success of transformers in applications it remains unclear what self-attention learns from data, and how. Here, we give a precise analytical and numerical characterisation of transformers trained on data drawn from a generalised Potts model with interactions between sites and Potts colours. While an off-the-shelf transformer requires several layers to learn this distribution, we show analytically that a single layer of self-attention with a small modification can learn the Potts model exactly in the limit of infinite sampling. We show that this modified self-attention, that we call ``factored'', has the same functional form as the conditional probability of a Potts spin given the other spins, compute its generalisation error using t
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#37325;&#26032;&#23457;&#35270;&#32852;&#37030;&#24179;&#22343;&#31639;&#27861;&#65292;&#22312;&#26368;&#23567;&#20551;&#35774;&#19979;&#23545;&#20998;&#24067;&#24335;&#38750;&#20984;&#30446;&#26631;&#36827;&#34892;&#20102;&#38543;&#26426;&#20248;&#21270;&#65292;&#24314;&#31435;&#20102;&#20165;&#28385;&#36275;&#38543;&#26426;&#26799;&#24230;&#28201;&#21644;&#26465;&#20214;&#30340;&#25910;&#25947;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2301.12677</link><description>&lt;p&gt;
&#36890;&#29992;&#26041;&#24046;&#26465;&#20214;&#19979;&#30340;&#20998;&#24067;&#24335;&#38543;&#26426;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Distributed Stochastic Optimization under a General Variance Condition. (arXiv:2301.12677v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12677
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#37325;&#26032;&#23457;&#35270;&#32852;&#37030;&#24179;&#22343;&#31639;&#27861;&#65292;&#22312;&#26368;&#23567;&#20551;&#35774;&#19979;&#23545;&#20998;&#24067;&#24335;&#38750;&#20984;&#30446;&#26631;&#36827;&#34892;&#20102;&#38543;&#26426;&#20248;&#21270;&#65292;&#24314;&#31435;&#20102;&#20165;&#28385;&#36275;&#38543;&#26426;&#26799;&#24230;&#28201;&#21644;&#26465;&#20214;&#30340;&#25910;&#25947;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#24335;&#38543;&#26426;&#20248;&#21270;&#22312;&#35299;&#20915;&#22823;&#35268;&#27169;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#26102;&#34920;&#29616;&#20986;&#20102;&#24456;&#39640;&#30340;&#25928;&#29575;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#24182;&#25104;&#21151;&#24212;&#29992;&#20110;&#19968;&#33324;&#23454;&#38469;&#38382;&#39064;&#30340;&#31639;&#27861;&#24456;&#22810;&#65292;&#20294;&#23427;&#20204;&#30340;&#29702;&#35770;&#20445;&#35777;&#20027;&#35201;&#20381;&#36182;&#20110;&#38543;&#26426;&#26799;&#24230;&#30340;&#26576;&#20123;&#26377;&#30028;&#26465;&#20214;&#65292;&#20174;&#22343;&#21248;&#26377;&#30028;&#24615;&#21040;&#25918;&#26494;&#22686;&#38271;&#26465;&#20214;&#12290;&#27492;&#22806;&#65292;&#22312;&#20195;&#29702;&#20043;&#38388;&#34920;&#24449;&#25968;&#25454;&#24322;&#36136;&#24615;&#21450;&#20854;&#23545;&#31639;&#27861;&#24615;&#33021;&#30340;&#24433;&#21709;&#20381;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20986;&#20110;&#36825;&#26679;&#30340;&#21160;&#26426;&#65292;&#25105;&#20204;&#37325;&#26032;&#32771;&#34385;&#20102;&#32463;&#20856;&#30340;&#32852;&#37030;&#24179;&#22343;&#65288;FedAvg&#65289;&#31639;&#27861;&#65292;&#20197;&#35299;&#20915;&#20998;&#24067;&#24335;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#22312;&#24179;&#28369;&#38750;&#20984;&#30446;&#26631;&#20989;&#25968;&#30340;&#38543;&#26426;&#26799;&#24230;&#20165;&#28385;&#36275;&#28201;&#21644;&#26041;&#24046;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#24314;&#31435;&#20102;&#25910;&#25947;&#32467;&#26524;&#12290;&#22312;&#27492;&#26465;&#20214;&#19979;&#65292;&#36824;&#24314;&#31435;&#20102;&#25509;&#36817;&#30830;&#23450;&#30340;&#25910;&#25947;&#21040;&#19968;&#20010;&#31283;&#24577;&#28857;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#19968;&#20010;&#26356;&#20855;&#20449;&#24687;&#24615;&#30340;&#24230;&#37327;&#26631;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distributed stochastic optimization has drawn great attention recently due to its effectiveness in solving large-scale machine learning problems. Though numerous algorithms have been proposed and successfully applied to general practical problems, their theoretical guarantees mainly rely on certain boundedness conditions on the stochastic gradients, varying from uniform boundedness to the relaxed growth condition. In addition, how to characterize the data heterogeneity among the agents and its impacts on the algorithmic performance remains challenging. In light of such motivations, we revisit the classical Federated Averaging (FedAvg) algorithm for solving the distributed stochastic optimization problem and establish the convergence results under only a mild variance condition on the stochastic gradients for smooth nonconvex objective functions. Almost sure convergence to a stationary point is also established under the condition. Moreover, we discuss a more informative measurement for
&lt;/p&gt;</description></item></channel></rss>