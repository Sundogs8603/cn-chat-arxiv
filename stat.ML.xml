<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>FastAMI&#26159;&#19968;&#31181;&#29992;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#30340;&#32858;&#31867;&#27604;&#36739;&#30340;&#24555;&#36895;&#26041;&#27861;&#65292;&#36890;&#36807;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#26469;&#23454;&#29616;&#20598;&#28982;&#24615;&#35843;&#25972;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#25490;&#21015;&#30340;&#26041;&#27861;&#26356;&#20934;&#30830;&#12290;</title><link>http://arxiv.org/abs/2305.03022</link><description>&lt;p&gt;
FastAMI -- &#19968;&#31181;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#29992;&#20110;&#32858;&#31867;&#27604;&#36739;&#24230;&#37327;&#20013;&#30340;&#20598;&#28982;&#24615;&#35843;&#25972;
&lt;/p&gt;
&lt;p&gt;
FastAMI -- a Monte Carlo Approach to the Adjustment for Chance in Clustering Comparison Metrics. (arXiv:2305.03022v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03022
&lt;/p&gt;
&lt;p&gt;
FastAMI&#26159;&#19968;&#31181;&#29992;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#30340;&#32858;&#31867;&#27604;&#36739;&#30340;&#24555;&#36895;&#26041;&#27861;&#65292;&#36890;&#36807;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#26469;&#23454;&#29616;&#20598;&#28982;&#24615;&#35843;&#25972;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#25490;&#21015;&#30340;&#26041;&#27861;&#26356;&#20934;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32858;&#31867;&#26159;&#26426;&#22120;&#23398;&#20064;&#30340;&#26680;&#24515;&#65292;&#38543;&#30528;&#25968;&#25454;&#21487;&#29992;&#24615;&#30340;&#22686;&#21152;&#65292;&#20854;&#24212;&#29992;&#26085;&#30410;&#22686;&#22810;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#25968;&#25454;&#38598;&#30340;&#22686;&#38271;&#65292;&#24102;&#26377;&#20598;&#28982;&#24615;&#35843;&#25972;&#30340;&#32858;&#31867;&#27604;&#36739;&#21464;&#24471;&#35745;&#31639;&#22256;&#38590;&#65292;&#23548;&#33268;&#27809;&#26377;&#20559;&#35265;&#30340;&#30495;&#23454;&#27604;&#36739;&#21644;&#35299;&#20915;&#26041;&#26696;&#36873;&#25321;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;FastAMI&#65292;&#19968;&#31181;&#22522;&#20110;&#33945;&#29305;&#21345;&#32599;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#25928;&#22320;&#20272;&#35745;&#32463;&#36807;&#35843;&#25972;&#30340;&#20114;&#20449;&#24687;&#65288;AMI&#65289;&#24182;&#23558;&#20854;&#25193;&#23637;&#21040;&#26631;&#20934;&#21270;&#20114;&#20449;&#24687;&#65288;SMI&#65289;&#12290;&#19982;&#20934;&#30830;&#35745;&#31639;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36275;&#22815;&#24555;&#65292;&#21487;&#20197;&#20026;&#22823;&#22411;&#25968;&#25454;&#38598;&#21551;&#29992;&#36825;&#20123;&#24102;&#26377;&#35843;&#25972;&#30340;&#20449;&#24687;&#35770;&#27604;&#36739;&#65292;&#21516;&#26102;&#20445;&#25345;&#27604;&#37197;&#23545;&#26041;&#27861;&#26356;&#20934;&#30830;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Clustering is at the very core of machine learning, and its applications proliferate with the increasing availability of data. However, as datasets grow, comparing clusterings with an adjustment for chance becomes computationally difficult, preventing unbiased ground-truth comparisons and solution selection. We propose FastAMI, a Monte Carlo-based method to efficiently approximate the Adjusted Mutual Information (AMI) and extend it to the Standardized Mutual Information (SMI). The approach is compared with the exact calculation and a recently developed variant of the AMI based on pairwise permutations, using both synthetic and real data. In contrast to the exact calculation our method is fast enough to enable these adjusted information-theoretic comparisons for large datasets while maintaining considerably more accurate results than the pairwise approach.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#23545;176&#20010;&#25968;&#25454;&#38598;&#30340;&#27604;&#36739;&#20998;&#26512;&#21457;&#29616;&#65292;&#22312;&#35768;&#22810;&#25968;&#25454;&#38598;&#20013;&#65292;GBDT&#21644;NN&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#24322;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#65292;&#25110;&#32773;GBDT&#30340;&#36731;&#24494;&#36229;&#21442;&#25968;&#35843;&#25972;&#27604;&#36873;&#25321;&#26368;&#20339;&#31639;&#27861;&#26356;&#37325;&#35201;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#20154;&#21592;&#23545;965&#20010;&#20803;&#29305;&#24449;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#21457;&#29616;GBDT&#22312;&#39640;&#32500;&#31232;&#30095;&#25968;&#25454;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2305.02997</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20309;&#26102;&#22312;&#34920;&#26684;&#25968;&#25454;&#19978;&#32988;&#36807;&#22686;&#24378;&#26641;&#65311;
&lt;/p&gt;
&lt;p&gt;
When Do Neural Nets Outperform Boosted Trees on Tabular Data?. (arXiv:2305.02997v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02997
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#23545;176&#20010;&#25968;&#25454;&#38598;&#30340;&#27604;&#36739;&#20998;&#26512;&#21457;&#29616;&#65292;&#22312;&#35768;&#22810;&#25968;&#25454;&#38598;&#20013;&#65292;GBDT&#21644;NN&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#24322;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#65292;&#25110;&#32773;GBDT&#30340;&#36731;&#24494;&#36229;&#21442;&#25968;&#35843;&#25972;&#27604;&#36873;&#25321;&#26368;&#20339;&#31639;&#27861;&#26356;&#37325;&#35201;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#20154;&#21592;&#23545;965&#20010;&#20803;&#29305;&#24449;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#21457;&#29616;GBDT&#22312;&#39640;&#32500;&#31232;&#30095;&#25968;&#25454;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34920;&#26684;&#25968;&#25454;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#24120;&#29992;&#30340;&#25968;&#25454;&#31867;&#22411;&#20043;&#19968;&#12290;&#23613;&#31649;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#22312;&#34920;&#26684;&#25968;&#25454;&#19978;&#21462;&#24471;&#20102;&#26368;&#36817;&#30340;&#36827;&#23637;&#65292;&#20294;&#20154;&#20204;&#20173;&#22312;&#31215;&#26497;&#35752;&#35770;NN&#26159;&#21542;&#36890;&#24120;&#20248;&#20110;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#65288;GBDT&#65289;&#22312;&#34920;&#26684;&#25968;&#25454;&#19978;&#30340;&#34920;&#29616;&#65292;&#19968;&#20123;&#26368;&#36817;&#30340;&#24037;&#20316;&#35201;&#20040;&#35748;&#20026;GBDT&#22312;&#34920;&#26684;&#25968;&#25454;&#19978;&#19968;&#36143;&#20248;&#20110;NN&#65292;&#35201;&#20040;&#35748;&#20026;NN&#20248;&#20110;GBDT&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36864;&#19968;&#27493;&#38382;&#65306;'&#36825;&#37325;&#35201;&#21527;&#65311;'&#25105;&#20204;&#36890;&#36807;&#23545;176&#20010;&#25968;&#25454;&#38598;&#27604;&#36739;19&#31181;&#31639;&#27861;&#65292;&#36827;&#34892;&#20102;&#36804;&#20170;&#20026;&#27490;&#26368;&#22823;&#30340;&#34920;&#26684;&#25968;&#25454;&#20998;&#26512;&#65292;&#24182;&#21457;&#29616;'NN vs. GBDT'&#20105;&#35770;&#34987;&#36807;&#20998;&#24378;&#35843;&#65306;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#22312;&#30456;&#24403;&#22810;&#30340;&#25968;&#25454;&#38598;&#20013;&#65292;GBDT&#21644;NN&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#24322;&#35201;&#20040;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#65292;&#35201;&#20040;GBDT&#30340;&#36731;&#24494;&#36229;&#21442;&#25968;&#35843;&#25972;&#27604;&#36873;&#25321;&#26368;&#20339;&#31639;&#27861;&#26356;&#37325;&#35201;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;965&#20010;&#20803;&#29305;&#24449;&#65292;&#20197;&#30830;&#23450;&#25968;&#25454;&#38598;&#30340;&#21738;&#20123;&#29305;&#24615;&#20351;NN&#25110;GBDT&#26356;&#36866;&#21512;&#34920;&#29616;&#33391;&#22909;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#21457;&#29616;GBDT&#35201;&#27604;NN&#22312;&#39640;&#32500;&#31232;&#30095;&#25968;&#25454;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tabular data is one of the most commonly used types of data in machine learning. Despite recent advances in neural nets (NNs) for tabular data, there is still an active discussion on whether or not NNs generally outperform gradient-boosted decision trees (GBDTs) on tabular data, with several recent works arguing either that GBDTs consistently outperform NNs on tabular data, or vice versa. In this work, we take a step back and ask, 'does it matter?' We conduct the largest tabular data analysis to date, by comparing 19 algorithms across 176 datasets, and we find that the 'NN vs. GBDT' debate is overemphasized: for a surprisingly high number of datasets, either the performance difference between GBDTs and NNs is negligible, or light hyperparameter tuning on a GBDT is more important than selecting the best algorithm. Next, we analyze 965 metafeatures to determine what properties of a dataset make NNs or GBDTs better-suited to perform well. For example, we find that GBDTs are much better th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#35770;&#30340;&#36235;&#21183;&#27979;&#24230;&#23450;&#29702;&#35270;&#35282;&#65292;&#35813;&#35270;&#35282;&#23558;&#38543;&#26426;&#36807;&#31243;&#30340;&#26377;&#38480;&#24615;&#19982;&#32034;&#24341;&#24230;&#37327;&#31354;&#38388;&#20803;&#32032;&#30340;&#26377;&#25928;&#21487;&#21464;&#38271;&#24230;&#32534;&#30721;&#30340;&#23384;&#22312;&#24615;&#30456;&#20851;&#32852;&#12290;</title><link>http://arxiv.org/abs/2305.02960</link><description>&lt;p&gt;
Majorizing Measures, Codes, and Information&#65288;&#27979;&#24230;&#20027;&#23548;&#12289;&#30721;&#21644;&#20449;&#24687;&#65289;
&lt;/p&gt;
&lt;p&gt;
Majorizing Measures, Codes, and Information. (arXiv:2305.02960v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02960
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#35770;&#30340;&#36235;&#21183;&#27979;&#24230;&#23450;&#29702;&#35270;&#35282;&#65292;&#35813;&#35270;&#35282;&#23558;&#38543;&#26426;&#36807;&#31243;&#30340;&#26377;&#38480;&#24615;&#19982;&#32034;&#24341;&#24230;&#37327;&#31354;&#38388;&#20803;&#32032;&#30340;&#26377;&#25928;&#21487;&#21464;&#38271;&#24230;&#32534;&#30721;&#30340;&#23384;&#22312;&#24615;&#30456;&#20851;&#32852;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Fernique&#21644;Talagrand&#30340;&#36235;&#21183;&#27979;&#24230;&#23450;&#29702;&#26159;&#38543;&#26426;&#36807;&#31243;&#29702;&#35770;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#32467;&#26524;&#12290;&#23427;&#23558;&#24230;&#37327;&#31354;&#38388;&#20013;&#20803;&#32032;&#32034;&#24341;&#30340;&#38543;&#26426;&#36807;&#31243;&#30340;&#26377;&#38480;&#24615;&#19982;&#26469;&#33258;&#26576;&#20123;&#22810;&#23610;&#24230;&#32452;&#21512;&#32467;&#26500;&#65288;&#22914;&#22635;&#20805;&#21644;&#35206;&#30422;&#26641;&#65289;&#30340;&#22797;&#26434;&#24615;&#24230;&#37327;&#30456;&#20851;&#32852;&#12290;&#26412;&#25991;&#22312;Andreas Maurer&#30340;&#19968;&#20221;&#40092;&#20026;&#20154;&#30693;&#30340;&#39044;&#21360;&#26412;&#20013;&#39318;&#27425;&#27010;&#36848;&#30340;&#24605;&#36335;&#19978;&#26500;&#24314;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#35770;&#30340;&#36235;&#21183;&#27979;&#24230;&#23450;&#29702;&#35270;&#35282;&#65292;&#26681;&#25454;&#35813;&#35270;&#35282;&#65292;&#38543;&#26426;&#36807;&#31243;&#30340;&#26377;&#38480;&#24615;&#26159;&#29992;&#32034;&#24341;&#24230;&#37327;&#31354;&#38388;&#20803;&#32032;&#30340;&#26377;&#25928;&#21487;&#21464;&#38271;&#24230;&#32534;&#30721;&#30340;&#23384;&#22312;&#24615;&#26469;&#34920;&#36848;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
The majorizing measure theorem of Fernique and Talagrand is a fundamental result in the theory of random processes. It relates the boundedness of random processes indexed by elements of a metric space to complexity measures arising from certain multiscale combinatorial structures, such as packing and covering trees. This paper builds on the ideas first outlined in a little-noticed preprint of Andreas Maurer to present an information-theoretic perspective on the majorizing measure theorem, according to which the boundedness of random processes is phrased in terms of the existence of efficient variable-length codes for the elements of the indexing metric space.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#26435;&#37325;&#24433;&#21709;&#30340;&#35745;&#25968;&#36172;&#21338;&#26426;(WTB)&#35774;&#32622;&#65292;&#36890;&#36807;Repeated Exposure Optimality(REO)&#26469;&#30740;&#31350;&#23427;&#12290;&#20182;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#26469;&#28385;&#36275;REO&#65292;&#24182;&#25552;&#20379;&#20102;&#26368;&#20248;&#30340;&#36951;&#25022;&#36793;&#30028;&#12290;</title><link>http://arxiv.org/abs/2305.02955</link><description>&lt;p&gt;
&#21463;&#26435;&#37325;&#24433;&#21709;&#30340;&#35745;&#25968;&#36172;&#21338;&#26426;: &#36890;&#36807;&#37325;&#22797;&#26292;&#38706;&#26469;&#20811;&#26381;&#19981;&#21487;&#35299;&#24615;
&lt;/p&gt;
&lt;p&gt;
Weighted Tallying Bandits: Overcoming Intractability via Repeated Exposure Optimality. (arXiv:2305.02955v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02955
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#26435;&#37325;&#24433;&#21709;&#30340;&#35745;&#25968;&#36172;&#21338;&#26426;(WTB)&#35774;&#32622;&#65292;&#36890;&#36807;Repeated Exposure Optimality(REO)&#26469;&#30740;&#31350;&#23427;&#12290;&#20182;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#26469;&#28385;&#36275;REO&#65292;&#24182;&#25552;&#20379;&#20102;&#26368;&#20248;&#30340;&#36951;&#25022;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22312;&#32447;&#23398;&#20064;&#30340;&#25512;&#33616;&#31995;&#32479;&#25110;&#20247;&#21253;&#24212;&#29992;&#20013;&#65292;&#20154;&#31867;&#30340;&#20559;&#22909;&#25110;&#33021;&#21147;&#36890;&#24120;&#26159;&#31639;&#27861;&#26368;&#36817;&#34892;&#21160;&#30340;&#19968;&#20010;&#20989;&#25968;&#12290; &#30456;&#20851;&#24037;&#20316;&#24050;&#32463;&#24418;&#24335;&#21270;&#20102;&#35774;&#32622;&#65292;&#22312;&#36825;&#20123;&#35774;&#32622;&#20013;&#65292;&#34892;&#21160;&#30340;&#25439;&#22833;&#26159;&#26368;&#36817;$m$&#20010;&#26102;&#38388;&#27493;&#20013;&#35813;&#34892;&#21160;&#30340;&#25773;&#25918;&#27425;&#25968;&#30340;&#20989;&#25968;&#65292;&#20854;&#20013;$m$&#23545;&#24212;&#20110;&#20154;&#31867;&#35760;&#24518;&#33021;&#21147;&#30340;&#19978;&#38480;&#12290; &#20026;&#20102;&#26356;&#24544;&#23454;&#22320;&#21453;&#26144;&#20154;&#31867;&#35760;&#24518;&#38543;&#26102;&#38388;&#30340;&#34928;&#20943;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#21463;&#26435;&#37325;&#24433;&#21709;&#30340;&#35745;&#25968;&#36172;&#21338;&#26426;(WTB)&#65292;&#23427;&#36890;&#36807;&#35201;&#27714;&#34892;&#21160;&#25439;&#22833;&#26159;&#26368;&#36817;$m$&#20010;&#26102;&#38388;&#27493;&#20013;&#35813;&#33218;&#34987;&#29609;&#30340;&#27425;&#25968;&#30340;&#21152;&#26435;&#24635;&#21644;&#30340;&#20989;&#25968;&#26469;&#27010;&#25324;&#36825;&#20010;&#35774;&#32622;&#12290;&#38500;&#38750;&#36827;&#19968;&#27493;&#20551;&#35774;&#65292;&#21542;&#21017;WTB&#35774;&#32622;&#26159;&#19981;&#21487;&#35299;&#30340;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#22312;Repeated Exposure Optimality(REO)&#19979;&#30740;&#31350;&#20102;&#23427;&#65292;&#35813;&#26465;&#20214;&#26159;&#21463;&#20154;&#20307;&#29983;&#29702;&#23398;&#25991;&#29486;&#30340;&#21551;&#21457;&#65292;&#23427;&#35201;&#27714;&#23384;&#22312;&#19968;&#31181;&#34892;&#21160;&#65292;&#24403;&#21453;&#22797;&#25773;&#25918;&#26102;&#65292;&#26368;&#32456;&#23558;&#20135;&#29983;&#27604;&#20219;&#20309;&#20854;&#20182;&#34892;&#21160;&#26356;&#23567;&#30340;&#25439;&#22833;&#12290; &#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#28385;&#36275;WTB&#35774;&#32622;&#19979;&#30340;REO&#65292;&#24182;&#25552;&#20379;&#20102;&#26368;&#20248;&#22320;&#32553;&#25918;$m$&#21644;&#34892;&#21160;&#38598;&#22823;&#23567;&#30340;&#36951;&#25022;&#36793;&#30028;&#12290; &#25105;&#20204;&#30340;&#35777;&#26126;&#25216;&#26415;&#35201;&#27714;&#22312;&#19968;&#31181;&#35299;&#32806;&#24418;&#24335;&#19979;&#36827;&#34892;&#26032;&#39062;&#30340;&#27987;&#24230;&#32467;&#26524;&#65292;&#36825;&#21487;&#33021;&#26159;&#29420;&#31435;&#24863;&#20852;&#36259;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recommender system or crowdsourcing applications of online learning, a human's preferences or abilities are often a function of the algorithm's recent actions. Motivated by this, a significant line of work has formalized settings where an action's loss is a function of the number of times that action was recently played in the prior $m$ timesteps, where $m$ corresponds to a bound on human memory capacity. To more faithfully capture decay of human memory with time, we introduce the Weighted Tallying Bandit (WTB), which generalizes this setting by requiring that an action's loss is a function of a \emph{weighted} summation of the number of times that arm was played in the last $m$ timesteps. This WTB setting is intractable without further assumption. So we study it under Repeated Exposure Optimality (REO), a condition motivated by the literature on human physiology, which requires the existence of an action that when repetitively played will eventually yield smaller loss than any othe
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#20998;&#27573;&#24402;&#19968;&#21270;&#27969;&#26041;&#27861;&#65292;&#23558;&#30446;&#26631;&#20998;&#24067;&#20998;&#25104;&#38598;&#32676;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#27169;&#25311;&#22797;&#26434;&#30340;&#22810;&#27169;&#24577;&#30446;&#26631;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#26356;&#22909;&#22320;&#21305;&#37197;&#26631;&#20934;&#27491;&#24577;&#22522;&#30784;&#20998;&#24067;&#30340;&#25299;&#25169;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2305.02930</link><description>&lt;p&gt;
&#20998;&#27573;&#24402;&#19968;&#21270;&#27969;
&lt;/p&gt;
&lt;p&gt;
Piecewise Normalizing Flows. (arXiv:2305.02930v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02930
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#20998;&#27573;&#24402;&#19968;&#21270;&#27969;&#26041;&#27861;&#65292;&#23558;&#30446;&#26631;&#20998;&#24067;&#20998;&#25104;&#38598;&#32676;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#27169;&#25311;&#22797;&#26434;&#30340;&#22810;&#27169;&#24577;&#30446;&#26631;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#26356;&#22909;&#22320;&#21305;&#37197;&#26631;&#20934;&#27491;&#24577;&#22522;&#30784;&#20998;&#24067;&#30340;&#25299;&#25169;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24402;&#19968;&#21270;&#27969;&#26159;&#19968;&#31181;&#36890;&#36807;&#20174;&#22522;&#30784;&#20998;&#24067;&#36827;&#34892;&#21487;&#36870;&#36716;&#25442;&#26469;&#23545;&#22797;&#26434;&#27010;&#29575;&#23494;&#24230;&#36827;&#34892;&#24314;&#27169;&#30340;&#25104;&#29087;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#30446;&#26631;&#20998;&#24067;&#33021;&#21542;&#31934;&#30830;&#22320;&#34987;&#24402;&#19968;&#21270;&#27969;&#25152;&#25429;&#25417;&#65292;&#24378;&#28872;&#21463;&#21040;&#22522;&#30784;&#20998;&#24067;&#30340;&#25299;&#25169;&#32467;&#26500;&#30340;&#24433;&#21709;&#12290;&#30446;&#26631;&#21644;&#22522;&#30784;&#20998;&#24067;&#20043;&#38388;&#30340;&#25299;&#25169;&#19981;&#21305;&#37197;&#21487;&#33021;&#23548;&#33268;&#24615;&#33021;&#24046;&#65292;&#22914;&#23545;&#20110;&#22810;&#27169;&#24577;&#38382;&#39064;&#12290;&#19968;&#20123;&#19981;&#21516;&#30340;&#24037;&#20316;&#35797;&#22270;&#36890;&#36807;&#20351;&#29992;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411; [Izmailov et al., 2020&#12289;Ardizzone et al., 2020&#12289;Hagemann and Neumayer, 2021] &#25110;&#23398;&#20064;&#25509;&#21463;/&#25298;&#32477;&#37319;&#26679; [Stimper et al., 2022] &#26469;&#20462;&#25913;&#22522;&#30784;&#20998;&#24067;&#30340;&#25299;&#25169;&#32467;&#26500;&#20197;&#26356;&#22909;&#22320;&#21305;&#37197;&#30446;&#26631;&#20998;&#24067;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#20998;&#27573;&#24402;&#19968;&#21270;&#27969;&#65292;&#23558;&#30446;&#26631;&#20998;&#24067;&#20998;&#25104;&#38598;&#32676;&#65292;&#24182;&#35757;&#32451;&#19968;&#31995;&#21015;&#27969;&#26469;&#27169;&#25311;&#22797;&#26434;&#30340;&#22810;&#27169;&#24577;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Normalizing flows are an established approach for modelling complex probability densities through invertible transformations from a base distribution. However, the accuracy with which the target distribution can be captured by the normalizing flow is strongly influenced by the topology of the base distribution. A mismatch between the topology of the target and the base can result in a poor performance, as is the case for multi-modal problems. A number of different works have attempted to modify the topology of the base distribution to better match the target, either through the use of Gaussian Mixture Models [Izmailov et al., 2020, Ardizzone et al., 2020, Hagemann and Neumayer, 2021] or learned accept/reject sampling [Stimper et al., 2022]. We introduce piecewise normalizing flows which divide the target distribution into clusters, with topologies that better match the standard normal base distribution, and train a series of flows to model complex multi-modal targets. The piecewise nat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22522;&#20110;&#19968;&#33268;&#24615;&#20248;&#21270;&#65288;CBO&#65289;&#30340;&#24605;&#24819;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#20114;&#21160;&#31890;&#23376;&#31995;&#32479;&#23454;&#29616;&#23545;&#20110;&#32858;&#31867;&#32852;&#37030;&#23398;&#20064;&#20013;&#21508;&#20010;&#32676;&#32452;&#30340;&#26377;&#25928;&#27169;&#22411;&#35757;&#32451;.</title><link>http://arxiv.org/abs/2305.02894</link><description>&lt;p&gt;
&#21033;&#29992;&#19968;&#33268;&#24615;&#20248;&#21270;&#23454;&#29616;&#38598;&#32676;&#32852;&#37030;&#23398;&#20064;&#30340;&#32452;&#20849;&#35782;
&lt;/p&gt;
&lt;p&gt;
FedCBO: Reaching Group Consensus in Clustered Federated Learning through Consensus-based Optimization. (arXiv:2305.02894v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02894
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22522;&#20110;&#19968;&#33268;&#24615;&#20248;&#21270;&#65288;CBO&#65289;&#30340;&#24605;&#24819;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#20114;&#21160;&#31890;&#23376;&#31995;&#32479;&#23454;&#29616;&#23545;&#20110;&#32858;&#31867;&#32852;&#37030;&#23398;&#20064;&#20013;&#21508;&#20010;&#32676;&#32452;&#30340;&#26377;&#25928;&#27169;&#22411;&#35757;&#32451;.
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26159;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#37325;&#35201;&#26694;&#26550;&#65292;&#26088;&#22312;&#25972;&#21512;&#26469;&#33258;&#22810;&#20010;&#29992;&#25143;&#30340;&#23398;&#20064;&#27169;&#22411;&#30340;&#35757;&#32451;&#65292;&#27599;&#20010;&#29992;&#25143;&#37117;&#26377;&#33258;&#24049;&#30340;&#26412;&#22320;&#25968;&#25454;&#38598;&#65292;&#20197;&#28385;&#36275;&#25968;&#25454;&#38544;&#31169;&#21644;&#36890;&#20449;&#20002;&#22833;&#32422;&#26463;&#12290;&#22312;&#32858;&#31867;&#32852;&#37030;&#23398;&#20064;&#20013;&#65292;&#20551;&#35774;&#29992;&#25143;&#20043;&#38388;&#23384;&#22312;&#38468;&#21152;&#30340;&#26410;&#30693;&#32676;&#32452;&#32467;&#26500;&#65292;&#24182;&#19988;&#30446;&#26631;&#26159;&#35757;&#32451;&#23545;&#27599;&#20010;&#32676;&#32452;&#26377;&#29992;&#30340;&#27169;&#22411;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#20026;&#25152;&#26377;&#29992;&#25143;&#35757;&#32451;&#19968;&#20010;&#21333;&#19968;&#30340;&#20840;&#23616;&#27169;&#22411;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#19968;&#33268;&#24615;&#20248;&#21270;&#65288;CBO&#65289;&#30340;&#24605;&#24819;&#65292;&#35299;&#20915;&#20102;&#32858;&#31867;&#32852;&#37030;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26032;&#22411;CBO&#31867;&#22411;&#26041;&#27861;&#22522;&#20110;&#19968;&#20010;&#20114;&#21160;&#31890;&#23376;&#31995;&#32479;&#65292;&#24573;&#30053;&#20102;&#32676;&#32452;&#25104;&#21592;&#36164;&#26684;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#24471;&#21040;&#20102;&#20005;&#26684;&#30340;&#25968;&#23398;&#25512;&#29702;&#25903;&#25345;&#65292;&#21253;&#25324;&#25551;&#36848;&#25105;&#20204;&#30340;&#31890;&#23376;&#31995;&#32479;&#22823;&#37327;&#31890;&#23376;&#26497;&#38480;&#30340;&#24179;&#22343;&#22330;&#20998;&#26512;&#65292;&#20197;&#21450;&#21516;&#26102;&#20840;&#23616;&#20248;&#21270;&#30340;&#25910;&#25947;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated learning is an important framework in modern machine learning that seeks to integrate the training of learning models from multiple users, each user having their own local data set, in a way that is sensitive to data privacy and to communication loss constraints. In clustered federated learning, one assumes an additional unknown group structure among users, and the goal is to train models that are useful for each group, rather than simply training a single global model for all users. In this paper, we propose a novel solution to the problem of clustered federated learning that is inspired by ideas in consensus-based optimization (CBO). Our new CBO-type method is based on a system of interacting particles that is oblivious to group memberships. Our model is motivated by rigorous mathematical reasoning, including a mean field analysis describing the large number of particles limit of our particle system, as well as convergence guarantees for the simultaneous global optimization
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#37327;&#23376;&#29983;&#25104;&#27169;&#22411;&#30340;&#21487;&#35757;&#32451;&#24615;&#38556;&#30861;&#65292;&#22914;&#33618;&#33436;&#39640;&#21407;&#21644;&#25351;&#25968;&#25439;&#22833;&#38598;&#20013;&#65292;&#20351;&#29992;&#38544;&#24335;&#29983;&#25104;&#27169;&#22411;&#21644;&#26126;&#30830;&#25439;&#22833;&#20250;&#20135;&#29983;&#19968;&#31181;&#26032;&#30340;&#33618;&#33436;&#39640;&#21407;&#29616;&#35937;&#12290;&#26368;&#22823;&#22343;&#20540;&#24046;&#21487;&#20197;&#26159;&#20302;&#31209;&#19988;&#21487;&#35757;&#32451;&#30340;&#25110;&#20840;&#23616;&#24615;&#19988;&#19981;&#21487;&#35757;&#32451;&#30340;&#12290;&#20294;&#26159;&#65292;&#21487;&#35757;&#32451;&#24615;&#25152;&#38656;&#30340;&#20302;&#31209;&#25439;&#22833;&#36890;&#24120;&#19981;&#33021;&#21306;&#20998;&#39640;&#39057;&#21644;&#20302;&#39057;&#29305;&#24449;&#12290;</title><link>http://arxiv.org/abs/2305.02881</link><description>&lt;p&gt;
&#37327;&#23376;&#29983;&#25104;&#24314;&#27169;&#20013;&#30340;&#21487;&#35757;&#32451;&#24615;&#38556;&#30861;&#21644;&#26426;&#36935;
&lt;/p&gt;
&lt;p&gt;
Trainability barriers and opportunities in quantum generative modeling. (arXiv:2305.02881v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02881
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#37327;&#23376;&#29983;&#25104;&#27169;&#22411;&#30340;&#21487;&#35757;&#32451;&#24615;&#38556;&#30861;&#65292;&#22914;&#33618;&#33436;&#39640;&#21407;&#21644;&#25351;&#25968;&#25439;&#22833;&#38598;&#20013;&#65292;&#20351;&#29992;&#38544;&#24335;&#29983;&#25104;&#27169;&#22411;&#21644;&#26126;&#30830;&#25439;&#22833;&#20250;&#20135;&#29983;&#19968;&#31181;&#26032;&#30340;&#33618;&#33436;&#39640;&#21407;&#29616;&#35937;&#12290;&#26368;&#22823;&#22343;&#20540;&#24046;&#21487;&#20197;&#26159;&#20302;&#31209;&#19988;&#21487;&#35757;&#32451;&#30340;&#25110;&#20840;&#23616;&#24615;&#19988;&#19981;&#21487;&#35757;&#32451;&#30340;&#12290;&#20294;&#26159;&#65292;&#21487;&#35757;&#32451;&#24615;&#25152;&#38656;&#30340;&#20302;&#31209;&#25439;&#22833;&#36890;&#24120;&#19981;&#33021;&#21306;&#20998;&#39640;&#39057;&#21644;&#20302;&#39057;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#29983;&#25104;&#27169;&#22411;&#25552;&#20379;&#20102;&#26412;&#36136;&#39640;&#25928;&#30340;&#37319;&#26679;&#31574;&#30053;&#65292;&#22240;&#27492;&#22312;&#37327;&#23376;&#30828;&#20214;&#19978;&#23454;&#29616;&#36817;&#26399;&#20248;&#21183;&#26377;&#24456;&#22823;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#21487;&#25193;&#23637;&#24615;&#20173;&#23384;&#22312;&#37325;&#35201;&#38382;&#39064;&#12290;&#26412;&#25991;&#30740;&#31350;&#37327;&#23376;&#29983;&#25104;&#27169;&#22411;&#30340;&#21487;&#35757;&#32451;&#24615;&#38556;&#30861;&#65292;&#22914;&#33618;&#33436;&#39640;&#21407;&#21644;&#25351;&#25968;&#25439;&#22833;&#38598;&#20013;&#12290;&#25105;&#20204;&#25506;&#32034;&#20102;&#26126;&#30830;&#21644;&#38544;&#21547;&#27169;&#22411;&#12289;&#25439;&#22833;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#34920;&#26126;&#20351;&#29992;&#38544;&#24335;&#29983;&#25104;&#27169;&#22411;&#65288;&#22914;&#22522;&#20110;&#37327;&#23376;&#30005;&#36335;&#30340;&#27169;&#22411;&#65289;&#21644;&#26126;&#30830;&#25439;&#22833;&#65288;&#22914;KL&#25955;&#24230;&#65289;&#20250;&#20135;&#29983;&#19968;&#31181;&#26032;&#30340;&#33618;&#33436;&#39640;&#21407;&#29616;&#35937;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#26368;&#22823;&#22343;&#20540;&#24046;&#65288;MMD&#65289;&#65292;&#20316;&#20026;&#38544;&#24335;&#25439;&#22833;&#30340;&#19968;&#20010;&#27969;&#34892;&#20363;&#23376;&#65292;&#21487;&#20197;&#30475;&#20316;&#26159;&#19968;&#20010;&#35266;&#27979;&#37327;&#30340;&#26399;&#26395;&#20540;&#65292;&#35813;&#35266;&#27979;&#37327;&#21487;&#33021;&#26159;&#20302;&#31209;&#19988;&#21487;&#35757;&#32451;&#30340;&#65292;&#20063;&#21487;&#33021;&#26159;&#20840;&#23616;&#24615;&#19988;&#19981;&#21487;&#35757;&#32451;&#30340;&#65292;&#20855;&#20307;&#21462;&#20915;&#20110;&#26680;&#20989;&#25968;&#30340;&#36873;&#25321;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21516;&#26102;&#24378;&#35843;&#65292;&#21487;&#35757;&#32451;&#24615;&#25152;&#38656;&#30340;&#20302;&#31209;&#25439;&#22833;&#36890;&#24120;&#19981;&#33021;&#21306;&#20998;&#39640;&#39057;&#21644;&#20302;&#39057;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantum generative models, in providing inherently efficient sampling strategies, show promise for achieving a near-term advantage on quantum hardware. Nonetheless, important questions remain regarding their scalability. In this work, we investigate the barriers to the trainability of quantum generative models posed by barren plateaus and exponential loss concentration. We explore the interplay between explicit and implicit models and losses, and show that using implicit generative models (such as quantum circuit-based models) with explicit losses (such as the KL divergence) leads to a new flavour of barren plateau. In contrast, the Maximum Mean Discrepancy (MMD), which is a popular example of an implicit loss, can be viewed as the expectation value of an observable that is either low-bodied and trainable, or global and untrainable depending on the choice of kernel. However, in parallel, we highlight that the low-bodied losses required for trainability cannot in general distinguish hig
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#22312;&#23384;&#22312;&#20559;&#35265;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#23376;&#27169;&#20989;&#25968;&#26469;&#20248;&#21270;&#25512;&#33616;&#31995;&#32479;&#12290;&#20808;&#21069;&#30740;&#31350;&#25351;&#20986;&#65292;&#22522;&#20110;&#20844;&#24179;&#24615;&#32422;&#26463;&#30340;&#24178;&#39044;&#21487;&#20197;&#30830;&#20445;&#27604;&#20363;&#20195;&#34920;&#24615;&#65292;&#24182;&#22312;&#23384;&#22312;&#20559;&#35265;&#26102;&#33719;&#24471;&#25509;&#36817;&#26368;&#20248;&#30340;&#25928;&#29992;&#12290;&#32780;&#26412;&#25991;&#21017;&#25506;&#35752;&#20102;&#19968;&#32452;&#33021;&#22815;&#25429;&#25417;&#36825;&#31181;&#30446;&#30340;&#30340;&#23376;&#27169;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2305.02806</link><description>&lt;p&gt;
&#22312;&#23384;&#22312;&#20559;&#35265;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#22823;&#21270;&#23376;&#27169;&#20989;&#25968;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Maximizing Submodular Functions for Recommendation in the Presence of Biases. (arXiv:2305.02806v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02806
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#22312;&#23384;&#22312;&#20559;&#35265;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#23376;&#27169;&#20989;&#25968;&#26469;&#20248;&#21270;&#25512;&#33616;&#31995;&#32479;&#12290;&#20808;&#21069;&#30740;&#31350;&#25351;&#20986;&#65292;&#22522;&#20110;&#20844;&#24179;&#24615;&#32422;&#26463;&#30340;&#24178;&#39044;&#21487;&#20197;&#30830;&#20445;&#27604;&#20363;&#20195;&#34920;&#24615;&#65292;&#24182;&#22312;&#23384;&#22312;&#20559;&#35265;&#26102;&#33719;&#24471;&#25509;&#36817;&#26368;&#20248;&#30340;&#25928;&#29992;&#12290;&#32780;&#26412;&#25991;&#21017;&#25506;&#35752;&#20102;&#19968;&#32452;&#33021;&#22815;&#25429;&#25417;&#36825;&#31181;&#30446;&#30340;&#30340;&#23376;&#27169;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23376;&#38598;&#36873;&#25321;&#20219;&#21153;&#22312;&#25512;&#33616;&#31995;&#32479;&#21644;&#25628;&#32034;&#24341;&#25806;&#20013;&#32463;&#24120;&#20986;&#29616;&#65292;&#35201;&#27714;&#36873;&#25321;&#19968;&#20123;&#26368;&#22823;&#21270;&#29992;&#25143;&#20215;&#20540;&#30340;&#29289;&#21697;&#23376;&#38598;&#12290;&#23376;&#38598;&#30340;&#20215;&#20540;&#24448;&#24448;&#21576;&#29616;&#20986;&#36882;&#20943;&#30340;&#22238;&#25253;&#65292;&#22240;&#27492;&#65292;&#20351;&#29992;&#23376;&#27169;&#20989;&#25968;&#26469;&#24314;&#27169;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#21457;&#29616;&#36755;&#20837;&#20855;&#26377;&#31038;&#20250;&#20559;&#35265;&#65292;&#20250;&#38477;&#20302;&#36755;&#20986;&#23376;&#38598;&#30340;&#25928;&#29992;&#65292;&#22240;&#27492;&#38656;&#35201;&#24178;&#39044;&#20197;&#25552;&#39640;&#20854;&#25928;&#29992;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#32452;&#23376;&#27169;&#20989;&#25968;&#30340;&#26368;&#22823;&#21270;&#65292;&#36825;&#20123;&#20989;&#25968;&#28085;&#30422;&#20102;&#19978;&#36848;&#24212;&#29992;&#20013;&#20986;&#29616;&#30340;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Subset selection tasks, arise in recommendation systems and search engines and ask to select a subset of items that maximize the value for the user. The values of subsets often display diminishing returns, and hence, submodular functions have been used to model them. If the inputs defining the submodular function are known, then existing algorithms can be used. In many applications, however, inputs have been observed to have social biases that reduce the utility of the output subset. Hence, interventions to improve the utility are desired. Prior works focus on maximizing linear functions -- a special case of submodular functions -- and show that fairness constraint-based interventions can not only ensure proportional representation but also achieve near-optimal utility in the presence of biases. We study the maximization of a family of submodular functions that capture functions arising in the aforementioned applications. Our first result is that, unlike linear functions, constraint-ba
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#21306;&#22495;&#25551;&#36848;&#31526;&#65292;&#23427;&#26159;&#19968;&#31181;&#27169;&#22411;&#26080;&#20851;&#30340;&#23616;&#37096;&#35299;&#37322;&#26041;&#27861;&#65292;&#36890;&#36807;&#25551;&#36848;&#36229;&#31435;&#26041;&#20307;&#26469;&#39044;&#27979;&#29305;&#24449;&#20540;&#21487;&#26356;&#25913;&#20294;&#19981;&#24433;&#21709;&#39044;&#27979;&#32467;&#26524;&#65292;&#24182;&#25552;&#20379;"&#21363;&#20351;&#26159;"&#21442;&#25968;&#65292;&#25581;&#31034;&#20915;&#31574;&#30340;&#29305;&#24449;&#21644;&#20559;&#24046;&#12290;</title><link>http://arxiv.org/abs/2305.02780</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#21306;&#22495;&#25551;&#36848;&#31526;&#65306;&#22522;&#20110;&#36229;&#31435;&#26041;&#20307;&#30340;&#23616;&#37096;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Interpretable Regional Descriptors: Hyperbox-Based Local Explanations. (arXiv:2305.02780v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02780
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#21306;&#22495;&#25551;&#36848;&#31526;&#65292;&#23427;&#26159;&#19968;&#31181;&#27169;&#22411;&#26080;&#20851;&#30340;&#23616;&#37096;&#35299;&#37322;&#26041;&#27861;&#65292;&#36890;&#36807;&#25551;&#36848;&#36229;&#31435;&#26041;&#20307;&#26469;&#39044;&#27979;&#29305;&#24449;&#20540;&#21487;&#26356;&#25913;&#20294;&#19981;&#24433;&#21709;&#39044;&#27979;&#32467;&#26524;&#65292;&#24182;&#25552;&#20379;"&#21363;&#20351;&#26159;"&#21442;&#25968;&#65292;&#25581;&#31034;&#20915;&#31574;&#30340;&#29305;&#24449;&#21644;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#27169;&#22411;&#26080;&#20851;&#30340;&#23616;&#37096;&#35299;&#37322;&#30340;&#21487;&#35299;&#37322;&#30340;&#21306;&#22495;&#25551;&#36848;&#31526;&#65288;IRDs&#65289;&#65292;&#23427;&#20204;&#26159;&#25551;&#36848;&#35266;&#27979;&#20540;&#29305;&#24449;&#20540;&#21487;&#26356;&#25913;&#32780;&#19981;&#24433;&#21709;&#20854;&#39044;&#27979;&#30340;&#36229;&#31435;&#26041;&#20307;&#12290;&#36890;&#36807;&#25552;&#20379;&#19968;&#32452;&#8220;&#21363;&#20351;&#26159;&#8221;&#21442;&#25968;&#65288;&#21322;&#20107;&#23454;&#30340;&#35299;&#37322;&#65289;&#65292;&#23427;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#39044;&#27979;&#65292;&#24182;&#25351;&#20986;&#21738;&#20123;&#29305;&#24449;&#24433;&#21709;&#20102;&#39044;&#27979;&#20197;&#21450;&#26159;&#21542;&#23384;&#22312;&#28857;&#20559;&#24046;&#25110;&#19981;&#21487;&#20449;&#12290;&#19968;&#20010;&#20855;&#20307;&#30340;&#29992;&#20363;&#23637;&#31034;&#20102;&#23427;&#23545;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#26500;&#24314;&#32773;&#21644;&#20915;&#31574;&#21463;&#24433;&#21709;&#20154;&#21592;&#37117;&#26159;&#26377;&#20215;&#20540;&#30340;&#12290;&#25105;&#20204;&#23558;IRDs&#30340;&#25628;&#32034;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#35745;&#31639;IRDs&#30340;&#32479;&#19968;&#26694;&#26550;&#65292;&#21253;&#25324;&#26399;&#26395;&#12289;&#21021;&#22987;&#21270;&#25216;&#26415;&#21644;&#21518;&#22788;&#29702;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#29616;&#26377;&#30340;&#36229;&#31435;&#26041;&#20307;&#26041;&#27861;&#36866;&#24212;&#21040;&#36825;&#20010;&#32479;&#19968;&#26694;&#26550;&#20013;&#12290;&#19968;&#39033;&#22522;&#20934;&#30740;&#31350;&#27604;&#36739;&#20102;&#22522;&#20110;&#22810;&#20010;&#36136;&#37327;&#25351;&#26631;&#30340;&#26041;&#27861;&#65292;&#24182;&#30830;&#23450;&#20102;&#20004;&#31181;&#25913;&#36827;IRDs&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work introduces interpretable regional descriptors, or IRDs, for local, model-agnostic interpretations. IRDs are hyperboxes that describe how an observation's feature values can be changed without affecting its prediction. They justify a prediction by providing a set of "even if" arguments (semi-factual explanations), and they indicate which features affect a prediction and whether pointwise biases or implausibilities exist. A concrete use case shows that this is valuable for both machine learning modelers and persons subject to a decision. We formalize the search for IRDs as an optimization problem and introduce a unifying framework for computing IRDs that covers desiderata, initialization techniques, and a post-processing method. We show how existing hyperbox methods can be adapted to fit into this unified framework. A benchmark study compares the methods based on several quality measures and identifies two strategies to improve IRDs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22914;&#20309;&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#25552;&#21319;&#31639;&#27861;&#26469;&#20998;&#26512;&#39640;&#32500;&#29615;&#22659;&#21644;&#20892;&#19994;&#25968;&#25454;&#12290;&#36890;&#36807;&#32771;&#34385;&#32452;&#32467;&#26500;&#21644;&#20351;&#29992;&#20004;&#27493;&#25552;&#21319;&#26041;&#27861;&#65292;&#25105;&#20204;&#39044;&#27979;&#20102;&#20892;&#27665;&#22312;&#38754;&#23545;&#27668;&#20505;&#28798;&#23475;&#26102;&#30340;&#36130;&#21153;&#33030;&#24369;&#24615;&#12290;&#37325;&#35201;&#30340;&#39044;&#27979;&#21464;&#37327;&#21253;&#25324;&#33258;&#28982;&#36164;&#20135;&#12289;&#28748;&#28297;&#31867;&#22411;&#21644;&#38468;&#36817;&#20892;&#22330;&#30340;&#20316;&#29289;&#25439;&#22351;&#12290;&#20132;&#20114;&#20316;&#29992;&#20063;&#25552;&#39640;&#20102;&#39044;&#27979;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2305.02699</link><description>&lt;p&gt;
&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#25552;&#21319;&#31639;&#27861;&#24314;&#27169;&#29615;&#22659;&#21644;&#20892;&#19994;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Using interpretable boosting algorithms for modeling environmental and agricultural data. (arXiv:2305.02699v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02699
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22914;&#20309;&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#25552;&#21319;&#31639;&#27861;&#26469;&#20998;&#26512;&#39640;&#32500;&#29615;&#22659;&#21644;&#20892;&#19994;&#25968;&#25454;&#12290;&#36890;&#36807;&#32771;&#34385;&#32452;&#32467;&#26500;&#21644;&#20351;&#29992;&#20004;&#27493;&#25552;&#21319;&#26041;&#27861;&#65292;&#25105;&#20204;&#39044;&#27979;&#20102;&#20892;&#27665;&#22312;&#38754;&#23545;&#27668;&#20505;&#28798;&#23475;&#26102;&#30340;&#36130;&#21153;&#33030;&#24369;&#24615;&#12290;&#37325;&#35201;&#30340;&#39044;&#27979;&#21464;&#37327;&#21253;&#25324;&#33258;&#28982;&#36164;&#20135;&#12289;&#28748;&#28297;&#31867;&#22411;&#21644;&#38468;&#36817;&#20892;&#22330;&#30340;&#20316;&#29289;&#25439;&#22351;&#12290;&#20132;&#20114;&#20316;&#29992;&#20063;&#25552;&#39640;&#20102;&#39044;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#38416;&#36848;&#20102;&#22914;&#20309;&#20351;&#29992;&#22522;&#20110;&#23725;&#27491;&#21017;&#21270;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#35299;&#37322;&#24615;&#25552;&#21319;&#31639;&#27861;&#26469;&#20998;&#26512;&#39640;&#32500;&#29615;&#22659;&#25968;&#25454;&#12290;&#25105;&#20204;&#20197;&#26234;&#21033;&#21644;&#31361;&#23612;&#26031;&#30340;&#20892;&#27665;&#22312;&#38754;&#23545;&#27668;&#20505;&#28798;&#23475;&#26102;&#30340;&#36130;&#21153;&#33030;&#24369;&#24615;&#20026;&#20363;&#65292;&#20351;&#29992;&#29615;&#22659;&#12289;&#31038;&#20250;&#12289;&#20154;&#31867;&#21644;&#29983;&#29289;&#29289;&#29702;&#25968;&#25454;&#36827;&#34892;&#39044;&#27979;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#32771;&#34385;&#32452;&#32467;&#26500;&#20197;&#21450;&#22914;&#20309;&#22312;&#39640;&#32500;&#25968;&#25454;&#38598;&#20013;&#25214;&#21040;&#20132;&#20114;&#20316;&#29992;&#65292;&#20351;&#29992;&#19968;&#31181;&#26032;&#30340;&#20004;&#27493;&#25552;&#21319;&#26041;&#27861;&#12290;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#20248;&#28857;&#21644;&#21151;&#25928;&#37117;&#24471;&#21040;&#20102;&#23454;&#35777;&#21644;&#35752;&#35770;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#20004;&#27493;&#25552;&#21319;&#20013;&#24341;&#20837;&#20132;&#20114;&#20316;&#29992;&#21487;&#20197;&#25552;&#39640;&#39044;&#27979;&#33021;&#21147;&#12290;&#22312;&#39044;&#27979;&#25152;&#26377;&#31867;&#22411;&#30340;&#33030;&#24369;&#24615;&#26041;&#38754;&#65292;&#26368;&#37325;&#35201;&#30340;&#21464;&#37327;&#26159;&#33258;&#28982;&#36164;&#20135;&#12290;&#20854;&#20182;&#37325;&#35201;&#21464;&#37327;&#21253;&#25324;&#28748;&#28297;&#31867;&#22411;&#12289;&#32463;&#27982;&#36164;&#20135;&#21644;&#38468;&#36817;&#20892;&#22330;&#20316;&#29289;&#25439;&#22351;&#30340;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;
We describe how interpretable boosting algorithms based on ridge-regularized generalized linear models can be used to analyze high-dimensional environmental data. We illustrate this by using environmental, social, human and biophysical data to predict the financial vulnerability of farmers in Chile and Tunisia against climate hazards. We show how group structures can be considered and how interactions can be found in high-dimensional datasets using a novel 2-step boosting approach. The advantages and efficacy of the proposed method are shown and discussed. Results indicate that the presence of interaction effects only improves predictive power when included in two-step boosting. The most important variable in predicting all types of vulnerabilities are natural assets. Other important variables are the type of irrigation, economic assets and the presence of crop damage of near farms.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#25968;&#20540;&#31163;&#25955;&#21270;&#21442;&#25968;&#23545;&#20809;&#23398;&#32435;&#31859;&#35745;&#37327;&#39046;&#22495;&#21442;&#25968;&#37325;&#24314;&#21644;&#27169;&#22411;&#21442;&#25968;&#20998;&#24067;&#30340;&#24433;&#21709;&#65292;&#30830;&#23450;&#20102;&#25968;&#20540;&#21442;&#25968;&#21487;&#20197;&#20801;&#35768;&#39640;&#31934;&#24230;&#37325;&#24314;&#12290;</title><link>http://arxiv.org/abs/2305.02663</link><description>&lt;p&gt;
&#25968;&#20540;&#31163;&#25955;&#21270;&#31934;&#24230;&#23545;&#21442;&#25968;&#37325;&#24314;&#21644;&#27169;&#22411;&#21442;&#25968;&#20998;&#24067;&#30340;&#24433;&#21709;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Impact Study of Numerical Discretization Accuracy on Parameter Reconstructions and Model Parameter Distributions. (arXiv:2305.02663v1 [physics.comp-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02663
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#25968;&#20540;&#31163;&#25955;&#21270;&#21442;&#25968;&#23545;&#20809;&#23398;&#32435;&#31859;&#35745;&#37327;&#39046;&#22495;&#21442;&#25968;&#37325;&#24314;&#21644;&#27169;&#22411;&#21442;&#25968;&#20998;&#24067;&#30340;&#24433;&#21709;&#65292;&#30830;&#23450;&#20102;&#25968;&#20540;&#21442;&#25968;&#21487;&#20197;&#20801;&#35768;&#39640;&#31934;&#24230;&#37325;&#24314;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#20540;&#27169;&#22411;&#22312;&#20809;&#23398;&#32435;&#31859;&#35745;&#37327;&#39046;&#22495;&#30340;&#21442;&#25968;&#37325;&#24314;&#20013;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;&#36890;&#36807;&#20351;&#29992;&#36125;&#21494;&#26031;&#30446;&#26631;&#21521;&#37327;&#20248;&#21270;&#26041;&#27861;&#23558;&#26377;&#38480;&#20803;&#25968;&#20540;&#27169;&#22411;&#25311;&#21512;&#21040;&#23454;&#39564;&#25968;&#25454;&#38598;&#65292;&#21487;&#20197;&#33719;&#24471;&#32435;&#31859;&#32467;&#26500;&#32447;&#20809;&#26629;&#30340;&#20960;&#20309;&#21442;&#25968;&#12290;&#22312;&#37325;&#24314;&#36807;&#31243;&#20013;&#65292;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#20195;&#29702;&#27169;&#22411;&#36827;&#34892;&#35757;&#32451;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#25277;&#26679;&#22120;&#23545;&#20195;&#29702;&#27169;&#22411;&#36827;&#34892;&#25277;&#26679;&#65292;&#20197;&#30830;&#23450;&#37325;&#24314;&#27169;&#22411;&#21442;&#25968;&#30340;&#23436;&#25972;&#27169;&#22411;&#21442;&#25968;&#20998;&#24067;&#12290;&#25968;&#20540;&#31163;&#25955;&#21270;&#21442;&#25968;&#30340;&#36873;&#25321;&#65292;&#22914;&#26377;&#38480;&#20803;&#35299;&#31572;&#20989;&#25968;&#30340;&#22810;&#39033;&#24335;&#38454;&#25968;&#65292;&#24433;&#21709;&#27491;&#28436;&#27169;&#22411;&#30340;&#25968;&#20540;&#31163;&#25955;&#21270;&#35823;&#24046;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#27491;&#28436;&#38382;&#39064;&#30340;&#25968;&#20540;&#31163;&#25955;&#21270;&#21442;&#25968;&#23545;&#37325;&#26500;&#21442;&#25968;&#20197;&#21450;&#27169;&#22411;&#21442;&#25968;&#20998;&#24067;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#34920;&#26126;&#36825;&#26679;&#30340;&#25910;&#25947;&#30740;&#31350;&#21487;&#20197;&#30830;&#23450;&#20801;&#35768;&#39640;&#31934;&#24230;&#37325;&#24314;&#30340;&#25968;&#20540;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Numerical models are used widely for parameter reconstructions in the field of optical nano metrology. To obtain geometrical parameters of a nano structured line grating, we fit a finite element numerical model to an experimental data set by using the Bayesian target vector optimization method. Gaussian process surrogate models are trained during the reconstruction. Afterwards, we employ a Markov chain Monte Carlo sampler on the surrogate models to determine the full model parameter distribution for the reconstructed model parameters. The choice of numerical discretization parameters, like the polynomial order of the finite element ansatz functions, impacts the numerical discretization error of the forward model. In this study we investigate the impact of numerical discretization parameters of the forward problem on the reconstructed parameters as well as on the model parameter distributions. We show that such a convergence study allows to determine numerical parameters which allow for
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#23485;&#26494;&#24347;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#35777;&#26126;&#36866;&#24403;&#26089;&#20572;&#30340;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#22810;&#23618;&#23485;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23454;&#29616;&#26368;&#23567;&#26497;&#22823;&#29575;&#65292;&#21069;&#25552;&#26159;&#22238;&#24402;&#20989;&#25968;&#22312;&#23545;&#24212;&#30340;NTK&#30456;&#20851;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#65292;&#20294;&#36807;&#24230;&#25311;&#21512;&#30340;&#22810;&#23618;&#23485;&#31070;&#32463;&#32593;&#32476;&#22312;$\mathbb S^{d}$&#19978;&#19981;&#33021;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;</title><link>http://arxiv.org/abs/2305.02657</link><description>&lt;p&gt;
&#28145;&#24230;&#23485;&#26494;&#24347;&#31070;&#32463;&#32593;&#32476;&#30340;&#32479;&#35745;&#20248;&#21270;&#24615;
&lt;/p&gt;
&lt;p&gt;
Statistical Optimality of Deep Wide Neural Networks. (arXiv:2305.02657v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02657
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#23485;&#26494;&#24347;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#35777;&#26126;&#36866;&#24403;&#26089;&#20572;&#30340;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#22810;&#23618;&#23485;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23454;&#29616;&#26368;&#23567;&#26497;&#22823;&#29575;&#65292;&#21069;&#25552;&#26159;&#22238;&#24402;&#20989;&#25968;&#22312;&#23545;&#24212;&#30340;NTK&#30456;&#20851;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#65292;&#20294;&#36807;&#24230;&#25311;&#21512;&#30340;&#22810;&#23618;&#23485;&#31070;&#32463;&#32593;&#32476;&#22312;$\mathbb S^{d}$&#19978;&#19981;&#33021;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23450;&#20041;&#22312;&#26377;&#30028;&#22495;$\mathcal X \subset \mathbb R^{d}$&#19978;&#30340;&#28145;&#24230;&#23485;&#26494;&#24347;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#39318;&#20808;&#35777;&#26126;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#21487;&#20197;&#34987;&#30456;&#24212;&#30340;&#28145;&#24230;&#31070;&#32463;&#20999;&#21521;&#26680;&#22238;&#24402;&#25152;&#23436;&#20840;&#25551;&#32472;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#20999;&#21521;&#26680;&#30340;&#35889;&#29305;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#28145;&#24230;&#31070;&#32463;&#20999;&#21521;&#26680;&#22312;$\mathcal{X}$&#19978;&#20026;&#27491;&#23450;&#65292;&#20854;&#29305;&#24449;&#20540;&#34928;&#20943;&#29575;&#20026;$(d+1)/d$&#12290;&#30001;&#20110;&#26680;&#22238;&#24402;&#20013;&#24050;&#32463;&#24314;&#31435;&#30340;&#29702;&#35770;&#65292;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65292;&#36866;&#24403;&#26089;&#20572;&#30340;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#22810;&#23618;&#23485;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23454;&#29616;&#26368;&#23567;&#26497;&#22823;&#29575;&#65292;&#21069;&#25552;&#26159;&#22238;&#24402;&#20989;&#25968;&#22312;&#23545;&#24212;&#30340;NTK&#30456;&#20851;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#36807;&#24230;&#25311;&#21512;&#30340;&#22810;&#23618;&#23485;&#31070;&#32463;&#32593;&#32476;&#22312;$\mathbb S^{d}$&#19978;&#19981;&#33021;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider the generalization ability of deep wide feedforward ReLU neural networks defined on a bounded domain $\mathcal X \subset \mathbb R^{d}$. We first demonstrate that the generalization ability of the neural network can be fully characterized by that of the corresponding deep neural tangent kernel (NTK) regression. We then investigate on the spectral properties of the deep NTK and show that the deep NTK is positive definite on $\mathcal{X}$ and its eigenvalue decay rate is $(d+1)/d$. Thanks to the well established theories in kernel regression, we then conclude that multilayer wide neural networks trained by gradient descent with proper early stopping achieve the minimax rate, provided that the regression function lies in the reproducing kernel Hilbert space (RKHS) associated with the corresponding NTK. Finally, we illustrate that the overfitted multilayer wide neural networks can not generalize well on $\mathbb S^{d}$.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;BA&#31639;&#27861;&#30340;&#19968;&#31181;&#26032;&#30340;&#20462;&#25913;&#65292;&#36890;&#36807;&#35753;&#20056;&#25968;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#36890;&#36807;&#19968;&#32500;&#27714;&#26681;&#26469;&#26356;&#26032;&#65292;&#36825;&#20351;&#24471;&#31639;&#27861;&#33021;&#22815;&#30452;&#25509;&#35745;&#31639;&#25152;&#38656;&#22833;&#30495;&#30340;RD&#20989;&#25968;&#65292;&#32780;&#26080;&#38656;&#20687;&#21407;&#22987;&#31639;&#27861;&#19968;&#26679;&#25506;&#32034;&#25972;&#20010;RD&#26354;&#32447;&#12290;</title><link>http://arxiv.org/abs/2305.02650</link><description>&lt;p&gt;
Blahut&#21644;Arimoto&#30340;&#20027;&#39064;&#21464;&#20307;
&lt;/p&gt;
&lt;p&gt;
Variations on a Theme by Blahut and Arimoto. (arXiv:2305.02650v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02650
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;BA&#31639;&#27861;&#30340;&#19968;&#31181;&#26032;&#30340;&#20462;&#25913;&#65292;&#36890;&#36807;&#35753;&#20056;&#25968;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#36890;&#36807;&#19968;&#32500;&#27714;&#26681;&#26469;&#26356;&#26032;&#65292;&#36825;&#20351;&#24471;&#31639;&#27861;&#33021;&#22815;&#30452;&#25509;&#35745;&#31639;&#25152;&#38656;&#22833;&#30495;&#30340;RD&#20989;&#25968;&#65292;&#32780;&#26080;&#38656;&#20687;&#21407;&#22987;&#31639;&#27861;&#19968;&#26679;&#25506;&#32034;&#25972;&#20010;RD&#26354;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Blahut-Arimoto&#65288;BA&#65289;&#31639;&#27861;&#22312;&#35745;&#31639;&#36895;&#29575;&#22833;&#30495;&#65288;RD&#65289;&#20989;&#25968;&#26041;&#38754;&#36215;&#30528;&#22522;&#30784;&#24615;&#20316;&#29992;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#20132;&#26367;&#26368;&#23567;&#21270;&#24102;&#26377;&#22266;&#23450;&#20056;&#25968;&#30340;Lagrangian&#20855;&#26377;&#29702;&#24819;&#30340;&#21333;&#35843;&#25910;&#25947;&#23646;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;BA&#31639;&#27861;&#30340;&#26032;&#39062;&#20462;&#25913;&#65292;&#20351;&#20056;&#25968;&#27599;&#27425;&#36845;&#20195;&#36890;&#36807;&#30456;&#23545;&#20110;&#21333;&#35843;&#21333;&#21464;&#37327;&#20989;&#25968;&#30340;&#19968;&#32500;&#27714;&#26681;&#27493;&#39588;&#26356;&#26032;&#65292;&#36825;&#21487;&#20197;&#36890;&#36807;&#29275;&#39039;&#27861;&#26377;&#25928;&#23454;&#29616;&#12290;&#36825;&#20801;&#35768;&#20197;&#28789;&#27963;&#21644;&#39640;&#25928;&#30340;&#26041;&#24335;&#26356;&#26032;&#20056;&#25968;&#65292;&#20811;&#26381;&#20102;&#21407;&#22987;BA&#31639;&#27861;&#30340;&#19968;&#20010;&#20027;&#35201;&#32570;&#28857;&#65292;&#20854;&#20013;&#20056;&#25968;&#22312;&#25972;&#20010;&#36845;&#20195;&#36807;&#31243;&#20013;&#37117;&#26159;&#22266;&#23450;&#30340;&#12290;&#22240;&#27492;&#65292;&#20462;&#25913;&#21518;&#30340;&#31639;&#27861;&#33021;&#22815;&#30452;&#25509;&#35745;&#31639;&#25152;&#38656;&#22833;&#30495;&#30340;RD&#20989;&#25968;&#65292;&#32780;&#19981;&#20687;&#21407;&#22987;BA&#31639;&#27861;&#19968;&#26679;&#25506;&#32034;&#25972;&#20010;RD&#26354;&#32447;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#20462;&#25913;&#21518;&#30340;&#31639;&#27861;&#20173;&#20250;&#25910;&#25947;&#21040;RD&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Blahut-Arimoto (BA) algorithm has played a fundamental role in the numerical computation of rate-distortion (RD) functions. This algorithm possesses a desirable monotonic convergence property by alternatively minimizing its Lagrangian with a fixed multiplier. In this paper, we propose a novel modification of the BA algorithm, letting the multiplier be updated in each iteration via a one-dimensional root-finding step with respect to a monotonic univariate function, which can be efficiently implemented by Newton's method. This allows the multiplier to be updated in a flexible and efficient manner, overcoming a major drawback of the original BA algorithm wherein the multiplier is fixed throughout iterations. Consequently, the modified algorithm is capable of directly computing the RD function for a given target distortion, without exploring the entire RD curve as in the original BA algorithm. A theoretical analysis shows that the modified algorithm still converges to the RD function a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#21512;&#22270;&#23398;&#20064;&#21644;&#27169;&#22411;&#25311;&#21512;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;LRSM&#38382;&#39064;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.02573</link><description>&lt;p&gt;
&#25289;&#26222;&#25289;&#26031;&#27491;&#21017;&#21270;&#20998;&#23618;&#27169;&#22411;&#20013;&#30340;&#32852;&#21512;&#22270;&#23398;&#20064;&#21644;&#27169;&#22411;&#25311;&#21512;
&lt;/p&gt;
&lt;p&gt;
Joint Graph Learning and Model Fitting in Laplacian Regularized Stratified Models. (arXiv:2305.02573v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02573
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#21512;&#22270;&#23398;&#20064;&#21644;&#27169;&#22411;&#25311;&#21512;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;LRSM&#38382;&#39064;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25289;&#26222;&#25289;&#26031;&#27491;&#21017;&#21270;&#20998;&#23618;&#27169;&#22411;&#65288;LRSM&#65289;&#26159;&#21033;&#29992;&#23376;&#38382;&#39064;&#30340;&#26174;&#24335;&#25110;&#38544;&#24335;&#32593;&#32476;&#32467;&#26500;&#65292;&#30001;&#20998;&#31867;&#29305;&#24449;&#31216;&#20026;&#23618;&#65288;&#20363;&#22914;&#24180;&#40836;&#12289;&#21306;&#22495;&#12289;&#26102;&#38388;&#12289;&#39044;&#27979;&#26102;&#38388;&#12289;&#31561;&#65289;&#65292;&#24182;&#20174;&#30456;&#37051;&#23618;&#20013;&#33719;&#21462;&#25968;&#25454;&#20197;&#22686;&#24378;&#27599;&#20010;&#23376;&#38382;&#39064;&#30340;&#21442;&#25968;&#23398;&#20064;&#12290;&#23427;&#20204;&#24050;&#24191;&#27867;&#24212;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#21644;&#20449;&#21495;&#22788;&#29702;&#38382;&#39064;&#65292;&#21253;&#25324;&#20294;&#19981;&#38480;&#20110;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#65292;&#34920;&#31034;&#23398;&#20064;&#65292;&#22270;&#32858;&#31867;&#65292;&#26368;&#22823;&#38388;&#38548;&#20998;&#31867;&#21644;&#19968;&#33324;&#23569;&#37327;&#26679;&#26412;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;LRSM&#30740;&#31350;&#35201;&#20040;&#20551;&#35774;&#24050;&#30693;&#22270;&#24418;&#65292;&#35201;&#20040;&#20165;&#38480;&#20110;&#29305;&#23450;&#24212;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;LRSM&#20013;&#22270;&#26435;&#37325;&#30340;&#37325;&#35201;&#24615;&#21644;&#25935;&#24863;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#24403;&#33410;&#28857;&#20043;&#38388;&#21442;&#25968;&#27604;&#20363;&#21644;&#26679;&#26412;&#37327;&#19981;&#24179;&#34913;&#26102;&#65292;&#25935;&#24863;&#24615;&#21487;&#33021;&#20250;&#20219;&#24847;&#22686;&#22823;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#26041;&#27861;&#65292;&#22312;&#25311;&#21512;&#27169;&#22411;&#30340;&#21516;&#26102;&#32852;&#21512;&#23398;&#20064;&#22270;&#65292;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;LRSM&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#21046;&#23450;&#20102;&#32852;&#21512;&#22270;&#23398;&#20064;&#21644;&#27169;&#22411;&#25311;&#21512;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#20132;&#26367;&#23398;&#20064;&#22270;&#65288;&#36890;&#36807;&#31232;&#30095;&#36870;&#21327;&#26041;&#24046;&#20272;&#35745;&#65289;&#21644;&#25311;&#21512;&#27169;&#22411;&#65288;&#36890;&#36807;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#65289;&#26469;&#35299;&#20915;&#23427;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20165;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#36824;&#25581;&#31034;&#20102;&#26377;&#20851;&#38382;&#39064;&#30340;&#26377;&#36259;&#22270;&#26696;&#21644;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Laplacian regularized stratified models (LRSM) are models that utilize the explicit or implicit network structure of the sub-problems as defined by the categorical features called strata (e.g., age, region, time, forecast horizon, etc.), and draw upon data from neighboring strata to enhance the parameter learning of each sub-problem. They have been widely applied in machine learning and signal processing problems, including but not limited to time series forecasting, representation learning, graph clustering, max-margin classification, and general few-shot learning. Nevertheless, existing works on LRSM have either assumed a known graph or are restricted to specific applications. In this paper, we start by showing the importance and sensitivity of graph weights in LRSM, and provably show that the sensitivity can be arbitrarily large when the parameter scales and sample sizes are heavily imbalanced across nodes. We then propose a generic approach to jointly learn the graph while fitting 
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#24320;&#21457;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#32447;&#24615;&#26102;&#38388;&#30340;&#40065;&#26834;PCA&#31639;&#27861;&#65292;&#20855;&#26377;&#25509;&#36817;&#26368;&#20248;&#30340;&#35823;&#24046;&#20445;&#35777;&#65292;&#24182;&#19988;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#21333;&#36941;&#27969;&#24335;PCA&#31639;&#27861;&#65292;&#20855;&#26377;&#20960;&#20046;&#32447;&#24615;&#30340;&#20869;&#23384;&#20351;&#29992;&#12290;</title><link>http://arxiv.org/abs/2305.02544</link><description>&lt;p&gt;
&#24322;&#24120;&#20540;&#40065;&#26834;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#36817;&#20284;&#32447;&#24615;&#26102;&#38388;&#21644;&#27969;&#24335;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Nearly-Linear Time and Streaming Algorithms for Outlier-Robust PCA. (arXiv:2305.02544v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02544
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#24320;&#21457;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#32447;&#24615;&#26102;&#38388;&#30340;&#40065;&#26834;PCA&#31639;&#27861;&#65292;&#20855;&#26377;&#25509;&#36817;&#26368;&#20248;&#30340;&#35823;&#24046;&#20445;&#35777;&#65292;&#24182;&#19988;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#21333;&#36941;&#27969;&#24335;PCA&#31639;&#27861;&#65292;&#20855;&#26377;&#20960;&#20046;&#32447;&#24615;&#30340;&#20869;&#23384;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20027;&#25104;&#20998;&#20998;&#26512;&#65292;&#20854;&#20013;&#32473;&#23450;&#26469;&#33258;&#20998;&#24067;&#30340;$\mathbb{R}^d$&#30340;&#25968;&#25454;&#38598;&#65292;&#20219;&#21153;&#26159;&#25214;&#21040;&#19968;&#20010;&#21333;&#20301;&#21521;&#37327;$v$&#65292;&#22312;&#27839;$v$&#25237;&#24433;&#21518;&#65292;&#36817;&#20284;&#22320;&#26368;&#22823;&#21270;&#20998;&#24067;&#30340;&#26041;&#24046;&#12290;&#23613;&#31649;&#26159;&#19968;&#20010;&#32463;&#20856;&#30340;&#20219;&#21153;&#65292;&#20294;&#22914;&#26524;&#25968;&#25454;&#21253;&#21547;&#21363;&#20351;&#26159;&#23569;&#37327;&#30340;&#24322;&#24120;&#20540;&#65292;&#26631;&#20934;&#20272;&#35745;&#22120;&#20063;&#20250;&#20005;&#37325;&#22833;&#36133;&#65292;&#36825;&#28608;&#21457;&#20102;&#40065;&#26834;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#38382;&#39064;&#12290;&#26368;&#36817;&#30340;&#24037;&#20316;&#24050;&#32463;&#24320;&#21457;&#20986;&#35745;&#31639;&#25928;&#29575;&#36739;&#39640;&#30340;&#40065;&#26834;PCA&#31639;&#27861;&#65292;&#20294;&#35201;&#20040;&#38656;&#35201;&#36229;&#32447;&#24615;&#26102;&#38388;&#65292;&#35201;&#20040;&#20855;&#26377;&#27425;&#20248;&#30340;&#35823;&#24046;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#24320;&#21457;&#20986;&#19968;&#31181;&#36817;&#20284;&#32447;&#24615;&#26102;&#38388;&#30340;&#40065;&#26834;PCA&#31639;&#27861;&#65292;&#24182;&#20855;&#26377;&#25509;&#36817;&#26368;&#20248;&#30340;&#35823;&#24046;&#20445;&#35777;&#12290;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#21333;&#36941;&#27969;&#24335;PCA&#31639;&#27861;&#65292;&#20854;&#20869;&#23384;&#20351;&#29992;&#20960;&#20046;&#19982;&#32500;&#25968;&#25104;&#32447;&#24615;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study principal component analysis (PCA), where given a dataset in $\mathbb{R}^d$ from a distribution, the task is to find a unit vector $v$ that approximately maximizes the variance of the distribution after being projected along $v$. Despite being a classical task, standard estimators fail drastically if the data contains even a small fraction of outliers, motivating the problem of robust PCA. Recent work has developed computationally-efficient algorithms for robust PCA that either take super-linear time or have sub-optimal error guarantees. Our main contribution is to develop a nearly-linear time algorithm for robust PCA with near-optimal error guarantees. We also develop a single-pass streaming algorithm for robust PCA with memory usage nearly-linear in the dimension.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;Monte-Carlo&#20272;&#35745;&#22120;&#65292;&#23427;&#33021;&#22815;&#20462;&#27491;&#22312;&#25238;&#38899;&#21452;&#21521;&#20869;&#23481;&#24066;&#22330;&#24179;&#21488;&#19978;&#23454;&#39564;&#26102;&#30340;&#24178;&#25200;&#38382;&#39064;&#65292;&#24182;&#22312;&#29616;&#22330;&#23454;&#39564;&#20013;&#23558;&#23454;&#39564;&#21534;&#21520;&#37327;&#25552;&#39640;&#20102;&#19968;&#20493;&#12290;</title><link>http://arxiv.org/abs/2305.02542</link><description>&lt;p&gt;
&#20462;&#27491;&#24178;&#25200;&#38382;&#39064;&#65306;&#20197;&#25238;&#38899;&#20026;&#20363;&#30340;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Correcting for Interference in Experiments: A Case Study at Douyin. (arXiv:2305.02542v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02542
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;Monte-Carlo&#20272;&#35745;&#22120;&#65292;&#23427;&#33021;&#22815;&#20462;&#27491;&#22312;&#25238;&#38899;&#21452;&#21521;&#20869;&#23481;&#24066;&#22330;&#24179;&#21488;&#19978;&#23454;&#39564;&#26102;&#30340;&#24178;&#25200;&#38382;&#39064;&#65292;&#24182;&#22312;&#29616;&#22330;&#23454;&#39564;&#20013;&#23558;&#23454;&#39564;&#21534;&#21520;&#37327;&#25552;&#39640;&#20102;&#19968;&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24178;&#25200;&#26159;&#22312;&#21452;&#21521;&#20869;&#23481;&#24066;&#22330;&#24179;&#21488;&#19978;&#36827;&#34892;&#23454;&#39564;&#26102;&#30340;&#26222;&#36941;&#38382;&#39064;&#65292;&#20363;&#22914;&#20013;&#22269;&#29256;&#30340;TikTok&#8212;&#8212;&#25238;&#38899;&#12290;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#21019;&#20316;&#32773;&#26159;&#23454;&#39564;&#30340;&#33258;&#28982;&#21333;&#20301;&#65292;&#20294;&#26159;&#21019;&#20316;&#32773;&#36890;&#36807;&#20105;&#22842;&#35266;&#20247;&#26377;&#38480;&#30340;&#26102;&#38388;&#21644;&#27880;&#24847;&#21147;&#20114;&#30456;&#24178;&#25200;&#12290;&#30446;&#21069;&#23454;&#36341;&#20013;&#20351;&#29992;&#30340;&#8220;&#26420;&#32032;&#8221;&#20272;&#35745;&#22120;&#31616;&#21333;&#22320;&#24573;&#30053;&#20102;&#24178;&#25200;&#65292;&#20294;&#36825;&#26679;&#20570;&#20250;&#20135;&#29983;&#27835;&#30103;&#25928;&#26524;&#30340;&#35823;&#24046;&#12290;&#25105;&#20204;&#23558;&#36825;&#26679;&#30340;&#23454;&#39564;&#25512;&#26029;&#38382;&#39064;&#24418;&#24335;&#21270;&#20026;&#25919;&#31574;&#35780;&#20272;&#20013;&#30340;&#38382;&#39064;&#12290;&#34429;&#28982;&#20559;&#24046;&#24456;&#23567;&#65292;&#20294;&#24418;&#24335;&#19978;&#34892;&#20026;&#31574;&#30053;&#19981;&#22815;&#23454;&#29992;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#8220;Q&#20540;&#24046;&#24322;&#8221;&#30340;(DQ)&#25216;&#26415;&#30340;&#26032;&#22411;Monte-Carlo&#20272;&#35745;&#22120;&#65292;&#23427;&#36798;&#21040;&#20102;&#27835;&#30103;&#25928;&#26524;&#22312;&#20108;&#38454;&#30340;&#20559;&#24046;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#26679;&#26412;&#25928;&#29575;&#12290;&#22312;&#29702;&#35770;&#26041;&#38754;&#65292;&#25105;&#20204;&#30340;&#36129;&#29486;&#26159;&#21457;&#23637;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#25919;&#31574;&#35780;&#20272;&#27888;&#21202;&#23637;&#24320;&#29702;&#35770;&#65292;&#23558;DQ&#29702;&#35770;&#25193;&#23637;&#21040;&#25152;&#26377;&#20027;&#35201;&#30340;MDP&#20844;&#24335;&#12290;&#22312;&#23454;&#36341;&#26041;&#38754;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#34987;&#37096;&#32626;&#22312;&#25238;&#38899;&#19978;&#65292;&#24182;&#22312;&#29616;&#22330;&#23454;&#39564;&#20013;&#23558;&#23454;&#39564;&#21534;&#21520;&#37327;&#25552;&#39640;&#20102;&#19968;&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;
Interference is a ubiquitous problem in experiments conducted on two-sided content marketplaces, such as Douyin (China's analog of TikTok). In many cases, creators are the natural unit of experimentation, but creators interfere with each other through competition for viewers' limited time and attention. "Naive" estimators currently used in practice simply ignore the interference, but in doing so incur bias on the order of the treatment effect. We formalize the problem of inference in such experiments as one of policy evaluation. Off-policy estimators, while unbiased, are impractically high variance. We introduce a novel Monte-Carlo estimator, based on "Differences-in-Qs" (DQ) techniques, which achieves bias that is second-order in the treatment effect, while remaining sample-efficient to estimate. On the theoretical side, our contribution is to develop a generalized theory of Taylor expansions for policy evaluation, which extends DQ theory to all major MDP formulations. On the practica
&lt;/p&gt;</description></item><item><title>AutoML-GPT &#26159;&#19968;&#31181;&#22522;&#20110; GPT &#30340;&#33258;&#21160;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21160;&#24577;&#22320;&#21033;&#29992;&#21508;&#31181;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#65292;&#33258;&#21160;&#21270;&#35757;&#32451;&#31649;&#36947;&#65292;&#33410;&#32422;&#20102;&#36873;&#25321;&#27169;&#22411;&#26550;&#26500;&#12289;&#20248;&#21270;&#31639;&#27861;&#21644;&#35843;&#25972;&#36229;&#21442;&#25968;&#30340;&#20154;&#21147;&#21644;&#26102;&#38388;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2305.02499</link><description>&lt;p&gt;
AutoML-GPT: &#22522;&#20110; GPT &#30340;&#33258;&#21160;&#26426;&#22120;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
AutoML-GPT: Automatic Machine Learning with GPT. (arXiv:2305.02499v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02499
&lt;/p&gt;
&lt;p&gt;
AutoML-GPT &#26159;&#19968;&#31181;&#22522;&#20110; GPT &#30340;&#33258;&#21160;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21160;&#24577;&#22320;&#21033;&#29992;&#21508;&#31181;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#65292;&#33258;&#21160;&#21270;&#35757;&#32451;&#31649;&#36947;&#65292;&#33410;&#32422;&#20102;&#36873;&#25321;&#27169;&#22411;&#26550;&#26500;&#12289;&#20248;&#21270;&#31639;&#27861;&#21644;&#35843;&#25972;&#36229;&#21442;&#25968;&#30340;&#20154;&#21147;&#21644;&#26102;&#38388;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
AI &#20219;&#21153;&#28085;&#30422;&#20102;&#24191;&#27867;&#30340;&#39046;&#22495;&#21644;&#39046;&#22495;&#12290;&#34429;&#28982;&#20026;&#29305;&#23450;&#20219;&#21153;&#21644;&#24212;&#29992;&#31243;&#24207;&#35774;&#35745;&#20102;&#20247;&#22810; AI &#27169;&#22411;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#38656;&#35201;&#22823;&#37327;&#30340;&#20154;&#21147;&#25237;&#20837;&#26469;&#26597;&#25214;&#27491;&#30830;&#30340;&#27169;&#22411;&#26550;&#26500;&#12289;&#20248;&#21270;&#31639;&#27861;&#21644;&#36229;&#21442;&#25968;&#12290;&#26368;&#36817;&#65292;&#20687; ChatGPT &#36825;&#26679;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411; (LLM) &#22312;&#25512;&#29702;&#12289;&#29702;&#35299;&#21644;&#20132;&#20114;&#30340;&#21508;&#20010;&#26041;&#38754;&#23637;&#29616;&#20986;&#20102;&#21331;&#36234;&#30340;&#33021;&#21147;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24320;&#21457;&#38754;&#21521;&#20219;&#21153;&#30340;&#25552;&#31034;&#24182;&#33258;&#21160;&#21033;&#29992; LLM &#33258;&#21160;&#21270;&#35757;&#32451;&#31649;&#36947;&#30340;&#24819;&#27861;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#27010;&#24565;&#65292;&#25105;&#20204;&#25512;&#20986;&#20102; AutoML-GPT&#65292;&#23427;&#37319;&#29992; GPT &#20316;&#20026;&#36830;&#25509;&#22810;&#31181; AI &#27169;&#22411;&#30340;&#26725;&#26753;&#65292;&#24182;&#21160;&#24577;&#22320;&#20351;&#29992;&#20248;&#21270;&#36229;&#21442;&#25968;&#35757;&#32451;&#27169;&#22411;&#12290;AutoML-GPT &#20174;&#27169;&#22411;&#21644;&#25968;&#25454;&#21345;&#20013;&#21160;&#24577;&#33719;&#21462;&#29992;&#25143;&#35831;&#27714;&#65292;&#24182;&#32452;&#25104;&#30456;&#24212;&#30340;&#25552;&#31034;&#27573;&#33853;&#12290;&#26368;&#32456;&#65292;&#36890;&#36807;&#36825;&#20010;&#25552;&#31034;&#27573;&#33853;&#65292;AutoML-GPT &#23558;&#33258;&#21160;&#20174;&#25968;&#25454;&#22788;&#29702;&#21040;&#27169;&#22411;&#26550;&#26500;&#12289;&#36229;&#21442;&#25968;&#35843;&#25972;&#36827;&#34892;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
AI tasks encompass a wide range of domains and fields. While numerous AI models have been designed for specific tasks and applications, they often require considerable human efforts in finding the right model architecture, optimization algorithm, and hyperparameters. Recent advances in large language models (LLMs) like ChatGPT show remarkable capabilities in various aspects of reasoning, comprehension, and interaction. Consequently, we propose developing task-oriented prompts and automatically utilizing LLMs to automate the training pipeline. To implement this concept, we present the AutoML-GPT, which employs GPT as the bridge to diverse AI models and dynamically trains models with optimized hyperparameters. AutoML-GPT dynamically takes user requests from the model and data cards and composes the corresponding prompt paragraph. Ultimately, with this prompt paragraph, AutoML-GPT will automatically conduct the experiments from data processing to model architecture, hyperparameter tuning,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21322;&#30417;&#30563;&#22238;&#24402;&#30340;&#28508;&#22312;&#32467;&#26500;&#32593;&#32476;&#27169;&#22411;&#65292;&#22312;&#26410;&#30693;&#26426;&#27969;&#24418;&#19978;&#20351;&#29992;&#27969;&#24418;&#23398;&#20064;&#21644;&#22270;&#23884;&#20837;&#25216;&#26415;&#36827;&#34892;&#21709;&#24212;&#39044;&#27979;&#65292;&#24182;&#20026;&#36825;&#20123;&#21709;&#24212;&#24314;&#31435;&#20102;&#25910;&#25947;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.02473</link><description>&lt;p&gt;
&#26410;&#30693;&#26426;&#27969;&#24418;&#19978;&#30340;&#28508;&#22312;&#32467;&#26500;&#32593;&#32476;&#20013;&#30340;&#21322;&#30417;&#30563;&#22238;&#24402;&#12290;
&lt;/p&gt;
&lt;p&gt;
Semisupervised regression in latent structure networks on unknown manifolds. (arXiv:2305.02473v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02473
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21322;&#30417;&#30563;&#22238;&#24402;&#30340;&#28508;&#22312;&#32467;&#26500;&#32593;&#32476;&#27169;&#22411;&#65292;&#22312;&#26410;&#30693;&#26426;&#27969;&#24418;&#19978;&#20351;&#29992;&#27969;&#24418;&#23398;&#20064;&#21644;&#22270;&#23884;&#20837;&#25216;&#26415;&#36827;&#34892;&#21709;&#24212;&#39044;&#27979;&#65292;&#24182;&#20026;&#36825;&#20123;&#21709;&#24212;&#24314;&#31435;&#20102;&#25910;&#25947;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#22270;&#22312;&#24314;&#27169;&#21508;&#31181;&#24212;&#29992;&#20013;&#30340;&#32593;&#32476;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#12290;&#28508;&#22312;&#20301;&#32622;&#38543;&#26426;&#22270;&#27169;&#22411;&#35748;&#20026;&#27599;&#20010;&#33410;&#28857;&#37117;&#19982;&#28508;&#22312;&#20301;&#32622;&#21521;&#37327;&#30456;&#20851;&#32852;&#65292;&#24182;&#19988;&#36825;&#20123;&#21521;&#37327;&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#36981;&#24490;&#26576;&#20123;&#20960;&#20309;&#32467;&#26500;&#12290;&#26412;&#25991;&#32771;&#34385;&#38543;&#26426;&#28857;&#31215;&#22270;&#65292;&#20854;&#20013;&#22312;&#20854;&#21508;&#33258;&#30340;&#28508;&#22312;&#20301;&#32622;&#30340;&#20869;&#31215;&#32473;&#23450;&#30340;&#27010;&#29575;&#19979;&#24418;&#25104;&#20004;&#20010;&#33410;&#28857;&#20043;&#38388;&#30340;&#36793;&#32536;&#12290;&#25105;&#20204;&#20551;&#35774;&#28508;&#22312;&#20301;&#32622;&#21521;&#37327;&#20301;&#20110;&#26410;&#30693;&#30340;&#19968;&#32500;&#26354;&#32447;&#19978;&#65292;&#24182;&#36890;&#36807;&#22238;&#24402;&#27169;&#22411;&#19982;&#21709;&#24212;&#21327;&#21464;&#37327;&#32806;&#21512;&#12290;&#21033;&#29992;&#28508;&#22312;&#20301;&#32622;&#21521;&#37327;&#30340;&#24213;&#23618;&#20960;&#20309;&#32467;&#26500;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#27969;&#24418;&#23398;&#20064;&#21644;&#22270;&#23884;&#20837;&#25216;&#26415;&#65292;&#20197;&#39044;&#27979;&#26679;&#26412;&#22806;&#33410;&#28857;&#19978;&#30340;&#21709;&#24212;&#21464;&#37327;&#65292;&#24182;&#20026;&#36825;&#20123;&#21709;&#24212;&#24314;&#31435;&#20102;&#25910;&#25947;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#24471;&#21040;&#27169;&#25311;&#21644;&#23545;Drosophila&#22823;&#33041;&#25968;&#25454;&#30340;&#24212;&#29992;&#30340;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
Random graphs are increasingly becoming objects of interest for modeling networks in a wide range of applications. Latent position random graph models posit that each node is associated with a latent position vector, and that these vectors follow some geometric structure in the latent space. In this paper, we consider random dot product graphs, in which an edge is formed between two nodes with probability given by the inner product of their respective latent positions. We assume that the latent position vectors lie on an unknown one-dimensional curve and are coupled with a response covariate via a regression model. Using the geometry of the underlying latent position vectors, we propose a manifold learning and graph embedding technique to predict the response variable on out-of-sample nodes, and we establish convergence guarantees for these responses. Our theoretical results are supported by simulations and an application to Drosophila brain data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#39532;&#23572;&#21487;&#22827;&#25968;&#25454;&#37319;&#26679;&#30340;&#27969;&#24335;PCA&#31639;&#27861;&#65292;&#24182;&#33719;&#24471;&#20102;&#35813;&#31639;&#27861;&#22312;&#25972;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#31532;&#19968;&#20010;&#23574;&#38160;&#29575;&#65292;&#25552;&#39640;&#20102;&#31639;&#27861;&#30340;&#25928;&#29575;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#25552;&#20986;&#30340;&#33258;&#36866;&#24212;&#26041;&#26696;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#31034;&#20363;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>http://arxiv.org/abs/2305.02456</link><description>&lt;p&gt;
&#38754;&#21521;&#39532;&#23572;&#21487;&#22827;&#25968;&#25454;&#30340;&#27969;&#24335;PCA&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Streaming PCA for Markovian Data. (arXiv:2305.02456v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02456
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#39532;&#23572;&#21487;&#22827;&#25968;&#25454;&#37319;&#26679;&#30340;&#27969;&#24335;PCA&#31639;&#27861;&#65292;&#24182;&#33719;&#24471;&#20102;&#35813;&#31639;&#27861;&#22312;&#25972;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#31532;&#19968;&#20010;&#23574;&#38160;&#29575;&#65292;&#25552;&#39640;&#20102;&#31639;&#27861;&#30340;&#25928;&#29575;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#25552;&#20986;&#30340;&#33258;&#36866;&#24212;&#26041;&#26696;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#31034;&#20363;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#20174;Oja&#22312;1982&#24180;&#30340;&#32463;&#20856;&#35770;&#25991;&#20013;&#39318;&#27425;&#25552;&#20986;&#20197;&#26469;&#65292;Oja&#31639;&#27861;&#24050;&#25104;&#20026;&#27969;&#24335;&#20027;&#25104;&#20998;&#20998;&#26512;(PCA)&#30340;&#19968;&#31181;&#24120;&#29992;&#26041;&#27861;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#27969;&#24335;PCA&#38382;&#39064;&#65292;&#20854;&#20013;&#25968;&#25454;&#28857;&#20174;&#19968;&#20010;&#19981;&#21487;&#32422;&#12289;&#26080;&#21608;&#26399;&#12289;&#21487;&#36870;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#20013;&#37319;&#26679;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20272;&#35745;&#24179;&#31283;&#20998;&#24067;&#30340;&#26410;&#30693;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#21069;&#19968;&#20010;&#29305;&#24449;&#21521;&#37327;&#12290;&#36825;&#31181;&#24773;&#20917;&#36866;&#29992;&#20110;&#21482;&#33021;&#20174;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;(MCMC)&#31867;&#22411;&#30340;&#31639;&#27861;&#20013;&#37319;&#26679;&#25968;&#25454;&#65292;&#24182;&#19988;&#30446;&#26631;&#26159;&#23545;&#35813;&#38142;&#30340;&#24179;&#31283;&#20998;&#24067;&#30340;&#21442;&#25968;&#36827;&#34892;&#25512;&#26029;&#30340;&#24773;&#20917;&#12290;&#29616;&#26377;&#25991;&#29486;&#20013;&#22823;&#22810;&#25968;Oja&#31639;&#27861;&#30340;&#25910;&#25947;&#20445;&#35777;&#37117;&#20551;&#23450;&#25968;&#25454;&#28857;&#26159;IID&#37319;&#26679;&#30340;&#12290;&#23545;&#20110;&#20855;&#26377;&#39532;&#23572;&#21487;&#22827;&#20381;&#36182;&#20851;&#31995;&#30340;&#25968;&#25454;&#27969;&#65292;&#20154;&#20204;&#36890;&#24120;&#23545;&#25968;&#25454;&#36827;&#34892;&#19979;&#37319;&#26679;&#20197;&#33719;&#24471;"&#20960;&#20046;"&#29420;&#31435;&#30340;&#25968;&#25454;&#27969;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;Oja&#31639;&#27861;&#22312;&#25972;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#31532;&#19968;&#20010;&#23574;&#38160;&#29575;&#65292;&#20854;&#20013;&#21435;&#25481;&#20102;$n$&#30340;&#23545;&#25968;&#20381;&#36182;&#24615;&#65292;&#32467;&#26524;&#26159;$\mathcal{O}(n^{-1})$&#30340;&#36895;&#29575;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26041;&#26696;&#26469;&#35843;&#25972;&#31639;&#27861;&#30340;&#27493;&#38271;&#65292;&#23427;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#31034;&#20363;&#20013;&#37117;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Since its inception in Erikki Oja's seminal paper in 1982, Oja's algorithm has become an established method for streaming principle component analysis (PCA). We study the problem of streaming PCA, where the data-points are sampled from an irreducible, aperiodic, and reversible Markov chain. Our goal is to estimate the top eigenvector of the unknown covariance matrix of the stationary distribution. This setting has implications in situations where data can only be sampled from a Markov Chain Monte Carlo (MCMC) type algorithm, and the goal is to do inference for parameters of the stationary distribution of this chain. Most convergence guarantees for Oja's algorithm in the literature assume that the data-points are sampled IID. For data streams with Markovian dependence, one typically downsamples the data to get a "nearly" independent data stream. In this paper, we obtain the first sharp rate for Oja's algorithm on the entire data, where we remove the logarithmic dependence on $n$ resulti
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22870;&#21169;&#25945;&#23398;&#24605;&#24819;&#30340;&#32852;&#37030;&#22810;&#33218;&#32769;&#34382;&#26426;&#35774;&#35745;&#65292;&#36890;&#36807;&#38544;&#24335;&#26412;&#22320;&#22870;&#21169;&#35843;&#25972;&#26469;&#25351;&#23548;&#23458;&#25143;&#31471;&#26397;&#30528;&#20840;&#23616;&#26368;&#20248;&#24615;&#65292;&#38431;&#26381;&#21153;&#31471;&#25552;&#20986;&#20102;&#32769;&#34382;&#26426;&#23398;&#20064;&#21644;&#30446;&#26631;&#25945;&#23398;&#20219;&#21153;&#36827;&#34892;&#20102;&#20248;&#21270;&#12290;</title><link>http://arxiv.org/abs/2305.02441</link><description>&lt;p&gt;
&#22522;&#20110;&#22870;&#21169;&#25945;&#23398;&#30340;&#32852;&#37030;&#22810;&#33218;&#32769;&#34382;&#26426;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Reward Teaching for Federated Multi-armed Bandits. (arXiv:2305.02441v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02441
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22870;&#21169;&#25945;&#23398;&#24605;&#24819;&#30340;&#32852;&#37030;&#22810;&#33218;&#32769;&#34382;&#26426;&#35774;&#35745;&#65292;&#36890;&#36807;&#38544;&#24335;&#26412;&#22320;&#22870;&#21169;&#35843;&#25972;&#26469;&#25351;&#23548;&#23458;&#25143;&#31471;&#26397;&#30528;&#20840;&#23616;&#26368;&#20248;&#24615;&#65292;&#38431;&#26381;&#21153;&#31471;&#25552;&#20986;&#20102;&#32769;&#34382;&#26426;&#23398;&#20064;&#21644;&#30446;&#26631;&#25945;&#23398;&#20219;&#21153;&#36827;&#34892;&#20102;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#22823;&#37096;&#20998;&#24050;&#26377;&#30340;&#32852;&#37030;&#22810;&#33218;&#32769;&#34382;&#26426;&#65288;FMAB&#65289;&#35774;&#35745;&#37117;&#22522;&#20110;&#20551;&#35774;&#23458;&#25143;&#31471;&#20250;&#23454;&#29616;&#25351;&#23450;&#30340;&#35774;&#35745;&#26469;&#19982;&#26381;&#21153;&#22120;&#21327;&#20316;&#12290;&#20294;&#23454;&#38469;&#19978;&#65292;&#21487;&#33021;&#26080;&#27861;&#20462;&#25913;&#23458;&#25143;&#31471;&#29616;&#26377;&#30340;&#21327;&#35758;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#19968;&#25361;&#25112;&#65292;&#35813;&#24037;&#20316;&#20851;&#27880;&#22987;&#32456;&#26368;&#22823;&#21270;&#20854;&#20010;&#20307;&#32047;&#31215;&#22870;&#21169;&#30340;&#23458;&#25143;&#31471;&#65292;&#24182;&#24341;&#20837;&#20102;&#8220;&#22870;&#21169;&#25945;&#23398;&#8221;&#30340;&#26032;&#24605;&#24819;&#65292;&#21363;&#36890;&#36807;&#38544;&#24335;&#30340;&#26412;&#22320;&#22870;&#21169;&#35843;&#25972;&#25351;&#23548;&#23458;&#25143;&#31471;&#26397;&#30528;&#20840;&#23616;&#26368;&#20248;&#24615;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#19979;&#65292;&#26381;&#21153;&#22120;&#38754;&#20020;&#20004;&#20010;&#23494;&#20999;&#32806;&#21512;&#30340;&#20219;&#21153;&#65292;&#21363;&#32769;&#34382;&#26426;&#23398;&#20064;&#21644;&#30446;&#26631;&#25945;&#23398;&#65292;&#23427;&#20204;&#30340;&#32467;&#21512;&#38750;&#24120;&#22797;&#26434;&#21644;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#39318;&#20808;&#35774;&#35745;&#20102;&#19968;&#20010;&#21517;&#20026; &#8220;Teaching-After-Learning&#65288;TAL&#65289;&#8221; &#30340;&#20998;&#38454;&#27573;&#26041;&#27861;&#65292;&#20998;&#21035;&#40723;&#21169;&#21644;&#38480;&#21046;&#23458;&#25143;&#31471;&#30340;&#25506;&#32034;&#12290;&#24403;&#23458;&#25143;&#31471;&#31574;&#30053;&#28385;&#36275;&#19968;&#23450;&#30340;&#28201;&#21644;&#35201;&#27714;&#26102;&#65292;&#24314;&#31435;&#20102;TAL&#30340;&#32508;&#21512;&#24615;&#33021;&#20998;&#26512;&#12290;&#36890;&#36807;&#24320;&#21457;&#26032;&#30340;&#25216;&#26415;&#26041;&#27861;&#26469;&#20998;&#26512;TAL&#30340;&#28909;&#21551;&#21160;&#21644;&#31639;&#27861;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;TAL&#21487;&#20197;&#27604;&#29616;&#26377;&#30340;FMAB&#35774;&#35745;&#24102;&#26469;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most of the existing federated multi-armed bandits (FMAB) designs are based on the presumption that clients will implement the specified design to collaborate with the server. In reality, however, it may not be possible to modify the client's existing protocols. To address this challenge, this work focuses on clients who always maximize their individual cumulative rewards, and introduces a novel idea of "reward teaching", where the server guides the clients towards global optimality through implicit local reward adjustments. Under this framework, the server faces two tightly coupled tasks of bandit learning and target teaching, whose combination is non-trivial and challenging. A phased approach, called Teaching-After-Learning (TAL), is first designed to encourage and discourage clients' explorations separately. General performance analyses of TAL are established when the clients' strategies satisfy certain mild requirements. With novel technical approaches developed to analyze the warm
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#31216;&#20026;&#8220;&#26102;&#38388;&#32534;&#30721;&#23884;&#20837;&#8221;&#65292;&#21487;&#20197;&#20197;&#32447;&#24615;&#22797;&#26434;&#24230;&#26377;&#25928;&#22320;&#23884;&#20837;&#22823;&#37327;&#22270;&#25968;&#25454;&#65292;&#24182;&#21033;&#29992;&#27492;&#26041;&#27861;&#22312;&#22823;&#22411;&#32452;&#32455;&#30340;&#36890;&#20449;&#32593;&#32476;&#20013;&#26816;&#27979;&#20986;&#20102;&#20010;&#20307;&#39030;&#28857;&#12289;&#39030;&#28857;&#31038;&#21306;&#21644;&#25972;&#20307;&#22270;&#32467;&#26500;&#30340;&#36890;&#20449;&#27169;&#24335;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2305.02381</link><description>&lt;p&gt;
&#21033;&#29992;&#32534;&#30721;&#23884;&#20837;&#21644;&#39030;&#28857;&#21160;&#24577;&#21457;&#29616;&#22823;&#35268;&#27169;&#32593;&#32476;&#20013;&#30340;&#36890;&#20449;&#27169;&#24335;&#21464;&#21270;
&lt;/p&gt;
&lt;p&gt;
Discovering Communication Pattern Shifts in Large-Scale Networks using Encoder Embedding and Vertex Dynamics. (arXiv:2305.02381v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02381
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#31216;&#20026;&#8220;&#26102;&#38388;&#32534;&#30721;&#23884;&#20837;&#8221;&#65292;&#21487;&#20197;&#20197;&#32447;&#24615;&#22797;&#26434;&#24230;&#26377;&#25928;&#22320;&#23884;&#20837;&#22823;&#37327;&#22270;&#25968;&#25454;&#65292;&#24182;&#21033;&#29992;&#27492;&#26041;&#27861;&#22312;&#22823;&#22411;&#32452;&#32455;&#30340;&#36890;&#20449;&#32593;&#32476;&#20013;&#26816;&#27979;&#20986;&#20102;&#20010;&#20307;&#39030;&#28857;&#12289;&#39030;&#28857;&#31038;&#21306;&#21644;&#25972;&#20307;&#22270;&#32467;&#26500;&#30340;&#36890;&#20449;&#27169;&#24335;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#26512;&#22823;&#35268;&#27169;&#26102;&#38388;&#24207;&#21015;&#32593;&#32476;&#25968;&#25454;&#65288;&#22914;&#31038;&#20132;&#23186;&#20307;&#21644;&#30005;&#23376;&#37038;&#20214;&#36890;&#20449;&#65289;&#20173;&#28982;&#26159;&#22270;&#20998;&#26512;&#26041;&#27861;&#23398;&#38754;&#20020;&#30340;&#37325;&#22823;&#25361;&#25112;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#26102;&#38388;&#32534;&#30721;&#23884;&#20837;&#8221;&#30340;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#20197;&#32447;&#24615;&#22797;&#26434;&#24230;&#26377;&#25928;&#22320;&#23884;&#20837;&#22823;&#37327;&#30340;&#22270;&#25968;&#25454;&#12290;&#25105;&#20204;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#19968;&#23478;&#22823;&#22411;&#26426;&#26500;&#36328;&#36234;2019&#24180;&#33267;2020&#24180;&#30340;&#21311;&#21517;&#26102;&#38388;&#24207;&#21015;&#36890;&#20449;&#32593;&#32476;&#65292;&#30001;&#36229;&#36807;10&#19975;&#20010;&#39030;&#28857;&#21644;8000&#19975;&#20010;&#36793;&#32452;&#25104;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26631;&#20934;&#35745;&#31639;&#26426;&#19978;&#20165;&#38656;10&#31186;&#21363;&#21487;&#23884;&#20837;&#25968;&#25454;&#65292;&#24182;&#33021;&#22815;&#26816;&#27979;&#20010;&#20307;&#39030;&#28857;&#12289;&#39030;&#28857;&#31038;&#21306;&#21644;&#25972;&#20307;&#22270;&#32467;&#26500;&#30340;&#36890;&#20449;&#27169;&#24335;&#21464;&#21270;&#12290;&#36890;&#36807;&#25903;&#25345;&#29702;&#35770;&#21644;&#32508;&#21512;&#30740;&#31350;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#38543;&#26426;&#22270;&#27169;&#22411;&#19979;&#30340;&#29702;&#35770;&#20581;&#20840;&#24615;&#21644;&#25968;&#20540;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
The analysis of large-scale time-series network data, such as social media and email communications, remains a significant challenge for graph analysis methodology. In particular, the scalability of graph analysis is a critical issue hindering further progress in large-scale downstream inference. In this paper, we introduce a novel approach called "temporal encoder embedding" that can efficiently embed large amounts of graph data with linear complexity. We apply this method to an anonymized time-series communication network from a large organization spanning 2019-2020, consisting of over 100 thousand vertices and 80 million edges. Our method embeds the data within 10 seconds on a standard computer and enables the detection of communication pattern shifts for individual vertices, vertex communities, and the overall graph structure. Through supporting theory and synthesis studies, we demonstrate the theoretical soundness of our approach under random graph models and its numerical effecti
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;/&#21435;&#20559;&#26426;&#22120;&#23398;&#20064;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#23545;&#26102;&#38388;&#33267;&#20107;&#20214;&#32467;&#26524;&#30340;&#21152;&#26435;&#24179;&#22343;&#27835;&#30103;&#25928;&#24212;&#36827;&#34892;&#20272;&#35745;&#65292;&#35299;&#20915;&#20102;&#35206;&#30422;&#24230;&#19981;&#36275;&#30340;&#25361;&#25112;&#65292;&#24182;&#36890;&#36807;&#35777;&#26126;&#20854;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24120;&#24615;&#26469;&#39564;&#35777;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.02373</link><description>&lt;p&gt;
&#21452;&#37325;/&#21435;&#20559;&#26426;&#22120;&#23398;&#20064;&#30340;&#21152;&#26435;&#32047;&#31215;&#27835;&#30103;&#25928;&#24212;&#30340;&#26377;&#25928;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Efficient estimation of weighted cumulative treatment effects by double/debiased machine learning. (arXiv:2305.02373v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02373
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;/&#21435;&#20559;&#26426;&#22120;&#23398;&#20064;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#23545;&#26102;&#38388;&#33267;&#20107;&#20214;&#32467;&#26524;&#30340;&#21152;&#26435;&#24179;&#22343;&#27835;&#30103;&#25928;&#24212;&#36827;&#34892;&#20272;&#35745;&#65292;&#35299;&#20915;&#20102;&#35206;&#30422;&#24230;&#19981;&#36275;&#30340;&#25361;&#25112;&#65292;&#24182;&#36890;&#36807;&#35777;&#26126;&#20854;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24120;&#24615;&#26469;&#39564;&#35777;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20855;&#26377;&#26102;&#38388;&#33267;&#20107;&#20214;&#32467;&#26524;&#30340;&#32463;&#39564;&#30740;&#31350;&#20013;&#65292;&#30740;&#31350;&#20154;&#21592;&#24120;&#24120;&#21033;&#29992;&#35266;&#23519;&#25968;&#25454;&#65292;&#22312;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#25968;&#25454;&#19981;&#36866;&#29992;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#26333;&#20809;&#30340;&#22240;&#26524;&#25512;&#26029;&#12290;&#27169;&#22411;&#38169;&#37197;&#21644;&#32570;&#20047;&#37325;&#21472;&#26159;&#35266;&#23519;&#30740;&#31350;&#20013;&#24120;&#35265;&#30340;&#38382;&#39064;&#65292;&#23427;&#20204;&#32463;&#24120;&#23548;&#33268;&#24179;&#22343;&#27835;&#30103;&#25928;&#24212;&#30340;&#19981;&#19968;&#33268;&#21644;&#20302;&#25928;&#30340;&#20272;&#35745;&#22120;&#12290;&#20026;&#35299;&#20915;&#35206;&#30422;&#24230;&#19981;&#36275;&#30340;&#25361;&#25112;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#38024;&#23545;&#21472;&#21152;&#21152;&#26435;&#25928;&#24212;&#30340;&#20272;&#35745;&#22120;&#65292;&#32780;&#20351;&#36741;&#21161;&#27169;&#22411;&#33021;&#22815;&#36827;&#34892;&#28789;&#27963;&#30340;&#26426;&#22120;&#23398;&#20064;&#30340;&#26041;&#27861;&#21487;&#20197;&#35299;&#20915;&#27169;&#22411;&#38169;&#37197;&#30340;&#38382;&#39064;&#12290;&#20294;&#26159;&#65292;&#24403;&#23384;&#22312;&#35206;&#30422;&#24230;&#19981;&#36275;&#26102;&#65292;&#20801;&#35768;&#36741;&#21161;&#27169;&#22411;&#36827;&#34892;&#26426;&#22120;&#23398;&#20064;&#30340;&#26041;&#27861;&#23578;&#26410;&#25193;&#23637;&#21040;&#26102;&#38388;&#33267;&#20107;&#20214;&#32467;&#26524;&#30340;&#21152;&#26435;&#24179;&#22343;&#27835;&#30103;&#25928;&#24212;&#30340;&#24773;&#26223;&#20013;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31867;&#19968;&#27493;&#20132;&#21449;&#36866;&#24212;&#30340;&#21452;&#37325;/&#21435;&#20559;&#26426;&#22120;&#23398;&#20064;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#20316;&#20026;&#38480;&#21046;&#26102;&#38388;&#30340;&#21152;&#26435;&#32047;&#31215;&#22240;&#26524;&#25928;&#24212;&#30340;&#20989;&#25968;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25311;&#35758;&#26041;&#27861;&#30340;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24120;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In empirical studies with time-to-event outcomes, investigators often leverage observational data to conduct causal inference on the effect of exposure when randomized controlled trial data is unavailable. Model misspecification and lack of overlap are common issues in observational studies, and they often lead to inconsistent and inefficient estimators of the average treatment effect. Estimators targeting overlap weighted effects have been proposed to address the challenge of poor overlap, and methods enabling flexible machine learning for nuisance models address model misspecification. However, the approaches that allow machine learning for nuisance models have not been extended to the setting of weighted average treatment effects for time-to-event outcomes when there is poor overlap. In this work, we propose a class of one-step cross-fitted double/debiased machine learning estimators for the weighted cumulative causal effect as a function of restriction time. We prove that the propo
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#23398;&#20064;&#37096;&#20998;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#26469;&#36827;&#34892;&#19978;&#19979;&#25991;&#36866;&#24212;&#21644;&#25506;&#32034;&#30340;&#26032;&#26041;&#27861;&#65292;&#20854;&#20351;&#29992;&#21464;&#21387;&#22120;&#36827;&#34892;&#25512;&#29702;&#36807;&#31243;&#23398;&#20064;&#65292;&#32771;&#34385;&#20102;&#27169;&#22411;&#20551;&#35774;&#31354;&#38388;&#65292;&#20551;&#35774;&#34920;&#31034;&#20026;&#23567;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65292;&#21487;&#20197;&#22312;&#24615;&#20215;&#27604;&#39640;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#21160;&#24577;&#35268;&#21010;&#12290;&#35813;&#26041;&#27861;&#22312;Symbolic Alchemy&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#19982;&#31934;&#30830;&#21518;&#39564;&#25277;&#26679;&#30456;&#36817;&#30340;&#36866;&#24212;&#36895;&#24230;&#21644;&#25506;&#32034;&#21033;&#29992;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2302.04250</link><description>&lt;p&gt;
&#23398;&#20064;&#22914;&#20309;&#25512;&#26029;&#37096;&#20998;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#36827;&#34892;&#19978;&#19979;&#25991;&#36866;&#24212;&#21644;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Learning How to Infer Partial MDPs for In-Context Adaptation and Exploration. (arXiv:2302.04250v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04250
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#23398;&#20064;&#37096;&#20998;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#26469;&#36827;&#34892;&#19978;&#19979;&#25991;&#36866;&#24212;&#21644;&#25506;&#32034;&#30340;&#26032;&#26041;&#27861;&#65292;&#20854;&#20351;&#29992;&#21464;&#21387;&#22120;&#36827;&#34892;&#25512;&#29702;&#36807;&#31243;&#23398;&#20064;&#65292;&#32771;&#34385;&#20102;&#27169;&#22411;&#20551;&#35774;&#31354;&#38388;&#65292;&#20551;&#35774;&#34920;&#31034;&#20026;&#23567;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65292;&#21487;&#20197;&#22312;&#24615;&#20215;&#27604;&#39640;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#21160;&#24577;&#35268;&#21010;&#12290;&#35813;&#26041;&#27861;&#22312;Symbolic Alchemy&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#19982;&#31934;&#30830;&#21518;&#39564;&#25277;&#26679;&#30456;&#36817;&#30340;&#36866;&#24212;&#36895;&#24230;&#21644;&#25506;&#32034;&#21033;&#29992;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#22312;&#20219;&#21153;&#38388;&#36827;&#34892;&#27867;&#21270;&#65292;&#26234;&#33021;&#20307;&#24212;&#35813;&#20174;&#36807;&#21435;&#30340;&#20219;&#21153;&#20013;&#33719;&#21462;&#30693;&#35782;&#65292;&#20197;&#20419;&#36827;&#26410;&#26469;&#20219;&#21153;&#20013;&#30340;&#36866;&#24212;&#21644;&#25506;&#32034;&#12290;&#25105;&#20204;&#20851;&#27880;&#19978;&#19979;&#25991;&#36866;&#24212;&#21644;&#25506;&#32034;&#38382;&#39064;&#65292;&#20854;&#20013;&#19968;&#20010;&#26234;&#33021;&#20307;&#21482;&#20381;&#36182;&#20110;&#19978;&#19979;&#25991;&#65292;&#21363;&#29366;&#24577;&#12289;&#21160;&#20316;&#21644;/&#25110;&#22870;&#21169;&#30340;&#21382;&#21490;&#35760;&#24405;&#65292;&#32780;&#19981;&#26159;&#26799;&#24230;&#26356;&#26032;&#12290;&#21518;&#39564;&#25277;&#26679;&#26159;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#65292;&#20294;&#23427;&#38656;&#35201;&#36125;&#21494;&#26031;&#25512;&#29702;&#21644;&#21160;&#24577;&#35268;&#21010;&#65292;&#36890;&#24120;&#28041;&#21450;&#26410;&#30693;&#37327;&#65288;&#20363;&#22914;&#65292;&#20808;&#39564;&#65289;&#21644;&#26114;&#36149;&#30340;&#35745;&#31639;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#22256;&#38590;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#21464;&#21387;&#22120;&#26469;&#20174;&#35757;&#32451;&#20219;&#21153;&#20013;&#23398;&#20064;&#25512;&#29702;&#36807;&#31243;&#65292;&#24182;&#32771;&#34385;&#19968;&#20010;&#20551;&#35774;&#31354;&#38388;&#30340;&#37096;&#20998;&#27169;&#22411;&#65292;&#34920;&#31034;&#20026;&#23567;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65292;&#36825;&#23545;&#20110;&#21160;&#24577;&#35268;&#21010;&#26469;&#35828;&#26159;&#24265;&#20215;&#30340;&#12290;&#22312;&#25105;&#20204;&#29256;&#26412;&#30340;Symbolic Alchemy&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#36866;&#24212;&#36895;&#24230;&#21644;&#25506;&#32034;&#21033;&#29992;&#24179;&#34913;&#25509;&#36817;&#20110;&#31934;&#30830;&#30340;&#21518;&#39564;&#25277;&#26679;&#31070;&#35861;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#21363;&#20351;&#37096;&#20998;&#27169;&#22411;&#25490;&#38500;&#20102;r
&lt;/p&gt;
&lt;p&gt;
To generalize across tasks, an agent should acquire knowledge from past tasks that facilitate adaptation and exploration in future tasks. We focus on the problem of in-context adaptation and exploration, where an agent only relies on context, i.e., history of states, actions and/or rewards, rather than gradient-based updates. Posterior sampling (extension of Thompson sampling) is a promising approach, but it requires Bayesian inference and dynamic programming, which often involve unknowns (e.g., a prior) and costly computations. To address these difficulties, we use a transformer to learn an inference process from training tasks and consider a hypothesis space of partial models, represented as small Markov decision processes that are cheap for dynamic programming. In our version of the Symbolic Alchemy benchmark, our method's adaptation speed and exploration-exploitation balance approach those of an exact posterior sampling oracle. We also show that even though partial models exclude r
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#39033;&#24335;logit&#27169;&#22411;&#30340;&#25512;&#26029;&#26694;&#26550;&#65292;&#21487;&#20197;&#27979;&#35797;&#26368;&#20248;&#20135;&#21697;&#32452;&#21512;&#26159;&#21542;&#20855;&#26377;&#29305;&#23450;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2301.12254</link><description>&lt;p&gt;
&#22810;&#39033;&#24335;Logit&#27169;&#22411;&#20013;&#26368;&#20248;&#20135;&#21697;&#32452;&#21512;&#30340;&#32452;&#21512;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Combinatorial Inference on the Optimal Assortment in Multinomial Logit Models. (arXiv:2301.12254v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12254
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#39033;&#24335;logit&#27169;&#22411;&#30340;&#25512;&#26029;&#26694;&#26550;&#65292;&#21487;&#20197;&#27979;&#35797;&#26368;&#20248;&#20135;&#21697;&#32452;&#21512;&#26159;&#21542;&#20855;&#26377;&#29305;&#23450;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20248;&#30340;&#20135;&#21697;&#32452;&#21512;&#20248;&#21270;&#24050;&#32463;&#25104;&#20026;&#23454;&#36341;&#20013;&#30340;&#37325;&#35201;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25512;&#26029;&#26694;&#26550;&#65292;&#29992;&#20110;&#27979;&#35797;&#26368;&#20248;&#20135;&#21697;&#32452;&#21512;&#26159;&#21542;&#20855;&#26377;&#29305;&#23450;&#24615;&#36136;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#24191;&#27867;&#37319;&#29992;&#30340;&#22810;&#39033;&#24335;logit&#65288;MNL&#65289;&#27169;&#22411;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#30740;&#31350;&#26368;&#20248;&#32452;&#21512;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Assortment optimization has received active explorations in the past few decades due to its practical importance. Despite the extensive literature dealing with optimization algorithms and latent score estimation, uncertainty quantification for the optimal assortment still needs to be explored and is of great practical significance. Instead of estimating and recovering the complete optimal offer set, decision-makers may only be interested in testing whether a given property holds true for the optimal assortment, such as whether they should include several products of interest in the optimal set, or how many categories of products the optimal set should include. This paper proposes a novel inferential framework for testing such properties. We consider the widely adopted multinomial logit (MNL) model, where we assume that each customer will purchase an item within the offered products with a probability proportional to the underlying preference score associated with the product. We reduce
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#25193;&#25955;&#27169;&#22411;&#20013;&#28418;&#31227;&#39033;&#30340;&#25968;&#23398;&#20998;&#26512;&#12290;&#36890;&#36807;&#27425;&#27969;&#24418;&#20551;&#35774;&#65292;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#30446;&#26631;&#20989;&#25968;&#21644;&#30456;&#20851;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#21487;&#22788;&#29702;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#22855;&#24322;&#25968;&#25454;&#20998;&#24067;&#65292;&#35299;&#20915;&#20102;&#22343;&#20540;&#28418;&#31227;&#20989;&#25968;&#21644;&#24471;&#20998;&#20989;&#25968;&#28176;&#36817;&#21457;&#25955;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2301.07882</link><description>&lt;p&gt;
&#22522;&#20110;&#27425;&#27969;&#24418;&#20551;&#35774;&#19979;&#25193;&#25955;&#27169;&#22411;&#22855;&#24322;&#24615;&#30340;&#25968;&#23398;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Mathematical analysis of singularities in the diffusion model under the submanifold assumption. (arXiv:2301.07882v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.07882
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#25193;&#25955;&#27169;&#22411;&#20013;&#28418;&#31227;&#39033;&#30340;&#25968;&#23398;&#20998;&#26512;&#12290;&#36890;&#36807;&#27425;&#27969;&#24418;&#20551;&#35774;&#65292;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#30446;&#26631;&#20989;&#25968;&#21644;&#30456;&#20851;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#21487;&#22788;&#29702;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#22855;&#24322;&#25968;&#25454;&#20998;&#24067;&#65292;&#35299;&#20915;&#20102;&#22343;&#20540;&#28418;&#31227;&#20989;&#25968;&#21644;&#24471;&#20998;&#20989;&#25968;&#28176;&#36817;&#21457;&#25955;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#25193;&#25955;&#27169;&#22411;&#30340;&#25968;&#23398;&#20998;&#26512;&#12290;&#20197;&#26465;&#20214;&#26399;&#26395;&#34920;&#31034;&#21453;&#21521;&#37319;&#26679;&#27969;&#31243;&#30340;&#28418;&#31227;&#39033;&#65292;&#20854;&#20013;&#28041;&#21450;&#25968;&#25454;&#20998;&#24067;&#21644;&#21069;&#21521;&#25193;&#25955;&#12290;&#35757;&#32451;&#36807;&#31243;&#26088;&#22312;&#36890;&#36807;&#26368;&#23567;&#21270;&#19982;&#26465;&#20214;&#26399;&#26395;&#30456;&#20851;&#30340;&#22343;&#26041;&#27531;&#24046;&#26469;&#23547;&#25214;&#27492;&#31867;&#28418;&#31227;&#20989;&#25968;&#12290;&#20351;&#29992;&#21069;&#21521;&#25193;&#25955;&#30340;Green&#20989;&#25968;&#30340;&#23567;&#26102;&#38388;&#36817;&#20284;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;DDPM&#20013;&#30340;&#35299;&#26512;&#22343;&#20540;&#28418;&#31227;&#20989;&#25968;&#21644;SGM&#20013;&#30340;&#24471;&#20998;&#20989;&#25968;&#22312;&#37319;&#26679;&#36807;&#31243;&#30340;&#26368;&#21518;&#38454;&#27573;&#65292;&#23545;&#20110;&#20687;&#37027;&#20123;&#38598;&#20013;&#22312;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#22855;&#24322;&#25968;&#25454;&#20998;&#24067;&#32780;&#35328;&#65292;&#28176;&#36817;&#22320;&#21457;&#25955;&#65292;&#22240;&#27492;&#38590;&#20197;&#36890;&#36807;&#32593;&#32476;&#36827;&#34892;&#36924;&#36817;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#22256;&#38590;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#30446;&#26631;&#20989;&#25968;&#21644;&#30456;&#20851;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;&#20351;&#22312;&#22788;&#29702;&#22855;&#24322;&#25968;&#25454;&#20998;&#24067;&#26102;&#20173;&#28982;&#20445;&#25345;&#26377;&#30028;&#12290;&#25105;&#20204;&#36890;&#36807;&#20960;&#20010;&#25968;&#20540;&#23454;&#39564;&#26469;&#35828;&#26126;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper provide several mathematical analyses of the diffusion model in machine learning. The drift term of the backwards sampling process is represented as a conditional expectation involving the data distribution and the forward diffusion. The training process aims to find such a drift function by minimizing the mean-squared residue related to the conditional expectation. Using small-time approximations of the Green's function of the forward diffusion, we show that the analytical mean drift function in DDPM and the score function in SGM asymptotically blow up in the final stages of the sampling process for singular data distributions such as those concentrated on lower-dimensional manifolds, and is therefore difficult to approximate by a network. To overcome this difficulty, we derive a new target function and associated loss, which remains bounded even for singular data distributions. We illustrate the theoretical findings with several numerical examples.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#27491;&#21017;&#21270;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;ProxSPS&#31639;&#27861;&#65292;&#30456;&#27604;&#38543;&#26426;Polyak&#27493;&#38271;&#65288;SPS&#65289;&#26356;&#31283;&#23450;&#26131;&#35843;&#25972;&#65292;&#21516;&#26102;&#22312;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#20013;&#34920;&#29616;&#33391;&#22909;&#65292;&#21487;&#23548;&#33268;&#32593;&#32476;&#20855;&#26377;&#26356;&#23567;&#30340;&#26435;&#37325;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2301.04935</link><description>&lt;p&gt;
&#19968;&#31181;&#38543;&#26426;Proximal Polyak&#27493;&#38271;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Stochastic Proximal Polyak Step Size. (arXiv:2301.04935v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.04935
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#27491;&#21017;&#21270;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;ProxSPS&#31639;&#27861;&#65292;&#30456;&#27604;&#38543;&#26426;Polyak&#27493;&#38271;&#65288;SPS&#65289;&#26356;&#31283;&#23450;&#26131;&#35843;&#25972;&#65292;&#21516;&#26102;&#22312;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#20013;&#34920;&#29616;&#33391;&#22909;&#65292;&#21487;&#23548;&#33268;&#32593;&#32476;&#20855;&#26377;&#26356;&#23567;&#30340;&#26435;&#37325;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#38543;&#26426;Polyak&#27493;&#38271;&#65288;SPS&#65289;&#24050;&#25104;&#20026;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#31454;&#20105;&#24615;&#33258;&#36866;&#24212;&#27493;&#38271;&#26041;&#26696;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;ProxSPS&#65292;&#36825;&#26159;SPS&#30340;proximal&#21464;&#20307;&#65292;&#21487;&#20197;&#22788;&#29702;&#27491;&#21017;&#21270;&#39033;&#12290;&#24320;&#21457;SPS&#30340;proximal&#21464;&#20307;&#29305;&#21035;&#37325;&#35201;&#65292;&#22240;&#20026;SPS&#38656;&#35201;&#30446;&#26631;&#20989;&#25968;&#30340;&#19979;&#30028;&#25165;&#33021;&#21457;&#25381;&#33391;&#22909;&#30340;&#20316;&#29992;&#12290;&#24403;&#30446;&#26631;&#20989;&#25968;&#26159;&#25439;&#22833;&#21644;&#27491;&#21017;&#21270;&#39033;&#30340;&#24635;&#21644;&#26102;&#65292;&#21487;&#29992;&#30340;&#24635;&#21644;&#19979;&#30028;&#20272;&#35745;&#21487;&#33021;&#19981;&#20934;&#30830;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;ProxSPS&#21482;&#38656;&#35201;&#23545;&#25439;&#22833;&#36827;&#34892;&#19979;&#30028;&#20272;&#35745;&#65292;&#32780;&#36825;&#36890;&#24120;&#24456;&#23481;&#26131;&#24471;&#21040;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;ProxSPS&#26356;&#26131;&#20110;&#35843;&#25972;&#65292;&#22312;&#27491;&#21017;&#21270;&#30340;&#24773;&#20917;&#19979;&#26356;&#31283;&#23450;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#65292;ProxSPS&#34920;&#29616;&#19982;AdamW&#19968;&#26679;&#22909;&#65292;&#20960;&#20046;&#19981;&#38656;&#35201;&#35843;&#25972;&#65292;&#24182;&#19988;&#23548;&#33268;&#20855;&#26377;&#26356;&#23567;&#26435;&#37325;&#21442;&#25968;&#30340;&#32593;&#32476;&#12290;&#25105;&#20204;&#36824;&#20026;ProxSPS&#25552;&#20379;&#20102;&#24191;&#27867;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#21253;&#25324;&#38750;&#20809;&#28369;&#12289;&#20809;&#28369;&#12289;&#24369;&#20984;&#21644;&#24378;&#20984;&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, the stochastic Polyak step size (SPS) has emerged as a competitive adaptive step size scheme for stochastic gradient descent. Here we develop ProxSPS, a proximal variant of SPS that can handle regularization terms. Developing a proximal variant of SPS is particularly important, since SPS requires a lower bound of the objective function to work well. When the objective function is the sum of a loss and a regularizer, available estimates of a lower bound of the sum can be loose. In contrast, ProxSPS only requires a lower bound for the loss which is often readily available. As a consequence, we show that ProxSPS is easier to tune and more stable in the presence of regularization. Furthermore for image classification tasks, ProxSPS performs as well as AdamW with little to no tuning, and results in a network with smaller weight parameters. We also provide an extensive convergence analysis for ProxSPS that includes the non-smooth, smooth, weakly convex and strongly convex setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30417;&#30563;&#23545;&#27604;&#25439;&#22833;&#24418;&#24335;&#65288;epsilon-SupInfoNCE&#65289;&#20197;&#21450;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#27491;&#21017;&#21270;&#25439;&#22833;&#65288;FairKL&#65289;&#65292;&#26088;&#22312;&#35299;&#20915;&#20174;&#26377;&#20559;&#25968;&#25454;&#20013;&#23398;&#20064;&#26080;&#20559;&#27169;&#22411;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2211.05568</link><description>&lt;p&gt;
&#26080;&#20559;&#30340;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Unbiased Supervised Contrastive Learning. (arXiv:2211.05568v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.05568
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30417;&#30563;&#23545;&#27604;&#25439;&#22833;&#24418;&#24335;&#65288;epsilon-SupInfoNCE&#65289;&#20197;&#21450;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#27491;&#21017;&#21270;&#25439;&#22833;&#65288;FairKL&#65289;&#65292;&#26088;&#22312;&#35299;&#20915;&#20174;&#26377;&#20559;&#25968;&#25454;&#20013;&#23398;&#20064;&#26080;&#20559;&#27169;&#22411;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#25968;&#25454;&#38598;&#23384;&#22312;&#20559;&#24046;&#65292;&#21363;&#23427;&#20204;&#21253;&#21547;&#20165;&#22312;&#25968;&#25454;&#38598;&#20013;&#19982;&#30446;&#26631;&#31867;&#39640;&#24230;&#30456;&#20851;&#30340;&#26131;&#20110;&#23398;&#20064;&#30340;&#29305;&#24449;&#65292;&#20294;&#19981;&#22312;&#30495;&#23454;&#30340;&#25968;&#25454;&#20998;&#24067;&#20013;&#12290;&#22240;&#27492;&#65292;&#20174;&#26377;&#20559;&#25968;&#25454;&#20013;&#23398;&#20064;&#26080;&#20559;&#27169;&#22411;&#24050;&#25104;&#20026;&#36817;&#24180;&#26469;&#38750;&#24120;&#30456;&#20851;&#30340;&#30740;&#31350;&#35838;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#23398;&#20064;&#23545;&#20559;&#24046;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#34920;&#24449;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36793;&#32536;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#28548;&#28165;&#20026;&#20160;&#20040;&#26368;&#36817;&#30340;&#23545;&#27604;&#25439;&#22833;&#65288;InfoNCE&#65292;SupCon&#31561;&#65289;&#22312;&#22788;&#29702;&#20559;&#24046;&#25968;&#25454;&#26102;&#21487;&#33021;&#22833;&#36133;&#12290;&#22522;&#20110;&#27492;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30417;&#30563;&#23545;&#27604;&#25439;&#22833;&#24418;&#24335;&#65288;epsilon-SupInfoNCE&#65289;&#65292;&#25552;&#20379;&#20102;&#26356;&#20934;&#30830;&#30340;&#23545;&#27491;&#36127;&#26679;&#26412;&#20043;&#38388;&#26368;&#23567;&#36317;&#31163;&#30340;&#25511;&#21046;&#12290;&#27492;&#22806;&#65292;&#30001;&#20110;&#25105;&#20204;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;FairKL&#65292;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#27491;&#21017;&#21270;&#25439;&#22833;&#65292;&#21363;&#20351;&#22312;&#26497;&#24230;&#20559;&#24046;&#30340;&#25968;&#25454;&#24773;&#20917;&#19979;&#20063;&#21487;&#20197;&#24456;&#22909;&#22320;&#24037;&#20316;&#12290;&#25105;&#20204;&#22312;&#26631;&#20934;&#30340;&#35270;&#35273;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;&#25152;&#25552;&#20986;&#30340;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many datasets are biased, namely they contain easy-to-learn features that are highly correlated with the target class only in the dataset but not in the true underlying distribution of the data. For this reason, learning unbiased models from biased data has become a very relevant research topic in the last years. In this work, we tackle the problem of learning representations that are robust to biases. We first present a margin-based theoretical framework that allows us to clarify why recent contrastive losses (InfoNCE, SupCon, etc.) can fail when dealing with biased data. Based on that, we derive a novel formulation of the supervised contrastive loss (epsilon-SupInfoNCE), providing more accurate control of the minimal distance between positive and negative samples. Furthermore, thanks to our theoretical framework, we also propose FairKL, a new debiasing regularization loss, that works well even with extremely biased data. We validate the proposed losses on standard vision datasets inc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35299;&#20915;&#20102;&#39046;&#22495;&#33258;&#36866;&#24212;&#38382;&#39064;&#20013;&#32570;&#22833;&#25968;&#25454;&#36716;&#31227;&#30340;&#24773;&#20917;&#65292;&#25552;&#20986;&#20102;DAMS&#26041;&#27861;&#12290;&#38024;&#23545;&#32570;&#22833;&#25968;&#25454;&#25351;&#26631;&#19981;&#21487;&#29992;&#30340;&#24773;&#20917;&#65292;&#25552;&#20379;&#20102;&#29702;&#35770;&#32467;&#26524;&#65292;&#21253;&#25324;&#21327;&#21464;&#37327;&#36716;&#31227;&#34987;&#36829;&#21453;&#12289;&#26368;&#20248;&#28304;&#39044;&#27979;&#22120;&#21487;&#33021;&#27604;&#24635;&#26159;&#39044;&#27979;&#22343;&#20540;&#34920;&#29616;&#26356;&#24046;&#12289;&#26368;&#20248;&#30446;&#26631;&#39044;&#27979;&#22120;&#21487;&#34987;&#35782;&#21035;&#31561;&#12290;</title><link>http://arxiv.org/abs/2211.02093</link><description>&lt;p&gt;
&#32570;&#22833;&#25968;&#25454;&#36716;&#31227;&#19979;&#30340;&#39046;&#22495;&#33258;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
Domain Adaptation under Missingness Shift. (arXiv:2211.02093v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.02093
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#39046;&#22495;&#33258;&#36866;&#24212;&#38382;&#39064;&#20013;&#32570;&#22833;&#25968;&#25454;&#36716;&#31227;&#30340;&#24773;&#20917;&#65292;&#25552;&#20986;&#20102;DAMS&#26041;&#27861;&#12290;&#38024;&#23545;&#32570;&#22833;&#25968;&#25454;&#25351;&#26631;&#19981;&#21487;&#29992;&#30340;&#24773;&#20917;&#65292;&#25552;&#20379;&#20102;&#29702;&#35770;&#32467;&#26524;&#65292;&#21253;&#25324;&#21327;&#21464;&#37327;&#36716;&#31227;&#34987;&#36829;&#21453;&#12289;&#26368;&#20248;&#28304;&#39044;&#27979;&#22120;&#21487;&#33021;&#27604;&#24635;&#26159;&#39044;&#27979;&#22343;&#20540;&#34920;&#29616;&#26356;&#24046;&#12289;&#26368;&#20248;&#30446;&#26631;&#39044;&#27979;&#22120;&#21487;&#34987;&#35782;&#21035;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32570;&#22833;&#25968;&#25454;&#30340;&#27604;&#29575;&#36890;&#24120;&#20250;&#22240;&#35760;&#24405;&#25919;&#31574;&#32780;&#21464;&#21270;&#65292;&#21363;&#20351;&#22522;&#30784;&#29305;&#24449;&#30456;&#23545;&#31283;&#23450;&#65292;&#36825;&#31181;&#24773;&#20917;&#21487;&#33021;&#22312;&#19981;&#21516;&#30340;&#26102;&#38388;&#21644;&#22320;&#28857;&#21457;&#29983;&#21464;&#21270;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#32570;&#22833;&#25968;&#25454;&#36716;&#31227;&#19979;&#30340;&#39046;&#22495;&#33258;&#36866;&#24212;&#38382;&#39064;(DAMS)&#12290;&#22312;&#36825;&#37324;&#65292;(&#26377;&#26631;&#31614;&#30340;)&#28304;&#25968;&#25454;&#21644;(&#26080;&#26631;&#31614;&#30340;)&#30446;&#26631;&#25968;&#25454;&#21487;&#20197;&#20114;&#25442;&#65292;&#20294;&#23384;&#22312;&#19981;&#21516;&#30340;&#32570;&#22833;&#25968;&#25454;&#26426;&#21046;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#65292;&#22914;&#26524;&#32570;&#22833;&#25968;&#25454;&#25351;&#26631;&#26159;&#21487;&#29992;&#30340;&#65292;DAMS&#23601;&#20250;&#24402;&#32467;&#20026;&#21327;&#21464;&#37327;&#36716;&#31227;&#12290;&#38024;&#23545;&#36825;&#31181;&#25351;&#26631;&#19981;&#21487;&#29992;&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#20026;&#22522;&#20110;&#23436;&#20840;&#38543;&#26426;&#19979;&#25253;&#21578;&#30340;&#35752;&#35770;&#25552;&#20379;&#20102;&#20197;&#19979;&#29702;&#35770;&#32467;&#26524;&#65306;(i)&#21327;&#21464;&#37327;&#36716;&#31227;&#34987;&#36829;&#21453;&#20102;(&#38656;&#35201;&#36866;&#24212;)&#65307;(ii)&#19982;&#24635;&#26159;&#39044;&#27979;&#22343;&#20540;&#30456;&#27604;&#65292;&#26368;&#20248;&#30340;&#32447;&#24615;&#28304;&#39044;&#27979;&#22120;&#22312;&#30446;&#26631;&#22495;&#19978;&#30340;&#34920;&#29616;&#21487;&#33021;&#20250;&#21464;&#24471;&#26356;&#31967;&#65307;(iii)&#21363;&#20351;&#32570;&#22833;&#29575;&#26412;&#36523;&#26080;&#27861;&#30830;&#23450;&#65292;&#20063;&#33021;&#22815;&#35782;&#21035;&#20986;&#26368;&#20248;&#30340;&#30446;&#26631;&#39044;&#27979;&#22120;&#65307;(iv)&#23545;&#20110;&#32447;&#24615;&#27169;&#22411;&#65292;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#26512;&#35843;&#25972;&#21487;&#20197;&#24471;&#21040;&#26368;&#20248;&#21442;&#25968;&#30340;&#19968;&#33268;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Rates of missing data often depend on record-keeping policies and thus may change across times and locations, even when the underlying features are comparatively stable. In this paper, we introduce the problem of Domain Adaptation under Missingness Shift (DAMS). Here, (labeled) source data and (unlabeled) target data would be exchangeable but for different missing data mechanisms. We show that if missing data indicators are available, DAMS reduces to covariate shift. Addressing cases where such indicators are absent, we establish the following theoretical results for underreporting completely at random: (i) covariate shift is violated (adaptation is required); (ii) the optimal linear source predictor can perform arbitrarily worse on the target domain than always predicting the mean; (iii) the optimal target predictor can be identified, even when the missingness rates themselves are not; and (iv) for linear models, a simple analytic adjustment yields consistent estimates of the optimal 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#36890;&#36807;&#26680;&#21270;Stein&#36317;&#31163;&#26500;&#24314;&#21518;&#39564;Coreset&#30340;MBRL&#26041;&#27861;&#65292;&#22312;&#25918;&#26494;&#36716;&#31227;&#27169;&#22411;&#39640;&#26031;&#25110;Lipschitz&#30340;&#38480;&#21046;&#19979;&#34920;&#29616;&#20986;&#20248;&#24322;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#21487;&#20197;&#24212;&#29992;&#20110;&#22823;&#35268;&#27169;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2206.01162</link><description>&lt;p&gt;
&#24102;&#26377;&#26680;&#21270;Stein&#36317;&#31163;&#30340;&#21518;&#39564;Coreset&#26500;&#24314;&#29992;&#20110;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Posterior Coreset Construction with Kernelized Stein Discrepancy for Model-Based Reinforcement Learning. (arXiv:2206.01162v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.01162
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#36890;&#36807;&#26680;&#21270;Stein&#36317;&#31163;&#26500;&#24314;&#21518;&#39564;Coreset&#30340;MBRL&#26041;&#27861;&#65292;&#22312;&#25918;&#26494;&#36716;&#31227;&#27169;&#22411;&#39640;&#26031;&#25110;Lipschitz&#30340;&#38480;&#21046;&#19979;&#34920;&#29616;&#20986;&#20248;&#24322;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#21487;&#20197;&#24212;&#29992;&#20110;&#22823;&#35268;&#27169;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#20026;&#22522;&#30784;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#20986;&#20248;&#24322;&#30340;&#24615;&#33021;&#65292;&#20294;&#22312;&#22823;&#31354;&#38388;&#30340;&#29702;&#35770;&#20445;&#35777;&#22823;&#22810;&#25968;&#38480;&#20110;&#36716;&#31227;&#27169;&#22411;&#20026;&#39640;&#26031;&#25110;Lipschitz&#30340;&#24773;&#20917;&#19979;&#65292;&#24182;&#19988;&#38656;&#35201;&#21518;&#39564;&#20272;&#35745;&#20854;&#34920;&#31034;&#22797;&#26434;&#24230;&#38543;&#26102;&#38388;&#22686;&#38271;&#32780;&#26080;&#30028;&#12290; &#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;MBRL&#26041;&#27861;&#65292;(i) &#25918;&#26494;&#30446;&#26631;&#36716;&#31227;&#27169;&#22411;&#23646;&#20110;&#36890;&#29992;&#28151;&#21512;&#27169;&#22411;&#26063;&#30340;&#20551;&#35774;&#65307;(ii) &#36890;&#36807;&#21253;&#21547;&#21387;&#32553;&#27493;&#39588;&#20197;&#20165;&#30001;&#32479;&#35745;&#26174;&#30528;&#30340;&#36807;&#21435;&#29366;&#24577; - &#25805;&#20316;&#23545;&#30340;&#36125;&#21494;&#26031;Coreset&#32452;&#25104;&#65292;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#35757;&#32451;&#65307;(iii) &#34920;&#29616;&#20986;&#20122;&#32447;&#24615;&#30340;&#36125;&#21494;&#26031;&#36951;&#25022;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20123;&#32467;&#26524;&#65292;&#25105;&#20204;&#37319;&#29992;&#19968;&#31181;&#22522;&#20110;Stein&#26041;&#27861;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#26500;&#36896;&#21518;&#39564;&#21644;&#30446;&#26631;&#19978;&#28385;&#36275;&#24179;&#28369;&#24615;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#20801;&#35768;&#20197;&#26680;Stein&#36317;&#31163;&#65288;KSD&#65289;&#30340;&#24418;&#24335;&#23553;&#38381;&#22320;&#35780;&#20272;&#20998;&#24067;&#36317;&#31163;&#12290;&#21069;&#38754;&#25552;&#21040;&#30340;&#21518;&#39564;Coreset&#26500;&#24314;&#26159;&#36890;&#36807;&#26368;&#23567;&#21270;&#36825;&#20010;KSD&#26469;&#23436;&#25104;&#30340;&#65292;&#20854;&#20013;&#28151;&#21512;&#32452;&#20214;&#30340;&#20301;&#32622;&#21462;&#20915;&#20110;l-inf&#39044;&#31639;&#65292;&#20197;&#38480;&#21046;&#20013;&#24515;&#30340;&#25968;&#37327;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#27169;&#25311;&#26426;&#22120;&#20154;&#25511;&#21046;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model-based approaches to reinforcement learning (MBRL) exhibit favorable performance in practice, but their theoretical guarantees in large spaces are mostly restricted to the setting when transition model is Gaussian or Lipschitz, and demands a posterior estimate whose representational complexity grows unbounded with time. In this work, we develop a novel MBRL method (i) which relaxes the assumptions on the target transition model to belong to a generic family of mixture models; (ii) is applicable to large-scale training by incorporating a compression step such that the posterior estimate consists of a Bayesian coreset of only statistically significant past state-action pairs; and (iii) exhibits a sublinear Bayesian regret. To achieve these results, we adopt an approach based upon Stein's method, which, under a smoothness condition on the constructed posterior and target, allows distributional distance to be evaluated in closed form as the kernelized Stein discrepancy (KSD). The afor
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#20132;&#21449;&#39564;&#35777;&#26694;&#26550;&#65292;&#21487;&#24212;&#29992;&#20110;&#20449;&#21495;&#21435;&#22122;&#21644;&#22238;&#24402;&#20998;&#26512;&#20013;&#65292;&#20854;&#20013;&#32463;&#36807;&#20132;&#21449;&#39564;&#35777;&#30340;&#29256;&#26412;&#21487;&#20197;&#36798;&#21040;&#19982;&#26368;&#20339;&#35843;&#33410;&#29256;&#26412;&#20960;&#20046;&#30456;&#21516;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#20855;&#26377;&#19968;&#23450;&#30340;&#26222;&#36866;&#24615;&#21644;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2201.02654</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#20449;&#21495;&#21435;&#22122;&#30340;&#20132;&#21449;&#39564;&#35777;&#26694;&#26550;&#21450;&#20854;&#22312;&#36235;&#21183;&#28388;&#27874;&#12289;&#20108;&#32423;&#20915;&#31574;&#26641;&#31561;&#31639;&#27861;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
A Cross Validation Framework for Signal Denoising with Applications to Trend Filtering, Dyadic CART and Beyond. (arXiv:2201.02654v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.02654
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#20132;&#21449;&#39564;&#35777;&#26694;&#26550;&#65292;&#21487;&#24212;&#29992;&#20110;&#20449;&#21495;&#21435;&#22122;&#21644;&#22238;&#24402;&#20998;&#26512;&#20013;&#65292;&#20854;&#20013;&#32463;&#36807;&#20132;&#21449;&#39564;&#35777;&#30340;&#29256;&#26412;&#21487;&#20197;&#36798;&#21040;&#19982;&#26368;&#20339;&#35843;&#33410;&#29256;&#26412;&#20960;&#20046;&#30456;&#21516;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#20855;&#26377;&#19968;&#23450;&#30340;&#26222;&#36866;&#24615;&#21644;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#20449;&#21495;&#21435;&#22122;&#20132;&#21449;&#39564;&#35777;&#26694;&#26550;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#38750;&#21442;&#25968;&#22238;&#24402;&#26041;&#27861;&#65292;&#22914;&#36235;&#21183;&#28388;&#27874;&#21644;&#20108;&#32423;&#20915;&#31574;&#26641;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#36825;&#20123;&#32463;&#36807;&#20132;&#21449;&#39564;&#35777;&#30340;&#29256;&#26412;&#21487;&#20197;&#36798;&#21040;&#19982;&#26368;&#20339;&#35843;&#33410;&#29256;&#26412;&#20960;&#20046;&#30456;&#21516;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;lasso&#21644;&#22855;&#24322;&#20540;&#38408;&#20540;&#27861;&#30340;&#32463;&#36807;&#20132;&#21449;&#39564;&#35777;&#30340;&#29256;&#26412;&#65292;&#20197;&#35777;&#26126;&#27492;&#26694;&#26550;&#30340;&#26222;&#36941;&#36866;&#29992;&#24615;&#12290;&#25105;&#20204;&#30340;&#36890;&#29992;&#26694;&#26550;&#28789;&#24863;&#26469;&#33258;Chatterjee&#21644;Jafarov&#65288;2015&#65289;&#30340;&#24605;&#24819;&#65292;&#24182;&#21487;&#33021;&#36866;&#29992;&#20110;&#20351;&#29992;&#35843;&#33410;&#21442;&#25968;&#30340;&#24191;&#27867;&#20272;&#35745;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper formulates a general cross validation framework for signal denoising. The general framework is then applied to nonparametric regression methods such as Trend Filtering and Dyadic CART. The resulting cross validated versions are then shown to attain nearly the same rates of convergence as are known for the optimally tuned analogues. There did not exist any previous theoretical analyses of cross validated versions of Trend Filtering or Dyadic CART. To illustrate the generality of the framework we also propose and study cross validated versions of two fundamental estimators; lasso for high dimensional linear regression and singular value thresholding for matrix estimation. Our general framework is inspired by the ideas in Chatterjee and Jafarov (2015) and is potentially applicable to a wide range of estimation methods which use tuning parameters.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#12289;&#36866;&#29992;&#20110;&#20989;&#25968;&#25968;&#25454;&#30340;&#26032;&#22411;&#38750;&#32447;&#24615;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#21464;&#20307;&#65292;&#26088;&#22312;&#26174;&#24335;&#21033;&#29992;&#20989;&#25968;&#25968;&#25454;&#20013;&#22266;&#26377;&#30340;&#32467;&#26500;&#65292;&#24182;&#36890;&#36807;&#20840;&#38754;&#30340;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#25968;&#25454;&#31034;&#20363;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2104.09371</link><description>&lt;p&gt;
&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Non-linear Functional Modeling using Neural Networks. (arXiv:2104.09371v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2104.09371
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#12289;&#36866;&#29992;&#20110;&#20989;&#25968;&#25968;&#25454;&#30340;&#26032;&#22411;&#38750;&#32447;&#24615;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#21464;&#20307;&#65292;&#26088;&#22312;&#26174;&#24335;&#21033;&#29992;&#20989;&#25968;&#25968;&#25454;&#20013;&#22266;&#26377;&#30340;&#32467;&#26500;&#65292;&#24182;&#36890;&#36807;&#20840;&#38754;&#30340;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#25968;&#25454;&#31034;&#20363;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#22411;&#38750;&#32447;&#24615;&#20989;&#25968;&#25968;&#25454;&#27169;&#22411;&#12290;&#28145;&#24230;&#23398;&#20064;&#22312;&#38750;&#32447;&#24615;&#24314;&#27169;&#26041;&#38754;&#38750;&#24120;&#25104;&#21151;&#65292;&#20294;&#22312;&#20989;&#25968;&#25968;&#25454;&#35774;&#32622;&#26041;&#38754;&#21364;&#24456;&#23569;&#26377;&#30740;&#31350;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#21464;&#20307;&#65306;&#19968;&#31181;&#26159;&#20855;&#26377;&#36830;&#32493;&#38544;&#34255;&#23618;&#30340;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#65292;&#31216;&#20026;&#20989;&#25968;&#30452;&#25509;&#31070;&#32463;&#32593;&#32476;&#65288;FDNN&#65289;&#65292;&#21478;&#19968;&#31181;&#21017;&#21033;&#29992;&#22522;&#25193;&#23637;&#21644;&#36830;&#32493;&#38544;&#34255;&#23618;&#65292;&#31216;&#20026;&#22522;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#65288;FBNN&#65289;&#12290;&#20004;&#31181;&#21464;&#20307;&#37117;&#26159;&#35774;&#35745;&#29992;&#26469;&#26174;&#24335;&#21033;&#29992;&#20989;&#25968;&#25968;&#25454;&#20013;&#22266;&#26377;&#30340;&#32467;&#26500;&#12290;&#20026;&#20102;&#25311;&#21512;&#36825;&#20123;&#27169;&#22411;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20989;&#25968;&#26799;&#24230;&#30340;&#20248;&#21270;&#31639;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#20840;&#38754;&#30340;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#25968;&#25454;&#31034;&#20363;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#22312;&#22788;&#29702;&#22797;&#26434;&#20989;&#25968;&#27169;&#22411;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new class of non-linear models for functional data based on neural networks. Deep learning has been very successful in non-linear modeling, but there has been little work done in the functional data setting. We propose two variations of our framework: a functional neural network with continuous hidden layers, called the Functional Direct Neural Network (FDNN), and a second version that utilizes basis expansions and continuous hidden layers, called the Functional Basis Neural Network (FBNN). Both are designed explicitly to exploit the structure inherent in functional data. To fit these models we derive a functional gradient based optimization algorithm. The effectiveness of the proposed methods in handling complex functional models is demonstrated by comprehensive simulation studies and real data examples.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102; GTEA&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#26102;&#24207;&#20132;&#20114;&#22270;&#19978;&#36827;&#34892;&#24402;&#32435;&#23398;&#20064;&#65292;&#32467;&#21512;&#20102;&#26102;&#38388;&#21160;&#24577;&#24314;&#27169;&#21644;&#22270;&#23884;&#20837;&#65292;&#36890;&#36807;&#32858;&#21512;&#30456;&#37051;&#33410;&#28857;&#21644;&#36793;&#23884;&#20837;&#30340;&#29305;&#24449;&#65292;&#20849;&#21516;&#23398;&#20064;&#20102; TIG &#30340;&#25299;&#25169;&#21644;&#26102;&#38388;&#20381;&#36182;&#20851;&#31995;&#65292;&#32780;&#19988;&#24341;&#20837;&#20102;&#19968;&#31181;&#31232;&#30095;&#24863;&#30693;&#30340;&#33258;&#27880;&#24847;&#26426;&#21046;&#65292;&#22312;&#22810;&#20010;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2009.05266</link><description>&lt;p&gt;
GTEA: &#36890;&#36807;&#26102;&#38388;&#36793;&#32858;&#21512;&#22312;&#26102;&#24207;&#20132;&#20114;&#22270;&#19978;&#36827;&#34892;&#24402;&#32435;&#34920;&#24449;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
GTEA: Inductive Representation Learning on Temporal Interaction Graphs via Temporal Edge Aggregation. (arXiv:2009.05266v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2009.05266
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102; GTEA&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#26102;&#24207;&#20132;&#20114;&#22270;&#19978;&#36827;&#34892;&#24402;&#32435;&#23398;&#20064;&#65292;&#32467;&#21512;&#20102;&#26102;&#38388;&#21160;&#24577;&#24314;&#27169;&#21644;&#22270;&#23884;&#20837;&#65292;&#36890;&#36807;&#32858;&#21512;&#30456;&#37051;&#33410;&#28857;&#21644;&#36793;&#23884;&#20837;&#30340;&#29305;&#24449;&#65292;&#20849;&#21516;&#23398;&#20064;&#20102; TIG &#30340;&#25299;&#25169;&#21644;&#26102;&#38388;&#20381;&#36182;&#20851;&#31995;&#65292;&#32780;&#19988;&#24341;&#20837;&#20102;&#19968;&#31181;&#31232;&#30095;&#24863;&#30693;&#30340;&#33258;&#27880;&#24847;&#26426;&#21046;&#65292;&#22312;&#22810;&#20010;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;Graph Temporal Edge Aggregation (GTEA)&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#26102;&#24207;&#20132;&#20114;&#22270;&#65288;TIGs&#65289;&#19978;&#36827;&#34892;&#24402;&#32435;&#23398;&#20064;&#12290;&#19981;&#21516;&#20110;&#20197;&#24448;&#24037;&#20316;&#65292;GTEA&#23558;&#20132;&#20114;&#24207;&#21015;&#30340;&#26102;&#38388;&#21160;&#24577;&#24314;&#27169;&#22312;&#36830;&#32493;&#26102;&#38388;&#31354;&#38388;&#20013;&#65292;&#24182;&#21516;&#26102;&#21033;&#29992;&#22270;&#20013;&#20016;&#23500;&#30340;&#33410;&#28857;&#21644;&#36793;/&#20132;&#20114;&#23646;&#24615;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23558;&#24207;&#21015;&#27169;&#22411;&#19982;&#26102;&#38388;&#32534;&#30721;&#22120;&#30456;&#32467;&#21512;&#65292;&#23398;&#20064;&#30456;&#37051;&#33410;&#28857;&#20043;&#38388;&#30340;&#25104;&#23545;&#20132;&#20114;&#21160;&#21147;&#23398;&#12290;&#36825;&#26377;&#21161;&#20110;&#25429;&#25417;&#33410;&#28857;&#23545;&#27839;&#21382;&#21490;&#30340;&#22797;&#26434;&#26102;&#38388;&#20132;&#20114;&#27169;&#24335;&#65292;&#29983;&#25104;&#36793;&#23884;&#20837;&#21487;&#20197;&#36755;&#20837;&#21040;GNN&#39592;&#24178;&#12290;&#36890;&#36807;&#32858;&#21512;&#30456;&#37051;&#33410;&#28857;&#21644;&#30456;&#24212;&#30340;&#36793;&#23884;&#20837;&#30340;&#29305;&#24449;&#65292;GTEA&#20849;&#21516;&#23398;&#20064;TIG&#30340;&#25299;&#25169;&#21644;&#26102;&#38388;&#20381;&#36182;&#20851;&#31995;&#12290;&#27492;&#22806;&#65292;&#36824;&#37319;&#29992;&#20102;&#19968;&#31181;&#31232;&#30095;&#24863;&#30693;&#33258;&#27880;&#24847;&#26426;&#21046;&#36827;&#34892;&#37051;&#23621;&#32858;&#21512;&#65292;&#31361;&#20986;&#26356;&#37325;&#35201;&#30340;&#37051;&#23621;&#24182;&#25233;&#21046;GTEA&#30340;&#29712;&#30862;&#22122;&#22768;&#12290;&#36890;&#36807;&#32852;&#21512;&#20248;&#21270;&#25972;&#20010;&#26694;&#26550;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#20854;&#22312;&#22810;&#20010;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose the Graph Temporal Edge Aggregation (GTEA) framework for inductive learning on Temporal Interaction Graphs (TIGs). Different from previous works, GTEA models the temporal dynamics of interaction sequences in the continuous-time space and simultaneously takes advantage of both rich node and edge/ interaction attributes in the graph. Concretely, we integrate a sequence model with a time encoder to learn pairwise interactional dynamics between two adjacent nodes.This helps capture complex temporal interactional patterns of a node pair along the history, which generates edge embeddings that can be fed into a GNN backbone. By aggregating features of neighboring nodes and the corresponding edge embeddings, GTEA jointly learns both topological and temporal dependencies of a TIG. In addition, a sparsity-inducing self-attention scheme is incorporated for neighbor aggregation, which highlights more important neighbors and suppresses trivial noises for GTEA. By jointly o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#23500;&#26377;&#23646;&#24615;&#32593;&#32476;&#20013;&#39030;&#28857;&#25552;&#21517;&#30340;&#21452;&#37325;&#20316;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#20869;&#23481;&#24863;&#30693;&#30340;&#32593;&#32476;&#23884;&#20837;&#26041;&#27861;&#65292;&#35777;&#26126;&#35813;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#19981;&#21033;&#29992;&#20869;&#23481;&#21644;&#19978;&#19979;&#25991;&#30340;&#39030;&#28857;&#25552;&#21517;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2005.02151</link><description>&lt;p&gt;
&#23500;&#26377;&#23646;&#24615;&#32593;&#32476;&#20013;&#30340;&#39030;&#28857;&#25552;&#21517;
&lt;/p&gt;
&lt;p&gt;
Vertex Nomination in Richly Attributed Networks. (arXiv:2005.02151v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2005.02151
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#23500;&#26377;&#23646;&#24615;&#32593;&#32476;&#20013;&#39030;&#28857;&#25552;&#21517;&#30340;&#21452;&#37325;&#20316;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#20869;&#23481;&#24863;&#30693;&#30340;&#32593;&#32476;&#23884;&#20837;&#26041;&#27861;&#65292;&#35777;&#26126;&#35813;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#19981;&#21033;&#29992;&#20869;&#23481;&#21644;&#19978;&#19979;&#25991;&#30340;&#39030;&#28857;&#25552;&#21517;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39030;&#28857;&#25552;&#21517;&#26159;&#19968;&#39033;&#36731;&#24230;&#30417;&#30563;&#30340;&#32593;&#32476;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#65292;&#22312;&#36825;&#20010;&#20219;&#21153;&#20013;&#65292;&#24863;&#20852;&#36259;&#30340;&#19968;&#24352;&#22270;&#30340;&#39030;&#28857;&#34987;&#29992;&#26469;&#26597;&#35810;&#31532;&#20108;&#24352;&#22270;&#20197;&#21457;&#29616;&#24863;&#20852;&#36259;&#30340;&#31532;&#20108;&#24352;&#22270;&#30340;&#39030;&#28857;&#12290;&#19982;&#20854;&#20182;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#31867;&#20284;&#65292;&#39030;&#28857;&#25552;&#21517;&#26041;&#26696;&#30340;&#36755;&#20986;&#26159;&#31532;&#20108;&#24352;&#22270;&#20013;&#39030;&#28857;&#30340;&#25490;&#24207;&#21015;&#34920;&#65292;&#29702;&#24819;&#24773;&#20917;&#19979;&#65292;&#26410;&#30693;&#30340;&#24863;&#20852;&#36259;&#30340;&#39030;&#28857;&#24212;&#35813;&#38598;&#20013;&#22312;&#21015;&#34920;&#30340;&#39030;&#37096;&#12290;&#39030;&#28857;&#25552;&#21517;&#26041;&#26696;&#20026;&#39640;&#25928;&#22320;&#25366;&#25496;&#22797;&#26434;&#32593;&#32476;&#20013;&#30340;&#30456;&#20851;&#20449;&#24687;&#25552;&#20379;&#20102;&#26377;&#29992;&#30340;&#24037;&#20855;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#29702;&#35770;&#21644;&#23454;&#36341;&#20004;&#26041;&#38754;&#25506;&#35752;&#20102;&#20869;&#23481;&#65288;&#21363;&#36793;&#32536;&#21644;&#39030;&#28857;&#23646;&#24615;&#65289;&#21644;&#19978;&#19979;&#25991;&#65288;&#21363;&#32593;&#32476;&#25299;&#25169;&#32467;&#26500;&#65289;&#22312;&#39030;&#28857;&#25552;&#21517;&#20013;&#30340;&#21452;&#37325;&#20316;&#29992;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#24517;&#35201;&#21644;&#20805;&#20998;&#30340;&#26465;&#20214;&#65292;&#35777;&#26126;&#20102;&#21033;&#29992;&#20869;&#23481;&#21644;&#19978;&#19979;&#25991;&#30340;&#39030;&#28857;&#25552;&#21517;&#26041;&#26696;&#33021;&#22815;&#36229;&#36234;&#20165;&#21033;&#29992;&#20869;&#23481;&#25110;&#19978;&#19979;&#25991;&#30340;&#26041;&#26696;&#12290;&#34429;&#28982;&#20869;&#23481;&#21644;&#19978;&#19979;&#25991;&#30340;&#32852;&#21512;&#25928;&#29992;&#22312;&#20854;&#20182;&#32593;&#32476;&#20998;&#26512;&#20219;&#21153;&#20013;&#24050;&#32463;&#24471;&#21040;&#35777;&#23454;&#65292;&#20294;&#25105;&#20204;&#35777;&#26126;&#22312;&#39030;&#28857;&#25552;&#21517;&#30340;&#32972;&#26223;&#19979;&#65292;&#36825;&#31181;&#32852;&#21512;&#25928;&#29992;&#20063;&#26159;&#25104;&#31435;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#20869;&#23481;&#24863;&#30693;&#30340;&#32593;&#32476;&#23884;&#20837;&#26041;&#27861;&#65292;&#29992;&#20110;&#39030;&#28857;&#25552;&#21517;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#32467;&#21512;&#23616;&#37096;&#21644;&#20840;&#23616;&#32593;&#32476;&#23646;&#24615;&#20449;&#24687;&#12290;&#25105;&#20204;&#22312;&#30495;&#23454;&#30340;&#31038;&#20132;&#21644;&#24341;&#29992;&#32593;&#32476;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#20248;&#20110;&#19981;&#21033;&#29992;&#20869;&#23481;&#21644;&#19978;&#19979;&#25991;&#30340;&#29616;&#26377;&#30340;&#39030;&#28857;&#25552;&#21517;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Vertex nomination is a lightly-supervised network information retrieval task in which vertices of interest in one graph are used to query a second graph to discover vertices of interest in the second graph. Similar to other information retrieval tasks, the output of a vertex nomination scheme is a ranked list of the vertices in the second graph, with the heretofore unknown vertices of interest ideally concentrating at the top of the list. Vertex nomination schemes provide a useful suite of tools for efficiently mining complex networks for pertinent information. In this paper, we explore, both theoretically and practically, the dual roles of content (i.e., edge and vertex attributes) and context (i.e., network topology) in vertex nomination. We provide necessary and sufficient conditions under which vertex nomination schemes that leverage both content and context outperform schemes that leverage only content or context separately. While the joint utility of both content and context has 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#32467;&#26524;&#25277;&#26679;&#30340;&#22240;&#26524;&#25512;&#26029;&#65292;&#21457;&#29616;&#24378;&#26080;&#20559;&#24615;&#19981;&#24635;&#26159;&#20687;&#38543;&#26426;&#25277;&#26679;&#19979;&#37027;&#26679;&#24378;&#22823;&#65292;&#24182;&#19988;&#26576;&#20123;&#21333;&#35843;&#24615;&#20551;&#35774;&#22312;&#38160;&#21033;&#35782;&#21035;&#38388;&#38548;&#26041;&#38754;&#20135;&#29983;&#21487;&#27604;&#36739;&#30340;&#32467;&#26524;&#12290; &#36890;&#36807;&#31639;&#27861;&#25512;&#26029;&#20986;&#21442;&#25968;&#24182;&#29992;&#23454;&#35777;&#20363;&#23376;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2004.08318</link><description>&lt;p&gt;
&#22522;&#20110;&#32467;&#26524;&#25277;&#26679;&#30340;&#22240;&#26524;&#25512;&#26029;&#21644;&#21333;&#35843;&#24615;&#20551;&#35774;
&lt;/p&gt;
&lt;p&gt;
Causal Inference under Outcome-Based Sampling with Monotonicity Assumptions. (arXiv:2004.08318v5 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2004.08318
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#32467;&#26524;&#25277;&#26679;&#30340;&#22240;&#26524;&#25512;&#26029;&#65292;&#21457;&#29616;&#24378;&#26080;&#20559;&#24615;&#19981;&#24635;&#26159;&#20687;&#38543;&#26426;&#25277;&#26679;&#19979;&#37027;&#26679;&#24378;&#22823;&#65292;&#24182;&#19988;&#26576;&#20123;&#21333;&#35843;&#24615;&#20551;&#35774;&#22312;&#38160;&#21033;&#35782;&#21035;&#38388;&#38548;&#26041;&#38754;&#20135;&#29983;&#21487;&#27604;&#36739;&#30340;&#32467;&#26524;&#12290; &#36890;&#36807;&#31639;&#27861;&#25512;&#26029;&#20986;&#21442;&#25968;&#24182;&#29992;&#23454;&#35777;&#20363;&#23376;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26681;&#25454;&#26696;&#20363;&#25511;&#21046;&#21644;&#26696;&#20363;&#32676;&#20307;&#21462;&#26679;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#30340;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20851;&#27880;&#20108;&#20803;&#32467;&#26524;&#21644;&#20108;&#20803;&#27835;&#30103;&#30340;&#24773;&#20917;&#65292;&#20854;&#20013;&#24863;&#20852;&#36259;&#30340;&#21442;&#25968;&#26159;&#36890;&#36807;&#28508;&#22312;&#32467;&#26524;&#26694;&#26550;&#23450;&#20041;&#30340;&#22240;&#26524;&#30456;&#23545;&#21644;&#21487;&#24402;&#22240;&#39118;&#38505;&#12290;&#25105;&#20204;&#21457;&#29616;&#24378;&#26080;&#20559;&#24615;&#19981;&#24635;&#26159;&#20687;&#38543;&#26426;&#25277;&#26679;&#19979;&#37027;&#26679;&#24378;&#22823;&#65292;&#24182;&#19988;&#26576;&#20123;&#21333;&#35843;&#24615;&#20551;&#35774;&#22312;&#38160;&#21033;&#35782;&#21035;&#38388;&#38548;&#26041;&#38754;&#20135;&#29983;&#21487;&#27604;&#36739;&#30340;&#32467;&#26524;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#36890;&#24120;&#30340;&#27604;&#20540;&#27604;&#22312;&#21333;&#35843;&#27835;&#30103;&#21453;&#24212;&#21644;&#21333;&#35843;&#27835;&#30103;&#36873;&#25321;&#20551;&#35774;&#19979;&#34987;&#35777;&#26126;&#26159;&#22240;&#26524;&#30456;&#23545;&#39118;&#38505;&#30340;&#38160;&#21033;&#35782;&#21035;&#19978;&#30028;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#32858;&#21512;&#22312;&#21327;&#21464;&#37327;&#30340;&#30495;&#23454;&#20154;&#21475;&#20998;&#24067;&#19978;&#30340;&#22240;&#26524;&#21442;&#25968;&#25512;&#26029;&#31639;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#30740;&#31350;&#19977;&#20010;&#23454;&#35777;&#20363;&#23376;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#29992;&#24615;&#65306;&#22312;&#24052;&#22522;&#26031;&#22374;&#36827;&#20837;&#33879;&#21517;&#22823;&#23398;&#30340;&#31169;&#31435;&#23398;&#26657;&#21463;&#30410;&#38382;&#39064;&#19978;&#65307;&#22312;&#30041;&#22312;&#23398;&#26657;&#21644;&#25918;&#24323;&#23398;&#26657;&#26089;&#26399;&#30340;&#20851;&#31995;&#38382;&#39064;&#19978;&#65307;&#22312;&#39044;&#27979;&#23703;&#20301;&#22521;&#35757;&#25928;&#26524;&#38382;&#39064;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study causal inference under case-control and case-population sampling. Specifically, we focus on the binary-outcome and binary-treatment case, where the parameters of interest are causal relative and attributable risks defined via the potential outcome framework. It is shown that strong ignorability is not always as powerful as it is under random sampling and that certain monotonicity assumptions yield comparable results in terms of sharp identified intervals. Specifically, the usual odds ratio is shown to be a sharp identified upper bound on causal relative risk under the monotone treatment response and monotone treatment selection assumptions. We offer algorithms for inference on the causal parameters that are aggregated over the true population distribution of the covariates. We show the usefulness of our approach by studying three empirical examples: the benefit of attending private school for entering a prestigious university in Pakistan; the relationship between staying in sc
&lt;/p&gt;</description></item></channel></rss>