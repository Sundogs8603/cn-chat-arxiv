<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#36890;&#36807;&#23558;&#20840;&#23616;&#22797;&#26434;&#24230;&#26367;&#25442;&#20026;&#36739;&#23567;&#30340;&#23616;&#37096;&#22797;&#26434;&#24230;&#26469;&#37325;&#26032;&#23457;&#35270;&#21644;&#21152;&#24378;&#20102;&#32479;&#35745;&#32858;&#21512;&#29702;&#35770;&#20013;&#30340;&#32463;&#20856;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.17151</link><description>&lt;p&gt;
&#32479;&#35745;&#32858;&#21512;&#30340;&#26412;&#22320;&#39118;&#38505;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Local Risk Bounds for Statistical Aggregation. (arXiv:2306.17151v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17151
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23558;&#20840;&#23616;&#22797;&#26434;&#24230;&#26367;&#25442;&#20026;&#36739;&#23567;&#30340;&#23616;&#37096;&#22797;&#26434;&#24230;&#26469;&#37325;&#26032;&#23457;&#35270;&#21644;&#21152;&#24378;&#20102;&#32479;&#35745;&#32858;&#21512;&#29702;&#35770;&#20013;&#30340;&#32463;&#20856;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32858;&#21512;&#38382;&#39064;&#20013;&#65292;&#30446;&#26631;&#26159;&#23558;&#32473;&#23450;&#31867;&#21035;&#30340;&#22522;&#26412;&#39044;&#27979;&#22120;&#32452;&#21512;&#36215;&#26469;&#65292;&#20197;&#23454;&#29616;&#20960;&#20046;&#19982;&#26368;&#20339;&#39044;&#27979;&#22120;&#19968;&#26679;&#20934;&#30830;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;&#22312;&#36825;&#20010;&#28789;&#27963;&#30340;&#26694;&#26550;&#20013;&#65292;&#23545;&#31867;&#21035;&#30340;&#32467;&#26500;&#25110;&#30446;&#26631;&#30340;&#24615;&#36136;&#19981;&#20570;&#20219;&#20309;&#20551;&#35774;&#12290;&#32858;&#21512;&#22312;&#39034;&#24207;&#21644;&#32479;&#35745;&#19978;&#19979;&#25991;&#20013;&#37117;&#26377;&#30740;&#31350;&#12290;&#23613;&#31649;&#36825;&#20004;&#20010;&#38382;&#39064;&#20043;&#38388;&#26377;&#19968;&#20123;&#37325;&#35201;&#30340;&#24046;&#24322;&#65292;&#20294;&#20004;&#31181;&#24773;&#20917;&#19979;&#30340;&#32463;&#20856;&#32467;&#26524;&#20855;&#26377;&#30456;&#21516;&#30340;&#20840;&#23616;&#22797;&#26434;&#24230;&#24230;&#37327;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#36890;&#36807;&#29992;&#36739;&#23567;&#30340;&#23616;&#37096;&#22797;&#26434;&#24230;&#26367;&#25442;&#20840;&#23616;&#22797;&#26434;&#24230;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#21644;&#21152;&#24378;&#20102;&#32479;&#35745;&#32858;&#21512;&#29702;&#35770;&#20013;&#30340;&#32463;&#20856;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#19968;&#20123;&#35777;&#26126;&#22522;&#20110;Catoni&#24341;&#20837;&#30340;PAC-Bayes&#26412;&#22320;&#21270;&#25216;&#26415;&#12290;&#22312;&#20854;&#20182;&#32467;&#26524;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#30001;Leung&#21644;Barron&#25552;&#20986;&#30340;&#25351;&#25968;&#26435;&#37325;&#20272;&#35745;&#22120;&#30340;&#23616;&#37096;&#29256;&#26412;&#30340;&#32463;&#20856;&#30028;&#38480;&#65292;&#20197;&#21450;Q-&#32858;&#21512;&#20272;&#35745;&#22120;&#30340;&#20559;&#24046;&#26368;&#20248;&#30028;&#38480;&#12290;&#36825;&#20123;&#30028;&#38480;&#25913;&#36827;&#20102;Dai&#65292;Rigollet&#21644;Zhang&#20851;&#20110;&#22266;&#23450;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the problem of aggregation, the aim is to combine a given class of base predictors to achieve predictions nearly as accurate as the best one. In this flexible framework, no assumption is made on the structure of the class or the nature of the target. Aggregation has been studied in both sequential and statistical contexts. Despite some important differences between the two problems, the classical results in both cases feature the same global complexity measure. In this paper, we revisit and tighten classical results in the theory of aggregation in the statistical setting by replacing the global complexity with a smaller, local one. Some of our proofs build on the PAC-Bayes localization technique introduced by Catoni. Among other results, we prove localized versions of the classical bound for the exponential weights estimator due to Leung and Barron and deviation-optimal bounds for the Q-aggregation estimator. These bounds improve over the results of Dai, Rigollet and Zhang for fixed
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;Safe-$\text{M}^3$-UCRL&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#27169;&#22411;&#20013;&#30340;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#21644;&#23545;&#25968;&#38556;&#30861;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#26410;&#30693;&#36716;&#31227;&#21160;&#24577;&#24773;&#20917;&#19979;&#36798;&#21040;&#23433;&#20840;&#31574;&#30053;&#30340;&#20248;&#21270;&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;&#22823;&#35268;&#27169;&#22810;&#26234;&#33021;&#20307;&#21327;&#35843;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.17052</link><description>&lt;p&gt;
&#23433;&#20840;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#22810;&#26234;&#33021;&#20307;&#22343;&#22330;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Safe Model-Based Multi-Agent Mean-Field Reinforcement Learning. (arXiv:2306.17052v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17052
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;Safe-$\text{M}^3$-UCRL&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#27169;&#22411;&#20013;&#30340;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#21644;&#23545;&#25968;&#38556;&#30861;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#26410;&#30693;&#36716;&#31227;&#21160;&#24577;&#24773;&#20917;&#19979;&#36798;&#21040;&#23433;&#20840;&#31574;&#30053;&#30340;&#20248;&#21270;&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;&#22823;&#35268;&#27169;&#22810;&#26234;&#33021;&#20307;&#21327;&#35843;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#24212;&#29992;&#65292;&#27604;&#22914;&#20849;&#20139;&#20132;&#36890;&#65292;&#38656;&#35201;&#21327;&#35843;&#22823;&#37327;&#30340;&#26234;&#33021;&#20307;&#12290;&#22343;&#22330;&#24378;&#21270;&#23398;&#20064;&#36890;&#36807;&#20248;&#21270;&#20195;&#34920;&#24615;&#26234;&#33021;&#20307;&#30340;&#31574;&#30053;&#26469;&#24212;&#23545;&#30001;&#27492;&#24102;&#26469;&#30340;&#21487;&#25193;&#23637;&#24615;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#19968;&#20010;&#37325;&#35201;&#30340;&#27867;&#21270;&#38382;&#39064;&#65292;&#21363;&#26234;&#33021;&#20307;&#20998;&#24067;&#23384;&#22312;&#20840;&#23616;&#32422;&#26463;&#30340;&#24773;&#20917;&#65288;&#20363;&#22914;&#38656;&#35201;&#28385;&#36275;&#23481;&#37327;&#32422;&#26463;&#25110;&#26368;&#23567;&#35206;&#30422;&#35201;&#27714;&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;Safe-$\text{M}^3$-UCRL&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#33021;&#22815;&#22312;&#26410;&#30693;&#36716;&#31227;&#21160;&#24577;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#23433;&#20840;&#31574;&#30053;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#31639;&#27861;&#12290;&#20316;&#20026;&#19968;&#20010;&#20851;&#38190;&#22240;&#32032;&#65292;&#23427;&#22312;&#20445;&#35777;&#24754;&#35266;&#32422;&#26463;&#28385;&#36275;&#30340;&#21516;&#26102;&#65292;&#21033;&#29992;&#36716;&#31227;&#27169;&#22411;&#20013;&#30340;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#26469;&#20351;&#29992;&#23545;&#25968;&#38556;&#30861;&#26041;&#27861;&#30830;&#20445;&#39640;&#27010;&#29575;&#12290;&#25105;&#20204;&#22312;&#35768;&#22810;&#20849;&#20139;&#20132;&#36890;&#36816;&#33829;&#21830;&#38754;&#20020;&#30340;&#36710;&#36742;&#37325;&#23450;&#20301;&#38382;&#39064;&#19978;&#23637;&#31034;&#20102;Safe-$\text{M}^3$-UCRL&#65292;&#24182;&#36890;&#36807;&#22522;&#20110;&#28145;&#22323;&#20986;&#31199;&#36710;&#36712;&#36857;&#25968;&#25454;&#30340;&#20223;&#30495;&#35780;&#20272;&#20854;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#33021;&#22815;&#26377;&#25928;&#28385;&#36275;&#20851;&#38190;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many applications, e.g., in shared mobility, require coordinating a large number of agents. Mean-field reinforcement learning addresses the resulting scalability challenge by optimizing the policy of a representative agent. In this paper, we address an important generalization where there exist global constraints on the distribution of agents (e.g., requiring capacity constraints or minimum coverage requirements to be met). We propose Safe-$\text{M}^3$-UCRL, the first model-based algorithm that attains safe policies even in the case of unknown transition dynamics. As a key ingredient, it uses epistemic uncertainty in the transition model within a log-barrier approach to ensure pessimistic constraints satisfaction with high probability. We showcase Safe-$\text{M}^3$-UCRL on the vehicle repositioning problem faced by many shared mobility operators and evaluate its performance through simulations built on Shenzhen taxi trajectory data. Our algorithm effectively meets the demand in critica
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#24230;&#37327;&#31354;&#38388;&#20013;&#25552;&#39640;&#38543;&#26426;&#26862;&#26519;&#25928;&#29575;&#30340;&#26032;&#21010;&#20998;&#35268;&#21017;&#65292;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#20013;&#24515;&#26679;&#26412;&#30340;&#26041;&#27861;&#65292;&#32780;&#38750;&#26114;&#36149;&#30340;Fr\'echet&#24179;&#22343;&#25805;&#20316;&#65292;&#35299;&#20915;&#20102;Fr\'echet&#22238;&#24402;&#20013;&#30340;&#22238;&#24402;&#25361;&#25112;&#65292;&#24182;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#21644;&#19968;&#33268;&#24615;&#12290;&#36825;&#25552;&#20379;&#20102;&#19968;&#20010;&#26356;&#39640;&#25928;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;Fr\'echet&#22238;&#24402;&#22312;&#38750;&#26631;&#20934;&#25968;&#25454;&#31867;&#22411;&#21644;&#22797;&#26434;&#29992;&#20363;&#20013;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2306.17031</link><description>&lt;p&gt;
&#22312;&#24230;&#37327;&#31354;&#38388;&#20013;&#25552;&#39640;&#38543;&#26426;&#26862;&#26519;&#25928;&#29575;&#30340;&#20013;&#24515;&#26679;&#26412;&#21010;&#20998;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Medoid splits for efficient random forests in metric spaces. (arXiv:2306.17031v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17031
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#24230;&#37327;&#31354;&#38388;&#20013;&#25552;&#39640;&#38543;&#26426;&#26862;&#26519;&#25928;&#29575;&#30340;&#26032;&#21010;&#20998;&#35268;&#21017;&#65292;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#20013;&#24515;&#26679;&#26412;&#30340;&#26041;&#27861;&#65292;&#32780;&#38750;&#26114;&#36149;&#30340;Fr\'echet&#24179;&#22343;&#25805;&#20316;&#65292;&#35299;&#20915;&#20102;Fr\'echet&#22238;&#24402;&#20013;&#30340;&#22238;&#24402;&#25361;&#25112;&#65292;&#24182;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#21644;&#19968;&#33268;&#24615;&#12290;&#36825;&#25552;&#20379;&#20102;&#19968;&#20010;&#26356;&#39640;&#25928;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;Fr\'echet&#22238;&#24402;&#22312;&#38750;&#26631;&#20934;&#25968;&#25454;&#31867;&#22411;&#21644;&#22797;&#26434;&#29992;&#20363;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#36866;&#29992;&#20110;Fr\'echet&#22238;&#24402;&#30340;&#38543;&#26426;&#26862;&#26519;&#31639;&#27861;&#30340;&#25913;&#36827;&#65292;&#22312;&#24230;&#37327;&#31354;&#38388;&#20013;&#22788;&#29702;&#38543;&#26426;&#23545;&#35937;&#30340;&#22238;&#24402;&#25361;&#25112;&#12290;&#37492;&#20110;&#20043;&#21069;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#21010;&#20998;&#35268;&#21017;&#65292;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#20013;&#24515;&#26679;&#26412;&#30340;&#26041;&#27861;&#26469;&#36991;&#20813;&#35745;&#31639;&#26114;&#36149;&#30340;Fr\'echet&#24179;&#22343;&#25805;&#20316;&#12290;&#36890;&#36807;&#35770;&#35777;&#20854;&#19982;&#22522;&#20110;Fr\'echet&#24179;&#22343;&#30340;&#36807;&#31243;&#30340;&#28176;&#36817;&#31561;&#20215;&#24615;&#65292;&#24182;&#24314;&#31435;&#30456;&#20851;&#22238;&#24402;&#20272;&#35745;&#37327;&#30340;&#19968;&#33268;&#24615;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#22362;&#23454;&#30340;&#29702;&#35770;&#26694;&#26550;&#21644;&#26356;&#39640;&#25928;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#20197;&#25193;&#23637;Fr\'echet&#22238;&#24402;&#30340;&#24212;&#29992;&#33539;&#22260;&#65292;&#36866;&#29992;&#20110;&#38750;&#26631;&#20934;&#25968;&#25454;&#31867;&#22411;&#21644;&#22797;&#26434;&#29992;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper revisits an adaptation of the random forest algorithm for Fr\'echet regression, addressing the challenge of regression in the context of random objects in metric spaces. Recognizing the limitations of previous approaches, we introduce a new splitting rule that circumvents the computationally expensive operation of Fr\'echet means by substituting with a medoid-based approach. We validate this approach by demonstrating its asymptotic equivalence to Fr\'echet mean-based procedures and establish the consistency of the associated regression estimator. The paper provides a sound theoretical framework and a more efficient computational approach to Fr\'echet regression, broadening its application to non-standard data types and complex use cases.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#28909;&#21147;&#23398;&#32422;&#26463;&#29366;&#24577;&#26041;&#31243;&#65292;&#24182;&#36827;&#34892;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#20197;&#25552;&#39640;&#26041;&#31243;&#39044;&#27979;&#30340;&#21487;&#20449;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.17004</link><description>&lt;p&gt;
&#23398;&#20064;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#28909;&#21147;&#23398;&#32422;&#26463;&#29366;&#24577;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
Learning thermodynamically constrained equations of state with uncertainty. (arXiv:2306.17004v1 [physics.data-an])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17004
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#28909;&#21147;&#23398;&#32422;&#26463;&#29366;&#24577;&#26041;&#31243;&#65292;&#24182;&#36827;&#34892;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#20197;&#25552;&#39640;&#26041;&#31243;&#39044;&#27979;&#30340;&#21487;&#20449;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#33021;&#37327;&#23494;&#24230;&#23454;&#39564;&#30340;&#25968;&#20540;&#27169;&#25311;&#38656;&#35201;&#26041;&#31243;&#29366;&#24577;&#27169;&#22411;&#65288;EOS&#65289;&#65292;&#29992;&#20110;&#20851;&#32852;&#26448;&#26009;&#30340;&#28909;&#21147;&#23398;&#29366;&#24577;&#21464;&#37327; - &#21363;&#21387;&#21147;&#12289;&#20307;&#31215;/&#23494;&#24230;&#12289;&#33021;&#37327;&#21644;&#28201;&#24230;&#12290;EOS&#27169;&#22411;&#36890;&#24120;&#37319;&#29992;&#21322;&#32463;&#39564;&#24615;&#21442;&#25968;&#21270;&#26041;&#27861;&#26500;&#24314;&#65292;&#20551;&#23450;&#20855;&#26377;&#19982;&#29289;&#29702;&#30456;&#20851;&#30340;&#20989;&#25968;&#24418;&#24335;&#65292;&#24182;&#20351;&#29992;&#23454;&#39564;/&#27169;&#25311;&#25968;&#25454;&#36827;&#34892;&#26657;&#20934;&#12290;&#30001;&#20110;&#26657;&#20934;&#25968;&#25454;&#65288;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#65289;&#21644;&#20551;&#23450;&#30340;EOS&#20989;&#25968;&#24418;&#24335;&#65288;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#65289;&#20013;&#23384;&#22312;&#22266;&#26377;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#25191;&#34892;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65288;UQ&#65289;&#20197;&#25552;&#39640;EOS&#39044;&#27979;&#30340;&#21487;&#20449;&#24230;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#23545;&#20110;UQ&#30740;&#31350;&#26469;&#35828;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#23427;&#38656;&#35201;&#25506;&#32034;&#25152;&#26377;&#21487;&#33021;&#30340;&#29289;&#29702;&#19968;&#33268;&#30340;&#20989;&#25968;&#24418;&#24335;&#31354;&#38388;&#12290;&#22240;&#27492;&#65292;&#36890;&#24120;&#22312;&#19981;&#36829;&#21453;&#28909;&#21147;&#23398;&#23450;&#24459;&#30340;&#24773;&#20917;&#19979;&#24573;&#30053;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#32780;&#20559;&#21521;&#20110;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#26469;&#23398;&#20064;EOS&#27169;&#22411;&#30340;&#28909;&#21147;&#23398;&#32422;&#26463;&#26041;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Numerical simulations of high energy-density experiments require equation of state (EOS) models that relate a material's thermodynamic state variables -specifically pressure, volume/density, energy, and temperature. EOS models are typically constructed using a semi-empirical parametric methodology, which assumes a physics-informed functional form with many tunable parameters calibrated using experimental/simulation data. Since there are inherent uncertainties in the calibration data (parametric uncertainty) and the assumed functional EOS form (model uncertainty), it is essential to perform uncertainty quantification (UQ) to improve confidence in the EOS predictions. Model uncertainty is challenging for UQ studies since it requires exploring the space of all possible physically consistent functional forms. Thus, it is often neglected in favor of parametric uncertainty, which is easier to quantify without violating thermodynamic laws. This work presents a data-driven machine learning a
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#35838;&#31243;&#23398;&#20064;&#65292;&#37319;&#29992;&#31232;&#30095;&#31034;&#20363;&#20808;&#23398;&#20064;&#30340;2&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#22312;&#28151;&#21512;&#36755;&#20837;&#30340;&#22855;&#20598;&#30446;&#26631;&#19978;&#23398;&#20064;&#21040;&#36275;&#22815;&#22823;&#38454;&#25968;&#30340;&#22855;&#20598;&#24615;&#65292;&#32780;&#20854;&#20182;&#31070;&#32463;&#32593;&#32476;&#26080;&#27861;&#22312;&#30456;&#21516;&#30340;&#26465;&#20214;&#19979;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2306.16921</link><description>&lt;p&gt;
&#23545;&#28151;&#21512;&#36755;&#20837;&#30340;&#22855;&#20598;&#30446;&#26631;&#65292;&#35838;&#31243;&#23398;&#20064;&#30340;&#21487;&#35777;&#26126;&#20248;&#21183;
&lt;/p&gt;
&lt;p&gt;
Provable Advantage of Curriculum Learning on Parity Targets with Mixed Inputs. (arXiv:2306.16921v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16921
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#35838;&#31243;&#23398;&#20064;&#65292;&#37319;&#29992;&#31232;&#30095;&#31034;&#20363;&#20808;&#23398;&#20064;&#30340;2&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#22312;&#28151;&#21512;&#36755;&#20837;&#30340;&#22855;&#20598;&#30446;&#26631;&#19978;&#23398;&#20064;&#21040;&#36275;&#22815;&#22823;&#38454;&#25968;&#30340;&#22855;&#20598;&#24615;&#65292;&#32780;&#20854;&#20182;&#31070;&#32463;&#32593;&#32476;&#26080;&#27861;&#22312;&#30456;&#21516;&#30340;&#26465;&#20214;&#19979;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35838;&#31243;&#23398;&#20064;&#65292;&#21363;&#20808;&#21576;&#29616;&#31616;&#21333;&#31034;&#20363;&#65292;&#28982;&#21518;&#20877;&#21576;&#29616;&#26356;&#22797;&#26434;&#30340;&#31034;&#20363;&#65292;&#21487;&#20197;&#25552;&#39640;&#23398;&#20064;&#25928;&#29575;&#12290;&#36817;&#26399;&#30340;&#19968;&#20123;&#29702;&#35770;&#32467;&#26524;&#20063;&#34920;&#26126;&#65292;&#25913;&#21464;&#37319;&#26679;&#20998;&#24067;&#21487;&#20197;&#24110;&#21161;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#22855;&#20598;&#24615;&#65292;&#20294;&#21482;&#26377;&#22823;&#23398;&#20064;&#29575;&#21644;&#21333;&#27493;&#21442;&#25968;&#30340;&#24418;&#24335;&#32467;&#26524;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#26631;&#20934;&#65288;&#26377;&#30028;&#65289;&#23398;&#20064;&#29575;&#21644;&#24120;&#35265;&#26679;&#26412;&#20998;&#24067;&#30340;&#35757;&#32451;&#27493;&#39588;&#25968;&#37327;&#19978;&#30340;&#20998;&#31163;&#32467;&#26524;&#65306;&#22914;&#26524;&#25968;&#25454;&#20998;&#24067;&#26159;&#31232;&#30095;&#21644;&#23494;&#38598;&#36755;&#20837;&#30340;&#28151;&#21512;&#29289;&#65292;&#21017;&#23384;&#22312;&#19968;&#31181;&#24773;&#20917;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#35838;&#31243;&#22024;&#26434;&#26799;&#24230;&#19979;&#38477;&#65288;&#25110;SGD&#65289;&#31639;&#27861;&#35757;&#32451;&#30340;2&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#65292;&#20808;&#20351;&#29992;&#31232;&#30095;&#31034;&#20363;&#65292;&#21487;&#20197;&#23398;&#20064;&#21040;&#36275;&#22815;&#22823;&#38454;&#25968;&#30340;&#22855;&#20598;&#24615;&#65292;&#32780;&#20219;&#20309;&#30001;&#22024;&#26434;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#35757;&#32451;&#30340;&#23436;&#20840;&#36830;&#25509;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;&#23485;&#24230;&#25110;&#28145;&#24230;&#21487;&#33021;&#26356;&#22823;&#65289;&#22312;&#20081;&#24207;&#26679;&#26412;&#19978;&#37117;&#19981;&#33021;&#22312;&#27809;&#26377;&#39069;&#22806;&#27493;&#39588;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#23454;&#39564;&#32467;&#26524;&#65292;&#25903;&#25345;&#36229;&#20986;&#30340;&#23450;&#24615;&#20998;&#31163;&#12290;
&lt;/p&gt;
&lt;p&gt;
Experimental results have shown that curriculum learning, i.e., presenting simpler examples before more complex ones, can improve the efficiency of learning. Some recent theoretical results also showed that changing the sampling distribution can help neural networks learn parities, with formal results only for large learning rates and one-step arguments. Here we show a separation result in the number of training steps with standard (bounded) learning rates on a common sample distribution: if the data distribution is a mixture of sparse and dense inputs, there exists a regime in which a 2-layer ReLU neural network trained by a curriculum noisy-GD (or SGD) algorithm that uses sparse examples first, can learn parities of sufficiently large degree, while any fully connected neural network of possibly larger width or depth trained by noisy-GD on the unordered samples cannot learn without additional steps. We also provide experimental results supporting the qualitative separation beyond the 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#20540;&#25968;&#25454;&#22635;&#34917;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#26368;&#36817;&#37051;&#20272;&#35745;&#21644;&#39640;&#26031;&#26680;&#23494;&#24230;&#20272;&#35745;&#32467;&#21512;&#65292;&#33021;&#22815;&#26377;&#25928;&#22788;&#29702;&#22810;&#27169;&#24577;&#25968;&#25454;&#38598;&#20013;&#30340;&#32570;&#22833;&#20540;&#65292;&#24182;&#25552;&#20379;&#27604;&#24403;&#21069;&#26041;&#27861;&#26356;&#39640;&#30340;&#27010;&#29575;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2306.16906</link><description>&lt;p&gt;
&#25968;&#20540;&#25968;&#25454;&#22635;&#34917;&#30340;&#22810;&#27169;&#24577;&#25968;&#25454;&#38598;:&#19968;&#31181;&#27010;&#29575;&#26368;&#36817;&#37051;&#26680;&#23494;&#24230;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Numerical Data Imputation for Multimodal Data Sets: A Probabilistic Nearest-Neighbor Kernel Density Approach. (arXiv:2306.16906v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16906
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#20540;&#25968;&#25454;&#22635;&#34917;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#26368;&#36817;&#37051;&#20272;&#35745;&#21644;&#39640;&#26031;&#26680;&#23494;&#24230;&#20272;&#35745;&#32467;&#21512;&#65292;&#33021;&#22815;&#26377;&#25928;&#22788;&#29702;&#22810;&#27169;&#24577;&#25968;&#25454;&#38598;&#20013;&#30340;&#32570;&#22833;&#20540;&#65292;&#24182;&#25552;&#20379;&#27604;&#24403;&#21069;&#26041;&#27861;&#26356;&#39640;&#30340;&#27010;&#29575;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#20540;&#25968;&#25454;&#22635;&#34917;&#26041;&#27861;&#36890;&#36807;&#20272;&#35745;&#26367;&#25442;&#32570;&#22833;&#30340;&#20540;&#20197;&#21033;&#29992;&#19981;&#23436;&#25972;&#30340;&#25968;&#25454;&#38598;&#12290;&#24403;&#21069;&#30340;&#22635;&#34917;&#26041;&#27861;&#35797;&#22270;&#26368;&#23567;&#21270;&#26410;&#35266;&#23519;&#21040;&#30340;&#30495;&#23454;&#20540;&#21644;&#22635;&#34917;&#20540;&#20043;&#38388;&#30340;&#35823;&#24046;&#12290;&#20294;&#26159;&#65292;&#22312;&#22810;&#27169;&#24577;&#25110;&#22797;&#26434;&#20998;&#24067;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#31181;&#31574;&#30053;&#21487;&#33021;&#20250;&#20135;&#29983;&#20266;&#20687;&#65292;&#23548;&#33268;&#22635;&#34917;&#25928;&#26524;&#36739;&#24046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;$k$NN$\times$KDE&#31639;&#27861;: &#19968;&#31181;&#23558;&#26368;&#36817;&#37051;&#20272;&#35745;($k$NN)&#21644;&#20351;&#29992;&#39640;&#26031;&#26680;&#36827;&#34892;&#23494;&#24230;&#20272;&#35745;(KDE)&#32467;&#21512;&#30340;&#25968;&#25454;&#22635;&#34917;&#26041;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;&#20154;&#24037;&#21644;&#30495;&#23454;&#25968;&#25454;&#36827;&#34892;&#20102;&#19982;&#20043;&#21069;&#25968;&#25454;&#22635;&#34917;&#26041;&#27861;&#30340;&#27604;&#36739;&#65292;&#28041;&#21450;&#20102;&#19981;&#21516;&#30340;&#25968;&#25454;&#32570;&#22833;&#24773;&#20917;&#21644;&#19981;&#21516;&#30340;&#25968;&#25454;&#32570;&#22833;&#29575;&#65292;&#24182;&#19988;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#22788;&#29702;&#22797;&#26434;&#30340;&#21407;&#22987;&#25968;&#25454;&#32467;&#26500;&#65292;&#20135;&#29983;&#26356;&#20302;&#30340;&#25968;&#25454;&#22635;&#34917;&#35823;&#24046;&#65292;&#24182;&#25552;&#20379;&#27604;&#24403;&#21069;&#26041;&#27861;&#26356;&#39640;&#30340;&#27010;&#29575;&#20272;&#35745;&#12290;&#25105;&#20204;&#23558;&#20195;&#30721;&#20197;&#24320;&#28304;&#24418;&#24335;&#21457;&#24067;&#32473;&#31038;&#21306;&#65306;https://github.com/DeltaFloflo/knnxkde
&lt;/p&gt;
&lt;p&gt;
Numerical data imputation algorithms replace missing values by estimates to leverage incomplete data sets. Current imputation methods seek to minimize the error between the unobserved ground truth and the imputed values. But this strategy can create artifacts leading to poor imputation in the presence of multimodal or complex distributions. To tackle this problem, we introduce the $k$NN$\times$KDE algorithm: a data imputation method combining nearest neighbor estimation ($k$NN) and density estimation with Gaussian kernels (KDE). We compare our method with previous data imputation methods using artificial and real-world data with different data missing scenarios and various data missing rates, and show that our method can cope with complex original data structure, yields lower data imputation errors, and provides probabilistic estimates with higher likelihood than current methods. We release the code in open-source for the community: https://github.com/DeltaFloflo/knnxkde
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26080;&#20154;&#26426;&#36827;&#34892;&#20132;&#36890;&#30417;&#27979;&#30340;&#22810;&#30446;&#26631;&#36319;&#36394;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#21033;&#29992;&#20809;&#23398;&#21644;&#28909;&#24863;&#25668;&#20687;&#22836;&#33719;&#21462;&#22270;&#20687;&#19978;&#30340;&#29289;&#20307;&#26816;&#27979;&#65292;&#24182;&#20351;&#29992;&#36712;&#36857;&#27850;&#26494;&#22810;&#20271;&#21162;&#21033;&#28151;&#21512;&#28388;&#27874;&#22120;&#26469;&#20272;&#35745;&#36710;&#36742;&#30340;&#36712;&#36857;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#39564;&#25968;&#25454;&#38598;&#20013;&#20855;&#26377;&#36739;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.16890</link><description>&lt;p&gt;
&#20351;&#29992;&#26080;&#20154;&#26426;&#36827;&#34892;&#20132;&#36890;&#30417;&#27979;&#30340;&#36712;&#36857;&#27850;&#26494;&#22810;&#20271;&#21162;&#21033;&#28151;&#21512;&#28388;&#27874;&#22120;
&lt;/p&gt;
&lt;p&gt;
Trajectory Poisson multi-Bernoulli mixture filter for traffic monitoring using a drone. (arXiv:2306.16890v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16890
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26080;&#20154;&#26426;&#36827;&#34892;&#20132;&#36890;&#30417;&#27979;&#30340;&#22810;&#30446;&#26631;&#36319;&#36394;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#21033;&#29992;&#20809;&#23398;&#21644;&#28909;&#24863;&#25668;&#20687;&#22836;&#33719;&#21462;&#22270;&#20687;&#19978;&#30340;&#29289;&#20307;&#26816;&#27979;&#65292;&#24182;&#20351;&#29992;&#36712;&#36857;&#27850;&#26494;&#22810;&#20271;&#21162;&#21033;&#28151;&#21512;&#28388;&#27874;&#22120;&#26469;&#20272;&#35745;&#36710;&#36742;&#30340;&#36712;&#36857;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#39564;&#25968;&#25454;&#38598;&#20013;&#20855;&#26377;&#36739;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#37197;&#22791;&#26377;&#20809;&#23398;&#21644;&#28909;&#24863;&#25668;&#20687;&#22836;&#30340;&#26080;&#20154;&#26426;&#36827;&#34892;&#20132;&#36890;&#30417;&#27979;&#30340;&#22810;&#30446;&#26631;&#36319;&#36394;&#65288;MOT&#65289;&#31639;&#27861;&#12290;&#22270;&#20687;&#19978;&#30340;&#29289;&#20307;&#26816;&#27979;&#26159;&#20351;&#29992;&#27599;&#31181;&#31867;&#22411;&#25668;&#20687;&#22836;&#30340;&#31070;&#32463;&#32593;&#32476;&#33719;&#24471;&#30340;&#12290;&#25668;&#20687;&#22836;&#34987;&#24314;&#27169;&#20026;&#21040;&#36798;&#26041;&#21521;&#65288;DOA&#65289;&#20256;&#24863;&#22120;&#12290;&#27599;&#20010;DOA&#26816;&#27979;&#37117;&#36981;&#24490;von-Mises Fisher&#20998;&#24067;&#65292;&#20854;&#24179;&#22343;&#26041;&#21521;&#26159;&#36890;&#36807;&#23558;&#36710;&#36742;&#20301;&#32622;&#25237;&#24433;&#21040;&#22320;&#38754;&#19978;&#30340;&#25668;&#20687;&#26426;&#33719;&#24471;&#30340;&#12290;&#28982;&#21518;&#25105;&#20204;&#20351;&#29992;&#36712;&#36857;&#27850;&#26494;&#22810;&#20271;&#21162;&#21033;&#28151;&#21512;&#28388;&#27874;&#22120;&#65288;TPMBM&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#36125;&#21494;&#26031;&#22810;&#30446;&#26631;&#36319;&#36394;&#31639;&#27861;&#65292;&#26469;&#26368;&#20248;&#20272;&#35745;&#19968;&#32452;&#36710;&#36742;&#36712;&#36857;&#12290;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#27979;&#37327;&#27169;&#22411;&#30340;&#21442;&#25968;&#20272;&#35745;&#31639;&#27861;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#23454;&#39564;&#25968;&#25454;&#38598;&#20013;&#27979;&#35797;&#20102;&#25152;&#24471;&#21040;&#30340;TPMBM&#28388;&#27874;&#22120;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a multi-object tracking (MOT) algorithm for traffic monitoring using a drone equipped with optical and thermal cameras. Object detections on the images are obtained using a neural network for each type of camera. The cameras are modelled as direction-of-arrival (DOA) sensors. Each DOA detection follows a von-Mises Fisher distribution, whose mean direction is obtain by projecting a vehicle position on the ground to the camera. We then use the trajectory Poisson multi-Bernoulli mixture filter (TPMBM), which is a Bayesian MOT algorithm, to optimally estimate the set of vehicle trajectories. We have also developed a parameter estimation algorithm for the measurement model. We have tested the accuracy of the resulting TPMBM filter in synthetic and experimental data sets.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#65292;&#36890;&#36807;&#31561;&#20215;&#30340;&#30446;&#26631;&#20989;&#25968;&#24418;&#24335;&#21644;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#25105;&#20204;&#19981;&#20165;&#21487;&#20197;&#20351;&#29992;&#20854;&#20182;&#24809;&#32602;&#26041;&#27861;&#65292;&#36824;&#33021;&#22815;&#20174;&#26799;&#24230;&#19979;&#38477;&#30340;&#35282;&#24230;&#30740;&#31350;&#26680;&#23725;&#22238;&#24402;&#12290;&#36890;&#36807;&#25552;&#21069;&#20572;&#27490;&#30340;&#27491;&#21017;&#21270;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#38381;&#21512;&#35299;&#65292;&#21363;&#26680;&#26799;&#24230;&#27969;&#65288;KGF&#65289;&#65292;&#24182;&#35777;&#26126;&#20102;KGF&#21644;KRR&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#25105;&#20204;&#36824;&#23558;KRR&#27867;&#21270;&#65292;&#20351;&#29992;$\ell_1$&#21644;$\ell_\infty$&#24809;&#32602;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#20351;&#29992;&#36825;&#20123;&#26041;&#27861;&#24471;&#21040;&#30340;&#35299;&#19982;&#21069;&#21521;&#20998;&#27493;&#22238;&#24402;&#21644;&#31526;&#21495;&#26799;&#24230;&#19979;&#38477;&#32467;&#21512;&#25552;&#21069;&#20572;&#27490;&#24471;&#21040;&#30340;&#35299;&#38750;&#24120;&#30456;&#20284;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#20943;&#23569;&#20102;&#35745;&#31639;&#22797;&#26434;&#24230;&#37325;&#30340;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2306.16838</link><description>&lt;p&gt;
&#29992;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#26041;&#27861;&#35299;&#20915;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Solving Kernel Ridge Regression with Gradient-Based Optimization Methods. (arXiv:2306.16838v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16838
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#65292;&#36890;&#36807;&#31561;&#20215;&#30340;&#30446;&#26631;&#20989;&#25968;&#24418;&#24335;&#21644;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#25105;&#20204;&#19981;&#20165;&#21487;&#20197;&#20351;&#29992;&#20854;&#20182;&#24809;&#32602;&#26041;&#27861;&#65292;&#36824;&#33021;&#22815;&#20174;&#26799;&#24230;&#19979;&#38477;&#30340;&#35282;&#24230;&#30740;&#31350;&#26680;&#23725;&#22238;&#24402;&#12290;&#36890;&#36807;&#25552;&#21069;&#20572;&#27490;&#30340;&#27491;&#21017;&#21270;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#38381;&#21512;&#35299;&#65292;&#21363;&#26680;&#26799;&#24230;&#27969;&#65288;KGF&#65289;&#65292;&#24182;&#35777;&#26126;&#20102;KGF&#21644;KRR&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#25105;&#20204;&#36824;&#23558;KRR&#27867;&#21270;&#65292;&#20351;&#29992;$\ell_1$&#21644;$\ell_\infty$&#24809;&#32602;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#20351;&#29992;&#36825;&#20123;&#26041;&#27861;&#24471;&#21040;&#30340;&#35299;&#19982;&#21069;&#21521;&#20998;&#27493;&#22238;&#24402;&#21644;&#31526;&#21495;&#26799;&#24230;&#19979;&#38477;&#32467;&#21512;&#25552;&#21069;&#20572;&#27490;&#24471;&#21040;&#30340;&#35299;&#38750;&#24120;&#30456;&#20284;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#20943;&#23569;&#20102;&#35745;&#31639;&#22797;&#26434;&#24230;&#37325;&#30340;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#23725;&#22238;&#24402;&#65288;KRR&#65289;&#26159;&#32447;&#24615;&#23725;&#22238;&#24402;&#30340;&#38750;&#32447;&#24615;&#25512;&#24191;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;KRR&#30446;&#26631;&#20989;&#25968;&#30340;&#31561;&#20215;&#24418;&#24335;&#65292;&#20026;&#20351;&#29992;&#20854;&#20182;&#24809;&#32602;&#26041;&#27861;&#21644;&#20174;&#26799;&#24230;&#19979;&#38477;&#30340;&#35282;&#24230;&#30740;&#31350;&#26680;&#23725;&#22238;&#24402;&#25171;&#24320;&#20102;&#21487;&#33021;&#12290;&#36890;&#36807;&#36830;&#32493;&#26102;&#38388;&#30340;&#35270;&#35282;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#38381;&#21512;&#35299;&#8212;&#8212;&#26680;&#26799;&#24230;&#27969;&#65288;KGF&#65289;&#65292;&#36890;&#36807;&#25552;&#21069;&#20572;&#27490;&#30340;&#27491;&#21017;&#21270;&#65292;&#35753;&#25105;&#20204;&#33021;&#22815;&#22312;KGF&#21644;KRR&#20043;&#38388;&#29702;&#35770;&#19978;&#30028;&#23450;&#24046;&#24322;&#12290;&#25105;&#20204;&#29992;$\ell_1$&#21644;$\ell_\infty$&#24809;&#32602;&#26041;&#27861;&#23558;KRR&#27867;&#21270;&#65292;&#24182;&#21033;&#29992;&#31867;&#20284;KGF&#21644;KRR&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#20351;&#29992;&#36825;&#20123;&#24809;&#32602;&#26041;&#27861;&#24471;&#21040;&#30340;&#35299;&#19982;&#20351;&#29992;&#21069;&#21521;&#20998;&#27493;&#22238;&#24402;&#65288;&#20063;&#31216;&#20026;&#22352;&#26631;&#19979;&#38477;&#65289;&#21644;&#31526;&#21495;&#26799;&#24230;&#19979;&#38477;&#32467;&#21512;&#25552;&#21069;&#20572;&#27490;&#24471;&#21040;&#30340;&#35299;&#38750;&#24120;&#30456;&#20284;&#12290;&#22240;&#27492;&#65292;&#20943;&#23569;&#20102;&#35745;&#31639;&#22797;&#26434;&#24230;&#37325;&#30340;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernel ridge regression, KRR, is a non-linear generalization of linear ridge regression. Here, we introduce an equivalent formulation of the objective function of KRR, opening up both for using other penalties than the ridge penalty and for studying kernel ridge regression from the perspective of gradient descent. Using a continuous-time perspective, we derive a closed-form solution, kernel gradient flow, KGF, with regularization through early stopping, which allows us to theoretically bound the differences between KGF and KRR. We generalize KRR by replacing the ridge penalty with the $\ell_1$ and $\ell_\infty$ penalties and utilize the fact that analogously to the similarities between KGF and KRR, the solutions obtained when using these penalties are very similar to those obtained from forward stagewise regression (also known as coordinate descent) and sign gradient descent in combination with early stopping. Thus the need for computationally heavy proximal gradient descent algorithms
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#20449;&#29992;&#20998;&#37197;&#31639;&#27861;&#65292;&#36890;&#36807;&#37327;&#21270;&#21453;&#20107;&#23454;&#26597;&#35810;&#26469;&#27979;&#37327;&#21160;&#20316;&#23545;&#26410;&#26469;&#22870;&#21169;&#30340;&#24433;&#21709;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#36890;&#36807;&#27979;&#37327;&#23545;&#22870;&#21169;&#25110;&#22870;&#21169;&#23545;&#35937;&#34920;&#31034;&#30340;&#36129;&#29486;&#65292;&#33719;&#24471;&#20102;&#20855;&#26377;&#26356;&#20302;&#26041;&#24046;&#30340;&#26799;&#24230;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2306.16803</link><description>&lt;p&gt;
&#38271;&#26399;&#20449;&#29992;&#24402;&#22240;&#36890;&#36807;&#21453;&#20107;&#23454;&#36129;&#29486;&#20998;&#26512;&#30340;&#26041;&#24335;
&lt;/p&gt;
&lt;p&gt;
Would I have gotten that reward? Long-term credit assignment by counterfactual contribution analysis. (arXiv:2306.16803v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16803
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#20449;&#29992;&#20998;&#37197;&#31639;&#27861;&#65292;&#36890;&#36807;&#37327;&#21270;&#21453;&#20107;&#23454;&#26597;&#35810;&#26469;&#27979;&#37327;&#21160;&#20316;&#23545;&#26410;&#26469;&#22870;&#21169;&#30340;&#24433;&#21709;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#36890;&#36807;&#27979;&#37327;&#23545;&#22870;&#21169;&#25110;&#22870;&#21169;&#23545;&#35937;&#34920;&#31034;&#30340;&#36129;&#29486;&#65292;&#33719;&#24471;&#20102;&#20855;&#26377;&#26356;&#20302;&#26041;&#24046;&#30340;&#26799;&#24230;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#20351;&#24378;&#21270;&#23398;&#20064;&#26356;&#21152;&#26679;&#26412;&#39640;&#25928;&#65292;&#25105;&#20204;&#38656;&#35201;&#26356;&#22909;&#30340;&#20449;&#29992;&#24402;&#22240;&#26041;&#27861;&#26469;&#34913;&#37327;&#21160;&#20316;&#23545;&#26410;&#26469;&#22870;&#21169;&#30340;&#24433;&#21709;&#12290;&#22312;&#24724;&#26827;&#20449;&#29992;&#24402;&#22240;&#65288;HCA&#65289;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#21453;&#20107;&#23454;&#36129;&#29486;&#20998;&#26512;&#65288;COCOA&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#20449;&#29992;&#24402;&#22240;&#31639;&#27861;&#31995;&#21015;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#36890;&#36807;&#37327;&#21270;&#19968;&#20010;&#21453;&#20107;&#23454;&#26597;&#35810;&#26469;&#23454;&#29616;&#31934;&#30830;&#30340;&#20449;&#29992;&#20998;&#37197;&#65306;&#8220;&#22914;&#26524;&#20195;&#29702;&#36873;&#25321;&#21478;&#19968;&#20010;&#21160;&#20316;&#65292;&#23427;&#20173;&#28982;&#20250;&#33719;&#24471;&#36825;&#20010;&#22870;&#21169;&#21527;&#65311;&#8221;&#36890;&#36807;&#27979;&#37327;&#21160;&#20316;&#23545;&#33719;&#24471;&#21518;&#32493;&#22870;&#21169;&#30340;&#36129;&#29486;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23545;&#20110;&#22870;&#21169;&#29366;&#24577;&#27979;&#37327;&#36129;&#29486;&#65288;&#21363;HCA&#20013;&#25152;&#20570;&#30340;&#65289;&#20250;&#23548;&#33268;&#36129;&#29486;&#30340;&#38169;&#35823;&#20272;&#35745;&#65292;&#20351;&#24471;HCA&#22312;&#35768;&#22810;&#30456;&#20851;&#29615;&#22659;&#20013;&#21521;&#39640;&#26041;&#24046;&#30340;REINFORCE&#20272;&#35745;&#22120;&#36864;&#21270;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#36890;&#36807;&#27979;&#37327;&#23545;&#22870;&#21169;&#25110;&#25152;&#23398;&#20064;&#30340;&#22870;&#21169;&#23545;&#35937;&#30340;&#34920;&#31034;&#30340;&#36129;&#29486;&#65292;&#24471;&#21040;&#20855;&#26377;&#26356;&#20302;&#26041;&#24046;&#30340;&#26799;&#24230;&#20272;&#35745;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#29305;&#23450;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;
&lt;/p&gt;
&lt;p&gt;
To make reinforcement learning more sample efficient, we need better credit assignment methods that measure an action's influence on future rewards. Building upon Hindsight Credit Assignment (HCA), we introduce Counterfactual Contribution Analysis (COCOA), a new family of model-based credit assignment algorithms. Our algorithms achieve precise credit assignment by measuring the contribution of actions upon obtaining subsequent rewards, by quantifying a counterfactual query: "Would the agent still have reached this reward if it had taken another action?". We show that measuring contributions w.r.t. rewarding states, as is done in HCA, results in spurious estimates of contributions, causing HCA to degrade towards the high-variance REINFORCE estimator in many relevant environments. Instead, we measure contributions w.r.t. rewards or learned representations of the rewarding objects, resulting in gradient estimates with lower variance. We run experiments on a suite of problems specifically 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#21033;&#29992;&#24322;&#26041;&#24046;&#31070;&#32463;&#22238;&#24402;&#27169;&#22411;&#23545;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#36827;&#34892;&#24314;&#27169;&#26102;&#30340;&#22256;&#38590;&#65292;&#24182;&#20174;&#32479;&#35745;&#29289;&#29702;&#30340;&#35282;&#24230;&#25552;&#20379;&#20102;&#35299;&#37322;&#12290;&#20316;&#32773;&#35777;&#26126;&#20102;&#36825;&#20123;&#19981;&#31283;&#23450;&#24615;&#19981;&#20165;&#36866;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#65292;&#32780;&#19988;&#24050;&#32463;&#22312;&#36807;&#21442;&#25968;&#21270;&#26465;&#20214;&#39640;&#26031;&#20284;&#28982;&#27169;&#22411;&#30340;&#22330;&#35770;&#20013;&#23384;&#22312;&#12290;&#25968;&#20540;&#27714;&#35299;&#32467;&#26524;&#19982;&#23454;&#35777;&#27169;&#22411;&#25311;&#21512;&#30340;&#23450;&#24615;&#19968;&#33268;&#24615;&#35777;&#26126;&#20102;&#30456;&#21464;&#30340;&#23384;&#22312;&#12290;</title><link>http://arxiv.org/abs/2306.16717</link><description>&lt;p&gt;
&#29702;&#35299;&#28145;&#24230;&#24322;&#26041;&#24046;&#22238;&#24402;&#30340;&#30149;&#24577;
&lt;/p&gt;
&lt;p&gt;
Understanding Pathologies of Deep Heteroskedastic Regression. (arXiv:2306.16717v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16717
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#21033;&#29992;&#24322;&#26041;&#24046;&#31070;&#32463;&#22238;&#24402;&#27169;&#22411;&#23545;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#36827;&#34892;&#24314;&#27169;&#26102;&#30340;&#22256;&#38590;&#65292;&#24182;&#20174;&#32479;&#35745;&#29289;&#29702;&#30340;&#35282;&#24230;&#25552;&#20379;&#20102;&#35299;&#37322;&#12290;&#20316;&#32773;&#35777;&#26126;&#20102;&#36825;&#20123;&#19981;&#31283;&#23450;&#24615;&#19981;&#20165;&#36866;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#65292;&#32780;&#19988;&#24050;&#32463;&#22312;&#36807;&#21442;&#25968;&#21270;&#26465;&#20214;&#39640;&#26031;&#20284;&#28982;&#27169;&#22411;&#30340;&#22330;&#35770;&#20013;&#23384;&#22312;&#12290;&#25968;&#20540;&#27714;&#35299;&#32467;&#26524;&#19982;&#23454;&#35777;&#27169;&#22411;&#25311;&#21512;&#30340;&#23450;&#24615;&#19968;&#33268;&#24615;&#35777;&#26126;&#20102;&#30456;&#21464;&#30340;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#30340;&#30740;&#31350;&#25253;&#21578;&#20102;&#22312;&#20351;&#29992;&#24322;&#26041;&#24046;&#31070;&#32463;&#22238;&#24402;&#27169;&#22411;&#23545;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#24314;&#27169;&#26102;&#20986;&#29616;&#30340;&#36127;&#38754;&#32467;&#26524;&#12290;&#29305;&#21035;&#26159;&#65292;&#23545;&#20110;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#65292;&#22343;&#20540;&#32593;&#32476;&#21644;&#26041;&#24046;&#32593;&#32476;&#36275;&#22815;&#24378;&#22823;&#65292;&#21487;&#20197;&#25311;&#21512;&#27599;&#20010;&#25968;&#25454;&#28857;&#65288;&#21516;&#26102;&#23558;&#39044;&#27979;&#30340;&#26041;&#24046;&#25910;&#32553;&#21040;&#38646;&#65289;&#65292;&#25110;&#32773;&#23398;&#20064;&#19968;&#20010;&#24658;&#23450;&#30340;&#39044;&#27979;&#65292;&#36755;&#20986;&#26041;&#24046;&#24688;&#22909;&#21305;&#37197;&#27599;&#20010;&#39044;&#27979;&#27531;&#24046;&#65288;&#21363;&#23558;&#30446;&#26631;&#35299;&#37322;&#20026;&#32431;&#22122;&#22768;&#65289;&#12290;&#26412;&#25991;&#20174;&#32479;&#35745;&#29289;&#29702;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#36825;&#20123;&#22256;&#38590;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35266;&#23519;&#21040;&#30340;&#19981;&#31283;&#23450;&#24615;&#19981;&#29305;&#23450;&#20110;&#20219;&#20309;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#65292;&#32780;&#26159;&#24050;&#32463;&#23384;&#22312;&#20110;&#36807;&#21442;&#25968;&#21270;&#26465;&#20214;&#39640;&#26031;&#20284;&#28982;&#27169;&#22411;&#30340;&#22330;&#35770;&#20013;&#12290;&#22312;&#36731;&#24494;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#19968;&#20010;&#21487;&#20197;&#36890;&#36807;&#25968;&#20540;&#27714;&#35299;&#30340;&#38750;&#21442;&#25968;&#33258;&#30001;&#33021;&#12290;&#24471;&#21040;&#30340;&#35299;&#19982;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#19978;&#30340;&#23454;&#35777;&#27169;&#22411;&#25311;&#21512;&#20855;&#26377;&#33391;&#22909;&#30340;&#23450;&#24615;&#19968;&#33268;&#24615;&#65292;&#24182;&#19988;&#29305;&#21035;&#35777;&#26126;&#20102;&#30456;&#21464;&#30340;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several recent studies have reported negative results when using heteroskedastic neural regression models to model real-world data. In particular, for overparameterized models, the mean and variance networks are powerful enough to either fit every single data point (while shrinking the predicted variances to zero), or to learn a constant prediction with an output variance exactly matching every predicted residual (i.e., explaining the targets as pure noise). This paper studies these difficulties from the perspective of statistical physics. We show that the observed instabilities are not specific to any neural network architecture but are already present in a field theory of an overparameterized conditional Gaussian likelihood model. Under light assumptions, we derive a nonparametric free energy that can be solved numerically. The resulting solutions show excellent qualitative agreement with empirical model fits on real-world data and, in particular, prove the existence of phase transit
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#22238;&#24402;&#26494;&#24347;&#26102;&#38388;&#24207;&#21015;&#65288;ARS&#65289;&#27169;&#22411;&#65292;&#36890;&#36807;&#32771;&#34385;&#21160;&#24577;&#31995;&#32479;&#30340;&#26102;&#38388;&#19981;&#21464;&#24615;&#21644;&#32447;&#24615;&#24615;&#65292;&#21516;&#26102;&#20272;&#35745;&#28436;&#21270;&#20989;&#25968;&#21644;&#32570;&#22833;&#21464;&#37327;&#65292;&#29992;&#20110;&#39044;&#27979;&#21160;&#24577;&#26102;&#38388;&#24207;&#21015;&#20013;&#32570;&#22833;&#21464;&#37327;&#30340;&#21457;&#23637;&#12290;</title><link>http://arxiv.org/abs/2306.16593</link><description>&lt;p&gt;
&#21160;&#24577;&#26102;&#38388;&#24207;&#21015;&#30340;&#21457;&#23637;&#39044;&#27979;&#22312;&#26102;&#38388;&#19981;&#21464;&#24615;&#21644;&#32447;&#24615;&#24615;&#30340;&#24110;&#21161;&#19979;
&lt;/p&gt;
&lt;p&gt;
Forecasting of the development of a partially-observed dynamical time series with the aid of time-invariance and linearity. (arXiv:2306.16593v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16593
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#22238;&#24402;&#26494;&#24347;&#26102;&#38388;&#24207;&#21015;&#65288;ARS&#65289;&#27169;&#22411;&#65292;&#36890;&#36807;&#32771;&#34385;&#21160;&#24577;&#31995;&#32479;&#30340;&#26102;&#38388;&#19981;&#21464;&#24615;&#21644;&#32447;&#24615;&#24615;&#65292;&#21516;&#26102;&#20272;&#35745;&#28436;&#21270;&#20989;&#25968;&#21644;&#32570;&#22833;&#21464;&#37327;&#65292;&#29992;&#20110;&#39044;&#27979;&#21160;&#24577;&#26102;&#38388;&#24207;&#21015;&#20013;&#32570;&#22833;&#21464;&#37327;&#30340;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21160;&#24577;&#31995;&#32479;&#20135;&#29983;&#19968;&#31181;&#20381;&#36182;&#22810;&#20803;&#24207;&#21015;&#65292;&#31216;&#20026;&#21160;&#24577;&#26102;&#38388;&#24207;&#21015;&#65292;&#36890;&#36807;&#28436;&#21270;&#20989;&#25968;&#21457;&#23637;&#32780;&#26469;&#12290;&#30001;&#20110;&#24403;&#21069;&#26102;&#38388;&#28857;&#30340;&#21160;&#24577;&#26102;&#38388;&#24207;&#21015;&#21464;&#37327;&#36890;&#24120;&#20381;&#36182;&#20110;&#21069;&#19968;&#20010;&#26102;&#38388;&#28857;&#30340;&#25152;&#26377;&#21464;&#37327;&#65292;&#29616;&#26377;&#30740;&#31350;&#36890;&#36807;&#20272;&#35745;&#28436;&#21270;&#20989;&#25968;&#26469;&#39044;&#27979;&#26410;&#26469;&#26102;&#38388;&#28857;&#30340;&#21464;&#37327;&#12290;&#28982;&#32780;&#65292;&#22312;&#26576;&#20123;&#23454;&#38469;&#24773;&#20917;&#19979;&#65292;&#21160;&#24577;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#19968;&#20123;&#21464;&#37327;&#26159;&#32570;&#22833;&#30340;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#22238;&#24402;&#26494;&#24347;&#26102;&#38388;&#24207;&#21015;&#65288;ARS&#65289;&#27169;&#22411;&#12290;ARS&#27169;&#22411;&#28041;&#21450;&#28436;&#21270;&#20989;&#25968;&#21644;&#20316;&#20026;&#26494;&#24347;&#26102;&#38388;&#24207;&#21015;&#30340;&#28508;&#22312;&#32570;&#22833;&#21464;&#37327;&#30340;&#21516;&#26102;&#20272;&#35745;&#65292;&#20511;&#21161;&#20110;&#21160;&#24577;&#31995;&#32479;&#30340;&#26102;&#38388;&#19981;&#21464;&#24615;&#21644;&#32447;&#24615;&#24615;&#12290;&#26412;&#30740;&#31350;&#23454;&#35777;&#20102;&#25552;&#20986;&#30340;ARS&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
A dynamical system produces a dependent multivariate sequence called dynamical time series, developed with an evolution function. As variables in the dynamical time series at the current time-point usually depend on the whole variables in the previous time-point, existing studies forecast the variables at the future time-point by estimating the evolution function. However, some variables in the dynamical time-series are missing in some practical situations. In this study, we propose an autoregressive with slack time series (ARS) model. ARS model involves the simultaneous estimation of the evolution function and the underlying missing variables as a slack time series, with the aid of the time-invariance and linearity of the dynamical system. This study empirically demonstrates the effectiveness of the proposed ARS model.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#27599;&#20010;&#21608;&#26399;&#23558;&#19968;&#21333;&#20301;&#21487;&#20998;&#36164;&#28304;&#20998;&#37197;&#21040;&#22810;&#20010;&#33218;&#19978;&#30340;&#38382;&#39064;&#65292;&#33218;&#19978;&#30340;&#22870;&#21169;&#26159;&#26410;&#30693;&#21644;&#38543;&#26426;&#30340;&#65292;&#32780;&#19988;&#19982;&#20998;&#37197;&#30340;&#36164;&#28304;&#25104;&#27604;&#20363;&#65292;&#32780;&#26041;&#24046;&#19982;&#20998;&#37197;&#36164;&#28304;&#30340;&#38454;&#25968;&#25104;&#27604;&#20363;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#19981;&#21516;&#38454;&#25968;&#19979;&#30340;&#26368;&#20248;&#26377;&#30028;&#21644;&#26080;&#30028;&#36951;&#25022;&#65292;&#32467;&#26524;&#34920;&#26126;&#22312;&#38454;&#25968;&#20026;1/2&#26102;&#23384;&#22312;&#30456;&#21464;&#29616;&#35937;&#12290;</title><link>http://arxiv.org/abs/2306.16578</link><description>&lt;p&gt;
&#22312;&#20855;&#26377;&#26410;&#30693;&#21644;&#38543;&#26426;&#22870;&#21169;&#30340;&#33218;&#19978;&#20998;&#37197;&#21487;&#20998;&#36164;&#28304;
&lt;/p&gt;
&lt;p&gt;
Allocating Divisible Resources on Arms with Unknown and Random Rewards. (arXiv:2306.16578v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16578
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#27599;&#20010;&#21608;&#26399;&#23558;&#19968;&#21333;&#20301;&#21487;&#20998;&#36164;&#28304;&#20998;&#37197;&#21040;&#22810;&#20010;&#33218;&#19978;&#30340;&#38382;&#39064;&#65292;&#33218;&#19978;&#30340;&#22870;&#21169;&#26159;&#26410;&#30693;&#21644;&#38543;&#26426;&#30340;&#65292;&#32780;&#19988;&#19982;&#20998;&#37197;&#30340;&#36164;&#28304;&#25104;&#27604;&#20363;&#65292;&#32780;&#26041;&#24046;&#19982;&#20998;&#37197;&#36164;&#28304;&#30340;&#38454;&#25968;&#25104;&#27604;&#20363;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#19981;&#21516;&#38454;&#25968;&#19979;&#30340;&#26368;&#20248;&#26377;&#30028;&#21644;&#26080;&#30028;&#36951;&#25022;&#65292;&#32467;&#26524;&#34920;&#26126;&#22312;&#38454;&#25968;&#20026;1/2&#26102;&#23384;&#22312;&#30456;&#21464;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;&#20915;&#31574;&#32773;&#22312;&#27599;&#20010;&#21608;&#26399;&#23558;&#19968;&#20010;&#21487;&#20877;&#29983;&#21644;&#21487;&#20998;&#36164;&#28304;&#20998;&#37197;&#21040;&#22810;&#20010;&#33218;&#19978;&#12290;&#36825;&#20123;&#33218;&#20855;&#26377;&#26410;&#30693;&#21644;&#38543;&#26426;&#30340;&#22870;&#21169;&#65292;&#20854;&#22343;&#20540;&#19982;&#20998;&#37197;&#30340;&#36164;&#28304;&#25104;&#27604;&#20363;&#65292;&#26041;&#24046;&#19982;&#20998;&#37197;&#36164;&#28304;&#30340;&#38454;&#25968;$b$&#25104;&#27604;&#20363;&#12290;&#29305;&#21035;&#22320;&#65292;&#22914;&#26524;&#20915;&#31574;&#32773;&#22312;&#19968;&#20010;&#21608;&#26399;&#23558;&#36164;&#28304;$A_i$&#20998;&#37197;&#32473;&#33218;$i$&#65292;&#37027;&#20040;&#22870;&#21169;$Y_i$&#26159;$Y_i(A_i)=A_i\mu_i+A_i^b\xi_i$&#65292;&#20854;&#20013;$\mu_i$&#26159;&#26410;&#30693;&#30340;&#22343;&#20540;&#65292;&#22122;&#22768;$\xi_i$&#26159;&#29420;&#31435;&#19988;&#23376;&#39640;&#26031;&#30340;&#12290;&#24403;&#38454;&#25968;$b$&#20174;0&#21040;1&#21464;&#21270;&#26102;&#65292;&#35813;&#26694;&#26550;&#24179;&#28369;&#22320;&#36830;&#25509;&#20102;&#26631;&#20934;&#30340;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#26426;&#21644;&#24102;&#26377;&#23436;&#20840;&#21453;&#39304;&#30340;&#22312;&#32447;&#23398;&#20064;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#23427;&#20204;&#23454;&#29616;&#20102;$b\in[0,1]$&#26102;&#30340;&#26368;&#20248;&#26377;&#30028;&#24046;&#21644;&#26080;&#30028;&#24046;&#30340;&#36951;&#25022;&#30028;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;$b=1/2$&#22788;&#30340;&#30456;&#21464;&#12290;&#29702;&#35770;&#32467;&#26524;&#20381;&#36182;&#20110;&#25105;&#20204;&#24320;&#21457;&#30340;&#19968;&#31181;&#26032;&#22411;&#27987;&#24230;&#19981;&#31561;&#24335;&#65292;&#23427;&#38480;&#21046;&#20102;&#23376;&#39640;&#26031;&#38543;&#26426;&#21464;&#37327;&#30340;&#32447;&#24615;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a decision maker allocating one unit of renewable and divisible resource in each period on a number of arms. The arms have unknown and random rewards whose means are proportional to the allocated resource and whose variances are proportional to an order $b$ of the allocated resource. In particular, if the decision maker allocates resource $A_i$ to arm $i$ in a period, then the reward $Y_i$ is$Y_i(A_i)=A_i \mu_i+A_i^b \xi_{i}$, where $\mu_i$ is the unknown mean and the noise $\xi_{i}$ is independent and sub-Gaussian. When the order $b$ ranges from 0 to 1, the framework smoothly bridges the standard stochastic multi-armed bandit and online learning with full feedback. We design two algorithms that attain the optimal gap-dependent and gap-independent regret bounds for $b\in [0,1]$, and demonstrate a phase transition at $b=1/2$. The theoretical results hinge on a novel concentration inequality we have developed that bounds a linear combination of sub-Gaussian random variables w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26377;&#38480;&#26679;&#26412;&#19979;&#23545;&#31216;&#22343;&#20540;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#24182;&#32473;&#20986;&#20102;&#22522;&#20110;&#36153;&#33293;&#23572;&#20449;&#24687;&#30340;&#20445;&#35777;&#12290;&#23545;&#20110;&#23545;&#31216;&#20998;&#24067;&#65292;&#21487;&#20197;&#33719;&#24471;&#25910;&#25947;&#21040;&#27425;&#39640;&#26031;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#32780;&#19981;&#38656;&#35201;&#28176;&#36817;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2306.16573</link><description>&lt;p&gt;
&#26377;&#38480;&#26679;&#26412;&#19979;&#20855;&#26377;&#36153;&#33293;&#23572;&#20449;&#24687;&#36895;&#29575;&#30340;&#23545;&#31216;&#22343;&#20540;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Finite-Sample Symmetric Mean Estimation with Fisher Information Rate. (arXiv:2306.16573v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16573
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26377;&#38480;&#26679;&#26412;&#19979;&#23545;&#31216;&#22343;&#20540;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#24182;&#32473;&#20986;&#20102;&#22522;&#20110;&#36153;&#33293;&#23572;&#20449;&#24687;&#30340;&#20445;&#35777;&#12290;&#23545;&#20110;&#23545;&#31216;&#20998;&#24067;&#65292;&#21487;&#20197;&#33719;&#24471;&#25910;&#25947;&#21040;&#27425;&#39640;&#26031;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#32780;&#19981;&#38656;&#35201;&#28176;&#36817;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#19968;&#20010;&#26410;&#30693;&#26041;&#24046;&#20026;$\sigma^2$&#30340;&#20998;&#24067;$f$&#65292;&#21487;&#20197;&#36890;&#36807;$n$&#20010;&#26679;&#26412;&#20197;&#26041;&#24046;$\frac{\sigma^2}{n}$&#21644;&#20960;&#20046;&#30456;&#23545;&#24212;&#30340;&#27425;&#39640;&#26031;&#36895;&#29575;&#26469;&#20272;&#35745;&#22343;&#20540;&#12290;&#24403;$f$&#24050;&#30693;&#19988;&#23545;&#31216;&#26102;&#65292;&#21487;&#20197;&#22312;&#28176;&#36817;&#26465;&#20214;&#19979;&#23558;&#20854;&#25913;&#36827;&#20026;$\frac{1}{n\mathcal I}$&#65292;&#20854;&#20013;$\mathcal I$&#20026;&#35813;&#20998;&#24067;&#30340;&#36153;&#33293;&#23572;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#19968;&#33324;&#30340;&#26410;&#30693;&#20998;&#24067;$f$&#65292;&#36825;&#26679;&#30340;&#25913;&#36827;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#20294;&#26159;&#65292;Stone(1975)&#35777;&#26126;&#20102;&#24403;$f$&#20851;&#20110;&#20854;&#22343;&#20540;&#23545;&#31216;&#26102;&#65292;&#36825;&#31181;&#28176;&#36817;&#25910;&#25947;&#26159;&#21487;&#33021;&#30340;&#12290;&#28982;&#32780;&#65292;Stone&#30340;&#30028;&#38480;&#26159;&#28176;&#36817;&#30340;&#65292;&#21363;&#25910;&#25947;&#25152;&#38656;&#30340;$n$&#20197;&#26410;&#25351;&#23450;&#30340;&#26041;&#24335;&#21462;&#20915;&#20110;&#20998;&#24067;$f$&#21644;&#22833;&#36133;&#27010;&#29575;$\delta$&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23601;&#23545;&#31216;&#22343;&#20540;&#20272;&#35745;&#30340;&#36153;&#33293;&#23572;&#20449;&#24687;&#32473;&#20986;&#26377;&#38480;&#26679;&#26412;&#30340;&#20445;&#35777;&#12290;&#23545;&#20110;&#27599;&#20010;$f,n,\delta$&#28385;&#36275;$n &gt; \log \frac{1}{\delta}$&#65292;&#25105;&#20204;&#21487;&#20197;&#24471;&#21040;&#25910;&#25947;&#21040;&#26041;&#24046;&#20026;$\frac{1}{n \mathcal I_r}$&#30340;&#27425;&#39640;&#26031;&#38468;&#36817;&#30340;&#25910;&#25947;&#65292;&#20854;&#20013;$\mathcal I_r$&#26159;$r$-$\textit{&#24179;&#28369;&#21270;}$&#36153;&#33293;&#23572;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
The mean of an unknown variance-$\sigma^2$ distribution $f$ can be estimated from $n$ samples with variance $\frac{\sigma^2}{n}$ and nearly corresponding subgaussian rate. When $f$ is known up to translation, this can be improved asymptotically to $\frac{1}{n\mathcal I}$, where $\mathcal I$ is the Fisher information of the distribution. Such an improvement is not possible for general unknown $f$, but [Stone, 1975] showed that this asymptotic convergence $\textit{is}$ possible if $f$ is $\textit{symmetric}$ about its mean. Stone's bound is asymptotic, however: the $n$ required for convergence depends in an unspecified way on the distribution $f$ and failure probability $\delta$. In this paper we give finite-sample guarantees for symmetric mean estimation in terms of Fisher information. For every $f, n, \delta$ with $n &gt; \log \frac{1}{\delta}$, we get convergence close to a subgaussian with variance $\frac{1}{n \mathcal I_r}$, where $\mathcal I_r$ is the $r$-$\textit{smoothed}$ Fisher in
&lt;/p&gt;</description></item><item><title>&#22312;&#23384;&#22312;&#32456;&#32467;&#20107;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#30740;&#31350;&#32463;&#24120;&#24615;&#20107;&#20214;&#30340;&#22240;&#26524;&#25512;&#26029;&#21644;&#39640;&#25928;&#20272;&#35745;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20056;&#27861;&#40065;&#26834;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#19981;&#20381;&#36182;&#20110;&#20998;&#24067;&#20551;&#35774;&#65292;&#24182;&#25351;&#20986;&#20102;&#19968;&#20123;&#26377;&#36259;&#30340;&#22240;&#26524;&#29983;&#21629;&#21608;&#26399;&#20013;&#30340;&#19981;&#19968;&#33268;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.16571</link><description>&lt;p&gt;
&#22312;&#23384;&#22312;&#32456;&#32467;&#20107;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#20851;&#20110;&#32463;&#24120;&#24615;&#20107;&#20214;&#30340;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Causal inference for the expected number of recurrent events in the presence of a terminal event. (arXiv:2306.16571v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16571
&lt;/p&gt;
&lt;p&gt;
&#22312;&#23384;&#22312;&#32456;&#32467;&#20107;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#30740;&#31350;&#32463;&#24120;&#24615;&#20107;&#20214;&#30340;&#22240;&#26524;&#25512;&#26029;&#21644;&#39640;&#25928;&#20272;&#35745;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20056;&#27861;&#40065;&#26834;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#19981;&#20381;&#36182;&#20110;&#20998;&#24067;&#20551;&#35774;&#65292;&#24182;&#25351;&#20986;&#20102;&#19968;&#20123;&#26377;&#36259;&#30340;&#22240;&#26524;&#29983;&#21629;&#21608;&#26399;&#20013;&#30340;&#19981;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#23384;&#22312;&#32456;&#32467;&#20107;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#20851;&#20110;&#32463;&#24120;&#24615;&#20107;&#20214;&#30340;&#22240;&#26524;&#25512;&#26029;&#21644;&#39640;&#25928;&#20272;&#35745;&#12290;&#25105;&#20204;&#23558;&#20272;&#35745;&#30446;&#26631;&#23450;&#20041;&#20026;&#21253;&#25324;&#32463;&#24120;&#24615;&#20107;&#20214;&#30340;&#39044;&#26399;&#25968;&#37327;&#20197;&#21450;&#22312;&#19968;&#31995;&#21015;&#37324;&#31243;&#30865;&#26102;&#38388;&#28857;&#22788;&#35780;&#20272;&#30340;&#22833;&#36133;&#29983;&#23384;&#20989;&#25968;&#30340;&#21521;&#37327;&#12290;&#25105;&#20204;&#22312;&#21491;&#25130;&#23614;&#21644;&#22240;&#26524;&#36873;&#25321;&#30340;&#24773;&#20917;&#19979;&#30830;&#23450;&#20102;&#20272;&#35745;&#30446;&#26631;&#65292;&#20316;&#20026;&#35266;&#23519;&#25968;&#25454;&#30340;&#21151;&#33021;&#24615;&#65292;&#25512;&#23548;&#20102;&#38750;&#21442;&#25968;&#25928;&#29575;&#30028;&#38480;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#37325;&#40065;&#26834;&#20272;&#35745;&#22120;&#65292;&#35813;&#20272;&#35745;&#22120;&#36798;&#21040;&#20102;&#30028;&#38480;&#65292;&#24182;&#20801;&#35768;&#38750;&#21442;&#25968;&#20272;&#35745;&#36741;&#21161;&#21442;&#25968;&#12290;&#22312;&#25972;&#20010;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#23545;&#22833;&#36133;&#12289;&#25130;&#23614;&#25110;&#35266;&#23519;&#25968;&#25454;&#30340;&#27010;&#29575;&#20998;&#24067;&#27809;&#26377;&#20570;&#32477;&#23545;&#36830;&#32493;&#24615;&#30340;&#20551;&#35774;&#12290;&#27492;&#22806;&#65292;&#24403;&#20998;&#21106;&#20998;&#24067;&#24050;&#30693;&#26102;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;&#24433;&#21709;&#20989;&#25968;&#30340;&#31867;&#21035;&#65292;&#24182;&#22238;&#39038;&#20102;&#24050;&#21457;&#34920;&#20272;&#35745;&#22120;&#22914;&#20309;&#23646;&#20110;&#35813;&#31867;&#21035;&#12290;&#22312;&#27492;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#22240;&#26524;&#29983;&#21629;&#21608;&#26399;&#20013;&#19968;&#20123;&#26377;&#36259;&#30340;&#19981;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study causal inference and efficient estimation for the expected number of recurrent events in the presence of a terminal event. We define our estimand as the vector comprising both the expected number of recurrent events and the failure survival function evaluated along a sequence of landmark times. We identify the estimand in the presence of right-censoring and causal selection as an observed data functional under coarsening at random, derive the nonparametric efficiency bound, and propose a multiply-robust estimator that achieves the bound and permits nonparametric estimation of nuisance parameters. Throughout, no absolute continuity assumption is made on the underlying probability distributions of failure, censoring, or the observed data. Additionally, we derive the class of influence functions when the coarsening distribution is known and review how published estimators may belong to the class. Along the way, we highlight some interesting inconsistencies in the causal lifetime 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;Pareto Optimal&#33258;&#30417;&#30563;&#26694;&#26550;&#65292;&#21033;&#29992;&#21487;&#29992;&#30340;&#32534;&#31243;&#30417;&#30563;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#30340;&#21709;&#24212;&#36827;&#34892;&#31995;&#32479;&#26657;&#20934;&#65292;&#36890;&#36807;&#20026;&#27599;&#20010;&#21709;&#24212;&#29983;&#25104;&#39118;&#38505;&#35780;&#20998;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#30340;&#25163;&#21160;&#24037;&#20316;&#12290;</title><link>http://arxiv.org/abs/2306.16564</link><description>&lt;p&gt;
&#36890;&#36807;Pareto Optimal&#33258;&#30417;&#30563;&#23454;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33258;&#21160;&#26657;&#20934;&#21644;&#38169;&#35823;&#20462;&#27491;
&lt;/p&gt;
&lt;p&gt;
Automatic Calibration and Error Correction for Large Language Models via Pareto Optimal Self-Supervision. (arXiv:2306.16564v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16564
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;Pareto Optimal&#33258;&#30417;&#30563;&#26694;&#26550;&#65292;&#21033;&#29992;&#21487;&#29992;&#30340;&#32534;&#31243;&#30417;&#30563;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#30340;&#21709;&#24212;&#36827;&#34892;&#31995;&#32479;&#26657;&#20934;&#65292;&#36890;&#36807;&#20026;&#27599;&#20010;&#21709;&#24212;&#29983;&#25104;&#39118;&#38505;&#35780;&#20998;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#30340;&#25163;&#21160;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#24050;&#32463;&#23637;&#29616;&#20102;&#20986;&#33394;&#30340;&#33021;&#21147;&#65292;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#24212;&#29992;&#39046;&#22495;&#65292;&#20294;&#26159;&#20934;&#30830;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#22686;&#38271;&#39046;&#22495;&#65292;&#29305;&#21035;&#26159;&#22312;&#29983;&#29289;&#21307;&#23398;&#31561;&#20851;&#38190;&#39046;&#22495;&#12290;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26657;&#20934;LLM&#21709;&#24212;&#30340;&#32622;&#20449;&#27700;&#24179;&#65292;&#23545;&#20110;&#33258;&#21160;&#26816;&#27979;&#38169;&#35823;&#24182;&#20419;&#36827;&#20154;&#26426;&#21327;&#20316;&#39564;&#35777;&#33267;&#20851;&#37325;&#35201;&#12290;&#19968;&#20010;&#37325;&#35201;&#30340;&#26657;&#20934;&#20449;&#21495;&#26469;&#28304;&#26159;&#19987;&#23478;&#25351;&#23450;&#30340;&#32534;&#31243;&#30417;&#30563;&#65292;&#36890;&#24120;&#20855;&#26377;&#36739;&#20302;&#30340;&#25104;&#26412;&#65292;&#20294;&#20063;&#26377;&#20854;&#33258;&#36523;&#30340;&#23616;&#38480;&#24615;&#65292;&#22914;&#22122;&#22768;&#21644;&#35206;&#30422;&#33539;&#22260;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;Pareto Optimal&#33258;&#30417;&#30563;&#26694;&#26550;&#65292;&#21487;&#20197;&#21033;&#29992;&#21487;&#29992;&#30340;&#32534;&#31243;&#30417;&#30563;&#26469;&#31995;&#32479;&#22320;&#26657;&#20934;LLM&#21709;&#24212;&#65292;&#36890;&#36807;&#20026;&#27599;&#20010;&#21709;&#24212;&#29983;&#25104;&#39118;&#38505;&#35780;&#20998;&#65292;&#32780;&#19981;&#38656;&#35201;&#20219;&#20309;&#39069;&#22806;&#30340;&#25163;&#21160;&#24037;&#20316;&#12290;&#36825;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#35843;&#21644;&#27169;&#22411;&#26469;&#23454;&#29616;&#65292;&#23558;LLM&#36755;&#20986;&#19982;&#20854;&#20182;&#21487;&#29992;&#30340;&#30417;&#30563;&#26469;&#28304;&#30456;&#21327;&#35843;&#65292;&#23558;&#26356;&#19981;&#30830;&#23450;&#30340;&#21709;&#24212;&#20998;&#37197;&#26356;&#39640;&#30340;&#39118;&#38505;&#35780;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have demonstrated remarkable capabilities out of box for a wide range of applications, yet accuracy still remains a major growth area, especially in mission-critical domains such as biomedicine. An effective method to calibrate the confidence level on LLM responses is essential to automatically detect errors and facilitate human-in-the-loop verification. An important source of calibration signals stems from expert-stipulated programmatic supervision, which is often available at low cost but has its own limitations such as noise and coverage. In this paper, we introduce a Pareto optimal self-supervision framework that can leverage available programmatic supervision to systematically calibrate LLM responses by producing a risk score for every response, without any additional manual efforts. This is accomplished by learning a harmonizer model to align LLM output with other available supervision sources, which would assign higher risk scores to more uncertain L
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25216;&#26415;&#65292;&#31216;&#20026;UTOPIA&#65292;&#29992;&#20110;&#32858;&#21512;&#22810;&#20010;&#39044;&#27979;&#21306;&#38388;&#20197;&#20943;&#23567;&#20854;&#23485;&#24230;&#24182;&#20445;&#35777;&#35206;&#30422;&#29575;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#32447;&#24615;&#25110;&#20984;&#35268;&#21010;&#65292;&#26131;&#20110;&#23454;&#29616;&#65292;&#36866;&#29992;&#33539;&#22260;&#24191;&#27867;&#12290;</title><link>http://arxiv.org/abs/2306.16549</link><description>&lt;p&gt;
UTOPIA&#65306;&#36890;&#29992;&#21487;&#35757;&#32451;&#30340;&#26368;&#20248;&#39044;&#27979;&#21306;&#38388;&#32858;&#21512;
&lt;/p&gt;
&lt;p&gt;
UTOPIA: Universally Trainable Optimal Prediction Intervals Aggregation. (arXiv:2306.16549v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16549
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25216;&#26415;&#65292;&#31216;&#20026;UTOPIA&#65292;&#29992;&#20110;&#32858;&#21512;&#22810;&#20010;&#39044;&#27979;&#21306;&#38388;&#20197;&#20943;&#23567;&#20854;&#23485;&#24230;&#24182;&#20445;&#35777;&#35206;&#30422;&#29575;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#32447;&#24615;&#25110;&#20984;&#35268;&#21010;&#65292;&#26131;&#20110;&#23454;&#29616;&#65292;&#36866;&#29992;&#33539;&#22260;&#24191;&#27867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26159;&#19968;&#20010;&#26377;&#36259;&#30340;&#38382;&#39064;&#65292;&#22312;&#29983;&#29289;&#21307;&#23398;&#31185;&#23398;&#12289;&#32463;&#27982;&#30740;&#31350;&#21644;&#22825;&#27668;&#39044;&#25253;&#31561;&#21508;&#20010;&#39046;&#22495;&#26377;&#37325;&#35201;&#30340;&#24212;&#29992;&#12290;&#26500;&#24314;&#39044;&#27979;&#21306;&#38388;&#30340;&#26041;&#27861;&#26377;&#24456;&#22810;&#65292;&#22914;&#20998;&#20301;&#25968;&#22238;&#24402;&#21644;&#19968;&#33268;&#24615;&#39044;&#27979;&#31561;&#12290;&#28982;&#32780;&#65292;&#27169;&#22411;&#38169;&#35823;&#35268;&#23450;&#65288;&#23588;&#20854;&#26159;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65289;&#25110;&#27425;&#20248;&#30340;&#26500;&#36896;&#36890;&#24120;&#20250;&#23548;&#33268;&#26377;&#20559;&#25110;&#36807;&#23485;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#19988;&#24191;&#27867;&#36866;&#29992;&#30340;&#25216;&#26415;&#65292;&#29992;&#20110;&#32858;&#21512;&#22810;&#20010;&#39044;&#27979;&#21306;&#38388;&#20197;&#26368;&#23567;&#21270;&#39044;&#27979;&#24102;&#30340;&#24179;&#22343;&#23485;&#24230;&#21644;&#35206;&#30422;&#20445;&#35777;&#65292;&#31216;&#20026;&#36890;&#29992;&#21487;&#35757;&#32451;&#30340;&#26368;&#20248;&#39044;&#27979;&#21306;&#38388;&#32858;&#21512;&#65288;UTOPIA&#65289;&#12290;&#35813;&#26041;&#27861;&#36824;&#20801;&#35768;&#25105;&#20204;&#26681;&#25454;&#22522;&#26412;&#30340;&#22522;&#20989;&#25968;&#30452;&#25509;&#26500;&#24314;&#39044;&#27979;&#24102;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#32447;&#24615;&#25110;&#20984;&#35268;&#21010;&#65292;&#26131;&#20110;&#23454;&#29616;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#25152;&#26377;&#26041;&#27861;&#37117;&#24471;&#21040;&#20102;&#23454;&#39564;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty quantification for prediction is an intriguing problem with significant applications in various fields, such as biomedical science, economic studies, and weather forecasts. Numerous methods are available for constructing prediction intervals, such as quantile regression and conformal predictions, among others. Nevertheless, model misspecification (especially in high-dimension) or sub-optimal constructions can frequently result in biased or unnecessarily-wide prediction intervals. In this paper, we propose a novel and widely applicable technique for aggregating multiple prediction intervals to minimize the average width of the prediction band along with coverage guarantee, called Universally Trainable Optimal Predictive Intervals Aggregation (UTOPIA). The method also allows us to directly construct predictive bands based on elementary basis functions. Our approach is based on linear or convex programming which is easy to implement. All of our proposed methodologies are suppo
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21464;&#20998;&#19981;&#31561;&#24335;&#20013;&#30340;&#38543;&#26426;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#24314;&#31435;&#22823;&#25968;&#23450;&#24459;&#21644;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#25581;&#31034;&#20102;&#36825;&#20123;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#36136;&#65292;&#23545;&#20110;&#24191;&#27867;&#30340;VIP&#38382;&#39064;&#65292;&#24179;&#22343;&#36845;&#20195;&#25910;&#25947;&#21040;&#19968;&#20010;&#21807;&#19968;&#30340;&#19981;&#21464;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2306.16502</link><description>&lt;p&gt;
&#21464;&#20998;&#19981;&#31561;&#24335;&#20013;&#30340;&#38543;&#26426;&#26041;&#27861;&#65306;&#36941;&#21382;&#24615;&#12289;&#20559;&#24046;&#19982;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
Stochastic Methods in Variational Inequalities: Ergodicity, Bias and Refinements. (arXiv:2306.16502v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16502
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21464;&#20998;&#19981;&#31561;&#24335;&#20013;&#30340;&#38543;&#26426;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#24314;&#31435;&#22823;&#25968;&#23450;&#24459;&#21644;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#25581;&#31034;&#20102;&#36825;&#20123;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#36136;&#65292;&#23545;&#20110;&#24191;&#27867;&#30340;VIP&#38382;&#39064;&#65292;&#24179;&#22343;&#36845;&#20195;&#25910;&#25947;&#21040;&#19968;&#20010;&#21807;&#19968;&#30340;&#19981;&#21464;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#36935;&#21040;&#30340;min-max&#20248;&#21270;&#21644;&#21464;&#20998;&#19981;&#31561;&#24335;&#38382;&#39064;(VIP)&#65292;&#38543;&#26426;&#22806;&#25512;&#26799;&#24230;(SEG)&#21644;&#38543;&#26426;&#26799;&#24230;&#19978;&#21319;&#19979;&#38477;(SGDA)&#31639;&#27861;&#24050;&#25104;&#20026;&#26480;&#20986;&#30340;&#31639;&#27861;&#12290;SEG/SGDA&#30340;&#24658;&#23450;&#27493;&#38271;&#21464;&#31181;&#24191;&#21463;&#27426;&#36814;&#65292;&#20855;&#26377;&#26131;&#20110;&#35843;&#33410;&#21644;&#21407;&#22987;&#26465;&#20214;&#36805;&#36895;&#36866;&#24212;&#30340;&#20248;&#28857;&#65292;&#20294;&#21363;&#20351;&#22312;&#22522;&#26412;&#30340;&#21452;&#32447;&#24615;&#27169;&#22411;&#20013;&#65292;&#23427;&#20204;&#30340;&#25910;&#25947;&#34892;&#20026;&#20063;&#26356;&#21152;&#22797;&#26434;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#26088;&#22312;&#38416;&#26126;&#21644;&#37327;&#21270;&#36825;&#20123;&#31639;&#27861;&#20869;&#22312;&#30340;&#27010;&#29575;&#32467;&#26500;&#12290;&#36890;&#36807;&#23558;&#24658;&#23450;&#27493;&#38271;SEG/SGDA&#37325;&#26032;&#26500;&#36896;&#20026;&#26102;&#38388;&#40784;&#27425;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#39318;&#20010;&#22823;&#25968;&#23450;&#24459;&#21644;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65292;&#35777;&#26126;&#20102;&#22312;&#24191;&#27867;&#30340;&#21333;&#35843;&#21644;&#38750;&#21333;&#35843;VIP&#24773;&#20917;&#19979;&#65292;&#24179;&#22343;&#36845;&#20195;&#25910;&#25947;&#21040;&#19968;&#20010;&#21807;&#19968;&#30340;&#19981;&#21464;&#20998;&#24067;&#12290;&#29305;&#21035;&#26159;&#23545;&#20110;&#20984;&#20985;min-max&#20248;&#21270;&#65292;&#25105;&#20204;&#21051;&#30011;&#20102;&#36830;&#25509;VIP&#21644;&#20248;&#21270;&#20559;&#24046;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
For min-max optimization and variational inequalities problems (VIP) encountered in diverse machine learning tasks, Stochastic Extragradient (SEG) and Stochastic Gradient Descent Ascent (SGDA) have emerged as preeminent algorithms. Constant step-size variants of SEG/SGDA have gained popularity, with appealing benefits such as easy tuning and rapid forgiveness of initial conditions, but their convergence behaviors are more complicated even in rudimentary bilinear models. Our work endeavors to elucidate and quantify the probabilistic structures intrinsic to these algorithms. By recasting the constant step-size SEG/SGDA as time-homogeneous Markov Chains, we establish a first-of-its-kind Law of Large Numbers and a Central Limit Theorem, demonstrating that the average iterate is asymptotically normal with a unique invariant distribution for an extensive range of monotone and non-monotone VIPs. Specializing to convex-concave min-max optimization, we characterize the relationship between the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#26816;&#27979;&#37329;&#34701;&#24066;&#22330;&#20013;&#30340;&#26080;&#27169;&#22411;&#38745;&#24577;&#22871;&#21033;&#26426;&#20250;&#65292;&#24182;&#21487;&#24212;&#29992;&#20110;&#20132;&#26131;&#35777;&#21048;&#25968;&#37327;&#36739;&#22810;&#30340;&#37329;&#34701;&#24066;&#22330;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#26131;&#22788;&#29702;&#24615;&#12289;&#26377;&#25928;&#24615;&#21644;&#31283;&#20581;&#24615;&#65292;&#24182;&#20351;&#29992;&#30495;&#23454;&#37329;&#34701;&#25968;&#25454;&#36827;&#34892;&#20102;&#31034;&#20363;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.16422</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#26816;&#27979;&#26080;&#27169;&#22411;&#38745;&#24577;&#22871;&#21033;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Neural networks can detect model-free static arbitrage strategies. (arXiv:2306.16422v1 [q-fin.CP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16422
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#26816;&#27979;&#37329;&#34701;&#24066;&#22330;&#20013;&#30340;&#26080;&#27169;&#22411;&#38745;&#24577;&#22871;&#21033;&#26426;&#20250;&#65292;&#24182;&#21487;&#24212;&#29992;&#20110;&#20132;&#26131;&#35777;&#21048;&#25968;&#37327;&#36739;&#22810;&#30340;&#37329;&#34701;&#24066;&#22330;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#26131;&#22788;&#29702;&#24615;&#12289;&#26377;&#25928;&#24615;&#21644;&#31283;&#20581;&#24615;&#65292;&#24182;&#20351;&#29992;&#30495;&#23454;&#37329;&#34701;&#25968;&#25454;&#36827;&#34892;&#20102;&#31034;&#20363;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#29702;&#35770;&#21644;&#25968;&#20540;&#26041;&#27861;&#35777;&#26126;&#20102;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#22312;&#24066;&#22330;&#23384;&#22312;&#22871;&#21033;&#26426;&#20250;&#26102;&#26816;&#27979;&#20986;&#26080;&#27169;&#22411;&#38745;&#24577;&#22871;&#21033;&#26426;&#20250;&#12290;&#30001;&#20110;&#20351;&#29992;&#20102;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#20132;&#26131;&#35777;&#21048;&#25968;&#37327;&#36739;&#22810;&#30340;&#37329;&#34701;&#24066;&#22330;&#65292;&#24182;&#30830;&#20445;&#30456;&#24212;&#20132;&#26131;&#31574;&#30053;&#30340;&#20960;&#20046;&#21363;&#26102;&#25191;&#34892;&#12290;&#20026;&#20102;&#35777;&#26126;&#20854;&#26131;&#22788;&#29702;&#24615;&#12289;&#26377;&#25928;&#24615;&#21644;&#31283;&#20581;&#24615;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20351;&#29992;&#30495;&#23454;&#37329;&#34701;&#25968;&#25454;&#30340;&#31034;&#20363;&#12290;&#20174;&#25216;&#26415;&#35282;&#24230;&#26469;&#30475;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21333;&#20010;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#36817;&#20284;&#35299;&#20915;&#19968;&#31867;&#20984;&#21322;&#26080;&#38480;&#35268;&#21010;&#38382;&#39064;&#65292;&#36825;&#26159;&#25512;&#23548;&#20986;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#30340;&#20851;&#38190;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we demonstrate both theoretically as well as numerically that neural networks can detect model-free static arbitrage opportunities whenever the market admits some. Due to the use of neural networks, our method can be applied to financial markets with a high number of traded securities and ensures almost immediate execution of the corresponding trading strategies. To demonstrate its tractability, effectiveness, and robustness we provide examples using real financial data. From a technical point of view, we prove that a single neural network can approximately solve a class of convex semi-infinite programs, which is the key result in order to derive our theoretical results that neural networks can detect model-free static arbitrage strategies whenever the financial market admits such opportunities.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36890;&#29992;&#30340;&#25968;&#25454;&#38598;&#36716;&#31227;&#26465;&#20214;&#19979;&#65292;&#21033;&#29992;&#21322;&#21442;&#25968;&#25928;&#29575;&#29702;&#35770;&#65292;&#39640;&#25928;&#20272;&#35745;&#30446;&#26631;&#24635;&#20307;&#39118;&#38505;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.16406</link><description>&lt;p&gt;
&#36890;&#29992;&#24418;&#24335;&#19979;&#30340;&#39640;&#25928;&#19988;&#22810;&#37325;&#31283;&#20581;&#30340;&#39118;&#38505;&#20272;&#35745;&#26041;&#27861;&#22312;&#25968;&#25454;&#36716;&#31227;&#20013;
&lt;/p&gt;
&lt;p&gt;
Efficient and Multiply Robust Risk Estimation under General Forms of Dataset Shift. (arXiv:2306.16406v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16406
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36890;&#29992;&#30340;&#25968;&#25454;&#38598;&#36716;&#31227;&#26465;&#20214;&#19979;&#65292;&#21033;&#29992;&#21322;&#21442;&#25968;&#25928;&#29575;&#29702;&#35770;&#65292;&#39640;&#25928;&#20272;&#35745;&#30446;&#26631;&#24635;&#20307;&#39118;&#38505;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32479;&#35745;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#32463;&#24120;&#38754;&#20020;&#26469;&#33258;&#24863;&#20852;&#36259;&#24635;&#20307;&#30340;&#26377;&#38480;&#25968;&#25454;&#30340;&#25361;&#25112;&#12290;&#19968;&#31181;&#35299;&#20915;&#26041;&#27861;&#26159;&#21033;&#29992;&#26469;&#33258;&#36741;&#21161;&#28304;&#24635;&#20307;&#30340;&#25968;&#25454;&#65292;&#36825;&#20123;&#25968;&#25454;&#19982;&#30446;&#26631;&#39046;&#22495;&#30340;&#26576;&#20123;&#26465;&#20214;&#20998;&#24067;&#30456;&#21516;&#25110;&#20197;&#20854;&#20182;&#26041;&#24335;&#30456;&#36830;&#12290;&#21033;&#29992;&#36825;&#31181;"&#25968;&#25454;&#36716;&#31227;"&#26465;&#20214;&#30340;&#25216;&#26415;&#34987;&#31216;&#20026;"&#39046;&#22495;&#36866;&#24212;"&#25110;"&#36801;&#31227;&#23398;&#20064;"&#12290;&#23613;&#31649;&#26377;&#22823;&#37327;&#20851;&#20110;&#25968;&#25454;&#36716;&#31227;&#30340;&#25991;&#29486;&#65292;&#20294;&#24456;&#23569;&#26377;&#30740;&#31350;&#25506;&#35752;&#22914;&#20309;&#26377;&#25928;&#21033;&#29992;&#36741;&#21161;&#24635;&#20307;&#26469;&#25552;&#39640;&#30446;&#26631;&#24635;&#20307;&#19978;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#39118;&#38505;&#35780;&#20272;&#30340;&#20934;&#30830;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#21322;&#21442;&#25968;&#25928;&#29575;&#29702;&#35770;&#30740;&#31350;&#20102;&#22312;&#19981;&#21516;&#30340;&#25968;&#25454;&#38598;&#36716;&#31227;&#26465;&#20214;&#19979;&#39640;&#25928;&#20272;&#35745;&#30446;&#26631;&#24635;&#20307;&#39118;&#38505;&#30340;&#19968;&#33324;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31867;&#36890;&#29992;&#30340;&#25968;&#25454;&#38598;&#36716;&#31227;&#26465;&#20214;&#65292;&#20854;&#20013;&#21253;&#25324;&#19977;&#31181;&#27969;&#34892;&#26465;&#20214;&#8212;&#8212;&#21327;&#21464;&#37327;&#12289;&#26631;&#31614;&#21644;&#27010;&#24565;&#36716;&#31227;&#8212;&#8212;&#20316;&#20026;&#29305;&#20363;&#12290;&#25105;&#20204;&#20801;&#35768;&#37096;&#20998;&#38750;&#37325;&#21472;&#12290;
&lt;/p&gt;
&lt;p&gt;
Statistical machine learning methods often face the challenge of limited data available from the population of interest. One remedy is to leverage data from auxiliary source populations, which share some conditional distributions or are linked in other ways with the target domain. Techniques leveraging such \emph{dataset shift} conditions are known as \emph{domain adaptation} or \emph{transfer learning}. Despite extensive literature on dataset shift, limited works address how to efficiently use the auxiliary populations to improve the accuracy of risk evaluation for a given machine learning task in the target population.  In this paper, we study the general problem of efficiently estimating target population risk under various dataset shift conditions, leveraging semiparametric efficiency theory. We consider a general class of dataset shift conditions, which includes three popular conditions -- covariate, label and concept shift -- as special cases. We allow for partially non-overlappi
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26080;&#20284;&#28982;&#36125;&#21494;&#26031;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#26500;&#24314;&#39640;&#25928;&#30340;&#25130;&#23614;&#36229;&#38408;&#20540;&#27169;&#22411;&#20272;&#35745;&#22120;&#12290;&#35813;&#26041;&#27861;&#25361;&#25112;&#20102;&#20256;&#32479;&#30340;&#22522;&#20110;&#25130;&#23614;&#20284;&#28982;&#30340;&#31354;&#38388;&#26497;&#20540;&#25512;&#29702;&#65292;&#24182;&#22312;&#35745;&#31639;&#21644;&#32479;&#35745;&#25928;&#29575;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2306.15642</link><description>&lt;p&gt;
&#26080;&#20284;&#28982;&#31070;&#32463;&#36125;&#21494;&#26031;&#20272;&#35745;&#30340;&#25130;&#23614;&#36229;&#38408;&#20540;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Likelihood-free neural Bayes estimators for censored peaks-over-threshold models. (arXiv:2306.15642v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15642
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26080;&#20284;&#28982;&#36125;&#21494;&#26031;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#26500;&#24314;&#39640;&#25928;&#30340;&#25130;&#23614;&#36229;&#38408;&#20540;&#27169;&#22411;&#20272;&#35745;&#22120;&#12290;&#35813;&#26041;&#27861;&#25361;&#25112;&#20102;&#20256;&#32479;&#30340;&#22522;&#20110;&#25130;&#23614;&#20284;&#28982;&#30340;&#31354;&#38388;&#26497;&#20540;&#25512;&#29702;&#65292;&#24182;&#22312;&#35745;&#31639;&#21644;&#32479;&#35745;&#25928;&#29575;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#24230;&#19979;&#65292;&#23545;&#20110;&#31354;&#38388;&#26497;&#20540;&#20381;&#36182;&#27169;&#22411;&#30340;&#25512;&#29702;&#24448;&#24448;&#22240;&#20854;&#20381;&#36182;&#20110;&#38590;&#20197;&#22788;&#29702;&#30340;&#25110;&#25130;&#23614;&#30340;&#20284;&#28982;&#20989;&#25968;&#32780;&#36896;&#25104;&#35745;&#31639;&#36127;&#25285;&#12290;&#21033;&#29992;&#26368;&#36817;&#22312;&#26080;&#20284;&#28982;&#25512;&#29702;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#20013;&#32534;&#30721;&#25130;&#23614;&#20449;&#24687;&#65292;&#20026;&#25130;&#23614;&#36229;&#38408;&#20540;&#27169;&#22411;&#26500;&#24314;&#20102;&#39640;&#25928;&#30340;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#30340;&#26032;&#26041;&#27861;&#23545;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#25130;&#23614;&#20284;&#28982;&#30340;&#31354;&#38388;&#26497;&#20540;&#25512;&#29702;&#25552;&#20986;&#20102;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#27169;&#25311;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#25512;&#26029;&#27969;&#34892;&#30340;&#26497;&#20540;&#20381;&#36182;&#27169;&#22411;&#65288;&#22914;&#26368;&#22823;&#31283;&#23450;&#27169;&#22411;&#12289;r-&#24085;&#32047;&#25176;&#27169;&#22411;&#21644;&#38543;&#26426;&#27604;&#20363;&#28151;&#21512;&#36807;&#31243;&#65289;&#26102;&#65292;&#30456;&#23545;&#20110;&#31454;&#20105;&#30340;&#22522;&#20110;&#20284;&#28982;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26032;&#20272;&#35745;&#22120;&#22312;&#35745;&#31639;&#21644;&#32479;&#35745;&#25928;&#29575;&#26041;&#38754;&#25552;&#20379;&#20102;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inference for spatial extremal dependence models can be computationally burdensome in moderate-to-high dimensions due to their reliance on intractable and/or censored likelihoods. Exploiting recent advances in likelihood-free inference with neural Bayes estimators (that is, neural estimators that target Bayes estimators), we develop a novel approach to construct highly efficient estimators for censored peaks-over-threshold models by encoding censoring information in the neural network architecture. Our new method provides a paradigm shift that challenges traditional censored likelihood-based inference for spatial extremes. Our simulation studies highlight significant gains in both computational and statistical efficiency, relative to competing likelihood-based approaches, when applying our novel estimators for inference of popular extremal dependence models, such as max-stable, $r$-Pareto, and random scale mixture processes. We also illustrate that it is possible to train a single esti
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36817;&#20284;&#39640;&#26031;&#28388;&#27874;&#21644;&#24179;&#28369;&#26041;&#27861;&#65292;&#23427;&#23558;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20302;&#31209;&#36817;&#20284;&#20256;&#25773;&#65292;&#36890;&#36807;&#23558;Lyapunov&#26041;&#31243;&#25237;&#24433;&#21040;&#20302;&#31209;&#30697;&#38453;&#30340;&#27969;&#24418;&#19978;&#65292;&#20351;&#29992;&#25968;&#20540;&#31283;&#23450;&#30340;&#21160;&#24577;&#20302;&#31209;&#31215;&#20998;&#22120;&#27714;&#35299;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2306.07774</link><description>&lt;p&gt;
&#38477;&#31209;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65306;&#22312;&#39640;&#32500;&#20013;&#36827;&#34892;&#36817;&#20284;&#20302;&#31209;&#21160;&#24577;&#28388;&#27874;
&lt;/p&gt;
&lt;p&gt;
The Rank-Reduced Kalman Filter: Approximate Dynamical-Low-Rank Filtering In High Dimensions. (arXiv:2306.07774v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07774
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36817;&#20284;&#39640;&#26031;&#28388;&#27874;&#21644;&#24179;&#28369;&#26041;&#27861;&#65292;&#23427;&#23558;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20302;&#31209;&#36817;&#20284;&#20256;&#25773;&#65292;&#36890;&#36807;&#23558;Lyapunov&#26041;&#31243;&#25237;&#24433;&#21040;&#20302;&#31209;&#30697;&#38453;&#30340;&#27969;&#24418;&#19978;&#65292;&#20351;&#29992;&#25968;&#20540;&#31283;&#23450;&#30340;&#21160;&#24577;&#20302;&#31209;&#31215;&#20998;&#22120;&#27714;&#35299;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#21160;&#24577;&#31995;&#32479;&#30340;&#25512;&#26029;&#21644;&#27169;&#25311;&#20013;&#65292;&#38656;&#35201;&#36827;&#34892;&#26576;&#31181;&#24418;&#24335;&#30340;&#38477;&#32500;&#25165;&#33021;&#20351;&#38382;&#39064;&#20855;&#26377;&#21487;&#22788;&#29702;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36817;&#20284;&#39640;&#26031;&#28388;&#27874;&#21644;&#24179;&#28369;&#26041;&#27861;&#65292;&#23427;&#23558;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20302;&#31209;&#36817;&#20284;&#20256;&#25773;&#12290;&#36825;&#26159;&#36890;&#36807;&#23558;&#39044;&#27979;&#27493;&#39588;&#30456;&#20851;&#30340;Lyapunov&#26041;&#31243;&#25237;&#24433;&#21040;&#20302;&#31209;&#30697;&#38453;&#30340;&#27969;&#24418;&#19978;&#26469;&#23454;&#29616;&#30340;&#65292;&#28982;&#21518;&#36890;&#36807;&#26368;&#36817;&#24320;&#21457;&#30340;&#25968;&#20540;&#31283;&#23450;&#12289;&#21160;&#24577;&#20302;&#31209;&#31215;&#20998;&#22120;&#27714;&#35299;&#36825;&#20123;&#26041;&#31243;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#36890;&#36807;&#27880;&#24847;&#21327;&#26041;&#24046;&#26356;&#26032;&#20165;&#36716;&#25442;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#21015;&#31354;&#38388;&#65292;&#32780;&#35813;&#31354;&#38388;&#30001;&#26500;&#36896;&#24471;&#21040;&#65292;&#20174;&#32780;&#20351;&#26356;&#26032;&#27493;&#39588;&#20855;&#26377;&#21487;&#22788;&#29702;&#24615;&#12290;&#31639;&#27861;&#19982;&#29616;&#26377;&#30340;&#22522;&#20110;&#38598;&#21512;&#30340;&#26041;&#27861;&#19981;&#21516;&#20043;&#22788;&#22312;&#20110;&#65292;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20302;&#31209;&#36817;&#20284;&#26159;&#30830;&#23450;&#24615;&#30340;&#65292;&#32780;&#19981;&#26159;&#38543;&#26426;&#30340;&#12290;&#20851;&#38190;&#22312;&#20110;&#65292;&#36825;&#20351;&#24471;&#35813;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inference and simulation in the context of high-dimensional dynamical systems remain computationally challenging problems. Some form of dimensionality reduction is required to make the problem tractable in general. In this paper, we propose a novel approximate Gaussian filtering and smoothing method which propagates low-rank approximations of the covariance matrices. This is accomplished by projecting the Lyapunov equations associated with the prediction step to a manifold of low-rank matrices, which are then solved by a recently developed, numerically stable, dynamical low-rank integrator. Meanwhile, the update steps are made tractable by noting that the covariance update only transforms the column space of the covariance matrix, which is low-rank by construction. The algorithm differentiates itself from existing ensemble-based approaches in that the low-rank approximations of the covariance matrices are deterministic, rather than stochastic. Crucially, this enables the method to repr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20165;&#38656;&#35201;&#24456;&#23569;&#30340;&#26679;&#26412;&#19988;&#33021;&#22815;&#23545;&#26435;&#37325;&#21644;&#22343;&#20540;&#36827;&#34892;&#20934;&#30830;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2305.04127</link><description>&lt;p&gt;
&#20351;&#29992;&#25130;&#26029;&#25968;&#25454;&#23398;&#20064;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning Mixtures of Gaussians with Censored Data. (arXiv:2305.04127v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04127
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20165;&#38656;&#35201;&#24456;&#23569;&#30340;&#26679;&#26412;&#19988;&#33021;&#22815;&#23545;&#26435;&#37325;&#21644;&#22343;&#20540;&#36827;&#34892;&#20934;&#30830;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20855;&#26377;&#25130;&#26029;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#23398;&#20064;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#38382;&#39064;&#12290;&#21363;&#20174;&#19968;&#20010;&#28151;&#21512;&#21333;&#21464;&#37327;&#39640;&#26031;&#20998;&#24067;$\sum_{i=1}^k w_i \mathcal{N}(\mu_i,\sigma^2)$&#20013;&#35266;&#27979;&#21040;&#30340;&#26679;&#26412;&#21482;&#26377;&#24403;&#20854;&#20301;&#20110;$S$&#38598;&#21512;&#20869;&#26102;&#25165;&#20250;&#34987;&#35266;&#23519;&#21040;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#20165;&#38656;&#35201;$\frac{1}{\varepsilon^{O(k)}}$&#20010;&#26679;&#26412;&#21363;&#21487;&#22312;$\varepsilon$&#35823;&#24046;&#20869;&#20272;&#35745;&#26435;&#37325;$w_i$&#21644;&#22343;&#20540;$\mu_i$&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of learning mixtures of Gaussians with censored data. Statistical learning with censored data is a classical problem, with numerous practical applications, however, finite-sample guarantees for even simple latent variable models such as Gaussian mixtures are missing. Formally, we are given censored data from a mixture of univariate Gaussians $$\sum_{i=1}^k w_i \mathcal{N}(\mu_i,\sigma^2),$$ i.e. the sample is observed only if it lies inside a set $S$. The goal is to learn the weights $w_i$ and the means $\mu_i$. We propose an algorithm that takes only $\frac{1}{\varepsilon^{O(k)}}$ samples to estimate the weights $w_i$ and the means $\mu_i$ within $\varepsilon$ error.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#19979;&#35299;&#20915;convex-concave Lipschitz&#38543;&#26426;Saddle Point&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#28385;&#36275;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#26368;&#20339;&#36895;&#29575;&#21644;&#26799;&#24230;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2302.12909</link><description>&lt;p&gt;
&#20855;&#26377;&#26368;&#20339;&#36895;&#29575;&#30340;&#20855;&#26377;&#24378;&#38388;&#38553;&#30340;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;Saddle Point&#38382;&#39064;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Algorithms for the Stochastic Saddle Point Problem with Optimal Rates for the Strong Gap. (arXiv:2302.12909v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.12909
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#19979;&#35299;&#20915;convex-concave Lipschitz&#38543;&#26426;Saddle Point&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#28385;&#36275;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#26368;&#20339;&#36895;&#29575;&#21644;&#26799;&#24230;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;$(\epsilon,\delta)$-&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#19979;&#65292;&#20984;&#20985;Lipschitz&#38543;&#26426;Saddle Point&#38382;&#39064;&#65288;&#20063;&#31216;&#20026;&#38543;&#26426;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#65289;&#21487;&#20197;&#34987;&#35299;&#20915;&#65292;&#20854;&#20855;&#26377;&#24378;&#65288;&#21407;&#22987;-&#23545;&#20598;&#65289;&#38388;&#38553;&#29575;&#20026;$\tilde O\big(\frac{1}{\sqrt{n}} + \frac{\sqrt{d}}{n\epsilon}\big)$&#65292;&#20854;&#20013;$n$&#20026;&#25968;&#25454;&#38598;&#22823;&#23567;&#65292;$d$&#20026;&#38382;&#39064;&#32500;&#24230;&#12290;&#26681;&#25454;&#29616;&#26377;&#30340;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#20248;&#21270;&#30340;&#19979;&#30028;&#65292;&#35813;&#36895;&#29575;&#20960;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#36890;&#36807;&#37325;&#26032;&#35774;&#35745;&#24182;&#20998;&#26512;&#36866;&#29992;&#20110;Saddle Point&#38382;&#39064;&#30340;&#36882;&#24402;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#35777;&#26126;&#20102;&#24378;&#38388;&#38553;&#30340;&#32039;&#23494;&#19978;&#30028;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#36895;&#29575;&#21487;&#20197;&#22312;$O\big(\min\big\{\frac{n^2\epsilon^{1.5}}{\sqrt{d}}, n^{3/2}\big\}\big)$&#30340;&#26799;&#24230;&#22797;&#26434;&#24230;&#20197;&#21450;&#22312;&#25439;&#22833;&#20989;&#25968;&#20809;&#28369;&#30340;&#24773;&#20917;&#19979;&#65292;$\tilde{O}(n)$&#30340;&#26799;&#24230;&#22797;&#26434;&#24230;&#19979;&#23454;&#29616;&#12290;&#20316;&#20026;&#25105;&#20204;&#26041;&#27861;&#30340;&#21103;&#20135;&#21697;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#36890;&#29992;&#31639;&#27861;&#65292;&#32473;&#23450;&#40657;&#30418;&#35775;&#38382;&#19968;&#20010;&#28385;&#36275;&#26465;&#20214;&#30340;&#23376;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show that convex-concave Lipschitz stochastic saddle point problems (also known as stochastic minimax optimization) can be solved under the constraint of $(\epsilon,\delta)$-differential privacy with \emph{strong (primal-dual) gap} rate of $\tilde O\big(\frac{1}{\sqrt{n}} + \frac{\sqrt{d}}{n\epsilon}\big)$, where $n$ is the dataset size and $d$ is the dimension of the problem. This rate is nearly optimal, based on existing lower bounds in differentially private stochastic optimization. Specifically, we prove a tight upper bound on the strong gap via novel implementation and analysis of the recursive regularization technique repurposed for saddle point problems. We show that this rate can be attained with $O\big(\min\big\{\frac{n^2\epsilon^{1.5}}{\sqrt{d}}, n^{3/2}\big\}\big)$ gradient complexity, and $\tilde{O}(n)$ gradient complexity if the loss function is smooth. As a byproduct of our method, we develop a general algorithm that, given a black-box access to a subroutine satisfying
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#25968;&#25454;&#27745;&#26579;&#30340;&#26102;&#24207;&#23041;&#32961;&#27169;&#22411;&#65292;&#36890;&#36807;&#21033;&#29992;&#25968;&#25454;&#30340;&#26102;&#38388;&#25139;&#65292;&#24341;&#20837;&#20102;&#25552;&#21069;&#26102;&#38388;&#21644;&#25345;&#32493;&#26102;&#38388;&#36825;&#20004;&#20010;&#25351;&#26631;&#65292;&#20174;&#32780;&#23450;&#20041;&#20102;&#25968;&#25454;&#27745;&#26579;&#30340;&#26102;&#24207;&#40065;&#26834;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#20445;&#25252;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2302.03684</link><description>&lt;p&gt;
&#25968;&#25454;&#27745;&#26579;&#20013;&#30340;&#26102;&#24207;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Temporal Robustness against Data Poisoning. (arXiv:2302.03684v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03684
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#25968;&#25454;&#27745;&#26579;&#30340;&#26102;&#24207;&#23041;&#32961;&#27169;&#22411;&#65292;&#36890;&#36807;&#21033;&#29992;&#25968;&#25454;&#30340;&#26102;&#38388;&#25139;&#65292;&#24341;&#20837;&#20102;&#25552;&#21069;&#26102;&#38388;&#21644;&#25345;&#32493;&#26102;&#38388;&#36825;&#20004;&#20010;&#25351;&#26631;&#65292;&#20174;&#32780;&#23450;&#20041;&#20102;&#25968;&#25454;&#27745;&#26579;&#30340;&#26102;&#24207;&#40065;&#26834;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#20445;&#25252;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#27745;&#26579;&#32771;&#34385;&#20102;&#36890;&#36807;&#24694;&#24847;&#35757;&#32451;&#25968;&#25454;&#25805;&#32437;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#34892;&#20026;&#30340;&#24773;&#20917;&#12290;&#29616;&#26377;&#30340;&#25968;&#25454;&#27745;&#26579;&#23041;&#32961;&#27169;&#22411;&#37117;&#22260;&#32469;&#30528;&#19968;&#20010;&#21333;&#19968;&#25351;&#26631;&#65292;&#21363;&#34987;&#27745;&#26579;&#26679;&#26412;&#30340;&#25968;&#37327;&#12290;&#22240;&#27492;&#65292;&#22914;&#26524;&#25915;&#20987;&#32773;&#33021;&#22815;&#20197;&#21487;&#25215;&#21463;&#30340;&#20195;&#20215;&#27745;&#26579;&#27604;&#39044;&#26399;&#26356;&#22810;&#30340;&#26679;&#26412;&#65292;&#23601;&#20687;&#35768;&#22810;&#23454;&#38469;&#22330;&#26223;&#20013;&#19968;&#26679;&#65292;&#20182;&#20204;&#21487;&#33021;&#33021;&#22815;&#22312;&#24456;&#30701;&#30340;&#26102;&#38388;&#20869;&#20351;&#29616;&#26377;&#30340;&#38450;&#24481;&#25514;&#26045;&#22833;&#25928;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#21033;&#29992;&#25968;&#25454;&#30340;&#20986;&#29983;&#26085;&#26399;&#26102;&#38388;&#25139;&#65292;&#36825;&#20123;&#26102;&#38388;&#25139;&#36890;&#24120;&#26159;&#21487;&#29992;&#30340;&#20294;&#36807;&#21435;&#34987;&#24573;&#30053;&#12290;&#21033;&#29992;&#36825;&#20123;&#26102;&#38388;&#25139;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#24102;&#26377;&#20004;&#20010;&#26032;&#22411;&#25351;&#26631;&#65288;&#25552;&#21069;&#26102;&#38388;&#21644;&#25345;&#32493;&#26102;&#38388;&#65289;&#30340;&#25968;&#25454;&#27745;&#26579;&#30340;&#26102;&#24207;&#23041;&#32961;&#27169;&#22411;&#65292;&#20998;&#21035;&#34913;&#37327;&#25915;&#20987;&#25552;&#21069;&#24320;&#22987;&#30340;&#26102;&#38388;&#21644;&#25915;&#20987;&#25345;&#32493;&#30340;&#26102;&#38388;&#12290;&#21033;&#29992;&#36825;&#20123;&#25351;&#26631;&#65292;&#25105;&#20204;&#23450;&#20041;&#20102;&#25968;&#25454;&#27745;&#26579;&#30340;&#26102;&#24207;&#40065;&#26834;&#24615;&#30340;&#27010;&#24565;&#65292;&#21363;&#20351;&#26377;&#22823;&#37327;&#34987;&#27745;&#26579;&#30340;&#26679;&#26412;&#65292;&#20063;&#33021;&#25552;&#20379;&#26377;&#24847;&#20041;&#30340;&#20445;&#25252;&#12290;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Data poisoning considers cases when an adversary manipulates the behavior of machine learning algorithms through malicious training data. Existing threat models of data poisoning center around a single metric, the number of poisoned samples. In consequence, if attackers can poison more samples than expected with affordable overhead, as in many practical scenarios, they may be able to render existing defenses ineffective in a short time. To address this issue, we leverage timestamps denoting the birth dates of data, which are often available but neglected in the past. Benefiting from these timestamps, we propose a temporal threat model of data poisoning with two novel metrics, earliness and duration, which respectively measure how long an attack started in advance and how long an attack lasted. Using these metrics, we define the notions of temporal robustness against data poisoning, providing a meaningful sense of protection even with unbounded amounts of poisoned samples. We present a 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#26377;&#25439;&#22270;&#20687;&#21387;&#32553;&#30340;&#20248;&#21270;&#26694;&#26550;&#12290;&#36890;&#36807;&#24341;&#20837;&#39069;&#22806;&#30340;&#20869;&#23481;&#28508;&#21464;&#37327;&#20197;&#21450;&#21512;&#25104;&#32441;&#29702;&#21464;&#37327;&#65292;&#35813;&#26041;&#27861;&#22312;&#22270;&#20687;&#36136;&#37327;&#35780;&#20272;&#25351;&#26631;&#19978;&#34920;&#29616;&#20986;&#26356;&#24378;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2209.06950</link><description>&lt;p&gt;
&#22522;&#20110;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#30340;&#26377;&#25439;&#22270;&#20687;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
Lossy Image Compression with Conditional Diffusion Models. (arXiv:2209.06950v5 [eess.IV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.06950
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#26377;&#25439;&#22270;&#20687;&#21387;&#32553;&#30340;&#20248;&#21270;&#26694;&#26550;&#12290;&#36890;&#36807;&#24341;&#20837;&#39069;&#22806;&#30340;&#20869;&#23481;&#28508;&#21464;&#37327;&#20197;&#21450;&#21512;&#25104;&#32441;&#29702;&#21464;&#37327;&#65292;&#35813;&#26041;&#27861;&#22312;&#22270;&#20687;&#36136;&#37327;&#35780;&#20272;&#25351;&#26631;&#19978;&#34920;&#29616;&#20986;&#26356;&#24378;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#30340;&#31471;&#21040;&#31471;&#20248;&#21270;&#30340;&#26377;&#25439;&#22270;&#20687;&#21387;&#32553;&#26694;&#26550;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#21464;&#25442;&#32534;&#30721;&#33539;&#24335;&#65292;&#23558;&#22270;&#20687;&#26144;&#23556;&#21040;&#28508;&#22312;&#31354;&#38388;&#36827;&#34892;&#20449;&#24687;&#29109;&#32534;&#30721;&#65292;&#28982;&#21518;&#20877;&#26144;&#23556;&#22238;&#25968;&#25454;&#31354;&#38388;&#36827;&#34892;&#37325;&#26500;&#12290;&#19982;&#22522;&#20110;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;(VAE)&#30340;&#31070;&#32463;&#21387;&#32553;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#35299;&#30721;&#22120;&#26159;&#19968;&#20010;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24341;&#20837;&#20102;&#19968;&#20010;&#39069;&#22806;&#30340;&#8220;&#20869;&#23481;&#8221;&#28508;&#21464;&#37327;&#65292;&#21453;&#21521;&#25193;&#25955;&#36807;&#31243;&#20250;&#23545;&#20854;&#36827;&#34892;&#26465;&#20214;&#21270;&#65292;&#24182;&#21033;&#29992;&#35813;&#21464;&#37327;&#23384;&#20648;&#22270;&#20687;&#20449;&#24687;&#12290;&#20915;&#23450;&#25193;&#25955;&#36807;&#31243;&#30340;&#21097;&#20313;&#8220;&#32441;&#29702;&#8221;&#21464;&#37327;&#20250;&#22312;&#35299;&#30721;&#26102;&#21512;&#25104;&#12290;&#36890;&#36807;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#21487;&#20197;&#26681;&#25454;&#24863;&#30693;&#24230;&#37327;&#36827;&#34892;&#35843;&#25972;&#12290;&#25105;&#20204;&#24191;&#27867;&#30340;&#23454;&#39564;&#28041;&#21450;&#20102;&#22810;&#20010;&#25968;&#25454;&#38598;&#21644;&#22270;&#20687;&#36136;&#37327;&#35780;&#20272;&#25351;&#26631;&#65292;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#36739;&#20110;&#22522;&#20110;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#26041;&#27861;&#33021;&#22815;&#24471;&#21040;&#26356;&#22909;&#30340;FID&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper outlines an end-to-end optimized lossy image compression framework using diffusion generative models. The approach relies on the transform coding paradigm, where an image is mapped into a latent space for entropy coding and, from there, mapped back to the data space for reconstruction. In contrast to VAE-based neural compression, where the (mean) decoder is a deterministic neural network, our decoder is a conditional diffusion model. Our approach thus introduces an additional "content" latent variable on which the reverse diffusion process is conditioned and uses this variable to store information about the image. The remaining "texture" variables characterizing the diffusion process are synthesized at decoding time. We show that the model's performance can be tuned toward perceptual metrics of interest. Our extensive experiments involving multiple datasets and image quality assessment metrics show that our approach yields stronger reported FID scores than the GAN-based mode
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;GNN&#22312;&#33410;&#28857;&#20998;&#31867;&#20013;&#25554;&#20540;&#24102;&#38480;&#20989;&#25968;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;GNN&#32467;&#26500;&#20197;&#30456;&#21516;&#30340;&#31934;&#24230;&#25554;&#20540;&#24102;&#38480;&#20989;&#25968;&#25152;&#38656;&#30340;&#26435;&#37325;&#27604;&#20351;&#29992;&#23436;&#20840;&#36830;&#25509;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#23569;&#24471;&#22810;&#12290;</title><link>http://arxiv.org/abs/2206.05904</link><description>&lt;p&gt;
GNN&#22312;&#25512;&#24191;&#24102;&#38480;&#20989;&#25968;&#26041;&#38754;&#30340;&#20248;&#36234;&#24615;&#27604;NN&#26356;&#21152;&#26126;&#26174;
&lt;/p&gt;
&lt;p&gt;
Superiority of GNN over NN in generalizing bandlimited functions. (arXiv:2206.05904v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.05904
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;GNN&#22312;&#33410;&#28857;&#20998;&#31867;&#20013;&#25554;&#20540;&#24102;&#38480;&#20989;&#25968;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;GNN&#32467;&#26500;&#20197;&#30456;&#21516;&#30340;&#31934;&#24230;&#25554;&#20540;&#24102;&#38480;&#20989;&#25968;&#25152;&#38656;&#30340;&#26435;&#37325;&#27604;&#20351;&#29992;&#23436;&#20840;&#36830;&#25509;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#23569;&#24471;&#22810;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#20197;&#20854;&#25972;&#21512;&#22270;&#24418;&#20449;&#24687;&#30340;&#33021;&#21147;&#34987;&#24191;&#27867;&#29992;&#20110;&#25968;&#25454;&#20998;&#26512;&#12290;&#28982;&#32780;&#65292;GNN&#30340;&#34920;&#36798;&#33021;&#21147;&#20165;&#38024;&#23545;&#22270;&#32423;&#20219;&#21153;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#32780;&#19981;&#26159;&#38024;&#23545;&#33410;&#28857;&#32423;&#20219;&#21153;&#65292;&#20363;&#22914;&#33410;&#28857;&#20998;&#31867;&#65292;&#20854;&#20013;&#35797;&#22270;&#20174;&#35266;&#23519;&#21040;&#30340;&#33410;&#28857;&#26631;&#31614;&#20013;&#25554;&#20540;&#20986;&#32570;&#22833;&#30340;&#26631;&#31614;&#20449;&#24687;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;GNN&#22312;&#25152;&#36848;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#23427;&#23454;&#36136;&#19978;&#26159;&#19968;&#20010;&#20989;&#25968;&#25554;&#20540;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;GNN&#25554;&#20540;$\mathbb{R}^d$&#20013;&#24102;&#38480;&#20989;&#25968;&#25152;&#38656;&#30340;&#26435;&#37325;&#21644;&#23618;&#25968;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;&#20351;&#29992;GNN&#26550;&#26500;&#20197;$\epsilon$-&#36817;&#20284;&#31163;&#25955;&#24102;&#38480;&#20449;&#21495;&#20165;&#38656;&#35201;$O((\log \epsilon^{-1})^{d})$&#20010;&#26435;&#37325;&#65292;&#36825;&#27604;&#20351;&#29992;&#23436;&#20840;&#36830;&#25509;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#24471;&#21040;&#30340;&#26368;&#20339;&#32467;&#26524;&#30340;&#25152;&#38656;&#26435;&#37325;&#23569;&#24471;&#22810; - &#29305;&#21035;&#22320;&#65292;&#20351;&#29992;&#20351;&#29992;$O((\log \epsilon^{-1})^{d})$&#20010;&#26679;&#26412;&#26469;&#35757;&#32451;GNN&#20197;$\epsilon$-&#36924;&#36817;&#24102;&#38480;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Network (GNN) with its ability to integrate graph information has been widely used for data analyses. However, the expressive power of GNN has only been studied for graph-level tasks but not for node-level tasks, such as node classification, where one tries to interpolate missing nodal labels from the observed ones. In this paper, we study the expressive power of GNN for the said classification task, which is in essence a function interpolation problem. Explicitly, we derive the number of weights and layers needed for a GNN to interpolate a band-limited function in $\mathbb{R}^d$. Our result shows that, the number of weights needed to $\epsilon$-approximate a bandlimited function using the GNN architecture is much fewer than the best known one using a fully connected neural network (NN) - in particular, one only needs $O((\log \epsilon^{-1})^{d})$ weights using a GNN trained by $O((\log \epsilon^{-1})^{d})$ samples to $\epsilon$-approximate a discretized bandlimited signal
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#21512;&#22810;&#35270;&#22270;&#26080;&#30417;&#30563;&#29305;&#24449;&#36873;&#25321;&#21644;&#22270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27491;&#20132;&#20998;&#35299;&#24314;&#27169;&#22810;&#35270;&#22270;&#29305;&#24449;&#36873;&#25321;&#65292;&#24212;&#29992;&#36328;&#31354;&#38388;&#23616;&#37096;&#20445;&#25345;&#36827;&#34892;&#32858;&#31867;&#32467;&#26500;&#23398;&#20064;&#21644;&#30456;&#20284;&#24615;&#23398;&#20064;&#30340;&#36830;&#25509;&#12290;</title><link>http://arxiv.org/abs/2204.08247</link><description>&lt;p&gt;
&#22810;&#35270;&#22270;&#26080;&#30417;&#30563;&#29305;&#24449;&#36873;&#25321;&#19982;&#22270;&#23398;&#20064;&#30340;&#32852;&#21512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Joint Multi-view Unsupervised Feature Selection and Graph Learning. (arXiv:2204.08247v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.08247
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#21512;&#22810;&#35270;&#22270;&#26080;&#30417;&#30563;&#29305;&#24449;&#36873;&#25321;&#21644;&#22270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27491;&#20132;&#20998;&#35299;&#24314;&#27169;&#22810;&#35270;&#22270;&#29305;&#24449;&#36873;&#25321;&#65292;&#24212;&#29992;&#36328;&#31354;&#38388;&#23616;&#37096;&#20445;&#25345;&#36827;&#34892;&#32858;&#31867;&#32467;&#26500;&#23398;&#20064;&#21644;&#30456;&#20284;&#24615;&#23398;&#20064;&#30340;&#36830;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#21462;&#24471;&#20102;&#19968;&#23450;&#30340;&#36827;&#23637;&#65292;&#20294;&#20043;&#21069;&#30340;&#22810;&#35270;&#22270;&#26080;&#30417;&#30563;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#20027;&#35201;&#23384;&#22312;&#20004;&#20010;&#38480;&#21046;&#12290;&#39318;&#20808;&#65292;&#23427;&#20204;&#36890;&#24120;&#20351;&#29992;&#32858;&#31867;&#32467;&#26500;&#25110;&#30456;&#20284;&#24615;&#32467;&#26500;&#26469;&#25351;&#23548;&#29305;&#24449;&#36873;&#25321;&#65292;&#24573;&#30053;&#20102;&#32852;&#21512;&#20844;&#24335;&#21487;&#33021;&#24102;&#26469;&#30340;&#20114;&#24800;&#25928;&#30410;&#12290;&#20854;&#27425;&#65292;&#23427;&#20204;&#36890;&#24120;&#36890;&#36807;&#20840;&#23616;&#32467;&#26500;&#23398;&#20064;&#25110;&#23616;&#37096;&#32467;&#26500;&#23398;&#20064;&#26469;&#23398;&#20064;&#30456;&#20284;&#24615;&#32467;&#26500;&#65292;&#32570;&#20047;&#21516;&#26102;&#20855;&#22791;&#20840;&#23616;&#21644;&#23616;&#37096;&#32467;&#26500;&#24863;&#30693;&#30340;&#22270;&#23398;&#20064;&#33021;&#21147;&#12290;&#37492;&#20110;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#21512;&#22810;&#35270;&#22270;&#26080;&#30417;&#30563;&#29305;&#24449;&#36873;&#25321;&#21644;&#22270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65288;JMVFG&#65289;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#37319;&#29992;&#27491;&#20132;&#20998;&#35299;&#23545;&#22810;&#35270;&#22270;&#29305;&#24449;&#36873;&#25321;&#36827;&#34892;&#24314;&#27169;&#65292;&#20854;&#20013;&#27599;&#20010;&#30446;&#26631;&#30697;&#38453;&#34987;&#20998;&#35299;&#20026;&#19968;&#20010;&#35270;&#22270;&#29305;&#23450;&#30340;&#22522;&#30697;&#38453;&#21644;&#19968;&#20010;&#35270;&#22270;&#19968;&#33268;&#30340;&#32858;&#31867;&#25351;&#31034;&#22120;&#12290;&#36328;&#31354;&#38388;&#23616;&#37096;&#20445;&#25345;&#34987;&#24212;&#29992;&#20110;&#22312;&#25237;&#24433;&#31354;&#38388;&#20013;&#36827;&#34892;&#32858;&#31867;&#32467;&#26500;&#23398;&#20064;&#21644;&#30456;&#20284;&#24615;&#23398;&#20064;&#30340;&#36830;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite significant progress, previous multi-view unsupervised feature selection methods mostly suffer from two limitations. First, they generally utilize either cluster structure or similarity structure to guide the feature selection, which neglect the possibility of a joint formulation with mutual benefits. Second, they often learn the similarity structure by either global structure learning or local structure learning, which lack the capability of graph learning with both global and local structural awareness. In light of this, this paper presents a joint multi-view unsupervised feature selection and graph learning (JMVFG) approach. Particularly, we formulate the multi-view feature selection with orthogonal decomposition, where each target matrix is decomposed into a view-specific basis matrix and a view-consistent cluster indicator. The cross-space locality preservation is incorporated to bridge the cluster structure learning in the projected space and the similarity learning (i.e.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22270;&#19978;&#30340;&#26799;&#24230;&#27969;&#38382;&#39064;&#65292;&#21457;&#29616;&#22312;&#22823;&#22270;&#30340;&#36793;&#26435;&#37325;&#36866;&#24403;&#20989;&#25968;&#30340;&#27431;&#20960;&#37324;&#24471;&#26799;&#24230;&#27969;&#25910;&#25947;&#21040;&#22270;&#20989;&#25968;&#31354;&#38388;&#19978;&#19968;&#26465;&#26032;&#22411;&#36830;&#32493;&#26497;&#38480;&#12290;&#35768;&#22810;&#33258;&#28982;&#20989;&#25968;&#22312;&#35813;&#35774;&#32622;&#19979;&#37117;&#24471;&#21040;&#20102;&#28085;&#30422;&#65292;&#20363;&#22914;&#21516;&#24577;&#20989;&#25968;&#21644;&#26631;&#37327;&#29109;&#12290;</title><link>http://arxiv.org/abs/2111.09459</link><description>&lt;p&gt;
&#22270;&#19978;&#30340;&#26799;&#24230;&#27969;&#65306;&#23384;&#22312;&#24615;&#12289;&#25910;&#25947;&#24615;&#12289;&#36830;&#32493;&#24615;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
Gradient flows on graphons: existence, convergence, continuity equations. (arXiv:2111.09459v3 [math.PR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.09459
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22270;&#19978;&#30340;&#26799;&#24230;&#27969;&#38382;&#39064;&#65292;&#21457;&#29616;&#22312;&#22823;&#22270;&#30340;&#36793;&#26435;&#37325;&#36866;&#24403;&#20989;&#25968;&#30340;&#27431;&#20960;&#37324;&#24471;&#26799;&#24230;&#27969;&#25910;&#25947;&#21040;&#22270;&#20989;&#25968;&#31354;&#38388;&#19978;&#19968;&#26465;&#26032;&#22411;&#36830;&#32493;&#26497;&#38480;&#12290;&#35768;&#22810;&#33258;&#28982;&#20989;&#25968;&#22312;&#35813;&#35774;&#32622;&#19979;&#37117;&#24471;&#21040;&#20102;&#28085;&#30422;&#65292;&#20363;&#22914;&#21516;&#24577;&#20989;&#25968;&#21644;&#26631;&#37327;&#29109;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#31181;&#20248;&#21270;&#38382;&#39064;&#20013;&#65292;Wasserstein&#26799;&#24230;&#27969;&#22312;&#27010;&#29575;&#27979;&#24230;&#19978;&#21457;&#29616;&#20102;&#35768;&#22810;&#24212;&#29992;&#12290;&#23427;&#20204;&#36890;&#24120;&#20986;&#29616;&#20026;&#20132;&#25442;&#31890;&#23376;&#31995;&#32479;&#30340;&#36830;&#32493;&#26497;&#38480;&#65292;&#36825;&#20123;&#31890;&#23376;&#31995;&#32479;&#36890;&#36807;&#26576;&#31181;&#28041;&#21450;&#26799;&#24230;&#22411;&#21183;&#33021;&#30340;&#22343;&#22330;&#30456;&#20114;&#20316;&#29992;&#28436;&#21270;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#38382;&#39064;&#20013;&#65292;&#35832;&#22914;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#25152;&#35859;&#30340;&#31890;&#23376;&#26159;&#22823;&#22270;&#19978;&#30340;&#36793;&#26435;&#37325;&#65292;&#20854;&#33410;&#28857;&#26159;&#21487;&#20132;&#25442;&#30340;&#12290;&#36825;&#26679;&#30340;&#22823;&#22270;&#24050;&#30693;&#22312;&#20854;&#22823;&#23567;&#36235;&#20110;&#26080;&#31351;&#22823;&#26102;&#25910;&#25947;&#21040;&#31216;&#20026;&#22270;&#20989;&#25968;&#30340;&#36830;&#32493;&#26497;&#38480;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36866;&#24403;&#20989;&#25968;&#30340;&#27431;&#20960;&#37324;&#24471;&#26799;&#24230;&#27969;&#25910;&#25947;&#21040;&#22270;&#20989;&#25968;&#31354;&#38388;&#19978;&#30340;&#19968;&#26465;&#26032;&#22411;&#36830;&#32493;&#26497;&#38480;&#65292;&#21487;&#36866;&#24403;&#25551;&#36848;&#20026;&#26799;&#24230;&#27969;&#25110;&#26356;&#25216;&#26415;&#24615;&#22320;&#35828;&#65292;&#26159;&#19968;&#26465;&#26368;&#22823;&#26012;&#29575;&#26354;&#32447;&#12290;&#25105;&#20204;&#30340;&#35774;&#32622;&#28085;&#30422;&#20102;&#22270;&#20989;&#25968;&#19978;&#30340;&#20960;&#20010;&#33258;&#28982;&#20989;&#25968;&#65292;&#20363;&#22914;&#21516;&#24577;&#20989;&#25968;&#21644;&#26631;&#37327;&#29109;&#65292;&#24182;&#19988;&#24050;&#32463;&#35814;&#32454;&#35745;&#31639;&#20102;&#36825;&#20123;&#20363;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;
Wasserstein gradient flows on probability measures have found a host of applications in various optimization problems. They typically arise as the continuum limit of exchangeable particle systems evolving by some mean-field interaction involving a gradient-type potential. However, in many problems, such as in multi-layer neural networks, the so-called particles are edge weights on large graphs whose nodes are exchangeable. Such large graphs are known to converge to continuum limits called graphons as their size grow to infinity. We show that the Euclidean gradient flow of a suitable function of the edge-weights converges to a novel continuum limit given by a curve on the space of graphons that can be appropriately described as a gradient flow or, more technically, a curve of maximal slope. Several natural functions on graphons, such as homomorphism functions and the scalar entropy, are covered by our set-up, and the examples have been worked out in detail.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#20998;&#22359;&#32570;&#22833;&#25968;&#25454;&#30340;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#26080;&#20559;&#20272;&#35745;&#26041;&#31243;&#21644;&#20998;&#22359;&#25554;&#34917;&#31243;&#24207;&#65292;&#23454;&#29616;&#20102;&#22238;&#24402;&#31995;&#25968;&#21521;&#37327;&#30340;&#39640;&#25928;&#20272;&#35745;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#27599;&#20010;&#22238;&#24402;&#31995;&#25968;&#30340;&#20960;&#20046;&#26080;&#20559;&#20272;&#35745;&#22120;&#21644;&#30456;&#24212;&#30340;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2106.03344</link><description>&lt;p&gt;
&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#20998;&#22359;&#32570;&#22833;&#25968;&#25454;&#30340;&#32479;&#35745;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Statistical Inference for High-Dimensional Linear Regression with Blockwise Missing Data. (arXiv:2106.03344v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.03344
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#20998;&#22359;&#32570;&#22833;&#25968;&#25454;&#30340;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#26080;&#20559;&#20272;&#35745;&#26041;&#31243;&#21644;&#20998;&#22359;&#25554;&#34917;&#31243;&#24207;&#65292;&#23454;&#29616;&#20102;&#22238;&#24402;&#31995;&#25968;&#21521;&#37327;&#30340;&#39640;&#25928;&#20272;&#35745;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#27599;&#20010;&#22238;&#24402;&#31995;&#25968;&#30340;&#20960;&#20046;&#26080;&#20559;&#20272;&#35745;&#22120;&#21644;&#30456;&#24212;&#30340;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#22359;&#32570;&#22833;&#25968;&#25454;&#32463;&#24120;&#22312;&#25972;&#21512;&#22810;&#28304;&#25110;&#22810;&#27169;&#24577;&#25968;&#25454;&#26102;&#20986;&#29616;&#65292;&#20854;&#20013;&#19981;&#21516;&#30340;&#25968;&#25454;&#28304;&#25110;&#27169;&#24577;&#21253;&#21547;&#20114;&#34917;&#30340;&#20449;&#24687;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20855;&#26377;&#20998;&#22359;&#32570;&#22833;&#21327;&#21464;&#37327;&#21644;&#37096;&#20998;&#35266;&#27979;&#21709;&#24212;&#21464;&#37327;&#30340;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#22522;&#20110;&#20180;&#32454;&#26500;&#24314;&#30340;&#26080;&#20559;&#20272;&#35745;&#26041;&#31243;&#21644;&#20998;&#22359;&#25554;&#34917;&#31243;&#24207;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#22238;&#24402;&#31995;&#25968;&#21521;&#37327;&#20272;&#35745;&#22120;&#65292;&#24182;&#24471;&#21040;&#20102;&#20854;&#25910;&#25947;&#36895;&#24230;&#12290;&#27492;&#22806;&#65292;&#22522;&#20110;&#19968;&#31181;&#21019;&#26032;&#30340;&#25237;&#24433;&#20272;&#35745;&#26041;&#31243;&#25216;&#26415;&#65292;&#35813;&#25216;&#26415;&#22312;&#20869;&#22312;&#19978;&#23454;&#29616;&#20102;&#21021;&#22987;&#20272;&#35745;&#22120;&#30340;&#20559;&#24046;&#26657;&#27491;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#27599;&#20010;&#20010;&#20307;&#22238;&#24402;&#31995;&#25968;&#30340;&#20960;&#20046;&#26080;&#20559;&#20272;&#35745;&#22120;&#65292;&#22312;&#28201;&#21644;&#26465;&#20214;&#19979;&#28176;&#36817;&#22320;&#26381;&#20174;&#27491;&#24577;&#20998;&#24067;&#12290;&#22522;&#20110;&#36825;&#20123;&#21435;&#20559;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#24314;&#31435;&#28176;&#36817;&#26377;&#25928;&#30340;&#32622;&#20449;&#21306;&#38388;&#21644;&#20851;&#20110;&#27599;&#20010;&#22238;&#24402;&#31995;&#25968;&#30340;&#32479;&#35745;&#26816;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Blockwise missing data occurs frequently when we integrate multisource or multimodality data where different sources or modalities contain complementary information. In this paper, we consider a high-dimensional linear regression model with blockwise missing covariates and a partially observed response variable. Under this framework, we propose a computationally efficient estimator for the regression coefficient vector based on carefully constructed unbiased estimating equations and a blockwise imputation procedure, and obtain its rate of convergence. Furthermore, building upon an innovative projected estimating equation technique that intrinsically achieves bias-correction of the initial estimator, we propose a nearly unbiased estimator for each individual regression coefficient, which is asymptotically normally distributed under mild conditions. Based on these debiased estimators, asymptotically valid confidence intervals and statistical tests about each regression coefficient are co
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#21442;&#25968;&#24314;&#27169;&#26694;&#26550;&#65292;&#29992;&#20110;&#32593;&#32476;&#24178;&#25200;&#26465;&#20214;&#19979;&#30340;&#22240;&#26524;&#25512;&#26029;&#65292;&#36890;&#36807;&#23545;&#20195;&#29702;&#20154;&#20043;&#38388;&#30340;&#36830;&#25509;&#26041;&#24335;&#36827;&#34892;&#24314;&#27169;&#21644;&#23398;&#20064;&#25919;&#31574;&#25110;&#27835;&#30103;&#20998;&#37197;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#27979;&#35797;&#26041;&#27861;&#26469;&#26816;&#39564;&#25919;&#31574;&#26080;&#20851;&#24615;/&#27835;&#30103;&#25928;&#24212;&#65292;&#24182;&#23545;&#24179;&#22343;&#25110;&#20998;&#24067;&#24335;&#25919;&#31574;&#25928;&#24212;/&#27835;&#30103;&#21453;&#24212;&#30340;&#20272;&#35745;&#22120;&#32473;&#20986;&#20102;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2105.03810</link><description>&lt;p&gt;
&#32593;&#32476;&#24178;&#25200;&#26465;&#20214;&#19979;&#22240;&#26524;&#25512;&#26029;&#30340;&#23616;&#37096;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
The Local Approach to Causal Inference under Network Interference. (arXiv:2105.03810v4 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.03810
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#21442;&#25968;&#24314;&#27169;&#26694;&#26550;&#65292;&#29992;&#20110;&#32593;&#32476;&#24178;&#25200;&#26465;&#20214;&#19979;&#30340;&#22240;&#26524;&#25512;&#26029;&#65292;&#36890;&#36807;&#23545;&#20195;&#29702;&#20154;&#20043;&#38388;&#30340;&#36830;&#25509;&#26041;&#24335;&#36827;&#34892;&#24314;&#27169;&#21644;&#23398;&#20064;&#25919;&#31574;&#25110;&#27835;&#30103;&#20998;&#37197;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#27979;&#35797;&#26041;&#27861;&#26469;&#26816;&#39564;&#25919;&#31574;&#26080;&#20851;&#24615;/&#27835;&#30103;&#25928;&#24212;&#65292;&#24182;&#23545;&#24179;&#22343;&#25110;&#20998;&#24067;&#24335;&#25919;&#31574;&#25928;&#24212;/&#27835;&#30103;&#21453;&#24212;&#30340;&#20272;&#35745;&#22120;&#32473;&#20986;&#20102;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#21442;&#25968;&#24314;&#27169;&#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#31038;&#20132;&#25110;&#32463;&#27982;&#32593;&#32476;&#20013;&#20195;&#29702;&#20154;&#20043;&#38388;&#36830;&#25509;&#26041;&#24335;&#23545;&#32467;&#26524;&#20135;&#29983;&#24433;&#21709;&#30340;&#22240;&#26524;&#25512;&#26029;&#38382;&#39064;&#12290;&#36825;&#31181;&#32593;&#32476;&#24178;&#25200;&#25551;&#36848;&#20102;&#20851;&#20110;&#27835;&#30103;&#28322;&#20986;&#12289;&#31038;&#20132;&#20114;&#21160;&#12289;&#31038;&#20250;&#23398;&#20064;&#12289;&#20449;&#24687;&#25193;&#25955;&#12289;&#30142;&#30149;&#21644;&#37329;&#34701;&#20256;&#26579;&#12289;&#31038;&#20250;&#36164;&#26412;&#24418;&#25104;&#31561;&#39046;&#22495;&#30340;&#22823;&#37327;&#25991;&#29486;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#39318;&#20808;&#36890;&#36807;&#27979;&#37327;&#36335;&#24452;&#36317;&#31163;&#26469;&#25551;&#36848;&#20195;&#29702;&#20154;&#22312;&#32593;&#32476;&#20013;&#30340;&#36830;&#25509;&#26041;&#24335;&#65292;&#28982;&#21518;&#36890;&#36807;&#27719;&#38598;&#20855;&#26377;&#31867;&#20284;&#37197;&#32622;&#30340;&#20195;&#29702;&#20154;&#30340;&#32467;&#26524;&#25968;&#25454;&#26469;&#23398;&#20064;&#25919;&#31574;&#25110;&#27835;&#30103;&#20998;&#37197;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#20010;&#28176;&#36817;&#26377;&#25928;&#30340;&#27979;&#35797;&#26469;&#28436;&#31034;&#35813;&#26041;&#27861;&#65292;&#35813;&#27979;&#35797;&#29992;&#20110;&#26816;&#39564;&#25919;&#31574;&#26080;&#20851;&#24615;/&#27835;&#30103;&#25928;&#24212;&#30340;&#20551;&#35774;&#65292;&#24182;&#32473;&#20986;&#20102;&#38024;&#23545;&#24179;&#22343;&#25110;&#20998;&#24067;&#24335;&#25919;&#31574;&#25928;&#24212;/&#27835;&#30103;&#21453;&#24212;&#30340;k&#26368;&#36817;&#37051;&#20272;&#35745;&#22120;&#30340;&#22343;&#26041;&#35823;&#24046;&#30340;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new nonparametric modeling framework for causal inference when outcomes depend on how agents are linked in a social or economic network. Such network interference describes a large literature on treatment spillovers, social interactions, social learning, information diffusion, disease and financial contagion, social capital formation, and more. Our approach works by first characterizing how an agent is linked in the network using the configuration of other agents and connections nearby as measured by path distance. The impact of a policy or treatment assignment is then learned by pooling outcome data across similarly configured agents. We demonstrate the approach by proposing an asymptotically valid test for the hypothesis of policy irrelevance/no treatment effects and bounding the mean-squared error of a k-nearest-neighbor estimator for the average or distributional policy effect/treatment response.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#20855;&#26377;&#38750;&#23545;&#31216;&#20960;&#20309;&#25955;&#23556;&#21464;&#25442;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#31867;&#38750;&#23545;&#31216;&#23567;&#27874;&#65292;&#23427;&#32479;&#19968;&#21644;&#25193;&#23637;&#20102;&#29616;&#26377;&#22270;&#24418;&#25955;&#23556;&#26550;&#26500;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#24182;&#20026;&#26410;&#26469;&#30340;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#20026;&#22270;&#24418;&#25552;&#20379;&#20102;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/1911.06253</link><description>&lt;p&gt;
&#20102;&#35299;&#20855;&#26377;&#38750;&#23545;&#31216;&#20960;&#20309;&#25955;&#23556;&#21464;&#25442;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Understanding Graph Neural Networks with Asymmetric Geometric Scattering Transforms. (arXiv:1911.06253v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1911.06253
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#20855;&#26377;&#38750;&#23545;&#31216;&#20960;&#20309;&#25955;&#23556;&#21464;&#25442;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#31867;&#38750;&#23545;&#31216;&#23567;&#27874;&#65292;&#23427;&#32479;&#19968;&#21644;&#25193;&#23637;&#20102;&#29616;&#26377;&#22270;&#24418;&#25955;&#23556;&#26550;&#26500;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#24182;&#20026;&#26410;&#26469;&#30340;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#20026;&#22270;&#24418;&#25552;&#20379;&#20102;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25955;&#23556;&#21464;&#25442;&#26159;&#19968;&#31181;&#22522;&#20110;&#23567;&#27874;&#30340;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#65292;&#20316;&#20026;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#27169;&#22411;&#12290;&#26368;&#36817;&#65292;&#26377;&#20960;&#31687;&#24037;&#20316;&#24341;&#20837;&#20102;&#25955;&#23556;&#21464;&#25442;&#22312;&#38750;&#27431;&#20960;&#37324;&#24503;&#35774;&#32622;&#65288;&#22914;&#22270;&#24418;&#65289;&#20013;&#30340;&#25512;&#24191;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#22522;&#20110;&#36825;&#20123;&#26500;&#36896;&#65292;&#24341;&#20837;&#20102;&#22522;&#20110;&#38750;&#24120;&#19968;&#33324;&#30340;&#38750;&#23545;&#31216;&#23567;&#27874;&#31867;&#30340;&#22270;&#24418;&#31383;&#21475;&#21270;&#21644;&#38750;&#31383;&#21475;&#21270;&#20960;&#20309;&#25955;&#23556;&#21464;&#25442;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#38750;&#23545;&#31216;&#22270;&#24418;&#25955;&#23556;&#21464;&#25442;&#19982;&#23545;&#31216;&#25955;&#23556;&#21464;&#25442;&#26377;&#35768;&#22810;&#30456;&#21516;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#22240;&#27492;&#65292;&#25552;&#20986;&#30340;&#26500;&#36896;&#32479;&#19968;&#21644;&#25193;&#23637;&#20102;&#29616;&#26377;&#22270;&#24418;&#25955;&#23556;&#26550;&#26500;&#30340;&#24050;&#30693;&#29702;&#35770;&#32467;&#26524;&#12290;&#36890;&#36807;&#36825;&#26679;&#20570;&#65292;&#36825;&#39033;&#24037;&#20316;&#36890;&#36807;&#24341;&#20837;&#22823;&#37327;&#24102;&#26377;&#21487;&#35777;&#26126;&#31283;&#23450;&#24615;&#21644;&#19981;&#21464;&#24615;&#20445;&#35777;&#30340;&#32593;&#32476;&#65292;&#26377;&#21161;&#20110;&#24357;&#21512;&#20960;&#20309;&#25955;&#23556;&#21644;&#20854;&#20182;&#22270;&#31070;&#32463;&#32593;&#32476;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#36825;&#20123;&#32467;&#26524;&#20026;&#26410;&#26469;&#30340;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#20026;&#22270;&#24418;&#25552;&#20379;&#20102;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
The scattering transform is a multilayered wavelet-based deep learning architecture that acts as a model of convolutional neural networks. Recently, several works have introduced generalizations of the scattering transform for non-Euclidean settings such as graphs. Our work builds upon these constructions by introducing windowed and non-windowed geometric scattering transforms for graphs based upon a very general class of asymmetric wavelets. We show that these asymmetric graph scattering transforms have many of the same theoretical guarantees as their symmetric counterparts. As a result, the proposed construction unifies and extends known theoretical results for many of the existing graph scattering architectures. In doing so, this work helps bridge the gap between geometric scattering and other graph neural networks by introducing a large family of networks with provable stability and invariance guarantees. These results lay the groundwork for future deep learning architectures for g
&lt;/p&gt;</description></item></channel></rss>