<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#23618;&#21098;&#26525;&#26041;&#27861;&#21487;&#20197;&#22312;&#27969;&#34892;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#23454;&#29616;&#22823;&#37096;&#20998;&#23618;&#30340;&#31227;&#38500;&#32780;&#20445;&#25345;&#24615;&#33021;&#65292;&#21516;&#26102;&#20351;&#29992;&#21442;&#25968;&#39640;&#25928;&#30340;&#24494;&#35843;&#26041;&#27861;&#21487;&#20197;&#36827;&#19968;&#27493;&#20943;&#23569;&#35745;&#31639;&#36164;&#28304;&#65292;&#25552;&#39640;&#25512;&#26029;&#30340;&#20869;&#23384;&#21644;&#24310;&#36831;&#12290;</title><link>https://arxiv.org/abs/2403.17887</link><description>&lt;p&gt;
&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#23618;&#21098;&#26525;&#30340;&#19981;&#21512;&#29702;&#26080;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;
The Unreasonable Ineffectiveness of the Deeper Layers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17887
&lt;/p&gt;
&lt;p&gt;
&#23618;&#21098;&#26525;&#26041;&#27861;&#21487;&#20197;&#22312;&#27969;&#34892;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#23454;&#29616;&#22823;&#37096;&#20998;&#23618;&#30340;&#31227;&#38500;&#32780;&#20445;&#25345;&#24615;&#33021;&#65292;&#21516;&#26102;&#20351;&#29992;&#21442;&#25968;&#39640;&#25928;&#30340;&#24494;&#35843;&#26041;&#27861;&#21487;&#20197;&#36827;&#19968;&#27493;&#20943;&#23569;&#35745;&#31639;&#36164;&#28304;&#65292;&#25552;&#39640;&#25512;&#26029;&#30340;&#20869;&#23384;&#21644;&#24310;&#36831;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#27969;&#34892;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#36827;&#34892;&#20102;&#31616;&#21333;&#30340;&#23618;&#21098;&#26525;&#31574;&#30053;&#30340;&#23454;&#35777;&#30740;&#31350;&#65292;&#21457;&#29616;&#22312;&#31227;&#38500;&#22823;&#37096;&#20998;&#23618;&#65288;&#26368;&#39640;&#36798;&#19968;&#21322;&#65289;&#20043;&#21069;&#65292;&#19981;&#21516;&#38382;&#31572;&#22522;&#20934;&#27979;&#35797;&#30340;&#24615;&#33021;&#20960;&#20046;&#27809;&#26377;&#21463;&#21040;&#24433;&#21709;&#12290;&#20026;&#20102;&#21098;&#26525;&#36825;&#20123;&#27169;&#22411;&#65292;&#25105;&#20204;&#36890;&#36807;&#32771;&#34385;&#23618;&#38388;&#30340;&#30456;&#20284;&#24615;&#26469;&#30830;&#23450;&#26368;&#20339;&#30340;&#21098;&#26525;&#23618;&#22359;&#65307;&#28982;&#21518;&#65292;&#20026;&#20102;&#8220;&#20462;&#22797;&#8221;&#25439;&#23475;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#23569;&#37327;&#24494;&#35843;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#20351;&#29992;&#21442;&#25968;&#39640;&#25928;&#30340;&#24494;&#35843;&#65288;PEFT&#65289;&#26041;&#27861;&#65292;&#20855;&#20307;&#21253;&#25324;&#37327;&#21270;&#21644;&#20302;&#31209;&#36866;&#37197;&#22120;&#65288;QLoRA&#65289;&#65292;&#36825;&#26679;&#25105;&#20204;&#30340;&#27599;&#20010;&#23454;&#39564;&#37117;&#21487;&#20197;&#22312;&#21333;&#20010;A100 GPU&#19978;&#25191;&#34892;&#12290;&#20174;&#23454;&#38469;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#36825;&#20123;&#32467;&#26524;&#34920;&#26126;&#23618;&#21098;&#26525;&#26041;&#27861;&#21487;&#20197;&#34917;&#20805;&#20854;&#20182;PEFT&#31574;&#30053;&#65292;&#20174;&#32780;&#36827;&#19968;&#27493;&#20943;&#23569;&#24494;&#35843;&#30340;&#35745;&#31639;&#36164;&#28304;&#65292;&#21478;&#19968;&#26041;&#38754;&#21487;&#20197;&#25552;&#39640;&#25512;&#26029;&#30340;&#20869;&#23384;&#21644;&#24310;&#36831;&#12290;&#20174;&#31185;&#23398;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#35813;&#30740;&#31350;&#34920;&#26126;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#26576;&#31181;&#31243;&#24230;&#19978;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#24182;&#19988;&#23545;&#27169;&#22411;&#30340;&#21098;&#26525;&#27809;&#26377;&#22826;&#22823;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17887v1 Announce Type: new  Abstract: We empirically study a simple layer-pruning strategy for popular families of open-weight pretrained LLMs, finding minimal degradation of performance on different question-answering benchmarks until after a large fraction (up to half) of the layers are removed. To prune these models, we identify the optimal block of layers to prune by considering similarity across layers; then, to "heal" the damage, we perform a small amount of finetuning. In particular, we use parameter-efficient finetuning (PEFT) methods, specifically quantization and Low Rank Adapters (QLoRA), such that each of our experiments can be performed on a single A100 GPU. From a practical perspective, these results suggest that layer pruning methods can complement other PEFT strategies to further reduce computational resources of finetuning on the one hand, and can improve the memory and latency of inference on the other hand. From a scientific perspective, the robustness of 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25968;&#25454;&#39044;&#22788;&#29702;&#31639;&#27861;&#65292;&#27491;&#20132;&#20110;&#20559;&#35265;&#65288;OB&#65289;&#65292;&#36890;&#36807;&#30830;&#20445;&#25968;&#25454;&#19982;&#25935;&#24863;&#21464;&#37327;&#19981;&#30456;&#20851;&#65292;&#23454;&#29616;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#30340;&#21453;&#20107;&#23454;&#20844;&#24179;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.17852</link><description>&lt;p&gt;
&#36890;&#36807;&#23558;&#25968;&#25454;&#36716;&#21270;&#20026;&#19982;&#20559;&#35265;&#27491;&#20132;&#30340;&#26041;&#24335;&#23454;&#29616;&#21453;&#20107;&#23454;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Counterfactual Fairness through Transforming Data Orthogonal to Bias
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17852
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25968;&#25454;&#39044;&#22788;&#29702;&#31639;&#27861;&#65292;&#27491;&#20132;&#20110;&#20559;&#35265;&#65288;OB&#65289;&#65292;&#36890;&#36807;&#30830;&#20445;&#25968;&#25454;&#19982;&#25935;&#24863;&#21464;&#37327;&#19981;&#30456;&#20851;&#65292;&#23454;&#29616;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#30340;&#21453;&#20107;&#23454;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#35299;&#20915;&#21508;&#20010;&#39046;&#22495;&#30340;&#22797;&#26434;&#38382;&#39064;&#20013;&#23637;&#29616;&#20986;&#20102;&#21331;&#36234;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#26377;&#26102;&#21487;&#33021;&#34920;&#29616;&#20986;&#26377;&#20559;&#35265;&#30340;&#20915;&#31574;&#65292;&#23548;&#33268;&#19981;&#21516;&#32676;&#20307;&#20043;&#38388;&#30340;&#24453;&#36935;&#19981;&#24179;&#31561;&#12290;&#23613;&#31649;&#20844;&#24179;&#24615;&#26041;&#38754;&#30340;&#30740;&#31350;&#24050;&#32463;&#24456;&#24191;&#27867;&#65292;&#20294;&#22810;&#20803;&#36830;&#32493;&#25935;&#24863;&#21464;&#37327;&#23545;&#20915;&#31574;&#32467;&#26524;&#30340;&#24494;&#22937;&#24433;&#21709;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#30740;&#31350;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25968;&#25454;&#39044;&#22788;&#29702;&#31639;&#27861;&#65292;&#21363;&#27491;&#20132;&#20110;&#20559;&#35265;&#65288;OB&#65289;&#65292;&#26088;&#22312;&#28040;&#38500;&#36830;&#32493;&#25935;&#24863;&#21464;&#37327;&#30340;&#24433;&#21709;&#65292;&#20174;&#32780;&#20419;&#36827;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#30340;&#21453;&#20107;&#23454;&#20844;&#24179;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#65288;SCM&#65289;&#20013;&#32852;&#21512;&#27491;&#24577;&#20998;&#24067;&#30340;&#20551;&#35774;&#65292;&#35777;&#26126;&#20102;&#36890;&#36807;&#30830;&#20445;&#25968;&#25454;&#19982;&#25935;&#24863;&#21464;&#37327;&#19981;&#30456;&#20851;&#21363;&#21487;&#23454;&#29616;&#21453;&#20107;&#23454;&#20844;&#24179;&#24615;&#12290;OB&#31639;&#27861;&#19982;&#27169;&#22411;&#26080;&#20851;&#65292;&#36866;&#29992;&#20110;&#22810;&#31181;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17852v1 Announce Type: new  Abstract: Machine learning models have shown exceptional prowess in solving complex issues across various domains. Nonetheless, these models can sometimes exhibit biased decision-making, leading to disparities in treatment across different groups. Despite the extensive research on fairness, the nuanced effects of multivariate and continuous sensitive variables on decision-making outcomes remain insufficiently studied. We introduce a novel data pre-processing algorithm, Orthogonal to Bias (OB), designed to remove the influence of a group of continuous sensitive variables, thereby facilitating counterfactual fairness in machine learning applications. Our approach is grounded in the assumption of a jointly normal distribution within a structural causal model (SCM), proving that counterfactual fairness can be achieved by ensuring the data is uncorrelated with sensitive variables. The OB algorithm is model-agnostic, catering to a wide array of machine 
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#23618;&#27169;&#22411;&#65292;&#29992;&#20110;&#34920;&#31034;&#26031;&#22612;&#31119;&#24503;&#37089;&#26725;&#30417;&#27979;&#31995;&#32479;&#20013;&#30340;&#28779;&#36710;&#36890;&#36807;&#20107;&#20214;&#30340;&#32858;&#21512;&#24773;&#20917;&#65292;&#21487;&#20197;&#27169;&#25311;&#20808;&#21069;&#26410;&#35266;&#23519;&#21040;&#30340;&#28779;&#36710;&#31867;&#22411;&#65292;&#20026;&#36827;&#19968;&#27493;&#23454;&#39564;&#25552;&#20379;&#37325;&#35201;&#20449;&#24687;&#12290;</title><link>https://arxiv.org/abs/2403.17820</link><description>&lt;p&gt;
&#22312;&#26031;&#22612;&#31119;&#24503;&#37089;&#26725;&#28779;&#36710;&#36890;&#36807;&#20107;&#20214;&#30340;&#22810;&#23618;&#24314;&#27169;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards Multilevel Modelling of Train Passing Events on the Staffordshire Bridge
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17820
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#23618;&#27169;&#22411;&#65292;&#29992;&#20110;&#34920;&#31034;&#26031;&#22612;&#31119;&#24503;&#37089;&#26725;&#30417;&#27979;&#31995;&#32479;&#20013;&#30340;&#28779;&#36710;&#36890;&#36807;&#20107;&#20214;&#30340;&#32858;&#21512;&#24773;&#20917;&#65292;&#21487;&#20197;&#27169;&#25311;&#20808;&#21069;&#26410;&#35266;&#23519;&#21040;&#30340;&#28779;&#36710;&#31867;&#22411;&#65292;&#20026;&#36827;&#19968;&#27493;&#23454;&#39564;&#25552;&#20379;&#37325;&#35201;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#23618;&#27169;&#22411;&#65292;&#20197;&#20195;&#34920;&#26031;&#22612;&#31119;&#24503;&#37089;&#26725;&#30417;&#27979;&#31995;&#32479;&#20013;&#30340;&#28779;&#36710;&#36890;&#36807;&#20107;&#20214;&#30340;&#32858;&#21512;&#24773;&#20917;&#12290;&#25105;&#20204;&#20174;&#31616;&#21333;&#21333;&#20803;&#26500;&#24314;&#20102;&#19968;&#20010;&#32508;&#21512;&#27169;&#22411;&#65292;&#20195;&#34920;&#20102;&#20004;&#31181;&#31867;&#22411;&#36890;&#21220;&#28779;&#36710;&#30340;&#24212;&#21464;&#21253;&#32476;&#65288;&#27599;&#21015;&#28779;&#36710;&#36890;&#36807;&#30340;&#65289;&#12290;&#27979;&#37327;&#20540;&#34987;&#22788;&#29702;&#20026;&#19968;&#20010;&#32437;&#21521;&#25968;&#25454;&#38598;&#65292;&#24182;&#29992;&#65288;&#20302;&#31209;&#36817;&#20284;&#65289;&#20998;&#23618;&#39640;&#26031;&#36807;&#31243;&#34920;&#31034;&#12290;&#23545;&#20110;&#32452;&#21512;&#27169;&#22411;&#20013;&#30340;&#27599;&#20010;&#21333;&#20803;&#65292;&#25105;&#20204;&#23558;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#32534;&#30721;&#20026;&#36793;&#30028;&#26465;&#20214;&#32422;&#26463;&#65292;&#24182;&#33268;&#21147;&#20110;&#24212;&#21464;&#21709;&#24212;&#30340;&#19968;&#33324;&#34920;&#31034;&#12290;&#23637;&#26395;&#26410;&#26469;&#65292;&#36825;&#24212;&#35813;&#20801;&#35768;&#23545;&#20808;&#21069;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#26410;&#35266;&#23519;&#21040;&#30340;&#28779;&#36710;&#31867;&#22411;&#36827;&#34892;&#27169;&#25311;&#12290;&#20363;&#22914;&#65292;&#20056;&#23458;&#26356;&#22810;&#30340;&#28779;&#36710;&#25110;&#36816;&#36733;&#26356;&#37325;&#36135;&#29289;&#30340;&#36135;&#36710;&#12290;&#24212;&#21464;&#20107;&#20214;&#27169;&#25311;&#20855;&#26377;&#20215;&#20540;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#20197;&#20026;&#36827;&#19968;&#27493;&#23454;&#39564;&#65288;&#21253;&#25324;&#26377;&#38480;&#20803;&#27861;&#26657;&#20934;&#12289;&#30130;&#21171;&#20998;&#26512;&#25110;&#35774;&#35745;&#65289;&#25552;&#20379;&#20449;&#24687;&#65292;&#20197;&#22312;&#20551;&#35774;&#30340;&#24773;&#26223;&#19979;&#27979;&#35797;&#26725;&#26753;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17820v1 Announce Type: cross  Abstract: We suggest a multilevel model, to represent aggregate train-passing events from the Staffordshire bridge monitoring system. We formulate a combined model from simple units, representing strain envelopes (of each train passing) for two types of commuter train. The measurements are treated as a longitudinal dataset and represented with a (low-rank approximation) hierarchical Gaussian process. For each unit in the combined model, we encode domain expertise as boundary condition constraints and work towards a general representation of the strain response. Looking forward, this should allow for the simulation of train types that were previously unobserved in the training data. For example, trains with more passengers or freights with a heavier payload. The strain event simulations are valuable since they can inform further experiments (including FEM calibration, fatigue analysis, or design) to test the bridge in hypothesised scenarios.
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#19981;&#30830;&#23450;&#26631;&#31614;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#28176;&#36817;&#36125;&#21494;&#26031;&#39118;&#38505;&#35745;&#31639;&#65292;&#24182;&#36890;&#36807;&#19982;&#26368;&#20339;&#31639;&#27861;&#27604;&#36739;&#24471;&#20986;&#26032;&#30340;&#35265;&#35299;&#12290;</title><link>https://arxiv.org/abs/2403.17767</link><description>&lt;p&gt;
&#22312;&#20855;&#26377;&#19981;&#30830;&#23450;&#26631;&#31614;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#28176;&#36817;&#36125;&#21494;&#26031;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
Asymptotic Bayes risk of semi-supervised learning with uncertain labeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17767
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#19981;&#30830;&#23450;&#26631;&#31614;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#28176;&#36817;&#36125;&#21494;&#26031;&#39118;&#38505;&#35745;&#31639;&#65292;&#24182;&#36890;&#36807;&#19982;&#26368;&#20339;&#31639;&#27861;&#27604;&#36739;&#24471;&#20986;&#26032;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#19978;&#30340;&#21322;&#30417;&#30563;&#20998;&#31867;&#35774;&#32622;&#65292;&#20854;&#20013;&#25968;&#25454;&#30340;&#26631;&#31614;&#19981;&#20687;&#36890;&#24120;&#37027;&#26679;&#20005;&#26684;&#65292;&#32780;&#26159;&#24102;&#26377;&#19981;&#30830;&#23450;&#26631;&#31614;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#35745;&#31639;&#35813;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#35813;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#19982;&#30446;&#21069;&#24050;&#30693;&#30340;&#26368;&#20339;&#31639;&#27861;&#30340;&#34892;&#20026;&#12290;&#36825;&#31181;&#27604;&#36739;&#26368;&#32456;&#20026;&#35813;&#31639;&#27861;&#25552;&#20379;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17767v1 Announce Type: cross  Abstract: This article considers a semi-supervised classification setting on a Gaussian mixture model, where the data is not labeled strictly as usual, but instead with uncertain labels. Our main aim is to compute the Bayes risk for this model. We compare the behavior of the Bayes risk and the best known algorithm for this model. This comparison eventually gives new insights over the algorithm.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#36229;&#21442;&#25968;&#21270;&#27169;&#22411;&#22312;&#36229;&#20986;&#20998;&#24067;&#27867;&#21270;&#26041;&#38754;&#30340;&#34920;&#29616;&#65292;&#25506;&#35752;&#20102;&#22312;&#33391;&#24615;&#36807;&#25311;&#21512;&#26465;&#20214;&#19979;&#30340;&#34920;&#29616;&#65292;&#24182;&#21457;&#29616;&#20102;&#24658;&#23450;&#30340;&#36229;&#20986;&#20998;&#24067;&#25439;&#22833;&#12290;</title><link>https://arxiv.org/abs/2403.17592</link><description>&lt;p&gt;
&#23545;&#36229;&#21442;&#25968;&#21270;&#23545;&#20110;&#36229;&#20986;&#20998;&#24067;&#27867;&#21270;&#30340;&#30410;&#22788;
&lt;/p&gt;
&lt;p&gt;
On the Benefits of Over-parameterization for Out-of-Distribution Generalization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17592
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#36229;&#21442;&#25968;&#21270;&#27169;&#22411;&#22312;&#36229;&#20986;&#20998;&#24067;&#27867;&#21270;&#26041;&#38754;&#30340;&#34920;&#29616;&#65292;&#25506;&#35752;&#20102;&#22312;&#33391;&#24615;&#36807;&#25311;&#21512;&#26465;&#20214;&#19979;&#30340;&#34920;&#29616;&#65292;&#24182;&#21457;&#29616;&#20102;&#24658;&#23450;&#30340;&#36229;&#20986;&#20998;&#24067;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26368;&#36817;&#20960;&#24180;&#65292;&#22522;&#20110;&#29420;&#31435;&#21516;&#20998;&#24067;&#20551;&#35774;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#36825;&#19968;&#20551;&#35774;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#20013;&#24456;&#23481;&#26131;&#34987;&#36829;&#21453;&#65292;&#23548;&#33268;&#20102;&#36229;&#20986;&#20998;&#24067;&#65288;OOD&#65289;&#38382;&#39064;&#12290;&#29702;&#35299;&#29616;&#20195;&#36229;&#21442;&#25968;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#38750;&#24179;&#20961;&#33258;&#28982;&#20998;&#24067;&#20559;&#31227;&#19979;&#30340;&#34892;&#20026;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#65292;&#22240;&#20026;&#30446;&#21069;&#23545;&#20854;&#22312;&#29702;&#35770;&#19978;&#30340;&#29702;&#35299;&#26159;&#19981;&#36275;&#30340;&#12290;&#29616;&#26377;&#30340;&#29702;&#35770;&#24037;&#20316;&#24120;&#24120;&#20026;OOD&#22330;&#26223;&#20013;&#30340;&#36229;&#21442;&#25968;&#21270;&#27169;&#22411;&#25552;&#20379;&#26080;&#24847;&#20041;&#30340;&#32467;&#26524;&#65292;&#29978;&#33267;&#19982;&#23454;&#35777;&#32467;&#26524;&#30456;&#30683;&#30462;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#27491;&#22312;&#30740;&#31350;&#22312;&#19968;&#33324;&#33391;&#24615;&#36807;&#25311;&#21512;&#26465;&#20214;&#19979;&#65292;&#36229;&#21442;&#25968;&#21270;&#27169;&#22411;&#22312;OOD&#27867;&#21270;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#38598;&#20013;&#22312;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#19978;&#65292;&#24182;&#30740;&#31350;&#38750;&#24179;&#20961;&#33258;&#28982;&#20998;&#24067;&#20559;&#31227;&#65292;&#20854;&#20013;&#33391;&#24615;&#36807;&#25311;&#21512;&#20272;&#35745;&#22120;&#23637;&#31034;&#20986;&#24658;&#23450;&#30340;&#36807;&#22823;OOD&#25439;&#22833;&#65292;&#23613;&#31649;&#36798;&#21040;&#20102;&#38646;&#36807;&#22823;i
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17592v1 Announce Type: new  Abstract: In recent years, machine learning models have achieved success based on the independently and identically distributed assumption. However, this assumption can be easily violated in real-world applications, leading to the Out-of-Distribution (OOD) problem. Understanding how modern over-parameterized DNNs behave under non-trivial natural distributional shifts is essential, as current theoretical understanding is insufficient. Existing theoretical works often provide meaningless results for over-parameterized models in OOD scenarios or even contradict empirical findings. To this end, we are investigating the performance of the over-parameterized model in terms of OOD generalization under the general benign overfitting conditions. Our analysis focuses on a random feature model and examines non-trivial natural distributional shifts, where the benign overfitting estimators demonstrate a constant excess OOD loss, despite achieving zero excess i
&lt;/p&gt;</description></item><item><title>&#23558;&#22270;&#20687;&#22686;&#24378;&#19982;&#27979;&#35797;&#26102;&#38388;&#36866;&#24212;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;TECA&#65292;&#36890;&#36807;&#20943;&#23569;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#25552;&#39640;&#27169;&#22411;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.17423</link><description>&lt;p&gt;
&#27979;&#35797;&#26102;&#38388;&#36866;&#24212;&#36935;&#35265;&#22270;&#20687;&#22686;&#24378;:&#36890;&#36807;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#23545;&#25968;&#36716;&#25442;&#25552;&#39640;&#20934;&#30830;&#24615;
&lt;/p&gt;
&lt;p&gt;
Test-time Adaptation Meets Image Enhancement: Improving Accuracy via Uncertainty-aware Logit Switching
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17423
&lt;/p&gt;
&lt;p&gt;
&#23558;&#22270;&#20687;&#22686;&#24378;&#19982;&#27979;&#35797;&#26102;&#38388;&#36866;&#24212;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;TECA&#65292;&#36890;&#36807;&#20943;&#23569;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#25552;&#39640;&#27169;&#22411;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#21508;&#31181;&#35745;&#31639;&#26426;&#35270;&#35273;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#24403;&#25968;&#25454;&#20998;&#24067;&#22312;&#35757;&#32451;&#21644;&#27979;&#35797;&#20043;&#38388;&#21457;&#29983;&#20559;&#31227;&#26102;&#65292;&#20934;&#30830;&#24615;&#20250;&#19979;&#38477;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#27979;&#35797;&#26102;&#38388;&#36866;&#24212;&#65288;TTA&#65289;&#24050;&#34987;&#24191;&#27867;&#30740;&#31350;&#22240;&#20026;&#20854;&#23454;&#29992;&#24615;&#12290;&#34429;&#28982;TTA&#26041;&#27861;&#36890;&#36807;&#22312;&#27979;&#35797;&#26102;&#26356;&#26032;&#27169;&#22411;&#26469;&#25552;&#39640;&#22312;&#20998;&#24067;&#20559;&#31227;&#19979;&#30340;&#20934;&#30830;&#24615;&#65292;&#20294;&#20351;&#29992;&#39640;&#19981;&#30830;&#23450;&#24615;&#39044;&#27979;&#24050;&#30693;&#20250;&#38477;&#20302;&#20934;&#30830;&#24615;&#12290;&#30001;&#20110;&#36755;&#20837;&#22270;&#20687;&#26159;&#20998;&#24067;&#20559;&#31227;&#30340;&#26681;&#28304;&#65292;&#25105;&#20204;&#23558;&#19968;&#20010;&#26032;&#30340;&#35270;&#35282;&#34701;&#20837;&#21040;TTA&#26041;&#27861;&#20013;&#65292;&#36890;&#36807;&#22686;&#24378;&#36755;&#20837;&#22270;&#20687;&#26469;&#20943;&#23569;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#20551;&#35774;&#22686;&#24378;&#36755;&#20837;&#22270;&#20687;&#21487;&#20197;&#38477;&#20302;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#25552;&#39640;TTA&#26041;&#27861;&#30340;&#20934;&#30830;&#24615;&#12290;&#22522;&#20110;&#36825;&#19968;&#20551;&#35774;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65306;&#27979;&#35797;&#26102;&#38388;&#22686;&#24378;&#22120;&#21644;&#20998;&#31867;&#22120;&#36866;&#24212;&#65288;TECA&#65289;&#12290;&#22312;TECA&#20013;&#65292;&#20998;&#31867;&#27169;&#22411;&#19982;&#22686;&#24378;&#27169;&#22411;&#21516;&#26102;&#35757;&#32451;&#24182;&#22312;&#27979;&#35797;&#26102;&#36827;&#34892;&#36866;&#24212;&#65292;&#20197;&#25552;&#39640;&#27979;&#35797;&#26102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17423v1 Announce Type: cross  Abstract: Deep neural networks have achieved remarkable success in a variety of computer vision applications. However, there is a problem of degrading accuracy when the data distribution shifts between training and testing. As a solution of this problem, Test-time Adaptation~(TTA) has been well studied because of its practicality. Although TTA methods increase accuracy under distribution shift by updating the model at test time, using high-uncertainty predictions is known to degrade accuracy. Since the input image is the root of the distribution shift, we incorporate a new perspective on enhancing the input image into TTA methods to reduce the prediction's uncertainty. We hypothesize that enhancing the input image reduces prediction's uncertainty and increase the accuracy of TTA methods. On the basis of our hypothesis, we propose a novel method: Test-time Enhancer and Classifier Adaptation~(TECA). In TECA, the classification model is combined wi
&lt;/p&gt;</description></item><item><title>&#31070;&#32463;&#32593;&#32476;&#22914;Deep Sets&#21644;Transformers&#30340;&#20986;&#29616;&#26174;&#33879;&#25512;&#21160;&#20102;&#22522;&#20110;&#38598;&#21512;&#30340;&#25968;&#25454;&#22788;&#29702;&#30340;&#36827;&#23637;</title><link>https://arxiv.org/abs/2403.17410</link><description>&lt;p&gt;
&#35770;&#25490;&#21015;&#19981;&#21464;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
On permutation-invariant neural networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17410
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#22914;Deep Sets&#21644;Transformers&#30340;&#20986;&#29616;&#26174;&#33879;&#25512;&#21160;&#20102;&#22522;&#20110;&#38598;&#21512;&#30340;&#25968;&#25454;&#22788;&#29702;&#30340;&#36827;&#23637;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#36890;&#24120;&#22312;&#20551;&#35774;&#36755;&#20837;&#25968;&#25454;&#36981;&#24490;&#22522;&#20110;&#21521;&#37327;&#30340;&#26684;&#24335;&#30340;&#21069;&#25552;&#19979;&#35774;&#35745;&#65292;&#30528;&#37325;&#20110;&#22522;&#20110;&#21521;&#37327;&#30340;&#33539;&#24335;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#38656;&#27714;&#28041;&#21450;&#22522;&#20110;&#38598;&#21512;&#30340;&#20219;&#21153;&#30340;&#22686;&#38271;&#65292;&#30740;&#31350;&#30028;&#23545;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#30340;&#20852;&#36259;&#21457;&#29983;&#20102;&#33539;&#24335;&#36716;&#21464;&#12290;&#36817;&#24180;&#26469;&#65292;Deep Sets&#21644;Transformers&#31561;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#20986;&#29616;&#22312;&#22788;&#29702;&#22522;&#20110;&#38598;&#21512;&#30340;&#25968;&#25454;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#12290;&#36825;&#20123;&#26550;&#26500;&#19987;&#38376;&#35774;&#35745;&#20026;&#33258;&#28982;&#23481;&#32435;&#38598;&#21512;&#20316;&#20026;&#36755;&#20837;&#65292;&#20174;&#32780;&#26356;&#26377;&#25928;&#22320;&#34920;&#31034;&#21644;&#22788;&#29702;&#38598;&#21512;&#32467;&#26500;&#12290;&#22240;&#27492;&#65292;&#36817;&#24180;&#26469;&#20986;&#29616;&#20102;&#22823;&#37327;&#33268;&#21147;&#20110;&#25506;&#32034;&#21644;&#21033;&#29992;&#36825;&#20123;&#26550;&#26500;&#33021;&#21147;&#30340;&#30740;&#31350;&#21162;&#21147;&#65292;&#20197;&#36924;&#36817;&#38598;&#21512;&#20989;&#25968;&#30340;&#21508;&#31181;&#20219;&#21153;&#12290;&#36825;&#39033;&#32508;&#21512;&#35843;&#26597;&#26088;&#22312;&#27010;&#36848;th
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17410v1 Announce Type: cross  Abstract: Conventional machine learning algorithms have traditionally been designed under the assumption that input data follows a vector-based format, with an emphasis on vector-centric paradigms. However, as the demand for tasks involving set-based inputs has grown, there has been a paradigm shift in the research community towards addressing these challenges. In recent years, the emergence of neural network architectures such as Deep Sets and Transformers has presented a significant advancement in the treatment of set-based data. These architectures are specifically engineered to naturally accommodate sets as input, enabling more effective representation and processing of set structures. Consequently, there has been a surge of research endeavors dedicated to exploring and harnessing the capabilities of these architectures for various tasks involving the approximation of set functions. This comprehensive survey aims to provide an overview of th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#8220;&#24369;&#20449;&#21495;&#20998;&#26512;&#8221;&#26694;&#26550;&#65292;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#24448;&#36820;&#35774;&#35745;&#23545;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#20934;&#30830;&#24615;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#22312;&#22823;&#37096;&#20998;&#22870;&#21169;&#35823;&#24046;&#20026;&#27491;&#30456;&#20851;&#26102;&#65292;&#24448;&#36820;&#35774;&#35745;&#27604;&#27599;&#26085;&#20999;&#25442;&#31574;&#30053;&#26356;&#26377;&#25928;&#65292;&#22686;&#21152;&#25919;&#31574;&#20999;&#25442;&#39057;&#29575;&#21487;&#20197;&#38477;&#20302;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#22120;&#30340;&#22343;&#26041;&#35823;&#24046;&#12290;</title><link>https://arxiv.org/abs/2403.17285</link><description>&lt;p&gt;
&#23545;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#24448;&#36820;&#35774;&#35745;&#36827;&#34892;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
An Analysis of Switchback Designs in Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17285
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#8220;&#24369;&#20449;&#21495;&#20998;&#26512;&#8221;&#26694;&#26550;&#65292;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#24448;&#36820;&#35774;&#35745;&#23545;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#20934;&#30830;&#24615;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#22312;&#22823;&#37096;&#20998;&#22870;&#21169;&#35823;&#24046;&#20026;&#27491;&#30456;&#20851;&#26102;&#65292;&#24448;&#36820;&#35774;&#35745;&#27604;&#27599;&#26085;&#20999;&#25442;&#31574;&#30053;&#26356;&#26377;&#25928;&#65292;&#22686;&#21152;&#25919;&#31574;&#20999;&#25442;&#39057;&#29575;&#21487;&#20197;&#38477;&#20302;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#22120;&#30340;&#22343;&#26041;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;A/B&#27979;&#35797;&#20013;&#24448;&#36820;&#35774;&#35745;&#30340;&#35814;&#32454;&#30740;&#31350;&#65292;&#36825;&#20123;&#35774;&#35745;&#38543;&#26102;&#38388;&#22312;&#22522;&#20934;&#21644;&#26032;&#31574;&#30053;&#20043;&#38388;&#20132;&#26367;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20840;&#38754;&#35780;&#20272;&#36825;&#20123;&#35774;&#35745;&#23545;&#20854;&#20135;&#29983;&#30340;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#20272;&#35745;&#22120;&#20934;&#30830;&#24615;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#8220;&#24369;&#20449;&#21495;&#20998;&#26512;&#8221;&#26694;&#26550;&#65292;&#22823;&#22823;&#31616;&#21270;&#20102;&#36825;&#20123;ATE&#30340;&#22343;&#26041;&#35823;&#24046;&#65288;MSE&#65289;&#22312;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#29615;&#22659;&#20013;&#30340;&#35745;&#31639;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65306;(i) &#24403;&#22823;&#37096;&#20998;&#22870;&#21169;&#35823;&#24046;&#21576;&#27491;&#30456;&#20851;&#26102;&#65292;&#24448;&#36820;&#35774;&#35745;&#27604;&#27599;&#26085;&#20999;&#25442;&#31574;&#30053;&#30340;&#20132;&#26367;&#35774;&#35745;&#26356;&#26377;&#25928;&#12290;&#27492;&#22806;&#65292;&#22686;&#21152;&#25919;&#31574;&#20999;&#25442;&#30340;&#39057;&#29575;&#24448;&#24448;&#20250;&#38477;&#20302;ATE&#20272;&#35745;&#22120;&#30340;MSE&#12290;(ii) &#28982;&#32780;&#65292;&#24403;&#35823;&#24046;&#19981;&#30456;&#20851;&#26102;&#65292;&#25152;&#26377;&#36825;&#20123;&#35774;&#35745;&#21464;&#24471;&#28176;&#36817;&#31561;&#25928;&#12290;(iii) &#22312;&#22823;&#22810;&#25968;&#35823;&#24046;&#20026;&#36127;&#30456;&#20851;&#26102;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17285v1 Announce Type: cross  Abstract: This paper offers a detailed investigation of switchback designs in A/B testing, which alternate between baseline and new policies over time. Our aim is to thoroughly evaluate the effects of these designs on the accuracy of their resulting average treatment effect (ATE) estimators. We propose a novel "weak signal analysis" framework, which substantially simplifies the calculations of the mean squared errors (MSEs) of these ATEs in Markov decision process environments. Our findings suggest that (i) when the majority of reward errors are positively correlated, the switchback design is more efficient than the alternating-day design which switches policies in a daily basis. Additionally, increasing the frequency of policy switches tends to reduce the MSE of the ATE estimator. (ii) When the errors are uncorrelated, however, all these designs become asymptotically equivalent. (iii) In cases where the majority of errors are negative correlate
&lt;/p&gt;</description></item><item><title>DASA&#31639;&#27861;&#26159;&#31532;&#19968;&#20010;&#25910;&#25947;&#36895;&#24230;&#20165;&#20381;&#36182;&#20110;&#28151;&#21512;&#26102;&#38388;&#21644;&#24179;&#22343;&#24310;&#36831;&#30340;&#31639;&#27861;&#65292;&#21516;&#26102;&#22312;&#39532;&#23572;&#31185;&#22827;&#37319;&#26679;&#19979;&#23454;&#29616;N&#20493;&#30340;&#25910;&#25947;&#21152;&#36895;&#12290;</title><link>https://arxiv.org/abs/2403.17247</link><description>&lt;p&gt;
DASA: &#24310;&#36831;&#33258;&#36866;&#24212;&#22810;&#26234;&#33021;&#20307;&#38543;&#26426;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
DASA: Delay-Adaptive Multi-Agent Stochastic Approximation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17247
&lt;/p&gt;
&lt;p&gt;
DASA&#31639;&#27861;&#26159;&#31532;&#19968;&#20010;&#25910;&#25947;&#36895;&#24230;&#20165;&#20381;&#36182;&#20110;&#28151;&#21512;&#26102;&#38388;&#21644;&#24179;&#22343;&#24310;&#36831;&#30340;&#31639;&#27861;&#65292;&#21516;&#26102;&#22312;&#39532;&#23572;&#31185;&#22827;&#37319;&#26679;&#19979;&#23454;&#29616;N&#20493;&#30340;&#25910;&#25947;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#19968;&#31181;&#35774;&#32622;&#65292;&#20854;&#20013;$N$&#20010;&#26234;&#33021;&#20307;&#26088;&#22312;&#36890;&#36807;&#24182;&#34892;&#25805;&#20316;&#24182;&#19982;&#20013;&#22830;&#26381;&#21153;&#22120;&#36890;&#20449;&#26469;&#21152;&#36895;&#19968;&#20010;&#24120;&#35265;&#30340;&#38543;&#26426;&#36924;&#36817;&#65288;SA&#65289;&#38382;&#39064;&#12290;&#25105;&#20204;&#20551;&#23450;&#19978;&#34892;&#20256;&#36755;&#21040;&#26381;&#21153;&#22120;&#30340;&#20256;&#36755;&#21463;&#21040;&#24322;&#27493;&#21644;&#28508;&#22312;&#26080;&#30028;&#26102;&#21464;&#24310;&#36831;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#20943;&#36731;&#24310;&#36831;&#21644;&#33853;&#21518;&#32773;&#30340;&#24433;&#21709;&#65292;&#21516;&#26102;&#21448;&#33021;&#33719;&#24471;&#20998;&#24067;&#24335;&#35745;&#31639;&#30340;&#22909;&#22788;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DASA&#30340;&#24310;&#36831;&#33258;&#36866;&#24212;&#22810;&#26234;&#33021;&#20307;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#12290;&#25105;&#20204;&#23545;DASA&#36827;&#34892;&#20102;&#26377;&#38480;&#26102;&#38388;&#20998;&#26512;&#65292;&#20551;&#35774;&#26234;&#33021;&#20307;&#30340;&#38543;&#26426;&#35266;&#27979;&#36807;&#31243;&#26159;&#29420;&#31435;&#39532;&#23572;&#31185;&#22827;&#38142;&#12290;&#19982;&#29616;&#26377;&#32467;&#26524;&#30456;&#27604;&#65292;DASA&#26159;&#31532;&#19968;&#20010;&#20854;&#25910;&#25947;&#36895;&#24230;&#20165;&#21462;&#20915;&#20110;&#28151;&#21512;&#26102;&#38388;$tmix$&#21644;&#24179;&#22343;&#24310;&#36831;$\tau_{avg}$&#65292;&#21516;&#26102;&#22312;&#39532;&#23572;&#31185;&#22827;&#37319;&#26679;&#19979;&#23454;&#29616;N&#20493;&#30340;&#25910;&#25947;&#21152;&#36895;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#23545;&#20110;&#21508;&#31181;SA&#24212;&#29992;&#26159;&#30456;&#20851;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17247v1 Announce Type: new  Abstract: We consider a setting in which $N$ agents aim to speedup a common Stochastic Approximation (SA) problem by acting in parallel and communicating with a central server. We assume that the up-link transmissions to the server are subject to asynchronous and potentially unbounded time-varying delays. To mitigate the effect of delays and stragglers while reaping the benefits of distributed computation, we propose \texttt{DASA}, a Delay-Adaptive algorithm for multi-agent Stochastic Approximation. We provide a finite-time analysis of \texttt{DASA} assuming that the agents' stochastic observation processes are independent Markov chains. Significantly advancing existing results, \texttt{DASA} is the first algorithm whose convergence rate depends only on the mixing time $\tmix$ and on the average delay $\tau_{avg}$ while jointly achieving an $N$-fold convergence speedup under Markovian sampling. Our work is relevant for various SA applications, inc
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25552;&#20986;&#20102;&#23545;&#20110;&#33073;&#26426;&#31574;&#30053;&#35780;&#20272;&#20219;&#21153;&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#21463;&#32858;&#21512;&#39532;&#23572;&#31185;&#22827;&#36716;&#25442;&#27169;&#22411;&#20013;&#30340;&#27987;&#32553;&#31995;&#25968;&#25511;&#21046;&#65292;&#32780;&#19981;&#26159;&#21407;&#22987;MDP&#20013;&#30340;&#31995;&#25968;&#12290;</title><link>https://arxiv.org/abs/2403.17091</link><description>&lt;p&gt;
&#33073;&#26426;&#24378;&#21270;&#23398;&#20064;&#65306;&#29366;&#24577;&#32858;&#21512;&#21644;&#36712;&#36857;&#25968;&#25454;&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Offline Reinforcement Learning: Role of State Aggregation and Trajectory Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17091
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25552;&#20986;&#20102;&#23545;&#20110;&#33073;&#26426;&#31574;&#30053;&#35780;&#20272;&#20219;&#21153;&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#21463;&#32858;&#21512;&#39532;&#23572;&#31185;&#22827;&#36716;&#25442;&#27169;&#22411;&#20013;&#30340;&#27987;&#32553;&#31995;&#25968;&#25511;&#21046;&#65292;&#32780;&#19981;&#26159;&#21407;&#22987;MDP&#20013;&#30340;&#31995;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#20855;&#26377;&#20215;&#20540;&#20989;&#25968;&#21487;&#23454;&#29616;&#24615;&#20294;&#19981;&#20855;&#26377;&#36125;&#23572;&#26364;&#23436;&#22791;&#24615;&#30340;&#33073;&#26426;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#12290;&#25105;&#20204;&#23545;&#33073;&#26426;&#31574;&#30053;&#35780;&#20272;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#21463;&#32858;&#21512;&#39532;&#23572;&#31185;&#22827;&#36716;&#25442;&#27169;&#22411;&#20013;&#30340;&#27987;&#32553;&#31995;&#25968;&#25511;&#21046;&#30340;&#21457;&#29616;&#65292;&#20197;&#21450;&#25552;&#20379;&#20102;&#20165;&#20855;&#26377;&#20215;&#20540;&#20989;&#25968;&#21487;&#23454;&#29616;&#24615;&#30340;&#33073;&#26426;&#31574;&#30053;&#35780;&#20272;&#30340;&#30456;&#24403;&#23436;&#25972;&#30340;&#22270;&#26223;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#21457;&#29616;&#26377;&#19977;&#20010;&#65306;1&#65289;&#33073;&#26426;&#31574;&#30053;&#35780;&#20272;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30001;&#32858;&#21512;&#30340;&#39532;&#23572;&#31185;&#22827;&#36716;&#25442;&#27169;&#22411;&#20013;&#30340;&#38598;&#20013;&#31995;&#25968;&#20915;&#23450;&#65292;&#36825;&#20010;&#31995;&#25968;&#30001;&#20989;&#25968;&#31867;&#21644;&#33073;&#26426;&#25968;&#25454;&#20998;&#24067;&#20849;&#21516;&#30830;&#23450;&#65292;&#32780;&#19981;&#26159;&#21407;&#22987;MDP&#20013;&#30340;&#31995;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17091v1 Announce Type: cross  Abstract: We revisit the problem of offline reinforcement learning with value function realizability but without Bellman completeness. Previous work by Xie and Jiang (2021) and Foster et al. (2022) left open the question whether a bounded concentrability coefficient along with trajectory-based offline data admits a polynomial sample complexity. In this work, we provide a negative answer to this question for the task of offline policy evaluation. In addition to addressing this question, we provide a rather complete picture for offline policy evaluation with only value function realizability. Our primary findings are threefold: 1) The sample complexity of offline policy evaluation is governed by the concentrability coefficient in an aggregated Markov Transition Model jointly determined by the function class and the offline data distribution, rather than that in the original MDP. This unifies and generalizes the ideas of Xie and Jiang (2021) and Fo
&lt;/p&gt;</description></item><item><title>&#24320;&#21457;&#20102;&#19968;&#20010;&#31639;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#23558;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#36890;&#29992;&#38750;&#32447;&#24615;&#36870;&#30340;&#34920;&#36798;&#25968;&#25454;&#20808;&#39564;&#12290;</title><link>https://arxiv.org/abs/2403.17042</link><description>&lt;p&gt;
&#21487;&#35777;&#23454;&#40065;&#26834;&#30340;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#21518;&#39564;&#37319;&#26679;&#29992;&#20110;&#21363;&#25554;&#21363;&#29992;&#22270;&#20687;&#37325;&#24314;
&lt;/p&gt;
&lt;p&gt;
Provably Robust Score-Based Diffusion Posterior Sampling for Plug-and-Play Image Reconstruction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17042
&lt;/p&gt;
&lt;p&gt;
&#24320;&#21457;&#20102;&#19968;&#20010;&#31639;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#23558;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#36890;&#29992;&#38750;&#32447;&#24615;&#36870;&#30340;&#34920;&#36798;&#25968;&#25454;&#20808;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#30340;&#35768;&#22810;&#20219;&#21153;&#20013;&#65292;&#30446;&#26631;&#26159;&#20174;&#24050;&#30693;&#25551;&#36848;&#26576;&#31181;&#24863;&#30693;&#25110;&#25104;&#20687;&#27169;&#24335;&#30340;&#24050;&#30693;&#21069;&#21521;&#27169;&#22411;&#25910;&#38598;&#30340;&#23569;&#37327;&#27979;&#37327;&#20013;&#25512;&#26029;&#26410;&#30693;&#22270;&#20687;&#12290;&#30001;&#20110;&#36164;&#28304;&#38480;&#21046;&#65292;&#36825;&#20010;&#20219;&#21153;&#36890;&#24120;&#38750;&#24120;&#19981;&#36866;&#21512;&#65292;&#36825;&#23601;&#38656;&#35201;&#37319;&#32435;&#34920;&#36798;&#20016;&#23500;&#30340;&#20808;&#39564;&#20449;&#24687;&#26469;&#35268;&#33539;&#35299;&#31354;&#38388;&#12290;&#30001;&#20110;&#20854;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#32463;&#39564;&#25104;&#21151;&#65292;&#22522;&#20110;&#20998;&#25968;&#30340;&#25193;&#25955;&#27169;&#22411;&#24050;&#32463;&#25104;&#20026;&#22270;&#20687;&#37325;&#24314;&#20013;&#19968;&#20010;&#20855;&#26377;&#21560;&#24341;&#21147;&#30340;&#34920;&#36798;&#20808;&#39564;&#30340;&#20505;&#36873;&#32773;&#12290;&#20026;&#20102;&#19968;&#27425;&#24615;&#23481;&#32435;&#22810;&#26679;&#30340;&#20219;&#21153;&#65292;&#24320;&#21457;&#23558;&#22270;&#20687;&#20808;&#39564;&#20998;&#24067;&#30340;&#26080;&#26465;&#20214;&#35780;&#20998;&#20989;&#25968;&#19982;&#28789;&#27963;&#30340;&#21069;&#21521;&#27169;&#22411;&#36873;&#25321;&#30456;&#32467;&#21512;&#30340;&#39640;&#25928;&#12289;&#19968;&#33268;&#21644;&#40065;&#26834;&#31639;&#27861;&#38750;&#24120;&#37325;&#35201;&#12290;&#36825;&#39033;&#24037;&#20316;&#24320;&#21457;&#20102;&#19968;&#20010;&#31639;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#23558;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#36890;&#29992;&#38750;&#32447;&#24615;&#36870;&#30340;&#34920;&#36798;&#25968;&#25454;&#20808;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17042v1 Announce Type: cross  Abstract: In a great number of tasks in science and engineering, the goal is to infer an unknown image from a small number of measurements collected from a known forward model describing certain sensing or imaging modality. Due to resource constraints, this task is often extremely ill-posed, which necessitates the adoption of expressive prior information to regularize the solution space. Score-based diffusion models, due to its impressive empirical success, have emerged as an appealing candidate of an expressive prior in image reconstruction. In order to accommodate diverse tasks at once, it is of great interest to develop efficient, consistent and robust algorithms that incorporate {\em unconditional} score functions of an image prior distribution in conjunction with flexible choices of forward models.   This work develops an algorithmic framework for employing score-based diffusion models as an expressive data prior in general nonlinear invers
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#22522;&#20110;&#21306;&#22495;&#31283;&#23450;&#24615;&#30340;&#26041;&#27861;&#65292;&#25512;&#23548;&#20986;&#20102;&#38543;&#26426;&#26862;&#26519;&#39044;&#27979;&#30340;&#39640;&#26031;&#36924;&#36817;&#30028;&#38480;&#65292;&#24182;&#24314;&#31435;&#20102;&#36866;&#29992;&#20110;&#21508;&#31181;&#30456;&#20851;&#32479;&#35745;&#38382;&#39064;&#30340;&#27010;&#29575;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.09960</link><description>&lt;p&gt;
&#36890;&#36807;&#22522;&#20110;&#21306;&#22495;&#31283;&#23450;&#24615;&#30340;&#22810;&#20803;&#39640;&#26031;&#36924;&#36817;&#25913;&#36827;&#38543;&#26426;&#26862;&#26519;
&lt;/p&gt;
&lt;p&gt;
Multivariate Gaussian Approximation for Random Forest via Region-based Stabilization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09960
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#22522;&#20110;&#21306;&#22495;&#31283;&#23450;&#24615;&#30340;&#26041;&#27861;&#65292;&#25512;&#23548;&#20986;&#20102;&#38543;&#26426;&#26862;&#26519;&#39044;&#27979;&#30340;&#39640;&#26031;&#36924;&#36817;&#30028;&#38480;&#65292;&#24182;&#24314;&#31435;&#20102;&#36866;&#29992;&#20110;&#21508;&#31181;&#30456;&#20851;&#32479;&#35745;&#38382;&#39064;&#30340;&#27010;&#29575;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#32473;&#23450;&#30001;&#27850;&#26494;&#36807;&#31243;&#20135;&#29983;&#30340;&#19968;&#32452;&#35757;&#32451;&#28857;&#30340;&#24773;&#20917;&#19979;&#65292;&#25512;&#23548;&#20102;&#38543;&#26426;&#26862;&#26519;&#39044;&#27979;&#30340;&#39640;&#26031;&#36924;&#36817;&#30028;&#38480;&#65292;&#20551;&#35774;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#23384;&#22312;&#30456;&#24403;&#28201;&#21644;&#30340;&#27491;&#21017;&#24615;&#20551;&#35774;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#19968;&#20010;&#20851;&#38190;&#35266;&#23519;&#65306;&#38543;&#26426;&#26862;&#26519;&#30340;&#39044;&#27979;&#28385;&#36275;&#19968;&#23450;&#30340;&#31216;&#20026;&#22522;&#20110;&#21306;&#22495;&#31283;&#23450;&#24615;&#30340;&#20960;&#20309;&#23646;&#24615;&#12290;&#22312;&#20026;&#38543;&#26426;&#26862;&#26519;&#24320;&#21457;&#32467;&#26524;&#30340;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#36824;&#20026;&#22522;&#20110;&#21306;&#22495;&#31283;&#23450;&#30340;&#27850;&#26494;&#36807;&#31243;&#30340;&#19968;&#33324;&#27867;&#20989;&#24314;&#31435;&#20102;&#19968;&#20010;&#27010;&#29575;&#32467;&#26524;&#65292;&#36825;&#21487;&#33021;&#26159;&#29420;&#31435;&#24863;&#20852;&#36259;&#30340;&#12290;&#36825;&#19968;&#26222;&#36941;&#32467;&#26524;&#21033;&#29992;&#20102;Malliavin-Stein&#26041;&#27861;&#65292;&#24182;&#19988;&#21487;&#33021;&#36866;&#29992;&#20110;&#21508;&#31181;&#30456;&#20851;&#30340;&#32479;&#35745;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09960v1 Announce Type: cross  Abstract: We derive Gaussian approximation bounds for random forest predictions based on a set of training points given by a Poisson process, under fairly mild regularity assumptions on the data generating process. Our approach is based on the key observation that the random forest predictions satisfy a certain geometric property called region-based stabilization. In the process of developing our results for the random forest, we also establish a probabilistic result, which might be of independent interest, on multivariate Gaussian approximation bounds for general functionals of Poisson process that are region-based stabilizing. This general result makes use of the Malliavin-Stein method, and is potentially applicable to various related statistical problems.
&lt;/p&gt;</description></item><item><title>&#28145;&#24230;&#23398;&#20064;&#30340;&#29702;&#35770;&#26041;&#38754;&#20173;&#19981;&#28165;&#26970;&#65292;&#26412;&#30740;&#31350;&#36890;&#36807;&#23558;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#24212;&#29992;&#20110;&#28145;&#24230;&#23398;&#20064;&#65292;&#25506;&#35752;&#20102;&#19981;&#21516;&#26550;&#26500;&#22312;&#22522;&#20110;&#26799;&#24230;&#26041;&#27861;&#35757;&#32451;&#26102;&#21487;&#33021;&#23548;&#33268;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#24182;&#35814;&#32454;&#30740;&#31350;&#20102;&#38544;&#21547;&#20559;&#24046;&#30340;&#25968;&#37327;&#21270;&#34920;&#31034;&#12290;</title><link>https://arxiv.org/abs/2311.15404</link><description>&lt;p&gt;
&#23558;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#24212;&#29992;&#20110;&#28145;&#24230;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Applying statistical learning theory to deep learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.15404
&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#29702;&#35770;&#26041;&#38754;&#20173;&#19981;&#28165;&#26970;&#65292;&#26412;&#30740;&#31350;&#36890;&#36807;&#23558;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#24212;&#29992;&#20110;&#28145;&#24230;&#23398;&#20064;&#65292;&#25506;&#35752;&#20102;&#19981;&#21516;&#26550;&#26500;&#22312;&#22522;&#20110;&#26799;&#24230;&#26041;&#27861;&#35757;&#32451;&#26102;&#21487;&#33021;&#23548;&#33268;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#24182;&#35814;&#32454;&#30740;&#31350;&#20102;&#38544;&#21547;&#20559;&#24046;&#30340;&#25968;&#37327;&#21270;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35299;&#30417;&#30563;&#23398;&#20064;&#30340;&#22362;&#23454;&#26694;&#26550;&#65292;&#20294;&#28145;&#24230;&#23398;&#20064;&#30340;&#35768;&#22810;&#29702;&#35770;&#26041;&#38754;&#20173;&#28982;&#19981;&#28165;&#26970;&#65292;&#29305;&#21035;&#26159;&#22312;&#20351;&#29992;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;&#19981;&#21516;&#30340;&#26550;&#26500;&#22914;&#20309;&#23548;&#33268;&#24402;&#32435;&#20559;&#24046;&#12290;&#36825;&#20123;&#35762;&#24231;&#30340;&#30446;&#26631;&#26159;&#20174;&#23398;&#20064;&#29702;&#35770;&#30340;&#35282;&#24230;&#25552;&#20379;&#20102;&#35299;&#28145;&#24230;&#23398;&#20064;&#26102;&#20986;&#29616;&#30340;&#19968;&#20123;&#20027;&#35201;&#38382;&#39064;&#30340;&#27010;&#35272;&#12290;&#22312;&#31616;&#35201;&#22238;&#39038;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#21644;&#38543;&#26426;&#20248;&#21270;&#20043;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#22312;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#32972;&#26223;&#19979;&#30340;&#38544;&#21547;&#20559;&#24046;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23545;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#36827;&#34892;&#19968;&#33324;&#24615;&#25551;&#36848;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#22914;&#20309;&#22312;&#32473;&#23450;&#23398;&#20064;&#38382;&#39064;&#30340;&#21442;&#25968;&#31354;&#38388;&#21644;&#30456;&#24212;&#30340;&#20989;&#25968;&#31354;&#38388;&#20043;&#38388;&#26469;&#22238;&#31227;&#21160;&#65292;&#20197;&#21450;&#23398;&#20064;&#38382;&#39064;&#30340;&#20960;&#20309;&#24615;&#36136;&#22914;&#20309;&#21487;&#20197;&#29992;&#24230;&#37327;&#24352;&#37327;&#34920;&#31034;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#23545;&#25968;&#37327;&#21270;&#38544;&#21547;&#20559;&#24046;&#30340;&#20855;&#20307;&#30740;&#31350;&#36827;&#34892;&#20102;&#35814;&#32454;&#25506;&#35752;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.15404v2 Announce Type: replace  Abstract: Although statistical learning theory provides a robust framework to understand supervised learning, many theoretical aspects of deep learning remain unclear, in particular how different architectures may lead to inductive bias when trained using gradient based methods. The goal of these lectures is to provide an overview of some of the main questions that arise when attempting to understand deep learning from a learning theory perspective. After a brief reminder on statistical learning theory and stochastic optimization, we discuss implicit bias in the context of benign overfitting. We then move to a general description of the mirror descent algorithm, showing how we may go back and forth between a parameter space and the corresponding function space for a given learning problem, as well as how the geometry of the learning problem may be represented by a metric tensor. Building on this framework, we provide a detailed study of the im
&lt;/p&gt;</description></item><item><title>&#40654;&#26364;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#30340;&#26032;&#26041;&#27861;&#21033;&#29992;Fisher&#24230;&#37327;&#25552;&#20379;&#26356;&#20016;&#23500;&#30340;&#36924;&#36817;&#26063;&#65292;&#35299;&#20915;&#20102;&#22312;&#26080;&#38480;&#25968;&#25454;&#26497;&#38480;&#19979;&#20808;&#21069;&#26041;&#27861;&#24230;&#37327;&#36873;&#25321;&#19981;&#24403;&#23548;&#33268;&#36924;&#36817;&#36807;&#20110;&#29421;&#31364;&#21644;&#26377;&#20559;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2311.02766</link><description>&lt;p&gt;
&#20855;&#26377;Fisher&#24230;&#37327;&#30340;&#40654;&#26364;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Riemannian Laplace Approximation with the Fisher Metric
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.02766
&lt;/p&gt;
&lt;p&gt;
&#40654;&#26364;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#30340;&#26032;&#26041;&#27861;&#21033;&#29992;Fisher&#24230;&#37327;&#25552;&#20379;&#26356;&#20016;&#23500;&#30340;&#36924;&#36817;&#26063;&#65292;&#35299;&#20915;&#20102;&#22312;&#26080;&#38480;&#25968;&#25454;&#26497;&#38480;&#19979;&#20808;&#21069;&#26041;&#27861;&#24230;&#37327;&#36873;&#25321;&#19981;&#24403;&#23548;&#33268;&#36924;&#36817;&#36807;&#20110;&#29421;&#31364;&#21644;&#26377;&#20559;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Laplace&#26041;&#27861;&#29992;&#39640;&#26031;&#20998;&#24067;&#22312;&#20854;&#27169;&#24335;&#22788;&#23545;&#30446;&#26631;&#23494;&#24230;&#36827;&#34892;&#36817;&#20284;&#12290;&#22522;&#20110;Bernstein-von Mises&#23450;&#29702;&#65292;&#23427;&#22312;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#26159;&#35745;&#31639;&#25928;&#29575;&#39640;&#19988;&#28176;&#36817;&#20934;&#30830;&#30340;&#65292;&#20294;&#23545;&#20110;&#22797;&#26434;&#30340;&#30446;&#26631;&#21644;&#26377;&#38480;&#25968;&#25454;&#21518;&#39564;&#65292;&#23427;&#24448;&#24448;&#26159;&#19968;&#31181;&#36807;&#20110;&#31895;&#31961;&#30340;&#36817;&#20284;&#12290;&#26368;&#36817;&#23545;Laplace&#36924;&#36817;&#30340;&#19968;&#33324;&#21270;&#26159;&#26681;&#25454;&#36873;&#25321;&#30340;&#40654;&#26364;&#20960;&#20309;&#23545;&#39640;&#26031;&#36817;&#20284;&#36827;&#34892;&#36716;&#25442;&#65292;&#25552;&#20379;&#20102;&#26356;&#20016;&#23500;&#30340;&#36817;&#20284;&#26063;&#65292;&#21516;&#26102;&#20445;&#25345;&#35745;&#31639;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#27491;&#22914;&#26412;&#25991;&#25152;&#31034;&#65292;&#20854;&#24615;&#36136;&#20005;&#37325;&#20381;&#36182;&#20110;&#25152;&#36873;&#25321;&#30340;&#24230;&#37327;&#65292;&#23454;&#38469;&#19978;&#65292;&#22312;&#20808;&#21069;&#30740;&#31350;&#20013;&#37319;&#29992;&#30340;&#24230;&#37327;&#23548;&#33268;&#30340;&#36924;&#36817;&#21363;&#20351;&#22312;&#26080;&#38480;&#25968;&#25454;&#37327;&#30340;&#26497;&#38480;&#19979;&#20063;&#36807;&#20110;&#29421;&#31364;&#19988;&#23384;&#22312;&#20559;&#24046;&#12290;&#25105;&#20204;&#36890;&#36807;&#36827;&#19968;&#27493;&#21457;&#23637;&#36924;&#36817;&#26063;&#65292;&#25512;&#23548;&#20986;&#20004;&#31181;&#22312;&#26080;&#38480;&#25968;&#25454;&#26497;&#38480;&#19979;&#31934;&#30830;&#30340;&#26367;&#20195;&#21464;&#31181;&#65292;&#25193;&#23637;&#20102;&#29702;&#35770;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.02766v3 Announce Type: replace  Abstract: Laplace's method approximates a target density with a Gaussian distribution at its mode. It is computationally efficient and asymptotically exact for Bayesian inference due to the Bernstein-von Mises theorem, but for complex targets and finite-data posteriors it is often too crude an approximation. A recent generalization of the Laplace Approximation transforms the Gaussian approximation according to a chosen Riemannian geometry providing a richer approximation family, while still retaining computational efficiency. However, as shown here, its properties depend heavily on the chosen metric, indeed the metric adopted in previous work results in approximations that are overly narrow as well as being biased even at the limit of infinite data. We correct this shortcoming by developing the approximation family further, deriving two alternative variants that are exact at the limit of infinite data, extending the theoretical analysis of the
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38754;&#21521;&#23618;&#27425;&#21270;&#25968;&#25454;&#24314;&#27169;&#30340;&#20998;&#24067;&#26080;&#20851;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#32447;&#24615;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#20013;&#36873;&#21462;&#32676;&#20307;&#29305;&#24615;&#26469;&#25552;&#39640;&#35299;&#20915;&#38382;&#39064;&#30340;&#25928;&#29575;&#65292;&#24182;&#22312;&#29983;&#25104;&#31232;&#30095;&#35299;&#26041;&#38754;&#34920;&#29616;&#20986;&#26356;&#39640;&#30340;&#39044;&#27979;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2302.03157</link><description>&lt;p&gt;
&#19968;&#20010;&#38754;&#21521;&#23618;&#27425;&#21270;&#24314;&#27169;&#30340;&#20998;&#24067;&#26080;&#20851;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A distribution-free mixed-integer optimization approach to hierarchical modelling of clustered and longitudinal data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.03157
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38754;&#21521;&#23618;&#27425;&#21270;&#25968;&#25454;&#24314;&#27169;&#30340;&#20998;&#24067;&#26080;&#20851;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#32447;&#24615;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#20013;&#36873;&#21462;&#32676;&#20307;&#29305;&#24615;&#26469;&#25552;&#39640;&#35299;&#20915;&#38382;&#39064;&#30340;&#25928;&#29575;&#65292;&#24182;&#22312;&#29983;&#25104;&#31232;&#30095;&#35299;&#26041;&#38754;&#34920;&#29616;&#20986;&#26356;&#39640;&#30340;&#39044;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;&#65288;MIO&#65289;&#31639;&#27861;&#30340;&#36827;&#23637;&#65292;&#32467;&#21512;&#30828;&#20214;&#22686;&#24378;&#65292;&#22823;&#22823;&#21152;&#24555;&#20102;&#35299;&#20915;MIO&#38382;&#39064;&#30340;&#36895;&#24230;&#12290;&#36825;&#20123;&#31574;&#30053;&#24050;&#34987;&#29992;&#20110;&#26368;&#20248;&#23376;&#38598;&#36873;&#25321;&#65292;&#29305;&#21035;&#26159;&#22312;&#32447;&#24615;&#22238;&#24402;&#20013;&#22312;&#32473;&#23450;$n$&#35266;&#27979;&#30340;&#24773;&#20917;&#19979;&#36873;&#25321;$k$&#20010;&#29305;&#24449;&#20013;&#30340;$p$&#20010;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#36825;&#31181;&#26041;&#27861;&#25193;&#23637;&#21040;&#20419;&#36827;&#32676;&#38598;&#24863;&#30693;&#22238;&#24402;&#65292;&#36873;&#25321;$LMM$&#27169;&#22411;&#30340;$K$&#20010;&#32676;&#38598;&#20013;&#30340;$\lambda$&#20010;&#65292;&#27599;&#20010;&#32676;&#38598;&#26377;$n_k$&#20010;&#35266;&#27979;&#12290;&#36890;&#36807;&#23545;&#22810;&#31181;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#20840;&#38754;&#27979;&#35797;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#22312;&#20960;&#20998;&#38047;&#20869;&#39640;&#25928;&#22320;&#35299;&#20915;&#38382;&#39064;&#12290;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;MIO&#26041;&#27861;&#22312;&#29983;&#25104;&#20855;&#26377;&#39640;&#39044;&#27979;&#33021;&#21147;&#30340;&#31232;&#30095;&#35299;&#26041;&#38754;&#20248;&#20110;&#39640;&#26031;&#20998;&#24067;&#21644;&#25289;&#26222;&#25289;&#26031;&#20998;&#24067;LMM&#12290;&#20256;&#32479;&#30340;LMM&#36890;&#24120;&#20551;&#35774;&#32858;&#31867;&#25928;&#26524;&#20026;
&lt;/p&gt;
&lt;p&gt;
arXiv:2302.03157v2 Announce Type: replace-cross  Abstract: Recent advancements in Mixed Integer Optimization (MIO) algorithms, paired with hardware enhancements, have led to significant speedups in resolving MIO problems. These strategies have been utilized for optimal subset selection, specifically for choosing $k$ features out of $p$ in linear regression given $n$ observations. In this paper, we broaden this method to facilitate cluster-aware regression, where selection aims to choose $\lambda$ out of $K$ clusters in a linear mixed effects (LMM) model with $n_k$ observations for each cluster. Through comprehensive testing on a multitude of synthetic and real datasets, we exhibit that our method efficiently solves problems within minutes. Through numerical experiments, we also show that the MIO approach outperforms both Gaussian- and Laplace-distributed LMMs in terms of generating sparse solutions with high predictive power. Traditional LMMs typically assume that clustering effects ar
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#37325;&#26032;&#21046;&#23450;&#28151;&#21512;&#25972;&#25968;&#38750;&#32447;&#24615;&#35268;&#21010;&#38382;&#39064;&#65292;&#20197;&#20248;&#21270;&#36870;&#21464;&#22120;&#30340;&#30005;&#21387;/&#26080;&#21151;&#25511;&#21046;&#35268;&#21017;&#35774;&#35745;&#12290;</title><link>https://arxiv.org/abs/2211.09557</link><description>&lt;p&gt;
&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#20248;&#21270;&#36870;&#21464;&#22120;&#30340;&#30005;&#21387;/&#26080;&#21151;&#25511;&#21046;&#35268;&#21017;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Optimal Design of Volt/VAR Control Rules of Inverters using Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2211.09557
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#37325;&#26032;&#21046;&#23450;&#28151;&#21512;&#25972;&#25968;&#38750;&#32447;&#24615;&#35268;&#21010;&#38382;&#39064;&#65292;&#20197;&#20248;&#21270;&#36870;&#21464;&#22120;&#30340;&#30005;&#21387;/&#26080;&#21151;&#25511;&#21046;&#35268;&#21017;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37197;&#30005;&#32593;&#38754;&#20020;&#30001;&#20998;&#24067;&#24335;&#33021;&#28304;&#36164;&#28304;&#65288;DERs&#65289;&#21487;&#21464;&#21151;&#29575;&#27880;&#20837;&#24341;&#36215;&#30340;&#30005;&#21387;&#24555;&#36895;&#27874;&#21160;&#30340;&#25361;&#25112;&#12290;&#20026;&#20102;&#35843;&#33410;&#30005;&#21387;&#65292;IEEE&#26631;&#20934;1547&#24314;&#35758;&#27599;&#20010;DER&#26681;&#25454;&#20998;&#27573;&#32447;&#24615;&#30340;&#30005;&#21387;/&#26080;&#21151;&#25511;&#21046;&#35268;&#21017;&#27880;&#20837;&#26080;&#21151;&#21151;&#29575;&#12290;&#23613;&#31649;&#35813;&#26631;&#20934;&#24314;&#35758;&#20102;&#40664;&#35748;&#24418;&#29366;&#65292;&#20294;&#35268;&#21017;&#21487;&#20197;&#25353;&#27597;&#32447;&#33258;&#23450;&#20041;&#12290;&#26368;&#20248;&#35268;&#21017;&#35774;&#35745;&#65288;ORD&#65289;&#30340;&#20219;&#21153;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#30005;&#21387;/&#26080;&#21151;&#35268;&#21017;&#24341;&#20837;&#38750;&#32447;&#24615;&#21160;&#24577;&#65292;&#24182;&#23384;&#22312;&#31283;&#23450;&#24615;&#21644;&#31283;&#24577;&#30005;&#21387;&#36718;&#24275;&#20043;&#38388;&#30340;&#25240;&#34935;&#12290; ORD&#34987;&#21046;&#23450;&#20026;&#28151;&#21512;&#25972;&#25968;&#38750;&#32447;&#24615;&#35268;&#21010;&#65288;MINLP&#65289;&#65292;&#20294;&#22312;&#38382;&#39064;&#35268;&#27169;&#19978;&#24182;&#19981;&#29702;&#24819;&#12290;&#20026;&#20102;&#25214;&#21040;&#26356;&#39640;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#25105;&#20204;&#23558;ORD&#37325;&#26032;&#21046;&#23450;&#20026;&#28145;&#24230;&#23398;&#20064;&#38382;&#39064;&#12290;&#20854;&#24605;&#24819;&#26159;&#35774;&#35745;&#19968;&#20010;&#27169;&#25311;&#30005;&#21387;/&#26080;&#21151;&#21160;&#24577;&#30340;DNN&#12290;DNN&#20197;&#30005;&#32593;&#22330;&#26223;&#20026;&#36755;&#20837;&#65292;&#35268;&#21017;&#21442;&#25968;&#20026;&#26435;&#37325;&#65292;&#36755;&#20986;&#24179;&#34913;&#30005;&#21387;&#12290;&#36890;&#36807;&#35757;&#32451;&#21487;&#20197;&#25214;&#21040;&#26368;&#20339;&#35268;&#21017;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2211.09557v2 Announce Type: replace-cross  Abstract: Distribution grids are challenged by rapid voltage fluctuations induced by variable power injections from distributed energy resources (DERs). To regulate voltage, the IEEE Standard 1547 recommends each DER inject reactive power according to piecewise-affine Volt/VAR control rules. Although the standard suggests a default shape, the rule can be customized per bus. This task of optimal rule design (ORD) is challenging as Volt/VAR rules introduce nonlinear dynamics, and lurk trade-offs between stability and steady-state voltage profiles. ORD is formulated as a mixed-integer nonlinear program (MINLP), but scales unfavorably with the problem size. Towards a more efficient solution, we reformulate ORD as a deep learning problem. The idea is to design a DNN that emulates Volt/VAR dynamics. The DNN takes grid scenarios as inputs, rule parameters as weights, and outputs equilibrium voltages. Optimal rule parameters can be found by trai
&lt;/p&gt;</description></item><item><title>&#24046;&#20998;&#31169;&#26377;&#22810;&#21464;&#37327;&#20013;&#20301;&#25968;&#30340;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#20445;&#35777;&#20026;&#24120;&#29992;&#28145;&#24230;&#20989;&#25968;&#25552;&#20379;&#20102;&#23574;&#38160;&#30340;&#32467;&#26524;&#65292;&#34920;&#26126;&#37325;&#23614;&#20301;&#32622;&#20272;&#35745;&#30340;&#25104;&#26412;&#36229;&#36807;&#20102;&#38544;&#31169;&#20445;&#25252;&#25104;&#26412;&#12290;</title><link>https://arxiv.org/abs/2210.06459</link><description>&lt;p&gt;
&#24046;&#20998;&#31169;&#26377;&#22810;&#21464;&#37327;&#20013;&#20301;&#25968;
&lt;/p&gt;
&lt;p&gt;
Differentially private multivariate medians
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2210.06459
&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#31169;&#26377;&#22810;&#21464;&#37327;&#20013;&#20301;&#25968;&#30340;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#20445;&#35777;&#20026;&#24120;&#29992;&#28145;&#24230;&#20989;&#25968;&#25552;&#20379;&#20102;&#23574;&#38160;&#30340;&#32467;&#26524;&#65292;&#34920;&#26126;&#37325;&#23614;&#20301;&#32622;&#20272;&#35745;&#30340;&#25104;&#26412;&#36229;&#36807;&#20102;&#38544;&#31169;&#20445;&#25252;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#25968;&#25454;&#20998;&#26512;&#38656;&#35201;&#28385;&#36275;&#20005;&#26684;&#38544;&#31169;&#20445;&#35777;&#30340;&#32479;&#35745;&#24037;&#20855;&#12290;&#20247;&#25152;&#21608;&#30693;&#65292;&#23545;&#27745;&#26579;&#30340;&#40065;&#26834;&#24615;&#19982;&#24046;&#20998;&#38544;&#31169;&#26377;&#20851;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#20351;&#29992;&#22810;&#20803;&#20013;&#20301;&#25968;&#36827;&#34892;&#24046;&#20998;&#31169;&#26377;&#21644;&#40065;&#26834;&#30340;&#22810;&#20803;&#20301;&#32622;&#20272;&#35745;&#23578;&#26410;&#24471;&#21040;&#31995;&#32479;&#30740;&#31350;&#12290;&#25105;&#20204;&#20026;&#24046;&#20998;&#31169;&#26377;&#22810;&#20803;&#28145;&#24230;&#20013;&#20301;&#25968;&#24320;&#21457;&#20102;&#26032;&#39062;&#30340;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#20445;&#35777;&#65292;&#36825;&#20123;&#20445;&#35777;&#22522;&#26412;&#19978;&#26159;&#23574;&#38160;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#28085;&#30422;&#20102;&#24120;&#29992;&#30340;&#28145;&#24230;&#20989;&#25968;&#65292;&#22914;&#21322;&#24179;&#38754;&#65288;&#25110;Tukey&#65289;&#28145;&#24230;&#65292;&#31354;&#38388;&#28145;&#24230;&#21644;&#38598;&#25104;&#21452;&#28145;&#24230;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#26607;&#35199;&#36793;&#38469;&#19979;&#65292;&#37325;&#23614;&#20301;&#32622;&#20272;&#35745;&#30340;&#20195;&#20215;&#36229;&#36807;&#20102;&#38544;&#31169;&#30340;&#20195;&#20215;&#12290;&#25105;&#20204;&#22312;&#39640;&#36798;d = 100&#30340;&#32500;&#24230;&#19978;&#20351;&#29992;&#39640;&#26031;&#27745;&#26579;&#27169;&#22411;&#36827;&#34892;&#20102;&#25968;&#20540;&#28436;&#31034;&#65292;&#24182;&#23558;&#20854;&#19982;&#26368;&#20808;&#36827;&#30340;&#31169;&#26377;&#22343;&#20540;&#20272;&#35745;&#31639;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#20316;&#20026;&#25105;&#20204;&#30740;&#31350;&#30340;&#19968;&#20010;&#21103;&#20135;&#21697;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2210.06459v2 Announce Type: replace-cross  Abstract: Statistical tools which satisfy rigorous privacy guarantees are necessary for modern data analysis. It is well-known that robustness against contamination is linked to differential privacy. Despite this fact, using multivariate medians for differentially private and robust multivariate location estimation has not been systematically studied. We develop novel finite-sample performance guarantees for differentially private multivariate depth-based medians, which are essentially sharp. Our results cover commonly used depth functions, such as the halfspace (or Tukey) depth, spatial depth, and the integrated dual depth. We show that under Cauchy marginals, the cost of heavy-tailed location estimation outweighs the cost of privacy. We demonstrate our results numerically using a Gaussian contamination model in dimensions up to d = 100, and compare them to a state-of-the-art private mean estimation algorithm. As a by-product of our inv
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#26041;&#24046;&#20943;&#23569;&#26426;&#21046;&#30340;&#21322;&#20809;&#28369;&#29275;&#39039;&#38543;&#26426;&#36817;&#31471;&#28857;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#19981;&#31934;&#30830;&#30340;&#26694;&#26550;&#19979;&#35299;&#20915;&#36817;&#31471;&#28857;&#26356;&#26032;&#65292;&#23454;&#29616;&#20102;&#23545;&#24369;&#20984;&#24615;&#12289;&#22797;&#21512;&#20248;&#21270;&#38382;&#39064;&#30340;&#26377;&#25928;&#27714;&#35299;&#12290;</title><link>https://arxiv.org/abs/2204.00406</link><description>&lt;p&gt;
&#20855;&#26377;&#26041;&#24046;&#20943;&#23569;&#30340;&#21322;&#20809;&#28369;&#29275;&#39039;&#38543;&#26426;&#36817;&#31471;&#28857;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Semismooth Newton Stochastic Proximal Point Algorithm with Variance Reduction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2204.00406
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#26041;&#24046;&#20943;&#23569;&#26426;&#21046;&#30340;&#21322;&#20809;&#28369;&#29275;&#39039;&#38543;&#26426;&#36817;&#31471;&#28857;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#19981;&#31934;&#30830;&#30340;&#26694;&#26550;&#19979;&#35299;&#20915;&#36817;&#31471;&#28857;&#26356;&#26032;&#65292;&#23454;&#29616;&#20102;&#23545;&#24369;&#20984;&#24615;&#12289;&#22797;&#21512;&#20248;&#21270;&#38382;&#39064;&#30340;&#26377;&#25928;&#27714;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20026;&#19968;&#31867;&#24369;&#20984;&#24615;&#12289;&#22797;&#21512;&#20248;&#21270;&#38382;&#39064;&#24320;&#21457;&#20102;&#19968;&#20010;&#21487;&#23454;&#26045;&#30340;&#38543;&#26426;&#36817;&#31471;&#28857;&#65288;SPP&#65289;&#26041;&#27861;&#12290;&#25152;&#25552;&#20986;&#30340;&#38543;&#26426;&#36817;&#31471;&#28857;&#31639;&#27861;&#34701;&#21512;&#20102;&#26041;&#24046;&#20943;&#23569;&#26426;&#21046;&#65292;&#30001;&#20110;&#37319;&#29992;&#20102;&#19981;&#31934;&#30830;&#30340;&#21322;&#20809;&#28369;&#29275;&#39039;&#26694;&#26550;&#26469;&#27714;&#35299;&#24471;&#21040;&#30340;SPP&#26356;&#26032;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#35814;&#32454;&#30340;&#25910;&#25947;&#24615;&#32467;&#26524;&#65292;&#32771;&#34385;&#20102;SPP&#27493;&#39588;&#30340;&#19981;&#31934;&#30830;&#24615;&#65292;&#24182;&#31526;&#21512;&#65288;&#36817;&#31471;&#65289;&#38543;&#26426;&#26041;&#24046;&#20943;&#23569;&#26799;&#24230;&#26041;&#27861;&#30340;&#29616;&#26377;&#25910;&#25947;&#20445;&#35777;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#19982;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#31454;&#20105;&#20248;&#21183;&#65292;&#24182;&#22312;&#27493;&#38271;&#36873;&#25321;&#26041;&#38754;&#20855;&#26377;&#26356;&#39640;&#30340;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2204.00406v3 Announce Type: replace-cross  Abstract: We develop an implementable stochastic proximal point (SPP) method for a class of weakly convex, composite optimization problems. The proposed stochastic proximal point algorithm incorporates a variance reduction mechanism and the resulting SPP updates are solved using an inexact semismooth Newton framework. We establish detailed convergence results that take the inexactness of the SPP steps into account and that are in accordance with existing convergence guarantees of (proximal) stochastic variance-reduced gradient methods. Numerical experiments show that the proposed algorithm competes favorably with other state-of-the-art methods and achieves higher robustness with respect to the step size selection.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20855;&#26377;&#21487;&#21464;&#31995;&#25968;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#21457;&#29616;&#30340;&#20808;&#36827;&#36125;&#21494;&#26031;&#31232;&#30095;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#38408;&#20540;&#36125;&#21494;&#26031;&#32452;Lasso&#22238;&#24402;&#21644;Gibbs&#37319;&#26679;&#22120;&#25552;&#39640;&#20102;&#31283;&#20581;&#24615;&#21644;&#20943;&#36731;&#20102;&#35745;&#31639;&#36127;&#25285;</title><link>https://arxiv.org/abs/2102.01432</link><description>&lt;p&gt;
&#24102;&#21487;&#21464;&#31995;&#25968;&#30340;&#36125;&#21494;&#26031;&#25968;&#25454;&#39537;&#21160;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Bayesian data-driven discovery of partial differential equations with variable coefficients
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2102.01432
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20855;&#26377;&#21487;&#21464;&#31995;&#25968;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#21457;&#29616;&#30340;&#20808;&#36827;&#36125;&#21494;&#26031;&#31232;&#30095;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#38408;&#20540;&#36125;&#21494;&#26031;&#32452;Lasso&#22238;&#24402;&#21644;Gibbs&#37319;&#26679;&#22120;&#25552;&#39640;&#20102;&#31283;&#20581;&#24615;&#21644;&#20943;&#36731;&#20102;&#35745;&#31639;&#36127;&#25285;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDEs&#65289;&#30340;&#21457;&#29616;&#26159;&#24212;&#29992;&#31185;&#23398;&#21644;&#24037;&#31243;&#30340;&#37325;&#35201;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#25968;&#25454;&#39537;&#21160;&#30340;PDEs&#21457;&#29616;&#36890;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#20027;&#35201;&#26159;&#30001;&#20110;&#25152;&#21457;&#29616;&#26041;&#31243;&#23545;&#22122;&#22768;&#30340;&#25935;&#24863;&#24615;&#20197;&#21450;&#27169;&#22411;&#36873;&#25321;&#30340;&#22797;&#26434;&#24615;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20808;&#36827;&#30340;&#36125;&#21494;&#26031;&#31232;&#30095;&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#20855;&#26377;&#21487;&#21464;&#31995;&#25968;&#30340;PDE&#21457;&#29616;&#65292;&#23588;&#20854;&#26159;&#24403;&#31995;&#25968;&#22312;&#31354;&#38388;&#25110;&#26102;&#38388;&#19978;&#20855;&#26377;&#30456;&#20851;&#24615;&#26102;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#24212;&#29992;&#20102;&#20855;&#26377;&#23574;&#23792;&#21644;&#24179;&#26495;&#20808;&#39564;&#30340;&#38408;&#20540;&#36125;&#21494;&#26031;&#32452;Lasso&#22238;&#24402;&#65288;tBGL-SS&#65289;&#65292;&#24182;&#21033;&#29992;Gibbs&#37319;&#26679;&#22120;&#26469;&#23545;PDE&#31995;&#25968;&#36827;&#34892;&#36125;&#21494;&#26031;&#21518;&#39564;&#20272;&#35745;&#12290;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#22686;&#24378;&#20102;&#28857;&#20272;&#35745;&#30340;&#31283;&#20581;&#24615;&#24182;&#20855;&#26377;&#26377;&#25928;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#32780;&#19988;&#36890;&#36807;&#23558;&#31995;&#25968;&#38408;&#20540;&#38598;&#25104;&#20026;&#36817;&#20284;MCMC&#26041;&#27861;&#65292;&#20943;&#36731;&#20102;&#26469;&#33258;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#35745;&#31639;&#36127;&#25285;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2102.01432v2 Announce Type: replace-cross  Abstract: The discovery of Partial Differential Equations (PDEs) is an essential task for applied science and engineering. However, data-driven discovery of PDEs is generally challenging, primarily stemming from the sensitivity of the discovered equation to noise and the complexities of model selection. In this work, we propose an advanced Bayesian sparse learning algorithm for PDE discovery with variable coefficients, predominantly when the coefficients are spatially or temporally dependent. Specifically, we apply threshold Bayesian group Lasso regression with a spike-and-slab prior (tBGL-SS) and leverage a Gibbs sampler for Bayesian posterior estimation of PDE coefficients. This approach not only enhances the robustness of point estimation with valid uncertainty quantification but also relaxes the computational burden from Bayesian inference through the integration of coefficient thresholds as an approximate MCMC method. Moreover, from
&lt;/p&gt;</description></item><item><title>PPI++&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#39044;&#27979;&#39537;&#21160;&#25512;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#21160;&#35843;&#25972;&#39044;&#27979;&#36136;&#37327;&#26469;&#25913;&#21892;&#32463;&#20856;&#21306;&#38388;&#30340;&#35745;&#31639;&#32622;&#20449;&#21306;&#38388;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#32479;&#35745;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2311.01453</link><description>&lt;p&gt;
PPI++:&#39640;&#25928;&#30340;&#39044;&#27979;&#39537;&#21160;&#25512;&#29702;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
PPI++: Efficient Prediction-Powered Inference. (arXiv:2311.01453v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01453
&lt;/p&gt;
&lt;p&gt;
PPI++&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#39044;&#27979;&#39537;&#21160;&#25512;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#21160;&#35843;&#25972;&#39044;&#27979;&#36136;&#37327;&#26469;&#25913;&#21892;&#32463;&#20856;&#21306;&#38388;&#30340;&#35745;&#31639;&#32622;&#20449;&#21306;&#38388;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#32479;&#35745;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;PPI++&#65306;&#19968;&#31181;&#22522;&#20110;&#23567;&#22411;&#26631;&#35760;&#25968;&#25454;&#38598;&#21644;&#36890;&#24120;&#27604;&#36739;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#25968;&#25454;&#38598;&#30340;&#35745;&#31639;&#36731;&#37327;&#32423;&#30340;&#20272;&#35745;&#21644;&#25512;&#29702;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#33258;&#21160;&#36866;&#24212;&#21487;&#29992;&#39044;&#27979;&#30340;&#36136;&#37327;&#65292;&#20135;&#29983;&#26131;&#20110;&#35745;&#31639;&#30340;&#32622;&#20449;&#21306;&#38388; - &#23545;&#20110;&#20219;&#24847;&#32500;&#24230;&#30340;&#21442;&#25968; - &#24635;&#26159;&#33021;&#22815;&#22312;&#21482;&#20351;&#29992;&#26631;&#35760;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#25913;&#21892;&#32463;&#20856;&#21306;&#38388;&#12290;PPI++&#22522;&#20110;&#39044;&#27979;&#39537;&#21160;&#25512;&#29702;&#65288;PPI&#65289;&#65292;&#38024;&#23545;&#30456;&#21516;&#30340;&#38382;&#39064;&#22330;&#26223;&#65292;&#25552;&#39640;&#20102;&#35745;&#31639;&#21644;&#32479;&#35745;&#25928;&#29575;&#12290;&#30495;&#23454;&#21644;&#21512;&#25104;&#23454;&#39564;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#25913;&#36827;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present PPI++: a computationally lightweight methodology for estimation and inference based on a small labeled dataset and a typically much larger dataset of machine-learning predictions. The methods automatically adapt to the quality of available predictions, yielding easy-to-compute confidence sets -for parameters of any dimensionality -- that always improve on classical intervals using only the labeled data. PPI++ builds on prediction-powered inference (PPI), which targets the same problem setting, improving its computational and statistical efficiency. Real and synthetic experiments demonstrate the benefits of the proposed adaptations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;Entropy-MCMC&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#36741;&#21161;&#30340;&#24341;&#23548;&#21464;&#37327;&#26469;&#22312;&#24179;&#22374;&#30406;&#22320;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#20197;&#35299;&#20915;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#20998;&#24067;&#30340;&#22810;&#27169;&#24577;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.05401</link><description>&lt;p&gt;
Entropy-MCMC: &#36731;&#26494;&#20174;&#24179;&#22374;&#30406;&#22320;&#36827;&#34892;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Entropy-MCMC: Sampling from Flat Basins with Ease. (arXiv:2310.05401v1 [cs.LG] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05401
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;Entropy-MCMC&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#36741;&#21161;&#30340;&#24341;&#23548;&#21464;&#37327;&#26469;&#22312;&#24179;&#22374;&#30406;&#22320;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#20197;&#35299;&#20915;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#20998;&#24067;&#30340;&#22810;&#27169;&#24577;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#20381;&#36182;&#20110;&#23545;&#21518;&#39564;&#20998;&#24067;&#30340;&#36136;&#37327;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#21518;&#39564;&#20998;&#24067;&#22312;&#24615;&#36136;&#19978;&#26159;&#39640;&#24230;&#22810;&#27169;&#24577;&#30340;&#65292;&#23616;&#37096;&#27169;&#24335;&#34920;&#29616;&#20986;&#19981;&#21516;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#22312;&#26377;&#38480;&#30340;&#35745;&#31639;&#36164;&#28304;&#19979;&#65292;&#20174;&#21407;&#22987;&#21518;&#39564;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#21487;&#33021;&#20250;&#23548;&#33268;&#27425;&#20248;&#24615;&#33021;&#65292;&#22240;&#20026;&#19968;&#20123;&#26679;&#26412;&#21487;&#33021;&#20250;&#38519;&#20837;&#8220;&#22351;&#8221;&#27169;&#24335;&#24182;&#20986;&#29616;&#36807;&#25311;&#21512;&#12290;&#22522;&#20110;&#35266;&#23519;&#21040;&#20302;&#27867;&#21270;&#35823;&#24046;&#30340;&#8220;&#22909;&#8221;&#27169;&#24335;&#36890;&#24120;&#23384;&#22312;&#20110;&#33021;&#37327;&#26223;&#35266;&#30340;&#24179;&#22374;&#30406;&#22320;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#20559;&#32622;&#37319;&#26679;&#26397;&#21521;&#36825;&#20123;&#24179;&#22374;&#21306;&#22495;&#30340;&#21518;&#39564;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#36741;&#21161;&#24341;&#23548;&#21464;&#37327;&#65292;&#20854;&#31283;&#24577;&#20998;&#24067;&#31867;&#20284;&#20110;&#24179;&#28369;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#19988;&#27809;&#26377;&#23574;&#38160;&#30340;&#27169;&#24577;&#65292;&#20197;&#24341;&#23548;MCMC&#37319;&#26679;&#22120;&#22312;&#24179;&#22374;&#30340;&#30406;&#22320;&#20013;&#37319;&#26679;&#12290;&#36890;&#36807;&#23558;&#27492;&#24341;&#23548;&#21464;&#37327;&#19982;&#27169;&#22411;&#21442;&#25968;&#30456;&#32467;&#21512;&#65292;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#32852;&#21512;&#20998;&#24067;&#65292;&#21487;&#20197;&#22312;&#26368;&#23567;&#35745;&#31639;&#24320;&#38144;&#19979;&#23454;&#29616;&#39640;&#25928;&#37319;&#26679;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#20803;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian deep learning counts on the quality of posterior distribution estimation. However, the posterior of deep neural networks is highly multi-modal in nature, with local modes exhibiting varying generalization performance. Given a practical budget, sampling from the original posterior can lead to suboptimal performance, as some samples may become trapped in "bad" modes and suffer from overfitting. Leveraging the observation that "good" modes with low generalization error often reside in flat basins of the energy landscape, we propose to bias sampling on the posterior toward these flat regions. Specifically, we introduce an auxiliary guiding variable, the stationary distribution of which resembles a smoothed posterior free from sharp modes, to lead the MCMC sampler to flat basins. By integrating this guiding variable with the model parameter, we create a simple joint distribution that enables efficient sampling with minimal computational overhead. We prove the convergence of our met
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#37327;&#21270;&#35780;&#20272;&#20998;&#31867;&#38543;&#26426;&#26862;&#26519;&#30340;&#35823;&#24046;&#20272;&#35745;&#26041;&#27861;&#65292;&#21457;&#29616;&#38543;&#26426;&#26862;&#26519;&#30340;&#39044;&#27979;&#35823;&#24046;&#20272;&#35745;&#27604;&#24179;&#22343;&#39044;&#27979;&#35823;&#24046;&#26356;&#25509;&#36817;&#30495;&#23454;&#35823;&#24046;&#29575;&#65292;&#24182;&#19988;&#36825;&#19968;&#32467;&#26524;&#36866;&#29992;&#20110;&#19981;&#21516;&#30340;&#35823;&#24046;&#20272;&#35745;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2309.00736</link><description>&lt;p&gt;
&#38543;&#26426;&#26862;&#26519;&#20013;&#30340;&#39044;&#27979;&#35823;&#24046;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Prediction Error Estimation in Random Forests. (arXiv:2309.00736v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00736
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#37327;&#21270;&#35780;&#20272;&#20998;&#31867;&#38543;&#26426;&#26862;&#26519;&#30340;&#35823;&#24046;&#20272;&#35745;&#26041;&#27861;&#65292;&#21457;&#29616;&#38543;&#26426;&#26862;&#26519;&#30340;&#39044;&#27979;&#35823;&#24046;&#20272;&#35745;&#27604;&#24179;&#22343;&#39044;&#27979;&#35823;&#24046;&#26356;&#25509;&#36817;&#30495;&#23454;&#35823;&#24046;&#29575;&#65292;&#24182;&#19988;&#36825;&#19968;&#32467;&#26524;&#36866;&#29992;&#20110;&#19981;&#21516;&#30340;&#35823;&#24046;&#20272;&#35745;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23450;&#37327;&#35780;&#20272;&#20102;&#20998;&#31867;&#38543;&#26426;&#26862;&#26519;&#30340;&#35823;&#24046;&#20272;&#35745;&#12290;&#22312;Bates&#31561;&#20154;&#65288;2023&#24180;&#65289;&#24314;&#31435;&#30340;&#21021;&#27493;&#29702;&#35770;&#26694;&#26550;&#30340;&#22522;&#30784;&#19978;&#65292;&#20174;&#29702;&#35770;&#21644;&#32463;&#39564;&#35282;&#24230;&#25506;&#35752;&#20102;&#38543;&#26426;&#26862;&#26519;&#20013;&#24120;&#35265;&#30340;&#21508;&#31181;&#35823;&#24046;&#20272;&#35745;&#26041;&#27861;&#22312;&#30495;&#23454;&#35823;&#24046;&#29575;&#21644;&#26399;&#26395;&#35823;&#24046;&#29575;&#26041;&#38754;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#20998;&#31867;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#26862;&#26519;&#30340;&#39044;&#27979;&#35823;&#24046;&#20272;&#35745;&#24179;&#22343;&#26356;&#25509;&#36817;&#30495;&#23454;&#35823;&#24046;&#29575;&#65292;&#32780;&#19981;&#26159;&#24179;&#22343;&#39044;&#27979;&#35823;&#24046;&#12290;&#19982;Bates&#31561;&#20154;&#65288;2023&#24180;&#65289;&#23545;&#36923;&#36753;&#22238;&#24402;&#30340;&#30740;&#31350;&#32467;&#26524;&#30456;&#21453;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#65292;&#36825;&#20010;&#32467;&#26524;&#36866;&#29992;&#20110;&#20132;&#21449;&#39564;&#35777;&#12289;&#33258;&#20030;&#21644;&#25968;&#25454;&#21010;&#20998;&#31561;&#19981;&#21516;&#30340;&#35823;&#24046;&#20272;&#35745;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, error estimates of classification Random Forests are quantitatively assessed. Based on the initial theoretical framework built by Bates et al. (2023), the true error rate and expected error rate are theoretically and empirically investigated in the context of a variety of error estimation methods common to Random Forests. We show that in the classification case, Random Forests' estimates of prediction error is closer on average to the true error rate instead of the average prediction error. This is opposite the findings of Bates et al. (2023) which were given for logistic regression. We further show that this result holds across different error estimation strategies such as cross-validation, bagging, and data splitting.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23558;&#36125;&#32034;&#22827;&#36807;&#31243;&#25512;&#24191;&#21040;&#26102;&#31354;&#39046;&#22495;&#65292;&#20197;&#26356;&#22909;&#22320;&#22788;&#29702;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#20013;&#30340;&#26102;&#31354;&#37325;&#24314;&#12290;&#36890;&#36807;&#26367;&#25442;&#38543;&#26426;&#31995;&#25968;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20445;&#25345;&#36793;&#32536;&#29305;&#24449;&#24182;&#27169;&#25311;&#21160;&#24577;&#21464;&#21270;&#22270;&#20687;&#30340;&#26102;&#31354;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.16378</link><description>&lt;p&gt;
&#36125;&#32034;&#22827;&#20808;&#39564;&#22312;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#20013;&#30340;&#26102;&#31354;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Spatiotemporal Besov Priors for Bayesian Inverse Problems. (arXiv:2306.16378v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16378
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23558;&#36125;&#32034;&#22827;&#36807;&#31243;&#25512;&#24191;&#21040;&#26102;&#31354;&#39046;&#22495;&#65292;&#20197;&#26356;&#22909;&#22320;&#22788;&#29702;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#20013;&#30340;&#26102;&#31354;&#37325;&#24314;&#12290;&#36890;&#36807;&#26367;&#25442;&#38543;&#26426;&#31995;&#25968;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20445;&#25345;&#36793;&#32536;&#29305;&#24449;&#24182;&#27169;&#25311;&#21160;&#24577;&#21464;&#21270;&#22270;&#20687;&#30340;&#26102;&#31354;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#31185;&#23398;&#25216;&#26415;&#30340;&#24555;&#36895;&#21457;&#23637;&#20419;&#20351;&#23545;&#25429;&#25417;&#25968;&#25454;&#29305;&#24449;&#65288;&#22914;&#31361;&#21464;&#25110;&#26126;&#26174;&#23545;&#27604;&#24230;&#65289;&#30340;&#36866;&#24403;&#32479;&#35745;&#24037;&#20855;&#30340;&#38656;&#27714;&#12290;&#35768;&#22810;&#25968;&#25454;&#31185;&#23398;&#24212;&#29992;&#38656;&#35201;&#20174;&#20855;&#26377;&#19981;&#36830;&#32493;&#24615;&#25110;&#22855;&#24322;&#24615;&#30340;&#26102;&#38388;&#30456;&#20851;&#23545;&#35937;&#24207;&#21015;&#20013;&#36827;&#34892;&#26102;&#31354;&#37325;&#24314;&#65292;&#22914;&#24102;&#26377;&#36793;&#32536;&#30340;&#21160;&#24577;&#35745;&#31639;&#26426;&#26029;&#23618;&#24433;&#20687;&#65288;CT&#65289;&#22270;&#20687;&#12290;&#20256;&#32479;&#30340;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#30340;&#26041;&#27861;&#21487;&#33021;&#26080;&#27861;&#25552;&#20379;&#20196;&#20154;&#28385;&#24847;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#22240;&#20026;&#23427;&#20204;&#24448;&#24448;&#25552;&#20379;&#36807;&#24230;&#24179;&#28369;&#30340;&#20808;&#39564;&#20505;&#36873;&#12290;&#26368;&#36817;&#65292;&#36890;&#36807;&#38543;&#26426;&#31995;&#25968;&#30340;&#23567;&#27874;&#23637;&#24320;&#23450;&#20041;&#30340;&#36125;&#32034;&#22827;&#36807;&#31243;&#65288;BP&#65289;&#34987;&#25552;&#20986;&#20316;&#20026;&#36825;&#31867;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#30340;&#26356;&#21512;&#36866;&#30340;&#20808;&#39564;&#12290;BP&#22312;&#25104;&#20687;&#20998;&#26512;&#20013;&#34920;&#29616;&#20986;&#20248;&#20110;GP&#30340;&#24615;&#33021;&#65292;&#33021;&#22815;&#20135;&#29983;&#20445;&#30041;&#36793;&#32536;&#29305;&#24449;&#30340;&#37325;&#24314;&#32467;&#26524;&#65292;&#20294;&#27809;&#26377;&#33258;&#21160;&#22320;&#32435;&#20837;&#21160;&#24577;&#21464;&#21270;&#22270;&#20687;&#20013;&#30340;&#26102;&#38388;&#30456;&#20851;&#24615;&#12290;&#26412;&#25991;&#23558;BP&#25512;&#24191;&#21040;&#26102;&#31354;&#39046;&#22495;&#65288;STBP&#65289;&#65292;&#36890;&#36807;&#22312;&#23567;&#27874;&#23637;&#24320;&#20013;&#26367;&#25442;&#38543;&#26426;&#31995;&#25968;&#65292;&#23454;&#29616;&#20102;&#26102;&#31354;&#30456;&#20851;&#24615;&#30340;&#24314;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fast development in science and technology has driven the need for proper statistical tools to capture special data features such as abrupt changes or sharp contrast. Many applications in the data science seek spatiotemporal reconstruction from a sequence of time-dependent objects with discontinuity or singularity, e.g. dynamic computerized tomography (CT) images with edges. Traditional methods based on Gaussian processes (GP) may not provide satisfactory solutions since they tend to offer over-smooth prior candidates. Recently, Besov process (BP) defined by wavelet expansions with random coefficients has been proposed as a more appropriate prior for this type of Bayesian inverse problems. While BP outperforms GP in imaging analysis to produce edge-preserving reconstructions, it does not automatically incorporate temporal correlation inherited in the dynamically changing images. In this paper, we generalize BP to the spatiotemporal domain (STBP) by replacing the random coefficients in 
&lt;/p&gt;</description></item><item><title>Omega&#26159;&#19968;&#31181;&#20248;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#21152;&#20837;&#21382;&#21490;&#26799;&#24230;EMA&#26469;&#20943;&#36731;&#22122;&#22768;&#30340;&#24433;&#21709;&#24182;&#22312;&#38543;&#26426;&#28216;&#25103;&#19978;&#34920;&#29616;&#26356;&#20339;&#12290;</title><link>http://arxiv.org/abs/2306.07905</link><description>&lt;p&gt;
Omega: &#20048;&#35266;EMA Gradients
&lt;/p&gt;
&lt;p&gt;
Omega: Optimistic EMA Gradients. (arXiv:2306.07905v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07905
&lt;/p&gt;
&lt;p&gt;
Omega&#26159;&#19968;&#31181;&#20248;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#21152;&#20837;&#21382;&#21490;&#26799;&#24230;EMA&#26469;&#20943;&#36731;&#22122;&#22768;&#30340;&#24433;&#21709;&#24182;&#22312;&#38543;&#26426;&#28216;&#25103;&#19978;&#34920;&#29616;&#26356;&#20339;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;GAN&#21644;&#23545;&#25239;&#24615;&#35757;&#32451;&#30340;&#36827;&#27493;&#65292;&#38543;&#26426;min-max&#20248;&#21270;&#21463;&#21040;&#20102;&#26426;&#22120;&#23398;&#20064;&#30028;&#30340;&#20851;&#27880;&#12290;&#23613;&#31649;&#30830;&#23450;&#24615;&#29366;&#24577;&#19979;&#30340;&#21338;&#24328;&#20248;&#21270;&#24050;&#32463;&#30456;&#24403;&#22909;&#22320;&#29702;&#35299;&#20102;&#65292;&#20294;&#22312;&#38543;&#26426;&#29366;&#24577;&#19979;&#20173;&#23384;&#22312;&#19968;&#20123;&#38382;&#39064;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#20687;&#20048;&#35266;&#26799;&#24230;&#36825;&#26679;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;-&#19978;&#21319;&#26041;&#27861;&#23545;&#22122;&#22768;&#38750;&#24120;&#25935;&#24863;&#25110;&#32773;&#20250;&#23548;&#33268;&#22833;&#36133;&#12290;&#34429;&#28982;&#23384;&#22312;&#26367;&#20195;&#31574;&#30053;&#65292;&#20294;&#36825;&#20123;&#31574;&#30053;&#21487;&#33021;&#25104;&#26412;&#36807;&#39640;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;Omega&#65292;&#19968;&#31181;&#20855;&#26377;&#31867;&#20284;&#20110;&#20048;&#35266;&#26356;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#20854;&#26356;&#26032;&#35268;&#21017;&#20013;&#21512;&#24182;&#21382;&#21490;&#26799;&#24230;&#30340;EMA&#26469;&#20943;&#36731;&#22122;&#22768;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#19968;&#31181;&#21253;&#21547;&#21160;&#37327;&#30340;&#35813;&#31639;&#27861;&#30340;&#21464;&#20307;&#12290;&#34429;&#28982;&#25105;&#20204;&#27809;&#26377;&#25552;&#20379;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#20294;&#25105;&#20204;&#22312;&#38543;&#26426;&#28216;&#25103;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#24403;&#24212;&#29992;&#20110;&#32447;&#24615;&#29609;&#23478;&#26102;&#65292;Omega&#20248;&#20110;&#20048;&#35266;&#26799;&#24230;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic min-max optimization has gained interest in the machine learning community with the advancements in GANs and adversarial training. Although game optimization is fairly well understood in the deterministic setting, some issues persist in the stochastic regime. Recent work has shown that stochastic gradient descent-ascent methods such as the optimistic gradient are highly sensitive to noise or can fail to converge. Although alternative strategies exist, they can be prohibitively expensive. We introduce Omega, a method with optimistic-like updates that mitigates the impact of noise by incorporating an EMA of historic gradients in its update rule. We also explore a variation of this algorithm that incorporates momentum. Although we do not provide convergence guarantees, our experiments on stochastic games show that Omega outperforms the optimistic gradient method when applied to linear players.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#22810;&#20010;&#32467;&#26500;&#39044;&#27979;&#26631;&#20934;&#27979;&#35797;&#20013;&#31934;&#30830;&#35782;&#21035;&#21547;&#26377;100&#20010;&#20197;&#19978;&#21407;&#23376;&#30340;&#35768;&#22810;&#26448;&#26009;&#30340;&#20840;&#23616;&#26368;&#23567;&#32467;&#26500;&#65292;&#24182;&#20197;&#21333;&#27425;&#33021;&#37327;&#35780;&#20272;&#20026;&#22522;&#30784;&#65292;&#21462;&#20195;&#20102;&#37325;&#22797;&#30340;&#31532;&#19968;&#21407;&#29702;&#33021;&#37327;&#35745;&#31639;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2305.02158</link><description>&lt;p&gt;
&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#30340;&#24418;&#25104;&#33021;&#37327;&#39044;&#27979;&#26041;&#27861;&#36827;&#34892;&#29454;&#26538;&#26230;&#20307;&#32467;&#26500;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Shotgun crystal structure prediction using machine-learned formation energies. (arXiv:2305.02158v1 [physics.comp-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02158
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#22810;&#20010;&#32467;&#26500;&#39044;&#27979;&#26631;&#20934;&#27979;&#35797;&#20013;&#31934;&#30830;&#35782;&#21035;&#21547;&#26377;100&#20010;&#20197;&#19978;&#21407;&#23376;&#30340;&#35768;&#22810;&#26448;&#26009;&#30340;&#20840;&#23616;&#26368;&#23567;&#32467;&#26500;&#65292;&#24182;&#20197;&#21333;&#27425;&#33021;&#37327;&#35780;&#20272;&#20026;&#22522;&#30784;&#65292;&#21462;&#20195;&#20102;&#37325;&#22797;&#30340;&#31532;&#19968;&#21407;&#29702;&#33021;&#37327;&#35745;&#31639;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#20197;&#36890;&#36807;&#25214;&#21040;&#21407;&#23376;&#26500;&#22411;&#33021;&#37327;&#26354;&#38754;&#30340;&#20840;&#23616;&#25110;&#23616;&#37096;&#26497;&#23567;&#20540;&#26469;&#39044;&#27979;&#32452;&#35013;&#21407;&#23376;&#30340;&#31283;&#23450;&#25110;&#20122;&#31283;&#23450;&#26230;&#20307;&#32467;&#26500;&#12290;&#36890;&#24120;&#65292;&#36825;&#38656;&#35201;&#37325;&#22797;&#30340;&#31532;&#19968;&#21407;&#29702;&#33021;&#37327;&#35745;&#31639;&#65292;&#36825;&#22312;&#21253;&#21547;30&#20010;&#20197;&#19978;&#21407;&#23376;&#30340;&#22823;&#22411;&#31995;&#32479;&#20013;&#26159;&#19981;&#23454;&#38469;&#30340;&#12290;&#26412;&#30740;&#31350;&#20351;&#29992;&#31616;&#21333;&#20294;&#21151;&#33021;&#24378;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#24037;&#20316;&#27969;&#65292;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#36741;&#21161;&#31532;&#19968;&#21407;&#29702;&#33021;&#37327;&#35745;&#31639;&#65292;&#23545;&#22823;&#37327;&#34394;&#25311;&#21019;&#24314;&#30340;&#26230;&#20307;&#32467;&#26500;&#36827;&#34892;&#38750;&#36845;&#20195;&#24335;&#21333;&#27425;&#31579;&#36873;&#65292;&#20174;&#32780;&#22312;&#35299;&#20915;&#26230;&#20307;&#32467;&#26500;&#39044;&#27979;&#38382;&#39064;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stable or metastable crystal structures of assembled atoms can be predicted by finding the global or local minima of the energy surface with respect to the atomic configurations. Generally, this requires repeated first-principles energy calculations that are impractical for large systems, such as those containing more than 30 atoms in the unit cell. Here, we have made significant progress in solving the crystal structure prediction problem with a simple but powerful machine-learning workflow; using a machine-learning surrogate for first-principles energy calculations, we performed non-iterative, single-shot screening using a large library of virtually created crystal structures. The present method relies on two key technical components: transfer learning, which enables a highly accurate energy prediction of pre-relaxed crystalline states given only a small set of training samples from first-principles calculations, and generative models to create promising and diverse crystal structure
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#27835;&#30103;&#19981;&#26381;&#20174;&#24615;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#21442;&#25968;&#26694;&#26550;&#26469;&#35780;&#20272;&#22240;&#26524;&#20013;&#20171;&#25928;&#24212;&#65292;&#25552;&#20986;&#20102;&#19968;&#32452;&#20551;&#35774;&#26469;&#35782;&#21035;&#33258;&#28982;&#20013;&#20171;&#25928;&#24212;&#24182;&#25512;&#23548;&#20986;&#25104;&#20493;&#31283;&#20581;&#20272;&#35745;&#22120;&#12290;</title><link>http://arxiv.org/abs/2304.10025</link><description>&lt;p&gt;
&#29992;&#20110;&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;&#20013;&#20855;&#26377;&#27835;&#30103;&#19981;&#26381;&#20174;&#24615;&#30340;&#35782;&#21035;&#21644;&#20493;&#22686;&#31283;&#20581;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Identification and multiply robust estimation in causal mediation analysis with treatment noncompliance. (arXiv:2304.10025v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10025
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#27835;&#30103;&#19981;&#26381;&#20174;&#24615;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#21442;&#25968;&#26694;&#26550;&#26469;&#35780;&#20272;&#22240;&#26524;&#20013;&#20171;&#25928;&#24212;&#65292;&#25552;&#20986;&#20102;&#19968;&#32452;&#20551;&#35774;&#26469;&#35782;&#21035;&#33258;&#28982;&#20013;&#20171;&#25928;&#24212;&#24182;&#25512;&#23548;&#20986;&#25104;&#20493;&#31283;&#20581;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#39564;&#21644;&#35266;&#23519;&#30740;&#31350;&#20013;&#65292;&#20154;&#20204;&#36890;&#24120;&#23545;&#20102;&#35299;&#24178;&#39044;&#26041;&#26696;&#22914;&#20309;&#25913;&#21892;&#26368;&#32456;&#32467;&#26524;&#30340;&#28508;&#22312;&#26426;&#21046;&#24863;&#20852;&#36259;&#12290;&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;&#26088;&#22312;&#36798;&#21040;&#27492;&#30446;&#30340;&#65292;&#20294;&#20027;&#35201;&#38480;&#20110;&#27835;&#30103;&#23436;&#20840;&#26381;&#20174;&#30340;&#24773;&#20917;&#65292;&#21482;&#26377;&#23569;&#25968;&#24773;&#20917;&#38656;&#35201;&#25490;&#38500;&#38480;&#21046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#21322;&#21442;&#25968;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#26080;&#38656;&#25490;&#38500;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#35780;&#20272;&#20855;&#26377;&#27835;&#30103;&#19981;&#26381;&#20174;&#24615;&#30340;&#22240;&#26524;&#20013;&#20171;&#25928;&#24212;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#32452;&#20551;&#35774;&#26469;&#35782;&#21035;&#25972;&#20010;&#30740;&#31350;&#20154;&#32676;&#30340;&#33258;&#28982;&#20013;&#20171;&#25928;&#24212;&#65292;&#24182;&#36827;&#19968;&#27493;&#38024;&#23545;&#30001;&#28508;&#22312;&#26381;&#20174;&#34892;&#20026;&#29305;&#24449;&#21270;&#30340;&#20122;&#20154;&#32676;&#20013;&#30340;&#20027;&#35201;&#33258;&#28982;&#20013;&#20171;&#25928;&#24212;&#36827;&#34892;&#35782;&#21035;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#20027;&#35201;&#33258;&#28982;&#20013;&#20171;&#25928;&#24212;&#20272;&#35745;&#37327;&#30340;&#26377;&#25928;&#24433;&#21709;&#20989;&#25968;&#65292;&#36825;&#28608;&#21169;&#20102;&#19968;&#32452;&#20493;&#22686;&#31283;&#20581;&#20272;&#35745;&#22120;&#36827;&#34892;&#25512;&#35770;&#12290;&#36825;&#20123;&#34987;&#35782;&#21035;&#20272;&#35745;&#37327;&#30340;&#21322;&#21442;&#25968;&#25928;&#29575;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
In experimental and observational studies, there is often interest in understanding the potential mechanism by which an intervention program improves the final outcome. Causal mediation analyses have been developed for this purpose but are primarily restricted to the case of perfect treatment compliance, with a few exceptions that require exclusion restriction. In this article, we establish a semiparametric framework for assessing causal mediation in the presence of treatment noncompliance without exclusion restriction. We propose a set of assumptions to identify the natural mediation effects for the entire study population and further, for the principal natural mediation effects within subpopulations characterized by the potential compliance behaviour. We derive the efficient influence functions for the principal natural mediation effect estimands, which motivate a set of multiply robust estimators for inference. The semiparametric efficiency theory for the identified estimands is der
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24314;&#31435;&#20102;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#19982;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#25512;&#23548;&#20102;&#29992;&#20110;&#25511;&#21046;&#28508;&#22312;SDE&#36793;&#38469;&#23494;&#24230;&#28436;&#21270;&#30340;&#27721;&#23494;&#23572;&#39039;-&#38597;&#21487;&#27604;-&#36125;&#23572;&#26364;&#26041;&#31243;&#65292;&#24182;&#23558;&#29983;&#25104;&#24314;&#27169;&#34920;&#36848;&#20026;&#23545;&#21512;&#36866;&#24230;&#37327;&#20043;&#38388;Kullback-Leibler&#25955;&#24230;&#30340;&#26368;&#23567;&#21270;&#12290;&#27492;&#22806;&#65292;&#20316;&#32773;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#22411;&#25193;&#25955;&#26041;&#27861;&#29992;&#20110;&#37319;&#26679;&#38750;&#24402;&#19968;&#21270;&#23494;&#24230;&#12290;</title><link>http://arxiv.org/abs/2211.01364</link><description>&lt;p&gt;
&#23545;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#26368;&#20248;&#25511;&#21046;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
An optimal control perspective on diffusion-based generative modeling. (arXiv:2211.01364v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.01364
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24314;&#31435;&#20102;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#19982;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#25512;&#23548;&#20102;&#29992;&#20110;&#25511;&#21046;&#28508;&#22312;SDE&#36793;&#38469;&#23494;&#24230;&#28436;&#21270;&#30340;&#27721;&#23494;&#23572;&#39039;-&#38597;&#21487;&#27604;-&#36125;&#23572;&#26364;&#26041;&#31243;&#65292;&#24182;&#23558;&#29983;&#25104;&#24314;&#27169;&#34920;&#36848;&#20026;&#23545;&#21512;&#36866;&#24230;&#37327;&#20043;&#38388;Kullback-Leibler&#25955;&#24230;&#30340;&#26368;&#23567;&#21270;&#12290;&#27492;&#22806;&#65292;&#20316;&#32773;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#22411;&#25193;&#25955;&#26041;&#27861;&#29992;&#20110;&#37319;&#26679;&#38750;&#24402;&#19968;&#21270;&#23494;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24314;&#31435;&#20102;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#19982;&#22522;&#20110;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#30340;&#29983;&#25104;&#27169;&#22411;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#20363;&#22914;&#26368;&#36817;&#21457;&#23637;&#36215;&#26469;&#30340;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#19968;&#20010;&#27721;&#23494;&#23572;&#39039;-&#38597;&#21487;&#27604;-&#36125;&#23572;&#26364;&#26041;&#31243;&#65292;&#29992;&#20110;&#25511;&#21046;&#28508;&#22312;&#30340;SDE&#36793;&#38469;&#23494;&#24230;&#30340;&#28436;&#21270;&#12290;&#36825;&#20010;&#35270;&#35282;&#20801;&#35768;&#23558;&#26368;&#20248;&#25511;&#21046;&#29702;&#35770;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#29983;&#25104;&#24314;&#27169;&#20013;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35777;&#25454;&#19979;&#30028;&#26159;&#25511;&#21046;&#29702;&#35770;&#20013;&#24191;&#20026;&#20154;&#30693;&#30340;&#39564;&#35777;&#23450;&#29702;&#30340;&#30452;&#25509;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21487;&#20197;&#23558;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#24314;&#27169;&#34920;&#36848;&#20026;&#36335;&#24452;&#31354;&#38388;&#20013;&#21512;&#36866;&#24230;&#37327;&#20043;&#38388;&#30340;Kullback-Leibler&#25955;&#24230;&#30340;&#26368;&#23567;&#21270;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#20174;&#38750;&#24402;&#19968;&#21270;&#23494;&#24230;&#20013;&#36827;&#34892;&#37319;&#26679;&#30340;&#26032;&#22411;&#25193;&#25955;&#26041;&#27861;&#65292;&#36825;&#22312;&#32479;&#35745;&#23398;&#21644;&#35745;&#31639;&#31185;&#23398;&#20013;&#32463;&#24120;&#20986;&#29616;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26102;&#24207;&#21453;&#21521;&#25193;&#25955;&#37319;&#26679;&#22120;&#65288;DIS&#65289;&#21487;&#20197;&#32988;&#36807;&#20854;&#20182;&#22522;&#20110;&#25193;&#25955;&#30340;&#37319;&#26679;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We establish a connection between stochastic optimal control and generative models based on stochastic differential equations (SDEs), such as recently developed diffusion probabilistic models. In particular, we derive a Hamilton-Jacobi-Bellman equation that governs the evolution of the log-densities of the underlying SDE marginals. This perspective allows to transfer methods from optimal control theory to generative modeling. First, we show that the evidence lower bound is a direct consequence of the well-known verification theorem from control theory. Further, we can formulate diffusion-based generative modeling as a minimization of the Kullback-Leibler divergence between suitable measures in path space. Finally, we develop a novel diffusion-based method for sampling from unnormalized densities -- a problem frequently occurring in statistics and computational sciences. We demonstrate that our time-reversed diffusion sampler (DIS) can outperform other diffusion-based sampling approache
&lt;/p&gt;</description></item></channel></rss>