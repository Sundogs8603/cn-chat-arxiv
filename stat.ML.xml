<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#20197;&#21069;&#30740;&#31350;&#34920;&#26126;&#26420;&#32032;&#30340;LBA&#21644;LLP&#19981;&#33021;&#25552;&#20379;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;&#12290;&#20294;&#26412;&#30740;&#31350;&#26174;&#31034;&#65292;&#20351;&#29992;&#20855;&#26377;&#38543;&#26426;&#25277;&#26679;&#30340;&#21152;&#26435;LBA&#21487;&#20197;&#25552;&#20379;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;&#12290;</title><link>http://arxiv.org/abs/2310.10092</link><description>&lt;p&gt;
&#36890;&#36807;&#32858;&#21512;&#23454;&#29616;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;
&lt;/p&gt;
&lt;p&gt;
Label Differential Privacy via Aggregation. (arXiv:2310.10092v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10092
&lt;/p&gt;
&lt;p&gt;
&#20197;&#21069;&#30740;&#31350;&#34920;&#26126;&#26420;&#32032;&#30340;LBA&#21644;LLP&#19981;&#33021;&#25552;&#20379;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;&#12290;&#20294;&#26412;&#30740;&#31350;&#26174;&#31034;&#65292;&#20351;&#29992;&#20855;&#26377;&#38543;&#26426;&#25277;&#26679;&#30340;&#21152;&#26435;LBA&#21487;&#20197;&#25552;&#20379;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#29616;&#23454;&#24212;&#29992;&#20013;&#65292;&#29305;&#21035;&#26159;&#30001;&#20110;&#38544;&#31169;&#39046;&#22495;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#35757;&#32451;&#25968;&#25454;&#21487;&#20197;&#36827;&#34892;&#32858;&#21512;&#65292;&#20197;&#20445;&#25252;&#25935;&#24863;&#35757;&#32451;&#26631;&#31614;&#30340;&#38544;&#31169;&#12290;&#22312;&#26631;&#31614;&#27604;&#20363;&#23398;&#20064;(LLP)&#26694;&#26550;&#20013;&#65292;&#25968;&#25454;&#38598;&#34987;&#21010;&#20998;&#20026;&#29305;&#24449;&#21521;&#37327;&#30340;&#21253;&#65292;&#21482;&#33021;&#33719;&#24471;&#27599;&#20010;&#21253;&#20013;&#26631;&#31614;&#30340;&#24635;&#21644;&#12290;&#36827;&#19968;&#27493;&#38480;&#21046;&#30340;&#38480;&#21046;&#23398;&#20064;(LBA)&#26159;&#21482;&#33021;&#33719;&#24471;&#21253;&#30340;&#29305;&#24449;&#21521;&#37327;&#30340;&#24635;&#21644;&#65288;&#21487;&#33021;&#26159;&#21152;&#26435;&#30340;&#65289;&#12290;&#25105;&#20204;&#30740;&#31350;&#36825;&#31181;&#32858;&#21512;&#25216;&#26415;&#26159;&#21542;&#33021;&#22815;&#22312;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;(label-DP)&#30340;&#27010;&#24565;&#19979;&#25552;&#20379;&#38544;&#31169;&#20445;&#35777;&#65292;&#35813;&#27010;&#24565;&#20043;&#21069;&#22312;[Chaudhuri-Hsu'11, Ghazi et al.'21, Esfandiari et al.'22]&#20013;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#24456;&#23481;&#26131;&#30475;&#20986;&#65292;&#26420;&#32032;&#30340;LBA&#21644;LLP&#19981;&#33021;&#25552;&#20379;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;&#20855;&#26377;$m$&#20010;&#38543;&#26426;&#25277;&#26679;&#30340;&#19981;&#30456;&#20132;$k$-&#22823;&#23567;&#21253;&#30340;&#21152;&#26435;LBA&#23454;&#38469;&#19978;&#26159;$(\varepsilon,
&lt;/p&gt;
&lt;p&gt;
In many real-world applications, in particular due to recent developments in the privacy landscape, training data may be aggregated to preserve the privacy of sensitive training labels. In the learning from label proportions (LLP) framework, the dataset is partitioned into bags of feature-vectors which are available only with the sum of the labels per bag. A further restriction, which we call learning from bag aggregates (LBA) is where instead of individual feature-vectors, only the (possibly weighted) sum of the feature-vectors per bag is available. We study whether such aggregation techniques can provide privacy guarantees under the notion of label differential privacy (label-DP) previously studied in for e.g. [Chaudhuri-Hsu'11, Ghazi et al.'21, Esfandiari et al.'22].  It is easily seen that naive LBA and LLP do not provide label-DP. Our main result however, shows that weighted LBA using iid Gaussian weights with $m$ randomly sampled disjoint $k$-sized bags is in fact $(\varepsilon, 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#31181;&#23454;&#29992;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#28145;&#24230;&#29983;&#25104;&#32452;&#20214;&#30340;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20013;&#35745;&#31639;&#22238;&#28335;&#21453;&#20107;&#23454;&#12290;&#36890;&#36807;&#22312;&#22240;&#26524;&#27169;&#22411;&#30340;&#32467;&#26500;&#21270;&#28508;&#22312;&#31354;&#38388;&#20013;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#29983;&#25104;&#21453;&#20107;&#23454;&#65292;&#24182;&#19988;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#27604;&#20855;&#22791;&#20102;&#22810;&#21151;&#33021;&#12289;&#27169;&#22359;&#21270;&#21644;&#31526;&#21512;&#22240;&#26524;&#20851;&#31995;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2310.07665</link><description>&lt;p&gt;
&#28145;&#24230;&#22238;&#28335;&#23545;&#22240;&#26524;&#19968;&#33268;&#35299;&#37322;&#30340;&#21453;&#20107;&#23454;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Deep Backtracking Counterfactuals for Causally Compliant Explanations. (arXiv:2310.07665v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07665
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#31181;&#23454;&#29992;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#28145;&#24230;&#29983;&#25104;&#32452;&#20214;&#30340;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20013;&#35745;&#31639;&#22238;&#28335;&#21453;&#20107;&#23454;&#12290;&#36890;&#36807;&#22312;&#22240;&#26524;&#27169;&#22411;&#30340;&#32467;&#26500;&#21270;&#28508;&#22312;&#31354;&#38388;&#20013;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#29983;&#25104;&#21453;&#20107;&#23454;&#65292;&#24182;&#19988;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#27604;&#20855;&#22791;&#20102;&#22810;&#21151;&#33021;&#12289;&#27169;&#22359;&#21270;&#21644;&#31526;&#21512;&#22240;&#26524;&#20851;&#31995;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#25512;&#29702;&#21487;&#20197;&#36890;&#36807;&#22238;&#31572;&#22312;&#25913;&#21464;&#24773;&#20917;&#19979;&#20250;&#35266;&#23519;&#21040;&#20160;&#20040;&#26469;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#35265;&#35299;&#65292;&#26465;&#20214;&#26159;&#26681;&#25454;&#23454;&#38469;&#35266;&#23519;&#12290;&#34429;&#28982;&#32463;&#20856;&#30340;&#20171;&#20837;&#24335;&#35299;&#37322;&#24050;&#32463;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#22238;&#28335;&#21407;&#21017;&#34987;&#25552;&#20986;&#20316;&#20026;&#19968;&#31181;&#20445;&#25345;&#25152;&#26377;&#22240;&#26524;&#23450;&#24459;&#23436;&#25972;&#24615;&#30340;&#26367;&#20195;&#21746;&#23398;&#65292;&#20294;&#20854;&#30740;&#31350;&#36739;&#23569;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#22312;&#30001;&#28145;&#24230;&#29983;&#25104;&#32452;&#20214;&#32452;&#25104;&#30340;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20013;&#35745;&#31639;&#22238;&#28335;&#21453;&#20107;&#23454;&#30340;&#23454;&#29992;&#26041;&#27861;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#23545;&#32467;&#26500;&#20998;&#37197;&#26045;&#21152;&#20102;&#26465;&#20214;&#65292;&#36890;&#36807;&#22312;&#22240;&#26524;&#27169;&#22411;&#30340;&#32467;&#26500;&#21270;&#28508;&#22312;&#31354;&#38388;&#20013;&#35299;&#20915;&#19968;&#20010;&#21487;&#34892;&#30340;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#26469;&#29983;&#25104;&#21453;&#20107;&#23454;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36824;&#21487;&#20197;&#19982;&#21453;&#20107;&#23454;&#35299;&#37322;&#39046;&#22495;&#30340;&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#12290;&#19982;&#36825;&#20123;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20195;&#34920;&#20102;&#19968;&#31181;&#22810;&#21151;&#33021;&#12289;&#27169;&#22359;&#21270;&#21644;&#36981;&#23432;&#22240;&#26524;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactuals can offer valuable insights by answering what would have been observed under altered circumstances, conditional on a factual observation. Whereas the classical interventional interpretation of counterfactuals has been studied extensively, backtracking constitutes a less studied alternative the backtracking principle has emerged as an alternative philosophy where all causal laws are kept intact. In the present work, we introduce a practical method for computing backtracking counterfactuals in structural causal models that consist of deep generative components. To this end, we impose conditions on the structural assignments that enable the generation of counterfactuals by solving a tractable constrained optimization problem in the structured latent space of a causal model. Our formulation also facilitates a comparison with methods in the field of counterfactual explanations. Compared to these, our method represents a versatile, modular and causally compliant alternative. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20026;&#25237;&#27880;&#32622;&#20449;&#21306;&#38388;&#30340;&#25913;&#36827;&#24615;&#33021;&#25552;&#20379;&#20102;&#29702;&#35770;&#35299;&#37322;&#65292;&#24182;&#27604;&#36739;&#20102;&#32463;&#20856;&#26041;&#27861;&#20013;&#30340;&#23485;&#24230;&#65292;&#21457;&#29616;&#25237;&#27880;&#32622;&#20449;&#21306;&#38388;&#20855;&#26377;&#36739;&#23567;&#30340;&#26497;&#38480;&#23485;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.01547</link><description>&lt;p&gt;
&#20851;&#20110;&#26377;&#30028;&#22343;&#20540;&#30340;&#25237;&#27880;&#32622;&#20449;&#21306;&#38388;&#30340;&#36817;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the near-optimality of betting confidence sets for bounded means. (arXiv:2310.01547v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01547
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20026;&#25237;&#27880;&#32622;&#20449;&#21306;&#38388;&#30340;&#25913;&#36827;&#24615;&#33021;&#25552;&#20379;&#20102;&#29702;&#35770;&#35299;&#37322;&#65292;&#24182;&#27604;&#36739;&#20102;&#32463;&#20856;&#26041;&#27861;&#20013;&#30340;&#23485;&#24230;&#65292;&#21457;&#29616;&#25237;&#27880;&#32622;&#20449;&#21306;&#38388;&#20855;&#26377;&#36739;&#23567;&#30340;&#26497;&#38480;&#23485;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32479;&#35745;&#23398;&#20013;&#65292;&#20174;&#29420;&#31435;&#21516;&#20998;&#24067;&#65288;i.i.d.&#65289;&#35266;&#27979;&#20013;&#26500;&#24314;&#19968;&#20803;&#20998;&#24067;&#30340;&#38750;&#28176;&#36817;&#32622;&#20449;&#21306;&#38388;&#65288;CI&#65289;&#26159;&#19968;&#39033;&#22522;&#26412;&#20219;&#21153;&#12290;&#23545;&#20110;&#26377;&#30028;&#35266;&#27979;&#20540;&#65292;&#32463;&#20856;&#30340;&#38750;&#21442;&#25968;&#26041;&#27861;&#36890;&#36807;&#21453;&#36716;&#26631;&#20934;&#27987;&#24230;&#30028;&#38480;&#65288;&#22914;Hoeffding&#25110;Bernstein&#19981;&#31561;&#24335;&#65289;&#26469;&#36827;&#34892;&#12290;&#26368;&#36817;&#65292;&#19968;&#31181;&#26367;&#20195;&#30340;&#22522;&#20110;&#25237;&#27880;&#30340;&#26041;&#27861;&#34987;&#29992;&#20110;&#23450;&#20041;CI&#21644;&#20854;&#26102;&#38388;&#19968;&#33268;&#21464;&#20307;&#65292;&#31216;&#20026;&#32622;&#20449;&#24207;&#21015;&#65288;CS&#65289;&#65292;&#24050;&#34987;&#35777;&#26126;&#22312;&#23454;&#35777;&#19978;&#20248;&#20110;&#32463;&#20856;&#26041;&#27861;&#12290;&#26412;&#25991;&#20026;&#36825;&#31181;&#25237;&#27880;CI&#21644;CS&#30340;&#25913;&#36827;&#32463;&#39564;&#24615;&#24615;&#33021;&#25552;&#20379;&#20102;&#29702;&#35770;&#19978;&#30340;&#35299;&#37322;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#22914;&#19979;&#65306;&#65288;i&#65289;&#25105;&#20204;&#39318;&#20808;&#27604;&#36739;CI&#65292;&#20351;&#29992;&#23427;&#20204;&#30340;&#19968;&#38454;&#28176;&#36817;&#23485;&#24230;&#30340;&#20540;&#65288;&#32463;&#36807;$\sqrt{n}$&#32553;&#25918;&#65289;&#65292;&#24182;&#19988;&#34920;&#26126;Waudby-Smith&#21644;Ramdas&#65288;2023&#65289;&#30340;&#25237;&#27880;CI&#27604;&#29616;&#26377;&#30340;&#32463;&#39564;Bernstein&#65288;EB&#65289;CI&#30340;&#26497;&#38480;&#23485;&#24230;&#26356;&#23567;&#12290;&#65288;ii&#65289;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#20004;&#20010;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
Constructing nonasymptotic confidence intervals (CIs) for the mean of a univariate distribution from independent and identically distributed (i.i.d.) observations is a fundamental task in statistics. For bounded observations, a classical nonparametric approach proceeds by inverting standard concentration bounds, such as Hoeffding's or Bernstein's inequalities. Recently, an alternative betting-based approach for defining CIs and their time-uniform variants called confidence sequences (CSs), has been shown to be empirically superior to the classical methods. In this paper, we provide theoretical justification for this improved empirical performance of betting CIs and CSs.  Our main contributions are as follows: (i) We first compare CIs using the values of their first-order asymptotic widths (scaled by $\sqrt{n}$), and show that the betting CI of Waudby-Smith and Ramdas (2023) has a smaller limiting width than existing empirical Bernstein (EB)-CIs. (ii) Next, we establish two lower bounds
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22686;&#24378;&#38543;&#26426;&#24179;&#28369;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#30740;&#31350;&#38543;&#26426;&#24179;&#28369;&#24341;&#20837;&#30340;&#26041;&#24046;&#19982;&#20998;&#31867;&#22120;&#30340;Lipschitz&#24120;&#25968;&#21644;&#36793;&#30028;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20197;&#21450;&#37319;&#29992;&#21333;&#32431;&#24418;&#25237;&#24433;&#25216;&#26415;&#26469;&#22686;&#21152;&#35748;&#35777;&#40065;&#26834;&#21322;&#24452;&#12290;</title><link>http://arxiv.org/abs/2309.16883</link><description>&lt;p&gt;
&#22686;&#24378;&#38543;&#26426;&#24179;&#28369;&#30340;Lipschitz-&#26041;&#24046;-&#36793;&#30028;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
The Lipschitz-Variance-Margin Tradeoff for Enhanced Randomized Smoothing. (arXiv:2309.16883v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16883
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22686;&#24378;&#38543;&#26426;&#24179;&#28369;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#30740;&#31350;&#38543;&#26426;&#24179;&#28369;&#24341;&#20837;&#30340;&#26041;&#24046;&#19982;&#20998;&#31867;&#22120;&#30340;Lipschitz&#24120;&#25968;&#21644;&#36793;&#30028;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20197;&#21450;&#37319;&#29992;&#21333;&#32431;&#24418;&#25237;&#24433;&#25216;&#26415;&#26469;&#22686;&#21152;&#35748;&#35777;&#40065;&#26834;&#21322;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38754;&#23545;&#22122;&#22768;&#36755;&#20837;&#21644;&#23545;&#25239;&#24615;&#25915;&#20987;&#26102;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#23454;&#38469;&#24212;&#29992;&#21463;&#21040;&#20854;&#19981;&#31283;&#23450;&#30340;&#39044;&#27979;&#30340;&#38459;&#30861;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#35748;&#35777;&#21322;&#24452;&#26159;&#27169;&#22411;&#40065;&#26834;&#24615;&#30340;&#20851;&#38190;&#25351;&#26631;&#12290;&#28982;&#32780;&#65292;&#22914;&#20309;&#35774;&#35745;&#19968;&#20010;&#20855;&#26377;&#36275;&#22815;&#35748;&#35777;&#21322;&#24452;&#30340;&#39640;&#25928;&#20998;&#31867;&#22120;&#21602;&#65311;&#38543;&#26426;&#24179;&#28369;&#36890;&#36807;&#22312;&#36755;&#20837;&#20013;&#27880;&#20837;&#22122;&#22768;&#26469;&#33719;&#24471;&#24179;&#28369;&#19988;&#26356;&#40065;&#26834;&#30340;&#20998;&#31867;&#22120;&#30340;&#26694;&#26550;&#25552;&#20379;&#20102;&#26377;&#24076;&#26395;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#26412;&#25991;&#39318;&#20808;&#23637;&#31034;&#20102;&#38543;&#26426;&#24179;&#28369;&#24341;&#20837;&#30340;&#26041;&#24046;&#19982;&#20998;&#31867;&#22120;&#30340;&#21478;&#22806;&#20004;&#20010;&#37325;&#35201;&#23646;&#24615;&#65292;&#21363;&#20854;Lipschitz&#24120;&#25968;&#21644;&#36793;&#30028;&#20043;&#38388;&#30340;&#23494;&#20999;&#20851;&#31995;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#24378;&#35843;&#20102;&#22522;&#20998;&#31867;&#22120;&#30340;Lipschitz&#24120;&#25968;&#23545;&#24179;&#28369;&#20998;&#31867;&#22120;&#21644;&#32463;&#39564;&#26041;&#24046;&#30340;&#21452;&#37325;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#22686;&#21152;&#35748;&#35777;&#40065;&#26834;&#21322;&#24452;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#19981;&#21516;&#30340;&#21333;&#32431;&#24418;&#25237;&#24433;&#25216;&#26415;&#65292;&#20197;&#20415;&#36890;&#36807;Bernst&#30340;&#26041;&#24046;-&#36793;&#30028;&#26435;&#34913;&#26469;&#21033;&#29992;&#22522;&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Real-life applications of deep neural networks are hindered by their unsteady predictions when faced with noisy inputs and adversarial attacks. The certified radius is in this context a crucial indicator of the robustness of models. However how to design an efficient classifier with a sufficient certified radius? Randomized smoothing provides a promising framework by relying on noise injection in inputs to obtain a smoothed and more robust classifier. In this paper, we first show that the variance introduced by randomized smoothing closely interacts with two other important properties of the classifier, i.e. its Lipschitz constant and margin. More precisely, our work emphasizes the dual impact of the Lipschitz constant of the base classifier, on both the smoothed classifier and the empirical variance. Moreover, to increase the certified robust radius, we introduce a different simplex projection technique for the base classifier to leverage the variance-margin trade-off thanks to Bernst
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#25581;&#31034;&#20102;&#22312;&#25104;&#23545;&#22330;&#26223;&#20013;&#39640;&#27700;&#24179;&#30340;&#20449;&#20219;&#21644;&#21487;&#20449;&#24230;&#26159;&#36890;&#36807;&#21516;&#26102;&#37325;&#35270;&#21382;&#21490;&#32463;&#39564;&#21644;&#26410;&#26469;&#22238;&#25253;&#26469;&#24418;&#25104;&#30340;&#12290;</title><link>http://arxiv.org/abs/2309.14598</link><description>&lt;p&gt;
&#35299;&#35835;&#20449;&#20219;:&#24378;&#21270;&#23398;&#20064;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Decoding trust: A reinforcement learning perspective. (arXiv:2309.14598v1 [q-bio.PE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14598
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#25581;&#31034;&#20102;&#22312;&#25104;&#23545;&#22330;&#26223;&#20013;&#39640;&#27700;&#24179;&#30340;&#20449;&#20219;&#21644;&#21487;&#20449;&#24230;&#26159;&#36890;&#36807;&#21516;&#26102;&#37325;&#35270;&#21382;&#21490;&#32463;&#39564;&#21644;&#26410;&#26469;&#22238;&#25253;&#26469;&#24418;&#25104;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20449;&#20219;&#28216;&#25103;&#30340;&#34892;&#20026;&#23454;&#39564;&#34920;&#26126;&#65292;&#20449;&#20219;&#21644;&#21487;&#20449;&#24230;&#22312;&#20154;&#31867;&#20013;&#26222;&#36941;&#23384;&#22312;&#65292;&#36825;&#19982;&#27491;&#32479;&#32463;&#27982;&#23398;&#20013;&#20551;&#35774;&#30340;&#32463;&#27982;&#20154;&#30340;&#39044;&#27979;&#30456;&#30683;&#30462;&#12290;&#36825;&#24847;&#21619;&#30528;&#19968;&#23450;&#23384;&#22312;&#26576;&#31181;&#26426;&#21046;&#20419;&#20351;&#20182;&#20204;&#30340;&#20986;&#29616;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#20808;&#21069;&#30340;&#35299;&#37322;&#37117;&#38656;&#35201;&#20381;&#36182;&#20110;&#19968;&#20123;&#22522;&#20110;&#27169;&#20223;&#23398;&#20064;&#30340;&#22240;&#32032;&#65292;&#21363;&#31616;&#21333;&#29256;&#26412;&#30340;&#31038;&#20250;&#23398;&#20064;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#36716;&#21521;&#24378;&#21270;&#23398;&#20064;&#30340;&#33539;&#24335;&#65292;&#20010;&#20307;&#36890;&#36807;&#32047;&#31215;&#32463;&#39564;&#35780;&#20272;&#38271;&#26399;&#22238;&#25253;&#26469;&#26356;&#26032;&#20182;&#20204;&#30340;&#31574;&#30053;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20351;&#29992;Q-learning&#31639;&#27861;&#30740;&#31350;&#20449;&#20219;&#28216;&#25103;&#65292;&#27599;&#20010;&#21442;&#19982;&#32773;&#20998;&#21035;&#19982;&#20004;&#20010;&#19981;&#26029;&#28436;&#21270;&#30340;Q&#34920;&#20851;&#32852;&#65292;&#25351;&#23548;&#20182;&#20204;&#20316;&#20026;&#20449;&#20219;&#32773;&#21644;&#25176;&#31649;&#26041;&#30340;&#20915;&#31574;&#12290;&#22312;&#25104;&#23545;&#30340;&#22330;&#26223;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#24403;&#20010;&#20307;&#21516;&#26102;&#37325;&#35270;&#21382;&#21490;&#32463;&#39564;&#21644;&#26410;&#26469;&#22238;&#25253;&#26102;&#65292;&#20449;&#20219;&#21644;&#21487;&#20449;&#24230;&#27700;&#24179;&#36739;&#39640;&#12290;&#20174;&#26426;&#21046;&#19978;&#30475;&#65292;Q&#30340;&#28436;&#21270;...
&lt;/p&gt;
&lt;p&gt;
Behavioral experiments on the trust game have shown that trust and trustworthiness are universal among human beings, contradicting the prediction by assuming \emph{Homo economicus} in orthodox Economics. This means some mechanism must be at work that favors their emergence. Most previous explanations however need to resort to some factors based upon imitative learning, a simple version of social learning. Here, we turn to the paradigm of reinforcement learning, where individuals update their strategies by evaluating the long-term return through accumulated experience. Specifically, we investigate the trust game with the Q-learning algorithm, where each participant is associated with two evolving Q-tables that guide one's decision making as trustor and trustee respectively. In the pairwise scenario, we reveal that high levels of trust and trustworthiness emerge when individuals appreciate both their historical experience and returns in the future. Mechanistically, the evolution of the Q
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;&#27867;&#21270;&#30028;&#38480;&#38382;&#39064;&#65292;&#36890;&#36807;&#20998;&#26512;&#22810;&#20010;&#30028;&#38480;&#21457;&#29616;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#26080;&#27861;&#25214;&#21040;&#32039;&#33268;&#30340;&#30028;&#38480;&#26469;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#30340;&#20986;&#33394;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.13658</link><description>&lt;p&gt;
&#26080;&#27861;&#25214;&#21040;&#20986;&#33394;&#30340;&#27867;&#21270;&#24230;&#37327;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Fantastic Generalization Measures are Nowhere to be Found. (arXiv:2309.13658v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13658
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;&#27867;&#21270;&#30028;&#38480;&#38382;&#39064;&#65292;&#36890;&#36807;&#20998;&#26512;&#22810;&#20010;&#30028;&#38480;&#21457;&#29616;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#26080;&#27861;&#25214;&#21040;&#32039;&#33268;&#30340;&#30028;&#38480;&#26469;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#30340;&#20986;&#33394;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21435;&#30340;&#25991;&#29486;&#20013;&#25552;&#20986;&#20102;&#35768;&#22810;&#27867;&#21270;&#30028;&#38480;&#20316;&#20026;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#22312;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#27867;&#21270;&#33021;&#21147;&#30340;&#28508;&#22312;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30028;&#38480;&#37117;&#19981;&#26159;&#32039;&#33268;&#30340;&#12290;&#20363;&#22914;&#65292;&#22312;&#20182;&#20204;&#30340;&#35770;&#25991;&#8220;Fantastic Generalization Measures and Where to Find Them&#8221;&#20013;&#65292;Jiang&#31561;&#20154;&#65288;2020&#65289;&#26816;&#26597;&#20102;&#21313;&#20960;&#20010;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#27809;&#26377;&#19968;&#20010;&#33021;&#22815;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;&#36825;&#24341;&#20986;&#20102;&#19968;&#20010;&#38382;&#39064;&#65292;&#21363;&#26159;&#21542;&#26377;&#21487;&#33021;&#25214;&#21040;&#32039;&#33268;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#25991;&#29486;&#20013;&#24120;&#35265;&#30340;&#20004;&#31181;&#27867;&#21270;&#30028;&#38480;&#65306;&#65288;1&#65289;&#20381;&#36182;&#20110;&#35757;&#32451;&#38598;&#21644;&#23398;&#20064;&#31639;&#27861;&#36755;&#20986;&#30340;&#30028;&#38480;&#12290;&#25991;&#29486;&#20013;&#26377;&#22810;&#20010;&#36825;&#31181;&#31867;&#22411;&#30340;&#30028;&#38480;&#65288;&#20363;&#22914;&#22522;&#20110;&#33539;&#25968;&#21644;&#22522;&#20110;&#38388;&#38548;&#30340;&#30028;&#38480;&#65289;&#65292;&#20294;&#25105;&#20204;&#35777;&#26126;&#22312;&#36807;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#27809;&#26377;&#36825;&#26679;&#30340;&#30028;&#38480;&#33021;&#22815;&#19968;&#33268;&#22320;&#32039;&#33268;&#65307;&#65288;2&#65289;&#20381;&#36182;&#20110;&#35757;&#32451;&#38598;&#21644;&#27979;&#35797;&#38598;&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Numerous generalization bounds have been proposed in the literature as potential explanations for the ability of neural networks to generalize in the overparameterized setting. However, none of these bounds are tight. For instance, in their paper ``Fantastic Generalization Measures and Where to Find Them'', Jiang et al. (2020) examine more than a dozen generalization bounds, and show empirically that none of them imply guarantees that can explain the remarkable performance of neural networks. This raises the question of whether tight generalization bounds are at all possible. We consider two types of generalization bounds common in the literature: (1) bounds that depend on the training set and the output of the learning algorithm. There are multiple bounds of this type in the literature (e.g., norm-based and margin-based bounds), but we prove mathematically that no such bound can be uniformly tight in the overparameterized setting; (2) bounds that depend on the training set and on the 
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#23558;&#39034;&#24207;&#21464;&#21270;&#26816;&#27979;&#31616;&#21270;&#20026;&#39034;&#24207;&#20272;&#35745;&#65292;&#36890;&#36807;&#20351;&#29992;&#32622;&#20449;&#24207;&#21015;&#26469;&#26816;&#27979;&#25968;&#25454;&#27969;&#20013;&#30340;&#21464;&#21270;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#20855;&#26377;&#24378;&#22823;&#30340;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2309.09111</link><description>&lt;p&gt;
&#23558;&#39034;&#24207;&#21464;&#21270;&#26816;&#27979;&#31616;&#21270;&#20026;&#39034;&#24207;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Reducing sequential change detection to sequential estimation. (arXiv:2309.09111v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09111
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#23558;&#39034;&#24207;&#21464;&#21270;&#26816;&#27979;&#31616;&#21270;&#20026;&#39034;&#24207;&#20272;&#35745;&#65292;&#36890;&#36807;&#20351;&#29992;&#32622;&#20449;&#24207;&#21015;&#26469;&#26816;&#27979;&#25968;&#25454;&#27969;&#20013;&#30340;&#21464;&#21270;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#20855;&#26377;&#24378;&#22823;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#39034;&#24207;&#21464;&#21270;&#26816;&#27979;&#30340;&#38382;&#39064;&#65292;&#30446;&#26631;&#26159;&#35774;&#35745;&#19968;&#20010;&#33021;&#22815;&#26816;&#27979;&#25968;&#25454;&#27969;&#20998;&#24067;&#20013;&#21442;&#25968;&#25110;&#20989;&#25968;&#120579;&#30340;&#20219;&#20309;&#21464;&#21270;&#30340;&#26041;&#26696;&#65292;&#35813;&#26041;&#26696;&#20855;&#26377;&#36739;&#23567;&#30340;&#26816;&#27979;&#24310;&#36831;&#65292;&#20294;&#22312;&#27809;&#26377;&#21464;&#21270;&#30340;&#24773;&#20917;&#19979;&#33021;&#22815;&#20445;&#35777;&#20551;&#35686;&#25253;&#30340;&#39057;&#29575;&#21463;&#25511;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#32622;&#20449;&#24207;&#21015;&#25551;&#36848;&#20102;&#19968;&#31181;&#20174;&#39034;&#24207;&#21464;&#21270;&#26816;&#27979;&#21040;&#39034;&#24207;&#20272;&#35745;&#30340;&#31616;&#21333;&#32422;&#21270;&#26041;&#27861;&#65306;&#25105;&#20204;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#24320;&#22987;&#19968;&#20010;&#26032;&#30340;$(1-\alpha)$&#32622;&#20449;&#24207;&#21015;&#65292;&#24182;&#22312;&#25152;&#26377;&#27963;&#21160;&#32622;&#20449;&#24207;&#21015;&#30340;&#20132;&#38598;&#20026;&#31354;&#26102;&#23459;&#24067;&#21464;&#21270;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#24179;&#22343;&#25345;&#32493;&#26102;&#38388;&#33267;&#23569;&#20026;$1/\alpha$&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#20855;&#26377;&#26368;&#23567;&#32467;&#26500;&#20551;&#35774;&#30340;&#21464;&#21270;&#26816;&#27979;&#26041;&#26696;&#65288;&#22240;&#27492;&#20801;&#35768;&#21487;&#33021;&#30456;&#20851;&#30340;&#35266;&#27979;&#21644;&#38750;&#21442;&#25968;&#20998;&#24067;&#31867;&#65289;&#65292;&#20294;&#21364;&#20855;&#26377;&#24378;&#22823;&#30340;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;Lorden&#65288;1971&#65289;&#30340;&#21464;&#21270;&#26816;&#27979;&#21040;&#39034;&#24207;&#27979;&#35797;&#30340;&#31616;&#21270;&#21644;Shin&#31561;&#20154;&#30340;e-detector&#26377;&#30528;&#26377;&#36259;&#30340;&#30456;&#20284;&#20043;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of sequential change detection, where the goal is to design a scheme for detecting any changes in a parameter or functional $\theta$ of the data stream distribution that has small detection delay, but guarantees control on the frequency of false alarms in the absence of changes. In this paper, we describe a simple reduction from sequential change detection to sequential estimation using confidence sequences: we begin a new $(1-\alpha)$-confidence sequence at each time step, and proclaim a change when the intersection of all active confidence sequences becomes empty. We prove that the average run length is at least $1/\alpha$, resulting in a change detection scheme with minimal structural assumptions~(thus allowing for possibly dependent observations, and nonparametric distribution classes), but strong guarantees. Our approach bears an interesting parallel with the reduction from change detection to sequential testing of Lorden (1971) and the e-detector of Shin e
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#20851;&#38190;&#39046;&#22495;&#20013;&#38024;&#23545;&#40723;&#21169;&#25919;&#31574;&#30340;&#26368;&#20248;&#21644;&#20844;&#24179;&#35780;&#20272;&#20197;&#21450;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#30740;&#31350;&#21457;&#29616;&#22312;&#20154;&#31867;&#19981;&#36981;&#24490;&#27835;&#30103;&#24314;&#35758;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#31574;&#30053;&#35268;&#21017;&#21482;&#26159;&#24314;&#35758;&#12290;&#21516;&#26102;&#65292;&#38024;&#23545;&#27835;&#30103;&#30340;&#24322;&#36136;&#24615;&#21644;&#20844;&#24179;&#32771;&#34385;&#22240;&#32032;&#65292;&#20915;&#31574;&#32773;&#30340;&#26435;&#34913;&#21644;&#20915;&#31574;&#35268;&#21017;&#20063;&#20250;&#21457;&#29983;&#21464;&#21270;&#12290;&#22312;&#31038;&#20250;&#26381;&#21153;&#39046;&#22495;&#65292;&#30740;&#31350;&#26174;&#31034;&#23384;&#22312;&#19968;&#20010;&#20351;&#29992;&#24046;&#36317;&#38382;&#39064;&#65292;&#37027;&#20123;&#26368;&#26377;&#21487;&#33021;&#21463;&#30410;&#30340;&#20154;&#21364;&#26080;&#27861;&#33719;&#24471;&#36825;&#20123;&#30410;&#26381;&#21153;&#12290;</title><link>http://arxiv.org/abs/2309.07176</link><description>&lt;p&gt;
&#26368;&#20248;&#21644;&#20844;&#24179;&#30340;&#40723;&#21169;&#25919;&#31574;&#35780;&#20272;&#19982;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Optimal and Fair Encouragement Policy Evaluation and Learning. (arXiv:2309.07176v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07176
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#20851;&#38190;&#39046;&#22495;&#20013;&#38024;&#23545;&#40723;&#21169;&#25919;&#31574;&#30340;&#26368;&#20248;&#21644;&#20844;&#24179;&#35780;&#20272;&#20197;&#21450;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#30740;&#31350;&#21457;&#29616;&#22312;&#20154;&#31867;&#19981;&#36981;&#24490;&#27835;&#30103;&#24314;&#35758;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#31574;&#30053;&#35268;&#21017;&#21482;&#26159;&#24314;&#35758;&#12290;&#21516;&#26102;&#65292;&#38024;&#23545;&#27835;&#30103;&#30340;&#24322;&#36136;&#24615;&#21644;&#20844;&#24179;&#32771;&#34385;&#22240;&#32032;&#65292;&#20915;&#31574;&#32773;&#30340;&#26435;&#34913;&#21644;&#20915;&#31574;&#35268;&#21017;&#20063;&#20250;&#21457;&#29983;&#21464;&#21270;&#12290;&#22312;&#31038;&#20250;&#26381;&#21153;&#39046;&#22495;&#65292;&#30740;&#31350;&#26174;&#31034;&#23384;&#22312;&#19968;&#20010;&#20351;&#29992;&#24046;&#36317;&#38382;&#39064;&#65292;&#37027;&#20123;&#26368;&#26377;&#21487;&#33021;&#21463;&#30410;&#30340;&#20154;&#21364;&#26080;&#27861;&#33719;&#24471;&#36825;&#20123;&#30410;&#26381;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20851;&#38190;&#39046;&#22495;&#20013;&#65292;&#24378;&#21046;&#20010;&#20307;&#25509;&#21463;&#27835;&#30103;&#36890;&#24120;&#26159;&#19981;&#21487;&#33021;&#30340;&#65292;&#22240;&#27492;&#22312;&#20154;&#31867;&#19981;&#36981;&#24490;&#27835;&#30103;&#24314;&#35758;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#31574;&#30053;&#35268;&#21017;&#21482;&#26159;&#24314;&#35758;&#12290;&#22312;&#36825;&#20123;&#39046;&#22495;&#20013;&#65292;&#25509;&#21463;&#27835;&#30103;&#30340;&#20010;&#20307;&#21487;&#33021;&#23384;&#22312;&#24322;&#36136;&#24615;&#65292;&#27835;&#30103;&#25928;&#26524;&#20063;&#21487;&#33021;&#23384;&#22312;&#24322;&#36136;&#24615;&#12290;&#34429;&#28982;&#26368;&#20248;&#27835;&#30103;&#35268;&#21017;&#21487;&#20197;&#26368;&#22823;&#21270;&#25972;&#20010;&#20154;&#32676;&#30340;&#22240;&#26524;&#32467;&#26524;&#65292;&#20294;&#22312;&#40723;&#21169;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#20110;&#35775;&#38382;&#24179;&#31561;&#38480;&#21046;&#25110;&#20854;&#20182;&#20844;&#24179;&#32771;&#34385;&#22240;&#32032;&#21487;&#33021;&#26159;&#30456;&#20851;&#30340;&#12290;&#20363;&#22914;&#65292;&#22312;&#31038;&#20250;&#26381;&#21153;&#39046;&#22495;&#65292;&#19968;&#20010;&#25345;&#20037;&#30340;&#38590;&#39064;&#26159;&#37027;&#20123;&#26368;&#26377;&#21487;&#33021;&#20174;&#20013;&#21463;&#30410;&#30340;&#20154;&#20013;&#37027;&#20123;&#33719;&#30410;&#26381;&#21153;&#30340;&#20351;&#29992;&#24046;&#36317;&#12290;&#24403;&#20915;&#31574;&#32773;&#23545;&#35775;&#38382;&#21644;&#24179;&#22343;&#32467;&#26524;&#37117;&#26377;&#20998;&#37197;&#20559;&#22909;&#26102;&#65292;&#26368;&#20248;&#20915;&#31574;&#35268;&#21017;&#20250;&#21457;&#29983;&#21464;&#21270;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22240;&#26524;&#35782;&#21035;&#12289;&#32479;&#35745;&#26041;&#24046;&#20943;&#23569;&#20272;&#35745;&#21644;&#31283;&#20581;&#20272;&#35745;&#30340;&#26368;&#20248;&#27835;&#30103;&#35268;&#21017;&#65292;&#21253;&#25324;&#22312;&#36829;&#21453;&#38451;&#24615;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
In consequential domains, it is often impossible to compel individuals to take treatment, so that optimal policy rules are merely suggestions in the presence of human non-adherence to treatment recommendations. In these same domains, there may be heterogeneity both in who responds in taking-up treatment, and heterogeneity in treatment efficacy. While optimal treatment rules can maximize causal outcomes across the population, access parity constraints or other fairness considerations can be relevant in the case of encouragement. For example, in social services, a persistent puzzle is the gap in take-up of beneficial services among those who may benefit from them the most. When in addition the decision-maker has distributional preferences over both access and average outcomes, the optimal decision rule changes. We study causal identification, statistical variance-reduced estimation, and robust estimation of optimal treatment rules, including under potential violations of positivity. We c
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#38754;&#20020;&#30340;&#38544;&#31169;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#38544;&#31169;&#21451;&#22909;&#30340;&#25913;&#36827;&#26041;&#27861;TKNN-Shapley&#65292;&#35813;&#26041;&#27861;&#22312;&#20445;&#25252;&#38544;&#31169;&#30340;&#21069;&#25552;&#19979;&#33021;&#22815;&#35780;&#20272;&#25968;&#25454;&#36136;&#37327;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#38544;&#31169;-&#23454;&#29992;&#24615;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2308.15709</link><description>&lt;p&gt;
&#38408;&#20540;KNN-Shapley&#65306;&#19968;&#31181;&#32447;&#24615;&#26102;&#38388;&#21644;&#38544;&#31169;&#21451;&#22909;&#30340;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Threshold KNN-Shapley: A Linear-Time and Privacy-Friendly Approach to Data Valuation. (arXiv:2308.15709v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15709
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#38754;&#20020;&#30340;&#38544;&#31169;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#38544;&#31169;&#21451;&#22909;&#30340;&#25913;&#36827;&#26041;&#27861;TKNN-Shapley&#65292;&#35813;&#26041;&#27861;&#22312;&#20445;&#25252;&#38544;&#31169;&#30340;&#21069;&#25552;&#19979;&#33021;&#22815;&#35780;&#20272;&#25968;&#25454;&#36136;&#37327;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#38544;&#31169;-&#23454;&#29992;&#24615;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#26159;&#25968;&#25454;&#20013;&#24515;&#21270;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#20013;&#30340;&#20851;&#38190;&#38382;&#39064;&#65292;&#26088;&#22312;&#37327;&#21270;&#21333;&#20010;&#25968;&#25454;&#28304;&#22312;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#26377;&#29992;&#24615;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#20854;&#37325;&#35201;&#24615;&#65292;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#38754;&#20020;&#30528;&#24456;&#22810;&#37325;&#35201;&#20294;&#32463;&#24120;&#34987;&#24573;&#35270;&#30340;&#38544;&#31169;&#25361;&#25112;&#12290;&#26412;&#25991;&#38024;&#23545;&#30446;&#21069;&#26368;&#23454;&#29992;&#30340;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#26041;&#27861;&#20043;&#19968;KNN-Shapley&#65292;&#30740;&#31350;&#20102;&#36825;&#20123;&#25361;&#25112;&#12290;&#25105;&#20204;&#39318;&#20808;&#24378;&#35843;&#20102;KNN-Shapley&#22266;&#26377;&#30340;&#38544;&#31169;&#39118;&#38505;&#65292;&#24182;&#23637;&#31034;&#20102;&#23558;KNN-Shapley&#25913;&#36827;&#20197;&#28385;&#36275;&#24046;&#20998;&#38544;&#31169;(DP)&#30340;&#26174;&#33879;&#25216;&#26415;&#22256;&#38590;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;TKNN-Shapley&#65292;KNN-Shapley&#30340;&#19968;&#31181;&#25913;&#36827;&#21464;&#20307;&#65292;&#20855;&#26377;&#38544;&#31169;&#21451;&#22909;&#24615;&#65292;&#21487;&#20197;&#36827;&#34892;&#31616;&#21333;&#30340;&#20462;&#27491;&#20197;&#21253;&#21547;DP&#20445;&#35777;&#65288;DP-TKNN-Shapley&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;DP-TKNN-Shapley&#22312;&#36776;&#21035;&#25968;&#25454;&#36136;&#37327;&#26041;&#38754;&#20855;&#26377;&#19968;&#20123;&#20248;&#21183;&#65292;&#24182;&#22312;&#38544;&#31169;-&#23454;&#29992;&#24615;&#26435;&#34913;&#26041;&#38754;&#20248;&#20110;&#26420;&#32032;&#21270;&#30340;KNN-Shapley&#12290;&#27492;&#22806;&#65292;&#21363;&#20351;&#26159;&#38750;&#38544;&#31169;&#30340;TKNN-Shapley&#20063;&#33021;&#20197;&#32447;&#24615;&#26102;&#38388;&#36816;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data valuation, a critical aspect of data-centric ML research, aims to quantify the usefulness of individual data sources in training machine learning (ML) models. However, data valuation faces significant yet frequently overlooked privacy challenges despite its importance. This paper studies these challenges with a focus on KNN-Shapley, one of the most practical data valuation methods nowadays. We first emphasize the inherent privacy risks of KNN-Shapley, and demonstrate the significant technical difficulties in adapting KNN-Shapley to accommodate differential privacy (DP). To overcome these challenges, we introduce TKNN-Shapley, a refined variant of KNN-Shapley that is privacy-friendly, allowing for straightforward modifications to incorporate DP guarantee (DP-TKNN-Shapley). We show that DP-TKNN-Shapley has several advantages and offers a superior privacy-utility tradeoff compared to naively privatized KNN-Shapley in discerning data quality. Moreover, even non-private TKNN-Shapley ac
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35843;&#26597;&#20102;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#20998;&#23376;&#22270;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#26367;&#25442;&#22270;&#29983;&#25104;&#27169;&#22411;&#30340;&#22522;&#30784;GNN&#26469;&#36827;&#34892;&#23454;&#39564;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#20351;&#29992;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;GNN&#21487;&#20197;&#25913;&#21892;&#29983;&#25104;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.11978</link><description>&lt;p&gt;
&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#29983;&#25104;&#20219;&#21153;&#20013;&#26159;&#21542;&#26356;&#22909;&#65311;
&lt;/p&gt;
&lt;p&gt;
Will More Expressive Graph Neural Networks do Better on Generative Tasks?. (arXiv:2308.11978v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11978
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35843;&#26597;&#20102;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#20998;&#23376;&#22270;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#26367;&#25442;&#22270;&#29983;&#25104;&#27169;&#22411;&#30340;&#22522;&#30784;GNN&#26469;&#36827;&#34892;&#23454;&#39564;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#20351;&#29992;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;GNN&#21487;&#20197;&#25913;&#21892;&#29983;&#25104;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#29983;&#25104;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#25361;&#25112;&#65292;&#23427;&#28041;&#21450;&#26681;&#25454;&#32473;&#23450;&#30340;&#26631;&#31614;&#39044;&#27979;&#19968;&#20010;&#23436;&#25972;&#30340;&#20855;&#26377;&#22810;&#20010;&#33410;&#28857;&#21644;&#36793;&#30340;&#22270;&#12290;&#36825;&#20010;&#20219;&#21153;&#23545;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#38750;&#24120;&#37325;&#35201;&#65292;&#21253;&#25324;&#33647;&#29289;&#21644;&#20998;&#23376;&#35774;&#35745;&#12290;&#36817;&#24180;&#26469;&#65292;&#22312;&#22270;&#29983;&#25104;&#39046;&#22495;&#20986;&#29616;&#20102;&#20960;&#31181;&#25104;&#21151;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#23384;&#22312;&#20004;&#20010;&#37325;&#22823;&#38382;&#39064;&#65306;(1) &#36825;&#20123;&#26041;&#27861;&#20013;&#20351;&#29992;&#30340;&#22522;&#30784;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26550;&#26500;&#24448;&#24448;&#26410;&#32463;&#28145;&#20837;&#25506;&#32034;&#65307;(2) &#36825;&#20123;&#26041;&#27861;&#24448;&#24448;&#21482;&#22312;&#26377;&#38480;&#30340;&#25351;&#26631;&#19978;&#36827;&#34892;&#35780;&#20272;&#12290;&#20026;&#22635;&#34917;&#36825;&#20010;&#31354;&#30333;&#65292;&#25105;&#20204;&#36890;&#36807;&#23558;&#22270;&#29983;&#25104;&#27169;&#22411;&#30340;&#22522;&#30784;GNN&#26367;&#25442;&#20026;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;GNN&#65292;&#30740;&#31350;&#20102;GNN&#22312;&#20998;&#23376;&#22270;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#33021;&#21147;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#20004;&#31181;&#19981;&#21516;&#29983;&#25104;&#26694;&#26550;&#65288;GCPN&#21644;GraphAF&#65289;&#20013;&#20845;&#31181;GNN&#22312;&#20845;&#20010;&#19981;&#21516;&#30340;&#20998;&#23376;&#29983;&#25104;&#30446;&#26631;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph generation poses a significant challenge as it involves predicting a complete graph with multiple nodes and edges based on simply a given label. This task also carries fundamental importance to numerous real-world applications, including de-novo drug and molecular design. In recent years, several successful methods have emerged in the field of graph generation. However, these approaches suffer from two significant shortcomings: (1) the underlying Graph Neural Network (GNN) architectures used in these methods are often underexplored; and (2) these methods are often evaluated on only a limited number of metrics. To fill this gap, we investigate the expressiveness of GNNs under the context of the molecular graph generation task, by replacing the underlying GNNs of graph generative models with more expressive GNNs. Specifically, we analyse the performance of six GNNs in two different generative frameworks (GCPN and GraphAF), on six different molecular generative objectives on the ZIN
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33021;&#37327;&#27169;&#22411;&#25439;&#22833;&#20989;&#25968;&#65292;&#33021;&#22815;&#22312;&#19981;&#20381;&#36182;&#20998;&#25968;&#35745;&#31639;&#25110;&#26114;&#36149;&#30340;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#30340;&#24773;&#20917;&#19979;&#65292;&#36817;&#20284;&#23454;&#29616;&#26174;&#24335;&#20998;&#25968;&#21305;&#37197;&#21644;&#36127;&#23545;&#25968;&#20284;&#28982;&#25439;&#22833;&#65292;&#24182;&#22312;&#23398;&#20064;&#20302;&#32500;&#25968;&#25454;&#20998;&#24067;&#26102;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.06431</link><description>&lt;p&gt;
&#33021;&#37327;&#24046;&#24322;&#65306;&#19968;&#31181;&#36866;&#29992;&#20110;&#33021;&#37327;&#27169;&#22411;&#30340;&#29420;&#31435;&#20110;&#35780;&#20998;&#30340;&#25439;&#22833;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Energy Discrepancies: A Score-Independent Loss for Energy-Based Models. (arXiv:2307.06431v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06431
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33021;&#37327;&#27169;&#22411;&#25439;&#22833;&#20989;&#25968;&#65292;&#33021;&#22815;&#22312;&#19981;&#20381;&#36182;&#20998;&#25968;&#35745;&#31639;&#25110;&#26114;&#36149;&#30340;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#30340;&#24773;&#20917;&#19979;&#65292;&#36817;&#20284;&#23454;&#29616;&#26174;&#24335;&#20998;&#25968;&#21305;&#37197;&#21644;&#36127;&#23545;&#25968;&#20284;&#28982;&#25439;&#22833;&#65292;&#24182;&#22312;&#23398;&#20064;&#20302;&#32500;&#25968;&#25454;&#20998;&#24067;&#26102;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#37327;&#27169;&#22411;&#26159;&#19968;&#31181;&#31616;&#21333;&#32780;&#24378;&#22823;&#30340;&#27010;&#29575;&#27169;&#22411;&#65292;&#20294;&#23427;&#20204;&#30340;&#26222;&#21450;&#21463;&#21040;&#20102;&#35757;&#32451;&#30340;&#35745;&#31639;&#36127;&#25285;&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#31216;&#20026;&#33021;&#37327;&#24046;&#24322;&#65288;ED&#65289;&#65292;&#23427;&#19981;&#20381;&#36182;&#20110;&#20998;&#25968;&#30340;&#35745;&#31639;&#25110;&#26114;&#36149;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19981;&#21516;&#30340;&#26497;&#38480;&#19979;&#65292;ED&#25509;&#36817;&#20110;&#26174;&#24335;&#20998;&#25968;&#21305;&#37197;&#21644;&#36127;&#23545;&#25968;&#20284;&#28982;&#25439;&#22833;&#65292;&#26377;&#25928;&#22320;&#22312;&#20004;&#32773;&#20043;&#38388;&#25554;&#20540;&#12290;&#22240;&#27492;&#65292;&#26368;&#23567;&#21270;ED&#20272;&#35745;&#20811;&#26381;&#20102;&#22312;&#22522;&#20110;&#20998;&#25968;&#30340;&#20272;&#35745;&#26041;&#27861;&#20013;&#36935;&#21040;&#30340;&#36817;&#35270;&#38382;&#39064;&#65292;&#21516;&#26102;&#36824;&#20139;&#26377;&#29702;&#35770;&#20445;&#35777;&#12290;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;&#26174;&#24335;&#20998;&#25968;&#21305;&#37197;&#25110;&#23545;&#27604;&#25955;&#24230;&#30456;&#27604;&#65292;ED&#33021;&#22815;&#26356;&#24555;&#36895;&#12289;&#26356;&#20934;&#30830;&#22320;&#23398;&#20064;&#20302;&#32500;&#25968;&#25454;&#20998;&#24067;&#12290;&#23545;&#20110;&#39640;&#32500;&#22270;&#20687;&#25968;&#25454;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#27969;&#24418;&#20551;&#35774;&#23545;&#25105;&#20204;&#26041;&#27861;&#30340;&#38480;&#21046;&#65292;&#24182;&#36890;&#36807;&#23545;e&#27169;&#22411;&#30340;&#35757;&#32451;&#65292;&#35777;&#26126;&#20102;&#33021;&#37327;&#24046;&#24322;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Energy-based models are a simple yet powerful class of probabilistic models, but their widespread adoption has been limited by the computational burden of training them. We propose a novel loss function called Energy Discrepancy (ED) which does not rely on the computation of scores or expensive Markov chain Monte Carlo. We show that ED approaches the explicit score matching and negative log-likelihood loss under different limits, effectively interpolating between both. Consequently, minimum ED estimation overcomes the problem of nearsightedness encountered in score-based estimation methods, while also enjoying theoretical guarantees. Through numerical experiments, we demonstrate that ED learns low-dimensional data distributions faster and more accurately than explicit score matching or contrastive divergence. For high-dimensional image data, we describe how the manifold hypothesis puts limitations on our approach and demonstrate the effectiveness of energy discrepancy by training the e
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#31283;&#20581;&#23494;&#24230;&#21151;&#29575;&#20998;&#27495;&#65288;DPD&#65289;&#22312;&#19968;&#33324;&#21442;&#25968;&#23494;&#24230;&#27169;&#22411;&#20013;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#24212;&#29992;&#20256;&#32479;&#30340;&#38543;&#26426;&#20248;&#21270;&#29702;&#35770;&#26469;&#39564;&#35777;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.05251</link><description>&lt;p&gt;
&#29992;&#20110;&#19968;&#33324;&#21442;&#25968;&#23494;&#24230;&#27169;&#22411;&#30340;&#26368;&#23567;&#21270;&#31283;&#20581;&#23494;&#24230;&#21151;&#29575;&#20998;&#27495;&#30340;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A stochastic optimization approach to minimize robust density power-based divergences for general parametric density models. (arXiv:2307.05251v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05251
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#31283;&#20581;&#23494;&#24230;&#21151;&#29575;&#20998;&#27495;&#65288;DPD&#65289;&#22312;&#19968;&#33324;&#21442;&#25968;&#23494;&#24230;&#27169;&#22411;&#20013;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#24212;&#29992;&#20256;&#32479;&#30340;&#38543;&#26426;&#20248;&#21270;&#29702;&#35770;&#26469;&#39564;&#35777;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23494;&#24230;&#21151;&#29575;&#20998;&#27495;&#65288;DPD&#65289;&#26159;&#19968;&#31181;&#29992;&#20110;&#31283;&#20581;&#22320;&#20272;&#35745;&#35266;&#27979;&#25968;&#25454;&#28508;&#22312;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#23427;&#21253;&#25324;&#19968;&#20010;&#35201;&#20272;&#35745;&#30340;&#21442;&#25968;&#23494;&#24230;&#27169;&#22411;&#30340;&#24130;&#30340;&#31215;&#20998;&#39033;&#12290;&#34429;&#28982;&#23545;&#20110;&#19968;&#20123;&#29305;&#23450;&#30340;&#23494;&#24230;&#65288;&#22914;&#27491;&#24577;&#23494;&#24230;&#21644;&#25351;&#25968;&#23494;&#24230;&#65289;&#21487;&#20197;&#24471;&#21040;&#31215;&#20998;&#39033;&#30340;&#26174;&#24335;&#24418;&#24335;&#65292;&#20294;DPD&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#20351;&#24471;&#20854;&#26080;&#27861;&#24212;&#29992;&#20110;&#26356;&#19968;&#33324;&#30340;&#21442;&#25968;&#23494;&#24230;&#27169;&#22411;&#65292;&#36825;&#24050;&#32463;&#36229;&#36807;&#20102;DPD&#25552;&#20986;&#30340;25&#24180;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#19968;&#33324;&#21442;&#25968;&#23494;&#24230;&#27169;&#22411;&#26368;&#23567;&#21270;DPD&#30340;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#21442;&#32771;&#38543;&#26426;&#20248;&#21270;&#30340;&#20256;&#32479;&#29702;&#35770;&#35828;&#26126;&#20102;&#20854;&#36866;&#29992;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#36824;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#26410;&#24402;&#19968;&#21270;&#27169;&#22411;&#26469;&#26368;&#23567;&#21270;&#21478;&#19968;&#20010;&#22522;&#20110;&#23494;&#24230;&#21151;&#29575;&#30340;&#947;-&#31163;&#24046;[Kanamori&#21644;Fujisawa&#65288;2015&#65289;&#65292;Biometrika]&#12290;
&lt;/p&gt;
&lt;p&gt;
Density power divergence (DPD) [Basu et al. (1998), Biometrika], designed to estimate the underlying distribution of the observations robustly, comprises an integral term of the power of the parametric density models to be estimated. While the explicit form of the integral term can be obtained for some specific densities (such as normal density and exponential density), its computational intractability has prohibited the application of DPD-based estimation to more general parametric densities, over a quarter of a century since the proposal of DPD. This study proposes a stochastic optimization approach to minimize DPD for general parametric density models and explains its adequacy by referring to conventional theories on stochastic optimization. The proposed approach also can be applied to the minimization of another density power-based $\gamma$-divergence with the aid of unnormalized models [Kanamori and Fujisawa (2015), Biometrika].
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Hadamard&#21442;&#25968;&#21270;&#19979;&#31574;&#30053;&#26799;&#24230;&#30340;&#25910;&#25947;&#24615;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#20855;&#26377;&#20840;&#23616;&#32447;&#24615;&#25910;&#25947;&#24615;&#21644;&#23616;&#37096;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#26356;&#24555;&#30340;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2305.19575</link><description>&lt;p&gt;
&#20851;&#20110;Hadamard&#21442;&#25968;&#21270;&#19979;&#31574;&#30053;&#26799;&#24230;&#30340;&#32447;&#24615;&#25910;&#25947;&#24615;.
&lt;/p&gt;
&lt;p&gt;
On the Linear Convergence of Policy Gradient under Hadamard Parameterization. (arXiv:2305.19575v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19575
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Hadamard&#21442;&#25968;&#21270;&#19979;&#31574;&#30053;&#26799;&#24230;&#30340;&#25910;&#25947;&#24615;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#20855;&#26377;&#20840;&#23616;&#32447;&#24615;&#25910;&#25947;&#24615;&#21644;&#23616;&#37096;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#26356;&#24555;&#30340;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#34920;&#26684;&#24335;&#35774;&#32622;&#19979;Hadamard&#21442;&#25968;&#21270;&#19979;&#30830;&#23450;&#24615;&#31574;&#30053;&#26799;&#24230;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#24314;&#31435;&#20102;&#31639;&#27861;&#30340;&#20840;&#23616;&#32447;&#24615;&#25910;&#25947;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#38169;&#35823;&#22312;&#25152;&#26377;&#36845;&#20195;&#20013;&#20197;$O(\frac{1}{k})$&#30340;&#36895;&#29575;&#19979;&#38477;&#12290;&#22522;&#20110;&#36825;&#20010;&#32467;&#26524;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#22312;$k_0$&#27425;&#36845;&#20195;&#20043;&#21518;&#20855;&#26377;&#26356;&#24555;&#30340;&#23616;&#37096;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#65292;&#20854;&#20013;$k_0$&#26159;&#20165;&#20381;&#36182;&#20110;MDP&#38382;&#39064;&#21644;&#27493;&#38271;&#30340;&#24120;&#25968;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#35813;&#31639;&#27861;&#26174;&#31034;&#20102;&#19968;&#20010;&#36739;&#24369;&#24120;&#25968;&#30340;&#32447;&#24615;&#25910;&#25947;&#29575;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#23616;&#37096;&#32447;&#24615;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
The convergence of deterministic policy gradient under the Hadamard parametrization is studied in the tabular setting and the global linear convergence of the algorithm is established. To this end, we first show that the error decreases at an $O(\frac{1}{k})$ rate for all the iterations. Based on this result, we further show that the algorithm has a faster local linear convergence rate after $k_0$ iterations, where $k_0$ is a constant that only depends on the MDP problem and the step size. Overall, the algorithm displays a linear convergence rate for all the iterations with a loose constant than that for the local linear convergence rate.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#26041;&#27861;&#65292;&#21363;SAMoSSA&#12290;&#35813;&#26041;&#27861;&#32508;&#21512;&#20102;&#22810;&#20803;&#22855;&#24322;&#35889;&#20998;&#26512;&#21644;&#33258;&#22238;&#24402;&#20998;&#26512;&#65292;&#22312;&#23398;&#20064;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#24615;&#25104;&#20998;&#26041;&#38754;&#20855;&#26377;&#33391;&#22909;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.16491</link><description>&lt;p&gt;
SAMoSSA&#65306;&#24102;&#38543;&#26426;&#33258;&#22238;&#24402;&#22122;&#22768;&#30340;&#22810;&#20803;&#22855;&#24322;&#35889;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
SAMoSSA: Multivariate Singular Spectrum Analysis with Stochastic Autoregressive Noise. (arXiv:2305.16491v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16491
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#26041;&#27861;&#65292;&#21363;SAMoSSA&#12290;&#35813;&#26041;&#27861;&#32508;&#21512;&#20102;&#22810;&#20803;&#22855;&#24322;&#35889;&#20998;&#26512;&#21644;&#33258;&#22238;&#24402;&#20998;&#26512;&#65292;&#22312;&#23398;&#20064;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#24615;&#25104;&#20998;&#26041;&#38754;&#20855;&#26377;&#33391;&#22909;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#30340;&#24815;&#20363;&#26159;&#20808;&#20272;&#35745;&#30830;&#23450;&#24615;&#12289;&#38750;&#24179;&#31283;&#36235;&#21183;&#21644;&#23395;&#33410;&#25104;&#20998;&#65292;&#28982;&#21518;&#23398;&#20064;&#27531;&#24046;&#38543;&#26426;&#12289;&#24179;&#31283;&#25104;&#20998;&#12290;&#26368;&#36817;&#24050;&#32463;&#34920;&#26126;&#65292;&#22312;&#27809;&#26377;&#30456;&#20851;&#24179;&#31283;&#25104;&#20998;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#20351;&#29992;&#22810;&#20803;&#22855;&#24322;&#35889;&#20998;&#26512;&#65288;mSSA&#65289;&#20934;&#30830;&#22320;&#23398;&#20064;&#30830;&#23450;&#24615;&#38750;&#24179;&#31283;&#25104;&#20998;&#65307;&#21516;&#26102;&#65292;&#22312;&#27809;&#26377;&#30830;&#23450;&#24615;&#38750;&#24179;&#31283;&#25104;&#20998;&#30340;&#24773;&#20917;&#19979;&#65292;&#33258;&#22238;&#24402;&#65288;AR&#65289;&#24179;&#31283;&#25104;&#20998;&#20063;&#21487;&#20197;&#36731;&#26494;&#23398;&#20064;&#65292;&#20363;&#22914;&#36890;&#36807;&#26222;&#36890;&#26368;&#23567;&#20108;&#20056;&#65288;OLS&#65289;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#36825;&#31181;&#20004;&#20010;&#27493;&#39588;&#30340;&#23398;&#20064;&#31639;&#27861;&#24050;&#32463;&#26222;&#36941;&#23384;&#22312;&#65292;&#20294;&#20851;&#20110;&#21516;&#26102;&#28041;&#21450;&#30830;&#23450;&#24615;&#21644;&#24179;&#31283;&#25104;&#20998;&#30340;&#22810;&#38454;&#27573;&#23398;&#20064;&#31639;&#27861;&#30340;&#29702;&#35770;&#25903;&#25745;&#22312;&#25991;&#29486;&#20013;&#36824;&#27809;&#26377;&#35299;&#20915;&#12290;&#25105;&#20204;&#36890;&#36807;&#20026;&#19968;&#31181;&#33258;&#28982;&#30340;&#20004;&#38454;&#27573;&#31639;&#27861;&#24314;&#31435;&#29702;&#35770;&#20445;&#35777;&#26469;&#35299;&#20915;&#36825;&#20010;&#24320;&#25918;&#24615;&#38382;&#39064;&#65292;&#20854;&#20013;&#39318;&#20808;&#24212;&#29992;mSSA&#26469;&#20272;&#35745;&#38750;&#24179;&#31283;&#25104;&#20998;&#65292;&#23613;&#31649;&#23384;&#22312;&#30456;&#20851;&#24615;&#24179;&#31283;&#25104;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
The well-established practice of time series analysis involves estimating deterministic, non-stationary trend and seasonality components followed by learning the residual stochastic, stationary components. Recently, it has been shown that one can learn the deterministic non-stationary components accurately using multivariate Singular Spectrum Analysis (mSSA) in the absence of a correlated stationary component; meanwhile, in the absence of deterministic non-stationary components, the Autoregressive (AR) stationary component can also be learnt readily, e.g. via Ordinary Least Squares (OLS). However, a theoretical underpinning of multi-stage learning algorithms involving both deterministic and stationary components has been absent in the literature despite its pervasiveness. We resolve this open question by establishing desirable theoretical guarantees for a natural two-stage algorithm, where mSSA is first applied to estimate the non-stationary components despite the presence of a correla
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;DIVA&#31639;&#27861;&#65292;&#19968;&#20010;&#22522;&#20110;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#30340;&#22686;&#37327;&#28145;&#24230;&#32858;&#31867;&#26694;&#26550;&#65292;&#21033;&#29992;&#26080;&#38480;&#28151;&#21512;&#39640;&#26031;&#20316;&#20026;&#20808;&#39564;&#65292;&#24182;&#21033;&#29992;&#19968;&#31181;&#35760;&#24518;&#21270;&#30340;&#22312;&#32447;&#21464;&#20998;&#25512;&#29702;&#26041;&#27861;&#23454;&#29616;&#31751;&#30340;&#21160;&#24577;&#36866;&#24212;&#31227;&#21160;&#65292;&#32780;&#19981;&#38656;&#35201;&#20808;&#30693;&#36947;&#29305;&#24449;&#30340;&#25968;&#37327;&#12290;&#35813;&#31639;&#27861;&#34920;&#29616;&#20248;&#36234;&#65292;&#29305;&#21035;&#26159;&#22312;&#22686;&#37327;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#12290;</title><link>http://arxiv.org/abs/2305.14067</link><description>&lt;p&gt;
DIVA&#65306;&#22522;&#20110;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#22686;&#37327;&#28145;&#24230;&#32858;&#31867;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
DIVA: A Dirichlet Process Based Incremental Deep Clustering Algorithm via Variational Auto-Encoder. (arXiv:2305.14067v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14067
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;DIVA&#31639;&#27861;&#65292;&#19968;&#20010;&#22522;&#20110;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#30340;&#22686;&#37327;&#28145;&#24230;&#32858;&#31867;&#26694;&#26550;&#65292;&#21033;&#29992;&#26080;&#38480;&#28151;&#21512;&#39640;&#26031;&#20316;&#20026;&#20808;&#39564;&#65292;&#24182;&#21033;&#29992;&#19968;&#31181;&#35760;&#24518;&#21270;&#30340;&#22312;&#32447;&#21464;&#20998;&#25512;&#29702;&#26041;&#27861;&#23454;&#29616;&#31751;&#30340;&#21160;&#24577;&#36866;&#24212;&#31227;&#21160;&#65292;&#32780;&#19981;&#38656;&#35201;&#20808;&#30693;&#36947;&#29305;&#24449;&#30340;&#25968;&#37327;&#12290;&#35813;&#31639;&#27861;&#34920;&#29616;&#20248;&#36234;&#65292;&#29305;&#21035;&#26159;&#22312;&#22686;&#37327;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#29983;&#25104;&#27169;&#22411;&#30340;&#28145;&#24230;&#32858;&#31867;&#26694;&#26550;&#22312;&#20998;&#31867;&#22797;&#26434;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#22788;&#29702;&#21160;&#24577;&#21644;&#22797;&#26434;&#29305;&#24449;&#26041;&#38754;&#21463;&#21040;&#38480;&#21046;&#65292;&#22240;&#20026;&#23427;&#20204;&#38656;&#35201;&#20808;&#30693;&#36947;&#31751;&#30340;&#25968;&#37327;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#21442;&#25968;&#28145;&#24230;&#32858;&#31867;&#26694;&#26550;&#65292;&#37319;&#29992;&#26080;&#38480;&#28151;&#21512;&#39640;&#26031;&#20316;&#20026;&#20808;&#39564;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21033;&#29992;&#19968;&#31181;&#35760;&#24518;&#21270;&#30340;&#22312;&#32447;&#21464;&#20998;&#25512;&#29702;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#31751;&#30340;&#8220;&#20986;&#29983;&#8221;&#21644;&#8220;&#21512;&#24182;&#8221;&#31227;&#21160;&#65292;&#20351;&#25105;&#20204;&#30340;&#26694;&#26550;&#33021;&#22815;&#20197;&#8220;&#21160;&#24577;&#36866;&#24212;&#8221;&#30340;&#26041;&#24335;&#32858;&#31867;&#25968;&#25454;&#65292;&#32780;&#19981;&#38656;&#35201;&#20808;&#30693;&#36947;&#29305;&#24449;&#30340;&#25968;&#37327;&#12290;&#25105;&#20204;&#25226;&#35813;&#26694;&#26550;&#21629;&#21517;&#20026;DIVA&#65292;&#21363;&#22522;&#20110;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#30340;&#22686;&#37327;&#28145;&#24230;&#32858;&#31867;&#26694;&#26550;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#22312;&#20998;&#31867;&#20855;&#26377;&#21160;&#24577;&#21464;&#21270;&#29305;&#24449;&#30340;&#22797;&#26434;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20248;&#36234;&#65292;&#29305;&#21035;&#26159;&#22312;&#22686;&#37327;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#65292;&#36229;&#36807;&#20102;&#26368;&#20808;&#36827;&#30340;&#22522;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative model-based deep clustering frameworks excel in classifying complex data, but are limited in handling dynamic and complex features because they require prior knowledge of the number of clusters. In this paper, we propose a nonparametric deep clustering framework that employs an infinite mixture of Gaussians as a prior. Our framework utilizes a memoized online variational inference method that enables the "birth" and "merge" moves of clusters, allowing our framework to cluster data in a "dynamic-adaptive" manner, without requiring prior knowledge of the number of features. We name the framework as DIVA, a Dirichlet Process-based Incremental deep clustering framework via Variational Auto-Encoder. Our framework, which outperforms state-of-the-art baselines, exhibits superior performance in classifying complex data with dynamically changing features, particularly in the case of incremental features.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21160;&#37327;&#21305;&#37197;&#21435;&#22122;Gibbs&#37319;&#26679;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#32473;&#23450;&#8216;&#22024;&#26434;&#8217;&#30340;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#20174;&#24178;&#20928;&#30340;&#27169;&#22411;&#20013;&#26377;&#25928;&#22320;&#36827;&#34892;&#37319;&#26679;&#12290;</title><link>http://arxiv.org/abs/2305.11650</link><description>&lt;p&gt;
&#21160;&#37327;&#21305;&#37197;&#21435;&#22122;Gibbs&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Moment Matching Denoising Gibbs Sampling. (arXiv:2305.11650v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11650
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21160;&#37327;&#21305;&#37197;&#21435;&#22122;Gibbs&#37319;&#26679;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#32473;&#23450;&#8216;&#22024;&#26434;&#8217;&#30340;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#20174;&#24178;&#20928;&#30340;&#27169;&#22411;&#20013;&#26377;&#25928;&#22320;&#36827;&#34892;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#37327;&#22522;&#27169;&#22411;&#65288;EBMs&#65289;&#20026;&#24314;&#27169;&#22797;&#26434;&#25968;&#25454;&#20998;&#24067;&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#26694;&#26550;&#12290;&#28982;&#32780;&#65292;EBMs &#30340;&#35757;&#32451;&#21644;&#37319;&#26679;&#20173;&#28982;&#38754;&#20020;&#37325;&#22823;&#25361;&#25112;&#12290;&#29992;&#20110;&#21487;&#25193;&#23637; EBM &#35757;&#32451;&#30340;&#24191;&#27867;&#20351;&#29992;&#30340;&#21435;&#22122;&#20998;&#25968;&#21305;&#37197;&#65288;DSM&#65289;&#26041;&#27861;&#23384;&#22312;&#19981;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#23548;&#33268;&#33021;&#37327;&#27169;&#22411;&#23398;&#20064;&#21040;&#8220;&#22024;&#26434;&#8221;&#30340;&#25968;&#25454;&#20998;&#24067;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#37319;&#26679;&#26694;&#26550;&#65306;&#65288;&#20266;&#65289;Gibbs&#37319;&#26679;&#19982;&#21160;&#37327;&#21305;&#37197;&#65292;&#21487;&#20197;&#22312;&#32473;&#23450;&#32463;&#36807;DSM&#35757;&#32451;&#33391;&#22909;&#30340;&#8220;&#22024;&#26434;&#8221;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#20174;&#22522;&#30784;&#8220;&#24178;&#20928;&#8221;&#27169;&#22411;&#20013;&#26377;&#25928;&#22320;&#36827;&#34892;&#37319;&#26679;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#23545;&#20110;&#30456;&#20851;&#26041;&#27861;&#30340;&#20248;&#21183;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#35813;&#26041;&#27861;&#25193;&#23637;&#21040;&#39640;&#32500;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Energy-Based Models (EBMs) offer a versatile framework for modeling complex data distributions. However, training and sampling from EBMs continue to pose significant challenges. The widely-used Denoising Score Matching (DSM) method for scalable EBM training suffers from inconsistency issues, causing the energy model to learn a `noisy' data distribution. In this work, we propose an efficient sampling framework: (pseudo)-Gibbs sampling with moment matching, which enables effective sampling from the underlying clean model when given a `noisy' model that has been well-trained via DSM. We explore the benefits of our approach compared to related methods and demonstrate how to scale the method to high-dimensional datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#33258;&#28982;&#21644;&#21487;&#35299;&#37322;&#30340;&#25928;&#29992;&#20989;&#25968;&#65292;&#26356;&#22909;&#22320;&#21453;&#26144;&#20102;KNN&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#25552;&#20379;&#20102;&#30456;&#24212;&#35745;&#31639;&#36807;&#31243;&#65292;&#35813;&#26041;&#27861;&#34987;&#31216;&#20026;&#36719;&#26631;&#31614;KNN-SV&#65292;&#19982;&#21407;&#22987;&#26041;&#27861;&#20855;&#26377;&#30456;&#21516;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2304.04258</link><description>&lt;p&gt;
&#20851;&#20110;&#8220;&#26368;&#36817;&#37051;&#31639;&#27861;&#30340;&#20219;&#21153;&#29305;&#23450;&#25968;&#25454;&#26377;&#25928;&#24615;&#8221;&#30340;&#27880;&#35760;&#65288;arXiv&#65306;2304.04258v1 [stat.ML]&#65289;
&lt;/p&gt;
&lt;p&gt;
A Note on "Efficient Task-Specific Data Valuation for Nearest Neighbor Algorithms". (arXiv:2304.04258v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04258
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#33258;&#28982;&#21644;&#21487;&#35299;&#37322;&#30340;&#25928;&#29992;&#20989;&#25968;&#65292;&#26356;&#22909;&#22320;&#21453;&#26144;&#20102;KNN&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#25552;&#20379;&#20102;&#30456;&#24212;&#35745;&#31639;&#36807;&#31243;&#65292;&#35813;&#26041;&#27861;&#34987;&#31216;&#20026;&#36719;&#26631;&#31614;KNN-SV&#65292;&#19982;&#21407;&#22987;&#26041;&#27861;&#20855;&#26377;&#30456;&#21516;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#26377;&#25928;&#24615;&#26159;&#19968;&#20010;&#30740;&#31350;&#21333;&#20010;&#25968;&#25454;&#28857;&#23545;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#27169;&#22411;&#24433;&#21709;&#30340;&#26085;&#30410;&#22686;&#38271;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#22522;&#20110;&#21512;&#20316;&#21338;&#24328;&#35770;&#21644;&#32463;&#27982;&#23398;&#65292;&#25968;&#25454; Shapley &#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#25968;&#25454;&#26377;&#25928;&#24615;&#35745;&#31639;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#20154;&#20204;&#37117;&#30693;&#36947; Shapley &#20540;&#65288;SV&#65289;&#30340;&#35745;&#31639;&#21487;&#33021;&#38750;&#24120;&#26114;&#36149;&#12290;&#24184;&#36816;&#30340;&#26159;&#65292;Jia &#31561;&#20154;&#65288;2019&#65289;&#34920;&#26126;&#65292;&#23545;&#20110; K &#26368;&#36817;&#37051;&#65288;KNN&#65289;&#27169;&#22411;&#65292;&#35745;&#31639; Data Shapley &#31455;&#28982;&#38750;&#24120;&#31616;&#21333;&#21644;&#39640;&#25928;&#12290;&#22312;&#26412;&#31508;&#35760;&#20013;&#65292;&#25105;&#20204;&#37325;&#23457;&#20102; Jia &#31561;&#20154;&#65288;2019&#65289;&#30340;&#24037;&#20316;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#33258;&#28982;&#21644;&#21487;&#35299;&#37322;&#30340;&#25928;&#29992;&#20989;&#25968;&#65292;&#26356;&#22909;&#22320;&#21453;&#26144;&#20102; KNN &#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#20855;&#26377;&#26032;&#25928;&#29992;&#20989;&#25968;&#30340; KNN &#20998;&#31867;&#22120;/&#22238;&#24402;&#22120;&#30340; Data Shapley &#30340;&#30456;&#24212;&#35745;&#31639;&#36807;&#31243;&#12290;&#25105;&#20204;&#30340;&#26032;&#26041;&#27861;&#34987;&#31216;&#20026;&#36719;&#26631;&#31614; KNN-SV&#65292;&#19982;&#21407;&#22987;&#26041;&#27861;&#20855;&#26377;&#30456;&#21516;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;&#65288;LSH&#65289;&#30340;&#36719;&#26631;&#31614; KNN-SV &#30340;&#39640;&#25928;&#36817;&#20284;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data valuation is a growing research field that studies the influence of individual data points for machine learning (ML) models. Data Shapley, inspired by cooperative game theory and economics, is an effective method for data valuation. However, it is well-known that the Shapley value (SV) can be computationally expensive. Fortunately, Jia et al. (2019) showed that for K-Nearest Neighbors (KNN) models, the computation of Data Shapley is surprisingly simple and efficient.  In this note, we revisit the work of Jia et al. (2019) and propose a more natural and interpretable utility function that better reflects the performance of KNN models. We derive the corresponding calculation procedure for the Data Shapley of KNN classifiers/regressors with the new utility functions. Our new approach, dubbed soft-label KNN-SV, achieves the same time complexity as the original method. We further provide an efficient approximation algorithm for soft-label KNN-SV based on locality sensitive hashing (LSH
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38598;&#25104;&#23398;&#20064;&#21644;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#30340;&#24212;&#29992;&#65292;&#38024;&#23545;&#31867;&#21035;&#19981;&#24179;&#34913;&#38382;&#39064;&#65292;&#36890;&#36807;&#35745;&#31639;&#35780;&#20272;&#65292;&#25214;&#21040;&#20102;&#26368;&#26377;&#25928;&#30340;&#32452;&#21512;&#12290;</title><link>http://arxiv.org/abs/2304.02858</link><description>&lt;p&gt;
&#38754;&#21521;&#31867;&#21035;&#19981;&#22343;&#38382;&#39064;&#30340;&#38598;&#25104;&#23398;&#20064;&#21644;&#25968;&#25454;&#22686;&#24378;&#27169;&#22411;&#32508;&#36848;&#65306;&#32452;&#21512;&#12289;&#23454;&#29616;&#21644;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
A review of ensemble learning and data augmentation models for class imbalanced problems: combination, implementation and evaluation. (arXiv:2304.02858v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02858
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38598;&#25104;&#23398;&#20064;&#21644;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#30340;&#24212;&#29992;&#65292;&#38024;&#23545;&#31867;&#21035;&#19981;&#24179;&#34913;&#38382;&#39064;&#65292;&#36890;&#36807;&#35745;&#31639;&#35780;&#20272;&#65292;&#25214;&#21040;&#20102;&#26368;&#26377;&#25928;&#30340;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#31867;&#21035;&#19981;&#24179;&#34913;&#65288;CI&#65289;&#26159;&#25351;&#23646;&#20110;&#19968;&#20010;&#31867;&#30340;&#35266;&#27979;&#20540;&#25968;&#37327;&#20302;&#20110;&#20854;&#20182;&#31867;&#30340;&#25968;&#37327;&#12290;&#38598;&#25104;&#23398;&#20064;&#32467;&#21512;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#24050;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#35299;&#20915;&#31867;&#21035;&#19981;&#24179;&#34913;&#38382;&#39064;&#12290;&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#37324;&#65292;&#19968;&#20123;&#31574;&#30053;&#24050;&#32463;&#34987;&#24212;&#29992;&#20110;&#22686;&#24378;&#38598;&#25104;&#23398;&#20064;&#21644;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#65292;&#21516;&#26102;&#36824;&#24320;&#21457;&#20102;&#19968;&#20123;&#26032;&#26041;&#27861;&#65292;&#22914;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#12290;&#26412;&#25991;&#23545;&#29992;&#20110;&#35299;&#20915;&#22522;&#20934;CI&#38382;&#39064;&#30340;&#25968;&#25454;&#22686;&#24378;&#21644;&#38598;&#25104;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#35745;&#31639;&#35780;&#20272;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#35780;&#20272;CI&#38382;&#39064;&#30340;10&#20010;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#21644;10&#20010;&#38598;&#25104;&#23398;&#20064;&#26041;&#27861;&#30340;&#36890;&#29992;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#35782;&#21035;&#25552;&#39640;&#20998;&#31867;&#25928;&#26524;&#26368;&#26377;&#25928;&#30340;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Class imbalance (CI) in classification problems arises when the number of observations belonging to one class is lower than the other classes. Ensemble learning that combines multiple models to obtain a robust model has been prominently used with data augmentation methods to address class imbalance problems. In the last decade, a number of strategies have been added to enhance ensemble learning and data augmentation methods, along with new methods such as generative adversarial networks (GANs). A combination of these has been applied in many studies, but the true rank of different combinations would require a computational review. In this paper, we present a computational review to evaluate data augmentation and ensemble learning methods used to address prominent benchmark CI problems. We propose a general framework that evaluates 10 data augmentation and 10 ensemble learning methods for CI problems. Our objective was to identify the most effective combination for improving classificat
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;Sobolev&#21644;Besov&#31354;&#38388;&#20013;&#65292;&#20351;&#29992;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#20197;&#24590;&#26679;&#30340;&#21442;&#25968;&#25928;&#29575;&#36924;&#36817;&#20989;&#25968;&#65292;&#21253;&#25324;$L_p(\Omega)$&#33539;&#25968;&#19979;&#30340;&#35823;&#24046;&#24230;&#37327;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25152;&#26377;$1\leq p,q \leq \infty$&#21644;$s&gt;0$&#30340;&#23436;&#25972;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#20301;&#25552;&#21462;&#25216;&#26415;&#26469;&#33719;&#24471;&#23574;&#38160;&#30340;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2211.14400</link><description>&lt;p&gt;
&#22312;Sobolev&#21644;Besov&#31354;&#38388;&#19978;&#65292;&#20851;&#20110;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#20339;&#36924;&#36817;&#36895;&#29575;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Optimal Approximation Rates for Deep ReLU Neural Networks on Sobolev and Besov Spaces. (arXiv:2211.14400v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.14400
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;Sobolev&#21644;Besov&#31354;&#38388;&#20013;&#65292;&#20351;&#29992;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#20197;&#24590;&#26679;&#30340;&#21442;&#25968;&#25928;&#29575;&#36924;&#36817;&#20989;&#25968;&#65292;&#21253;&#25324;$L_p(\Omega)$&#33539;&#25968;&#19979;&#30340;&#35823;&#24046;&#24230;&#37327;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25152;&#26377;$1\leq p,q \leq \infty$&#21644;$s&gt;0$&#30340;&#23436;&#25972;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#20301;&#25552;&#21462;&#25216;&#26415;&#26469;&#33719;&#24471;&#23574;&#38160;&#30340;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;Sobolev&#31354;&#38388;$W^s(L_q(\Omega))$&#21644;Besov&#31354;&#38388;$B^s_r(L_q(\Omega))$&#20013;&#20197;$L_p(\Omega)$&#33539;&#25968;&#24230;&#37327;&#35823;&#24046;&#30340;&#21442;&#25968;&#25928;&#29575;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#23545;&#20110;&#22312;&#31185;&#23398;&#35745;&#31639;&#21644;&#20449;&#21495;&#22788;&#29702;&#31561;&#39046;&#22495;&#20013;&#24212;&#29992;&#31070;&#32463;&#32593;&#32476;&#38750;&#24120;&#37325;&#35201;&#65292;&#22312;&#36807;&#21435;&#21482;&#26377;&#24403;$p=q=\infty$&#26102;&#25165;&#23436;&#20840;&#35299;&#20915;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#26159;&#25552;&#20379;&#20102;&#25152;&#26377;$1\leq p,q\leq \infty$&#21644;$s&gt;0$&#30340;&#23436;&#25972;&#35299;&#20915;&#26041;&#26696;&#65292;&#21253;&#25324;&#28176;&#36817;&#21305;&#37197;&#30340;&#19978;&#19979;&#30028;&#12290;&#20851;&#38190;&#30340;&#25216;&#26415;&#24037;&#20855;&#26159;&#19968;&#31181;&#26032;&#30340;&#20301;&#25552;&#21462;&#25216;&#26415;&#65292;&#23427;&#25552;&#20379;&#20102;&#31232;&#30095;&#21521;&#37327;&#30340;&#26368;&#20339;&#32534;&#30721;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;$p&gt;q$&#30340;&#38750;&#32447;&#24615;&#21306;&#22495;&#33719;&#24471;&#23574;&#38160;&#30340;&#19978;&#30028;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#30340;$L_p$&#36924;&#36817;&#19979;&#30028;&#25512;&#23548;&#30340;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Let $\Omega = [0,1]^d$ be the unit cube in $\mathbb{R}^d$. We study the problem of how efficiently, in terms of the number of parameters, deep neural networks with the ReLU activation function can approximate functions in the Sobolev spaces $W^s(L_q(\Omega))$ and Besov spaces $B^s_r(L_q(\Omega))$, with error measured in the $L_p(\Omega)$ norm. This problem is important when studying the application of neural networks in a variety of fields, including scientific computing and signal processing, and has previously been completely solved only when $p=q=\infty$. Our contribution is to provide a complete solution for all $1\leq p,q\leq \infty$ and $s &gt; 0$, including asymptotically matching upper and lower bounds. The key technical tool is a novel bit-extraction technique which gives an optimal encoding of sparse vectors. This enables us to obtain sharp upper bounds in the non-linear regime where $p &gt; q$. We also provide a novel method for deriving $L_p$-approximation lower bounds based upon
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;$k$-&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#22312;&#25345;&#20037;&#22270;&#31354;&#38388;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#35299;&#20915;&#20102;&#20195;&#25968;&#26500;&#36896;&#23548;&#33268;&#30340;&#22797;&#26434;&#24230;&#38382;&#39064;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#30452;&#25509;&#22312;&#25345;&#20037;&#22270;&#21644;&#25345;&#20037;&#24230;&#37327;&#19978;&#36827;&#34892;&#32858;&#31867;&#20248;&#20110;&#21521;&#37327;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2210.10003</link><description>&lt;p&gt;
$k$-&#22343;&#20540;&#32858;&#31867;&#29992;&#20110;&#25345;&#20037;&#21516;&#35843;
&lt;/p&gt;
&lt;p&gt;
$k$-Means Clustering for Persistent Homology. (arXiv:2210.10003v3 [stat.AP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.10003
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;$k$-&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#22312;&#25345;&#20037;&#22270;&#31354;&#38388;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#35299;&#20915;&#20102;&#20195;&#25968;&#26500;&#36896;&#23548;&#33268;&#30340;&#22797;&#26434;&#24230;&#38382;&#39064;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#30452;&#25509;&#22312;&#25345;&#20037;&#22270;&#21644;&#25345;&#20037;&#24230;&#37327;&#19978;&#36827;&#34892;&#32858;&#31867;&#20248;&#20110;&#21521;&#37327;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25345;&#20037;&#21516;&#35843;&#26159;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#25552;&#21462;&#21644;&#24635;&#32467;&#25968;&#25454;&#38598;&#20013;&#30340;&#25299;&#25169;&#29305;&#24449;&#65292;&#24182;&#20197;&#25345;&#20037;&#22270;&#30340;&#24418;&#24335;&#34920;&#31034;&#12290;&#36817;&#24180;&#26469;&#65292;&#22312;&#35768;&#22810;&#39046;&#22495;&#20013;&#24191;&#27867;&#24212;&#29992;&#30340;&#25345;&#20037;&#21516;&#35843;&#26041;&#27861;&#21463;&#21040;&#20102;&#24456;&#22823;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#23427;&#30340;&#20195;&#25968;&#26500;&#36896;&#23548;&#33268;&#20102;&#19968;&#20010;&#20855;&#26377;&#39640;&#24230;&#22797;&#26434;&#20960;&#20309;&#30340;&#25345;&#32493;&#22270;&#31354;&#38388;&#30340;&#24230;&#37327;&#31354;&#38388;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;$k$-&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#22312;&#25345;&#20037;&#22270;&#31354;&#38388;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#22312;Karush-Kuhn-Tucker&#26694;&#26550;&#19979;&#24314;&#31435;&#20102;&#20248;&#21270;&#38382;&#39064;&#30340;&#29702;&#35770;&#24615;&#36136;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#25345;&#20037;&#21516;&#35843;&#30340;&#21508;&#31181;&#34920;&#31034;&#36827;&#34892;&#20102;&#25968;&#20540;&#23454;&#39564;&#65292;&#21253;&#25324;&#25345;&#20037;&#22270;&#30340;&#23884;&#20837;&#20197;&#21450;&#22270;&#21644;&#23427;&#20204;&#30340;&#25512;&#24191;&#20316;&#20026;&#25345;&#20037;&#24230;&#37327;&#65307;&#25105;&#20204;&#21457;&#29616;&#65292;&#30452;&#25509;&#22312;&#25345;&#20037;&#22270;&#21644;&#25345;&#20037;&#24230;&#37327;&#19978;&#36827;&#34892;&#32858;&#31867;&#30340;&#24615;&#33021;&#20248;&#20110;&#23427;&#20204;&#30340;&#21521;&#37327;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Persistent homology is a methodology central to topological data analysis that extracts and summarizes the topological features within a dataset as a persistence diagram; it has recently gained much popularity from its myriad successful applications to many domains. However, its algebraic construction induces a metric space of persistence diagrams with a highly complex geometry. In this paper, we prove convergence of the $k$-means clustering algorithm on persistence diagram space and establish theoretical properties of the solution to the optimization problem in the Karush--Kuhn--Tucker framework. Additionally, we perform numerical experiments on various representations of persistent homology, including embeddings of persistence diagrams as well as diagrams themselves and their generalizations as persistence measures; we find that clustering performance directly on persistence diagrams and measures outperform their vectorized representations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#22238;&#24402;&#26694;&#26550;&#20013;&#30340;&#38477;&#32500;&#19982;Wasserstein&#31283;&#23450;&#24615;&#24212;&#29992;&#65292;&#38024;&#23545;&#22312;&#25200;&#21160;&#36755;&#20837;&#25968;&#25454;&#29992;&#20110;&#25311;&#21512;&#22238;&#24402;&#20989;&#25968;&#26102;&#20986;&#29616;&#30340;&#35823;&#24046;&#25512;&#23548;&#20102;&#31283;&#23450;&#24615;&#32467;&#26524;&#65292;&#24182;&#21033;&#29992;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#26680;&#22238;&#24402;&#25991;&#29486;&#20013;&#30340;&#20272;&#35745;&#65292;&#25512;&#23548;&#20102;&#20004;&#27493;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2203.09347</link><description>&lt;p&gt;
&#38477;&#32500;&#19982;Wasserstein&#31283;&#23450;&#24615;&#22312;&#26680;&#22238;&#24402;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Dimensionality Reduction and Wasserstein Stability for Kernel Regression. (arXiv:2203.09347v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.09347
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#22238;&#24402;&#26694;&#26550;&#20013;&#30340;&#38477;&#32500;&#19982;Wasserstein&#31283;&#23450;&#24615;&#24212;&#29992;&#65292;&#38024;&#23545;&#22312;&#25200;&#21160;&#36755;&#20837;&#25968;&#25454;&#29992;&#20110;&#25311;&#21512;&#22238;&#24402;&#20989;&#25968;&#26102;&#20986;&#29616;&#30340;&#35823;&#24046;&#25512;&#23548;&#20102;&#31283;&#23450;&#24615;&#32467;&#26524;&#65292;&#24182;&#21033;&#29992;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#26680;&#22238;&#24402;&#25991;&#29486;&#20013;&#30340;&#20272;&#35745;&#65292;&#25512;&#23548;&#20102;&#20004;&#27493;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#22238;&#24402;&#26694;&#26550;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#26420;&#32032;&#30340;&#20004;&#27493;&#27861;&#65292;&#39318;&#20808;&#38477;&#20302;&#36755;&#20837;&#21464;&#37327;&#30340;&#32500;&#25968;&#65292;&#20877;&#20351;&#29992;&#26680;&#22238;&#24402;&#26469;&#39044;&#27979;&#36755;&#20986;&#21464;&#37327;&#12290;&#20026;&#20102;&#20998;&#26512;&#30001;&#27492;&#20135;&#29983;&#30340;&#22238;&#24402;&#35823;&#24046;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#20010;&#38024;&#23545;Wasserstein&#36317;&#31163;&#30340;&#26032;&#30340;&#26680;&#22238;&#24402;&#31283;&#23450;&#24615;&#32467;&#26524;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#38480;&#21046;&#24403;&#25200;&#21160;&#36755;&#20837;&#25968;&#25454;&#29992;&#20110;&#25311;&#21512;&#22238;&#24402;&#20989;&#25968;&#26102;&#20986;&#29616;&#30340;&#35823;&#24046;&#12290;&#25105;&#20204;&#23558;&#36890;&#29992;&#30340;&#31283;&#23450;&#24615;&#32467;&#26524;&#24212;&#29992;&#20110;&#20027;&#25104;&#20998;&#20998;&#26512;(PCA)&#65292;&#21033;&#29992;&#24050;&#30693;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#26680;&#22238;&#24402;&#25991;&#29486;&#20013;&#30340;&#20272;&#35745;&#65292;&#25512;&#23548;&#20986;&#20102;&#20004;&#27493;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#21518;&#32773;&#22312;&#21322;&#30417;&#30563;&#35774;&#32622;&#20013;&#29305;&#21035;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In a high-dimensional regression framework, we study consequences of the naive two-step procedure where first the dimension of the input variables is reduced and second, the reduced input variables are used to predict the output variable with kernel regression. In order to analyze the resulting regression errors, a novel stability result for kernel regression with respect to the Wasserstein distance is derived. This allows us to bound errors that occur when perturbed input data is used to fit the regression function. We apply the general stability result to principal component analysis (PCA). Exploiting known estimates from the literature on both principal component analysis and kernel regression, we deduce convergence rates for the two-step procedure. The latter turns out to be particularly useful in a semi-supervised setting.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#39640;&#26031;&#36807;&#31243;&#25554;&#20540;&#20013;&#20809;&#28369;&#21442;&#25968;&#20272;&#35745;&#30340;&#28176;&#36817;&#30028;&#38480;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#20809;&#28369;&#21442;&#25968;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#19981;&#33021;&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#27424;&#24179;&#28369;&#30495;&#20540;&#65292;&#24182;&#19988;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#33021;&#24674;&#22797;&#19968;&#31867;&#20998;&#27573;&#25903;&#25345;&#33258;&#30456;&#20284;&#20989;&#25968;&#30340;&#30495;&#23454;&#20809;&#28369;&#24230;&#12290;</title><link>http://arxiv.org/abs/2203.05400</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#25554;&#20540;&#20013;&#20809;&#28369;&#21442;&#25968;&#20272;&#35745;&#30340;&#28176;&#36817;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Asymptotic Bounds for Smoothness Parameter Estimates in Gaussian Process Interpolation. (arXiv:2203.05400v4 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.05400
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#39640;&#26031;&#36807;&#31243;&#25554;&#20540;&#20013;&#20809;&#28369;&#21442;&#25968;&#20272;&#35745;&#30340;&#28176;&#36817;&#30028;&#38480;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#20809;&#28369;&#21442;&#25968;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#19981;&#33021;&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#27424;&#24179;&#28369;&#30495;&#20540;&#65292;&#24182;&#19988;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#33021;&#24674;&#22797;&#19968;&#31867;&#20998;&#27573;&#25903;&#25345;&#33258;&#30456;&#20284;&#20989;&#25968;&#30340;&#30495;&#23454;&#20809;&#28369;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24120;&#35265;&#30340;&#26041;&#27861;&#26159;&#29992;Matern&#21327;&#26041;&#24046;&#26680;&#23558;&#30830;&#23450;&#24615;&#21709;&#24212;&#20989;&#25968;&#65288;&#22914;&#35745;&#31639;&#26426;&#23454;&#39564;&#30340;&#36755;&#20986;&#65289;&#24314;&#27169;&#20026;&#39640;&#26031;&#36807;&#31243;&#12290;Matern&#26680;&#30340;&#20809;&#28369;&#21442;&#25968;&#20915;&#23450;&#20102;&#27169;&#22411;&#22312;&#22823;&#25968;&#25454;&#26497;&#38480;&#19979;&#30340;&#35768;&#22810;&#37325;&#35201;&#23646;&#24615;&#65292;&#21253;&#25324;&#26465;&#20214;&#22343;&#20540;&#25910;&#25947;&#21040;&#21709;&#24212;&#20989;&#25968;&#30340;&#36895;&#29575;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#24403;&#25968;&#25454;&#22312;&#22266;&#23450;&#26377;&#30028;&#23376;&#38598;$\mathbb{R}^d$&#19978;&#33719;&#24471;&#26102;&#65292;&#20809;&#28369;&#21442;&#25968;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#19981;&#33021;&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#27424;&#24179;&#28369;&#30495;&#20540;&#12290;&#25442;&#21477;&#35805;&#35828;&#65292;&#22914;&#26524;&#25968;&#25454;&#29983;&#25104;&#30340;&#21709;&#24212;&#20989;&#25968;&#20855;&#26377;Sobolev&#20809;&#28369;&#24230;$\nu_0 &gt; d/2$&#65292;&#37027;&#20040;&#20809;&#28369;&#21442;&#25968;&#20272;&#35745;&#19981;&#33021;&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#23567;&#20110;$\nu_0$&#12290;&#36825;&#19968;&#19979;&#30028;&#26159;&#31934;&#20934;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22312;&#19968;&#31867;&#20998;&#27573;&#25903;&#25345;&#33258;&#30456;&#20284;&#20989;&#25968;&#20013;&#33021;&#24674;&#22797;&#30495;&#23454;&#30340;&#20809;&#28369;&#24230;&#12290;&#23545;&#20110;&#20132;&#21449;&#39564;&#35777;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#28176;&#36817;&#19979;&#30028;$\nu_0-d/2$&#65292;&#20294;&#36825;&#24456;&#19981;&#21487;&#33021;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is common to model a deterministic response function, such as the output of a computer experiment, as a Gaussian process with a Mat\'ern covariance kernel. The smoothness parameter of a Mat\'ern kernel determines many important properties of the model in the large data limit, including the rate of convergence of the conditional mean to the response function. We prove that the maximum likelihood estimate of the smoothness parameter cannot asymptotically undersmooth the truth when the data are obtained on a fixed bounded subset of $\mathbb{R}^d$. That is, if the data-generating response function has Sobolev smoothness $\nu_0 &gt; d/2$, then the smoothness parameter estimate cannot be asymptotically less than $\nu_0$. The lower bound is sharp. Additionally, we show that maximum likelihood estimation recovers the true smoothness for a class of compactly supported self-similar functions. For cross-validation we prove an asymptotic lower bound $\nu_0 - d/2$, which however is unlikely to be s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#24179;&#26041;&#26681;&#36895;&#24230;&#20989;&#25968;&#30340;&#26032;&#34920;&#31034;&#26041;&#27861;&#21644;&#24230;&#37327;&#26041;&#27861;&#65292;&#29992;&#20110;&#20998;&#26512;&#21644;&#27604;&#36739;&#26641;&#29366;&#19977;&#32500;&#29289;&#20307;&#65292;&#20174;&#32780;&#25552;&#39640;&#29289;&#20307;&#24418;&#29366;&#24046;&#24322;&#35745;&#31639;&#30340;&#31934;&#24230;&#21644;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2110.08693</link><description>&lt;p&gt;
&#23398;&#20064;&#26641;&#29366;&#19977;&#32500;&#29289;&#20307;&#30340;&#20960;&#20309;&#21644;&#25299;&#25169;&#30340;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning Generative Models of the Geometry and Topology of Tree-like 3D Objects. (arXiv:2110.08693v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.08693
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#24179;&#26041;&#26681;&#36895;&#24230;&#20989;&#25968;&#30340;&#26032;&#34920;&#31034;&#26041;&#27861;&#21644;&#24230;&#37327;&#26041;&#27861;&#65292;&#29992;&#20110;&#20998;&#26512;&#21644;&#27604;&#36739;&#26641;&#29366;&#19977;&#32500;&#29289;&#20307;&#65292;&#20174;&#32780;&#25552;&#39640;&#29289;&#20307;&#24418;&#29366;&#24046;&#24322;&#35745;&#31639;&#30340;&#31934;&#24230;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#20309;&#20998;&#26512;&#23637;&#29616;&#20986;&#22797;&#26434;&#20960;&#20309;&#21644;&#25299;&#25169;&#21464;&#21270;&#30340;&#35814;&#32454;&#19977;&#32500;&#29983;&#29289;&#29289;&#20307;&#65292;&#20363;&#22914;&#31070;&#32463;&#20803;&#21644;&#26893;&#29289;&#26641;&#65311;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#23398;&#26694;&#26550;&#65292;&#29992;&#20110;&#34920;&#31034;&#12289;&#27604;&#36739;&#21644;&#35745;&#31639;&#36825;&#20123;&#26641;&#29366;&#19977;&#32500;&#23545;&#35937;&#30340;&#24418;&#29366;&#24046;&#24322;&#65292;&#24182;&#23450;&#20041;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26041;&#27861;&#26469;&#37327;&#21270;&#23558;&#19968;&#20010;&#26641;&#29366;&#29289;&#20307;&#21464;&#24418;&#20026;&#21478;&#19968;&#20010;&#29289;&#20307;&#25152;&#38656;&#30340;&#24367;&#26354;&#12289;&#25289;&#20280;&#21644;&#20998;&#25903;&#28369;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;
How can one analyze detailed 3D biological objects, such as neurons and botanical trees, that exhibit complex geometrical and topological variation? In this paper, we develop a novel mathematical framework for representing, comparing, and computing geodesic deformations between the shapes of such tree-like 3D objects. A hierarchical organization of subtrees characterizes these objects -- each subtree has the main branch with some side branches attached -- and one needs to match these structures across objects for meaningful comparisons. We propose a novel representation that extends the Square-Root Velocity Function (SRVF), initially developed for Euclidean curves, to tree-shaped 3D objects. We then define a new metric that quantifies the bending, stretching, and branch sliding needed to deform one tree-shaped object into the other. Compared to the current metrics, such as the Quotient Euclidean Distance (QED) and the Tree Edit Distance (TED), the proposed representation and metric cap
&lt;/p&gt;</description></item></channel></rss>