<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;&#29256;&#26412;&#30340;Na\"ive Bayes&#20998;&#31867;&#22120;&#65292;&#36890;&#36807;&#32771;&#34385;&#29305;&#24449;&#38388;&#30340;&#30456;&#20851;&#32467;&#26500;&#23454;&#29616;&#20102;&#31232;&#30095;&#24615;&#65292;&#24182;&#25903;&#25345;&#19981;&#21516;&#30340;&#24615;&#33021;&#24230;&#37327;&#26469;&#25351;&#23548;&#29305;&#24449;&#36873;&#25321;&#12290;</title><link>https://arxiv.org/abs/2401.18039</link><description>&lt;p&gt;
Na\"ive Bayes&#20998;&#31867;&#30340;&#21464;&#37327;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Variable selection for Na\"ive Bayes classification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.18039
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;&#29256;&#26412;&#30340;Na\"ive Bayes&#20998;&#31867;&#22120;&#65292;&#36890;&#36807;&#32771;&#34385;&#29305;&#24449;&#38388;&#30340;&#30456;&#20851;&#32467;&#26500;&#23454;&#29616;&#20102;&#31232;&#30095;&#24615;&#65292;&#24182;&#25903;&#25345;&#19981;&#21516;&#30340;&#24615;&#33021;&#24230;&#37327;&#26469;&#25351;&#23548;&#29305;&#24449;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#21464;&#37327;&#20998;&#26512;&#20013;&#65292;&#32463;&#20856;&#30340;Na\"ive Bayes&#20998;&#31867;&#26041;&#27861;&#24050;&#34987;&#35777;&#26126;&#26159;&#19968;&#31181;&#26131;&#20110;&#22788;&#29702;&#21644;&#39640;&#25928;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#29305;&#24449;&#36890;&#24120;&#26159;&#30456;&#20851;&#30340;&#65292;&#36825;&#36829;&#21453;&#20102;Na\"ive Bayes&#26465;&#20214;&#29420;&#31435;&#24615;&#30340;&#20551;&#35774;&#65292;&#21487;&#33021;&#20250;&#25439;&#23475;&#35813;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25968;&#25454;&#38598;&#36890;&#24120;&#20855;&#26377;&#22823;&#37327;&#30340;&#29305;&#24449;&#65292;&#36825;&#21487;&#33021;&#20250;&#20351;&#32467;&#26524;&#30340;&#35299;&#37322;&#21464;&#24471;&#22797;&#26434;&#65292;&#24182;&#20943;&#24930;&#35813;&#26041;&#27861;&#30340;&#25191;&#34892;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;&#29256;&#26412;&#30340;Na\"ive Bayes&#20998;&#31867;&#22120;&#65292;&#23427;&#20855;&#26377;&#19977;&#20010;&#29305;&#28857;&#12290;&#39318;&#20808;&#65292;&#36890;&#36807;&#32771;&#34385;&#21327;&#21464;&#37327;&#30340;&#30456;&#20851;&#32467;&#26500;&#23454;&#29616;&#20102;&#31232;&#30095;&#24615;&#12290;&#20854;&#27425;&#65292;&#21487;&#20197;&#20351;&#29992;&#19981;&#21516;&#30340;&#24615;&#33021;&#24230;&#37327;&#26469;&#25351;&#23548;&#29305;&#24449;&#30340;&#36873;&#25321;&#12290;&#31532;&#19977;&#65292;&#21487;&#20197;&#21253;&#25324;&#23545;&#26356;&#24863;&#20852;&#36259;&#30340;&#32452;&#21035;&#30340;&#24615;&#33021;&#32422;&#26463;&#12290;&#25105;&#20204;&#30340;&#25552;&#26696;&#21487;&#20197;&#23454;&#29616;&#26234;&#33021;&#25628;&#32034;&#65292;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#36816;&#34892;&#26102;&#38388;&#65292;&#21516;&#26102;&#22312;&#20998;&#31867;&#30340;&#24615;&#33021;&#24230;&#37327;&#26041;&#38754;&#20855;&#26377;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Na\"ive Bayes has proven to be a tractable and efficient method for classification in multivariate analysis. However, features are usually correlated, a fact that violates the Na\"ive Bayes' assumption of conditional independence, and may deteriorate the method's performance. Moreover, datasets are often characterized by a large number of features, which may complicate the interpretation of the results as well as slow down the method's execution.   In this paper we propose a sparse version of the Na\"ive Bayes classifier that is characterized by three properties. First, the sparsity is achieved taking into account the correlation structure of the covariates. Second, different performance measures can be used to guide the selection of features. Third, performance constraints on groups of higher interest can be included. Our proposal leads to a smart search, which yields competitive running times, whereas the flexibility in terms of performance measure for classification is integrate
&lt;/p&gt;</description></item><item><title>&#36825;&#31181;&#25104;&#26412;&#25935;&#24863;&#30340;&#32422;&#26463;Lasso&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;Lasso&#29256;&#26412;&#65292;&#22312;Lasso&#22522;&#30784;&#19978;&#28155;&#21152;&#20102;&#20108;&#27425;&#24615;&#33021;&#32422;&#26463;&#65292;&#20197;&#38480;&#21046;&#19981;&#21516;&#24863;&#20852;&#36259;&#32452;&#20013;&#30340;&#39044;&#27979;&#35823;&#24046;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#24322;&#36136;&#26679;&#26412;&#65292;&#20855;&#26377;&#35768;&#22810;&#29983;&#29289;&#21307;&#23398;&#32972;&#26223;&#19979;&#30340;&#30452;&#25509;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2401.18023</link><description>&lt;p&gt;
&#19968;&#31181;&#25104;&#26412;&#25935;&#24863;&#30340;&#32422;&#26463;Lasso
&lt;/p&gt;
&lt;p&gt;
A cost-sensitive constrained Lasso
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.18023
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31181;&#25104;&#26412;&#25935;&#24863;&#30340;&#32422;&#26463;Lasso&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;Lasso&#29256;&#26412;&#65292;&#22312;Lasso&#22522;&#30784;&#19978;&#28155;&#21152;&#20102;&#20108;&#27425;&#24615;&#33021;&#32422;&#26463;&#65292;&#20197;&#38480;&#21046;&#19981;&#21516;&#24863;&#20852;&#36259;&#32452;&#20013;&#30340;&#39044;&#27979;&#35823;&#24046;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#24322;&#36136;&#26679;&#26412;&#65292;&#20855;&#26377;&#35768;&#22810;&#29983;&#29289;&#21307;&#23398;&#32972;&#26223;&#19979;&#30340;&#30452;&#25509;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Lasso&#24050;&#32463;&#25104;&#20026;&#19968;&#20010;&#22522;&#20934;&#25968;&#25454;&#20998;&#26512;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#25991;&#29486;&#20013;&#25552;&#20986;&#20102;&#35768;&#22810;&#21464;&#20307;&#12290;&#34429;&#28982;Lasso&#30340;&#20844;&#24335;&#26159;&#20026;&#20102;&#20248;&#21270;&#25972;&#20307;&#39044;&#27979;&#35823;&#24046;&#32780;&#35774;&#23450;&#30340;&#65292;&#20294;&#19981;&#33021;&#23545;&#24863;&#20852;&#36259;&#30340;&#29305;&#23450;&#20010;&#20307;&#30340;&#20934;&#30830;&#24615;&#39044;&#27979;&#36827;&#34892;&#23436;&#20840;&#25511;&#21046;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;Lasso&#29256;&#26412;&#65292;&#20854;&#20013;&#36890;&#36807;&#21521;&#22522;&#20110;Lasso&#30340;&#30446;&#26631;&#20989;&#25968;&#28155;&#21152;&#20108;&#27425;&#24615;&#33021;&#32422;&#26463;&#30340;&#26041;&#24335;&#26469;&#35774;&#32622;&#38408;&#20540;&#65292;&#20197;&#38480;&#21046;&#19981;&#21516;&#24863;&#20852;&#36259;&#32452;&#65288;&#19981;&#19968;&#23450;&#20114;&#26021;&#65289;&#20013;&#30340;&#39044;&#27979;&#35823;&#24046;&#12290;&#22240;&#27492;&#65292;&#36890;&#36807;&#38750;&#32447;&#24615;&#20248;&#21270;&#38382;&#39064;&#23450;&#20041;&#20102;&#19968;&#31181;&#21463;&#25104;&#26412;&#38480;&#21046;&#30340;&#31232;&#30095;&#22238;&#24402;&#27169;&#22411;&#12290;&#36825;&#31181;&#25104;&#26412;&#25935;&#24863;&#30340;&#32422;&#26463;Lasso&#22312;&#24322;&#36136;&#26679;&#26412;&#20013;&#20855;&#26377;&#30452;&#25509;&#24212;&#29992;&#65292;&#20854;&#20013;&#25968;&#25454;&#26159;&#20174;&#19981;&#21516;&#26469;&#28304;&#25910;&#38598;&#30340;&#65292;&#36825;&#22312;&#35768;&#22810;&#29983;&#29289;&#21307;&#23398;&#32972;&#26223;&#19979;&#26159;&#26631;&#20934;&#30340;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#36825;&#31181;&#26032;&#26041;&#27861;&#30340;&#29702;&#35770;&#24615;&#36136;&#21644;&#32463;&#39564;&#35777;&#26126;&#30740;&#31350;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#36824;&#36827;&#34892;&#20102;&#20004;&#20010;&#24212;&#29992;&#31034;&#20363;&#30340;&#28436;&#31034;&#65306;
&lt;/p&gt;
&lt;p&gt;
The Lasso has become a benchmark data analysis procedure, and numerous variants have been proposed in the literature. Although the Lasso formulations are stated so that overall prediction error is optimized, no full control over the accuracy prediction on certain individuals of interest is allowed. In this work we propose a novel version of the Lasso in which quadratic performance constraints are added to Lasso-based objective functions, in such a way that threshold values are set to bound the prediction errors in the different groups of interest (not necessarily disjoint). As a result, a constrained sparse regression model is defined by a nonlinear optimization problem. This cost-sensitive constrained Lasso has a direct application in heterogeneous samples where data are collected from distinct sources, as it is standard in many biomedical contexts. Both theoretical properties and empirical studies concerning the new method are explored in this paper. In addition, two illustrations of
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24322;&#26500;&#21464;&#25442;&#30340;&#26680;&#20559;&#24046;&#27979;&#37327;&#26469;&#35299;&#20915;&#22240;&#26524;&#20851;&#31995;&#21457;&#29616;&#20013;&#30340;&#25361;&#25112;&#65292;&#20197;&#25429;&#25417;&#22240;&#26524;&#20851;&#31995;&#21644;&#25928;&#24212;&#20043;&#38388;&#30340;&#39640;&#38454;&#32467;&#26500;&#21464;&#24322;&#30340;&#20027;&#35201;&#26631;&#35760;&#12290;</title><link>https://arxiv.org/abs/2401.18017</link><description>&lt;p&gt;
&#36890;&#36807;&#24322;&#26500;&#21464;&#25442;&#30340;&#26680;&#20559;&#24046;&#27979;&#37327;&#26469;&#36827;&#34892;&#22240;&#26524;&#20851;&#31995;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Causal Discovery by Kernel Deviance Measures with Heterogeneous Transforms
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.18017
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24322;&#26500;&#21464;&#25442;&#30340;&#26680;&#20559;&#24046;&#27979;&#37327;&#26469;&#35299;&#20915;&#22240;&#26524;&#20851;&#31995;&#21457;&#29616;&#20013;&#30340;&#25361;&#25112;&#65292;&#20197;&#25429;&#25417;&#22240;&#26524;&#20851;&#31995;&#21644;&#25928;&#24212;&#20043;&#38388;&#30340;&#39640;&#38454;&#32467;&#26500;&#21464;&#24322;&#30340;&#20027;&#35201;&#26631;&#35760;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19968;&#32452;&#38543;&#26426;&#21464;&#37327;&#20013;&#21457;&#29616;&#22240;&#26524;&#20851;&#31995;&#26159;&#31185;&#23398;&#30340;&#22522;&#26412;&#30446;&#26631;&#65292;&#24182;&#19988;&#26368;&#36817;&#20063;&#34987;&#35748;&#20026;&#26159;&#23454;&#29616;&#30495;&#27491;&#26426;&#22120;&#26234;&#33021;&#30340;&#24517;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#20854;&#20013;&#19968;&#31867;&#22240;&#26524;&#20851;&#31995;&#21457;&#29616;&#25216;&#26415;&#22522;&#20110;&#36825;&#26679;&#19968;&#31181;&#35770;&#28857;&#65306;&#22240;&#26524;&#26041;&#21521;&#21644;&#21453;&#22240;&#26524;&#26041;&#21521;&#20043;&#38388;&#23384;&#22312;&#22266;&#26377;&#30340;&#32467;&#26500;&#19981;&#23545;&#31216;&#24615;&#65292;&#21487;&#20197;&#21033;&#29992;&#36825;&#31181;&#19981;&#23545;&#31216;&#24615;&#26469;&#30830;&#23450;&#22240;&#26524;&#20851;&#31995;&#30340;&#26041;&#21521;&#12290;&#28982;&#32780;&#65292;&#22914;&#20309;&#25429;&#25417;&#22240;&#26524;&#20851;&#31995;&#21644;&#25928;&#24212;&#20043;&#38388;&#30340;&#24046;&#24322;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#65292;&#35768;&#22810;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#25552;&#20986;&#20102;&#36890;&#36807;&#27604;&#36739;&#26465;&#20214;&#20998;&#24067;&#30340;&#26680;&#22343;&#20540;&#23884;&#20837;&#30340;&#33539;&#25968;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#26412;&#25991;&#35748;&#20026;&#65292;&#22522;&#20110;RKHS&#23884;&#20837;&#30340;&#36825;&#31181;&#26041;&#27861;&#19981;&#36275;&#20197;&#25429;&#25417;&#28041;&#21450;&#26465;&#20214;&#20998;&#24067;&#30340;&#39640;&#38454;&#32467;&#26500;&#21464;&#24322;&#30340;&#20027;&#35201;&#26631;&#35760;&#30340;&#22240;&#26524;&#25928;&#24212;&#19981;&#23545;&#31216;&#24615;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24341;&#20837;&#20102;&#24322;&#26500;&#21464;&#25442;&#30340;&#26680;&#20869;&#22312;&#19981;&#21464;&#24615;&#27979;&#37327;&#65288;KIIM-HT&#65289;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The discovery of causal relationships in a set of random variables is a fundamental objective of science and has also recently been argued as being an essential component towards real machine intelligence. One class of causal discovery techniques are founded based on the argument that there are inherent structural asymmetries between the causal and anti-causal direction which could be leveraged in determining the direction of causation. To go about capturing these discrepancies between cause and effect remains to be a challenge and many current state-of-the-art algorithms propose to compare the norms of the kernel mean embeddings of the conditional distributions. In this work, we argue that such approaches based on RKHS embeddings are insufficient in capturing principal markers of cause-effect asymmetry involving higher-order structural variabilities of the conditional distributions. We propose Kernel Intrinsic Invariance Measure with Heterogeneous Transform (KIIM-HT) which introduces 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#24182;&#21457;&#24378;&#21270;&#23398;&#20064;&#30340;&#26032;&#31639;&#27861;&#26694;&#26550;&#65292;&#36890;&#36807;&#25968;&#25454;&#20849;&#20139;&#21644;&#21327;&#21516;&#25506;&#32034;&#26469;&#23398;&#20064;&#26356;&#39640;&#25928;&#21644;&#34920;&#29616;&#26356;&#22909;&#30340;&#31574;&#30053;&#12290;&#31639;&#27861;&#20013;&#21033;&#29992;&#22240;&#26524;&#25512;&#26029;&#31639;&#27861;&#25552;&#21462;&#25511;&#21046;&#20010;&#20307;&#24046;&#24322;&#30340;&#27169;&#22411;&#21442;&#25968;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30456;&#20284;&#24615;&#24230;&#37327;&#30340;&#25968;&#25454;&#20849;&#20139;&#26041;&#26696;&#65292;&#23637;&#31034;&#20102;&#26356;&#24555;&#30340;&#23398;&#20064;&#36895;&#24230;&#21644;&#22810;&#26679;&#21270;&#21160;&#20316;&#36873;&#25321;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2401.18012</link><description>&lt;p&gt;
&#22240;&#26524;&#21327;&#21516;&#24182;&#21457;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Causal Coordinated Concurrent Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.18012
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#24182;&#21457;&#24378;&#21270;&#23398;&#20064;&#30340;&#26032;&#31639;&#27861;&#26694;&#26550;&#65292;&#36890;&#36807;&#25968;&#25454;&#20849;&#20139;&#21644;&#21327;&#21516;&#25506;&#32034;&#26469;&#23398;&#20064;&#26356;&#39640;&#25928;&#21644;&#34920;&#29616;&#26356;&#22909;&#30340;&#31574;&#30053;&#12290;&#31639;&#27861;&#20013;&#21033;&#29992;&#22240;&#26524;&#25512;&#26029;&#31639;&#27861;&#25552;&#21462;&#25511;&#21046;&#20010;&#20307;&#24046;&#24322;&#30340;&#27169;&#22411;&#21442;&#25968;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30456;&#20284;&#24615;&#24230;&#37327;&#30340;&#25968;&#25454;&#20849;&#20139;&#26041;&#26696;&#65292;&#23637;&#31034;&#20102;&#26356;&#24555;&#30340;&#23398;&#20064;&#36895;&#24230;&#21644;&#22810;&#26679;&#21270;&#21160;&#20316;&#36873;&#25321;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#25968;&#25454;&#20849;&#20139;&#21644;&#21327;&#21516;&#25506;&#32034;&#65292;&#20197;&#22312;&#24182;&#21457;&#24378;&#21270;&#23398;&#20064;&#65288;CRL&#65289;&#29615;&#22659;&#19979;&#23398;&#20064;&#26356;&#39640;&#25928;&#21644;&#34920;&#29616;&#26356;&#22909;&#30340;&#31574;&#30053;&#12290;&#19982;&#20854;&#20182;&#20551;&#35774;&#25152;&#26377;&#20195;&#29702;&#37117;&#22312;&#30456;&#21516;&#29615;&#22659;&#19979;&#34892;&#21160;&#30340;&#24037;&#20316;&#30456;&#27604;&#65292;&#25105;&#20204;&#25918;&#23485;&#20102;&#36825;&#19968;&#38480;&#21046;&#65292;&#32780;&#26159;&#32771;&#34385;&#27599;&#20010;&#20195;&#29702;&#22312;&#20849;&#20139;&#20840;&#23616;&#32467;&#26500;&#20294;&#20063;&#23384;&#22312;&#20010;&#20307;&#24046;&#24322;&#30340;&#29615;&#22659;&#20013;&#34892;&#21160;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#21033;&#29992;&#20102;&#19968;&#20010;&#22240;&#26524;&#25512;&#26029;&#31639;&#27861;&#65292;&#21363;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411; - &#28151;&#21512;&#27169;&#22411;&#65288;ANM-MM&#65289;&#65292;&#36890;&#36807;&#29420;&#31435;&#24615;&#24378;&#21270;&#25552;&#21462;&#25511;&#21046;&#20010;&#20307;&#24046;&#24322;&#30340;&#27169;&#22411;&#21442;&#25968;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25552;&#21462;&#30340;&#27169;&#22411;&#21442;&#25968;&#30456;&#20284;&#24615;&#24230;&#37327;&#30340;&#25968;&#25454;&#20849;&#20139;&#26041;&#26696;&#65292;&#24182;&#22312;&#19968;&#32452;&#33258;&#22238;&#24402;&#12289;&#25670;&#26438;&#21644;&#20498;&#31435;&#25670;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#26356;&#24555;&#30340;&#23398;&#20064;&#36895;&#24230;&#65292;&#26368;&#21518;&#25105;&#20204;&#23637;&#31034;&#20102;&#22810;&#26679;&#21270;&#21160;&#20316;&#36873;&#25321;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we propose a novel algorithmic framework for data sharing and coordinated exploration for the purpose of learning more data-efficient and better performing policies under a concurrent reinforcement learning (CRL) setting. In contrast to other work which make the assumption that all agents act under identical environments, we relax this restriction and instead consider the formulation where each agent acts within an environment which shares a global structure but also exhibits individual variations. Our algorithm leverages a causal inference algorithm in the form of Additive Noise Model - Mixture Model (ANM-MM) in extracting model parameters governing individual differentials via independence enforcement. We propose a new data sharing scheme based on a similarity measure of the extracted model parameters and demonstrate superior learning speeds on a set of autoregressive, pendulum and cart-pole swing-up tasks and finally, we show the effectiveness of diverse action selecti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#22312;2-Wasserstein&#36317;&#31163;&#20013;&#30340;&#19968;&#33324;&#31867;&#27010;&#29575;&#27969;ODE&#25277;&#26679;&#22120;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#20551;&#35774;&#24471;&#20998;&#20272;&#35745;&#20934;&#30830;&#12290;</title><link>https://arxiv.org/abs/2401.17958</link><description>&lt;p&gt;
&#22312;Wasserstein&#36317;&#31163;&#20013;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#19968;&#33324;&#27010;&#29575;&#27969;ODE&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Convergence Analysis for General Probability Flow ODEs of Diffusion Models in Wasserstein Distances
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17958
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#22312;2-Wasserstein&#36317;&#31163;&#20013;&#30340;&#19968;&#33324;&#31867;&#27010;&#29575;&#27969;ODE&#25277;&#26679;&#22120;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#20551;&#35774;&#24471;&#20998;&#20272;&#35745;&#20934;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27010;&#29575;&#27969;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#30340;&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#12290;&#34429;&#28982;&#25991;&#29486;&#20013;&#25552;&#20986;&#20102;&#21508;&#31181;&#24555;&#36895;&#30340;&#22522;&#20110;ODE&#30340;&#25277;&#26679;&#22120;&#24182;&#22312;&#23454;&#36341;&#20013;&#20351;&#29992;&#65292;&#20294;&#23545;&#27010;&#29575;&#27969;ODE&#30340;&#25910;&#25947;&#24615;&#23646;&#24615;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#38750;&#24120;&#26377;&#38480;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#36866;&#29992;&#20110;2-Wasserstein&#36317;&#31163;&#20013;&#30340;&#19968;&#33324;&#31867;&#27010;&#29575;&#27969;ODE&#25277;&#26679;&#22120;&#30340;&#39318;&#20010;&#38750;&#28176;&#36817;&#25910;&#25947;&#24615;&#20998;&#26512;&#32467;&#26524;&#65292;&#20551;&#35774;&#20934;&#30830;&#30340;&#24471;&#20998;&#20272;&#35745;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#21508;&#31181;&#31034;&#20363;&#65292;&#24182;&#30830;&#23450;&#20102;&#30456;&#24212;&#22522;&#20110;ODE&#30340;&#25277;&#26679;&#22120;&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based generative modeling with probability flow ordinary differential equations (ODEs) has achieved remarkable success in a variety of applications. While various fast ODE-based samplers have been proposed in the literature and employed in practice, the theoretical understandings about convergence properties of the probability flow ODE are still quite limited. In this paper, we provide the first non-asymptotic convergence analysis for a general class of probability flow ODE samplers in 2-Wasserstein distance, assuming accurate score estimates. We then consider various examples and establish results on the iteration complexity of the corresponding ODE-based samplers.
&lt;/p&gt;</description></item><item><title>&#22810;&#20219;&#21153;&#26041;&#27861;&#21487;&#20197;&#36890;&#36807;&#21033;&#29992;&#24322;&#36136;&#25968;&#25454;&#28304;&#26469;&#39044;&#27979;&#20998;&#23376;&#23646;&#24615;&#65292;&#22823;&#22823;&#38477;&#20302;&#25968;&#25454;&#29983;&#25104;&#25104;&#26412;&#65292;&#24182;&#19988;&#36798;&#21040;&#19982;&#32806;&#21512;&#31751;&#25968;&#25454;&#30456;&#24403;&#30340;&#20934;&#30830;&#24230;&#12290;</title><link>https://arxiv.org/abs/2401.17898</link><description>&lt;p&gt;
&#20174;&#24322;&#36136;&#25968;&#25454;&#39044;&#27979;&#20998;&#23376;&#23646;&#24615;&#30340;&#22810;&#20219;&#21153;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Multitask methods for predicting molecular properties from heterogeneous data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17898
&lt;/p&gt;
&lt;p&gt;
&#22810;&#20219;&#21153;&#26041;&#27861;&#21487;&#20197;&#36890;&#36807;&#21033;&#29992;&#24322;&#36136;&#25968;&#25454;&#28304;&#26469;&#39044;&#27979;&#20998;&#23376;&#23646;&#24615;&#65292;&#22823;&#22823;&#38477;&#20302;&#25968;&#25454;&#29983;&#25104;&#25104;&#26412;&#65292;&#24182;&#19988;&#36798;&#21040;&#19982;&#32806;&#21512;&#31751;&#25968;&#25454;&#30456;&#24403;&#30340;&#20934;&#30830;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#29983;&#25104;&#20173;&#28982;&#26159;&#35757;&#32451;&#20195;&#29702;&#27169;&#22411;&#39044;&#27979;&#20998;&#23376;&#23646;&#24615;&#30340;&#29942;&#39048;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22810;&#20219;&#21153;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#36890;&#36807;&#21033;&#29992;&#26114;&#36149;&#21644;&#24265;&#20215;&#30340;&#25968;&#25454;&#28304;&#65292;&#20811;&#26381;&#20102;&#36825;&#20010;&#38480;&#21046;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#32771;&#34385;&#20174;&#32806;&#21512;&#31751;&#65288;CC&#65289;&#21644;&#23494;&#24230;&#27867;&#20989;&#29702;&#35770;&#65288;DFT&#65289;&#25968;&#25454;&#26500;&#24314;&#30340;&#35757;&#32451;&#38598;&#12290;&#25105;&#20204;&#25253;&#21578;&#35828;&#65292;&#22810;&#20219;&#21153;&#20195;&#29702;&#27169;&#22411;&#21487;&#20197;&#20197;CC&#32423;&#31934;&#24230;&#36827;&#34892;&#39044;&#27979;&#65292;&#24182;&#19988;&#25968;&#25454;&#29983;&#25104;&#25104;&#26412;&#20943;&#23569;&#20102;&#19968;&#20010;&#25968;&#37327;&#32423;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#35757;&#32451;&#38598;&#21253;&#25324;&#30001;&#24322;&#36136;&#28151;&#21512;&#30340;&#20132;&#25442;&#30456;&#20851;&#27867;&#20989;&#29983;&#25104;&#30340;DFT&#25968;&#25454;&#65292;&#32780;&#19981;&#23545;&#27867;&#20989;&#31934;&#24230;&#26045;&#21152;&#20219;&#20309;&#20154;&#20026;&#30340;&#23618;&#27425;&#32467;&#26500;&#12290;&#26356;&#19968;&#33324;&#22320;&#65292;&#22810;&#20219;&#21153;&#26694;&#26550;&#21487;&#20197;&#36866;&#24212;&#26356;&#24191;&#27867;&#33539;&#22260;&#30340;&#35757;&#32451;&#38598;&#32467;&#26500;&#65292;&#21253;&#25324;&#19981;&#21516;&#20445;&#30495;&#32423;&#21035;&#20043;&#38388;&#30340;&#23436;&#20840;&#24046;&#24322;&#65292;&#32780;&#19981;&#20687;&#29616;&#26377;&#30340;&#22522;&#20110;$\Delta$&#23398;&#20064;&#30340;&#26680;&#26041;&#27861;&#37027;&#26679;&#65292;&#25105;&#20204;&#35777;&#26126;&#36825;&#20004;&#31181;&#26041;&#27861;&#30340;&#20934;&#30830;&#24230;&#21487;&#20197;&#30456;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data generation remains a bottleneck in training surrogate models to predict molecular properties. We demonstrate that multitask Gaussian process regression overcomes this limitation by leveraging both expensive and cheap data sources. In particular, we consider training sets constructed from coupled-cluster (CC) and density function theory (DFT) data. We report that multitask surrogates can predict at CC level accuracy with a reduction to data generation cost by over an order of magnitude. Of note, our approach allows the training set to include DFT data generated by a heterogeneous mix of exchange-correlation functionals without imposing any artificial hierarchy on functional accuracy. More generally, the multitask framework can accommodate a wider range of training set structures -- including full disparity between the different levels of fidelity -- than existing kernel approaches based on $\Delta$-learning, though we show that the accuracy of the two approaches can be similar. Con
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#40065;&#26834;&#30340;&#36807;&#25311;&#21512;&#28508;&#21464;&#37327;&#26041;&#27861;&#26469;&#25913;&#36827;&#31070;&#32463;&#22270;&#20687;&#21387;&#32553;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;SGA+&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#24182;&#20943;&#23569;&#23545;&#36229;&#21442;&#25968;&#36873;&#25321;&#30340;&#25935;&#24863;&#24615;&#12290;</title><link>https://arxiv.org/abs/2401.17789</link><description>&lt;p&gt;
&#24377;&#24615;&#31070;&#32463;&#22270;&#20687;&#21387;&#32553;&#20013;&#30340;&#40065;&#26834;&#36807;&#25311;&#21512;&#28508;&#21464;&#37327;
&lt;/p&gt;
&lt;p&gt;
Robustly overfitting latents for flexible neural image compression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17789
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#40065;&#26834;&#30340;&#36807;&#25311;&#21512;&#28508;&#21464;&#37327;&#26041;&#27861;&#26469;&#25913;&#36827;&#31070;&#32463;&#22270;&#20687;&#21387;&#32553;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;SGA+&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#24182;&#20943;&#23569;&#23545;&#36229;&#21442;&#25968;&#36873;&#25321;&#30340;&#25935;&#24863;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#22270;&#20687;&#21387;&#32553;&#21462;&#24471;&#20102;&#24456;&#22823;&#30340;&#36827;&#23637;&#12290;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#22522;&#20110;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65292;&#32988;&#36807;&#20102;&#20256;&#32479;&#27169;&#22411;&#12290;&#31070;&#32463;&#21387;&#32553;&#27169;&#22411;&#23398;&#20250;&#23558;&#22270;&#20687;&#32534;&#30721;&#20026;&#37327;&#21270;&#30340;&#28508;&#21464;&#37327;&#34920;&#31034;&#65292;&#28982;&#21518;&#23558;&#20854;&#39640;&#25928;&#22320;&#21457;&#36865;&#32473;&#35299;&#30721;&#22120;&#65292;&#35299;&#30721;&#22120;&#20877;&#23558;&#37327;&#21270;&#30340;&#28508;&#21464;&#37327;&#35299;&#30721;&#20026;&#37325;&#24314;&#22270;&#20687;&#12290;&#34429;&#28982;&#36825;&#20123;&#27169;&#22411;&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#30001;&#20110;&#20248;&#21270;&#19981;&#23436;&#32654;&#20197;&#21450;&#32534;&#30721;&#22120;&#21644;&#35299;&#30721;&#22120;&#23481;&#37327;&#30340;&#38480;&#21046;&#65292;&#23427;&#20204;&#23548;&#33268;&#20102;&#27425;&#20248;&#32467;&#26524;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22914;&#20309;&#21033;&#29992;&#38543;&#26426;Gumbel&#36864;&#28779;&#65288;SGA&#65289;&#26469;&#25913;&#36827;&#39044;&#35757;&#32451;&#30340;&#31070;&#32463;&#22270;&#20687;&#21387;&#32553;&#27169;&#22411;&#30340;&#28508;&#21464;&#37327;&#12290;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;SGA+&#25193;&#23637;&#20102;&#36825;&#20010;&#24819;&#27861;&#65292;SGA+&#21253;&#21547;&#20102;&#19977;&#31181;&#19981;&#21516;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#37117;&#24314;&#31435;&#22312;SGA&#30340;&#22522;&#30784;&#19978;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#35814;&#32454;&#20998;&#26512;&#65292;&#23637;&#31034;&#20102;&#23427;&#20204;&#22914;&#20309;&#25913;&#36827;&#24615;&#33021;&#65292;&#24182;&#19988;&#35777;&#26126;&#23427;&#20204;&#23545;&#36229;&#21442;&#25968;&#36873;&#25321;&#19981;&#25935;&#24863;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#27599;&#20010;&#26041;&#27861;&#25193;&#23637;&#21040;&#19977;&#20010;&#32780;&#19981;&#26159;&#20004;&#20010;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural image compression has made a great deal of progress. State-of-the-art models are based on variational autoencoders and are outperforming classical models. Neural compression models learn to encode an image into a quantized latent representation that can be efficiently sent to the decoder, which decodes the quantized latent into a reconstructed image. While these models have proven successful in practice, they lead to sub-optimal results due to imperfect optimization and limitations in the encoder and decoder capacity. Recent work shows how to use stochastic Gumbel annealing (SGA) to refine the latents of pre-trained neural image compression models. We extend this idea by introducing SGA+, which contains three different methods that build upon SGA. Further, we give a detailed analysis of our proposed methods, show how they improve performance, and show that they are less sensitive to hyperparameter choices. Besides, we show how each method can be extended to three- instead of two
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#21452;&#37325;InfoGAN&#26041;&#27861;&#29992;&#20110;&#23545;&#27604;&#20998;&#26512;&#65292;&#36890;&#36807;&#32467;&#21512;GAN&#30340;&#39640;&#36136;&#37327;&#21512;&#25104;&#21644;InfoGAN&#30340;&#20998;&#31163;&#33021;&#21147;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#24403;&#21069;&#22522;&#20110;VAE&#30340;&#26041;&#27861;&#22312;&#22788;&#29702;&#20849;&#21516;&#22240;&#32032;&#21644;&#29305;&#27530;&#22240;&#32032;&#26102;&#30340;&#19981;&#36275;&#65292;&#24182;&#22312;&#19981;&#21516;&#30340;&#35270;&#35273;&#25968;&#25454;&#38598;&#19978;&#23637;&#29616;&#20986;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2401.17776</link><description>&lt;p&gt;
&#21452;&#37325;InfoGAN&#29992;&#20110;&#23545;&#27604;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Double InfoGAN for Contrastive Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17776
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#21452;&#37325;InfoGAN&#26041;&#27861;&#29992;&#20110;&#23545;&#27604;&#20998;&#26512;&#65292;&#36890;&#36807;&#32467;&#21512;GAN&#30340;&#39640;&#36136;&#37327;&#21512;&#25104;&#21644;InfoGAN&#30340;&#20998;&#31163;&#33021;&#21147;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#24403;&#21069;&#22522;&#20110;VAE&#30340;&#26041;&#27861;&#22312;&#22788;&#29702;&#20849;&#21516;&#22240;&#32032;&#21644;&#29305;&#27530;&#22240;&#32032;&#26102;&#30340;&#19981;&#36275;&#65292;&#24182;&#22312;&#19981;&#21516;&#30340;&#35270;&#35273;&#25968;&#25454;&#38598;&#19978;&#23637;&#29616;&#20986;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#27604;&#20998;&#26512;&#65288;CA&#65289;&#22788;&#29702;&#30340;&#26159;&#21457;&#29616;&#30446;&#26631;&#39046;&#22495;&#19982;&#32972;&#26223;&#39046;&#22495;&#30456;&#27604;&#30340;&#20849;&#21516;&#28857;&#21644;&#29305;&#27530;&#28857;&#12290;&#36825;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#20855;&#26377;&#26497;&#22823;&#30340;&#20852;&#36259;&#65292;&#20363;&#22914;&#21307;&#23398;&#25104;&#20687;&#12290;&#30446;&#21069;&#30340;&#26368;&#26032;&#26041;&#27861;&#26159;&#22522;&#20110;VAE&#30340;&#28508;&#22312;&#21464;&#37327;&#27169;&#22411;&#65288;CA-VAEs&#65289;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#35201;&#20040;&#24573;&#30053;&#37325;&#35201;&#30340;&#32422;&#26463;&#26465;&#20214;&#65292;&#35201;&#20040;&#27809;&#26377;&#24378;&#21046;&#25191;&#34892;&#22522;&#26412;&#20551;&#35774;&#12290;&#36825;&#21487;&#33021;&#23548;&#33268;&#27425;&#20248;&#35299;&#65292;&#20854;&#20013;&#23558;&#29305;&#27530;&#22240;&#32032;&#35823;&#35748;&#20026;&#20849;&#21516;&#22240;&#32032;&#65288;&#25110;&#21453;&#20043;&#20134;&#28982;&#65289;&#12290;&#27492;&#22806;&#65292;&#29983;&#25104;&#30340;&#22270;&#20687;&#20855;&#26377;VAE&#30340;&#36739;&#24046;&#36136;&#37327;&#65292;&#38477;&#20302;&#20102;&#20854;&#21487;&#35299;&#37322;&#24615;&#21644;&#23454;&#29992;&#24615;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21452;&#37325;InfoGAN&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#22522;&#20110;GAN&#30340;CA&#26041;&#27861;&#65292;&#23427;&#20805;&#20998;&#21033;&#29992;&#20102;GAN&#30340;&#39640;&#36136;&#37327;&#21512;&#25104;&#21644;InfoGAN&#30340;&#20998;&#31163;&#33021;&#21147;&#12290;&#22312;&#20174;&#31616;&#21333;&#30340;&#21512;&#25104;&#31034;&#20363;&#21040;&#22797;&#26434;&#30340;&#21307;&#23398;&#22270;&#20687;&#30340;&#22235;&#20010;&#35270;&#35273;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#28508;&#22312;&#20998;&#31163;&#21644;&#22270;&#20687;&#36136;&#37327;&#26041;&#38754;&#20248;&#20110;&#26368;&#26032;&#30340;CA-VAEs&#12290;
&lt;/p&gt;
&lt;p&gt;
Contrastive Analysis (CA) deals with the discovery of what is common and what is distinctive of a target domain compared to a background one. This is of great interest in many applications, such as medical imaging. Current state-of-the-art (SOTA) methods are latent variable models based on VAE (CA-VAEs). However, they all either ignore important constraints or they don't enforce fundamental assumptions. This may lead to sub-optimal solutions where distinctive factors are mistaken for common ones (or viceversa). Furthermore, the generated images have a rather poor quality, typical of VAEs, decreasing their interpretability and usefulness. Here, we propose Double InfoGAN, the first GAN based method for CA that leverages the high-quality synthesis of GAN and the separation power of InfoGAN. Experimental results on four visual datasets, from simple synthetic examples to complex medical images, show that the proposed method outperforms SOTA CA-VAEs in terms of latent separation and image qu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#32452;&#26465;&#20214;&#65292;&#20445;&#35777;&#20102;&#19968;&#31867;&#20272;&#35745;&#31163;&#25955;&#21644;&#36830;&#32493;&#21442;&#25968;&#28151;&#21512;&#30340;&#29305;&#23450;EM&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#20026;&#35299;&#20915;&#28151;&#21512;&#25972;&#25968;&#38750;&#32447;&#24615;&#20248;&#21270;&#38382;&#39064;&#30340;&#36845;&#20195;&#31639;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#25216;&#26415;&#12290;</title><link>https://arxiv.org/abs/2401.17763</link><description>&lt;p&gt;
&#22522;&#20110;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;&#30340;&#26399;&#26395;&#26368;&#22823;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Convergence of Expectation-Maximization Algorithm with Mixed-Integer Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17763
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#32452;&#26465;&#20214;&#65292;&#20445;&#35777;&#20102;&#19968;&#31867;&#20272;&#35745;&#31163;&#25955;&#21644;&#36830;&#32493;&#21442;&#25968;&#28151;&#21512;&#30340;&#29305;&#23450;EM&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#20026;&#35299;&#20915;&#28151;&#21512;&#25972;&#25968;&#38750;&#32447;&#24615;&#20248;&#21270;&#38382;&#39064;&#30340;&#36845;&#20195;&#31639;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26399;&#26395;&#26368;&#22823;&#21270;&#65288;EM&#65289;&#31639;&#27861;&#30340;&#25910;&#25947;&#36890;&#24120;&#38656;&#35201;&#20284;&#28982;&#20989;&#25968;&#23545;&#25152;&#26377;&#26410;&#30693;&#21442;&#25968;&#65288;&#20248;&#21270;&#21464;&#37327;&#65289;&#36830;&#32493;&#12290;&#24403;&#21442;&#25968;&#21253;&#25324;&#31163;&#25955;&#21644;&#36830;&#32493;&#21464;&#37327;&#26102;&#65292;&#36825;&#19968;&#35201;&#27714;&#26080;&#27861;&#28385;&#36275;&#65292;&#23548;&#33268;&#25910;&#25947;&#20998;&#26512;&#38750;&#24120;&#22256;&#38590;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#32452;&#26465;&#20214;&#65292;&#20445;&#35777;&#20102;&#19968;&#31867;&#20272;&#35745;&#31163;&#25955;&#21644;&#36830;&#32493;&#21442;&#25968;&#28151;&#21512;&#30340;&#29305;&#23450;EM&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;&#35299;&#20915;&#28151;&#21512;&#25972;&#25968;&#38750;&#32447;&#24615;&#20248;&#21270;&#38382;&#39064;&#30340;&#36845;&#20195;&#31639;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#25216;&#26415;&#12290;&#20316;&#20026;&#19968;&#20010;&#20855;&#20307;&#30340;&#20363;&#23376;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22522;&#20110;EM&#30340;&#31232;&#30095;&#36125;&#21494;&#26031;&#23398;&#20064;&#31639;&#27861;&#22312;&#20272;&#35745;&#20855;&#26377;&#32852;&#21512;&#31232;&#30095;&#36755;&#20837;&#21644;&#26029;&#32493;&#32570;&#22833;&#35266;&#27979;&#30340;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#29366;&#24577;&#26102;&#30340;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#35777;&#26126;&#20102;[1]&#20013;&#30340;&#31639;&#27861;&#25910;&#25947;&#21040;&#26368;&#22823;&#20284;&#28982;&#20195;&#20215;&#20851;&#20110;&#36830;&#32493;&#20248;&#21270;&#21464;&#37327;&#30340;&#31283;&#23450;&#28857;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
The convergence of expectation-maximization (EM)-based algorithms typically requires continuity of the likelihood function with respect to all the unknown parameters (optimization variables). The requirement is not met when parameters comprise both discrete and continuous variables, making the convergence analysis nontrivial. This paper introduces a set of conditions that ensure the convergence of a specific class of EM algorithms that estimate a mixture of discrete and continuous parameters. Our results offer a new analysis technique for iterative algorithms that solve mixed-integer non-linear optimization problems. As a concrete example, we prove the convergence of the EM-based sparse Bayesian learning algorithm in [1] that estimates the state of a linear dynamical system with jointly sparse inputs and bursty missing observations. Our results establish that the algorithm in [1] converges to the set of stationary points of the maximum likelihood cost with respect to the continuous opt
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#38750;&#32447;&#24615;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#22120;&#30340;&#27491;&#21017;&#21270;&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#29305;&#24449;&#31354;&#38388;&#32500;&#24230;&#39640;&#20110;&#35757;&#32451;&#25968;&#25454;&#22823;&#23567;&#26102;&#25968;&#25454;&#21327;&#26041;&#24046;&#30697;&#38453;&#30149;&#24577;&#23548;&#33268;&#25928;&#29575;&#20302;&#19979;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2401.17760</link><description>&lt;p&gt;
&#20351;&#29992;&#38750;&#32447;&#24615;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#22120;&#30340;&#27491;&#21017;&#21270;&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Regularized Linear Discriminant Analysis Using a Nonlinear Covariance Matrix Estimator
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17760
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#38750;&#32447;&#24615;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#22120;&#30340;&#27491;&#21017;&#21270;&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#29305;&#24449;&#31354;&#38388;&#32500;&#24230;&#39640;&#20110;&#35757;&#32451;&#25968;&#25454;&#22823;&#23567;&#26102;&#25968;&#25454;&#21327;&#26041;&#24046;&#30697;&#38453;&#30149;&#24577;&#23548;&#33268;&#25928;&#29575;&#20302;&#19979;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#65288;LDA&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#25968;&#25454;&#20998;&#31867;&#25216;&#26415;&#12290;&#35813;&#26041;&#27861;&#22312;&#35768;&#22810;&#20998;&#31867;&#38382;&#39064;&#20013;&#20855;&#26377;&#33391;&#22909;&#30340;&#24615;&#33021;&#65292;&#20294;&#22312;&#25968;&#25454;&#21327;&#26041;&#24046;&#30697;&#38453;&#30149;&#24577;&#26465;&#20214;&#19979;&#25928;&#29575;&#20302;&#19979;&#12290;&#36825;&#36890;&#24120;&#21457;&#29983;&#22312;&#29305;&#24449;&#31354;&#38388;&#30340;&#32500;&#24230;&#39640;&#20110;&#25110;&#25509;&#36817;&#35757;&#32451;&#25968;&#25454;&#22823;&#23567;&#30340;&#24773;&#20917;&#19979;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#31181;&#24773;&#20917;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#27491;&#21017;&#21270;&#32447;&#24615;&#20272;&#35745;&#22120;&#30340;&#27491;&#21017;&#21270;LDA&#65288;RLDA&#65289;&#26041;&#27861;&#12290;RLDA&#26041;&#27861;&#30340;&#24615;&#33021;&#24050;&#24471;&#21040;&#20805;&#20998;&#30740;&#31350;&#65292;&#24182;&#24050;&#25552;&#20986;&#20102;&#26368;&#20248;&#30340;&#27491;&#21017;&#21270;&#26041;&#26696;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19982;&#38750;&#32447;&#24615;&#65288;NL&#65289;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#22120;&#30456;&#19968;&#33268;&#30340;&#27491;&#21322;&#23450; Ridge &#22411;&#36870;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#22120;&#30340;&#33021;&#21147;&#12290;&#36890;&#36807;&#37325;&#26032;&#21046;&#23450;&#21033;&#29992;&#32447;&#24615;&#20272;&#35745;&#26041;&#27861;&#30340;&#26368;&#20248;&#20998;&#31867;&#22120;&#30340;&#24471;&#20998;&#20989;&#25968;&#65292;&#24471;&#21040;&#20102;&#35813;&#20272;&#35745;&#22120;&#65292;&#26368;&#32456;&#24418;&#25104;&#20102;&#25152;&#25552;&#20986;&#30340;NL-RLDA&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Linear discriminant analysis (LDA) is a widely used technique for data classification. The method offers adequate performance in many classification problems, but it becomes inefficient when the data covariance matrix is ill-conditioned. This often occurs when the feature space's dimensionality is higher than or comparable to the training data size. Regularized LDA (RLDA) methods based on regularized linear estimators of the data covariance matrix have been proposed to cope with such a situation. The performance of RLDA methods is well studied, with optimal regularization schemes already proposed. In this paper, we investigate the capability of a positive semidefinite ridge-type estimator of the inverse covariance matrix that coincides with a nonlinear (NL) covariance matrix estimator. The estimator is derived by reformulating the score function of the optimal classifier utilizing linear estimation methods, which eventually results in the proposed NL-RLDA classifier. We derive asymptot
&lt;/p&gt;</description></item><item><title>BICauseTree&#26159;&#19968;&#31181;&#22522;&#20110;&#23618;&#32423;&#20559;&#24046;&#39537;&#21160;&#20998;&#23618;&#30340;&#21487;&#35299;&#37322;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#20915;&#31574;&#26641;&#36827;&#34892;&#24179;&#34913;&#12289;&#20943;&#23569;&#20559;&#24046;&#21644;&#30830;&#23450;&#30446;&#26631;&#20154;&#32676;&#23450;&#20041;&#65292;&#25552;&#20379;&#20102;&#21487;&#35299;&#37322;&#24615;&#21644;&#36879;&#26126;&#24615;&#12290;</title><link>https://arxiv.org/abs/2401.17737</link><description>&lt;p&gt;
&#22522;&#20110;&#23618;&#32423;&#20559;&#24046;&#39537;&#21160;&#20998;&#23618;&#30340;&#21487;&#35299;&#37322;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Bias-Driven Stratification for Interpretable Causal Effect Estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17737
&lt;/p&gt;
&lt;p&gt;
BICauseTree&#26159;&#19968;&#31181;&#22522;&#20110;&#23618;&#32423;&#20559;&#24046;&#39537;&#21160;&#20998;&#23618;&#30340;&#21487;&#35299;&#37322;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#20915;&#31574;&#26641;&#36827;&#34892;&#24179;&#34913;&#12289;&#20943;&#23569;&#20559;&#24046;&#21644;&#30830;&#23450;&#30446;&#26631;&#20154;&#32676;&#23450;&#20041;&#65292;&#25552;&#20379;&#20102;&#21487;&#35299;&#37322;&#24615;&#21644;&#36879;&#26126;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#24615;&#21644;&#36879;&#26126;&#24615;&#23545;&#20110;&#23558;&#35266;&#23519;&#25968;&#25454;&#20013;&#30340;&#22240;&#26524;&#25928;&#24212;&#27169;&#22411;&#32435;&#20837;&#25919;&#31574;&#20915;&#31574;&#33267;&#20851;&#37325;&#35201;&#12290;&#23427;&#20204;&#21487;&#20197;&#22312;&#32570;&#20047;&#30495;&#23454;&#26631;&#31614;&#26469;&#35780;&#20272;&#36825;&#20123;&#27169;&#22411;&#20934;&#30830;&#24615;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#23545;&#27169;&#22411;&#30340;&#20449;&#20219;&#12290;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#36879;&#26126;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#23581;&#35797;&#21253;&#25324;&#23558;&#20107;&#21518;&#35299;&#37322;&#26041;&#27861;&#24212;&#29992;&#20110;&#19981;&#21487;&#35299;&#37322;&#30340;&#40657;&#30418;&#27169;&#22411;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;BICauseTree&#65306;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#24179;&#34913;&#26041;&#27861;&#65292;&#29992;&#20110;&#35782;&#21035;&#23616;&#37096;&#21457;&#29983;&#33258;&#28982;&#23454;&#39564;&#30340;&#32858;&#31867;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#24102;&#26377;&#33258;&#23450;&#20041;&#30446;&#26631;&#20989;&#25968;&#30340;&#20915;&#31574;&#26641;&#65292;&#20197;&#25913;&#36827;&#24179;&#34913;&#21644;&#20943;&#23569;&#22788;&#29702;&#20998;&#37197;&#20559;&#24046;&#12290;&#22240;&#27492;&#65292;&#23427;&#36824;&#21487;&#20197;&#26816;&#27979;&#20986;&#23384;&#22312;&#27491;&#24615;&#36829;&#35268;&#30340;&#23376;&#32676;&#20307;&#65292;&#25490;&#38500;&#23427;&#20204;&#65292;&#24182;&#25552;&#20379;&#22522;&#20110;&#21327;&#21464;&#37327;&#30340;&#30446;&#26631;&#20154;&#32676;&#23450;&#20041;&#65292;&#25105;&#20204;&#21487;&#20197;&#20174;&#20013;&#25512;&#26029;&#24182;&#25512;&#24191;&#12290;&#25105;&#20204;&#20351;&#29992;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#35780;&#20272;&#35813;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#24182;&#25506;&#32034;&#20854;&#20559;&#24046;&#21487;&#35299;&#37322;&#24615;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
Interpretability and transparency are essential for incorporating causal effect models from observational data into policy decision-making. They can provide trust for the model in the absence of ground truth labels to evaluate the accuracy of such models. To date, attempts at transparent causal effect estimation consist of applying post hoc explanation methods to black-box models, which are not interpretable. Here, we present BICauseTree: an interpretable balancing method that identifies clusters where natural experiments occur locally. Our approach builds on decision trees with a customized objective function to improve balancing and reduce treatment allocation bias. Consequently, it can additionally detect subgroups presenting positivity violations, exclude them, and provide a covariate-based definition of the target population we can infer from and generalize to. We evaluate the method's performance using synthetic and realistic datasets, explore its bias-interpretability tradeoff, 
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#22312;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20851;&#20110;t-SNE&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;t-SNE&#29983;&#25104;&#30340;&#28857;&#26159;&#26377;&#30028;&#30340;&#65292;&#24182;&#24471;&#20986;&#20102;KL&#25955;&#24230;&#26368;&#23567;&#20540;&#30340;&#23384;&#22312;&#24615;&#12290;</title><link>https://arxiv.org/abs/2401.17675</link><description>&lt;p&gt;
t-SNE&#20316;&#20026;&#27969;&#24418;&#19978;&#28857;&#20113;&#30340;&#26799;&#24230;&#27969;&#30340;&#25910;&#25947;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Convergence analysis of t-SNE as a gradient flow for point cloud on a manifold
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17675
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20851;&#20110;t-SNE&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;t-SNE&#29983;&#25104;&#30340;&#28857;&#26159;&#26377;&#30028;&#30340;&#65292;&#24182;&#24471;&#20986;&#20102;KL&#25955;&#24230;&#26368;&#23567;&#20540;&#30340;&#23384;&#22312;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#20851;&#20110;t-SNE&#31639;&#27861;&#26377;&#30028;&#24615;&#30340;&#29702;&#35770;&#22522;&#30784;&#12290;t-SNE&#37319;&#29992;&#26799;&#24230;&#19979;&#38477;&#36845;&#20195;&#21644;KL&#25955;&#24230;&#20316;&#20026;&#30446;&#26631;&#20989;&#25968;&#65292;&#26088;&#22312;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#25214;&#21040;&#19968;&#32452;&#28857;&#65292;&#20351;&#20854;&#19982;&#21407;&#22987;&#25968;&#25454;&#28857;&#30340;&#30456;&#20284;&#24230;&#36739;&#39640;&#65292;&#26368;&#23567;&#21270;KL&#25955;&#24230;&#12290;&#22312;&#23545;&#37319;&#26679;&#25968;&#25454;&#38598;&#36827;&#34892;&#24369;&#25910;&#25947;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#30740;&#31350;&#20102;t-SNE&#30340;&#23646;&#24615;&#65292;&#22914;&#22256;&#24785;&#24230;&#21644;&#30456;&#20284;&#24230;&#65292;&#25506;&#31350;&#20102;t-SNE&#29983;&#25104;&#30340;&#28857;&#22312;&#36830;&#32493;&#26799;&#24230;&#27969;&#19979;&#30340;&#34892;&#20026;&#12290;&#36890;&#36807;&#35777;&#26126;t-SNE&#29983;&#25104;&#30340;&#28857;&#20445;&#25345;&#26377;&#30028;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#20010;&#32467;&#35770;&#26469;&#24314;&#31435;KL&#25955;&#24230;&#30340;&#26368;&#23567;&#20540;&#23384;&#22312;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a theoretical foundation regarding the boundedness of the t-SNE algorithm. t-SNE employs gradient descent iteration with Kullback-Leibler (KL) divergence as the objective function, aiming to identify a set of points that closely resemble the original data points in a high-dimensional space, minimizing KL divergence. Investigating t-SNE properties such as perplexity and affinity under a weak convergence assumption on the sampled dataset, we examine the behavior of points generated by t-SNE under continuous gradient flow. Demonstrating that points generated by t-SNE remain bounded, we leverage this insight to establish the existence of a minimizer for KL divergence.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24352;&#37327;&#30340;&#24037;&#33402;&#25511;&#21046;&#21644;&#30417;&#25511;&#26041;&#27861;&#65292;&#29992;&#20110;&#21322;&#23548;&#20307;&#21046;&#36896;&#36807;&#31243;&#20013;&#39640;&#32500;&#24230;&#22522;&#20110;&#22270;&#20687;&#30340;&#21472;&#21152;&#35823;&#24046;&#30340;&#22797;&#26434;&#32467;&#26500;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#26377;&#38480;&#30340;&#25511;&#21046;&#37197;&#26041;&#20943;&#23567;&#21472;&#21152;&#35823;&#24046;&#65292;&#24182;&#35774;&#35745;&#20102;&#31283;&#23450;&#30340;&#24352;&#37327;&#25968;&#25454;&#25511;&#21046;&#22120;&#26469;&#22788;&#29702;&#39640;&#32500;&#24230;&#25200;&#21160;&#12290;</title><link>https://arxiv.org/abs/2401.17573</link><description>&lt;p&gt;
&#22522;&#20110;&#24352;&#37327;&#30340;&#21322;&#23548;&#20307;&#21046;&#36896;&#36807;&#31243;&#25511;&#21046;&#19982;&#30417;&#25511;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Tensor-based process control and monitoring for semiconductor manufacturing with unstable disturbances
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17573
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24352;&#37327;&#30340;&#24037;&#33402;&#25511;&#21046;&#21644;&#30417;&#25511;&#26041;&#27861;&#65292;&#29992;&#20110;&#21322;&#23548;&#20307;&#21046;&#36896;&#36807;&#31243;&#20013;&#39640;&#32500;&#24230;&#22522;&#20110;&#22270;&#20687;&#30340;&#21472;&#21152;&#35823;&#24046;&#30340;&#22797;&#26434;&#32467;&#26500;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#26377;&#38480;&#30340;&#25511;&#21046;&#37197;&#26041;&#20943;&#23567;&#21472;&#21152;&#35823;&#24046;&#65292;&#24182;&#35774;&#35745;&#20102;&#31283;&#23450;&#30340;&#24352;&#37327;&#25968;&#25454;&#25511;&#21046;&#22120;&#26469;&#22788;&#29702;&#39640;&#32500;&#24230;&#25200;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#21046;&#36896;&#31995;&#32479;&#20013;&#23433;&#35013;&#20256;&#24863;&#22120;&#30340;&#21457;&#23637;&#21644;&#26222;&#21450;&#65292;&#21046;&#36896;&#36807;&#31243;&#20013;&#25910;&#38598;&#21040;&#20102;&#22797;&#26434;&#30340;&#25968;&#25454;&#65292;&#32473;&#20256;&#32479;&#30340;&#36807;&#31243;&#25511;&#21046;&#26041;&#27861;&#24102;&#26469;&#20102;&#25361;&#25112;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24037;&#33402;&#25511;&#21046;&#21644;&#30417;&#25511;&#26041;&#27861;&#65292;&#29992;&#20110;&#21322;&#23548;&#20307;&#21046;&#36896;&#36807;&#31243;&#20013;&#39640;&#32500;&#24230;&#22522;&#20110;&#22270;&#20687;&#30340;&#21472;&#21152;&#35823;&#24046;&#65288;&#20197;&#24352;&#37327;&#24418;&#24335;&#24314;&#27169;&#65289;&#30340;&#22797;&#26434;&#32467;&#26500;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#26088;&#22312;&#20351;&#29992;&#26377;&#38480;&#30340;&#25511;&#21046;&#37197;&#26041;&#20943;&#23567;&#21472;&#21152;&#35823;&#24046;&#12290;&#39318;&#20808;&#24314;&#31435;&#20102;&#19968;&#20010;&#39640;&#32500;&#24230;&#30340;&#36807;&#31243;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19981;&#21516;&#30340;&#24352;&#37327;-&#21521;&#37327;&#22238;&#24402;&#31639;&#27861;&#26469;&#20272;&#35745;&#27169;&#22411;&#20013;&#30340;&#21442;&#25968;&#65292;&#20197;&#20943;&#36731;&#32500;&#24230;&#28798;&#38590;&#12290;&#28982;&#21518;&#65292;&#22522;&#20110;&#24352;&#37327;&#21442;&#25968;&#30340;&#20272;&#35745;&#65292;&#35774;&#35745;&#20102;&#20855;&#26377;&#31283;&#23450;&#24615;&#30340;&#25351;&#25968;&#21152;&#26435;&#31227;&#21160;&#24179;&#22343;&#65288;EWMA&#65289;&#24352;&#37327;&#25968;&#25454;&#25511;&#21046;&#22120;&#65292;&#20854;&#31283;&#23450;&#24615;&#22312;&#29702;&#35770;&#19978;&#24471;&#21040;&#20102;&#20445;&#35777;&#12290;&#32771;&#34385;&#21040;&#20302;&#32500;&#24230;&#30340;&#25511;&#21046;&#37197;&#26041;&#19981;&#33021;&#24357;&#34917;&#25152;&#26377;&#39640;&#32500;&#24230;&#25200;&#21160;&#30340;&#20107;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the development and popularity of sensors installed in manufacturing systems, complex data are collected during manufacturing processes, which brings challenges for traditional process control methods. This paper proposes a novel process control and monitoring method for the complex structure of high-dimensional image-based overlay errors (modeled in tensor form), which are collected in semiconductor manufacturing processes. The proposed method aims to reduce overlay errors using limited control recipes. We first build a high-dimensional process model and propose different tensor-on-vector regression algorithms to estimate parameters in the model to alleviate the curse of dimensionality. Then, based on the estimate of tensor parameters, the exponentially weighted moving average (EWMA) controller for tensor data is designed whose stability is theoretically guaranteed. Considering the fact that low-dimensional control recipes cannot compensate for all high-dimensional disturbances o
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20174;&#28216;&#25103;&#35770;&#22495;&#30340;&#35282;&#24230;&#26469;&#36827;&#34892;&#19981;&#21487;&#23398;&#20064;&#31034;&#20363;&#25915;&#20987;&#30340;&#26041;&#27861;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#21338;&#24328;&#22343;&#34913;&#32473;&#20986;&#20102;&#26368;&#24378;&#22823;&#30340;&#27602;&#25915;&#20987;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28216;&#25103;&#35770;&#22495;&#19981;&#21487;&#23398;&#20064;&#31034;&#20363;&#65288;GUE&#65289;&#30340;&#26032;&#25915;&#20987;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2401.17523</link><description>&lt;p&gt;
&#28216;&#25103;&#35770;&#22495;&#19981;&#21487;&#23398;&#20064;&#31034;&#20363;&#29983;&#25104;&#22120;
&lt;/p&gt;
&lt;p&gt;
Game-Theoretic Unlearnable Example Generator
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17523
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20174;&#28216;&#25103;&#35770;&#22495;&#30340;&#35282;&#24230;&#26469;&#36827;&#34892;&#19981;&#21487;&#23398;&#20064;&#31034;&#20363;&#25915;&#20987;&#30340;&#26041;&#27861;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#21338;&#24328;&#22343;&#34913;&#32473;&#20986;&#20102;&#26368;&#24378;&#22823;&#30340;&#27602;&#25915;&#20987;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28216;&#25103;&#35770;&#22495;&#19981;&#21487;&#23398;&#20064;&#31034;&#20363;&#65288;GUE&#65289;&#30340;&#26032;&#25915;&#20987;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#21487;&#23398;&#20064;&#31034;&#20363;&#25915;&#20987;&#26159;&#19968;&#31181;&#25968;&#25454;&#27602;&#21270;&#25915;&#20987;&#65292;&#26088;&#22312;&#36890;&#36807;&#21521;&#35757;&#32451;&#26679;&#26412;&#28155;&#21152;&#24494;&#19981;&#21487;&#23519;&#35273;&#30340;&#25200;&#21160;&#65292;&#38477;&#20302;&#28145;&#24230;&#23398;&#20064;&#30340;&#24178;&#20928;&#27979;&#35797;&#20934;&#30830;&#24615;&#65292;&#36825;&#21487;&#20197;&#34987;&#23450;&#20041;&#20026;&#19968;&#20010;&#20108;&#23618;&#20248;&#21270;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#30452;&#25509;&#35299;&#20915;&#36825;&#20010;&#20248;&#21270;&#38382;&#39064;&#23545;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26469;&#35828;&#26159;&#38590;&#20197;&#22788;&#29702;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#21338;&#24328;&#35770;&#30340;&#35282;&#24230;&#23545;&#19981;&#21487;&#23398;&#20064;&#31034;&#20363;&#25915;&#20987;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#23558;&#25915;&#20987;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#38750;&#38646;&#21644;Stackelberg&#21338;&#24328;&#12290;&#39318;&#20808;&#65292;&#22312;&#27491;&#24120;&#35774;&#32622;&#21644;&#23545;&#25239;&#35757;&#32451;&#35774;&#32622;&#19979;&#35777;&#26126;&#20102;&#21338;&#24328;&#22343;&#34913;&#30340;&#23384;&#22312;&#24615;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#20351;&#29992;&#29305;&#23450;&#25439;&#22833;&#20989;&#25968;&#26102;&#65292;&#21338;&#24328;&#22343;&#34913;&#32473;&#20986;&#20102;&#26368;&#24378;&#22823;&#30340;&#27602;&#25915;&#20987;&#65292;&#21363;&#22312;&#30456;&#21516;&#20551;&#35774;&#31354;&#38388;&#20869;&#65292;&#21463;&#23475;&#32773;&#30340;&#27979;&#35797;&#20934;&#30830;&#29575;&#26368;&#20302;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25915;&#20987;&#26041;&#27861;&#65292;&#31216;&#20026;&#28216;&#25103;&#35770;&#22495;&#19981;&#21487;&#23398;&#20064;&#31034;&#20363;&#65288;GUE&#65289;&#65292;&#23427;&#20027;&#35201;&#21253;&#25324;&#19977;&#20010;&#26799;&#24230;&#12290;&#65288;1&#65289;&#36890;&#36807;&#30452;&#25509;&#27714;&#35299;&#22343;&#34913;&#33719;&#24471;&#27602;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unlearnable example attacks are data poisoning attacks aiming to degrade the clean test accuracy of deep learning by adding imperceptible perturbations to the training samples, which can be formulated as a bi-level optimization problem. However, directly solving this optimization problem is intractable for deep neural networks. In this paper, we investigate unlearnable example attacks from a game-theoretic perspective, by formulating the attack as a nonzero sum Stackelberg game. First, the existence of game equilibria is proved under the normal setting and the adversarial training setting. It is shown that the game equilibrium gives the most powerful poison attack in that the victim has the lowest test accuracy among all networks within the same hypothesis space, when certain loss functions are used. Second, we propose a novel attack method, called the Game Unlearnable Example (GUE), which has three main gradients. (1) The poisons are obtained by directly solving the equilibrium of the
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#21457;&#29616;&#65292;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#20027;&#35201;&#21463;&#21040;&#21333;&#20010;&#29305;&#24449;&#25110;&#29305;&#24449;&#20043;&#38388;&#20056;&#31215;&#30456;&#20114;&#20316;&#29992;&#30340;&#20108;&#38454;&#24433;&#21709;&#30340;&#24433;&#21709;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36825;&#20123;&#20108;&#38454;&#24433;&#21709;&#26469;&#35299;&#37322;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#26032;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#31616;&#21333;&#30340;&#21327;&#26041;&#24046;&#35745;&#31639;&#23545;&#19968;&#38454;&#35299;&#37322;&#36827;&#34892;&#22788;&#29702;&#65292;&#21487;&#20197;&#23558;&#24120;&#35265;&#30340;&#24402;&#22240;&#25216;&#26415;&#36716;&#21270;&#20026;&#24378;&#22823;&#30340;&#20108;&#38454;&#19981;&#30830;&#23450;&#24615;&#35299;&#37322;&#22120;&#12290;&#20316;&#32773;&#36890;&#36807;&#37327;&#21270;&#35780;&#20272;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#35299;&#37322;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#25972;&#20307;&#23454;&#29992;&#24615;&#12290;</title><link>https://arxiv.org/abs/2401.17441</link><description>&lt;p&gt;
&#25581;&#31034;&#20108;&#38454;&#24433;&#21709;&#26469;&#35299;&#37322;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Explaining Predictive Uncertainty by Exposing Second-Order Effects
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17441
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#21457;&#29616;&#65292;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#20027;&#35201;&#21463;&#21040;&#21333;&#20010;&#29305;&#24449;&#25110;&#29305;&#24449;&#20043;&#38388;&#20056;&#31215;&#30456;&#20114;&#20316;&#29992;&#30340;&#20108;&#38454;&#24433;&#21709;&#30340;&#24433;&#21709;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36825;&#20123;&#20108;&#38454;&#24433;&#21709;&#26469;&#35299;&#37322;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#26032;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#31616;&#21333;&#30340;&#21327;&#26041;&#24046;&#35745;&#31639;&#23545;&#19968;&#38454;&#35299;&#37322;&#36827;&#34892;&#22788;&#29702;&#65292;&#21487;&#20197;&#23558;&#24120;&#35265;&#30340;&#24402;&#22240;&#25216;&#26415;&#36716;&#21270;&#20026;&#24378;&#22823;&#30340;&#20108;&#38454;&#19981;&#30830;&#23450;&#24615;&#35299;&#37322;&#22120;&#12290;&#20316;&#32773;&#36890;&#36807;&#37327;&#21270;&#35780;&#20272;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#35299;&#37322;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#25972;&#20307;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;Explainable AI&#65289;&#20351;&#22797;&#26434;&#30340;&#26426;&#22120;&#23398;&#20064;&#40657;&#31665;&#21464;&#24471;&#36879;&#26126;&#65292;&#29305;&#21035;&#26159;&#21487;&#20197;&#30830;&#23450;&#27169;&#22411;&#29992;&#26469;&#36827;&#34892;&#39044;&#27979;&#30340;&#29305;&#24449;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#35299;&#37322;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#65292;&#21363;&#20026;&#20160;&#20040;&#27169;&#22411;&#8220;&#19981;&#30830;&#23450;&#8221;&#65292;&#30446;&#21069;&#30740;&#31350;&#36739;&#23569;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#20027;&#35201;&#30001;&#28041;&#21450;&#21333;&#20010;&#29305;&#24449;&#25110;&#29305;&#24449;&#20043;&#38388;&#30340;&#20056;&#31215;&#30456;&#20114;&#20316;&#29992;&#30340;&#20108;&#38454;&#24433;&#21709;&#25152;&#20027;&#23548;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36825;&#20123;&#20108;&#38454;&#24433;&#21709;&#26469;&#35299;&#37322;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#26032;&#26041;&#27861;&#12290;&#22312;&#35745;&#31639;&#19978;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#31616;&#21270;&#25104;&#23545;&#19968;&#32452;&#19968;&#38454;&#35299;&#37322;&#36827;&#34892;&#31616;&#21333;&#21327;&#26041;&#24046;&#35745;&#31639;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#26222;&#36941;&#36866;&#29992;&#24615;&#65292;&#21487;&#20197;&#23558;&#24120;&#35265;&#30340;&#24402;&#22240;&#25216;&#26415;&#65288;LRP&#65292;Gradient x Input&#31561;&#65289;&#36716;&#21270;&#20026;&#24378;&#22823;&#30340;&#20108;&#38454;&#19981;&#30830;&#23450;&#24615;&#35299;&#37322;&#22120;&#65292;&#31216;&#20026;CovLRP&#65292;CovGI&#31561;&#12290;&#25105;&#20204;&#36890;&#36807;&#31995;&#32479;&#37327;&#21270;&#35780;&#20272;&#39564;&#35777;&#20102;&#25105;&#20204;&#26041;&#27861;&#20135;&#29983;&#35299;&#37322;&#30340;&#20934;&#30830;&#24615;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#25972;&#20307;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Explainable AI has brought transparency into complex ML blackboxes, enabling, in particular, to identify which features these models use for their predictions. So far, the question of explaining predictive uncertainty, i.e. why a model 'doubts', has been scarcely studied. Our investigation reveals that predictive uncertainty is dominated by second-order effects, involving single features or product interactions between them. We contribute a new method for explaining predictive uncertainty based on these second-order effects. Computationally, our method reduces to a simple covariance computation over a collection of first-order explanations. Our method is generally applicable, allowing for turning common attribution techniques (LRP, Gradient x Input, etc.) into powerful second-order uncertainty explainers, which we call CovLRP, CovGI, etc. The accuracy of the explanations our method produces is demonstrated through systematic quantitative evaluations, and the overall usefulness of our m
&lt;/p&gt;</description></item><item><title>&#22810;&#22836;&#27880;&#24847;&#21147;&#22312;&#19978;&#19979;&#25991;&#32447;&#24615;&#22238;&#24402;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20248;&#20110;&#21333;&#22836;&#27880;&#24847;&#21147;&#30340;&#24615;&#33021;&#65292;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#35777;&#26126;&#20102;&#22810;&#22836;&#27880;&#24847;&#21147;&#22312;&#22823;&#23884;&#20837;&#32500;&#24230;&#24773;&#20917;&#19979;&#26377;&#26356;&#23567;&#30340;&#39044;&#27979;&#25439;&#22833;&#65292;&#24182;&#19988;&#22312;&#21508;&#31181;&#25968;&#25454;&#20998;&#24067;&#35774;&#32622;&#19979;&#37117;&#26174;&#31034;&#20986;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2401.17426</link><description>&lt;p&gt;
&#22810;&#22836;&#27880;&#24847;&#21147;&#22312;&#19978;&#19979;&#25991;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#20248;&#21183;
&lt;/p&gt;
&lt;p&gt;
Superiority of Multi-Head Attention in In-Context Linear Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17426
&lt;/p&gt;
&lt;p&gt;
&#22810;&#22836;&#27880;&#24847;&#21147;&#22312;&#19978;&#19979;&#25991;&#32447;&#24615;&#22238;&#24402;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20248;&#20110;&#21333;&#22836;&#27880;&#24847;&#21147;&#30340;&#24615;&#33021;&#65292;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#35777;&#26126;&#20102;&#22810;&#22836;&#27880;&#24847;&#21147;&#22312;&#22823;&#23884;&#20837;&#32500;&#24230;&#24773;&#20917;&#19979;&#26377;&#26356;&#23567;&#30340;&#39044;&#27979;&#25439;&#22833;&#65292;&#24182;&#19988;&#22312;&#21508;&#31181;&#25968;&#25454;&#20998;&#24067;&#35774;&#32622;&#19979;&#37117;&#26174;&#31034;&#20986;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#22312;&#32447;&#24615;&#22238;&#24402;&#20219;&#21153;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#20013;&#65292;&#20351;&#29992;softmax&#27880;&#24847;&#21147;&#30340;transformer&#30340;&#24615;&#33021;&#12290;&#19982;&#29616;&#26377;&#25991;&#29486;&#20027;&#35201;&#20851;&#27880;&#21333;&#22836;/&#22810;&#22836;&#27880;&#24847;&#21147;&#30340;&#25910;&#25947;&#24615;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#30528;&#37325;&#27604;&#36739;&#23427;&#20204;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#31934;&#30830;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#20855;&#26377;&#36739;&#22823;&#23884;&#20837;&#32500;&#24230;&#30340;&#22810;&#22836;&#27880;&#24847;&#21147;&#27604;&#21333;&#22836;&#27880;&#24847;&#21147;&#34920;&#29616;&#26356;&#22909;&#12290;&#24403;&#19978;&#19979;&#25991;&#31034;&#20363;&#25968;&#37327;D&#22686;&#21152;&#26102;&#65292;&#20351;&#29992;&#21333;&#22836;/&#22810;&#22836;&#27880;&#24847;&#21147;&#30340;&#39044;&#27979;&#25439;&#22833;&#20026;O(1/D)&#65292;&#32780;&#22810;&#22836;&#27880;&#24847;&#21147;&#30340;&#20056;&#27861;&#24120;&#25968;&#36739;&#23567;&#12290;&#38500;&#20102;&#26368;&#31616;&#21333;&#30340;&#25968;&#25454;&#20998;&#24067;&#35774;&#32622;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#26356;&#22810;&#24773;&#26223;&#65292;&#20363;&#22914;&#22122;&#22768;&#26631;&#31614;&#65292;&#23616;&#37096;&#31034;&#20363;&#65292;&#30456;&#20851;&#29305;&#24449;&#21644;&#20808;&#39564;&#30693;&#35782;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#24635;&#30340;&#26469;&#35828;&#65292;&#22810;&#22836;&#27880;&#24847;&#21147;&#20248;&#20110;&#21333;&#22836;&#27880;&#24847;&#21147;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#39564;&#35777;&#20102;&#22810;&#22836;&#27880;&#24847;&#21147;&#35774;&#35745;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a theoretical analysis of the performance of transformer with softmax attention in in-context learning with linear regression tasks. While the existing literature predominantly focuses on the convergence of transformers with single-/multi-head attention, our research centers on comparing their performance. We conduct an exact theoretical analysis to demonstrate that multi-head attention with a substantial embedding dimension performs better than single-head attention. When the number of in-context examples D increases, the prediction loss using single-/multi-head attention is in O(1/D), and the one for multi-head attention has a smaller multiplicative constant. In addition to the simplest data distribution setting, we consider more scenarios, e.g., noisy labels, local examples, correlated features, and prior knowledge. We observe that, in general, multi-head attention is preferred over single-head attention. Our results verify the effectiveness of the design of multi-head at
&lt;/p&gt;</description></item><item><title>&#21435;&#20013;&#24515;&#21270;&#32852;&#37030;&#23398;&#20064;&#26550;&#26500;&#20801;&#35768;&#20445;&#25252;&#38544;&#31169;&#65292;&#20294;&#20063;&#24341;&#20837;&#20102;&#26032;&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#23041;&#32961;&#65292;&#35813;&#32508;&#36848;&#23545;&#21435;&#20013;&#24515;&#21270;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#23041;&#32961;&#12289;&#23545;&#25163;&#21644;&#38450;&#24481;&#26426;&#21046;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;</title><link>https://arxiv.org/abs/2401.17319</link><description>&lt;p&gt;
&#21435;&#20013;&#24515;&#21270;&#32852;&#37030;&#23398;&#20064;&#65306;&#23433;&#20840;&#19982;&#38544;&#31169;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Decentralized Federated Learning: A Survey on Security and Privacy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17319
&lt;/p&gt;
&lt;p&gt;
&#21435;&#20013;&#24515;&#21270;&#32852;&#37030;&#23398;&#20064;&#26550;&#26500;&#20801;&#35768;&#20445;&#25252;&#38544;&#31169;&#65292;&#20294;&#20063;&#24341;&#20837;&#20102;&#26032;&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#23041;&#32961;&#65292;&#35813;&#32508;&#36848;&#23545;&#21435;&#20013;&#24515;&#21270;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#23041;&#32961;&#12289;&#23545;&#25163;&#21644;&#38450;&#24481;&#26426;&#21046;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#30001;&#20110;&#20854;&#20445;&#25252;&#38544;&#31169;&#31561;&#20248;&#21183;&#65292;&#22312;&#36817;&#24180;&#26469;&#36805;&#36895;&#21457;&#23637;&#24182;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#31181;&#26550;&#26500;&#20013;&#65292;&#27169;&#22411;&#26356;&#26032;&#21644;&#26799;&#24230;&#30340;&#20132;&#25442;&#20026;&#32593;&#32476;&#20013;&#30340;&#24694;&#24847;&#29992;&#25143;&#25552;&#20379;&#20102;&#26032;&#30340;&#25915;&#20987;&#38754;&#65292;&#21487;&#33021;&#21361;&#21450;&#27169;&#22411;&#24615;&#33021;&#20197;&#21450;&#29992;&#25143;&#21644;&#25968;&#25454;&#30340;&#38544;&#31169;&#12290;&#22240;&#27492;&#65292;&#21435;&#20013;&#24515;&#21270;&#32852;&#37030;&#23398;&#20064;&#30340;&#20027;&#35201;&#21160;&#26426;&#20043;&#19968;&#26159;&#36890;&#36807;&#21435;&#38500;&#26381;&#21153;&#22120;&#24182;&#36890;&#36807;&#21306;&#22359;&#38142;&#31561;&#25216;&#26415;&#36827;&#34892;&#34917;&#20607;&#26469;&#28040;&#38500;&#19982;&#26381;&#21153;&#22120;&#30456;&#20851;&#30340;&#23041;&#32961;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#20248;&#21183;&#21364;&#20197;&#25361;&#25112;&#31995;&#32479;&#38754;&#20020;&#26032;&#30340;&#38544;&#31169;&#23041;&#32961;&#20026;&#20195;&#20215;&#12290;&#22240;&#27492;&#65292;&#23545;&#36825;&#31181;&#26032;&#33539; paradigm&#65292;&#24182;&#36827;&#34892;&#20840;&#38754;&#30340;&#23433;&#20840;&#20998;&#26512;&#26159;&#24517;&#35201;&#30340;&#12290;&#36825;&#39033;&#35843;&#26597;&#30740;&#31350;&#20102;&#21435;&#20013;&#24515;&#21270;&#32852;&#37030;&#23398;&#20064;&#20013;&#21487;&#33021;&#23384;&#22312;&#30340;&#23041;&#32961;&#21644;&#23545;&#25163;&#21464;&#21270;&#65292;&#24182;&#27010;&#36848;&#20102;&#28508;&#22312;&#30340;&#38450;&#24481;&#26426;&#21046;&#12290;&#36824;&#32771;&#34385;&#20102;&#21435;&#20013;&#24515;&#21270;&#32852;&#37030;&#23398;&#20064;&#30340;&#21487;&#20449;&#24230;&#21644;&#39564;&#35777;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated learning has been rapidly evolving and gaining popularity in recent years due to its privacy-preserving features, among other advantages. Nevertheless, the exchange of model updates and gradients in this architecture provides new attack surfaces for malicious users of the network which may jeopardize the model performance and user and data privacy. For this reason, one of the main motivations for decentralized federated learning is to eliminate server-related threats by removing the server from the network and compensating for it through technologies such as blockchain. However, this advantage comes at the cost of challenging the system with new privacy threats. Thus, performing a thorough security analysis in this new paradigm is necessary. This survey studies possible variations of threats and adversaries in decentralized federated learning and overviews the potential defense mechanisms. Trustability and verifiability of decentralized federated learning are also considered 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#22122;&#22768;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#26657;&#20934;&#38477;&#32500;&#36229;&#21442;&#25968;&#65292;&#25506;&#32034;&#20102;&#22256;&#24785;&#24230;&#21644;&#32500;&#24230;&#25968;&#37327;&#30340;&#20316;&#29992;&#12290;</title><link>https://arxiv.org/abs/2312.02946</link><description>&lt;p&gt;
&#22312;&#22122;&#22768;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#26657;&#20934;&#38477;&#32500;&#36229;&#21442;&#25968;
&lt;/p&gt;
&lt;p&gt;
Calibrating dimension reduction hyperparameters in the presence of noise
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.02946
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#22122;&#22768;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#26657;&#20934;&#38477;&#32500;&#36229;&#21442;&#25968;&#65292;&#25506;&#32034;&#20102;&#22256;&#24785;&#24230;&#21644;&#32500;&#24230;&#25968;&#37327;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38477;&#32500;&#24037;&#20855;&#30340;&#30446;&#26631;&#26159;&#26500;&#24314;&#39640;&#32500;&#25968;&#25454;&#30340;&#20302;&#32500;&#34920;&#31034;&#12290;&#36825;&#20123;&#24037;&#20855;&#34987;&#29992;&#20110;&#22122;&#22768;&#38477;&#20302;&#12289;&#21487;&#35270;&#21270;&#21644;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#31561;&#21508;&#31181;&#21407;&#22240;&#12290;&#28982;&#32780;&#65292;&#22312;&#38477;&#32500;&#25991;&#29486;&#20013;&#20960;&#20046;&#27809;&#26377;&#35752;&#35770;&#36807;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#26159;&#36807;&#25311;&#21512;&#65292;&#32780;&#22312;&#20854;&#20182;&#24314;&#27169;&#38382;&#39064;&#20013;&#36825;&#20010;&#38382;&#39064;&#24050;&#32463;&#34987;&#24191;&#27867;&#35752;&#35770;&#12290;&#22914;&#26524;&#25105;&#20204;&#23558;&#25968;&#25454;&#35299;&#37322;&#20026;&#20449;&#21495;&#21644;&#22122;&#22768;&#30340;&#32452;&#21512;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#23545;&#38477;&#32500;&#25216;&#26415;&#30340;&#35780;&#21028;&#26159;&#20854;&#26159;&#21542;&#33021;&#22815;&#25429;&#25417;&#21040;&#25968;&#25454;&#30340;&#20840;&#37096;&#20869;&#23481;&#65292;&#21363;&#20449;&#21495;&#21644;&#22122;&#22768;&#12290;&#22312;&#20854;&#20182;&#24314;&#27169;&#38382;&#39064;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#20250;&#37319;&#29992;&#29305;&#24449;&#36873;&#25321;&#12289;&#20132;&#21449;&#39564;&#35777;&#21644;&#27491;&#21017;&#21270;&#31561;&#25216;&#26415;&#26469;&#38450;&#27490;&#36807;&#25311;&#21512;&#65292;&#20294;&#22312;&#36827;&#34892;&#38477;&#32500;&#26102;&#21364;&#27809;&#26377;&#37319;&#21462;&#31867;&#20284;&#30340;&#39044;&#38450;&#25514;&#26045;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#22122;&#22768;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#24314;&#27169;&#38477;&#32500;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#35813;&#26694;&#26550;&#25506;&#32034;&#20102;&#22256;&#24785;&#24230;&#21644;&#32500;&#24230;&#25968;&#37327;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
The goal of dimension reduction tools is to construct a low-dimensional representation of high-dimensional data. These tools are employed for a variety of reasons such as noise reduction, visualization, and to lower computational costs. However, there is a fundamental issue that is highly discussed in other modeling problems, but almost entirely ignored in the dimension reduction literature: overfitting. If we interpret data as a combination of signal and noise, prior works judge dimension reduction techniques on their ability to capture the entirety of the data, i.e. both the signal and the noise. In the context of other modeling problems, techniques such as feature-selection, cross-validation, and regularization are employed to combat overfitting, but no such precautions are taken when performing dimension reduction. In this paper, we present a framework that models dimension reduction problems in the presence of noise and use this framework to explore the role perplexity and number 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#19968;&#33324;&#27969;&#24418;&#19978;&#26500;&#36896;&#39640;&#26031;&#36807;&#31243;&#30340;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#36866;&#29992;&#20110;&#20855;&#26377;&#39069;&#22806;&#23545;&#31216;&#24615;&#27969;&#24418;&#30340;&#26465;&#24102;&#31639;&#27861;&#21644;&#36866;&#29992;&#20110;&#20219;&#24847;&#27969;&#24418;&#30340;&#29699;&#31639;&#27861;&#65292;&#36825;&#20123;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#36890;&#36807;&#29702;&#35770;&#35777;&#26126;&#21644;&#25968;&#20540;&#27979;&#35797;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;</title><link>https://arxiv.org/abs/2006.14266</link><description>&lt;p&gt;
&#27969;&#24418;&#19978;&#30340;&#20869;&#22312;&#39640;&#26031;&#36807;&#31243;&#21450;&#20854;&#36890;&#36807;&#23545;&#31216;&#24615;&#30340;&#21152;&#36895;
&lt;/p&gt;
&lt;p&gt;
Intrinsic Gaussian Processes on Manifolds and Their Accelerations by Symmetry
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2006.14266
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#19968;&#33324;&#27969;&#24418;&#19978;&#26500;&#36896;&#39640;&#26031;&#36807;&#31243;&#30340;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#36866;&#29992;&#20110;&#20855;&#26377;&#39069;&#22806;&#23545;&#31216;&#24615;&#27969;&#24418;&#30340;&#26465;&#24102;&#31639;&#27861;&#21644;&#36866;&#29992;&#20110;&#20219;&#24847;&#27969;&#24418;&#30340;&#29699;&#31639;&#27861;&#65292;&#36825;&#20123;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#36890;&#36807;&#29702;&#35770;&#35777;&#26126;&#21644;&#25968;&#20540;&#27979;&#35797;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23545;&#27969;&#24418;&#39044;&#27979;&#22120;&#24212;&#29992;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#26102;&#65292;&#25105;&#20204;&#38754;&#20020;&#19968;&#20010;&#37325;&#35201;&#30340;&#25361;&#25112;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#20302;&#32500;&#32422;&#26463;&#22495;&#20013;&#29992;&#20110;&#28909;&#26680;&#20272;&#35745;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#39640;&#32500;&#27969;&#24418;&#20013;&#30340;&#25928;&#26524;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#19968;&#33324;&#27969;&#24418;&#19978;&#26500;&#36896;GP&#30340;&#20869;&#22312;&#26041;&#27861;&#65292;&#20363;&#22914;&#27491;&#20132;&#32676;&#12289;&#24186;&#27491;&#32676;&#12289;Stiefel&#27969;&#24418;&#21644;Grassmann&#27969;&#24418;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#29992;&#25351;&#25968;&#26144;&#23556;&#27169;&#25311;&#24067;&#26391;&#36816;&#21160;&#26679;&#26412;&#36335;&#24452;&#26469;&#20272;&#35745;&#28909;&#26680;&#65292;&#30830;&#20445;&#19982;&#27969;&#24418;&#30340;&#23884;&#20837;&#26080;&#20851;&#12290;&#25105;&#20204;&#24341;&#20837;&#30340;&#29992;&#20110;&#20855;&#26377;&#39069;&#22806;&#23545;&#31216;&#24615;&#27969;&#24418;&#30340;&#26465;&#24102;&#31639;&#27861;&#21644;&#29992;&#20110;&#20219;&#24847;&#27969;&#24418;&#30340;&#29699;&#31639;&#27861;&#26500;&#25104;&#20102;&#25105;&#20204;&#30340;&#37325;&#22823;&#36129;&#29486;&#12290;&#36890;&#36807;&#29702;&#35770;&#35777;&#26126;&#21644;&#25968;&#20540;&#27979;&#35797;&#65292;&#20004;&#20010;&#31639;&#27861;&#37117;&#24471;&#21040;&#20102;&#20005;&#26684;&#35777;&#23454;&#65292;&#20854;&#20013;&#26465;&#24102;&#31639;&#27861;&#23637;&#31034;&#20102;&#26174;&#30528;&#30340;&#25928;&#29575;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
Amidst the growing interest in nonparametric regression, we address a significant challenge in Gaussian processes(GP) applied to manifold-based predictors. Existing methods primarily focus on low dimensional constrained domains for heat kernel estimation, limiting their effectiveness in higher-dimensional manifolds. Our research proposes an intrinsic approach for constructing GP on general manifolds such as orthogonal groups, unitary groups, Stiefel manifolds and Grassmannian manifolds. Our methodology estimates the heat kernel by simulating Brownian motion sample paths using the exponential map, ensuring independence from the manifold's embedding. The introduction of our strip algorithm, tailored for manifolds with extra symmetries, and the ball algorithm, designed for arbitrary manifolds, constitutes our significant contribution. Both algorithms are rigorously substantiated through theoretical proofs and numerical testing, with the strip algorithm showcasing remarkable efficiency gai
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#39044;&#27979;&#25588;&#21161;&#20998;&#37197;&#30340;&#24322;&#36136;&#21270;&#27835;&#30103;&#25928;&#26524;&#65292;&#20197;&#25903;&#25345;&#26377;&#25928;&#30340;&#25588;&#21161;&#20998;&#37197;&#20915;&#31574;&#12290;</title><link>http://arxiv.org/abs/2401.16986</link><description>&lt;p&gt;
&#29992;&#20110;&#25104;&#26412;&#25928;&#30410;&#20248;&#21270;&#30340;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#22312;&#21457;&#23637;&#25588;&#21161;&#20998;&#37197;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Causal Machine Learning for Cost-Effective Allocation of Development Aid. (arXiv:2401.16986v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16986
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#39044;&#27979;&#25588;&#21161;&#20998;&#37197;&#30340;&#24322;&#36136;&#21270;&#27835;&#30103;&#25928;&#26524;&#65292;&#20197;&#25903;&#25345;&#26377;&#25928;&#30340;&#25588;&#21161;&#20998;&#37197;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#21512;&#22269;&#30340;&#21487;&#25345;&#32493;&#21457;&#23637;&#30446;&#26631;&#25552;&#20379;&#20102;&#8220;&#26080;&#20154;&#34987;&#36951;&#24323;&#8221;&#30340;&#26356;&#32654;&#22909;&#26410;&#26469;&#34013;&#22270;&#65292;&#20026;&#20102;&#22312;2030&#24180;&#20043;&#21069;&#23454;&#29616;&#36825;&#20123;&#30446;&#26631;&#65292;&#36139;&#31351;&#22269;&#23478;&#38656;&#35201;&#22823;&#37327;&#30340;&#21457;&#23637;&#25588;&#21161;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#39044;&#27979;&#25588;&#21161;&#20998;&#37197;&#30340;&#24322;&#36136;&#21270;&#27835;&#30103;&#25928;&#26524;&#65292;&#20197;&#25903;&#25345;&#26377;&#25928;&#30340;&#25588;&#21161;&#20998;&#37197;&#20915;&#31574;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#21253;&#25324;&#19977;&#20010;&#32452;&#25104;&#37096;&#20998;&#65306;&#65288;i&#65289;&#19968;&#20010;&#24179;&#34913;&#33258;&#32534;&#30721;&#22120;&#65292;&#21033;&#29992;&#34920;&#31034;&#23398;&#20064;&#23558;&#39640;&#32500;&#22269;&#23478;&#29305;&#24449;&#23884;&#20837;&#65292;&#21516;&#26102;&#35299;&#20915;&#27835;&#30103;&#36873;&#25321;&#20559;&#24046;&#38382;&#39064;&#65307;&#65288;ii&#65289;&#19968;&#20010;&#21453;&#20107;&#23454;&#29983;&#25104;&#22120;&#65292;&#29992;&#20110;&#35745;&#31639;&#22312;&#19981;&#21516;&#25588;&#21161;&#35268;&#27169;&#19979;&#30340;&#21453;&#20107;&#23454;&#32467;&#26524;&#65292;&#20197;&#35299;&#20915;&#23567;&#26679;&#26412;&#38382;&#39064;&#65307;&#65288;iii&#65289;&#19968;&#20010;&#25512;&#26029;&#27169;&#22411;&#65292;&#29992;&#20110;&#39044;&#27979;&#24322;&#36136;&#21270;&#30340;&#27835;&#30103;&#25928;&#26524;&#26354;&#32447;&#12290;&#25105;&#20204;&#20351;&#29992;105&#20010;&#22269;&#23478;&#25112;&#30053;&#24615;&#21457;&#23637;&#25588;&#21161;&#25968;&#25454;&#65288;&#24635;&#39069;&#36229;&#36807;52&#20159;&#32654;&#20803;&#65289;&#65292;&#20197;&#32467;&#26463;HIV/AIDS&#20026;&#30446;&#26631;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Sustainable Development Goals (SDGs) of the United Nations provide a blueprint of a better future by 'leaving no one behind', and, to achieve the SDGs by 2030, poor countries require immense volumes of development aid. In this paper, we develop a causal machine learning framework for predicting heterogeneous treatment effects of aid disbursements to inform effective aid allocation. Specifically, our framework comprises three components: (i) a balancing autoencoder that uses representation learning to embed high-dimensional country characteristics while addressing treatment selection bias; (ii) a counterfactual generator to compute counterfactual outcomes for varying aid volumes to address small sample-size settings; and (iii) an inference model that is used to predict heterogeneous treatment-response curves. We demonstrate the effectiveness of our framework using data with official development aid earmarked to end HIV/AIDS in 105 countries, amounting to more than USD 5.2 billion. F
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;Chen-Fliess&#24207;&#21015;&#23637;&#24320;&#23558;&#36830;&#32493;&#28145;&#24230;&#31070;&#32463;ODE&#27169;&#22411;&#36716;&#21270;&#20026;&#21333;&#23618;&#12289;&#26080;&#38480;&#23485;&#24230;&#30340;&#32593;&#32476;&#65292;&#24182;&#21033;&#29992;&#27492;&#26694;&#26550;&#25512;&#23548;&#20986;&#20102;&#23558;&#21021;&#22987;&#26465;&#20214;&#26144;&#23556;&#21040;&#26576;&#20010;&#32456;&#31471;&#26102;&#38388;&#30340;ODE&#27169;&#22411;&#30340;Rademacher&#22797;&#26434;&#24230;&#30340;&#32039;&#20945;&#34920;&#36798;&#24335;&#12290;</title><link>http://arxiv.org/abs/2401.16655</link><description>&lt;p&gt;
&#36890;&#36807;Chen-Fliess&#24207;&#21015;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#36830;&#32493;&#28145;&#24230;&#31070;&#32463;ODE&#27169;&#22411;&#26500;&#24314;&#20026;&#21333;&#23618;&#12289;&#26080;&#38480;&#23485;&#24230;&#30340;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
Rademacher Complexity of Neural ODEs via Chen-Fliess Series. (arXiv:2401.16655v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16655
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;Chen-Fliess&#24207;&#21015;&#23637;&#24320;&#23558;&#36830;&#32493;&#28145;&#24230;&#31070;&#32463;ODE&#27169;&#22411;&#36716;&#21270;&#20026;&#21333;&#23618;&#12289;&#26080;&#38480;&#23485;&#24230;&#30340;&#32593;&#32476;&#65292;&#24182;&#21033;&#29992;&#27492;&#26694;&#26550;&#25512;&#23548;&#20986;&#20102;&#23558;&#21021;&#22987;&#26465;&#20214;&#26144;&#23556;&#21040;&#26576;&#20010;&#32456;&#31471;&#26102;&#38388;&#30340;ODE&#27169;&#22411;&#30340;Rademacher&#22797;&#26434;&#24230;&#30340;&#32039;&#20945;&#34920;&#36798;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#36830;&#32493;&#28145;&#24230;&#31070;&#32463;ODE&#27169;&#22411;&#20351;&#29992;Chen-Fliess&#24207;&#21015;&#23637;&#24320;&#20026;&#21333;&#23618;&#12289;&#26080;&#38480;&#23485;&#24230;&#30340;&#32593;&#32476;&#12290;&#22312;&#36825;&#20010;&#32593;&#32476;&#20013;&#65292;&#36755;&#20986;&#30340;&#8220;&#26435;&#37325;&#8221;&#26469;&#33258;&#25511;&#21046;&#36755;&#20837;&#30340;&#29305;&#24449;&#24207;&#21015;&#65292;&#23427;&#30001;&#25511;&#21046;&#36755;&#20837;&#22312;&#21333;&#32431;&#24418;&#19978;&#30340;&#36845;&#20195;&#31215;&#20998;&#26500;&#25104;&#12290;&#32780;&#8220;&#29305;&#24449;&#8221;&#21017;&#22522;&#20110;&#21463;&#25511;ODE&#27169;&#22411;&#20013;&#36755;&#20986;&#20989;&#25968;&#30456;&#23545;&#20110;&#21521;&#37327;&#22330;&#30340;&#36845;&#20195;&#26446;&#23548;&#25968;&#12290;&#26412;&#25991;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#65292;&#24212;&#29992;&#36825;&#20010;&#26694;&#26550;&#25512;&#23548;&#20986;&#20102;&#23558;&#21021;&#22987;&#26465;&#20214;&#26144;&#23556;&#21040;&#26576;&#20010;&#32456;&#31471;&#26102;&#38388;&#30340;ODE&#27169;&#22411;&#30340;Rademacher&#22797;&#26434;&#24230;&#30340;&#32039;&#20945;&#34920;&#36798;&#24335;&#12290;&#36825;&#19968;&#32467;&#26524;&#21033;&#29992;&#20102;&#21333;&#23618;&#32467;&#26500;&#25152;&#24102;&#26469;&#30340;&#30452;&#25509;&#20998;&#26512;&#24615;&#36136;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#20123;&#20855;&#20307;&#31995;&#32479;&#30340;&#20363;&#23376;&#23454;&#20363;&#21270;&#35813;&#30028;&#65292;&#24182;&#35752;&#35770;&#20102;&#21487;&#33021;&#30340;&#21518;&#32493;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show how continuous-depth neural ODE models can be framed as single-layer, infinite-width nets using the Chen--Fliess series expansion for nonlinear ODEs. In this net, the output ''weights'' are taken from the signature of the control input -- a tool used to represent infinite-dimensional paths as a sequence of tensors -- which comprises iterated integrals of the control input over a simplex. The ''features'' are taken to be iterated Lie derivatives of the output function with respect to the vector fields in the controlled ODE model. The main result of this work applies this framework to derive compact expressions for the Rademacher complexity of ODE models that map an initial condition to a scalar output at some terminal time. The result leverages the straightforward analysis afforded by single-layer architectures. We conclude with some examples instantiating the bound for some specific systems and discuss potential follow-up work.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#19987;&#21033;&#25968;&#25454;&#25552;&#39640;&#20102;&#25239;&#20307;&#20154;&#24615;&#39044;&#27979;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#22810;&#38454;&#27573;&#12289;&#22810;&#25439;&#22833;&#30340;&#35757;&#32451;&#36807;&#31243;&#20197;&#21450;&#24369;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#25104;&#21151;&#22320;&#39044;&#27979;&#20102;&#25239;&#20307;&#24207;&#21015;&#30340;&#20154;&#24615;&#35780;&#20998;&#12290;</title><link>http://arxiv.org/abs/2401.14442</link><description>&lt;p&gt;
&#21033;&#29992;&#19987;&#21033;&#25968;&#25454;&#25552;&#39640;&#25239;&#20307;&#20154;&#24615;&#39044;&#27979;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Improving Antibody Humanness Prediction using Patent Data. (arXiv:2401.14442v1 [q-bio.QM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14442
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#19987;&#21033;&#25968;&#25454;&#25552;&#39640;&#20102;&#25239;&#20307;&#20154;&#24615;&#39044;&#27979;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#22810;&#38454;&#27573;&#12289;&#22810;&#25439;&#22833;&#30340;&#35757;&#32451;&#36807;&#31243;&#20197;&#21450;&#24369;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#25104;&#21151;&#22320;&#39044;&#27979;&#20102;&#25239;&#20307;&#24207;&#21015;&#30340;&#20154;&#24615;&#35780;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#21033;&#29992;&#19987;&#21033;&#25968;&#25454;&#26469;&#25552;&#39640;&#25239;&#20307;&#20154;&#24615;&#39044;&#27979;&#30340;&#28508;&#21147;&#65292;&#37319;&#29992;&#20102;&#22810;&#38454;&#27573;&#12289;&#22810;&#25439;&#22833;&#30340;&#35757;&#32451;&#36807;&#31243;&#12290;&#25239;&#20307;&#20154;&#24615;&#20316;&#20026;&#23545;&#25239;&#20307;&#27835;&#30103;&#30340;&#20813;&#30123;&#21453;&#24212;&#30340;&#20195;&#29702;&#65292;&#26159;&#33647;&#29289;&#21457;&#29616;&#20013;&#30340;&#20027;&#35201;&#21407;&#22240;&#20043;&#19968;&#65292;&#22312;&#20020;&#24202;&#29615;&#22659;&#20013;&#20351;&#29992;&#25239;&#20307;&#27835;&#30103;&#38754;&#20020;&#30528;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38556;&#30861;&#12290;&#25105;&#20204;&#23558;&#21021;&#22987;&#23398;&#20064;&#38454;&#27573;&#35270;&#20026;&#19968;&#20010;&#24369;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#38382;&#39064;&#65292;&#27599;&#20010;&#25239;&#20307;&#24207;&#21015;&#19982;&#21487;&#33021;&#26377;&#22810;&#20010;&#21151;&#33021;&#26631;&#35782;&#31526;&#30456;&#20851;&#32852;&#65292;&#30446;&#26631;&#26159;&#23398;&#20064;&#19968;&#20010;&#32534;&#30721;&#22120;&#65292;&#26681;&#25454;&#20854;&#19987;&#21033;&#23646;&#24615;&#23558;&#23427;&#20204;&#20998;&#32452;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20923;&#32467;&#23545;&#27604;&#32534;&#30721;&#22120;&#30340;&#19968;&#37096;&#20998;&#65292;&#24182;&#32487;&#32493;&#20351;&#29992;&#20132;&#21449;&#29109;&#25439;&#22833;&#22312;&#19987;&#21033;&#25968;&#25454;&#19978;&#35757;&#32451;&#65292;&#20197;&#39044;&#27979;&#32473;&#23450;&#25239;&#20307;&#24207;&#21015;&#30340;&#20154;&#24615;&#35780;&#20998;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#19977;&#20010;&#19981;&#21516;&#30340;&#20813;&#30123;&#21407;&#24615;&#25968;&#25454;&#38598;&#36827;&#34892;&#25512;&#29702;&#65292;&#23637;&#31034;&#20102;&#19987;&#21033;&#25968;&#25454;&#21644;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#25928;&#29992;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;l
&lt;/p&gt;
&lt;p&gt;
We investigate the potential of patent data for improving the antibody humanness prediction using a multi-stage, multi-loss training process. Humanness serves as a proxy for the immunogenic response to antibody therapeutics, one of the major causes of attrition in drug discovery and a challenging obstacle for their use in clinical settings. We pose the initial learning stage as a weakly-supervised contrastive-learning problem, where each antibody sequence is associated with possibly multiple identifiers of function and the objective is to learn an encoder that groups them according to their patented properties. We then freeze a part of the contrastive encoder and continue training it on the patent data using the cross-entropy loss to predict the humanness score of a given antibody sequence. We illustrate the utility of the patent data and our approach by performing inference on three different immunogenicity datasets, unseen during training. Our empirical results demonstrate that the l
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25193;&#23637;&#20102;&#20043;&#21069;&#30340;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#22522;&#20110;&#23485;&#32780;&#28145;&#30340;ReLU&#31070;&#32463;&#32593;&#32476;&#21644;&#36923;&#36753;&#25439;&#22833;&#35757;&#32451;&#30340;&#20998;&#31867;&#35268;&#21017;&#20855;&#26377;&#26222;&#36866;&#19968;&#33268;&#24615;&#65292;&#24182;&#32473;&#20986;&#20102;&#19968;&#31867;&#27010;&#29575;&#27979;&#24230;&#26465;&#20214;&#19979;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#31867;&#22120;&#23454;&#29616;&#26497;&#23567;&#26497;&#38480;&#25910;&#25947;&#36895;&#29575;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2401.04286</link><description>&lt;p&gt;
&#23485;&#32780;&#28145;&#30340;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#26222;&#36866;&#19968;&#33268;&#24615;&#20197;&#21450;Kolmogorov-Donoho&#26368;&#20248;&#20989;&#25968;&#31867;&#30340;&#26497;&#23567;&#26497;&#38480;&#25910;&#25947;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Universal Consistency of Wide and Deep ReLU Neural Networks and Minimax Optimal Convergence Rates for Kolmogorov-Donoho Optimal Function Classes. (arXiv:2401.04286v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04286
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25193;&#23637;&#20102;&#20043;&#21069;&#30340;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#22522;&#20110;&#23485;&#32780;&#28145;&#30340;ReLU&#31070;&#32463;&#32593;&#32476;&#21644;&#36923;&#36753;&#25439;&#22833;&#35757;&#32451;&#30340;&#20998;&#31867;&#35268;&#21017;&#20855;&#26377;&#26222;&#36866;&#19968;&#33268;&#24615;&#65292;&#24182;&#32473;&#20986;&#20102;&#19968;&#31867;&#27010;&#29575;&#27979;&#24230;&#26465;&#20214;&#19979;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#31867;&#22120;&#23454;&#29616;&#26497;&#23567;&#26497;&#38480;&#25910;&#25947;&#36895;&#29575;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#20808;&#25193;&#23637;&#20102;FL93&#30340;&#32467;&#26524;&#65292;&#24182;&#35777;&#26126;&#20102;&#22522;&#20110;&#23485;&#32780;&#28145;&#30340;ReLU&#31070;&#32463;&#32593;&#32476;&#21644;&#36923;&#36753;&#25439;&#22833;&#35757;&#32451;&#30340;&#20998;&#31867;&#35268;&#21017;&#30340;&#26222;&#36866;&#19968;&#33268;&#24615;&#12290;&#19982;FL93&#20013;&#20998;&#35299;&#20272;&#35745;&#21644;&#32463;&#39564;&#35823;&#24046;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#26681;&#25454;&#19968;&#20010;&#24191;&#27867;&#30340;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#25554;&#20540;&#20219;&#24847;&#25968;&#37327;&#30340;&#28857;&#30340;&#35266;&#23519;&#65292;&#30452;&#25509;&#20998;&#26512;&#20998;&#31867;&#39118;&#38505;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#31867;&#27010;&#29575;&#27979;&#24230;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#22312;&#36825;&#20123;&#26465;&#20214;&#19979;&#65292;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#31867;&#22120;&#23454;&#29616;&#20102;&#26497;&#23567;&#26497;&#38480;&#25910;&#25947;&#36895;&#29575;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#28304;&#20110;&#23454;&#36341;&#32773;&#35266;&#23519;&#21040;&#31070;&#32463;&#32593;&#32476;&#36890;&#24120;&#34987;&#35757;&#32451;&#25104;&#36798;&#21040;0&#35757;&#32451;&#35823;&#24046;&#30340;&#20107;&#23454;&#65292;&#36825;&#20063;&#26159;&#25105;&#20204;&#25552;&#20986;&#30340;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#20381;&#36182;&#20110;&#26368;&#36817;&#22312;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#21644;&#28145;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#36895;&#29575;&#26041;&#38754;&#30340;&#21457;&#23637;&#65292;&#36866;&#29992;&#20110;&#19981;&#21516;&#30340;&#24863;&#20852;&#36259;&#20989;&#25968;&#31867;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we first extend the result of FL93 and prove universal consistency for a classification rule based on wide and deep ReLU neural networks trained on the logistic loss. Unlike the approach in FL93 that decomposes the estimation and empirical error, we directly analyze the classification risk based on the observation that a realization of a neural network that is wide enough is capable of interpolating an arbitrary number of points. Secondly, we give sufficient conditions for a class of probability measures under which classifiers based on neural networks achieve minimax optimal rates of convergence. Our result is motivated from the practitioner's observation that neural networks are often trained to achieve 0 training error, which is the case for our proposed neural network classifiers. Our proofs hinge on recent developments in empirical risk minimization and on approximation rates of deep ReLU neural networks for various function classes of interest. Applications to clas
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21457;&#29616;&#22312;&#24378;&#21270;&#24494;&#35843;&#65288;RFT&#65289;&#20013;&#23384;&#22312;&#26799;&#24230;&#28040;&#22833;&#30340;&#38382;&#39064;&#65292;&#24403;&#27169;&#22411;&#19979;&#22870;&#21169;&#30340;&#26631;&#20934;&#24046;&#36739;&#23567;&#26102;&#65292;&#36755;&#20837;&#30340;&#26399;&#26395;&#26799;&#24230;&#20250;&#28040;&#22833;&#65292;&#23548;&#33268;&#22870;&#21169;&#26368;&#22823;&#21270;&#32531;&#24930;&#12290;&#21021;&#22987;&#30417;&#30563;&#24494;&#35843;&#65288;SFT&#65289;&#38454;&#27573;&#26159;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#30340;&#26368;&#26377;&#24076;&#26395;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.20703</link><description>&lt;p&gt;
&#24378;&#21270;&#24494;&#35843;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#26799;&#24230;&#28040;&#22833;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Vanishing Gradients in Reinforcement Finetuning of Language Models. (arXiv:2310.20703v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20703
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21457;&#29616;&#22312;&#24378;&#21270;&#24494;&#35843;&#65288;RFT&#65289;&#20013;&#23384;&#22312;&#26799;&#24230;&#28040;&#22833;&#30340;&#38382;&#39064;&#65292;&#24403;&#27169;&#22411;&#19979;&#22870;&#21169;&#30340;&#26631;&#20934;&#24046;&#36739;&#23567;&#26102;&#65292;&#36755;&#20837;&#30340;&#26399;&#26395;&#26799;&#24230;&#20250;&#28040;&#22833;&#65292;&#23548;&#33268;&#22870;&#21169;&#26368;&#22823;&#21270;&#32531;&#24930;&#12290;&#21021;&#22987;&#30417;&#30563;&#24494;&#35843;&#65288;SFT&#65289;&#38454;&#27573;&#26159;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#30340;&#26368;&#26377;&#24076;&#26395;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#36890;&#36807;&#24378;&#21270;&#24494;&#35843;&#65288;RFT&#65289;&#19982;&#20154;&#31867;&#20559;&#22909;&#21644;&#19979;&#28216;&#20219;&#21153;&#23545;&#40784;&#65292;&#21363;&#20351;&#29992;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#26368;&#22823;&#21270;&#65288;&#21487;&#33021;&#26159;&#23398;&#20064;&#24471;&#21040;&#30340;&#65289;&#22870;&#21169;&#20989;&#25968;&#12290;&#26412;&#30740;&#31350;&#21457;&#29616;&#20102;RFT&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#30340;&#20248;&#21270;&#38556;&#30861;&#65306;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#27169;&#22411;&#19979;&#30340;&#22870;&#21169;&#26631;&#20934;&#24046;&#36739;&#23567;&#26102;&#65292;&#36755;&#20837;&#30340;&#26399;&#26395;&#26799;&#24230;&#20250;&#28040;&#22833;&#65292;&#21363;&#20351;&#26399;&#26395;&#22870;&#21169;&#36828;&#31163;&#26368;&#20248;&#35299;&#12290;&#36890;&#36807;&#22312;RFT&#22522;&#20934;&#21644;&#25511;&#21046;&#29615;&#22659;&#20013;&#36827;&#34892;&#23454;&#39564;&#65292;&#20197;&#21450;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#30001;&#20110;&#23567;&#30340;&#22870;&#21169;&#26631;&#20934;&#24046;&#23548;&#33268;&#30340;&#26799;&#24230;&#28040;&#22833;&#38382;&#39064;&#26222;&#36941;&#23384;&#22312;&#19988;&#26377;&#23475;&#65292;&#23548;&#33268;&#22870;&#21169;&#26368;&#22823;&#21270;&#26497;&#20854;&#32531;&#24930;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#20811;&#26381;RFT&#20013;&#26799;&#24230;&#28040;&#22833;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#21457;&#29616;&#21021;&#22987;&#30417;&#30563;&#24494;&#35843;&#65288;SFT&#65289;&#38454;&#27573;&#26159;&#26368;&#26377;&#24076;&#26395;&#30340;&#20505;&#36873;&#26041;&#27861;&#65292;&#24182;&#19988;&#25581;&#31034;&#20102;&#23427;&#22312;RFT&#27969;&#31243;&#20013;&#30340;&#37325;&#35201;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#34920;&#26126;&#30456;&#23545;&#36739;&#23567;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;SFT&#38454;&#27573;&#21487;&#20197;&#26377;&#25928;&#20811;&#26381;&#26799;&#24230;&#28040;&#22833;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pretrained language models are commonly aligned with human preferences and downstream tasks via reinforcement finetuning (RFT), which entails maximizing a (possibly learned) reward function using policy gradient algorithms. This work highlights a fundamental optimization obstacle in RFT: we prove that the expected gradient for an input vanishes when its reward standard deviation under the model is small, even if the expected reward is far from optimal. Through experiments on an RFT benchmark and controlled environments, as well as a theoretical analysis, we then demonstrate that vanishing gradients due to small reward standard deviation are prevalent and detrimental, leading to extremely slow reward maximization. Lastly, we explore ways to overcome vanishing gradients in RFT. We find the common practice of an initial supervised finetuning (SFT) phase to be the most promising candidate, which sheds light on its importance in an RFT pipeline. Moreover, we show that a relatively small num
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19978;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#21253;&#25324;&#25512;&#23548;&#20102;&#25928;&#26524;&#21644;&#25104;&#21151;&#29575;&#30340;&#32479;&#35745;&#37327;&#65292;&#24182;&#25552;&#20379;&#20102;&#20960;&#31181;&#24773;&#20917;&#19979;&#30340;&#30028;&#38480;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#26681;&#25454;&#26679;&#26412;&#25968;&#37327;&#21644;&#20854;&#20182;&#32467;&#26500;&#21442;&#25968;&#25512;&#26029;&#28508;&#22312;&#25915;&#20987;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.13786</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#30340;&#22522;&#26412;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
Fundamental Limits of Membership Inference Attacks on Machine Learning Models. (arXiv:2310.13786v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13786
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19978;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#21253;&#25324;&#25512;&#23548;&#20102;&#25928;&#26524;&#21644;&#25104;&#21151;&#29575;&#30340;&#32479;&#35745;&#37327;&#65292;&#24182;&#25552;&#20379;&#20102;&#20960;&#31181;&#24773;&#20917;&#19979;&#30340;&#30028;&#38480;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#26681;&#25454;&#26679;&#26412;&#25968;&#37327;&#21644;&#20854;&#20182;&#32467;&#26500;&#21442;&#25968;&#25512;&#26029;&#28508;&#22312;&#25915;&#20987;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#65288;MIA&#65289;&#21487;&#20197;&#25581;&#31034;&#29305;&#23450;&#25968;&#25454;&#28857;&#26159;&#21542;&#26159;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#19968;&#37096;&#20998;&#65292;&#21487;&#33021;&#26292;&#38706;&#20010;&#20154;&#30340;&#25935;&#24863;&#20449;&#24687;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#20851;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19978;MIA&#30340;&#22522;&#26412;&#32479;&#35745;&#38480;&#21046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#25512;&#23548;&#20102;&#32479;&#35745;&#37327;&#65292;&#35813;&#32479;&#35745;&#37327;&#20915;&#23450;&#20102;&#36825;&#31181;&#25915;&#20987;&#30340;&#26377;&#25928;&#24615;&#21644;&#25104;&#21151;&#29575;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20960;&#31181;&#24773;&#20917;&#65292;&#24182;&#23545;&#36825;&#20010;&#24863;&#20852;&#36259;&#30340;&#32479;&#35745;&#37327;&#25552;&#20379;&#20102;&#30028;&#38480;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#26681;&#25454;&#26679;&#26412;&#25968;&#37327;&#21644;&#23398;&#20064;&#27169;&#22411;&#30340;&#20854;&#20182;&#32467;&#26500;&#21442;&#25968;&#25512;&#26029;&#28508;&#22312;&#25915;&#20987;&#30340;&#20934;&#30830;&#24615;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#21487;&#20197;&#30452;&#25509;&#20174;&#25968;&#25454;&#38598;&#20013;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Membership inference attacks (MIA) can reveal whether a particular data point was part of the training dataset, potentially exposing sensitive information about individuals. This article explores the fundamental statistical limitations associated with MIAs on machine learning models. More precisely, we first derive the statistical quantity that governs the effectiveness and success of such attacks. Then, we investigate several situations for which we provide bounds on this quantity of interest. This allows us to infer the accuracy of potential attacks as a function of the number of samples and other structural parameters of learning models, which in some cases can be directly estimated from the dataset.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#22810;&#31181;&#28608;&#27963;&#20989;&#25968;&#19979;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;&#21487;&#20197;&#36890;&#36807;&#22312;&#26377;&#30028;&#38598;&#21512;&#19978;&#26500;&#24314;&#19968;&#20010;&#23485;&#24230;&#20026;6N&#12289;&#28145;&#24230;&#20026;2L&#30340;varrho&#28608;&#27963;&#32593;&#32476;&#26469;&#36924;&#36817;&#19968;&#20010;&#23485;&#24230;&#20026;N&#12289;&#28145;&#24230;&#20026;L&#30340;ReLU&#32593;&#32476;&#65292;&#20174;&#32780;&#23558;&#23545;ReLU&#32593;&#32476;&#30340;&#36924;&#36817;&#32467;&#26524;&#25512;&#24191;&#21040;&#20854;&#20182;&#28608;&#27963;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2307.06555</link><description>&lt;p&gt;
&#28145;&#24230;&#32593;&#32476;&#36924;&#36817;&#65306;&#20174;ReLU&#21040;&#22810;&#31181;&#28608;&#27963;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Deep Network Approximation: Beyond ReLU to Diverse Activation Functions. (arXiv:2307.06555v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06555
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#22810;&#31181;&#28608;&#27963;&#20989;&#25968;&#19979;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;&#21487;&#20197;&#36890;&#36807;&#22312;&#26377;&#30028;&#38598;&#21512;&#19978;&#26500;&#24314;&#19968;&#20010;&#23485;&#24230;&#20026;6N&#12289;&#28145;&#24230;&#20026;2L&#30340;varrho&#28608;&#27963;&#32593;&#32476;&#26469;&#36924;&#36817;&#19968;&#20010;&#23485;&#24230;&#20026;N&#12289;&#28145;&#24230;&#20026;L&#30340;ReLU&#32593;&#32476;&#65292;&#20174;&#32780;&#23558;&#23545;ReLU&#32593;&#32476;&#30340;&#36924;&#36817;&#32467;&#26524;&#25512;&#24191;&#21040;&#20854;&#20182;&#28608;&#27963;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#22810;&#31181;&#28608;&#27963;&#20989;&#25968;&#19979;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;&#23450;&#20041;&#20102;&#19968;&#20010;&#28608;&#27963;&#20989;&#25968;&#38598;&#21512;A&#65292;&#21253;&#25324;&#22823;&#22810;&#25968;&#24120;&#29992;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#22914;ReLU&#12289;LeakyReLU&#12289;ReLU^2&#12289;ELU&#12289;SELU&#12289;Softplus&#12289;GELU&#12289;SiLU&#12289;Swish&#12289;Mish&#12289;Sigmoid&#12289;Tanh&#12289;Arctan&#12289;Softsign&#12289;dSiLU&#21644;SRS&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20219;&#24847;&#28608;&#27963;&#20989;&#25968;varrho&#8712;A&#65292;&#21487;&#20197;&#36890;&#36807;&#19968;&#20010;&#23485;&#24230;&#20026;6N&#12289;&#28145;&#24230;&#20026;2L&#30340;varrho&#28608;&#27963;&#32593;&#32476;&#22312;&#26377;&#30028;&#38598;&#21512;&#19978;&#20197;&#20219;&#24847;&#31934;&#24230;&#36924;&#36817;&#19968;&#20010;&#23485;&#24230;&#20026;N&#12289;&#28145;&#24230;&#20026;L&#30340;ReLU&#32593;&#32476;&#12290;&#36825;&#19968;&#21457;&#29616;&#20351;&#24471;&#22823;&#37096;&#20998;&#23545;&#20110;ReLU&#32593;&#32476;&#30340;&#36924;&#36817;&#32467;&#26524;&#33021;&#22815;&#25512;&#24191;&#21040;&#20854;&#20182;&#28608;&#27963;&#20989;&#25968;&#65292;&#23613;&#31649;&#38656;&#35201;&#31245;&#22823;&#30340;&#24120;&#25968;&#20195;&#20215;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores the expressive power of deep neural networks for a diverse range of activation functions. An activation function set $\mathscr{A}$ is defined to encompass the majority of commonly used activation functions, such as $\mathtt{ReLU}$, $\mathtt{LeakyReLU}$, $\mathtt{ReLU}^2$, $\mathtt{ELU}$, $\mathtt{SELU}$, $\mathtt{Softplus}$, $\mathtt{GELU}$, $\mathtt{SiLU}$, $\mathtt{Swish}$, $\mathtt{Mish}$, $\mathtt{Sigmoid}$, $\mathtt{Tanh}$, $\mathtt{Arctan}$, $\mathtt{Softsign}$, $\mathtt{dSiLU}$, and $\mathtt{SRS}$. We demonstrate that for any activation function $\varrho\in \mathscr{A}$, a $\mathtt{ReLU}$ network of width $N$ and depth $L$ can be approximated to arbitrary precision by a $\varrho$-activated network of width $6N$ and depth $2L$ on any bounded set. This finding enables the extension of most approximation results achieved with $\mathtt{ReLU}$ networks to a wide variety of other activation functions, at the cost of slightly larger constants.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#26102;&#31354;Tweedie&#27169;&#22411;STTD&#65292;&#26088;&#22312;&#35299;&#20915;&#39640;&#20998;&#36776;&#29575;OD&#30697;&#38453;&#20013;&#31232;&#30095;&#21644;&#38271;&#23614;&#29305;&#24449;&#30340;&#38382;&#39064;&#65292;&#24182;&#25104;&#21151;&#37327;&#21270;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#65292;&#20855;&#26377;&#24456;&#39640;&#30340;&#24212;&#29992;&#21069;&#26223;&#12290;</title><link>http://arxiv.org/abs/2306.09882</link><description>&lt;p&gt;
&#26102;&#31354;Tweedie&#27169;&#22411;&#22312;&#39044;&#27979;&#23384;&#22312;&#38646;&#33192;&#32960;&#21644;&#38271;&#23614;&#26053;&#34892;&#38656;&#27714;&#20013;&#30340;&#24212;&#29992;&#21450;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Uncertainty Quantification via Spatial-Temporal Tweedie Model for Zero-inflated and Long-tail Travel Demand Prediction. (arXiv:2306.09882v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09882
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#26102;&#31354;Tweedie&#27169;&#22411;STTD&#65292;&#26088;&#22312;&#35299;&#20915;&#39640;&#20998;&#36776;&#29575;OD&#30697;&#38453;&#20013;&#31232;&#30095;&#21644;&#38271;&#23614;&#29305;&#24449;&#30340;&#38382;&#39064;&#65292;&#24182;&#25104;&#21151;&#37327;&#21270;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#65292;&#20855;&#26377;&#24456;&#39640;&#30340;&#24212;&#29992;&#21069;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#26102;&#31354;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#38590;&#20197;&#35299;&#20915;&#39640;&#20998;&#36776;&#29575;OD&#30697;&#38453;&#20013;&#31232;&#30095;&#21644;&#38271;&#23614;&#29305;&#24449;&#30340;&#38382;&#39064;&#65292;&#20174;&#32780;&#38590;&#20197;&#37327;&#21270;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#65292;&#32780;&#36825;&#23545;&#20110;&#20132;&#36890;&#31649;&#29702;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65306;&#31354;&#38388;-Tweedie&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;STTD&#65289;&#12290;STTD&#23558;Tweedie&#20998;&#24067;&#20316;&#20026;&#20256;&#32479;&#30340;&#8220;&#38646;&#33192;&#32960;&#8221;&#27169;&#22411;&#30340;&#26377;&#21147;&#26367;&#20195;&#21697;&#65292;&#24182;&#21033;&#29992;&#31354;&#38388;&#21644;&#26102;&#38388;&#23884;&#20837;&#26469;&#21442;&#25968;&#21270;&#26053;&#34892;&#38656;&#27714;&#20998;&#24067;&#12290;&#25105;&#20204;&#20351;&#29992;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#35780;&#20272;&#65292;&#32467;&#26524;&#34920;&#26126;STTD&#22312;&#39640;&#20998;&#36776;&#29575;&#22330;&#26223;&#19979;&#25552;&#20379;&#20102;&#20934;&#30830;&#30340;&#39044;&#27979;&#21644;&#31934;&#30830;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#20855;&#26377;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
crucial for transportation management. However, traditional spatial-temporal deep learning models grapple with addressing the sparse and long-tail characteristics in high-resolution O-D matrices and quantifying prediction uncertainty. This dilemma arises from the numerous zeros and over-dispersed demand patterns within these matrices, which challenge the Gaussian assumption inherent to deterministic deep learning models. To address these challenges, we propose a novel approach: the Spatial-Temporal Tweedie Graph Neural Network (STTD). The STTD introduces the Tweedie distribution as a compelling alternative to the traditional 'zero-inflated' model and leverages spatial and temporal embeddings to parameterize travel demand distributions. Our evaluations using real-world datasets highlight STTD's superiority in providing accurate predictions and precise confidence intervals, particularly in high-resolution scenarios.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#32452;&#21512;&#21644;&#20195;&#25968;&#35270;&#35282;&#25506;&#35752;&#20102;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#36793;&#38469;&#29420;&#31435;&#32467;&#26500;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110; Gr&#246;bner &#22522;&#30784;&#30340; MCMC &#26041;&#27861; GrUES&#65292;&#35813;&#26041;&#27861;&#22312;&#24674;&#22797;&#30495;&#23454;&#32467;&#26500;&#21644;&#20272;&#35745;&#21518;&#39564;&#19978;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2210.00822</link><description>&lt;p&gt;
&#20851;&#20110;&#36125;&#21494;&#26031;&#32593;&#32476;&#36793;&#38469;&#29420;&#31435;&#32467;&#26500;&#30340;&#32452;&#21512;&#21644;&#20195;&#25968;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Combinatorial and algebraic perspectives on the marginal independence structure of Bayesian networks. (arXiv:2210.00822v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.00822
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#32452;&#21512;&#21644;&#20195;&#25968;&#35270;&#35282;&#25506;&#35752;&#20102;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#36793;&#38469;&#29420;&#31435;&#32467;&#26500;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110; Gr&#246;bner &#22522;&#30784;&#30340; MCMC &#26041;&#27861; GrUES&#65292;&#35813;&#26041;&#27861;&#22312;&#24674;&#22797;&#30495;&#23454;&#32467;&#26500;&#21644;&#20272;&#35745;&#21518;&#39564;&#19978;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#20272;&#35745;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#36793;&#38469;&#29420;&#31435;&#32467;&#26500;&#30340;&#38382;&#39064;&#65292;&#36825;&#20123;&#25968;&#25454;&#20197;&#19968;&#20010;&#26080;&#21521;&#22270;&#30340;&#24418;&#24335;&#21576;&#29616;&#65292;&#34987;&#31216;&#20026;&#26080;&#26465;&#20214;&#20381;&#36182;&#22270;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#26080;&#26465;&#20214;&#20381;&#36182;&#22270;&#23545;&#24212;&#20110;&#20855;&#26377;&#30456;&#31561;&#29420;&#31435;&#24615;&#21644;&#20132;&#38598;&#25968;&#30340;&#22270;&#12290;&#22522;&#20110;&#36825;&#19968;&#35266;&#23519;&#32467;&#26524;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19982;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#26080;&#26465;&#20214;&#20381;&#36182;&#22270;&#30456;&#20851;&#30340;&#19968;&#20010;&#25299;&#25169;&#29702;&#24819;&#30340; Gr&#246;bner &#22522;&#30784;&#65292;&#28982;&#21518;&#36890;&#36807;&#39069;&#22806;&#30340;&#20108;&#39033;&#24335;&#20851;&#31995;&#23558;&#20854;&#25193;&#23637;&#20197;&#36830;&#25509;&#25152;&#26377;&#36825;&#20123;&#22270;&#30340;&#31354;&#38388;&#12290;&#25105;&#20204;&#23454;&#29616;&#20102;&#19968;&#31181;&#21517;&#20026; GrUES (Gr&#246;bner-based Unconditional Equivalence Search) &#30340; MCMC &#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#25152;&#24471;&#30340;&#31227;&#21160;&#24182;&#24212;&#29992;&#20110;&#21512;&#25104;&#39640;&#26031;&#25968;&#25454;&#12290;GrUES &#20197;&#27604;&#31616;&#21333;&#30340;&#29420;&#31435;&#24615;&#27979;&#35797;&#26356;&#39640;&#30340;&#36895;&#29575;&#24674;&#22797;&#30495;&#23454;&#30340;&#36793;&#38469;&#29420;&#31435;&#32467;&#26500;&#65292;&#21516;&#26102;&#36824;&#20135;&#29983;&#20102;&#19968;&#20010;&#21253;&#25324;&#30495;&#23454;&#32467;&#26500;&#30340;&#21518;&#39564;&#20272;&#35745;&#65292;&#20854;&#20013; $20\%$ &#30340; HPD &#32622;&#20449;&#21306;&#38388;&#21253;&#21547;&#30495;&#23454;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of estimating the marginal independence structure of a Bayesian network from observational data in the form of an undirected graph called the unconditional dependence graph. We show that unconditional dependence graphs of Bayesian networks correspond to the graphs having equal independence and intersection numbers. Using this observation, a Gr\"obner basis for a toric ideal associated to unconditional dependence graphs of Bayesian networks is given and then extended by additional binomial relations to connect the space of all such graphs. An MCMC method, called GrUES (Gr\"obner-based Unconditional Equivalence Search), is implemented based on the resulting moves and applied to synthetic Gaussian data. GrUES recovers the true marginal independence structure via a penalized maximum likelihood or MAP estimate at a higher rate than simple independence tests while also yielding an estimate of the posterior, for which the $20\%$ HPD credible sets include the true struc
&lt;/p&gt;</description></item></channel></rss>