<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#24212;&#29992;&#30340;&#26032;&#30340;&#20381;&#20174;PID&#25511;&#21046;&#31639;&#27861;&#65292;&#33021;&#22815;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#24182;&#36866;&#24212;&#19981;&#21516;&#30340;&#31995;&#32479;&#35823;&#24046;&#65292;&#24182;&#22312;COVID-19&#27515;&#20129;&#20154;&#25968;&#12289;&#30005;&#21147;&#38656;&#27714;&#21644;&#24066;&#22330;&#22238;&#25253;&#31561;&#26041;&#38754;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.16895</link><description>&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#20381;&#20174;PID&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Conformal PID Control for Time Series Prediction. (arXiv:2307.16895v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16895
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#24212;&#29992;&#30340;&#26032;&#30340;&#20381;&#20174;PID&#25511;&#21046;&#31639;&#27861;&#65292;&#33021;&#22815;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#24182;&#36866;&#24212;&#19981;&#21516;&#30340;&#31995;&#32479;&#35823;&#24046;&#65292;&#24182;&#22312;COVID-19&#27515;&#20129;&#20154;&#25968;&#12289;&#30005;&#21147;&#38656;&#27714;&#21644;&#24066;&#22330;&#22238;&#25253;&#31561;&#26041;&#38754;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#38382;&#39064;&#65292;&#30446;&#26631;&#26159;&#25552;&#20379;&#26131;&#20110;&#20351;&#29992;&#30340;&#31639;&#27861;&#24182;&#20855;&#22791;&#24418;&#24335;&#20445;&#35777;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#22522;&#20110;&#20381;&#20174;&#39044;&#27979;&#21644;&#25511;&#21046;&#29702;&#35770;&#30340;&#24605;&#24819;&#65292;&#33021;&#22815;&#22312;&#22312;&#32447;&#29615;&#22659;&#20013;&#21069;&#30651;&#24615;&#22320;&#24314;&#27169;&#20381;&#20174;&#24471;&#20998;&#65292;&#24182;&#36866;&#24212;&#30001;&#20110;&#23395;&#33410;&#24615;&#12289;&#36235;&#21183;&#21644;&#24635;&#20307;&#20998;&#24067;&#21464;&#21270;&#32780;&#23548;&#33268;&#30340;&#31995;&#32479;&#35823;&#24046;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#31616;&#21270;&#24182;&#21152;&#24378;&#20102;&#22312;&#32447;&#20381;&#20174;&#39044;&#27979;&#20013;&#30340;&#29616;&#26377;&#20998;&#26512;&#12290;&#22312;&#32654;&#22269;&#24030;&#32423;COVID-19&#27515;&#20129;&#20154;&#25968;&#30340;4&#21608;&#39044;&#27979;&#23454;&#39564;&#20013;&#65292;&#19982;&#23448;&#26041;CDC&#36890;&#20449;&#20013;&#20351;&#29992;&#30340;&#38598;&#25104;&#39044;&#27979;&#22120;&#30456;&#27604;&#65292;&#24471;&#21040;&#20102;&#26356;&#22909;&#30340;&#35206;&#30422;&#29575;&#12290;&#25105;&#20204;&#36824;&#23545;&#20351;&#29992;&#33258;&#22238;&#24402;&#12289;Theta&#12289;Prophet&#21644;Transformer&#27169;&#22411;&#36827;&#34892;&#30005;&#21147;&#38656;&#27714;&#12289;&#24066;&#22330;&#22238;&#25253;&#21644;&#28201;&#24230;&#39044;&#27979;&#30340;&#23454;&#39564;&#36827;&#34892;&#20102;&#36816;&#34892;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#20195;&#30721;&#24211;&#65292;&#29992;&#20110;&#27979;&#35797;&#25105;&#20204;&#30340;&#26041;&#27861;&#24182;&#38598;&#25104;&#26032;&#30340;&#31639;&#27861;&#12289;&#25968;&#25454;&#38598;&#21644;&#39044;&#27979;&#35268;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of uncertainty quantification for time series prediction, with the goal of providing easy-to-use algorithms with formal guarantees. The algorithms we present build upon ideas from conformal prediction and control theory, are able to prospectively model conformal scores in an online setting, and adapt to the presence of systematic errors due to seasonality, trends, and general distribution shifts. Our theory both simplifies and strengthens existing analyses in online conformal prediction. Experiments on 4-week-ahead forecasting of statewide COVID-19 death counts in the U.S. show an improvement in coverage over the ensemble forecaster used in official CDC communications. We also run experiments on predicting electricity demand, market returns, and temperature using autoregressive, Theta, Prophet, and Transformer models. We provide an extendable codebase for testing our methods and for the integration of new algorithms, data sets, and forecasting rules.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;oracle&#22411;&#19981;&#31561;&#24335;&#65292;&#36890;&#36807;&#35299;&#20915;&#36923;&#36753;&#25439;&#22833;&#30340;&#30446;&#26631;&#20989;&#25968;&#26080;&#30028;&#24615;&#38480;&#21046;&#65292;&#25512;&#23548;&#20986;&#20351;&#29992;&#36923;&#36753;&#25439;&#22833;&#35757;&#32451;&#30340;&#20840;&#36830;&#25509;ReLU&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#20165;&#35201;&#27714;&#25968;&#25454;&#30340;&#26465;&#20214;&#31867;&#27010;&#29575;&#20855;&#26377;H\"older&#24179;&#28369;&#24615;&#65292;&#24182;&#19988;&#32771;&#34385;&#20102;&#32452;&#21512;&#20551;&#35774;&#65292;&#20351;&#24471;&#35813;&#26041;&#27861;&#20855;&#26377;&#26356;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.16792</link><description>&lt;p&gt;
&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#36923;&#36753;&#25439;&#22833;&#36827;&#34892;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Classification with Deep Neural Networks and Logistic Loss. (arXiv:2307.16792v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16792
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;oracle&#22411;&#19981;&#31561;&#24335;&#65292;&#36890;&#36807;&#35299;&#20915;&#36923;&#36753;&#25439;&#22833;&#30340;&#30446;&#26631;&#20989;&#25968;&#26080;&#30028;&#24615;&#38480;&#21046;&#65292;&#25512;&#23548;&#20986;&#20351;&#29992;&#36923;&#36753;&#25439;&#22833;&#35757;&#32451;&#30340;&#20840;&#36830;&#25509;ReLU&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#20165;&#35201;&#27714;&#25968;&#25454;&#30340;&#26465;&#20214;&#31867;&#27010;&#29575;&#20855;&#26377;H\"older&#24179;&#28369;&#24615;&#65292;&#24182;&#19988;&#32771;&#34385;&#20102;&#32452;&#21512;&#20551;&#35774;&#65292;&#20351;&#24471;&#35813;&#26041;&#27861;&#20855;&#26377;&#26356;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#36923;&#36753;&#25439;&#22833;&#65288;&#21363;&#20132;&#21449;&#29109;&#25439;&#22833;&#65289;&#35757;&#32451;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#21508;&#31181;&#20108;&#20998;&#31867;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#36923;&#36753;&#25439;&#22833;&#36827;&#34892;&#20108;&#20998;&#31867;&#30340;&#27867;&#21270;&#20998;&#26512;&#20173;&#28982;&#24456;&#23569;&#12290;&#36923;&#36753;&#25439;&#22833;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;&#26080;&#30028;&#24615;&#26159;&#23548;&#33268;&#25512;&#23548;&#20986;&#20196;&#20154;&#28385;&#24847;&#30340;&#27867;&#21270;&#30028;&#38480;&#30340;&#20027;&#35201;&#38556;&#30861;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#24314;&#31435;&#19968;&#31181;&#26032;&#39062;&#32780;&#20248;&#38597;&#30340;oracle&#22411;&#19981;&#31561;&#24335;&#26469;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#35813;&#19981;&#31561;&#24335;&#20351;&#25105;&#20204;&#33021;&#22815;&#22788;&#29702;&#30446;&#26631;&#20989;&#25968;&#30340;&#26377;&#30028;&#24615;&#38480;&#21046;&#65292;&#24182;&#21033;&#29992;&#23427;&#25512;&#23548;&#20986;&#20351;&#29992;&#36923;&#36753;&#25439;&#22833;&#35757;&#32451;&#30340;&#20840;&#36830;&#25509;ReLU&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#20165;&#38656;&#35201;&#25968;&#25454;&#30340;&#26465;&#20214;&#31867;&#27010;&#29575;$\eta$&#30340;H\"older&#24179;&#28369;&#24615;&#65292;&#23601;&#21487;&#20197;&#33719;&#24471;&#26368;&#20248;&#30340;&#25910;&#25947;&#36895;&#29575;&#65288;&#20165;&#38480;&#20110;&#23545;&#25968;&#22240;&#23376;&#65289;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#32452;&#21512;&#20551;&#35774;&#65292;&#35201;&#27714;$\eta$&#26159;&#33509;&#24178;&#21521;&#37327;&#20540;&#20989;&#25968;&#30340;&#22797;&#21512;&#20989;&#25968;&#65292;&#20854;&#20013;&#27599;&#20010;&#21521;&#37327;&#20540;&#20989;&#25968;&#37117;&#26159;&#29420;&#31435;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks (DNNs) trained with the logistic loss (i.e., the cross entropy loss) have made impressive advancements in various binary classification tasks. However, generalization analysis for binary classification with DNNs and logistic loss remains scarce. The unboundedness of the target function for the logistic loss is the main obstacle to deriving satisfying generalization bounds. In this paper, we aim to fill this gap by establishing a novel and elegant oracle-type inequality, which enables us to deal with the boundedness restriction of the target function, and using it to derive sharp convergence rates for fully connected ReLU DNN classifiers trained with logistic loss. In particular, we obtain optimal convergence rates (up to log factors) only requiring the H\"older smoothness of the conditional class probability $\eta$ of data. Moreover, we consider a compositional assumption that requires $\eta$ to be the composition of several vector-valued functions of which each co
&lt;/p&gt;</description></item><item><title>&#22312;&#32479;&#35745;&#25512;&#26029;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26080;&#25439;&#36716;&#25442;&#21644;&#36807;&#37327;&#39118;&#38505;&#30340;&#27010;&#24565;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#26080;&#25439;&#36716;&#25442;&#30340;&#29305;&#24449;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#29992;&#20110;&#21028;&#26029;&#32473;&#23450;&#36716;&#25442;&#26159;&#21542;&#26159;&#26080;&#25439;&#30340;&#32479;&#35745;&#37327;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;delta-&#26080;&#25439;&#36716;&#25442;&#30340;&#27010;&#24565;&#65292;&#24182;&#32473;&#20986;&#20102;&#20805;&#20998;&#26465;&#20214;&#12290;&#36825;&#20123;&#30740;&#31350;&#22312;&#20998;&#31867;&#12289;&#38750;&#21442;&#25968;&#22238;&#24402;&#21644;&#25237;&#36164;&#32452;&#21512;&#31574;&#30053;&#31561;&#39046;&#22495;&#20855;&#26377;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2307.16735</link><description>&lt;p&gt;
&#26080;&#25439;&#36716;&#25442;&#21644;&#32479;&#35745;&#25512;&#26029;&#20013;&#30340;&#36807;&#37327;&#39118;&#38505;&#30028;&#38480;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Lossless Transformations and Excess Risk Bounds in Statistical Inference. (arXiv:2307.16735v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16735
&lt;/p&gt;
&lt;p&gt;
&#22312;&#32479;&#35745;&#25512;&#26029;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26080;&#25439;&#36716;&#25442;&#21644;&#36807;&#37327;&#39118;&#38505;&#30340;&#27010;&#24565;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#26080;&#25439;&#36716;&#25442;&#30340;&#29305;&#24449;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#29992;&#20110;&#21028;&#26029;&#32473;&#23450;&#36716;&#25442;&#26159;&#21542;&#26159;&#26080;&#25439;&#30340;&#32479;&#35745;&#37327;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;delta-&#26080;&#25439;&#36716;&#25442;&#30340;&#27010;&#24565;&#65292;&#24182;&#32473;&#20986;&#20102;&#20805;&#20998;&#26465;&#20214;&#12290;&#36825;&#20123;&#30740;&#31350;&#22312;&#20998;&#31867;&#12289;&#38750;&#21442;&#25968;&#22238;&#24402;&#21644;&#25237;&#36164;&#32452;&#21512;&#31574;&#30053;&#31561;&#39046;&#22495;&#20855;&#26377;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#32479;&#35745;&#25512;&#26029;&#20013;&#30340;&#36807;&#37327;&#26368;&#23567;&#39118;&#38505;&#65292;&#23450;&#20041;&#20026;&#20174;&#35266;&#27979;&#21040;&#30340;&#29305;&#24449;&#21521;&#37327;&#20013;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;&#30340;&#26368;&#23567;&#26399;&#26395;&#25439;&#22833;&#19982;&#20174;&#29305;&#24449;&#21521;&#37327;&#30340;&#36716;&#25442;&#65288;&#32479;&#35745;&#37327;&#65289;&#20013;&#20272;&#35745;&#30456;&#21516;&#38543;&#26426;&#21464;&#37327;&#30340;&#26368;&#23567;&#26399;&#26395;&#25439;&#22833;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#22312;&#25551;&#36848;&#20102;&#26080;&#25439;&#36716;&#25442;&#65288;&#21363;&#23545;&#20110;&#25152;&#26377;&#25439;&#22833;&#20989;&#25968;&#65292;&#36807;&#37327;&#39118;&#38505;&#20026;&#38646;&#30340;&#36716;&#25442;&#65289;&#20043;&#21518;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#23545;&#20551;&#35774;&#36827;&#34892;&#20998;&#21306;&#26816;&#39564;&#30340;&#32479;&#35745;&#37327;&#65292;&#29992;&#20110;&#21028;&#26029;&#32473;&#23450;&#36716;&#25442;&#26159;&#21542;&#20026;&#26080;&#25439;&#36716;&#25442;&#65292;&#24182;&#35777;&#26126;&#23545;&#20110;i.i.d.&#25968;&#25454;&#65292;&#35813;&#26816;&#39564;&#26159;&#24378;&#19968;&#33268;&#30340;&#12290;&#26356;&#19968;&#33324;&#22320;&#65292;&#25105;&#20204;&#26681;&#25454;&#20449;&#24687;&#29702;&#35770;&#32473;&#20986;&#20102;&#36807;&#37327;&#39118;&#38505;&#30340;&#19978;&#30028;&#65292;&#35813;&#19978;&#30028;&#22312;&#30456;&#24403;&#19968;&#33324;&#30340;&#25439;&#22833;&#20989;&#25968;&#31867;&#19978;&#37117;&#26159;&#19968;&#33268;&#30340;&#12290;&#22522;&#20110;&#36825;&#20123;&#30028;&#38480;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#8220;delta-&#26080;&#25439;&#36716;&#25442;&#8221;&#30340;&#27010;&#24565;&#65292;&#24182;&#32473;&#20986;&#20102;&#32473;&#23450;&#36716;&#25442;&#26222;&#36941;&#26159;delta-&#26080;&#25439;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#35813;&#30740;&#31350;&#22312;&#20998;&#31867;&#12289;&#38750;&#21442;&#25968;&#22238;&#24402;&#12289;&#25237;&#36164;&#32452;&#21512;&#31574;&#30053;&#31561;&#26041;&#38754;&#20855;&#26377;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the excess minimum risk in statistical inference, defined as the difference between the minimum expected loss in estimating a random variable from an observed feature vector and the minimum expected loss in estimating the same random variable from a transformation (statistic) of the feature vector. After characterizing lossless transformations, i.e., transformations for which the excess risk is zero for all loss functions, we construct a partitioning test statistic for the hypothesis that a given transformation is lossless and show that for i.i.d. data the test is strongly consistent. More generally, we develop information-theoretic upper bounds on the excess risk that uniformly hold over fairly general classes of loss functions. Based on these bounds, we introduce the notion of a delta-lossless transformation and give sufficient conditions for a given transformation to be universally delta-lossless. Applications to classification, nonparametric regression, portfolio strategie
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#22312;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#20013;&#35745;&#31639;Shapley&#20540;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#19982;Weight of Evidence&#21644;KernelShap&#36827;&#34892;&#20102;&#23454;&#35777;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2307.16718</link><description>&lt;p&gt;
&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#39640;&#25928;Shapley Value&#35745;&#31639;
&lt;/p&gt;
&lt;p&gt;
An Efficient Shapley Value Computation for the Naive Bayes Classifier. (arXiv:2307.16718v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16718
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#22312;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#20013;&#35745;&#31639;Shapley&#20540;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#19982;Weight of Evidence&#21644;KernelShap&#36827;&#34892;&#20102;&#23454;&#35777;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#37327;&#36873;&#25321;&#25110;&#36755;&#20837;&#21464;&#37327;&#30340;&#37325;&#35201;&#24615;&#27979;&#37327;&#24050;&#32463;&#25104;&#20026;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30740;&#31350;&#30340;&#37325;&#28857;&#12290;&#25317;&#26377;&#19968;&#20010;&#22909;&#30340;&#27169;&#22411;&#24050;&#32463;&#19981;&#36275;&#22815;&#65292;&#36824;&#24517;&#39035;&#35299;&#37322;&#20854;&#20915;&#31574;&#12290;&#36825;&#23601;&#26159;&#20026;&#20160;&#20040;&#29616;&#22312;&#26377;&#24456;&#22810;&#21487;&#35299;&#37322;&#24615;&#31639;&#27861;&#12290;&#20854;&#20013;&#65292;Shapley&#20540;&#20272;&#35745;&#31639;&#27861;&#26159;&#19968;&#31181;&#22522;&#20110;&#21512;&#20316;&#21338;&#24328;&#29702;&#35770;&#30340;&#21487;&#35299;&#37322;&#24615;&#26041;&#27861;&#12290;&#22312;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#24773;&#20917;&#19979;&#65292;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#27809;&#26377;&#20851;&#20110;Shapley&#20540;&#30340;&#8220;&#20998;&#26512;&#24615;&#8221;&#20844;&#24335;&#12290;&#26412;&#25991;&#22312;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#29305;&#27530;&#24773;&#20917;&#19979;&#25552;&#20986;&#20102;Shapley&#20540;&#30340;&#31934;&#30830;&#20998;&#26512;&#34920;&#36798;&#24335;&#12290;&#25105;&#20204;&#23545;&#27604;&#20102;&#36825;&#20010;Shapley&#25552;&#35758;&#19982;&#21478;&#19968;&#20010;&#24120;&#29992;&#30340;&#25351;&#26631;&#65292;&#35777;&#25454;&#26435;&#37325;&#65288;Weight of Evidence&#65292;WoE&#65289;&#65292;&#24182;&#22312;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#23545;&#25105;&#20204;&#30340;&#25552;&#35758;&#19982;WoE&#20197;&#21450;KernelShap&#30340;&#32467;&#26524;&#36827;&#34892;&#20102;&#23454;&#35777;&#27604;&#36739;&#65292;&#35752;&#35770;&#20102;&#30456;&#20284;&#21644;&#19981;&#30456;&#20284;&#30340;&#32467;&#26524;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#23545;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;Shapley&#25552;&#35758;&#25552;&#20379;&#20102;
&lt;/p&gt;
&lt;p&gt;
Variable selection or importance measurement of input variables to a machine learning model has become the focus of much research. It is no longer enough to have a good model, one also must explain its decisions. This is why there are so many intelligibility algorithms available today. Among them, Shapley value estimation algorithms are intelligibility methods based on cooperative game theory. In the case of the naive Bayes classifier, and to our knowledge, there is no ``analytical" formulation of Shapley values. This article proposes an exact analytic expression of Shapley values in the special case of the naive Bayes Classifier. We analytically compare this Shapley proposal, to another frequently used indicator, the Weight of Evidence (WoE) and provide an empirical comparison of our proposal with (i) the WoE and (ii) KernelShap results on real world datasets, discussing similar and dissimilar results. The results show that our Shapley proposal for the naive Bayes classifier provides 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#27867;&#21270;&#24615;&#30340;&#22330;&#35770;&#24418;&#24335;&#20307;&#31995;&#65292;&#29992;&#20110;&#30740;&#31350;&#31070;&#32463;&#32593;&#32476;&#22312;&#26080;&#38480;&#23485;&#38544;&#34255;&#23618;&#30340;&#26497;&#38480;&#24773;&#20917;&#65292;&#24182;&#36890;&#36807;&#35745;&#31639;&#38750;&#32447;&#24615;&#21644;&#28145;&#24230;&#38750;&#32447;&#24615;&#32593;&#32476;&#30340;&#27867;&#21270;&#29305;&#24615;&#65292;&#38416;&#26126;&#20102;&#25968;&#25454;&#30340;&#21464;&#24322;&#24615;&#23545;&#32593;&#32476;&#34892;&#20026;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2307.16695</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#36125;&#21494;&#26031;&#25512;&#29702;&#20013;&#30340;&#25968;&#25454;&#21464;&#24322;&#24615;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
A theory of data variability in Neural Network Bayesian inference. (arXiv:2307.16695v1 [cond-mat.dis-nn])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16695
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#27867;&#21270;&#24615;&#30340;&#22330;&#35770;&#24418;&#24335;&#20307;&#31995;&#65292;&#29992;&#20110;&#30740;&#31350;&#31070;&#32463;&#32593;&#32476;&#22312;&#26080;&#38480;&#23485;&#38544;&#34255;&#23618;&#30340;&#26497;&#38480;&#24773;&#20917;&#65292;&#24182;&#36890;&#36807;&#35745;&#31639;&#38750;&#32447;&#24615;&#21644;&#28145;&#24230;&#38750;&#32447;&#24615;&#32593;&#32476;&#30340;&#27867;&#21270;&#29305;&#24615;&#65292;&#38416;&#26126;&#20102;&#25968;&#25454;&#30340;&#21464;&#24322;&#24615;&#23545;&#32593;&#32476;&#34892;&#20026;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#25512;&#29702;&#21644;&#26680;&#26041;&#27861;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#24050;&#32463;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#24212;&#29992;&#12290;&#29305;&#21035;&#26159;&#31070;&#32463;&#32593;&#32476;&#39640;&#26031;&#36807;&#31243;&#36890;&#36807;&#20351;&#29992;&#26680;&#21644;&#25512;&#29702;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#30740;&#31350;&#31070;&#32463;&#32593;&#32476;&#22312;&#26080;&#38480;&#23485;&#38544;&#34255;&#23618;&#30340;&#26497;&#38480;&#24773;&#20917;&#30340;&#27010;&#24565;&#12290;&#26412;&#25991;&#22312;&#36825;&#20010;&#26497;&#38480;&#30340;&#22522;&#30784;&#19978;&#24314;&#31435;&#20102;&#19968;&#20010;&#22330;&#35770;&#24418;&#24335;&#20307;&#31995;&#65292;&#28085;&#30422;&#20102;&#26080;&#38480;&#23485;&#32593;&#32476;&#30340;&#27867;&#21270;&#29305;&#24615;&#12290;&#25105;&#20204;&#31995;&#32479;&#22320;&#35745;&#31639;&#20102;&#20855;&#26377;&#24322;&#36136;&#26465;&#30446;&#30340;&#26680;&#30697;&#38453;&#30340;&#32447;&#24615;&#12289;&#38750;&#32447;&#24615;&#21644;&#28145;&#24230;&#38750;&#32447;&#24615;&#32593;&#32476;&#30340;&#27867;&#21270;&#29305;&#24615;&#12290;&#19982;&#30446;&#21069;&#20351;&#29992;&#30340;&#35889;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#36890;&#36807;&#20174;&#36755;&#20837;&#25968;&#25454;&#30340;&#32479;&#35745;&#29305;&#24615;&#25512;&#23548;&#20986;&#27867;&#21270;&#29305;&#24615;&#65292;&#38416;&#26126;&#20102;&#36755;&#20837;&#32500;&#24230;&#12289;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#20197;&#21450;&#25968;&#25454;&#30340;&#21464;&#24322;&#24615;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#25105;&#20204;&#34920;&#26126;&#25968;&#25454;&#30340;&#21464;&#24322;&#24615;&#23548;&#33268;&#20102;&#19968;&#31181;&#38750;&#39640;&#26031;&#20316;&#29992;&#65292;&#31867;&#20284;&#20110;($\varphi^3+\varphi^4$)-&#29702;&#35770;&#12290;&#22312;&#19968;&#20010;&#21512;&#25104;&#20219;&#21153;&#21644;MNIST&#19978;&#20351;&#29992;&#25105;&#20204;&#30340;&#24418;&#24335;&#20307;&#31995;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20010;&#22343;&#21248;&#30340;&#26680;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian inference and kernel methods are well established in machine learning. The neural network Gaussian process in particular provides a concept to investigate neural networks in the limit of infinitely wide hidden layers by using kernel and inference methods. Here we build upon this limit and provide a field-theoretic formalism which covers the generalization properties of infinitely wide networks. We systematically compute generalization properties of linear, non-linear, and deep non-linear networks for kernel matrices with heterogeneous entries. In contrast to currently employed spectral methods we derive the generalization properties from the statistical properties of the input, elucidating the interplay of input dimensionality, size of the training data set, and variability of the data. We show that data variability leads to a non-Gaussian action reminiscent of a ($\varphi^3+\varphi^4$)-theory. Using our formalism on a synthetic task and on MNIST we obtain a homogeneous kernel
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35774;&#35745;&#20102;&#36830;&#32493;&#21644;&#20849;&#20139;&#20869;&#23384;&#24182;&#34892;&#31639;&#27861;&#29992;&#20110;&#20998;&#21106;&#23616;&#37096;&#28145;&#24230;&#65292;&#24182;&#24341;&#20837;&#20102;&#24615;&#33021;&#20248;&#21270;&#31574;&#30053;&#65292;&#23454;&#29616;&#20102;&#36739;&#39640;&#30340;&#21152;&#36895;&#12290;&#36890;&#36807;&#19977;&#20803;&#32452;&#27604;&#36739;&#20004;&#20004;&#36317;&#31163;&#65292;&#23454;&#29616;&#20102;&#23545;&#31264;&#23494;&#21644;&#31232;&#30095;&#31038;&#21306;&#20869;&#24378;&#20851;&#31995;&#30340;&#35782;&#21035;&#12290;</title><link>http://arxiv.org/abs/2307.16652</link><description>&lt;p&gt;
&#38024;&#23545;&#20998;&#21106;&#23616;&#37096;&#28145;&#24230;&#30340;&#36830;&#32493;&#21644;&#20849;&#20139;&#20869;&#23384;&#24182;&#34892;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sequential and Shared-Memory Parallel Algorithms for Partitioned Local Depths. (arXiv:2307.16652v1 [cs.DC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16652
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35774;&#35745;&#20102;&#36830;&#32493;&#21644;&#20849;&#20139;&#20869;&#23384;&#24182;&#34892;&#31639;&#27861;&#29992;&#20110;&#20998;&#21106;&#23616;&#37096;&#28145;&#24230;&#65292;&#24182;&#24341;&#20837;&#20102;&#24615;&#33021;&#20248;&#21270;&#31574;&#30053;&#65292;&#23454;&#29616;&#20102;&#36739;&#39640;&#30340;&#21152;&#36895;&#12290;&#36890;&#36807;&#19977;&#20803;&#32452;&#27604;&#36739;&#20004;&#20004;&#36317;&#31163;&#65292;&#23454;&#29616;&#20102;&#23545;&#31264;&#23494;&#21644;&#31232;&#30095;&#31038;&#21306;&#20869;&#24378;&#20851;&#31995;&#30340;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#12289;&#20998;&#26512;&#21644;&#20248;&#21270;&#20102;&#20998;&#21106;&#23616;&#37096;&#28145;&#24230;&#65288;PaLD&#65289;&#30340;&#36830;&#32493;&#21644;&#20849;&#20139;&#20869;&#23384;&#24182;&#34892;&#31639;&#27861;&#12290;&#32473;&#23450;&#19968;&#32452;&#25968;&#25454;&#28857;&#21644;&#20004;&#20004;&#36317;&#31163;&#65292;PaLD&#26159;&#19968;&#31181;&#22522;&#20110;&#30456;&#23545;&#36317;&#31163;&#35782;&#21035;&#20004;&#20004;&#20851;&#31995;&#24378;&#24230;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#31264;&#23494;&#21644;&#31232;&#30095;&#31038;&#21306;&#20869;&#35782;&#21035;&#24378;&#20851;&#31995;&#65292;&#21363;&#20351;&#23427;&#20204;&#30340;&#22823;&#23567;&#21644;&#31038;&#21306;&#20869;&#37096;&#32477;&#23545;&#36317;&#31163;&#24046;&#21035;&#24456;&#22823;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#31181;&#31639;&#27861;&#21464;&#20307;&#65292;&#36890;&#36807;&#19977;&#20803;&#32452;&#27604;&#36739;&#20004;&#20004;&#36317;&#31163;&#36827;&#34892;&#31038;&#21306;&#32467;&#26500;&#20998;&#26512;&#12290;&#25105;&#20204;&#23545;&#35745;&#31639;&#21644;&#36890;&#20449;&#25104;&#26412;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#24182;&#35777;&#26126;&#20102;&#36830;&#32493;&#31639;&#27861;&#22312;&#36890;&#20449;&#26041;&#38754;&#26159;&#26368;&#20248;&#30340;&#65292;&#26368;&#22810;&#21482;&#26377;&#24120;&#25968;&#22240;&#23376;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#24615;&#33021;&#20248;&#21270;&#31574;&#30053;&#65292;&#22312;&#22522;&#20934;&#36830;&#32493;&#23454;&#29616;&#19978;&#23454;&#29616;&#20102;&#39640;&#36798;29&#20493;&#30340;&#36830;&#32493;&#21152;&#36895;&#21644;&#22312;&#22810;&#26680;Intel&#19978;&#20351;&#29992;&#39640;&#36798;32&#20010;&#32447;&#31243;&#30340;&#20248;&#21270;&#36830;&#32493;&#23454;&#29616;&#19978;&#23454;&#29616;&#20102;&#39640;&#36798;19.4&#20493;&#30340;&#24182;&#34892;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we design, analyze, and optimize sequential and shared-memory parallel algorithms for partitioned local depths (PaLD). Given a set of data points and pairwise distances, PaLD is a method for identifying strength of pairwise relationships based on relative distances, enabling the identification of strong ties within dense and sparse communities even if their sizes and within-community absolute distances vary greatly. We design two algorithmic variants that perform community structure analysis through triplet comparisons of pairwise distances. We present theoretical analyses of computation and communication costs and prove that the sequential algorithms are communication optimal, up to constant factors. We introduce performance optimization strategies that yield sequential speedups of up to $29\times$ over a baseline sequential implementation and parallel speedups of up to $19.4\times$ over optimized sequential implementations using up to $32$ threads on an Intel multicore 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#32771;&#34385;&#20854;&#20182;&#26234;&#33021;&#20307;&#25110;&#22806;&#37096;&#20107;&#20214;&#23545;&#31995;&#32479;&#30340;&#24178;&#39044;&#65292;&#20351;&#20854;&#33021;&#22815;&#36866;&#24212;&#38750;&#24179;&#31283;&#24615;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#20855;&#26377;&#26377;&#30028;&#36951;&#25022;&#30340;&#23545;&#25239;&#24615;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;CBO-MW&#12290;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#22312;&#32447;&#23398;&#20064;&#31574;&#30053;&#21644;&#22240;&#26524;&#24314;&#27169;&#65292;&#36890;&#36807;&#22240;&#26524;&#22270;&#20256;&#25773;&#19981;&#30830;&#23450;&#24615;&#26469;&#35745;&#31639;&#20048;&#35266;&#30340;&#21453;&#20107;&#23454;&#22870;&#21169;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2307.16625</link><description>&lt;p&gt;
&#22522;&#20110;&#27169;&#22411;&#30340;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Model-based Causal Bayesian Optimization. (arXiv:2307.16625v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16625
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#32771;&#34385;&#20854;&#20182;&#26234;&#33021;&#20307;&#25110;&#22806;&#37096;&#20107;&#20214;&#23545;&#31995;&#32479;&#30340;&#24178;&#39044;&#65292;&#20351;&#20854;&#33021;&#22815;&#36866;&#24212;&#38750;&#24179;&#31283;&#24615;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#20855;&#26377;&#26377;&#30028;&#36951;&#25022;&#30340;&#23545;&#25239;&#24615;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;CBO-MW&#12290;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#22312;&#32447;&#23398;&#20064;&#31574;&#30053;&#21644;&#22240;&#26524;&#24314;&#27169;&#65292;&#36890;&#36807;&#22240;&#26524;&#22270;&#20256;&#25773;&#19981;&#30830;&#23450;&#24615;&#26469;&#35745;&#31639;&#20048;&#35266;&#30340;&#21453;&#20107;&#23454;&#22870;&#21169;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#65292;&#19968;&#20010;&#26234;&#33021;&#20307;&#23545;&#26410;&#30693;&#30340;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#36827;&#34892;&#24178;&#39044;&#65292;&#20197;&#26368;&#22823;&#21270;&#19979;&#28216;&#30340;&#22870;&#21169;&#21464;&#37327;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#20854;&#20182;&#26234;&#33021;&#20307;&#25110;&#22806;&#37096;&#20107;&#20214;&#20063;&#23545;&#31995;&#32479;&#36827;&#34892;&#24178;&#39044;&#30340;&#24773;&#20917;&#65292;&#36825;&#23545;&#20110;&#36866;&#24212;&#38750;&#24179;&#31283;&#24615;&#65292;&#22914;&#22825;&#27668;&#21464;&#21270;&#12289;&#24066;&#22330;&#21147;&#37327;&#25110;&#23545;&#25163;&#30340;&#21464;&#21270;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#27867;&#21270;&#24418;&#24335;&#31216;&#20026;&#23545;&#25239;&#24615;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#24182;&#24341;&#20837;&#20102;&#31532;&#19968;&#20010;&#20855;&#26377;&#26377;&#30028;&#36951;&#25022;&#30340;&#23545;&#25239;&#24615;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#65306;&#22522;&#20110;&#20056;&#27861;&#26435;&#37325;&#30340;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;CBO-MW&#65289;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#32463;&#20856;&#30340;&#22312;&#32447;&#23398;&#20064;&#31574;&#30053;&#19982;&#22870;&#21169;&#30340;&#22240;&#26524;&#24314;&#27169;&#30456;&#32467;&#21512;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#23427;&#36890;&#36807;&#22240;&#26524;&#22270;&#20256;&#25773;&#19981;&#30830;&#23450;&#24615;&#26469;&#35745;&#31639;&#20048;&#35266;&#30340;&#21453;&#20107;&#23454;&#22870;&#21169;&#20272;&#35745;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;CBO-MW&#30340;&#36951;&#25022;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#33258;&#28982;&#22320;&#21462;&#20915;&#20110;&#19982;&#22270;&#30456;&#20851;&#30340;&#37327;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#23454;&#29616;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#32452;&#21512;&#24178;&#39044;&#21644;&#23376;&#27169;&#22359;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
In Causal Bayesian Optimization (CBO), an agent intervenes on an unknown structural causal model to maximize a downstream reward variable. In this paper, we consider the generalization where other agents or external events also intervene on the system, which is key for enabling adaptiveness to non-stationarities such as weather changes, market forces, or adversaries. We formalize this generalization of CBO as Adversarial Causal Bayesian Optimization (ACBO) and introduce the first algorithm for ACBO with bounded regret: Causal Bayesian Optimization with Multiplicative Weights (CBO-MW). Our approach combines a classical online learning strategy with causal modeling of the rewards. To achieve this, it computes optimistic counterfactual reward estimates by propagating uncertainty through the causal graph. We derive regret bounds for CBO-MW that naturally depend on graph-related quantities. We further propose a scalable implementation for the case of combinatorial interventions and submodul
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#23545;&#22810;&#35821;&#35328;&#25919;&#20826;&#32434;&#39046;&#36827;&#34892;&#20998;&#31867;&#30340;&#39046;&#22495;&#36716;&#31227;&#65292;&#22312;&#22823;&#35268;&#27169;&#25919;&#27835;&#32434;&#39046;&#25968;&#25454;&#24211;&#20013;&#23637;&#31034;&#20102;&#24494;&#35843;Transformer&#27169;&#22411;&#22312;&#21516;&#19968;&#39046;&#22495;&#20869;&#30340;&#24378;&#22823;&#24615;&#33021;&#65292;&#24182;&#27979;&#35797;&#20102;&#20854;&#22312;&#19981;&#21516;&#22320;&#29702;&#20301;&#32622;&#12289;&#35821;&#35328;&#12289;&#26102;&#38388;&#21644;&#20307;&#35009;&#20043;&#38388;&#30340;&#31283;&#20581;&#24615;&#21644;&#21487;&#36716;&#31227;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.16511</link><description>&lt;p&gt;
&#23545;&#22810;&#35821;&#35328;&#25919;&#20826;&#32434;&#39046;&#36827;&#34892;&#20998;&#31867;: &#36328;&#22269;&#23478;&#12289;&#26102;&#38388;&#21644;&#20307;&#35009;&#30340;&#39046;&#22495;&#36716;&#31227;
&lt;/p&gt;
&lt;p&gt;
Classifying multilingual party manifestos: Domain transfer across country, time, and genre. (arXiv:2307.16511v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16511
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#23545;&#22810;&#35821;&#35328;&#25919;&#20826;&#32434;&#39046;&#36827;&#34892;&#20998;&#31867;&#30340;&#39046;&#22495;&#36716;&#31227;&#65292;&#22312;&#22823;&#35268;&#27169;&#25919;&#27835;&#32434;&#39046;&#25968;&#25454;&#24211;&#20013;&#23637;&#31034;&#20102;&#24494;&#35843;Transformer&#27169;&#22411;&#22312;&#21516;&#19968;&#39046;&#22495;&#20869;&#30340;&#24378;&#22823;&#24615;&#33021;&#65292;&#24182;&#27979;&#35797;&#20102;&#20854;&#22312;&#19981;&#21516;&#22320;&#29702;&#20301;&#32622;&#12289;&#35821;&#35328;&#12289;&#26102;&#38388;&#21644;&#20307;&#35009;&#20043;&#38388;&#30340;&#31283;&#20581;&#24615;&#21644;&#21487;&#36716;&#31227;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#35777;&#31038;&#20250;&#31185;&#23398;&#30740;&#31350;&#20013;&#65292;&#26631;&#27880;&#22823;&#22411;&#35821;&#26009;&#24211;&#30340;&#25104;&#26412;&#20173;&#28982;&#26159;&#20027;&#35201;&#30340;&#29942;&#39048;&#20043;&#19968;&#12290;&#19968;&#26041;&#38754;&#65292;&#21033;&#29992;&#39046;&#22495;&#36716;&#31227;&#30340;&#33021;&#21147;&#21487;&#20197;&#37325;&#22797;&#20351;&#29992;&#26631;&#27880;&#25968;&#25454;&#38598;&#21644;&#35757;&#32451;&#27169;&#22411;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#39046;&#22495;&#36716;&#31227;&#30340;&#25928;&#26524;&#22914;&#20309;&#20197;&#21450;&#22312;&#19981;&#21516;&#32500;&#24230;&#20043;&#38388;&#30340;&#36716;&#31227;&#32467;&#26524;&#30340;&#21487;&#38752;&#24615;&#36824;&#19981;&#28165;&#26970;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#22823;&#22411;&#25919;&#27835;&#32434;&#39046;&#25968;&#25454;&#24211;&#20013;&#25506;&#32034;&#20102;&#22320;&#29702;&#20301;&#32622;&#12289;&#35821;&#35328;&#12289;&#26102;&#38388;&#21644;&#20307;&#35009;&#31561;&#39046;&#22495;&#36716;&#31227;&#30340;&#28508;&#21147;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#32463;&#36807;&#24494;&#35843;&#30340;Transformer&#27169;&#22411;&#22312;&#21516;&#19968;&#39046;&#22495;&#20869;&#30340;&#24378;&#22823;&#20998;&#31867;&#24615;&#33021;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#36890;&#36807;&#25913;&#21464;&#27979;&#35797;&#38598;&#30340;&#20307;&#35009;&#26469;&#27979;&#35797;&#32463;&#36807;&#24494;&#35843;&#30340;&#27169;&#22411;&#22312;&#19978;&#36848;&#39046;&#22495;&#20013;&#30340;&#31283;&#20581;&#24615;&#21644;&#21487;&#36716;&#31227;&#24615;&#12290;&#23545;&#20110;&#20307;&#35009;&#20999;&#25442;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#20221;&#26469;&#33258;&#26032;&#35199;&#20848;&#25919;&#27835;&#23478;&#30340;&#24405;&#38899;&#28436;&#35762;&#30340;&#22806;&#37096;&#35821;&#26009;&#24211;&#65292;&#32780;&#23545;&#20110;&#20854;&#20182;&#19977;&#20010;&#32500;&#24230;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;Manifesto&#25968;&#25454;&#24211;&#30340;&#33258;&#23450;&#20041;&#21010;&#20998;&#12290;&#34429;&#28982;BERT&#21462;&#24471;&#20102;&#26368;&#22909;&#30340;&#24471;&#20998;&#65292;&#20294;&#25105;&#20204;&#36824;&#21457;&#29616;&#20854;&#23427;&#27169;&#22411;&#20063;&#20855;&#26377;&#24456;&#22909;&#30340;&#24615;&#33021;&#21644;&#21487;&#36716;&#31227;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Annotating costs of large corpora are still one of the main bottlenecks in empirical social science research. On the one hand, making use of the capabilities of domain transfer allows re-using annotated data sets and trained models. On the other hand, it is not clear how well domain transfer works and how reliable the results are for transfer across different dimensions. We explore the potential of domain transfer across geographical locations, languages, time, and genre in a large-scale database of political manifestos. First, we show the strong within-domain classification performance of fine-tuned transformer models. Second, we vary the genre of the test set across the aforementioned dimensions to test for the fine-tuned models' robustness and transferability. For switching genres, we use an external corpus of transcribed speeches from New Zealand politicians while for the other three dimensions, custom splits of the Manifesto database are used. While BERT achieves the best scores i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;Gen-neG&#65292;&#23427;&#21033;&#29992;&#39069;&#22806;&#30340;&#36741;&#21161;&#20449;&#24687;&#26469;&#25351;&#23548;&#29983;&#25104;&#36807;&#31243;&#12290;&#36890;&#36807;&#24341;&#23548;&#29983;&#25104;&#36807;&#31243;&#26397;&#30528;&#27491;&#25903;&#25345;&#21306;&#22495;&#29983;&#25104;&#26679;&#26412;&#65292;&#35813;&#26041;&#27861;&#22312;&#33258;&#21160;&#39550;&#39542;&#27169;&#25311;&#22120;&#20013;&#30340;&#36991;&#30896;&#24212;&#29992;&#21644;&#23433;&#20840;&#38450;&#25252;&#20154;&#20307;&#21160;&#20316;&#29983;&#25104;&#20013;&#23637;&#29616;&#20102;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.16463</link><description>&lt;p&gt;
&#19981;&#35201;&#37027;&#20040;&#28040;&#26497;&#65281;&#24102;&#26377;Oracle&#36741;&#21161;&#25351;&#23548;&#30340;&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Don't be so negative! Score-based Generative Modeling with Oracle-assisted Guidance. (arXiv:2307.16463v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16463
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;Gen-neG&#65292;&#23427;&#21033;&#29992;&#39069;&#22806;&#30340;&#36741;&#21161;&#20449;&#24687;&#26469;&#25351;&#23548;&#29983;&#25104;&#36807;&#31243;&#12290;&#36890;&#36807;&#24341;&#23548;&#29983;&#25104;&#36807;&#31243;&#26397;&#30528;&#27491;&#25903;&#25345;&#21306;&#22495;&#29983;&#25104;&#26679;&#26412;&#65292;&#35813;&#26041;&#27861;&#22312;&#33258;&#21160;&#39550;&#39542;&#27169;&#25311;&#22120;&#20013;&#30340;&#36991;&#30896;&#24212;&#29992;&#21644;&#23433;&#20840;&#38450;&#25252;&#20154;&#20307;&#21160;&#20316;&#29983;&#25104;&#20013;&#23637;&#29616;&#20102;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#22823;&#20284;&#28982;&#21407;&#21017;&#25552;&#20513;&#36890;&#36807;&#20248;&#21270;&#25968;&#25454;&#20284;&#28982;&#20989;&#25968;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#12290;&#20197;&#36825;&#31181;&#26041;&#24335;&#20272;&#35745;&#30340;&#27169;&#22411;&#21487;&#20197;&#23637;&#29616;&#20986;&#21508;&#31181;&#30001;&#26550;&#26500;&#12289;&#21442;&#25968;&#21270;&#21644;&#20248;&#21270;&#20559;&#24046;&#31561;&#22240;&#32032;&#20915;&#23450;&#30340;&#27867;&#21270;&#29305;&#24615;&#12290;&#26412;&#25991;&#35299;&#20915;&#20102;&#22312;&#23384;&#22312;&#39069;&#22806;&#36741;&#21161;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#30340;&#27169;&#22411;&#23398;&#20064;&#38382;&#39064;&#65292;&#35813;&#36741;&#21161;&#20449;&#24687;&#20197;Oracle&#30340;&#24418;&#24335;&#23384;&#22312;&#65292;&#21487;&#20197;&#26631;&#35760;&#26679;&#26412;&#26159;&#21542;&#22788;&#20110;&#30495;&#23454;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#30340;&#25903;&#25345;&#33539;&#22260;&#20043;&#22806;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#24314;&#27169;&#65288;DDPM&#65289;&#26041;&#27861;&#65292;&#31216;&#20026;Gen-neG&#65292;&#23427;&#21033;&#29992;&#20102;&#36825;&#20010;&#39069;&#22806;&#30340;&#36741;&#21161;&#20449;&#24687;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#21644;&#25193;&#25955;&#27169;&#22411;&#20013;&#30340;&#37492;&#21035;&#22120;&#25351;&#23548;&#65292;&#20197;&#24341;&#23548;&#29983;&#25104;&#36807;&#31243;&#26397;&#30528;Oracle&#25152;&#25351;&#31034;&#30340;&#27491;&#25903;&#25345;&#21306;&#22495;&#29983;&#25104;&#26679;&#26412;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#33258;&#21160;&#39550;&#39542;&#27169;&#25311;&#22120;&#20013;&#30340;&#36991;&#30896;&#24212;&#29992;&#21644;&#23433;&#20840;&#38450;&#25252;&#20154;&#20307;&#21160;&#20316;&#29983;&#25104;&#20013;&#30340;&#23454;&#35777;&#39564;&#35777;&#20102;Gen-neG&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The maximum likelihood principle advocates parameter estimation via optimization of the data likelihood function. Models estimated in this way can exhibit a variety of generalization characteristics dictated by, e.g. architecture, parameterization, and optimization bias. This work addresses model learning in a setting where there further exists side-information in the form of an oracle that can label samples as being outside the support of the true data generating distribution. Specifically we develop a new denoising diffusion probabilistic modeling (DDPM) methodology, Gen-neG, that leverages this additional side-information. Our approach builds on generative adversarial networks (GANs) and discriminator guidance in diffusion models to guide the generation process towards the positive support region indicated by the oracle. We empirically establish the utility of Gen-neG in applications including collision avoidance in self-driving simulators and safety-guarded human motion generation.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36830;&#32493;&#27979;&#37327;&#24230;&#37327;&#65292;&#29992;&#20110;&#27604;&#36739;&#30495;&#23454;&#22240;&#26524;&#22270;&#19982;&#23398;&#20064;&#21040;&#30340;&#22240;&#26524;&#22270;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#24182;&#36890;&#36807;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#23884;&#20837;&#24178;&#39044;&#20998;&#24067;&#26469;&#35745;&#31639;&#24046;&#24322;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.16452</link><description>&lt;p&gt;
&#19968;&#31181;&#36830;&#32493;&#32467;&#26500;&#24178;&#39044;&#36317;&#31163;&#29992;&#20110;&#27604;&#36739;&#22240;&#26524;&#22270;
&lt;/p&gt;
&lt;p&gt;
A continuous Structural Intervention Distance to compare Causal Graphs. (arXiv:2307.16452v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16452
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36830;&#32493;&#27979;&#37327;&#24230;&#37327;&#65292;&#29992;&#20110;&#27604;&#36739;&#30495;&#23454;&#22240;&#26524;&#22270;&#19982;&#23398;&#20064;&#21040;&#30340;&#22240;&#26524;&#22270;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#24182;&#36890;&#36807;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#23884;&#20837;&#24178;&#39044;&#20998;&#24067;&#26469;&#35745;&#31639;&#24046;&#24322;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20102;&#35299;&#21644;&#20805;&#20998;&#35780;&#20272;&#30495;&#23454;&#22240;&#26524;&#22270;&#19982;&#23398;&#20064;&#21040;&#30340;&#22240;&#26524;&#22270;&#20043;&#38388;&#30340;&#24046;&#24322;&#23545;&#20110;&#24178;&#39044;&#22240;&#26524;&#25512;&#26029;&#33267;&#20851;&#37325;&#35201;&#12290;&#20316;&#20026;&#22522;&#20110;&#22270;&#32467;&#26500;&#30340;&#32467;&#26500;&#27721;&#26126;&#36317;&#31163;&#21644;&#32467;&#26500;&#24178;&#39044;&#36317;&#31163;&#30340;&#25193;&#23637;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36830;&#32493;&#27979;&#37327;&#24230;&#37327;&#65292;&#23427;&#19981;&#20165;&#32771;&#34385;&#20102;&#24213;&#23618;&#25968;&#25454;&#65292;&#36824;&#32771;&#34385;&#20102;&#22240;&#26524;&#22270;&#20043;&#38388;&#30340;&#24046;&#24322;&#35745;&#31639;&#12290;&#35813;&#36317;&#31163;&#22522;&#20110;&#23558;&#24178;&#39044;&#20998;&#24067;&#20316;&#20026;&#26465;&#20214;&#22343;&#20540;&#23884;&#20837;&#21040;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#27599;&#23545;&#33410;&#28857;&#65292;&#24182;&#36890;&#36807;&#26368;&#22823;&#65288;&#26465;&#20214;&#65289;&#22343;&#20540;&#24046;&#24322;&#26469;&#20272;&#35745;&#23427;&#20204;&#30340;&#24046;&#24322;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#36827;&#34892;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding and adequately assessing the difference between a true and a learnt causal graphs is crucial for causal inference under interventions. As an extension to the graph-based structural Hamming distance and structural intervention distance, we propose a novel continuous-measured metric that considers the underlying data in addition to the graph structure for its calculation of the difference between a true and a learnt causal graph. The distance is based on embedding intervention distributions over each pair of nodes as conditional mean embeddings into reproducing kernel Hilbert spaces and estimating their difference by the maximum (conditional) mean discrepancy. We show theoretical results which we validate with numerical experiments on synthetic data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#29702;&#35770;&#26041;&#27861;&#26469;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#65292;&#30830;&#20445;&#20854;&#22312;&#26679;&#26412;&#22823;&#23567;&#36235;&#36817;&#26080;&#31351;&#26102;&#19982;&#30495;&#23454;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#30340;&#35823;&#24046;&#25910;&#25947;&#20026;&#38646;&#65292;&#24182;&#19988;&#36828;&#31163;&#22797;&#21046;&#35757;&#32451;&#25968;&#25454;&#20013;&#31034;&#20363;&#30340;&#20219;&#20309;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2307.16422</link><description>&lt;p&gt;
&#20445;&#35777;&#20174;&#32463;&#39564;&#20998;&#24067;&#20013;&#26368;&#22823;&#20559;&#24046;&#30340;&#26368;&#20339;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Guaranteed Optimal Generative Modeling with Maximum Deviation from the Empirical Distribution. (arXiv:2307.16422v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16422
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#29702;&#35770;&#26041;&#27861;&#26469;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#65292;&#30830;&#20445;&#20854;&#22312;&#26679;&#26412;&#22823;&#23567;&#36235;&#36817;&#26080;&#31351;&#26102;&#19982;&#30495;&#23454;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#30340;&#35823;&#24046;&#25910;&#25947;&#20026;&#38646;&#65292;&#24182;&#19988;&#36828;&#31163;&#22797;&#21046;&#35757;&#32451;&#25968;&#25454;&#20013;&#31034;&#20363;&#30340;&#20219;&#20309;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24314;&#27169;&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#20110;&#31185;&#23398;&#21644;&#24037;&#19994;&#39046;&#22495;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#12290;&#20854;&#20027;&#35201;&#30446;&#26631;&#26159;&#22312;&#32473;&#23450;&#35757;&#32451;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#27169;&#25311;&#20174;&#26410;&#30693;&#20998;&#24067;&#20013;&#25277;&#21462;&#30340;&#26032;&#31034;&#20363;&#65292;&#21516;&#26102;&#30830;&#20445;&#22810;&#26679;&#24615;&#24182;&#36991;&#20813;&#20174;&#35757;&#32451;&#25968;&#25454;&#20013;&#22797;&#21046;&#31034;&#20363;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20851;&#20110;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#30340;&#29702;&#35770;&#35265;&#35299;&#65292;&#35813;&#27169;&#22411;&#20855;&#26377;&#20004;&#20010;&#23646;&#24615;&#65306;&#65288;i&#65289;&#23558;&#30495;&#23454;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#19982;&#35757;&#32451;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#26367;&#25442;&#30340;&#35823;&#24046;&#22312;&#26679;&#26412;&#22823;&#23567;&#36235;&#36817;&#26080;&#31351;&#26102;&#24212;&#26368;&#20339;&#25910;&#25947;&#20110;&#38646;&#65307;&#65288;ii&#65289;&#35757;&#32451;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#24212;&#36828;&#31163;&#22797;&#21046;&#35757;&#32451;&#25968;&#25454;&#20013;&#31034;&#20363;&#30340;&#20219;&#20309;&#20998;&#24067;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20197;&#26377;&#38480;&#26679;&#26412;&#39118;&#38505;&#30028;&#20026;&#24418;&#24335;&#30340;&#38750;&#28176;&#36817;&#32467;&#26524;&#65292;&#37327;&#21270;&#20102;&#36825;&#20123;&#23646;&#24615;&#65292;&#24182;&#21462;&#20915;&#20110;&#30456;&#20851;&#21442;&#25968;&#65292;&#22914;&#26679;&#26412;&#22823;&#23567;&#12289;&#29615;&#22659;&#31354;&#38388;&#30340;&#32500;&#25968;&#21644;&#28508;&#31354;&#38388;&#30340;&#32500;&#25968;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#29983;&#25104;&#27169;&#22411;&#30340;&#21508;&#31181;&#24212;&#29992;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative modeling is a widely-used machine learning method with various applications in scientific and industrial fields. Its primary objective is to simulate new examples drawn from an unknown distribution given training data while ensuring diversity and avoiding replication of examples from the training data.  This paper presents theoretical insights into training a generative model with two properties: (i) the error of replacing the true data-generating distribution with the trained data-generating distribution should optimally converge to zero as the sample size approaches infinity, and (ii) the trained data-generating distribution should be far enough from any distribution replicating examples in the training data.  We provide non-asymptotic results in the form of finite sample risk bounds that quantify these properties and depend on relevant parameters such as sample size, the dimension of the ambient space, and the dimension of the latent space. Our results are applicable to g
&lt;/p&gt;</description></item><item><title>Sinkhorn&#31639;&#27861;&#21644;&#36845;&#20195;&#27604;&#20363;&#25311;&#21512;&#31243;&#24207;&#21487;&#20197;&#25910;&#25947;&#21040;&#19968;&#20010;Wasserstein&#38236;&#20687;&#26799;&#24230;&#27969;&#65292;&#20854;&#20013;&#36895;&#24230;&#22330;&#30340;&#33539;&#25968;&#20195;&#34920;&#32447;&#24615;&#21270;&#26368;&#20339;&#36755;&#36816;&#36317;&#31163;&#30340;&#24230;&#37327;&#23548;&#25968;&#12290;</title><link>http://arxiv.org/abs/2307.16421</link><description>&lt;p&gt;
Wasserstein&#38236;&#20687;&#26799;&#24230;&#27969;&#20316;&#20026;Sinkhorn&#31639;&#27861;&#30340;&#26497;&#38480;
&lt;/p&gt;
&lt;p&gt;
Wasserstein Mirror Gradient Flow as the limit of the Sinkhorn Algorithm. (arXiv:2307.16421v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16421
&lt;/p&gt;
&lt;p&gt;
Sinkhorn&#31639;&#27861;&#21644;&#36845;&#20195;&#27604;&#20363;&#25311;&#21512;&#31243;&#24207;&#21487;&#20197;&#25910;&#25947;&#21040;&#19968;&#20010;Wasserstein&#38236;&#20687;&#26799;&#24230;&#27969;&#65292;&#20854;&#20013;&#36895;&#24230;&#22330;&#30340;&#33539;&#25968;&#20195;&#34920;&#32447;&#24615;&#21270;&#26368;&#20339;&#36755;&#36816;&#36317;&#31163;&#30340;&#24230;&#37327;&#23548;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;Sinkhorn&#31639;&#27861;&#25110;&#36845;&#20195;&#27604;&#20363;&#25311;&#21512;&#31243;&#24207;&#65288;IPFP&#65289;&#24471;&#21040;&#30340;&#24207;&#21015;&#36793;&#32536;&#22312;$\varepsilon$&#36235;&#21521;&#20110;&#38646;&#19988;&#36845;&#20195;&#27425;&#25968;&#25353;$1/\varepsilon$&#32553;&#25918;&#26102;&#65292;&#20250;&#25910;&#25947;&#21040;$2$-Wasserstein&#31354;&#38388;&#19978;&#30340;&#19968;&#20010;&#32477;&#23545;&#36830;&#32493;&#26354;&#32447;&#65288;&#22312;&#28385;&#36275;&#20854;&#20182;&#25216;&#26415;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65289;&#12290;&#25105;&#20204;&#31216;&#36825;&#20010;&#26497;&#38480;&#20026;Sinkhorn&#27969;&#65292;&#23427;&#26159;Wasserstein&#38236;&#20687;&#26799;&#24230;&#27969;&#30340;&#19968;&#20010;&#20363;&#23376;&#65292;&#36825;&#20010;&#27010;&#24565;&#26159;&#25105;&#20204;&#22312;&#36825;&#37324;&#24341;&#20837;&#30340;&#65292;&#21463;&#21040;&#20102;&#20247;&#25152;&#21608;&#30693;&#30340;&#27431;&#20960;&#37324;&#24471;&#38236;&#20687;&#26799;&#24230;&#27969;&#30340;&#21551;&#21457;&#12290;&#22312;Sinkhorn&#30340;&#24773;&#20917;&#19979;&#65292;&#26799;&#24230;&#26159;&#30456;&#23545;&#29109;&#27867;&#20989;&#30456;&#23545;&#20110;&#20854;&#20013;&#19968;&#20010;&#36793;&#32536;&#30340;&#26799;&#24230;&#65292;&#32780;&#38236;&#20687;&#21017;&#26159;&#30456;&#23545;&#20110;&#21478;&#19968;&#20010;&#36793;&#32536;&#30340;&#24179;&#26041;Wasserstein&#36317;&#31163;&#27867;&#20989;&#30340;&#19968;&#21322;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#36825;&#20010;&#27969;&#30340;&#36895;&#24230;&#22330;&#30340;&#33539;&#25968;&#21487;&#20197;&#35299;&#37322;&#20026;&#30456;&#23545;&#20110;&#32447;&#24615;&#21270;&#26368;&#20339;&#36755;&#36816;&#65288;LOT&#65289;&#36317;&#31163;&#30340;&#24230;&#37327;&#23548;&#25968;&#12290;&#23545;&#36825;&#20010;&#27969;&#30340;&#31561;&#20215;&#25551;&#36848;&#26159;...
&lt;/p&gt;
&lt;p&gt;
We prove that the sequence of marginals obtained from the iterations of the Sinkhorn algorithm or the iterative proportional fitting procedure (IPFP) on joint densities, converges to an absolutely continuous curve on the $2$-Wasserstein space, as the regularization parameter $\varepsilon$ goes to zero and the number of iterations is scaled as $1/\varepsilon$ (and other technical assumptions). This limit, which we call the Sinkhorn flow, is an example of a Wasserstein mirror gradient flow, a concept we introduce here inspired by the well-known Euclidean mirror gradient flows. In the case of Sinkhorn, the gradient is that of the relative entropy functional with respect to one of the marginals and the mirror is half of the squared Wasserstein distance functional from the other marginal. Interestingly, the norm of the velocity field of this flow can be interpreted as the metric derivative with respect to the linearized optimal transport (LOT) distance. An equivalent description of this flo
&lt;/p&gt;</description></item><item><title>RCS-YOLO&#26159;&#19968;&#31181;&#24555;&#36895;&#19988;&#39640;&#20934;&#30830;&#24615;&#30340;&#33041;&#32959;&#30244;&#26816;&#27979;&#29289;&#20307;&#26816;&#27979;&#22120;&#65292;&#36890;&#36807;&#24341;&#20837;Reparameterized Convolution&#21644;RCS-OSA&#25216;&#26415;&#65292;&#25552;&#39640;&#20102;YOLO&#26694;&#26550;&#22312;&#22788;&#29702;&#33041;&#32959;&#30244;&#26816;&#27979;&#20013;&#30340;&#24615;&#33021;&#65292;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;</title><link>http://arxiv.org/abs/2307.16412</link><description>&lt;p&gt;
RCS-YOLO: &#19968;&#31181;&#24555;&#36895;&#19988;&#39640;&#20934;&#30830;&#24615;&#30340;&#33041;&#32959;&#30244;&#26816;&#27979;&#29289;&#20307;&#26816;&#27979;&#22120;
&lt;/p&gt;
&lt;p&gt;
RCS-YOLO: A Fast and High-Accuracy Object Detector for Brain Tumor Detection. (arXiv:2307.16412v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16412
&lt;/p&gt;
&lt;p&gt;
RCS-YOLO&#26159;&#19968;&#31181;&#24555;&#36895;&#19988;&#39640;&#20934;&#30830;&#24615;&#30340;&#33041;&#32959;&#30244;&#26816;&#27979;&#29289;&#20307;&#26816;&#27979;&#22120;&#65292;&#36890;&#36807;&#24341;&#20837;Reparameterized Convolution&#21644;RCS-OSA&#25216;&#26415;&#65292;&#25552;&#39640;&#20102;YOLO&#26694;&#26550;&#22312;&#22788;&#29702;&#33041;&#32959;&#30244;&#26816;&#27979;&#20013;&#30340;&#24615;&#33021;&#65292;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#36895;&#24230;&#21644;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#20986;&#33394;&#24179;&#34913;&#65292;&#20808;&#36827;&#30340;YOLO&#26694;&#26550;&#24050;&#25104;&#20026;&#26368;&#39640;&#25928;&#30340;&#29289;&#20307;&#26816;&#27979;&#31639;&#27861;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#22312;&#33041;&#32959;&#30244;&#26816;&#27979;&#20013;&#65292;&#20351;&#29992;YOLO&#32593;&#32476;&#30340;&#24615;&#33021;&#24456;&#23569;&#21463;&#21040;&#30740;&#31350;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Reparameterized Convolution&#30340;RCS-YOLO&#30340;&#26032;&#22411;YOLO&#26550;&#26500;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;RCS&#21644;RCS&#30340;&#19968;&#27425;&#24615;&#32858;&#21512;(RCS-OSA)&#65292;&#23427;&#23558;&#29305;&#24449;&#32423;&#32852;&#21644;&#35745;&#31639;&#25928;&#29575;&#30456;&#32467;&#21512;&#65292;&#20197;&#25552;&#21462;&#26356;&#20016;&#23500;&#30340;&#20449;&#24687;&#24182;&#20943;&#23569;&#26102;&#38388;&#28040;&#32791;&#12290;&#22312;&#33041;&#32959;&#30244;&#25968;&#25454;&#38598;Br35H&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#22312;&#36895;&#24230;&#21644;&#20934;&#30830;&#24615;&#19978;&#36229;&#36807;&#20102;YOLOv6&#65292;YOLOv7&#21644;YOLOv8&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#19982;YOLOv7&#30456;&#27604;&#65292;RCS-YOLO&#30340;&#31934;&#24230;&#25552;&#39640;&#20102;2.6&#65285;&#65292;&#25512;&#26029;&#36895;&#24230;&#25552;&#39640;&#20102;60&#65285;&#65292;&#36798;&#21040;&#27599;&#31186;114.8&#24352;&#22270;&#20687;&#26816;&#27979;&#65288;FPS&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;RCS-YOLO&#22312;&#33041;&#32959;&#30244;&#26816;&#27979;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#20195;&#30721;&#21487;&#22312;https://github.com/mkang315/RCS-YOLO&#33719;&#21462;&#12290;
&lt;/p&gt;
&lt;p&gt;
With an excellent balance between speed and accuracy, cutting-edge YOLO frameworks have become one of the most efficient algorithms for object detection. However, the performance of using YOLO networks is scarcely investigated in brain tumor detection. We propose a novel YOLO architecture with Reparameterized Convolution based on channel Shuffle (RCS-YOLO). We present RCS and a One-Shot Aggregation of RCS (RCS-OSA), which link feature cascade and computation efficiency to extract richer information and reduce time consumption. Experimental results on the brain tumor dataset Br35H show that the proposed model surpasses YOLOv6, YOLOv7, and YOLOv8 in speed and accuracy. Notably, compared with YOLOv7, the precision of RCS-YOLO improves by 2.6%, and the inference speed by 60% at 114.8 images detected per second (FPS). Our proposed RCS-YOLO achieves state-of-the-art performance on the brain tumor detection task. The code is available at https://github.com/mkang315/RCS-YOLO.
&lt;/p&gt;</description></item><item><title>Causal-learn&#26159;&#19968;&#20010;Python&#24211;&#65292;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#20174;&#19994;&#32773;&#21644;&#30740;&#31350;&#20154;&#21592;&#12290;&#19982;&#20854;&#20182;&#35821;&#35328;&#24320;&#21457;&#30340;&#21253;&#19981;&#21516;&#65292;Causal-learn&#23436;&#20840;&#30001;Python&#24320;&#21457;&#12290;</title><link>http://arxiv.org/abs/2307.16405</link><description>&lt;p&gt;
Causal-learn: Python&#20013;&#30340;&#22240;&#26524;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Causal-learn: Causal Discovery in Python. (arXiv:2307.16405v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16405
&lt;/p&gt;
&lt;p&gt;
Causal-learn&#26159;&#19968;&#20010;Python&#24211;&#65292;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#20174;&#19994;&#32773;&#21644;&#30740;&#31350;&#20154;&#21592;&#12290;&#19982;&#20854;&#20182;&#35821;&#35328;&#24320;&#21457;&#30340;&#21253;&#19981;&#21516;&#65292;Causal-learn&#23436;&#20840;&#30001;Python&#24320;&#21457;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#21457;&#29616;&#26088;&#22312;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#25581;&#31034;&#22240;&#26524;&#20851;&#31995;&#65292;&#36825;&#26159;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#30340;&#19968;&#39033;&#22522;&#30784;&#20219;&#21153;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;$\textit {causal-learn}$&#65292;&#19968;&#20010;&#29992;&#20110;&#22240;&#26524;&#21457;&#29616;&#30340;&#24320;&#28304;Python&#24211;&#12290;&#35813;&#24211;&#19987;&#27880;&#20110;&#20026;&#20174;&#19994;&#32773;&#21644;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#20840;&#38754;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#12290;&#23427;&#20026;&#38750;&#19987;&#19994;&#20154;&#21592;&#25552;&#20379;&#26131;&#20110;&#20351;&#29992;&#30340;API&#65292;&#20026;&#24320;&#21457;&#20154;&#21592;&#25552;&#20379;&#27169;&#22359;&#21270;&#26500;&#24314;&#22359;&#65292;&#20026;&#23398;&#20064;&#32773;&#25552;&#20379;&#35814;&#32454;&#30340;&#25991;&#26723;&#65292;&#24182;&#25552;&#20379;&#20840;&#38754;&#30340;&#26041;&#27861;&#12290;&#19982;&#20043;&#21069;&#30340;R&#25110;Java&#21253;&#19981;&#21516;&#65292;$\textit {causal-learn}$&#23436;&#20840;&#30001;Python&#24320;&#21457;&#65292;&#36825;&#26356;&#31526;&#21512;&#30456;&#20851;&#31038;&#21306;&#22312;&#32534;&#31243;&#35821;&#35328;&#26041;&#38754;&#30340;&#26368;&#36817;&#20559;&#22909;&#36716;&#21464;&#12290;&#35813;&#24211;&#21487;&#22312;https://github.com/py-why/causal-learn&#19978;&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal discovery aims at revealing causal relations from observational data, which is a fundamental task in science and engineering. We describe $\textit{causal-learn}$, an open-source Python library for causal discovery. This library focuses on bringing a comprehensive collection of causal discovery methods to both practitioners and researchers. It provides easy-to-use APIs for non-specialists, modular building blocks for developers, detailed documentation for learners, and comprehensive methods for all. Different from previous packages in R or Java, $\textit{causal-learn}$ is fully developed in Python, which could be more in tune with the recent preference shift in programming languages within related communities. The library is available at https://github.com/py-why/causal-learn.
&lt;/p&gt;</description></item><item><title>&#20912;&#31435;&#26041;DeepCore&#20013;&#30340;&#20108;&#32500;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#20107;&#20214;&#37325;&#24314;&#65292;&#22312;GeV&#32423;&#33021;&#37327;&#19979;&#20855;&#26377;&#26356;&#22909;&#30340;&#25104;&#21151;&#29575;&#65292;&#23545;&#20110;&#21619;&#36947;&#35782;&#21035;&#21644;&#19981;&#24377;&#24615;&#37325;&#24314;&#20855;&#26377;&#29305;&#21035;&#30340;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2307.16373</link><description>&lt;p&gt;
&#20912;&#31435;&#26041;DeepCore&#20013;&#30340;&#20108;&#32500;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#20107;&#20214;&#37325;&#24314;
&lt;/p&gt;
&lt;p&gt;
2D Convolutional Neural Network for Event Reconstruction in IceCube DeepCore. (arXiv:2307.16373v1 [astro-ph.HE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16373
&lt;/p&gt;
&lt;p&gt;
&#20912;&#31435;&#26041;DeepCore&#20013;&#30340;&#20108;&#32500;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#20107;&#20214;&#37325;&#24314;&#65292;&#22312;GeV&#32423;&#33021;&#37327;&#19979;&#20855;&#26377;&#26356;&#22909;&#30340;&#25104;&#21151;&#29575;&#65292;&#23545;&#20110;&#21619;&#36947;&#35782;&#21035;&#21644;&#19981;&#24377;&#24615;&#37325;&#24314;&#20855;&#26377;&#29305;&#21035;&#30340;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20912;&#31435;&#26041;DeepCore&#26159;&#20912;&#31435;&#26041;&#20013;&#24494;&#23376;&#35266;&#27979;&#31449;&#30340;&#25193;&#23637;&#65292;&#26088;&#22312;&#27979;&#37327;GeV&#32423;&#22823;&#27668;&#20013;&#24494;&#23376;&#30456;&#20114;&#20316;&#29992;&#20197;&#36827;&#34892;&#20013;&#24494;&#23376;&#25391;&#33633;&#30740;&#31350;&#12290;&#30001;&#20110;&#20202;&#22120;&#31232;&#30095;&#65292;&#20912;&#31435;&#26041;DeepCore&#22312;GeV&#32423;&#33021;&#37327;&#19979;&#21306;&#20998;muon&#20013;&#24494;&#23376;&#21644;&#20854;&#20182;&#21619;&#36947;&#20197;&#21450;&#37325;&#24314;&#19981;&#24377;&#24615;&#26159;&#29305;&#21035;&#22256;&#38590;&#30340;&#20219;&#21153;&#12290;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#22312;&#20013;&#24494;&#23376;&#20107;&#20214;&#37325;&#24314;&#26041;&#38754;&#27604;&#20256;&#32479;&#30340;&#22522;&#20110;&#20284;&#28982;&#30340;&#26041;&#27861;&#26356;&#25104;&#21151;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;CNN&#27169;&#22411;&#65292;&#21033;&#29992;&#20102;&#20912;&#31435;&#26041;DeepCore&#25968;&#25454;&#20013;&#30340;&#26102;&#38388;&#21644;&#28145;&#24230;&#24179;&#31227;&#23545;&#31216;&#24615;&#65292;&#24182;&#38024;&#23545;&#21619;&#36947;&#35782;&#21035;&#21644;&#19981;&#24377;&#24615;&#37325;&#24314;&#35780;&#20272;&#20102;&#35813;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
IceCube DeepCore is an extension of the IceCube Neutrino Observatory designed to measure GeV scale atmospheric neutrino interactions for the purpose of neutrino oscillation studies. Distinguishing muon neutrinos from other flavors and reconstructing inelasticity are especially difficult tasks at GeV scale energies in IceCube DeepCore due to sparse instrumentation. Convolutional neural networks (CNNs) have been found to have better success at neutrino event reconstruction than conventional likelihood-based methods. In this contribution, we present a new CNN model that exploits time and depth translational symmetry in IceCube DeepCore data and present the model's performance, specifically for flavor identification and inelasticity reconstruction.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#27010;&#29575;&#40065;&#26834;&#24615;&#30340;&#31526;&#21512;&#24615;&#39044;&#27979;&#65288;PRCP&#65289;&#38382;&#39064;&#65292;&#36890;&#36807;&#25552;&#20986;aPRCP&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#24178;&#20928;&#36755;&#20837;&#31034;&#20363;&#30340;&#22823;&#22810;&#25968;&#25200;&#21160;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2307.16360</link><description>&lt;p&gt;
&#27010;&#29575;&#40065;&#26834;&#24615;&#30340;&#31526;&#21512;&#24615;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Probabilistically robust conformal prediction. (arXiv:2307.16360v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16360
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27010;&#29575;&#40065;&#26834;&#24615;&#30340;&#31526;&#21512;&#24615;&#39044;&#27979;&#65288;PRCP&#65289;&#38382;&#39064;&#65292;&#36890;&#36807;&#25552;&#20986;aPRCP&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#24178;&#20928;&#36755;&#20837;&#31034;&#20363;&#30340;&#22823;&#22810;&#25968;&#25200;&#21160;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31526;&#21512;&#24615;&#39044;&#27979;&#65288;CP&#65289;&#26159;&#19968;&#31181;&#37327;&#21270;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#19981;&#30830;&#23450;&#24615;&#30340;&#26694;&#26550;&#65292;&#21253;&#25324;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#12290;&#32473;&#23450;&#19968;&#20010;&#27979;&#35797;&#31034;&#20363;&#21644;&#19968;&#20010;&#35757;&#32451;&#22909;&#30340;&#20998;&#31867;&#22120;&#65292;CP&#20250;&#20135;&#29983;&#19968;&#20010;&#39044;&#27979;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#20102;&#20505;&#36873;&#26631;&#31614;&#65292;&#24182;&#19988;&#20855;&#26377;&#29992;&#25143;&#25351;&#23450;&#30340;&#35206;&#30422;&#29575;&#65288;&#21363;&#30495;&#23454;&#31867;&#26631;&#31614;&#20197;&#24456;&#39640;&#30340;&#27010;&#29575;&#21253;&#21547;&#22312;&#20869;&#65289;&#12290;&#20960;&#20046;&#25152;&#26377;&#29616;&#26377;&#20851;&#20110;CP&#30340;&#24037;&#20316;&#37117;&#20551;&#35774;&#27979;&#35797;&#25968;&#25454;&#26159;&#24178;&#20928;&#30340;&#65292;&#24182;&#19988;&#23545;&#20110;&#19982;&#27979;&#35797;&#31034;&#20363;&#30340;&#33258;&#28982;/&#25932;&#23545;&#25200;&#21160;&#23545;CP&#31639;&#27861;&#30340;&#40065;&#26834;&#24615;&#27809;&#26377;&#22826;&#22810;&#20102;&#35299;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#27010;&#29575;&#40065;&#26834;&#24615;&#30340;&#31526;&#21512;&#24615;&#39044;&#27979;&#65288;PRCP&#65289;&#38382;&#39064;&#65292;&#23427;&#30830;&#20445;&#23545;&#24178;&#20928;&#36755;&#20837;&#31034;&#20363;&#30340;&#22823;&#22810;&#25968;&#25200;&#21160;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;PRCP&#25512;&#24191;&#20102;&#26631;&#20934;CP&#65288;&#26080;&#27861;&#22788;&#29702;&#25200;&#21160;&#65289;&#21644;&#23545;&#25239;&#40065;&#26834;CP&#65288;&#30830;&#20445;&#38024;&#23545;&#26368;&#22351;&#24773;&#20917;&#30340;&#25200;&#21160;&#20855;&#26377;&#40065;&#26834;&#24615;&#65289;&#20043;&#38388;&#30340;&#26356;&#22909;&#24179;&#34913;nominal&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#33258;&#36866;&#24212;PRCP&#65288;aPRCP&#65289;&#31639;&#27861;&#26469;&#23454;&#29616;&#27010;&#29575;&#40065;&#26834;&#30340;&#35206;&#30422;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conformal prediction (CP) is a framework to quantify uncertainty of machine learning classifiers including deep neural networks. Given a testing example and a trained classifier, CP produces a prediction set of candidate labels with a user-specified coverage (i.e., true class label is contained with high probability). Almost all the existing work on CP assumes clean testing data and there is not much known about the robustness of CP algorithms w.r.t natural/adversarial perturbations to testing examples. This paper studies the problem of probabilistically robust conformal prediction (PRCP) which ensures robustness to most perturbations around clean input examples. PRCP generalizes the standard CP (cannot handle perturbations) and adversarially robust CP (ensures robustness w.r.t worst-case perturbations) to achieve better trade-offs between nominal performance and robustness. We propose a novel adaptive PRCP (aPRCP) algorithm to achieve probabilistically robust coverage. The key idea be
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#23454;&#29992;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#26597;&#25214;&#25110;&#35777;&#20266;&#25968;&#25454;&#38598;&#20013;&#23545;&#26222;&#36890;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#20855;&#26377;&#24433;&#21709;&#30340;&#23567;&#23376;&#38598;&#12290;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;&#65292;&#36825;&#20123;&#31639;&#27861;&#26041;&#27861;&#22312;&#40065;&#26834;&#24615;&#26816;&#26597;&#20013;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#20302;&#32500;&#22238;&#24402;&#38382;&#39064;&#30340;&#26377;&#29992;&#26816;&#26597;&#12290;&#20294;&#23545;&#20110;&#39640;&#32500;&#22238;&#24402;&#38382;&#39064;&#65292;&#35745;&#31639;&#29942;&#39048;&#20173;&#28982;&#23384;&#22312;&#12290;&#36890;&#36807;&#20351;&#29992;&#26032;&#39062;&#30340;&#35889;&#31639;&#27861;&#65292;&#25105;&#20204;&#21462;&#24471;&#20102;&#19968;&#20123;&#36827;&#23637;&#12290;</title><link>http://arxiv.org/abs/2307.16315</link><description>&lt;p&gt;
&#38754;&#21521;&#32447;&#24615;&#22238;&#24402;&#30340;&#23454;&#29992;&#40065;&#26834;&#24615;&#23457;&#35745;
&lt;/p&gt;
&lt;p&gt;
Towards Practical Robustness Auditing for Linear Regression. (arXiv:2307.16315v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16315
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#23454;&#29992;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#26597;&#25214;&#25110;&#35777;&#20266;&#25968;&#25454;&#38598;&#20013;&#23545;&#26222;&#36890;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#20855;&#26377;&#24433;&#21709;&#30340;&#23567;&#23376;&#38598;&#12290;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;&#65292;&#36825;&#20123;&#31639;&#27861;&#26041;&#27861;&#22312;&#40065;&#26834;&#24615;&#26816;&#26597;&#20013;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#20302;&#32500;&#22238;&#24402;&#38382;&#39064;&#30340;&#26377;&#29992;&#26816;&#26597;&#12290;&#20294;&#23545;&#20110;&#39640;&#32500;&#22238;&#24402;&#38382;&#39064;&#65292;&#35745;&#31639;&#29942;&#39048;&#20173;&#28982;&#23384;&#22312;&#12290;&#36890;&#36807;&#20351;&#29992;&#26032;&#39062;&#30340;&#35889;&#31639;&#27861;&#65292;&#25105;&#20204;&#21462;&#24471;&#20102;&#19968;&#20123;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#23454;&#29992;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#25214;&#21040;&#25110;&#35777;&#20266;&#19968;&#20010;&#25968;&#25454;&#38598;&#20013;&#30340;&#23567;&#23376;&#38598;&#65292;&#24403;&#31227;&#38500;&#36825;&#20123;&#23376;&#38598;&#26102;&#65292;&#20250;&#25913;&#21464;&#26222;&#36890;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#20013;&#30340;&#31995;&#25968;&#30340;&#31526;&#21495;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#20102;&#29992;&#20110;&#27492;&#20219;&#21153;&#30340;&#20808;&#36827;&#31639;&#27861;&#25216;&#26415;&#30340;&#24615;&#33021; - &#28151;&#21512;&#25972;&#25968;&#20108;&#27425;&#32422;&#26463;&#20248;&#21270;&#29992;&#20110;&#19968;&#33324;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#65292;&#20197;&#21450;&#23545;&#29305;&#27530;&#24773;&#20917;&#30340;&#30830;&#20999;&#36138;&#23146;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#36825;&#20123;&#26041;&#27861;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#32988;&#36807;&#20102;&#29616;&#26377;&#25216;&#26415;&#65292;&#24182;&#19988;&#20026;&#20302;&#32500;&#22238;&#24402;&#38382;&#39064;&#25552;&#20379;&#20102;&#26377;&#29992;&#30340;&#40065;&#26834;&#24615;&#26816;&#26597;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#32500;&#24230;&#20026;3&#25110;&#26356;&#39640;&#30340;&#22238;&#24402;&#38382;&#39064;&#65292;&#20173;&#28982;&#23384;&#22312;&#37325;&#35201;&#30340;&#35745;&#31639;&#29942;&#39048;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#35777;&#20266;&#36825;&#31181;&#23567;&#32780;&#20855;&#24433;&#21709;&#21147;&#30340;&#26679;&#26412;&#38598;&#21512;&#30340;&#23384;&#22312;&#12290;&#36890;&#36807;&#20351;&#29992;&#26368;&#36817;&#31639;&#27861;&#40065;&#26834;&#32479;&#35745;&#39046;&#22495;&#21019;&#26032;&#30340;&#24605;&#24819;&#65292;&#25105;&#20204;&#22312;&#36825;&#19968;&#25361;&#25112;&#19978;&#21462;&#24471;&#20102;&#19968;&#20123;&#36827;&#23637;&#65292;&#21033;&#29992;&#35889;&#31639;&#27861;&#12290;&#25105;&#20204;&#24635;&#32467;&#20102;&#24050;&#30693;&#25216;&#26415;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate practical algorithms to find or disprove the existence of small subsets of a dataset which, when removed, reverse the sign of a coefficient in an ordinary least squares regression involving that dataset. We empirically study the performance of well-established algorithmic techniques for this task -- mixed integer quadratically constrained optimization for general linear regression problems and exact greedy methods for special cases. We show that these methods largely outperform the state of the art and provide a useful robustness check for regression problems in a few dimensions. However, significant computational bottlenecks remain, especially for the important task of disproving the existence of such small sets of influential samples for regression problems of dimension $3$ or greater. We make some headway on this challenge via a spectral algorithm using ideas drawn from recent innovations in algorithmic robust statistics. We summarize the limitations of known techniqu
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#19968;&#31867;&#23494;&#24230;&#27604;&#29575;&#20272;&#35745;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#23398;&#20064;&#30340;&#21442;&#25968;&#36873;&#25321;&#21407;&#21017;&#65292;&#24182;&#22312;&#26377;&#38480;&#26679;&#26412;&#24773;&#20917;&#19979;&#25512;&#23548;&#20986;&#26032;&#30340;&#35823;&#24046;&#30028;&#12290;&#20854;&#26041;&#27861;&#22312;&#20108;&#27425;&#25439;&#22833;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#26497;&#23567;&#21270;&#26368;&#20248;&#35823;&#24046;&#29575;&#12290;</title><link>http://arxiv.org/abs/2307.16164</link><description>&lt;p&gt;
&#22312;RKHS&#20013;&#33258;&#36866;&#24212;&#23398;&#20064;&#23494;&#24230;&#27604;&#29575;
&lt;/p&gt;
&lt;p&gt;
Adaptive learning of density ratios in RKHS. (arXiv:2307.16164v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16164
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#19968;&#31867;&#23494;&#24230;&#27604;&#29575;&#20272;&#35745;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#23398;&#20064;&#30340;&#21442;&#25968;&#36873;&#25321;&#21407;&#21017;&#65292;&#24182;&#22312;&#26377;&#38480;&#26679;&#26412;&#24773;&#20917;&#19979;&#25512;&#23548;&#20986;&#26032;&#30340;&#35823;&#24046;&#30028;&#12290;&#20854;&#26041;&#27861;&#22312;&#20108;&#27425;&#25439;&#22833;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#26497;&#23567;&#21270;&#26368;&#20248;&#35823;&#24046;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#26377;&#38480;&#25968;&#37327;&#30340;&#23494;&#24230;&#35266;&#27979;&#20013;&#20272;&#35745;&#20004;&#20010;&#27010;&#29575;&#23494;&#24230;&#30340;&#27604;&#29575;&#26159;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#23398;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#65292;&#24212;&#29992;&#21253;&#25324;&#21452;&#26679;&#26412;&#26816;&#39564;&#12289;&#20998;&#27495;&#20272;&#35745;&#12289;&#29983;&#25104;&#24314;&#27169;&#12289;&#21327;&#21464;&#37327;&#36716;&#31227;&#36866;&#24212;&#12289;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#21644;&#26032;&#39062;&#24615;&#26816;&#27979;&#12290;&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#19968;&#22823;&#31867;&#23494;&#24230;&#27604;&#29575;&#20272;&#35745;&#26041;&#27861;&#65292;&#23427;&#20204;&#36890;&#36807;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#20013;&#26368;&#23567;&#21270;&#30495;&#23454;&#23494;&#24230;&#27604;&#29575;&#19982;&#27169;&#22411;&#20043;&#38388;&#30340;&#27491;&#21017;Bregman&#36317;&#31163;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#26032;&#30340;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#30028;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;Lepskii&#31867;&#22411;&#30340;&#21442;&#25968;&#36873;&#25321;&#21407;&#21017;&#65292;&#22312;&#19981;&#30693;&#36947;&#23494;&#24230;&#27604;&#29575;&#30340;&#27491;&#21017;&#24615;&#30340;&#24773;&#20917;&#19979;&#26368;&#23567;&#21270;&#35823;&#24046;&#30028;&#12290;&#22312;&#20108;&#27425;&#25439;&#22833;&#30340;&#29305;&#27530;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33258;&#36866;&#24212;&#22320;&#23454;&#29616;&#20102;&#26497;&#23567;&#21270;&#26368;&#20248;&#35823;&#24046;&#29575;&#12290;&#25552;&#20379;&#20102;&#19968;&#20010;&#25968;&#20540;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating the ratio of two probability densities from finitely many observations of the densities is a central problem in machine learning and statistics with applications in two-sample testing, divergence estimation, generative modeling, covariate shift adaptation, conditional density estimation, and novelty detection. In this work, we analyze a large class of density ratio estimation methods that minimize a regularized Bregman divergence between the true density ratio and a model in a reproducing kernel Hilbert space (RKHS). We derive new finite-sample error bounds, and we propose a Lepskii type parameter choice principle that minimizes the bounds without knowledge of the regularity of the density ratio. In the special case of quadratic loss, our method adaptively achieves a minimax optimal error rate. A numerical illustration is provided.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#23545;&#29702;&#24819;&#30340;&#23545;&#25239;&#25915;&#20987;&#36827;&#34892;&#36817;&#20284;&#34920;&#31034;&#65292;&#24182;&#23558;&#23545;&#25239;&#35757;&#32451;&#36716;&#21270;&#20026;&#36827;&#25915;&#32593;&#32476;&#21644;&#38450;&#23432;&#32593;&#32476;&#20043;&#38388;&#30340;&#25968;&#23398;&#21338;&#24328;&#65292;&#21516;&#26102;&#32473;&#20986;&#20102;&#23545;&#25239;&#35757;&#32451;&#22312;&#26679;&#26412;&#22823;&#23567;$n$&#19979;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2307.16099</link><description>&lt;p&gt;
&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#29702;&#24819;&#23545;&#25239;&#25915;&#20987;&#21644;&#23545;&#25239;&#35757;&#32451;&#25910;&#25947;&#24615;&#30340;&#35770;&#25991;&#32763;&#35793;
&lt;/p&gt;
&lt;p&gt;
On Neural Network approximation of ideal adversarial attack and convergence of adversarial training. (arXiv:2307.16099v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16099
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#23545;&#29702;&#24819;&#30340;&#23545;&#25239;&#25915;&#20987;&#36827;&#34892;&#36817;&#20284;&#34920;&#31034;&#65292;&#24182;&#23558;&#23545;&#25239;&#35757;&#32451;&#36716;&#21270;&#20026;&#36827;&#25915;&#32593;&#32476;&#21644;&#38450;&#23432;&#32593;&#32476;&#20043;&#38388;&#30340;&#25968;&#23398;&#21338;&#24328;&#65292;&#21516;&#26102;&#32473;&#20986;&#20102;&#23545;&#25239;&#35757;&#32451;&#22312;&#26679;&#26412;&#22823;&#23567;$n$&#19979;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#25915;&#20987;&#36890;&#24120;&#26159;&#36890;&#36807;&#23545;&#36755;&#20837;&#25968;&#25454;&#21644;&#27169;&#22411;&#36827;&#34892;&#22522;&#20110;&#26799;&#24230;&#30340;&#25805;&#20316;&#26469;&#23454;&#29616;&#30340;&#65292;&#36825;&#23548;&#33268;&#27599;&#27425;&#29983;&#25104;&#25915;&#20987;&#26102;&#37117;&#38656;&#35201;&#36827;&#34892;&#22823;&#37327;&#30340;&#35745;&#31639;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;&#23545;&#25239;&#25915;&#20987;&#34920;&#31034;&#20026;&#21487;&#35757;&#32451;&#30340;&#20989;&#25968;&#30340;&#24605;&#24819;&#26356;&#21152;&#24041;&#22266;&#65292;&#32780;&#26080;&#38656;&#36827;&#19968;&#27493;&#35745;&#31639;&#26799;&#24230;&#12290;&#25105;&#20204;&#39318;&#20808;&#28608;&#21457;&#20986;&#22312;&#36866;&#24403;&#26465;&#20214;&#19979;&#65292;&#29702;&#35770;&#19978;&#30340;&#26368;&#20339;&#25915;&#20987;&#21487;&#20197;&#34920;&#31034;&#20026;&#20809;&#28369;&#30340;&#20998;&#27573;&#20989;&#25968;&#65288;&#20998;&#27573;H\"older&#20989;&#25968;&#65289;&#12290;&#28982;&#21518;&#25105;&#20204;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#24471;&#21040;&#20102;&#36825;&#20123;&#20989;&#25968;&#30340;&#36817;&#20284;&#32467;&#26524;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#27169;&#25311;&#29702;&#24819;&#30340;&#25915;&#20987;&#36807;&#31243;&#65292;&#24182;&#23558;&#23545;&#25239;&#35757;&#32451;&#21270;&#31616;&#20026;&#36827;&#25915;&#32593;&#32476;&#21644;&#38450;&#23432;&#27169;&#22411;&#65288;&#38450;&#23432;&#32593;&#32476;&#65289;&#20043;&#38388;&#30340;&#25968;&#23398;&#21338;&#24328;&#12290;&#22312;&#36825;&#26679;&#30340;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#36824;&#24471;&#21040;&#20102;&#23545;&#25239;&#35757;&#32451;&#30340;&#26679;&#26412;&#22823;&#23567;$n$&#23545;&#20110;&#23545;&#25239;&#25439;&#22833;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial attacks are usually expressed in terms of a gradient-based operation on the input data and model, this results in heavy computations every time an attack is generated. In this work, we solidify the idea of representing adversarial attacks as a trainable function, without further gradient computation. We first motivate that the theoretical best attacks, under proper conditions, can be represented as smooth piece-wise functions (piece-wise H\"older functions). Then we obtain an approximation result of such functions by a neural network. Subsequently, we emulate the ideal attack process by a neural network and reduce the adversarial training to a mathematical game between an attack network and a training model (a defense network). We also obtain convergence rates of adversarial loss in terms of the sample size $n$ for adversarial training in such a setting.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#30340;&#30446;&#26631;&#26159;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#35782;&#21035;&#30446;&#26631;&#21464;&#37327;&#30340;&#30452;&#25509;&#21407;&#22240;&#65292;&#36890;&#36807;&#19981;&#23545;&#20854;&#20182;&#21464;&#37327;&#20570;&#22826;&#22810;&#20551;&#35774;&#65292;&#30740;&#31350;&#32773;&#25552;&#20986;&#20102;&#21487;&#35782;&#21035;&#24615;&#32467;&#26524;&#21644;&#20004;&#31181;&#23454;&#29992;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.16048</link><description>&lt;p&gt;
&#23616;&#37096;&#22240;&#26524;&#21457;&#29616;&#20013;&#30340;&#32467;&#26500;&#38480;&#21046;: &#35782;&#21035;&#30446;&#26631;&#21464;&#37327;&#30340;&#30452;&#25509;&#21407;&#22240;
&lt;/p&gt;
&lt;p&gt;
Structural restrictions in local causal discovery: identifying direct causes of a target variable. (arXiv:2307.16048v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16048
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#30340;&#30446;&#26631;&#26159;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#35782;&#21035;&#30446;&#26631;&#21464;&#37327;&#30340;&#30452;&#25509;&#21407;&#22240;&#65292;&#36890;&#36807;&#19981;&#23545;&#20854;&#20182;&#21464;&#37327;&#20570;&#22826;&#22810;&#20551;&#35774;&#65292;&#30740;&#31350;&#32773;&#25552;&#20986;&#20102;&#21487;&#35782;&#21035;&#24615;&#32467;&#26524;&#21644;&#20004;&#31181;&#23454;&#29992;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#35266;&#23519;&#32852;&#21512;&#20998;&#24067;&#20013;&#23398;&#20064;&#30446;&#26631;&#21464;&#37327;&#30340;&#19968;&#32452;&#30452;&#25509;&#21407;&#22240;&#30340;&#38382;&#39064;&#12290;&#23398;&#20064;&#34920;&#31034;&#22240;&#26524;&#32467;&#26500;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;(DAG)&#26159;&#31185;&#23398;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#12290;&#24403;&#23436;&#25972;&#30340;DAG&#20174;&#20998;&#24067;&#20013;&#21487;&#35782;&#21035;&#26102;&#65292;&#24050;&#30693;&#26377;&#19968;&#20123;&#32467;&#26524;&#65292;&#20363;&#22914;&#20551;&#35774;&#38750;&#32447;&#24615;&#39640;&#26031;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#12290;&#36890;&#24120;&#65292;&#25105;&#20204;&#21482;&#23545;&#35782;&#21035;&#19968;&#20010;&#30446;&#26631;&#21464;&#37327;&#30340;&#30452;&#25509;&#21407;&#22240;&#65288;&#23616;&#37096;&#22240;&#26524;&#32467;&#26500;&#65289;&#65292;&#32780;&#19981;&#26159;&#23436;&#25972;&#30340;DAG&#24863;&#20852;&#36259;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#23545;&#30446;&#26631;&#21464;&#37327;&#30340;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#19981;&#21516;&#20551;&#35774;&#65292;&#35813;&#20551;&#35774;&#19979;&#30452;&#25509;&#21407;&#22240;&#38598;&#21512;&#21487;&#20197;&#20174;&#20998;&#24067;&#20013;&#35782;&#21035;&#20986;&#26469;&#12290;&#22312;&#36825;&#26679;&#20570;&#30340;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#23545;&#38500;&#30446;&#26631;&#21464;&#37327;&#20043;&#22806;&#30340;&#21464;&#37327;&#22522;&#26412;&#19978;&#27809;&#26377;&#20219;&#20309;&#20551;&#35774;&#12290;&#38500;&#20102;&#26032;&#30340;&#21487;&#35782;&#21035;&#24615;&#32467;&#26524;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#20004;&#31181;&#20174;&#26377;&#38480;&#38543;&#26426;&#26679;&#26412;&#20272;&#35745;&#30452;&#25509;&#21407;&#22240;&#30340;&#23454;&#29992;&#31639;&#27861;&#65292;&#24182;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning a set of direct causes of a target variable from an observational joint distribution. Learning directed acyclic graphs (DAGs) that represent the causal structure is a fundamental problem in science. Several results are known when the full DAG is identifiable from the distribution, such as assuming a nonlinear Gaussian data-generating process. Often, we are only interested in identifying the direct causes of one target variable (local causal structure), not the full DAG. In this paper, we discuss different assumptions for the data-generating process of the target variable under which the set of direct causes is identifiable from the distribution. While doing so, we put essentially no assumptions on the variables other than the target variable. In addition to the novel identifiability results, we provide two practical algorithms for estimating the direct causes from a finite random sample and demonstrate their effectiveness on several benchmark dataset
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#20998;&#31867;&#22120;&#30340;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#31639;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#26631;&#35760;&#35757;&#32451;&#25968;&#25454;&#38598;&#26469;&#36817;&#20284;&#35745;&#31639;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#30340;&#27604;&#29575;&#12290;</title><link>http://arxiv.org/abs/2307.16035</link><description>&lt;p&gt;
&#22522;&#20110;&#31070;&#32463;&#20998;&#31867;&#22120;&#30340;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;
&lt;/p&gt;
&lt;p&gt;
Neural Classifiers based Monte Carlo simulation. (arXiv:2307.16035v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16035
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#20998;&#31867;&#22120;&#30340;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#31639;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#26631;&#35760;&#35757;&#32451;&#25968;&#25454;&#38598;&#26469;&#36817;&#20284;&#35745;&#31639;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#30340;&#27604;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25509;&#21463;-&#25298;&#32477;(AR)&#65292;&#29420;&#31435;Metropolis Hastings&#65288;IMH&#65289;&#25110;&#37325;&#35201;&#24615;&#25277;&#26679;&#65288;IS&#65289;&#33945;&#29305;&#21345;&#27931;&#65288;MC&#65289;&#27169;&#25311;&#31639;&#27861;&#37117;&#28041;&#21450;&#35745;&#31639;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#65288;pdf&#65289;&#30340;&#27604;&#29575;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#20998;&#31867;&#22120;&#21487;&#20197;&#21306;&#20998;&#28151;&#21512;&#23494;&#24230;&#27169;&#22411;&#20135;&#29983;&#30340;&#26631;&#35760;&#26679;&#26412;&#65292;&#21363;&#20004;&#20010;pdf&#30340;&#20984;&#32447;&#24615;&#32452;&#21512;&#65292;&#24182;&#19988;&#21487;&#20197;&#29992;&#20110;&#36817;&#20284;&#36825;&#20004;&#20010;&#23494;&#24230;&#30340;&#27604;&#29575;&#12290;&#36825;&#20010;&#27169;&#25311;&#21644;&#20998;&#31867;&#25216;&#26415;&#20043;&#38388;&#30340;&#26725;&#26753;&#20351;&#25105;&#20204;&#33021;&#22815;&#25552;&#20986;&#20165;&#22522;&#20110;&#26631;&#35760;&#35757;&#32451;&#25968;&#25454;&#38598;&#26500;&#24314;&#30340;&#65288;&#36817;&#20284;&#65289;pdf&#27604;&#29575;&#30340;&#27169;&#25311;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Acceptance-rejection (AR), Independent Metropolis Hastings (IMH) or importance sampling (IS) Monte Carlo (MC) simulation algorithms all involve computing ratios of probability density functions (pdfs). On the other hand, classifiers discriminate labellized samples produced by a mixture density model, i.e., a convex linear combination of two pdfs, and can thus be used for approximating the ratio of these two densities. This bridge between simulation and classification techniques enables us to propose (approximate) pdf-ratios-based simulation algorithms which are built only from a labellized training data set.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#35745;&#26694;&#26550;&#65292;&#36890;&#36807;&#20998;&#26512;&#35821;&#35328;&#27169;&#22411;&#30340;&#20132;&#21449;&#29109;&#25439;&#22833;&#19982;&#22522;&#26412;&#35821;&#35328;&#20219;&#21153;&#30340;&#33021;&#21147;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25581;&#31034;&#20102;&#35821;&#35328;&#27169;&#22411;&#20013;&#22797;&#26434;&#25216;&#33021;&#20135;&#29983;&#30340;&#26426;&#21046;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#25193;&#23637;&#23450;&#24459;&#65292;&#39044;&#35757;&#32451;&#27169;&#22411;&#33021;&#22815;&#39640;&#25928;&#23398;&#20064;&#65292;&#24182;&#34920;&#29616;&#20986;&#36829;&#21453;&#36890;&#24120;&#27867;&#21270;&#29702;&#35770;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.15936</link><description>&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#20013;&#22797;&#26434;&#25216;&#33021;&#20135;&#29983;&#30340;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
A Theory for Emergence of Complex Skills in Language Models. (arXiv:2307.15936v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15936
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#35745;&#26694;&#26550;&#65292;&#36890;&#36807;&#20998;&#26512;&#35821;&#35328;&#27169;&#22411;&#30340;&#20132;&#21449;&#29109;&#25439;&#22833;&#19982;&#22522;&#26412;&#35821;&#35328;&#20219;&#21153;&#30340;&#33021;&#21147;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25581;&#31034;&#20102;&#35821;&#35328;&#27169;&#22411;&#20013;&#22797;&#26434;&#25216;&#33021;&#20135;&#29983;&#30340;&#26426;&#21046;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#25193;&#23637;&#23450;&#24459;&#65292;&#39044;&#35757;&#32451;&#27169;&#22411;&#33021;&#22815;&#39640;&#25928;&#23398;&#20064;&#65292;&#24182;&#34920;&#29616;&#20986;&#36829;&#21453;&#36890;&#24120;&#27867;&#21270;&#29702;&#35770;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#35821;&#35328;&#27169;&#22411;&#30340;&#21442;&#25968;&#38598;&#21512;&#21644;&#35757;&#32451;&#35821;&#26009;&#24211;&#25193;&#22823;&#26102;&#65292;&#26032;&#30340;&#25216;&#33021;&#23558;&#22312; AI &#20135;&#21697;&#20013;&#20986;&#29616;&#30340;&#20027;&#35201;&#39537;&#21160;&#22240;&#32032;&#12290;&#36825;&#31181;&#29616;&#35937;&#23578;&#19981;&#20026;&#20154;&#25152;&#29702;&#35299;&#65292;&#24182;&#19988;&#36890;&#36807;&#23545;&#22522;&#20110;&#26799;&#24230;&#35757;&#32451;&#30340;&#25968;&#23398;&#20998;&#26512;&#25552;&#20379;&#26426;&#26800;&#35299;&#37322;&#20284;&#20046;&#24456;&#22256;&#38590;&#12290;&#26412;&#25991;&#37319;&#29992;&#19981;&#21516;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#33879;&#21517;&#30340;&#65288;&#21644;&#32463;&#39564;&#24615;&#30340;&#65289;LLM&#25193;&#23637;&#23450;&#24459;&#21644;&#31616;&#21333;&#30340;&#32479;&#35745;&#26694;&#26550;&#26469;&#20998;&#26512;&#20986;&#29616;&#12290;&#36129;&#29486;&#21253;&#25324;&#65306;&#65288;a&#65289;&#19968;&#20010;&#32479;&#35745;&#26694;&#26550;&#23558;LLM&#30340;&#20132;&#21449;&#29109;&#25439;&#22833;&#19982;&#35821;&#35328;&#20219;&#21153;&#22522;&#26412;&#25216;&#33021;&#30340;&#33021;&#21147;&#30456;&#20851;&#32852;&#12290;&#65288;b&#65289;&#25968;&#23398;&#20998;&#26512;&#34920;&#26126;&#65292;&#25193;&#23637;&#23450;&#24459;&#24847;&#21619;&#30528;&#24378;&#28872;&#30340;&#24402;&#32435;&#20559;&#35265;&#65292;&#20351;&#39044;&#35757;&#32451;&#27169;&#22411;&#33021;&#22815;&#23398;&#20064;&#24471;&#38750;&#24120;&#39640;&#25928;&#12290;&#25105;&#20204;&#38750;&#27491;&#24335;&#22320;&#31216;&#20043;&#20026;&#8220;&#24377;&#24339;&#27867;&#21270;&#8221;&#65292;&#22240;&#20026;&#34920;&#38754;&#19978;&#30475;&#65292;&#23427;&#20284;&#20046;&#25552;&#20379;&#20102;&#22312;&#25216;&#33021;&#27700;&#24179;&#19978;&#36829;&#21453;&#36890;&#24120;&#27867;&#21270;&#29702;&#35770;&#30340;&#33021;&#21147;&#12290;&#65288;c&#65289;&#24377;&#24339;&#27867;&#21270;&#30340;&#19968;&#20010;&#20851;&#38190;&#20363;&#23376;&#65292;&#21363;&#22312;&#25191;&#34892;&#20219;&#21153;&#26102;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
A major driver of AI products today is the fact that new skills emerge in language models when their parameter set and training corpora are scaled up. This phenomenon is poorly understood, and a mechanistic explanation via mathematical analysis of gradient-based training seems difficult. The current paper takes a different approach, analysing emergence using the famous (and empirical) Scaling Laws of LLMs and a simple statistical framework. Contributions include: (a) A statistical framework that relates cross-entropy loss of LLMs to competence on the basic skills that underlie language tasks. (b) Mathematical analysis showing that the Scaling Laws imply a strong form of inductive bias that allows the pre-trained model to learn very efficiently. We informally call this {\em slingshot generalization} since naively viewed it appears to give competence levels at skills that violate usual generalization theory. (c) A key example of slingshot generalization, that competence at executing task
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#22522;&#20110;IRT&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;&#31639;&#27861;&#32452;&#21512;&#22312;&#25968;&#25454;&#38598;&#20179;&#24211;&#20013;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#33719;&#21462;&#31639;&#27861;&#19968;&#33268;&#24615;&#21644;&#24322;&#24120;&#24615;&#31561;&#29305;&#24449;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#23545;&#20256;&#32479;IRT&#27169;&#22411;&#36827;&#34892;&#20498;&#36716;&#21644;&#37325;&#26032;&#35299;&#37322;&#26469;&#23454;&#29616;&#65292;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#25968;&#25454;&#38598;&#29305;&#24449;&#35745;&#31639;&#12290;</title><link>http://arxiv.org/abs/2307.15850</link><description>&lt;p&gt;
&#20351;&#29992;&#39033;&#30446;&#21453;&#24212;&#29702;&#35770;&#23545;&#32508;&#21512;&#31639;&#27861;&#32452;&#21512;&#36827;&#34892;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Comprehensive Algorithm Portfolio Evaluation using Item Response Theory. (arXiv:2307.15850v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15850
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#22522;&#20110;IRT&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;&#31639;&#27861;&#32452;&#21512;&#22312;&#25968;&#25454;&#38598;&#20179;&#24211;&#20013;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#33719;&#21462;&#31639;&#27861;&#19968;&#33268;&#24615;&#21644;&#24322;&#24120;&#24615;&#31561;&#29305;&#24449;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#23545;&#20256;&#32479;IRT&#27169;&#22411;&#36827;&#34892;&#20498;&#36716;&#21644;&#37325;&#26032;&#35299;&#37322;&#26469;&#23454;&#29616;&#65292;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#25968;&#25454;&#38598;&#29305;&#24449;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39033;&#30446;&#21453;&#24212;&#29702;&#35770;&#65288;IRT&#65289;&#34987;&#25552;&#20986;&#29992;&#20110;&#25945;&#32946;&#24515;&#29702;&#27979;&#37327;&#23398;&#39046;&#22495;&#65292;&#29992;&#20110;&#35780;&#20272;&#23398;&#29983;&#33021;&#21147;&#12289;&#27979;&#35797;&#39064;&#38590;&#24230;&#21644;&#21306;&#20998;&#24230;&#12290;&#26368;&#36817;&#65292;IRT&#24050;&#34987;&#24212;&#29992;&#20110;&#35780;&#20272;&#21333;&#20010;&#20998;&#31867;&#25968;&#25454;&#38598;&#19978;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#24615;&#33021;&#65292;&#20854;&#20013;&#23398;&#29983;&#29616;&#22312;&#26159;&#19968;&#20010;&#31639;&#27861;&#65292;&#32780;&#27979;&#35797;&#39064;&#26159;&#31639;&#27861;&#35201;&#23545;&#35266;&#23519;&#32467;&#26524;&#36827;&#34892;&#20998;&#31867;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#22522;&#20110;IRT&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;&#19968;&#20010;&#31639;&#27861;&#32452;&#21512;&#22312;&#19968;&#20010;&#25968;&#25454;&#38598;&#20179;&#24211;&#20013;&#30340;&#34920;&#29616;&#65292;&#21516;&#26102;&#33719;&#21462;&#31639;&#27861;&#19968;&#33268;&#24615;&#21644;&#24322;&#24120;&#24615;&#31561;&#26356;&#20016;&#23500;&#30340;&#29305;&#24449;&#65292;&#36825;&#20123;&#29305;&#24449;&#25551;&#36848;&#20102;&#31639;&#27861;&#24615;&#33021;&#30340;&#37325;&#35201;&#26041;&#38754;&#12290;&#36825;&#20123;&#29305;&#24449;&#26159;&#36890;&#36807;&#23545;&#20256;&#32479;IRT&#27169;&#22411;&#36827;&#34892;&#26032;&#39062;&#30340;&#20498;&#36716;&#21644;&#37325;&#26032;&#35299;&#37322;&#32780;&#24471;&#21040;&#30340;&#65292;&#32780;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#25968;&#25454;&#38598;&#29305;&#24449;&#35745;&#31639;&#12290;&#25105;&#20204;&#23545;&#19981;&#21516;&#24212;&#29992;&#30340;&#31639;&#27861;&#32452;&#21512;&#22312;&#35813;&#26694;&#26550;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#35777;&#26126;&#20102;&#20854;&#24191;&#27867;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Item Response Theory (IRT) has been proposed within the field of Educational Psychometrics to assess student ability as well as test question difficulty and discrimination power. More recently, IRT has been applied to evaluate machine learning algorithm performance on a single classification dataset, where the student is now an algorithm, and the test question is an observation to be classified by the algorithm. In this paper we present a modified IRT-based framework for evaluating a portfolio of algorithms across a repository of datasets, while simultaneously eliciting a richer suite of characteristics such as algorithm consistency and anomalousness - that describe important aspects of algorithm performance. These characteristics arise from a novel inversion and reinterpretation of the traditional IRT model without requiring additional dataset feature computations. We test this framework on algorithm portfolios for a wide range of applications, demonstrating the broad applicability 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#25968;&#25454;&#24322;&#36136;&#24615;&#20013;&#20445;&#25345;&#29992;&#25143;&#32423;&#38544;&#31169;&#30340;&#22343;&#20540;&#20272;&#35745;&#26041;&#27861;&#65292;&#20801;&#35768;&#29992;&#25143;&#25968;&#25454;&#22312;&#20998;&#24067;&#21644;&#25968;&#37327;&#19978;&#30340;&#24046;&#24322;&#65292;&#24182;&#35777;&#26126;&#20102;&#20272;&#35745;&#22120;&#30340;&#28176;&#36817;&#26368;&#20248;&#24615;&#21644;&#21487;&#36798;&#21040;&#30340;&#35823;&#24046;&#19979;&#30028;&#12290;</title><link>http://arxiv.org/abs/2307.15835</link><description>&lt;p&gt;
&#22312;&#25968;&#25454;&#24322;&#36136;&#24615;&#20013;&#20445;&#25345;&#29992;&#25143;&#32423;&#38544;&#31169;&#30340;&#22343;&#20540;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Mean Estimation with User-level Privacy under Data Heterogeneity. (arXiv:2307.15835v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15835
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#25968;&#25454;&#24322;&#36136;&#24615;&#20013;&#20445;&#25345;&#29992;&#25143;&#32423;&#38544;&#31169;&#30340;&#22343;&#20540;&#20272;&#35745;&#26041;&#27861;&#65292;&#20801;&#35768;&#29992;&#25143;&#25968;&#25454;&#22312;&#20998;&#24067;&#21644;&#25968;&#37327;&#19978;&#30340;&#24046;&#24322;&#65292;&#24182;&#35777;&#26126;&#20102;&#20272;&#35745;&#22120;&#30340;&#28176;&#36817;&#26368;&#20248;&#24615;&#21644;&#21487;&#36798;&#21040;&#30340;&#35823;&#24046;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#35768;&#22810;&#29616;&#20195;&#25968;&#25454;&#20998;&#26512;&#20219;&#21153;&#38754;&#20020;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#26159;&#29992;&#25143;&#25968;&#25454;&#30340;&#24322;&#36136;&#24615;&#12290;&#19981;&#21516;&#30340;&#29992;&#25143;&#21487;&#33021;&#25317;&#26377;&#25130;&#28982;&#19981;&#21516;&#25968;&#37327;&#30340;&#25968;&#25454;&#28857;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#19981;&#33021;&#20551;&#35774;&#25152;&#26377;&#29992;&#25143;&#20174;&#30456;&#21516;&#30340;&#24213;&#23618;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#20363;&#22914;&#65292;&#22312;&#35821;&#35328;&#25968;&#25454;&#20013;&#65292;&#19981;&#21516;&#30340;&#35821;&#38899;&#39118;&#26684;&#23548;&#33268;&#20102;&#25968;&#25454;&#30340;&#24322;&#36136;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#24322;&#36136;&#29992;&#25143;&#25968;&#25454;&#27169;&#22411;&#65292;&#20801;&#35768;&#29992;&#25143;&#25968;&#25454;&#22312;&#20998;&#24067;&#21644;&#25968;&#37327;&#19978;&#30340;&#24046;&#24322;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#22312;&#20445;&#25345;&#29992;&#25143;&#32423;&#24046;&#20998;&#38544;&#31169;&#30340;&#21516;&#26102;&#20272;&#35745;&#20154;&#21475;&#22343;&#20540;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#30340;&#28176;&#36817;&#26368;&#20248;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#25105;&#20204;&#24341;&#20837;&#30340;&#35774;&#32622;&#20013;&#21487;&#20197;&#36798;&#21040;&#30340;&#35823;&#24046;&#30340;&#19968;&#33324;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
A key challenge in many modern data analysis tasks is that user data are heterogeneous. Different users may possess vastly different numbers of data points. More importantly, it cannot be assumed that all users sample from the same underlying distribution. This is true, for example in language data, where different speech styles result in data heterogeneity. In this work we propose a simple model of heterogeneous user data that allows user data to differ in both distribution and quantity of data, and provide a method for estimating the population-level mean while preserving user-level differential privacy. We demonstrate asymptotic optimality of our estimator and also prove general lower bounds on the error achievable in the setting we introduce.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#20998;&#24067;&#23545;&#31216;&#24615;&#30340;&#38750;&#21442;&#25968;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#23545;&#31216;&#24615;&#30340;&#25968;&#25454;&#38598;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#26041;&#27861;&#22312;&#32039;&#33268;&#32676;&#20316;&#29992;&#19979;&#27979;&#35797;&#36793;&#38469;&#25110;&#32852;&#21512;&#20998;&#24067;&#30340;&#19981;&#21464;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26131;&#20110;&#23454;&#26045;&#30340;&#26465;&#20214;&#33945;&#29305;&#21345;&#32599;&#26816;&#39564;&#12290;</title><link>http://arxiv.org/abs/2307.15834</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;&#20551;&#35774;&#26816;&#39564;&#23545;&#20998;&#37197;&#32676;&#23545;&#31216;&#24615;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Non-parametric Hypothesis Tests for Distributional Group Symmetry. (arXiv:2307.15834v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15834
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#20998;&#24067;&#23545;&#31216;&#24615;&#30340;&#38750;&#21442;&#25968;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#23545;&#31216;&#24615;&#30340;&#25968;&#25454;&#38598;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#26041;&#27861;&#22312;&#32039;&#33268;&#32676;&#20316;&#29992;&#19979;&#27979;&#35797;&#36793;&#38469;&#25110;&#32852;&#21512;&#20998;&#24067;&#30340;&#19981;&#21464;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26131;&#20110;&#23454;&#26045;&#30340;&#26465;&#20214;&#33945;&#29305;&#21345;&#32599;&#26816;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#31216;&#24615;&#22312;&#31185;&#23398;&#12289;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#23398;&#20013;&#36215;&#30528;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#23545;&#20110;&#24050;&#30693;&#36981;&#24490;&#23545;&#31216;&#24615;&#30340;&#25968;&#25454;&#65292;&#24050;&#32463;&#24320;&#21457;&#20986;&#20102;&#35768;&#22810;&#21033;&#29992;&#23545;&#31216;&#24615;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#26222;&#36941;&#32676;&#23545;&#31216;&#24615;&#30340;&#23384;&#22312;&#25110;&#19981;&#23384;&#22312;&#30340;&#32479;&#35745;&#26816;&#39564;&#20960;&#20046;&#19981;&#23384;&#22312;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#22522;&#20110;&#21333;&#20010;&#29420;&#31435;&#21516;&#20998;&#24067;&#26679;&#26412;&#65292;&#29992;&#20110;&#38024;&#23545;&#29305;&#23450;&#32676;&#30340;&#20998;&#24067;&#23545;&#31216;&#24615;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#36866;&#29992;&#20110;&#20004;&#31181;&#24191;&#27867;&#24773;&#20917;&#30340;&#23545;&#31216;&#24615;&#26816;&#39564;&#30340;&#19968;&#33324;&#20844;&#24335;&#12290;&#31532;&#19968;&#31181;&#24773;&#20917;&#26159;&#27979;&#35797;&#22312;&#32039;&#33268;&#32676;&#20316;&#29992;&#19979;&#30340;&#36793;&#38469;&#25110;&#32852;&#21512;&#20998;&#24067;&#30340;&#19981;&#21464;&#24615;&#12290;&#22312;&#36825;&#37324;&#65292;&#19968;&#20010;&#28176;&#36817;&#26080;&#20559;&#30340;&#26816;&#39564;&#21482;&#38656;&#35201;&#19968;&#20010;&#21487;&#35745;&#31639;&#30340;&#27010;&#29575;&#20998;&#24067;&#31354;&#38388;&#19978;&#30340;&#24230;&#37327;&#21644;&#33021;&#22815;&#22343;&#21248;&#38543;&#26426;&#37319;&#26679;&#32676;&#20803;&#32032;&#30340;&#33021;&#21147;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26131;&#20110;&#23454;&#26045;&#30340;&#26465;&#20214;&#33945;&#29305;&#21345;&#32599;&#26816;&#39564;&#65292;&#24182;&#35777;&#26126;&#23427;&#21487;&#20197;&#23454;&#29616;&#31934;&#30830;&#30340;p&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Symmetry plays a central role in the sciences, machine learning, and statistics. For situations in which data are known to obey a symmetry, a multitude of methods that exploit symmetry have been developed. Statistical tests for the presence or absence of general group symmetry, however, are largely non-existent. This work formulates non-parametric hypothesis tests, based on a single independent and identically distributed sample, for distributional symmetry under a specified group. We provide a general formulation of tests for symmetry that apply to two broad settings. The first setting tests for the invariance of a marginal or joint distribution under the action of a compact group. Here, an asymptotically unbiased test only requires a computable metric on the space of probability distributions and the ability to sample uniformly random group elements. Building on this, we propose an easy-to-implement conditional Monte Carlo test and prove that it achieves exact $p$-values with finitel
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#26368;&#20248;&#27969;&#24418;&#27010;&#24565;&#23558;&#26367;&#20195;&#27169;&#22411;&#21644;&#37325;&#35201;&#24615;&#37319;&#26679;&#26041;&#27861;&#32852;&#31995;&#36215;&#26469;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#39640;&#32500;SRAM&#35780;&#20272;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21517;&#20026;OPTIMIS&#65292;&#32467;&#21512;&#20102;&#31070;&#32463;&#32806;&#21512;&#27969;&#21644;&#27915;&#33905;&#37319;&#26679;&#65292;&#22312;&#20445;&#25345;&#24615;&#33021;&#20248;&#21183;&#30340;&#21516;&#26102;&#20855;&#22791;&#40065;&#26834;&#24615;&#21644;&#19968;&#33268;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.15773</link><description>&lt;p&gt;
&#23547;&#27714;&#25910;&#30410;&#22721;&#22418;&#65306;&#36890;&#36807;&#26368;&#20248;&#27969;&#24418;&#36827;&#34892;&#39640;&#32500;SRAM&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Seeking the Yield Barrier: High-Dimensional SRAM Evaluation Through Optimal Manifold. (arXiv:2307.15773v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15773
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#26368;&#20248;&#27969;&#24418;&#27010;&#24565;&#23558;&#26367;&#20195;&#27169;&#22411;&#21644;&#37325;&#35201;&#24615;&#37319;&#26679;&#26041;&#27861;&#32852;&#31995;&#36215;&#26469;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#39640;&#32500;SRAM&#35780;&#20272;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21517;&#20026;OPTIMIS&#65292;&#32467;&#21512;&#20102;&#31070;&#32463;&#32806;&#21512;&#27969;&#21644;&#27915;&#33905;&#37319;&#26679;&#65292;&#22312;&#20445;&#25345;&#24615;&#33021;&#20248;&#21183;&#30340;&#21516;&#26102;&#20855;&#22791;&#40065;&#26834;&#24615;&#21644;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#27169;&#22411;&#30005;&#36335;&#23558;&#35268;&#27169;&#32553;&#23567;&#21040;&#20122;&#24494;&#31859;&#32423;&#21035;&#30340;&#20808;&#36827;&#25216;&#26415;&#33410;&#28857;&#65292;&#26377;&#25928;&#33719;&#24471;SRAM&#32452;&#20214;&#25925;&#38556;&#27010;&#29575;&#30340;&#20934;&#30830;&#20272;&#35745;&#24050;&#25104;&#20026;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#32463;&#20856;&#30340;&#33539;&#25968;&#26368;&#23567;&#21270;&#26041;&#27861;&#65292;&#24182;&#25512;&#24191;&#20102;&#23427;&#20197;&#36866;&#29992;&#20110;&#26080;&#38480;&#32452;&#20214;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#39062;&#30340;&#26368;&#20248;&#27969;&#24418;&#27010;&#24565;&#65292;&#23558;&#22522;&#20110;&#26367;&#20195;&#27169;&#22411;&#21644;&#37325;&#35201;&#24615;&#37319;&#26679;&#65288;IS&#65289;&#30340;&#20135;&#37327;&#20272;&#35745;&#26041;&#27861;&#32852;&#31995;&#36215;&#26469;&#12290;&#25509;&#30528;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#27425;&#20248;&#27969;&#24418;&#65292;&#26368;&#20248;&#36229;&#29699;&#20307;&#65292;&#23427;&#24341;&#23548;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#37319;&#26679;&#26041;&#27861;&#65292;&#33021;&#22815;&#35782;&#21035;&#21040;&#25925;&#38556;&#36793;&#30028;&#65292;&#31216;&#20026;&#27915;&#33905;&#37319;&#26679;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#31070;&#32463;&#32806;&#21512;&#27969;&#20316;&#20026;&#37325;&#35201;&#24615;&#37319;&#26679;&#30340;&#25552;&#35758;&#20998;&#24067;&#65292;&#35813;&#20998;&#24067;&#31867;&#20284;&#20110;&#26367;&#20195;&#27169;&#22411;&#20174;&#26679;&#26412;&#20013;&#23398;&#20064;&#12290;&#36825;&#20123;&#32452;&#21512;&#20135;&#29983;&#20102;&#19968;&#31181;&#21517;&#20026;"&#20248;&#21270;&#27969;&#24418;&#37325;&#35201;&#24615;&#37319;&#26679;"&#65288;OPTIMIS&#65289;&#30340;&#26032;&#22411;&#20135;&#37327;&#20272;&#35745;&#26041;&#27861;&#65292;&#23427;&#20445;&#25345;&#20102;&#26367;&#20195;&#27169;&#22411;&#21644;&#37325;&#35201;&#24615;&#37319;&#26679;&#26041;&#27861;&#30340;&#20248;&#28857;&#65292;&#20855;&#26377;&#24378;&#38887;&#24615;&#21644;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Being able to efficiently obtain an accurate estimate of the failure probability of SRAM components has become a central issue as model circuits shrink their scale to submicrometer with advanced technology nodes. In this work, we revisit the classic norm minimization method. We then generalize it with infinite components and derive the novel optimal manifold concept, which bridges the surrogate-based and importance sampling (IS) yield estimation methods. We then derive a sub-optimal manifold, optimal hypersphere, which leads to an efficient sampling method being aware of the failure boundary called onion sampling. Finally, we use a neural coupling flow (which learns from samples like a surrogate model) as the IS proposal distribution. These combinations give rise to a novel yield estimation method, named Optimal Manifold Important Sampling (OPTIMIS), which keeps the advantages of the surrogate and IS methods to deliver state-of-the-art performance with robustness and consistency, with 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#30028;&#22495;&#19978;&#36890;&#36807;&#21333;&#38544;&#34255;&#23618;ReLU&#32593;&#32476;&#36924;&#36817;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#20171;&#32461;&#20102;&#26032;&#30340;&#27169;&#22411;&#31867;&#23450;&#20041;&#21152;&#26435;&#21464;&#24046;&#31354;&#38388;&#65292;&#35813;&#23450;&#20041;&#19982;&#22495;&#26412;&#36523;&#30456;&#20851;&#12290;</title><link>http://arxiv.org/abs/2307.15772</link><description>&lt;p&gt;
&#21152;&#26435;&#21464;&#24046;&#31354;&#38388;&#19982;&#27973;&#23618;ReLU&#32593;&#32476;&#30340;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Weighted variation spaces and approximation by shallow ReLU networks. (arXiv:2307.15772v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15772
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#30028;&#22495;&#19978;&#36890;&#36807;&#21333;&#38544;&#34255;&#23618;ReLU&#32593;&#32476;&#36924;&#36817;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#20171;&#32461;&#20102;&#26032;&#30340;&#27169;&#22411;&#31867;&#23450;&#20041;&#21152;&#26435;&#21464;&#24046;&#31354;&#38388;&#65292;&#35813;&#23450;&#20041;&#19982;&#22495;&#26412;&#36523;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#30028;&#22495;&#937;&#8834;Rd&#19978;&#65292;&#36890;&#36807;&#23485;&#24230;&#20026;n&#30340;&#21333;&#38544;&#34255;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20986;&#26469;&#36924;&#36817;&#20989;&#25968;f&#30340;&#24773;&#20917;&#12290;&#36825;&#31181;&#38750;&#32447;&#24615;&#30340;n&#39033;&#23383;&#20856;&#36924;&#36817;&#24050;&#32463;&#24471;&#21040;&#24191;&#27867;&#30740;&#31350;&#65292;&#22240;&#20026;&#23427;&#26159;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;(NNA)&#30340;&#26368;&#31616;&#21333;&#24773;&#20917;&#12290;&#23545;&#20110;&#36825;&#31181;NNA&#24418;&#24335;&#65292;&#26377;&#20960;&#20010;&#33879;&#21517;&#30340;&#36924;&#36817;&#32467;&#26524;&#65292;&#24341;&#20837;&#20102;&#22312;&#937;&#19978;&#30340;&#20989;&#25968;&#30340;&#26032;&#22411;&#27169;&#22411;&#31867;&#65292;&#20854;&#36924;&#36817;&#36895;&#29575;&#36991;&#20813;&#20102;&#32500;&#25968;&#28798;&#38590;&#12290;&#36825;&#20123;&#26032;&#22411;&#27169;&#22411;&#31867;&#21253;&#25324;Barron&#31867;&#21644;&#22522;&#20110;&#31232;&#30095;&#24615;&#25110;&#21464;&#24046;&#30340;&#31867;&#65292;&#20363;&#22914;Radon&#22495;BV&#31867;&#12290;&#26412;&#25991;&#20851;&#27880;&#20110;&#22312;&#22495;&#937;&#19978;&#23450;&#20041;&#36825;&#20123;&#26032;&#22411;&#27169;&#22411;&#31867;&#12290;&#24403;&#21069;&#36825;&#20123;&#27169;&#22411;&#31867;&#30340;&#23450;&#20041;&#19981;&#20381;&#36182;&#20110;&#22495;&#937;&#12290;&#36890;&#36807;&#24341;&#20837;&#21152;&#26435;&#21464;&#24046;&#31354;&#38388;&#30340;&#27010;&#24565;&#65292;&#32473;&#20986;&#20102;&#20851;&#20110;&#22495;&#30340;&#26356;&#24688;&#24403;&#30340;&#27169;&#22411;&#31867;&#23450;&#20041;&#12290;&#36825;&#20123;&#26032;&#22411;&#27169;&#22411;&#31867;&#19982;&#22495;&#26412;&#36523;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the approximation of functions $f$ on a bounded domain $\Omega\subset \mathbb{R}^d$ by the outputs of single-hidden-layer ReLU neural networks of width $n$. This form of nonlinear $n$-term dictionary approximation has been intensely studied since it is the simplest case of neural network approximation (NNA). There are several celebrated approximation results for this form of NNA that introduce novel model classes of functions on $\Omega$ whose approximation rates avoid the curse of dimensionality. These novel classes include Barron classes, and classes based on sparsity or variation such as the Radon-domain BV classes.  The present paper is concerned with the definition of these novel model classes on domains $\Omega$. The current definition of these model classes does not depend on the domain $\Omega$. A new and more proper definition of model classes on domains is given by introducing the concept of weighted variation spaces. These new model classes are intrinsic to th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#30740;&#31350;&#20102;&#22312;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#20013;&#27169;&#20223;&#22797;&#26434;&#19987;&#23478;&#28436;&#31034;&#30340;&#34892;&#20026;&#12290;&#36890;&#36807;&#31283;&#23450;&#27169;&#20223;&#31574;&#30053;&#24182;&#30830;&#20445;&#20934;&#30830;&#20272;&#35745;&#28436;&#31034;&#32773;&#20998;&#24067;&#65292;&#21487;&#20197;&#20351;&#27169;&#20223;&#32773;&#19982;&#28436;&#31034;&#32773;&#30340;&#36712;&#36857;&#20998;&#24067;&#30456;&#36817;&#12290;</title><link>http://arxiv.org/abs/2307.14619</link><description>&lt;p&gt;
&#27169;&#20223;&#22797;&#26434;&#36712;&#36857;&#65306;&#26725;&#25509;&#20302;&#23618;&#31283;&#23450;&#24615;&#19982;&#39640;&#23618;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Imitating Complex Trajectories: Bridging Low-Level Stability and High-Level Behavior. (arXiv:2307.14619v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14619
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#30740;&#31350;&#20102;&#22312;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#20013;&#27169;&#20223;&#22797;&#26434;&#19987;&#23478;&#28436;&#31034;&#30340;&#34892;&#20026;&#12290;&#36890;&#36807;&#31283;&#23450;&#27169;&#20223;&#31574;&#30053;&#24182;&#30830;&#20445;&#20934;&#30830;&#20272;&#35745;&#28436;&#31034;&#32773;&#20998;&#24067;&#65292;&#21487;&#20197;&#20351;&#27169;&#20223;&#32773;&#19982;&#28436;&#31034;&#32773;&#30340;&#36712;&#36857;&#20998;&#24067;&#30456;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#30740;&#31350;&#22312;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#20013;&#27169;&#20223;&#38543;&#26426;&#12289;&#38750;&#39532;&#23572;&#21487;&#22827;&#12289;&#28508;&#22312;&#22810;&#27169;&#24577;&#65288;&#21363;&#8220;&#22797;&#26434;&#8221;&#65289;&#19987;&#23478;&#28436;&#31034;&#30340;&#34892;&#20026;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#20351;&#29992;&#20302;&#23618;&#25511;&#21046;&#22120;&#65288;&#26080;&#35770;&#26159;&#23398;&#20064;&#30340;&#36824;&#26159;&#38544;&#21547;&#30340;&#65289;&#26469;&#31283;&#23450;&#22260;&#32469;&#19987;&#23478;&#28436;&#31034;&#30340;&#27169;&#20223;&#31574;&#30053;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#65288;a&#65289;&#21512;&#36866;&#30340;&#20302;&#23618;&#31283;&#23450;&#24615;&#20445;&#35777;&#21644;&#65288;b&#65289;&#23398;&#20064;&#31574;&#30053;&#30340;&#38543;&#26426;&#36830;&#32493;&#24615;&#23646;&#24615;&#65288;&#25105;&#20204;&#31216;&#20043;&#20026;&#8220;&#24635;&#21464;&#24046;&#36830;&#32493;&#24615;&#8221;&#65289;&#65288;TVC&#65289;&#30340;&#24773;&#20917;&#19979;&#65292;&#19968;&#20010;&#31934;&#30830;&#20272;&#35745;&#28436;&#31034;&#32773;&#29366;&#24577;&#20998;&#24067;&#19978;&#30340;&#34892;&#21160;&#30340;&#27169;&#20223;&#32773;&#20250;&#19982;&#28436;&#31034;&#32773;&#23545;&#25972;&#20010;&#36712;&#36857;&#30340;&#20998;&#24067;&#30456;&#36817;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#21487;&#20197;&#36890;&#36807;&#23558;&#27969;&#34892;&#30340;&#25968;&#25454;&#22686;&#24378;&#35268;&#21017;&#19982;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#25216;&#24039;&#30456;&#32467;&#21512;&#65288;&#21363;&#22312;&#25191;&#34892;&#26102;&#28155;&#21152;&#22686;&#24378;&#22122;&#22768;&#65289;&#26469;&#30830;&#20445;TVC&#24182;&#19988;&#26368;&#23567;&#31243;&#24230;&#19978;&#38477;&#20302;&#31934;&#24230;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#20445;&#35777;&#23454;&#20363;&#21270;&#20026;&#30001;&#25193;&#25955;&#27169;&#22411;&#21442;&#25968;&#21270;&#30340;&#31574;&#30053;&#65292;&#24182;&#35777;&#26126;&#22914;&#26524;&#23398;&#20064;&#32773;&#20934;&#30830;&#22320;&#20272;&#35745;&#20102;&#28436;&#31034;&#32773;&#30340;&#20998;&#24067;&#65292;&#21017;&#26368;&#32456;&#23436;&#25104;&#36825;&#31181;&#23454;&#20363;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a theoretical framework for studying the imitation of stochastic, non-Markovian, potentially multi-modal (i.e. "complex" ) expert demonstrations in nonlinear dynamical systems. Our framework invokes low-level controllers either learned or implicit in position-command control - to stabilize imitation policies around expert demonstrations. We show that with (a) a suitable low-level stability guarantee and (b) a stochastic continuity property of the learned policy we call "total variation continuity" (TVC), an imitator that accurately estimates actions on the demonstrator's state distribution closely matches the demonstrator's distribution over entire trajectories. We then show that TVC can be ensured with minimal degradation of accuracy by combining a popular data-augmentation regimen with a novel algorithmic trick: adding augmentation noise at execution time. We instantiate our guarantees for policies parameterized by diffusion models and prove that if the learner accuratel
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#24515;&#34880;&#31649;&#27169;&#22411;&#30340;&#36870;&#38382;&#39064;&#20316;&#20026;&#32479;&#35745;&#25512;&#29702;&#36827;&#34892;&#35299;&#20915;&#65292;&#22312;&#20307;&#22806;&#36827;&#34892;&#20102;&#20116;&#20010;&#29983;&#29289;&#26631;&#35760;&#29289;&#30340;&#19981;&#30830;&#23450;&#24615;&#20998;&#26512;&#65292;&#23637;&#31034;&#20102;&#27169;&#25311;&#25512;&#29702;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.13918</link><description>&lt;p&gt;
&#22522;&#20110;&#27169;&#25311;&#30340;&#25512;&#29702;&#29992;&#20110;&#24515;&#34880;&#31649;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Simulation-based Inference for Cardiovascular Models. (arXiv:2307.13918v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13918
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#24515;&#34880;&#31649;&#27169;&#22411;&#30340;&#36870;&#38382;&#39064;&#20316;&#20026;&#32479;&#35745;&#25512;&#29702;&#36827;&#34892;&#35299;&#20915;&#65292;&#22312;&#20307;&#22806;&#36827;&#34892;&#20102;&#20116;&#20010;&#29983;&#29289;&#26631;&#35760;&#29289;&#30340;&#19981;&#30830;&#23450;&#24615;&#20998;&#26512;&#65292;&#23637;&#31034;&#20102;&#27169;&#25311;&#25512;&#29702;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#30340;&#20960;&#21313;&#24180;&#20013;&#65292;&#34880;&#27969;&#21160;&#21147;&#23398;&#27169;&#25311;&#22120;&#19981;&#26029;&#21457;&#23637;&#65292;&#24050;&#25104;&#20026;&#30740;&#31350;&#20307;&#22806;&#24515;&#34880;&#31649;&#31995;&#32479;&#30340;&#39318;&#36873;&#24037;&#20855;&#12290;&#34429;&#28982;&#36825;&#26679;&#30340;&#24037;&#20855;&#36890;&#24120;&#29992;&#20110;&#20174;&#29983;&#29702;&#21442;&#25968;&#27169;&#25311;&#20840;&#36523;&#34880;&#27969;&#21160;&#21147;&#23398;&#65292;&#20294;&#35299;&#20915;&#23558;&#27874;&#24418;&#26144;&#23556;&#22238;&#21512;&#29702;&#30340;&#29983;&#29702;&#21442;&#25968;&#30340;&#36870;&#38382;&#39064;&#20173;&#28982;&#26377;&#24456;&#22823;&#30340;&#28508;&#21147;&#21644;&#25361;&#25112;&#12290;&#21463;&#27169;&#25311;&#25512;&#29702;&#65288;SBI&#65289;&#30340;&#36827;&#23637;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#36870;&#38382;&#39064;&#20316;&#20026;&#32479;&#35745;&#25512;&#29702;&#26469;&#22788;&#29702;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#19981;&#21516;&#65292;SBI&#20026;&#24863;&#20852;&#36259;&#30340;&#21442;&#25968;&#25552;&#20379;&#20102;&#21518;&#39564;&#20998;&#24067;&#65292;&#25552;&#20379;&#20102;&#20851;&#20110;&#20010;&#20307;&#27979;&#37327;&#30340;&#19981;&#30830;&#23450;&#24615;&#30340;&#22810;&#32500;&#34920;&#31034;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#27604;&#20960;&#31181;&#27979;&#37327;&#27169;&#24577;&#26469;&#23637;&#31034;&#36825;&#31181;&#33021;&#21147;&#65292;&#36827;&#34892;&#20102;&#20116;&#20010;&#20020;&#24202;&#24863;&#20852;&#36259;&#30340;&#29983;&#29289;&#26631;&#24535;&#29289;&#30340;&#20307;&#22806;&#19981;&#30830;&#23450;&#24615;&#20998;&#26512;&#12290;&#38500;&#20102;&#30830;&#35748;&#24050;&#30693;&#20107;&#23454;&#65292;&#27604;&#22914;&#20272;&#35745;&#24515;&#29575;&#30340;&#21487;&#34892;&#24615;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#36824;&#31361;&#20986;&#20102;&#8230;
&lt;/p&gt;
&lt;p&gt;
Over the past decades, hemodynamics simulators have steadily evolved and have become tools of choice for studying cardiovascular systems in-silico. While such tools are routinely used to simulate whole-body hemodynamics from physiological parameters, solving the corresponding inverse problem of mapping waveforms back to plausible physiological parameters remains both promising and challenging. Motivated by advances in simulation-based inference (SBI), we cast this inverse problem as statistical inference. In contrast to alternative approaches, SBI provides \textit{posterior distributions} for the parameters of interest, providing a \textit{multi-dimensional} representation of uncertainty for \textit{individual} measurements. We showcase this ability by performing an in-silico uncertainty analysis of five biomarkers of clinical interest comparing several measurement modalities. Beyond the corroboration of known facts, such as the feasibility of estimating heart rate, our study highlight
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#32452;&#21512;&#20998;&#24067;&#20559;&#31227;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#30697;&#38453;&#34917;&#20840;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;&#36890;&#36807;&#22312;&#29305;&#27530;&#24773;&#20917;&#19979;&#30340;&#21452;&#32447;&#24615;&#23884;&#20837;&#65292;&#23454;&#29616;&#23545;&#35757;&#32451;&#20013;&#26410;&#28085;&#30422;&#30340;&#27979;&#35797;&#20998;&#24067;&#36827;&#34892;&#22806;&#25512;&#12290;&#36825;&#20010;&#35774;&#32622;&#23558;&#32570;&#22833;&#38750;&#38543;&#26426;&#25968;&#25454;&#30340;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#24191;&#20041;&#21270;&#12290;</title><link>http://arxiv.org/abs/2307.06457</link><description>&lt;p&gt;
&#35299;&#20915;&#32452;&#21512;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65306;&#22522;&#20110;&#30697;&#38453;&#34917;&#20840;&#30340;&#35266;&#28857;
&lt;/p&gt;
&lt;p&gt;
Tackling Combinatorial Distribution Shift: A Matrix Completion Perspective. (arXiv:2307.06457v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06457
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#32452;&#21512;&#20998;&#24067;&#20559;&#31227;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#30697;&#38453;&#34917;&#20840;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;&#36890;&#36807;&#22312;&#29305;&#27530;&#24773;&#20917;&#19979;&#30340;&#21452;&#32447;&#24615;&#23884;&#20837;&#65292;&#23454;&#29616;&#23545;&#35757;&#32451;&#20013;&#26410;&#28085;&#30422;&#30340;&#27979;&#35797;&#20998;&#24067;&#36827;&#34892;&#22806;&#25512;&#12290;&#36825;&#20010;&#35774;&#32622;&#23558;&#32570;&#22833;&#38750;&#38543;&#26426;&#25968;&#25454;&#30340;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#24191;&#20041;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20998;&#24067;&#20559;&#31227;&#19979;&#33719;&#24471;&#20005;&#26684;&#30340;&#32479;&#35745;&#20445;&#35777;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#19988;&#27963;&#36291;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#31216;&#20026;&#32452;&#21512;&#20998;&#24067;&#20559;&#31227;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;(a)&#22312;&#27979;&#35797;&#21644;&#35757;&#32451;&#20998;&#24067;&#19979;&#65292;&#26631;&#31614;$z$&#30001;&#29305;&#24449;$(x,y)$&#30340;&#23545;&#20915;&#23450;&#65292;(b)&#35757;&#32451;&#20998;&#24067;&#28085;&#30422;&#20102;$x$&#21644;$y$&#20998;&#21035;&#30340;&#19968;&#23450;&#36793;&#32536;&#20998;&#24067;&#65292;&#20294;&#26159;(c)&#27979;&#35797;&#20998;&#24067;&#28041;&#21450;&#20102;&#19968;&#20010;&#22312;&#35757;&#32451;&#20998;&#24067;&#20013;&#26410;&#28085;&#30422;&#30340;$(x,y)$&#30340;&#20135;&#21697;&#20998;&#24067;&#30340;&#31034;&#20363;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#26631;&#31614;&#30001;&#21452;&#32447;&#24615;&#23884;&#20837;&#21040;Hilbert&#31354;&#38388;$H$&#20013;&#32473;&#20986;&#30340;&#29305;&#27530;&#24773;&#20917;&#65306;$\mathbb{E}[z \mid x,y ]=\langle f_{\star}(x),g_{\star}(y)\rangle_{{H}}$&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#23545;&#22312;&#35757;&#32451;&#20013;&#26410;&#28085;&#30422;&#30340;&#27979;&#35797;&#20998;&#24067;&#22495;&#36827;&#34892;&#22806;&#25512;&#65292;&#21363;&#23454;&#29616;&#21452;&#32447;&#24615;&#32452;&#21512;&#22806;&#25512;&#12290;&#25105;&#20204;&#30340;&#35774;&#32622;&#23558;&#32570;&#22833;&#38750;&#38543;&#26426;&#25968;&#25454;&#30340;&#30697;&#38453;&#34917;&#20840;&#30340;&#19968;&#20010;&#29305;&#27530;&#24773;&#20917;&#24191;&#20041;&#21270;&#65292;&#23545;&#20110;&#35813;&#24773;&#20917;&#65292;&#25152;&#26377;&#29616;&#26377;&#32467;&#26524;&#37117;&#35201;&#27714;....
&lt;/p&gt;
&lt;p&gt;
Obtaining rigorous statistical guarantees for generalization under distribution shift remains an open and active research area. We study a setting we call combinatorial distribution shift, where (a) under the test- and training-distributions, the labels $z$ are determined by pairs of features $(x,y)$, (b) the training distribution has coverage of certain marginal distributions over $x$ and $y$ separately, but (c) the test distribution involves examples from a product distribution over $(x,y)$ that is {not} covered by the training distribution. Focusing on the special case where the labels are given by bilinear embeddings into a Hilbert space $H$: $\mathbb{E}[z \mid x,y ]=\langle f_{\star}(x),g_{\star}(y)\rangle_{{H}}$, we aim to extrapolate to a test distribution domain that is $not$ covered in training, i.e., achieving bilinear combinatorial extrapolation.  Our setting generalizes a special case of matrix completion from missing-not-at-random data, for which all existing results requi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#30142;&#30149;&#36827;&#23637;&#32858;&#31867;&#20013;&#35299;&#35835;&#28145;&#24230;&#23884;&#20837;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#35780;&#20272;2&#22411;&#31958;&#23615;&#30149;&#21442;&#19982;&#32773;&#25968;&#25454;&#38598;&#23637;&#31034;&#20102;&#23545;&#30142;&#30149;&#36827;&#23637;&#27169;&#24335;&#30340;&#20020;&#24202;&#24847;&#20041;&#24615;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2307.06060</link><description>&lt;p&gt;
&#35299;&#35835;&#30142;&#30149;&#36827;&#23637;&#32858;&#31867;&#20013;&#30340;&#28145;&#24230;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Interpreting deep embeddings for disease progression clustering. (arXiv:2307.06060v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06060
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#30142;&#30149;&#36827;&#23637;&#32858;&#31867;&#20013;&#35299;&#35835;&#28145;&#24230;&#23884;&#20837;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#35780;&#20272;2&#22411;&#31958;&#23615;&#30149;&#21442;&#19982;&#32773;&#25968;&#25454;&#38598;&#23637;&#31034;&#20102;&#23545;&#30142;&#30149;&#36827;&#23637;&#27169;&#24335;&#30340;&#20020;&#24202;&#24847;&#20041;&#24615;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#24739;&#32773;&#32858;&#31867;&#30340;&#32972;&#26223;&#19979;&#35299;&#35835;&#28145;&#24230;&#23884;&#20837;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;&#26469;&#33258;&#33521;&#22269;&#29983;&#29289;&#24211;&#30340;2&#22411;&#31958;&#23615;&#30149;&#21442;&#19982;&#32773;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20986;&#23545;&#30142;&#30149;&#36827;&#23637;&#27169;&#24335;&#30340;&#20020;&#24202;&#24847;&#20041;&#24615;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel approach for interpreting deep embeddings in the context of patient clustering. We evaluate our approach on a dataset of participants with type 2 diabetes from the UK Biobank, and demonstrate clinically meaningful insights into disease progression patterns.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#32452;&#21512;&#24615;&#25968;&#25454;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#23545;&#38543;&#26426;&#23618;&#27425;&#27169;&#22411;&#36827;&#34892;&#20998;&#31867;&#20219;&#21153;&#65292;&#21457;&#29616;&#28145;&#24230;CNN&#23398;&#20064;&#36825;&#20010;&#20219;&#21153;&#25152;&#38656;&#30340;&#35757;&#32451;&#25968;&#25454;&#25968;&#37327;&#38543;&#30528;&#31867;&#21035;&#25968;&#12289;&#32452;&#21512;&#25968;&#21644;&#36845;&#20195;&#27425;&#25968;&#30340;&#22686;&#21152;&#32780;&#28176;&#36827;&#22686;&#21152;&#12290;</title><link>http://arxiv.org/abs/2307.02129</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22914;&#20309;&#23398;&#20064;&#32452;&#21512;&#24615;&#25968;&#25454;&#65306;&#38543;&#26426;&#23618;&#27425;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
How Deep Neural Networks Learn Compositional Data: The Random Hierarchy Model. (arXiv:2307.02129v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02129
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#32452;&#21512;&#24615;&#25968;&#25454;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#23545;&#38543;&#26426;&#23618;&#27425;&#27169;&#22411;&#36827;&#34892;&#20998;&#31867;&#20219;&#21153;&#65292;&#21457;&#29616;&#28145;&#24230;CNN&#23398;&#20064;&#36825;&#20010;&#20219;&#21153;&#25152;&#38656;&#30340;&#35757;&#32451;&#25968;&#25454;&#25968;&#37327;&#38543;&#30528;&#31867;&#21035;&#25968;&#12289;&#32452;&#21512;&#25968;&#21644;&#36845;&#20195;&#27425;&#25968;&#30340;&#22686;&#21152;&#32780;&#28176;&#36827;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#19968;&#33324;&#39640;&#32500;&#20219;&#21153;&#26159;&#38750;&#24120;&#22256;&#38590;&#30340;&#65292;&#22240;&#20026;&#23427;&#38656;&#35201;&#19982;&#32500;&#24230;&#25104;&#25351;&#25968;&#22686;&#38271;&#30340;&#35757;&#32451;&#25968;&#25454;&#25968;&#37327;&#12290;&#28982;&#32780;&#65292;&#28145;&#24230;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#22312;&#20811;&#26381;&#36825;&#19968;&#25361;&#25112;&#26041;&#38754;&#26174;&#31034;&#20986;&#20102;&#21331;&#36234;&#30340;&#25104;&#21151;&#12290;&#19968;&#31181;&#26222;&#36941;&#30340;&#20551;&#35774;&#26159;&#21487;&#23398;&#20064;&#20219;&#21153;&#20855;&#26377;&#39640;&#24230;&#32467;&#26500;&#21270;&#65292;CNN&#21033;&#29992;&#36825;&#31181;&#32467;&#26500;&#24314;&#31435;&#20102;&#25968;&#25454;&#30340;&#20302;&#32500;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#23545;&#23427;&#20204;&#38656;&#35201;&#22810;&#23569;&#35757;&#32451;&#25968;&#25454;&#20197;&#21450;&#36825;&#20010;&#25968;&#23383;&#22914;&#20309;&#21462;&#20915;&#20110;&#25968;&#25454;&#32467;&#26500;&#30693;&#20043;&#29978;&#23569;&#12290;&#26412;&#25991;&#22238;&#31572;&#20102;&#38024;&#23545;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#31867;&#20219;&#21153;&#30340;&#36825;&#20010;&#38382;&#39064;&#65292;&#35813;&#20219;&#21153;&#26088;&#22312;&#25429;&#25417;&#30495;&#23454;&#25968;&#25454;&#30340;&#30456;&#20851;&#26041;&#38754;&#65306;&#38543;&#26426;&#23618;&#27425;&#27169;&#22411;&#12290;&#22312;&#36825;&#20010;&#27169;&#22411;&#20013;&#65292;$n_c$&#20010;&#31867;&#21035;&#20013;&#30340;&#27599;&#19968;&#20010;&#23545;&#24212;&#20110;$m$&#20010;&#21516;&#20041;&#32452;&#21512;&#30340;&#39640;&#23618;&#27425;&#29305;&#24449;&#65292;&#24182;&#19988;&#36825;&#20123;&#29305;&#24449;&#21448;&#36890;&#36807;&#19968;&#20010;&#37325;&#22797;$L$&#27425;&#30340;&#36845;&#20195;&#36807;&#31243;&#30001;&#23376;&#29305;&#24449;&#32452;&#25104;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#38656;&#35201;&#28145;&#24230;CNN&#23398;&#20064;&#36825;&#20010;&#20219;&#21153;&#30340;&#35757;&#32451;&#25968;&#25454;&#25968;&#37327;$P^*$&#65288;i&#65289;&#38543;&#30528;$n_c m^L$&#30340;&#22686;&#38271;&#32780;&#28176;&#36827;&#22320;&#22686;&#38271;&#65292;&#36825;&#21482;&#26377;...
&lt;/p&gt;
&lt;p&gt;
Learning generic high-dimensional tasks is notably hard, as it requires a number of training data exponential in the dimension. Yet, deep convolutional neural networks (CNNs) have shown remarkable success in overcoming this challenge. A popular hypothesis is that learnable tasks are highly structured and that CNNs leverage this structure to build a low-dimensional representation of the data. However, little is known about how much training data they require, and how this number depends on the data structure. This paper answers this question for a simple classification task that seeks to capture relevant aspects of real data: the Random Hierarchy Model. In this model, each of the $n_c$ classes corresponds to $m$ synonymic compositions of high-level features, which are in turn composed of sub-features through an iterative process repeated $L$ times. We find that the number of training data $P^*$ required by deep CNNs to learn this task (i) grows asymptotically as $n_c m^L$, which is only
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#38543;&#26426;&#25237;&#24433;&#25216;&#26415;&#20248;&#21270;&#20102;Koopman&#31639;&#23376;&#30340;&#20272;&#35745;&#22120;&#65292;&#21152;&#24555;&#20102;&#35745;&#31639;&#36895;&#24230;&#65292;&#24182;&#32473;&#20986;&#20102;&#31934;&#30830;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#25552;&#39640;&#20102;&#31639;&#27861;&#30340;&#21487;&#38752;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.04520</link><description>&lt;p&gt;
&#21033;&#29992;&#33609;&#22270;&#25216;&#26415;&#20272;&#35745;Koopman&#31639;&#23376;&#24182;&#21487;&#38752;&#22320;&#23398;&#20064;&#22823;&#35268;&#27169;&#21160;&#24577;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Estimating Koopman operators with sketching to provably learn large scale dynamical systems. (arXiv:2306.04520v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04520
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#38543;&#26426;&#25237;&#24433;&#25216;&#26415;&#20248;&#21270;&#20102;Koopman&#31639;&#23376;&#30340;&#20272;&#35745;&#22120;&#65292;&#21152;&#24555;&#20102;&#35745;&#31639;&#36895;&#24230;&#65292;&#24182;&#32473;&#20986;&#20102;&#31934;&#30830;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#25552;&#39640;&#20102;&#31639;&#27861;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Koopman&#31639;&#23376;&#29702;&#35770;&#20801;&#35768;&#20351;&#29992;&#38750;&#21442;&#25968;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#26469;&#39044;&#27979;&#21644;&#20998;&#26512;&#22797;&#26434;&#30340;&#21160;&#24577;&#31995;&#32479;&#12290;&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#38543;&#26426;&#25237;&#24433;&#65288;&#33609;&#22270;&#25216;&#26415;&#65289;&#25552;&#39640;&#22522;&#20110;&#26680;&#30340;Koopman&#31639;&#23376;&#20272;&#35745;&#22120;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#22823;&#35268;&#27169;&#20998;&#23376;&#21160;&#21147;&#23398;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#23454;&#39564;&#65292;&#24182;&#24314;&#31435;&#20102;&#38750;&#28176;&#36827;&#35823;&#24046;&#30028;&#65292;&#32473;&#20986;&#20102;&#32479;&#35745;&#23398;&#20064;&#36895;&#29575;&#21644;&#35745;&#31639;&#25928;&#29575;&#20043;&#38388;&#30340;&#26435;&#34913;&#30340;&#31934;&#30830;&#21051;&#30011;&#12290;&#25105;&#20204;&#30340;&#32463;&#39564;&#21644;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#32463;&#36807;&#25913;&#36827;&#30340;&#20272;&#35745;&#22120;&#22312;&#20445;&#35777;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#22823;&#22823;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
The theory of Koopman operators allows to deploy non-parametric machine learning algorithms to predict and analyze complex dynamical systems. Estimators such as principal component regression (PCR) or reduced rank regression (RRR) in kernel spaces can be shown to provably learn Koopman operators from finite empirical observations of the system's time evolution. Scaling these approaches to very long trajectories is a challenge and requires introducing suitable approximations to make computations feasible. In this paper, we boost the efficiency of different kernel-based Koopman operator estimators using random projections (sketching). We derive, implement and test the new "sketched" estimators with extensive experiments on synthetic and large-scale molecular dynamics datasets. Further, we establish non asymptotic error bounds giving a sharp characterization of the trade-offs between statistical learning rates and computational efficiency. Our empirical and theoretical analysis shows that
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#31163;&#25955;&#20998;&#24067;&#26679;&#26412;&#23545;&#20110;&#31867;&#21035;&#38388;&#30340;&#22343;&#21248;&#20998;&#24067;&#25311;&#21512;&#38382;&#39064;&#19979;&#30340;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;&#65292;&#22312;&#32570;&#23569;&#29699;&#24418;&#26367;&#20195;&#26041;&#26696;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20102;&#35752;&#35770;&#65292;&#36890;&#36807;&#31163;&#25955;&#30452;&#26041;&#22270;&#36827;&#34892;&#26816;&#39564;&#65292;&#33719;&#24471;&#20102;&#19968;&#31181;&#20855;&#26377;&#31934;&#30830;&#21051;&#30011;&#30340;&#26816;&#39564;&#26041;&#27861;&#65292;&#24182;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#20102;&#26174;&#33879;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.18111</link><description>&lt;p&gt;
&#22312;&#32570;&#23569;&#29699;&#24418;&#26367;&#20195;&#26041;&#26696;&#19979;&#27979;&#35797;&#31163;&#25955;&#20998;&#24067;&#30452;&#26041;&#22270;&#22343;&#21248;&#24615;&#30340;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
The minimax risk in testing the histogram of discrete distributions for uniformity under missing ball alternatives. (arXiv:2305.18111v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18111
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#31163;&#25955;&#20998;&#24067;&#26679;&#26412;&#23545;&#20110;&#31867;&#21035;&#38388;&#30340;&#22343;&#21248;&#20998;&#24067;&#25311;&#21512;&#38382;&#39064;&#19979;&#30340;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;&#65292;&#22312;&#32570;&#23569;&#29699;&#24418;&#26367;&#20195;&#26041;&#26696;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20102;&#35752;&#35770;&#65292;&#36890;&#36807;&#31163;&#25955;&#30452;&#26041;&#22270;&#36827;&#34892;&#26816;&#39564;&#65292;&#33719;&#24471;&#20102;&#19968;&#31181;&#20855;&#26377;&#31934;&#30830;&#21051;&#30011;&#30340;&#26816;&#39564;&#26041;&#27861;&#65292;&#24182;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#20102;&#26174;&#33879;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#27979;&#35797;&#19968;&#20010;&#26469;&#33258;&#35768;&#22810;&#31867;&#21035;&#30340;&#31163;&#25955;&#26679;&#26412;&#23545;&#20110;&#31867;&#21035;&#38388;&#30340;&#22343;&#21248;&#20998;&#24067;&#25311;&#21512;&#30340;&#38382;&#39064;&#12290;&#20316;&#20026;&#21478;&#19968;&#31867;&#26367;&#20195;&#20551;&#35774;&#65292;&#25105;&#20204;&#32771;&#34385;&#21435;&#38500;&#21322;&#24452;&#20026;$\epsilon$&#30340;$\ell_p$&#29699;&#24418;&#26367;&#20195;&#26041;&#26696;&#65292;&#20854;&#20013;$p\leq 2$&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#22522;&#20110;&#30452;&#26041;&#22270;&#65288;&#32570;&#22833;&#31867;&#21035;&#12289;&#21333;&#20363;&#12289;&#30896;&#25758;&#30340;&#25968;&#37327;&#65289;&#30340;&#26816;&#39564;&#22312;&#26679;&#26412;&#25968;&#21644;&#32500;&#25968;&#36235;&#21521;&#26080;&#31351;&#22823;&#65292;$\epsilon\to0$&#26102;&#65292;&#28176;&#36827;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;&#30340;&#19968;&#20010;&#31934;&#30830;&#21051;&#30011;&#12290;&#20363;&#22914;&#65292;&#24403;$p=1$&#19988;&#26399;&#26395;&#26679;&#26412;&#25968;$n$&#19982;&#31867;&#21035;&#25968;$N$&#30340;&#27604;&#20540;&#24456;&#23567;&#65288;&#20063;&#31216;&#20026;&#8220;&#27425;&#32447;&#24615;&#8221;&#21306;&#22495;&#65289;&#26102;&#65292;&#28176;&#36827;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;$R^*_\epsilon$&#36235;&#36817;&#20110;$2\bar{\Phi}\left(n\epsilon^2/\sqrt{8N}\right)$&#65292;&#20854;&#20013;$\bar{\Phi}(x)$&#26159;&#27491;&#24577;&#27531;&#23384;&#20989;&#25968;&#12290;&#22312;&#19968;&#31995;&#21015;&#38382;&#39064;&#21442;&#25968;&#33539;&#22260;&#20869;&#30340;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;&#36825;&#20010;&#20272;&#35745;&#22312;&#26377;&#38480;&#26679;&#26412;&#20013;&#24456;&#31934;&#30830;&#65292;&#24182;&#19988;&#25105;&#20204;&#30340;&#26816;&#39564;&#26174;&#33879;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of testing the fit of a discrete sample of items from many categories to the uniform distribution over the categories. As a class of alternative hypotheses, we consider the removal of an $\ell_p$ ball of radius $\epsilon$ around the uniform rate sequence for $p \leq 2$. We deliver a sharp characterization of the asymptotic minimax risk when $\epsilon \to 0$ as the number of samples and number of dimensions go to infinity, for testing based on the occurrences' histogram (number of absent categories, singletons, collisions, ...). For example, for $p=1$ and in the limit of a small expected number of samples $n$ compared to the number of categories $N$ (aka "sub-linear" regime), the minimax risk $R^*_\epsilon$ asymptotes to $2 \bar{\Phi}\left(n \epsilon^2/\sqrt{8N}\right) $, with $\bar{\Phi}(x)$ the normal survival function. Empirical studies over a range of problem parameters show that this estimate is accurate in finite samples, and that our test is significantly 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#34920;&#31034;&#30340;&#26032;&#22411;&#25955;&#24230;&#8212;&#8212;&#34920;&#31034;Jensen-Shannon&#25955;&#24230;&#65292;&#36890;&#36807;&#23558;&#25968;&#25454;&#20998;&#24067;&#23884;&#20837;&#21040;RKHS&#20013;&#65292;&#24182;&#21033;&#29992;&#34920;&#31034;&#30340;&#21327;&#26041;&#24046;&#31639;&#23376;&#30340;&#39057;&#35889;&#65292;&#23454;&#29616;&#23545;&#25968;&#25454;&#20998;&#24067;&#30340;&#20272;&#35745;&#65292;&#24182;&#25552;&#20379;&#20102;&#20855;&#26377;&#28789;&#27963;&#24615;&#65292;&#21487;&#25193;&#23637;&#24615;&#65292;&#21487;&#24494;&#20998;&#24615;&#30340;&#32463;&#39564;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#20989;&#25968;&#21644;&#22522;&#20110;&#26680;&#30697;&#38453;&#30340;&#20272;&#35745;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2305.16446</link><description>&lt;p&gt;
&#22522;&#20110;&#34920;&#31034;&#30340;Jensen-Shannon&#25955;&#24230;
&lt;/p&gt;
&lt;p&gt;
The Representation Jensen-Shannon Divergence. (arXiv:2305.16446v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16446
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#34920;&#31034;&#30340;&#26032;&#22411;&#25955;&#24230;&#8212;&#8212;&#34920;&#31034;Jensen-Shannon&#25955;&#24230;&#65292;&#36890;&#36807;&#23558;&#25968;&#25454;&#20998;&#24067;&#23884;&#20837;&#21040;RKHS&#20013;&#65292;&#24182;&#21033;&#29992;&#34920;&#31034;&#30340;&#21327;&#26041;&#24046;&#31639;&#23376;&#30340;&#39057;&#35889;&#65292;&#23454;&#29616;&#23545;&#25968;&#25454;&#20998;&#24067;&#30340;&#20272;&#35745;&#65292;&#24182;&#25552;&#20379;&#20102;&#20855;&#26377;&#28789;&#27963;&#24615;&#65292;&#21487;&#25193;&#23637;&#24615;&#65292;&#21487;&#24494;&#20998;&#24615;&#30340;&#32463;&#39564;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#20989;&#25968;&#21644;&#22522;&#20110;&#26680;&#30697;&#38453;&#30340;&#20272;&#35745;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32479;&#35745;&#25955;&#24230;&#37327;&#21270;&#27010;&#29575;&#20998;&#24067;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#31181;&#37325;&#35201;&#26041;&#27861;&#12290;&#20294;&#26159;&#65292;&#30001;&#20110;&#25968;&#25454;&#30340;&#24213;&#23618;&#20998;&#24067;&#36890;&#24120;&#26410;&#30693;&#65292;&#20174;&#32463;&#39564;&#26679;&#26412;&#20013;&#20272;&#35745;&#25955;&#24230;&#26159;&#19968;&#20010;&#22522;&#26412;&#38590;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;(RKHS)&#20013;&#21327;&#26041;&#24046;&#31639;&#23376;&#30340;&#26032;&#22411;&#25955;&#24230;&#8212;&#8212;&#34920;&#31034;Jensen-Shannon&#25955;&#24230;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#25968;&#25454;&#20998;&#24067;&#23884;&#20837;&#21040;RKHS&#20013;&#65292;&#24182;&#21033;&#29992;&#34920;&#31034;&#30340;&#21327;&#26041;&#24046;&#31639;&#23376;&#30340;&#39057;&#35889;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#20174;&#32463;&#39564;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#30340;&#20272;&#35745;&#20989;&#25968;&#65292;&#23427;&#36890;&#36807;&#20351;&#29992;Fourier&#29305;&#24449;&#23558;&#25968;&#25454;&#26144;&#23556;&#21040;RKHS&#20013;&#12290;&#27492;&#20272;&#35745;&#20989;&#25968;&#26159;&#28789;&#27963;&#12289;&#21487;&#25193;&#23637;&#12289;&#21487;&#24494;&#20998;&#30340;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#23567;&#25209;&#37327;&#20248;&#21270;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30697;&#38453;&#30340;&#20272;&#35745;&#20989;&#25968;&#65292;&#32780;&#19981;&#38656;&#35201;&#23545;RKHS&#36827;&#34892;&#26174;&#24335;&#26144;&#23556;&#12290;&#25105;&#20204;&#35777;&#26126;&#36825;&#20010;&#37327;&#26159;Jensen-Shannon&#25955;&#24230;&#30340;&#19968;&#20010;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
Statistical divergences quantify the difference between probability distributions finding multiple uses in machine-learning. However, a fundamental challenge is to estimate divergence from empirical samples since the underlying distributions of the data are usually unknown. In this work, we propose the representation Jensen-Shannon Divergence, a novel divergence based on covariance operators in reproducing kernel Hilbert spaces (RKHS). Our approach embeds the data distributions in an RKHS and exploits the spectrum of the covariance operators of the representations. We provide an estimator from empirical covariance matrices by explicitly mapping the data to an RKHS using Fourier features. This estimator is flexible, scalable, differentiable, and suitable for minibatch-based optimization problems. Additionally, we provide an estimator based on kernel matrices without having an explicit mapping to the RKHS. We show that this quantity is a lower bound on the Jensen-Shannon divergence, and 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#26694;&#26550;&#65292;&#23558;&#27785;&#31215;&#35745;&#31639;&#21644;&#24402;&#19968;&#21270;&#27969;&#32467;&#21512;&#36215;&#26469;&#20197;&#30740;&#31350;&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#30340;&#39044;&#27979;&#21644;&#21160;&#21147;&#23398;&#34892;&#20026;&#65292;&#25104;&#21151;&#22320;&#39044;&#27979;&#20102;&#38271;&#26399;&#28436;&#21270;&#24182;&#22797;&#21046;&#20102;&#21160;&#21147;&#23398;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2305.00669</link><description>&lt;p&gt;
&#24102;&#35823;&#24046;&#26657;&#27491;&#30340;&#27785;&#31215;&#35745;&#31639;&#65306;&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#30340;&#38271;&#26399;&#34892;&#20026;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Reservoir Computing with Error Correction: Long-term Behaviors of Stochastic Dynamical Systems. (arXiv:2305.00669v1 [math.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00669
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#26694;&#26550;&#65292;&#23558;&#27785;&#31215;&#35745;&#31639;&#21644;&#24402;&#19968;&#21270;&#27969;&#32467;&#21512;&#36215;&#26469;&#20197;&#30740;&#31350;&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#30340;&#39044;&#27979;&#21644;&#21160;&#21147;&#23398;&#34892;&#20026;&#65292;&#25104;&#21151;&#22320;&#39044;&#27979;&#20102;&#38271;&#26399;&#28436;&#21270;&#24182;&#22797;&#21046;&#20102;&#21160;&#21147;&#23398;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#30340;&#39044;&#27979;&#21644;&#21160;&#21147;&#23398;&#34892;&#20026;&#30340;&#25429;&#25417;&#26159;&#19968;&#20010;&#28145;&#21051;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#26694;&#26550;&#65292;&#23558;&#27785;&#31215;&#35745;&#31639;&#21644;&#24402;&#19968;&#21270;&#27969;&#32467;&#21512;&#36215;&#26469;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#65292;&#23427;&#27169;&#20223;&#35823;&#24046;&#24314;&#27169;&#26469;&#25552;&#39640;&#20256;&#32479;&#27785;&#31215;&#35745;&#31639;&#30340;&#24615;&#33021;&#65292;&#24182;&#20805;&#20998;&#21033;&#29992;&#20102;&#20004;&#31181;&#26041;&#27861;&#30340;&#20248;&#28857;&#12290;&#36825;&#31181;&#26080;&#27169;&#22411;&#26041;&#27861;&#25104;&#21151;&#22320;&#39044;&#27979;&#20102;&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#30340;&#38271;&#26399;&#28436;&#21270;&#65292;&#24182;&#22797;&#21046;&#20102;&#21160;&#21147;&#23398;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
The prediction of stochastic dynamical systems and the capture of dynamical behaviors are profound problems. In this article, we propose a data-driven framework combining Reservoir Computing and Normalizing Flow to study this issue, which mimics error modeling to improve the traditional Reservoir Computing performance and takes advantage of both approaches. This model-free method successfully predicts the long-term evolution of stochastic dynamical systems and replicates dynamical behaviors. With few assumptions about the underlying stochastic dynamical systems, we deal with Markov/non-Markov and stationary/non-stationary stochastic processes defined by linear/nonlinear stochastic differential equations or stochastic delay differential equations. We verify the effectiveness of the proposed framework in five experiments, including the Ornstein-Uhlenbeck process, Double-Well system, El Ni\~no Southern Oscillation simplified model, and stochastic Lorenz system. Additionally, we explore th
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#23884;&#20837;&#38750;&#20984;&#20998;&#27573;&#20223;&#23556;&#20915;&#31574;&#35268;&#21017;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#29305;&#24449;&#19982;&#26368;&#20248;&#20915;&#31574;&#20043;&#38388;&#30340;&#30452;&#25509;&#26144;&#23556;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#29992;&#20110;&#24191;&#27867;&#30340;&#38750;&#20984;&#22411;SP&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#25968;&#20540;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.13646</link><description>&lt;p&gt;
&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#20998;&#27573;&#20223;&#23556;&#20915;&#31574;&#35268;&#21017;&#29992;&#20110;&#24102;&#21327;&#21464;&#20449;&#24687;&#30340;&#38543;&#26426;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
Data-driven Piecewise Affine Decision Rules for Stochastic Programming with Covariate Information. (arXiv:2304.13646v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13646
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#23884;&#20837;&#38750;&#20984;&#20998;&#27573;&#20223;&#23556;&#20915;&#31574;&#35268;&#21017;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#29305;&#24449;&#19982;&#26368;&#20248;&#20915;&#31574;&#20043;&#38388;&#30340;&#30452;&#25509;&#26144;&#23556;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#29992;&#20110;&#24191;&#27867;&#30340;&#38750;&#20984;&#22411;SP&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#25968;&#20540;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#24102;&#21327;&#21464;&#20449;&#24687;&#30340;&#38543;&#26426;&#35268;&#21010;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23884;&#20837;&#38750;&#20984;&#20998;&#27573;&#20223;&#23556;&#20915;&#31574;&#35268;&#21017;(PADR)&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;(ERM)&#26041;&#27861;&#65292;&#26088;&#22312;&#23398;&#20064;&#29305;&#24449;&#19982;&#26368;&#20248;&#20915;&#31574;&#20043;&#38388;&#30340;&#30452;&#25509;&#26144;&#23556;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#22522;&#20110;PADR&#30340;ERM&#27169;&#22411;&#30340;&#38750;&#28176;&#36817;&#19968;&#33268;&#24615;&#32467;&#26524;&#65292;&#21487;&#29992;&#20110;&#26080;&#32422;&#26463;&#38382;&#39064;&#65292;&#20197;&#21450;&#32422;&#26463;&#38382;&#39064;&#30340;&#28176;&#36817;&#19968;&#33268;&#24615;&#32467;&#26524;&#12290;&#20026;&#20102;&#35299;&#20915;&#38750;&#20984;&#21644;&#38750;&#21487;&#24494;&#30340;ERM&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22686;&#24378;&#30340;&#38543;&#26426;&#20027;&#23548;&#19979;&#38477;&#31639;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#27839;&#65288;&#22797;&#21512;&#24378;&#65289;&#26041;&#21521;&#31283;&#23450;&#24615;&#30340;&#28176;&#36817;&#25910;&#25947;&#20197;&#21450;&#22797;&#26434;&#24615;&#20998;&#26512;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;PADR-based ERM&#26041;&#27861;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#38750;&#20984;&#22411;SP&#38382;&#39064;&#65292;&#24182;&#20855;&#26377;&#29702;&#35770;&#19968;&#33268;&#24615;&#20445;&#35777;&#21644;&#35745;&#31639;&#21487;&#22788;&#29702;&#24615;&#12290;&#25968;&#20540;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#21508;&#31181;&#35774;&#32622;&#19979;&#65292;PADR-based ERM&#26041;&#27861;&#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#20855;&#26377;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Focusing on stochastic programming (SP) with covariate information, this paper proposes an empirical risk minimization (ERM) method embedded within a nonconvex piecewise affine decision rule (PADR), which aims to learn the direct mapping from features to optimal decisions. We establish the nonasymptotic consistency result of our PADR-based ERM model for unconstrained problems and asymptotic consistency result for constrained ones. To solve the nonconvex and nondifferentiable ERM problem, we develop an enhanced stochastic majorization-minimization algorithm and establish the asymptotic convergence to (composite strong) directional stationarity along with complexity analysis. We show that the proposed PADR-based ERM method applies to a broad class of nonconvex SP problems with theoretical consistency guarantees and computational tractability. Our numerical study demonstrates the superior performance of PADR-based ERM methods compared to state-of-the-art approaches under various settings,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#28145;&#20837;&#29702;&#35299;&#20102;&#25193;&#25955;&#30446;&#26631;&#65292;&#24182;&#25581;&#31034;&#20102;&#21152;&#26435;&#25439;&#22833;&#21644;ELBO&#30446;&#26631;&#20043;&#38388;&#30340;&#30452;&#25509;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2303.00848</link><description>&lt;p&gt;
&#20197;ELBOs&#30340;&#21152;&#26435;&#31215;&#20998;&#29702;&#35299;&#25193;&#25955;&#30446;&#26631;
&lt;/p&gt;
&lt;p&gt;
Understanding the Diffusion Objective as a Weighted Integral of ELBOs. (arXiv:2303.00848v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.00848
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#28145;&#20837;&#29702;&#35299;&#20102;&#25193;&#25955;&#30446;&#26631;&#65292;&#24182;&#25581;&#31034;&#20102;&#21152;&#26435;&#25439;&#22833;&#21644;ELBO&#30446;&#26631;&#20043;&#38388;&#30340;&#30452;&#25509;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#29486;&#20013;&#30340;&#25193;&#25955;&#27169;&#22411;&#37319;&#29992;&#19981;&#21516;&#30340;&#30446;&#26631;&#36827;&#34892;&#20248;&#21270;&#65292;&#24182;&#19988;&#36825;&#20123;&#30446;&#26631;&#37117;&#26159;&#21152;&#26435;&#25439;&#22833;&#30340;&#29305;&#20363;&#65292;&#20854;&#20013;&#21152;&#26435;&#20989;&#25968;&#25351;&#23450;&#27599;&#20010;&#22122;&#22768;&#32423;&#21035;&#30340;&#26435;&#37325;&#12290;&#22343;&#21248;&#21152;&#26435;&#23545;&#24212;&#20110;&#26368;&#22823;&#20284;&#28982;&#30340;&#21407;&#21017;&#24615;&#36817;&#20284;ELBO&#30340;&#26368;&#22823;&#21270;&#12290;&#20294;&#26159;&#23454;&#38469;&#19978;&#65292;&#30001;&#20110;&#26356;&#22909;&#30340;&#26679;&#26412;&#36136;&#37327;&#65292;&#30446;&#21069;&#30340;&#25193;&#25955;&#27169;&#22411;&#20351;&#29992;&#38750;&#22343;&#21248;&#21152;&#26435;&#12290;&#26412;&#25991;&#25581;&#31034;&#20102;&#21152;&#26435;&#25439;&#22833;&#65288;&#24102;&#26377;&#20219;&#20309;&#21152;&#26435;&#65289;&#21644;ELBO&#30446;&#26631;&#20043;&#38388;&#30340;&#30452;&#25509;&#20851;&#31995;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21152;&#26435;&#25439;&#22833;&#21487;&#20197;&#34987;&#20889;&#25104;&#19968;&#31181;ELBOs&#30340;&#21152;&#26435;&#31215;&#20998;&#24418;&#24335;&#65292;&#20854;&#20013;&#27599;&#20010;&#22122;&#22768;&#32423;&#21035;&#37117;&#26377;&#19968;&#20010;ELBO&#12290;&#22914;&#26524;&#26435;&#37325;&#20989;&#25968;&#26159;&#21333;&#35843;&#30340;&#65292;&#37027;&#20040;&#21152;&#26435;&#25439;&#22833;&#26159;&#19968;&#31181;&#22522;&#20110;&#20284;&#28982;&#30340;&#30446;&#26631;&#65306;&#23427;&#22312;&#31616;&#21333;&#30340;&#25968;&#25454;&#22686;&#24378;&#19979;&#65288;&#21363;&#39640;&#26031;&#22122;&#22768;&#25200;&#21160;&#65289;&#19979;&#26368;&#22823;&#21270;ELBO&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#26356;&#28145;&#20837;&#22320;&#29702;&#35299;&#20102;&#25193;&#25955;&#30446;&#26631;&#65292;&#20294;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#19968;&#20123;&#27604;&#36739;&#21333;&#35843;&#21644;&#38750;&#21333;&#35843;&#26435;&#37325;&#30340;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models in the literature are optimized with various objectives that are special cases of a weighted loss, where the weighting function specifies the weight per noise level. Uniform weighting corresponds to maximizing the ELBO, a principled approximation of maximum likelihood. In current practice diffusion models are optimized with non-uniform weighting due to better results in terms of sample quality. In this work we expose a direct relationship between the weighted loss (with any weighting) and the ELBO objective.  We show that the weighted loss can be written as a weighted integral of ELBOs, with one ELBO per noise level. If the weighting function is monotonic, then the weighted loss is a likelihood-based objective: it maximizes the ELBO under simple data augmentation, namely Gaussian noise perturbation. Our main contribution is a deeper theoretical understanding of the diffusion objective, but we also performed some experiments comparing monotonic with non-monotonic weight
&lt;/p&gt;</description></item><item><title>&#36825;&#31181;&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#19968;&#27425;&#24615;&#32852;&#37030;&#23398;&#20064;&#35774;&#32622;&#19979;&#36827;&#34892;&#36866;&#24212;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23450;&#20041;&#20998;&#20301;&#25968;&#20272;&#35745;&#22120;&#65292;&#24182;&#19988;&#20165;&#38656;&#35201;&#36827;&#34892;&#19968;&#36718;&#36890;&#20449;&#23601;&#21487;&#20197;&#33719;&#24471;&#20855;&#26377;&#26399;&#26395;&#35206;&#30422;&#29575;&#30340;&#39044;&#27979;&#38598;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#35206;&#30422;&#29575;&#21644;&#38271;&#24230;&#26041;&#38754;&#19982;&#38598;&#20013;&#24335;&#35774;&#32622;&#30340;&#32467;&#26524;&#38750;&#24120;&#30456;&#20284;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#19968;&#27425;&#24615;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.06322</link><description>&lt;p&gt;
&#19968;&#27425;&#24615;&#32852;&#37030;&#36866;&#24212;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
One-Shot Federated Conformal Prediction. (arXiv:2302.06322v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06322
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31181;&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#19968;&#27425;&#24615;&#32852;&#37030;&#23398;&#20064;&#35774;&#32622;&#19979;&#36827;&#34892;&#36866;&#24212;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23450;&#20041;&#20998;&#20301;&#25968;&#20272;&#35745;&#22120;&#65292;&#24182;&#19988;&#20165;&#38656;&#35201;&#36827;&#34892;&#19968;&#36718;&#36890;&#20449;&#23601;&#21487;&#20197;&#33719;&#24471;&#20855;&#26377;&#26399;&#26395;&#35206;&#30422;&#29575;&#30340;&#39044;&#27979;&#38598;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#35206;&#30422;&#29575;&#21644;&#38271;&#24230;&#26041;&#38754;&#19982;&#38598;&#20013;&#24335;&#35774;&#32622;&#30340;&#32467;&#26524;&#38750;&#24120;&#30456;&#20284;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#19968;&#27425;&#24615;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#19968;&#27425;&#24615;&#32852;&#37030;&#23398;&#20064;&#35774;&#32622;&#19979;&#26500;&#24314;&#39044;&#27979;&#38598;&#30340;&#36866;&#24212;&#39044;&#27979;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23450;&#20041;&#20102;&#19968;&#20010;&#20998;&#20301;&#25968;&#20272;&#35745;&#22120;&#65292;&#24182;&#35777;&#26126;&#23545;&#20110;&#20219;&#20309;&#20998;&#24067;&#65292;&#21482;&#38656;&#19968;&#36718;&#36890;&#20449;&#21363;&#21487;&#36755;&#20986;&#20855;&#26377;&#26399;&#26395;&#35206;&#30422;&#29575;&#30340;&#39044;&#27979;&#38598;&#12290;&#20026;&#20102;&#35299;&#20915;&#38544;&#31169;&#38382;&#39064;&#65292;&#25105;&#20204;&#36824;&#25551;&#36848;&#20102;&#19968;&#20010;&#26412;&#22320;&#24046;&#20998;&#38544;&#31169;&#29256;&#26412;&#30340;&#20272;&#35745;&#22120;&#12290;&#26368;&#21518;&#65292;&#22312;&#24191;&#27867;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#36820;&#22238;&#30340;&#39044;&#27979;&#38598;&#30340;&#35206;&#30422;&#29575;&#21644;&#38271;&#24230;&#38750;&#24120;&#31867;&#20284;&#20110;&#22312;&#38598;&#20013;&#24335;&#35774;&#32622;&#20013;&#33719;&#24471;&#30340;&#32467;&#26524;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#36825;&#20123;&#32467;&#26524;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#19968;&#27425;&#24615;&#32852;&#37030;&#23398;&#20064;&#35774;&#32622;&#19979;&#36827;&#34892;&#36866;&#24212;&#39044;&#27979;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce a conformal prediction method to construct prediction sets in a oneshot federated learning setting. More specifically, we define a quantile-of-quantiles estimator and prove that for any distribution, it is possible to output prediction sets with desired coverage in only one round of communication. To mitigate privacy issues, we also describe a locally differentially private version of our estimator. Finally, over a wide range of experiments, we show that our method returns prediction sets with coverage and length very similar to those obtained in a centralized setting. Overall, these results demonstrate that our method is particularly well-suited to perform conformal predictions in a one-shot federated learning setting.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;&#30340;&#31070;&#32463;&#32593;&#32476;&#35770;&#35777;&#35299;&#37322;&#26041;&#27861;SpArX&#65292;&#36890;&#36807;&#21033;&#29992;&#22810;&#23618;&#24863;&#30693;&#22120;&#21644;&#23450;&#37327;&#35770;&#35777;&#26694;&#26550;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#21487;&#20197;&#20026;&#31070;&#32463;&#32593;&#32476;&#30340;&#20915;&#31574;&#36807;&#31243;&#25552;&#20379;&#26356;&#24544;&#23454;&#21644;&#28145;&#20837;&#30340;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2301.09559</link><description>&lt;p&gt;
SpArX: &#31232;&#30095;&#30340;&#31070;&#32463;&#32593;&#32476;&#35770;&#35777;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
SpArX: Sparse Argumentative Explanations for Neural Networks. (arXiv:2301.09559v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.09559
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;&#30340;&#31070;&#32463;&#32593;&#32476;&#35770;&#35777;&#35299;&#37322;&#26041;&#27861;SpArX&#65292;&#36890;&#36807;&#21033;&#29992;&#22810;&#23618;&#24863;&#30693;&#22120;&#21644;&#23450;&#37327;&#35770;&#35777;&#26694;&#26550;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#21487;&#20197;&#20026;&#31070;&#32463;&#32593;&#32476;&#30340;&#20915;&#31574;&#36807;&#31243;&#25552;&#20379;&#26356;&#24544;&#23454;&#21644;&#28145;&#20837;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#22312;&#20154;&#24037;&#26234;&#33021;&#20013;&#26377;&#21508;&#31181;&#24212;&#29992;&#65292;&#20294;&#35299;&#37322;&#23427;&#20204;&#30340;&#20915;&#31574;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#20851;&#27880;&#35299;&#37322;&#25913;&#21464;&#21333;&#20010;&#36755;&#20837;&#22914;&#20309;&#24433;&#21709;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20986;&#12290;&#28982;&#32780;&#65292;&#19968;&#20010;&#19982;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20837;&#36755;&#20986;&#34892;&#20026;&#19968;&#33268;&#30340;&#35299;&#37322;&#26410;&#24517;&#24544;&#23454;&#20110;&#20854;&#23454;&#38469;&#26426;&#21046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#22810;&#23618;&#24863;&#30693;&#22120;&#21644;&#23450;&#37327;&#35770;&#35777;&#26694;&#26550;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20026;&#22810;&#23618;&#24863;&#30693;&#22120;&#30340;&#26426;&#21046;&#21019;&#24314;&#20102;&#35770;&#35777;&#24615;&#35299;&#37322;&#12290;&#25105;&#20204;&#30340;SpArX&#26041;&#27861;&#39318;&#20808;&#23558;&#22810;&#23618;&#24863;&#30693;&#22120;&#31232;&#30095;&#21270;&#65292;&#21516;&#26102;&#20445;&#25345;&#23613;&#21487;&#33021;&#22810;&#30340;&#21407;&#22987;&#32467;&#26500;&#12290;&#28982;&#21518;&#23558;&#31232;&#30095;&#30340;&#22810;&#23618;&#24863;&#30693;&#22120;&#36716;&#21270;&#20026;&#31561;&#25928;&#30340;&#23450;&#37327;&#35770;&#35777;&#26694;&#26550;&#65292;&#20197;&#25581;&#31034;&#22810;&#23618;&#24863;&#30693;&#22120;&#30340;&#28508;&#22312;&#20915;&#31574;&#36807;&#31243;&#65292;&#20135;&#29983;&#20840;&#23616;&#21644;/&#25110;&#23616;&#37096;&#35299;&#37322;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;SpArX&#27604;&#29616;&#26377;&#26041;&#27861;&#21487;&#20197;&#32473;&#20986;&#26356;&#24544;&#23454;&#30340;&#35299;&#37322;&#65292;&#21516;&#26102;&#25552;&#20379;&#26356;&#28145;&#20837;&#30340;&#27934;&#23519;&#23454;&#38469;&#25512;&#29702;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural networks (NNs) have various applications in AI, but explaining their decisions remains challenging. Existing approaches often focus on explaining how changing individual inputs affects NNs' outputs. However, an explanation that is consistent with the input-output behaviour of an NN is not necessarily faithful to the actual mechanics thereof. In this paper, we exploit relationships between multi-layer perceptrons (MLPs) and quantitative argumentation frameworks (QAFs) to create argumentative explanations for the mechanics of MLPs. Our SpArX method first sparsifies the MLP while maintaining as much of the original structure as possible. It then translates the sparse MLP into an equivalent QAF to shed light on the underlying decision process of the MLP, producing global and/or local explanations. We demonstrate experimentally that SpArX can give more faithful explanations than existing approaches, while simultaneously providing deeper insights into the actual reasoning process of M
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#28508;&#22312;&#22810;&#27169;&#24577;&#21151;&#33021;&#22270;&#27169;&#22411;&#20272;&#35745;&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#21516;&#26102;&#20272;&#35745;&#36716;&#25442;&#31639;&#23376;&#21644;&#28508;&#22312;&#22270;&#26469;&#22635;&#34917;&#24403;&#21069;&#31185;&#23398;&#26041;&#27861;&#22312;&#20272;&#35745;&#22810;&#27169;&#24577;&#21151;&#33021;&#25968;&#25454;&#22270;&#27169;&#22411;&#26041;&#38754;&#30340;&#31354;&#30333;</title><link>http://arxiv.org/abs/2210.17237</link><description>&lt;p&gt;
&#28508;&#22312;&#22810;&#27169;&#24577;&#21151;&#33021;&#22270;&#27169;&#22411;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Latent Multimodal Functional Graphical Model Estimation. (arXiv:2210.17237v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.17237
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#28508;&#22312;&#22810;&#27169;&#24577;&#21151;&#33021;&#22270;&#27169;&#22411;&#20272;&#35745;&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#21516;&#26102;&#20272;&#35745;&#36716;&#25442;&#31639;&#23376;&#21644;&#28508;&#22312;&#22270;&#26469;&#22635;&#34917;&#24403;&#21069;&#31185;&#23398;&#26041;&#27861;&#22312;&#20272;&#35745;&#22810;&#27169;&#24577;&#21151;&#33021;&#25968;&#25454;&#22270;&#27169;&#22411;&#26041;&#38754;&#30340;&#31354;&#30333;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20849;&#21516;&#22810;&#27169;&#24577;&#21151;&#33021;&#25968;&#25454;&#37319;&#38598;&#26159;&#19968;&#31181;&#29616;&#20195;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#36817;&#22312;&#31070;&#32463;&#23398;&#21644;&#29983;&#29289;&#31185;&#23398;&#20013;&#30340;&#24037;&#31243;&#31361;&#30772;&#65292;&#21487;&#20197;&#21516;&#26102;&#20174;&#21516;&#19968;&#20027;&#20307;&#20013;&#27979;&#37327;&#26469;&#33258;&#22810;&#31181;&#27169;&#24335;&#30340;&#21151;&#33021;&#25968;&#25454;&#12290;&#33719;&#21462;&#36825;&#26679;&#30340;&#25968;&#25454;&#30340;&#19968;&#20010;&#37325;&#35201;&#21160;&#26426;&#26159;&#36890;&#36807;&#32467;&#21512;&#22810;&#27169;&#24577;&#20449;&#21495;&#26469;&#21457;&#29616;&#28508;&#22312;&#30340;&#36830;&#25509;&#24615;&#12290;&#23613;&#31649;&#23384;&#22312;&#31185;&#23398;&#20852;&#36259;&#65292;&#20294;&#22312;&#20272;&#35745;&#22810;&#27169;&#24577;&#21151;&#33021;&#25968;&#25454;&#19979;&#30340;&#22270;&#27169;&#22411;&#26041;&#38754;&#20173;&#23384;&#22312;&#24046;&#36317;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#32508;&#21512;&#26694;&#26550;&#65292;&#23545;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#35782;&#21035;&#20174;&#35266;&#27979;&#31354;&#38388;&#21040;&#28508;&#22312;&#31354;&#38388;&#30340;&#31639;&#23376;&#26144;&#23556;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#21516;&#26102;&#20272;&#35745;&#36716;&#25442;&#31639;&#23376;&#21644;&#28508;&#22312;&#22270;&#12290;&#36825;&#20010;&#20272;&#35745;&#22120;&#22522;&#20110;&#20559;&#30456;&#20851;&#31639;&#23376;&#65292;&#25105;&#20204;&#20174;&#22810;&#20803;&#21040;&#21151;&#33021;&#35774;&#32622;&#20013;&#20005;&#26684;&#25512;&#24191;&#20102;&#23427;&#12290;&#25105;&#20204;&#30340;&#31243;&#24207;&#26159;pr&#23553;&#38381;&#30340;
&lt;/p&gt;
&lt;p&gt;
Joint multimodal functional data acquisition, where functional data from multiple modes are measured simultaneously from the same subject, has emerged as an exciting modern approach enabled by recent engineering breakthroughs in the neurological and biological sciences. One prominent motivation to acquire such data is to enable new discoveries of the underlying connectivity by combining multimodal signals. Despite the scientific interest, there remains a gap in principled statistical methods for estimating the graph underlying multimodal functional data. To this end, we propose a new integrative framework that models the data generation process and identifies operators mapping from the observation space to the latent space. We then develop an estimator that simultaneously estimates the transformation operators and the latent graph. This estimator is based on the partial correlation operator, which we rigorously extend from the multivariate to the functional setting. Our procedure is pr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;$k$-&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#22312;&#25345;&#20037;&#22270;&#31354;&#38388;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#35299;&#20915;&#20102;&#20195;&#25968;&#26500;&#36896;&#23548;&#33268;&#30340;&#22797;&#26434;&#24230;&#38382;&#39064;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#30452;&#25509;&#22312;&#25345;&#20037;&#22270;&#21644;&#25345;&#20037;&#24230;&#37327;&#19978;&#36827;&#34892;&#32858;&#31867;&#20248;&#20110;&#21521;&#37327;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2210.10003</link><description>&lt;p&gt;
$k$-&#22343;&#20540;&#32858;&#31867;&#29992;&#20110;&#25345;&#20037;&#21516;&#35843;
&lt;/p&gt;
&lt;p&gt;
$k$-Means Clustering for Persistent Homology. (arXiv:2210.10003v3 [stat.AP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.10003
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;$k$-&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#22312;&#25345;&#20037;&#22270;&#31354;&#38388;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#35299;&#20915;&#20102;&#20195;&#25968;&#26500;&#36896;&#23548;&#33268;&#30340;&#22797;&#26434;&#24230;&#38382;&#39064;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#30452;&#25509;&#22312;&#25345;&#20037;&#22270;&#21644;&#25345;&#20037;&#24230;&#37327;&#19978;&#36827;&#34892;&#32858;&#31867;&#20248;&#20110;&#21521;&#37327;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25345;&#20037;&#21516;&#35843;&#26159;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#25552;&#21462;&#21644;&#24635;&#32467;&#25968;&#25454;&#38598;&#20013;&#30340;&#25299;&#25169;&#29305;&#24449;&#65292;&#24182;&#20197;&#25345;&#20037;&#22270;&#30340;&#24418;&#24335;&#34920;&#31034;&#12290;&#36817;&#24180;&#26469;&#65292;&#22312;&#35768;&#22810;&#39046;&#22495;&#20013;&#24191;&#27867;&#24212;&#29992;&#30340;&#25345;&#20037;&#21516;&#35843;&#26041;&#27861;&#21463;&#21040;&#20102;&#24456;&#22823;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#23427;&#30340;&#20195;&#25968;&#26500;&#36896;&#23548;&#33268;&#20102;&#19968;&#20010;&#20855;&#26377;&#39640;&#24230;&#22797;&#26434;&#20960;&#20309;&#30340;&#25345;&#32493;&#22270;&#31354;&#38388;&#30340;&#24230;&#37327;&#31354;&#38388;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;$k$-&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#22312;&#25345;&#20037;&#22270;&#31354;&#38388;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#22312;Karush-Kuhn-Tucker&#26694;&#26550;&#19979;&#24314;&#31435;&#20102;&#20248;&#21270;&#38382;&#39064;&#30340;&#29702;&#35770;&#24615;&#36136;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#25345;&#20037;&#21516;&#35843;&#30340;&#21508;&#31181;&#34920;&#31034;&#36827;&#34892;&#20102;&#25968;&#20540;&#23454;&#39564;&#65292;&#21253;&#25324;&#25345;&#20037;&#22270;&#30340;&#23884;&#20837;&#20197;&#21450;&#22270;&#21644;&#23427;&#20204;&#30340;&#25512;&#24191;&#20316;&#20026;&#25345;&#20037;&#24230;&#37327;&#65307;&#25105;&#20204;&#21457;&#29616;&#65292;&#30452;&#25509;&#22312;&#25345;&#20037;&#22270;&#21644;&#25345;&#20037;&#24230;&#37327;&#19978;&#36827;&#34892;&#32858;&#31867;&#30340;&#24615;&#33021;&#20248;&#20110;&#23427;&#20204;&#30340;&#21521;&#37327;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Persistent homology is a methodology central to topological data analysis that extracts and summarizes the topological features within a dataset as a persistence diagram; it has recently gained much popularity from its myriad successful applications to many domains. However, its algebraic construction induces a metric space of persistence diagrams with a highly complex geometry. In this paper, we prove convergence of the $k$-means clustering algorithm on persistence diagram space and establish theoretical properties of the solution to the optimization problem in the Karush--Kuhn--Tucker framework. Additionally, we perform numerical experiments on various representations of persistent homology, including embeddings of persistence diagrams as well as diagrams themselves and their generalizations as persistence measures; we find that clustering performance directly on persistence diagrams and measures outperform their vectorized representations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;CitySim&#25968;&#25454;&#38598;&#65292;&#35813;&#25968;&#25454;&#38598;&#36890;&#36807;&#26080;&#20154;&#26426;&#24405;&#21046;&#30340;&#35270;&#39057;&#25552;&#21462;&#36710;&#36742;&#36712;&#36857;&#65292;&#26088;&#22312;&#20419;&#36827;&#23433;&#20840;&#23548;&#21521;&#30340;&#30740;&#31350;&#21644;&#24212;&#29992;&#12290;&#25968;&#25454;&#38598;&#21253;&#21547;&#22823;&#37327;&#30340;&#32454;&#31890;&#24230;&#36710;&#36742;&#36712;&#36857;&#65292;&#24182;&#36890;&#36807;&#20116;&#27493;&#39588;&#30340;&#22788;&#29702;&#30830;&#20445;&#20102;&#36712;&#36857;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2208.11036</link><description>&lt;p&gt;
CitySim&#65306;&#38754;&#21521;&#23433;&#20840;&#30740;&#31350;&#21644;&#25968;&#23383;&#23402;&#29983;&#30340;&#22522;&#20110;&#26080;&#20154;&#26426;&#36710;&#36742;&#36712;&#36857;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
CitySim: A Drone-Based Vehicle Trajectory Dataset for Safety Oriented Research and Digital Twins. (arXiv:2208.11036v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.11036
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;CitySim&#25968;&#25454;&#38598;&#65292;&#35813;&#25968;&#25454;&#38598;&#36890;&#36807;&#26080;&#20154;&#26426;&#24405;&#21046;&#30340;&#35270;&#39057;&#25552;&#21462;&#36710;&#36742;&#36712;&#36857;&#65292;&#26088;&#22312;&#20419;&#36827;&#23433;&#20840;&#23548;&#21521;&#30340;&#30740;&#31350;&#21644;&#24212;&#29992;&#12290;&#25968;&#25454;&#38598;&#21253;&#21547;&#22823;&#37327;&#30340;&#32454;&#31890;&#24230;&#36710;&#36742;&#36712;&#36857;&#65292;&#24182;&#36890;&#36807;&#20116;&#27493;&#39588;&#30340;&#22788;&#29702;&#30830;&#20445;&#20102;&#36712;&#36857;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23433;&#20840;&#23548;&#21521;&#30740;&#31350;&#21644;&#24212;&#29992;&#30340;&#21457;&#23637;&#38656;&#35201;&#39640;&#31934;&#24230;&#19988;&#33021;&#25429;&#25417;&#37325;&#35201;&#23433;&#20840;&#20107;&#20214;&#30340;&#32454;&#31890;&#24230;&#36710;&#36742;&#36712;&#36857;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#36710;&#36742;&#36712;&#36857;&#25968;&#25454;&#38598;&#24456;&#38590;&#21516;&#26102;&#28385;&#36275;&#36825;&#20004;&#20010;&#35201;&#27714;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;CitySim&#25968;&#25454;&#38598;&#65292;&#20854;&#26680;&#24515;&#30446;&#26631;&#26159;&#20419;&#36827;&#23433;&#20840;&#23548;&#21521;&#30340;&#30740;&#31350;&#21644;&#24212;&#29992;&#12290;CitySim&#21253;&#21547;&#20174;12&#20010;&#22320;&#28857;&#24405;&#21046;&#30340;1140&#20998;&#38047;&#26080;&#20154;&#26426;&#35270;&#39057;&#20013;&#25552;&#21462;&#30340;&#36710;&#36742;&#36712;&#36857;&#12290;&#23427;&#28085;&#30422;&#20102;&#21508;&#31181;&#36947;&#36335;&#20960;&#20309;&#24418;&#29366;&#65292;&#21253;&#25324;&#39640;&#36895;&#20844;&#36335;&#22522;&#26412;&#27573;&#12289;&#20449;&#21495;&#21270;&#21313;&#23383;&#36335;&#21475;&#12289;&#20572;&#25511;&#21313;&#23383;&#36335;&#21475;&#21644;&#26080;&#25511;&#20132;&#21449;&#36335;&#21475;&#12290;CitySim&#36890;&#36807;&#20116;&#20010;&#27493;&#39588;&#29983;&#25104;&#65292;&#30830;&#20445;&#20102;&#36712;&#36857;&#30340;&#20934;&#30830;&#24615;&#12290;&#36825;&#20116;&#20010;&#27493;&#39588;&#21253;&#25324;&#35270;&#39057;&#31283;&#23450;&#12289;&#30446;&#26631;&#36807;&#28388;&#12289;&#22810;&#35270;&#39057;&#25340;&#25509;&#12289;&#30446;&#26631;&#26816;&#27979;&#21644;&#36319;&#36394;&#20197;&#21450;&#22686;&#24378;&#24335;&#35823;&#24046;&#36807;&#28388;&#12290;
&lt;/p&gt;
&lt;p&gt;
The development of safety-oriented research and applications requires fine-grain vehicle trajectories that not only have high accuracy, but also capture substantial safety-critical events. However, it would be challenging to satisfy both these requirements using the available vehicle trajectory datasets do not have the capacity to satisfy both.This paper introduces the CitySim dataset that has the core objective of facilitating safety-oriented research and applications. CitySim has vehicle trajectories extracted from 1140 minutes of drone videos recorded at 12 locations. It covers a variety of road geometries including freeway basic segments, signalized intersections, stop-controlled intersections, and control-free intersections. CitySim was generated through a five-step procedure that ensured trajectory accuracy. The five-step procedure included video stabilization, object filtering, multi-video stitching, object detection and tracking, and enhanced error filtering. Furthermore, CityS
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#36827;&#34892;&#21452;&#21521;&#20114;&#21160;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20801;&#35768;&#31070;&#32463;&#32593;&#32476;&#23637;&#31034;&#20854;&#25152;&#23398;&#22240;&#26524;&#22270;&#65292;&#24182;&#20801;&#35768;&#20154;&#31867;&#20462;&#25913;&#22240;&#26524;&#22270;&#21518;&#37325;&#26032;&#27880;&#20837;&#26426;&#22120;&#20013;&#65292;&#20174;&#32780;&#25552;&#20379;&#20102;&#19968;&#31181;&#35843;&#35797;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#24335;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#35813;&#26041;&#27861;&#21487;&#20197;&#26174;&#33879;&#25913;&#21892;&#39044;&#27979;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2205.09787</link><description>&lt;p&gt;
&#21487;&#20105;&#35758;&#31070;&#32463;&#32593;&#32476;&#30340;&#22240;&#26524;&#21457;&#29616;&#19982;&#30693;&#35782;&#27880;&#20837;
&lt;/p&gt;
&lt;p&gt;
Causal Discovery and Knowledge Injection for Contestable Neural Networks. (arXiv:2205.09787v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.09787
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#36827;&#34892;&#21452;&#21521;&#20114;&#21160;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20801;&#35768;&#31070;&#32463;&#32593;&#32476;&#23637;&#31034;&#20854;&#25152;&#23398;&#22240;&#26524;&#22270;&#65292;&#24182;&#20801;&#35768;&#20154;&#31867;&#20462;&#25913;&#22240;&#26524;&#22270;&#21518;&#37325;&#26032;&#27880;&#20837;&#26426;&#22120;&#20013;&#65292;&#20174;&#32780;&#25552;&#20379;&#20102;&#19968;&#31181;&#35843;&#35797;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#24335;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#35813;&#26041;&#27861;&#21487;&#20197;&#26174;&#33879;&#25913;&#21892;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#22312;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#23427;&#20204;&#26159;&#21542;&#23398;&#20064;&#21040;&#20102;&#30456;&#20851;&#30340;&#22240;&#26524;&#20851;&#31995;&#23578;&#19981;&#28165;&#26970;&#65292;&#32780;&#23427;&#20204;&#30340;&#40657;&#31665;&#29305;&#24615;&#20351;&#24471;&#27169;&#22411;&#26500;&#24314;&#32773;&#38590;&#20197;&#29702;&#35299;&#21644;&#35843;&#35797;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#36890;&#36807;&#20801;&#35768;&#31070;&#32463;&#32593;&#32476;&#39537;&#21160;&#30340;&#26426;&#22120;&#23637;&#31034;&#20854;&#25152;&#23398;&#22240;&#26524;&#22270;&#65292;&#24182;&#20801;&#35768;&#20154;&#31867;&#20462;&#25913;&#22240;&#26524;&#22270;&#21518;&#37325;&#26032;&#27880;&#20837;&#26426;&#22120;&#20013;&#65292;&#23454;&#29616;&#21452;&#21521;&#20114;&#21160;&#12290;&#25152;&#23398;&#27169;&#22411;&#20445;&#35777;&#31526;&#21512;&#22240;&#26524;&#22270;&#24182;&#36981;&#24490;&#19987;&#23478;&#30693;&#35782;&#65292;&#20854;&#20013;&#37096;&#20998;&#30693;&#35782;&#20063;&#21487;&#20197;&#20107;&#20808;&#32473;&#23450;&#12290;&#36890;&#36807;&#23545;&#27169;&#22411;&#34892;&#20026;&#36827;&#34892;&#21487;&#35270;&#21270;&#24182;&#23454;&#29616;&#30693;&#35782;&#27880;&#20837;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#20174;&#25968;&#25454;&#20013;&#21457;&#29616;&#22240;&#26524;&#32467;&#26500;&#24182;&#25903;&#25745;&#39044;&#27979;&#30340;&#20174;&#19994;&#32773;&#36827;&#34892;&#35843;&#35797;&#12290;&#22312;&#30495;&#23454;&#21644;&#21512;&#25104;&#34920;&#26684;&#25968;&#25454;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#25913;&#36827;&#39044;&#27979;&#24615;&#33021;&#39640;&#36798;2.4&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural networks have proven to be effective at solving machine learning tasks but it is unclear whether they learn any relevant causal relationships, while their black-box nature makes it difficult for modellers to understand and debug them. We propose a novel method overcoming these issues by allowing a two-way interaction whereby neural-network-empowered machines can expose the underpinning learnt causal graphs and humans can contest the machines by modifying the causal graphs before re-injecting them into the machines. The learnt models are guaranteed to conform to the graphs and adhere to expert knowledge, some of which can also be given up-front. By building a window into the model behaviour and enabling knowledge injection, our method allows practitioners to debug networks based on the causal structure discovered from the data and underpinning the predictions. Experiments with real and synthetic tabular data show that our method improves predictive performance up to 2.4x while pr
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#22797;&#26434;&#29615;&#22659;&#20013;&#22914;&#20309;&#26356;&#26032;&#39044;&#27979;&#39118;&#38505;&#35780;&#20998;&#26469;&#25351;&#23548;&#24178;&#39044;&#12290;&#20316;&#32773;&#25552;&#20986;&#20351;&#29992;&#30041;&#32622;&#38598;&#30340;&#26041;&#24335;&#36827;&#34892;&#26356;&#26032;&#65292;&#36890;&#36807;&#25214;&#21040;&#30041;&#32622;&#38598;&#30340;&#21512;&#36866;&#22823;&#23567;&#21487;&#20197;&#20445;&#35777;&#26356;&#26032;&#21518;&#30340;&#39118;&#38505;&#35780;&#20998;&#24615;&#33021;&#33391;&#22909;&#65292;&#21516;&#26102;&#20943;&#23569;&#30041;&#32622;&#26679;&#26412;&#25968;&#37327;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#24635;&#25104;&#26412;&#22686;&#38271;&#36895;&#24230;&#26041;&#38754;&#20855;&#26377;&#31454;&#20105;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2202.06374</link><description>&lt;p&gt;
&#38024;&#23545;&#39044;&#27979;&#27169;&#22411;&#26356;&#26032;&#30340;&#30041;&#32622;&#38598;
&lt;/p&gt;
&lt;p&gt;
Holdouts set for predictive model updating. (arXiv:2202.06374v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.06374
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#22797;&#26434;&#29615;&#22659;&#20013;&#22914;&#20309;&#26356;&#26032;&#39044;&#27979;&#39118;&#38505;&#35780;&#20998;&#26469;&#25351;&#23548;&#24178;&#39044;&#12290;&#20316;&#32773;&#25552;&#20986;&#20351;&#29992;&#30041;&#32622;&#38598;&#30340;&#26041;&#24335;&#36827;&#34892;&#26356;&#26032;&#65292;&#36890;&#36807;&#25214;&#21040;&#30041;&#32622;&#38598;&#30340;&#21512;&#36866;&#22823;&#23567;&#21487;&#20197;&#20445;&#35777;&#26356;&#26032;&#21518;&#30340;&#39118;&#38505;&#35780;&#20998;&#24615;&#33021;&#33391;&#22909;&#65292;&#21516;&#26102;&#20943;&#23569;&#30041;&#32622;&#26679;&#26412;&#25968;&#37327;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#24635;&#25104;&#26412;&#22686;&#38271;&#36895;&#24230;&#26041;&#38754;&#20855;&#26377;&#31454;&#20105;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22797;&#26434;&#30340;&#29615;&#22659;&#20013;&#65292;&#22914;&#21307;&#30103;&#20445;&#20581;&#39046;&#22495;&#65292;&#39044;&#27979;&#39118;&#38505;&#35780;&#20998;&#22312;&#25351;&#23548;&#24178;&#39044;&#26041;&#38754;&#36215;&#30528;&#36234;&#26469;&#36234;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#30452;&#25509;&#26356;&#26032;&#29992;&#20110;&#25351;&#23548;&#24178;&#39044;&#30340;&#39118;&#38505;&#35780;&#20998;&#21487;&#33021;&#23548;&#33268;&#20559;&#24046;&#39118;&#38505;&#20272;&#35745;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#8220;&#30041;&#32622;&#38598;&#8221;&#26469;&#36827;&#34892;&#26356;&#26032;-&#30041;&#32622;&#38598;&#26159;&#19968;&#20010;&#19981;&#25509;&#21463;&#39118;&#38505;&#35780;&#20998;&#25351;&#23548;&#24178;&#39044;&#30340;&#20154;&#32676;&#30340;&#23376;&#38598;&#12290;&#22312;&#30041;&#32622;&#38598;&#30340;&#22823;&#23567;&#19978;&#21462;&#24471;&#24179;&#34913;&#26159;&#20851;&#38190;&#65292;&#20197;&#30830;&#20445;&#26356;&#26032;&#21518;&#30340;&#39118;&#38505;&#35780;&#20998;&#24615;&#33021;&#33391;&#22909;&#65292;&#21516;&#26102;&#26368;&#22823;&#38480;&#24230;&#22320;&#20943;&#23569;&#30041;&#32622;&#26679;&#26412;&#30340;&#25968;&#37327;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#20351;&#24471;&#24635;&#25104;&#26412;&#21487;&#20197;&#20197;$O\left(N^{2/3}\right)$&#30340;&#36895;&#24230;&#22686;&#38271;&#65292;&#20854;&#20013;$N$&#26159;&#20154;&#21475;&#35268;&#27169;&#65292;&#24182;&#19988;&#35748;&#20026;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#27809;&#26377;&#31454;&#20105;&#24615;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#36890;&#36807;&#23450;&#20041;&#36866;&#24403;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#20123;&#26465;&#20214;&#65292;&#21487;&#20197;&#24456;&#23481;&#26131;&#22320;&#30830;&#23450;&#26368;&#20339;&#30041;&#32622;&#38598;&#22823;&#23567;&#65288;OHS&#65289;&#65292;&#24182;&#24341;&#20837;&#21442;&#25968;&#21270;&#21644;&#21322;&#21442;&#25968;&#21270;&#31639;&#27861;&#26469;&#20272;&#35745;OHS&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#26368;&#26032;&#39118;&#38505;&#35780;&#20998;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In complex settings, such as healthcare, predictive risk scores play an increasingly crucial role in guiding interventions. However, directly updating risk scores used to guide intervention can lead to biased risk estimates. To address this, we propose updating using a `holdout set' - a subset of the population that does not receive interventions guided by the risk score. Striking a balance in the size of the holdout set is essential, to ensure good performance of the updated risk score whilst minimising the number of held out samples. We prove that this approach enables total costs to grow at a rate $O\left(N^{2/3}\right)$ for a population of size $N$, and argue that in general circumstances there is no competitive alternative. By defining an appropriate loss function, we describe conditions under which an optimal holdout size (OHS) can be readily identified, and introduce parametric and semi-parametric algorithms for OHS estimation, demonstrating their use on a recent risk score for 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#39640;&#20998;&#36776;&#29575;&#24494;&#20998;&#26041;&#31243;&#22312;&#38797;&#28857;&#20248;&#21270;&#20013;&#35774;&#35745;&#20102;&#19981;&#21516;&#30340;&#24494;&#20998;&#26041;&#31243;&#27169;&#22411;&#65292;&#36825;&#20123;&#27169;&#22411;&#22312;&#21452;&#32447;&#24615;&#21338;&#24328;&#20013;&#30340;&#25910;&#25947;&#24615;&#36136;&#19982;&#31163;&#25955;&#26041;&#27861;&#30456;&#21305;&#37197;&#12290;</title><link>http://arxiv.org/abs/2112.13826</link><description>&lt;p&gt;
&#39640;&#20998;&#36776;&#29575;&#24494;&#20998;&#26041;&#31243;&#22312;&#38797;&#28857;&#20248;&#21270;&#22120;&#30340;&#26368;&#21518;&#36845;&#20195;&#25910;&#25947;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Last-Iterate Convergence of Saddle-Point Optimizers via High-Resolution Differential Equations. (arXiv:2112.13826v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.13826
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#39640;&#20998;&#36776;&#29575;&#24494;&#20998;&#26041;&#31243;&#22312;&#38797;&#28857;&#20248;&#21270;&#20013;&#35774;&#35745;&#20102;&#19981;&#21516;&#30340;&#24494;&#20998;&#26041;&#31243;&#27169;&#22411;&#65292;&#36825;&#20123;&#27169;&#22411;&#22312;&#21452;&#32447;&#24615;&#21338;&#24328;&#20013;&#30340;&#25910;&#25947;&#24615;&#36136;&#19982;&#31163;&#25955;&#26041;&#27861;&#30456;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20960;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#19968;&#38454;&#38797;&#28857;&#20248;&#21270;&#26041;&#27861;&#22312;&#34893;&#29983;&#26102;&#21487;&#20197;&#24471;&#21040;&#19982;&#26799;&#24230;&#19979;&#38477;&#19978;&#21319; (GDA) &#26041;&#27861;&#30456;&#21516;&#30340;&#36830;&#32493;&#26102;&#38388;&#24120;&#24494;&#20998;&#26041;&#31243; (ODE)&#65292;&#20294;&#26159;&#36825;&#20123;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#36136;&#22312;&#31616;&#21333;&#30340;&#21452;&#32447;&#24615;&#21338;&#24328;&#20013;&#26159;&#26377;&#24046;&#24322;&#30340;&#12290;&#22240;&#27492;&#65292;ODE &#35270;&#35282;&#22312;&#20998;&#26512;&#21333;&#30446;&#26631;&#20248;&#21270;&#26041;&#27861;&#26041;&#38754;&#24050;&#32463;&#21457;&#25381;&#20102;&#24378;&#22823;&#30340;&#20316;&#29992;&#65292;&#20294;&#22312;&#38797;&#28857;&#20248;&#21270;&#20013;&#30340;&#24212;&#29992;&#23578;&#19981;&#26126;&#26224;&#12290;&#25105;&#20204;&#37319;&#29992;&#22312;&#27969;&#20307;&#21160;&#21147;&#23398;&#20013;&#30740;&#31350;&#30340;&#39640;&#20998;&#36776;&#29575;&#24494;&#20998;&#26041;&#31243; (HRDEs) &#26694;&#26550;&#26469;&#35774;&#35745;&#20960;&#31181;&#38797;&#28857;&#20248;&#21270;&#26041;&#27861;&#30340;&#24494;&#20998;&#26041;&#31243;&#27169;&#22411;&#12290;&#23588;&#20854;&#38656;&#35201;&#25351;&#20986;&#30340;&#26159;&#65292;&#36825;&#20123; HRDEs &#23545;&#24212;&#20110;&#19981;&#21516;&#30340;&#38797;&#28857;&#20248;&#21270;&#26041;&#27861;&#26159;&#19981;&#21516;&#30340;&#12290;&#27492;&#22806;&#65292;&#22312;&#21452;&#32447;&#24615;&#21338;&#24328;&#20013;&#65292;HRDEs &#30340;&#25910;&#25947;&#24615;&#36136;&#19982;&#30456;&#24212;&#30340;&#31163;&#25955;&#26041;&#27861;&#30340;&#24615;&#36136;&#30456;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several widely-used first-order saddle-point optimization methods yield an identical continuous-time ordinary differential equation (ODE) that is identical to that of the Gradient Descent Ascent (GDA) method when derived naively. However, the convergence properties of these methods are qualitatively different, even on simple bilinear games. Thus the ODE perspective, which has proved powerful in analyzing single-objective optimization methods, has not played a similar role in saddle-point optimization.  We adopt a framework studied in fluid dynamics -- known as High-Resolution Differential Equations (HRDEs) -- to design differential equation models for several saddle-point optimization methods. Critically, these HRDEs are distinct for various saddle-point optimization methods. Moreover, in bilinear games, the convergence properties of the HRDEs match the qualitative features of the corresponding discrete methods. Additionally, we show that the HRDE of Optimistic Gradient Descent Ascent 
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20998;&#26512;&#22810;&#20803;&#26497;&#20540;&#30340;&#35889;&#32858;&#31867;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#21644;&#25968;&#20540;&#23454;&#39564;&#23637;&#31034;&#20102;&#20854;&#22312;&#23398;&#20064;&#35282;&#24230;&#27979;&#24230;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2111.07799</link><description>&lt;p&gt;
&#22810;&#20803;&#26497;&#20540;&#30340;&#35889;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Spectral learning of multivariate extremes. (arXiv:2111.07799v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.07799
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20998;&#26512;&#22810;&#20803;&#26497;&#20540;&#30340;&#35889;&#32858;&#31867;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#21644;&#25968;&#20540;&#23454;&#39564;&#23637;&#31034;&#20102;&#20854;&#22312;&#23398;&#20064;&#35282;&#24230;&#27979;&#24230;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20998;&#26512;&#22810;&#20803;&#26497;&#20540;&#30340;&#35889;&#32858;&#31867;&#31639;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20851;&#27880;&#26497;&#20540;&#29702;&#35770;&#20013;&#30001;&#35282;&#24230;&#25110;&#35889;&#27979;&#24230;&#34920;&#24449;&#30340;&#22810;&#20803;&#26497;&#20540;&#30340;&#28176;&#36817;&#20381;&#36182;&#24615;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#30740;&#31350;&#20102;&#35889;&#32858;&#31867;&#30340;&#29702;&#35770;&#24615;&#33021;&#65292;&#35813;&#32858;&#31867;&#22522;&#20110;&#20174;&#26497;&#20540;&#26679;&#26412;&#20013;&#26500;&#24314;&#30340;&#38543;&#26426;k&#26368;&#36817;&#37051;&#22270;&#65292;&#21363;&#23545;&#20110;&#21322;&#24452;&#36229;&#36807;&#19968;&#20010;&#36739;&#22823;&#38408;&#20540;&#30340;&#38543;&#26426;&#21521;&#37327;&#30340;&#35282;&#24230;&#37096;&#20998;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#32447;&#24615;&#22240;&#23376;&#27169;&#22411;&#20135;&#29983;&#30340;&#26497;&#20540;&#30340;&#28176;&#36817;&#20998;&#24067;&#65292;&#24182;&#35777;&#26126;&#65292;&#22312;&#26576;&#20123;&#26465;&#20214;&#19979;&#65292;&#35889;&#32858;&#31867;&#21487;&#20197;&#19968;&#33268;&#22320;&#35782;&#21035;&#20986;&#22312;&#35813;&#27169;&#22411;&#20013;&#20135;&#29983;&#30340;&#26497;&#20540;&#30340;&#32858;&#31867;&#12290;&#22522;&#20110;&#36825;&#20010;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#19968;&#33268;&#24615;&#20272;&#35745;&#31574;&#30053;&#26469;&#23398;&#20064;&#35282;&#24230;&#27979;&#24230;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#19982;&#25968;&#20540;&#23454;&#39564;&#30456;&#32467;&#21512;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#22312;&#26377;&#38480;&#26679;&#26412;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a spectral clustering algorithm for analyzing the dependence structure of multivariate extremes. More specifically, we focus on the asymptotic dependence of multivariate extremes characterized by the angular or spectral measure in extreme value theory. Our work studies the theoretical performance of spectral clustering based on a random $k$-nearest neighbor graph constructed from an extremal sample, i.e., the angular part of random vectors for which the radius exceeds a large threshold. In particular, we derive the asymptotic distribution of extremes arising from a linear factor model and prove that, under certain conditions, spectral clustering can consistently identify the clusters of extremes arising in this model. Leveraging this result we propose a simple consistent estimation strategy for learning the angular measure. Our theoretical findings are complemented with numerical experiments illustrating the finite sample performance of our methods.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#38024;&#23545;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#28176;&#36817;&#27867;&#21270;&#29702;&#35770;&#65292;&#36890;&#36807;&#24341;&#20837;&#32553;&#25918;&#21464;&#20998;&#27491;&#21017;&#21270;&#65292;&#24182;&#21033;&#29992;"&#23725;-&#22871;&#32034;&#23545;&#20598;&#24615;"&#33719;&#24471;&#20102;&#26032;&#30340;&#39044;&#27979;&#30028;&#38480;&#65292;&#35299;&#37322;&#20102;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#22312;&#36229;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;&#34920;&#29616;&#20197;&#21450;&#21452;&#35895;&#29616;&#35937;&#12290;</title><link>http://arxiv.org/abs/2106.04795</link><description>&lt;p&gt;
&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#28176;&#36817;&#29702;&#35770;&#65306;&#36229;&#36234;&#20559;&#24046;-&#26041;&#24046;&#25240;&#34935;
&lt;/p&gt;
&lt;p&gt;
Nonasymptotic theory for two-layer neural networks: Beyond the bias-variance trade-off. (arXiv:2106.04795v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.04795
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#38024;&#23545;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#28176;&#36817;&#27867;&#21270;&#29702;&#35770;&#65292;&#36890;&#36807;&#24341;&#20837;&#32553;&#25918;&#21464;&#20998;&#27491;&#21017;&#21270;&#65292;&#24182;&#21033;&#29992;"&#23725;-&#22871;&#32034;&#23545;&#20598;&#24615;"&#33719;&#24471;&#20102;&#26032;&#30340;&#39044;&#27979;&#30028;&#38480;&#65292;&#35299;&#37322;&#20102;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#22312;&#36229;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;&#34920;&#29616;&#20197;&#21450;&#21452;&#35895;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#22312;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#23454;&#36341;&#20013;&#34920;&#29616;&#20986;&#24778;&#20154;&#30340;&#25928;&#26524;&#65292;&#21363;&#20351;&#22312;&#36229;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#21363;&#27963;&#36291;&#21442;&#25968;&#25968;&#37327;&#30456;&#23545;&#20110;&#26679;&#26412;&#22823;&#23567;&#24456;&#22823;&#12290;&#36825;&#19982;&#20256;&#32479;&#35266;&#28857;&#30456;&#30683;&#30462;&#65292;&#20256;&#32479;&#35266;&#28857;&#35748;&#20026;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#24517;&#39035;&#22312;&#20559;&#24046;&#21644;&#26041;&#24046;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#20197;&#23454;&#29616;&#26368;&#20339;&#27867;&#21270;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#20914;&#31361;&#65292;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#32553;&#25918;&#21464;&#20998;&#27491;&#21017;&#21270;&#65292;&#32473;&#20986;&#20102;&#38024;&#23545;&#20855;&#26377;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#28176;&#36817;&#27867;&#21270;&#29702;&#35770;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#36825;&#20010;&#27491;&#21017;&#21270;&#22120;&#20174;&#26799;&#24230;&#20248;&#21270;&#30340;&#35282;&#24230;&#26469;&#30475;&#31561;&#20215;&#20110;&#23725;&#22238;&#24402;&#65292;&#20294;&#22312;&#25511;&#21046;&#27169;&#22411;&#22797;&#26434;&#24615;&#26041;&#38754;&#36215;&#21040;&#20102;&#31867;&#20284;&#20110;&#20998;&#32452;&#22871;&#32034;&#30340;&#20316;&#29992;&#12290;&#36890;&#36807;&#21033;&#29992;&#36825;&#31181;"&#23725;-&#22871;&#32034;&#23545;&#20598;&#24615;"&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#36866;&#29992;&#20110;&#25152;&#26377;&#32593;&#32476;&#23485;&#24230;&#30340;&#26032;&#30340;&#39044;&#27979;&#30028;&#38480;&#65292;&#20174;&#32780;&#37325;&#29616;&#20102;&#21452;&#35895;&#29616;&#35937;&#12290;&#27492;&#22806;&#65292;&#22312;&#20449;&#21495;&#24378;&#30340;&#24773;&#20917;&#19979;&#65292;&#36229;&#21442;&#25968;&#21270;&#30340;&#26368;&#23567;&#39118;&#38505;&#20302;&#20110;&#20854;&#27424;&#21442;&#25968;&#21270;&#30340;&#23545;&#24212;&#20540;&#65292;&#24182;&#19988;&#20960;&#20046;&#26159;&#26368;&#23567;&#26368;&#22823;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large neural networks have proved remarkably effective in modern deep learning practice, even in the overparametrized regime where the number of active parameters is large relative to the sample size. This contradicts the classical perspective that a machine learning model must trade off bias and variance for optimal generalization. To resolve this conflict, we present a nonasymptotic generalization theory for two-layer neural networks with ReLU activation function by incorporating scaled variation regularization. Interestingly, the regularizer is equivalent to ridge regression from the angle of gradient-based optimization, but plays a similar role to the group lasso in controlling the model complexity. By exploiting this "ridge-lasso duality," we obtain new prediction bounds for all network widths, which reproduce the double descent phenomenon. Moreover, the overparametrized minimum risk is lower than its underparametrized counterpart when the signal is strong, and is nearly minimax o
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;Fr&#233;chet&#22343;&#20540;&#21644;&#24418;&#29366;&#19981;&#21464;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26816;&#27979;&#21151;&#33021;&#24615;&#36718;&#24275;&#20013;&#30340;&#24418;&#29366;&#21464;&#21270;&#65292;&#24182;&#26500;&#24314;&#20102;&#21151;&#33021;&#24615;&#25968;&#25454;&#30340;&#25511;&#21046;&#22270;&#65292;&#21487;&#35299;&#37322;&#24615;&#24378;&#19988;&#33021;&#35782;&#21035;&#28508;&#22312;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2010.02968</link><description>&lt;p&gt;
&#21151;&#33021;&#24615;&#36718;&#24275;&#24314;&#27169;&#21644;&#21487;&#35299;&#37322;&#24418;&#29366;&#21464;&#21270;&#26816;&#27979;&#65306;&#32467;&#21512;Fr&#233;chet&#22343;&#20540;&#19982;&#24418;&#29366;&#19981;&#21464;&#27169;&#22411;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Modelling of functional profiles and explainable shape shifts detection: An approach combining the notion of the Fr\'echet mean with the shape invariant model}. (arXiv:2010.02968v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2010.02968
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;Fr&#233;chet&#22343;&#20540;&#21644;&#24418;&#29366;&#19981;&#21464;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26816;&#27979;&#21151;&#33021;&#24615;&#36718;&#24275;&#20013;&#30340;&#24418;&#29366;&#21464;&#21270;&#65292;&#24182;&#26500;&#24314;&#20102;&#21151;&#33021;&#24615;&#25968;&#25454;&#30340;&#25511;&#21046;&#22270;&#65292;&#21487;&#35299;&#37322;&#24615;&#24378;&#19988;&#33021;&#35782;&#21035;&#28508;&#22312;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#26816;&#27979;&#21151;&#33021;&#24615;&#36718;&#24275;&#20013;&#24418;&#29366;&#21464;&#21270;&#30340;&#24314;&#27169;&#26694;&#26550;&#65292;&#32467;&#21512;&#20102;Fr&#233;chet&#22343;&#20540;&#27010;&#24565;&#21644;&#21464;&#24418;&#27169;&#22411;&#30340;&#27010;&#24565;&#12290;&#21033;&#29992;Fr&#233;chet&#22343;&#20540;&#25552;&#20379;&#30340;&#24191;&#20041;&#22343;&#20540;&#24863;&#30693;&#33021;&#22815;&#25429;&#25417;&#30740;&#31350;&#23545;&#35937;&#36718;&#24275;&#30340;&#20856;&#22411;&#27169;&#24335;&#65292;&#32780;&#21464;&#24418;&#27169;&#22411;&#30340;&#27010;&#24565;&#65292;&#29305;&#21035;&#26159;&#24418;&#29366;&#19981;&#21464;&#27169;&#22411;&#65292;&#20801;&#35768;&#23545;&#36718;&#24275;&#19982;&#20856;&#22411;&#24418;&#29366;&#20043;&#38388;&#30340;&#20559;&#24046;&#36827;&#34892;&#21487;&#35299;&#37322;&#30340;&#21442;&#25968;&#21270;&#12290;&#26500;&#24314;&#21644;&#25552;&#20986;&#20102;&#19982;&#25968;&#25454;&#30340;&#21151;&#33021;&#24615;&#29305;&#24615;&#21644;&#25152;&#37319;&#29992;&#30340;&#21464;&#24418;&#27169;&#22411;&#30456;&#20860;&#23481;&#30340;EWMA&#31867;&#22411;&#25511;&#21046;&#22270;&#65292;&#21033;&#29992;&#30740;&#31350;&#23545;&#35937;&#30340;&#36718;&#24275;&#22312;&#24191;&#20041;&#22343;&#20540;&#24863;&#30693;&#19979;&#30340;&#26576;&#20123;&#24418;&#29366;&#29305;&#24449;&#65292;&#23454;&#29616;&#23545;&#24418;&#29366;&#21644;/&#25110;&#21464;&#24418;&#36807;&#31243;&#28508;&#22312;&#21464;&#21270;&#30340;&#35782;&#21035;&#12290;&#36827;&#19968;&#27493;&#23558;&#24418;&#29366;&#21464;&#24418;&#36807;&#31243;&#30340;&#28508;&#22312;&#21464;&#21270;&#21306;&#20998;&#20026;&#19982;&#24133;&#24230;&#21644;/&#25110;&#30456;&#20301;&#30456;&#20851;&#30340;&#26174;&#33879;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
A modelling framework suitable for detecting shape shifts in functional profiles combining the notion of Fr\'echet mean and the concept of deformation models is developed and proposed. The generalized mean sense offerred by the Fr\'echet mean notion is employed to capture the typical pattern of the profiles under study, while the concept of deformation models, and in particular of the shape invariant model, allows for interpretable parameterizations of profile's deviations from the typical shape. EWMA-type control charts compatible with the functional nature of data and the employed deformation model are built and proposed, exploiting certain shape characteristics of the profiles under study with respect to the generalised mean sense, allowing for the identification of potential shifts concerning the shape and/or the deformation process. Potential shifts in the shape deformation process, are further distingu\-ished to significant shifts with respect to amplitude and/or the phase of the
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20844;&#24179;&#30340;&#23618;&#27425;&#32858;&#31867;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#19981;&#21463;&#36317;&#31163;&#38142;&#25509;&#20934;&#21017;&#30340;&#38480;&#21046;&#65292;&#33021;&#36866;&#24212;&#19981;&#21516;&#30340;&#20844;&#24179;&#24230;&#37327;&#26631;&#20934;&#65292;&#24182;&#21487;&#20197;&#22788;&#29702;&#22810;&#20010;&#21463;&#20445;&#25252;&#32676;&#20307;&#12290;</title><link>http://arxiv.org/abs/2005.03197</link><description>&lt;p&gt;
&#20844;&#24179;&#30340;&#23618;&#27425;&#32858;&#31867;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Fair Algorithms for Hierarchical Agglomerative Clustering. (arXiv:2005.03197v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2005.03197
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20844;&#24179;&#30340;&#23618;&#27425;&#32858;&#31867;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#19981;&#21463;&#36317;&#31163;&#38142;&#25509;&#20934;&#21017;&#30340;&#38480;&#21046;&#65292;&#33021;&#36866;&#24212;&#19981;&#21516;&#30340;&#20844;&#24179;&#24230;&#37327;&#26631;&#20934;&#65292;&#24182;&#21487;&#20197;&#22788;&#29702;&#22810;&#20010;&#21463;&#20445;&#25252;&#32676;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23618;&#27425;&#32858;&#31867;&#31639;&#27861;&#22312;&#29616;&#20195;&#25968;&#25454;&#31185;&#23398;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#26088;&#22312;&#23558;&#25968;&#25454;&#38598;&#20998;&#21106;&#20026;&#32858;&#31867;&#65292;&#24182;&#29983;&#25104;&#25968;&#25454;&#26679;&#26412;&#20043;&#38388;&#30340;&#23618;&#27425;&#20851;&#31995;&#12290;&#23618;&#27425;&#32858;&#31867;&#31639;&#27861;&#34987;&#24212;&#29992;&#20110;&#29983;&#29289;&#23398;&#12289;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#25512;&#33616;&#31995;&#32479;&#31561;&#35768;&#22810;&#24212;&#29992;&#20013;&#12290;&#22240;&#27492;&#65292;&#30830;&#20445;&#36825;&#20123;&#31639;&#27861;&#26159;&#20844;&#24179;&#30340;&#33267;&#20851;&#37325;&#35201; -- &#21363;&#20351;&#25968;&#25454;&#38598;&#23545;&#26576;&#20123;&#21463;&#20445;&#25252;&#32676;&#20307;&#23384;&#22312;&#20559;&#24046;&#65292;&#29983;&#25104;&#30340;&#32858;&#31867;&#36755;&#20986;&#20063;&#19981;&#24212;&#27495;&#35270;&#26469;&#33258;&#20219;&#20309;&#36825;&#20123;&#32676;&#20307;&#30340;&#26679;&#26412;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#38024;&#23545;&#20844;&#24179;&#32858;&#31867;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#22522;&#20110;&#20013;&#24515;&#30340;&#32858;&#31867;&#31639;&#27861;&#65292;&#22914;k-&#20013;&#20540;&#21644;k-&#22343;&#20540;&#32858;&#31867;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20844;&#24179;&#30340;&#23618;&#27425;&#32858;&#31867;&#31639;&#27861;&#65292;&#23427;&#33021;&#22312;&#20351;&#29992;&#20219;&#20309;&#36317;&#31163;&#38142;&#25509;&#20934;&#21017;&#30340;&#24773;&#20917;&#19979;&#24378;&#21046;&#25191;&#34892;&#20844;&#24179;&#32422;&#26463;&#65292;&#24182;&#33021;&#25512;&#24191;&#21040;&#23618;&#27425;&#32858;&#31867;&#30340;&#20219;&#20309;&#33258;&#28982;&#20844;&#24179;&#24230;&#37327;&#65292;&#36866;&#29992;&#20110;&#22810;&#20010;&#21463;&#20445;&#25252;&#32676;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Agglomerative Clustering (HAC) algorithms are extensively utilized in modern data science, and seek to partition the dataset into clusters while generating a hierarchical relationship between the data samples. HAC algorithms are employed in many applications, such as biology, natural language processing, and recommender systems. Thus, it is imperative to ensure that these algorithms are fair -- even if the dataset contains biases against certain protected groups, the cluster outputs generated should not discriminate against samples from any of these groups. However, recent work in clustering fairness has mostly focused on center-based clustering algorithms, such as k-median and k-means clustering. In this paper, we propose fair algorithms for performing HAC that enforce fairness constraints 1) irrespective of the distance linkage criteria used, 2) generalize to any natural measures of clustering fairness for HAC, 3) work for multiple protected groups, and 4) have competiti
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20174;&#35760;&#24405;&#30340;&#32972;&#26223;&#12289;&#20915;&#31574;&#21644;&#32467;&#26524;&#20013;&#20272;&#35745;&#20010;&#20307;&#23618;&#38754;&#30340;&#22240;&#26524;&#25928;&#24212;&#30340;&#38382;&#39064;&#65292;&#32473;&#20986;&#20102;&#22522;&#20110;&#36317;&#31163;&#24230;&#37327;&#30340;&#24191;&#20041;&#21270;&#30028;&#38480;&#20197;&#21450;&#30456;&#24212;&#30340;&#26679;&#26412;&#37325;&#26032;&#21152;&#26435;&#26041;&#27861;&#65292;&#24182;&#35774;&#35745;&#20102;&#26368;&#23567;&#21270;&#30028;&#38480;&#30340;&#34920;&#31034;&#23398;&#20064;&#31639;&#27861;&#26469;&#23454;&#29616;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2001.07426</link><description>&lt;p&gt;
&#24191;&#20041;&#21270;&#30028;&#38480;&#21644;&#34920;&#31034;&#23398;&#20064;&#29992;&#20110;&#20272;&#35745;&#28508;&#22312;&#32467;&#26524;&#21644;&#22240;&#26524;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
Generalization Bounds and Representation Learning for Estimation of Potential Outcomes and Causal Effects. (arXiv:2001.07426v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2001.07426
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20174;&#35760;&#24405;&#30340;&#32972;&#26223;&#12289;&#20915;&#31574;&#21644;&#32467;&#26524;&#20013;&#20272;&#35745;&#20010;&#20307;&#23618;&#38754;&#30340;&#22240;&#26524;&#25928;&#24212;&#30340;&#38382;&#39064;&#65292;&#32473;&#20986;&#20102;&#22522;&#20110;&#36317;&#31163;&#24230;&#37327;&#30340;&#24191;&#20041;&#21270;&#30028;&#38480;&#20197;&#21450;&#30456;&#24212;&#30340;&#26679;&#26412;&#37325;&#26032;&#21152;&#26435;&#26041;&#27861;&#65292;&#24182;&#35774;&#35745;&#20102;&#26368;&#23567;&#21270;&#30028;&#38480;&#30340;&#34920;&#31034;&#23398;&#20064;&#31639;&#27861;&#26469;&#23454;&#29616;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21307;&#30103;&#12289;&#32463;&#27982;&#21644;&#25945;&#32946;&#31561;&#21508;&#39046;&#22495;&#30340;&#20174;&#19994;&#32773;&#37117;&#28212;&#26395;&#24212;&#29992;&#26426;&#22120;&#23398;&#20064;&#26469;&#25913;&#21892;&#20915;&#31574;&#12290;&#30001;&#20110;&#23454;&#39564;&#30340;&#25104;&#26412;&#21644;&#19981;&#20999;&#23454;&#38469;&#24615;&#65292;&#20197;&#21450;&#30005;&#23376;&#35760;&#24405;&#20445;&#30041;&#30340;&#24040;&#22823;&#22686;&#38271;&#65292;&#38750;&#23454;&#39564;&#35266;&#27979;&#25968;&#25454;&#35780;&#20272;&#20915;&#31574;&#30340;&#38382;&#39064;&#24341;&#36215;&#20102;&#20851;&#27880;&#12290;&#26412;&#25991;&#21363;&#26159;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#23637;&#24320;&#30740;&#31350;&#12290;&#25105;&#20204;&#29305;&#21035;&#30740;&#31350;&#20102;&#20174;&#35760;&#24405;&#30340;&#32972;&#26223;&#12289;&#20915;&#31574;&#21644;&#32467;&#26524;&#20013;&#20272;&#35745;&#20010;&#20307;&#23618;&#38754;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#20363;&#22914;&#21333;&#20010;&#24739;&#32773;&#23545;&#19981;&#21516;&#33647;&#29289;&#30340;&#21453;&#24212;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#22522;&#20110;&#25509;&#21463;&#19981;&#21516;&#27835;&#30103;&#32452;&#20043;&#38388;&#36317;&#31163;&#24230;&#37327;&#30340;&#20272;&#35745;&#25928;&#26524;&#35823;&#24046;&#30340;&#24191;&#20041;&#21270;&#30028;&#38480;&#65292;&#20801;&#35768;&#26679;&#26412;&#37325;&#26032;&#21152;&#26435;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#25105;&#20204;&#30028;&#38480;&#32039;&#23494;&#30340;&#26465;&#20214;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#19982;&#26080;&#30417;&#30563;&#39046;&#22495;&#36866;&#24212;&#32467;&#26524;&#30340;&#20851;&#31995;&#12290;&#22312;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#30340;&#25351;&#23548;&#19979;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#26368;&#23567;&#21270;&#30028;&#38480;&#30340;&#34920;&#31034;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#27491;&#21017;&#21270;&#34920;&#31034;&#21521;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Practitioners in diverse fields such as healthcare, economics and education are eager to apply machine learning to improve decision making. The cost and impracticality of performing experiments and a recent monumental increase in electronic record keeping has brought attention to the problem of evaluating decisions based on non-experimental observational data. This is the setting of this work. In particular, we study estimation of individual-level causal effects, such as a single patient's response to alternative medication, from recorded contexts, decisions and outcomes. We give generalization bounds on the error in estimated effects based on distance measures between groups receiving different treatments, allowing for sample re-weighting. We provide conditions under which our bound is tight and show how it relates to results for unsupervised domain adaptation. Led by our theoretical results, we devise representation learning algorithms that minimize our bound, by regularizing the rep
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#32771;&#23519;&#20102;&#31232;&#30095;&#35266;&#27979;&#19979;&#30340;&#20108;&#27425;&#24352;&#37327;&#24674;&#22797;&#38382;&#39064;&#65292;&#21457;&#29616;&#38750;&#20984;&#26041;&#27861;&#33021;&#22815;&#22312;&#32447;&#24615;&#26679;&#26412;&#25968;&#37327;&#19979;&#20445;&#35777;&#35823;&#24046;&#26368;&#23567;&#21270;&#38382;&#39064;&#30340;&#20840;&#23616;&#26497;&#23567;&#20540;&#65292;&#24182;&#25913;&#36827;&#20102;&#35266;&#27979;&#26377;&#38480;&#24773;&#20917;&#19979;&#30340;CP&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/1811.00148</link><description>&lt;p&gt;
&#23545;&#31232;&#30095;&#35266;&#27979;&#19979;&#30340;&#20108;&#27425;&#24352;&#37327;&#36827;&#34892;&#24674;&#22797;&#30340;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Recovery Guarantees for Quadratic Tensors with Sparse Observations. (arXiv:1811.00148v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1811.00148
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#32771;&#23519;&#20102;&#31232;&#30095;&#35266;&#27979;&#19979;&#30340;&#20108;&#27425;&#24352;&#37327;&#24674;&#22797;&#38382;&#39064;&#65292;&#21457;&#29616;&#38750;&#20984;&#26041;&#27861;&#33021;&#22815;&#22312;&#32447;&#24615;&#26679;&#26412;&#25968;&#37327;&#19979;&#20445;&#35777;&#35823;&#24046;&#26368;&#23567;&#21270;&#38382;&#39064;&#30340;&#20840;&#23616;&#26497;&#23567;&#20540;&#65292;&#24182;&#25913;&#36827;&#20102;&#35266;&#27979;&#26377;&#38480;&#24773;&#20917;&#19979;&#30340;CP&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#24352;&#37327;&#23436;&#25972;&#38382;&#39064;&#65292;&#21363;&#39044;&#27979;&#24352;&#37327;&#20013;&#32570;&#22833;&#30340;&#26465;&#30446;&#12290;&#24120;&#29992;&#30340;CP&#27169;&#22411;&#20855;&#26377;&#19977;&#27425;&#20056;&#31215;&#24418;&#24335;&#65292;&#20294;&#19968;&#31181;&#26367;&#20195;&#30340;&#20108;&#27425;&#27169;&#22411;&#23478;&#26063;&#24050;&#32463;&#20174;&#25512;&#33616;&#31995;&#32479;&#31561;&#24212;&#29992;&#20013;&#20986;&#29616;&#65292;&#20854;&#26159;&#23545;&#25104;&#23545;&#20056;&#31215;&#27714;&#21644;&#32780;&#19981;&#26159;&#19977;&#27425;&#20056;&#31215;&#12290;&#38750;&#20984;&#26041;&#27861;&#26159;&#23398;&#20064;&#20108;&#27425;&#27169;&#22411;&#30340;&#39318;&#36873;&#26041;&#27861;&#65292;&#26412;&#30740;&#31350;&#32771;&#23519;&#20102;&#23427;&#20204;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#21644;&#35823;&#24046;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#65292;&#21482;&#38656;&#32447;&#24615;&#25968;&#37327;&#30340;&#26679;&#26412;&#65292;&#24179;&#22343;&#22343;&#26041;&#35823;&#24046;&#30446;&#26631;&#20989;&#25968;&#30340;&#25152;&#26377;&#23616;&#37096;&#26497;&#23567;&#20540;&#37117;&#26159;&#20840;&#23616;&#26497;&#23567;&#20540;&#65292;&#24182;&#21487;&#20197;&#24674;&#22797;&#21407;&#22987;&#24352;&#37327;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#30340;&#23454;&#39564;&#35777;&#23454;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#34920;&#26126;&#22312;&#35266;&#27979;&#25968;&#37327;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#65292;&#20108;&#27425;&#27169;&#22411;&#27604;CP&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the tensor completion problem of predicting the missing entries of a tensor. The commonly used CP model has a triple product form, but an alternate family of quadratic models, which are the sum of pairwise products instead of a triple product, have emerged from applications such as recommendation systems. Non-convex methods are the method of choice for learning quadratic models, and this work examines their sample complexity and error guarantee. Our main result is that with the number of samples being only linear in the dimension, all local minima of the mean squared error objective are global minima and recover the original tensor. We substantiate our theoretical results with experiments on synthetic and real-world data, showing that quadratic models have better performance than CP models where there are a limited amount of observations available.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#24418;&#24335;&#21270;&#25512;&#23548;&#26469;&#35299;&#37322;&#20102;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#65288;RNN&#65289;&#21644;&#38271;&#30701;&#26399;&#35760;&#24518;&#65288;LSTM&#65289;&#32593;&#32476;&#30340;&#22522;&#26412;&#21407;&#29702;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;RNN&#36716;&#21270;&#20026;&#8220;Vanilla LSTM&#8221;&#32593;&#32476;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/1808.03314</link><description>&lt;p&gt;
&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#65288;RNN&#65289;&#21644;&#38271;&#30701;&#26399;&#35760;&#24518;&#65288;LSTM&#65289;&#32593;&#32476;&#30340;&#22522;&#30784;
&lt;/p&gt;
&lt;p&gt;
Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) Network. (arXiv:1808.03314v10 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1808.03314
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24418;&#24335;&#21270;&#25512;&#23548;&#26469;&#35299;&#37322;&#20102;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#65288;RNN&#65289;&#21644;&#38271;&#30701;&#26399;&#35760;&#24518;&#65288;LSTM&#65289;&#32593;&#32476;&#30340;&#22522;&#26412;&#21407;&#29702;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;RNN&#36716;&#21270;&#20026;&#8220;Vanilla LSTM&#8221;&#32593;&#32476;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38271;&#30701;&#26399;&#35760;&#24518;&#65288;LSTM&#65289;&#32593;&#32476;&#22312;&#24191;&#27867;&#30340;&#23454;&#38469;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#20102;&#39640;&#25928;&#30340;&#25928;&#26524;&#65292;&#22240;&#27492;&#22312;&#31185;&#23398;&#26399;&#21002;&#12289;&#25216;&#26415;&#21338;&#23458;&#21644;&#23454;&#29616;&#25351;&#21335;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#22312;&#22823;&#22810;&#25968;&#25991;&#31456;&#20013;&#65292;LSTM&#32593;&#32476;&#21450;&#20854;&#29238;&#31867;RNN&#30340;&#25512;&#25512;&#29702;&#20844;&#24335;&#34987;&#20197;&#20844;&#29702;&#30340;&#26041;&#24335;&#38472;&#36848;&#65292;&#32780;&#35757;&#32451;&#20844;&#24335;&#21017;&#23436;&#20840;&#34987;&#30465;&#30053;&#12290;&#27492;&#22806;&#65292;&#20851;&#20110;&#8220;&#23637;&#24320;&#8221;RNN&#30340;&#25216;&#26415;&#22312;&#25991;&#29486;&#20013;&#36890;&#24120;&#34987;&#25551;&#36848;&#65292;&#20294;&#32570;&#20047;&#35299;&#37322;&#12290;&#26412;&#25991;&#26088;&#22312;&#22312;&#19968;&#31687;&#25991;&#31456;&#20013;&#35299;&#37322;RNN&#21644;LSTM&#30340;&#22522;&#26412;&#21407;&#29702;&#12290;&#25105;&#20204;&#20174;&#20449;&#21495;&#22788;&#29702;&#30340;&#27010;&#24565;&#20013;&#24418;&#24335;&#21270;&#22320;&#25512;&#23548;&#20986;&#20102;RNN&#30340;&#22522;&#26412;&#20844;&#24335;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#35777;&#26126;&#20102;&#19968;&#20010;&#31934;&#30830;&#30340;&#38472;&#36848;&#65292;&#24471;&#21040;&#20102;RNN&#30340;&#23637;&#24320;&#25216;&#26415;&#12290;&#25105;&#20204;&#36824;&#23457;&#26597;&#20102;&#35757;&#32451;&#26631;&#20934;RNN&#30340;&#22256;&#38590;&#65292;&#24182;&#36890;&#36807;&#19968;&#31995;&#21015;&#36923;&#36753;&#35770;&#35777;&#23558;RNN&#36716;&#21270;&#20026;&#8220;Vanilla LSTM&#8221;&#32593;&#32476;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19982;&#35757;&#32451;&#36807;&#31243;&#30456;&#20851;&#30340;&#25152;&#26377;&#26041;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Because of their effectiveness in broad practical applications, LSTM networks have received a wealth of coverage in scientific journals, technical blogs, and implementation guides. However, in most articles, the inference formulas for the LSTM network and its parent, RNN, are stated axiomatically, while the training formulas are omitted altogether. In addition, the technique of "unrolling" an RNN is routinely presented without justification throughout the literature. The goal of this paper is to explain the essential RNN and LSTM fundamentals in a single document. Drawing from concepts in signal processing, we formally derive the canonical RNN formulation from differential equations. We then propose and prove a precise statement, which yields the RNN unrolling technique. We also review the difficulties with training the standard RNN and address them by transforming the RNN into the "Vanilla LSTM" network through a series of logical arguments. We provide all equations pertaining to the 
&lt;/p&gt;</description></item></channel></rss>