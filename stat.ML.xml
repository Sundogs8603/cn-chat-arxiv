<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#24102;&#27927;&#29260;&#26631;&#31614;&#30340;&#31232;&#30095;&#24674;&#22797;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#23454;&#29992;&#20272;&#35745;&#22120;&#65292;&#24182;&#24314;&#31435;&#20102;&#30456;&#24212;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.11233</link><description>&lt;p&gt;
&#24102;&#27927;&#29260;&#26631;&#31614;&#30340;&#31232;&#30095;&#24674;&#22797;&#65306;&#32479;&#35745;&#38480;&#21046;&#19982;&#23454;&#29992;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Sparse Recovery with Shuffled Labels: Statistical Limits and Practical Estimators. (arXiv:2303.11233v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11233
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#24102;&#27927;&#29260;&#26631;&#31614;&#30340;&#31232;&#30095;&#24674;&#22797;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#23454;&#29992;&#20272;&#35745;&#22120;&#65292;&#24182;&#24314;&#31435;&#20102;&#30456;&#24212;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#24102;&#27927;&#29260;&#26631;&#31614;&#30340;&#31232;&#30095;&#24674;&#22797;&#38382;&#39064;&#65292;&#21363;$\by=\bPitrue \bX \bbetatrue + \bw$&#65292;&#20854;&#20013;$\by \in \RR^n$&#65292;$\bPi\in \RR^{n\times n}$&#65292;$\bX\in \RR^{n\times p}$&#65292;$\bbetatrue\in \RR^p$&#65292;$\bw \in \RR^n$&#20998;&#21035;&#26159;&#35266;&#27979;&#32467;&#26524;&#12289;&#26410;&#30693;&#30340;&#32622;&#25442;&#30697;&#38453;&#12289;&#35774;&#35745;&#30697;&#38453;&#12289;&#31232;&#30095;&#20449;&#21495;&#21644;&#21152;&#24615;&#22122;&#22768;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#21516;&#26102;&#37325;&#26500;&#20986;&#32622;&#25442;&#30697;&#38453;$\bPitrue$&#21644;&#31232;&#30095;&#20449;&#21495;$\bbetatrue$&#12290;&#25105;&#20204;&#20174;&#32479;&#35745;&#21644;&#35745;&#31639;&#20004;&#20010;&#26041;&#38754;&#36827;&#34892;&#30740;&#31350;&#12290;&#20174;&#32479;&#35745;&#23398;&#30340;&#35282;&#24230;&#65292;&#25105;&#20204;&#39318;&#20808;&#24314;&#31435;&#20102;&#26679;&#26412;&#25968;$n$&#21644;"&#20449;&#22122;&#27604;"($\snr$)&#30340;&#26368;&#23567;&#26497;&#22823;&#30028;&#65292;&#20197;&#30830;&#20445;&#27491;&#30830;&#24674;&#22797;&#32622;&#25442;&#30697;&#38453;$\bPitrue$&#21644;&#25903;&#25745;&#38598;$\supp(\bbetatrue)$&#65292;&#20855;&#20307;&#32780;&#35328;&#65292;$n\gtrsim k\log p$&#21644;$\log\snr\gtrsim\log n+\frac{k\log p}{n}$&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#31351;&#20030;&#25628;&#32034;&#30340;&#20272;&#35745;&#22120;&#26469;&#30830;&#35748;&#36825;&#20123;&#26368;&#23567;&#26497;&#22823;&#30028;&#30340;&#32039;&#33268;&#24615;&#65292;&#20854;&#34920;&#29616;&#19982;&#26368;&#23567;&#26497;&#22823;&#30028;&#30456;&#21305;&#37197;&#65292;&#20294;&#23384;&#22312;&#19968;&#20010;&#24120;&#25968;&#12290;&#20174;&#35745;&#31639;&#30340;&#35282;&#24230;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#20984;&#26494;&#24347;&#26041;&#27861;&#21644;&#32452;&#21512;&#20248;&#21270;&#26041;&#27861;&#30340;&#23454;&#29992;&#20272;&#35745;&#22120;&#12290;&#24403;&#26679;&#26412;&#25968;$n$&#21644;&#31232;&#30095;&#24230;$k$&#28385;&#36275;&#26576;&#20123;&#26465;&#20214;&#26102;&#65292;&#25105;&#20204;&#26174;&#31034;&#20102;&#36825;&#20004;&#31181;&#26041;&#27861;&#30340;&#23436;&#20840;&#24674;&#22797;&#29702;&#35770;&#20445;&#35777;&#12290;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper considers the sparse recovery with shuffled labels, i.e., $\by = \bPitrue \bX \bbetatrue + \bw$, where $\by \in \RR^n$, $\bPi\in \RR^{n\times n}$, $\bX\in \RR^{n\times p}$, $\bbetatrue\in \RR^p$, $\bw \in \RR^n$ denote the sensing result, the unknown permutation matrix, the design matrix, the sparse signal, and the additive noise, respectively. Our goal is to reconstruct both the permutation matrix $\bPitrue$ and the sparse signal $\bbetatrue$. We investigate this problem from both the statistical and computational aspects. From the statistical aspect, we first establish the minimax lower bounds on the sample number $n$ and the \emph{signal-to-noise ratio} ($\snr$) for the correct recovery of permutation matrix $\bPitrue$ and the support set $\supp(\bbetatrue)$, to be more specific, $n \gtrsim k\log p$ and $\log\snr \gtrsim \log n + \frac{k\log p}{n}$. Then, we confirm the tightness of these minimax lower bounds by presenting an exhaustive-search based estimator whose perfor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20197;&#33258;&#25105;&#20026;&#20013;&#24515;&#37319;&#26679;&#30340;&#37096;&#20998;&#32593;&#32476;&#19978;&#25311;&#21512;&#20302;&#31209;&#27169;&#22411;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#35299;&#20915;&#30446;&#21069;&#30340;&#19968;&#20123;&#32479;&#35745;&#26041;&#27861;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#20174;&#32780;&#31283;&#20581;&#22320;&#24674;&#22797;&#32570;&#22833;&#30340;&#23376;&#32593;&#32476;&#12290;</title><link>http://arxiv.org/abs/2303.11230</link><description>&lt;p&gt;
&#22312;&#20197;&#33258;&#25105;&#20026;&#20013;&#24515;&#37319;&#26679;&#30340;&#37096;&#20998;&#32593;&#32476;&#19978;&#25311;&#21512;&#20302;&#31209;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Fitting Low-rank Models on Egocentrically Sampled Partial Networks. (arXiv:2303.11230v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11230
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20197;&#33258;&#25105;&#20026;&#20013;&#24515;&#37319;&#26679;&#30340;&#37096;&#20998;&#32593;&#32476;&#19978;&#25311;&#21512;&#20302;&#31209;&#27169;&#22411;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#35299;&#20915;&#30446;&#21069;&#30340;&#19968;&#20123;&#32479;&#35745;&#26041;&#27861;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#20174;&#32780;&#31283;&#20581;&#22320;&#24674;&#22797;&#32570;&#22833;&#30340;&#23376;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#32593;&#32476;&#30340;&#32479;&#35745;&#24314;&#27169;&#34987;&#24191;&#27867;&#29992;&#20110;&#25581;&#31034;&#22797;&#26434;&#31995;&#32479;&#20013;&#30340;&#30456;&#20114;&#20316;&#29992;&#26426;&#21046;&#21644;&#39044;&#27979;&#29616;&#23454;&#19990;&#30028;&#20013;&#26410;&#35266;&#27979;&#21040;&#30340;&#32593;&#32476;&#38142;&#25509;&#12290;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#32593;&#32476;&#36830;&#25509;&#26159;&#36890;&#36807;&#33258;&#25105;&#20026;&#20013;&#24515;&#30340;&#37319;&#26679;&#25910;&#38598;&#30340;&#65306;&#39318;&#20808;&#23545;&#33410;&#28857;&#30340;&#23376;&#38598;&#36827;&#34892;&#37319;&#26679;&#65292;&#28982;&#21518;&#35760;&#24405;&#28041;&#21450;&#35813;&#23376;&#38598;&#30340;&#25152;&#26377;&#38142;&#25509;&#65307;&#25152;&#26377;&#20854;&#20182;&#20449;&#24687;&#37117;&#32570;&#22833;&#12290;&#19982;&#8220;&#22343;&#21248;&#38543;&#26426;&#32570;&#22833;&#8221;&#30340;&#20551;&#35774;&#30456;&#27604;&#65292;&#20197;&#33258;&#25105;&#20026;&#20013;&#24515;&#37319;&#26679;&#30340;&#37096;&#20998;&#32593;&#32476;&#38656;&#35201;&#29305;&#21035;&#35774;&#35745;&#30340;&#24314;&#27169;&#31574;&#30053;&#12290;&#24403;&#21069;&#30340;&#32479;&#35745;&#26041;&#27861;&#35201;&#20040;&#35745;&#31639;&#19978;&#19981;&#21487;&#34892;&#65292;&#35201;&#20040;&#22522;&#20110;&#30452;&#35273;&#35774;&#35745;&#32780;&#27809;&#26377;&#29702;&#35770;&#20381;&#25454;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#20197;&#33258;&#25105;&#20026;&#20013;&#24515;&#37319;&#26679;&#30340;&#32593;&#32476;&#30340;&#20302;&#31209;&#36890;&#29992;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#21253;&#25324;&#20960;&#31181;&#27969;&#34892;&#30340;&#32593;&#32476;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#22270;&#35889;&#29305;&#24615;&#19988;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#65292;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#32593;&#32476;&#12290;&#30001;&#20110;&#35813;&#26041;&#27861;&#33021;&#22815;&#24674;&#22797;&#30001;&#33258;&#25105;&#20026;&#20013;&#24515;&#37319;&#26679;&#24341;&#36215;&#30340;&#32570;&#22833;&#23376;&#32593;&#32476;&#65292;&#22240;&#27492;&#24471;&#21040;&#20102;&#31283;&#20581;&#30340;&#24674;&#22797;&#12290;
&lt;/p&gt;
&lt;p&gt;
The statistical modeling of random networks has been widely used to uncover interaction mechanisms in complex systems and to predict unobserved links in real-world networks. In many applications, network connections are collected via egocentric sampling: a subset of nodes is sampled first, after which all links involving this subset are recorded; all other information is missing. Compared with the assumption of ``uniformly missing at random", egocentrically sampled partial networks require specially designed modeling strategies. Current statistical methods are either computationally infeasible or based on intuitive designs without theoretical justification. Here, we propose an approach to fit general low-rank models for egocentrically sampled networks, which include several popular network models. This method is based on graph spectral properties and is computationally efficient for large-scale networks. It results in consistent recovery of missing subnetworks due to egocentric samplin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#8220;&#22240;&#26524;&#35843;&#25972;&#24754;&#35266;&#65288;CAP&#65289;&#31574;&#30053;&#23398;&#20064;&#8221;&#30340;&#31639;&#27861;&#65292;&#26088;&#22312;&#20811;&#26381;&#31163;&#32447;&#24773;&#22659;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#23384;&#22312;&#30340;&#28151;&#28102;&#20559;&#24046;&#21644;&#32570;&#22833;&#35266;&#27979;&#38382;&#39064;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#26500;&#24314;&#22870;&#21169;&#20989;&#25968;&#30340;&#31215;&#20998;&#26041;&#31243;&#31995;&#32479;&#30340;&#35299;&#24182;&#24314;&#31435;&#32622;&#20449;&#21306;&#38388;&#26469;&#36798;&#21040;&#30446;&#30340;&#65292;&#24182;&#24102;&#26377;&#24754;&#35266;&#20027;&#20041;&#22320;&#37319;&#21462;&#34892;&#21160;&#12290;</title><link>http://arxiv.org/abs/2303.11187</link><description>&lt;p&gt;
&#20855;&#26377;&#28151;&#26434;&#20559;&#24046;&#21644;&#32570;&#22833;&#35266;&#27979;&#30340;&#24773;&#22659;&#36172;&#21338;&#26426;&#31574;&#30053;&#23398;&#20064;&#30340;&#32479;&#19968;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Unified Framework of Policy Learning for Contextual Bandit with Confounding Bias and Missing Observations. (arXiv:2303.11187v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11187
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#8220;&#22240;&#26524;&#35843;&#25972;&#24754;&#35266;&#65288;CAP&#65289;&#31574;&#30053;&#23398;&#20064;&#8221;&#30340;&#31639;&#27861;&#65292;&#26088;&#22312;&#20811;&#26381;&#31163;&#32447;&#24773;&#22659;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#23384;&#22312;&#30340;&#28151;&#28102;&#20559;&#24046;&#21644;&#32570;&#22833;&#35266;&#27979;&#38382;&#39064;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#26500;&#24314;&#22870;&#21169;&#20989;&#25968;&#30340;&#31215;&#20998;&#26041;&#31243;&#31995;&#32479;&#30340;&#35299;&#24182;&#24314;&#31435;&#32622;&#20449;&#21306;&#38388;&#26469;&#36798;&#21040;&#30446;&#30340;&#65292;&#24182;&#24102;&#26377;&#24754;&#35266;&#20027;&#20041;&#22320;&#37319;&#21462;&#34892;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#31163;&#32447;&#24773;&#22659;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#26088;&#22312;&#20351;&#29992;&#35266;&#23519;&#25968;&#25454;&#33719;&#24471;&#26368;&#20248;&#31574;&#30053;&#12290;&#20294;&#26159;&#65292;&#36825;&#20123;&#25968;&#25454;&#36890;&#24120;&#23384;&#22312;&#20004;&#20010;&#19981;&#36275;&#65306;(i)&#19968;&#20123;&#28151;&#28102;&#34892;&#21160;&#30340;&#21464;&#37327;&#26410;&#34987;&#35266;&#23519;&#21040;&#65292;(ii)&#37319;&#38598;&#21040;&#30340;&#25968;&#25454;&#20013;&#23384;&#22312;&#32570;&#22833;&#35266;&#27979;&#12290;&#26410;&#34987;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#23548;&#33268;&#28151;&#28102;&#20559;&#24046;&#65292;&#32570;&#22833;&#35266;&#27979;&#21017;&#23548;&#33268;&#20559;&#24046;&#21644;&#20302;&#25928;&#38382;&#39064;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#25361;&#25112;&#65292;&#24182;&#20174;&#35266;&#23519;&#21040;&#30340;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#26368;&#20248;&#31574;&#30053;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#22240;&#26524;&#35843;&#25972;&#24754;&#35266;&#65288;CAP&#65289;&#31574;&#30053;&#23398;&#20064;&#30340;&#26032;&#31639;&#27861;&#65292;&#23427;&#23558;&#22870;&#21169;&#20989;&#25968;&#26500;&#24314;&#20026;&#31215;&#20998;&#26041;&#31243;&#31995;&#32479;&#30340;&#35299;&#65292;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#65292;&#24182;&#24102;&#26377;&#24754;&#35266;&#20027;&#20041;&#22320;&#37319;&#21462;&#34892;&#21160;&#12290;&#22312;&#25968;&#25454;&#30340;&#28201;&#21644;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#20026;&#31163;&#32447;&#24773;&#22659;&#36172;&#21338;&#26426;&#38382;&#39064;&#21457;&#23637;&#20102;CAP&#20122;&#20248;&#35299;&#30340;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the offline contextual bandit problem, where we aim to acquire an optimal policy using observational data. However, this data usually contains two deficiencies: (i) some variables that confound actions are not observed, and (ii) missing observations exist in the collected data. Unobserved confounders lead to a confounding bias and missing observations cause bias and inefficiency problems. To overcome these challenges and learn the optimal policy from the observed dataset, we present a new algorithm called Causal-Adjusted Pessimistic (CAP) policy learning, which forms the reward function as the solution of an integral equation system, builds a confidence set, and greedily takes action with pessimism. With mild assumptions on the data, we develop an upper bound to the suboptimality of CAP for the offline contextual bandit problem.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;ConRad&#30340;&#27169;&#22411;&#65292;&#23558;&#25918;&#23556;&#32452;&#23398;&#21644;DNN&#39044;&#27979;&#30340;&#29983;&#29289;&#26631;&#24535;&#29289;&#38598;&#25104;&#21040;&#32954;&#30284;CT&#25195;&#25551;&#30340;&#21487;&#35299;&#37322;&#20998;&#31867;&#22120;&#20013;&#65292;&#26080;&#38656;&#32791;&#36153;&#21171;&#21160;&#23494;&#38598;&#21644;&#32791;&#26102;&#30340;&#29983;&#29289;&#26631;&#24535;&#29289;&#12290;&#35813;&#27169;&#22411;&#30340;&#24615;&#33021;&#20248;&#20110;CNN&#40657;&#21283;&#23376;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2303.11177</link><description>&lt;p&gt;
&#24453;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#25918;&#23556;&#32452;&#23398;&#21644;&#32959;&#30244;&#29983;&#29289;&#26631;&#24535;&#29289;&#30340;&#25972;&#21512;
&lt;/p&gt;
&lt;p&gt;
Integration of Radiomics and Tumor Biomarkers in Interpretable Machine Learning Models. (arXiv:2303.11177v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11177
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;ConRad&#30340;&#27169;&#22411;&#65292;&#23558;&#25918;&#23556;&#32452;&#23398;&#21644;DNN&#39044;&#27979;&#30340;&#29983;&#29289;&#26631;&#24535;&#29289;&#38598;&#25104;&#21040;&#32954;&#30284;CT&#25195;&#25551;&#30340;&#21487;&#35299;&#37322;&#20998;&#31867;&#22120;&#20013;&#65292;&#26080;&#38656;&#32791;&#36153;&#21171;&#21160;&#23494;&#38598;&#21644;&#32791;&#26102;&#30340;&#29983;&#29289;&#26631;&#24535;&#29289;&#12290;&#35813;&#27169;&#22411;&#30340;&#24615;&#33021;&#20248;&#20110;CNN&#40657;&#21283;&#23376;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#39046;&#22495;&#34920;&#29616;&#20986;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#24615;&#33021;&#65292;&#20294;&#23427;&#20204;&#22312;&#20351;&#29992;&#21307;&#23398;&#25104;&#20687;&#36827;&#34892;&#30284;&#30151;&#35786;&#26029;&#21644;&#39044;&#21518;&#30340;&#23454;&#38469;&#24212;&#29992;&#26041;&#38754;&#21463;&#21040;&#38480;&#21046;&#12290;&#20854;&#20013;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#26159;&#23558;&#35786;&#26029;&#24615;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#21040;&#25918;&#23556;&#23398;&#21644;&#32959;&#30244;&#23398;&#24212;&#29992;&#20013;&#30340;&#21487;&#35299;&#37322;&#24615;&#19981;&#36275;&#65292;&#20351;&#20020;&#24202;&#21307;&#29983;&#26080;&#27861;&#29702;&#35299;&#27169;&#22411;&#39044;&#27979;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30740;&#31350;&#21644;&#25552;&#20986;&#20102;&#19987;&#23478;&#23548;&#20986;&#30340;&#25918;&#23556;&#32452;&#23398;&#21644;DNN&#39044;&#27979;&#30340;&#29983;&#29289;&#26631;&#24535;&#29289;&#22312;&#21487;&#35299;&#37322;&#20998;&#31867;&#22120;&#20013;&#30340;&#38598;&#25104;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;ConRad&#65292;&#29992;&#20110;&#32954;&#30284;&#30340;&#35745;&#31639;&#26426;&#26029;&#23618;&#25195;&#25551;&#65288;CT&#65289;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#32959;&#30244;&#29983;&#29289;&#26631;&#24535;&#29289;&#26159;&#20174;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#65288;CBM&#65289;&#39044;&#27979;&#30340;&#65292;&#22240;&#27492;&#19968;&#26086;&#35757;&#32451;&#22909;&#65292;&#25105;&#20204;&#30340;ConRad&#27169;&#22411;&#23601;&#19981;&#38656;&#35201;&#32791;&#36153;&#21171;&#21160;&#23494;&#38598;&#21644;&#32791;&#26102;&#30340;&#29983;&#29289;&#26631;&#24535;&#29289;&#12290;&#22312;&#25105;&#20204;&#30340;&#35780;&#20272;&#21644;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;ConRad&#30340;&#21807;&#19968;&#36755;&#20837;&#26159;&#20998;&#21106;&#30340;CT&#25195;&#25551;&#12290;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#19982;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#21518;&#32773;&#20805;&#24403;&#40657;&#21283;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the unprecedented performance of deep neural networks (DNNs) in computer vision, their practical application in the diagnosis and prognosis of cancer using medical imaging has been limited. One of the critical challenges for integrating diagnostic DNNs into radiological and oncological applications is their lack of interpretability, preventing clinicians from understanding the model predictions. Therefore, we study and propose the integration of expert-derived radiomics and DNN-predicted biomarkers in interpretable classifiers which we call ConRad, for computerized tomography (CT) scans of lung cancer. Importantly, the tumor biomarkers are predicted from a concept bottleneck model (CBM) such that once trained, our ConRad models do not require labor-intensive and time-consuming biomarkers. In our evaluation and practical application, the only input to ConRad is a segmented CT scan. The proposed model is compared to convolutional neural networks (CNNs) which act as a black box cl
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27491;&#21017;&#21270;&#22238;&#24402;&#26041;&#27861;MADMMplasso&#65292;&#33021;&#22815;&#25214;&#21040;&#20855;&#26377;&#22810;&#20010;&#30456;&#20851;&#21709;&#24212;&#30340;&#21327;&#21464;&#37327;&#21644;&#23427;&#20204;&#30340;&#23545;&#24212;&#20132;&#20114;&#20316;&#29992;&#65292;&#23545;&#20110;&#22788;&#29702;&#30456;&#20851;&#21709;&#24212;&#21644;&#20132;&#20114;&#25928;&#24212;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2303.11155</link><description>&lt;p&gt;
&#19968;&#31181;&#24102;&#26377;&#37325;&#21472;&#32452;&#21644;&#20132;&#20114;&#25928;&#24212;&#30340;&#22810;&#21709;&#24212;&#22238;&#24402;ADMM&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
An ADMM approach for multi-response regression with overlapping groups and interaction effects. (arXiv:2303.11155v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11155
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27491;&#21017;&#21270;&#22238;&#24402;&#26041;&#27861;MADMMplasso&#65292;&#33021;&#22815;&#25214;&#21040;&#20855;&#26377;&#22810;&#20010;&#30456;&#20851;&#21709;&#24212;&#30340;&#21327;&#21464;&#37327;&#21644;&#23427;&#20204;&#30340;&#23545;&#24212;&#20132;&#20114;&#20316;&#29992;&#65292;&#23545;&#20110;&#22788;&#29702;&#30456;&#20851;&#21709;&#24212;&#21644;&#20132;&#20114;&#25928;&#24212;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#23384;&#22312;&#26576;&#20123;&#21709;&#24212;&#20043;&#38388;&#30340;&#32467;&#26500;&#20851;&#31995;&#20197;&#21450;&#21327;&#21464;&#37327;&#19982;&#19968;&#32452;&#20462;&#25913;&#21464;&#37327;&#20043;&#38388;&#20851;&#31995;&#30340;&#35268;&#33539;&#21270;&#22810;&#21709;&#24212;&#22238;&#24402;&#38382;&#39064;&#12290;&#20026;&#20102;&#22788;&#29702;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27491;&#21017;&#21270;&#22238;&#24402;&#26041;&#27861;MADMMplasso&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25214;&#21040;&#20855;&#26377;&#22810;&#20010;&#30456;&#20851;&#21709;&#24212;&#30340;&#21327;&#21464;&#37327;&#21644;&#23427;&#20204;&#30340;&#23545;&#24212;&#20132;&#20114;&#20316;&#29992;&#12290;&#25105;&#20204;&#20801;&#35768;&#22312;&#39318;&#20808;&#32771;&#34385;&#30456;&#24212;&#21327;&#21464;&#37327;&#30340;&#20027;&#35201;&#39033;&#26159;&#21542;&#22312;&#27169;&#22411;&#20013;&#30340;&#65288;&#24369;&#65289;&#19981;&#23545;&#31216;&#30340;&#20998;&#23618;&#26041;&#24335;&#19979;&#21253;&#21547;&#21327;&#21464;&#37327;&#21644;&#20462;&#25913;&#21464;&#37327;&#20043;&#38388;&#30340;&#20132;&#20114;&#39033;&#12290;&#20026;&#20102;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;ADMM&#31639;&#27861;&#65292;&#20801;&#35768;&#25105;&#20204;&#20197;&#31616;&#21333;&#30340;&#26041;&#24335;&#23454;&#29616;&#37325;&#21472;&#32452;&#12290;&#20223;&#30495;&#21644;&#33647;&#29702;&#22522;&#22240;&#32452;&#31579;&#36873;&#25968;&#25454;&#38598;&#20998;&#26512;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#22788;&#29702;&#30456;&#20851;&#21709;&#24212;&#21644;&#20132;&#20114;&#25928;&#24212;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#65292;&#26080;&#35770;&#26159;&#22312;&#39044;&#27979;&#36824;&#26159;&#22312;&#26041;&#24046;&#26041;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider the regularized multi-response regression problem where there exists some structural relation within the responses and also between the covariates and a set of modifying variables. To handle this problem, we propose MADMMplasso, a novel regularized regression method. This method is able to find covariates and their corresponding interactions, with some joint association with multiple related responses. We allow the interaction term between covariate and modifying variable to be included in a (weak) asymmetrical hierarchical manner by first considering whether the corresponding covariate main term is in the model. For parameter estimation, we develop an ADMM algorithm that allows us to implement the overlapping groups in a simple way. The results from the simulations and analysis of a pharmacogenomic screen data set show that the proposed method has an advantage in handling correlated responses and interaction effects, both with respect to prediction and varia
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21344;&#25454;&#26680;PCA&#26041;&#27861;&#36827;&#34892;&#25925;&#38556;&#26816;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#19988;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.11138</link><description>&lt;p&gt;
&#22522;&#20110;&#21344;&#25454;&#26680;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#25925;&#38556;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Fault Detection via Occupation Kernel Principal Component Analysis. (arXiv:2303.11138v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11138
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21344;&#25454;&#26680;PCA&#26041;&#27861;&#36827;&#34892;&#25925;&#38556;&#26816;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#19988;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#31995;&#32479;&#30340;&#21487;&#38752;&#25805;&#20316;&#24456;&#22823;&#31243;&#24230;&#19978;&#20381;&#36182;&#20110;&#26816;&#27979;&#22522;&#30784;&#21160;&#24577;&#31995;&#32479;&#20013;&#30340;&#25925;&#38556;&#12290;&#34429;&#28982;&#20256;&#32479;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#24050;&#34987;&#24191;&#27867;&#29992;&#20110;&#25925;&#38556;&#26816;&#27979;&#65292;&#20294;&#22522;&#20110;&#25968;&#25454;&#30340;&#26041;&#27861;&#22240;&#20854;&#26131;&#20110;&#37096;&#32626;&#21644;&#23545;&#19987;&#23478;&#30693;&#35782;&#38656;&#27714;&#26368;&#23567;&#30340;&#29305;&#28857;&#32780;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21344;&#25454;&#26680;&#36827;&#34892;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#30340;&#26032;&#26041;&#27861;&#12290;&#21344;&#25454;&#26680;&#20135;&#29983;&#30340;&#29305;&#24449;&#26144;&#23556;&#36866;&#29992;&#20110;&#27979;&#37327;&#25968;&#25454;&#65292;&#30001;&#20110;&#20351;&#29992;&#31215;&#20998;&#20855;&#26377;&#20869;&#22312;&#30340;&#22122;&#22768;&#40065;&#26834;&#24615;&#65292;&#24182;&#19988;&#21487;&#20197;&#21033;&#29992;&#38271;&#24230;&#21487;&#21464;&#30340;&#19981;&#35268;&#21017;&#37319;&#26679;&#31995;&#32479;&#36712;&#36857;&#36827;&#34892;PCA&#12290;&#21344;&#25454;&#26680;PCA&#26041;&#27861;&#34987;&#29992;&#20110;&#24320;&#21457;&#19968;&#31181;&#37325;&#26500;&#35823;&#24046;&#26041;&#27861;&#36827;&#34892;&#25925;&#38556;&#26816;&#27979;&#65292;&#24182;&#19988;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The reliable operation of automatic systems is heavily dependent on the ability to detect faults in the underlying dynamical system. While traditional model-based methods have been widely used for fault detection, data-driven approaches have garnered increasing attention due to their ease of deployment and minimal need for expert knowledge. In this paper, we present a novel principal component analysis (PCA) method that uses occupation kernels. Occupation kernels result in feature maps that are tailored to the measured data, have inherent noise-robustness due to the use of integration, and can utilize irregularly sampled system trajectories of variable lengths for PCA. The occupation kernel PCA method is used to develop a reconstruction error approach to fault detection and its efficacy is validated using numerical simulations.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#22522;&#20110;&#20998;&#20301;&#25968;&#21644;&#30697;&#36924;&#36817;&#30340;&#20004;&#31867;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#23398;&#20064;&#27010;&#29575;&#31354;&#38388;&#20013;&#20998;&#24067;&#30340;&#20989;&#25968;&#65292;&#24182;&#28151;&#21512;&#36825;&#20123;&#29305;&#24449;&#20197;&#20248;&#20110;&#29616;&#26377;&#32593;&#32476;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2303.11060</link><description>&lt;p&gt;
&#20998;&#20301;&#25968;&#31070;&#32463;&#32593;&#32476;&#19982;&#30697;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#20998;&#24067;&#30340;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Quantile and moment neural networks for learning functionals of distributions. (arXiv:2303.11060v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11060
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#22522;&#20110;&#20998;&#20301;&#25968;&#21644;&#30697;&#36924;&#36817;&#30340;&#20004;&#31867;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#23398;&#20064;&#27010;&#29575;&#31354;&#38388;&#20013;&#20998;&#24067;&#30340;&#20989;&#25968;&#65292;&#24182;&#28151;&#21512;&#36825;&#20123;&#29305;&#24449;&#20197;&#20248;&#20110;&#29616;&#26377;&#32593;&#32476;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#29992;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#27010;&#29575;&#31354;&#38388;&#20013;&#20998;&#24067;&#20989;&#25968;&#30340;&#26041;&#27861;&#12290;&#25552;&#20986;&#20102;&#22522;&#20110;&#20998;&#20301;&#25968;&#21644;&#30697;&#36924;&#36817;&#30340;&#20004;&#31867;&#31070;&#32463;&#32593;&#32476;&#65292;&#29702;&#35770;&#19978;&#25903;&#25345;&#23427;&#20204;&#30340;&#26222;&#36866;&#36924;&#36817;&#23450;&#29702;&#12290;&#36890;&#36807;&#22312;&#20854;&#20182;&#26032;&#32593;&#32476;&#20013;&#28151;&#21512;&#20998;&#20301;&#25968;&#21644;&#30697;&#29305;&#24449;&#65292;&#25105;&#20204;&#24320;&#21457;&#20986;&#22312;&#28041;&#21450;&#21333;&#21464;&#37327;&#20998;&#24067;&#30340;&#25968;&#20540;&#27979;&#35797;&#26696;&#20363;&#20013;&#20248;&#20110;&#29616;&#26377;&#32593;&#32476;&#30340;&#26041;&#26696;&#12290;&#23545;&#20110;&#21452;&#21464;&#37327;&#20998;&#24067;&#65292;&#30697;&#31070;&#32463;&#32593;&#32476;&#20248;&#20110;&#25152;&#26377;&#20854;&#20182;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study news neural networks to approximate function of distributions in a probability space. Two classes of neural networks based on quantile and moment approximation are proposed to learn these functions and are theoretically supported by universal approximation theorems. By mixing the quantile and moment features in other new networks, we develop schemes that outperform existing networks on numerical test cases involving univariate distributions. For bivariate distributions, the moment neural network outperforms all other networks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25506;&#32034;&#26080;&#30417;&#30563;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#28508;&#22312;&#31354;&#38388;&#26469;&#21457;&#29616;&#25968;&#25454;&#20013;&#26377;&#24847;&#20041;&#30340;&#23646;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26497;&#31471;&#20540;&#22240;&#26524;&#20998;&#31163; (CDEV) &#30340;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#27979;&#35797;&#40120;&#40060;&#36890;&#20449;&#31995;&#32479;&#24182;&#21457;&#29616;&#20854;&#20013;&#23384;&#22312;&#35821;&#27861;&#12290;</title><link>http://arxiv.org/abs/2303.10931</link><description>&lt;p&gt;
&#36890;&#36807;&#28508;&#22312;&#31354;&#38388;&#25506;&#32034;&#21644;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#36924;&#36817;&#26410;&#30693;&#30340;&#36890;&#20449;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Approaching an unknown communication system by latent space exploration and causal inference. (arXiv:2303.10931v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10931
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25506;&#32034;&#26080;&#30417;&#30563;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#28508;&#22312;&#31354;&#38388;&#26469;&#21457;&#29616;&#25968;&#25454;&#20013;&#26377;&#24847;&#20041;&#30340;&#23646;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26497;&#31471;&#20540;&#22240;&#26524;&#20998;&#31163; (CDEV) &#30340;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#27979;&#35797;&#40120;&#40060;&#36890;&#20449;&#31995;&#32479;&#24182;&#21457;&#29616;&#20854;&#20013;&#23384;&#22312;&#35821;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#25506;&#32034;&#26080;&#30417;&#30563;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#28508;&#22312;&#31354;&#38388;&#26469;&#21457;&#29616;&#25968;&#25454;&#20013;&#26377;&#24847;&#20041;&#30340;&#23646;&#24615;&#12290;&#25105;&#20204;&#23558;&#23545;&#21333;&#20010;&#28508;&#22312;&#21464;&#37327;&#30340;&#25805;&#20316;&#19982;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#19968;&#20010;&#31216;&#20026;&#26497;&#31471;&#20540;&#22240;&#26524;&#20998;&#31163; (CDEV) &#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#23545;&#27169;&#22411;&#21487;&#35299;&#37322;&#24615;&#30340;&#27934;&#23519;&#21147;&#12290;&#36890;&#36807;&#27492;&#25216;&#26415;&#65292;&#25105;&#20204;&#21487;&#20197;&#25512;&#26029;&#27169;&#22411;&#23558;&#26410;&#30693;&#25968;&#25454;&#32534;&#30721;&#20026;&#26377;&#24847;&#20041;&#30340;&#23646;&#24615;&#12290;&#25105;&#20204;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#27979;&#35797;&#40120;&#40060;&#30340;&#36890;&#20449;&#31995;&#32479;&#20013;&#23384;&#22312;&#21738;&#20123;&#26377;&#24847;&#20041;&#30340;&#23646;&#24615;&#65292;&#40120;&#40060;&#36890;&#20449;&#26159;&#26368;&#20855;&#26377;&#21560;&#24341;&#21147;&#21644;&#30740;&#31350;&#19981;&#36275;&#30340;&#21160;&#29289;&#36890;&#20449;&#20043;&#19968;&#12290;&#25105;&#20204;&#35757;&#32451;&#20102;&#19968;&#20010;&#32593;&#32476;&#65292;&#35813;&#32593;&#32476;&#24050;&#34987;&#35777;&#26126;&#33021;&#22815;&#23398;&#20064;&#21040;&#26377;&#24847;&#20041;&#30340;&#35821;&#38899;&#34920;&#31034;&#65292;&#24182;&#27979;&#35797;&#26159;&#21542;&#21487;&#20197;&#21033;&#29992;&#36825;&#31181;&#26080;&#30417;&#30563;&#23398;&#20064;&#26469;&#35299;&#26512;&#21478;&#19968;&#20010;&#25105;&#20204;&#27809;&#26377;&#22320;&#38754;&#30495;&#30456;&#30340;&#22768;&#38899;&#36890;&#20449;&#31995;&#32479;&#30340;&#23646;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#25216;&#26415;&#34920;&#26126;&#65292;&#40120;&#40060;&#22312;&#20854;&#22768;&#38899;&#36890;&#20449;&#20013;&#23384;&#22312;&#35821;&#27861;&#65292;&#36825;&#26159;&#20197;&#21069;&#19981;&#30693;&#36947;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a methodology for discovering meaningful properties in data by exploring the latent space of unsupervised deep generative models. We combine manipulation of individual latent variables to extreme values outside the training range with methods inspired by causal inference into an approach we call causal disentanglement with extreme values (CDEV) and show that this approach yields insights for model interpretability. Using this technique, we can infer what properties of unknown data the model encodes as meaningful. We apply the methodology to test what is meaningful in the communication system of sperm whales, one of the most intriguing and understudied animal communication systems. We train a network that has been shown to learn meaningful representations of speech and test whether we can leverage such unsupervised learning to decipher the properties of another vocal communication system for which we have no ground truth. The proposed technique suggests that sperm wh
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#31639;&#27861;RAFFLE&#65292;&#33021;&#22815;&#22312;&#20302;&#31209;MDP&#19979;&#23454;&#29616;&#26080;&#22870;&#21169;&#25506;&#32034;&#65292;&#24182;&#19988;&#20855;&#26377;&#26174;&#33879;&#25913;&#36827;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2303.10859</link><description>&lt;p&gt;
&#20302;&#31209;MDP&#19979;&#26080;&#22870;&#21169;&#24378;&#21270;&#23398;&#20064;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
Improved Sample Complexity for Reward-free Reinforcement Learning under Low-rank MDPs. (arXiv:2303.10859v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10859
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#31639;&#27861;RAFFLE&#65292;&#33021;&#22815;&#22312;&#20302;&#31209;MDP&#19979;&#23454;&#29616;&#26080;&#22870;&#21169;&#25506;&#32034;&#65292;&#24182;&#19988;&#20855;&#26377;&#26174;&#33879;&#25913;&#36827;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26080;&#22870;&#21169;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#26234;&#33021;&#20307;&#39318;&#20808;&#22312;&#27809;&#26377;&#22870;&#21169;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#25506;&#32034;&#29615;&#22659;&#65292;&#20197;&#20415;&#22312;&#20219;&#20309;&#32473;&#23450;&#30340;&#22870;&#21169;&#19979;&#23454;&#29616;&#26576;&#20123;&#23398;&#20064;&#30446;&#26631;&#12290;&#26412;&#25991;&#20391;&#37325;&#20110;&#20302;&#31209;MDP&#27169;&#22411;&#19979;&#30340;&#26080;&#22870;&#21169;&#24378;&#21270;&#23398;&#20064;&#65292;&#20854;&#20013;&#34920;&#31034;&#21644;&#32447;&#24615;&#26435;&#21521;&#37327;&#22343;&#26410;&#30693;&#12290;&#34429;&#28982;&#38024;&#23545;&#26080;&#22870;&#21169;&#20302;&#31209;MDP&#25552;&#20986;&#20102;&#21508;&#31181;&#31639;&#27861;&#65292;&#20294;&#30456;&#24212;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20173;&#36828;&#26410;&#36798;&#21040;&#20196;&#20154;&#28385;&#24847;&#30340;&#27700;&#24179;&#12290;&#26412;&#25991;&#39318;&#20808;&#25552;&#20379;&#20102;&#20302;&#31209;MDP&#19979;&#30340;&#39318;&#20010;&#24050;&#30693;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#19979;&#30028;&#65292;&#35813;&#19979;&#30028;&#24847;&#21619;&#30528;&#22312;&#20302;&#31209;MDP&#19979;&#25214;&#21040;&#25509;&#36817;&#26368;&#20248;&#31574;&#30053;&#27604;&#22312;&#32447;&#24615;MDP&#19979;&#26356;&#21152;&#22256;&#38590;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#31639;&#27861;RAFFLE&#65292;&#24182;&#19988;&#36890;&#36807;&#26080;&#22870;&#21169;&#25506;&#32034;&#65292;&#23427;&#33021;&#22815;&#33719;&#24471;$\epsilon$-&#26368;&#20248;&#31574;&#30053;&#21644;$\epsilon$-&#20934;&#30830;&#30340;&#31995;&#32479;&#35782;&#21035;&#65292;&#19988;&#20854;&#26679;&#26412;&#22797;&#26434;&#24230;&#26174;&#33879;&#20248;&#20110;&#20197;&#21069;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In reward-free reinforcement learning (RL), an agent explores the environment first without any reward information, in order to achieve certain learning goals afterwards for any given reward. In this paper we focus on reward-free RL under low-rank MDP models, in which both the representation and linear weight vectors are unknown. Although various algorithms have been proposed for reward-free low-rank MDPs, the corresponding sample complexity is still far from being satisfactory. In this work, we first provide the first known sample complexity lower bound that holds for any algorithm under low-rank MDPs. This lower bound implies it is strictly harder to find a near-optimal policy under low-rank MDPs than under linear MDPs. We then propose a novel model-based algorithm, coined RAFFLE, and show it can both find an $\epsilon$-optimal policy and achieve an $\epsilon$-accurate system identification via reward-free exploration, with a sample complexity significantly improving the previous res
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27010;&#36848;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#32622;&#20449;&#24230;&#26657;&#20934;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#29616;&#20195;&#26657;&#20934;&#25216;&#26415;&#30340;&#32463;&#39564;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2303.10761</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#30340;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Calibration of Neural Networks. (arXiv:2303.10761v1 [cs.NE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10761
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27010;&#36848;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#32622;&#20449;&#24230;&#26657;&#20934;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#29616;&#20195;&#26657;&#20934;&#25216;&#26415;&#30340;&#32463;&#39564;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35299;&#20915;&#29616;&#23454;&#38382;&#39064;&#26102;&#65292;&#31070;&#32463;&#32593;&#32476;&#19981;&#20165;&#38656;&#35201;&#36827;&#34892;&#20934;&#30830;&#30340;&#39044;&#27979;&#65292;&#36824;&#38656;&#35201;&#25552;&#20379;&#39044;&#27979;&#32467;&#26524;&#30340;&#32622;&#20449;&#24230;&#27700;&#24179;&#12290;&#27169;&#22411;&#30340;&#26657;&#20934;&#25351;&#30340;&#26159;&#20272;&#35745;&#30340;&#32622;&#20449;&#24230;&#19982;&#30495;&#23454;&#27010;&#29575;&#20043;&#38388;&#30340;&#25509;&#36817;&#31243;&#24230;&#12290;&#26412;&#25991;&#22312;&#31070;&#32463;&#32593;&#32476;&#30340;&#32972;&#26223;&#19979;&#25552;&#20379;&#20102;&#32622;&#20449;&#24230;&#26657;&#20934;&#38382;&#39064;&#30340;&#27010;&#36848;&#65292;&#24182;&#25552;&#20379;&#20102;&#26657;&#20934;&#26041;&#27861;&#30340;&#32463;&#39564;&#27604;&#36739;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#38382;&#39064;&#38472;&#36848;&#12289;&#26657;&#20934;&#23450;&#20041;&#20197;&#21450;&#23545;&#27169;&#22411;&#26159;&#21542;&#26657;&#20934;&#33391;&#22909;&#30340;&#21487;&#35270;&#21270;&#21644;&#26631;&#37327;&#24230;&#37327;&#30340;&#19981;&#21516;&#26041;&#27861;&#12290;&#25105;&#20204;&#23457;&#26597;&#20102;&#22522;&#20110;&#21518;&#22788;&#29702;&#25110;&#38656;&#35201;&#25913;&#21464;&#35757;&#32451;&#30340;&#29616;&#20195;&#26657;&#20934;&#25216;&#26415;&#12290;&#23454;&#35777;&#23454;&#39564;&#28085;&#30422;&#21508;&#31181;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#65292;&#26681;&#25454;&#19981;&#21516;&#30340;&#26631;&#20934;&#27604;&#36739;&#26657;&#20934;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural networks solving real-world problems are often required not only to make accurate predictions but also to provide a confidence level in the forecast. The calibration of a model indicates how close the estimated confidence is to the true probability. This paper presents a survey of confidence calibration problems in the context of neural networks and provides an empirical comparison of calibration methods. We analyze problem statement, calibration definitions, and different approaches to evaluation: visualizations and scalar measures that estimate whether the model is well-calibrated. We review modern calibration techniques: based on post-processing or requiring changes in training. Empirical experiments cover various datasets and models, comparing calibration methods according to different criteria.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35777;&#26126;&#20102;&#22312;&#24179;&#31283;&#38543;&#26426;&#20984;&#20248;&#21270;&#20013;&#65292;GD&#21644;SGD&#30340;&#27867;&#21270;&#19979;&#30028;&#21487;&#20197;&#38477;&#20302;&#65292;&#24182;&#19988;&#38271;&#26102;&#38388;&#30340;&#35757;&#32451;&#21487;&#33021;&#23548;&#33268;&#26356;&#24046;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#36825;&#19982;&#20854;&#20182;&#30740;&#31350;&#25104;&#26524;&#19981;&#21516;&#12290;</title><link>http://arxiv.org/abs/2303.10758</link><description>&lt;p&gt;
&#24179;&#31283;&#38543;&#26426;&#20984;&#20248;&#21270;&#20013;GD&#21644;SGD&#30340;&#27867;&#21270;&#19979;&#30028;&#38477;&#20302;
&lt;/p&gt;
&lt;p&gt;
Lower Generalization Bounds for GD and SGD in Smooth Stochastic Convex Optimization. (arXiv:2303.10758v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10758
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35777;&#26126;&#20102;&#22312;&#24179;&#31283;&#38543;&#26426;&#20984;&#20248;&#21270;&#20013;&#65292;GD&#21644;SGD&#30340;&#27867;&#21270;&#19979;&#30028;&#21487;&#20197;&#38477;&#20302;&#65292;&#24182;&#19988;&#38271;&#26102;&#38388;&#30340;&#35757;&#32451;&#21487;&#33021;&#23548;&#33268;&#26356;&#24046;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#36825;&#19982;&#20854;&#20182;&#30740;&#31350;&#25104;&#26524;&#19981;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#23398;&#20064;&#29702;&#35770;&#30028;&#22312;&#21051;&#30011;&#19968;&#33324;&#20984;&#25439;&#22833;&#26799;&#24230;&#26041;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;&#26041;&#38754;&#21462;&#24471;&#20102;&#36827;&#23637;&#12290;&#26412;&#25991;&#20391;&#37325;&#20110;&#35752;&#35770;&#22312;&#27867;&#21270;&#20809;&#28369;&#38543;&#26426;&#20984;&#20248;&#21270;&#65288;SCO&#65289;&#38382;&#39064;&#20013;&#35757;&#32451;&#26102;&#38388;&#22914;&#20309;&#24433;&#21709;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#39318;&#20808;&#20026;&#19968;&#33324;&#30340;&#19981;&#21487;&#23454;&#29616;SCO&#38382;&#39064;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#30340;&#19978;&#30028;&#32467;&#26524;&#34920;&#26126;&#65292;&#20551;&#35774;&#25439;&#22833;&#21487;&#23454;&#29616;&#65288;&#21363;&#26368;&#20248;&#35299;&#21516;&#26102;&#26368;&#23567;&#21270;&#25152;&#26377;&#25968;&#25454;&#28857;&#65289;&#21487;&#20197;&#25552;&#39640;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#20294;&#26159;&#65292;&#24403;&#35757;&#32451;&#26102;&#38388;&#38271;&#19988;&#32570;&#20047;&#19979;&#30028;&#26102;&#65292;&#36825;&#31181;&#25913;&#36827;&#20250;&#21463;&#21040;&#25439;&#23475;&#12290;&#25105;&#20204;&#23545;&#27492;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#25552;&#20379;&#20102;&#23545;&#20110;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#21644;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#22312;&#20004;&#31181;&#21487;&#23454;&#29616;&#24773;&#20917;&#19979;&#30340;&#36807;&#37327;&#39118;&#38505;&#19979;&#30028;&#65306;1&#65289;&#23454;&#29616;&#38656;$T = O(n)$&#65292;&#21644;&#65288;2&#65289;&#23454;&#29616;&#38656;$T = \Omega(n)$&#65292;&#20854;&#20013;$T$&#34920;&#31034;&#35757;&#32451;&#36845;&#20195;&#27425;&#25968;&#65292;$n$&#20026;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#12290;&#36825;&#20123;&#19979;&#30028;&#30340;&#35777;&#26126;&#20351;&#29992;&#20102;&#26469;&#33258;&#20248;&#21270;&#30340;&#29616;&#20195;&#24037;&#20855;&#65292;&#21253;&#25324;&#23545;&#20598;&#29702;&#35770;&#21644;&#38236;&#20687;&#19979;&#38477;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#21487;&#23454;&#29616;&#30340;SCO&#20013;&#65292;&#26356;&#38271;&#30340;&#35757;&#32451;&#26102;&#38388;&#21487;&#33021;&#20250;&#23548;&#33268;&#26356;&#24046;&#30340;&#27867;&#21270;&#65292;&#36825;&#19982;&#25991;&#29486;&#20013;&#30340;&#20808;&#21069;&#21457;&#29616;&#24418;&#25104;&#40092;&#26126;&#23545;&#27604;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#25903;&#25345;&#25105;&#20204;&#32467;&#26524;&#30340;&#25968;&#20540;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent progress was made in characterizing the generalization error of gradient methods for general convex loss by the learning theory community. In this work, we focus on how training longer might affect generalization in smooth stochastic convex optimization (SCO) problems. We first provide tight lower bounds for general non-realizable SCO problems. Furthermore, existing upper bound results suggest that sample complexity can be improved by assuming the loss is realizable, i.e. an optimal solution simultaneously minimizes all the data points. However, this improvement is compromised when training time is long and lower bounds are lacking. Our paper examines this observation by providing excess risk lower bounds for gradient descent (GD) and stochastic gradient descent (SGD) in two realizable settings: 1) realizable with $T = O(n)$, and (2) realizable with $T = \Omega(n)$, where $T$ denotes the number of training iterations and $n$ is the size of the training dataset. These bounds are 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#20998;&#21106;&#27169;&#22411;&#65292;&#21487;&#20197;&#22788;&#29702;&#24322;&#36136;&#24615;&#21151;&#33021;&#25968;&#25454;&#65292;&#36890;&#36807;&#21160;&#24577;&#35268;&#21010;&#30340;EM&#31639;&#27861;&#36817;&#20284;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#65292;&#26041;&#27861;&#22312;&#27169;&#25311;&#19982;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2303.10712</link><description>&lt;p&gt;
&#24322;&#36136;&#24615;&#21151;&#33021;&#25968;&#25454;&#30340;&#28151;&#21512;&#20998;&#21106;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Mixture of segmentation for heterogeneous functional data. (arXiv:2303.10712v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10712
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#20998;&#21106;&#27169;&#22411;&#65292;&#21487;&#20197;&#22788;&#29702;&#24322;&#36136;&#24615;&#21151;&#33021;&#25968;&#25454;&#65292;&#36890;&#36807;&#21160;&#24577;&#35268;&#21010;&#30340;EM&#31639;&#27861;&#36817;&#20284;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#65292;&#26041;&#27861;&#22312;&#27169;&#25311;&#19982;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#26102;&#38388;&#21644;&#20154;&#21475;&#24322;&#36136;&#24615;&#30340;&#21151;&#33021;&#25968;&#25454;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#20998;&#21106;&#27169;&#22411;&#65292;&#26088;&#22312;&#20445;&#25345;&#21151;&#33021;&#32467;&#26500;&#30340;&#21516;&#26102;&#34920;&#31034;&#24322;&#36136;&#24615;&#12290; &#35752;&#35770;&#20102;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#30340;&#21487;&#36776;&#35782;&#24615;&#21644;&#19968;&#33268;&#24615;&#65292;&#24182;&#37319;&#29992;&#21160;&#24577;&#35268;&#21010;&#30340;EM&#31639;&#27861;&#26469;&#36817;&#20284;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#12290; &#35813;&#26041;&#27861;&#22312;&#27169;&#25311;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#35828;&#26126;&#65292;&#24182;&#22312;&#29992;&#30005;&#37327;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#20102;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we consider functional data with heterogeneity in time and in population. We propose a mixture model with segmentation of time to represent this heterogeneity while keeping the functional structure. Maximum likelihood estimator is considered, proved to be identifiable and consistent. In practice, an EM algorithm is used, combined with dynamic programming for the maximization step, to approximate the maximum likelihood estimator. The method is illustrated on a simulated dataset, and used on a real dataset of electricity consumption.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;Neighborhood Conformal Prediction(NCP)&#65292;&#21487;&#20197;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#21040;&#30340;&#34920;&#31034;&#25552;&#39640;&#28145;&#24230;&#20998;&#31867;&#22120;&#30340;&#30830;&#23450;&#24615;&#37327;&#21270;&#25928;&#29575;&#65307;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;NCP&#21487;&#20197;&#20135;&#29983;&#26356;&#23567;&#30340;&#39044;&#27979;&#38598;&#12290;</title><link>http://arxiv.org/abs/2303.10694</link><description>&lt;p&gt;
&#36890;&#36807;&#39046;&#22495;&#19968;&#33268;&#24615;&#39044;&#27979;&#25913;&#36827;&#28145;&#24230;&#20998;&#31867;&#22120;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65306;&#26032;&#30340;&#31639;&#27861;&#21644;&#29702;&#35770;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Improving Uncertainty Quantification of Deep Classifiers via Neighborhood Conformal Prediction: Novel Algorithm and Theoretical Analysis. (arXiv:2303.10694v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10694
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;Neighborhood Conformal Prediction(NCP)&#65292;&#21487;&#20197;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#21040;&#30340;&#34920;&#31034;&#25552;&#39640;&#28145;&#24230;&#20998;&#31867;&#22120;&#30340;&#30830;&#23450;&#24615;&#37327;&#21270;&#25928;&#29575;&#65307;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;NCP&#21487;&#20197;&#20135;&#29983;&#26356;&#23567;&#30340;&#39044;&#27979;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#39118;&#38505;&#23454;&#38469;&#24212;&#29992;&#20013;&#23433;&#20840;&#37096;&#32626;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#38656;&#35201;&#26377;&#29702;&#35770;&#22522;&#30784;&#30340;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#23545;&#20110;&#20998;&#31867;&#20219;&#21153;&#65292;&#31526;&#21512;&#24615;&#39044;&#27979;&#65288;CP&#65289;&#26159;&#19968;&#31181;&#21487;&#20197;&#20197;&#29992;&#25143;&#25351;&#23450;&#30340;&#35206;&#30422;&#29575;&#65288;&#21363;&#30495;&#23454;&#31867;&#26631;&#31614;&#21253;&#21547;&#22312;&#39640;&#27010;&#29575;&#20869;&#65289;&#26469;&#30830;&#23450;&#28145;&#24230;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#30340;&#21407;&#21017;&#24615;&#26694;&#26550;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#8212;&#8212;&#39046;&#22495;&#19968;&#33268;&#24615;&#39044;&#27979;&#65288;NCP&#65289;&#65292;&#20197;&#25913;&#36827;&#30001;CP&#36827;&#34892;&#30340;&#28145;&#24230;&#20998;&#31867;&#22120;&#30340;&#30830;&#23450;&#24615;&#37327;&#21270;&#25928;&#29575;&#65288;&#21363;&#20943;&#23569;&#39044;&#27979;&#38598;&#22823;&#23567;&#65289;&#12290;NCP&#30340;&#20851;&#38190;&#24605;&#24819;&#26159;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#21040;&#30340;&#34920;&#31034;&#26469;&#35782;&#21035;&#32473;&#23450;&#27979;&#35797;&#36755;&#20837;&#30340;k&#20010;&#26368;&#36817;&#37051;&#26657;&#20934;&#31034;&#20363;&#65292;&#24182;&#20998;&#37197;&#19982;&#20854;&#36317;&#31163;&#25104;&#27604;&#20363;&#30340;&#37325;&#35201;&#24615;&#26435;&#37325;&#20197;&#21019;&#24314;&#33258;&#36866;&#24212;&#39044;&#27979;&#38598;&#12290;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#65292;&#22914;&#26524;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#21040;&#30340;&#25968;&#25454;&#34920;&#31034;&#28385;&#36275;&#19968;&#20123;&#28201;&#21644;&#30340;&#26465;&#20214;&#65292;NCP&#23558;&#20135;&#29983;&#26356;&#23567;&#30340;&#39044;&#27979;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Safe deployment of deep neural networks in high-stake real-world applications requires theoretically sound uncertainty quantification. Conformal prediction (CP) is a principled framework for uncertainty quantification of deep models in the form of prediction set for classification tasks with a user-specified coverage (i.e., true class label is contained with high probability). This paper proposes a novel algorithm referred to as Neighborhood Conformal Prediction (NCP) to improve the efficiency of uncertainty quantification from CP for deep classifiers (i.e., reduce prediction set size). The key idea behind NCP is to use the learned representation of the neural network to identify k nearest-neighbors calibration examples for a given testing input and assign them importance weights proportional to their distance to create adaptive prediction sets. We theoretically show that if the learned data representation of the neural network satisfies some mild conditions, NCP will produce smaller p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#21464;&#20998;&#33945;&#29305;&#21345;&#32599;&#65288;VMC&#65289;&#26041;&#27861;&#25910;&#25947;&#24615;&#30340;&#21487;&#39564;&#35777;&#26041;&#27861;&#65292;&#22312;&#20551;&#35774;&#23616;&#37096;&#33021;&#37327;&#26159;&#27425;&#25351;&#25968;&#30340;&#26465;&#20214;&#19979;&#65292;&#20351;&#29992;&#38750;&#24179;&#31283;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;Bernstein&#19981;&#31561;&#24335;&#25512;&#23548;&#20986;&#20102;MCMC&#20272;&#35745;&#37327;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#35777;&#26126;&#20102;VMC&#20855;&#26377;&#19968;&#38454;&#25910;&#25947;&#36895;&#29575;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#25910;&#25947;&#36895;&#29575;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2303.10599</link><description>&lt;p&gt;
&#21487;&#39564;&#35777;&#21464;&#20998;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Provable Convergence of Variational Monte Carlo Methods. (arXiv:2303.10599v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10599
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#21464;&#20998;&#33945;&#29305;&#21345;&#32599;&#65288;VMC&#65289;&#26041;&#27861;&#25910;&#25947;&#24615;&#30340;&#21487;&#39564;&#35777;&#26041;&#27861;&#65292;&#22312;&#20551;&#35774;&#23616;&#37096;&#33021;&#37327;&#26159;&#27425;&#25351;&#25968;&#30340;&#26465;&#20214;&#19979;&#65292;&#20351;&#29992;&#38750;&#24179;&#31283;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;Bernstein&#19981;&#31561;&#24335;&#25512;&#23548;&#20986;&#20102;MCMC&#20272;&#35745;&#37327;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#35777;&#26126;&#20102;VMC&#20855;&#26377;&#19968;&#38454;&#25910;&#25947;&#36895;&#29575;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#25910;&#25947;&#36895;&#29575;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#33945;&#29305;&#21345;&#32599;&#65288;VMC&#65289;&#26159;&#19968;&#31181;&#29992;&#20110;&#35745;&#31639;&#37327;&#23376;&#22810;&#20307;&#38382;&#39064;&#22522;&#24577;&#33021;&#37327;&#30340;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#65292;&#24182;&#30001;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#21457;&#23637;&#32780;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#12290;&#26368;&#36817;&#30340;VMC&#26041;&#27861;&#20197;&#31070;&#32463;&#32593;&#32476;&#26500;&#24314;&#35797;&#25506;&#27874;&#20989;&#25968;&#65292;&#20351;&#29992;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#65288;MCMC&#65289;&#37319;&#26679;&#37327;&#23376;&#24577;&#65292;&#24182;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#26041;&#27861;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#12290;&#28982;&#32780;&#65292;&#24403;SGD&#19982;MCMC&#37319;&#26679;&#19982;&#35774;&#35745;&#33391;&#22909;&#30340;&#35797;&#25506;&#27874;&#20989;&#25968;&#20132;&#20114;&#20316;&#29992;&#26102;&#65292;VMC&#30340;&#29702;&#35770;&#25910;&#25947;&#24615;&#20173;&#28982;&#26410;&#30693;&#12290;&#30001;&#20110;MCMC&#38477;&#20302;&#20102;&#26799;&#24230;&#20272;&#35745;&#30340;&#38590;&#24230;&#65292;&#23454;&#38469;&#19978;&#19981;&#21487;&#36991;&#20813;&#22320;&#23384;&#22312;&#20559;&#24046;&#12290;&#27492;&#22806;&#65292;&#23616;&#37096;&#33021;&#37327;&#21487;&#33021;&#26159;&#26080;&#30028;&#30340;&#65292;&#36825;&#20351;&#24471;&#20998;&#26512;MCMC&#37319;&#26679;&#30340;&#35823;&#24046;&#26356;&#21152;&#22256;&#38590;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#20551;&#35774;&#23616;&#37096;&#33021;&#37327;&#26159;&#27425;&#25351;&#25968;&#30340;&#65292;&#24182;&#20351;&#29992;&#38750;&#24179;&#31283;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;Bernstein&#19981;&#31561;&#24335;&#25512;&#23548;&#20986;MCMC&#20272;&#35745;&#37327;&#30340;&#35823;&#24046;&#30028;&#38480;&#12290;&#22240;&#27492;&#65292;&#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#65292;VMC&#34987;&#35777;&#26126;&#20855;&#26377;&#19968;&#38454;&#25910;&#25947;&#36895;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#25910;&#25947;&#36895;&#29575;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Variational Monte Carlo (VMC) is a promising approach for computing the ground state energy of many-body quantum problems and attracts more and more interests due to the development of machine learning. The recent paradigms in VMC construct neural networks as trial wave functions, sample quantum configurations using Markov chain Monte Carlo (MCMC) and train neural networks with stochastic gradient descent (SGD) method. However, the theoretical convergence of VMC is still unknown when SGD interacts with MCMC sampling given a well-designed trial wave function. Since MCMC reduces the difficulty of estimating gradients, it has inevitable bias in practice. Moreover, the local energy may be unbounded, which makes it harder to analyze the error of MCMC sampling. Therefore, we assume that the local energy is sub-exponential and use the Bernstein inequality for non-stationary Markov chains to derive error bounds of the MCMC estimator. Consequently, VMC is proven to have a first order conver
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#34920;&#26126;&#40657;&#30418;&#21464;&#20998;&#25512;&#29702;&#65288;BBVI&#65289;&#28385;&#36275;SGD&#25991;&#29486;&#20013;&#30340;ABC&#26465;&#20214;&#65292;&#35813;&#32467;&#26524;&#36866;&#29992;&#20110;&#24179;&#28369;&#21644;&#20108;&#27425;&#22686;&#38271;&#30340;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#65292;&#21516;&#26102;&#25105;&#20204;&#30340;&#32467;&#26524;&#25512;&#24191;&#21040;&#24191;&#27867;&#24212;&#29992;&#20110;BBVI&#23454;&#36341;&#20013;&#30340;&#38750;&#32447;&#24615;&#21327;&#26041;&#24046;&#21442;&#25968;&#21270;&#12290;</title><link>http://arxiv.org/abs/2303.10472</link><description>&lt;p&gt;
&#40657;&#30418;&#21464;&#20998;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#23454;&#29992;&#21305;&#37197;&#26799;&#24230;&#26041;&#24046;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Practical and Matching Gradient Variance Bounds for Black-Box Variational Bayesian Inference. (arXiv:2303.10472v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10472
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#34920;&#26126;&#40657;&#30418;&#21464;&#20998;&#25512;&#29702;&#65288;BBVI&#65289;&#28385;&#36275;SGD&#25991;&#29486;&#20013;&#30340;ABC&#26465;&#20214;&#65292;&#35813;&#32467;&#26524;&#36866;&#29992;&#20110;&#24179;&#28369;&#21644;&#20108;&#27425;&#22686;&#38271;&#30340;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#65292;&#21516;&#26102;&#25105;&#20204;&#30340;&#32467;&#26524;&#25512;&#24191;&#21040;&#24191;&#27867;&#24212;&#29992;&#20110;BBVI&#23454;&#36341;&#20013;&#30340;&#38750;&#32447;&#24615;&#21327;&#26041;&#24046;&#21442;&#25968;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#40657;&#30418;&#21464;&#20998;&#25512;&#29702;&#65288;BBVI&#65289;&#30340;&#26799;&#24230;&#26041;&#24046;&#26159;&#24314;&#31435;&#20854;&#25910;&#25947;&#24615;&#21644;&#31639;&#27861;&#25913;&#36827;&#30340;&#20851;&#38190;&#19968;&#27493;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30740;&#31350;&#23578;&#26410;&#34920;&#26126;BBVI&#30340;&#26799;&#24230;&#26041;&#24046;&#28385;&#36275;&#29992;&#20110;&#30740;&#31350;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#25910;&#25947;&#30340;&#26465;&#20214;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#24212;&#29992;&#20110;&#24179;&#28369;&#21644;&#20108;&#27425;&#22686;&#38271;&#30340;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#26102;&#65292;BBVI&#28385;&#36275;&#19982;SGD&#25991;&#29486;&#20013;&#20351;&#29992;&#30340;ABC&#26465;&#20214;&#30456;&#21305;&#37197;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25512;&#24191;&#21040;&#24191;&#27867;&#24212;&#29992;&#20110;BBVI&#23454;&#36341;&#20013;&#30340;&#38750;&#32447;&#24615;&#21327;&#26041;&#24046;&#21442;&#25968;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#24179;&#22343;&#22330;&#21442;&#25968;&#21270;&#30340;&#26041;&#24046;&#20855;&#26377;&#32463;&#36807;&#39564;&#35777;&#30340;&#20248;&#36234;&#32500;&#24230;&#20381;&#36182;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding the gradient variance of black-box variational inference (BBVI) is a crucial step for establishing its convergence and developing algorithmic improvements. However, existing studies have yet to show that the gradient variance of BBVI satisfies the conditions used to study the convergence of stochastic gradient descent (SGD), the workhorse of BBVI. In this work, we show that BBVI satisfies a matching bound corresponding to the $ABC$ condition used in the SGD literature when applied to smooth and quadratically-growing log-likelihoods. Our results generalize to nonlinear covariance parameterizations widely used in the practice of BBVI. Furthermore, we show that the variance of the mean-field parameterization has provably superior dimensional dependence.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#36870;&#22810;&#38754;&#31215;&#31215;&#20998;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;I-CKF&#65289;&#21644;&#36870;&#22810;&#39033;&#24335;&#31215;&#20998;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;I-QKF&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#31995;&#32479;&#27169;&#22411;&#30340;&#36870;&#35748;&#30693;&#38382;&#39064;&#65292;&#24182;&#22312;&#25351;&#25968;-&#24179;&#22343;-&#20108;&#27425;&#26377;&#30028;&#24615;&#24847;&#20041;&#19979;&#25512;&#23548;&#20102;&#20854;&#30340;&#38543;&#26426;&#31283;&#23450;&#24615;&#26465;&#20214;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#39640;&#30340;&#20272;&#35745;&#31934;&#24230;&#21644;&#36882;&#24402;Cram\'{e}r-Rao&#19979;&#30028;&#30456;&#24403;&#12290;</title><link>http://arxiv.org/abs/2303.10322</link><description>&lt;p&gt;
&#36870;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#21644;&#36870;&#22810;&#38754;&#31215;&#31215;&#20998;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;
&lt;/p&gt;
&lt;p&gt;
Inverse Cubature and Quadrature Kalman filters. (arXiv:2303.10322v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10322
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#36870;&#22810;&#38754;&#31215;&#31215;&#20998;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;I-CKF&#65289;&#21644;&#36870;&#22810;&#39033;&#24335;&#31215;&#20998;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;I-QKF&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#31995;&#32479;&#27169;&#22411;&#30340;&#36870;&#35748;&#30693;&#38382;&#39064;&#65292;&#24182;&#22312;&#25351;&#25968;-&#24179;&#22343;-&#20108;&#27425;&#26377;&#30028;&#24615;&#24847;&#20041;&#19979;&#25512;&#23548;&#20102;&#20854;&#30340;&#38543;&#26426;&#31283;&#23450;&#24615;&#26465;&#20214;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#39640;&#30340;&#20272;&#35745;&#31934;&#24230;&#21644;&#36882;&#24402;Cram\'{e}r-Rao&#19979;&#30028;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#23545;&#25239;&#31995;&#32479;&#30740;&#31350;&#30340;&#26368;&#26032;&#36827;&#23637;&#24050;&#32463;&#23548;&#33268;&#24320;&#21457;&#20102;&#36870;&#38543;&#26426;&#28388;&#27874;&#22120;&#65292;&#36825;&#20123;&#28388;&#27874;&#22120;&#34987;&#38450;&#24481;&#32773;&#29992;&#26469;&#25512;&#26029;&#20854;&#23545;&#25163;&#21487;&#33021;&#23398;&#21040;&#30340;&#20449;&#24687;&#12290;&#26089;&#26399;&#30340;&#20316;&#21697;&#36890;&#36807;&#38024;&#23545;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#39640;&#26031;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#20998;&#21035;&#25552;&#20986;&#20102;&#36870;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;I-KF&#65289;&#21644;&#36870;&#25193;&#23637;KF&#65288;I-EKF&#65289;&#26469;&#35299;&#20915;&#36825;&#20010;&#36870;&#35748;&#30693;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#24456;&#22810;&#21453;&#23545;&#25239;&#24615;&#35774;&#32622;&#20250;&#28041;&#21450;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#31995;&#32479;&#27169;&#22411;&#65292;&#20854;&#20013;EKF&#30340;&#32447;&#24615;&#21270;&#24120;&#24120;&#20250;&#22833;&#36133;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#26377;&#25928;&#30340;&#25968;&#20540;&#31215;&#20998;&#25216;&#26415;&#26469;&#35299;&#20915;&#36825;&#31181;&#38750;&#32447;&#24615;&#38382;&#39064;&#65292;&#24182;&#22240;&#27492;&#24320;&#21457;&#20102;&#36870;&#22810;&#38754;&#31215;&#31215;&#20998;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;I-CKF&#65289;&#21644;&#36870;&#22810;&#39033;&#24335;&#31215;&#20998;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;I-QKF&#65289;&#12290;&#25105;&#20204;&#22312;&#25351;&#25968;-&#24179;&#22343;-&#20108;&#27425;&#26377;&#30028;&#24615;&#24847;&#20041;&#19979;&#25512;&#23548;&#20102;&#25152;&#25552;&#20986;&#30340;&#28388;&#27874;&#22120;&#30340;&#38543;&#26426;&#31283;&#23450;&#24615;&#26465;&#20214;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;I-CKF&#21644;I-QKF&#30340;&#20272;&#35745;&#31934;&#24230;&#65292;&#36319;&#36882;&#24402;Cram\'{e}r-Rao&#19979;&#30028;&#20316;&#20026;&#22522;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent developments in counter-adversarial system research have led to the development of inverse stochastic filters that are employed by a defender to infer the information its adversary may have learned. Prior works addressed this inverse cognition problem by proposing inverse Kalman filter (I-KF) and inverse extended KF (I-EKF), respectively, for linear and non-linear Gaussian state-space models. However, in practice, many counter-adversarial settings involve highly non-linear system models, wherein EKF's linearization often fails. In this paper, we consider the efficient numerical integration techniques to address such nonlinearities and, to this end, develop inverse cubature KF (I-CKF) and inverse quadrature KF (I-QKF). We derive the stochastic stability conditions for the proposed filters in the exponential-mean-squared-boundedness sense. Numerical experiments demonstrate the estimation accuracy of our I-CKF and I-QKF with the recursive Cram\'{e}r-Rao lower bound as a benchmark.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#23398;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;&#29992;&#25688;&#35201;&#32479;&#35745;&#25968;&#25454;&#23545;&#39640;&#32500;&#34920;&#22411;&#36827;&#34892;GWAS&#65292;&#35813;&#26041;&#27861;&#26126;&#30830;&#24314;&#27169;&#22810;&#25928;&#24615;&#65292;&#20855;&#26377;&#24555;&#36895;&#35745;&#31639;&#33021;&#21147;&#24182;&#21487;&#20197;&#20351;&#29992;&#29983;&#29289;&#23398;&#20808;&#39564;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2303.10221</link><description>&lt;p&gt;
&#19968;&#31181;&#21033;&#29992;&#32479;&#35745;&#26694;&#26550;&#36827;&#34892;&#39640;&#32500;&#34920;&#22411;GWAS&#30340;&#25688;&#35201;&#32479;&#35745;&#23398;&#26041;&#27861;&#65292;&#20197;&#20195;&#35874;&#29289;GWAS&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
A statistical framework for GWAS of high dimensional phenotypes using summary statistics, with application to metabolite GWAS. (arXiv:2303.10221v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10221
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#23398;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;&#29992;&#25688;&#35201;&#32479;&#35745;&#25968;&#25454;&#23545;&#39640;&#32500;&#34920;&#22411;&#36827;&#34892;GWAS&#65292;&#35813;&#26041;&#27861;&#26126;&#30830;&#24314;&#27169;&#22810;&#25928;&#24615;&#65292;&#20855;&#26377;&#24555;&#36895;&#35745;&#31639;&#33021;&#21147;&#24182;&#21487;&#20197;&#20351;&#29992;&#29983;&#29289;&#23398;&#20808;&#39564;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#36951;&#20256;&#21644;&#39640;&#32500;&#29983;&#29289;&#38134;&#34892;&#21644;&#8220;&#32452;&#23398;&#8221;&#25968;&#25454;&#30340;&#29190;&#28856;&#24335;&#22686;&#38271;&#20026;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#20102;&#30740;&#31350;&#25968;&#30334;&#21040;&#25968;&#21315;&#20010;&#30456;&#20851;&#34920;&#22411;&#30340;&#20849;&#21516;&#36951;&#20256;&#36215;&#28304;&#65288;&#22810;&#25928;&#24615;&#65289;&#30340;&#26426;&#20250;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22810;&#34920;&#22411;&#20840;&#22522;&#22240;&#32452;&#20851;&#32852;&#30740;&#31350;&#65288;GWAS&#65289;&#26041;&#27861;&#24182;&#26410;&#24314;&#27169;&#22810;&#25928;&#24615;&#65292;&#21482;&#36866;&#29992;&#20110;&#23569;&#37327;&#34920;&#22411;&#65292;&#25110;&#26080;&#27861;&#36827;&#34892;&#25512;&#26029;&#12290;&#27492;&#22806;&#65292;&#24456;&#23569;&#35266;&#27979;&#21040;&#21407;&#22987;&#36951;&#20256;&#21644;&#34920;&#22411;&#25968;&#25454;&#65292;&#36825;&#24847;&#21619;&#30528;&#24517;&#39035;&#22312;&#39640;&#32500;&#24230;&#30340;GWAS&#25688;&#35201;&#32479;&#35745;&#20449;&#24687;&#19978;&#36827;&#34892;&#20998;&#26512;&#65292;&#32780;&#36825;&#20123;&#25688;&#35201;&#32479;&#35745;&#20449;&#24687;&#22312;&#39640;&#32500;&#24230;&#19979;&#30340;&#32479;&#35745;&#29305;&#24615;&#36824;&#19981;&#22815;&#29702;&#35299;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;&#12289;&#29702;&#35770;&#26694;&#26550;&#21644;&#19968;&#22871;&#26041;&#27861;&#65292;&#29992;&#20110;&#20351;&#29992;&#25688;&#35201;&#32479;&#35745;&#23398;&#25968;&#25454;&#36827;&#34892;&#39640;&#32500;&#34920;&#22411;GWAS&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#26126;&#30830;&#22320;&#24314;&#27169;&#22810;&#25928;&#24615;&#65292;&#20419;&#36827;&#24555;&#36895;&#35745;&#31639;&#65292;&#24182;&#26377;&#21161;&#20110;&#20351;&#29992;&#29983;&#29289;&#20449;&#24687;&#20808;&#39564;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#20854;&#24212;&#29992;&#20110;&#20195;&#35874;&#29289;GWAS&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31243;&#24207;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recent explosion of genetic and high dimensional biobank and 'omic' data has provided researchers with the opportunity to investigate the shared genetic origin (pleiotropy) of hundreds to thousands of related phenotypes. However, existing methods for multi-phenotype genome-wide association studies (GWAS) do not model pleiotropy, are only applicable to a small number of phenotypes, or provide no way to perform inference. To add further complication, raw genetic and phenotype data are rarely observed, meaning analyses must be performed on GWAS summary statistics whose statistical properties in high dimensions are poorly understood. We therefore developed a novel model, theoretical framework, and set of methods to perform Bayesian inference in GWAS of high dimensional phenotypes using summary statistics that explicitly model pleiotropy, beget fast computation, and facilitate the use of biologically informed priors. We demonstrate the utility of our procedure by applying it to metaboli
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22270;&#34920;&#33258;&#32534;&#30721;&#22120;&#29992;&#20110;&#28145;&#24230;&#38750;&#21442;&#25968;&#20272;&#35745;&#20869;&#37096;&#25968;&#25454;&#32467;&#26500;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#24191;&#20041;&#35823;&#24046;&#20445;&#35777;&#21644;&#21435;&#22122;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2303.09863</link><description>&lt;p&gt;
&#36890;&#36807;&#22270;&#34920;&#33258;&#32534;&#30721;&#22120;&#36827;&#34892;&#20869;&#37096;&#25968;&#25454;&#32467;&#26500;&#30340;&#28145;&#24230;&#38750;&#21442;&#25968;&#20272;&#35745;&#65306;&#24191;&#20041;&#35823;&#24046;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Nonparametric Estimation of Intrinsic Data Structures by Chart Autoencoders: Generalization Error and Robustness. (arXiv:2303.09863v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09863
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22270;&#34920;&#33258;&#32534;&#30721;&#22120;&#29992;&#20110;&#28145;&#24230;&#38750;&#21442;&#25968;&#20272;&#35745;&#20869;&#37096;&#25968;&#25454;&#32467;&#26500;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#24191;&#20041;&#35823;&#24046;&#20445;&#35777;&#21644;&#21435;&#22122;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#32534;&#30721;&#22120;&#22312;&#23398;&#20064;&#39640;&#32500;&#25968;&#25454;&#30340;&#20302;&#32500;&#28508;&#22312;&#29305;&#24449;&#26041;&#38754;&#24050;&#32463;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#23637;&#29616;&#20986;&#20102;&#26174;&#30528;&#30340;&#25104;&#21151;&#12290;&#20551;&#35774;&#25968;&#25454;&#22312;&#20302;&#32500;&#27969;&#24418;&#38468;&#36817;&#37319;&#26679;&#65292;&#25105;&#20204;&#37319;&#29992;&#22270;&#34920;&#33258;&#32534;&#30721;&#22120;&#65292;&#23558;&#25968;&#25454;&#32534;&#30721;&#20026;&#19968;&#32452;&#22270;&#34920;&#19978;&#30340;&#20302;&#32500;&#28508;&#22312;&#29305;&#24449;&#65292;&#20174;&#32780;&#20445;&#30041;&#20102;&#25968;&#25454;&#27969;&#24418;&#30340;&#25299;&#25169;&#21644;&#20960;&#20309;&#12290;&#25105;&#20204;&#30340;&#35770;&#25991;&#20026;&#22270;&#34920;&#33258;&#32534;&#30721;&#22120;&#30340;&#24191;&#20041;&#35823;&#24046;&#24314;&#31435;&#20102;&#32479;&#35745;&#20445;&#35777;&#65292;&#24182;&#19988;&#36890;&#36807;&#32771;&#34385;$d$&#32500;&#27969;&#24418;&#19978;$n$&#20010;&#24102;&#22122;&#22768;&#35757;&#32451;&#26679;&#26412;&#21450;&#20854;&#26080;&#22122;&#22768;&#23545;&#24212;&#29289;&#26469;&#23637;&#31034;&#23427;&#20204;&#30340;&#21435;&#22122;&#33021;&#21147;&#12290;&#36890;&#36807;&#35757;&#32451;&#33258;&#32534;&#30721;&#22120;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22270;&#34920;&#33258;&#32534;&#30721;&#22120;&#33021;&#22815;&#26377;&#25928;&#22320;&#21435;&#22122;&#36755;&#20837;&#25968;&#25454;&#21644;&#27491;&#24577;&#20998;&#24067;&#22122;&#22768;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#36866;&#24403;&#30340;&#32593;&#32476;&#26550;&#26500;&#19979;&#65292;&#22270;&#34920;&#33258;&#32534;&#30721;&#22120;&#23454;&#29616;&#20102;&#19968;&#20010;&#22823;&#33268;&#20026;$\displaystyle n^{-\frac{2}{d+2}}\log^4 n$&#38454;&#30340;&#24179;&#26041;&#24191;&#20041;&#35823;&#24046;&#65292;&#35813;&#35823;&#24046;&#21462;&#20915;&#20110;&#27969;&#24418;&#30340;&#20869;&#22312;&#32500;&#24230;&#65292;&#24182;&#19988;&#20165;&#24369;&#20381;&#36182;&#20110;&#26679;&#26412;&#25968;&#37327;$n$&#12290;
&lt;/p&gt;
&lt;p&gt;
Autoencoders have demonstrated remarkable success in learning low-dimensional latent features of high-dimensional data across various applications. Assuming that data are sampled near a low-dimensional manifold, we employ chart autoencoders, which encode data into low-dimensional latent features on a collection of charts, preserving the topology and geometry of the data manifold. Our paper establishes statistical guarantees on the generalization error of chart autoencoders, and we demonstrate their denoising capabilities by considering $n$ noisy training samples, along with their noise-free counterparts, on a $d$-dimensional manifold. By training autoencoders, we show that chart autoencoders can effectively denoise the input data with normal noise. We prove that, under proper network architectures, chart autoencoders achieve a squared generalization error in the order of $\displaystyle n^{-\frac{2}{d+2}}\log^4 n$, which depends on the intrinsic dimension of the manifold and only weakly
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102; MSC-DBSCAN&#25193;&#23637;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#19977;&#20803;&#32858;&#31867;&#20013;&#20174;&#25968;&#25454;&#20013;&#25552;&#21462;&#19981;&#21516;&#23376;&#31354;&#38388;&#30340;&#19981;&#21516;&#20999;&#29255;&#32858;&#31867;&#65292;&#24182;&#21487;&#20197;&#33719;&#24471;&#19982; MSC &#31639;&#27861;&#22312;&#22788;&#29702;&#31209;&#19968;&#24352;&#37327;&#25968;&#25454;&#26102;&#30456;&#21516;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2303.07768</link><description>&lt;p&gt;
&#22810;&#32500;&#25968;&#32452;&#30340;&#22810;&#20999;&#29255;&#32858;&#31867;&#20013;&#30340;DBSCAN&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
DBSCAN of Multi-Slice Clustering for three-order Tensor. (arXiv:2303.07768v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.07768
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102; MSC-DBSCAN&#25193;&#23637;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#19977;&#20803;&#32858;&#31867;&#20013;&#20174;&#25968;&#25454;&#20013;&#25552;&#21462;&#19981;&#21516;&#23376;&#31354;&#38388;&#30340;&#19981;&#21516;&#20999;&#29255;&#32858;&#31867;&#65292;&#24182;&#21487;&#20197;&#33719;&#24471;&#19982; MSC &#31639;&#27861;&#22312;&#22788;&#29702;&#31209;&#19968;&#24352;&#37327;&#25968;&#25454;&#26102;&#30456;&#21516;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#19977;&#32500;&#25968;&#25454;&#30340;&#19977;&#20803;&#32858;&#31867;&#65292;&#29616;&#26377;&#30340;&#20960;&#31181;&#26041;&#27861;&#38656;&#35201;&#25351;&#23450;&#27599;&#20010;&#32500;&#24230;&#30340;&#32858;&#31867;&#22823;&#23567;&#25110;&#32858;&#31867;&#25968;&#37327;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#19977;&#20803;&#32858;&#31867;(MSC)&#31639;&#27861;&#21487;&#20197;&#22312;&#20302;&#32500;&#23376;&#31354;&#38388;&#20013;&#25214;&#21040;&#20445;&#30041;&#20449;&#21495;&#30340;&#20999;&#29255;&#20197;&#20415;&#22522;&#20110;&#30456;&#20284;&#24230;&#38408;&#20540;&#25214;&#21040;&#32858;&#31867;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102; MSC-DBSCAN&#25193;&#23637;&#31639;&#27861;&#20197;&#20174;&#25968;&#25454;&#20013;&#25552;&#21462;&#20301;&#20110;&#19981;&#21516;&#23376;&#31354;&#38388;&#30340;&#19981;&#21516;&#20999;&#29255;&#32858;&#31867;(&#22914;&#26524;&#25968;&#25454;&#38598;&#26159;r&#20010;&#31209;&#19968;&#24352;&#37327;(r&gt;1)&#30340;&#24635;&#21644;)&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20351;&#29992;&#21644; MSC &#31639;&#27861;&#30456;&#21516;&#30340;&#36755;&#20837;&#65292;&#21487;&#20197;&#22312;&#22788;&#29702;&#31209;&#19968;&#24352;&#37327;&#25968;&#25454;&#26102;&#19982; MSC &#31639;&#27861;&#33719;&#24471;&#30456;&#21516;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several methods for triclustering three-dimensional data require the cluster size or the number of clusters in each dimension to be specified. To address this issue, the Multi-Slice Clustering (MSC) for 3-order tensor finds signal slices that lie in a low dimensional subspace for a rank-one tensor dataset in order to find a cluster based on the threshold similarity. We propose an extension algorithm called MSC-DBSCAN to extract the different clusters of slices that lie in the different subspaces from the data if the dataset is a sum of r rank-one tensor (r &gt; 1). Our algorithm uses the same input as the MSC algorithm and can find the same solution for rank-one tensor data as MSC.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;SurvLIMEpy&#30340;Python&#21253;&#65292;&#23427;&#23454;&#29616;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#35745;&#31639;&#36866;&#29992;&#20110;&#24314;&#27169;&#29983;&#23384;&#20998;&#26512;&#25968;&#25454;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#23616;&#37096;&#29305;&#24449;&#37325;&#35201;&#24615;&#65292;&#24182;&#25903;&#25345;&#21508;&#31181;&#29983;&#23384;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2302.10571</link><description>&lt;p&gt;
SurvLIMEpy: &#19968;&#20010;&#23454;&#29616;&#20102;SurvLIME&#31639;&#27861;&#30340;Python&#21253;
&lt;/p&gt;
&lt;p&gt;
SurvLIMEpy: A Python package implementing SurvLIME. (arXiv:2302.10571v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10571
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;SurvLIMEpy&#30340;Python&#21253;&#65292;&#23427;&#23454;&#29616;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#35745;&#31639;&#36866;&#29992;&#20110;&#24314;&#27169;&#29983;&#23384;&#20998;&#26512;&#25968;&#25454;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#23616;&#37096;&#29305;&#24449;&#37325;&#35201;&#24615;&#65292;&#24182;&#25903;&#25345;&#21508;&#31181;&#29983;&#23384;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;SurvLIMEpy&#65292;&#36825;&#26159;&#19968;&#20010;&#24320;&#28304;&#30340;Python&#21253;&#65292;&#23454;&#29616;&#20102;SurvLIME&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#21487;&#20197;&#35745;&#31639;&#36866;&#29992;&#20110;&#24314;&#27169;&#29983;&#23384;&#20998;&#26512;&#25968;&#25454;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#23616;&#37096;&#29305;&#24449;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#30340;&#23454;&#29616;&#21033;&#29992;&#20102;&#24182;&#34892;&#21270;&#33539;&#20363;&#65292;&#22240;&#20026;&#25152;&#26377;&#35745;&#31639;&#37117;&#20197;&#30697;&#38453;&#26041;&#24335;&#25191;&#34892;&#65292;&#20174;&#32780;&#21152;&#24555;&#20102;&#25191;&#34892;&#26102;&#38388;&#12290;&#27492;&#22806;&#65292;SurvLIMEpy&#36824;&#25552;&#20379;&#20102;&#21487;&#35270;&#21270;&#24037;&#20855;&#26469;&#26356;&#22909;&#22320;&#29702;&#35299;&#31639;&#27861;&#30340;&#32467;&#26524;&#12290;&#35813;&#21253;&#25903;&#25345;&#21508;&#31181;&#29983;&#23384;&#27169;&#22411;&#65292;&#20174;Cox&#27604;&#20363;&#39118;&#38505;&#27169;&#22411;&#21040;DeepHit&#25110;DeepSurv&#31561;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#31867;&#22411;&#30340;&#23454;&#39564;&#12290;&#39318;&#20808;&#65292;&#36890;&#36807;&#27169;&#25311;&#25968;&#25454;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#31639;&#27861;&#25429;&#33719;&#29305;&#24449;&#37325;&#35201;&#24615;&#30340;&#33021;&#21147;&#12290;&#20854;&#27425;&#65292;&#22312;&#20351;&#29992;&#19977;&#20010;&#24320;&#28304;&#29983;&#23384;&#25968;&#25454;&#38598;&#20197;&#21450;&#19968;&#32452;&#29983;&#23384;&#31639;&#27861;&#26102;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;SurvLIMEpy&#22312;&#24212;&#29992;&#20110;&#19981;&#21516;&#25968;&#25454;&#38598;&#26102;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we present SurvLIMEpy, an open-source Python package that implements the SurvLIME algorithm. This method allows to compute local feature importance for machine learning algorithms designed for modelling Survival Analysis data. Our implementation takes advantage of the parallelisation paradigm as all computations are performed in a matrix-wise fashion which speeds up execution time. Additionally, SurvLIMEpy assists the user with visualization tools to better understand the result of the algorithm. The package supports a wide variety of survival models, from the Cox Proportional Hazards Model to deep learning models such as DeepHit or DeepSurv. Two types of experiments are presented in this paper. First, by means of simulated data, we study the ability of the algorithm to capture the importance of the features. Second, we use three open source survival datasets together with a set of survival algorithms in order to demonstrate how SurvLIMEpy behaves when applied to differen
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#28145;&#24230;&#23398;&#29983;&#26426;&#22120;&#30340;&#25945;&#24072;-&#23398;&#29983;&#35774;&#32622;&#65292;&#36890;&#36807;&#23398;&#29983;&#26426;&#22120;&#30340;&#38598;&#21512;&#26469;&#30740;&#31350;&#30001;&#20855;&#26377;&#22823;&#37327;&#21487;&#35843;&#21442;&#25968;&#30340;DNN&#30340;&#30417;&#30563;&#23398;&#20064;&#12290;&#30740;&#31350;&#34920;&#26126;DNN&#30340;&#23398;&#20064;&#22312;&#32593;&#32476;&#31354;&#38388;&#20013;&#30456;&#24403;&#24322;&#36136;&#12290;</title><link>http://arxiv.org/abs/2302.07419</link><description>&lt;p&gt;
&#36890;&#36807;&#28145;&#24230;&#23398;&#29983;&#26426;&#22120;&#23454;&#29616;&#31354;&#38388;&#24322;&#36136;&#24615;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Spatially heterogeneous learning by a deep student machine. (arXiv:2302.07419v3 [cond-mat.dis-nn] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07419
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#28145;&#24230;&#23398;&#29983;&#26426;&#22120;&#30340;&#25945;&#24072;-&#23398;&#29983;&#35774;&#32622;&#65292;&#36890;&#36807;&#23398;&#29983;&#26426;&#22120;&#30340;&#38598;&#21512;&#26469;&#30740;&#31350;&#30001;&#20855;&#26377;&#22823;&#37327;&#21487;&#35843;&#21442;&#25968;&#30340;DNN&#30340;&#30417;&#30563;&#23398;&#20064;&#12290;&#30740;&#31350;&#34920;&#26126;DNN&#30340;&#23398;&#20064;&#22312;&#32593;&#32476;&#31354;&#38388;&#20013;&#30456;&#24403;&#24322;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#21462;&#24471;&#20102;&#38750;&#20961;&#30340;&#25104;&#21151;&#65292;&#20294;&#30001;&#20110;&#20855;&#26377;&#22823;&#37327;&#21487;&#35843;&#21442;&#25968;&#65292;&#20854;&#20173;&#28982;&#26159;&#40657;&#21283;&#23376;&#12290;&#20026;&#20102;&#30740;&#31350;DNN&#30340;&#38544;&#34255;&#23618;&#65292;&#26412;&#25991;&#36890;&#36807;&#19968;&#31181;&#32479;&#35745;&#21147;&#23398;&#26041;&#27861;&#31216;&#20026;&#25945;&#24072;-&#23398;&#29983;&#35774;&#32622;&#65292;&#30740;&#31350;&#20102;&#30001;&#23485;&#24230;&#20026;N&#65292;&#28145;&#24230;&#20026;L&#65292;&#30001;&#20855;&#26377;c&#20010;&#36755;&#20837;&#30340;&#24863;&#30693;&#26426;&#32452;&#25104;&#30340;DNN&#30340;&#30417;&#30563;&#23398;&#20064;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#23398;&#29983;&#26426;&#22120;&#30340;&#38598;&#21512;&#65292;&#35813;&#38598;&#21512;&#21487;&#20197;&#31934;&#30830;&#37325;&#29616;&#30001;&#25945;&#24072;&#26426;&#22120;&#25552;&#20379;&#30340;M&#32452;N&#32500;&#36755;&#20837;/&#36755;&#20986;&#20851;&#31995;&#12290;&#25105;&#20204;&#20351;&#29992;&#21103;&#26412;&#26041;&#27861;&#65288;H. Yoshino&#65288;2020&#65289;&#65289;&#29702;&#35770;&#20998;&#26512;&#20102;&#38598;&#21512;&#65292;&#24182;&#36827;&#34892;&#20102;&#36138;&#23146;&#30340;Monte Carlo&#27169;&#25311;&#12290;&#23545;&#20110;&#39640;&#32500;&#25968;&#25454;$N \gg 1$&#65292;&#29702;&#35770;&#22312;'&#23494;&#38598;&#26497;&#38480;' $N \gg c \gg 1$ &#21644; $M \gg 1$ &#19988;&#22266;&#23450;$\alpha=M/c$&#26102;&#21464;&#24471;&#31934;&#30830;&#12290;&#29702;&#35770;&#21644;&#27169;&#25311;&#37117;&#34920;&#26126;&#65292;DNN&#30340;&#23398;&#20064;&#22312;&#32593;&#32476;&#31354;&#38388;&#20013;&#30456;&#24403;&#24322;&#36136;&#65306;&#26426;&#22120;&#30340;&#37197;&#32622;&#22312;&#38752;&#36817;&#36755;&#20837;/&#36755;&#20986;&#30340;&#23618;&#20869;&#26356;&#21152;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the spectacular successes, deep neural networks (DNN) with a huge number of adjustable parameters remain largely black boxes. To shed light on the hidden layers of DNN, we study supervised learning by a DNN of width $N$ and depth $L$ consisting of perceptrons with $c$ inputs by a statistical mechanics approach called the teacher-student setting. We consider an ensemble of student machines that exactly reproduce $M$ sets of $N$ dimensional input/output relations provided by a teacher machine. We analyze the ensemble theoretically using a replica method (H. Yoshino (2020)) and numerically performing greedy Monte Carlo simulations. The replica theory which works on high dimensional data $N \gg 1$ becomes exact in 'dense limit' $N \gg c \gg 1$ and $M \gg 1$ with fixed $\alpha=M/c$. Both the theory and the simulation suggest learning by the DNN is quite heterogeneous in the network space: configurations of the machines are more correlated within the layers closer to the input/output
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#31532;&#19968;&#20221;&#23545;&#20110;&#27973;&#23618;ViT&#36827;&#34892;&#35757;&#32451;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#20351;&#29992;SGD&#35757;&#32451;&#20250;&#20135;&#29983;&#31232;&#30095;&#30340;&#27880;&#24847;&#21147;&#22270;&#65292;&#30446;&#21069;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#26631;&#35760;&#30456;&#20851;&#20196;&#29260;&#30340;&#20998;&#25968;&#20498;&#25968;&#12289;&#26631;&#35760;&#32423;&#21035;&#30340;&#20196;&#29260;&#22122;&#22768;&#27700;&#24179;&#21644;&#21021;&#22987;&#27169;&#22411;&#38169;&#35823;&#21576;&#27491;&#30456;&#20851;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2302.06015</link><description>&lt;p&gt;
&#27973;&#23618;&#35270;&#35273;Transformer&#30340;&#29702;&#35770;&#29702;&#35299;&#65306;&#23398;&#20064;&#12289;&#27867;&#21270;&#21644;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Theoretical Understanding of Shallow Vision Transformers: Learning, Generalization, and Sample Complexity. (arXiv:2302.06015v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06015
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#31532;&#19968;&#20221;&#23545;&#20110;&#27973;&#23618;ViT&#36827;&#34892;&#35757;&#32451;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#20351;&#29992;SGD&#35757;&#32451;&#20250;&#20135;&#29983;&#31232;&#30095;&#30340;&#27880;&#24847;&#21147;&#22270;&#65292;&#30446;&#21069;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#26631;&#35760;&#30456;&#20851;&#20196;&#29260;&#30340;&#20998;&#25968;&#20498;&#25968;&#12289;&#26631;&#35760;&#32423;&#21035;&#30340;&#20196;&#29260;&#22122;&#22768;&#27700;&#24179;&#21644;&#21021;&#22987;&#27169;&#22411;&#38169;&#35823;&#21576;&#27491;&#30456;&#20851;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20855;&#26377;&#33258;&#25105;&#27880;&#24847;&#26426;&#21046;&#30340;&#35270;&#35273;Transformer&#65288;ViTs&#65289;&#22312;&#35768;&#22810;&#35270;&#35273;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#23454;&#35777;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23618;&#38388;&#30340;&#38750;&#20984;&#20132;&#20114;&#65292;&#29702;&#35770;&#19978;&#30340;&#23398;&#20064;&#21644;&#27867;&#21270;&#20998;&#26512;&#22823;&#22810;&#26159;&#38590;&#20197;&#29702;&#35299;&#30340;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#20110;&#19968;&#39033;&#20998;&#31867;&#20219;&#21153;&#65292;&#20351;&#29992;&#19968;&#20010;&#33258;&#25105;&#27880;&#24847;&#23618;&#21644;&#20004;&#23618;&#24863;&#30693;&#26426;&#30340;&#27973;&#23618;ViT&#36827;&#34892;&#35757;&#32451;&#30340;&#31532;&#19968;&#31687;&#29702;&#35770;&#20998;&#26512;&#65292;&#24314;&#31435;&#20102;&#23545;&#20110;&#25968;&#25454;&#27169;&#22411;&#30340;&#25551;&#36848;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#21516;&#26102;&#34920;&#24449;&#26631;&#35760;&#30456;&#20851;&#21644;&#26631;&#35760;&#19981;&#30456;&#20851;&#30340;&#20196;&#29260;&#12290;&#25105;&#20204;&#30028;&#23450;&#20102;&#36798;&#21040;&#38646;&#27867;&#21270;&#35823;&#24046;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#38480;&#21046;&#19982;&#26631;&#35760;&#30456;&#20851;&#20196;&#29260;&#30340;&#37096;&#20998;&#20498;&#25968;&#12289;&#26631;&#35760;&#32423;&#21035;&#30340;&#20196;&#29260;&#22122;&#22768;&#27700;&#24179;&#21644;&#21021;&#22987;&#27169;&#22411;&#35823;&#24046;&#21576;&#27491;&#30456;&#20851;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;SGD&#65288;stochastic gradient descent&#65289;&#36827;&#34892;&#35757;&#32451;&#36807;&#31243;&#20250;&#23548;&#33268;&#31232;&#30095;&#30340;&#27880;&#24847;&#21147;&#22270;&#65292;&#36825;&#26159;&#23545;&#20110;&#27880;&#24847;&#21147;&#25104;&#21151;&#30340;&#19968;&#31181;&#24418;&#24335;&#35777;&#26126;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#25351;&#20986;&#65292;&#36866;&#24403;&#30340;&#20196;&#29260;&#30830;&#23450;&#26159;&#30830;&#20445;&#23454;&#29616;&#26368;&#20248;&#24615;&#33021;&#30340;&#20851;&#38190;&#12290;
&lt;/p&gt;
&lt;p&gt;
Vision Transformers (ViTs) with self-attention modules have recently achieved great empirical success in many vision tasks. Due to non-convex interactions across layers, however, theoretical learning and generalization analysis is mostly elusive. Based on a data model characterizing both label-relevant and label-irrelevant tokens, this paper provides the first theoretical analysis of training a shallow ViT, i.e., one self-attention layer followed by a two-layer perceptron, for a classification task. We characterize the sample complexity to achieve a zero generalization error. Our sample complexity bound is positively correlated with the inverse of the fraction of label-relevant tokens, the token noise level, and the initial model error. We also prove that a training process using stochastic gradient descent (SGD) leads to a sparse attention map, which is a formal verification of the general intuition about the success of attention. Moreover, this paper indicates that a proper token spa
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20379;&#20102;&#24102;&#26377;&#20154;&#31867;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22312;Bradley-Terry-Luce&#21644;Plackett-Luce&#27169;&#22411;&#19979;&#25910;&#25947;&#12290;&#27492;&#22806;&#65292;&#25552;&#20986;&#20102;&#22312;&#19968;&#23450;&#30340;&#35206;&#30422;&#20551;&#35774;&#19979;&#65292;&#22522;&#20110;&#24754;&#35266;&#20272;&#35745;&#30340;MLE&#25552;&#20379;&#20102;&#24615;&#33021;&#26356;&#22909;&#30340;&#31574;&#30053;&#12290;&#22312;&#35777;&#26126;&#20102;&#30495;&#23454;MLE&#21644;&#20197;&#25104;&#23545;&#27604;&#36739;&#24418;&#24335;&#26367;&#20195;&#30340;&#22791;&#36873;MLE&#37117;&#21487;&#20197;&#22312;PL&#27169;&#22411;&#19979;&#25910;&#25947;&#30340;&#21516;&#26102;&#65292;&#20063;&#34920;&#26126;&#20102;&#30495;&#23454;MLE&#30340;&#39640;&#25928;&#24615;&#12290;&#36825;&#20123;&#32467;&#26524;&#20026;RLHF&#31639;&#27861;&#25552;&#20379;&#20102;&#26032;&#30340;&#35265;&#35299;&#65292;&#24182;&#32479;&#19968;&#20102;RLHF&#38382;&#39064;&#21644;IRL&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2301.11270</link><description>&lt;p&gt;
&#20351;&#29992;&#26469;&#33258;&#25104;&#23545;&#25110;$K$&#20803;&#27604;&#36739;&#30340;&#20154;&#31867;&#21453;&#39304;&#30340;&#35268;&#33539;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Principled Reinforcement Learning with Human Feedback from Pairwise or $K$-wise Comparisons. (arXiv:2301.11270v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11270
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20379;&#20102;&#24102;&#26377;&#20154;&#31867;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22312;Bradley-Terry-Luce&#21644;Plackett-Luce&#27169;&#22411;&#19979;&#25910;&#25947;&#12290;&#27492;&#22806;&#65292;&#25552;&#20986;&#20102;&#22312;&#19968;&#23450;&#30340;&#35206;&#30422;&#20551;&#35774;&#19979;&#65292;&#22522;&#20110;&#24754;&#35266;&#20272;&#35745;&#30340;MLE&#25552;&#20379;&#20102;&#24615;&#33021;&#26356;&#22909;&#30340;&#31574;&#30053;&#12290;&#22312;&#35777;&#26126;&#20102;&#30495;&#23454;MLE&#21644;&#20197;&#25104;&#23545;&#27604;&#36739;&#24418;&#24335;&#26367;&#20195;&#30340;&#22791;&#36873;MLE&#37117;&#21487;&#20197;&#22312;PL&#27169;&#22411;&#19979;&#25910;&#25947;&#30340;&#21516;&#26102;&#65292;&#20063;&#34920;&#26126;&#20102;&#30495;&#23454;MLE&#30340;&#39640;&#25928;&#24615;&#12290;&#36825;&#20123;&#32467;&#26524;&#20026;RLHF&#31639;&#27861;&#25552;&#20379;&#20102;&#26032;&#30340;&#35265;&#35299;&#65292;&#24182;&#32479;&#19968;&#20102;RLHF&#38382;&#39064;&#21644;IRL&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20026;&#24102;&#26377;&#20154;&#31867;&#21453;&#39304;&#30340;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#24403;&#30495;&#23454;&#22870;&#21169;&#20989;&#25968;&#20026;&#32447;&#24615;&#20989;&#25968;&#26102;&#65292;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65288;MLE&#65289;&#22312;Bradley-Terry-Luce&#65288;BTL&#65289;&#27169;&#22411;&#21644;Plackett-Luce&#65288;PL&#65289;&#27169;&#22411;&#19979;&#22343;&#25910;&#25947;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#24403;&#22522;&#20110;&#23398;&#24471;&#30340;&#22870;&#21169;&#27169;&#22411;&#35757;&#32451;&#31574;&#30053;&#26102;&#65292;MLE&#20250;&#22833;&#36133;&#65292;&#32780;&#22522;&#20110;&#24754;&#35266;&#20272;&#35745;&#30340;MLE&#22312;&#19968;&#23450;&#30340;&#35206;&#30422;&#20551;&#35774;&#19979;&#25552;&#20379;&#24615;&#33021;&#26356;&#22909;&#30340;&#31574;&#30053;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;PL&#27169;&#22411;&#19979;&#65292;&#30495;&#23454;MLE&#21644;&#23558;$k$&#20803;&#27604;&#36739;&#25286;&#20998;&#20026;&#25104;&#23545;&#27604;&#36739;&#30340;&#22791;&#36873;MLE&#37117;&#25910;&#25947;&#12290;&#32780;&#30495;&#23454;MLE&#26159;&#28176;&#36817;&#26356;&#20026;&#39640;&#25928;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#39564;&#35777;&#20102;&#29616;&#26377;RLHF&#31639;&#27861;&#65288;&#22914;InstructGPT&#65289;&#30340;&#23454;&#39564;&#25104;&#21151;&#65292;&#24182;&#20026;&#31639;&#27861;&#35774;&#35745;&#25552;&#20379;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#32479;&#19968;&#20102;RLHF&#38382;&#39064;&#21644;&#26368;&#22823;&#29109;&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;(IRL)&#38382;&#39064;&#65292;&#24182;&#20026;&#20854;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide a theoretical framework for Reinforcement Learning with Human Feedback (RLHF). Our analysis shows that when the true reward function is linear, the widely used maximum likelihood estimator (MLE) converges under both the Bradley-Terry-Luce (BTL) model and the Plackett-Luce (PL) model. However, we show that when training a policy based on the learned reward model, MLE fails while a pessimistic MLE provides policies with improved performance under certain coverage assumptions. Additionally, we demonstrate that under the PL model, the true MLE and an alternative MLE that splits the $K$-wise comparison into pairwise comparisons both converge. Moreover, the true MLE is asymptotically more efficient. Our results validate the empirical success of existing RLHF algorithms in InstructGPT and provide new insights for algorithm design. Furthermore, our results unify the problem of RLHF and max-entropy Inverse Reinforcement Learning (IRL), and provide the first sample complexity bound fo
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25506;&#31350;&#20102;&#24322;&#26041;&#24046;&#39640;&#26031;&#24207;&#21015;&#27169;&#22411;&#20013;&#30340;&#31232;&#30095;&#20449;&#21495;&#26816;&#27979;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#23567;&#26497;&#22823;&#20998;&#31163;&#21322;&#24452;&#30340;&#19978;&#19979;&#30028;&#20197;&#21450;&#30456;&#24212;&#30340;&#27979;&#35797;&#65292;&#23637;&#31034;&#20102;&#20851;&#20110;&#31232;&#30095;&#24230;&#12289;&#36317;&#31163;&#34913;&#37327;&#21644;&#24322;&#26041;&#24046;&#24615;&#36136;&#30340;&#26032;&#30340;&#30456;&#21464;&#29305;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.08580</link><description>&lt;p&gt;
&#24322;&#26041;&#24046;&#39640;&#26031;&#24207;&#21015;&#27169;&#22411;&#20013;&#30340;&#31232;&#30095;&#20449;&#21495;&#26816;&#27979;: &#23574;&#38160;&#30340;&#26497;&#23567;&#26497;&#22823;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Sparse Signal Detection in Heteroscedastic Gaussian Sequence Models: Sharp Minimax Rates. (arXiv:2211.08580v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.08580
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25506;&#31350;&#20102;&#24322;&#26041;&#24046;&#39640;&#26031;&#24207;&#21015;&#27169;&#22411;&#20013;&#30340;&#31232;&#30095;&#20449;&#21495;&#26816;&#27979;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#23567;&#26497;&#22823;&#20998;&#31163;&#21322;&#24452;&#30340;&#19978;&#19979;&#30028;&#20197;&#21450;&#30456;&#24212;&#30340;&#27979;&#35797;&#65292;&#23637;&#31034;&#20102;&#20851;&#20110;&#31232;&#30095;&#24230;&#12289;&#36317;&#31163;&#34913;&#37327;&#21644;&#24322;&#26041;&#24046;&#24615;&#36136;&#30340;&#26032;&#30340;&#30456;&#21464;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19968;&#20010;&#20855;&#26377;&#26410;&#30693;&#22343;&#20540; $\theta \in \mathbb R^d$ &#21644;&#24050;&#30693;&#21327;&#26041;&#24046;&#30697;&#38453; $\Sigma = \operatorname{diag}(\sigma_1^2,\dots, \sigma_d^2)$ &#30340;&#24322;&#36136;&#39640;&#26031;&#24207;&#21015;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38024;&#23545;&#31232;&#30095;&#22791;&#36873;&#26041;&#26696;&#30340;&#20449;&#21495;&#26816;&#27979;&#38382;&#39064;&#65292;&#23545;&#20110;&#24050;&#30693;&#30340;&#31232;&#30095;&#24230; $s$&#12290;&#20063;&#23601;&#26159;&#35828;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#26377;&#22810;&#22823;&#30340; $\epsilon^*&gt;0$&#65292;&#20197;&#20415;&#21487;&#20197;&#21306;&#20998;&#20986;&#38646;&#20551;&#35774; $\theta=0$ &#21644;&#30001; $\mathbb R^d$ &#20013; $s$-&#31232;&#30095;&#21521;&#37327;&#32452;&#25104;&#30340;&#22791;&#36873;&#35299;&#65292;&#23427;&#20204;&#36890;&#36807; $L^t$ &#33539;&#25968; ($t \in [1,\infty]$) &#19982; $0$ &#20998;&#24320;&#33267;&#23569; $\epsilon^*$ &#30340;&#27010;&#29575;&#24456;&#39640;&#12290;&#25105;&#20204;&#25214;&#21040;&#20102;&#26497;&#23567;&#26497;&#22823;&#20998;&#31163;&#21322;&#24452; $\epsilon^*$ &#30340;&#26497;&#23567;&#26497;&#22823;&#19978;&#19979;&#30028;&#65292;&#24182;&#35777;&#26126;&#23427;&#20204;&#24635;&#26159;&#21305;&#37197;&#30340;&#12290;&#25105;&#20204;&#36824;&#25512;&#23548;&#20102;&#30456;&#24212;&#30340;&#26497;&#23567;&#26497;&#22823;&#27979;&#35797;&#26469;&#23454;&#29616;&#36825;&#20123;&#30028;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25581;&#31034;&#20102;&#20851;&#20110; $\epsilon^*$ &#34892;&#20026;&#30340;&#26032;&#30340;&#30456;&#21464;&#29305;&#24615;&#65292;&#36825;&#21462;&#20915;&#20110;&#31232;&#30095;&#31243;&#24230;&#12289;$L^t$&#25351;&#26631;&#21644; $\Sigma$ &#30340;&#24322;&#26041;&#24046;&#29305;&#24615;&#12290;&#22312;&#27431;&#20960;&#37324;&#24471;&#65288;&#21363; $L^2$&#65289;&#20998;&#31163;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#20801;&#35768;&#25105;&#20204;&#24674;&#22797;&#20197;&#21069;&#30340;&#32467;&#26524;&#65292;&#24182;&#30830;&#23450;&#20102;&#30456;&#24212;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given a heterogeneous Gaussian sequence model with unknown mean $\theta \in \mathbb R^d$ and known covariance matrix $\Sigma = \operatorname{diag}(\sigma_1^2,\dots, \sigma_d^2)$, we study the signal detection problem against sparse alternatives, for known sparsity $s$. Namely, we characterize how large $\epsilon^*&gt;0$ should be, in order to distinguish with high probability the null hypothesis $\theta=0$ from the alternative composed of $s$-sparse vectors in $\mathbb R^d$, separated from $0$ in $L^t$ norm ($t \in [1,\infty]$) by at least $\epsilon^*$. We find minimax upper and lower bounds over the minimax separation radius $\epsilon^*$ and prove that they are always matching. We also derive the corresponding minimax tests achieving these bounds. Our results reveal new phase transitions regarding the behavior of $\epsilon^*$ with respect to the level of sparsity, to the $L^t$ metric, and to the heteroscedasticity profile of $\Sigma$. In the case of the Euclidean (i.e. $L^2$) separation,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#32437;&#21521;&#32593;&#32476;&#20272;&#35745;&#26694;&#26550;&#65292;&#21033;&#29992;&#33258;&#36866;&#24212;&#21512;&#24182;&#12289;&#24352;&#37327;&#20998;&#35299;&#21644;&#28857;&#36807;&#31243;&#31561;&#26041;&#27861;&#26469;&#20943;&#23569;&#20272;&#35745;&#20559;&#24046;&#21644;&#26041;&#24046;&#12290;</title><link>http://arxiv.org/abs/2211.07866</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#21512;&#24182;&#19979;&#30340;&#32437;&#21521;&#32593;&#32476;&#26377;&#25928;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Efficient Estimation for Longitudinal Network via Adaptive Merging. (arXiv:2211.07866v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.07866
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#32437;&#21521;&#32593;&#32476;&#20272;&#35745;&#26694;&#26550;&#65292;&#21033;&#29992;&#33258;&#36866;&#24212;&#21512;&#24182;&#12289;&#24352;&#37327;&#20998;&#35299;&#21644;&#28857;&#36807;&#31243;&#31561;&#26041;&#27861;&#26469;&#20943;&#23569;&#20272;&#35745;&#20559;&#24046;&#21644;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32437;&#21521;&#32593;&#32476;&#30001;&#22810;&#20010;&#33410;&#28857;&#20043;&#38388;&#30340;&#26102;&#38388;&#36793;&#24207;&#21015;&#32452;&#25104;&#65292;&#20854;&#20013;&#26102;&#38388;&#36793;&#22312;&#23454;&#26102;&#20013;&#34987;&#35266;&#23519;&#21040;&#12290;&#38543;&#30528;&#22312;&#32447;&#31038;&#20132;&#24179;&#21488;&#21644;&#30005;&#23376;&#21830;&#21153;&#30340;&#20852;&#36215;&#65292;&#23427;&#24050;&#32463;&#21464;&#24471;&#26222;&#36941;&#65292;&#20294;&#22312;&#25991;&#29486;&#20013;&#24448;&#24448;&#34987;&#24573;&#30053;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#32437;&#21521;&#32593;&#32476;&#20272;&#35745;&#26694;&#26550;&#65292;&#21033;&#29992;&#33258;&#36866;&#24212;&#32593;&#32476;&#21512;&#24182;&#12289;&#24352;&#37327;&#20998;&#35299;&#21644;&#28857;&#36807;&#31243;&#30340;&#20248;&#21183;&#12290;&#23427;&#21512;&#24182;&#30456;&#37051;&#30340;&#31232;&#30095;&#32593;&#32476;&#65292;&#20197;&#25193;&#22823;&#35266;&#27979;&#36793;&#30340;&#25968;&#37327;&#24182;&#20943;&#23569;&#20272;&#35745;&#26041;&#24046;&#65292;&#21516;&#26102;&#36890;&#36807;&#21033;&#29992;&#26412;&#22320;&#26102;&#38388;&#32467;&#26500;&#36827;&#34892;&#33258;&#36866;&#24212;&#32593;&#32476;&#37051;&#22495;&#25511;&#21046;&#24341;&#20837;&#30340;&#20272;&#35745;&#20559;&#24046;&#12290;&#25552;&#20986;&#20102;&#19968;&#20010;&#25237;&#24433;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#26469;&#20419;&#36827;&#20272;&#35745;&#65292;&#20854;&#20013;&#27599;&#27425;&#36845;&#20195;&#30340;&#20272;&#35745;&#38169;&#35823;&#19978;&#30028;&#34987;&#24314;&#31435;&#12290;&#36827;&#34892;&#20102;&#24443;&#24213;&#30340;&#20998;&#26512;&#65292;&#20197;&#37327;&#21270;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#28176;&#36817;&#34892;&#20026;&#65292;&#32467;&#26524;&#34920;&#26126;&#23427;&#21487;&#20197;&#26174;&#30528;&#20943;&#23569;&#20272;&#35745;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Longitudinal network consists of a sequence of temporal edges among multiple nodes, where the temporal edges are observed in real time. It has become ubiquitous with the rise of online social platform and e-commerce, but largely under-investigated in literature. In this paper, we propose an efficient estimation framework for longitudinal network, leveraging strengths of adaptive network merging, tensor decomposition and point process. It merges neighboring sparse networks so as to enlarge the number of observed edges and reduce estimation variance, whereas the estimation bias introduced by network merging is controlled by exploiting local temporal structures for adaptive network neighborhood. A projected gradient descent algorithm is proposed to facilitate estimation, where the upper bound of the estimation error in each iteration is established. A thorough analysis is conducted to quantify the asymptotic behavior of the proposed method, which shows that it can significantly reduce the
&lt;/p&gt;</description></item><item><title>&#38544;&#21464;&#37327;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#36890;&#36807;&#23558;&#23450;&#24615;&#22240;&#32032;&#26144;&#23556;&#21040;&#24213;&#23618;&#38544;&#21464;&#37327;&#30340;&#26041;&#24335;&#35299;&#20915;&#20102;&#26631;&#20934;&#39640;&#26031;&#36807;&#31243;&#26080;&#27861;&#36866;&#24212;&#23450;&#24615;&#36755;&#20837;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32771;&#34385;&#38544;&#21464;&#37327;&#20272;&#35745;&#19981;&#30830;&#23450;&#24615;&#30340;&#23436;&#20840;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#25903;&#25345;&#36890;&#36807;&#38544;&#21464;&#37327;&#21487;&#35270;&#21270;&#23450;&#24615;&#36755;&#20837;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2211.02218</link><description>&lt;p&gt;
&#38544;&#21464;&#37327;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#23436;&#20840;&#36125;&#21494;&#26031;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Fully Bayesian inference for latent variable Gaussian process models. (arXiv:2211.02218v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.02218
&lt;/p&gt;
&lt;p&gt;
&#38544;&#21464;&#37327;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#36890;&#36807;&#23558;&#23450;&#24615;&#22240;&#32032;&#26144;&#23556;&#21040;&#24213;&#23618;&#38544;&#21464;&#37327;&#30340;&#26041;&#24335;&#35299;&#20915;&#20102;&#26631;&#20934;&#39640;&#26031;&#36807;&#31243;&#26080;&#27861;&#36866;&#24212;&#23450;&#24615;&#36755;&#20837;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32771;&#34385;&#38544;&#21464;&#37327;&#20272;&#35745;&#19981;&#30830;&#23450;&#24615;&#30340;&#23436;&#20840;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#25903;&#25345;&#36890;&#36807;&#38544;&#21464;&#37327;&#21487;&#35270;&#21270;&#23450;&#24615;&#36755;&#20837;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#38469;&#24037;&#31243;&#21644;&#31185;&#23398;&#24212;&#29992;&#24120;&#24120;&#28041;&#21450;&#19968;&#20010;&#25110;&#22810;&#20010;&#23450;&#24615;&#36755;&#20837;&#12290;&#28982;&#32780;&#65292;&#26631;&#20934;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#19981;&#33021;&#30452;&#25509;&#36866;&#24212;&#23450;&#24615;&#36755;&#20837;&#12290;&#26368;&#36817;&#24341;&#20837;&#30340;&#38544;&#21464;&#37327;&#39640;&#26031;&#36807;&#31243;&#65288;LVGP&#65289;&#36890;&#36807;&#39318;&#20808;&#23558;&#27599;&#20010;&#23450;&#24615;&#22240;&#32032;&#26144;&#23556;&#21040;&#24213;&#23618;&#38544;&#21464;&#37327;&#65288;LV&#65289;&#65292;&#28982;&#21518;&#22312;&#36825;&#20123;LV&#19978;&#20351;&#29992;&#20219;&#20309;&#26631;&#20934;GP&#21327;&#26041;&#24046;&#20989;&#25968;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#36890;&#36807;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65292;&#23545;LV&#36827;&#34892;&#20272;&#35745;&#65292;&#28982;&#21518;&#23558;&#20854;&#25554;&#20837;&#21040;&#39044;&#27979;&#34920;&#36798;&#24335;&#20013;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#25554;&#20837;&#26041;&#27861;&#19981;&#32771;&#34385;LV&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#32780;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#22312;&#35757;&#32451;&#25968;&#25454;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#21487;&#33021;&#20250;&#24456;&#22823;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20026;LVGP&#27169;&#22411;&#24320;&#21457;&#20102;&#19968;&#20010;&#23436;&#20840;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#20854;LV&#21487;&#35270;&#21270;&#20102;&#23450;&#24615;&#36755;&#20837;&#30340;&#25928;&#26524;&#12290;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#36866;&#29992;&#20110;&#25193;&#23637;LVGP&#21644;LVGP&#36229;&#21442;&#25968;&#30340;&#23436;&#20840;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#36817;&#20284;&#26041;&#27861;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#25968;&#20540;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Real engineering and scientific applications often involve one or more qualitative inputs. Standard Gaussian processes (GPs), however, cannot directly accommodate qualitative inputs. The recently introduced latent variable Gaussian process (LVGP) overcomes this issue by first mapping each qualitative factor to underlying latent variables (LVs), and then uses any standard GP covariance function over these LVs. The LVs are estimated similarly to the other GP hyperparameters through maximum likelihood estimation, and then plugged into the prediction expressions. However, this plug-in approach will not account for uncertainty in estimation of the LVs, which can be significant especially with limited training data. In this work, we develop a fully Bayesian approach for the LVGP model and for visualizing the effects of the qualitative inputs via their LVs. We also develop approximations for scaling up LVGPs and fully Bayesian inference for the LVGP hyperparameters. We conduct numerical studi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#26234;&#33021;&#20307;&#23398;&#20064;&#20013;&#30340;&#26426;&#22120;&#20154;&#23398;&#20064;&#31639;&#27861;&#65292;&#25351;&#20986;&#20102;&#39321;&#33609;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#21487;&#33021;&#22240;&#20855;&#26377;&#19981;&#25910;&#25947;&#30340;&#21442;&#25968;&#32780;&#23384;&#22312;&#23398;&#20064;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;NPG&#31639;&#27861;&#21464;&#31181;&#20197;&#35299;&#20915;&#27492;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2210.12812</link><description>&lt;p&gt;
&#23545;&#31216;&#65288;&#20048;&#35266;&#65289;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#30340;&#21442;&#25968;&#25910;&#25947;&#24615;&#22810;&#26234;&#33021;&#20307;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Symmetric (Optimistic) Natural Policy Gradient for Multi-agent Learning with Parameter Convergence. (arXiv:2210.12812v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.12812
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#26234;&#33021;&#20307;&#23398;&#20064;&#20013;&#30340;&#26426;&#22120;&#20154;&#23398;&#20064;&#31639;&#27861;&#65292;&#25351;&#20986;&#20102;&#39321;&#33609;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#21487;&#33021;&#22240;&#20855;&#26377;&#19981;&#25910;&#25947;&#30340;&#21442;&#25968;&#32780;&#23384;&#22312;&#23398;&#20064;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;NPG&#31639;&#27861;&#21464;&#31181;&#20197;&#35299;&#20915;&#27492;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#22810;&#26234;&#33021;&#20307;&#20114;&#21160;&#36234;&#26469;&#36234;&#37325;&#35201;&#65292;&#24182;&#19988;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#30340;&#29702;&#35770;&#22522;&#30784;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#27987;&#21402;&#20852;&#36259;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#26234;&#33021;&#20307;&#23398;&#20064;&#20013;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#65288;NPG&#65289;&#31639;&#27861;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#39321;&#33609;NPG&#21487;&#33021;&#27809;&#26377;&#21442;&#25968;&#25910;&#25947;&#65292;&#21363;&#21442;&#25968;&#21270;&#31574;&#30053;&#30340;&#21521;&#37327;&#30340;&#25910;&#25947;&#65292;&#21363;&#20351;&#25104;&#26412;&#34987;&#35268;&#21017;&#21270;&#65288;&#22312;&#25991;&#29486;&#20013;&#20351;&#31574;&#30053;&#31354;&#38388;&#26377;&#24378;&#30340;&#25910;&#25947;&#20445;&#35777;&#65289;&#12290;&#36825;&#20123;&#38750;&#25910;&#25947;&#30340;&#21442;&#25968;&#23548;&#33268;&#23398;&#20064;&#20013;&#30340;&#31283;&#23450;&#24615;&#38382;&#39064;&#65292;&#22312;&#20989;&#25968;&#36924;&#36817;&#30340;&#24773;&#20917;&#19979;&#23588;&#20026;&#37325;&#35201;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#21482;&#33021;&#22788;&#29702;&#20302;&#32500;&#21442;&#25968;&#65292;&#32780;&#19981;&#26159;&#39640;&#32500;&#31574;&#30053;&#12290;&#28982;&#21518;&#25105;&#20204;&#38024;&#23545;&#20960;&#31181;&#26631;&#20934;&#22810;&#26234;&#33021;&#20307;&#23398;&#20064;&#22330;&#26223;&#25552;&#20986;&#20102;NPG&#31639;&#27861;&#30340;&#21464;&#31181;&#65306;&#20004;&#20010;&#29609;&#23478;&#30340;&#38646;&#21644;&#30697;&#38453;&#21644;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#65292;&#20197;&#21450;&#22810;&#20010;&#29609;&#23478;&#30340;&#21333;&#35843;&#21338;&#24328;&#65292;&#20854;&#20855;&#26377;&#20840;&#23616;&#26368;&#21518;&#36845;&#20195;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-agent interactions are increasingly important in the context of reinforcement learning, and the theoretical foundations of policy gradient methods have attracted surging research interest. We investigate the global convergence of natural policy gradient (NPG) algorithms in multi-agent learning. We first show that vanilla NPG may not have parameter convergence, i.e., the convergence of the vector that parameterizes the policy, even when the costs are regularized (which enabled strong convergence guarantees in the policy space in the literature). This non-convergence of parameters leads to stability issues in learning, which becomes especially relevant in the function approximation setting, where we can only operate on low-dimensional parameters, instead of the high-dimensional policy. We then propose variants of the NPG algorithm, for several standard multi-agent learning scenarios: two-player zero-sum matrix and Markov games, and multi-player monotone games, with global last-iter
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#22522;&#20110;&#29305;&#24449;&#31526;&#21512;&#39044;&#27979;&#30340;&#39044;&#27979;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#28145;&#24230;&#34920;&#31034;&#23398;&#20064;&#30340;&#24402;&#32435;&#20559;&#32622;&#65292;&#25193;&#23637;&#20102;&#31526;&#21512;&#39044;&#27979;&#21040;&#35821;&#20041;&#29305;&#24449;&#31354;&#38388;&#12290;&#20174;&#29702;&#35770;&#21644;&#23454;&#39564;&#32467;&#26524;&#26469;&#30475;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#24120;&#35268;&#31526;&#21512;&#39044;&#27979;&#65292;&#24182;&#22312;&#22823;&#35268;&#27169;&#20219;&#21153;&#19978;&#23637;&#29616;&#20102;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2210.00173</link><description>&lt;p&gt;
&#22522;&#20110;&#29305;&#24449;&#31526;&#21512;&#39044;&#27979;&#30340;&#39044;&#27979;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Predictive Inference with Feature Conformal Prediction. (arXiv:2210.00173v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.00173
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#22522;&#20110;&#29305;&#24449;&#31526;&#21512;&#39044;&#27979;&#30340;&#39044;&#27979;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#28145;&#24230;&#34920;&#31034;&#23398;&#20064;&#30340;&#24402;&#32435;&#20559;&#32622;&#65292;&#25193;&#23637;&#20102;&#31526;&#21512;&#39044;&#27979;&#21040;&#35821;&#20041;&#29305;&#24449;&#31354;&#38388;&#12290;&#20174;&#29702;&#35770;&#21644;&#23454;&#39564;&#32467;&#26524;&#26469;&#30475;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#24120;&#35268;&#31526;&#21512;&#39044;&#27979;&#65292;&#24182;&#22312;&#22823;&#35268;&#27169;&#20219;&#21153;&#19978;&#23637;&#29616;&#20102;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31526;&#21512;&#39044;&#27979;&#26159;&#19968;&#31181;&#26080;&#20998;&#24067;&#25216;&#26415;&#65292;&#29992;&#20110;&#24314;&#31435;&#26377;&#25928;&#30340;&#39044;&#27979;&#38388;&#38548;&#12290;&#34429;&#28982;&#20256;&#32479;&#19978;&#20154;&#20204;&#22312;&#36755;&#20986;&#31354;&#38388;&#20013;&#36827;&#34892;&#31526;&#21512;&#39044;&#27979;&#65292;&#20294;&#36825;&#24182;&#19981;&#26159;&#21807;&#19968;&#30340;&#21487;&#33021;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#29305;&#24449;&#30340;&#31526;&#21512;&#39044;&#27979;&#65292;&#36890;&#36807;&#21033;&#29992;&#28145;&#24230;&#34920;&#31034;&#23398;&#20064;&#30340;&#24402;&#32435;&#20559;&#32622;&#65292;&#25193;&#23637;&#20102;&#31526;&#21512;&#39044;&#27979;&#23545;&#35821;&#20041;&#29305;&#24449;&#31354;&#38388;&#30340;&#33539;&#22260;&#12290;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22522;&#20110;&#29305;&#24449;&#30340;&#31526;&#21512;&#39044;&#27979;&#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#21487;&#20197;&#35777;&#26126;&#20248;&#20110;&#24120;&#35268;&#31526;&#21512;&#39044;&#27979;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20165;&#21487;&#20197;&#19982;&#26222;&#36890;&#31526;&#21512;&#39044;&#27979;&#32467;&#21512;&#20351;&#29992;&#65292;&#32780;&#19988;&#21487;&#20197;&#19982;&#20854;&#20182;&#33258;&#36866;&#24212;&#31526;&#21512;&#39044;&#27979;&#26041;&#27861;&#32467;&#21512;&#20351;&#29992;&#12290;&#38500;&#20102;&#29616;&#26377;&#39044;&#27979;&#25512;&#26029;&#22522;&#20934;&#27979;&#35797;&#30340;&#23454;&#39564;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#22823;&#35268;&#27169;&#20219;&#21153;&#65288;&#22914;ImageNet&#20998;&#31867;&#21644;Cityscapes&#22270;&#20687;&#20998;&#21106;&#65289;&#19978;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conformal prediction is a distribution-free technique for establishing valid prediction intervals. Although conventionally people conduct conformal prediction in the output space, this is not the only possibility. In this paper, we propose feature conformal prediction, which extends the scope of conformal prediction to semantic feature spaces by leveraging the inductive bias of deep representation learning. From a theoretical perspective, we demonstrate that feature conformal prediction provably outperforms regular conformal prediction under mild assumptions. Our approach could be combined with not only vanilla conformal prediction, but also other adaptive conformal prediction methods. Apart from experiments on existing predictive inference benchmarks, we also demonstrate the state-of-the-art performance of the proposed methods on large-scale tasks such as ImageNet classification and Cityscapes image segmentation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#23384;&#22312;&#25200;&#21160;&#24773;&#20917;&#19979;&#23433;&#20840;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;&#25506;&#32034;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#25152;&#25511;&#21046;&#23545;&#35937;&#21644;&#25200;&#21160;&#30340;&#37096;&#20998;&#20808;&#39564;&#30693;&#35782;&#65292;&#21487;&#20197;&#20445;&#35777;&#20197;&#39044;&#20808;&#25351;&#23450;&#30340;&#27010;&#29575;&#28385;&#36275;&#26174;&#24335;&#29366;&#24577;&#32422;&#26463;&#12290;</title><link>http://arxiv.org/abs/2209.15452</link><description>&lt;p&gt;
&#23384;&#22312;&#25200;&#21160;&#24773;&#20917;&#19979;&#24378;&#21270;&#23398;&#20064;&#30340;&#23433;&#20840;&#25506;&#32034;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Safe Exploration Method for Reinforcement Learning under Existence of Disturbance. (arXiv:2209.15452v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.15452
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#23384;&#22312;&#25200;&#21160;&#24773;&#20917;&#19979;&#23433;&#20840;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;&#25506;&#32034;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#25152;&#25511;&#21046;&#23545;&#35937;&#21644;&#25200;&#21160;&#30340;&#37096;&#20998;&#20808;&#39564;&#30693;&#35782;&#65292;&#21487;&#20197;&#20445;&#35777;&#20197;&#39044;&#20808;&#25351;&#23450;&#30340;&#27010;&#29575;&#28385;&#36275;&#26174;&#24335;&#29366;&#24577;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#24555;&#36895;&#21457;&#23637;&#22312;&#35768;&#22810;&#39046;&#22495;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20854;&#25506;&#32034;&#29305;&#24615;&#65292;&#24403;&#25105;&#20204;&#23558;&#36825;&#20123;&#31639;&#27861;&#24212;&#29992;&#20110;&#23433;&#20840;&#20851;&#38190;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#22312;&#23454;&#38469;&#29615;&#22659;&#20013;&#26102;&#65292;&#25105;&#20204;&#24517;&#39035;&#32771;&#34385;&#39118;&#38505;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28041;&#21450;&#23384;&#22312;&#25200;&#21160;&#26102;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#23433;&#20840;&#25506;&#32034;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#23558;&#23398;&#20064;&#36807;&#31243;&#20013;&#30340;&#23433;&#20840;&#24615;&#23450;&#20041;&#20026;&#20197;&#29366;&#24577;&#26126;&#30830;&#23450;&#20041;&#30340;&#38480;&#21046;&#26465;&#20214;&#30340;&#28385;&#36275;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#23433;&#20840;&#25506;&#32034;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#25152;&#25511;&#21046;&#23545;&#35937;&#21644;&#25200;&#21160;&#30340;&#37096;&#20998;&#20808;&#39564;&#30693;&#35782;&#12290;&#21363;&#20351;&#25152;&#25511;&#21046;&#23545;&#35937;&#26292;&#38706;&#20110;&#36981;&#24490;&#27491;&#24577;&#20998;&#24067;&#30340;&#38543;&#26426;&#25200;&#21160;&#65292;&#35813;&#26041;&#27861;&#20063;&#33021;&#20445;&#35777;&#20197;&#39044;&#20808;&#25351;&#23450;&#30340;&#27010;&#29575;&#28385;&#36275;&#26174;&#24335;&#29366;&#24577;&#32422;&#26463;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#36275;&#22815;&#30340;&#26465;&#20214;&#26469;&#26500;&#24314;&#19981;&#21253;&#21547;&#20256;&#32479;&#25506;&#32034;&#26041;&#27861;&#20013;&#30340;&#25506;&#32034;&#22240;&#32032;&#30340;&#20445;&#23432;&#36755;&#20837;&#12290;&#22312;&#25670;&#21160;&#20219;&#21153;&#30340;&#27169;&#25311;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#22312;&#28385;&#36275;&#26174;&#24335;&#32422;&#26463;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#23433;&#20840;&#22320;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent rapid developments in reinforcement learning algorithms have been giving us novel possibilities in many fields. However, due to their exploring property, we have to take the risk into consideration when we apply those algorithms to safety-critical problems especially in real environments. In this study, we deal with a safe exploration problem in reinforcement learning under the existence of disturbance. We define the safety during learning as satisfaction of the constraint conditions explicitly defined in terms of the state and propose a safe exploration method that uses partial prior knowledge of a controlled object and disturbance. The proposed method assures the satisfaction of the explicit state constraints with a pre-specified probability even if the controlled object is exposed to a stochastic disturbance following a normal distribution. As theoretical results, we introduce sufficient conditions to construct conservative inputs not containing an exploring aspect used in th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20048;&#35266;&#21407;&#21017;&#21644;&#31163;&#32447;&#22270;&#24418;&#35268;&#21010;&#31639;&#27861;&#30340;&#23398;&#20064;&#31639;&#27861;G-UCB&#65292;&#33021;&#22815;&#24179;&#34913;&#38271;&#26399;&#25506;&#32034;&#21033;&#29992;&#65292;&#29992;&#20110;&#35299;&#20915;&#19968;&#31181;&#21517;&#20026;&#22270;&#36172;&#21338;&#26426;&#30340;MAB&#25193;&#23637;&#65292;&#20174;&#32780;&#33719;&#24471;&#26368;&#22823;&#21270;&#30340;&#25910;&#30410;&#12290;</title><link>http://arxiv.org/abs/2209.09419</link><description>&lt;p&gt;
&#19968;&#31181;&#22270;&#19978;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Multi-armed Bandit Learning on a Graph. (arXiv:2209.09419v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.09419
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20048;&#35266;&#21407;&#21017;&#21644;&#31163;&#32447;&#22270;&#24418;&#35268;&#21010;&#31639;&#27861;&#30340;&#23398;&#20064;&#31639;&#27861;G-UCB&#65292;&#33021;&#22815;&#24179;&#34913;&#38271;&#26399;&#25506;&#32034;&#21033;&#29992;&#65292;&#29992;&#20110;&#35299;&#20915;&#19968;&#31181;&#21517;&#20026;&#22270;&#36172;&#21338;&#26426;&#30340;MAB&#25193;&#23637;&#65292;&#20174;&#32780;&#33719;&#24471;&#26368;&#22823;&#21270;&#30340;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#26159;&#19968;&#20010;&#31616;&#21333;&#32780;&#24378;&#22823;&#30340;&#26694;&#26550;&#65292;&#22312;&#19981;&#30830;&#23450;&#24615;&#20915;&#31574;&#26041;&#38754;&#24050;&#32463;&#24471;&#21040;&#24191;&#27867;&#30740;&#31350;&#12290;&#22312;&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#20013;&#65292;&#20363;&#22914;&#26426;&#22120;&#20154;&#24212;&#29992;&#20013;&#65292;&#36873;&#25321;&#19968;&#20010;&#33218;&#23545;&#24212;&#20110;&#38480;&#21046;&#19979;&#19968;&#20010;&#21487;&#29992;&#33218;&#65288;&#21160;&#20316;&#65289;&#30340;&#36873;&#25321;&#12290;&#20986;&#20110;&#36825;&#20010;&#30446;&#30340;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#21517;&#20026;&#22270;&#36172;&#21338;&#26426;&#30340;MAB&#25193;&#23637;&#65292;&#22312;&#27492;&#36807;&#31243;&#20013;&#65292;&#26234;&#33021;&#20307;&#20174;&#19981;&#21516;&#33410;&#28857;&#20013;&#25910;&#38598;&#22870;&#21169;&#20197;&#33719;&#24471;&#26368;&#22823;&#21270;&#30340;&#25910;&#30410;&#12290;&#22270;&#23450;&#20041;&#20102;&#26234;&#33021;&#20307;&#22312;&#27599;&#19968;&#27493;&#20013;&#36873;&#25321;&#19979;&#19968;&#20010;&#21487;&#29992;&#33410;&#28857;&#30340;&#33258;&#30001;&#24230;&#12290;&#25105;&#20204;&#20551;&#35774;&#22270;&#30340;&#32467;&#26500;&#26159;&#23436;&#20840;&#21487;&#29992;&#30340;&#65292;&#20294;&#22870;&#21169;&#20998;&#24067;&#26159;&#26410;&#30693;&#30340;&#12290;&#22522;&#20110;&#31163;&#32447;&#22270;&#24418;&#35268;&#21010;&#31639;&#27861;&#21644;&#20048;&#35266;&#21407;&#21017;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#23398;&#20064;&#31639;&#27861;G-UCB&#65292;&#24179;&#34913;&#38271;&#26399;&#25506;&#32034;&#21033;&#29992;&#20351;&#29992;&#20048;&#35266;&#21407;&#21017;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#36798;&#21040;&#20102;$O(\sqrt{|S|T\log(T)}+D|S|\log T)$&#30340;&#23398;&#20064;&#36951;&#25022;&#12290;&#20854;&#20013;$|S|$&#26159;
&lt;/p&gt;
&lt;p&gt;
The multi-armed bandit(MAB) problem is a simple yet powerful framework that has been extensively studied in the context of decision-making under uncertainty. In many real-world applications, such as robotic applications, selecting an arm corresponds to a physical action that constrains the choices of the next available arms (actions). Motivated by this, we study an extension of MAB called the graph bandit, where an agent travels over a graph to maximize the reward collected from different nodes. The graph defines the agent's freedom in selecting the next available nodes at each step. We assume the graph structure is fully available, but the reward distributions are unknown. Built upon an offline graph-based planning algorithm and the principle of optimism, we design a learning algorithm, G-UCB, that balances long-term exploration-exploitation using the principle of optimism. We show that our proposed algorithm achieves $O(\sqrt{|S|T\log(T)}+D|S|\log T)$ learning regret, where $|S|$ is 
&lt;/p&gt;</description></item><item><title>AceIRL&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36870;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#20027;&#21160;&#25506;&#32034;&#26469;&#23398;&#20064;&#22870;&#21169;&#20989;&#25968;&#21644;&#31574;&#30053;&#65292;&#22312;&#19981;&#38656;&#35201;&#29615;&#22659;&#29983;&#25104;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#33021;&#22815;&#30830;&#23450;&#21487;&#34892;&#22870;&#21169;&#20989;&#25968;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#24182;&#25214;&#21040;&#20391;&#37325;&#20110;&#29615;&#22659;&#20013;&#26368;&#26377;&#20449;&#24687;&#30340;&#21306;&#22495;&#30340;&#25506;&#32034;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2207.08645</link><description>&lt;p&gt;
&#36870;&#24378;&#21270;&#23398;&#20064;&#30340;&#20027;&#21160;&#25506;&#32034;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Active Exploration for Inverse Reinforcement Learning. (arXiv:2207.08645v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.08645
&lt;/p&gt;
&lt;p&gt;
AceIRL&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36870;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#20027;&#21160;&#25506;&#32034;&#26469;&#23398;&#20064;&#22870;&#21169;&#20989;&#25968;&#21644;&#31574;&#30053;&#65292;&#22312;&#19981;&#38656;&#35201;&#29615;&#22659;&#29983;&#25104;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#33021;&#22815;&#30830;&#23450;&#21487;&#34892;&#22870;&#21169;&#20989;&#25968;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#24182;&#25214;&#21040;&#20391;&#37325;&#20110;&#29615;&#22659;&#20013;&#26368;&#26377;&#20449;&#24687;&#30340;&#21306;&#22495;&#30340;&#25506;&#32034;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36870;&#24378;&#21270;&#23398;&#20064;&#65288;IRL&#65289;&#26159;&#20174;&#19987;&#23478;&#28436;&#31034;&#20013;&#25512;&#26029;&#22870;&#21169;&#20989;&#25968;&#30340;&#24378;&#22823;&#33539;&#24335;&#12290;&#35768;&#22810;IRL&#31639;&#27861;&#38656;&#35201;&#24050;&#30693;&#30340;&#36716;&#31227;&#27169;&#22411;&#65292;&#26377;&#26102;&#29978;&#33267;&#38656;&#35201;&#24050;&#30693;&#30340;&#19987;&#23478;&#31574;&#30053;&#65292;&#25110;&#32773;&#33267;&#23569;&#38656;&#35201;&#35775;&#38382;&#29983;&#25104;&#27169;&#22411;&#12290;&#20294;&#26159;&#65292;&#36825;&#20123;&#20551;&#35774;&#23545;&#20110;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#26469;&#35828;&#22826;&#24378;&#20102;&#65292;&#22240;&#20026;&#21482;&#33021;&#36890;&#36807;&#39034;&#24207;&#20132;&#20114;&#26469;&#35775;&#38382;&#29615;&#22659;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;IRL&#31639;&#27861;&#65306;&#20027;&#21160;&#25506;&#32034;&#36870;&#24378;&#21270;&#23398;&#20064;&#65288;AceIRL&#65289;&#65292;&#23427;&#20027;&#21160;&#25506;&#32034;&#26410;&#30693;&#29615;&#22659;&#21644;&#19987;&#23478;&#31574;&#30053;&#65292;&#24555;&#36895;&#23398;&#20064;&#19987;&#23478;&#30340;&#22870;&#21169;&#20989;&#25968;&#24182;&#35782;&#21035;&#20986;&#19968;&#20010;&#22909;&#30340;&#31574;&#30053;&#12290;AceIRL&#20351;&#29992;&#20808;&#21069;&#30340;&#35266;&#23519;&#32467;&#26524;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#26469;&#25429;&#25417;&#21487;&#34892;&#30340;&#22870;&#21169;&#20989;&#25968;&#65292;&#24182;&#25214;&#21040;&#20391;&#37325;&#20110;&#29615;&#22659;&#20013;&#26368;&#26377;&#20449;&#24687;&#30340;&#21306;&#22495;&#30340;&#25506;&#32034;&#31574;&#30053;&#12290;AceIRL&#26159;&#31532;&#19968;&#31181;&#20855;&#26377;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#19988;&#19981;&#38656;&#35201;&#29615;&#22659;&#29983;&#25104;&#27169;&#22411;&#30340;&#20027;&#21160;IRL&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inverse Reinforcement Learning (IRL) is a powerful paradigm for inferring a reward function from expert demonstrations. Many IRL algorithms require a known transition model and sometimes even a known expert policy, or they at least require access to a generative model. However, these assumptions are too strong for many real-world applications, where the environment can be accessed only through sequential interaction. We propose a novel IRL algorithm: Active exploration for Inverse Reinforcement Learning (AceIRL), which actively explores an unknown environment and expert policy to quickly learn the expert's reward function and identify a good policy. AceIRL uses previous observations to construct confidence intervals that capture plausible reward functions and find exploration policies that focus on the most informative regions of the environment. AceIRL is the first approach to active IRL with sample-complexity bounds that does not require a generative model of the environment. AceIRL 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#28151;&#21512;&#27169;&#22411;&#20013;&#28151;&#21512;&#27979;&#24230;&#30340;Wasserstein&#36317;&#31163;&#30340;&#26032;&#30340;&#35268;&#33539;&#35299;&#37322;&#65292;&#24182;&#25552;&#20379;&#20102;&#22312;&#20027;&#39064;&#27169;&#22411;&#20013;&#36827;&#34892;&#27492;&#36317;&#31163;&#25512;&#26029;&#30340;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2206.12768</link><description>&lt;p&gt;
&#20027;&#39064;&#27169;&#22411;&#20013;&#28151;&#21512;&#27979;&#24230;&#30340;Wasserstein&#36317;&#31163;&#30340;&#20272;&#35745;&#21644;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Estimation and inference for the Wasserstein distance between mixing measures in topic models. (arXiv:2206.12768v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.12768
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#28151;&#21512;&#27169;&#22411;&#20013;&#28151;&#21512;&#27979;&#24230;&#30340;Wasserstein&#36317;&#31163;&#30340;&#26032;&#30340;&#35268;&#33539;&#35299;&#37322;&#65292;&#24182;&#25552;&#20379;&#20102;&#22312;&#20027;&#39064;&#27169;&#22411;&#20013;&#36827;&#34892;&#27492;&#36317;&#31163;&#25512;&#26029;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28151;&#21512;&#27169;&#22411;&#30340;&#32479;&#35745;&#20998;&#26512;&#20013;&#65292;&#28151;&#21512;&#27979;&#24230;&#30340;Wasserstein&#36317;&#31163;&#24050;&#32463;&#25104;&#20026;&#20102;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#36825;&#31181;&#36317;&#31163;&#30340;&#26032;&#30340;&#35268;&#33539;&#35299;&#37322;&#65292;&#24182;&#25552;&#20379;&#20102;&#22312;&#20027;&#39064;&#27169;&#22411;&#20013;&#36827;&#34892;&#28151;&#21512;&#27979;&#24230;&#30340;Wasserstein&#36317;&#31163;&#25512;&#26029;&#30340;&#24037;&#20855;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#33324;&#21487;&#35782;&#21035;&#28151;&#21512;&#27169;&#22411;&#30340;&#24773;&#20917;&#65292;&#20854;&#20013;&#21253;&#25324;&#20102;&#22810;&#20010;&#26469;&#33258;&#38598;&#21512;$\mathcal{A}$&#20869;&#24102;&#26377;&#20219;&#24847;&#24230;&#37327;$d$&#30340;&#20998;&#24067;&#30340;&#28151;&#21512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#28151;&#21512;&#27979;&#24230;&#30340;Wasserstein&#36317;&#31163;&#26159;&#21807;&#19968;&#22320;&#34920;&#24449;&#20986;&#28151;&#21512;&#20803;&#32032;&#38598;&#21512;$\mathcal{A}$&#19978;&#24230;&#37327;$d$&#30340;&#26368;&#26377;&#21306;&#20998;&#24615;&#30340;&#20984;&#25193;&#23637;&#12290;&#34429;&#28982;Wasserstein&#36317;&#31163;&#22312;&#28151;&#21512;&#27169;&#22411;&#30340;&#30740;&#31350;&#20013;&#24050;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#32570;&#20047;&#20844;&#29702;&#35777;&#26126;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#30830;&#31435;&#20102;&#36825;&#20010;&#24230;&#37327;&#20316;&#20026;&#19968;&#20010;&#35268;&#33539;&#36873;&#25321;&#12290;&#29305;&#20934;&#21270;&#36825;&#20010;&#24230;&#37327;&#21040;&#20027;&#39064;&#27169;&#22411;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#36825;&#20010;&#36317;&#31163;&#30340;&#20272;&#35745;&#21644;&#25512;&#26029;&#12290;&#34429;&#28982;$i$
&lt;/p&gt;
&lt;p&gt;
The Wasserstein distance between mixing measures has come to occupy a central place in the statistical analysis of mixture models. This work proposes a new canonical interpretation of this distance and provides tools to perform inference on the Wasserstein distance between mixing measures in topic models.  We consider the general setting of an identifiable mixture model consisting of mixtures of distributions from a set $\mathcal{A}$ equipped with an arbitrary metric $d$, and show that the Wasserstein distance between mixing measures is uniquely characterized as the most discriminative convex extension of the metric $d$ to the set of mixtures of elements of $\mathcal{A}$. The Wasserstein distance between mixing measures has been widely used in the study of such models, but without axiomatic justification. Our results establish this metric to be a canonical choice.  Specializing our results to topic models, we consider estimation and inference of this distance. Though upper bounds for i
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#38543;&#26426;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27987;&#24230;&#19981;&#31561;&#24335;&#65292;&#36890;&#36807;&#26399;&#26395;&#20998;&#31867;&#22120;&#32473;&#20986;&#20102;&#20998;&#31867;&#35823;&#24046;&#30340;&#27010;&#29575;&#19978;&#30028;&#65292;&#24182;&#30830;&#23450;&#20102;&#26368;&#20248;&#23618;&#25968;&#12290;</title><link>http://arxiv.org/abs/2206.11241</link><description>&lt;p&gt;
&#38543;&#26426;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27987;&#24230;&#19981;&#31561;&#24335;&#21644;&#26368;&#20248;&#23618;&#25968;
&lt;/p&gt;
&lt;p&gt;
Concentration inequalities and optimal number of layers for stochastic deep neural networks. (arXiv:2206.11241v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.11241
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#38543;&#26426;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27987;&#24230;&#19981;&#31561;&#24335;&#65292;&#36890;&#36807;&#26399;&#26395;&#20998;&#31867;&#22120;&#32473;&#20986;&#20102;&#20998;&#31867;&#35823;&#24046;&#30340;&#27010;&#29575;&#19978;&#30028;&#65292;&#24182;&#30830;&#23450;&#20102;&#26368;&#20248;&#23618;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#38543;&#26426;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;SDNN&#65289;&#38544;&#34255;&#23618;&#36755;&#20986;&#30340;&#27987;&#24230;&#19981;&#31561;&#24335;&#65292;&#20197;&#21450;&#25972;&#20010;SDNN&#36755;&#20986;&#30340;&#27987;&#24230;&#19981;&#31561;&#24335;&#12290;&#36825;&#20123;&#32467;&#26524;&#20351;&#25105;&#20204;&#33021;&#22815;&#24341;&#20837;&#26399;&#26395;&#20998;&#31867;&#22120;&#65288;EC&#65289;&#65292;&#24182;&#32473;&#20986;EC&#20998;&#31867;&#35823;&#24046;&#30340;&#27010;&#29575;&#19978;&#30028;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#26368;&#20248;&#20572;&#27490;&#31574;&#30053;&#30830;&#23450;&#20102;SDNN&#30340;&#26368;&#20339;&#23618;&#25968;&#12290;&#25105;&#20204;&#23558;&#20998;&#26512;&#24212;&#29992;&#20110;&#20855;&#26377;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#30340;&#38543;&#26426;&#29256;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
We state concentration inequalities for the output of the hidden layers of a stochastic deep neural network (SDNN), as well as for the output of the whole SDNN. These results allow us to introduce an expected classifier (EC), and to give probabilistic upper bound for the classification error of the EC. We also state the optimal number of layers for the SDNN via an optimal stopping procedure. We apply our analysis to a stochastic version of a feedforward neural network with ReLU activation function.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#34507;&#30333;&#36136;&#33050;&#25163;&#26550;&#38382;&#39064;&#65292;&#37319;&#29992;E(3)-&#31561;&#21464;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#23398;&#20064;&#22810;&#26679;&#21644;&#38271;&#30340;&#34507;&#30333;&#36136;&#20027;&#24178;&#32467;&#26500;&#30340;&#20998;&#24067;&#65292;&#24182;&#29992;SMCDiff&#31639;&#27861;&#20174;&#20998;&#24067;&#20013;&#26377;&#25928;&#22320;&#37319;&#26679;&#20986;&#31526;&#21512;&#32473;&#23450;&#27169;&#20307;&#26465;&#20214;&#30340;&#33050;&#25163;&#26550;&#65292;&#36825;&#19968;&#31639;&#27861;&#22312;&#22823;&#35745;&#31639;&#26497;&#38480;&#20013;&#21487;&#20197;&#29702;&#35770;&#19978;&#20445;&#35777;&#26465;&#20214;&#26679;&#26412;&#30340;&#37319;&#26679;&#65307;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#29983;&#25104;&#38271;&#36798;80&#20010;&#27531;&#22522;&#30340;&#33050;&#25163;&#26550;&#65292;&#24182;&#21487;&#20197;&#20026;&#22266;&#23450;&#27169;&#20307;&#23454;&#29616;&#32467;&#26500;&#22810;&#26679;&#30340;&#33050;&#25163;&#26550;&#12290;</title><link>http://arxiv.org/abs/2206.04119</link><description>&lt;p&gt;
&#19977;&#32500;&#34507;&#30333;&#36136;&#20027;&#24178;&#30340;&#25193;&#25955;&#27010;&#29575;&#24314;&#27169;&#22312;&#22522;&#20110;&#27169;&#20307;&#33050;&#25163;&#26550;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Diffusion probabilistic modeling of protein backbones in 3D for the motif-scaffolding problem. (arXiv:2206.04119v2 [q-bio.BM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.04119
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#34507;&#30333;&#36136;&#33050;&#25163;&#26550;&#38382;&#39064;&#65292;&#37319;&#29992;E(3)-&#31561;&#21464;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#23398;&#20064;&#22810;&#26679;&#21644;&#38271;&#30340;&#34507;&#30333;&#36136;&#20027;&#24178;&#32467;&#26500;&#30340;&#20998;&#24067;&#65292;&#24182;&#29992;SMCDiff&#31639;&#27861;&#20174;&#20998;&#24067;&#20013;&#26377;&#25928;&#22320;&#37319;&#26679;&#20986;&#31526;&#21512;&#32473;&#23450;&#27169;&#20307;&#26465;&#20214;&#30340;&#33050;&#25163;&#26550;&#65292;&#36825;&#19968;&#31639;&#27861;&#22312;&#22823;&#35745;&#31639;&#26497;&#38480;&#20013;&#21487;&#20197;&#29702;&#35770;&#19978;&#20445;&#35777;&#26465;&#20214;&#26679;&#26412;&#30340;&#37319;&#26679;&#65307;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#29983;&#25104;&#38271;&#36798;80&#20010;&#27531;&#22522;&#30340;&#33050;&#25163;&#26550;&#65292;&#24182;&#21487;&#20197;&#20026;&#22266;&#23450;&#27169;&#20307;&#23454;&#29616;&#32467;&#26500;&#22810;&#26679;&#30340;&#33050;&#25163;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26500;&#24314;&#25903;&#25345;&#25152;&#38656;&#27169;&#20307;&#30340;&#33050;&#25163;&#26550;&#32467;&#26500;&#65292;&#21363;&#36171;&#20104;&#34507;&#30333;&#36136;&#21151;&#33021;&#30340;&#33050;&#25163;&#26550;&#35774;&#35745;&#23545;&#20110;&#30123;&#33495;&#21644;&#37238;&#30340;&#35774;&#35745;&#20855;&#26377;&#28508;&#22312;&#20215;&#20540;&#12290;&#28982;&#32780;&#65292;&#27169;&#20307;&#33050;&#25163;&#26550;&#38382;&#39064;&#30340;&#36890;&#29992;&#35299;&#20915;&#26041;&#26696;&#20173;&#28982;&#27809;&#26377;&#20986;&#29616;&#12290;&#30446;&#21069;&#29992;&#20110;&#33050;&#25163;&#26550;&#35774;&#35745;&#30340;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#21482;&#36866;&#29992;&#20110;&#38271;&#24230;&#19981;&#36229;&#36807;20&#30340;&#19981;&#30495;&#23454;&#33050;&#25163;&#26550;&#25110;&#38590;&#20197;&#29983;&#25104;&#22810;&#20010;&#19981;&#21516;&#26679;&#24335;&#30340;&#33050;&#25163;&#26550;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#21033;&#29992;E(3)-&#31561;&#21464;&#22270;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#22810;&#31181;&#22810;&#26679;&#19988;&#38271;&#24230;&#26356;&#38271;&#30340;&#34507;&#30333;&#36136;&#20027;&#24178;&#32467;&#26500;&#30340;&#20998;&#24067;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;SMCDiff&#20197;&#26377;&#25928;&#22320;&#20174;&#32473;&#23450;&#30340;&#27169;&#20307;&#26465;&#20214;&#19979;&#30340;&#20998;&#24067;&#20013;&#37319;&#26679;&#20986;&#33050;&#25163;&#26550;&#65307;&#25105;&#20204;&#30340;&#31639;&#27861;&#26159;&#31532;&#19968;&#20010;&#29702;&#35770;&#19978;&#20445;&#35777;&#20174;&#22823;&#35745;&#31639;&#26497;&#38480;&#20013;&#25193;&#25955;&#27169;&#22411;&#20013;&#30340;&#26465;&#20214;&#26679;&#26412;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#19982;AlphaFold2&#39044;&#27979;&#32467;&#26500;&#30340;&#23545;&#40784;&#31243;&#24230;&#35780;&#20272;&#25105;&#20204;&#35774;&#35745;&#30340;&#20027;&#24178;&#12290;&#25105;&#20204;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;(1)&#37319;&#26679;&#38271;&#36798;80&#20010;&#27531;&#22522;&#30340;&#33050;&#25163;&#26550;&#65292;&#24182;&#19988;(2)&#20026;&#22266;&#23450;&#27169;&#20307;&#23454;&#29616;&#32467;&#26500;&#22810;&#26679;&#30340;&#33050;&#25163;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Construction of a scaffold structure that supports a desired motif, conferring protein function, shows promise for the design of vaccines and enzymes. But a general solution to this motif-scaffolding problem remains open. Current machine-learning techniques for scaffold design are either limited to unrealistically small scaffolds (up to length 20) or struggle to produce multiple diverse scaffolds. We propose to learn a distribution over diverse and longer protein backbone structures via an E(3)-equivariant graph neural network. We develop SMCDiff to efficiently sample scaffolds from this distribution conditioned on a given motif; our algorithm is the first to theoretically guarantee conditional samples from a diffusion model in the large-compute limit. We evaluate our designed backbones by how well they align with AlphaFold2-predicted structures. We show that our method can (1) sample scaffolds up to 80 residues and (2) achieve structurally diverse scaffolds for a fixed motif.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#32570;&#22833;&#25968;&#25454;&#25554;&#34917;&#26694;&#26550;&#65292;&#21487;&#36866;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#65292;&#33021;&#22815;&#26174;&#33879;&#20248;&#20110;&#22522;&#32447;&#26041;&#27861;&#65292;&#21516;&#26102;&#22312;&#20998;&#31867;&#20219;&#21153;&#20013;&#23454;&#29616;&#21487;&#27604;&#36739;&#25110;&#26356;&#22909;&#30340;&#20998;&#31867;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2205.15150</link><description>&lt;p&gt;
&#22522;&#20110;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#39640;&#25928;&#32570;&#22833;&#25968;&#25454;&#25554;&#34917;&#31639;&#27861;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Principal Component Analysis based frameworks for efficient missing data imputation algorithms. (arXiv:2205.15150v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.15150
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#32570;&#22833;&#25968;&#25454;&#25554;&#34917;&#26694;&#26550;&#65292;&#21487;&#36866;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#65292;&#33021;&#22815;&#26174;&#33879;&#20248;&#20110;&#22522;&#32447;&#26041;&#27861;&#65292;&#21516;&#26102;&#22312;&#20998;&#31867;&#20219;&#21153;&#20013;&#23454;&#29616;&#21487;&#27604;&#36739;&#25110;&#26356;&#22909;&#30340;&#20998;&#31867;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32570;&#22833;&#25968;&#25454;&#26159;&#23454;&#36341;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;&#35768;&#22810;&#22635;&#34917;&#32570;&#22833;&#20540;&#30340;&#26041;&#27861;&#24050;&#32463;&#34987;&#24320;&#21457;&#20986;&#26469;&#12290;&#28982;&#32780;&#65292;&#24182;&#19981;&#26159;&#25152;&#26377;&#30340;&#26041;&#27861;&#37117;&#33021;&#22815;&#36866;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#65292;&#29305;&#21035;&#26159;&#22810;&#37325;&#25554;&#34917;&#25216;&#26415;&#12290;&#21516;&#26102;&#65292;&#22914;&#20170;&#30340;&#25968;&#25454;&#36235;&#21521;&#20110;&#39640;&#32500;&#12290;&#22240;&#27492;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#30340;&#31616;&#21333;&#32780;&#36890;&#29992;&#30340;&#32570;&#22833;&#20540;&#25554;&#34917;&#26694;&#26550;PCA Imputation&#65288;PCAI&#65289;&#65292;&#20197;&#21152;&#24555;&#25554;&#34917;&#36807;&#31243;&#24182;&#20943;&#36731;&#35768;&#22810;&#21487;&#29992;&#25554;&#34917;&#25216;&#26415;&#30340;&#20869;&#23384;&#38382;&#39064;&#65292;&#32780;&#19981;&#20250;&#29306;&#29298;&#22343;&#26041;&#35823;&#24046;&#26041;&#38754;&#30340;&#25554;&#34917;&#36136;&#37327;&#12290;&#27492;&#22806;&#65292;&#21363;&#20351;&#37096;&#20998;&#25110;&#20840;&#37096;&#32570;&#22833;&#29305;&#24449;&#26159;&#20998;&#31867;&#30340;&#65292;&#25110;&#32773;&#32570;&#22833;&#29305;&#24449;&#25968;&#37327;&#36739;&#22823;&#65292;&#35813;&#26694;&#26550;&#20063;&#21487;&#20197;&#20351;&#29992;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#20171;&#32461;PCA Imputation - Classification&#65288;PIC&#65289;&#65292;&#36825;&#26159;&#23545;&#20855;&#26377;&#19968;&#20123;&#35843;&#25972;&#30340;&#20998;&#31867;&#38382;&#39064;PCAI&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#36890;&#36807;&#21508;&#31181;&#24773;&#20917;&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#34920;&#26126;PCA I&#21644;PIC&#21487;&#20197;&#26174;&#33879;&#20248;&#20110;&#22522;&#32447;&#26041;&#27861;&#65292;&#21516;&#26102;&#22312;&#20998;&#31867;&#20219;&#21153;&#20013;&#23454;&#29616;&#21487;&#27604;&#36739;&#25110;&#26356;&#22909;&#30340;&#20998;&#31867;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Missing data is a commonly occurring problem in practice. Many imputation methods have been developed to fill in the missing entries. However, not all of them can scale to high-dimensional data, especially the multiple imputation techniques. Meanwhile, the data nowadays tends toward high-dimensional. Therefore, in this work, we propose Principal Component Analysis Imputation (PCAI), a simple but versatile framework based on Principal Component Analysis (PCA) to speed up the imputation process and alleviate memory issues of many available imputation techniques, without sacrificing the imputation quality in term of MSE. In addition, the frameworks can be used even when some or all of the missing features are categorical, or when the number of missing features is large. Next, we introduce PCA Imputation - Classification (PIC), an application of PCAI for classification problems with some adjustments. We validate our approach by experiments on various scenarios, which shows that PCAI and PI
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#36817;&#20046;&#26368;&#20248;&#32479;&#35745;&#29575;&#30340;&#25308;&#21344;&#24237;&#40065;&#26834;&#32852;&#37030;&#23398;&#20064;&#21327;&#35758;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#19982;&#31454;&#20105;&#21327;&#35758;&#30456;&#27604;&#30340;&#32463;&#39564;&#20248;&#36234;&#24615;&#65292;&#21327;&#35758;&#36890;&#36807;&#20998;&#26742;&#21487;&#20197;&#32467;&#21512;&#38544;&#31169;&#20445;&#38556;&#31243;&#24207;&#20197;&#23545;&#21322;&#35802;&#23454;&#26381;&#21153;&#22120;&#36827;&#34892;&#23433;&#20840;&#20445;&#38556;&#12290;</title><link>http://arxiv.org/abs/2205.11765</link><description>&lt;p&gt;
&#20855;&#26377;&#26368;&#20248;&#32479;&#35745;&#29575;&#21644;&#38544;&#31169;&#20445;&#35777;&#30340;&#25308;&#21344;&#24237;&#40065;&#26834;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Byzantine-Robust Federated Learning with Optimal Statistical Rates and Privacy Guarantees. (arXiv:2205.11765v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.11765
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#36817;&#20046;&#26368;&#20248;&#32479;&#35745;&#29575;&#30340;&#25308;&#21344;&#24237;&#40065;&#26834;&#32852;&#37030;&#23398;&#20064;&#21327;&#35758;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#19982;&#31454;&#20105;&#21327;&#35758;&#30456;&#27604;&#30340;&#32463;&#39564;&#20248;&#36234;&#24615;&#65292;&#21327;&#35758;&#36890;&#36807;&#20998;&#26742;&#21487;&#20197;&#32467;&#21512;&#38544;&#31169;&#20445;&#38556;&#31243;&#24207;&#20197;&#23545;&#21322;&#35802;&#23454;&#26381;&#21153;&#22120;&#36827;&#34892;&#23433;&#20840;&#20445;&#38556;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#36817;&#20046;&#26368;&#20248;&#32479;&#35745;&#29575;&#30340;&#25308;&#21344;&#24237;&#40065;&#26834;&#32852;&#37030;&#23398;&#20064;&#21327;&#35758;&#12290;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;&#30456;&#27604;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#21327;&#35758;&#25552;&#39640;&#20102;&#32500;&#24230;&#20381;&#36182;&#24615;&#65292;&#24182;&#22312;&#24378;&#20984;&#25439;&#22833;&#30340;&#25152;&#26377;&#21442;&#25968;&#26041;&#38754;&#23454;&#29616;&#20102;&#32039;&#23494;&#30340;&#32479;&#35745;&#29575;&#12290;&#25105;&#20204;&#23545;&#31454;&#20105;&#21327;&#35758;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#24182;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#21327;&#35758;&#30340;&#32463;&#39564;&#20248;&#36234;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25351;&#20986;&#65292;&#25105;&#20204;&#30340;&#20998;&#26742;&#21327;&#35758;&#21487;&#20197;&#19982;&#38544;&#31169;&#20445;&#38556;&#31243;&#24207;&#33258;&#28982;&#22320;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#24341;&#20837;&#23545;&#21322;&#35802;&#23454;&#26381;&#21153;&#22120;&#30340;&#23433;&#20840;&#20445;&#38556;&#12290;&#35780;&#20272;&#20195;&#30721;&#20301;&#20110;https://github.com/wanglun1996/secure-robust-federated-learning&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose Byzantine-robust federated learning protocols with nearly optimal statistical rates. In contrast to prior work, our proposed protocols improve the dimension dependence and achieve a tight statistical rate in terms of all the parameters for strongly convex losses. We benchmark against competing protocols and show the empirical superiority of the proposed protocols. Finally, we remark that our protocols with bucketing can be naturally combined with privacy-guaranteeing procedures to introduce security against a semi-honest server. The code for evaluation is provided in https://github.com/wanglun1996/secure-robust-federated-learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#38024;&#23545;&#39640;&#26031;&#20998;&#24067;&#38544;&#31169;&#21327;&#26041;&#24046;&#20272;&#35745;&#21644;&#26377;&#30028;&#21327;&#26041;&#24046;&#20998;&#24067;&#30340;&#22343;&#20540;&#20272;&#35745;&#30340;&#26032;&#19979;&#30028;&#65292;&#36890;&#36807;&#24191;&#20041;&#21270;&#25351;&#32441;&#27861;&#21040;&#25351;&#25968;&#23478;&#26063;&#26469;&#35777;&#26126;&#36825;&#20123;&#19979;&#30028;&#30340;&#27491;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2205.08532</link><description>&lt;p&gt;
&#38544;&#31169;&#20272;&#35745;&#30340;&#26032;&#19979;&#30028;&#21644;&#24191;&#20041;&#25351;&#32441;&#24341;&#29702;
&lt;/p&gt;
&lt;p&gt;
New Lower Bounds for Private Estimation and a Generalized Fingerprinting Lemma. (arXiv:2205.08532v4 [cs.DS] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.08532
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#38024;&#23545;&#39640;&#26031;&#20998;&#24067;&#38544;&#31169;&#21327;&#26041;&#24046;&#20272;&#35745;&#21644;&#26377;&#30028;&#21327;&#26041;&#24046;&#20998;&#24067;&#30340;&#22343;&#20540;&#20272;&#35745;&#30340;&#26032;&#19979;&#30028;&#65292;&#36890;&#36807;&#24191;&#20041;&#21270;&#25351;&#32441;&#27861;&#21040;&#25351;&#25968;&#23478;&#26063;&#26469;&#35777;&#26126;&#36825;&#20123;&#19979;&#30028;&#30340;&#27491;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;$(\varepsilon, \delta)$-&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#19979;&#32479;&#35745;&#20272;&#35745;&#20219;&#21153;&#30340;&#26032;&#30340;&#19979;&#30028;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#39640;&#26031;&#20998;&#24067;&#38544;&#31169;&#21327;&#26041;&#24046;&#20272;&#35745;&#30340;&#20005;&#26684;&#19979;&#30028;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;Frobenius&#33539;&#25968;&#19979;&#20272;&#35745;&#21327;&#26041;&#24046;&#30697;&#38453;&#38656;&#35201;$\Omega(d^2)$&#20010;&#26679;&#26412;&#65292;&#22312;&#35889;&#33539;&#25968;&#19979;&#38656;&#35201;$\Omega(d^{3/2})$&#20010;&#26679;&#26412;&#65292;&#20004;&#32773;&#37117;&#21305;&#37197;&#19978;&#30028;&#65292;&#38500;&#20102;&#23545;&#25968;&#22240;&#23376;&#12290;&#21518;&#19968;&#39033;&#19979;&#30028;&#39564;&#35777;&#20102;&#19968;&#20010;&#20851;&#20110;&#39640;&#26031;&#21327;&#26041;&#24046;&#35889;&#20272;&#35745;&#30340;&#38544;&#31169;&#21644;&#38750;&#38544;&#31169;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#29468;&#24819;&#32479;&#35745;&#24046;&#36317;&#30340;&#23384;&#22312;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#25351;&#32441;&#26041;&#27861;&#24191;&#20041;&#21270;&#21040;&#25351;&#25968;&#23478;&#26063;&#26469;&#35777;&#26126;&#36825;&#20123;&#19979;&#30028;&#26159;&#27491;&#30830;&#30340;&#25216;&#26415;&#36129;&#29486;&#12290;&#27492;&#22806;&#65292;&#20351;&#29992;Acharya&#65292;Sun&#21644;Zhang&#25552;&#20986;&#30340;&#24046;&#20998;&#38544;&#31169;Assouad&#26041;&#27861;&#65292;&#25105;&#20204;&#22312;$\ell_2$-&#36317;&#31163;&#19979;&#34920;&#26126;&#20102;&#22312;&#26377;&#30028;&#21327;&#26041;&#24046;&#20998;&#24067;&#30340;&#22343;&#20540;&#20272;&#35745;&#20013;&#65292;&#21040;$\alpha$&#35823;&#24046;&#30340;&#20005;&#26684;$\Omega(d/(\alpha^2 \varepsilon))$&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We prove new lower bounds for statistical estimation tasks under the constraint of $(\varepsilon, \delta)$-differential privacy. First, we provide tight lower bounds for private covariance estimation of Gaussian distributions. We show that estimating the covariance matrix in Frobenius norm requires $\Omega(d^2)$ samples, and in spectral norm requires $\Omega(d^{3/2})$ samples, both matching upper bounds up to logarithmic factors. The latter bound verifies the existence of a conjectured statistical gap between the private and the non-private sample complexities for spectral estimation of Gaussian covariances. We prove these bounds via our main technical contribution, a broad generalization of the fingerprinting method to exponential families. Additionally, using the private Assouad method of Acharya, Sun, and Zhang, we show a tight $\Omega(d/(\alpha^2 \varepsilon))$ lower bound for estimating the mean of a distribution with bounded covariance to $\alpha$-error in $\ell_2$-distance. Prio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#38134;&#34892;&#21453;&#27927;&#38065;&#30340;&#32479;&#35745;&#21644;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#23458;&#25143;&#39118;&#38505;&#35780;&#20272;&#21644;&#21487;&#30097;&#34892;&#20026;&#26631;&#35782;&#20004;&#20010;&#26680;&#24515;&#35201;&#32032;&#12290;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#21253;&#25324;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#12289;&#21322;&#30417;&#30563;&#21644;&#28145;&#24230;&#23398;&#20064;&#12289;&#21487;&#35299;&#37322;&#24615;&#20197;&#21450;&#32467;&#26524;&#30340;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2201.04207</link><description>&lt;p&gt;
&#29992;&#32479;&#35745;&#21644;&#26426;&#22120;&#23398;&#20064;&#25171;&#20987;&#27927;&#38065;&#65306;&#32508;&#36848;&#19982;&#20171;&#32461;
&lt;/p&gt;
&lt;p&gt;
Fighting Money Laundering with Statistics and Machine Learning: An Introduction and Review. (arXiv:2201.04207v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.04207
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#38134;&#34892;&#21453;&#27927;&#38065;&#30340;&#32479;&#35745;&#21644;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#23458;&#25143;&#39118;&#38505;&#35780;&#20272;&#21644;&#21487;&#30097;&#34892;&#20026;&#26631;&#35782;&#20004;&#20010;&#26680;&#24515;&#35201;&#32032;&#12290;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#21253;&#25324;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#12289;&#21322;&#30417;&#30563;&#21644;&#28145;&#24230;&#23398;&#20064;&#12289;&#21487;&#35299;&#37322;&#24615;&#20197;&#21450;&#32467;&#26524;&#30340;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27927;&#38065;&#26159;&#19968;&#20010;&#20005;&#37325;&#30340;&#20840;&#29699;&#24615;&#38382;&#39064;&#65292;&#20294;&#26159;&#38024;&#23545;&#21453;&#27927;&#38065;&#30340;&#32479;&#35745;&#21644;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#31185;&#23398;&#25991;&#29486;&#21364;&#24456;&#23569;&#12290;&#26412;&#25991;&#30528;&#37325;&#20110;&#38134;&#34892;&#21453;&#27927;&#38065;&#65292;&#24182;&#25552;&#20379;&#20102;&#25991;&#29486;&#32508;&#36848;&#21644;&#20171;&#32461;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26415;&#35821;&#65292;&#20854;&#20013;&#21253;&#25324;&#23458;&#25143;&#39118;&#38505;&#35780;&#20272;&#21644;&#21487;&#30097;&#34892;&#20026;&#26631;&#35782;&#20004;&#20010;&#26680;&#24515;&#35201;&#32032;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23458;&#25143;&#39118;&#38505;&#35780;&#20272;&#26159;&#36890;&#36807;&#35786;&#26029;&#26469;&#23547;&#25214;&#21644;&#35299;&#37322;&#39118;&#38505;&#22240;&#32032;&#65292;&#32780;&#21487;&#30097;&#34892;&#20026;&#26631;&#35782;&#21017;&#26159;&#36890;&#36807;&#26410;&#20844;&#24320;&#30340;&#29305;&#24449;&#21644;&#25163;&#24037;&#39118;&#38505;&#25351;&#25968;&#26469;&#23454;&#29616;&#30340;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#26041;&#21521;&#65292;&#20854;&#20013;&#20027;&#35201;&#25361;&#25112;&#20043;&#19968;&#26159;&#38656;&#35201;&#26356;&#22810;&#30340;&#20844;&#20849;&#25968;&#25454;&#38598;&#65292;&#36825;&#21487;&#33021;&#21487;&#20197;&#36890;&#36807;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#26469;&#35299;&#20915;&#65292;&#20854;&#20182;&#21487;&#33021;&#30340;&#30740;&#31350;&#26041;&#21521;&#21253;&#25324;&#21322;&#30417;&#30563;&#21644;&#28145;&#24230;&#23398;&#20064;&#12289;&#21487;&#35299;&#37322;&#24615;&#20197;&#21450;&#32467;&#26524;&#30340;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Money laundering is a profound global problem. Nonetheless, there is little scientific literature on statistical and machine learning methods for anti-money laundering. In this paper, we focus on anti-money laundering in banks and provide an introduction and review of the literature. We propose a unifying terminology with two central elements: (i) client risk profiling and (ii) suspicious behavior flagging. We find that client risk profiling is characterized by diagnostics, i.e., efforts to find and explain risk factors. On the other hand, suspicious behavior flagging is characterized by non-disclosed features and hand-crafted risk indices. Finally, we discuss directions for future research. One major challenge is the need for more public data sets. This may potentially be addressed by synthetic data generation. Other possible research directions include semi-supervised and deep learning, interpretability, and fairness of the results.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20989;&#25968;&#26041;&#24046;&#30340;Langevin&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#25928;&#35745;&#31639;&#36229;&#21442;&#25968;&#27169;&#22411;&#30340;&#27867;&#21270;&#32570;&#21475;&#65292;&#23454;&#29616;&#19982;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#31639;&#27861;&#19968;&#33268;&#12290;</title><link>http://arxiv.org/abs/2112.03660</link><description>&lt;p&gt;
&#36890;&#36807;Langevin&#20989;&#25968;&#26041;&#24046;&#20272;&#35745;&#36229;&#21442;&#25968;&#27169;&#22411;&#30340;&#27867;&#21270;&#32570;&#21475;
&lt;/p&gt;
&lt;p&gt;
A generalization gap estimation for overparameterized models via the Langevin functional variance. (arXiv:2112.03660v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.03660
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20989;&#25968;&#26041;&#24046;&#30340;Langevin&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#25928;&#35745;&#31639;&#36229;&#21442;&#25968;&#27169;&#22411;&#30340;&#27867;&#21270;&#32570;&#21475;&#65292;&#23454;&#29616;&#19982;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#31639;&#27861;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#27867;&#21270;&#32570;&#21475;&#30340;&#20272;&#35745;&#65292;&#21363;&#27867;&#21270;&#24615;&#33021;&#19982;&#35757;&#32451;&#24615;&#33021;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#38024;&#23545;&#21253;&#25324;&#31070;&#32463;&#32593;&#32476;&#22312;&#20869;&#30340;&#36229;&#21442;&#25968;&#27169;&#22411;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#20989;&#25968;&#26041;&#24046;&#8212;&#8212;&#19968;&#20010;&#23450;&#20041;&#24191;&#27867;&#30340;&#20449;&#24687;&#20934;&#21017;&#20013;&#30340;&#20851;&#38190;&#27010;&#24565;&#8212;&#8212;&#22312;&#36229;&#21442;&#25968;&#27169;&#22411;&#20013;&#20063;&#33021;&#34920;&#24449;&#27867;&#21270;&#32570;&#21475;&#65292;&#21363;&#20351;&#20256;&#32479;&#29702;&#35770;&#26080;&#27861;&#24212;&#29992;&#20110;&#36229;&#21442;&#25968;&#27169;&#22411;&#12290;&#30001;&#20110;&#20989;&#25968;&#26041;&#24046;&#30340;&#35745;&#31639;&#25104;&#26412;&#23545;&#20110;&#36229;&#21442;&#25968;&#27169;&#22411;&#32780;&#35328;&#38750;&#24120;&#26114;&#36149;&#65292;&#22240;&#27492;&#25105;&#20204;&#25552;&#20986;&#20102;&#20989;&#25968;&#26041;&#24046;&#30340;&#39640;&#25928;&#36817;&#20284;&#26041;&#27861;&#8212;&#8212;&#20989;&#25968;&#26041;&#24046;&#30340;Langevin&#20272;&#35745;&#65288;Langevin FV&#65289;&#12290;&#36825;&#31181;&#26041;&#27861;&#21482;&#21033;&#29992;&#20102;&#24179;&#26041;&#25439;&#22833;&#20989;&#25968;&#30340;&#19968;&#38454;&#26799;&#24230;&#65292;&#32780;&#27809;&#26377;&#20351;&#29992;&#20108;&#38454;&#26799;&#24230;&#65292;&#20174;&#32780;&#20445;&#35777;&#20102;&#35745;&#31639;&#30340;&#39640;&#25928;&#24615;&#65292;&#24182;&#19988;&#23454;&#29616;&#19982;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#31639;&#27861;&#26159;&#19968;&#33268;&#30340;&#12290;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#28436;&#31034;&#20102;Langevin FV&#65292;&#20272;&#35745;&#20102;&#36229;&#21442;&#25968;&#27169;&#22411;&#30340;&#27867;&#21270;&#32570;&#21475;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper discusses the estimation of the generalization gap, the difference between generalization performance and training performance, for overparameterized models including neural networks. We first show that a functional variance, a key concept in defining a widely-applicable information criterion, characterizes the generalization gap even in overparameterized settings where a conventional theory cannot be applied. As the computational cost of the functional variance is expensive for the overparameterized models, we propose an efficient approximation of the function variance, the Langevin approximation of the functional variance (Langevin FV). This method leverages only the $1$st-order gradient of the squared loss function, without referencing the $2$nd-order gradient; this ensures that the computation is efficient and the implementation is consistent with gradient-based optimization algorithms. We demonstrate the Langevin FV numerically by estimating the generalization gaps of o
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#8220;&#30693;&#35782;&#33457;&#25197;&#8221;&#26041;&#27861;&#26469;&#25551;&#36848;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#27169;&#22411;&#65292;&#24182;&#21487;&#20197;&#34920;&#36798;&#24191;&#27867;&#30340;&#23884;&#20837;&#20808;&#39564;&#32422;&#26463;&#65292;&#21487;&#36731;&#26494;&#24212;&#23545;&#22797;&#21512;&#20851;&#31995;&#25512;&#29702;&#12290;</title><link>http://arxiv.org/abs/2110.03789</link><description>&lt;p&gt;
&#30693;&#35782;&#33457;&#26463;&#65306;&#36866;&#29992;&#20110;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#30340;&#33457;&#25197;&#29702;&#35770;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Knowledge Sheaves: A Sheaf-Theoretic Framework for Knowledge Graph Embedding. (arXiv:2110.03789v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.03789
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#8220;&#30693;&#35782;&#33457;&#25197;&#8221;&#26041;&#27861;&#26469;&#25551;&#36848;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#27169;&#22411;&#65292;&#24182;&#21487;&#20197;&#34920;&#36798;&#24191;&#27867;&#30340;&#23884;&#20837;&#20808;&#39564;&#32422;&#26463;&#65292;&#21487;&#36731;&#26494;&#24212;&#23545;&#22797;&#21512;&#20851;&#31995;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#25351;&#23398;&#20064;&#23454;&#20307;&#65288;&#22270;&#30340;&#39030;&#28857;&#65289;&#21644;&#20851;&#31995;&#65288;&#22270;&#30340;&#36793;&#65289;&#30340;&#34920;&#31034;&#65292;&#20197;&#20351;&#24471;&#29983;&#25104;&#30340;&#34920;&#31034;&#32534;&#30721;&#30693;&#35782;&#22270;&#35889;&#20013;&#24050;&#30693;&#30340;&#20107;&#23454;&#20449;&#24687;&#65292;&#24182;&#21487;&#20197;&#29992;&#20110;&#25512;&#29702;&#26032;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#33258;&#28982;&#22320;&#34920;&#36798;&#20026;&#8220;&#32454;&#32990;&#33457;&#25197;&#8221;&#30340;&#25299;&#25169;&#21644;&#33539;&#30068;&#35821;&#35328;&#65306;&#19968;&#20010;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#21487;&#20197;&#25551;&#36848;&#20026;&#36866;&#24403;&#30340;&#8220;&#30693;&#35782;&#33457;&#25197;&#8221;&#22312;&#22270;&#19978;&#30340;&#36817;&#20284;&#20840;&#23616;&#25130;&#38754;&#65292;&#20854;&#19968;&#33268;&#24615;&#32422;&#26463;&#26159;&#30001;&#30693;&#35782;&#22270;&#35889;&#30340;&#26550;&#26500;&#24341;&#36215;&#30340;&#12290;&#36825;&#31181;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#20010;&#24191;&#20041;&#30340;&#26694;&#26550;&#26469;&#25512;&#29702;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#27169;&#22411;&#65292;&#24182;&#20801;&#35768;&#34920;&#36798;&#24191;&#27867;&#30340;&#23884;&#20837;&#20808;&#39564;&#32422;&#26463;&#12290;&#27492;&#22806;&#65292;&#29983;&#25104;&#30340;&#23884;&#20837;&#21487;&#20197;&#36731;&#26494;&#22320;&#36866;&#24212;&#20110;&#22797;&#21512;&#20851;&#31995;&#30340;&#25512;&#29702;&#65292;&#26080;&#38656;&#29305;&#27530;&#30340;&#35757;&#32451;&#12290;&#25105;&#20204;&#23454;&#29616;&#20102;&#36825;&#20123;&#24819;&#27861;&#65292;&#20197;&#23637;&#31034;&#36825;&#31181;&#26041;&#27861;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge graph embedding involves learning representations of entities -the vertices of the graph -- and relations -- the edges of the graph -- such that the resulting representations encode the known factual information represented by the knowledge graph and can be used in the inference of new relations. We show that knowledge graph embedding is naturally expressed in the topological and categorical language of \textit{cellular sheaves}: a knowledge graph embedding can be described as an approximate global section of an appropriate \textit{knowledge sheaf} over the graph, with consistency constraints induced by the knowledge graph's schema. This approach provides a generalized framework for reasoning about knowledge graph embedding models and allows for the expression of a wide range of prior constraints on embeddings. Further, the resulting embeddings can be easily adapted for reasoning over composite relations without special training. We implement these ideas to highlight the be
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Spacetimeformer&#30340;&#26041;&#27861;&#65292;&#23558;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#36716;&#21270;&#20026;&#8220;&#26102;&#31354;&#24207;&#21015;&#8221;&#24418;&#24335;&#36827;&#34892;&#24314;&#27169;&#65292;&#23454;&#29616;&#20102;&#23545;&#21464;&#37327;&#20043;&#38388;&#21160;&#24577;&#31354;&#38388;&#20851;&#31995;&#30340;&#23398;&#20064;&#65292;&#21516;&#26102;&#22312;&#22810;&#20010;&#22522;&#20934;&#27979;&#35797;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2109.12218</link><description>&lt;p&gt;
&#38754;&#21521;&#21160;&#24577;&#26102;&#31354;&#39044;&#27979;&#30340;&#38271;&#36317;&#31163;Transformer
&lt;/p&gt;
&lt;p&gt;
Long-Range Transformers for Dynamic Spatiotemporal Forecasting. (arXiv:2109.12218v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.12218
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Spacetimeformer&#30340;&#26041;&#27861;&#65292;&#23558;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#36716;&#21270;&#20026;&#8220;&#26102;&#31354;&#24207;&#21015;&#8221;&#24418;&#24335;&#36827;&#34892;&#24314;&#27169;&#65292;&#23454;&#29616;&#20102;&#23545;&#21464;&#37327;&#20043;&#38388;&#21160;&#24577;&#31354;&#38388;&#20851;&#31995;&#30340;&#23398;&#20064;&#65292;&#21516;&#26102;&#22312;&#22810;&#20010;&#22522;&#20934;&#27979;&#35797;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#33268;&#21147;&#20110;&#22522;&#20110;&#21382;&#21490;&#24773;&#22659;&#39044;&#27979;&#26410;&#26469;&#20540;&#12290;&#29616;&#26377;&#24207;&#21015;&#21040;&#24207;&#21015;&#27169;&#22411;&#21033;&#29992;&#31070;&#32463;&#20851;&#27880;&#26426;&#21046;&#36827;&#34892;&#26102;&#38388;&#23398;&#20064;&#65292;&#20294;&#26410;&#32771;&#34385;&#21464;&#37327;&#38388;&#30340;&#31354;&#38388;&#20851;&#31995;&#12290;&#30456;&#27604;&#32780;&#35328;&#65292;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#26126;&#30830;&#24314;&#27169;&#21464;&#37327;&#20851;&#31995;&#65292;&#20294;&#24448;&#24448;&#20381;&#36182;&#20110;&#39044;&#23450;&#20041;&#22270;&#65292;&#19981;&#33021;&#38543;&#26102;&#38388;&#21464;&#21270;&#19988;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#20013;&#23545;&#21508;&#21464;&#37327;&#36827;&#34892;&#29420;&#31435;&#30340;&#31354;&#38388;&#21644;&#26102;&#38388;&#26356;&#26032;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#36890;&#36807;&#23558;&#22810;&#20803;&#39044;&#27979;&#36716;&#21270;&#20026;&#8220;&#26102;&#31354;&#24207;&#21015;&#8221;&#24418;&#24335;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20854;&#20013;&#27599;&#20010;Transformer&#36755;&#20837;&#34920;&#31034;&#32473;&#23450;&#26102;&#38388;&#21333;&#20010;&#21464;&#37327;&#30340;&#20540;&#12290;&#38271;&#36317;&#31163;Transformer&#21487;&#20197;&#27839;&#30528;&#36825;&#20010;&#25193;&#23637;&#24207;&#21015;&#20849;&#21516;&#23398;&#20064;&#31354;&#38388;&#12289;&#26102;&#38388;&#21644;&#20540;&#20449;&#24687;&#20043;&#38388;&#30340;&#20132;&#20114;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#31216;&#20026;Spacetimeformer&#65292;&#22312;&#22810;&#20010;&#22810;&#20803;&#39044;&#27979;&#22522;&#20934;&#27979;&#35797;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#24182;&#21487;&#20197;&#21160;&#24577;&#26356;&#26032;&#21464;&#37327;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multivariate time series forecasting focuses on predicting future values based on historical context. State-of-the-art sequence-to-sequence models rely on neural attention between timesteps, which allows for temporal learning but fails to consider distinct spatial relationships between variables. In contrast, methods based on graph neural networks explicitly model variable relationships. However, these methods often rely on predefined graphs that cannot change over time and perform separate spatial and temporal updates without establishing direct connections between each variable at every timestep. Our work addresses these problems by translating multivariate forecasting into a "spatiotemporal sequence" formulation where each Transformer input token represents the value of a single variable at a given time. Long-Range Transformers can then learn interactions between space, time, and value information jointly along this extended sequence. Our method, which we call Spacetimeformer, achie
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#32039;&#23494;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20998;&#26512;&#22238;&#31572;&#20102;Q&#23398;&#20064;&#26159;&#21542;&#26159;&#26497;&#23567;&#26497;&#22823;&#26368;&#20248;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2102.06548</link><description>&lt;p&gt;
Q&#23398;&#20064;&#26159;&#21542;&#26159;&#26497;&#23567;&#26497;&#22823;&#26368;&#20248;&#30340;&#65311;&#19968;&#39033;&#32039;&#23494;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Is Q-Learning Minimax Optimal? A Tight Sample Complexity Analysis. (arXiv:2102.06548v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.06548
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#32039;&#23494;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20998;&#26512;&#22238;&#31572;&#20102;Q&#23398;&#20064;&#26159;&#21542;&#26159;&#26497;&#23567;&#26497;&#22823;&#26368;&#20248;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Q&#23398;&#20064;&#26159;&#24378;&#21270;&#23398;&#20064;&#30340;&#26680;&#24515;&#65292;&#26088;&#22312;&#20197;&#27169;&#22411;&#33258;&#30001;&#30340;&#26041;&#24335;&#23398;&#20064;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#26368;&#20248;Q&#20989;&#25968;&#12290;&#38024;&#23545;&#21516;&#27493;&#35774;&#32622;&#65288;&#21363;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#20174;&#29983;&#25104;&#27169;&#22411;&#20013;&#29420;&#31435;&#22320;&#25277;&#21462;&#25152;&#26377;&#29366;&#24577;-&#21160;&#20316;&#23545;&#30340;&#26679;&#26412;&#65289;&#65292;&#22312;&#29702;&#35299;Q&#23398;&#20064;&#30340;&#26679;&#26412;&#25928;&#29575;&#26041;&#38754;&#24050;&#32463;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#12290;&#23545;&#20110;&#19968;&#20010;&#20855;&#26377;&#29366;&#24577;&#31354;&#38388;&#931;&#21644;&#21160;&#20316;&#31354;&#38388;&#913;&#30340;&#947;&#25240;&#25187;&#30340;&#26080;&#38480;&#26102;&#38388;&#38454;&#27573;MDP&#65292;&#20026;&#20102;&#20135;&#29983;&#26368;&#20248;Q&#20989;&#25968;&#30340;&#20803;&#32032;&#32423;&#949;&#36817;&#20284;&#65292;&#38024;&#23545;Q&#23398;&#20064;&#30340;&#26368;&#26032;&#29702;&#35770;&#38656;&#35201;&#19968;&#20010;&#26679;&#26412;&#22823;&#23567;&#36229;&#36807;&#931;&#8739;&#8739;&#215;&#913;&#8739;&#8739;&#8725;(1&#8722;&#947;)^5&#949;^{2}&#30340;&#37327;&#32423;&#65292;&#20294;&#36825;&#24182;&#19981;&#31526;&#21512;&#29616;&#26377;&#30340;&#26497;&#23567;&#26497;&#22823;&#19979;&#30028;&#12290;&#36825;&#24341;&#20986;&#20102;&#19968;&#20010;&#33258;&#28982;&#30340;&#38382;&#39064;&#65306;Q&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#26159;&#22810;&#23569;&#65311;Q&#23398;&#20064;&#26159;&#21542;&#21487;&#35777;&#26126;&#26159;&#27425;&#20248;&#30340;&#65311;&#26412;&#25991;&#38024;&#23545;&#21516;&#27493;&#35774;&#32622;&#22238;&#31572;&#20102;&#36825;&#20123;&#38382;&#39064;&#65306;(1)
&lt;/p&gt;
&lt;p&gt;
Q-learning, which seeks to learn the optimal Q-function of a Markov decision process (MDP) in a model-free fashion, lies at the heart of reinforcement learning. When it comes to the synchronous setting (such that independent samples for all state-action pairs are drawn from a generative model in each iteration), substantial progress has been made towards understanding the sample efficiency of Q-learning. Consider a $\gamma$-discounted infinite-horizon MDP with state space $\mathcal{S}$ and action space $\mathcal{A}$: to yield an entrywise $\varepsilon$-approximation of the optimal Q-function, state-of-the-art theory for Q-learning requires a sample size exceeding the order of $\frac{|\mathcal{S}||\mathcal{A}|}{(1-\gamma)^5\varepsilon^{2}}$, which fails to match existing minimax lower bounds. This gives rise to natural questions: what is the sharp sample complexity of Q-learning? Is Q-learning provably sub-optimal? This paper addresses these questions for the synchronous setting: (1) wh
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#31350;&#20102;&#39640;&#32500;&#21322;&#30417;&#30563;&#23398;&#20064;&#30340;&#20272;&#35745;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#26368;&#20248;&#21644;&#23433;&#20840;&#30340;&#21322;&#30417;&#30563;&#20272;&#35745;&#22120;&#12290;&#26368;&#20248;&#20272;&#35745;&#22120;&#21487;&#20197;&#23454;&#29616;&#26497;&#23567;&#26497;&#22823;&#19979;&#30028;&#65292;&#25913;&#36827;&#30417;&#30563;&#20272;&#35745;&#22120;&#12290;&#23433;&#20840;&#20272;&#35745;&#22120;&#33267;&#23569;&#21644;&#30417;&#30563;&#20272;&#35745;&#22120;&#19968;&#26679;&#22909;&#65292;&#19988;&#20004;&#32773;&#32858;&#21512;&#21487;&#20197;&#26356;&#22909;&#22320;&#35299;&#20915;&#35823;&#24046;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2011.14185</link><description>&lt;p&gt;
&#39640;&#32500;&#21322;&#30417;&#30563;&#23398;&#20064;&#30340;&#26368;&#20248;&#19982;&#23433;&#20840;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Optimal and Safe Estimation for High-Dimensional Semi-Supervised Learning. (arXiv:2011.14185v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2011.14185
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#31350;&#20102;&#39640;&#32500;&#21322;&#30417;&#30563;&#23398;&#20064;&#30340;&#20272;&#35745;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#26368;&#20248;&#21644;&#23433;&#20840;&#30340;&#21322;&#30417;&#30563;&#20272;&#35745;&#22120;&#12290;&#26368;&#20248;&#20272;&#35745;&#22120;&#21487;&#20197;&#23454;&#29616;&#26497;&#23567;&#26497;&#22823;&#19979;&#30028;&#65292;&#25913;&#36827;&#30417;&#30563;&#20272;&#35745;&#22120;&#12290;&#23433;&#20840;&#20272;&#35745;&#22120;&#33267;&#23569;&#21644;&#30417;&#30563;&#20272;&#35745;&#22120;&#19968;&#26679;&#22909;&#65292;&#19988;&#20004;&#32773;&#32858;&#21512;&#21487;&#20197;&#26356;&#22909;&#22320;&#35299;&#20915;&#35823;&#24046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#32771;&#34385;&#39640;&#32500;&#21322;&#30417;&#30563;&#23398;&#20064;&#30340;&#20272;&#35745;&#38382;&#39064;&#65292;&#26088;&#22312;&#25506;&#31350;&#26080;&#26631;&#31614;&#25968;&#25454;&#22914;&#20309;&#25552;&#39640;&#32447;&#24615;&#27169;&#22411;&#22238;&#24402;&#21442;&#25968;&#30340;&#20272;&#35745;&#20934;&#30830;&#24615;&#65292;&#22240;&#20026;&#36825;&#26679;&#30340;&#32447;&#24615;&#27169;&#22411;&#21487;&#33021;&#22312;&#25968;&#25454;&#20998;&#26512;&#20013;&#34987;&#38169;&#35823;&#22320;&#35268;&#23450;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#21322;&#30417;&#30563;&#35774;&#32622;&#19979;&#21442;&#25968;&#20272;&#35745;&#30340;&#26497;&#23567;&#26497;&#22823;&#19979;&#30028;&#65292;&#24182;&#35777;&#26126;&#20102;&#20165;&#20351;&#29992;&#26377;&#26631;&#31614;&#25968;&#25454;&#30340;&#30417;&#30563;&#20272;&#35745;&#22120;&#26080;&#27861;&#23454;&#29616;&#27492;&#19979;&#30028;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#20248;&#21322;&#30417;&#30563;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#23454;&#29616;&#27492;&#19979;&#30028;&#65292;&#22240;&#27492;&#21487;&#20197;&#25913;&#36827;&#30417;&#30563;&#20272;&#35745;&#22120;&#65292;&#21069;&#25552;&#26159;&#26465;&#20214;&#22343;&#20540;&#20989;&#25968;&#21487;&#20197;&#20197;&#36866;&#24403;&#30340;&#36895;&#29575;&#19968;&#33268;&#22320;&#20272;&#35745;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#31181;&#23433;&#20840;&#30340;&#21322;&#30417;&#30563;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#35748;&#20026;&#23427;&#26159;&#23433;&#20840;&#30340;&#65292;&#22240;&#20026;&#36825;&#20010;&#20272;&#35745;&#22120;&#24635;&#26159;&#33267;&#23569;&#21644;&#30417;&#30563;&#20272;&#35745;&#22120;&#19968;&#26679;&#22909;&#12290;&#25105;&#20204;&#36824;&#23558;&#25105;&#20204;&#30340;&#24819;&#27861;&#25193;&#23637;&#21040;&#22810;&#20010;&#30001;&#19981;&#21516;&#35823;&#24046;&#24341;&#36215;&#30340;&#21322;&#30417;&#30563;&#20272;&#35745;&#22120;&#30340;&#32858;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the estimation problem in high-dimensional semi-supervised learning. Our goal is to investigate when and how the unlabeled data can be exploited to improve the estimation of the regression parameters of linear model in light of the fact that such linear models may be misspecified in data analysis. We first establish the minimax lower bound for parameter estimation in the semi-supervised setting, and show that this lower bound cannot be achieved by supervised estimators using the labeled data only. We propose an optimal semi-supervised estimator that can attain this lower bound and therefore improves the supervised estimators, provided that the conditional mean function can be consistently estimated with a proper rate. We further propose a safe semi-supervised estimator. We view it safe, because this estimator is always at least as good as the supervised estimators. We also extend our idea to the aggregation of multiple semi-supervised estimators caused by different misspeci
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#31574;&#30053;&#26469;&#33719;&#24471;&#20219;&#20309;&#20559;&#24046;&#23567;&#20110;&#39044;&#23450;&#30028;&#38480;&#30340;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#19979;&#38480;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#19968;&#20123;&#20851;&#20110;&#26041;&#24046;&#30340;&#25277;&#35937;&#19979;&#38480;&#65292;&#28041;&#21450;&#21040;&#23545;&#19981;&#21516;&#27010;&#29575;&#27979;&#24230;&#30340;&#26399;&#26395;&#20540;&#30340;&#21464;&#21270;&#20197;&#21450;&#20449;&#24687;&#24230;&#37327;&#65292;&#22914;KL&#25110;$\chi^2$&#20998;&#27495;&#12290;&#22312;&#20960;&#20010;&#32479;&#35745;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2006.00278</link><description>&lt;p&gt;
&#35770;&#20559;&#24046;-&#26041;&#24046;&#22343;&#34913;&#30340;&#19979;&#38480;
&lt;/p&gt;
&lt;p&gt;
On lower bounds for the bias-variance trade-off. (arXiv:2006.00278v4 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.00278
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#31574;&#30053;&#26469;&#33719;&#24471;&#20219;&#20309;&#20559;&#24046;&#23567;&#20110;&#39044;&#23450;&#30028;&#38480;&#30340;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#19979;&#38480;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#19968;&#20123;&#20851;&#20110;&#26041;&#24046;&#30340;&#25277;&#35937;&#19979;&#38480;&#65292;&#28041;&#21450;&#21040;&#23545;&#19981;&#21516;&#27010;&#29575;&#27979;&#24230;&#30340;&#26399;&#26395;&#20540;&#30340;&#21464;&#21270;&#20197;&#21450;&#20449;&#24687;&#24230;&#37327;&#65292;&#22914;KL&#25110;$\chi^2$&#20998;&#27495;&#12290;&#22312;&#20960;&#20010;&#32479;&#35745;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#39640;&#32500;&#21644;&#38750;&#21442;&#25968;&#32479;&#35745;&#27169;&#22411;&#65292;&#36895;&#29575;&#26368;&#20248;&#20272;&#35745;&#22120;&#36890;&#24120;&#24179;&#34913;&#24179;&#26041;&#20559;&#24046;&#21644;&#26041;&#24046;&#12290;&#34429;&#28982;&#36825;&#31181;&#24179;&#34913;&#24191;&#27867;&#23384;&#22312;&#65292;&#20294;&#24456;&#23569;&#26377;&#20154;&#30693;&#36947;&#26159;&#21542;&#23384;&#22312;&#21487;&#20197;&#36991;&#20813;&#20559;&#24046;&#21644;&#26041;&#24046;&#20043;&#38388;&#30340;&#26435;&#34913;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#31574;&#30053;&#65292;&#20197;&#33719;&#24471;&#20219;&#20309;&#20559;&#24046;&#23567;&#20110;&#39044;&#23450;&#30028;&#38480;&#30340;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#19979;&#38480;&#12290;&#36825;&#34920;&#26126;&#20102;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#19981;&#21487;&#36991;&#20813;&#30340;&#31243;&#24230;&#65292;&#24182;&#20801;&#35768;&#37327;&#21270;&#19981;&#36981;&#23432;&#35813;&#26435;&#34913;&#30340;&#26041;&#27861;&#30340;&#24615;&#33021;&#25439;&#22833;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#19968;&#20123;&#20851;&#20110;&#26041;&#24046;&#30340;&#25277;&#35937;&#19979;&#38480;&#65292;&#28041;&#21450;&#21040;&#23545;&#19981;&#21516;&#27010;&#29575;&#27979;&#24230;&#30340;&#26399;&#26395;&#20540;&#30340;&#21464;&#21270;&#20197;&#21450;&#20449;&#24687;&#24230;&#37327;&#65292;&#22914;Kullback-Leibler&#25110;$\chi^2$-&#20998;&#27495;&#12290;&#22312;&#25991;&#31456;&#30340;&#31532;&#20108;&#37096;&#20998;&#20013;&#65292;&#23558;&#36825;&#20123;&#25277;&#35937;&#19979;&#38480;&#24212;&#29992;&#20110;&#20960;&#20010;&#32479;&#35745;&#27169;&#22411;&#65292;&#21253;&#25324;&#39640;&#26031;&#30333;&#22122;&#22768;&#27169;&#22411;&#65292;&#36793;&#30028;&#20272;&#35745;&#38382;&#39064;&#65292;&#39640;&#26031;&#31616;&#21333;&#21327;&#26041;&#24046;&#21644;&#22343;&#20540;&#30697;&#38453;&#20272;&#35745;&#31561;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is a common phenomenon that for high-dimensional and nonparametric statistical models, rate-optimal estimators balance squared bias and variance. Although this balancing is widely observed, little is known whether methods exist that could avoid the trade-off between bias and variance. We propose a general strategy to obtain lower bounds on the variance of any estimator with bias smaller than a prespecified bound. This shows to which extent the bias-variance trade-off is unavoidable and allows to quantify the loss of performance for methods that do not obey it. The approach is based on a number of abstract lower bounds for the variance involving the change of expectation with respect to different probability measures as well as information measures such as the Kullback-Leibler or $\chi^2$-divergence. In a second part of the article, the abstract lower bounds are applied to several statistical models including the Gaussian white noise model, a boundary estimation problem, the Gaussian
&lt;/p&gt;</description></item></channel></rss>