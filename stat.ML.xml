<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#20174;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#38750;&#21487;&#20998;&#35299;&#24615;&#33021;&#24230;&#37327;&#30340;&#22810;&#31867;&#23398;&#20064;&#31639;&#27861;&#12290;&#36825;&#20123;&#31639;&#27861;&#20998;&#21035;&#36866;&#29992;&#20110;&#21333;&#35843;&#20984;&#24615;&#21644;&#32447;&#24615;&#27604;&#29575;&#20004;&#31867;&#24615;&#33021;&#24230;&#37327;&#65292;&#24182;&#22522;&#20110;&#31867;&#26465;&#20214;&#22122;&#22768;&#27169;&#22411;&#36827;&#34892;&#22122;&#22768;&#26657;&#27491;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01055</link><description>&lt;p&gt;
&#20174;&#26377;&#22122;&#22768;&#26631;&#31614;&#23398;&#20064;&#38750;&#21487;&#20998;&#35299;&#24615;&#33021;&#24230;&#37327;&#30340;&#22810;&#31867;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Multiclass Learning from Noisy Labels for Non-decomposable Performance Measures
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01055
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#20174;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#38750;&#21487;&#20998;&#35299;&#24615;&#33021;&#24230;&#37327;&#30340;&#22810;&#31867;&#23398;&#20064;&#31639;&#27861;&#12290;&#36825;&#20123;&#31639;&#27861;&#20998;&#21035;&#36866;&#29992;&#20110;&#21333;&#35843;&#20984;&#24615;&#21644;&#32447;&#24615;&#27604;&#29575;&#20004;&#31867;&#24615;&#33021;&#24230;&#37327;&#65292;&#24182;&#22522;&#20110;&#31867;&#26465;&#20214;&#22122;&#22768;&#27169;&#22411;&#36827;&#34892;&#22122;&#22768;&#26657;&#27491;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#23398;&#20064;&#20174;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#25968;&#25454;&#20013;&#24471;&#21040;&#33391;&#22909;&#20998;&#31867;&#22120;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#22823;&#22810;&#25968;&#20851;&#20110;&#20174;&#26377;&#22122;&#22768;&#26631;&#31614;&#23398;&#20064;&#30340;&#24037;&#20316;&#37117;&#38598;&#20013;&#22312;&#26631;&#20934;&#30340;&#22522;&#20110;&#25439;&#22833;&#30340;&#24615;&#33021;&#24230;&#37327;&#19978;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#38656;&#35201;&#20351;&#29992;&#38750;&#21487;&#20998;&#35299;&#24615;&#33021;&#24230;&#37327;&#65292;&#36825;&#20123;&#24230;&#37327;&#19981;&#33021;&#34920;&#31034;&#20026;&#21333;&#20010;&#31034;&#20363;&#19978;&#30340;&#25439;&#22833;&#30340;&#26399;&#26395;&#25110;&#24635;&#21644;&#65307;&#20854;&#20013;&#21253;&#25324;&#31867;&#19981;&#24179;&#34913;&#35774;&#32622;&#20013;&#30340;H-mean&#65292;Q-mean&#21644;G-mean&#65292;&#20197;&#21450;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;Micro F1&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#31639;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#20004;&#31867;&#24191;&#27867;&#30340;&#22810;&#31867;&#38750;&#21487;&#20998;&#35299;&#24615;&#33021;&#24230;&#37327;&#65292;&#21363;&#21333;&#35843;&#20984;&#24615;&#21644;&#32447;&#24615;&#27604;&#29575;&#65292;&#23427;&#20204;&#21253;&#25324;&#19978;&#36848;&#25152;&#26377;&#31034;&#20363;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#22522;&#20110;Narasimhan&#31561;&#20154;&#30340;Frank-Wolfe&#21644;Bisection&#31639;&#27861;(2015)&#12290;&#22312;&#36825;&#20004;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#22312;&#24191;&#27867;&#30740;&#31350;&#30340;&#31867;&#26465;&#20214;&#22122;&#22768;&#27169;&#22411;&#23478;&#26063;&#19979;&#24320;&#21457;&#20102;&#31639;&#27861;&#30340;&#22122;&#22768;&#26657;&#27491;&#29256;&#26412;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#36951;&#25022;(&#36229;&#39069;&#39118;&#38505;)&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
There has been much interest in recent years in learning good classifiers from data with noisy labels. Most work on learning from noisy labels has focused on standard loss-based performance measures. However, many machine learning problems require using non-decomposable performance measures which cannot be expressed as the expectation or sum of a loss on individual examples; these include for example the H-mean, Q-mean and G-mean in class imbalance settings, and the Micro $F_1$ in information retrieval. In this paper, we design algorithms to learn from noisy labels for two broad classes of multiclass non-decomposable performance measures, namely, monotonic convex and ratio-of-linear, which encompass all the above examples. Our work builds on the Frank-Wolfe and Bisection based methods of Narasimhan et al. (2015). In both cases, we develop noise-corrected versions of the algorithms under the widely studied family of class-conditional noise models. We provide regret (excess risk) bounds 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#23545;&#40784;&#38160;&#24230;&#25216;&#26415;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#21333;&#25351;&#25968;&#27169;&#22411;&#30340;&#24120;&#25968;&#36817;&#20284;&#23398;&#20064;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#20998;&#24067;&#21644;&#36830;&#25509;&#20989;&#25968;&#65292;&#26159;&#39318;&#20010;&#36866;&#29992;&#20110;&#39640;&#26031;&#25968;&#25454;&#21644;&#20219;&#20309;&#38750;&#24179;&#20961;&#36830;&#25509;&#20989;&#25968;&#31867;&#30340;&#31283;&#20581;&#23398;&#20064;&#22120;&#12290;</title><link>https://arxiv.org/abs/2402.17756</link><description>&lt;p&gt;
&#36890;&#36807;&#23545;&#40784;&#38160;&#24230;&#31283;&#20581;&#23398;&#20064;&#21333;&#25351;&#25968;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Robustly Learning Single-Index Models via Alignment Sharpness
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17756
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#23545;&#40784;&#38160;&#24230;&#25216;&#26415;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#21333;&#25351;&#25968;&#27169;&#22411;&#30340;&#24120;&#25968;&#36817;&#20284;&#23398;&#20064;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#20998;&#24067;&#21644;&#36830;&#25509;&#20989;&#25968;&#65292;&#26159;&#39318;&#20010;&#36866;&#29992;&#20110;&#39640;&#26031;&#25968;&#25454;&#21644;&#20219;&#20309;&#38750;&#24179;&#20961;&#36830;&#25509;&#20989;&#25968;&#31867;&#30340;&#31283;&#20581;&#23398;&#20064;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#23545;&#40784;&#27169;&#22411;&#19979;&#20197;$L_2^2$&#25439;&#22833;&#23398;&#20064;&#21333;&#25351;&#25968;&#27169;&#22411;&#30340;&#38382;&#39064;&#12290;&#22312;&#23545;&#40784;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#26368;&#20248;&#25439;&#22833;&#30340;&#24120;&#25968;&#36817;&#20284;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#19968;&#31995;&#21015;&#20998;&#24067;&#65288;&#21253;&#25324;&#23545;&#25968;&#20985;&#20998;&#24067;&#65289;&#21644;&#24191;&#27867;&#30340;&#21333;&#35843;&#21644;Lipschitz&#36830;&#25509;&#20989;&#25968;&#30340;&#31867;&#12290;&#36825;&#26159;&#39318;&#20010;&#39640;&#25928;&#30340;&#24120;&#25968;&#36817;&#20284;&#23545;&#40784;&#23398;&#20064;&#22120;&#65292;&#21363;&#20351;&#23545;&#20110;&#39640;&#26031;&#25968;&#25454;&#21644;&#20219;&#20309;&#38750;&#24179;&#20961;&#30340;&#36830;&#25509;&#20989;&#25968;&#31867;&#12290;&#20197;&#21069;&#38024;&#23545;&#26410;&#30693;&#36830;&#25509;&#20989;&#25968;&#24773;&#20917;&#30340;&#24037;&#20316;&#35201;&#20040;&#36866;&#29992;&#20110;&#21487;&#23454;&#29616;&#35774;&#32622;&#65292;&#35201;&#20040;&#26080;&#27861;&#36798;&#21040;&#24120;&#25968;&#36817;&#20284;&#12290;&#20351;&#25105;&#20204;&#30340;&#31639;&#27861;&#21644;&#20998;&#26512;&#25104;&#20026;&#21487;&#33021;&#30340;&#20027;&#35201;&#25216;&#26415;&#35201;&#32032;&#26159;&#25105;&#20204;&#31216;&#20043;&#20026;&#23545;&#40784;&#38160;&#24230;&#30340;&#26032;&#39062;&#20248;&#21270;&#23616;&#37096;&#35823;&#24046;&#30028;&#30340;&#27010;&#24565;&#65292;&#36825;&#21487;&#33021;&#20855;&#26377;&#26356;&#24191;&#27867;&#30340;&#20852;&#36259;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17756v1 Announce Type: new  Abstract: We study the problem of learning Single-Index Models under the $L_2^2$ loss in the agnostic model. We give an efficient learning algorithm, achieving a constant factor approximation to the optimal loss, that succeeds under a range of distributions (including log-concave distributions) and a broad class of monotone and Lipschitz link functions. This is the first efficient constant factor approximate agnostic learner, even for Gaussian data and for any nontrivial class of link functions. Prior work for the case of unknown link function either works in the realizable setting or does not attain constant factor approximation. The main technical ingredient enabling our algorithm and analysis is a novel notion of a local error bound in optimization that we term alignment sharpness and that may be of broader interest.
&lt;/p&gt;</description></item><item><title>RLHF&#22312;&#32771;&#34385;&#37096;&#20998;&#35266;&#23519;&#24615;&#26102;&#21487;&#33021;&#23548;&#33268;&#31574;&#30053;&#27450;&#39575;&#24615;&#22320;&#22840;&#22823;&#24615;&#33021;&#25110;&#36807;&#24230;&#36777;&#25252;&#34892;&#20026;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#25968;&#23398;&#26465;&#20214;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#35686;&#21578;&#19981;&#35201;&#30450;&#30446;&#24212;&#29992;RLHF&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#24773;&#20917;&#19979;&#12290;</title><link>https://arxiv.org/abs/2402.17747</link><description>&lt;p&gt;
&#24403;&#20320;&#30340;AI&#27450;&#39575;&#20320;&#65306;&#22312;&#22870;&#21169;&#23398;&#20064;&#20013;&#20154;&#31867;&#35780;&#20272;&#32773;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#30340;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
When Your AI Deceives You: Challenges with Partial Observability of Human Evaluators in Reward Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17747
&lt;/p&gt;
&lt;p&gt;
RLHF&#22312;&#32771;&#34385;&#37096;&#20998;&#35266;&#23519;&#24615;&#26102;&#21487;&#33021;&#23548;&#33268;&#31574;&#30053;&#27450;&#39575;&#24615;&#22320;&#22840;&#22823;&#24615;&#33021;&#25110;&#36807;&#24230;&#36777;&#25252;&#34892;&#20026;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#25968;&#23398;&#26465;&#20214;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#35686;&#21578;&#19981;&#35201;&#30450;&#30446;&#24212;&#29992;RLHF&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#65288;RLHF&#65289;&#30340;&#36807;&#21435;&#20998;&#26512;&#20551;&#35774;&#20154;&#31867;&#23436;&#20840;&#35266;&#23519;&#21040;&#29615;&#22659;&#12290;&#24403;&#20154;&#31867;&#21453;&#39304;&#20165;&#22522;&#20110;&#37096;&#20998;&#35266;&#23519;&#26102;&#20250;&#21457;&#29983;&#20160;&#20040;&#65311;&#25105;&#20204;&#23545;&#20004;&#31181;&#22833;&#36133;&#24773;&#20917;&#36827;&#34892;&#20102;&#27491;&#24335;&#23450;&#20041;&#65306;&#27450;&#39575;&#21644;&#36807;&#24230;&#36777;&#25252;&#12290;&#36890;&#36807;&#23558;&#20154;&#31867;&#24314;&#27169;&#20026;&#23545;&#36712;&#36857;&#20449;&#24565;&#30340;Boltzmann-&#29702;&#24615;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;RLHF&#20445;&#35777;&#20250;&#23548;&#33268;&#31574;&#30053;&#27450;&#39575;&#24615;&#22320;&#22840;&#22823;&#20854;&#24615;&#33021;&#12289;&#20026;&#20102;&#30041;&#19979;&#21360;&#35937;&#32780;&#36807;&#24230;&#36777;&#25252;&#25110;&#32773;&#20004;&#32773;&#20860;&#32780;&#26377;&#20043;&#30340;&#26465;&#20214;&#12290;&#20026;&#20102;&#24110;&#21161;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25968;&#23398;&#22320;&#21051;&#30011;&#20102;&#29615;&#22659;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#22914;&#20309;&#36716;&#21270;&#20026;&#65288;&#32570;&#20047;&#65289;&#23398;&#21040;&#30340;&#22238;&#25253;&#20989;&#25968;&#20013;&#30340;&#27169;&#31946;&#24615;&#12290;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#32771;&#34385;&#29615;&#22659;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#20351;&#24471;&#22312;&#29702;&#35770;&#19978;&#21487;&#33021;&#24674;&#22797;&#22238;&#25253;&#20989;&#25968;&#21644;&#26368;&#20248;&#31574;&#30053;&#65292;&#32780;&#22312;&#20854;&#20182;&#24773;&#20917;&#19979;&#65292;&#23384;&#22312;&#19981;&#21487;&#20943;&#23569;&#30340;&#27169;&#31946;&#24615;&#12290;&#25105;&#20204;&#35686;&#21578;&#19981;&#35201;&#30450;&#30446;&#24212;&#29992;RLHF&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17747v1 Announce Type: cross  Abstract: Past analyses of reinforcement learning from human feedback (RLHF) assume that the human fully observes the environment. What happens when human feedback is based only on partial observations? We formally define two failure cases: deception and overjustification. Modeling the human as Boltzmann-rational w.r.t. a belief over trajectories, we prove conditions under which RLHF is guaranteed to result in policies that deceptively inflate their performance, overjustify their behavior to make an impression, or both. To help address these issues, we mathematically characterize how partial observability of the environment translates into (lack of) ambiguity in the learned return function. In some cases, accounting for partial observability makes it theoretically possible to recover the return function and thus the optimal policy, while in other cases, there is irreducible ambiguity. We caution against blindly applying RLHF in partially observa
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#25209;&#22788;&#29702;&#32422;&#26463;&#19979;&#30340;&#38750;&#21442;&#25968;&#19978;&#19979;&#25991;&#33218;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BaSEDB&#30340;&#26041;&#26696;&#65292;&#22312;&#21160;&#24577;&#20998;&#21106;&#21327;&#21464;&#37327;&#31354;&#38388;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#20102;&#26368;&#20248;&#30340;&#21518;&#24724;&#12290;</title><link>https://arxiv.org/abs/2402.17732</link><description>&lt;p&gt;
&#25209;&#22788;&#29702;&#38750;&#21442;&#25968;&#19978;&#19979;&#25991;&#33218;
&lt;/p&gt;
&lt;p&gt;
Batched Nonparametric Contextual Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17732
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#25209;&#22788;&#29702;&#32422;&#26463;&#19979;&#30340;&#38750;&#21442;&#25968;&#19978;&#19979;&#25991;&#33218;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BaSEDB&#30340;&#26041;&#26696;&#65292;&#22312;&#21160;&#24577;&#20998;&#21106;&#21327;&#21464;&#37327;&#31354;&#38388;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#20102;&#26368;&#20248;&#30340;&#21518;&#24724;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#25209;&#22788;&#29702;&#32422;&#26463;&#19979;&#30340;&#38750;&#21442;&#25968;&#19978;&#19979;&#25991;&#33218;&#38382;&#39064;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#27599;&#20010;&#21160;&#20316;&#30340;&#26399;&#26395;&#22870;&#21169;&#34987;&#24314;&#27169;&#20026;&#21327;&#21464;&#37327;&#30340;&#24179;&#28369;&#20989;&#25968;&#65292;&#24182;&#19988;&#31574;&#30053;&#26356;&#26032;&#26159;&#22312;&#27599;&#20010;Observations&#25209;&#27425;&#32467;&#26463;&#26102;&#36827;&#34892;&#30340;&#12290;&#25105;&#20204;&#20026;&#36825;&#31181;&#35774;&#32622;&#24314;&#31435;&#20102;&#19968;&#20010;&#26368;&#23567;&#21270;&#21518;&#24724;&#30340;&#19979;&#38480;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Batched Successive Elimination with Dynamic Binning&#65288;BaSEDB&#65289;&#30340;&#26041;&#26696;&#65292;&#21487;&#20197;&#23454;&#29616;&#26368;&#20248;&#30340;&#21518;&#24724;&#65288;&#36798;&#21040;&#23545;&#25968;&#22240;&#23376;&#65289;&#12290;&#23454;&#36136;&#19978;&#65292;BaSEDB&#21160;&#24577;&#22320;&#23558;&#21327;&#21464;&#37327;&#31354;&#38388;&#20998;&#21106;&#25104;&#26356;&#23567;&#30340;&#31665;&#23376;&#65292;&#24182;&#20180;&#32454;&#35843;&#25972;&#23427;&#20204;&#30340;&#23485;&#24230;&#20197;&#31526;&#21512;&#25209;&#27425;&#22823;&#23567;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22312;&#25209;&#22788;&#29702;&#32422;&#26463;&#19979;&#38745;&#24577;&#20998;&#31665;&#30340;&#38750;&#26368;&#20248;&#24615;&#65292;&#31361;&#20986;&#20102;&#21160;&#24577;&#20998;&#31665;&#30340;&#24517;&#35201;&#24615;&#12290;&#21478;&#22806;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#23436;&#20840;&#22312;&#32447;&#35774;&#32622;&#20013;&#65292;&#20960;&#20046;&#24658;&#23450;&#25968;&#37327;&#30340;&#31574;&#30053;&#26356;&#26032;&#21487;&#20197;&#36798;&#21040;&#26368;&#20339;&#21518;&#24724;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17732v1 Announce Type: cross  Abstract: We study nonparametric contextual bandits under batch constraints, where the expected reward for each action is modeled as a smooth function of covariates, and the policy updates are made at the end of each batch of observations. We establish a minimax regret lower bound for this setting and propose Batched Successive Elimination with Dynamic Binning (BaSEDB) that achieves optimal regret (up to logarithmic factors). In essence, BaSEDB dynamically splits the covariate space into smaller bins, carefully aligning their widths with the batch size. We also show the suboptimality of static binning under batch constraints, highlighting the necessity of dynamic binning. Additionally, our results suggest that a nearly constant number of policy updates can attain optimal regret in the fully online setting.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23558;&#36716;&#31227;&#23398;&#20064;&#30340;&#20195;&#29702;&#27169;&#22411;&#19982;&#36125;&#21494;&#26031;&#20248;&#21270;&#30456;&#32467;&#21512;&#65292;&#26412;&#25991;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#22312;&#20248;&#21270;&#20219;&#21153;&#20043;&#38388;&#20849;&#20139;&#20449;&#24687;&#26469;&#20943;&#23569;&#23454;&#39564;&#30340;&#24635;&#25968;&#65292;&#24182;&#19988;&#28436;&#31034;&#20102;&#22312;&#35774;&#35745;&#29992;&#20110;&#25193;&#22686;&#22522;&#22240;&#35786;&#26029;&#27979;&#23450;&#30340;DNA&#31454;&#20105;&#23545;&#25163;&#26102;&#23454;&#39564;&#25968;&#37327;&#30340;&#20943;&#23569;&#12290;</title><link>https://arxiv.org/abs/2402.17704</link><description>&lt;p&gt;
&#23558;&#36125;&#21494;&#26031;&#20248;&#21270;&#24212;&#29992;&#20110;&#36716;&#31227;&#23398;&#20064;&#20197;&#35774;&#35745;&#29992;&#20110;&#35786;&#26029;&#27979;&#23450;&#30340;&#31454;&#20105;&#23545;&#25163;DNA&#20998;&#23376;
&lt;/p&gt;
&lt;p&gt;
Transfer Learning Bayesian Optimization to Design Competitor DNA Molecules for Use in Diagnostic Assays
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17704
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23558;&#36716;&#31227;&#23398;&#20064;&#30340;&#20195;&#29702;&#27169;&#22411;&#19982;&#36125;&#21494;&#26031;&#20248;&#21270;&#30456;&#32467;&#21512;&#65292;&#26412;&#25991;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#22312;&#20248;&#21270;&#20219;&#21153;&#20043;&#38388;&#20849;&#20139;&#20449;&#24687;&#26469;&#20943;&#23569;&#23454;&#39564;&#30340;&#24635;&#25968;&#65292;&#24182;&#19988;&#28436;&#31034;&#20102;&#22312;&#35774;&#35745;&#29992;&#20110;&#25193;&#22686;&#22522;&#22240;&#35786;&#26029;&#27979;&#23450;&#30340;DNA&#31454;&#20105;&#23545;&#25163;&#26102;&#23454;&#39564;&#25968;&#37327;&#30340;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#24037;&#31243;&#29983;&#29289;&#20998;&#23376;&#35774;&#22791;&#30340;&#20852;&#36215;&#65292;&#23450;&#21046;&#29983;&#29289;&#24207;&#21015;&#30340;&#38656;&#27714;&#19981;&#26029;&#22686;&#21152;&#12290;&#36890;&#24120;&#65292;&#20026;&#20102;&#29305;&#23450;&#24212;&#29992;&#38656;&#35201;&#21046;&#20316;&#35768;&#22810;&#31867;&#20284;&#30340;&#29983;&#29289;&#24207;&#21015;&#65292;&#36825;&#24847;&#21619;&#30528;&#38656;&#35201;&#36827;&#34892;&#22823;&#37327;&#29978;&#33267;&#26114;&#36149;&#30340;&#23454;&#39564;&#26469;&#20248;&#21270;&#36825;&#20123;&#24207;&#21015;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36716;&#31227;&#23398;&#20064;&#35774;&#35745;&#23454;&#39564;&#24037;&#20316;&#27969;&#31243;&#65292;&#20351;&#36825;&#31181;&#24320;&#21457;&#21464;&#24471;&#21487;&#34892;&#12290;&#36890;&#36807;&#23558;&#36716;&#31227;&#23398;&#20064;&#20195;&#29702;&#27169;&#22411;&#19982;&#36125;&#21494;&#26031;&#20248;&#21270;&#30456;&#32467;&#21512;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#22312;&#20248;&#21270;&#20219;&#21153;&#20043;&#38388;&#20849;&#20139;&#20449;&#24687;&#26469;&#20943;&#23569;&#23454;&#39564;&#30340;&#24635;&#25968;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#20351;&#29992;&#29992;&#20110;&#25193;&#22686;&#22522;&#22240;&#35786;&#26029;&#27979;&#23450;&#20013;&#20351;&#29992;&#30340;DNA&#31454;&#20105;&#23545;&#25163;&#24320;&#21457;&#25968;&#25454;&#26469;&#20943;&#23569;&#23454;&#39564;&#25968;&#37327;&#12290;&#25105;&#20204;&#20351;&#29992;&#20132;&#21449;&#39564;&#35777;&#26469;&#27604;&#36739;&#19981;&#21516;&#36716;&#31227;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#65292;&#28982;&#21518;&#27604;&#36739;&#36825;&#20123;&#27169;&#22411;&#22312;&#21333;&#19968;&#30446;&#26631;&#21644;&#24809;&#32602;&#20248;&#21270;&#19979;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17704v1 Announce Type: cross  Abstract: With the rise in engineered biomolecular devices, there is an increased need for tailor-made biological sequences. Often, many similar biological sequences need to be made for a specific application meaning numerous, sometimes prohibitively expensive, lab experiments are necessary for their optimization. This paper presents a transfer learning design of experiments workflow to make this development feasible. By combining a transfer learning surrogate model with Bayesian optimization, we show how the total number of experiments can be reduced by sharing information between optimization tasks. We demonstrate the reduction in the number of experiments using data from the development of DNA competitors for use in an amplification-based diagnostic assay. We use cross-validation to compare the predictive accuracy of different transfer learning models, and then compare the performance of the models for both single objective and penalized opti
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#33258;&#21160;&#24490;&#29615;&#35843;&#24230;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#31163;&#25955;&#37319;&#26679;&#26041;&#27861;&#65292;&#26377;&#25928;&#24212;&#23545;&#39640;&#24230;&#22810;&#27169;&#24577;&#30340;&#31163;&#25955;&#20998;&#24067;&#65292;&#21253;&#25324;&#24490;&#29615;&#27493;&#38271;&#35843;&#24230;&#12289;&#24490;&#29615;&#24179;&#34913;&#35843;&#24230;&#21644;&#33258;&#21160;&#35843;&#25972;&#36229;&#21442;&#25968;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2402.17699</link><description>&lt;p&gt;
&#20351;&#29992;&#33258;&#21160;&#24490;&#29615;&#35843;&#24230;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#31163;&#25955;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Gradient-based Discrete Sampling with Automatic Cyclical Scheduling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17699
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#33258;&#21160;&#24490;&#29615;&#35843;&#24230;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#31163;&#25955;&#37319;&#26679;&#26041;&#27861;&#65292;&#26377;&#25928;&#24212;&#23545;&#39640;&#24230;&#22810;&#27169;&#24577;&#30340;&#31163;&#25955;&#20998;&#24067;&#65292;&#21253;&#25324;&#24490;&#29615;&#27493;&#38271;&#35843;&#24230;&#12289;&#24490;&#29615;&#24179;&#34913;&#35843;&#24230;&#21644;&#33258;&#21160;&#35843;&#25972;&#36229;&#21442;&#25968;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#25955;&#20998;&#24067;&#65292;&#29305;&#21035;&#26159;&#22312;&#39640;&#32500;&#28145;&#24230;&#27169;&#22411;&#20013;&#65292;&#36890;&#24120;&#30001;&#20110;&#22266;&#26377;&#30340;&#19981;&#36830;&#32493;&#24615;&#32780;&#21576;&#29616;&#39640;&#24230;&#22810;&#27169;&#24577;&#12290;&#34429;&#28982;&#22522;&#20110;&#26799;&#24230;&#30340;&#31163;&#25955;&#37319;&#26679;&#24050;&#34987;&#35777;&#26126;&#26159;&#26377;&#25928;&#30340;&#65292;&#20294;&#30001;&#20110;&#26799;&#24230;&#20449;&#24687;&#65292;&#23427;&#23481;&#26131;&#38519;&#20837;&#23616;&#37096;&#27169;&#24335;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#24490;&#29615;&#35843;&#24230;&#65292;&#26088;&#22312;&#23454;&#29616;&#23545;&#22810;&#27169;&#24577;&#31163;&#25955;&#20998;&#24067;&#36827;&#34892;&#39640;&#25928;&#20934;&#30830;&#30340;&#37319;&#26679;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21253;&#25324;&#19977;&#20010;&#20851;&#38190;&#37096;&#20998;&#65306;&#65288;1&#65289;&#24490;&#29615;&#27493;&#38271;&#35843;&#24230;&#65292;&#20854;&#20013;&#22823;&#27493;&#38271;&#21457;&#29616;&#26032;&#27169;&#24335;&#65292;&#23567;&#27493;&#38271;&#21033;&#29992;&#27599;&#20010;&#27169;&#24335;&#65307;&#65288;2&#65289;&#24490;&#29615;&#24179;&#34913;&#35843;&#24230;&#65292;&#30830;&#20445;&#32473;&#23450;&#27493;&#38271;&#30340;&#8220;&#24179;&#34913;&#8221;&#25552;&#26696;&#21644;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#39640;&#25928;&#29575;&#65307;&#20197;&#21450;&#65288;3&#65289;&#33258;&#21160;&#35843;&#25972;&#26041;&#26696;&#65292;&#29992;&#20110;&#35843;&#25972;&#24490;&#29615;&#35843;&#24230;&#20013;&#30340;&#36229;&#21442;&#25968;&#65292;&#23454;&#29616;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#30340;&#33258;&#36866;&#24212;&#24615;&#19988;&#38656;&#26368;&#23567;&#35843;&#25972;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#21644;&#25512;&#26029;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17699v1 Announce Type: new  Abstract: Discrete distributions, particularly in high-dimensional deep models, are often highly multimodal due to inherent discontinuities. While gradient-based discrete sampling has proven effective, it is susceptible to becoming trapped in local modes due to the gradient information. To tackle this challenge, we propose an automatic cyclical scheduling, designed for efficient and accurate sampling in multimodal discrete distributions. Our method contains three key components: (1) a cyclical step size schedule where large steps discover new modes and small steps exploit each mode; (2) a cyclical balancing schedule, ensuring ``balanced" proposals for given step sizes and high efficiency of the Markov chain; and (3) an automatic tuning scheme for adjusting the hyperparameters in the cyclical schedules, allowing adaptability across diverse datasets with minimal tuning. We prove the non-asymptotic convergence and inference guarantee for our method i
&lt;/p&gt;</description></item><item><title>&#21464;&#20998;&#23398;&#20064;&#22312;&#22823;&#22411;&#28145;&#24230;&#32593;&#32476;&#20013;&#23637;&#29616;&#20986;&#38750;&#24120;&#22909;&#30340;&#25928;&#26524;&#65292;IVON&#20248;&#21270;&#22120;&#22312;&#35757;&#32451;&#22823;&#22411;&#32593;&#32476;&#26102;&#20960;&#20046;&#33021;&#19982;Adam&#30456;&#23218;&#32654;&#29978;&#33267;&#32988;&#36807;&#23427;&#65292;&#19988;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#26356;&#20934;&#30830;&#65292;&#23545;&#27169;&#22411;&#24494;&#35843;&#12289;&#27867;&#21270;&#35823;&#24046;&#39044;&#27979;&#21644;&#25968;&#25454;&#25935;&#24863;&#24615;&#20272;&#35745;&#22343;&#26377;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2402.17641</link><description>&lt;p&gt;
&#21464;&#20998;&#23398;&#20064;&#23545;&#22823;&#22411;&#28145;&#24230;&#32593;&#32476;&#26377;&#25928;
&lt;/p&gt;
&lt;p&gt;
Variational Learning is Effective for Large Deep Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17641
&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#23398;&#20064;&#22312;&#22823;&#22411;&#28145;&#24230;&#32593;&#32476;&#20013;&#23637;&#29616;&#20986;&#38750;&#24120;&#22909;&#30340;&#25928;&#26524;&#65292;IVON&#20248;&#21270;&#22120;&#22312;&#35757;&#32451;&#22823;&#22411;&#32593;&#32476;&#26102;&#20960;&#20046;&#33021;&#19982;Adam&#30456;&#23218;&#32654;&#29978;&#33267;&#32988;&#36807;&#23427;&#65292;&#19988;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#26356;&#20934;&#30830;&#65292;&#23545;&#27169;&#22411;&#24494;&#35843;&#12289;&#27867;&#21270;&#35823;&#24046;&#39044;&#27979;&#21644;&#25968;&#25454;&#25935;&#24863;&#24615;&#20272;&#35745;&#22343;&#26377;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#22823;&#37327;&#23454;&#35777;&#35777;&#25454;&#65292;&#21453;&#39539;&#20102;&#21464;&#20998;&#23398;&#20064;&#23545;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#26080;&#25928;&#30340;&#26222;&#36941;&#30475;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#21517;&#20026;Improved Variational Online Newton (IVON)&#30340;&#20248;&#21270;&#22120;&#65292;&#22312;&#35757;&#32451;&#22823;&#22411;&#32593;&#32476;&#65288;&#22914;GPT-2&#21644;ResNets&#65289;&#26102;&#22987;&#32456;&#33021;&#22815;&#19982;Adam&#30456;&#21305;&#37197;&#25110;&#32988;&#36807;&#23427;&#12290;IVON&#30340;&#35745;&#31639;&#25104;&#26412;&#20960;&#20046;&#19982;Adam&#30456;&#21516;&#65292;&#20294;&#20854;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#26356;&#22909;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;IVON&#30340;&#20960;&#31181;&#26032;&#29992;&#20363;&#65292;&#20854;&#20013;&#25105;&#20204;&#25913;&#36827;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24494;&#35843;&#21644;&#27169;&#22411;&#21512;&#24182;&#65292;&#22312;&#20934;&#30830;&#39044;&#27979;&#27867;&#21270;&#35823;&#24046;&#21644;&#24544;&#23454;&#20272;&#35745;&#23545;&#25968;&#25454;&#30340;&#25935;&#24863;&#24615;&#26041;&#38754;&#12290;&#25105;&#20204;&#25214;&#21040;&#20102;&#22823;&#37327;&#25903;&#25345;&#21464;&#20998;&#23398;&#20064;&#26377;&#25928;&#24615;&#30340;&#35777;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17641v1 Announce Type: cross  Abstract: We give extensive empirical evidence against the common belief that variational learning is ineffective for large neural networks. We show that an optimizer called Improved Variational Online Newton (IVON) consistently matches or outperforms Adam for training large networks such as GPT-2 and ResNets from scratch. IVON's computational costs are nearly identical to Adam but its predictive uncertainty is better. We show several new use cases of IVON where we improve fine-tuning and model merging in Large Language Models, accurately predict generalization error, and faithfully estimate sensitivity to data. We find overwhelming evidence in support of effectiveness of variational learning.
&lt;/p&gt;</description></item><item><title>DAGnosis&#20351;&#29992;&#26377;&#21521;&#26080;&#29615;&#22270;(DAGs)&#26469;&#35299;&#20915;&#25968;&#25454;&#19968;&#33268;&#24615;&#26816;&#27979;&#20013;&#30340;&#20004;&#20010;&#20851;&#38190;&#38480;&#21046;&#65292;&#24182;&#33021;&#22815;&#20934;&#30830;&#23450;&#20301;&#20026;&#20309;&#26679;&#26412;&#20250;&#34987;&#26631;&#35760;&#20026;&#19981;&#19968;&#33268;&#12290;</title><link>https://arxiv.org/abs/2402.17599</link><description>&lt;p&gt;
DAGnosis&#65306;&#20351;&#29992;&#32467;&#26500;&#36827;&#34892;&#25968;&#25454;&#19981;&#19968;&#33268;&#24615;&#30340;&#23616;&#37096;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
DAGnosis: Localized Identification of Data Inconsistencies using Structures
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17599
&lt;/p&gt;
&lt;p&gt;
DAGnosis&#20351;&#29992;&#26377;&#21521;&#26080;&#29615;&#22270;(DAGs)&#26469;&#35299;&#20915;&#25968;&#25454;&#19968;&#33268;&#24615;&#26816;&#27979;&#20013;&#30340;&#20004;&#20010;&#20851;&#38190;&#38480;&#21046;&#65292;&#24182;&#33021;&#22815;&#20934;&#30830;&#23450;&#20301;&#20026;&#20309;&#26679;&#26412;&#20250;&#34987;&#26631;&#35760;&#20026;&#19981;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#37096;&#32626;&#26102;&#35782;&#21035;&#21644;&#36866;&#24403;&#22788;&#29702;&#25968;&#25454;&#20013;&#30340;&#19981;&#19968;&#33268;&#24615;&#23545;&#21487;&#38752;&#22320;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#33267;&#20851;&#37325;&#35201;&#12290;&#36817;&#26399;&#30340;&#25968;&#25454;&#20013;&#24515;&#26041;&#27861;&#33021;&#22815;&#35782;&#21035;&#19982;&#35757;&#32451;&#38598;&#30456;&#20851;&#30340;&#36825;&#31181;&#19981;&#19968;&#33268;&#24615;&#65292;&#20294;&#23384;&#22312;&#20004;&#20010;&#20851;&#38190;&#38480;&#21046;&#65306;&#65288;1&#65289;&#22312;&#29305;&#24449;&#23637;&#29616;&#32479;&#35745;&#29420;&#31435;&#24615;&#30340;&#24773;&#20917;&#19979;&#34920;&#29616;&#19981;&#20339;&#65292;&#22240;&#20026;&#23427;&#20204;&#20351;&#29992;&#21387;&#32553;&#34920;&#31034;&#65307;&#65288;2&#65289;&#32570;&#20047;&#23616;&#37096;&#21270;&#65292;&#26080;&#27861;&#20934;&#30830;&#23450;&#20301;&#26679;&#26412;&#20026;&#20309;&#34987;&#26631;&#35760;&#20026;&#19981;&#19968;&#33268;&#65292;&#36825;&#23545;&#25351;&#23548;&#26410;&#26469;&#25968;&#25454;&#25910;&#38598;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#20351;&#29992;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAGs&#65289;&#26469;&#32534;&#30721;&#35757;&#32451;&#38598;&#30340;&#29305;&#24449;&#27010;&#29575;&#20998;&#24067;&#21644;&#29420;&#31435;&#24615;&#20316;&#20026;&#32467;&#26500;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#36825;&#20004;&#20010;&#22522;&#26412;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#34987;&#31216;&#20026;DAGnosis&#65292;&#21033;&#29992;&#36825;&#20123;&#32467;&#26500;&#20132;&#20114;&#24102;&#26469;&#26377;&#20215;&#20540;&#30340;&#12289;&#28145;&#21051;&#30340;&#25968;&#25454;&#20013;&#24515;&#32467;&#35770;&#12290;DAGnosis&#35299;&#38145;&#20102;&#22312;DAG&#19978;&#23450;&#20301;&#19981;&#19968;&#33268;&#24615;&#21407;&#22240;&#30340;&#33021;&#21147;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17599v1 Announce Type: cross  Abstract: Identification and appropriate handling of inconsistencies in data at deployment time is crucial to reliably use machine learning models. While recent data-centric methods are able to identify such inconsistencies with respect to the training set, they suffer from two key limitations: (1) suboptimality in settings where features exhibit statistical independencies, due to their usage of compressive representations and (2) lack of localization to pin-point why a sample might be flagged as inconsistent, which is important to guide future data collection. We solve these two fundamental limitations using directed acyclic graphs (DAGs) to encode the training set's features probability distribution and independencies as a structure. Our method, called DAGnosis, leverages these structural interactions to bring valuable and insightful data-centric conclusions. DAGnosis unlocks the localization of the causes of inconsistencies on a DAG, an aspec
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#26356;&#29616;&#23454;&#30340;&#31070;&#32463;&#32593;&#32476;&#32972;&#26223;&#19979;&#25506;&#35752;&#20102;&#38544;&#24335;&#27491;&#21017;&#21270;&#29616;&#35937;&#65292;&#36890;&#36807;&#30740;&#31350;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#30340;&#19968;&#33324;&#31867;&#21035;&#65292;&#20005;&#26684;&#35777;&#26126;&#20102;&#22312;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#35774;&#32622;&#20013;&#36825;&#20123;&#32593;&#32476;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#29616;&#35937;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#36895;&#29575;&#20445;&#35777;&#65292;&#30830;&#20445;&#26799;&#24230;&#30340;&#25351;&#25968;&#32423;&#24555;&#36895;&#25910;&#25947;&#12290;</title><link>https://arxiv.org/abs/2402.17595</link><description>&lt;p&gt;
&#36890;&#36807;&#35889;&#31070;&#32463;&#32593;&#32476;&#21644;&#38750;&#32447;&#24615;&#30697;&#38453;&#24863;&#30693;&#23454;&#29616;&#38544;&#24335;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Implicit Regularization via Spectral Neural Networks and Non-linear Matrix Sensing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17595
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#26356;&#29616;&#23454;&#30340;&#31070;&#32463;&#32593;&#32476;&#32972;&#26223;&#19979;&#25506;&#35752;&#20102;&#38544;&#24335;&#27491;&#21017;&#21270;&#29616;&#35937;&#65292;&#36890;&#36807;&#30740;&#31350;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#30340;&#19968;&#33324;&#31867;&#21035;&#65292;&#20005;&#26684;&#35777;&#26126;&#20102;&#22312;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#35774;&#32622;&#20013;&#36825;&#20123;&#32593;&#32476;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#29616;&#35937;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#36895;&#29575;&#20445;&#35777;&#65292;&#30830;&#20445;&#26799;&#24230;&#30340;&#25351;&#25968;&#32423;&#24555;&#36895;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38544;&#24335;&#27491;&#21017;&#21270;&#29616;&#35937;&#36817;&#24180;&#26469;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20852;&#36259;&#65292;&#20316;&#20026;&#31070;&#32463;&#32593;&#32476;&#20986;&#33394;&#27867;&#21270;&#33021;&#21147;&#30340;&#19968;&#20010;&#22522;&#26412;&#26041;&#38754;&#12290;&#31616;&#32780;&#35328;&#20043;&#65292;&#23427;&#24847;&#21619;&#30528;&#22312;&#35768;&#22810;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#21363;&#20351;&#25439;&#22833;&#20989;&#25968;&#20013;&#27809;&#26377;&#20219;&#20309;&#26174;&#24335;&#27491;&#21017;&#21270;&#22120;&#65292;&#26799;&#24230;&#19979;&#38477;&#21160;&#24577;&#20063;&#20250;&#25910;&#25947;&#21040;&#19968;&#20010;&#27491;&#21017;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#35299;&#12290;&#28982;&#32780;&#65292;&#24050;&#30693;&#30340;&#35797;&#22270;&#20174;&#29702;&#35770;&#19978;&#35299;&#37322;&#36825;&#19968;&#29616;&#35937;&#30340;&#32467;&#26524;&#20027;&#35201;&#38598;&#20013;&#22312;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#30340;&#35774;&#32622;&#19978;&#65292;&#32447;&#24615;&#32467;&#26500;&#30340;&#31616;&#21333;&#24615;&#23545;&#29616;&#26377;&#35770;&#25454;&#29305;&#21035;&#20851;&#38190;&#12290;&#26412;&#25991;&#22312;&#26356;&#29616;&#23454;&#30340;&#31070;&#32463;&#32593;&#32476;&#21644;&#19968;&#33324;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#30340;&#32972;&#26223;&#19979;&#25506;&#35752;&#20102;&#36825;&#19968;&#38382;&#39064;&#65292;&#24182;&#22312;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#30340;&#35774;&#32622;&#20013;&#20005;&#26684;&#35777;&#26126;&#20102;&#36825;&#20123;&#32593;&#32476;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#29616;&#35937;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#36895;&#29575;&#20445;&#35777;&#65292;&#30830;&#20445;&#26799;&#24230;&#30340;&#25351;&#25968;&#32423;&#24555;&#36895;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17595v1 Announce Type: cross  Abstract: The phenomenon of implicit regularization has attracted interest in recent years as a fundamental aspect of the remarkable generalizing ability of neural networks. In a nutshell, it entails that gradient descent dynamics in many neural nets, even without any explicit regularizer in the loss function, converges to the solution of a regularized learning problem. However, known results attempting to theoretically explain this phenomenon focus overwhelmingly on the setting of linear neural nets, and the simplicity of the linear structure is particularly crucial to existing arguments. In this paper, we explore this problem in the context of more realistic neural networks with a general class of non-linear activation functions, and rigorously demonstrate the implicit regularization phenomenon for such networks in the setting of matrix sensing problems, together with rigorous rate guarantees that ensure exponentially fast convergence of gradi
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#21521;&#37327;&#23450;&#20041;&#27880;&#24847;&#21147;&#30340;&#26041;&#27861;&#65292;&#23558;&#26631;&#20934;transformer&#20013;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#20174;&#20108;&#27425;&#26041;&#38477;&#20302;&#21040;&#19982;&#26102;&#38388;&#32447;&#24615;&#30456;&#20851;&#65292;&#34920;&#29616;&#19982;&#26631;&#20934;&#27880;&#24847;&#21147;&#23218;&#32654;&#65292;&#20294;&#20801;&#35768;&#19978;&#19979;&#25991;&#31383;&#21475;&#25193;&#23637;&#21040;&#36828;&#36828;&#36229;&#20986;&#26631;&#20934;&#30340;&#33539;&#22260;&#12290;</title><link>https://arxiv.org/abs/2402.17512</link><description>&lt;p&gt;
Latent Attention for Linear Time Transformers
&lt;/p&gt;
&lt;p&gt;
Latent Attention for Linear Time Transformers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17512
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#21521;&#37327;&#23450;&#20041;&#27880;&#24847;&#21147;&#30340;&#26041;&#27861;&#65292;&#23558;&#26631;&#20934;transformer&#20013;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#20174;&#20108;&#27425;&#26041;&#38477;&#20302;&#21040;&#19982;&#26102;&#38388;&#32447;&#24615;&#30456;&#20851;&#65292;&#34920;&#29616;&#19982;&#26631;&#20934;&#27880;&#24847;&#21147;&#23218;&#32654;&#65292;&#20294;&#20801;&#35768;&#19978;&#19979;&#25991;&#31383;&#21475;&#25193;&#23637;&#21040;&#36828;&#36828;&#36229;&#20986;&#26631;&#20934;&#30340;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;transformer&#20013;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#38543;&#30528;&#24207;&#21015;&#38271;&#24230;&#30340;&#22686;&#21152;&#21576;&#20108;&#27425;&#26041;&#22686;&#38271;&#12290;&#25105;&#20204;&#24341;&#20837;&#19968;&#31181;&#36890;&#36807;&#23450;&#20041;&#28508;&#22312;&#21521;&#37327;&#30340;&#27880;&#24847;&#21147;&#26469;&#23558;&#20854;&#38477;&#20302;&#21040;&#19982;&#26102;&#38388;&#32447;&#24615;&#30456;&#20851;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#36731;&#26494;&#20316;&#20026;&#26631;&#20934;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26367;&#20195;&#21697;&#12290;&#25105;&#20204;&#30340;&#8220;Latte Transformer&#8221;&#27169;&#22411;&#21487;&#29992;&#20110;&#21452;&#21521;&#21644;&#21333;&#21521;&#20219;&#21153;&#65292;&#22240;&#26524;&#29256;&#26412;&#20801;&#35768;&#19968;&#31181;&#22312;&#25512;&#29702;&#35821;&#35328;&#29983;&#25104;&#20219;&#21153;&#20013;&#20869;&#23384;&#21644;&#26102;&#38388;&#39640;&#25928;&#30340;&#36882;&#24402;&#23454;&#29616;&#12290;&#26631;&#20934;transformer&#30340;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#38543;&#30528;&#24207;&#21015;&#38271;&#24230;&#32447;&#24615;&#22686;&#38271;&#65292;&#32780;Latte Transformer&#35745;&#31639;&#19979;&#19968;&#20010;&#26631;&#35760;&#25152;&#38656;&#30340;&#26102;&#38388;&#26159;&#24658;&#23450;&#30340;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#23454;&#35777;&#34920;&#29616;&#21487;&#19982;&#26631;&#20934;&#27880;&#24847;&#21147;&#23218;&#32654;&#65292;&#20294;&#20801;&#35768;&#23558;&#19978;&#19979;&#25991;&#31383;&#21475;&#25193;&#23637;&#21040;&#36828;&#36828;&#36229;&#20986;&#26631;&#20934;&#27880;&#24847;&#21147;&#23454;&#38469;&#21487;&#34892;&#30340;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17512v1 Announce Type: new  Abstract: The time complexity of the standard attention mechanism in a transformer scales quadratically with the length of the sequence. We introduce a method to reduce this to linear scaling with time, based on defining attention via latent vectors. The method is readily usable as a drop-in replacement for the standard attention mechanism. Our "Latte Transformer" model can be implemented for both bidirectional and unidirectional tasks, with the causal version allowing a recurrent implementation which is memory and time-efficient during inference of language generation tasks. Whilst next token prediction scales linearly with the sequence length for a standard transformer, a Latte Transformer requires constant time to compute the next token. The empirical performance of our method is comparable to standard attention, yet allows scaling to context windows much larger than practical in standard attention.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20154;&#24037;&#26234;&#33021;&#21327;&#20316;&#30340;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#19987;&#23478;&#23545;&#26410;&#34987;&#27979;&#37327;&#30340;&#25277;&#35937;&#23646;&#24615;&#30340;&#20559;&#22909;&#32435;&#20837;&#21040;&#26367;&#20195;&#24314;&#27169;&#20013;&#65292;&#36827;&#19968;&#27493;&#25552;&#21319;&#20102;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.17343</link><description>&lt;p&gt;
&#36890;&#36807;&#20248;&#20808;&#24314;&#27169;&#25277;&#35937;&#23646;&#24615;&#22686;&#24378;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Enhanced Bayesian Optimization via Preferential Modeling of Abstract Properties
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17343
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20154;&#24037;&#26234;&#33021;&#21327;&#20316;&#30340;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#19987;&#23478;&#23545;&#26410;&#34987;&#27979;&#37327;&#30340;&#25277;&#35937;&#23646;&#24615;&#30340;&#20559;&#22909;&#32435;&#20837;&#21040;&#26367;&#20195;&#24314;&#27169;&#20013;&#65292;&#36827;&#19968;&#27493;&#25552;&#21319;&#20102;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#39564;&#35774;&#35745;&#20248;&#21270;&#26159;&#35774;&#35745;&#21644;&#21457;&#29616;&#26032;&#20135;&#21697;&#21644;&#27969;&#31243;&#30340;&#20851;&#38190;&#39537;&#21160;&#22240;&#32032;&#12290;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#26159;&#20248;&#21270;&#26114;&#36149;&#21644;&#40657;&#30418;&#23454;&#39564;&#35774;&#35745;&#36807;&#31243;&#30340;&#26377;&#25928;&#24037;&#20855;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20154;&#24037;&#26234;&#33021;&#21327;&#20316;&#30340;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#23558;&#19987;&#23478;&#23545;&#26410;&#34987;&#27979;&#37327;&#30340;&#25277;&#35937;&#23646;&#24615;&#30340;&#20559;&#22909;&#32435;&#20837;&#21040;&#26367;&#20195;&#24314;&#27169;&#20013;&#65292;&#20197;&#36827;&#19968;&#27493;&#25552;&#21319;BO&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#31574;&#30053;&#65292;&#21487;&#20197;&#22788;&#29702;&#20219;&#20309;&#19981;&#27491;&#30830;/&#35823;&#23548;&#24615;&#30340;&#19987;&#23478;&#20559;&#35265;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#25910;&#25947;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17343v1 Announce Type: new  Abstract: Experimental (design) optimization is a key driver in designing and discovering new products and processes. Bayesian Optimization (BO) is an effective tool for optimizing expensive and black-box experimental design processes. While Bayesian optimization is a principled data-driven approach to experimental optimization, it learns everything from scratch and could greatly benefit from the expertise of its human (domain) experts who often reason about systems at different abstraction levels using physical properties that are not necessarily directly measured (or measurable). In this paper, we propose a human-AI collaborative Bayesian framework to incorporate expert preferences about unmeasured abstract properties into the surrogate modeling to further boost the performance of BO. We provide an efficient strategy that can also handle any incorrect/misleading expert bias in preferential judgments. We discuss the convergence behavior of our pr
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#26032;&#39062;&#24615;&#30340;&#22522;&#20110;&#26680;&#30340;&#29109;&#26032;&#39062;&#24615; (KEN) &#20998;&#25968;</title><link>https://arxiv.org/abs/2402.17287</link><description>&lt;p&gt;
&#19968;&#20010;&#21487;&#35299;&#37322;&#30340;&#29983;&#25104;&#27169;&#22411;&#29109;&#20540;&#26032;&#39062;&#24615;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
An Interpretable Evaluation of Entropy-based Novelty of Generative Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17287
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#26032;&#39062;&#24615;&#30340;&#22522;&#20110;&#26680;&#30340;&#29109;&#26032;&#39062;&#24615; (KEN) &#20998;&#25968;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27169;&#22411;&#26694;&#26550;&#21644;&#26550;&#26500;&#30340;&#24040;&#22823;&#21457;&#23637;&#38656;&#35201;&#26377;&#21407;&#21017;&#30340;&#26041;&#27861;&#26469;&#35780;&#20272;&#27169;&#22411;&#30456;&#23545;&#20110;&#21442;&#32771;&#25968;&#25454;&#38598;&#25110;&#22522;&#32447;&#29983;&#25104;&#27169;&#22411;&#30340;&#26032;&#39062;&#24615;&#12290; &#34429;&#28982;&#26368;&#36817;&#30340;&#25991;&#29486;&#24050;&#24191;&#27867;&#30740;&#31350;&#20102;&#29983;&#25104;&#27169;&#22411;&#30340;&#36136;&#37327;&#12289;&#22810;&#26679;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#30340;&#35780;&#20272;&#65292;&#20294;&#19982;&#22522;&#32447;&#27169;&#22411;&#30456;&#27604;&#30340;&#27169;&#22411;&#26032;&#39062;&#24615;&#35780;&#20272;&#22312;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#20013;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#30740;&#31350;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20851;&#27880;&#22810;&#27169;&#24577;&#29983;&#25104;&#27169;&#22411;&#19979;&#30340;&#26032;&#39062;&#24615;&#35780;&#20272;&#65292;&#24182;&#23581;&#35797;&#22238;&#31572;&#20197;&#19979;&#38382;&#39064;&#65306;&#32473;&#23450;&#29983;&#25104;&#27169;&#22411; $\mathcal{G}$ &#30340;&#26679;&#26412;&#21644;&#21442;&#32771;&#25968;&#25454;&#38598; $\mathcal{S}$&#65292;&#25105;&#20204;&#22914;&#20309;&#21457;&#29616;&#24182;&#35745;&#31639; $\mathcal{G}$ &#27604; $\mathcal{S}$ &#20013;&#26356;&#39057;&#32321;&#22320;&#34920;&#36798;&#30340;&#27169;&#24335;&#12290; &#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#35889;&#26041;&#27861;&#26469;&#25551;&#36848;&#36825;&#19968;&#20219;&#21153;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#26680;&#30340;&#29109;&#26032;&#39062;&#24615; (KEN) &#20998;&#25968;&#26469;&#37327;&#21270;&#22522;&#20110;&#27169;&#24335;&#30340;&#26032;&#39062;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17287v1 Announce Type: new  Abstract: The massive developments of generative model frameworks and architectures require principled methods for the evaluation of a model's novelty compared to a reference dataset or baseline generative models. While the recent literature has extensively studied the evaluation of the quality, diversity, and generalizability of generative models, the assessment of a model's novelty compared to a baseline model has not been adequately studied in the machine learning community. In this work, we focus on the novelty assessment under multi-modal generative models and attempt to answer the following question: Given the samples of a generative model $\mathcal{G}$ and a reference dataset $\mathcal{S}$, how can we discover and count the modes expressed by $\mathcal{G}$ more frequently than in $\mathcal{S}$. We introduce a spectral approach to the described task and propose the Kernel-based Entropic Novelty (KEN) score to quantify the mode-based novelty 
&lt;/p&gt;</description></item><item><title>&#38543;&#26426;&#36924;&#36817;&#22312;&#26080;&#38480;&#32500;&#31354;&#38388;&#30340;&#24212;&#29992;&#26159;&#19968;&#20010;&#27963;&#36291;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#29305;&#21035;&#26159;&#22312;Banach&#31354;&#38388;&#20013;&#30340;&#36924;&#36817;&#24773;&#20917;&#12290;</title><link>https://arxiv.org/abs/2402.17258</link><description>&lt;p&gt;
&#26080;&#38480;&#32500;&#38543;&#26426;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Stochastic approximation in infinite dimensions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17258
&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#36924;&#36817;&#22312;&#26080;&#38480;&#32500;&#31354;&#38388;&#30340;&#24212;&#29992;&#26159;&#19968;&#20010;&#27963;&#36291;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#29305;&#21035;&#26159;&#22312;Banach&#31354;&#38388;&#20013;&#30340;&#36924;&#36817;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
20&#19990;&#32426;50&#24180;&#20195;&#21021;&#24341;&#20837;&#20102;&#38543;&#26426;&#36924;&#36817;&#65288;SA&#65289;&#65292;&#24182;&#22312;&#20960;&#21313;&#24180;&#26469;&#19968;&#30452;&#26159;&#19968;&#20010;&#27963;&#36291;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#34429;&#28982;&#26368;&#21021;&#20851;&#27880;&#30340;&#26159;&#32479;&#35745;&#38382;&#39064;&#65292;&#20294;&#20154;&#20204;&#21457;&#29616;&#23427;&#21487;&#20197;&#24212;&#29992;&#20110;&#20449;&#21495;&#22788;&#29702;&#12289;&#20984;&#20248;&#21270;&#12290;&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#37324;&#65292;&#30740;&#31350;&#32773;&#23545;SA&#37325;&#26032;&#20135;&#29983;&#20102;&#20852;&#36259;&#65292;&#21518;&#26469;&#21457;&#29616;SA&#22312;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20013;&#20063;&#26377;&#24212;&#29992;&#65292;&#24182;&#24341;&#21457;&#20102;&#20154;&#20204;&#30340;&#20852;&#36259;&#22797;&#33487;&#12290;&#23613;&#31649;&#22823;&#37096;&#20998;&#25991;&#29486;&#26159;&#38024;&#23545;&#20174;&#26377;&#38480;&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#35266;&#27979;&#30340;SA&#24773;&#20917;&#65292;&#20294;&#20154;&#20204;&#23545;&#23558;&#20854;&#25193;&#23637;&#21040;&#26080;&#38480;&#32500;&#24230;&#20063;&#24456;&#24863;&#20852;&#36259;&#12290;&#25193;&#23637;&#21040;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30456;&#23545;&#36739;&#23481;&#26131;&#65292;&#20294;&#24403;&#25105;&#20204;&#28041;&#21450;&#21040;Banach&#31354;&#38388;&#26102;&#24773;&#20917;&#24182;&#38750;&#22914;&#27492; - &#22240;&#20026;&#22312;Banach&#31354;&#38388;&#30340;&#24773;&#20917;&#19979;&#65292;&#21363;&#20351;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#20063;&#19981;&#23384;&#22312;&#8220;&#22823;&#25968;&#23450;&#24459;&#8221;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20123;&#36924;&#36817;&#22312;Banach&#31354;&#38388;&#20013;&#26377;&#25928;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21253;&#25324;&#24403;Banach&#31354;&#38388;B&#26159;C&#26102;&#30340;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17258v1 Announce Type: cross  Abstract: Stochastic Approximation (SA) was introduced in the early 1950's and has been an active area of research for several decades. While the initial focus was on statistical questions, it was seen to have applications to signal processing, convex optimisation. %Over the last decade, there has been a revival of interest in SA as In later years SA has found application in Reinforced Learning (RL) and led to revival of interest.   While bulk of the literature is on SA for the case when the observations are from a finite dimensional Euclidian space, there has been interest in extending the same to infinite dimension. Extension to Hilbert spaces is relatively easier to do, but this is not so when we come to a Banach space - since in the case of a Banach space, even {\em law of large numbers} is not true in general. We consider some cases where approximation works in a Banach space. Our framework includes case when the Banach space $\Bb$ is $\Cb(
&lt;/p&gt;</description></item><item><title>&#29983;&#25104;&#24335;&#23398;&#20064;&#21487;&#20197;&#36890;&#36807;&#23398;&#20064;&#21644;&#28436;&#21464;&#31995;&#32479;&#30340;&#26377;&#25928;&#21160;&#24577;&#21152;&#36895;&#27169;&#25311;&#65292;&#20026;&#20934;&#30830;&#39044;&#27979;&#22797;&#26434;&#31995;&#32479;&#30340;&#32479;&#35745;&#24615;&#36136;&#25552;&#20379;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.17157</link><description>&lt;p&gt;
&#29992;&#20110;&#39044;&#27979;&#22797;&#26434;&#31995;&#32479;&#21160;&#24577;&#30340;&#29983;&#25104;&#24335;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Generative Learning for Forecasting the Dynamics of Complex Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17157
&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#23398;&#20064;&#21487;&#20197;&#36890;&#36807;&#23398;&#20064;&#21644;&#28436;&#21464;&#31995;&#32479;&#30340;&#26377;&#25928;&#21160;&#24577;&#21152;&#36895;&#27169;&#25311;&#65292;&#20026;&#20934;&#30830;&#39044;&#27979;&#22797;&#26434;&#31995;&#32479;&#30340;&#32479;&#35745;&#24615;&#36136;&#25552;&#20379;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#29992;&#20110;&#36890;&#36807;&#23398;&#20064;&#21644;&#28436;&#21464;&#20854;&#26377;&#25928;&#21160;&#24577;&#21152;&#36895;&#22797;&#26434;&#31995;&#32479;&#27169;&#25311;&#30340;&#29983;&#25104;&#24335;&#27169;&#22411;&#12290;&#22312;&#25552;&#20986;&#30340;&#26377;&#25928;&#21160;&#24577;&#29983;&#25104;&#24335;&#23398;&#20064;&#65288;G-LED&#65289;&#20013;&#65292;&#23558;&#39640;&#32500;&#25968;&#25454;&#30340;&#23454;&#20363;&#36827;&#34892;&#38477;&#37319;&#26679;&#21040;&#19968;&#20010;&#32463;&#36807;&#33258;&#22238;&#24402;&#27880;&#24847;&#26426;&#21046;&#28436;&#21270;&#30340;&#20302;&#32500;&#27969;&#24418;&#20013;&#12290;&#21453;&#36807;&#26469;&#65292;&#36125;&#21494;&#26031;&#25193;&#25955;&#27169;&#22411;&#23558;&#36825;&#20010;&#20302;&#32500;&#27969;&#24418;&#26144;&#23556;&#21040;&#20854;&#30456;&#24212;&#30340;&#39640;&#32500;&#31354;&#38388;&#65292;&#25429;&#25417;&#31995;&#32479;&#21160;&#24577;&#30340;&#32479;&#35745;&#20449;&#24687;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;G-LED&#22312;&#20960;&#20010;&#22522;&#20934;&#31995;&#32479;&#30340;&#27169;&#25311;&#20013;&#30340;&#33021;&#21147;&#21644;&#32570;&#38519;&#65292;&#21253;&#25324;Kuramoto-Sivashinsky&#65288;KS&#65289;&#26041;&#31243;&#65292;&#21453;&#21521;&#33033;&#20914;&#21518;&#26041;&#39640;&#38647;&#35834;&#25968;&#27969;&#20307;&#30340;&#20108;&#32500;&#27969;&#21160;&#65292;&#20197;&#21450;&#19977;&#32500;&#28237;&#27969;&#36890;&#36947;&#27969;&#30340;&#27169;&#25311;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#29983;&#25104;&#24335;&#23398;&#20064;&#20026;&#20934;&#30830;&#39044;&#27979;&#22797;&#26434;&#31995;&#32479;&#30340;&#32479;&#35745;&#24615;&#36136;&#24320;&#36767;&#20102;&#26032;&#30340;&#21069;&#27839;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17157v1 Announce Type: new  Abstract: We introduce generative models for accelerating simulations of complex systems through learning and evolving their effective dynamics. In the proposed Generative Learning of Effective Dynamics (G-LED), instances of high dimensional data are down sampled to a lower dimensional manifold that is evolved through an auto-regressive attention mechanism. In turn, Bayesian diffusion models, that map this low-dimensional manifold onto its corresponding high-dimensional space, capture the statistics of the system dynamics. We demonstrate the capabilities and drawbacks of G-LED in simulations of several benchmark systems, including the Kuramoto-Sivashinsky (KS) equation, two-dimensional high Reynolds number flow over a backward-facing step, and simulations of three-dimensional turbulent channel flow. The results demonstrate that generative learning offers new frontiers for the accurate forecasting of the statistical properties of complex systems at
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#25968;&#25454;&#38598;&#29305;&#24615;&#37327;&#36523;&#23450;&#21046;&#30340;&#36817;&#20284;&#20844;&#24179;&#24615;-&#20934;&#30830;&#24615;&#26435;&#34913;&#26354;&#32447;&#35745;&#31639;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#20943;&#36731;&#35757;&#32451;&#22810;&#20010;&#27169;&#22411;&#30340;&#35745;&#31639;&#36127;&#25285;&#24182;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#32479;&#35745;&#20445;&#35777;</title><link>https://arxiv.org/abs/2402.17106</link><description>&lt;p&gt;
&#25968;&#25454;&#38598;&#20844;&#24179;&#24615;&#65306;&#22312;&#24744;&#30340;&#25968;&#25454;&#19978;&#23454;&#29616;&#20855;&#26377;&#25928;&#29992;&#20445;&#35777;&#30340;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Dataset Fairness: Achievable Fairness on Your Data With Utility Guarantees
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17106
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#25968;&#25454;&#38598;&#29305;&#24615;&#37327;&#36523;&#23450;&#21046;&#30340;&#36817;&#20284;&#20844;&#24179;&#24615;-&#20934;&#30830;&#24615;&#26435;&#34913;&#26354;&#32447;&#35745;&#31639;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#20943;&#36731;&#35757;&#32451;&#22810;&#20010;&#27169;&#22411;&#30340;&#35745;&#31639;&#36127;&#25285;&#24182;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#32479;&#35745;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#20844;&#24179;&#24615;&#20013;&#65292;&#35757;&#32451;&#33021;&#22815;&#26368;&#23567;&#21270;&#19981;&#21516;&#25935;&#24863;&#32676;&#20307;&#20043;&#38388;&#24046;&#24322;&#30340;&#27169;&#22411;&#36890;&#24120;&#20250;&#23548;&#33268;&#20934;&#30830;&#24615;&#19979;&#38477;&#65292;&#36825;&#31181;&#29616;&#35937;&#34987;&#31216;&#20026;&#20844;&#24179;&#24615;-&#20934;&#30830;&#24615;&#26435;&#34913;&#12290;&#36825;&#31181;&#26435;&#34913;&#30340;&#20005;&#37325;&#31243;&#24230;&#22522;&#26412;&#21462;&#20915;&#20110;&#25968;&#25454;&#38598;&#30340;&#29305;&#24615;&#65292;&#22914;&#25968;&#25454;&#38598;&#30340;&#19981;&#22343;&#34913;&#25110;&#20559;&#35265;&#12290;&#22240;&#27492;&#65292;&#22312;&#25968;&#25454;&#38598;&#20043;&#38388;&#20351;&#29992;&#32479;&#19968;&#30340;&#20844;&#24179;&#24615;&#35201;&#27714;&#20173;&#28982;&#20540;&#24471;&#24576;&#30097;&#65292;&#24182;&#19988;&#24448;&#24448;&#20250;&#23548;&#33268;&#25928;&#29992;&#26497;&#20302;&#30340;&#27169;&#22411;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#21333;&#20010;&#25968;&#25454;&#38598;&#37327;&#36523;&#23450;&#21046;&#30340;&#36817;&#20284;&#20844;&#24179;&#24615;-&#20934;&#30830;&#24615;&#26435;&#34913;&#26354;&#32447;&#30340;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#25903;&#25345;&#20005;&#26684;&#30340;&#32479;&#35745;&#20445;&#35777;&#12290;&#36890;&#36807;&#21033;&#29992;You-Only-Train-Once&#65288;YOTO&#65289;&#26694;&#26550;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20943;&#36731;&#20102;&#22312;&#36924;&#36817;&#26435;&#34913;&#26354;&#32447;&#26102;&#38656;&#35201;&#35757;&#32451;&#22810;&#20010;&#27169;&#22411;&#30340;&#35745;&#31639;&#36127;&#25285;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#35813;&#26354;&#32447;&#21608;&#22260;&#24341;&#20837;&#32622;&#20449;&#21306;&#38388;&#26469;&#37327;&#21270;&#25105;&#20204;&#36817;&#20284;&#20540;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17106v1 Announce Type: cross  Abstract: In machine learning fairness, training models which minimize disparity across different sensitive groups often leads to diminished accuracy, a phenomenon known as the fairness-accuracy trade-off. The severity of this trade-off fundamentally depends on dataset characteristics such as dataset imbalances or biases. Therefore using a uniform fairness requirement across datasets remains questionable and can often lead to models with substantially low utility. To address this, we present a computationally efficient approach to approximate the fairness-accuracy trade-off curve tailored to individual datasets, backed by rigorous statistical guarantees. By utilizing the You-Only-Train-Once (YOTO) framework, our approach mitigates the computational burden of having to train multiple models when approximating the trade-off curve. Moreover, we quantify the uncertainty in our approximation by introducing confidence intervals around this curve, offe
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#22522;&#20110;&#35745;&#31639;&#26426;&#35270;&#35273;&#30340;&#20449;&#21495;&#20998;&#31867;&#22120;&#23545;&#29289;&#29702;&#20449;&#21495;&#30340;&#23545;&#25239;&#25200;&#21160;&#30340;&#33030;&#24369;&#24615;&#65292;&#36890;&#36807;&#24341;&#20837;PDE&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#26500;&#36896;&#24178;&#25200;&#20449;&#21495;&#65292;&#25104;&#21151;&#23454;&#29616;&#23545;&#26816;&#27979;&#22120;&#30340;&#35823;&#20998;&#31867;&#65292;&#23545;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#25552;&#20986;&#20102;&#39640;&#25928;&#26041;&#27861;&#65292;&#23454;&#39564;&#35777;&#26126;&#21487;&#20197;&#35745;&#31639;&#20986;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#23545;&#25239;&#25200;&#21160;&#12290;</title><link>https://arxiv.org/abs/2402.17104</link><description>&lt;p&gt;
&#29289;&#29702;&#20449;&#21495;&#30340;&#23545;&#25239;&#25200;&#21160;
&lt;/p&gt;
&lt;p&gt;
Adversarial Perturbations of Physical Signals
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17104
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#22522;&#20110;&#35745;&#31639;&#26426;&#35270;&#35273;&#30340;&#20449;&#21495;&#20998;&#31867;&#22120;&#23545;&#29289;&#29702;&#20449;&#21495;&#30340;&#23545;&#25239;&#25200;&#21160;&#30340;&#33030;&#24369;&#24615;&#65292;&#36890;&#36807;&#24341;&#20837;PDE&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#26500;&#36896;&#24178;&#25200;&#20449;&#21495;&#65292;&#25104;&#21151;&#23454;&#29616;&#23545;&#26816;&#27979;&#22120;&#30340;&#35823;&#20998;&#31867;&#65292;&#23545;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#25552;&#20986;&#20102;&#39640;&#25928;&#26041;&#27861;&#65292;&#23454;&#39564;&#35777;&#26126;&#21487;&#20197;&#35745;&#31639;&#20986;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#23545;&#25239;&#25200;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#35745;&#31639;&#26426;&#35270;&#35273;&#30340;&#20449;&#21495;&#20998;&#31867;&#22120;&#23545;&#20854;&#36755;&#20837;&#30340;&#23545;&#25239;&#25200;&#21160;&#30340;&#33030;&#24369;&#24615;&#65292;&#20854;&#20013;&#20449;&#21495;&#21644;&#25200;&#21160;&#21463;&#29289;&#29702;&#32422;&#26463;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#36825;&#26679;&#19968;&#20010;&#24773;&#26223;&#65306;&#19968;&#20010;&#28304;&#21644;&#24178;&#25200;&#22120;&#21457;&#20986;&#20449;&#21495;&#20316;&#20026;&#27874;&#20256;&#25773;&#21040;&#26816;&#27979;&#22120;&#65292;&#26816;&#27979;&#22120;&#35797;&#22270;&#36890;&#36807;&#20998;&#26512;&#25509;&#25910;&#21040;&#30340;&#20449;&#21495;&#30340;&#39057;&#35889;&#22270;&#26469;&#20998;&#31867;&#28304;&#65292;&#20351;&#29992;&#19968;&#20010;&#39044;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#36890;&#36807;&#27714;&#35299;PDE&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#65292;&#25105;&#20204;&#26500;&#36896;&#24178;&#25200;&#20449;&#21495;&#65292;&#21363;&#20351;&#23545;&#25509;&#25910;&#21040;&#30340;&#20449;&#21495;&#30340;&#39057;&#35889;&#22270;&#30340;&#25200;&#21160;&#20960;&#20046;&#19981;&#21487;&#23519;&#35273;&#65292;&#20063;&#20250;&#23548;&#33268;&#26816;&#27979;&#22120;&#23545;&#28304;&#36827;&#34892;&#38169;&#35823;&#20998;&#31867;&#12290;&#34429;&#28982;&#36825;&#31867;&#38382;&#39064;&#21487;&#33021;&#21253;&#21547;&#25968;&#30334;&#19975;&#20010;&#20915;&#31574;&#21464;&#37327;&#65292;&#20294;&#25105;&#20204;&#24341;&#20837;&#20102;&#26377;&#25928;&#27714;&#35299;&#23427;&#20204;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#21487;&#20197;&#20026;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#19981;&#21516;&#30340;&#29289;&#29702;&#32422;&#26463;&#19979;&#35745;&#31639;&#20986;&#26377;&#25928;&#19988;&#29289;&#29702;&#21487;&#23454;&#29616;&#30340;&#23545;&#25239;&#25200;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17104v1 Announce Type: new  Abstract: We investigate the vulnerability of computer-vision-based signal classifiers to adversarial perturbations of their inputs, where the signals and perturbations are subject to physical constraints. We consider a scenario in which a source and interferer emit signals that propagate as waves to a detector, which attempts to classify the source by analyzing the spectrogram of the signal it receives using a pre-trained neural network. By solving PDE-constrained optimization problems, we construct interfering signals that cause the detector to misclassify the source even though the perturbations to the spectrogram of the received signal are nearly imperceptible. Though such problems can have millions of decision variables, we introduce methods to solve them efficiently. Our experiments demonstrate that one can compute effective and physically realizable adversarial perturbations for a variety of machine learning models under various physical co
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25552;&#20986;&#20004;&#21442;&#25968;&#27169;&#22411;&#21644;&#26799;&#24230;&#27969;&#23398;&#20064;&#39640;&#32500;&#30446;&#26631;&#30340;&#29702;&#35770;&#21487;&#33021;&#24615;&#65292;&#30740;&#31350;&#21457;&#29616;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#23384;&#22312;&#22823;&#37327;&#19981;&#21487;&#23398;&#20064;&#30446;&#26631;&#65292;&#24182;&#19988;&#36825;&#20123;&#30446;&#26631;&#30340;&#38598;&#21512;&#19981;&#23494;&#38598;&#65292;&#20855;&#26377;&#19968;&#23450;&#25299;&#25169;&#24615;&#36136;&#30340;&#23376;&#38598;&#20013;&#20063;&#23384;&#22312;&#19981;&#21487;&#23398;&#20064;&#30446;&#26631;&#12290;&#26368;&#32456;&#65292;&#21457;&#29616;&#20351;&#29992;&#23618;&#27425;&#36807;&#31243;&#26500;&#24314;&#30340;&#20027;&#35201;&#23450;&#29702;&#27169;&#22411;&#22312;&#25968;&#23398;&#34920;&#36798;&#19978;&#24182;&#38750;&#30001;&#21333;&#19968;&#21021;&#31561;&#20989;&#25968;&#34920;&#31034;&#12290;</title><link>https://arxiv.org/abs/2402.17089</link><description>&lt;p&gt;
&#36890;&#36807;&#20004;&#21442;&#25968;&#27169;&#22411;&#21644;&#26799;&#24230;&#27969;&#23398;&#20064;&#39640;&#32500;&#30446;&#26631;
&lt;/p&gt;
&lt;p&gt;
Learning high-dimensional targets by two-parameter models and gradient flow
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17089
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20986;&#20004;&#21442;&#25968;&#27169;&#22411;&#21644;&#26799;&#24230;&#27969;&#23398;&#20064;&#39640;&#32500;&#30446;&#26631;&#30340;&#29702;&#35770;&#21487;&#33021;&#24615;&#65292;&#30740;&#31350;&#21457;&#29616;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#23384;&#22312;&#22823;&#37327;&#19981;&#21487;&#23398;&#20064;&#30446;&#26631;&#65292;&#24182;&#19988;&#36825;&#20123;&#30446;&#26631;&#30340;&#38598;&#21512;&#19981;&#23494;&#38598;&#65292;&#20855;&#26377;&#19968;&#23450;&#25299;&#25169;&#24615;&#36136;&#30340;&#23376;&#38598;&#20013;&#20063;&#23384;&#22312;&#19981;&#21487;&#23398;&#20064;&#30446;&#26631;&#12290;&#26368;&#32456;&#65292;&#21457;&#29616;&#20351;&#29992;&#23618;&#27425;&#36807;&#31243;&#26500;&#24314;&#30340;&#20027;&#35201;&#23450;&#29702;&#27169;&#22411;&#22312;&#25968;&#23398;&#34920;&#36798;&#19978;&#24182;&#38750;&#30001;&#21333;&#19968;&#21021;&#31561;&#20989;&#25968;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25506;&#35752;&#20102;&#24403;$W&lt;d$&#26102;&#65292;&#36890;&#36807;&#26799;&#24230;&#27969;&#65288;GF&#65289;&#20197;$W$&#21442;&#25968;&#27169;&#22411;&#23398;&#20064;$d$&#32500;&#30446;&#26631;&#30340;&#29702;&#35770;&#21487;&#33021;&#24615;&#65292;&#24517;&#28982;&#23384;&#22312;GF-&#19981;&#21487;&#23398;&#20064;&#30446;&#26631;&#30340;&#22823;&#23376;&#38598;&#12290;&#29305;&#21035;&#26159;&#65292;&#21487;&#23398;&#20064;&#30446;&#26631;&#30340;&#38598;&#21512;&#22312;$\mathbb R^d$&#20013;&#19981;&#26159;&#23494;&#38598;&#30340;&#65292;&#20219;&#20309;&#24418;&#21516;$W$&#32500;&#29699;&#38754;&#30340;$\mathbb R^d$&#23376;&#38598;&#21253;&#21547;&#19981;&#21487;&#23398;&#20064;&#30446;&#26631;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#22312;&#20960;&#20046;&#20445;&#35777;&#20108;&#21442;&#25968;&#23398;&#20064;&#30340;&#20027;&#35201;&#23450;&#29702;&#20013;&#65292;&#25152;&#36848;&#27169;&#22411;&#26159;&#36890;&#36807;&#23618;&#27425;&#36807;&#31243;&#26500;&#24314;&#30340;&#65292;&#22240;&#27492;&#19981;&#33021;&#29992;&#21333;&#20010;&#21021;&#31561;&#20989;&#25968;&#34920;&#36798;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#38480;&#21046;&#22312;&#26412;&#36136;&#19978;&#26159;&#24517;&#35201;&#30340;&#65292;&#22240;&#20026;&#36825;&#31181;&#21487;&#23398;&#20064;&#24615;&#23545;&#20110;&#35768;&#22810;&#21021;&#31561;&#20989;&#25968;&#31867;&#30340;&#21487;&#23398;&#20064;&#24615;&#26159;&#34987;&#25490;&#38500;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17089v1 Announce Type: cross  Abstract: We explore the theoretical possibility of learning $d$-dimensional targets with $W$-parameter models by gradient flow (GF) when $W&lt;d$ there is necessarily a large subset of GF-non-learnable targets. In particular, the set of learnable targets is not dense in $\mathbb R^d$, and any subset of $\mathbb R^d$ homeomorphic to the $W$-dimensional sphere contains non-learnable targets. Finally, we observe that the model in our main theorem on almost guaranteed two-parameter learning is constructed using a hierarchical procedure and as a result is not expressible by a single elementary function. We show that this limitation is essential in the sense that such learnability can be ruled out for a large class of elementary functions.
&lt;/p&gt;</description></item><item><title>&#20174;&#36125;&#21494;&#26031;&#32593;&#32476;&#35745;&#31639;&#20986;&#30340;&#25968;&#25454;&#38598;&#30340;&#20284;&#28982;&#24615;&#20027;&#35201;&#30001;&#32463;&#39564;&#32593;&#32476;&#30340;&#20284;&#28982;&#24615;&#30340;&#20840;&#23616;&#26368;&#22823;&#20540;&#25152;&#20027;&#23548;&#65292;&#24182;&#19988;&#20165;&#24403;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#21442;&#25968;&#19982;&#32463;&#39564;&#27169;&#22411;&#30340;&#21442;&#25968;&#19968;&#33268;&#26102;&#65292;&#36825;&#26679;&#30340;&#26368;&#22823;&#20540;&#25165;&#20250;&#34987;&#23454;&#29616;&#12290;</title><link>https://arxiv.org/abs/2402.17087</link><description>&lt;p&gt;
&#20851;&#20110;&#20855;&#26377;&#28508;&#22312;&#26681;&#21464;&#37327;&#30340;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#27880;&#35299;
&lt;/p&gt;
&lt;p&gt;
A Note on Bayesian Networks with Latent Root Variables
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17087
&lt;/p&gt;
&lt;p&gt;
&#20174;&#36125;&#21494;&#26031;&#32593;&#32476;&#35745;&#31639;&#20986;&#30340;&#25968;&#25454;&#38598;&#30340;&#20284;&#28982;&#24615;&#20027;&#35201;&#30001;&#32463;&#39564;&#32593;&#32476;&#30340;&#20284;&#28982;&#24615;&#30340;&#20840;&#23616;&#26368;&#22823;&#20540;&#25152;&#20027;&#23548;&#65292;&#24182;&#19988;&#20165;&#24403;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#21442;&#25968;&#19982;&#32463;&#39564;&#27169;&#22411;&#30340;&#21442;&#25968;&#19968;&#33268;&#26102;&#65292;&#36825;&#26679;&#30340;&#26368;&#22823;&#20540;&#25165;&#20250;&#34987;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#34920;&#24449;&#20102;&#20174;&#20855;&#26377;&#28508;&#22312;&#26681;&#33410;&#28857;&#30340;&#36125;&#21494;&#26031;&#32593;&#32476;&#35745;&#31639;&#20986;&#30340;&#20284;&#28982;&#20989;&#25968;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#23545;&#20110;&#21097;&#20313;&#30340;&#26174;&#24615;&#21464;&#37327;&#30340;&#36793;&#32536;&#20998;&#24067;&#20063;&#20250;&#20687;&#19968;&#20010;&#36125;&#21494;&#26031;&#32593;&#32476;&#19968;&#26679;&#20998;&#35299;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#32463;&#39564;&#21270;&#12290;&#19968;&#32452;&#35266;&#27979;&#21040;&#30340;&#26174;&#24615;&#21464;&#37327;&#30340;&#25968;&#25454;&#38598;&#20351;&#25105;&#20204;&#33021;&#22815;&#37327;&#21270;&#32463;&#39564;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#21442;&#25968;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;(i)&#20174;&#21407;&#22987;&#36125;&#21494;&#26031;&#32593;&#32476;&#35745;&#31639;&#20986;&#36825;&#26679;&#19968;&#20010;&#25968;&#25454;&#38598;&#30340;&#20284;&#28982;&#24615;&#30001;&#32463;&#39564;&#21270;&#27169;&#22411;&#30340;&#20284;&#28982;&#24615;&#30340;&#20840;&#23616;&#26368;&#22823;&#20540;&#25152;&#20027;&#23548;&#65307;&#20197;&#21450;(ii)&#36825;&#26679;&#19968;&#20010;&#26368;&#22823;&#20540;&#20165;&#22312;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#21442;&#25968;&#19982;&#32463;&#39564;&#27169;&#22411;&#30340;&#21442;&#25968;&#19968;&#33268;&#26102;&#25165;&#20250;&#36798;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17087v1 Announce Type: cross  Abstract: We characterise the likelihood function computed from a Bayesian network with latent variables as root nodes. We show that the marginal distribution over the remaining, manifest, variables also factorises as a Bayesian network, which we call empirical. A dataset of observations of the manifest variables allows us to quantify the parameters of the empirical Bayesian net. We prove that (i) the likelihood of such a dataset from the original Bayesian network is dominated by the global maximum of the likelihood from the empirical one; and that (ii) such a maximum is attained if and only if the parameters of the Bayesian network are consistent with those of the empirical model.
&lt;/p&gt;</description></item><item><title>&#22312;&#35813;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26391;&#20043;&#20961;&#25193;&#25955;&#21644;&#26410;&#35843;&#25972;&#26391;&#20043;&#20961;&#31639;&#27861;&#20013;&#38543;&#26426;&#21464;&#37327;&#29420;&#31435;&#21270;&#36895;&#29575;&#30340;&#25910;&#25947;&#24615;&#65292;&#35777;&#26126;&#20102;&#22312;&#30446;&#26631;&#20989;&#25968;&#24378;&#23545;&#25968;&#20985;&#21644;&#24179;&#28369;&#30340;&#24773;&#20917;&#19979;&#65292;&#20114;&#20449;&#24687;&#20250;&#20197;&#25351;&#25968;&#36895;&#29575;&#25910;&#25947;&#20110;$0$&#12290;</title><link>https://arxiv.org/abs/2402.17067</link><description>&lt;p&gt;
&#20851;&#20110;&#26391;&#20043;&#20961;&#25193;&#25955;&#21644;&#26410;&#35843;&#25972;&#26391;&#20043;&#20961;&#31639;&#27861;&#20013;&#29420;&#31435;&#26679;&#26412;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Independent Samples Along the Langevin Diffusion and the Unadjusted Langevin Algorithm
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17067
&lt;/p&gt;
&lt;p&gt;
&#22312;&#35813;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26391;&#20043;&#20961;&#25193;&#25955;&#21644;&#26410;&#35843;&#25972;&#26391;&#20043;&#20961;&#31639;&#27861;&#20013;&#38543;&#26426;&#21464;&#37327;&#29420;&#31435;&#21270;&#36895;&#29575;&#30340;&#25910;&#25947;&#24615;&#65292;&#35777;&#26126;&#20102;&#22312;&#30446;&#26631;&#20989;&#25968;&#24378;&#23545;&#25968;&#20985;&#21644;&#24179;&#28369;&#30340;&#24773;&#20917;&#19979;&#65292;&#20114;&#20449;&#24687;&#20250;&#20197;&#25351;&#25968;&#36895;&#29575;&#25910;&#25947;&#20110;$0$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#39532;&#23572;&#21487;&#22827;&#38142;&#20013;&#21021;&#22987;&#21644;&#24403;&#21069;&#38543;&#26426;&#21464;&#37327;&#29420;&#31435;&#21270;&#30340;&#36895;&#29575;&#65292;&#37325;&#28857;&#20851;&#27880;&#36830;&#32493;&#26102;&#38388;&#20013;&#30340;&#26391;&#20043;&#20961;&#25193;&#25955;&#21644;&#31163;&#25955;&#26102;&#38388;&#20013;&#30340;&#26410;&#35843;&#25972;&#26391;&#20043;&#20961;&#31639;&#27861;&#65288;ULA&#65289;&#12290;&#25105;&#20204;&#36890;&#36807;&#23427;&#20204;&#30340;&#20114;&#20449;&#24687;&#24230;&#37327;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#23545;&#20110;&#26391;&#20043;&#20961;&#25193;&#25955;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#30446;&#26631;&#20989;&#25968;&#24378;&#23545;&#25968;&#20985;&#26102;&#65292;&#20114;&#20449;&#24687;&#20197;&#25351;&#25968;&#36895;&#29575;&#25910;&#25947;&#20110;$0$&#65292;&#24403;&#30446;&#26631;&#20989;&#25968;&#24369;&#23545;&#25968;&#20985;&#26102;&#65292;&#20197;&#22810;&#39033;&#24335;&#36895;&#29575;&#25910;&#25947;&#12290;&#36825;&#20123;&#36895;&#29575;&#31867;&#20284;&#20110;&#22312;&#31867;&#20284;&#26465;&#20214;&#19979;&#26391;&#20043;&#20961;&#25193;&#25955;&#30340;&#28151;&#21512;&#26102;&#38388;&#12290;&#23545;&#20110;ULA&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#30446;&#26631;&#20989;&#25968;&#24378;&#23545;&#25968;&#20985;&#19988;&#20809;&#28369;&#26102;&#65292;&#20114;&#20449;&#24687;&#20197;&#25351;&#25968;&#36895;&#29575;&#25910;&#25947;&#20110;$0$&#12290;&#25105;&#20204;&#36890;&#36807;&#21457;&#23637;&#36825;&#20123;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#20114;&#20449;&#24687;&#29256;&#26412;&#30340;&#28151;&#21512;&#26102;&#38388;&#20998;&#26512;&#26469;&#35777;&#26126;&#25105;&#20204;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#22522;&#20110;&#26391;&#20043;&#20961;&#25193;&#25955;&#30340;&#24378;&#25968;&#25454;&#22788;&#29702;&#19981;&#31561;&#24335;&#30340;&#26367;&#20195;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17067v1 Announce Type: cross  Abstract: We study the rate at which the initial and current random variables become independent along a Markov chain, focusing on the Langevin diffusion in continuous time and the Unadjusted Langevin Algorithm (ULA) in discrete time. We measure the dependence between random variables via their mutual information. For the Langevin diffusion, we show the mutual information converges to $0$ exponentially fast when the target is strongly log-concave, and at a polynomial rate when the target is weakly log-concave. These rates are analogous to the mixing time of the Langevin diffusion under similar assumptions. For the ULA, we show the mutual information converges to $0$ exponentially fast when the target is strongly log-concave and smooth. We prove our results by developing the mutual version of the mixing time analyses of these Markov chains. We also provide alternative proofs based on strong data processing inequalities for the Langevin diffusion 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36845;&#20195;INLA&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#38750;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#20013;&#25512;&#26029;&#29366;&#24577;&#21644;&#21442;&#25968;&#65292;&#33021;&#22815;&#20445;&#30041;&#21487;&#35299;&#37322;&#24615;&#24182;&#19988;&#36866;&#29992;&#20110;&#20219;&#24847;&#38750;&#32447;&#24615;&#31995;&#32479;&#12290;</title><link>https://arxiv.org/abs/2402.17036</link><description>&lt;p&gt;
&#36845;&#20195;INLA&#29992;&#20110;&#38750;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#20013;&#30340;&#29366;&#24577;&#21644;&#21442;&#25968;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Iterated INLA for State and Parameter Estimation in Nonlinear Dynamical Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17036
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36845;&#20195;INLA&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#38750;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#20013;&#25512;&#26029;&#29366;&#24577;&#21644;&#21442;&#25968;&#65292;&#33021;&#22815;&#20445;&#30041;&#21487;&#35299;&#37322;&#24615;&#24182;&#19988;&#36866;&#29992;&#20110;&#20219;&#24847;&#38750;&#32447;&#24615;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#21516;&#21270;&#65288;DA&#65289;&#26041;&#27861;&#20351;&#29992;&#28304;&#33258;&#24494;&#20998;&#26041;&#31243;&#30340;&#20808;&#39564;&#26465;&#20214;&#26469;&#31283;&#20581;&#22320;&#23545;&#25968;&#25454;&#36827;&#34892;&#25554;&#20540;&#21644;&#22806;&#25512;&#12290;&#27969;&#34892;&#30340;&#25216;&#26415;&#65292;&#22914;&#22788;&#29702;&#39640;&#32500;&#38750;&#32447;&#24615;PDE&#20808;&#39564;&#26465;&#20214;&#30340;&#38598;&#21512;&#26041;&#27861;&#65292;&#20027;&#35201;&#20851;&#27880;&#29366;&#24577;&#20272;&#35745;&#65292;&#20294;&#21487;&#33021;&#20250;&#22312;&#23398;&#20064;&#21442;&#25968;&#26041;&#38754;&#36935;&#21040;&#22256;&#38590;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26041;&#27861;&#21487;&#20197;&#33258;&#28982;&#22320;&#23398;&#20064;&#29366;&#24577;&#21644;&#21442;&#25968;&#65292;&#20294;&#23427;&#20204;&#30340;&#36866;&#29992;&#24615;&#21487;&#33021;&#21463;&#21040;&#38480;&#21046;&#65292;&#25110;&#32773;&#20135;&#29983;&#38590;&#20197;&#35299;&#37322;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#21463;&#31354;&#38388;&#32479;&#35745;&#20013;&#38598;&#25104;&#23884;&#22871;&#25289;&#26222;&#25289;&#26031;&#36817;&#20284;&#65288;INLA&#65289;&#26041;&#27861;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36845;&#20195;&#32447;&#24615;&#21270;&#21160;&#21147;&#23398;&#27169;&#22411;&#30340;DA&#26367;&#20195;&#26041;&#27861;&#12290;&#36825;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#20135;&#29983;&#19968;&#20010;&#39640;&#26031;&#39532;&#23572;&#21487;&#22827;&#38543;&#26426;&#22330;&#65292;&#20351;&#24471;&#21487;&#20197;&#20351;&#29992;INLA&#26469;&#25512;&#26029;&#29366;&#24577;&#21644;&#21442;&#25968;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#20219;&#24847;&#38750;&#32447;&#24615;&#31995;&#32479;&#65292;&#21516;&#26102;&#20445;&#25345;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#19988;&#36827;&#19968;&#27493;&#34987;&#35777;&#26126;&#21487;&#20197;o
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17036v1 Announce Type: cross  Abstract: Data assimilation (DA) methods use priors arising from differential equations to robustly interpolate and extrapolate data. Popular techniques such as ensemble methods that handle high-dimensional, nonlinear PDE priors focus mostly on state estimation, however can have difficulty learning the parameters accurately. On the other hand, machine learning based approaches can naturally learn the state and parameters, but their applicability can be limited, or produce uncertainties that are hard to interpret. Inspired by the Integrated Nested Laplace Approximation (INLA) method in spatial statistics, we propose an alternative approach to DA based on iteratively linearising the dynamical model. This produces a Gaussian Markov random field at each iteration, enabling one to use INLA to infer the state and parameters. Our approach can be used for arbitrary nonlinear systems, while retaining interpretability, and is furthermore demonstrated to o
&lt;/p&gt;</description></item><item><title>&#25193;&#25955;&#27169;&#22411;&#22312;&#30740;&#31350;&#25968;&#25454;&#30340;&#20998;&#23618;&#29983;&#25104;&#27169;&#22411;&#20013;&#23637;&#31034;&#20986;&#20102;&#22312;&#38408;&#20540;&#26102;&#38388;&#21457;&#29983;&#30456;&#21464;&#30340;&#29305;&#24615;&#65292;&#36825;&#24433;&#21709;&#20102;&#39640;&#32423;&#29305;&#24449;&#21644;&#20302;&#32423;&#29305;&#24449;&#30340;&#37325;&#24314;&#36807;&#31243;&#12290;</title><link>https://arxiv.org/abs/2402.16991</link><description>&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#20013;&#30340;&#30456;&#21464;&#25581;&#31034;&#20102;&#25968;&#25454;&#30340;&#20998;&#23618;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
A Phase Transition in Diffusion Models Reveals the Hierarchical Nature of Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16991
&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#30740;&#31350;&#25968;&#25454;&#30340;&#20998;&#23618;&#29983;&#25104;&#27169;&#22411;&#20013;&#23637;&#31034;&#20986;&#20102;&#22312;&#38408;&#20540;&#26102;&#38388;&#21457;&#29983;&#30456;&#21464;&#30340;&#29305;&#24615;&#65292;&#36825;&#24433;&#21709;&#20102;&#39640;&#32423;&#29305;&#24449;&#21644;&#20302;&#32423;&#29305;&#24449;&#30340;&#37325;&#24314;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#30495;&#23454;&#25968;&#25454;&#30340;&#32467;&#26500;&#22312;&#25512;&#21160;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#26041;&#38754;&#33267;&#20851;&#37325;&#35201;&#12290;&#33258;&#28982;&#25968;&#25454;&#65292;&#22914;&#22270;&#20687;&#65292;&#34987;&#35748;&#20026;&#26159;&#30001;&#20197;&#23618;&#27425;&#21644;&#32452;&#21512;&#26041;&#24335;&#32452;&#32455;&#30340;&#29305;&#24449;&#32452;&#25104;&#30340;&#65292;&#31070;&#32463;&#32593;&#32476;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#25429;&#25417;&#21040;&#36825;&#20123;&#29305;&#24449;&#12290;&#26368;&#36817;&#30340;&#36827;&#23637;&#26174;&#31034;&#65292;&#25193;&#25955;&#27169;&#22411;&#33021;&#22815;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#22270;&#20687;&#65292;&#26263;&#31034;&#20102;&#23427;&#20204;&#25429;&#25417;&#21040;&#36825;&#31181;&#28508;&#22312;&#32467;&#26500;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#25968;&#25454;&#30340;&#20998;&#23618;&#29983;&#25104;&#27169;&#22411;&#20013;&#30340;&#36825;&#19968;&#29616;&#35937;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#26102;&#38388;$t$&#21518;&#20316;&#29992;&#30340;&#21453;&#21521;&#25193;&#25955;&#36807;&#31243;&#21463;&#21040;&#26576;&#20010;&#38408;&#20540;&#26102;&#38388;&#22788;&#30340;&#30456;&#21464;&#25511;&#21046;&#65292;&#27492;&#26102;&#37325;&#24314;&#39640;&#32423;&#29305;&#24449;&#65288;&#22914;&#22270;&#20687;&#30340;&#31867;&#21035;&#65289;&#30340;&#27010;&#29575;&#31361;&#28982;&#19979;&#38477;&#12290;&#30456;&#21453;&#65292;&#20302;&#32423;&#29305;&#24449;&#65288;&#22914;&#22270;&#20687;&#30340;&#20855;&#20307;&#32454;&#33410;&#65289;&#30340;&#37325;&#24314;&#22312;&#25972;&#20010;&#25193;&#25955;&#36807;&#31243;&#20013;&#24179;&#31283;&#28436;&#21464;&#12290;&#36825;&#19968;&#32467;&#26524;&#26263;&#31034;&#65292;&#22312;&#36229;&#20986;&#36716;&#21464;&#26102;&#38388;&#30340;&#26102;&#21051;&#65292;&#31867;&#21035;&#24050;&#21464;&#21270;&#65292;&#20294;&#26159;&#22522;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16991v1 Announce Type: cross  Abstract: Understanding the structure of real data is paramount in advancing modern deep-learning methodologies. Natural data such as images are believed to be composed of features organised in a hierarchical and combinatorial manner, which neural networks capture during learning. Recent advancements show that diffusion models can generate high-quality images, hinting at their ability to capture this underlying structure. We study this phenomenon in a hierarchical generative model of data. We find that the backward diffusion process acting after a time $t$ is governed by a phase transition at some threshold time, where the probability of reconstructing high-level features, like the class of an image, suddenly drops. Instead, the reconstruction of low-level features, such as specific details of an image, evolves smoothly across the whole diffusion process. This result implies that at times beyond the transition, the class has changed but the gene
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#20013;&#21518;&#38376;&#26816;&#27979;&#38382;&#39064;&#30340;&#27491;&#24335;&#32479;&#35745;&#23450;&#20041;&#65292;&#24182;&#24471;&#20986;&#20102;&#21518;&#38376;&#26816;&#27979;&#30340;&#19981;&#21487;&#33021;&#24615;&#19982;&#21487;&#23454;&#29616;&#24615;&#32467;&#26524;&#65292;&#25351;&#20986;&#20102;&#36890;&#29992;&#21518;&#38376;&#26816;&#27979;&#30340;&#23616;&#38480;&#24615;&#65292;&#24378;&#35843;&#21518;&#38376;&#26816;&#27979;&#26041;&#27861;&#38656;&#35201;&#32771;&#34385;&#25932;&#23545;&#22240;&#32032;&#12290;</title><link>https://arxiv.org/abs/2402.16926</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#21518;&#38376;&#26816;&#27979;&#30340;&#21487;&#34892;&#24615;&#38382;&#39064;&#20316;&#20026;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#30340;&#25506;&#35752;
&lt;/p&gt;
&lt;p&gt;
On the (In)feasibility of ML Backdoor Detection as an Hypothesis Testing Problem
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16926
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#20013;&#21518;&#38376;&#26816;&#27979;&#38382;&#39064;&#30340;&#27491;&#24335;&#32479;&#35745;&#23450;&#20041;&#65292;&#24182;&#24471;&#20986;&#20102;&#21518;&#38376;&#26816;&#27979;&#30340;&#19981;&#21487;&#33021;&#24615;&#19982;&#21487;&#23454;&#29616;&#24615;&#32467;&#26524;&#65292;&#25351;&#20986;&#20102;&#36890;&#29992;&#21518;&#38376;&#26816;&#27979;&#30340;&#23616;&#38480;&#24615;&#65292;&#24378;&#35843;&#21518;&#38376;&#26816;&#27979;&#26041;&#27861;&#38656;&#35201;&#32771;&#34385;&#25932;&#23545;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#27491;&#24335;&#30340;&#32479;&#35745;&#23398;&#23450;&#20041;&#65292;&#29992;&#20110;&#20998;&#26512;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#20013;&#30340;&#21518;&#38376;&#26816;&#27979;&#38382;&#39064;&#30340;&#21487;&#34892;&#24615;&#65292;&#24182;&#20351;&#29992;&#23427;&#26469;&#20998;&#26512;&#36825;&#20123;&#38382;&#39064;&#30340;&#21487;&#34892;&#24615;&#65292;&#25552;&#20379;&#20102;&#23545;&#25105;&#20204;&#23450;&#20041;&#30340;&#23454;&#29992;&#24615;&#21644;&#36866;&#29992;&#24615;&#30340;&#35777;&#25454;&#12290;&#36825;&#39033;&#24037;&#20316;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#23545;&#21518;&#38376;&#26816;&#27979;&#30340;&#19981;&#21487;&#33021;&#24615;&#32467;&#26524;&#21644;&#21487;&#23454;&#29616;&#24615;&#32467;&#26524;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#27809;&#26377;&#20813;&#36153;&#21320;&#39184;&#23450;&#29702;&#65292;&#35777;&#26126;&#20102;&#36890;&#29992;&#65288;&#23545;&#25932;&#26041;&#19981;&#30693;&#24773;&#65289;&#21518;&#38376;&#26816;&#27979;&#26159;&#19981;&#21487;&#33021;&#30340;&#65292;&#38500;&#38750;Alphabet&#22823;&#23567;&#38750;&#24120;&#23567;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#35748;&#20026;&#65292;&#21518;&#38376;&#26816;&#27979;&#26041;&#27861;&#38656;&#35201;&#26126;&#30830;&#22320;&#25110;&#38544;&#24335;&#22320;&#32771;&#34385;&#25932;&#23545;&#22240;&#32032;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#24182;&#19981;&#24847;&#21619;&#30528;&#21518;&#38376;&#26816;&#27979;&#22312;&#29305;&#23450;&#22330;&#26223;&#19979;&#19981;&#33021;&#36215;&#20316;&#29992;&#65292;&#22240;&#20026;&#31185;&#23398;&#25991;&#29486;&#20013;&#25104;&#21151;&#30340;&#21518;&#38376;&#26816;&#27979;&#26041;&#27861;&#35777;&#26126;&#20102;&#36825;&#19968;&#28857;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#23450;&#20041;&#19982;&#22823;&#27010;&#36817;&#20284;&#27491;&#30830;&#65288;PAC&#65289;&#23398;&#20064;&#19982;&#22806;&#20998;&#24067;&#26816;&#27979;&#38382;&#39064;&#32852;&#31995;&#36215;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16926v1 Announce Type: cross  Abstract: We introduce a formal statistical definition for the problem of backdoor detection in machine learning systems and use it to analyze the feasibility of such problems, providing evidence for the utility and applicability of our definition. The main contributions of this work are an impossibility result and an achievability result for backdoor detection. We show a no-free-lunch theorem, proving that universal (adversary-unaware) backdoor detection is impossible, except for very small alphabet sizes. Thus, we argue, that backdoor detection methods need to be either explicitly, or implicitly adversary-aware. However, our work does not imply that backdoor detection cannot work in specific scenarios, as evidenced by successful backdoor detection methods in the scientific literature. Furthermore, we connect our definition to the probably approximately correct (PAC) learnability of the out-of-distribution detection problem.
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;MIM-Reasoner&#65292;&#32467;&#21512;&#24378;&#21270;&#23398;&#20064;&#21644;&#27010;&#29575;&#22270;&#27169;&#22411;&#65292;&#26377;&#25928;&#22320;&#25429;&#25417;&#20102;&#32473;&#23450;&#22810;&#37325;&#32593;&#32476;&#20869;&#37096;&#21644;&#23618;&#38388;&#30340;&#22797;&#26434;&#20256;&#25773;&#36807;&#31243;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;MIM&#20013;&#26368;&#20855;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.16898</link><description>&lt;p&gt;
MIM-Reasoner: &#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#30340;&#22810;&#37325;&#24433;&#21709;&#26368;&#22823;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
MIM-Reasoner: Learning with Theoretical Guarantees for Multiplex Influence Maximization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16898
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;MIM-Reasoner&#65292;&#32467;&#21512;&#24378;&#21270;&#23398;&#20064;&#21644;&#27010;&#29575;&#22270;&#27169;&#22411;&#65292;&#26377;&#25928;&#22320;&#25429;&#25417;&#20102;&#32473;&#23450;&#22810;&#37325;&#32593;&#32476;&#20869;&#37096;&#21644;&#23618;&#38388;&#30340;&#22797;&#26434;&#20256;&#25773;&#36807;&#31243;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;MIM&#20013;&#26368;&#20855;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#37325;&#24433;&#21709;&#26368;&#22823;&#21270;&#65288;MIM&#65289;&#35201;&#27714;&#25105;&#20204;&#35782;&#21035;&#19968;&#32452;&#31181;&#23376;&#29992;&#25143;&#65292;&#20197;&#26368;&#22823;&#21270;&#22810;&#37325;&#32593;&#32476;&#20013;&#21463;&#24433;&#21709;&#29992;&#25143;&#30340;&#39044;&#26399;&#25968;&#37327;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;MIM-Reasoner&#65292;&#23558;&#24378;&#21270;&#23398;&#20064;&#19982;&#27010;&#29575;&#22270;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#26377;&#25928;&#25429;&#25417;&#32473;&#23450;&#22810;&#37325;&#32593;&#32476;&#20869;&#37096;&#21644;&#23618;&#38388;&#30340;&#22797;&#26434;&#20256;&#25773;&#36807;&#31243;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;MIM&#20013;&#26368;&#20855;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16898v1 Announce Type: cross  Abstract: Multiplex influence maximization (MIM) asks us to identify a set of seed users such as to maximize the expected number of influenced users in a multiplex network. MIM has been one of central research topics, especially in nowadays social networking landscape where users participate in multiple online social networks (OSNs) and their influences can propagate among several OSNs simultaneously. Although there exist a couple combinatorial algorithms to MIM, learning-based solutions have been desired due to its generalization ability to heterogeneous networks and their diversified propagation characteristics. In this paper, we introduce MIM-Reasoner, coupling reinforcement learning with probabilistic graphical model, which effectively captures the complex propagation process within and between layers of a given multiplex network, thereby tackling the most challenging problem in MIM. We establish a theoretical guarantee for MIM-Reasoner as w
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21453;&#39304;&#39640;&#25928;&#30340;&#22312;&#32447;&#24494;&#35843;&#25193;&#25955;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#31243;&#24207;</title><link>https://arxiv.org/abs/2402.16359</link><description>&lt;p&gt;
&#21453;&#39304;&#39640;&#25928;&#22312;&#32447;&#24494;&#35843;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Feedback Efficient Online Fine-Tuning of Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16359
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21453;&#39304;&#39640;&#25928;&#30340;&#22312;&#32447;&#24494;&#35843;&#25193;&#25955;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#31243;&#24207;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#24314;&#27169;&#22797;&#26434;&#25968;&#25454;&#20998;&#24067;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#21253;&#25324;&#22270;&#20687;&#65292;&#34507;&#30333;&#36136;&#21644;&#23567;&#20998;&#23376;&#30340;&#20998;&#24067;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#27169;&#25311;&#26368;&#22823;&#21270;&#26576;&#20123;&#23646;&#24615;&#30340;&#20998;&#24067;&#30340;&#37096;&#20998;&#65306;&#20363;&#22914;&#65292;&#25105;&#20204;&#21487;&#33021;&#24076;&#26395;&#29983;&#25104;&#20855;&#26377;&#39640;&#23457;&#32654;&#36136;&#37327;&#30340;&#22270;&#20687;&#65292;&#25110;&#20855;&#26377;&#39640;&#29983;&#29289;&#27963;&#24615;&#30340;&#20998;&#23376;&#12290;&#33258;&#28982;&#22320;&#65292;&#25105;&#20204;&#21487;&#20197;&#23558;&#36825;&#35270;&#20026;&#19968;&#20010;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#38382;&#39064;&#65292;&#20854;&#30446;&#26631;&#26159;&#24494;&#35843;&#25193;&#25955;&#27169;&#22411;&#20197;&#26368;&#22823;&#21270;&#19982;&#26576;&#20123;&#23646;&#24615;&#23545;&#24212;&#30340;&#22870;&#21169;&#20989;&#25968;&#12290;&#21363;&#20351;&#21487;&#20197;&#35775;&#38382;&#22320;&#38754;&#30495;&#23454;&#22870;&#21169;&#20989;&#25968;&#30340;&#22312;&#32447;&#26597;&#35810;&#65292;&#26377;&#25928;&#22320;&#21457;&#29616;&#39640;&#22870;&#21169;&#26679;&#26412;&#20063;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#65306;&#23427;&#20204;&#22312;&#21021;&#22987;&#20998;&#24067;&#20013;&#30340;&#27010;&#29575;&#21487;&#33021;&#24456;&#20302;&#65292;&#24182;&#19988;&#21487;&#33021;&#23384;&#22312;&#35768;&#22810;&#19981;&#21487;&#34892;&#30340;&#26679;&#26412;&#65292;&#29978;&#33267;&#27809;&#26377;&#23450;&#20041;&#33391;&#22909;&#30340;&#22870;&#21169;&#65288;&#20363;&#22914;&#65292;&#19981;&#33258;&#28982;&#30340;&#22270;&#20687;&#25110;&#29289;&#29702;&#19978;&#19981;&#21487;&#33021;&#30340;&#20998;&#23376;&#65289;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24378;&#21270;&#23398;&#20064;&#31243;&#24207;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#21457;&#29616;&#39640;&#22870;&#21169;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16359v1 Announce Type: cross  Abstract: Diffusion models excel at modeling complex data distributions, including those of images, proteins, and small molecules. However, in many cases, our goal is to model parts of the distribution that maximize certain properties: for example, we may want to generate images with high aesthetic quality, or molecules with high bioactivity. It is natural to frame this as a reinforcement learning (RL) problem, in which the objective is to fine-tune a diffusion model to maximize a reward function that corresponds to some property. Even with access to online queries of the ground-truth reward function, efficiently discovering high-reward samples can be challenging: they might have a low probability in the initial distribution, and there might be many infeasible samples that do not even have a well-defined reward (e.g., unnatural images or physically impossible molecules). In this work, we propose a novel reinforcement learning procedure that effi
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#39034;&#24207;&#38543;&#26426;&#25237;&#24433;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#36890;&#36807;&#26500;&#24314;&#20572;&#27490;&#36807;&#31243;&#24182;&#37319;&#29992;&#28151;&#21512;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#19968;&#31995;&#21015;&#30456;&#20114;&#36830;&#25509;&#30340;&#27987;&#32553;&#20107;&#20214;&#30340;&#20998;&#26512;&#65292;&#20174;&#32780;&#21019;&#36896;&#20102;&#23545;Johnson-Lindenstrauss&#24341;&#29702;&#30340;&#38750;&#24179;&#20961;&#38789;&#25193;&#23637;&#12290;</title><link>https://arxiv.org/abs/2402.14026</link><description>&lt;p&gt;
&#29992;&#20110;&#39034;&#24207;&#38543;&#26426;&#25237;&#24433;&#30340;&#27010;&#29575;&#24037;&#20855;
&lt;/p&gt;
&lt;p&gt;
Probability Tools for Sequential Random Projection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14026
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#39034;&#24207;&#38543;&#26426;&#25237;&#24433;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#36890;&#36807;&#26500;&#24314;&#20572;&#27490;&#36807;&#31243;&#24182;&#37319;&#29992;&#28151;&#21512;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#19968;&#31995;&#21015;&#30456;&#20114;&#36830;&#25509;&#30340;&#27987;&#32553;&#20107;&#20214;&#30340;&#20998;&#26512;&#65292;&#20174;&#32780;&#21019;&#36896;&#20102;&#23545;Johnson-Lindenstrauss&#24341;&#29702;&#30340;&#38750;&#24179;&#20961;&#38789;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#31532;&#19968;&#20010;&#19987;&#20026;&#39034;&#24207;&#38543;&#26426;&#25237;&#24433;&#23450;&#21046;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#36825;&#31181;&#26041;&#27861;&#26893;&#26681;&#20110;&#38754;&#23545;&#19981;&#30830;&#23450;&#24615;&#30340;&#39034;&#24207;&#20915;&#31574;&#30340;&#25361;&#25112;&#12290;&#20998;&#26512;&#21463;&#21040;&#38543;&#26426;&#21464;&#37327;&#30340;&#39034;&#24207;&#20381;&#36182;&#21644;&#39640;&#32500;&#24615;&#36136;&#30340;&#24433;&#21709;&#65292;&#36825;&#26159;&#39034;&#24207;&#20915;&#31574;&#36807;&#31243;&#20013;&#22266;&#26377;&#30340;&#33258;&#36866;&#24212;&#26426;&#21046;&#30340;&#21103;&#20135;&#21697;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#29305;&#28857;&#26159;&#26500;&#24314;&#20102;&#19968;&#20010;&#20572;&#27490;&#36807;&#31243;&#65292;&#20415;&#20110;&#20998;&#26512;&#19968;&#31995;&#21015;&#20197;&#39034;&#24207;&#26041;&#24335;&#30456;&#20114;&#36830;&#25509;&#30340;&#27987;&#32553;&#20107;&#20214;&#12290;&#36890;&#36807;&#22312;&#20174;&#20572;&#27490;&#36807;&#31243;&#24471;&#20986;&#30340;&#33258;&#35268;&#33539;&#36807;&#31243;&#20869;&#37319;&#29992;&#28151;&#21512;&#26041;&#27861;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#25152;&#38656;&#30340;&#38750;&#28176;&#36817;&#27010;&#29575;&#30028;&#38480;&#12290;&#35813;&#30028;&#38480;&#20195;&#34920;&#20102;&#23545;Johnson-Lindenstrauss&#65288;JL&#65289;&#24341;&#29702;&#30340;&#19968;&#20010;&#38750;&#24179;&#20961;&#30340;&#38789;&#25193;&#23637;&#65292;&#26631;&#24535;&#30528;&#23545;&#38543;&#26426;&#25237;&#24433;&#21644;&#39034;&#24207;&#20998;&#26512;&#30340;&#25991;&#29486;&#20570;&#20986;&#20102;&#24320;&#21019;&#24615;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14026v1 Announce Type: cross  Abstract: We introduce the first probabilistic framework tailored for sequential random projection, an approach rooted in the challenges of sequential decision-making under uncertainty. The analysis is complicated by the sequential dependence and high-dimensional nature of random variables, a byproduct of the adaptive mechanisms inherent in sequential decision processes. Our work features a novel construction of a stopped process, facilitating the analysis of a sequence of concentration events that are interconnected in a sequential manner. By employing the method of mixtures within a self-normalized process, derived from the stopped process, we achieve a desired non-asymptotic probability bound. This bound represents a non-trivial martingale extension of the Johnson-Lindenstrauss (JL) lemma, marking a pioneering contribution to the literature on random projection and sequential analysis.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;Johnson-Lindenstrauss&#65288;JL&#65289;&#24341;&#29702;&#30340;&#31616;&#21333;&#32479;&#19968;&#20998;&#26512;&#65292;&#31616;&#21270;&#21644;&#32479;&#19968;&#20102;&#21508;&#31181;&#26500;&#36896;&#65292;&#21253;&#25324;&#29699;&#24418;&#12289;&#39640;&#26031;&#12289;&#20108;&#36827;&#21046;&#30828;&#24065;&#21644;&#27425;&#39640;&#26031;&#27169;&#22411;&#65292;&#36890;&#36807;&#21019;&#26032;&#24615;&#22320;&#23558;Hanson-Wright&#19981;&#31561;&#24335;&#25299;&#23637;&#21040;&#39640;&#32500;&#24230;&#65292;&#26631;&#24535;&#30528;&#23545;&#25968;&#25454;&#22266;&#26377;&#20960;&#20309;&#30340;&#20445;&#25345;&#21462;&#24471;&#37325;&#22823;&#36827;&#23637;&#12290;</title><link>https://arxiv.org/abs/2402.10232</link><description>&lt;p&gt;
Johnson-Lindenstrauss&#30340;&#31616;&#21333;&#32479;&#19968;&#20998;&#26512;&#21450;&#20854;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Simple, unified analysis of Johnson-Lindenstrauss with applications
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10232
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;Johnson-Lindenstrauss&#65288;JL&#65289;&#24341;&#29702;&#30340;&#31616;&#21333;&#32479;&#19968;&#20998;&#26512;&#65292;&#31616;&#21270;&#21644;&#32479;&#19968;&#20102;&#21508;&#31181;&#26500;&#36896;&#65292;&#21253;&#25324;&#29699;&#24418;&#12289;&#39640;&#26031;&#12289;&#20108;&#36827;&#21046;&#30828;&#24065;&#21644;&#27425;&#39640;&#26031;&#27169;&#22411;&#65292;&#36890;&#36807;&#21019;&#26032;&#24615;&#22320;&#23558;Hanson-Wright&#19981;&#31561;&#24335;&#25299;&#23637;&#21040;&#39640;&#32500;&#24230;&#65292;&#26631;&#24535;&#30528;&#23545;&#25968;&#25454;&#22266;&#26377;&#20960;&#20309;&#30340;&#20445;&#25345;&#21462;&#24471;&#37325;&#22823;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Johnson-Lindenstrauss&#65288;JL&#65289;&#24341;&#29702;&#30340;&#31616;&#21333;&#32479;&#19968;&#20998;&#26512;&#65292;&#36825;&#26159;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#33267;&#20851;&#37325;&#35201;&#30340;&#38477;&#32500;&#39046;&#22495;&#20013;&#30340;&#22522;&#30707;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20165;&#31616;&#21270;&#20102;&#29702;&#35299;&#65292;&#36824;&#23558;&#21508;&#31181;&#26500;&#36896;&#32479;&#19968;&#21040;JL&#26694;&#26550;&#19979;&#65292;&#21253;&#25324;&#29699;&#24418;&#12289;&#39640;&#26031;&#12289;&#20108;&#36827;&#21046;&#30828;&#24065;&#21644;&#27425;&#39640;&#26031;&#27169;&#22411;&#12290;&#36825;&#31181;&#31616;&#21270;&#21644;&#32479;&#19968;&#22312;&#20445;&#25345;&#25968;&#25454;&#22266;&#26377;&#20960;&#20309;&#30340;&#37325;&#35201;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#65292;&#23545;&#20174;&#27969;&#31639;&#27861;&#21040;&#24378;&#21270;&#23398;&#20064;&#31561;&#21508;&#31181;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#22312;&#36825;&#20010;&#31616;&#21270;&#26694;&#26550;&#20869;&#25552;&#20986;&#20102;&#29699;&#24418;&#26500;&#36896;&#26377;&#25928;&#24615;&#30340;&#31532;&#19968;&#20010;&#20005;&#26684;&#35777;&#26126;&#12290;&#25105;&#20204;&#36129;&#29486;&#30340;&#26680;&#24515;&#26159;&#23558;Hanson-Wright&#19981;&#31561;&#24335;&#25299;&#23637;&#21040;&#39640;&#32500;&#24230;&#65292;&#20855;&#26377;&#26126;&#30830;&#30340;&#24120;&#25968;&#65292;&#36825;&#26631;&#24535;&#30528;&#25991;&#29486;&#20013;&#36136;&#30340;&#39134;&#36291;&#12290;&#36890;&#36807;&#36816;&#29992;&#31616;&#21333;&#32780;&#24378;&#22823;&#30340;&#27010;&#29575;&#24037;&#20855;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10232v1 Announce Type: new  Abstract: In this work, we present a simple and unified analysis of the Johnson-Lindenstrauss (JL) lemma, a cornerstone in the field of dimensionality reduction critical for managing high-dimensional data. Our approach not only simplifies the understanding but also unifies various constructions under the JL framework, including spherical, Gaussian, binary coin, and sub-Gaussian models. This simplification and unification make significant strides in preserving the intrinsic geometry of data, essential across diverse applications from streaming algorithms to reinforcement learning. Notably, we deliver the first rigorous proof of the spherical construction's effectiveness within this simplified framework. At the heart of our contribution is an innovative extension of the Hanson-Wright inequality to high dimensions, complete with explicit constants, marking a substantial leap in the literature. By employing simple yet powerful probabilistic tools and 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#36890;&#20449;&#22797;&#26434;&#24615;&#35777;&#26126;&#20102;Transformer&#23618;&#22312;&#22788;&#29702;&#20989;&#25968;&#32452;&#21512;&#20219;&#21153;&#26102;&#30340;&#23616;&#38480;&#24615;&#65292;&#25351;&#20986;&#23545;&#20110;&#22823;&#22411;&#23450;&#20041;&#22495;&#21644;&#26576;&#20123;&#25968;&#23398;&#20219;&#21153;&#65292;Transformers&#21487;&#33021;&#26080;&#27861;&#35299;&#20915;&#12290;</title><link>https://arxiv.org/abs/2402.08164</link><description>&lt;p&gt;
&#20851;&#20110;Transformer&#26550;&#26500;&#30340;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
On Limitations of the Transformer Architecture
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08164
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#36890;&#20449;&#22797;&#26434;&#24615;&#35777;&#26126;&#20102;Transformer&#23618;&#22312;&#22788;&#29702;&#20989;&#25968;&#32452;&#21512;&#20219;&#21153;&#26102;&#30340;&#23616;&#38480;&#24615;&#65292;&#25351;&#20986;&#23545;&#20110;&#22823;&#22411;&#23450;&#20041;&#22495;&#21644;&#26576;&#20123;&#25968;&#23398;&#20219;&#21153;&#65292;Transformers&#21487;&#33021;&#26080;&#27861;&#35299;&#20915;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20013;&#24187;&#35273;&#30340;&#26681;&#26412;&#21407;&#22240;&#26159;&#20160;&#20040;&#65311;&#25105;&#20204;&#20351;&#29992;&#36890;&#20449;&#22797;&#26434;&#24615;&#26469;&#35777;&#26126;&#65292;&#22914;&#26524;&#20989;&#25968;&#30340;&#23450;&#20041;&#22495;&#36275;&#22815;&#22823;&#65292;Transformer&#23618;&#26080;&#27861;&#32452;&#21512;&#20989;&#25968;&#65288;&#20363;&#22914;&#65292;&#22312;&#23478;&#35889;&#20013;&#26597;&#25214;&#19968;&#20010;&#20154;&#30340;&#31062;&#29238;&#65289;&#65307;&#25105;&#20204;&#36890;&#36807;&#31034;&#20363;&#26174;&#31034;&#65292;&#24403;&#23450;&#20041;&#22495;&#30456;&#24403;&#23567;&#30340;&#26102;&#20505;&#65292;&#36825;&#31181;&#33021;&#21147;&#30340;&#32570;&#20047;&#24050;&#32463;&#22312;&#32463;&#39564;&#19978;&#23384;&#22312;&#12290;&#25105;&#20204;&#36824;&#25351;&#20986;&#65292;&#35768;&#22810;&#22312;&#25152;&#35859;&#30340;&#32452;&#21512;&#20219;&#21153;&#20013;&#30340;&#25968;&#23398;&#20219;&#21153;&#65292;&#35748;&#20026;&#23427;&#20204;&#23545;LLMs&#26469;&#35828;&#24456;&#38590;&#35299;&#20915;&#65292;&#23545;&#20110;&#36275;&#22815;&#22823;&#30340;&#23454;&#20363;&#26469;&#35828;&#65292;&#19988;&#20551;&#35774;&#35745;&#31639;&#22797;&#26434;&#24615;&#39046;&#22495;&#30340;&#26576;&#20123;&#34987;&#24191;&#27867;&#25509;&#21463;&#30340;&#29468;&#24819;&#26159;&#27491;&#30830;&#30340;&#65292;Transformers&#20063;&#19981;&#22826;&#21487;&#33021;&#35299;&#20915;&#12290;
&lt;/p&gt;
&lt;p&gt;
What are the root causes of hallucinations in large language models (LLMs)? We use Communication Complexity to prove that the Transformer layer is incapable of composing functions (e.g., identify a grandparent of a person in a genealogy) if the domains of the functions are large enough; we show through examples that this inability is already empirically present when the domains are quite small. We also point out that several mathematical tasks that are at the core of the so-called compositional tasks thought to be hard for LLMs are unlikely to be solvable by Transformers, for large enough instances and assuming that certain well accepted conjectures in the field of Computational Complexity are true.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24471;&#20998;&#30340;&#31639;&#27861;&#31867;&#65292;&#29992;&#20110;&#24178;&#39044;&#33539;&#22260;&#20869;&#30340;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#65292;&#28085;&#30422;&#20102;&#32447;&#24615;&#21644;&#19968;&#33324;&#36716;&#21270;&#12290;&#31639;&#27861;&#20445;&#35777;&#20102;&#21487;&#35782;&#21035;&#24615;&#21644;&#23454;&#29616;&#24615;&#65292;&#24182;&#19988;&#36890;&#36807;&#21019;&#36896;&#24615;&#22320;&#23558;&#24471;&#20998;&#20989;&#25968;&#19982;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#30456;&#32467;&#21512;&#12290;</title><link>https://arxiv.org/abs/2402.00849</link><description>&lt;p&gt;
&#22522;&#20110;&#24471;&#20998;&#30340;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#65306;&#32447;&#24615;&#21644;&#19968;&#33324;&#30340;&#36716;&#21270;
&lt;/p&gt;
&lt;p&gt;
Score-based Causal Representation Learning: Linear and General Transformations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00849
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24471;&#20998;&#30340;&#31639;&#27861;&#31867;&#65292;&#29992;&#20110;&#24178;&#39044;&#33539;&#22260;&#20869;&#30340;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#65292;&#28085;&#30422;&#20102;&#32447;&#24615;&#21644;&#19968;&#33324;&#36716;&#21270;&#12290;&#31639;&#27861;&#20445;&#35777;&#20102;&#21487;&#35782;&#21035;&#24615;&#21644;&#23454;&#29616;&#24615;&#65292;&#24182;&#19988;&#36890;&#36807;&#21019;&#36896;&#24615;&#22320;&#23558;&#24471;&#20998;&#20989;&#25968;&#19982;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#30456;&#32467;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#31687;&#35770;&#25991;&#38024;&#23545;&#19968;&#33324;&#38750;&#21442;&#25968;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#21644;&#23558;&#28508;&#22312;&#21464;&#37327;&#26144;&#23556;&#21040;&#35266;&#27979;&#21464;&#37327;&#30340;&#26410;&#30693;&#36716;&#21270;&#65292;&#30740;&#31350;&#20102;&#22522;&#20110;&#24178;&#39044;&#30340;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#65288;CRL&#65289;&#12290;&#30740;&#31350;&#20102;&#32447;&#24615;&#21644;&#19968;&#33324;&#30340;&#36716;&#21270;&#12290;&#36825;&#31687;&#35770;&#25991;&#21516;&#26102;&#35752;&#35770;&#20102;&#21487;&#35782;&#21035;&#24615;&#21644;&#23454;&#29616;&#24615;&#20004;&#20010;&#26041;&#38754;&#12290;&#21487;&#35782;&#21035;&#24615;&#26159;&#25351;&#30830;&#23450;&#31639;&#27861;&#19981;&#30456;&#20851;&#30340;&#26465;&#20214;&#65292;&#20197;&#30830;&#20445;&#24674;&#22797;&#30495;&#23454;&#30340;&#28508;&#22312;&#22240;&#26524;&#21464;&#37327;&#21644;&#28508;&#22312;&#22240;&#26524;&#22270;&#12290;&#23454;&#29616;&#24615;&#26159;&#25351;&#31639;&#27861;&#26041;&#38754;&#65292;&#35299;&#20915;&#35774;&#35745;&#31639;&#27861;&#26469;&#23454;&#29616;&#21487;&#35782;&#21035;&#20445;&#35777;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#23558;&#24471;&#20998;&#20989;&#25968;&#65288;&#21363;&#23494;&#24230;&#20989;&#25968;&#23545;&#25968;&#30340;&#26799;&#24230;&#65289;&#19982;CRL&#20043;&#38388;&#24314;&#31435;&#26032;&#32852;&#31995;&#65292;&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#31181;&#24471;&#20998;&#20026;&#22522;&#30784;&#30340;&#31639;&#27861;&#31867;&#65292;&#30830;&#20445;&#20102;&#21487;&#35782;&#21035;&#24615;&#21644;&#23454;&#29616;&#24615;&#12290;&#39318;&#20808;&#65292;&#26412;&#25991;&#19987;&#27880;&#20110;&#32447;&#24615;&#36716;&#21270;&#65292;&#24182;&#23637;&#31034;&#20102;&#27599;&#20010;n&#20010;&#38543;&#26426;&#30828;&#24178;&#39044;&#19979;&#35813;&#36716;&#21270;&#30340;&#22240;&#26524;&#34920;&#31034;&#21487;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper addresses intervention-based causal representation learning (CRL) under a general nonparametric latent causal model and an unknown transformation that maps the latent variables to the observed variables. Linear and general transformations are investigated. The paper addresses both the \emph{identifiability} and \emph{achievability} aspects. Identifiability refers to determining algorithm-agnostic conditions that ensure recovering the true latent causal variables and the latent causal graph underlying them. Achievability refers to the algorithmic aspects and addresses designing algorithms that achieve identifiability guarantees. By drawing novel connections between \emph{score functions} (i.e., the gradients of the logarithm of density functions) and CRL, this paper designs a \emph{score-based class of algorithms} that ensures both identifiability and achievability. First, the paper focuses on \emph{linear} transformations and shows that one stochastic hard intervention per n
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#23545;&#21355;&#26143;&#21644;&#27979;&#31449;&#25968;&#25454;&#36827;&#34892;&#25554;&#20540;&#65292;&#36890;&#36807;&#37327;&#21270;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#26469;&#25552;&#39640;&#38477;&#27700;&#25968;&#25454;&#38598;&#30340;&#20998;&#36776;&#29575;&#12290;</title><link>https://arxiv.org/abs/2311.07511</link><description>&lt;p&gt;
&#29992;&#26426;&#22120;&#23398;&#20064;&#36827;&#34892;&#21355;&#26143;&#38477;&#27700;&#25554;&#20540;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Uncertainty estimation in satellite precipitation interpolation with machine learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.07511
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#23545;&#21355;&#26143;&#21644;&#27979;&#31449;&#25968;&#25454;&#36827;&#34892;&#25554;&#20540;&#65292;&#36890;&#36807;&#37327;&#21270;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#26469;&#25552;&#39640;&#38477;&#27700;&#25968;&#25454;&#38598;&#30340;&#20998;&#36776;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21512;&#24182;&#21355;&#26143;&#21644;&#27979;&#31449;&#25968;&#25454;&#24182;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#20135;&#29983;&#39640;&#20998;&#36776;&#29575;&#38477;&#27700;&#25968;&#25454;&#38598;&#65292;&#20294;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#24448;&#24448;&#32570;&#22833;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#27604;&#20845;&#31181;&#31639;&#27861;&#65292;&#22823;&#37096;&#20998;&#26159;&#38024;&#23545;&#36825;&#19968;&#20219;&#21153;&#32780;&#35774;&#35745;&#30340;&#26032;&#31639;&#27861;&#65292;&#26469;&#37327;&#21270;&#31354;&#38388;&#25554;&#20540;&#20013;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#12290;&#22312;&#36830;&#32493;&#32654;&#22269;&#30340;15&#24180;&#26376;&#24230;&#25968;&#25454;&#19978;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#20998;&#20301;&#25968;&#22238;&#24402;&#65288;QR&#65289;&#12289;&#20998;&#20301;&#25968;&#22238;&#24402;&#26862;&#26519;&#65288;QRF&#65289;&#12289;&#24191;&#20041;&#38543;&#26426;&#26862;&#26519;&#65288;GRF&#65289;&#12289;&#26799;&#24230;&#25552;&#21319;&#26426;&#65288;GBM&#65289;&#12289;&#36731;&#26799;&#24230;&#25552;&#21319;&#26426;&#65288;LightGBM&#65289;&#21644;&#20998;&#20301;&#25968;&#22238;&#24402;&#31070;&#32463;&#32593;&#32476;&#65288;QRNN&#65289;&#12290;&#23427;&#20204;&#33021;&#22815;&#22312;&#20061;&#20010;&#20998;&#20301;&#27700;&#24179;&#65288;0.025&#12289;0.050&#12289;0.100&#12289;0.250&#12289;0.500&#12289;0.750&#12289;0.900&#12289;0.950&#12289;0.975&#65289;&#19978;&#21457;&#24067;&#39044;&#27979;&#38477;&#27700;&#20998;&#20301;&#25968;&#65292;&#20197;&#36817;&#20284;&#23436;&#25972;&#27010;&#29575;&#20998;&#24067;&#65292;&#35780;&#20272;&#26102;&#37319;&#29992;&#20998;&#20301;&#25968;&#35780;&#20998;&#20989;&#25968;&#21644;&#20998;&#20301;&#25968;&#35780;&#20998;&#35268;&#21017;&#12290;&#29305;&#24449;&#37325;&#35201;&#24615;&#20998;&#26512;&#25581;&#31034;&#20102;&#21355;&#26143;&#38477;&#27700;&#65288;PERSIA
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.07511v2 Announce Type: replace-cross  Abstract: Merging satellite and gauge data with machine learning produces high-resolution precipitation datasets, but uncertainty estimates are often missing. We address this gap by benchmarking six algorithms, mostly novel for this task, for quantifying predictive uncertainty in spatial interpolation. On 15 years of monthly data over the contiguous United States (CONUS), we compared quantile regression (QR), quantile regression forests (QRF), generalized random forests (GRF), gradient boosting machines (GBM), light gradient boosting machines (LightGBM), and quantile regression neural networks (QRNN). Their ability to issue predictive precipitation quantiles at nine quantile levels (0.025, 0.050, 0.100, 0.250, 0.500, 0.750, 0.900, 0.950, 0.975), approximating the full probability distribution, was evaluated using quantile scoring functions and the quantile scoring rule. Feature importance analysis revealed satellite precipitation (PERSIA
&lt;/p&gt;</description></item><item><title>&#22122;&#38899;&#22914;&#20309;&#24433;&#21709;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#29616;&#35937;&#12290;</title><link>https://arxiv.org/abs/2302.05059</link><description>&lt;p&gt;
&#22122;&#38899;&#23545;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Effects of noise on the overparametrization of quantum neural networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.05059
&lt;/p&gt;
&lt;p&gt;
&#22122;&#38899;&#22914;&#20309;&#24433;&#21709;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#24230;&#21442;&#25968;&#21270;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#20196;&#20154;&#24778;&#35766;&#21644;&#33261;&#21517;&#26157;&#33879;&#30340;&#29616;&#35937;&#20043;&#19968;&#12290;&#26368;&#36817;&#65292;&#26377;&#22810;&#27425;&#23581;&#35797;&#30740;&#31350;&#22312;&#27809;&#26377;&#30828;&#20214;&#22122;&#38899;&#30340;&#24773;&#20917;&#19979;&#65292;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65288;QNNs&#65289;&#26159;&#21542;&#20197;&#21450;&#22914;&#20309;&#34987;&#36807;&#24230;&#21442;&#25968;&#21270;&#12290;&#29305;&#21035;&#26159;&#65292;&#24050;&#32463;&#25552;&#20986;&#65292;&#22914;&#26524;QNN&#20855;&#26377;&#36275;&#22815;&#30340;&#21442;&#25968;&#26469;&#25506;&#32034;&#29366;&#24577;&#31354;&#38388;&#20013;&#30340;&#25152;&#26377;&#21487;&#29992;&#26041;&#21521;&#65292;&#21017;&#21487;&#20197;&#23558;&#20854;&#23450;&#20041;&#20026;&#36807;&#24230;&#21442;&#25968;&#21270;&#12290;&#20063;&#23601;&#26159;&#35828;&#65292;&#22914;&#26524;QNN&#30340;&#36755;&#20986;&#29366;&#24577;&#30340;&#37327;&#23376;&#36153;&#33293;&#23572;&#20449;&#24687;&#30697;&#38453;&#65288;QFIM&#65289;&#30340;&#31209;&#24471;&#20197;&#39281;&#21644;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#22122;&#38899;&#30340;&#23384;&#22312;&#22914;&#20309;&#24433;&#21709;&#36807;&#24230;&#21442;&#25968;&#21270;&#29616;&#35937;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22122;&#38899;&#21487;&#20197;&#8220;&#25171;&#24320;&#8221;&#20808;&#21069;&#20026;&#38646;&#30340;QFIM&#29305;&#24449;&#20540;&#12290;&#36825;&#20351;&#24471;&#21442;&#25968;&#21270;&#29366;&#24577;&#21487;&#20197;&#25506;&#32034;&#21407;&#26412;&#26080;&#27861;&#35775;&#38382;&#30340;&#26041;&#21521;&#65292;&#20174;&#32780;&#28508;&#22312;&#22320;&#23558;&#19968;&#20010;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;QNN&#36716;&#21270;&#20026;&#19968;&#20010;&#27424;&#21442;&#25968;&#21270;&#30340;QNN&#12290;&#23545;&#20110;&#23567;&#22122;&#38899;&#27700;&#24179;&#65292;QNN&#26159;&#20934;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#65292;&#22240;&#20026;&#23384;&#22312;&#22823;&#30340;&#29305;&#24449;&#20540;
&lt;/p&gt;
&lt;p&gt;
arXiv:2302.05059v2 Announce Type: replace-cross  Abstract: Overparametrization is one of the most surprising and notorious phenomena in machine learning. Recently, there have been several efforts to study if, and how, Quantum Neural Networks (QNNs) acting in the absence of hardware noise can be overparametrized. In particular, it has been proposed that a QNN can be defined as overparametrized if it has enough parameters to explore all available directions in state space. That is, if the rank of the Quantum Fisher Information Matrix (QFIM) for the QNN's output state is saturated. Here, we explore how the presence of noise affects the overparametrization phenomenon. Our results show that noise can "turn on" previously-zero eigenvalues of the QFIM. This enables the parametrized state to explore directions that were otherwise inaccessible, thus potentially turning an overparametrized QNN into an underparametrized one. For small noise levels, the QNN is quasi-overparametrized, as large eige
&lt;/p&gt;</description></item><item><title>&#30456;&#23545;&#20110;&#36125;&#21494;&#26031;&#22240;&#23376;&#65292;&#30456;&#23545;&#20449;&#24565;&#27604;&#20316;&#20026;&#34913;&#37327;&#35777;&#25454;&#26356;&#20026;&#21512;&#36866;&#65292;&#21363;&#20351;&#22312;&#23545;&#28151;&#21512;&#20808;&#39564;&#26045;&#21152;&#38480;&#21046;&#21518;&#65292;&#36125;&#21494;&#26031;&#22240;&#23376;&#20173;&#28982;&#31561;&#20110;&#19981;&#20351;&#29992;&#28151;&#21512;&#20808;&#39564;&#24471;&#20986;&#30340;&#30456;&#23545;&#20449;&#24565;&#27604;&#65292;&#24403;&#21069;&#23454;&#36341;&#20013;&#20351;&#29992;&#36125;&#21494;&#26031;&#22240;&#23376;&#30340;&#22823;&#23567;&#26469;&#34913;&#37327;&#24378;&#24230;&#26159;&#19981;&#27491;&#30830;&#30340;&#12290;</title><link>https://arxiv.org/abs/2301.08994</link><description>&lt;p&gt;
&#22914;&#20309;&#34913;&#37327;&#35777;&#25454;&#21450;&#20854;&#24378;&#24230;&#65306;&#36125;&#21494;&#26031;&#22240;&#23376;&#36824;&#26159;&#30456;&#23545;&#20449;&#24565;&#27604;&#65311;
&lt;/p&gt;
&lt;p&gt;
How to Measure Evidence and Its Strength: Bayes Factors or Relative Belief Ratios?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2301.08994
&lt;/p&gt;
&lt;p&gt;
&#30456;&#23545;&#20110;&#36125;&#21494;&#26031;&#22240;&#23376;&#65292;&#30456;&#23545;&#20449;&#24565;&#27604;&#20316;&#20026;&#34913;&#37327;&#35777;&#25454;&#26356;&#20026;&#21512;&#36866;&#65292;&#21363;&#20351;&#22312;&#23545;&#28151;&#21512;&#20808;&#39564;&#26045;&#21152;&#38480;&#21046;&#21518;&#65292;&#36125;&#21494;&#26031;&#22240;&#23376;&#20173;&#28982;&#31561;&#20110;&#19981;&#20351;&#29992;&#28151;&#21512;&#20808;&#39564;&#24471;&#20986;&#30340;&#30456;&#23545;&#20449;&#24565;&#27604;&#65292;&#24403;&#21069;&#23454;&#36341;&#20013;&#20351;&#29992;&#36125;&#21494;&#26031;&#22240;&#23376;&#30340;&#22823;&#23567;&#26469;&#34913;&#37327;&#24378;&#24230;&#26159;&#19981;&#27491;&#30830;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#22240;&#23376;&#21644;&#30456;&#23545;&#20449;&#24565;&#27604;&#37117;&#28385;&#36275;&#35777;&#25454;&#21407;&#21017;&#65292;&#22240;&#27492;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#32479;&#35745;&#35777;&#25454;&#30340;&#26377;&#25928;&#24230;&#37327;&#12290;&#36125;&#21494;&#26031;&#22240;&#23376;&#32463;&#24120;&#34987;&#20351;&#29992;&#12290;&#38382;&#39064;&#22312;&#20110;&#65306;&#36825;&#20123;&#35777;&#25454;&#30340;&#24230;&#37327;&#21738;&#19968;&#20010;&#26356;&#21512;&#36866;&#65311;&#26412;&#25991;&#35748;&#20026;&#65292;&#23545;&#22522;&#20110;&#28151;&#21512;&#20808;&#39564;&#30340;&#24403;&#21069;&#24120;&#29992;&#36125;&#21494;&#26031;&#22240;&#23376;&#23450;&#20041;&#30340;&#26377;&#25928;&#24615;&#23384;&#22312;&#30097;&#38382;&#65292;&#32780;&#20174;&#25972;&#20307;&#32771;&#34385;&#65292;&#30456;&#23545;&#20449;&#24565;&#27604;&#20316;&#20026;&#35777;&#25454;&#30340;&#24230;&#37327;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#36136;&#12290;&#27492;&#22806;&#36824;&#34920;&#26126;&#65292;&#24403;&#23545;&#28151;&#21512;&#20808;&#39564;&#26045;&#21152;&#19968;&#39033;&#33258;&#28982;&#38480;&#21046;&#26102;&#65292;&#36125;&#21494;&#26031;&#22240;&#23376;&#31561;&#20110;&#19981;&#20351;&#29992;&#28151;&#21512;&#20808;&#39564;&#24471;&#20986;&#30340;&#30456;&#23545;&#20449;&#24565;&#27604;&#12290;&#21363;&#20351;&#21463;&#21040;&#27492;&#38480;&#21046;&#65292;&#22914;&#20309;&#34913;&#37327;&#35777;&#25454;&#30340;&#24378;&#24230;&#20173;&#28982;&#26159;&#20010;&#24453;&#35299;&#38382;&#39064;&#12290;&#26412;&#25991;&#35748;&#20026;&#65292;&#30446;&#21069;&#30340;&#20570;&#27861;&#26159;&#20351;&#29992;&#36125;&#21494;&#26031;&#22240;&#23376;&#30340;&#22823;&#23567;&#26469;&#34913;&#37327;&#24378;&#24230;&#26159;&#19981;&#27491;&#30830;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2301.08994v2 Announce Type: replace-cross  Abstract: Both the Bayes factor and the relative belief ratio satisfy the principle of evidence and so can be seen to be valid measures of statistical evidence. Certainly Bayes factors are regularly employed. The question then is: which of these measures of evidence is more appropriate? It is argued here that there are questions concerning the validity of a current commonly used definition of the Bayes factor based on a mixture prior and, when all is considered, the relative belief ratio has better properties as a measure of evidence. It is further shown that, when a natural restriction on the mixture prior is imposed, the Bayes factor equals the relative belief ratio obtained without using the mixture prior. Even with this restriction, this still leaves open the question of how the strength of evidence is to be measured. It is argued here that the current practice of using the size of the Bayes factor to measure strength is not correct 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22823;&#35268;&#27169;&#22238;&#24402;&#30340;&#26641;&#23548;&#21521;&#29305;&#24449;&#36873;&#25321;&#21644;&#36923;&#36753;&#32858;&#21512;&#26041;&#27861;&#65292;&#26088;&#22312;&#25913;&#21892;&#22522;&#20110;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#30340;&#24314;&#27169;&#21644;&#21033;&#29992;&#30142;&#30149;&#20998;&#31867;&#30340;&#33258;&#28982;&#20998;&#23618;&#32467;&#26500;</title><link>https://arxiv.org/abs/2206.09107</link><description>&lt;p&gt;
&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#25968;&#25454;&#20013;&#30340;&#26641;&#23548;&#21521;&#32597;&#35265;&#29305;&#24449;&#36873;&#25321;&#21644;&#36923;&#36753;&#32858;&#21512;
&lt;/p&gt;
&lt;p&gt;
Tree-Guided Rare Feature Selection and Logic Aggregation with Electronic Health Records Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2206.09107
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22823;&#35268;&#27169;&#22238;&#24402;&#30340;&#26641;&#23548;&#21521;&#29305;&#24449;&#36873;&#25321;&#21644;&#36923;&#36753;&#32858;&#21512;&#26041;&#27861;&#65292;&#26088;&#22312;&#25913;&#21892;&#22522;&#20110;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#30340;&#24314;&#27169;&#21644;&#21033;&#29992;&#30142;&#30149;&#20998;&#31867;&#30340;&#33258;&#28982;&#20998;&#23618;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22788;&#29702;&#20855;&#26377;&#22823;&#37327;&#32597;&#35265;&#20108;&#36827;&#21046;&#29305;&#24449;&#30340;&#32479;&#35745;&#23398;&#20064;&#22312;&#20998;&#26512;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;EHR&#65289;&#25968;&#25454;&#26102;&#24456;&#24120;&#35265;&#65292;&#23588;&#20854;&#26159;&#22312;&#21033;&#29992;&#20808;&#21069;&#30340;&#21307;&#23398;&#35786;&#26029;&#21644;&#31243;&#24207;&#23545;&#30142;&#30149;&#21457;&#29983;&#36827;&#34892;&#24314;&#27169;&#26102;&#12290;&#20026;&#20102;&#25913;&#21892;&#22522;&#20110;EHR&#30340;&#24314;&#27169;&#24182;&#21033;&#29992;&#30142;&#30149;&#20998;&#31867;&#30340;&#33258;&#28982;&#20998;&#23618;&#32467;&#26500;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22823;&#35268;&#27169;&#22238;&#24402;&#30340;&#26641;&#23548;&#21521;&#29305;&#24449;&#36873;&#25321;&#21644;&#36923;&#36753;&#32858;&#21512;&#26041;&#27861;&#65292;&#36890;&#36807;&#31232;&#30095;&#36861;&#27714;&#21644;&#8220;&#25110;&#8221;&#36923;&#36753;&#36816;&#31639;&#31526;&#30340;&#32858;&#21512;&#20419;&#36827;&#22120;&#23454;&#29616;&#20102;&#38477;&#32500;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2206.09107v2 Announce Type: replace  Abstract: Statistical learning with a large number of rare binary features is commonly encountered in analyzing electronic health records (EHR) data, especially in the modeling of disease onset with prior medical diagnoses and procedures. Dealing with the resulting highly sparse and large-scale binary feature matrix is notoriously challenging as conventional methods may suffer from a lack of power in testing and inconsistency in model fitting while machine learning methods may suffer from the inability of producing interpretable results or clinically-meaningful risk factors. To improve EHR-based modeling and utilize the natural hierarchical structure of disease classification, we propose a tree-guided feature selection and logic aggregation approach for large-scale regression with rare binary features, in which dimension reduction is achieved through not only a sparsity pursuit but also an aggregation promoter with the logic operator of ``or''
&lt;/p&gt;</description></item><item><title>DoubleML&#26159;&#22312;R&#20013;&#23454;&#29616;&#30340;&#21452;&#37325;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#25552;&#20379;&#20102;&#20272;&#35745;&#22240;&#26524;&#27169;&#22411;&#21442;&#25968;&#30340;&#21151;&#33021;&#65292;&#21253;&#25324;&#22312;&#37096;&#20998;&#32447;&#24615;&#21644;&#20132;&#20114;&#22238;&#24402;&#27169;&#22411;&#20013;&#36827;&#34892;&#25512;&#26029;&#12290;&#23545;&#35937;&#23548;&#21521;&#30340;&#23454;&#29616;&#20351;&#24471;&#27169;&#22411;&#35268;&#33539;&#20855;&#26377;&#24456;&#39640;&#30340;&#28789;&#27963;&#24615;&#24182;&#26131;&#20110;&#25193;&#23637;&#12290;</title><link>https://arxiv.org/abs/2103.09603</link><description>&lt;p&gt;
DoubleML -- &#21452;&#37325;&#26426;&#22120;&#23398;&#20064;&#30340;&#38754;&#21521;&#23545;&#35937;&#23454;&#29616;&#22312;R&#20013;
&lt;/p&gt;
&lt;p&gt;
DoubleML -- An Object-Oriented Implementation of Double Machine Learning in R
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2103.09603
&lt;/p&gt;
&lt;p&gt;
DoubleML&#26159;&#22312;R&#20013;&#23454;&#29616;&#30340;&#21452;&#37325;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#25552;&#20379;&#20102;&#20272;&#35745;&#22240;&#26524;&#27169;&#22411;&#21442;&#25968;&#30340;&#21151;&#33021;&#65292;&#21253;&#25324;&#22312;&#37096;&#20998;&#32447;&#24615;&#21644;&#20132;&#20114;&#22238;&#24402;&#27169;&#22411;&#20013;&#36827;&#34892;&#25512;&#26029;&#12290;&#23545;&#35937;&#23548;&#21521;&#30340;&#23454;&#29616;&#20351;&#24471;&#27169;&#22411;&#35268;&#33539;&#20855;&#26377;&#24456;&#39640;&#30340;&#28789;&#27963;&#24615;&#24182;&#26131;&#20110;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#20171;&#32461;&#20102;R&#21253;DoubleML&#23454;&#29616;&#20102;Chernozhukov&#31561;&#20154;&#65288;2018&#65289;&#25552;&#20986;&#30340;&#21452;&#37325;/&#26080;&#20559;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#12290;&#23427;&#25552;&#20379;&#20102;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20272;&#35745;&#22240;&#26524;&#27169;&#22411;&#21442;&#25968;&#30340;&#21151;&#33021;&#12290;&#21452;&#37325;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#21253;&#25324;&#19977;&#20010;&#20851;&#38190;&#35201;&#32032;&#65306;Neyman&#27491;&#20132;&#24615;&#12289;&#39640;&#36136;&#37327;&#30340;&#26426;&#22120;&#23398;&#20064;&#20272;&#35745;&#21644;&#26679;&#26412;&#25286;&#20998;&#12290;&#21487;&#20197;&#36890;&#36807;mlr3&#29983;&#24577;&#31995;&#32479;&#20013;&#25552;&#20379;&#30340;&#21508;&#31181;&#26368;&#20808;&#36827;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#26469;&#20272;&#35745;&#24178;&#25200;&#25104;&#20998;&#12290;DoubleML&#20351;&#24471;&#21487;&#20197;&#22312;&#21508;&#31181;&#22240;&#26524;&#27169;&#22411;&#20013;&#36827;&#34892;&#25512;&#26029;&#65292;&#21253;&#25324;&#37096;&#20998;&#32447;&#24615;&#21644;&#20132;&#20114;&#22238;&#24402;&#27169;&#22411;&#20197;&#21450;&#23427;&#20204;&#23545;&#24037;&#20855;&#21464;&#37327;&#20272;&#35745;&#30340;&#25193;&#23637;&#12290;DoubleML&#30340;&#38754;&#21521;&#23545;&#35937;&#23454;&#29616;&#20351;&#27169;&#22411;&#35268;&#33539;&#38750;&#24120;&#28789;&#27963;&#19988;&#26131;&#20110;&#25193;&#23637;&#12290;&#26412;&#25991;&#20316;&#20026;&#21452;&#37325;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#21644;R pac&#30340;&#20171;&#32461;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2103.09603v5 Announce Type: replace-cross  Abstract: The R package DoubleML implements the double/debiased machine learning framework of Chernozhukov et al. (2018). It provides functionalities to estimate parameters in causal models based on machine learning methods. The double machine learning framework consist of three key ingredients: Neyman orthogonality, high-quality machine learning estimation and sample splitting. Estimation of nuisance components can be performed by various state-of-the-art machine learning methods that are available in the mlr3 ecosystem. DoubleML makes it possible to perform inference in a variety of causal models, including partially linear and interactive regression models and their extensions to instrumental variable estimation. The object-oriented implementation of DoubleML enables a high flexibility for the model specification and makes it easily extendable. This paper serves as an introduction to the double machine learning framework and the R pac
&lt;/p&gt;</description></item><item><title>&#33258;&#21160;&#21270;&#26426;&#22120;&#23398;&#20064;&#65288;AutoML&#65289;&#26088;&#22312;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#29983;&#25104;&#20196;&#20154;&#28385;&#24847;&#30340;ML&#37197;&#32622;&#65292;&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;AutoML&#21407;&#29702;&#21644;&#23454;&#36341;&#30340;&#20840;&#38754;&#35843;&#30740;&#12290;</title><link>https://arxiv.org/abs/1810.13306</link><description>&lt;p&gt;
&#33258;&#21160;&#21270;&#26426;&#22120;&#23398;&#20064;&#65306;&#20174;&#21407;&#29702;&#21040;&#23454;&#36341;
&lt;/p&gt;
&lt;p&gt;
Automated Machine Learning: From Principles to Practices
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/1810.13306
&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#21270;&#26426;&#22120;&#23398;&#20064;&#65288;AutoML&#65289;&#26088;&#22312;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#29983;&#25104;&#20196;&#20154;&#28385;&#24847;&#30340;ML&#37197;&#32622;&#65292;&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;AutoML&#21407;&#29702;&#21644;&#23454;&#36341;&#30340;&#20840;&#38754;&#35843;&#30740;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#26041;&#27861;&#21457;&#23637;&#36805;&#36895;&#65292;&#20294;&#37197;&#32622;&#21644;&#36873;&#25321;&#21512;&#36866;&#30340;&#26041;&#27861;&#20197;&#36798;&#21040;&#25152;&#38656;&#24615;&#33021;&#27491;&#21464;&#24471;&#36234;&#26469;&#36234;&#22256;&#38590;&#21644;&#20047;&#21619;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#33258;&#21160;&#21270;&#26426;&#22120;&#23398;&#20064;&#65288;AutoML&#65289;&#24212;&#36816;&#32780;&#29983;&#65292;&#26088;&#22312;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#20026;&#32473;&#23450;&#20219;&#21153;&#29983;&#25104;&#20196;&#20154;&#28385;&#24847;&#30340;ML&#37197;&#32622;&#12290;&#26412;&#25991;&#23601;&#35813;&#20027;&#39064;&#36827;&#34892;&#20102;&#20840;&#38754;&#35843;&#30740;&#12290;&#25105;&#20204;&#20174;AutoML&#30340;&#27491;&#24335;&#23450;&#20041;&#24320;&#22987;&#65292;&#28982;&#21518;&#20171;&#32461;&#20854;&#21407;&#29702;&#65292;&#21253;&#25324;&#21452;&#23618;&#23398;&#20064;&#30446;&#26631;&#12289;&#23398;&#20064;&#31574;&#30053;&#21644;&#29702;&#35770;&#35299;&#37322;&#12290;&#25509;&#30528;&#65292;&#25105;&#20204;&#36890;&#36807;&#22522;&#20110;&#19977;&#20010;&#20027;&#35201;&#22240;&#32032;&#8212;&#8212;&#25628;&#32034;&#31354;&#38388;&#12289;&#25628;&#32034;&#31639;&#27861;&#21644;&#35780;&#20272;&#31574;&#30053;&#8212;&#8212;&#35774;&#31435;&#29616;&#26377;&#24037;&#20316;&#30340;&#20998;&#31867;&#27861;&#26469;&#24635;&#32467;AutoML&#23454;&#36341;&#12290;&#27599;&#20010;&#31867;&#21035;&#36824;&#20250;&#36890;&#36807;&#20195;&#34920;&#24615;&#26041;&#27861;&#36827;&#34892;&#35299;&#37322;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#37197;&#32622;ML&#31649;&#32447;&#31561;&#31034;&#20363;&#24212;&#29992;&#35828;&#26126;&#20102;AutoML&#30340;&#21407;&#29702;&#21644;&#23454;&#36341;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:1810.13306v5 Announce Type: replace  Abstract: Machine learning (ML) methods have been developing rapidly, but configuring and selecting proper methods to achieve a desired performance is increasingly difficult and tedious. To address this challenge, automated machine learning (AutoML) has emerged, which aims to generate satisfactory ML configurations for given tasks in a data-driven way. In this paper, we provide a comprehensive survey on this topic. We begin with the formal definition of AutoML and then introduce its principles, including the bi-level learning objective, the learning strategy, and the theoretical interpretation. Then, we summarize the AutoML practices by setting up the taxonomy of existing works based on three main factors: the search space, the search algorithm, and the evaluation strategy. Each category is also explained with the representative methods. Then, we illustrate the principles and practices with exemplary applications from configuring ML pipeline, 
&lt;/p&gt;</description></item><item><title>&#21033;&#29992;Ricci&#27969;&#24341;&#23548;&#30340;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#33021;&#22815;&#23398;&#20064;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#65292;&#23588;&#20854;&#26159;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;&#35757;&#32451;&#20013;&#23398;&#20064;&#27969;&#24418;&#65292;&#24182;&#20351;&#29992;Ricci&#27969;&#20351;&#27969;&#24418;&#28508;&#31354;&#38388;&#36880;&#27493;&#36866;&#24212;&#21160;&#21147;&#23398;&#30340;&#21464;&#21270;&#65292;&#20174;&#32780;&#33719;&#24471;&#26356;&#22909;&#30340;&#34920;&#31034;&#33021;&#21147;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#20855;&#26377;&#21608;&#26399;&#24615;&#21644;&#38543;&#26426;&#24615;&#30340;PDE&#19978;&#30340;&#24212;&#29992;&#65292;&#24182;&#35780;&#20272;&#20102;&#22312;&#20998;&#24067;&#20869;&#21644;&#22806;&#25512;&#22330;&#26223;&#20013;&#30340;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2401.14591</link><description>&lt;p&gt;
&#21033;&#29992;Ricci&#27969;&#24341;&#23548;&#30340;&#33258;&#32534;&#30721;&#22120;&#23398;&#20064;&#26102;&#21464;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Ricci flow-guided autoencoders in learning time-dependent dynamics. (arXiv:2401.14591v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14591
&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;Ricci&#27969;&#24341;&#23548;&#30340;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#33021;&#22815;&#23398;&#20064;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#65292;&#23588;&#20854;&#26159;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;&#35757;&#32451;&#20013;&#23398;&#20064;&#27969;&#24418;&#65292;&#24182;&#20351;&#29992;Ricci&#27969;&#20351;&#27969;&#24418;&#28508;&#31354;&#38388;&#36880;&#27493;&#36866;&#24212;&#21160;&#21147;&#23398;&#30340;&#21464;&#21270;&#65292;&#20174;&#32780;&#33719;&#24471;&#26356;&#22909;&#30340;&#34920;&#31034;&#33021;&#21147;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#20855;&#26377;&#21608;&#26399;&#24615;&#21644;&#38543;&#26426;&#24615;&#30340;PDE&#19978;&#30340;&#24212;&#29992;&#65292;&#24182;&#35780;&#20272;&#20102;&#22312;&#20998;&#24067;&#20869;&#21644;&#22806;&#25512;&#22330;&#26223;&#20013;&#30340;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27969;&#24418;&#30340;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#26102;&#38388;&#19978;&#30340;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#65292;&#23588;&#20854;&#26159;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDE&#65289;&#65292;&#20854;&#20013;&#27969;&#24418;&#28508;&#31354;&#38388;&#26681;&#25454;Ricci&#27969;&#21457;&#23637;&#12290;&#36825;&#21487;&#20197;&#36890;&#36807;&#22312;&#29289;&#29702;&#20449;&#24687;&#35774;&#32622;&#20013;&#27169;&#25311;Ricci&#27969;&#26469;&#23454;&#29616;&#65292;&#24182;&#19988;&#21487;&#20197;&#21305;&#37197;&#27969;&#24418;&#37327;&#65292;&#20197;&#20415;&#23454;&#29616;Ricci&#27969;&#12290;&#20351;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#27969;&#24418;&#26159;&#20316;&#20026;&#35757;&#32451;&#36807;&#31243;&#30340;&#19968;&#37096;&#20998;&#23398;&#20064;&#30340;&#65292;&#22240;&#27492;&#21487;&#20197;&#35782;&#21035;&#20986;&#29702;&#24819;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#21516;&#26102;&#28436;&#21464;&#20063;&#33021;&#22312;&#38745;&#24577;&#26041;&#27861;&#19978;&#24341;&#36215;&#26356;&#23485;&#23481;&#30340;&#28508;&#22312;&#34920;&#31034;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#25968;&#20540;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#20855;&#26377;&#21608;&#26399;&#24615;&#21644;&#38543;&#26426;&#24615;&#31561;&#29702;&#24819;&#29305;&#24449;&#30340;PDE&#65292;&#24182;&#22312;&#20998;&#24067;&#20869;&#21644;&#22806;&#25512;&#22330;&#26223;&#20013;&#36827;&#34892;&#35823;&#24046;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a manifold-based autoencoder method for learning nonlinear dynamics in time, notably partial differential equations (PDEs), in which the manifold latent space evolves according to Ricci flow. This can be accomplished by simulating Ricci flow in a physics-informed setting, and manifold quantities can be matched so that Ricci flow is empirically achieved. With our methodology, the manifold is learned as part of the training procedure, so ideal geometries may be discerned, while the evolution simultaneously induces a more accommodating latent representation over static methods. We present our method on a range of numerical experiments consisting of PDEs that encompass desirable characteristics such as periodicity and randomness, remarking error on in-distribution and extrapolation scenarios.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#22312;&#32447;&#33258;&#21161;&#27861;&#29992;&#20110;&#22788;&#29702;&#22823;&#35268;&#27169;&#30340;&#26102;&#38388;&#24207;&#21015;&#21644;&#30456;&#20851;&#25968;&#25454;&#27969;&#65292;&#36890;&#36807;&#32771;&#34385;&#25968;&#25454;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#20379;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#22635;&#34917;&#20102;&#29616;&#26377;&#33258;&#21161;&#27861;&#22312;&#22797;&#26434;&#25968;&#25454;&#20381;&#36182;&#24773;&#20917;&#19979;&#30340;&#24212;&#29992;&#31354;&#30333;&#12290;</title><link>http://arxiv.org/abs/2310.19683</link><description>&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#30340;&#22312;&#32447;&#33258;&#21161;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Online Bootstrap for Time Series. (arXiv:2310.19683v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19683
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#22312;&#32447;&#33258;&#21161;&#27861;&#29992;&#20110;&#22788;&#29702;&#22823;&#35268;&#27169;&#30340;&#26102;&#38388;&#24207;&#21015;&#21644;&#30456;&#20851;&#25968;&#25454;&#27969;&#65292;&#36890;&#36807;&#32771;&#34385;&#25968;&#25454;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#20379;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#22635;&#34917;&#20102;&#29616;&#26377;&#33258;&#21161;&#27861;&#22312;&#22797;&#26434;&#25968;&#25454;&#20381;&#36182;&#24773;&#20917;&#19979;&#30340;&#24212;&#29992;&#31354;&#30333;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#20309;&#22788;&#29702;&#22823;&#35268;&#27169;&#30340;&#30456;&#20851;&#25968;&#25454;&#27969;&#65288;&#22914;&#26102;&#38388;&#24207;&#21015;&#25110;&#31354;&#38388;&#30456;&#20851;&#35266;&#27979;&#25968;&#25454;&#65289;&#26102;&#65292;&#20256;&#32479;&#30340;&#33258;&#21161;&#27861;&#21463;&#38480;&#21046;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#22312;&#32447;&#25191;&#34892;&#30340;&#26032;&#22411;&#33258;&#21161;&#27861;&#65292;&#19987;&#38376;&#29992;&#20110;&#32771;&#34385;&#25968;&#25454;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#20351;&#20854;&#29305;&#21035;&#36866;&#29992;&#20110;&#23454;&#26102;&#24212;&#29992;&#12290;&#36825;&#31181;&#26041;&#27861;&#22522;&#20110;&#19968;&#20010;&#33258;&#22238;&#24402;&#24207;&#21015;&#65292;&#20854;&#20013;&#21253;&#21547;&#36234;&#26469;&#36234;&#30456;&#20851;&#30340;&#37325;&#37319;&#26679;&#26435;&#37325;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19968;&#33324;&#26465;&#20214;&#19979;&#25552;&#20986;&#30340;&#33258;&#21161;&#27861;&#30340;&#29702;&#35770;&#26377;&#25928;&#24615;&#12290;&#36890;&#36807;&#22823;&#37327;&#30340;&#27169;&#25311;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#26174;&#31034;&#23427;&#22312;&#22797;&#26434;&#25968;&#25454;&#20381;&#36182;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#22635;&#34917;&#20102;&#20256;&#32479;&#37325;&#37319;&#26679;&#25216;&#26415;&#19982;&#29616;&#20195;&#25968;&#25454;&#20998;&#26512;&#38656;&#27714;&#20043;&#38388;&#30340;&#40511;&#27807;&#65292;&#20026;&#30740;&#31350;&#20154;&#21592;&#21644;&#20174;&#19994;&#32773;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#20215;&#20540;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
Resampling methods such as the bootstrap have proven invaluable in the field of machine learning. However, the applicability of traditional bootstrap methods is limited when dealing with large streams of dependent data, such as time series or spatially correlated observations. In this paper, we propose a novel bootstrap method that is designed to account for data dependencies and can be executed online, making it particularly suitable for real-time applications. This method is based on an autoregressive sequence of increasingly dependent resampling weights. We prove the theoretical validity of the proposed bootstrap scheme under general conditions. We demonstrate the effectiveness of our approach through extensive simulations and show that it provides reliable uncertainty quantification even in the presence of complex data dependencies. Our work bridges the gap between classical resampling techniques and the demands of modern data analysis, providing a valuable tool for researchers and
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#37096;&#20998;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#36716;&#21270;&#20026;&#27169;&#25311;&#36153;&#26364;-&#21345;&#20811;&#27169;&#22411;&#30340;&#39640;&#25928;&#37319;&#26679;&#35757;&#32451;&#31574;&#30053;&#65292;&#24182;&#36890;&#36807;&#21508;&#31181;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#39044;&#27979;&#24615;&#33021;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2310.19608</link><description>&lt;p&gt;
&#35770;&#36153;&#26364;-&#21345;&#20811;&#35757;&#32451;&#37096;&#20998;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
On Feynman--Kac training of partial Bayesian neural networks. (arXiv:2310.19608v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19608
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#37096;&#20998;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#36716;&#21270;&#20026;&#27169;&#25311;&#36153;&#26364;-&#21345;&#20811;&#27169;&#22411;&#30340;&#39640;&#25928;&#37319;&#26679;&#35757;&#32451;&#31574;&#30053;&#65292;&#24182;&#36890;&#36807;&#21508;&#31181;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#39044;&#27979;&#24615;&#33021;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#37096;&#20998;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;(pBNNs)&#34987;&#35777;&#26126;&#19982;&#20840;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#31454;&#20105;&#21147;&#65292;&#20294;pBNNs&#22312;&#28508;&#21464;&#37327;&#31354;&#38388;&#20013;&#24448;&#24448;&#26159;&#22810;&#23792;&#30340;&#65292;&#22240;&#27492;&#29992;&#21442;&#25968;&#27169;&#22411;&#26469;&#36817;&#20284;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#22522;&#20110;&#37319;&#26679;&#30340;&#35757;&#32451;&#31574;&#30053;&#65292;&#21363;&#23558;pBNN&#30340;&#35757;&#32451;&#36716;&#21270;&#20026;&#27169;&#25311;&#36153;&#26364;-&#21345;&#20811;&#27169;&#22411;&#12290;&#25105;&#20204;&#36824;&#25551;&#36848;&#20102;&#24207;&#36143;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#22120;&#30340;&#21464;&#31181;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#20197;&#21487;&#34892;&#30340;&#35745;&#31639;&#25104;&#26412;&#21516;&#26102;&#20272;&#35745;&#21442;&#25968;&#21644;&#35813;&#27169;&#22411;&#30340;&#28508;&#22312;&#21518;&#39564;&#20998;&#24067;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#35757;&#32451;&#26041;&#26696;&#22312;&#39044;&#27979;&#24615;&#33021;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, partial Bayesian neural networks (pBNNs), which only consider a subset of the parameters to be stochastic, were shown to perform competitively with full Bayesian neural networks. However, pBNNs are often multi-modal in the latent-variable space and thus challenging to approximate with parametric models. To address this problem, we propose an efficient sampling-based training strategy, wherein the training of a pBNN is formulated as simulating a Feynman--Kac model. We then describe variations of sequential Monte Carlo samplers that allow us to simultaneously estimate the parameters and the latent posterior distribution of this model at a tractable computational cost. We show on various synthetic and real-world datasets that our proposed training scheme outperforms the state of the art in terms of predictive performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20197;Hessian-Vector&#20056;&#31215;&#31995;&#21015;&#20026;&#22522;&#30784;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#24179;&#26041;&#26681;&#21644;&#27714;&#36870;&#25805;&#20316;&#23454;&#29616;&#20102;&#39640;&#25928;&#21487;&#20280;&#32553;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#24182;&#30456;&#23545;&#20110;&#20854;&#20182;&#19968;&#38454;&#21644;&#20108;&#38454;&#20248;&#21270;&#26041;&#27861;&#22312;&#36816;&#34892;&#26102;&#38388;&#21644;&#24615;&#33021;&#19978;&#20855;&#26377;&#21487;&#27604;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.14901</link><description>&lt;p&gt;
&#21487;&#34892;&#30340;&#26080;&#38797;&#29275;&#39039;&#20248;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;Hessian-Vector&#20056;&#31215;&#31995;&#21015;
&lt;/p&gt;
&lt;p&gt;
Series of Hessian-Vector Products for Tractable Saddle-Free Newton Optimisation of Neural Networks. (arXiv:2310.14901v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14901
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20197;Hessian-Vector&#20056;&#31215;&#31995;&#21015;&#20026;&#22522;&#30784;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#24179;&#26041;&#26681;&#21644;&#27714;&#36870;&#25805;&#20316;&#23454;&#29616;&#20102;&#39640;&#25928;&#21487;&#20280;&#32553;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#24182;&#30456;&#23545;&#20110;&#20854;&#20182;&#19968;&#38454;&#21644;&#20108;&#38454;&#20248;&#21270;&#26041;&#27861;&#22312;&#36816;&#34892;&#26102;&#38388;&#21644;&#24615;&#33021;&#19978;&#20855;&#26377;&#21487;&#27604;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#25311;&#29275;&#39039;&#26041;&#27861;&#22312;&#36830;&#32493;&#20248;&#21270;&#39046;&#22495;&#38750;&#24120;&#21463;&#27426;&#36814;&#65292;&#20294;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#24212;&#29992;&#20173;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;Hessian&#30697;&#38453;&#30340;&#35268;&#27169;&#36807;&#22823;&#12290;&#36890;&#36807;&#20462;&#25913;Hessian&#30340;&#29305;&#24449;&#20540;&#26469;&#22788;&#29702;&#38750;&#20984;&#24615;&#65292;&#22914;&#26080;&#38797;&#29275;&#39039;&#26041;&#27861;&#65292;&#36827;&#19968;&#27493;&#22686;&#21152;&#20102;&#35745;&#31639;&#36127;&#25285;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21516;&#26102;&#35299;&#20915;&#36825;&#20004;&#20010;&#38382;&#39064;&#30340;&#20248;&#21270;&#31639;&#27861;-&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#39318;&#20010;&#21487;&#20197;&#28176;&#36817;&#22320;&#20351;&#29992;&#31934;&#30830;&#65288;&#29305;&#24449;&#20540;&#20462;&#25913;&#21518;&#30340;&#65289;&#36870;Hessian&#30340;&#39640;&#25928;&#21487;&#20280;&#32553;&#20248;&#21270;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#38382;&#39064;&#34920;&#36848;&#20026;&#19968;&#20010;&#20027;&#35201;&#23545;Hessian&#36827;&#34892;&#24179;&#26041;&#26681;&#21644;&#27714;&#36870;&#30340;&#32423;&#25968;&#65292;&#28982;&#21518;&#29992;&#23427;&#26469;&#39044;&#22788;&#29702;&#26799;&#24230;&#21521;&#37327;&#65292;&#32780;&#26080;&#38656;&#26174;&#24335;&#35745;&#31639;&#25110;&#36827;&#34892;&#29305;&#24449;&#20998;&#35299;&#12290;&#23545;&#35813;&#26080;&#38480;&#32423;&#25968;&#30340;&#25130;&#26029;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#21487;&#20280;&#32553;&#20248;&#21270;&#31639;&#27861;&#65292;&#20854;&#36816;&#34892;&#26102;&#38388;&#21644;&#20248;&#21270;&#24615;&#33021;&#19982;&#20854;&#20182;&#19968;&#38454;&#21644;&#20108;&#38454;&#20248;&#21270;&#26041;&#27861;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite their popularity in the field of continuous optimisation, second-order quasi-Newton methods are challenging to apply in machine learning, as the Hessian matrix is intractably large. This computational burden is exacerbated by the need to address non-convexity, for instance by modifying the Hessian's eigenvalues as in Saddle-Free Newton methods. We propose an optimisation algorithm which addresses both of these concerns - to our knowledge, the first efficiently-scalable optimisation algorithm to asymptotically use the exact (eigenvalue-modified) inverse Hessian. Our method frames the problem as a series which principally square-roots and inverts the squared Hessian, then uses it to precondition a gradient vector, all without explicitly computing or eigendecomposing the Hessian. A truncation of this infinite series provides a new optimisation algorithm which is scalable and comparable to other first- and second-order optimisation methods in both runtime and optimisation performan
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#28145;&#24230;&#32593;&#32476;&#20013;&#20351;&#29992;&#20154;&#31867;&#20559;&#22909;&#36827;&#34892;&#38750;&#21442;&#25968;&#31163;&#31574;&#30053;&#35780;&#20272;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#65292;&#24182;&#24314;&#31435;&#20102;&#32479;&#35745;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.10556</link><description>&lt;p&gt;
&#22522;&#20110;&#20154;&#31867;&#20559;&#22909;&#30340;&#38750;&#21442;&#25968;&#31163;&#31574;&#30053;&#35780;&#20272;&#22312;&#28145;&#24230;&#32593;&#32476;&#20013;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
Sample Complexity of Preference-Based Nonparametric Off-Policy Evaluation with Deep Networks. (arXiv:2310.10556v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10556
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#28145;&#24230;&#32593;&#32476;&#20013;&#20351;&#29992;&#20154;&#31867;&#20559;&#22909;&#36827;&#34892;&#38750;&#21442;&#25968;&#31163;&#31574;&#30053;&#35780;&#20272;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#65292;&#24182;&#24314;&#31435;&#20102;&#32479;&#35745;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#27969;&#34892;&#30340;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#26041;&#27861;&#26159;&#20351;&#29992;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#12290;&#20107;&#23454;&#19978;&#65292;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#29616;&#22312;&#19982;&#32463;&#20856;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65288;&#22914;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26041;&#27861;&#65289;&#19968;&#36215;&#20351;&#29992;&#65292;&#22312;&#20174;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#20013;&#23398;&#20064;&#30340;&#22870;&#21169;&#19978;&#35780;&#20272;&#20013;&#38388;&#31574;&#30053;&#65292;&#21363;&#31163;&#31574;&#30053;&#35780;&#20272;&#65288;OPE&#65289;&#12290;&#35813;&#31639;&#27861;&#21253;&#25324;&#65288;i&#65289;&#20174;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#22870;&#21169;&#20989;&#25968;&#65292;&#20197;&#21450;&#65288;ii&#65289;&#23398;&#20064;&#30446;&#26631;&#31574;&#30053;&#30340;&#32047;&#31215;&#22870;&#21169;&#12290;&#23613;&#31649;&#26377;&#24040;&#22823;&#30340;&#32463;&#39564;&#25104;&#21151;&#65292;&#20294;&#29616;&#26377;&#30340;&#20351;&#29992;&#20559;&#22909;&#25968;&#25454;&#30340;OPE&#26041;&#27861;&#36890;&#24120;&#32570;&#20047;&#29702;&#35770;&#29702;&#35299;&#65292;&#24182;&#19988;&#20005;&#37325;&#20381;&#36182;&#20110;&#21551;&#21457;&#24335;&#26041;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#20154;&#31867;&#20559;&#22909;&#30340;OPE&#30340;&#26679;&#26412;&#25928;&#29575;&#65292;&#24182;&#20026;&#20854;&#24314;&#31435;&#20102;&#32479;&#35745;&#20445;&#35777;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#25311;&#21512;Q&#35780;&#20272;&#26469;&#22788;&#29702;OPE&#12290;&#36890;&#36807;&#36866;&#24403;&#36873;&#25321;ReLU&#32593;&#32476;&#30340;&#22823;&#23567;&#65292;&#25105;&#20204;&#34920;&#26126;&#21487;&#20197;&#21033;&#29992;&#20219;&#20309;lo
&lt;/p&gt;
&lt;p&gt;
A recently popular approach to solving reinforcement learning is with data from human preferences. In fact, human preference data are now used with classic reinforcement learning algorithms such as actor-critic methods, which involve evaluating an intermediate policy over a reward learned from human preference data with distribution shift, known as off-policy evaluation (OPE). Such algorithm includes (i) learning reward function from human preference dataset, and (ii) learning expected cumulative reward of a target policy. Despite the huge empirical success, existing OPE methods with preference data often lack theoretical understanding and rely heavily on heuristics. In this paper, we study the sample efficiency of OPE with human preference and establish a statistical guarantee for it. Specifically, we approach OPE by learning the value function by fitted-Q-evaluation with a deep neural network. By appropriately selecting the size of a ReLU network, we show that one can leverage any lo
&lt;/p&gt;</description></item><item><title>NECO&#26159;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#22349;&#22604;&#30340;&#26032;&#39062;&#30340;&#36229;&#20986;&#20998;&#24067;&#26816;&#27979;&#26041;&#27861;&#65292;&#21033;&#29992;&#20960;&#20309;&#23646;&#24615;&#21644;&#20027;&#25104;&#20998;&#31354;&#38388;&#35782;&#21035;OOD&#25968;&#25454;&#65292;&#22312;&#23567;&#35268;&#27169;&#21644;&#22823;&#35268;&#27169;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.06823</link><description>&lt;p&gt;
NECO: &#22522;&#20110;&#31070;&#32463;&#22349;&#22604;&#30340;&#36229;&#20986;&#20998;&#24067;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
NECO: NEural Collapse Based Out-of-distribution detection. (arXiv:2310.06823v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06823
&lt;/p&gt;
&lt;p&gt;
NECO&#26159;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#22349;&#22604;&#30340;&#26032;&#39062;&#30340;&#36229;&#20986;&#20998;&#24067;&#26816;&#27979;&#26041;&#27861;&#65292;&#21033;&#29992;&#20960;&#20309;&#23646;&#24615;&#21644;&#20027;&#25104;&#20998;&#31354;&#38388;&#35782;&#21035;OOD&#25968;&#25454;&#65292;&#22312;&#23567;&#35268;&#27169;&#21644;&#22823;&#35268;&#27169;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#27169;&#22411;&#36807;&#20110;&#33258;&#20449;&#24182;&#19988;&#27809;&#26377;&#24847;&#35782;&#21040;&#20854;&#35748;&#35782;&#35770;&#38480;&#21046;&#65292;&#26816;&#27979;&#36229;&#20986;&#20998;&#24067;&#65288;OOD&#65289;&#25968;&#25454;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#12290;&#25105;&#20204;&#20551;&#35774;&#8220;&#31070;&#32463;&#22349;&#22604;&#8221;&#65292;&#19968;&#31181;&#24433;&#21709;&#36229;&#20986;&#20998;&#24067;&#25968;&#25454;&#30340;&#29616;&#35937;&#65292;&#20063;&#20250;&#24433;&#21709;&#36229;&#20986;&#20998;&#24067;&#25968;&#25454;&#12290;&#20026;&#20102;&#20174;&#36825;&#31181;&#30456;&#20114;&#20316;&#29992;&#20013;&#21463;&#30410;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;NECO&#65292;&#19968;&#31181;&#29992;&#20110;OOD&#26816;&#27979;&#30340;&#26032;&#39062;&#30340;&#20107;&#21518;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#8220;&#31070;&#32463;&#22349;&#22604;&#8221;&#21644;&#20027;&#25104;&#20998;&#31354;&#38388;&#30340;&#20960;&#20309;&#23646;&#24615;&#26469;&#35782;&#21035;OOD&#25968;&#25454;&#12290;&#25105;&#20204;&#30340;&#22823;&#37327;&#23454;&#39564;&#34920;&#26126;&#65292;NECO&#22312;&#23567;&#35268;&#27169;&#21644;&#22823;&#35268;&#27169;OOD&#26816;&#27979;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#22312;&#19981;&#21516;&#30340;&#32593;&#32476;&#26550;&#26500;&#19978;&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;OOD&#26816;&#27979;&#20013;&#30340;&#26377;&#25928;&#24615;&#25552;&#20379;&#20102;&#29702;&#35770;&#35299;&#37322;&#12290;&#25105;&#20204;&#35745;&#21010;&#22312;&#21311;&#21517;&#26399;&#32467;&#26463;&#21518;&#21457;&#24067;&#20195;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
Detecting out-of-distribution (OOD) data is a critical challenge in machine learning due to model overconfidence, often without awareness of their epistemological limits. We hypothesize that ``neural collapse'', a phenomenon affecting in-distribution data for models trained beyond loss convergence, also influences OOD data. To benefit from this interplay, we introduce NECO, a novel post-hoc method for OOD detection, which leverages the geometric properties of ``neural collapse'' and of principal component spaces to identify OOD data. Our extensive experiments demonstrate that NECO achieves state-of-the-art results on both small and large-scale OOD detection tasks while exhibiting strong generalization capabilities across different network architectures. Furthermore, we provide a theoretical explanation for the effectiveness of our method in OOD detection. We plan to release the code after the anonymity period.
&lt;/p&gt;</description></item><item><title>&#36825;&#26159;&#19968;&#31181;&#23616;&#37096;&#24179;&#31283;&#22270;&#24418;&#36807;&#31243;&#27169;&#22411;&#65292;&#26088;&#22312;&#23558;&#23616;&#37096;&#24179;&#31283;&#27010;&#24565;&#25193;&#23637;&#21040;&#19981;&#35268;&#21017;&#30340;&#22270;&#22495;&#19978;&#12290;&#23427;&#36890;&#36807;&#23558;&#25972;&#20010;&#36807;&#31243;&#34920;&#31034;&#20026;&#19968;&#32452;&#32452;&#25104;&#37096;&#20998;&#36807;&#31243;&#30340;&#32452;&#21512;&#26469;&#34920;&#24449;&#23616;&#37096;&#24179;&#31283;&#24615;&#65292;&#20197;&#20351;&#36807;&#31243;&#22312;&#22270;&#19978;&#25353;&#29031;&#27599;&#20010;&#32452;&#25104;&#37096;&#20998;&#30340;&#35201;&#27714;&#21464;&#21270;&#24471;&#26356;&#21152;&#24179;&#28369;&#12290;</title><link>http://arxiv.org/abs/2309.01657</link><description>&lt;p&gt;
&#23616;&#37096;&#24179;&#31283;&#22270;&#24418;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Locally Stationary Graph Processes. (arXiv:2309.01657v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01657
&lt;/p&gt;
&lt;p&gt;
&#36825;&#26159;&#19968;&#31181;&#23616;&#37096;&#24179;&#31283;&#22270;&#24418;&#36807;&#31243;&#27169;&#22411;&#65292;&#26088;&#22312;&#23558;&#23616;&#37096;&#24179;&#31283;&#27010;&#24565;&#25193;&#23637;&#21040;&#19981;&#35268;&#21017;&#30340;&#22270;&#22495;&#19978;&#12290;&#23427;&#36890;&#36807;&#23558;&#25972;&#20010;&#36807;&#31243;&#34920;&#31034;&#20026;&#19968;&#32452;&#32452;&#25104;&#37096;&#20998;&#36807;&#31243;&#30340;&#32452;&#21512;&#26469;&#34920;&#24449;&#23616;&#37096;&#24179;&#31283;&#24615;&#65292;&#20197;&#20351;&#36807;&#31243;&#22312;&#22270;&#19978;&#25353;&#29031;&#27599;&#20010;&#32452;&#25104;&#37096;&#20998;&#30340;&#35201;&#27714;&#21464;&#21270;&#24471;&#26356;&#21152;&#24179;&#28369;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19981;&#35268;&#21017;&#30340;&#32593;&#32476;&#25299;&#25169;&#19978;&#25910;&#38598;&#30340;&#25968;&#25454;&#38598;&#30340;&#20998;&#26512;&#21644;&#25512;&#29702;&#20013;&#65292;&#24120;&#24120;&#20250;&#20351;&#29992;&#24179;&#31283;&#22270;&#24418;&#36807;&#31243;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#20351;&#29992;&#21333;&#19968;&#30340;&#20840;&#23616;&#26377;&#25928;&#30340;&#24179;&#31283;&#36807;&#31243;&#27169;&#22411;&#34920;&#31034;&#22270;&#24418;&#20449;&#21495;&#65292;&#20294;&#22312;&#35768;&#22810;&#23454;&#38469;&#38382;&#39064;&#20013;&#65292;&#36807;&#31243;&#30340;&#29305;&#24615;&#21487;&#33021;&#20250;&#22312;&#22270;&#30340;&#19981;&#21516;&#21306;&#22495;&#21457;&#29983;&#23616;&#37096;&#21464;&#21270;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23616;&#37096;&#24179;&#31283;&#22270;&#24418;&#36807;&#31243;&#65288;LSGP&#65289;&#27169;&#22411;&#65292;&#26088;&#22312;&#23558;&#32463;&#20856;&#30340;&#23616;&#37096;&#24179;&#31283;&#27010;&#24565;&#25193;&#23637;&#21040;&#19981;&#35268;&#21017;&#30340;&#22270;&#22495;&#19978;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#25972;&#20010;&#36807;&#31243;&#34920;&#31034;&#20026;&#19968;&#32452;&#32452;&#25104;&#37096;&#20998;&#36807;&#31243;&#30340;&#32452;&#21512;&#26469;&#34920;&#24449;&#23616;&#37096;&#24179;&#31283;&#24615;&#65292;&#20197;&#20351;&#36807;&#31243;&#22312;&#22270;&#19978;&#25353;&#29031;&#27599;&#20010;&#32452;&#25104;&#37096;&#20998;&#30340;&#35201;&#27714;&#21464;&#21270;&#24471;&#26356;&#21152;&#24179;&#28369;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;LSGP&#27169;&#22411;&#30340;&#31639;&#27861;&#65292;&#24182;&#30740;&#31350;&#20102;&#29992;WSS&#36807;&#31243;&#23545;LSGP&#36827;&#34892;&#23616;&#37096;&#36817;&#20284;&#12290;&#22312;&#20449;&#21495;&#20869;&#25554;&#38382;&#39064;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#34920;&#26126;
&lt;/p&gt;
&lt;p&gt;
Stationary graph process models are commonly used in the analysis and inference of data sets collected on irregular network topologies. While most of the existing methods represent graph signals with a single stationary process model that is globally valid on the entire graph, in many practical problems, the characteristics of the process may be subject to local variations in different regions of the graph. In this work, we propose a locally stationary graph process (LSGP) model that aims to extend the classical concept of local stationarity to irregular graph domains. We characterize local stationarity by expressing the overall process as the combination of a set of component processes such that the extent to which the process adheres to each component varies smoothly over the graph. We propose an algorithm for computing LSGP models from realizations of the process, and also study the approximation of LSGPs locally with WSS processes. Experiments on signal interpolation problems show 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#39640;&#26031;&#21464;&#20998;&#36807;&#31243;&#21442;&#25968;&#21270;&#26041;&#27861;&#26469;&#26356;&#22909;&#22320;&#23398;&#20064;&#20855;&#26377;&#38750;&#32447;&#24615;&#25193;&#25955;&#36807;&#31243;&#30340;&#28508;&#22312;&#36807;&#31243;&#65292;&#27492;&#26041;&#27861;&#37319;&#29992;&#20855;&#26377;&#36830;&#32493;&#25351;&#25968;&#26063;&#25551;&#36848;&#30340;&#31639;&#27861;&#23454;&#29616;&#20984;&#20248;&#21270;&#65292;&#21487;&#20197;&#20195;&#26367;&#32531;&#24930;&#30340;&#20855;&#26377;&#22266;&#23450;&#28857;&#36845;&#20195;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.02066</link><description>&lt;p&gt;
&#21464;&#20998;&#39640;&#26031;&#36807;&#31243;&#25193;&#25955;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Variational Gaussian Process Diffusion Processes. (arXiv:2306.02066v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02066
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#39640;&#26031;&#21464;&#20998;&#36807;&#31243;&#21442;&#25968;&#21270;&#26041;&#27861;&#26469;&#26356;&#22909;&#22320;&#23398;&#20064;&#20855;&#26377;&#38750;&#32447;&#24615;&#25193;&#25955;&#36807;&#31243;&#30340;&#28508;&#22312;&#36807;&#31243;&#65292;&#27492;&#26041;&#27861;&#37319;&#29992;&#20855;&#26377;&#36830;&#32493;&#25351;&#25968;&#26063;&#25551;&#36848;&#30340;&#31639;&#27861;&#23454;&#29616;&#20984;&#20248;&#21270;&#65292;&#21487;&#20197;&#20195;&#26367;&#32531;&#24930;&#30340;&#20855;&#26377;&#22266;&#23450;&#28857;&#36845;&#20195;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#36807;&#31243;&#26159;&#19968;&#31867;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65292;&#25552;&#20379;&#20102;&#19968;&#31995;&#21015;&#34920;&#29616;&#20016;&#23500;&#30340;&#27169;&#22411;&#65292;&#33258;&#28982;&#22320;&#20986;&#29616;&#22312;&#21160;&#24577;&#24314;&#27169;&#20219;&#21153;&#20013;&#12290;&#27010;&#29575;&#25512;&#29702;&#21644;&#29983;&#25104;&#27169;&#22411;&#19979;&#20855;&#26377;&#38750;&#32447;&#24615;&#25193;&#25955;&#36807;&#31243;&#30340;&#28508;&#22312;&#36807;&#31243;&#30340;&#23398;&#20064;&#37117;&#26159;&#26840;&#25163;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#22312;&#21464;&#20998;&#25512;&#29702;&#30340;&#22522;&#30784;&#19978;&#26500;&#24314;&#39640;&#26031;&#36807;&#31243;&#25193;&#25955;&#36807;&#31243;&#30340;&#21442;&#25968;&#21270;&#65292;&#25351;&#20986;&#26041;&#27861;&#20013;&#30340;&#30149;&#24577;&#65292;&#24182;&#25552;&#20986;&#19968;&#31181;&#20351;&#29992;&#36830;&#32493;&#25351;&#25968;&#26063;&#25551;&#36848;&#30340;&#39640;&#26031;&#21464;&#20998;&#36807;&#31243;&#30340;&#26367;&#20195;&#21442;&#25968;&#21270;&#26041;&#27861;&#12290;&#36825;&#20351;&#25105;&#20204;&#21487;&#20197;&#29992;&#20984;&#20248;&#21270;&#30340;&#24555;&#36895;&#31639;&#27861;&#20195;&#26367;&#20855;&#26377;&#22266;&#23450;&#28857;&#36845;&#20195;&#30340;&#32531;&#24930;&#31639;&#27861;&#65292;&#36825;&#31181;&#31639;&#27861;&#31867;&#20284;&#20110;&#33258;&#28982;&#26799;&#24230;&#19979;&#38477;&#65292;&#21516;&#26102;&#25552;&#20379;&#26356;&#22909;&#30340;&#30446;&#26631;&#26469;&#23398;&#20064;&#27169;&#22411;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion processes are a class of stochastic differential equations (SDEs) providing a rich family of expressive models that arise naturally in dynamic modelling tasks. Probabilistic inference and learning under generative models with latent processes endowed with a non-linear diffusion process prior are intractable problems. We build upon work within variational inference approximating the posterior process as a linear diffusion process, point out pathologies in the approach, and propose an alternative parameterization of the Gaussian variational process using a continuous exponential family description. This allows us to trade a slow inference algorithm with fixed-point iterations for a fast algorithm for convex optimization akin to natural gradient descent, which also provides a better objective for the learning of model parameters.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24555;&#36895;&#30340;&#22810;&#36724;&#39640;&#26031;&#22270;&#24418;&#27169;&#22411;&#65292;&#29992;&#20110;&#26500;&#24314;&#31232;&#30095;&#22270;&#24418;&#34920;&#31034;&#12290;&#30456;&#27604;&#20808;&#21069;&#24037;&#20316;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#27599;&#20010;&#36724;&#19978;&#20165;&#20351;&#29992;&#19968;&#27425;&#29305;&#24449;&#20998;&#35299;&#65292;&#23454;&#29616;&#20102;&#25968;&#37327;&#32423;&#30340;&#21152;&#36895;&#12290;&#35813;&#27169;&#22411;&#21487;&#20197;&#24212;&#29992;&#20110;&#22823;&#22411;&#22810;&#27169;&#24577;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#21333;&#32454;&#32990;&#22810;&#32452;&#23398;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2211.02920</link><description>&lt;p&gt;
GmGM: &#19968;&#31181;&#24555;&#36895;&#30340;&#22810;&#36724;&#39640;&#26031;&#22270;&#24418;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
GmGM: a Fast Multi-Axis Gaussian Graphical Model. (arXiv:2211.02920v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.02920
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24555;&#36895;&#30340;&#22810;&#36724;&#39640;&#26031;&#22270;&#24418;&#27169;&#22411;&#65292;&#29992;&#20110;&#26500;&#24314;&#31232;&#30095;&#22270;&#24418;&#34920;&#31034;&#12290;&#30456;&#27604;&#20808;&#21069;&#24037;&#20316;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#27599;&#20010;&#36724;&#19978;&#20165;&#20351;&#29992;&#19968;&#27425;&#29305;&#24449;&#20998;&#35299;&#65292;&#23454;&#29616;&#20102;&#25968;&#37327;&#32423;&#30340;&#21152;&#36895;&#12290;&#35813;&#27169;&#22411;&#21487;&#20197;&#24212;&#29992;&#20110;&#22823;&#22411;&#22810;&#27169;&#24577;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#21333;&#32454;&#32990;&#22810;&#32452;&#23398;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#26031;&#22810;&#22270;&#24418;&#27169;&#22411;&#65292;&#29992;&#20110;&#26500;&#24314;&#30697;&#38453;&#21644;&#24352;&#37327;&#21464;&#37327;&#25968;&#25454;&#30340;&#31232;&#30095;&#22270;&#24418;&#34920;&#31034;&#12290;&#25105;&#20204;&#36890;&#36807;&#21516;&#26102;&#23398;&#20064;&#22810;&#20010;&#20849;&#20139;&#36724;&#30340;&#24352;&#37327;&#19978;&#30340;&#34920;&#31034;&#26469;&#25512;&#24191;&#35813;&#39046;&#22495;&#30340;&#20808;&#21069;&#24037;&#20316;&#65292;&#36825;&#23545;&#20110;&#20998;&#26512;&#22810;&#27169;&#24577;&#25968;&#25454;&#38598;&#65288;&#22914;&#22810;&#32452;&#23398;&#20013;&#36935;&#21040;&#30340;&#25968;&#25454;&#38598;&#65289;&#26159;&#24517;&#35201;&#30340;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#27599;&#20010;&#36724;&#19978;&#20165;&#20351;&#29992;&#19968;&#27425;&#29305;&#24449;&#20998;&#35299;&#65292;&#30456;&#23545;&#20110;&#38750;&#24191;&#20041;&#24773;&#20917;&#19979;&#30340;&#20808;&#21069;&#24037;&#20316;&#23454;&#29616;&#20102;&#25968;&#37327;&#32423;&#30340;&#21152;&#36895;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#21253;&#25324;&#21333;&#32454;&#32990;&#22810;&#32452;&#23398;&#25968;&#25454;&#22312;&#20869;&#30340;&#22823;&#22411;&#22810;&#27169;&#24577;&#25968;&#25454;&#38598;&#65292;&#36825;&#22312;&#20043;&#21069;&#30340;&#26041;&#27861;&#20013;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#20116;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces the Gaussian multi-Graphical Model, a model to construct sparse graph representations of matrix- and tensor-variate data. We generalize prior work in this area by simultaneously learning this representation across several tensors that share axes, which is necessary to allow the analysis of multimodal datasets such as those encountered in multi-omics. Our algorithm uses only a single eigendecomposition per axis, achieving an order of magnitude speedup over prior work in the ungeneralized case. This allows the use of our methodology on large multi-modal datasets such as single-cell multi-omics data, which was challenging with previous approaches. We validate our model on synthetic data and five real-world datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#35299;&#20915;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22797;&#21512;&#26816;&#39564;&#38382;&#39064;&#65292;&#20854;&#26680;&#24515;&#24605;&#24819;&#26159;&#22312;&#27491;&#30830;&#30340;&#27169;&#22411;&#35268;&#33539;&#30340;&#38646;&#20551;&#35774;&#19979;&#65292;&#38750;&#21442;&#25968;&#22320;&#20272;&#35745;&#21442;&#25968;&#65288;&#25110;&#27169;&#25311;&#22120;&#65289;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2111.10275</link><description>&lt;p&gt;
&#24102;&#26377;&#26680;&#30340;&#22797;&#21512;&#36866;&#21512;&#24615;&#26816;&#39564;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Composite Goodness-of-fit Tests with Kernels. (arXiv:2111.10275v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.10275
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#35299;&#20915;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22797;&#21512;&#26816;&#39564;&#38382;&#39064;&#65292;&#20854;&#26680;&#24515;&#24605;&#24819;&#26159;&#22312;&#27491;&#30830;&#30340;&#27169;&#22411;&#35268;&#33539;&#30340;&#38646;&#20551;&#35774;&#19979;&#65292;&#38750;&#21442;&#25968;&#22320;&#20272;&#35745;&#21442;&#25968;&#65288;&#25110;&#27169;&#25311;&#22120;&#65289;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#38169;&#35823;&#35828;&#26126;&#21487;&#33021;&#20250;&#23545;&#27010;&#29575;&#27169;&#22411;&#30340;&#23454;&#29616;&#36896;&#25104;&#37325;&#22823;&#25361;&#25112;&#65292;&#36825;&#20419;&#20351;&#24320;&#21457;&#20986;&#19968;&#20123;&#30452;&#25509;&#35299;&#20915;&#27492;&#38382;&#39064;&#30340;&#40065;&#26834;&#26041;&#27861;&#12290;&#20294;&#26159;&#65292;&#36825;&#20123;&#26356;&#20026;&#22797;&#26434;&#30340;&#26041;&#27861;&#26159;&#21542;&#38656;&#35201;&#21462;&#20915;&#20110;&#27169;&#22411;&#26159;&#21542;&#30495;&#30340;&#38169;&#35823;&#65292;&#30446;&#21069;&#32570;&#20047;&#36890;&#29992;&#30340;&#26041;&#27861;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#26680;&#30340;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22797;&#21512;&#26816;&#39564;&#38382;&#39064;&#65292;&#21363;&#25105;&#20204;&#26159;&#21542;&#24863;&#20852;&#36259;&#30340;&#25968;&#25454;&#26469;&#33258;&#26576;&#20123;&#21442;&#25968;&#27169;&#22411;&#26063;&#20013;&#30340;&#20219;&#20309;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#27979;&#35797;&#21033;&#29992;&#22522;&#20110;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#21644;&#26680;Stein&#24046;&#24322;&#30340;&#26368;&#23567;&#36317;&#31163;&#20272;&#35745;&#22120;&#12290;&#23427;&#20204;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#65292;&#21253;&#25324;&#24403;&#21442;&#25968;&#27169;&#22411;&#30340;&#23494;&#24230;&#24050;&#30693;&#38500;&#26631;&#20934;&#21270;&#24120;&#25968;&#22806;&#65292;&#25110;&#32773;&#22914;&#26524;&#27169;&#22411;&#37319;&#29992;&#27169;&#25311;&#22120;&#24418;&#24335;&#12290;&#20316;&#20026;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#27491;&#30830;&#30340;&#27169;&#22411;&#35268;&#33539;&#30340;&#38646;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#33021;&#22815;&#38750;&#21442;&#25968;&#22320;&#20272;&#35745;&#21442;&#25968;&#65288;&#25110;&#27169;&#25311;&#22120;&#65289;&#20998;&#24067;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#24314;&#31435;&#25105;&#20204;&#26041;&#27861;&#26377;&#25928;&#24615;&#30340;&#29702;&#35770;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#21644;&#24322;&#24120;&#26816;&#27979;&#24212;&#29992;&#26696;&#20363;&#28436;&#31034;&#20102;&#20854;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model misspecification can create significant challenges for the implementation of probabilistic models, and this has led to development of a range of robust methods which directly account for this issue. However, whether these more involved methods are required will depend on whether the model is really misspecified, and there is a lack of generally applicable methods to answer this question. In this paper, we propose one such method. More precisely, we propose kernel-based hypothesis tests for the challenging composite testing problem, where we are interested in whether the data comes from any distribution in some parametric family. Our tests make use of minimum distance estimators based on the maximum mean discrepancy and the kernel Stein discrepancy. They are widely applicable, including whenever the density of the parametric model is known up to normalisation constant, or if the model takes the form of a simulator. As our main result, we show that we are able to estimate the param
&lt;/p&gt;</description></item></channel></rss>