<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#24605;&#32500;&#38142;&#36171;&#20104;&#21464;&#21387;&#22120;&#27169;&#22411;&#25191;&#34892;&#22266;&#26377;&#20018;&#34892;&#35745;&#31639;&#30340;&#33021;&#21147;&#65292;&#25552;&#39640;&#20102;&#21464;&#21387;&#22120;&#22312;&#31639;&#26415;&#21644;&#31526;&#21495;&#25512;&#29702;&#20219;&#21153;&#20013;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.12875</link><description>&lt;p&gt;
&#24605;&#32500;&#38142;&#28608;&#21457;&#21464;&#21387;&#22120;&#35299;&#20915;&#22266;&#26377;&#20018;&#34892;&#38382;&#39064;&#30340;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Chain of Thought Empowers Transformers to Solve Inherently Serial Problems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12875
&lt;/p&gt;
&lt;p&gt;
&#24605;&#32500;&#38142;&#36171;&#20104;&#21464;&#21387;&#22120;&#27169;&#22411;&#25191;&#34892;&#22266;&#26377;&#20018;&#34892;&#35745;&#31639;&#30340;&#33021;&#21147;&#65292;&#25552;&#39640;&#20102;&#21464;&#21387;&#22120;&#22312;&#31639;&#26415;&#21644;&#31526;&#21495;&#25512;&#29702;&#20219;&#21153;&#20013;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25351;&#23548;&#27169;&#22411;&#29983;&#25104;&#19968;&#31995;&#21015;&#20013;&#38388;&#27493;&#39588;&#65292;&#21363;&#24605;&#32500;&#38142;&#65288;CoT&#65289;&#65292;&#26159;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#31639;&#26415;&#21644;&#31526;&#21495;&#25512;&#29702;&#20219;&#21153;&#19978;&#20934;&#30830;&#24615;&#30340;&#39640;&#25928;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;CoT&#32972;&#21518;&#30340;&#26426;&#21046;&#20173;&#19981;&#28165;&#26970;&#12290;&#36825;&#39033;&#24037;&#20316;&#36890;&#36807;&#34920;&#36798;&#24615;&#30340;&#35270;&#35282;&#25552;&#20379;&#20102;&#23545;&#35299;&#30721;&#22120;&#19987;&#29992;&#21464;&#21387;&#22120;&#30340;CoT&#33021;&#21147;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;&#22312;&#27010;&#24565;&#19978;&#65292;CoT&#36171;&#20104;&#27169;&#22411;&#25191;&#34892;&#22266;&#26377;&#20018;&#34892;&#35745;&#31639;&#30340;&#33021;&#21147;&#65292;&#32780;&#36825;&#31181;&#33021;&#21147;&#22312;&#21464;&#21387;&#22120;&#20013;&#32570;&#20047;&#65292;&#29305;&#21035;&#26159;&#24403;&#28145;&#24230;&#36739;&#20302;&#26102;&#12290;&#20808;&#21069;&#30340;&#20316;&#21697;&#24050;&#32463;&#34920;&#26126;&#65292;&#22312;&#27809;&#26377;CoT&#30340;&#24773;&#20917;&#19979;&#65292;&#20855;&#26377;&#26377;&#38480;&#31934;&#24230;$\mathsf{poly}(n)$&#23884;&#20837;&#23610;&#23544;&#30340;&#24658;&#23450;&#28145;&#24230;&#21464;&#21387;&#22120;&#21482;&#33021;&#22312;$\mathsf{TC}^0$&#20013;&#35299;&#20915;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#20855;&#26377;&#24120;&#25968;&#20301;&#31934;&#24230;&#30340;&#24658;&#23450;&#28145;&#24230;&#21464;&#21387;&#22120;&#30340;&#26356;&#32039;&#23494;&#30340;&#34920;&#36798;&#24615;&#19978;&#30028;&#65292;&#23427;&#21482;&#33021;&#35299;&#20915;$\mathsf{AC}^0$&#20013;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12875v1 Announce Type: new  Abstract: Instructing the model to generate a sequence of intermediate steps, a.k.a., a chain of thought (CoT), is a highly effective method to improve the accuracy of large language models (LLMs) on arithmetics and symbolic reasoning tasks. However, the mechanism behind CoT remains unclear. This work provides a theoretical understanding of the power of CoT for decoder-only transformers through the lens of expressiveness. Conceptually, CoT empowers the model with the ability to perform inherently serial computation, which is otherwise lacking in transformers, especially when depth is low. Given input length $n$, previous works have shown that constant-depth transformers with finite precision $\mathsf{poly}(n)$ embedding size can only solve problems in $\mathsf{TC}^0$ without CoT. We first show an even tighter expressiveness upper bound for constant-depth transformers with constant-bit precision, which can only solve problems in $\mathsf{AC}^0$, a 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#36817;&#30830;&#23450;&#24615;&#22238;&#24402;&#20013;&#38169;&#35823;&#35268;&#33539;&#21270;&#30340;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32452;&#21512;&#27169;&#22411;&#65292;&#20197;&#20934;&#30830;&#39044;&#27979;&#21644;&#25511;&#21046;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.01810</link><description>&lt;p&gt;
&#36817;&#30830;&#23450;&#24615;&#22238;&#24402;&#20013;&#30340;&#38169;&#35823;&#35268;&#33539;&#21270;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Misspecification uncertainties in near-deterministic regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01810
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#36817;&#30830;&#23450;&#24615;&#22238;&#24402;&#20013;&#38169;&#35823;&#35268;&#33539;&#21270;&#30340;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32452;&#21512;&#27169;&#22411;&#65292;&#20197;&#20934;&#30830;&#39044;&#27979;&#21644;&#25511;&#21046;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26399;&#26395;&#25439;&#22833;&#26159;&#27169;&#22411;&#27867;&#21270;&#35823;&#24046;&#30340;&#19978;&#30028;&#65292;&#21487;&#29992;&#20110;&#23398;&#20064;&#30340;&#40065;&#26834;PAC-Bayes&#36793;&#30028;&#12290;&#28982;&#32780;&#65292;&#25439;&#22833;&#26368;&#23567;&#21270;&#34987;&#35748;&#20026;&#24573;&#30053;&#20102;&#38169;&#35823;&#35268;&#33539;&#21270;&#65292;&#21363;&#27169;&#22411;&#19981;&#33021;&#23436;&#20840;&#22797;&#21046;&#35266;&#27979;&#32467;&#26524;&#12290;&#36825;&#23548;&#33268;&#22823;&#25968;&#25454;&#25110;&#27424;&#21442;&#25968;&#21270;&#26497;&#38480;&#19979;&#23545;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#30340;&#26174;&#33879;&#20302;&#20272;&#12290;&#25105;&#20204;&#20998;&#26512;&#36817;&#30830;&#23450;&#24615;&#12289;&#38169;&#35823;&#35268;&#33539;&#21270;&#21644;&#27424;&#21442;&#25968;&#21270;&#26367;&#20195;&#27169;&#22411;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#36825;&#26159;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#24191;&#27867;&#30456;&#20851;&#30340;&#19968;&#20010;&#39046;&#22495;&#12290;&#25105;&#20204;&#35777;&#26126;&#21518;&#39564;&#20998;&#24067;&#24517;&#39035;&#35206;&#30422;&#27599;&#20010;&#35757;&#32451;&#28857;&#65292;&#20197;&#36991;&#20813;&#21457;&#25955;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#24182;&#23548;&#20986;&#19968;&#20010;&#31526;&#21512;&#36825;&#20010;&#32422;&#26463;&#30340;&#32452;&#21512;&#27169;&#22411;&#12290;&#23545;&#20110;&#32447;&#24615;&#27169;&#22411;&#65292;&#36825;&#31181;&#39640;&#25928;&#30340;&#26041;&#27861;&#20135;&#29983;&#30340;&#39069;&#22806;&#24320;&#38144;&#26368;&#23567;&#12290;&#36825;&#31181;&#39640;&#25928;&#26041;&#27861;&#22312;&#27169;&#22411;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#28436;&#31034;&#65292;&#28982;&#21518;&#24212;&#29992;&#20110;&#21407;&#23376;&#23610;&#24230;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#39640;&#32500;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
The expected loss is an upper bound to the model generalization error which admits robust PAC-Bayes bounds for learning. However, loss minimization is known to ignore misspecification, where models cannot exactly reproduce observations. This leads to significant underestimates of parameter uncertainties in the large data, or underparameterized, limit. We analyze the generalization error of near-deterministic, misspecified and underparametrized surrogate models, a regime of broad relevance in science and engineering. We show posterior distributions must cover every training point to avoid a divergent generalization error and derive an ensemble {ansatz} that respects this constraint, which for linear models incurs minimal overhead. The efficient approach is demonstrated on model problems before application to high dimensional datasets in atomistic machine learning. Parameter uncertainties from misspecification survive in the underparametrized limit, giving accurate prediction and boundin
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#32593;&#32476;&#37325;&#24314;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27425;&#20108;&#27425;&#26102;&#38388;&#20869;&#23454;&#29616;&#32467;&#26524;&#65292;&#36890;&#36807;&#38543;&#26426;&#30340;&#20108;&#38454;&#37051;&#23621;&#25628;&#32034;&#20135;&#29983;&#26368;&#20339;&#30340;&#36793;&#20505;&#36873;&#12290;</title><link>http://arxiv.org/abs/2401.01404</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;&#23376;&#20108;&#27425;&#26102;&#38388;&#32593;&#32476;&#37325;&#24314;
&lt;/p&gt;
&lt;p&gt;
Scalable network reconstruction in subquadratic time. (arXiv:2401.01404v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01404
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#32593;&#32476;&#37325;&#24314;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27425;&#20108;&#27425;&#26102;&#38388;&#20869;&#23454;&#29616;&#32467;&#26524;&#65292;&#36890;&#36807;&#38543;&#26426;&#30340;&#20108;&#38454;&#37051;&#23621;&#25628;&#32034;&#20135;&#29983;&#26368;&#20339;&#30340;&#36793;&#20505;&#36873;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#37325;&#24314;&#26159;&#25351;&#22312;&#21482;&#26377;&#20851;&#20110;&#26465;&#20214;&#20598;&#32852;&#30340;&#35266;&#27979;&#25968;&#25454;&#65292;&#20363;&#22914;&#26102;&#38388;&#24207;&#21015;&#25110;&#22270;&#27169;&#22411;&#30340;&#29420;&#31435;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#65292;&#30830;&#23450;N&#20010;&#33410;&#28857;&#20043;&#38388;&#26410;&#35266;&#27979;&#21040;&#30340;&#25104;&#23545;&#32806;&#21512;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#25552;&#20986;&#30340;&#31639;&#27861;&#30340;&#21487;&#25193;&#23637;&#24615;&#30340;&#20027;&#35201;&#38556;&#30861;&#26159;&#20284;&#20046;&#26080;&#27861;&#36991;&#20813;&#30340;&#20108;&#27425;&#22797;&#26434;&#24230;O(N^2)&#65292;&#21363;&#35201;&#32771;&#34385;&#27599;&#31181;&#21487;&#33021;&#30340;&#25104;&#23545;&#32806;&#21512;&#33267;&#23569;&#19968;&#27425;&#65292;&#23613;&#31649;&#22823;&#22810;&#25968;&#24863;&#20852;&#36259;&#30340;&#32593;&#32476;&#37117;&#26159;&#31232;&#30095;&#30340;&#65292;&#38750;&#38646;&#32806;&#21512;&#30340;&#25968;&#37327;&#21482;&#26377;O(N)&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#24191;&#27867;&#37325;&#24314;&#38382;&#39064;&#30340;&#36890;&#29992;&#31639;&#27861;&#65292;&#20854;&#22312;&#23376;&#20108;&#27425;&#26102;&#38388;&#20869;&#23454;&#29616;&#32467;&#26524;&#65292;&#20854;&#25968;&#25454;&#30456;&#20851;&#22797;&#26434;&#24230;&#23485;&#26494;&#19978;&#30028;&#20026;O(N^(3/2)logN)&#65292;&#20294;&#20855;&#26377;&#26356;&#20856;&#22411;&#30340;&#23545;&#25968;&#32447;&#24615;&#22797;&#26434;&#24230;O(Nlog^2 N)&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20381;&#36182;&#20110;&#19968;&#20010;&#38543;&#26426;&#30340;&#20108;&#38454;&#37051;&#23621;&#25628;&#32034;&#65292;&#20135;&#29983;&#20102;&#26368;&#20339;&#30340;&#36793;&#20505;&#36873;&#12290;
&lt;/p&gt;
&lt;p&gt;
Network reconstruction consists in determining the unobserved pairwise couplings between $N$ nodes given only observational data on the resulting behavior that is conditioned on those couplings -- typically a time-series or independent samples from a graphical model. A major obstacle to the scalability of algorithms proposed for this problem is a seemingly unavoidable quadratic complexity of $O(N^2)$, corresponding to the requirement of each possible pairwise coupling being contemplated at least once, despite the fact that most networks of interest are sparse, with a number of non-zero couplings that is only $O(N)$. Here we present a general algorithm applicable to a broad range of reconstruction problems that achieves its result in subquadratic time, with a data-dependent complexity loosely upper bounded by $O(N^{3/2}\log N)$, but with a more typical log-linear complexity of $O(N\log^2N)$. Our algorithm relies on a stochastic second neighbor search that produces the best edge candidat
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#20915;&#31574;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#23545;&#20110;&#20219;&#20309;&#36125;&#21494;&#26031;&#22238;&#24402;&#27169;&#22411;&#65292;&#21487;&#20197;&#24471;&#21040;&#27599;&#20010;&#26465;&#20214;&#20998;&#20301;&#25968;&#30340;&#26368;&#20339;&#21644;&#21487;&#35299;&#37322;&#30340;&#32447;&#24615;&#20272;&#35745;&#20540;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#35813;&#26041;&#27861;&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#29305;&#23450;&#20998;&#20301;&#25968;&#23376;&#38598;&#36873;&#25321;&#30340;&#26377;&#25928;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2311.02043</link><description>&lt;p&gt;
&#22522;&#20110;&#23376;&#38598;&#36873;&#25321;&#30340;&#36125;&#21494;&#26031;&#20998;&#20301;&#22238;&#24402;&#65306;&#21518;&#39564;&#24635;&#32467;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Bayesian Quantile Regression with Subset Selection: A Posterior Summarization Perspective. (arXiv:2311.02043v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.02043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#20915;&#31574;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#23545;&#20110;&#20219;&#20309;&#36125;&#21494;&#26031;&#22238;&#24402;&#27169;&#22411;&#65292;&#21487;&#20197;&#24471;&#21040;&#27599;&#20010;&#26465;&#20214;&#20998;&#20301;&#25968;&#30340;&#26368;&#20339;&#21644;&#21487;&#35299;&#37322;&#30340;&#32447;&#24615;&#20272;&#35745;&#20540;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#35813;&#26041;&#27861;&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#29305;&#23450;&#20998;&#20301;&#25968;&#23376;&#38598;&#36873;&#25321;&#30340;&#26377;&#25928;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#20301;&#22238;&#24402;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#24037;&#20855;&#65292;&#29992;&#20110;&#25512;&#26029;&#21327;&#21464;&#37327;&#22914;&#20309;&#24433;&#21709;&#21709;&#24212;&#20998;&#24067;&#30340;&#29305;&#23450;&#20998;&#20301;&#25968;&#12290;&#29616;&#26377;&#26041;&#27861;&#35201;&#20040;&#20998;&#21035;&#20272;&#35745;&#27599;&#20010;&#24863;&#20852;&#36259;&#20998;&#20301;&#25968;&#30340;&#26465;&#20214;&#20998;&#20301;&#25968;&#65292;&#35201;&#20040;&#20351;&#29992;&#21322;&#21442;&#25968;&#25110;&#38750;&#21442;&#25968;&#27169;&#22411;&#20272;&#35745;&#25972;&#20010;&#26465;&#20214;&#20998;&#24067;&#12290;&#21069;&#32773;&#32463;&#24120;&#20135;&#29983;&#19981;&#36866;&#21512;&#23454;&#38469;&#25968;&#25454;&#30340;&#27169;&#22411;&#65292;&#24182;&#19988;&#19981;&#22312;&#20998;&#20301;&#25968;&#20043;&#38388;&#20849;&#20139;&#20449;&#24687;&#65292;&#32780;&#21518;&#32773;&#21017;&#20197;&#22797;&#26434;&#19988;&#21463;&#38480;&#21046;&#30340;&#27169;&#22411;&#20026;&#29305;&#28857;&#65292;&#38590;&#20197;&#35299;&#37322;&#21644;&#35745;&#31639;&#25928;&#29575;&#20302;&#19979;&#12290;&#27492;&#22806;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#19981;&#36866;&#21512;&#20110;&#29305;&#23450;&#20998;&#20301;&#25968;&#30340;&#23376;&#38598;&#36873;&#25321;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#20174;&#36125;&#21494;&#26031;&#20915;&#31574;&#20998;&#26512;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#25552;&#20986;&#20102;&#32447;&#24615;&#20998;&#20301;&#20272;&#35745;&#12289;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#23376;&#38598;&#36873;&#25321;&#30340;&#22522;&#26412;&#38382;&#39064;&#12290;&#23545;&#20110;&#20219;&#20309;&#36125;&#21494;&#26031;&#22238;&#24402;&#27169;&#22411;&#65292;&#25105;&#20204;&#20026;&#27599;&#20010;&#22522;&#20110;&#27169;&#22411;&#30340;&#26465;&#20214;&#20998;&#20301;&#25968;&#25512;&#23548;&#20986;&#26368;&#20339;&#21644;&#21487;&#35299;&#37322;&#30340;&#32447;&#24615;&#20272;&#35745;&#20540;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#24341;&#20837;&#20102;&#19968;&#31181;&#20998;&#20301;&#25968;&#32858;&#28966;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantile regression is a powerful tool for inferring how covariates affect specific percentiles of the response distribution. Existing methods either estimate conditional quantiles separately for each quantile of interest or estimate the entire conditional distribution using semi- or non-parametric models. The former often produce inadequate models for real data and do not share information across quantiles, while the latter are characterized by complex and constrained models that can be difficult to interpret and computationally inefficient. Further, neither approach is well-suited for quantile-specific subset selection. Instead, we pose the fundamental problems of linear quantile estimation, uncertainty quantification, and subset selection from a Bayesian decision analysis perspective. For any Bayesian regression model, we derive optimal and interpretable linear estimates and uncertainty quantification for each model-based conditional quantile. Our approach introduces a quantile-focu
&lt;/p&gt;</description></item><item><title>&#28145;&#24230;&#23398;&#20064;&#20013;&#24120;&#29992;&#30340;MLP&#26377;&#28508;&#21147;&#25552;&#39640;&#24615;&#33021;&#12290;&#26412;&#30740;&#31350;&#25581;&#31034;MLP-Mixer &#21487;&#20197;&#20316;&#20026;&#20855;&#26377;&#31232;&#30095;&#26435;&#37325;&#30340;&#23485;MLP&#26377;&#25928;&#22320;&#24037;&#20316;&#12290;</title><link>http://arxiv.org/abs/2306.01470</link><description>&lt;p&gt;
MLP-Mixer&#20316;&#20026;&#23485;&#19988;&#31232;&#30095;&#30340;MLP
&lt;/p&gt;
&lt;p&gt;
MLP-Mixer as a Wide and Sparse MLP. (arXiv:2306.01470v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01470
&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#20013;&#24120;&#29992;&#30340;MLP&#26377;&#28508;&#21147;&#25552;&#39640;&#24615;&#33021;&#12290;&#26412;&#30740;&#31350;&#25581;&#31034;MLP-Mixer &#21487;&#20197;&#20316;&#20026;&#20855;&#26377;&#31232;&#30095;&#26435;&#37325;&#30340;&#23485;MLP&#26377;&#25928;&#22320;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#23618;&#24863;&#30693;&#22120;(MLP)&#26159;&#28145;&#24230;&#23398;&#20064;&#20013;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#22810;&#31181;&#38382;&#39064;&#30340;&#22522;&#30784;&#32452;&#20214;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#22522;&#20110;MLP&#30340;&#26550;&#26500;(&#29305;&#21035;&#26159;MLP-Mixer)&#30340;&#23454;&#35777;&#25104;&#21151;&#34920;&#26126;&#65292;&#25552;&#39640;MLP&#30340;&#24615;&#33021;&#20173;&#20855;&#26377;&#28508;&#22312;&#30340;&#28508;&#21147;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;MLP-Mixer&#26377;&#25928;&#22320;&#20316;&#20026;&#20855;&#26377;&#26576;&#20123;&#31232;&#30095;&#26435;&#37325;&#30340;&#23485;MLP&#12290;&#26368;&#21021;&#65292;&#25105;&#20204;&#28548;&#28165;Mixer&#30340;&#28151;&#21512;&#23618;&#21487;&#20197;&#20316;&#20026;&#20855;&#26377;&#31232;&#30095;&#26435;&#37325;&#19988;&#30001;Kronecker&#20056;&#31215;&#34920;&#31034;&#30340;&#26356;&#23485;MLP&#30340;&#26377;&#25928;&#34920;&#36798;&#12290;&#35813;&#34920;&#36798;&#24335;&#33258;&#28982;&#22320;&#23450;&#20041;&#20102;&#19968;&#32452;&#32622;&#25442;-Kronecker(PK)&#23478;&#26063;&#65292;&#21487;&#20197;&#34987;&#35270;&#20026;&#28151;&#21512;&#23618;&#30340;&#19968;&#33324;&#31867;&#65292;&#20063;&#21487;&#20197;&#34987;&#35270;&#20026;Monarch&#30697;&#38453;&#30340;&#19968;&#31181;&#36817;&#20284;&#12290;&#38543;&#21518;&#65292;&#30001;&#20110;PK&#23478;&#26063;&#26377;&#25928;&#26500;&#25104;&#20855;&#26377;&#31232;&#30095;&#26435;&#37325;&#30340;&#23485;MLP&#65292;&#22240;&#27492;&#65292;&#21487;&#20197;&#24212;&#29992;Golubeva&#12289;Neyshabur&#21644;Gur-Ari(2021)&#25552;&#20986;&#30340;&#20551;&#35774;&#65292;&#21363;&#39044;&#27979;&#24615;&#33021;&#65306;
&lt;/p&gt;
&lt;p&gt;
Multi-layer perceptron (MLP) is a fundamental component of deep learning that has been extensively employed for various problems. However, recent empirical successes in MLP-based architectures, particularly the progress of the MLP-Mixer, have revealed that there is still hidden potential in improving MLPs to achieve better performance. In this study, we reveal that the MLP-Mixer works effectively as a wide MLP with certain sparse weights. Initially, we clarify that the mixing layer of the Mixer has an effective expression as a wider MLP whose weights are sparse and represented by the Kronecker product. This expression naturally defines a permuted-Kronecker (PK) family, which can be regarded as a general class of mixing layers and is also regarded as an approximation of Monarch matrices. Subsequently, because the PK family effectively constitutes a wide MLP with sparse weights, one can apply the hypothesis proposed by Golubeva, Neyshabur and Gur-Ari (2021) that the prediction performanc
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20551;&#35774;&#31616;&#32422;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#26816;&#39564;&#26041;&#27861;&#65292;&#21033;&#29992;&#38750;&#21442;&#25968;&#25110;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#23454;&#29616;&#31283;&#20581;&#30340;&#35823;&#24046;&#25511;&#21046;&#21644;&#39640;&#21151;&#25928;&#12290;</title><link>http://arxiv.org/abs/2211.02039</link><description>&lt;p&gt;
&#20551;&#35774;&#31616;&#32422;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#26816;&#39564;&#30340;&#25237;&#24433;&#21327;&#26041;&#24046;&#27979;&#37327;
&lt;/p&gt;
&lt;p&gt;
The Projected Covariance Measure for assumption-lean variable significance testing. (arXiv:2211.02039v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.02039
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20551;&#35774;&#31616;&#32422;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#26816;&#39564;&#26041;&#27861;&#65292;&#21033;&#29992;&#38750;&#21442;&#25968;&#25110;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#23454;&#29616;&#31283;&#20581;&#30340;&#35823;&#24046;&#25511;&#21046;&#21644;&#39640;&#21151;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32479;&#35745;&#23398;&#20013;&#65292;&#23545;&#20110;&#32473;&#23450;&#38468;&#21152;&#21327;&#21464;&#37327;Z&#65292;&#27979;&#35797;&#21464;&#37327;&#25110;&#21464;&#37327;&#32452;X&#23545;&#20110;&#39044;&#27979;&#21709;&#24212;Y&#30340;&#37325;&#35201;&#24615;&#26159;&#19968;&#39033;&#26222;&#36941;&#20219;&#21153;&#12290;&#19968;&#31181;&#31616;&#21333;&#20294;&#24120;&#35265;&#30340;&#26041;&#27861;&#26159;&#25351;&#23450;&#19968;&#20010;&#32447;&#24615;&#27169;&#22411;&#65292;&#28982;&#21518;&#27979;&#35797;X&#30340;&#22238;&#24402;&#31995;&#25968;&#26159;&#21542;&#20026;&#38750;&#38646;&#12290;&#28982;&#32780;&#65292;&#24403;&#27169;&#22411;&#38169;&#35823;&#25351;&#23450;&#26102;&#65292;&#27979;&#35797;&#30340;&#21151;&#25928;&#21487;&#33021;&#24456;&#24046;&#65292;&#20363;&#22914;&#24403;X&#21442;&#19982;&#22797;&#26434;&#30340;&#20132;&#20114;&#20316;&#29992;&#65292;&#25110;&#32773;&#23548;&#33268;&#35768;&#22810;&#38169;&#35823;&#25298;&#32477;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#27979;&#35797;&#26465;&#20214;&#22343;&#20540;&#29420;&#31435;&#30340;&#26080;&#27169;&#22411;&#20551;&#35774;&#65292;&#21363;&#32473;&#23450;X&#21644;Z&#65292;Y&#30340;&#26465;&#20214;&#22343;&#20540;&#19981;&#20381;&#36182;&#20110;X&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#36890;&#29992;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#21033;&#29992;&#28789;&#27963;&#30340;&#38750;&#21442;&#25968;&#25110;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#22914;&#21152;&#27861;&#27169;&#22411;&#25110;&#38543;&#26426;&#26862;&#26519;&#65292;&#23454;&#29616;&#31283;&#20581;&#30340;&#35823;&#24046;&#25511;&#21046;&#21644;&#39640;&#21151;&#25928;&#12290;&#35813;&#36807;&#31243;&#21253;&#25324;&#20351;&#29992;&#36825;&#20123;&#26041;&#27861;&#36827;&#34892;&#22238;&#24402;&#65292;&#39318;&#20808;&#20351;&#29992;&#19968;&#21322;&#30340;&#25968;&#25454;&#20272;&#35745;&#20197;X&#21644;Z&#20026;&#22522;&#30784;&#30340;Y&#30340;&#19968;&#31181;&#25237;&#24433;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Testing the significance of a variable or group of variables $X$ for predicting a response $Y$, given additional covariates $Z$, is a ubiquitous task in statistics. A simple but common approach is to specify a linear model, and then test whether the regression coefficient for $X$ is non-zero. However, when the model is misspecified, the test may have poor power, for example when $X$ is involved in complex interactions, or lead to many false rejections. In this work we study the problem of testing the model-free null of conditional mean independence, i.e. that the conditional mean of $Y$ given $X$ and $Z$ does not depend on $X$. We propose a simple and general framework that can leverage flexible nonparametric or machine learning methods, such as additive models or random forests, to yield both robust error control and high power. The procedure involves using these methods to perform regressions, first to estimate a form of projection of $Y$ on $X$ and $Z$ using one half of the data, an
&lt;/p&gt;</description></item></channel></rss>