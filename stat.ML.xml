<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#36890;&#29992;&#21270;&#30340;&#20132;&#26131;&#25191;&#34892;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#29616;&#26377;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#23384;&#22312;&#36807;&#25311;&#21512;&#38382;&#39064;&#65292;&#38459;&#30861;&#20102;&#23454;&#38469;&#24212;&#29992;&#12290;&#20316;&#32773;&#36890;&#36807;&#20351;&#29992;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#21644;&#21160;&#24577;&#19978;&#19979;&#25991;&#24314;&#27169;&#26469;&#35299;&#20915;&#36807;&#25311;&#21512;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#23398;&#20064;&#19978;&#19979;&#25991;&#30340;&#32039;&#20945;&#34920;&#31034;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.11685</link><description>&lt;p&gt;
&#38754;&#21521;&#36890;&#29992;&#21270;&#30340;&#20132;&#26131;&#25191;&#34892;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Towards Generalizable Reinforcement Learning for Trade Execution. (arXiv:2307.11685v1 [q-fin.TR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11685
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#36890;&#29992;&#21270;&#30340;&#20132;&#26131;&#25191;&#34892;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#29616;&#26377;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#23384;&#22312;&#36807;&#25311;&#21512;&#38382;&#39064;&#65292;&#38459;&#30861;&#20102;&#23454;&#38469;&#24212;&#29992;&#12290;&#20316;&#32773;&#36890;&#36807;&#20351;&#29992;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#21644;&#21160;&#24577;&#19978;&#19979;&#25991;&#24314;&#27169;&#26469;&#35299;&#20915;&#36807;&#25311;&#21512;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#23398;&#20064;&#19978;&#19979;&#25991;&#30340;&#32039;&#20945;&#34920;&#31034;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20248;&#21270;&#30340;&#20132;&#26131;&#25191;&#34892;&#26159;&#22312;&#32473;&#23450;&#26102;&#38388;&#20869;&#20197;&#26368;&#20302;&#30340;&#20132;&#26131;&#25104;&#26412;&#21334;&#20986;&#65288;&#25110;&#20080;&#20837;&#65289;&#32473;&#23450;&#36164;&#20135;&#30340;&#36807;&#31243;&#12290;&#26368;&#36817;&#65292;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#34987;&#24212;&#29992;&#20110;&#20248;&#21270;&#30340;&#20132;&#26131;&#25191;&#34892;&#65292;&#20197;&#20174;&#24066;&#22330;&#25968;&#25454;&#20013;&#23398;&#20064;&#26356;&#26234;&#33021;&#30340;&#31574;&#30053;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#35768;&#22810;&#29616;&#26377;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#23384;&#22312;&#26174;&#33879;&#30340;&#36807;&#25311;&#21512;&#38382;&#39064;&#65292;&#20174;&#32780;&#38459;&#30861;&#20102;&#23427;&#20204;&#30340;&#23454;&#38469;&#24212;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23545;&#20248;&#21270;&#30340;&#20132;&#26131;&#25191;&#34892;&#20013;&#30340;&#36807;&#25311;&#21512;&#38382;&#39064;&#36827;&#34892;&#20102;&#24191;&#27867;&#30740;&#31350;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23558;&#20248;&#21270;&#30340;&#20132;&#26131;&#25191;&#34892;&#24314;&#27169;&#20026;&#24102;&#26377;&#21160;&#24577;&#19978;&#19979;&#25991;&#65288;ORDC&#65289;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#20854;&#20013;&#19978;&#19979;&#25991;&#34920;&#31034;&#19981;&#33021;&#21463;&#21040;&#20132;&#26131;&#31574;&#30053;&#24433;&#21709;&#24182;&#20197;&#31163;&#32447;&#26041;&#24335;&#25910;&#38598;&#30340;&#24066;&#22330;&#21464;&#37327;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#21457;&#29616;&#36807;&#25311;&#21512;&#38382;&#39064;&#26159;&#30001;&#20110;&#31163;&#32447;&#29615;&#22659;&#20013;&#19978;&#19979;&#25991;&#31354;&#38388;&#24040;&#22823;&#19988;&#19978;&#19979;&#25991;&#26679;&#26412;&#26377;&#38480;&#25152;&#23548;&#33268;&#30340;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23398;&#20064;&#19978;&#19979;&#25991;&#30340;&#32039;&#20945;&#34920;&#31034;&#26469;&#35299;&#20915;&#36807;&#25311;&#21512;&#38382;&#39064;&#65292;&#21487;&#20197;&#36890;&#36807;...
&lt;/p&gt;
&lt;p&gt;
Optimized trade execution is to sell (or buy) a given amount of assets in a given time with the lowest possible trading cost. Recently, reinforcement learning (RL) has been applied to optimized trade execution to learn smarter policies from market data. However, we find that many existing RL methods exhibit considerable overfitting which prevents them from real deployment. In this paper, we provide an extensive study on the overfitting problem in optimized trade execution. First, we model the optimized trade execution as offline RL with dynamic context (ORDC), where the context represents market variables that cannot be influenced by the trading policy and are collected in an offline manner. Under this framework, we derive the generalization bound and find that the overfitting issue is caused by large context space and limited context samples in the offline setting. Accordingly, we propose to learn compact representations for context to address the overfitting problem, either by levera
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21327;&#21464;&#37327;&#20559;&#31227;&#33258;&#36866;&#24212;&#20013;&#30340;&#19968;&#33324;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#32452;&#21512;&#24050;&#26377;&#32467;&#26524;&#24471;&#21040;&#20102;&#26032;&#30340;&#32467;&#26524;&#12290;&#22312;&#24369;&#24179;&#28369;&#26465;&#20214;&#19979;&#35777;&#26126;&#20102;&#23454;&#29616;&#19982;&#26631;&#20934;&#30417;&#30563;&#23398;&#20064;&#20013;&#30456;&#21516;&#31934;&#24230;&#25152;&#38656;&#30340;&#26679;&#26412;&#37327;&#35201;&#27604;&#29616;&#26377;&#20998;&#26512;&#35777;&#26126;&#30340;&#23569;&#12290;</title><link>http://arxiv.org/abs/2307.11503</link><description>&lt;p&gt;
&#22312;&#21327;&#21464;&#37327;&#20559;&#31227;&#33258;&#36866;&#24212;&#20013;&#30340;&#19968;&#33324;&#27491;&#21017;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
General regularization in covariate shift adaptation. (arXiv:2307.11503v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11503
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21327;&#21464;&#37327;&#20559;&#31227;&#33258;&#36866;&#24212;&#20013;&#30340;&#19968;&#33324;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#32452;&#21512;&#24050;&#26377;&#32467;&#26524;&#24471;&#21040;&#20102;&#26032;&#30340;&#32467;&#26524;&#12290;&#22312;&#24369;&#24179;&#28369;&#26465;&#20214;&#19979;&#35777;&#26126;&#20102;&#23454;&#29616;&#19982;&#26631;&#20934;&#30417;&#30563;&#23398;&#20064;&#20013;&#30456;&#21516;&#31934;&#24230;&#25152;&#38656;&#30340;&#26679;&#26412;&#37327;&#35201;&#27604;&#29616;&#26377;&#20998;&#26512;&#35777;&#26126;&#30340;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26679;&#26412;&#37325;&#21152;&#26435;&#26159;&#32416;&#27491;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;(RKHS)&#20013;&#30001;&#26410;&#26469;&#25968;&#25454;&#20998;&#24067;&#19982;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#19981;&#21516;&#24341;&#36215;&#30340;&#26368;&#23567;&#20108;&#20056;&#23398;&#20064;&#31639;&#27861;&#38169;&#35823;&#30340;&#26368;&#24120;&#29992;&#26041;&#27861;&#20043;&#19968;&#12290;&#22312;&#23454;&#38469;&#24773;&#20917;&#20013;&#65292;&#26679;&#26412;&#26435;&#37325;&#26159;&#30001;&#26410;&#26469;&#25968;&#25454;&#20998;&#24067;&#23545;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#30340;&#20272;&#35745;Radon-Nikod\'ym&#23548;&#25968;&#30340;&#20540;&#30830;&#23450;&#30340;&#12290;&#26412;&#30740;&#31350;&#22238;&#39038;&#20102;&#22312;RKHS&#20013;&#37325;&#26032;&#21152;&#26435;&#26680;&#22238;&#24402;&#30340;&#24050;&#30693;&#35823;&#24046;&#30028;&#38480;&#65292;&#24182;&#36890;&#36807;&#32452;&#21512;&#24471;&#21040;&#26032;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#22312;&#24369;&#24179;&#28369;&#26465;&#20214;&#19979;&#34920;&#26126;&#65292;&#20026;&#20102;&#23454;&#29616;&#19982;&#26631;&#20934;&#30417;&#30563;&#23398;&#20064;&#20013;&#25968;&#25454;&#20998;&#24067;&#24046;&#24322;&#30456;&#21516;&#31934;&#24230;&#30340;&#26679;&#26412;&#25968;&#30446;&#35201;&#27604;&#29616;&#26377;&#30340;&#20998;&#26512;&#35777;&#26126;&#30340;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sample reweighting is one of the most widely used methods for correcting the error of least squares learning algorithms in reproducing kernel Hilbert spaces (RKHS), that is caused by future data distributions that are different from the training data distribution. In practical situations, the sample weights are determined by values of the estimated Radon-Nikod\'ym derivative, of the future data distribution w.r.t.~the training data distribution. In this work, we review known error bounds for reweighted kernel regression in RKHS and obtain, by combination, novel results. We show under weak smoothness conditions, that the amount of samples, needed to achieve the same order of accuracy as in the standard supervised learning without differences in data distributions, is smaller than proven by state-of-the-art analyses.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#33258;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#65292;&#31216;&#20026;TSDiff&#12290;&#35813;&#27169;&#22411;&#19981;&#38656;&#35201;&#36741;&#21161;&#32593;&#32476;&#25110;&#35757;&#32451;&#36807;&#31243;&#30340;&#25913;&#21464;&#65292;&#22312;&#39044;&#27979;&#12289;&#25913;&#36827;&#21644;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#31561;&#26102;&#38388;&#24207;&#21015;&#20219;&#21153;&#19978;&#23637;&#29616;&#20986;&#20102;&#31454;&#20105;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.11494</link><description>&lt;p&gt;
&#39044;&#27979;&#12289;&#25913;&#36827;&#12289;&#21512;&#25104;&#65306;&#38754;&#21521;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#33258;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Predict, Refine, Synthesize: Self-Guiding Diffusion Models for Probabilistic Time Series Forecasting. (arXiv:2307.11494v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11494
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#33258;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#65292;&#31216;&#20026;TSDiff&#12290;&#35813;&#27169;&#22411;&#19981;&#38656;&#35201;&#36741;&#21161;&#32593;&#32476;&#25110;&#35757;&#32451;&#36807;&#31243;&#30340;&#25913;&#21464;&#65292;&#22312;&#39044;&#27979;&#12289;&#25913;&#36827;&#21644;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#31561;&#26102;&#38388;&#24207;&#21015;&#20219;&#21153;&#19978;&#23637;&#29616;&#20986;&#20102;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#29983;&#25104;&#24314;&#27169;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#20043;&#21069;&#20851;&#20110;&#26102;&#38388;&#24207;&#21015;&#25193;&#25955;&#27169;&#22411;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#24320;&#21457;&#38024;&#23545;&#29305;&#23450;&#39044;&#27979;&#25110;&#22635;&#34917;&#20219;&#21153;&#30340;&#26465;&#20214;&#27169;&#22411;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#38754;&#21521;&#22810;&#31181;&#26102;&#38388;&#24207;&#21015;&#24212;&#29992;&#30340;&#20219;&#21153;&#19981;&#21487;&#30693;&#26465;&#20214;&#19979;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;TSDiff&#65292;&#19968;&#31181;&#38754;&#21521;&#26102;&#38388;&#24207;&#21015;&#30340;&#26080;&#26465;&#20214;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#33258;&#24341;&#23548;&#26426;&#21046;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#20351;&#24471;TSDiff&#33021;&#22815;&#20026;&#19979;&#28216;&#20219;&#21153;&#36827;&#34892;&#26465;&#20214;&#35774;&#32622;&#65292;&#32780;&#26080;&#38656;&#36741;&#21161;&#32593;&#32476;&#25110;&#25913;&#21464;&#35757;&#32451;&#36807;&#31243;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#19981;&#21516;&#30340;&#26102;&#38388;&#24207;&#21015;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65306;&#39044;&#27979;&#12289;&#25913;&#36827;&#21644;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#34920;&#26126;TSDiff&#19982;&#20960;&#31181;&#20219;&#21153;&#29305;&#23450;&#30340;&#26465;&#20214;&#39044;&#27979;&#26041;&#27861;&#30456;&#31454;&#20105;&#65288;&#39044;&#27979;&#65289;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#21033;&#29992;TSDiff&#23398;&#21040;&#30340;&#38544;&#24615;&#27010;&#29575;&#23494;&#24230;&#26469;&#36845;&#20195;&#22320;&#25913;&#36827;p
&lt;/p&gt;
&lt;p&gt;
Diffusion models have achieved state-of-the-art performance in generative modeling tasks across various domains. Prior works on time series diffusion models have primarily focused on developing conditional models tailored to specific forecasting or imputation tasks. In this work, we explore the potential of task-agnostic, unconditional diffusion models for several time series applications. We propose TSDiff, an unconditionally trained diffusion model for time series. Our proposed self-guidance mechanism enables conditioning TSDiff for downstream tasks during inference, without requiring auxiliary networks or altering the training procedure. We demonstrate the effectiveness of our method on three different time series tasks: forecasting, refinement, and synthetic data generation. First, we show that TSDiff is competitive with several task-specific conditional forecasting methods (predict). Second, we leverage the learned implicit probability density of TSDiff to iteratively refine the p
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#36890;&#20449;&#29702;&#35770;&#20013;&#32467;&#21512;&#27880;&#24847;&#21147;&#21644;&#30456;&#23545;&#29109;&#30340;&#27010;&#24565;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#36890;&#20449;&#20013;&#20351;&#29992;&#27880;&#24847;&#21147;&#23548;&#21521;&#30340;&#21152;&#26435;&#30456;&#23545;&#29109;&#26159;&#19981;&#36866;&#24403;&#30340;&#65292;&#32780;&#36866;&#24403;&#30340;&#27880;&#24847;&#21147;&#36890;&#20449;&#21487;&#36890;&#36807;&#21457;&#36865;&#32773;&#20165;&#38656;&#35201;&#20102;&#35299;&#25509;&#25910;&#32773;&#30340;&#25928;&#29992;&#20989;&#25968;&#26469;&#23454;&#29616;&#26368;&#20339;&#36890;&#30693;&#12290;</title><link>http://arxiv.org/abs/2307.11423</link><description>&lt;p&gt;
&#27880;&#24847;&#21147;&#23545;&#29109;&#36890;&#20449;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Attention to Entropic Communication. (arXiv:2307.11423v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11423
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#36890;&#20449;&#29702;&#35770;&#20013;&#32467;&#21512;&#27880;&#24847;&#21147;&#21644;&#30456;&#23545;&#29109;&#30340;&#27010;&#24565;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#36890;&#20449;&#20013;&#20351;&#29992;&#27880;&#24847;&#21147;&#23548;&#21521;&#30340;&#21152;&#26435;&#30456;&#23545;&#29109;&#26159;&#19981;&#36866;&#24403;&#30340;&#65292;&#32780;&#36866;&#24403;&#30340;&#27880;&#24847;&#21147;&#36890;&#20449;&#21487;&#36890;&#36807;&#21457;&#36865;&#32773;&#20165;&#38656;&#35201;&#20102;&#35299;&#25509;&#25910;&#32773;&#30340;&#25928;&#29992;&#20989;&#25968;&#26469;&#23454;&#29616;&#26368;&#20339;&#36890;&#30693;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27880;&#24847;&#21147;&#30340;&#27010;&#24565;&#26159;&#25351;&#22312;&#20154;&#24037;&#26234;&#33021;&#20013;&#24378;&#35843;&#29305;&#23450;&#25968;&#25454;&#37325;&#35201;&#24615;&#30340;&#25968;&#20540;&#26435;&#37325;&#65292;&#22312;&#36890;&#20449;&#29702;&#35770;&#20013;&#30456;&#23545;&#29109;&#65288;RE&#65292;&#20063;&#31216;&#20026;&#24211;&#23572;&#24052;&#20811;-&#21202;&#24067;&#21202;&#25955;&#24230;&#65289;&#21457;&#25381;&#30528;&#26680;&#24515;&#20316;&#29992;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#32467;&#21512;&#20102;&#36825;&#20123;&#27010;&#24565;&#65292;&#21363;&#27880;&#24847;&#21147;&#21644;RE&#12290;RE&#24341;&#23548;&#24102;&#23485;&#26377;&#38480;&#36890;&#20449;&#20013;&#30340;&#26368;&#20339;&#32534;&#30721;&#20197;&#21450;&#36890;&#36807;&#26368;&#22823;&#29109;&#21407;&#29702;&#65288;MEP&#65289;&#36827;&#34892;&#26368;&#20339;&#28040;&#24687;&#35299;&#30721;&#12290;&#22312;&#32534;&#30721;&#22330;&#26223;&#20013;&#65292;RE&#21487;&#20197;&#20174;&#22235;&#20010;&#35201;&#27714;&#20013;&#25512;&#23548;&#20986;&#26469;&#65292;&#21363;&#20998;&#26512;&#24615;&#12289;&#23616;&#37096;&#24615;&#12289;&#36866;&#24403;&#24615;&#21644;&#26657;&#20934;&#24615;&#12290;&#32780;&#29992;&#20110;&#36890;&#20449;&#20013;&#27880;&#24847;&#21147;&#23548;&#21521;&#30340;&#21152;&#26435;RE&#23454;&#38469;&#19978;&#26159;&#19981;&#36866;&#24403;&#30340;&#12290;&#20026;&#20102;&#30475;&#21040;&#36866;&#24403;&#30340;&#27880;&#24847;&#21147;&#36890;&#20449;&#26159;&#22914;&#20309;&#20986;&#29616;&#30340;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#20010;&#22330;&#26223;&#65292;&#21363;&#28040;&#24687;&#21457;&#36865;&#32773;&#24076;&#26395;&#30830;&#20445;&#25509;&#25910;&#32773;&#33021;&#22815;&#25191;&#34892;&#30693;&#24773;&#30340;&#25805;&#20316;&#12290;&#22914;&#26524;&#25509;&#25910;&#32773;&#20351;&#29992;MEP&#35299;&#30721;&#28040;&#24687;&#65292;&#21017;&#21457;&#36865;&#32773;&#21482;&#38656;&#35201;&#30693;&#36947;&#25509;&#25910;&#32773;&#30340;&#25928;&#29992;&#20989;&#25968;&#26469;&#36827;&#34892;&#26368;&#20339;&#36890;&#30693;&#65292;&#19981;&#38656;&#35201;&#30693;&#36947;&#25509;&#25910;&#32773;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
The concept of attention, numerical weights that emphasize the importance of particular data, has proven to be very relevant in artificial intelligence. Relative entropy (RE, aka Kullback-Leibler divergence) plays a central role in communication theory. Here we combine these concepts, attention and RE. RE guides optimal encoding of messages in bandwidth-limited communication as well as optimal message decoding via the maximum entropy principle (MEP). In the coding scenario, RE can be derived from four requirements, namely being analytical, local, proper, and calibrated. Weighted RE, used for attention steering in communications, turns out to be improper. To see how proper attention communication can emerge, we analyze a scenario of a message sender who wants to ensure that the receiver of the message can perform well-informed actions. If the receiver decodes the message using the MEP, the sender only needs to know the receiver's utility function to inform optimally, but not the receive
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#38543;&#26426;&#29305;&#24449;&#20998;&#26512;&#65292;&#23545;&#21333;&#20010;&#27880;&#24847;&#23618;&#30340;&#23398;&#20064;&#21644;&#27867;&#21270;&#36827;&#34892;&#20102;&#20005;&#26684;&#30340;&#29702;&#35770;&#30740;&#31350;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#20855;&#26377;&#38543;&#26426;&#37319;&#26679;&#30340;&#20851;&#38190;&#30697;&#38453;&#21644;&#21487;&#35757;&#32451;&#20540;&#30697;&#38453;&#30340;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#29305;&#24449;&#27880;&#24847;&#23618;&#21487;&#20197;&#34920;&#31034;&#19968;&#31867;&#19982;&#20851;&#38190;&#21521;&#37327;&#32622;&#25442;&#26080;&#20851;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#24182;&#25552;&#20379;&#20102;&#23398;&#20064;&#36825;&#20123;&#30446;&#26631;&#20989;&#25968;&#30340;&#39118;&#38505;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2307.11353</link><description>&lt;p&gt;
&#19968;&#20010;&#21333;&#19968;&#30340;&#27880;&#24847;&#23618;&#33021;&#23398;&#21040;&#20160;&#20040;&#65311;&#36890;&#36807;&#38543;&#26426;&#29305;&#24449;&#35270;&#35282;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
What can a Single Attention Layer Learn? A Study Through the Random Features Lens. (arXiv:2307.11353v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11353
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#38543;&#26426;&#29305;&#24449;&#20998;&#26512;&#65292;&#23545;&#21333;&#20010;&#27880;&#24847;&#23618;&#30340;&#23398;&#20064;&#21644;&#27867;&#21270;&#36827;&#34892;&#20102;&#20005;&#26684;&#30340;&#29702;&#35770;&#30740;&#31350;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#20855;&#26377;&#38543;&#26426;&#37319;&#26679;&#30340;&#20851;&#38190;&#30697;&#38453;&#21644;&#21487;&#35757;&#32451;&#20540;&#30697;&#38453;&#30340;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#29305;&#24449;&#27880;&#24847;&#23618;&#21487;&#20197;&#34920;&#31034;&#19968;&#31867;&#19982;&#20851;&#38190;&#21521;&#37327;&#32622;&#25442;&#26080;&#20851;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#24182;&#25552;&#20379;&#20102;&#23398;&#20064;&#36825;&#20123;&#30446;&#26631;&#20989;&#25968;&#30340;&#39118;&#38505;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27880;&#24847;&#23618;&#26159;Transformer&#26550;&#26500;&#30340;&#26680;&#24515;&#32452;&#25104;&#37096;&#20998;&#65292;&#36890;&#36807;&#23558;&#36755;&#20837;&#24207;&#21015;&#26144;&#23556;&#21040;&#36755;&#20986;&#24207;&#21015;&#65292;&#22312;&#29616;&#20195;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#21462;&#24471;&#20102;&#37325;&#35201;&#31361;&#30772;&#12290;&#26412;&#25991;&#23545;&#21333;&#20010;&#22810;&#22836;&#27880;&#24847;&#23618;&#36827;&#34892;&#20102;&#20005;&#26684;&#30340;&#29702;&#35770;&#30740;&#31350;&#65292;&#36755;&#20837;&#26159;&#19968;&#31995;&#21015;&#20851;&#38190;&#21521;&#37327;&#21644;&#19968;&#20010;&#29420;&#31435;&#30340;&#26597;&#35810;&#21521;&#37327;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#38543;&#26426;&#29305;&#24449;&#35774;&#32622;&#65292;&#20854;&#20013;&#27880;&#24847;&#23618;&#20855;&#26377;&#22823;&#37327;&#22836;&#37096;&#65292;&#20855;&#26377;&#38543;&#26426;&#37319;&#26679;&#30340;&#20923;&#32467;&#26597;&#35810;&#21644;&#20851;&#38190;&#30697;&#38453;&#20197;&#21450;&#21487;&#35757;&#32451;&#30340;&#20540;&#30697;&#38453;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#26679;&#19968;&#20010;&#38543;&#26426;&#29305;&#24449;&#30340;&#27880;&#24847;&#23618;&#21487;&#20197;&#34920;&#31034;&#19968;&#31867;&#19982;&#20851;&#38190;&#21521;&#37327;&#32622;&#25442;&#26080;&#20851;&#30340;&#30446;&#26631;&#20989;&#25968;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20379;&#20102;&#26377;&#38480;&#26679;&#26412;&#24773;&#20917;&#19979;&#23398;&#20064;&#36825;&#20123;&#30446;&#26631;&#20989;&#25968;&#30340;&#23450;&#37327;&#36807;&#37327;&#39118;&#38505;&#30028;&#38480;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#26377;&#38480;&#25968;&#37327;&#30340;&#22836;&#37096;&#21644;&#38543;&#26426;&#29305;&#24449;&#27880;&#24847;&#23618;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#30456;&#27604;&#29616;&#26377;&#30340;&#38543;&#26426;&#32447;&#24615;&#21151;&#33021;&#27169;&#22411;&#26377;&#20960;&#20010;&#27880;&#24847;&#32467;&#26500;&#19978;&#30340;&#29420;&#29305;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Attention layers -- which map a sequence of inputs to a sequence of outputs -- are core building blocks of the Transformer architecture which has achieved significant breakthroughs in modern artificial intelligence. This paper presents a rigorous theoretical study on the learning and generalization of a single multi-head attention layer, with a sequence of key vectors and a separate query vector as input. We consider the random feature setting where the attention layer has a large number of heads, with randomly sampled frozen query and key matrices, and trainable value matrices. We show that such a random-feature attention layer can express a broad class of target functions that are permutation invariant to the key vectors. We further provide quantitative excess risk bounds for learning these target functions from finite samples, using random feature attention with finitely many heads.  Our results feature several implications unique to the attention structure compared with existing ra
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;$\texttt{Count-MORL}$&#65292;&#36890;&#36807;&#21033;&#29992;&#35745;&#25968;&#20445;&#23432;&#24615;&#26469;&#37327;&#21270;&#27169;&#22411;&#20272;&#35745;&#35823;&#24046;&#65292;&#35777;&#26126;&#20102;&#22522;&#20110;&#35745;&#25968;&#20445;&#23432;&#24615;&#22312;&#31163;&#32447;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#23398;&#20064;&#21040;&#30340;&#31574;&#30053;&#25552;&#20379;&#20102;&#25509;&#36817;&#26368;&#20248;&#24615;&#33021;&#30340;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2307.11352</link><description>&lt;p&gt;
&#22522;&#20110;&#27169;&#22411;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#19982;&#22522;&#20110;&#35745;&#25968;&#20445;&#23432;&#24615;&#30340;&#32467;&#21512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Model-based Offline Reinforcement Learning with Count-based Conservatism. (arXiv:2307.11352v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11352
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;$\texttt{Count-MORL}$&#65292;&#36890;&#36807;&#21033;&#29992;&#35745;&#25968;&#20445;&#23432;&#24615;&#26469;&#37327;&#21270;&#27169;&#22411;&#20272;&#35745;&#35823;&#24046;&#65292;&#35777;&#26126;&#20102;&#22522;&#20110;&#35745;&#25968;&#20445;&#23432;&#24615;&#22312;&#31163;&#32447;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#23398;&#20064;&#21040;&#30340;&#31574;&#30053;&#25552;&#20379;&#20102;&#25509;&#36817;&#26368;&#20248;&#24615;&#33021;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;$\texttt{Count-MORL}$&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#20102;&#29366;&#24577;&#21160;&#20316;&#23545;&#30340;&#35745;&#25968;&#20272;&#35745;&#26469;&#37327;&#21270;&#27169;&#22411;&#20272;&#35745;&#35823;&#24046;&#65292;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#39318;&#20010;&#35777;&#26126;&#20102;&#22522;&#20110;&#35745;&#25968;&#20445;&#23432;&#24615;&#22312;&#22522;&#20110;&#27169;&#22411;&#30340;&#31163;&#32447;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#26377;&#25928;&#24615;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#20272;&#35745;&#35823;&#24046;&#19982;&#29366;&#24577;&#21160;&#20316;&#23545;&#30340;&#39057;&#29575;&#25104;&#21453;&#27604;&#30340;&#20851;&#31995;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#22522;&#20110;&#35745;&#25968;&#20445;&#23432;&#27169;&#22411;&#19979;&#23398;&#20064;&#30340;&#31574;&#30053;&#25552;&#20379;&#20102;&#25509;&#36817;&#26368;&#20248;&#24615;&#33021;&#30340;&#20445;&#35777;&#12290;&#36890;&#36807;&#22823;&#37327;&#30340;&#25968;&#20540;&#23454;&#39564;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#20351;&#29992;&#21704;&#24076;&#32534;&#30721;&#23454;&#29616;&#30340;$\texttt{Count-MORL}$&#22312;D4RL&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#26174;&#33879;&#20248;&#20110;&#29616;&#26377;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#12290;&#20195;&#30721;&#21487;&#22312;$\href{https://github.com/oh-lab/Count-MORL}{https://github.com/oh-lab/Count-MORL}$&#19978;&#36827;&#34892;&#35775;&#38382;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a model-based offline reinforcement learning method that integrates count-based conservatism, named $\texttt{Count-MORL}$. Our method utilizes the count estimates of state-action pairs to quantify model estimation error, marking the first algorithm of demonstrating the efficacy of count-based conservatism in model-based offline deep RL to the best of our knowledge. For our proposed method, we first show that the estimation error is inversely proportional to the frequency of state-action pairs. Secondly, we demonstrate that the learned policy under the count-based conservative model offers near-optimality performance guarantees. Through extensive numerical experiments, we validate that $\texttt{Count-MORL}$ with hash code implementation significantly outperforms existing offline RL algorithms on the D4RL benchmark datasets. The code is accessible at $\href{https://github.com/oh-lab/Count-MORL}{https://github.com/oh-lab/Count-MORL}$.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38477;&#20302;&#21442;&#25968;&#35268;&#21010;&#36873;&#25321;&#24615;&#25512;&#26029;&#35745;&#31639;&#25104;&#26412;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35745;&#31639;p&#20540;&#30340;&#19978;&#30028;&#21644;&#19979;&#30028;&#26469;&#20445;&#35777;&#25152;&#38656;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2307.11351</link><description>&lt;p&gt;
&#21442;&#25968;&#35268;&#21010;&#30340;&#36873;&#25321;&#24615;&#25512;&#26029;&#20013;&#30340;&#26377;&#30028;P&#20540;
&lt;/p&gt;
&lt;p&gt;
Bounded P-values in Parametric Programming-based Selective Inference. (arXiv:2307.11351v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11351
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38477;&#20302;&#21442;&#25968;&#35268;&#21010;&#36873;&#25321;&#24615;&#25512;&#26029;&#35745;&#31639;&#25104;&#26412;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35745;&#31639;p&#20540;&#30340;&#19978;&#30028;&#21644;&#19979;&#30028;&#26469;&#20445;&#35777;&#25152;&#38656;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36873;&#25321;&#24615;&#25512;&#26029;&#65288;SI&#65289;&#20316;&#20026;&#19968;&#31181;&#36866;&#29992;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#20551;&#35774;&#26816;&#39564;&#30340;&#26377;&#21069;&#26223;&#30340;&#26694;&#26550;&#65292;&#19968;&#30452;&#21463;&#21040;&#30740;&#31350;&#20851;&#27880;&#12290;SI&#30340;&#22522;&#26412;&#24605;&#24819;&#26159;&#22312;&#19968;&#20010;&#20551;&#35774;&#34987;&#36873;&#20013;&#30340;&#20107;&#20214;&#30340;&#26465;&#20214;&#19979;&#36827;&#34892;&#25512;&#26029;&#12290;&#20026;&#20102;&#36827;&#34892;SI&#65292;&#24517;&#39035;&#20197;&#21487;&#36861;&#36394;&#30340;&#24418;&#24335;&#23545;&#36825;&#20010;&#20107;&#20214;&#36827;&#34892;&#25551;&#36848;&#12290;&#24403;&#36873;&#25321;&#20107;&#20214;&#38590;&#20197;&#25551;&#36848;&#26102;&#65292;&#21487;&#20197;&#24341;&#20837;&#39069;&#22806;&#30340;&#26465;&#20214;&#20197;&#20351;&#20854;&#21487;&#22788;&#29702;&#12290;&#36825;&#20123;&#39069;&#22806;&#30340;&#26465;&#20214;&#24448;&#24448;&#20250;&#23548;&#33268;&#21151;&#25928;&#30340;&#25439;&#22833;&#65292;&#36825;&#19968;&#38382;&#39064;&#34987;&#31216;&#20026;&#36807;&#24230;&#26465;&#20214;&#21270;&#12290;&#22522;&#20110;&#21442;&#25968;&#35268;&#21010;&#30340;SI&#65288;PP-based SI&#65289;&#34987;&#25552;&#20986;&#20316;&#20026;&#35299;&#20915;&#36807;&#24230;&#26465;&#20214;&#21270;&#38382;&#39064;&#30340;&#19968;&#31181;&#26041;&#27861;&#12290;PP-based SI&#30340;&#20027;&#35201;&#38382;&#39064;&#26159;&#30001;&#20110;&#38656;&#35201;&#23436;&#20840;&#22320;&#25506;&#32034;&#25968;&#25454;&#31354;&#38388;&#32780;&#23548;&#33268;&#35745;&#31639;&#25104;&#26412;&#39640;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#30340;&#36807;&#31243;&#65292;&#21516;&#26102;&#20445;&#35777;&#25152;&#38656;&#31934;&#24230;&#65292;&#36890;&#36807;&#25552;&#20986;&#35745;&#31639;p&#20540;&#30340;&#19978;&#30028;&#21644;&#19979;&#30028;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19977;&#31181;&#31867;&#22411;&#30340;&#25628;&#32034;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Selective inference (SI) has been actively studied as a promising framework for statistical hypothesis testing for data-driven hypotheses. The basic idea of SI is to make inferences conditional on an event that a hypothesis is selected. In order to perform SI, this event must be characterized in a traceable form. When selection event is too difficult to characterize, additional conditions are introduced for tractability. This additional conditions often causes the loss of power, and this issue is referred to as over-conditioning. Parametric programming-based SI (PP-based SI) has been proposed as one way to address the over-conditioning issue. The main problem of PP-based SI is its high computational cost due to the need to exhaustively explore the data space. In this study, we introduce a procedure to reduce the computational cost while guaranteeing the desired precision, by proposing a method to compute the upper and lower bounds of p-values. We also proposed three types of search str
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#21442;&#25968;&#21487;&#35782;&#21035;&#24615;&#12290;&#36890;&#36807;&#19968;&#20010;&#36816;&#21160;&#20256;&#24863;&#22120;&#25968;&#25454;&#30340;&#21442;&#25968;&#20272;&#35745;&#26696;&#20363;&#30740;&#31350;&#65292;&#21457;&#29616;&#34429;&#28982;&#26576;&#20123;&#21442;&#25968;&#21487;&#20197;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#35782;&#21035;&#20986;&#26469;&#65292;&#20294;&#20854;&#20182;&#21442;&#25968;&#20173;&#28982;&#19981;&#21487;&#35782;&#21035;&#12290;&#36825;&#34920;&#26126;&#19981;&#21487;&#35782;&#21035;&#24615;&#26159;&#23454;&#39564;&#35774;&#32622;&#30340;&#22266;&#26377;&#38480;&#21046;&#65292;&#38656;&#35201;&#25913;&#21464;&#25968;&#25454;&#25910;&#38598;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.11332</link><description>&lt;p&gt;
&#36229;&#36234;&#25910;&#25947;&#24615;&#65306;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#21487;&#35782;&#21035;&#24615;
&lt;/p&gt;
&lt;p&gt;
Beyond Convergence: Identifiability of Machine Learning and Deep Learning Models. (arXiv:2307.11332v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11332
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#21442;&#25968;&#21487;&#35782;&#21035;&#24615;&#12290;&#36890;&#36807;&#19968;&#20010;&#36816;&#21160;&#20256;&#24863;&#22120;&#25968;&#25454;&#30340;&#21442;&#25968;&#20272;&#35745;&#26696;&#20363;&#30740;&#31350;&#65292;&#21457;&#29616;&#34429;&#28982;&#26576;&#20123;&#21442;&#25968;&#21487;&#20197;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#35782;&#21035;&#20986;&#26469;&#65292;&#20294;&#20854;&#20182;&#21442;&#25968;&#20173;&#28982;&#19981;&#21487;&#35782;&#21035;&#12290;&#36825;&#34920;&#26126;&#19981;&#21487;&#35782;&#21035;&#24615;&#26159;&#23454;&#39564;&#35774;&#32622;&#30340;&#22266;&#26377;&#38480;&#21046;&#65292;&#38656;&#35201;&#25913;&#21464;&#25968;&#25454;&#25910;&#38598;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#21442;&#25968;&#20248;&#21270;&#21644;&#22238;&#24402;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#24182;&#38750;&#25152;&#26377;&#26426;&#22120;&#23398;&#20064;&#30340;&#36870;&#38382;&#39064;&#37117;&#26159;&#8220;&#21487;&#35782;&#21035;&#30340;&#8221;&#65292;&#36825;&#24847;&#21619;&#30528;&#27169;&#22411;&#21442;&#25968;&#21487;&#33021;&#26080;&#27861;&#20174;&#21487;&#29992;&#25968;&#25454;&#21644;&#25968;&#25454;&#27169;&#22411;&#30340;&#36755;&#20837;-&#36755;&#20986;&#20851;&#31995;&#20013;&#21807;&#19968;&#30830;&#23450;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#19968;&#20010;&#20197;&#36816;&#21160;&#20256;&#24863;&#22120;&#25968;&#25454;&#30340;&#21442;&#25968;&#20272;&#35745;&#20026;&#37325;&#28857;&#30340;&#26696;&#20363;&#30740;&#31350;&#65292;&#25506;&#35752;&#20102;&#27169;&#22411;&#21442;&#25968;&#21487;&#35782;&#21035;&#24615;&#30340;&#27010;&#24565;&#12290;&#21033;&#29992;&#21452;&#36275;&#24377;&#31783;&#36136;&#28857;&#20154;&#31867;&#34892;&#36208;&#21160;&#21147;&#23398;&#27169;&#22411;&#65292;&#25105;&#20204;&#29983;&#25104;&#20102;&#34920;&#31034;&#19981;&#21516;&#27493;&#24577;&#27169;&#24335;&#21644;&#26465;&#20214;&#30340;&#21512;&#25104;&#25968;&#25454;&#12290;&#36890;&#36807;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#23581;&#35797;&#20272;&#35745;&#20010;&#20307;&#21442;&#25968;&#65292;&#21253;&#25324;&#36136;&#37327;&#12289;&#21018;&#24230;&#21644;&#24179;&#34913;&#33151;&#38271;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#34429;&#28982;&#26576;&#20123;&#21442;&#25968;&#21487;&#20197;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#35782;&#21035;&#20986;&#26469;&#65292;&#20294;&#20854;&#20182;&#21442;&#25968;&#20173;&#28982;&#19981;&#21487;&#35782;&#21035;&#65292;&#36825;&#20984;&#26174;&#20102;&#19981;&#21487;&#35782;&#21035;&#24615;&#26159;&#23454;&#39564;&#35774;&#32622;&#30340;&#22266;&#26377;&#38480;&#21046;&#65292;&#38656;&#35201;&#25913;&#21464;&#25968;&#25454;&#25910;&#38598;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning (ML) and deep learning models are extensively used for parameter optimization and regression problems. However, not all inverse problems in ML are ``identifiable,'' indicating that model parameters may not be uniquely determined from the available data and the data model's input-output relationship. In this study, we investigate the notion of model parameter identifiability through a case study focused on parameter estimation from motion sensor data. Utilizing a bipedal-spring mass human walk dynamics model, we generate synthetic data representing diverse gait patterns and conditions. Employing a deep neural network, we attempt to estimate subject-wise parameters, including mass, stiffness, and equilibrium leg length. The results show that while certain parameters can be identified from the observation data, others remain unidentifiable, highlighting that unidentifiability is an intrinsic limitation of the experimental setup, necessitating a change in data collection a
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#20869;&#26680;&#30340;&#31163;&#32447;&#32972;&#26223;&#21452;&#21521;&#31454;&#26631;&#32773;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#22522;&#20110;&#20559;&#22909;&#21453;&#39304;&#30340;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#36951;&#25022;&#30028;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#20248;&#20110;&#20351;&#29992;&#22343;&#21248;&#37319;&#26679;&#19978;&#19979;&#25991;&#30340;&#30456;&#20284;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2307.11288</link><description>&lt;p&gt;
&#22522;&#20110;&#20869;&#26680;&#30340;&#31163;&#32447;&#32972;&#26223;&#21452;&#21521;&#31454;&#26631;&#32773;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Kernelized Offline Contextual Dueling Bandits. (arXiv:2307.11288v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11288
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#20869;&#26680;&#30340;&#31163;&#32447;&#32972;&#26223;&#21452;&#21521;&#31454;&#26631;&#32773;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#22522;&#20110;&#20559;&#22909;&#21453;&#39304;&#30340;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#36951;&#25022;&#30028;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#20248;&#20110;&#20351;&#29992;&#22343;&#21248;&#37319;&#26679;&#19978;&#19979;&#25991;&#30340;&#30456;&#20284;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20559;&#22909;&#30340;&#21453;&#39304;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#38750;&#24120;&#37325;&#35201;&#65292;&#36825;&#20123;&#24212;&#29992;&#20013;&#26080;&#27861;&#30452;&#25509;&#35780;&#20272;&#22870;&#21169;&#20989;&#25968;&#12290;&#22312;&#20154;&#20204;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#36825;&#26159;&#19968;&#20010;&#26174;&#33879;&#30340;&#26368;&#26032;&#23454;&#20363;&#12290;&#23545;&#20110;&#35768;&#22810;&#36825;&#20123;&#24212;&#29992;&#65292;&#33719;&#21462;&#20154;&#31867;&#21453;&#39304;&#30340;&#25104;&#26412;&#21487;&#33021;&#30456;&#24403;&#39640;&#29978;&#33267;&#19981;&#21487;&#34892;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#19968;&#20010;&#20107;&#23454;&#65292;&#21363;&#20195;&#29702;&#36890;&#24120;&#21487;&#20197;&#36873;&#25321;&#33719;&#24471;&#20154;&#31867;&#21453;&#39304;&#30340;&#19978;&#19979;&#25991;&#65292;&#20197;&#26368;&#39640;&#25928;&#22320;&#30830;&#23450;&#19968;&#20010;&#33391;&#22909;&#31574;&#30053;&#65292;&#24182;&#24341;&#20837;&#20102;&#31163;&#32447;&#32972;&#26223;&#21452;&#21521;&#31454;&#26631;&#32773;&#35774;&#32622;&#12290;&#25105;&#20204;&#20026;&#36825;&#20010;&#35774;&#32622;&#25552;&#20379;&#20102;&#19968;&#20010;&#19978;&#30028;&#32622;&#20449;&#21306;&#38388;&#26679;&#24335;&#30340;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#19968;&#20010;&#36951;&#25022;&#19978;&#30028;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#32463;&#39564;&#35777;&#23454;&#36825;&#31181;&#26041;&#27861;&#32988;&#36807;&#20351;&#29992;&#22343;&#21248;&#37319;&#26679;&#19978;&#19979;&#25991;&#30340;&#31867;&#20284;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Preference-based feedback is important for many applications where direct evaluation of a reward function is not feasible. A notable recent example arises in reinforcement learning from human feedback on large language models. For many of these applications, the cost of acquiring the human feedback can be substantial or even prohibitive. In this work, we take advantage of the fact that often the agent can choose contexts at which to obtain human feedback in order to most efficiently identify a good policy, and introduce the offline contextual dueling bandit setting. We give an upper-confidence-bound style algorithm for this setting and prove a regret bound. We also give empirical confirmation that this method outperforms a similar strategy that uses uniformly sampled contexts.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35777;&#25454;&#19979;&#30028;&#30340;Fisher-Rao&#26799;&#24230;&#65292;&#25581;&#31034;&#20102;&#23427;&#19982;&#30446;&#26631;&#20998;&#24067;&#30340;Kullback-Leibler&#25955;&#24230;&#26799;&#24230;&#30340;&#20851;&#31995;&#65292;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#26368;&#23567;&#21270;&#20027;&#35201;&#30446;&#26631;&#20989;&#25968;&#19982;&#26368;&#22823;&#21270;ELBO&#30340;&#31561;&#20215;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.11249</link><description>&lt;p&gt;
&#20851;&#20110;&#35777;&#25454;&#19979;&#30028;&#30340;Fisher-Rao&#26799;&#24230;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Fisher-Rao Gradient of the Evidence Lower Bound. (arXiv:2307.11249v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11249
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35777;&#25454;&#19979;&#30028;&#30340;Fisher-Rao&#26799;&#24230;&#65292;&#25581;&#31034;&#20102;&#23427;&#19982;&#30446;&#26631;&#20998;&#24067;&#30340;Kullback-Leibler&#25955;&#24230;&#26799;&#24230;&#30340;&#20851;&#31995;&#65292;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#26368;&#23567;&#21270;&#20027;&#35201;&#30446;&#26631;&#20989;&#25968;&#19982;&#26368;&#22823;&#21270;ELBO&#30340;&#31561;&#20215;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35777;&#25454;&#19979;&#30028;&#65288;ELBO&#65289;&#30340;Fisher-Rao&#26799;&#24230;&#65292;&#20063;&#31216;&#20026;&#33258;&#28982;&#26799;&#24230;&#65292;&#23427;&#22312;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#29702;&#35770;&#12289;Helmholtz&#26426;&#21644;&#33258;&#30001;&#33021;&#21407;&#29702;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;ELBO&#30340;&#33258;&#28982;&#26799;&#24230;&#19982;&#30446;&#26631;&#20998;&#24067;&#30340;Kullback-Leibler&#25955;&#24230;&#30340;&#33258;&#28982;&#26799;&#24230;&#30456;&#20851;&#65292;&#21518;&#32773;&#26159;&#23398;&#20064;&#30340;&#20027;&#35201;&#30446;&#26631;&#20989;&#25968;&#12290;&#22522;&#20110;&#20449;&#24687;&#20960;&#20309;&#20013;&#26799;&#24230;&#30340;&#19981;&#21464;&#24615;&#29305;&#24615;&#65292;&#25552;&#20379;&#20102;&#20851;&#20110;&#24213;&#23618;&#27169;&#22411;&#30340;&#26465;&#20214;&#65292;&#30830;&#20445;&#26368;&#23567;&#21270;&#20027;&#35201;&#30446;&#26631;&#20989;&#25968;&#19982;&#26368;&#22823;&#21270;ELBO&#30340;&#31561;&#20215;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article studies the Fisher-Rao gradient, also referred to as the natural gradient, of the evidence lower bound, the ELBO, which plays a crucial role within the theory of the Variational Autonecoder, the Helmholtz Machine and the Free Energy Principle. The natural gradient of the ELBO is related to the natural gradient of the Kullback-Leibler divergence from a target distribution, the prime objective function of learning. Based on invariance properties of gradients within information geometry, conditions on the underlying model are provided that ensure the equivalence of minimising the prime objective function and the maximisation of the ELBO.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#23558;&#26426;&#22120;&#21462;&#28040;&#23398;&#20064;&#38382;&#39064;&#24418;&#24335;&#21270;&#20026;&#35774;&#35745;&#39640;&#25928;&#30340;&#21462;&#28040;&#23398;&#20064;&#31639;&#27861;&#65292;&#32473;&#20986;&#20102;&#32447;&#24615;&#21644;&#21069;&#32512;&#21644;&#26597;&#35810;&#31867;&#30340;&#39640;&#25928;&#21462;&#28040;&#23398;&#20064;&#31639;&#27861;&#65292;&#20197;&#21450;&#24212;&#29992;&#20110;&#38543;&#26426;&#20984;&#20248;&#21270;&#38382;&#39064;&#30340;&#25913;&#36827;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2307.11228</link><description>&lt;p&gt;
&#20174;&#33258;&#36866;&#24212;&#26597;&#35810;&#37322;&#25918;&#21040;&#26426;&#22120;&#21462;&#28040;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
From Adaptive Query Release to Machine Unlearning. (arXiv:2307.11228v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11228
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#23558;&#26426;&#22120;&#21462;&#28040;&#23398;&#20064;&#38382;&#39064;&#24418;&#24335;&#21270;&#20026;&#35774;&#35745;&#39640;&#25928;&#30340;&#21462;&#28040;&#23398;&#20064;&#31639;&#27861;&#65292;&#32473;&#20986;&#20102;&#32447;&#24615;&#21644;&#21069;&#32512;&#21644;&#26597;&#35810;&#31867;&#30340;&#39640;&#25928;&#21462;&#28040;&#23398;&#20064;&#31639;&#27861;&#65292;&#20197;&#21450;&#24212;&#29992;&#20110;&#38543;&#26426;&#20984;&#20248;&#21270;&#38382;&#39064;&#30340;&#25913;&#36827;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#26426;&#22120;&#21462;&#28040;&#23398;&#20064;&#38382;&#39064;&#24418;&#24335;&#21270;&#20026;&#35774;&#35745;&#39640;&#25928;&#21462;&#28040;&#23398;&#20064;&#31639;&#27861;&#26469;&#23545;&#24212;&#20174;&#32467;&#26500;&#21270;&#26597;&#35810;&#31867;&#20013;&#36873;&#25321;&#33258;&#36866;&#24212;&#26597;&#35810;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#32447;&#24615;&#21644;&#21069;&#32512;&#21644;&#26597;&#35810;&#31867;&#30340;&#39640;&#25928;&#21462;&#28040;&#23398;&#20064;&#31639;&#27861;&#12290;&#20316;&#20026;&#24212;&#29992;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#35768;&#22810;&#38382;&#39064;&#20013;&#65292;&#29305;&#21035;&#26159;&#38543;&#26426;&#20984;&#20248;&#21270;&#65288;SCO&#65289;&#20013;&#30340;&#21462;&#28040;&#23398;&#20064;&#21487;&#20197;&#36890;&#36807;&#19978;&#36848;&#26041;&#27861;&#26469;&#20943;&#23569;&#65292;&#20174;&#32780;&#25913;&#21892;&#38382;&#39064;&#30340;&#20445;&#35777;&#12290;&#29305;&#21035;&#22320;&#65292;&#23545;&#20110;&#24179;&#28369;&#30340;Lipschitz&#25439;&#22833;&#21644;&#20219;&#24847;&#30340;$\rho&gt;0$&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#32473;&#20986;&#20102;&#19968;&#20010;&#21462;&#28040;&#23398;&#20064;&#31639;&#27861;&#65292;&#20854;&#36229;&#20986;&#24635;&#20307;&#39118;&#38505;&#20026;$\tilde O\big(\frac{1}{\sqrt{n}}+\frac{\sqrt{d}}{n\rho}\big)$&#65292;&#21462;&#28040;&#23398;&#20064;&#26597;&#35810;&#65288;&#26799;&#24230;&#65289;&#22797;&#26434;&#24615;&#20026;$\tilde O(\rho \cdot \text{&#37325;&#26032;&#35757;&#32451;&#22797;&#26434;&#24615;})$&#65292;&#20854;&#20013;$d$&#26159;&#27169;&#22411;&#30340;&#32500;&#24230;&#65292;$n$&#26159;&#21021;&#22987;&#26679;&#26412;&#25968;&#12290;&#23545;&#20110;&#38750;&#24179;&#28369;&#30340;Lipschitz&#25439;&#22833;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#20010;&#21462;&#28040;&#23398;&#20064;&#31639;&#27861;&#65292;&#20854;&#36229;&#20986;&#24635;&#20307;&#39118;&#38505;&#20026;$\tilde O\big(\frac{1}{\sqrt{n}}+\big(\frac{\sqrt{d}}{n\rho}$
&lt;/p&gt;
&lt;p&gt;
We formalize the problem of machine unlearning as design of efficient unlearning algorithms corresponding to learning algorithms which perform a selection of adaptive queries from structured query classes. We give efficient unlearning algorithms for linear and prefix-sum query classes. As applications, we show that unlearning in many problems, in particular, stochastic convex optimization (SCO), can be reduced to the above, yielding improved guarantees for the problem. In particular, for smooth Lipschitz losses and any $\rho&gt;0$, our results yield an unlearning algorithm with excess population risk of $\tilde O\big(\frac{1}{\sqrt{n}}+\frac{\sqrt{d}}{n\rho}\big)$ with unlearning query (gradient) complexity $\tilde O(\rho \cdot \text{Retraining Complexity})$, where $d$ is the model dimensionality and $n$ is the initial number of samples. For non-smooth Lipschitz losses, we give an unlearning algorithm with excess population risk $\tilde O\big(\frac{1}{\sqrt{n}}+\big(\frac{\sqrt{d}}{n\rho}
&lt;/p&gt;</description></item><item><title>&#23494;&#38598;&#26679;&#26412;&#28145;&#24230;&#23398;&#20064;&#26159;&#19968;&#31181;&#38024;&#23545;&#28145;&#24230;&#23398;&#20064;&#32593;&#32476;&#30340;&#30740;&#31350;&#26041;&#27861;&#65292;&#26088;&#22312;&#25581;&#31034;&#23398;&#20064;&#26426;&#21046;&#21644;&#34920;&#31034;&#30340;&#26410;&#30693;&#29305;&#24615;&#65292;&#24182;&#35299;&#20915;&#22823;&#35268;&#27169;&#25968;&#25454;&#21644;&#38544;&#34255;&#21333;&#20803;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.10991</link><description>&lt;p&gt;
&#23494;&#38598;&#26679;&#26412;&#28145;&#24230;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Dense Sample Deep Learning. (arXiv:2307.10991v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10991
&lt;/p&gt;
&lt;p&gt;
&#23494;&#38598;&#26679;&#26412;&#28145;&#24230;&#23398;&#20064;&#26159;&#19968;&#31181;&#38024;&#23545;&#28145;&#24230;&#23398;&#20064;&#32593;&#32476;&#30340;&#30740;&#31350;&#26041;&#27861;&#65292;&#26088;&#22312;&#25581;&#31034;&#23398;&#20064;&#26426;&#21046;&#21644;&#34920;&#31034;&#30340;&#26410;&#30693;&#29305;&#24615;&#65292;&#24182;&#35299;&#20915;&#22823;&#35268;&#27169;&#25968;&#25454;&#21644;&#38544;&#34255;&#21333;&#20803;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#26159;20&#19990;&#32426;80&#24180;&#20195;&#25552;&#20986;&#30340;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#31639;&#27861;&#30340;&#21464;&#20307;&#65292;&#22312;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#39046;&#22495;&#21462;&#24471;&#20102;&#20196;&#20154;&#24778;&#35766;&#30340;&#36827;&#23637;&#65292;&#21253;&#25324;&#35821;&#35328;&#32763;&#35793;&#12289;&#34507;&#30333;&#36136;&#25240;&#21472;&#12289;&#33258;&#21160;&#39550;&#39542;&#27773;&#36710;&#65292;&#20197;&#21450;&#26368;&#36817;&#30340;&#31867;&#20154;&#35821;&#35328;&#27169;&#22411;&#65288;CHATbots&#65289;&#12290;&#23613;&#31649;&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#32593;&#32476;&#30340;&#20351;&#29992;&#36234;&#26469;&#36234;&#24191;&#27867;&#65292;&#20294;&#23545;&#20110;&#20351;&#36825;&#20123;&#32593;&#32476;&#22312;&#22914;&#27492;&#24191;&#27867;&#30340;&#24212;&#29992;&#20013;&#26377;&#25928;&#30340;&#23398;&#20064;&#26426;&#21046;&#21644;&#34920;&#31034;&#20173;&#30693;&#20043;&#29978;&#23569;&#12290;&#37096;&#20998;&#21407;&#22240;&#21487;&#33021;&#26159;&#20854;&#22823;&#35268;&#27169;&#26550;&#26500;&#21644;&#22823;&#35268;&#27169;&#25968;&#25454;&#30340;&#20351;&#29992;&#65292;&#20294;&#28145;&#24230;&#23398;&#20064;&#34920;&#31034;&#30340;&#26412;&#36136;&#20173;&#28982;&#22823;&#37096;&#20998;&#26410;&#30693;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#20855;&#26377;&#25968;&#30334;&#19975;&#25110;&#25968;&#21313;&#20159;&#20010;&#26631;&#35760;&#30340;&#35757;&#32451;&#38598;&#23384;&#22312;&#26410;&#30693;&#30340;&#32452;&#21512;&#26041;&#24335;&#65292;&#21516;&#26102;&#25968;&#30334;&#19975;&#25110;&#25968;&#21313;&#20159;&#20010;&#38544;&#34255;&#21333;&#20803;&#30340;&#32593;&#32476;&#38590;&#20197;&#21487;&#35270;&#21270;&#65292;&#20854;&#26426;&#21046;&#20063;&#38590;&#20197;&#25581;&#31034;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23494;&#38598;&#26679;&#26412;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Learning (DL) , a variant of the neural network algorithms originally proposed in the 1980s, has made surprising progress in Artificial Intelligence (AI), ranging from language translation, protein folding, autonomous cars, and more recently human-like language models (CHATbots), all that seemed intractable until very recently. Despite the growing use of Deep Learning (DL) networks, little is actually understood about the learning mechanisms and representations that makes these networks effective across such a diverse range of applications. Part of the answer must be the huge scale of the architecture and of course the large scale of the data, since not much has changed since 1987. But the nature of deep learned representations remain largely unknown. Unfortunately training sets with millions or billions of tokens have unknown combinatorics and Networks with millions or billions of hidden units cannot easily be visualized and their mechanisms cannot be easily revealed. In this pap
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#38543;&#26426;&#39640;&#26031;&#26435;&#37325;&#21644;&#20559;&#32622;&#30340;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#24067;&#65292;&#24471;&#21040;&#20102;&#22312;&#22823;&#20294;&#26377;&#38480;&#30340; $n$ &#21644;&#20219;&#24847;&#22266;&#23450;&#32593;&#32476;&#28145;&#24230;&#19979;&#25104;&#31435;&#30340;&#27491;&#24577;&#36924;&#36817;&#30340;&#23450;&#37327;&#30028;&#38480;&#65292;&#35777;&#26126;&#20102;&#38543;&#26426;&#20840;&#36830;&#25509;&#32593;&#32476;&#19982;&#30456;&#24212;&#30340;&#26080;&#38480;&#23485;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#36317;&#31163;&#25353;&#29031; $n^{-\gamma}$ &#32553;&#25918;&#65292;&#30028;&#38480;&#22312;&#32593;&#32476;&#23485;&#24230;&#30340;&#20381;&#36182;&#24615;&#26041;&#38754;&#20248;&#20110;&#20197;&#21069;&#30340;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2307.06092</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#23450;&#37327;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;
&lt;/p&gt;
&lt;p&gt;
Quantitative CLTs in Deep Neural Networks. (arXiv:2307.06092v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06092
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#38543;&#26426;&#39640;&#26031;&#26435;&#37325;&#21644;&#20559;&#32622;&#30340;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#24067;&#65292;&#24471;&#21040;&#20102;&#22312;&#22823;&#20294;&#26377;&#38480;&#30340; $n$ &#21644;&#20219;&#24847;&#22266;&#23450;&#32593;&#32476;&#28145;&#24230;&#19979;&#25104;&#31435;&#30340;&#27491;&#24577;&#36924;&#36817;&#30340;&#23450;&#37327;&#30028;&#38480;&#65292;&#35777;&#26126;&#20102;&#38543;&#26426;&#20840;&#36830;&#25509;&#32593;&#32476;&#19982;&#30456;&#24212;&#30340;&#26080;&#38480;&#23485;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#36317;&#31163;&#25353;&#29031; $n^{-\gamma}$ &#32553;&#25918;&#65292;&#30028;&#38480;&#22312;&#32593;&#32476;&#23485;&#24230;&#30340;&#20381;&#36182;&#24615;&#26041;&#38754;&#20248;&#20110;&#20197;&#21069;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#38543;&#26426;&#39640;&#26031;&#26435;&#37325;&#21644;&#20559;&#32622;&#30340;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#24067;&#65292;&#20854;&#20013;&#38544;&#34255;&#23618;&#23485;&#24230;&#19982;&#22823;&#24120;&#25968; $n$ &#25104;&#27604;&#20363;&#12290;&#22312;&#38750;&#32447;&#24615;&#30340;&#28201;&#21644;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#22312;&#22823;&#20294;&#26377;&#38480;&#30340; $n$ &#21644;&#20219;&#24847;&#22266;&#23450;&#32593;&#32476;&#28145;&#24230;&#19979;&#25104;&#31435;&#30340;&#27491;&#24577;&#36924;&#36817;&#30340;&#23450;&#37327;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#23450;&#29702;&#34920;&#26126;&#65292;&#26080;&#35770;&#26159;&#23545;&#20110;&#26377;&#38480;&#32500;&#20998;&#24067;&#36824;&#26159;&#25972;&#20010;&#36807;&#31243;&#65292;&#38543;&#26426;&#20840;&#36830;&#25509;&#32593;&#32476;&#65288;&#21450;&#20854;&#23548;&#25968;&#65289;&#19982;&#30456;&#24212;&#30340;&#26080;&#38480;&#23485;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#36317;&#31163;&#37117;&#20250;&#25353;&#29031; $n^{-\gamma}$ &#32553;&#25918;&#65292;&#20854;&#20013; $\gamma&gt;0$&#65292;&#25351;&#25968;&#21462;&#20915;&#20110;&#29992;&#20110;&#24230;&#37327;&#24046;&#24322;&#30340;&#24230;&#37327;&#26041;&#24335;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#22312;&#32593;&#32476;&#23485;&#24230;&#30340;&#20381;&#36182;&#24615;&#26041;&#38754;&#27604;&#25991;&#29486;&#20013;&#20197;&#21069;&#25552;&#20379;&#30340;&#20219;&#20309;&#30028;&#38480;&#37117;&#35201;&#24378;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the distribution of a fully connected neural network with random Gaussian weights and biases in which the hidden layer widths are proportional to a large constant $n$. Under mild assumptions on the non-linearity, we obtain quantitative bounds on normal approximations valid at large but finite $n$ and any fixed network depth. Our theorems show, both for the finite-dimensional distributions and the entire process, that the distance between a random fully connected network (and its derivatives) to the corresponding infinite width Gaussian process scales like $n^{-\gamma}$ for $\gamma&gt;0,$ with the exponent depending on the metric used to measure discrepancy. Our bounds are stronger in terms of their dependence on network width than any previously available in the literature.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#32039;&#31995;&#25968;&#26679;&#26465;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#20013;&#27169;&#24335;&#30340;&#25968;&#37327;&#12290;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#26680;&#20272;&#35745;&#22120;&#21644;&#32452;&#21512;&#26679;&#26465;&#65292;&#23454;&#29616;&#20102;&#29305;&#24449;&#25506;&#32034;&#12289;&#27169;&#22411;&#36873;&#25321;&#21644;&#27169;&#24335;&#26816;&#39564;&#65292;&#24182;&#20801;&#35768;&#24341;&#20837;&#19987;&#23478;&#21028;&#26029;&#12290;&#36890;&#36807;&#22312;&#20307;&#32946;&#20998;&#26512;&#20013;&#30340;&#26696;&#20363;&#30740;&#31350;&#20013;&#30340;&#39564;&#35777;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.05825</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#32039;&#31995;&#25968;&#26679;&#26465;&#20272;&#35745;&#27169;&#24335;&#30340;&#25968;&#37327;
&lt;/p&gt;
&lt;p&gt;
Bayesian taut splines for estimating the number of modes. (arXiv:2307.05825v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05825
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#32039;&#31995;&#25968;&#26679;&#26465;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#20013;&#27169;&#24335;&#30340;&#25968;&#37327;&#12290;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#26680;&#20272;&#35745;&#22120;&#21644;&#32452;&#21512;&#26679;&#26465;&#65292;&#23454;&#29616;&#20102;&#29305;&#24449;&#25506;&#32034;&#12289;&#27169;&#22411;&#36873;&#25321;&#21644;&#27169;&#24335;&#26816;&#39564;&#65292;&#24182;&#20801;&#35768;&#24341;&#20837;&#19987;&#23478;&#21028;&#26029;&#12290;&#36890;&#36807;&#22312;&#20307;&#32946;&#20998;&#26512;&#20013;&#30340;&#26696;&#20363;&#30740;&#31350;&#20013;&#30340;&#39564;&#35777;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#20013;&#27169;&#24335;&#30340;&#25968;&#37327;&#20195;&#34920;&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#65292;&#20063;&#21487;&#20197;&#30475;&#20316;&#29616;&#26377;&#20122;&#32676;&#20307;&#30340;&#25968;&#37327;&#12290;&#23613;&#31649;&#20854;&#30456;&#20851;&#24615;&#65292;&#23545;&#20854;&#20272;&#35745;&#30340;&#30740;&#31350;&#38750;&#24120;&#26377;&#38480;&#12290;&#25105;&#20204;&#38024;&#23545;&#21333;&#21464;&#37327;&#24773;&#20917;&#25552;&#20986;&#19968;&#20010;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#33268;&#21147;&#20110;&#39044;&#27979;&#20934;&#30830;&#24615;&#65292;&#21463;&#21040;&#20102;&#38382;&#39064;&#30340;&#19968;&#20123;&#34987;&#24573;&#35270;&#30340;&#26041;&#38754;&#30340;&#21551;&#21457;&#12290;&#25105;&#20204;&#35748;&#20026;&#35299;&#20915;&#26041;&#26696;&#38656;&#35201;&#32467;&#26500;&#65292;&#27169;&#24335;&#30340;&#20027;&#35266;&#19988;&#19981;&#30830;&#23450;&#24615;&#65292;&#20197;&#21450;&#34701;&#21512;&#20840;&#23616;&#21644;&#23616;&#37096;&#23494;&#24230;&#29305;&#24615;&#30340;&#25972;&#20307;&#35270;&#22270;&#30340;&#20415;&#21033;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#32467;&#21512;&#20102;&#28789;&#27963;&#30340;&#26680;&#20272;&#35745;&#22120;&#21644;&#31616;&#27905;&#30340;&#32452;&#21512;&#26679;&#26465;&#12290;&#29305;&#24449;&#25506;&#32034;&#12289;&#27169;&#22411;&#36873;&#25321;&#21644;&#27169;&#24335;&#26816;&#39564;&#37117;&#22312;&#36125;&#21494;&#26031;&#25512;&#29702;&#33539;&#24335;&#20013;&#23454;&#29616;&#65292;&#20026;&#36719;&#35299;&#20915;&#26041;&#26696;&#25552;&#20379;&#20102;&#20415;&#21033;&#65292;&#24182;&#20801;&#35768;&#22312;&#36807;&#31243;&#20013;&#24341;&#20837;&#19987;&#23478;&#21028;&#26029;&#12290;&#25105;&#20204;&#30340;&#25552;&#35758;&#30340;&#23454;&#29992;&#24615;&#36890;&#36807;&#22312;&#20307;&#32946;&#20998;&#26512;&#20013;&#30340;&#26696;&#20363;&#30740;&#31350;&#20013;&#36827;&#34892;&#20102;&#39564;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#22810;&#20010;&#38506;&#20276;&#30340;&#21487;&#35270;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
The number of modes in a probability density function is representative of the model's complexity and can also be viewed as the number of existing subpopulations. Despite its relevance, little research has been devoted to its estimation. Focusing on the univariate setting, we propose a novel approach targeting prediction accuracy inspired by some overlooked aspects of the problem. We argue for the need for structure in the solutions, the subjective and uncertain nature of modes, and the convenience of a holistic view blending global and local density properties. Our method builds upon a combination of flexible kernel estimators and parsimonious compositional splines. Feature exploration, model selection and mode testing are implemented in the Bayesian inference paradigm, providing soft solutions and allowing to incorporate expert judgement in the process. The usefulness of our proposal is illustrated through a case study in sports analytics, showcasing multiple companion visualisation 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#21363;MADD&#65292;&#21487;&#20197;&#29420;&#31435;&#20110;&#39044;&#27979;&#24615;&#33021;&#20998;&#26512;&#27169;&#22411;&#30340;&#27495;&#35270;&#34892;&#20026;&#12290;&#30740;&#31350;&#32773;&#36824;&#25552;&#20379;&#20102;&#21487;&#35270;&#21270;&#20998;&#26512;&#30340;&#34917;&#20805;&#26469;&#24110;&#21161;&#36827;&#34892;&#20154;&#31867;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2305.15342</link><description>&lt;p&gt;
&#20320;&#30340;&#27169;&#22411;&#8220;MADD&#8221;&#20102;&#21527;&#65311;&#19968;&#31181;&#29992;&#20110;&#35780;&#20272;&#39044;&#27979;&#24615;&#23398;&#29983;&#27169;&#22411;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#26032;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Is Your Model "MADD"? A Novel Metric to Evaluate Algorithmic Fairness for Predictive Student Models. (arXiv:2305.15342v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15342
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#21363;MADD&#65292;&#21487;&#20197;&#29420;&#31435;&#20110;&#39044;&#27979;&#24615;&#33021;&#20998;&#26512;&#27169;&#22411;&#30340;&#27495;&#35270;&#34892;&#20026;&#12290;&#30740;&#31350;&#32773;&#36824;&#25552;&#20379;&#20102;&#21487;&#35270;&#21270;&#20998;&#26512;&#30340;&#34917;&#20805;&#26469;&#24110;&#21161;&#36827;&#34892;&#20154;&#31867;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#22686;&#24378;&#25945;&#32946;&#25104;&#26524;&#21644;&#25903;&#25345;&#21033;&#30410;&#30456;&#20851;&#32773;&#20570;&#20986;&#26126;&#26234;&#20915;&#31574;&#30340;&#33021;&#21147;&#65292;&#39044;&#27979;&#24615;&#23398;&#29983;&#27169;&#22411;&#22312;&#23398;&#20064;&#29615;&#22659;&#20013;&#36234;&#26469;&#36234;&#26222;&#36941;&#12290;&#28982;&#32780;&#65292;&#39044;&#27979;&#27169;&#22411;&#21487;&#33021;&#23384;&#22312;&#20559;&#35265;&#65292;&#23548;&#33268;&#23545;&#26576;&#20123;&#23398;&#29983;&#30340;&#28508;&#22312;&#27495;&#35270;&#21644;&#21487;&#33021;&#30340;&#26377;&#23475;&#38271;&#26399;&#24433;&#21709;&#12290;&#36825;&#20419;&#20351;&#20102;&#23545;&#20844;&#24179;&#24615;&#24230;&#37327;&#26631;&#20934;&#30340;&#30740;&#31350;&#65292;&#26088;&#22312;&#25429;&#25417;&#21644;&#37327;&#21270;&#27492;&#31867;&#20559;&#35265;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#30446;&#21069;&#22312;&#25945;&#32946;&#39046;&#22495;&#20351;&#29992;&#30340;&#29616;&#26377;&#20844;&#24179;&#24230;&#37327;&#26631;&#20934;&#26159;&#38754;&#21521;&#39044;&#27979;&#24615;&#33021;&#30340;&#65292;&#37325;&#28857;&#26159;&#35780;&#20272;&#32452;&#38388;&#23384;&#22312;&#30340;&#26377;&#20559;&#32467;&#26524;&#65292;&#32780;&#19981;&#32771;&#34385;&#27169;&#22411;&#30340;&#34892;&#20026;&#20197;&#21450;&#32467;&#26524;&#20013;&#30340;&#20559;&#35265;&#31243;&#24230;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#21363;&#8220;&#27169;&#22411;&#32477;&#23545;&#23494;&#24230;&#36317;&#31163;&#8221;&#65288;MADD&#65289;&#65292;&#20197;&#20998;&#26512;&#27169;&#22411;&#30340;&#27495;&#35270;&#34892;&#20026;&#65292;&#29420;&#31435;&#20110;&#20854;&#39044;&#27979;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#22522;&#20110;&#21487;&#35270;&#21270;&#20998;&#26512;&#30340;&#34917;&#20805;&#65292;&#20197;&#23454;&#29616;&#23545;&#27169;&#22411;&#34892;&#20026;&#30340;&#32454;&#31890;&#24230;&#20154;&#31867;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Predictive student models are increasingly used in learning environments due to their ability to enhance educational outcomes and support stakeholders in making informed decisions. However, predictive models can be biased and produce unfair outcomes, leading to potential discrimination against some students and possible harmful long-term implications. This has prompted research on fairness metrics meant to capture and quantify such biases. Nonetheless, so far, existing fairness metrics used in education are predictive performance-oriented, focusing on assessing biased outcomes across groups of students, without considering the behaviors of the models nor the severity of the biases in the outcomes. Therefore, we propose a novel metric, the Model Absolute Density Distance (MADD), to analyze models' discriminatory behaviors independently from their predictive performance. We also provide a complementary visualization-based analysis to enable fine-grained human assessment of how the models
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#39318;&#27425;&#24314;&#31435;&#20102;&#38750;&#22343;&#21248;&#36229;&#22270;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;HSBM&#65289;&#19979;&#30340;&#31934;&#30830;&#24674;&#22797;&#30340;&#23574;&#38160;&#38408;&#20540;&#65292;&#25552;&#20379;&#20102;&#20004;&#31181;&#26377;&#25928;&#31639;&#27861;&#65292;&#24182;&#20381;&#36182;&#20110;&#38750;&#22343;&#21248;&#38543;&#26426;&#36229;&#22270;&#30340;&#37051;&#25509;&#30697;&#38453;&#30340;&#38598;&#20013;&#21644;&#27491;&#21017;&#21270;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2304.13139</link><description>&lt;p&gt;
&#38750;&#22343;&#21248;&#36229;&#22270;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#31934;&#30830;&#24674;&#22797;
&lt;/p&gt;
&lt;p&gt;
Exact recovery for the non-uniform Hypergraph Stochastic Block Model. (arXiv:2304.13139v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13139
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#24314;&#31435;&#20102;&#38750;&#22343;&#21248;&#36229;&#22270;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;HSBM&#65289;&#19979;&#30340;&#31934;&#30830;&#24674;&#22797;&#30340;&#23574;&#38160;&#38408;&#20540;&#65292;&#25552;&#20379;&#20102;&#20004;&#31181;&#26377;&#25928;&#31639;&#27861;&#65292;&#24182;&#20381;&#36182;&#20110;&#38750;&#22343;&#21248;&#38543;&#26426;&#36229;&#22270;&#30340;&#37051;&#25509;&#30697;&#38453;&#30340;&#38598;&#20013;&#21644;&#27491;&#21017;&#21270;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32771;&#34385;&#22312;&#38750;&#22343;&#21248;&#36229;&#22270;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;HSBM&#65289;&#19979;&#30340;&#38543;&#26426;&#36229;&#22270;&#20013;&#30340;&#31038;&#21306;&#26816;&#27979;&#38382;&#39064;&#65292;&#20854;&#20013;&#27599;&#20010;&#36229;&#36793;&#29420;&#31435;&#22320;&#20197;&#26576;&#20123;&#32473;&#23450;&#27010;&#29575;&#20986;&#29616;&#65292;&#35813;&#27010;&#29575;&#20165;&#21462;&#20915;&#20110;&#20854;&#39030;&#28857;&#30340;&#26631;&#31614;&#12290;&#25105;&#20204;&#22312;&#26412;&#25991;&#20013;&#39318;&#27425;&#24314;&#31435;&#20102;&#22312;&#36825;&#31181;&#38750;&#22343;&#21248;&#24773;&#20917;&#19979;&#23454;&#29616;&#31934;&#30830;&#24674;&#22797;&#30340;&#23574;&#38160;&#38408;&#20540;&#65292;&#21463;&#21040;&#27425;&#35201;&#32422;&#26463;&#65307;&#23588;&#20854;&#26159;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20855;&#26377;K&#31867;&#21035;&#30340;&#27169;&#22411;&#21644;&#23545;&#31216;&#20108;&#36827;&#21046;&#27169;&#22411;&#65288;K=2&#65289;&#12290;&#20851;&#38190;&#28857;&#26159;&#36890;&#36807;&#32858;&#21512;&#25152;&#26377;&#22343;&#21248;&#23618;&#30340;&#20449;&#24687;&#65292;&#21363;&#20351;&#22312;&#32771;&#34385;&#27599;&#20010;&#23618;&#26102;&#20284;&#20046;&#19981;&#21487;&#33021;&#23454;&#29616;&#31934;&#30830;&#24674;&#22797;&#65292;&#25105;&#20204;&#20063;&#21487;&#20197;&#33719;&#24471;&#31934;&#30830;&#24674;&#22797;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#31181;&#26377;&#25928;&#31639;&#27861;&#65292;&#25104;&#21151;&#22320;&#22312;&#38408;&#20540;&#20197;&#19978;&#23454;&#29616;&#20102;&#31934;&#30830;&#24674;&#22797;&#12290;&#25105;&#20204;&#31639;&#27861;&#30340;&#29702;&#35770;&#20998;&#26512;&#20381;&#36182;&#20110;&#38750;&#22343;&#21248;&#38543;&#26426;&#36229;&#22270;&#30340;&#37051;&#25509;&#30697;&#38453;&#30340;&#38598;&#20013;&#21644;&#27491;&#21017;&#21270;&#65292;&#36825;&#21487;&#33021;&#20855;&#26377;&#29420;&#31435;&#30340;&#20852;&#36259;&#12290;&#25105;&#20204;&#36824;&#35299;&#20915;&#20102;&#19968;&#20123;&#23454;&#38469;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Consider the community detection problem in random hypergraphs under the non-uniform hypergraph stochastic block model (HSBM), where each hyperedge appears independently with some given probability depending only on the labels of its vertices. We establish, for the first time in the literature, a sharp threshold for exact recovery under this non-uniform case, subject to minor constraints; in particular, we consider the model with $K$ classes as well as the symmetric binary model ($K=2$). One crucial point here is that by aggregating information from all the uniform layers, we may obtain exact recovery even in cases when this may appear impossible if each layer were considered alone. Two efficient algorithms that successfully achieve exact recovery above the threshold are provided. The theoretical analysis of our algorithms relies on the concentration and regularization of the adjacency matrix for non-uniform random hypergraphs, which could be of independent interest. We also address so
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#19981;&#31934;&#30830;&#30340;&#36845;&#20195;&#32447;&#24615;&#20195;&#25968;&#26041;&#27861;&#65292;&#29992;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#35889;&#20272;&#35745;&#21644;&#20174;&#30701;&#36712;&#36857;&#25968;&#25454;&#38598;&#20013;&#36827;&#34892;&#31232;&#26377;&#20107;&#20214;&#30340;&#39044;&#27979;&#65292;&#36825;&#23545;&#20110;&#29702;&#35299;&#22797;&#26434;&#31995;&#32479;&#30340;&#21160;&#24577;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#24182;&#35752;&#35770;&#20102;&#35813;&#26041;&#27861;&#23545;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#39044;&#27979;&#38382;&#39064;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2303.12534</link><description>&lt;p&gt;
&#19981;&#31934;&#30830;&#30340;&#36845;&#20195;&#25968;&#20540;&#32447;&#24615;&#20195;&#25968;&#29992;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#35889;&#20272;&#35745;&#21644;&#31232;&#26377;&#20107;&#20214;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Inexact iterative numerical linear algebra for neural network-based spectral estimation and rare-event prediction. (arXiv:2303.12534v1 [physics.comp-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12534
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#19981;&#31934;&#30830;&#30340;&#36845;&#20195;&#32447;&#24615;&#20195;&#25968;&#26041;&#27861;&#65292;&#29992;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#35889;&#20272;&#35745;&#21644;&#20174;&#30701;&#36712;&#36857;&#25968;&#25454;&#38598;&#20013;&#36827;&#34892;&#31232;&#26377;&#20107;&#20214;&#30340;&#39044;&#27979;&#65292;&#36825;&#23545;&#20110;&#29702;&#35299;&#22797;&#26434;&#31995;&#32479;&#30340;&#21160;&#24577;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#24182;&#35752;&#35770;&#20102;&#35813;&#26041;&#27861;&#23545;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#39044;&#27979;&#38382;&#39064;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#22797;&#26434;&#31995;&#32479;&#23384;&#22312;&#22823;&#37327;&#33258;&#30001;&#24230;&#65292;&#20854;&#20013;&#26368;&#37325;&#35201;&#30340;&#24230;&#37327;&#36890;&#24120;&#24182;&#19981;&#26126;&#26174;&#65292;&#22240;&#27492;&#29702;&#35299;&#20854;&#21160;&#24577;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#36716;&#31227;&#31639;&#31526;&#30340;&#20027;&#35201;&#29305;&#24449;&#20989;&#25968;&#23545;&#20110;&#21487;&#35270;&#21270;&#24456;&#26377;&#29992;&#65292;&#23427;&#20204;&#21487;&#20197;&#20026;&#35745;&#31639;&#32479;&#35745;&#37327;&#65288;&#20363;&#22914;&#20107;&#20214;&#30340;&#21487;&#33021;&#24615;&#21644;&#24179;&#22343;&#26102;&#38388;&#65289;&#25552;&#20379;&#39640;&#25928;&#30340;&#22522;&#30784;&#65288;&#39044;&#27979;&#65289;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19981;&#31934;&#30830;&#30340;&#36845;&#20195;&#32447;&#24615;&#20195;&#25968;&#26041;&#27861;&#26469;&#35745;&#31639;&#36825;&#20123;&#29305;&#24449;&#20989;&#25968;&#65288;&#35889;&#20272;&#35745;&#65289;&#24182;&#20174;&#30701;&#36712;&#36857;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#39044;&#27979;&#12290;&#25105;&#20204;&#22312;&#20415;&#20110;&#21487;&#35270;&#21270;&#30340;&#20302;&#32500;&#27169;&#22411;&#21644;&#29983;&#29289;&#20998;&#23376;&#31995;&#32479;&#30340;&#39640;&#32500;&#27169;&#22411;&#19978;&#28436;&#31034;&#20102;&#35813;&#26041;&#27861;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#36825;&#20123;&#26041;&#27861;&#23545;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#39044;&#27979;&#38382;&#39064;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding dynamics in complex systems is challenging because there are many degrees of freedom, and those that are most important for describing events of interest are often not obvious. The leading eigenfunctions of the transition operator are useful for visualization, and they can provide an efficient basis for computing statistics such as the likelihood and average time of events (predictions). Here we develop inexact iterative linear algebra methods for computing these eigenfunctions (spectral estimation) and making predictions from a data set of short trajectories sampled at finite intervals. We demonstrate the methods on a low-dimensional model that facilitates visualization and a high-dimensional model of a biomolecular system. Implications for the prediction problem in reinforcement learning are discussed.
&lt;/p&gt;</description></item><item><title>&#35813;&#35843;&#26597;&#30740;&#31350;&#36890;&#36807;&#26102;&#38388;&#36807;&#31243;&#24314;&#27169;&#20107;&#20214;&#24207;&#21015;&#30340;&#27010;&#29575;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#31616;&#21333;&#12289;&#26631;&#35760;&#21644;&#26102;&#31354;&#28857;&#36807;&#31243;&#20998;&#31867;&#65292;&#23545;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#29616;&#26377;&#26041;&#27861;&#36827;&#34892;&#31995;&#32479;&#22238;&#39038;&#65292;&#24182;&#20998;&#26512;&#20102;&#24212;&#29992;&#20110;&#39044;&#27979;&#21644;&#24314;&#27169;&#26041;&#38754;&#30340;&#22330;&#26223;&#12290;</title><link>http://arxiv.org/abs/2303.06067</link><description>&lt;p&gt;
&#36890;&#36807;&#26102;&#38388;&#36807;&#31243;&#24314;&#27169;&#20107;&#20214;&#21644;&#30456;&#20114;&#20316;&#29992; - &#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Modeling Events and Interactions through Temporal Processes -- A Survey. (arXiv:2303.06067v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06067
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35843;&#26597;&#30740;&#31350;&#36890;&#36807;&#26102;&#38388;&#36807;&#31243;&#24314;&#27169;&#20107;&#20214;&#24207;&#21015;&#30340;&#27010;&#29575;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#31616;&#21333;&#12289;&#26631;&#35760;&#21644;&#26102;&#31354;&#28857;&#36807;&#31243;&#20998;&#31867;&#65292;&#23545;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#29616;&#26377;&#26041;&#27861;&#36827;&#34892;&#31995;&#32479;&#22238;&#39038;&#65292;&#24182;&#20998;&#26512;&#20102;&#24212;&#29992;&#20110;&#39044;&#27979;&#21644;&#24314;&#27169;&#26041;&#38754;&#30340;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#22330;&#26223;&#20013;&#65292;&#35768;&#22810;&#29616;&#35937;&#20197;&#36830;&#32493;&#26102;&#38388;&#21457;&#29983;&#30340;&#19968;&#31995;&#21015;&#20107;&#20214;&#20135;&#29983;&#12290;&#28857;&#36807;&#31243;&#20026;&#24314;&#27169;&#36825;&#20123;&#20107;&#20214;&#24207;&#21015;&#25552;&#20379;&#20102;&#19968;&#31181;&#33258;&#28982;&#30340;&#25968;&#23398;&#26694;&#26550;&#12290;&#22312;&#26412;&#35843;&#26597;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#26102;&#38388;&#36807;&#31243;&#30740;&#31350;&#27010;&#29575;&#27169;&#22411;&#26469;&#24314;&#27169;&#20107;&#20214;&#24207;&#21015;&#12290;&#25105;&#20204;&#20462;&#35746;&#20102;&#20107;&#20214;&#24314;&#27169;&#30340;&#27010;&#24565;&#65292;&#24182;&#25552;&#20379;&#20102;&#34920;&#24449;&#30456;&#20851;&#25991;&#29486;&#30340;&#25968;&#23398;&#22522;&#30784;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#19968;&#20010;&#26412;&#20307;&#26469;&#20197;&#19977;&#20010;&#31867;&#21035;&#65288;&#31616;&#21333;&#12289;&#26631;&#35760;&#21644;&#26102;&#31354;&#28857;&#36807;&#31243;&#65289;&#23545;&#29616;&#26377;&#26041;&#27861;&#36827;&#34892;&#20998;&#31867;&#12290;&#23545;&#20110;&#27599;&#20010;&#31867;&#21035;&#65292;&#25105;&#20204;&#31995;&#32479;&#22320;&#22238;&#39038;&#20102;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#29616;&#26377;&#26041;&#27861;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#25552;&#20986;&#30340;&#25216;&#26415;&#21487;&#20197;&#29992;&#20110;&#35299;&#20915;&#39044;&#27979;&#21644;&#24314;&#27169;&#26041;&#38754;&#30340;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
In real-world scenario, many phenomena produce a collection of events that occur in continuous time. Point Processes provide a natural mathematical framework for modeling these sequences of events. In this survey, we investigate probabilistic models for modeling event sequences through temporal processes. We revise the notion of event modeling and provide the mathematical foundations that characterize the literature on the topic. We define an ontology to categorize the existing approaches in terms of three families: simple, marked, and spatio-temporal point processes. For each family, we systematically review the existing approaches based based on deep learning. Finally, we analyze the scenarios where the proposed techniques can be used for addressing prediction and modeling aspects.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#20915;&#31574;&#20272;&#35745;&#31995;&#25968;&#23545;&#20219;&#24847;&#32467;&#26500;&#21270;&#36172;&#33218;&#38382;&#39064;&#30340;$\gamma$-&#36951;&#25022;&#36827;&#34892;&#20102;&#32039;&#23494;&#30028;&#23450;&#65292;&#35813;&#30028;&#23450;&#26159;&#23545;&#20989;&#25968;&#31867;&#30340;&#32479;&#35745;&#22797;&#26434;&#24230;&#21442;&#25968;$\gamma$-DEC&#30340;&#20462;&#25913;&#29256;&#26412;&#12290;&#20316;&#32773;&#21457;&#29616;$\gamma$-DEC&#26159;&#20219;&#20309;&#27169;&#22411;&#31867;$\mathcal{F}$&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#23545;&#20110;&#20219;&#20309;&#31639;&#27861;&#37117;&#23384;&#22312;&#26576;&#20010;$f \in \mathcal{F}$&#65292;&#35813;&#31639;&#27861;&#30340;$\gamma$-&#36951;&#25022;&#19982;$\mathcal{F}$&#30340;$\gamma$-DEC&#20960;&#20046;&#25104;&#27491;&#27604;&#12290;</title><link>http://arxiv.org/abs/2303.03327</link><description>&lt;p&gt;
&#36890;&#36807;&#20915;&#31574;&#20272;&#35745;&#31995;&#25968;&#65292;&#23545;$\gamma$-&#36951;&#25022;&#36827;&#34892;&#32039;&#23494;&#30028;&#23450;
&lt;/p&gt;
&lt;p&gt;
Tight Bounds for $\gamma$-Regret via the Decision-Estimation Coefficient. (arXiv:2303.03327v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.03327
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#20915;&#31574;&#20272;&#35745;&#31995;&#25968;&#23545;&#20219;&#24847;&#32467;&#26500;&#21270;&#36172;&#33218;&#38382;&#39064;&#30340;$\gamma$-&#36951;&#25022;&#36827;&#34892;&#20102;&#32039;&#23494;&#30028;&#23450;&#65292;&#35813;&#30028;&#23450;&#26159;&#23545;&#20989;&#25968;&#31867;&#30340;&#32479;&#35745;&#22797;&#26434;&#24230;&#21442;&#25968;$\gamma$-DEC&#30340;&#20462;&#25913;&#29256;&#26412;&#12290;&#20316;&#32773;&#21457;&#29616;$\gamma$-DEC&#26159;&#20219;&#20309;&#27169;&#22411;&#31867;$\mathcal{F}$&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#23545;&#20110;&#20219;&#20309;&#31639;&#27861;&#37117;&#23384;&#22312;&#26576;&#20010;$f \in \mathcal{F}$&#65292;&#35813;&#31639;&#27861;&#30340;$\gamma$-&#36951;&#25022;&#19982;$\mathcal{F}$&#30340;$\gamma$-DEC&#20960;&#20046;&#25104;&#27491;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#23545;&#20219;&#24847;&#32467;&#26500;&#21270;&#36172;&#33218;&#38382;&#39064;&#30340;$\gamma$-&#36951;&#25022;&#30340;&#32479;&#35745;&#25551;&#36848;&#65292;&#35813;&#36951;&#25022;&#26159;&#19982;$\gamma$&#20493;&#26368;&#20248;&#35299;&#30456;&#27604;&#36739;&#26102;&#20135;&#29983;&#30340;&#36951;&#25022;&#12290;&#22312;&#20989;&#25968;&#31867;$\mathcal{F}$&#19978;&#30340;&#32467;&#26500;&#21270;&#36172;&#33218;&#38382;&#39064;&#20013;&#65292;&#23547;&#25214;$f \in \mathcal{F}$&#30340;&#31934;&#30830;&#26368;&#20248;&#35299;&#26159;&#38590;&#20197;&#22788;&#29702;&#30340;&#12290;&#25105;&#20204;&#30340;&#25551;&#36848;&#26159;&#22522;&#20110;$\gamma$-DEC&#30340;&#65292;&#23427;&#26159;&#20989;&#25968;&#31867;$\mathcal{F}$&#30340;&#32479;&#35745;&#22797;&#26434;&#24230;&#21442;&#25968;&#65292;&#26159;Foster et al.&#65292;2023&#30340;&#32422;&#26463;&#20915;&#31574;&#20272;&#35745;&#31995;&#25968;(DEC)&#30340;&#20462;&#25913;&#29256;&#26412;&#65288;&#19982;Foster et al.&#65292;2021&#30340;&#21407;&#22987;&#20559;&#31227;DEC&#23494;&#20999;&#30456;&#20851;&#65289;&#12290;&#25105;&#20204;&#30340;&#19979;&#30028;&#34920;&#26126;&#65292;&#23545;&#20110;&#20219;&#20309;&#27169;&#22411;&#31867;$\mathcal{F}$&#65292;$\gamma$-DEC&#26159;&#19968;&#20010;&#22522;&#26412;&#38480;&#21046;&#65306;&#23545;&#20110;&#20219;&#20309;&#31639;&#27861;&#65292;&#23384;&#22312;&#19968;&#20123;$f \in \mathcal{F}$&#65292;&#35813;&#31639;&#27861;&#30340;$\gamma$-&#36951;&#25022;&#19982;$\mathcal{F}$&#30340;$\gamma$-DEC&#30340;&#35268;&#27169;&#65288;&#20960;&#20046;&#65289;&#25104;&#27491;&#27604;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#19978;&#30028;&#65292;&#35777;&#26126;&#20102;&#23384;&#22312;&#19968;&#20123;......
&lt;/p&gt;
&lt;p&gt;
In this work, we give a statistical characterization of the $\gamma$-regret for arbitrary structured bandit problems, the regret which arises when comparing against a benchmark that is $\gamma$ times the optimal solution. The $\gamma$-regret emerges in structured bandit problems over a function class $\mathcal{F}$ where finding an exact optimum of $f \in \mathcal{F}$ is intractable. Our characterization is given in terms of the $\gamma$-DEC, a statistical complexity parameter for the class $\mathcal{F}$, which is a modification of the constrained Decision-Estimation Coefficient (DEC) of Foster et al., 2023 (and closely related to the original offset DEC of Foster et al., 2021). Our lower bound shows that the $\gamma$-DEC is a fundamental limit for any model class $\mathcal{F}$: for any algorithm, there exists some $f \in \mathcal{F}$ for which the $\gamma$-regret of that algorithm scales (nearly) with the $\gamma$-DEC of $\mathcal{F}$. We provide an upper bound showing that there exist
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#21487;&#35777;&#26126;&#29256;&#26435;&#20445;&#25252;&#29983;&#25104;&#27169;&#22411;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#36817;&#26080;&#38459;&#30861;&#24615;&#65288;NAF&#65289;&#30340;&#23450;&#20041;&#65292;&#24182;&#32473;&#20986;&#20102;&#28385;&#36275;&#35813;&#23450;&#20041;&#30340;&#27169;&#22411;&#36755;&#20986;&#19982;&#21463;&#29256;&#26435;&#20445;&#25252;&#25968;&#25454;&#30456;&#20284;&#26679;&#26412;&#30340;&#27010;&#29575;&#19978;&#38480;&#12290;&#21516;&#26102;&#65292;&#36824;&#25552;&#20379;&#20102;&#29983;&#25104;&#27169;&#22411;&#23398;&#20064;&#31639;&#27861;&#65292;&#33021;&#22815;&#39640;&#25928;&#36755;&#20986;&#20855;&#26377;&#24378;&#22823;&#29256;&#26435;&#20445;&#25252;&#33021;&#21147;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#26368;&#21518;&#65292;&#36827;&#34892;&#20102;&#26377;&#21069;&#26223;&#30340;&#35821;&#35328;&#21644;&#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#23454;&#39564;&#12290;</title><link>http://arxiv.org/abs/2302.10870</link><description>&lt;p&gt;
&#20851;&#20110;&#21487;&#35777;&#26126;&#29256;&#26435;&#20445;&#25252;&#29983;&#25104;&#27169;&#22411;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Provable Copyright Protection for Generative Models. (arXiv:2302.10870v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10870
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#21487;&#35777;&#26126;&#29256;&#26435;&#20445;&#25252;&#29983;&#25104;&#27169;&#22411;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#36817;&#26080;&#38459;&#30861;&#24615;&#65288;NAF&#65289;&#30340;&#23450;&#20041;&#65292;&#24182;&#32473;&#20986;&#20102;&#28385;&#36275;&#35813;&#23450;&#20041;&#30340;&#27169;&#22411;&#36755;&#20986;&#19982;&#21463;&#29256;&#26435;&#20445;&#25252;&#25968;&#25454;&#30456;&#20284;&#26679;&#26412;&#30340;&#27010;&#29575;&#19978;&#38480;&#12290;&#21516;&#26102;&#65292;&#36824;&#25552;&#20379;&#20102;&#29983;&#25104;&#27169;&#22411;&#23398;&#20064;&#31639;&#27861;&#65292;&#33021;&#22815;&#39640;&#25928;&#36755;&#20986;&#20855;&#26377;&#24378;&#22823;&#29256;&#26435;&#20445;&#25252;&#33021;&#21147;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#26368;&#21518;&#65292;&#36827;&#34892;&#20102;&#26377;&#21069;&#26223;&#30340;&#35821;&#35328;&#21644;&#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25285;&#24515;&#23398;&#20064;&#30340;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#21487;&#33021;&#36755;&#20986;&#19982;&#20854;&#35757;&#32451;&#38598;&#20013;&#30340;&#26576;&#20123;&#21463;&#29256;&#26435;&#20445;&#25252;&#30340;&#25968;&#25454;$C$&#26497;&#20026;&#30456;&#20284;&#30340;&#26679;&#26412;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#8220;&#36817;&#26080;&#38459;&#30861;&#24615;&#65288;NAF&#65289;&#8221;&#30340;&#27491;&#24335;&#23450;&#20041;&#65292;&#24182;&#35777;&#26126;&#20102;&#28385;&#36275;&#36825;&#20010;&#23450;&#20041;&#30340;&#27169;&#22411;&#36755;&#20986;&#19982;$C$&#30456;&#20284;&#26679;&#26412;&#30340;&#27010;&#29575;&#19978;&#38480;&#65292;&#21363;&#20351;$C$&#21253;&#21547;&#22312;&#20854;&#35757;&#32451;&#38598;&#20013;&#12290;&#31895;&#30053;&#22320;&#35828;&#65292;&#29983;&#25104;&#27169;&#22411;$p$&#26159;&#8220;$k$-NAF&#8221;&#30340;&#65292;&#22914;&#26524;&#23545;&#20110;&#27599;&#19968;&#20010;&#28508;&#22312;&#30340;&#21463;&#29256;&#26435;&#20445;&#25252;&#30340;&#25968;&#25454;$C$&#65292;$p$&#30340;&#36755;&#20986;&#19982;&#19968;&#20010;&#23436;&#20840;&#26410;&#35775;&#38382;$C$&#30340;&#27169;&#22411;$q$&#30340;&#36755;&#20986;&#20043;&#38388;&#30340;&#24046;&#21035;&#26368;&#22823;&#20026;$k$&#27604;&#29305;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#29983;&#25104;&#27169;&#22411;&#23398;&#20064;&#31639;&#27861;&#65292;&#20197;&#40657;&#30418;&#26041;&#24335;&#39640;&#25928;&#20462;&#25913;&#21407;&#22987;&#29983;&#25104;&#27169;&#22411;&#23398;&#20064;&#31639;&#27861;&#65292;&#36755;&#20986;&#20855;&#26377;&#24378;&#22823;&#30340;&#20445;&#25252;&#20869;&#23481;&#37319;&#26679;&#27010;&#29575;&#19978;&#38480;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#38024;&#23545;&#35821;&#35328;&#65288;Transformer&#65289;&#21644;&#22270;&#20687;&#65288;Diffusion&#65289;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#20102;&#26377;&#21069;&#26223;&#30340;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is a growing concern that learned conditional generative models may output samples that are substantially similar to some copyrighted data $C$ that was in their training set. We give a formal definition of $\textit{near access-freeness (NAF)}$ and prove bounds on the probability that a model satisfying this definition outputs a sample similar to $C$, even if $C$ is included in its training set. Roughly speaking, a generative model $p$ is $\textit{$k$-NAF}$ if for every potentially copyrighted data $C$, the output of $p$ diverges by at most $k$-bits from the output of a model $q$ that $\textit{did not access $C$ at all}$. We also give generative model learning algorithms, which efficiently modify the original generative model learning algorithm in a black box manner, that output generative models with strong bounds on the probability of sampling protected content. Furthermore, we provide promising experiments for both language (transformers) and image (diffusion) generative models
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#31616;&#21270;&#65292;&#25552;&#20986;&#20102;&#40654;&#26364;&#27491;&#24120;&#22352;&#26631;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#21487;&#29992;&#20110;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#30340;&#23376;&#27969;&#24418;&#20248;&#21270;&#65292;&#24182;&#20026;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#65292;&#26080;&#38656;&#26174;&#24335;&#30697;&#38453;&#27714;&#36870;&#12290;</title><link>http://arxiv.org/abs/2302.09738</link><description>&lt;p&gt;
&#31616;&#21270;&#22522;&#20110;&#21160;&#37327;&#30340;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Simplifying Momentum-based Riemannian Submanifold Optimization. (arXiv:2302.09738v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09738
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#31616;&#21270;&#65292;&#25552;&#20986;&#20102;&#40654;&#26364;&#27491;&#24120;&#22352;&#26631;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#21487;&#29992;&#20110;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#30340;&#23376;&#27969;&#24418;&#20248;&#21270;&#65292;&#24182;&#20026;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#65292;&#26080;&#38656;&#26174;&#24335;&#30697;&#38453;&#27714;&#36870;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24102;&#26377;&#21160;&#37327;&#30340;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;&#22312;&#35745;&#31639;&#19978;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#30830;&#20445;&#36845;&#20195;&#20445;&#25345;&#22312;&#23376;&#27969;&#24418;&#19978;&#36890;&#24120;&#38656;&#35201;&#35299;&#20915;&#22256;&#38590;&#30340;&#24494;&#20998;&#26041;&#31243;&#12290;&#26412;&#25991;&#38024;&#23545;&#20855;&#26377;&#20223;&#23556;&#19981;&#21464;&#24230;&#37327;&#30340;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#30340;&#23376;&#27969;&#24418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#31616;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#40654;&#26364;&#27491;&#24120;&#22352;&#26631;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#21487;&#20197;&#23558;&#38382;&#39064;&#21160;&#24577;&#22320;&#31616;&#21270;&#20026;&#27431;&#20960;&#37324;&#24471;&#26080;&#32422;&#26463;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#26469;&#35299;&#37322;&#21644;&#31616;&#21270;&#29616;&#26377;&#30340;&#32467;&#26500;&#21270;&#21327;&#26041;&#24046;&#26041;&#27861;&#65292;&#24182;&#20026;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#65292;&#32780;&#26080;&#38656;&#26174;&#24335;&#30697;&#38453;&#27714;&#36870;&#12290;
&lt;/p&gt;
&lt;p&gt;
Riemannian submanifold optimization with momentum is computationally challenging because ensuring iterates remain on the submanifold often requires solving difficult differential equations. We simplify such optimization algorithms for the submanifold of symmetric positive-definite matrices with the affine invariant metric. We propose a generalized version of the Riemannian normal coordinates which dynamically trivializes the problem into a Euclidean unconstrained problem. We use our approach to explain and simplify existing approaches for structured covariances and develop efficient second-order optimizers for deep learning without explicit matrix inverses.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;&#30340;&#31070;&#32463;&#32593;&#32476;&#35770;&#35777;&#35299;&#37322;&#26041;&#27861;SpArX&#65292;&#36890;&#36807;&#21033;&#29992;&#22810;&#23618;&#24863;&#30693;&#22120;&#21644;&#23450;&#37327;&#35770;&#35777;&#26694;&#26550;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#21487;&#20197;&#20026;&#31070;&#32463;&#32593;&#32476;&#30340;&#20915;&#31574;&#36807;&#31243;&#25552;&#20379;&#26356;&#24544;&#23454;&#21644;&#28145;&#20837;&#30340;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2301.09559</link><description>&lt;p&gt;
SpArX: &#31232;&#30095;&#30340;&#31070;&#32463;&#32593;&#32476;&#35770;&#35777;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
SpArX: Sparse Argumentative Explanations for Neural Networks. (arXiv:2301.09559v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.09559
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;&#30340;&#31070;&#32463;&#32593;&#32476;&#35770;&#35777;&#35299;&#37322;&#26041;&#27861;SpArX&#65292;&#36890;&#36807;&#21033;&#29992;&#22810;&#23618;&#24863;&#30693;&#22120;&#21644;&#23450;&#37327;&#35770;&#35777;&#26694;&#26550;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#21487;&#20197;&#20026;&#31070;&#32463;&#32593;&#32476;&#30340;&#20915;&#31574;&#36807;&#31243;&#25552;&#20379;&#26356;&#24544;&#23454;&#21644;&#28145;&#20837;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#22312;&#20154;&#24037;&#26234;&#33021;&#20013;&#26377;&#21508;&#31181;&#24212;&#29992;&#65292;&#20294;&#35299;&#37322;&#23427;&#20204;&#30340;&#20915;&#31574;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#20851;&#27880;&#35299;&#37322;&#25913;&#21464;&#21333;&#20010;&#36755;&#20837;&#22914;&#20309;&#24433;&#21709;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20986;&#12290;&#28982;&#32780;&#65292;&#19968;&#20010;&#19982;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20837;&#36755;&#20986;&#34892;&#20026;&#19968;&#33268;&#30340;&#35299;&#37322;&#26410;&#24517;&#24544;&#23454;&#20110;&#20854;&#23454;&#38469;&#26426;&#21046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#22810;&#23618;&#24863;&#30693;&#22120;&#21644;&#23450;&#37327;&#35770;&#35777;&#26694;&#26550;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20026;&#22810;&#23618;&#24863;&#30693;&#22120;&#30340;&#26426;&#21046;&#21019;&#24314;&#20102;&#35770;&#35777;&#24615;&#35299;&#37322;&#12290;&#25105;&#20204;&#30340;SpArX&#26041;&#27861;&#39318;&#20808;&#23558;&#22810;&#23618;&#24863;&#30693;&#22120;&#31232;&#30095;&#21270;&#65292;&#21516;&#26102;&#20445;&#25345;&#23613;&#21487;&#33021;&#22810;&#30340;&#21407;&#22987;&#32467;&#26500;&#12290;&#28982;&#21518;&#23558;&#31232;&#30095;&#30340;&#22810;&#23618;&#24863;&#30693;&#22120;&#36716;&#21270;&#20026;&#31561;&#25928;&#30340;&#23450;&#37327;&#35770;&#35777;&#26694;&#26550;&#65292;&#20197;&#25581;&#31034;&#22810;&#23618;&#24863;&#30693;&#22120;&#30340;&#28508;&#22312;&#20915;&#31574;&#36807;&#31243;&#65292;&#20135;&#29983;&#20840;&#23616;&#21644;/&#25110;&#23616;&#37096;&#35299;&#37322;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;SpArX&#27604;&#29616;&#26377;&#26041;&#27861;&#21487;&#20197;&#32473;&#20986;&#26356;&#24544;&#23454;&#30340;&#35299;&#37322;&#65292;&#21516;&#26102;&#25552;&#20379;&#26356;&#28145;&#20837;&#30340;&#27934;&#23519;&#23454;&#38469;&#25512;&#29702;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural networks (NNs) have various applications in AI, but explaining their decisions remains challenging. Existing approaches often focus on explaining how changing individual inputs affects NNs' outputs. However, an explanation that is consistent with the input-output behaviour of an NN is not necessarily faithful to the actual mechanics thereof. In this paper, we exploit relationships between multi-layer perceptrons (MLPs) and quantitative argumentation frameworks (QAFs) to create argumentative explanations for the mechanics of MLPs. Our SpArX method first sparsifies the MLP while maintaining as much of the original structure as possible. It then translates the sparse MLP into an equivalent QAF to shed light on the underlying decision process of the MLP, producing global and/or local explanations. We demonstrate experimentally that SpArX can give more faithful explanations than existing approaches, while simultaneously providing deeper insights into the actual reasoning process of M
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#27969;&#24418;&#31070;&#32463;&#32593;&#32476;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#36890;&#36807;&#24314;&#31435;&#19968;&#20010;&#19982;&#29615;&#22659;&#32500;&#24230;&#26080;&#20851;&#20294;&#19982;&#27969;&#24418;&#20869;&#22312;&#32500;&#24230;&#30456;&#20851;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#23545;&#20808;&#21069;&#30340;&#24037;&#20316;&#36827;&#34892;&#20102;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2212.12606</link><description>&lt;p&gt;
&#27969;&#24418;&#31070;&#32463;&#32593;&#32476;&#30340;&#25910;&#25947;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
A Convergence Rate for Manifold Neural Networks. (arXiv:2212.12606v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.12606
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#27969;&#24418;&#31070;&#32463;&#32593;&#32476;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#36890;&#36807;&#24314;&#31435;&#19968;&#20010;&#19982;&#29615;&#22659;&#32500;&#24230;&#26080;&#20851;&#20294;&#19982;&#27969;&#24418;&#20869;&#22312;&#32500;&#24230;&#30456;&#20851;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#23545;&#20808;&#21069;&#30340;&#24037;&#20316;&#36827;&#34892;&#20102;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#25968;&#25454;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#20135;&#29983;&#65292;&#24182;&#19988;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#36825;&#19968;&#24555;&#36895;&#21457;&#23637;&#30340;&#39046;&#22495;&#33268;&#21147;&#20110;&#24320;&#21457;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#20197;&#20415;&#22312;&#38750;&#27431;&#20960;&#37324;&#24503;&#39046;&#22495;&#65288;&#22914;&#22270;&#21644;&#27969;&#24418;&#65289;&#20013;&#20998;&#26512;&#27492;&#31867;&#25968;&#25454;&#12290;&#24343;&#19969;&#183;&#29579;&#12289;&#21776;&#22372;&#183;&#21346;&#20197;&#21450;&#20122;&#21382;&#23665;&#22823;&#183;&#37324;&#36125;&#32599;&#26368;&#36817;&#30340;&#24037;&#20316;&#24341;&#20837;&#20102;&#19968;&#31181;&#21033;&#29992;&#25289;&#26222;&#25289;&#26031;-&#36125;&#23572;&#29305;&#25289;&#31859;&#31639;&#23376;&#30340;&#35889;&#20998;&#35299;&#26500;&#24314;&#27969;&#24418;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#20316;&#32773;&#25552;&#20379;&#20102;&#19968;&#31181;&#25968;&#20540;&#26041;&#26696;&#65292;&#20197;&#22312;&#27969;&#24418;&#26410;&#30693;&#19988;&#20165;&#26377;&#26377;&#38480;&#25968;&#37327;&#26679;&#26412;&#28857;&#21487;&#33719;&#24471;&#30340;&#24773;&#20917;&#19979;&#23454;&#26045;&#27492;&#31867;&#31070;&#32463;&#32593;&#32476;&#12290;&#20316;&#32773;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#26696;&#65292;&#20381;&#38752;&#26500;&#24314;&#25968;&#25454;&#39537;&#21160;&#30340;&#22270;&#65292;&#24403;&#26679;&#26412;&#28857;&#25968;&#37327;&#36235;&#20110;&#26080;&#31351;&#22823;&#26102;&#65292;&#25910;&#25947;&#21040;&#36830;&#32493;&#26497;&#38480;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#22312;&#27492;&#32467;&#26524;&#30340;&#22522;&#30784;&#19978;&#24314;&#31435;&#20102;&#19968;&#20010;&#25910;&#25947;&#36895;&#29575;&#65292;&#35813;&#25910;&#25947;&#36895;&#29575;&#21462;&#20915;&#20110;&#27969;&#24418;&#30340;&#20869;&#22312;&#32500;&#24230;&#65292;&#20294;&#19982;&#29615;&#22659;&#32500;&#24230;&#26080;&#20851;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#25910;&#25947;&#36895;&#29575;&#22914;&#20309;&#20381;&#36182;&#20110;...
&lt;/p&gt;
&lt;p&gt;
High-dimensional data arises in numerous applications, and the rapidly developing field of geometric deep learning seeks to develop neural network architectures to analyze such data in non-Euclidean domains, such as graphs and manifolds. Recent work by Z. Wang, L. Ruiz, and A. Ribeiro has introduced a method for constructing manifold neural networks using the spectral decomposition of the Laplace Beltrami operator. Moreover, in this work, the authors provide a numerical scheme for implementing such neural networks when the manifold is unknown and one only has access to finitely many sample points. The authors show that this scheme, which relies upon building a data-driven graph, converges to the continuum limit as the number of sample points tends to infinity. Here, we build upon this result by establishing a rate of convergence that depends on the intrinsic dimension of the manifold but is independent of the ambient dimension. We also discuss how the rate of convergence depends on the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20998;&#24067;&#36716;&#31227;&#20889;&#19979;&#65292;&#26399;&#26395;&#27169;&#22411;&#22312;&#20004;&#20010;&#20998;&#24067;&#19978;&#24615;&#33021;&#23384;&#22312;&#21333;&#35843;&#20851;&#31995;&#30340;&#26465;&#20214;&#65292;&#21033;&#29992;&#23725;&#27491;&#21017;&#21270;&#36890;&#29992;&#32447;&#24615;&#27169;&#22411;&#35777;&#26126;&#20102;&#24179;&#26041;&#35823;&#24046;&#30340;&#31934;&#30830;&#28176;&#36817;&#32447;&#24615;&#20851;&#31995;&#21644;&#35823;&#20998;&#31867;&#35823;&#24046;&#30340;&#21333;&#35843;&#20851;&#31995;&#65292;&#20197;&#21450;&#32447;&#24615;&#36870;&#38382;&#39064;&#30340;&#36817;&#20284;&#32447;&#24615;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2210.11589</link><description>&lt;p&gt;
&#22312;&#20998;&#24067;&#20559;&#31227;&#19979;&#27491;&#21017;&#21270;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#21333;&#35843;&#39118;&#38505;&#20851;&#31995;
&lt;/p&gt;
&lt;p&gt;
Monotonic Risk Relationships under Distribution Shifts for Regularized Risk Minimization. (arXiv:2210.11589v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.11589
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20998;&#24067;&#36716;&#31227;&#20889;&#19979;&#65292;&#26399;&#26395;&#27169;&#22411;&#22312;&#20004;&#20010;&#20998;&#24067;&#19978;&#24615;&#33021;&#23384;&#22312;&#21333;&#35843;&#20851;&#31995;&#30340;&#26465;&#20214;&#65292;&#21033;&#29992;&#23725;&#27491;&#21017;&#21270;&#36890;&#29992;&#32447;&#24615;&#27169;&#22411;&#35777;&#26126;&#20102;&#24179;&#26041;&#35823;&#24046;&#30340;&#31934;&#30830;&#28176;&#36817;&#32447;&#24615;&#20851;&#31995;&#21644;&#35823;&#20998;&#31867;&#35823;&#24046;&#30340;&#21333;&#35843;&#20851;&#31995;&#65292;&#20197;&#21450;&#32447;&#24615;&#36870;&#38382;&#39064;&#30340;&#36817;&#20284;&#32447;&#24615;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#36890;&#24120;&#24212;&#29992;&#20110;&#19982;&#35757;&#32451;&#20998;&#24067;&#19981;&#21516;&#30340;&#25968;&#25454;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#21508;&#31181;&#20998;&#31867;&#21644;&#20449;&#21495;&#37325;&#24314;&#38382;&#39064;&#20013;&#65292;&#36229;&#20986;&#20998;&#24067;&#30340;&#24615;&#33021;&#19982;&#20869;&#37096;&#20998;&#24067;&#30340;&#24615;&#33021;&#24378;&#28872;&#32447;&#24615;&#30456;&#20851;&#12290;&#22914;&#26524;&#23384;&#22312;&#36825;&#31181;&#20851;&#31995;&#25110;&#26356;&#19968;&#33324;&#30340;&#21333;&#35843;&#20851;&#31995;&#65292;&#23558;&#20135;&#29983;&#37325;&#35201;&#30340;&#24433;&#21709;&#12290;&#20363;&#22914;&#65292;&#23427;&#20801;&#35768;&#23558;&#19968;&#20010;&#20998;&#24067;&#19978;&#30340;&#24615;&#33021;&#20248;&#21270;&#20316;&#20026;&#21478;&#19968;&#20010;&#20998;&#24067;&#19978;&#24615;&#33021;&#30340;&#20195;&#29702;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#20004;&#20010;&#20998;&#24067;&#19978;&#27169;&#22411;&#24615;&#33021;&#20043;&#38388;&#39044;&#26399;&#23384;&#22312;&#21333;&#35843;&#20851;&#31995;&#30340;&#26465;&#20214;&#12290;&#25105;&#20204;&#22312;&#21327;&#21464;&#37327;&#36716;&#31227;&#19979;&#65292;&#35777;&#26126;&#20102;&#23725;&#27491;&#21017;&#21270;&#36890;&#29992;&#32447;&#24615;&#27169;&#22411;&#30340;&#24179;&#26041;&#35823;&#24046;&#30340;&#31934;&#30830;&#28176;&#36817;&#32447;&#24615;&#20851;&#31995;&#21644;&#35823;&#20998;&#31867;&#35823;&#24046;&#30340;&#21333;&#35843;&#20851;&#31995;&#65292;&#20197;&#21450;&#32447;&#24615;&#36870;&#38382;&#39064;&#30340;&#36817;&#20284;&#32447;&#24615;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning systems are often applied to data that is drawn from a different distribution than the training distribution. Recent work has shown that for a variety of classification and signal reconstruction problems, the out-of-distribution performance is strongly linearly correlated with the in-distribution performance. If this relationship or more generally a monotonic one holds, it has important consequences. For example, it allows to optimize performance on one distribution as a proxy for performance on the other. In this paper, we study conditions under which a monotonic relationship between the performances of a model on two distributions is expected. We prove an exact asymptotic linear relation for squared error and a monotonic relation for misclassification error for ridge-regularized general linear models under covariate shift, as well as an approximate linear relation for linear inverse problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#25239;&#36125;&#21494;&#26031;&#27169;&#25311;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#36817;&#20284;&#36125;&#21494;&#26031;&#35745;&#31639;&#19982;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#21644;&#23545;&#25239;&#21464;&#20998;&#36125;&#21494;&#26031;&#30456;&#32467;&#21512;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#30452;&#25509;&#38024;&#23545;&#21518;&#39564;&#27010;&#29575;&#30340;&#36125;&#21494;&#26031;GAN&#65288;B-GAN&#65289;&#37319;&#26679;&#22120;&#65292;&#36890;&#36807;&#35299;&#20915;&#19968;&#20010;&#23545;&#25239;&#20248;&#21270;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;&#25968;&#25454;&#39537;&#21160;&#24314;&#35758;&#21644;&#37325;&#35201;&#24615;&#37325;&#26032;&#21152;&#26435;&#20197;&#21450;&#21464;&#20998;&#36125;&#21494;&#26031;&#31561;&#21518;&#22788;&#29702;&#25216;&#26415;&#65292;&#36827;&#19968;&#27493;&#25552;&#39640;&#20102;&#27169;&#25311;&#32467;&#26524;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2208.12113</link><description>&lt;p&gt;
&#23545;&#25239;&#36125;&#21494;&#26031;&#27169;&#25311;
&lt;/p&gt;
&lt;p&gt;
Adversarial Bayesian Simulation. (arXiv:2208.12113v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.12113
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#25239;&#36125;&#21494;&#26031;&#27169;&#25311;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#36817;&#20284;&#36125;&#21494;&#26031;&#35745;&#31639;&#19982;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#21644;&#23545;&#25239;&#21464;&#20998;&#36125;&#21494;&#26031;&#30456;&#32467;&#21512;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#30452;&#25509;&#38024;&#23545;&#21518;&#39564;&#27010;&#29575;&#30340;&#36125;&#21494;&#26031;GAN&#65288;B-GAN&#65289;&#37319;&#26679;&#22120;&#65292;&#36890;&#36807;&#35299;&#20915;&#19968;&#20010;&#23545;&#25239;&#20248;&#21270;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;&#25968;&#25454;&#39537;&#21160;&#24314;&#35758;&#21644;&#37325;&#35201;&#24615;&#37325;&#26032;&#21152;&#26435;&#20197;&#21450;&#21464;&#20998;&#36125;&#21494;&#26031;&#31561;&#21518;&#22788;&#29702;&#25216;&#26415;&#65292;&#36827;&#19968;&#27493;&#25552;&#39640;&#20102;&#27169;&#25311;&#32467;&#26524;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27809;&#26377;&#26126;&#30830;&#25110;&#21487;&#35745;&#31639;&#30340;&#20284;&#28982;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#36125;&#21494;&#26031;&#25512;&#26029;&#24120;&#24120;&#20351;&#29992;&#36817;&#20284;&#36125;&#21494;&#26031;&#35745;&#31639;&#65288;ABC&#65289;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#23558;ABC&#19982;&#22522;&#20110;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#21644;&#23545;&#25239;&#21464;&#20998;&#36125;&#21494;&#26031;&#30340;&#28145;&#24230;&#31070;&#32463;&#38544;&#24335;&#37319;&#26679;&#22120;&#30456;&#32467;&#21512;&#12290;ABC&#21644;GANs&#20998;&#21035;&#27604;&#36739;&#35266;&#27979;&#25968;&#25454;&#21644;&#34394;&#20551;&#25968;&#25454;&#30340;&#21508;&#20010;&#26041;&#38754;&#20197;&#27169;&#25311;&#21518;&#39564;&#27010;&#29575;&#21644;&#20284;&#28982;&#20989;&#25968;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;GAN&#65288;B-GAN&#65289;&#37319;&#26679;&#22120;&#65292;&#36890;&#36807;&#35299;&#20915;&#19968;&#20010;&#23545;&#25239;&#20248;&#21270;&#38382;&#39064;&#30452;&#25509;&#23545;&#20934;&#30446;&#26631;&#21518;&#39564;&#27010;&#29575;&#12290;B-GAN&#30001;&#22312;ABC&#21442;&#32771;&#19978;&#36890;&#36807;&#26465;&#20214;GANs&#23398;&#20064;&#30340;&#30830;&#23450;&#24615;&#26144;&#23556;&#39537;&#21160;&#12290;&#19968;&#26086;&#26144;&#23556;&#34987;&#35757;&#32451;&#22909;&#65292;&#36890;&#36807;&#28388;&#38500;&#22122;&#22768;&#20197;&#20960;&#20046;&#27809;&#26377;&#39069;&#22806;&#20195;&#20215;&#30340;&#26041;&#24335;&#33719;&#24471;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#21518;&#39564;&#26679;&#26412;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#21518;&#22788;&#29702;&#23616;&#37096;&#25913;&#36827;&#26041;&#27861;&#65292;&#20998;&#21035;&#20351;&#29992;&#20102;&#65288;1&#65289;&#25968;&#25454;&#39537;&#21160;&#30340;&#24314;&#35758;&#21644;&#37325;&#35201;&#24615;&#37325;&#26032;&#21152;&#26435;&#65292;&#21644;&#65288;2&#65289;&#21464;&#20998;&#36125;&#21494;&#26031;&#12290;&#25105;&#20204;&#29992;&#39057;&#29575;&#23398;-&#36125;&#21494;&#26031;&#30340;&#32467;&#26524;&#25903;&#25345;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#26174;&#31034;&#30495;&#23454;&#20540;&#19982;&#19968;&#20010;&#24120;&#35265;&#30340;&#24635;&#21464;&#24046;&#36317;&#31163;&#20043;&#38388;&#30340;&#24046;&#24322;
&lt;/p&gt;
&lt;p&gt;
In the absence of explicit or tractable likelihoods, Bayesians often resort to approximate Bayesian computation (ABC) for inference. Our work bridges ABC with deep neural implicit samplers based on generative adversarial networks (GANs) and adversarial variational Bayes. Both ABC and GANs compare aspects of observed and fake data to simulate from posteriors and likelihoods, respectively. We develop a Bayesian GAN (B-GAN) sampler that directly targets the posterior by solving an adversarial optimization problem. B-GAN is driven by a deterministic mapping learned on the ABC reference by conditional GANs. Once the mapping has been trained, iid posterior samples are obtained by filtering noise at a negligible additional cost. We propose two post-processing local refinements using (1) data-driven proposals with importance reweighting, and (2) variational Bayes. We support our findings with frequentist-Bayesian results, showing that the typical total variation distance between the true and a
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#21457;&#29616;&#20102;&#22312;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#31070;&#32463;&#20803;&#27963;&#21160;&#30340;&#21464;&#21270;&#19982;&#36830;&#25509;&#21040;&#19979;&#19968;&#23618;&#31070;&#32463;&#20803;&#30340;&#26435;&#37325;&#21464;&#21270;&#20043;&#38388;&#30340;&#20934;&#30830;&#23545;&#20598;&#20851;&#31995;&#12290;&#36890;&#36807;&#36825;&#31181;&#23545;&#20598;&#24615;&#65292;&#25105;&#20204;&#33021;&#22815;&#23558;&#36755;&#20837;&#25968;&#25454;&#30340;&#21464;&#21270;&#26144;&#23556;&#21040;&#23545;&#24212;&#30340;&#26435;&#37325;&#21464;&#21270;&#65292;&#24182;&#21457;&#29616;&#27867;&#21270;&#25439;&#22833;&#21487;&#20197;&#36890;&#36807;&#35299;&#30340;&#25439;&#22833;&#20989;&#25968;&#30340;Hessian&#30697;&#38453;&#30340;&#29305;&#24449;&#26041;&#21521;&#30340;&#20960;&#20309;&#22240;&#23376;&#30340;&#20056;&#31215;&#26469;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2203.10736</link><description>&lt;p&gt;
&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#27963;&#21160;-&#26435;&#37325;&#23545;&#20598;&#24615;&#65306;&#27867;&#21270;&#24615;&#30340;&#20960;&#20309;&#20915;&#23450;&#22240;&#32032;
&lt;/p&gt;
&lt;p&gt;
The activity-weight duality in feed forward neural networks: The geometric determinants of generalization. (arXiv:2203.10736v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.10736
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#21457;&#29616;&#20102;&#22312;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#31070;&#32463;&#20803;&#27963;&#21160;&#30340;&#21464;&#21270;&#19982;&#36830;&#25509;&#21040;&#19979;&#19968;&#23618;&#31070;&#32463;&#20803;&#30340;&#26435;&#37325;&#21464;&#21270;&#20043;&#38388;&#30340;&#20934;&#30830;&#23545;&#20598;&#20851;&#31995;&#12290;&#36890;&#36807;&#36825;&#31181;&#23545;&#20598;&#24615;&#65292;&#25105;&#20204;&#33021;&#22815;&#23558;&#36755;&#20837;&#25968;&#25454;&#30340;&#21464;&#21270;&#26144;&#23556;&#21040;&#23545;&#24212;&#30340;&#26435;&#37325;&#21464;&#21270;&#65292;&#24182;&#21457;&#29616;&#27867;&#21270;&#25439;&#22833;&#21487;&#20197;&#36890;&#36807;&#35299;&#30340;&#25439;&#22833;&#20989;&#25968;&#30340;Hessian&#30697;&#38453;&#30340;&#29305;&#24449;&#26041;&#21521;&#30340;&#20960;&#20309;&#22240;&#23376;&#30340;&#20056;&#31215;&#26469;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#19968;&#20010;&#22522;&#26412;&#30340;&#38382;&#39064;&#26159;&#27867;&#21270;&#24615;&#12290;&#22312;&#20855;&#26377;&#22823;&#37327;&#26435;&#37325;&#65288;&#21442;&#25968;&#65289;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20013;&#65292;&#21487;&#20197;&#25214;&#21040;&#24456;&#22810;&#35299;&#26469;&#24456;&#22909;&#22320;&#25311;&#21512;&#35757;&#32451;&#25968;&#25454;&#12290;&#20851;&#38190;&#38382;&#39064;&#26159;&#21738;&#20010;&#35299;&#33021;&#22815;&#25551;&#36848;&#19981;&#22312;&#35757;&#32451;&#38598;&#20013;&#30340;&#27979;&#35797;&#25968;&#25454;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25253;&#21578;&#20102;&#22312;&#20219;&#20309;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#30340;&#23494;&#38598;&#36830;&#25509;&#23618;&#20013;&#65292;&#32473;&#23450;&#23618;&#31070;&#32463;&#20803;&#27963;&#21160;&#30340;&#21464;&#21270;&#19982;&#36830;&#25509;&#21040;&#19979;&#19968;&#23618;&#31070;&#32463;&#20803;&#30340;&#26435;&#37325;&#21464;&#21270;&#20043;&#38388;&#30340;&#30830;&#20999;&#23545;&#20598;&#65288;&#31561;&#20215;&#65289;&#20851;&#31995;&#30340;&#21457;&#29616;&#12290;&#27963;&#21160;-&#26435;&#37325;&#65288;A-W&#65289;&#23545;&#20598;&#24615;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#36755;&#20837;&#65288;&#25968;&#25454;&#65289;&#30340;&#21464;&#21270;&#26144;&#23556;&#21040;&#30456;&#24212;&#30340;&#23545;&#20598;&#26435;&#37325;&#30340;&#21464;&#21270;&#12290;&#36890;&#36807;&#20351;&#29992;&#36825;&#31181;&#26144;&#23556;&#65292;&#25105;&#20204;&#34920;&#26126;&#27867;&#21270;&#25439;&#22833;&#21487;&#20197;&#20998;&#35299;&#20026;&#22312;&#26435;&#37325;&#31354;&#38388;&#20013;&#30340;&#35299;&#30340;&#25439;&#22833;&#20989;&#25968;&#30340;Hessian&#30697;&#38453;&#30340;&#19981;&#21516;&#29305;&#24449;&#26041;&#21521;&#30340;&#36129;&#29486;&#20043;&#21644;&#12290;&#32473;&#23450;&#29305;&#24449;&#26041;&#21521;&#30340;&#36129;&#29486;&#26159;&#20004;&#20010;&#20960;&#20309;&#22240;&#23376;&#65288;&#34892;&#21015;&#24335;&#65289;&#30340;&#20056;&#31215;&#65306;&#23574;&#38160;&#24230;
&lt;/p&gt;
&lt;p&gt;
One of the fundamental problems in machine learning is generalization. In neural network models with a large number of weights (parameters), many solutions can be found to fit the training data equally well. The key question is which solution can describe testing data not in the training set. Here, we report the discovery of an exact duality (equivalence) between changes in activities in a given layer of neurons and changes in weights that connect to the next layer of neurons in a densely connected layer in any feed forward neural network. The activity-weight (A-W) duality allows us to map variations in inputs (data) to variations of the corresponding dual weights. By using this mapping, we show that the generalization loss can be decomposed into a sum of contributions from different eigen-directions of the Hessian matrix of the loss function at the solution in weight space. The contribution from a given eigen-direction is the product of two geometric factors (determinants): the sharpn
&lt;/p&gt;</description></item><item><title>&#8220;&#21516;&#36136;&#24615;&#23545;&#20110;&#33391;&#22909;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#24615;&#33021;&#26159;&#21542;&#24517;&#35201;&#30340;&#8221;&#36825;&#19968;&#38382;&#39064;&#22312;&#30740;&#31350;&#20013;&#24471;&#21040;&#20102;&#37325;&#26032;&#35780;&#20272;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#26631;&#20934;&#30340;&#22270;&#21367;&#31215;&#32593;&#32476;&#65288;GCNs&#65289;&#22312;&#19968;&#20123;&#24120;&#29992;&#30340;&#24322;&#36136;&#24615;&#22270;&#19978;&#21487;&#20197;&#23454;&#29616;&#27604;&#31934;&#24515;&#35774;&#35745;&#30340;&#26041;&#27861;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2106.06134</link><description>&lt;p&gt;
&#8220;&#21516;&#36136;&#24615;&#23545;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#26159;&#24517;&#35201;&#30340;&#21527;&#65311;&#8221;
&lt;/p&gt;
&lt;p&gt;
Is Homophily a Necessity for Graph Neural Networks?. (arXiv:2106.06134v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.06134
&lt;/p&gt;
&lt;p&gt;
&#8220;&#21516;&#36136;&#24615;&#23545;&#20110;&#33391;&#22909;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#24615;&#33021;&#26159;&#21542;&#24517;&#35201;&#30340;&#8221;&#36825;&#19968;&#38382;&#39064;&#22312;&#30740;&#31350;&#20013;&#24471;&#21040;&#20102;&#37325;&#26032;&#35780;&#20272;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#26631;&#20934;&#30340;&#22270;&#21367;&#31215;&#32593;&#32476;&#65288;GCNs&#65289;&#22312;&#19968;&#20123;&#24120;&#29992;&#30340;&#24322;&#36136;&#24615;&#22270;&#19978;&#21487;&#20197;&#23454;&#29616;&#27604;&#31934;&#24515;&#35774;&#35745;&#30340;&#26041;&#27861;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#22312;&#23398;&#20064;&#36866;&#29992;&#20110;&#20247;&#22810;&#22522;&#20110;&#22270;&#30340;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#30340;&#34920;&#31034;&#26041;&#38754;&#26174;&#31034;&#20986;&#26497;&#24378;&#30340;&#33021;&#21147;&#12290;&#24403;&#24212;&#29992;&#20110;&#21322;&#30417;&#30563;&#33410;&#28857;&#20998;&#31867;&#26102;&#65292;&#30001;&#20110;&#21516;&#36136;&#24615;&#20551;&#35774;&#65288;&#8220;&#31867;&#20284;&#30456;&#20114;&#21560;&#24341;&#8221;&#65289;&#65292;&#20154;&#20204;&#26222;&#36941;&#35748;&#20026;GNN&#21487;&#20197;&#24456;&#22909;&#22320;&#24037;&#20316;&#65292;&#20294;&#22312;&#24322;&#36136;&#24615;&#22270;&#20013;&#65288;&#36830;&#25509;&#19981;&#30456;&#20284;&#33410;&#28857;&#30340;&#22270;&#65289;&#26080;&#27861;&#27867;&#21270;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#36890;&#36807;&#35774;&#35745;&#26032;&#30340;&#26550;&#26500;&#26469;&#20811;&#26381;&#36825;&#31181;&#19982;&#24322;&#36136;&#24615;&#30456;&#20851;&#30340;&#38480;&#21046;&#65292;&#24341;&#29992;&#20102;&#36139;&#24369;&#30340;&#22522;&#20934;&#24615;&#33021;&#20197;&#21450;&#22312;&#19968;&#20123;&#24322;&#36136;&#24615;&#22270;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#26032;&#26550;&#26500;&#25913;&#36827;&#20316;&#20026;&#35777;&#25454;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#26631;&#20934;&#30340;&#22270;&#21367;&#31215;&#32593;&#32476;&#65288;GCN&#65289;&#23454;&#38469;&#19978;&#22312;&#19968;&#20123;&#24120;&#29992;&#30340;&#24322;&#36136;&#24615;&#22270;&#19978;&#21487;&#20197;&#23454;&#29616;&#27604;&#36825;&#20123;&#31934;&#24515;&#35774;&#35745;&#30340;&#26041;&#27861;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#36825;&#28608;&#21169;&#25105;&#20204;&#37325;&#26032;&#24605;&#32771;&#21516;&#36136;&#24615;&#26159;&#21542;&#30495;&#27491;&#23545;&#20110;&#33391;&#22909;&#30340;GNN&#24615;&#33021;&#26159;&#24517;&#35201;&#30340;&#12290;&#25105;&#20204;&#21457;&#29616;&#36825;&#31181;&#35828;&#27861;&#24182;&#19981;&#23436;&#20840;&#27491;&#30830;&#65292;&#20107;&#23454;&#19978;&#65292;GCN&#21487;&#20197;&#22312;&#24322;&#36136;&#24615;&#22270;&#19978;&#23454;&#29616;&#24378;&#22823;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) have shown great prowess in learning representations suitable for numerous graph-based machine learning tasks. When applied to semi-supervised node classification, GNNs are widely believed to work well due to the homophily assumption ("like attracts like"), and fail to generalize to heterophilous graphs where dissimilar nodes connect. Recent works design new architectures to overcome such heterophily-related limitations, citing poor baseline performance and new architecture improvements on a few heterophilous graph benchmark datasets as evidence for this notion. In our experiments, we empirically find that standard graph convolutional networks (GCNs) can actually achieve better performance than such carefully designed methods on some commonly used heterophilous graphs. This motivates us to reconsider whether homophily is truly necessary for good GNN performance. We find that this claim is not quite true, and in fact, GCNs can achieve strong performance on h
&lt;/p&gt;</description></item></channel></rss>