<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26080;&#20284;&#28982;&#36125;&#21494;&#26031;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#26500;&#24314;&#39640;&#25928;&#30340;&#25130;&#23614;&#36229;&#38408;&#20540;&#27169;&#22411;&#20272;&#35745;&#22120;&#12290;&#35813;&#26041;&#27861;&#25361;&#25112;&#20102;&#20256;&#32479;&#30340;&#22522;&#20110;&#25130;&#23614;&#20284;&#28982;&#30340;&#31354;&#38388;&#26497;&#20540;&#25512;&#29702;&#65292;&#24182;&#22312;&#35745;&#31639;&#21644;&#32479;&#35745;&#25928;&#29575;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2306.15642</link><description>&lt;p&gt;
&#26080;&#20284;&#28982;&#31070;&#32463;&#36125;&#21494;&#26031;&#20272;&#35745;&#30340;&#25130;&#23614;&#36229;&#38408;&#20540;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Likelihood-free neural Bayes estimators for censored peaks-over-threshold models. (arXiv:2306.15642v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15642
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26080;&#20284;&#28982;&#36125;&#21494;&#26031;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#26500;&#24314;&#39640;&#25928;&#30340;&#25130;&#23614;&#36229;&#38408;&#20540;&#27169;&#22411;&#20272;&#35745;&#22120;&#12290;&#35813;&#26041;&#27861;&#25361;&#25112;&#20102;&#20256;&#32479;&#30340;&#22522;&#20110;&#25130;&#23614;&#20284;&#28982;&#30340;&#31354;&#38388;&#26497;&#20540;&#25512;&#29702;&#65292;&#24182;&#22312;&#35745;&#31639;&#21644;&#32479;&#35745;&#25928;&#29575;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#24230;&#19979;&#65292;&#23545;&#20110;&#31354;&#38388;&#26497;&#20540;&#20381;&#36182;&#27169;&#22411;&#30340;&#25512;&#29702;&#24448;&#24448;&#22240;&#20854;&#20381;&#36182;&#20110;&#38590;&#20197;&#22788;&#29702;&#30340;&#25110;&#25130;&#23614;&#30340;&#20284;&#28982;&#20989;&#25968;&#32780;&#36896;&#25104;&#35745;&#31639;&#36127;&#25285;&#12290;&#21033;&#29992;&#26368;&#36817;&#22312;&#26080;&#20284;&#28982;&#25512;&#29702;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#20013;&#32534;&#30721;&#25130;&#23614;&#20449;&#24687;&#65292;&#20026;&#25130;&#23614;&#36229;&#38408;&#20540;&#27169;&#22411;&#26500;&#24314;&#20102;&#39640;&#25928;&#30340;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#30340;&#26032;&#26041;&#27861;&#23545;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#25130;&#23614;&#20284;&#28982;&#30340;&#31354;&#38388;&#26497;&#20540;&#25512;&#29702;&#25552;&#20986;&#20102;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#27169;&#25311;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#25512;&#26029;&#27969;&#34892;&#30340;&#26497;&#20540;&#20381;&#36182;&#27169;&#22411;&#65288;&#22914;&#26368;&#22823;&#31283;&#23450;&#27169;&#22411;&#12289;r-&#24085;&#32047;&#25176;&#27169;&#22411;&#21644;&#38543;&#26426;&#27604;&#20363;&#28151;&#21512;&#36807;&#31243;&#65289;&#26102;&#65292;&#30456;&#23545;&#20110;&#31454;&#20105;&#30340;&#22522;&#20110;&#20284;&#28982;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26032;&#20272;&#35745;&#22120;&#22312;&#35745;&#31639;&#21644;&#32479;&#35745;&#25928;&#29575;&#26041;&#38754;&#25552;&#20379;&#20102;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inference for spatial extremal dependence models can be computationally burdensome in moderate-to-high dimensions due to their reliance on intractable and/or censored likelihoods. Exploiting recent advances in likelihood-free inference with neural Bayes estimators (that is, neural estimators that target Bayes estimators), we develop a novel approach to construct highly efficient estimators for censored peaks-over-threshold models by encoding censoring information in the neural network architecture. Our new method provides a paradigm shift that challenges traditional censored likelihood-based inference for spatial extremes. Our simulation studies highlight significant gains in both computational and statistical efficiency, relative to competing likelihood-based approaches, when applying our novel estimators for inference of popular extremal dependence models, such as max-stable, $r$-Pareto, and random scale mixture processes. We also illustrate that it is possible to train a single esti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;LeanDojo&#65292;&#35813;&#24037;&#20855;&#36890;&#36807;&#25552;&#21462;Lean&#30340;&#25968;&#25454;&#65292;&#20026;&#23450;&#29702;&#35777;&#26126;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#20010;&#24320;&#25918;&#28304;&#20195;&#30721;&#30340;&#24179;&#21488;&#12290;&#21033;&#29992;LeanDojo&#30340;&#25968;&#25454;&#65292;&#24320;&#21457;&#20102;ReProver&#65292;&#23427;&#26159;&#31532;&#19968;&#20010;&#20351;&#29992;&#26816;&#32034;&#22686;&#24378;&#30340;&#35821;&#35328;&#27169;&#22411;&#30340;&#35777;&#26126;&#22120;&#65292;&#21487;&#20197;&#20174;&#24222;&#22823;&#30340;&#25968;&#23398;&#24211;&#20013;&#36873;&#25321;&#21629;&#39064;&#65292;&#35757;&#32451;&#25104;&#26412;&#20302;&#65292;&#24182;&#19988;&#21482;&#38656;&#35201;&#19968;&#21608;&#30340;GPU&#35757;&#32451;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2306.15626</link><description>&lt;p&gt;
LeanDojo: &#26816;&#32034;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#30340;&#23450;&#29702;&#35777;&#26126;
&lt;/p&gt;
&lt;p&gt;
LeanDojo: Theorem Proving with Retrieval-Augmented Language Models. (arXiv:2306.15626v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15626
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;LeanDojo&#65292;&#35813;&#24037;&#20855;&#36890;&#36807;&#25552;&#21462;Lean&#30340;&#25968;&#25454;&#65292;&#20026;&#23450;&#29702;&#35777;&#26126;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#20010;&#24320;&#25918;&#28304;&#20195;&#30721;&#30340;&#24179;&#21488;&#12290;&#21033;&#29992;LeanDojo&#30340;&#25968;&#25454;&#65292;&#24320;&#21457;&#20102;ReProver&#65292;&#23427;&#26159;&#31532;&#19968;&#20010;&#20351;&#29992;&#26816;&#32034;&#22686;&#24378;&#30340;&#35821;&#35328;&#27169;&#22411;&#30340;&#35777;&#26126;&#22120;&#65292;&#21487;&#20197;&#20174;&#24222;&#22823;&#30340;&#25968;&#23398;&#24211;&#20013;&#36873;&#25321;&#21629;&#39064;&#65292;&#35757;&#32451;&#25104;&#26412;&#20302;&#65292;&#24182;&#19988;&#21482;&#38656;&#35201;&#19968;&#21608;&#30340;GPU&#35757;&#32451;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24050;&#32463;&#26174;&#31034;&#20986;&#22312;&#20351;&#29992;Lean&#31561;&#35777;&#26126;&#21161;&#25163;&#35777;&#26126;&#24418;&#24335;&#23450;&#29702;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#31169;&#26377;&#20195;&#30721;&#12289;&#25968;&#25454;&#21644;&#22823;&#37327;&#35745;&#31639;&#35201;&#27714;&#65292;&#29616;&#26377;&#30340;&#26041;&#27861;&#24456;&#38590;&#22797;&#21046;&#25110;&#24314;&#31435;&#22312;&#20854;&#22522;&#30784;&#19978;&#65292;&#36825;&#32473;&#23450;&#29702;&#35777;&#26126;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#30740;&#31350;&#24102;&#26469;&#20102;&#24040;&#22823;&#30340;&#38556;&#30861;&#12290;&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;LeanDojo&#26469;&#28040;&#38500;&#36825;&#20123;&#38556;&#30861;&#65306;&#19968;&#20010;&#21253;&#21547;&#24037;&#20855;&#21253;&#12289;&#25968;&#25454;&#12289;&#27169;&#22411;&#21644;&#22522;&#20934;&#27979;&#35797;&#30340;&#24320;&#25918;&#28304;&#20195;&#30721;&#30340;Lean&#28216;&#20048;&#22330;&#12290;LeanDojo&#20174;Lean&#20013;&#25552;&#21462;&#25968;&#25454;&#65292;&#24182;&#20351;&#24471;&#21487;&#20197;&#36890;&#36807;&#32534;&#31243;&#19982;&#35777;&#26126;&#29615;&#22659;&#36827;&#34892;&#20132;&#20114;&#12290;&#23427;&#21253;&#21547;&#35777;&#26126;&#20013;&#21629;&#39064;&#30340;&#32454;&#31890;&#24230;&#27880;&#37322;&#65292;&#20026;&#21629;&#39064;&#36873;&#25321;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#25968;&#25454;&#65306;&#36825;&#26159;&#23450;&#29702;&#35777;&#26126;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#29942;&#39048;&#12290;&#21033;&#29992;&#36825;&#20123;&#25968;&#25454;&#65292;&#25105;&#20204;&#24320;&#21457;&#20986;&#20102;ReProver&#65288;&#26816;&#32034;&#22686;&#24378;&#30340;&#35777;&#26126;&#22120;&#65289;&#65306;&#23427;&#26159;&#31532;&#19968;&#20010;&#20351;&#29992;LLM&#30340;&#35777;&#26126;&#22120;&#65292;&#36890;&#36807;&#26816;&#32034;&#20174;&#24222;&#22823;&#30340;&#25968;&#23398;&#24211;&#20013;&#36873;&#25321;&#21629;&#39064;&#12290;&#23427;&#25104;&#26412;&#20302;&#24265;&#65292;&#21482;&#38656;&#35201;&#19968;&#21608;&#30340;GPU&#35757;&#32451;&#26102;&#38388;&#12290;&#25105;&#20204;&#30340;&#26816;&#32034;&#22120;&#21033;&#29992;&#20102;LeanDojo&#30340;pro&#30456;&#20851;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have shown promise in proving formal theorems using proof assistants such as Lean. However, existing methods are difficult to reproduce or build on, due to private code, data, and large compute requirements. This has created substantial barriers to research on machine learning methods for theorem proving. This paper removes these barriers by introducing LeanDojo: an open-source Lean playground consisting of toolkits, data, models, and benchmarks. LeanDojo extracts data from Lean and enables interaction with the proof environment programmatically. It contains fine-grained annotations of premises in proofs, providing valuable data for premise selection: a key bottleneck in theorem proving. Using this data, we develop ReProver (Retrieval-Augmented Prover): the first LLM-based prover that is augmented with retrieval for selecting premises from a vast math library. It is inexpensive and needs only one GPU week of training. Our retriever leverages LeanDojo's prog
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#30697;&#38453;&#24352;&#37327;&#20056;&#31215;&#27169;&#22411;&#30340;&#36817;&#20284;&#20256;&#36882;&#28040;&#24687;&#65288;AMP&#65289;&#31639;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#20854;&#24615;&#33021;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#26435;&#34913;&#21644;&#32452;&#21512;&#22810;&#20010;&#20272;&#35745;&#26469;&#20248;&#21270;&#31639;&#27861;&#36845;&#20195;&#36807;&#31243;&#12290;&#36890;&#36807;&#23545;&#38750;&#21487;&#20998;&#20989;&#25968;&#30340;AMP&#25910;&#25947;&#23450;&#29702;&#21644;&#29366;&#24577;&#28436;&#21270;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#24674;&#22797;&#30446;&#26631;&#20449;&#21495;&#25152;&#38656;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;&#35813;&#31639;&#27861;&#36866;&#29992;&#20110;&#22810;&#31181;&#31867;&#22411;&#30340;&#20004;&#20004;&#35266;&#27979;&#12290;</title><link>http://arxiv.org/abs/2306.15580</link><description>&lt;p&gt;
&#36817;&#20284;&#20256;&#36882;&#28040;&#24687;&#22312;&#30697;&#38453;&#24352;&#37327;&#20056;&#31215;&#27169;&#22411;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Approximate Message Passing for the Matrix Tensor Product Model. (arXiv:2306.15580v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15580
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#30697;&#38453;&#24352;&#37327;&#20056;&#31215;&#27169;&#22411;&#30340;&#36817;&#20284;&#20256;&#36882;&#28040;&#24687;&#65288;AMP&#65289;&#31639;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#20854;&#24615;&#33021;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#26435;&#34913;&#21644;&#32452;&#21512;&#22810;&#20010;&#20272;&#35745;&#26469;&#20248;&#21270;&#31639;&#27861;&#36845;&#20195;&#36807;&#31243;&#12290;&#36890;&#36807;&#23545;&#38750;&#21487;&#20998;&#20989;&#25968;&#30340;AMP&#25910;&#25947;&#23450;&#29702;&#21644;&#29366;&#24577;&#28436;&#21270;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#24674;&#22797;&#30446;&#26631;&#20449;&#21495;&#25152;&#38656;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;&#35813;&#31639;&#27861;&#36866;&#29992;&#20110;&#22810;&#31181;&#31867;&#22411;&#30340;&#20004;&#20004;&#35266;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#30697;&#38453;&#24352;&#37327;&#20056;&#31215;&#27169;&#22411;&#30340;&#36817;&#20284;&#20256;&#36882;&#28040;&#24687;&#65288;AMP&#65289;&#31639;&#27861;&#65292;&#24182;&#36827;&#34892;&#20102;&#20998;&#26512;&#12290;&#35813;&#27169;&#22411;&#26159;&#26631;&#20934;&#23574;&#23792;&#30697;&#38453;&#27169;&#22411;&#30340;&#25512;&#24191;&#65292;&#20801;&#35768;&#23545;&#19968;&#32452;&#28508;&#22312;&#21464;&#37327;&#36827;&#34892;&#22810;&#31181;&#31867;&#22411;&#30340;&#20004;&#20004;&#35266;&#27979;&#12290;&#35813;&#31639;&#27861;&#30340;&#19968;&#20010;&#20851;&#38190;&#21019;&#26032;&#26159;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#36890;&#36807;&#19968;&#31181;&#26041;&#27861;&#23545;&#22810;&#20010;&#20272;&#35745;&#36827;&#34892;&#26368;&#20248;&#26435;&#37325;&#21644;&#32452;&#21512;&#12290;&#20511;&#21161;&#38750;&#21487;&#20998;&#20989;&#25968;&#30340;AMP&#25910;&#25947;&#23450;&#29702;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#38750;&#21487;&#20998;&#20989;&#25968;&#30340;&#29366;&#24577;&#28436;&#21270;&#65292;&#20174;&#32780;&#22312;&#39640;&#32500;&#26497;&#38480;&#19979;&#25552;&#20379;&#20102;&#20854;&#24615;&#33021;&#30340;&#28176;&#36817;&#31934;&#30830;&#25551;&#36848;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20010;&#29366;&#24577;&#28436;&#21270;&#32467;&#26524;&#32473;&#20986;&#20102;&#24674;&#22797;&#30446;&#26631;&#20449;&#21495;&#25152;&#38656;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;&#36825;&#20123;&#26465;&#20214;&#21462;&#20915;&#20110;&#20174;&#25105;&#20204;&#27169;&#22411;&#30340;&#36866;&#24403;&#25512;&#24191;&#20013;&#23548;&#20986;&#30340;&#32447;&#24615;&#31639;&#23376;&#30340;&#22855;&#24322;&#20540;&#65292;&#36825;&#20010;&#32447;&#24615;&#31639;&#23376;&#26159;&#19968;&#20010;&#36866;&#24403;&#25512;&#24191;&#30340;&#20449;&#22122;&#27604;&#30340;&#19968;&#20010;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20316;&#20026;&#29305;&#27530;&#24773;&#20917;&#28085;&#30422;&#20102;&#19968;&#20123;&#26368;&#36817;&#25552;&#20986;&#30340;&#32972;&#26223;&#27169;&#22411;&#26041;&#27861;&#65288;&#20363;&#22914;&#65292;covariance-&#65289;
&lt;/p&gt;
&lt;p&gt;
We propose and analyze an approximate message passing (AMP) algorithm for the matrix tensor product model, which is a generalization of the standard spiked matrix models that allows for multiple types of pairwise observations over a collection of latent variables. A key innovation for this algorithm is a method for optimally weighing and combining multiple estimates in each iteration. Building upon an AMP convergence theorem for non-separable functions, we prove a state evolution for non-separable functions that provides an asymptotically exact description of its performance in the high-dimensional limit. We leverage this state evolution result to provide necessary and sufficient conditions for recovery of the signal of interest. Such conditions depend on the singular values of a linear operator derived from an appropriate generalization of a signal-to-noise ratio for our model. Our results recover as special cases a number of recently proposed methods for contextual models (e.g., cova
&lt;/p&gt;</description></item><item><title>PyBADS&#26159;Python&#20013;&#19968;&#31181;&#24555;&#36895;&#32780;&#31283;&#20581;&#30340;&#40657;&#30418;&#20248;&#21270;&#31639;&#27861;&#65292;&#36866;&#29992;&#20110;&#35299;&#20915;&#30446;&#26631;&#20989;&#25968;&#31895;&#31961;&#12289;&#35745;&#31639;&#20195;&#20215;&#39640;&#12289;&#21487;&#33021;&#23384;&#22312;&#22122;&#22768;&#19988;&#26799;&#24230;&#20449;&#24687;&#19981;&#21487;&#29992;&#30340;&#22256;&#38590;&#20248;&#21270;&#38382;&#39064;&#12290;&#23427;&#25903;&#25345;&#39640;&#36798;20&#20010;&#36830;&#32493;&#36755;&#20837;&#21442;&#25968;&#30340;&#40657;&#30418;&#20989;&#25968;&#65292;&#24182;&#25552;&#20379;&#26131;&#20110;&#20351;&#29992;&#30340;Python&#25509;&#21475;&#12290;</title><link>http://arxiv.org/abs/2306.15576</link><description>&lt;p&gt;
PyBADS&#65306;Python&#20013;&#24555;&#36895;&#32780;&#31283;&#20581;&#30340;&#40657;&#30418;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
PyBADS: Fast and robust black-box optimization in Python. (arXiv:2306.15576v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15576
&lt;/p&gt;
&lt;p&gt;
PyBADS&#26159;Python&#20013;&#19968;&#31181;&#24555;&#36895;&#32780;&#31283;&#20581;&#30340;&#40657;&#30418;&#20248;&#21270;&#31639;&#27861;&#65292;&#36866;&#29992;&#20110;&#35299;&#20915;&#30446;&#26631;&#20989;&#25968;&#31895;&#31961;&#12289;&#35745;&#31639;&#20195;&#20215;&#39640;&#12289;&#21487;&#33021;&#23384;&#22312;&#22122;&#22768;&#19988;&#26799;&#24230;&#20449;&#24687;&#19981;&#21487;&#29992;&#30340;&#22256;&#38590;&#20248;&#21270;&#38382;&#39064;&#12290;&#23427;&#25903;&#25345;&#39640;&#36798;20&#20010;&#36830;&#32493;&#36755;&#20837;&#21442;&#25968;&#30340;&#40657;&#30418;&#20989;&#25968;&#65292;&#24182;&#25552;&#20379;&#26131;&#20110;&#20351;&#29992;&#30340;Python&#25509;&#21475;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
PyBADS&#26159;Bayesian Adaptive Direct Search&#65288;BADS&#65289;&#31639;&#27861;&#30340;Python&#23454;&#29616;&#65292;&#29992;&#20110;&#24555;&#36895;&#32780;&#31283;&#20581;&#30340;&#40657;&#30418;&#20248;&#21270;&#65288;Acerbi&#21644;Ma&#65292;2017&#65289;&#12290;BADS&#26159;&#19968;&#31181;&#38024;&#23545;&#30446;&#26631;&#20989;&#25968;&#31895;&#31961;&#65288;&#38750;&#20984;&#12289;&#38750;&#20809;&#28369;&#65289;&#12289;&#35745;&#31639;&#20195;&#20215;&#36739;&#39640;&#65288;&#20363;&#22914;&#20989;&#25968;&#35780;&#20272;&#38656;&#35201;&#36229;&#36807;0.1&#31186;&#65289;&#12289;&#21487;&#33021;&#23384;&#22312;&#22122;&#22768;&#19988;&#26799;&#24230;&#20449;&#24687;&#19981;&#21487;&#29992;&#30340;&#22256;&#38590;&#20248;&#21270;&#38382;&#39064;&#32780;&#35774;&#35745;&#30340;&#20248;&#21270;&#31639;&#27861;&#12290;&#36890;&#36807;BADS&#65292;&#36825;&#20123;&#38382;&#39064;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#35299;&#20915;&#65292;&#20351;&#20854;&#25104;&#20026;&#20351;&#29992;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#31561;&#26041;&#27861;&#25311;&#21512;&#35745;&#31639;&#27169;&#22411;&#30340;&#20248;&#31168;&#36873;&#25321;&#12290;&#35813;&#31639;&#27861;&#22312;&#20855;&#26377;&#39640;&#36798;$D \approx 20$&#20010;&#36830;&#32493;&#36755;&#20837;&#21442;&#25968;&#30340;&#40657;&#30418;&#20989;&#25968;&#19978;&#20855;&#26377;&#39640;&#25928;&#30340;&#25193;&#23637;&#24615;&#65292;&#24182;&#25903;&#25345;&#36793;&#30028;&#32422;&#26463;&#25110;&#26080;&#32422;&#26463;&#12290;PyBADS&#25552;&#20379;&#20102;&#19968;&#20010;&#26131;&#20110;&#20351;&#29992;&#30340;Python&#25509;&#21475;&#65292;&#29992;&#20110;&#36816;&#34892;&#31639;&#27861;&#21644;&#26816;&#26597;&#20854;&#32467;&#26524;&#12290;PyBADS&#21482;&#38656;&#35201;&#29992;&#25143;&#25552;&#20379;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#30446;&#26631;&#20989;&#25968;&#30340;Python&#20989;&#25968;&#65292;&#20197;&#21450;&#20854;&#20182;&#32422;&#26463;&#65288;&#21487;&#36873;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
PyBADS is a Python implementation of the Bayesian Adaptive Direct Search (BADS) algorithm for fast and robust black-box optimization (Acerbi and Ma 2017). BADS is an optimization algorithm designed to efficiently solve difficult optimization problems where the objective function is rough (non-convex, non-smooth), mildly expensive (e.g., the function evaluation requires more than 0.1 seconds), possibly noisy, and gradient information is unavailable. With BADS, these issues are well addressed, making it an excellent choice for fitting computational models using methods such as maximum-likelihood estimation. The algorithm scales efficiently to black-box functions with up to $D \approx 20$ continuous input parameters and supports bounds or no constraints. PyBADS comes along with an easy-to-use Pythonic interface for running the algorithm and inspecting its results. PyBADS only requires the user to provide a Python function for evaluating the target function, and optionally other constraint
&lt;/p&gt;</description></item><item><title>&#26377;&#38480;&#20869;&#23384;&#36138;&#23146;&#25311;&#29275;&#39039;&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#26631;&#20934;&#25311;&#29275;&#39039;&#26041;&#27861;&#35745;&#31639;&#25104;&#26412;&#21644;&#20869;&#23384;&#38656;&#27714;&#36807;&#39640;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#36824;&#26377;&#20855;&#26377;&#38750;&#28176;&#36827;&#36229;&#32447;&#24615;&#25910;&#25947;&#36895;&#29575;&#30340;&#24615;&#33021;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2306.15444</link><description>&lt;p&gt;
&#26377;&#38480;&#20869;&#23384;&#36138;&#23146;&#25311;&#29275;&#39039;&#26041;&#27861;&#19982;&#38750;&#28176;&#36827;&#36229;&#32447;&#24615;&#25910;&#25947;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Limited-Memory Greedy Quasi-Newton Method with Non-asymptotic Superlinear Convergence Rate. (arXiv:2306.15444v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15444
&lt;/p&gt;
&lt;p&gt;
&#26377;&#38480;&#20869;&#23384;&#36138;&#23146;&#25311;&#29275;&#39039;&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#26631;&#20934;&#25311;&#29275;&#39039;&#26041;&#27861;&#35745;&#31639;&#25104;&#26412;&#21644;&#20869;&#23384;&#38656;&#27714;&#36807;&#39640;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#36824;&#26377;&#20855;&#26377;&#38750;&#28176;&#36827;&#36229;&#32447;&#24615;&#25910;&#25947;&#36895;&#29575;&#30340;&#24615;&#33021;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#28176;&#36827;&#25910;&#25947;&#20998;&#26512;&#34920;&#26126;&#65292;&#25311;&#29275;&#39039;&#26041;&#27861;&#30340;&#26174;&#24335;&#36229;&#32447;&#24615;&#36895;&#29575;&#20026;O$((1/\sqrt{t})^t)$&#12290;&#28982;&#32780;&#65292;&#33719;&#24471;&#36825;&#19968;&#36895;&#29575;&#30340;&#26041;&#27861;&#23384;&#22312;&#19968;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#32570;&#28857;&#65306;&#23427;&#20204;&#38656;&#35201;&#23384;&#20648;&#20808;&#21069;&#30340;&#40657;&#22622;&#36817;&#20284;&#30697;&#38453;&#65292;&#25110;&#32773;&#23384;&#20648;&#25152;&#26377;&#36807;&#21435;&#30340;&#26354;&#29575;&#20449;&#24687;&#20197;&#24418;&#25104;&#24403;&#21069;&#30340;&#40657;&#22622;&#36870;&#36817;&#20284;&#12290;&#26377;&#38480;&#20869;&#23384;&#30340;&#25311;&#29275;&#39039;&#26041;&#27861;&#65288;&#22914;&#33879;&#21517;&#30340;L-BFGS&#65289;&#36890;&#36807;&#21033;&#29992;&#26377;&#38480;&#31383;&#21475;&#30340;&#36807;&#21435;&#26354;&#29575;&#20449;&#24687;&#26469;&#26500;&#36896;&#40657;&#22622;&#36870;&#36817;&#20284;&#65292;&#20174;&#32780;&#32531;&#35299;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;&#22240;&#27492;&#65292;&#23427;&#20204;&#30340;&#27599;&#27425;&#36845;&#20195;&#22797;&#26434;&#24230;&#21644;&#23384;&#20648;&#38656;&#27714;&#20026;O$(\tau d)$&#65292;&#20854;&#20013;$\tau \le d$ &#26159;&#31383;&#21475;&#30340;&#22823;&#23567;&#65292;$d$ &#26159;&#38382;&#39064;&#30340;&#32500;&#25968;&#65292;&#20174;&#32780;&#38477;&#20302;&#20102;&#26631;&#20934;&#25311;&#29275;&#39039;&#26041;&#27861;&#30340;O$(d^2)$ &#35745;&#31639;&#25104;&#26412;&#21644;&#20869;&#23384;&#38656;&#27714;&#12290;&#28982;&#32780;&#65292;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#27809;&#26377;&#32467;&#26524;&#34920;&#26126;&#26377;&#38480;&#20869;&#23384;&#25311;&#29275;&#39039;&#26041;&#27861;&#23384;&#22312;&#38750;&#28176;&#36827;&#36229;&#32447;&#24615;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Non-asymptotic convergence analysis of quasi-Newton methods has gained attention with a landmark result establishing an explicit superlinear rate of O$((1/\sqrt{t})^t)$. The methods that obtain this rate, however, exhibit a well-known drawback: they require the storage of the previous Hessian approximation matrix or instead storing all past curvature information to form the current Hessian inverse approximation. Limited-memory variants of quasi-Newton methods such as the celebrated L-BFGS alleviate this issue by leveraging a limited window of past curvature information to construct the Hessian inverse approximation. As a result, their per iteration complexity and storage requirement is O$(\tau d)$ where $\tau \le d$ is the size of the window and $d$ is the problem dimension reducing the O$(d^2)$ computational cost and memory requirement of standard quasi-Newton methods. However, to the best of our knowledge, there is no result showing a non-asymptotic superlinear convergence rate for a
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#27169;&#25311;&#21453;&#20107;&#23454;&#20998;&#24067;&#20013;&#30340;&#20540;&#65292;&#21487;&#23545;&#31163;&#25955;&#21644;&#36830;&#32493;&#21464;&#37327;&#35774;&#23450;&#26465;&#20214;&#65292;&#24182;&#24212;&#29992;&#20110;&#20449;&#29992;&#35780;&#20998;&#20013;&#30340;&#20844;&#24179;&#24615;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2306.15328</link><description>&lt;p&gt;
&#27169;&#25311;&#21453;&#20107;&#23454;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
Simulating counterfactuals. (arXiv:2306.15328v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15328
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#27169;&#25311;&#21453;&#20107;&#23454;&#20998;&#24067;&#20013;&#30340;&#20540;&#65292;&#21487;&#23545;&#31163;&#25955;&#21644;&#36830;&#32493;&#21464;&#37327;&#35774;&#23450;&#26465;&#20214;&#65292;&#24182;&#24212;&#29992;&#20110;&#20449;&#29992;&#35780;&#20998;&#20013;&#30340;&#20844;&#24179;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#25512;&#26029;&#32771;&#34385;&#20102;&#22312;&#19982;&#23454;&#38469;&#19990;&#30028;&#23384;&#22312;&#19968;&#20123;&#35777;&#25454;&#30340;&#24179;&#34892;&#19990;&#30028;&#20013;&#36827;&#34892;&#30340;&#20551;&#35774;&#24615;&#24178;&#39044;&#12290;&#22914;&#26524;&#35777;&#25454;&#22312;&#27969;&#24418;&#19978;&#25351;&#23450;&#20102;&#26465;&#20214;&#20998;&#24067;&#65292;&#21453;&#20107;&#23454;&#21487;&#33021;&#26159;&#35299;&#26512;&#38590;&#35299;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#21453;&#20107;&#23454;&#20998;&#24067;&#20013;&#27169;&#25311;&#20540;&#65292;&#20854;&#20013;&#21487;&#20197;&#23545;&#31163;&#25955;&#21644;&#36830;&#32493;&#21464;&#37327;&#35774;&#23450;&#26465;&#20214;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#21487;&#20197;&#34987;&#21576;&#29616;&#20026;&#31890;&#23376;&#28388;&#27874;&#22120;&#65292;&#20174;&#32780;&#23548;&#33268;&#28176;&#36817;&#26377;&#25928;&#30340;&#25512;&#26029;&#12290;&#35813;&#31639;&#27861;&#34987;&#24212;&#29992;&#20110;&#20449;&#29992;&#35780;&#20998;&#20013;&#30340;&#20844;&#24179;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactual inference considers a hypothetical intervention in a parallel world that shares some evidence with the factual world. If the evidence specifies a conditional distribution on a manifold, counterfactuals may be analytically intractable. We present an algorithm for simulating values from a counterfactual distribution where conditions can be set on both discrete and continuous variables. We show that the proposed algorithm can be presented as a particle filter leading to asymptotically valid inference. The algorithm is applied to fairness analysis in credit scoring.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#36864;&#28779;&#37325;&#35201;&#24615;&#37319;&#26679;&#31639;&#27861;&#65292;&#36890;&#36807;&#25512;&#23548;&#20986;&#24658;&#23450;&#36895;&#29575;&#31163;&#25955;&#21270;&#36827;&#23637;&#35745;&#21010;&#65292;&#23454;&#29616;&#20102;&#22312;&#36864;&#28779;&#36807;&#31243;&#20013;&#26679;&#26412;&#22312;&#21508;&#20010;&#20998;&#24067;&#20043;&#38388;&#30340;&#33258;&#36866;&#24212;&#31227;&#21160;&#65292;&#20174;&#32780;&#25552;&#21319;&#20102;&#37319;&#26679;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.15283</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#36864;&#28779;&#37325;&#35201;&#24615;&#37319;&#26679;&#19982;&#24658;&#23450;&#36895;&#29575;&#36827;&#23637;
&lt;/p&gt;
&lt;p&gt;
Adaptive Annealed Importance Sampling with Constant Rate Progress. (arXiv:2306.15283v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15283
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#36864;&#28779;&#37325;&#35201;&#24615;&#37319;&#26679;&#31639;&#27861;&#65292;&#36890;&#36807;&#25512;&#23548;&#20986;&#24658;&#23450;&#36895;&#29575;&#31163;&#25955;&#21270;&#36827;&#23637;&#35745;&#21010;&#65292;&#23454;&#29616;&#20102;&#22312;&#36864;&#28779;&#36807;&#31243;&#20013;&#26679;&#26412;&#22312;&#21508;&#20010;&#20998;&#24067;&#20043;&#38388;&#30340;&#33258;&#36866;&#24212;&#31227;&#21160;&#65292;&#20174;&#32780;&#25552;&#21319;&#20102;&#37319;&#26679;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36864;&#28779;&#37325;&#35201;&#24615;&#37319;&#26679;(AIS)&#33021;&#22815;&#22312;&#32473;&#23450;&#38590;&#20197;&#35745;&#31639;&#30340;&#27010;&#29575;&#20998;&#24067;&#30340;&#38750;&#35268;&#33539;&#21270;&#23494;&#24230;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#21512;&#25104;&#21152;&#26435;&#26679;&#26412;&#12290;&#35813;&#31639;&#27861;&#20381;&#36182;&#20110;&#19968;&#31995;&#21015;&#25554;&#20540;&#20998;&#24067;&#65292;&#23558;&#30446;&#26631;&#20998;&#24067;&#19982;&#21021;&#22987;&#26131;&#20110;&#35745;&#31639;&#30340;&#20998;&#24067;&#36827;&#34892;&#34900;&#25509;&#65292;&#20854;&#20013;&#33879;&#21517;&#30340;&#20960;&#20309;&#24179;&#22343;&#36335;&#24452;&#34987;&#35748;&#20026;&#36890;&#24120;&#26159;&#27425;&#20248;&#30340;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;&#20960;&#20309;&#36864;&#28779;&#26159;&#24403;&#21069;&#31890;&#23376;&#20998;&#24067;&#19982;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;KL&#25955;&#24230;&#26368;&#23567;&#30340;&#36335;&#24452;&#12290;&#25105;&#20204;&#22522;&#20110;&#36825;&#19968;&#35266;&#23519;&#65292;&#25512;&#23548;&#20986;&#20102;&#36825;&#19968;&#36864;&#28779;&#24207;&#21015;&#30340;&#24658;&#23450;&#36895;&#29575;&#31163;&#25955;&#21270;&#36827;&#23637;&#35745;&#21010;&#65292;&#26681;&#25454;&#26679;&#26412;&#22312;&#21021;&#22987;&#21644;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#31227;&#21160;&#30340;&#38590;&#24230;&#35843;&#25972;&#36827;&#23637;&#35745;&#21010;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;&#32467;&#26524;&#25512;&#24191;&#33267;f-&#25955;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#36864;&#28779;&#24207;&#21015;&#21160;&#21147;&#23398;&#12290;
&lt;/p&gt;
&lt;p&gt;
Annealed Importance Sampling (AIS) synthesizes weighted samples from an intractable distribution given its unnormalized density function. This algorithm relies on a sequence of interpolating distributions bridging the target to an initial tractable distribution such as the well-known geometric mean path of unnormalized distributions which is assumed to be suboptimal in general. In this paper, we prove that the geometric annealing corresponds to the distribution path that minimizes the KL divergence between the current particle distribution and the desired target when the feasible change in the particle distribution is constrained. Following this observation, we derive the constant rate discretization schedule for this annealing sequence, which adjusts the schedule to the difficulty of moving samples between the initial and the target distributions. We further extend our results to $f$-divergences and present the respective dynamics of annealing sequences based on which we propose the C
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21464;&#20998;&#28508;&#22312;&#31163;&#25955;&#34920;&#31034;&#27169;&#22411;&#65292;&#20854;&#20013;&#31163;&#25955;&#29366;&#24577;&#37319;&#29992;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#24182;&#22312;&#24314;&#31569;&#31649;&#29702;&#25968;&#25454;&#38598;&#21644;&#30005;&#21147;&#21464;&#21387;&#22120;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24615;&#33021;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2306.15282</link><description>&lt;p&gt;
&#21464;&#20998;&#28508;&#22312;&#31163;&#25955;&#34920;&#31034;&#22312;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Variational Latent Discrete Representation for Time Series Modelling. (arXiv:2306.15282v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15282
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21464;&#20998;&#28508;&#22312;&#31163;&#25955;&#34920;&#31034;&#27169;&#22411;&#65292;&#20854;&#20013;&#31163;&#25955;&#29366;&#24577;&#37319;&#29992;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#24182;&#22312;&#24314;&#31569;&#31649;&#29702;&#25968;&#25454;&#38598;&#21644;&#30005;&#21147;&#21464;&#21387;&#22120;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24615;&#33021;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#27169;&#22411;&#22312;&#28145;&#24230;&#21464;&#20998;&#25512;&#26029;&#20013;&#30340;&#24615;&#33021;&#19982;&#20854;&#36830;&#32493;&#23545;&#24212;&#29289;&#30456;&#23218;&#32654;&#12290;&#34429;&#28982;&#23427;&#20204;&#20173;&#28982;&#38754;&#20020;&#21508;&#31181;&#23454;&#29616;&#25361;&#25112;&#65292;&#20294;&#36825;&#20123;&#27169;&#22411;&#20026;&#28508;&#22312;&#31354;&#38388;&#30340;&#26356;&#22909;&#35299;&#37322;&#25552;&#20379;&#20102;&#26426;&#20250;&#65292;&#21516;&#26102;&#26356;&#30452;&#25509;&#22320;&#34920;&#31034;&#33258;&#28982;&#31163;&#25955;&#29616;&#35937;&#12290;&#26368;&#36817;&#30340;&#19968;&#20123;&#26041;&#27861;&#24314;&#35758;&#20998;&#21035;&#22312;&#31163;&#25955;&#28508;&#22312;&#25968;&#25454;&#19978;&#35757;&#32451;&#38750;&#24120;&#39640;&#32500;&#30340;&#20808;&#39564;&#27169;&#22411;&#65292;&#36825;&#26412;&#36523;&#23601;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#28508;&#22312;&#25968;&#25454;&#27169;&#22411;&#65292;&#20854;&#20013;&#31163;&#25955;&#29366;&#24577;&#26159;&#19968;&#20010;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#23427;&#20801;&#35768;&#24555;&#36895;&#31471;&#21040;&#31471;&#35757;&#32451;&#12290;&#25105;&#20204;&#23545;&#25105;&#20204;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#24314;&#31569;&#31649;&#29702;&#25968;&#25454;&#38598;&#21644;&#20844;&#24320;&#21487;&#29992;&#30340;&#30005;&#21147;&#21464;&#21387;&#22120;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24615;&#33021;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Discrete latent space models have recently achieved performance on par with their continuous counterparts in deep variational inference. While they still face various implementation challenges, these models offer the opportunity for a better interpretation of latent spaces, as well as a more direct representation of naturally discrete phenomena. Most recent approaches propose to train separately very high-dimensional prior models on the discrete latent data which is a challenging task on its own. In this paper, we introduce a latent data model where the discrete state is a Markov chain, which allows fast end-to-end training. The performance of our generative model is assessed on a building management dataset and on the publicly available Electricity Transformer Dataset.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20379;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#21033;&#29992;&#25512;&#29702;&#32467;&#26500;&#22312;&#31070;&#32463;&#36807;&#31243;&#20013;&#36827;&#34892;&#25193;&#23637;&#12290;&#25105;&#20204;&#20026;NPs&#30340;&#28508;&#21464;&#37327;&#25552;&#20379;&#20102;&#20016;&#23500;&#30340;&#20808;&#39564;&#65292;&#24182;&#25552;&#20986;&#20102;&#36866;&#24403;&#30340;&#19978;&#19979;&#25991;&#38598;&#32858;&#21512;&#31574;&#30053;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25551;&#36848;&#20102;&#19968;&#31181;&#28040;&#24687;&#20256;&#36882;&#36807;&#31243;&#65292;&#21487;&#20197;&#36827;&#34892;&#31471;&#21040;&#31471;&#20248;&#21270;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#28151;&#21512;&#21644;&#23398;&#29983;-t&#20551;&#35774;&#25913;&#21892;&#20102;&#20989;&#25968;&#24314;&#27169;&#21644;&#27979;&#35797;&#26102;&#38388;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.15169</link><description>&lt;p&gt;
&#21033;&#29992;&#25512;&#29702;&#32467;&#26500;&#22312;&#31070;&#32463;&#36807;&#31243;&#20013;&#36827;&#34892;&#25193;&#23637;
&lt;/p&gt;
&lt;p&gt;
Exploiting Inferential Structure in Neural Processes. (arXiv:2306.15169v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15169
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20379;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#21033;&#29992;&#25512;&#29702;&#32467;&#26500;&#22312;&#31070;&#32463;&#36807;&#31243;&#20013;&#36827;&#34892;&#25193;&#23637;&#12290;&#25105;&#20204;&#20026;NPs&#30340;&#28508;&#21464;&#37327;&#25552;&#20379;&#20102;&#20016;&#23500;&#30340;&#20808;&#39564;&#65292;&#24182;&#25552;&#20986;&#20102;&#36866;&#24403;&#30340;&#19978;&#19979;&#25991;&#38598;&#32858;&#21512;&#31574;&#30053;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25551;&#36848;&#20102;&#19968;&#31181;&#28040;&#24687;&#20256;&#36882;&#36807;&#31243;&#65292;&#21487;&#20197;&#36827;&#34892;&#31471;&#21040;&#31471;&#20248;&#21270;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#28151;&#21512;&#21644;&#23398;&#29983;-t&#20551;&#35774;&#25913;&#21892;&#20102;&#20989;&#25968;&#24314;&#27169;&#21644;&#27979;&#35797;&#26102;&#38388;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#36807;&#31243;(NPs)&#30001;&#20110;&#20854;&#33021;&#22815;&#22522;&#20110;&#19978;&#19979;&#25991;&#38598;&#25191;&#34892;&#24555;&#36895;&#36866;&#24212;&#32780;&#20855;&#26377;&#21560;&#24341;&#21147;&#12290;&#36825;&#20010;&#38598;&#21512;&#30001;&#19968;&#20010;&#28508;&#21464;&#37327;&#32534;&#30721;&#65292;&#36890;&#24120;&#20551;&#35774;&#35813;&#21464;&#37327;&#36981;&#24490;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#24067;&#12290;&#28982;&#32780;&#65292;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#24773;&#20917;&#19979;&#65292;&#19978;&#19979;&#25991;&#38598;&#21487;&#33021;&#26469;&#33258;&#20855;&#26377;&#22810;&#20010;&#27169;&#24335;&#12289;&#37325;&#23614;&#31561;&#20016;&#23500;&#20998;&#24067;&#30340;&#25277;&#26679;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#20801;&#35768;&#32473;&#20104;NPs&#28508;&#21464;&#37327;&#19968;&#20010;&#30001;&#22270;&#27169;&#22411;&#23450;&#20041;&#30340;&#20016;&#23500;&#20808;&#39564;&#12290;&#36825;&#20123;&#20998;&#24067;&#20551;&#35774;&#30452;&#25509;&#36716;&#21270;&#20026;&#36866;&#21512;&#19978;&#19979;&#25991;&#38598;&#30340;&#36866;&#24403;&#32858;&#21512;&#31574;&#30053;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#31181;&#28040;&#24687;&#20256;&#36882;&#36807;&#31243;&#65292;&#20173;&#28982;&#21487;&#20197;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#36827;&#34892;&#31471;&#21040;&#31471;&#20248;&#21270;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#28151;&#21512;&#21644;&#23398;&#29983;-t&#20551;&#35774;&#26469;&#35777;&#26126;&#25105;&#20204;&#26694;&#26550;&#30340;&#26222;&#36866;&#24615;&#65292;&#20174;&#32780;&#25913;&#21892;&#20102;&#20989;&#25968;&#24314;&#27169;&#21644;&#27979;&#35797;&#26102;&#38388;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural Processes (NPs) are appealing due to their ability to perform fast adaptation based on a context set. This set is encoded by a latent variable, which is often assumed to follow a simple distribution. However, in real-word settings, the context set may be drawn from richer distributions having multiple modes, heavy tails, etc. In this work, we provide a framework that allows NPs' latent variable to be given a rich prior defined by a graphical model. These distributional assumptions directly translate into an appropriate aggregation strategy for the context set. Moreover, we describe a message-passing procedure that still allows for end-to-end optimization with stochastic gradients. We demonstrate the generality of our framework by using mixture and Student-t assumptions that yield improvements in function modelling and test-time robustness.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#19968;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#21644;&#26465;&#20214;&#20998;&#24067;&#23398;&#20064;&#26041;&#27861;&#65292;&#20351;&#29992;&#29983;&#25104;&#23398;&#20064;&#26694;&#26550;&#21516;&#26102;&#20272;&#35745;&#22238;&#24402;&#20989;&#25968;&#21644;&#26465;&#20214;&#29983;&#25104;&#22120;&#65292;&#24182;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#24314;&#27169;&#26465;&#20214;&#29983;&#25104;&#22120;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#22788;&#29702;&#20855;&#26377;&#22810;&#20803;&#36755;&#20986;&#21644;&#21327;&#21464;&#37327;&#30340;&#38382;&#39064;&#65292;&#21487;&#20197;&#26500;&#24314;&#39044;&#27979;&#21306;&#38388;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#20445;&#35777;&#21644;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.15163</link><description>&lt;p&gt;
Wasserstein&#29983;&#25104;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Wasserstein Generative Regression. (arXiv:2306.15163v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15163
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#19968;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#21644;&#26465;&#20214;&#20998;&#24067;&#23398;&#20064;&#26041;&#27861;&#65292;&#20351;&#29992;&#29983;&#25104;&#23398;&#20064;&#26694;&#26550;&#21516;&#26102;&#20272;&#35745;&#22238;&#24402;&#20989;&#25968;&#21644;&#26465;&#20214;&#29983;&#25104;&#22120;&#65292;&#24182;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#24314;&#27169;&#26465;&#20214;&#29983;&#25104;&#22120;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#22788;&#29702;&#20855;&#26377;&#22810;&#20803;&#36755;&#20986;&#21644;&#21327;&#21464;&#37327;&#30340;&#38382;&#39064;&#65292;&#21487;&#20197;&#26500;&#24314;&#39044;&#27979;&#21306;&#38388;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#20445;&#35777;&#21644;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#19968;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#21644;&#26465;&#20214;&#20998;&#24067;&#23398;&#20064;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21516;&#26102;&#20272;&#35745;&#22238;&#24402;&#20989;&#25968;&#21644;&#26465;&#20214;&#29983;&#25104;&#22120;&#65292;&#20351;&#29992;&#29983;&#25104;&#23398;&#20064;&#26694;&#26550;&#65292;&#20854;&#20013;&#26465;&#20214;&#29983;&#25104;&#22120;&#26159;&#19968;&#20010;&#21487;&#20197;&#20174;&#26465;&#20214;&#20998;&#24067;&#29983;&#25104;&#26679;&#26412;&#30340;&#20989;&#25968;&#12290;&#20027;&#35201;&#24605;&#24819;&#26159;&#20272;&#35745;&#19968;&#20010;&#28385;&#36275;&#20135;&#29983;&#33391;&#22909;&#22238;&#24402;&#20989;&#25968;&#20272;&#35745;&#30340;&#32422;&#26463;&#26465;&#20214;&#30340;&#26465;&#20214;&#29983;&#25104;&#22120;&#12290;&#25105;&#20204;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26469;&#24314;&#27169;&#26465;&#20214;&#29983;&#25104;&#22120;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#22788;&#29702;&#20855;&#26377;&#22810;&#20803;&#36755;&#20986;&#21644;&#21327;&#21464;&#37327;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#21487;&#20197;&#29992;&#26469;&#26500;&#24314;&#39044;&#27979;&#21306;&#38388;&#12290;&#25105;&#20204;&#36890;&#36807;&#24471;&#20986;&#38750;&#28176;&#36817;&#35823;&#24046;&#30028;&#21644;&#22312;&#36866;&#24403;&#30340;&#20551;&#35774;&#19979;&#25105;&#20204;&#26041;&#27861;&#30340;&#20998;&#24067;&#19968;&#33268;&#24615;&#26469;&#25552;&#20379;&#29702;&#35770;&#20445;&#35777;&#12290;&#25105;&#20204;&#36824;&#20351;&#29992;&#27169;&#25311;&#21644;&#23454;&#38469;&#25968;&#25454;&#36827;&#34892;&#25968;&#20540;&#23454;&#39564;&#65292;&#20197;&#23637;&#31034;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26576;&#20123;&#29616;&#26377;&#26041;&#27861;&#19978;&#30340;&#26377;&#25928;&#24615;&#21644;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a new and unified approach for nonparametric regression and conditional distribution learning. Our approach simultaneously estimates a regression function and a conditional generator using a generative learning framework, where a conditional generator is a function that can generate samples from a conditional distribution. The main idea is to estimate a conditional generator that satisfies the constraint that it produces a good regression function estimator. We use deep neural networks to model the conditional generator. Our approach can handle problems with multivariate outcomes and covariates, and can be used to construct prediction intervals. We provide theoretical guarantees by deriving non-asymptotic error bounds and the distributional consistency of our approach under suitable assumptions. We also perform numerical experiments with simulated and real data to demonstrate the effectiveness and superiority of our approach over some existing approaches in va
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#35780;&#20272;&#20102;&#22810;&#31181;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#22312;&#22797;&#26434;&#21160;&#24577;&#31995;&#32479;&#30340;UQ&#20013;&#30340;&#20934;&#30830;&#24615;&#65292;&#20026;&#38477;&#20302;&#35757;&#32451;&#25968;&#25454;&#38598;&#35268;&#27169;&#21644;&#23433;&#20840;&#22240;&#23376;&#25552;&#20379;&#20102;&#25104;&#26412;&#33410;&#32422;&#30340;&#26426;&#20250;&#12290;</title><link>http://arxiv.org/abs/2306.15159</link><description>&lt;p&gt;
&#22312;&#22797;&#26434;&#21160;&#24577;&#31995;&#32479;&#30340;UQ&#20013;&#35780;&#20272;&#26426;&#22120;&#23398;&#20064;&#26550;&#26500;&#23545;&#20851;&#20110;&#35748;&#30693;&#21644;&#27979;&#35797;&#35823;&#24046;&#30340;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Evaluation of machine learning architectures on the quantification of epistemic and aleatoric uncertainties in complex dynamical systems. (arXiv:2306.15159v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15159
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#35780;&#20272;&#20102;&#22810;&#31181;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#22312;&#22797;&#26434;&#21160;&#24577;&#31995;&#32479;&#30340;UQ&#20013;&#30340;&#20934;&#30830;&#24615;&#65292;&#20026;&#38477;&#20302;&#35757;&#32451;&#25968;&#25454;&#38598;&#35268;&#27169;&#21644;&#23433;&#20840;&#22240;&#23376;&#25552;&#20379;&#20102;&#25104;&#26412;&#33410;&#32422;&#30340;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#29992;&#20110;&#26500;&#24314;&#25968;&#25454;&#39537;&#21160;&#30340;&#38477;&#38454;&#27169;&#22411;&#65292;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#24037;&#31243;&#39046;&#22495;&#65292;&#29305;&#21035;&#26159;&#20316;&#20026;&#26114;&#36149;&#35745;&#31639;&#27969;&#20307;&#21147;&#23398;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#23545;&#20110;&#27169;&#22411;&#21487;&#38752;&#24615;&#30340;&#37325;&#35201;&#26816;&#39564;&#26159;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65288;UQ&#65289;&#65292;&#23427;&#26159;&#23545;&#27169;&#22411;&#35823;&#24046;&#30340;&#33258;&#25105;&#35780;&#20272;&#12290;&#20934;&#30830;&#30340;UQ&#21487;&#20197;&#36890;&#36807;&#20943;&#23569;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#35268;&#27169;&#21644;&#23433;&#20840;&#22240;&#23376;&#26469;&#23454;&#29616;&#25104;&#26412;&#33410;&#32422;&#65292;&#32780;&#36739;&#24046;&#30340;UQ&#21017;&#20250;&#38459;&#30861;&#29992;&#25143;&#23545;&#27169;&#22411;&#39044;&#27979;&#30340;&#20449;&#20219;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20960;&#31181;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#65292;&#21253;&#25324;&#39640;&#26031;&#36807;&#31243;&#21644;&#19968;&#31995;&#21015;&#22686;&#24378;UQ&#30340;&#31070;&#32463;&#32593;&#32476;&#65306;&#38598;&#25104;&#31070;&#32463;&#32593;&#32476;&#65288;ENN&#65289;&#12289;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNN&#65289;&#12289;Dropout&#31070;&#32463;&#32593;&#32476;&#65288;D-NN&#65289;&#21644;&#39640;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;G-NN&#65289;&#12290;&#25105;&#20204;&#20351;&#29992;&#20004;&#20010;&#25351;&#26631;&#26469;&#35780;&#20272;UQ&#20934;&#30830;&#24615;&#65288;&#19982;&#27169;&#22411;&#20934;&#30830;&#24615;&#19981;&#21516;&#65289;&#65306;&#39564;&#35777;&#25968;&#25454;&#19978;&#24402;&#19968;&#21270;&#27531;&#24046;&#30340;&#20998;&#24067;&#21644;&#20272;&#35745;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning methods for the construction of data-driven reduced order model models are used in an increasing variety of engineering domains, especially as a supplement to expensive computational fluid dynamics for design problems. An important check on the reliability of surrogate models is Uncertainty Quantification (UQ), a self assessed estimate of the model error. Accurate UQ allows for cost savings by reducing both the required size of training data sets and the required safety factors, while poor UQ prevents users from confidently relying on model predictions. We examine several machine learning techniques, including both Gaussian processes and a family UQ-augmented neural networks: Ensemble neural networks (ENN), Bayesian neural networks (BNN), Dropout neural networks (D-NN), and Gaussian neural networks (G-NN). We evaluate UQ accuracy (distinct from model accuracy) using two metrics: the distribution of normalized residuals on validation data, and the distribution of estima
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#26041;&#27861;Adaptive IPS (AIPS)&#65292;&#38024;&#23545;&#25490;&#21517;&#31574;&#30053;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#36890;&#36807;&#32771;&#34385;&#29992;&#25143;&#34892;&#20026;&#30340;&#22810;&#26679;&#24615;&#21644;&#19978;&#19979;&#25991;&#30340;&#21464;&#21270;&#65292;&#26377;&#25928;&#38477;&#20302;&#20102;&#20272;&#35745;&#20013;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#12290;</title><link>http://arxiv.org/abs/2306.15098</link><description>&lt;p&gt;
&#19981;&#21516;&#29992;&#25143;&#34892;&#20026;&#19979;&#30340;&#25490;&#21517;&#31574;&#30053;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Off-Policy Evaluation of Ranking Policies under Diverse User Behavior. (arXiv:2306.15098v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15098
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#26041;&#27861;Adaptive IPS (AIPS)&#65292;&#38024;&#23545;&#25490;&#21517;&#31574;&#30053;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#36890;&#36807;&#32771;&#34385;&#29992;&#25143;&#34892;&#20026;&#30340;&#22810;&#26679;&#24615;&#21644;&#19978;&#19979;&#25991;&#30340;&#21464;&#21270;&#65292;&#26377;&#25928;&#38477;&#20302;&#20102;&#20272;&#35745;&#20013;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#24179;&#21488;&#19978;&#21040;&#22788;&#37117;&#26159;&#25490;&#21517;&#30028;&#38754;&#12290;&#22240;&#27492;&#65292;&#23545;&#20110;&#20351;&#29992;&#35760;&#24405;&#25968;&#25454;&#36827;&#34892;&#25490;&#21517;&#31574;&#30053;&#30340;&#20934;&#30830;&#24615;&#33021;&#35780;&#20272;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#65288;OPE&#65289;&#36234;&#26469;&#36234;&#24863;&#20852;&#36259;&#12290;OPE&#30340;&#19968;&#31181;&#20107;&#23454;&#19978;&#30340;&#26041;&#27861;&#26159;&#20498;&#25968;&#20542;&#21521;&#24471;&#20998;&#27861;&#65288;IPS&#65289;&#65292;&#23427;&#25552;&#20379;&#20102;&#19968;&#20010;&#26080;&#20559;&#19988;&#19968;&#33268;&#30340;&#20540;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#22312;&#25490;&#21517;&#35774;&#32622;&#20013;&#65292;&#30001;&#20110;&#22312;&#22823;&#22411;&#34892;&#20026;&#31354;&#38388;&#19979;&#20855;&#26377;&#36739;&#39640;&#30340;&#26041;&#24046;&#65292;&#23427;&#21464;&#24471;&#26497;&#20854;&#19981;&#20934;&#30830;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#20551;&#35774;&#29992;&#25143;&#34892;&#20026;&#26159;&#29420;&#31435;&#30340;&#25110;&#32423;&#32852;&#30340;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#19968;&#20123;IPS&#30340;&#25490;&#21517;&#29256;&#26412;&#12290;&#23613;&#31649;&#36825;&#20123;&#20272;&#35745;&#22120;&#22312;&#20943;&#23569;&#26041;&#24046;&#26041;&#38754;&#26377;&#19968;&#23450;&#30340;&#25928;&#26524;&#65292;&#20294;&#25152;&#26377;&#29616;&#26377;&#30340;&#20272;&#35745;&#22120;&#37117;&#23545;&#27599;&#20010;&#29992;&#25143;&#24212;&#29992;&#20102;&#19968;&#20010;&#21333;&#19968;&#30340;&#36890;&#29992;&#20551;&#35774;&#65292;&#23548;&#33268;&#36807;&#24230;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#12290;&#22240;&#27492;&#65292;&#36825;&#39033;&#24037;&#20316;&#25506;&#32034;&#20102;&#26356;&#36890;&#29992;&#30340;&#20844;&#24335;&#65292;&#20854;&#20013;&#29992;&#25143;&#34892;&#20026;&#26159;&#22810;&#26679;&#30340;&#65292;&#24182;&#19988;&#21487;&#20197;&#26681;&#25454;&#29992;&#25143;&#19978;&#19979;&#25991;&#30340;&#19981;&#21516;&#32780;&#21464;&#21270;&#12290;&#25105;&#20204;&#23637;&#31034;&#20986;&#30001;&#27492;&#20135;&#29983;&#30340;&#20272;&#35745;&#22120;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#33258;&#36866;&#24212;IPS&#65288;AIPS&#65289;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#36827;&#34892;&#31163;&#31574;&#30053;&#35780;&#20272;&#21644;&#25490;&#21517;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ranking interfaces are everywhere in online platforms. There is thus an ever growing interest in their Off-Policy Evaluation (OPE), aiming towards an accurate performance evaluation of ranking policies using logged data. A de-facto approach for OPE is Inverse Propensity Scoring (IPS), which provides an unbiased and consistent value estimate. However, it becomes extremely inaccurate in the ranking setup due to its high variance under large action spaces. To deal with this problem, previous studies assume either independent or cascade user behavior, resulting in some ranking versions of IPS. While these estimators are somewhat effective in reducing the variance, all existing estimators apply a single universal assumption to every user, causing excessive bias and variance. Therefore, this work explores a far more general formulation where user behavior is diverse and can vary depending on the user context. We show that the resulting estimator, which we call Adaptive IPS (AIPS), can be unb
&lt;/p&gt;</description></item><item><title>BatchGFN&#26159;&#19968;&#31181;&#29992;&#20110;&#25209;&#37327;&#20027;&#21160;&#23398;&#20064;&#30340;&#26032;&#39062;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#29983;&#25104;&#27969;&#32593;&#32476;&#26681;&#25454;&#25209;&#37327;&#22870;&#21169;&#37319;&#26679;&#25968;&#25454;&#28857;&#38598;&#21512;&#65292;&#33021;&#22815;&#20197;&#21407;&#21017;&#24615;&#30340;&#26041;&#24335;&#26500;&#24314;&#39640;&#24230;&#20449;&#24687;&#37327;&#30340;&#25209;&#37327;&#65292;&#29992;&#20110;&#20027;&#21160;&#23398;&#20064;&#12290;&#36890;&#36807;&#22312;&#25512;&#29702;&#26102;&#38388;&#20869;&#36827;&#34892;&#21333;&#27425;&#21069;&#21521;&#20256;&#36882;&#26469;&#37319;&#26679;&#36817;&#20046;&#26368;&#20248;&#25928;&#29992;&#30340;&#25209;&#37327;&#65292;&#20943;&#36731;&#20102;&#38754;&#21521;&#25209;&#37327;&#30340;&#31639;&#27861;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#65292;&#24182;&#28040;&#38500;&#20102;&#36138;&#23146;&#36817;&#20284;&#30340;&#38656;&#27714;&#12290;&#25552;&#20986;&#20102;&#36328;&#33719;&#21462;&#27493;&#39588;&#20998;&#25674;&#35757;&#32451;&#30340;&#26089;&#26399;&#32467;&#26524;&#65292;&#23454;&#29616;&#20102;&#23545;&#23454;&#38469;&#20219;&#21153;&#30340;&#25193;&#23637;&#12290;</title><link>http://arxiv.org/abs/2306.15058</link><description>&lt;p&gt;
BatchGFN: &#29992;&#20110;&#25209;&#37327;&#20027;&#21160;&#23398;&#20064;&#30340;&#29983;&#25104;&#27969;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
BatchGFN: Generative Flow Networks for Batch Active Learning. (arXiv:2306.15058v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15058
&lt;/p&gt;
&lt;p&gt;
BatchGFN&#26159;&#19968;&#31181;&#29992;&#20110;&#25209;&#37327;&#20027;&#21160;&#23398;&#20064;&#30340;&#26032;&#39062;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#29983;&#25104;&#27969;&#32593;&#32476;&#26681;&#25454;&#25209;&#37327;&#22870;&#21169;&#37319;&#26679;&#25968;&#25454;&#28857;&#38598;&#21512;&#65292;&#33021;&#22815;&#20197;&#21407;&#21017;&#24615;&#30340;&#26041;&#24335;&#26500;&#24314;&#39640;&#24230;&#20449;&#24687;&#37327;&#30340;&#25209;&#37327;&#65292;&#29992;&#20110;&#20027;&#21160;&#23398;&#20064;&#12290;&#36890;&#36807;&#22312;&#25512;&#29702;&#26102;&#38388;&#20869;&#36827;&#34892;&#21333;&#27425;&#21069;&#21521;&#20256;&#36882;&#26469;&#37319;&#26679;&#36817;&#20046;&#26368;&#20248;&#25928;&#29992;&#30340;&#25209;&#37327;&#65292;&#20943;&#36731;&#20102;&#38754;&#21521;&#25209;&#37327;&#30340;&#31639;&#27861;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#65292;&#24182;&#28040;&#38500;&#20102;&#36138;&#23146;&#36817;&#20284;&#30340;&#38656;&#27714;&#12290;&#25552;&#20986;&#20102;&#36328;&#33719;&#21462;&#27493;&#39588;&#20998;&#25674;&#35757;&#32451;&#30340;&#26089;&#26399;&#32467;&#26524;&#65292;&#23454;&#29616;&#20102;&#23545;&#23454;&#38469;&#20219;&#21153;&#30340;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;BatchGFN - &#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#27744;&#30340;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#29983;&#25104;&#27969;&#32593;&#32476;&#26681;&#25454;&#25209;&#37327;&#22870;&#21169;&#37319;&#26679;&#25968;&#25454;&#28857;&#38598;&#21512;&#12290;&#36890;&#36807;&#36866;&#24403;&#30340;&#22870;&#21169;&#20989;&#25968;&#26469;&#37327;&#21270;&#33719;&#21462;&#25209;&#37327;&#30340;&#25928;&#29992;&#65292;&#22914;&#25209;&#37327;&#19982;&#27169;&#22411;&#21442;&#25968;&#20043;&#38388;&#30340;&#32852;&#21512;&#20114;&#20449;&#24687;&#65292;BatchGFN&#33021;&#22815;&#20197;&#21407;&#21017;&#24615;&#30340;&#26041;&#24335;&#26500;&#24314;&#39640;&#24230;&#20449;&#24687;&#37327;&#30340;&#25209;&#37327;&#65292;&#29992;&#20110;&#20027;&#21160;&#23398;&#20064;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#29609;&#20855;&#22238;&#24402;&#38382;&#39064;&#20013;&#21487;&#20197;&#22312;&#25512;&#29702;&#26102;&#38388;&#20869;&#36890;&#36807;&#23545;&#25209;&#37327;&#20013;&#27599;&#20010;&#28857;&#36827;&#34892;&#21333;&#27425;&#21069;&#21521;&#20256;&#36882;&#26469;&#37319;&#26679;&#36817;&#20046;&#26368;&#20248;&#25928;&#29992;&#30340;&#25209;&#37327;&#65292;&#36825;&#20943;&#36731;&#20102;&#38754;&#21521;&#25209;&#37327;&#30340;&#31639;&#27861;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#65292;&#24182;&#28040;&#38500;&#20102;&#23547;&#25214;&#25209;&#37327;&#22870;&#21169;&#26368;&#22823;&#21270;&#22120;&#30340;&#36138;&#23146;&#36817;&#20284;&#30340;&#38656;&#27714;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#36328;&#33719;&#21462;&#27493;&#39588;&#20998;&#25674;&#35757;&#32451;&#30340;&#26089;&#26399;&#32467;&#26524;&#65292;&#36825;&#23558;&#23454;&#29616;&#23545;&#23454;&#38469;&#20219;&#21153;&#30340;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce BatchGFN -- a novel approach for pool-based active learning that uses generative flow networks to sample sets of data points proportional to a batch reward. With an appropriate reward function to quantify the utility of acquiring a batch, such as the joint mutual information between the batch and the model parameters, BatchGFN is able to construct highly informative batches for active learning in a principled way. We show our approach enables sampling near-optimal utility batches at inference time with a single forward pass per point in the batch in toy regression problems. This alleviates the computational complexity of batch-aware algorithms and removes the need for greedy approximations to find maximizers for the batch reward. We also present early results for amortizing training across acquisition steps, which will enable scaling to real-world tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20844;&#20849;&#25968;&#25454;&#30340;&#26368;&#20248;&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;&#65292;&#24182;&#35299;&#20915;&#20102;&#22312;&#35757;&#32451;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#26102;&#22914;&#20309;&#21033;&#29992;&#20844;&#20849;&#25968;&#25454;&#25552;&#39640;&#20934;&#30830;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.15056</link><description>&lt;p&gt;
&#20855;&#26377;&#20844;&#20849;&#25968;&#25454;&#30340;&#26368;&#20248;&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Optimal Differentially Private Learning with Public Data. (arXiv:2306.15056v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15056
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20844;&#20849;&#25968;&#25454;&#30340;&#26368;&#20248;&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;&#65292;&#24182;&#35299;&#20915;&#20102;&#22312;&#35757;&#32451;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#26102;&#22914;&#20309;&#21033;&#29992;&#20844;&#20849;&#25968;&#25454;&#25552;&#39640;&#20934;&#30830;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#33021;&#22815;&#30830;&#20445;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19981;&#27844;&#28431;&#31169;&#23494;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#24046;&#20998;&#38544;&#31169;&#30340;&#20195;&#20215;&#26159;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#38477;&#20302;&#25110;&#26679;&#26412;&#22797;&#26434;&#24230;&#22686;&#21152;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#25105;&#20204;&#21487;&#33021;&#21487;&#20197;&#35775;&#38382;&#19981;&#28041;&#21450;&#38544;&#31169;&#38382;&#39064;&#30340;&#36741;&#21161;&#20844;&#20849;&#25968;&#25454;&#12290;&#36825;&#20419;&#20351;&#20102;&#26368;&#36817;&#30740;&#31350;&#20844;&#20849;&#25968;&#25454;&#22312;&#25552;&#39640;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#20934;&#30830;&#24615;&#26041;&#38754;&#30340;&#20316;&#29992;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20551;&#35774;&#26377;&#19968;&#23450;&#25968;&#37327;&#30340;&#20844;&#20849;&#25968;&#25454;&#65292;&#24182;&#35299;&#20915;&#20197;&#19979;&#22522;&#26412;&#24320;&#25918;&#38382;&#39064;&#65306;1.&#22312;&#26377;&#20844;&#20849;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#35757;&#32451;&#22522;&#20110;&#31169;&#26377;&#25968;&#25454;&#38598;&#30340;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#30340;&#26368;&#20248;&#65288;&#26368;&#22351;&#24773;&#20917;&#65289;&#35823;&#24046;&#26159;&#22810;&#23569;&#65311;&#21738;&#20123;&#31639;&#27861;&#26159;&#26368;&#20248;&#30340;&#65311;2.&#22914;&#20309;&#21033;&#29992;&#20844;&#20849;&#25968;&#25454;&#22312;&#23454;&#36341;&#20013;&#25913;&#36827;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#35757;&#32451;&#65311;&#25105;&#20204;&#22312;&#26412;&#22320;&#27169;&#22411;&#21644;&#20013;&#24515;&#27169;&#22411;&#30340;&#24046;&#20998;&#38544;&#31169;&#38382;&#39064;&#19979;&#32771;&#34385;&#36825;&#20123;&#38382;&#39064;&#12290;&#20026;&#20102;&#22238;&#31572;&#31532;&#19968;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#19977;&#20010;&#22522;&#26412;&#38382;&#39064;&#30340;&#26368;&#20248;&#35823;&#24046;&#29575;&#30340;&#32039;&#23494;&#65288;&#26368;&#39640;&#24120;&#25968;&#22240;&#23376;&#65289;&#19979;&#30028;&#21644;&#19978;&#30028;&#12290;&#36825;&#19977;&#20010;&#38382;&#39064;&#26159;&#65306;&#22343;&#20540;&#20272;&#35745;&#65292;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#21644;&#20984;&#22855;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differential Privacy (DP) ensures that training a machine learning model does not leak private data. However, the cost of DP is lower model accuracy or higher sample complexity. In practice, we may have access to auxiliary public data that is free of privacy concerns. This has motivated the recent study of what role public data might play in improving the accuracy of DP models. In this work, we assume access to a given amount of public data and settle the following fundamental open questions: 1. What is the optimal (worst-case) error of a DP model trained over a private data set while having access to side public data? What algorithms are optimal? 2. How can we harness public data to improve DP model training in practice? We consider these questions in both the local and central models of DP. To answer the first question, we prove tight (up to constant factors) lower and upper bounds that characterize the optimal error rates of three fundamental problems: mean estimation, empirical ris
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#20248;&#36755;&#36816;&#27969;&#21305;&#37197;&#30340;&#31561;&#21464;CNF&#35757;&#32451;&#30446;&#26631;&#65292;&#21487;&#20197;&#25552;&#39640;&#31561;&#21464;CNF&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#23454;&#38469;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2306.15030</link><description>&lt;p&gt;
&#31561;&#21464;&#27969;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Equivariant flow matching. (arXiv:2306.15030v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15030
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#20248;&#36755;&#36816;&#27969;&#21305;&#37197;&#30340;&#31561;&#21464;CNF&#35757;&#32451;&#30446;&#26631;&#65292;&#21487;&#20197;&#25552;&#39640;&#31561;&#21464;CNF&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#23454;&#38469;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;&#21270;&#27969;&#26159;&#19968;&#31867;&#29305;&#21035;&#36866;&#29992;&#20110;&#29289;&#29702;&#23398;&#20013;&#27010;&#29575;&#20998;&#24067;&#24314;&#27169;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#12290;&#20854;&#20013;&#65292;&#27969;&#30340;&#20934;&#30830;&#20284;&#28982;&#24615;&#36136;&#21487;&#20197;&#23454;&#29616;&#23545;&#24050;&#30693;&#30446;&#26631;&#33021;&#37327;&#20989;&#25968;&#30340;&#21152;&#26435;&#37325;&#37325;&#21644;&#26080;&#20559;&#35266;&#27979;&#37327;&#30340;&#35745;&#31639;&#12290;&#20363;&#22914;&#65292;Boltzmann&#29983;&#25104;&#22120;&#36890;&#36807;&#35757;&#32451;&#27969;&#29983;&#25104;&#22788;&#20110;&#24179;&#34913;&#29366;&#24577;&#30340;&#22810;&#20307;&#31995;&#32479;&#65288;&#22914;&#23567;&#20998;&#23376;&#21644;&#34507;&#30333;&#36136;&#65289;&#26679;&#26412;&#65292;&#35299;&#20915;&#20102;&#32479;&#35745;&#29289;&#29702;&#23398;&#20013;&#38271;&#26399;&#23384;&#22312;&#30340;&#37319;&#26679;&#38382;&#39064;&#12290;&#20026;&#20102;&#26500;&#24314;&#26377;&#25928;&#30340;&#27169;&#22411;&#65292;&#20063;&#24456;&#20851;&#38190;&#23558;&#30446;&#26631;&#33021;&#37327;&#30340;&#23545;&#31216;&#24615;&#32435;&#20837;&#27169;&#22411;&#20013;&#65292;&#36825;&#21487;&#20197;&#36890;&#36807;&#31561;&#21464;&#36830;&#32493;&#26631;&#20934;&#21270;&#27969;&#65288;CNF&#65289;&#26469;&#23454;&#29616;&#12290;&#28982;&#32780;&#65292;CNF&#30340;&#35757;&#32451;&#21644;&#26679;&#26412;&#29983;&#25104;&#30340;&#35745;&#31639;&#24320;&#38144;&#36739;&#22823;&#65292;&#36825;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#23454;&#38469;&#24212;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31561;&#21464;&#27969;&#21305;&#37197;&#65292;&#19968;&#31181;&#26032;&#30340;&#31561;&#21464;CNF&#35757;&#32451;&#30446;&#26631;&#65292;&#20854;&#22522;&#20110;&#26368;&#36817;&#25552;&#20986;&#30340;&#26368;&#20248;&#36755;&#36816;&#27969;&#21305;&#37197;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Normalizing flows are a class of deep generative models that are especially interesting for modeling probability distributions in physics, where the exact likelihood of flows allows reweighting to known target energy functions and computing unbiased observables. For instance, Boltzmann generators tackle the long-standing sampling problem in statistical physics by training flows to produce equilibrium samples of many-body systems such as small molecules and proteins. To build effective models for such systems, it is crucial to incorporate the symmetries of the target energy into the model, which can be achieved by equivariant continuous normalizing flows (CNFs). However, CNFs can be computationally expensive to train and generate samples from, which has hampered their scalability and practical application. In this paper, we introduce equivariant flow matching, a new training objective for equivariant CNFs that is based on the recently proposed optimal transport flow matching. Equivarian
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20174;&#22122;&#22768;&#28151;&#21512;&#29289;&#20013;&#24674;&#22797;&#30446;&#26631;&#20449;&#21495;&#30340;&#32479;&#35745;&#20998;&#37327;&#20998;&#31163;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#22270;&#20687;&#38477;&#22122;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#20854;&#20248;&#20110;&#26631;&#20934;&#38477;&#22122;&#26041;&#27861;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.15012</link><description>&lt;p&gt;
&#29992;&#20110;&#22122;&#22768;&#28151;&#21512;&#29289;&#20013;&#30446;&#26631;&#20449;&#21495;&#24674;&#22797;&#30340;&#32479;&#35745;&#20998;&#37327;&#20998;&#31163;
&lt;/p&gt;
&lt;p&gt;
Statistical Component Separation for Targeted Signal Recovery in Noisy Mixtures. (arXiv:2306.15012v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15012
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20174;&#22122;&#22768;&#28151;&#21512;&#29289;&#20013;&#24674;&#22797;&#30446;&#26631;&#20449;&#21495;&#30340;&#32479;&#35745;&#20998;&#37327;&#20998;&#31163;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#22270;&#20687;&#38477;&#22122;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#20854;&#20248;&#20110;&#26631;&#20934;&#38477;&#22122;&#26041;&#27861;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21482;&#23545;&#32473;&#23450;&#20449;&#21495;&#30340;&#29305;&#23450;&#23646;&#24615;&#24863;&#20852;&#36259;&#26102;&#65292;&#20174;&#19968;&#20010;&#21152;&#24615;&#28151;&#21512;&#29289;&#20013;&#20998;&#31163;&#20449;&#21495;&#21487;&#33021;&#26159;&#19968;&#20010;&#19981;&#24517;&#35201;&#22320;&#22256;&#38590;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#26356;&#31616;&#21333;&#30340;&#8220;&#32479;&#35745;&#20998;&#37327;&#20998;&#31163;&#8221;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#19987;&#27880;&#20110;&#20174;&#22122;&#22768;&#28151;&#21512;&#29289;&#20013;&#24674;&#22797;&#30446;&#26631;&#20449;&#21495;&#30340;&#39044;&#23450;&#20041;&#32479;&#35745;&#25551;&#36848;&#37327;&#12290;&#20551;&#35774;&#21487;&#20197;&#33719;&#24471;&#22122;&#22768;&#36807;&#31243;&#30340;&#26679;&#26412;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26088;&#22312;&#20351;&#21463;&#22122;&#22768;&#26679;&#26412;&#27745;&#26579;&#30340;&#35299;&#20915;&#26041;&#26696;&#20505;&#36873;&#30340;&#32479;&#35745;&#29305;&#24615;&#19982;&#35266;&#27979;&#30340;&#28151;&#21512;&#29289;&#30340;&#32479;&#35745;&#29305;&#24615;&#21305;&#37197;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20351;&#29992;&#20855;&#26377;&#35299;&#26512;&#21487;&#36861;&#36394;&#35745;&#31639;&#30340;&#31616;&#21333;&#31034;&#20363;&#20998;&#26512;&#20102;&#35813;&#26041;&#27861;&#30340;&#34892;&#20026;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#20854;&#24212;&#29992;&#20110;&#22270;&#20687;&#38477;&#22122;&#29615;&#22659;&#20013;&#65292;&#20351;&#29992;&#20102;1&#65289;&#22522;&#20110;&#23567;&#27874;&#30340;&#25551;&#36848;&#31526;&#65292;2&#65289;&#38024;&#23545;&#22825;&#20307;&#29289;&#29702;&#21644;ImageNet&#25968;&#25454;&#30340;ConvNet-based&#25551;&#36848;&#31526;&#12290;&#22312;&#31532;&#19968;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#27604;&#26631;&#20934;&#38477;&#22122;&#26041;&#27861;&#26356;&#22909;&#22320;&#24674;&#22797;&#20102;&#30446;&#26631;&#25968;&#25454;&#30340;&#25551;&#36848;&#31526;&#12290;&#27492;&#22806;&#65292;&#23613;&#31649;&#19981;&#26159;&#20026;&#27492;&#30446;&#30340;&#26500;&#24314;&#30340;&#65292;&#23427;&#20063;&#34920;&#29616;&#20986;&#23545;&#30446;&#26631;&#20449;&#21495;&#25551;&#36848;&#31526;&#24674;&#22797;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Separating signals from an additive mixture may be an unnecessarily hard problem when one is only interested in specific properties of a given signal. In this work, we tackle simpler "statistical component separation" problems that focus on recovering a predefined set of statistical descriptors of a target signal from a noisy mixture. Assuming access to samples of the noise process, we investigate a method devised to match the statistics of the solution candidate corrupted by noise samples with those of the observed mixture. We first analyze the behavior of this method using simple examples with analytically tractable calculations. Then, we apply it in an image denoising context employing 1) wavelet-based descriptors, 2) ConvNet-based descriptors on astrophysics and ImageNet data. In the case of 1), we show that our method better recovers the descriptors of the target data than a standard denoising method in most situations. Additionally, despite not constructed for this purpose, it pe
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20998;&#23376;&#21147;&#22330;&#20013;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#35201;&#27714;&#21644;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#20808;&#21069;&#30340;&#30740;&#31350;&#26041;&#27861;&#26080;&#27861;&#28385;&#36275;&#25152;&#26377;&#26631;&#20934;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23616;&#37096;&#31070;&#32463;&#26680;&#30340;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65288;LNK&#65289;&#12290;</title><link>http://arxiv.org/abs/2306.14916</link><description>&lt;p&gt;
&#20998;&#23376;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;: &#26399;&#26395;&#21644;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Uncertainty Estimation for Molecules: Desiderata and Methods. (arXiv:2306.14916v1 [physics.chem-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14916
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20998;&#23376;&#21147;&#22330;&#20013;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#35201;&#27714;&#21644;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#20808;&#21069;&#30340;&#30740;&#31350;&#26041;&#27861;&#26080;&#27861;&#28385;&#36275;&#25152;&#26377;&#26631;&#20934;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23616;&#37096;&#31070;&#32463;&#26680;&#30340;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65288;LNK&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#20316;&#20026;&#37327;&#23376;&#21147;&#23398;&#35745;&#31639;&#30340;&#26377;&#24076;&#26395;&#26367;&#20195;&#26041;&#27861;&#65292;&#22312;&#20998;&#23376;&#21160;&#21147;&#23398;&#65288;MD&#65289;&#36712;&#36857;&#38598;&#21512;&#19978;&#24314;&#31435;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#20302;&#35823;&#24046;&#12290;&#30001;&#20110;&#23427;&#20204;&#24555;&#36895;&#30340;&#25512;&#29702;&#26102;&#38388;&#65292;&#23427;&#20204;&#25215;&#35834;&#21152;&#36895;&#35745;&#31639;&#21270;&#23398;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#22312;&#20998;&#24067;&#65288;ID&#65289;&#35823;&#24046;&#19978;&#21487;&#20302;&#65292;&#20294;&#36825;&#20123;GNNs&#22312;&#20998;&#24067;&#22806;&#65288;OOD&#65289;&#26679;&#26412;&#19978;&#21487;&#33021;&#23436;&#20840;&#38169;&#35823;&#12290;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65288;UE&#65289;&#21487;&#20197;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#24110;&#21161;&#36890;&#36807;&#20256;&#36798;&#27169;&#22411;&#23545;&#20854;&#39044;&#27979;&#30340;&#30830;&#23450;&#24615;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#30528;&#30524;&#20110;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#30830;&#23450;&#20102;&#20998;&#23376;&#21147;&#22330;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#20013;&#30340;&#20845;&#20010;&#20851;&#38190;&#35201;&#27714;&#65292;&#19977;&#20010;&#26159;&#8220;&#29289;&#29702;&#20449;&#24687;&#8221;&#26041;&#38754;&#30340;&#65292;&#19977;&#20010;&#26159;&#8220;&#24212;&#29992;&#28966;&#28857;&#8221;&#26041;&#38754;&#30340;&#12290;&#20026;&#20102;&#27010;&#36848;&#35813;&#39046;&#22495;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#29616;&#26377;&#30340;UE&#26041;&#27861;&#65292;&#24182;&#20998;&#26512;&#23427;&#20204;&#22914;&#20309;&#31526;&#21512;&#36825;&#20123;&#35201;&#27714;&#12290;&#36890;&#36807;&#25105;&#20204;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#37117;&#26080;&#27861;&#28385;&#36275;&#25152;&#26377;&#26631;&#20934;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#20010;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#23616;&#37096;&#31070;&#32463;&#26680;&#65288;LNK&#65289;&#30340;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) are promising surrogates for quantum mechanical calculations as they establish unprecedented low errors on collections of molecular dynamics (MD) trajectories. Thanks to their fast inference times they promise to accelerate computational chemistry applications. Unfortunately, despite low in-distribution (ID) errors, such GNNs might be horribly wrong for out-of-distribution (OOD) samples. Uncertainty estimation (UE) may aid in such situations by communicating the model's certainty about its prediction. Here, we take a closer look at the problem and identify six key desiderata for UE in molecular force fields, three 'physics-informed' and three 'application-focused' ones. To overview the field, we survey existing methods from the field of UE and analyze how they fit to the set desiderata. By our analysis, we conclude that none of the previous works satisfies all criteria. To fill this gap, we propose Localized Neural Kernel (LNK) a Gaussian Process (GP)-based
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#29575;&#29983;&#25104;&#27169;&#22411;&#26469;&#35774;&#35745;&#20855;&#26377;&#25152;&#38656;&#21270;&#23398;&#21644;&#29983;&#29289;&#24615;&#36136;&#30340;&#20998;&#23376;&#65292;&#24182;&#36890;&#36807;&#36880;&#27493;&#20998;&#24067;&#21464;&#25442;&#37319;&#26679;&#31639;&#27861;&#25628;&#32034;&#20855;&#26377;&#25152;&#38656;&#24615;&#36136;&#30340;&#20998;&#23376;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#20998;&#23376;&#35774;&#35745;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#24456;&#24378;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.14902</link><description>&lt;p&gt;
&#36890;&#36807;&#28508;&#22312;&#31354;&#38388;&#33021;&#37327;&#24314;&#27169;&#21644;&#20998;&#24067;&#36880;&#27493;&#21464;&#25442;&#36827;&#34892;&#20998;&#23376;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Molecule Design by Latent Space Energy-Based Modeling and Gradual Distribution Shifting. (arXiv:2306.14902v1 [q-bio.BM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14902
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#29575;&#29983;&#25104;&#27169;&#22411;&#26469;&#35774;&#35745;&#20855;&#26377;&#25152;&#38656;&#21270;&#23398;&#21644;&#29983;&#29289;&#24615;&#36136;&#30340;&#20998;&#23376;&#65292;&#24182;&#36890;&#36807;&#36880;&#27493;&#20998;&#24067;&#21464;&#25442;&#37319;&#26679;&#31639;&#27861;&#25628;&#32034;&#20855;&#26377;&#25152;&#38656;&#24615;&#36136;&#30340;&#20998;&#23376;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#20998;&#23376;&#35774;&#35745;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#24456;&#24378;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#33647;&#29289;&#30740;&#21457;&#65292;&#29983;&#25104;&#20855;&#26377;&#25152;&#38656;&#21270;&#23398;&#21644;&#29983;&#29289;&#24615;&#36136;&#65288;&#22914;&#39640;&#33647;&#29289;&#26679;&#24615;&#65292;&#39640;&#20146;&#21644;&#21147;&#65289;&#30340;&#20998;&#23376;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#27010;&#29575;&#29983;&#25104;&#27169;&#22411;&#65292;&#29992;&#20110;&#25429;&#25417;&#20998;&#23376;&#21644;&#20854;&#24615;&#36136;&#30340;&#32852;&#21512;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#22522;&#20110;&#33021;&#37327;&#24314;&#27169;&#65288;EBM&#65289;&#12290;&#22312;&#28508;&#22312;&#21521;&#37327;&#30340;&#26465;&#20214;&#19979;&#65292;&#20998;&#23376;&#21450;&#20854;&#24615;&#36136;&#34987;&#20998;&#21035;&#24314;&#27169;&#20026;&#20998;&#23376;&#29983;&#25104;&#27169;&#22411;&#21644;&#24615;&#36136;&#22238;&#24402;&#27169;&#22411;&#12290;&#20026;&#20102;&#25628;&#32034;&#20855;&#26377;&#25152;&#38656;&#24615;&#36136;&#30340;&#20998;&#23376;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36880;&#27493;&#20998;&#24067;&#21464;&#25442;&#37319;&#26679;&#65288;SGDS&#65289;&#31639;&#27861;&#65292;&#20351;&#24471;&#22312;&#26368;&#21021;&#23398;&#20064;&#29616;&#26377;&#20998;&#23376;&#21450;&#20854;&#24615;&#36136;&#30340;&#35757;&#32451;&#25968;&#25454;&#21518;&#65292;&#35813;&#31639;&#27861;&#36880;&#28176;&#23558;&#27169;&#22411;&#20998;&#24067;&#36716;&#31227;&#21040;&#25903;&#25345;&#25152;&#38656;&#24615;&#36136;&#20540;&#30340;&#20998;&#23376;&#21306;&#22495;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21508;&#31181;&#20998;&#23376;&#35774;&#35745;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#24456;&#24378;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generation of molecules with desired chemical and biological properties such as high drug-likeness, high binding affinity to target proteins, is critical for drug discovery. In this paper, we propose a probabilistic generative model to capture the joint distribution of molecules and their properties. Our model assumes an energy-based model (EBM) in the latent space. Conditional on the latent vector, the molecule and its properties are modeled by a molecule generation model and a property regression model respectively. To search for molecules with desired properties, we propose a sampling with gradual distribution shifting (SGDS) algorithm, so that after learning the model initially on the training data of existing molecules and their properties, the proposed algorithm gradually shifts the model distribution towards the region supported by molecules with desired values of properties. Our experiments show that our method achieves very strong performances on various molecule design tasks.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#21644;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#32593;&#32476;&#27169;&#22411;&#65292;&#36890;&#36807;&#33945;&#29305;&#21345;&#32599;&#21644;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#37319;&#26679;&#32593;&#32476;&#32467;&#26500;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#35813;&#26041;&#27861;&#22312;&#24674;&#22797;&#32593;&#32476;&#30340;&#22270;&#24418;&#32467;&#26500;&#26041;&#38754;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#21518;&#39564;&#27010;&#29575;&#30340;&#20934;&#30830;&#36817;&#20284;&#12290;</title><link>http://arxiv.org/abs/2306.11380</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#32593;&#32476;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Bayesian Take on Gaussian Process Networks. (arXiv:2306.11380v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11380
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#21644;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#32593;&#32476;&#27169;&#22411;&#65292;&#36890;&#36807;&#33945;&#29305;&#21345;&#32599;&#21644;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#37319;&#26679;&#32593;&#32476;&#32467;&#26500;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#35813;&#26041;&#27861;&#22312;&#24674;&#22797;&#32593;&#32476;&#30340;&#22270;&#24418;&#32467;&#26500;&#26041;&#38754;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#21518;&#39564;&#27010;&#29575;&#30340;&#20934;&#30830;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#32593;&#32476;&#65288;GPNs&#65289;&#26159;&#19968;&#31867;&#26377;&#21521;&#22270;&#27169;&#22411;&#65292;&#20854;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#20316;&#20026;&#32593;&#32476;&#20013;&#27599;&#20010;&#21464;&#37327;&#32473;&#23450;&#20854;&#29238;&#21464;&#37327;&#30340;&#26465;&#20214;&#26399;&#26395;&#30340;&#20808;&#39564;&#20998;&#24067;&#12290;&#35813;&#27169;&#22411;&#20801;&#35768;&#20197;&#32039;&#20945;&#20294;&#28789;&#27963;&#30340;&#26041;&#24335;&#25551;&#36848;&#36830;&#32493;&#32852;&#21512;&#20998;&#24067;&#65292;&#23545;&#21464;&#37327;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#20165;&#20570;&#26368;&#23569;&#30340;&#21442;&#25968;&#20551;&#35774;&#12290;GPNs&#30340;&#36125;&#21494;&#26031;&#32467;&#26500;&#23398;&#20064;&#38656;&#35201;&#35745;&#31639;&#32593;&#32476;&#32467;&#26500;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#21363;&#20351;&#22312;&#20302;&#32500;&#24773;&#20917;&#19979;&#65292;&#36825;&#20063;&#26159;&#35745;&#31639;&#19978;&#19981;&#21487;&#34892;&#30340;&#12290;&#26412;&#25991;&#23454;&#29616;&#20102;&#33945;&#29305;&#21345;&#32599;&#21644;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#26469;&#20174;&#32593;&#32476;&#32467;&#26500;&#30340;&#21518;&#39564;&#20998;&#24067;&#20013;&#37319;&#26679;&#12290;&#22240;&#27492;&#65292;&#35813;&#26041;&#27861;&#36981;&#24490;&#36125;&#21494;&#26031;&#33539;&#24335;&#65292;&#36890;&#36807;&#36793;&#32536;&#20284;&#28982;&#27604;&#36739;&#27169;&#22411;&#65292;&#24182;&#35745;&#31639;GPN&#29305;&#24449;&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;&#27169;&#25311;&#30740;&#31350;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#24674;&#22797;&#32593;&#32476;&#30340;&#22270;&#24418;&#32467;&#26500;&#26041;&#38754;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#20854;&#21518;&#39564;&#30340;&#20934;&#30830;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian Process Networks (GPNs) are a class of directed graphical models which employ Gaussian processes as priors for the conditional expectation of each variable given its parents in the network. The model allows describing continuous joint distributions in a compact but flexible manner with minimal parametric assumptions on the dependencies between variables. Bayesian structure learning of GPNs requires computing the posterior over graphs of the network and is computationally infeasible even in low dimensions. This work implements Monte Carlo and Markov Chain Monte Carlo methods to sample from the posterior distribution of network structures. As such, the approach follows the Bayesian paradigm, comparing models via their marginal likelihood and computing the posterior probability of the GPN features. Simulation studies show that our method outperforms state-of-the-art algorithms in recovering the graphical structure of the network and provides an accurate approximation of its poste
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26494;&#24347;&#20102;&#23436;&#20840;&#19981;&#21464;&#24615;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#25928;&#26524;&#19981;&#21464;&#24615;&#65292;&#35777;&#26126;&#23427;&#36275;&#20197;&#36827;&#34892;&#38646;&#26679;&#26412;&#31574;&#30053;&#27010;&#25324;&#65292;&#24182;&#35752;&#35770;&#20102;&#22522;&#20110;&#23569;&#37327;&#26679;&#26412;&#30340;&#25193;&#23637;&#12290;</title><link>http://arxiv.org/abs/2306.10983</link><description>&lt;p&gt;
&#31574;&#30053;&#27010;&#25324;&#20013;&#30340;&#25928;&#26524;&#19981;&#21464;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Effect-Invariant Mechanisms for Policy Generalization. (arXiv:2306.10983v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10983
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26494;&#24347;&#20102;&#23436;&#20840;&#19981;&#21464;&#24615;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#25928;&#26524;&#19981;&#21464;&#24615;&#65292;&#35777;&#26126;&#23427;&#36275;&#20197;&#36827;&#34892;&#38646;&#26679;&#26412;&#31574;&#30053;&#27010;&#25324;&#65292;&#24182;&#35752;&#35770;&#20102;&#22522;&#20110;&#23569;&#37327;&#26679;&#26412;&#30340;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31574;&#30053;&#23398;&#20064;&#26159;&#35768;&#22810;&#23454;&#38469;&#23398;&#20064;&#31995;&#32479;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#31574;&#30053;&#23398;&#20064;&#30340;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#26159;&#22914;&#20309;&#26377;&#25928;&#22320;&#36866;&#24212;&#26410;&#35265;&#36807;&#30340;&#29615;&#22659;&#25110;&#20219;&#21153;&#12290;&#26368;&#36817;&#65292;&#26377;&#20154;&#24314;&#35758;&#21033;&#29992;&#19981;&#21464;&#30340;&#26465;&#20214;&#20998;&#24067;&#26469;&#23398;&#20064;&#26356;&#22909;&#22320;&#27010;&#25324;&#26410;&#35265;&#36807;&#29615;&#22659;&#30340;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#20551;&#35774;&#25972;&#20010;&#26465;&#20214;&#20998;&#24067;&#26159;&#19981;&#21464;&#30340;&#65288;&#25105;&#20204;&#31216;&#20043;&#20026;&#23436;&#20840;&#19981;&#21464;&#24615;&#65289;&#65292;&#22312;&#23454;&#36341;&#20013;&#21487;&#33021;&#26159;&#19968;&#20010;&#22826;&#24378;&#30340;&#20551;&#35774;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26494;&#24347;&#23436;&#20840;&#19981;&#21464;&#24615;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#25928;&#26524;&#19981;&#21464;&#24615;&#65288;&#31616;&#31216;e-&#19981;&#21464;&#24615;&#65289;&#65292;&#24182;&#35777;&#26126;&#23427;&#26159;&#36275;&#22815;&#30340;&#65288;&#22312;&#36866;&#24403;&#30340;&#20551;&#35774;&#19979;&#65289;&#65292;&#29992;&#20110;&#38646;&#26679;&#26412;&#31574;&#30053;&#27010;&#25324;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#19968;&#31181;&#25193;&#23637;&#65292;&#23427;&#22312;&#27979;&#35797;&#29615;&#22659;&#20013;&#21482;&#26377;&#23569;&#37327;&#26679;&#26412;&#26102;&#21033;&#29992;e-&#19981;&#21464;&#24615;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23569;&#26679;&#26412;&#31574;&#30053;&#25512;&#24191;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#19981;&#20551;&#35774;&#23384;&#22312;&#19968;&#20010;&#22522;&#30784;&#22240;&#26524;&#22270;&#65292;&#20063;&#19981;&#20551;&#35774;&#25968;&#25454;&#26159;&#30001;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#29983;&#25104;&#30340;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#27979;&#35797;&#36807;&#31243;&#26469;&#27979;&#35797;e-&#19981;&#21464;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Policy learning is an important component of many real-world learning systems. A major challenge in policy learning is how to adapt efficiently to unseen environments or tasks. Recently, it has been suggested to exploit invariant conditional distributions to learn models that generalize better to unseen environments. However, assuming invariance of entire conditional distributions (which we call full invariance) may be too strong of an assumption in practice. In this paper, we introduce a relaxation of full invariance called effect-invariance (e-invariance for short) and prove that it is sufficient, under suitable assumptions, for zero-shot policy generalization. We also discuss an extension that exploits e-invariance when we have a small sample from the test environment, enabling few-shot policy generalization. Our work does not assume an underlying causal graph or that the data are generated by a structural causal model; instead, we develop testing procedures to test e-invariance dir
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32039;&#26680;&#30340;&#31639;&#23376;&#29702;&#35770;&#26041;&#27861;&#26469;&#35299;&#20915;&#26465;&#20214;&#26399;&#26395;&#20272;&#35745;&#38382;&#39064;&#65292;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#23454;&#29616;&#65292;&#26131;&#20110;&#23454;&#29616;&#65292;&#19988;&#25104;&#21151;&#24212;&#29992;&#20110;&#23454;&#38469;&#38382;&#39064;&#20013;&#12290;</title><link>http://arxiv.org/abs/2306.10592</link><description>&lt;p&gt;
&#22522;&#20110;&#32039;&#26680;&#30340;&#26465;&#20214;&#26399;&#26395;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Conditional expectation via compact kernels. (arXiv:2306.10592v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10592
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32039;&#26680;&#30340;&#31639;&#23376;&#29702;&#35770;&#26041;&#27861;&#26469;&#35299;&#20915;&#26465;&#20214;&#26399;&#26395;&#20272;&#35745;&#38382;&#39064;&#65292;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#23454;&#29616;&#65292;&#26131;&#20110;&#23454;&#29616;&#65292;&#19988;&#25104;&#21151;&#24212;&#29992;&#20110;&#23454;&#38469;&#38382;&#39064;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21435;&#22122;&#12289;&#26465;&#20214;&#26399;&#26395;&#21644;&#27969;&#24418;&#23398;&#20064;&#20219;&#21153;&#36890;&#24120;&#21487;&#20197;&#22312;&#23547;&#25214;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;&#31215;&#30340;&#26465;&#20214;&#26399;&#26395;&#30340;&#20844;&#20849;&#29615;&#22659;&#19979;&#34920;&#36848;&#12290;&#26412;&#25991;&#38024;&#23545;&#36825;&#20010;&#26356;&#19968;&#33324;&#30340;&#38382;&#39064;&#65292;&#25551;&#36848;&#20102;&#19968;&#31181;&#31639;&#23376;&#29702;&#35770;&#26041;&#27861;&#26469;&#20272;&#35745;&#26465;&#20214;&#26399;&#26395;&#12290;&#26680;&#31215;&#20998;&#31639;&#23376;&#34987;&#29992;&#20316;&#32039;&#33268;&#21270;&#24037;&#20855;&#65292;&#23558;&#20272;&#35745;&#38382;&#39064;&#35774;&#32622;&#20026;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#32447;&#24615;&#36870;&#38382;&#39064;&#12290;&#35813;&#26041;&#31243;&#30340;&#35299;&#34987;&#35777;&#26126;&#23545;&#25968;&#20540;&#36924;&#36817;&#26159;&#31283;&#23450;&#30340;&#65292;&#20174;&#32780;&#30830;&#20445;&#20102;&#25968;&#25454;&#39537;&#21160;&#23454;&#29616;&#30340;&#25910;&#25947;&#24615;&#12290;&#24635;&#20307;&#25216;&#26415;&#26131;&#20110;&#23454;&#29616;&#65292;&#36824;&#23637;&#31034;&#20102;&#20854;&#22312;&#19968;&#20123;&#23454;&#38469;&#38382;&#39064;&#20013;&#30340;&#25104;&#21151;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
The separate tasks of denoising, conditional expectation and manifold learning can often be posed in a common setting of finding the conditional expectations arising from a product of two random variables. This paper focuses on this more general problem and describes an operator theoretic approach to estimating the conditional expectation. Kernel integral operators are used as a compactification tool, to set up the estimation problem as a linear inverse problem in a reproducing kernel Hilbert space. This equation is shown to have solutions that are stable to numerical approximation, thus guaranteeing the convergence of data-driven implementations. The overall technique is easy to implement, and their successful application to some real-world problems are also shown.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ProjUnit&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#23454;&#29616;&#39640;&#25928;&#30340;&#26412;&#22320;&#38544;&#31169;&#22343;&#20540;&#20272;&#35745;&#65292;&#36890;&#36807;&#38543;&#26426;&#25237;&#24433;&#20302;&#32500;&#31354;&#38388;&#23454;&#29616;&#26368;&#20248;&#35299;&#65292;&#19988;&#20855;&#26377;&#20302;&#36890;&#20449;&#22797;&#26434;&#24230;&#21644;&#24555;&#36895;&#30340;&#26381;&#21153;&#22120;&#36816;&#34892;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2306.04444</link><description>&lt;p&gt;
&#36890;&#36807;&#38543;&#26426;&#25237;&#24433;&#24555;&#36895;&#33719;&#24471;&#26368;&#20248;&#30340;&#26412;&#22320;&#38544;&#31169;&#22343;&#20540;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Fast Optimal Locally Private Mean Estimation via Random Projections. (arXiv:2306.04444v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04444
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ProjUnit&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#23454;&#29616;&#39640;&#25928;&#30340;&#26412;&#22320;&#38544;&#31169;&#22343;&#20540;&#20272;&#35745;&#65292;&#36890;&#36807;&#38543;&#26426;&#25237;&#24433;&#20302;&#32500;&#31354;&#38388;&#23454;&#29616;&#26368;&#20248;&#35299;&#65292;&#19988;&#20855;&#26377;&#20302;&#36890;&#20449;&#22797;&#26434;&#24230;&#21644;&#24555;&#36895;&#30340;&#26381;&#21153;&#22120;&#36816;&#34892;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#39640;&#32500;&#21521;&#37327;&#30340;&#26412;&#22320;&#38544;&#31169;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#12290;&#29616;&#26377;&#31639;&#27861;&#35201;&#20040;&#20135;&#29983;&#27425;&#20248;&#35823;&#24046;&#65292;&#35201;&#20040;&#20855;&#26377;&#39640;&#36890;&#20449;&#21644;/&#25110;&#36816;&#34892;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#26694;&#26550;ProjUnit&#65292;&#29992;&#20110;&#38544;&#31169;&#22343;&#20540;&#20272;&#35745;&#30340;&#31639;&#27861;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#39640;&#12289;&#36890;&#20449;&#22797;&#26434;&#24230;&#20302;&#19988;&#35823;&#24046;&#19982;&#26368;&#20248;&#35299;&#20043;&#38388;&#30340;&#24046;&#36317;&#26368;&#22823;&#20026;1 + o(1)&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#23454;&#29616;&#36215;&#26469;&#38750;&#24120;&#31616;&#21333;&#65306;&#27599;&#20010;&#38543;&#26426;&#21270;&#22120;&#23558;&#20854;&#36755;&#20837;&#25237;&#24433;&#21040;&#19968;&#20010;&#38543;&#26426;&#30340;&#20302;&#32500;&#23376;&#31354;&#38388;&#20013;&#65292;&#23545;&#32467;&#26524;&#36827;&#34892;&#24402;&#19968;&#21270;&#65292;&#28982;&#21518;&#22312;&#20302;&#32500;&#31354;&#38388;&#20013;&#36816;&#34892;&#19968;&#20010;&#26368;&#20248;&#31639;&#27861;&#65292;&#20363;&#22914;PrivUnitG&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#36866;&#24403;&#22320;&#21327;&#35843;&#35774;&#22791;&#20043;&#38388;&#30340;&#38543;&#26426;&#25237;&#24433;&#30697;&#38453;&#65292;&#21487;&#20197;&#23454;&#29616;&#24555;&#36895;&#30340;&#26381;&#21153;&#22120;&#36816;&#34892;&#26102;&#38388;&#12290;&#25105;&#20204;&#36890;&#36807;&#38543;&#26426;&#25237;&#24433;&#30340;&#24615;&#36136;&#20998;&#26512;&#20102;&#31639;&#27861;&#30340;&#35823;&#24046;&#65292;&#24182;&#30740;&#31350;&#20102;&#20004;&#31181;&#23454;&#20363;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;ProjUnit&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#20855;&#26377;&#26174;&#33879;&#30340;&#24615;&#33021;&#20248;&#21183;&#65292;&#29305;&#21035;&#26159;&#22312;&#39640;&#32500;&#39640;&#26031;&#28151;&#21512;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of locally private mean estimation of high-dimensional vectors in the Euclidean ball. Existing algorithms for this problem either incur sub-optimal error or have high communication and/or run-time complexity. We propose a new algorithmic framework, ProjUnit, for private mean estimation that yields algorithms that are computationally efficient, have low communication complexity, and incur optimal error up to a $1+o(1)$-factor. Our framework is deceptively simple: each randomizer projects its input to a random low-dimensional subspace, normalizes the result, and then runs an optimal algorithm such as PrivUnitG in the lower-dimensional space. In addition, we show that, by appropriately correlating the random projection matrices across devices, we can achieve fast server run-time. We mathematically analyze the error of the algorithm in terms of properties of the random projections, and study two instantiations. Lastly, our experiments for private mean estimation and pr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#19982;&#31070;&#32463;&#32593;&#32476;&#23436;&#20840;&#23545;&#24212;&#30340;&#26080;&#38480;&#26641;&#29366;PGMs&#26469;&#35299;&#20915;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#32570;&#20047;PGMs&#30340;&#31934;&#30830;&#35821;&#20041;&#21644;&#26126;&#30830;&#23450;&#20041;&#30340;&#27010;&#29575;&#35299;&#37322;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#21457;&#29616;DNNs&#22312;&#21069;&#21521;&#20256;&#25773;&#26102;&#30830;&#23454;&#25191;&#34892;PGM&#25512;&#26029;&#30340;&#36817;&#20284;&#65292;&#36825;&#19982;&#29616;&#26377;&#30740;&#31350;&#19981;&#21516;&#65292;&#23427;&#38416;&#26126;&#20102;DNNs&#23545;PGMs&#20013;&#30340;&#31934;&#30830;&#25512;&#29702;&#30340;&#26356;&#30452;&#25509;&#36817;&#20284;&#65292;&#28508;&#22312;&#30340;&#22909;&#22788;&#21253;&#25324;&#25913;&#36827;DNNs&#30340;&#25945;&#23398;&#21644;&#35299;&#37322;&#65292;&#20197;&#21450;&#33021;&#22815;&#21512;&#24182;PGMs&#21644;DNNs&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.17583</link><description>&lt;p&gt;
&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#26080;&#38480;&#26641;&#29366;&#27010;&#29575;&#22270;&#27169;&#22411;&#30340;&#35770;&#25991;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Neural Networks as Infinite Tree-Structured Probabilistic Graphical Models. (arXiv:2305.17583v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17583
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#19982;&#31070;&#32463;&#32593;&#32476;&#23436;&#20840;&#23545;&#24212;&#30340;&#26080;&#38480;&#26641;&#29366;PGMs&#26469;&#35299;&#20915;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#32570;&#20047;PGMs&#30340;&#31934;&#30830;&#35821;&#20041;&#21644;&#26126;&#30830;&#23450;&#20041;&#30340;&#27010;&#29575;&#35299;&#37322;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#21457;&#29616;DNNs&#22312;&#21069;&#21521;&#20256;&#25773;&#26102;&#30830;&#23454;&#25191;&#34892;PGM&#25512;&#26029;&#30340;&#36817;&#20284;&#65292;&#36825;&#19982;&#29616;&#26377;&#30740;&#31350;&#19981;&#21516;&#65292;&#23427;&#38416;&#26126;&#20102;DNNs&#23545;PGMs&#20013;&#30340;&#31934;&#30830;&#25512;&#29702;&#30340;&#26356;&#30452;&#25509;&#36817;&#20284;&#65292;&#28508;&#22312;&#30340;&#22909;&#22788;&#21253;&#25324;&#25913;&#36827;DNNs&#30340;&#25945;&#23398;&#21644;&#35299;&#37322;&#65292;&#20197;&#21450;&#33021;&#22815;&#21512;&#24182;PGMs&#21644;DNNs&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#32570;&#20047;&#27010;&#29575;&#22270;&#27169;&#22411;(PGMs)&#30340;&#31934;&#30830;&#35821;&#20041;&#21644;&#26126;&#30830;&#23450;&#20041;&#30340;&#27010;&#29575;&#35299;&#37322;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#19982;&#31070;&#32463;&#32593;&#32476;&#23436;&#20840;&#23545;&#24212;&#30340;&#26080;&#38480;&#26641;&#29366;PGMs&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;DNNs&#22312;&#21069;&#21521;&#20256;&#25773;&#26399;&#38388;&#30830;&#23454;&#25191;&#34892;PGM&#25512;&#26029;&#30340;&#36817;&#20284;&#65292;&#36825;&#19982;&#26366;&#32463;&#30340;&#31070;&#32463;&#32593;&#32476;&#25551;&#36848;&#20026;&#26680;&#26426;&#22120;&#25110;&#26080;&#38480;&#22823;&#23567;&#30340;&#39640;&#26031;&#36807;&#31243;&#30340;&#29616;&#26377;&#30740;&#31350;&#19981;&#21516;&#65292;&#23427;&#38416;&#26126;&#20102;DNNs&#23545;PGMs&#20013;&#30340;&#31934;&#30830;&#25512;&#29702;&#30340;&#26356;&#30452;&#25509;&#36817;&#20284;&#12290;&#28508;&#22312;&#30340;&#22909;&#22788;&#21253;&#25324;&#25913;&#36827;DNNs&#30340;&#25945;&#23398;&#21644;&#35299;&#37322;&#65292;&#20197;&#21450;&#33021;&#22815;&#21512;&#24182;PGMs&#21644;DNNs&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks (DNNs) lack the precise semantics and definitive probabilistic interpretation of probabilistic graphical models (PGMs). In this paper, we propose an innovative solution by constructing infinite tree-structured PGMs that correspond exactly to neural networks. Our research reveals that DNNs, during forward propagation, indeed perform approximations of PGM inference that are precise in this alternative PGM structure. Not only does our research complement existing studies that describe neural networks as kernel machines or infinite-sized Gaussian processes, it also elucidates a more direct approximation that DNNs make to exact inference in PGMs. Potential benefits include improved pedagogy and interpretation of DNNs, and algorithms that can merge the strengths of PGMs and DNNs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27969;&#24418;&#27491;&#21017;&#21270;Tucker&#20998;&#35299;&#30340;&#26102;&#31354;&#20132;&#36890;&#25968;&#25454;&#22635;&#20805;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#31232;&#30095;&#27491;&#21017;&#21270;&#39033;&#25913;&#21892;&#20102;Tucker&#26680;&#30340;&#31232;&#30095;&#24615;&#65292;&#24182;&#24341;&#20837;&#27969;&#24418;&#27491;&#21017;&#21270;&#21644;&#26102;&#38388;&#32422;&#26463;&#39033;&#26469;&#20248;&#21270;&#24352;&#37327;&#30340;&#22635;&#20805;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.06563</link><description>&lt;p&gt;
&#22522;&#20110;&#27969;&#24418;&#27491;&#21017;&#21270; Tucker &#20998;&#35299;&#30340;&#26102;&#31354;&#20132;&#36890;&#25968;&#25454;&#22635;&#20805;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Manifold Regularized Tucker Decomposition Approach for Spatiotemporal Traffic Data Imputation. (arXiv:2305.06563v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06563
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27969;&#24418;&#27491;&#21017;&#21270;Tucker&#20998;&#35299;&#30340;&#26102;&#31354;&#20132;&#36890;&#25968;&#25454;&#22635;&#20805;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#31232;&#30095;&#27491;&#21017;&#21270;&#39033;&#25913;&#21892;&#20102;Tucker&#26680;&#30340;&#31232;&#30095;&#24615;&#65292;&#24182;&#24341;&#20837;&#27969;&#24418;&#27491;&#21017;&#21270;&#21644;&#26102;&#38388;&#32422;&#26463;&#39033;&#26469;&#20248;&#21270;&#24352;&#37327;&#30340;&#22635;&#20805;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#31354;&#20132;&#36890;&#25968;&#25454;&#22635;&#20805;(STDI)&#26159;&#25968;&#25454;&#39537;&#21160;&#26234;&#33021;&#20132;&#36890;&#31995;&#32479;&#20013;&#19981;&#21487;&#36991;&#20813;&#21644;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#22312;&#37096;&#20998;&#35266;&#27979;&#21040;&#30340;&#20132;&#36890;&#25968;&#25454;&#20013;&#20272;&#35745;&#20002;&#22833;&#25968;&#25454;&#12290;&#30001;&#20110;&#20132;&#36890;&#25968;&#25454;&#20855;&#26377;&#22810;&#32500;&#21644;&#26102;&#31354;&#24615;&#36136;&#65292;&#25105;&#20204;&#23558;&#20002;&#22833;&#25968;&#25454;&#22635;&#20805;&#35270;&#20026;&#24352;&#37327;&#23436;&#25104;&#38382;&#39064;&#12290;&#36807;&#21435;&#21313;&#24180;&#20013;&#65292;&#35768;&#22810;&#20851;&#20110;&#22522;&#20110;&#24352;&#37327;&#20998;&#35299;&#30340; STDI &#30340;&#30740;&#31350;&#24050;&#32463;&#23637;&#24320;&#12290;&#28982;&#32780;&#65292;&#22914;&#20309;&#21033;&#29992;&#26102;&#31354;&#30456;&#20851;&#24615;&#21644;&#26680;&#24352;&#37327;&#31232;&#30095;&#24615;&#26469;&#25913;&#21892;&#22635;&#20805;&#24615;&#33021;&#20173;&#28982;&#38656;&#35201;&#35299;&#20915;&#12290;&#26412;&#25991;&#37325;&#26032;&#26500;&#36896;&#20102;3/4&#38454;&#27721;&#20811;&#23572;&#24352;&#37327;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#27969;&#24418;&#27491;&#21017;&#21270; Tucker &#20998;&#35299;(maniRTD)&#27169;&#22411;&#29992;&#20110;STDI&#12290;&#26126;&#30830;&#22320;&#65292;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#22810;&#32500;&#24310;&#36831;&#23884;&#20837;&#21464;&#25442;&#23558;&#20256;&#24863;&#20132;&#36890;&#29366;&#24577;&#25968;&#25454;&#34920;&#31034;&#20026;3/4&#38454;&#24352;&#37327;&#12290;&#28982;&#21518;&#65292;ManiRTD&#20351;&#29992;&#31232;&#30095;&#27491;&#21017;&#21270;&#39033;&#25913;&#21892;&#20102;Tucker&#26680;&#30340;&#31232;&#30095;&#24615;&#65292;&#24182;&#20351;&#29992;&#27969;&#24418;&#27491;&#21017;&#21270;&#21644;&#26102;&#38388;&#32422;&#26463;&#39033;&#26469;&#20248;&#21270;&#24352;&#37327;&#30340;&#22635;&#20805;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Spatiotemporal traffic data imputation (STDI), estimating the missing data from partially observed traffic data, is an inevitable and challenging task in data-driven intelligent transportation systems (ITS). Due to traffic data's multidimensional and spatiotemporal properties, we treat the missing data imputation as a tensor completion problem. Many studies have been on STDI based on tensor decomposition in the past decade. However, how to use spatiotemporal correlations and core tensor sparsity to improve the imputation performance still needs to be solved. This paper reshapes a 3rd/4th order Hankel tensor and proposes an innovative manifold regularized Tucker decomposition (ManiRTD) model for STDI. Expressly, we represent the sensory traffic state data as the 3rd/4th tensors by introducing Multiway Delay Embedding Transforms. Then, ManiRTD improves the sparsity of the Tucker core using a sparse regularization term and employs manifold regularization and temporal constraint terms of f
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#22312;&#36716;&#31227;&#23398;&#20064;&#19979;&#27169;&#22411;&#36873;&#25321;&#23384;&#22312;&#30340;&#38480;&#21046;&#65292;&#20854;&#36716;&#31227;&#36317;&#31163;&#20250;&#24433;&#21709;&#33258;&#36866;&#24212;&#36895;&#29575;&#65292;&#21487;&#33021;&#23548;&#33268;&#36895;&#29575;&#36739;&#24930;&#12290;</title><link>http://arxiv.org/abs/2305.00152</link><description>&lt;p&gt;
&#36716;&#31227;&#23398;&#20064;&#19979;&#30340;&#27169;&#22411;&#36873;&#25321;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
Limits of Model Selection under Transfer Learning. (arXiv:2305.00152v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00152
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#22312;&#36716;&#31227;&#23398;&#20064;&#19979;&#27169;&#22411;&#36873;&#25321;&#23384;&#22312;&#30340;&#38480;&#21046;&#65292;&#20854;&#36716;&#31227;&#36317;&#31163;&#20250;&#24433;&#21709;&#33258;&#36866;&#24212;&#36895;&#29575;&#65292;&#21487;&#33021;&#23548;&#33268;&#36895;&#29575;&#36739;&#24930;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#65292;&#20851;&#20110;&#36716;&#31227;&#23398;&#20064;&#25110;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#29702;&#35770;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#24050;&#30693;&#20551;&#35774;&#31867;&#25110;&#27169;&#22411;&#30340;&#24773;&#20917;&#65307;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#36890;&#24120;&#28041;&#21450;&#19968;&#23450;&#31243;&#24230;&#30340;&#27169;&#22411;&#36873;&#25321;&#65292;&#36825;&#32463;&#24120;&#20986;&#29616;&#22312;&#36229;&#21442;&#25968;&#35843;&#25972;&#30340;&#24635;&#20307;&#33539;&#30068;&#19979;&#65306;&#20363;&#22914;&#65292;&#25105;&#20204;&#21487;&#20197;&#32771;&#34385;&#35843;&#25972;&#38024;&#23545;&#30446;&#26631;&#20219;&#21153;&#30340;&#27491;&#30830;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#21033;&#29992;&#26469;&#33258;&#30456;&#20851;&#28304;&#20219;&#21153;&#30340;&#25968;&#25454;&#12290;&#38500;&#20102;&#19982;&#27169;&#22411;&#36873;&#25321;&#26377;&#20851;&#30340;&#36817;&#20284;&#19982;&#20272;&#35745;&#35823;&#24046;&#30340;&#36890;&#24120;&#26435;&#34913;&#20043;&#22806;&#65292;&#36825;&#20010;&#38382;&#39064;&#36824;&#24102;&#26469;&#20102;&#26032;&#30340;&#22797;&#26434;&#24230;&#65292;&#21363;&#28304;&#20998;&#24067;&#19982;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#30340;&#36716;&#31227;&#36317;&#31163;&#65292;&#36825;&#20010;&#36317;&#31163;&#38543;&#30528;&#20551;&#35774;&#31867;&#30340;&#36873;&#25321;&#32780;&#21457;&#29983;&#21464;&#21270;&#12290;&#25105;&#20204;&#39318;&#27425;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#37325;&#28857;&#20851;&#27880;&#20998;&#31867;&#38382;&#39064;&#12290;&#29305;&#21035;&#30340;&#65292;&#20998;&#26512;&#25581;&#31034;&#20102;&#19968;&#20123;&#24341;&#20154;&#27880;&#30446;&#30340;&#29616;&#35937;&#65306;&#33258;&#36866;&#24212;&#36895;&#29575;&#65292;&#21363;&#27809;&#26377;&#20998;&#24067;&#24335;&#20449;&#24687;&#26102;&#21487;&#36798;&#21040;&#30340;&#36895;&#29575;&#65292;&#21487;&#20197;&#20219;&#24847;&#24930;&#20110;oracle&#36895;&#29575;&#65292;&#21363;&#22312;&#32473;&#23450;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Theoretical studies on transfer learning or domain adaptation have so far focused on situations with a known hypothesis class or model; however in practice, some amount of model selection is usually involved, often appearing under the umbrella term of hyperparameter-tuning: for example, one may think of the problem of tuning for the right neural network architecture towards a target task, while leveraging data from a related source task.  Now, in addition to the usual tradeoffs on approximation vs estimation errors involved in model selection, this problem brings in a new complexity term, namely, the transfer distance between source and target distributions, which is known to vary with the choice of hypothesis class.  We present a first study of this problem, focusing on classification; in particular, the analysis reveals some remarkable phenomena: adaptive rates, i.e., those achievable with no distributional information, can be arbitrarily slower than oracle rates, i.e., when given kn
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32806;&#21512;&#26041;&#27861;&#20998;&#26512;&#20102;&#22312;$d$&#32500;&#29615;&#38754;$\mathbb{T}_L^d$&#19978;&#23450;&#20041;&#30340;&#22312;Haar&#27979;&#24230;&#30456;&#23545;&#20110;&#23494;&#24230;&#21487;&#20801;&#35768;&#30340;&#27010;&#29575;&#24230;&#37327;&#30340;Sinkhorn&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#65292;&#35777;&#26126;&#20102;Sinkhorn&#36845;&#20195;&#21450;&#20854;&#26799;&#24230;&#30340;&#28857;&#24120;&#25351;&#25968;&#25910;&#25947;&#24615;&#65292;&#21516;&#26102;&#23548;&#20986;&#20102;&#20854;&#38750;&#28176;&#36817;&#35823;&#24046;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#19982;&#29615;&#22659;&#32500;&#25968;$d$&#21644;&#31163;&#25955;&#20803;&#32032;&#20195;&#20215;&#30697;&#38453;&#30340;&#23610;&#23544;&#26080;&#20851;&#12290;</title><link>http://arxiv.org/abs/2304.06549</link><description>&lt;p&gt;
&#38024;&#23545;Sinkhorn&#36845;&#20195;&#21450;&#20854;&#26799;&#24230;&#30340;&#38750;&#28176;&#36827;&#25910;&#25947;&#30028;&#38480;: &#19968;&#31181;&#32806;&#21512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Non-asymptotic convergence bounds for Sinkhorn iterates and their gradients: a coupling approach. (arXiv:2304.06549v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06549
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32806;&#21512;&#26041;&#27861;&#20998;&#26512;&#20102;&#22312;$d$&#32500;&#29615;&#38754;$\mathbb{T}_L^d$&#19978;&#23450;&#20041;&#30340;&#22312;Haar&#27979;&#24230;&#30456;&#23545;&#20110;&#23494;&#24230;&#21487;&#20801;&#35768;&#30340;&#27010;&#29575;&#24230;&#37327;&#30340;Sinkhorn&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#65292;&#35777;&#26126;&#20102;Sinkhorn&#36845;&#20195;&#21450;&#20854;&#26799;&#24230;&#30340;&#28857;&#24120;&#25351;&#25968;&#25910;&#25947;&#24615;&#65292;&#21516;&#26102;&#23548;&#20986;&#20102;&#20854;&#38750;&#28176;&#36817;&#35823;&#24046;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#19982;&#29615;&#22659;&#32500;&#25968;$d$&#21644;&#31163;&#25955;&#20803;&#32032;&#20195;&#20215;&#30697;&#38453;&#30340;&#23610;&#23544;&#26080;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#35745;&#31639;&#26368;&#20248;&#20256;&#36755;&#65288;OT&#65289;&#20316;&#20026;&#19968;&#20010;&#22312;&#21508;&#20010;&#39046;&#22495;&#24212;&#29992;&#30340;&#24378;&#26377;&#21147;&#30340;&#26694;&#26550;&#20986;&#29616;&#20102;&#12290;&#26412;&#25991;&#30528;&#37325;&#35752;&#35770;&#23545;&#21407;&#22987;OT&#38382;&#39064;&#30340;&#19968;&#31181;&#25918;&#26494;&#24418;&#24335;&#65292;&#21363;&#29109;OT&#38382;&#39064;&#65292;&#23427;&#21487;&#20197;&#23454;&#29616;&#39640;&#25928;&#30340;&#23454;&#38469;&#31639;&#27861;&#35299;&#20915;&#26041;&#26696;&#65292;&#21363;&#20351;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#20063;&#26159;&#22914;&#27492;&#12290;&#36825;&#20010;&#20844;&#24335;&#20063;&#34987;&#31216;&#20026;Schr\"odinger&#26725;&#38382;&#39064;&#65292;&#26174;&#28982;&#19982;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#65288;SOC&#65289;&#30456;&#20851;&#65292;&#24182;&#19988;&#21487;&#20197;&#29992;&#27969;&#34892;&#30340;Sinkhorn&#31639;&#27861;&#26469;&#35299;&#20915;&#12290;&#23545;&#20110;&#31163;&#25955;&#29366;&#24577;&#31354;&#38388;&#30340;&#24773;&#20917;&#65292;&#24050;&#30693;&#35813;&#31639;&#27861;&#20855;&#26377;&#25351;&#25968;&#25910;&#25947;&#24615;&#65307;&#28982;&#32780;&#65292;&#22312;&#26356;&#19968;&#33324;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#31867;&#20284;&#30340;&#25910;&#25947;&#36895;&#29575;&#20173;&#28982;&#26159;&#19968;&#20010;&#31215;&#26497;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#22312;$d$&#32500;&#29615;&#38754;$\mathbb{T}_L^d$&#19978;&#23450;&#20041;&#30340;&#22312;Haar&#27979;&#24230;&#30456;&#23545;&#20110;&#23494;&#24230;&#21487;&#20801;&#35768;&#30340;&#27010;&#29575;&#24230;&#37327;&#30340;Sinkhorn&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;&#29305;&#21035;&#30340;&#65292;&#22312;&#36873;&#25321;&#19968;&#23450;&#33539;&#22260;&#20869;&#30340;&#29109;&#21442;&#25968;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;Sinkhorn&#36845;&#20195;&#21450;&#20854;&#26799;&#24230;&#30340;&#28857;&#24120;&#25351;&#25968;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#25216;&#26415;&#20381;&#36182;&#20110;&#19968;&#31181;&#32806;&#21512;&#26041;&#27861;&#65292;&#21463;&#21040;[C. E. Brubaker, M. Fathi&#21644;G. Peyr&#233;, NeurIPS 2020]&#30340;&#26368;&#26032;&#24037;&#20316;&#30340;&#21551;&#21457;&#12290;&#25105;&#20204;&#36824;&#25512;&#23548;&#20102;Sinkhorn&#31639;&#27861;&#30340;&#26032;&#25910;&#25947;&#36895;&#29575;&#65292;&#20174;&#32780;&#23548;&#20986;&#20102;Sinkhorn&#36845;&#20195;&#21644;&#32806;&#21512;&#30340;&#38750;&#28176;&#36817;&#35823;&#24046;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#29420;&#31435;&#20110;&#29615;&#22659;&#32500;&#25968;$d$&#21644;&#31163;&#25955;&#20803;&#32032;&#20195;&#20215;&#30697;&#38453;&#30340;&#23610;&#23544;&#12290;
&lt;/p&gt;
&lt;p&gt;
Computational optimal transport (OT) has recently emerged as a powerful framework with applications in various fields. In this paper we focus on a relaxation of the original OT problem, the entropic OT problem, which allows to implement efficient and practical algorithmic solutions, even in high dimensional settings. This formulation, also known as the Schr\"odinger Bridge problem, notably connects with Stochastic Optimal Control (SOC) and can be solved with the popular Sinkhorn algorithm. In the case of discrete-state spaces, this algorithm is known to have exponential convergence; however, achieving a similar rate of convergence in a more general setting is still an active area of research. In this work, we analyze the convergence of the Sinkhorn algorithm for probability measures defined on the $d$-dimensional torus $\mathbb{T}_L^d$, that admit densities with respect to the Haar measure of $\mathbb{T}_L^d$. In particular, we prove pointwise exponential convergence of Sinkhorn iterat
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#22312;&#26377;&#30028;f-&#25955;&#24230;&#32422;&#26463;&#19979;&#65292;&#36817;&#20284;&#25298;&#32477;&#37319;&#26679;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#21487;&#20197;&#36890;&#36807;&#920;(~(D/f'(n)))&#20989;&#25968;&#26469;&#34920;&#31034;&#65292;&#24182;&#19988;&#24212;&#29992;&#20110;&#24179;&#28369;&#22312;&#32447;&#23398;&#20064;&#20013;&#30340;&#30456;&#20851;&#31639;&#27861;&#30340;&#24615;&#33021;&#20381;&#28982;&#25104;&#31435;&#12290;</title><link>http://arxiv.org/abs/2302.04658</link><description>&lt;p&gt;
&#36817;&#20284;&#25298;&#32477;&#37319;&#26679;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#21450;&#20854;&#22312;&#24179;&#28369;&#22312;&#32447;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
The Sample Complexity of Approximate Rejection Sampling with Applications to Smoothed Online Learning. (arXiv:2302.04658v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04658
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#22312;&#26377;&#30028;f-&#25955;&#24230;&#32422;&#26463;&#19979;&#65292;&#36817;&#20284;&#25298;&#32477;&#37319;&#26679;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#21487;&#20197;&#36890;&#36807;&#920;(~(D/f'(n)))&#20989;&#25968;&#26469;&#34920;&#31034;&#65292;&#24182;&#19988;&#24212;&#29992;&#20110;&#24179;&#28369;&#22312;&#32447;&#23398;&#20064;&#20013;&#30340;&#30456;&#20851;&#31639;&#27861;&#30340;&#24615;&#33021;&#20381;&#28982;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20551;&#35774;&#25105;&#20204;&#21487;&#20197;&#35775;&#38382;&#26469;&#33258;&#20998;&#24067;&#956;&#30340;n&#20010;&#29420;&#31435;&#26679;&#26412;&#65292;&#24182;&#19988;&#25105;&#20204;&#24076;&#26395;&#36755;&#20986;&#20854;&#20013;&#19968;&#20010;&#26679;&#26412;&#65292;&#20351;&#24471;&#36755;&#20986;&#30340;&#20998;&#24067;&#23613;&#21487;&#33021;&#25509;&#36817;&#30446;&#26631;&#20998;&#24067;&#957;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#25152;&#26377;&#20855;&#26377;&#26377;&#30028;f-&#25955;&#24230;Df(&#957;|&#956;)&#8804;D&#30340;&#957;,&#956;&#23545;&#20013;&#65292;&#20851;&#20110;n&#30340;&#26368;&#20248;&#24635;&#21464;&#24046;&#36317;&#31163;&#30001;&#920;(~(D/f'(n)))&#32473;&#20986;&#12290;&#20043;&#21069;&#65292;&#36825;&#20010;&#38382;&#39064;&#21482;&#30740;&#31350;&#20102;&#957;&#30456;&#23545;&#20110;&#956;&#30340;Radon-Nikodym&#23548;&#25968;&#19968;&#33268;&#26377;&#30028;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#36824;&#32771;&#34385;&#20102;&#20284;&#20046;&#38750;&#24120;&#19981;&#21516;&#30340;&#24179;&#28369;&#22312;&#32447;&#23398;&#20064;&#39046;&#22495;&#30340;&#19968;&#20010;&#24212;&#29992;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26368;&#23567;&#21270;&#36951;&#25022;&#21644;&#20855;&#26377;oracle&#25928;&#29575;&#30340;&#31639;&#27861;&#30340;&#36951;&#25022;&#21363;&#20351;&#22312;&#23545;&#25163;&#26377;&#36793;&#30028;f-&#25955;&#24230;&#65288;&#32780;&#19981;&#26159;&#26377;&#30028;Radon-Nikodym&#23548;&#25968;&#65289;&#30340;&#26494;&#24347;&#32422;&#26463;&#19979;&#65292;&#20173;&#28982;&#25104;&#31435;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#22312;&#22343;&#21248;&#20272;&#35745;&#20013;&#29992;&#20110;&#24179;&#22343;&#20272;&#35745;&#30340;&#37325;&#35201;&#24615;&#37319;&#26679;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Suppose we are given access to $n$ independent samples from distribution $\mu$ and we wish to output one of them with the goal of making the output distributed as close as possible to a target distribution $\nu$. In this work we show that the optimal total variation distance as a function of $n$ is given by $\tilde\Theta(\frac{D}{f'(n)})$ over the class of all pairs $\nu,\mu$ with a bounded $f$-divergence $D_f(\nu\|\mu)\leq D$. Previously, this question was studied only for the case when the Radon-Nikodym derivative of $\nu$ with respect to $\mu$ is uniformly bounded. We then consider an application in the seemingly very different field of smoothed online learning, where we show that recent results on the minimax regret and the regret of oracle-efficient algorithms still hold even under relaxed constraints on the adversary (to have bounded $f$-divergence, as opposed to bounded Radon-Nikodym derivative). Finally, we also study efficacy of importance sampling for mean estimates uniform o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#26089;&#20572;&#19982;conformal&#26657;&#20934;&#30456;&#32467;&#21512;&#30340;&#26032;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#20351;&#29992;&#26089;&#20572;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;&#32570;&#20047;&#29420;&#31435;&#26657;&#20934;&#25968;&#25454;&#26102;&#26080;&#27861;&#25552;&#20379;&#20934;&#30830;&#32479;&#35745;&#20445;&#35777;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2301.11556</link><description>&lt;p&gt;
&#23545;&#20110;&#20351;&#29992;&#26089;&#20572;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;conformal&#25512;&#29702;&#26159;&#20960;&#20046;&#20813;&#36153;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conformal inference is (almost) free for neural networks trained with early stopping. (arXiv:2301.11556v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11556
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#26089;&#20572;&#19982;conformal&#26657;&#20934;&#30456;&#32467;&#21512;&#30340;&#26032;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#20351;&#29992;&#26089;&#20572;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;&#32570;&#20047;&#29420;&#31435;&#26657;&#20934;&#25968;&#25454;&#26102;&#26080;&#27861;&#25552;&#20379;&#20934;&#30830;&#32479;&#35745;&#20445;&#35777;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20445;&#30041;&#25968;&#25454;&#30340;&#26089;&#20572;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#29992;&#20110;&#20943;&#36731;&#36807;&#25311;&#21512;&#24182;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#20351;&#29992;&#26089;&#20572;&#35757;&#32451;&#30340;&#27169;&#22411;&#36890;&#24120;&#25552;&#20379;&#30456;&#23545;&#20934;&#30830;&#30340;&#39044;&#27979;&#65292;&#20294;&#38500;&#38750;&#36827;&#19968;&#27493;&#20351;&#29992;&#29420;&#31435;&#30340;&#20445;&#30041;&#25968;&#25454;&#36827;&#34892;&#26657;&#20934;&#65292;&#21542;&#21017;&#23427;&#20204;&#36890;&#24120;&#20173;&#28982;&#32570;&#20047;&#31934;&#30830;&#30340;&#32479;&#35745;&#20445;&#35777;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#26089;&#20572;&#19982;conformal&#26657;&#20934;&#30456;&#32467;&#21512;&#65292;&#21516;&#26102;&#39640;&#25928;&#22320;&#37325;&#22797;&#20351;&#29992;&#30456;&#21516;&#30340;&#20445;&#30041;&#25968;&#25454;&#65292;&#35299;&#20915;&#20102;&#19978;&#36848;&#38480;&#21046;&#12290;&#36825;&#23548;&#33268;&#20102;&#26082;&#20934;&#30830;&#21448;&#33021;&#22815;&#25552;&#20379;&#31934;&#30830;&#39044;&#27979;&#25512;&#26029;&#30340;&#27169;&#22411;&#65292;&#32780;&#26080;&#38656;&#22810;&#27425;&#25968;&#25454;&#25286;&#20998;&#25110;&#36807;&#20110;&#20445;&#23432;&#30340;&#35843;&#25972;&#12290;&#20026;&#19981;&#21516;&#30340;&#23398;&#20064;&#20219;&#21153;&#65288;&#24322;&#24120;&#20540;&#26816;&#27979;&#65292;&#22810;&#31867;&#20998;&#31867;&#65292;&#22238;&#24402;&#65289;&#24320;&#21457;&#20102;&#23454;&#38469;&#23454;&#29616;&#65292;&#24182;&#22312;&#30495;&#23454;&#25968;&#25454;&#19978;&#23637;&#31034;&#20102;&#23427;&#20204;&#30340;&#31454;&#20105;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Early stopping based on hold-out data is a popular regularization technique designed to mitigate overfitting and increase the predictive accuracy of neural networks. Models trained with early stopping often provide relatively accurate predictions, but they generally still lack precise statistical guarantees unless they are further calibrated using independent hold-out data. This paper addresses the above limitation with conformalized early stopping: a novel method that combines early stopping with conformal calibration while efficiently recycling the same hold-out data. This leads to models that are both accurate and able to provide exact predictive inferences without multiple data splits nor overly conservative adjustments. Practical implementations are developed for different learning tasks -- outlier detection, multi-class classification, regression -- and their competitive performance is demonstrated on real data.
&lt;/p&gt;</description></item><item><title>XPER&#26041;&#27861;&#33021;&#34913;&#37327;&#36755;&#20837;&#29305;&#24449;&#23545;&#27169;&#22411;&#39044;&#27979;&#24615;&#33021;&#30340;&#20855;&#20307;&#36129;&#29486;&#65292;&#24182;&#21487;&#29992;&#20110;&#22788;&#29702;&#24322;&#36136;&#24615;&#38382;&#39064;&#65292;&#26500;&#24314;&#21516;&#36136;&#21270;&#20010;&#20307;&#32676;&#20307;&#65292;&#20174;&#32780;&#25552;&#39640;&#39044;&#27979;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2212.05866</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#24615;&#33021;&#65306;&#34913;&#37327;&#39044;&#27979;&#24615;&#33021;&#30340;&#39537;&#21160;&#21147;
&lt;/p&gt;
&lt;p&gt;
Explainable Performance: Measuring the Driving Forces of Predictive Performance. (arXiv:2212.05866v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.05866
&lt;/p&gt;
&lt;p&gt;
XPER&#26041;&#27861;&#33021;&#34913;&#37327;&#36755;&#20837;&#29305;&#24449;&#23545;&#27169;&#22411;&#39044;&#27979;&#24615;&#33021;&#30340;&#20855;&#20307;&#36129;&#29486;&#65292;&#24182;&#21487;&#29992;&#20110;&#22788;&#29702;&#24322;&#36136;&#24615;&#38382;&#39064;&#65292;&#26500;&#24314;&#21516;&#36136;&#21270;&#20010;&#20307;&#32676;&#20307;&#65292;&#20174;&#32780;&#25552;&#39640;&#39044;&#27979;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;XPER&#65288;eXplainable PERformance&#65289;&#26041;&#27861;&#26469;&#34913;&#37327;&#36755;&#20837;&#29305;&#24449;&#23545;&#27169;&#22411;&#39044;&#27979;&#24615;&#33021;&#30340;&#20855;&#20307;&#36129;&#29486;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#29702;&#35770;&#19978;&#22522;&#20110;Shapley&#20540;&#65292;&#26082;&#19981;&#20381;&#36182;&#20110;&#27169;&#22411;&#65292;&#20063;&#19981;&#20381;&#36182;&#20110;&#24615;&#33021;&#24230;&#37327;&#12290;&#27492;&#22806;&#65292;XPER&#21487;&#22312;&#27169;&#22411;&#32423;&#21035;&#25110;&#20010;&#20307;&#32423;&#21035;&#23454;&#29616;&#12290;&#25105;&#20204;&#35777;&#26126;XPER&#20855;&#26377;&#26631;&#20934;&#35299;&#37322;&#24615;&#26041;&#27861;&#65288;SHAP&#65289;&#30340;&#29305;&#27530;&#24773;&#20917;&#12290;&#22312;&#36151;&#27454;&#36829;&#32422;&#39044;&#27979;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;XPER&#22788;&#29702;&#24322;&#36136;&#24615;&#38382;&#39064;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#26679;&#26412;&#22806;&#24615;&#33021;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#36890;&#36807;&#22522;&#20110;&#20010;&#20307;XPER&#20540;&#23545;&#20182;&#20204;&#36827;&#34892;&#32858;&#31867;&#26469;&#26500;&#24314;&#21516;&#36136;&#21270;&#30340;&#20010;&#20307;&#32676;&#20307;&#12290;&#25105;&#20204;&#21457;&#29616;&#20272;&#35745;&#32676;&#20307;&#29305;&#23450;&#30340;&#27169;&#22411;&#27604;&#19968;&#20010;&#27169;&#22411;&#36866;&#29992;&#20110;&#25152;&#26377;&#20010;&#20307;&#20855;&#26377;&#26356;&#39640;&#30340;&#39044;&#27979;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the XPER (eXplainable PERformance) methodology to measure the specific contribution of the input features to the predictive performance of a model. Our methodology is theoretically grounded on Shapley values and is both model-agnostic and performance metric-agnostic. Furthermore, XPER can be implemented either at the model level or at the individual level. We demonstrate that XPER has as a special case the standard explainability method in machine learning (SHAP). In a loan default forecasting application, we show how XPER can be used to deal with heterogeneity issues and significantly boost out-of-sample performance. To do so, we build homogeneous groups of individuals by clustering them based on their individual XPER values. We find that estimating group-specific models yields a much higher predictive accuracy than with a one-fits-all model.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;Q-&#25351;&#25968;&#36807;&#31243;&#30340;&#36125;&#21494;&#26031;&#23398;&#20064;&#65292;&#36890;&#36807;&#25512;&#24191;Q-&#25351;&#25968;&#20998;&#24067;&#20026;Q-&#25351;&#25968;&#36807;&#31243;&#65292;&#26469;&#23545;&#20989;&#25968;&#30340;L_q&#27491;&#21017;&#21270;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#36873;&#25321;&#19968;&#33268;&#30340;&#22810;&#20803;q-&#25351;&#25968;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2210.07987</link><description>&lt;p&gt;
&#22522;&#20110;Q-&#25351;&#25968;&#36807;&#31243;&#30340;&#36125;&#21494;&#26031;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Bayesian Learning via Q-Exponential Process. (arXiv:2210.07987v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.07987
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;Q-&#25351;&#25968;&#36807;&#31243;&#30340;&#36125;&#21494;&#26031;&#23398;&#20064;&#65292;&#36890;&#36807;&#25512;&#24191;Q-&#25351;&#25968;&#20998;&#24067;&#20026;Q-&#25351;&#25968;&#36807;&#31243;&#65292;&#26469;&#23545;&#20989;&#25968;&#30340;L_q&#27491;&#21017;&#21270;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#36873;&#25321;&#19968;&#33268;&#30340;&#22810;&#20803;q-&#25351;&#25968;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;&#21017;&#21270;&#26159;&#20248;&#21270;&#12289;&#32479;&#35745;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#22522;&#30784;&#30340;&#20027;&#39064;&#20043;&#19968;&#12290;&#20026;&#20102;&#22312;&#20272;&#35745;&#21442;&#25968;$u\in\mbR^d$&#26102;&#33719;&#24471;&#31232;&#30095;&#24615;&#65292;&#22312;&#30446;&#26631;&#20989;&#25968;&#20013;&#36890;&#24120;&#20250;&#28155;&#21152;$\ell_q$&#24809;&#32602;&#39033;&#65292;&#21363;$\Vert u\Vert_q$&#12290;&#36825;&#26679;&#30340;$\ell_q$&#24809;&#32602;&#23545;&#24212;&#30340;&#27010;&#29575;&#20998;&#24067;&#26159;&#20160;&#20040;&#65311;&#24403;&#25105;&#20204;&#23545;&#20989;&#25968;$u\in L^q$&#24314;&#27169;&#26102;&#65292;$\Vert u\Vert_q$&#23545;&#24212;&#30340;&#27491;&#30830;&#38543;&#26426;&#36807;&#31243;&#26159;&#20160;&#20040;&#65311;&#36825;&#23545;&#20110;&#32479;&#35745;&#24314;&#27169;&#22823;&#32500;&#24230;&#23545;&#35937;&#65288;&#20363;&#22914;&#22270;&#20687;&#65289;&#24182;&#20445;&#30041;&#30830;&#23450;&#24615;&#29305;&#24615;&#65288;&#20363;&#22914;&#22270;&#20687;&#36793;&#32536;&#65289;&#30340;&#24809;&#32602;&#38750;&#24120;&#37325;&#35201;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;$Q$-&#25351;&#25968;&#20998;&#24067;&#65288;&#23494;&#24230;&#27491;&#27604;&#20110;$\exp{(- \half|u|^q)}$&#65289;&#25512;&#24191;&#20026;&#19968;&#31181;&#31216;&#20026;\emph{$Q$-&#25351;&#25968;&#65288;Q-EP&#65289;&#36807;&#31243;}&#30340;&#38543;&#26426;&#36807;&#31243;&#65292;&#23427;&#23545;&#24212;&#20110;&#20989;&#25968;&#30340;$L_q$&#27491;&#21017;&#21270;&#12290;&#20851;&#38190;&#27493;&#39588;&#26159;&#36890;&#36807;&#20174;&#22823;&#22411;&#26925;&#22278;&#36718;&#24275;&#20998;&#24067;&#26063;&#20013;&#36873;&#25321;&#26469;&#25351;&#23450;&#19968;&#33268;&#30340;&#22810;&#20803;$q$-&#25351;&#25968;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
Regularization is one of the most fundamental topics in optimization, statistics and machine learning. To get sparsity in estimating a parameter $u\in\mbR^d$, an $\ell_q$ penalty term, $\Vert u\Vert_q$, is usually added to the objective function. What is the probabilistic distribution corresponding to such $\ell_q$ penalty? What is the correct stochastic process corresponding to $\Vert u\Vert_q$ when we model functions $u\in L^q$? This is important for statistically modeling large dimensional objects, e.g. images, with penalty to preserve certainty properties, e.g. edges in the image. In this work, we generalize the $q$-exponential distribution (with density proportional to) $\exp{(- \half|u|^q)}$ to a stochastic process named \emph{$Q$-exponential (Q-EP) process} that corresponds to the $L_q$ regularization of functions. The key step is to specify consistent multivariate $q$-exponential distributions by choosing from a large family of elliptic contour distributions. The work is closel
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20107;&#20214;&#35302;&#21457;&#31639;&#27861;ET-GP-UCB&#65292;&#29992;&#20110;&#35299;&#20915;&#26102;&#21464;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#25506;&#32034;&#21644;&#24320;&#21457;&#30340;&#26435;&#34913;&#38382;&#39064;&#12290;&#36890;&#36807;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#27010;&#29575;&#22343;&#21248;&#35823;&#24046;&#30028;&#65292;&#31639;&#27861;&#33021;&#22815;&#22312;&#26410;&#30693;&#21464;&#21270;&#36895;&#29575;&#30340;&#24773;&#20917;&#19979;&#33258;&#36866;&#24212;&#22320;&#36866;&#24212;&#23454;&#38469;&#30340;&#26102;&#38388;&#21464;&#21270;&#12290;&#25968;&#20540;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;ET-GP-UCB&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#19978;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2208.10790</link><description>&lt;p&gt;
&#20107;&#20214;&#35302;&#21457;&#30340;&#26102;&#21464;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Event-Triggered Time-Varying Bayesian Optimization. (arXiv:2208.10790v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.10790
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20107;&#20214;&#35302;&#21457;&#31639;&#27861;ET-GP-UCB&#65292;&#29992;&#20110;&#35299;&#20915;&#26102;&#21464;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#25506;&#32034;&#21644;&#24320;&#21457;&#30340;&#26435;&#34913;&#38382;&#39064;&#12290;&#36890;&#36807;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#27010;&#29575;&#22343;&#21248;&#35823;&#24046;&#30028;&#65292;&#31639;&#27861;&#33021;&#22815;&#22312;&#26410;&#30693;&#21464;&#21270;&#36895;&#29575;&#30340;&#24773;&#20917;&#19979;&#33258;&#36866;&#24212;&#22320;&#36866;&#24212;&#23454;&#38469;&#30340;&#26102;&#38388;&#21464;&#21270;&#12290;&#25968;&#20540;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;ET-GP-UCB&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#19978;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#26102;&#21464;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;TVBO&#65289;&#39034;&#24207;&#20248;&#21270;&#26102;&#21464;&#30446;&#26631;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#20854;&#20013;&#65292;&#20851;&#38190;&#25361;&#25112;&#26159;&#22312;&#26102;&#38388;&#21464;&#21270;&#19979;&#30340;&#21208;&#25506;&#19982;&#24320;&#21457;&#30340;&#26435;&#34913;&#12290;&#24403;&#21069;&#30340;TVBO&#26041;&#27861;&#38656;&#35201;&#23545;&#21464;&#21270;&#36895;&#29575;&#26377;&#20808;&#39564;&#30693;&#35782;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#21464;&#21270;&#36895;&#29575;&#36890;&#24120;&#26159;&#26410;&#30693;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20107;&#20214;&#35302;&#21457;&#31639;&#27861;ET-GP-UCB&#65292;&#23427;&#23558;&#20248;&#21270;&#38382;&#39064;&#35270;&#20026;&#38745;&#24577;&#38382;&#39064;&#65292;&#30452;&#21040;&#22312;&#32447;&#26816;&#27979;&#21040;&#30446;&#26631;&#20989;&#25968;&#30340;&#21464;&#21270;&#24182;&#37325;&#32622;&#25968;&#25454;&#38598;&#12290;&#36825;&#20351;&#24471;&#31639;&#27861;&#33021;&#22815;&#36866;&#24212;&#23454;&#38469;&#30340;&#26102;&#38388;&#21464;&#21270;&#65292;&#32780;&#19981;&#38656;&#35201;&#20808;&#39564;&#30693;&#35782;&#12290;&#20107;&#20214;&#35302;&#21457;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#20013;&#20351;&#29992;&#30340;&#27010;&#29575;&#22343;&#21248;&#35823;&#24046;&#30028;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;ET-GP-UCB&#30340;&#36951;&#25022;&#30028;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#23427;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#19978;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#32467;&#26524;&#34920;&#26126;ET-GP-UCB&#21487;&#24191;&#27867;&#24212;&#29992;&#20110;&#19981;&#21516;&#30340;&#35774;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of sequentially optimizing a time-varying objective function using time-varying Bayesian optimization (TVBO). Here, the key challenge is the exploration-exploitation trade-off under time variations. Current approaches to TVBO require prior knowledge of a constant rate of change. However, in practice, the rate of change is usually unknown. We propose an event-triggered algorithm, ET-GP-UCB, that treats the optimization problem as static until it detects changes in the objective function online and then resets the dataset. This allows the algorithm to adapt to realized temporal changes without the need for prior knowledge. The event-trigger is based on probabilistic uniform error bounds used in Gaussian process regression. We provide regret bounds for ET-GP-UCB and show in numerical experiments that it outperforms state-of-the-art algorithms on synthetic and real-world data. Furthermore, these results demonstrate that ET-GP-UCB is readily applicable to various set
&lt;/p&gt;</description></item><item><title>&#21452;&#37325;PC&#31639;&#27861;&#36890;&#36807;&#21033;&#29992;&#21327;&#26041;&#24046;&#21644;&#31934;&#24230;&#30697;&#38453;&#20043;&#38388;&#30340;&#21453;&#21521;&#20851;&#31995;&#65292;&#23454;&#29616;&#20102;CI&#27979;&#35797;&#65292;&#33021;&#22815;&#24674;&#22797;&#27491;&#30830;&#30340;&#31561;&#20215;&#31867;&#65292;&#24182;&#21487;&#23545;&#20114;&#34917;&#35843;&#33410;&#38598;&#30340;&#20559;&#30456;&#20851;&#36827;&#34892;&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2112.09036</link><description>&lt;p&gt;
&#21452;&#37325;PC&#31639;&#27861;&#21450;&#20854;&#23545;&#39640;&#26031;&#24615;&#36136;&#22312;&#36125;&#21494;&#26031;&#32593;&#32476;&#32467;&#26500;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
The Dual PC Algorithm and the Role of Gaussianity for Structure Learning of Bayesian Networks. (arXiv:2112.09036v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.09036
&lt;/p&gt;
&lt;p&gt;
&#21452;&#37325;PC&#31639;&#27861;&#36890;&#36807;&#21033;&#29992;&#21327;&#26041;&#24046;&#21644;&#31934;&#24230;&#30697;&#38453;&#20043;&#38388;&#30340;&#21453;&#21521;&#20851;&#31995;&#65292;&#23454;&#29616;&#20102;CI&#27979;&#35797;&#65292;&#33021;&#22815;&#24674;&#22797;&#27491;&#30830;&#30340;&#31561;&#20215;&#31867;&#65292;&#24182;&#21487;&#23545;&#20114;&#34917;&#35843;&#33410;&#38598;&#30340;&#20559;&#30456;&#20851;&#36827;&#34892;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#22270;&#24418;&#32467;&#26500;&#26159;&#25551;&#36848;&#35768;&#22810;&#22797;&#26434;&#24212;&#29992;&#31243;&#24207;&#20013;&#30340;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#30340;&#20851;&#38190;&#65292;&#20294;&#38754;&#20020;&#30528;&#24040;&#22823;&#30340;&#35745;&#31639;&#25361;&#25112;&#12290;&#22312;&#26576;&#20123;&#20551;&#35774;&#19979;&#65292;&#27969;&#34892;&#30340;PC&#31639;&#27861;&#21487;&#20197;&#36890;&#36807;&#36870;&#21521;&#24037;&#31243;&#21464;&#37327;&#20998;&#24067;&#20013;&#25152;&#20855;&#26377;&#30340;&#26465;&#20214;&#29420;&#31435;&#20851;&#31995;&#26469;&#19968;&#33268;&#22320;&#24674;&#22797;&#27491;&#30830;&#30340;&#31561;&#20215;&#31867;&#12290;&#21452;&#37325;PC&#31639;&#27861;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#26696;&#65292;&#36890;&#36807;&#21033;&#29992;&#21327;&#26041;&#24046;&#21644;&#31934;&#24230;&#30697;&#38453;&#20043;&#38388;&#30340;&#21453;&#21521;&#20851;&#31995;&#26469;&#36827;&#34892;PC&#31639;&#27861;&#20013;&#30340;CI&#27979;&#35797;&#12290;&#36890;&#36807;&#21033;&#29992;&#22359;&#30697;&#38453;&#27714;&#36870;&#65292;&#25105;&#20204;&#36824;&#21487;&#20197;&#23545;&#20114;&#34917;&#65288;&#25110;&#21452;&#37325;&#65289;&#35843;&#33410;&#38598;&#30340;&#20559;&#30456;&#20851;&#36827;&#34892;&#27979;&#35797;&#12290;&#21452;&#37325;PC&#31639;&#27861;&#30340;&#22810;&#20010;CI&#27979;&#35797;&#39318;&#20808;&#32771;&#34385;&#36793;&#32536;&#21644;&#23436;&#20840;&#25490;&#24207;CI&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning the graphical structure of Bayesian networks is key to describing data-generating mechanisms in many complex applications but poses considerable computational challenges. Observational data can only identify the equivalence class of the directed acyclic graph underlying a Bayesian network model, and a variety of methods exist to tackle the problem. Under certain assumptions, the popular PC algorithm can consistently recover the correct equivalence class by reverse-engineering the conditional independence (CI) relationships holding in the variable distribution. The dual PC algorithm is a novel scheme to carry out the CI tests within the PC algorithm by leveraging the inverse relationship between covariance and precision matrices. By exploiting block matrix inversions we can also perform tests on partial correlations of complementary (or dual) conditioning sets. The multiple CI tests of the dual PC algorithm proceed by first considering marginal and full-order CI relationships a
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#21160;&#37327;&#30340;&#38543;&#26426;&#36817;&#31471;&#28857;&#31639;&#27861;&#65288;SPPAM&#65289;&#30340;&#25910;&#25947;&#24615;&#21644;&#31283;&#23450;&#24615;&#65292;&#23637;&#31034;&#20102;SPPAM&#30456;&#27604;&#20110;&#38543;&#26426;&#36817;&#31471;&#28857;&#31639;&#27861;&#65288;SPPA&#65289;&#20855;&#26377;&#26356;&#24555;&#30340;&#32447;&#24615;&#25910;&#25947;&#21644;&#26356;&#22909;&#30340;&#25910;&#32553;&#22240;&#23376;&#12290;</title><link>http://arxiv.org/abs/2111.06171</link><description>&lt;p&gt;
&#24102;&#26377;&#21160;&#37327;&#30340;&#38543;&#26426;&#36817;&#31471;&#28857;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#21644;&#31283;&#23450;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Convergence and Stability of the Stochastic Proximal Point Algorithm with Momentum. (arXiv:2111.06171v5 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.06171
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#21160;&#37327;&#30340;&#38543;&#26426;&#36817;&#31471;&#28857;&#31639;&#27861;&#65288;SPPAM&#65289;&#30340;&#25910;&#25947;&#24615;&#21644;&#31283;&#23450;&#24615;&#65292;&#23637;&#31034;&#20102;SPPAM&#30456;&#27604;&#20110;&#38543;&#26426;&#36817;&#31471;&#28857;&#31639;&#27861;&#65288;SPPA&#65289;&#20855;&#26377;&#26356;&#24555;&#30340;&#32447;&#24615;&#25910;&#25947;&#21644;&#26356;&#22909;&#30340;&#25910;&#32553;&#22240;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#19982;&#21160;&#37327;&#65288;SGDM&#65289;&#26159;&#35768;&#22810;&#20248;&#21270;&#22330;&#26223;&#20013;&#30340;&#20027;&#35201;&#31639;&#27861;&#65292;&#21253;&#25324;&#20984;&#20248;&#21270;&#21644;&#38750;&#20984;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#22312;&#38543;&#26426;&#35774;&#32622;&#20013;&#65292;&#21160;&#37327;&#20250;&#24178;&#25200;&#26799;&#24230;&#22122;&#22768;&#65292;&#36890;&#24120;&#38656;&#35201;&#29305;&#23450;&#30340;&#27493;&#38271;&#21644;&#21160;&#37327;&#36873;&#25321;&#25165;&#33021;&#20445;&#35777;&#25910;&#25947;&#65292;&#20294;&#21152;&#36895;&#24448;&#24448;&#34987;&#24573;&#30053;&#12290;&#30456;&#23545;&#32780;&#35328;&#65292;&#36817;&#31471;&#28857;&#26041;&#27861;&#22240;&#20854;&#25968;&#20540;&#31283;&#23450;&#24615;&#21644;&#23545;&#19981;&#23436;&#32654;&#35843;&#25972;&#30340;&#24377;&#24615;&#32780;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#38543;&#26426;&#21152;&#36895;&#21464;&#20307;&#21364;&#21463;&#21040;&#20102;&#38480;&#21046;&#30340;&#20851;&#27880;&#65306;&#21160;&#37327;&#22914;&#20309;&#24433;&#21709;&#65288;&#38543;&#26426;&#65289;&#36817;&#31471;&#28857;&#26041;&#27861;&#30340;&#31283;&#23450;&#24615;&#20173;&#28982;&#26410;&#32463;&#30740;&#31350;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20851;&#27880;&#24102;&#26377;&#21160;&#37327;&#30340;&#38543;&#26426;&#36817;&#31471;&#28857;&#31639;&#27861;&#65288;SPPAM&#65289;&#30340;&#25910;&#25947;&#24615;&#21644;&#31283;&#23450;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;SPPAM&#30456;&#27604;&#20110;&#24102;&#26377;&#26356;&#22909;&#25910;&#32553;&#22240;&#23376;&#30340;&#38543;&#26426;&#36817;&#31471;&#28857;&#31639;&#27861;&#65288;SPPA&#65289;&#20855;&#26377;&#26356;&#24555;&#30340;&#32447;&#24615;&#25910;&#25947;&#21040;&#19968;&#20010;&#37051;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic gradient descent with momentum (SGDM) is the dominant algorithm in many optimization scenarios, including convex optimization instances and non-convex neural network training. Yet, in the stochastic setting, momentum interferes with gradient noise, often leading to specific step size and momentum choices in order to guarantee convergence, set aside acceleration. Proximal point methods, on the other hand, have gained much attention due to their numerical stability and elasticity against imperfect tuning. Their stochastic accelerated variants though have received limited attention: how momentum interacts with the stability of (stochastic) proximal point methods remains largely unstudied. To address this, we focus on the convergence and stability of the stochastic proximal point algorithm with momentum (SPPAM), and show that SPPAM allows a faster linear convergence to a neighborhood compared to the stochastic proximal point algorithm (SPPA) with a better contraction factor, und
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#34701;&#21512;&#22871;&#32034;&#31243;&#24207;&#30340;&#29702;&#35770;&#24615;&#36136;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#35774;&#35745;&#30697;&#38453;&#21463;&#38480;&#31561;&#36317;&#26465;&#20214;&#65292;&#24471;&#20986;&#20102;&#34701;&#21512;&#22871;&#32034;&#30340;&#20272;&#35745;&#30028;&#38480;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#20272;&#35745;&#35823;&#24046;&#30340;&#20027;&#23548;&#22240;&#32032;&#21462;&#20915;&#20110;&#38750;&#38646;&#31995;&#25968;&#21644;&#20998;&#27573;&#24120;&#25968;&#27573;&#30340;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2110.14298</link><description>&lt;p&gt;
&#22312;&#20998;&#27573;&#24120;&#25968;&#39640;&#32500;&#22238;&#24402;&#31995;&#25968;&#20013;&#36827;&#34892;&#21435;&#22122;&#21644;&#21464;&#28857;&#23450;&#20301;
&lt;/p&gt;
&lt;p&gt;
Denoising and change point localisation in piecewise-constant high-dimensional regression coefficients. (arXiv:2110.14298v2 [math.ST] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.14298
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#34701;&#21512;&#22871;&#32034;&#31243;&#24207;&#30340;&#29702;&#35770;&#24615;&#36136;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#35774;&#35745;&#30697;&#38453;&#21463;&#38480;&#31561;&#36317;&#26465;&#20214;&#65292;&#24471;&#20986;&#20102;&#34701;&#21512;&#22871;&#32034;&#30340;&#20272;&#35745;&#30028;&#38480;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#20272;&#35745;&#35823;&#24046;&#30340;&#20027;&#23548;&#22240;&#32032;&#21462;&#20915;&#20110;&#38750;&#38646;&#31995;&#25968;&#21644;&#20998;&#27573;&#24120;&#25968;&#27573;&#30340;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#34701;&#21512;&#22871;&#32034;&#31243;&#24207;&#30340;&#29702;&#35770;&#29305;&#24615;&#12290;&#35813;&#27169;&#22411;&#20551;&#35774;&#22238;&#24402;&#31995;&#25968;&#26159;&#26377;&#24207;&#19988;&#31232;&#30095;&#30340;&#20998;&#27573;&#24120;&#25968;&#12290;&#23613;&#31649;&#35813;&#26041;&#27861;&#24456;&#21463;&#27426;&#36814;&#65292;&#20294;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#30446;&#21069;&#20165;&#22312;&#35774;&#35745;&#30697;&#38453;&#20026;&#21333;&#20301;&#30697;&#38453;&#30340;&#31616;&#21333;&#24773;&#20917;&#19979;&#25165;&#33021;&#24471;&#21040;&#39640;&#32500;&#24773;&#20917;&#19979;&#30340;&#20272;&#35745;&#35823;&#24046;&#30028;&#38480;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#35774;&#35745;&#30697;&#38453;&#21463;&#38480;&#31561;&#36317;&#26465;&#20214;&#65292;&#38024;&#23545;&#34701;&#21512;&#22871;&#32034;&#20272;&#35745;&#22120;&#65292;&#24182;&#24471;&#20986;&#20102;&#34701;&#21512;&#22871;&#32034;&#30340;&#32422;&#26463;&#29256;&#26412;&#21644;&#24809;&#32602;&#29256;&#26412;&#30340;&#20272;&#35745;&#30028;&#38480;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#20272;&#35745;&#35823;&#24046;&#21487;&#33021;&#30001;&#22871;&#32034;&#25110;&#34701;&#21512;&#22871;&#32034;&#30340;&#36895;&#29575;&#20027;&#23548;&#65292;&#36825;&#21462;&#20915;&#20110;&#38750;&#38646;&#31995;&#25968;&#30340;&#25968;&#37327;&#26159;&#21542;&#22823;&#20110;&#20998;&#27573;&#24120;&#25968;&#27573;&#30340;&#25968;&#37327;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#21518;&#22788;&#29702;&#31243;&#24207;&#26469;&#24674;&#22797;...
&lt;/p&gt;
&lt;p&gt;
We study the theoretical properties of the fused lasso procedure originally proposed by \cite{tibshirani2005sparsity} in the context of a linear regression model in which the regression coefficient are totally ordered and assumed to be sparse and piecewise constant. Despite its popularity, to the best of our knowledge, estimation error bounds in high-dimensional settings have only been obtained for the simple case in which the design matrix is the identity matrix. We formulate a novel restricted isometry condition on the design matrix that is tailored to the fused lasso estimator and derive estimation bounds for both the constrained version of the fused lasso assuming dense coefficients and for its penalised version. We observe that the estimation error can be dominated by either the lasso or the fused lasso rate, depending on whether the number of non-zero coefficient is larger than the number of piece-wise constant segments. Finally, we devise a post-processing procedure to recover t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;FedPower&#30340;&#31639;&#27861;&#65292;&#22312;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#20869;&#35299;&#20915;&#20102;&#29305;&#24449;&#31354;&#38388;&#20272;&#35745;&#30340;&#38544;&#31169;&#21644;&#36890;&#20449;&#25928;&#29575;&#38382;&#39064;&#12290;&#31639;&#27861;&#21033;&#29992;&#24130;&#27861;&#36827;&#34892;&#26412;&#22320;&#36845;&#20195;&#21644;&#20840;&#23616;&#32858;&#21512;&#65292;&#37319;&#29992;&#27491;&#20132;Procrustes&#21464;&#25442;&#21152;&#26435;&#20197;&#23454;&#29616;&#23545;&#40784;&#65292;&#24182;&#24341;&#20837;&#24046;&#20998;&#38544;&#31169;&#20197;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#12290;</title><link>http://arxiv.org/abs/2103.00704</link><description>&lt;p&gt;
FedPower: &#38544;&#31169;&#20445;&#25252;&#30340;&#20998;&#24067;&#24335;&#29305;&#24449;&#31354;&#38388;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
FedPower: Privacy-Preserving Distributed Eigenspace Estimation. (arXiv:2103.00704v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2103.00704
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;FedPower&#30340;&#31639;&#27861;&#65292;&#22312;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#20869;&#35299;&#20915;&#20102;&#29305;&#24449;&#31354;&#38388;&#20272;&#35745;&#30340;&#38544;&#31169;&#21644;&#36890;&#20449;&#25928;&#29575;&#38382;&#39064;&#12290;&#31639;&#27861;&#21033;&#29992;&#24130;&#27861;&#36827;&#34892;&#26412;&#22320;&#36845;&#20195;&#21644;&#20840;&#23616;&#32858;&#21512;&#65292;&#37319;&#29992;&#27491;&#20132;Procrustes&#21464;&#25442;&#21152;&#26435;&#20197;&#23454;&#29616;&#23545;&#40784;&#65292;&#24182;&#24341;&#20837;&#24046;&#20998;&#38544;&#31169;&#20197;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#31354;&#38388;&#20272;&#35745;&#26159;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#23398;&#20013;&#30340;&#22522;&#30784;&#38382;&#39064;&#65292;&#22312;&#20027;&#25104;&#20998;&#20998;&#26512;&#12289;&#32500;&#24230;&#32422;&#31616;&#21644;&#32858;&#31867;&#31561;&#39046;&#22495;&#37117;&#26377;&#24212;&#29992;&#12290;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#36890;&#24120;&#20551;&#35774;&#25968;&#25454;&#26469;&#33258;&#19981;&#21516;&#30340;&#32452;&#32455;&#19988;&#23646;&#20110;&#19981;&#21516;&#32452;&#32455;&#12290;&#25968;&#25454;&#30340;&#20302;&#36890;&#20449;&#33021;&#21147;&#21644;&#21487;&#33021;&#30340;&#38544;&#31169;&#27844;&#28431;&#20351;&#24471;&#29305;&#24449;&#31354;&#38388;&#30340;&#35745;&#31639;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#22312;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#26694;&#26550;&#20869;&#25552;&#20986;&#20102;&#19968;&#31867;&#31639;&#27861;&#65292;&#31216;&#20026;FedPower&#12290;FedPower&#21033;&#29992;&#20102;&#33879;&#21517;&#30340;&#24130;&#27861;&#65292;&#36890;&#36807;&#20132;&#26367;&#36827;&#34892;&#22810;&#20010;&#26412;&#22320;&#24130;&#36845;&#20195;&#21644;&#20840;&#23616;&#32858;&#21512;&#27493;&#39588;&#65292;&#20174;&#32780;&#25552;&#39640;&#36890;&#20449;&#25928;&#29575;&#12290;&#22312;&#32858;&#21512;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#27491;&#20132;Procrustes&#21464;&#25442;&#65288;OPT&#65289;&#23545;&#27599;&#20010;&#26412;&#22320;&#29305;&#24449;&#21521;&#37327;&#30697;&#38453;&#36827;&#34892;&#21152;&#26435;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#23545;&#40784;&#12290;&#20026;&#20102;&#30830;&#20445;&#24378;&#22823;&#30340;&#38544;&#31169;&#20445;&#25252;&#65292;&#25105;&#20204;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#28155;&#21152;&#39640;&#26031;&#22122;&#22768;&#65292;&#37319;&#29992;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#30340;&#27010;&#24565;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;...
&lt;/p&gt;
&lt;p&gt;
Eigenspace estimation is fundamental in machine learning and statistics, which has found applications in PCA, dimension reduction, and clustering, among others. The modern machine learning community usually assumes that data come from and belong to different organizations. The low communication power and the possible privacy breaches of data make the computation of eigenspace challenging. To address these challenges, we propose a class of algorithms called \textsf{FedPower} within the federated learning (FL) framework. \textsf{FedPower} leverages the well-known power method by alternating multiple local power iterations and a global aggregation step, thus improving communication efficiency. In the aggregation, we propose to weight each local eigenvector matrix with {\it Orthogonal Procrustes Transformation} (OPT) for better alignment. To ensure strong privacy protection, we add Gaussian noise in each iteration by adopting the notion of \emph{differential privacy} (DP). We provide conve
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28145;&#24230;&#29305;&#24449;&#24037;&#20855;&#21464;&#37327;&#22238;&#24402;&#65288;DFIV&#65289;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#35266;&#27979;&#25968;&#25454;&#20013;&#24037;&#20855;&#21464;&#37327;&#12289;&#22788;&#29702;&#21464;&#37327;&#21644;&#32467;&#26524;&#21464;&#37327;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#20851;&#31995;&#12290;&#36890;&#36807;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26469;&#23450;&#20041;&#24037;&#20855;&#21464;&#37327;&#21644;&#22788;&#29702;&#21464;&#37327;&#19978;&#30340;&#38750;&#32447;&#24615;&#29305;&#24449;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#20132;&#26367;&#35757;&#32451;&#26426;&#21046;&#20197;&#33719;&#24471;&#33391;&#22909;&#30340;&#31471;&#21040;&#31471;&#24615;&#33021;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22312;&#35745;&#31639;&#19978;&#33719;&#24471;&#39640;&#24230;&#28789;&#27963;&#30340;&#29305;&#24449;&#26144;&#23556;&#12290;</title><link>http://arxiv.org/abs/2010.07154</link><description>&lt;p&gt;
&#22312;&#24037;&#20855;&#21464;&#37327;&#22238;&#24402;&#20013;&#23398;&#20064;&#28145;&#24230;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Learning Deep Features in Instrumental Variable Regression. (arXiv:2010.07154v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2010.07154
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28145;&#24230;&#29305;&#24449;&#24037;&#20855;&#21464;&#37327;&#22238;&#24402;&#65288;DFIV&#65289;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#35266;&#27979;&#25968;&#25454;&#20013;&#24037;&#20855;&#21464;&#37327;&#12289;&#22788;&#29702;&#21464;&#37327;&#21644;&#32467;&#26524;&#21464;&#37327;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#20851;&#31995;&#12290;&#36890;&#36807;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26469;&#23450;&#20041;&#24037;&#20855;&#21464;&#37327;&#21644;&#22788;&#29702;&#21464;&#37327;&#19978;&#30340;&#38750;&#32447;&#24615;&#29305;&#24449;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#20132;&#26367;&#35757;&#32451;&#26426;&#21046;&#20197;&#33719;&#24471;&#33391;&#22909;&#30340;&#31471;&#21040;&#31471;&#24615;&#33021;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22312;&#35745;&#31639;&#19978;&#33719;&#24471;&#39640;&#24230;&#28789;&#27963;&#30340;&#29305;&#24449;&#26144;&#23556;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24037;&#20855;&#21464;&#37327;&#65288;IV&#65289;&#22238;&#24402;&#26159;&#19968;&#31181;&#22312;&#35266;&#27979;&#25968;&#25454;&#20013;&#21033;&#29992;&#20165;&#36890;&#36807;&#22788;&#29702;&#24433;&#21709;&#32467;&#26524;&#30340;&#24037;&#20855;&#21464;&#37327;&#26469;&#23398;&#20064;&#28151;&#28102;&#30340;&#22788;&#29702;&#21644;&#32467;&#26524;&#21464;&#37327;&#20043;&#38388;&#22240;&#26524;&#20851;&#31995;&#30340;&#26631;&#20934;&#31574;&#30053;&#12290;&#22312;&#20256;&#32479;&#30340;IV&#22238;&#24402;&#20013;&#65292;&#23398;&#20064;&#20998;&#20026;&#20004;&#20010;&#38454;&#27573;&#65306;&#38454;&#27573;1&#20174;&#24037;&#20855;&#21464;&#37327;&#21040;&#22788;&#29702;&#21464;&#37327;&#36827;&#34892;&#32447;&#24615;&#22238;&#24402;&#65307;&#38454;&#27573;2&#22312;&#24037;&#20855;&#21464;&#37327;&#30340;&#26465;&#20214;&#19979;&#65292;&#20174;&#22788;&#29702;&#21464;&#37327;&#21040;&#32467;&#26524;&#21464;&#37327;&#36827;&#34892;&#32447;&#24615;&#22238;&#24402;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21363;&#28145;&#24230;&#29305;&#24449;&#24037;&#20855;&#21464;&#37327;&#22238;&#24402;&#65288;DFIV&#65289;&#65292;&#29992;&#20110;&#22788;&#29702;&#24037;&#20855;&#21464;&#37327;&#12289;&#22788;&#29702;&#21464;&#37327;&#21644;&#32467;&#26524;&#21464;&#37327;&#20043;&#38388;&#21487;&#33021;&#26159;&#38750;&#32447;&#24615;&#20851;&#31995;&#30340;&#24773;&#20917;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26469;&#23450;&#20041;&#24037;&#20855;&#21464;&#37327;&#21644;&#22788;&#29702;&#21464;&#37327;&#19978;&#30340;&#20449;&#24687;&#24615;&#38750;&#32447;&#24615;&#29305;&#24449;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20132;&#26367;&#35757;&#32451;&#26426;&#21046;&#26469;&#35757;&#32451;&#36825;&#20123;&#29305;&#24449;&#65292;&#20197;&#20445;&#35777;&#36890;&#36807;&#32452;&#21512;&#38454;&#27573;1&#21644;&#38454;&#27573;2&#33719;&#24471;&#33391;&#22909;&#30340;&#31471;&#21040;&#31471;&#24615;&#33021;&#65292;&#20174;&#32780;&#22312;&#35745;&#31639;&#19978;&#33719;&#24471;&#39640;&#24230;&#28789;&#27963;&#30340;&#29305;&#24449;&#26144;&#23556;&#12290;
&lt;/p&gt;
&lt;p&gt;
Instrumental variable (IV) regression is a standard strategy for learning causal relationships between confounded treatment and outcome variables from observational data by utilizing an instrumental variable, which affects the outcome only through the treatment. In classical IV regression, learning proceeds in two stages: stage 1 performs linear regression from the instrument to the treatment; and stage 2 performs linear regression from the treatment to the outcome, conditioned on the instrument. We propose a novel method, deep feature instrumental variable regression (DFIV), to address the case where relations between instruments, treatments, and outcomes may be nonlinear. In this case, deep neural nets are trained to define informative nonlinear features on the instruments and treatments. We propose an alternating training regime for these features to ensure good end-to-end performance when composing stages 1 and 2, thus obtaining highly flexible feature maps in a computationally eff
&lt;/p&gt;</description></item></channel></rss>