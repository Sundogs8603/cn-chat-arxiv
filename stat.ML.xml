<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#22312;&#24102;&#23574;&#23792;&#30340;Wigner&#27169;&#22411;&#20013;&#20351;&#29992;AIC&#31867;&#22411;&#20934;&#21017;&#36827;&#34892;&#19968;&#33268;&#24615;&#27169;&#22411;&#36873;&#25321;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#23545;&#20110;$\gamma &gt; 2$&#65292;&#35813;&#20934;&#21017;&#26159;&#24378;&#19968;&#33268;&#20272;&#35745;&#30340;&#65292;&#32780;&#23545;&#20110;$\gamma &lt; 2$&#65292;&#23427;&#20960;&#20046;&#32943;&#23450;&#20250;&#39640;&#20272;&#23574;&#23792;&#25968;&#37327;$k$&#12290;&#27492;&#22806;&#65292;&#20316;&#32773;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#20351;AIC&#24369;&#19968;&#33268;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#26576;&#20010;&#36719;&#26368;&#23567;&#21270;&#22120;&#26159;&#24378;&#19968;&#33268;&#20272;&#35745;&#30340;&#12290;</title><link>http://arxiv.org/abs/2307.12982</link><description>&lt;p&gt;
&#22312;&#24102;&#23574;&#23792;&#30340;Wigner&#27169;&#22411;&#20013;&#36890;&#36807;AIC&#31867;&#22411;&#20934;&#21017;&#36827;&#34892;&#19968;&#33268;&#24615;&#27169;&#22411;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Consistent model selection in the spiked Wigner model via AIC-type criteria. (arXiv:2307.12982v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12982
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#22312;&#24102;&#23574;&#23792;&#30340;Wigner&#27169;&#22411;&#20013;&#20351;&#29992;AIC&#31867;&#22411;&#20934;&#21017;&#36827;&#34892;&#19968;&#33268;&#24615;&#27169;&#22411;&#36873;&#25321;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#23545;&#20110;$\gamma &gt; 2$&#65292;&#35813;&#20934;&#21017;&#26159;&#24378;&#19968;&#33268;&#20272;&#35745;&#30340;&#65292;&#32780;&#23545;&#20110;$\gamma &lt; 2$&#65292;&#23427;&#20960;&#20046;&#32943;&#23450;&#20250;&#39640;&#20272;&#23574;&#23792;&#25968;&#37327;$k$&#12290;&#27492;&#22806;&#65292;&#20316;&#32773;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#20351;AIC&#24369;&#19968;&#33268;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#26576;&#20010;&#36719;&#26368;&#23567;&#21270;&#22120;&#26159;&#24378;&#19968;&#33268;&#20272;&#35745;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32771;&#34385;&#24102;&#23574;&#23792;&#30340;Wigner&#27169;&#22411;\[ X = \sum_{i = 1}^k \lambda_i u_i u_i^\top + \sigma G, \]&#20854;&#20013;$G$&#26159;&#19968;&#20010;$N \times N$&#30340;GOE&#38543;&#26426;&#30697;&#38453;&#65292;&#32780;&#29305;&#24449;&#20540;$\lambda_i$&#37117;&#26159;&#26377;&#23574;&#23792;&#30340;&#65292;&#21363;&#36229;&#36807;&#20102;Baik-Ben Arous-P\'ech\'e (BBP)&#30340;&#38408;&#20540;$\sigma$&#12290;&#25105;&#20204;&#32771;&#34385;&#24418;&#24335;&#20026;\[ -2 \, (\text{&#26368;&#22823;&#21270;&#30340;&#23545;&#25968;&#20284;&#28982;}) + \gamma \, (\text{&#21442;&#25968;&#25968;&#37327;}) \]&#30340;AIC&#31867;&#22411;&#27169;&#22411;&#36873;&#25321;&#20934;&#21017;&#65292;&#29992;&#20110;&#20272;&#35745;&#23574;&#23792;&#25968;&#37327;$k$&#12290;&#23545;&#20110;$\gamma &gt; 2$&#65292;&#19978;&#36848;&#20934;&#21017;&#26159;&#24378;&#19968;&#33268;&#20272;&#35745;&#30340;&#65292;&#21069;&#25552;&#26159;$\lambda_k &gt; \lambda_{\gamma}$&#65292;&#20854;&#20013;$\lambda_{\gamma}$&#26159;&#20005;&#26684;&#39640;&#20110;BBP&#38408;&#20540;&#30340;&#38408;&#20540;&#65292;&#32780;&#23545;&#20110;$\gamma &lt; 2$&#65292;&#23427;&#20960;&#20046;&#32943;&#23450;&#20250;&#39640;&#20272;$k$&#12290;&#34429;&#28982;AIC&#65288;&#23545;&#24212;&#20110;$\gamma = 2$&#65289;&#24182;&#38750;&#24378;&#19968;&#33268;&#20272;&#35745;&#65292;&#20294;&#25105;&#20204;&#35777;&#26126;&#65292;&#21462;$\gamma = 2 + \delta_N$&#65292;&#20854;&#20013;$\delta_N \to 0$&#19988;$\delta_N \gg N^{-2/3}$&#65292;&#20250;&#24471;&#21040;$k$&#30340;&#24369;&#19968;&#33268;&#20272;&#35745;&#37327;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;AIC&#30340;&#26576;&#20010;&#36719;&#26368;&#23567;&#21270;&#22120;&#26159;&#24378;&#19968;&#33268;&#20272;&#35745;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consider the spiked Wigner model \[ X = \sum_{i = 1}^k \lambda_i u_i u_i^\top + \sigma G, \] where $G$ is an $N \times N$ GOE random matrix, and the eigenvalues $\lambda_i$ are all spiked, i.e. above the Baik-Ben Arous-P\'ech\'e (BBP) threshold $\sigma$. We consider AIC-type model selection criteria of the form \[ -2 \, (\text{maximised log-likelihood}) + \gamma \, (\text{number of parameters}) \] for estimating the number $k$ of spikes. For $\gamma &gt; 2$, the above criterion is strongly consistent provided $\lambda_k &gt; \lambda_{\gamma}$, where $\lambda_{\gamma}$ is a threshold strictly above the BBP threshold, whereas for $\gamma &lt; 2$, it almost surely overestimates $k$. Although AIC (which corresponds to $\gamma = 2$) is not strongly consistent, we show that taking $\gamma = 2 + \delta_N$, where $\delta_N \to 0$ and $\delta_N \gg N^{-2/3}$, results in a weakly consistent estimator of $k$. We also show that a certain soft minimiser of AIC is strongly consistent.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20559;&#22909;&#30340;&#25919;&#31574;&#23398;&#20064;&#26041;&#27861;&#22312;&#31163;&#32447;&#24773;&#22659;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#20013;&#30340;&#20248;&#21183;&#65292;&#24182;&#36890;&#36807;&#25913;&#36827;&#24314;&#27169;&#21644;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#36825;&#19968;&#26041;&#27861;&#30456;&#27604;&#20854;&#20182;&#25919;&#31574;&#23398;&#20064;&#26041;&#27861;&#20855;&#26377;&#26356;&#20302;&#30340;&#27425;&#20248;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.12975</link><description>&lt;p&gt;
&#20174;&#20154;&#31867;&#20559;&#22909;&#20013;&#23398;&#20064;&#30340;&#25919;&#31574;&#22312;&#24773;&#22659;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#20013;&#30340;&#21487;&#35777;&#26126;&#20248;&#21183;
&lt;/p&gt;
&lt;p&gt;
Provable Benefits of Policy Learning from Human Preferences in Contextual Bandit Problems. (arXiv:2307.12975v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12975
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20559;&#22909;&#30340;&#25919;&#31574;&#23398;&#20064;&#26041;&#27861;&#22312;&#31163;&#32447;&#24773;&#22659;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#20013;&#30340;&#20248;&#21183;&#65292;&#24182;&#36890;&#36807;&#25913;&#36827;&#24314;&#27169;&#21644;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#36825;&#19968;&#26041;&#27861;&#30456;&#27604;&#20854;&#20182;&#25919;&#31574;&#23398;&#20064;&#26041;&#27861;&#20855;&#26377;&#26356;&#20302;&#30340;&#27425;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20915;&#31574;&#38382;&#39064;&#20013;&#65292;&#22870;&#21169;&#24037;&#31243;&#26159;&#19968;&#20010;&#20851;&#38190;&#30340;&#20219;&#21153;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#24448;&#24448;&#19981;&#23384;&#22312;&#26126;&#26174;&#30340;&#22870;&#21169;&#20989;&#25968;&#36873;&#25321;&#12290;&#22240;&#27492;&#65292;&#19968;&#31181;&#24120;&#35265;&#30340;&#26041;&#27861;&#26159;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#24341;&#20837;&#20154;&#31867;&#21453;&#39304;&#65292;&#24182;&#21033;&#29992;&#36825;&#31181;&#21453;&#39304;&#26469;&#23398;&#20064;&#22870;&#21169;&#20989;&#25968;&#12290;&#22312;&#20351;&#29992;&#20154;&#31867;&#21453;&#39304;&#30340;&#25152;&#26377;&#25919;&#31574;&#23398;&#20064;&#26041;&#27861;&#20013;&#65292;&#22522;&#20110;&#20559;&#22909;&#30340;&#26041;&#27861;&#22312;&#26368;&#36817;&#30340;&#23454;&#35777;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#22914;InstructGPT&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#29702;&#35770;&#65292;&#21487;&#20197;&#35777;&#26126;&#22312;&#31163;&#32447;&#24773;&#22659;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#20013;&#65292;&#22522;&#20110;&#20559;&#22909;&#30340;&#26041;&#27861;&#20855;&#26377;&#26174;&#33879;&#30340;&#20248;&#21183;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;&#22312;&#20154;&#31867;&#35780;&#20998;&#26679;&#26412;&#19978;&#36816;&#34892;&#25919;&#31574;&#23398;&#20064;&#26041;&#27861;&#30340;&#24314;&#27169;&#21644;&#27425;&#20248;&#24615;&#20998;&#26512;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#20854;&#19982;&#22522;&#20110;&#20559;&#22909;&#30340;&#26041;&#27861;&#30340;&#27425;&#20248;&#24615;&#20445;&#35777;&#36827;&#34892;&#27604;&#36739;&#65292;&#24182;&#34920;&#26126;&#22522;&#20110;&#20559;&#22909;&#30340;&#26041;&#27861;&#20139;&#26377;&#26356;&#20302;&#30340;&#27425;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
A crucial task in decision-making problems is reward engineering. It is common in practice that no obvious choice of reward function exists. Thus, a popular approach is to introduce human feedback during training and leverage such feedback to learn a reward function. Among all policy learning methods that use human feedback, preference-based methods have demonstrated substantial success in recent empirical applications such as InstructGPT. In this work, we develop a theory that provably shows the benefits of preference-based methods in offline contextual bandits. In particular, we improve the modeling and suboptimality analysis for running policy learning methods on human-scored samples directly. Then, we compare it with the suboptimality guarantees of preference-based methods and show that preference-based methods enjoy lower suboptimality.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22823;&#25968;&#25454;-&#20379;&#24212;&#38142;&#31649;&#29702;&#26694;&#26550;&#65292;&#36890;&#36807;&#25968;&#25454;&#39044;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#23454;&#29616;&#20379;&#24212;&#38142;&#39044;&#27979;&#65292;&#20248;&#21270;&#25805;&#20316;&#31649;&#29702;&#12289;&#36879;&#26126;&#24230;&#65292;&#24182;&#35752;&#35770;&#20102;&#24187;&#24433;&#24211;&#23384;&#23545;&#39044;&#27979;&#30340;&#19981;&#21033;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2307.12971</link><description>&lt;p&gt;
&#22823;&#25968;&#25454;-&#20379;&#24212;&#38142;&#31649;&#29702;&#26694;&#26550;&#30340;&#39044;&#27979;&#65306;&#25968;&#25454;&#39044;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Big Data - Supply Chain Management Framework for Forecasting: Data Preprocessing and Machine Learning Techniques. (arXiv:2307.12971v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12971
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22823;&#25968;&#25454;-&#20379;&#24212;&#38142;&#31649;&#29702;&#26694;&#26550;&#65292;&#36890;&#36807;&#25968;&#25454;&#39044;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#23454;&#29616;&#20379;&#24212;&#38142;&#39044;&#27979;&#65292;&#20248;&#21270;&#25805;&#20316;&#31649;&#29702;&#12289;&#36879;&#26126;&#24230;&#65292;&#24182;&#35752;&#35770;&#20102;&#24187;&#24433;&#24211;&#23384;&#23545;&#39044;&#27979;&#30340;&#19981;&#21033;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#31995;&#32479;&#22320;&#35782;&#21035;&#21644;&#27604;&#36739;&#20998;&#26512;&#26368;&#20808;&#36827;&#30340;&#20379;&#24212;&#38142;&#39044;&#27979;&#31574;&#30053;&#21644;&#25216;&#26415;&#12290;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#23558;&#22823;&#25968;&#25454;&#20998;&#26512;&#24212;&#29992;&#20110;&#20379;&#24212;&#38142;&#31649;&#29702;&#20013;&#65292;&#21253;&#25324;&#38382;&#39064;&#35782;&#21035;&#12289;&#25968;&#25454;&#26469;&#28304;&#12289;&#25506;&#32034;&#24615;&#25968;&#25454;&#20998;&#26512;&#12289;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#35757;&#32451;&#12289;&#36229;&#21442;&#25968;&#35843;&#20248;&#12289;&#24615;&#33021;&#35780;&#20272;&#21644;&#20248;&#21270;&#65292;&#20197;&#21450;&#39044;&#27979;&#23545;&#20154;&#21147;&#12289;&#24211;&#23384;&#21644;&#25972;&#20010;&#20379;&#24212;&#38142;&#30340;&#24433;&#21709;&#12290;&#39318;&#20808;&#35752;&#35770;&#20102;&#26681;&#25454;&#20379;&#24212;&#38142;&#31574;&#30053;&#25910;&#38598;&#25968;&#25454;&#30340;&#38656;&#27714;&#20197;&#21450;&#22914;&#20309;&#25910;&#38598;&#25968;&#25454;&#12290;&#25991;&#31456;&#35752;&#35770;&#20102;&#26681;&#25454;&#21608;&#26399;&#25110;&#20379;&#24212;&#38142;&#30446;&#26631;&#38656;&#35201;&#19981;&#21516;&#31867;&#22411;&#30340;&#39044;&#27979;&#12290;&#25512;&#33616;&#20351;&#29992;&#20379;&#24212;&#38142;&#32489;&#25928;&#25351;&#26631;&#21644;&#35823;&#24046;&#27979;&#37327;&#31995;&#32479;&#26469;&#20248;&#21270;&#34920;&#29616;&#26368;&#20339;&#30340;&#27169;&#22411;&#12290;&#36824;&#35752;&#35770;&#20102;&#24187;&#24433;&#24211;&#23384;&#23545;&#39044;&#27979;&#30340;&#19981;&#21033;&#24433;&#21709;&#20197;&#21450;&#31649;&#29702;&#20915;&#31574;&#20381;&#36182;&#20379;&#24212;&#38142;&#32489;&#25928;&#25351;&#26631;&#26469;&#30830;&#23450;&#27169;&#22411;&#24615;&#33021;&#21442;&#25968;&#21644;&#25913;&#36827;&#36816;&#33829;&#31649;&#29702;&#12289;&#36879;&#26126;&#24230;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article intends to systematically identify and comparatively analyze state-of-the-art supply chain (SC) forecasting strategies and technologies. A novel framework has been proposed incorporating Big Data Analytics in SC Management (problem identification, data sources, exploratory data analysis, machine-learning model training, hyperparameter tuning, performance evaluation, and optimization), forecasting effects on human-workforce, inventory, and overall SC. Initially, the need to collect data according to SC strategy and how to collect them has been discussed. The article discusses the need for different types of forecasting according to the period or SC objective. The SC KPIs and the error-measurement systems have been recommended to optimize the top-performing model. The adverse effects of phantom inventory on forecasting and the dependence of managerial decisions on the SC KPIs for determining model performance parameters and improving operations management, transparency, and 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#24615;&#36172;&#21338;&#26426;&#20013;&#36827;&#34892;&#20219;&#24847;&#27169;&#22411;&#36873;&#25321;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27169;&#25311;&#20840;&#20449;&#24687;&#21453;&#39304;&#23454;&#29616;&#22312;&#36951;&#25022;&#26041;&#38754;&#20855;&#26377;&#25351;&#25968;&#25913;&#36827;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#19981;&#20381;&#36182;&#26102;&#38388;&#30028;&#38480;&#21644;&#32431;&#25506;&#32034;&#38454;&#27573;&#12290;</title><link>http://arxiv.org/abs/2307.12897</link><description>&lt;p&gt;
&#32447;&#24615;&#36172;&#21338;&#26426;&#20013;&#30340;&#20219;&#24847;&#27169;&#22411;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Anytime Model Selection in Linear Bandits. (arXiv:2307.12897v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12897
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#24615;&#36172;&#21338;&#26426;&#20013;&#36827;&#34892;&#20219;&#24847;&#27169;&#22411;&#36873;&#25321;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27169;&#25311;&#20840;&#20449;&#24687;&#21453;&#39304;&#23454;&#29616;&#22312;&#36951;&#25022;&#26041;&#38754;&#20855;&#26377;&#25351;&#25968;&#25913;&#36827;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#19981;&#20381;&#36182;&#26102;&#38388;&#30028;&#38480;&#21644;&#32431;&#25506;&#32034;&#38454;&#27573;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36172;&#21338;&#20248;&#21270;&#20013;&#65292;&#27169;&#22411;&#36873;&#25321;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#65292;&#22240;&#20026;&#23427;&#19981;&#20165;&#38656;&#35201;&#22312;&#34892;&#21160;&#36873;&#25321;&#26041;&#38754;&#24179;&#34913;&#25506;&#32034;&#21644;&#24320;&#21457;&#65292;&#36824;&#38656;&#35201;&#22312;&#27169;&#22411;&#36873;&#25321;&#26041;&#38754;&#24179;&#34913;&#25506;&#32034;&#21644;&#24320;&#21457;&#12290;&#19968;&#31181;&#33258;&#28982;&#30340;&#26041;&#27861;&#26159;&#20381;&#36182;&#20110;&#23558;&#19981;&#21516;&#27169;&#22411;&#35270;&#20026;&#19987;&#23478;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#22312;&#36951;&#25022;&#26041;&#38754;&#19982;&#27169;&#22411;&#25968;&#37327;$M$&#30340;&#35268;&#27169;&#65288;$\text{poly}M$&#65289;&#21576;&#19981;&#33391;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#27934;&#23519;&#26159;&#65292;&#22312;&#32447;&#24615;&#36172;&#21338;&#26426;&#30340;&#27169;&#22411;&#36873;&#25321;&#20013;&#65292;&#25105;&#20204;&#21487;&#20197;&#36890;&#36807;&#26377;&#21033;&#30340;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#26469;&#27169;&#25311;&#20840;&#20449;&#24687;&#21453;&#39304;&#32473;&#22312;&#32447;&#23398;&#20064;&#32773;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#24320;&#21457;&#20986;&#20855;&#26377;&#25351;&#25968;&#25913;&#36827;&#65288;$\log M$&#65289;&#22312;&#36951;&#25022;&#26041;&#38754;&#23545;$M$&#20381;&#36182;&#24615;&#30340;ALEXP&#12290;ALEXP&#22312;&#36951;&#25022;&#26041;&#38754;&#20855;&#26377;&#20219;&#24847;&#20445;&#35777;&#65292;&#24182;&#19988;&#26082;&#19981;&#38656;&#35201;&#23545;&#26102;&#38388;&#30028;$n$&#20855;&#26377;&#30693;&#35782;&#65292;&#20063;&#19981;&#20381;&#36182;&#20110;&#21021;&#22987;&#30340;&#32431;&#25506;&#32034;&#38454;&#27573;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;Lasso&#30340;&#19968;&#31181;&#26032;&#39062;&#30340;&#26102;&#38388;&#22343;&#21248;&#20998;&#26512;&#65292;&#24314;&#31435;&#20102;&#22312;&#32447;&#23398;&#20064;&#21644;&#39640;&#32500;&#32479;&#35745;&#20043;&#38388;&#30340;&#26032;&#36830;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model selection in the context of bandit optimization is a challenging problem, as it requires balancing exploration and exploitation not only for action selection, but also for model selection. One natural approach is to rely on online learning algorithms that treat different models as experts. Existing methods, however, scale poorly ($\text{poly}M$) with the number of models $M$ in terms of their regret. Our key insight is that, for model selection in linear bandits, we can emulate full-information feedback to the online learner with a favorable bias-variance trade-off. This allows us to develop ALEXP, which has an exponentially improved ($\log M$) dependence on $M$ for its regret. ALEXP has anytime guarantees on its regret, and neither requires knowledge of the horizon $n$, nor relies on an initial purely exploratory stage. Our approach utilizes a novel time-uniform analysis of the Lasso, establishing a new connection between online learning and high-dimensional statistics.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#27493;&#36827;&#29305;&#24449;&#36873;&#25321;&#30340;&#25351;&#25968;&#38543;&#26426;&#22270;&#27169;&#22411; (ERGMs) &#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#31038;&#20132;&#32593;&#32476;&#24314;&#27169;&#20013;&#30340;&#22810;&#20010;&#25361;&#25112;&#24182;&#22686;&#24378;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.12862</link><description>&lt;p&gt;
Stochastic Step-wise Feature Selection for Exponential Random Graph Models (ERGMs)
&lt;/p&gt;
&lt;p&gt;
Stochastic Step-wise Feature Selection for Exponential Random Graph Models (ERGMs). (arXiv:2307.12862v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12862
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#27493;&#36827;&#29305;&#24449;&#36873;&#25321;&#30340;&#25351;&#25968;&#38543;&#26426;&#22270;&#27169;&#22411; (ERGMs) &#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#31038;&#20132;&#32593;&#32476;&#24314;&#27169;&#20013;&#30340;&#22810;&#20010;&#25361;&#25112;&#24182;&#22686;&#24378;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#32593;&#32476;&#30340;&#32479;&#35745;&#20998;&#26512;&#20026;&#21508;&#20010;&#31185;&#23398;&#39046;&#22495;&#25552;&#20379;&#20102;&#23453;&#36149;&#30340;&#35265;&#35299;&#65292;&#28982;&#32780;&#65292;&#30001;&#20110;&#35745;&#31639;&#36127;&#25285;&#27785;&#37325;&#19988;&#38656;&#35201;&#32771;&#34385;&#35266;&#23519;&#21040;&#30340;&#32593;&#32476;&#20381;&#36182;&#20851;&#31995;&#65292;&#20934;&#30830;&#24314;&#27169;&#32593;&#32476;&#20173;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#25351;&#25968;&#38543;&#26426;&#22270;&#27169;&#22411;&#65288;ERGM&#65289;&#20316;&#20026;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#25216;&#26415;&#65292;&#22312;&#31038;&#20132;&#32593;&#32476;&#24314;&#27169;&#20013;&#24212;&#29992;&#20110;&#25429;&#25417;&#36890;&#36807;&#25972;&#21512;&#20869;&#29983;&#21464;&#37327;&#26469;&#20307;&#29616;&#32593;&#32476;&#20381;&#36182;&#20851;&#31995;&#12290;&#28982;&#32780;&#65292;&#20351;&#29992;ERGM&#23384;&#22312;&#22810;&#20010;&#25361;&#25112;&#65292;&#21253;&#25324;ERGM&#36864;&#21270;&#38382;&#39064;&#65292;&#20174;&#32780;&#29983;&#25104;&#19981;&#29616;&#23454;&#19988;&#27627;&#26080;&#24847;&#20041;&#30340;&#32593;&#32476;&#32467;&#26500;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#24182;&#22686;&#24378;&#21327;&#20316;&#32593;&#32476;&#30340;&#24314;&#27169;&#33021;&#21147;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#27979;&#35797;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#19987;&#27880;&#20110;ERGM&#20869;&#29983;&#21464;&#37327;&#30340;&#36873;&#25321;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26088;&#22312;&#24212;&#23545;&#35745;&#31639;&#36127;&#25285;&#65292;&#24182;&#25913;&#21892;&#23545;&#35266;&#23519;&#21040;&#30340;&#32593;&#32476;&#20381;&#36182;&#20851;&#31995;&#30340;&#36866;&#24212;&#24615;&#65292;&#20174;&#32780;&#20419;&#36827;&#26356;&#20934;&#30830;&#21644;&#26377;&#24847;&#20041;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Statistical analysis of social networks provides valuable insights into complex network interactions across various scientific disciplines. However, accurate modeling of networks remains challenging due to the heavy computational burden and the need to account for observed network dependencies. Exponential Random Graph Models (ERGMs) have emerged as a promising technique used in social network modeling to capture network dependencies by incorporating endogenous variables. Nevertheless, using ERGMs poses multiple challenges, including the occurrence of ERGM degeneracy, which generates unrealistic and meaningless network structures. To address these challenges and enhance the modeling of collaboration networks, we propose and test a novel approach that focuses on endogenous variable selection within ERGMs. Our method aims to overcome the computational burden and improve the accommodation of observed network dependencies, thereby facilitating more accurate and meaningful interpretations o
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20351;&#29992;&#24352;&#37327;&#20998;&#35299;&#21644;&#33298;&#23572;&#22810;&#39033;&#24335;&#29702;&#35770;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#26631;&#20934;&#39640;&#26031;&#20998;&#24067;&#19979;&#23398;&#20064;$k$&#20010;ReLU&#28608;&#27963;&#30340;&#32447;&#24615;&#32452;&#21512;&#12290;&#36825;&#20010;&#31639;&#27861;&#22312;&#26679;&#26412;&#21644;&#35745;&#31639;&#22797;&#26434;&#24615;&#19978;&#25509;&#36817;&#26368;&#20248;&#65292;&#24182;&#33021;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#25214;&#21040;&#36739;&#23567;&#30340;&#39640;&#38454;&#30697;&#35823;&#24046;&#24352;&#37327;&#12290;</title><link>http://arxiv.org/abs/2307.12840</link><description>&lt;p&gt;
&#36890;&#36807;&#33298;&#23572;&#22810;&#39033;&#24335;&#39640;&#25928;&#23398;&#20064;&#20855;&#26377;&#19968;&#20010;&#38544;&#34255;&#23618;&#30340;ReLU&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Efficiently Learning One-Hidden-Layer ReLU Networks via Schur Polynomials. (arXiv:2307.12840v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12840
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#24352;&#37327;&#20998;&#35299;&#21644;&#33298;&#23572;&#22810;&#39033;&#24335;&#29702;&#35770;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#26631;&#20934;&#39640;&#26031;&#20998;&#24067;&#19979;&#23398;&#20064;$k$&#20010;ReLU&#28608;&#27963;&#30340;&#32447;&#24615;&#32452;&#21512;&#12290;&#36825;&#20010;&#31639;&#27861;&#22312;&#26679;&#26412;&#21644;&#35745;&#31639;&#22797;&#26434;&#24615;&#19978;&#25509;&#36817;&#26368;&#20248;&#65292;&#24182;&#33021;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#25214;&#21040;&#36739;&#23567;&#30340;&#39640;&#38454;&#30697;&#35823;&#24046;&#24352;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#26631;&#20934;&#39640;&#26031;&#20998;&#24067;&#19979;&#65292;&#20851;&#20110;&#24179;&#26041;&#25439;&#22833;&#30340;PAC&#23398;&#20064;$k$&#20010;ReLU&#28608;&#27963;&#30340;&#32447;&#24615;&#32452;&#21512;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#38024;&#23545;&#36825;&#20010;&#23398;&#20064;&#20219;&#21153;&#30340;&#19968;&#31181;&#39640;&#25928;&#31639;&#27861;&#65292;&#20854;&#26679;&#26412;&#21644;&#35745;&#31639;&#22797;&#26434;&#24615;&#20026;$(dk/\epsilon)^{O(k)}$&#65292;&#20854;&#20013;$\epsilon&gt;0$&#26159;&#30446;&#26631;&#31934;&#24230;&#12290;&#20043;&#21069;&#30340;&#24037;&#20316;&#32473;&#20986;&#20102;&#19968;&#20010;&#22797;&#26434;&#24615;&#20026;$(dk/\epsilon)^{h(k)}$&#30340;&#31639;&#27861;&#65292;&#20854;&#20013;&#20989;&#25968;$h(k)$&#22312;$k$&#19978;&#30340;&#35268;&#27169;&#26159;&#36229;&#22810;&#39033;&#24335;&#30340;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#30456;&#20851;&#32479;&#35745;&#26597;&#35810;&#31639;&#27861;&#31867;&#20013;&#25509;&#36817;&#26368;&#20248;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#20351;&#29992;&#24352;&#37327;&#20998;&#35299;&#26469;&#35782;&#21035;&#19968;&#20010;&#23376;&#31354;&#38388;&#65292;&#20351;&#24471;&#25152;&#26377;$O(k)$&#38454;&#30697;&#22312;&#27491;&#20132;&#26041;&#21521;&#19978;&#37117;&#24456;&#23567;&#12290;&#20854;&#20998;&#26512;&#22522;&#20110;&#33298;&#23572;&#22810;&#39033;&#24335;&#29702;&#35770;&#65292;&#20197;&#26174;&#31034;&#36739;&#20302;&#38454;&#35823;&#24046;&#24352;&#37327;&#30340;&#24773;&#20917;&#19979;&#65292;&#26356;&#39640;&#38454;&#30340;&#35823;&#24046;&#24352;&#37327;&#20063;&#24456;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of PAC learning a linear combination of $k$ ReLU activations under the standard Gaussian distribution on $\mathbb{R}^d$ with respect to the square loss. Our main result is an efficient algorithm for this learning task with sample and computational complexity $(dk/\epsilon)^{O(k)}$, where $\epsilon&gt;0$ is the target accuracy. Prior work had given an algorithm for this problem with complexity $(dk/\epsilon)^{h(k)}$, where the function $h(k)$ scales super-polynomially in $k$. Interestingly, the complexity of our algorithm is near-optimal within the class of Correlational Statistical Query algorithms. At a high-level, our algorithm uses tensor decomposition to identify a subspace such that all the $O(k)$-order moments are small in the orthogonal directions. Its analysis makes essential use of the theory of Schur polynomials to show that the higher-moment error tensors are small given that the lower-order ones are.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20445;&#25345;&#25490;&#24207;&#30340;&#24178;&#39044;&#20998;&#24067;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#20844;&#24179;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#19968;&#20010;&#29702;&#24819;&#30340;&#19990;&#30028;&#20013;&#28040;&#38500;&#21463;&#20445;&#25252;&#23646;&#24615;&#23545;&#30446;&#26631;&#30340;&#22240;&#26524;&#24433;&#21709;&#26469;&#20943;&#23569;&#19981;&#20844;&#24179;&#12290;</title><link>http://arxiv.org/abs/2307.12797</link><description>&lt;p&gt;
&#36890;&#36807;&#20445;&#25345;&#25490;&#24207;&#30340;&#24178;&#39044;&#20998;&#24067;&#23454;&#29616;&#22240;&#26524;&#20844;&#24179;&#30340;&#26426;&#22120;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Causal Fair Machine Learning via Rank-Preserving Interventional Distributions. (arXiv:2307.12797v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12797
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20445;&#25345;&#25490;&#24207;&#30340;&#24178;&#39044;&#20998;&#24067;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#20844;&#24179;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#19968;&#20010;&#29702;&#24819;&#30340;&#19990;&#30028;&#20013;&#28040;&#38500;&#21463;&#20445;&#25252;&#23646;&#24615;&#23545;&#30446;&#26631;&#30340;&#22240;&#26524;&#24433;&#21709;&#26469;&#20943;&#23569;&#19981;&#20844;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#26524;&#30456;&#21516;&#30340;&#20010;&#20307;&#24471;&#21040;&#30456;&#21516;&#30340;&#23545;&#24453;&#65292;&#32780;&#19981;&#21516;&#30340;&#20010;&#20307;&#24471;&#21040;&#19981;&#21516;&#30340;&#23545;&#24453;&#65292;&#37027;&#20040;&#19968;&#20010;&#20915;&#31574;&#34987;&#23450;&#20041;&#20026;&#20844;&#24179;&#30340;&#12290;&#26681;&#25454;&#36825;&#20010;&#23450;&#20041;&#65292;&#22312;&#35774;&#35745;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20197;&#20943;&#23569;&#33258;&#21160;&#20915;&#31574;&#31995;&#32479;&#20013;&#30340;&#19981;&#20844;&#24179;&#26102;&#65292;&#24517;&#39035;&#24341;&#20837;&#22240;&#26524;&#24605;&#32771;&#26469;&#24341;&#20837;&#21463;&#20445;&#25252;&#23646;&#24615;&#12290;&#26681;&#25454;&#26368;&#36817;&#30340;&#25552;&#35758;&#65292;&#25105;&#20204;&#23558;&#20010;&#20307;&#23450;&#20041;&#20026;&#22312;&#19968;&#20010;&#20551;&#35774;&#30340;&#12289;&#29702;&#24819;&#30340;&#65288;FiND&#65289;&#19990;&#30028;&#20013;&#26159;&#35268;&#33539;&#19978;&#30456;&#31561;&#30340;&#65292;&#36825;&#20010;&#19990;&#30028;&#20013;&#21463;&#20445;&#25252;&#23646;&#24615;&#23545;&#30446;&#26631;&#27809;&#26377;&#65288;&#30452;&#25509;&#25110;&#38388;&#25509;&#65289;&#30340;&#22240;&#26524;&#24433;&#21709;&#12290;&#25105;&#20204;&#25552;&#20986;&#20445;&#25345;&#25490;&#24207;&#30340;&#24178;&#39044;&#20998;&#24067;&#26469;&#23450;&#20041;&#36825;&#20010;FiND&#19990;&#30028;&#30340;&#20272;&#35745;&#30446;&#26631;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#20272;&#35745;&#26041;&#27861;&#12290;&#36890;&#36807;&#27169;&#25311;&#21644;&#23454;&#35777;&#25968;&#25454;&#30340;&#39564;&#35777;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#26041;&#27861;&#21644;&#29983;&#25104;&#27169;&#22411;&#30340;&#35780;&#20215;&#26631;&#20934;&#12290;&#36890;&#36807;&#36825;&#20123;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#24178;&#39044;&#26041;&#27861;&#26377;&#25928;&#22320;&#35782;&#21035;&#20986;&#26368;&#21463;&#27495;&#35270;&#30340;&#20010;&#20307;&#24182;&#20943;&#23569;&#19981;&#20844;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
A decision can be defined as fair if equal individuals are treated equally and unequals unequally. Adopting this definition, the task of designing machine learning models that mitigate unfairness in automated decision-making systems must include causal thinking when introducing protected attributes. Following a recent proposal, we define individuals as being normatively equal if they are equal in a fictitious, normatively desired (FiND) world, where the protected attribute has no (direct or indirect) causal effect on the target. We propose rank-preserving interventional distributions to define an estimand of this FiND world and a warping method for estimation. Evaluation criteria for both the method and resulting model are presented and validated through simulations and empirical data. With this, we show that our warping approach effectively identifies the most discriminated individuals and mitigates unfairness.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23581;&#35797;&#23558;&#22522;&#20110;&#27010;&#24565;&#28608;&#27963;&#21521;&#37327;&#65288;CAVs&#65289;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#33041;&#30005;&#22270;&#65288;EEG&#65289;&#25968;&#25454;&#30340;&#35299;&#37322;&#24615;&#65292;&#36890;&#36807;&#23450;&#20041;&#35299;&#37322;&#24615;&#27010;&#24565;&#21644;&#36873;&#25321;&#30456;&#20851;&#25968;&#25454;&#38598;&#65292;&#20197;&#23454;&#29616;&#23545;&#22823;&#35268;&#27169;&#36716;&#25442;&#22120;&#27169;&#22411;&#20013;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#29702;&#35299;&#12290;</title><link>http://arxiv.org/abs/2307.12745</link><description>&lt;p&gt;
EEG&#36716;&#25442;&#22120;&#27169;&#22411;&#30340;&#22522;&#20110;&#27010;&#24565;&#30340;&#21487;&#35299;&#37322;&#24615;
&lt;/p&gt;
&lt;p&gt;
Concept-based explainability for an EEG transformer model. (arXiv:2307.12745v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12745
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23581;&#35797;&#23558;&#22522;&#20110;&#27010;&#24565;&#28608;&#27963;&#21521;&#37327;&#65288;CAVs&#65289;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#33041;&#30005;&#22270;&#65288;EEG&#65289;&#25968;&#25454;&#30340;&#35299;&#37322;&#24615;&#65292;&#36890;&#36807;&#23450;&#20041;&#35299;&#37322;&#24615;&#27010;&#24565;&#21644;&#36873;&#25321;&#30456;&#20851;&#25968;&#25454;&#38598;&#65292;&#20197;&#23454;&#29616;&#23545;&#22823;&#35268;&#27169;&#36716;&#25442;&#22120;&#27169;&#22411;&#20013;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30001;&#20110;&#20854;&#35268;&#27169;&#12289;&#32467;&#26500;&#20197;&#21450;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#20869;&#22312;&#38543;&#26426;&#24615;&#32780;&#21464;&#24471;&#22797;&#26434;&#12290;&#36873;&#25321;&#25968;&#25454;&#38598;&#21644;&#24402;&#32435;&#20559;&#35265;&#20063;&#22686;&#21152;&#20102;&#39069;&#22806;&#30340;&#22797;&#26434;&#24615;&#12290;&#20026;&#20102;&#35299;&#37322;&#36825;&#20123;&#25361;&#25112;&#65292;Kim&#31561;&#20154;&#65288;2018&#65289;&#24341;&#20837;&#20102;&#27010;&#24565;&#28608;&#27963;&#21521;&#37327;&#65288;CAVs&#65289;&#65292;&#26088;&#22312;&#20174;&#20154;&#31867;&#23545;&#40784;&#30340;&#27010;&#24565;&#35282;&#24230;&#29702;&#35299;&#28145;&#24230;&#27169;&#22411;&#30340;&#20869;&#37096;&#29366;&#24577;&#12290;&#36825;&#20123;&#27010;&#24565;&#23545;&#24212;&#20110;&#28508;&#22312;&#31354;&#38388;&#20013;&#30340;&#26041;&#21521;&#65292;&#20351;&#29992;&#32447;&#24615;&#21028;&#21035;&#27861;&#36827;&#34892;&#35782;&#21035;&#12290;&#23613;&#31649;&#35813;&#26041;&#27861;&#39318;&#20808;&#24212;&#29992;&#20110;&#22270;&#20687;&#20998;&#31867;&#65292;&#20294;&#21518;&#26469;&#34987;&#36866;&#24212;&#21040;&#21253;&#25324;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#22312;&#20869;&#30340;&#20854;&#20182;&#39046;&#22495;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23581;&#35797;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;Kostas&#31561;&#20154;&#30340;BENDR&#65288;2021&#65289;&#30340;&#33041;&#30005;&#22270;&#65288;EEG&#65289;&#25968;&#25454;&#65292;&#20197;&#23454;&#29616;&#21487;&#35299;&#37322;&#24615;&#12290;&#36825;&#39033;&#21162;&#21147;&#30340;&#20851;&#38190;&#37096;&#20998;&#21253;&#25324;&#23450;&#20041;&#35299;&#37322;&#24615;&#27010;&#24565;&#21644;&#36873;&#25321;&#30456;&#20851;&#25968;&#25454;&#38598;&#20197;&#23558;&#27010;&#24565;&#19982;&#28508;&#22312;&#31354;&#38388;&#30456;&#23545;&#24212;&#12290;&#25105;&#20204;&#30340;&#37325;&#28857;&#26159;EEG&#27010;&#24565;&#24418;&#25104;&#30340;&#20004;&#20010;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning models are complex due to their size, structure, and inherent randomness in training procedures. Additional complexity arises from the selection of datasets and inductive biases. Addressing these challenges for explainability, Kim et al. (2018) introduced Concept Activation Vectors (CAVs), which aim to understand deep models' internal states in terms of human-aligned concepts. These concepts correspond to directions in latent space, identified using linear discriminants. Although this method was first applied to image classification, it was later adapted to other domains, including natural language processing. In this work, we attempt to apply the method to electroencephalogram (EEG) data for explainability in Kostas et al.'s BENDR (2021), a large-scale transformer model. A crucial part of this endeavor involves defining the explanatory concepts and selecting relevant datasets to ground concepts in the latent space. Our focus is on two mechanisms for EEG concept formation
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#30456;&#20851;&#36335;&#24452;&#26469;&#38477;&#20302;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#20013;&#30340;&#26041;&#24046;&#65292;&#20174;&#32780;&#20272;&#35745;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#35299;&#30340;&#20989;&#25968;&#12290;&#36890;&#36807;&#25919;&#31574;&#26799;&#24230;&#21644;&#24378;&#21270;&#23398;&#20064;&#25216;&#26415;&#65292;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#26368;&#20248;&#30456;&#20851;&#20989;&#25968;&#24182;&#36827;&#34892;&#26657;&#20934;&#12290;&#36825;&#19982;&#26368;&#22823;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#26377;&#20851;&#12290;</title><link>http://arxiv.org/abs/2307.12703</link><description>&lt;p&gt;
&#25919;&#31574;&#26799;&#24230;&#26368;&#20248;&#30456;&#20851;&#25628;&#32034;&#29992;&#20110;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#21644;&#26368;&#22823;&#26368;&#20248;&#20256;&#36755;&#20013;&#30340;&#26041;&#24046;&#38477;&#20302;
&lt;/p&gt;
&lt;p&gt;
Policy Gradient Optimal Correlation Search for Variance Reduction in Monte Carlo simulation and Maximum Optimal Transport. (arXiv:2307.12703v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12703
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#30456;&#20851;&#36335;&#24452;&#26469;&#38477;&#20302;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#20013;&#30340;&#26041;&#24046;&#65292;&#20174;&#32780;&#20272;&#35745;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#35299;&#30340;&#20989;&#25968;&#12290;&#36890;&#36807;&#25919;&#31574;&#26799;&#24230;&#21644;&#24378;&#21270;&#23398;&#20064;&#25216;&#26415;&#65292;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#26368;&#20248;&#30456;&#20851;&#20989;&#25968;&#24182;&#36827;&#34892;&#26657;&#20934;&#12290;&#36825;&#19982;&#26368;&#22823;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#26377;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20272;&#35745;$f(X_T)$&#30340;&#26041;&#24046;&#38477;&#20302;&#31639;&#27861;&#65292;&#20854;&#20013;$X$&#26159;&#26576;&#20010;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#35299;&#65292;$f$&#26159;&#19968;&#20010;&#27979;&#35797;&#20989;&#25968;&#12290;&#26032;&#30340;&#20272;&#35745;&#22120;&#26159;$(f(X^1_T) + f(X^2_T))/2$&#65292;&#20854;&#20013;$X^1$&#21644;$X^2$&#20855;&#26377;&#19982;$X$&#30456;&#21516;&#30340;&#36793;&#38469;&#20998;&#24067;&#65292;&#20294;&#36335;&#24452;&#19978;&#23384;&#22312;&#30456;&#20851;&#24615;&#65292;&#20197;&#38477;&#20302;&#26041;&#24046;&#12290;&#26368;&#20248;&#30456;&#20851;&#20989;&#25968;$\rho$&#30001;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#65292;&#24182;&#36890;&#36807;&#25919;&#31574;&#26799;&#24230;&#21644;&#24378;&#21270;&#23398;&#20064;&#25216;&#26415;&#22312;$(X^1, X^2)$&#30340;&#36712;&#36857;&#19978;&#36827;&#34892;&#26657;&#20934;&#12290;&#22312;&#32473;&#23450;&#36793;&#38469;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#25214;&#21040;&#26368;&#20248;&#32806;&#21512;&#19982;&#26368;&#22823;&#26368;&#20248;&#20256;&#36755;&#26377;&#20851;&#32852;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new algorithm for variance reduction when estimating $f(X_T)$ where $X$ is the solution to some stochastic differential equation and $f$ is a test function. The new estimator is $(f(X^1_T) + f(X^2_T))/2$, where $X^1$ and $X^2$ have same marginal law as $X$ but are pathwise correlated so that to reduce the variance. The optimal correlation function $\rho$ is approximated by a deep neural network and is calibrated along the trajectories of $(X^1, X^2)$ by policy gradient and reinforcement learning techniques. Finding an optimal coupling given marginal laws has links with maximum optimal transport.
&lt;/p&gt;</description></item><item><title>InVAErt&#32593;&#32476;&#26159;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#26512;&#21644;&#21512;&#25104;&#29289;&#29702;&#31995;&#32479;&#65292;&#20855;&#26377;&#27169;&#22411;&#21453;&#28436;&#21644;&#21487;&#35782;&#21035;&#24615;&#20998;&#26512;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.12586</link><description>&lt;p&gt;
InVAErt&#32593;&#32476;&#65306;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#30340;&#26694;&#26550;&#29992;&#20110;&#20223;&#30495;&#12289;&#25512;&#29702;&#21644;&#21487;&#35782;&#21035;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
InVAErt networks: a data-driven framework for emulation, inference and identifiability analysis. (arXiv:2307.12586v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12586
&lt;/p&gt;
&lt;p&gt;
InVAErt&#32593;&#32476;&#26159;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#26512;&#21644;&#21512;&#25104;&#29289;&#29702;&#31995;&#32479;&#65292;&#20855;&#26377;&#27169;&#22411;&#21453;&#28436;&#21644;&#21487;&#35782;&#21035;&#24615;&#20998;&#26512;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#65292;&#22522;&#20110;&#29289;&#29702;&#30340;&#31995;&#32479;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#21644;&#28145;&#24230;&#23398;&#20064;&#20027;&#35201;&#29992;&#20110;&#20223;&#30495;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#25968;&#25454;&#39537;&#21160;&#32467;&#26500;&#25552;&#20379;&#30340;&#20986;&#33394;&#28789;&#27963;&#24615;&#34920;&#26126;&#24212;&#23558;&#35813;&#34920;&#31034;&#25193;&#23637;&#21040;&#31995;&#32479;&#32508;&#21512;&#30340;&#20854;&#20182;&#26041;&#38754;&#65292;&#21253;&#25324;&#27169;&#22411;&#21453;&#28436;&#21644;&#21487;&#35782;&#21035;&#24615;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;InVAErt&#32593;&#32476;&#65292;&#36825;&#26159;&#19968;&#20010;&#32508;&#21512;&#30340;&#25968;&#25454;&#39537;&#21160;&#20998;&#26512;&#21644;&#21512;&#25104;&#21442;&#25968;&#21270;&#29289;&#29702;&#31995;&#32479;&#30340;&#26694;&#26550;&#65292;&#23427;&#20351;&#29992;&#30830;&#23450;&#24615;&#32534;&#30721;&#22120;&#21644;&#35299;&#30721;&#22120;&#34920;&#31034;&#21069;&#21521;&#21644;&#36870;&#21521;&#35299;&#26144;&#23556;&#65292;&#29992;&#24402;&#19968;&#21270;&#27969;&#26469;&#25429;&#25417;&#31995;&#32479;&#36755;&#20986;&#30340;&#27010;&#29575;&#20998;&#24067;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#21464;&#20998;&#32534;&#30721;&#22120;&#26469;&#23398;&#20064;&#36755;&#20837;&#21644;&#36755;&#20986;&#20043;&#38388;&#32570;&#20047;&#21452;&#23556;&#24615;&#30340;&#32039;&#20945;&#28508;&#22312;&#34920;&#31034;&#12290;&#25105;&#20204;&#27491;&#24335;&#30740;&#31350;&#20102;&#25439;&#22833;&#20989;&#25968;&#20013;&#24809;&#32602;&#31995;&#25968;&#30340;&#36873;&#25321;&#21644;&#28508;&#22312;&#31354;&#38388;&#37319;&#26679;&#31574;&#30053;&#65292;&#22240;&#20026;&#25105;&#20204;&#21457;&#29616;&#36825;&#20123;&#22240;&#32032;&#20250;&#26174;&#33879;&#24433;&#21709;&#35757;&#32451;&#21644;&#27979;&#35797;&#24615;&#33021;&#12290;&#25105;&#20204;&#26377;&#25928;&#22320;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Use of generative models and deep learning for physics-based systems is currently dominated by the task of emulation. However, the remarkable flexibility offered by data-driven architectures would suggest to extend this representation to other aspects of system synthesis including model inversion and identifiability. We introduce inVAErt (pronounced \emph{invert}) networks, a comprehensive framework for data-driven analysis and synthesis of parametric physical systems which uses a deterministic encoder and decoder to represent the forward and inverse solution maps, normalizing flow to capture the probabilistic distribution of system outputs, and a variational encoder designed to learn a compact latent representation for the lack of bijectivity between inputs and outputs. We formally investigate the selection of penalty coefficients in the loss function and strategies for latent space sampling, since we find that these significantly affect both training and testing performance. We valid
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#21435;&#20559;&#26426;&#22120;&#23398;&#20064;&#65288;ADML&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#25968;&#25454;&#39537;&#21160;&#30340;&#27169;&#22411;&#36873;&#25321;&#21644;&#21435;&#20559;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#65292;&#26500;&#24314;&#20102;&#28176;&#36827;&#32447;&#24615;&#12289;&#33258;&#36866;&#24212;&#21644;&#36229;&#25928;&#29575;&#30340;&#36335;&#24452;&#21487;&#24494;&#30340;&#21151;&#33021;&#20272;&#35745;&#22120;&#12290;</title><link>http://arxiv.org/abs/2307.12544</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#21435;&#20559;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#21450;&#25968;&#25454;&#39537;&#21160;&#27169;&#22411;&#36873;&#25321;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Adaptive debiased machine learning using data-driven model selection techniques. (arXiv:2307.12544v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12544
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#21435;&#20559;&#26426;&#22120;&#23398;&#20064;&#65288;ADML&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#25968;&#25454;&#39537;&#21160;&#30340;&#27169;&#22411;&#36873;&#25321;&#21644;&#21435;&#20559;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#65292;&#26500;&#24314;&#20102;&#28176;&#36827;&#32447;&#24615;&#12289;&#33258;&#36866;&#24212;&#21644;&#36229;&#25928;&#29575;&#30340;&#36335;&#24452;&#21487;&#24494;&#30340;&#21151;&#33021;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#21442;&#25968;&#25512;&#26029;&#20013;&#30340;&#21435;&#20559;&#26426;&#22120;&#23398;&#20064;&#20272;&#35745;&#22120;&#21487;&#33021;&#23384;&#22312;&#36807;&#39640;&#30340;&#21464;&#24322;&#24615;&#21644;&#19981;&#31283;&#23450;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#21435;&#20559;&#26426;&#22120;&#23398;&#20064;&#65288;ADML&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#25968;&#25454;&#39537;&#21160;&#30340;&#27169;&#22411;&#36873;&#25321;&#21644;&#21435;&#20559;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#65292;&#26500;&#24314;&#28176;&#36827;&#32447;&#24615;&#12289;&#33258;&#36866;&#24212;&#21644;&#36229;&#25928;&#29575;&#30340;&#36335;&#24452;&#21487;&#24494;&#30340;&#21151;&#33021;&#20272;&#35745;&#22120;&#12290;&#36890;&#36807;&#20174;&#25968;&#25454;&#20013;&#30452;&#25509;&#23398;&#20064;&#27169;&#22411;&#32467;&#26500;&#65292;ADML&#36991;&#20813;&#20102;&#27169;&#22411;&#35268;&#33539;&#38169;&#35823;&#24341;&#20837;&#30340;&#20559;&#24046;&#65292;&#24182;&#25670;&#33073;&#20102;&#21442;&#25968;&#21270;&#21644;&#21322;&#21442;&#25968;&#21270;&#27169;&#22411;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Debiased machine learning estimators for nonparametric inference of smooth functionals of the data-generating distribution can suffer from excessive variability and instability. For this reason, practitioners may resort to simpler models based on parametric or semiparametric assumptions. However, such simplifying assumptions may fail to hold, and estimates may then be biased due to model misspecification. To address this problem, we propose Adaptive Debiased Machine Learning (ADML), a nonparametric framework that combines data-driven model selection and debiased machine learning techniques to construct asymptotically linear, adaptive, and superefficient estimators for pathwise differentiable functionals. By learning model structure directly from data, ADML avoids the bias introduced by model misspecification and remains free from the restrictions of parametric and semiparametric models. While they may exhibit irregular behavior for the target parameter in a nonparametric statistical mo
&lt;/p&gt;</description></item><item><title>&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Wasserstein&#32479;&#35745;&#22312;&#20223;&#23556;&#21464;&#24418;&#32479;&#35745;&#27169;&#22411;&#20013;&#30340;&#20449;&#24687;&#20960;&#20309;&#29305;&#24449;&#65292;&#27604;&#36739;&#20102;&#20449;&#24687;&#20960;&#20309;&#21644;Wasserstein&#20960;&#20309;&#30340;&#20272;&#35745;&#22120;&#30340;&#20248;&#32570;&#28857;&#65292;&#24182;&#21457;&#29616;Wasserstein&#20272;&#35745;&#37327;&#22312;&#26925;&#22278;&#23545;&#31216;&#20223;&#23556;&#21464;&#24418;&#27169;&#22411;&#20013;&#26159;&#30697;&#20272;&#35745;&#37327;&#65292;&#22312;&#27874;&#24418;&#20026;&#39640;&#26031;&#20998;&#24067;&#26102;&#19982;&#20449;&#24687;&#20960;&#20309;&#20272;&#35745;&#37327;&#37325;&#21512;&#12290;</title><link>http://arxiv.org/abs/2307.12508</link><description>&lt;p&gt;
&#24418;&#29366;&#21644;&#20223;&#23556;&#21464;&#24418;&#30340;Wasserstein&#32479;&#35745;&#30340;&#20449;&#24687;&#20960;&#20309;
&lt;/p&gt;
&lt;p&gt;
Information Geometry of Wasserstein Statistics on Shapes and Affine Deformations. (arXiv:2307.12508v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12508
&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Wasserstein&#32479;&#35745;&#22312;&#20223;&#23556;&#21464;&#24418;&#32479;&#35745;&#27169;&#22411;&#20013;&#30340;&#20449;&#24687;&#20960;&#20309;&#29305;&#24449;&#65292;&#27604;&#36739;&#20102;&#20449;&#24687;&#20960;&#20309;&#21644;Wasserstein&#20960;&#20309;&#30340;&#20272;&#35745;&#22120;&#30340;&#20248;&#32570;&#28857;&#65292;&#24182;&#21457;&#29616;Wasserstein&#20272;&#35745;&#37327;&#22312;&#26925;&#22278;&#23545;&#31216;&#20223;&#23556;&#21464;&#24418;&#27169;&#22411;&#20013;&#26159;&#30697;&#20272;&#35745;&#37327;&#65292;&#22312;&#27874;&#24418;&#20026;&#39640;&#26031;&#20998;&#24067;&#26102;&#19982;&#20449;&#24687;&#20960;&#20309;&#20272;&#35745;&#37327;&#37325;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#20960;&#20309;&#21644;Wasserstein&#20960;&#20309;&#26159;&#20171;&#32461;&#27010;&#29575;&#20998;&#24067;&#27969;&#24418;&#20013;&#30340;&#20004;&#20010;&#20027;&#35201;&#32467;&#26500;&#65292;&#23427;&#20204;&#25429;&#25417;&#20102;&#19981;&#21516;&#30340;&#29305;&#24449;&#12290;&#25105;&#20204;&#22312;&#20223;&#23556;&#21464;&#24418;&#32479;&#35745;&#27169;&#22411;&#30340;Li&#21644;Zhao&#65288;2023&#65289;&#26694;&#26550;&#20013;&#30740;&#31350;&#20102;Wasserstein&#20960;&#20309;&#30340;&#29305;&#24449;&#65292;&#23427;&#26159;&#20301;&#32622;-&#23610;&#24230;&#27169;&#22411;&#30340;&#22810;&#32500;&#27867;&#21270;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#22522;&#20110;&#20449;&#24687;&#20960;&#20309;&#21644;Wasserstein&#20960;&#20309;&#30340;&#20272;&#35745;&#22120;&#30340;&#20248;&#28857;&#21644;&#32570;&#28857;&#12290;&#22312;Wasserstein&#20960;&#20309;&#20013;&#65292;&#27010;&#29575;&#20998;&#24067;&#30340;&#24418;&#29366;&#21644;&#20223;&#23556;&#21464;&#24418;&#26159;&#20998;&#31163;&#30340;&#65292;&#34920;&#26126;&#22312;&#23545;&#27874;&#24418;&#25200;&#21160;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#21516;&#26102;&#65292;&#20250;&#25439;&#22833;Fisher&#25928;&#29575;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#26925;&#22278;&#23545;&#31216;&#20223;&#23556;&#21464;&#24418;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;Wasserstein&#20272;&#35745;&#37327;&#26159;&#30697;&#20272;&#35745;&#37327;&#12290;&#23427;&#19982;&#20449;&#24687;&#20960;&#20309;&#20272;&#35745;&#37327;&#65288;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#37327;&#65289;&#20165;&#22312;&#27874;&#24418;&#20026;&#39640;&#26031;&#20998;&#24067;&#26102;&#37325;&#21512;&#12290;Wasserstein&#25928;&#29575;&#30340;&#20316;&#29992;&#26159;...
&lt;/p&gt;
&lt;p&gt;
Information geometry and Wasserstein geometry are two main structures introduced in a manifold of probability distributions, and they capture its different characteristics. We study characteristics of Wasserstein geometry in the framework of Li and Zhao (2023) for the affine deformation statistical model, which is a multi-dimensional generalization of the location-scale model. We compare merits and demerits of estimators based on information geometry and Wasserstein geometry. The shape of a probability distribution and its affine deformation are separated in the Wasserstein geometry, showing its robustness against the waveform perturbation in exchange for the loss in Fisher efficiency. We show that the Wasserstein estimator is the moment estimator in the case of the elliptically symmetric affine deformation model. It coincides with the information-geometrical estimator (maximum-likelihood estimator) when and only when the waveform is Gaussian. The role of the Wasserstein efficiency is 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#31616;&#21333;&#30340;&#31639;&#27861;&#26469;&#23398;&#20064;&#27973;&#23618;&#32593;&#32476;&#65292;&#20854;&#36816;&#34892;&#26102;&#38388;&#26356;&#30701;&#19988;&#21482;&#38656;&#35201;&#19968;&#20010;&#38454;&#27573;&#21363;&#21487;&#12290;</title><link>http://arxiv.org/abs/2307.12496</link><description>&lt;p&gt;
&#23398;&#20064;&#27973;&#23618;&#32593;&#32476;&#30340;&#19968;&#31181;&#26356;&#24555;&#26356;&#31616;&#21333;&#30340;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A faster and simpler algorithm for learning shallow networks. (arXiv:2307.12496v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12496
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#31616;&#21333;&#30340;&#31639;&#27861;&#26469;&#23398;&#20064;&#27973;&#23618;&#32593;&#32476;&#65292;&#20854;&#36816;&#34892;&#26102;&#38388;&#26356;&#30701;&#19988;&#21482;&#38656;&#35201;&#19968;&#20010;&#38454;&#27573;&#21363;&#21487;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#37325;&#26032;&#30740;&#31350;&#20102;&#23398;&#20064;&#32447;&#24615;&#32452;&#21512;&#30340;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#32473;&#20986;&#20102;&#19968;&#31181;&#22312;&#22810;&#20010;&#38454;&#27573;&#20869;&#36816;&#34892;&#30340;&#31639;&#27861;&#65292;&#20854;&#26102;&#38388;&#22797;&#26434;&#24230;&#20026;$(d/\varepsilon)^{\mathrm{quasipoly}(k)}$&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#19968;&#20010;&#26356;&#31616;&#21333;&#30340;&#21333;&#38454;&#27573;&#29256;&#26412;&#30340;&#35813;&#31639;&#27861;&#23601;&#36275;&#22815;&#20102;&#65292;&#32780;&#19988;&#20854;&#36816;&#34892;&#26102;&#38388;&#21482;&#26377;$(d/\varepsilon)^{O(k^2)}$&#12290;
&lt;/p&gt;
&lt;p&gt;
We revisit the well-studied problem of learning a linear combination of $k$ ReLU activations given labeled examples drawn from the standard $d$-dimensional Gaussian measure. Chen et al. [CDG+23] recently gave the first algorithm for this problem to run in $\text{poly}(d,1/\varepsilon)$ time when $k = O(1)$, where $\varepsilon$ is the target error. More precisely, their algorithm runs in time $(d/\varepsilon)^{\mathrm{quasipoly}(k)}$ and learns over multiple stages. Here we show that a much simpler one-stage version of their algorithm suffices, and moreover its runtime is only $(d/\varepsilon)^{O(k^2)}$.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#27169;&#22411;&#30340;&#32479;&#35745;&#26694;&#26550;&#65292;&#29992;&#20110;&#19981;&#20934;&#30830;&#27010;&#29575;&#39044;&#27979;&#25512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#24182;&#32771;&#34385;&#20102;&#31934;&#30830;&#27010;&#29575;&#36817;&#20284;&#27169;&#22411;&#26080;&#20851;&#30340;&#19981;&#20934;&#30830;&#25512;&#29702;&#26694;&#26550;&#30340;&#29305;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.12472</link><description>&lt;p&gt;
&#26080;&#27169;&#22411;&#24191;&#20041;&#22522;&#20934;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Model-free generalized fiducial inference. (arXiv:2307.12472v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12472
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#27169;&#22411;&#30340;&#32479;&#35745;&#26694;&#26550;&#65292;&#29992;&#20110;&#19981;&#20934;&#30830;&#27010;&#29575;&#39044;&#27979;&#25512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#24182;&#32771;&#34385;&#20102;&#31934;&#30830;&#27010;&#29575;&#36817;&#20284;&#27169;&#22411;&#26080;&#20851;&#30340;&#19981;&#20934;&#30830;&#25512;&#29702;&#26694;&#26550;&#30340;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#26426;&#22120;&#23398;&#20064;&#20013;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#30340;&#23433;&#20840;&#21487;&#38752;&#24615;&#30340;&#38656;&#27714;&#65292;&#26412;&#25991;&#25552;&#20986;&#24182;&#21457;&#23637;&#20102;&#19968;&#31181;&#26080;&#27169;&#22411;&#30340;&#32479;&#35745;&#26694;&#26550;&#65292;&#29992;&#20110;&#19981;&#20934;&#30830;&#27010;&#29575;&#39044;&#27979;&#25512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#25552;&#20379;&#39044;&#27979;&#38598;&#30340;&#24418;&#24335;&#65292;&#23454;&#29616;&#20102;&#23545;&#31532;&#19968;&#31867;&#38169;&#35823;&#30340;&#26377;&#38480;&#26679;&#26412;&#25511;&#21046;&#65292;&#36825;&#19982;&#19968;&#33268;&#24615;&#39044;&#27979;&#38598;&#20855;&#26377;&#30456;&#21516;&#30340;&#23646;&#24615;&#65292;&#20294;&#36825;&#31181;&#26032;&#26041;&#27861;&#36824;&#25552;&#20379;&#20102;&#26356;&#28789;&#27963;&#30340;&#19981;&#20934;&#30830;&#27010;&#29575;&#25512;&#29702;&#24037;&#20855;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#25552;&#20986;&#24182;&#32771;&#34385;&#20102;&#19968;&#31181;&#31934;&#30830;&#27010;&#29575;&#36817;&#20284;&#27169;&#22411;&#26080;&#20851;&#30340;&#19981;&#20934;&#30830;&#25512;&#29702;&#26694;&#26550;&#30340;&#29702;&#35770;&#21644;&#23454;&#35777;&#29305;&#24615;&#12290;&#36890;&#36807;&#23558;&#20449;&#24565;/&#21487;&#20449;&#24230;&#24230;&#37327;&#23545;&#36817;&#20284;&#20026;&#22312;&#21487;&#20449;&#21306;&#38388;&#20013;&#30340;[&#22312;&#26576;&#31181;&#24847;&#20041;&#19978;&#26368;&#20248;]&#27010;&#29575;&#24230;&#37327;&#65292;&#26159;&#25193;&#22823;&#22312;&#32479;&#35745;&#21644;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#25512;&#24191;&#19981;&#20934;&#30830;&#27010;&#29575;&#25512;&#29702;&#26041;&#27861;&#25152;&#38656;&#30340;&#20851;&#38190;&#35299;&#20915;&#26041;&#26696;&#65292;&#30446;&#21069;&#22312;&#32479;&#35745;&#21644;
&lt;/p&gt;
&lt;p&gt;
Motivated by the need for the development of safe and reliable methods for uncertainty quantification in machine learning, I propose and develop ideas for a model-free statistical framework for imprecise probabilistic prediction inference. This framework facilitates uncertainty quantification in the form of prediction sets that offer finite sample control of type 1 errors, a property shared with conformal prediction sets, but this new approach also offers more versatile tools for imprecise probabilistic reasoning. Furthermore, I propose and consider the theoretical and empirical properties of a precise probabilistic approximation to the model-free imprecise framework. Approximating a belief/plausibility measure pair by an [optimal in some sense] probability measure in the credal set is a critical resolution needed for the broader adoption of imprecise probabilistic approaches to inference in statistical and machine learning communities. It is largely undetermined in the statistical and
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;ReLU&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#22343;&#21248;&#36924;&#36817;&#29575;&#65292;&#21487;&#20197;&#20197;&#25509;&#36817;&#20110;&#26368;&#20248;&#36924;&#36817;&#29575;&#30340;&#36895;&#24230;&#22312;H\"older&#31354;&#38388;&#20013;&#36924;&#36817;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2307.12461</link><description>&lt;p&gt;
ReLU&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#29575;
&lt;/p&gt;
&lt;p&gt;
Rates of Approximation by ReLU Shallow Neural Networks. (arXiv:2307.12461v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12461
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;ReLU&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#22343;&#21248;&#36924;&#36817;&#29575;&#65292;&#21487;&#20197;&#20197;&#25509;&#36817;&#20110;&#26368;&#20248;&#36924;&#36817;&#29575;&#30340;&#36895;&#24230;&#22312;H\"older&#31354;&#38388;&#20013;&#36924;&#36817;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20462;&#27491;&#32447;&#24615;&#21333;&#20803;&#65288;ReLU&#65289;&#28608;&#27963;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;&#28145;&#24230;&#23398;&#20064;&#30340;&#26368;&#26032;&#21457;&#23637;&#20013;&#21457;&#25381;&#30528;&#26680;&#24515;&#20316;&#29992;&#12290;&#36890;&#36807;&#36825;&#20123;&#32593;&#32476;&#36924;&#36817;H\"older&#31354;&#38388;&#20013;&#30340;&#20989;&#25968;&#30340;&#35805;&#39064;&#23545;&#20110;&#29702;&#35299;&#25152;&#24341;&#21457;&#23398;&#20064;&#31639;&#27861;&#30340;&#25928;&#29575;&#33267;&#20851;&#37325;&#35201;&#12290;&#34429;&#28982;&#22312;&#20855;&#26377;&#22810;&#23618;&#38544;&#34255;&#31070;&#32463;&#20803;&#30340;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35774;&#32622;&#20013;&#35813;&#35805;&#39064;&#24050;&#32463;&#24471;&#21040;&#24456;&#22909;&#30340;&#30740;&#31350;&#65292;&#20294;&#23545;&#20110;&#20165;&#26377;&#19968;&#20010;&#38544;&#34255;&#23618;&#30340;&#27973;&#23618;&#32593;&#32476;&#20173;&#28982;&#26159;&#26410;&#35299;&#20043;&#35868;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#36825;&#20123;&#32593;&#32476;&#30340;&#22343;&#21248;&#36924;&#36817;&#29575;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#24403;$r&lt;d/2 +2$&#26102;&#65292;ReLU&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#20197;&#29575;$O((\log m)^{\frac{1}{2} +d}m^{-\frac{r}{d}\frac{d+2}{d+4}})$&#22343;&#21248;&#36924;&#36817;H\"older&#31354;&#38388;$W_\infty^r([-1, 1]^d)$&#20013;&#30340;&#20989;&#25968;&#12290;&#24403;$d$&#24456;&#22823;&#26102;&#65292;&#36825;&#26679;&#30340;&#36924;&#36817;&#29575;&#38750;&#24120;&#25509;&#36817;&#26368;&#20248;&#36924;&#36817;&#29575;$O(m^{-\frac{r}{d}})$&#65292;&#22240;&#20026;$\frac{d+2}{d+4}$&#25509;&#36817;&#20110;$1$&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural networks activated by the rectified linear unit (ReLU) play a central role in the recent development of deep learning. The topic of approximating functions from H\"older spaces by these networks is crucial for understanding the efficiency of the induced learning algorithms. Although the topic has been well investigated in the setting of deep neural networks with many layers of hidden neurons, it is still open for shallow networks having only one hidden layer. In this paper, we provide rates of uniform approximation by these networks. We show that ReLU shallow neural networks with $m$ hidden neurons can uniformly approximate functions from the H\"older space $W_\infty^r([-1, 1]^d)$ with rates $O((\log m)^{\frac{1}{2} +d}m^{-\frac{r}{d}\frac{d+2}{d+4}})$ when $r&lt;d/2 +2$. Such rates are very close to the optimal one $O(m^{-\frac{r}{d}})$ in the sense that $\frac{d+2}{d+4}$ is close to $1$, when the dimension $d$ is large.
&lt;/p&gt;</description></item><item><title>&#26412;&#31687;&#35770;&#25991;&#36827;&#34892;&#20102;&#20851;&#20110;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#20449;&#24687;&#35770;&#20998;&#26512;&#65292;&#23558;&#20854;&#20005;&#26684;&#20998;&#35299;&#20026;&#26412;&#36136;&#19981;&#30830;&#23450;&#24615;&#21644;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#20998;&#26512;&#26041;&#27861;&#26080;&#27861;&#35299;&#37322;&#27979;&#35797;&#25968;&#25454;&#21644;&#35757;&#32451;&#25968;&#25454;&#20043;&#38388;&#30340;&#25935;&#24863;&#24615;&#12290;&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#26032;&#39062;&#30340;&#20998;&#35299;&#26041;&#27861;&#30740;&#31350;&#20102;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#25935;&#24863;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.12456</link><description>&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#20013;&#27979;&#35797;&#25968;&#25454;&#25935;&#24863;&#24615;&#30340;&#20449;&#24687;&#35770;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Information-theoretic Analysis of Test Data Sensitivity in Uncertainty. (arXiv:2307.12456v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12456
&lt;/p&gt;
&lt;p&gt;
&#26412;&#31687;&#35770;&#25991;&#36827;&#34892;&#20102;&#20851;&#20110;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#20449;&#24687;&#35770;&#20998;&#26512;&#65292;&#23558;&#20854;&#20005;&#26684;&#20998;&#35299;&#20026;&#26412;&#36136;&#19981;&#30830;&#23450;&#24615;&#21644;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#20998;&#26512;&#26041;&#27861;&#26080;&#27861;&#35299;&#37322;&#27979;&#35797;&#25968;&#25454;&#21644;&#35757;&#32451;&#25968;&#25454;&#20043;&#38388;&#30340;&#25935;&#24863;&#24615;&#12290;&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#26032;&#39062;&#30340;&#20998;&#35299;&#26041;&#27861;&#30740;&#31350;&#20102;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#25935;&#24863;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#25512;&#26029;&#24120;&#34987;&#29992;&#20110;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#20219;&#21153;&#12290;Xu&#21644;Raginsky&#22312;2022&#24180;&#30340;&#26368;&#26032;&#20998;&#26512;&#20013;&#65292;&#23558;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#20005;&#26684;&#20998;&#35299;&#20026;&#20004;&#20010;&#19981;&#30830;&#23450;&#24615;&#65292;&#31216;&#20026;&#26412;&#36136;&#19981;&#30830;&#23450;&#24615;&#21644;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#65292;&#20998;&#21035;&#34920;&#31034;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20013;&#30340;&#22266;&#26377;&#38543;&#26426;&#24615;&#21644;&#30001;&#20110;&#25968;&#25454;&#19981;&#36275;&#32780;&#20135;&#29983;&#30340;&#21464;&#24322;&#24615;&#12290;&#20182;&#20204;&#20197;&#20449;&#24687;&#35770;&#30340;&#26041;&#24335;&#20998;&#26512;&#20102;&#36825;&#20123;&#19981;&#30830;&#23450;&#24615;&#65292;&#20551;&#35774;&#27169;&#22411;&#26159;&#33391;&#22909;&#25351;&#23450;&#30340;&#65292;&#24182;&#23558;&#27169;&#22411;&#21442;&#25968;&#35270;&#20026;&#28508;&#21464;&#37327;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#19981;&#30830;&#23450;&#24615;&#30340;&#20449;&#24687;&#35770;&#20998;&#26512;&#19981;&#33021;&#35299;&#37322;&#34987;&#24191;&#27867;&#35748;&#20026;&#30340;&#19981;&#30830;&#23450;&#24615;&#29305;&#24615;&#65292;&#21363;&#27979;&#35797;&#25968;&#25454;&#21644;&#35757;&#32451;&#25968;&#25454;&#20043;&#38388;&#30340;&#25935;&#24863;&#24615;&#12290;&#36825;&#24847;&#21619;&#30528;&#24403;&#27979;&#35797;&#25968;&#25454;&#22312;&#26576;&#31181;&#24847;&#20041;&#19978;&#19982;&#35757;&#32451;&#25968;&#25454;&#30456;&#20284;&#26102;&#65292;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#24212;&#35813;&#21464;&#23567;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#25105;&#20204;&#30340;&#26032;&#39062;&#20998;&#35299;&#26041;&#27861;&#30740;&#31350;&#20102;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#30340;&#25935;&#24863;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian inference is often utilized for uncertainty quantification tasks. A recent analysis by Xu and Raginsky 2022 rigorously decomposed the predictive uncertainty in Bayesian inference into two uncertainties, called aleatoric and epistemic uncertainties, which represent the inherent randomness in the data-generating process and the variability due to insufficient data, respectively. They analyzed those uncertainties in an information-theoretic way, assuming that the model is well-specified and treating the model's parameters as latent variables. However, the existing information-theoretic analysis of uncertainty cannot explain the widely believed property of uncertainty, known as the sensitivity between the test and training data. It implies that when test data are similar to training data in some sense, the epistemic uncertainty should become small. In this work, we study such uncertainty sensitivity using our novel decomposition method for the predictive uncertainty. Our analysis 
&lt;/p&gt;</description></item><item><title>DiAMoNDBack&#26159;&#19968;&#20010;&#24357;&#25955;&#21435;&#22122;&#30340;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#29992;&#20110;&#23558;&#31895;&#31890;&#21270;&#34507;&#30333;&#36136;&#27169;&#22411;&#24674;&#22797;&#21040;&#20840;&#21407;&#23376;&#20998;&#36776;&#29575;&#65292;&#36890;&#36807;&#21033;&#29992;C{\alpha}&#22352;&#26631;&#30340;&#20449;&#24687;&#21644;&#23616;&#37096;&#37051;&#22495;&#20013;&#30340;&#20808;&#21069;&#21453;&#26144;&#23556;&#30340;&#39592;&#26550;&#21644;&#20391;&#38142;&#21407;&#23376;&#12290;</title><link>http://arxiv.org/abs/2307.12451</link><description>&lt;p&gt;
DiAMoNDBack: &#24357;&#25955;&#21435;&#22122;&#30340;&#33258;&#22238;&#24402;&#27169;&#22411;&#29992;&#20110;&#38750;&#30830;&#23450;&#24615;&#34507;&#30333;&#36125;&#31867;C{\alpha}&#36861;&#36394;&#30340;&#21453;&#26144;&#23556;
&lt;/p&gt;
&lt;p&gt;
DiAMoNDBack: Diffusion-denoising Autoregressive Model for Non-Deterministic Backmapping of C{\alpha} Protein Traces. (arXiv:2307.12451v1 [q-bio.BM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12451
&lt;/p&gt;
&lt;p&gt;
DiAMoNDBack&#26159;&#19968;&#20010;&#24357;&#25955;&#21435;&#22122;&#30340;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#29992;&#20110;&#23558;&#31895;&#31890;&#21270;&#34507;&#30333;&#36136;&#27169;&#22411;&#24674;&#22797;&#21040;&#20840;&#21407;&#23376;&#20998;&#36776;&#29575;&#65292;&#36890;&#36807;&#21033;&#29992;C{\alpha}&#22352;&#26631;&#30340;&#20449;&#24687;&#21644;&#23616;&#37096;&#37051;&#22495;&#20013;&#30340;&#20808;&#21069;&#21453;&#26144;&#23556;&#30340;&#39592;&#26550;&#21644;&#20391;&#38142;&#21407;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34507;&#30333;&#36136;&#30340;&#31895;&#31890;&#21270;&#20998;&#23376;&#27169;&#22411;&#20801;&#35768;&#35775;&#38382;&#25152;&#26377;&#21407;&#23376;&#27169;&#22411;&#26080;&#27861;&#36798;&#21040;&#30340;&#38271;&#24230;&#21644;&#26102;&#38388;&#23610;&#24230;&#65292;&#24182;&#27169;&#25311;&#38271;&#26102;&#38388;&#23610;&#24230;&#19979;&#21457;&#29983;&#30340;&#32858;&#38598;&#21644;&#25240;&#21472;&#31561;&#36807;&#31243;&#12290;&#38477;&#20302;&#30340;&#20998;&#36776;&#29575;&#23454;&#29616;&#20102;&#35745;&#31639;&#21152;&#36895;&#65292;&#20294;&#21407;&#23376;&#32423;&#34920;&#31034;&#23545;&#20110;&#23436;&#20840;&#29702;&#35299;&#26426;&#21046;&#32454;&#33410;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#21453;&#26144;&#23556;&#26159;&#23558;&#31895;&#31890;&#21270;&#20998;&#23376;&#27169;&#22411;&#24674;&#22797;&#21040;&#20840;&#21407;&#23376;&#20998;&#36776;&#29575;&#30340;&#36807;&#31243;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25253;&#21578;&#20102;DiAMoNDBack&#65288;&#38750;&#30830;&#23450;&#24615;&#34507;&#30333;&#36125;&#31867;C{\alpha}&#36861;&#36394;&#30340;&#24357;&#25955;&#21435;&#22122;&#33258;&#22238;&#24402;&#27169;&#22411;&#65289;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#23558;&#20840;&#21407;&#23376;&#32454;&#33410;&#24674;&#22797;&#21040;&#20165;&#20445;&#30041;C{\alpha}&#22352;&#26631;&#30340;&#31895;&#31890;&#21270;&#34507;&#30333;&#36136;&#34920;&#31034;&#12290;&#33258;&#22238;&#24402;&#29983;&#25104;&#36807;&#31243;&#20174;&#34507;&#30333;&#36136;N&#31471;&#21040;C&#31471;&#36880;&#20010;&#27531;&#22522;&#22320;&#36827;&#34892;&#65292;&#26465;&#20214;&#26159;C{\alpha}&#36861;&#36394;&#20197;&#21450;&#20808;&#21069;&#21453;&#26144;&#23556;&#30340;&#39592;&#26550;&#21644;&#20391;&#38142;&#21407;&#23376;&#22312;&#23616;&#37096;&#37051;&#22495;&#20869;&#12290;
&lt;/p&gt;
&lt;p&gt;
Coarse-grained molecular models of proteins permit access to length and time scales unattainable by all-atom models and the simulation of processes that occur on long-time scales such as aggregation and folding. The reduced resolution realizes computational accelerations but an atomistic representation can be vital for a complete understanding of mechanistic details. Backmapping is the process of restoring all-atom resolution to coarse-grained molecular models. In this work, we report DiAMoNDBack (Diffusion-denoising Autoregressive Model for Non-Deterministic Backmapping) as an autoregressive denoising diffusion probability model to restore all-atom details to coarse-grained protein representations retaining only C{\alpha} coordinates. The autoregressive generation process proceeds from the protein N-terminus to C-terminus in a residue-by-residue fashion conditioned on the C{\alpha} trace and previously backmapped backbone and side chain atoms within the local neighborhood. The local a
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#32447;&#24615;&#36807;&#31243;&#30340;&#20855;&#26377;&#30456;&#20851;&#21019;&#26032;&#30340;&#38598;&#20013;&#24230;&#19981;&#31561;&#24335;&#65292;&#24182;&#21033;&#29992;&#35813;&#19981;&#31561;&#24335;&#33719;&#24471;&#20102;&#32447;&#24615;&#36807;&#31243;&#28382;&#21518;&#33258;&#21327;&#26041;&#24046;&#30697;&#38453;&#26368;&#22823;&#20998;&#37327;&#33539;&#25968;&#30340;&#38598;&#20013;&#24230;&#30028;&#38480;&#12290;&#36825;&#20123;&#32467;&#26524;&#22312;&#20272;&#35745;&#39640;&#32500;&#21521;&#37327;&#33258;&#22238;&#24402;&#36807;&#31243;&#12289;&#26102;&#38388;&#24207;&#21015;&#24341;&#23548;&#21644;&#38271;&#26399;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#20013;&#20855;&#26377;&#37325;&#35201;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2307.12395</link><description>&lt;p&gt;
&#39640;&#32500;&#32447;&#24615;&#36807;&#31243;&#20013;&#20855;&#26377;&#30456;&#20851;&#21019;&#26032;&#30340;&#38598;&#20013;&#24230;
&lt;/p&gt;
&lt;p&gt;
Concentration for high-dimensional linear processes with dependent innovations. (arXiv:2307.12395v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12395
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#32447;&#24615;&#36807;&#31243;&#30340;&#20855;&#26377;&#30456;&#20851;&#21019;&#26032;&#30340;&#38598;&#20013;&#24230;&#19981;&#31561;&#24335;&#65292;&#24182;&#21033;&#29992;&#35813;&#19981;&#31561;&#24335;&#33719;&#24471;&#20102;&#32447;&#24615;&#36807;&#31243;&#28382;&#21518;&#33258;&#21327;&#26041;&#24046;&#30697;&#38453;&#26368;&#22823;&#20998;&#37327;&#33539;&#25968;&#30340;&#38598;&#20013;&#24230;&#30028;&#38480;&#12290;&#36825;&#20123;&#32467;&#26524;&#22312;&#20272;&#35745;&#39640;&#32500;&#21521;&#37327;&#33258;&#22238;&#24402;&#36807;&#31243;&#12289;&#26102;&#38388;&#24207;&#21015;&#24341;&#23548;&#21644;&#38271;&#26399;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#20013;&#20855;&#26377;&#37325;&#35201;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#38024;&#23545;&#20855;&#26377;&#23376;&#38886;&#24067;&#23572;&#23614;&#30340;&#28151;&#21512;&#24207;&#21015;&#19978;&#30340;&#32447;&#24615;&#36807;&#31243;&#30340;$l_\infty$&#33539;&#25968;&#24320;&#21457;&#20102;&#38598;&#20013;&#19981;&#31561;&#24335;&#12290;&#36825;&#20123;&#19981;&#31561;&#24335;&#21033;&#29992;&#20102;Beveridge-Nelson&#20998;&#35299;&#65292;&#23558;&#38382;&#39064;&#31616;&#21270;&#20026;&#21521;&#37327;&#28151;&#21512;&#24207;&#21015;&#25110;&#20854;&#21152;&#26435;&#21644;&#30340;&#19978;&#30830;&#30028;&#33539;&#25968;&#30340;&#38598;&#20013;&#24230;&#12290;&#36825;&#20010;&#19981;&#31561;&#24335;&#29992;&#20110;&#24471;&#21040;&#32447;&#24615;&#36807;&#31243;&#30340;&#28382;&#21518;$h$&#33258;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#26368;&#22823;&#20998;&#37327;&#33539;&#25968;&#30340;&#38598;&#20013;&#24230;&#30028;&#38480;&#12290;&#36825;&#20123;&#32467;&#26524;&#23545;&#20110;&#20351;&#29992;$l_1$&#27491;&#21017;&#21270;&#20272;&#35745;&#30340;&#39640;&#32500;&#21521;&#37327;&#33258;&#22238;&#24402;&#36807;&#31243;&#30340;&#20272;&#35745;&#30028;&#38480;&#12289;&#26102;&#38388;&#24207;&#21015;&#30340;&#39640;&#32500;&#39640;&#26031;&#24341;&#23548;&#12289;&#20197;&#21450;&#38271;&#26399;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#38750;&#24120;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop concentration inequalities for the $l_\infty$ norm of a vector linear processes on mixingale sequences with sub-Weibull tails. These inequalities make use of the Beveridge-Nelson decomposition, which reduces the problem to concentration for sup-norm of a vector-mixingale or its weighted sum. This inequality is used to obtain a concentration bound for the maximum entrywise norm of the lag-$h$ autocovariance matrices of linear processes. These results are useful for estimation bounds for high-dimensional vector-autoregressive processes estimated using $l_1$ regularisation, high-dimensional Gaussian bootstrap for time series, and long-run covariance matrix estimation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#29289;&#29702;&#20449;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;(PINNs)&#35299;&#20915;&#39640;&#32500;&#24230;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;(PDEs)&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#25910;&#25947;&#24615;&#21644;&#20854;&#20182;&#26399;&#26395;&#23646;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.12306</link><description>&lt;p&gt;
&#29992;&#29289;&#29702;&#20449;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;&#35299;&#20915;&#32500;&#24230;&#35781;&#21650;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Tackling the Curse of Dimensionality with Physics-Informed Neural Networks. (arXiv:2307.12306v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12306
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#29289;&#29702;&#20449;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;(PINNs)&#35299;&#20915;&#39640;&#32500;&#24230;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;(PDEs)&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#25910;&#25947;&#24615;&#21644;&#20854;&#20182;&#26399;&#26395;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32500;&#24230;&#35781;&#21650;(CoD)&#38543;&#30528;&#32500;&#24230;&#30340;&#22686;&#21152;&#65292;&#20197;&#25351;&#25968;&#32423;&#22686;&#38271;&#30340;&#35745;&#31639;&#25104;&#26412;&#26469;&#26497;&#24230;&#31246;&#36153;&#35745;&#31639;&#36164;&#28304;&#12290;&#36825;&#22312;&#35299;&#20915;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;(PDEs)&#20013;&#38754;&#20020;&#26497;&#22823;&#25361;&#25112;&#65292;&#27491;&#22914;Richard Bellman&#22312;60&#24180;&#21069;&#39318;&#27425;&#25351;&#20986;&#30340;&#37027;&#26679;&#12290;&#23613;&#31649;&#36817;&#24180;&#26469;&#22312;&#39640;&#32500;&#24230;&#19978;&#25968;&#20540;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;(PDEs)&#21462;&#24471;&#20102;&#19968;&#20123;&#25104;&#21151;&#65292;&#20294;&#36825;&#26679;&#30340;&#35745;&#31639;&#20195;&#20215;&#36807;&#39640;&#65292;&#32780;&#23558;&#19968;&#33324;&#38750;&#32447;&#24615;PDEs&#25193;&#23637;&#21040;&#39640;&#32500;&#24230;&#20174;&#26410;&#23454;&#29616;&#36807;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#23558;&#29289;&#29702;&#20449;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;(PINNs)&#25193;&#23637;&#21040;&#35299;&#20915;&#20219;&#24847;&#39640;&#32500;PDEs&#12290;&#35813;&#26032;&#26041;&#27861;&#31216;&#20026;&#38543;&#26426;&#32500;&#24230;&#26799;&#24230;&#19979;&#38477;(SDGD)&#65292;&#23558;PDE&#30340;&#26799;&#24230;&#20998;&#35299;&#20026;&#19982;&#19981;&#21516;&#32500;&#24230;&#23545;&#24212;&#30340;&#37096;&#20998;&#65292;&#24182;&#22312;&#35757;&#32451;PINNs&#30340;&#27599;&#27425;&#36845;&#20195;&#20013;&#38543;&#26426;&#36873;&#25321;&#36825;&#20123;&#32500;&#24230;&#37096;&#20998;&#30340;&#23376;&#38598;&#36827;&#34892;&#37319;&#26679;&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#25910;&#25947;&#20445;&#35777;&#21644;&#20854;&#20182;&#26399;&#26395;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The curse-of-dimensionality (CoD) taxes computational resources heavily with exponentially increasing computational cost as the dimension increases. This poses great challenges in solving high-dimensional PDEs as Richard Bellman first pointed out over 60 years ago. While there has been some recent success in solving numerically partial differential equations (PDEs) in high dimensions, such computations are prohibitively expensive, and true scaling of general nonlinear PDEs to high dimensions has never been achieved. In this paper, we develop a new method of scaling up physics-informed neural networks (PINNs) to solve arbitrary high-dimensional PDEs. The new method, called Stochastic Dimension Gradient Descent (SDGD), decomposes a gradient of PDEs into pieces corresponding to different dimensions and samples randomly a subset of these dimensional pieces in each iteration of training PINNs. We theoretically prove the convergence guarantee and other desired properties of the proposed meth
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#26631;&#31614;&#20043;&#38388;&#30340;&#36317;&#31163;&#20851;&#31995;&#26469;&#35843;&#25972;&#24050;&#35757;&#32451;&#30340;&#27169;&#22411;&#65292;&#20197;&#21487;&#38752;&#22320;&#39044;&#27979;&#26032;&#31867;&#21035;&#25110;&#25913;&#21892;&#38646;&#26679;&#26412;&#39044;&#27979;&#30340;&#24615;&#33021;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#30340;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2307.12226</link><description>&lt;p&gt;
&#38754;&#21521;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#20960;&#20309;&#24863;&#30693;&#33258;&#36866;&#24212;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Geometry-Aware Adaptation for Pretrained Models. (arXiv:2307.12226v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12226
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#26631;&#31614;&#20043;&#38388;&#30340;&#36317;&#31163;&#20851;&#31995;&#26469;&#35843;&#25972;&#24050;&#35757;&#32451;&#30340;&#27169;&#22411;&#65292;&#20197;&#21487;&#38752;&#22320;&#39044;&#27979;&#26032;&#31867;&#21035;&#25110;&#25913;&#21892;&#38646;&#26679;&#26412;&#39044;&#27979;&#30340;&#24615;&#33021;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#30340;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#21253;&#25324;&#33879;&#21517;&#30340;&#38646;&#26679;&#26412;&#27169;&#22411;&#65292;&#36890;&#24120;&#22312;&#20165;&#20855;&#26377;&#36739;&#23567;&#27604;&#20363;&#26631;&#31614;&#31354;&#38388;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35757;&#32451;&#12290;&#36825;&#20123;&#26631;&#31614;&#31354;&#38388;&#36890;&#24120;&#20351;&#29992;&#24230;&#37327;&#26469;&#34913;&#37327;&#26631;&#31614;&#20043;&#38388;&#30340;&#36317;&#31163;&#20851;&#31995;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#21033;&#29992;&#36825;&#20123;&#20449;&#24687;&#65292;&#23558;&#24050;&#35757;&#32451;&#30340;&#27169;&#22411;&#35843;&#25972;&#20197;&#21487;&#38752;&#22320;&#39044;&#27979;&#26032;&#31867;&#21035;&#65292;&#25110;&#32773;&#22312;&#38646;&#26679;&#26412;&#39044;&#27979;&#30340;&#24773;&#20917;&#19979;&#25913;&#21892;&#24615;&#33021;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#30340;&#35757;&#32451;&#12290;&#25105;&#20204;&#30340;&#25216;&#26415;&#26159;&#26631;&#20934;&#39044;&#27979;&#35268;&#21017;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#22312;&#20854;&#20013;&#23558;argmax&#26367;&#25442;&#20026;Fr&#233;chet&#24179;&#22343;&#20540;&#12290;&#25105;&#20204;&#20026;&#36825;&#31181;&#26041;&#27861;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#30740;&#31350;&#20102;&#65288;i&#65289;&#23398;&#20064;&#29702;&#35770;&#32467;&#26524;&#65292;&#26435;&#34913;&#26631;&#31614;&#31354;&#38388;&#30452;&#24452;&#12289;&#26679;&#26412;&#22797;&#26434;&#24615;&#21644;&#27169;&#22411;&#32500;&#24230;&#65292;&#65288;ii&#65289;&#34920;&#24449;&#21487;&#33021;&#39044;&#27979;&#20219;&#20309;&#26410;&#35266;&#23519;&#21040;&#30340;&#31867;&#21035;&#30340;&#25152;&#26377;&#24773;&#26223;&#30340;&#29305;&#24449;&#65292;&#65288;iii&#65289;&#19968;&#31181;&#26368;&#20248;&#30340;&#20027;&#21160;&#23398;&#20064;&#24335;&#19979;&#19968;&#31867;&#21035;&#36873;&#25321;&#36807;&#31243;&#65292;&#20197;&#33719;&#21462;&#26368;&#20339;&#30340;&#35757;&#32451;&#31867;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning models -- including prominent zero-shot models -- are often trained on datasets whose labels are only a small proportion of a larger label space. Such spaces are commonly equipped with a metric that relates the labels via distances between them. We propose a simple approach to exploit this information to adapt the trained model to reliably predict new classes -- or, in the case of zero-shot prediction, to improve its performance -- without any additional training. Our technique is a drop-in replacement of the standard prediction rule, swapping argmax with the Fr\'echet mean. We provide a comprehensive theoretical analysis for this approach, studying (i) learning-theoretic results trading off label space diameter, sample complexity, and model dimension, (ii) characterizations of the full range of scenarios in which it is possible to predict any unobserved class, and (iii) an optimal active learning-like next class selection procedure to obtain optimal training classes f
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#20998;&#24067;&#23398;&#20064;&#23545;VC&#31867;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#21457;&#29616;&#29616;&#26377;&#30340;&#19978;&#19979;&#30028;&#23384;&#22312;&#26174;&#33879;&#24046;&#36317;&#65292;&#24182;&#35752;&#35770;&#20102;&#19968;&#20123;&#28041;&#21450;&#32479;&#35745;&#23398;&#20064;&#20013;&#21338;&#24328;&#21160;&#24577;&#30340;&#22256;&#38590;&#12290;</title><link>http://arxiv.org/abs/2307.12135</link><description>&lt;p&gt;
&#22810;&#20998;&#24067;&#23398;&#20064;&#23545;VC&#31867;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
The Sample Complexity of Multi-Distribution Learning for VC Classes. (arXiv:2307.12135v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12135
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#20998;&#24067;&#23398;&#20064;&#23545;VC&#31867;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#21457;&#29616;&#29616;&#26377;&#30340;&#19978;&#19979;&#30028;&#23384;&#22312;&#26174;&#33879;&#24046;&#36317;&#65292;&#24182;&#35752;&#35770;&#20102;&#19968;&#20123;&#28041;&#21450;&#32479;&#35745;&#23398;&#20064;&#20013;&#21338;&#24328;&#21160;&#24577;&#30340;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20998;&#24067;&#23398;&#20064;&#26159;&#23558;PAC&#23398;&#20064;&#25512;&#24191;&#21040;&#20855;&#26377;&#22810;&#20010;&#25968;&#25454;&#20998;&#24067;&#30340;&#24773;&#22659;&#12290;&#25105;&#20204;&#23545;&#20110;PAC&#21487;&#23398;&#20064;&#31867;&#30340;&#24050;&#30693;&#19978;&#19979;&#30028;&#20173;&#28982;&#23384;&#22312;&#26174;&#33879;&#24046;&#36317;&#12290;&#23613;&#31649;&#25105;&#20204;&#20102;&#35299;&#22312;$k$&#20010;&#20998;&#24067;&#19978;&#23398;&#20064;&#20855;&#26377;VC&#32500;&#24230;d&#30340;&#31867;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$O(\epsilon^{-2} \ln(k)(d + k) + \min\{\epsilon^{-1} dk, \epsilon^{-4} \ln(k) d\})$&#65292;&#20294;&#26368;&#22909;&#30340;&#19979;&#30028;&#26159;$\Omega(\epsilon^{-2}(d + k \ln(k)))$&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#36825;&#20010;&#38382;&#39064;&#30340;&#26368;&#26032;&#36827;&#23637;&#20197;&#21450;&#22312;&#32479;&#35745;&#23398;&#20064;&#20013;&#20351;&#29992;&#21338;&#24328;&#21160;&#24577;&#30340;&#19968;&#20123;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-distribution learning is a natural generalization of PAC learning to settings with multiple data distributions. There remains a significant gap between the known upper and lower bounds for PAC-learnable classes. In particular, though we understand the sample complexity of learning a VC dimension d class on $k$ distributions to be $O(\epsilon^{-2} \ln(k)(d + k) + \min\{\epsilon^{-1} dk, \epsilon^{-4} \ln(k) d\})$, the best lower bound is $\Omega(\epsilon^{-2}(d + k \ln(k)))$. We discuss recent progress on this problem and some hurdles that are fundamental to the use of game dynamics in statistical learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26088;&#22312;&#25552;&#20379;IRM&#30340;&#29702;&#35770;&#39564;&#35777;&#65292;&#20005;&#26684;&#35777;&#26126;&#20102;&#35299;&#20915;&#26041;&#26696;&#21487;&#20197;&#26368;&#23567;&#21270;&#21306;&#22806;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2307.11972</link><description>&lt;p&gt;
&#19981;&#21464;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#21306;&#22806;&#20248;&#21270;&#24615;
&lt;/p&gt;
&lt;p&gt;
Out-of-Distribution Optimality of Invariant Risk Minimization. (arXiv:2307.11972v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11972
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#25552;&#20379;IRM&#30340;&#29702;&#35770;&#39564;&#35777;&#65292;&#20005;&#26684;&#35777;&#26126;&#20102;&#35299;&#20915;&#26041;&#26696;&#21487;&#20197;&#26368;&#23567;&#21270;&#21306;&#22806;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#32463;&#24120;&#32487;&#25215;&#35757;&#32451;&#25968;&#25454;&#20013;&#23884;&#20837;&#30340;&#34394;&#20551;&#30456;&#20851;&#24615;&#65292;&#22240;&#27492;&#21487;&#33021;&#26080;&#27861;&#27867;&#21270;&#21040;&#20855;&#26377;&#19982;&#25552;&#20379;&#35757;&#32451;&#25968;&#25454;&#30340;&#39046;&#22495;&#19981;&#21516;&#30340;&#26410;&#30693;&#22495;&#12290;M. Arjovsky&#31561;&#20154;&#65288;2019&#24180;&#65289;&#24341;&#20837;&#20102;&#21306;&#22806;&#65288;o.o.d.&#65289;&#39118;&#38505;&#30340;&#27010;&#24565;&#65292;&#21363;&#25152;&#26377;&#22495;&#20013;&#30340;&#26368;&#22823;&#39118;&#38505;&#65292;&#24182;&#23558;&#30001;&#34394;&#20551;&#30456;&#20851;&#24615;&#24341;&#36215;&#30340;&#38382;&#39064;&#35268;&#23450;&#20026;&#26368;&#23567;&#21270;&#21306;&#22806;&#39118;&#38505;&#30340;&#38382;&#39064;&#12290;&#19981;&#21464;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;IRM&#65289;&#34987;&#35748;&#20026;&#26159;&#26368;&#23567;&#21270;&#21306;&#22806;&#39118;&#38505;&#30340;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#65306;IRM&#36890;&#36807;&#35299;&#20915;&#19968;&#20010;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#26469;&#20272;&#35745;&#26368;&#23567;&#21270;&#30340;&#21306;&#22806;&#39118;&#38505;&#12290;&#23613;&#31649;IRM&#20197;&#23454;&#35777;&#25104;&#21151;&#21560;&#24341;&#20102;&#30456;&#24403;&#22810;&#30340;&#20851;&#27880;&#65292;&#20294;&#23427;&#32570;&#20047;&#19968;&#20123;&#29702;&#35770;&#20445;&#35777;&#12290;&#29305;&#21035;&#26159;&#65292;&#36824;&#27809;&#26377;&#30830;&#31435;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#32473;&#20986;&#26368;&#23567;&#21270;&#21306;&#22806;&#39118;&#38505;&#30340;&#22362;&#23454;&#29702;&#35770;&#20445;&#35777;&#12290;&#26412;&#25991;&#26088;&#22312;&#25552;&#20379;IRM&#30340;&#29702;&#35770;&#39564;&#35777;&#65292;&#20005;&#26684;&#35777;&#26126;&#20102;&#35299;&#20915;&#26041;&#26696;&#21487;&#20197;&#36890;&#36807;&#22312;&#22823;&#20223;&#30495;&#36319;&#36394;&#25968;&#25454;&#24211;&#20013;&#36827;&#34892;&#23454;&#26102;&#20223;&#30495;&#65292;&#20854;&#21253;&#25324;&#23545;&#21608;&#22260;&#29615;&#22659;&#30340;&#30452;&#25509;&#24863;&#30693;&#65292;&#23545;&#28508;&#22312;&#36335;&#32447;&#35268;&#21010;&#30340;&#31574;&#30053;&#35748;&#35782;&#65292;&#21516;&#26102;&#32771;&#34385;&#21040;&#22810;&#36710;&#36742;&#20132;&#20114;&#65292;&#20197;&#23454;&#29616;&#35813;&#38382;&#39064;&#30340;&#20840;&#23616;&#20248;&#21270;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Neural Networks often inherit spurious correlations embedded in training data and hence may fail to generalize to unseen domains, which have different distributions from the domain to provide training data. M. Arjovsky et al. (2019) introduced the concept out-of-distribution (o.o.d.) risk, which is the maximum risk among all domains, and formulated the issue caused by spurious correlations as a minimization problem of the o.o.d. risk. Invariant Risk Minimization (IRM) is considered to be a promising approach to minimize the o.o.d. risk: IRM estimates a minimum of the o.o.d. risk by solving a bi-level optimization problem. While IRM has attracted considerable attention with empirical success, it comes with few theoretical guarantees. Especially, a solid theoretical guarantee that the bi-level optimization problem gives the minimum of the o.o.d. risk has not yet been established. Aiming at providing a theoretical justification for IRM, this paper rigorously proves that a solution to
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21327;&#21516;&#23398;&#20064;&#32447;&#24615;&#27169;&#22411;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#24067;&#24335;&#12289;&#21322;&#30417;&#30563;&#30340;&#31639;&#27861;Collab&#65292;&#35813;&#31639;&#27861;&#22312;&#26080;&#27861;&#35775;&#38382;&#26631;&#35760;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#36890;&#20449;&#25928;&#29575;&#21644;&#23454;&#29992;&#24615;&#65292;&#21516;&#26102;&#22312;&#28176;&#36817;&#23616;&#37096;&#26497;&#23567;&#26497;&#20540;&#26041;&#38754;&#20063;&#34920;&#29616;&#20986;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.11947</link><description>&lt;p&gt;
&#36890;&#36807;&#32467;&#26500;&#21270;&#32570;&#22833;&#25968;&#25454;&#21327;&#21516;&#23398;&#20064;&#32447;&#24615;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Collaboratively Learning Linear Models with Structured Missing Data. (arXiv:2307.11947v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11947
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21327;&#21516;&#23398;&#20064;&#32447;&#24615;&#27169;&#22411;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#24067;&#24335;&#12289;&#21322;&#30417;&#30563;&#30340;&#31639;&#27861;Collab&#65292;&#35813;&#31639;&#27861;&#22312;&#26080;&#27861;&#35775;&#38382;&#26631;&#35760;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#36890;&#20449;&#25928;&#29575;&#21644;&#23454;&#29992;&#24615;&#65292;&#21516;&#26102;&#22312;&#28176;&#36817;&#23616;&#37096;&#26497;&#23567;&#26497;&#20540;&#26041;&#38754;&#20063;&#34920;&#29616;&#20986;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;$m$&#20010;&#20195;&#29702;&#21327;&#21516;&#23398;&#20064;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#30340;&#38382;&#39064;&#12290;&#27599;&#20010;&#20195;&#29702;&#35266;&#23519;&#21040;&#19981;&#21516;&#30340;&#29305;&#24449;&#23376;&#38598;&#65292;&#20363;&#22914;&#20174;&#19981;&#21516;&#20998;&#36776;&#29575;&#30340;&#20256;&#24863;&#22120;&#25910;&#38598;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#30830;&#23450;&#22914;&#20309;&#21327;&#35843;&#20195;&#29702;&#20197;&#20135;&#29983;&#26368;&#20339;&#30340;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#24067;&#24335;&#12289;&#21322;&#30417;&#30563;&#30340;&#31639;&#27861;Collab&#65292;&#21253;&#25324;&#19977;&#20010;&#27493;&#39588;&#65306;&#26412;&#22320;&#35757;&#32451;&#12289;&#32858;&#21512;&#21644;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#38656;&#35201;&#36890;&#20449;&#26631;&#35760;&#25968;&#25454;&#65292;&#20351;&#20854;&#22312;&#26080;&#27861;&#35775;&#38382;&#26631;&#35760;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#36890;&#20449;&#25928;&#29575;&#21644;&#23454;&#29992;&#24615;&#12290;&#23613;&#31649;&#23384;&#22312;&#36825;&#20010;&#38556;&#30861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20960;&#20046;&#26159;&#28176;&#36817;&#23616;&#37096;&#26497;&#23567;&#26497;&#20540;$\unicode{x2013}$&#21363;&#20351;&#22312;&#20801;&#35768;&#36890;&#20449;&#26631;&#35760;&#25968;&#25454;&#30340;&#20272;&#35745;&#22120;&#20013;&#65292;&#22914;&#25554;&#34917;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;&#30495;&#23454;&#25968;&#25454;&#21644;&#21512;&#25104;&#25968;&#25454;&#19978;&#27979;&#35797;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of collaboratively learning least squares estimates for $m$ agents. Each agent observes a different subset of the features$\unicode{x2013}$e.g., containing data collected from sensors of varying resolution. Our goal is to determine how to coordinate the agents in order to produce the best estimator for each agent. We propose a distributed, semi-supervised algorithm Collab, consisting of three steps: local training, aggregation, and distribution. Our procedure does not require communicating the labeled data, making it communication efficient and useful in settings where the labeled data is inaccessible. Despite this handicap, our procedure is nearly asymptotically local minimax optimal$\unicode{x2013}$even among estimators allowed to communicate the labeled data such as imputation methods. We test our method on real and synthetic data.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23884;&#20837;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#65292;&#23884;&#20837;&#23618;&#27425;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#21644;&#38754;&#21521;&#26102;&#38388;&#30340;&#21160;&#24577;&#23884;&#20837;&#19977;&#31181;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#22312;&#22024;&#26434;&#30340;&#22823;&#25968;&#25454;&#29615;&#22659;&#20013;&#23436;&#20840;&#26080;&#30417;&#30563;&#30340;&#20027;&#39064;&#25552;&#21462;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2307.11775</link><description>&lt;p&gt;
&#25429;&#25417;&#31038;&#20132;&#23186;&#20307;&#20013;&#23458;&#25143;&#35265;&#35299;&#30340;&#20027;&#39064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Topical Approach to Capturing Customer Insight In Social Media. (arXiv:2307.11775v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11775
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23884;&#20837;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#65292;&#23884;&#20837;&#23618;&#27425;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#21644;&#38754;&#21521;&#26102;&#38388;&#30340;&#21160;&#24577;&#23884;&#20837;&#19977;&#31181;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#22312;&#22024;&#26434;&#30340;&#22823;&#25968;&#25454;&#29615;&#22659;&#20013;&#23436;&#20840;&#26080;&#30417;&#30563;&#30340;&#20027;&#39064;&#25552;&#21462;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#23186;&#20307;&#26102;&#20195;&#20026;&#20225;&#19994;&#24102;&#26469;&#20102;&#26032;&#30340;&#26426;&#36935;&#12290;&#36825;&#31181;&#32321;&#33635;&#30340;&#20449;&#24687;&#36130;&#23500;&#36229;&#20986;&#20102;&#20256;&#32479;&#33829;&#38144;&#30740;&#31350;&#30340;&#28192;&#36947;&#21644;&#26694;&#26550;&#65292;&#21253;&#25324;&#33829;&#38144;&#32452;&#21512;&#24314;&#27169;(MMM)&#12290;&#29305;&#21035;&#26159;&#65292;&#25991;&#26412;&#25968;&#25454;&#25552;&#20986;&#20102;&#35768;&#22810;&#25968;&#25454;&#20998;&#26512;&#20174;&#19994;&#20154;&#21592;&#24517;&#39035;&#24212;&#23545;&#30340;&#25361;&#25112;&#12290;&#31038;&#20132;&#23186;&#20307;&#26500;&#25104;&#20102;&#22823;&#35268;&#27169;&#12289;&#24322;&#26500;&#21644;&#22024;&#26434;&#30340;&#25991;&#26723;&#26469;&#28304;&#12290;&#24037;&#19994;&#25968;&#25454;&#37319;&#38598;&#36807;&#31243;&#21253;&#25324;&#19968;&#23450;&#37327;&#30340;ETL&#12290;&#28982;&#32780;&#65292;&#25968;&#25454;&#20013;&#22122;&#22768;&#30340;&#21464;&#24322;&#24615;&#21644;&#19981;&#21516;&#26469;&#28304;&#24341;&#20837;&#30340;&#24322;&#26500;&#24615;&#32473;&#20104;&#20102;&#20020;&#26102;&#24037;&#20855;&#30340;&#38656;&#27714;&#12290;&#25442;&#21477;&#35805;&#35828;&#65292;&#22312;&#23436;&#20840;&#26080;&#30417;&#30563;&#12289;&#22024;&#26434;&#30340;&#29615;&#22659;&#20013;&#25552;&#21462;&#23458;&#25143;&#35265;&#35299;&#26159;&#19968;&#39033;&#33392;&#24040;&#30340;&#20219;&#21153;&#12290;&#26412;&#30740;&#31350;&#35299;&#20915;&#20102;&#22312;&#22024;&#26434;&#30340;&#22823;&#25968;&#25454;&#29615;&#22659;&#20013;&#23436;&#20840;&#26080;&#30417;&#30563;&#30340;&#20027;&#39064;&#25552;&#21462;&#25361;&#25112;&#12290;&#25105;&#20204;&#22312;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#26694;&#26550;&#19978;&#25552;&#20986;&#20102;&#19977;&#31181;&#26041;&#27861;&#65306;&#23884;&#20837;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#12289;&#23884;&#20837;&#23618;&#27425;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#21644;&#38754;&#21521;&#26102;&#38388;&#30340;&#21160;&#24577;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
The age of social media has opened new opportunities for businesses. This flourishing wealth of information is outside traditional channels and frameworks of classical marketing research, including that of Marketing Mix Modeling (MMM). Textual data, in particular, poses many challenges that data analysis practitioners must tackle. Social media constitute massive, heterogeneous, and noisy document sources. Industrial data acquisition processes include some amount of ETL. However, the variability of noise in the data and the heterogeneity induced by different sources create the need for ad-hoc tools. Put otherwise, customer insight extraction in fully unsupervised, noisy contexts is an arduous task. This research addresses the challenge of fully unsupervised topic extraction in noisy, Big Data contexts. We present three approaches we built on the Variational Autoencoder framework: the Embedded Dirichlet Process, the Embedded Hierarchical Dirichlet Process, and the time-aware Dynamic Embe
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23433;&#20840;&#22810;&#26041;&#35745;&#31639;&#23454;&#29616;&#22402;&#30452;&#38544;&#31169;&#20445;&#25252;&#30340;&#31526;&#21495;&#22238;&#24402;&#12290;</title><link>http://arxiv.org/abs/2307.11756</link><description>&lt;p&gt;
&#36890;&#36807;&#23433;&#20840;&#22810;&#26041;&#35745;&#31639;&#23454;&#29616;&#22402;&#30452;&#38544;&#31169;&#20445;&#25252;&#30340;&#31526;&#21495;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Towards Vertical Privacy-Preserving Symbolic Regression via Secure Multiparty Computation. (arXiv:2307.11756v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11756
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23433;&#20840;&#22810;&#26041;&#35745;&#31639;&#23454;&#29616;&#22402;&#30452;&#38544;&#31169;&#20445;&#25252;&#30340;&#31526;&#21495;&#22238;&#24402;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31526;&#21495;&#22238;&#24402;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#25968;&#25454;&#39537;&#21160;&#25216;&#26415;&#65292;&#29992;&#20110;&#25628;&#32034;&#33021;&#22815;&#35299;&#37322;&#36755;&#20837;&#21464;&#37327;&#19982;&#30446;&#26631;&#21464;&#37327;&#20043;&#38388;&#20851;&#31995;&#30340;&#25968;&#23398;&#34920;&#36798;&#24335;&#12290;&#30001;&#20110;&#20854;&#39640;&#25928;&#24615;&#21644;&#28789;&#27963;&#24615;&#65292;&#36951;&#20256;&#32534;&#31243;&#34987;&#35270;&#20026;&#31526;&#21495;&#22238;&#24402;&#30340;&#26631;&#20934;&#25628;&#32034;&#25216;&#26415;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;&#36951;&#20256;&#32534;&#31243;&#31639;&#27861;&#38656;&#35201;&#23558;&#25152;&#26377;&#25968;&#25454;&#23384;&#20648;&#22312;&#19968;&#20010;&#20013;&#22830;&#20301;&#32622;&#65292;&#36825;&#22312;&#26085;&#30410;&#20851;&#27880;&#25968;&#25454;&#38544;&#31169;&#21644;&#23433;&#20840;&#30340;&#24773;&#20917;&#19979;&#24182;&#19981;&#24635;&#26159;&#21487;&#34892;&#30340;&#12290;&#34429;&#28982;&#38544;&#31169;&#20445;&#25252;&#30740;&#31350;&#36817;&#24180;&#26469;&#21462;&#24471;&#20102;&#36827;&#23637;&#65292;&#21487;&#33021;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#25552;&#20379;&#20102;&#26041;&#26696;&#65292;&#20294;&#23545;&#31526;&#21495;&#22238;&#24402;&#30340;&#24212;&#29992;&#20173;&#28982;&#36739;&#23569;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#30340;&#24037;&#20316;&#21482;&#20851;&#27880;&#27700;&#24179;&#20998;&#21306;&#30340;&#35774;&#32622;&#65292;&#32780;&#22402;&#30452;&#20998;&#21306;&#30340;&#35774;&#32622;&#65292;&#21478;&#19968;&#31181;&#24120;&#35265;&#22330;&#26223;&#65292;&#23578;&#26410;&#34987;&#30740;&#31350;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#37319;&#29992;&#23433;&#20840;&#22810;&#26041;&#35745;&#31639;&#25216;&#26415;&#30340;&#26041;&#27861;&#65292;&#20351;&#21508;&#26041;&#33021;&#22815;&#20849;&#21516;&#26500;&#24314;&#31526;&#21495;&#22238;&#24402;&#27169;&#22411;&#65292;&#21516;&#26102;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#12290;
&lt;/p&gt;
&lt;p&gt;
Symbolic Regression is a powerful data-driven technique that searches for mathematical expressions that explain the relationship between input variables and a target of interest. Due to its efficiency and flexibility, Genetic Programming can be seen as the standard search technique for Symbolic Regression. However, the conventional Genetic Programming algorithm requires storing all data in a central location, which is not always feasible due to growing concerns about data privacy and security. While privacy-preserving research has advanced recently and might offer a solution to this problem, their application to Symbolic Regression remains largely unexplored. Furthermore, the existing work only focuses on the horizontally partitioned setting, whereas the vertically partitioned setting, another popular scenario, has yet to be investigated. Herein, we propose an approach that employs a privacy-preserving technique called Secure Multiparty Computation to enable parties to jointly build Sy
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#21457;&#29616;&#65292;&#23574;&#38160;&#24615;&#26368;&#23567;&#21270;&#31639;&#27861;&#19981;&#20165;&#20165;&#26159;&#20026;&#20102;&#26368;&#23567;&#21270;&#23574;&#38160;&#24615;&#32780;&#36798;&#21040;&#26356;&#22909;&#30340;&#27867;&#21270;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#23574;&#38160;&#24615;&#19982;&#27867;&#21270;&#20043;&#38388;&#30340;&#20851;&#31995;&#21462;&#20915;&#20110;&#25968;&#25454;&#20998;&#24067;&#21644;&#27169;&#22411;&#26550;&#26500;&#12290;</title><link>http://arxiv.org/abs/2307.11007</link><description>&lt;p&gt;
&#23574;&#38160;&#24615;&#26368;&#23567;&#21270;&#31639;&#27861;&#19981;&#20165;&#20165;&#26159;&#20026;&#20102;&#26356;&#22909;&#22320;&#27867;&#21270;&#32780;&#26368;&#23567;&#21270;&#23574;&#38160;&#24615;
&lt;/p&gt;
&lt;p&gt;
Sharpness Minimization Algorithms Do Not Only Minimize Sharpness To Achieve Better Generalization. (arXiv:2307.11007v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11007
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#21457;&#29616;&#65292;&#23574;&#38160;&#24615;&#26368;&#23567;&#21270;&#31639;&#27861;&#19981;&#20165;&#20165;&#26159;&#20026;&#20102;&#26368;&#23567;&#21270;&#23574;&#38160;&#24615;&#32780;&#36798;&#21040;&#26356;&#22909;&#30340;&#27867;&#21270;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#23574;&#38160;&#24615;&#19982;&#27867;&#21270;&#20043;&#38388;&#30340;&#20851;&#31995;&#21462;&#20915;&#20110;&#25968;&#25454;&#20998;&#24067;&#21644;&#27169;&#22411;&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#30740;&#31350;&#65292;&#20294;&#36807;&#21442;&#25968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#27867;&#21270;&#30340;&#22522;&#26412;&#21407;&#22240;&#20173;&#28982;&#19981;&#26126;&#30830;&#12290;&#29616;&#26377;&#30340;&#29702;&#35770;&#34920;&#26126;&#65292;&#24120;&#35265;&#30340;&#38543;&#26426;&#20248;&#21270;&#22120;&#26356;&#20542;&#21521;&#20110;&#35757;&#32451;&#25439;&#22833;&#26356;&#24179;&#22374;&#30340;&#26368;&#23567;&#21270;&#22120;&#65292;&#22240;&#27492;&#33258;&#28982;&#32780;&#28982;&#30340;&#35299;&#37322;&#26159;&#24179;&#22374;&#24615;&#24847;&#21619;&#30528;&#27867;&#21270;&#12290;&#26412;&#25991;&#23545;&#36825;&#19968;&#35299;&#37322;&#36827;&#34892;&#20102;&#25209;&#21028;&#24615;&#30340;&#30740;&#31350;&#12290;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#35777;&#35843;&#26597;&#65292;&#25105;&#20204;&#21457;&#29616;&#23545;&#20110;&#20004;&#23618;ReLU&#32593;&#32476;&#23384;&#22312;&#20197;&#19979;&#19977;&#31181;&#24773;&#20917;&#65306;(1) &#24179;&#22374;&#24615;&#30830;&#23454;&#26263;&#31034;&#27867;&#21270;&#65307;(2) &#23384;&#22312;&#26368;&#24179;&#22374;&#30340;&#38750;&#27867;&#21270;&#27169;&#22411;&#65292;&#23574;&#38160;&#24615;&#26368;&#23567;&#21270;&#31639;&#27861;&#26080;&#27861;&#27867;&#21270;&#65307;(3) &#26356;&#21152;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#23384;&#22312;&#38750;&#27867;&#21270;&#26368;&#24179;&#22374;&#30340;&#27169;&#22411;&#65292;&#20294;&#23574;&#38160;&#24615;&#26368;&#23567;&#21270;&#31639;&#27861;&#20173;&#28982;&#33021;&#22815;&#27867;&#21270;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#23574;&#38160;&#24615;&#19982;&#27867;&#21270;&#20043;&#38388;&#30340;&#20851;&#31995;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#21462;&#20915;&#20110;&#25968;&#25454;&#20998;&#24067;&#21644;&#27169;&#22411;&#26550;&#26500;&#65292;&#23574;&#38160;&#24615;&#26368;&#23567;&#21270;&#31639;&#27861;&#19981;&#20165;&#20165;&#26159;&#20026;&#20102;&#26368;&#23567;&#21270;&#23574;&#38160;&#24615;&#32780;&#36798;&#21040;&#26356;&#22909;&#30340;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite extensive studies, the underlying reason as to why overparameterized neural networks can generalize remains elusive. Existing theory shows that common stochastic optimizers prefer flatter minimizers of the training loss, and thus a natural potential explanation is that flatness implies generalization. This work critically examines this explanation. Through theoretical and empirical investigation, we identify the following three scenarios for two-layer ReLU networks: (1) flatness provably implies generalization; (2) there exist non-generalizing flattest models and sharpness minimization algorithms fail to generalize, and (3) perhaps most surprisingly, there exist non-generalizing flattest models, but sharpness minimization algorithms still generalize. Our results suggest that the relationship between sharpness and generalization subtly depends on the data distributions and the model architectures and sharpness minimization algorithms do not only minimize sharpness to achieve bet
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;AFT&#25490;&#21517;&#22238;&#24402;&#27169;&#22411;&#65292;&#29992;&#20110;&#28789;&#27963;&#22320;&#36827;&#34892;&#26102;&#38388;&#20107;&#20214;&#24314;&#27169;&#65292;&#20174;&#32780;&#25913;&#21892;&#39044;&#27979;&#24615;&#33021;&#24182;&#20943;&#36731;&#20005;&#26684;&#30340;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2307.08044</link><description>&lt;p&gt;
&#26580;&#24615;&#26102;&#38388;&#20107;&#20214;&#24314;&#27169;&#65306;&#36890;&#36807;&#25490;&#21517;&#22238;&#24402;&#20248;&#21270;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Towards Flexible Time-to-event Modeling: Optimizing Neural Networks via Rank Regression. (arXiv:2307.08044v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08044
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;AFT&#25490;&#21517;&#22238;&#24402;&#27169;&#22411;&#65292;&#29992;&#20110;&#28789;&#27963;&#22320;&#36827;&#34892;&#26102;&#38388;&#20107;&#20214;&#24314;&#27169;&#65292;&#20174;&#32780;&#25913;&#21892;&#39044;&#27979;&#24615;&#33021;&#24182;&#20943;&#36731;&#20005;&#26684;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#20107;&#20214;&#20998;&#26512;&#65292;&#20063;&#34987;&#31216;&#20026;&#29983;&#23384;&#20998;&#26512;&#65292;&#26088;&#22312;&#26681;&#25454;&#19968;&#32452;&#29305;&#24449;&#39044;&#27979;&#20107;&#20214;&#21457;&#29983;&#30340;&#26102;&#38388;&#12290;&#36825;&#20010;&#39046;&#22495;&#38754;&#20020;&#30340;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#26159;&#22788;&#29702;&#34987;&#25130;&#23614;&#30340;&#25968;&#25454;&#65292;&#36825;&#21487;&#33021;&#20351;&#23398;&#20064;&#31639;&#27861;&#26356;&#21152;&#22797;&#26434;&#12290;&#20256;&#32479;&#26041;&#27861;&#22914;Cox&#27604;&#20363;&#39118;&#38505;&#27169;&#22411;&#21644;&#21152;&#36895;&#22833;&#25928;&#26102;&#38388;&#65288;AFT&#65289;&#27169;&#22411;&#22312;&#36825;&#20010;&#39046;&#22495;&#24456;&#21463;&#27426;&#36814;&#65292;&#20294;&#23427;&#20204;&#32463;&#24120;&#38656;&#35201;&#19968;&#20123;&#20551;&#35774;&#65292;&#22914;&#27604;&#20363;&#39118;&#38505;&#21644;&#32447;&#24615;&#12290;&#29305;&#21035;&#26159;&#65292;AFT&#27169;&#22411;&#36890;&#24120;&#38656;&#35201;&#39044;&#20808;&#25351;&#23450;&#30340;&#21442;&#25968;&#20998;&#24067;&#20551;&#35774;&#12290;&#20026;&#20102;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#21644;&#20943;&#36731;&#20005;&#26684;&#30340;&#20551;&#35774;&#65292;&#36817;&#24180;&#26469;&#20986;&#29616;&#20102;&#35768;&#22810;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#21361;&#38505;&#27169;&#22411;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#31070;&#32463;&#32593;&#32476;&#25991;&#29486;&#20013;&#23545;&#20110;AFT&#30340;&#34920;&#31034;&#23398;&#20064;&#23578;&#26410;&#24191;&#27867;&#25506;&#32034;&#65292;&#23613;&#31649;&#30456;&#23545;&#20110;&#20197;&#21361;&#38505;&#20026;&#37325;&#28857;&#30340;&#26041;&#27861;&#32780;&#35328;&#65292;&#23427;&#26356;&#21152;&#31616;&#21333;&#21644;&#21487;&#35299;&#37322;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#28145;&#24230;AFT&#25490;&#21517;&#22238;&#24402;&#27169;&#22411;&#26469;&#36827;&#34892;&#26102;&#38388;&#20107;&#20214;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Time-to-event analysis, also known as survival analysis, aims to predict the time of occurrence of an event, given a set of features. One of the major challenges in this area is dealing with censored data, which can make learning algorithms more complex. Traditional methods such as Cox's proportional hazards model and the accelerated failure time (AFT) model have been popular in this field, but they often require assumptions such as proportional hazards and linearity. In particular, the AFT models often require pre-specified parametric distributional assumptions. To improve predictive performance and alleviate strict assumptions, there have been many deep learning approaches for hazard-based models in recent years. However, representation learning for AFT has not been widely explored in the neural network literature, despite its simplicity and interpretability in comparison to hazard-focused methods. In this work, we introduce the Deep AFT Rank-regression model for Time-to-event predic
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20197;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;&#20026;&#22522;&#30784;&#65292;&#25552;&#20986;&#20102;&#23398;&#20064;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#28151;&#21512;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#12290;&#31639;&#27861;&#25104;&#21151;&#22320;&#24212;&#29992;&#20110;&#27809;&#26377;&#32452;&#20214;&#20998;&#31163;&#26465;&#20214;&#30340;&#24773;&#20917;&#65292;&#24182;&#21487;&#20197;&#19982;&#36125;&#21494;&#26031;&#26368;&#20248;&#32858;&#31867;&#31454;&#20105;&#12290;&#27492;&#22806;&#65292;&#31639;&#27861;&#21487;&#20197;&#22312;&#37096;&#20998;&#35266;&#27979;&#35774;&#32622;&#19979;&#24037;&#20316;&#12290;</title><link>http://arxiv.org/abs/2307.06538</link><description>&lt;p&gt;
&#24352;&#37327;&#20998;&#35299;&#19982;&#25511;&#21046;&#29702;&#35770;&#30340;&#32467;&#21512;&#65306;&#23398;&#20064;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#30340;&#28151;&#21512;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Tensor Decompositions Meet Control Theory: Learning General Mixtures of Linear Dynamical Systems. (arXiv:2307.06538v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06538
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20197;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;&#20026;&#22522;&#30784;&#65292;&#25552;&#20986;&#20102;&#23398;&#20064;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#28151;&#21512;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#12290;&#31639;&#27861;&#25104;&#21151;&#22320;&#24212;&#29992;&#20110;&#27809;&#26377;&#32452;&#20214;&#20998;&#31163;&#26465;&#20214;&#30340;&#24773;&#20917;&#65292;&#24182;&#21487;&#20197;&#19982;&#36125;&#21494;&#26031;&#26368;&#20248;&#32858;&#31867;&#31454;&#20105;&#12290;&#27492;&#22806;&#65292;&#31639;&#27861;&#21487;&#20197;&#22312;&#37096;&#20998;&#35266;&#27979;&#35774;&#32622;&#19979;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;Chen&#21644;Poor&#24320;&#22987;&#30740;&#31350;&#23398;&#20064;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#30340;&#28151;&#21512;&#27169;&#22411;&#12290;&#34429;&#28982;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#24050;&#32463;&#22312;&#24314;&#27169;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#26041;&#38754;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#65292;&#20294;&#20351;&#29992;&#28151;&#21512;&#27169;&#22411;&#21487;&#20197;&#24102;&#26469;&#26356;&#22909;&#30340;&#25311;&#21512;&#25110;&#32773;&#23545;&#25968;&#25454;&#20013;&#34920;&#31034;&#30340;&#22522;&#30784;&#23376;&#32676;&#20307;&#26377;&#26356;&#20016;&#23500;&#30340;&#29702;&#35299;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24352;&#37327;&#20998;&#35299;&#30340;&#23398;&#20064;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#28151;&#21512;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#32452;&#20214;&#26080;&#24378;&#20998;&#31163;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#25104;&#21151;&#65292;&#24182;&#21487;&#20197;&#29992;&#20110;&#19982;&#36712;&#36857;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#32858;&#31867;&#31454;&#20105;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#36866;&#29992;&#20110;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#37096;&#20998;&#35266;&#27979;&#35774;&#32622;&#12290;&#25105;&#20204;&#30340;&#36215;&#28857;&#26159;&#31616;&#21333;&#20294;&#24378;&#22823;&#30340;&#35266;&#23519;&#65292;&#21363;&#32463;&#20856;&#30340;&#20309;-&#21345;&#23572;&#26364;&#31639;&#27861;&#26159;&#23398;&#20064;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#29616;&#20195;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;&#30340;&#36817;&#20146;&#12290;&#36825;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#25193;&#23637;&#21040;&#26356;&#22797;&#26434;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#25805;&#20316;&#25351;&#21335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently Chen and Poor initiated the study of learning mixtures of linear dynamical systems. While linear dynamical systems already have wide-ranging applications in modeling time-series data, using mixture models can lead to a better fit or even a richer understanding of underlying subpopulations represented in the data. In this work we give a new approach to learning mixtures of linear dynamical systems that is based on tensor decompositions. As a result, our algorithm succeeds without strong separation conditions on the components, and can be used to compete with the Bayes optimal clustering of the trajectories. Moreover our algorithm works in the challenging partially-observed setting. Our starting point is the simple but powerful observation that the classic Ho-Kalman algorithm is a close relative of modern tensor decomposition methods for learning latent variable models. This gives us a playbook for how to extend it to work with more complicated generative models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#28789;&#27963;&#30340;PFN&#20316;&#20026;BO&#20195;&#29702;&#24314;&#27169;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#20801;&#35768;&#36827;&#19968;&#27493;&#20449;&#24687;&#32435;&#20837;&#20197;&#36827;&#34892;&#38750;&#36828;&#35270;BO&#12290;&#22312;&#19977;&#31181;&#19981;&#21516;&#30340;&#38382;&#39064;&#19978;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.17535</link><description>&lt;p&gt;
PFN&#26159;&#36866;&#29992;&#20110;&#23454;&#38469;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#28789;&#27963;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
PFNs Are Flexible Models for Real-World Bayesian Optimization. (arXiv:2305.17535v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17535
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#28789;&#27963;&#30340;PFN&#20316;&#20026;BO&#20195;&#29702;&#24314;&#27169;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#20801;&#35768;&#36827;&#19968;&#27493;&#20449;&#24687;&#32435;&#20837;&#20197;&#36827;&#34892;&#38750;&#36828;&#35270;BO&#12290;&#22312;&#19977;&#31181;&#19981;&#21516;&#30340;&#38382;&#39064;&#19978;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#20808;&#39564;&#25968;&#25454;&#25311;&#21512;&#32593;&#32476;(PFNs)&#20316;&#20026;&#36125;&#21494;&#26031;&#20248;&#21270;(BO)&#30340;&#28789;&#27963;&#20195;&#29702;&#12290;PFN&#26159;&#19968;&#31181;&#31070;&#32463;&#36807;&#31243;&#65292;&#34987;&#35757;&#32451;&#29992;&#20110;&#36817;&#20284;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;(PPD)&#65292;&#36866;&#29992;&#20110;&#20219;&#20309;&#21487;&#26377;&#25928;&#37319;&#26679;&#30340;&#20808;&#39564;&#20998;&#24067;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#22914;&#20309;&#21033;&#29992;&#36825;&#31181;&#28789;&#27963;&#24615;&#26469;&#36827;&#34892;BO&#30340;&#20195;&#29702;&#24314;&#27169;&#12290;&#25105;&#20204;&#20351;&#29992;PFN&#26469;&#27169;&#25311;&#19968;&#20010;&#26420;&#32032;&#39640;&#26031;&#36807;&#31243;(GP)&#65292;&#19968;&#20010;&#20808;&#36827;&#30340;GP&#21644;&#19968;&#20010;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;(BNN)&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#36827;&#19968;&#27493;&#30340;&#20449;&#24687;&#32435;&#20837;&#20808;&#39564;&#65292;&#20363;&#22914;&#20801;&#35768;&#26377;&#20851;&#26368;&#20248;&#20301;&#32622;&#30340;&#25552;&#31034;(&#29992;&#25143;&#20808;&#39564;)&#65292;&#24573;&#30053;&#19981;&#30456;&#20851;&#30340;&#32500;&#24230;&#65292;&#24182;&#36890;&#36807;&#23398;&#20064;&#33719;&#21462;&#20989;&#25968;&#26469;&#25191;&#34892;&#38750;&#36828;&#35270;BO&#12290;&#36825;&#20123;&#25193;&#23637;&#30340;&#28789;&#27963;&#24615;&#20026;&#20351;&#29992;PFN&#36827;&#34892;BO&#24320;&#36767;&#20102;&#24191;&#38420;&#30340;&#21487;&#33021;&#24615;&#12290;&#25105;&#20204;&#22312;&#20154;&#24037;&#39640;&#26031;&#36807;&#31243;&#26679;&#26412;&#21644;&#19977;&#20010;&#19981;&#21516;&#30340;&#36229;&#21442;&#25968;&#20248;&#21270;&#27979;&#35797;&#24179;&#21488;&#19978;&#23637;&#31034;&#20102;PFN&#23545;BO&#30340;&#26377;&#29992;&#24615;&#65306;HPO-B&#12289;Bayesmark&#21644;PD1&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we use Prior-data Fitted Networks (PFNs) as a flexible surrogate for Bayesian Optimization (BO). PFNs are neural processes that are trained to approximate the posterior predictive distribution (PPD) for any prior distribution that can be efficiently sampled from. We describe how this flexibility can be exploited for surrogate modeling in BO. We use PFNs to mimic a naive Gaussian process (GP), an advanced GP, and a Bayesian Neural Network (BNN). In addition, we show how to incorporate further information into the prior, such as allowing hints about the position of optima (user priors), ignoring irrelevant dimensions, and performing non-myopic BO by learning the acquisition function. The flexibility underlying these extensions opens up vast possibilities for using PFNs for BO. We demonstrate the usefulness of PFNs for BO in a large-scale evaluation on artificial GP samples and three different hyperparameter optimization testbeds: HPO-B, Bayesmark, and PD1. We publish code 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20351;&#29992;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#36890;&#29992;&#36924;&#36817;&#22120;&#20026;&#26500;&#24314;&#22359;&#65292;&#26500;&#24314;&#20102;&#22312;&#20219;&#24847;&#27874;&#20848;&#24230;&#37327;&#31354;&#38388; $\mathcal{X}$ &#21644; $\mathcal{Y}$ &#20043;&#38388;&#30340;&#36890;&#29992;&#36924;&#36817;&#22120;&#65292;&#24182;&#36890;&#36807;&#38543;&#26426;&#21270;&#36755;&#20986;&#31163;&#25955;&#27010;&#29575;&#27979;&#24230;&#26469;&#20811;&#26381;&#26576;&#20123;&#38480;&#21046;&#12290;&#22312;&#36866;&#24403;&#30340;&#32467;&#26500;&#19979;&#25552;&#20379;&#20102;&#27010;&#29575;&#21644;&#23450;&#37327;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2304.12231</link><description>&lt;p&gt;
&#19968;&#31181;&#36716;&#31227;&#21407;&#29702;&#65306;&#20174;&#27431;&#20960;&#37324;&#24471;&#36890;&#29992;&#36924;&#36817;&#22120;&#21040;&#24230;&#37327;&#31354;&#38388;&#20043;&#38388;&#30340;&#36890;&#29992;&#36924;&#36817;&#22120;
&lt;/p&gt;
&lt;p&gt;
A Transfer Principle: Universal Approximators Between Metric Spaces From Euclidean Universal Approximators. (arXiv:2304.12231v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12231
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20351;&#29992;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#36890;&#29992;&#36924;&#36817;&#22120;&#20026;&#26500;&#24314;&#22359;&#65292;&#26500;&#24314;&#20102;&#22312;&#20219;&#24847;&#27874;&#20848;&#24230;&#37327;&#31354;&#38388; $\mathcal{X}$ &#21644; $\mathcal{Y}$ &#20043;&#38388;&#30340;&#36890;&#29992;&#36924;&#36817;&#22120;&#65292;&#24182;&#36890;&#36807;&#38543;&#26426;&#21270;&#36755;&#20986;&#31163;&#25955;&#27010;&#29575;&#27979;&#24230;&#26469;&#20811;&#26381;&#26576;&#20123;&#38480;&#21046;&#12290;&#22312;&#36866;&#24403;&#30340;&#32467;&#26500;&#19979;&#25552;&#20379;&#20102;&#27010;&#29575;&#21644;&#23450;&#37327;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20351;&#29992;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#36890;&#29992;&#36924;&#36817;&#22120;&#20316;&#20026;&#26500;&#24314;&#22359;&#65292;&#26500;&#24314;&#20102;&#36830;&#32493;&#26144;&#23556;&#30340;&#24230;&#37327;&#31354;&#38388;&#20043;&#38388;&#30340;&#36890;&#29992;&#36924;&#36817;&#22120;&#12290;&#26089;&#26399;&#32467;&#26524;&#20551;&#23450;&#36755;&#20986;&#31354;&#38388; $\mathcal{Y}$ &#26159;&#25299;&#25169;&#21521;&#37327;&#31354;&#38388;&#12290;&#25105;&#20204;&#36890;&#36807;&#8220;&#38543;&#26426;&#21270;&#8221;&#26469;&#20811;&#26381;&#36825;&#31181;&#38480;&#21046;&#65306;&#25105;&#20204;&#30340;&#36924;&#36817;&#22120;&#36755;&#20986; $\mathcal{Y}$ &#19978;&#30340;&#31163;&#25955;&#27010;&#29575;&#27979;&#24230;&#12290;&#24403; $\mathcal{X}$ &#21644; $\mathcal{Y}$ &#27809;&#26377;&#38468;&#21152;&#32467;&#26500;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#38750;&#24120;&#36890;&#29992;&#30340;&#23450;&#24615;&#20445;&#35777;&#65307;&#24403;&#23427;&#20204;&#20855;&#26377;&#36866;&#24403;&#30340;&#32452;&#21512;&#32467;&#26500;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102; H\"older &#31867;&#26144;&#23556;&#30340;&#23450;&#37327;&#20445;&#35777;&#65292;&#21253;&#25324;&#26377;&#38480;&#22270;&#20043;&#38388;&#30340;&#26144;&#23556;&#65292;&#22312;&#26576;&#20123; Carnot &#32676;&#20043;&#38388;&#30340;&#31895;&#24494;&#20998;&#26041;&#31243;&#30340;&#35299;&#31639;&#23376;&#20197;&#21450;&#21453;&#38382;&#39064;&#20013;&#20986;&#29616;&#30340; Banach &#31354;&#38388;&#20043;&#38388;&#30340;&#36830;&#32493;&#38750;&#32447;&#24615;&#31639;&#23376;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#38656;&#30340; Dirac &#27979;&#24230;&#25968;&#37327;&#30001; $\mathcal{X}$ &#21644; $\mathcal{Y}$ &#30340;&#32452;&#21512;&#32467;&#26500;&#20915;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
We build universal approximators of continuous maps between arbitrary Polish metric spaces $\mathcal{X}$ and $\mathcal{Y}$ using universal approximators between Euclidean spaces as building blocks. Earlier results assume that the output space $\mathcal{Y}$ is a topological vector space. We overcome this limitation by "randomization": our approximators output discrete probability measures over $\mathcal{Y}$. When $\mathcal{X}$ and $\mathcal{Y}$ are Polish without additional structure, we prove very general qualitative guarantees; when they have suitable combinatorial structure, we prove quantitative guarantees for H\"older-like maps, including maps between finite graphs, solution operators to rough differential equations between certain Carnot groups, and continuous non-linear operators between Banach spaces arising in inverse problems. In particular, we show that the required number of Dirac measures is determined by the combinatorial structure of $\mathcal{X}$ and $\mathcal{Y}$. For b
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#65292;&#24403;&#27169;&#22411;&#31867;&#36275;&#22815;&#20016;&#23500;&#20197;&#28085;&#30422;&#30495;&#23454;&#24773;&#20917;&#26102;&#65292;&#38750;&#32447;&#24615;&#38382;&#39064;&#30340;&#8220;&#20808;&#20272;&#35745;&#20877;&#20248;&#21270;&#8221;&#26041;&#27861;&#20248;&#20110;&#38598;&#25104;&#26041;&#27861;&#65292;&#21253;&#25324;&#20248;&#21270;&#38388;&#38553;&#30340;&#28176;&#36827;&#20248;&#21183;&#30340;&#22343;&#20540;&#65292;&#25152;&#26377;&#20854;&#20182;&#26102;&#21051;&#21644;&#25972;&#20010;&#28176;&#36827;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2304.06833</link><description>&lt;p&gt;
&#35780;&#20272;-&#20248;&#21270;&#26041;&#27861;&#19982;&#38598;&#25104;&#35780;&#20272;&#20248;&#21270;&#27861;&#65306;&#22522;&#20110;&#38543;&#26426;&#20248;&#21183;&#30340;&#35266;&#28857;
&lt;/p&gt;
&lt;p&gt;
Estimate-Then-Optimize Versus Integrated-Estimation-Optimization: A Stochastic Dominance Perspective. (arXiv:2304.06833v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06833
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#65292;&#24403;&#27169;&#22411;&#31867;&#36275;&#22815;&#20016;&#23500;&#20197;&#28085;&#30422;&#30495;&#23454;&#24773;&#20917;&#26102;&#65292;&#38750;&#32447;&#24615;&#38382;&#39064;&#30340;&#8220;&#20808;&#20272;&#35745;&#20877;&#20248;&#21270;&#8221;&#26041;&#27861;&#20248;&#20110;&#38598;&#25104;&#26041;&#27861;&#65292;&#21253;&#25324;&#20248;&#21270;&#38388;&#38553;&#30340;&#28176;&#36827;&#20248;&#21183;&#30340;&#22343;&#20540;&#65292;&#25152;&#26377;&#20854;&#20182;&#26102;&#21051;&#21644;&#25972;&#20010;&#28176;&#36827;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#25454;&#39537;&#21160;&#30340;&#38543;&#26426;&#20248;&#21270;&#20013;&#65292;&#38500;&#20102;&#38656;&#35201;&#20248;&#21270;&#20219;&#21153;&#65292;&#36824;&#38656;&#35201;&#20174;&#25968;&#25454;&#20013;&#20272;&#35745;&#28508;&#22312;&#20998;&#24067;&#30340;&#27169;&#22411;&#21442;&#25968;&#12290;&#26368;&#36817;&#30340;&#25991;&#29486;&#34920;&#26126;&#65292;&#36890;&#36807;&#36873;&#25321;&#23548;&#33268;&#26368;&#20339;&#32463;&#39564;&#30446;&#26631;&#24615;&#33021;&#30340;&#27169;&#22411;&#21442;&#25968;&#65292;&#21487;&#20197;&#38598;&#25104;&#20272;&#35745;&#21644;&#20248;&#21270;&#36807;&#31243;&#12290;&#24403;&#27169;&#22411;&#34987;&#38169;&#35823;&#22320;&#25351;&#23450;&#26102;&#65292;&#36825;&#31181;&#38598;&#25104;&#26041;&#27861;&#21487;&#20197;&#24456;&#23481;&#26131;&#22320;&#26174;&#31034;&#20986;&#20248;&#20110;&#31616;&#21333;&#30340;&#8220;&#20808;&#20272;&#35745;&#20877;&#20248;&#21270;&#8221;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#35748;&#20026;&#65292;&#22312;&#27169;&#22411;&#31867;&#36275;&#22815;&#20016;&#23500;&#20197;&#28085;&#30422;&#30495;&#23454;&#24773;&#20917;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#20110;&#38750;&#32447;&#24615;&#38382;&#39064;&#65292;&#20004;&#31181;&#26041;&#27861;&#20043;&#38388;&#30340;&#24615;&#33021;&#25490;&#24207;&#22312;&#24378;&#28872;&#30340;&#24847;&#20041;&#19979;&#34987;&#39072;&#20498;&#12290;&#22312;&#21463;&#38480;&#26465;&#20214;&#21644;&#24403;&#19978;&#19979;&#25991;&#29305;&#24449;&#21487;&#29992;&#26102;&#65292;&#31867;&#20284;&#30340;&#32467;&#26524;&#20063;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;
In data-driven stochastic optimization, model parameters of the underlying distribution need to be estimated from data in addition to the optimization task. Recent literature suggests the integration of the estimation and optimization processes, by selecting model parameters that lead to the best empirical objective performance. Such an integrated approach can be readily shown to outperform simple ``estimate then optimize" when the model is misspecified. In this paper, we argue that when the model class is rich enough to cover the ground truth, the performance ordering between the two approaches is reversed for nonlinear problems in a strong sense. Simple ``estimate then optimize" outperforms the integrated approach in terms of stochastic dominance of the asymptotic optimality gap, i,e, the mean, all other moments, and the entire asymptotic distribution of the optimality gap is always better. Analogous results also hold under constrained settings and when contextual features are availa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;Transformer&#23398;&#20064;&#35821;&#20041;&#32467;&#26500;&#30340;&#26426;&#21046;&#24615;&#29702;&#35299;&#65292;&#36890;&#36807;&#25968;&#23398;&#20998;&#26512;&#21644;&#23454;&#39564;&#35777;&#26126;&#20102;&#23884;&#20837;&#23618;&#21644;&#33258;&#27880;&#24847;&#21147;&#23618;&#22914;&#20309;&#23545;&#35789;&#27719;&#30340;&#20849;&#29616;&#32467;&#26500;&#36827;&#34892;&#32534;&#30721;&#12290;</title><link>http://arxiv.org/abs/2303.04245</link><description>&lt;p&gt;
Transformers&#22914;&#20309;&#23398;&#20064;&#20027;&#39064;&#32467;&#26500;&#65306;&#36208;&#21521;&#23545;&#20854;&#26426;&#21046;&#30340;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
How Do Transformers Learn Topic Structure: Towards a Mechanistic Understanding. (arXiv:2303.04245v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.04245
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;Transformer&#23398;&#20064;&#35821;&#20041;&#32467;&#26500;&#30340;&#26426;&#21046;&#24615;&#29702;&#35299;&#65292;&#36890;&#36807;&#25968;&#23398;&#20998;&#26512;&#21644;&#23454;&#39564;&#35777;&#26126;&#20102;&#23884;&#20837;&#23618;&#21644;&#33258;&#27880;&#24847;&#21147;&#23618;&#22914;&#20309;&#23545;&#35789;&#27719;&#30340;&#20849;&#29616;&#32467;&#26500;&#36827;&#34892;&#32534;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;Transformer&#22312;&#35768;&#22810;&#39046;&#22495;&#37117;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#23545;&#20854;&#23398;&#20064;&#26426;&#21046;&#30340;&#20934;&#30830;&#29702;&#35299;&#20173;&#28982;&#23384;&#22312;&#36739;&#22823;&#30340;&#32570;&#20047;&#12290;&#34429;&#28982;&#23427;&#20204;&#22312;&#21253;&#25324;&#21508;&#31181;&#32467;&#26500;&#21270;&#21644;&#25512;&#29702;&#20219;&#21153;&#22312;&#20869;&#30340;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#20102;&#24378;&#22823;&#30340;&#33021;&#21147;&#65292;&#20294;&#23545;&#25968;&#23398;&#29702;&#35299;&#30340;&#30740;&#31350;&#20173;&#28982;&#28382;&#21518;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#24320;&#22987;&#20174;&#34920;&#31034;&#26041;&#38754;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#65306;&#21363;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#32593;&#32476;&#30340;&#22823;&#23567;/&#28145;&#24230;/&#22797;&#26434;&#24615;&#29992;&#20110;&#25191;&#34892;&#26576;&#20123;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#24182;&#19981;&#33021;&#20445;&#35777;&#23398;&#20064;&#21160;&#24577;&#20250;&#25910;&#25947;&#21040;&#25152;&#25552;&#20986;&#30340;&#32467;&#26500;&#19978;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#32454;&#33268;&#20837;&#24494;&#30340;&#26426;&#21046;&#29702;&#35299;&#65292;&#38416;&#26126;&#20102;Transformer&#22914;&#20309;&#23398;&#20064;&#8220;&#35821;&#20041;&#32467;&#26500;&#8221;&#65292;&#21363;&#25429;&#25417;&#35789;&#27719;&#30340;&#20849;&#29616;&#32467;&#26500;&#12290;&#20934;&#30830;&#22320;&#35828;&#65292;&#25105;&#20204;&#36890;&#36807;&#25968;&#23398;&#20998;&#26512;&#21644;&#23545;&#32500;&#22522;&#30334;&#31185;&#25968;&#25454;&#20197;&#21450;&#30001;&#28508;&#22312;&#29380;&#21033;&#20811;&#38647;&#20998;&#37197;&#65288;LDA&#65289;&#24314;&#27169;&#30340;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#30340;&#23454;&#39564;&#65292;&#23637;&#31034;&#20102;&#23884;&#20837;&#23618;&#21644;&#33258;&#27880;&#24847;&#21147;&#23618;&#22914;&#20309;&#23545;&#20027;&#39064;&#36827;&#34892;&#32534;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
While the successes of transformers across many domains are indisputable, accurate understanding of the learning mechanics is still largely lacking. Their capabilities have been probed on benchmarks which include a variety of structured and reasoning tasks -- but mathematical understanding is lagging substantially behind. Recent lines of work have begun studying representational aspects of this question: that is, the size/depth/complexity of attention-based networks to perform certain tasks. However, there is no guarantee the learning dynamics will converge to the constructions proposed. In our paper, we provide fine-grained mechanistic understanding of how transformers learn "semantic structure", understood as capturing co-occurrence structure of words. Precisely, we show, through a combination of mathematical analysis and experiments on Wikipedia data and synthetic data modeled by Latent Dirichlet Allocation (LDA), that the embedding layer and the self-attention layer encode the topi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#20998;&#31867;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#22270;&#29983;&#25104;&#27169;&#22411;&#65292;&#25512;&#23548;&#20986;&#20102;&#32473;&#23450;&#22270;&#30340;&#31867;&#26631;&#31614;&#27010;&#29575;&#30340;&#20998;&#31867;&#20844;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26465;&#20214; ELBO &#29992;&#20110;&#35757;&#32451;&#29983;&#25104;&#22270;&#33258;&#32534;&#30721;&#22120;&#27169;&#22411;&#12290;&#36825;&#26159;&#19968;&#31181;&#22312;&#22270;&#20998;&#31867;&#20013;&#20855;&#26377;&#21019;&#26032;&#24615;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2302.07989</link><description>&lt;p&gt;
&#20174;&#22270;&#29983;&#25104;&#21040;&#22270;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
From Graph Generation to Graph Classification. (arXiv:2302.07989v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07989
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#20998;&#31867;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#22270;&#29983;&#25104;&#27169;&#22411;&#65292;&#25512;&#23548;&#20986;&#20102;&#32473;&#23450;&#22270;&#30340;&#31867;&#26631;&#31614;&#27010;&#29575;&#30340;&#20998;&#31867;&#20844;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26465;&#20214; ELBO &#29992;&#20110;&#35757;&#32451;&#29983;&#25104;&#22270;&#33258;&#32534;&#30721;&#22120;&#27169;&#22411;&#12290;&#36825;&#26159;&#19968;&#31181;&#22312;&#22270;&#20998;&#31867;&#20013;&#20855;&#26377;&#21019;&#26032;&#24615;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25551;&#36848;&#20102;&#19968;&#31181;&#21033;&#29992;&#22270;&#29983;&#25104;&#27169;&#22411; (GGM) &#36827;&#34892;&#22270;&#20998;&#31867;&#30340;&#26032;&#26041;&#27861;&#12290;&#20551;&#35774;&#19968;&#20010;&#23450;&#20041;&#20102;&#22270;&#21450;&#20854;&#31867;&#26631;&#31614;&#30340;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#30340; GGM&#65292;&#25105;&#25512;&#23548;&#20102;&#35745;&#31639;&#32473;&#23450;&#22270;&#30340;&#31867;&#26631;&#31614;&#27010;&#29575;&#30340;&#20998;&#31867;&#20844;&#24335;&#12290;&#21487;&#20197;&#20351;&#29992;&#26032;&#30340;&#26465;&#20214; ELBO &#26469;&#35757;&#32451;&#29983;&#25104;&#22270;&#33258;&#32534;&#30721;&#22120;&#27169;&#22411;&#36827;&#34892;&#21306;&#20998;&#12290;&#34429;&#28982;&#21033;&#29992;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#20998;&#31867;&#22312;&#38750;&#20851;&#31995; i.i.d. &#25968;&#25454;&#20013;&#24050;&#32463;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#30740;&#31350;&#65292;&#20294;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#19968;&#31181;&#22270;&#20998;&#31867;&#30340;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This note describes a new approach to classifying graphs that leverages graph generative models (GGM). Assuming a GGM that defines a joint probability distribution over graphs and their class labels, I derive classification formulas for the probability of a class label given a graph. A new conditional ELBO can be used to train a generative graph auto-encoder model for discrimination. While leveraging generative models for classification has been well explored for non-relational i.i.d. data, to our knowledge it is a novel approach to graph classification.
&lt;/p&gt;</description></item><item><title>DNArch&#26159;&#19968;&#31181;&#36890;&#36807;&#21453;&#21521;&#20256;&#25773;&#21516;&#26102;&#23398;&#20064;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#26435;&#37325;&#21644;&#26550;&#26500;&#30340;&#26041;&#27861;&#65292;&#23427;&#19981;&#20165;&#21487;&#20197;&#23398;&#20064;&#27599;&#19968;&#23618;&#30340;&#21367;&#31215;&#26680;&#22823;&#23567;&#21644;&#36890;&#36947;&#25968;&#65292;&#36824;&#21487;&#20197;&#23398;&#20064;&#32593;&#32476;&#30340;&#28145;&#24230;&#21644;&#19979;&#37319;&#26679;&#23618;&#30340;&#20301;&#32622;&#21644;&#20540;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;DNArch&#19981;&#38480;&#20110;&#39044;&#23450;&#20041;&#30340;&#31070;&#32463;&#32452;&#20214;&#65292;&#33021;&#22815;&#21457;&#29616;&#21508;&#31181;&#26680;&#22823;&#23567;&#12289;&#23485;&#24230;&#12289;&#28145;&#24230;&#21644;&#19979;&#37319;&#26679;&#32452;&#21512;&#20013;&#30340;&#25972;&#20010;CNN&#26550;&#26500;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;DNArch&#22312;&#22810;&#20010;&#20998;&#31867;&#21644;&#23494;&#38598;&#39044;&#27979;&#20219;&#21153;&#19978;&#25214;&#21040;&#20102;&#39640;&#24615;&#33021;&#30340;CNN&#26550;&#26500;&#12290;</title><link>http://arxiv.org/abs/2302.05400</link><description>&lt;p&gt;
DNArch: &#36890;&#36807;&#21453;&#21521;&#20256;&#25773;&#23398;&#20064;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#21487;&#23398;&#20064;&#26550;&#26500;
&lt;/p&gt;
&lt;p&gt;
DNArch: Learning Convolutional Neural Architectures by Backpropagation. (arXiv:2302.05400v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05400
&lt;/p&gt;
&lt;p&gt;
DNArch&#26159;&#19968;&#31181;&#36890;&#36807;&#21453;&#21521;&#20256;&#25773;&#21516;&#26102;&#23398;&#20064;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#26435;&#37325;&#21644;&#26550;&#26500;&#30340;&#26041;&#27861;&#65292;&#23427;&#19981;&#20165;&#21487;&#20197;&#23398;&#20064;&#27599;&#19968;&#23618;&#30340;&#21367;&#31215;&#26680;&#22823;&#23567;&#21644;&#36890;&#36947;&#25968;&#65292;&#36824;&#21487;&#20197;&#23398;&#20064;&#32593;&#32476;&#30340;&#28145;&#24230;&#21644;&#19979;&#37319;&#26679;&#23618;&#30340;&#20301;&#32622;&#21644;&#20540;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;DNArch&#19981;&#38480;&#20110;&#39044;&#23450;&#20041;&#30340;&#31070;&#32463;&#32452;&#20214;&#65292;&#33021;&#22815;&#21457;&#29616;&#21508;&#31181;&#26680;&#22823;&#23567;&#12289;&#23485;&#24230;&#12289;&#28145;&#24230;&#21644;&#19979;&#37319;&#26679;&#32452;&#21512;&#20013;&#30340;&#25972;&#20010;CNN&#26550;&#26500;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;DNArch&#22312;&#22810;&#20010;&#20998;&#31867;&#21644;&#23494;&#38598;&#39044;&#27979;&#20219;&#21153;&#19978;&#25214;&#21040;&#20102;&#39640;&#24615;&#33021;&#30340;CNN&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;Differentiable Neural Architectures (DNArch)&#65292;&#19968;&#31181;&#36890;&#36807;&#21453;&#21521;&#20256;&#25773;&#21516;&#26102;&#23398;&#20064;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(CNNs)&#30340;&#26435;&#37325;&#21644;&#26550;&#26500;&#30340;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;DNArch&#20801;&#35768;&#23398;&#20064;(i)&#27599;&#19968;&#23618;&#30340;&#21367;&#31215;&#26680;&#22823;&#23567;&#65292;(ii)&#27599;&#19968;&#23618;&#30340;&#36890;&#36947;&#25968;&#65292;(iii)&#19979;&#37319;&#26679;&#23618;&#30340;&#20301;&#32622;&#21644;&#20540;&#65292;&#20197;&#21450;(iv)&#32593;&#32476;&#30340;&#28145;&#24230;&#12290;&#20026;&#27492;&#65292;DNArch&#23558;&#31070;&#32463;&#26550;&#26500;&#35270;&#20026;&#36830;&#32493;&#30340;&#22810;&#32500;&#23454;&#20307;&#65292;&#24182;&#20351;&#29992;&#21487;&#23398;&#20064;&#30340;&#21487;&#24494;&#25513;&#30721;&#26469;&#25511;&#21046;&#20854;&#22823;&#23567;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#65292;DNArch&#19981;&#38480;&#20110;&#39044;&#23450;&#20041;&#30340;&#21487;&#33021;&#31070;&#32463;&#32452;&#20214;&#38598;&#65292;&#32780;&#26159;&#33021;&#22815;&#21457;&#29616;&#22312;&#25152;&#26377;&#21487;&#34892;&#30340;&#26680;&#22823;&#23567;&#12289;&#23485;&#24230;&#12289;&#28145;&#24230;&#21644;&#19979;&#37319;&#26679;&#32452;&#21512;&#20013;&#30340;&#25972;&#20010;CNN&#26550;&#26500;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;DNArch&#33021;&#22815;&#20026;&#39034;&#24207;&#21644;&#22270;&#20687;&#25968;&#25454;&#30340;&#22810;&#20010;&#20998;&#31867;&#21644;&#23494;&#38598;&#39044;&#27979;&#20219;&#21153;&#25214;&#21040;&#26377;&#25928;&#30340;CNN&#26550;&#26500;&#12290;&#24403;&#19982;&#25511;&#21046;&#26550;&#26500;&#22823;&#23567;&#30340;&#25439;&#22833;&#39033;&#30456;&#32467;&#21512;&#26102;&#65292;DNArch&#36824;&#33021;&#22312;&#36816;&#34892;&#26102;&#38388;&#21644;&#27169;&#22411;&#24615;&#33021;&#20043;&#38388;&#23454;&#29616;&#26377;&#25928;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present Differentiable Neural Architectures (DNArch), a method that jointly learns the weights and the architecture of Convolutional Neural Networks (CNNs) by backpropagation. In particular, DNArch allows learning (i) the size of convolutional kernels at each layer, (ii) the number of channels at each layer, (iii) the position and values of downsampling layers, and (iv) the depth of the network. To this end, DNArch views neural architectures as continuous multidimensional entities, and uses learnable differentiable masks along each dimension to control their size. Unlike existing methods, DNArch is not limited to a predefined set of possible neural components, but instead it is able to discover entire CNN architectures across all feasible combinations of kernel sizes, widths, depths and downsampling. Empirically, DNArch finds performant CNN architectures for several classification and dense prediction tasks on sequential and image data. When combined with a loss term that controls t
&lt;/p&gt;</description></item><item><title>&#26500;&#24314;&#20102;&#19968;&#31181;&#26032;&#30340;&#29983;&#25104;&#31639;&#27861;&#31867;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#23398;&#20064;&#31232;&#32570;&#39640;&#32500;&#25968;&#25454;&#30340;&#20219;&#24847;&#30446;&#26631;&#20998;&#24067;&#24182;&#29983;&#25104;&#26032;&#26679;&#26412;&#65292;&#20855;&#26377;&#24456;&#22909;&#30340;&#25968;&#25454;&#25972;&#21512;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2210.17230</link><description>&lt;p&gt;
Lipschitz&#27491;&#21017;&#21270;&#26799;&#24230;&#27969;&#21644;&#39640;&#32500;&#31232;&#32570;&#25968;&#25454;&#30340;&#29983;&#25104;&#31890;&#23376;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Lipschitz-regularized gradient flows and generative particle algorithms for high-dimensional scarce data. (arXiv:2210.17230v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.17230
&lt;/p&gt;
&lt;p&gt;
&#26500;&#24314;&#20102;&#19968;&#31181;&#26032;&#30340;&#29983;&#25104;&#31639;&#27861;&#31867;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#23398;&#20064;&#31232;&#32570;&#39640;&#32500;&#25968;&#25454;&#30340;&#20219;&#24847;&#30446;&#26631;&#20998;&#24067;&#24182;&#29983;&#25104;&#26032;&#26679;&#26412;&#65292;&#20855;&#26377;&#24456;&#22909;&#30340;&#25968;&#25454;&#25972;&#21512;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#31181;&#26032;&#30340;&#29983;&#25104;&#31639;&#27861;&#31867;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#20174;&#21487;&#33021;&#31232;&#32570;&#12289;&#39640;&#32500;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#20219;&#24847;&#30446;&#26631;&#20998;&#24067;&#65292;&#24182;&#29983;&#25104;&#26032;&#30340;&#26679;&#26412;&#12290;&#36825;&#20123;&#29983;&#25104;&#31639;&#27861;&#26159;&#22522;&#20110;&#31890;&#23376;&#30340;&#65292;&#24182;&#19988;&#26159;&#36890;&#36807;Lipschitz&#27491;&#21017;&#21270;Kullback-Leibler&#25110;&#20854;&#20182;f-&#25955;&#24230;&#30340;&#26799;&#24230;&#27969;&#26469;&#26500;&#36896;&#30340;&#65292;&#20854;&#20013;&#26469;&#33258;&#28304;&#20998;&#24067;&#30340;&#25968;&#25454;&#21487;&#20197;&#31283;&#23450;&#22320;&#20316;&#20026;&#31890;&#23376;&#20256;&#36755;&#21040;&#30446;&#26631;&#20998;&#24067;&#30340;&#38468;&#36817;&#12290;&#20316;&#20026;&#25968;&#25454;&#25972;&#21512;&#30340;&#19968;&#20010;&#31361;&#20986;&#32467;&#26524;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#21487;&#20197;&#27491;&#30830;&#20256;&#36755;&#32500;&#25968;&#36229;&#36807;54K&#30340;&#22522;&#22240;&#34920;&#36798;&#25968;&#25454;&#28857;&#65292;&#32780;&#26679;&#26412;&#37327;&#36890;&#24120;&#21482;&#26377;&#20960;&#30334;&#20010;&#12290;
&lt;/p&gt;
&lt;p&gt;
We build a new class of generative algorithms capable of efficiently learning an arbitrary target distribution from possibly scarce, high-dimensional data and subsequently generate new samples. These generative algorithms are particle-based and are constructed as gradient flows of Lipschitz-regularized Kullback-Leibler or other $f$-divergences, where data from a source distribution can be stably transported as particles, towards the vicinity of the target distribution. As a highlighted result in data integration, we demonstrate that the proposed algorithms correctly transport gene expression data points with dimension exceeding 54K, while the sample size is typically only in the hundreds.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#20004;&#20010;&#26080;&#31351;&#32500;Sobolev&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20043;&#38388;&#30340;Hilbert-Schmidt&#31639;&#23376;&#30340;&#32479;&#35745;&#26497;&#38480;&#65292;&#22312;&#22810;&#23618;&#32423;&#35757;&#32451;&#26041;&#27861;&#19979;&#65292;&#36890;&#36807;&#23398;&#20064;&#20559;&#24046;&#20197;&#19979;&#30340;&#35889;&#20998;&#37327;&#21644;&#24573;&#30053;&#26041;&#24046;&#20197;&#19978;&#30340;&#20998;&#37327;&#65292;&#21487;&#20197;&#36798;&#21040;&#26368;&#20248;&#30340;&#23398;&#20064;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2209.14430</link><description>&lt;p&gt;
&#26368;&#23567;&#21270;&#25439;&#22833;&#30340;&#22810;&#23618;&#35757;&#32451;&#26041;&#27861;&#19979;&#30340;&#26368;&#20248;&#26680;&#31639;&#23376;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Minimax Optimal Kernel Operator Learning via Multilevel Training. (arXiv:2209.14430v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.14430
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#20004;&#20010;&#26080;&#31351;&#32500;Sobolev&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20043;&#38388;&#30340;Hilbert-Schmidt&#31639;&#23376;&#30340;&#32479;&#35745;&#26497;&#38480;&#65292;&#22312;&#22810;&#23618;&#32423;&#35757;&#32451;&#26041;&#27861;&#19979;&#65292;&#36890;&#36807;&#23398;&#20064;&#20559;&#24046;&#20197;&#19979;&#30340;&#35889;&#20998;&#37327;&#21644;&#24573;&#30053;&#26041;&#24046;&#20197;&#19978;&#30340;&#20998;&#37327;&#65292;&#21487;&#20197;&#36798;&#21040;&#26368;&#20248;&#30340;&#23398;&#20064;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26080;&#31351;&#32500;&#20989;&#25968;&#31354;&#38388;&#20013;&#23398;&#20064;&#26144;&#23556;&#24050;&#32463;&#22312;&#26426;&#22120;&#23398;&#20064;&#30340;&#35768;&#22810;&#39046;&#22495;&#20013;&#21462;&#24471;&#20102;&#32463;&#39564;&#19978;&#30340;&#25104;&#21151;&#65292;&#21253;&#25324;&#29983;&#25104;&#27169;&#22411;&#12289;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#12289;&#22240;&#26524;&#25512;&#26029;&#21644;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#20004;&#20010;&#26080;&#31351;&#32500;Sobolev&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20043;&#38388;&#30340;Hilbert-Schmidt&#31639;&#23376;&#30340;&#32479;&#35745;&#26497;&#38480;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#20351;&#29992;Sobolev Hilbert-Schmidt&#33539;&#25968;&#30340;&#20449;&#24687;&#29702;&#35770;&#19979;&#30028;&#65292;&#24182;&#23637;&#31034;&#20102;&#19968;&#20010;&#35268;&#21017;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#20559;&#24046;&#36718;&#24275;&#20197;&#19979;&#30340;&#35889;&#20998;&#37327;&#24182;&#24573;&#30053;&#26041;&#24046;&#36718;&#24275;&#20197;&#19978;&#30340;&#20998;&#37327;&#65292;&#21487;&#20197;&#36798;&#21040;&#26368;&#20248;&#30340;&#23398;&#20064;&#36895;&#29575;&#12290;&#21516;&#26102;&#65292;&#20559;&#24046;&#21644;&#26041;&#24046;&#36718;&#24275;&#20043;&#38388;&#30340;&#35889;&#20998;&#37327;&#32473;&#25105;&#20204;&#22312;&#35774;&#35745;&#35745;&#31639;&#19978;&#21487;&#34892;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#26102;&#25552;&#20379;&#20102;&#28789;&#27963;&#24615;&#12290;&#22522;&#20110;&#36825;&#19968;&#35266;&#23519;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22810;&#23618;&#32423;&#30340;&#26680;&#31639;&#23376;&#23398;&#20064;&#31639;&#27861;&#65292;&#24403;&#23398;&#20064;&#32447;&#24615;&#31639;&#23376;&#26102;&#23427;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning mappings between infinite-dimensional function spaces has achieved empirical success in many disciplines of machine learning, including generative modeling, functional data analysis, causal inference, and multi-agent reinforcement learning. In this paper, we study the statistical limit of learning a Hilbert-Schmidt operator between two infinite-dimensional Sobolev reproducing kernel Hilbert spaces. We establish the information-theoretic lower bound in terms of the Sobolev Hilbert-Schmidt norm and show that a regularization that learns the spectral components below the bias contour and ignores the ones that are above the variance contour can achieve the optimal learning rate. At the same time, the spectral components between the bias and variance contours give us flexibility in designing computationally feasible machine learning algorithms. Based on this observation, we develop a multilevel kernel operator learning algorithm that is optimal when learning linear operators betwee
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#38459;&#22622;Gibbs&#37319;&#26679;&#26041;&#27861;&#65292;&#21487;&#20197;&#26356;&#21487;&#34892;&#22320;&#36827;&#34892;&#23567;&#25209;&#37327;MCMC&#37319;&#26679;&#65292;&#25552;&#39640;&#20102;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#21644;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#37327;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2208.11389</link><description>&lt;p&gt;
Bayesian&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#36817;&#20284;&#38459;&#22622;Gibbs&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Approximate blocked Gibbs sampling for Bayesian neural networks. (arXiv:2208.11389v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.11389
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#38459;&#22622;Gibbs&#37319;&#26679;&#26041;&#27861;&#65292;&#21487;&#20197;&#26356;&#21487;&#34892;&#22320;&#36827;&#34892;&#23567;&#25209;&#37327;MCMC&#37319;&#26679;&#65292;&#25552;&#39640;&#20102;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#21644;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#37327;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#21487;&#34892;&#30340;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#30340;&#23567;&#25209;&#37327;MCMC&#37319;&#26679;&#26041;&#27861;&#12290;&#20026;&#27492;&#65292;&#25991;&#20013;&#25552;&#20986;&#20102;&#36890;&#36807;&#38459;&#22622;Gibbs&#37319;&#26679;&#26041;&#26696;&#23545;&#21442;&#25968;&#36827;&#34892;&#23376;&#32452;&#25277;&#26679;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#23545;&#21442;&#25968;&#31354;&#38388;&#36827;&#34892;&#21010;&#20998;&#65292;&#26080;&#35770;&#23618;&#23485;&#22914;&#20309;&#65292;&#37117;&#33021;&#36827;&#34892;&#37319;&#26679;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#22312;&#28145;&#23618;&#20943;&#23567;&#24314;&#35758;&#26041;&#24046;&#65292;&#21487;&#20197;&#20943;&#36731;&#36882;&#22686;&#28145;&#24230;&#26102;&#28040;&#22833;&#30340;&#25509;&#21463;&#29575;&#38382;&#39064;&#12290;&#22312;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;&#22686;&#21152;&#38750;&#25910;&#25947;&#38142;&#30340;&#38271;&#24230;&#21487;&#20197;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#65292;&#22240;&#27492;&#36991;&#20813;&#28040;&#22833;&#30340;&#25509;&#21463;&#29575;&#21644;&#20801;&#35768;&#26356;&#38271;&#30340;&#38142;&#36816;&#34892;&#20855;&#26377;&#23454;&#38469;&#22909;&#22788;&#12290;&#27492;&#22806;&#65292;&#38750;&#25910;&#25947;&#38142;&#30340;&#23454;&#29616;&#26377;&#21161;&#20110;&#37327;&#21270;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#12290;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#26159;&#22312;&#23384;&#22312;&#22686;&#24191;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#22914;&#20309;&#36827;&#34892;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#30340;&#23567;&#25209;&#37327;MCMC&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, minibatch MCMC sampling for feedforward neural networks is made more feasible. To this end, it is proposed to sample subgroups of parameters via a blocked Gibbs sampling scheme. By partitioning the parameter space, sampling is possible irrespective of layer width. It is also possible to alleviate vanishing acceptance rates for increasing depth by reducing the proposal variance in deeper layers. Increasing the length of a non-convergent chain increases the predictive accuracy in classification tasks, so avoiding vanishing acceptance rates and consequently enabling longer chain runs have practical benefits. Moreover, non-convergent chain realizations aid in the quantification of predictive uncertainty. An open problem is how to perform minibatch MCMC sampling for feedforward neural networks in the presence of augmented data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36793;&#32536;&#20998;&#24067;&#30340;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#38750;&#21442;&#25968;&#28040;&#36153;&#32773;&#36873;&#25321;&#24314;&#27169;&#26041;&#27861;&#65292;&#22312;&#20219;&#20309;&#36873;&#25321;&#38598;&#21512;&#20013;&#20250;&#25226;&#36873;&#25321;&#27010;&#29575;&#30340;&#38598;&#21512;&#19968;&#33268;&#22320;&#25551;&#36848;&#20986;&#26469;&#12290;</title><link>http://arxiv.org/abs/2208.06115</link><description>&lt;p&gt;
&#22522;&#20110;&#36793;&#32536;&#20998;&#24067;&#30340;&#38750;&#21442;&#25968;&#28040;&#36153;&#32773;&#36873;&#25321;&#24314;&#27169;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Nonparametric Approach with Marginals for Modeling Consumer Choice. (arXiv:2208.06115v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.06115
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36793;&#32536;&#20998;&#24067;&#30340;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#38750;&#21442;&#25968;&#28040;&#36153;&#32773;&#36873;&#25321;&#24314;&#27169;&#26041;&#27861;&#65292;&#22312;&#20219;&#20309;&#36873;&#25321;&#38598;&#21512;&#20013;&#20250;&#25226;&#36873;&#25321;&#27010;&#29575;&#30340;&#38598;&#21512;&#19968;&#33268;&#22320;&#25551;&#36848;&#20986;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#28040;&#36153;&#32773;&#22312;&#19981;&#21516;&#36873;&#25321;&#38598;&#21512;&#20013;&#20316;&#20986;&#36873;&#25321;&#30340;&#25968;&#25454;&#65292;&#24320;&#21457;&#25551;&#36848;&#21644;&#39044;&#27979;&#28040;&#36153;&#32773;&#36873;&#25321;&#34892;&#20026;&#30340;&#31616;&#27905;&#27169;&#22411;&#26159;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#12290;&#20854;&#20013;&#19968;&#31181;&#36873;&#25321;&#27169;&#22411;&#26159;&#36793;&#32536;&#20998;&#24067;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20165;&#38656;&#35201;&#35268;&#23450;&#38543;&#26426;&#25928;&#29992;&#30340;&#36793;&#32536;&#20998;&#24067;&#21363;&#21487;&#35299;&#37322;&#36873;&#39033;&#25968;&#25454;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#31934;&#30830;&#30340;&#36873;&#25321;&#27010;&#29575;&#38598;&#21512;&#30340;&#29305;&#24449;&#21270;&#26041;&#27861;&#65292;&#35813;&#38598;&#21512;&#21487;&#20197;&#22312;&#20219;&#20309;&#38598;&#21512;&#20013;&#19968;&#33268;&#22320;&#36890;&#36807;&#36793;&#32536;&#20998;&#24067;&#27169;&#22411;&#26469;&#25551;&#36848;&#12290;&#20801;&#35768;&#26681;&#25454;&#20854;&#25928;&#29992;&#30340;&#36793;&#32536;&#20998;&#24067;&#23558;&#36873;&#25321;&#38598;&#21512;&#36827;&#34892;&#20998;&#32452;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;(a)&#39564;&#35777;&#36825;&#20010;&#27169;&#22411;&#19982;&#36873;&#25321;&#27010;&#29575;&#25968;&#25454;&#30340;&#19968;&#33268;&#24615;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#26159;&#21487;&#33021;&#30340;&#65292;(b)&#26368;&#25509;&#36817;&#25311;&#21512;&#30340;&#26041;&#27861;&#21487;&#20197;&#31616;&#21270;&#20026;&#35299;&#20915;&#28151;&#21512;&#25972;&#25968;&#20984;&#35268;&#21010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#22810;&#39033;&#24335;Logit&#27169;&#22411;&#21644;m&#30456;&#27604;&#65292;&#36793;&#32536;&#20998;&#24067;&#27169;&#22411;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#34920;&#29616;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given data on choices made by consumers for different assortments, a key challenge is to develop parsimonious models that describe and predict consumer choice behavior. One such choice model is the marginal distribution model which requires only the specification of the marginal distributions of the random utilities of the alternatives to explain choice data. In this paper, we develop an exact characterisation of the set of choice probabilities which are representable by the marginal distribution model consistently across any collection of assortments. Allowing for the possibility of alternatives to be grouped based on the marginal distribution of their utilities, we show (a) verifying consistency of choice probability data with this model is possible in polynomial time and (b) finding the closest fit reduces to solving a mixed integer convex program. Our results show that the marginal distribution model provides much better representational power as compared to multinomial logit and m
&lt;/p&gt;</description></item><item><title>TF-GNN&#26159;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340; TensorFlow &#22270;&#31070;&#32463;&#32593;&#32476;&#24211;&#65292;&#29992;&#20110;&#25903;&#25345;&#20016;&#23500;&#30340;&#24322;&#26500;&#22270;&#25968;&#25454;&#12290;&#23427;&#25552;&#20379;&#20102;&#20302;&#20195;&#30721;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#24191;&#27867;&#24212;&#29992;&#20110;&#35895;&#27468;&#30340;&#29983;&#20135;&#27169;&#22411;&#20013;&#12290;&#36825;&#20010;&#24211;&#26368;&#36817;&#20316;&#20026;&#24320;&#28304;&#39033;&#30446;&#21457;&#24067;&#65292;&#20026;&#22270;&#23398;&#20064;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2207.03522</link><description>&lt;p&gt;
TF-GNN: TensorFlow&#20013;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
TF-GNN: Graph Neural Networks in TensorFlow. (arXiv:2207.03522v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.03522
&lt;/p&gt;
&lt;p&gt;
TF-GNN&#26159;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340; TensorFlow &#22270;&#31070;&#32463;&#32593;&#32476;&#24211;&#65292;&#29992;&#20110;&#25903;&#25345;&#20016;&#23500;&#30340;&#24322;&#26500;&#22270;&#25968;&#25454;&#12290;&#23427;&#25552;&#20379;&#20102;&#20302;&#20195;&#30721;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#24191;&#27867;&#24212;&#29992;&#20110;&#35895;&#27468;&#30340;&#29983;&#20135;&#27169;&#22411;&#20013;&#12290;&#36825;&#20010;&#24211;&#26368;&#36817;&#20316;&#20026;&#24320;&#28304;&#39033;&#30446;&#21457;&#24067;&#65292;&#20026;&#22270;&#23398;&#20064;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
TensorFlow-GNN (TF-GNN) &#26159;&#19968;&#20010;&#22312; TensorFlow &#20013;&#21487;&#25193;&#23637;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#24211;&#12290;&#23427;&#20174;&#24213;&#23618;&#35774;&#35745;&#26469;&#25903;&#25345;&#24403;&#20170;&#20449;&#24687;&#29983;&#24577;&#31995;&#32479;&#20013;&#20986;&#29616;&#30340;&#21508;&#31181;&#20016;&#23500;&#30340;&#24322;&#26500;&#22270;&#25968;&#25454;&#12290;&#38500;&#20102;&#20026;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#20154;&#21592;&#21644;&#39640;&#32423;&#24320;&#21457;&#20154;&#21592;&#25552;&#20379;&#25903;&#25345;&#65292;TF-GNN&#36824;&#25552;&#20379;&#20302;&#20195;&#30721;&#35299;&#20915;&#26041;&#26696;&#65292;&#20197;&#36171;&#33021;&#26356;&#24191;&#27867;&#30340;&#24320;&#21457;&#32773;&#31038;&#21306;&#36827;&#34892;&#22270;&#23398;&#20064;&#12290;&#35895;&#27468;&#30340;&#35768;&#22810;&#29983;&#20135;&#27169;&#22411;&#37117;&#22312;&#20351;&#29992; TF-GNN&#65292;&#24182;&#19988;&#23427;&#26368;&#36817;&#20316;&#20026;&#19968;&#20010;&#24320;&#28304;&#39033;&#30446;&#21457;&#24067;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102; TF-GNN &#30340;&#25968;&#25454;&#27169;&#22411;&#12289;&#20854; Keras &#28040;&#24687;&#20256;&#36882; API &#20197;&#21450;&#30456;&#20851;&#30340;&#33021;&#21147;&#65292;&#22914;&#22270;&#37319;&#26679;&#21644;&#20998;&#24067;&#24335;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
TensorFlow-GNN (TF-GNN) is a scalable library for Graph Neural Networks in TensorFlow. It is designed from the bottom up to support the kinds of rich heterogeneous graph data that occurs in today's information ecosystems. In addition to enabling machine learning researchers and advanced developers, TF-GNN offers low-code solutions to empower the broader developer community in graph learning. Many production models at Google use TF-GNN, and it has been recently released as an open source project. In this paper we describe the TF-GNN data model, its Keras message passing API, and relevant capabilities such as graph sampling and distributed training.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21457;&#29616;&#65292;&#20351;&#29992;&#32676;&#20307;&#23646;&#24615;&#20010;&#24615;&#21270;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21487;&#33021;&#38477;&#20302;&#32676;&#20307;&#27700;&#24179;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#30830;&#20445;&#22312;&#39044;&#27979;&#20219;&#21153;&#20013;&#20844;&#24179;&#20351;&#29992;&#32676;&#20307;&#23646;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24418;&#24335;&#21270;&#26465;&#20214;&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#24212;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#20020;&#24202;&#39044;&#27979;&#20219;&#21153;&#20013;&#26222;&#36941;&#23384;&#22312;&#20844;&#24179;&#20351;&#29992;&#36829;&#35268;&#30340;&#24773;&#20917;&#65292;&#20294;&#25105;&#20204;&#20063;&#25214;&#21040;&#20102;&#31616;&#21333;&#24178;&#39044;&#25163;&#27573;&#26469;&#20943;&#36731;&#20854;&#20260;&#23475;&#12290;</title><link>http://arxiv.org/abs/2206.02058</link><description>&lt;p&gt;
&#24403;&#20010;&#24615;&#21270;&#36896;&#25104;&#20260;&#23475;&#26102;&#65306;&#37325;&#26032;&#32771;&#34385;&#22312;&#39044;&#27979;&#20013;&#20351;&#29992;&#32676;&#20307;&#23646;&#24615;
&lt;/p&gt;
&lt;p&gt;
When Personalization Harms: Reconsidering the Use of Group Attributes in Prediction. (arXiv:2206.02058v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.02058
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21457;&#29616;&#65292;&#20351;&#29992;&#32676;&#20307;&#23646;&#24615;&#20010;&#24615;&#21270;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21487;&#33021;&#38477;&#20302;&#32676;&#20307;&#27700;&#24179;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#30830;&#20445;&#22312;&#39044;&#27979;&#20219;&#21153;&#20013;&#20844;&#24179;&#20351;&#29992;&#32676;&#20307;&#23646;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24418;&#24335;&#21270;&#26465;&#20214;&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#24212;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#20020;&#24202;&#39044;&#27979;&#20219;&#21153;&#20013;&#26222;&#36941;&#23384;&#22312;&#20844;&#24179;&#20351;&#29992;&#36829;&#35268;&#30340;&#24773;&#20917;&#65292;&#20294;&#25105;&#20204;&#20063;&#25214;&#21040;&#20102;&#31616;&#21333;&#24178;&#39044;&#25163;&#27573;&#26469;&#20943;&#36731;&#20854;&#20260;&#23475;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#36890;&#24120;&#20250;&#20351;&#29992;&#21463;&#20445;&#25252;&#12289;&#25935;&#24863;&#12289;&#33258;&#25253;&#21578;&#25110;&#32773;&#26114;&#36149;&#30340;&#20998;&#31867;&#23646;&#24615;&#36827;&#34892;&#20010;&#24615;&#21270;&#12290;&#26412;&#30740;&#31350;&#25351;&#20986;&#65292;&#20351;&#29992;&#32676;&#20307;&#23646;&#24615;&#36827;&#34892;&#20010;&#24615;&#21270;&#20250;&#38477;&#20302;&#32676;&#20307;&#27700;&#24179;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24418;&#24335;&#21270;&#26465;&#20214;&#65292;&#20197;&#30830;&#20445;&#22312;&#39044;&#27979;&#20219;&#21153;&#20013;&#8220;&#20844;&#24179;&#20351;&#29992;&#8221;&#32676;&#20307;&#23646;&#24615;&#65292;&#26041;&#27861;&#26159;&#36890;&#36807;&#35757;&#32451;&#19968;&#20010;&#39069;&#22806;&#30340;&#27169;&#22411;&#65292;&#21363;&#20445;&#35777;&#27599;&#20010;&#25552;&#20379;&#20010;&#20154;&#25968;&#25454;&#30340;&#32676;&#20307;&#20250;&#33719;&#24471;&#30456;&#23545;&#24212;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#36275;&#22815;&#30340;&#26465;&#20214;&#65292;&#20197;&#30830;&#20445;&#22312;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#20013;&#30340;&#20844;&#24179;&#20351;&#29992;&#65292;&#24182;&#25551;&#36848;&#20102;&#23548;&#33268;&#20844;&#24179;&#20351;&#29992;&#36829;&#35268;&#30340;&#25925;&#38556;&#27169;&#24335;&#65292;&#36825;&#26159;&#30001;&#20110;&#27169;&#22411;&#24320;&#21457;&#21644;&#37096;&#32626;&#20013;&#30340;&#26631;&#20934;&#20570;&#27861;&#25152;&#23548;&#33268;&#30340;&#12290;&#25105;&#20204;&#23545;&#20020;&#24202;&#39044;&#27979;&#20219;&#21153;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#23454;&#35777;&#30740;&#31350;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#23454;&#36341;&#20013;&#26222;&#36941;&#23384;&#22312;&#20844;&#24179;&#20351;&#29992;&#36829;&#35268;&#65292;&#24182;&#35828;&#26126;&#20102;&#20943;&#36731;&#20854;&#20260;&#23475;&#30340;&#31616;&#21333;&#24178;&#39044;&#25163;&#27573;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning models are often personalized with categorical attributes that are protected, sensitive, self-reported, or costly to acquire. In this work, we show models that are personalized with group attributes can reduce performance at a group level. We propose formal conditions to ensure the "fair use" of group attributes in prediction tasks by training one additional model -- i.e., collective preference guarantees to ensure that each group who provides personal data will receive a tailored gain in performance in return. We present sufficient conditions to ensure fair use in empirical risk minimization and characterize failure modes that lead to fair use violations due to standard practices in model development and deployment. We present a comprehensive empirical study of fair use in clinical prediction tasks. Our results demonstrate the prevalence of fair use violations in practice and illustrate simple interventions to mitigate their harm.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20195;&#25968;&#20998;&#26512;&#25913;&#36827;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;GNN&#33021;&#22815;&#27604;Weisfeiler-Lehman&#65288;WL&#65289;&#31639;&#27861;&#26356;&#22909;&#22320;&#20135;&#29983;&#21306;&#20998;&#24615;&#34920;&#31034;&#65292;&#29305;&#21035;&#26159;&#22312;&#20855;&#26377;&#19981;&#21516;&#29305;&#24449;&#20540;&#30340;&#22270;&#19978;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21457;&#29616;&#31616;&#21333;&#30340;&#21367;&#31215;&#32467;&#26500;&#19982;&#26080;&#20449;&#24687;&#36755;&#20837;&#20135;&#29983;&#30340;&#31561;&#21464;&#29305;&#24449;&#27604;WL&#34920;&#31034;&#26356;&#20855;&#34920;&#36798;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2205.09801</link><description>&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#65306;&#36890;&#36807;&#20195;&#25968;&#20998;&#26512;&#25913;&#36827;&#34920;&#36798;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Representation Power of Graph Neural Networks: Improved Expressivity via Algebraic Analysis. (arXiv:2205.09801v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.09801
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20195;&#25968;&#20998;&#26512;&#25913;&#36827;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;GNN&#33021;&#22815;&#27604;Weisfeiler-Lehman&#65288;WL&#65289;&#31639;&#27861;&#26356;&#22909;&#22320;&#20135;&#29983;&#21306;&#20998;&#24615;&#34920;&#31034;&#65292;&#29305;&#21035;&#26159;&#22312;&#20855;&#26377;&#19981;&#21516;&#29305;&#24449;&#20540;&#30340;&#22270;&#19978;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21457;&#29616;&#31616;&#21333;&#30340;&#21367;&#31215;&#32467;&#26500;&#19982;&#26080;&#20449;&#24687;&#36755;&#20837;&#20135;&#29983;&#30340;&#31561;&#21464;&#29305;&#24449;&#27604;WL&#34920;&#31034;&#26356;&#20855;&#34920;&#36798;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#20294;&#26222;&#36941;&#35748;&#20026;&#23427;&#20204;&#30340;&#34920;&#36798;&#33021;&#21147;&#26377;&#38480;&#65292;&#24182;&#19988;&#23427;&#20204;&#26368;&#22810;&#19982;Weisfeiler-Lehman&#65288;WL&#65289;&#31639;&#27861;&#19968;&#26679;&#20855;&#26377;&#34920;&#36798;&#33021;&#21147;&#12290;&#26412;&#25991;&#19982;&#27492;&#30456;&#21453;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#26631;&#20934;&#30340;GNN&#65288;&#21311;&#21517;&#36755;&#20837;&#65289;&#20135;&#29983;&#30340;&#34920;&#31034;&#27604;WL&#31639;&#27861;&#26356;&#20855;&#26377;&#21306;&#20998;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#32447;&#24615;&#20195;&#25968;&#24037;&#20855;&#23545;GNN&#30340;&#34920;&#31034;&#33021;&#21147;&#36827;&#34892;&#20102;&#20840;&#26032;&#30340;&#20998;&#26512;&#65292;&#24182;&#23558;&#20854;&#19982;&#22270;&#25805;&#20316;&#31526;&#30340;&#29305;&#24449;&#20540;&#20998;&#35299;&#30456;&#20851;&#32852;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;GNN&#33021;&#22815;&#20174;&#26080;&#20449;&#24687;&#36755;&#20837;&#20135;&#29983;&#29420;&#29305;&#30340;&#36755;&#20986;&#65292;&#33267;&#23569;&#23545;&#20110;&#25152;&#26377;&#20855;&#26377;&#19981;&#21516;&#29305;&#24449;&#20540;&#30340;&#22270;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#31616;&#21333;&#30340;&#21367;&#31215;&#32467;&#26500;&#19982;&#26080;&#20449;&#24687;&#36755;&#20837;&#20135;&#29983;&#30340;&#31561;&#21464;&#29305;&#24449;&#65292;&#23427;&#20204;&#35745;&#31639;&#22270;&#20013;&#30340;&#38381;&#21512;&#36335;&#24452;&#24182;&#19988;&#26126;&#26174;&#27604;WL&#34920;&#31034;&#20855;&#26377;&#26356;&#39640;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;&#22312;&#22270;&#21516;&#26500;&#21644;&#22270;&#20998;&#31867;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24443;&#24213;&#30340;&#23454;&#39564;&#20998;&#26512;&#65292;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the remarkable success of Graph Neural Networks (GNNs), the common belief is that their representation power is limited and that they are at most as expressive as the Weisfeiler-Lehman (WL) algorithm. In this paper, we argue the opposite and show that standard GNNs, with anonymous inputs, produce more discriminative representations than the WL algorithm. Our novel analysis employs linear algebraic tools and characterizes the representation power of GNNs with respect to the eigenvalue decomposition of the graph operators. We prove that GNNs are able to generate distinctive outputs from white uninformative inputs, for, at least, all graphs that have different eigenvalues. We also show that simple convolutional architectures with white inputs, produce equivariant features that count the closed paths in the graph and are provably more expressive than the WL representations. Thorough experimental analysis on graph isomorphism and graph classification datasets corroborates our theore
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25581;&#31034;&#20102;&#25968;&#25454;&#23494;&#24230;&#12289;&#22122;&#22768;&#21644;&#30456;&#20284;&#24615;&#23398;&#20064;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#35777;&#26126;&#20102;&#25968;&#25454;&#23545;&#30340;&#23494;&#24230;&#23545;&#20110;&#27867;&#21270;&#33267;&#20851;&#37325;&#35201;&#65292;&#24182;&#21457;&#29616;&#20102;&#19968;&#31181;&#22312;&#23494;&#38598;&#25968;&#25454;&#38598;&#19978;&#27604;&#23545;&#31216;&#26631;&#31614;&#22122;&#22768;&#26356;&#24046;&#30340;&#27867;&#21270;&#24615;&#33021;&#30340;&#29616;&#35937;&#65292;&#31216;&#20026;&#23494;&#24230;&#35825;&#23548;&#30340;&#30456;&#20284;&#24615;&#30772;&#22351;&#65288;DIBS&#65289;&#12290;</title><link>http://arxiv.org/abs/2201.12803</link><description>&lt;p&gt;
&#22122;&#22768;&#35774;&#32622;&#20013;&#30340;&#30456;&#20284;&#24615;&#27867;&#21270;&#65306;DIBS&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
Generalizing similarity in noisy setups: the DIBS phenomenon. (arXiv:2201.12803v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.12803
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25581;&#31034;&#20102;&#25968;&#25454;&#23494;&#24230;&#12289;&#22122;&#22768;&#21644;&#30456;&#20284;&#24615;&#23398;&#20064;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#35777;&#26126;&#20102;&#25968;&#25454;&#23545;&#30340;&#23494;&#24230;&#23545;&#20110;&#27867;&#21270;&#33267;&#20851;&#37325;&#35201;&#65292;&#24182;&#21457;&#29616;&#20102;&#19968;&#31181;&#22312;&#23494;&#38598;&#25968;&#25454;&#38598;&#19978;&#27604;&#23545;&#31216;&#26631;&#31614;&#22122;&#22768;&#26356;&#24046;&#30340;&#27867;&#21270;&#24615;&#33021;&#30340;&#29616;&#35937;&#65292;&#31216;&#20026;&#23494;&#24230;&#35825;&#23548;&#30340;&#30456;&#20284;&#24615;&#30772;&#22351;&#65288;DIBS&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25581;&#31034;&#20102;&#25968;&#25454;&#23494;&#24230;&#12289;&#22122;&#22768;&#21644;&#30456;&#20284;&#24615;&#23398;&#20064;&#30340;&#26222;&#36866;&#24615;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#26297;&#32599;&#31070;&#32463;&#32593;&#32476;&#65288;SNNs&#65289;&#65292;&#36825;&#26159;&#23545;&#27604;&#23398;&#20064;&#30340;&#22522;&#26412;&#24418;&#24335;&#65292;&#24182;&#25506;&#32034;&#20102;&#20004;&#31181;&#21487;&#33021;&#24433;&#21709;SNNs&#30340;&#22122;&#22768;&#31867;&#22411;&#65292;&#21363;&#23545;&#27604;&#26631;&#31614;&#22122;&#22768;&#65288;PLN&#65289;&#21644;&#21333;&#26631;&#31614;&#22122;&#22768;&#65288;SLN&#65289;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#19981;&#35770;&#35757;&#32451;&#35774;&#32622;&#22914;&#20309;&#65292;SNNs&#37117;&#34920;&#29616;&#20986;&#21452;&#38477;&#34892;&#20026;&#65292;&#24182;&#19988;&#22122;&#22768;&#36827;&#19968;&#27493;&#21152;&#21095;&#20102;&#36825;&#31181;&#34892;&#20026;&#12290;&#25105;&#20204;&#35777;&#26126;&#25968;&#25454;&#23545;&#30340;&#23494;&#24230;&#23545;&#20110;&#27867;&#21270;&#33267;&#20851;&#37325;&#35201;&#12290;&#24403;SNNs&#22312;&#31232;&#30095;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#26102;&#65292;&#20855;&#26377;&#30456;&#21516;&#25968;&#37327;&#30340;PLN&#25110;SLN&#65292;&#23427;&#20204;&#30340;&#27867;&#21270;&#24615;&#33021;&#26159;&#21487;&#27604;&#36739;&#30340;&#12290;&#28982;&#32780;&#65292;&#24403;&#20351;&#29992;&#23494;&#38598;&#25968;&#25454;&#38598;&#26102;&#65292;&#22312;&#36807;&#21442;&#25968;&#21270;&#21306;&#22495;&#20013;&#65292;PLN&#26696;&#20363;&#30340;&#27867;&#21270;&#24615;&#33021;&#36739;&#24046;&#65292;&#30456;&#23545;&#20110;SLN&#26696;&#20363;&#65292;&#36825;&#23548;&#33268;&#20102;&#19968;&#31181;&#25105;&#20204;&#31216;&#20026;&#23494;&#24230;&#35825;&#23548;&#30340;&#30456;&#20284;&#24615;&#30772;&#22351;&#65288;DIBS&#65289;&#30340;&#29616;&#35937;&#12290;&#22312;&#36825;&#20010;&#24773;&#20917;&#19979;&#65292;PLN&#30456;&#20284;&#24615;&#36829;&#35268;&#21464;&#24471;&#23439;&#35266;&#21270;&#65292;&#20351;&#24471;&#25968;&#25454;&#38598;&#34987;&#25439;&#22351;&#21040;&#26080;&#27861;&#23454;&#29616;&#23436;&#20840;&#25554;&#20540;&#30340;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work uncovers an interplay among data density, noise, and the generalization ability in similarity learning. We consider Siamese Neural Networks (SNNs), which are the basic form of contrastive learning, and explore two types of noise that can impact SNNs, Pair Label Noise (PLN) and Single Label Noise (SLN). Our investigation reveals that SNNs exhibit double descent behaviour regardless of the training setup and that it is further exacerbated by noise. We demonstrate that the density of data pairs is crucial for generalization. When SNNs are trained on sparse datasets with the same amount of PLN or SLN, they exhibit comparable generalization properties. However, when using dense datasets, PLN cases generalize worse than SLN ones in the overparametrized region, leading to a phenomenon we call Density-Induced Break of Similarity (DIBS). In this regime, PLN similarity violation becomes macroscopical, corrupting the dataset to the point where complete interpolation cannot be achieved, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#24179;&#26041;&#26681;&#36895;&#24230;&#20989;&#25968;&#30340;&#26032;&#34920;&#31034;&#26041;&#27861;&#21644;&#24230;&#37327;&#26041;&#27861;&#65292;&#29992;&#20110;&#20998;&#26512;&#21644;&#27604;&#36739;&#26641;&#29366;&#19977;&#32500;&#29289;&#20307;&#65292;&#20174;&#32780;&#25552;&#39640;&#29289;&#20307;&#24418;&#29366;&#24046;&#24322;&#35745;&#31639;&#30340;&#31934;&#24230;&#21644;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2110.08693</link><description>&lt;p&gt;
&#23398;&#20064;&#26641;&#29366;&#19977;&#32500;&#29289;&#20307;&#30340;&#20960;&#20309;&#21644;&#25299;&#25169;&#30340;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning Generative Models of the Geometry and Topology of Tree-like 3D Objects. (arXiv:2110.08693v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.08693
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#24179;&#26041;&#26681;&#36895;&#24230;&#20989;&#25968;&#30340;&#26032;&#34920;&#31034;&#26041;&#27861;&#21644;&#24230;&#37327;&#26041;&#27861;&#65292;&#29992;&#20110;&#20998;&#26512;&#21644;&#27604;&#36739;&#26641;&#29366;&#19977;&#32500;&#29289;&#20307;&#65292;&#20174;&#32780;&#25552;&#39640;&#29289;&#20307;&#24418;&#29366;&#24046;&#24322;&#35745;&#31639;&#30340;&#31934;&#24230;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#20309;&#20998;&#26512;&#23637;&#29616;&#20986;&#22797;&#26434;&#20960;&#20309;&#21644;&#25299;&#25169;&#21464;&#21270;&#30340;&#35814;&#32454;&#19977;&#32500;&#29983;&#29289;&#29289;&#20307;&#65292;&#20363;&#22914;&#31070;&#32463;&#20803;&#21644;&#26893;&#29289;&#26641;&#65311;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#23398;&#26694;&#26550;&#65292;&#29992;&#20110;&#34920;&#31034;&#12289;&#27604;&#36739;&#21644;&#35745;&#31639;&#36825;&#20123;&#26641;&#29366;&#19977;&#32500;&#23545;&#35937;&#30340;&#24418;&#29366;&#24046;&#24322;&#65292;&#24182;&#23450;&#20041;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26041;&#27861;&#26469;&#37327;&#21270;&#23558;&#19968;&#20010;&#26641;&#29366;&#29289;&#20307;&#21464;&#24418;&#20026;&#21478;&#19968;&#20010;&#29289;&#20307;&#25152;&#38656;&#30340;&#24367;&#26354;&#12289;&#25289;&#20280;&#21644;&#20998;&#25903;&#28369;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;
How can one analyze detailed 3D biological objects, such as neurons and botanical trees, that exhibit complex geometrical and topological variation? In this paper, we develop a novel mathematical framework for representing, comparing, and computing geodesic deformations between the shapes of such tree-like 3D objects. A hierarchical organization of subtrees characterizes these objects -- each subtree has the main branch with some side branches attached -- and one needs to match these structures across objects for meaningful comparisons. We propose a novel representation that extends the Square-Root Velocity Function (SRVF), initially developed for Euclidean curves, to tree-shaped 3D objects. We then define a new metric that quantifies the bending, stretching, and branch sliding needed to deform one tree-shaped object into the other. Compared to the current metrics, such as the Quotient Euclidean Distance (QED) and the Tree Edit Distance (TED), the proposed representation and metric cap
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20174;&#35266;&#23519;&#25968;&#25454;&#20013;&#23398;&#20064;&#26368;&#20248;&#22788;&#26041;&#26641;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#25968;&#25454;&#38543;&#26426;&#21270;&#21644;&#23545;&#26641;&#26377;&#20005;&#26684;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;&#25216;&#26415;&#36827;&#34892;&#23398;&#20064;&#65292;&#24182;&#20855;&#26377;&#24314;&#27169;&#39046;&#22495;&#29305;&#23450;&#38382;&#39064;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2108.13628</link><description>&lt;p&gt;
&#20174;&#35266;&#23519;&#25968;&#25454;&#20013;&#23398;&#20064;&#26368;&#20248;&#30340;&#22788;&#26041;&#26641;
&lt;/p&gt;
&lt;p&gt;
Learning Optimal Prescriptive Trees from Observational Data. (arXiv:2108.13628v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.13628
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20174;&#35266;&#23519;&#25968;&#25454;&#20013;&#23398;&#20064;&#26368;&#20248;&#22788;&#26041;&#26641;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#25968;&#25454;&#38543;&#26426;&#21270;&#21644;&#23545;&#26641;&#26377;&#20005;&#26684;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;&#25216;&#26415;&#36827;&#34892;&#23398;&#20064;&#65292;&#24182;&#20855;&#26377;&#24314;&#27169;&#39046;&#22495;&#29305;&#23450;&#38382;&#39064;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#35266;&#23519;&#25968;&#25454;&#20013;&#23398;&#20064;&#19968;&#20010;&#36866;&#24230;&#28145;&#24230;&#30340;&#26368;&#20248;&#22788;&#26041;&#26641;&#65288;&#21363;&#65292;&#20197;&#20108;&#21449;&#26641;&#24418;&#24335;&#34920;&#31034;&#30340;&#21487;&#35299;&#37322;&#30340;&#27835;&#30103;&#20998;&#37197;&#31574;&#30053;&#65289;&#30340;&#38382;&#39064;&#12290;&#36825;&#20010;&#38382;&#39064;&#22312;&#35768;&#22810;&#31038;&#20250;&#37325;&#35201;&#39046;&#22495;&#65288;&#22914;&#20844;&#20849;&#21355;&#29983;&#21644;&#20010;&#24615;&#21270;&#21307;&#23398;&#65289;&#20013;&#26159;&#23384;&#22312;&#30340;&#65292;&#36825;&#20123;&#39046;&#22495;&#20013;&#36890;&#36807;&#34987;&#21160;&#25910;&#38598;&#25968;&#25454;&#26469;&#23547;&#25214;&#22522;&#20110;&#25968;&#25454;&#30340;&#21487;&#35299;&#37322;&#21644;&#25968;&#25454;&#39537;&#21160;&#24178;&#39044;&#65292;&#32780;&#19981;&#26159;&#36890;&#36807;&#38543;&#26426;&#35797;&#39564;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;&#65288;MIO&#65289;&#25216;&#26415;&#26469;&#23398;&#20064;&#26368;&#20248;&#22788;&#26041;&#26641;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#28201;&#21644;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#28176;&#36817;&#31934;&#30830;&#30340;&#65292;&#21363;&#38543;&#30528;&#21382;&#21490;&#25968;&#25454;&#26679;&#26412;&#30340;&#25968;&#37327;&#36235;&#21521;&#20110;&#26080;&#31351;&#22823;&#65292;&#23427;&#25910;&#25947;&#21040;&#19968;&#20010;&#26368;&#20248;&#30340;&#26679;&#26412;&#22806;&#27835;&#30103;&#20998;&#37197;&#31574;&#30053;&#12290;&#19982;&#29616;&#26377;&#25991;&#29486;&#30456;&#21453;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#65306;1&#65289;&#19981;&#38656;&#35201;&#25968;&#25454;&#38543;&#26426;&#21270;&#65292;2&#65289;&#19981;&#23545;&#23398;&#20064;&#21040;&#30340;&#26641;&#26045;&#21152;&#20005;&#26684;&#30340;&#20551;&#35774;&#65292;3&#65289;&#20855;&#26377;&#24314;&#27169;&#39046;&#22495;&#29305;&#23450;&#38382;&#39064;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning an optimal prescriptive tree (i.e., an interpretable treatment assignment policy in the form of a binary tree) of moderate depth, from observational data. This problem arises in numerous socially important domains such as public health and personalized medicine, where interpretable and data-driven interventions are sought based on data gathered in deployment -- through passive collection of data -- rather than from randomized trials. We propose a method for learning optimal prescriptive trees using mixed-integer optimization (MIO) technology. We show that under mild conditions our method is asymptotically exact in the sense that it converges to an optimal out-of-sample treatment assignment policy as the number of historical data samples tends to infinity. Contrary to existing literature, our approach: 1) does not require data to be randomized, 2) does not impose stringent assumptions on the learned trees, and 3) has the ability to model domain specif
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27604;&#36739;&#20102;&#20004;&#31181;&#22788;&#29702;&#20855;&#26377;&#28508;&#22312;&#28151;&#28102;&#22240;&#32032;&#30340;&#22270;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#20102;&#36825;&#20004;&#31181;&#26041;&#27861;&#20248;&#21183;&#30340;&#26032;&#26041;&#27861;&#12290;&#20316;&#32773;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#35777;&#30740;&#31350;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#21487;&#34892;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2105.06600</link><description>&lt;p&gt;
&#23398;&#20064;&#20855;&#26377;&#28508;&#22312;&#28151;&#28102;&#22240;&#32032;&#30340;&#39640;&#26031;&#22270;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning Gaussian Graphical Models with Latent Confounders. (arXiv:2105.06600v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.06600
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27604;&#36739;&#20102;&#20004;&#31181;&#22788;&#29702;&#20855;&#26377;&#28508;&#22312;&#28151;&#28102;&#22240;&#32032;&#30340;&#22270;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#20102;&#36825;&#20004;&#31181;&#26041;&#27861;&#20248;&#21183;&#30340;&#26032;&#26041;&#27861;&#12290;&#20316;&#32773;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#35777;&#30740;&#31350;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#21487;&#34892;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#22270;&#27169;&#22411;&#65288;GGM&#65289;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#20272;&#35745;&#20174;&#29983;&#29289;&#23398;&#21040;&#37329;&#34701;&#31561;&#22810;&#20010;&#39046;&#22495;&#20013;&#30340;&#32593;&#32476;&#32467;&#26500;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#25968;&#25454;&#24448;&#24448;&#34987;&#28508;&#22312;&#30340;&#28151;&#28102;&#22240;&#32032;&#25439;&#22351;&#65292;&#20174;&#32780;&#24433;&#21709;&#23545;&#30495;&#23454;&#22270;&#32467;&#26500;&#30340;&#25512;&#26029;&#12290;&#26412;&#25991;&#27604;&#36739;&#24182;&#23545;&#27604;&#20102;&#20004;&#31181;&#22788;&#29702;&#20855;&#26377;&#28508;&#22312;&#28151;&#28102;&#22240;&#32032;&#30340;&#22270;&#27169;&#22411;&#30340;&#31574;&#30053;&#65306;&#20855;&#26377;&#28508;&#21464;&#37327;&#30340;&#39640;&#26031;&#22270;&#27169;&#22411;&#65288;LVGGM&#65289;&#21644;&#22522;&#20110;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#28151;&#28102;&#21435;&#38500;&#26041;&#27861;&#65288;PCA+GGM&#65289;&#12290;&#23613;&#31649;&#36825;&#20004;&#31181;&#26041;&#27861;&#26377;&#30528;&#31867;&#20284;&#30340;&#30446;&#26631;&#65292;&#20294;&#23427;&#20204;&#26159;&#22522;&#20110;&#19981;&#21516;&#30340;&#28151;&#28102;&#20551;&#35774;&#36827;&#34892;&#25512;&#23548;&#30340;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#36825;&#20004;&#31181;&#26041;&#27861;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#20102;&#20004;&#31181;&#26041;&#27861;&#20248;&#21183;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22522;&#20110;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#26041;&#27861;&#30340;&#19968;&#33268;&#24615;&#21644;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#21033;&#29992;&#36825;&#20123;&#32467;&#26524;&#25552;&#20379;&#20102;&#20309;&#26102;&#20351;&#29992;&#27599;&#31181;&#26041;&#27861;&#30340;&#25351;&#23548;&#12290;&#36890;&#36807;&#27169;&#25311;&#21644;&#20004;&#20010;&#30495;&#23454;&#19990;&#30028;&#24212;&#29992;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian Graphical models (GGM) are widely used to estimate the network structures in many applications ranging from biology to finance. In practice, data is often corrupted by latent confounders which biases inference of the underlying true graphical structure. In this paper, we compare and contrast two strategies for inference in graphical models with latent confounders: Gaussian graphical models with latent variables (LVGGM) and PCA-based removal of confounding (PCA+GGM). While these two approaches have similar goals, they are motivated by different assumptions about confounding. In this paper, we explore the connection between these two approaches and propose a new method, which combines the strengths of these two approaches. We prove the consistency and convergence rate for the PCA-based method and use these results to provide guidance about when to use each method. We demonstrate the effectiveness of our methodology using both simulations and in two real-world applications.
&lt;/p&gt;</description></item></channel></rss>