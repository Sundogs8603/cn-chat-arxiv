<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#28151;&#21512;&#26041;&#27861;&#65292;&#29992;&#20110;&#20248;&#21270;&#22522;&#20110;&#29615;&#22659;&#30340;&#22522;&#22240;&#22411;&#36873;&#25321;&#12290;&#36890;&#36807;&#25972;&#21512;&#19981;&#21516;&#20316;&#29289;&#21697;&#31181;&#30340;&#22825;&#27668;&#25968;&#25454;&#65292;&#29305;&#21035;&#26159;&#22312;&#19981;&#21516;&#27668;&#20505;&#26465;&#20214;&#19979;&#65292;&#20934;&#30830;&#22320;&#39044;&#27979;&#20316;&#29289;&#20135;&#37327;&#23545;&#20110;&#29702;&#35299;&#20854;&#36866;&#24212;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#35770;&#25991;&#20013;&#24320;&#21457;&#20102;&#20004;&#31181;&#26032;&#39062;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#24182;&#21033;&#29992;&#24191;&#20041;&#38598;&#25104;&#26041;&#27861;&#30830;&#23450;&#20102;&#26368;&#20248;&#30340;&#22522;&#22240;&#22411;&#19982;&#29615;&#22659;&#36873;&#25321;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2309.13021</link><description>&lt;p&gt;
&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#28151;&#21512;&#26041;&#27861;&#29992;&#20110;&#20248;&#21270;&#22522;&#20110;&#29615;&#22659;&#30340;&#22522;&#22240;&#22411;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
A Hybrid Deep Learning-based Approach for Optimal Genotype by Environment Selection. (arXiv:2309.13021v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13021
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#28151;&#21512;&#26041;&#27861;&#65292;&#29992;&#20110;&#20248;&#21270;&#22522;&#20110;&#29615;&#22659;&#30340;&#22522;&#22240;&#22411;&#36873;&#25321;&#12290;&#36890;&#36807;&#25972;&#21512;&#19981;&#21516;&#20316;&#29289;&#21697;&#31181;&#30340;&#22825;&#27668;&#25968;&#25454;&#65292;&#29305;&#21035;&#26159;&#22312;&#19981;&#21516;&#27668;&#20505;&#26465;&#20214;&#19979;&#65292;&#20934;&#30830;&#22320;&#39044;&#27979;&#20316;&#29289;&#20135;&#37327;&#23545;&#20110;&#29702;&#35299;&#20854;&#36866;&#24212;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#35770;&#25991;&#20013;&#24320;&#21457;&#20102;&#20004;&#31181;&#26032;&#39062;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#24182;&#21033;&#29992;&#24191;&#20041;&#38598;&#25104;&#26041;&#27861;&#30830;&#23450;&#20102;&#26368;&#20248;&#30340;&#22522;&#22240;&#22411;&#19982;&#29615;&#22659;&#36873;&#25321;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20934;&#30830;&#30340;&#20316;&#29289;&#20135;&#37327;&#39044;&#27979;&#23545;&#20110;&#25913;&#21892;&#20892;&#19994;&#23454;&#36341;&#21644;&#30830;&#20445;&#20316;&#29289;&#22312;&#19981;&#21516;&#27668;&#20505;&#26465;&#20214;&#19979;&#30340;&#38887;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;MLCAS2021&#20316;&#29289;&#20135;&#37327;&#39044;&#27979;&#25361;&#25112;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#21253;&#21547;93,028&#20010;&#35757;&#32451;&#35760;&#24405;&#30340;&#25968;&#25454;&#38598;&#65292;&#39044;&#27979;&#20102;10,337&#20010;&#27979;&#35797;&#35760;&#24405;&#30340;&#20135;&#37327;&#65292;&#22312;13&#24180;&#65288;2003-2015&#24180;&#65289;&#30340;&#26102;&#38388;&#33539;&#22260;&#20869;&#35206;&#30422;&#20102;&#32654;&#22269;28&#20010;&#24030;&#21644;&#21152;&#25343;&#22823;&#30465;&#20221;&#30340;159&#20010;&#22320;&#28857;&#12290;&#35813;&#25968;&#25454;&#38598;&#21253;&#25324;5,838&#20010;&#19981;&#21516;&#22522;&#22240;&#22411;&#30340;&#35814;&#32454;&#20449;&#24687;&#21644;&#20026;&#26399;214&#22825;&#30340;&#29983;&#38271;&#23395;&#33410;&#30340;&#27599;&#26085;&#22825;&#27668;&#25968;&#25454;&#65292;&#20351;&#24471;&#32508;&#21512;&#20998;&#26512;&#25104;&#20026;&#21487;&#33021;&#12290;&#20316;&#20026;&#33719;&#32988;&#22242;&#38431;&#20043;&#19968;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#20004;&#31181;&#26032;&#39062;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#26550;&#26500;&#65306;CNN-DNN&#27169;&#22411;&#65292;&#32467;&#21512;&#20102;CNN&#21644;&#20840;&#36830;&#25509;&#32593;&#32476;&#65307;&#20197;&#21450;CNN-LSTM-DNN&#27169;&#22411;&#65292;&#21152;&#20837;&#20102;LSTM&#23618;&#29992;&#20110;&#22825;&#27668;&#21464;&#37327;&#12290;&#21033;&#29992;&#24191;&#20041;&#38598;&#25104;&#26041;&#27861;&#65288;GEM&#65289;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#26368;&#20248;&#30340;&#22522;&#22240;&#22411;&#19982;&#29615;&#22659;&#36873;&#25321;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Precise crop yield prediction is essential for improving agricultural practices and ensuring crop resilience in varying climates. Integrating weather data across the growing season, especially for different crop varieties, is crucial for understanding their adaptability in the face of climate change. In the MLCAS2021 Crop Yield Prediction Challenge, we utilized a dataset comprising 93,028 training records to forecast yields for 10,337 test records, covering 159 locations across 28 U.S. states and Canadian provinces over 13 years (2003-2015). This dataset included details on 5,838 distinct genotypes and daily weather data for a 214-day growing season, enabling comprehensive analysis. As one of the winning teams, we developed two novel convolutional neural network (CNN) architectures: the CNN-DNN model, combining CNN and fully-connected networks, and the CNN-LSTM-DNN model, with an added LSTM layer for weather variables. Leveraging the Generalized Ensemble Method (GEM), we determined opt
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#19978;&#30340;Wasserstein&#24230;&#37327;&#65292;&#24182;&#36890;&#36807;&#32553;&#25918;&#26497;&#38480;&#26500;&#24314;&#20102;&#19968;&#31867;&#22312;&#26377;&#30028;&#19968;&#32500;&#40784;&#27425;&#26230;&#26684;&#19978;&#30340;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;Wasserstein&#24230;&#37327;&#12290;&#27492;&#22806;&#65292;&#36824;&#25512;&#24191;&#20102;&#36825;&#31181;&#24230;&#37327;&#21040;&#19968;&#33324;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#24182;&#30740;&#31350;&#20102;Wasserstein&#26799;&#24230;&#27969;&#22312;&#19981;&#21516;&#27867;&#20989;&#19979;&#30340;&#34892;&#20026;&#12290;&#25968;&#20540;&#23454;&#20363;&#39564;&#35777;&#20102;&#32467;&#26524;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.12997</link><description>&lt;p&gt;
&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20013;Wasserstein&#20449;&#24687;&#30697;&#38453;&#30340;&#25193;&#23637;&#26497;&#38480;
&lt;/p&gt;
&lt;p&gt;
Scaling Limits of the Wasserstein information matrix on Gaussian Mixture Models. (arXiv:2309.12997v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12997
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#19978;&#30340;Wasserstein&#24230;&#37327;&#65292;&#24182;&#36890;&#36807;&#32553;&#25918;&#26497;&#38480;&#26500;&#24314;&#20102;&#19968;&#31867;&#22312;&#26377;&#30028;&#19968;&#32500;&#40784;&#27425;&#26230;&#26684;&#19978;&#30340;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;Wasserstein&#24230;&#37327;&#12290;&#27492;&#22806;&#65292;&#36824;&#25512;&#24191;&#20102;&#36825;&#31181;&#24230;&#37327;&#21040;&#19968;&#33324;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#24182;&#30740;&#31350;&#20102;Wasserstein&#26799;&#24230;&#27969;&#22312;&#19981;&#21516;&#27867;&#20989;&#19979;&#30340;&#34892;&#20026;&#12290;&#25968;&#20540;&#23454;&#20363;&#39564;&#35777;&#20102;&#32467;&#26524;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;(GMMs)&#19978;&#30340;Wasserstein&#24230;&#37327;&#65292;&#23427;&#34987;&#23450;&#20041;&#20026;&#20855;&#26377;&#26377;&#38480;&#20108;&#38454;&#30697;&#30340;&#24179;&#28369;&#27010;&#29575;&#20998;&#24067;&#31354;&#38388;&#19978;Wasserstein&#24230;&#37327;&#30340;&#25512;&#22238;&#12290;&#36890;&#36807;&#23545;GMMs&#19978;&#30340;Wasserstein&#24230;&#37327;&#30340;&#32553;&#25918;&#26497;&#38480;&#65292;&#23427;&#23548;&#20986;&#20102;&#19968;&#31867;&#22312;&#19968;&#32500;&#26377;&#30028;&#40784;&#27425;&#26230;&#26684;&#19978;&#30340;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;Wasserstein&#24230;&#37327;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#23545;&#20110;&#19968;&#20010;&#26041;&#24046;&#36235;&#20110;&#38646;&#30340;GMMs&#24207;&#21015;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#26576;&#31181;&#24402;&#19968;&#21270;&#21518;Wasserstein&#24230;&#37327;&#30340;&#26497;&#38480;&#23384;&#22312;&#12290;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;&#19968;&#33324;GMMs&#20013;&#30340;&#36825;&#31181;&#24230;&#37327;&#30340;&#25512;&#24191;&#65292;&#21253;&#25324;&#19981;&#21516;&#30340;&#38750;&#40784;&#27425;&#26230;&#26684;&#27169;&#22411;&#65292;&#25193;&#23637;&#30340;GMMs(&#39640;&#26031;&#32452;&#20214;&#30340;&#22343;&#20540;&#21442;&#25968;&#20063;&#21487;&#20197;&#25913;&#21464;)&#65292;&#20197;&#21450;&#21253;&#21547;&#32553;&#25918;&#26497;&#38480;&#39640;&#38454;&#20449;&#24687;&#30340;&#20108;&#38454;&#24230;&#37327;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#30740;&#31350;&#20102;GMMs&#19978;&#30340;Wasserstein&#26799;&#24230;&#27969;&#23545;&#19977;&#20010;&#20856;&#22411;&#30340;&#27867;&#20989;: &#21183;&#33021;&#12289;&#20869;&#33021;&#21644;&#30456;&#20114;&#20316;&#29992;&#33021;&#30340;&#24773;&#20917;&#12290;&#25968;&#20540;&#23454;&#20363;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the Wasserstein metric on the Gaussian mixture models (GMMs), which is defined as the pullback of the full Wasserstein metric on the space of smooth probability distributions with finite second moment. It derives a class of Wasserstein metrics on probability simplices over one-dimensional bounded homogeneous lattices via a scaling limit of the Wasserstein metric on GMMs. Specifically, for a sequence of GMMs whose variances tend to zero, we prove that the limit of the Wasserstein metric exists after certain renormalization. Generalizations of this metric in general GMMs are established, including inhomogeneous lattice models whose lattice gaps are not the same, extended GMMs whose mean parameters of Gaussian components can also change, and the second-order metric containing high-order information of the scaling limit. We further study the Wasserstein gradient flows on GMMs for three typical functionals: potential, internal, and interaction energies. Numerical examples demons
&lt;/p&gt;</description></item><item><title>BayesDLL&#26159;&#19968;&#20010;&#29992;&#20110;PyTorch&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#24211;&#65292;&#19982;&#20854;&#20182;&#29616;&#26377;&#24211;&#30456;&#27604;&#65292;&#23427;&#21487;&#20197;&#22788;&#29702;&#38750;&#24120;&#22823;&#35268;&#27169;&#30340;&#28145;&#24230;&#32593;&#32476;&#65292;&#26080;&#38656;&#20462;&#25913;&#29992;&#25143;&#20195;&#30721;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#39044;&#35757;&#32451;&#27169;&#22411;&#26435;&#37325;&#20316;&#20026;&#20808;&#39564;&#22343;&#20540;&#65292;&#36866;&#29992;&#20110;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2309.12928</link><description>&lt;p&gt;
BayesDLL: &#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#24211;
&lt;/p&gt;
&lt;p&gt;
BayesDLL: Bayesian Deep Learning Library. (arXiv:2309.12928v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12928
&lt;/p&gt;
&lt;p&gt;
BayesDLL&#26159;&#19968;&#20010;&#29992;&#20110;PyTorch&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#24211;&#65292;&#19982;&#20854;&#20182;&#29616;&#26377;&#24211;&#30456;&#27604;&#65292;&#23427;&#21487;&#20197;&#22788;&#29702;&#38750;&#24120;&#22823;&#35268;&#27169;&#30340;&#28145;&#24230;&#32593;&#32476;&#65292;&#26080;&#38656;&#20462;&#25913;&#29992;&#25143;&#20195;&#30721;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#39044;&#35757;&#32451;&#27169;&#22411;&#26435;&#37325;&#20316;&#20026;&#20808;&#39564;&#22343;&#20540;&#65292;&#36866;&#29992;&#20110;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#21457;&#24067;&#20102;&#19968;&#20010;&#26032;&#30340;&#29992;&#20110;PyTorch&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#24211;&#65292;&#29992;&#20110;&#22823;&#35268;&#27169;&#28145;&#24230;&#32593;&#32476;&#12290;&#25105;&#20204;&#30340;&#24211;&#23454;&#29616;&#20102;&#20027;&#27969;&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#25512;&#26029;&#31639;&#27861;&#65306;&#21464;&#20998;&#25512;&#26029;&#12289;MC-dropout&#12289;&#38543;&#26426;&#26799;&#24230;MCMC&#21644;&#25289;&#26222;&#25289;&#26031;&#36817;&#20284;&#12290;&#19982;&#20854;&#20182;&#29616;&#26377;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#24211;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#24211;&#26377;&#20197;&#19979;&#20027;&#35201;&#21306;&#21035;&#65306;1&#65289;&#25105;&#20204;&#30340;&#24211;&#21487;&#20197;&#22788;&#29702;&#21253;&#25324;&#35270;&#35273;&#21464;&#25442;&#22120;&#65288;ViTs&#65289;&#22312;&#20869;&#30340;&#38750;&#24120;&#22823;&#35268;&#27169;&#30340;&#28145;&#24230;&#32593;&#32476;&#12290;2&#65289;&#29992;&#25143;&#20960;&#20046;&#19981;&#38656;&#35201;&#20462;&#25913;&#20195;&#30721;&#65288;&#20363;&#22914;&#65292;&#39592;&#24178;&#32593;&#32476;&#23450;&#20041;&#20195;&#30721;&#26681;&#26412;&#19981;&#38656;&#35201;&#20462;&#25913;&#65289;&#12290;3&#65289;&#25105;&#20204;&#30340;&#24211;&#36824;&#20801;&#35768;&#39044;&#35757;&#32451;&#27169;&#22411;&#26435;&#37325;&#20316;&#20026;&#20808;&#39564;&#22343;&#20540;&#65292;&#36825;&#23545;&#20110;&#20351;&#29992;&#20165;&#20165;&#20381;&#38752;&#19979;&#28216;&#25968;&#25454;&#38590;&#20197;&#20174;&#22836;&#24320;&#22987;&#20248;&#21270;&#30340;&#22823;&#35268;&#27169;&#22522;&#30784;&#27169;&#22411;&#65288;&#22914;ViTs&#65289;&#36827;&#34892;&#36125;&#21494;&#26031;&#25512;&#26029;&#38750;&#24120;&#26377;&#29992;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#20844;&#24320;&#21487;&#29992;&#20110;: \url{https://github.com/SamsungLabs/BayesDLL}&#65288;&#22791;&#29992;&#23384;&#20648;&#24211;&#20063;&#21487;&#22312;&#27492;&#22788;&#25214;&#21040;&#65306;\url{https://github.com/miny})
&lt;/p&gt;
&lt;p&gt;
We release a new Bayesian neural network library for PyTorch for large-scale deep networks. Our library implements mainstream approximate Bayesian inference algorithms: variational inference, MC-dropout, stochastic-gradient MCMC, and Laplace approximation. The main differences from other existing Bayesian neural network libraries are as follows: 1) Our library can deal with very large-scale deep networks including Vision Transformers (ViTs). 2) We need virtually zero code modifications for users (e.g., the backbone network definition codes do not neet to be modified at all). 3) Our library also allows the pre-trained model weights to serve as a prior mean, which is very useful for performing Bayesian inference with the large-scale foundation models like ViTs that are hard to optimise from scratch with the downstream data alone. Our code is publicly available at: \url{https://github.com/SamsungLabs/BayesDLL}\footnote{A mirror repository is also available at: \url{https://github.com/miny
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#38598;&#25104;&#24046;&#20998;&#36827;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#27169;&#25311;&#28151;&#21512;&#21644;&#33258;&#36866;&#24212;&#26426;&#21046;&#26469;&#35299;&#20915;&#19981;&#30830;&#23450;&#26465;&#20214;&#19979;&#30340;&#24211;&#23384;&#31649;&#29702;&#38382;&#39064;&#12290;&#23454;&#35777;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#24211;&#23384;&#31649;&#29702;&#30340;&#36130;&#21153;&#32489;&#25928;&#21644;&#20248;&#21270;&#22823;&#25628;&#32034;&#31354;&#38388;&#12290;</title><link>http://arxiv.org/abs/2309.12852</link><description>&lt;p&gt;
&#22522;&#20110;&#27169;&#25311;&#28151;&#21512;&#21644;&#33258;&#36866;&#24212;&#30340;&#38598;&#25104;&#24046;&#20998;&#36827;&#21270;&#31639;&#27861;&#29992;&#20110;&#19981;&#30830;&#23450;&#26465;&#20214;&#19979;&#30340;&#24211;&#23384;&#31649;&#29702;
&lt;/p&gt;
&lt;p&gt;
Ensemble Differential Evolution with Simulation-Based Hybridization and Self-Adaptation for Inventory Management Under Uncertainty. (arXiv:2309.12852v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12852
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#38598;&#25104;&#24046;&#20998;&#36827;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#27169;&#25311;&#28151;&#21512;&#21644;&#33258;&#36866;&#24212;&#26426;&#21046;&#26469;&#35299;&#20915;&#19981;&#30830;&#23450;&#26465;&#20214;&#19979;&#30340;&#24211;&#23384;&#31649;&#29702;&#38382;&#39064;&#12290;&#23454;&#35777;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#24211;&#23384;&#31649;&#29702;&#30340;&#36130;&#21153;&#32489;&#25928;&#21644;&#20248;&#21270;&#22823;&#25628;&#32034;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#25311;&#28151;&#21512;&#21644;&#33258;&#36866;&#24212;&#30340;&#38598;&#25104;&#24046;&#20998;&#36827;&#21270;&#31639;&#27861;&#65288;EDESH-SA&#65289;&#26469;&#35299;&#20915;&#19981;&#30830;&#23450;&#26465;&#20214;&#19979;&#30340;&#24211;&#23384;&#31649;&#29702;&#38382;&#39064;&#12290;&#35813;&#31639;&#27861;&#23558;&#24046;&#20998;&#36827;&#21270;&#31639;&#27861;&#19982;&#27169;&#25311;&#28151;&#21512;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#24182;&#36890;&#36807;&#33258;&#36866;&#24212;&#26426;&#21046;&#21160;&#24577;&#22320;&#25913;&#21464;&#21464;&#24322;&#29575;&#21644;&#20132;&#21449;&#29575;&#12290;&#30001;&#20110;&#20854;&#36866;&#24212;&#24615;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#22788;&#29702;&#24211;&#23384;&#31649;&#29702;&#20013;&#30340;&#22797;&#26434;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#12290;&#36890;&#36807;&#20351;&#29992;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#65288;MCS&#65289;&#65292;&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#36830;&#32493;&#23457;&#26597;&#65288;CR&#65289;&#24211;&#23384;&#31574;&#30053;&#65292;&#24182;&#32771;&#34385;&#20102;&#38543;&#26426;&#24615;&#21644;&#19981;&#21516;&#30340;&#38656;&#27714;&#24773;&#26223;&#12290;&#36825;&#31181;&#22522;&#20110;&#27169;&#25311;&#30340;&#26041;&#27861;&#21487;&#20197;&#30495;&#23454;&#22320;&#35780;&#20272;&#25152;&#25552;&#31639;&#27861;&#22312;&#23454;&#38469;&#29615;&#22659;&#20013;&#35299;&#20915;&#24211;&#23384;&#31649;&#29702;&#25361;&#25112;&#30340;&#36866;&#29992;&#24615;&#12290;&#23454;&#35777;&#30740;&#31350;&#30340;&#32467;&#26524;&#26174;&#31034;&#20102;&#25152;&#25552;&#26041;&#27861;&#22312;&#25552;&#39640;&#24211;&#23384;&#31649;&#29702;&#30340;&#36130;&#21153;&#32489;&#25928;&#21644;&#20248;&#21270;&#22823;&#25628;&#32034;&#31354;&#38388;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study proposes an Ensemble Differential Evolution with Simula-tion-Based Hybridization and Self-Adaptation (EDESH-SA) approach for inven-tory management (IM) under uncertainty. In this study, DE with multiple runs is combined with a simulation-based hybridization method that includes a self-adaptive mechanism that dynamically alters mutation and crossover rates based on the success or failure of each iteration. Due to its adaptability, the algorithm is able to handle the complexity and uncertainty present in IM. Utilizing Monte Carlo Simulation (MCS), the continuous review (CR) inventory strategy is ex-amined while accounting for stochasticity and various demand scenarios. This simulation-based approach enables a realistic assessment of the proposed algo-rithm's applicability in resolving the challenges faced by IM in practical settings. The empirical findings demonstrate the potential of the proposed method to im-prove the financial performance of IM and optimize large search spa
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22522;&#20110;&#27169;&#22411;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#21709;&#24212;&#31867;&#22411;&#30340;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#19981;&#21464;&#24615;&#20551;&#35774;&#20174;&#24322;&#36136;&#29615;&#22659;&#30340;&#25968;&#25454;&#20013;&#36755;&#20986;&#19968;&#37096;&#20998;&#22240;&#26524;&#29305;&#24449;&#30340;&#23376;&#38598;&#65292;&#36866;&#29992;&#20110;&#19968;&#33324;&#30340;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#21644;&#38750;&#21442;&#25968;&#35774;&#32622;&#65292;&#35299;&#20915;&#20102;&#38750;&#21442;&#25968;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#20302;&#21151;&#29575;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.12833</link><description>&lt;p&gt;
&#22522;&#20110;&#27169;&#22411;&#30340;&#36890;&#29992;&#21709;&#24212;&#31867;&#22411;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Model-based causal feature selection for general response types. (arXiv:2309.12833v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12833
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22522;&#20110;&#27169;&#22411;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#21709;&#24212;&#31867;&#22411;&#30340;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#19981;&#21464;&#24615;&#20551;&#35774;&#20174;&#24322;&#36136;&#29615;&#22659;&#30340;&#25968;&#25454;&#20013;&#36755;&#20986;&#19968;&#37096;&#20998;&#22240;&#26524;&#29305;&#24449;&#30340;&#23376;&#38598;&#65292;&#36866;&#29992;&#20110;&#19968;&#33324;&#30340;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#21644;&#38750;&#21442;&#25968;&#35774;&#32622;&#65292;&#35299;&#20915;&#20102;&#38750;&#21442;&#25968;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#20302;&#21151;&#29575;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#21457;&#29616;&#22240;&#26524;&#20851;&#31995;&#26159;&#19968;&#39033;&#22522;&#26412;&#32780;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#22312;&#26576;&#20123;&#24212;&#29992;&#20013;&#65292;&#20165;&#23398;&#20064;&#32473;&#23450;&#21709;&#24212;&#21464;&#37327;&#30340;&#22240;&#26524;&#29305;&#24449;&#21487;&#33021;&#24050;&#32463;&#36275;&#22815;&#65292;&#32780;&#19981;&#26159;&#23398;&#20064;&#25972;&#20010;&#28508;&#22312;&#30340;&#22240;&#26524;&#32467;&#26500;&#12290;&#19981;&#21464;&#22240;&#26524;&#39044;&#27979;&#65288;ICP&#65289;&#26159;&#19968;&#31181;&#29992;&#20110;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#30340;&#26041;&#27861;&#65292;&#38656;&#35201;&#26469;&#33258;&#24322;&#36136;&#29615;&#22659;&#30340;&#25968;&#25454;&#12290;ICP&#20551;&#35774;&#20174;&#30452;&#25509;&#21407;&#22240;&#29983;&#25104;&#21709;&#24212;&#30340;&#26426;&#21046;&#22312;&#25152;&#26377;&#29615;&#22659;&#20013;&#37117;&#30456;&#21516;&#65292;&#24182;&#21033;&#29992;&#36825;&#31181;&#19981;&#21464;&#24615;&#36755;&#20986;&#19968;&#37096;&#20998;&#22240;&#26524;&#29305;&#24449;&#30340;&#23376;&#38598;&#12290;ICP&#30340;&#26694;&#26550;&#24050;&#32463;&#25193;&#23637;&#21040;&#19968;&#33324;&#30340;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#21644;&#38750;&#21442;&#25968;&#35774;&#32622;&#65292;&#20351;&#29992;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#12290;&#28982;&#32780;&#65292;&#38750;&#21442;&#25968;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#32463;&#24120;&#21463;&#21040;&#20302;&#21151;&#29575;&#65288;&#25110;&#36739;&#24046;&#30340;&#31867;&#22411;I&#38169;&#35823;&#25511;&#21046;&#65289;&#30340;&#22256;&#25200;&#65292;&#24182;&#19988;&#19978;&#36848;&#21442;&#25968;&#27169;&#22411;&#19981;&#36866;&#29992;&#20110;&#21709;&#24212;&#19981;&#26159;&#22312;&#36830;&#32493;&#21051;&#24230;&#19978;&#27979;&#37327;&#30340;&#24212;&#29992;&#24773;&#20917;&#65292;&#32780;&#26159;&#21453;&#26144;&#20102;&#20998;&#31867;&#20449;&#24687;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Discovering causal relationships from observational data is a fundamental yet challenging task. In some applications, it may suffice to learn the causal features of a given response variable, instead of learning the entire underlying causal structure. Invariant causal prediction (ICP, Peters et al., 2016) is a method for causal feature selection which requires data from heterogeneous settings. ICP assumes that the mechanism for generating the response from its direct causes is the same in all settings and exploits this invariance to output a subset of the causal features. The framework of ICP has been extended to general additive noise models and to nonparametric settings using conditional independence testing. However, nonparametric conditional independence testing often suffers from low power (or poor type I error control) and the aforementioned parametric models are not suitable for applications in which the response is not measured on a continuous scale, but rather reflects categor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#31232;&#30095;&#30340;&#29616;&#20195; Hopfield &#27169;&#22411;&#65292;&#36890;&#36807;&#24341;&#20837;&#31232;&#30095;&#33021;&#37327;&#20989;&#25968;&#21644;&#31232;&#30095;&#35760;&#24518;&#26816;&#32034;&#21160;&#21147;&#23398;&#65292;&#23454;&#29616;&#20102;&#23545;&#31232;&#30095;&#27880;&#24847;&#26426;&#21046;&#30340;&#19968;&#27493;&#36817;&#20284;&#12290;&#30456;&#27604;&#23494;&#38598;&#27169;&#22411;&#65292;&#31232;&#30095;&#27169;&#22411;&#30340;&#35760;&#24518;&#26816;&#32034;&#35823;&#24046;&#19978;&#30028;&#26356;&#32039;&#20945;&#65292;&#20855;&#26377;&#26126;&#30830;&#30340;&#31232;&#30095;&#20248;&#21183;&#26465;&#20214;&#12290;&#21516;&#26102;&#65292;&#31232;&#30095;&#30340;&#29616;&#20195; Hopfield &#27169;&#22411;&#36824;&#20445;&#25345;&#20102;&#20854;&#23494;&#38598;&#23545;&#24212;&#29289;&#30340;&#31283;&#20581;&#29702;&#35770;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2309.12673</link><description>&lt;p&gt;
&#20851;&#20110;&#31232;&#30095;&#30340;&#29616;&#20195; Hopfield &#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
On Sparse Modern Hopfield Model. (arXiv:2309.12673v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12673
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#31232;&#30095;&#30340;&#29616;&#20195; Hopfield &#27169;&#22411;&#65292;&#36890;&#36807;&#24341;&#20837;&#31232;&#30095;&#33021;&#37327;&#20989;&#25968;&#21644;&#31232;&#30095;&#35760;&#24518;&#26816;&#32034;&#21160;&#21147;&#23398;&#65292;&#23454;&#29616;&#20102;&#23545;&#31232;&#30095;&#27880;&#24847;&#26426;&#21046;&#30340;&#19968;&#27493;&#36817;&#20284;&#12290;&#30456;&#27604;&#23494;&#38598;&#27169;&#22411;&#65292;&#31232;&#30095;&#27169;&#22411;&#30340;&#35760;&#24518;&#26816;&#32034;&#35823;&#24046;&#19978;&#30028;&#26356;&#32039;&#20945;&#65292;&#20855;&#26377;&#26126;&#30830;&#30340;&#31232;&#30095;&#20248;&#21183;&#26465;&#20214;&#12290;&#21516;&#26102;&#65292;&#31232;&#30095;&#30340;&#29616;&#20195; Hopfield &#27169;&#22411;&#36824;&#20445;&#25345;&#20102;&#20854;&#23494;&#38598;&#23545;&#24212;&#29289;&#30340;&#31283;&#20581;&#29702;&#35770;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#31232;&#30095;&#30340;&#29616;&#20195; Hopfield &#27169;&#22411;&#20316;&#20026;&#29616;&#20195; Hopfield &#27169;&#22411;&#30340;&#19968;&#31181;&#25193;&#23637;&#12290;&#19982;&#20854;&#23494;&#38598;&#30340;&#23545;&#24212;&#29289;&#19968;&#26679;&#65292;&#31232;&#30095;&#30340;&#29616;&#20195; Hopfield &#27169;&#22411;&#20855;&#22791;&#19968;&#31181;&#35760;&#24518;&#26816;&#32034;&#21160;&#21147;&#23398;&#65292;&#20854;&#19968;&#27493;&#36817;&#20284;&#23545;&#24212;&#20110;&#31232;&#30095;&#30340;&#27880;&#24847;&#26426;&#21046;&#12290;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;&#25105;&#20204;&#30340;&#20851;&#38190;&#36129;&#29486;&#26159;&#36890;&#36807;&#31232;&#30095;&#29109;&#27491;&#21017;&#21270;&#22120;&#30340;&#20984;&#20849;&#36717;&#23548;&#20986;&#20102;&#23553;&#38381;&#24418;&#24335;&#30340;&#31232;&#30095; Hopfield &#33021;&#37327;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#20174;&#31232;&#30095;&#33021;&#37327;&#20989;&#25968;&#20013;&#25512;&#23548;&#20986;&#31232;&#30095;&#35760;&#24518;&#26816;&#32034;&#21160;&#21147;&#23398;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#30340;&#19968;&#27493;&#36817;&#20284;&#31561;&#20215;&#20110;&#31232;&#30095;&#32467;&#26500;&#21270;&#27880;&#24847;&#21147;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#20381;&#36182;&#20110;&#31232;&#30095;&#24230;&#30340;&#35760;&#24518;&#26816;&#32034;&#35823;&#24046;&#19978;&#30028;&#65292;&#35813;&#19978;&#30028;&#22312;&#35777;&#26126;&#19978;&#35201;&#27604;&#20854;&#23494;&#38598;&#23545;&#24212;&#29289;&#26356;&#32039;&#20945;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30830;&#23450;&#24182;&#35752;&#35770;&#20102;&#31232;&#30095;&#20248;&#21183;&#20986;&#29616;&#30340;&#26465;&#20214;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#34920;&#26126;&#31232;&#30095;&#30340;&#29616;&#20195; Hopfield &#27169;&#22411;&#20445;&#25345;&#20102;&#20854;&#23494;&#38598;&#23545;&#24212;&#29289;&#30340;&#31283;&#20581;&#29702;&#35770;&#24615;&#36136;&#65292;&#21253;&#25324;&#24555;&#36895;&#30340;&#22266;&#23450;&#28857;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the sparse modern Hopfield model as a sparse extension of the modern Hopfield model. Like its dense counterpart, the sparse modern Hopfield model equips a memory-retrieval dynamics whose one-step approximation corresponds to the sparse attention mechanism. Theoretically, our key contribution is a principled derivation of a closed-form sparse Hopfield energy using the convex conjugate of the sparse entropic regularizer. Building upon this, we derive the sparse memory retrieval dynamics from the sparse energy function and show its one-step approximation is equivalent to the sparse-structured attention. Importantly, we provide a sparsity-dependent memory retrieval error bound which is provably tighter than its dense analog. The conditions for the benefits of sparsity to arise are therefore identified and discussed. In addition, we show that the sparse modern Hopfield model maintains the robust theoretical properties of its dense counterpart, including rapid fixed point conver
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;Langevin&#20934;&#33945;&#29305;&#21345;&#27931;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#20302;&#24046;&#24322;&#20934;&#38543;&#26426;&#26679;&#26412;&#21487;&#20197;&#20943;&#23569;&#20854;&#20272;&#35745;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2309.12664</link><description>&lt;p&gt;
Langevin&#20934;&#33945;&#29305;&#21345;&#27931;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Langevin Quasi-Monte Carlo. (arXiv:2309.12664v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12664
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;Langevin&#20934;&#33945;&#29305;&#21345;&#27931;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#20302;&#24046;&#24322;&#20934;&#38543;&#26426;&#26679;&#26412;&#21487;&#20197;&#20943;&#23569;&#20854;&#20272;&#35745;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Langevin&#33945;&#29305;&#21345;&#27931;&#65288;LMC&#65289;&#21450;&#20854;&#38543;&#26426;&#26799;&#24230;&#29256;&#26412;&#26159;&#29992;&#20110;&#20174;&#22797;&#26434;&#39640;&#32500;&#20998;&#24067;&#20013;&#25277;&#26679;&#30340;&#24378;&#22823;&#31639;&#27861;&#12290;&#20026;&#20102;&#20174;&#23494;&#24230;&#20026;$\pi(\theta)\propto \exp(-U(\theta)) $&#30340;&#20998;&#24067;&#20013;&#25277;&#26679;&#65292;LMC&#36890;&#36807;&#22312;&#26799;&#24230;&#26041;&#21521;$\nabla U$&#19978;&#21152;&#20837;&#39640;&#26031;&#25200;&#21160;&#26469;&#36845;&#20195;&#29983;&#25104;&#19979;&#19968;&#20010;&#26679;&#26412;&#12290;&#23545;&#20110;&#30446;&#26631;&#20998;&#24067;$\pi$&#30340;&#26399;&#26395;&#20540;&#36890;&#36807;&#23545;LMC&#26679;&#26412;&#36827;&#34892;&#24179;&#22343;&#20272;&#35745;&#12290;&#22312;&#26222;&#36890;&#33945;&#29305;&#21345;&#27931;&#20013;&#65292;&#24050;&#30693;&#36890;&#36807;&#29992;&#20302;&#24046;&#24322;&#24207;&#21015;&#31561;&#20934;&#38543;&#26426;&#26679;&#26412;&#26367;&#20195;&#29420;&#31435;&#38543;&#26426;&#26679;&#26412;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#20272;&#35745;&#35823;&#24046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;LMC&#30340;&#20272;&#35745;&#35823;&#24046;&#20063;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#20934;&#38543;&#26426;&#26679;&#26412;&#26469;&#20943;&#23569;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;&#20855;&#26377;&#29305;&#23450;&#20302;&#24046;&#24322;&#24615;&#36136;&#30340;&#23436;&#20840;&#22343;&#21248;&#20998;&#24067;&#65288;CUD&#65289;&#24207;&#21015;&#26469;&#29983;&#25104;&#39640;&#26031;&#25200;&#21160;&#12290;&#22312;&#20809;&#28369;&#24615;&#21644;&#20984;&#24615;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24102;&#26377;&#20302;&#24046;&#24322;CUD&#30340;LMC&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#21644;&#28176;&#36827;&#27491;&#24577;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Langevin Monte Carlo (LMC) and its stochastic gradient versions are powerful algorithms for sampling from complex high-dimensional distributions. To sample from a distribution with density $\pi(\theta)\propto \exp(-U(\theta)) $, LMC iteratively generates the next sample by taking a step in the gradient direction $\nabla U$ with added Gaussian perturbations. Expectations w.r.t. the target distribution $\pi$ are estimated by averaging over LMC samples. In ordinary Monte Carlo, it is well known that the estimation error can be substantially reduced by replacing independent random samples by quasi-random samples like low-discrepancy sequences. In this work, we show that the estimation error of LMC can also be reduced by using quasi-random samples. Specifically, we propose to use completely uniformly distributed (CUD) sequences with certain low-discrepancy property to generate the Gaussian perturbations. Under smoothness and convexity conditions, we prove that LMC with a low-discrepancy CUD
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;&#27491;&#21017;&#21270;Stein&#24046;&#24322;&#30340;&#31070;&#32463;&#31639;&#23376;&#21464;&#20998;&#25512;&#26029;&#29992;&#20110;&#28145;&#24230;&#39640;&#26031;&#36807;&#31243;&#65292;&#36890;&#36807;&#20351;&#29992;&#31070;&#32463;&#29983;&#25104;&#22120;&#33719;&#24471;&#21462;&#26679;&#22120;&#20197;&#21450;&#20351;&#29992;&#33945;&#29305;&#21345;&#32599;&#20272;&#35745;&#21644;&#23376;&#37319;&#26679;&#38543;&#26426;&#20248;&#21270;&#25216;&#26415;&#35299;&#20915;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#25552;&#39640;&#20102;&#28145;&#24230;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#25512;&#26029;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.12658</link><description>&lt;p&gt;
&#22522;&#20110;&#27491;&#21017;&#21270;Stein&#24046;&#24322;&#30340;&#31070;&#32463;&#31639;&#23376;&#21464;&#20998;&#25512;&#26029;&#29992;&#20110;&#28145;&#24230;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Neural Operator Variational Inference based on Regularized Stein Discrepancy for Deep Gaussian Processes. (arXiv:2309.12658v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12658
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27491;&#21017;&#21270;Stein&#24046;&#24322;&#30340;&#31070;&#32463;&#31639;&#23376;&#21464;&#20998;&#25512;&#26029;&#29992;&#20110;&#28145;&#24230;&#39640;&#26031;&#36807;&#31243;&#65292;&#36890;&#36807;&#20351;&#29992;&#31070;&#32463;&#29983;&#25104;&#22120;&#33719;&#24471;&#21462;&#26679;&#22120;&#20197;&#21450;&#20351;&#29992;&#33945;&#29305;&#21345;&#32599;&#20272;&#35745;&#21644;&#23376;&#37319;&#26679;&#38543;&#26426;&#20248;&#21270;&#25216;&#26415;&#35299;&#20915;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#25552;&#39640;&#20102;&#28145;&#24230;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#25512;&#26029;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#39640;&#26031;&#36807;&#31243;&#65288;DGP&#65289;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#31181;&#24378;&#22823;&#30340;&#38750;&#21442;&#25968;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#20294;&#31934;&#30830;&#25512;&#26029;&#36890;&#24120;&#26159;&#38590;&#20197;&#27714;&#35299;&#30340;&#65292;&#36825;&#20419;&#20351;&#25105;&#20204;&#20351;&#29992;&#21508;&#31181;&#36817;&#20284;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#26041;&#27861;&#65292;&#22914;&#22343;&#20540;&#22330;&#39640;&#26031;&#20551;&#35774;&#65292;&#38480;&#21046;&#20102;DGP&#27169;&#22411;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#25928;&#26524;&#65292;&#32780;&#38543;&#26426;&#36924;&#36817;&#21487;&#33021;&#35745;&#31639;&#20195;&#20215;&#39640;&#26114;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#31070;&#32463;&#31639;&#23376;&#30340;&#21464;&#20998;&#25512;&#26029;&#65288;NOVI&#65289;&#29992;&#20110;&#28145;&#24230;&#39640;&#26031;&#36807;&#31243;&#12290;NOVI&#20351;&#29992;&#31070;&#32463;&#29983;&#25104;&#22120;&#33719;&#24471;&#21462;&#26679;&#22120;&#65292;&#24182;&#22312;L2&#31354;&#38388;&#20013;&#26368;&#23567;&#21270;&#29983;&#25104;&#20998;&#24067;&#21644;&#30495;&#23454;&#21518;&#39564;&#20043;&#38388;&#30340;&#27491;&#21017;&#21270;Stein&#24046;&#24322;&#12290;&#25105;&#20204;&#20351;&#29992;&#33945;&#29305;&#21345;&#32599;&#20272;&#35745;&#21644;&#23376;&#37319;&#26679;&#38543;&#26426;&#20248;&#21270;&#25216;&#26415;&#35299;&#20915;&#20102;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36890;&#36807;&#23558;Fisher&#25955;&#24230;&#19982;&#24120;&#25968;&#30456;&#20056;&#26469;&#25511;&#21046;&#26041;&#27861;&#24341;&#20837;&#30340;&#20559;&#24046;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#40065;&#26834;&#30340;&#35823;&#24046;&#25511;&#21046;&#65292;&#30830;&#20445;&#20102;&#31639;&#27861;&#30340;&#31283;&#23450;&#24615;&#21644;&#31934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Gaussian Process (DGP) models offer a powerful nonparametric approach for Bayesian inference, but exact inference is typically intractable, motivating the use of various approximations. However, existing approaches, such as mean-field Gaussian assumptions, limit the expressiveness and efficacy of DGP models, while stochastic approximation can be computationally expensive. To tackle these challenges, we introduce Neural Operator Variational Inference (NOVI) for Deep Gaussian Processes. NOVI uses a neural generator to obtain a sampler and minimizes the Regularized Stein Discrepancy in L2 space between the generated distribution and true posterior. We solve the minimax problem using Monte Carlo estimation and subsampling stochastic optimization techniques. We demonstrate that the bias introduced by our method can be controlled by multiplying the Fisher divergence with a constant, which leads to robust error control and ensures the stability and precision of the algorithm. Our experim
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#26679;&#24615;&#40065;&#26834;&#24615;&#32852;&#37030;&#26041;&#27861;&#65292;&#29992;&#20110;&#36890;&#36807;&#22810;&#20013;&#24515;&#25968;&#25454;&#36827;&#34892;&#21512;&#29702;&#30340;&#22240;&#26524;&#25512;&#26029;&#65292;&#35299;&#20915;&#20102;&#25968;&#25454;&#38544;&#31169;&#20445;&#25252;&#21644;&#20010;&#20307;&#21327;&#21464;&#37327;&#20998;&#24067;&#24322;&#36136;&#24615;&#30340;&#25361;&#25112;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#25928;&#29575;&#21644;&#40065;&#26834;&#24615;&#26041;&#38754;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#26377;&#38480;&#26679;&#26412;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2309.12600</link><description>&lt;p&gt;
&#22810;&#26679;&#24615;&#40065;&#26834;&#24615;&#32852;&#37030;&#20272;&#35745;&#30340;&#30446;&#26631;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
Multiply Robust Federated Estimation of Targeted Average Treatment Effects. (arXiv:2309.12600v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12600
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#26679;&#24615;&#40065;&#26834;&#24615;&#32852;&#37030;&#26041;&#27861;&#65292;&#29992;&#20110;&#36890;&#36807;&#22810;&#20013;&#24515;&#25968;&#25454;&#36827;&#34892;&#21512;&#29702;&#30340;&#22240;&#26524;&#25512;&#26029;&#65292;&#35299;&#20915;&#20102;&#25968;&#25454;&#38544;&#31169;&#20445;&#25252;&#21644;&#20010;&#20307;&#21327;&#21464;&#37327;&#20998;&#24067;&#24322;&#36136;&#24615;&#30340;&#25361;&#25112;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#25928;&#29575;&#21644;&#40065;&#26834;&#24615;&#26041;&#38754;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#26377;&#38480;&#26679;&#26412;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#25110;&#22810;&#20013;&#24515;&#30740;&#31350;&#30456;&#27604;&#21333;&#20013;&#24515;&#30740;&#31350;&#20855;&#26377;&#26126;&#26174;&#20248;&#21183;&#65292;&#21253;&#25324;&#22686;&#21152;&#26222;&#36866;&#24615;&#12289;&#33021;&#22815;&#30740;&#31350;&#23569;&#25968;&#32676;&#20307;&#21644;&#30740;&#31350;&#31232;&#26377;&#26292;&#38706;&#19982;&#32467;&#26524;&#30340;&#26426;&#20250;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30740;&#31350;&#23384;&#22312;&#25968;&#25454;&#38544;&#31169;&#20445;&#25252;&#21644;&#20010;&#20307;&#21327;&#21464;&#37327;&#20998;&#24067;&#24322;&#36136;&#24615;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#32852;&#37030;&#26041;&#27861;&#65292;&#36890;&#36807;&#24320;&#21457;&#22810;&#26679;&#24615;&#40065;&#26834;&#24615;&#21644;&#38544;&#31169;&#20445;&#25252;&#30340;&#36741;&#21161;&#20989;&#25968;&#20272;&#35745;&#65292;&#20026;&#30446;&#26631;&#20154;&#32676;&#25552;&#20379;&#26377;&#25928;&#30340;&#22240;&#26524;&#25512;&#26029;&#12290;&#25105;&#20204;&#36890;&#36807;&#38598;&#25104;&#23398;&#20064;&#24314;&#31435;&#20102;&#36716;&#31227;&#23398;&#20064;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#28304;&#31449;&#28857;&#30340;&#32452;&#21512;&#26435;&#37325;&#20197;&#32452;&#21512;&#20449;&#24687;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#23398;&#20064;&#21040;&#30340;&#26435;&#37325;&#22312;&#19981;&#21516;&#22330;&#26223;&#19979;&#26159;&#39640;&#25928;&#21644;&#26368;&#20248;&#30340;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25928;&#29575;&#21644;&#40065;&#26834;&#24615;&#26041;&#38754;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#26377;&#38480;&#26679;&#26412;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated or multi-site studies have distinct advantages over single-site studies, including increased generalizability, the ability to study underrepresented populations, and the opportunity to study rare exposures and outcomes. However, these studies are challenging due to the need to preserve the privacy of each individual's data and the heterogeneity in their covariate distributions. We propose a novel federated approach to derive valid causal inferences for a target population using multi-site data. We adjust for covariate shift and covariate mismatch between sites by developing multiply-robust and privacy-preserving nuisance function estimation. Our methodology incorporates transfer learning to estimate ensemble weights to combine information from source sites. We show that these learned weights are efficient and optimal under different scenarios. We showcase the finite sample advantages of our approach in terms of efficiency and robustness compared to existing approaches.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#31867;&#20284;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#20026;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;(SAM)&#65292;&#19968;&#31181;&#25913;&#36827;&#27867;&#21270;&#24615;&#33021;&#30340;&#26799;&#24230;&#19979;&#38477;&#21464;&#31181;&#65292;&#30830;&#23450;&#20102;&#19968;&#20010;&#31283;&#23450;&#24615;&#36793;&#30028;&#65292;&#35813;&#36793;&#30028;&#21462;&#20915;&#20110;&#26799;&#24230;&#30340;&#33539;&#25968;&#12290;</title><link>http://arxiv.org/abs/2309.12488</link><description>&lt;p&gt;
&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#21644;&#31283;&#23450;&#24615;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sharpness-Aware Minimization and the Edge of Stability. (arXiv:2309.12488v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12488
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#31867;&#20284;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#20026;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;(SAM)&#65292;&#19968;&#31181;&#25913;&#36827;&#27867;&#21270;&#24615;&#33021;&#30340;&#26799;&#24230;&#19979;&#38477;&#21464;&#31181;&#65292;&#30830;&#23450;&#20102;&#19968;&#20010;&#31283;&#23450;&#24615;&#36793;&#30028;&#65292;&#35813;&#36793;&#30028;&#21462;&#20915;&#20110;&#26799;&#24230;&#30340;&#33539;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#24403;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;(GD)&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26102;&#65292;&#25439;&#22833;&#20989;&#25968;&#30340;Hessian&#30697;&#38453;&#30340;&#25805;&#20316;&#31526;&#33539;&#25968;&#20250;&#22686;&#38271;&#65292;&#30452;&#21040;&#25509;&#36817;$2/\eta$&#65292;&#20043;&#21518;&#20250;&#22312;&#35813;&#20540;&#21608;&#22260;&#27874;&#21160;&#12290;&#26681;&#25454;&#23545;&#25439;&#22833;&#20989;&#25968;&#30340;&#23616;&#37096;&#20108;&#27425;&#36924;&#36817;&#65292;$2/\eta$&#34987;&#31216;&#20026;&#8220;&#31283;&#23450;&#24615;&#36793;&#30028;&#8221;&#12290;&#25105;&#20204;&#20351;&#29992;&#31867;&#20284;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#20026;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;(SAM)&#30830;&#23450;&#20102;&#19968;&#20010;&#8220;&#31283;&#23450;&#24615;&#36793;&#30028;&#8221;&#65292;SAM&#26159;&#19968;&#31181;&#25913;&#36827;&#27867;&#21270;&#24615;&#33021;&#30340;GD&#21464;&#31181;&#12290;&#19982;GD&#19981;&#21516;&#65292;SAM&#30340;&#31283;&#23450;&#24615;&#36793;&#30028;&#21462;&#20915;&#20110;&#26799;&#24230;&#30340;&#33539;&#25968;&#12290;&#36890;&#36807;&#19977;&#20010;&#28145;&#24230;&#23398;&#20064;&#20219;&#21153;&#30340;&#23454;&#35777;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;SAM&#22312;&#36825;&#20010;&#20998;&#26512;&#20013;&#30830;&#23450;&#30340;&#31283;&#23450;&#24615;&#36793;&#30028;&#19978;&#36816;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent experiments have shown that, often, when training a neural network with gradient descent (GD) with a step size $\eta$, the operator norm of the Hessian of the loss grows until it approximately reaches $2/\eta$, after which it fluctuates around this value.  The quantity $2/\eta$ has been called the "edge of stability" based on consideration of a local quadratic approximation of the loss. We perform a similar calculation to arrive at an "edge of stability" for Sharpness-Aware Minimization (SAM), a variant of GD which has been shown to improve its generalization. Unlike the case for GD, the resulting SAM-edge depends on the norm of the gradient. Using three deep learning training tasks, we see empirically that SAM operates on the edge of stability identified by this analysis.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25903;&#25745;&#40065;&#26834;&#25512;&#26029;&#30340;&#20984;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#20984;&#35268;&#21010;&#25552;&#20379;&#31574;&#30053;&#20215;&#20540;&#30340;&#31934;&#30830;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#35813;&#26041;&#27861;&#36824;&#21487;&#20197;&#36827;&#34892;&#22810;&#31181;&#25193;&#23637;&#65292;&#24182;&#19988;&#20855;&#26377;&#24378;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2309.12450</link><description>&lt;p&gt;
&#25903;&#25745;&#40065;&#26834;&#25512;&#26029;&#30340;&#20984;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Convex Framework for Confounding Robust Inference. (arXiv:2309.12450v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12450
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25903;&#25745;&#40065;&#26834;&#25512;&#26029;&#30340;&#20984;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#20984;&#35268;&#21010;&#25552;&#20379;&#31574;&#30053;&#20215;&#20540;&#30340;&#31934;&#30830;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#35813;&#26041;&#27861;&#36824;&#21487;&#20197;&#36827;&#34892;&#22810;&#31181;&#25193;&#23637;&#65292;&#24182;&#19988;&#20855;&#26377;&#24378;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#21463;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#24433;&#21709;&#30340;&#31163;&#32447;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#12290;&#20256;&#32479;&#30340;&#25935;&#24863;&#24615;&#20998;&#26512;&#26041;&#27861;&#24120;&#34987;&#29992;&#26469;&#22312;&#32473;&#23450;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#19978;&#20272;&#35745;&#22312;&#26368;&#22351;&#28151;&#28102;&#24773;&#20917;&#19979;&#30340;&#31574;&#30053;&#20215;&#20540;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#24037;&#20316;&#36890;&#24120;&#20026;&#20102;&#21487;&#34892;&#24615;&#32780;&#37319;&#29992;&#19968;&#20123;&#31895;&#31961;&#30340;&#26494;&#24347;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#30340;&#26041;&#27861;&#65292;&#23548;&#33268;&#23545;&#31574;&#30053;&#20215;&#20540;&#30340;&#20272;&#35745;&#36807;&#20110;&#20445;&#23432;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#20272;&#35745;&#22120;&#65292;&#21033;&#29992;&#20984;&#35268;&#21010;&#25552;&#20379;&#20102;&#31574;&#30053;&#20215;&#20540;&#30340;&#19968;&#20010;&#36739;&#20026;&#31934;&#30830;&#30340;&#19979;&#30028;&#12290;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#30340;&#24191;&#27867;&#36866;&#29992;&#24615;&#20351;&#24471;&#20854;&#33021;&#22815;&#36827;&#34892;&#22810;&#31181;&#25193;&#23637;&#65292;&#20363;&#22914;&#22522;&#20110;f-&#20998;&#27495;&#30340;&#25935;&#24863;&#24615;&#20998;&#26512;&#12289;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#21644;&#20449;&#24687;&#20934;&#21017;&#30340;&#27169;&#22411;&#36873;&#25321;&#20197;&#21450;&#21033;&#29992;&#19978;&#30028;&#36827;&#34892;&#40065;&#26834;&#31574;&#30053;&#23398;&#20064;&#31561;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#26041;&#27861;&#21487;&#20197;&#36890;&#36807;&#24378;&#23545;&#20598;&#24615;&#37325;&#26032;&#34920;&#36848;&#20026;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#20174;&#32780;&#21033;&#29992;M&#25216;&#26415;&#25552;&#20379;&#20102;&#23545;&#25152;&#25552;&#20986;&#20272;&#35745;&#22120;&#30340;&#24378;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study policy evaluation of offline contextual bandits subject to unobserved confounders. Sensitivity analysis methods are commonly used to estimate the policy value under the worst-case confounding over a given uncertainty set. However, existing work often resorts to some coarse relaxation of the uncertainty set for the sake of tractability, leading to overly conservative estimation of the policy value. In this paper, we propose a general estimator that provides a sharp lower bound of the policy value using convex programming. The generality of our estimator enables various extensions such as sensitivity analysis with f-divergence, model selection with cross validation and information criterion, and robust policy learning with the sharp lower bound. Furthermore, our estimation method can be reformulated as an empirical risk minimization problem thanks to the strong duality, which enables us to provide strong theoretical guarantees of the proposed estimator using techniques of the M-
&lt;/p&gt;</description></item><item><title>&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#35774;&#32622;&#19979;&#23398;&#20064;&#26080;&#38480;&#32500;&#32447;&#24615;&#31639;&#23376;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19968;&#23450;&#30340;&#26465;&#20214;&#19979;&#65292;&#32447;&#24615;&#31639;&#23376;&#26159;&#21487;&#20197;&#22312;&#32447;&#23398;&#20064;&#30340;&#65292;&#32780;&#22312;&#21478;&#19968;&#20123;&#26465;&#20214;&#19979;&#21017;&#19981;&#21487;&#20197;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#22312;&#32447;&#22343;&#19968;&#25910;&#25947;&#21644;&#23398;&#20064;&#33021;&#21147;&#20043;&#38388;&#30340;&#20998;&#31163;&#65292;&#24182;&#22312;PAC&#35774;&#32622;&#19979;&#24471;&#21040;&#20102;&#30456;&#21516;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.06548</link><description>&lt;p&gt;
&#22312;&#22312;&#32447;&#35774;&#32622;&#19979;&#23398;&#20064;&#32447;&#24615;&#31639;&#23376;&#30340;&#26080;&#38480;&#32500;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Online Infinite-Dimensional Regression: Learning Linear Operators. (arXiv:2309.06548v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06548
&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#35774;&#32622;&#19979;&#23398;&#20064;&#26080;&#38480;&#32500;&#32447;&#24615;&#31639;&#23376;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19968;&#23450;&#30340;&#26465;&#20214;&#19979;&#65292;&#32447;&#24615;&#31639;&#23376;&#26159;&#21487;&#20197;&#22312;&#32447;&#23398;&#20064;&#30340;&#65292;&#32780;&#22312;&#21478;&#19968;&#20123;&#26465;&#20214;&#19979;&#21017;&#19981;&#21487;&#20197;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#22312;&#32447;&#22343;&#19968;&#25910;&#25947;&#21644;&#23398;&#20064;&#33021;&#21147;&#20043;&#38388;&#30340;&#20998;&#31163;&#65292;&#24182;&#22312;PAC&#35774;&#32622;&#19979;&#24471;&#21040;&#20102;&#30456;&#21516;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#32447;&#35774;&#32622;&#19979;&#23398;&#20064;&#20004;&#20010;&#26080;&#38480;&#32500;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20043;&#38388;&#30340;&#32447;&#24615;&#31639;&#23376;&#38382;&#39064;&#65292;&#36890;&#36807;&#26368;&#23567;&#20108;&#20056;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#23398;&#20064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;$p \in [1, \infty)$&#33539;&#22260;&#20869;&#65292;&#20855;&#26377;&#22343;&#21248;&#26377;&#30028;$p$-Schatten&#33539;&#25968;&#30340;&#32447;&#24615;&#31639;&#23376;&#31867;&#26159;&#21487;&#20197;&#22312;&#32447;&#23398;&#20064;&#30340;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20855;&#26377;&#22343;&#21248;&#26377;&#30028;&#31639;&#23376;&#33539;&#25968;&#30340;&#32447;&#24615;&#31639;&#23376;&#31867;\textit{&#19981;}&#26159;&#21487;&#20197;&#22312;&#32447;&#23398;&#20064;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#25214;&#21040;&#19968;&#31867;&#26377;&#30028;&#32447;&#24615;&#31639;&#23376;&#65292;&#35777;&#26126;&#20102;&#22312;&#32447;&#22343;&#19968;&#25910;&#25947;&#21644;&#23398;&#20064;&#33021;&#21147;&#20043;&#38388;&#30340;&#20998;&#31163;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19981;&#21487;&#33021;&#24615;&#32467;&#26524;&#21644;&#22343;&#19968;&#25910;&#25947;&#19982;&#23398;&#20064;&#33021;&#21147;&#20043;&#38388;&#30340;&#20998;&#31163;&#22312;PAC&#35774;&#32622;&#19979;&#21516;&#26679;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning linear operators under squared loss between two infinite-dimensional Hilbert spaces in the online setting. We show that the class of linear operators with uniformly bounded $p$-Schatten norm is online learnable for any $p \in [1, \infty)$. On the other hand, we prove an impossibility result by showing that the class of uniformly bounded linear operators with respect to the operator norm is \textit{not} online learnable. Moreover, we show a separation between online uniform convergence and online learnability by identifying a class of bounded linear operators that is online learnable but uniform convergence does not hold. Finally, we prove that the impossibility result and the separation between uniform convergence and learnability also hold in the agnostic PAC setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#28508;&#22312;&#37327;&#21270;&#30340;&#26041;&#24335;&#23454;&#29616;&#20102;&#35299;&#32544;&#34920;&#31034;&#23398;&#20064;&#65292;&#24182;&#36890;&#36807;&#20005;&#26684;&#30340;&#20132;&#27969;&#29942;&#39048;&#21644;&#24378;&#22823;&#30340;&#27169;&#22411;&#35268;&#33539;&#21270;&#25104;&#21151;&#23558;&#25968;&#25454;&#36827;&#34892;&#20102;&#32452;&#21512;&#32534;&#30721;&#21644;&#35299;&#30721;&#65292;&#26368;&#32456;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#35299;&#32544;&#24615;&#33021;&#65292;&#24182;&#25552;&#39640;&#20102;&#26631;&#20934;VAE&#27169;&#22411;&#23398;&#20064;&#34920;&#24449;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.18378</link><description>&lt;p&gt;
&#36890;&#36807;&#28508;&#22312;&#37327;&#21270;&#36827;&#34892;&#35299;&#32544;
&lt;/p&gt;
&lt;p&gt;
Disentanglement via Latent Quantization. (arXiv:2305.18378v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18378
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#28508;&#22312;&#37327;&#21270;&#30340;&#26041;&#24335;&#23454;&#29616;&#20102;&#35299;&#32544;&#34920;&#31034;&#23398;&#20064;&#65292;&#24182;&#36890;&#36807;&#20005;&#26684;&#30340;&#20132;&#27969;&#29942;&#39048;&#21644;&#24378;&#22823;&#30340;&#27169;&#22411;&#35268;&#33539;&#21270;&#25104;&#21151;&#23558;&#25968;&#25454;&#36827;&#34892;&#20102;&#32452;&#21512;&#32534;&#30721;&#21644;&#35299;&#30721;&#65292;&#26368;&#32456;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#35299;&#32544;&#24615;&#33021;&#65292;&#24182;&#25552;&#39640;&#20102;&#26631;&#20934;VAE&#27169;&#22411;&#23398;&#20064;&#34920;&#24449;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35299;&#32544;&#34920;&#31034;&#23398;&#20064;&#20013;&#65292;&#27169;&#22411;&#38656;&#35201;&#23558;&#25968;&#25454;&#38598;&#30340;&#22522;&#30784;&#21464;&#21270;&#22240;&#32032;&#20998;&#24320;&#24182;&#29420;&#31435;&#22320;&#34920;&#31034;&#20986;&#26469;&#65292;&#32780;&#27169;&#22411;&#24182;&#27809;&#26377;&#25552;&#20379;&#26377;&#20851;&#36825;&#20123;&#22240;&#32032;&#30340;&#30495;&#23454;&#20449;&#24687;&#65292;&#24402;&#32435;&#20559;&#35265;&#22312;&#23454;&#29616;&#35299;&#32544;&#26041;&#38754;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#26045;&#21152;&#20005;&#26684;&#30340;&#20132;&#27969;&#29942;&#39048;&#21644;&#24378;&#22823;&#30340;&#27169;&#22411;&#35268;&#33539;&#21270;&#65292;&#26500;&#24314;&#20102;&#19968;&#31181;&#26397;&#30528;&#32452;&#21512;&#32534;&#30721;&#21644;&#35299;&#30721;&#25968;&#25454;&#30340;&#24402;&#32435;&#20559;&#35265;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23545;&#28508;&#22312;&#32500;&#24230;&#36827;&#34892;&#21487;&#23398;&#20064;&#30340;&#31163;&#25955;&#32534;&#30721;&#65292;&#24182;&#20026;&#27599;&#20010;&#32500;&#24230;&#24212;&#29992;&#19968;&#20010;&#21333;&#29420;&#30340;&#26631;&#37327;&#30721;&#20070;&#12290;&#28508;&#22312;&#37327;&#21270;&#36843;&#20351;&#32534;&#30721;&#22120;&#22312;&#35768;&#22810;&#25968;&#25454;&#28857;&#19978;&#20351;&#29992;&#23569;&#37327;&#28508;&#22312;&#20540;&#65292;&#20174;&#32780;&#20351;&#35299;&#30721;&#22120;&#33021;&#22815;&#20026;&#27599;&#20010;&#20540;&#20998;&#37197;&#19968;&#33268;&#30340;&#21547;&#20041;&#12290;&#35268;&#33539;&#21270;&#26377;&#21161;&#20110;&#23558;&#27169;&#22411;&#24341;&#21521;&#36825;&#31181;&#31616;&#26126;&#31574;&#30053;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#24191;&#27867;&#24212;&#29992;&#24615;&#65292;&#24182;&#19988;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;&#19968;&#31995;&#21015;&#26631;&#20934;VAE&#27169;&#22411;&#23398;&#20064;&#30340;&#34920;&#24449;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In disentangled representation learning, a model is asked to tease apart a dataset's underlying sources of variation and represent them independently of one another. Since the model is provided with no ground truth information about these sources, inductive biases take a paramount role in enabling disentanglement. In this work, we construct an inductive bias towards compositionally encoding and decoding data by enforcing a harsh communication bottleneck. Concretely, we do this by (i) quantizing the latent space into learnable discrete codes with a separate scalar codebook per dimension and (ii) applying strong model regularization via an unusually high weight decay. Intuitively, the quantization forces the encoder to use a small number of latent values across many datapoints, which in turn enables the decoder to assign a consistent meaning to each value. Regularization then serves to drive the model towards this parsimonious strategy. We demonstrate the broad applicability of this appr
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#34394;&#25311;&#31890;&#23376;&#38543;&#26426;&#36924;&#36817;&#30340;&#21487;&#35777;&#36895;&#38480;&#21046;&#21464;&#31181;&#30340;SVGD&#31639;&#27861;&#65292;&#20855;&#26377;&#21487;&#35777;&#36895;&#30340;&#26377;&#38480;&#31890;&#23376;&#25910;&#25947;&#29575;&#12290;</title><link>http://arxiv.org/abs/2305.17558</link><description>&lt;p&gt;
&#22522;&#20110;&#34394;&#25311;&#31890;&#23376;&#38543;&#26426;&#36924;&#36817;&#30340;&#21487;&#35777;&#36895;&#38480;&#21046;&#21464;&#31181;&#30340;SVGD&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Provably Fast Finite Particle Variants of SVGD via Virtual Particle Stochastic Approximation. (arXiv:2305.17558v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17558
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#34394;&#25311;&#31890;&#23376;&#38543;&#26426;&#36924;&#36817;&#30340;&#21487;&#35777;&#36895;&#38480;&#21046;&#21464;&#31181;&#30340;SVGD&#31639;&#27861;&#65292;&#20855;&#26377;&#21487;&#35777;&#36895;&#30340;&#26377;&#38480;&#31890;&#23376;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#65288;SVGD&#65289;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#23427;&#27169;&#25311;&#30456;&#20114;&#20316;&#29992;&#30340;&#31890;&#23376;&#31995;&#32479;&#20197;&#36817;&#20284;&#20174;&#30446;&#26631;&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#20855;&#26377;&#21508;&#31181;&#39046;&#22495;&#30340;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#32463;&#39564;&#24615;&#33021;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#23427;&#30340;&#32676;&#20307;&#65288;&#21363;&#65292;&#26080;&#38480;&#31890;&#23376;&#65289;&#26497;&#38480;&#21160;&#21147;&#23398;&#24050;&#32463;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#30740;&#31350;&#65292;&#20294;&#26159;SVGD&#22312;&#26377;&#38480;&#31890;&#23376;&#20307;&#21046;&#19979;&#30340;&#34892;&#20026;&#21017;&#19981;&#22826;&#28165;&#26970;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#31181;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;SVGD&#21464;&#20307;&#65292;&#21363;VP-SVGD&#65288;&#20174;&#27010;&#24565;&#19978;&#35762;&#24456;&#20248;&#38597;&#65289;&#21644;GB-SVGD&#65288;&#20174;&#32463;&#39564;&#19978;&#30475;&#24456;&#26377;&#25928;&#65289;&#65292;&#20855;&#26377;&#21487;&#35777;&#36895;&#30340;&#26377;&#38480;&#31890;&#23376;&#25910;&#25947;&#29575;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#8220;&#34394;&#25311;&#31890;&#23376;&#8221;&#30340;&#27010;&#24565;&#65292;&#24182;&#22312;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#20013;&#24320;&#21457;&#20102;&#20154;&#21475;&#26497;&#38480;SVGD&#21160;&#21147;&#23398;&#30340;&#26032;&#22411;&#38543;&#26426;&#36924;&#36817;&#26041;&#27861;&#65292;&#23427;&#20204;&#21487;&#20197;&#20351;&#29992;&#26377;&#38480;&#25968;&#37327;&#30340;&#31890;&#23376;&#31934;&#30830;&#23454;&#29616;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#30475;&#20316;&#26159;SVGD&#30340;&#29305;&#23450;&#38543;&#26426;&#25209;&#22788;&#29702;&#36924;&#36817;&#65292;&#27604;&#26222;&#36890;&#26041;&#27861;&#26356;&#20855;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stein Variational Gradient Descent (SVGD) is a popular variational inference algorithm which simulates an interacting particle system to approximately sample from a target distribution, with impressive empirical performance across various domains. Theoretically, its population (i.e, infinite-particle) limit dynamics is well studied but the behavior of SVGD in the finite-particle regime is much less understood. In this work, we design two computationally efficient variants of SVGD, namely VP-SVGD (which is conceptually elegant) and GB-SVGD (which is empirically effective), with provably fast finite-particle convergence rates. We introduce the notion of \emph{virtual particles} and develop novel stochastic approximations of population-limit SVGD dynamics in the space of probability measures, which are exactly implementable using a finite number of particles. Our algorithms can be viewed as specific random-batch approximations of SVGD, which are computationally more efficient than ordinar
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26469;&#25551;&#36848;&#22312;&#21327;&#20316;&#23398;&#20064;&#20013;&#31454;&#20105;&#23545;&#25163;&#30340;&#19981;&#35802;&#23454;&#34892;&#20026;&#65292;&#25552;&#20986;&#20102;&#26426;&#21046;&#26469;&#28608;&#21169;&#35802;&#23454;&#27807;&#36890;&#65292;&#24182;&#30830;&#20445;&#23398;&#20064;&#36136;&#37327;&#19982;&#20840;&#38754;&#21512;&#20316;&#30456;&#24403;&#12290;</title><link>http://arxiv.org/abs/2305.16272</link><description>&lt;p&gt;
&#22312;&#21327;&#21516;&#23398;&#20064;&#21644;&#20248;&#21270;&#20013;&#28608;&#21169;&#31454;&#20105;&#23545;&#25163;&#35802;&#23454;&#34892;&#20026;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Incentivizing Honesty among Competitors in Collaborative Learning and Optimization. (arXiv:2305.16272v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16272
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26469;&#25551;&#36848;&#22312;&#21327;&#20316;&#23398;&#20064;&#20013;&#31454;&#20105;&#23545;&#25163;&#30340;&#19981;&#35802;&#23454;&#34892;&#20026;&#65292;&#25552;&#20986;&#20102;&#26426;&#21046;&#26469;&#28608;&#21169;&#35802;&#23454;&#27807;&#36890;&#65292;&#24182;&#30830;&#20445;&#23398;&#20064;&#36136;&#37327;&#19982;&#20840;&#38754;&#21512;&#20316;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21327;&#21516;&#23398;&#20064;&#25216;&#26415;&#33021;&#22815;&#35753;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#35757;&#32451;&#27604;&#20165;&#21033;&#29992;&#21333;&#19968;&#25968;&#25454;&#28304;&#30340;&#27169;&#22411;&#25928;&#26524;&#26356;&#22909;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#28508;&#22312;&#30340;&#21442;&#19982;&#32773;&#26159;&#19979;&#28216;&#20219;&#21153;&#20013;&#30340;&#31454;&#20105;&#23545;&#25163;&#65292;&#22914;&#27599;&#20010;&#37117;&#24076;&#26395;&#36890;&#36807;&#25552;&#20379;&#26368;&#20339;&#25512;&#33616;&#26469;&#21560;&#24341;&#23458;&#25143;&#30340;&#20844;&#21496;&#12290;&#36825;&#21487;&#33021;&#20250;&#28608;&#21169;&#19981;&#35802;&#23454;&#30340;&#26356;&#26032;&#65292;&#25439;&#23475;&#20854;&#20182;&#21442;&#19982;&#32773;&#30340;&#27169;&#22411;&#65292;&#20174;&#32780;&#21487;&#33021;&#30772;&#22351;&#21327;&#20316;&#30340;&#22909;&#22788;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#20010;&#27169;&#22411;&#26469;&#25551;&#36848;&#36825;&#31181;&#20132;&#20114;&#65292;&#24182;&#22312;&#35813;&#26694;&#26550;&#20869;&#30740;&#31350;&#20102;&#20004;&#20010;&#23398;&#20064;&#20219;&#21153;&#65306;&#21333;&#36718;&#22343;&#20540;&#20272;&#35745;&#21644;&#24378;&#20984;&#30446;&#26631;&#30340;&#22810;&#36718; SGD&#12290;&#23545;&#20110;&#19968;&#31867;&#33258;&#28982;&#30340;&#21442;&#19982;&#32773;&#34892;&#20026;&#65292;&#25105;&#20204;&#21457;&#29616;&#29702;&#24615;&#30340;&#23458;&#25143;&#20250;&#34987;&#28608;&#21169;&#24378;&#28872;&#22320;&#25805;&#32437;&#20182;&#20204;&#30340;&#26356;&#26032;&#65292;&#20174;&#32780;&#38450;&#27490;&#23398;&#20064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26426;&#21046;&#26469;&#28608;&#21169;&#35802;&#23454;&#27807;&#36890;&#65292;&#24182;&#30830;&#20445;&#23398;&#20064;&#36136;&#37327;&#19982;&#20840;&#38754;&#21512;&#20316;&#30456;&#24403;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#19968;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Collaborative learning techniques have the potential to enable training machine learning models that are superior to models trained on a single entity's data. However, in many cases, potential participants in such collaborative schemes are competitors on a downstream task, such as firms that each aim to attract customers by providing the best recommendations. This can incentivize dishonest updates that damage other participants' models, potentially undermining the benefits of collaboration. In this work, we formulate a game that models such interactions and study two learning tasks within this framework: single-round mean estimation and multi-round SGD on strongly-convex objectives. For a natural class of player actions, we show that rational clients are incentivized to strongly manipulate their updates, preventing learning. We then propose mechanisms that incentivize honest communication and ensure learning quality comparable to full cooperation. Lastly, we empirically demonstrate the
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#23567;&#27874;&#22495;&#30340;&#23646;&#24615;&#26041;&#27861;WCAM&#65292;&#33021;&#22815;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#23545;&#22270;&#20687;&#25439;&#22351;&#30340;&#25935;&#24863;&#24615;&#65292;&#30830;&#23450;&#39044;&#27979;&#30340;&#36275;&#22815;&#20449;&#24687;&#65292;&#24182;&#38416;&#26126;&#32553;&#25918;&#22914;&#20309;&#22686;&#21152;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.14979</link><description>&lt;p&gt;
&#23610;&#24230;&#24456;&#37325;&#35201;&#65306;&#22522;&#20110;&#23567;&#27874;&#22495;&#30340;&#23646;&#24615;&#26041;&#27861;&#35299;&#37322;&#27169;&#22411;&#23545;&#22270;&#20687;&#25439;&#22351;&#30340;&#25935;&#24863;&#24615;
&lt;/p&gt;
&lt;p&gt;
Scale Matters: Attribution Meets the Wavelet Domain to Explain Model Sensitivity to Image Corruptions. (arXiv:2305.14979v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14979
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#23567;&#27874;&#22495;&#30340;&#23646;&#24615;&#26041;&#27861;WCAM&#65292;&#33021;&#22815;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#23545;&#22270;&#20687;&#25439;&#22351;&#30340;&#25935;&#24863;&#24615;&#65292;&#30830;&#23450;&#39044;&#27979;&#30340;&#36275;&#22815;&#20449;&#24687;&#65292;&#24182;&#38416;&#26126;&#32553;&#25918;&#22914;&#20309;&#22686;&#21152;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#26041;&#38754;&#34920;&#29616;&#20986;&#20102;&#20986;&#33394;&#30340;&#24615;&#33021;&#65292;&#20294;&#23427;&#20204;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#37096;&#32626;&#30001;&#20110;&#23545;&#22270;&#20687;&#25439;&#22351;&#30340;&#25935;&#24863;&#24615;&#32780;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#29616;&#26377;&#30340;&#23646;&#24615;&#26041;&#27861;&#23545;&#20110;&#35299;&#37322;&#23545;&#22270;&#20687;&#25439;&#22351;&#30340;&#25935;&#24863;&#24615;&#26159;&#26080;&#25928;&#30340;&#65292;&#32780;&#24378;&#20581;&#24615;&#39046;&#22495;&#30340;&#25991;&#29486;&#20165;&#25552;&#20379;&#22522;&#20110;&#27169;&#22411;&#30340;&#35299;&#37322;&#12290;&#28982;&#32780;&#65292;&#22312;&#22270;&#20687;&#25439;&#22351;&#30340;&#24773;&#20917;&#19979;&#65292;&#23457;&#26597;&#27169;&#22411;&#30340;&#34892;&#20026;&#33021;&#21147;&#23545;&#20110;&#25552;&#39640;&#29992;&#25143;&#20449;&#20219;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;Wavelet sCale Attribution Method (WCAM)&#65292;&#23427;&#26159;&#20174;&#20687;&#32032;&#22495;&#21040;&#31354;&#38388;&#23610;&#24230;&#22495;&#30340;&#23646;&#24615;&#26041;&#27861;&#30340;&#27010;&#25324;&#12290;&#22312;&#31354;&#38388;&#23610;&#24230;&#22495;&#20013;&#36827;&#34892;&#23646;&#24615;&#25581;&#31034;&#20102;&#27169;&#22411;&#30340;&#20851;&#27880;&#28857;&#21644;&#23610;&#24230;&#12290;&#25105;&#20204;&#23637;&#31034;WCAM&#35299;&#37322;&#20102;&#27169;&#22411;&#22312;&#22270;&#20687;&#30772;&#22351;&#19979;&#30340;&#22833;&#25928;&#65292;&#30830;&#23450;&#20102;&#39044;&#27979;&#30340;&#36275;&#22815;&#20449;&#24687;&#65292;&#24182;&#35299;&#37322;&#20102;&#22914;&#20309;&#36890;&#36807;&#32553;&#25918;&#22686;&#21152;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural networks have shown remarkable performance in computer vision, but their deployment in real-world scenarios is challenging due to their sensitivity to image corruptions. Existing attribution methods are uninformative for explaining the sensitivity to image corruptions, while the literature on robustness only provides model-based explanations. However, the ability to scrutinize models' behavior under image corruptions is crucial to increase the user's trust. Towards this end, we introduce the Wavelet sCale Attribution Method (WCAM), a generalization of attribution from the pixel domain to the space-scale domain. Attribution in the space-scale domain reveals where and on what scales the model focuses. We show that the WCAM explains models' failures under image corruptions, identifies sufficient information for prediction, and explains how zoom-in increases accuracy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21512;&#25104;&#32463;&#39564;&#22238;&#25918;&#26041;&#27861;&#35299;&#20915;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#25968;&#25454;&#21294;&#20047;&#38382;&#39064;&#65292;&#36890;&#36807;&#24039;&#22937;&#24212;&#29992;&#29983;&#25104;&#24314;&#27169;&#25216;&#26415;&#26469;&#25193;&#20805;&#25968;&#25454;&#25928;&#26524;&#26174;&#33879;&#12290;</title><link>http://arxiv.org/abs/2303.06614</link><description>&lt;p&gt;
&#21512;&#25104;&#32463;&#39564;&#22238;&#25918;&#65306;&#26088;&#22312;&#29992;&#25193;&#20805;&#25968;&#25454;&#26469;&#25552;&#39640;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#25928;&#26524;
&lt;/p&gt;
&lt;p&gt;
Synthetic Experience Replay. (arXiv:2303.06614v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06614
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21512;&#25104;&#32463;&#39564;&#22238;&#25918;&#26041;&#27861;&#35299;&#20915;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#25968;&#25454;&#21294;&#20047;&#38382;&#39064;&#65292;&#36890;&#36807;&#24039;&#22937;&#24212;&#29992;&#29983;&#25104;&#24314;&#27169;&#25216;&#26415;&#26469;&#25193;&#20805;&#25968;&#25454;&#25928;&#26524;&#26174;&#33879;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21435;&#21313;&#24180;&#30340;&#19968;&#20010;&#20851;&#38190;&#20027;&#39064;&#26159;&#65292;&#24403;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#21644;&#22823;&#22411;&#25968;&#25454;&#38598;&#30456;&#32467;&#21512;&#26102;&#65292;&#23427;&#20204;&#21487;&#20197;&#20135;&#29983;&#20196;&#20154;&#24778;&#24322;&#30340;&#32467;&#26524;&#12290;&#22312;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#36825;&#31181;&#33539;&#24335;&#36890;&#24120;&#36890;&#36807;&#32463;&#39564;&#22238;&#25918;&#23454;&#29616;&#65292;&#20854;&#20013;&#36807;&#21435;&#30340;&#32463;&#39564;&#25968;&#25454;&#38598;&#29992;&#20110;&#35757;&#32451;&#31574;&#30053;&#25110;&#20540;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#19982;&#30417;&#30563;&#23398;&#20064;&#25110;&#33258;&#30417;&#30563;&#23398;&#20064;&#19981;&#21516;&#65292;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#24517;&#39035;&#25910;&#38598;&#33258;&#24049;&#30340;&#25968;&#25454;&#65292;&#36825;&#36890;&#24120;&#26159;&#26377;&#38480;&#30340;&#12290;&#22240;&#27492;&#65292;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#30340;&#22909;&#22788;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#21363;&#20351;&#26159;&#23567;&#22411;&#31070;&#32463;&#32593;&#32476;&#22312;&#35757;&#32451;&#24320;&#22987;&#26102;&#20063;&#21487;&#33021;&#20986;&#29616;&#36807;&#25311;&#21512;&#29616;&#35937;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#20102;&#29983;&#25104;&#24314;&#27169;&#30340;&#24040;&#22823;&#36827;&#27493;&#65292;&#24182;&#25552;&#20986;&#20102;&#21512;&#25104;&#32463;&#39564;&#22238;&#25918;&#65288;SynthER&#65289;&#65292;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#30340;&#26041;&#27861;&#26469;&#28789;&#27963;&#22320;&#19978;&#37319;&#26679;&#20195;&#29702;&#25910;&#38598;&#30340;&#32463;&#39564;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;SynthER&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#31163;&#32447;&#21644;&#22312;&#32447;&#35774;&#32622;&#19979;&#35757;&#32451;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#65292;&#26080;&#35770;&#26159;&#22312;&#24863;&#30693;&#29615;&#22659;&#36824;&#26159;&#22312;&#20687;&#32032;&#29615;&#22659;&#20013;&#12290;&#22312;&#31163;&#32447;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#20102;&#26174;&#30528;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
A key theme in the past decade has been that when large neural networks and large datasets combine they can produce remarkable results. In deep reinforcement learning (RL), this paradigm is commonly made possible through experience replay, whereby a dataset of past experiences is used to train a policy or value function. However, unlike in supervised or self-supervised learning, an RL agent has to collect its own data, which is often limited. Thus, it is challenging to reap the benefits of deep learning, and even small neural networks can overfit at the start of training. In this work, we leverage the tremendous recent progress in generative modeling and propose Synthetic Experience Replay (SynthER), a diffusion-based approach to flexibly upsample an agent's collected experience. We show that SynthER is an effective method for training RL agents across offline and online settings, in both proprioceptive and pixel-based environments. In offline settings, we observe drastic improvements 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#39034;&#24207;&#22806;&#28304;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#19979;&#30340;&#24378;&#20581;&#31574;&#30053;&#35780;&#20272;&#21644;&#20248;&#21270;&#26041;&#27861;&#65292;&#20351;&#29992;&#27491;&#20132;&#21270;&#30340;&#24378;&#20581;Fitted-Q&#36845;&#20195;&#65292;&#24182;&#28155;&#21152;&#20102;&#20998;&#20301;&#25968;&#20272;&#35745;&#30340;&#20559;&#24046;&#26657;&#27491;&#12290;</title><link>http://arxiv.org/abs/2302.00662</link><description>&lt;p&gt;
&#24378;&#20581;&#30340;Fitted-Q&#35780;&#20272;&#21644;&#36845;&#20195;&#22312;&#39034;&#24207;&#22806;&#28304;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#19979;
&lt;/p&gt;
&lt;p&gt;
Robust Fitted-Q-Evaluation and Iteration under Sequentially Exogenous Unobserved Confounders. (arXiv:2302.00662v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00662
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#39034;&#24207;&#22806;&#28304;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#19979;&#30340;&#24378;&#20581;&#31574;&#30053;&#35780;&#20272;&#21644;&#20248;&#21270;&#26041;&#27861;&#65292;&#20351;&#29992;&#27491;&#20132;&#21270;&#30340;&#24378;&#20581;Fitted-Q&#36845;&#20195;&#65292;&#24182;&#28155;&#21152;&#20102;&#20998;&#20301;&#25968;&#20272;&#35745;&#30340;&#20559;&#24046;&#26657;&#27491;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21307;&#23398;&#12289;&#32463;&#27982;&#21644;&#30005;&#23376;&#21830;&#21153;&#31561;&#39046;&#22495;&#65292;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#38750;&#24120;&#37325;&#35201;&#65292;&#22240;&#20026;&#22312;&#32447;&#23454;&#39564;&#21487;&#33021;&#25104;&#26412;&#39640;&#26114;&#12289;&#21361;&#38505;&#25110;&#19981;&#36947;&#24503;&#65292;&#24182;&#19988;&#30495;&#23454;&#27169;&#22411;&#26410;&#30693;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#26041;&#27861;&#20551;&#35774;&#34892;&#20026;&#31574;&#30053;&#30340;&#25152;&#26377;&#21327;&#21464;&#37327;&#37117;&#26159;&#24050;&#35266;&#23519;&#21040;&#30340;&#12290;&#23613;&#31649;&#36825;&#20010;&#20551;&#35774;"&#39034;&#24207;&#21487;&#24573;&#30053;&#24615;"&#22312;&#35266;&#23519;&#25968;&#25454;&#20013;&#19981;&#22826;&#21487;&#33021;&#25104;&#31435;&#65292;&#20294;&#22823;&#37096;&#20998;&#32771;&#34385;&#36827;&#20837;&#27835;&#30103;&#22240;&#32032;&#30340;&#25968;&#25454;&#21487;&#33021;&#26159;&#35266;&#23519;&#21040;&#30340;&#65292;&#36825;&#28608;&#21169;&#20102;&#25935;&#24863;&#24615;&#20998;&#26512;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#25935;&#24863;&#24615;&#27169;&#22411;&#19979;&#39034;&#24207;&#22806;&#28304;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#19979;&#30340;&#24378;&#20581;&#31574;&#30053;&#35780;&#20272;&#21644;&#31574;&#30053;&#20248;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#24182;&#20998;&#26512;&#20102;&#27491;&#20132;&#21270;&#30340;&#24378;&#20581;Fitted-Q&#36845;&#20195;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#24378;&#20581;&#36125;&#23572;&#26364;&#31639;&#23376;&#30340;&#23553;&#38381;&#24418;&#24335;&#35299;&#26469;&#23548;&#20986;&#24378;&#20581;Q&#20989;&#25968;&#30340;&#25439;&#22833;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#24182;&#23545;&#20998;&#20301;&#25968;&#20272;&#35745;&#21152;&#20837;&#20559;&#24046;&#26657;&#27491;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20860;&#20855;Fitted-Q&#36845;&#20195;&#30340;&#35745;&#31639;&#31616;&#20415;&#24615;&#21644;&#32479;&#35745;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Offline reinforcement learning is important in domains such as medicine, economics, and e-commerce where online experimentation is costly, dangerous or unethical, and where the true model is unknown. However, most methods assume all covariates used in the behavior policy's action decisions are observed. Though this assumption, sequential ignorability/unconfoundedness, likely does not hold in observational data, most of the data that accounts for selection into treatment may be observed, motivating sensitivity analysis. We study robust policy evaluation and policy optimization in the presence of sequentially-exogenous unobserved confounders under a sensitivity model. We propose and analyze orthogonalized robust fitted-Q-iteration that uses closed-form solutions of the robust Bellman operator to derive a loss minimization problem for the robust Q function, and adds a bias-correction to quantile estimation. Our algorithm enjoys the computational ease of fitted-Q-iteration and statistical 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;A-NeSI&#30340;&#26032;&#39062;PNL&#26694;&#26550;&#65292;&#23427;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#20102;&#36817;&#20284;&#25512;&#29702;&#65292;&#33021;&#22815;&#20445;&#35777;&#27010;&#29575;&#36923;&#36753;&#35821;&#20041;&#30340;&#21516;&#26102;&#35299;&#20915;&#20102;PNL&#30340;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#65292;&#33021;&#22815;&#22312;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#20013;&#20445;&#35777;&#36923;&#36753;&#32422;&#26463;&#30340;&#28385;&#36275;&#12290;</title><link>http://arxiv.org/abs/2212.12393</link><description>&lt;p&gt;
A-NeSI: &#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#36817;&#20284;&#26041;&#27861;&#29992;&#20110;&#27010;&#29575;&#31070;&#32463;&#31526;&#21495;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
A-NeSI: A Scalable Approximate Method for Probabilistic Neurosymbolic Inference. (arXiv:2212.12393v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.12393
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;A-NeSI&#30340;&#26032;&#39062;PNL&#26694;&#26550;&#65292;&#23427;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#20102;&#36817;&#20284;&#25512;&#29702;&#65292;&#33021;&#22815;&#20445;&#35777;&#27010;&#29575;&#36923;&#36753;&#35821;&#20041;&#30340;&#21516;&#26102;&#35299;&#20915;&#20102;PNL&#30340;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#65292;&#33021;&#22815;&#22312;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#20013;&#20445;&#35777;&#36923;&#36753;&#32422;&#26463;&#30340;&#28385;&#36275;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#31070;&#32463;&#32593;&#32476;&#19982;&#31526;&#21495;&#25512;&#29702;&#30456;&#32467;&#21512;&#30340;&#38382;&#39064;&#12290;&#26368;&#36817;&#24341;&#20837;&#30340;&#27010;&#29575;&#31070;&#32463;&#31526;&#21495;&#23398;&#20064;&#65288;PNL&#65289;&#26694;&#26550;&#65292;&#22914;DeepProbLog&#65292;&#25191;&#34892;&#25351;&#25968;&#26102;&#38388;&#30340;&#31934;&#30830;&#25512;&#29702;&#65292;&#38480;&#21046;&#20102;PNL&#35299;&#20915;&#26041;&#26696;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#36817;&#20284;&#31070;&#32463;&#31526;&#21495;&#25512;&#29702;&#65288;A-NeSI&#65289;&#65306;&#19968;&#31181;&#26032;&#30340;PNL&#26694;&#26550;&#65292;&#23427;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#21487;&#25193;&#23637;&#30340;&#36817;&#20284;&#25512;&#29702;&#12290;A-NeSI 1) &#22312;&#19981;&#25913;&#21464;&#27010;&#29575;&#36923;&#36753;&#35821;&#20041;&#30340;&#24773;&#20917;&#19979;&#65292;&#20197;&#22810;&#39033;&#24335;&#26102;&#38388;&#25191;&#34892;&#36817;&#20284;&#25512;&#29702;&#65307;2) &#20351;&#29992;&#30001;&#32972;&#26223;&#30693;&#35782;&#29983;&#25104;&#30340;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#65307;3) &#21487;&#20197;&#29983;&#25104;&#26377;&#20851;&#39044;&#27979;&#30340;&#31526;&#21495;&#35299;&#37322;&#65307;4) &#21487;&#20197;&#22312;&#27979;&#35797;&#26102;&#38388;&#20445;&#35777;&#36923;&#36753;&#32422;&#26463;&#30340;&#28385;&#36275;&#65292;&#36825;&#22312;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#20013;&#38750;&#24120;&#37325;&#35201;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;A-NeSI&#26159;&#31532;&#19968;&#20010;&#33021;&#22815;&#35299;&#20915;&#20855;&#26377;&#25351;&#25968;&#32452;&#21512;&#25193;&#23637;&#30340;&#19977;&#31181;&#31070;&#32463;&#31526;&#21495;&#20219;&#21153;&#30340;&#31471;&#21040;&#31471;&#26041;&#27861;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;A-NeSI&#23454;&#29616;&#20102;&#21487;&#35299;&#37322;&#24615;&#21644;&#23433;&#20840;&#24615;&#65292;&#32780;&#27809;&#26377;&#24809;&#32602;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of combining neural networks with symbolic reasoning. Recently introduced frameworks for Probabilistic Neurosymbolic Learning (PNL), such as DeepProbLog, perform exponential-time exact inference, limiting the scalability of PNL solutions. We introduce Approximate Neurosymbolic Inference (A-NeSI): a new framework for PNL that uses neural networks for scalable approximate inference. A-NeSI 1) performs approximate inference in polynomial time without changing the semantics of probabilistic logics; 2) is trained using data generated by the background knowledge; 3) can generate symbolic explanations of predictions; and 4) can guarantee the satisfaction of logical constraints at test time, which is vital in safety-critical applications. Our experiments show that A-NeSI is the first end-to-end method to solve three neurosymbolic tasks with exponential combinatorial scaling. Finally, our experiments show that A-NeSI achieves explainability and safety without a penalty in p
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#37327;&#21270;&#39640;&#26031;&#36924;&#36817;&#30340;&#26041;&#27861;&#65292;&#30740;&#31350;&#20102;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20986;&#20998;&#24067;&#19982;&#39640;&#26031;&#36807;&#31243;&#30340;&#20108;&#27425;Wasserstein&#36317;&#31163;&#30340;&#19978;&#30028;&#65292;&#25581;&#31034;&#20102;&#38544;&#34255;&#23618;&#21644;&#36755;&#20986;&#23618;&#22823;&#23567;&#23545;&#32593;&#32476;&#39640;&#26031;&#34892;&#20026;&#30340;&#24433;&#21709;&#65292;&#24182;&#23450;&#37327;&#22320;&#24674;&#22797;&#20102;&#22312;&#23485;&#38480;&#21046;&#19979;&#30340;&#20998;&#24067;&#25910;&#25947;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2203.07379</link><description>&lt;p&gt;
&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#37327;&#21270;&#39640;&#26031;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Quantitative Gaussian Approximation of Randomly Initialized Deep Neural Networks. (arXiv:2203.07379v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.07379
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#37327;&#21270;&#39640;&#26031;&#36924;&#36817;&#30340;&#26041;&#27861;&#65292;&#30740;&#31350;&#20102;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20986;&#20998;&#24067;&#19982;&#39640;&#26031;&#36807;&#31243;&#30340;&#20108;&#27425;Wasserstein&#36317;&#31163;&#30340;&#19978;&#30028;&#65292;&#25581;&#31034;&#20102;&#38544;&#34255;&#23618;&#21644;&#36755;&#20986;&#23618;&#22823;&#23567;&#23545;&#32593;&#32476;&#39640;&#26031;&#34892;&#20026;&#30340;&#24433;&#21709;&#65292;&#24182;&#23450;&#37327;&#22320;&#24674;&#22797;&#20102;&#22312;&#23485;&#38480;&#21046;&#19979;&#30340;&#20998;&#24067;&#25910;&#25947;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#20219;&#24847;&#19968;&#20010;&#20351;&#29992;&#38543;&#26426;&#39640;&#26031;&#21442;&#25968;&#21021;&#22987;&#21270;&#30340;&#28145;&#24230;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#23545;&#20854;&#36755;&#20986;&#20998;&#24067;&#19982;&#36866;&#24403;&#30340;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#20108;&#27425;Wasserstein&#36317;&#31163;&#36827;&#34892;&#20102;&#19978;&#30028;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#26126;&#30830;&#19981;&#31561;&#24335;&#34920;&#26126;&#38544;&#34255;&#23618;&#21644;&#36755;&#20986;&#23618;&#30340;&#22823;&#23567;&#22914;&#20309;&#24433;&#21709;&#32593;&#32476;&#30340;&#39640;&#26031;&#34892;&#20026;&#65292;&#24182;&#19988;&#23450;&#37327;&#22320;&#24674;&#22797;&#20102;&#23485;&#38480;&#21046;&#19979;&#30340;&#20998;&#24067;&#25910;&#25947;&#32467;&#26524;&#65292;&#21363;&#22914;&#26524;&#25152;&#26377;&#38544;&#34255;&#23618;&#30340;&#22823;&#23567;&#21464;&#24471;&#24456;&#22823;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given any deep fully connected neural network, initialized with random Gaussian parameters, we bound from above the quadratic Wasserstein distance between its output distribution and a suitable Gaussian process. Our explicit inequalities indicate how the hidden and output layers sizes affect the Gaussian behaviour of the network and quantitatively recover the distributional convergence results in the wide limit, i.e., if all the hidden layers sizes become large.
&lt;/p&gt;</description></item></channel></rss>