<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36890;&#36807;&#28155;&#21152;&#22122;&#22768;&#21040;&#26368;&#21518;&#23618;&#30340;&#28608;&#27963;&#26469;&#20445;&#25252;&#38544;&#31169;&#65292;&#20351;&#29992;HCR&#30028;&#38480;&#21487;&#37327;&#21270;&#20445;&#25252;&#26426;&#23494;&#24615;&#30340;&#21487;&#20449;&#24230;</title><link>https://arxiv.org/abs/2404.02866</link><description>&lt;p&gt;
&#36890;&#36807;Hammersley-Chapman-Robbins&#30028;&#38480;&#20445;&#35777;&#26426;&#23494;&#24615;
&lt;/p&gt;
&lt;p&gt;
Guarantees of confidentiality via Hammersley-Chapman-Robbins bounds
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02866
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28155;&#21152;&#22122;&#22768;&#21040;&#26368;&#21518;&#23618;&#30340;&#28608;&#27963;&#26469;&#20445;&#25252;&#38544;&#31169;&#65292;&#20351;&#29992;HCR&#30028;&#38480;&#21487;&#37327;&#21270;&#20445;&#25252;&#26426;&#23494;&#24615;&#30340;&#21487;&#20449;&#24230;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25512;&#26029;&#36807;&#31243;&#20013;&#36890;&#36807;&#21521;&#26368;&#21518;&#20960;&#23618;&#30340;&#28608;&#27963;&#28155;&#21152;&#22122;&#22768;&#26469;&#20445;&#25252;&#38544;&#31169;&#26159;&#21487;&#33021;&#30340;&#12290;&#36825;&#20123;&#23618;&#20013;&#30340;&#28608;&#27963;&#34987;&#31216;&#20026;&#8220;&#29305;&#24449;&#8221;&#65288;&#23569;&#35265;&#30340;&#31216;&#20026;&#8220;&#23884;&#20837;&#8221;&#25110;&#8220;&#29305;&#24449;&#23884;&#20837;&#8221;&#65289;&#12290;&#28155;&#21152;&#30340;&#22122;&#22768;&#26377;&#21161;&#20110;&#38450;&#27490;&#20174;&#22024;&#26434;&#30340;&#29305;&#24449;&#20013;&#37325;&#24314;&#36755;&#20837;&#12290;&#36890;&#36807;&#23545;&#25152;&#26377;&#21487;&#33021;&#30340;&#26080;&#20559;&#20272;&#35745;&#37327;&#30340;&#26041;&#24046;&#36827;&#34892;&#19979;&#38480;&#20272;&#35745;&#65292;&#37327;&#21270;&#20102;&#30001;&#27492;&#28155;&#21152;&#30340;&#22122;&#22768;&#20135;&#29983;&#30340;&#26426;&#23494;&#24615;&#12290;&#32463;&#20856;&#19981;&#31561;&#24335;Hammersley&#21644;Chapman&#20197;&#21450;Robbins&#25552;&#20379;&#20415;&#21033;&#30340;&#12289;&#21487;&#35745;&#31639;&#30340;&#30028;&#38480;-- HCR&#30028;&#38480;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#23545;&#20110;&#21253;&#21547;10&#20010;&#31867;&#21035;&#30340;&#22270;&#20687;&#20998;&#31867;&#25968;&#25454;&#38598;&#8220;MNIST&#8221;&#21644;&#8220;CIFAR-10&#8221;&#65292;HCR&#30028;&#38480;&#22312;&#23567;&#22411;&#31070;&#32463;&#32593;&#32476;&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;HCR&#30028;&#38480;&#20284;&#20046;&#21333;&#29420;&#26080;&#27861;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02866v1 Announce Type: new  Abstract: Protecting privacy during inference with deep neural networks is possible by adding noise to the activations in the last layers prior to the final classifiers or other task-specific layers. The activations in such layers are known as "features" (or, less commonly, as "embeddings" or "feature embeddings"). The added noise helps prevent reconstruction of the inputs from the noisy features. Lower bounding the variance of every possible unbiased estimator of the inputs quantifies the confidentiality arising from such added noise. Convenient, computationally tractable bounds are available from classic inequalities of Hammersley and of Chapman and Robbins -- the HCR bounds. Numerical experiments indicate that the HCR bounds are on the precipice of being effectual for small neural nets with the data sets, "MNIST" and "CIFAR-10," which contain 10 classes each for image classification. The HCR bounds appear to be insufficient on their own to guar
&lt;/p&gt;</description></item><item><title>&#23637;&#31034;&#20102;&#23545;&#40784;&#30340;LLM&#23545;&#31616;&#21333;&#33258;&#36866;&#24212;&#36234;&#29425;&#25915;&#20987;&#19981;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#24182;&#25104;&#21151;&#23454;&#29616;&#20102;&#22312;&#22810;&#20010;&#27169;&#22411;&#19978;&#20960;&#20046;100%&#30340;&#25915;&#20987;&#25104;&#21151;&#29575;&#65292;&#21516;&#26102;&#36824;&#20171;&#32461;&#20102;&#23545;&#20110;&#19981;&#20844;&#24320;logprobs&#30340;&#27169;&#22411;&#22914;&#20309;&#36827;&#34892;&#36234;&#29425;&#20197;&#21450;&#22914;&#20309;&#22312;&#21463;&#27745;&#26579;&#30340;&#27169;&#22411;&#20013;&#26597;&#25214;&#26408;&#39532;&#23383;&#31526;&#20018;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2404.02151</link><description>&lt;p&gt;
&#29992;&#31616;&#21333;&#33258;&#36866;&#24212;&#25915;&#20987;&#36234;&#29425;&#21151;&#33021;&#23545;&#40784;&#30340;LLM
&lt;/p&gt;
&lt;p&gt;
Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02151
&lt;/p&gt;
&lt;p&gt;
&#23637;&#31034;&#20102;&#23545;&#40784;&#30340;LLM&#23545;&#31616;&#21333;&#33258;&#36866;&#24212;&#36234;&#29425;&#25915;&#20987;&#19981;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#24182;&#25104;&#21151;&#23454;&#29616;&#20102;&#22312;&#22810;&#20010;&#27169;&#22411;&#19978;&#20960;&#20046;100%&#30340;&#25915;&#20987;&#25104;&#21151;&#29575;&#65292;&#21516;&#26102;&#36824;&#20171;&#32461;&#20102;&#23545;&#20110;&#19981;&#20844;&#24320;logprobs&#30340;&#27169;&#22411;&#22914;&#20309;&#36827;&#34892;&#36234;&#29425;&#20197;&#21450;&#22914;&#20309;&#22312;&#21463;&#27745;&#26579;&#30340;&#27169;&#22411;&#20013;&#26597;&#25214;&#26408;&#39532;&#23383;&#31526;&#20018;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#21363;&#20351;&#26159;&#26368;&#26032;&#30340;&#23433;&#20840;&#23545;&#40784;&#30340;LLM&#20063;&#19981;&#20855;&#26377;&#25269;&#25239;&#31616;&#21333;&#33258;&#36866;&#24212;&#36234;&#29425;&#25915;&#20987;&#30340;&#31283;&#20581;&#24615;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#25104;&#21151;&#21033;&#29992;&#23545;logprobs&#30340;&#35775;&#38382;&#36827;&#34892;&#36234;&#29425;&#65306;&#25105;&#20204;&#26368;&#21021;&#35774;&#35745;&#20102;&#19968;&#20010;&#23545;&#25239;&#24615;&#25552;&#31034;&#27169;&#26495;&#65288;&#26377;&#26102;&#20250;&#36866;&#24212;&#30446;&#26631;LLM&#65289;&#65292;&#28982;&#21518;&#25105;&#20204;&#22312;&#21518;&#32512;&#19978;&#24212;&#29992;&#38543;&#26426;&#25628;&#32034;&#20197;&#26368;&#22823;&#21270;&#30446;&#26631;logprob&#65288;&#20363;&#22914;token&#8220;Sure&#8221;&#65289;&#65292;&#21487;&#33021;&#20250;&#36827;&#34892;&#22810;&#27425;&#37325;&#21551;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#23545;GPT-3.5/4&#12289;Llama-2-Chat-7B/13B/70B&#12289;Gemma-7B&#21644;&#38024;&#23545;GCG&#25915;&#20987;&#36827;&#34892;&#23545;&#25239;&#35757;&#32451;&#30340;HarmBench&#19978;&#30340;R2D2&#31561;&#20960;&#20046;100%&#30340;&#25915;&#20987;&#25104;&#21151;&#29575;--&#26681;&#25454;GPT-4&#30340;&#35780;&#21028;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#36716;&#31227;&#25110;&#39044;&#22635;&#20805;&#25915;&#20987;&#20197;100%&#30340;&#25104;&#21151;&#29575;&#23545;&#25152;&#26377;&#19981;&#26292;&#38706;logprobs&#30340;Claude&#27169;&#22411;&#36827;&#34892;&#36234;&#29425;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#21463;&#27745;&#26579;&#30340;&#27169;&#22411;&#20013;&#20351;&#29992;&#23545;&#19968;&#32452;&#21463;&#38480;&#21046;&#30340;token&#25191;&#34892;&#38543;&#26426;&#25628;&#32034;&#20197;&#26597;&#25214;&#26408;&#39532;&#23383;&#31526;&#20018;&#30340;&#26041;&#27861;--&#36825;&#39033;&#20219;&#21153;&#19982;&#35768;&#22810;&#20854;&#20182;&#20219;&#21153;&#20849;&#20139;&#30456;&#21516;&#30340;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02151v1 Announce Type: cross  Abstract: We show that even the most recent safety-aligned LLMs are not robust to simple adaptive jailbreaking attacks. First, we demonstrate how to successfully leverage access to logprobs for jailbreaking: we initially design an adversarial prompt template (sometimes adapted to the target LLM), and then we apply random search on a suffix to maximize the target logprob (e.g., of the token "Sure"), potentially with multiple restarts. In this way, we achieve nearly 100\% attack success rate -- according to GPT-4 as a judge -- on GPT-3.5/4, Llama-2-Chat-7B/13B/70B, Gemma-7B, and R2D2 from HarmBench that was adversarially trained against the GCG attack. We also show how to jailbreak all Claude models -- that do not expose logprobs -- via either a transfer or prefilling attack with 100\% success rate. In addition, we show how to use random search on a restricted set of tokens for finding trojan strings in poisoned models -- a task that shares many s
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30417;&#30563;&#22411;&#33258;&#32534;&#30721;&#22120;&#30340;&#20351;&#29992;&#21644;&#21442;&#25968;&#35843;&#25972;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#21319;&#37329;&#34701;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#25928;&#26524;&#65292;&#23545;&#25237;&#36164;&#31574;&#30053;&#24615;&#33021;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2404.01866</link><description>&lt;p&gt;
&#30417;&#30563;&#22411;&#33258;&#32534;&#30721;&#22120;&#22810;&#23618;&#24863;&#30693;&#26426;&#29992;&#20110;&#37329;&#34701;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Supervised Autoencoder MLP for Financial Time Series Forecasting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01866
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30417;&#30563;&#22411;&#33258;&#32534;&#30721;&#22120;&#30340;&#20351;&#29992;&#21644;&#21442;&#25968;&#35843;&#25972;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#21319;&#37329;&#34701;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#25928;&#26524;&#65292;&#23545;&#25237;&#36164;&#31574;&#30053;&#24615;&#33021;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#36890;&#36807;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#30417;&#30563;&#22411;&#33258;&#32534;&#30721;&#22120;&#26469;&#22686;&#24378;&#37329;&#34701;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#65292;&#26088;&#22312;&#25913;&#21892;&#25237;&#36164;&#31574;&#30053;&#34920;&#29616;&#12290;&#20855;&#20307;&#30740;&#31350;&#20102;&#22122;&#22768;&#22686;&#24378;&#21644;&#19977;&#37325;&#38556;&#30861;&#26631;&#35760;&#23545;&#39118;&#38505;&#35843;&#25972;&#22238;&#25253;&#30340;&#24433;&#21709;&#65292;&#20351;&#29992;&#22799;&#26222;&#27604;&#29575;&#21644;&#20449;&#24687;&#27604;&#29575;&#12290;&#30740;&#31350;&#37325;&#28857;&#20851;&#27880;&#20102;&#20174;2010&#24180;1&#26376;1&#26085;&#33267;2022&#24180;4&#26376;30&#26085;&#26399;&#38388;&#20316;&#20026;&#20132;&#26131;&#36164;&#20135;&#30340;&#26631;&#26222;500&#25351;&#25968;&#65292;EUR/USD&#21644;BTC/USD&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#20855;&#26377;&#24179;&#34913;&#22122;&#22768;&#22686;&#24378;&#21644;&#29942;&#39048;&#22823;&#23567;&#30340;&#30417;&#30563;&#22411;&#33258;&#32534;&#30721;&#22120;&#26174;&#33879;&#25552;&#21319;&#20102;&#31574;&#30053;&#25928;&#26524;&#12290;&#28982;&#32780;&#65292;&#36807;&#22810;&#30340;&#22122;&#22768;&#21644;&#22823;&#30340;&#29942;&#39048;&#22823;&#23567;&#21487;&#33021;&#20250;&#25439;&#23475;&#34920;&#29616;&#65292;&#31361;&#20986;&#20102;&#31934;&#30830;&#21442;&#25968;&#35843;&#25972;&#30340;&#37325;&#35201;&#24615;&#12290;&#26412;&#25991;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20248;&#21270;&#25351;&#26631;&#30340;&#25512;&#23548;&#65292;&#21487;&#19982;&#19977;&#37325;&#38556;&#30861;&#26631;&#35760;&#19968;&#36215;&#20351;&#29992;&#12290;&#36825;&#39033;&#30740;&#31350;&#30340;&#32467;&#26524;&#23545;&#25919;&#31574;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#26263;&#31034;&#37329;&#34701;&#24066;&#22330;&#39044;&#27979;&#24037;&#20855;&#30340;&#25345;&#32493;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01866v1 Announce Type: new  Abstract: This paper investigates the enhancement of financial time series forecasting with the use of neural networks through supervised autoencoders, aiming to improve investment strategy performance. It specifically examines the impact of noise augmentation and triple barrier labeling on risk-adjusted returns, using the Sharpe and Information Ratios. The study focuses on the S&amp;P 500 index, EUR/USD, and BTC/USD as the traded assets from January 1, 2010, to April 30, 2022. Findings indicate that supervised autoencoders, with balanced noise augmentation and bottleneck size, significantly boost strategy effectiveness. However, excessive noise and large bottleneck sizes can impair performance, highlighting the importance of precise parameter tuning. This paper also presents a derivation of a novel optimization metric that can be used with triple barrier labeling. The results of this study have substantial policy implications, suggesting that financi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#25237;&#24433;&#26041;&#24046;&#23545;&#39640;&#26031;&#36807;&#31243;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#20197;&#21450;&#38598;&#25104;&#20102;&#35889;&#28151;&#21512;&#65288;SM&#65289;&#26680;&#21644;&#21487;&#24494;&#38543;&#26426;&#20613;&#31435;&#21494;&#29305;&#24449;&#65288;RFF&#65289;&#26680;&#36924;&#36817;&#26469;&#35299;&#20915;&#26680;&#28789;&#27963;&#24615;&#19981;&#36275;&#38382;&#39064;&#65292;&#20174;&#32780;&#38450;&#27490;&#27169;&#22411;&#23849;&#28291;&#12290;</title><link>https://arxiv.org/abs/2404.01697</link><description>&lt;p&gt;
&#38450;&#27490;&#39640;&#26031;&#36807;&#31243;&#28508;&#21464;&#37327;&#27169;&#22411;&#20013;&#30340;&#27169;&#22411;&#23849;&#28291;
&lt;/p&gt;
&lt;p&gt;
Preventing Model Collapse in Gaussian Process Latent Variable Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01697
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#25237;&#24433;&#26041;&#24046;&#23545;&#39640;&#26031;&#36807;&#31243;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#20197;&#21450;&#38598;&#25104;&#20102;&#35889;&#28151;&#21512;&#65288;SM&#65289;&#26680;&#21644;&#21487;&#24494;&#38543;&#26426;&#20613;&#31435;&#21494;&#29305;&#24449;&#65288;RFF&#65289;&#26680;&#36924;&#36817;&#26469;&#35299;&#20915;&#26680;&#28789;&#27963;&#24615;&#19981;&#36275;&#38382;&#39064;&#65292;&#20174;&#32780;&#38450;&#27490;&#27169;&#22411;&#23849;&#28291;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Gaussian process latent variable models (GPLVMs)&#26159;&#19968;&#31867;&#22810;&#25165;&#22810;&#33402;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#65292;&#36890;&#24120;&#29992;&#20110;&#38477;&#32500;&#12290;&#28982;&#32780;&#65292;&#29992;GPLVMs&#23545;&#25968;&#25454;&#24314;&#27169;&#26102;&#24120;&#35265;&#30340;&#25361;&#25112;&#21253;&#25324;&#26680;&#28789;&#27963;&#24615;&#19981;&#36275;&#21644;&#25237;&#24433;&#22122;&#22768;&#36873;&#25321;&#19981;&#24403;&#65292;&#23548;&#33268;&#20102;&#19968;&#31181;&#20197;&#27169;&#31946;&#28508;&#21464;&#37327;&#34920;&#31034;&#20026;&#20027;&#35201;&#29305;&#24449;&#30340;&#27169;&#22411;&#23849;&#28291;&#65292;&#36825;&#31181;&#34920;&#31034;&#19981;&#21453;&#26144;&#25968;&#25454;&#30340;&#28508;&#22312;&#32467;&#26500;&#12290;&#26412;&#25991;&#39318;&#20808;&#20174;&#29702;&#35770;&#19978;&#36890;&#36807;&#32447;&#24615;GPLVM&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#25237;&#24433;&#26041;&#24046;&#23545;&#27169;&#22411;&#23849;&#28291;&#30340;&#24433;&#21709;&#12290;&#20854;&#27425;&#65292;&#36890;&#36807;&#38598;&#25104;&#35889;&#28151;&#21512;&#65288;SM&#65289;&#26680;&#21644;&#21487;&#24494;&#38543;&#26426;&#20613;&#31435;&#21494;&#29305;&#24449;&#65288;RFF&#65289;&#26680;&#36924;&#36817;&#65292;&#35299;&#20915;&#20102;&#30001;&#20110;&#26680;&#28789;&#27963;&#24615;&#19981;&#36275;&#23548;&#33268;&#30340;&#27169;&#22411;&#23849;&#28291;&#38382;&#39064;&#65292;&#20174;&#32780;&#20445;&#35777;&#20102;&#36890;&#36807;&#29616;&#25104;&#30340;&#33258;&#21160;&#24494;&#20998;&#24037;&#20855;&#23454;&#29616;&#23398;&#20064;&#26680;&#21442;&#25968;&#30340;&#35745;&#31639;&#21487;&#25193;&#23637;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01697v1 Announce Type: cross  Abstract: Gaussian process latent variable models (GPLVMs) are a versatile family of unsupervised learning models, commonly used for dimensionality reduction. However, common challenges in modeling data with GPLVMs include inadequate kernel flexibility and improper selection of the projection noise, which leads to a type of model collapse characterized primarily by vague latent representations that do not reflect the underlying structure of the data. This paper addresses these issues by, first, theoretically examining the impact of the projection variance on model collapse through the lens of a linear GPLVM. Second, we address the problem of model collapse due to inadequate kernel flexibility by integrating the spectral mixture (SM) kernel and a differentiable random Fourier feature (RFF) kernel approximation, which ensures computational scalability and efficiency through off-the-shelf automatic differentiation tools for learning the kernel hype
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;Lie&#32676;&#30340;&#21160;&#21147;&#23398;Langevin Monte Carlo&#37319;&#26679;&#31639;&#27861;&#65292;&#36890;&#36807;&#28155;&#21152;&#22122;&#22768;&#21644;&#31934;&#32454;&#31163;&#25955;&#21270;&#23454;&#29616;&#20102;Lie&#32676;&#32467;&#26500;&#30340;&#20445;&#25345;&#65292;&#24182;&#22312;W2&#36317;&#31163;&#19979;&#35777;&#26126;&#20102;&#36830;&#32493;&#21160;&#21147;&#23398;&#21644;&#31163;&#25955;&#37319;&#26679;&#22120;&#30340;&#25351;&#25968;&#25910;&#25947;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.12012</link><description>&lt;p&gt;
&#22522;&#20110;Lie&#32676;&#30340;&#21160;&#21147;&#23398;Langevin Monte Carlo&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Convergence of Kinetic Langevin Monte Carlo on Lie groups
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12012
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;Lie&#32676;&#30340;&#21160;&#21147;&#23398;Langevin Monte Carlo&#37319;&#26679;&#31639;&#27861;&#65292;&#36890;&#36807;&#28155;&#21152;&#22122;&#22768;&#21644;&#31934;&#32454;&#31163;&#25955;&#21270;&#23454;&#29616;&#20102;Lie&#32676;&#32467;&#26500;&#30340;&#20445;&#25345;&#65292;&#24182;&#22312;W2&#36317;&#31163;&#19979;&#35777;&#26126;&#20102;&#36830;&#32493;&#21160;&#21147;&#23398;&#21644;&#31163;&#25955;&#37319;&#26679;&#22120;&#30340;&#25351;&#25968;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22522;&#20110;&#21464;&#20998;&#20248;&#21270;&#21644;&#24038;&#24179;&#20961;&#21270;&#31561;&#25216;&#26415;&#26500;&#24314;&#20102;&#19968;&#20010;&#26126;&#30830;&#30340;&#12289;&#22522;&#20110;&#21160;&#37327;&#30340;&#21160;&#21147;&#23398;&#31995;&#32479;&#65292;&#29992;&#20110;&#20248;&#21270;&#23450;&#20041;&#22312;Lie&#32676;&#19978;&#30340;&#20989;&#25968;&#12290;&#25105;&#20204;&#36866;&#24403;&#22320;&#20026;&#20248;&#21270;&#21160;&#21147;&#23398;&#28155;&#21152;&#21487;&#22788;&#29702;&#30340;&#22122;&#22768;&#65292;&#23558;&#20854;&#36716;&#21270;&#20026;&#37319;&#26679;&#21160;&#21147;&#23398;&#65292;&#21033;&#29992;&#21160;&#37327;&#21464;&#37327;&#26159;&#27431;&#20960;&#37324;&#24471;&#30340;&#36825;&#19968;&#26377;&#21033;&#29305;&#24615;&#65292;&#23613;&#31649;&#28508;&#22312;&#20989;&#25968;&#23384;&#22312;&#20110;&#27969;&#24418;&#19978;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#31934;&#24515;&#31163;&#25955;&#21270;&#23548;&#33268;&#30340;&#21160;&#21147;&#23398;&#37319;&#26679;&#21160;&#21147;&#23398;&#25552;&#20986;&#20102;&#19968;&#20010;Lie&#32676;MCMC&#37319;&#26679;&#22120;&#12290;&#36825;&#31181;&#31163;&#25955;&#21270;&#23436;&#20840;&#20445;&#25345;&#20102;Lie&#32676;&#32467;&#26500;&#12290;&#22312;W2&#36317;&#31163;&#19979;&#65292;&#20998;&#21035;&#23545;&#36830;&#32493;&#21160;&#21147;&#23398;&#21644;&#31163;&#25955;&#37319;&#26679;&#22120;&#35777;&#26126;&#20102;&#25351;&#25968;&#25910;&#25947;&#24615;&#65292;&#20854;&#20013;&#21482;&#38656;&#35201;Lie&#32676;&#30340;&#32039;&#33268;&#24615;&#21644;&#28508;&#22312;&#20989;&#25968;&#30340;&#27979;&#22320;L-&#20809;&#28369;&#24615;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#23545;&#21160;&#21147;&#23398;Langevin&#31639;&#27861;&#30340;&#31532;&#19968;&#20010;&#25910;&#25947;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12012v1 Announce Type: cross  Abstract: Explicit, momentum-based dynamics for optimizing functions defined on Lie groups was recently constructed, based on techniques such as variational optimization and left trivialization. We appropriately add tractable noise to the optimization dynamics to turn it into a sampling dynamics, leveraging the advantageous feature that the momentum variable is Euclidean despite that the potential function lives on a manifold. We then propose a Lie-group MCMC sampler, by delicately discretizing the resulting kinetic-Langevin-type sampling dynamics. The Lie group structure is exactly preserved by this discretization. Exponential convergence with explicit convergence rate for both the continuous dynamics and the discrete sampler are then proved under W2 distance. Only compactness of the Lie group and geodesically L-smoothness of the potential function are needed. To the best of our knowledge, this is the first convergence result for kinetic Langev
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#23398;&#21040;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#34920;&#31034;&#36981;&#24490;&#39640;&#26031;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#20174;&#32780;&#21551;&#29992;&#35268;&#21010;&#21644;&#25512;&#26029;</title><link>https://arxiv.org/abs/2403.04082</link><description>&lt;p&gt;
&#36890;&#36807;&#25554;&#20540;&#36827;&#34892;&#25512;&#26029;&#65306;&#23545;&#27604;&#34920;&#31034;&#21487;&#35777;&#26126;&#21551;&#29992;&#35268;&#21010;&#21644;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Inference via Interpolation: Contrastive Representations Provably Enable Planning and Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04082
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#23398;&#21040;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#34920;&#31034;&#36981;&#24490;&#39640;&#26031;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#20174;&#32780;&#21551;&#29992;&#35268;&#21010;&#21644;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32473;&#23450;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#25105;&#20204;&#22914;&#20309;&#22238;&#31572;&#35832;&#22914;&#8220;&#26410;&#26469;&#20250;&#21457;&#29983;&#20160;&#20040;&#65311;&#8221;&#21644;&#8220;&#25105;&#20204;&#26159;&#22914;&#20309;&#21040;&#36798;&#36825;&#37324;&#30340;&#65311;&#8221;&#36825;&#31867;&#27010;&#29575;&#25512;&#26029;&#38382;&#39064;&#22312;&#35266;&#27979;&#20540;&#20026;&#39640;&#32500;&#26102;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;&#36825;&#20123;&#38382;&#39064;&#22914;&#20309;&#36890;&#36807;&#23398;&#20064;&#34920;&#31034;&#30340;&#32039;&#20945;&#38381;&#24335;&#35299;&#20915;&#26041;&#26696;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#23558;&#23545;&#27604;&#23398;&#20064;&#30340;&#21464;&#20307;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#12290;&#20043;&#21069;&#30340;&#24037;&#20316;&#24050;&#32463;&#34920;&#26126;&#65292;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#23398;&#21040;&#30340;&#34920;&#31034;&#32534;&#30721;&#20102;&#27010;&#29575;&#27604;&#12290;&#36890;&#36807;&#23558;&#20043;&#21069;&#30340;&#24037;&#20316;&#25193;&#23637;&#20197;&#34920;&#26126;&#34920;&#31034;&#30340;&#36793;&#38469;&#20998;&#24067;&#26159;&#39640;&#26031;&#20998;&#24067;&#65292;&#25105;&#20204;&#38543;&#21518;&#35777;&#26126;&#34920;&#31034;&#30340;&#32852;&#21512;&#20998;&#24067;&#20063;&#26159;&#39640;&#26031;&#20998;&#24067;&#12290;&#36825;&#20123;&#32467;&#26524;&#20849;&#21516;&#34920;&#26126;&#65292;&#36890;&#36807;&#26102;&#38388;&#23545;&#27604;&#23398;&#20064;&#23398;&#21040;&#30340;&#34920;&#31034;&#36981;&#24490;&#39640;&#26031;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#19968;&#31181;&#22270;&#24418;&#27169;&#22411;&#65292;&#20854;&#20013;&#23545;&#34920;&#31034;&#36827;&#34892;&#30340;&#25512;&#26029;&#65288;&#20363;&#22914;&#39044;&#27979;&#12289;&#35268;&#21010;&#65289;&#23545;&#24212;&#20110;&#21453;&#28436;&#20302;&#32500;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04082v1 Announce Type: new  Abstract: Given time series data, how can we answer questions like "what will happen in the future?" and "how did we get here?" These sorts of probabilistic inference questions are challenging when observations are high-dimensional. In this paper, we show how these questions can have compact, closed form solutions in terms of learned representations. The key idea is to apply a variant of contrastive learning to time series data. Prior work already shows that the representations learned by contrastive learning encode a probability ratio. By extending prior work to show that the marginal distribution over representations is Gaussian, we can then prove that joint distribution of representations is also Gaussian. Taken together, these results show that representations learned via temporal contrastive learning follow a Gauss-Markov chain, a graphical model where inference (e.g., prediction, planning) over representations corresponds to inverting a low-
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#32447;&#24615;&#22238;&#24402;&#20219;&#21153;&#30340;&#23454;&#39564;&#30740;&#31350;&#20102;Transformer&#22312;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#20013;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#33021;&#21147;&#65292;&#24182;&#35299;&#37322;&#20102;&#20854;&#20013;&#30340;&#20851;&#38190;&#32452;&#20214;&#12290;</title><link>https://arxiv.org/abs/2402.00743</link><description>&lt;p&gt;
Transformer&#30340;&#22909;&#22788;&#65306;&#22312;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#30340;&#32447;&#24615;&#22238;&#24402;&#20219;&#21153;&#20013;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Benefits of Transformer: In-Context Learning in Linear Regression Tasks with Unstructured Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00743
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#32447;&#24615;&#22238;&#24402;&#20219;&#21153;&#30340;&#23454;&#39564;&#30740;&#31350;&#20102;Transformer&#22312;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#20013;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#33021;&#21147;&#65292;&#24182;&#35299;&#37322;&#20102;&#20854;&#20013;&#30340;&#20851;&#38190;&#32452;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#36341;&#20013;&#35266;&#23519;&#21040;&#65292;&#22522;&#20110;Transformer&#30340;&#27169;&#22411;&#22312;&#25512;&#29702;&#38454;&#27573;&#33021;&#22815;&#23398;&#20064;&#19978;&#19979;&#25991;&#20013;&#30340;&#27010;&#24565;&#12290;&#29616;&#26377;&#30340;&#25991;&#29486;&#65292;&#20363;&#22914;\citet{zhang2023trained,huang2023context}&#23545;&#36825;&#31181;&#19978;&#19979;&#25991;&#23398;&#20064;&#33021;&#21147;&#25552;&#20379;&#20102;&#29702;&#35770;&#35299;&#37322;&#65292;&#20294;&#26159;&#20182;&#20204;&#20551;&#35774;&#27599;&#20010;&#26679;&#26412;&#30340;&#36755;&#20837;$x_i$&#21644;&#36755;&#20986;$y_i$&#37117;&#34987;&#23884;&#20837;&#21040;&#30456;&#21516;&#30340;&#20196;&#29260;&#20013;&#65288;&#21363;&#32467;&#26500;&#21270;&#25968;&#25454;&#65289;&#12290;&#28982;&#32780;&#65292;&#22312;&#29616;&#23454;&#20013;&#65292;&#23427;&#20204;&#21576;&#29616;&#20026;&#20004;&#20010;&#20196;&#29260;&#65288;&#21363;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;\cite{wibisono2023role}&#65289;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26412;&#25991;&#36827;&#34892;&#20102;&#32447;&#24615;&#22238;&#24402;&#20219;&#21153;&#30340;&#23454;&#39564;&#65292;&#30740;&#31350;&#20102;Transformer&#26550;&#26500;&#30340;&#22909;&#22788;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20123;&#30456;&#24212;&#30340;&#29702;&#35770;&#30452;&#35273;&#65292;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;Transformer&#21487;&#20197;&#20174;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#20013;&#23398;&#20064;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;Transformer&#20013;&#36215;&#21040;&#19978;&#19979;&#25991;&#23398;&#20064;&#20316;&#29992;&#30340;&#30830;&#20999;&#32452;&#20214;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#65288;1&#65289;&#24102;&#26377;&#20004;&#23618;softmax&#65288;&#33258;&#25105;&#65289;&#27880;&#24847;&#21147;&#21644;&#21069;&#30651;&#24615;&#27880;&#24847;&#21147;&#25513;&#30721;&#30340;Transformer&#21487;&#20197;&#20174;&#25552;&#31034;&#20013;&#23398;&#20064;&#65292;&#22914;&#26524;$y_i$&#22312;&#20196;&#29260;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
In practice, it is observed that transformer-based models can learn concepts in context in the inference stage. While existing literature, e.g., \citet{zhang2023trained,huang2023context}, provide theoretical explanations on this in-context learning ability, they assume the input $x_i$ and the output $y_i$ for each sample are embedded in the same token (i.e., structured data). However, in reality, they are presented in two tokens (i.e., unstructured data \cite{wibisono2023role}). In this case, this paper conducts experiments in linear regression tasks to study the benefits of the architecture of transformers and provides some corresponding theoretical intuitions to explain why the transformer can learn from unstructured data. We study the exact components in a transformer that facilitate the in-context learning. In particular, we observe that (1) a transformer with two layers of softmax (self-)attentions with look-ahead attention mask can learn from the prompt if $y_i$ is in the token n
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#24212;&#29992;&#20110;&#20020;&#24202;&#35797;&#39564;&#32467;&#26524;&#39044;&#27979;&#65292;&#25552;&#39640;&#27169;&#22411;&#23545;&#24494;&#22937;&#24046;&#24322;&#30340;&#35782;&#21035;&#33021;&#21147;&#65292;&#20174;&#32780;&#25913;&#21892;&#20854;&#25972;&#20307;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.03482</link><description>&lt;p&gt;
&#20020;&#24202;&#35797;&#39564;&#32467;&#26524;&#39044;&#27979;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Uncertainty Quantification on Clinical Trial Outcome Prediction. (arXiv:2401.03482v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03482
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#24212;&#29992;&#20110;&#20020;&#24202;&#35797;&#39564;&#32467;&#26524;&#39044;&#27979;&#65292;&#25552;&#39640;&#27169;&#22411;&#23545;&#24494;&#22937;&#24046;&#24322;&#30340;&#35782;&#21035;&#33021;&#21147;&#65292;&#20174;&#32780;&#25913;&#21892;&#20854;&#25972;&#20307;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#22312;&#26426;&#22120;&#23398;&#20064;&#30340;&#19981;&#21516;&#39046;&#22495;&#20013;&#30340;&#37325;&#35201;&#24615;&#26085;&#30410;&#34987;&#35748;&#35782;&#21040;&#12290;&#20934;&#30830;&#35780;&#20272;&#27169;&#22411;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#21487;&#20197;&#24110;&#21161;&#30740;&#31350;&#20154;&#21592;&#21644;&#20174;&#19994;&#20154;&#21592;&#26356;&#28145;&#20837;&#22320;&#29702;&#35299;&#21644;&#22686;&#21152;&#20449;&#24515;&#12290;&#36825;&#22312;&#21307;&#23398;&#35786;&#26029;&#21644;&#33647;&#29289;&#21457;&#29616;&#39046;&#22495;&#23588;&#20026;&#37325;&#35201;&#65292;&#22240;&#20026;&#21487;&#38752;&#30340;&#39044;&#27979;&#30452;&#25509;&#24433;&#21709;&#30740;&#31350;&#36136;&#37327;&#21644;&#24739;&#32773;&#20581;&#24247;&#12290;&#26412;&#25991;&#25552;&#20986;&#23558;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#32435;&#20837;&#20020;&#24202;&#35797;&#39564;&#32467;&#26524;&#39044;&#27979;&#20013;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#25552;&#39640;&#27169;&#22411;&#36776;&#21035;&#24494;&#22937;&#24046;&#24322;&#30340;&#33021;&#21147;&#65292;&#20174;&#32780;&#26174;&#33879;&#25913;&#21892;&#20854;&#25972;&#20307;&#24615;&#33021;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#19968;&#31181;&#36873;&#25321;&#24615;&#20998;&#31867;&#26041;&#27861;&#26469;&#23454;&#29616;&#25105;&#20204;&#30340;&#30446;&#26631;&#65292;&#24182;&#23558;&#20854;&#19982;&#23618;&#27425;&#20132;&#20114;&#32593;&#32476;(HINT)&#26080;&#32541;&#38598;&#25104;&#65292;HINT&#26159;&#20020;&#24202;&#35797;&#39564;&#39044;&#27979;&#24314;&#27169;&#30340;&#26368;&#21069;&#27839;&#12290;&#36873;&#25321;&#24615;&#20998;&#31867;&#28085;&#30422;&#20102;&#19968;&#31995;&#21015;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#20445;&#30041;&#20449;&#24687;&#20197;&#20379;&#36827;&#19968;&#27493;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
The importance of uncertainty quantification is increasingly recognized in the diverse field of machine learning. Accurately assessing model prediction uncertainty can help provide deeper understanding and confidence for researchers and practitioners. This is especially critical in medical diagnosis and drug discovery areas, where reliable predictions directly impact research quality and patient health.  In this paper, we proposed incorporating uncertainty quantification into clinical trial outcome predictions. Our main goal is to enhance the model's ability to discern nuanced differences, thereby significantly improving its overall performance.  We have adopted a selective classification approach to fulfill our objective, integrating it seamlessly with the Hierarchical Interaction Network (HINT), which is at the forefront of clinical trial prediction modeling. Selective classification, encompassing a spectrum of methods for uncertainty quantification, empowers the model to withhold de
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#24102;&#26377;&#22266;&#26377;&#22122;&#22768;&#21644;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#30340;&#38543;&#26426;&#35745;&#31639;&#27169;&#22411;&#30340;&#22810;&#39033;&#24335;&#28151;&#27788;&#20195;&#29702;&#26500;&#24314;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2311.00553</link><description>&lt;p&gt;
&#38024;&#23545;&#24102;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#30340;&#38543;&#26426;&#22330;&#30340;&#22810;&#39033;&#24335;&#28151;&#27788;&#20195;&#29702;&#26500;&#24314;
&lt;/p&gt;
&lt;p&gt;
Polynomial Chaos Surrogate Construction for Random Fields with Parametric Uncertainty. (arXiv:2311.00553v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00553
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#24102;&#26377;&#22266;&#26377;&#22122;&#22768;&#21644;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#30340;&#38543;&#26426;&#35745;&#31639;&#27169;&#22411;&#30340;&#22810;&#39033;&#24335;&#28151;&#27788;&#20195;&#29702;&#26500;&#24314;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24037;&#31243;&#21644;&#24212;&#29992;&#31185;&#23398;&#20381;&#38752;&#35745;&#31639;&#23454;&#39564;&#26469;&#20005;&#35880;&#22320;&#30740;&#31350;&#29289;&#29702;&#31995;&#32479;&#12290;&#29992;&#20110;&#25506;&#31350;&#36825;&#20123;&#31995;&#32479;&#30340;&#25968;&#23398;&#27169;&#22411;&#38750;&#24120;&#22797;&#26434;&#65292;&#32780;&#19988;&#37319;&#26679;&#23494;&#38598;&#30340;&#30740;&#31350;&#36890;&#24120;&#38656;&#35201;&#22823;&#37327;&#27169;&#25311;&#20197;&#33719;&#24471;&#21487;&#25509;&#21463;&#30340;&#20934;&#30830;&#24615;&#12290;&#20195;&#29702;&#27169;&#22411;&#20026;&#36991;&#20813;&#37319;&#26679;&#36825;&#20123;&#22797;&#26434;&#27169;&#22411;&#30340;&#39640;&#35745;&#31639;&#24320;&#38144;&#25552;&#20379;&#20102;&#19968;&#31181;&#26041;&#27861;&#12290;&#23588;&#20854;&#26159;&#65292;&#22312;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#20026;&#20027;&#35201;&#19981;&#30830;&#23450;&#22240;&#32032;&#30340;&#30830;&#23450;&#24615;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30740;&#31350;&#20013;&#65292;&#22810;&#39033;&#24335;&#28151;&#27788;&#23637;&#24320;&#65288;PCEs&#65289;&#24050;&#32463;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#19968;&#31181;&#23545;&#20256;&#32479;&#30340;PCE&#20195;&#29702;&#27169;&#22411;&#30340;&#25193;&#23637;&#65292;&#20197;&#23454;&#29616;&#23545;&#20855;&#26377;&#22266;&#26377;&#22122;&#22768;&#21644;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#30340;&#38543;&#26426;&#35745;&#31639;&#27169;&#22411;&#30340;&#20195;&#29702;&#26500;&#24314;&#12290;&#25105;&#20204;&#36890;&#36807;Rosenblatt&#21464;&#25442;&#22312;&#22266;&#26377;&#21644;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#30340;&#32852;&#21512;&#31354;&#38388;&#19978;&#24320;&#21457;&#20102;&#19968;&#20010;PCE&#20195;&#29702;&#65292;&#28982;&#21518;&#36890;&#36807;Karhunen-Loeve&#23637;&#24320;&#23558;&#20854;&#25193;&#23637;&#21040;&#38543;&#26426;&#22330;&#25968;&#25454;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
Engineering and applied science rely on computational experiments to rigorously study physical systems. The mathematical models used to probe these systems are highly complex, and sampling-intensive studies often require prohibitively many simulations for acceptable accuracy. Surrogate models provide a means of circumventing the high computational expense of sampling such complex models. In particular, polynomial chaos expansions (PCEs) have been successfully used for uncertainty quantification studies of deterministic models where the dominant source of uncertainty is parametric. We discuss an extension to conventional PCE surrogate modeling to enable surrogate construction for stochastic computational models that have intrinsic noise in addition to parametric uncertainty. We develop a PCE surrogate on a joint space of intrinsic and parametric uncertainty, enabled by Rosenblatt transformations, and then extend the construction to random field data via the Karhunen-Loeve expansion. We 
&lt;/p&gt;</description></item><item><title>&#23545;&#20110;$p$-&#33539;&#25968;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#19978;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#21487;&#23454;&#29616;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;$O(d)$&#20010;&#26679;&#26412;&#23601;&#36275;&#22815;&#31934;&#30830;&#22320;&#24674;&#22797;&#30446;&#26631;&#20540;&#65292;&#24182;&#19988;&#22312;&#20854;&#20182;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#30340;&#39640;&#27010;&#29575;&#36229;&#20986;&#39118;&#38505;&#30028;&#12290;</title><link>http://arxiv.org/abs/2310.12437</link><description>&lt;p&gt;
&#22312;$p$-&#33539;&#25968;&#32447;&#24615;&#22238;&#24402;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#20013;&#30340;&#26368;&#20248;&#36229;&#20986;&#39118;&#38505;&#30028;
&lt;/p&gt;
&lt;p&gt;
Optimal Excess Risk Bounds for Empirical Risk Minimization on $p$-norm Linear Regression. (arXiv:2310.12437v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12437
&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;$p$-&#33539;&#25968;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#19978;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#21487;&#23454;&#29616;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;$O(d)$&#20010;&#26679;&#26412;&#23601;&#36275;&#22815;&#31934;&#30830;&#22320;&#24674;&#22797;&#30446;&#26631;&#20540;&#65292;&#24182;&#19988;&#22312;&#20854;&#20182;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#30340;&#39640;&#27010;&#29575;&#36229;&#20986;&#39118;&#38505;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;$p$-&#33539;&#25968;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#19978;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#21487;&#23454;&#29616;&#30340;&#24773;&#20917;&#19979;&#65292;&#22312;&#27809;&#26377;&#30697;&#30340;&#20551;&#35774;&#19979;&#65292;&#36890;&#36807;$O(d)$&#20010;&#26679;&#26412;&#23601;&#36275;&#22815;&#31934;&#30830;&#22320;&#24674;&#22797;&#30446;&#26631;&#20540;&#65292;&#30456;&#24212;&#24615;&#21270;&#24120;&#25968;&#26377;&#20851;&#12290;&#21542;&#21017;&#65292;&#23545;&#20110;$p \in [2, \infty)$&#24182;&#19988;&#23545;&#30446;&#26631;&#21644;&#21327;&#21464;&#37327;&#20855;&#26377;&#36739;&#24369;&#30340;&#30697;&#20551;&#35774;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#39640;&#27010;&#29575;&#36229;&#20986;&#39118;&#38505;&#30028;&#65292;&#20854;&#20013;&#20027;&#35201;&#39033;&#19982;&#28176;&#36817;&#31934;&#30830;&#29575;&#21305;&#37197;&#65292;&#24120;&#25968;&#20165;&#20381;&#36182;&#20110;$p$&#12290;&#22312;&#20445;&#35777;&#39118;&#38505;&#20989;&#25968;&#22312;&#20854;&#26368;&#23567;&#21270;&#28857;&#19978;&#23384;&#22312;Hessian&#30697;&#38453;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23558;&#27492;&#32467;&#26524;&#25193;&#23637;&#21040;$p \in (1, 2)$&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the performance of empirical risk minimization on the $p$-norm linear regression problem for $p \in (1, \infty)$. We show that, in the realizable case, under no moment assumptions, and up to a distribution-dependent constant, $O(d)$ samples are enough to exactly recover the target. Otherwise, for $p \in [2, \infty)$, and under weak moment assumptions on the target and the covariates, we prove a high probability excess risk bound on the empirical risk minimizer whose leading term matches, up to a constant that depends only on $p$, the asymptotically exact rate. We extend this result to the case $p \in (1, 2)$ under mild assumptions that guarantee the existence of the Hessian of the risk at its minimizer.
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#22312;&#38543;&#26426;&#22359;&#27169;&#22411;&#20013;&#36827;&#34892;&#22270;&#32858;&#31867;&#30340;&#26032;&#31639;&#27861;&#65292;&#33021;&#22815;&#24674;&#22797;&#22823;&#32858;&#31867;&#65292;&#26080;&#35770;&#20854;&#20182;&#32858;&#31867;&#30340;&#22823;&#23567;&#65292;&#24182;&#19988;&#23545;&#20013;&#31561;&#22823;&#23567;&#30340;&#32858;&#31867;&#25552;&#20986;&#20102;&#26032;&#30340;&#25216;&#26415;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2308.15642</link><description>&lt;p&gt;
&#26080;&#38656;&#29305;&#24449;&#38388;&#38548;&#30340;&#32858;&#31867;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Clustering Without an Eigengap. (arXiv:2308.15642v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15642
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#22312;&#38543;&#26426;&#22359;&#27169;&#22411;&#20013;&#36827;&#34892;&#22270;&#32858;&#31867;&#30340;&#26032;&#31639;&#27861;&#65292;&#33021;&#22815;&#24674;&#22797;&#22823;&#32858;&#31867;&#65292;&#26080;&#35770;&#20854;&#20182;&#32858;&#31867;&#30340;&#22823;&#23567;&#65292;&#24182;&#19988;&#23545;&#20013;&#31561;&#22823;&#23567;&#30340;&#32858;&#31867;&#25552;&#20986;&#20102;&#26032;&#30340;&#25216;&#26415;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;SBM&#65289;&#20013;&#30740;&#31350;&#20102;&#20855;&#26377;&#22823;&#32858;&#31867;&#21644;&#23567;&#19981;&#21487;&#24674;&#22797;&#32858;&#31867;&#30340;&#22270;&#32858;&#31867;&#38382;&#39064;&#12290;&#20043;&#21069;&#30340;&#26041;&#27861;&#35201;&#20040;&#19981;&#20801;&#35768;&#23567;&#20110;$ o&#65288;\sqrt {n}&#65289;$&#22823;&#23567;&#30340;&#23567;&#32858;&#31867;&#65292;&#35201;&#20040;&#35201;&#27714;&#26368;&#23567;&#21487;&#24674;&#22797;&#32858;&#31867;&#21644;&#26368;&#22823;&#19981;&#21487;&#24674;&#22797;&#32858;&#31867;&#20043;&#38388;&#23384;&#22312;&#22823;&#23567;&#38388;&#38548;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#22522;&#20110;&#21322;&#23450;&#35268;&#21010;&#65288;SDP&#65289;&#30340;&#31639;&#27861;&#65292;&#23427;&#28040;&#38500;&#20102;&#36825;&#20123;&#35201;&#27714;&#65292;&#24182;&#21487;&#20197;&#30830;&#23450;&#22320;&#24674;&#22797;&#22823;&#32858;&#31867;&#65292;&#32780;&#19981;&#32771;&#34385;&#20854;&#20182;&#32858;&#31867;&#30340;&#22823;&#23567;&#12290;&#20013;&#31561;&#22823;&#23567;&#30340;&#32858;&#31867;&#23545;&#20998;&#26512;&#25552;&#20986;&#20102;&#29420;&#29305;&#30340;&#25361;&#25112;&#65292;&#22240;&#20026;&#23427;&#20204;&#25509;&#36817;&#24674;&#22797;&#38408;&#20540;&#65292;&#38750;&#24120;&#25935;&#24863;&#20110;&#23567;&#30340;&#22122;&#22768;&#25200;&#21160;&#65292;&#19981;&#20801;&#35768;&#38381;&#21512;&#24418;&#24335;&#30340;&#20505;&#36873;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#26032;&#39062;&#30340;&#25216;&#26415;&#65292;&#21253;&#25324;leave-one-out&#39118;&#26684;&#30340;&#35770;&#35777;&#65292;&#21363;&#20351;&#21435;&#25481;&#19968;&#34892;&#22122;&#22768;&#20063;&#21487;&#33021;&#22823;&#24133;&#25913;&#21464;SDP&#35299;&#20915;&#26041;&#26696;&#65292;&#20173;&#28982;&#21487;&#20197;&#25511;&#21046;SDP&#35299;&#20915;&#26041;&#26696;&#19982;&#22122;&#22768;&#21521;&#37327;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study graph clustering in the Stochastic Block Model (SBM) in the presence of both large clusters and small, unrecoverable clusters. Previous approaches achieving exact recovery do not allow any small clusters of size $o(\sqrt{n})$, or require a size gap between the smallest recovered cluster and the largest non-recovered cluster. We provide an algorithm based on semidefinite programming (SDP) which removes these requirements and provably recovers large clusters regardless of the remaining cluster sizes. Mid-sized clusters pose unique challenges to the analysis, since their proximity to the recovery threshold makes them highly sensitive to small noise perturbations and precludes a closed-form candidate solution. We develop novel techniques, including a leave-one-out-style argument which controls the correlation between SDP solutions and noise vectors even when the removal of one row of noise can drastically change the SDP solution. We also develop improved eigenvalue perturbation bo
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26080;&#20284;&#28982;&#36125;&#21494;&#26031;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#26500;&#24314;&#39640;&#25928;&#30340;&#25130;&#23614;&#36229;&#38408;&#20540;&#27169;&#22411;&#20272;&#35745;&#22120;&#12290;&#35813;&#26041;&#27861;&#25361;&#25112;&#20102;&#20256;&#32479;&#30340;&#22522;&#20110;&#25130;&#23614;&#20284;&#28982;&#30340;&#31354;&#38388;&#26497;&#20540;&#25512;&#29702;&#65292;&#24182;&#22312;&#35745;&#31639;&#21644;&#32479;&#35745;&#25928;&#29575;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2306.15642</link><description>&lt;p&gt;
&#26080;&#20284;&#28982;&#31070;&#32463;&#36125;&#21494;&#26031;&#20272;&#35745;&#30340;&#25130;&#23614;&#36229;&#38408;&#20540;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Likelihood-free neural Bayes estimators for censored peaks-over-threshold models. (arXiv:2306.15642v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15642
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26080;&#20284;&#28982;&#36125;&#21494;&#26031;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#26500;&#24314;&#39640;&#25928;&#30340;&#25130;&#23614;&#36229;&#38408;&#20540;&#27169;&#22411;&#20272;&#35745;&#22120;&#12290;&#35813;&#26041;&#27861;&#25361;&#25112;&#20102;&#20256;&#32479;&#30340;&#22522;&#20110;&#25130;&#23614;&#20284;&#28982;&#30340;&#31354;&#38388;&#26497;&#20540;&#25512;&#29702;&#65292;&#24182;&#22312;&#35745;&#31639;&#21644;&#32479;&#35745;&#25928;&#29575;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#24230;&#19979;&#65292;&#23545;&#20110;&#31354;&#38388;&#26497;&#20540;&#20381;&#36182;&#27169;&#22411;&#30340;&#25512;&#29702;&#24448;&#24448;&#22240;&#20854;&#20381;&#36182;&#20110;&#38590;&#20197;&#22788;&#29702;&#30340;&#25110;&#25130;&#23614;&#30340;&#20284;&#28982;&#20989;&#25968;&#32780;&#36896;&#25104;&#35745;&#31639;&#36127;&#25285;&#12290;&#21033;&#29992;&#26368;&#36817;&#22312;&#26080;&#20284;&#28982;&#25512;&#29702;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#20013;&#32534;&#30721;&#25130;&#23614;&#20449;&#24687;&#65292;&#20026;&#25130;&#23614;&#36229;&#38408;&#20540;&#27169;&#22411;&#26500;&#24314;&#20102;&#39640;&#25928;&#30340;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#30340;&#26032;&#26041;&#27861;&#23545;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#25130;&#23614;&#20284;&#28982;&#30340;&#31354;&#38388;&#26497;&#20540;&#25512;&#29702;&#25552;&#20986;&#20102;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#27169;&#25311;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#25512;&#26029;&#27969;&#34892;&#30340;&#26497;&#20540;&#20381;&#36182;&#27169;&#22411;&#65288;&#22914;&#26368;&#22823;&#31283;&#23450;&#27169;&#22411;&#12289;r-&#24085;&#32047;&#25176;&#27169;&#22411;&#21644;&#38543;&#26426;&#27604;&#20363;&#28151;&#21512;&#36807;&#31243;&#65289;&#26102;&#65292;&#30456;&#23545;&#20110;&#31454;&#20105;&#30340;&#22522;&#20110;&#20284;&#28982;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26032;&#20272;&#35745;&#22120;&#22312;&#35745;&#31639;&#21644;&#32479;&#35745;&#25928;&#29575;&#26041;&#38754;&#25552;&#20379;&#20102;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inference for spatial extremal dependence models can be computationally burdensome in moderate-to-high dimensions due to their reliance on intractable and/or censored likelihoods. Exploiting recent advances in likelihood-free inference with neural Bayes estimators (that is, neural estimators that target Bayes estimators), we develop a novel approach to construct highly efficient estimators for censored peaks-over-threshold models by encoding censoring information in the neural network architecture. Our new method provides a paradigm shift that challenges traditional censored likelihood-based inference for spatial extremes. Our simulation studies highlight significant gains in both computational and statistical efficiency, relative to competing likelihood-based approaches, when applying our novel estimators for inference of popular extremal dependence models, such as max-stable, $r$-Pareto, and random scale mixture processes. We also illustrate that it is possible to train a single esti
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;DU-Shapley&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26356;&#26377;&#25928;&#22320;&#35745;&#31639;Shapley&#20540;&#65292;&#20197;&#23454;&#29616;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#25968;&#25454;&#38598;&#20215;&#20540;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2306.02071</link><description>&lt;p&gt;
DU-Shapley: &#19968;&#31181;&#26377;&#25928;&#30340;&#25968;&#25454;&#38598;&#20215;&#20540;&#35780;&#20272;&#30340;Shapley&#20540;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
DU-Shapley: A Shapley Value Proxy for Efficient Dataset Valuation. (arXiv:2306.02071v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02071
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;DU-Shapley&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26356;&#26377;&#25928;&#22320;&#35745;&#31639;Shapley&#20540;&#65292;&#20197;&#23454;&#29616;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#25968;&#25454;&#38598;&#20215;&#20540;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#38656;&#35201;&#36827;&#34892;&#25968;&#25454;&#38598;&#35780;&#20272;&#65292;&#21363;&#37327;&#21270;&#23558;&#19968;&#20010;&#21333;&#29420;&#30340;&#25968;&#25454;&#38598;&#19982;&#20854;&#20182;&#25968;&#25454;&#38598;&#32858;&#21512;&#30340;&#22686;&#37327;&#25910;&#30410;&#65292;&#20197;&#26576;&#20123;&#30456;&#20851;&#39044;&#23450;&#20041;&#20844;&#29992;&#20107;&#19994;&#20026;&#22522;&#30784;&#12290;&#26368;&#36817;&#65292;Shapley&#20540;&#34987;&#25552;&#20986;&#20316;&#20026;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#30340;&#19968;&#31181;&#22522;&#26412;&#24037;&#20855;&#65292;&#22240;&#20026;&#23427;&#20855;&#26377;&#24418;&#24335;&#20844;&#29702;&#35777;&#26126;&#12290;&#30001;&#20110;&#20854;&#35745;&#31639;&#36890;&#24120;&#38656;&#35201;&#25351;&#25968;&#26102;&#38388;&#65292;&#22240;&#27492;&#32771;&#34385;&#22522;&#20110;Monte Carlo&#31215;&#20998;&#30340;&#26631;&#20934;&#36817;&#20284;&#31574;&#30053;&#12290;&#28982;&#32780;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#36825;&#31181;&#36890;&#29992;&#36817;&#20284;&#26041;&#27861;&#20173;&#28982;&#26114;&#36149;&#12290;&#26412;&#25991;&#21033;&#29992;&#25968;&#25454;&#38598;&#35780;&#20272;&#38382;&#39064;&#30340;&#32467;&#26500;&#30693;&#35782;&#65292;&#35774;&#35745;&#20102;&#26356;&#26377;&#25928;&#30340;Shapley&#20540;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;Shapley&#20540;&#36817;&#20284;&#65292;&#31216;&#20026;&#31163;&#25955;&#22343;&#21248;Shapley (DU-Shapley)&#65292;&#20854;&#34920;&#36798;&#20026;&#26399;&#26395;&#20540;
&lt;/p&gt;
&lt;p&gt;
Many machine learning problems require performing dataset valuation, i.e. to quantify the incremental gain, to some relevant pre-defined utility, of aggregating an individual dataset to others. As seminal examples, dataset valuation has been leveraged in collaborative and federated learning to create incentives for data sharing across several data owners. The Shapley value has recently been proposed as a principled tool to achieve this goal due to formal axiomatic justification. Since its computation often requires exponential time, standard approximation strategies based on Monte Carlo integration have been considered. Such generic approximation methods, however, remain expensive in some cases. In this paper, we exploit the knowledge about the structure of the dataset valuation problem to devise more efficient Shapley value estimators. We propose a novel approximation of the Shapley value, referred to as discrete uniform Shapley (DU-Shapley) which is expressed as an expectation under 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19981;&#21516;&#28608;&#27963;&#20989;&#25968;&#30340;Barron&#31354;&#38388;&#20043;&#38388;&#30340;&#23884;&#20837;&#65292;&#24182;&#35777;&#26126;&#20102;Barron&#31354;&#38388;&#30340;&#23618;&#27425;&#32467;&#26500;&#31867;&#20284;&#20110;Sobolev&#31354;&#38388;$H^m$&#12290;&#20854;&#20013;&#65292;&#20462;&#27491;&#21151;&#29575;&#21333;&#20301;&#28608;&#27963;&#20989;&#25968;&#22312;&#36825;&#20010;&#30740;&#31350;&#20013;&#29305;&#21035;&#37325;&#35201;&#12290;</title><link>http://arxiv.org/abs/2305.15839</link><description>&lt;p&gt;
&#20855;&#26377;&#39640;&#38454;&#28608;&#27963;&#20989;&#25968;&#30340;Barron&#31354;&#38388;&#20043;&#38388;&#30340;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Embeddings between Barron spaces with higher order activation functions. (arXiv:2305.15839v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15839
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19981;&#21516;&#28608;&#27963;&#20989;&#25968;&#30340;Barron&#31354;&#38388;&#20043;&#38388;&#30340;&#23884;&#20837;&#65292;&#24182;&#35777;&#26126;&#20102;Barron&#31354;&#38388;&#30340;&#23618;&#27425;&#32467;&#26500;&#31867;&#20284;&#20110;Sobolev&#31354;&#38388;$H^m$&#12290;&#20854;&#20013;&#65292;&#20462;&#27491;&#21151;&#29575;&#21333;&#20301;&#28608;&#27963;&#20989;&#25968;&#22312;&#36825;&#20010;&#30740;&#31350;&#20013;&#29305;&#21035;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#38480;&#23485;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#24615;&#36136;&#24456;&#22823;&#31243;&#24230;&#19978;&#21462;&#20915;&#20110;&#28608;&#27963;&#20989;&#25968;&#30340;&#36873;&#25321;&#12290;&#20026;&#20102;&#20102;&#35299;&#36825;&#31181;&#24433;&#21709;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#19981;&#21516;&#28608;&#27963;&#20989;&#25968;&#30340;Barron&#31354;&#38388;&#20043;&#38388;&#30340;&#23884;&#20837;&#12290;&#36890;&#36807;&#25552;&#20379;&#29992;&#20110;&#34920;&#31034;&#20989;&#25968;$f$&#30340;&#27979;&#37327;$\mu$&#19978;&#30340;&#25512;&#36827;&#26144;&#23556;&#26469;&#35777;&#26126;&#36825;&#20123;&#23884;&#20837;&#12290;&#19968;&#31181;&#29305;&#21035;&#24863;&#20852;&#36259;&#30340;&#28608;&#27963;&#20989;&#25968;&#26159;&#32473;&#23450;&#20026;$\operatorname{RePU}_s(x)=\max(0,x)^s$&#30340;&#20462;&#27491;&#21151;&#29575;&#21333;&#20301;($\operatorname{RePU}$)&#12290;&#23545;&#20110;&#35768;&#22810;&#24120;&#29992;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#21487;&#20197;&#20351;&#29992;&#20247;&#25152;&#21608;&#30693;&#30340;&#27888;&#21202;&#20313;&#39033;&#23450;&#29702;&#26500;&#36896;&#25512;&#36827;&#26144;&#23556;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#35777;&#26126;&#30456;&#20851;Barron&#31354;&#38388;&#23884;&#20837;&#21040;&#20855;&#26377;$\operatorname{RePU}$&#20316;&#20026;&#28608;&#27963;&#20989;&#25968;&#30340;Barron&#31354;&#38388;&#20013;&#12290;&#27492;&#22806;&#65292;&#19982;$\operatorname{RePU}_s$&#30456;&#20851;&#30340;Barron&#31354;&#38388;&#20855;&#26377;&#31867;&#20284;&#20110;Sobolev&#31354;&#38388;$H^m$&#30340;&#20998;&#23618;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
The approximation properties of infinitely wide shallow neural networks heavily depend on the choice of the activation function. To understand this influence, we study embeddings between Barron spaces with different activation functions. These embeddings are proven by providing push-forward maps on the measures $\mu$ used to represent functions $f$. An activation function of particular interest is the rectified power unit ($\operatorname{RePU}$) given by $\operatorname{RePU}_s(x)=\max(0,x)^s$. For many commonly used activation functions, the well-known Taylor remainder theorem can be used to construct a push-forward map, which allows us to prove the embedding of the associated Barron space into a Barron space with a $\operatorname{RePU}$ as activation function. Moreover, the Barron spaces associated with the $\operatorname{RePU}_s$ have a hierarchical structure similar to the Sobolev spaces $H^m$.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#28459;&#25193;&#25193;&#25955;&#27169;&#22411;&#21644;&#37319;&#26679;&#22120;&#26041;&#38754;&#36827;&#34892;&#20102;&#34920;&#36798;&#33021;&#21147;&#30340;&#30740;&#31350;&#65292;&#36890;&#36807;&#23558;&#24050;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#32467;&#26524;&#25193;&#23637;&#21040;&#28459;&#25193;&#25193;&#25955;&#27169;&#22411;&#21644;&#37319;&#26679;&#22120;&#26469;&#23454;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.09605</link><description>&lt;p&gt;
&#28459;&#25193;&#25193;&#25955;&#27169;&#22411;&#21644;&#37319;&#26679;&#22120;&#30340;&#34920;&#36798;&#33021;&#21147;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Expressiveness Remarks for Denoising Diffusion Models and Samplers. (arXiv:2305.09605v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09605
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#28459;&#25193;&#25193;&#25955;&#27169;&#22411;&#21644;&#37319;&#26679;&#22120;&#26041;&#38754;&#36827;&#34892;&#20102;&#34920;&#36798;&#33021;&#21147;&#30340;&#30740;&#31350;&#65292;&#36890;&#36807;&#23558;&#24050;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#32467;&#26524;&#25193;&#23637;&#21040;&#28459;&#25193;&#25193;&#25955;&#27169;&#22411;&#21644;&#37319;&#26679;&#22120;&#26469;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28459;&#25193;&#25193;&#25955;&#27169;&#22411;&#26159;&#19968;&#31867;&#29983;&#25104;&#27169;&#22411;&#65292;&#22312;&#35768;&#22810;&#39046;&#22495;&#26368;&#36817;&#24050;&#32463;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;&#36890;&#36807;&#28459;&#25193;&#36807;&#31243;&#36880;&#28176;&#21521;&#25968;&#25454;&#20013;&#28155;&#21152;&#22122;&#22768;&#65292;&#23558;&#25968;&#25454;&#20998;&#24067;&#36716;&#21270;&#20026;&#39640;&#26031;&#20998;&#24067;&#12290;&#28982;&#21518;&#65292;&#36890;&#36807;&#27169;&#25311;&#35813;&#28459;&#25193;&#30340;&#26102;&#38388;&#21453;&#28436;&#30340;&#36924;&#36817;&#26469;&#33719;&#21462;&#29983;&#25104;&#27169;&#22411;&#30340;&#26679;&#26412;&#65292;&#21018;&#24320;&#22987;&#36825;&#20010;&#28459;&#25193;&#27169;&#25311;&#30340;&#21021;&#22987;&#20540;&#26159;&#39640;&#26031;&#26679;&#26412;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#25506;&#32034;&#20102;&#23558;&#28459;&#25193;&#27169;&#22411;&#36866;&#24212;&#20110;&#37319;&#26679;&#21644;&#25512;&#26029;&#20219;&#21153;&#12290;&#26412;&#25991;&#22522;&#20110;&#20247;&#25152;&#21608;&#30693;&#30340;&#19982;F\"ollmer&#28418;&#31227;&#31867;&#20284;&#30340;&#38543;&#26426;&#25511;&#21046;&#32852;&#31995;&#65292;&#23558;&#38024;&#23545;F\"ollmer&#28418;&#31227;&#30340;&#24050;&#30693;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#32467;&#26524;&#25193;&#23637;&#21040;&#28459;&#25193;&#25193;&#25955;&#27169;&#22411;&#21644;&#37319;&#26679;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Denoising diffusion models are a class of generative models which have recently achieved state-of-the-art results across many domains. Gradual noise is added to the data using a diffusion process, which transforms the data distribution into a Gaussian. Samples from the generative model are then obtained by simulating an approximation of the time reversal of this diffusion initialized by Gaussian samples. Recent research has explored adapting diffusion models for sampling and inference tasks. In this paper, we leverage known connections to stochastic control akin to the F\"ollmer drift to extend established neural network approximation results for the F\"ollmer drift to denoising diffusion models and samplers.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26694;&#26550;GCDTC&#65292;&#21033;&#29992;&#25968;&#20540;&#20808;&#39564;&#21644;&#24191;&#20041;CP&#20998;&#35299;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#20302;&#31209;&#24352;&#37327;&#34917;&#20840;&#31934;&#24230;&#65307;&#21516;&#26102;&#20171;&#32461;&#20102;&#19968;&#20010;&#31639;&#27861;SPTC&#65292;&#20316;&#20026;&#35813;&#26694;&#26550;&#30340;&#19968;&#20010;&#23454;&#29616;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#27604;&#29616;&#26377;&#25216;&#26415;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2302.05881</link><description>&lt;p&gt;
&#25506;&#32034;&#22522;&#20110;&#25968;&#20540;&#20808;&#39564;&#30340;&#24191;&#20041;CP&#20998;&#35299;&#20302;&#31209;&#24352;&#37327;&#34917;&#20840;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Exploring Numerical Priors for Low-Rank Tensor Completion with Generalized CP Decomposition. (arXiv:2302.05881v3 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05881
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26694;&#26550;GCDTC&#65292;&#21033;&#29992;&#25968;&#20540;&#20808;&#39564;&#21644;&#24191;&#20041;CP&#20998;&#35299;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#20302;&#31209;&#24352;&#37327;&#34917;&#20840;&#31934;&#24230;&#65307;&#21516;&#26102;&#20171;&#32461;&#20102;&#19968;&#20010;&#31639;&#27861;SPTC&#65292;&#20316;&#20026;&#35813;&#26694;&#26550;&#30340;&#19968;&#20010;&#23454;&#29616;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#27604;&#29616;&#26377;&#25216;&#26415;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24352;&#37327;&#34917;&#20840;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#25968;&#25454;&#20998;&#26512;&#21644;&#20449;&#21495;&#22788;&#29702;&#31561;&#39046;&#22495;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#26368;&#36817;&#65292;&#20302;&#31209;&#24352;&#37327;&#34917;&#20840;&#36825;&#19968;&#31867;&#21035;&#30340;&#26041;&#27861;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#23545;&#34917;&#20840;&#24352;&#37327;&#26045;&#21152;&#20302;&#31209;&#32467;&#26500;&#12290;&#34429;&#28982;&#36825;&#20123;&#26041;&#27861;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#65292;&#20294;&#23578;&#26410;&#32771;&#34385;&#21040;&#24352;&#37327;&#20803;&#32032;&#30340;&#25968;&#20540;&#20808;&#39564;&#20449;&#24687;&#12290;&#24573;&#30053;&#25968;&#20540;&#20808;&#39564;&#23558;&#23548;&#33268;&#20002;&#22833;&#20851;&#20110;&#25968;&#25454;&#30340;&#37325;&#35201;&#20449;&#24687;&#65292;&#22240;&#27492;&#38459;&#27490;&#31639;&#27861;&#36798;&#21040;&#26368;&#20248;&#31934;&#24230;&#12290;&#26412;&#30740;&#31350;&#35797;&#22270;&#26500;&#24314;&#19968;&#20010;&#26032;&#30340;&#26041;&#27861;&#26694;&#26550;&#65292;&#21517;&#20026;GCDTC&#65288;&#24191;&#20041;CP&#20998;&#35299;&#24352;&#37327;&#34917;&#20840;&#65289;&#65292;&#20197;&#21033;&#29992;&#25968;&#20540;&#20808;&#39564;&#24182;&#23454;&#29616;&#26356;&#39640;&#30340;&#24352;&#37327;&#34917;&#20840;&#31934;&#24230;&#12290;&#22312;&#36825;&#20010;&#26032;&#24341;&#20837;&#30340;&#26694;&#26550;&#20013;&#65292;&#23558;&#24191;&#20041;&#30340;CP&#20998;&#35299;&#24212;&#29992;&#20110;&#20302;&#31209;&#24352;&#37327;&#34917;&#20840;&#12290;&#26412;&#25991;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SPTC&#65288;&#24179;&#28369;&#27850;&#26494;&#24352;&#37327;&#34917;&#20840;&#65289;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#38750;&#36127;&#25972;&#25968;&#24352;&#37327;&#34917;&#20840;&#65292;&#20316;&#20026;GCDTC&#26694;&#26550;&#30340;&#19968;&#20010;&#23454;&#29616;&#12290;&#36890;&#36807;&#23545;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#30340;&#22823;&#37327;&#23454;&#39564;&#65292;&#35777;&#26126;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30456;&#27604;&#20110;&#29616;&#26377;&#25216;&#26415;&#20855;&#26377;&#26356;&#20248;&#30340;&#24352;&#37327;&#34917;&#20840;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tensor completion is important to many areas such as computer vision, data analysis, and signal processing. Enforcing low-rank structures on completed tensors, a category of methods known as low-rank tensor completion has recently been studied extensively. While such methods attained great success, none considered exploiting numerical priors of tensor elements. Ignoring numerical priors causes loss of important information regarding the data, and therefore prevents the algorithms from reaching optimal accuracy. This work attempts to construct a new methodological framework called GCDTC (Generalized CP Decomposition Tensor Completion) for leveraging numerical priors and achieving higher accuracy in tensor completion. In this newly introduced framework, a generalized form of CP Decomposition is applied to low-rank tensor completion. This paper also proposes an algorithm known as SPTC (Smooth Poisson Tensor Completion) for nonnegative integer tensor completion as an instantiation of the G
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#20195;&#29702;&#22240;&#26524;&#23398;&#20064;&#65288;PCL&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#23384;&#22312;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#27835;&#30103;&#23545;&#32467;&#26524;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#36890;&#36807;&#26500;&#24314;&#27835;&#30103;&#21644;&#20195;&#29702;&#20043;&#38388;&#30340;&#27169;&#22411;&#65292;&#24182;&#21033;&#29992;&#35813;&#27169;&#22411;&#22312;&#32473;&#23450;&#20195;&#29702;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#27835;&#30103;&#23545;&#32467;&#26524;&#30340;&#24433;&#21709;&#65292;PCL&#21487;&#20197;&#20445;&#35777;&#24674;&#22797;&#30495;&#23454;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#20316;&#32773;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28145;&#24230;&#29305;&#24449;&#20195;&#29702;&#21464;&#37327;&#26041;&#27861;&#65288;DFPV&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#39640;&#32500;&#21644;&#38750;&#32447;&#24615;&#22797;&#26434;&#20851;&#31995;&#30340;&#24773;&#20917;&#65292;&#24182;&#34920;&#26126;DFPV&#22312;&#21512;&#25104;&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#24615;&#33021;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;PCL&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2106.03907</link><description>&lt;p&gt;
&#28145;&#24230;&#20195;&#29702;&#22240;&#26524;&#23398;&#20064;&#21450;&#20854;&#22312;&#28151;&#28102;&#36172;&#21338;&#31574;&#30053;&#35780;&#20272;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Deep Proxy Causal Learning and its Application to Confounded Bandit Policy Evaluation. (arXiv:2106.03907v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.03907
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#20195;&#29702;&#22240;&#26524;&#23398;&#20064;&#65288;PCL&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#23384;&#22312;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#27835;&#30103;&#23545;&#32467;&#26524;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#36890;&#36807;&#26500;&#24314;&#27835;&#30103;&#21644;&#20195;&#29702;&#20043;&#38388;&#30340;&#27169;&#22411;&#65292;&#24182;&#21033;&#29992;&#35813;&#27169;&#22411;&#22312;&#32473;&#23450;&#20195;&#29702;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#27835;&#30103;&#23545;&#32467;&#26524;&#30340;&#24433;&#21709;&#65292;PCL&#21487;&#20197;&#20445;&#35777;&#24674;&#22797;&#30495;&#23454;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#20316;&#32773;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28145;&#24230;&#29305;&#24449;&#20195;&#29702;&#21464;&#37327;&#26041;&#27861;&#65288;DFPV&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#39640;&#32500;&#21644;&#38750;&#32447;&#24615;&#22797;&#26434;&#20851;&#31995;&#30340;&#24773;&#20917;&#65292;&#24182;&#34920;&#26126;DFPV&#22312;&#21512;&#25104;&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#24615;&#33021;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;PCL&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20195;&#29702;&#22240;&#26524;&#23398;&#20064;&#65288;PCL&#65289;&#26159;&#19968;&#31181;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#26102;&#65292;&#21033;&#29992;&#20195;&#29702;&#65288;&#32467;&#26500;&#21270;&#20391;&#38754;&#20449;&#24687;&#65289;&#20272;&#35745;&#27835;&#30103;&#23545;&#32467;&#26524;&#30340;&#22240;&#26524;&#25928;&#24212;&#30340;&#26041;&#27861;&#12290;&#36825;&#26159;&#36890;&#36807;&#20004;&#38454;&#27573;&#22238;&#24402;&#23454;&#29616;&#30340;&#65306;&#22312;&#31532;&#19968;&#38454;&#27573;&#65292;&#25105;&#20204;&#24314;&#27169;&#27835;&#30103;&#21644;&#20195;&#29702;&#20043;&#38388;&#30340;&#20851;&#31995;&#65307;&#22312;&#31532;&#20108;&#38454;&#27573;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#20010;&#27169;&#22411;&#26469;&#23398;&#20064;&#22312;&#32473;&#23450;&#20195;&#29702;&#25552;&#20379;&#30340;&#19978;&#19979;&#25991;&#19979;&#65292;&#27835;&#30103;&#23545;&#32467;&#26524;&#30340;&#24433;&#21709;&#12290;PCL&#22312;&#21487;&#35782;&#21035;&#26465;&#20214;&#19979;&#20445;&#35777;&#24674;&#22797;&#30495;&#23454;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;PCL&#26041;&#27861;&#65292;&#28145;&#24230;&#29305;&#24449;&#20195;&#29702;&#21464;&#37327;&#26041;&#27861;&#65288;DFPV&#65289;&#65292;&#20197;&#35299;&#20915;&#20195;&#29702;&#12289;&#27835;&#30103;&#21644;&#32467;&#26524;&#20026;&#39640;&#32500;&#19988;&#20855;&#26377;&#38750;&#32447;&#24615;&#22797;&#26434;&#20851;&#31995;&#30340;&#24773;&#20917;&#65292;&#22914;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#29305;&#24449;&#34920;&#31034;&#12290;&#25105;&#20204;&#34920;&#26126;DFPV&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#21512;&#25104;&#22522;&#20934;&#27979;&#35797;&#20013;&#20248;&#20110;&#26368;&#36817;&#30340;&#26368;&#20808;&#36827;&#30340;PCL&#26041;&#27861;&#65292;&#21253;&#25324;&#28041;&#21450;&#39640;&#32500;&#22270;&#20687;&#25968;&#25454;&#30340;&#35774;&#32622;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;PCL&#30340;&#24212;&#29992;...
&lt;/p&gt;
&lt;p&gt;
Proxy causal learning (PCL) is a method for estimating the causal effect of treatments on outcomes in the presence of unobserved confounding, using proxies (structured side information) for the confounder. This is achieved via two-stage regression: in the first stage, we model relations among the treatment and proxies; in the second stage, we use this model to learn the effect of treatment on the outcome, given the context provided by the proxies. PCL guarantees recovery of the true causal effect, subject to identifiability conditions. We propose a novel method for PCL, the deep feature proxy variable method (DFPV), to address the case where the proxies, treatments, and outcomes are high-dimensional and have nonlinear complex relationships, as represented by deep neural network features. We show that DFPV outperforms recent state-of-the-art PCL methods on challenging synthetic benchmarks, including settings involving high dimensional image data. Furthermore, we show that PCL can be app
&lt;/p&gt;</description></item></channel></rss>