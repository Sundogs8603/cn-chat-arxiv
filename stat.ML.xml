<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#22343;&#21248;&#30340;$k$-dag&#24191;&#25773;&#27169;&#22411;&#65292;&#30830;&#23450;&#20102;&#19982;$p$&#21644;$k$&#26377;&#20851;&#30340;&#38408;&#20540;&#65292;&#24182;&#35752;&#35770;&#20102;&#22823;&#22810;&#25968;&#35268;&#21017;&#30340;&#35823;&#24046;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.01727</link><description>&lt;p&gt;
&#22312;&#38543;&#26426;&#36882;&#24402;&#26377;&#21521;&#26080;&#29615;&#22270;&#20013;&#30340;&#24191;&#25773;
&lt;/p&gt;
&lt;p&gt;
Broadcasting in random recursive dags. (arXiv:2306.01727v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01727
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#22343;&#21248;&#30340;$k$-dag&#24191;&#25773;&#27169;&#22411;&#65292;&#30830;&#23450;&#20102;&#19982;$p$&#21644;$k$&#26377;&#20851;&#30340;&#38408;&#20540;&#65292;&#24182;&#35752;&#35770;&#20102;&#22823;&#22810;&#25968;&#35268;&#21017;&#30340;&#35823;&#24046;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#20010;&#22343;&#21248;&#30340;$k$-dag&#36890;&#36807;&#20174;&#29616;&#26377;&#33410;&#28857;&#20013;&#22343;&#21248;&#38543;&#26426;&#36873;&#25321;$k$&#20010;&#29238;&#33410;&#28857;&#26469;&#25512;&#24191;&#22343;&#21248;&#30340;&#38543;&#26426;&#36882;&#24402;&#26641;&#12290;&#23427;&#20197;$k$&#20010;&#8220;&#26681;&#8221;&#24320;&#22987;&#12290;&#27599;&#20010;$k$&#20010;&#26681;&#33410;&#28857;&#37117;&#34987;&#20998;&#37197;&#19968;&#20010;&#20301;&#12290;&#36825;&#20123;&#20301;&#36890;&#36807;&#19968;&#20010;&#22024;&#26434;&#30340;&#20449;&#36947;&#20256;&#25773;&#12290;&#27599;&#20010;&#29238;&#33410;&#28857;&#30340;&#20301;&#37117;&#20197;&#27010;&#29575;$p$&#21457;&#29983;&#21464;&#21270;&#65292;&#24182;&#36827;&#34892;&#22823;&#22810;&#25968;&#34920;&#20915;&#12290;&#24403;&#25152;&#26377;&#33410;&#28857;&#37117;&#25509;&#25910;&#21040;&#23427;&#20204;&#30340;&#20301;&#21518;&#65292;$k$-dag&#34987;&#26174;&#31034;&#65292;&#19981;&#35782;&#21035;&#26681;&#33410;&#28857;&#12290;&#30446;&#26631;&#26159;&#20272;&#35745;&#25152;&#26377;&#26681;&#33410;&#28857;&#20013;&#30340;&#22823;&#22810;&#25968;&#20301;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;$p$&#30340;&#38408;&#20540;&#65292;&#20316;&#20026;&#19968;&#20010;&#20851;&#20110;$k$&#30340;&#20989;&#25968;&#65292;&#20351;&#24471;&#25152;&#26377;&#33410;&#28857;&#30340;&#22823;&#22810;&#25968;&#35268;&#21017;&#20135;&#29983;&#38169;&#35823;$c+o(1)$&#30340;&#27010;&#29575;&#23567;&#20110;$1/2$&#12290;&#22312;&#38408;&#20540;&#20197;&#19978;&#65292;&#22823;&#22810;&#25968;&#35268;&#21017;&#30340;&#38169;&#35823;&#27010;&#29575;&#20026;$1/2+o(1)$&#12290;
&lt;/p&gt;
&lt;p&gt;
A uniform $k$-{\sc dag} generalizes the uniform random recursive tree by picking $k$ parents uniformly at random from the existing nodes. It starts with $k$ ''roots''. Each of the $k$ roots is assigned a bit. These bits are propagated by a noisy channel. The parents' bits are flipped with probability $p$, and a majority vote is taken. When all nodes have received their bits, the $k$-{\sc dag} is shown without identifying the roots. The goal is to estimate the majority bit among the roots. We identify the threshold for $p$ as a function of $k$ below which the majority rule among all nodes yields an error $c+o(1)$ with $c&lt;1/2$. Above the threshold the majority rule errs with probability $1/2+o(1)$.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#20195;&#25968;&#35780;&#20272;&#22120;&#26469;&#20272;&#35745;&#26410;&#26631;&#35760;&#25968;&#25454;&#20013;&#26377;&#22122;&#22768;&#20108;&#20803;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;&#20854;&#20013;&#65292;&#31532;&#20108;&#31181;&#35780;&#20272;&#22120;&#30340;&#27491;&#30830;&#24615;&#34987;&#20445;&#35777;&#12290;&#20316;&#32773;&#36890;&#36807;&#21033;&#29992;&#29420;&#31435;&#35780;&#20272;&#22120;&#26080;&#27861;&#36820;&#22238;&#21512;&#29702;&#20272;&#35745;&#30340;&#22833;&#36133;&#65292;&#32531;&#35299;&#20102;&#22996;&#25176;/&#20195;&#29702;&#30417;&#25511;&#24726;&#35770;&#65292;&#24182;&#36890;&#36807;&#25628;&#32034;&#26469;&#23547;&#25214;&#20960;&#20046;&#26080;&#35823;&#24046;&#30340;&#19977;&#20803;&#32452;&#12290;</title><link>http://arxiv.org/abs/2306.01726</link><description>&lt;p&gt;
&#35780;&#20272;&#26377;&#22122;&#22768;&#21028;&#21035;&#22120;&#23545;&#26410;&#26631;&#35760;&#25968;&#25454;&#30340;&#27969;&#24335;&#31639;&#27861; -- &#20108;&#20803;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Streaming algorithms for evaluating noisy judges on unlabeled data -- binary classification. (arXiv:2306.01726v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01726
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#20195;&#25968;&#35780;&#20272;&#22120;&#26469;&#20272;&#35745;&#26410;&#26631;&#35760;&#25968;&#25454;&#20013;&#26377;&#22122;&#22768;&#20108;&#20803;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;&#20854;&#20013;&#65292;&#31532;&#20108;&#31181;&#35780;&#20272;&#22120;&#30340;&#27491;&#30830;&#24615;&#34987;&#20445;&#35777;&#12290;&#20316;&#32773;&#36890;&#36807;&#21033;&#29992;&#29420;&#31435;&#35780;&#20272;&#22120;&#26080;&#27861;&#36820;&#22238;&#21512;&#29702;&#20272;&#35745;&#30340;&#22833;&#36133;&#65292;&#32531;&#35299;&#20102;&#22996;&#25176;/&#20195;&#29702;&#30417;&#25511;&#24726;&#35770;&#65292;&#24182;&#36890;&#36807;&#25628;&#32034;&#26469;&#23547;&#25214;&#20960;&#20046;&#26080;&#35823;&#24046;&#30340;&#19977;&#20803;&#32452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#23545;&#26410;&#26631;&#35760;&#25968;&#25454;&#20013;&#30340;&#26377;&#22122;&#22768;&#20108;&#20803;&#20998;&#31867;&#22120;&#30340;&#35780;&#20272;&#20316;&#20026;&#27969;&#24335;&#20219;&#21153;&#36827;&#34892;&#30740;&#31350;: &#32473;&#23450;&#19968;&#20010;&#20998;&#31867;&#22120;&#20915;&#31574;&#30340;&#25968;&#25454;&#33609;&#22270;&#65292;&#20272;&#35745;&#26631;&#31614;&#30340;&#30495;&#23454;&#27969;&#34892;&#24230;&#20197;&#21450;&#27599;&#20010;&#20998;&#31867;&#22120;&#23545;&#23427;&#20204;&#30340;&#20934;&#30830;&#24230;&#12290;&#26412;&#25991;&#26500;&#24314;&#20102;&#20004;&#31181;&#23436;&#20840;&#20195;&#25968;&#21270;&#30340;&#35780;&#20272;&#22120;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#12290;&#20004;&#31181;&#35780;&#20272;&#22120;&#37117;&#22522;&#20110;&#20998;&#31867;&#22120;&#20135;&#29983;&#29420;&#31435;&#38169;&#35823;&#30340;&#20551;&#35774;&#12290;&#31532;&#19968;&#31181;&#26159;&#22522;&#20110;&#22810;&#25968;&#25237;&#31080;&#30340;&#12290;&#32780;&#31532;&#20108;&#31181;&#21017;&#26159;&#26412;&#25991;&#30340;&#20027;&#35201;&#36129;&#29486;&#65292;&#24182;&#34987;&#20445;&#35777;&#26159;&#27491;&#30830;&#30340;&#12290;&#20294;&#26159;&#22914;&#20309;&#30830;&#20445;&#20998;&#31867;&#22120;&#22312;&#20219;&#20309;&#32473;&#23450;&#30340;&#27979;&#35797;&#20013;&#26159;&#29420;&#31435;&#30340;&#21602;&#65311;&#26412;&#25991;&#36890;&#36807;&#21033;&#29992;&#29420;&#31435;&#35780;&#20272;&#22120;&#26080;&#27861;&#36820;&#22238;&#21512;&#29702;&#20272;&#35745;&#30340;&#22833;&#36133;&#26469;&#32531;&#35299;&#36825;&#20010;&#22996;&#25176;/&#20195;&#29702;&#30417;&#25511;&#24726;&#35770;&#12290;&#36890;&#36807;&#21033;&#29992;&#20195;&#25968;&#25925;&#38556;&#27169;&#24335;&#26469;&#25298;&#32477;&#22826;&#30456;&#20851;&#30340;&#35780;&#20272;&#38598;&#21512;&#65292;&#20351;&#29992; \texttt{adult}&#65292;\texttt{mushroom} &#21644; \texttt{two-norm} &#25968;&#25454;&#38598;&#23545;&#19968;&#32452;&#20960;&#20046;&#26080;&#35823;&#24046;&#19977;&#20803;&#32452;&#36827;&#34892;&#20102;&#23454;&#35777;&#25628;&#32034;&#12290;&#36825;&#20123;&#25628;&#32034;&#36890;&#36807;&#26500;&#24314;&#35780;&#20272;&#31354;&#38388;&#20013;&#30340;&#34920;&#38754;&#26469;&#36827;&#34892;&#31934;&#32454;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
The evaluation of noisy binary classifiers on unlabeled data is treated as a streaming task: given a data sketch of the decisions by an ensemble, estimate the true prevalence of the labels as well as each classifier's accuracy on them. Two fully algebraic evaluators are constructed to do this. Both are based on the assumption that the classifiers make independent errors. The first is based on majority voting. The second, the main contribution of the paper, is guaranteed to be correct. But how do we know the classifiers are independent on any given test? This principal/agent monitoring paradox is ameliorated by exploiting the failures of the independent evaluator to return sensible estimates. A search for nearly error independent trios is empirically carried out on the \texttt{adult}, \texttt{mushroom}, and \texttt{two-norm} datasets by using the algebraic failure modes to reject evaluation ensembles as too correlated. The searches are refined by constructing a surface in evaluation spa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#30456;&#23545;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#29992;&#20110;&#35823;&#20998;&#31867;&#26816;&#27979;&#12290;&#35813;&#24230;&#37327;&#21487;&#20197;&#36890;&#36807;&#23398;&#20064;&#36719;&#39044;&#27979;&#30340;&#20998;&#24067;&#27169;&#24335;&#65292;&#35782;&#21035;&#20986;&#34987;&#35823;&#20998;&#31867;&#30340;&#26679;&#26412;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#22810;&#20010;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#23454;&#35777;&#25913;&#36827;&#65292;&#20248;&#20110;&#29616;&#26377;&#30340;&#35823;&#20998;&#31867;&#26816;&#27979;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.01710</link><description>&lt;p&gt;
&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#30456;&#23545;&#19981;&#30830;&#23450;&#24615;&#27979;&#24230;&#29992;&#20110;&#35823;&#20998;&#31867;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
A Data-Driven Measure of Relative Uncertainty for Misclassification Detection. (arXiv:2306.01710v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01710
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#30456;&#23545;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#29992;&#20110;&#35823;&#20998;&#31867;&#26816;&#27979;&#12290;&#35813;&#24230;&#37327;&#21487;&#20197;&#36890;&#36807;&#23398;&#20064;&#36719;&#39044;&#27979;&#30340;&#20998;&#24067;&#27169;&#24335;&#65292;&#35782;&#21035;&#20986;&#34987;&#35823;&#20998;&#31867;&#30340;&#26679;&#26412;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#22810;&#20010;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#23454;&#35777;&#25913;&#36827;&#65292;&#20248;&#20110;&#29616;&#26377;&#30340;&#35823;&#20998;&#31867;&#26816;&#27979;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35823;&#20998;&#31867;&#26816;&#27979;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65292;&#23427;&#21487;&#20197;&#35782;&#21035;&#27169;&#22411;&#39044;&#27979;&#19981;&#21487;&#38752;&#30340;&#23454;&#20363;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;&#19981;&#30830;&#23450;&#24615;&#27979;&#24230;&#22914;&#39321;&#20892;&#29109;&#24182;&#19981;&#33021;&#25552;&#20379;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#24335;&#26469;&#25512;&#26029;&#27169;&#22411;&#39044;&#27979;&#30340;&#23454;&#38469;&#19981;&#30830;&#23450;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25968;&#25454;&#39537;&#21160;&#30456;&#23545;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#29992;&#20110;&#35823;&#20998;&#31867;&#26816;&#27979;&#12290;&#36890;&#36807;&#23398;&#20064;&#36719;&#39044;&#27979;&#30340;&#20998;&#24067;&#27169;&#24335;&#65292;&#25105;&#20204;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#21487;&#20197;&#22522;&#20110;&#39044;&#27979;&#30340;&#31867;&#27010;&#29575;&#26631;&#35782;&#34987;&#35823;&#20998;&#31867;&#30340;&#26679;&#26412;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#26681;&#25454;&#25152;&#25552;&#20986;&#30340;&#24230;&#37327;&#65292;&#19982;&#35823;&#20998;&#31867;&#23454;&#20363;&#23545;&#24212;&#30340;&#36719;&#39044;&#27979;&#21487;&#33021;&#20855;&#26377;&#24456;&#22823;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#21363;&#20351;&#23427;&#20204;&#30340;&#39321;&#20892;&#29109;&#21487;&#33021;&#24456;&#20302;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22810;&#20010;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#23454;&#35777;&#25913;&#36827;&#65292;&#20248;&#20110;&#29616;&#26377;&#30340;&#35823;&#20998;&#31867;&#26816;&#27979;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Misclassification detection is an important problem in machine learning, as it allows for the identification of instances where the model's predictions are unreliable. However, conventional uncertainty measures such as Shannon entropy do not provide an effective way to infer the real uncertainty associated with the model's predictions. In this paper, we introduce a novel data-driven measure of relative uncertainty to an observer for misclassification detection. By learning patterns in the distribution of soft-predictions, our uncertainty measure can identify misclassified samples based on the predicted class probabilities. Interestingly, according to the proposed measure, soft-predictions that correspond to misclassified instances can carry a large amount of uncertainty, even though they may have low Shannon entropy. We demonstrate empirical improvements over multiple image classification tasks, outperforming state-of-the-art misclassification detection methods.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20146;&#21644;&#24615;&#32858;&#31867;&#30340;&#25968;&#25454;&#25193;&#20805;&#26041;&#27861;MASC&#65292;&#36890;&#36807;&#21516;&#31867;&#25968;&#25454;&#38598;&#20013;&#30340;&#20146;&#21644;&#32858;&#31867;&#21644;&#20445;&#25252;&#25968;&#25454;&#30340;&#20849;&#20139;&#36798;&#21040;&#25968;&#25454;&#38598;&#30340;&#24179;&#34913;&#65292;&#20174;&#32780;&#35299;&#20915;&#25968;&#25454;&#38598;&#20195;&#34920;&#24615;&#20559;&#35265;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.01699</link><description>&lt;p&gt;
&#22522;&#20110;&#25104;&#23545;&#20998;&#24067;&#24046;&#24322;&#30340;&#25968;&#25454;&#21435;&#20559;&#35265;&#20146;&#21644;&#24615;&#32858;&#31867;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Affinity Clustering Framework for Data Debiasing Using Pairwise Distribution Discrepancy. (arXiv:2306.01699v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01699
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20146;&#21644;&#24615;&#32858;&#31867;&#30340;&#25968;&#25454;&#25193;&#20805;&#26041;&#27861;MASC&#65292;&#36890;&#36807;&#21516;&#31867;&#25968;&#25454;&#38598;&#20013;&#30340;&#20146;&#21644;&#32858;&#31867;&#21644;&#20445;&#25252;&#25968;&#25454;&#30340;&#20849;&#20139;&#36798;&#21040;&#25968;&#25454;&#38598;&#30340;&#24179;&#34913;&#65292;&#20174;&#32780;&#35299;&#20915;&#25968;&#25454;&#38598;&#20195;&#34920;&#24615;&#20559;&#35265;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#37319;&#38598;&#26041;&#27861;&#19981;&#36275;&#25110;&#19981;&#20855;&#20195;&#34920;&#24615;&#24120;&#23548;&#33268;&#36523;&#20221;&#32452;&#19981;&#24179;&#34913;&#65292;&#24418;&#25104;&#25968;&#25454;&#38598;&#20195;&#34920;&#24615;&#20559;&#35265;&#12290;&#36825;&#31181;&#20559;&#35265;&#21487;&#33021;&#23384;&#22312;&#20110;&#19968;&#20010;&#25110;&#22810;&#20010;&#21463;&#20445;&#25252;&#23646;&#24615;&#30340;&#19981;&#21516;&#32452;&#20043;&#38388;&#65292;&#24182;&#21487;&#33021;&#23548;&#33268;&#23545;&#26576;&#20123;&#20154;&#32676;&#30340;&#20559;&#35265;&#21644;&#27495;&#35270;&#24615;&#32467;&#26524;&#12290;&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#25193;&#20805;&#26041;&#27861;MASC&#65292;&#21033;&#29992;&#20146;&#21644;&#24615;&#32858;&#31867;&#24179;&#34913;&#30446;&#26631;&#25968;&#25454;&#38598;&#30340;&#38750;&#20445;&#25252;&#32452;&#21644;&#20445;&#25252;&#32452;&#34920;&#24449;&#12290;&#36890;&#36807;&#23558;&#21516;&#19968;&#20445;&#25252;&#23646;&#24615;&#30340;&#23454;&#20363;&#20174;&#30456;&#20284;&#25968;&#25454;&#38598;&#20013;&#36827;&#34892;&#32858;&#31867;&#65292;&#20849;&#20139;&#26469;&#33258;&#21463;&#20445;&#25252;&#23646;&#24615;&#30340;&#23454;&#20363;&#12290;&#35813;&#26041;&#27861;&#21253;&#25324;&#36890;&#36807;&#37327;&#21270;&#25968;&#25454;&#38598;&#38388;&#30340;&#20998;&#24067;&#24046;&#24322;&#26500;&#24314;&#20146;&#21644;&#30697;&#38453;&#65292;&#24182;&#23558;&#20854;&#36716;&#25442;&#20026;&#23545;&#31216;&#25104;&#23545;&#30456;&#20284;&#24615;&#30697;&#38453;&#12290;&#20351;&#29992;&#38750;&#21442;&#25968;&#30340;&#35889;&#32858;&#31867;&#31639;&#27861;&#23545;&#30446;&#26631;&#25968;&#25454;&#38598;&#36827;&#34892;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Group imbalance, resulting from inadequate or unrepresentative data collection methods, is a primary cause of representation bias in datasets. Representation bias can exist with respect to different groups of one or more protected attributes and might lead to prejudicial and discriminatory outcomes toward certain groups of individuals; in cases where a learning model is trained on such biased data. This paper presents MASC, a data augmentation approach that leverages affinity clustering to balance the representation of non-protected and protected groups of a target dataset by utilizing instances of the same protected attributes from similar datasets that are categorized in the same cluster as the target dataset by sharing instances of the protected attribute. The proposed method involves constructing an affinity matrix by quantifying distribution discrepancies between dataset pairs and transforming them into a symmetric pairwise similarity matrix. A non-parametric spectral clustering i
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;ODE&#30340;RNN&#27169;&#22411;&#65292;&#36890;&#36807;&#35843;&#25972;&#26102;&#38388;&#27493;&#38271;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#22788;&#29702;&#23574;&#23792;&#22411;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#12290;&#27169;&#22411;&#21487;&#20197;&#26377;&#25928;&#20272;&#35745;Hawkes&#31867;&#22411;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#24378;&#24230;&#20989;&#25968;&#65292;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#39044;&#27979;&#31934;&#24230;&#24182;&#20943;&#23569;&#35745;&#31639;&#28040;&#32791;&#12290;</title><link>http://arxiv.org/abs/2306.01674</link><description>&lt;p&gt;
&#20855;&#26377;&#33258;&#36866;&#24212;&#26102;&#38388;&#27493;&#38271;&#30340;&#31070;&#32463;&#24494;&#20998;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Neural Differential Recurrent Neural Network with Adaptive Time Steps. (arXiv:2306.01674v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01674
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;ODE&#30340;RNN&#27169;&#22411;&#65292;&#36890;&#36807;&#35843;&#25972;&#26102;&#38388;&#27493;&#38271;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#22788;&#29702;&#23574;&#23792;&#22411;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#12290;&#27169;&#22411;&#21487;&#20197;&#26377;&#25928;&#20272;&#35745;Hawkes&#31867;&#22411;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#24378;&#24230;&#20989;&#25968;&#65292;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#39044;&#27979;&#31934;&#24230;&#24182;&#20943;&#23569;&#35745;&#31639;&#28040;&#32791;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#27169;&#22411;&#24050;&#32463;&#22312;&#20174;&#31163;&#25955;&#26102;&#38388;&#25139;&#30340;&#35266;&#27979;&#20013;&#23398;&#20064;&#22797;&#26434;&#30340;&#36830;&#32493;&#26102;&#38388;&#36807;&#31243;&#26041;&#38754;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;&#26412;&#25991;&#32771;&#34385;&#24314;&#27169;&#21644;&#39044;&#27979;&#19968;&#20123;&#21487;&#33021;&#20855;&#26377;&#23574;&#23792;&#31561;&#38160;&#21464;&#30340;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;RNN&#30340;&#27169;&#22411;&#65292;&#31216;&#20026;RNN-ODE-Adap&#65292;&#23427;&#20351;&#29992;&#31070;&#32463;ODE&#26469;&#34920;&#31034;&#38544;&#34255;&#29366;&#24577;&#30340;&#26102;&#38388;&#21457;&#23637;&#65292;&#24182;&#26681;&#25454;&#25968;&#25454;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#38497;&#23789;&#31243;&#24230;&#33258;&#36866;&#24212;&#22320;&#36873;&#25321;&#26102;&#38388;&#27493;&#38271;&#65292;&#20197;&#26356;&#39640;&#25928;&#22320;&#35757;&#32451;"&#23574;&#23792;"&#26102;&#38388;&#24207;&#21015;&#30340;&#27169;&#22411;&#12290;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;RNN-ODE-Adap&#21487;&#26377;&#25928;&#22320;&#20272;&#35745;Hawkes&#31867;&#22411;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#24378;&#24230;&#20989;&#25968;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#20851;&#20110;RNN-ODE&#27169;&#22411;&#30340;&#36817;&#20284;&#20998;&#26512;&#65292;&#26174;&#31034;&#20102;&#33258;&#36866;&#24212;&#27493;&#38271;&#30340;&#20248;&#21183;&#12290;&#22312;&#27169;&#25311;&#21160;&#24577;&#31995;&#32479;&#25968;&#25454;&#21644;&#28857;&#36807;&#31243;&#25968;&#25454;&#19978;&#30340;&#27979;&#35797;&#20013;&#65292;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#35777;&#26126;&#20102;&#20855;&#26377;&#26356;&#39640;&#30340;&#39044;&#27979;&#31934;&#24230;&#21644;&#26356;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
The neural Ordinary Differential Equation (ODE) model has shown success in learning complex continuous-time processes from observations on discrete time stamps. In this work, we consider the modeling and forecasting of time series data that are non-stationary and may have sharp changes like spikes. We propose an RNN-based model, called RNN-ODE-Adap, that uses a neural ODE to represent the time development of the hidden states, and we adaptively select time steps based on the steepness of changes of the data over time so as to train the model more efficiently for the "spike-like" time series. Theoretically, RNN-ODE-Adap yields provably a consistent estimation of the intensity function for the Hawkes-type time series data. We also provide an approximation analysis of the RNN-ODE model showing the benefit of adaptive steps. The proposed model is demonstrated to achieve higher prediction accuracy with reduced computational cost on simulated dynamic system data and point process data and on
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21464;&#20998;&#26041;&#27861;&#26469;&#32479;&#19968;&#20998;&#26512;&#29983;&#25104;&#22120;&#30340;&#20248;&#21270;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;f-&#25955;&#24230;&#26368;&#23567;&#21270;&#21644;IPM GAN&#20013;&#29983;&#25104;&#22120;&#30340;&#26368;&#20248;&#35299;&#20915;&#26041;&#26696;&#12290;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#24179;&#28369;&#20998;&#25968;&#21305;&#37197;&#12290;</title><link>http://arxiv.org/abs/2306.01654</link><description>&lt;p&gt;
GANs&#35299;&#20915;&#20998;&#25968;&#20105;&#35758;&#38382;&#39064;&#65281;
&lt;/p&gt;
&lt;p&gt;
GANs Settle Scores!. (arXiv:2306.01654v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01654
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21464;&#20998;&#26041;&#27861;&#26469;&#32479;&#19968;&#20998;&#26512;&#29983;&#25104;&#22120;&#30340;&#20248;&#21270;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;f-&#25955;&#24230;&#26368;&#23567;&#21270;&#21644;IPM GAN&#20013;&#29983;&#25104;&#22120;&#30340;&#26368;&#20248;&#35299;&#20915;&#26041;&#26696;&#12290;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#24179;&#28369;&#20998;&#25968;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#30001;&#19968;&#20010;&#29983;&#25104;&#22120;&#21644;&#19968;&#20010;&#21028;&#21035;&#22120;&#32452;&#25104;&#65292;&#29983;&#25104;&#22120;&#34987;&#35757;&#32451;&#20197;&#23398;&#20064;&#26399;&#26395;&#25968;&#25454;&#30340;&#22522;&#30784;&#20998;&#24067;&#65292;&#32780;&#21028;&#21035;&#22120;&#21017;&#34987;&#35757;&#32451;&#20197;&#21306;&#20998;&#30495;&#23454;&#26679;&#26412;&#21644;&#29983;&#25104;&#22120;&#36755;&#20986;&#30340;&#26679;&#26412;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21464;&#20998;&#26041;&#27861;&#26469;&#20998;&#26512;&#29983;&#25104;&#22120;&#20248;&#21270;&#12290;&#22312;f-&#25955;&#24230;&#26368;&#23567;&#21270; GAN &#20013;&#65292;&#25105;&#20204;&#34920;&#26126;&#26368;&#20248;&#29983;&#25104;&#22120;&#26159;&#36890;&#36807;&#23558;&#20854;&#36755;&#20986;&#20998;&#24067;&#30340;&#24471;&#20998;&#19982;&#25968;&#25454;&#20998;&#24067;&#30340;&#24471;&#20998;&#36827;&#34892;&#21305;&#37197;&#24471;&#21040;&#30340;&#12290;&#22312;IPM GAN&#20013;&#65292;&#25105;&#20204;&#34920;&#26126;&#36825;&#20010;&#26368;&#20248;&#29983;&#25104;&#22120;&#21305;&#37197;&#24471;&#20998;&#22411;&#20989;&#25968;&#65292;&#21253;&#25324;&#19982;&#25152;&#36873;IPM&#32422;&#26463;&#31354;&#38388;&#30456;&#20851;&#30340;&#26680;&#27969;&#22330;&#12290;&#27492;&#22806;&#65292;IPM-GAN&#20248;&#21270;&#21487;&#20197;&#30475;&#20316;&#26159;&#24179;&#28369;&#20998;&#25968;&#21305;&#37197;&#20013;&#30340;&#19968;&#31181;&#65292;&#20854;&#20013;&#25968;&#25454;&#21644;&#29983;&#25104;&#22120;&#20998;&#24067;&#30340;&#24471;&#20998;&#19982;&#22312;&#26680;&#20989;&#25968;&#19978;&#36827;&#34892;&#21367;&#31215;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative adversarial networks (GANs) comprise a generator, trained to learn the underlying distribution of the desired data, and a discriminator, trained to distinguish real samples from those output by the generator. A majority of GAN literature focuses on understanding the optimality of the discriminator through integral probability metric (IPM) or divergence based analysis. In this paper, we propose a unified approach to analyzing the generator optimization through variational approach. In $f$-divergence-minimizing GANs, we show that the optimal generator is the one that matches the score of its output distribution with that of the data distribution, while in IPM GANs, we show that this optimal generator matches score-like functions, involving the flow-field of the kernel associated with a chosen IPM constraint space. Further, the IPM-GAN optimization can be seen as one of smoothed score-matching, where the scores of the data and the generator distributions are convolved with the 
&lt;/p&gt;</description></item><item><title>&#20154;&#31867;&#19987;&#23478;&#30340;&#20215;&#20540;&#36229;&#20986;&#20102;&#31639;&#27861;&#21487;&#25429;&#25417;&#33539;&#22260;&#65292;&#25105;&#20204;&#21487;&#20197;&#29992;&#19968;&#20010;&#31616;&#21333;&#30340;&#31243;&#24207;&#27979;&#35797;&#36825;&#20010;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.01646</link><description>&lt;p&gt;
&#20154;&#31867;&#19987;&#23478;&#23457;&#26680;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Auditing for Human Expertise. (arXiv:2306.01646v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01646
&lt;/p&gt;
&lt;p&gt;
&#20154;&#31867;&#19987;&#23478;&#30340;&#20215;&#20540;&#36229;&#20986;&#20102;&#31639;&#27861;&#21487;&#25429;&#25417;&#33539;&#22260;&#65292;&#25105;&#20204;&#21487;&#20197;&#29992;&#19968;&#20010;&#31616;&#21333;&#30340;&#31243;&#24207;&#27979;&#35797;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#39118;&#38505;&#39044;&#27979;&#20219;&#21153;&#65288;&#20363;&#22914;&#24739;&#32773;&#35786;&#26029;&#65289;&#36890;&#24120;&#30001;&#25509;&#21463;&#22521;&#35757;&#30340;&#20154;&#31867;&#19987;&#23478;&#22788;&#29702;&#12290;&#22312;&#36825;&#20123;&#35774;&#32622;&#20013;&#65292;&#33258;&#21160;&#21270;&#30340;&#19968;&#20010;&#24120;&#35265;&#38382;&#39064;&#26159;&#65292;&#19987;&#23478;&#21487;&#33021;&#36816;&#29992;&#24456;&#38590;&#24314;&#27169;&#30340;&#30452;&#35273;&#65292;&#24182;&#19988;/&#25110;&#32773;&#21487;&#20197;&#33719;&#21462;&#20449;&#24687;&#65288;&#20363;&#22914;&#19982;&#24739;&#32773;&#30340;&#20132;&#35848;&#65289;&#65292;&#36825;&#20123;&#20449;&#24687;&#23545;&#20110;&#31639;&#27861;&#26469;&#35828;&#26159;&#19981;&#21487;&#29992;&#30340;&#12290;&#36825;&#24341;&#21457;&#20102;&#19968;&#20010;&#33258;&#28982;&#30340;&#38382;&#39064;&#65292;&#20154;&#31867;&#19987;&#23478;&#26159;&#21542;&#22686;&#21152;&#20102;&#26080;&#27861;&#34987;&#31639;&#27861;&#39044;&#27979;&#22120;&#25429;&#25417;&#21040;&#30340;&#20215;&#20540;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#32479;&#35745;&#26694;&#26550;&#65292;&#21487;&#20197;&#23558;&#36825;&#20010;&#38382;&#39064;&#25552;&#20986;&#20026;&#19968;&#20010;&#33258;&#28982;&#30340;&#20551;&#35774;&#26816;&#39564;&#12290;&#27491;&#22914;&#25105;&#20204;&#30340;&#26694;&#26550;&#25152;&#24378;&#35843;&#30340;&#37027;&#26679;&#65292;&#26816;&#27979;&#20154;&#31867;&#19987;&#19994;&#30693;&#35782;&#27604;&#31616;&#21333;&#27604;&#36739;&#19987;&#23478;&#39044;&#27979;&#20934;&#30830;&#24615;&#19982;&#29305;&#23450;&#23398;&#20064;&#31639;&#27861;&#20570;&#20986;&#30340;&#20934;&#30830;&#24615;&#26356;&#21152;&#24494;&#22937;&#12290;&#32780;&#26159;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#31243;&#24207;&#65292;&#27979;&#35797;&#19987;&#23478;&#39044;&#27979;&#26159;&#21542;&#22312;&#8220;&#29305;&#24449;&#8221;&#21487;&#29992;&#32780;&#26465;&#20214;&#19979;&#26159;&#21542;&#19982;&#24863;&#20852;&#36259;&#30340;&#32467;&#26524;&#32479;&#35745;&#19978;&#29420;&#31435;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#27979;&#35797;&#30340;&#25298;&#32477;&#34920;&#26126;&#20102;&#20154;&#31867;&#19987;&#19994;&#30693;&#35782;&#30830;&#23454;&#22686;&#21152;&#20102;&#36229;&#20986;&#31639;&#27861;&#21487;&#25429;&#25417;&#33539;&#22260;&#30340;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
High-stakes prediction tasks (e.g., patient diagnosis) are often handled by trained human experts. A common source of concern about automation in these settings is that experts may exercise intuition that is difficult to model and/or have access to information (e.g., conversations with a patient) that is simply unavailable to a would-be algorithm. This raises a natural question whether human experts add value which could not be captured by an algorithmic predictor. We develop a statistical framework under which we can pose this question as a natural hypothesis test. Indeed, as our framework highlights, detecting human expertise is more subtle than simply comparing the accuracy of expert predictions to those made by a particular learning algorithm. Instead, we propose a simple procedure which tests whether expert predictions are statistically independent from the outcomes of interest after conditioning on the available inputs (`features'). A rejection of our test thus suggests that huma
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#31350;&#20102;&#22914;&#20309;&#21033;&#29992;&#20998;&#23618;&#32972;&#26223;&#30693;&#35782;&#26469;&#38480;&#21046;&#31561;&#20215;&#31867;&#65292;&#20174;&#32780;&#26377;&#25928;&#31616;&#21270;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#21644;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#20851;&#20110;&#32972;&#26223;&#30693;&#35782;&#26377;&#25928;&#30340;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2306.01638</link><description>&lt;p&gt;
&#38543;&#30528;&#26102;&#38388;&#30340;&#25512;&#31227;&#25105;&#20204;&#26159;&#21542;&#21464;&#24471;&#26356;&#21152;&#32874;&#26126;&#65311;&#20851;&#20110;&#20998;&#23618;&#32972;&#26223;&#30693;&#35782;&#30340;&#22240;&#26524;&#31561;&#20215;&#24615;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Do we become wiser with time? On causal equivalence with tiered background knowledge. (arXiv:2306.01638v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01638
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#31350;&#20102;&#22914;&#20309;&#21033;&#29992;&#20998;&#23618;&#32972;&#26223;&#30693;&#35782;&#26469;&#38480;&#21046;&#31561;&#20215;&#31867;&#65292;&#20174;&#32780;&#26377;&#25928;&#31616;&#21270;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#21644;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#20851;&#20110;&#32972;&#26223;&#30693;&#35782;&#26377;&#25928;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#31561;&#20215;&#31867;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;&#36890;&#36807;CPDAGs&#34920;&#31034;&#65289;&#21487;&#33021;&#36807;&#20110;&#24222;&#22823;&#65292;&#26080;&#27861;&#25552;&#20379;&#26377;&#29992;&#30340;&#22240;&#26524;&#20449;&#24687;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#22914;&#20309;&#25972;&#21512;&#20998;&#23618;&#32972;&#26223;&#30693;&#35782;&#26469;&#38480;&#21046;&#31561;&#20215;&#31867;&#65292;&#20174;&#32780;&#24471;&#20986;&#30001;&#8220;&#20998;&#23618;MPDAGs&#8221;&#34920;&#31034;&#30340;&#31561;&#20215;&#31867;&#12290;&#20351;&#29992;&#20998;&#23618;&#30693;&#35782;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#20449;&#24687;&#37327;&#21644;&#35745;&#31639;&#25928;&#29575;&#65306;&#25105;&#20204;&#34920;&#26126;&#65292;&#26500;&#24314;&#20998;&#23618;MPDAGs&#21482;&#38656;&#35201;&#24212;&#29992;Meek&#30340;&#31532;&#19968;&#27861;&#21017;&#65292;&#24182;&#19988;&#20998;&#23618;MPDAG&#65288;&#19981;&#21516;&#20110;&#19968;&#33324;&#30340;MPDAG&#65289;&#26159;&#20855;&#26377;&#24358;&#22270;&#32452;&#25104;&#37096;&#20998;&#30340;&#38142;&#22270;&#12290;&#36825;&#24102;&#26469;&#20102;&#31616;&#21270;&#65292;&#20363;&#22914;&#30830;&#23450;&#29992;&#20110;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#30340;&#26377;&#25928;&#35843;&#25972;&#38598;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#34920;&#24449;&#20102;&#20309;&#26102;&#19968;&#31181;&#20998;&#23618;&#25490;&#24207;&#27604;&#21478;&#19968;&#31181;&#26356;&#20855;&#20449;&#24687;&#37327;&#65292;&#20174;&#32780;&#25552;&#20379;&#20102;&#20851;&#20110;&#32972;&#26223;&#30693;&#35782;&#26377;&#29992;&#30340;&#26041;&#38754;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Equivalence classes of DAGs (represented by CPDAGs) may be too large to provide useful causal information. Here, we address incorporating tiered background knowledge yielding restricted equivalence classes represented by 'tiered MPDAGs'. Tiered knowledge leads to considerable gains in informativeness and computational efficiency: We show that construction of tiered MPDAGs only requires application of Meek's 1st rule, and that tiered MPDAGs (unlike general MPDAGs) are chain graphs with chordal components. This entails simplifications e.g. of determining valid adjustment sets for causal effect estimation. Further, we characterise when one tiered ordering is more informative than another, providing insights into useful aspects of background knowledge.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32771;&#34385;&#25915;&#20987;&#23545;&#36229;&#21442;&#25968;&#24433;&#21709;&#30340;&#26368;&#20248;&#25915;&#20987;&#20844;&#24335;&#65292;&#23558;&#25915;&#20987;&#24314;&#27169;&#20026;&#22810;&#30446;&#26631;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#35780;&#20272;&#31639;&#27861;&#40065;&#26834;&#24615;&#21644;&#23398;&#20064;&#36229;&#21442;&#25968;&#65292;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#35780;&#20272;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2306.01613</link><description>&lt;p&gt;
&#25968;&#25454;&#27745;&#26579;&#19979;&#30340;&#36229;&#21442;&#25968;&#23398;&#20064;&#65306;&#22522;&#20110;&#22810;&#30446;&#26631;&#20108;&#23618;&#20248;&#21270;&#30340;&#27491;&#21017;&#21270;&#24433;&#21709;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Hyperparameter Learning under Data Poisoning: Analysis of the Influence of Regularization via Multiobjective Bilevel Optimization. (arXiv:2306.01613v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01613
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32771;&#34385;&#25915;&#20987;&#23545;&#36229;&#21442;&#25968;&#24433;&#21709;&#30340;&#26368;&#20248;&#25915;&#20987;&#20844;&#24335;&#65292;&#23558;&#25915;&#20987;&#24314;&#27169;&#20026;&#22810;&#30446;&#26631;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#35780;&#20272;&#31639;&#27861;&#40065;&#26834;&#24615;&#21644;&#23398;&#20064;&#36229;&#21442;&#25968;&#65292;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#35780;&#20272;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#23481;&#26131;&#36973;&#21463;&#25968;&#25454;&#27745;&#26579;&#25915;&#20987;&#65292;&#21363;&#36890;&#36807;&#25805;&#32437;&#37096;&#20998;&#35757;&#32451;&#25968;&#25454;&#26469;&#26377;&#24847;&#30772;&#22351;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;&#26368;&#20248;&#25915;&#20987;&#21487;&#20197;&#34987;&#21046;&#23450;&#20026;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#26377;&#21161;&#20110;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#35780;&#20272;&#31639;&#27861;&#30340;&#24378;&#20581;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#24403;&#21069;&#30340;&#26041;&#27861;&#36890;&#24120;&#20551;&#23450;&#36229;&#21442;&#25968;&#20445;&#25345;&#19981;&#21464;&#65292;&#36825;&#23548;&#33268;&#20102;&#23545;&#31639;&#27861;&#40065;&#26834;&#24615;&#21644;&#27491;&#21017;&#21270;&#24433;&#21709;&#30340;&#36807;&#20110;&#24754;&#35266;&#30340;&#35266;&#28857;&#12290;&#22240;&#27492;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26368;&#20248;&#25915;&#20987;&#20844;&#24335;&#65292;&#32771;&#34385;&#25915;&#20987;&#23545;&#36229;&#21442;&#25968;&#30340;&#24433;&#21709;&#65292;&#24182;&#23558;&#25915;&#20987;&#24314;&#27169;&#20026;&#22810;&#30446;&#26631;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#12290;&#36825;&#20801;&#35768;&#21046;&#23450;&#26368;&#20248;&#25915;&#20987;&#12289;&#23398;&#20064;&#36229;&#21442;&#25968;&#24182;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#35780;&#20272;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#23558;&#27492;&#25915;&#20987;&#20844;&#24335;&#24212;&#29992;&#20110;&#20351;&#29992;$L_2$&#21644;$L_1$&#27491;&#21017;&#21270;&#30340;&#22810;&#20010;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#19978;&#12290;&#25105;&#20204;&#23545;&#22810;&#20010;&#25968;&#25454;&#38598;&#30340;&#35780;&#20272;&#30830;&#35748;&#20102;&#20808;&#21069;&#31574;&#30053;&#30340;&#38480;&#21046;&#65292;&#24182;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#31934;&#30830;&#30340;&#40065;&#26834;&#24615;&#35780;&#20272;&#21644;&#22312;&#23384;&#22312;&#25968;&#25454;&#27745;&#26579;&#25915;&#20987;&#26102;&#26356;&#26377;&#25928;&#22320;&#23398;&#20064;&#36229;&#21442;&#25968;&#30340;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine Learning (ML) algorithms are vulnerable to poisoning attacks, where a fraction of the training data is manipulated to deliberately degrade the algorithms' performance. Optimal attacks can be formulated as bilevel optimization problems and help to assess their robustness in worst-case scenarios. We show that current approaches, which typically assume that hyperparameters remain constant, lead to an overly pessimistic view of the algorithms' robustness and of the impact of regularization. We propose a novel optimal attack formulation that considers the effect of the attack on the hyperparameters and models the attack as a multiobjective bilevel optimization problem. This allows to formulate optimal attacks, learn hyperparameters and evaluate robustness under worst-case conditions. We apply this attack formulation to several ML classifiers using $L_2$ and $L_1$ regularization. Our evaluation on multiple datasets confirms the limitations of previous strategies and evidences the ben
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#21033;&#29992;&#31526;&#21512;&#24615;&#39044;&#27979;&#20998;&#24067;&#35780;&#20272;&#26426;&#22120;&#32763;&#35793;&#36136;&#37327;&#30340;&#26032;&#26041;&#27861;&#65292;&#21516;&#26102;&#35780;&#20272;&#32763;&#35793;&#36136;&#37327;&#24182;&#25552;&#20379;&#21487;&#38752;&#30340;&#32622;&#20449;&#24230;&#24471;&#20998;&#65292;&#22312;&#20845;&#31181;&#19981;&#21516;&#30340;&#35821;&#35328;&#23545;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#20248;&#20110;&#22522;&#32447;&#26041;&#27861;&#65292;&#38656;&#35201;&#25968;&#25454;&#21487;&#20132;&#25442;&#24615;&#20551;&#35774;&#25165;&#33021;&#23454;&#29616;&#26368;&#20339;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.01549</link><description>&lt;p&gt;
&#21033;&#29992;&#31526;&#21512;&#24615;&#39044;&#27979;&#20998;&#24067;&#35780;&#20272;&#26426;&#22120;&#32763;&#35793;&#36136;&#37327;
&lt;/p&gt;
&lt;p&gt;
Evaluating Machine Translation Quality with Conformal Predictive Distributions. (arXiv:2306.01549v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01549
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#21033;&#29992;&#31526;&#21512;&#24615;&#39044;&#27979;&#20998;&#24067;&#35780;&#20272;&#26426;&#22120;&#32763;&#35793;&#36136;&#37327;&#30340;&#26032;&#26041;&#27861;&#65292;&#21516;&#26102;&#35780;&#20272;&#32763;&#35793;&#36136;&#37327;&#24182;&#25552;&#20379;&#21487;&#38752;&#30340;&#32622;&#20449;&#24230;&#24471;&#20998;&#65292;&#22312;&#20845;&#31181;&#19981;&#21516;&#30340;&#35821;&#35328;&#23545;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#20248;&#20110;&#22522;&#32447;&#26041;&#27861;&#65292;&#38656;&#35201;&#25968;&#25454;&#21487;&#20132;&#25442;&#24615;&#20551;&#35774;&#25165;&#33021;&#23454;&#29616;&#26368;&#20339;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21516;&#26102;&#35780;&#20272;&#32763;&#35793;&#36136;&#37327;&#24182;&#25552;&#20379;&#21487;&#38752;&#30340;&#32622;&#20449;&#24230;&#24471;&#20998;&#65292;&#26469;&#35780;&#20272;&#26426;&#22120;&#32763;&#35793;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#31526;&#21512;&#24615;&#39044;&#27979;&#20998;&#24067;&#26469;&#20135;&#29983;&#20855;&#26377;&#20445;&#35777;&#35206;&#30422;&#29575;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#36825;&#24847;&#21619;&#30528;&#23545;&#20110;&#20219;&#20309;&#32473;&#23450;&#30340;&#26174;&#33879;&#24615;&#27700;&#24179;$\epsilon$&#65292;&#25105;&#20204;&#21487;&#20197;&#26399;&#26395;&#19968;&#20010;&#32763;&#35793;&#30340;&#30495;&#23454;&#36136;&#37327;&#24471;&#20998;&#20197;$1-\epsilon$&#30340;&#36895;&#29575;&#33853;&#22312;&#21306;&#38388;&#20869;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22914;&#20309;&#22312;&#20845;&#31181;&#19981;&#21516;&#30340;&#35821;&#35328;&#23545;&#19978;&#65292;&#22312;&#35206;&#30422;&#29575;&#21644;&#38160;&#24230;&#26041;&#38754;&#20248;&#20110;&#31616;&#21333;&#20294;&#26377;&#25928;&#30340;&#22522;&#32447;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#38656;&#35201;&#25968;&#25454;&#21487;&#20132;&#25442;&#24615;&#20551;&#35774;&#25165;&#33021;&#23454;&#29616;&#26368;&#20339;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a new approach for assessing uncertainty in machine translation by simultaneously evaluating translation quality and providing a reliable confidence score. Our approach utilizes conformal predictive distributions to produce prediction intervals with guaranteed coverage, meaning that for any given significance level $\epsilon$, we can expect the true quality score of a translation to fall out of the interval at a rate of $1-\epsilon$. In this paper, we demonstrate how our method outperforms a simple, but effective baseline on six different language pairs in terms of coverage and sharpness. Furthermore, we validate that our approach requires the data exchangeability assumption to hold for optimal performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21457;&#29616;&#32593;&#32476;&#21155;&#21270;&#29616;&#35937;&#65292;&#36825;&#20250;&#24433;&#21709;&#32593;&#32476;&#35757;&#32451;&#24182;&#23548;&#33268;&#20854;&#34920;&#29616;&#19981;&#20339;&#12290;&#25105;&#20204;&#36824;&#20351;&#29992;&#20102;&#19968;&#31181;&#31616;&#21333;&#31639;&#27861;&#26469;&#39044;&#27979;&#32593;&#32476;&#21155;&#21270;&#30340;&#27700;&#24179;&#12290;</title><link>http://arxiv.org/abs/2306.01513</link><description>&lt;p&gt;
&#32593;&#32476;&#21155;&#21270;&#20316;&#20026;&#35757;&#32451;&#24615;&#33021;&#35780;&#20272;&#30340;&#25351;&#26631;&#65306;&#26377;&#38480;&#21644;&#26080;&#38480;&#23485;&#24230;&#35282;&#24230;&#39044;&#27979;&#30340;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Network Degeneracy as an Indicator of Training Performance: Comparing Finite and Infinite Width Angle Predictions. (arXiv:2306.01513v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01513
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21457;&#29616;&#32593;&#32476;&#21155;&#21270;&#29616;&#35937;&#65292;&#36825;&#20250;&#24433;&#21709;&#32593;&#32476;&#35757;&#32451;&#24182;&#23548;&#33268;&#20854;&#34920;&#29616;&#19981;&#20339;&#12290;&#25105;&#20204;&#36824;&#20351;&#29992;&#20102;&#19968;&#31181;&#31616;&#21333;&#31639;&#27861;&#26469;&#39044;&#27979;&#32593;&#32476;&#21155;&#21270;&#30340;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#26159;&#21151;&#33021;&#24378;&#22823;&#19988;&#24191;&#27867;&#20351;&#29992;&#30340;&#26041;&#27861;&#65292;&#20294;&#20854;&#29702;&#35770;&#34892;&#20026;&#24182;&#27809;&#26377;&#23436;&#20840;&#34987;&#29702;&#35299;&#12290;&#36890;&#36807;&#22534;&#21472;&#35768;&#22810;&#23618;&#65292;&#21487;&#20197;&#21019;&#24314;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#20986;&#33394;&#30340;&#24615;&#33021;&#65292;&#24182;&#20419;&#25104;&#20102;&#26368;&#36817;&#36825;&#20123;&#26041;&#27861;&#30340;&#29190;&#28856;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#28145;&#24230;&#21487;&#20197;&#25351;&#25968;&#32423;&#22686;&#21152;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#32593;&#32476;&#36234;&#26469;&#36234;&#28145;&#65292;&#23427;&#20204;&#36234;&#26469;&#36234;&#23481;&#26131;&#21464;&#24471;&#21155;&#21270;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#36825;&#31181;&#36864;&#21270;&#29616;&#35937;&#65292;&#22240;&#20026;&#22312;&#21021;&#22987;&#21270;&#26102;&#65292;&#36755;&#20837;&#20542;&#21521;&#20110;&#22312;&#36890;&#36807;&#32593;&#32476;&#30340;&#23618;&#26102;&#21464;&#24471;&#36234;&#26469;&#36234;&#30456;&#20851;&#12290;&#22914;&#26524;&#19968;&#20010;&#32593;&#32476;&#26377;&#22826;&#22810;&#23618;&#65292;&#23427;&#20542;&#21521;&#20110;&#36924;&#36817;&#19968;&#20010;&#65288;&#38543;&#26426;&#30340;&#65289;&#24120;&#25968;&#20989;&#25968;&#65292;&#26377;&#25928;&#22320;&#26080;&#27861;&#21306;&#20998;&#36755;&#20837;&#12290;&#25105;&#20204;&#22312;&#26412;&#25991;&#20013;&#36827;&#34892;&#20102;&#23454;&#35777;&#30740;&#31350;&#65292;&#21457;&#29616;&#36825;&#20284;&#20046;&#24433;&#21709;&#20102;&#32593;&#32476;&#30340;&#35757;&#32451;&#65292;&#24182;&#23548;&#33268;&#23427;&#34920;&#29616;&#19981;&#20339;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#31181;&#31616;&#21333;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#20934;&#30830;&#22320;&#39044;&#27979;&#32593;&#32476;&#36798;&#21040;&#30340;&#21155;&#21270;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural networks are powerful functions with widespread use, but the theoretical behaviour of these functions is not fully understood. Creating deep neural networks by stacking many layers has achieved exceptional performance in many applications and contributed to the recent explosion of these methods. Previous works have shown that depth can exponentially increase the expressibility of the network. However, as networks get deeper and deeper, they are more susceptible to becoming degenerate. We observe this degeneracy in the sense that on initialization, inputs tend to become more and more correlated as they travel through the layers of the network. If a network has too many layers, it tends to approximate a (random) constant function, making it effectively incapable of distinguishing between inputs. This seems to affect the training of the network and cause it to perform poorly, as we empirically investigate in this paper. We use a simple algorithm that can accurately predict the leve
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35821;&#35328;&#20064;&#24471;&#21451;&#22909;&#22411;&#22522;&#20934;&#65292;&#20197;&#26816;&#39564;&#33258;&#25105;&#30417;&#30563;&#21475;&#35821;&#35821;&#35328;&#27169;&#22411;&#22312;&#20799;&#31461;&#35789;&#27719;&#21644;&#21477;&#27861;&#32463;&#21382;&#20013;&#30340;&#34920;&#29616;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#38656;&#35201;&#35299;&#20915;&#30340;&#25361;&#25112;&#65306;&#25991;&#26412;&#21644;&#35821;&#38899;&#20043;&#38388;&#30340;&#24046;&#36317;&#21644;&#24178;&#20928;&#35821;&#38899;&#21644;&#37326;&#22806;&#35821;&#38899;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2306.01506</link><description>&lt;p&gt;
BabySLM: &#33258;&#25105;&#30417;&#30563;&#21475;&#35821;&#35821;&#35328;&#27169;&#22411;&#30340;&#35821;&#35328;&#20064;&#24471;&#21451;&#22909;&#22411;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
BabySLM: language-acquisition-friendly benchmark of self-supervised spoken language models. (arXiv:2306.01506v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01506
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35821;&#35328;&#20064;&#24471;&#21451;&#22909;&#22411;&#22522;&#20934;&#65292;&#20197;&#26816;&#39564;&#33258;&#25105;&#30417;&#30563;&#21475;&#35821;&#35821;&#35328;&#27169;&#22411;&#22312;&#20799;&#31461;&#35789;&#27719;&#21644;&#21477;&#27861;&#32463;&#21382;&#20013;&#30340;&#34920;&#29616;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#38656;&#35201;&#35299;&#20915;&#30340;&#25361;&#25112;&#65306;&#25991;&#26412;&#21644;&#35821;&#38899;&#20043;&#38388;&#30340;&#24046;&#36317;&#21644;&#24178;&#20928;&#35821;&#38899;&#21644;&#37326;&#22806;&#35821;&#38899;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24050;&#32463;&#35777;&#26126;&#65292;&#23398;&#20064;&#35821;&#38899;&#34920;&#31034;&#30340;&#33258;&#25105;&#30417;&#30563;&#25216;&#26415;&#33021;&#22815;&#20174;&#21548;&#21040;&#30340;&#35821;&#38899;&#20013;&#21457;&#23637;&#20986;&#35821;&#35328;&#33021;&#21147;&#65292;&#32780;&#26080;&#38656;&#20154;&#31867;&#26631;&#31614;&#12290;&#20026;&#20102;&#20805;&#20998;&#21457;&#25381;&#36825;&#20123;&#26041;&#27861;&#30340;&#28508;&#21147;&#24182;&#36827;&#19968;&#27493;&#20102;&#35299;&#23156;&#20799;&#23398;&#20064;&#35821;&#35328;&#30340;&#26041;&#24335;&#65292;&#27169;&#25311;&#24517;&#39035;&#32039;&#23494;&#27169;&#20223;&#29616;&#23454;&#24773;&#20917;&#65292;&#36890;&#36807;&#22312;&#24320;&#21457;&#19978;&#31526;&#21512;&#20799;&#31461;&#35821;&#35328;&#32463;&#39564;&#20856;&#22411;&#35789;&#27719;&#24211;&#21644;&#23545;&#24212;&#27979;&#35797;&#38598;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26816;&#27979;&#22312;&#35789;&#27719;&#21644;&#21477;&#27861;&#23618;&#38754;&#19978;&#30340;&#21475;&#35821;&#35821;&#35328;&#27169;&#22411;&#30340;&#35821;&#35328;&#20064;&#24471;&#21451;&#22909;&#22411;&#22522;&#20934;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#27492;&#22522;&#20934;&#65292;&#24182;&#24635;&#32467;&#20102;&#19968;&#31995;&#21015;&#23454;&#39564;&#65292;&#35777;&#26126;&#20854;&#26377;&#29992;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24378;&#35843;&#20102;&#38656;&#35201;&#35299;&#20915;&#30340;&#20004;&#20010;&#25361;&#25112;&#65306;&#22635;&#34917;&#25991;&#26412;&#21644;&#35821;&#38899;&#20043;&#38388;&#20197;&#21450;&#24178;&#20928;&#35821;&#38899;&#21644;&#37326;&#22806;&#35821;&#38899;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-supervised techniques for learning speech representations have been shown to develop linguistic competence from exposure to speech without the need for human labels. In order to fully realize the potential of these approaches and further our understanding of how infants learn language, simulations must closely emulate real-life situations by training on developmentally plausible corpora and benchmarking against appropriate test sets. To this end, we propose a language-acquisition-friendly benchmark to probe spoken language models at the lexical and syntactic levels, both of which are compatible with the vocabulary typical of children's language experiences. This paper introduces the benchmark and summarizes a range of experiments showing its usefulness. In addition, we highlight two exciting challenges that need to be addressed for further progress: bridging the gap between text and speech and between clean speech and in-the-wild speech.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#36861;&#21152;&#27491;&#20132;&#32422;&#26463;&#65292;&#20174;&#32780;&#22312;&#20445;&#25345;&#20302;&#31209;&#30697;&#38453;&#20998;&#35299;&#21069;&#25552;&#19979;&#25552;&#39640;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;&#19982;&#20934;&#30830;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.01485</link><description>&lt;p&gt;
&#36890;&#36807;&#36817;&#20284;&#30340;&#27491;&#20132;&#32422;&#26463;&#23454;&#29616;&#31283;&#20581;&#30340;&#20302;&#31209;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
Robust low-rank training via approximate orthonormal constraints. (arXiv:2306.01485v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01485
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#36861;&#21152;&#27491;&#20132;&#32422;&#26463;&#65292;&#20174;&#32780;&#22312;&#20445;&#25345;&#20302;&#31209;&#30697;&#38453;&#20998;&#35299;&#21069;&#25552;&#19979;&#25552;&#39640;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;&#19982;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#27169;&#22411;&#21644;&#25968;&#25454;&#35268;&#27169;&#30340;&#22686;&#38271;&#65292;&#35774;&#35745;&#21098;&#26525;&#25216;&#26415;&#20197;&#38477;&#20302;&#28145;&#24230;&#23398;&#20064;&#27969;&#31243;&#30340;&#36164;&#28304;&#38656;&#27714;&#24182;&#20445;&#25345;&#27169;&#22411;&#24615;&#33021;&#24050;&#25104;&#20026;&#24191;&#27867;&#21162;&#21147;&#30340;&#30446;&#26631;&#12290;&#20026;&#20102;&#38477;&#20302;&#25512;&#29702;&#21644;&#35757;&#32451;&#25104;&#26412;&#65292;&#20027;&#35201;&#30340;&#24037;&#20316;&#26041;&#21521;&#20043;&#19968;&#20351;&#29992;&#20302;&#31209;&#30697;&#38453;&#20998;&#35299;&#26469;&#34920;&#31034;&#32593;&#32476;&#26435;&#37325;&#12290;&#23613;&#31649;&#33021;&#22815;&#20445;&#25345;&#20934;&#30830;&#24615;&#65292;&#20294;&#25105;&#20204;&#35266;&#23519;&#21040;&#20302;&#31209;&#26041;&#27861;&#24448;&#24448;&#20250;&#25439;&#23475;&#27169;&#22411;&#23545;&#25239;&#25200;&#21160;&#30340;&#40065;&#26834;&#24615;&#12290;&#36890;&#36807;&#23558;&#31283;&#20581;&#24615;&#24314;&#27169;&#20026;&#31070;&#32463;&#32593;&#32476;&#30340;&#26465;&#20214;&#25968;&#65292;&#25105;&#20204;&#35748;&#20026;&#36825;&#31181;&#31283;&#20581;&#24615;&#25439;&#22833;&#26159;&#30001;&#20110;&#20302;&#31209;&#26435;&#37325;&#30697;&#38453;&#30340;&#22855;&#24322;&#20540;&#29190;&#28856;&#24341;&#36215;&#30340;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31283;&#20581;&#30340;&#20302;&#31209;&#35757;&#32451;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#20445;&#25345;&#32593;&#32476;&#26435;&#37325;&#20301;&#20110;&#20302;&#31209;&#30697;&#38453;&#27969;&#24418;&#19978;&#30340;&#21516;&#26102;&#65292;&#21516;&#26102;&#24378;&#21046;&#26045;&#21152;&#36817;&#20284;&#30340;&#27491;&#20132;&#32422;&#26463;&#12290;&#22240;&#27492;&#65292;&#35813;&#27169;&#22411;&#38477;&#20302;&#20102;&#35757;&#32451;&#21644;&#25512;&#29702;&#25104;&#26412;&#65292;&#21516;&#26102;&#30830;&#20445;&#20102;&#33391;&#22909;&#30340;&#26465;&#20214;&#24615;&#21644;&#26356;&#22909;&#30340;&#25239;&#24178;&#25200;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the growth of model and data sizes, a broad effort has been made to design pruning techniques that reduce the resource demand of deep learning pipelines, while retaining model performance. In order to reduce both inference and training costs, a prominent line of work uses low-rank matrix factorizations to represent the network weights. Although able to retain accuracy, we observe that low-rank methods tend to compromise model robustness against adversarial perturbations. By modeling robustness in terms of the condition number of the neural network, we argue that this loss of robustness is due to the exploding singular values of the low-rank weight matrices. Thus, we introduce a robust low-rank training algorithm that maintains the network's weights on the low-rank matrix manifold while simultaneously enforcing approximate orthonormal constraints. The resulting model reduces both training and inference costs while ensuring well-conditioning and thus better adversarial robustness, w
&lt;/p&gt;</description></item><item><title>&#28145;&#24230;&#23398;&#20064;&#20013;&#24120;&#29992;&#30340;MLP&#26377;&#28508;&#21147;&#25552;&#39640;&#24615;&#33021;&#12290;&#26412;&#30740;&#31350;&#25581;&#31034;MLP-Mixer &#21487;&#20197;&#20316;&#20026;&#20855;&#26377;&#31232;&#30095;&#26435;&#37325;&#30340;&#23485;MLP&#26377;&#25928;&#22320;&#24037;&#20316;&#12290;</title><link>http://arxiv.org/abs/2306.01470</link><description>&lt;p&gt;
MLP-Mixer&#20316;&#20026;&#23485;&#19988;&#31232;&#30095;&#30340;MLP
&lt;/p&gt;
&lt;p&gt;
MLP-Mixer as a Wide and Sparse MLP. (arXiv:2306.01470v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01470
&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#20013;&#24120;&#29992;&#30340;MLP&#26377;&#28508;&#21147;&#25552;&#39640;&#24615;&#33021;&#12290;&#26412;&#30740;&#31350;&#25581;&#31034;MLP-Mixer &#21487;&#20197;&#20316;&#20026;&#20855;&#26377;&#31232;&#30095;&#26435;&#37325;&#30340;&#23485;MLP&#26377;&#25928;&#22320;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#23618;&#24863;&#30693;&#22120;(MLP)&#26159;&#28145;&#24230;&#23398;&#20064;&#20013;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#22810;&#31181;&#38382;&#39064;&#30340;&#22522;&#30784;&#32452;&#20214;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#22522;&#20110;MLP&#30340;&#26550;&#26500;(&#29305;&#21035;&#26159;MLP-Mixer)&#30340;&#23454;&#35777;&#25104;&#21151;&#34920;&#26126;&#65292;&#25552;&#39640;MLP&#30340;&#24615;&#33021;&#20173;&#20855;&#26377;&#28508;&#22312;&#30340;&#28508;&#21147;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;MLP-Mixer&#26377;&#25928;&#22320;&#20316;&#20026;&#20855;&#26377;&#26576;&#20123;&#31232;&#30095;&#26435;&#37325;&#30340;&#23485;MLP&#12290;&#26368;&#21021;&#65292;&#25105;&#20204;&#28548;&#28165;Mixer&#30340;&#28151;&#21512;&#23618;&#21487;&#20197;&#20316;&#20026;&#20855;&#26377;&#31232;&#30095;&#26435;&#37325;&#19988;&#30001;Kronecker&#20056;&#31215;&#34920;&#31034;&#30340;&#26356;&#23485;MLP&#30340;&#26377;&#25928;&#34920;&#36798;&#12290;&#35813;&#34920;&#36798;&#24335;&#33258;&#28982;&#22320;&#23450;&#20041;&#20102;&#19968;&#32452;&#32622;&#25442;-Kronecker(PK)&#23478;&#26063;&#65292;&#21487;&#20197;&#34987;&#35270;&#20026;&#28151;&#21512;&#23618;&#30340;&#19968;&#33324;&#31867;&#65292;&#20063;&#21487;&#20197;&#34987;&#35270;&#20026;Monarch&#30697;&#38453;&#30340;&#19968;&#31181;&#36817;&#20284;&#12290;&#38543;&#21518;&#65292;&#30001;&#20110;PK&#23478;&#26063;&#26377;&#25928;&#26500;&#25104;&#20855;&#26377;&#31232;&#30095;&#26435;&#37325;&#30340;&#23485;MLP&#65292;&#22240;&#27492;&#65292;&#21487;&#20197;&#24212;&#29992;Golubeva&#12289;Neyshabur&#21644;Gur-Ari(2021)&#25552;&#20986;&#30340;&#20551;&#35774;&#65292;&#21363;&#39044;&#27979;&#24615;&#33021;&#65306;
&lt;/p&gt;
&lt;p&gt;
Multi-layer perceptron (MLP) is a fundamental component of deep learning that has been extensively employed for various problems. However, recent empirical successes in MLP-based architectures, particularly the progress of the MLP-Mixer, have revealed that there is still hidden potential in improving MLPs to achieve better performance. In this study, we reveal that the MLP-Mixer works effectively as a wide MLP with certain sparse weights. Initially, we clarify that the mixing layer of the Mixer has an effective expression as a wider MLP whose weights are sparse and represented by the Kronecker product. This expression naturally defines a permuted-Kronecker (PK) family, which can be regarded as a general class of mixing layers and is also regarded as an approximation of Monarch matrices. Subsequently, because the PK family effectively constitutes a wide MLP with sparse weights, one can apply the hypothesis proposed by Golubeva, Neyshabur and Gur-Ari (2021) that the prediction performanc
&lt;/p&gt;</description></item><item><title>&#35813;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;Bayesian&#38750;&#21442;&#25968;&#23398;&#20064;&#26694;&#26550;&#65292;&#23545;&#20110;&#27979;&#37327;&#35823;&#24046;&#20855;&#26377;&#24378;&#40065;&#26834;&#24615;&#65292;&#19981;&#38656;&#35201;&#30693;&#36947;&#35823;&#24046;&#20998;&#24067;&#21644;&#21327;&#21464;&#37327;&#21487;&#37325;&#22797;&#27979;&#37327;&#30340;&#20551;&#35774;&#65292;&#24182;&#33021;&#22815;&#21560;&#25910;&#20808;&#39564;&#20449;&#24565;&#65292;&#36825;&#33021;&#20135;&#29983;&#20004;&#31181;&#36890;&#36807;&#19981;&#21516;&#25439;&#22833;&#20989;&#25968;&#30340;&#27979;&#37327;&#35823;&#24046;&#24378;&#40065;&#26834;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.01468</link><description>&lt;p&gt;
&#27979;&#37327;&#35823;&#24046;&#27169;&#22411;&#30340;&#24378;&#40065;&#26834;&#24615;Bayesian&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Robust Bayesian Inference for Measurement Error Models. (arXiv:2306.01468v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01468
&lt;/p&gt;
&lt;p&gt;
&#35813;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;Bayesian&#38750;&#21442;&#25968;&#23398;&#20064;&#26694;&#26550;&#65292;&#23545;&#20110;&#27979;&#37327;&#35823;&#24046;&#20855;&#26377;&#24378;&#40065;&#26834;&#24615;&#65292;&#19981;&#38656;&#35201;&#30693;&#36947;&#35823;&#24046;&#20998;&#24067;&#21644;&#21327;&#21464;&#37327;&#21487;&#37325;&#22797;&#27979;&#37327;&#30340;&#20551;&#35774;&#65292;&#24182;&#33021;&#22815;&#21560;&#25910;&#20808;&#39564;&#20449;&#24565;&#65292;&#36825;&#33021;&#20135;&#29983;&#20004;&#31181;&#36890;&#36807;&#19981;&#21516;&#25439;&#22833;&#20989;&#25968;&#30340;&#27979;&#37327;&#35823;&#24046;&#24378;&#40065;&#26834;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27979;&#37327;&#35823;&#24046;&#26159;&#25351;&#24433;&#21709;&#21709;&#24212;&#21464;&#37327;&#30340;&#21327;&#21464;&#37327;&#21463;&#21040;&#22122;&#22768;&#24178;&#25200;&#12290;&#36825;&#21487;&#33021;&#20250;&#23548;&#33268;&#35823;&#23548;&#24615;&#30340;&#25512;&#26029;&#32467;&#26524;&#65292;&#23588;&#20854;&#26159;&#22312;&#20272;&#35745;&#21327;&#21464;&#37327;&#21644;&#21709;&#24212;&#21464;&#37327;&#20043;&#38388;&#20851;&#31995;&#30340;&#20934;&#30830;&#24615;&#33267;&#20851;&#37325;&#35201;&#30340;&#38382;&#39064;&#20013;&#65292;&#22914;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#38382;&#39064;&#20013;&#12290;&#29616;&#26377;&#30340;&#22788;&#29702;&#27979;&#37327;&#35823;&#24046;&#30340;&#26041;&#27861;&#36890;&#24120;&#20381;&#36182;&#20110;&#24378;&#20551;&#35774;&#65292;&#20363;&#22914;&#23545;&#35823;&#24046;&#20998;&#24067;&#25110;&#20854;&#26041;&#24046;&#30340;&#30693;&#35782;&#21644;&#21327;&#21464;&#37327;&#21487;&#37325;&#22797;&#27979;&#37327;&#30340;&#21487;&#29992;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;Bayesian&#38750;&#21442;&#25968;&#23398;&#20064;&#26694;&#26550;&#65292;&#23427;&#23545;&#20110;&#27979;&#37327;&#35823;&#24046;&#20855;&#26377;&#24378;&#40065;&#26834;&#24615;&#65292;&#19981;&#38656;&#35201;&#19978;&#36848;&#20551;&#35774;&#65292;&#24182;&#33021;&#22815;&#21560;&#25910;&#20851;&#20110;&#30495;&#23454;&#35823;&#24046;&#20998;&#24067;&#30340;&#20808;&#39564;&#20449;&#24565;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20135;&#29983;&#20102;&#20004;&#31181;&#36890;&#36807;&#19981;&#21516;&#25439;&#22833;&#20989;&#25968;&#30340;&#27979;&#37327;&#35823;&#24046;&#24378;&#40065;&#26834;&#26041;&#27861;&#65306;&#19968;&#31181;&#22522;&#20110;&#24635;&#26368;&#23567;&#20108;&#20056;&#30446;&#26631;&#65292;&#21478;&#19968;&#31181;&#22522;&#20110;&#26368;&#22823;&#24179;&#22343;&#20559;&#24046;&#65288;MMD&#65289;&#12290;&#21518;&#32773;&#20801;&#35768;&#25512;&#24191;&#21040;&#38750;&#39640;&#26031;&#20998;&#24067;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Measurement error occurs when a set of covariates influencing a response variable are corrupted by noise. This can lead to misleading inference outcomes, particularly in problems where accurately estimating the relationship between covariates and response variables is crucial, such as causal effect estimation. Existing methods for dealing with measurement error often rely on strong assumptions such as knowledge of the error distribution or its variance and availability of replicated measurements of the covariates. We propose a Bayesian Nonparametric Learning framework which is robust to mismeasured covariates, does not require the preceding assumptions, and is able to incorporate prior beliefs about the true error distribution. Our approach gives rise to two methods that are robust to measurement error via different loss functions: one based on the Total Least Squares objective and the other based on Maximum Mean Discrepancy (MMD). The latter allows for generalisation to non-Gaussian d
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#32508;&#21512;&#30740;&#31350;&#34920;&#26126;&#65292;XAI &#26041;&#27861;&#22312;&#23384;&#22312;&#25233;&#21046;&#21464;&#37327;&#26102;&#35299;&#37322;&#21487;&#33021;&#20986;&#29616;&#35823;&#23548;&#24615;&#65292;&#38656;&#35201;&#36827;&#34892;&#26356;&#21152;&#29702;&#35770;&#21270;&#21644;&#32463;&#39564;&#21270;&#30340;&#30740;&#31350;&#65292;&#30830;&#20445;&#20854;&#24212;&#29992;&#30340;&#27491;&#30830;&#24615;&#21644;&#21487;&#33021;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.01464</link><description>&lt;p&gt;
&#23384;&#22312;&#25233;&#21046;&#21464;&#37327;&#26102; XAI &#26041;&#27861;&#30340;&#29702;&#35770;&#34892;&#20026;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Theoretical Behavior of XAI Methods in the Presence of Suppressor Variables. (arXiv:2306.01464v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01464
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#32508;&#21512;&#30740;&#31350;&#34920;&#26126;&#65292;XAI &#26041;&#27861;&#22312;&#23384;&#22312;&#25233;&#21046;&#21464;&#37327;&#26102;&#35299;&#37322;&#21487;&#33021;&#20986;&#29616;&#35823;&#23548;&#24615;&#65292;&#38656;&#35201;&#36827;&#34892;&#26356;&#21152;&#29702;&#35770;&#21270;&#21644;&#32463;&#39564;&#21270;&#30340;&#30740;&#31350;&#65292;&#30830;&#20445;&#20854;&#24212;&#29992;&#30340;&#27491;&#30830;&#24615;&#21644;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#8220;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#8221;&#65288;XAI&#65289;&#31038;&#21306;&#24050;&#32463;&#21019;&#24314;&#20102;&#19968;&#20010;&#22823;&#37327;&#30340;&#26041;&#27861;&#26469;&#24357;&#21512;&#27169;&#22411;&#8220;&#22797;&#26434;&#24230;&#8221;&#21644;&#8220;&#21487;&#35299;&#37322;&#24615;&#8221;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#28982;&#32780;&#65292;XAI &#26041;&#27861;&#38656;&#35201;&#35299;&#20915;&#30340;&#20855;&#20307;&#38382;&#39064;&#23578;&#26410;&#24471;&#21040;&#27491;&#24335;&#35828;&#26126;&#12290;&#22240;&#27492;&#65292;XAI &#26041;&#27861;&#32570;&#20047;&#29702;&#35770;&#21644;&#23454;&#35777;&#35777;&#25454;&#65292;&#20197;&#39564;&#35777;&#20854;&#35299;&#37322;&#30340;&#8220;&#27491;&#30830;&#24615;&#8221;&#65292;&#38480;&#21046;&#20102;&#20854;&#29992;&#20110;&#36136;&#37327;&#25511;&#21046;&#21644;&#36879;&#26126;&#24230;&#30446;&#30340;&#30340;&#28508;&#21147;&#12290;&#21516;&#26102;&#65292;Haufe&#31561;&#20154;&#65288;2014&#65289;&#20351;&#29992;&#31616;&#21333;&#30340;&#29609;&#20855;&#20363;&#23376;&#23637;&#31034;&#20102;&#21363;&#20351;&#26159;&#32447;&#24615;&#27169;&#22411;&#30340;&#26631;&#20934;&#35299;&#37322;&#20063;&#21487;&#33021;&#26497;&#20855;&#35823;&#23548;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#21487;&#33021;&#20250;&#34987;&#24402;&#22240;&#20110;&#25152;&#35859;&#30340;&#25233;&#21046;&#21464;&#37327;&#65292;&#36825;&#20123;&#21464;&#37327;&#19982;&#39044;&#27979;&#30446;&#26631;&#32570;&#20047;&#20219;&#20309;&#32479;&#35745;&#20851;&#31995;&#12290;Wilming&#31561;&#20154;&#65288;2022&#65289;&#24050;&#32463;&#32463;&#39564;&#35777;&#20102;&#36825;&#31181;&#34892;&#20026;&#22312;&#22823;&#37327; XAI &#26041;&#27861;&#20013;&#30340;&#23454;&#35777;&#30740;&#31350;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25512;&#23548;&#20102;&#22810;&#31181;&#27969;&#34892;&#30340; XAI &#26041;&#27861;&#22312;&#31616;&#21333;&#30340; toy dataset &#19978;&#30340;&#34892;&#20026;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, the community of 'explainable artificial intelligence' (XAI) has created a vast body of methods to bridge a perceived gap between model 'complexity' and 'interpretability'. However, a concrete problem to be solved by XAI methods has not yet been formally stated. As a result, XAI methods are lacking theoretical and empirical evidence for the 'correctness' of their explanations, limiting their potential use for quality-control and transparency purposes. At the same time, Haufe et al. (2014) showed, using simple toy examples, that even standard interpretations of linear models can be highly misleading. Specifically, high importance may be attributed to so-called suppressor variables lacking any statistical relation to the prediction target. This behavior has been confirmed empirically for a large array of XAI methods in Wilming et al. (2022). Here, we go one step further by deriving analytical expressions for the behavior of a variety of popular XAI methods on a simple tw
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#31070;&#32463;&#21160;&#21147;&#23398;&#30340;&#35299;&#37322;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23545;&#25239;&#35757;&#32451;&#26694;&#26550;&#65292;&#36890;&#36807;&#36880;&#27493;&#26356;&#26032;&#36755;&#20837;&#26469;&#38477;&#20302;&#39044;&#27979;&#29109;&#65292;&#20174;&#32780;&#25552;&#39640;DEQ&#27169;&#22411;&#30340;&#23545;&#25239;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.01435</link><description>&lt;p&gt;
&#36890;&#36807;&#31070;&#32463;&#21160;&#21147;&#23398;&#30340;&#26174;&#24335;&#35268;&#23450;&#26469;&#25552;&#39640;DEQ&#27169;&#22411;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Improving Adversarial Robustness of DEQs with Explicit Regulations Along the Neural Dynamics. (arXiv:2306.01435v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01435
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#31070;&#32463;&#21160;&#21147;&#23398;&#30340;&#35299;&#37322;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23545;&#25239;&#35757;&#32451;&#26694;&#26550;&#65292;&#36890;&#36807;&#36880;&#27493;&#26356;&#26032;&#36755;&#20837;&#26469;&#38477;&#20302;&#39044;&#27979;&#29109;&#65292;&#20174;&#32780;&#25552;&#39640;DEQ&#27169;&#22411;&#30340;&#23545;&#25239;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24179;&#34913;&#65288; DEQ &#65289;&#27169;&#22411;&#23558;&#20256;&#32479;&#28145;&#23618;&#32593;&#32476;&#30340;&#22810;&#23618;&#22534;&#21472;&#26367;&#25442;&#20026;&#21333;&#23618;&#21464;&#25442;&#30340;&#19981;&#21160;&#28857;&#36845;&#20195;&#12290;&#24050;&#32463;&#35777;&#26126;&#22312;&#21508;&#31181;&#23454;&#38469;&#24212;&#29992;&#22330;&#26223;&#20013; DEQ &#27169;&#22411;&#20855;&#26377;&#31454;&#20105;&#20248;&#21183;&#65292;&#22240;&#27492;&#19968;&#33324; DEQ &#27169;&#22411;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#29616;&#26377;&#30340;&#24037;&#20316;&#36890;&#36807;&#24191;&#27867;&#20351;&#29992;&#30340;&#23545;&#25239;&#35757;&#32451;&#65288; AT&#65289;&#26694;&#26550;&#26469;&#25552;&#39640;&#19968;&#33324; DEQ &#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#65292;&#20294;&#23427;&#20204;&#26410;&#33021;&#21033;&#29992; DEQ &#27169;&#22411;&#30340;&#32467;&#26500;&#29420;&#29305;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#36890;&#36807;&#31070;&#32463;&#21160;&#21147;&#23398;&#30340;&#35270;&#35282;&#35299;&#37322; DEQs&#65292;&#24182;&#21457;&#29616; AT &#23545;&#20013;&#38388;&#29366;&#24577;&#36827;&#34892;&#20102;&#19981;&#20805;&#20998;&#30340;&#35268;&#23450;&#12290;&#27492;&#22806;&#65292;&#20013;&#38388;&#29366;&#24577;&#36890;&#24120;&#25552;&#20379;&#20855;&#26377;&#39640;&#39044;&#27979;&#29109;&#30340;&#39044;&#27979;&#12290;&#21463;&#21160;&#24577;&#31995;&#32479;&#29109;&#19982;&#20854;&#31283;&#23450;&#24615;&#36136;&#20043;&#38388;&#20851;&#32852;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#27839;&#30528;&#31070;&#32463;&#21160;&#21147;&#23398;&#36880;&#27493;&#26356;&#26032;&#36755;&#20837;&#26469;&#38477;&#20302;&#39044;&#27979;&#29109;&#12290;&#22312; AT &#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#36824;&#21033;&#29992;&#38543;&#26426;&#20013;&#38388;&#29366;&#24577;t
&lt;/p&gt;
&lt;p&gt;
Deep equilibrium (DEQ) models replace the multiple-layer stacking of conventional deep networks with a fixed-point iteration of a single-layer transformation. Having been demonstrated to be competitive in a variety of real-world scenarios, the adversarial robustness of general DEQs becomes increasingly crucial for their reliable deployment. Existing works improve the robustness of general DEQ models with the widely-used adversarial training (AT) framework, but they fail to exploit the structural uniquenesses of DEQ models. To this end, we interpret DEQs through the lens of neural dynamics and find that AT under-regulates intermediate states. Besides, the intermediate states typically provide predictions with a high prediction entropy. Informed by the correlation between the entropy of dynamical systems and their stability properties, we propose reducing prediction entropy by progressively updating inputs along the neural dynamics. During AT, we also utilize random intermediate states t
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#31350;&#20102;&#28145;&#24230;&#24179;&#34913;&#27169;&#22411;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20272;&#35745;&#20013;&#38388;&#26799;&#24230;&#20197;&#25913;&#36827;&#25915;&#20987;&#27969;&#31243;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.01429</link><description>&lt;p&gt;
&#28145;&#24230;&#24179;&#34913;&#27169;&#22411;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#20877;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Closer Look at the Adversarial Robustness of Deep Equilibrium Models. (arXiv:2306.01429v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01429
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#31350;&#20102;&#28145;&#24230;&#24179;&#34913;&#27169;&#22411;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20272;&#35745;&#20013;&#38388;&#26799;&#24230;&#20197;&#25913;&#36827;&#25915;&#20987;&#27969;&#31243;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24179;&#34913;&#27169;&#22411;&#65288;DEQ&#65289;&#25682;&#24323;&#20102;&#20256;&#32479;&#30340;&#23618;&#21472;&#26041;&#27861;&#65292;&#36716;&#32780;&#23547;&#25214;&#21333;&#19968;&#23618;&#30340;&#22266;&#23450;&#28857;&#12290;DEQ&#22312;&#19981;&#21516;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#21644;&#29305;&#24449;&#30340;&#20869;&#23384;&#25928;&#29575;&#12290;&#21516;&#26102;&#65292;DEQ&#30340;&#23545;&#25239;&#24615;&#28431;&#27934;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#12290;&#19968;&#20123;&#24037;&#20316;&#25552;&#20986;&#20102;&#23545;&#21333;&#35843;DEQ&#36827;&#34892;&#40065;&#26834;&#24615;&#39564;&#35777;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23545;&#20110;&#19968;&#33324;DEQ&#30340;&#32463;&#39564;&#40065;&#26834;&#24615;&#30340;&#30740;&#31350;&#36824;&#24456;&#26377;&#38480;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#23545;&#25239;&#35757;&#32451;&#30340;DEQ&#38656;&#35201;&#26356;&#22810;&#30340;&#21069;&#21521;&#27493;&#39588;&#25165;&#33021;&#36798;&#21040;&#24179;&#34913;&#29366;&#24577;&#65292;&#29978;&#33267;&#21487;&#33021;&#36829;&#21453;&#20854;&#22266;&#23450;&#28857;&#32467;&#26500;&#12290;&#27492;&#22806;&#65292;&#40657;&#30418;&#27714;&#35299;&#22120;&#23548;&#33268;DEQ&#30340;&#21069;&#21521;&#21644;&#21518;&#21521;&#36712;&#36857;&#19981;&#23545;&#40784;&#12290;&#36825;&#20123;&#20107;&#23454;&#22312;&#35780;&#20272;&#25110;&#23545;&#25239;&#24615;&#35757;&#32451;DEQ&#26102;&#20250;&#23548;&#33268;&#26799;&#24230;&#28151;&#28102;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20123;&#26041;&#27861;&#26469;&#20272;&#35745;DEQ&#30340;&#20013;&#38388;&#26799;&#24230;&#65292;&#24182;&#23558;&#20854;&#38598;&#25104;&#21040;&#25915;&#20987;&#27969;&#31243;&#20013;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26377;&#21161;&#20110;&#20805;&#20998;&#35780;&#20272;DEQ&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep equilibrium models (DEQs) refrain from the traditional layer-stacking paradigm and turn to find the fixed point of a single layer. DEQs have achieved promising performance on different applications with featured memory efficiency. At the same time, the adversarial vulnerability of DEQs raises concerns. Several works propose to certify robustness for monotone DEQs. However, limited efforts are devoted to studying empirical robustness for general DEQs. To this end, we observe that an adversarially trained DEQ requires more forward steps to arrive at the equilibrium state, or even violates its fixed-point structure. Besides, the forward and backward tracks of DEQs are misaligned due to the black-box solvers. These facts cause gradient obfuscation when applying the ready-made attacks to evaluate or adversarially train DEQs. Given this, we develop approaches to estimate the intermediate gradients of DEQs and integrate them into the attacking pipelines. Our approaches facilitate fully w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36830;&#32493;&#24615;&#32467;&#26524;&#30340;&#37096;&#20998;&#21453;&#20107;&#23454;&#35782;&#21035;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25935;&#24863;&#24615;&#27169;&#22411;&#8212;&#8212;&#26354;&#29575;&#25935;&#24863;&#27169;&#22411;&#65292;&#36890;&#36807;&#38480;&#21046;&#20989;&#25968;&#32423;&#38598;&#30340;&#26354;&#29575;&#26469;&#33719;&#24471;&#20449;&#24687;&#36793;&#30028;&#12290;</title><link>http://arxiv.org/abs/2306.01424</link><description>&lt;p&gt;
&#24102;&#26354;&#29575;&#25935;&#24863;&#27169;&#22411;&#30340;&#36830;&#32493;&#24615;&#32467;&#26524;&#30340;&#37096;&#20998;&#21453;&#20107;&#23454;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Partial Counterfactual Identification of Continuous Outcomes with a Curvature Sensitivity Model. (arXiv:2306.01424v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01424
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36830;&#32493;&#24615;&#32467;&#26524;&#30340;&#37096;&#20998;&#21453;&#20107;&#23454;&#35782;&#21035;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25935;&#24863;&#24615;&#27169;&#22411;&#8212;&#8212;&#26354;&#29575;&#25935;&#24863;&#27169;&#22411;&#65292;&#36890;&#36807;&#38480;&#21046;&#20989;&#25968;&#32423;&#38598;&#30340;&#26354;&#29575;&#26469;&#33719;&#24471;&#20449;&#24687;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#25512;&#26029;&#26088;&#22312;&#22238;&#31572;&#8220;&#22914;&#26524;&#8221;&#38382;&#39064;&#65292;&#22240;&#27492;&#23646;&#20110;Pearl&#22240;&#26524;&#20851;&#31995;&#38454;&#26799;&#20013;&#26368;&#31934;&#32454;&#30340;&#25512;&#29702;&#31867;&#22411;&#12290;&#29616;&#26377;&#30340;&#38024;&#23545;&#20855;&#26377;&#36830;&#32493;&#32467;&#26524;&#30340;&#21453;&#20107;&#23454;&#25512;&#26029;&#26041;&#27861;&#26088;&#22312;&#36827;&#34892;&#28857;&#35782;&#21035;&#65292;&#22240;&#27492;&#23545;&#22522;&#30784;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#36827;&#34892;&#20102;&#24378;&#26377;&#21147;&#19988;&#19981;&#33258;&#28982;&#30340;&#20551;&#35774;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25918;&#23485;&#20102;&#36825;&#20123;&#20551;&#35774;&#65292;&#26088;&#22312;&#36827;&#34892;&#36830;&#32493;&#32467;&#26524;&#30340;&#37096;&#20998;&#21453;&#20107;&#23454;&#35782;&#21035;&#65292;&#21363;&#24403;&#21453;&#20107;&#23454;&#26597;&#35810;&#23384;&#22312;&#20855;&#26377;&#20449;&#24687;&#36793;&#30028;&#30340;&#26080;&#30693;&#21306;&#38388;&#20013;&#26102;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#65292;&#21363;&#20351;&#26159;&#36830;&#32493;&#21487;&#24494;&#30340;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20989;&#25968;&#30340;&#32423;&#38598;&#30340;&#26354;&#29575;&#20063;&#26159;&#38750;&#20449;&#24687;&#30340;&#65292;&#21453;&#20107;&#23454;&#26597;&#35810;&#30340;&#26080;&#30693;&#21306;&#38388;&#20063;&#26159;&#38750;&#20449;&#24687;&#30340;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25935;&#24863;&#24615;&#27169;&#22411;&#31216;&#20026;&#26354;&#29575;&#25935;&#24863;&#27169;&#22411;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#23427;&#20801;&#35768;&#25105;&#20204;&#36890;&#36807;&#38480;&#21046;&#20989;&#25968;&#32423;&#38598;&#30340;&#26354;&#29575;&#26469;&#33719;&#24471;&#20449;&#24687;&#36793;&#30028;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#29616;&#26377;&#30340;&#28857;&#21453;&#20107;&#23454;&#35782;&#21035;&#26041;&#27861;&#21487;&#20197;&#35270;&#20026;&#25105;&#20204;&#25552;&#20986;&#26694;&#26550;&#30340;&#29305;&#23450;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactual inference aims to answer retrospective ''what if'' questions and thus belongs to the most fine-grained type of inference in Pearl's causality ladder. Existing methods for counterfactual inference with continuous outcomes aim at point identification and thus make strong and unnatural assumptions about the underlying structural causal model. In this paper, we relax these assumptions and aim at partial counterfactual identification of continuous outcomes, i.e., when the counterfactual query resides in an ignorance interval with informative bounds. We prove that, in general, the ignorance interval of the counterfactual queries has non-informative bounds, already when functions of structural causal models are continuously differentiable. As a remedy, we propose a novel sensitivity model called Curvature Sensitivity Model. This allows us to obtain informative bounds by bounding the curvature of level sets of the functions. We further show that existing point counterfactual ide
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20351;&#29992;GPT-4&#35299;&#20915;&#26356;&#22797;&#26434;&#21644;&#26377;&#25361;&#25112;&#24615;&#30340;&#25968;&#23398;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MathChat&#30340;&#23545;&#35805;&#24335;&#38382;&#39064;&#27714;&#35299;&#26694;&#26550;&#65292;&#24182;&#22312;&#22256;&#38590;&#39640;&#20013;&#31454;&#36187;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2306.01337</link><description>&lt;p&gt;
&#22522;&#20110;GPT-4&#30340;&#22797;&#26434;&#25968;&#23398;&#38382;&#39064;&#27714;&#35299;&#30340;&#23454;&#35777;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
An Empirical Study on Challenging Math Problem Solving with GPT-4. (arXiv:2306.01337v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01337
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20351;&#29992;GPT-4&#35299;&#20915;&#26356;&#22797;&#26434;&#21644;&#26377;&#25361;&#25112;&#24615;&#30340;&#25968;&#23398;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MathChat&#30340;&#23545;&#35805;&#24335;&#38382;&#39064;&#27714;&#35299;&#26694;&#26550;&#65292;&#24182;&#22312;&#22256;&#38590;&#39640;&#20013;&#31454;&#36187;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26469;&#35299;&#20915;&#25968;&#23398;&#38382;&#39064;&#26159;&#19968;&#39033;&#26377;&#36259;&#30340;&#30740;&#31350;&#65292;&#32771;&#34385;&#21040;&#22312;&#21508;&#31181;&#31185;&#23398;&#21644;&#24037;&#31243;&#39046;&#22495;&#20013;&#29992;&#33258;&#28982;&#35821;&#35328;&#34920;&#36798;&#30340;&#25968;&#23398;&#38382;&#39064;&#30340;&#20016;&#23500;&#24615;&#12290;&#34429;&#28982;&#20043;&#21069;&#26377;&#20960;&#39033;&#24037;&#20316;&#30740;&#31350;&#20102;&#20351;&#29992;LLM&#35299;&#20915;&#21021;&#31561;&#25968;&#23398;&#38382;&#39064;&#65292;&#20294;&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#20351;&#29992;GPT-4&#35299;&#20915;&#26356;&#22797;&#26434;&#21644;&#26377;&#25361;&#25112;&#24615;&#30340;&#25968;&#23398;&#38382;&#39064;&#30340;&#21069;&#27839;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#20351;&#29992;GPT-4&#30340;&#21508;&#31181;&#26041;&#27861;&#12290;&#20854;&#20013;&#19968;&#20123;&#26159;&#20174;&#29616;&#26377;&#24037;&#20316;&#20013;&#25913;&#32534;&#32780;&#26469;&#30340;&#65292;&#20854;&#20013;&#19968;&#20010;&#26159;MathChat&#65292;&#36825;&#26159;&#26412;&#30740;&#31350;&#26032;&#25552;&#20986;&#30340;&#19968;&#31181;&#23545;&#35805;&#24335;&#38382;&#39064;&#27714;&#35299;&#26694;&#26550;&#12290;&#25105;&#20204;&#22312;&#26469;&#33258;MATH&#25968;&#25454;&#38598;&#30340;&#22256;&#38590;&#39640;&#20013;&#31454;&#36187;&#38382;&#39064;&#19978;&#36827;&#34892;&#35780;&#20272;&#65292;&#34920;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#23545;&#35805;&#24335;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Employing Large Language Models (LLMs) to address mathematical problems is an intriguing research endeavor, considering the abundance of math problems expressed in natural language across numerous science and engineering fields. While several prior works have investigated solving elementary mathematics using LLMs, this work explores the frontier of using GPT-4 for solving more complex and challenging math problems. We evaluate various ways of using GPT-4. Some of them are adapted from existing work, and one is \MathChat, a conversational problem-solving framework newly proposed in this work. We perform the evaluation on difficult high school competition problems from the MATH dataset, which shows the advantage of the proposed conversational approach.
&lt;/p&gt;</description></item><item><title>&#23545;&#25239;&#35757;&#32451;&#26159;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25239;&#20987;&#23545;&#25239;&#25200;&#21160;&#30340;&#26631;&#20934;&#26041;&#27861;, &#20854;&#23398;&#20064;&#26426;&#21046;&#23548;&#33268;&#24178;&#20928;&#27867;&#21270;&#21644;&#24378;&#20581;&#36807;&#25311;&#21512;&#29616;&#35937;&#21516;&#26102;&#21457;&#29983;&#12290;</title><link>http://arxiv.org/abs/2306.01271</link><description>&lt;p&gt;
&#20026;&#20160;&#20040;&#22312;&#23545;&#25239;&#35757;&#32451;&#20013;&#20250;&#21516;&#26102;&#20986;&#29616;&#24178;&#20928;&#27867;&#21270;&#21644;&#24378;&#20581;&#36807;&#25311;&#21512;&#29616;&#35937;&#65311;
&lt;/p&gt;
&lt;p&gt;
Why Clean Generalization and Robust Overfitting Both Happen in Adversarial Training. (arXiv:2306.01271v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01271
&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#35757;&#32451;&#26159;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25239;&#20987;&#23545;&#25239;&#25200;&#21160;&#30340;&#26631;&#20934;&#26041;&#27861;, &#20854;&#23398;&#20064;&#26426;&#21046;&#23548;&#33268;&#24178;&#20928;&#27867;&#21270;&#21644;&#24378;&#20581;&#36807;&#25311;&#21512;&#29616;&#35937;&#21516;&#26102;&#21457;&#29983;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#35757;&#32451;&#26159;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25239;&#20987;&#23545;&#25239;&#25200;&#21160;&#30340;&#26631;&#20934;&#26041;&#27861;&#12290;&#19982;&#22312;&#26631;&#20934;&#28145;&#24230;&#23398;&#20064;&#29615;&#22659;&#20013;&#20986;&#29616;&#24778;&#20154;&#30340;&#24178;&#20928;&#27867;&#21270;&#33021;&#21147;&#31867;&#20284;&#65292;&#36890;&#36807;&#23545;&#25239;&#35757;&#32451;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#20063;&#33021;&#24456;&#22909;&#22320;&#27867;&#21270;&#21040;&#26410;&#35265;&#36807;&#30340;&#24178;&#20928;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#19982;&#24178;&#20928;&#27867;&#21270;&#19981;&#21516;&#30340;&#26159;&#65292;&#23613;&#31649;&#23545;&#25239;&#35757;&#32451;&#33021;&#22815;&#23454;&#29616;&#20302;&#40065;&#26834;&#35757;&#32451;&#35823;&#24046;&#65292;&#20173;&#23384;&#22312;&#26174;&#33879;&#30340;&#40065;&#26834;&#27867;&#21270;&#36317;&#31163;&#65292;&#36825;&#20419;&#20351;&#25105;&#20204;&#25506;&#32034;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#23548;&#33268;&#24178;&#20928;&#27867;&#21270;&#21644;&#24378;&#20581;&#36807;&#25311;&#21512;&#29616;&#35937;&#21516;&#26102;&#21457;&#29983;&#30340;&#26426;&#21046;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#25239;&#35757;&#32451;&#20013;&#36825;&#31181;&#29616;&#35937;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#25239;&#35757;&#32451;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#20998;&#26512;&#20102;&#29305;&#24449;&#23398;&#20064;&#36807;&#31243;&#65292;&#35299;&#37322;&#20102;&#23545;&#25239;&#35757;&#32451;&#22914;&#20309;&#23548;&#33268;&#32593;&#32476;&#23398;&#20064;&#32773;&#36827;&#20837;&#21040;&#24178;&#20928;&#27867;&#21270;&#21644;&#24378;&#20581;&#36807;&#25311;&#21512;&#29366;&#24577;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#36890;&#36807;&#36843;&#20351;&#23398;&#20064;&#22120;&#25104;&#20026;&#24378;&#39044;&#27979;&#32593;&#32476;&#65292;&#23545;&#25239;&#35757;&#32451;&#23558;&#23548;&#33268;&#24178;&#20928;&#27867;&#21270;&#21644;&#40065;&#26834;&#36807;&#25311;&#21512;&#29616;&#35937;&#21516;&#26102;&#21457;&#29983;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial training is a standard method to train deep neural networks to be robust to adversarial perturbation. Similar to surprising $\textit{clean generalization}$ ability in the standard deep learning setting, neural networks trained by adversarial training also generalize well for $\textit{unseen clean data}$. However, in constrast with clean generalization, while adversarial training method is able to achieve low $\textit{robust training error}$, there still exists a significant $\textit{robust generalization gap}$, which promotes us exploring what mechanism leads to both $\textit{clean generalization and robust overfitting (CGRO)}$ during learning process. In this paper, we provide a theoretical understanding of this CGRO phenomenon in adversarial training. First, we propose a theoretical framework of adversarial training, where we analyze $\textit{feature learning process}$ to explain how adversarial training leads network learner to CGRO regime. Specifically, we prove that, u
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21457;&#23637;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#25216;&#26415;&#65292;&#24182;&#25512;&#24191;&#20102;&#24191;&#20041;&#24179;&#28369;&#24230;&#26465;&#20214;&#65292;&#20351;&#20984;&#21644;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#33719;&#24471;&#26356;&#24378;&#30340;&#32467;&#26524;&#12290;&#22312;&#35813;&#26465;&#20214;&#19979;&#65292;&#33719;&#24471;&#20102;&#65288;&#38543;&#26426;&#65289;&#26799;&#24230;&#19979;&#38477;&#21644;Nesterov&#21152;&#36895;&#26799;&#24230;&#26041;&#27861;&#30340;&#32463;&#20856;&#25910;&#25947;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.01264</link><description>&lt;p&gt;
&#24191;&#20041;&#24179;&#28369;&#24230;&#19979;&#30340;&#20984;&#21644;&#38750;&#20984;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Convex and Non-Convex Optimization under Generalized Smoothness. (arXiv:2306.01264v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01264
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21457;&#23637;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#25216;&#26415;&#65292;&#24182;&#25512;&#24191;&#20102;&#24191;&#20041;&#24179;&#28369;&#24230;&#26465;&#20214;&#65292;&#20351;&#20984;&#21644;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#33719;&#24471;&#26356;&#24378;&#30340;&#32467;&#26524;&#12290;&#22312;&#35813;&#26465;&#20214;&#19979;&#65292;&#33719;&#24471;&#20102;&#65288;&#38543;&#26426;&#65289;&#26799;&#24230;&#19979;&#38477;&#21644;Nesterov&#21152;&#36895;&#26799;&#24230;&#26041;&#27861;&#30340;&#32463;&#20856;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32463;&#20856;&#30340;&#20984;&#21644;&#38750;&#20984;&#20248;&#21270;&#26041;&#27861;&#30340;&#20998;&#26512;&#36890;&#24120;&#38656;&#35201;&#26799;&#24230;&#30340;Lipshitz&#24615;&#36136;&#65292;&#36825;&#38480;&#21046;&#20102;&#20998;&#26512;&#33539;&#22260;&#20165;&#38480;&#20110;&#20108;&#27425;&#20989;&#25968;&#30340;&#30028;&#38480;&#20869;&#12290;&#26368;&#36817;&#30340;&#24037;&#20316;&#25918;&#26494;&#20102;&#36825;&#20010;&#35201;&#27714;&#65292;&#36716;&#32780;&#20351;&#29992;&#19968;&#31181;&#38750;&#22343;&#21248;&#24179;&#28369;&#26465;&#20214;&#65292;&#20854;&#20013;Hessian&#33539;&#25968;&#21463;&#26799;&#24230;&#33539;&#25968;&#30340;&#20223;&#23556;&#20989;&#25968;&#38480;&#21046;&#65292;&#24182;&#36890;&#36807;&#26799;&#24230;&#35009;&#21098;&#35777;&#26126;&#20102;&#38750;&#20984;&#24773;&#20917;&#19979;&#30340;&#25910;&#25947;&#24615;&#65292;&#20551;&#35774;&#23384;&#22312;&#26377;&#30028;&#22122;&#22768;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25512;&#24191;&#20102;&#36825;&#31181;&#38750;&#22343;&#21248;&#24179;&#28369;&#26465;&#20214;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#21151;&#33021;&#24378;&#22823;&#30340;&#20998;&#26512;&#25216;&#26415;&#65292;&#21487;&#20197;&#27839;&#36712;&#36857;&#26041;&#21521;&#38480;&#21046;&#26799;&#24230;&#65292;&#20174;&#32780;&#33719;&#24471;&#26356;&#24378;&#30340;&#20984;&#21644;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#32467;&#26524;&#12290;&#29305;&#21035;&#22320;&#65292;&#22312;&#36825;&#20010;&#24191;&#20041;&#24179;&#28369;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#65288;&#38543;&#26426;&#65289;&#26799;&#24230;&#19979;&#38477;&#21644;Nesterov&#21152;&#36895;&#26799;&#24230;&#26041;&#27861;&#30340;&#32463;&#20856;&#25910;&#25947;&#29575;&#65292;&#36866;&#29992;&#20110;&#20984;&#21644;&#65288;&#25110;&#65289;&#38750;&#20984;&#35774;&#23450;&#12290;&#26032;&#30340;&#20998;&#26512;&#26041;&#27861;&#19981;&#38656;&#35201;&#26799;&#24230;&#35009;&#21098;&#65292;&#24182;&#20801;&#35768;&#26377;&#37325;&#23614;&#22122;&#22768;&#65292;&#36825;&#26159;&#19968;&#31181;&#38750;&#24120;&#23454;&#29992;&#30340;&#20248;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classical analysis of convex and non-convex optimization methods often requires the Lipshitzness of the gradient, which limits the analysis to functions bounded by quadratics. Recent work relaxed this requirement to a non-uniform smoothness condition with the Hessian norm bounded by an affine function of the gradient norm, and proved convergence in the non-convex setting via gradient clipping, assuming bounded noise. In this paper, we further generalize this non-uniform smoothness condition and develop a simple, yet powerful analysis technique that bounds the gradients along the trajectory, thereby leading to stronger results for both convex and non-convex optimization problems. In particular, we obtain the classical convergence rates for (stochastic) gradient descent and Nesterov's accelerated gradient method in the convex and/or non-convex setting under this general smoothness condition. The new analysis approach does not require gradient clipping and allows heavy-tailed noise with b
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#19968;&#33324;&#30340;&#20805;&#20998;&#26465;&#20214;&#26469;&#35299;&#20915;MPE&#20013;&#19981;&#21487;&#31616;&#32422;&#24615;&#20551;&#35774;&#19979;&#30340;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#20272;&#35745;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.01253</link><description>&lt;p&gt;
&#36229;&#36234;&#19981;&#21487;&#31616;&#32422;&#24615;&#30340;&#28151;&#21512;&#27604;&#20363;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Mixture Proportion Estimation Beyond Irreducibility. (arXiv:2306.01253v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01253
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#19968;&#33324;&#30340;&#20805;&#20998;&#26465;&#20214;&#26469;&#35299;&#20915;MPE&#20013;&#19981;&#21487;&#31616;&#32422;&#24615;&#20551;&#35774;&#19979;&#30340;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#20272;&#35745;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28151;&#21512;&#27604;&#20363;&#20272;&#35745;&#65288;MPE&#65289;&#30340;&#20219;&#21153;&#26159;&#20272;&#35745;&#28151;&#21512;&#29289;&#20013;&#32452;&#25104;&#20998;&#24067;&#30340;&#26435;&#37325;&#65292;&#32473;&#23450;&#26469;&#33258;&#32452;&#25104;&#20998;&#24067;&#21644;&#28151;&#21512;&#29289;&#30340;&#35266;&#27979;&#12290;&#20197;&#21069;&#30340;MPE&#24037;&#20316;&#37319;&#29992;&#20102;&#19981;&#21487;&#31616;&#32422;&#24615;&#20551;&#35774;&#65292;&#36825;&#30830;&#20445;&#20102;&#28151;&#21512;&#27604;&#20363;&#30340;&#21487;&#36776;&#35782;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26356;&#19968;&#33324;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#36866;&#29992;&#20110;&#20960;&#31181;&#24863;&#20852;&#36259;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#19981;&#21487;&#31616;&#32422;&#24615;&#19981;&#25104;&#31435;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#37325;&#37319;&#26679;&#30340;&#20803;&#31639;&#27861;&#65292;&#23427;&#25509;&#21463;&#20219;&#20309;&#29616;&#26377;&#30340;&#22312;&#19981;&#21487;&#31616;&#32422;&#24615;&#19979;&#35774;&#35745;&#30340;MPE&#31639;&#27861;&#65292;&#24182;&#23558;&#20854;&#35843;&#25972;&#20026;&#22312;&#25105;&#20204;&#26356;&#19968;&#33324;&#30340;&#26465;&#20214;&#19979;&#24037;&#20316;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#32463;&#39564;&#19978;&#23637;&#29616;&#20102;&#30456;&#23545;&#20110;&#22522;&#32447;&#26041;&#27861;&#21644;&#26368;&#36817;&#25552;&#20986;&#30340;&#22522;&#20110;&#37325;&#26032;&#20998;&#32452;&#30340;&#31639;&#27861;&#30340;&#20272;&#35745;&#24615;&#33021;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;
The task of mixture proportion estimation (MPE) is to estimate the weight of a component distribution in a mixture, given observations from both the component and mixture. Previous work on MPE adopts the irreducibility assumption, which ensures identifiablity of the mixture proportion. In this paper, we propose a more general sufficient condition that accommodates several settings of interest where irreducibility does not hold. We further present a resampling-based meta-algorithm that takes any existing MPE algorithm designed to work under irreducibility and adapts it to work under our more general condition. Our approach empirically exhibits improved estimation performance relative to baseline methods and to a recently proposed regrouping-based algorithm.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#30452;&#25509;&#26368;&#23567;&#21270;&#36125;&#21494;&#26031;&#36951;&#25022;&#19978;&#30028;&#30340;&#26032;&#26041;&#27861;&#65292;&#33719;&#24471;&#26356;&#22909;&#30340;&#29702;&#35770;&#31163;&#32447;&#36951;&#25022;&#30028;&#21644;&#25968;&#20540;&#27169;&#25311;&#32467;&#26524;&#65292;&#24182;&#25552;&#20379;&#20102;&#35777;&#25454;&#34920;&#26126;&#27969;&#34892;&#30340;LCB-style&#31639;&#27861;&#21487;&#33021;&#19981;&#36866;&#29992;&#12290;</title><link>http://arxiv.org/abs/2306.01237</link><description>&lt;p&gt;
&#31163;&#32447;&#36172;&#21338;&#20013;&#36125;&#21494;&#26031;&#36951;&#25022;&#26368;&#23567;&#21270;&#30340;&#20984;&#26494;&#24347;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Convex Relaxation Approach to Bayesian Regret Minimization in Offline Bandits. (arXiv:2306.01237v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01237
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#30452;&#25509;&#26368;&#23567;&#21270;&#36125;&#21494;&#26031;&#36951;&#25022;&#19978;&#30028;&#30340;&#26032;&#26041;&#27861;&#65292;&#33719;&#24471;&#26356;&#22909;&#30340;&#29702;&#35770;&#31163;&#32447;&#36951;&#25022;&#30028;&#21644;&#25968;&#20540;&#27169;&#25311;&#32467;&#26524;&#65292;&#24182;&#25552;&#20379;&#20102;&#35777;&#25454;&#34920;&#26126;&#27969;&#34892;&#30340;LCB-style&#31639;&#27861;&#21487;&#33021;&#19981;&#36866;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#36172;&#21338;&#31639;&#27861;&#24517;&#39035;&#20165;&#21033;&#29992;&#31163;&#32447;&#25968;&#25454;&#22312;&#19981;&#30830;&#23450;&#29615;&#22659;&#20013;&#20248;&#21270;&#20915;&#31574;&#12290;&#31163;&#32447;&#36172;&#21338;&#20013;&#19968;&#31181;&#24341;&#20154;&#27880;&#30446;&#19988;&#36880;&#28176;&#27969;&#34892;&#30340;&#30446;&#26631;&#26159;&#23398;&#20064;&#19968;&#20010;&#23454;&#29616;&#20302;&#36125;&#21494;&#26031;&#36951;&#25022;&#24182;&#20855;&#26377;&#39640;&#32622;&#20449;&#24230;&#30340;&#31574;&#30053;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#30452;&#25509;&#21033;&#29992;&#39640;&#25928;&#30340;&#38181;&#20248;&#21270;&#27714;&#35299;&#22120;&#26469;&#26368;&#23567;&#21270;&#36125;&#21494;&#26031;&#36951;&#25022;&#30340;&#19978;&#30028;&#12290;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#29702;&#35770;&#19978;&#33719;&#24471;&#20102;&#26356;&#20248;&#30340;&#31163;&#32447;&#36951;&#25022;&#30028;&#65292;&#24182;&#22312;&#25968;&#20540;&#27169;&#25311;&#20013;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#19968;&#20123;&#35777;&#25454;&#34920;&#26126;&#27969;&#34892;&#30340;LCB&#65288;lower confidence bound&#65289;-style&#31639;&#27861;&#21487;&#33021;&#19981;&#36866;&#21512;&#31163;&#32447;&#36172;&#21338;&#20013;&#26368;&#23567;&#21270;&#36125;&#21494;&#26031;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithms for offline bandits must optimize decisions in uncertain environments using only offline data. A compelling and increasingly popular objective in offline bandits is to learn a policy which achieves low Bayesian regret with high confidence. An appealing approach to this problem, inspired by recent offline reinforcement learning results, is to maximize a form of lower confidence bound (LCB). This paper proposes a new approach that directly minimizes upper bounds on Bayesian regret using efficient conic optimization solvers. Our bounds build on connections among Bayesian regret, Value-at-Risk (VaR), and chance-constrained optimization. Compared to prior work, our algorithm attains superior theoretical offline regret bounds and better results in numerical simulations. Finally, we provide some evidence that popular LCB-style algorithms may be unsuitable for minimizing Bayesian regret in offline bandits.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23450;&#20041;&#29420;&#31435;&#22240;&#26524;&#26426;&#21046;&#65292;&#25552;&#20986;&#20102;ICM-VAE&#26694;&#26550;&#65292;&#20351;&#24471;&#23398;&#20064;&#22240;&#26524;&#35299;&#32544;&#32469;&#34920;&#31034;&#26356;&#20934;&#30830;</title><link>http://arxiv.org/abs/2306.01213</link><description>&lt;p&gt;
&#22522;&#20110;&#29420;&#31435;&#22240;&#26524;&#26426;&#21046;&#21407;&#21017;&#23398;&#20064;&#22240;&#26524;&#35299;&#32544;&#32469;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Learning Causally Disentangled Representations via the Principle of Independent Causal Mechanisms. (arXiv:2306.01213v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01213
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23450;&#20041;&#29420;&#31435;&#22240;&#26524;&#26426;&#21046;&#65292;&#25552;&#20986;&#20102;ICM-VAE&#26694;&#26550;&#65292;&#20351;&#24471;&#23398;&#20064;&#22240;&#26524;&#35299;&#32544;&#32469;&#34920;&#31034;&#26356;&#20934;&#30830;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#35299;&#32544;&#32469;&#30340;&#22240;&#26524;&#34920;&#31034;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#65292;&#36817;&#24180;&#26469;&#22240;&#20854;&#23545;&#25552;&#21462;&#19979;&#28216;&#20219;&#21153;&#30340;&#26377;&#24847;&#20041;&#20449;&#24687;&#32780;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#26412;&#25991;&#20174;&#29420;&#31435;&#22240;&#26524;&#26426;&#21046;&#30340;&#35282;&#24230;&#23450;&#20041;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#35299;&#32544;&#32469;&#27010;&#24565;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;ICM-VAE&#26694;&#26550;&#65292;&#36890;&#36807;&#22240;&#22240;&#26524;&#20851;&#31995;&#35266;&#23519;&#26631;&#31614;&#26469;&#30417;&#30563;&#23398;&#20064;&#22240;&#26524;&#35299;&#32544;&#32469;&#34920;&#31034;&#12290;&#25105;&#20204;&#20351;&#29992;&#21487;&#23398;&#20064;&#30340;&#22522;&#20110;&#27969;&#30340;&#24494;&#20998;&#21516;&#32986;&#20989;&#25968;&#23558;&#22122;&#22768;&#21464;&#37327;&#26144;&#23556;&#21040;&#28508;&#22312;&#22240;&#26524;&#21464;&#37327;&#20013;&#26469;&#24314;&#27169;&#22240;&#26524;&#26426;&#21046;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#20419;&#36827;&#22240;&#26524;&#35201;&#32032;&#30340;&#35299;&#32544;&#32469;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#35299;&#32544;&#32469;&#20808;&#39564;&#65292;&#21033;&#29992;&#24050;&#30693;&#30340;&#22240;&#26524;&#32467;&#26500;&#26469;&#40723;&#21169;&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#23398;&#20064;&#22240;&#26524;&#20998;&#35299;&#20998;&#24067;&#12290;&#22312;&#30456;&#23545;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#32467;&#26524;&#65292;&#26174;&#31034;&#20102;&#22240;&#26524;&#35201;&#32032;&#21644;&#26426;&#21046;&#30340;&#21487;&#35782;&#21035;&#24615;&#65292;&#30452;&#21040;&#25490;&#21015;&#21644;&#36880;&#20803;&#37325;&#21442;&#25968;&#21270;&#30340;&#38480;&#24230;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#23454;&#35777;&#30740;&#31350;...
&lt;/p&gt;
&lt;p&gt;
Learning disentangled causal representations is a challenging problem that has gained significant attention recently due to its implications for extracting meaningful information for downstream tasks. In this work, we define a new notion of causal disentanglement from the perspective of independent causal mechanisms. We propose ICM-VAE, a framework for learning causally disentangled representations supervised by causally related observed labels. We model causal mechanisms using learnable flow-based diffeomorphic functions to map noise variables to latent causal variables. Further, to promote the disentanglement of causal factors, we propose a causal disentanglement prior that utilizes the known causal structure to encourage learning a causally factorized distribution in the latent space. Under relatively mild conditions, we provide theoretical results showing the identifiability of causal factors and mechanisms up to permutation and elementwise reparameterization. We empirically demons
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38142;&#25509;&#28145;&#39640;&#26031;&#36807;&#31243;&#27169;&#25311;&#65288;LDGP&#65289;&#26694;&#26550;&#65292;&#21487;&#29992;&#20110;&#39640;&#25928;&#20223;&#30495;&#20855;&#26377;&#38750;&#31283;&#24577;&#34892;&#20026;&#30340;&#22797;&#26434;&#27169;&#22411;&#65292;&#24182;&#25552;&#39640;&#20102;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.01212</link><description>&lt;p&gt;
&#38142;&#25509;&#28145;&#39640;&#26031;&#36807;&#31243;&#27169;&#25311;&#29992;&#20110;&#27169;&#22411;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Linked Deep Gaussian Process Emulation for Model Networks. (arXiv:2306.01212v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01212
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38142;&#25509;&#28145;&#39640;&#26031;&#36807;&#31243;&#27169;&#25311;&#65288;LDGP&#65289;&#26694;&#26550;&#65292;&#21487;&#29992;&#20110;&#39640;&#25928;&#20223;&#30495;&#20855;&#26377;&#38750;&#31283;&#24577;&#34892;&#20026;&#30340;&#22797;&#26434;&#27169;&#22411;&#65292;&#24182;&#25552;&#39640;&#20102;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#31185;&#23398;&#38382;&#39064;&#36890;&#24120;&#26159;&#22810;&#23398;&#31185;&#30340;&#65292;&#38656;&#35201;&#25972;&#21512;&#26469;&#33258;&#19981;&#21516;&#23398;&#31185;&#30340;&#35745;&#31639;&#26426;&#27169;&#22411;&#65292;&#27599;&#20010;&#27169;&#22411;&#20855;&#26377;&#19981;&#21516;&#30340;&#21151;&#33021;&#22797;&#26434;&#24615;&#65292;&#32534;&#31243;&#29615;&#22659;&#21644;&#35745;&#31639;&#26102;&#38388;&#12290;&#38142;&#25509;&#39640;&#26031;&#36807;&#31243;&#65288;LGP&#65289;&#20223;&#30495;&#36890;&#36807;&#23558;&#21508;&#20010;&#35745;&#31639;&#26426;&#27169;&#22411;&#30340;&#39640;&#26031;&#36807;&#31243;&#20223;&#30495;&#22120;&#38598;&#25104;&#21040;&#32593;&#32476;&#20013;&#30340;&#20998;&#32780;&#27835;&#20043;&#31574;&#30053;&#26469;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#12290;&#28982;&#32780;&#65292;&#22312;LGP&#26694;&#26550;&#20013;&#65292;&#32452;&#20214;&#39640;&#26031;&#36807;&#31243;&#20223;&#30495;&#22120;&#30340;&#25152;&#38656;&#31283;&#23450;&#24615;&#38480;&#21046;&#20102;&#20854;&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;&#35745;&#31639;&#27169;&#22411;&#32593;&#32476;&#27010;&#24565;&#21270;&#20026;&#19968;&#20010;&#20855;&#26377;&#37096;&#20998;&#38544;&#34255;&#23618;&#26333;&#20809;&#30340;&#28145;&#39640;&#26031;&#36807;&#31243;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#25512;&#26029;&#36825;&#20123;&#37096;&#20998;&#26292;&#38706;&#30340;&#28145;&#24230;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#20445;&#30041;&#20102;LGP&#26694;&#26550;&#30340;&#19968;&#20010;&#20851;&#38190;&#20248;&#21183;&#65292;&#21363;&#27599;&#20010;&#27169;&#22411;&#37117;&#21487;&#20197;&#20351;&#29992;DGP&#20998;&#21035;&#20223;&#30495;&#65292;&#28982;&#21518;&#38142;&#25509;&#22312;&#19968;&#36215;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#23454;&#35777;&#31034;&#20363;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#38142;&#25509;&#28145;&#24230;&#39640;&#26031;&#36807;&#31243;&#27169;&#25311;&#65288;LDGP&#65289;&#26694;&#26550;&#21487;&#20197;&#39640;&#25928;&#22320;&#20223;&#30495;&#20855;&#26377;&#38750;&#31283;&#24577;&#34892;&#20026;&#30340;&#22797;&#26434;&#27169;&#22411;&#65292;&#24182;&#25552;&#39640;&#20102;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#65292;&#32780;&#30456;&#27604;&#20043;&#19979;&#65292;LGP&#26694;&#26550;&#30340;&#25928;&#26524;&#26377;&#25152;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern scientific problems are often multi-disciplinary and require integration of computer models from different disciplines, each with distinct functional complexities, programming environments, and computation times. Linked Gaussian process (LGP) emulation tackles this challenge through a divide-and-conquer strategy that integrates Gaussian process emulators of the individual computer models in a network. However, the required stationarity of the component Gaussian process emulators within the LGP framework limits its applicability in many real-world applications. In this work, we conceptualize a network of computer models as a deep Gaussian process with partial exposure of its hidden layers. We develop a method for inference for these partially exposed deep networks that retains a key strength of the LGP framework, whereby each model can be emulated separately using a DGP and then linked together. We show in both synthetic and empirical examples that our linked deep Gaussian proces
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22238;&#39038;&#20102;&#26500;&#24314;&#21305;&#37197;&#20219;&#21153;&#35823;&#24046;&#29575;&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#65292;&#30740;&#31350;&#20854;&#32479;&#35745;&#29305;&#24615;&#24182;&#25552;&#20379;&#20102;&#26368;&#20339;&#23454;&#36341;&#24314;&#35758;&#12290;</title><link>http://arxiv.org/abs/2306.01198</link><description>&lt;p&gt;
&#21305;&#37197;&#20219;&#21153;&#30340;&#35823;&#24046;&#29575;&#32622;&#20449;&#21306;&#38388;&#65306;&#20851;&#38190;&#32508;&#36848;&#19982;&#24314;&#35758;
&lt;/p&gt;
&lt;p&gt;
Confidence Intervals for Error Rates in Matching Tasks: Critical Review and Recommendations. (arXiv:2306.01198v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01198
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22238;&#39038;&#20102;&#26500;&#24314;&#21305;&#37197;&#20219;&#21153;&#35823;&#24046;&#29575;&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#65292;&#30740;&#31350;&#20854;&#32479;&#35745;&#29305;&#24615;&#24182;&#25552;&#20379;&#20102;&#26368;&#20339;&#23454;&#36341;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21305;&#37197;&#31639;&#27861;&#36890;&#24120;&#29992;&#20110;&#39044;&#27979;&#25910;&#38598;&#20013;&#39033;&#30446;&#20043;&#38388;&#30340;&#21305;&#37197;&#12290;&#20363;&#22914;&#65292;&#22312;1&#65306;1&#30340;&#20154;&#33080;&#39564;&#35777;&#20013;&#65292;&#21305;&#37197;&#31639;&#27861;&#39044;&#27979;&#20004;&#24352;&#20154;&#33080;&#22270;&#20687;&#26159;&#21542;&#25551;&#32472;&#21516;&#19968;&#20010;&#20154;&#12290;&#24403;&#25968;&#25454;&#30456;&#20851;&#19988;&#35823;&#24046;&#29575;&#20302;&#26102;&#65292;&#20934;&#30830;&#35780;&#20272;&#27492;&#31867;&#31639;&#27861;&#35823;&#24046;&#29575;&#30340;&#19981;&#30830;&#23450;&#24615;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#36825;&#26159;&#25991;&#29486;&#20013;&#32463;&#24120;&#34987;&#24573;&#30053;&#30340;&#20004;&#20010;&#26041;&#38754;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22238;&#39038;&#20102;&#26500;&#24314;1:1&#20154;&#33080;&#39564;&#35777;&#31561;&#21305;&#37197;&#20219;&#21153;&#35823;&#24046;&#29575;&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#25512;&#23548;&#21644;&#26816;&#39564;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#32479;&#35745;&#23646;&#24615;&#65292;&#24182;&#20351;&#29992;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#28436;&#31034;&#20102;&#35206;&#30422;&#29575;&#21644;&#21306;&#38388;&#23485;&#24230;&#22914;&#20309;&#38543;&#30528;&#26679;&#26412;&#37327;&#12289;&#35823;&#24046;&#29575;&#21644;&#25968;&#25454;&#30456;&#20851;&#31243;&#24230;&#21464;&#21270;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#26500;&#24314;&#21305;&#37197;&#20219;&#21153;&#35823;&#24046;&#29575;&#32622;&#20449;&#21306;&#38388;&#26368;&#20339;&#23454;&#36341;&#30340;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
Matching algorithms are commonly used to predict matches between items in a collection. For example, in 1:1 face verification, a matching algorithm predicts whether two face images depict the same person. Accurately assessing the uncertainty of the error rates of such algorithms can be challenging when data are dependent and error rates are low, two aspects that have been often overlooked in the literature. In this work, we review methods for constructing confidence intervals for error rates in matching tasks such as 1:1 face verification. We derive and examine the statistical properties of these methods and demonstrate how coverage and interval width vary with sample size, error rates, and degree of data dependence using both synthetic and real-world datasets. Based on our findings, we provide recommendations for best practices for constructing confidence intervals for error rates in matching tasks.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#35780;&#20272;&#29983;&#23384;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#20351;&#29992;&#20266;&#35266;&#23519;&#20540;&#30340;MAE&#25351;&#26631;&#33021;&#22815;&#20934;&#30830;&#22320;&#25490;&#21517;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#21457;&#29616;&#36825;&#31181;&#26041;&#27861;&#27604;&#20854;&#20182;&#26367;&#20195;&#26041;&#27861;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2306.01196</link><description>&lt;p&gt;
&#19968;&#31181;&#26377;&#25928;&#30340;&#35780;&#20272;&#29983;&#23384;&#27169;&#22411;&#30340;&#26377;&#24847;&#20041;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
An Effective Meaningful Way to Evaluate Survival Models. (arXiv:2306.01196v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01196
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#35780;&#20272;&#29983;&#23384;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#20351;&#29992;&#20266;&#35266;&#23519;&#20540;&#30340;MAE&#25351;&#26631;&#33021;&#22815;&#20934;&#30830;&#22320;&#25490;&#21517;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#21457;&#29616;&#36825;&#31181;&#26041;&#27861;&#27604;&#20854;&#20182;&#26367;&#20195;&#26041;&#27861;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#29983;&#23384;&#39044;&#27979;&#27169;&#22411;&#30340;&#19968;&#31181;&#30452;&#25509;&#25351;&#26631;&#26159;&#22522;&#20110;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#65288;MAE&#65289;-&#27169;&#22411;&#39044;&#27979;&#26102;&#38388;&#19982;&#30495;&#23454;&#20107;&#20214;&#26102;&#38388;&#20043;&#38388;&#30340;&#32477;&#23545;&#24046;&#20540;&#30340;&#24179;&#22343;&#20540;&#65292;&#23545;&#25152;&#26377;&#20010;&#20307;&#36827;&#34892;&#12290;&#28982;&#32780;&#65292;&#36825;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#22312;&#23454;&#36341;&#20013;&#65292;&#27979;&#35797;&#38598;&#21253;&#25324;&#65288;&#27491;&#30830;&#65289;&#34987;&#23457;&#26597;&#30340;&#20010;&#20307;&#65292;&#36825;&#24847;&#21619;&#30528;&#25105;&#20204;&#19981;&#30693;&#36947;&#34987;&#23457;&#26597;&#20010;&#20307;&#23454;&#38469;&#32463;&#21382;&#20107;&#20214;&#30340;&#26102;&#38388;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#29992;&#20110;&#35780;&#20272;&#21253;&#25324;&#65288;&#35768;&#22810;&#65289;&#34987;&#23457;&#26597;&#20010;&#20307;&#30340;&#29983;&#23384;&#25968;&#25454;&#38598;&#30340;&#21508;&#31181;&#25351;&#26631;&#26469;&#20272;&#35745;MAE&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#32780;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#29983;&#25104;&#36924;&#30495;&#30340;&#21322;&#21512;&#25104;&#29983;&#23384;&#25968;&#25454;&#38598;&#65292;&#20197;&#20415;&#35780;&#20272;&#25351;&#26631;&#12290;&#22522;&#20110;&#21322;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#30340;&#21457;&#29616;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#25351;&#26631;&#65288;&#20351;&#29992;&#20266;&#35266;&#23519;&#27861;&#30340;MAE&#65289;&#33021;&#22815;&#20934;&#30830;&#22320;&#25490;&#21517;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#36890;&#24120;&#19982;&#30495;&#23454;&#30340;MAE&#38750;&#24120;&#25509;&#36817;-&#29305;&#21035;&#26159;&#20248;&#20110;&#20960;&#31181;&#26367;&#20195;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
One straightforward metric to evaluate a survival prediction model is based on the Mean Absolute Error (MAE) -- the average of the absolute difference between the time predicted by the model and the true event time, over all subjects. Unfortunately, this is challenging because, in practice, the test set includes (right) censored individuals, meaning we do not know when a censored individual actually experienced the event. In this paper, we explore various metrics to estimate MAE for survival datasets that include (many) censored individuals. Moreover, we introduce a novel and effective approach for generating realistic semi-synthetic survival datasets to facilitate the evaluation of metrics. Our findings, based on the analysis of the semi-synthetic datasets, reveal that our proposed metric (MAE using pseudo-observations) is able to rank models accurately based on their performance, and often closely matches the true MAE -- in particular, is better than several alternative methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23558;&#39034;&#20174;&#39044;&#27979;&#31243;&#24207;&#19982;&#38598;&#21512;&#20540;&#30340;&#35757;&#32451;&#25968;&#25454;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38598;&#21512;&#20540;&#35757;&#32451;&#21644;&#26657;&#20934;&#25968;&#25454;&#30340;&#39034;&#20174;&#39044;&#27979;&#31243;&#24207;&#12290;</title><link>http://arxiv.org/abs/2306.01191</link><description>&lt;p&gt;
&#26377;&#37096;&#20998;&#26631;&#31614;&#25968;&#25454;&#30340;&#39034;&#20174;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Conformal Prediction with Partially Labeled Data. (arXiv:2306.01191v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01191
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#39034;&#20174;&#39044;&#27979;&#31243;&#24207;&#19982;&#38598;&#21512;&#20540;&#30340;&#35757;&#32451;&#25968;&#25454;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38598;&#21512;&#20540;&#35757;&#32451;&#21644;&#26657;&#20934;&#25968;&#25454;&#30340;&#39034;&#20174;&#39044;&#27979;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#39034;&#20174;&#39044;&#27979;&#20135;&#29983;&#30340;&#39044;&#27979;&#26159;&#38598;&#21512;&#20540;&#65292;&#20294;&#29992;&#20110;&#35757;&#32451;&#21644;&#26657;&#20934;&#30340;&#25968;&#25454;&#24212;&#35813;&#26159;&#31934;&#30830;&#30340;&#12290;&#22312;&#36229;&#38598;&#23398;&#20064;&#25110;&#37096;&#20998;&#26631;&#31614;&#23398;&#20064;&#30340;&#35774;&#32622;&#20013;&#65292;&#19968;&#31181;&#24369;&#30417;&#30563;&#23398;&#20064;&#30340;&#21464;&#20307;&#65292;&#24773;&#20917;&#24688;&#24688;&#30456;&#21453;:&#35757;&#32451;&#25968;&#25454;&#21487;&#33021;&#19981;&#31934;&#30830;&#65288;&#38598;&#21512;&#20540;&#65289;&#65292;&#20294;&#20174;&#27492;&#25968;&#25454;&#20013;&#24341;&#20986;&#30340;&#27169;&#22411;&#20135;&#29983;&#31934;&#30830;&#39044;&#27979;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#20004;&#31181;&#35774;&#32622;&#30456;&#32467;&#21512;&#65292;&#20351;&#39034;&#20174;&#39044;&#27979;&#36866;&#24212;&#38598;&#21512;&#20540;&#30340;&#35757;&#32451;&#25968;&#25454;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39034;&#20174;&#39044;&#27979;&#31243;&#24207;&#30340;&#27010;&#25324;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#38598;&#21512;&#20540;&#30340;&#35757;&#32451;&#21644;&#26657;&#20934;&#25968;&#25454;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#23454;&#39564;&#30740;&#31350;&#65292;&#22312;&#20854;&#20013;&#23427;&#19982;&#33258;&#28982;&#22522;&#32447;&#30456;&#27604;&#36739;&#26377;&#21033;&#12290;
&lt;/p&gt;
&lt;p&gt;
While the predictions produced by conformal prediction are set-valued, the data used for training and calibration is supposed to be precise. In the setting of superset learning or learning from partial labels, a variant of weakly supervised learning, it is exactly the other way around: training data is possibly imprecise (set-valued), but the model induced from this data yields precise predictions. In this paper, we combine the two settings by making conformal prediction amenable to set-valued training data. We propose a generalization of the conformal prediction procedure that can be applied to set-valued training and calibration data. We prove the validity of the proposed method and present experimental studies in which it compares favorably to natural baselines.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20998;&#26512;&#24120;&#35265;&#30340;&#22352;&#26631;&#19978;&#21319;&#21464;&#20998;&#25512;&#26029;&#65288;CAVI&#65289;&#31639;&#27861;&#22312;&#20004;&#20010;&#22359;&#30340;&#24773;&#20917;&#19979;&#30340;&#25910;&#25947;&#24615;&#65292;&#25552;&#20379;&#20102;&#35777;&#26126;&#20840;&#23616;&#25110;&#23616;&#37096;&#25351;&#25968;&#25910;&#25947;&#30340;&#19968;&#33324;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2306.01122</link><description>&lt;p&gt;
&#35770;&#22352;&#26631;&#19978;&#21319;&#21464;&#20998;&#25512;&#26029;&#30340;&#25910;&#25947;&#24615;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
On the Convergence of Coordinate Ascent Variational Inference. (arXiv:2306.01122v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01122
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20998;&#26512;&#24120;&#35265;&#30340;&#22352;&#26631;&#19978;&#21319;&#21464;&#20998;&#25512;&#26029;&#65288;CAVI&#65289;&#31639;&#27861;&#22312;&#20004;&#20010;&#22359;&#30340;&#24773;&#20917;&#19979;&#30340;&#25910;&#25947;&#24615;&#65292;&#25552;&#20379;&#20102;&#35777;&#26126;&#20840;&#23616;&#25110;&#23616;&#37096;&#25351;&#25968;&#25910;&#25947;&#30340;&#19968;&#33324;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#25512;&#26029;&#65288;VI&#65289;&#20316;&#20026;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#30340;&#19968;&#31181;&#35745;&#31639;&#26367;&#20195;&#26041;&#27861;&#65292;&#30001;&#20110;&#20854;&#21487;&#27604;&#36739;&#30340;&#21151;&#25928;&#21644;&#21331;&#36234;&#30340;&#25928;&#29575;&#65292;&#22312;&#22823;&#35268;&#27169;&#36125;&#21494;&#26031;&#27169;&#22411;&#20013;&#29992;&#20110;&#36817;&#20284;&#38590;&#20197;&#35745;&#31639;&#30340;&#21518;&#39564;&#20998;&#24067;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#23613;&#31649;&#26377;&#20960;&#39033;&#26368;&#36817;&#30340;&#24037;&#20316;&#36890;&#36807;&#35777;&#26126;&#22312;&#19981;&#21516;&#35774;&#32622;&#19979;VI&#22312;&#21442;&#25968;&#20272;&#35745;&#26041;&#38754;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#65292;&#20026;VI&#25552;&#20379;&#20102;&#29702;&#35770;&#35777;&#25454;&#65292;&#20294;&#23545;VI&#31639;&#27861;&#25910;&#25947;&#24615;&#26041;&#38754;&#30340;&#24418;&#24335;&#21270;&#20998;&#26512;&#20173;&#28982;&#32570;&#20047;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#24120;&#35265;&#30340;&#22352;&#26631;&#19978;&#21319;&#21464;&#20998;&#25512;&#26029;&#65288;CAVI&#65289;&#31639;&#27861;&#65292;&#20197;&#23454;&#29616;&#22343;&#20540;&#22330;&#65288;MF&#65289;VI&#65292;&#24182;&#20248;&#21270;&#25152;&#26377;&#20998;&#35299;&#20998;&#24067;&#31354;&#38388;&#19978;&#30340;KL&#25955;&#24230;&#30446;&#26631;&#21151;&#33021;&#12290;&#25105;&#20204;&#36890;&#36807;&#21033;&#29992;&#20989;&#25968;&#20998;&#26512;&#21644;&#20248;&#21270;&#30340;&#24191;&#27867;&#24037;&#20855;&#31665;&#65292;&#37325;&#28857;&#20851;&#27880;&#20004;&#20010;&#22359;&#30340;&#24773;&#20917;&#65292;&#20998;&#26512;CAVI&#30340;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#35777;&#26126;&#20840;&#23616;&#25110;&#23616;&#37096;&#25351;&#25968;&#25910;&#25947;&#30340;&#19968;&#33324;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
As a computational alternative to Markov chain Monte Carlo approaches, variational inference (VI) is becoming more and more popular for approximating intractable posterior distributions in large-scale Bayesian models due to its comparable efficacy and superior efficiency. Several recent works provide theoretical justifications of VI by proving its statistical optimality for parameter estimation under various settings; meanwhile, formal analysis on the algorithmic convergence aspects of VI is still largely lacking. In this paper, we consider the common coordinate ascent variational inference (CAVI) algorithm for implementing the mean-field (MF) VI towards optimizing a Kullback--Leibler divergence objective functional over the space of all factorized distributions. Focusing on the two-block case, we analyze the convergence of CAVI by leveraging the extensive toolbox from functional analysis and optimization. We provide general conditions for certifying global or local exponential converg
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32467;&#26500;&#30456;&#20284;&#24230;&#25351;&#26631;&#30340;&#24555;&#36895;&#21322;&#30417;&#30563;&#31038;&#21306;&#26816;&#27979;&#31639;&#27861;&#65292;&#24182;&#22312;&#29702;&#35770;&#19982;&#23454;&#39564;&#26041;&#38754;&#22343;&#26377;&#33391;&#22909;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.01089</link><description>&lt;p&gt;
&#22522;&#20110;&#32467;&#26500;&#30456;&#20284;&#24230;&#24230;&#37327;&#30340;&#21322;&#30417;&#30563;&#31038;&#21306;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Semi-supervised Community Detection via Structural Similarity Metrics. (arXiv:2306.01089v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01089
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32467;&#26500;&#30456;&#20284;&#24230;&#25351;&#26631;&#30340;&#24555;&#36895;&#21322;&#30417;&#30563;&#31038;&#21306;&#26816;&#27979;&#31639;&#27861;&#65292;&#24182;&#22312;&#29702;&#35770;&#19982;&#23454;&#39564;&#26041;&#38754;&#22343;&#26377;&#33391;&#22909;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21322;&#30417;&#30563;&#31038;&#21306;&#26816;&#27979;&#38382;&#39064;&#65292;&#26088;&#22312;&#20351;&#29992;&#32593;&#32476;&#25299;&#25169;&#32467;&#26500;&#21644;&#24050;&#35266;&#23519;&#21040;&#30340;&#33410;&#28857;&#26631;&#31614;&#37096;&#20998;&#25512;&#26029;&#26032;&#33410;&#28857;&#30340;&#31038;&#21306;&#26631;&#31614;&#12290;&#25991;&#31456;&#25552;&#20986;&#20102;&#35745;&#31639;&#26032;&#33410;&#28857;&#19982;$K$&#20010;&#31038;&#21306;&#20043;&#38388;&#8220;&#32467;&#26500;&#30456;&#20284;&#24230;&#25351;&#26631;&#8221;&#30340;&#31639;&#27861;&#65292;&#33021;&#22815;&#29992;&#26631;&#35760;&#21644;&#26410;&#26631;&#35760;&#25968;&#25454;&#23545;&#20854;&#36827;&#34892;&#32858;&#21512;&#65292;&#20174;&#32780;&#39044;&#27979;&#26032;&#33410;&#28857;&#30340;&#26631;&#31614;&#12290;&#35813;&#26041;&#27861;&#24555;&#36895;&#19988;&#25968;&#20540;&#19978;&#20248;&#20110;&#29616;&#26377;&#30340;&#21322;&#30417;&#30563;&#31639;&#27861;&#12290;&#29702;&#35770;&#19978;&#65292;&#25991;&#31456;&#23548;&#20986;&#20102;&#35823;&#20998;&#31867;&#35823;&#24046;&#30340;&#26126;&#30830;&#30028;&#38480;&#65292;&#24182;&#36890;&#36807;&#19982;&#29702;&#24819;&#20998;&#31867;&#22120;&#30340;&#27604;&#36739;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by social network analysis and network-based recommendation systems, we study a semi-supervised community detection problem in which the objective is to estimate the community label of a new node using the network topology and partially observed community labels of existing nodes. The network is modeled using a degree-corrected stochastic block model, which allows for severe degree heterogeneity and potentially non-assortative communities. We propose an algorithm that computes a `structural similarity metric' between the new node and each of the $K$ communities by aggregating labeled and unlabeled data. The estimated label of the new node corresponds to the value of $k$ that maximizes this similarity metric. Our method is fast and numerically outperforms existing semi-supervised algorithms. Theoretically, we derive explicit bounds for the misclassification error and show the efficiency of our method by comparing it with an ideal classifier. Our findings highlight, to the best
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22810;&#30740;&#31350;R-learner&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#24456;&#22909;&#22320;&#20272;&#35745;&#22810;&#30740;&#31350;&#20013;&#30340;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#65292;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#24182;&#22312;&#29616;&#23454;&#30284;&#30151;&#25968;&#25454;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#26356;&#23567;&#30340;&#20272;&#35745;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2306.01086</link><description>&lt;p&gt;
&#22810;&#30740;&#31350;R-learner&#29992;&#20110;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Multi-study R-learner for Heterogeneous Treatment Effect Estimation. (arXiv:2306.01086v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01086
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22810;&#30740;&#31350;R-learner&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#24456;&#22909;&#22320;&#20272;&#35745;&#22810;&#30740;&#31350;&#20013;&#30340;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#65292;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#24182;&#22312;&#29616;&#23454;&#30284;&#30151;&#25968;&#25454;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#26356;&#23567;&#30340;&#20272;&#35745;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#31639;&#27861;&#31867;&#26469;&#20272;&#35745;&#22810;&#20010;&#30740;&#31350;&#20013;&#30340;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#31216;&#20026;&#22810;&#30740;&#31350;R-learner&#65292;&#21487;&#20197;&#27010;&#25324;R-learner&#20197;&#32771;&#34385;&#30740;&#31350;&#38388;&#30340;&#24322;&#36136;&#24615;&#24182;&#23454;&#29616;&#35843;&#25972;&#28151;&#28102;&#30340;&#36328;&#30740;&#31350;&#40065;&#26834;&#24615;&#12290;&#22810;&#30740;&#31350;R-learner&#33021;&#22815;&#28789;&#27963;&#22320;&#34701;&#21512;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#20197;&#20272;&#35745;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#12289;&#22256;&#25200;&#20989;&#25968;&#21644;&#25104;&#21592;&#27010;&#29575;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22810;&#30740;&#31350;R-learner&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#22120;&#22312;&#24207;&#21015;&#20272;&#35745;&#26694;&#26550;&#20869;&#26159;&#28176;&#36817;&#27491;&#24120;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#29616;&#23454;&#30284;&#30151;&#25968;&#25454;&#23454;&#39564;&#35777;&#26126;&#65292;&#38543;&#30528;&#30740;&#31350;&#38388;&#30340;&#24322;&#36136;&#24615;&#22686;&#21152;&#65292;&#19982;R-learner&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20272;&#35745;&#35823;&#24046;&#26356;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a general class of algorithms for estimating heterogeneous treatment effects on multiple studies. Our approach, called the multi-study R-learner, generalizes the R-learner to account for between-study heterogeneity and achieves cross-study robustness of confounding adjustment. The multi-study R-learner is flexible in its ability to incorporate many machine learning techniques for estimating heterogeneous treatment effects, nuisance functions, and membership probabilities. We show that the multi-study R-learner treatment effect estimator is asymptotically normal within the series estimation framework. Moreover, we illustrate via realistic cancer data experiments that our approach results in lower estimation error than the R-learner as between-study heterogeneity increases.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#25955;&#27169;&#22411;&#20013;&#30340;&#36127;&#33655;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#37319;&#29992;Seq2Seq&#32593;&#32476;&#32467;&#26500;&#26469;&#20998;&#31163;&#20004;&#31181;&#31867;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#24182;&#22788;&#29702;&#24322;&#24120;&#24773;&#20917;&#65292;&#19981;&#20165;&#30528;&#30524;&#20110;&#39044;&#27979;&#26465;&#20214;&#26399;&#26395;&#20540;&#12290;</title><link>http://arxiv.org/abs/2306.01001</link><description>&lt;p&gt;
DiffLoad:&#25193;&#25955;&#27169;&#22411;&#20013;&#30340;&#36127;&#33655;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
DiffLoad: Uncertainty Quantification in Load Forecasting with Diffusion Model. (arXiv:2306.01001v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01001
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#25955;&#27169;&#22411;&#20013;&#30340;&#36127;&#33655;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#37319;&#29992;Seq2Seq&#32593;&#32476;&#32467;&#26500;&#26469;&#20998;&#31163;&#20004;&#31181;&#31867;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#24182;&#22788;&#29702;&#24322;&#24120;&#24773;&#20917;&#65292;&#19981;&#20165;&#30528;&#30524;&#20110;&#39044;&#27979;&#26465;&#20214;&#26399;&#26395;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30005;&#21147;&#36127;&#33655;&#39044;&#27979;&#23545;&#30005;&#21147;&#31995;&#32479;&#30340;&#20915;&#31574;&#21046;&#23450;&#65292;&#22914;&#26426;&#32452;&#25237;&#20837;&#21644;&#33021;&#28304;&#31649;&#29702;&#31561;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#36817;&#24180;&#26469;&#65292;&#21508;&#31181;&#22522;&#20110;&#33258;&#30417;&#30563;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#24050;&#32463;&#34987;&#24212;&#29992;&#20110;&#30005;&#21147;&#36127;&#33655;&#39044;&#27979;&#65292;&#20197;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#21644;&#25429;&#25417;&#19981;&#30830;&#23450;&#24615;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#26041;&#27861;&#26159;&#22522;&#20110;&#39640;&#26031;&#20284;&#28982;&#26041;&#27861;&#30340;&#65292;&#23427;&#26088;&#22312;&#22312;&#32473;&#23450;&#30340;&#21327;&#21464;&#37327;&#19979;&#20934;&#30830;&#20272;&#35745;&#20998;&#24067;&#26399;&#26395;&#20540;&#12290;&#36825;&#31181;&#26041;&#27861;&#24456;&#38590;&#36866;&#24212;&#23384;&#22312;&#20998;&#24067;&#20559;&#31227;&#21644;&#24322;&#24120;&#20540;&#30340;&#26102;&#38388;&#25968;&#25454;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#30340;Seq2seq&#32467;&#26500;&#26469;&#20272;&#35745;&#26412;&#20307;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#20351;&#29992;&#40065;&#26834;&#30340;&#21152;&#24615;&#26607;&#35199;&#20998;&#24067;&#26469;&#20272;&#35745;&#29289;&#35937;&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#20998;&#31163;&#20004;&#31181;&#31867;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#24182;&#22788;&#29702;&#31361;&#21464;&#24773;&#20917;&#65292;&#32780;&#19981;&#26159;&#20934;&#30830;&#39044;&#27979;&#26465;&#20214;&#26399;&#26395;&#12290;
&lt;/p&gt;
&lt;p&gt;
Electrical load forecasting is of great significance for the decision makings in power systems, such as unit commitment and energy management. In recent years, various self-supervised neural network-based methods have been applied to electrical load forecasting to improve forecasting accuracy and capture uncertainties. However, most current methods are based on Gaussian likelihood methods, which aim to accurately estimate the distribution expectation under a given covariate. This kind of approach is difficult to adapt to situations where temporal data has a distribution shift and outliers. In this paper, we propose a diffusion-based Seq2seq structure to estimate epistemic uncertainty and use the robust additive Cauchy distribution to estimate aleatoric uncertainty. Rather than accurately forecasting conditional expectations, we demonstrate our method's ability in separating two types of uncertainties and dealing with the mutant scenarios.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#25955;&#33258;&#23548;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#20869;&#37096;&#34920;&#31034;&#26469;&#25552;&#20379;&#23545;&#29983;&#25104;&#22270;&#20687;&#30340;&#26356;&#22823;&#25511;&#21046;&#65292;&#21487;&#20197;&#29992;&#20110;&#25191;&#34892;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22270;&#20687;&#25805;&#20316;&#65292;&#21516;&#26102;&#19981;&#38656;&#35201;&#39069;&#22806;&#27169;&#22411;&#25110;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2306.00986</link><description>&lt;p&gt;
&#21487;&#25511;&#22270;&#20687;&#29983;&#25104;&#30340;&#25193;&#25955;&#33258;&#23548;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Diffusion Self-Guidance for Controllable Image Generation. (arXiv:2306.00986v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00986
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#25955;&#33258;&#23548;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#20869;&#37096;&#34920;&#31034;&#26469;&#25552;&#20379;&#23545;&#29983;&#25104;&#22270;&#20687;&#30340;&#26356;&#22823;&#25511;&#21046;&#65292;&#21487;&#20197;&#29992;&#20110;&#25191;&#34892;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22270;&#20687;&#25805;&#20316;&#65292;&#21516;&#26102;&#19981;&#38656;&#35201;&#39069;&#22806;&#27169;&#22411;&#25110;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#29983;&#25104;&#27169;&#22411;&#33021;&#22815;&#20174;&#35814;&#32454;&#25991;&#26412;&#25551;&#36848;&#20013;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#22270;&#20687;&#12290;&#28982;&#32780;&#65292;&#22270;&#20687;&#30340;&#35768;&#22810;&#26041;&#38754;&#24456;&#38590;&#25110;&#19981;&#21487;&#33021;&#36890;&#36807;&#25991;&#26412;&#26469;&#20256;&#36798;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#33258;&#23548;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#20869;&#37096;&#34920;&#31034;&#26469;&#25552;&#20379;&#23545;&#29983;&#25104;&#22270;&#20687;&#30340;&#26356;&#22823;&#25511;&#21046;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#20174;&#36825;&#20123;&#34920;&#31034;&#20013;&#25552;&#21462;&#20986;&#23545;&#35937;&#30340;&#24418;&#29366;&#12289;&#20301;&#32622;&#21644;&#22806;&#35266;&#31561;&#23646;&#24615;&#24182;&#29992;&#20110;&#25351;&#23548;&#37319;&#26679;&#12290;&#33258;&#23548;&#31867;&#20284;&#20110;&#20998;&#31867;&#22120;&#24341;&#23548;&#65292;&#20294;&#26159;&#20351;&#29992;&#39044;&#35757;&#32451;&#27169;&#22411;&#26412;&#36523;&#20013;&#23384;&#22312;&#30340;&#20449;&#21495;&#65292;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#27169;&#22411;&#25110;&#35757;&#32451;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#32452;&#21512;&#19968;&#32452;&#31616;&#21333;&#30340;&#23646;&#24615;&#26469;&#25191;&#34892;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22270;&#20687;&#25805;&#20316;&#65292;&#20363;&#22914;&#20462;&#25913;&#23545;&#35937;&#30340;&#20301;&#32622;&#25110;&#22823;&#23567;&#65292;&#23558;&#19968;&#20010;&#22270;&#20687;&#20013;&#30340;&#23545;&#35937;&#22806;&#35266;&#19982;&#21478;&#19968;&#20010;&#22270;&#20687;&#30340;&#24067;&#23616;&#30456;&#32467;&#21512;&#65292;&#23558;&#22810;&#20010;&#22270;&#20687;&#30340;&#23545;&#35937;&#32452;&#21512;&#25104;&#19968;&#20010;&#65292;&#31561;&#31561;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#33258;&#23548;&#21487;&#20197;&#29992;&#20110;&#32534;&#36753;&#30495;&#23454;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large-scale generative models are capable of producing high-quality images from detailed text descriptions. However, many aspects of an image are difficult or impossible to convey through text. We introduce self-guidance, a method that provides greater control over generated images by guiding the internal representations of diffusion models. We demonstrate that properties such as the shape, location, and appearance of objects can be extracted from these representations and used to steer sampling. Self-guidance works similarly to classifier guidance, but uses signals present in the pretrained model itself, requiring no additional models or training. We show how a simple set of properties can be composed to perform challenging image manipulations, such as modifying the position or size of objects, merging the appearance of objects in one image with the layout of another, composing objects from many images into one, and more. We also show that self-guidance can be used to edit real images
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28151;&#21512;&#20114;&#20449;&#24687;&#20272;&#35745;&#30340;&#26377;&#25928;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#26041;&#27861;&#20197;&#24212;&#23545;&#21028;&#21035;&#24335;&#21644;&#29983;&#25104;&#24335;&#26041;&#27861;&#21508;&#33258;&#32570;&#28857;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#39044;&#27979;&#37327;&#21270;&#30340;&#29983;&#25104;&#26041;&#27861;&#65292;&#19982;&#21028;&#21035;&#24335;&#20272;&#35745;&#22120;&#32467;&#21512;&#21487;&#33719;&#24471;&#26356;&#31934;&#30830;&#30340;&#20114;&#20449;&#24687;&#20272;&#35745;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.00608</link><description>&lt;p&gt;
&#20851;&#20110;&#28151;&#21512;&#20114;&#20449;&#24687;&#20272;&#35745;&#30340;&#26377;&#25928;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Effectiveness of Hybrid Mutual Information Estimation. (arXiv:2306.00608v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00608
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28151;&#21512;&#20114;&#20449;&#24687;&#20272;&#35745;&#30340;&#26377;&#25928;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#26041;&#27861;&#20197;&#24212;&#23545;&#21028;&#21035;&#24335;&#21644;&#29983;&#25104;&#24335;&#26041;&#27861;&#21508;&#33258;&#32570;&#28857;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#39044;&#27979;&#37327;&#21270;&#30340;&#29983;&#25104;&#26041;&#27861;&#65292;&#19982;&#21028;&#21035;&#24335;&#20272;&#35745;&#22120;&#32467;&#21512;&#21487;&#33719;&#24471;&#26356;&#31934;&#30830;&#30340;&#20114;&#20449;&#24687;&#20272;&#35745;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#32852;&#21512;&#20998;&#24067;&#30340;&#26679;&#26412;&#20013;&#20272;&#35745;&#20114;&#20449;&#24687;&#26159;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#30340;&#19968;&#20010;&#38590;&#39064;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#27010;&#25324;&#20102;&#21028;&#21035;&#24335;&#21644;&#29983;&#25104;&#24335;&#26041;&#27861;&#30340;&#21464;&#20998;&#30028;&#32422;&#26463;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#26041;&#27861;&#26469;&#20943;&#23569;&#23427;&#20204;&#21508;&#33258;&#30340;&#32570;&#28857;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#39044;&#27979;&#37327;&#21270; (PQ) &#30340;&#31616;&#21333;&#29983;&#25104;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#19982;&#21028;&#21035;&#24335;&#20272;&#35745;&#22120;&#36731;&#26494;&#32467;&#21512;&#20197;&#23454;&#29616;&#26368;&#23567;&#30340;&#35745;&#31639;&#24320;&#38144;&#12290;&#25105;&#20204;&#30340;&#25552;&#35758;&#36890;&#36807;&#38477;&#20302;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#32780;&#20135;&#29983;&#26356;&#32039;&#30340;&#20449;&#24687;&#30028;&#32422;&#26463;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#26041;&#27861;&#24212;&#29992;&#20110;&#30456;&#20851;&#30340;&#39640;&#32500;&#39640;&#26031;&#20998;&#24067;&#21644;&#28041;&#21450;&#21463;&#22266;&#23450;&#33021;&#37327;&#26223;&#35266;&#32422;&#26463;&#30340;&#33258;&#30001;&#31890;&#23376;&#31995;&#32479;&#30340;&#38543;&#26426;&#36807;&#31243;&#30340;&#25361;&#25112;&#24615;&#20219;&#21153;&#19978;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#30456;&#24212;&#30340;&#21028;&#21035;&#24335;&#20272;&#35745;&#26041;&#27861;&#30456;&#27604;&#65292;&#28151;&#21512;&#26041;&#27861;&#21487;&#20197;&#25345;&#32493;&#25552;&#39640;&#20114;&#20449;&#24687;&#20272;&#35745;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating the mutual information from samples from a joint distribution is a challenging problem in both science and engineering. In this work, we realize a variational bound that generalizes both discriminative and generative approaches. Using this bound, we propose a hybrid method to mitigate their respective shortcomings. Further, we propose Predictive Quantization (PQ): a simple generative method that can be easily combined with discriminative estimators for minimal computational overhead. Our propositions yield a tighter bound on the information thanks to the reduced variance of the estimator. We test our methods on a challenging task of correlated high-dimensional Gaussian distributions and a stochastic process involving a system of free particles subjected to a fixed energy landscape. Empirical results show that hybrid methods consistently improved mutual information estimates when compared to the corresponding discriminative counterpart.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#26041;&#24046;&#32422;&#31616;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#20197;&#23454;&#29616;&#23545;&#22810;&#22359;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#30340;&#39640;&#25928;&#27714;&#35299;&#65292;&#21516;&#26102;&#21305;&#37197;&#21333;&#22359;&#26631;&#20934; BO &#38382;&#39064;&#30340;&#26368;&#20248;&#22797;&#26434;&#24230;&#12289;&#23454;&#29616;&#24182;&#34892;&#21270;&#21152;&#36895;&#65292;&#20197;&#21450;&#36991;&#20813;&#35745;&#31639;&#39640;&#32500;&#24230;&#30340; Hessian &#30697;&#38453;&#30340;&#36870;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2305.18730</link><description>&lt;p&gt;
&#22810;&#22359;&#21452;&#23618;&#20248;&#21270;&#30340;&#20998;&#22359;&#38543;&#26426;&#26041;&#24046;&#32422;&#31616;&#26041;&#27861;&#21450;&#24182;&#34892;&#21152;&#36895;
&lt;/p&gt;
&lt;p&gt;
Blockwise Stochastic Variance-Reduced Methods with Parallel Speedup for Multi-Block Bilevel Optimization. (arXiv:2305.18730v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18730
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#26041;&#24046;&#32422;&#31616;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#20197;&#23454;&#29616;&#23545;&#22810;&#22359;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#30340;&#39640;&#25928;&#27714;&#35299;&#65292;&#21516;&#26102;&#21305;&#37197;&#21333;&#22359;&#26631;&#20934; BO &#38382;&#39064;&#30340;&#26368;&#20248;&#22797;&#26434;&#24230;&#12289;&#23454;&#29616;&#24182;&#34892;&#21270;&#21152;&#36895;&#65292;&#20197;&#21450;&#36991;&#20813;&#35745;&#31639;&#39640;&#32500;&#24230;&#30340; Hessian &#30697;&#38453;&#30340;&#36870;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#38750;&#20984;&#30340;&#22810;&#22359;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#20998;&#22359;&#26041;&#24046;&#32422;&#31616;&#30340;&#20248;&#21270;&#31639;&#27861;&#12290;&#20026;&#20102;&#36798;&#21040;&#31639;&#27861;&#30340;&#19977;&#20010;&#26399;&#26395;&#65306;&#65288;a&#65289;&#33021;&#21305;&#37197;&#21333;&#22359;&#26631;&#20934; BO &#38382;&#39064;&#30340;&#26368;&#20248;&#22797;&#26434;&#24230;&#65307;&#65288;b&#65289;&#23454;&#29616;&#24182;&#34892;&#21270;&#21152;&#36895;&#65292;&#27599;&#20010;&#36845;&#20195;&#20013;&#37319;&#26679; $I$ &#22359;&#24182;&#23545;&#27599;&#20010;&#37319;&#26679;&#22359;&#37319;&#26679; $B$ &#20010;&#26679;&#26412;&#65307;&#65288;c&#65289;&#36991;&#20813;&#35745;&#31639;&#39640;&#32500;&#24230;&#30340; Hessian &#30697;&#38453;&#30340;&#36870;&#20272;&#35745;&#12290;&#26412;&#25991;&#26088;&#22312;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#25506;&#35752;&#20102;&#29616;&#26377;&#31639;&#27861;&#30340;&#20851;&#32852;&#24615;&#20197;&#21450;&#19981;&#36275;&#20043;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider non-convex multi-block bilevel optimization (MBBO) problems, which involve $m\gg 1$ lower level problems and have important applications in machine learning. Designing a stochastic gradient and controlling its variance is more intricate due to the hierarchical sampling of blocks and data and the unique challenge of estimating hyper-gradient. We aim to achieve three nice properties for our algorithm: (a) matching the state-of-the-art complexity of standard BO problems with a single block; (b) achieving parallel speedup by sampling $I$ blocks and sampling $B$ samples for each sampled block per-iteration; (c) avoiding the computation of the inverse of a high-dimensional Hessian matrix estimator. However, it is non-trivial to achieve all of these by observing that existing works only achieve one or two of these properties. To address the involved challenges for achieving (a, b, c), we propose two stochastic algorithms by using advanced blockwise variance-reductio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#31350;&#20102;&#39640;&#26031;-&#26031;&#22374;&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#21160;&#24577;&#24615;&#12290;&#23545;&#20110;&#20174;&#39640;&#26031;&#30446;&#26631;&#20013;&#37319;&#26679;&#65292;&#21482;&#35201;&#21021;&#22987;&#20540;&#26159;&#39640;&#26031;&#30340;&#65292;&#20855;&#26377;&#21452;&#32447;&#24615;&#26680;&#30340;SVGD&#21160;&#24577;&#23558;&#20445;&#25345;&#39640;&#26031;&#29366;&#24577;&#12290;&#24403;&#30446;&#26631;&#20989;&#25968;&#21576;&#29616;&#20986;&#24378;&#23545;&#25968;&#20985;&#24615;&#26102;&#65292;&#35777;&#26126;&#20102;&#22343;&#22330;&#39640;&#26031;-SVGD&#21160;&#24577;&#20250;&#32447;&#24615;&#25910;&#25947;&#20110;KL&#25955;&#24230;&#19979;&#26368;&#25509;&#36817;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#12290;&#22312;&#26377;&#38480;&#31890;&#23376;&#35774;&#32622;&#20013;&#65292;&#23384;&#22312;&#23545;&#22343;&#22330;&#26497;&#38480;&#30340;&#26102;&#38388;&#24494;&#27493;&#19968;&#33268;&#25910;&#25947;&#20197;&#21450;&#32447;&#24615;&#25910;&#25947;&#33267;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2305.14076</link><description>&lt;p&gt;
&#20851;&#20110;&#39640;&#26031;-&#26031;&#22374;&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#21160;&#24577;&#24615;&#30340;&#25506;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards Understanding the Dynamics of Gaussian--Stein Variational Gradient Descent. (arXiv:2305.14076v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14076
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#31350;&#20102;&#39640;&#26031;-&#26031;&#22374;&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#21160;&#24577;&#24615;&#12290;&#23545;&#20110;&#20174;&#39640;&#26031;&#30446;&#26631;&#20013;&#37319;&#26679;&#65292;&#21482;&#35201;&#21021;&#22987;&#20540;&#26159;&#39640;&#26031;&#30340;&#65292;&#20855;&#26377;&#21452;&#32447;&#24615;&#26680;&#30340;SVGD&#21160;&#24577;&#23558;&#20445;&#25345;&#39640;&#26031;&#29366;&#24577;&#12290;&#24403;&#30446;&#26631;&#20989;&#25968;&#21576;&#29616;&#20986;&#24378;&#23545;&#25968;&#20985;&#24615;&#26102;&#65292;&#35777;&#26126;&#20102;&#22343;&#22330;&#39640;&#26031;-SVGD&#21160;&#24577;&#20250;&#32447;&#24615;&#25910;&#25947;&#20110;KL&#25955;&#24230;&#19979;&#26368;&#25509;&#36817;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#12290;&#22312;&#26377;&#38480;&#31890;&#23376;&#35774;&#32622;&#20013;&#65292;&#23384;&#22312;&#23545;&#22343;&#22330;&#26497;&#38480;&#30340;&#26102;&#38388;&#24494;&#27493;&#19968;&#33268;&#25910;&#25947;&#20197;&#21450;&#32447;&#24615;&#25910;&#25947;&#33267;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Stein Variational Gradient Descent (SVGD)&#26159;&#19968;&#31181;&#38750;&#21442;&#25968;&#22522;&#20110;&#31890;&#23376;&#30340;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#12290;&#23613;&#31649;&#20854;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#29702;&#35299;SVGD&#30340;&#29702;&#35770;&#23646;&#24615;&#19968;&#30452;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;&#23545;&#20110;&#20174;&#39640;&#26031;&#30446;&#26631;&#20013;&#37319;&#26679;&#65292;&#21482;&#35201;&#21021;&#22987;&#20540;&#26159;&#39640;&#26031;&#30340;&#65292;&#20855;&#26377;&#21452;&#32447;&#24615;&#26680;&#30340;SVGD&#21160;&#24577;&#23558;&#20445;&#25345;&#39640;&#26031;&#29366;&#24577;&#12290;&#21463;&#27492;&#20107;&#23454;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#36890;&#36807;&#21452;&#32447;&#24615;&#26680;&#23558;SVGD&#25237;&#24433;&#21040;&#39640;&#26031;&#20998;&#24067;&#26063;&#20013;&#65292;&#21363;&#39640;&#26031;&#21464;&#20998;&#25512;&#26029; (GVI) &#19982; SVGD&#12290;&#25105;&#20204;&#36890;&#36807;&#32771;&#34385;&#22343;&#22330; PDE &#21644;&#31163;&#25955;&#31890;&#23376;&#31995;&#32479;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#23436;&#25972;&#30340;&#22270;&#20687;&#12290;&#24403;&#30446;&#26631;&#20989;&#25968;&#21576;&#29616;&#20986;&#24378;&#23545;&#25968;&#20985;&#24615;&#26102;&#65292;&#35777;&#26126;&#20102;&#22343;&#22330;&#39640;&#26031;-SVGD&#21160;&#24577;&#20250;&#32447;&#24615;&#25910;&#25947;&#20110;KL&#25955;&#24230;&#19979;&#26368;&#25509;&#36817;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#12290;&#22312;&#26377;&#38480;&#31890;&#23376;&#35774;&#32622;&#20013;&#65292;&#23384;&#22312;&#23545;&#22343;&#22330;&#26497;&#38480;&#30340;&#26102;&#38388;&#24494;&#27493;&#19968;&#33268;&#25910;&#25947;&#20197;&#21450;&#32447;&#24615;&#25910;&#25947;&#33267;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#22522;&#20110;&#19968;&#20010;&#26032;&#30340;&#20195;&#25968;&#24658;&#31561;&#24335;&#65292;&#35813;&#31561;&#24335;&#23558;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#30340;&#36153;&#24076;&#23572;&#20449;&#24687;&#30697;&#38453;&#19982;&#31890;&#23376;&#22343;&#21248;&#20998;&#24067;&#30340;&#36153;&#24076;&#23572;&#20449;&#24687;&#30697;&#38453;&#30456;&#20851;&#32852;&#12290;&#36825;&#20010;&#31561;&#24335;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#36879;&#35270; GVI with SVGD &#22312;&#22343;&#22330;&#21644;&#31890;&#23376;&#35774;&#32622;&#20013;&#30340;&#21160;&#24577;&#24615;&#30340;&#32479;&#19968;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stein Variational Gradient Descent (SVGD) is a nonparametric particle-based deterministic sampling algorithm. Despite its wide usage, understanding the theoretical properties of SVGD has remained a challenging problem. For sampling from a Gaussian target, the SVGD dynamics with a bilinear kernel will remain Gaussian as long as the initializer is Gaussian. Inspired by this fact, we undertake a detailed theoretical study of the Gaussian-SVGD, i.e., SVGD projected to the family of Gaussian distributions via the bilinear kernel, or equivalently Gaussian variational inference (GVI) with SVGD. We present a complete picture by considering both the mean-field PDE and discrete particle systems. When the target is strongly log-concave, the mean-field Gaussian-SVGD dynamics is proven to converge linearly to the Gaussian distribution closest to the target in KL divergence. In the finite-particle setting, there is both uniform in time convergence to the mean-field limit and linear convergence in ti
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#20174;&#19968;&#20010;&#25968;&#25454;&#20998;&#24067;P&#20256;&#36755;&#21040;&#20219;&#24847;&#35775;&#38382;&#36890;&#36807;&#26377;&#38480;&#26679;&#26412;&#30340;Q&#30340;&#27969;&#27169;&#22411;&#12290;&#36825;&#20010;&#27169;&#22411;&#36890;&#36807;&#31070;&#32463;ODE&#27169;&#22411;&#36827;&#34892;&#65292;&#21487;&#20197;&#36827;&#34892;&#26080;&#31351;&#23567;DRE&#12290;</title><link>http://arxiv.org/abs/2305.11857</link><description>&lt;p&gt;
Q-malizing&#27969;&#21644;&#26080;&#31351;&#23567;&#23494;&#24230;&#27604;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Q-malizing flow and infinitesimal density ratio estimation. (arXiv:2305.11857v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11857
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#20174;&#19968;&#20010;&#25968;&#25454;&#20998;&#24067;P&#20256;&#36755;&#21040;&#20219;&#24847;&#35775;&#38382;&#36890;&#36807;&#26377;&#38480;&#26679;&#26412;&#30340;Q&#30340;&#27969;&#27169;&#22411;&#12290;&#36825;&#20010;&#27169;&#22411;&#36890;&#36807;&#31070;&#32463;ODE&#27169;&#22411;&#36827;&#34892;&#65292;&#21487;&#20197;&#36827;&#34892;&#26080;&#31351;&#23567;DRE&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36830;&#32493;&#30340;&#27491;&#21017;&#21270;&#27969;&#22312;&#29983;&#25104;&#20219;&#21153;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20854;&#20013;&#27969;&#32593;&#32476;&#20174;&#25968;&#25454;&#20998;&#24067;P&#20256;&#36755;&#21040;&#27491;&#24577;&#20998;&#24067;&#12290;&#19968;&#31181;&#33021;&#22815;&#20174;P&#20256;&#36755;&#21040;&#20219;&#24847;Q&#30340;&#27969;&#27169;&#22411;&#65292;&#20854;&#20013;P&#21644;Q&#37117;&#21487;&#36890;&#36807;&#26377;&#38480;&#26679;&#26412;&#35775;&#38382;&#65292;&#23558;&#22312;&#21508;&#31181;&#24212;&#29992;&#20852;&#36259;&#20013;&#20351;&#29992;&#65292;&#29305;&#21035;&#26159;&#22312;&#26368;&#36817;&#24320;&#21457;&#30340;&#26395;&#36828;&#38236;&#23494;&#24230;&#27604;&#20272;&#35745;&#20013;&#65288;DRE&#65289;&#65292;&#23427;&#38656;&#35201;&#26500;&#24314;&#20013;&#38388;&#23494;&#24230;&#20197;&#22312;P&#21644;Q&#20043;&#38388;&#24314;&#31435;&#26725;&#26753;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36825;&#26679;&#30340;&#8220;Q-malizing&#27969;&#8221;&#65292;&#36890;&#36807;&#31070;&#32463;ODE&#27169;&#22411;&#36827;&#34892;&#65292;&#35813;&#27169;&#22411;&#36890;&#36807;&#32463;&#39564;&#26679;&#26412;&#30340;&#21487;&#36870;&#20256;&#36755;&#20174;P&#21040;Q&#65288;&#21453;&#20043;&#20134;&#28982;&#65289;&#65292;&#24182;&#36890;&#36807;&#26368;&#23567;&#21270;&#20256;&#36755;&#25104;&#26412;&#36827;&#34892;&#27491;&#21017;&#21270;&#12290;&#35757;&#32451;&#22909;&#30340;&#27969;&#27169;&#22411;&#20351;&#25105;&#20204;&#33021;&#22815;&#27839;&#19982;&#26102;&#38388;&#21442;&#25968;&#21270;&#30340;log&#23494;&#24230;&#36827;&#34892;&#26080;&#31351;&#23567;DRE&#65292;&#36890;&#36807;&#35757;&#32451;&#38468;&#21152;&#30340;&#36830;&#32493;&#26102;&#38388;&#27969;&#32593;&#32476;&#20351;&#29992;&#20998;&#31867;&#25439;&#22833;&#26469;&#20272;&#35745;log&#23494;&#24230;&#30340;&#26102;&#38388;&#20559;&#23548;&#25968;&#12290;&#36890;&#36807;&#31215;&#20998;&#26102;&#38388;&#24471;&#20998;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Continuous normalizing flows are widely used in generative tasks, where a flow network transports from a data distribution $P$ to a normal distribution. A flow model that can transport from $P$ to an arbitrary $Q$, where both $P$ and $Q$ are accessible via finite samples, would be of various application interests, particularly in the recently developed telescoping density ratio estimation (DRE) which calls for the construction of intermediate densities to bridge between $P$ and $Q$. In this work, we propose such a ``Q-malizing flow'' by a neural-ODE model which is trained to transport invertibly from $P$ to $Q$ (and vice versa) from empirical samples and is regularized by minimizing the transport cost. The trained flow model allows us to perform infinitesimal DRE along the time-parametrized $\log$-density by training an additional continuous-time flow network using classification loss, which estimates the time-partial derivative of the $\log$-density. Integrating the time-score network
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#31350;&#20102; multi-label &#23398;&#20064;&#20013;&#24120;&#29992;&#30340; Macro-AUC &#30340;&#27867;&#21270;&#24615;&#36136;&#65292;&#24182;&#21457;&#29616;&#25968;&#25454;&#38598;&#20013;&#26631;&#31614;&#19981;&#24179;&#34913;&#23545;&#27867;&#21270;&#30028;&#38480;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#26410;&#32463;&#21464;&#37327;&#22788;&#29702;&#30340;&#22522;&#20110;&#25439;&#22833;&#20989;&#25968;&#30340;&#31639;&#27861;&#21487;&#33021;&#30001;&#20110;&#23545;&#26631;&#31614;&#30340;&#19981;&#24179;&#34913;&#26356;&#25935;&#24863;&#32780;&#34920;&#29616;&#36739;&#24046;&#65292;&#36825;&#19968;&#32467;&#35770;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.05248</link><description>&lt;p&gt;
&#20851;&#20110;&#22810;&#26631;&#31614;&#23398;&#20064;&#20013;Macro-AUC&#30340;&#27867;&#21270;&#29702;&#35299;&#25506;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards Understanding Generalization of Macro-AUC in Multi-label Learning. (arXiv:2305.05248v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05248
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#31350;&#20102; multi-label &#23398;&#20064;&#20013;&#24120;&#29992;&#30340; Macro-AUC &#30340;&#27867;&#21270;&#24615;&#36136;&#65292;&#24182;&#21457;&#29616;&#25968;&#25454;&#38598;&#20013;&#26631;&#31614;&#19981;&#24179;&#34913;&#23545;&#27867;&#21270;&#30028;&#38480;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#26410;&#32463;&#21464;&#37327;&#22788;&#29702;&#30340;&#22522;&#20110;&#25439;&#22833;&#20989;&#25968;&#30340;&#31639;&#27861;&#21487;&#33021;&#30001;&#20110;&#23545;&#26631;&#31614;&#30340;&#19981;&#24179;&#34913;&#26356;&#25935;&#24863;&#32780;&#34920;&#29616;&#36739;&#24046;&#65292;&#36825;&#19968;&#32467;&#35770;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#26631;&#31614;&#23398;&#20064;&#20013;&#65292;Macro-AUC&#26159;&#31867;&#20869;AUC&#31639;&#26415;&#24179;&#22343;&#20540;&#65292;&#36890;&#24120;&#22312;&#23454;&#36341;&#20013;&#20351;&#29992;&#12290;&#28982;&#32780;&#65292;&#23427;&#30340;&#29702;&#35770;&#29702;&#35299;&#36828;&#36828;&#19981;&#36275;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#22522;&#20110;&#23545;&#24212;&#30340;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#34920;&#24449;&#21508;&#31181;&#23398;&#20064;&#31639;&#27861;&#30340;&#23439;AUC&#30340;&#27867;&#21270;&#23646;&#24615;&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#30830;&#23450;&#20102;&#24433;&#21709;&#27867;&#21270;&#30028;&#38480;&#30340;&#25968;&#25454;&#38598;&#30340;&#20851;&#38190;&#22240;&#32032;&#65306;&#26631;&#31614;&#31867;&#21035;&#19981;&#24179;&#34913;&#12290;&#25105;&#20204;&#23545;&#19981;&#24179;&#34913;&#24863;&#30693;&#35823;&#24046;&#30028;&#38480;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#24191;&#27867;&#20351;&#29992;&#30340;&#26410;&#32463;&#21464;&#37327;&#22788;&#29702;&#30340;&#22522;&#20110;&#25439;&#22833;&#20989;&#25968;&#30340;&#31639;&#27861;&#27604;&#25552;&#20986;&#30340;&#22522;&#20110;&#25104;&#23545;&#21644;&#37325;&#26032;&#21152;&#26435;&#30340;&#31639;&#27861;&#26356;&#25935;&#24863;&#20110;&#26631;&#31614;&#31867;&#21035;&#30340;&#19981;&#24179;&#34913;&#65292;&#36825;&#21487;&#33021;&#24847;&#21619;&#30528;&#23427;&#30340;&#24615;&#33021;&#36739;&#24046;&#12290;&#27492;&#22806;&#65292;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#30340;&#32463;&#39564;&#32467;&#26524;&#35777;&#23454;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;&#23601;&#25216;&#26415;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#65288;&#26356;&#36890;&#29992;&#30340;&#65289;McDiarmid&#22411;&#38598;&#20013;&#19981;&#31561;&#24335;&#65292;&#36825;&#21487;&#33021;&#20855;&#26377;&#29420;&#31435;&#30340;&#20852;&#36259;&#12290;
&lt;/p&gt;
&lt;p&gt;
Macro-AUC is the arithmetic mean of the class-wise AUCs in multi-label learning and is commonly used in practice. However, its theoretical understanding is far lacking. Toward solving it, we characterize the generalization properties of various learning algorithms based on the corresponding surrogate losses w.r.t. Macro-AUC. We theoretically identify a critical factor of the dataset affecting the generalization bounds: \emph{the label-wise class imbalance}. Our results on the imbalance-aware error bounds show that the widely-used univariate loss-based algorithm is more sensitive to the label-wise class imbalance than the proposed pairwise and reweighted loss-based ones, which probably implies its worse performance. Moreover, empirical results on various datasets corroborate our theory findings. To establish it, technically, we propose a new (and more general) McDiarmid-type concentration inequality, which may be of independent interest.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#38745;&#24577;&#29615;&#22659;&#19979;&#30340;MNL-Bandit&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#20854;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#39044;&#26399;&#36951;&#25022;&#24230;&#20026;$\tilde{O}\left( \min \left\{ \sqrt{NTL}\;,\; N^{\frac{1}{3}}(\Delta_{\infty}^{K})^{\frac{1}{3}} T^{\frac{2}{3}} + \sqrt{NT}\right\}\right)$&#12290;&#31639;&#27861;&#22522;&#20110;&#26102;&#20195;&#31639;&#27861;&#65292;&#23545;&#30001;&#20110;&#38750;&#38745;&#24577;&#24615;&#24341;&#20837;&#30340;&#20272;&#35745;&#22120;&#20559;&#24046;&#36827;&#34892;&#20102;&#32039;&#33268;&#29305;&#24449;&#32473;&#20986;&#26032;&#30340;&#27987;&#24230;&#30028;&#12290;</title><link>http://arxiv.org/abs/2303.02504</link><description>&lt;p&gt;
&#38750;&#38745;&#24577;&#29615;&#22659;&#19979;&#30340;MNL-Bandit&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
MNL-Bandit in non-stationary environments. (arXiv:2303.02504v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.02504
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#38745;&#24577;&#29615;&#22659;&#19979;&#30340;MNL-Bandit&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#20854;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#39044;&#26399;&#36951;&#25022;&#24230;&#20026;$\tilde{O}\left( \min \left\{ \sqrt{NTL}\;,\; N^{\frac{1}{3}}(\Delta_{\infty}^{K})^{\frac{1}{3}} T^{\frac{2}{3}} + \sqrt{NT}\right\}\right)$&#12290;&#31639;&#27861;&#22522;&#20110;&#26102;&#20195;&#31639;&#27861;&#65292;&#23545;&#30001;&#20110;&#38750;&#38745;&#24577;&#24615;&#24341;&#20837;&#30340;&#20272;&#35745;&#22120;&#20559;&#24046;&#36827;&#34892;&#20102;&#32039;&#33268;&#29305;&#24449;&#32473;&#20986;&#26032;&#30340;&#27987;&#24230;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#38745;&#24577;&#29615;&#22659;&#19979;&#30340;MNL-Bandit&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#20854;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#39044;&#26399;&#36951;&#25022;&#24230;&#20026;$\tilde{O}\left( \min \left\{ \sqrt{NTL}\;,\; N^{\frac{1}{3}}(\Delta_{\infty}^{K})^{\frac{1}{3}} T^{\frac{2}{3}} + \sqrt{NT}\right\}\right)$&#12290;&#20854;&#20013;$N$&#26159;&#33218;&#30340;&#25968;&#37327;&#65292;$L$&#26159;&#21464;&#21270;&#30340;&#25968;&#37327;&#65292;$\Delta_{\infty}^{K}$&#26159;&#26410;&#30693;&#21442;&#25968;&#30340;&#21464;&#21270;&#24230;&#37327;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26399;&#26395;&#36951;&#25022;&#24230;&#30340;&#21305;&#37197;&#19979;&#30028;&#65288;&#23545;&#25968;&#22240;&#23376;&#20869;&#30340;&#19979;&#30028;&#65289;&#65292;&#35828;&#26126;&#25105;&#20204;&#30340;&#31639;&#27861;&#26159;&#26368;&#20248;&#30340;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;Agrawal&#31561;&#20154;2016&#24180;&#25552;&#20986;&#30340;&#38745;&#24577;MNL-Bandit&#30340;&#26102;&#20195;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#38750;&#38745;&#24577;&#24615;&#24102;&#26469;&#20102;&#19968;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#26032;&#30340;&#25216;&#26415;&#21644;&#24819;&#27861;&#26469;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#30001;&#20110;&#38750;&#38745;&#24577;&#24615;&#24341;&#20837;&#30340;&#20272;&#35745;&#22120;&#20559;&#24046;&#30340;&#32039;&#33268;&#29305;&#24449;&#65292;&#24182;&#25512;&#23548;&#20986;&#26032;&#30340;&#27987;&#24230;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the MNL-Bandit problem in a non-stationary environment and present an algorithm with a worst-case expected regret of $\tilde{O}\left( \min \left\{ \sqrt{NTL}\;,\; N^{\frac{1}{3}}(\Delta_{\infty}^{K})^{\frac{1}{3}} T^{\frac{2}{3}} + \sqrt{NT}\right\}\right)$. Here $N$ is the number of arms, $L$ is the number of changes and $\Delta_{\infty}^{K}$ is a variation measure of the unknown parameters. Furthermore, we show matching lower bounds on the expected regret (up to logarithmic factors), implying that our algorithm is optimal. Our approach builds upon the epoch-based algorithm for stationary MNL-Bandit in Agrawal et al. 2016. However, non-stationarity poses several challenges and we introduce new techniques and ideas to address these. In particular, we give a tight characterization for the bias introduced in the estimators due to non stationarity and derive new concentration bounds.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#38754;&#21521;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#30340;&#22312;&#32447;&#36830;&#32493;&#36229;&#21442;&#25968;&#35843;&#25972;&#26694;&#26550;CDT&#65292;&#33021;&#22815;&#21160;&#24577;&#22320;&#22312;&#25628;&#32034;&#31354;&#38388;&#20869;&#23398;&#20064;&#26368;&#20248;&#21442;&#25968;&#37197;&#32622;&#12290;</title><link>http://arxiv.org/abs/2302.09440</link><description>&lt;p&gt;
&#22312;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#36827;&#34892;&#22312;&#32447;&#36830;&#32493;&#36229;&#21442;&#25968;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Online Continuous Hyperparameter Optimization for Contextual Bandits. (arXiv:2302.09440v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09440
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#38754;&#21521;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#30340;&#22312;&#32447;&#36830;&#32493;&#36229;&#21442;&#25968;&#35843;&#25972;&#26694;&#26550;CDT&#65292;&#33021;&#22815;&#21160;&#24577;&#22320;&#22312;&#25628;&#32034;&#31354;&#38388;&#20869;&#23398;&#20064;&#26368;&#20248;&#21442;&#25968;&#37197;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#38543;&#26426;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#20195;&#29702;&#26681;&#25454;&#36807;&#21435;&#30340;&#32463;&#39564;&#20174;&#26102;&#38388;&#30456;&#20851;&#34892;&#21160;&#38598;&#20013;&#20381;&#27425;&#37319;&#21462;&#34892;&#21160;&#65292;&#20197;&#26368;&#23567;&#21270;&#24635;&#21518;&#24724;&#12290;&#19982;&#35768;&#22810;&#20854;&#20182;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#19968;&#26679;&#65292;&#24378;&#21270;&#23398;&#20064;&#30340;&#24615;&#33021;&#20005;&#37325;&#20381;&#36182;&#20110;&#20854;&#22810;&#20010;&#36229;&#21442;&#25968;&#65292;&#24182;&#19988;&#29702;&#35770;&#25512;&#23548;&#20986;&#30340;&#21442;&#25968;&#20540;&#21487;&#33021;&#23548;&#33268;&#23454;&#38469;&#19978;&#19981;&#20196;&#20154;&#28385;&#24847;&#30340;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#22312;&#24378;&#21270;&#23398;&#20064;&#29615;&#22659;&#19979;&#20351;&#29992;&#31163;&#32447;&#20248;&#21270;&#26041;&#27861;&#65288;&#22914;&#20132;&#21449;&#39564;&#35777;&#65289;&#36873;&#25321;&#36229;&#21442;&#25968;&#26159;&#19981;&#21487;&#34892;&#30340;&#65292;&#22240;&#20026;&#20915;&#31574;&#24517;&#39035;&#23454;&#26102;&#36827;&#34892;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#38754;&#21521;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#30340;&#22312;&#32447;&#36830;&#32493;&#36229;&#21442;&#25968;&#35843;&#25972;&#26694;&#26550;&#65292;&#20197;&#23398;&#20064;&#39134;&#34892;&#20013;&#30340;&#26368;&#20339;&#21442;&#25968;&#37197;&#32622;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#20010;&#21517;&#20026;CDT&#65288;Continuous Dynamic Tuning&#65289;&#30340;&#21452;&#23618;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#24182;&#23558;&#36229;&#21442;&#25968;&#20248;&#21270;&#24418;&#24335;&#21270;&#20026;&#38750;&#24179;&#31283;&#36830;&#32493;&#27494;&#22120;&#24378;&#21270;&#23398;&#20064;&#65292;&#22312;&#20854;&#20013;&#27599;&#20010;&#27494;&#22120;&#20195;&#34920;&#19968;&#31181;&#36229;&#21442;&#25968;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
In stochastic contextual bandits, an agent sequentially makes actions from a time-dependent action set based on past experience to minimize the cumulative regret. Like many other machine learning algorithms, the performance of bandits heavily depends on their multiple hyperparameters, and theoretically derived parameter values may lead to unsatisfactory results in practice. Moreover, it is infeasible to use offline tuning methods like cross-validation to choose hyperparameters under the bandit environment, as the decisions should be made in real time. To address this challenge, we propose the first online continuous hyperparameter tuning framework for contextual bandits to learn the optimal parameter configuration within a search space on the fly. Specifically, we use a double-layer bandit framework named CDT (Continuous Dynamic Tuning) and formulate the hyperparameter optimization as a non-stationary continuum-armed bandit, where each arm represents a combination of hyperparameters, a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20449;&#24687;&#35770;&#27867;&#21270;&#30028;&#38480;&#65292;&#21033;&#29992;&#25237;&#24433;&#25439;&#22833;&#23545;&#65292;&#19982;Rademacher&#24207;&#21015;&#30456;&#20851;&#32852;&#26469;&#28304;&#20110;&#36229;&#21462;&#26679;&#30340;&#35774;&#32622;&#65292;&#36825;&#20123;&#30028;&#38480;&#27604;&#21516;&#19968;&#36229;&#21462;&#26679;&#35774;&#32622;&#20013;&#36804;&#20170;&#24050;&#30693;&#30340;&#25152;&#26377;&#20449;&#24687;&#29702;&#35770;&#30028;&#38480;&#37117;&#26356;&#32039;&#23494;&#12290;</title><link>http://arxiv.org/abs/2302.02432</link><description>&lt;p&gt;
&#28304;&#20110;&#36229;&#21462;&#26679;&#30340;&#20449;&#24687;&#35770;&#27867;&#21270;&#30028;&#38480;&#26356;&#32039;&#23494;
&lt;/p&gt;
&lt;p&gt;
Tighter Information-Theoretic Generalization Bounds from Supersamples. (arXiv:2302.02432v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02432
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20449;&#24687;&#35770;&#27867;&#21270;&#30028;&#38480;&#65292;&#21033;&#29992;&#25237;&#24433;&#25439;&#22833;&#23545;&#65292;&#19982;Rademacher&#24207;&#21015;&#30456;&#20851;&#32852;&#26469;&#28304;&#20110;&#36229;&#21462;&#26679;&#30340;&#35774;&#32622;&#65292;&#36825;&#20123;&#30028;&#38480;&#27604;&#21516;&#19968;&#36229;&#21462;&#26679;&#35774;&#32622;&#20013;&#36804;&#20170;&#24050;&#30693;&#30340;&#25152;&#26377;&#20449;&#24687;&#29702;&#35770;&#30028;&#38480;&#37117;&#26356;&#32039;&#23494;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#38024;&#23545;&#23398;&#20064;&#31639;&#27861;&#30340;&#21508;&#31181;&#26032;&#39062;&#30340;&#20449;&#24687;&#35770;&#27867;&#21270;&#30028;&#38480;&#65292;&#28304;&#20110;Steinke&#65286;Zakynthinou&#65288;2020&#65289;&#30340;&#36229;&#21462;&#26679;&#35774;&#32622;-&#8220;&#26465;&#20214;&#20114;&#20449;&#24687;&#8221;&#26694;&#26550;&#30340;&#35774;&#32622;&#12290;&#25105;&#20204;&#30340;&#24320;&#21457;&#21033;&#29992;&#23558;&#25439;&#22833;&#23545;&#65288;&#20174;&#35757;&#32451;&#23454;&#20363;&#21644;&#27979;&#35797;&#23454;&#20363;&#33719;&#24471;&#65289;&#25237;&#24433;&#21040;&#21333;&#20010;&#25968;&#23383;&#65292;&#24182;&#23558;&#25439;&#22833;&#20540;&#19982;Rademacher&#24207;&#21015;&#65288;&#21450;&#20854;&#31227;&#21160;&#21464;&#20307;&#65289;&#30456;&#20851;&#32852;&#12290;&#25152;&#21576;&#29616;&#30340;&#30028;&#38480;&#21253;&#25324;&#24179;&#26041;&#26681;&#30028;&#38480;&#65292;&#24555;&#36895;&#29575;&#30028;&#38480;&#65292;&#21253;&#25324;&#22522;&#20110;&#26041;&#24046;&#21644;&#23574;&#38160;&#24230;&#30340;&#30028;&#38480;&#20197;&#21450;&#25554;&#20540;&#31639;&#27861;&#30340;&#30028;&#38480;&#31561;&#12290;&#25105;&#20204;&#29702;&#35770;&#19978;&#25110;&#32463;&#39564;&#19978;&#35777;&#26126;&#65292;&#36825;&#20123;&#30028;&#38480;&#27604;&#21516;&#19968;&#36229;&#21462;&#26679;&#35774;&#32622;&#20013;&#36804;&#20170;&#24050;&#30693;&#30340;&#25152;&#26377;&#20449;&#24687;&#29702;&#35770;&#30028;&#38480;&#37117;&#26356;&#32039;&#23494;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we present a variety of novel information-theoretic generalization bounds for learning algorithms, from the supersample setting of Steinke &amp; Zakynthinou (2020)-the setting of the "conditional mutual information" framework. Our development exploits projecting the loss pair (obtained from a training instance and a testing instance) down to a single number and correlating loss values with a Rademacher sequence (and its shifted variants). The presented bounds include square-root bounds, fast-rate bounds, including those based on variance and sharpness, and bounds for interpolating algorithms etc. We show theoretically or empirically that these bounds are tighter than all information-theoretic bounds known to date on the same supersample setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#27010;&#29575;&#32534;&#31243;&#20013;&#20351;&#29992;&#33258;&#21160;&#36793;&#32536;&#21270;&#20316;&#20026;&#37319;&#26679;&#36807;&#31243;&#30340;&#19968;&#37096;&#20998;&#65292;&#20351;&#29992; HMC &#22312;&#20174; PPL &#20013;&#25552;&#21462;&#30340;&#22270;&#24418;&#27169;&#22411;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#20174;&#29616;&#23454;&#19990;&#30028;&#30340;&#23618;&#27425;&#27169;&#22411;&#20013;&#37319;&#26679;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2302.00564</link><description>&lt;p&gt;
&#27010;&#29575;&#32534;&#31243;&#20013;&#30340;&#33258;&#21160;&#36793;&#32536;&#21270; MCMC
&lt;/p&gt;
&lt;p&gt;
Automatically Marginalized MCMC in Probabilistic Programming. (arXiv:2302.00564v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00564
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#27010;&#29575;&#32534;&#31243;&#20013;&#20351;&#29992;&#33258;&#21160;&#36793;&#32536;&#21270;&#20316;&#20026;&#37319;&#26679;&#36807;&#31243;&#30340;&#19968;&#37096;&#20998;&#65292;&#20351;&#29992; HMC &#22312;&#20174; PPL &#20013;&#25552;&#21462;&#30340;&#22270;&#24418;&#27169;&#22411;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#20174;&#29616;&#23454;&#19990;&#30028;&#30340;&#23618;&#27425;&#27169;&#22411;&#20013;&#37319;&#26679;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Hamiltonian Monte Carlo (HMC) &#26159;&#20174;&#36125;&#21494;&#26031;&#27169;&#22411;&#20013;&#37319;&#26679;&#28508;&#22312;&#21464;&#37327;&#30340;&#19968;&#31181;&#24378;&#22823;&#31639;&#27861;&#12290;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328; (PPL) &#30340;&#20986;&#29616;&#20351;&#29992;&#25143;&#25670;&#33073;&#20102;&#32534;&#20889;&#25512;&#26029;&#31639;&#27861;&#30340;&#28902;&#24700;&#65292;&#24182;&#35753;&#29992;&#25143;&#19987;&#27880;&#20110;&#27169;&#22411;&#24314;&#31435;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#27169;&#22411;&#37117;&#38590;&#20197;&#30452;&#25509;&#20351;&#29992; HMC &#35299;&#20915;&#65292;&#36890;&#24120;&#38656;&#35201;&#20351;&#29992;&#19968;&#20123;&#25216;&#24039;&#65292;&#22914;&#27169;&#22411;&#37325;&#26032;&#21442;&#25968;&#21270;&#12290;&#25105;&#20204;&#30340;&#21160;&#26426;&#22312;&#20110;&#35768;&#22810;&#36825;&#20123;&#27169;&#22411;&#21487;&#33021;&#36890;&#36807;&#36793;&#32536;&#21270;&#26469;&#31616;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#23558;&#33258;&#21160;&#36793;&#32536;&#21270;&#20316;&#20026;&#37319;&#26679;&#36807;&#31243;&#30340;&#19968;&#37096;&#20998;&#65292;&#20351;&#29992; HMC &#22312;&#20174; PPL &#20013;&#25552;&#21462;&#30340;&#22270;&#24418;&#27169;&#22411;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#36825;&#26174;&#33879;&#25552;&#39640;&#20102;&#20174;&#29616;&#23454;&#19990;&#30028;&#30340;&#23618;&#27425;&#27169;&#22411;&#20013;&#37319;&#26679;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hamiltonian Monte Carlo (HMC) is a powerful algorithm to sample latent variables from Bayesian models. The advent of probabilistic programming languages (PPLs) frees users from writing inference algorithms and lets users focus on modeling. However, many models are difficult for HMC to solve directly, and often require tricks like model reparameterization. We are motivated by the fact that many of those models could be simplified by marginalization. We propose to use automatic marginalization as part of the sampling process using HMC in a graphical model extracted from a PPL, which substantially improves sampling from real-world hierarchical models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21487;&#33021;&#20219;&#20309;&#26102;&#20505;&#23433;&#20840;&#30340;&#38543;&#26426;&#32452;&#21512;&#21322;&#33218;&#36172;&#21338;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20986;&#31639;&#27861;PASCombUCB&#22312;&#26102;&#38388;&#36724;&#19978;&#26368;&#23567;&#21270;&#21518;&#24724;&#20540;&#12290;</title><link>http://arxiv.org/abs/2301.13393</link><description>&lt;p&gt;
&#21487;&#33021;&#20219;&#20309;&#26102;&#20505;&#23433;&#20840;&#30340;&#38543;&#26426;&#32452;&#21512;&#21322;&#33218;&#36172;&#21338;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Probably Anytime-Safe Stochastic Combinatorial Semi-Bandits. (arXiv:2301.13393v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13393
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21487;&#33021;&#20219;&#20309;&#26102;&#20505;&#23433;&#20840;&#30340;&#38543;&#26426;&#32452;&#21512;&#21322;&#33218;&#36172;&#21338;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20986;&#31639;&#27861;PASCombUCB&#22312;&#26102;&#38388;&#36724;&#19978;&#26368;&#23567;&#21270;&#21518;&#24724;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#35299;&#20915;&#22312;&#32447;&#20915;&#31574;&#20013;&#21487;&#33021;&#36896;&#25104;&#36807;&#24230;&#39118;&#38505;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#21487;&#33021;&#20219;&#20309;&#26102;&#20505;&#23433;&#20840;&#30340;&#38543;&#26426;&#32452;&#21512;&#21322;&#33218;&#36172;&#21338;&#38382;&#39064;&#12290;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#26234;&#33021;&#20307;&#26377;&#36873;&#25321;&#20174;$L$&#20010;&#22522;&#30784;&#39033;&#20013;&#19981;&#36229;&#36807;$K$&#20010;&#36827;&#34892;&#23376;&#38598;&#30340;&#36873;&#39033;&#12290;&#27599;&#20010;&#20803;&#32032;&#37117;&#19982;&#26576;&#20010;&#24179;&#22343;&#22870;&#21169;&#21644;&#34920;&#31034;&#20854;&#39118;&#38505;&#30340;&#26041;&#24046;&#30456;&#20851;&#32852;&#12290;&#20026;&#20102;&#20943;&#23569;&#20195;&#29702;&#20154;&#25152;&#36973;&#21463;&#30340;&#39118;&#38505;&#65292;&#25105;&#20204;&#35201;&#27714;&#65292;&#22312;&#25972;&#20010;&#26102;&#38388;$T$&#30340;&#26102;&#38388;&#36328;&#24230;&#19978;&#65292;&#26234;&#33021;&#20307;&#25152;&#20570;&#30340;&#27599;&#20010;&#36873;&#25321;&#37117;&#24212;&#21253;&#21547;&#20854;&#26041;&#24046;&#20043;&#21644;&#19981;&#36229;&#36807;&#26576;&#20010;&#26041;&#24046;&#39044;&#31639;&#30340;&#20803;&#32032;&#65292;&#19988;&#20854;&#21487;&#33021;&#20219;&#20309;&#26102;&#20505;&#28385;&#36275;&#27492;&#32422;&#26463;&#12290;&#22312;&#27492;&#32422;&#26463;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#35774;&#35745;&#21644;&#20998;&#26512;&#20102;&#19968;&#31181;&#31639;&#27861;PASCombUCB&#65292;&#20197;&#22312;&#26102;&#38388;&#36724;&#19978;&#26368;&#23567;&#21270;&#21518;&#24724;&#20540;&#12290;&#36890;&#36807;&#24320;&#21457;&#37197;&#22871;&#20449;&#24687;&#29702;&#35770;&#19979;&#30028;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#38382;&#39064;&#30456;&#20851;&#21644;&#38382;&#39064;&#26080;&#20851;&#30340;&#20004;&#31181;&#33539;&#20363;&#19979;&#65292;&#31639;&#27861;&#37117;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by concerns about making online decisions that incur undue amount of risk at each time step, in this paper, we formulate the probably anytime-safe stochastic combinatorial semi-bandits problem. In this problem, the agent is given the option to select a subset of size at most $K$ from a set of $L$ ground items. Each item is associated to a certain mean reward as well as a variance that represents its risk. To mitigate the risk that the agent incurs, we require that with probability at least $1-\delta$, over the entire horizon of time $T$, each of the choices that the agent makes should contain items whose sum of variances does not exceed a certain variance budget. We call this probably anytime-safe constraint. Under this constraint, we design and analyze an algorithm {\sc PASCombUCB} that minimizes the regret over the horizon of time $T$. By developing accompanying information-theoretic lower bounds, we show that under both the problem-dependent and problem-independent paradig
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BHMC&#30340;&#26032;&#30340;&#33945;&#29305;&#21345;&#32599;&#37319;&#26679;&#31639;&#27861;&#65292;&#33021;&#22815;&#20174;&#23450;&#20041;&#20102;&#32422;&#26463;&#30340;&#40654;&#26364;&#27969;&#24418;&#20013;&#36827;&#34892;&#26080;&#20559;&#37319;&#26679;&#65292;&#20854;&#20013;&#21253;&#21547;&#19968;&#31181;&#26032;&#30340;&#36807;&#28388;&#27493;&#39588;involution checking step&#12290;</title><link>http://arxiv.org/abs/2210.11925</link><description>&lt;p&gt;
&#33258;&#20849;&#36717;&#38556;&#30861;&#21704;&#23494;&#23572;&#39039;&#33945;&#29305;&#21345;&#27931;&#30340;&#26080;&#20559;&#32422;&#26463;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Unbiased constrained sampling with Self-Concordant Barrier Hamiltonian Monte Carlo. (arXiv:2210.11925v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.11925
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BHMC&#30340;&#26032;&#30340;&#33945;&#29305;&#21345;&#32599;&#37319;&#26679;&#31639;&#27861;&#65292;&#33021;&#22815;&#20174;&#23450;&#20041;&#20102;&#32422;&#26463;&#30340;&#40654;&#26364;&#27969;&#24418;&#20013;&#36827;&#34892;&#26080;&#20559;&#37319;&#26679;&#65292;&#20854;&#20013;&#21253;&#21547;&#19968;&#31181;&#26032;&#30340;&#36807;&#28388;&#27493;&#39588;involution checking step&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38556;&#30861;&#21704;&#23494;&#23572;&#39039;&#33945;&#29305;&#21345;&#32599;(BHMC)&#65292;&#23427;&#26159;HMC&#31639;&#27861;&#30340;&#19968;&#31181;&#21464;&#20307;&#65292;&#26088;&#22312;&#20174;&#24102;&#26377;&#33258;&#20849;&#36717;&#38556;&#30861;&#24230;&#37327;&#30340;&#27969;&#24418;&#20013;&#30340;Gibbs&#20998;&#24067;&#960;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#35813;&#26041;&#27861;&#20381;&#36182;&#20110;&#21253;&#21547;&#24230;&#37327;&#30340;Hamiltonian&#21160;&#21147;&#23398;&#12290;&#22240;&#27492;&#65292;&#23427;&#21253;&#21547;&#23450;&#20041;&#27969;&#24418;&#30340;&#32422;&#26463;&#65292;&#24182;&#33021;&#22815;&#21033;&#29992;&#20854;&#24213;&#23618;&#20960;&#20309;&#24418;&#29366;&#12290;&#28982;&#32780;&#65292;&#30456;&#24212;&#30340;Hamilton&#21160;&#21147;&#23398;&#26159;&#36890;&#36807;&#19981;&#21487;&#20998;&#31163;&#30340;&#24120;&#24494;&#20998;&#26041;&#31243;&#26469;&#23450;&#20041;&#30340;&#65292;&#19982;&#27431;&#20960;&#37324;&#24471;&#24773;&#20917;&#30456;&#21453;&#12290;&#36825;&#24847;&#21619;&#30528;&#23558;HMC&#25512;&#24191;&#21040;&#40654;&#26364;&#27969;&#24418;&#20013;&#20250;&#20135;&#29983;&#19981;&#21487;&#36991;&#20813;&#30340;&#20559;&#24046;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36807;&#28388;&#27493;&#39588;&#65292;&#31216;&#20026;&#8220;involution&#26816;&#26597;&#27493;&#39588;&#8221;&#12290;&#35813;&#27493;&#39588;&#22312;&#20004;&#20010;BHMC&#29256;&#26412;&#8212;&#8212;&#36830;&#32493;BHMC(c-BHMC)&#21644;&#25968;&#20540;BHMC(n-BHMC)&#20013;&#23454;&#29616;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20004;&#20010;&#26032;&#31639;&#27861;&#29983;&#25104;&#21487;&#36870;Markov&#38142;&#19988;&#26080;&#20559;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose Barrier Hamiltonian Monte Carlo (BHMC), a version of the HMC algorithm which aims at sampling from a Gibbs distribution $\pi$ on a manifold $\mathrm{M}$, endowed with a Hessian metric $\mathfrak{g}$ derived from a self-concordant barrier. Our method relies on Hamiltonian dynamics which comprises $\mathfrak{g}$. Therefore, it incorporates the constraints defining $\mathrm{M}$ and is able to exploit its underlying geometry. However, the corresponding Hamiltonian dynamics is defined via non separable Ordinary Differential Equations (ODEs) in contrast to the Euclidean case. It implies unavoidable bias in existing generalization of HMC to Riemannian manifolds. In this paper, we propose a new filter step, called "involution checking step", to address this problem. This step is implemented in two versions of BHMC, coined continuous BHMC (c-BHMC) and numerical BHMC (n-BHMC) respectively. Our main results establish that these two new algorithms generate reversible Mark
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#24102;&#23574;&#23792;&#30340;PCA&#38382;&#39064;&#65292;&#21033;&#29992;&#27491;&#20132;&#22810;&#39033;&#24335;&#30697;&#38453;&#25277;&#21462;&#22122;&#22768;&#27169;&#22411;&#25552;&#20986;&#20102;&#35813;&#27169;&#22411;&#20013;&#25512;&#26029;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#26497;&#38480;&#30340;&#34920;&#24449;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;AMP&#31639;&#27861;&#20197;&#23454;&#29616;&#20449;&#24687;&#35770;&#26497;&#38480;&#12290;</title><link>http://arxiv.org/abs/2210.01237</link><description>&lt;p&gt;
&#32467;&#26500;&#21270;PCA&#20013;&#30340;&#36125;&#21494;&#26031;&#26497;&#38480;&#21450;&#20854;&#23454;&#29616;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Bayes-optimal limits in structured PCA, and how to reach them. (arXiv:2210.01237v2 [cs.IT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.01237
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#24102;&#23574;&#23792;&#30340;PCA&#38382;&#39064;&#65292;&#21033;&#29992;&#27491;&#20132;&#22810;&#39033;&#24335;&#30697;&#38453;&#25277;&#21462;&#22122;&#22768;&#27169;&#22411;&#25552;&#20986;&#20102;&#35813;&#27169;&#22411;&#20013;&#25512;&#26029;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#26497;&#38480;&#30340;&#34920;&#24449;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;AMP&#31639;&#27861;&#20197;&#23454;&#29616;&#20449;&#24687;&#35770;&#26497;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27979;&#37327;&#22122;&#22768;&#20013;&#30340;&#32479;&#35745;&#30456;&#20851;&#24615;&#22914;&#20309;&#24433;&#21709;&#39640;&#32500;&#25512;&#26029;&#65311;&#20026;&#20102;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#33539;&#20363;&#24615;&#30340;&#24102;&#23574;&#23792;&#30697;&#38453;&#27169;&#22411;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#38382;&#39064;&#65292;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#19968;&#20010;&#31209;&#20026;&#19968;&#30340;&#30697;&#38453;&#34987;&#21152;&#24615;&#22122;&#22768;&#27745;&#26579;&#65292;&#20174;&#32780;&#36229;&#36234;&#20102;&#22122;&#22768;&#39033;&#29420;&#31435;&#30340;&#20551;&#35774;&#12290;&#25105;&#20204;&#20174;&#20302;&#38454;&#22810;&#39033;&#24335;&#27491;&#20132;&#30697;&#38453;&#38598;&#21512;&#20013;&#25277;&#21462;&#22122;&#22768;&#65292;&#20135;&#29983;&#30340;&#22122;&#22768;&#30456;&#20851;&#24615;&#20351;&#24471;&#35813;&#35774;&#32622;&#23545;&#24212;&#29992;&#39046;&#22495;&#20855;&#26377;&#30456;&#20851;&#24615;&#20294;&#22312;&#29702;&#35770;&#19978;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#39318;&#27425;&#25552;&#20379;&#20102;&#35813;&#27169;&#22411;&#20013;&#25512;&#26029;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#26497;&#38480;&#30340;&#34920;&#24449;&#12290;&#22914;&#26524;&#23574;&#23792;&#22312;&#26059;&#36716;&#19979;&#26159;&#19981;&#21464;&#30340;&#65292;&#21017;&#26631;&#20934;&#35889;PCA&#26159;&#26368;&#20248;&#30340;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#26356;&#19968;&#33324;&#30340;&#20808;&#39564;&#65292;&#26080;&#35770;&#26159;PCA&#36824;&#26159;&#29616;&#26377;&#30340;&#36817;&#20284;&#20449;&#24687;&#20256;&#36882;&#31639;&#27861;&#65288;AMP&#65289;&#37117;&#26080;&#27861;&#36798;&#21040;&#20449;&#24687;&#35770;&#26497;&#38480;&#65292;&#25105;&#20204;&#20351;&#29992;&#32479;&#35745;&#21147;&#23398;&#20013;&#30340;&#37325;&#22797;&#26041;&#27861;&#35745;&#31639;&#20102;&#36825;&#19968;&#26497;&#38480;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;AMP&#31639;&#27861;&#65292;&#28789;&#24863;&#26469;&#33258;&#33258;&#36866;&#24212;Thouless-Anderson-Palmer&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
How do statistical dependencies in measurement noise influence high-dimensional inference? To answer this, we study the paradigmatic spiked matrix model of principal components analysis (PCA), where a rank-one matrix is corrupted by additive noise. We go beyond the usual independence assumption on the noise entries, by drawing the noise from a low-order polynomial orthogonal matrix ensemble. The resulting noise correlations make the setting relevant for applications but analytically challenging. We provide the first characterization of the Bayes-optimal limits of inference in this model. If the spike is rotation-invariant, we show that standard spectral PCA is optimal. However, for more general priors, both PCA and the existing approximate message passing algorithm (AMP) fall short of achieving the information-theoretic limits, which we compute using the replica method from statistical mechanics. We thus propose a novel AMP, inspired by the theory of Adaptive Thouless-Anderson-Palmer e
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#35299;&#37322;&#24615;&#26631;&#27880;&#21161;&#25163;&#24037;&#20855;XLabel&#65292;&#36890;&#36807;&#21487;&#35299;&#37322;&#24615;&#25552;&#21319;&#26426;&#65288;EBM&#65289;&#21644;&#21487;&#35270;&#21270;&#23637;&#29616;&#65292;&#24110;&#21161;&#21307;&#30103;&#19987;&#23478;&#26631;&#35760;&#38750;&#20256;&#26579;&#24615;&#30142;&#30149;&#65288;NCDs&#65289;&#30340;&#30005;&#23376;&#30149;&#21382;&#65292;&#19982;&#20854;&#20182;&#30693;&#21517;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30456;&#27604;&#65292;EBM&#30340;&#20934;&#30830;&#24615;&#26356;&#20339;&#12290;</title><link>http://arxiv.org/abs/2209.12778</link><description>&lt;p&gt;
&#24320;&#21457;&#19968;&#31181;&#35299;&#37322;&#24615;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#25903;&#25345;&#30340;&#30005;&#23376;&#30149;&#21382;&#26631;&#27880;&#21487;&#35270;&#21270;&#20132;&#20114;&#24037;&#20855;
&lt;/p&gt;
&lt;p&gt;
Developing A Visual-Interactive Interface for Electronic Health Record Labeling: An Explainable Machine Learning Approach. (arXiv:2209.12778v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.12778
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#35299;&#37322;&#24615;&#26631;&#27880;&#21161;&#25163;&#24037;&#20855;XLabel&#65292;&#36890;&#36807;&#21487;&#35299;&#37322;&#24615;&#25552;&#21319;&#26426;&#65288;EBM&#65289;&#21644;&#21487;&#35270;&#21270;&#23637;&#29616;&#65292;&#24110;&#21161;&#21307;&#30103;&#19987;&#23478;&#26631;&#35760;&#38750;&#20256;&#26579;&#24615;&#30142;&#30149;&#65288;NCDs&#65289;&#30340;&#30005;&#23376;&#30149;&#21382;&#65292;&#19982;&#20854;&#20182;&#30693;&#21517;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30456;&#27604;&#65292;EBM&#30340;&#20934;&#30830;&#24615;&#26356;&#20339;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#27880;&#22823;&#37327;&#30005;&#23376;&#30149;&#21382;&#30340;&#24037;&#20316;&#37327;&#22823;&#19988;&#36153;&#26102;&#65292;&#25317;&#26377;&#19968;&#20010;&#26631;&#27880;&#21161;&#25163;&#24037;&#20855;&#21487;&#20197;&#26174;&#33879;&#20943;&#36731;&#21307;&#30103;&#19987;&#23478;&#30340;&#24037;&#20316;&#37327;&#65292;&#20294;&#20026;&#20102;&#36194;&#24471;&#19987;&#23478;&#30340;&#20449;&#20219;&#65292;&#35813;&#24037;&#20855;&#24517;&#39035;&#33021;&#22815;&#35299;&#37322;&#20854;&#32467;&#26524;&#32972;&#21518;&#30340;&#21407;&#22240;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#35299;&#37322;&#24615;&#26631;&#27880;&#21161;&#25163;&#24037;&#20855;XLabel&#65292;&#35813;&#24037;&#20855;&#21033;&#29992;&#21487;&#35299;&#37322;&#24615;&#25552;&#21319;&#26426;&#65288;EBM&#65289;&#23545;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#26631;&#31614;&#36827;&#34892;&#20998;&#31867;&#65292;&#24182;&#21487;&#35270;&#21270;EBM&#35299;&#37322;&#30340;&#28909;&#22270;&#12290;&#25105;&#20204;&#20351;&#29992;XLabel&#20316;&#20026;&#26696;&#20363;&#30740;&#31350;&#65292;&#24110;&#21161;&#21307;&#30103;&#19987;&#23478;&#26631;&#35760;&#20102;&#22235;&#31181;&#24120;&#35265;&#30340;&#38750;&#20256;&#26579;&#24615;&#30142;&#30149;(NCDs)&#30340;&#30005;&#23376;&#30149;&#21382;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65306;1&#65289;XLabel&#26377;&#21161;&#20110;&#20943;&#23569;&#26631;&#27880;&#25805;&#20316;&#30340;&#27425;&#25968;&#65307;2&#65289;&#20316;&#20026;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#20998;&#31867;&#22120;&#65292;EBM&#30340;&#20934;&#30830;&#24615;&#19982;&#20854;&#20182;&#30693;&#21517;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30456;&#24403;&#65292;&#20248;&#20110;NCD&#19987;&#23478;&#20351;&#29992;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#27169;&#22411;&#65307;3&#65289;&#21363;&#20351;&#36229;&#36807;40%&#30340;&#35760;&#24405;&#34987;&#26377;&#24847;&#35823;&#26631;&#65292;EBM&#20173;&#33021;&#20445;&#25345;&#36739;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Labeling a large number of electronic health records is expensive and time consuming, and having a labeling assistant tool can significantly reduce medical experts' workload. Nevertheless, to gain the experts' trust, the tool must be able to explain the reasons behind its outputs. Motivated by this, we introduce Explainable Labeling Assistant (XLabel) a new visual-interactive tool for data labeling. At a high level, XLabel uses Explainable Boosting Machine (EBM) to classify the labels of each data point and visualizes heatmaps of EBM's explanations. As a case study, we use XLabel to help medical experts label electronic health records with four common non-communicable diseases (NCDs). Our experiments show that 1) XLabel helps reduce the number of labeling actions, 2) EBM as an explainable classifier is as accurate as other well-known machine learning models outperforms a rule-based model used by NCD experts, and 3) even when more than 40% of the records were intentionally mislabeled, E
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#38598;&#21512;&#32534;&#30721;&#26041;&#27861;UMBC&#65292;&#21487;&#20197;&#19982;&#20219;&#24847;&#38750;MBC&#32452;&#20214;&#30456;&#32467;&#21512;&#65292;&#21516;&#26102;&#20173;&#28385;&#36275;MBC&#65307;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;MBC&#35757;&#32451;&#31639;&#27861;&#65292;&#21487;&#20197;&#20026;&#20219;&#20309;&#38598;&#21512;&#22823;&#23567;&#22312;&#35757;&#32451;&#21644;&#27979;&#35797;&#26102;&#37117;&#20855;&#26377;&#24658;&#23450;&#30340;&#20869;&#23384;&#24320;&#38144;&#65292;&#32473;&#20986;&#23436;&#25972;&#38598;&#21512;&#26799;&#24230;&#30340;&#26080;&#20559;&#36817;&#20284;&#12290;</title><link>http://arxiv.org/abs/2208.12401</link><description>&lt;p&gt;
&#20855;&#26377;&#36890;&#29992;&#36855;&#20320;&#25209;&#37327;&#19968;&#33268;&#24615;&#21644;&#26080;&#20559;&#23436;&#20840;&#38598;&#21512;&#26799;&#24230;&#36817;&#20284;&#30340;&#21487;&#25193;&#23637;&#38598;&#21512;&#32534;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
Scalable Set Encoding with Universal Mini-Batch Consistency and Unbiased Full Set Gradient Approximation. (arXiv:2208.12401v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.12401
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#38598;&#21512;&#32534;&#30721;&#26041;&#27861;UMBC&#65292;&#21487;&#20197;&#19982;&#20219;&#24847;&#38750;MBC&#32452;&#20214;&#30456;&#32467;&#21512;&#65292;&#21516;&#26102;&#20173;&#28385;&#36275;MBC&#65307;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;MBC&#35757;&#32451;&#31639;&#27861;&#65292;&#21487;&#20197;&#20026;&#20219;&#20309;&#38598;&#21512;&#22823;&#23567;&#22312;&#35757;&#32451;&#21644;&#27979;&#35797;&#26102;&#37117;&#20855;&#26377;&#24658;&#23450;&#30340;&#20869;&#23384;&#24320;&#38144;&#65292;&#32473;&#20986;&#23436;&#25972;&#38598;&#21512;&#26799;&#24230;&#30340;&#26080;&#20559;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#65292;&#20851;&#20110;&#38598;&#21512;&#20989;&#25968;&#30340;&#23567;&#25209;&#37327;&#19968;&#33268;&#24615;(MBC)&#30340;&#30740;&#31350;&#24341;&#36215;&#20102;&#20154;&#20204;&#23545;&#20110;&#20445;&#35777;&#23558;&#19968;&#20010;&#20998;&#21106;&#30340;&#38598;&#21512;&#30340;&#37096;&#20998;&#39034;&#24207;&#22788;&#29702;&#21644;&#32858;&#21512;&#65292;&#32780;&#20445;&#35777;&#25152;&#26377;&#20998;&#21106;&#30340;&#36755;&#20986;&#30456;&#21516;&#30340;&#38656;&#27714;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;MBC&#26550;&#26500;&#30340;&#38480;&#21046;&#23548;&#33268;&#20102;&#20855;&#26377;&#26377;&#38480;&#34920;&#36798;&#33021;&#21147;&#30340;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#27809;&#26377;&#35299;&#20915;&#22312;&#38656;&#35201;&#23436;&#25972;&#38598;&#21512;&#26799;&#24230;&#30340;&#24773;&#20917;&#19979;&#22914;&#20309;&#22788;&#29702;&#35757;&#32451;&#20013;&#30340;&#22823;&#22411;&#38598;&#21512;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#29992;&#20110;&#20219;&#24847;&#38750;-MBC&#32452;&#20214;&#30456;&#32467;&#21512;&#30340;&#36890;&#29992;MBC (UMBC) &#31867;&#38598;&#21512;&#20989;&#25968;&#65292;&#21516;&#26102;&#20173;&#28385;&#36275;MBC&#65292;&#20351;&#24471;MBC&#35774;&#32622;&#20013;&#21487;&#20197;&#20351;&#29992;&#26356;&#24191;&#27867;&#30340;&#21151;&#33021;&#31867;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;MBC&#35757;&#32451;&#31639;&#27861;&#65292;&#23427;&#33021;&#22815;&#20026;&#20219;&#20309;&#38598;&#21512;&#22823;&#23567;&#22312;&#35757;&#32451;&#21644;&#27979;&#35797;&#26102;&#37117;&#20855;&#26377;&#24658;&#23450;&#30340;&#20869;&#23384;&#24320;&#38144;&#65292;&#32473;&#20986;&#23436;&#25972;&#38598;&#21512;&#26799;&#24230;&#30340;&#26080;&#20559;&#36817;&#20284;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#39564;&#65292;&#21253;&#25324;&#22270;&#20687;&#23436;&#25104;&#12289;&#25991;&#26412;&#20998;&#31867;&#12289;&#26080;&#30417;&#30563;&#32858;&#31867;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work on mini-batch consistency (MBC) for set functions has brought attention to the need for sequentially processing and aggregating chunks of a partitioned set while guaranteeing the same output for all partitions. However, existing constraints on MBC architectures lead to models with limited expressive power. Additionally, prior work has not addressed how to deal with large sets during training when the full set gradient is required. To address these issues, we propose a Universally MBC (UMBC) class of set functions which can be used in conjunction with arbitrary non-MBC components while still satisfying MBC, enabling a wider range of function classes to be used in MBC settings. Furthermore, we propose an efficient MBC training algorithm which gives an unbiased approximation of the full set gradient and has a constant memory overhead for any set size for both train- and test-time. We conduct extensive experiments including image completion, text classification, unsupervised cl
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39640;&#25928;&#30340;&#24102;&#26377;&#22806;&#37096;&#36755;&#20837;&#30340;MDPs&#31639;&#27861;&#65292;&#21517;&#20026;&#36861;&#28335;&#23398;&#20064;&#65288;HL&#65289;&#12290;HL&#31639;&#27861;&#36890;&#36807;&#21033;&#29992;&#22806;&#37096;&#21464;&#37327;&#26679;&#26412;&#20351;&#24471;&#36807;&#21435;&#30340;&#20915;&#31574;&#22312;&#22238;&#28335;&#20013;&#21487;&#20197;&#21152;&#36895;&#31574;&#30053;&#25913;&#36827;&#65292;&#22312;&#36164;&#28304;&#31649;&#29702;&#38382;&#39064;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2207.06272</link><description>&lt;p&gt;
&#24102;&#22806;&#37096;&#36755;&#20837;&#30340;MDPs&#30340;&#36861;&#28335;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Hindsight Learning for MDPs with Exogenous Inputs. (arXiv:2207.06272v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.06272
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39640;&#25928;&#30340;&#24102;&#26377;&#22806;&#37096;&#36755;&#20837;&#30340;MDPs&#31639;&#27861;&#65292;&#21517;&#20026;&#36861;&#28335;&#23398;&#20064;&#65288;HL&#65289;&#12290;HL&#31639;&#27861;&#36890;&#36807;&#21033;&#29992;&#22806;&#37096;&#21464;&#37327;&#26679;&#26412;&#20351;&#24471;&#36807;&#21435;&#30340;&#20915;&#31574;&#22312;&#22238;&#28335;&#20013;&#21487;&#20197;&#21152;&#36895;&#31574;&#30053;&#25913;&#36827;&#65292;&#22312;&#36164;&#28304;&#31649;&#29702;&#38382;&#39064;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#36164;&#28304;&#31649;&#29702;&#38382;&#39064;&#38656;&#35201;&#22312;&#19981;&#30830;&#23450;&#24615;&#19979;&#20570;&#20986;&#36845;&#20195;&#20915;&#31574;&#65292;&#20854;&#20013;&#24433;&#21709;&#20915;&#31574;&#32467;&#26524;&#30340;&#21807;&#19968;&#19981;&#30830;&#23450;&#24615;&#26159;&#20915;&#31574;&#32773;&#25511;&#21046;&#20043;&#22806;&#30340;&#22806;&#37096;&#21464;&#37327;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#38382;&#39064;&#24314;&#27169;&#20026;&#24102;&#26377;&#22806;&#37096;&#36755;&#20837;&#30340;MDPs&#65288;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65289;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31867;&#21517;&#20026;&#36861;&#28335;&#23398;&#20064;&#65288;HL&#65289;&#30340;&#25968;&#25454;&#39640;&#25928;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;HL&#31639;&#27861;&#36890;&#36807;&#21033;&#29992;&#19968;&#20010;&#20851;&#38190;&#27934;&#35265;&#23454;&#29616;&#20102;&#25968;&#25454;&#25928;&#29575;&#65306;&#36890;&#36807;&#22806;&#37096;&#21464;&#37327;&#30340;&#26679;&#26412;&#65292;&#36807;&#21435;&#30340;&#20915;&#31574;&#21487;&#20197;&#22312;&#22238;&#28335;&#20013;&#37325;&#26032;&#23457;&#35270;&#65292;&#20197;&#25512;&#26029;&#20986;&#21487;&#20197;&#21152;&#36895;&#31574;&#30053;&#25913;&#36827;&#30340;&#21453;&#20107;&#23454;&#21518;&#26524;&#12290;&#25105;&#20204;&#23558;HL&#19982;&#22810;&#20010;&#22522;&#32447;&#31639;&#27861;&#22312;&#22810;&#20010;&#27979;&#35797;&#26696;&#20363;&#20013;&#36827;&#34892;&#27604;&#36739;&#65292;&#21253;&#25324;&#22810;&#31192;&#20070;&#21644;&#33322;&#31354;&#20844;&#21496;&#25910;&#30410;&#31649;&#29702;&#38382;&#39064;&#12290;&#25105;&#20204;&#36824;&#23558;&#25105;&#20204;&#30340;&#31639;&#27861;&#25193;&#23637;&#21040;&#19994;&#21153;&#20851;&#38190;&#30340;&#20113;&#36164;&#28304;&#31649;&#29702;&#38382;&#39064;&#8212;&#8212;&#23558;&#34394;&#25311;&#26426;&#65288;VM&#65289;&#20998;&#37197;&#21040;&#29289;&#29702;&#26426;&#22120;&#19978;&#65292;&#24182;&#20351;&#29992;&#26469;&#33258;&#22823;&#22411;&#20844;&#20849;&#20113;&#25552;&#20379;&#21830;&#30340;&#30495;&#23454;&#25968;&#25454;&#38598;&#27169;&#25311;&#20854;&#24615;&#33021;&#12290;&#25105;&#20204;&#21457;&#29616;HL&#31639;&#27861;&#20248;&#20110;&#22522;&#20934;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many resource management problems require sequential decision-making under uncertainty, where the only uncertainty affecting the decision outcomes are exogenous variables outside the control of the decision-maker. We model these problems as Exo-MDPs (Markov Decision Processes with Exogenous Inputs) and design a class of data-efficient algorithms for them termed Hindsight Learning (HL). Our HL algorithms achieve data efficiency by leveraging a key insight: having samples of the exogenous variables, past decisions can be revisited in hindsight to infer counterfactual consequences that can accelerate policy improvements. We compare HL against classic baselines in the multi-secretary and airline revenue management problems. We also scale our algorithms to a business-critical cloud resource management problem -- allocating Virtual Machines (VMs) to physical machines, and simulate their performance with real datasets from a large public cloud provider. We find that HL algorithms outperform d
&lt;/p&gt;</description></item><item><title>D-Struct&#26159;&#19968;&#31181;&#21487;&#24494;&#21644;&#21487;&#20256;&#36755;&#30340;&#32467;&#26500;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#26032;&#39062;&#30340;&#26550;&#26500;&#21644;&#25439;&#22833;&#20989;&#25968;&#20351;&#24471;&#32467;&#26500;&#21487;&#20197;&#22312;&#21516;&#19968;&#39046;&#22495;&#30340;&#19981;&#21516;&#25968;&#25454;&#38598;&#20013;&#20256;&#36755;&#65292;&#27604;NOTEARS&#21644;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2206.06354</link><description>&lt;p&gt;
&#21487;&#24494;&#21644;&#21487;&#20256;&#36755;&#30340;&#32467;&#26500;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Differentiable and Transportable Structure Learning. (arXiv:2206.06354v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.06354
&lt;/p&gt;
&lt;p&gt;
D-Struct&#26159;&#19968;&#31181;&#21487;&#24494;&#21644;&#21487;&#20256;&#36755;&#30340;&#32467;&#26500;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#26032;&#39062;&#30340;&#26550;&#26500;&#21644;&#25439;&#22833;&#20989;&#25968;&#20351;&#24471;&#32467;&#26500;&#21487;&#20197;&#22312;&#21516;&#19968;&#39046;&#22495;&#30340;&#19981;&#21516;&#25968;&#25454;&#38598;&#20013;&#20256;&#36755;&#65292;&#27604;NOTEARS&#21644;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26377;&#21521;&#26080;&#29615;&#22270;&#22312;&#23427;&#20204;&#30340;&#32467;&#26500;&#20013;&#32534;&#30721;&#20102;&#20851;&#20110;&#29305;&#23450;&#20998;&#24067;&#30340;&#22823;&#37327;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#25512;&#26029;&#36825;&#20123;&#32467;&#26500;&#25152;&#38656;&#30340;&#35745;&#31639;&#36890;&#24120;&#26159;&#21464;&#37327;&#25968;&#30340;&#36229;&#25351;&#25968;&#65292;&#22240;&#20026;&#25512;&#26029;&#38656;&#35201;&#25195;&#25551;&#19968;&#20010;&#32452;&#21512;&#25968;&#37327;&#24040;&#22823;&#30340;&#28508;&#22312;&#32467;&#26500;&#31354;&#38388;&#12290;&#30452;&#21040;&#26368;&#36817;&#30340;&#36827;&#23637;&#25165;&#20351;&#24471;&#20351;&#29992;&#21487;&#24494;&#24230;&#37327;&#25628;&#32034;&#36825;&#20010;&#31354;&#38388;&#25104;&#20026;&#21487;&#33021;&#65292;&#20174;&#32780;&#26497;&#22823;&#22320;&#20943;&#23569;&#20102;&#25628;&#32034;&#26102;&#38388;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;D-Struct&#65292;&#23427;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#26550;&#26500;&#21644;&#25439;&#22833;&#20989;&#25968;&#24674;&#22797;&#20102;&#21457;&#29616;&#32467;&#26500;&#22312;&#21516;&#19968;&#39046;&#22495;&#20013;&#30340;&#20256;&#36755;&#24615;&#65292;&#21516;&#26102;&#20173;&#28982;&#23436;&#20840;&#21487;&#24494;&#12290;&#22240;&#20026;D-Struct&#20173;&#28982;&#26159;&#21487;&#24494;&#30340;&#65292;&#25152;&#20197;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#36731;&#26494;&#22320;&#24212;&#29992;&#20110;&#29616;&#26377;&#30340;&#21487;&#24494;&#26694;&#26550;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Directed acyclic graphs (DAGs) encode a lot of information about a particular distribution in their structure. However, compute required to infer these structures is typically super-exponential in the number of variables, as inference requires a sweep of a combinatorially large space of potential structures. That is, until recent advances made it possible to search this space using a differentiable metric, drastically reducing search time. While this technique -- named NOTEARS -- is widely considered a seminal work in DAG-discovery, it concedes an important property in favour of differentiability: transportability. To be transportable, the structures discovered on one dataset must apply to another dataset from the same domain. We introduce D-Struct which recovers transportability in the discovered structures through a novel architecture and loss function while remaining fully differentiable. Because D-Struct remains differentiable, our method can be easily adopted in existing different
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#26102;&#21464;&#22270;&#19978;&#30340;&#20998;&#25955;&#22312;&#32447;&#27491;&#21017;&#21270;&#32447;&#24615;&#22238;&#24402;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#38750;&#36127;&#36229;-&#38789;&#19981;&#31561;&#24335;&#30340;&#20272;&#35745;&#35823;&#24046;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#22312;&#28385;&#36275;&#26679;&#26412;&#36335;&#24452;&#26102;&#31354;&#20852;&#22859;&#26465;&#20214;&#26102;&#65292;&#33410;&#28857;&#30340;&#20272;&#35745;&#21487;&#20197;&#25910;&#25947;&#20110;&#26410;&#30693;&#30340;&#30495;&#23454;&#21442;&#25968;&#21521;&#37327;&#12290;</title><link>http://arxiv.org/abs/2206.03861</link><description>&lt;p&gt;
&#38543;&#26426;&#26102;&#21464;&#22270;&#19978;&#30340;&#20998;&#25955;&#22312;&#32447;&#27491;&#21017;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Decentralized Online Regularized Learning Over Random Time-Varying Graphs. (arXiv:2206.03861v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.03861
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#26102;&#21464;&#22270;&#19978;&#30340;&#20998;&#25955;&#22312;&#32447;&#27491;&#21017;&#21270;&#32447;&#24615;&#22238;&#24402;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#38750;&#36127;&#36229;-&#38789;&#19981;&#31561;&#24335;&#30340;&#20272;&#35745;&#35823;&#24046;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#22312;&#28385;&#36275;&#26679;&#26412;&#36335;&#24452;&#26102;&#31354;&#20852;&#22859;&#26465;&#20214;&#26102;&#65292;&#33410;&#28857;&#30340;&#20272;&#35745;&#21487;&#20197;&#25910;&#25947;&#20110;&#26410;&#30693;&#30340;&#30495;&#23454;&#21442;&#25968;&#21521;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38543;&#26426;&#26102;&#21464;&#22270;&#19978;&#30340;&#20998;&#25955;&#22312;&#32447;&#27491;&#21017;&#21270;&#32447;&#24615;&#22238;&#24402;&#31639;&#27861;&#12290;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#20013;&#65292;&#27599;&#20010;&#33410;&#28857;&#37117;&#36816;&#34892;&#19968;&#20010;&#22312;&#32447;&#20272;&#35745;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21253;&#25324;&#21019;&#26032;&#39033;&#65288;&#22788;&#29702;&#33258;&#36523;&#26032;&#27979;&#37327;&#20540;&#65289;&#12289;&#20849;&#35782;&#39033;&#65288;&#21152;&#26435;&#24179;&#22343;&#33258;&#36523;&#21450;&#20854;&#37051;&#23621;&#30340;&#20272;&#35745;&#65292;&#24102;&#26377;&#21152;&#24615;&#21644;&#20056;&#24615;&#36890;&#20449;&#22122;&#22768;&#65289;&#21644;&#27491;&#21017;&#21270;&#39033;&#65288;&#38450;&#27490;&#36807;&#24230;&#25311;&#21512;&#65289;&#12290;&#19981;&#35201;&#27714;&#22238;&#24402;&#30697;&#38453;&#21644;&#22270;&#28385;&#36275;&#29305;&#27530;&#30340;&#32479;&#35745;&#20551;&#35774;&#65292;&#22914;&#30456;&#20114;&#29420;&#31435;&#12289;&#26102;&#31354;&#29420;&#31435;&#25110;&#24179;&#31283;&#24615;&#12290;&#25105;&#20204;&#21457;&#23637;&#20102;&#38750;&#36127;&#36229;-&#38789;&#19981;&#31561;&#24335;&#30340;&#20272;&#35745;&#35823;&#24046;&#65292;&#24182;&#35777;&#26126;&#20102;&#22914;&#26524;&#31639;&#27861;&#22686;&#30410;&#12289;&#22270;&#21644;&#22238;&#24402;&#30697;&#38453;&#20849;&#21516;&#28385;&#36275;&#26679;&#26412;&#36335;&#24452;&#26102;&#31354;&#20852;&#22859;&#26465;&#20214;&#65292;&#33410;&#28857;&#30340;&#20272;&#35745;&#20960;&#20046;&#21487;&#20197;&#32943;&#23450;&#22320;&#25910;&#25947;&#20110;&#26410;&#30693;&#30340;&#30495;&#23454;&#21442;&#25968;&#21521;&#37327;&#12290;&#29305;&#21035;&#22320;&#65292;&#36890;&#36807;&#36873;&#25321;&#36866;&#24403;&#30340;&#31639;&#27861;&#22686;&#30410;&#65292;&#35813;&#26465;&#20214;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the decentralized online regularized linear regression algorithm over random time-varying graphs. At each time step, every node runs an online estimation algorithm consisting of an innovation term processing its own new measurement, a consensus term taking a weighted sum of estimations of its own and its neighbors with additive and multiplicative communication noises and a regularization term preventing over-fitting. It is not required that the regression matrices and graphs satisfy special statistical assumptions such as mutual independence, spatio-temporal independence or stationarity. We develop the nonnegative supermartingale inequality of the estimation error, and prove that the estimations of all nodes converge to the unknown true parameter vector almost surely if the algorithm gains, graphs and regression matrices jointly satisfy the sample path spatio-temporal persistence of excitation condition. Especially, this condition holds by choosing appropriate algorithm gains 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#24555;&#36895;&#38750;&#32447;&#24615;&#21521;&#37327;&#20998;&#20301;&#25968;&#22238;&#24402;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20445;&#30041;&#20102;&#21521;&#37327;&#20998;&#20301;&#25968;&#22238;&#24402;&#30340;&#20248;&#38597;&#30340;&#22522;&#20110;&#20960;&#20309;&#30340;&#20844;&#24335;&#65292;&#21516;&#26102;&#37319;&#29992;&#20102;&#20960;&#31181;&#21019;&#26032;&#30340;&#31639;&#27861;&#24605;&#24819;&#20197;&#21450;&#26377;&#25928;&#30340;&#35757;&#32451;&#21644;&#25512;&#26029;&#27493;&#39588;&#65292;&#20855;&#26377;&#20248;&#36234;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2205.14977</link><description>&lt;p&gt;
&#24555;&#36895;&#38750;&#32447;&#24615;&#21521;&#37327;&#20998;&#20301;&#25968;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Fast Nonlinear Vector Quantile Regression. (arXiv:2205.14977v3 [stat.CO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.14977
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#24555;&#36895;&#38750;&#32447;&#24615;&#21521;&#37327;&#20998;&#20301;&#25968;&#22238;&#24402;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20445;&#30041;&#20102;&#21521;&#37327;&#20998;&#20301;&#25968;&#22238;&#24402;&#30340;&#20248;&#38597;&#30340;&#22522;&#20110;&#20960;&#20309;&#30340;&#20844;&#24335;&#65292;&#21516;&#26102;&#37319;&#29992;&#20102;&#20960;&#31181;&#21019;&#26032;&#30340;&#31639;&#27861;&#24605;&#24819;&#20197;&#21450;&#26377;&#25928;&#30340;&#35757;&#32451;&#21644;&#25512;&#26029;&#27493;&#39588;&#65292;&#20855;&#26377;&#20248;&#36234;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#20301;&#25968;&#22238;&#24402;&#26159;&#20272;&#35745;&#32473;&#23450;&#35299;&#37322;&#29305;&#24449;X&#30340;&#30446;&#26631;&#21464;&#37327;Y&#30340;&#19968;&#20010;&#25110;&#22810;&#20010;&#26465;&#20214;&#20998;&#20301;&#25968;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;QR&#30340;&#23616;&#38480;&#24615;&#22312;&#20110;&#65292;&#30001;&#20110;&#20854;&#30446;&#26631;&#20989;&#25968;&#30340;&#21046;&#23450;&#65292;&#20165;&#23545;&#26631;&#37327;&#30446;&#26631;&#21464;&#37327;&#36827;&#34892;&#23450;&#20041;&#65292;&#30001;&#20110;&#37327;&#23376;&#30340;&#27010;&#24565;&#22312;&#22810;&#20803;&#20998;&#24067;&#20013;&#27809;&#26377;&#26631;&#20934;&#23450;&#20041;&#12290;&#26368;&#36817;&#65292;&#21521;&#37327;&#20998;&#20301;&#25968;&#22238;&#24402;(VQR)&#34987;&#25552;&#20986;&#20316;&#20026;QR&#30340;&#19968;&#31181;&#25193;&#23637;&#65292;&#29992;&#20110;&#21521;&#37327;&#20540;&#30446;&#26631;&#21464;&#37327;&#65292;&#24471;&#30410;&#20110;&#36890;&#36807;&#26368;&#20248;&#20256;&#36755;&#23545;&#22810;&#20803;&#20998;&#24067;&#30340;&#20998;&#20301;&#25968;&#27010;&#24565;&#30340;&#26377;&#24847;&#20041;&#30340;&#27010;&#25324;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24555;&#36895;&#38750;&#32447;&#24615;&#21521;&#37327;&#20998;&#20301;&#25968;&#22238;&#24402;(Fast-NVQR)&#65292;&#19968;&#31181;&#22522;&#20110;&#37327;&#20301;&#20989;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#30340;&#26032;&#26041;&#27861;&#12290;Fast-NVQR&#20445;&#30041;&#20102;VQR&#30340;&#20248;&#38597;&#30340;&#22522;&#20110;&#20960;&#20309;&#30340;&#20844;&#24335;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#20960;&#31181;&#21019;&#26032;&#30340;&#31639;&#27861;&#24605;&#24819;&#65292;&#20197;&#26377;&#25928;&#22320;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#21644;&#25191;&#34892;&#25512;&#26029;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;Fast-NVQR&#19968;&#33268;&#24615;&#21644;&#25910;&#25947;&#36895;&#24230;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#29616;&#23454;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#20854;&#21487;&#20280;&#32553;&#24615;&#21644;&#20248;&#36234;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantile regression (QR) is a powerful tool for estimating one or more conditional quantiles of a target variable $\mathrm{Y}$ given explanatory features $\boldsymbol{\mathrm{X}}$. A limitation of QR is that it is only defined for scalar target variables, due to the formulation of its objective function, and since the notion of quantiles has no standard definition for multivariate distributions. Recently, vector quantile regression (VQR) was proposed as an extension of QR for vector-valued target variables, thanks to a meaningful generalization of the notion of quantiles to multivariate distributions via optimal transport. Despite its elegance, VQR is arguably not applicable in practice due to several limitations: (i) it assumes a linear model for the quantiles of the target $\boldsymbol{\mathrm{Y}}$ given the features $\boldsymbol{\mathrm{X}}$; (ii) its exact formulation is intractable even for modestly-sized problems in terms of target dimensions, number of regressed quantile levels,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20984;&#24615;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65292;&#21457;&#29616;&#26080;&#27861;&#20351;&#29992;&#38745;&#24577;&#22870;&#21169;&#20989;&#25968;&#34920;&#36798;&#30446;&#26631;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#20803;&#31639;&#27861;&#35299;&#20915;&#27492;&#38382;&#39064;&#65292;&#24182;&#32479;&#19968;&#20102;&#25991;&#29486;&#20013;&#30340;&#29616;&#26377;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2106.00661</link><description>&lt;p&gt;
&#22870;&#21169;&#36275;&#20197;&#22788;&#29702;&#20984;&#24615;MDP&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Reward is enough for convex MDPs. (arXiv:2106.00661v4 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.00661
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20984;&#24615;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65292;&#21457;&#29616;&#26080;&#27861;&#20351;&#29992;&#38745;&#24577;&#22870;&#21169;&#20989;&#25968;&#34920;&#36798;&#30446;&#26631;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#20803;&#31639;&#27861;&#35299;&#20915;&#27492;&#38382;&#39064;&#65292;&#24182;&#32479;&#19968;&#20102;&#25991;&#29486;&#20013;&#30340;&#29616;&#26377;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243; (MDP) &#20013;&#65292;&#26368;&#22823;&#21270;&#19968;&#20010;&#39532;&#23572;&#21487;&#22827;&#21644;&#24179;&#31283;&#30340;&#32047;&#31215;&#22870;&#21169;&#20989;&#25968;&#21487;&#20197;&#25429;&#25417;&#21040;&#35768;&#22810;&#30446;&#26631;&#12290;&#28982;&#32780;&#65292;&#24182;&#38750;&#25152;&#26377;&#30446;&#26631;&#37117;&#33021;&#20197;&#27492;&#26041;&#24335;&#25429;&#33719;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20984;&#24615;MDPs&#65292;&#20854;&#20013;&#30446;&#26631;&#26159;&#20316;&#20026;&#38745;&#24577;&#20998;&#24067;&#30340;&#20984;&#20989;&#25968;&#34920;&#36798;&#30340;&#65292;&#32467;&#26524;&#34920;&#26126;&#26080;&#27861;&#20351;&#29992;&#38745;&#24577;&#22870;&#21169;&#20989;&#25968;&#26469;&#34920;&#36798;&#30446;&#26631;&#12290;&#25105;&#20204;&#23558;&#20984;&#24615;MDP&#38382;&#39064;&#37325;&#26032;&#34920;&#36848;&#20026;&#25919;&#31574;&#21644;&#20195;&#20215;(&#36127;&#22870;&#21169;)&#8220;&#29609;&#23478;&#8221;&#30340;&#26368;&#23567;&#26368;&#22823;&#21338;&#24328;&#65292;&#21033;&#29992; Fenchel &#23545;&#20598;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#35299;&#20915;&#27492;&#38382;&#39064;&#30340;&#20803;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#32479;&#19968;&#20102;&#25991;&#29486;&#20013;&#35768;&#22810;&#29616;&#26377;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Maximising a cumulative reward function that is Markov and stationary, i.e., defined over state-action pairs and independent of time, is sufficient to capture many kinds of goals in a Markov decision process (MDP). However, not all goals can be captured in this manner. In this paper we study convex MDPs in which goals are expressed as convex functions of the stationary distribution and show that they cannot be formulated using stationary reward functions. Convex MDPs generalize the standard reinforcement learning (RL) problem formulation to a larger framework that includes many supervised and unsupervised RL problems, such as apprenticeship learning, constrained MDPs, and so-called `pure exploration'. Our approach is to reformulate the convex MDP problem as a min-max game involving policy and cost (negative reward) `players', using Fenchel duality. We propose a meta-algorithm for solving this problem and show that it unifies many existing algorithms in the literature.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#30340;QCBA&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#25913;&#36827;&#22522;&#20110;&#25968;&#20540;&#31867;&#22411;&#25968;&#25454;&#23398;&#20064;&#30340;&#35268;&#21017;&#20998;&#31867;&#22120;&#65292;&#24674;&#22797;&#39044;&#31163;&#25955;&#21270;&#36807;&#31243;&#20013;&#20002;&#22833;&#30340;&#20449;&#24687;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#21098;&#26525;&#25216;&#26415;&#12290;&#22312;22&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;FOIL2+QCBA&#30456;&#23545;&#20854;&#20182;&#22522;&#32447;&#26041;&#27861;&#32780;&#35328;&#65292;&#20855;&#26377;&#26356;&#39640;&#30340;&#39044;&#27979;&#24615;&#33021;&#21644;&#26356;&#23567;&#30340;&#27169;&#22411;&#22823;&#23567;&#12290;</title><link>http://arxiv.org/abs/1711.10166</link><description>&lt;p&gt;
QCBA: &#36890;&#36807;&#24674;&#22797;&#31163;&#25955;&#21270;&#36807;&#31243;&#20013;&#30340;&#20449;&#24687;&#25913;&#36827;&#22522;&#20110;&#25968;&#20540;&#25968;&#25454;&#23398;&#20064;&#30340;&#35268;&#21017;&#20998;&#31867;&#22120;
&lt;/p&gt;
&lt;p&gt;
QCBA: Improving Rule Classifiers Learned from Quantitative Data by Recovering Information Lost by Discretisation. (arXiv:1711.10166v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1711.10166
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#30340;QCBA&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#25913;&#36827;&#22522;&#20110;&#25968;&#20540;&#31867;&#22411;&#25968;&#25454;&#23398;&#20064;&#30340;&#35268;&#21017;&#20998;&#31867;&#22120;&#65292;&#24674;&#22797;&#39044;&#31163;&#25955;&#21270;&#36807;&#31243;&#20013;&#20002;&#22833;&#30340;&#20449;&#24687;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#21098;&#26525;&#25216;&#26415;&#12290;&#22312;22&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;FOIL2+QCBA&#30456;&#23545;&#20854;&#20182;&#22522;&#32447;&#26041;&#27861;&#32780;&#35328;&#65292;&#20855;&#26377;&#26356;&#39640;&#30340;&#39044;&#27979;&#24615;&#33021;&#21644;&#26356;&#23567;&#30340;&#27169;&#22411;&#22823;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#20540;&#23646;&#24615;&#30340;&#39044;&#31163;&#25955;&#21270;&#26159;&#26576;&#20123;&#35268;&#21017;&#23398;&#20064;&#31639;&#27861;&#30340;&#24517;&#35201;&#27493;&#39588;&#65292;&#20294;&#26159;&#20250;&#23548;&#33268;&#19968;&#20123;&#25928;&#29575;&#20302;&#19979;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#26032;&#30340;&#35268;&#21017;&#35843;&#25972;&#27493;&#39588;&#20197;&#24674;&#22797;&#31163;&#25955;&#21270;&#20013;&#20002;&#22833;&#30340;&#20449;&#24687;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#21098;&#26525;&#25216;&#26415;&#65292;&#21487;&#20197;&#36827;&#19968;&#27493;&#20943;&#23567;&#35268;&#21017;&#27169;&#22411;&#30340;&#22823;&#23567;&#21644;&#25552;&#39640;&#20854;&#20934;&#30830;&#24615;&#12290;&#25552;&#20986;&#30340;QCBA&#26041;&#27861;&#26368;&#21021;&#26159;&#20026;&#20102;&#23545;&#22522;&#20110;&#20851;&#32852;&#24615;&#20998;&#31867;&#65288;CBA&#65289;&#31639;&#27861;&#29983;&#25104;&#30340;&#27169;&#22411;&#20013;&#30340;&#23450;&#37327;&#23646;&#24615;&#36827;&#34892;&#21518;&#22788;&#29702;&#65292;&#20294;&#20063;&#21487;&#24212;&#29992;&#20110;&#20854;&#20182;&#35268;&#21017;&#23398;&#20064;&#26041;&#27861;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#23545;&#20116;&#20010;&#20851;&#32852;&#35268;&#21017;&#20998;&#31867;&#31639;&#27861;&#65288;CBA&#12289;CMAR&#12289;CPAR&#12289;IDS&#12289;SBRL&#65289;&#21644;&#20004;&#20010;&#19968;&#38454;&#36923;&#36753;&#35268;&#21017;&#23398;&#20064;&#22120;&#65288;FOIL2&#21644;PRM&#65289;&#29983;&#25104;&#27169;&#22411;&#30340;&#21518;&#22788;&#29702;&#25928;&#26524;&#65292;&#20351;&#29992;UCI&#20179;&#24211;&#30340;22&#20010;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#32467;&#26524;&#34920;&#26126;FOIL2+QCBA&#30456;&#27604;&#20110;&#25152;&#26377;&#19971;&#20010;&#22522;&#32447;&#30340;&#22823;&#23567;&#26356;&#23567;&#65292;&#24182;&#19988;&#20855;&#26377;&#26368;&#20339;&#30340;&#25972;&#20307;&#39044;&#27979;&#24615;&#33021;&#12290;&#21518;&#20248;&#21270;&#30340;CBA&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#39044;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
A prediscretisation of numerical attributes which is required by some rule learning algorithms is a source of inefficiencies. This paper describes new rule tuning steps that aim to recover lost information in the discretisation and new pruning techniques that may further reduce the size of rule models and improve their accuracy. The proposed QCBA method was initially developed to postprocess quantitative attributes in models generated by the Classification based on associations (CBA) algorithm, but it can also be applied to the results of other rule learning approaches. We demonstrate the effectiveness on the postprocessing of models generated by five association rule classification algorithms (CBA, CMAR, CPAR, IDS, SBRL) and two first-order logic rule learners (FOIL2 and PRM). Benchmarks on 22 datasets from the UCI repository show smaller size and the overall best predictive performance for FOIL2+QCBA compared to all seven baselines. Postoptimised CBA models have a better predictive p
&lt;/p&gt;</description></item></channel></rss>