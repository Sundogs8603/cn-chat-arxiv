<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#22522;&#20110;&#36830;&#32493;&#26102;&#24207;&#27979;&#37327;&#21644;&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#30340;&#30005;&#32593;&#30417;&#27979;&#21644;&#25511;&#21046;&#31995;&#32479;&#65292;&#36890;&#36807;&#25968;&#25454;&#21387;&#32553;&#21644;&#25925;&#38556;&#26816;&#27979;&#65292;&#23454;&#29616;&#20102;&#23545;&#20256;&#32479;&#30417;&#25511;&#31995;&#32479;&#30340;&#36827;&#27493;&#12290;</title><link>https://arxiv.org/abs/2403.06942</link><description>&lt;p&gt;
&#20351;&#29992;&#36830;&#32493;&#26102;&#24207;&#27979;&#37327;&#21644;&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#36827;&#34892;&#30005;&#32593;&#30417;&#27979;&#21644;&#20445;&#25252;
&lt;/p&gt;
&lt;p&gt;
Grid Monitoring and Protection with Continuous Point-on-Wave Measurements and Generative AI
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06942
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#22522;&#20110;&#36830;&#32493;&#26102;&#24207;&#27979;&#37327;&#21644;&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#30340;&#30005;&#32593;&#30417;&#27979;&#21644;&#25511;&#21046;&#31995;&#32479;&#65292;&#36890;&#36807;&#25968;&#25454;&#21387;&#32553;&#21644;&#25925;&#38556;&#26816;&#27979;&#65292;&#23454;&#29616;&#20102;&#23545;&#20256;&#32479;&#30417;&#25511;&#31995;&#32479;&#30340;&#36827;&#27493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#19979;&#19968;&#20195;&#30005;&#32593;&#30417;&#27979;&#21644;&#25511;&#21046;&#31995;&#32479;&#30340;&#26696;&#20363;&#65292;&#21033;&#29992;&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#12289;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#25512;&#26029;&#26041;&#38754;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36830;&#32493;&#26102;&#24207;&#27979;&#37327;&#21644;AI&#25903;&#25345;&#30340;&#25968;&#25454;&#21387;&#32553;&#21644;&#25925;&#38556;&#26816;&#27979;&#30340;&#30417;&#27979;&#21644;&#25511;&#21046;&#26694;&#26550;&#65292;&#36229;&#36234;&#20102;&#20808;&#21069;&#22522;&#20110;SCADA&#21644;&#21516;&#27493;&#30456;&#37327;&#25216;&#26415;&#26500;&#24314;&#30340;&#24191;&#22495;&#30417;&#27979;&#31995;&#32479;&#30340;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06942v1 Announce Type: cross  Abstract: Purpose This article presents a case for a next-generation grid monitoring and control system, leveraging recent advances in generative artificial intelligence (AI), machine learning, and statistical inference. Advancing beyond earlier generations of wide-area monitoring systems built upon supervisory control and data acquisition (SCADA) and synchrophasor technologies, we argue for a monitoring and control framework based on the streaming of continuous point-on-wave (CPOW) measurements with AI-powered data compression and fault detection.   Methods and Results: The architecture of the proposed design originates from the Wiener-Kallianpur innovation representation of a random process that transforms causally a stationary random process into an innovation sequence with independent and identically distributed random variables. This work presents a generative AI approach that (i) learns an innovation autoencoder that extracts innovation se
&lt;/p&gt;</description></item><item><title>Transformers&#22312;&#19981;&#21516;&#25968;&#25454;&#27169;&#24577;&#19978;&#20855;&#26377;&#20302;&#25935;&#24863;&#24615;&#65292;&#36825;&#31181;&#31616;&#21333;&#24615;&#20559;&#24046;&#26377;&#21161;&#20110;&#35299;&#37322;&#20854;&#22312;&#35270;&#35273;&#21644;&#35821;&#35328;&#20219;&#21153;&#20013;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.06925</link><description>&lt;p&gt;
Transformers&#23398;&#20064;&#20302;&#25935;&#24863;&#24615;&#20989;&#25968;&#30340;&#31616;&#21333;&#24615;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Simplicity Bias of Transformers to Learn Low Sensitivity Functions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06925
&lt;/p&gt;
&lt;p&gt;
Transformers&#22312;&#19981;&#21516;&#25968;&#25454;&#27169;&#24577;&#19978;&#20855;&#26377;&#20302;&#25935;&#24863;&#24615;&#65292;&#36825;&#31181;&#31616;&#21333;&#24615;&#20559;&#24046;&#26377;&#21161;&#20110;&#35299;&#37322;&#20854;&#22312;&#35270;&#35273;&#21644;&#35821;&#35328;&#20219;&#21153;&#20013;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformers&#22312;&#35768;&#22810;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#65292;&#20294;&#23545;&#23427;&#20204;&#20855;&#26377;&#30340;&#24402;&#32435;&#20559;&#24046;&#20197;&#21450;&#36825;&#20123;&#20559;&#24046;&#22914;&#20309;&#19982;&#20854;&#20182;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#19981;&#21516;&#30340;&#29702;&#35299;&#20173;&#28982;&#38590;&#20197;&#25417;&#25720;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#27169;&#22411;&#23545;&#36755;&#20837;&#20013;&#30340;&#38543;&#26426;&#26356;&#25913;&#30340;&#25935;&#24863;&#24615;&#27010;&#24565;&#21270;&#20026;&#19968;&#31181;&#31616;&#21333;&#24615;&#20559;&#24046;&#30340;&#27010;&#24565;&#65292;&#36825;&#20026;&#35299;&#37322;transformers&#22312;&#19981;&#21516;&#25968;&#25454;&#27169;&#24577;&#19978;&#30340;&#31616;&#21333;&#24615;&#21644;&#35889;&#20559;&#24046;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#24230;&#37327;&#26631;&#20934;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;transformers&#22312;&#35270;&#35273;&#21644;&#35821;&#35328;&#20219;&#21153;&#20013;&#27604;&#20854;&#20182;&#26367;&#20195;&#26550;&#26500;&#65288;&#22914;LSTMs&#12289;MLPs&#21644;CNNs&#65289;&#20855;&#26377;&#26356;&#20302;&#30340;&#25935;&#24863;&#24615;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#20302;&#25935;&#24863;&#24615;&#20559;&#24046;&#19982;&#25913;&#36827;&#24615;&#33021;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06925v1 Announce Type: cross  Abstract: Transformers achieve state-of-the-art accuracy and robustness across many tasks, but an understanding of the inductive biases that they have and how those biases are different from other neural network architectures remains elusive. Various neural network architectures such as fully connected networks have been found to have a simplicity bias towards simple functions of the data; one version of this simplicity bias is a spectral bias to learn simple functions in the Fourier space. In this work, we identify the notion of sensitivity of the model to random changes in the input as a notion of simplicity bias which provides a unified metric to explain the simplicity and spectral bias of transformers across different data modalities. We show that transformers have lower sensitivity than alternative architectures, such as LSTMs, MLPs and CNNs, across both vision and language tasks. We also show that low-sensitivity bias correlates with impro
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#22312;&#27844;&#28431;ReLU&#32593;&#32476;&#19978;&#20351;&#29992;&#38128;&#38142;&#25439;&#22833;&#36827;&#34892;&#35757;&#32451;&#30340;&#36807;&#31243;&#20013;&#65292;&#20449;&#22122;&#27604;&#65288;SNR&#65289;&#26465;&#20214;&#23545;&#20110;&#33391;&#24615;&#21644;&#38750;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#24433;&#21709;&#65292;&#24182;&#21457;&#29616;&#39640;SNR&#20540;&#20250;&#23548;&#33268;&#33391;&#24615;&#36807;&#25311;&#21512;&#65292;&#20302;SNR&#20540;&#21017;&#20250;&#23548;&#33268;&#26377;&#23475;&#36807;&#25311;&#21512;&#12290;</title><link>https://arxiv.org/abs/2403.06903</link><description>&lt;p&gt;
&#20855;&#26377;&#36866;&#24230;&#36755;&#20837;&#32500;&#24230;&#30340;&#27844;&#28431;ReLU&#32593;&#32476;&#20013;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Benign overfitting in leaky ReLU networks with moderate input dimension
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06903
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#22312;&#27844;&#28431;ReLU&#32593;&#32476;&#19978;&#20351;&#29992;&#38128;&#38142;&#25439;&#22833;&#36827;&#34892;&#35757;&#32451;&#30340;&#36807;&#31243;&#20013;&#65292;&#20449;&#22122;&#27604;&#65288;SNR&#65289;&#26465;&#20214;&#23545;&#20110;&#33391;&#24615;&#21644;&#38750;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#24433;&#21709;&#65292;&#24182;&#21457;&#29616;&#39640;SNR&#20540;&#20250;&#23548;&#33268;&#33391;&#24615;&#36807;&#25311;&#21512;&#65292;&#20302;SNR&#20540;&#21017;&#20250;&#23548;&#33268;&#26377;&#23475;&#36807;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33391;&#24615;&#36807;&#25311;&#21512;&#38382;&#39064;&#25506;&#35752;&#20102;&#19968;&#20010;&#27169;&#22411;&#26159;&#21542;&#33021;&#22815;&#23436;&#32654;&#22320;&#25311;&#21512;&#22024;&#26434;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#21516;&#26102;&#21448;&#33021;&#22815;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#20108;&#23618;&#27844;&#28431;ReLU&#32593;&#32476;&#19978;&#20351;&#29992;&#38128;&#38142;&#25439;&#22833;&#36827;&#34892;&#35757;&#32451;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#38382;&#39064;&#65292;&#38024;&#23545;&#20108;&#20998;&#31867;&#20219;&#21153;&#12290;&#25105;&#20204;&#32771;&#34385;&#36755;&#20837;&#25968;&#25454;&#65292;&#21487;&#20197;&#20998;&#35299;&#20026;&#19968;&#20010;&#20849;&#21516;&#20449;&#21495;&#21644;&#19968;&#20010;&#38543;&#26426;&#22122;&#22768;&#25104;&#20998;&#30340;&#24635;&#21644;&#65292;&#36825;&#20004;&#32773;&#30456;&#20114;&#27491;&#20132;&#12290;&#25105;&#20204;&#34920;&#24449;&#20102;&#27169;&#22411;&#21442;&#25968;&#30340;&#20449;&#22122;&#27604;&#65288;SNR&#65289;&#26465;&#20214;&#65292;&#23548;&#33268;&#20102;&#33391;&#24615;&#21644;&#38750;&#33391;&#24615;&#65288;&#26377;&#23475;&#65289;&#36807;&#25311;&#21512;&#65306;&#29305;&#21035;&#26159;&#65292;&#22914;&#26524;SNR&#24456;&#39640;&#65292;&#21017;&#21457;&#29983;&#33391;&#24615;&#36807;&#25311;&#21512;&#65292;&#30456;&#21453;&#65292;&#22914;&#26524;SNR&#24456;&#20302;&#65292;&#21017;&#21457;&#29983;&#26377;&#23475;&#36807;&#25311;&#21512;&#12290;&#25105;&#20204;&#23558;&#33391;&#24615;&#21644;&#38750;&#33391;&#24615;&#36807;&#25311;&#21512;&#24402;&#22240;&#20110;&#19968;&#20010;&#36817;&#20284;&#36793;&#30028;&#26368;&#22823;&#21270;&#24615;&#36136;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#38128;&#38142;&#25439;&#22833;&#19979;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#35757;&#32451;&#30340;&#27844;&#28431;ReLU&#32593;&#32476;&#28385;&#36275;&#36825;&#19968;&#24615;&#36136;&#12290;&#19982;&#20197;&#21069;&#30340;&#24037;&#20316;&#30456;&#27604;&#65292;&#25105;&#20204;&#19981;&#38656;&#35201;nea
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06903v1 Announce Type: new  Abstract: The problem of benign overfitting asks whether it is possible for a model to perfectly fit noisy training data and still generalize well. We study benign overfitting in two-layer leaky ReLU networks trained with the hinge loss on a binary classification task. We consider input data which can be decomposed into the sum of a common signal and a random noise component, which lie on subspaces orthogonal to one another. We characterize conditions on the signal to noise ratio (SNR) of the model parameters giving rise to benign versus non-benign, or harmful, overfitting: in particular, if the SNR is high then benign overfitting occurs, conversely if the SNR is low then harmful overfitting occurs. We attribute both benign and non-benign overfitting to an approximate margin maximization property and show that leaky ReLU networks trained on hinge loss with Gradient Descent (GD) satisfy this property. In contrast to prior work we do not require nea
&lt;/p&gt;</description></item><item><title>&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#22914;&#20309;&#24433;&#21709;&#27169;&#22411;&#27867;&#21270;&#33021;&#21147;&#30340;&#20851;&#38190;&#22240;&#32032;&#30340;&#26032;&#29702;&#35770;&#26694;&#26550;</title><link>https://arxiv.org/abs/2403.06871</link><description>&lt;p&gt;
&#20851;&#20110;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#30340;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
On the Generalization Ability of Unsupervised Pretraining
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06871
&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#22914;&#20309;&#24433;&#21709;&#27169;&#22411;&#27867;&#21270;&#33021;&#21147;&#30340;&#20851;&#38190;&#22240;&#32032;&#30340;&#26032;&#29702;&#35770;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#34920;&#26126;&#65292;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#65292;&#28982;&#21518;&#36827;&#34892;&#24494;&#35843;&#65292;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23545;&#20110;&#22312;&#26410;&#26631;&#35760;&#25968;&#25454;&#38598;&#19978;&#23398;&#20064;&#30340;&#34920;&#31034;&#20989;&#25968;&#22914;&#20309;&#24433;&#21709;&#24494;&#35843;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#32570;&#20047;&#20005;&#26684;&#30340;&#29702;&#35299;&#12290;&#29616;&#26377;&#29702;&#35770;&#30740;&#31350;&#26410;&#33021;&#20805;&#20998;&#32771;&#34385;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#38454;&#27573;&#30340;&#20998;&#24067;&#21644;&#20219;&#21153;&#30340;&#24322;&#36136;&#24615;&#12290;&#20026;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#38416;&#26126;&#20102;&#24433;&#21709;&#20174;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#33719;&#24471;&#30340;&#30693;&#35782;&#22312;&#38543;&#21518;&#30340;&#24494;&#35843;&#38454;&#27573;&#30340;&#21487;&#20256;&#36882;&#24615;&#30340;&#20851;&#38190;&#22240;&#32032;&#65292;&#26368;&#32456;&#24433;&#21709;&#20102;&#24494;&#35843;&#27169;&#22411;&#22312;&#19979;&#28216;&#20219;&#21153;&#19978;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#24212;&#29992;&#25105;&#20204;&#30340;&#29702;&#35770;&#26694;&#26550;&#26469;&#20998;&#26512;&#20004;&#31181;&#19981;&#21516;&#24773;&#26223;&#30340;&#27867;&#21270;&#30028;&#38480;&#65306;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#19978;&#19979;&#25991;&#32534;&#30721;&#22120;&#39044;&#35757;&#32451;&#21644;&#33945;&#29256;&#33258;&#32534;&#30721;&#39044;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06871v1 Announce Type: new  Abstract: Recent advances in unsupervised learning have shown that unsupervised pre-training, followed by fine-tuning, can improve model generalization. However, a rigorous understanding of how the representation function learned on an unlabeled dataset affects the generalization of the fine-tuned model is lacking. Existing theoretical research does not adequately account for the heterogeneity of the distribution and tasks in pre-training and fine-tuning stage. To bridge this gap, this paper introduces a novel theoretical framework that illuminates the critical factor influencing the transferability of knowledge acquired during unsupervised pre-training to the subsequent fine-tuning phase, ultimately affecting the generalization capabilities of the fine-tuned model on downstream tasks. We apply our theoretical framework to analyze generalization bound of two distinct scenarios: Context Encoder pre-training with deep neural networks and Masked Auto
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;In-context Exploration-Exploitation (ICEE)&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;Transformer&#27169;&#22411;&#20869;&#37096;&#36827;&#34892;&#25506;&#32034;-&#21033;&#29992;&#26435;&#34913;&#65292;&#25552;&#39640;&#20102;&#22312;-context&#31574;&#30053;&#23398;&#20064;&#30340;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.06826</link><description>&lt;p&gt;
&#22522;&#20110;&#19978;&#19979;&#25991;&#30340;&#25506;&#32034;-&#21033;&#29992;&#29992;&#20110;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
In-context Exploration-Exploitation for Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06826
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;In-context Exploration-Exploitation (ICEE)&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;Transformer&#27169;&#22411;&#20869;&#37096;&#36827;&#34892;&#25506;&#32034;-&#21033;&#29992;&#26435;&#34913;&#65292;&#25552;&#39640;&#20102;&#22312;-context&#31574;&#30053;&#23398;&#20064;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;-context&#23398;&#20064;&#26159;&#22312;&#32447;&#31574;&#30053;&#23398;&#20064;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#26041;&#27861;&#30340;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#25512;&#29702;&#26102;&#38388;&#20869;&#23454;&#29616;&#65292;&#26080;&#38656;&#26799;&#24230;&#20248;&#21270;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#38656;&#35201;&#25910;&#38598;&#22823;&#37327;&#35757;&#32451;&#36712;&#36857;&#38598;&#24182;&#35757;&#32451;&#22823;&#22411;Transformer&#27169;&#22411;&#65292;&#36825;&#31181;&#26041;&#27861;&#25152;&#24102;&#26469;&#30340;&#26174;&#33879;&#35745;&#31639;&#25104;&#26412;&#12290;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#22522;&#20110;In-context Exploration-Exploitation&#65288;ICEE&#65289;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#35813;&#31639;&#27861;&#26088;&#22312;&#20248;&#21270;&#22312;-context&#31574;&#30053;&#23398;&#20064;&#30340;&#25928;&#29575;&#12290;ICEE&#22312;&#25512;&#29702;&#26102;&#38388;&#20869;&#22312;Transformer&#27169;&#22411;&#20013;&#25191;&#34892;&#25506;&#32034;-&#21033;&#29992;&#26435;&#34913;&#65292;&#19981;&#38656;&#35201;&#26174;&#24335;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#22240;&#27492;&#65292;ICEE&#21487;&#20197;&#20687;&#39640;&#26031;&#36807;&#31243;&#20559;&#24046;&#26041;&#27861;&#37027;&#26679;&#26377;&#25928;&#22320;&#35299;&#20915;&#36125;&#21494;&#26031;&#20248;&#21270;&#38382;&#39064;&#65292;&#20294;&#26102;&#38388;&#26174;&#30528;&#36739;&#30701;&#12290;&#36890;&#36807;&#22312;&#32593;&#26684;&#19990;&#30028;&#29615;&#22659;&#20013;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;ICEE&#33021;&#22815;&#23398;&#20064;&#35299;&#20915;&#26032;&#30340;R
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06826v1 Announce Type: cross  Abstract: In-context learning is a promising approach for online policy learning of offline reinforcement learning (RL) methods, which can be achieved at inference time without gradient optimization. However, this method is hindered by significant computational costs resulting from the gathering of large training trajectory sets and the need to train large Transformer models. We address this challenge by introducing an In-context Exploration-Exploitation (ICEE) algorithm, designed to optimize the efficiency of in-context policy learning. Unlike existing models, ICEE performs an exploration-exploitation trade-off at inference time within a Transformer model, without the need for explicit Bayesian inference. Consequently, ICEE can solve Bayesian optimization problems as efficiently as Gaussian process biased methods do, but in significantly less time. Through experiments in grid world environments, we demonstrate that ICEE can learn to solve new R
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#21033;&#29992;Kullback-Leibler&#25955;&#24230;&#35757;&#32451;&#22823;&#35268;&#27169;&#12289;&#38750;&#20809;&#28369;&#30340;Maxent&#27169;&#22411;</title><link>https://arxiv.org/abs/2403.06816</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#12289;&#38750;&#20809;&#28369;&#26368;&#22823;&#29109;&#27169;&#22411;&#30340;&#39640;&#25928;&#19968;&#38454;&#31639;&#27861;&#21450;&#20854;&#22312;&#37326;&#28779;&#31185;&#23398;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Efficient first-order algorithms for large-scale, non-smooth maximum entropy models with application to wildfire science
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06816
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#21033;&#29992;Kullback-Leibler&#25955;&#24230;&#35757;&#32451;&#22823;&#35268;&#27169;&#12289;&#38750;&#20809;&#28369;&#30340;Maxent&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#22823;&#29109;&#65288;Maxent&#65289;&#27169;&#22411;&#26159;&#19968;&#31867;&#21033;&#29992;&#26368;&#22823;&#29109;&#21407;&#29702;&#20174;&#25968;&#25454;&#20013;&#20272;&#35745;&#27010;&#29575;&#20998;&#24067;&#30340;&#32479;&#35745;&#27169;&#22411;&#12290;&#30001;&#20110;&#29616;&#20195;&#25968;&#25454;&#38598;&#30340;&#35268;&#27169;&#65292;Maxent&#27169;&#22411;&#38656;&#35201;&#39640;&#25928;&#30340;&#20248;&#21270;&#31639;&#27861;&#26469;&#36866;&#24212;&#22823;&#25968;&#25454;&#24212;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#20811;&#26381;&#20102;&#35757;&#32451;&#22823;&#35268;&#27169;&#12289;&#38750;&#20809;&#28369;Maxent&#27169;&#22411;&#30340;&#29616;&#26377;&#31639;&#27861;&#30340;&#32570;&#28857;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#19968;&#38454;&#31639;&#27861;&#21033;&#29992;Kullback-Leibler&#25955;&#24230;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35757;&#32451;&#22823;&#35268;&#27169;&#19988;&#38750;&#20809;&#28369;&#30340;Maxent&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06816v1 Announce Type: cross  Abstract: Maximum entropy (Maxent) models are a class of statistical models that use the maximum entropy principle to estimate probability distributions from data. Due to the size of modern data sets, Maxent models need efficient optimization algorithms to scale well for big data applications. State-of-the-art algorithms for Maxent models, however, were not originally designed to handle big data sets; these algorithms either rely on technical devices that may yield unreliable numerical results, scale poorly, or require smoothness assumptions that many practical Maxent models lack. In this paper, we present novel optimization algorithms that overcome the shortcomings of state-of-the-art algorithms for training large-scale, non-smooth Maxent models. Our proposed first-order algorithms leverage the Kullback-Leibler divergence to train large-scale and non-smooth Maxent models efficiently. For Maxent models with discrete probability distribution of $
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#21333;&#35843;&#32858;&#21512;&#20989;&#25968;&#23454;&#29616;&#20102;&#19968;&#31181;&#20010;&#20307;&#20844;&#24179;&#24615;&#23457;&#35745;&#26041;&#26696;&#65292;&#21487;&#20197;&#26377;&#25928;&#38477;&#20302;&#22810;&#20010;&#23457;&#35745;&#21592;&#23545;&#20010;&#20307;&#20844;&#24179;&#24615;&#30340;&#20998;&#26512;&#22797;&#26434;&#24230;&#12290;</title><link>https://arxiv.org/abs/2403.06812</link><description>&lt;p&gt;
&#21333;&#35843;&#20010;&#20307;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Monotone Individual Fairness
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06812
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#21333;&#35843;&#32858;&#21512;&#20989;&#25968;&#23454;&#29616;&#20102;&#19968;&#31181;&#20010;&#20307;&#20844;&#24179;&#24615;&#23457;&#35745;&#26041;&#26696;&#65292;&#21487;&#20197;&#26377;&#25928;&#38477;&#20302;&#22810;&#20010;&#23457;&#35745;&#21592;&#23545;&#20010;&#20307;&#20844;&#24179;&#24615;&#30340;&#20998;&#26512;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#24102;&#26377;&#20010;&#20307;&#20844;&#24179;&#24615;&#30340;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#65292;&#20854;&#20013;&#22312;&#32447;&#23398;&#20064;&#32773;&#21162;&#21147;&#22312;&#26368;&#22823;&#21270;&#39044;&#27979;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#30830;&#20445;&#30456;&#20284;&#20010;&#20307;&#21463;&#21040;&#31867;&#20284;&#23545;&#24453;&#12290;&#25105;&#20204;&#39318;&#20808;&#25193;&#23637;&#20102;Gillen&#31561;&#20154;&#65288;2018&#24180;&#65289;&#65307;Bechavod&#31561;&#20154;&#65288;2020&#24180;&#65289;&#30340;&#26694;&#26550;&#65292;&#36825;&#20123;&#26694;&#26550;&#20381;&#36182;&#20110;&#26469;&#33258;&#20154;&#31867;&#23457;&#35745;&#21592;&#26377;&#20851;&#20844;&#24179;&#24615;&#36829;&#35268;&#30340;&#21453;&#39304;&#65292;&#22240;&#20026;&#25105;&#20204;&#32771;&#34385;&#20102;&#33021;&#22815;&#32858;&#21512;&#20219;&#24847;&#25968;&#37327;&#23457;&#35745;&#21592;&#21453;&#39304;&#30340;&#23457;&#35745;&#26041;&#26696;&#65292;&#20351;&#29992;&#20102;&#25105;&#20204;&#31216;&#20026;&#21333;&#35843;&#32858;&#21512;&#20989;&#25968;&#30340;&#20016;&#23500;&#31867;&#21035;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#23457;&#35745;&#26041;&#26696;&#30340;&#29305;&#24615;&#65292;&#36890;&#36807;&#23454;&#38469;&#23558;&#22810;&#20010;&#23457;&#35745;&#21592;&#30340;&#20010;&#20307;&#20844;&#24179;&#24615;&#23457;&#35745;&#20998;&#26512;&#31616;&#21270;&#20026;&#65288;&#23454;&#20363;&#29305;&#23450;&#30340;&#65289;&#21333;&#20010;&#23457;&#35745;&#21592;&#30340;&#23457;&#35745;&#12290;&#21033;&#29992;&#25105;&#20204;&#30340;&#24191;&#20041;&#26694;&#26550;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23454;&#29616;&#19978;&#30028;&#21069;&#27839;&#30340;oracle-efficient&#31639;&#27861;&#65292;&#20998;&#21035;&#20026;&#36951;&#25022;&#20540;&#21644;&#20844;&#24179;&#24615;&#36829;&#35268;&#27425;&#25968;&#30340;&#19978;&#30028;$(\mathcal{O}(T^{1/2+2b}),\mathcal{O}(T^{3/4-b}))$&#65292;&#20854;&#20013;$0\leq b$
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06812v1 Announce Type: new  Abstract: We revisit the problem of online learning with individual fairness, where an online learner strives to maximize predictive accuracy while ensuring that similar individuals are treated similarly. We first extend the frameworks of Gillen et al. (2018); Bechavod et al. (2020), which rely on feedback from human auditors regarding fairness violations, as we consider auditing schemes that are capable of aggregating feedback from any number of auditors, using a rich class we term monotone aggregation functions. We then prove a characterization for such auditing schemes, practically reducing the analysis of auditing for individual fairness by multiple auditors to that of auditing by (instance-specific) single auditors. Using our generalized framework, we present an oracle-efficient algorithm achieving an upper bound frontier of $(\mathcal{O}(T^{1/2+2b}),\mathcal{O}(T^{3/4-b}))$ respectively for regret, number of fairness violations, for $0\leq b
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22810;&#27493;&#19968;&#33268;&#24615;&#27169;&#22411;&#65292;&#36890;&#36807;&#22312;&#19968;&#33268;&#24615;&#27169;&#22411;&#21644;&#25193;&#25955;&#27169;&#22411;&#20043;&#38388;&#25554;&#20540;&#65292;&#23454;&#29616;&#20102;&#37319;&#26679;&#36895;&#24230;&#21644;&#37319;&#26679;&#36136;&#37327;&#30340;&#24179;&#34913;&#12290;</title><link>https://arxiv.org/abs/2403.06807</link><description>&lt;p&gt;
&#22810;&#27493;&#19968;&#33268;&#24615;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Multistep Consistency Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06807
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22810;&#27493;&#19968;&#33268;&#24615;&#27169;&#22411;&#65292;&#36890;&#36807;&#22312;&#19968;&#33268;&#24615;&#27169;&#22411;&#21644;&#25193;&#25955;&#27169;&#22411;&#20043;&#38388;&#25554;&#20540;&#65292;&#23454;&#29616;&#20102;&#37319;&#26679;&#36895;&#24230;&#21644;&#37319;&#26679;&#36136;&#37327;&#30340;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#30456;&#23545;&#23481;&#26131;&#35757;&#32451;&#65292;&#20294;&#29983;&#25104;&#26679;&#26412;&#38656;&#35201;&#35768;&#22810;&#27493;&#39588;&#12290;&#19968;&#33268;&#24615;&#27169;&#22411;&#26356;&#38590;&#35757;&#32451;&#65292;&#20294;&#21487;&#20197;&#22312;&#19968;&#20010;&#27493;&#39588;&#20013;&#29983;&#25104;&#26679;&#26412;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#22810;&#27493;&#19968;&#33268;&#24615;&#27169;&#22411;&#65306;&#36890;&#36807;&#19968;&#33268;&#24615;&#27169;&#22411;&#21644;TRACT&#30340;&#32479;&#19968;&#65292;&#21487;&#20197;&#22312;&#19968;&#33268;&#24615;&#27169;&#22411;&#21644;&#25193;&#25955;&#27169;&#22411;&#20043;&#38388;&#36827;&#34892;&#25554;&#20540;&#65306;&#22312;&#37319;&#26679;&#36895;&#24230;&#21644;&#37319;&#26679;&#36136;&#37327;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;1&#27493;&#19968;&#33268;&#24615;&#27169;&#22411;&#26159;&#20256;&#32479;&#30340;&#19968;&#33268;&#24615;&#27169;&#22411;&#65292;&#32780;&#25105;&#20204;&#23637;&#31034;&#20102;$\infty$&#27493;&#19968;&#33268;&#24615;&#27169;&#22411;&#26159;&#25193;&#25955;&#27169;&#22411;&#12290;&#22810;&#27493;&#19968;&#33268;&#24615;&#27169;&#22411;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;&#23558;&#26679;&#26412;&#39044;&#31639;&#20174;&#21333;&#27493;&#22686;&#21152;&#21040;2-8&#27493;&#65292;&#25105;&#20204;&#21487;&#20197;&#26356;&#36731;&#26494;&#22320;&#35757;&#32451;&#27169;&#22411;&#65292;&#29983;&#25104;&#26356;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#65292;&#21516;&#26102;&#20445;&#30041;&#22823;&#37096;&#20998;&#37319;&#26679;&#36895;&#24230;&#20248;&#21183;&#12290;&#22312;Imagenet 64&#19978;8&#27493;&#36798;&#21040;1.4&#30340;FID&#65292;&#22312;Imagenet128&#19978;8&#27493;&#36798;&#21040;2.1&#30340;FID&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06807v1 Announce Type: new  Abstract: Diffusion models are relatively easy to train but require many steps to generate samples. Consistency models are far more difficult to train, but generate samples in a single step.   In this paper we propose Multistep Consistency Models: A unification between Consistency Models (Song et al., 2023) and TRACT (Berthelot et al., 2023) that can interpolate between a consistency model and a diffusion model: a trade-off between sampling speed and sampling quality. Specifically, a 1-step consistency model is a conventional consistency model whereas we show that a $\infty$-step consistency model is a diffusion model.   Multistep Consistency Models work really well in practice. By increasing the sample budget from a single step to 2-8 steps, we can train models more easily that generate higher quality samples, while retaining much of the sampling speed benefits. Notable results are 1.4 FID on Imagenet 64 in 8 step and 2.1 FID on Imagenet128 in 8 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32771;&#34385;&#24452;&#21521;&#26680;&#20989;&#25968;&#30340;&#27888;&#21202;&#32423;&#25968;&#36924;&#36817;&#65292;&#24314;&#31435;&#20102;&#23545;&#26680;&#20989;&#25968;&#30340;&#36739;&#22909;&#36817;&#20284;&#65292;&#35777;&#23454;&#20102;&#21487;&#20197;&#20351;&#29992;&#27604;&#25991;&#29486;&#20013;&#26356;&#23567;&#30340;&#27491;&#21017;&#21270;&#21442;&#25968;&#26469;&#23454;&#29616;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.06731</link><description>&lt;p&gt;
&#23545;&#26680;&#20989;&#25968;&#30340;&#36817;&#20284;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
On the Approximation of Kernel functions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06731
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32771;&#34385;&#24452;&#21521;&#26680;&#20989;&#25968;&#30340;&#27888;&#21202;&#32423;&#25968;&#36924;&#36817;&#65292;&#24314;&#31435;&#20102;&#23545;&#26680;&#20989;&#25968;&#30340;&#36739;&#22909;&#36817;&#20284;&#65292;&#35777;&#23454;&#20102;&#21487;&#20197;&#20351;&#29992;&#27604;&#25991;&#29486;&#20013;&#26356;&#23567;&#30340;&#27491;&#21017;&#21270;&#21442;&#25968;&#26469;&#23454;&#29616;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32479;&#35745;&#23398;&#20064;&#20013;&#30340;&#21508;&#31181;&#26041;&#27861;&#37117;&#24314;&#31435;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#32771;&#34385;&#30340;&#26680;&#20989;&#25968;&#22522;&#30784;&#20043;&#19978;&#12290;&#22312;&#24212;&#29992;&#20013;&#65292;&#36890;&#24120;&#26681;&#25454;&#38382;&#39064;&#21644;&#25968;&#25454;&#30340;&#29305;&#24449;&#36873;&#25321;&#26680;&#20989;&#25968;&#12290;&#28982;&#21518;&#21033;&#29992;&#36825;&#20010;&#26680;&#20989;&#25968;&#25512;&#26029;&#37027;&#20123;&#27809;&#26377;&#35266;&#27979;&#21040;&#35299;&#37322;&#25968;&#25454;&#30340;&#28857;&#30340;&#21709;&#24212;&#21464;&#37327;&#12290;&#26412;&#25991;&#30740;&#31350;&#30340;&#25968;&#25454;&#20301;&#20110;&#39640;&#32500;&#31354;&#38388;&#20013;&#30340;&#32039;&#33268;&#38598;&#21512;&#20013;&#65292;&#24182;&#35299;&#20915;&#20102;&#26680;&#20989;&#25968;&#26412;&#36523;&#30340;&#36817;&#20284;&#38382;&#39064;&#12290;&#26032;&#26041;&#27861;&#32771;&#34385;&#20102;&#24452;&#21521;&#26680;&#20989;&#25968;&#30340;&#27888;&#21202;&#32423;&#25968;&#36924;&#36817;&#12290;&#23545;&#20110;&#21333;&#20301;&#31435;&#26041;&#20307;&#19978;&#30340;&#39640;&#26031;&#26680;&#20989;&#25968;&#65292;&#26412;&#25991;&#24314;&#31435;&#20102;&#20851;&#32852;&#29305;&#24449;&#20989;&#25968;&#30340;&#19978;&#38480;&#65292;&#36825;&#20010;&#19978;&#38480;&#38543;&#25351;&#25968;&#22810;&#39033;&#24335;&#22686;&#38271;&#12290;&#35813;&#26032;&#26041;&#27861;&#35777;&#26126;&#20102;&#27604;&#25991;&#29486;&#20013;&#32771;&#34385;&#30340;&#26356;&#23567;&#30340;&#27491;&#21017;&#21270;&#21442;&#25968;&#65292;&#20174;&#32780;&#25972;&#20307;&#19978;&#23454;&#29616;&#26356;&#22909;&#30340;&#36817;&#20284;&#12290;&#36825;&#19968;&#25913;&#36827;&#35777;&#23454;&#20102;&#20302;&#31209;&#36924;&#36817;&#26041;&#27861;&#65292;&#22914;Nystrom&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06731v1 Announce Type: cross  Abstract: Various methods in statistical learning build on kernels considered in reproducing kernel Hilbert spaces. In applications, the kernel is often selected based on characteristics of the problem and the data. This kernel is then employed to infer response variables at points, where no explanatory data were observed. The data considered here are located in compact sets in higher dimensions and the paper addresses approximations of the kernel itself. The new approach considers Taylor series approximations of radial kernel functions. For the Gauss kernel on the unit cube, the paper establishes an upper bound of the associated eigenfunctions, which grows only polynomially with respect to the index. The novel approach substantiates smaller regularization parameters than considered in the literature, overall leading to better approximations. This improvement confirms low rank approximation methods such as the Nystr\"om method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38544;&#31169;&#25935;&#24863;&#39046;&#22495;&#20013;&#22914;&#20309;&#35774;&#35745;&#19968;&#31181;FL&#21327;&#35758;&#65292;&#26082;&#33021;&#20445;&#35777;&#38544;&#31169;&#65292;&#21448;&#33021;&#25552;&#39640;&#27169;&#22411;&#20934;&#30830;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#35774;&#35745;&#20986;&#23545;&#25152;&#26377;&#21442;&#19982;&#32773;&#37117;&#26377;&#30410;&#22788;&#30340;&#21327;&#35758;&#12290;</title><link>https://arxiv.org/abs/2403.06672</link><description>&lt;p&gt;
&#22312;&#38544;&#31169;&#25935;&#24863;&#39046;&#22495;&#20013;&#20174;&#32852;&#37030;&#23398;&#20064;&#20013;&#26377;&#21487;&#35777;&#26126;&#30340;&#20114;&#24800;&#30410;&#22788;
&lt;/p&gt;
&lt;p&gt;
Provable Mutual Benefits from Federated Learning in Privacy-Sensitive Domains
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06672
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38544;&#31169;&#25935;&#24863;&#39046;&#22495;&#20013;&#22914;&#20309;&#35774;&#35745;&#19968;&#31181;FL&#21327;&#35758;&#65292;&#26082;&#33021;&#20445;&#35777;&#38544;&#31169;&#65292;&#21448;&#33021;&#25552;&#39640;&#27169;&#22411;&#20934;&#30830;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#35774;&#35745;&#20986;&#23545;&#25152;&#26377;&#21442;&#19982;&#32773;&#37117;&#26377;&#30410;&#22788;&#30340;&#21327;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36328;&#39046;&#22495;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#20801;&#35768;&#25968;&#25454;&#25152;&#26377;&#32773;&#36890;&#36807;&#20174;&#24444;&#27492;&#30340;&#31169;&#26377;&#25968;&#25454;&#38598;&#20013;&#33719;&#30410;&#26469;&#35757;&#32451;&#20934;&#30830;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20309;&#26102;&#20197;&#21450;&#22914;&#20309;&#26381;&#21153;&#22120;&#21487;&#20197;&#35774;&#35745;&#19968;&#31181;&#23545;&#25152;&#26377;&#21442;&#19982;&#32773;&#37117;&#26377;&#21033;&#30340;FL&#21327;&#35758;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#22312;&#22343;&#20540;&#20272;&#35745;&#21644;&#20984;&#38543;&#26426;&#20248;&#21270;&#32972;&#26223;&#19979;&#23384;&#22312;&#30456;&#20114;&#26377;&#21033;&#21327;&#35758;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#22312;&#23545;&#31216;&#38544;&#31169;&#20559;&#22909;&#19979;&#65292;&#26368;&#22823;&#21270;&#24635;&#23458;&#25143;&#25928;&#29992;&#30340;&#21327;&#35758;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#26368;&#22823;&#21270;&#26368;&#32456;&#27169;&#22411;&#20934;&#30830;&#24615;&#30340;&#21327;&#35758;&#65292;&#24182;&#22312;&#21512;&#25104;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#23427;&#20204;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06672v1 Announce Type: cross  Abstract: Cross-silo federated learning (FL) allows data owners to train accurate machine learning models by benefiting from each others private datasets. Unfortunately, the model accuracy benefits of collaboration are often undermined by privacy defenses. Therefore, to incentivize client participation in privacy-sensitive domains, a FL protocol should strike a delicate balance between privacy guarantees and end-model accuracy. In this paper, we study the question of when and how a server could design a FL protocol provably beneficial for all participants. First, we provide necessary and sufficient conditions for the existence of mutually beneficial protocols in the context of mean estimation and convex stochastic optimization. We also derive protocols that maximize the total clients' utility, given symmetric privacy preferences. Finally, we design protocols maximizing end-model accuracy and demonstrate their benefits in synthetic experiments.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#25506;&#32034;&#30446;&#26631;&#26694;&#26550;&#65292;&#24341;&#20837;&#20102;$L_1$-&#35206;&#30422;&#24230;&#20316;&#20026;&#26032;&#30340;&#25506;&#32034;&#30446;&#26631;&#65292;&#25903;&#25345;&#20869;&#22312;&#22797;&#26434;&#24230;&#25511;&#21046;&#12289;&#39640;&#25928;&#35268;&#21010;&#21644;&#28789;&#27963;&#38598;&#25104;&#30340;&#20248;&#28857;&#12290;</title><link>https://arxiv.org/abs/2403.06571</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;&#22312;&#32447;&#25506;&#32034;&#26041;&#27861;&#65306;&#36890;&#36807;Coverability
&lt;/p&gt;
&lt;p&gt;
Scalable Online Exploration via Coverability
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06571
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#25506;&#32034;&#30446;&#26631;&#26694;&#26550;&#65292;&#24341;&#20837;&#20102;$L_1$-&#35206;&#30422;&#24230;&#20316;&#20026;&#26032;&#30340;&#25506;&#32034;&#30446;&#26631;&#65292;&#25903;&#25345;&#20869;&#22312;&#22797;&#26434;&#24230;&#25511;&#21046;&#12289;&#39640;&#25928;&#35268;&#21010;&#21644;&#28789;&#27963;&#38598;&#25104;&#30340;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#25506;&#32034;&#26159;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#65292;&#23588;&#20854;&#23545;&#20110;&#38656;&#35201;&#20989;&#25968;&#36924;&#36817;&#30340;&#39640;&#32500;&#39046;&#22495;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#25506;&#32034;&#30446;&#26631;&#8212;&#8212;&#20316;&#20026;&#19968;&#20010;&#27010;&#24565;&#26694;&#26550;&#65292;&#33021;&#22815;&#20351;&#20219;&#20309;&#22870;&#21169;&#20989;&#25968;&#30340;&#19979;&#28216;&#26368;&#22823;&#21270;&#25104;&#20026;&#21487;&#33021;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20869;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#30446;&#26631;&#65292;&#21363;$L_1$-&#35206;&#30422;&#24230;&#65292;&#23427;&#27867;&#21270;&#20102;&#20197;&#24448;&#30340;&#25506;&#32034;&#26041;&#26696;&#65292;&#24182;&#25903;&#25345;&#19977;&#20010;&#22522;&#26412;&#24895;&#26395;&#65306;1.&#20869;&#22312;&#22797;&#26434;&#24230;&#25511;&#21046;&#12290;$L_1$-&#35206;&#30422;&#24230;&#19982;&#32467;&#26500;&#21442;&#25968;$L_1$-Coverability&#30456;&#20851;&#32852;&#65292;&#21453;&#26144;&#20102;&#28508;&#22312;MDP&#30340;&#20869;&#22312;&#32479;&#35745;&#22256;&#38590;&#24230;&#65292;&#21253;&#21547;Block&#21644;Low-Rank MDPs&#12290;2.&#39640;&#25928;&#35268;&#21010;&#12290;&#23545;&#20110;&#24050;&#30693;&#30340;MDP&#65292;&#20248;&#21270;$L_1$-&#35206;&#30422;&#24230;&#33021;&#22815;&#26377;&#25928;&#22320;&#38477;&#20302;&#21040;&#26631;&#20934;&#30340;&#31574;&#30053;&#20248;&#21270;&#65292;&#20801;&#35768;&#19982;&#35832;&#22914;&#31574;&#30053;&#26799;&#24230;&#21644;Q-learning&#31561;&#29616;&#25104;&#26041;&#27861;&#28789;&#27963;&#38598;&#25104;&#12290;3.&#39640;&#25928;&#30340;&#25506;&#32034;&#12290;$L_1$-&#35206;&#30422;&#24230;&#30340;&#20248;&#21270;&#31561;&#21516;&#20110;&#29616;&#26377;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#25805;&#20316;&#65292;&#23588;&#20854;&#22312;&#39640;&#32500;&#39046;&#22495;&#20013;&#20855;&#26377;&#24456;&#24378;&#30340;&#27867;&#21270;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06571v1 Announce Type: new  Abstract: Exploration is a major challenge in reinforcement learning, especially for high-dimensional domains that require function approximation. We propose exploration objectives -- policy optimization objectives that enable downstream maximization of any reward function -- as a conceptual framework to systematize the study of exploration. Within this framework, we introduce a new objective, $L_1$-Coverage, which generalizes previous exploration schemes and supports three fundamental desiderata:   1. Intrinsic complexity control. $L_1$-Coverage is associated with a structural parameter, $L_1$-Coverability, which reflects the intrinsic statistical difficulty of the underlying MDP, subsuming Block and Low-Rank MDPs.   2. Efficient planning. For a known MDP, optimizing $L_1$-Coverage efficiently reduces to standard policy optimization, allowing flexible integration with off-the-shelf methods such as policy gradient and Q-learning approaches.   3. E
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#22312;&#21345;&#22374;-&#21704;&#36798;&#29595;&#24503;&#27969;&#24418;&#19978;&#25512;&#23548;&#20102;&#20999;&#29255;-&#21326;&#22622;&#26031;&#22374;&#36317;&#31163;&#30340;&#19968;&#33324;&#26500;&#36896;&#65292;&#25552;&#20986;&#20102;&#19981;&#21516;&#24212;&#29992;&#65292;&#24182;&#19988;&#25512;&#23548;&#20102;&#38750;&#21442;&#25968;&#26041;&#26696;&#20197;&#26368;&#23567;&#21270;&#36825;&#20123;&#26032;&#36317;&#31163;&#12290;</title><link>https://arxiv.org/abs/2403.06560</link><description>&lt;p&gt;
&#20999;&#29255;-&#21326;&#22622;&#26031;&#22374;&#36317;&#31163;&#21450;&#22312;&#21345;&#22374;-&#21704;&#36798;&#29595;&#24503;&#27969;&#24418;&#19978;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Sliced-Wasserstein Distances and Flows on Cartan-Hadamard Manifolds
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06560
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#22312;&#21345;&#22374;-&#21704;&#36798;&#29595;&#24503;&#27969;&#24418;&#19978;&#25512;&#23548;&#20102;&#20999;&#29255;-&#21326;&#22622;&#26031;&#22374;&#36317;&#31163;&#30340;&#19968;&#33324;&#26500;&#36896;&#65292;&#25552;&#20986;&#20102;&#19981;&#21516;&#24212;&#29992;&#65292;&#24182;&#19988;&#25512;&#23548;&#20102;&#38750;&#21442;&#25968;&#26041;&#26696;&#20197;&#26368;&#23567;&#21270;&#36825;&#20123;&#26032;&#36317;&#31163;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#34987;&#24320;&#21457;&#25110;&#31227;&#26893;&#21040;&#40654;&#26364;&#27969;&#24418;&#19978;&#65292;&#20197;&#24212;&#23545;&#20855;&#26377;&#24050;&#30693;&#38750;&#27431;&#20960;&#20309;&#32467;&#26500;&#30340;&#25968;&#25454;&#65292;&#22312;&#36825;&#20123;&#31354;&#38388;&#20013;&#23545;&#26368;&#20248;&#36755;&#36816;&#65288;Optimal Transport, OT&#65289;&#26041;&#27861;&#21364;&#27809;&#26377;&#24471;&#21040;&#22826;&#22810;&#20851;&#27880;&#12290;&#22312;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#65292;&#19968;&#31181;&#27969;&#34892;&#30340;&#26367;&#20195;&#26041;&#27861;&#26159;&#20999;&#29255;-&#21326;&#22622;&#26031;&#22374;&#36317;&#31163;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#19968;&#32500;&#21326;&#22622;&#26031;&#22374;&#36317;&#31163;&#30340;&#23553;&#38381;&#24418;&#24335;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#22312;&#27969;&#24418;&#19978;&#26080;&#27861;&#30452;&#25509;&#20351;&#29992;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#21345;&#22374;-&#21704;&#36798;&#29595;&#24503;&#27969;&#24418;&#19978;&#20999;&#29255;-&#21326;&#22622;&#26031;&#22374;&#36317;&#31163;&#30340;&#19968;&#33324;&#26500;&#36896;&#65292;&#36825;&#20123;&#27969;&#24418;&#26159;&#20855;&#26377;&#38750;&#27491;&#26354;&#29575;&#30340;&#40654;&#26364;&#27969;&#24418;&#65292;&#20854;&#20013;&#21253;&#25324;&#20102;&#21452;&#26354;&#31354;&#38388;&#25110;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#31354;&#38388;&#31561;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19981;&#21516;&#30340;&#24212;&#29992;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#38750;&#21442;&#25968;&#26041;&#26696;&#26469;&#26368;&#23567;&#21270;&#36825;&#20123;&#26032;&#36317;&#31163;&#65292;&#36890;&#36807;&#36817;&#20284;&#23427;&#20204;&#30340;&#21326;&#22622;&#26031;&#22374;&#36317;&#31163;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06560v1 Announce Type: new  Abstract: While many Machine Learning methods were developed or transposed on Riemannian manifolds to tackle data with known non Euclidean geometry, Optimal Transport (OT) methods on such spaces have not received much attention. The main OT tool on these spaces is the Wasserstein distance which suffers from a heavy computational burden. On Euclidean spaces, a popular alternative is the Sliced-Wasserstein distance, which leverages a closed-form solution of the Wasserstein distance in one dimension, but which is not readily available on manifolds. In this work, we derive general constructions of Sliced-Wasserstein distances on Cartan-Hadamard manifolds, Riemannian manifolds with non-positive curvature, which include among others Hyperbolic spaces or the space of Symmetric Positive Definite matrices. Then, we propose different applications. Additionally, we derive non-parametric schemes to minimize these new distances by approximating their Wasserste
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#26032;&#26041;&#27861;CLOUD&#65292;&#29992;&#20110;&#20165;&#22522;&#20110;&#35266;&#27979;&#25968;&#25454;&#26816;&#27979;&#26410;&#35266;&#27979;&#21040;&#30340;&#20849;&#21516;&#21407;&#22240;&#65292;&#26080;&#38656;&#23545;&#26410;&#35266;&#27979;&#21464;&#37327;&#30340;&#26041;&#31243;&#27169;&#22411;&#24418;&#24335;&#20570;&#20219;&#20309;&#20551;&#35774;</title><link>https://arxiv.org/abs/2403.06499</link><description>&lt;p&gt;
&#22522;&#20110;NML&#32534;&#30721;&#22312;&#31163;&#25955;&#12289;&#28151;&#21512;&#21644;&#36830;&#32493;&#21464;&#37327;&#20013;&#26816;&#27979;&#26410;&#35266;&#27979;&#21040;&#30340;&#20849;&#21516;&#21407;&#22240;
&lt;/p&gt;
&lt;p&gt;
Detection of Unobserved Common Causes based on NML Code in Discrete, Mixed, and Continuous Variables
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06499
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#26032;&#26041;&#27861;CLOUD&#65292;&#29992;&#20110;&#20165;&#22522;&#20110;&#35266;&#27979;&#25968;&#25454;&#26816;&#27979;&#26410;&#35266;&#27979;&#21040;&#30340;&#20849;&#21516;&#21407;&#22240;&#65292;&#26080;&#38656;&#23545;&#26410;&#35266;&#27979;&#21464;&#37327;&#30340;&#26041;&#31243;&#27169;&#22411;&#24418;&#24335;&#20570;&#20219;&#20309;&#20551;&#35774;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20165;&#22522;&#20110;&#35266;&#27979;&#25968;&#25454;&#20174;&#22240;&#26524;&#21457;&#29616;&#20013;&#26816;&#27979;&#26410;&#35266;&#27979;&#21040;&#30340;&#20849;&#21516;&#21407;&#22240;&#26159;&#19968;&#20010;&#33267;&#20851;&#37325;&#35201;&#20294;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#25152;&#26377;&#21487;&#33021;&#30340;&#22240;&#26524;&#20851;&#31995;&#24402;&#20026;&#22235;&#20010;&#31867;&#21035;&#65292;&#24182;&#26088;&#22312;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#35782;&#21035;&#19968;&#20010;&#65306;&#30452;&#25509;&#22240;&#26524;&#20851;&#31995;&#23384;&#22312;&#30340;&#20004;&#31181;&#24773;&#20917;&#65292;&#21464;&#37327;&#30456;&#20114;&#29420;&#31435;&#30340;&#24773;&#20917;&#65292;&#20197;&#21450;&#21464;&#37327;&#34987;&#28508;&#22312;&#28151;&#26434;&#22240;&#32032;&#25152;&#28151;&#28102;&#30340;&#24773;&#20917;&#12290;&#23613;&#31649;&#24050;&#25552;&#20986;&#20102;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#30340;&#29616;&#26377;&#26041;&#27861;&#65292;&#20294;&#23427;&#20204;&#35201;&#27714;&#26410;&#35266;&#27979;&#21040;&#30340;&#21464;&#37327;&#28385;&#36275;&#20854;&#26041;&#31243;&#27169;&#22411;&#24418;&#24335;&#30340;&#20551;&#35774;&#12290;&#22312;&#25105;&#20204;&#20043;&#21069;&#30340;&#30740;&#31350;&#20013;&#65288;Kobayashi&#31561;&#65292;2022&#24180;&#65289;&#65292;&#39318;&#27425;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#36825;&#20123;&#20551;&#35774;&#30340;&#31163;&#25955;&#25968;&#25454;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#65292;&#21629;&#21517;&#20026;CLOUD&#12290;&#20351;&#29992;&#24402;&#19968;&#21270;&#26368;&#22823;&#20284;&#28982;&#65288;NML&#65289;&#32534;&#30721;&#65292;CLOUD&#20174;&#19968;&#32452;&#20505;&#36873;&#27169;&#22411;&#20013;&#36873;&#25321;&#19968;&#20010;&#29983;&#25104;&#35266;&#27979;&#25968;&#25454;&#26368;&#23567;&#32534;&#30721;&#38271;&#24230;&#30340;&#27169;&#22411;&#12290;&#26412;&#25991;&#23558;CLOUD&#25193;&#23637;&#21040;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06499v1 Announce Type: cross  Abstract: Causal discovery in the presence of unobserved common causes from observational data only is a crucial but challenging problem. We categorize all possible causal relationships between two random variables into the following four categories and aim to identify one from observed data: two cases in which either of the direct causality exists, a case that variables are independent, and a case that variables are confounded by latent confounders. Although existing methods have been proposed to tackle this problem, they require unobserved variables to satisfy assumptions on the form of their equation models. In our previous study (Kobayashi et al., 2022), the first causal discovery method without such assumptions is proposed for discrete data and named CLOUD. Using Normalized Maximum Likelihood (NML) Code, CLOUD selects a model that yields the minimum codelength of the observed data from a set of model candidates. This paper extends CLOUD to 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26694;&#26550;&#65292;&#26681;&#25454;&#29305;&#24449;&#19982;&#26631;&#31614;&#30340;&#30456;&#20851;&#24615;&#26041;&#24046;&#26469;&#21306;&#20998;&#29305;&#24449;&#30340;&#25928;&#29992;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#23398;&#20064;&#36807;&#31243;&#65292;&#20174;&#28304;&#20219;&#21153;&#23398;&#20064;&#21040;&#22823;&#33268;&#20849;&#20139;&#30340;&#29305;&#24449;&#34920;&#31034;&#65292;&#24182;&#22312;&#30446;&#26631;&#20219;&#21153;&#19978;&#36827;&#34892;&#24494;&#35843;&#65292;&#20197;&#20248;&#21270;&#24635;&#20307;&#39118;&#38505;&#12290;</title><link>https://arxiv.org/abs/2403.06424</link><description>&lt;p&gt;
&#36890;&#36807;&#22823;&#33268;&#20849;&#20139;&#29305;&#24449;&#26469;&#23454;&#29616;&#39046;&#22495;&#20043;&#38388;&#30340;&#26725;&#26753;
&lt;/p&gt;
&lt;p&gt;
Bridging Domains with Approximately Shared Features
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06424
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26694;&#26550;&#65292;&#26681;&#25454;&#29305;&#24449;&#19982;&#26631;&#31614;&#30340;&#30456;&#20851;&#24615;&#26041;&#24046;&#26469;&#21306;&#20998;&#29305;&#24449;&#30340;&#25928;&#29992;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#23398;&#20064;&#36807;&#31243;&#65292;&#20174;&#28304;&#20219;&#21153;&#23398;&#20064;&#21040;&#22823;&#33268;&#20849;&#20139;&#30340;&#29305;&#24449;&#34920;&#31034;&#65292;&#24182;&#22312;&#30446;&#26631;&#20219;&#21153;&#19978;&#36827;&#34892;&#24494;&#35843;&#65292;&#20197;&#20248;&#21270;&#24635;&#20307;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#28304;&#39046;&#22495;&#36866;&#24212;&#26088;&#22312;&#22312;&#23558;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#24212;&#29992;&#20110;&#26410;&#30693;&#39046;&#22495;&#26102;&#38477;&#20302;&#24615;&#33021;&#19979;&#38477;&#12290;&#19968;&#20010;&#22522;&#26412;&#25361;&#25112;&#26159;&#35774;&#35745;&#29305;&#24449;&#36873;&#25321;&#30340;&#26368;&#20339;&#31574;&#30053;&#12290;&#29616;&#26377;&#25991;&#29486;&#22312;&#26576;&#31181;&#31243;&#24230;&#19978;&#23384;&#22312;&#24726;&#35770;&#65306;&#26377;&#20123;&#20154;&#20027;&#24352;&#20174;&#28304;&#39046;&#22495;&#23398;&#20064;&#19981;&#21464;&#29305;&#24449;&#65292;&#32780;&#21478;&#19968;&#20123;&#20154;&#21017;&#26356;&#38738;&#30544;&#22810;&#26679;&#21270;&#29305;&#24449;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#35745;&#26694;&#26550;&#65292;&#26681;&#25454;&#23427;&#20204;&#19982;&#26631;&#31614; $y$ &#30340;&#30456;&#20851;&#24615;&#30340;&#26041;&#24046;&#26469;&#21306;&#20998;&#29305;&#24449;&#30340;&#25928;&#29992;&#12290;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#35774;&#35745;&#21644;&#20998;&#26512;&#20102;&#19968;&#20010;&#23398;&#20064;&#36807;&#31243;&#65292;&#35813;&#36807;&#31243;&#30001;&#20174;&#28304;&#20219;&#21153;&#23398;&#20064;&#21040;&#30340;&#22823;&#33268;&#20849;&#20139;&#29305;&#24449;&#34920;&#31034;&#65292;&#24182;&#22312;&#30446;&#26631;&#20219;&#21153;&#19978;&#36827;&#34892;&#24494;&#35843;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#38656;&#35201;&#23398;&#20064;&#22823;&#33268;&#20849;&#20139;&#29305;&#24449;&#30340;&#37325;&#35201;&#24615;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#20005;&#26684;&#19981;&#21464;&#30340;&#29305;&#24449;&#65292;&#24182;&#19988;&#30456;&#23545;&#20110;&#20197;&#21069;&#20851;&#20110;&#28304;&#39046;&#22495;&#36866;&#24212;&#24615;&#30340;&#32467;&#26524;&#32780;&#35328;&#65292;&#20135;&#29983;&#20102;&#25913;&#36827;&#30340;&#24635;&#20307;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06424v1 Announce Type: cross  Abstract: Multi-source domain adaptation aims to reduce performance degradation when applying machine learning models to unseen domains. A fundamental challenge is devising the optimal strategy for feature selection. Existing literature is somewhat paradoxical: some advocate for learning invariant features from source domains, while others favor more diverse features. To address the challenge, we propose a statistical framework that distinguishes the utilities of features based on the variance of their correlation to label $y$ across domains. Under our framework, we design and analyze a learning procedure consisting of learning approximately shared feature representation from source tasks and fine-tuning it on the target task. Our theoretical analysis necessitates the importance of learning approximately shared features instead of only the strictly invariant features and yields an improved population risk compared to previous results on both sou
&lt;/p&gt;</description></item><item><title>&#22810;&#27169;&#24577;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#22312;&#35299;&#24320;&#20849;&#20139;&#21644;&#31169;&#26377;&#28508;&#22312;&#22240;&#32032;&#26041;&#38754;&#30340;&#33021;&#21147;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#24182;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#26041;&#27861;&#20197;&#22686;&#24378;&#23545;&#29305;&#23450;&#27169;&#24577;&#21464;&#21270;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.06338</link><description>&lt;p&gt;
&#22312;&#22810;&#27169;&#24335;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#20013;&#35299;&#24320;&#20849;&#20139;&#21644;&#31169;&#26377;&#28508;&#22312;&#22240;&#32032;
&lt;/p&gt;
&lt;p&gt;
Disentangling shared and private latent factors in multimodal Variational Autoencoders
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06338
&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#22312;&#35299;&#24320;&#20849;&#20139;&#21644;&#31169;&#26377;&#28508;&#22312;&#22240;&#32032;&#26041;&#38754;&#30340;&#33021;&#21147;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#24182;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#26041;&#27861;&#20197;&#22686;&#24378;&#23545;&#29305;&#23450;&#27169;&#24577;&#21464;&#21270;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#25968;&#25454;&#30340;&#29983;&#25104;&#27169;&#22411;&#21487;&#20197;&#30830;&#23450;&#21487;&#33021;&#19982;&#35266;&#27979;&#25968;&#25454;&#24322;&#36136;&#24615;&#30340;&#37325;&#35201;&#20915;&#23450;&#22240;&#32032;&#30456;&#20851;&#32852;&#30340;&#28508;&#22312;&#22240;&#32032;&#12290;&#20849;&#20139;&#22240;&#32032;&#21487;&#20197;&#29992;&#20110;&#35299;&#37322;&#36328;&#27169;&#24577;&#30340;&#21464;&#21270;&#65292;&#32780;&#20854;&#20182;&#22240;&#32032;&#21487;&#33021;&#26159;&#31169;&#26377;&#30340;&#65292;&#20165;&#29992;&#20110;&#35299;&#37322;&#21333;&#20010;&#27169;&#24577;&#12290;&#22810;&#27169;&#24577;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#22914;MVAE&#21644;MMVAE&#65292;&#26159;&#25512;&#26029;&#36825;&#20123;&#28508;&#22312;&#28508;&#22240;&#32032;&#24182;&#23558;&#20849;&#20139;&#21464;&#24322;&#19982;&#31169;&#26377;&#21464;&#24322;&#20998;&#31163;&#30340;&#33258;&#28982;&#36873;&#25321;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#23427;&#20204;&#21487;&#38752;&#25191;&#34892;&#27492;&#35299;&#32544;&#30340;&#33021;&#21147;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#35774;&#32622;&#65292;&#20854;&#20013;&#29305;&#23450;&#20110;&#27169;&#24577;&#30340;&#21464;&#24322;&#25903;&#37197;&#20102;&#20849;&#20139;&#20449;&#21495;&#12290;&#37319;&#29992;&#20132;&#21449;&#27169;&#24577;&#39044;&#27979;&#30340;&#35270;&#35282;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#29616;&#26377;&#27169;&#22411;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#26041;&#27861;&#65292;&#20351;&#23427;&#20204;&#23545;&#29305;&#23450;&#20110;&#27169;&#24577;&#30340;&#21464;&#24322;&#26356;&#21152;&#31283;&#20581;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#24471;&#21040;&#20102;&#23454;&#39564;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06338v1 Announce Type: cross  Abstract: Generative models for multimodal data permit the identification of latent factors that may be associated with important determinants of observed data heterogeneity. Common or shared factors could be important for explaining variation across modalities whereas other factors may be private and important only for the explanation of a single modality. Multimodal Variational Autoencoders, such as MVAE and MMVAE, are a natural choice for inferring those underlying latent factors and separating shared variation from private. In this work, we investigate their capability to reliably perform this disentanglement. In particular, we highlight a challenging problem setting where modality-specific variation dominates the shared signal. Taking a cross-modal prediction perspective, we demonstrate limitations of existing models, and propose a modification how to make them more robust to modality-specific variation. Our findings are supported by experi
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#32771;&#34385;&#27599;&#20010;&#31867;&#21035;&#30340;&#35757;&#32451;&#26679;&#26412;&#25968;&#37327;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#24635;&#20307;&#35757;&#32451;&#26679;&#26412;&#25968;&#37327;&#65292;&#26469;&#39044;&#27979;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#27169;&#22411;&#24615;&#33021;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31354;&#38388;&#22635;&#20805;&#35774;&#35745;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#23545; CIFAR10 &#21644; EMNIST &#25968;&#25454;&#38598;&#36827;&#34892;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2403.06311</link><description>&lt;p&gt;
&#20320;&#38656;&#35201;&#22810;&#23569;&#25968;&#25454;&#65311;&#31532;&#20108;&#37096;&#20998;&#65306;&#39044;&#27979;&#28145;&#24230;&#23398;&#20064;&#31867;&#29305;&#23450;&#35757;&#32451;&#25968;&#25454;&#38598;&#22823;&#23567;
&lt;/p&gt;
&lt;p&gt;
How much data do you need? Part 2: Predicting DL class specific training dataset sizes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06311
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#32771;&#34385;&#27599;&#20010;&#31867;&#21035;&#30340;&#35757;&#32451;&#26679;&#26412;&#25968;&#37327;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#24635;&#20307;&#35757;&#32451;&#26679;&#26412;&#25968;&#37327;&#65292;&#26469;&#39044;&#27979;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#27169;&#22411;&#24615;&#33021;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31354;&#38388;&#22635;&#20805;&#35774;&#35745;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#23545; CIFAR10 &#21644; EMNIST &#25968;&#25454;&#38598;&#36827;&#34892;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#30740;&#31350;&#22312;&#32771;&#34385;&#27599;&#20010;&#31867;&#21035;&#30340;&#35757;&#32451;&#26679;&#26412;&#25968;&#37327;&#32780;&#19981;&#20165;&#20165;&#26159;&#24635;&#20307;&#35757;&#32451;&#26679;&#26412;&#25968;&#37327;&#26102;&#65292;&#39044;&#27979;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#27169;&#22411;&#24615;&#33021;&#30340;&#38382;&#39064;&#12290;&#36825;&#24102;&#26469;&#20102;&#19968;&#20010;&#32452;&#21512;&#38382;&#39064;&#65292;&#21363;&#22312;&#32473;&#23450;&#22266;&#23450;&#24635;&#20307;&#35757;&#32451;&#25968;&#25454;&#38598;&#22823;&#23567;&#30340;&#24773;&#20917;&#19979;&#65292;&#24212;&#32771;&#34385;&#21738;&#20123;&#27599;&#20010;&#31867;&#30340;&#35757;&#32451;&#26679;&#26412;&#25968;&#37327;&#32452;&#21512;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21463;&#21040;&#23454;&#39564;&#35774;&#35745;&#20013;&#30340;&#31354;&#38388;&#22635;&#28385;&#35774;&#35745;&#30340;&#29305;&#27530;&#24773;&#20917;&#30340;&#21551;&#21457;&#12290;&#29983;&#25104;&#30340;&#25968;&#25454;&#20351;&#29992;&#35832;&#22914;&#24130;&#24459;&#26354;&#32447;&#21644;&#31867;&#20284;&#27169;&#22411;&#12289;&#25193;&#23637;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#31561;&#27169;&#22411;&#26469;&#36827;&#34892;&#24314;&#27169;&#65292;&#21363;&#36890;&#36807;&#23558;&#24635;&#20307;&#35757;&#32451;&#25968;&#25454;&#38598;&#22823;&#23567;&#26367;&#25442;&#20026;&#32473;&#23450;&#26631;&#31614;&#31867;&#21035;&#30340;&#35757;&#32451;&#26679;&#26412;&#25968;&#37327;&#30340;&#21442;&#25968;&#21270;&#32447;&#24615;&#32452;&#21512;&#12290;&#35813;&#31639;&#27861;&#24050;&#24212;&#29992;&#20110;CIFAR10&#21644;EMNIST&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06311v1 Announce Type: new  Abstract: This paper targets the question of predicting machine learning classification model performance, when taking into account the number of training examples per class and not just the overall number of training examples. This leads to the a combinatorial question, which combinations of number of training examples per class should be considered, given a fixed overall training dataset size. In order to solve this question, an algorithm is suggested which is motivated from special cases of space filling design of experiments. The resulting data are modeled using models like powerlaw curves and similar models, extended like generalized linear models i.e. by replacing the overall training dataset size by a parametrized linear combination of the number of training examples per label class. The proposed algorithm has been applied on the CIFAR10 and the EMNIST datasets.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26679;&#26465;&#30340;&#38750;&#21442;&#25968;&#36924;&#36817;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#22797;&#26434;&#32467;&#26500;&#20998;&#24067;&#30340;&#28789;&#27963;&#21518;&#39564;&#36924;&#36817;&#65292;&#25552;&#39640;&#20102;&#29983;&#25104;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.06302</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;&#33258;&#21160;&#24494;&#20998;&#21464;&#20998;&#25512;&#26029;&#19982;&#26679;&#26465;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Nonparametric Automatic Differentiation Variational Inference with Spline Approximation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06302
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26679;&#26465;&#30340;&#38750;&#21442;&#25968;&#36924;&#36817;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#22797;&#26434;&#32467;&#26500;&#20998;&#24067;&#30340;&#28789;&#27963;&#21518;&#39564;&#36924;&#36817;&#65292;&#25552;&#39640;&#20102;&#29983;&#25104;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#24494;&#20998;&#21464;&#20998;&#25512;&#26029;&#65288;ADVI&#65289;&#22312;&#23398;&#20064;&#27010;&#29575;&#27169;&#22411;&#26041;&#38754;&#24456;&#26377;&#25928;&#12290;&#32463;&#20856;ADVI&#20381;&#36182;&#20110;&#21442;&#25968;&#21270;&#26041;&#27861;&#26469;&#36924;&#36817;&#21518;&#39564;&#20998;&#24067;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26679;&#26465;&#30340;&#38750;&#21442;&#25968;&#36924;&#36817;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#20855;&#26377;&#22797;&#26434;&#32467;&#26500;&#30340;&#20998;&#24067;&#65288;&#22914;&#20559;&#24230;&#12289;&#22810;&#23792;&#24615;&#21644;&#26377;&#30028;&#25903;&#25345;&#65289;&#30340;&#28789;&#27963;&#21518;&#39564;&#36924;&#36817;&#12290;&#19982;&#24191;&#27867;&#20351;&#29992;&#30340;&#38750;&#21442;&#25968;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#30456;&#27604;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#26131;&#20110;&#23454;&#29616;&#65292;&#24182;&#36866;&#24212;&#21508;&#31181;&#25968;&#25454;&#32467;&#26500;&#12290;&#36890;&#36807;&#37319;&#29992;&#26679;&#26465;&#36924;&#36817;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#37325;&#35201;&#24615;&#21152;&#26435;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#19968;&#20010;&#19979;&#30028;&#65292;&#24182;&#30830;&#31435;&#20102;&#28176;&#36817;&#19968;&#33268;&#24615;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#22312;&#36924;&#36817;&#22797;&#26434;&#21518;&#39564;&#20998;&#24067;&#21644;&#25913;&#21892;&#20855;&#26377;&#19981;&#23436;&#20840;&#25968;&#25454;&#30340;&#29983;&#25104;&#27169;&#22411;&#24615;&#33021;&#26041;&#38754;&#30340;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06302v1 Announce Type: cross  Abstract: Automatic Differentiation Variational Inference (ADVI) is efficient in learning probabilistic models. Classic ADVI relies on the parametric approach to approximate the posterior. In this paper, we develop a spline-based nonparametric approximation approach that enables flexible posterior approximation for distributions with complicated structures, such as skewness, multimodality, and bounded support. Compared with widely-used nonparametric variational inference methods, the proposed method is easy to implement and adaptive to various data structures. By adopting the spline approximation, we derive a lower bound of the importance weighted autoencoder and establish the asymptotic consistency. Experiments demonstrate the efficiency of the proposed method in approximating complex posterior distributions and improving the performance of generative models with incomplete data.
&lt;/p&gt;</description></item><item><title>PNCs&#23558;&#27010;&#29575;&#30005;&#36335;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#29305;&#28857;&#32467;&#21512;&#36215;&#26469;&#65292;&#21487;&#20197;&#35299;&#37322;&#20026;&#28145;&#23618;&#28151;&#21512;&#30340;&#36125;&#21494;&#26031;&#32593;&#32476;&#65292;&#21516;&#26102;&#20316;&#20026;&#24378;&#22823;&#30340;&#20989;&#25968;&#36924;&#36817;&#22120;&#12290;</title><link>https://arxiv.org/abs/2403.06235</link><description>&lt;p&gt;
&#27010;&#29575;&#31070;&#32463;&#30005;&#36335;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Neural Circuits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06235
&lt;/p&gt;
&lt;p&gt;
PNCs&#23558;&#27010;&#29575;&#30005;&#36335;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#29305;&#28857;&#32467;&#21512;&#36215;&#26469;&#65292;&#21487;&#20197;&#35299;&#37322;&#20026;&#28145;&#23618;&#28151;&#21512;&#30340;&#36125;&#21494;&#26031;&#32593;&#32476;&#65292;&#21516;&#26102;&#20316;&#20026;&#24378;&#22823;&#30340;&#20989;&#25968;&#36924;&#36817;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27010;&#29575;&#30005;&#36335;&#65288;PCs&#65289;&#36817;&#24180;&#26469;&#20316;&#20026;&#19968;&#20010;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#25506;&#35752;&#25903;&#25345;&#21487;&#22788;&#29702;&#26597;&#35810;&#19988;&#36275;&#22815;&#34920;&#36798;&#22797;&#26434;&#27010;&#29575;&#20998;&#24067;&#30340;&#27010;&#29575;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#21487;&#22788;&#29702;&#24615;&#26159;&#26377;&#20195;&#20215;&#30340;&#65306;PCs&#27604;&#31070;&#32463;&#32593;&#32476;&#34920;&#36798;&#33021;&#21147;&#26356;&#24369;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#27010;&#29575;&#31070;&#32463;&#30005;&#36335;&#65288;PNCs&#65289;&#65292;&#22312;&#21487;&#22788;&#29702;&#24615;&#21644;&#34920;&#36798;&#33021;&#21147;&#26041;&#38754;&#22312;PCs&#21644;&#31070;&#32463;&#32593;&#32476;&#20043;&#38388;&#21462;&#24471;&#20102;&#24179;&#34913;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;PNCs&#21487;&#20197;&#34987;&#35299;&#37322;&#20026;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#28145;&#24230;&#28151;&#21512;&#12290;&#23454;&#39564;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;PNCs&#26500;&#25104;&#20102;&#24378;&#22823;&#30340;&#20989;&#25968;&#36924;&#36817;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06235v1 Announce Type: cross  Abstract: Probabilistic circuits (PCs) have gained prominence in recent years as a versatile framework for discussing probabilistic models that support tractable queries and are yet expressive enough to model complex probability distributions. Nevertheless, tractability comes at a cost: PCs are less expressive than neural networks. In this paper we introduce probabilistic neural circuits (PNCs), which strike a balance between PCs and neural nets in terms of tractability and expressive power. Theoretically, we show that PNCs can be interpreted as deep mixtures of Bayesian networks. Experimentally, we demonstrate that PNCs constitute powerful function approximators.
&lt;/p&gt;</description></item><item><title>LinearAPT&#31639;&#27861;&#26159;&#19968;&#31181;&#20026;&#22266;&#23450;&#39044;&#31639;&#35774;&#32622;&#30340;&#38408;&#20540;&#32447;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#32780;&#35774;&#35745;&#30340;&#26032;&#31639;&#27861;&#65292;&#20855;&#26377;&#36866;&#24212;&#24615;&#12289;&#31616;&#21333;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#65292;&#24182;&#22312;&#20248;&#21270;&#39034;&#24207;&#20915;&#31574;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>https://arxiv.org/abs/2403.06230</link><description>&lt;p&gt;
LinearAPT: &#19968;&#31181;&#29992;&#20110;&#22266;&#23450;&#39044;&#31639;&#38408;&#20540;&#32447;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#33258;&#36866;&#24212;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
LinearAPT: An Adaptive Algorithm for the Fixed-Budget Thresholding Linear Bandit Problem
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06230
&lt;/p&gt;
&lt;p&gt;
LinearAPT&#31639;&#27861;&#26159;&#19968;&#31181;&#20026;&#22266;&#23450;&#39044;&#31639;&#35774;&#32622;&#30340;&#38408;&#20540;&#32447;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#32780;&#35774;&#35745;&#30340;&#26032;&#31639;&#27861;&#65292;&#20855;&#26377;&#36866;&#24212;&#24615;&#12289;&#31616;&#21333;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#65292;&#24182;&#22312;&#20248;&#21270;&#39034;&#24207;&#20915;&#31574;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#28145;&#20837;&#25506;&#35752;&#20102;&#38408;&#20540;&#32447;&#24615;&#36172;&#21338;&#26426;&#65288;TLB&#65289;&#38382;&#39064;&#65292;&#36825;&#26159;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#20013;&#30340;&#19968;&#20010;&#24494;&#22937;&#39046;&#22495;&#65292;&#37325;&#28857;&#26159;&#22312;&#36164;&#28304;&#32422;&#26463;&#19979;&#26368;&#22823;&#21270;&#38024;&#23545;&#32447;&#24615;&#23450;&#20041;&#38408;&#20540;&#30340;&#20915;&#31574;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;LinearAPT&#65292;&#36825;&#26159;&#19968;&#31181;&#20026;TLB&#30340;&#22266;&#23450;&#39044;&#31639;&#35774;&#32622;&#32780;&#35774;&#35745;&#30340;&#26032;&#39062;&#31639;&#27861;&#65292;&#20026;&#20248;&#21270;&#39034;&#24207;&#20915;&#31574;&#25552;&#20379;&#20102;&#39640;&#25928;&#35299;&#20915;&#26041;&#26696;&#12290;&#35813;&#31639;&#27861;&#19981;&#20165;&#20026;&#20272;&#35745;&#25439;&#22833;&#25552;&#20379;&#20102;&#29702;&#35770;&#19978;&#30028;&#65292;&#32780;&#19988;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#31361;&#20986;&#20102;LinearAPT&#30340;&#36866;&#24212;&#24615;&#12289;&#31616;&#21333;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#65292;&#20351;&#20854;&#25104;&#20026;&#35299;&#20915;&#22797;&#26434;&#39034;&#24207;&#20915;&#31574;&#25361;&#25112;&#30340;&#26377;&#20215;&#20540;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06230v1 Announce Type: new  Abstract: In this study, we delve into the Thresholding Linear Bandit (TLB) problem, a nuanced domain within stochastic Multi-Armed Bandit (MAB) problems, focusing on maximizing decision accuracy against a linearly defined threshold under resource constraints. We present LinearAPT, a novel algorithm designed for the fixed budget setting of TLB, providing an efficient solution to optimize sequential decision-making. This algorithm not only offers a theoretical upper bound for estimated loss but also showcases robust performance on both synthetic and real-world datasets. Our contributions highlight the adaptability, simplicity, and computational efficiency of LinearAPT, making it a valuable addition to the toolkit for addressing complex sequential decision-making challenges.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20808;&#21069;&#25193;&#25955;&#25216;&#26415;&#23545;&#28385;&#36275;&#23545;&#25968;Sobolev&#19981;&#31561;&#24335;&#30340;&#30446;&#26631;&#20998;&#24067;&#30340;&#20316;&#29992;&#65292;&#25193;&#23637;&#20102;&#20808;&#21069;&#20165;&#38024;&#23545;&#24378;&#23545;&#25968;&#20985;&#20998;&#24067;&#30340;&#30456;&#20851;&#24037;&#20316;&#12290;</title><link>https://arxiv.org/abs/2403.06183</link><description>&lt;p&gt;
&#20855;&#26377;&#20808;&#21069;&#25193;&#25955;&#30340;&#20848;&#22522;&#25991;&#31639;&#27861;&#22312;&#38750;&#23545;&#25968;&#20985;&#25277;&#26679;&#20013;&#30340;&#25913;&#36827;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
An Improved Analysis of Langevin Algorithms with Prior Diffusion for Non-Log-Concave Sampling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06183
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20808;&#21069;&#25193;&#25955;&#25216;&#26415;&#23545;&#28385;&#36275;&#23545;&#25968;Sobolev&#19981;&#31561;&#24335;&#30340;&#30446;&#26631;&#20998;&#24067;&#30340;&#20316;&#29992;&#65292;&#25193;&#23637;&#20102;&#20808;&#21069;&#20165;&#38024;&#23545;&#24378;&#23545;&#25968;&#20985;&#20998;&#24067;&#30340;&#30456;&#20851;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#25277;&#26679;&#38382;&#39064;&#20013;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#30340;&#32500;&#24230;&#30456;&#20851;&#24615;&#26159;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#65292;&#26080;&#35770;&#26159;&#20174;&#23454;&#38469;&#36824;&#26159;&#29702;&#35770;&#30340;&#35282;&#24230;&#26469;&#30475;&#12290;&#30456;&#23545;&#20110;&#20855;&#26377;&#26080;&#20559;&#31283;&#24577;&#20998;&#24067;&#30340;&#25277;&#26679;&#22120;&#65292;&#22914;Metropolis-adjusted Langevin algorithm (MALA)&#65292;&#20855;&#26377;&#20559;&#32622;&#31283;&#24577;&#20998;&#24067;&#30340;&#25277;&#26679;&#22120;&#65292;&#22914;Underdamped Langevin Dynamics (ULD)&#65292;&#22312;&#20302;&#20934;&#30830;&#24230;&#24773;&#20917;&#19979;&#34920;&#29616;&#26356;&#22909;&#65292;&#20165;&#20165;&#22240;&#20026;&#23427;&#20204;&#30340;&#22797;&#26434;&#24230;&#23545;&#32500;&#24230;&#30340;&#20381;&#36182;&#24615;&#26356;&#20302;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;Freund&#31561;&#20154;(2022)&#25552;&#20986;&#65292;&#20855;&#26377;&#20808;&#21069;&#25193;&#25955;&#30340;&#20462;&#25913;&#20848;&#22522;&#25991;&#31639;&#27861;&#33021;&#22815;&#32500;&#24230;&#29420;&#31435;&#22320;&#25910;&#25947;&#20110;&#24378;&#23545;&#25968;&#20985;&#30446;&#26631;&#20998;&#24067;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#26356;&#19968;&#33324;&#30340;&#24773;&#20917;&#26159;&#21542;&#23384;&#22312;&#36825;&#26679;&#30340;&#24615;&#36136;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20043;&#35868;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#23545;&#28385;&#36275;&#23545;&#25968;Sobolev&#19981;&#31561;&#24335;&#65288;LSI&#65289;&#30340;&#30446;&#26631;&#20998;&#24067;&#30340;&#20808;&#21069;&#25193;&#25955;&#25216;&#26415;&#65292;&#35813;&#25216;&#26415;&#35206;&#30422;&#20102;&#27604;&#24378;&#23545;&#25968;&#20985;&#20998;&#24067;&#26356;&#24191;&#27867;&#30340;&#20998;&#24067;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06183v1 Announce Type: new  Abstract: Understanding the dimension dependency of computational complexity in high-dimensional sampling problem is a fundamental problem, both from a practical and theoretical perspective. Compared with samplers with unbiased stationary distribution, e.g., Metropolis-adjusted Langevin algorithm (MALA), biased samplers, e.g., Underdamped Langevin Dynamics (ULD), perform better in low-accuracy cases just because a lower dimension dependency in their complexities. Along this line, Freund et al. (2022) suggest that the modified Langevin algorithm with prior diffusion is able to converge dimension independently for strongly log-concave target distributions. Nonetheless, it remains open whether such property establishes for more general cases. In this paper, we investigate the prior diffusion technique for the target distributions satisfying log-Sobolev inequality (LSI), which covers a much broader class of distributions compared to the strongly log-c
&lt;/p&gt;</description></item><item><title>ALL0CORE&#26159;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#38750;&#36127;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;&#65292;&#23427;&#22312;&#20445;&#25345;&#35745;&#31639;&#21487;&#22788;&#29702;&#24615;&#30340;&#22522;&#30784;&#19978;&#21033;&#29992;Tucker&#20998;&#35299;&#30340;&#28508;&#22312;&#32467;&#26500;&#65292;&#21487;&#20197;&#20165;&#20351;&#29992;&#26680;&#30340;&#24494;&#23567;&#37096;&#20998;&#21363;&#36798;&#21040;&#19982;&#23436;&#25972;Tucker&#20998;&#35299;&#30456;&#21516;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.06153</link><description>&lt;p&gt;
ALL0CORE&#24352;&#37327;&#20998;&#35299;&#29992;&#20110;&#31232;&#30095;&#35745;&#25968;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
The ALL0CORE Tensor Decomposition for Sparse Count Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06153
&lt;/p&gt;
&lt;p&gt;
ALL0CORE&#26159;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#38750;&#36127;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;&#65292;&#23427;&#22312;&#20445;&#25345;&#35745;&#31639;&#21487;&#22788;&#29702;&#24615;&#30340;&#22522;&#30784;&#19978;&#21033;&#29992;Tucker&#20998;&#35299;&#30340;&#28508;&#22312;&#32467;&#26500;&#65292;&#21487;&#20197;&#20165;&#20351;&#29992;&#26680;&#30340;&#24494;&#23567;&#37096;&#20998;&#21363;&#36798;&#21040;&#19982;&#23436;&#25972;Tucker&#20998;&#35299;&#30456;&#21516;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;ALL0CORE&#65292;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#38750;&#36127;&#24352;&#37327;&#20998;&#35299;&#24418;&#24335;&#12290;ALL0CORE&#26159;&#19968;&#31181;Tucker&#20998;&#35299;&#65292;&#20854;&#20013;&#26680;&#24352;&#37327;&#30340;&#38750;&#38646;&#20803;&#32032;&#25968;&#37327;&#65288;&#21363;L0&#33539;&#25968;&#65289;&#34987;&#38480;&#21046;&#20026;&#36828;&#23567;&#20110;&#26680;&#30340;&#22823;&#23567;&#30340;&#39044;&#35774;&#20540;Q&#12290;&#34429;&#28982;&#29992;&#25143;&#35268;&#23450;&#20102;&#24635;&#39044;&#31639;Q&#65292;&#20294;&#38750;&#38646;&#20803;&#32032;&#30340;&#20301;&#32622;&#21644;&#20540;&#26159;&#28508;&#22312;&#21464;&#37327;&#65292;&#22312;&#25512;&#26029;&#36807;&#31243;&#20013;&#20998;&#37197;&#32473;&#26680;&#24352;&#37327;&#30340;&#21508;&#20010;&#37096;&#20998;&#12290;ALL0CORE&#65292;&#21363;&#20998;&#37197;&#30340;L0&#32422;&#26463;&#26680;&#65292;&#22240;&#27492;&#26082;&#20855;&#26377;CP&#20998;&#35299;&#30340;&#35745;&#31639;&#21487;&#22788;&#29702;&#24615;&#65292;&#21448;&#20855;&#26377;Tucker&#30340;&#28508;&#22312;&#32467;&#26500;&#65292;&#20196;&#20154;&#28385;&#24847;&#12290;&#22312;&#19968;&#31995;&#21015;&#30495;&#23454;&#25968;&#25454;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;ALL0CORE&#36890;&#24120;&#21482;&#38656;&#20351;&#29992;&#26680;&#30340;&#24494;&#23567;&#37096;&#20998;&#65288;&#20363;&#22914;&#65374;1%&#65289;&#21363;&#21487;&#20197;&#19982;&#23436;&#25972;Tucker&#20998;&#35299;&#30456;&#21516;&#30340;&#32467;&#26524;&#65292;&#32780;&#25104;&#26412;&#20165;&#30456;&#24212;&#30340;&#19968;&#23567;&#37096;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06153v1 Announce Type: cross  Abstract: This paper introduces ALL0CORE, a new form of probabilistic non-negative tensor decomposition. ALL0CORE is a Tucker decomposition where the number of non-zero elements (i.e., the L0-norm) of the core tensor is constrained to a preset value Q much smaller than the size of the core. While the user dictates the total budget Q, the locations and values of the non-zero elements are latent variables and allocated across the core tensor during inference. ALL0CORE -- i.e., allocated L0-constrained core -- thus enjoys both the computational tractability of CP decomposition and the qualitatively appealing latent structure of Tucker. In a suite of real-data experiments, we demonstrate that ALL0CORE typically requires only tiny fractions (e.g.,~1%) of the full core to achieve the same results as full Tucker decomposition at only a correspondingly tiny fraction of the cost.
&lt;/p&gt;</description></item><item><title>&#22312;&#20247;&#21253;&#29615;&#22659;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#20248;&#21270;&#26041;&#27861;&#65292;&#21033;&#29992;&#22312;&#32447;&#23398;&#20064;&#23545;&#37197;&#23545;&#32452;&#21512;&#21644;&#35780;&#20272;&#37327;&#36827;&#34892;&#20248;&#21270;&#65292;&#23454;&#29616;&#22522;&#20110;&#21916;&#22909;&#30340;&#20027;&#35266;&#35780;&#20272;&#30340;&#35774;&#35745;&#20248;&#21270;&#12290;</title><link>https://arxiv.org/abs/2403.06100</link><description>&lt;p&gt;
&#22312;&#20247;&#21253;&#29615;&#22659;&#20013;&#21033;&#29992;&#22312;&#32447;&#23398;&#20064;&#36827;&#34892;&#22522;&#20110;&#21916;&#22909;&#30340;&#20027;&#35266;&#35780;&#20272;&#35774;&#35745;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Automatic design optimization of preference-based subjective evaluation with online learning in crowdsourcing environment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06100
&lt;/p&gt;
&lt;p&gt;
&#22312;&#20247;&#21253;&#29615;&#22659;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#20248;&#21270;&#26041;&#27861;&#65292;&#21033;&#29992;&#22312;&#32447;&#23398;&#20064;&#23545;&#37197;&#23545;&#32452;&#21512;&#21644;&#35780;&#20272;&#37327;&#36827;&#34892;&#20248;&#21270;&#65292;&#23454;&#29616;&#22522;&#20110;&#21916;&#22909;&#30340;&#20027;&#35266;&#35780;&#20272;&#30340;&#35774;&#35745;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#21916;&#22909;&#30340;&#20027;&#35266;&#35780;&#20272;&#26159;&#35780;&#20215;&#29983;&#25104;&#24335;&#23186;&#20307;&#21487;&#38752;&#24615;&#30340;&#20851;&#38190;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#20854;&#24222;&#22823;&#30340;&#37197;&#23545;&#32452;&#21512;&#20351;&#24471;&#23427;&#26080;&#27861;&#24212;&#29992;&#20110;&#21033;&#29992;&#20247;&#21253;&#36827;&#34892;&#22823;&#35268;&#27169;&#35780;&#20272;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#20247;&#21253;&#29615;&#22659;&#20013;&#36827;&#34892;&#22522;&#20110;&#21916;&#22909;&#30340;&#20027;&#35266;&#35780;&#20272;&#30340;&#33258;&#21160;&#20248;&#21270;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#28041;&#21450;&#23545;&#37197;&#23545;&#32452;&#21512;&#36873;&#25321;&#21644;&#35780;&#20272;&#37327;&#20998;&#37197;&#30340;&#22312;&#32447;&#23398;&#20064;&#12290;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#25490;&#24207;&#31639;&#27861;&#30340;&#22522;&#20110;&#21916;&#22909;&#30340;&#22312;&#32447;&#23398;&#20064;&#26041;&#27861;&#26469;&#35782;&#21035;&#20855;&#26377;&#26368;&#23567;&#26679;&#26412;&#37327;&#30340;&#35780;&#20272;&#30446;&#26631;&#30340;&#23436;&#20840;&#39034;&#24207;&#12290;&#25105;&#20204;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#25903;&#25345;&#22312;&#20247;&#21253;&#25152;&#38656;&#30340;&#22266;&#23450;&#39044;&#31639;&#26465;&#20214;&#19979;&#30340;&#24182;&#34892;&#21644;&#24322;&#27493;&#25191;&#34892;&#12290;&#25105;&#20204;&#23545;&#21512;&#25104;&#35821;&#38899;&#30340;&#22522;&#20110;&#21916;&#22909;&#30340;&#20027;&#35266;&#35780;&#20272;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#25104;&#21151;&#36890;&#36807;&#23558;&#37197;&#23545;&#32452;&#21512;&#20174;351&#20943;&#23569;&#21040;83&#24182;&#20998;&#37197;&#26368;&#20248;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06100v1 Announce Type: cross  Abstract: A preference-based subjective evaluation is a key method for evaluating generative media reliably. However, its huge combinations of pairs prohibit it from being applied to large-scale evaluation using crowdsourcing. To address this issue, we propose an automatic optimization method for preference-based subjective evaluation in terms of pair combination selections and allocation of evaluation volumes with online learning in a crowdsourcing environment. We use a preference-based online learning method based on a sorting algorithm to identify the total order of evaluation targets with minimum sample volumes. Our online learning algorithm supports parallel and asynchronous execution under fixed-budget conditions required for crowdsourcing. Our experiment on preference-based subjective evaluation of synthetic speech shows that our method successfully optimizes the test by reducing pair combinations from 351 to 83 and allocating optimal eva
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#23558;&#19968;&#33268;&#21270;&#20272;&#35745;&#22120;&#31227;&#26893;&#21040;&#27973;&#23618;&#20915;&#31574;&#26641;&#65288;CART&#65289;&#30340;&#36866;&#29992;&#24615;&#65292;&#24182;&#34920;&#26126;&#36825;&#31181;&#26041;&#27861;&#20855;&#26377;&#19968;&#33268;&#24615;&#20445;&#35777;&#24182;&#22312;&#23454;&#35777;&#29615;&#22659;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>https://arxiv.org/abs/2403.06015</link><description>&lt;p&gt;
&#31227;&#26893;&#65306;&#20351;&#38543;&#26426;&#26862;&#26519;&#19968;&#33268;&#21270;
&lt;/p&gt;
&lt;p&gt;
Grafting: Making Random Forests Consistent
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06015
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#23558;&#19968;&#33268;&#21270;&#20272;&#35745;&#22120;&#31227;&#26893;&#21040;&#27973;&#23618;&#20915;&#31574;&#26641;&#65288;CART&#65289;&#30340;&#36866;&#29992;&#24615;&#65292;&#24182;&#34920;&#26126;&#36825;&#31181;&#26041;&#27861;&#20855;&#26377;&#19968;&#33268;&#24615;&#20445;&#35777;&#24182;&#22312;&#23454;&#35777;&#29615;&#22659;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#38543;&#26426;&#26862;&#26519;&#22312;&#24615;&#33021;&#21644;&#24191;&#27867;&#24212;&#29992;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#20851;&#20110;&#20854;&#29702;&#35770;&#30693;&#20043;&#29978;&#23569;&#12290;&#19968;&#20010;&#26410;&#35299;&#20043;&#35868;&#26159;&#38543;&#26426;&#26862;&#26519;&#31639;&#27861;&#26159;&#21542;&#19968;&#33268;&#21270;&#65292;&#25110;&#20309;&#26102;&#36798;&#21040;&#19968;&#33268;&#21270;&#12290;&#25991;&#29486;&#25506;&#35752;&#20102;&#32463;&#20856;&#38543;&#26426;&#26862;&#26519;&#31639;&#27861;&#30340;&#21508;&#31181;&#21464;&#20307;&#65292;&#20197;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#21644;&#24050;&#30693;&#32570;&#38519;&#12290;&#26412;&#25991;&#20026;&#36825;&#19968;&#25991;&#29486;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25506;&#35752;&#20102;&#23558;&#19968;&#33268;&#21270;&#20272;&#35745;&#22120;&#31227;&#26893;&#21040;&#27973;&#23618;CART&#30340;&#36866;&#29992;&#24615;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#31181;&#26041;&#27861;&#20855;&#26377;&#19968;&#33268;&#21270;&#20445;&#35777;&#24182;&#22312;&#23454;&#35777;&#29615;&#22659;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06015v1 Announce Type: cross  Abstract: Despite their performance and widespread use, little is known about the theory of Random Forests. A major unanswered question is whether, or when, the Random Forest algorithm is consistent. The literature explores various variants of the classic Random Forest algorithm to address this question and known short-comings of the method. This paper is a contribution to this literature. Specifically, the suitability of grafting consistent estimators onto a shallow CART is explored. It is shown that this approach has a consistency guarantee and performs well in empirical settings.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#20998;&#24067;&#24335;&#26102;&#38388;&#24046;&#20998;&#30340;&#32479;&#35745;&#25928;&#29575;&#21644;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.05811</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#26102;&#38388;&#24046;&#20998;&#30340;&#32479;&#35745;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
Statistical Efficiency of Distributional Temporal Difference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05811
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#20998;&#24067;&#24335;&#26102;&#38388;&#24046;&#20998;&#30340;&#32479;&#35745;&#25928;&#29575;&#21644;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;(DRL)&#20851;&#27880;&#30340;&#26159;&#36820;&#22238;&#30340;&#23436;&#25972;&#20998;&#24067;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#22343;&#20540;&#65292;&#22312;&#21508;&#20010;&#39046;&#22495;&#21462;&#24471;&#20102;&#32463;&#39564;&#25104;&#21151;&#12290;&#39046;&#22495;DRL&#20013;&#30340;&#26680;&#24515;&#20219;&#21153;&#20043;&#19968;&#26159;&#20998;&#24067;&#24335;&#31574;&#30053;&#35780;&#20272;&#65292;&#28041;&#21450;&#20272;&#35745;&#32473;&#23450;&#31574;&#30053;pi&#30340;&#36820;&#22238;&#20998;&#24067;&#951;^pi&#12290;&#30456;&#24212;&#22320;&#25552;&#20986;&#20102;&#20998;&#24067;&#26102;&#38388;&#24046;&#20998;(TD)&#31639;&#27861;&#65292;&#36825;&#26159;&#32463;&#20856;RL&#25991;&#29486;&#20013;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;&#30340;&#24310;&#20280;&#12290;&#22312;&#34920;&#26684;&#26696;&#20363;&#20013;&#65292;citet{rowland2018analysis}&#21644;citet{rowland2023analysis}&#20998;&#21035;&#35777;&#26126;&#20102;&#20004;&#20010;&#20998;&#24067;&#24335;TD&#23454;&#20363;&#21363;&#20998;&#31867;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;(CTD)&#21644;&#20998;&#20301;&#25968;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;(QTD)&#30340;&#28176;&#36817;&#25910;&#25947;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#20998;&#26512;&#20102;&#20998;&#24067;&#24335;TD&#30340;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#12290;&#20026;&#20102;&#20419;&#36827;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#21442;&#25968;&#30340; dis
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05811v1 Announce Type: cross  Abstract: Distributional reinforcement learning (DRL), which cares about the full distribution of returns instead of just the mean, has achieved empirical success in various domains. One of the core tasks in the field of DRL is distributional policy evaluation, which involves estimating the return distribution $\eta^\pi$ for a given policy $\pi$. A distributional temporal difference (TD) algorithm has been accordingly proposed, which is an extension of the temporal difference algorithm in the classic RL literature. In the tabular case, \citet{rowland2018analysis} and \citet{rowland2023analysis} proved the asymptotic convergence of two instances of distributional TD, namely categorical temporal difference algorithm (CTD) and quantile temporal difference algorithm (QTD), respectively. In this paper, we go a step further and analyze the finite-sample performance of distributional TD. To facilitate theoretical analysis, we propose non-parametric dis
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24314;&#31435;&#22312;&#32473;&#23450;&#30340;&#26368;&#22823;&#26080;&#21521;&#22242;&#22823;&#23567;($s$)&#26041;&#38754;&#30340;&#19979;&#30028;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#36890;&#36807;&#29420;&#31435;&#26597;&#35810;&#39044;&#35328;&#32773;&#22312;&#39532;&#23572;&#21487;&#22827;&#31561;&#20215;&#31867;&#20013;&#36827;&#34892;&#25104;&#21592;&#27979;&#35797;&#36825;&#19968;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.05759</link><description>&lt;p&gt;
&#36890;&#36807;&#29420;&#31435;&#26597;&#35810;&#39044;&#35328;&#32773;&#22312;&#39532;&#23572;&#21487;&#22827;&#31561;&#20215;&#31867;&#20013;&#36827;&#34892;&#25104;&#21592;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Membership Testing in Markov Equivalence Classes via Independence Query Oracles
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05759
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24314;&#31435;&#22312;&#32473;&#23450;&#30340;&#26368;&#22823;&#26080;&#21521;&#22242;&#22823;&#23567;($s$)&#26041;&#38754;&#30340;&#19979;&#30028;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#36890;&#36807;&#29420;&#31435;&#26597;&#35810;&#39044;&#35328;&#32773;&#22312;&#39532;&#23572;&#21487;&#22827;&#31561;&#20215;&#31867;&#20013;&#36827;&#34892;&#25104;&#21592;&#27979;&#35797;&#36825;&#19968;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#37327;&#20043;&#38388;&#22240;&#26524;&#20851;&#31995;&#30340;&#29702;&#35299;&#26159;&#35768;&#22810;&#31185;&#23398;&#39046;&#22495;&#20013;&#20855;&#26377;&#24191;&#27867;&#24433;&#21709;&#30340;&#22522;&#26412;&#38382;&#39064;&#12290;&#34429;&#28982;&#24050;&#32463;&#25237;&#20837;&#20102;&#22823;&#37327;&#30740;&#31350;&#26469;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#22240;&#26524;&#22270;&#65292;&#20294;&#20854;&#34917;&#20805;&#27010;&#24565;&#8212;&#8212;&#27979;&#35797;&#22240;&#26524;&#20851;&#31995;&#21364;&#22522;&#26412;&#27809;&#26377;&#34987;&#25506;&#32034;&#12290;&#25105;&#20204;&#36890;&#36807;&#24314;&#31435;&#22312;&#32473;&#23450;MEC(Markov&#31561;&#20215;&#31867;)&#30340;&#26368;&#22823;&#26080;&#21521;&#22242;&#30340;&#22823;&#23567;($s$)&#26041;&#38754;&#30340;&#19979;&#30028;&#65292;&#25506;&#35752;&#22522;&#20110;&#32422;&#26463;&#30340;&#27979;&#35797;&#26041;&#27861;&#12290;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;$\exp(\Omega(s))$&#20010;&#29420;&#31435;&#24615;&#27979;&#35797;&#30340;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05759v1 Announce Type: cross  Abstract: Understanding causal relationships between variables is a fundamental problem with broad impact in numerous scientific fields. While extensive research has been dedicated to learning causal graphs from data, its complementary concept of testing causal relationships has remained largely unexplored. While learning involves the task of recovering the Markov equivalence class (MEC) of the underlying causal graph from observational data, the testing counterpart addresses the following critical question: Given a specific MEC and observational data from some causal graph, can we determine if the data-generating causal graph belongs to the given MEC?   We explore constraint-based testing methods by establishing bounds on the required number of conditional independence tests. Our bounds are in terms of the size of the maximum undirected clique ($s$) of the given MEC. In the worst case, we show a lower bound of $\exp(\Omega(s))$ independence tes
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#28155;&#21152;&#39069;&#22806;&#33410;&#28857;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#25968;&#20540;&#21644;&#20998;&#31867;&#20449;&#24687;&#21516;&#26102;&#32435;&#20837;&#35889;&#32858;&#31867;&#31639;&#27861;&#65292;&#36991;&#20813;&#20102;&#25968;&#25454;&#39044;&#22788;&#29702;&#25110;&#22797;&#26434;&#30456;&#20284;&#24615;&#20989;&#25968;&#30340;&#38656;&#27714;&#12290;</title><link>https://arxiv.org/abs/2403.05669</link><description>&lt;p&gt;
&#36890;&#36807;&#39069;&#22806;&#22270;&#33410;&#28857;&#30340;&#26041;&#27861;&#23545;&#20998;&#31867;&#21644;&#28151;&#21512;&#25968;&#25454;&#36827;&#34892;&#35889;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Spectral Clustering of Categorical and Mixed-type Data via Extra Graph Nodes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05669
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28155;&#21152;&#39069;&#22806;&#33410;&#28857;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#25968;&#20540;&#21644;&#20998;&#31867;&#20449;&#24687;&#21516;&#26102;&#32435;&#20837;&#35889;&#32858;&#31867;&#31639;&#27861;&#65292;&#36991;&#20813;&#20102;&#25968;&#25454;&#39044;&#22788;&#29702;&#25110;&#22797;&#26434;&#30456;&#20284;&#24615;&#20989;&#25968;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#25968;&#25454;&#23545;&#35937;&#32858;&#31867;&#25104;&#21516;&#36136;&#32676;&#20307;&#26159;&#25968;&#25454;&#25366;&#25496;&#20013;&#26368;&#37325;&#35201;&#30340;&#20219;&#21153;&#20043;&#19968;&#12290;&#35889;&#32858;&#31867;&#26159;&#19968;&#31181;&#29702;&#35770;&#19978;&#22362;&#23454;&#19988;&#36866;&#24212;&#22810;&#31181;&#29616;&#23454;&#22330;&#26223;&#30340;&#26368;&#37325;&#35201;&#30340;&#32858;&#31867;&#31639;&#27861;&#20043;&#19968;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#19968;&#31181;&#26356;&#33258;&#28982;&#30340;&#26041;&#27861;&#65292;&#23558;&#25968;&#20540;&#21644;&#20998;&#31867;&#20449;&#24687;&#21516;&#26102;&#32435;&#20837;&#35889;&#32858;&#31867;&#31639;&#27861;&#65292;&#36991;&#20813;&#20102;&#38656;&#35201;&#23545;&#25968;&#25454;&#36827;&#34892;&#39044;&#22788;&#29702;&#25110;&#20351;&#29992;&#22797;&#26434;&#30456;&#20284;&#24615;&#20989;&#25968;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05669v1 Announce Type: cross  Abstract: Clustering data objects into homogeneous groups is one of the most important tasks in data mining. Spectral clustering is arguably one of the most important algorithms for clustering, as it is appealing for its theoretical soundness and is adaptable to many real-world data settings. For example, mixed data, where the data is composed of numerical and categorical features, is typically handled via numerical discretization, dummy coding, or similarity computation that takes into account both data types. This paper explores a more natural way to incorporate both numerical and categorical information into the spectral clustering algorithm, avoiding the need for data preprocessing or the use of sophisticated similarity functions. We propose adding extra nodes corresponding to the different categories the data may belong to and show that it leads to an interpretable clustering objective function. Furthermore, we demonstrate that this simple 
&lt;/p&gt;</description></item><item><title>&#23494;&#24230;&#22238;&#24402;&#26159;&#19968;&#31181;&#21033;&#29992;&#23494;&#24230;&#20989;&#25968;&#36827;&#34892;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#24182;&#36890;&#36807;&#21333;&#27425;&#21069;&#21521;&#20256;&#36882;&#23454;&#29616;&#24555;&#36895;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#20855;&#26377;&#36317;&#31163;&#24863;&#30693;&#33021;&#21147;&#65292;&#33021;&#22815;&#22312;&#20998;&#24067;&#20559;&#31227;&#19979;&#20135;&#29983;&#39640;&#36136;&#37327;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2403.05600</link><description>&lt;p&gt;
&#23494;&#24230;&#22238;&#24402;&#65306;&#38754;&#21521;&#20998;&#24067;&#20559;&#31227;&#19979;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#39640;&#25928;&#19988;&#36317;&#31163;&#24863;&#30693;&#30340;&#28145;&#24230;&#22238;&#24402;&#22120;
&lt;/p&gt;
&lt;p&gt;
Density-Regression: Efficient and Distance-Aware Deep Regressor for Uncertainty Estimation under Distribution Shifts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05600
&lt;/p&gt;
&lt;p&gt;
&#23494;&#24230;&#22238;&#24402;&#26159;&#19968;&#31181;&#21033;&#29992;&#23494;&#24230;&#20989;&#25968;&#36827;&#34892;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#24182;&#36890;&#36807;&#21333;&#27425;&#21069;&#21521;&#20256;&#36882;&#23454;&#29616;&#24555;&#36895;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#20855;&#26377;&#36317;&#31163;&#24863;&#30693;&#33021;&#21147;&#65292;&#33021;&#22815;&#22312;&#20998;&#24067;&#20559;&#31227;&#19979;&#20135;&#29983;&#39640;&#36136;&#37327;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#28145;&#24230;&#21512;&#22863;&#25216;&#26415;&#36890;&#36807;&#20351;&#29992;&#19981;&#21516;&#27169;&#22411;&#30340;&#22810;&#27425;&#21069;&#21521;&#20256;&#36882;&#23454;&#29616;&#24378;&#22823;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#36825;&#26679;&#20570;&#20250;&#21344;&#29992;&#22823;&#37327;&#23384;&#20648;&#31354;&#38388;&#24182;&#19988;&#25512;&#26029;&#65288;&#27979;&#35797;&#65289;&#26102;&#38388;&#36739;&#24930;&#12290;&#20026;&#20102;&#35299;&#20915;&#27492;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#23494;&#24230;&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#20013;&#21033;&#29992;&#23494;&#24230;&#20989;&#25968;&#65292;&#36890;&#36807;&#21333;&#27425;&#21069;&#21521;&#20256;&#36882;&#23454;&#29616;&#24555;&#36895;&#25512;&#26029;&#12290;&#25105;&#20204;&#35777;&#26126;&#23427;&#22312;&#29305;&#24449;&#31354;&#38388;&#19978;&#20855;&#26377;&#36317;&#31163;&#24863;&#30693;&#65292;&#36825;&#26159;&#31070;&#32463;&#32593;&#32476;&#20135;&#29983;&#39640;&#36136;&#37327;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;&#22312;&#23454;&#35777;&#26041;&#38754;&#65292;&#25105;&#20204;&#22312;&#31435;&#26041;&#20307;&#29609;&#20855;&#25968;&#25454;&#38598;&#12289;&#22522;&#20934;UCI&#25968;&#25454;&#38598;&#12289;&#20855;&#26377;&#26102;&#38388;&#24207;&#21015;&#30340;&#22825;&#27668;&#39044;&#27979;&#21644;&#30495;&#23454;&#19990;&#30028;&#20559;&#31227;&#24212;&#29992;&#19979;&#30340;&#28145;&#24230;&#20272;&#35745;&#31561;&#22238;&#24402;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#20998;&#24067;&#20559;&#31227;&#19979;&#65292;&#23494;&#24230;&#22238;&#24402;&#19982;&#29616;&#20195;&#28145;&#24230;&#22238;&#24402;&#22120;&#30456;&#27604;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#24615;&#33021;&#65292;&#21516;&#26102;&#20351;&#29992;&#30340;&#27169;&#24335;&#36739;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05600v1 Announce Type: new  Abstract: Morden deep ensembles technique achieves strong uncertainty estimation performance by going through multiple forward passes with different models. This is at the price of a high storage space and a slow speed in the inference (test) time. To address this issue, we propose Density-Regression, a method that leverages the density function in uncertainty estimation and achieves fast inference by a single forward pass. We prove it is distance aware on the feature space, which is a necessary condition for a neural network to produce high-quality uncertainty estimation under distribution shifts. Empirically, we conduct experiments on regression tasks with the cubic toy dataset, benchmark UCI, weather forecast with time series, and depth estimation under real-world shifted applications. We show that Density-Regression has competitive uncertainty estimation performance under distribution shifts with modern deep regressors while using a lower mode
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#35752;&#35770;&#20102;&#22914;&#20309;&#35774;&#35745;&#33021;&#22815;&#21487;&#38752;&#21306;&#20998;&#30495;&#23454;&#25968;&#25454;&#21644;&#19981;&#30495;&#23454;&#25968;&#25454;&#30340;&#20989;&#25968;&#65292;&#25552;&#20986;&#20102;&#36890;&#29992;&#35780;&#35770;&#32773;&#30340;&#27010;&#24565;&#20316;&#20026;&#19968;&#20010;&#26032;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2403.04493</link><description>&lt;p&gt;
&#20351;&#22270;&#20687;&#30495;&#23454;&#30340;&#22240;&#32032;&#26159;&#20160;&#20040;&#65311;
&lt;/p&gt;
&lt;p&gt;
What makes an image realistic?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04493
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#35752;&#35770;&#20102;&#22914;&#20309;&#35774;&#35745;&#33021;&#22815;&#21487;&#38752;&#21306;&#20998;&#30495;&#23454;&#25968;&#25454;&#21644;&#19981;&#30495;&#23454;&#25968;&#25454;&#30340;&#20989;&#25968;&#65292;&#25552;&#20986;&#20102;&#36890;&#29992;&#35780;&#35770;&#32773;&#30340;&#27010;&#24565;&#20316;&#20026;&#19968;&#20010;&#26032;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#37324;&#65292;&#25105;&#20204;&#22312;&#29983;&#25104;&#30475;&#36215;&#26469;&#30495;&#23454;&#30340;&#25968;&#25454;&#26041;&#38754;&#21462;&#24471;&#20102;&#24040;&#22823;&#36827;&#23637;&#65292;&#26080;&#35770;&#26159;&#22270;&#20687;&#12289;&#25991;&#26412;&#12289;&#38899;&#39057;&#36824;&#26159;&#35270;&#39057;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#19982;&#20043;&#23494;&#20999;&#30456;&#20851;&#30340;&#38382;&#39064;&#65292;&#21363;&#37327;&#21270;&#29616;&#23454;&#20027;&#20041;&#65292;&#21363;&#35774;&#35745;&#33021;&#22815;&#21487;&#38752;&#22320;&#21306;&#20998;&#30495;&#23454;&#25968;&#25454;&#21644;&#19981;&#30495;&#23454;&#25968;&#25454;&#30340;&#20989;&#25968;&#12290;&#20174;&#31639;&#27861;&#20449;&#24687;&#29702;&#35770;&#30340;&#35266;&#28857;&#20986;&#21457;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#20026;&#20160;&#20040;&#36825;&#20010;&#38382;&#39064;&#24456;&#20855;&#25361;&#25112;&#24615;&#65292;&#20026;&#20160;&#20040;&#19968;&#20010;&#22909;&#30340;&#29983;&#25104;&#27169;&#22411;&#21333;&#29420;&#19981;&#33021;&#35299;&#20915;&#23427;&#65292;&#20197;&#21450;&#19968;&#20010;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#24212;&#35813;&#26159;&#20160;&#20040;&#26679;&#30340;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#36890;&#29992;&#35780;&#35770;&#32773;&#30340;&#27010;&#24565;&#65292;&#19981;&#20687;&#23545;&#25239;&#24615;&#35780;&#35770;&#32773;&#37027;&#26679;&#38656;&#35201;&#23545;&#25239;&#24615;&#35757;&#32451;&#12290;&#23613;&#31649;&#36890;&#29992;&#35780;&#35770;&#32773;&#24182;&#19981;&#31435;&#21363;&#23454;&#29992;&#65292;&#20294;&#23427;&#20204;&#26082;&#21487;&#20197;&#20316;&#20026;&#24341;&#23548;&#23454;&#38469;&#23454;&#29616;&#30340;&#21271;&#26497;&#26143;&#65292;&#20063;&#21487;&#20197;&#20316;&#20026;&#19968;&#20010;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04493v1 Announce Type: new  Abstract: The last decade has seen tremendous progress in our ability to generate realistic-looking data, be it images, text, audio, or video. Here, we discuss the closely related problem of quantifying realism, that is, designing functions that can reliably tell realistic data from unrealistic data. This problem turns out to be significantly harder to solve and remains poorly understood, despite its prevalence in machine learning and recent breakthroughs in generative AI. Drawing on insights from algorithmic information theory, we discuss why this problem is challenging, why a good generative model alone is insufficient to solve it, and what a good solution would look like. In particular, we introduce the notion of a universal critic, which unlike adversarial critics does not require adversarial training. While universal critics are not immediately practical, they can serve both as a North Star for guiding practical implementations and as a tool 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24212;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#23398;&#20064;&#20551;&#35774;&#31354;&#38388;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#20877;&#29983;&#26680;Banach&#31354;&#38388;&#65292;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#23398;&#20064;&#21644;&#26368;&#23567;&#25554;&#20540;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#23398;&#20064;&#27169;&#22411;&#30340;&#35299;&#21487;&#20197;&#34920;&#31034;&#20026;&#32447;&#24615;&#32452;&#21512;&#12290;</title><link>https://arxiv.org/abs/2403.03353</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#20551;&#35774;&#31354;&#38388;
&lt;/p&gt;
&lt;p&gt;
Hypothesis Spaces for Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03353
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24212;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#23398;&#20064;&#20551;&#35774;&#31354;&#38388;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#20877;&#29983;&#26680;Banach&#31354;&#38388;&#65292;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#23398;&#20064;&#21644;&#26368;&#23567;&#25554;&#20540;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#23398;&#20064;&#27169;&#22411;&#30340;&#35299;&#21487;&#20197;&#34920;&#31034;&#20026;&#32447;&#24615;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24212;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#30340;&#28145;&#24230;&#23398;&#20064;&#20551;&#35774;&#31354;&#38388;&#12290;&#36890;&#36807;&#23558;DNN&#35270;&#20026;&#20004;&#20010;&#21464;&#37327;&#30340;&#20989;&#25968;&#65292;&#21363;&#29289;&#29702;&#21464;&#37327;&#21644;&#21442;&#25968;&#21464;&#37327;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;DNNs&#30340;&#21407;&#22987;&#38598;&#21512;&#65292;&#21442;&#25968;&#21464;&#37327;&#20301;&#20110;&#30001;DNNs&#30340;&#26435;&#37325;&#30697;&#38453;&#21644;&#20559;&#32622;&#20915;&#23450;&#30340;&#19968;&#32452;&#28145;&#24230;&#21644;&#23485;&#24230;&#20013;&#12290;&#28982;&#21518;&#22312;&#24369;*&#25299;&#25169;&#20013;&#23436;&#25104;&#21407;&#22987;DNN&#38598;&#21512;&#30340;&#32447;&#24615;&#36328;&#24230;&#65292;&#20197;&#26500;&#24314;&#19968;&#20010;&#29289;&#29702;&#21464;&#37327;&#20989;&#25968;&#30340;Banach&#31354;&#38388;&#12290;&#25105;&#20204;&#35777;&#26126;&#25152;&#26500;&#36896;&#30340;Banach&#31354;&#38388;&#26159;&#19968;&#20010;&#20877;&#29983;&#26680;Banach&#31354;&#38388;&#65288;RKBS&#65289;&#65292;&#24182;&#26500;&#36896;&#20854;&#20877;&#29983;&#26680;&#12290;&#36890;&#36807;&#20026;&#23398;&#20064;&#27169;&#22411;&#30340;&#35299;&#24314;&#31435;&#34920;&#36798;&#23450;&#29702;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#20010;&#23398;&#20064;&#27169;&#22411;&#65292;&#27491;&#21017;&#21270;&#23398;&#20064;&#21644;&#26368;&#23567;&#25554;&#20540;&#38382;&#39064;&#22312;&#32467;&#26524;RKBS&#20013;&#12290;&#34920;&#36798;&#23450;&#29702;&#25581;&#31034;&#20102;&#36825;&#20123;&#23398;&#20064;&#27169;&#22411;&#30340;&#35299;&#21487;&#20197;&#34920;&#31034;&#20026;&#32447;&#24615;&#32452;&#21512;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03353v1 Announce Type: cross  Abstract: This paper introduces a hypothesis space for deep learning that employs deep neural networks (DNNs). By treating a DNN as a function of two variables, the physical variable and parameter variable, we consider the primitive set of the DNNs for the parameter variable located in a set of the weight matrices and biases determined by a prescribed depth and widths of the DNNs. We then complete the linear span of the primitive DNN set in a weak* topology to construct a Banach space of functions of the physical variable. We prove that the Banach space so constructed is a reproducing kernel Banach space (RKBS) and construct its reproducing kernel. We investigate two learning models, regularized learning and minimum interpolation problem in the resulting RKBS, by establishing representer theorems for solutions of the learning models. The representer theorems unfold that solutions of these learning models can be expressed as linear combination of
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#22240;&#26524;&#27491;&#21017;&#21270;&#25193;&#23637;&#21040;&#38170;&#22238;&#24402;&#65288;AR&#65289;&#20013;&#65292;&#25552;&#20986;&#20102;&#19982;&#38170;&#26694;&#26550;&#30456;&#21305;&#37197;&#30340;&#25439;&#22833;&#20989;&#25968;&#30830;&#20445;&#31283;&#20581;&#24615;&#65292;&#21508;&#31181;&#22810;&#20803;&#20998;&#26512;&#31639;&#27861;&#22343;&#22312;&#38170;&#26694;&#26550;&#20869;&#65292;&#31616;&#21333;&#27491;&#21017;&#21270;&#22686;&#24378;&#20102;OOD&#35774;&#32622;&#20013;&#30340;&#31283;&#20581;&#24615;&#65292;&#39564;&#35777;&#20102;&#38170;&#27491;&#21017;&#21270;&#30340;&#22810;&#21151;&#33021;&#24615;&#21644;&#23545;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#35770;&#30340;&#25512;&#36827;&#12290;</title><link>https://arxiv.org/abs/2403.01865</link><description>&lt;p&gt;
&#36890;&#36807;&#38170;&#22810;&#20803;&#20998;&#26512;&#25913;&#21892;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Improving generalisation via anchor multivariate analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01865
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#22240;&#26524;&#27491;&#21017;&#21270;&#25193;&#23637;&#21040;&#38170;&#22238;&#24402;&#65288;AR&#65289;&#20013;&#65292;&#25552;&#20986;&#20102;&#19982;&#38170;&#26694;&#26550;&#30456;&#21305;&#37197;&#30340;&#25439;&#22833;&#20989;&#25968;&#30830;&#20445;&#31283;&#20581;&#24615;&#65292;&#21508;&#31181;&#22810;&#20803;&#20998;&#26512;&#31639;&#27861;&#22343;&#22312;&#38170;&#26694;&#26550;&#20869;&#65292;&#31616;&#21333;&#27491;&#21017;&#21270;&#22686;&#24378;&#20102;OOD&#35774;&#32622;&#20013;&#30340;&#31283;&#20581;&#24615;&#65292;&#39564;&#35777;&#20102;&#38170;&#27491;&#21017;&#21270;&#30340;&#22810;&#21151;&#33021;&#24615;&#21644;&#23545;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#35770;&#30340;&#25512;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#38170;&#22238;&#24402;&#65288;AR&#65289;&#20013;&#24341;&#20837;&#22240;&#26524;&#27491;&#21017;&#21270;&#25193;&#23637;&#65292;&#20197;&#25913;&#21892;&#36229;&#20986;&#20998;&#24067;&#65288;OOD&#65289;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19982;&#38170;&#26694;&#26550;&#30456;&#21305;&#37197;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#20197;&#30830;&#20445;&#23545;&#20998;&#24067;&#36716;&#31227;&#30340;&#31283;&#20581;&#24615;&#12290;&#21508;&#31181;&#22810;&#20803;&#20998;&#26512;&#65288;MVA&#65289;&#31639;&#27861;&#65292;&#22914;&#65288;&#27491;&#20132;&#21270;&#65289;PLS&#12289;RRR&#21644;MLR&#65292;&#22343;&#22312;&#38170;&#26694;&#26550;&#20869;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#31616;&#21333;&#30340;&#27491;&#21017;&#21270;&#22686;&#24378;&#20102;OOD&#35774;&#32622;&#20013;&#30340;&#31283;&#20581;&#24615;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#30340;&#27668;&#20505;&#31185;&#23398;&#38382;&#39064;&#20013;&#65292;&#20026;&#25152;&#36873;&#31639;&#27861;&#25552;&#20379;&#20102;&#20272;&#35745;&#22120;&#65292;&#23637;&#31034;&#20102;&#20854;&#19968;&#33268;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;&#32463;&#39564;&#39564;&#35777;&#31361;&#26174;&#20102;&#38170;&#27491;&#21017;&#21270;&#30340;&#22810;&#21151;&#33021;&#24615;&#65292;&#24378;&#35843;&#20854;&#19982;MVA&#26041;&#27861;&#30340;&#20860;&#23481;&#24615;&#65292;&#24182;&#24378;&#35843;&#20854;&#22312;&#22686;&#24378;&#21487;&#22797;&#21046;&#24615;&#30340;&#21516;&#26102;&#25269;&#24481;&#20998;&#24067;&#36716;&#31227;&#20013;&#30340;&#20316;&#29992;&#12290;&#25193;&#23637;&#30340;AR&#26694;&#26550;&#25512;&#36827;&#20102;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#35770;&#65292;&#35299;&#20915;&#20102;&#21487;&#38752;OOD&#27867;&#21270;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01865v1 Announce Type: cross  Abstract: We introduce a causal regularisation extension to anchor regression (AR) for improved out-of-distribution (OOD) generalisation. We present anchor-compatible losses, aligning with the anchor framework to ensure robustness against distribution shifts. Various multivariate analysis (MVA) algorithms, such as (Orthonormalized) PLS, RRR, and MLR, fall within the anchor framework. We observe that simple regularisation enhances robustness in OOD settings. Estimators for selected algorithms are provided, showcasing consistency and efficacy in synthetic and real-world climate science problems. The empirical validation highlights the versatility of anchor regularisation, emphasizing its compatibility with MVA approaches and its role in enhancing replicability while guarding against distribution shifts. The extended AR framework advances causal inference methodologies, addressing the need for reliable OOD generalisation.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#31454;&#20105;&#20998;&#26512;&#26694;&#26550;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35843;&#25972;FTRL&#23398;&#20064;&#29575;&#30340;&#26356;&#26032;&#35268;&#21017;&#65292;&#20351;&#20854;&#22312;&#24120;&#25968;&#22240;&#23376;&#20869;&#36798;&#21040;&#26368;&#20339;&#31454;&#20105;&#27604;&#65292;&#24182;&#19988;&#23637;&#31034;&#20102;&#24403;&#24809;&#32602;&#39033;&#20855;&#26377;&#36817;&#20284;&#21333;&#35843;&#24615;&#26102;&#30340;&#31454;&#20105;&#27604;&#29305;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.00715</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#30340;FTRL&#31639;&#27861;&#30340;&#31454;&#20105;&#27604;&#20998;&#26512;&#21644;&#26368;&#20339;&#26041;&#26696;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Adaptive Learning Rate for Follow-the-Regularized-Leader: Competitive Ratio Analysis and Best-of-Both-Worlds
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00715
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#31454;&#20105;&#20998;&#26512;&#26694;&#26550;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35843;&#25972;FTRL&#23398;&#20064;&#29575;&#30340;&#26356;&#26032;&#35268;&#21017;&#65292;&#20351;&#20854;&#22312;&#24120;&#25968;&#22240;&#23376;&#20869;&#36798;&#21040;&#26368;&#20339;&#31454;&#20105;&#27604;&#65292;&#24182;&#19988;&#23637;&#31034;&#20102;&#24403;&#24809;&#32602;&#39033;&#20855;&#26377;&#36817;&#20284;&#21333;&#35843;&#24615;&#26102;&#30340;&#31454;&#20105;&#27604;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Follow-The-Regularized-Leader (FTRL)&#34987;&#35748;&#20026;&#26159;&#22312;&#32447;&#23398;&#20064;&#20013;&#19968;&#31181;&#26377;&#25928;&#19988;&#22810;&#21151;&#33021;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#23398;&#20064;&#29575;&#30340;&#24688;&#24403;&#36873;&#25321;&#23545;&#20110;&#20943;&#23567;&#21518;&#24724;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#23558;&#35843;&#25972;FTRL&#23398;&#20064;&#29575;&#30340;&#38382;&#39064;&#26500;&#24314;&#20026;&#19968;&#20010;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#31454;&#20105;&#20998;&#26512;&#26694;&#26550;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#31454;&#20105;&#27604;&#30340;&#19979;&#30028;&#65292;&#24182;&#25552;&#20986;&#20102;&#23398;&#20064;&#29575;&#30340;&#26356;&#26032;&#35268;&#21017;&#65292;&#20351;&#20854;&#22312;&#19968;&#20010;&#24120;&#25968;&#22240;&#23376;&#20869;&#36798;&#21040;&#19979;&#30028;&#30340;&#19978;&#30028;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#35828;&#26126;&#20102;&#26368;&#20248;&#31454;&#20105;&#27604;&#26159;&#30001;&#24809;&#32602;&#39033;&#30340;&#32452;&#25104;&#37096;&#20998;&#30340;&#65288;&#36817;&#20284;&#65289;&#21333;&#35843;&#24615;&#25152;&#20915;&#23450;&#30340;&#65292;&#34920;&#26126;&#22914;&#26524;&#24809;&#32602;&#39033;&#30340;&#32452;&#25104;&#37096;&#20998;&#24418;&#25104;&#21333;&#35843;&#38750;&#22686;&#24207;&#21015;&#65292;&#21017;&#21487;&#20197;&#23454;&#29616;&#24120;&#25968;&#31454;&#20105;&#27604;&#65292;&#24182;&#25512;&#23548;&#20986;&#20102;&#22312;&#24809;&#32602;&#39033;$\xi$&#36817;&#20284;&#21333;&#35843;&#38750;&#22686;&#26102;&#30340;&#32039;&#23494;&#31454;&#20105;&#27604;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26356;&#26032;&#35268;&#21017;&#34987;&#31216;&#20026;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00715v1 Announce Type: new  Abstract: Follow-The-Regularized-Leader (FTRL) is known as an effective and versatile approach in online learning, where appropriate choice of the learning rate is crucial for smaller regret. To this end, we formulate the problem of adjusting FTRL's learning rate as a sequential decision-making problem and introduce the framework of competitive analysis. We establish a lower bound for the competitive ratio and propose update rules for learning rate that achieves an upper bound within a constant factor of this lower bound. Specifically, we illustrate that the optimal competitive ratio is characterized by the (approximate) monotonicity of components of the penalty term, showing that a constant competitive ratio is achievable if the components of the penalty term form a monotonically non-increasing sequence, and derive a tight competitive ratio when penalty terms are $\xi$-approximately monotone non-increasing. Our proposed update rule, referred to a
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#21322;&#30417;&#30563; U-&#32479;&#35745;&#37327;&#65292;&#21033;&#29992;&#22823;&#37327;&#26410;&#26631;&#35760;&#25968;&#25454;&#65292;&#33719;&#24471;&#20102;&#28176;&#36817;&#27491;&#24577;&#20998;&#24067;&#30340;&#24615;&#36136;&#65292;&#24182;&#36890;&#36807;&#26377;&#25928;&#25972;&#21512;&#21508;&#31181;&#24378;&#22823;&#39044;&#27979;&#24037;&#20855;&#23454;&#29616;&#20102;&#26126;&#26174;&#30340;&#25928;&#29575;&#25552;&#21319;&#12290;</title><link>https://arxiv.org/abs/2402.18921</link><description>&lt;p&gt;
&#21322;&#30417;&#30563; U-&#32479;&#35745;&#37327;
&lt;/p&gt;
&lt;p&gt;
Semi-Supervised U-statistics
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18921
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#21322;&#30417;&#30563; U-&#32479;&#35745;&#37327;&#65292;&#21033;&#29992;&#22823;&#37327;&#26410;&#26631;&#35760;&#25968;&#25454;&#65292;&#33719;&#24471;&#20102;&#28176;&#36817;&#27491;&#24577;&#20998;&#24067;&#30340;&#24615;&#36136;&#65292;&#24182;&#36890;&#36807;&#26377;&#25928;&#25972;&#21512;&#21508;&#31181;&#24378;&#22823;&#39044;&#27979;&#24037;&#20855;&#23454;&#29616;&#20102;&#26126;&#26174;&#30340;&#25928;&#29575;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18921v1 &#36890;&#25253;&#31867;&#22411;: &#36328;&#39046;&#22495;  &#25688;&#35201;: &#21322;&#30417;&#30563;&#25968;&#25454;&#38598;&#22312;&#22810;&#20010;&#39046;&#22495;&#20013;&#26222;&#36941;&#23384;&#22312;&#65292;&#20854;&#20013;&#33719;&#24471;&#23436;&#20840;&#26631;&#35760;&#25968;&#25454;&#25104;&#26412;&#39640;&#26114;&#25110;&#32791;&#26102;&#12290;&#36825;&#31867;&#25968;&#25454;&#38598;&#30340;&#26222;&#36941;&#23384;&#22312;&#19968;&#30452;&#25512;&#21160;&#30528;&#23545;&#21033;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#28508;&#21147;&#30340;&#26032;&#24037;&#20855;&#21644;&#26041;&#27861;&#30340;&#38656;&#27714;&#12290;&#20026;&#20102;&#28385;&#36275;&#36825;&#31181;&#38656;&#27714;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#21463;&#30410;&#20110;&#22823;&#37327;&#26410;&#26631;&#35760;&#25968;&#25454;&#30340;&#21322;&#30417;&#30563; U-&#32479;&#35745;&#37327;&#65292;&#24182;&#30740;&#31350;&#20102;&#23427;&#20204;&#30340;&#32479;&#35745;&#29305;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#28176;&#36817;&#22320;&#26381;&#20174;&#27491;&#24577;&#20998;&#24067;&#65292;&#24182;&#19988;&#36890;&#36807;&#26377;&#25928;&#22320;&#23558;&#21508;&#31181;&#24378;&#22823;&#30340;&#39044;&#27979;&#24037;&#20855;&#25972;&#21512;&#21040;&#26694;&#26550;&#20013;&#65292;&#33719;&#24471;&#20102;&#26126;&#26174;&#30340;&#25928;&#29575;&#25552;&#21319;&#65292;&#36229;&#36807;&#20102;&#32463;&#20856; U-&#32479;&#35745;&#37327;&#12290;&#20026;&#20102;&#29702;&#35299;&#38382;&#39064;&#30340;&#26681;&#26412;&#22256;&#38590;&#65292;&#25105;&#20204;&#22312;&#21322;&#30417;&#30563;&#35774;&#32622;&#20013;&#25512;&#23548;&#20102;&#26497;&#23567;&#26497;&#22823;&#19979;&#30028;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#27491;&#21017;&#26465;&#20214;&#19979;&#25105;&#20204;&#30340;&#36807;&#31243;&#26159;&#21322;&#21442;&#25968;&#26377;&#25928;&#30340;&#12290;&#27492;&#22806;&#65292;&#38024;&#23545;&#21452;&#21464;&#37327;&#26680;&#20989;&#25968;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#32988;&#36807;&#20102;&#32463;&#20856;&#30340; U-&#32479;&#35745;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18921v1 Announce Type: cross  Abstract: Semi-supervised datasets are ubiquitous across diverse domains where obtaining fully labeled data is costly or time-consuming. The prevalence of such datasets has consistently driven the demand for new tools and methods that exploit the potential of unlabeled data. Responding to this demand, we introduce semi-supervised U-statistics enhanced by the abundance of unlabeled data, and investigate their statistical properties. We show that the proposed approach is asymptotically Normal and exhibits notable efficiency gains over classical U-statistics by effectively integrating various powerful prediction tools into the framework. To understand the fundamental difficulty of the problem, we derive minimax lower bounds in semi-supervised settings and showcase that our procedure is semi-parametrically efficient under regularity conditions. Moreover, tailored to bivariate kernels, we propose a refined approach that outperforms the classical U-st
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;MIM-Reasoner&#65292;&#32467;&#21512;&#24378;&#21270;&#23398;&#20064;&#21644;&#27010;&#29575;&#22270;&#27169;&#22411;&#65292;&#26377;&#25928;&#22320;&#25429;&#25417;&#20102;&#32473;&#23450;&#22810;&#37325;&#32593;&#32476;&#20869;&#37096;&#21644;&#23618;&#38388;&#30340;&#22797;&#26434;&#20256;&#25773;&#36807;&#31243;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;MIM&#20013;&#26368;&#20855;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.16898</link><description>&lt;p&gt;
MIM-Reasoner: &#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#30340;&#22810;&#37325;&#24433;&#21709;&#26368;&#22823;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
MIM-Reasoner: Learning with Theoretical Guarantees for Multiplex Influence Maximization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16898
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;MIM-Reasoner&#65292;&#32467;&#21512;&#24378;&#21270;&#23398;&#20064;&#21644;&#27010;&#29575;&#22270;&#27169;&#22411;&#65292;&#26377;&#25928;&#22320;&#25429;&#25417;&#20102;&#32473;&#23450;&#22810;&#37325;&#32593;&#32476;&#20869;&#37096;&#21644;&#23618;&#38388;&#30340;&#22797;&#26434;&#20256;&#25773;&#36807;&#31243;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;MIM&#20013;&#26368;&#20855;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#37325;&#24433;&#21709;&#26368;&#22823;&#21270;&#65288;MIM&#65289;&#35201;&#27714;&#25105;&#20204;&#35782;&#21035;&#19968;&#32452;&#31181;&#23376;&#29992;&#25143;&#65292;&#20197;&#26368;&#22823;&#21270;&#22810;&#37325;&#32593;&#32476;&#20013;&#21463;&#24433;&#21709;&#29992;&#25143;&#30340;&#39044;&#26399;&#25968;&#37327;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;MIM-Reasoner&#65292;&#23558;&#24378;&#21270;&#23398;&#20064;&#19982;&#27010;&#29575;&#22270;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#26377;&#25928;&#25429;&#25417;&#32473;&#23450;&#22810;&#37325;&#32593;&#32476;&#20869;&#37096;&#21644;&#23618;&#38388;&#30340;&#22797;&#26434;&#20256;&#25773;&#36807;&#31243;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;MIM&#20013;&#26368;&#20855;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16898v1 Announce Type: cross  Abstract: Multiplex influence maximization (MIM) asks us to identify a set of seed users such as to maximize the expected number of influenced users in a multiplex network. MIM has been one of central research topics, especially in nowadays social networking landscape where users participate in multiple online social networks (OSNs) and their influences can propagate among several OSNs simultaneously. Although there exist a couple combinatorial algorithms to MIM, learning-based solutions have been desired due to its generalization ability to heterogeneous networks and their diversified propagation characteristics. In this paper, we introduce MIM-Reasoner, coupling reinforcement learning with probabilistic graphical model, which effectively captures the complex propagation process within and between layers of a given multiplex network, thereby tackling the most challenging problem in MIM. We establish a theoretical guarantee for MIM-Reasoner as w
&lt;/p&gt;</description></item><item><title>&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#30740;&#31350;&#20102;&#39057;&#35889;&#30340;&#26497;&#22823;&#24615;&#36136;&#65292;&#35777;&#26126;&#20102;&#22312;&#19968;&#31867;&#27169;&#22411;&#20013;&#23384;&#22312;&#26497;&#22823;&#32467;&#26524;&#65292;&#20197;&#21450;&#22312;&#19968;&#20123;&#26465;&#20214;&#19979;&#23384;&#22312;&#20445;&#25345;&#39057;&#35889;&#30340;&#20809;&#35889;&#19981;&#21464;&#24615;&#65292;&#35299;&#37322;&#20102;&#25991;&#29486;&#20013;&#35266;&#23519;&#21040;&#30340;&#32467;&#26524;&#23545;&#31216;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.14515</link><description>&lt;p&gt;
&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#39057;&#35889;&#30340;&#20809;&#35889;&#19981;&#21464;&#24615;&#21644;&#26497;&#22823;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Spectral invariance and maximality properties of the frequency spectrum of quantum neural networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14515
&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#30740;&#31350;&#20102;&#39057;&#35889;&#30340;&#26497;&#22823;&#24615;&#36136;&#65292;&#35777;&#26126;&#20102;&#22312;&#19968;&#31867;&#27169;&#22411;&#20013;&#23384;&#22312;&#26497;&#22823;&#32467;&#26524;&#65292;&#20197;&#21450;&#22312;&#19968;&#20123;&#26465;&#20214;&#19979;&#23384;&#22312;&#20445;&#25345;&#39057;&#35889;&#30340;&#20809;&#35889;&#19981;&#21464;&#24615;&#65292;&#35299;&#37322;&#20102;&#25991;&#29486;&#20013;&#35266;&#23519;&#21040;&#30340;&#32467;&#26524;&#23545;&#31216;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65288;QNNs&#65289;&#26159;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30340;&#28909;&#38376;&#26041;&#27861;&#65292;&#30001;&#20110;&#20854;&#19982;&#21464;&#20998;&#37327;&#23376;&#30005;&#36335;&#30340;&#23494;&#20999;&#32852;&#31995;&#65292;&#20351;&#20854;&#25104;&#20026;&#22312;&#22122;&#22768;&#20013;&#38388;&#23610;&#24230;&#37327;&#23376;&#65288;NISQ&#65289;&#35774;&#22791;&#19978;&#36827;&#34892;&#23454;&#38469;&#24212;&#29992;&#30340;&#26377;&#21069;&#36884;&#30340;&#20505;&#36873;&#26041;&#27861;&#12290;QNN&#21487;&#20197;&#34920;&#31034;&#20026;&#26377;&#38480;&#20613;&#37324;&#21494;&#32423;&#25968;&#65292;&#20854;&#20013;&#39057;&#29575;&#38598;&#34987;&#31216;&#20026;&#39057;&#35889;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#36825;&#20010;&#39057;&#35889;&#24182;&#35777;&#26126;&#65292;&#23545;&#20110;&#19968;&#22823;&#31867;&#27169;&#22411;&#65292;&#23384;&#22312;&#21508;&#31181;&#26497;&#22823;&#24615;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#19968;&#20123;&#28201;&#21644;&#26465;&#20214;&#19979;&#65292;&#23384;&#22312;&#19968;&#20010;&#20445;&#25345;&#39057;&#35889;&#30340;&#20855;&#26377;&#30456;&#21516;&#38754;&#31215;$A = RL$&#30340;&#27169;&#22411;&#31867;&#20043;&#38388;&#30340;&#21452;&#23556;&#65292;&#20854;&#20013;$R$&#34920;&#31034;&#37327;&#23376;&#27604;&#29305;&#25968;&#37327;&#65292;$L$&#34920;&#31034;&#23618;&#25968;&#65292;&#25105;&#20204;&#22240;&#27492;&#31216;&#20043;&#20026;&#38754;&#31215;&#20445;&#25345;&#21464;&#25442;&#19979;&#30340;&#20809;&#35889;&#19981;&#21464;&#24615;&#12290;&#36890;&#36807;&#36825;&#20010;&#65292;&#25105;&#20204;&#35299;&#37322;&#20102;&#25991;&#29486;&#20013;&#32463;&#24120;&#35266;&#23519;&#21040;&#30340;&#22312;&#32467;&#26524;&#20013;$R$&#21644;$L$&#30340;&#23545;&#31216;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#26368;&#22823;&#39057;&#35889;&#30340;&#20381;&#36182;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14515v1 Announce Type: cross  Abstract: Quantum Neural Networks (QNNs) are a popular approach in Quantum Machine Learning due to their close connection to Variational Quantum Circuits, making them a promising candidate for practical applications on Noisy Intermediate-Scale Quantum (NISQ) devices. A QNN can be expressed as a finite Fourier series, where the set of frequencies is called the frequency spectrum. We analyse this frequency spectrum and prove, for a large class of models, various maximality results. Furthermore, we prove that under some mild conditions there exists a bijection between classes of models with the same area $A = RL$ that preserves the frequency spectrum, where $R$ denotes the number of qubits and $L$ the number of layers, which we consequently call spectral invariance under area-preserving transformations. With this we explain the symmetry in $R$ and $L$ in the results often observed in the literature and show that the maximal frequency spectrum depen
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#31232;&#30095;&#35299;&#37322;&#20540;(SEV)&#65292;&#29992;&#20110;&#34913;&#37327;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20915;&#31574;&#31232;&#30095;&#24615;&#12290;&#21363;&#20351;&#27169;&#22411;&#19981;&#26159;&#31232;&#30095;&#30340;&#65292;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;SEV&#30340;&#34913;&#37327;&#19979;&#20173;&#20855;&#26377;&#20302;&#20915;&#31574;&#31232;&#30095;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.09702</link><description>&lt;p&gt;
&#26080;&#38656;&#31232;&#30095;&#27169;&#22411;&#30340;&#31232;&#30095;&#19988;&#20934;&#30830;&#30340;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Sparse and Faithful Explanations Without Sparse Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09702
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#31232;&#30095;&#35299;&#37322;&#20540;(SEV)&#65292;&#29992;&#20110;&#34913;&#37327;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20915;&#31574;&#31232;&#30095;&#24615;&#12290;&#21363;&#20351;&#27169;&#22411;&#19981;&#26159;&#31232;&#30095;&#30340;&#65292;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;SEV&#30340;&#34913;&#37327;&#19979;&#20173;&#20855;&#26377;&#20302;&#20915;&#31574;&#31232;&#30095;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21363;&#20351;&#27169;&#22411;&#19981;&#28385;&#36275;&#20840;&#23616;&#30340;&#31232;&#30095;&#24615;&#65292;&#20915;&#31574;&#20173;&#28982;&#21487;&#20197;&#29992;&#23569;&#37327;&#30340;&#29305;&#24449;&#20934;&#30830;&#22320;&#25551;&#36848;&#12290;&#20363;&#22914;&#65292;&#23545;&#20110;&#26576;&#20154;&#32780;&#35328;&#65292;&#23613;&#31649;&#27809;&#26377;&#20449;&#29992;&#21382;&#21490;&#65292;&#20294;&#30003;&#35831;&#22823;&#31508;&#36151;&#27454;&#21487;&#33021;&#20250;&#34987;&#25298;&#32477;&#65292;&#36825;&#23601;&#24573;&#35270;&#20102;&#19982;&#20854;&#20449;&#29992;&#20215;&#20540;&#30456;&#20851;&#30340;&#20219;&#20309;&#35777;&#25454;&#12290;&#22312;&#26412;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31232;&#30095;&#35299;&#37322;&#20540;&#65288;SEV&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#34913;&#37327;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#31232;&#30095;&#24615;&#30340;&#26032;&#26041;&#27861;&#12290;&#22312;&#20197;&#19978;&#36151;&#27454;&#25298;&#32477;&#30340;&#20363;&#23376;&#20013;&#65292;SEV&#20026;1&#65292;&#22240;&#20026;&#21482;&#38656;&#35201;&#19968;&#20010;&#22240;&#32032;&#26469;&#35299;&#37322;&#20026;&#20160;&#20040;&#36151;&#27454;&#34987;&#25298;&#32477;&#12290;SEV&#26159;&#23545;&#20915;&#31574;&#31232;&#30095;&#24615;&#30340;&#34913;&#37327;&#65292;&#32780;&#19981;&#26159;&#23545;&#25972;&#20307;&#27169;&#22411;&#31232;&#30095;&#24615;&#30340;&#34913;&#37327;&#65292;&#24182;&#19988;&#25105;&#20204;&#33021;&#22815;&#35777;&#26126;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#8212;&#8212;&#21363;&#20351;&#23427;&#20204;&#19981;&#26159;&#31232;&#30095;&#30340;&#8212;&#8212;&#23454;&#38469;&#19978;&#22312;SEV&#30340;&#34913;&#37327;&#19979;&#20855;&#26377;&#20302;&#20915;&#31574;&#31232;&#30095;&#24615;&#12290;SEV&#20351;&#29992;&#36229;&#31435;&#26041;&#20307;&#19978;&#30340;&#31227;&#21160;&#36827;&#34892;&#23450;&#20041;&#65292;&#20351;&#24471;SEV&#33021;&#22815;&#22312;&#21508;&#31181;&#27169;&#22411;&#31867;&#21035;&#19978;&#19968;&#33268;&#22320;&#23450;&#20041;&#65292;&#20854;&#20013;&#31227;&#21160;&#38480;&#21046;&#21453;&#26144;&#20102;&#27169;&#22411;&#30340;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09702v1 Announce Type: new  Abstract: Even if a model is not globally sparse, it is possible for decisions made from that model to be accurately and faithfully described by a small number of features. For instance, an application for a large loan might be denied to someone because they have no credit history, which overwhelms any evidence towards their creditworthiness. In this work, we introduce the Sparse Explanation Value (SEV), a new way of measuring sparsity in machine learning models. In the loan denial example above, the SEV is 1 because only one factor is needed to explain why the loan was denied. SEV is a measure of decision sparsity rather than overall model sparsity, and we are able to show that many machine learning models -- even if they are not sparse -- actually have low decision sparsity, as measured by SEV. SEV is defined using movements over a hypercube, allowing SEV to be defined consistently over various model classes, with movement restrictions reflectin
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#34701;&#21512;&#27425;&#35201;&#32467;&#26524;&#26469;&#23398;&#20064;&#20010;&#20307;&#21270;&#27835;&#30103;&#35268;&#21017;(ITR)&#65292;&#26082;&#26368;&#22823;&#21270;&#20027;&#35201;&#32467;&#26524;&#30340;&#20215;&#20540;&#20989;&#25968;&#65292;&#21448;&#23613;&#21487;&#33021;&#25509;&#36817;&#27425;&#35201;&#32467;&#26524;&#30340;&#26368;&#20248;&#35268;&#21017;&#12290;</title><link>https://arxiv.org/abs/2402.08828</link><description>&lt;p&gt;
&#20351;&#29992;&#27425;&#35201;&#32467;&#26524;&#34701;&#21512;&#20010;&#20307;&#21270;&#27835;&#30103;&#35268;&#21017;
&lt;/p&gt;
&lt;p&gt;
Fusing Individualized Treatment Rules Using Secondary Outcomes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08828
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#34701;&#21512;&#27425;&#35201;&#32467;&#26524;&#26469;&#23398;&#20064;&#20010;&#20307;&#21270;&#27835;&#30103;&#35268;&#21017;(ITR)&#65292;&#26082;&#26368;&#22823;&#21270;&#20027;&#35201;&#32467;&#26524;&#30340;&#20215;&#20540;&#20989;&#25968;&#65292;&#21448;&#23613;&#21487;&#33021;&#25509;&#36817;&#27425;&#35201;&#32467;&#26524;&#30340;&#26368;&#20248;&#35268;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#20307;&#21270;&#27835;&#30103;&#35268;&#21017;(ITR)&#26159;&#26681;&#25454;&#24739;&#32773;&#20010;&#20307;&#29305;&#24449;&#21464;&#37327;&#25512;&#33616;&#27835;&#30103;&#26041;&#26696;&#30340;&#20915;&#31574;&#35268;&#21017;&#12290;&#22312;&#35768;&#22810;&#23454;&#36341;&#20013;&#65292;&#29702;&#24819;&#30340;&#20027;&#35201;&#32467;&#26524;&#30340;ITR&#36824;&#39044;&#35745;&#23545;&#20854;&#20182;&#27425;&#35201;&#32467;&#26524;&#36896;&#25104;&#26368;&#23567;&#30340;&#21361;&#23475;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#23398;&#20064;&#19968;&#31181;ITR&#65292;&#23427;&#19981;&#20165;&#26368;&#22823;&#21270;&#20027;&#35201;&#32467;&#26524;&#30340;&#20215;&#20540;&#20989;&#25968;&#65292;&#36824;&#23613;&#21487;&#33021;&#22320;&#25509;&#36817;&#27425;&#35201;&#32467;&#26524;&#30340;&#26368;&#20248;&#35268;&#21017;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#34701;&#21512;&#24809;&#32602;&#65292;&#40723;&#21169;&#22522;&#20110;&#19981;&#21516;&#32467;&#26524;&#30340;ITR&#20135;&#29983;&#31867;&#20284;&#30340;&#25512;&#33616;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#20351;&#29992;&#26367;&#20195;&#25439;&#22833;&#20989;&#25968;&#20272;&#35745;ITR&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20027;&#35201;&#32467;&#26524;&#30340;&#20272;&#35745;ITR&#19982;&#27425;&#35201;&#32467;&#26524;&#30340;&#26368;&#20248;ITR&#20043;&#38388;&#30340;&#19968;&#33268;&#29575;&#25910;&#25947;&#27604;&#27809;&#26377;&#32771;&#34385;&#27425;&#35201;&#32467;&#26524;&#26102;&#26356;&#24555;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08828v1 Announce Type: cross Abstract: An individualized treatment rule (ITR) is a decision rule that recommends treatments for patients based on their individual feature variables. In many practices, the ideal ITR for the primary outcome is also expected to cause minimal harm to other secondary outcomes. Therefore, our objective is to learn an ITR that not only maximizes the value function for the primary outcome, but also approximates the optimal rule for the secondary outcomes as closely as possible. To achieve this goal, we introduce a fusion penalty to encourage the ITRs based on different outcomes to yield similar recommendations. Two algorithms are proposed to estimate the ITR using surrogate loss functions. We prove that the agreement rate between the estimated ITR of the primary outcome and the optimal ITRs of the secondary outcomes converges to the true agreement rate faster than if the secondary outcomes are not taken into consideration. Furthermore, we derive the
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#20998;&#21106;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#35299;&#21078;&#21487;&#25511;&#21307;&#23398;&#22270;&#20687;&#29983;&#25104;&#26041;&#27861;&#65292;&#36890;&#36807;&#38543;&#26426;&#25513;&#27169;&#28040;&#34701;&#35757;&#32451;&#31639;&#27861;&#23454;&#29616;&#23545;&#35299;&#21078;&#32422;&#26463;&#30340;&#26465;&#20214;&#21270;&#65292;&#21516;&#26102;&#25552;&#39640;&#20102;&#32593;&#32476;&#23545;&#35299;&#21078;&#30495;&#23454;&#24615;&#30340;&#23398;&#20064;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.05210</link><description>&lt;p&gt;
&#37319;&#29992;&#20998;&#21106;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#35299;&#21078;&#21487;&#25511;&#21307;&#23398;&#22270;&#20687;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Anatomically-Controllable Medical Image Generation with Segmentation-Guided Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05210
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#20998;&#21106;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#35299;&#21078;&#21487;&#25511;&#21307;&#23398;&#22270;&#20687;&#29983;&#25104;&#26041;&#27861;&#65292;&#36890;&#36807;&#38543;&#26426;&#25513;&#27169;&#28040;&#34701;&#35757;&#32451;&#31639;&#27861;&#23454;&#29616;&#23545;&#35299;&#21078;&#32422;&#26463;&#30340;&#26465;&#20214;&#21270;&#65292;&#21516;&#26102;&#25552;&#39640;&#20102;&#32593;&#32476;&#23545;&#35299;&#21078;&#30495;&#23454;&#24615;&#30340;&#23398;&#20064;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#24050;&#32463;&#23454;&#29616;&#20102;&#38750;&#24120;&#39640;&#36136;&#37327;&#30340;&#21307;&#23398;&#22270;&#20687;&#29983;&#25104;&#65292;&#21487;&#20197;&#36890;&#36807;&#20026;&#23567;&#22411;&#25110;&#19981;&#24179;&#34913;&#30340;&#25968;&#25454;&#38598;&#25552;&#20379;&#34917;&#20805;&#65292;&#20174;&#32780;&#24110;&#21161;&#20943;&#36731;&#33719;&#21462;&#21644;&#27880;&#37322;&#26032;&#22270;&#20687;&#30340;&#36153;&#29992;&#65292;&#21516;&#26102;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#20854;&#20182;&#26041;&#38754;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#22312;&#29983;&#25104;&#22270;&#20687;&#26102;&#38754;&#20020;&#30528;&#20840;&#23616;&#35299;&#21078;&#30495;&#23454;&#24615;&#30340;&#25361;&#25112;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#21078;&#21487;&#25511;&#30340;&#21307;&#23398;&#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#27599;&#20010;&#37319;&#26679;&#27493;&#39588;&#20013;&#36981;&#24490;&#22810;&#31867;&#35299;&#21078;&#20998;&#21106;&#25513;&#27169;&#65292;&#24182;&#37319;&#29992;&#38543;&#26426;&#25513;&#27169;&#28040;&#34701;&#35757;&#32451;&#31639;&#27861;&#65292;&#20197;&#23454;&#29616;&#23545;&#25152;&#36873;&#35299;&#21078;&#32422;&#26463;&#30340;&#26465;&#20214;&#21270;&#65292;&#21516;&#26102;&#20801;&#35768;&#20854;&#20182;&#35299;&#21078;&#21306;&#22495;&#30340;&#28789;&#27963;&#24615;&#12290;&#36825;&#20063;&#25913;&#21892;&#20102;&#32593;&#32476;&#22312;&#23436;&#20840;&#26080;&#26465;&#20214;&#65288;&#26080;&#32422;&#26463;&#29983;&#25104;&#65289;&#24773;&#20917;&#19979;&#23545;&#35299;&#21078;&#30495;&#23454;&#24615;&#30340;&#23398;&#20064;&#12290;&#36890;&#36807;&#23545;&#20083;&#33146;MRI&#21644;&#33145;&#37096;/&#39048;&#37096;&#21040;&#30406;&#33108;CT&#25968;&#25454;&#38598;&#30340;&#27604;&#36739;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#27169;&#22411;&#22312;&#35299;&#21078;&#30495;&#23454;&#24615;&#21644;&#36755;&#20837;&#25513;&#27169;&#20445;&#30495;&#24230;&#26041;&#38754;&#20855;&#26377;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models have enabled remarkably high-quality medical image generation, which can help mitigate the expenses of acquiring and annotating new images by supplementing small or imbalanced datasets, along with other applications. However, these are hampered by the challenge of enforcing global anatomical realism in generated images. To this end, we propose a diffusion model for anatomically-controlled medical image generation. Our model follows a multi-class anatomical segmentation mask at each sampling step and incorporates a \textit{random mask ablation} training algorithm, to enable conditioning on a selected combination of anatomical constraints while allowing flexibility in other anatomical areas. This also improves the network's learning of anatomical realism for the completely unconditional (unconstrained generation) case. Comparative evaluation on breast MRI and abdominal/neck-to-pelvis CT datasets demonstrates superior anatomical realism and input mask faithfulness over st
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#20351;&#29992;Moreau&#21253;&#32476;&#26469;&#23545;&#27979;&#24230;f-&#24046;&#24322;&#36827;&#34892;&#27491;&#21017;&#21270;&#30340;&#26041;&#27861;&#65292;&#24182;&#21033;&#29992;&#35813;&#26041;&#27861;&#20998;&#26512;&#20102;Wasserstein&#26799;&#24230;&#27969;&#12290;</title><link>https://arxiv.org/abs/2402.04613</link><description>&lt;p&gt;
&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;Moreau&#21253;&#32476;&#30340;f-&#24046;&#24322;&#30340;Wasserstein&#26799;&#24230;&#27969;
&lt;/p&gt;
&lt;p&gt;
Wasserstein Gradient Flows for Moreau Envelopes of f-Divergences in Reproducing Kernel Hilbert Spaces
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04613
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#20351;&#29992;Moreau&#21253;&#32476;&#26469;&#23545;&#27979;&#24230;f-&#24046;&#24322;&#36827;&#34892;&#27491;&#21017;&#21270;&#30340;&#26041;&#27861;&#65292;&#24182;&#21033;&#29992;&#35813;&#26041;&#27861;&#20998;&#26512;&#20102;Wasserstein&#26799;&#24230;&#27969;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#24120;&#29992;&#30340;&#27979;&#24230;f-&#24046;&#24322;&#65292;&#20363;&#22914;Kullback-Leibler&#24046;&#24322;&#65292;&#23545;&#20110;&#25152;&#28041;&#21450;&#30340;&#27979;&#24230;&#30340;&#25903;&#25345;&#23384;&#22312;&#38480;&#21046;&#12290;&#35299;&#20915;&#21150;&#27861;&#26159;&#36890;&#36807;&#19982;&#29305;&#24449;&#26680;K&#30456;&#20851;&#30340;&#24179;&#26041;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;(MMD)&#23545;f-&#24046;&#24322;&#36827;&#34892;&#27491;&#21017;&#21270;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#25152;&#35859;&#30340;&#26680;&#22343;&#20540;&#23884;&#20837;&#26469;&#26174;&#31034;&#30456;&#24212;&#30340;&#27491;&#21017;&#21270;&#21487;&#20197;&#37325;&#20889;&#20026;&#19982;K&#30456;&#20851;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#26576;&#20123;&#20989;&#25968;&#30340;Moreau&#21253;&#32476;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#20851;&#20110;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;Moreau&#21253;&#32476;&#30340;&#20247;&#25152;&#21608;&#30693;&#30340;&#32467;&#26524;&#26469;&#35777;&#26126;MMD&#27491;&#21017;&#21270;&#30340;f-&#24046;&#24322;&#21450;&#20854;&#26799;&#24230;&#30340;&#23646;&#24615;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#26469;&#20998;&#26512;&#21463;MMD&#27491;&#21017;&#21270;&#30340;f-&#24046;&#24322;&#30340;Wasserstein&#26799;&#24230;&#27969;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#32771;&#34385;&#20174;&#32463;&#39564;&#27979;&#24230;&#24320;&#22987;&#30340;Wasserstein&#26799;&#24230;&#27969;&#65292;&#24182;&#25552;&#20379;&#20351;&#29992;Tsallis-$\alpha$&#24046;&#24322;&#30340;&#27010;&#24565;&#24615;&#25968;&#20540;&#31034;&#20363;&#30340;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most commonly used $f$-divergences of measures, e.g., the Kullback-Leibler divergence, are subject to limitations regarding the support of the involved measures. A remedy consists of regularizing the $f$-divergence by a squared maximum mean discrepancy (MMD) associated with a characteristic kernel $K$. In this paper, we use the so-called kernel mean embedding to show that the corresponding regularization can be rewritten as the Moreau envelope of some function in the reproducing kernel Hilbert space associated with $K$. Then, we exploit well-known results on Moreau envelopes in Hilbert spaces to prove properties of the MMD-regularized $f$-divergences and, in particular, their gradients. Subsequently, we use our findings to analyze Wasserstein gradient flows of MMD-regularized $f$-divergences. Finally, we consider Wasserstein gradient flows starting from empirical measures and provide proof-of-the-concept numerical examples with Tsallis-$\alpha$ divergences.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377;&#20999;&#29255;Wasserstein Weisfeiler-Lehman&#22270;&#26680;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#26041;&#27861;&#65292;&#22312;&#22788;&#29702;&#22823;&#35268;&#27169;&#31232;&#30095;&#22270;&#24418;&#25968;&#25454;&#38598;&#26102;&#20855;&#26377;&#27491;&#23450;&#24615;&#21644;&#26174;&#33879;&#30340;&#22797;&#26434;&#24230;&#38477;&#20302;&#12290;</title><link>https://arxiv.org/abs/2402.03838</link><description>&lt;p&gt;
&#24102;&#26377;&#20999;&#29255;Wasserstein Weisfeiler-Lehman&#22270;&#26680;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Gaussian process regression with Sliced Wasserstein Weisfeiler-Lehman graph kernels
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03838
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377;&#20999;&#29255;Wasserstein Weisfeiler-Lehman&#22270;&#26680;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#26041;&#27861;&#65292;&#22312;&#22788;&#29702;&#22823;&#35268;&#27169;&#31232;&#30095;&#22270;&#24418;&#25968;&#25454;&#38598;&#26102;&#20855;&#26377;&#27491;&#23450;&#24615;&#21644;&#26174;&#33879;&#30340;&#22797;&#26434;&#24230;&#38477;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30417;&#30563;&#23398;&#20064;&#22312;&#35745;&#31639;&#29289;&#29702;&#39046;&#22495;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#22240;&#20026;&#23427;&#33021;&#22815;&#26377;&#25928;&#22320;&#25552;&#21462;&#22797;&#26434;&#27169;&#24335;&#65292;&#29992;&#20110;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;&#25110;&#39044;&#27979;&#26448;&#26009;&#24615;&#36136;&#31561;&#20219;&#21153;&#12290;&#20256;&#32479;&#19978;&#65292;&#36825;&#31867;&#25968;&#25454;&#38598;&#30001;&#20855;&#26377;&#22823;&#37327;&#33410;&#28857;&#30340;&#32593;&#26684;&#34920;&#31034;&#30340;&#36755;&#20837;&#65288;&#35270;&#20026;&#22270;&#24418;&#65289;&#21644;&#20351;&#29992;&#25968;&#20540;&#27714;&#35299;&#22120;&#33719;&#24471;&#30340;&#30456;&#24212;&#36755;&#20986;&#32452;&#25104;&#12290;&#36825;&#24847;&#21619;&#30528;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#24517;&#39035;&#33021;&#22815;&#22788;&#29702;&#20855;&#26377;&#36830;&#32493;&#33410;&#28857;&#23646;&#24615;&#30340;&#22823;&#35268;&#27169;&#31232;&#30095;&#22270;&#24418;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#65292;&#24341;&#20837;&#20102;&#20999;&#29255;Wasserstein Weisfeiler-Lehman&#65288;SWWL&#65289;&#22270;&#26680;&#12290;&#19982;&#29616;&#26377;&#30340;&#22270;&#26680;&#30456;&#27604;&#65292;&#25152;&#25552;&#20986;&#30340;SWWL&#26680;&#20855;&#26377;&#27491;&#23450;&#24615;&#21644;&#26174;&#33879;&#30340;&#22797;&#26434;&#24230;&#38477;&#20302;&#65292;&#20351;&#20854;&#33021;&#22815;&#22788;&#29702;&#27492;&#21069;&#19981;&#21487;&#22788;&#29702;&#30340;&#25968;&#25454;&#38598;&#12290;&#26032;&#30340;&#26680;&#39318;&#20808;&#22312;&#20998;&#23376;&#22270;&#20998;&#31867;&#20013;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Supervised learning has recently garnered significant attention in the field of computational physics due to its ability to effectively extract complex patterns for tasks like solving partial differential equations, or predicting material properties. Traditionally, such datasets consist of inputs given as meshes with a large number of nodes representing the problem geometry (seen as graphs), and corresponding outputs obtained with a numerical solver. This means the supervised learning model must be able to handle large and sparse graphs with continuous node attributes. In this work, we focus on Gaussian process regression, for which we introduce the Sliced Wasserstein Weisfeiler-Lehman (SWWL) graph kernel. In contrast to existing graph kernels, the proposed SWWL kernel enjoys positive definiteness and a drastic complexity reduction, which  makes it possible to process datasets that were previously impossible to handle. The new kernel is first validated on graph classification for molec
&lt;/p&gt;</description></item><item><title>&#20559;&#20519;&#30340;&#38750;&#21709;&#24212;&#23545;&#20027;&#21160;&#23398;&#20064;&#27169;&#22411;&#24615;&#33021;&#26377;&#23475;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25104;&#26412;-based &#20462;&#27491;&#31574;&#30053;&#26469;&#20943;&#36731;&#20854;&#24433;&#21709;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#26377;&#25928;&#12290;</title><link>https://arxiv.org/abs/2312.08150</link><description>&lt;p&gt;
&#20855;&#26377;&#20559;&#20519;&#30340;&#38750;&#21709;&#24212;&#38382;&#39064;&#30340;&#20027;&#21160;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Active learning with biased non-response to label requests
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.08150
&lt;/p&gt;
&lt;p&gt;
&#20559;&#20519;&#30340;&#38750;&#21709;&#24212;&#23545;&#20027;&#21160;&#23398;&#20064;&#27169;&#22411;&#24615;&#33021;&#26377;&#23475;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25104;&#26412;-based &#20462;&#27491;&#31574;&#30053;&#26469;&#20943;&#36731;&#20854;&#24433;&#21709;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#21160;&#23398;&#20064;&#21487;&#20197;&#36890;&#36807;&#35782;&#21035;&#33719;&#21462;&#26368;&#20855;&#20449;&#24687;&#37327;&#30340;&#26032;&#26631;&#31614;&#26469;&#25552;&#39640;&#35757;&#32451;&#39044;&#27979;&#27169;&#22411;&#30340;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#22312;&#26631;&#31614;&#35831;&#27714;&#30340;&#38750;&#21709;&#24212;&#24773;&#20917;&#19979;&#65292;&#20250;&#24433;&#21709;&#20027;&#21160;&#23398;&#20064;&#22312;&#23454;&#38469;&#29615;&#22659;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#32771;&#34385;&#25968;&#25454;&#20013;&#23384;&#22312;&#30340;&#38750;&#21709;&#24212;&#31867;&#22411;&#26469;&#27010;&#24565;&#21270;&#36825;&#31181;&#36864;&#21270;&#65292;&#35777;&#26126;&#20559;&#20519;&#30340;&#38750;&#21709;&#24212;&#23545;&#27169;&#22411;&#24615;&#33021;&#29305;&#21035;&#26377;&#23475;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#22312;&#26631;&#31614;&#36807;&#31243;&#22825;&#28982;&#20381;&#36182;&#29992;&#25143;&#20132;&#20114;&#30340;&#29615;&#22659;&#20013;&#65292;&#20559;&#20519;&#30340;&#38750;&#21709;&#24212;&#24456;&#21487;&#33021;&#20250;&#20986;&#29616;&#12290;&#20026;&#20102;&#20943;&#36731;&#20559;&#20519;&#30340;&#38750;&#21709;&#24212;&#24433;&#21709;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25104;&#26412;&#30340;&#20462;&#27491;&#37319;&#26679;&#31574;&#30053;&#8212;&#8212;&#39044;&#26399;&#25928;&#29992;&#30340;&#19978;&#30028;&#32622;&#20449;&#24230;&#65288;UCB-EU&#65289;, &#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#21512;&#29702;&#22320;&#24212;&#29992;&#20110;&#20219;&#20309;&#20027;&#21160;&#23398;&#20064;&#31639;&#27861;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25104;&#21151;&#22320;&#20943;&#23569;&#20102;&#22312;&#35768;&#22810;&#22330;&#26223;&#20013;&#26631;&#31614;&#38750;&#21709;&#24212;&#36896;&#25104;&#30340;&#20260;&#23475;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.08150v2 Announce Type: replace  Abstract: Active learning can improve the efficiency of training prediction models by identifying the most informative new labels to acquire. However, non-response to label requests can impact active learning's effectiveness in real-world contexts. We conceptualise this degradation by considering the type of non-response present in the data, demonstrating that biased non-response is particularly detrimental to model performance. We argue that biased non-response is likely in contexts where the labelling process, by nature, relies on user interactions. To mitigate the impact of biased non-response, we propose a cost-based correction to the sampling strategy--the Upper Confidence Bound of the Expected Utility (UCB-EU)--that can, plausibly, be applied to any active learning algorithm. Through experiments, we demonstrate that our method successfully reduces the harm from labelling non-response in many settings. However, we also characterise settin
&lt;/p&gt;</description></item><item><title>&#22312;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20013;&#65292;&#36890;&#36807;&#20004;&#38454;&#27573;&#26041;&#27861;&#23398;&#20064;&#26410;&#30693;&#24178;&#39044;&#30446;&#26631;&#30340;&#22806;&#29983;&#22122;&#22768;&#65292;&#24182;&#23558;&#20854;&#19982;&#30456;&#24212;&#30340;&#20869;&#29983;&#21464;&#37327;&#21305;&#37197;&#65292;&#26377;&#25928;&#22320;&#35782;&#21035;&#24178;&#39044;&#30446;&#26631;&#12290;</title><link>https://arxiv.org/abs/2312.06091</link><description>&lt;p&gt;
&#20174;&#24322;&#26500;&#25968;&#25454;&#20013;&#23398;&#20064;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20013;&#30340;&#26410;&#30693;&#24178;&#39044;&#30446;&#26631;
&lt;/p&gt;
&lt;p&gt;
Learning Unknown Intervention Targets in Structural Causal Models from Heterogeneous Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.06091
&lt;/p&gt;
&lt;p&gt;
&#22312;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20013;&#65292;&#36890;&#36807;&#20004;&#38454;&#27573;&#26041;&#27861;&#23398;&#20064;&#26410;&#30693;&#24178;&#39044;&#30446;&#26631;&#30340;&#22806;&#29983;&#22122;&#22768;&#65292;&#24182;&#23558;&#20854;&#19982;&#30456;&#24212;&#30340;&#20869;&#29983;&#21464;&#37327;&#21305;&#37197;&#65292;&#26377;&#25928;&#22320;&#35782;&#21035;&#24178;&#39044;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20013;&#35782;&#21035;&#26410;&#30693;&#24178;&#39044;&#30446;&#26631;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#25105;&#20204;&#21487;&#20197;&#35775;&#38382;&#20174;&#22810;&#20010;&#29615;&#22659;&#20013;&#25910;&#38598;&#30340;&#24322;&#26500;&#25968;&#25454;&#12290;&#26410;&#30693;&#24178;&#39044;&#30446;&#26631;&#26159;&#19968;&#32452;&#20869;&#29983;&#21464;&#37327;&#65292;&#20854;&#30456;&#24212;&#30340;&#22806;&#29983;&#22122;&#22768;&#22312;&#19981;&#21516;&#29615;&#22659;&#20013;&#21457;&#29983;&#21464;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#26041;&#27861;&#65292;&#31532;&#19968;&#38454;&#27573;&#20013;&#24674;&#22797;&#20102;&#36328;&#19981;&#21516;&#29615;&#22659;&#21457;&#29983;&#21464;&#21270;&#30340;&#26410;&#30693;&#24178;&#39044;&#30446;&#26631;&#23545;&#24212;&#30340;&#22806;&#29983;&#22122;&#22768;&#12290;&#22312;&#31532;&#20108;&#38454;&#27573;&#65292;&#24674;&#22797;&#30340;&#22122;&#22768;&#19982;&#30456;&#24212;&#30340;&#20869;&#29983;&#21464;&#37327;&#36827;&#34892;&#21305;&#37197;&#12290;&#23545;&#20110;&#24674;&#22797;&#38454;&#27573;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23398;&#20064;&#36825;&#20123;&#22806;&#29983;&#22122;&#22768;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#21487;&#36798;&#21040;&#26576;&#31181;&#20998;&#37327;&#26041;&#21521;&#21487;&#36870;&#36716;&#25442;&#12290;&#23545;&#20110;&#21305;&#37197;&#38454;&#27573;&#65292;&#22312;&#22240;&#26524;&#20805;&#20998;&#24615;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#26041;&#27861;&#21487;&#20197;&#21807;&#19968;&#22320;&#35782;&#21035;&#24178;&#39044;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.06091v2 Announce Type: replace-cross  Abstract: We study the problem of identifying the unknown intervention targets in structural causal models where we have access to heterogeneous data collected from multiple environments. The unknown intervention targets are the set of endogenous variables whose corresponding exogenous noises change across the environments. We propose a two-phase approach which in the first phase recovers the exogenous noises corresponding to unknown intervention targets whose distributions have changed across environments. In the second phase, the recovered noises are matched with the corresponding endogenous variables. For the recovery phase, we provide sufficient conditions for learning these exogenous noises up to some component-wise invertible transformation. For the matching phase, under the causal sufficiency assumption, we show that the proposed method uniquely identifies the intervention targets. In the presence of latent confounders, the interv
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#21033;&#29992;&#24314;&#31569;&#29289;&#29702;&#23398;&#27934;&#23519;&#23454;&#29616;&#22266;&#26377;&#21487;&#35299;&#37322;&#30340;&#33021;&#28304;&#25968;&#25454;&#25554;&#34917;&#27169;&#22411;PI-DAE&#65292;&#22312;&#25439;&#22833;&#20989;&#25968;&#20013;&#24341;&#20837;&#29289;&#29702;&#21551;&#21457;&#36719;&#32422;&#26463;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#21487;&#35299;&#37322;&#30340;&#39044;&#27979;&#12290;</title><link>https://arxiv.org/abs/2311.16632</link><description>&lt;p&gt;
&#25171;&#24320;&#40657;&#21283;&#23376;&#65306;&#21033;&#29992;&#24314;&#31569;&#29289;&#29702;&#23398;&#27934;&#23519;&#23454;&#29616;&#22266;&#26377;&#21487;&#35299;&#37322;&#30340;&#33021;&#28304;&#25968;&#25454;&#25554;&#34917;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Opening the Black Box: Towards inherently interpretable energy data imputation models using building physics insight
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.16632
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#21033;&#29992;&#24314;&#31569;&#29289;&#29702;&#23398;&#27934;&#23519;&#23454;&#29616;&#22266;&#26377;&#21487;&#35299;&#37322;&#30340;&#33021;&#28304;&#25968;&#25454;&#25554;&#34917;&#27169;&#22411;PI-DAE&#65292;&#22312;&#25439;&#22833;&#20989;&#25968;&#20013;&#24341;&#20837;&#29289;&#29702;&#21551;&#21457;&#36719;&#32422;&#26463;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#21487;&#35299;&#37322;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32570;&#22833;&#25968;&#25454;&#32463;&#24120;&#34987;&#24314;&#31569;&#33021;&#28304;&#24314;&#27169;&#39046;&#22495;&#30340;&#23454;&#36341;&#32773;&#21644;&#30740;&#31350;&#20154;&#21592;&#35266;&#23519;&#21040;&#12290;&#22312;&#36825;&#26041;&#38754;&#65292;&#36890;&#24120;&#38656;&#35201;&#20808;&#36827;&#30340;&#25968;&#25454;&#39537;&#21160;&#35299;&#20915;&#26041;&#26696;&#65292;&#22914;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#21453;&#26144;&#36825;&#20123;&#24322;&#24120;&#30340;&#38750;&#32447;&#24615;&#34892;&#20026;&#12290;&#20316;&#20026;&#19982;&#28145;&#24230;&#23398;&#20064;&#30456;&#20851;&#30340;&#19968;&#20010;&#25345;&#32493;&#30740;&#31350;&#38382;&#39064;&#65292;&#21487;&#20197;&#36890;&#36807;&#22312;&#32593;&#32476;&#20013;&#24341;&#20837;&#20808;&#39564;&#30693;&#35782;&#26469;&#25506;&#32034;&#27169;&#22411;&#22312;&#26377;&#38480;&#25968;&#25454;&#35774;&#32622;&#19979;&#30340;&#36866;&#29992;&#24615;&#12290;&#36825;&#31181;&#31574;&#30053;&#20063;&#21487;&#20197;&#23548;&#33268;&#26356;&#21487;&#35299;&#37322;&#30340;&#39044;&#27979;&#65292;&#20174;&#32780;&#20419;&#36827;&#26041;&#27861;&#30340;&#29616;&#22330;&#24212;&#29992;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#26088;&#22312;&#25552;&#20986;&#29289;&#29702;&#21551;&#21457;&#22411;&#21435;&#22122;&#33258;&#21160;&#32534;&#30721;&#22120;(PI-DAE)&#29992;&#20110;&#21830;&#19994;&#24314;&#31569;&#30340;&#32570;&#22833;&#25968;&#25454;&#25554;&#34917;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#23558;&#29289;&#29702;&#21551;&#21457;&#36719;&#32422;&#26463;&#24378;&#21152;&#32473;&#21435;&#22122;&#33258;&#21160;&#32534;&#30721;&#22120;(DAE)&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#20026;&#20102;&#37327;&#21270;&#29289;&#29702;&#32452;&#20214;&#30340;&#22909;&#22788;&#65292;&#36827;&#34892;&#20102;&#19968;&#39033;&#28040;&#34701;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.16632v2 Announce Type: replace-cross  Abstract: Missing data are frequently observed by practitioners and researchers in the building energy modeling community. In this regard, advanced data-driven solutions, such as Deep Learning methods, are typically required to reflect the non-linear behavior of these anomalies. As an ongoing research question related to Deep Learning, a model's applicability to limited data settings can be explored by introducing prior knowledge in the network. This same strategy can also lead to more interpretable predictions, hence facilitating the field application of the approach. For that purpose, the aim of this paper is to propose the use of Physics-informed Denoising Autoencoders (PI-DAE) for missing data imputation in commercial buildings. In particular, the presented method enforces physics-inspired soft constraints to the loss function of a Denoising Autoencoder (DAE). In order to quantify the benefits of the physical component, an ablation s
&lt;/p&gt;</description></item><item><title>&#23637;&#31034;&#20102;&#26925;&#22278;&#23545;&#31216;&#20998;&#24067;&#28151;&#21512;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#19968;&#33268;&#24615;&#65292;&#20026;&#22522;&#20110;&#38750;&#21442;&#25968;&#20998;&#24067;&#30340;&#32858;&#31867;&#25552;&#20379;&#20102;&#29702;&#35770;&#20381;&#25454;&#12290;</title><link>https://arxiv.org/abs/2311.06108</link><description>&lt;p&gt;
&#22522;&#20110;&#26925;&#22278;&#23545;&#31216;&#20998;&#24067;&#28151;&#21512;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#21644;&#32858;&#31867;&#30340;&#38750;&#21442;&#25968;&#19968;&#33268;&#24615;
&lt;/p&gt;
&lt;p&gt;
Nonparametric consistency for maximum likelihood estimation and clustering based on mixtures of elliptically-symmetric distributions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.06108
&lt;/p&gt;
&lt;p&gt;
&#23637;&#31034;&#20102;&#26925;&#22278;&#23545;&#31216;&#20998;&#24067;&#28151;&#21512;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#19968;&#33268;&#24615;&#65292;&#20026;&#22522;&#20110;&#38750;&#21442;&#25968;&#20998;&#24067;&#30340;&#32858;&#31867;&#25552;&#20379;&#20102;&#29702;&#35770;&#20381;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#23637;&#31034;&#20102;&#26925;&#22278;&#23545;&#31216;&#20998;&#24067;&#28151;&#21512;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#23545;&#20854;&#24635;&#20307;&#29256;&#26412;&#30340;&#19968;&#33268;&#24615;&#65292;&#20854;&#20013;&#28508;&#22312;&#20998;&#24067;P&#26159;&#38750;&#21442;&#25968;&#30340;&#65292;&#24182;&#19981;&#19968;&#23450;&#23646;&#20110;&#20272;&#35745;&#22120;&#25152;&#22522;&#20110;&#30340;&#28151;&#21512;&#31867;&#21035;&#12290;&#24403;P&#26159;&#36275;&#22815;&#20998;&#31163;&#20294;&#38750;&#21442;&#25968;&#30340;&#20998;&#24067;&#28151;&#21512;&#26102;&#65292;&#34920;&#26126;&#20102;&#20272;&#35745;&#22120;&#30340;&#24635;&#20307;&#29256;&#26412;&#30340;&#32452;&#20998;&#23545;&#24212;&#20110;P&#30340;&#33391;&#22909;&#20998;&#31163;&#32452;&#20998;&#12290;&#36825;&#20026;&#22312;P&#20855;&#26377;&#33391;&#22909;&#20998;&#31163;&#23376;&#24635;&#20307;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;&#36825;&#26679;&#30340;&#20272;&#35745;&#22120;&#36827;&#34892;&#32858;&#31867;&#20998;&#26512;&#25552;&#20379;&#20102;&#19968;&#20123;&#29702;&#35770;&#19978;&#30340;&#29702;&#25454;&#65292;&#21363;&#20351;&#36825;&#20123;&#23376;&#24635;&#20307;&#19982;&#28151;&#21512;&#27169;&#22411;&#25152;&#20551;&#35774;&#30340;&#19981;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.06108v2 Announce Type: replace-cross  Abstract: The consistency of the maximum likelihood estimator for mixtures of elliptically-symmetric distributions for estimating its population version is shown, where the underlying distribution $P$ is nonparametric and does not necessarily belong to the class of mixtures on which the estimator is based. In a situation where $P$ is a mixture of well enough separated but nonparametric distributions it is shown that the components of the population version of the estimator correspond to the well separated components of $P$. This provides some theoretical justification for the use of such estimators for cluster analysis in case that $P$ has well separated subpopulations even if these subpopulations differ from what the mixture model assumes.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20844;&#24179;&#21463;&#30417;&#30563;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#31616;&#21333;&#38543;&#26426;&#37319;&#26679;&#22120;&#22788;&#29702;&#25935;&#24863;&#23646;&#24615;&#65292;&#21487;&#20197;&#26356;&#24191;&#27867;&#22320;&#36866;&#29992;&#20110;&#23454;&#36341;&#20013;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#32676;&#20307;&#32423;&#21035;&#22788;&#29702;&#20844;&#24179;&#24863;&#30693;&#30340;&#35757;&#32451;&#26694;&#26550;&#12290;</title><link>https://arxiv.org/abs/2311.05866</link><description>&lt;p&gt;
&#20844;&#24179;&#21463;&#30417;&#30563;&#23398;&#20064;&#20013;&#20855;&#26377;&#25935;&#24863;&#23646;&#24615;&#30340;&#31616;&#21333;&#38543;&#26426;&#37319;&#26679;&#22120;
&lt;/p&gt;
&lt;p&gt;
Fair Supervised Learning with A Simple Random Sampler of Sensitive Attributes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.05866
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20844;&#24179;&#21463;&#30417;&#30563;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#31616;&#21333;&#38543;&#26426;&#37319;&#26679;&#22120;&#22788;&#29702;&#25935;&#24863;&#23646;&#24615;&#65292;&#21487;&#20197;&#26356;&#24191;&#27867;&#22320;&#36866;&#29992;&#20110;&#23454;&#36341;&#20013;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#32676;&#20307;&#32423;&#21035;&#22788;&#29702;&#20844;&#24179;&#24863;&#30693;&#30340;&#35757;&#32451;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#25968;&#25454;&#39537;&#21160;&#30340;&#20915;&#31574;&#36807;&#31243;&#22312;&#24037;&#19994;&#24212;&#29992;&#20013;&#21464;&#24471;&#20027;&#23548;&#65292;&#21508;&#20010;&#39046;&#22495;&#23545;&#20855;&#26377;&#20844;&#24179;&#24847;&#35782;&#30340;&#26426;&#22120;&#23398;&#20064;&#24341;&#36215;&#20102;&#26497;&#22823;&#20851;&#27880;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#21033;&#29992;&#25935;&#24863;&#23646;&#24615;&#30340;&#31616;&#21333;&#38543;&#26426;&#37319;&#26679;&#22120;&#23398;&#20064;&#20844;&#24179;&#24809;&#32602;&#30340;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#29992;&#20110;&#38750;&#27495;&#35270;&#24615;&#21463;&#30417;&#30563;&#23398;&#20064;&#12290;&#19982;&#35768;&#22810;&#29616;&#26377;&#20316;&#21697;&#22522;&#26412;&#20381;&#36182;&#20110;&#25935;&#24863;&#23646;&#24615;&#21644;&#21709;&#24212;&#21464;&#37327;&#30340;&#31163;&#25955;&#24615;&#19981;&#21516;&#65292;&#25152;&#25552;&#20986;&#30340;&#24809;&#32602;&#33021;&#22815;&#22788;&#29702;&#22810;&#31181;&#26684;&#24335;&#30340;&#25935;&#24863;&#23646;&#24615;&#65292;&#22240;&#27492;&#22312;&#23454;&#36341;&#20013;&#27604;&#35768;&#22810;&#29616;&#26377;&#31639;&#27861;&#26356;&#20855;&#24191;&#27867;&#36866;&#29992;&#24615;&#12290;&#35813;&#24809;&#32602;&#20351;&#25105;&#20204;&#33021;&#22815;&#26500;&#24314;&#19968;&#20010;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#32676;&#20307;&#32423;&#21035;&#22788;&#29702;&#20844;&#24179;&#24863;&#30693;&#30340;&#35757;&#32451;&#26694;&#26550;&#12290;&#23454;&#35777;&#35777;&#25454;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#22312;&#27969;&#34892;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#27604;&#31454;&#20105;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#25928;&#29992;&#21644;&#20844;&#24179;&#24230;&#37327;&#12290;&#25105;&#20204;&#36824;&#22312;&#29702;&#35770;&#19978;&#23545;&#20272;&#35745;&#35823;&#24046;&#21644;&#25439;&#22833;&#36827;&#34892;&#20102;&#34920;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.05866v2 Announce Type: replace-cross  Abstract: As the data-driven decision process becomes dominating for industrial applications, fairness-aware machine learning arouses great attention in various areas. This work proposes fairness penalties learned by neural networks with a simple random sampler of sensitive attributes for non-discriminatory supervised learning. In contrast to many existing works that critically rely on the discreteness of sensitive attributes and response variables, the proposed penalty is able to handle versatile formats of the sensitive attributes, so it is more extensively applicable in practice than many existing algorithms. This penalty enables us to build a computationally efficient group-level in-processing fairness-aware training framework. Empirical evidence shows that our framework enjoys better utility and fairness measures on popular benchmark data sets than competing methods. We also theoretically characterize estimation errors and loss of u
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26435;&#37325;&#20849;&#20139;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#23545;&#31070;&#32463;&#32593;&#32476;&#26435;&#37325;&#30340;&#24809;&#32602;&#65292;&#35774;&#35745;&#24182;&#23454;&#29616;&#20102;&#19968;&#20010;&#26032;&#22411;&#24182;&#34892;&#31639;&#27861;&#65292;&#20351;&#32593;&#32476;&#33021;&#22815;&#23398;&#20064;&#21367;&#31215;&#26679;&#24335;&#30340;&#28388;&#27874;&#22120;</title><link>https://arxiv.org/abs/2311.03096</link><description>&lt;p&gt;
&#26435;&#37325;&#20849;&#20139;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Weight-Sharing Regularization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.03096
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26435;&#37325;&#20849;&#20139;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#23545;&#31070;&#32463;&#32593;&#32476;&#26435;&#37325;&#30340;&#24809;&#32602;&#65292;&#35774;&#35745;&#24182;&#23454;&#29616;&#20102;&#19968;&#20010;&#26032;&#22411;&#24182;&#34892;&#31639;&#27861;&#65292;&#20351;&#32593;&#32476;&#33021;&#22815;&#23398;&#20064;&#21367;&#31215;&#26679;&#24335;&#30340;&#28388;&#27874;&#22120;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#65292;&#26435;&#37325;&#20849;&#20139;&#26159;&#26080;&#22788;&#19981;&#22312;&#30340;&#12290;&#21463;&#27492;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#31070;&#32463;&#32593;&#32476;&#30340;&#26435;&#37325;$w \in \mathbb{R}^d$&#36827;&#34892;&#8220;&#26435;&#37325;&#20849;&#20139;&#27491;&#21017;&#21270;&#8221;&#24809;&#32602;&#65292;&#23450;&#20041;&#20026;$\mathcal{R}(w) = \frac{1}{d - 1}\sum_{i &gt; j}^d |w_i - w_j|$&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;$\mathcal{R}$&#30340;&#36817;&#31471;&#26144;&#23556;&#65292;&#24182;&#36890;&#36807;&#19968;&#20010;&#29289;&#29702;&#31890;&#23376;&#30456;&#20114;&#20316;&#29992;&#30340;&#31995;&#32479;&#23545;&#20854;&#36827;&#34892;&#20102;&#30452;&#35266;&#35299;&#37322;&#12290;&#25105;&#20204;&#36824;&#24182;&#34892;&#21270;&#20102;&#29616;&#26377;&#30340;$\operatorname{prox}_\mathcal{R}$&#31639;&#27861;&#65288;&#22312;GPU&#19978;&#36816;&#34892;&#65289;&#65292;&#24182;&#21457;&#29616;&#20854;&#20013;&#19968;&#31181;&#22312;&#23454;&#36341;&#20013;&#24555;&#36895;&#65292;&#20294;&#23545;&#20110;&#26368;&#22351;&#24773;&#20917;&#36755;&#20837;&#36739;&#24930;&#65288;$O(d)$&#65289;&#12290;&#21033;&#29992;&#29289;&#29702;&#35299;&#37322;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24182;&#34892;&#31639;&#27861;&#65292;&#24403;&#26377;&#36275;&#22815;&#30340;&#22788;&#29702;&#22120;&#21487;&#29992;&#26102;&#65292;&#20854;&#36816;&#34892;&#26102;&#38388;&#20026;$O(\log^3 d)$&#65292;&#20174;&#32780;&#20445;&#35777;&#20102;&#24555;&#36895;&#35757;&#32451;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#26174;&#31034;&#65292;&#26435;&#37325;&#20849;&#20139;&#27491;&#21017;&#21270;&#20351;&#20840;&#36830;&#25509;&#32593;&#32476;&#33021;&#22815;&#23398;&#20064;&#21367;&#31215;&#26679;&#24335;&#30340;&#28388;&#27874;&#22120;&#65292;&#21363;&#20351;&#20687;&#32032;&#24050;&#34987;&#25171;&#20081;&#65292;&#32780;&#21367;&#31215;&#31070;&#32463;&#32593;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.03096v2 Announce Type: replace  Abstract: Weight-sharing is ubiquitous in deep learning. Motivated by this, we propose a "weight-sharing regularization" penalty on the weights $w \in \mathbb{R}^d$ of a neural network, defined as $\mathcal{R}(w) = \frac{1}{d - 1}\sum_{i &gt; j}^d |w_i - w_j|$. We study the proximal mapping of $\mathcal{R}$ and provide an intuitive interpretation of it in terms of a physical system of interacting particles. We also parallelize existing algorithms for $\operatorname{prox}_\mathcal{R}$ (to run on GPU) and find that one of them is fast in practice but slow ($O(d)$) for worst-case inputs. Using the physical interpretation, we design a novel parallel algorithm which runs in $O(\log^3 d)$ when sufficient processors are available, thus guaranteeing fast training. Our experiments reveal that weight-sharing regularization enables fully connected networks to learn convolution-like filters even when pixels have been shuffled while convolutional neural netwo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20272;&#35745;&#32479;&#35745;&#27169;&#22411;&#30340;&#26367;&#20195;&#24615;&#36125;&#21494;&#26031;&#32852;&#21512;&#25512;&#26029;&#65288;BFI&#65289;&#26694;&#26550;&#65292;&#26088;&#22312;&#22788;&#29702;&#25968;&#25454;&#38598;&#36739;&#23567;&#30340;&#24773;&#20917;&#65292;&#24182;&#33021;&#22815;&#33719;&#21462;&#26356;&#22823;&#25968;&#25454;&#38598;&#30340;&#32479;&#35745;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2302.07677</link><description>&lt;p&gt;
&#22522;&#20110;&#38750;&#20849;&#20139;&#22810;&#20013;&#24515;&#25968;&#25454;&#38598;&#30340;&#36125;&#21494;&#26031;&#32852;&#21512;&#25512;&#26029;&#29992;&#20110;&#20272;&#35745;&#32479;&#35745;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Bayesian Federated Inference for estimating Statistical Models based on Non-shared Multicenter Data sets
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.07677
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20272;&#35745;&#32479;&#35745;&#27169;&#22411;&#30340;&#26367;&#20195;&#24615;&#36125;&#21494;&#26031;&#32852;&#21512;&#25512;&#26029;&#65288;BFI&#65289;&#26694;&#26550;&#65292;&#26088;&#22312;&#22788;&#29702;&#25968;&#25454;&#38598;&#36739;&#23567;&#30340;&#24773;&#20917;&#65292;&#24182;&#33021;&#22815;&#33719;&#21462;&#26356;&#22823;&#25968;&#25454;&#38598;&#30340;&#32479;&#35745;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22810;&#21464;&#37327;&#20998;&#26512;&#35782;&#21035;&#30446;&#26631;&#32467;&#26524;&#30340;&#39044;&#27979;&#22240;&#32032;&#22312;&#25968;&#25454;&#38598;&#36739;&#23567;&#26102;&#24448;&#24448;&#24456;&#22256;&#38590;&#12290;&#23558;&#26469;&#33258;&#19981;&#21516;&#21307;&#30103;&#20013;&#24515;&#30340;&#25968;&#25454;&#21512;&#24182;&#21040;&#19968;&#20010;&#65288;&#26356;&#22823;&#65289;&#25968;&#25454;&#24211;&#20013;&#23558;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#23454;&#38469;&#19978;&#30001;&#20110;&#30417;&#31649;&#21644;&#29289;&#27969;&#38382;&#39064;&#32780;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#26159;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#26088;&#22312;&#20174;&#19981;&#21516;&#25968;&#25454;&#20013;&#24515;&#30340;&#26412;&#22320;&#25512;&#26029;&#26500;&#24314;&#20986;&#25968;&#25454;&#38598;&#21512;&#24182;&#21518;&#23558;&#20250;&#25512;&#26029;&#20986;&#30340;&#20869;&#23481;&#12290;&#23427;&#26088;&#22312;&#33719;&#21462;&#26356;&#22823;&#25968;&#25454;&#38598;&#30340;&#32479;&#35745;&#33021;&#21147;&#65292;&#32780;&#23454;&#38469;&#19978;&#24182;&#26410;&#21019;&#24314;&#23427;&#20204;&#12290;FL&#31574;&#30053;&#24182;&#38750;&#24635;&#26159;&#39640;&#25928;&#21644;&#31934;&#30830;&#12290;&#22240;&#27492;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23436;&#21892;&#24182;&#23454;&#26045;&#20102;&#19968;&#31181;&#29992;&#20110;&#20855;&#26377;&#30456;&#21516;&#30446;&#30340;&#30340;&#22810;&#20013;&#24515;&#25968;&#25454;&#30340;&#26367;&#20195;&#24615;&#36125;&#21494;&#26031;&#32852;&#21512;&#25512;&#26029;&#65288;BFI&#65289;&#26694;&#26550;&#12290;BFI&#26694;&#26550;&#26088;&#22312;&#36890;&#36807;&#22312;&#26412;&#22320;&#25512;&#26029;&#19981;&#20165;&#26368;&#20339;&#21442;&#25968;&#20540;&#65292;&#36824;&#21478;&#22806;&#19968;&#20123;&#20869;&#23481;&#26469;&#22788;&#29702;&#25968;&#25454;&#38598;&#36739;&#23567;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2302.07677v2 Announce Type: replace-cross  Abstract: Identifying predictive factors for an outcome of interest via a multivariable analysis is often difficult when the data set is small. Combining data from different medical centers into a single (larger) database would alleviate this problem, but is in practice challenging due to regulatory and logistic problems. Federated Learning (FL) is a machine learning approach that aims to construct from local inferences in separate data centers what would have been inferred had the data sets been merged. It seeks to harvest the statistical power of larger data sets without actually creating them. The FL strategy is not always efficient and precise. Therefore, in this paper we refine and implement an alternative Bayesian Federated Inference (BFI) framework for multicenter data with the same aim as FL. The BFI framework is designed to cope with small data sets by inferring locally not only the optimal parameter values, but also additional 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#21306;&#20998;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26159;&#39044;&#27979;&#20010;&#20307;&#26410;&#26469;&#36824;&#26159;&#37325;&#22797;&#36807;&#21435;&#27169;&#24335;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21521;&#21518;&#22522;&#32447;&#27979;&#35797;&#23637;&#31034;&#27169;&#22411;&#26159;&#21542;&#22238;&#28335;&#36807;&#21435;&#65292;&#24182;&#22312;&#38271;&#26399;&#38754;&#26495;&#35843;&#30740;&#20219;&#21153;&#20013;&#39564;&#35777;&#20102;&#35813;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2206.11673</link><description>&lt;p&gt;
&#24744;&#30340;&#27169;&#22411;&#26159;&#22312;&#39044;&#27979;&#36807;&#21435;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Is your model predicting the past?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2206.11673
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#21306;&#20998;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26159;&#39044;&#27979;&#20010;&#20307;&#26410;&#26469;&#36824;&#26159;&#37325;&#22797;&#36807;&#21435;&#27169;&#24335;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21521;&#21518;&#22522;&#32447;&#27979;&#35797;&#23637;&#31034;&#27169;&#22411;&#26159;&#21542;&#22238;&#28335;&#36807;&#21435;&#65292;&#24182;&#22312;&#38271;&#26399;&#38754;&#26495;&#35843;&#30740;&#20219;&#21153;&#20013;&#39564;&#35777;&#20102;&#35813;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20309;&#26102;&#39044;&#27979;&#20010;&#20307;&#30340;&#26410;&#26469;&#65292;&#20309;&#26102;&#37325;&#22797;&#39044;&#20808;&#23384;&#22312;&#30340;&#27169;&#24335;&#65311;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#36825;&#20004;&#31181;&#39044;&#27979;&#36335;&#24452;&#36827;&#34892;&#21306;&#20998;&#65292;&#36825;&#19968;&#25552;&#35758;&#24471;&#21040;&#20102;&#29702;&#35770;&#12289;&#32463;&#39564;&#21644;&#35268;&#33539;&#24615;&#35770;&#35777;&#30340;&#25903;&#25345;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26680;&#24515;&#26159;&#19968;&#31867;&#31616;&#21333;&#39640;&#25928;&#30340;&#32479;&#35745;&#27979;&#35797;&#65292;&#31216;&#20026;&#8220;&#21521;&#21518;&#22522;&#32447;&#8221;&#65292;&#21487;&#20197;&#23637;&#31034;&#27169;&#22411;&#26159;&#21542;&#20197;&#21450;&#22312;&#20309;&#31181;&#31243;&#24230;&#19978;&#37325;&#26032;&#35762;&#36848;&#20102;&#36807;&#21435;&#12290;&#25105;&#20204;&#30340;&#32479;&#35745;&#29702;&#35770;&#20026;&#35299;&#37322;&#21521;&#21518;&#22522;&#32447;&#25552;&#20379;&#20102;&#25351;&#23548;&#65292;&#24182;&#24314;&#31435;&#20102;&#19981;&#21516;&#22522;&#32447;&#21644;&#29087;&#24713;&#32479;&#35745;&#27010;&#24565;&#20043;&#38388;&#30340;&#31561;&#20215;&#20851;&#31995;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#20010;&#26377;&#24847;&#20041;&#30340;&#21521;&#21518;&#22522;&#32447;&#65292;&#21487;&#20197;&#23545;&#39044;&#27979;&#31995;&#32479;&#36827;&#34892;&#23457;&#35745;&#65292;&#21363;&#20351;&#21482;&#25552;&#20379;&#20102;&#32972;&#26223;&#21464;&#37327;&#21644;&#31995;&#32479;&#30340;&#39044;&#27979;&#12290;&#22312;&#32463;&#39564;&#19978;&#65292;&#25105;&#20204;&#22312;&#20174;&#32437;&#21521;&#38754;&#26495;&#35843;&#26597;&#20013;&#34893;&#29983;&#20986;&#30340;&#19981;&#21516;&#39044;&#27979;&#20219;&#21153;&#19978;&#35780;&#20272;&#20102;&#35813;&#26694;&#26550;&#65292;&#23637;&#31034;&#20102;&#23558;&#20854;&#32435;&#20837;&#30340;&#20415;&#25463;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2206.11673v2 Announce Type: replace  Abstract: When does a machine learning model predict the future of individuals and when does it recite patterns that predate the individuals? In this work, we propose a distinction between these two pathways of prediction, supported by theoretical, empirical, and normative arguments. At the center of our proposal is a family of simple and efficient statistical tests, called backward baselines, that demonstrate if, and to what extent, a model recounts the past. Our statistical theory provides guidance for interpreting backward baselines, establishing equivalences between different baselines and familiar statistical concepts. Concretely, we derive a meaningful backward baseline for auditing a prediction system as a black box, given only background variables and the system's predictions. Empirically, we evaluate the framework on different prediction tasks derived from longitudinal panel surveys, demonstrating the ease and effectiveness of incorpo
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#20266;&#26631;&#31614;&#36873;&#25321;&#36807;&#31243;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#27491;&#36127;&#26679;&#26412;&#23398;&#20064;&#20013;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#26657;&#20934;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#22312;&#39640;&#24230;&#19981;&#24179;&#34913;&#30340;&#24773;&#20917;&#19979;&#33021;&#26174;&#33879;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2201.13192</link><description>&lt;p&gt;
&#38024;&#23545;&#27491;&#36127;&#26679;&#26412;&#23398;&#20064;&#30340;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#20266;&#26631;&#31614;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Uncertainty-aware Pseudo-label Selection for Positive-Unlabeled Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2201.13192
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#20266;&#26631;&#31614;&#36873;&#25321;&#36807;&#31243;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#27491;&#36127;&#26679;&#26412;&#23398;&#20064;&#20013;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#26657;&#20934;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#22312;&#39640;&#24230;&#19981;&#24179;&#34913;&#30340;&#24773;&#20917;&#19979;&#33021;&#26174;&#33879;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;&#36127;&#26679;&#26412;&#23398;&#20064;&#65288;PUL&#65289;&#26088;&#22312;&#20174;&#20165;&#20855;&#26377;&#27491;&#26679;&#26412;&#21644;&#26410;&#26631;&#35760;&#35757;&#32451;&#25968;&#25454;&#20013;&#23398;&#20064;&#20108;&#20803;&#20998;&#31867;&#22120;&#12290;&#23613;&#31649;&#29616;&#23454;&#24212;&#29992;&#36890;&#24120;&#28041;&#21450;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#22823;&#22810;&#25968;&#31034;&#20363;&#23646;&#20110;&#19968;&#31867;&#65292;&#20294;&#22823;&#22810;&#25968;&#24403;&#20195;PUL&#26041;&#27861;&#24182;&#26410;&#30740;&#31350;&#36825;&#31181;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#65292;&#22240;&#27492;&#20005;&#37325;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#23454;&#36341;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#31181;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#20266;&#26631;&#31614;&#36873;&#25321;&#36807;&#31243;&#65288;PUUPL&#65289;&#26469;&#35299;&#20915;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#26657;&#20934;&#38382;&#39064;&#65306;&#36890;&#36807;&#22686;&#24378;&#23569;&#25968;&#31867;&#30340;&#20449;&#21495;&#65292;&#20266;&#26631;&#31614;&#20174;&#26410;&#26631;&#35760;&#38598;&#20013;&#25193;&#23637;&#20102;&#24102;&#26631;&#31614;&#30340;&#25968;&#25454;&#38598;&#65292;&#32780;&#26174;&#24335;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#38450;&#27490;&#20102;&#26377;&#23475;&#30340;&#30830;&#35748;&#20559;&#35265;&#30340;&#20986;&#29616;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#39044;&#27979;&#24615;&#33021;&#12290;&#36890;&#36807;&#19968;&#31995;&#21015;&#23454;&#39564;&#65292;PUUPL&#22312;&#39640;&#24230;&#19981;&#24179;&#34913;&#30340;&#24773;&#20917;&#19979;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2201.13192v3 Announce Type: replace-cross  Abstract: Positive-unlabeled learning (PUL) aims at learning a binary classifier from only positive and unlabeled training data. Even though real-world applications often involve imbalanced datasets where the majority of examples belong to one class, most contemporary approaches to PUL do not investigate performance in this setting, thus severely limiting their applicability in practice. In this work, we thus propose to tackle the issues of imbalanced datasets and model calibration in a PUL setting through an uncertainty-aware pseudo-labeling procedure (PUUPL): by boosting the signal from the minority class, pseudo-labeling expands the labeled dataset with new samples from the unlabeled set, while explicit uncertainty quantification prevents the emergence of harmful confirmation bias leading to increased predictive performance. Within a series of experiments, PUUPL yields substantial performance gains in highly imbalanced settings while 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#23884;&#22871;&#38750;&#21442;&#25968;&#24037;&#20855;&#21464;&#37327;&#22238;&#24402;&#30340;&#23545;&#25239;&#20272;&#35745;&#22120;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#22240;&#26524;&#21442;&#25968;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#20855;&#26377;&#38480;&#21046;&#30149;&#24577;&#24615;&#22797;&#21512;&#25216;&#26415;&#12289;&#22810;&#31181;&#36866;&#24212;&#27169;&#22411;&#21644;&#25193;&#23637;&#21040;&#22240;&#26524;&#20989;&#25968;&#31561;&#29305;&#24449;&#12290;</title><link>https://arxiv.org/abs/2112.14249</link><description>&lt;p&gt;
&#23884;&#22871;&#38750;&#21442;&#25968;&#24037;&#20855;&#21464;&#37327;&#22238;&#24402;&#65306;&#38271;&#26399;&#12289;&#20013;&#20171;&#21644;&#26102;&#21464;&#27835;&#30103;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
Nested Nonparametric Instrumental Variable Regression: Long Term, Mediated, and Time Varying Treatment Effects
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2112.14249
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#23884;&#22871;&#38750;&#21442;&#25968;&#24037;&#20855;&#21464;&#37327;&#22238;&#24402;&#30340;&#23545;&#25239;&#20272;&#35745;&#22120;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#22240;&#26524;&#21442;&#25968;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#20855;&#26377;&#38480;&#21046;&#30149;&#24577;&#24615;&#22797;&#21512;&#25216;&#26415;&#12289;&#22810;&#31181;&#36866;&#24212;&#27169;&#22411;&#21644;&#25193;&#23637;&#21040;&#22240;&#26524;&#20989;&#25968;&#31561;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30701;&#38754;&#26495;&#25968;&#25454;&#27169;&#22411;&#20013;&#30340;&#20960;&#20010;&#22240;&#26524;&#21442;&#25968;&#26159;&#31216;&#20026;&#23884;&#22871;&#38750;&#21442;&#25968;&#24037;&#20855;&#21464;&#37327;&#22238;&#24402;&#65288;nested NPIV&#65289;&#30340;&#20989;&#25968;&#30340;&#26631;&#37327;&#24635;&#32467;&#12290;&#20363;&#22914;&#65292;&#20351;&#29992;&#20195;&#29702;&#21464;&#37327;&#35782;&#21035;&#20986;&#38271;&#26399;&#12289;&#20013;&#20171;&#21644;&#26102;&#21464;&#27835;&#30103;&#25928;&#24212;&#12290;&#28982;&#32780;&#65292;&#20284;&#20046;&#19981;&#23384;&#22312;&#20851;&#20110;&#23884;&#22871;NPIV&#30340;&#20808;&#21069;&#20272;&#35745;&#37327;&#25110;&#20445;&#35777;&#65292;&#36825;&#26679;&#23601;&#26080;&#27861;&#28789;&#27963;&#22320;&#20272;&#35745;&#21644;&#25512;&#26029;&#36825;&#20123;&#22240;&#26524;&#21442;&#25968;&#12290;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#26159;&#30001;&#20110;&#23884;&#22871;&#36870;&#38382;&#39064;&#32780;&#23548;&#33268;&#30340;&#22797;&#21512;&#30149;&#24577;&#24615;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#23884;&#22871;NPIV&#30340;&#23545;&#25239;&#20272;&#35745;&#22120;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#22240;&#26524;&#21442;&#25968;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#25105;&#20204;&#30340;&#38750;&#28176;&#36817;&#20998;&#26512;&#20855;&#26377;&#19977;&#20010;&#26174;&#33879;&#29305;&#24449;&#65306;&#65288;i&#65289;&#24341;&#20837;&#38480;&#21046;&#30149;&#24577;&#24615;&#22797;&#21512;&#30340;&#25216;&#26415;&#65307;&#65288;ii&#65289;&#36866;&#24212;&#31070;&#32463;&#32593;&#32476;&#12289;&#38543;&#26426;&#26862;&#26519;&#21644;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65307;&#65288;iii&#65289;&#25193;&#23637;&#21040;&#22240;&#26524;&#20989;&#25968;&#65292;&#20363;&#22914;&#38271;&#26399;&#24322;&#36136;&#27835;&#30103;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2112.14249v3 Announce Type: replace-cross  Abstract: Several causal parameters in short panel data models are scalar summaries of a function called a nested nonparametric instrumental variable regression (nested NPIV). Examples include long term, mediated, and time varying treatment effects identified using proxy variables. However, it appears that no prior estimators or guarantees for nested NPIV exist, preventing flexible estimation and inference for these causal parameters. A major challenge is compounding ill posedness due to the nested inverse problems. We analyze adversarial estimators of nested NPIV, and provide sufficient conditions for efficient inference on the causal parameter. Our nonasymptotic analysis has three salient features: (i) introducing techniques that limit how ill posedness compounds; (ii) accommodating neural networks, random forests, and reproducing kernel Hilbert spaces; and (iii) extending to causal functions, e.g. long term heterogeneous treatment eff
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#30340;&#8220;&#19978;&#38480;&#21453;&#20107;&#23454;&#32622;&#20449;&#21306;&#38388;&#8221;&#65288;UCCB&#65289;&#26159;&#38024;&#23545;&#19968;&#33324;&#19978;&#19979;&#25991;&#36172;&#21338;&#35774;&#35745;&#20048;&#35266;&#31639;&#27861;&#30340;&#26032;&#21407;&#21017;&#65292;&#36890;&#36807;&#22312;&#31574;&#30053;&#31354;&#38388;&#20013;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#65292;&#32780;&#38750;&#20687;UCB&#37027;&#26679;&#22312;&#34892;&#21160;&#31354;&#38388;&#20013;&#65292;&#36825;&#20351;&#24471;&#31639;&#27861;&#22312;&#22788;&#29702;&#19968;&#33324;&#20989;&#25968;&#31867;&#21644;&#22823;&#19978;&#19979;&#25991;&#31354;&#38388;&#26102;&#22343;&#20855;&#26377;&#20248;&#36234;&#24615;&#12290;</title><link>https://arxiv.org/abs/2007.07876</link><description>&lt;p&gt;
&#19978;&#38480;&#21453;&#20107;&#23454;&#32622;&#20449;&#21306;&#38388;&#65306;&#19968;&#31181;&#38754;&#21521;&#19978;&#19979;&#25991;&#36172;&#21338;&#30340;&#26032;&#20048;&#35266;&#21407;&#21017;
&lt;/p&gt;
&lt;p&gt;
Upper Counterfactual Confidence Bounds: a New Optimism Principle for Contextual Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2007.07876
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#30340;&#8220;&#19978;&#38480;&#21453;&#20107;&#23454;&#32622;&#20449;&#21306;&#38388;&#8221;&#65288;UCCB&#65289;&#26159;&#38024;&#23545;&#19968;&#33324;&#19978;&#19979;&#25991;&#36172;&#21338;&#35774;&#35745;&#20048;&#35266;&#31639;&#27861;&#30340;&#26032;&#21407;&#21017;&#65292;&#36890;&#36807;&#22312;&#31574;&#30053;&#31354;&#38388;&#20013;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#65292;&#32780;&#38750;&#20687;UCB&#37027;&#26679;&#22312;&#34892;&#21160;&#31354;&#38388;&#20013;&#65292;&#36825;&#20351;&#24471;&#31639;&#27861;&#22312;&#22788;&#29702;&#19968;&#33324;&#20989;&#25968;&#31867;&#21644;&#22823;&#19978;&#19979;&#25991;&#31354;&#38388;&#26102;&#22343;&#20855;&#26377;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20048;&#35266;&#21407;&#21017;&#38754;&#23545;&#19981;&#30830;&#23450;&#24615;&#26159;&#22810;&#33218;&#36172;&#21338;&#21644;&#24378;&#21270;&#23398;&#20064;&#20013;&#26368;&#24191;&#27867;&#20351;&#29992;&#21644;&#25104;&#21151;&#30340;&#29702;&#24565;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#20048;&#35266;&#31639;&#27861;&#65288;&#20027;&#35201;&#26159;UCB&#21450;&#20854;&#21464;&#31181;&#65289;&#36890;&#24120;&#26080;&#27861;&#22788;&#29702;&#19968;&#33324;&#30340;&#20989;&#25968;&#31867;&#21644;&#22823;&#30340;&#19978;&#19979;&#25991;&#31354;&#38388;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#31163;&#32447;&#22238;&#24402;&#39044;&#35328;&#26426;&#30340;&#19968;&#33324;&#19978;&#19979;&#25991;&#36172;&#21338;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#36890;&#29992;&#21407;&#21017;&#26469;&#35774;&#35745;&#20048;&#35266;&#31639;&#27861;&#65292;&#31216;&#20026;&#8220;&#19978;&#38480;&#21453;&#20107;&#23454;&#32622;&#20449;&#21306;&#38388;&#8221;&#65288;UCCB&#65289;&#12290;UCCB&#30340;&#20851;&#38190;&#21019;&#26032;&#26159;&#22312;&#31574;&#30053;&#31354;&#38388;&#20013;&#24314;&#31435;&#32622;&#20449;&#21306;&#38388;&#65292;&#32780;&#19981;&#26159;&#20687;UCB&#37027;&#26679;&#22312;&#34892;&#21160;&#31354;&#38388;&#20013;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#31639;&#27861;&#22312;&#22788;&#29702;&#19968;&#33324;&#20989;&#25968;&#31867;&#21644;&#22823;&#19978;&#19979;&#25991;&#31354;&#38388;&#26041;&#38754;&#26082;&#26159;&#21487;&#35777;&#26126;&#30340;&#26368;&#20248;&#30340;&#65292;&#21448;&#22312;&#35745;&#31639;&#19978;&#26159;&#39640;&#25928;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;UCCB&#21407;&#21017;&#21487;&#20197;&#36731;&#26494;&#22320;&#25193;&#23637;&#21040;&#26080;&#38480;&#21160;&#20316;&#30340;&#19968;&#33324;&#19978;&#19979;&#25991;&#36172;&#21338;&#65292;&#24182;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2007.07876v4 Announce Type: replace  Abstract: The principle of optimism in the face of uncertainty is one of the most widely used and successful ideas in multi-armed bandits and reinforcement learning. However, existing optimistic algorithms (primarily UCB and its variants) often struggle to deal with general function classes and large context spaces. In this paper, we study general contextual bandits with an offline regression oracle and propose a simple, generic principle to design optimistic algorithms, dubbed "Upper Counterfactual Confidence Bounds" (UCCB). The key innovation of UCCB is building confidence bounds in policy space, rather than in action space as is done in UCB. We demonstrate that these algorithms are provably optimal and computationally efficient in handling general function classes and large context spaces. Furthermore, we illustrate that the UCCB principle can be seamlessly extended to infinite-action general contextual bandits, provide the first solutions 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#36890;&#36807;&#32467;&#26500;&#20445;&#25345;&#24178;&#39044;&#26469;&#37327;&#21270;&#33410;&#28857;&#23545;&#30446;&#26631;&#33410;&#28857;&#30340;&#22266;&#26377;&#22240;&#26524;&#36129;&#29486;&#30340;&#26041;&#27861;&#65292;&#20174;&#32780;&#23558;&#22240;&#26524;&#20449;&#24687;&#19982;&#31062;&#20808;&#33410;&#28857;&#20449;&#24687;&#20998;&#31163;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;&#26041;&#24046;&#21644;&#29109;&#30340;&#36129;&#29486;&#20998;&#26512;&#12290;</title><link>https://arxiv.org/abs/2007.00714</link><description>&lt;p&gt;
&#36890;&#36807;&#20445;&#25345;&#32467;&#26500;&#30340;&#24178;&#39044;&#26469;&#37327;&#21270;&#22266;&#26377;&#22240;&#26524;&#36129;&#29486;
&lt;/p&gt;
&lt;p&gt;
Quantifying intrinsic causal contributions via structure preserving interventions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2007.00714
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#36890;&#36807;&#32467;&#26500;&#20445;&#25345;&#24178;&#39044;&#26469;&#37327;&#21270;&#33410;&#28857;&#23545;&#30446;&#26631;&#33410;&#28857;&#30340;&#22266;&#26377;&#22240;&#26524;&#36129;&#29486;&#30340;&#26041;&#27861;&#65292;&#20174;&#32780;&#23558;&#22240;&#26524;&#20449;&#24687;&#19982;&#31062;&#20808;&#33410;&#28857;&#20449;&#24687;&#20998;&#31163;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;&#26041;&#24046;&#21644;&#29109;&#30340;&#36129;&#29486;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25551;&#36848;&#26377;&#21521;&#26080;&#29615;&#22270;&#20013;&#19968;&#20010;&#33410;&#28857;&#23545;&#30446;&#26631;&#33410;&#28857;&#30340;&#8220;&#22266;&#26377;&#8221;&#36129;&#29486;&#37096;&#20998;&#30340;&#22240;&#26524;&#24433;&#21709;&#27010;&#24565;&#12290;&#36890;&#36807;&#23558;&#27599;&#20010;&#33410;&#28857;&#36882;&#24402;&#22320;&#20889;&#25104;&#19978;&#28216;&#22122;&#22768;&#39033;&#30340;&#20989;&#25968;&#65292;&#25105;&#20204;&#23558;&#27599;&#20010;&#33410;&#28857;&#28155;&#21152;&#30340;&#22266;&#26377;&#20449;&#24687;&#19982;&#20174;&#31062;&#20808;&#33410;&#28857;&#33719;&#24471;&#30340;&#20449;&#24687;&#20998;&#24320;&#12290;&#20026;&#20102;&#23558;&#22266;&#26377;&#20449;&#24687;&#35299;&#37322;&#20026;&#8220;&#22240;&#26524;&#8221;&#36129;&#29486;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#8220;&#20445;&#25345;&#32467;&#26500;&#30340;&#24178;&#39044;&#8221;&#65292;&#36825;&#20123;&#24178;&#39044;&#20197;&#19968;&#31181;&#27169;&#25311;&#23545;&#29238;&#33410;&#28857;&#30340;&#36890;&#24120;&#20381;&#36182;&#20851;&#31995;&#24182;&#19988;&#19981;&#25200;&#20081;&#35266;&#23519;&#21040;&#30340;&#32852;&#21512;&#20998;&#24067;&#30340;&#26041;&#24335;&#38543;&#26426;&#21270;&#27599;&#20010;&#33410;&#28857;&#12290;&#20026;&#20102;&#33719;&#24471;&#19968;&#20010;&#23545;&#37325;&#26032;&#26631;&#35760;&#33410;&#28857;&#19981;&#21464;&#30340;&#27979;&#37327;&#65292;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;Shapley&#30340;&#23545;&#31216;&#21270;&#65292;&#24182;&#19988;&#34920;&#26126;&#22312;&#32447;&#24615;&#24773;&#20917;&#19979;&#65292;&#22312;&#23558;&#30446;&#26631;&#33410;&#28857;&#35299;&#26512;&#20026;&#22122;&#22768;&#21464;&#37327;&#21518;&#65292;&#23427;&#21270;&#31616;&#20026;&#31616;&#21333;&#30340;ANOVA&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#26041;&#24046;&#21644;&#29109;&#30340;&#36129;&#29486;&#20998;&#26512;&#65292;&#20294;&#20854;&#20182;&#30446;&#26631;&#24230;&#37327;&#30340;&#36129;&#29486;&#21487;&#20197;&#31867;&#20284;&#22320;&#23450;&#20041;&#12290;&#20195;&#30721;&#21487;&#22312;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2007.00714v4 Announce Type: replace  Abstract: We propose a notion of causal influence that describes the `intrinsic' part of the contribution of a node on a target node in a DAG. By recursively writing each node as a function of the upstream noise terms, we separate the intrinsic information added by each node from the one obtained from its ancestors. To interpret the intrinsic information as a {\it causal} contribution, we consider `structure-preserving interventions' that randomize each node in a way that mimics the usual dependence on the parents and does not perturb the observed joint distribution. To get a measure that is invariant with respect to relabelling nodes we use Shapley based symmetrization and show that it reduces in the linear case to simple ANOVA after resolving the target node into noise variables. We describe our contribution analysis for variance and entropy, but contributions for other target metrics can be defined analogously. The code is available in the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#21512;&#22810;&#20219;&#21153;&#32593;&#32476;&#35774;&#35745;&#65292;&#20197;&#23454;&#29616;&#22312;&#33258;&#21160;&#39550;&#39542;&#20013;&#30340;&#35270;&#35273;&#24863;&#30693;&#20219;&#21153;&#20013;&#20849;&#20139;&#35745;&#31639;&#36164;&#28304;&#65292;&#20174;&#32780;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#24182;&#25552;&#20379;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/1902.03589</link><description>&lt;p&gt;
NeurAll: &#38754;&#21521;&#33258;&#21160;&#39550;&#39542;&#30340;&#32479;&#19968;&#35270;&#35273;&#24863;&#30693;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
NeurAll: Towards a Unified Visual Perception Model for Automated Driving
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/1902.03589
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#21512;&#22810;&#20219;&#21153;&#32593;&#32476;&#35774;&#35745;&#65292;&#20197;&#23454;&#29616;&#22312;&#33258;&#21160;&#39550;&#39542;&#20013;&#30340;&#35270;&#35273;&#24863;&#30693;&#20219;&#21153;&#20013;&#20849;&#20139;&#35745;&#31639;&#36164;&#28304;&#65292;&#20174;&#32780;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#24182;&#25552;&#20379;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNNs&#65289;&#34987;&#25104;&#21151;&#24212;&#29992;&#20110;&#37325;&#35201;&#30340;&#27773;&#36710;&#35270;&#35273;&#24863;&#30693;&#20219;&#21153;&#65292;&#21253;&#25324;&#30446;&#26631;&#35782;&#21035;&#12289;&#36816;&#21160;&#21644;&#28145;&#24230;&#20272;&#35745;&#12289;&#35270;&#35273;SLAM&#31561;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#20219;&#21153;&#36890;&#24120;&#26159;&#29420;&#31435;&#25506;&#32034;&#21644;&#24314;&#27169;&#30340;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#21512;&#22810;&#20219;&#21153;&#32593;&#32476;&#35774;&#35745;&#65292;&#21516;&#26102;&#23398;&#20064;&#22810;&#20010;&#20219;&#21153;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#21160;&#26426;&#26159;&#36890;&#36807;&#22312;&#25152;&#26377;&#20219;&#21153;&#20043;&#38388;&#20849;&#20139;&#26114;&#36149;&#30340;&#21021;&#22987;&#21367;&#31215;&#23618;&#26469;&#23454;&#29616;&#35745;&#31639;&#25928;&#29575;&#12290;&#20107;&#23454;&#19978;&#65292;&#33258;&#21160;&#39550;&#39542;&#31995;&#32479;&#20013;&#30340;&#20027;&#35201;&#29942;&#39048;&#26159;&#37096;&#32626;&#30828;&#20214;&#19978;&#21487;&#29992;&#30340;&#26377;&#38480;&#22788;&#29702;&#33021;&#21147;&#12290;&#36824;&#26377;&#19968;&#20123;&#35777;&#25454;&#34920;&#26126;&#65292;&#23545;&#20110;&#26576;&#20123;&#20219;&#21153;&#26469;&#35828;&#65292;&#22312;&#25552;&#39640;&#20934;&#30830;&#24615;&#26041;&#38754;&#23384;&#22312;&#20854;&#20182;&#22909;&#22788;&#65292;&#24182;&#19988;&#21487;&#20197;&#20943;&#36731;&#24320;&#21457;&#24037;&#20316;&#37327;&#12290;&#23427;&#36824;&#25552;&#20379;&#20102;&#21487;&#20280;&#32553;&#24615;&#65292;&#21487;&#20197;&#36890;&#36807;&#21033;&#29992;&#29616;&#26377;&#29305;&#24449;&#22686;&#21152;&#26356;&#22810;&#20219;&#21153;&#65292;&#24182;&#23454;&#29616;&#26356;&#22909;&#30340;&#27867;&#21270;&#12290;&#25105;&#20204;&#35843;&#26597;&#20102;&#33258;&#21160;&#39550;&#39542;&#20013;&#29992;&#20110;&#35270;&#35273;&#24863;&#30693;&#20219;&#21153;&#30340;&#21508;&#31181;&#22522;&#20110;CNN&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:1902.03589v3 Announce Type: replace-cross  Abstract: Convolutional Neural Networks (CNNs) are successfully used for the important automotive visual perception tasks including object recognition, motion and depth estimation, visual SLAM, etc. However, these tasks are typically independently explored and modeled. In this paper, we propose a joint multi-task network design for learning several tasks simultaneously. Our main motivation is the computational efficiency achieved by sharing the expensive initial convolutional layers between all tasks. Indeed, the main bottleneck in automated driving systems is the limited processing power available on deployment hardware. There is also some evidence for other benefits in improving accuracy for some tasks and easing development effort. It also offers scalability to add more tasks leveraging existing features and achieving better generalization. We survey various CNN based solutions for visual perception tasks in automated driving. Then we
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#21028;&#21035;&#24335;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#32467;&#21512;&#20808;&#21069;&#30740;&#31350;&#30340;&#35789;&#20856;&#20808;&#39564;&#21644;&#34920;&#31034;&#27861;&#65292;&#25552;&#20986;&#20102;&#29992;&#20110;&#21452;&#35821;&#35789;&#20856;&#24402;&#32435;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#25454;&#23637;&#31034;&#20808;&#39564;&#21487;&#20197;&#25913;&#21892;&#35825;&#23548;&#30340;&#21452;&#35821;&#35789;&#20856;&#12290;</title><link>https://arxiv.org/abs/1808.09334</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#21452;&#35821;&#35789;&#20856;&#24402;&#32435;&#30340;&#21028;&#21035;&#24335;&#28508;&#21464;&#37327;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Discriminative Latent-Variable Model for Bilingual Lexicon Induction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/1808.09334
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#21028;&#21035;&#24335;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#32467;&#21512;&#20808;&#21069;&#30740;&#31350;&#30340;&#35789;&#20856;&#20808;&#39564;&#21644;&#34920;&#31034;&#27861;&#65292;&#25552;&#20986;&#20102;&#29992;&#20110;&#21452;&#35821;&#35789;&#20856;&#24402;&#32435;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#25454;&#23637;&#31034;&#20808;&#39564;&#21487;&#20197;&#25913;&#21892;&#35825;&#23548;&#30340;&#21452;&#35821;&#35789;&#20856;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29992;&#20110;&#21452;&#35821;&#35789;&#20856;&#24402;&#32435;&#30340;&#21028;&#21035;&#24335;&#28508;&#21464;&#37327;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#23558;Haghighi&#31561;&#20154;&#65288;2008&#65289;&#30340;&#20108;&#20998;&#21305;&#37197;&#35789;&#20856;&#20808;&#39564;&#19982;&#22522;&#20110;&#34920;&#31034;&#30340;&#26041;&#27861;&#65288;Artetxe&#31561;&#20154;&#65292;2017&#65289;&#30456;&#32467;&#21512;&#12290;&#20026;&#20102;&#35757;&#32451;&#27169;&#22411;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#39640;&#25928;&#30340;Viterbi EM&#31639;&#27861;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#24230;&#37327;&#26631;&#20934;&#19979;&#23545;&#20845;&#31181;&#35821;&#35328;&#23545;&#36827;&#34892;&#20102;&#23454;&#35777;&#32467;&#26524;&#65292;&#24182;&#26174;&#31034;&#20808;&#39564;&#25913;&#21892;&#20102;&#35825;&#23548;&#30340;&#21452;&#35821;&#35789;&#20856;&#12290;&#25105;&#20204;&#36824;&#28436;&#31034;&#20102;&#22914;&#20309;&#23558;&#20808;&#21069;&#30340;&#24037;&#20316;&#35270;&#20026;&#31867;&#20284;&#39118;&#26684;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#23613;&#31649;&#26377;&#19981;&#21516;&#30340;&#20808;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:1808.09334v3 Announce Type: replace  Abstract: We introduce a novel discriminative latent variable model for bilingual lexicon induction. Our model combines the bipartite matching dictionary prior of Haghighi et al. (2008) with a representation-based approach (Artetxe et al., 2017). To train the model, we derive an efficient Viterbi EM algorithm. We provide empirical results on six language pairs under two metrics and show that the prior improves the induced bilingual lexicons. We also demonstrate how previous work may be viewed as a similarly fashioned latent-variable model, albeit with a different prior.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#31070;&#32463;&#20449;&#24687;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#26469;&#35780;&#20272;&#22899;&#24615;&#36816;&#21160;&#21592;&#33041;&#38663;&#33633;&#30340;&#26041;&#27861;&#12290;&#30456;&#27604;&#20256;&#32479;&#30340;&#20020;&#24202;&#26041;&#27861;&#65292;&#22312;&#22899;&#24615;&#36816;&#21160;&#21592;&#20013;&#35786;&#26029;&#33041;&#38663;&#33633;&#23384;&#22312;&#19968;&#20123;&#23616;&#38480;&#24615;&#65292;&#32780;&#36825;&#20123;&#26032;&#25216;&#26415;&#21487;&#20197;&#36890;&#36807;&#25968;&#25454;&#20998;&#26512;&#25214;&#20986;&#19982;&#24615;&#21035;&#30456;&#20851;&#30340;&#29983;&#29289;&#26426;&#21046;&#65292;&#20174;&#32780;&#22635;&#34917;&#36825;&#19968;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2401.13045</link><description>&lt;p&gt;
&#35780;&#20272;&#22899;&#24615;&#36816;&#21160;&#21592;&#33041;&#38663;&#33633;&#65306;&#31070;&#32463;&#20449;&#24687;&#23398;&#30340;&#20316;&#29992;&#65311;
&lt;/p&gt;
&lt;p&gt;
Assessment of Sports Concussion in Female Athletes: A Role for Neuroinformatics?. (arXiv:2401.13045v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13045
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#31070;&#32463;&#20449;&#24687;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#26469;&#35780;&#20272;&#22899;&#24615;&#36816;&#21160;&#21592;&#33041;&#38663;&#33633;&#30340;&#26041;&#27861;&#12290;&#30456;&#27604;&#20256;&#32479;&#30340;&#20020;&#24202;&#26041;&#27861;&#65292;&#22312;&#22899;&#24615;&#36816;&#21160;&#21592;&#20013;&#35786;&#26029;&#33041;&#38663;&#33633;&#23384;&#22312;&#19968;&#20123;&#23616;&#38480;&#24615;&#65292;&#32780;&#36825;&#20123;&#26032;&#25216;&#26415;&#21487;&#20197;&#36890;&#36807;&#25968;&#25454;&#20998;&#26512;&#25214;&#20986;&#19982;&#24615;&#21035;&#30456;&#20851;&#30340;&#29983;&#29289;&#26426;&#21046;&#65292;&#20174;&#32780;&#22635;&#34917;&#36825;&#19968;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#20013;&#65292;&#22899;&#24615;&#36816;&#21160;&#21592;&#33041;&#38663;&#33633;&#30340;&#22797;&#26434;&#24615;&#21464;&#24471;&#26126;&#26174;&#12290;&#20256;&#32479;&#30340;&#20020;&#24202;&#35786;&#26029;&#33041;&#38663;&#33633;&#30340;&#26041;&#27861;&#22312;&#24212;&#29992;&#20110;&#22899;&#24615;&#36816;&#21160;&#21592;&#26102;&#23384;&#22312;&#23616;&#38480;&#24615;&#65292;&#24448;&#24448;&#26080;&#27861;&#25429;&#25417;&#21040;&#33041;&#32467;&#26500;&#21644;&#21151;&#33021;&#30340;&#32454;&#24494;&#21464;&#21270;&#12290;&#20808;&#36827;&#30340;&#31070;&#32463;&#20449;&#24687;&#23398;&#25216;&#26415;&#21644;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#36825;&#26041;&#38754;&#24050;&#32463;&#25104;&#20026;&#23453;&#36149;&#30340;&#36164;&#20135;&#12290;&#34429;&#28982;&#36825;&#20123;&#25216;&#26415;&#22312;&#29702;&#35299;&#30007;&#24615;&#36816;&#21160;&#21592;&#30340;&#33041;&#38663;&#33633;&#26041;&#38754;&#24050;&#32463;&#34987;&#24191;&#27867;&#24212;&#29992;&#65292;&#20294;&#22312;&#25105;&#20204;&#23545;&#20110;&#23427;&#20204;&#23545;&#22899;&#24615;&#36816;&#21160;&#21592;&#30340;&#26377;&#25928;&#24615;&#30340;&#29702;&#35299;&#19978;&#20173;&#23384;&#22312;&#26174;&#33879;&#24046;&#36317;&#12290;&#36890;&#36807;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#30340;&#24378;&#22823;&#25968;&#25454;&#20998;&#26512;&#33021;&#21147;&#65292;&#30740;&#31350;&#20154;&#21592;&#21487;&#20197;&#23558;&#35266;&#23519;&#21040;&#30340;&#34920;&#22411;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#32852;&#31995;&#21040;&#29305;&#23450;&#20110;&#24615;&#21035;&#30340;&#29983;&#29289;&#26426;&#21046;&#65292;&#25581;&#31034;&#22899;&#24615;&#36816;&#21160;&#21592;&#33041;&#38663;&#33633;&#30340;&#22885;&#31192;&#12290;&#27492;&#22806;&#65292;&#23884;&#20837;&#26426;&#22120;&#23398;&#20064;&#30340;&#26041;&#27861;&#36824;&#21487;&#20197;&#22312;&#30740;&#31350;&#20013;&#36827;&#34892;&#20132;&#21449;&#39564;&#35777;&#65292;&#36827;&#19968;&#27493;&#26816;&#39564;&#24615;&#21035;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Over the past decade, the intricacies of sports-related concussions among female athletes have become readily apparent. Traditional clinical methods for diagnosing concussions suffer limitations when applied to female athletes, often failing to capture subtle changes in brain structure and function. Advanced neuroinformatics techniques and machine learning models have become invaluable assets in this endeavor. While these technologies have been extensively employed in understanding concussion in male athletes, there remains a significant gap in our comprehension of their effectiveness for female athletes. With its remarkable data analysis capacity, machine learning offers a promising avenue to bridge this deficit. By harnessing the power of machine learning, researchers can link observed phenotypic neuroimaging data to sex-specific biological mechanisms, unraveling the mysteries of concussions in female athletes. Furthermore, embedding methods within machine learning enable examining b
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#35299;&#20915;&#20102;&#35782;&#21035;&#20855;&#26377;&#26368;&#39640;&#39044;&#26399;&#25928;&#26524;&#30340;&#27835;&#30103;&#26041;&#26696;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20855;&#26377;&#22266;&#23450;&#39044;&#31639;&#30340;&#23616;&#37096;&#26368;&#20248;&#31639;&#27861;&#26469;&#38477;&#20302;&#38169;&#35823;&#35782;&#21035;&#30340;&#27010;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.19788</link><description>&lt;p&gt;
&#20855;&#26377;&#22266;&#23450;&#39044;&#31639;&#30340;&#23616;&#37096;&#26368;&#20248;&#26368;&#20339;&#33218;&#35782;&#21035;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Locally Optimal Best Arm Identification with a Fixed Budget. (arXiv:2310.19788v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19788
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#35299;&#20915;&#20102;&#35782;&#21035;&#20855;&#26377;&#26368;&#39640;&#39044;&#26399;&#25928;&#26524;&#30340;&#27835;&#30103;&#26041;&#26696;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20855;&#26377;&#22266;&#23450;&#39044;&#31639;&#30340;&#23616;&#37096;&#26368;&#20248;&#31639;&#27861;&#26469;&#38477;&#20302;&#38169;&#35823;&#35782;&#21035;&#30340;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#35782;&#21035;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#30340;&#38382;&#39064;&#65292;&#21363;&#20855;&#26377;&#26368;&#39640;&#39044;&#26399;&#25928;&#26524;&#30340;&#27835;&#30103;&#26041;&#26696;&#12290;&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;&#38477;&#20302;&#38169;&#35823;&#35782;&#21035;&#30340;&#27010;&#29575;&#26469;&#30830;&#23450;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#65292;&#36825;&#19968;&#38382;&#39064;&#22312;&#35768;&#22810;&#30740;&#31350;&#39046;&#22495;&#20013;&#24050;&#34987;&#25506;&#32034;&#65292;&#21253;&#25324;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;Best Arm Identification&#65292;BAI&#65289;&#21644;&#24207;&#21015;&#20248;&#21270;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#27835;&#30103;&#20998;&#37197;&#30340;&#36718;&#25968;&#26159;&#22266;&#23450;&#30340;&#12290;&#22312;&#27599;&#19968;&#36718;&#20013;&#65292;&#20915;&#31574;&#32773;&#23558;&#19968;&#31181;&#27835;&#30103;&#26041;&#26696;&#20998;&#37197;&#32473;&#19968;&#20010;&#23454;&#39564;&#21333;&#20803;&#65292;&#24182;&#35266;&#23519;&#30456;&#24212;&#30340;&#32467;&#26524;&#65292;&#35813;&#32467;&#26524;&#36981;&#24490;&#19981;&#21516;&#27835;&#30103;&#26041;&#26696;&#20043;&#38388;&#26041;&#24046;&#19981;&#21516;&#30340;&#39640;&#26031;&#20998;&#24067;&#12290;&#22312;&#23454;&#39564;&#32467;&#26463;&#26102;&#65292;&#25105;&#20204;&#26681;&#25454;&#35266;&#23519;&#32467;&#26524;&#25512;&#33616;&#19968;&#31181;&#27835;&#30103;&#26041;&#26696;&#20316;&#20026;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#30340;&#20272;&#35745;&#20540;&#12290;&#20915;&#31574;&#32773;&#30340;&#30446;&#26631;&#26159;&#35774;&#35745;&#19968;&#20010;&#23454;&#39564;&#65292;&#20351;&#38169;&#35823;&#35782;&#21035;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#30340;&#27010;&#29575;&#26368;&#23567;&#21270;&#12290;&#22522;&#20110;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#35823;&#35782;&#21035;&#27010;&#29575;&#30340;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study investigates the problem of identifying the best treatment arm, a treatment arm with the highest expected outcome. We aim to identify the best treatment arm with a lower probability of misidentification, which has been explored under various names across numerous research fields, including \emph{best arm identification} (BAI) and ordinal optimization. In our experiments, the number of treatment-allocation rounds is fixed. In each round, a decision-maker allocates a treatment arm to an experimental unit and observes a corresponding outcome, which follows a Gaussian distribution with a variance different among treatment arms. At the end of the experiment, we recommend one of the treatment arms as an estimate of the best treatment arm based on the observations. The objective of the decision-maker is to design an experiment that minimizes the probability of misidentifying the best treatment arm. With this objective in mind, we develop lower bounds for the probability of misident
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#36951;&#25022;&#21040;&#32622;&#20449;&#38598;&#36716;&#25442;&#26041;&#27861;&#25913;&#36827;&#20102;&#36923;&#36753;&#22238;&#24402;&#36172;&#21338;&#26426;&#30340;&#36951;&#25022;&#30028;&#38480;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#30340;&#20984;&#32622;&#20449;&#38598;&#65292;&#24182;&#24212;&#29992;&#20110;&#20855;&#26377;&#26032;&#30340;&#38789;&#38598;&#20013;&#27493;&#39588;&#30340;&#36951;&#25022;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2310.18554</link><description>&lt;p&gt;
&#36890;&#36807;&#36951;&#25022;&#21040;&#32622;&#20449;&#38598;&#36716;&#25442;&#25913;&#36827;&#65288;&#22810;&#39033;&#24335;&#65289;&#36923;&#36753;&#22238;&#24402;&#36172;&#21338;&#26426;&#30340;&#36951;&#25022;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Improved Regret Bounds of (Multinomial) Logistic Bandits via Regret-to-Confidence-Set Conversion. (arXiv:2310.18554v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18554
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#36951;&#25022;&#21040;&#32622;&#20449;&#38598;&#36716;&#25442;&#26041;&#27861;&#25913;&#36827;&#20102;&#36923;&#36753;&#22238;&#24402;&#36172;&#21338;&#26426;&#30340;&#36951;&#25022;&#30028;&#38480;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#30340;&#20984;&#32622;&#20449;&#38598;&#65292;&#24182;&#24212;&#29992;&#20110;&#20855;&#26377;&#26032;&#30340;&#38789;&#38598;&#20013;&#27493;&#39588;&#30340;&#36951;&#25022;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36923;&#36753;&#22238;&#24402;&#36172;&#21338;&#26426;&#26159;&#24314;&#27169;&#29992;&#25143;&#36873;&#25321;&#30340;&#26222;&#36941;&#26694;&#26550;&#65292;&#20363;&#22914;&#24191;&#21578;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#28857;&#20987;&#19982;&#21542;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#20808;&#21069;&#30340;&#24037;&#20316;&#24573;&#35270;&#25110;&#24573;&#30053;&#20102;$S \geq \lVert \theta_\star \rVert_2$&#20013;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#20854;&#20013;$\theta_\star \in \mathbb{R}^d$&#26159;&#26410;&#30693;&#30340;&#21442;&#25968;&#21521;&#37327;&#65292;&#24403;$S$&#36739;&#22823;&#26102;&#65292;&#20363;&#22914;$S \geq d$&#65292;&#36825;&#20250;&#20135;&#29983;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#31181;&#31216;&#20026;&#8220;&#36951;&#25022;&#21040;&#32622;&#20449;&#38598;&#36716;&#25442;&#65288;R2CS&#65289;&#8221;&#30340;&#26032;&#26041;&#27861;&#25913;&#21892;&#20102;&#23545;$S$&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#35813;&#26041;&#27861;&#20801;&#35768;&#25105;&#20204;&#26500;&#24314;&#19968;&#20010;&#22522;&#20110;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#23384;&#22312;&#24615;&#30340;&#20984;&#32622;&#20449;&#38598;&#12290;&#20351;&#29992;R2CS&#65292;&#25105;&#20204;&#22312;&#36923;&#36753;&#22238;&#24402;&#36172;&#21338;&#26426;&#30340;&#36951;&#25022;&#30028;&#38480;&#26041;&#38754;&#33719;&#24471;&#20102;&#20005;&#26684;&#30340;&#25913;&#36827;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#35745;&#31639;&#21487;&#34892;&#24615;&#21644;&#23545;&#20854;&#20182;&#22240;&#32032;&#65288;&#22914;$d$&#21644;$T$&#65289;&#30340;&#20381;&#36182;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26032;&#32622;&#20449;&#38598;&#24212;&#29992;&#20110;&#20855;&#26377;&#26032;&#30340;&#38789;&#38598;&#20013;&#27493;&#39588;&#30340;&#36923;&#36753;&#22238;&#24402;&#36172;&#21338;&#26426;&#30340;&#36951;&#25022;&#20998;&#26512;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#39069;&#22806;&#30340;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;
Logistic bandit is a ubiquitous framework of modeling users' choices, e.g., click vs. no click for advertisement recommender system. We observe that the prior works overlook or neglect dependencies in $S \geq \lVert \theta_\star \rVert_2$, where $\theta_\star \in \mathbb{R}^d$ is the unknown parameter vector, which is particularly problematic when $S$ is large, e.g., $S \geq d$. In this work, we improve the dependency on $S$ via a novel approach called {\it regret-to-confidence set conversion (R2CS)}, which allows us to construct a convex confidence set based on only the \textit{existence} of an online learning algorithm with a regret guarantee. Using R2CS, we obtain a strict improvement in the regret bound w.r.t. $S$ in logistic bandits while retaining computational feasibility and the dependence on other factors such as $d$ and $T$. We apply our new confidence set to the regret analyses of logistic bandits with a new martingale concentration step that circumvents an additional factor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#26694;&#26550;&#26469;&#25552;&#21319;&#25968;&#25454;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#22312;&#27492;&#26041;&#27861;&#20013;&#65292;&#20351;&#29992;&#20808;&#36827;&#27169;&#22411;&#29983;&#25104;&#39640;&#36924;&#30495;&#24230;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#24182;&#37319;&#29992;&#32479;&#35745;&#26041;&#27861;&#36827;&#34892;&#20998;&#26512;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#30340;&#32479;&#35745;&#26041;&#27861;&#38169;&#35823;&#38543;&#30528;&#21512;&#25104;&#25968;&#25454;&#30340;&#22686;&#21152;&#32780;&#20943;&#23569;&#65292;&#20294;&#26368;&#32456;&#21487;&#33021;&#20250;&#22686;&#21152;&#25110;&#20572;&#28382;&#12290;</title><link>http://arxiv.org/abs/2310.17848</link><description>&lt;p&gt;
&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#25193;&#23637;&#25552;&#21319;&#25968;&#25454;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Boosting Data Analytics With Synthetic Volume Expansion. (arXiv:2310.17848v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17848
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#26694;&#26550;&#26469;&#25552;&#21319;&#25968;&#25454;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#22312;&#27492;&#26041;&#27861;&#20013;&#65292;&#20351;&#29992;&#20808;&#36827;&#27169;&#22411;&#29983;&#25104;&#39640;&#36924;&#30495;&#24230;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#24182;&#37319;&#29992;&#32479;&#35745;&#26041;&#27861;&#36827;&#34892;&#20998;&#26512;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#30340;&#32479;&#35745;&#26041;&#27861;&#38169;&#35823;&#38543;&#30528;&#21512;&#25104;&#25968;&#25454;&#30340;&#22686;&#21152;&#32780;&#20943;&#23569;&#65292;&#20294;&#26368;&#32456;&#21487;&#33021;&#20250;&#22686;&#21152;&#25110;&#20572;&#28382;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#20316;&#20026;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#30340;&#22522;&#30707;&#65292;&#22312;&#35299;&#20915;&#25968;&#25454;&#31232;&#32570;&#21644;&#38544;&#31169;&#38382;&#39064;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#24615;&#33021;&#12290;&#38543;&#30528;&#21512;&#25104;&#25968;&#25454;&#30340;&#26085;&#30410;&#37325;&#35201;&#65292;&#20154;&#20204;&#24320;&#22987;&#20851;&#27880;&#32479;&#35745;&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#19982;&#21407;&#22987;&#25968;&#25454;&#19978;&#30340;&#20934;&#30830;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#29992;&#20110;&#20998;&#26512;&#30340;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#26694;&#26550;&#12290;&#35813;&#26694;&#26550;&#20351;&#29992;&#39640;&#36924;&#30495;&#24230;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#36890;&#36807;&#20808;&#36827;&#27169;&#22411;&#22914;&#34920;&#26684;&#25193;&#25955;&#21644;&#29983;&#25104;&#24335;&#39044;&#35757;&#32451;&#36716;&#25442;&#22120;&#27169;&#22411;&#29983;&#25104;&#65292;&#24182;&#32467;&#21512;&#30456;&#20851;&#30740;&#31350;&#27934;&#23519;&#36827;&#19968;&#27493;&#22686;&#24378;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#21457;&#29616;&#26159;&#29983;&#25104;&#25928;&#24212;&#65306;&#32479;&#35745;&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#30340;&#38169;&#35823;&#38543;&#30528;&#21512;&#25104;&#25968;&#25454;&#30340;&#22686;&#21152;&#19968;&#24320;&#22987;&#20943;&#23569;&#65292;&#20294;&#26368;&#32456;&#21487;&#33021;&#20250;&#22686;&#21152;&#25110;&#20572;&#28382;&#12290;&#36825;&#20010;&#29616;&#35937;&#26681;&#28304;&#20110;&#22797;&#21046;&#21407;&#22987;&#25968;&#25454;&#20998;&#24067;&#30340;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Synthetic data generation, a cornerstone of Generative Artificial Intelligence, signifies a paradigm shift in data science by addressing data scarcity and privacy while enabling unprecedented performance. As synthetic data gains prominence, questions arise concerning the accuracy of statistical methods when applied to synthetic data compared to raw data. In this article, we introduce the Synthetic Data Generation for Analytics framework. This framework employs statistical methods on high-fidelity synthetic data generated by advanced models such as tabular diffusion and Generative Pre-trained Transformer models. These models, trained on raw data, are further enhanced with insights from pertinent studies. A significant discovery within this framework is the generational effect: the error of a statistical method on synthetic data initially diminishes with added synthetic data but may eventually increase or plateau. This phenomenon, rooted in the complexities of replicating raw data distri
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20132;&#26367;&#25237;&#24433;&#30340;&#36845;&#20195;&#26041;&#27861;&#26469;&#35299;&#20915;&#39640;&#26031;&#36807;&#31243;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#30340;&#35757;&#32451;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#20855;&#26377;&#32447;&#24615;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.17137</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#39640;&#26031;&#36807;&#31243;&#36890;&#36807;&#20132;&#26367;&#25237;&#24433;
&lt;/p&gt;
&lt;p&gt;
Large-Scale Gaussian Processes via Alternating Projection. (arXiv:2310.17137v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17137
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20132;&#26367;&#25237;&#24433;&#30340;&#36845;&#20195;&#26041;&#27861;&#26469;&#35299;&#20915;&#39640;&#26031;&#36807;&#31243;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#30340;&#35757;&#32451;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#20855;&#26377;&#32447;&#24615;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#36229;&#21442;&#25968;&#20248;&#21270;&#38656;&#35201;&#21453;&#22797;&#27714;&#35299;&#20855;&#26377; nxn &#26680;&#30697;&#38453;&#30340;&#32447;&#24615;&#31995;&#32479;&#12290;&#20026;&#20102;&#35299;&#20915; O(n^3) &#30340;&#26102;&#38388;&#22797;&#26434;&#24615;&#38382;&#39064;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#37319;&#29992;&#20102;&#24555;&#36895;&#36845;&#20195;&#25968;&#20540;&#26041;&#27861;&#65292;&#22914;&#20849;&#36717;&#26799;&#24230;&#65288;CG&#65289;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#25968;&#25454;&#38598;&#35268;&#27169;&#30340;&#22686;&#21152;&#65292;&#30456;&#24212;&#30340;&#26680;&#30697;&#38453;&#21464;&#24471;&#36234;&#26469;&#36234;&#30149;&#24577;&#65292;&#24182;&#19988;&#22312;&#27809;&#26377;&#20998;&#21106;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#38656;&#35201; O(n^2) &#30340;&#31354;&#38388;&#12290;&#22240;&#27492;&#65292;&#34429;&#28982; CG &#22686;&#21152;&#20102;&#21487;&#35757;&#32451; GP &#22522;&#20110;&#30340;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#65292;&#20294;&#29616;&#20195;&#25968;&#25454;&#38598;&#24050;&#32463;&#36798;&#21040;&#36229;&#20986;&#20854;&#36866;&#29992;&#33539;&#22260;&#30340;&#35268;&#27169;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21482;&#35775;&#38382;&#26680;&#30697;&#38453;&#30340;&#23376;&#22359;&#30340;&#36845;&#20195;&#26041;&#27861;&#65292;&#26377;&#25928;&#22320;&#23454;&#29616;&#20102;&#23567;&#25209;&#37327;&#22788;&#29702;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22522;&#20110;&#20132;&#26367;&#25237;&#24433;&#65292;&#27599;&#27425;&#36845;&#20195;&#30340;&#26102;&#38388;&#21644;&#31354;&#38388;&#22797;&#26434;&#24230;&#20026; O(n)&#65292;&#35299;&#20915;&#20102;&#23558; GP &#25193;&#23637;&#21040;&#38750;&#24120;&#22823;&#30340;&#25968;&#25454;&#38598;&#26102;&#30340;&#35768;&#22810;&#23454;&#38469;&#25361;&#25112;&#12290;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#32447;&#24615;&#25910;&#25947;&#24615;&#65292;&#20174;&#23454;&#35777;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;
&lt;/p&gt;
&lt;p&gt;
Gaussian process (GP) hyperparameter optimization requires repeatedly solving linear systems with $n \times n$ kernel matrices. To address the prohibitive $\mathcal{O}(n^3)$ time complexity, recent work has employed fast iterative numerical methods, like conjugate gradients (CG). However, as datasets increase in magnitude, the corresponding kernel matrices become increasingly ill-conditioned and still require $\mathcal{O}(n^2)$ space without partitioning. Thus, while CG increases the size of datasets GPs can be trained on, modern datasets reach scales beyond its applicability. In this work, we propose an iterative method which only accesses subblocks of the kernel matrix, effectively enabling \emph{mini-batching}. Our algorithm, based on alternating projection, has $\mathcal{O}(n)$ per-iteration time and space complexity, solving many of the practical challenges of scaling GPs to very large datasets. Theoretically, we prove our method enjoys linear convergence and empirically we demons
&lt;/p&gt;</description></item><item><title>Coreset MCMC&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27169;&#25311;&#39532;&#23572;&#21487;&#22827;&#38142;&#20197;&#26356;&#26032;coreset&#26435;&#37325;&#65292;&#20174;&#32780;&#23454;&#29616;&#22312;&#25512;&#26029;&#36807;&#31243;&#20013;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#30340;&#30446;&#30340;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#27604;&#65292;Coreset MCMC&#25552;&#20379;&#20102;&#26356;&#39640;&#36136;&#37327;&#30340;&#21518;&#39564;&#36817;&#20284;&#21644;&#26356;&#39640;&#30340;&#37319;&#26679;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.17063</link><description>&lt;p&gt;
Coreset&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;
&lt;/p&gt;
&lt;p&gt;
Coreset Markov Chain Monte Carlo. (arXiv:2310.17063v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17063
&lt;/p&gt;
&lt;p&gt;
Coreset MCMC&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27169;&#25311;&#39532;&#23572;&#21487;&#22827;&#38142;&#20197;&#26356;&#26032;coreset&#26435;&#37325;&#65292;&#20174;&#32780;&#23454;&#29616;&#22312;&#25512;&#26029;&#36807;&#31243;&#20013;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#30340;&#30446;&#30340;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#27604;&#65292;Coreset MCMC&#25552;&#20379;&#20102;&#26356;&#39640;&#36136;&#37327;&#30340;&#21518;&#39564;&#36817;&#20284;&#21644;&#26356;&#39640;&#30340;&#37319;&#26679;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;coreset&#26159;&#19968;&#20010;&#23567;&#32780;&#21152;&#26435;&#30340;&#25968;&#25454;&#23376;&#38598;&#65292;&#29992;&#20110;&#22312;&#25512;&#26029;&#36807;&#31243;&#20013;&#26367;&#20195;&#23436;&#25972;&#25968;&#25454;&#38598;&#20197;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#35843;&#25972;coreset&#26435;&#37325;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#32791;&#26102;&#26114;&#36149;&#65292;&#38656;&#35201;&#22797;&#26434;&#30340;&#29992;&#25143;&#36755;&#20837;&#65292;&#24182;&#23545;&#27169;&#22411;&#26045;&#21152;&#32422;&#26463;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#8212;&#8212;Coreset MCMC&#65292;&#35813;&#26041;&#27861;&#27169;&#25311;&#20102;&#19968;&#20010;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#30446;&#26631;&#26159;coreset&#21518;&#39564;&#20998;&#24067;&#65292;&#21516;&#26102;&#20351;&#29992;&#30456;&#21516;&#30340;&#25277;&#26679;&#26356;&#26032;coreset&#26435;&#37325;&#12290;Coreset MCMC&#26131;&#20110;&#23454;&#26045;&#21644;&#35843;&#25972;&#65292;&#24182;&#21487;&#19982;&#20219;&#20309;&#29616;&#26377;&#30340;MCMC&#20869;&#26680;&#19968;&#36215;&#20351;&#29992;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#20195;&#34920;&#24615;&#22330;&#26223;&#20013;&#20998;&#26512;&#20102;Coreset MCMC&#65292;&#20197;&#33719;&#24471;&#26377;&#20851;&#35813;&#26041;&#27861;&#25910;&#25947;&#34892;&#20026;&#30340;&#20851;&#38190;&#35265;&#35299;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20854;&#20182;coreset&#26500;&#36896;&#26041;&#27861;&#30456;&#27604;&#65292;Coreset MCMC&#33021;&#22815;&#25552;&#20379;&#26356;&#39640;&#36136;&#37327;&#30340;&#21518;&#39564;&#36817;&#20284;&#21644;&#26356;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#27492;&#22806;&#65292;&#19982;&#20854;&#20182;&#24120;&#35268;&#23376;&#37319;&#26679;MCMC&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#21457;&#29616;Coreset MCMC&#20855;&#26377;&#36739;&#39640;&#30340;&#37319;&#26679;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Bayesian coreset is a small, weighted subset of data that replaces the full dataset during inference in order to reduce computational cost. However, state of the art methods for tuning coreset weights are expensive, require nontrivial user input, and impose constraints on the model. In this work, we propose a new method -- Coreset MCMC -- that simulates a Markov chain targeting the coreset posterior, while simultaneously updating the coreset weights using those same draws. Coreset MCMC is simple to implement and tune, and can be used with any existing MCMC kernel. We analyze Coreset MCMC in a representative setting to obtain key insights about the convergence behaviour of the method. Empirical results demonstrate that Coreset MCMC provides higher quality posterior approximations and reduced computational cost compared with other coreset construction methods. Further, compared with other general subsampling MCMC methods, we find that Coreset MCMC has a higher sampling efficiency with 
&lt;/p&gt;</description></item><item><title>DeepFDR&#26159;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#34394;&#35686;&#25511;&#21046;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#26080;&#30417;&#30563;&#30340;&#22270;&#20687;&#20998;&#21106;&#25216;&#26415;&#35299;&#20915;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#20013;&#30340;&#22810;&#37325;&#26816;&#39564;&#38382;&#39064;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20854;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#20855;&#26377;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.13349</link><description>&lt;p&gt;
DeepFDR&#65306;&#19968;&#31181;&#29992;&#20110;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#30340;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#34394;&#35686;&#25511;&#21046;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
DeepFDR: A Deep Learning-based False Discovery Rate Control Method for Neuroimaging Data. (arXiv:2310.13349v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13349
&lt;/p&gt;
&lt;p&gt;
DeepFDR&#26159;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#34394;&#35686;&#25511;&#21046;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#26080;&#30417;&#30563;&#30340;&#22270;&#20687;&#20998;&#21106;&#25216;&#26415;&#35299;&#20915;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#20013;&#30340;&#22810;&#37325;&#26816;&#39564;&#38382;&#39064;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20854;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#20855;&#26377;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20307;&#32032;&#30340;&#22810;&#37325;&#26816;&#39564;&#22312;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#20998;&#26512;&#20013;&#24191;&#27867;&#24212;&#29992;&#12290;&#20256;&#32479;&#30340;&#34394;&#35686;&#25511;&#21046;&#26041;&#27861;&#24120;&#24120;&#24573;&#35270;&#22522;&#20110;&#20307;&#32032;&#30340;&#26816;&#39564;&#20043;&#38388;&#30340;&#31354;&#38388;&#30456;&#20851;&#24615;&#65292;&#20174;&#32780;&#23548;&#33268;&#27979;&#35797;&#33021;&#21147;&#30340;&#22823;&#24133;&#25439;&#22833;&#12290;&#34429;&#28982;&#26368;&#36817;&#20986;&#29616;&#20102;&#19968;&#20123;&#31354;&#38388;&#34394;&#35686;&#25511;&#21046;&#26041;&#27861;&#65292;&#20294;&#26159;&#24403;&#22788;&#29702;&#22797;&#26434;&#30340;&#33041;&#31354;&#38388;&#20381;&#36182;&#20851;&#31995;&#26102;&#65292;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#21644;&#26368;&#20248;&#24615;&#20173;&#23384;&#22312;&#30097;&#38382;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#24050;&#32463;&#22312;&#22270;&#20687;&#20998;&#21106;&#26041;&#38754;&#21462;&#24471;&#20102;&#38761;&#21629;&#24615;&#30340;&#36827;&#23637;&#65292;&#32780;&#22270;&#20687;&#20998;&#21106;&#19982;&#22522;&#20110;&#20307;&#32032;&#30340;&#22810;&#37325;&#26816;&#39564;&#23494;&#20999;&#30456;&#20851;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DeepFDR&#30340;&#26032;&#22411;&#31354;&#38388;&#34394;&#35686;&#25511;&#21046;&#26041;&#27861;&#65292;&#21033;&#29992;&#26080;&#30417;&#30563;&#30340;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#22270;&#20687;&#20998;&#21106;&#26469;&#35299;&#20915;&#22522;&#20110;&#20307;&#32032;&#30340;&#22810;&#37325;&#26816;&#39564;&#38382;&#39064;&#12290;&#21253;&#25324;&#20840;&#38754;&#30340;&#27169;&#25311;&#21644;&#38463;&#23572;&#33576;&#28023;&#40664;&#30149;FDG-PET&#24433;&#20687;&#20998;&#26512;&#22312;&#20869;&#30340;&#25968;&#20540;&#30740;&#31350;&#34920;&#26126;DeepFDR&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#20855;&#26377;&#20248;&#21183;&#12290;DeepFDR&#19981;&#20165;&#22312;&#34394;&#35686;&#25511;&#21046;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#36824;&#26377;&#25928;&#38477;&#20302;&#20102;&#34394;&#20551;&#30340;&#38750;&#21457;&#29616;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Voxel-based multiple testing is widely used in neuroimaging data analysis. Traditional false discovery rate (FDR) control methods often ignore the spatial dependence among the voxel-based tests and thus suffer from substantial loss of testing power. While recent spatial FDR control methods have emerged, their validity and optimality remain questionable when handling the complex spatial dependencies of the brain. Concurrently, deep learning methods have revolutionized image segmentation, a task closely related to voxel-based multiple testing. In this paper, we propose DeepFDR, a novel spatial FDR control method that leverages unsupervised deep learning-based image segmentation to address the voxel-based multiple testing problem. Numerical studies, including comprehensive simulations and Alzheimer's disease FDG-PET image analysis, demonstrate DeepFDR's superiority over existing methods. DeepFDR not only excels in FDR control and effectively diminishes the false nondiscovery rate, but als
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26799;&#24230;&#27969;&#25277;&#26679;&#26041;&#27861;&#30340;&#30740;&#31350;&#26041;&#21521;&#22312;&#35745;&#31639;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#20013;&#30340;&#26799;&#24230;&#27969;&#30340;&#35774;&#35745;&#32452;&#25104;&#37096;&#20998;&#65292;&#25552;&#20986;&#20102;&#19977;&#20010;&#36129;&#29486;&#65306;Kullback-Leibler&#25955;&#24230;&#20316;&#20026;&#33021;&#37327;&#27867;&#20989;&#30340;&#29420;&#29305;&#23646;&#24615;&#12289;&#24230;&#37327;&#30340;&#36873;&#25321;&#19982;&#19981;&#21464;&#24615;&#30340;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2310.03597</link><description>&lt;p&gt;
&#22312;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#20013;&#36890;&#36807;&#26799;&#24230;&#27969;&#36827;&#34892;&#25277;&#26679;
&lt;/p&gt;
&lt;p&gt;
Sampling via Gradient Flows in the Space of Probability Measures. (arXiv:2310.03597v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03597
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26799;&#24230;&#27969;&#25277;&#26679;&#26041;&#27861;&#30340;&#30740;&#31350;&#26041;&#21521;&#22312;&#35745;&#31639;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#20013;&#30340;&#26799;&#24230;&#27969;&#30340;&#35774;&#35745;&#32452;&#25104;&#37096;&#20998;&#65292;&#25552;&#20986;&#20102;&#19977;&#20010;&#36129;&#29486;&#65306;Kullback-Leibler&#25955;&#24230;&#20316;&#20026;&#33021;&#37327;&#27867;&#20989;&#30340;&#29420;&#29305;&#23646;&#24615;&#12289;&#24230;&#37327;&#30340;&#36873;&#25321;&#19982;&#19981;&#21464;&#24615;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35745;&#31639;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#65292;&#20351;&#29992;&#26410;&#30693;&#24402;&#19968;&#21270;&#24120;&#25968;&#30340;&#30446;&#26631;&#27010;&#29575;&#20998;&#24067;&#36827;&#34892;&#25277;&#26679;&#26159;&#19968;&#39033;&#22522;&#26412;&#30340;&#25361;&#25112;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;&#32771;&#34385;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#20013;&#30340;&#26799;&#24230;&#27969;&#27966;&#29983;&#30340;&#31639;&#27861;&#20026;&#31639;&#27861;&#24320;&#21457;&#24320;&#36767;&#20102;&#26032;&#30340;&#36884;&#24452;&#12290;&#26412;&#25991;&#36890;&#36807;&#23457;&#26597;&#36825;&#31181;&#26799;&#24230;&#27969;&#30340;&#35774;&#35745;&#32452;&#25104;&#37096;&#20998;&#65292;&#23545;&#36825;&#31181;&#25277;&#26679;&#26041;&#27861;&#20570;&#20986;&#20102;&#19977;&#20010;&#36129;&#29486;&#12290;&#25277;&#26679;&#30340;&#20219;&#20309;&#23454;&#20363;&#21270;&#37117;&#38656;&#35201;&#19968;&#20010;&#33021;&#37327;&#27867;&#20989;&#21644;&#19968;&#20010;&#24230;&#37327;&#26469;&#30830;&#23450;&#27969;&#21160;&#65292;&#20197;&#21450;&#27969;&#21160;&#30340;&#25968;&#20540;&#36817;&#20284;&#26469;&#25512;&#23548;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#31532;&#19968;&#20010;&#36129;&#29486;&#26159;&#23637;&#31034;&#20102;Kullback-Leibler&#25955;&#24230;&#20316;&#20026;&#19968;&#20010;&#33021;&#37327;&#27867;&#20989;&#20855;&#26377;&#21807;&#19968;&#30340;&#29305;&#24449;&#65288;&#22312;&#25152;&#26377;f-&#25955;&#24230;&#20013;&#65289;&#65292;&#21363;&#30001;&#20854;&#24471;&#21040;&#30340;&#26799;&#24230;&#27969;&#19981;&#20381;&#36182;&#20110;&#30446;&#26631;&#20998;&#24067;&#30340;&#24402;&#19968;&#21270;&#24120;&#25968;&#12290;&#25105;&#20204;&#30340;&#31532;&#20108;&#20010;&#36129;&#29486;&#26159;&#20174;&#19981;&#21464;&#24615;&#30340;&#35282;&#24230;&#30740;&#31350;&#24230;&#37327;&#30340;&#36873;&#25321;&#12290;Fisher-Rao&#24230;&#37327;&#34987;&#31216;&#20026;t
&lt;/p&gt;
&lt;p&gt;
Sampling a target probability distribution with an unknown normalization constant is a fundamental challenge in computational science and engineering. Recent work shows that algorithms derived by considering gradient flows in the space of probability measures open up new avenues for algorithm development. This paper makes three contributions to this sampling approach by scrutinizing the design components of such gradient flows. Any instantiation of a gradient flow for sampling needs an energy functional and a metric to determine the flow, as well as numerical approximations of the flow to derive algorithms. Our first contribution is to show that the Kullback-Leibler divergence, as an energy functional, has the unique property (among all f-divergences) that gradient flows resulting from it do not depend on the normalization constant of the target distribution. Our second contribution is to study the choice of metric from the perspective of invariance. The Fisher-Rao metric is known as t
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#25193;&#25955;&#29983;&#25104;&#27969;&#37319;&#26679;&#22120;&#65288;DGFS&#65289;&#30340;&#37319;&#26679;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#23398;&#20064;&#36807;&#31243;&#20998;&#35299;&#20026;&#30701;&#30340;&#37096;&#20998;&#36712;&#36857;&#27573;&#65292;&#23454;&#29616;&#20174;&#38590;&#20197;&#22788;&#29702;&#30340;&#39640;&#32500;&#23494;&#24230;&#20989;&#25968;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#23427;&#36890;&#36807;&#21033;&#29992;&#20013;&#38388;&#30340;&#23398;&#20064;&#20449;&#21495;&#21644;&#38750;&#31574;&#30053;&#25506;&#32034;&#33021;&#21147;&#26469;&#25913;&#21892;&#23398;&#20064;&#20449;&#21495;&#30340;&#20998;&#37197;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.02679</link><description>&lt;p&gt;
&#25193;&#25955;&#29983;&#25104;&#27969;&#37319;&#26679;&#22120;&#65306;&#36890;&#36807;&#37096;&#20998;&#36712;&#36857;&#20248;&#21270;&#25913;&#21892;&#23398;&#20064;&#20449;&#21495;
&lt;/p&gt;
&lt;p&gt;
Diffusion Generative Flow Samplers: Improving learning signals through partial trajectory optimization. (arXiv:2310.02679v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02679
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#25193;&#25955;&#29983;&#25104;&#27969;&#37319;&#26679;&#22120;&#65288;DGFS&#65289;&#30340;&#37319;&#26679;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#23398;&#20064;&#36807;&#31243;&#20998;&#35299;&#20026;&#30701;&#30340;&#37096;&#20998;&#36712;&#36857;&#27573;&#65292;&#23454;&#29616;&#20174;&#38590;&#20197;&#22788;&#29702;&#30340;&#39640;&#32500;&#23494;&#24230;&#20989;&#25968;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#23427;&#36890;&#36807;&#21033;&#29992;&#20013;&#38388;&#30340;&#23398;&#20064;&#20449;&#21495;&#21644;&#38750;&#31574;&#30053;&#25506;&#32034;&#33021;&#21147;&#26469;&#25913;&#21892;&#23398;&#20064;&#20449;&#21495;&#30340;&#20998;&#37197;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#20174;&#38590;&#20197;&#22788;&#29702;&#30340;&#39640;&#32500;&#23494;&#24230;&#20989;&#25968;&#20013;&#36827;&#34892;&#37319;&#26679;&#30340;&#38382;&#39064;&#65292;&#36825;&#26159;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#20013;&#32463;&#24120;&#20986;&#29616;&#30340;&#22522;&#26412;&#20219;&#21153;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;&#26368;&#36817;&#30340;&#22522;&#20110;&#37319;&#26679;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#25511;&#21046;&#30340;&#38543;&#26426;&#36807;&#31243;&#26469;&#27169;&#25311;&#36825;&#20123;&#30446;&#26631;&#23494;&#24230;&#30340;&#36817;&#20284;&#26679;&#26412;&#12290;&#36825;&#20123;&#26041;&#27861;&#30340;&#20027;&#35201;&#32570;&#28857;&#26159;&#35757;&#32451;&#30446;&#26631;&#38656;&#35201;&#35745;&#31639;&#23436;&#25972;&#30340;&#36712;&#36857;&#65292;&#23548;&#33268;&#30001;&#20110;&#20351;&#29992;&#23436;&#25972;&#36712;&#36857;&#21644;&#21482;&#22312;&#32456;&#31471;&#26102;&#38388;&#23384;&#22312;&#30340;&#23398;&#20064;&#20449;&#21495;&#30340;&#20351;&#29992;&#32780;&#20135;&#29983;&#32531;&#24930;&#30340;&#20449;&#29992;&#20998;&#37197;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#25193;&#25955;&#29983;&#25104;&#27969;&#37319;&#26679;&#22120;&#65288;DGFS&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;&#37319;&#26679;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#23558;&#23398;&#20064;&#36807;&#31243;&#21487;&#34892;&#22320;&#20998;&#35299;&#20026;&#30701;&#30340;&#37096;&#20998;&#36712;&#36857;&#27573;&#65292;&#36890;&#36807;&#21442;&#25968;&#21270;&#19968;&#20010;&#39069;&#22806;&#30340;&#8220;&#27969;&#20989;&#25968;&#8221;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20511;&#37492;&#20102;&#29983;&#25104;&#27969;&#32593;&#32476;&#65288;GFlowNets&#65289;&#30340;&#29702;&#35770;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#21033;&#29992;&#20013;&#38388;&#30340;&#23398;&#20064;&#20449;&#21495;&#65292;&#24182;&#20174;&#38750;&#31574;&#30053;&#25506;&#32034;&#33021;&#21147;&#20013;&#21463;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
We tackle the problem of sampling from intractable high-dimensional density functions, a fundamental task that often appears in machine learning and statistics. We extend recent sampling-based approaches that leverage controlled stochastic processes to model approximate samples from these target densities. The main drawback of these approaches is that the training objective requires full trajectories to compute, resulting in sluggish credit assignment issues due to use of entire trajectories and a learning signal present only at the terminal time. In this work, we present Diffusion Generative Flow Samplers (DGFS), a sampling-based framework where the learning process can be tractably broken down into short partial trajectory segments, via parameterizing an additional "flow function". Our method takes inspiration from the theory developed for generative flow networks (GFlowNets), allowing us to make use of intermediate learning signals and benefit from off-policy exploration capabilitie
&lt;/p&gt;</description></item><item><title>M-OFDFT&#26159;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#35299;&#20915;&#20998;&#23376;&#31995;&#32479;&#38382;&#39064;&#30340;OFDFT&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#38750;&#23616;&#22495;&#24615;&#24314;&#31435;&#22312;&#27169;&#22411;&#20013;&#24182;&#20351;&#29992;&#32039;&#20945;&#30340;&#23494;&#24230;&#34920;&#31034;&#65292;&#23454;&#29616;&#20102;&#19982;Kohn-Sham DFT&#30456;&#36817;&#30340;&#31934;&#30830;&#24230;&#65292;&#24182;&#19988;&#20855;&#26377;&#33391;&#22909;&#30340;&#22806;&#25512;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2309.16578</link><description>&lt;p&gt;
M-OFDFT&#65306;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#20811;&#26381;&#20998;&#23376;&#31995;&#32479;&#20013;&#30340;&#26080;&#36712;&#36947;&#23494;&#24230;&#27867;&#20989;&#29702;&#35770;&#30340;&#38556;&#30861;
&lt;/p&gt;
&lt;p&gt;
M-OFDFT: Overcoming the Barrier of Orbital-Free Density Functional Theory for Molecular Systems Using Deep Learning. (arXiv:2309.16578v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16578
&lt;/p&gt;
&lt;p&gt;
M-OFDFT&#26159;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#35299;&#20915;&#20998;&#23376;&#31995;&#32479;&#38382;&#39064;&#30340;OFDFT&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#38750;&#23616;&#22495;&#24615;&#24314;&#31435;&#22312;&#27169;&#22411;&#20013;&#24182;&#20351;&#29992;&#32039;&#20945;&#30340;&#23494;&#24230;&#34920;&#31034;&#65292;&#23454;&#29616;&#20102;&#19982;Kohn-Sham DFT&#30456;&#36817;&#30340;&#31934;&#30830;&#24230;&#65292;&#24182;&#19988;&#20855;&#26377;&#33391;&#22909;&#30340;&#22806;&#25512;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#36712;&#36947;&#23494;&#24230;&#27867;&#20989;&#29702;&#35770;&#65288;OFDFT&#65289;&#26159;&#19968;&#31181;&#20855;&#26377;&#36739;&#20302;&#36816;&#31639;&#25104;&#26412;&#30340;&#37327;&#23376;&#21270;&#23398;&#35745;&#31639;&#26041;&#27861;&#65292;&#27604;&#36215;&#24120;&#29992;&#30340;Kohn-Sham&#23494;&#24230;&#27867;&#20989;&#29702;&#35770;&#26356;&#21152;&#36866;&#29992;&#20110;&#24403;&#20195;&#20998;&#23376;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;OFDFT&#30340;&#31934;&#30830;&#24615;&#21463;&#21040;&#20102;&#21160;&#33021;&#23494;&#24230;&#27867;&#20989;&#30340;&#38480;&#21046;&#65292;&#23545;&#20110;&#38750;&#21608;&#26399;&#24615;&#20998;&#23376;&#31995;&#32479;&#30340;&#36817;&#20284;&#27714;&#35299;&#38750;&#24120;&#22256;&#38590;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#21517;&#20026;M-OFDFT&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#30340;&#20989;&#25968;&#27169;&#22411;&#35299;&#20915;&#20102;&#20998;&#23376;&#31995;&#32479;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#24517;&#35201;&#30340;&#38750;&#23616;&#22495;&#24615;&#24314;&#31435;&#22312;&#36825;&#20010;&#27169;&#22411;&#20013;&#65292;&#36890;&#36807;&#21407;&#23376;&#22522;&#19979;&#30340;&#23637;&#24320;&#31995;&#25968;&#20316;&#20026;&#32039;&#20945;&#30340;&#23494;&#24230;&#34920;&#31034;&#26469;&#38477;&#20302;&#25104;&#26412;&#12290;&#36890;&#36807;&#35299;&#20915;&#20854;&#20013;&#30340;&#38750;&#20256;&#32479;&#23398;&#20064;&#25361;&#25112;&#30340;&#25216;&#26415;&#65292;M-OFDFT&#22312;&#19968;&#31995;&#21015;OFDFT&#26080;&#27861;&#35302;&#21450;&#30340;&#20998;&#23376;&#19978;&#23454;&#29616;&#20102;&#19982;Kohn-Sham DFT&#30456;&#24403;&#30340;&#31934;&#30830;&#24230;&#12290;&#26356;&#26377;&#21560;&#24341;&#21147;&#30340;&#26159;&#65292;M-OFDFT&#22312;&#35757;&#32451;&#26102;&#23646;&#20110;&#26356;&#22823;&#30340;&#20998;&#23376;&#20013;&#26377;&#30528;&#33391;&#22909;&#30340;&#22806;&#25512;&#33021;&#21147;&#65292;&#20026;&#30740;&#31350;&#22823;&#20998;&#23376;&#25552;&#20379;&#20102;&#26377;&#21560;&#24341;&#21147;&#30340;&#35268;&#27169;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
Orbital-free density functional theory (OFDFT) is a quantum chemistry formulation that has a lower cost scaling than the prevailing Kohn-Sham DFT, which is increasingly desired for contemporary molecular research. However, its accuracy is limited by the kinetic energy density functional, which is notoriously hard to approximate for non-periodic molecular systems. In this work, we propose M-OFDFT, an OFDFT approach capable of solving molecular systems using a deep-learning functional model. We build the essential nonlocality into the model, which is made affordable by the concise density representation as expansion coefficients under an atomic basis. With techniques to address unconventional learning challenges therein, M-OFDFT achieves a comparable accuracy with Kohn-Sham DFT on a wide range of molecules untouched by OFDFT before. More attractively, M-OFDFT extrapolates well to molecules much larger than those in training, which unleashes the appealing scaling for studying large molecu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#24102;&#26377;&#25511;&#21046;&#21464;&#37327;&#30340;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#22312;&#23436;&#32654;&#21464;&#20998;&#26063;&#35268;&#33539;&#19979;&#20197;&#20960;&#20309;&#36895;&#24230;&#25910;&#25947;&#65292;&#20026;BBVI&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#23545;&#29109;&#26799;&#24230;&#20272;&#35745;&#22120;&#30340;&#25913;&#36827;&#65292;&#23545;&#27604;&#20102;STL&#20272;&#35745;&#22120;&#65292;&#24182;&#32473;&#20986;&#20102;&#26126;&#30830;&#30340;&#38750;&#28176;&#36817;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2307.14642</link><description>&lt;p&gt;
&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#30340;&#32447;&#24615;&#25910;&#25947;&#24615;&#65306;&#25105;&#20204;&#24212;&#35813;&#22362;&#25345;&#21040;&#24213;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Linear Convergence of Black-Box Variational Inference: Should We Stick the Landing?. (arXiv:2307.14642v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14642
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#24102;&#26377;&#25511;&#21046;&#21464;&#37327;&#30340;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#22312;&#23436;&#32654;&#21464;&#20998;&#26063;&#35268;&#33539;&#19979;&#20197;&#20960;&#20309;&#36895;&#24230;&#25910;&#25947;&#65292;&#20026;BBVI&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#23545;&#29109;&#26799;&#24230;&#20272;&#35745;&#22120;&#30340;&#25913;&#36827;&#65292;&#23545;&#27604;&#20102;STL&#20272;&#35745;&#22120;&#65292;&#24182;&#32473;&#20986;&#20102;&#26126;&#30830;&#30340;&#38750;&#28176;&#36817;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#24102;&#26377;&#25511;&#21046;&#21464;&#37327;&#30340;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#65288;BBVI&#65289;&#65292;&#29305;&#21035;&#26159;&#30528;&#38470;&#31283;&#23450;&#65288;STL&#65289;&#20272;&#35745;&#22120;&#65292;&#22312;&#23436;&#32654;&#21464;&#20998;&#26063;&#35268;&#33539;&#19979;&#25910;&#25947;&#20110;&#20960;&#20309;&#65288;&#20256;&#32479;&#19978;&#31216;&#20026;&#8220;&#32447;&#24615;&#8221;&#65289;&#36895;&#24230;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;STL&#20272;&#35745;&#22120;&#30340;&#26799;&#24230;&#26041;&#24046;&#30340;&#20108;&#27425;&#30028;&#38480;&#65292;&#35813;&#30028;&#38480;&#21253;&#25324;&#20102;&#35823;&#25351;&#23450;&#30340;&#21464;&#20998;&#26063;&#12290;&#32467;&#21512;&#20808;&#21069;&#20851;&#20110;&#20108;&#27425;&#26041;&#24046;&#26465;&#20214;&#30340;&#24037;&#20316;&#65292;&#36825;&#30452;&#25509;&#26263;&#31034;&#20102;&#22312;&#20351;&#29992;&#25237;&#24433;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#24773;&#20917;&#19979;BBVI&#30340;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#36824;&#25913;&#36827;&#20102;&#29616;&#26377;&#23545;&#20110;&#27491;&#24120;&#23553;&#38381;&#24418;&#24335;&#29109;&#26799;&#24230;&#20272;&#35745;&#22120;&#30340;&#20998;&#26512;&#65292;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#23558;&#20854;&#19982;STL&#20272;&#35745;&#22120;&#36827;&#34892;&#27604;&#36739;&#65292;&#24182;&#20026;&#20004;&#32773;&#25552;&#20379;&#26126;&#30830;&#30340;&#38750;&#28176;&#36827;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We prove that black-box variational inference (BBVI) with control variates, particularly the sticking-the-landing (STL) estimator, converges at a geometric (traditionally called "linear") rate under perfect variational family specification. In particular, we prove a quadratic bound on the gradient variance of the STL estimator, one which encompasses misspecified variational families. Combined with previous works on the quadratic variance condition, this directly implies convergence of BBVI with the use of projected stochastic gradient descent. We also improve existing analysis on the regular closed-form entropy gradient estimators, which enables comparison against the STL estimator and provides explicit non-asymptotic complexity guarantees for both.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#25299;&#25169;&#27491;&#21017;&#21270;&#30340;&#22810;&#23454;&#20363;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#32597;&#35265;&#36139;&#34880;&#30142;&#30149;&#30340;&#32418;&#32454;&#32990;&#20998;&#31867;&#12290;&#36890;&#36807;&#20174;&#21333;&#20010;&#32418;&#32454;&#32990;&#22270;&#20687;&#20013;&#25552;&#21462;&#22810;&#23610;&#24230;&#30340;&#25299;&#25169;&#29305;&#24449;&#26469;&#36827;&#34892;&#27169;&#22411;&#27491;&#21017;&#21270;&#65292;&#20197;&#20445;&#25345;&#25968;&#25454;&#30340;&#29305;&#24449;&#25299;&#25169;&#23646;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#26159;&#26377;&#25928;&#30340;&#12290;</title><link>http://arxiv.org/abs/2307.14025</link><description>&lt;p&gt;
&#22522;&#20110;&#25299;&#25169;&#27491;&#21017;&#21270;&#30340;&#22810;&#23454;&#20363;&#23398;&#20064;&#29992;&#20110;&#32418;&#32454;&#32990;&#30142;&#30149;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Topologically-Regularized Multiple Instance Learning for Red Blood Cell Disease Classification. (arXiv:2307.14025v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14025
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#25299;&#25169;&#27491;&#21017;&#21270;&#30340;&#22810;&#23454;&#20363;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#32597;&#35265;&#36139;&#34880;&#30142;&#30149;&#30340;&#32418;&#32454;&#32990;&#20998;&#31867;&#12290;&#36890;&#36807;&#20174;&#21333;&#20010;&#32418;&#32454;&#32990;&#22270;&#20687;&#20013;&#25552;&#21462;&#22810;&#23610;&#24230;&#30340;&#25299;&#25169;&#29305;&#24449;&#26469;&#36827;&#34892;&#27169;&#22411;&#27491;&#21017;&#21270;&#65292;&#20197;&#20445;&#25345;&#25968;&#25454;&#30340;&#29305;&#24449;&#25299;&#25169;&#23646;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#26159;&#26377;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#26174;&#24494;&#22270;&#20687;&#35786;&#26029;&#32597;&#35265;&#30340;&#36139;&#34880;&#30142;&#30149;&#23545;&#20110;&#29087;&#32451;&#30340;&#19987;&#23478;&#21644;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#26469;&#35828;&#37117;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#30001;&#20110;&#22312;&#21333;&#20010;&#34880;&#26679;&#20013;&#26377;&#25968;&#21315;&#20010;&#19982;&#30142;&#30149;&#30456;&#20851;&#30340;&#32454;&#32990;&#65292;&#36825;&#26500;&#25104;&#20102;&#19968;&#20010;&#22797;&#26434;&#30340;&#22810;&#23454;&#20363;&#23398;&#20064;&#65288;MIL&#65289;&#38382;&#39064;&#12290;&#34429;&#28982;&#32418;&#32454;&#32990;&#30340;&#31354;&#38388;&#37051;&#22495;&#26412;&#36523;&#24182;&#19981;&#37325;&#35201;&#65292;&#20294;&#25972;&#20010;&#34880;&#26679;&#30340;&#25299;&#25169;&#32467;&#26500;&#65292;&#21363;&#25968;&#25454;&#30340;&#20960;&#20309;&#24615;&#36136;&#65292;&#21253;&#21547;&#20102;&#26377;&#30410;&#30340;&#29305;&#24449;&#65292;&#20197;&#35299;&#20915;&#20856;&#22411;&#30340;MIL&#38382;&#39064;&#65292;&#22914;&#26799;&#24230;&#28040;&#22833;&#21644;&#22312;&#26377;&#38480;&#25968;&#25454;&#19978;&#35757;&#32451;&#26102;&#30340;&#36807;&#25311;&#21512;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#25299;&#25169;&#30340;&#26041;&#27861;&#65292;&#20174;&#21333;&#20010;&#32418;&#32454;&#32990;&#22270;&#20687;&#30340;&#21253;&#20013;&#25552;&#21462;&#22810;&#23610;&#24230;&#30340;&#25299;&#25169;&#29305;&#24449;&#12290;&#36825;&#20123;&#25299;&#25169;&#29305;&#24449;&#34987;&#29992;&#26469;&#23545;&#27169;&#22411;&#36827;&#34892;&#27491;&#21017;&#21270;&#65292;&#24378;&#21046;&#20445;&#25345;&#25968;&#25454;&#30340;&#29305;&#24449;&#25299;&#25169;&#23646;&#24615;&#12290;&#22312;&#21253;&#21547;71&#20010;&#32597;&#35265;&#36139;&#34880;&#30142;&#30149;&#24739;&#32773;&#30340;&#25968;&#25454;&#38598;&#19978;&#65292;&#21253;&#25324;521&#24352;&#32418;&#32454;&#32990;&#26174;&#24494;&#22270;&#20687;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#25299;&#25169;&#27491;&#21017;&#21270;&#26159;&#19968;&#20010;&#26377;&#25928;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diagnosing rare anemia disorders using microscopic images is challenging for skilled specialists and machine-learning methods alike. Due to thousands of disease-relevant cells in a single blood sample, this constitutes a complex multiple-instance learning (MIL) problem. While the spatial neighborhood of red blood cells is not meaningful per se, the topology, i.e., the geometry of blood samples as a whole, contains informative features to remedy typical MIL issues, such as vanishing gradients and overfitting when training on limited data. We thus develop a topology-based approach that extracts multi-scale topological features from bags of single red blood cell images. The topological features are used to regularize the model, enforcing the preservation of characteristic topological properties of the data. Applied to a dataset of 71 patients suffering from rare anemia disorders with 521 microscopic images of red blood cells, our experiments show that topological regularization is an effe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;NetHack&#28216;&#25103;&#20013;&#30340;&#27169;&#20223;&#23398;&#20064;&#65292;&#21457;&#29616;&#36890;&#36807;&#25193;&#22823;&#27169;&#22411;&#21644;&#25968;&#25454;&#35268;&#27169;&#21487;&#20197;&#25913;&#36827;&#27169;&#20223;&#23398;&#20064;&#30340;&#25928;&#26524;&#65292;&#24182;&#24314;&#31435;&#20102;&#35757;&#32451;&#35745;&#31639;&#26368;&#20248;IL&#20195;&#29702;&#20154;&#30340;&#24130;&#24459;&#12290;</title><link>http://arxiv.org/abs/2307.09423</link><description>&lt;p&gt;
&#22312;NetHack&#20013;&#30340;&#27169;&#20223;&#23398;&#20064;&#30340;&#35268;&#27169;&#24459;
&lt;/p&gt;
&lt;p&gt;
Scaling Laws for Imitation Learning in NetHack. (arXiv:2307.09423v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09423
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;NetHack&#28216;&#25103;&#20013;&#30340;&#27169;&#20223;&#23398;&#20064;&#65292;&#21457;&#29616;&#36890;&#36807;&#25193;&#22823;&#27169;&#22411;&#21644;&#25968;&#25454;&#35268;&#27169;&#21487;&#20197;&#25913;&#36827;&#27169;&#20223;&#23398;&#20064;&#30340;&#25928;&#26524;&#65292;&#24182;&#24314;&#31435;&#20102;&#35757;&#32451;&#35745;&#31639;&#26368;&#20248;IL&#20195;&#29702;&#20154;&#30340;&#24130;&#24459;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#20223;&#23398;&#20064; (IL) &#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#24120;&#29992;&#30340;&#26041;&#27861;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#34429;&#28982;&#24378;&#22823;&#65292;&#20294;&#35768;&#22810;&#30740;&#31350;&#21457;&#29616;&#23427;&#24448;&#24448;&#19981;&#33021;&#23436;&#20840;&#24674;&#22797;&#20986;&#28508;&#22312;&#30340;&#19987;&#23478;&#34892;&#20026;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30740;&#31350;&#27809;&#26377;&#28145;&#20837;&#25506;&#31350;&#27169;&#22411;&#21644;&#25968;&#25454;&#35268;&#27169;&#30340;&#25193;&#22823;&#22312;&#20854;&#20013;&#30340;&#20316;&#29992;&#12290;&#21463;&#26368;&#36817;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702; (NLP) &#39046;&#22495;&#30340;&#24037;&#20316;&#30340;&#21551;&#21457;&#65292;&#22312;&#37027;&#37324;&#8220;&#25193;&#22823;&#35268;&#27169;&#8221;&#24050;&#32463;&#23548;&#33268;&#20102;&#36234;&#26469;&#36234;&#26377;&#33021;&#21147;&#30340;&#39046;&#22495;&#29305;&#23450;&#35821;&#35328;&#27169;&#22411; (LLMs)&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20180;&#32454;&#25193;&#22823;&#27169;&#22411;&#21644;&#25968;&#25454;&#35268;&#27169;&#26159;&#21542;&#21487;&#20197;&#22312;&#27169;&#20223;&#23398;&#20064;&#30340;&#35774;&#32622;&#20013;&#24102;&#26469;&#31867;&#20284;&#30340;&#25913;&#36827;&#12290;&#20026;&#20102;&#23637;&#31034;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#25105;&#20204;&#23558;&#37325;&#28857;&#25918;&#22312; NetHack &#28216;&#25103;&#19978;&#65292;&#36825;&#26159;&#19968;&#20010;&#20855;&#26377;&#31243;&#24207;&#29983;&#25104;&#12289;&#38543;&#26426;&#24615;&#12289;&#38271;&#26399;&#20381;&#36182;&#24615;&#21644;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#30340;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#29615;&#22659;&#12290;&#25105;&#20204;&#21457;&#29616; IL &#30340;&#25439;&#22833;&#21644;&#24179;&#22343;&#22238;&#25253;&#38543;&#30528;&#35745;&#31639;&#39044;&#31639;&#30340;&#21464;&#21270;&#32780;&#24179;&#28369;&#21464;&#21270;&#19988;&#24378;&#30456;&#20851;&#65292;&#20174;&#32780;&#22312;&#27169;&#22411;&#22823;&#23567;&#21644;&#26679;&#26412;&#25968;&#37327;&#26041;&#38754;&#20026;&#35757;&#32451;&#35745;&#31639;&#26368;&#20248;&#30340; IL &#20195;&#29702;&#20154;&#30340;&#35745;&#31639;&#39044;&#31639;&#24314;&#31435;&#20102;&#24130;&#24459;&#12290;&#25105;&#20204;&#39044;&#27979;&#24182;&#35757;&#32451;&#20102;&#20960;&#20010;&#20855;&#26377; IL &#30340;NetHack&#20195;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Imitation Learning (IL) is one of the most widely used methods in machine learning. Yet, while powerful, many works find it is often not able to fully recover the underlying expert behavior. However, none of these works deeply investigate the role of scaling up the model and data size. Inspired by recent work in Natural Language Processing (NLP) where "scaling up" has resulted in increasingly more capable LLMs, we investigate whether carefully scaling up model and data size can bring similar improvements in the imitation learning setting. To demonstrate our findings, we focus on the game of NetHack, a challenging environment featuring procedural generation, stochasticity, long-term dependencies, and partial observability. We find IL loss and mean return scale smoothly with the compute budget and are strongly correlated, resulting in power laws for training compute-optimal IL agents with respect to model size and number of samples. We forecast and train several NetHack agents with IL an
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#29305;&#24449;&#20998;&#24067;&#24335;&#25968;&#25454;&#30340;&#21487;&#25193;&#23637;&#39640;&#32500;&#22810;&#21464;&#37327;&#32447;&#24615;&#22238;&#24402;&#31639;&#27861;&#65292;&#20855;&#26377;&#36890;&#20449;&#22797;&#26434;&#24230;&#19981;&#20381;&#36182;&#20110;&#29305;&#24449;&#32500;&#24230;&#21644;&#24555;&#36895;&#25910;&#25947;&#24615;&#30340;&#20248;&#21183;&#65292;&#21487;&#24212;&#29992;&#20110;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#21644;&#20855;&#26377;&#22810;&#21464;&#37327;&#21709;&#24212;&#21464;&#37327;&#30340;&#22330;&#26223;&#12290;</title><link>http://arxiv.org/abs/2307.03410</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#39640;&#32500;&#22810;&#21464;&#37327;&#32447;&#24615;&#22238;&#24402;&#29992;&#20110;&#29305;&#24449;&#20998;&#24067;&#24335;&#25968;&#25454;&#32763;&#35793;&#26631;&#39064;
&lt;/p&gt;
&lt;p&gt;
Scalable High-Dimensional Multivariate Linear Regression for Feature-Distributed Data. (arXiv:2307.03410v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03410
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#29305;&#24449;&#20998;&#24067;&#24335;&#25968;&#25454;&#30340;&#21487;&#25193;&#23637;&#39640;&#32500;&#22810;&#21464;&#37327;&#32447;&#24615;&#22238;&#24402;&#31639;&#27861;&#65292;&#20855;&#26377;&#36890;&#20449;&#22797;&#26434;&#24230;&#19981;&#20381;&#36182;&#20110;&#29305;&#24449;&#32500;&#24230;&#21644;&#24555;&#36895;&#25910;&#25947;&#24615;&#30340;&#20248;&#21183;&#65292;&#21487;&#24212;&#29992;&#20110;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#21644;&#20855;&#26377;&#22810;&#21464;&#37327;&#21709;&#24212;&#21464;&#37327;&#30340;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#20998;&#24067;&#24335;&#25968;&#25454;&#26159;&#25351;&#26681;&#25454;&#29305;&#24449;&#21010;&#20998;&#24182;&#23384;&#20648;&#22312;&#22810;&#20010;&#35745;&#31639;&#33410;&#28857;&#19978;&#30340;&#25968;&#25454;&#65292;&#22312;&#20855;&#26377;&#22823;&#37327;&#29305;&#24449;&#30340;&#24212;&#29992;&#20013;&#36234;&#26469;&#36234;&#24120;&#35265;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#36825;&#31181;&#25968;&#25454;&#30340;&#20004;&#38454;&#27573;&#25918;&#26494;&#36138;&#23146;&#31639;&#27861; (TSRGA)&#65292;&#29992;&#20110;&#24212;&#29992;&#22810;&#21464;&#37327;&#32447;&#24615;&#22238;&#24402;&#12290;TSRGA &#30340;&#20027;&#35201;&#20248;&#21183;&#22312;&#20110;&#20854;&#36890;&#20449;&#22797;&#26434;&#24230;&#19981;&#20381;&#36182;&#20110;&#29305;&#24449;&#32500;&#24230;&#65292;&#20351;&#20854;&#33021;&#22815;&#39640;&#24230;&#25193;&#23637;&#21040;&#38750;&#24120;&#22823;&#30340;&#25968;&#25454;&#38598;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#22810;&#21464;&#37327;&#21709;&#24212;&#21464;&#37327;&#65292;TSRGA &#21487;&#29992;&#20110;&#20135;&#29983;&#20302;&#31209;&#31995;&#25968;&#20272;&#35745;&#12290;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#20102;TSRGA &#30340;&#24555;&#36895;&#25910;&#25947;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#25552;&#20986;&#30340;TSRGA &#24212;&#29992;&#20110;&#19968;&#31181;&#37329;&#34701;&#24212;&#29992;&#20013;&#65292;&#21033;&#29992;&#26469;&#33258; 10-K &#25253;&#21578;&#30340;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#20855;&#26377;&#35768;&#22810;&#23494;&#38598;&#22823;&#32500;&#30697;&#38453;&#30340;&#24212;&#29992;&#20013;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Feature-distributed data, referred to data partitioned by features and stored across multiple computing nodes, are increasingly common in applications with a large number of features. This paper proposes a two-stage relaxed greedy algorithm (TSRGA) for applying multivariate linear regression to such data. The main advantage of TSRGA is that its communication complexity does not depend on the feature dimension, making it highly scalable to very large data sets. In addition, for multivariate response variables, TSRGA can be used to yield low-rank coefficient estimates. The fast convergence of TSRGA is validated by simulation experiments. Finally, we apply the proposed TSRGA in a financial application that leverages unstructured data from the 10-K reports, demonstrating its usefulness in applications with many dense large-dimensional matrices.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#36866;&#24212;&#24615;&#39044;&#27979;&#38598;&#30340;&#26399;&#26395;&#22823;&#23567;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#37327;&#21270;&#26041;&#27861;&#20197;&#21450;&#28857;&#20272;&#35745;&#21644;&#39640;&#27010;&#29575;&#21306;&#38388;&#65292;&#24182;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;&#20854;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.07254</link><description>&lt;p&gt;
&#20851;&#20110;&#36866;&#24212;&#24615;&#39044;&#27979;&#38598;&#26399;&#26395;&#22823;&#23567;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Expected Size of Conformal Prediction Sets. (arXiv:2306.07254v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07254
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#36866;&#24212;&#24615;&#39044;&#27979;&#38598;&#30340;&#26399;&#26395;&#22823;&#23567;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#37327;&#21270;&#26041;&#27861;&#20197;&#21450;&#28857;&#20272;&#35745;&#21644;&#39640;&#27010;&#29575;&#21306;&#38388;&#65292;&#24182;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;&#20854;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#36866;&#24212;&#24615;&#39044;&#27979;&#22120;&#22312;&#35823;&#24046;&#39057;&#29575;&#26041;&#38754;&#20855;&#26377;&#20005;&#26684;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#20294;&#20854;&#39044;&#27979;&#38598;&#22823;&#23567;&#23545;&#20854;&#23454;&#38469;&#25928;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#30446;&#21069;&#32570;&#20047;&#26377;&#38480;&#26679;&#26412;&#20998;&#26512;&#21644;&#39044;&#27979;&#38598;&#22823;&#23567;&#30340;&#20445;&#35777;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#22312;&#20998;&#35010;&#36866;&#24212;&#24615;&#39044;&#27979;&#26694;&#26550;&#19979;&#29702;&#35770;&#37327;&#21270;&#39044;&#27979;&#38598;&#30340;&#26399;&#26395;&#22823;&#23567;&#12290;&#22240;&#20026;&#36825;&#31181;&#31934;&#30830;&#30340;&#35745;&#31639;&#36890;&#24120;&#26080;&#27861;&#30452;&#25509;&#35745;&#31639;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25512;&#23548;&#20986;&#21487;&#36731;&#26494;&#35745;&#31639;&#30340;&#28857;&#20272;&#35745;&#21644;&#39640;&#27010;&#29575;&#21306;&#38388;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#25551;&#36848;&#27979;&#35797;&#21644;&#26657;&#20934;&#25968;&#25454;&#19981;&#21516;&#21487;&#33021;&#23454;&#29616;&#30340;&#26399;&#26395;&#39044;&#27979;&#38598;&#22823;&#23567;&#30340;&#23454;&#29992;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#23545;&#22238;&#24402;&#21644;&#20998;&#31867;&#38382;&#39064;&#30340;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#39564;&#35777;&#23454;&#20102;&#25105;&#20204;&#32467;&#26524;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
While conformal predictors reap the benefits of rigorous statistical guarantees for their error frequency, the size of their corresponding prediction sets is critical to their practical utility. Unfortunately, there is currently a lack of finite-sample analysis and guarantees for their prediction set sizes. To address this shortfall, we theoretically quantify the expected size of the prediction set under the split conformal prediction framework. As this precise formulation cannot usually be calculated directly, we further derive point estimates and high probability intervals that can be easily computed, providing a practical method for characterizing the expected prediction set size across different possible realizations of the test and calibration data. Additionally, we corroborate the efficacy of our results with experiments on real-world datasets, for both regression and classification problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22686;&#37327;&#23398;&#20064;&#20998;&#31867;&#26041;&#27861;&#8212;&#8212;&#22522;&#20110;&#39044;&#27979;&#35823;&#24046;&#30340;&#20998;&#31867;&#26041;&#27861;&#65288;PEC&#65289;&#12290;&#23545;PEC&#30340;&#35780;&#20272;&#34920;&#26126;&#65292;&#22312;&#21508;&#31181;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;PEC&#21487;&#20197;&#19982;&#26368;&#20808;&#36827;&#30340;&#22686;&#37327;&#23398;&#20064;&#26041;&#27861;&#30456;&#31454;&#20105;&#65292;&#24182;&#20855;&#26377;&#35768;&#22810;&#23454;&#38469;&#20248;&#21183;&#65292;&#20363;&#22914;&#26679;&#26412;&#25928;&#29575;&#39640;&#12289;&#26131;&#20110;&#35843;&#25972;&#12290;</title><link>http://arxiv.org/abs/2305.18806</link><description>&lt;p&gt;
&#22522;&#20110;&#39044;&#27979;&#35823;&#24046;&#30340;&#22686;&#37327;&#23398;&#20064;&#20998;&#31867;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Prediction Error-based Classification for Class-Incremental Learning. (arXiv:2305.18806v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18806
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22686;&#37327;&#23398;&#20064;&#20998;&#31867;&#26041;&#27861;&#8212;&#8212;&#22522;&#20110;&#39044;&#27979;&#35823;&#24046;&#30340;&#20998;&#31867;&#26041;&#27861;&#65288;PEC&#65289;&#12290;&#23545;PEC&#30340;&#35780;&#20272;&#34920;&#26126;&#65292;&#22312;&#21508;&#31181;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;PEC&#21487;&#20197;&#19982;&#26368;&#20808;&#36827;&#30340;&#22686;&#37327;&#23398;&#20064;&#26041;&#27861;&#30456;&#31454;&#20105;&#65292;&#24182;&#20855;&#26377;&#35768;&#22810;&#23454;&#38469;&#20248;&#21183;&#65292;&#20363;&#22914;&#26679;&#26412;&#25928;&#29575;&#39640;&#12289;&#26131;&#20110;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22686;&#37327;&#23398;&#20064;&#20998;&#31867;&#26159;&#36830;&#32493;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#25361;&#25112;&#24615;&#38382;&#39064;&#65292;&#30446;&#26631;&#26159;&#23398;&#20064;&#26469;&#21306;&#20998;&#25152;&#26377;&#31867;&#21035;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#22312;&#22788;&#29702;&#22823;&#37327;&#20998;&#31867;&#26102;&#23481;&#26131;&#20986;&#29616;&#36807;&#24230;&#36951;&#24536;&#21644;&#20998;&#25968;&#19981;&#22343;&#34913;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21517;&#20026;&#39044;&#27979;&#35823;&#24046;&#20998;&#31867;&#65288;PEC&#65289;&#65292;&#23427;&#19982;&#20256;&#32479;&#30340;&#21028;&#21035;&#21644;&#29983;&#25104;&#20998;&#31867;&#33539;&#24335;&#26377;&#25152;&#19981;&#21516;&#12290;PEC&#36890;&#36807;&#27979;&#37327;&#27169;&#22411;&#22312;&#20174;&#35813;&#31867;&#21035;&#20013;&#23398;&#20064;&#30340;&#25968;&#25454;&#19978;&#22797;&#21046;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#36755;&#20986;&#30340;&#39044;&#27979;&#35823;&#24046;&#26469;&#35745;&#31639;&#31867;&#21035;&#24471;&#20998;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#35299;&#37322;&#20026;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#21518;&#39564;&#26041;&#24046;&#30340;&#20998;&#31867;&#35268;&#21017;&#30340;&#36817;&#20284;&#12290;PEC&#20855;&#26377;&#20960;&#20010;&#23454;&#38469;&#20248;&#21183;&#65292;&#21253;&#25324;&#26679;&#26412;&#25928;&#29575;&#39640;&#12289;&#26131;&#20110;&#35843;&#25972;&#20197;&#21450;&#21363;&#20351;&#22312;&#36880;&#20010;&#21576;&#29616;&#25968;&#25454;&#26102;&#20063;&#24456;&#26377;&#25928;&#12290;&#26412;&#25991;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;PEC&#22312;&#24191;&#27867;&#30340;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#21487;&#20197;&#19982;&#26368;&#20808;&#36827;&#30340;&#22686;&#37327;&#23398;&#20064;&#26041;&#27861;&#30456;&#31454;&#20105;&#12290;
&lt;/p&gt;
&lt;p&gt;
Class-incremental learning (CIL) is a particularly challenging variant of continual learning, where the goal is to learn to discriminate between all classes presented in an incremental fashion. Existing approaches often suffer from excessive forgetting and imbalance of the scores assigned to classes that have not been seen together during training. In this study, we introduce a novel approach, Prediction Error-based Classification (PEC), which differs from traditional discriminative and generative classification paradigms. PEC computes a class score by measuring the prediction error of a model trained to replicate the outputs of a frozen random neural network on data from that class. The method can be interpreted as approximating a classification rule based on Gaussian Process posterior variance. PEC offers several practical advantages, including sample efficiency, ease of tuning, and effectiveness even when data are presented one class at a time. Our empirical results show that PEC pe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38381;&#29615;&#26694;&#26550;&#65292;&#21363;LLMs&#20316;&#20026;&#24037;&#20855;&#21046;&#36896;&#32773;&#65288;LATM&#65289;&#65292;&#20351;LLMs&#33021;&#22815;&#33258;&#20027;&#22320;&#21019;&#24314;&#29992;&#20110;&#35299;&#20915;&#38382;&#39064;&#30340;&#24037;&#20855;&#65292;&#32780;&#19981;&#38656;&#35201;&#20381;&#36182;&#20110;&#29616;&#26377;&#30340;&#22806;&#37096;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2305.17126</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#24037;&#20855;&#21046;&#36896;&#32773;
&lt;/p&gt;
&lt;p&gt;
Large Language Models as Tool Makers. (arXiv:2305.17126v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17126
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38381;&#29615;&#26694;&#26550;&#65292;&#21363;LLMs&#20316;&#20026;&#24037;&#20855;&#21046;&#36896;&#32773;&#65288;LATM&#65289;&#65292;&#20351;LLMs&#33021;&#22815;&#33258;&#20027;&#22320;&#21019;&#24314;&#29992;&#20110;&#35299;&#20915;&#38382;&#39064;&#30340;&#24037;&#20855;&#65292;&#32780;&#19981;&#38656;&#35201;&#20381;&#36182;&#20110;&#29616;&#26377;&#30340;&#22806;&#37096;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;&#20351;&#29992;&#22806;&#37096;&#24037;&#20855;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21487;&#20197;&#22686;&#24378;&#20854;&#38382;&#39064;&#35299;&#20915;&#33021;&#21147;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#26041;&#38754;&#30340;&#20808;&#21069;&#24037;&#20316;&#20381;&#36182;&#20110;&#29616;&#26377;&#24037;&#20855;&#30340;&#21487;&#29992;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38381;&#29615;&#26694;&#26550;&#65292;&#31216;&#20026;LLMs As Tool Makers&#65288;LATM&#65289;&#65292;&#20197;&#28040;&#38500;&#36825;&#31181;&#20381;&#36182;&#24615;&#65292;&#20854;&#20013;LLMs&#21019;&#24314;&#33258;&#24049;&#30340;&#21487;&#37325;&#29992;&#24037;&#20855;&#26469;&#35299;&#20915;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21253;&#25324;&#20004;&#20010;&#20851;&#38190;&#38454;&#27573;&#65306;1&#65289;&#21046;&#36896;&#24037;&#20855;&#65306;LLM&#20316;&#20026;&#24037;&#20855;&#21046;&#36896;&#32773;&#65292;&#20026;&#32473;&#23450;&#20219;&#21153;&#21046;&#20316;&#24037;&#20855;&#65292;&#20854;&#20013;&#24037;&#20855;&#20316;&#20026;Python&#23454;&#29992;&#20989;&#25968;&#23454;&#29616;&#12290;2&#65289;&#20351;&#29992;&#24037;&#20855;&#65306;LLM&#20316;&#20026;&#24037;&#20855;&#29992;&#25143;&#65292;&#24212;&#29992;&#24037;&#20855;&#21046;&#36896;&#32773;&#26500;&#24314;&#30340;&#24037;&#20855;&#26469;&#35299;&#20915;&#38382;&#39064;&#12290;&#24037;&#20855;&#29992;&#25143;&#21487;&#20197;&#26159;&#19982;&#24037;&#20855;&#21046;&#36896;&#32773;&#30456;&#21516;&#25110;&#19981;&#21516;&#30340;LLM&#12290;&#24037;&#20855;&#21046;&#36896;&#20351;LLM&#33021;&#22815;&#19981;&#26029;&#29983;&#25104;&#21487;&#24212;&#29992;&#20110;&#19981;&#21516;&#35831;&#27714;&#30340;&#24037;&#20855;&#65292;&#20197;&#20415;&#23558;&#26469;&#35831;&#27714;&#22312;&#35299;&#20915;&#38382;&#39064;&#26102;&#33021;&#35843;&#29992;&#30456;&#24212;&#30340;API&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent research shows the potential of enhancing the problem-solving ability of large language models (LLMs) through the use of external tools. However, prior work along this line depends on the availability of existing tools. In this work, we take an initial step towards removing this dependency by proposing a closed-loop framework, referred to as LLMs As Tool Makers (LATM), where LLMs create their own reusable tools for problem-solving. Our approach consists of two key phases: 1) tool making: an LLM acts as the tool maker that crafts tools for given tasks, where a tool is implemented as a Python utility function. 2) tool using: an LLM acts as the tool user, which applies the tool built by the tool maker for problem-solving. The tool user can be either the same or a different LLM from the tool maker. Tool-making enables an LLM to continually generate tools that can be applied to different requests so that future requests can call the corresponding APIs when beneficial for solving the 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#36890;&#36807;&#21152;&#26435;&#34928;&#20943;&#35757;&#32451;&#30340;&#22810;&#36755;&#20986;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#20989;&#25968;&#31867;&#22411;&#21644;&#30456;&#24212;&#30340;&#35299;&#20915;&#26041;&#26696;&#30340;&#26032;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2305.16534</link><description>&lt;p&gt;
&#21521;&#37327;&#20540;&#21464;&#20998;&#31354;&#38388;&#21644;DNN&#30340;&#23485;&#24230;&#30028;&#65306;&#20851;&#20110;&#26435;&#37325;&#34928;&#20943;&#27491;&#21017;&#21270;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Vector-Valued Variation Spaces and Width Bounds for DNNs: Insights on Weight Decay Regularization. (arXiv:2305.16534v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16534
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#36890;&#36807;&#21152;&#26435;&#34928;&#20943;&#35757;&#32451;&#30340;&#22810;&#36755;&#20986;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#20989;&#25968;&#31867;&#22411;&#21644;&#30456;&#24212;&#30340;&#35299;&#20915;&#26041;&#26696;&#30340;&#26032;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#26368;&#23567;&#21270;&#25439;&#22833;&#39033;&#21644;&#24179;&#26041;&#26435;&#37325;&#21644;&#30456;&#24212;&#65292;&#23545;&#24212;&#20110;&#35757;&#32451;&#21152;&#26435;&#34928;&#20943;&#30340;&#24120;&#35265;&#26041;&#27861;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#26377;&#20851;&#36825;&#31181;&#24120;&#35265;&#23398;&#20064;&#26694;&#26550;&#30340;&#26032;&#35265;&#35299;&#12290;&#25105;&#20204;&#34920;&#24449;&#20102;&#35757;&#32451;&#21152;&#26435;&#34928;&#20943;&#20197;&#33719;&#24471;&#22810;&#36755;&#20986;(&#21521;&#37327;&#20540;)ReLU&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#30340;&#20989;&#25968;&#31867;&#22411;&#12290;&#36825;&#25193;&#23637;&#20102;&#20808;&#21069;&#38480;&#20110;&#21333;&#36755;&#20986;(&#26631;&#37327;&#20540;)&#32593;&#32476;&#30340;&#34920;&#24449;&#12290;&#36825;&#31181;&#34920;&#24449;&#38656;&#35201;&#23450;&#20041;&#25105;&#20204;&#31216;&#20043;&#20026;&#21521;&#37327;&#20540;&#21464;&#20998;(VV)&#31354;&#38388;&#30340;&#26032;&#31867;&#31070;&#32463;&#20989;&#25968;&#31354;&#38388;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#31181;&#26032;&#30340;&#34920;&#24449;&#23450;&#29702;&#35777;&#26126;&#65292;&#31070;&#32463;&#32593;&#32476;(NNs)&#26159;&#36890;&#36807;VV&#31354;&#38388;&#20013;&#25552;&#20986;&#23398;&#20064;&#38382;&#39064;&#30340;&#26368;&#20248;&#35299;&#12290;&#36825;&#20010;&#26032;&#30340;&#34920;&#24449;&#23450;&#29702;&#34920;&#26126;&#65292;&#36825;&#20123;&#23398;&#20064;&#38382;&#39064;&#30340;&#35299;&#23384;&#22312;&#20110;&#23485;&#24230;&#21463;&#35757;&#32451;&#25968;&#25454;&#25968;&#38480;&#21046;&#30340;&#21521;&#37327;&#20540;&#31070;&#32463;&#32593;&#32476;&#20013;&#12290;&#25509;&#19979;&#26469;&#65292;&#36890;&#36807;&#19982;&#22810;&#20219;&#21153;lasso&#38382;&#39064;&#30340;&#26032;&#32852;&#31995;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks (DNNs) trained to minimize a loss term plus the sum of squared weights via gradient descent corresponds to the common approach of training with weight decay. This paper provides new insights into this common learning framework. We characterize the kinds of functions learned by training with weight decay for multi-output (vector-valued) ReLU neural networks. This extends previous characterizations that were limited to single-output (scalar-valued) networks. This characterization requires the definition of a new class of neural function spaces that we call vector-valued variation (VV) spaces. We prove that neural networks (NNs) are optimal solutions to learning problems posed over VV spaces via a novel representer theorem. This new representer theorem shows that solutions to these learning problems exist as vector-valued neural networks with widths bounded in terms of the number of training data. Next, via a novel connection to the multi-task lasso problem, we derive
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36125;&#21494;&#26031;&#26412;&#22320;&#20248;&#21270;&#31574;&#30053;&#30340;&#34892;&#20026;&#21644;&#25910;&#25947;&#24615;&#65292;&#24182;&#22312;&#39640;&#32500;&#38382;&#39064;&#19978;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#23454;&#35777;&#24615;&#33021;&#12290;&#32479;&#35745;&#25968;&#25454;&#34920;&#26126;&#65292;&#21333;&#20010;&#39640;&#26031;&#36807;&#31243;&#26679;&#26412;&#36335;&#24452;&#30340;&#26412;&#22320;&#35299;&#27604;&#20840;&#23616;&#26041;&#27861;&#24674;&#22797;&#30340;&#39044;&#26399;&#20540;&#26356;&#22909;&#12290;M&#252;ller&#31561;&#20154;&#25552;&#20986;&#30340;&#36125;&#21494;&#26031;&#26412;&#22320;&#20248;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#29575;&#22312;&#26377;&#22122;&#38899;&#21644;&#26080;&#22122;&#38899;&#30340;&#24773;&#20917;&#19979;&#37117;&#26377;&#25512;&#23548;&#12290;</title><link>http://arxiv.org/abs/2305.15572</link><description>&lt;p&gt;
&#26412;&#22320;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#34892;&#20026;&#21644;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
The Behavior and Convergence of Local Bayesian Optimization. (arXiv:2305.15572v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15572
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36125;&#21494;&#26031;&#26412;&#22320;&#20248;&#21270;&#31574;&#30053;&#30340;&#34892;&#20026;&#21644;&#25910;&#25947;&#24615;&#65292;&#24182;&#22312;&#39640;&#32500;&#38382;&#39064;&#19978;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#23454;&#35777;&#24615;&#33021;&#12290;&#32479;&#35745;&#25968;&#25454;&#34920;&#26126;&#65292;&#21333;&#20010;&#39640;&#26031;&#36807;&#31243;&#26679;&#26412;&#36335;&#24452;&#30340;&#26412;&#22320;&#35299;&#27604;&#20840;&#23616;&#26041;&#27861;&#24674;&#22797;&#30340;&#39044;&#26399;&#20540;&#26356;&#22909;&#12290;M&#252;ller&#31561;&#20154;&#25552;&#20986;&#30340;&#36125;&#21494;&#26031;&#26412;&#22320;&#20248;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#29575;&#22312;&#26377;&#22122;&#38899;&#21644;&#26080;&#22122;&#38899;&#30340;&#24773;&#20917;&#19979;&#37117;&#26377;&#25512;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#19968;&#39033;&#26368;&#26032;&#30340;&#21457;&#23637;&#26159;&#20351;&#29992;&#26412;&#22320;&#20248;&#21270;&#31574;&#30053;&#65292;&#19982;&#20256;&#32479;&#30340;&#20840;&#23616;&#31574;&#30053;&#30456;&#27604;&#65292;&#21487;&#20197;&#22312;&#39640;&#32500;&#38382;&#39064;&#19978;&#25552;&#20379;&#24378;&#22823;&#30340;&#23454;&#35777;&#24615;&#33021;&#12290;&#25991;&#29486;&#20013;&#30340;&#8220;&#20256;&#32479;&#26234;&#24935;&#8221;&#26159;&#65292;&#19987;&#27880;&#20110;&#26412;&#22320;&#20248;&#21270;&#35268;&#36991;&#20102;&#32500;&#24230;&#35781;&#21650;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#36125;&#21494;&#26031;&#26412;&#22320;&#20248;&#21270;&#20363;&#31243;&#30340;&#39044;&#26399;&#34892;&#20026;&#25110;&#25910;&#25947;&#24615;&#20102;&#35299;&#29978;&#23569;&#12290;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#20102;&#26412;&#22320;&#26041;&#27861;&#30340;&#34892;&#20026;&#65292;&#24182;&#21457;&#29616;&#39640;&#26031;&#36807;&#31243;&#26679;&#26412;&#36335;&#24452;&#21333;&#20010;&#26412;&#22320;&#35299;&#30340;&#32479;&#35745;&#25968;&#25454;&#19982;&#20174;&#20840;&#23616;&#26041;&#27861;&#24674;&#22797;&#30340;&#39044;&#26399;&#20540;&#30456;&#27604;&#38750;&#24120;&#22909;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26368;&#36817;&#30001;M&#252;ller&#31561;&#20154;&#25552;&#20986;&#30340;&#22522;&#20110;&#36125;&#21494;&#26031;&#26412;&#22320;&#20248;&#21270;&#31639;&#27861;&#30340;&#31532;&#19968;&#27425;&#20005;&#26684;&#20998;&#26512;&#65292;&#24182;&#22312;&#26377;&#22122;&#38899;&#21644;&#26080;&#22122;&#38899;&#30340;&#24773;&#20917;&#19979;&#25512;&#23548;&#20986;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
A recent development in Bayesian optimization is the use of local optimization strategies, which can deliver strong empirical performance on high-dimensional problems compared to traditional global strategies. The "folk wisdom" in the literature is that the focus on local optimization sidesteps the curse of dimensionality; however, little is known concretely about the expected behavior or convergence of Bayesian local optimization routines. We first study the behavior of the local approach, and find that the statistics of individual local solutions of Gaussian process sample paths are surprisingly good compared to what we would expect to recover from global methods. We then present the first rigorous analysis of such a Bayesian local optimization algorithm recently proposed by M\"uller et al. (2021), and derive convergence rates in both the noisy and noiseless settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;Cholesky&#20998;&#35299;&#31639;&#27861;&#65292;&#29992;&#20110;&#39640;&#26031;&#36807;&#31243;&#27714;&#35299;&#38750;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#65292;&#33021;&#22815;&#26377;&#25928;&#22788;&#29702;&#39640;&#32500;&#21644;&#30072;&#24418;&#22495;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.01294</link><description>&lt;p&gt;
&#36890;&#36807;&#39640;&#26031;&#36807;&#31243;&#27714;&#35299;&#38750;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#31232;&#30095;Cholesky&#20998;&#35299;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sparse Cholesky Factorization for Solving Nonlinear PDEs via Gaussian Processes. (arXiv:2304.01294v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01294
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;Cholesky&#20998;&#35299;&#31639;&#27861;&#65292;&#29992;&#20110;&#39640;&#26031;&#36807;&#31243;&#27714;&#35299;&#38750;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#65292;&#33021;&#22815;&#26377;&#25928;&#22788;&#29702;&#39640;&#32500;&#21644;&#30072;&#24418;&#22495;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#39640;&#26031;&#36807;&#31243;&#26694;&#26550;&#27714;&#35299;&#19968;&#33324;&#38750;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#35745;&#31639;&#21487;&#20280;&#32553;&#24615;&#12290;&#36825;&#20010;&#26694;&#26550;&#25226;&#27714;&#35299;PDE&#36716;&#21270;&#20026;&#35299;&#38750;&#32447;&#24615;&#32422;&#26463;&#19979;&#30340;&#20108;&#27425;&#20248;&#21270;&#38382;&#39064;&#12290;&#20854;&#22797;&#26434;&#24230;&#30340;&#29942;&#39048;&#22312;&#20110;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#30340;&#21327;&#26041;&#24046;&#26680;&#21450;&#20854;&#22312;&#25311;&#21512;&#28857;&#30340;&#20559;&#23548;&#25968;&#36827;&#34892;&#28857;&#23545;&#28857;&#35745;&#31639;&#25152;&#24471;&#21040;&#30340;&#23494;&#38598;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#35745;&#31639;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Diracs&#21644;&#23548;&#25968;&#27979;&#37327;&#30340;&#26032;&#25490;&#21015;&#39034;&#24207;&#30340;&#31232;&#30095;Cholesky&#20998;&#35299;&#31639;&#27861;&#29992;&#20110;&#35745;&#31639;&#27492;&#31867;&#21327;&#26041;&#24046;&#30697;&#38453;&#12290;&#25105;&#20204;&#20005;&#26684;&#22320;&#30830;&#23450;&#20102;&#35813;Cholesky&#20998;&#35299;&#30340;&#31232;&#30095;&#27169;&#24335;&#65292;&#24182;&#37327;&#21270;&#20102;&#30456;&#24212;Vecchia&#36817;&#20284;&#30340;&#25351;&#25968;&#25910;&#25947;&#31934;&#24230;&#65292;&#22312;Kullback-Leibler&#36317;&#31163;&#24230;&#37327;&#19979;&#36798;&#21040;&#26368;&#20248;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#20197;$O(N\log^d(N/\epsilon))$&#30340;&#31354;&#38388;&#22797;&#26434;&#24230;&#21644;$O(N\log^{d+2}(N/\epsilon))$&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#35745;&#31639;$\epsilon$-&#36817;&#20284;&#30340;&#36870;Cholesky&#22240;&#23376;&#12290;&#20854;&#20013;&#65292;$N$&#34920;&#31034;&#25311;&#21512;&#28857;&#30340;&#25968;&#37327;&#65292;$d$&#20026;&#29289;&#29702;&#22495;&#30340;&#32500;&#25968;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#39640;&#32500;&#65288;&#26368;&#39640;&#21487;&#36798;&#21040;$d=50$&#65289;&#21644;&#30072;&#24418;&#22495;&#30340;&#22522;&#20934;&#38382;&#39064;&#19978;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the computational scalability of a Gaussian process (GP) framework for solving general nonlinear partial differential equations (PDEs). This framework transforms solving PDEs to solving quadratic optimization problem with nonlinear constraints. Its complexity bottleneck lies in computing with dense kernel matrices obtained from pointwise evaluations of the covariance kernel of the GP and its partial derivatives at collocation points.  We present a sparse Cholesky factorization algorithm for such kernel matrices based on the near-sparsity of the Cholesky factor under a new ordering of Diracs and derivative measurements. We rigorously identify the sparsity pattern and quantify the exponentially convergent accuracy of the corresponding Vecchia approximation of the GP, which is optimal in the Kullback-Leibler divergence. This enables us to compute $\epsilon$-approximate inverse Cholesky factors of the kernel matrices with complexity $O(N\log^d(N/\epsilon))$ in space and $O(N\log^{
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#21442;&#25968;&#39034;&#24207;&#26816;&#39564;&#21644;&#32622;&#20449;&#21306;&#38388;&#65292;&#22312;&#19968;&#33324;&#38750;&#21442;&#25968;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#19979;&#25552;&#20379;&#20102;&#31867;&#22411;I&#38169;&#35823;&#21644;&#26399;&#26395;&#25298;&#32477;&#26102;&#38388;&#20445;&#35777;&#65292;&#25552;&#39640;&#20102;&#20854;&#28789;&#27963;&#24615;&#21644;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2212.14411</link><description>&lt;p&gt;
&#36817;&#20284;&#26368;&#20248;&#30340;&#38750;&#21442;&#25968;&#39034;&#24207;&#26816;&#39564;&#21644;&#20855;&#26377;&#21487;&#33021;&#30456;&#20851;&#35266;&#27979;&#30340;&#32622;&#20449;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;
Near-Optimal Non-Parametric Sequential Tests and Confidence Sequences with Possibly Dependent Observations. (arXiv:2212.14411v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.14411
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#21442;&#25968;&#39034;&#24207;&#26816;&#39564;&#21644;&#32622;&#20449;&#21306;&#38388;&#65292;&#22312;&#19968;&#33324;&#38750;&#21442;&#25968;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#19979;&#25552;&#20379;&#20102;&#31867;&#22411;I&#38169;&#35823;&#21644;&#26399;&#26395;&#25298;&#32477;&#26102;&#38388;&#20445;&#35777;&#65292;&#25552;&#39640;&#20102;&#20854;&#28789;&#27963;&#24615;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39034;&#24207;&#26816;&#39564;&#21644;&#20854;&#38544;&#21547;&#30340;&#32622;&#20449;&#21306;&#38388;&#22312;&#20219;&#24847;&#20572;&#27490;&#26102;&#38388;&#19979;&#37117;&#33021;&#25552;&#20379;&#28789;&#27963;&#30340;&#32479;&#35745;&#25512;&#26029;&#21644;&#21363;&#26102;&#20915;&#31574;&#12290;&#28982;&#32780;&#65292;&#24378;&#26377;&#21147;&#30340;&#20445;&#35777;&#20165;&#36866;&#29992;&#20110;&#22312;&#23454;&#36341;&#20013;&#20302;&#20272;&#25110;&#27987;&#24230;&#30028;&#38480;&#20026;&#22522;&#30784;&#30340;&#39034;&#24207;&#24207;&#21015;&#65292;&#32780;&#36825;&#20123;&#24207;&#21015;&#20855;&#26377;&#27425;&#20248;&#30340;&#25298;&#32477;&#26102;&#38388;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#32599;&#23486;&#26031;&#65288;Robbins&#65289;1970&#24180;&#30340;&#24310;&#36831;&#21551;&#21160;&#27491;&#24577;&#28151;&#21512;&#39034;&#24207;&#27010;&#29575;&#27604;&#26816;&#39564;&#65292;&#24182;&#22312;&#19968;&#33324;&#38750;&#21442;&#25968;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#19979;&#25552;&#20379;&#20102;&#39318;&#20010;&#28176;&#36817;&#31867;&#22411;I&#38169;&#35823;&#21644;&#26399;&#26395;&#25298;&#32477;&#26102;&#38388;&#20445;&#35777;&#65292;&#20854;&#20013;&#28176;&#36817;&#24615;&#36136;&#30001;&#27979;&#35797;&#30340;&#28903;&#20837;&#26102;&#38388;&#30830;&#23450;&#12290;&#31867;&#22411;I&#38169;&#35823;&#30340;&#32467;&#26524;&#20027;&#35201;&#20381;&#36182;&#20110;&#38789;&#24378;&#19981;&#21464;&#21407;&#29702;&#65292;&#24182;&#35777;&#26126;&#36825;&#20123;&#26816;&#39564;&#65288;&#21450;&#20854;&#38544;&#21547;&#30340;&#32622;&#20449;&#21306;&#38388;&#65289;&#20855;&#26377;&#25509;&#36817;&#25152;&#38656;&#945;&#27700;&#24179;&#30340;&#31867;&#22411;I&#38169;&#35823;&#29575;&#12290;&#26399;&#26395;&#25298;&#32477;&#26102;&#38388;&#30340;&#32467;&#26524;&#20027;&#35201;&#21033;&#29992;&#20102;&#19968;&#31181;&#21463;&#20234;&#34276;&#24341;&#29702;&#21551;&#21457;&#30340;&#24658;&#31561;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential tests and their implied confidence sequences, which are valid at arbitrary stopping times, promise flexible statistical inference and on-the-fly decision making. However, strong guarantees are limited to parametric sequential tests that under-cover in practice or concentration-bound-based sequences that over-cover and have suboptimal rejection times. In this work, we consider \cite{robbins1970boundary}'s delayed-start normal-mixture sequential probability ratio tests, and we provide the first asymptotic type-I-error and expected-rejection-time guarantees under general non-parametric data generating processes, where the asymptotics are indexed by the test's burn-in time. The type-I-error results primarily leverage a martingale strong invariance principle and establish that these tests (and their implied confidence sequences) have type-I error rates approaching a desired $\alpha$-level. The expected-rejection-time results primarily leverage an identity inspired by It\^o's lemm
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#33258;&#36866;&#24212;&#21464;&#20998;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#22810;&#20010;&#27169;&#22411;&#19978;&#36816;&#34892;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#33258;&#36866;&#24212;&#22320;&#23454;&#29616;&#26368;&#20248;&#30340;&#25910;&#32553;&#36895;&#29575;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#25216;&#26415;&#26041;&#27861;&#26469;&#20445;&#25345;&#21487;&#35745;&#31639;&#24615;&#21644;&#33258;&#36866;&#24212;&#26368;&#20248;&#24615;&#12290;</title><link>http://arxiv.org/abs/2109.03204</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#21464;&#20998;&#36125;&#21494;&#26031;&#65306;&#20248;&#21270;&#24615;&#36136;&#65292;&#35745;&#31639;&#21644;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Adaptive variational Bayes: Optimality, computation and applications. (arXiv:2109.03204v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.03204
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#33258;&#36866;&#24212;&#21464;&#20998;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#22810;&#20010;&#27169;&#22411;&#19978;&#36816;&#34892;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#33258;&#36866;&#24212;&#22320;&#23454;&#29616;&#26368;&#20248;&#30340;&#25910;&#32553;&#36895;&#29575;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#25216;&#26415;&#26041;&#27861;&#26469;&#20445;&#25345;&#21487;&#35745;&#31639;&#24615;&#21644;&#33258;&#36866;&#24212;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22522;&#20110;&#21464;&#20998;&#36125;&#21494;&#26031;&#30340;&#33258;&#36866;&#24212;&#25512;&#26029;&#12290;&#34429;&#28982;&#24050;&#32463;&#36827;&#34892;&#20102;&#19968;&#20123;&#30740;&#31350;&#26469;&#20998;&#26512;&#21464;&#20998;&#21518;&#39564;&#30340;&#25910;&#25947;&#24615;&#36136;&#65292;&#20294;&#20173;&#28982;&#32570;&#20047;&#19968;&#31181;&#36890;&#29992;&#19988;&#20855;&#26377;&#35745;&#31639;&#21487;&#34892;&#24615;&#30340;&#33258;&#36866;&#24212;&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;&#12290;&#20026;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#33258;&#36866;&#24212;&#21464;&#20998;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#22810;&#20010;&#27169;&#22411;&#19978;&#36816;&#34892;&#12290;&#35813;&#26694;&#26550;&#39318;&#20808;&#20998;&#21035;&#35745;&#31639;&#27599;&#20010;&#21333;&#29420;&#27169;&#22411;&#30340;&#21464;&#20998;&#21518;&#39564;&#65292;&#28982;&#21518;&#23558;&#23427;&#20204;&#19982;&#19968;&#23450;&#30340;&#26435;&#37325;&#32467;&#21512;&#36215;&#26469;&#65292;&#20135;&#29983;&#25972;&#20010;&#27169;&#22411;&#30340;&#21464;&#20998;&#21518;&#39564;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20010;&#32452;&#21512;&#30340;&#21464;&#20998;&#21518;&#39564;&#26159;&#22312;&#39044;&#23450;&#20041;&#30340;&#19968;&#26063;&#36817;&#20284;&#20998;&#24067;&#20013;&#26368;&#25509;&#36817;&#25972;&#20010;&#27169;&#22411;&#30340;&#21518;&#39564;&#30340;&#25104;&#21592;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#38750;&#24120;&#26222;&#36941;&#30340;&#26465;&#20214;&#19979;&#65292;&#33258;&#36866;&#24212;&#21464;&#20998;&#36125;&#21494;&#26031;&#21487;&#20197;&#33258;&#36866;&#24212;&#22320;&#23454;&#29616;&#26368;&#20248;&#30340;&#25910;&#32553;&#36895;&#29575;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#25216;&#26415;&#26041;&#27861;&#26469;&#20445;&#25345;&#21487;&#35745;&#31639;&#24615;&#21644;&#33258;&#36866;&#24212;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we explore adaptive inference based on variational Bayes. Although several studies have been conducted to analyze the contraction properties of variational posteriors, there is still a lack of a general and computationally tractable variational Bayes method that performs adaptive inference. To fill this gap, we propose a novel adaptive variational Bayes framework, which can operate on a collection of models. The proposed framework first computes a variational posterior over each individual model separately and then combines them with certain weights to produce a variational posterior over the entire model. It turns out that this combined variational posterior is the closest member to the posterior over the entire model in a predefined family of approximating distributions. We show that the adaptive variational Bayes attains optimal contraction rates adaptively under very general conditions. We also provide a methodology to maintain the tractability and adaptive optimalit
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20013;&#30340;&#36127;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#30340;&#23616;&#37096;&#26497;&#23567;&#20540;&#32467;&#26500;&#65292;&#21457;&#29616;&#23427;&#20204;&#37117;&#20849;&#20139;&#19968;&#31181;&#24120;&#35265;&#32467;&#26500;&#32780;&#37096;&#20998;&#30830;&#23450;&#20102;&#30495;&#27491;&#30340;&#20301;&#32622;&#28151;&#21512;&#29289;&#30340;&#31751;&#20013;&#24515;&#12290;&#36825;&#20123;&#32467;&#26524;&#36866;&#29992;&#20110;&#30495;&#23454;&#28151;&#21512;&#32452;&#20998;&#28385;&#36275;&#26576;&#31181;&#20998;&#31163;&#26465;&#20214;&#30340;&#24773;&#20917;&#65292;&#20063;&#36866;&#29992;&#20110;&#25104;&#20998;&#25968;&#37327;&#36807;&#22810;&#25110;&#36807;&#23569;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2009.13040</link><description>&lt;p&gt;
&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20013;&#30340;&#23616;&#37096;&#26497;&#23567;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
Local Minima Structures in Gaussian Mixture Models. (arXiv:2009.13040v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2009.13040
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20013;&#30340;&#36127;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#30340;&#23616;&#37096;&#26497;&#23567;&#20540;&#32467;&#26500;&#65292;&#21457;&#29616;&#23427;&#20204;&#37117;&#20849;&#20139;&#19968;&#31181;&#24120;&#35265;&#32467;&#26500;&#32780;&#37096;&#20998;&#30830;&#23450;&#20102;&#30495;&#27491;&#30340;&#20301;&#32622;&#28151;&#21512;&#29289;&#30340;&#31751;&#20013;&#24515;&#12290;&#36825;&#20123;&#32467;&#26524;&#36866;&#29992;&#20110;&#30495;&#23454;&#28151;&#21512;&#32452;&#20998;&#28385;&#36275;&#26576;&#31181;&#20998;&#31163;&#26465;&#20214;&#30340;&#24773;&#20917;&#65292;&#20063;&#36866;&#29992;&#20110;&#25104;&#20998;&#25968;&#37327;&#36807;&#22810;&#25110;&#36807;&#23569;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#20154;&#21475;&#26497;&#38480;&#30340;&#24773;&#20917;&#19979;&#35843;&#26597;&#20102;&#28151;&#21512;&#25104;&#20998;&#27169;&#22411;&#65288;GMM&#65289;&#30340;&#36127;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#30340;&#24773;&#20917;&#65292;&#24182;&#25506;&#35752;&#20102;&#20855;&#26377;&#19968;&#33324;&#25104;&#20998;&#25968;&#37327;&#30340;GMM&#30340;&#36127;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#30340;&#23616;&#37096;&#26497;&#23567;&#20540;&#32467;&#26500;&#12290;&#30001;&#20110;&#30446;&#26631;&#20989;&#25968;&#26159;&#38750;&#20984;&#30340;&#65292;&#21363;&#20351;&#23545;&#20110;&#20998;&#31163;&#33391;&#22909;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#20063;&#21487;&#33021;&#23384;&#22312;&#19981;&#26159;&#20840;&#23616;&#26368;&#20248;&#30340;&#22810;&#20010;&#23616;&#37096;&#26497;&#23567;&#20540;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#25152;&#26377;&#23616;&#37096;&#26497;&#23567;&#20540;&#37117;&#20849;&#20139;&#19968;&#31181;&#24120;&#35265;&#32467;&#26500;&#65292;&#35813;&#32467;&#26500;&#37096;&#20998;&#30830;&#23450;&#20102;&#30495;&#27491;&#30340;&#20301;&#32622;&#28151;&#21512;&#29289;&#65288;&#21363;&#39640;&#26031;&#25104;&#20998;&#30340;&#22343;&#20540;&#65289;&#30340;&#31751;&#20013;&#24515;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#27599;&#20010;&#23616;&#37096;&#26497;&#23567;&#20540;&#21487;&#20197;&#34920;&#31034;&#20026;&#20004;&#31181;&#31867;&#22411;&#23376;&#37197;&#32622;&#30340;&#38750;&#37325;&#21472;&#32452;&#21512;&#65306;&#23558;&#21333;&#20010;&#22343;&#20540;&#20272;&#35745;&#19982;&#22810;&#20010;&#39640;&#26031;&#20998;&#37327;&#25311;&#21512;&#25110;&#23558;&#22810;&#20010;&#20272;&#35745;&#25311;&#21512;&#21040;&#21333;&#20010;&#30495;&#23454;&#20998;&#37327;&#12290;&#36825;&#20123;&#32467;&#26524;&#36866;&#29992;&#20110;&#30495;&#23454;&#28151;&#21512;&#32452;&#20998;&#28385;&#36275;&#26576;&#31181;&#20998;&#31163;&#26465;&#20214;&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#22312;&#25104;&#20998;&#25968;&#37327;&#36807;&#22810;&#25110;&#36807;&#23569;&#30340;&#24773;&#20917;&#19979;&#20063;&#26159;&#26377;&#25928;&#30340;&#12290;&#25105;&#20204;&#36824;&#38024;&#23545;&#19968;&#32500;&#39640;&#26031;&#28151;&#21512;&#29289;&#30340;&#35774;&#32622;&#25552;&#20379;&#20102;&#26356;&#31934;&#32454;&#30340;&#20998;&#26512;&#65292;&#36890;&#36807;&#32467;&#26500;&#35745;&#25968;&#35770;&#35777;&#23548;&#20986;&#20102;&#36825;&#20123;&#38750;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#31934;&#30830;&#25968;&#37327;&#21644;&#23427;&#20204;&#23545;&#24212;&#30340;&#37197;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the landscape of the negative log-likelihood function of Gaussian Mixture Models (GMMs) with a general number of components in the population limit. As the objective function is non-convex, there can be multiple local minima that are not globally optimal, even for well-separated mixture models. Our study reveals that all local minima share a common structure that partially identifies the cluster centers (i.e., means of the Gaussian components) of the true location mixture. Specifically, each local minimum can be represented as a non-overlapping combination of two types of sub-configurations: fitting a single mean estimate to multiple Gaussian components or fitting multiple estimates to a single true component. These results apply to settings where the true mixture components satisfy a certain separation condition, and are valid even when the number of components is overor under-specified. We also present a more fine-grained analysis for the setting of one-dimensional G
&lt;/p&gt;</description></item></channel></rss>