<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#23494;&#38598;&#23545;&#24212;&#20851;&#31995;&#20174;&#26080;&#21160;&#20316;&#35270;&#39057;&#20013;&#23398;&#20064;&#25191;&#34892;&#21160;&#20316;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#19981;&#20351;&#29992;&#20219;&#20309;&#21160;&#20316;&#27880;&#37322;&#30340;&#24773;&#20917;&#19979;&#26500;&#24314;&#21487;&#38752;&#25191;&#34892;&#22810;&#26679;&#20219;&#21153;&#30340;&#22522;&#20110;&#35270;&#39057;&#30340;&#26426;&#22120;&#20154;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2310.08576</link><description>&lt;p&gt;
&#36890;&#36807;&#23494;&#38598;&#23545;&#24212;&#20851;&#31995;&#20174;&#26080;&#21160;&#20316;&#35270;&#39057;&#20013;&#23398;&#20064;&#25191;&#34892;&#21160;&#20316;
&lt;/p&gt;
&lt;p&gt;
Learning to Act from Actionless Videos through Dense Correspondences. (arXiv:2310.08576v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08576
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#23494;&#38598;&#23545;&#24212;&#20851;&#31995;&#20174;&#26080;&#21160;&#20316;&#35270;&#39057;&#20013;&#23398;&#20064;&#25191;&#34892;&#21160;&#20316;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#19981;&#20351;&#29992;&#20219;&#20309;&#21160;&#20316;&#27880;&#37322;&#30340;&#24773;&#20917;&#19979;&#26500;&#24314;&#21487;&#38752;&#25191;&#34892;&#22810;&#26679;&#20219;&#21153;&#30340;&#22522;&#20110;&#35270;&#39057;&#30340;&#26426;&#22120;&#20154;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#23569;&#37327;&#35270;&#39057;&#28436;&#31034;&#26500;&#24314;&#19968;&#20010;&#22522;&#20110;&#35270;&#39057;&#30340;&#26426;&#22120;&#20154;&#31574;&#30053;&#65292;&#33021;&#22815;&#21487;&#38752;&#22320;&#22312;&#19981;&#21516;&#26426;&#22120;&#20154;&#21644;&#29615;&#22659;&#19979;&#25191;&#34892;&#21508;&#31181;&#20219;&#21153;&#65292;&#32780;&#26080;&#38656;&#20351;&#29992;&#20219;&#20309;&#21160;&#20316;&#27880;&#37322;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#22270;&#20687;&#20316;&#20026;&#20219;&#21153;&#19981;&#21487;&#30693;&#30340;&#34920;&#31034;&#65292;&#32534;&#30721;&#29366;&#24577;&#21644;&#21160;&#20316;&#20449;&#24687;&#65292;&#24182;&#20351;&#29992;&#25991;&#26412;&#20316;&#20026;&#25351;&#23450;&#26426;&#22120;&#20154;&#30446;&#26631;&#30340;&#36890;&#29992;&#34920;&#31034;&#12290;&#36890;&#36807;&#21512;&#25104;&#8220;&#22914;&#24187;&#33324;&#8221;&#25191;&#34892;&#21160;&#20316;&#30340;&#35270;&#39057;&#65292;&#24182;&#32467;&#21512;&#24103;&#20043;&#38388;&#30340;&#23494;&#38598;&#23545;&#24212;&#20851;&#31995;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#25512;&#26029;&#20986;&#22312;&#29615;&#22659;&#20013;&#25191;&#34892;&#30340;&#38381;&#21512;&#24418;&#24335;&#21160;&#20316;&#65292;&#32780;&#19981;&#38656;&#35201;&#20219;&#20309;&#26174;&#24335;&#30340;&#21160;&#20316;&#26631;&#31614;&#12290;&#36825;&#31181;&#29420;&#29305;&#30340;&#33021;&#21147;&#20351;&#25105;&#20204;&#33021;&#22815;&#20165;&#22522;&#20110;RGB&#35270;&#39057;&#35757;&#32451;&#31574;&#30053;&#65292;&#24182;&#23558;&#23398;&#20064;&#21040;&#30340;&#31574;&#30053;&#37096;&#32626;&#21040;&#21508;&#31181;&#26426;&#22120;&#20154;&#20219;&#21153;&#20013;&#12290;&#25105;&#20204;&#22312;&#26700;&#38754;&#25805;&#20316;&#21644;&#23548;&#33322;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#36129;&#29486;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#35270;&#39057;&#24314;&#27169;&#24320;&#28304;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we present an approach to construct a video-based robot policy capable of reliably executing diverse tasks across different robots and environments from few video demonstrations without using any action annotations. Our method leverages images as a task-agnostic representation, encoding both the state and action information, and text as a general representation for specifying robot goals. By synthesizing videos that ``hallucinate'' robot executing actions and in combination with dense correspondences between frames, our approach can infer the closed-formed action to execute to an environment without the need of any explicit action labels. This unique capability allows us to train the policy solely based on RGB videos and deploy learned policies to various robotic tasks. We demonstrate the efficacy of our approach in learning policies on table-top manipulation and navigation tasks. Additionally, we contribute an open-source framework for efficient video modeling, enabling 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30417;&#30563;&#39044;&#35757;&#32451;&#65292;&#35813;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#20998;&#26512;&#20102;&#22823;&#22411;Transformer&#27169;&#22411;&#22312;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#30740;&#31350;&#35777;&#26126;&#65292;&#22312;&#20551;&#35774;&#27169;&#22411;&#21487;&#23454;&#29616;&#30340;&#24773;&#20917;&#19979;&#65292;&#32463;&#36807;&#30417;&#30563;&#39044;&#35757;&#32451;&#30340;Transformer&#27169;&#22411;&#33021;&#22815;&#27169;&#20223;&#19987;&#23478;&#31639;&#27861;&#22312;&#35266;&#23519;&#21040;&#30340;&#36712;&#36857;&#19978;&#30340;&#26465;&#20214;&#26399;&#26395;&#12290;</title><link>http://arxiv.org/abs/2310.08566</link><description>&lt;p&gt;
&#20197;Transformer&#20026;&#20915;&#31574;&#32773;&#65306;&#36890;&#36807;&#30417;&#30563;&#39044;&#35757;&#32451;&#23454;&#29616;&#21487;&#35777;&#26126;&#30340;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Transformers as Decision Makers: Provable In-Context Reinforcement Learning via Supervised Pretraining. (arXiv:2310.08566v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08566
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30417;&#30563;&#39044;&#35757;&#32451;&#65292;&#35813;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#20998;&#26512;&#20102;&#22823;&#22411;Transformer&#27169;&#22411;&#22312;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#30740;&#31350;&#35777;&#26126;&#65292;&#22312;&#20551;&#35774;&#27169;&#22411;&#21487;&#23454;&#29616;&#30340;&#24773;&#20917;&#19979;&#65292;&#32463;&#36807;&#30417;&#30563;&#39044;&#35757;&#32451;&#30340;Transformer&#27169;&#22411;&#33021;&#22815;&#27169;&#20223;&#19987;&#23478;&#31639;&#27861;&#22312;&#35266;&#23519;&#21040;&#30340;&#36712;&#36857;&#19978;&#30340;&#26465;&#20214;&#26399;&#26395;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#25968;&#25454;&#38598;&#19978;&#39044;&#35757;&#32451;&#30340;&#22823;&#22411;Transformer&#27169;&#22411;&#23637;&#31034;&#20102;&#20196;&#20154;&#24778;&#21497;&#30340;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#33021;&#21147;&#65292;&#21363;&#24403;&#23427;&#20204;&#38754;&#23545;&#26469;&#33258;&#26410;&#30693;&#29615;&#22659;&#30340;&#20132;&#20114;&#36712;&#36857;&#26102;&#65292;&#23427;&#20204;&#33021;&#22815;&#20570;&#20986;&#33391;&#22909;&#30340;&#20915;&#31574;&#12290;&#28982;&#32780;&#65292;Transformer&#27169;&#22411;&#22914;&#20309;&#36827;&#34892;&#35757;&#32451;&#20197;&#25191;&#34892;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#65292;&#22312;&#29702;&#35770;&#19978;&#23578;&#26410;&#24471;&#21040;&#24456;&#22909;&#30340;&#29702;&#35299;&#12290;&#29305;&#21035;&#26159;&#65292;&#23578;&#19981;&#28165;&#26970;Transformer&#27169;&#22411;&#21487;&#20197;&#22312;&#19978;&#19979;&#25991;&#20013;&#25191;&#34892;&#21738;&#20123;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#20197;&#21450;&#31163;&#32447;&#35757;&#32451;&#25968;&#25454;&#20013;&#30340;&#20998;&#24067;&#24046;&#24322;&#22914;&#20309;&#24433;&#21709;&#24050;&#23398;&#20064;&#30340;&#31639;&#27861;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#20998;&#26512;&#20102;&#23545;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#30340;&#30417;&#30563;&#39044;&#35757;&#32451;&#12290;&#36825;&#21253;&#25324;&#20102;&#20004;&#31181;&#26368;&#36817;&#25552;&#20986;&#30340;&#35757;&#32451;&#26041;&#27861;&#65306;&#31639;&#27861;&#33976;&#39311;&#21644;&#20915;&#31574;&#39044;&#35757;&#32451;&#30340;Transformer&#27169;&#22411;&#12290;&#39318;&#20808;&#65292;&#22312;&#20551;&#35774;&#27169;&#22411;&#21487;&#23454;&#29616;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#32463;&#36807;&#30417;&#30563;&#39044;&#35757;&#32451;&#30340;Transformer&#27169;&#22411;&#23558;&#27169;&#20223;&#19987;&#23478;&#31639;&#27861;&#22312;&#35266;&#23519;&#21040;&#30340;&#36712;&#36857;&#19978;&#30340;&#26465;&#20214;&#26399;&#26395;&#12290;&#24191;&#20041;&#35823;&#24046;&#30340;&#32553;&#25918;&#33539;&#22260;&#19982;&#8230;
&lt;/p&gt;
&lt;p&gt;
Large transformer models pretrained on offline reinforcement learning datasets have demonstrated remarkable in-context reinforcement learning (ICRL) capabilities, where they can make good decisions when prompted with interaction trajectories from unseen environments. However, when and how transformers can be trained to perform ICRL have not been theoretically well-understood. In particular, it is unclear which reinforcement-learning algorithms transformers can perform in context, and how distribution mismatch in offline training data affects the learned algorithms. This paper provides a theoretical framework that analyzes supervised pretraining for ICRL. This includes two recently proposed training methods -- algorithm distillation and decision-pretrained transformers. First, assuming model realizability, we prove the supervised-pretrained transformer will imitate the conditional expectation of the expert algorithm given the observed trajectory. The generalization error will scale with
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#20351;&#29992;&#22238;&#22768;&#29366;&#24577;&#32593;&#32476;&#65288;ESN&#65289;&#26469;&#21051;&#30011;&#27668;&#20505;&#36335;&#24452;&#30340;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#29305;&#24449;&#37325;&#35201;&#24615;&#20998;&#26512;&#26469;&#20102;&#35299;&#21508;&#20010;&#21464;&#37327;&#23545;&#27668;&#20505;&#36335;&#24452;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.08495</link><description>&lt;p&gt;
&#21033;&#29992;&#22238;&#22768;&#29366;&#24577;&#32593;&#32476;&#23545;&#27668;&#20505;&#36335;&#24452;&#36827;&#34892;&#29305;&#24449;&#37325;&#35201;&#24615;&#21051;&#30011;
&lt;/p&gt;
&lt;p&gt;
Characterizing climate pathways using feature importance on echo state networks. (arXiv:2310.08495v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08495
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#20351;&#29992;&#22238;&#22768;&#29366;&#24577;&#32593;&#32476;&#65288;ESN&#65289;&#26469;&#21051;&#30011;&#27668;&#20505;&#36335;&#24452;&#30340;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#29305;&#24449;&#37325;&#35201;&#24615;&#20998;&#26512;&#26469;&#20102;&#35299;&#21508;&#20010;&#21464;&#37327;&#23545;&#27668;&#20505;&#36335;&#24452;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32654;&#22269;2022&#24180;&#22269;&#38450;&#25112;&#30053;&#23558;&#27668;&#20505;&#21464;&#21270;&#21015;&#20026;&#23545;&#22269;&#23478;&#23433;&#20840;&#30340;&#20005;&#37325;&#23041;&#32961;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#35832;&#22914;&#24179;&#27969;&#23618;&#27668;&#28342;&#33014;&#21943;&#23556;&#31561;&#27668;&#20505;&#24178;&#39044;&#26041;&#27861;&#20316;&#20026;&#32531;&#35299;&#31574;&#30053;&#65292;&#20294;&#27492;&#31867;&#34892;&#21160;&#23545;&#22797;&#26434;&#27668;&#20505;&#31995;&#32479;&#30340;&#19979;&#28216;&#24433;&#21709;&#23578;&#19981;&#26126;&#30830;&#12290;&#24320;&#21457;&#37327;&#21270;&#19982;&#27668;&#20505;&#20107;&#20214;&#30456;&#20851;&#30340;&#28304;&#21644;&#24433;&#21709;&#21464;&#37327;&#65288;&#21363;&#27668;&#20505;&#36335;&#24452;&#65289;&#20043;&#38388;&#20851;&#31995;&#30340;&#31639;&#27861;&#25216;&#26415;&#23558;&#26377;&#21161;&#20110;&#20915;&#31574;&#12290;&#25968;&#25454;&#39537;&#21160;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#24050;&#25104;&#20026;&#24314;&#27169;&#39640;&#24230;&#38750;&#32447;&#24615;&#20851;&#31995;&#30340;&#24378;&#22823;&#24037;&#20855;&#65292;&#21487;&#33021;&#20026;&#21051;&#30011;&#27668;&#20505;&#21464;&#37327;&#20851;&#31995;&#25552;&#20379;&#19968;&#31181;&#36884;&#24452;&#12290;&#26412;&#25991;&#25506;&#32034;&#20102;&#20351;&#29992;&#22238;&#22768;&#29366;&#24577;&#32593;&#32476;&#65288;ESN&#65289;&#23545;&#27668;&#20505;&#36335;&#24452;&#36827;&#34892;&#21051;&#30011;&#30340;&#26041;&#27861;&#12290;ESN&#26159;&#19968;&#31181;&#35745;&#31639;&#39640;&#25928;&#30340;&#31070;&#32463;&#32593;&#32476;&#21464;&#20307;&#65292;&#19987;&#20026;&#22788;&#29702;&#26102;&#38388;&#25968;&#25454;&#32780;&#35774;&#35745;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#25552;&#20986;ESN&#21487;&#20197;&#29992;&#20316;&#39044;&#27979;&#26102;&#31354;&#27668;&#20505;&#25968;&#25454;&#30340;&#26377;&#29992;&#24037;&#20855;&#12290;&#19982;&#20854;&#20182;&#27169;&#22411;&#65288;&#22914;LSTM&#65289;&#30456;&#27604;&#65292;ESN&#20855;&#26377;&#26356;&#24555;&#30340;&#35757;&#32451;&#36895;&#24230;&#65292;&#26356;&#23569;&#30340;&#21442;&#25968;&#21644;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#20351;&#29992;&#29305;&#24449;&#37325;&#35201;&#24615;&#20998;&#26512;&#65292;&#20197;&#20102;&#35299;&#21508;&#20010;&#21464;&#37327;&#23545;&#27668;&#20505;&#36335;&#24452;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
The 2022 National Defense Strategy of the United States listed climate change as a serious threat to national security. Climate intervention methods, such as stratospheric aerosol injection, have been proposed as mitigation strategies, but the downstream effects of such actions on a complex climate system are not well understood. The development of algorithmic techniques for quantifying relationships between source and impact variables related to a climate event (i.e., a climate pathway) would help inform policy decisions. Data-driven deep learning models have become powerful tools for modeling highly nonlinear relationships and may provide a route to characterize climate variable relationships. In this paper, we explore the use of an echo state network (ESN) for characterizing climate pathways. ESNs are a computationally efficient neural network variation designed for temporal data, and recent work proposes ESNs as a useful tool for forecasting spatio-temporal climate data. Like other
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20010;&#24615;&#21270;&#21160;&#24577;&#36229;&#32423;&#23398;&#20064;&#31639;&#27861; (POSL)&#65292;&#21487;&#20197;&#23454;&#29616;&#23454;&#26102;&#26356;&#26032;&#30340;&#39044;&#27979;&#12290;&#20316;&#32773;&#36890;&#36807;&#39044;&#27979;&#34880;&#28082;&#36879;&#26512;&#24739;&#32773;&#30340;&#23545;&#27969;&#23481;&#31215;&#65292;&#23637;&#31034;&#20102;POSL&#22312;&#20013;&#20301;&#32477;&#23545;&#35823;&#24046;&#12289;&#22823;&#22411;&#26657;&#20934;&#12289;&#21306;&#20998;&#24230;&#21644;&#20928;&#25910;&#30410;&#26041;&#38754;&#30340;&#20248;&#36234;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2310.08479</link><description>&lt;p&gt;
&#20010;&#24615;&#21270;&#21160;&#24577;&#36229;&#32423;&#23398;&#20064;&#65306;&#22312;&#39044;&#27979;&#34880;&#28082;&#36879;&#26512;&#30340;&#23545;&#27969;&#23481;&#31215;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Personalised dynamic super learning: an application in predicting hemodiafiltration's convection volumes. (arXiv:2310.08479v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08479
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20010;&#24615;&#21270;&#21160;&#24577;&#36229;&#32423;&#23398;&#20064;&#31639;&#27861; (POSL)&#65292;&#21487;&#20197;&#23454;&#29616;&#23454;&#26102;&#26356;&#26032;&#30340;&#39044;&#27979;&#12290;&#20316;&#32773;&#36890;&#36807;&#39044;&#27979;&#34880;&#28082;&#36879;&#26512;&#24739;&#32773;&#30340;&#23545;&#27969;&#23481;&#31215;&#65292;&#23637;&#31034;&#20102;POSL&#22312;&#20013;&#20301;&#32477;&#23545;&#35823;&#24046;&#12289;&#22823;&#22411;&#26657;&#20934;&#12289;&#21306;&#20998;&#24230;&#21644;&#20928;&#25910;&#30410;&#26041;&#38754;&#30340;&#20248;&#36234;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#26102;&#26356;&#26032;&#30340;&#39044;&#27979;&#26159;&#20010;&#24615;&#21270;&#21307;&#30103;&#30340;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#12290;&#36890;&#36807;&#32467;&#21512;&#21442;&#25968;&#22238;&#24402;&#21644;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#20010;&#24615;&#21270;&#22312;&#32447;&#36229;&#32423;&#23398;&#20064;&#31639;&#27861;&#65288;POSL&#65289;&#21487;&#20197;&#23454;&#29616;&#21160;&#24577;&#21644;&#20010;&#24615;&#21270;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#23558;POSL&#24212;&#29992;&#20110;&#21160;&#24577;&#39044;&#27979;&#37325;&#22797;&#36830;&#32493;&#32467;&#26524;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39564;&#35777;&#20010;&#24615;&#21270;&#25110;&#21160;&#24577;&#39044;&#27979;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#39044;&#27979;&#36827;&#34892;&#34880;&#28082;&#36879;&#26512;&#30340;&#24739;&#32773;&#30340;&#23545;&#27969;&#23481;&#31215;&#26469;&#23637;&#31034;&#20854;&#24615;&#33021;&#12290;POSL&#22312;&#20013;&#20301;&#32477;&#23545;&#35823;&#24046;&#12289;&#22823;&#22411;&#26657;&#20934;&#12289;&#21306;&#20998;&#24230;&#21644;&#20928;&#25910;&#30410;&#26041;&#38754;&#30340;&#34920;&#29616;&#20248;&#20110;&#20854;&#20505;&#36873;&#23398;&#20064;&#22120;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#20351;&#29992;POSL&#30340;&#36873;&#25321;&#21644;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Obtaining continuously updated predictions is a major challenge for personalised medicine. Leveraging combinations of parametric regressions and machine learning approaches, the personalised online super learner (POSL) can achieve such dynamic and personalised predictions. We adapt POSL to predict a repeated continuous outcome dynamically and propose a new way to validate such personalised or dynamic prediction models. We illustrate its performance by predicting the convection volume of patients undergoing hemodiafiltration. POSL outperformed its candidate learners with respect to median absolute error, calibration-in-the-large, discrimination, and net benefit. We finally discuss the choices and challenges underlying the use of POSL.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25551;&#36848;&#20102;Heterogeneity in Integration and Prediction (HIP)&#30340;&#25193;&#23637;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;R Shiny&#24212;&#29992;&#30028;&#38754;&#65292;&#33021;&#22815;&#36866;&#24212;&#22810;&#31181;&#32467;&#26524;&#31867;&#22411;&#65292;&#21516;&#26102;&#20445;&#30041;&#20102;HIP&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2310.08426</link><description>&lt;p&gt;
Heterogeneity in Integration and Prediction (HIP)&#30340;&#25193;&#23637;&#19982;R Shiny&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Extensions of Heterogeneity in Integration and Prediction (HIP) with R Shiny Application. (arXiv:2310.08426v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08426
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25551;&#36848;&#20102;Heterogeneity in Integration and Prediction (HIP)&#30340;&#25193;&#23637;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;R Shiny&#24212;&#29992;&#30028;&#38754;&#65292;&#33021;&#22815;&#36866;&#24212;&#22810;&#31181;&#32467;&#26524;&#31867;&#22411;&#65292;&#21516;&#26102;&#20445;&#30041;&#20102;HIP&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20010;&#25968;&#25454;&#35270;&#22270;&#22312;&#21516;&#19968;&#32452;&#21442;&#19982;&#32773;&#19978;&#30340;&#27979;&#37327;&#36234;&#26469;&#36234;&#24120;&#35265;&#65292;&#24182;&#19988;&#36890;&#36807;&#21516;&#26102;&#20998;&#26512;&#36825;&#20123;&#19981;&#21516;&#35270;&#22270;&#65292;&#26377;&#21487;&#33021;&#21152;&#28145;&#25105;&#20204;&#23545;&#35768;&#22810;&#22797;&#26434;&#30142;&#30149;&#30340;&#29702;&#35299;&#12290;&#21516;&#26679;&#37325;&#35201;&#30340;&#26159;&#65292;&#35768;&#22810;&#22797;&#26434;&#30142;&#30149;&#26174;&#31034;&#20986;&#20122;&#32452;&#24322;&#36136;&#24615;&#65288;&#20363;&#22914;&#24615;&#21035;&#25110;&#31181;&#26063;&#65289;&#12290;HIP&#65288;Heterogeneity in Integration and Prediction&#65289;&#26159;&#26368;&#26089;&#25552;&#20986;&#30340;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#38598;&#25104;&#22810;&#20010;&#25968;&#25454;&#35270;&#22270;&#65292;&#21516;&#26102;&#32771;&#34385;&#20122;&#32452;&#24322;&#36136;&#24615;&#65292;&#20197;&#30830;&#23450;&#29305;&#23450;&#30142;&#30149;&#30340;&#20849;&#26377;&#21644;&#20122;&#32452;&#29305;&#24322;&#24615;&#26631;&#35760;&#29289;&#12290;&#28982;&#32780;&#65292;HIP&#36866;&#29992;&#20110;&#36830;&#32493;&#32467;&#26524;&#65292;&#24182;&#19988;&#38656;&#35201;&#29992;&#25143;&#20855;&#22791;&#32534;&#31243;&#19987;&#38271;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;HIP&#30340;&#25193;&#23637;&#65292;&#20197;&#36866;&#24212;&#22810;&#31867;&#21035;&#12289;&#27850;&#26494;&#20998;&#24067;&#21644;&#38646;&#33192;&#32960;&#27850;&#26494;&#20998;&#24067;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#20445;&#30041;HIP&#30340;&#20248;&#21183;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#20171;&#32461;&#20102;&#19968;&#20010;R Shiny&#24212;&#29992;&#65292;&#21487;&#20197;&#36890;&#36807;https://multi-viewlearn.shinyapps.io/HIP_ShinyApp/&#35775;&#38382;&#65292;&#23427;&#25552;&#20379;&#20102;&#19982;Python&#23454;&#29616;&#30340;&#25509;&#21475;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multiple data views measured on the same set of participants is becoming more common and has the potential to deepen our understanding of many complex diseases by analyzing these different views simultaneously. Equally important, many of these complex diseases show evidence of subgroup heterogeneity (e.g., by sex or race). HIP (Heterogeneity in Integration and Prediction) is among the first methods proposed to integrate multiple data views while also accounting for subgroup heterogeneity to identify common and subgroup-specific markers of a particular disease. However, HIP is applicable to continuous outcomes and requires programming expertise by the user. Here we propose extensions to HIP that accommodate multi-class, Poisson, and Zero-Inflated Poisson outcomes while retaining the benefits of HIP. Additionally, we introduce an R Shiny application, accessible on shinyapps.io at https://multi-viewlearn.shinyapps.io/HIP_ShinyApp/, that provides an interface with the Python implementation
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#30340;&#38750;&#20984;&#23398;&#20064;&#38382;&#39064;&#22312;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#25552;&#20986;&#26032;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#25968;&#25454;&#32500;&#24230;&#19981;&#21464;&#30340;&#24773;&#20917;&#19979;&#36798;&#21040;&#36807;&#24230;&#32676;&#20307;&#39118;&#38505;&#12290;&#21516;&#26102;&#65292;&#23545;&#27604;&#20102;&#19981;&#21516;&#38142;&#25509;&#20989;&#25968;&#21644;&#19981;&#21516;&#27169;&#22411;&#35774;&#23450;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.08425</link><description>&lt;p&gt;
&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#24046;&#20998;&#38544;&#31169;&#38750;&#20984;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Non-convex Learning for Multi-layer Neural Networks. (arXiv:2310.08425v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08425
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#30340;&#38750;&#20984;&#23398;&#20064;&#38382;&#39064;&#22312;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#25552;&#20986;&#26032;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#25968;&#25454;&#32500;&#24230;&#19981;&#21464;&#30340;&#24773;&#20917;&#19979;&#36798;&#21040;&#36807;&#24230;&#32676;&#20307;&#39118;&#38505;&#12290;&#21516;&#26102;&#65292;&#23545;&#27604;&#20102;&#19981;&#21516;&#38142;&#25509;&#20989;&#25968;&#21644;&#19981;&#21516;&#27169;&#22411;&#35774;&#23450;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#20855;&#26377;&#21333;&#36755;&#20986;&#33410;&#28857;&#30340;&#65288;&#22810;&#23618;&#65289;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#12290;&#39318;&#20808;, &#25105;&#20204;&#30740;&#31350;&#20102;&#27809;&#26377;&#38544;&#34255;&#33410;&#28857;&#30340;&#24773;&#20917;&#65292;&#20855;&#20307;&#20851;&#27880;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;GLMs&#65289;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#38543;&#26426;&#22122;&#22768;&#20855;&#26377;&#38646;&#22343;&#20540;&#19988;&#38142;&#25509;&#20989;&#25968;&#26082;&#26377;&#30028;&#21448;Lipschitz&#36830;&#32493;&#30340;&#29305;&#23450;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#31181;&#31639;&#27861;&#65292;&#24182;&#20998;&#26512;&#35777;&#26126;&#20102;&#22312;&#25968;&#25454;&#32500;&#24230;&#19981;&#21464;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#36807;&#24230;&#32676;&#20307;&#39118;&#38505;&#30340;&#21487;&#34892;&#24615;&#12290;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#28041;&#21450;ReLU&#38142;&#25509;&#20989;&#25968;&#30340;&#22330;&#26223;&#65292;&#21457;&#29616;&#19982;&#26377;&#30028;&#38142;&#25509;&#20989;&#25968;&#30340;&#32467;&#26524;&#30456;&#20284;&#12290;&#36890;&#36807;&#20351;&#29992;ReLU&#22238;&#24402;&#20316;&#20026;&#20195;&#34920;&#24615;&#31034;&#20363;, &#23545;&#27604;&#20102;&#29305;&#23450;&#21644;&#19981;&#27491;&#30830;&#25351;&#23450;&#30340;&#27169;&#22411;&#12290;&#22312;&#35770;&#25991;&#30340;&#31532;&#20108;&#37096;&#20998;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#29702;&#24565;&#25193;&#23637;&#21040;&#20855;&#26377;Sigmoid&#25110;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#29305;&#23450;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper focuses on the problem of Differentially Private Stochastic Optimization for (multi-layer) fully connected neural networks with a single output node. In the first part, we examine cases with no hidden nodes, specifically focusing on Generalized Linear Models (GLMs). We investigate the well-specific model where the random noise possesses a zero mean, and the link function is both bounded and Lipschitz continuous. We propose several algorithms and our analysis demonstrates the feasibility of achieving an excess population risk that remains invariant to the data dimension. We also delve into the scenario involving the ReLU link function, and our findings mirror those of the bounded link function. We conclude this section by contrasting well-specified and misspecified models, using ReLU regression as a representative example.  In the second part of the paper, we extend our ideas to two-layer neural networks with sigmoid or ReLU activation functions in the well-specified model. I
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#24635;&#32467;&#20102;&#20851;&#20110;&#35780;&#20272;ChatGPT&#22312;&#21307;&#23398;&#20013;&#24615;&#33021;&#30340;&#29616;&#26377;&#35777;&#25454;&#65292;&#24182;&#21457;&#29616;ChatGPT&#22312;&#22788;&#29702;&#21307;&#23398;&#26597;&#35810;&#26102;&#30340;&#20934;&#30830;&#29575;&#20026;56%&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#32570;&#20047;&#35780;&#20272;&#26631;&#20934;&#65292;&#30740;&#31350;&#20013;&#23384;&#22312;&#26041;&#27861;&#19978;&#30340;&#19981;&#19968;&#33268;&#21644;&#35814;&#32454;&#20449;&#24687;&#19981;&#20840;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.08410</link><description>&lt;p&gt;
ChatGPT&#29983;&#25104;&#30340;&#21307;&#23398;&#22238;&#22797;&#30340;&#35780;&#20272;&#65306;&#19968;&#39033;&#31995;&#32479;&#35780;&#36848;&#21644;&#33631;&#33795;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Evaluation of ChatGPT-Generated Medical Responses: A Systematic Review and Meta-Analysis. (arXiv:2310.08410v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08410
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#24635;&#32467;&#20102;&#20851;&#20110;&#35780;&#20272;ChatGPT&#22312;&#21307;&#23398;&#20013;&#24615;&#33021;&#30340;&#29616;&#26377;&#35777;&#25454;&#65292;&#24182;&#21457;&#29616;ChatGPT&#22312;&#22788;&#29702;&#21307;&#23398;&#26597;&#35810;&#26102;&#30340;&#20934;&#30830;&#29575;&#20026;56%&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#32570;&#20047;&#35780;&#20272;&#26631;&#20934;&#65292;&#30740;&#31350;&#20013;&#23384;&#22312;&#26041;&#27861;&#19978;&#30340;&#19981;&#19968;&#33268;&#21644;&#35814;&#32454;&#20449;&#24687;&#19981;&#20840;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36234;&#26469;&#36234;&#22810;&#22320;&#22312;&#21307;&#23398;&#39046;&#22495;&#25506;&#32034;&#20351;&#29992;ChatGPT&#31561;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#32570;&#20047;&#24615;&#33021;&#35780;&#20272;&#30340;&#26631;&#20934;&#25351;&#21335;&#23548;&#33268;&#20102;&#26041;&#27861;&#19978;&#30340;&#19981;&#19968;&#33268;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#24635;&#32467;&#20851;&#20110;&#35780;&#20272;ChatGPT&#22312;&#21307;&#23398;&#20013;&#24615;&#33021;&#30340;&#29616;&#26377;&#35777;&#25454;&#65292;&#24182;&#20026;&#26410;&#26469;&#30340;&#30740;&#31350;&#25351;&#26126;&#26041;&#21521;&#12290;&#25105;&#20204;&#22312;2023&#24180;6&#26376;15&#26085;&#20351;&#29992;&#20851;&#38190;&#35789;&#8220;ChatGPT&#8221;&#22312;&#21313;&#20010;&#21307;&#23398;&#25991;&#29486;&#25968;&#25454;&#24211;&#20013;&#36827;&#34892;&#25628;&#32034;&#12290;&#20849;&#37492;&#23450;&#20102;3520&#31687;&#25991;&#31456;&#65292;&#20854;&#20013;60&#31687;&#22312;&#26412;&#25991;&#20013;&#36827;&#34892;&#20102;&#22238;&#39038;&#21644;&#24635;&#32467;&#65292;17&#31687;&#36827;&#34892;&#20102;&#33631;&#33795;&#20998;&#26512;&#12290;&#20998;&#26512;&#32467;&#26524;&#26174;&#31034;&#65292;ChatGPT&#22312;&#22788;&#29702;&#21307;&#23398;&#26597;&#35810;&#26102;&#30340;&#25972;&#20307;&#32508;&#21512;&#20934;&#30830;&#29575;&#20026;56%&#65288;95% CI&#65306;51%-60%&#65292;I2 = 87%&#65289;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30740;&#31350;&#22312;&#38382;&#39064;&#36164;&#28304;&#12289;&#25552;&#38382;&#36807;&#31243;&#21644;&#35780;&#20272;&#25351;&#26631;&#19978;&#23384;&#22312;&#24046;&#24322;&#12290;&#27492;&#22806;&#65292;&#35768;&#22810;&#30740;&#31350;&#26410;&#33021;&#25253;&#21578;&#26041;&#27861;&#32454;&#33410;&#65292;&#21253;&#25324;ChatGPT&#30340;&#29256;&#26412;&#20197;&#21450;&#27599;&#20010;&#38382;&#39064;&#26159;&#29420;&#31435;&#20351;&#29992;&#36824;&#26159;&#37325;&#22797;&#20351;&#29992;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;...
&lt;/p&gt;
&lt;p&gt;
Large language models such as ChatGPT are increasingly explored in medical domains. However, the absence of standard guidelines for performance evaluation has led to methodological inconsistencies. This study aims to summarize the available evidence on evaluating ChatGPT's performance in medicine and provide direction for future research. We searched ten medical literature databases on June 15, 2023, using the keyword "ChatGPT". A total of 3520 articles were identified, of which 60 were reviewed and summarized in this paper and 17 were included in the meta-analysis. The analysis showed that ChatGPT displayed an overall integrated accuracy of 56% (95% CI: 51%-60%, I2 = 87%) in addressing medical queries. However, the studies varied in question resource, question-asking process, and evaluation metrics. Moreover, many studies failed to report methodological details, including the version of ChatGPT and whether each question was used independently or repeatedly. Our findings revealed that 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#65292;&#24182;&#21457;&#29616;&#26377;&#25928;&#30340;&#39044;&#35757;&#32451;&#21482;&#38656;&#35201;&#23569;&#37327;&#29420;&#31435;&#20219;&#21153;&#65292;&#39044;&#35757;&#32451;&#27169;&#22411;&#19982;&#36125;&#21494;&#26031;&#26368;&#20248;&#31639;&#27861;&#25509;&#36817;&#12290;&#36825;&#20123;&#29702;&#35770;&#21457;&#29616;&#23545;ICL&#30340;&#32479;&#35745;&#22522;&#30784;&#25552;&#20379;&#20102;&#21551;&#31034;&#12290;</title><link>http://arxiv.org/abs/2310.08391</link><description>&lt;p&gt;
&#22810;&#23569;&#20010;&#39044;&#35757;&#32451;&#20219;&#21153;&#38656;&#35201;&#29992;&#20110;&#32447;&#24615;&#22238;&#24402;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#65311;
&lt;/p&gt;
&lt;p&gt;
How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?. (arXiv:2310.08391v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08391
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#65292;&#24182;&#21457;&#29616;&#26377;&#25928;&#30340;&#39044;&#35757;&#32451;&#21482;&#38656;&#35201;&#23569;&#37327;&#29420;&#31435;&#20219;&#21153;&#65292;&#39044;&#35757;&#32451;&#27169;&#22411;&#19982;&#36125;&#21494;&#26031;&#26368;&#20248;&#31639;&#27861;&#25509;&#36817;&#12290;&#36825;&#20123;&#29702;&#35770;&#21457;&#29616;&#23545;ICL&#30340;&#32479;&#35745;&#22522;&#30784;&#25552;&#20379;&#20102;&#21551;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#26679;&#20219;&#21153;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#30340;Transformer&#23637;&#29616;&#20102;&#38750;&#20961;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#65288;ICL&#65289;&#33021;&#21147;&#65292;&#20351;&#20854;&#33021;&#22815;&#20165;&#22522;&#20110;&#36755;&#20837;&#19978;&#19979;&#25991;&#35299;&#20915;&#26410;&#35265;&#20219;&#21153;&#65292;&#32780;&#26080;&#38656;&#35843;&#25972;&#27169;&#22411;&#21442;&#25968;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20854;&#20013;&#26368;&#31616;&#21333;&#35774;&#32622;&#30340;ICL&#65306;&#39044;&#35757;&#32451;&#32447;&#24615;&#21442;&#25968;&#21270;&#30340;&#21333;&#23618;&#32447;&#24615;&#27880;&#24847;&#21147;&#27169;&#22411;&#65292;&#29992;&#20110;&#20855;&#26377;&#39640;&#26031;&#20808;&#39564;&#30340;&#32447;&#24615;&#22238;&#24402;&#12290;&#25105;&#20204;&#20026;&#27880;&#24847;&#21147;&#27169;&#22411;&#39044;&#35757;&#32451;&#24314;&#31435;&#20102;&#19968;&#20010;&#32479;&#35745;&#20219;&#21153;&#22797;&#26434;&#24230;&#30028;&#65292;&#34920;&#26126;&#26377;&#25928;&#30340;&#39044;&#35757;&#32451;&#21482;&#38656;&#35201;&#23569;&#37327;&#29420;&#31435;&#20219;&#21153;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#39044;&#35757;&#32451;&#27169;&#22411;&#19982;&#36125;&#21494;&#26031;&#26368;&#20248;&#31639;&#27861;&#38750;&#24120;&#25509;&#36817;&#65292;&#21363;&#20960;&#20046;&#23454;&#29616;&#20102;&#22266;&#23450;&#19978;&#19979;&#25991;&#38271;&#24230;&#19979;&#26410;&#35265;&#20219;&#21153;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#39118;&#38505;&#12290;&#36825;&#20123;&#29702;&#35770;&#21457;&#29616;&#23545;&#20043;&#21069;&#30340;&#23454;&#39564;&#30740;&#31350;&#36827;&#34892;&#20102;&#34917;&#20805;&#65292;&#24182;&#20026;ICL&#30340;&#32479;&#35745;&#22522;&#30784;&#25552;&#20379;&#20102;&#21551;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformers pretrained on diverse tasks exhibit remarkable in-context learning (ICL) capabilities, enabling them to solve unseen tasks solely based on input contexts without adjusting model parameters. In this paper, we study ICL in one of its simplest setups: pretraining a linearly parameterized single-layer linear attention model for linear regression with a Gaussian prior. We establish a statistical task complexity bound for the attention model pretraining, showing that effective pretraining only requires a small number of independent tasks. Furthermore, we prove that the pretrained model closely matches the Bayes optimal algorithm, i.e., optimally tuned ridge regression, by achieving nearly Bayes optimal risk on unseen tasks under a fixed context length. These theoretical findings complement prior experimental research and shed light on the statistical foundations of ICL.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;&#33258;&#21160;&#39550;&#39542;&#22330;&#26223;&#20013;&#20351;&#29992;&#37096;&#20998;&#21487;&#35266;&#27979;&#31995;&#32479;&#65292;&#36890;&#36807;&#37096;&#32626;&#21644;&#27979;&#35797;&#22810;&#31181;&#25216;&#26415;&#26469;&#24179;&#34913;&#25506;&#32034;&#21644;&#21033;&#29992;&#30340;&#26435;&#34913;&#65292;&#20197;&#39044;&#27979;&#26041;&#21521;&#30424;&#25805;&#20316;&#12290;</title><link>http://arxiv.org/abs/2310.08331</link><description>&lt;p&gt;
&#22810;&#33218;&#36172;&#21338;&#31574;&#30053;&#23545;&#28145;&#24230;&#24490;&#29615;&#24378;&#21270;&#23398;&#20064;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Impact of multi-armed bandit strategies on deep recurrent reinforcement learning. (arXiv:2310.08331v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08331
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#33258;&#21160;&#39550;&#39542;&#22330;&#26223;&#20013;&#20351;&#29992;&#37096;&#20998;&#21487;&#35266;&#27979;&#31995;&#32479;&#65292;&#36890;&#36807;&#37096;&#32626;&#21644;&#27979;&#35797;&#22810;&#31181;&#25216;&#26415;&#26469;&#24179;&#34913;&#25506;&#32034;&#21644;&#21033;&#29992;&#30340;&#26435;&#34913;&#65292;&#20197;&#39044;&#27979;&#26041;&#21521;&#30424;&#25805;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#29615;&#22659;&#30340;&#19981;&#23436;&#20840;&#20102;&#35299;&#23548;&#33268;&#26234;&#33021;&#20307;&#22312;&#19981;&#30830;&#23450;&#24615;&#19979;&#20570;&#20986;&#20915;&#31574;&#12290;&#24378;&#21270;&#23398;&#20064;&#20013;&#19968;&#20010;&#37325;&#35201;&#30340;&#22256;&#22659;&#26159;&#65292;&#22312;&#20570;&#20986;&#20915;&#31574;&#26102;&#65292;&#26234;&#33021;&#20307;&#38656;&#35201;&#22312;&#21033;&#29992;&#24403;&#21069;&#29615;&#22659;&#30693;&#35782;&#26368;&#22823;&#21270;&#32047;&#31215;&#22870;&#21169;&#21644;&#25506;&#32034;&#34892;&#21160;&#20197;&#25552;&#39640;&#29615;&#22659;&#30693;&#35782;&#30340;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#65288;&#25506;&#32034;-&#21033;&#29992;&#30340;&#24179;&#34913;&#65289;&#12290;&#21516;&#26102;&#65292;&#21478;&#19968;&#20010;&#30456;&#20851;&#38382;&#39064;&#26159;&#29366;&#24577;&#30340;&#23436;&#20840;&#21487;&#35266;&#27979;&#24615;&#65292;&#19981;&#26159;&#25152;&#26377;&#24212;&#29992;&#37117;&#33021;&#20551;&#23450;&#12290;&#20363;&#22914;&#65292;&#24403;&#21482;&#23558;2D&#22270;&#20687;&#20316;&#20026;&#36755;&#20837;&#29992;&#20110;&#22312;3D&#27169;&#25311;&#29615;&#22659;&#20013;&#25214;&#21040;&#26368;&#20339;&#34892;&#21160;&#26102;&#65292;&#23601;&#23384;&#22312;&#36825;&#20010;&#38382;&#39064;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#37096;&#32626;&#21644;&#27979;&#35797;&#22810;&#31181;&#25216;&#26415;&#26469;&#35299;&#20915;&#37096;&#20998;&#21487;&#35266;&#27979;&#31995;&#32479;&#20013;&#25506;&#32034;&#21644;&#21033;&#29992;&#30340;&#24179;&#34913;&#38382;&#39064;&#65292;&#20197;&#39044;&#27979;&#33258;&#21160;&#39550;&#39542;&#22330;&#26223;&#20013;&#30340;&#26041;&#21521;&#30424;&#25805;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
Incomplete knowledge of the environment leads an agent to make decisions under uncertainty. One of the major dilemmas in Reinforcement Learning (RL) where an autonomous agent has to balance two contrasting needs in making its decisions is: exploiting the current knowledge of the environment to maximize the cumulative reward as well as exploring actions that allow improving the knowledge of the environment, hopefully leading to higher reward values (exploration-exploitation trade-off). Concurrently, another relevant issue regards the full observability of the states, which may not be assumed in all applications. Such as when only 2D images are considered as input in a RL approach used for finding the optimal action within a 3D simulation environment. In this work, we address these issues by deploying and testing several techniques to balance exploration and exploitation trade-off on partially observable systems for predicting steering wheels in autonomous driving scenario. More precisel
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#36827;&#34892;&#20102;&#22823;&#35268;&#27169;&#25506;&#32034;&#65292;&#30740;&#31350;&#20102;&#36924;&#36817;&#21518;&#39564;&#30340;&#26368;&#20339;&#26041;&#27861;&#21644;&#21518;&#39564;&#36136;&#37327;&#19982;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#20851;&#31995;&#65292;&#21516;&#26102;&#21457;&#29616;&#20102;&#26435;&#37325;&#31354;&#38388;&#23545;&#31216;&#24615;&#23545;&#21518;&#39564;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.08287</link><description>&lt;p&gt;
&#23545;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#30340;&#23545;&#31216;&#24863;&#30693;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
A Symmetry-Aware Exploration of Bayesian Neural Network Posteriors. (arXiv:2310.08287v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08287
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#36827;&#34892;&#20102;&#22823;&#35268;&#27169;&#25506;&#32034;&#65292;&#30740;&#31350;&#20102;&#36924;&#36817;&#21518;&#39564;&#30340;&#26368;&#20339;&#26041;&#27861;&#21644;&#21518;&#39564;&#36136;&#37327;&#19982;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#20851;&#31995;&#65292;&#21516;&#26102;&#21457;&#29616;&#20102;&#26435;&#37325;&#31354;&#38388;&#23545;&#31216;&#24615;&#23545;&#21518;&#39564;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#30340;&#26435;&#37325;&#20998;&#24067;&#23545;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#40065;&#26834;&#24615;&#38750;&#24120;&#37325;&#35201;&#65292;&#30001;&#20110;&#20854;&#26497;&#39640;&#30340;&#32500;&#24230;&#65292;&#20854;&#26412;&#36136;&#38750;&#24120;&#22797;&#26434;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#28145;&#24230;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;(BNNs)&#21518;&#39564;&#20998;&#24067;&#30340;&#39318;&#27425;&#22823;&#35268;&#27169;&#25506;&#32034;&#65292;&#23558;&#20854;&#30740;&#31350;&#25193;&#23637;&#21040;&#29616;&#23454;&#19990;&#30028;&#30340;&#35270;&#35273;&#20219;&#21153;&#21644;&#26550;&#26500;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#36924;&#36817;&#21518;&#39564;&#30340;&#26368;&#20339;&#26041;&#27861;&#65292;&#20998;&#26512;&#20102;&#21518;&#39564;&#36136;&#37327;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#28145;&#20837;&#30740;&#31350;&#20102;&#21518;&#39564;&#20013;&#27169;&#24335;&#30340;&#24433;&#21709;&#65292;&#24182;&#25506;&#32034;&#20102;&#21487;&#35270;&#21270;&#21518;&#39564;&#30340;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#26435;&#37325;&#31354;&#38388;&#30340;&#23545;&#31216;&#24615;&#26159;&#29702;&#35299;&#21518;&#39564;&#30340;&#20851;&#38190;&#26041;&#38754;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#23545;&#32622;&#25442;&#21644;&#32553;&#25918;&#23545;&#31216;&#24615;&#30340;&#24433;&#21709;&#36827;&#34892;&#20102;&#28145;&#20837;&#35780;&#20272;&#65292;&#36825;&#20123;&#23545;&#31216;&#24615;&#24448;&#24448;&#20250;&#20351;&#36125;&#21494;&#26031;&#21518;&#39564;&#21464;&#24471;&#27169;&#31946;&#12290;&#23613;&#31649;&#31532;&#19968;&#31181;&#21464;&#25442;&#24050;&#30693;&#20250;&#22797;&#21046;&#27169;&#24335;&#65292;&#20294;&#25105;&#20204;&#36824;&#26159;&#23545;&#20854;&#36827;&#34892;&#20102;&#25506;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;
The distribution of the weights of modern deep neural networks (DNNs) crucial for uncertainty quantification and robustness - is an eminently complex object due to its extremely high dimensionality. This paper proposes one of the first large-scale explorations of the posterior distribution of deep Bayesian Neural Networks (BNNs), expanding its study to real-world vision tasks and architectures. Specifically, we investigate the optimal approach for approximating the posterior, analyze the connection between posterior quality and uncertainty quantification, delve into the impact of modes on the posterior, and explore methods for visualizing the posterior. Moreover, we uncover weight-space symmetries as a critical aspect for understanding the posterior. To this extent, we develop an in-depth assessment of the impact of both permutation and scaling symmetries that tend to obfuscate the Bayesian posterior. While the first type of transformation is known for duplicating modes, we explore t
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#21327;&#21464;&#37327;&#28418;&#31227;&#19979;&#23545;&#19968;&#33324;&#38750;&#21442;&#25968;&#26041;&#27861;&#36827;&#34892;&#32479;&#19968;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24314;&#31435;&#25910;&#25947;&#36895;&#24230;&#20026;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2310.08237</link><description>&lt;p&gt;
&#22312;&#21327;&#21464;&#37327;&#28418;&#31227;&#19979;&#22522;&#20110;&#26680;&#26041;&#27861;&#30340;&#32479;&#19968;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Towards a Unified Analysis of Kernel-based Methods Under Covariate Shift. (arXiv:2310.08237v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08237
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#21327;&#21464;&#37327;&#28418;&#31227;&#19979;&#23545;&#19968;&#33324;&#38750;&#21442;&#25968;&#26041;&#27861;&#36827;&#34892;&#32479;&#19968;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24314;&#31435;&#25910;&#25947;&#36895;&#24230;&#20026;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#21327;&#21464;&#37327;&#28418;&#31227;&#26159;&#26222;&#36941;&#23384;&#22312;&#30340;&#65292;&#21363;&#28304;&#25968;&#25454;&#21644;&#30446;&#26631;&#25968;&#25454;&#30340;&#36755;&#20837;&#20998;&#24067;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#12290;&#23613;&#31649;&#22312;&#21508;&#31181;&#23398;&#20064;&#38382;&#39064;&#20013;&#20855;&#26377;&#23454;&#38469;&#37325;&#35201;&#24615;&#65292;&#20294;&#29616;&#26377;&#30340;&#22823;&#22810;&#25968;&#26041;&#27861;&#21482;&#20851;&#27880;&#20110;&#19968;&#20123;&#29305;&#23450;&#30340;&#23398;&#20064;&#20219;&#21153;&#65292;&#24182;&#27809;&#26377;&#22312;&#29702;&#35770;&#19978;&#21644;&#25968;&#20540;&#19978;&#24471;&#21040;&#24456;&#22909;&#30340;&#39564;&#35777;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#21327;&#21464;&#37327;&#28418;&#31227;&#19979;&#23545;&#19968;&#33324;&#38750;&#21442;&#25968;&#26041;&#27861;&#36827;&#34892;&#32479;&#19968;&#20998;&#26512;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#36866;&#29992;&#20110;&#23646;&#20110;&#19968;&#20010;&#20016;&#23500;&#30340;&#25439;&#22833;&#20989;&#25968;&#23478;&#26063;&#30340;&#19968;&#33324;&#25439;&#22833;&#65292;&#20854;&#20013;&#21253;&#25324;&#35768;&#22810;&#24120;&#29992;&#30340;&#26041;&#27861;&#65292;&#22914;&#22343;&#20540;&#22238;&#24402;&#12289;&#20998;&#20301;&#25968;&#22238;&#24402;&#12289;&#22522;&#20110;&#20284;&#28982;&#30340;&#20998;&#31867;&#21644;&#22522;&#20110;&#36793;&#32536;&#30340;&#20998;&#31867;&#12290;&#26412;&#25991;&#37325;&#28857;&#30740;&#31350;&#20102;&#20004;&#31867;&#21327;&#21464;&#37327;&#28418;&#31227;&#38382;&#39064;&#65292;&#24182;&#20026;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#24314;&#31435;&#20102;&#23574;&#38160;&#30340;&#25910;&#25947;&#36895;&#24230;&#20197;&#25552;&#20379;&#19968;&#20010;&#32479;&#19968;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#35813;&#32467;&#26524;&#19982;&#25991;&#29486;&#20013;&#30340;&#26368;&#20248;&#32467;&#26524;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
Covariate shift occurs prevalently in practice, where the input distributions of the source and target data are substantially different. Despite its practical importance in various learning problems, most of the existing methods only focus on some specific learning tasks and are not well validated theoretically and numerically. To tackle this problem, we propose a unified analysis of general nonparametric methods in a reproducing kernel Hilbert space (RKHS) under covariate shift. Our theoretical results are established for a general loss belonging to a rich loss function family, which includes many commonly used methods as special cases, such as mean regression, quantile regression, likelihood-based classification, and margin-based classification. Two types of covariate shift problems are the focus of this paper and the sharp convergence rates are established for a general loss function to provide a unified theoretical analysis, which concurs with the optimal results in literature wher
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#36827;&#34892;&#22238;&#24402;&#22330;&#26223;&#30340;&#39044;&#27979;&#38598;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20123;&#21306;&#22495;&#30340;&#32463;&#39564;&#29256;&#26412;&#22312;&#22823;&#26679;&#26412;&#19979;&#30340;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.08209</link><description>&lt;p&gt;
&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#36827;&#34892;&#22238;&#24402;&#30340;&#19968;&#33268;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Conformal inference for regression on Riemannian Manifolds. (arXiv:2310.08209v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08209
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#36827;&#34892;&#22238;&#24402;&#22330;&#26223;&#30340;&#39044;&#27979;&#38598;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20123;&#21306;&#22495;&#30340;&#32463;&#39564;&#29256;&#26412;&#22312;&#22823;&#26679;&#26412;&#19979;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27969;&#24418;&#19978;&#36827;&#34892;&#22238;&#24402;&#65292;&#20197;&#21450;&#26356;&#24191;&#27867;&#22320;&#35828;&#65292;&#23545;&#27969;&#24418;&#19978;&#30340;&#32479;&#35745;&#23398;&#26377;&#20102;&#37325;&#35201;&#30340;&#20851;&#27880;&#65292;&#22240;&#20026;&#36825;&#31181;&#31867;&#22411;&#30340;&#25968;&#25454;&#26377;&#22823;&#37327;&#30340;&#24212;&#29992;&#12290;&#22278;&#24418;&#25968;&#25454;&#26159;&#19968;&#20010;&#32463;&#20856;&#31034;&#20363;&#65292;&#20294;&#21327;&#26041;&#24046;&#30697;&#38453;&#31354;&#38388;&#19978;&#30340;&#25968;&#25454;&#12289;&#20027;&#25104;&#20998;&#20998;&#26512;&#24471;&#21040;&#30340;Grassmann&#27969;&#24418;&#19978;&#30340;&#25968;&#25454;&#31561;&#20063;&#26159;&#22914;&#27492;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#24403;&#21709;&#24212;&#21464;&#37327;$Y$&#20301;&#20110;&#27969;&#24418;&#19978;&#65292;&#32780;&#21327;&#21464;&#37327;$X$&#20301;&#20110;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#26102;&#65292;&#22238;&#24402;&#22330;&#26223;&#30340;&#39044;&#27979;&#38598;&#12290;&#36825;&#25193;&#23637;&#20102;[Lei and Wasserman, 2014]&#20013;&#22312;&#36825;&#19968;&#26032;&#39046;&#22495;&#20013;&#27010;&#36848;&#30340;&#27010;&#24565;&#12290;&#19982;&#19968;&#33268;&#25512;&#26029;&#20013;&#30340;&#20256;&#32479;&#21407;&#21017;&#19968;&#33268;&#65292;&#36825;&#20123;&#39044;&#27979;&#38598;&#26159;&#26080;&#20998;&#24067;&#30340;&#65292;&#34920;&#26126;&#23545;$(X, Y)$&#30340;&#32852;&#21512;&#20998;&#24067;&#27809;&#26377;&#26045;&#21152;&#29305;&#23450;&#30340;&#20551;&#35774;&#65292;&#32780;&#19988;&#23427;&#20204;&#20445;&#25345;&#38750;&#21442;&#25968;&#24615;&#36136;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#21306;&#22495;&#30340;&#32463;&#39564;&#29256;&#26412;&#22312;&#20960;&#20046;&#24517;&#28982;&#25910;&#25947;&#20110;&#26080;&#31351;&#22823;&#26102;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Regression on manifolds, and, more broadly, statistics on manifolds, has garnered significant importance in recent years due to the vast number of applications for this type of data. Circular data is a classic example, but so is data in the space of covariance matrices, data on the Grassmannian manifold obtained as a result of principal component analysis, among many others. In this work we investigate prediction sets for regression scenarios when the response variable, denoted by $Y$, resides in a manifold, and the covariable, denoted by X, lies in Euclidean space. This extends the concepts delineated in [Lei and Wasserman, 2014] to this novel context. Aligning with traditional principles in conformal inference, these prediction sets are distribution-free, indicating that no specific assumptions are imposed on the joint distribution of $(X, Y)$, and they maintain a non-parametric character. We prove the asymptotic almost sure convergence of the empirical version of these regions on th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#21521;&#37327;&#26102;&#38388;&#24207;&#21015;&#26679;&#26412;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20989;&#25968;&#30340;&#26368;&#22823;&#22411;&#32479;&#35745;&#37327;&#65292;&#25512;&#24191;&#20102;&#26679;&#26412;&#33258;&#21327;&#26041;&#24046;&#20989;&#25968;&#30340;&#26368;&#22823;&#20559;&#24046;&#24773;&#20917;&#65292;&#35777;&#26126;&#20102;Gumbel&#22411;&#26497;&#20540;&#28176;&#36817;&#24615;&#25104;&#31435;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#37329;&#34701;&#21644;&#21367;&#31215;&#32593;&#32476;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2310.08150</link><description>&lt;p&gt;
&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#30740;&#31350;&#25237;&#24433;&#26679;&#26412;&#21327;&#26041;&#24046;&#30340;&#26497;&#20540;&#28176;&#36817;&#24615;&#65292;&#24182;&#22312;&#37329;&#34701;&#21644;&#21367;&#31215;&#32593;&#32476;&#20013;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
On Extreme Value Asymptotics of Projected Sample Covariances in High Dimensions with Applications in Finance and Convolutional Networks. (arXiv:2310.08150v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08150
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#21521;&#37327;&#26102;&#38388;&#24207;&#21015;&#26679;&#26412;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20989;&#25968;&#30340;&#26368;&#22823;&#22411;&#32479;&#35745;&#37327;&#65292;&#25512;&#24191;&#20102;&#26679;&#26412;&#33258;&#21327;&#26041;&#24046;&#20989;&#25968;&#30340;&#26368;&#22823;&#20559;&#24046;&#24773;&#20917;&#65292;&#35777;&#26126;&#20102;Gumbel&#22411;&#26497;&#20540;&#28176;&#36817;&#24615;&#25104;&#31435;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#37329;&#34701;&#21644;&#21367;&#31215;&#32593;&#32476;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#21521;&#37327;&#26102;&#38388;&#24207;&#21015;&#26679;&#26412;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#26576;&#20123;&#20989;&#25968;&#30340;&#26368;&#22823;&#22411;&#32479;&#35745;&#37327;&#65292;&#20197;&#32479;&#35745;&#22320;&#30830;&#35748;&#25110;&#25298;&#32477;&#25968;&#25454;&#38598;&#22312;&#27491;&#24120;&#26465;&#20214;&#19979;&#34987;&#25910;&#38598;&#30340;&#38646;&#20551;&#35774;&#12290;&#26412;&#26041;&#27861;&#25512;&#24191;&#20102;&#26679;&#26412;&#33258;&#21327;&#26041;&#24046;&#20989;&#25968;&#30340;&#26368;&#22823;&#20559;&#24046;&#24773;&#20917;&#12290;&#22312;&#32447;&#24615;&#26102;&#38388;&#24207;&#21015;&#26694;&#26550;&#19979;&#65292;&#35777;&#26126;&#20102;Gumbel&#22411;&#26497;&#20540;&#28176;&#36817;&#24615;&#25104;&#31435;&#12290;&#20316;&#20026;&#24212;&#29992;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#20165;&#20570;&#22810;&#30340;&#26368;&#23567;&#39118;&#38505;&#32452;&#21512;&#20248;&#21270;&#12289;&#30001;&#31232;&#30095;&#36319;&#36394;&#32452;&#21512;&#36827;&#34892;ETF&#25351;&#25968;&#36319;&#36394;&#12289;&#29992;&#20110;&#22270;&#20687;&#20998;&#26512;&#30340;&#21367;&#31215;&#28145;&#24230;&#23398;&#20064;&#21644;&#38453;&#21015;&#20256;&#24863;&#22120;&#25968;&#25454;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Maximum-type statistics of certain functions of the sample covariance matrix of high-dimensional vector time series are studied to statistically confirm or reject the null hypothesis that a data set has been collected under normal conditions. The approach generalizes the case of the maximal deviation of the sample autocovariances function from its assumed values. Within a linear time series framework it is shown that Gumbel-type extreme value asymptotics holds true. As applications we discuss long-only mimimal-variance portfolio optimization and subportfolio analysis with respect to idiosyncratic risks, ETF index tracking by sparse tracking portfolios, convolutional deep learners for image analysis and the analysis of array-of-sensors data.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#19981;&#21487;&#30693;&#30340;&#25512;&#26029;&#26041;&#27861;&#65292;&#22312;&#37096;&#20998;&#21487;&#36776;&#35782;&#30340;&#22240;&#26524;&#20272;&#35745;&#20013;&#24212;&#29992;&#24191;&#27867;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#30340;&#23545;&#20598;&#29702;&#35770;&#65292;&#33021;&#22815;&#36866;&#24212;&#38543;&#26426;&#23454;&#39564;&#21644;&#35266;&#27979;&#30740;&#31350;&#65292;&#24182;&#19988;&#20855;&#26377;&#32479;&#19968;&#26377;&#25928;&#21644;&#21452;&#37325;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.08115</link><description>&lt;p&gt;
&#27169;&#22411;&#19981;&#21487;&#30693;&#30340;&#36741;&#21161;&#25512;&#26029;&#26041;&#27861;&#22312;&#37096;&#20998;&#21487;&#36776;&#35782;&#22240;&#26524;&#25928;&#24212;&#19978;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Model-Agnostic Covariate-Assisted Inference on Partially Identified Causal Effects. (arXiv:2310.08115v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08115
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#19981;&#21487;&#30693;&#30340;&#25512;&#26029;&#26041;&#27861;&#65292;&#22312;&#37096;&#20998;&#21487;&#36776;&#35782;&#30340;&#22240;&#26524;&#20272;&#35745;&#20013;&#24212;&#29992;&#24191;&#27867;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#30340;&#23545;&#20598;&#29702;&#35770;&#65292;&#33021;&#22815;&#36866;&#24212;&#38543;&#26426;&#23454;&#39564;&#21644;&#35266;&#27979;&#30740;&#31350;&#65292;&#24182;&#19988;&#20855;&#26377;&#32479;&#19968;&#26377;&#25928;&#21644;&#21452;&#37325;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24456;&#22810;&#22240;&#26524;&#20272;&#35745;&#26159;&#37096;&#20998;&#21487;&#36776;&#35782;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#20381;&#36182;&#20110;&#28508;&#22312;&#32467;&#26524;&#20043;&#38388;&#30340;&#19981;&#21487;&#35266;&#23519;&#32852;&#21512;&#20998;&#24067;&#12290;&#22522;&#20110;&#21069;&#22788;&#29702;&#21327;&#21464;&#37327;&#30340;&#20998;&#23618;&#21487;&#20197;&#33719;&#24471;&#26356;&#26126;&#30830;&#30340;&#37096;&#20998;&#21487;&#36776;&#35782;&#24615;&#33539;&#22260;&#65307;&#28982;&#32780;&#65292;&#38500;&#38750;&#21327;&#21464;&#37327;&#20026;&#31163;&#25955;&#19988;&#25903;&#25745;&#24230;&#30456;&#23545;&#36739;&#23567;&#65292;&#21542;&#21017;&#36825;&#31181;&#26041;&#27861;&#36890;&#24120;&#38656;&#35201;&#23545;&#32473;&#23450;&#21327;&#21464;&#37327;&#30340;&#28508;&#22312;&#32467;&#26524;&#30340;&#26465;&#20214;&#20998;&#24067;&#36827;&#34892;&#19968;&#33268;&#20272;&#35745;&#12290;&#22240;&#27492;&#65292;&#29616;&#26377;&#30340;&#26041;&#27861;&#22312;&#27169;&#22411;&#38169;&#35823;&#25110;&#19968;&#33268;&#24615;&#20551;&#35774;&#34987;&#36829;&#21453;&#26102;&#21487;&#33021;&#22833;&#36133;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#30340;&#23545;&#20598;&#29702;&#35770;&#30340;&#32479;&#19968;&#19988;&#27169;&#22411;&#19981;&#21487;&#30693;&#30340;&#25512;&#26029;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#24191;&#27867;&#31867;&#21035;&#30340;&#37096;&#20998;&#21487;&#36776;&#35782;&#20272;&#35745;&#12290;&#22312;&#38543;&#26426;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#32467;&#21512;&#20219;&#20309;&#23545;&#26465;&#20214;&#20998;&#24067;&#30340;&#20272;&#35745;&#65292;&#24182;&#25552;&#20379;&#32479;&#19968;&#26377;&#25928;&#30340;&#25512;&#26029;&#65292;&#21363;&#20351;&#21021;&#22987;&#20272;&#35745;&#26159;&#20219;&#24847;&#19981;&#20934;&#30830;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#35266;&#27979;&#30740;&#31350;&#20013;&#20063;&#26159;&#21452;&#37325;&#40065;&#26834;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many causal estimands are only partially identifiable since they depend on the unobservable joint distribution between potential outcomes. Stratification on pretreatment covariates can yield sharper partial identification bounds; however, unless the covariates are discrete with relatively small support, this approach typically requires consistent estimation of the conditional distributions of the potential outcomes given the covariates. Thus, existing approaches may fail under model misspecification or if consistency assumptions are violated. In this study, we propose a unified and model-agnostic inferential approach for a wide class of partially identified estimands, based on duality theory for optimal transport problems. In randomized experiments, our approach can wrap around any estimates of the conditional distributions and provide uniformly valid inference, even if the initial estimates are arbitrarily inaccurate. Also, our approach is doubly robust in observational studies. Notab
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#22270;&#21305;&#37197;&#22330;&#21338;&#24328;&#30340;&#23384;&#22312;&#24615;&#21644;&#23398;&#20064;&#31639;&#27861;&#38382;&#39064;&#65292;&#22312;&#24369;&#21333;&#35843;&#26465;&#20214;&#19979;&#25552;&#20986;&#20102;&#19968;&#31181;&#31163;&#25955;&#26102;&#38388;&#31639;&#27861;&#65292;&#24182;&#24320;&#21457;&#20102;&#21160;&#20316;&#20540;&#20989;&#25968;&#20272;&#35745;&#36807;&#31243;&#20316;&#20026;&#20248;&#21270;&#36807;&#31243;&#30340;&#23376;&#27169;&#22359;&#12290;</title><link>http://arxiv.org/abs/2310.08089</link><description>&lt;p&gt;
&#23398;&#20064;&#27491;&#21017;&#21270;&#30340;&#21333;&#35843;&#22270;&#21305;&#37197;&#22330;&#21338;&#24328;
&lt;/p&gt;
&lt;p&gt;
Learning Regularized Monotone Graphon Mean-Field Games. (arXiv:2310.08089v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08089
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#22270;&#21305;&#37197;&#22330;&#21338;&#24328;&#30340;&#23384;&#22312;&#24615;&#21644;&#23398;&#20064;&#31639;&#27861;&#38382;&#39064;&#65292;&#22312;&#24369;&#21333;&#35843;&#26465;&#20214;&#19979;&#25552;&#20986;&#20102;&#19968;&#31181;&#31163;&#25955;&#26102;&#38388;&#31639;&#27861;&#65292;&#24182;&#24320;&#21457;&#20102;&#21160;&#20316;&#20540;&#20989;&#25968;&#20272;&#35745;&#36807;&#31243;&#20316;&#20026;&#20248;&#21270;&#36807;&#31243;&#30340;&#23376;&#27169;&#22359;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#22270;&#21305;&#37197;&#22330;&#21338;&#24328;&#65288;GMFG&#65289;&#20013;&#30340;&#20004;&#20010;&#22522;&#26412;&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#20219;&#24847;&#955;&#27491;&#21017;&#21270;GMFG&#65288;&#23545;&#20110;&#955;&#8805;0&#65289;&#30340;&#32435;&#20160;&#22343;&#34913;&#23384;&#22312;&#24615;&#12290;&#36825;&#20010;&#32467;&#26524;&#25152;&#20381;&#36182;&#30340;&#26465;&#20214;&#27604;&#20197;&#21069;&#30740;&#31350;&#38750;&#27491;&#21017;&#21270;GMFG&#65288;&#955;=0&#65289;&#21644;&#955;-&#27491;&#21017;&#21270;MFG&#30340;&#26465;&#20214;&#35201;&#24369;&#12290;&#31532;&#20108;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35777;&#26126;&#26377;&#25928;&#30340;&#31639;&#27861;&#26469;&#23398;&#20064;&#24369;&#21333;&#35843;GMFG&#30340;&#32435;&#20160;&#22343;&#34913;&#65292;&#21463;&#21040;Lasry&#21644;Lions [2007]&#30340;&#21551;&#21457;&#12290;&#20197;&#21069;&#30340;&#25991;&#29486;&#35201;&#20040;&#21482;&#20998;&#26512;&#36830;&#32493;&#26102;&#38388;&#31639;&#27861;&#65292;&#35201;&#20040;&#38656;&#35201;&#39069;&#22806;&#30340;&#26465;&#20214;&#26469;&#20998;&#26512;&#31163;&#25955;&#26102;&#38388;&#31639;&#27861;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#31163;&#25955;&#26102;&#38388;&#31639;&#27861;&#65292;&#24182;&#22312;&#24369;&#21333;&#35843;&#26465;&#20214;&#19979;&#25512;&#23548;&#20102;&#20854;&#25910;&#25947;&#36895;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;&#22312;&#32447;&#23398;&#20064;&#36807;&#31243;&#20013;&#24320;&#21457;&#21644;&#20998;&#26512;&#20102;&#21160;&#20316;&#20540;&#20989;&#25968;&#20272;&#35745;&#36807;&#31243;&#65292;&#36825;&#22312;&#21333;&#35843;GMFG&#30340;&#31639;&#27861;&#20013;&#26159;&#32570;&#22833;&#30340;&#12290;&#36825;&#22312;&#25105;&#20204;&#30340;&#20248;&#21270;&#36807;&#31243;&#20013;&#36215;&#21040;&#20102;&#23376;&#27169;&#22359;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies two fundamental problems in regularized Graphon Mean-Field Games (GMFGs). First, we establish the existence of a Nash Equilibrium (NE) of any $\lambda$-regularized GMFG (for $\lambda\geq 0$). This result relies on weaker conditions than those in previous works for analyzing both unregularized GMFGs ($\lambda=0$) and $\lambda$-regularized MFGs, which are special cases of GMFGs. Second, we propose provably efficient algorithms to learn the NE in weakly monotone GMFGs, motivated by Lasry and Lions [2007]. Previous literature either only analyzed continuous-time algorithms or required extra conditions to analyze discrete-time algorithms. In contrast, we design a discrete-time algorithm and derive its convergence rate solely under weakly monotone conditions. Furthermore, we develop and analyze the action-value function estimation procedure during the online learning process, which is absent from algorithms for monotone GMFGs. This serves as a sub-module in our optimizatio
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;gamma&#20998;&#24067;&#21644;log-Gaussian&#24314;&#27169;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#38598;&#20197;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#65292;&#35299;&#20915;&#20102;&#23454;&#38469;&#35266;&#27979;&#25968;&#25454;&#26377;&#38480;&#30340;&#25361;&#25112;&#12290;&#36890;&#36807;&#24212;&#29992;&#20110;Raman&#21644;CARS&#20809;&#35889;&#65292;&#21516;&#26102;&#35757;&#32451;&#20004;&#20010;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26469;&#20272;&#35745;gamma&#36807;&#31243;&#30340;&#21442;&#25968;&#65292;&#21487;&#20197;&#20272;&#35745;&#22522;&#30784;&#30340;&#20809;&#35889;&#24182;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.08055</link><description>&lt;p&gt;
&#29992;&#20110;Raman&#21644;CARS&#20809;&#35889;&#23398;&#20013;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#23545;&#25968;-&#39640;&#26031;&#947;&#36807;&#31243;&#30340;&#35757;&#32451;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Log-Gaussian Gamma Processes for Training Bayesian Neural Networks in Raman and CARS Spectroscopies. (arXiv:2310.08055v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08055
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;gamma&#20998;&#24067;&#21644;log-Gaussian&#24314;&#27169;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#38598;&#20197;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#65292;&#35299;&#20915;&#20102;&#23454;&#38469;&#35266;&#27979;&#25968;&#25454;&#26377;&#38480;&#30340;&#25361;&#25112;&#12290;&#36890;&#36807;&#24212;&#29992;&#20110;Raman&#21644;CARS&#20809;&#35889;&#65292;&#21516;&#26102;&#35757;&#32451;&#20004;&#20010;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26469;&#20272;&#35745;gamma&#36807;&#31243;&#30340;&#21442;&#25968;&#65292;&#21487;&#20197;&#20272;&#35745;&#22522;&#30784;&#30340;&#20809;&#35889;&#24182;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;gamma&#20998;&#24067;&#30340;&#38543;&#26426;&#21464;&#37327;&#21644;log-Gaussian&#24314;&#27169;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#36866;&#21512;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#12290;&#36825;&#31181;&#26041;&#27861;&#35299;&#20915;&#20102;&#21508;&#31181;&#24212;&#29992;&#20013;&#23454;&#38469;&#35266;&#27979;&#25968;&#25454;&#26377;&#38480;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#23558;&#27492;&#26041;&#27861;&#24212;&#29992;&#20110;Raman&#21644;&#30456;&#24178;&#38450;-&#26031;&#25176;&#20811;&#26031;&#25289;&#26364;&#25955;&#23556;(CARS)&#20809;&#35889;&#20013;&#65292;&#20351;&#29992;&#23454;&#39564;&#20809;&#35889;&#20272;&#35745;gamma&#36807;&#31243;&#30340;&#21442;&#25968;&#12290;&#21442;&#25968;&#20272;&#35745;&#20351;&#29992;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#36827;&#34892;&#65292;&#20174;&#32780;&#20026;&#27169;&#22411;&#25552;&#20379;&#23436;&#25972;&#36125;&#21494;&#26031;&#21518;&#39564;&#20998;&#24067;&#65292;&#21487;&#29992;&#20110;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#23545;Raman&#21644;CARS&#30340;&#21152;&#24615;&#21644;&#20056;&#24615;&#32972;&#26223;&#20989;&#25968;&#36827;&#34892;&#24314;&#27169;&#12290;&#25105;&#20204;&#35757;&#32451;&#20102;&#20004;&#20010;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26469;&#20272;&#35745;gamma&#36807;&#31243;&#30340;&#21442;&#25968;&#65292;&#28982;&#21518;&#21487;&#20197;&#29992;&#36825;&#20123;&#21442;&#25968;&#26469;&#20272;&#35745;&#22522;&#30784;&#30340;Raman&#20809;&#35889;&#65292;&#24182;&#36890;&#36807;&#27010;&#29575;&#20998;&#24067;&#21442;&#25968;&#30340;&#20272;&#35745;&#21516;&#26102;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an approach utilizing gamma-distributed random variables, coupled with log-Gaussian modeling, to generate synthetic datasets suitable for training neural networks. This addresses the challenge of limited real observations in various applications. We apply this methodology to both Raman and coherent anti-Stokes Raman scattering (CARS) spectra, using experimental spectra to estimate gamma process parameters. Parameter estimation is performed using Markov chain Monte Carlo methods, yielding a full Bayesian posterior distribution for the model which can be sampled for synthetic data generation. Additionally, we model the additive and multiplicative background functions for Raman and CARS with Gaussian processes. We train two Bayesian neural networks to estimate parameters of the gamma process which can then be used to estimate the underlying Raman spectrum and simultaneously provide uncertainty through the estimation of parameters of a probability distribution. We apply the trai
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#23398;&#20064;&#30340;&#26368;&#20248;&#26680;&#36827;&#34892;&#26684;&#23376;&#23454;&#26102;&#27169;&#25311;&#30340;&#26041;&#27861;&#65292;&#22312;&#22797;&#26434;&#26391;&#20043;&#19975;&#26041;&#27861;&#30340;&#22522;&#30784;&#19978;&#28155;&#21152;&#20808;&#39564;&#20449;&#24687;&#65292;&#25104;&#21151;&#20811;&#26381;&#20102;&#31526;&#21495;&#38382;&#39064;&#65292;&#24182;&#25193;&#23637;&#20102;&#23454;&#26102;&#27169;&#25311;&#30340;&#33539;&#22260;&#65292;&#24182;&#36991;&#20813;&#20102;&#31163;&#25955;&#21270;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.08053</link><description>&lt;p&gt;
&#20351;&#29992;&#23398;&#20064;&#30340;&#26368;&#20248;&#26680;&#36827;&#34892;&#26684;&#23376;&#23454;&#26102;&#27169;&#25311;
&lt;/p&gt;
&lt;p&gt;
Lattice real-time simulations with learned optimal kernels. (arXiv:2310.08053v1 [hep-lat])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08053
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#23398;&#20064;&#30340;&#26368;&#20248;&#26680;&#36827;&#34892;&#26684;&#23376;&#23454;&#26102;&#27169;&#25311;&#30340;&#26041;&#27861;&#65292;&#22312;&#22797;&#26434;&#26391;&#20043;&#19975;&#26041;&#27861;&#30340;&#22522;&#30784;&#19978;&#28155;&#21152;&#20808;&#39564;&#20449;&#24687;&#65292;&#25104;&#21151;&#20811;&#26381;&#20102;&#31526;&#21495;&#38382;&#39064;&#65292;&#24182;&#25193;&#23637;&#20102;&#23454;&#26102;&#27169;&#25311;&#30340;&#33539;&#22260;&#65292;&#24182;&#36991;&#20813;&#20102;&#31163;&#25955;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#24378;&#21270;&#23398;&#20064;&#21551;&#21457;&#30340;&#37327;&#23376;&#22330;&#23454;&#26102;&#21160;&#21147;&#23398;&#27169;&#25311;&#31574;&#30053;&#12290;&#23427;&#22312;&#22797;&#26434;&#26391;&#20043;&#19975;&#26041;&#27861;&#22522;&#30784;&#19978;&#28155;&#21152;&#20102;&#31995;&#32479;&#29305;&#24322;&#30340;&#20808;&#39564;&#20449;&#24687;&#65292;&#36825;&#26159;&#20811;&#26381;&#20005;&#37325;&#30340;&#31526;&#21495;&#38382;&#39064;&#30340;&#24517;&#35201;&#21069;&#25552;&#12290;&#25105;&#20204;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#20248;&#21270;&#36807;&#31243;&#26159;&#36890;&#36807;&#20351;&#29992;&#26412;&#36136;&#19978;&#31283;&#23450;&#30340;&#22797;&#26434;&#26391;&#20043;&#19975;&#38543;&#26426;&#36807;&#31243;&#27714;&#35299;&#22120;&#21644;&#20174;&#36793;&#30028;&#39033;&#30340;&#27934;&#23519;&#20013;&#23548;&#20986;&#30340;&#26032;&#39062;&#26368;&#20248;&#24615;&#20934;&#21017;&#23454;&#29616;&#30340;&#12290;&#36825;&#31181;&#27010;&#24565;&#21644;&#25216;&#26415;&#36827;&#27493;&#20351;&#25105;&#20204;&#33021;&#22815;&#26174;&#33879;&#25193;&#23637;1+1&#32500;&#26631;&#37327;&#22330;&#29702;&#35770;&#20013;&#23454;&#26102;&#27169;&#25311;&#30340;&#33539;&#22260;&#65292;&#36229;&#36807;&#29616;&#26377;&#27700;&#24179;&#65292;&#24182;&#36991;&#20813;&#20102;&#20043;&#21069;&#23454;&#26102;&#22330;&#35770;&#27169;&#25311;&#20013;&#30340;&#31163;&#25955;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#35813;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#21644;&#26377;&#21069;&#26223;&#30340;&#26410;&#26469;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a simulation strategy for the real-time dynamics of quantum fields, inspired by reinforcement learning. It builds on the complex Langevin approach, which it amends with system specific prior information, a necessary prerequisite to overcome this exceptionally severe sign problem. The optimization process underlying our machine learning approach is made possible by deploying inherently stable solvers of the complex Langevin stochastic process and a novel optimality criterion derived from insight into so-called boundary terms. This conceptual and technical progress allows us to both significantly extend the range of real-time simulations in 1+1d scalar field theory beyond the state-of-the-art and to avoid discretization artifacts that plagued previous real-time field theory simulations. Limitations of and promising future directions are discussed.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22122;&#22768;&#33410;&#28857;&#26631;&#31614;&#20316;&#20026;&#39069;&#22806;&#33410;&#28857;&#20449;&#24687;&#30340;&#23616;&#37096;&#22270;&#32858;&#31867;&#26041;&#27861;&#65292;&#24182;&#25506;&#31350;&#20102;&#23558;&#22122;&#22768;&#26631;&#31614;&#32435;&#20837;&#23616;&#37096;&#22270;&#32858;&#31867;&#30340;&#22909;&#22788;&#12290;</title><link>http://arxiv.org/abs/2310.08031</link><description>&lt;p&gt;
&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#23616;&#37096;&#22270;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Local Graph Clustering with Noisy Labels. (arXiv:2310.08031v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08031
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22122;&#22768;&#33410;&#28857;&#26631;&#31614;&#20316;&#20026;&#39069;&#22806;&#33410;&#28857;&#20449;&#24687;&#30340;&#23616;&#37096;&#22270;&#32858;&#31867;&#26041;&#27861;&#65292;&#24182;&#25506;&#31350;&#20102;&#23558;&#22122;&#22768;&#26631;&#31614;&#32435;&#20837;&#23616;&#37096;&#22270;&#32858;&#31867;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#65292;&#23545;&#20110;&#24102;&#26377;&#39069;&#22806;&#33410;&#28857;&#20449;&#24687;&#65288;&#22914;&#25991;&#26412;&#12289;&#22270;&#20687;&#25110;&#26631;&#31614;&#65289;&#30340;&#22270;&#24418;&#30340;&#22686;&#21152;&#20852;&#36259;&#65292;&#20419;&#20351;&#20102;&#38656;&#35201;&#32791;&#36153;&#22823;&#37327;&#36164;&#28304;&#22788;&#29702;&#25972;&#20010;&#22270;&#24418;&#30340;&#26041;&#27861;&#30340;&#27969;&#34892;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#20174;&#36825;&#26679;&#30340;&#25968;&#25454;&#20013;&#25552;&#21462;&#26377;&#29992;&#20449;&#24687;&#30340;&#24555;&#36895;&#23616;&#37096;&#26041;&#27861;&#65288;&#21363;&#19981;&#38656;&#35201;&#35775;&#38382;&#25972;&#20010;&#22270;&#24418;&#65289;&#30340;&#21457;&#23637;&#36824;&#24456;&#23569;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#29992;&#22122;&#22768;&#33410;&#28857;&#26631;&#31614;&#20316;&#20026;&#39069;&#22806;&#33410;&#28857;&#20449;&#24687;&#30340;&#23616;&#37096;&#22270;&#32858;&#31867;&#30340;&#30740;&#31350;&#12290;&#22312;&#36825;&#31181;&#35774;&#32622;&#19979;&#65292;&#33410;&#28857;&#26681;&#25454;&#25152;&#23646;&#31751;&#30340;&#32852;&#23646;&#20851;&#31995;&#25509;&#25910;&#21021;&#22987;&#20108;&#36827;&#21046;&#26631;&#31614;&#65306;&#22914;&#26524;&#23427;&#20204;&#23646;&#20110;&#30446;&#26631;&#31751;&#65292;&#21017;&#20026;1&#65307;&#21542;&#21017;&#20026;0&#12290;&#38543;&#21518;&#65292;&#36825;&#20123;&#26631;&#31614;&#30340;&#19968;&#37096;&#20998;&#20250;&#34987;&#32763;&#36716;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#23558;&#22122;&#22768;&#26631;&#31614;&#32435;&#20837;&#23616;&#37096;&#22270;&#32858;&#31867;&#30340;&#22909;&#22788;&#12290;&#36890;&#36807;&#26500;&#24314;&#24102;&#26377;&#36825;&#20123;&#26631;&#31614;&#30340;&#21152;&#26435;&#22270;&#24418;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#22270;&#25193;&#25955;&#30340;&#23616;&#37096;&#32858;&#31867;&#26041;&#27861;&#22312;&#21407;&#22987;&#22270;&#24418;&#21644;&#21152;&#26435;&#22270;&#24418;&#19978;&#30340;&#24615;&#33021;&#12290;&#20174;&#29702;&#35770;&#35282;&#24230;&#20986;&#21457;&#65292;
&lt;/p&gt;
&lt;p&gt;
The growing interest in machine learning problems over graphs with additional node information such as texts, images, or labels has popularized methods that require the costly operation of processing the entire graph. Yet, little effort has been made to the development of fast local methods (i.e. without accessing the entire graph) that extract useful information from such data. To that end, we propose a study of local graph clustering using noisy node labels as a proxy for additional node information. In this setting, nodes receive initial binary labels based on cluster affiliation: 1 if they belong to the target cluster and 0 otherwise. Subsequently, a fraction of these labels is flipped. We investigate the benefits of incorporating noisy labels for local graph clustering. By constructing a weighted graph with such labels, we study the performance of graph diffusion-based local clustering method on both the original and the weighted graphs. From a theoretical perspective, we consider
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#40065;&#26834;&#30340;&#19968;&#27604;&#29305;&#21387;&#32553;&#24863;&#30693;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20108;&#20803;&#36845;&#20195;&#30828;&#38408;&#20540;&#21270;&#65288;BIHT&#65289;&#31639;&#27861;&#65292;&#22312;&#22122;&#22768;&#24773;&#20917;&#19979;&#27604;&#30446;&#21069;&#24050;&#30693;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2310.08019</link><description>&lt;p&gt;
&#40065;&#26834;&#30340;&#19968;&#27604;&#29305;&#21387;&#32553;&#24863;&#30693;&#19982;&#36845;&#20195;&#30828;&#38408;&#20540;&#21270;
&lt;/p&gt;
&lt;p&gt;
Robust 1-bit Compressed Sensing with Iterative Hard Thresholding. (arXiv:2310.08019v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08019
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#40065;&#26834;&#30340;&#19968;&#27604;&#29305;&#21387;&#32553;&#24863;&#30693;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20108;&#20803;&#36845;&#20195;&#30828;&#38408;&#20540;&#21270;&#65288;BIHT&#65289;&#31639;&#27861;&#65292;&#22312;&#22122;&#22768;&#24773;&#20917;&#19979;&#27604;&#30446;&#21069;&#24050;&#30693;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19968;&#27604;&#29305;&#21387;&#32553;&#24863;&#30693;&#20013;&#65292;&#30446;&#26631;&#26159;&#20174;&#20165;&#26377;&#27491;&#36127;&#31526;&#21495;&#37327;&#21270;&#30340;&#32447;&#24615;&#27979;&#37327;&#20013;&#24674;&#22797;&#19968;&#20010;k-&#31232;&#30095;&#21333;&#20301;&#21521;&#37327;x&#65292;&#20351;&#20854;&#30456;&#23545;&#20110;&#26368;&#23567;&#20108;&#20056;&#35823;&#24046;&#1013;&#65288;&#22312;&#8467;2&#33539;&#25968;&#19979;&#65289;&#20869;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#24102;&#22122;&#22768;&#30340;&#24773;&#20917;&#65292;&#21363;&#37096;&#20998;&#27979;&#37327;&#20540;&#21487;&#33021;&#34987;&#23545;&#25163;&#32763;&#36716;&#30340;&#24773;&#20917;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#31181;&#21517;&#20026;&#20108;&#20803;&#36845;&#20195;&#30828;&#38408;&#20540;&#21270;&#65288;Binary Iterative Hard Thresholding&#65292;BIHT&#65289;&#30340;&#31639;&#27861;&#65292;&#22312;&#36825;&#20010;&#22122;&#22768;&#24773;&#20917;&#19979;&#36827;&#34892;&#19968;&#27604;&#29305;&#21387;&#32553;&#24863;&#30693;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;&#36817;&#20284;O(k/&#1013;)&#20010;&#26080;&#22122;&#22768;&#27979;&#37327;&#65292;BIHT&#31639;&#27861;&#21487;&#20197;&#25552;&#20379;&#19968;&#20010;&#1013;&#35823;&#24046;&#33539;&#22260;&#20869;&#30340;&#20272;&#35745;&#12290;&#36825;&#20010;&#32467;&#26524;&#26159;&#26368;&#20248;&#30340;&#21644;&#36890;&#29992;&#30340;&#65292;&#24847;&#21619;&#30528;&#19968;&#32452;&#27979;&#37327;&#21487;&#20197;&#36866;&#29992;&#20110;&#25152;&#26377;&#31232;&#30095;&#21521;&#37327;&#12290;&#26412;&#25991;&#36824;&#23637;&#31034;&#20102;&#22312;&#22122;&#22768;&#24773;&#20917;&#19979;&#65292;BIHT&#31639;&#27861;&#27604;&#30446;&#21069;&#24050;&#30693;&#30340;&#25152;&#26377;&#26041;&#27861;&#37117;&#25552;&#20379;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In 1-bit compressed sensing, the aim is to estimate a $k$-sparse unit vector $x\in S^{n-1}$ within an $\epsilon$ error (in $\ell_2$) from minimal number of linear measurements that are quantized to just their signs, i.e., from measurements of the form $y = \mathrm{Sign}(\langle a, x\rangle).$ In this paper, we study a noisy version where a fraction of the measurements can be flipped, potentially by an adversary. In particular, we analyze the Binary Iterative Hard Thresholding (BIHT) algorithm, a proximal gradient descent on a properly defined loss function used for 1-bit compressed sensing, in this noisy setting. It is known from recent results that, with $\tilde{O}(\frac{k}{\epsilon})$ noiseless measurements, BIHT provides an estimate within $\epsilon$ error. This result is optimal and universal, meaning one set of measurements work for all sparse vectors. In this paper, we show that BIHT also provides better results than all known methods for the noisy setting. We show that when up t
&lt;/p&gt;</description></item><item><title>LEMON&#26159;&#19968;&#31181;&#26080;&#25439;&#27169;&#22411;&#25193;&#23637;&#26041;&#27861;&#65292;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#33021;&#22815;&#36890;&#36807;&#21033;&#29992;&#23567;&#22411;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#30693;&#35782;&#26469;&#21021;&#22987;&#21270;&#21644;&#35757;&#32451;&#22823;&#22411;&#27169;&#22411;&#65292;&#20174;&#32780;&#22823;&#22823;&#20943;&#23569;&#35757;&#32451;&#26102;&#38388;&#65292;&#21516;&#26102;&#20855;&#26377;&#36890;&#29992;&#24615;&#36866;&#29992;&#20110;&#21508;&#31181;&#32593;&#32476;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2310.07999</link><description>&lt;p&gt;
LEMON&#65306;&#26080;&#25439;&#27169;&#22411;&#25193;&#23637;
&lt;/p&gt;
&lt;p&gt;
LEMON: Lossless model expansion. (arXiv:2310.07999v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07999
&lt;/p&gt;
&lt;p&gt;
LEMON&#26159;&#19968;&#31181;&#26080;&#25439;&#27169;&#22411;&#25193;&#23637;&#26041;&#27861;&#65292;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#33021;&#22815;&#36890;&#36807;&#21033;&#29992;&#23567;&#22411;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#30693;&#35782;&#26469;&#21021;&#22987;&#21270;&#21644;&#35757;&#32451;&#22823;&#22411;&#27169;&#22411;&#65292;&#20174;&#32780;&#22823;&#22823;&#20943;&#23569;&#35757;&#32451;&#26102;&#38388;&#65292;&#21516;&#26102;&#20855;&#26377;&#36890;&#29992;&#24615;&#36866;&#29992;&#20110;&#21508;&#31181;&#32593;&#32476;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;&#29305;&#21035;&#26159;Transformer&#65289;&#30340;&#25193;&#23637;&#23545;&#20110;&#23427;&#20204;&#30340;&#20986;&#33394;&#24615;&#33021;&#33267;&#20851;&#37325;&#35201;&#65292;&#24182;&#19988;&#36827;&#19968;&#27493;&#23548;&#33268;&#20102;&#22522;&#30784;&#27169;&#22411;&#20013;&#22797;&#26434;&#30340;&#25512;&#29702;&#33021;&#21147;&#30340;&#20986;&#29616;&#12290;&#36825;&#31181;&#25193;&#23637;&#36890;&#24120;&#38656;&#35201;&#20174;&#22836;&#24320;&#22987;&#35757;&#32451;&#22823;&#22411;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;&#38543;&#26426;&#21021;&#22987;&#21270;&#65292;&#32780;&#26080;&#27861;&#21033;&#29992;&#24050;&#26377;&#30340;&#23567;&#22411;&#27169;&#22411;&#25152;&#33719;&#24471;&#30340;&#30693;&#35782;&#65292;&#36825;&#20123;&#23567;&#22411;&#27169;&#22411;&#24050;&#32463;&#32791;&#36153;&#20102;&#22823;&#37327;&#36164;&#28304;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#31181;&#20302;&#25928;&#29575;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26080;&#25439;&#27169;&#22411;&#25193;&#23637;&#65288;LEMON&#65289;&#65292;&#19968;&#31181;&#20351;&#29992;&#23567;&#22411;&#20294;&#24050;&#32463;&#39044;&#35757;&#32451;&#30340;&#27169;&#22411;&#30340;&#26435;&#37325;&#26469;&#21021;&#22987;&#21270;&#25193;&#23637;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#19987;&#38376;&#20026;&#25193;&#23637;&#27169;&#22411;&#23450;&#21046;&#30340;&#20248;&#21270;&#23398;&#20064;&#29575;&#35843;&#24230;&#22120;&#36827;&#34892;&#27169;&#22411;&#35757;&#32451;&#65292;&#19982;&#20174;&#22836;&#35757;&#32451;&#30456;&#27604;&#65292;&#22823;&#22823;&#20943;&#23569;&#20102;&#35757;&#32451;&#26102;&#38388;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;LEMON&#20855;&#26377;&#36890;&#29992;&#24615;&#65292;&#33021;&#22815;&#19982;&#21508;&#31181;&#32593;&#32476;&#32467;&#26500;&#20860;&#23481;&#65292;&#21253;&#25324;Vision Transformer&#21644;BERT&#31561;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#32467;&#26524;&#35777;&#26126;&#20102;LEMON&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Scaling of deep neural networks, especially Transformers, is pivotal for their surging performance and has further led to the emergence of sophisticated reasoning capabilities in foundation models. Such scaling generally requires training large models from scratch with random initialization, failing to leverage the knowledge acquired by their smaller counterparts, which are already resource-intensive to obtain. To tackle this inefficiency, we present $\textbf{L}$ossl$\textbf{E}$ss $\textbf{MO}$del Expansio$\textbf{N}$ (LEMON), a recipe to initialize scaled models using the weights of their smaller but pre-trained counterparts. This is followed by model training with an optimized learning rate scheduler tailored explicitly for the scaled models, substantially reducing the training time compared to training from scratch. Notably, LEMON is versatile, ensuring compatibility with various network structures, including models like Vision Transformers and BERT. Our empirical results demonstrat
&lt;/p&gt;</description></item><item><title>RandCom&#26159;&#19968;&#31181;&#21435;&#20013;&#24515;&#21270;&#30340;&#38543;&#26426;&#36890;&#20449;&#36339;&#36291;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#20998;&#24067;&#24335;&#20248;&#21270;&#20013;&#36890;&#36807;&#27010;&#29575;&#24615;&#26412;&#22320;&#26356;&#26032;&#20943;&#23569;&#36890;&#20449;&#24320;&#38144;&#65292;&#24182;&#22312;&#19981;&#21516;&#30340;&#35774;&#32622;&#20013;&#23454;&#29616;&#32447;&#24615;&#21152;&#36895;&#12290;</title><link>http://arxiv.org/abs/2310.07983</link><description>&lt;p&gt;
RandCom&#65306;&#21435;&#20013;&#24515;&#21270;&#38543;&#26426;&#36890;&#20449;&#36339;&#36291;&#26041;&#27861;&#29992;&#20110;&#20998;&#24067;&#24335;&#38543;&#26426;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
RandCom: Random Communication Skipping Method for Decentralized Stochastic Optimization. (arXiv:2310.07983v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07983
&lt;/p&gt;
&lt;p&gt;
RandCom&#26159;&#19968;&#31181;&#21435;&#20013;&#24515;&#21270;&#30340;&#38543;&#26426;&#36890;&#20449;&#36339;&#36291;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#20998;&#24067;&#24335;&#20248;&#21270;&#20013;&#36890;&#36807;&#27010;&#29575;&#24615;&#26412;&#22320;&#26356;&#26032;&#20943;&#23569;&#36890;&#20449;&#24320;&#38144;&#65292;&#24182;&#22312;&#19981;&#21516;&#30340;&#35774;&#32622;&#20013;&#23454;&#29616;&#32447;&#24615;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;&#38543;&#26426;&#36890;&#20449;&#36339;&#36807;&#30340;&#20998;&#24067;&#24335;&#20248;&#21270;&#26041;&#27861;&#22240;&#20854;&#22312;&#21152;&#36895;&#36890;&#20449;&#22797;&#26434;&#24615;&#26041;&#38754;&#20855;&#26377;&#30340;&#20248;&#21183;&#32780;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#24378;&#20984;&#30830;&#23450;&#24615;&#35774;&#32622;&#30340;&#38598;&#20013;&#24335;&#36890;&#20449;&#21327;&#35758;&#19978;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;RandCom&#30340;&#20998;&#24067;&#24335;&#20248;&#21270;&#26041;&#27861;&#65292;&#23427;&#37319;&#29992;&#20102;&#27010;&#29575;&#24615;&#30340;&#26412;&#22320;&#26356;&#26032;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;RandCom&#22312;&#38543;&#26426;&#38750;&#20984;&#12289;&#20984;&#21644;&#24378;&#20984;&#35774;&#32622;&#20013;&#30340;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#33021;&#22815;&#36890;&#36807;&#36890;&#20449;&#27010;&#29575;&#26469;&#28176;&#36817;&#22320;&#20943;&#23569;&#36890;&#20449;&#24320;&#38144;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#24403;&#33410;&#28857;&#25968;&#37327;&#22686;&#21152;&#26102;&#65292;RandCom&#33021;&#22815;&#23454;&#29616;&#32447;&#24615;&#21152;&#36895;&#12290;&#22312;&#38543;&#26426;&#24378;&#20984;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;RandCom&#21487;&#20197;&#36890;&#36807;&#29420;&#31435;&#20110;&#32593;&#32476;&#30340;&#27493;&#38271;&#23454;&#29616;&#32447;&#24615;&#21152;&#36895;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;RandCom&#24212;&#29992;&#20110;&#32852;&#37030;&#23398;&#20064;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#23454;&#29616;&#32447;&#24615;&#21152;&#36895;&#30340;&#28508;&#21147;&#30340;&#31215;&#26497;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distributed optimization methods with random communication skips are gaining increasing attention due to their proven benefits in accelerating communication complexity. Nevertheless, existing research mainly focuses on centralized communication protocols for strongly convex deterministic settings. In this work, we provide a decentralized optimization method called RandCom, which incorporates probabilistic local updates. We analyze the performance of RandCom in stochastic non-convex, convex, and strongly convex settings and demonstrate its ability to asymptotically reduce communication overhead by the probability of communication. Additionally, we prove that RandCom achieves linear speedup as the number of nodes increases. In stochastic strongly convex settings, we further prove that RandCom can achieve linear speedup with network-independent stepsizes. Moreover, we apply RandCom to federated learning and provide positive results concerning the potential for achieving linear speedup and
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#36873;&#25321;&#26368;&#26377;&#21487;&#33021;&#20174;&#27835;&#30103;&#20013;&#33719;&#30410;&#30340;&#20154;&#30340;&#38382;&#39064;&#65292;&#22312;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;&#21644;&#30830;&#23450;&#25130;&#26029;&#20540;&#26102;&#38754;&#20020;&#22810;&#37325;&#27979;&#35797;&#38382;&#39064;&#65292;&#25552;&#20986;&#19968;&#31181;&#32479;&#19968;&#30340;&#32622;&#20449;&#24102;&#26041;&#27861;&#26469;&#35780;&#20272;&#36825;&#20123;&#20010;&#20307;&#30340;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.07973</link><description>&lt;p&gt;
&#23545;&#20110;&#36873;&#25321;&#26368;&#26377;&#21487;&#33021;&#20174;&#27835;&#30103;&#20013;&#33719;&#30410;&#30340;&#20154;&#30340;&#32479;&#35745;&#24615;&#33021;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Statistical Performance Guarantee for Selecting Those Predicted to Benefit Most from Treatment. (arXiv:2310.07973v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07973
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#36873;&#25321;&#26368;&#26377;&#21487;&#33021;&#20174;&#27835;&#30103;&#20013;&#33719;&#30410;&#30340;&#20154;&#30340;&#38382;&#39064;&#65292;&#22312;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;&#21644;&#30830;&#23450;&#25130;&#26029;&#20540;&#26102;&#38754;&#20020;&#22810;&#37325;&#27979;&#35797;&#38382;&#39064;&#65292;&#25552;&#20986;&#19968;&#31181;&#32479;&#19968;&#30340;&#32622;&#20449;&#24102;&#26041;&#27861;&#26469;&#35780;&#20272;&#36825;&#20123;&#20010;&#20307;&#30340;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24191;&#27867;&#30340;&#23398;&#31185;&#39046;&#22495;&#20013;&#65292;&#35768;&#22810;&#30740;&#31350;&#20154;&#21592;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#26469;&#35782;&#21035;&#19968;&#32452;&#34987;&#31216;&#20026;&#20363;&#22806;&#21453;&#24212;&#32773;&#30340;&#20010;&#20307;&#65292;&#20182;&#20204;&#26368;&#26377;&#21487;&#33021;&#20174;&#27835;&#30103;&#20013;&#33719;&#30410;&#12290;&#19968;&#20010;&#24120;&#35265;&#30340;&#26041;&#27861;&#21253;&#25324;&#20004;&#20010;&#27493;&#39588;&#12290;&#39318;&#20808;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#25110;&#20854;&#20195;&#29702;&#12290;&#28982;&#21518;&#30830;&#23450;&#25152;&#24471;&#27835;&#30103;&#20248;&#20808;&#39034;&#24207;&#20998;&#25968;&#30340;&#25130;&#26029;&#20540;&#65292;&#20197;&#36873;&#25321;&#37027;&#20123;&#26368;&#26377;&#21487;&#33021;&#20174;&#27835;&#30103;&#20013;&#33719;&#30410;&#30340;&#20154;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#20123;&#20272;&#35745;&#30340;&#27835;&#30103;&#20248;&#20808;&#39034;&#24207;&#20998;&#25968;&#24448;&#24448;&#23384;&#22312;&#20559;&#24046;&#21644;&#22122;&#22768;&#12290;&#27492;&#22806;&#65292;&#21033;&#29992;&#30456;&#21516;&#30340;&#25968;&#25454;&#26082;&#36873;&#25321;&#25130;&#26029;&#20540;&#21448;&#20272;&#35745;&#25152;&#36873;&#20010;&#20307;&#30340;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#20250;&#36935;&#21040;&#22810;&#37325;&#27979;&#35797;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#32622;&#20449;&#24102;&#26469;&#23454;&#39564;&#24615;&#22320;&#35780;&#20272;&#37027;&#20123;&#27835;&#30103;&#20248;&#20808;&#39034;&#24207;&#20998;&#25968;&#33267;&#23569;&#19982;&#20219;&#20309;&#32473;&#23450;&#37327;&#21270;&#20540;&#30456;&#31561;&#30340;&#20010;&#20307;&#30340;&#25490;&#24207;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#65288;GATES&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Across a wide array of disciplines, many researchers use machine learning (ML) algorithms to identify a subgroup of individuals, called exceptional responders, who are likely to be helped by a treatment the most. A common approach consists of two steps. One first estimates the conditional average treatment effect or its proxy using an ML algorithm. They then determine the cutoff of the resulting treatment prioritization score to select those predicted to benefit most from the treatment. Unfortunately, these estimated treatment prioritization scores are often biased and noisy. Furthermore, utilizing the same data to both choose a cutoff value and estimate the average treatment effect among the selected individuals suffer from a multiple testing problem. To address these challenges, we develop a uniform confidence band for experimentally evaluating the sorted average treatment effect (GATES) among the individuals whose treatment prioritization score is at least as high as any given quant
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#30740;&#31350;&#20102;&#20195;&#29702;&#20248;&#21270;&#31639;&#27861;&#20013;&#36229;&#21442;&#25968;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#25628;&#32034;&#30340;&#20195;&#29702;&#20248;&#21270;&#26041;&#27861;&#65288;HASSO&#65289;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#21160;&#24577;&#35843;&#25972;&#36229;&#21442;&#25968;&#32780;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#35780;&#20272;&#12290;&#35813;&#26041;&#27861;&#26088;&#22312;&#25552;&#39640;&#20195;&#29702;&#20248;&#21270;&#31639;&#27861;&#30340;&#21487;&#35775;&#38382;&#24615;&#12289;&#25928;&#26524;&#21644;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.07970</link><description>&lt;p&gt;
&#36229;&#21442;&#25968;&#33258;&#36866;&#24212;&#25628;&#32034;&#29992;&#20110;&#20195;&#29702;&#20248;&#21270;&#65306;&#19968;&#31181;&#33258;&#35843;&#25972;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Hyperparameter Adaptive Search for Surrogate Optimization: A Self-Adjusting Approach. (arXiv:2310.07970v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07970
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#30740;&#31350;&#20102;&#20195;&#29702;&#20248;&#21270;&#31639;&#27861;&#20013;&#36229;&#21442;&#25968;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#25628;&#32034;&#30340;&#20195;&#29702;&#20248;&#21270;&#26041;&#27861;&#65288;HASSO&#65289;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#21160;&#24577;&#35843;&#25972;&#36229;&#21442;&#25968;&#32780;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#35780;&#20272;&#12290;&#35813;&#26041;&#27861;&#26088;&#22312;&#25552;&#39640;&#20195;&#29702;&#20248;&#21270;&#31639;&#27861;&#30340;&#21487;&#35775;&#38382;&#24615;&#12289;&#25928;&#26524;&#21644;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20195;&#29702;&#20248;&#21270;&#31639;&#27861;&#22312;&#20248;&#21270;&#26114;&#36149;&#30340;&#40657;&#30418;&#20989;&#25968;&#26041;&#38754;&#34920;&#29616;&#20986;&#20102;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#24615;&#33021;&#21463;&#19982;&#37319;&#26679;&#21644;&#20195;&#29702;&#25311;&#21512;&#30456;&#20851;&#30340;&#36229;&#21442;&#25968;&#30340;&#24433;&#21709;&#24456;&#22823;&#65292;&#36825;&#23545;&#20110;&#23427;&#20204;&#30340;&#24191;&#27867;&#24212;&#29992;&#26500;&#25104;&#25361;&#25112;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#21508;&#31181;&#20195;&#29702;&#20248;&#21270;&#31639;&#27861;&#20013;&#36229;&#21442;&#25968;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36229;&#21442;&#25968;&#33258;&#36866;&#24212;&#25628;&#32034;&#30340;&#20195;&#29702;&#20248;&#21270;&#26041;&#27861;&#65288;HASSO&#65289;&#12290;HASSO&#19981;&#26159;&#19968;&#20010;&#36229;&#21442;&#25968;&#35843;&#25972;&#31639;&#27861;&#65292;&#32780;&#26159;&#19968;&#31181;&#36890;&#29992;&#30340;&#33258;&#35843;&#25972;&#20195;&#29702;&#20248;&#21270;&#31639;&#27861;&#65292;&#23427;&#22312;&#21516;&#26102;&#20248;&#21270;&#20027;&#35201;&#30446;&#26631;&#20989;&#25968;&#30340;&#36807;&#31243;&#20013;&#21160;&#24577;&#35843;&#25972;&#33258;&#24049;&#30340;&#36229;&#21442;&#25968;&#65292;&#32780;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#35780;&#20272;&#12290;&#20854;&#30446;&#26631;&#26159;&#25552;&#39640;&#20195;&#29702;&#20248;&#21270;&#31639;&#27861;&#23545;&#20110;&#20174;&#19994;&#32773;&#30340;&#21487;&#35775;&#38382;&#24615;&#12289;&#25928;&#26524;&#21644;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#35782;&#21035;&#24182;&#20462;&#25913;&#20102;&#27599;&#20010;&#38382;&#39064;&#21644;&#20195;&#29702;&#20248;&#21270;&#26041;&#27861;&#29305;&#23450;&#30340;&#26368;&#26377;&#24433;&#21709;&#21147;&#30340;&#36229;&#21442;&#25968;&#65292;&#20943;&#23569;&#20102;&#25163;&#21160;&#35843;&#25972;&#30340;&#38656;&#27714;&#65292;&#21516;&#26102;&#19981;&#26174;&#33879;&#22686;&#21152;&#35745;&#31639;&#36127;&#25285;&#12290;&#23454;&#39564;&#32467;&#26524;&#28436;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Surrogate Optimization (SO) algorithms have shown promise for optimizing expensive black-box functions. However, their performance is heavily influenced by hyperparameters related to sampling and surrogate fitting, which poses a challenge to their widespread adoption. We investigate the impact of hyperparameters on various SO algorithms and propose a Hyperparameter Adaptive Search for SO (HASSO) approach. HASSO is not a hyperparameter tuning algorithm, but a generic self-adjusting SO algorithm that dynamically tunes its own hyperparameters while concurrently optimizing the primary objective function, without requiring additional evaluations. The aim is to improve the accessibility, effectiveness, and convergence speed of SO algorithms for practitioners. Our approach identifies and modifies the most influential hyperparameters specific to each problem and SO approach, reducing the need for manual tuning without significantly increasing the computational burden. Experimental results demo
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19978;&#19979;&#25991;&#21270;&#25919;&#31574;&#24674;&#22797;&#26041;&#27861;&#29992;&#20110;&#24314;&#27169;&#22797;&#26434;&#30340;&#21307;&#30103;&#20915;&#31574;&#36807;&#31243;&#65292;&#20197;&#35299;&#20915;&#29616;&#26377;&#27169;&#22411;&#22312;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#23558;&#20915;&#31574;&#31574;&#30053;&#25286;&#20998;&#20026;&#19978;&#19979;&#25991;&#29305;&#23450;&#31574;&#30053;&#65292;&#36890;&#36807;&#22810;&#20219;&#21153;&#23398;&#20064;&#26469;&#23454;&#29616;&#24314;&#27169;&#65292;&#24182;&#25552;&#20379;&#22797;&#26434;&#34892;&#20026;&#30340;&#31616;&#27905;&#25551;&#36848;&#12290;</title><link>http://arxiv.org/abs/2310.07918</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#21270;&#25919;&#31574;&#24674;&#22797;&#65306;&#36890;&#36807;&#33258;&#36866;&#24212;&#27169;&#20223;&#23398;&#20064;&#23545;&#21307;&#30103;&#20915;&#31574;&#36827;&#34892;&#24314;&#27169;&#21644;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Contextualized Policy Recovery: Modeling and Interpreting Medical Decisions with Adaptive Imitation Learning. (arXiv:2310.07918v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07918
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19978;&#19979;&#25991;&#21270;&#25919;&#31574;&#24674;&#22797;&#26041;&#27861;&#29992;&#20110;&#24314;&#27169;&#22797;&#26434;&#30340;&#21307;&#30103;&#20915;&#31574;&#36807;&#31243;&#65292;&#20197;&#35299;&#20915;&#29616;&#26377;&#27169;&#22411;&#22312;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#23558;&#20915;&#31574;&#31574;&#30053;&#25286;&#20998;&#20026;&#19978;&#19979;&#25991;&#29305;&#23450;&#31574;&#30053;&#65292;&#36890;&#36807;&#22810;&#20219;&#21153;&#23398;&#20064;&#26469;&#23454;&#29616;&#24314;&#27169;&#65292;&#24182;&#25552;&#20379;&#22797;&#26434;&#34892;&#20026;&#30340;&#31616;&#27905;&#25551;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#31574;&#30053;&#23398;&#20064;&#26088;&#22312;&#20174;&#35266;&#23519;&#21040;&#30340;&#34892;&#20026;&#20013;&#20272;&#35745;&#21487;&#29702;&#35299;&#30340;&#20915;&#31574;&#31574;&#30053;&#65307;&#28982;&#32780;&#65292;&#29616;&#26377;&#27169;&#22411;&#22312;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#20043;&#38388;&#23384;&#22312;&#26435;&#34913;&#12290;&#36825;&#31181;&#26435;&#34913;&#38480;&#21046;&#20102;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#23545;&#20154;&#31867;&#20915;&#31574;&#36807;&#31243;&#30340;&#35299;&#37322;&#65292;&#20363;&#22914;&#65292;&#23457;&#35745;&#21307;&#30103;&#20915;&#31574;&#30340;&#20559;&#35265;&#21644;&#27425;&#20248;&#23454;&#36341;&#65292;&#25105;&#20204;&#38656;&#35201;&#20915;&#31574;&#36807;&#31243;&#30340;&#27169;&#22411;&#65292;&#33021;&#22815;&#25552;&#20379;&#22797;&#26434;&#34892;&#20026;&#30340;&#31616;&#27905;&#25551;&#36848;&#12290;&#29616;&#26377;&#26041;&#27861;&#22522;&#26412;&#19978;&#30001;&#20110;&#23558;&#28508;&#22312;&#20915;&#31574;&#36807;&#31243;&#34920;&#31034;&#20026;&#36890;&#29992;&#31574;&#30053;&#32780;&#36127;&#25285;&#20102;&#36825;&#31181;&#26435;&#34913;&#65292;&#32780;&#23454;&#38469;&#19978;&#20154;&#31867;&#20915;&#31574;&#26159;&#21160;&#24577;&#30340;&#65292;&#21487;&#20197;&#38543;&#19978;&#19979;&#25991;&#20449;&#24687;&#32780;&#22823;&#24133;&#25913;&#21464;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19978;&#19979;&#25991;&#21270;&#25919;&#31574;&#24674;&#22797;&#65288;CPR&#65289;&#65292;&#23558;&#24314;&#27169;&#22797;&#26434;&#20915;&#31574;&#36807;&#31243;&#30340;&#38382;&#39064;&#37325;&#26032;&#23450;&#20041;&#20026;&#22810;&#20219;&#21153;&#23398;&#20064;&#38382;&#39064;&#65292;&#20854;&#20013;&#22797;&#26434;&#20915;&#31574;&#31574;&#30053;&#30001;&#29305;&#23450;&#19978;&#19979;&#25991;&#30340;&#31574;&#30053;&#32452;&#25104;&#12290;CPR&#23558;&#27599;&#20010;&#19978;&#19979;&#25991;&#29305;&#23450;&#31574;&#30053;&#24314;&#27169;&#20026;&#32447;&#24615;&#30340;&#35266;&#23519;-&#21160;&#20316;&#26144;&#23556;
&lt;/p&gt;
&lt;p&gt;
Interpretable policy learning seeks to estimate intelligible decision policies from observed actions; however, existing models fall short by forcing a tradeoff between accuracy and interpretability. This tradeoff limits data-driven interpretations of human decision-making process. e.g. to audit medical decisions for biases and suboptimal practices, we require models of decision processes which provide concise descriptions of complex behaviors. Fundamentally, existing approaches are burdened by this tradeoff because they represent the underlying decision process as a universal policy, when in fact human decisions are dynamic and can change drastically with contextual information. Thus, we propose Contextualized Policy Recovery (CPR), which re-frames the problem of modeling complex decision processes as a multi-task learning problem in which complex decision policies are comprised of context-specific policies. CPR models each context-specific policy as a linear observation-to-action mapp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20849;&#36717;&#31215;&#20998;&#22120;&#21644;&#20998;&#35010;&#31215;&#20998;&#22120;&#20004;&#31181;&#26694;&#26550;&#65292;&#29992;&#20110;&#21152;&#36895;&#39044;&#35757;&#32451;&#27169;&#22411;&#20013;&#30340;&#26679;&#26412;&#29983;&#25104;&#12290;&#32463;&#36807;&#23454;&#35777;&#21644;&#29702;&#35770;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#20339;&#24615;&#33021;&#30340;&#28151;&#21512;&#26041;&#27861;&#65292;&#33021;&#22815;&#24212;&#29992;&#20110;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2310.07894</link><description>&lt;p&gt;
&#39640;&#25928;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#30340;&#31215;&#20998;&#22120;
&lt;/p&gt;
&lt;p&gt;
Efficient Integrators for Diffusion Generative Models. (arXiv:2310.07894v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07894
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20849;&#36717;&#31215;&#20998;&#22120;&#21644;&#20998;&#35010;&#31215;&#20998;&#22120;&#20004;&#31181;&#26694;&#26550;&#65292;&#29992;&#20110;&#21152;&#36895;&#39044;&#35757;&#32451;&#27169;&#22411;&#20013;&#30340;&#26679;&#26412;&#29983;&#25104;&#12290;&#32463;&#36807;&#23454;&#35777;&#21644;&#29702;&#35770;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#20339;&#24615;&#33021;&#30340;&#28151;&#21512;&#26041;&#27861;&#65292;&#33021;&#22815;&#24212;&#29992;&#20110;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#25512;&#29702;&#26102;&#38388;&#29983;&#25104;&#26679;&#26412;&#36895;&#24230;&#36739;&#24930;&#12290;&#22240;&#27492;&#65292;&#20026;&#26356;&#24191;&#27867;&#30340;&#25193;&#25955;&#27169;&#22411;&#24320;&#21457;&#24555;&#36895;&#30830;&#23450;&#24615;/&#38543;&#26426;&#37319;&#26679;&#30340;&#21407;&#21017;&#24615;&#26694;&#26550;&#26159;&#19968;&#20010;&#26377;&#24076;&#26395;&#30340;&#26041;&#21521;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#20114;&#34917;&#30340;&#21152;&#36895;&#39044;&#35757;&#32451;&#27169;&#22411;&#26679;&#26412;&#29983;&#25104;&#30340;&#26694;&#26550;&#65306;&#20849;&#36717;&#31215;&#20998;&#22120;&#21644;&#20998;&#35010;&#31215;&#20998;&#22120;&#12290;&#20849;&#36717;&#31215;&#20998;&#22120;&#23558;DDIM&#27867;&#21270;&#65292;&#23558;&#21453;&#21521;&#25193;&#25955;&#21160;&#21147;&#23398;&#26144;&#23556;&#21040;&#26356;&#26131;&#20110;&#37319;&#26679;&#30340;&#31354;&#38388;&#12290;&#30456;&#21453;&#65292;&#22522;&#20110;&#20998;&#35010;&#30340;&#31215;&#20998;&#22120;&#65292;&#24120;&#29992;&#20110;&#20998;&#23376;&#21160;&#21147;&#23398;&#65292;&#36890;&#36807;&#24039;&#22937;&#22320;&#22312;&#28041;&#21450;&#25968;&#25454;&#21644;&#36741;&#21161;&#21464;&#37327;&#30340;&#25968;&#20540;&#26356;&#26032;&#20043;&#38388;&#20132;&#26367;&#65292;&#20943;&#23569;&#20102;&#25968;&#20540;&#27169;&#25311;&#35823;&#24046;&#12290;&#32463;&#36807;&#24191;&#27867;&#30340;&#23454;&#35777;&#21644;&#29702;&#35770;&#30740;&#31350;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#22686;&#24378;&#31354;&#38388;&#20013;&#33719;&#24471;&#20102;&#25253;&#21578;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#26368;&#20339;&#24615;&#33021;&#12290;&#25105;&#20204;&#22312;CIFAR-10&#19978;&#24212;&#29992;&#30456;&#31354;&#38388;&#26391;&#20043;&#19975;&#25193;&#25955;[Pandey&#65286;Mandt&#65292;2023]&#65292;&#25105;&#20204;&#30340;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#26679;&#26412;&#29983;&#25104;&#33719;&#24471;&#20102;&#26368;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models suffer from slow sample generation at inference time. Therefore, developing a principled framework for fast deterministic/stochastic sampling for a broader class of diffusion models is a promising direction. We propose two complementary frameworks for accelerating sample generation in pre-trained models: Conjugate Integrators and Splitting Integrators. Conjugate integrators generalize DDIM, mapping the reverse diffusion dynamics to a more amenable space for sampling. In contrast, splitting-based integrators, commonly used in molecular dynamics, reduce the numerical simulation error by cleverly alternating between numerical updates involving the data and auxiliary variables. After extensively studying these methods empirically and theoretically, we present a hybrid method that leads to the best-reported performance for diffusion models in augmented spaces. Applied to Phase Space Langevin Diffusion [Pandey &amp; Mandt, 2023] on CIFAR-10, our deterministic and stochastic samp
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#38750;&#32447;&#24615;&#29305;&#24449;&#23398;&#20064;&#30340;&#29702;&#35770;&#12290;&#36890;&#36807;&#19968;&#27493;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#36807;&#31243;&#20013;&#24341;&#20837;&#19981;&#21516;&#30340;&#22810;&#39033;&#24335;&#29305;&#24449;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#23398;&#20064;&#21040;&#30446;&#26631;&#20989;&#25968;&#30340;&#38750;&#32447;&#24615;&#32452;&#20214;&#65292;&#32780;&#26356;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#21017;&#30001;&#36825;&#20123;&#29305;&#24449;&#25152;&#20915;&#23450;&#12290;</title><link>http://arxiv.org/abs/2310.07891</link><description>&lt;p&gt;
&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#19968;&#27425;&#26799;&#24230;&#19979;&#38477;&#30340;&#38750;&#32447;&#24615;&#29305;&#24449;&#23398;&#20064;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
A Theory of Non-Linear Feature Learning with One Gradient Step in Two-Layer Neural Networks. (arXiv:2310.07891v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07891
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#38750;&#32447;&#24615;&#29305;&#24449;&#23398;&#20064;&#30340;&#29702;&#35770;&#12290;&#36890;&#36807;&#19968;&#27493;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#36807;&#31243;&#20013;&#24341;&#20837;&#19981;&#21516;&#30340;&#22810;&#39033;&#24335;&#29305;&#24449;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#23398;&#20064;&#21040;&#30446;&#26631;&#20989;&#25968;&#30340;&#38750;&#32447;&#24615;&#32452;&#20214;&#65292;&#32780;&#26356;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#21017;&#30001;&#36825;&#20123;&#29305;&#24449;&#25152;&#20915;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#23398;&#20064;&#34987;&#35748;&#20026;&#26159;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25104;&#21151;&#30340;&#22522;&#26412;&#21407;&#22240;&#20043;&#19968;&#12290;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#24050;&#32463;&#20005;&#26684;&#35777;&#26126;&#65292;&#22312;&#20004;&#23618;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#31532;&#19968;&#23618;&#36827;&#34892;&#19968;&#27493;&#26799;&#24230;&#19979;&#38477;&#65292;&#28982;&#21518;&#22312;&#31532;&#20108;&#23618;&#36827;&#34892;&#23725;&#22238;&#24402;&#21487;&#20197;&#23548;&#33268;&#29305;&#24449;&#23398;&#20064;&#65307;&#29305;&#24449;&#30697;&#38453;&#30340;&#35889;&#20013;&#20250;&#20986;&#29616;&#20998;&#31163;&#30340;&#19968;&#32500;&#32452;&#20214;&#65292;&#31216;&#20026;&#8220;spike&#8221;&#12290;&#28982;&#32780;&#65292;&#20351;&#29992;&#22266;&#23450;&#26799;&#24230;&#19979;&#38477;&#27493;&#38271;&#26102;&#65292;&#36825;&#20010;&#8220;spike&#8221;&#20165;&#25552;&#20379;&#20102;&#30446;&#26631;&#20989;&#25968;&#30340;&#32447;&#24615;&#32452;&#20214;&#30340;&#20449;&#24687;&#65292;&#22240;&#27492;&#23398;&#20064;&#38750;&#32447;&#24615;&#32452;&#20214;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#23398;&#20064;&#29575;&#38543;&#26679;&#26412;&#22823;&#23567;&#22686;&#38271;&#26102;&#65292;&#36825;&#26679;&#30340;&#35757;&#32451;&#23454;&#38469;&#19978;&#24341;&#20837;&#20102;&#22810;&#20010;&#19968;&#32500;&#32452;&#20214;&#65292;&#27599;&#20010;&#32452;&#20214;&#23545;&#24212;&#19968;&#20010;&#29305;&#23450;&#30340;&#22810;&#39033;&#24335;&#29305;&#24449;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#26356;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#26497;&#38480;&#22823;&#32500;&#24230;&#21644;&#22823;&#26679;&#26412;&#35757;&#32451;&#21644;&#27979;&#35797;&#35823;&#24046;&#23436;&#20840;&#30001;&#36825;&#20123;&#8220;spike&#8221;&#25152;&#20915;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
Feature learning is thought to be one of the fundamental reasons for the success of deep neural networks. It is rigorously known that in two-layer fully-connected neural networks under certain conditions, one step of gradient descent on the first layer followed by ridge regression on the second layer can lead to feature learning; characterized by the appearance of a separated rank-one component -- spike -- in the spectrum of the feature matrix. However, with a constant gradient descent step size, this spike only carries information from the linear component of the target function and therefore learning non-linear components is impossible. We show that with a learning rate that grows with the sample size, such training in fact introduces multiple rank-one components, each corresponding to a specific polynomial feature. We further prove that the limiting large-dimensional and large sample training and test errors of the updated neural networks are fully characterized by these spikes. By 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#25351;&#25968;&#26426;&#21046;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#24182;&#25552;&#20986;&#20102;Metropolis-Hastings&#31639;&#27861;&#26469;&#20811;&#26381;&#25351;&#25968;&#25628;&#32034;&#31354;&#38388;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#19968;&#23450;&#36793;&#30028;&#26465;&#20214;&#19979;&#33021;&#22815;&#23454;&#29616;&#24378;&#27169;&#22411;&#24674;&#22797;&#24615;&#36136;&#65292;&#24182;&#20855;&#26377;&#22810;&#39033;&#24335;&#28151;&#21512;&#26102;&#38388;&#21644;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2310.07852</link><description>&lt;p&gt;
&#20851;&#20110;&#36890;&#36807;&#25351;&#25968;&#26426;&#21046;&#36827;&#34892;&#39640;&#32500;&#31169;&#26377;&#27169;&#22411;&#36873;&#25321;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Computational Complexity of Private High-dimensional Model Selection via the Exponential Mechanism. (arXiv:2310.07852v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07852
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#25351;&#25968;&#26426;&#21046;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#24182;&#25552;&#20986;&#20102;Metropolis-Hastings&#31639;&#27861;&#26469;&#20811;&#26381;&#25351;&#25968;&#25628;&#32034;&#31354;&#38388;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#19968;&#23450;&#36793;&#30028;&#26465;&#20214;&#19979;&#33021;&#22815;&#23454;&#29616;&#24378;&#27169;&#22411;&#24674;&#22797;&#24615;&#36136;&#65292;&#24182;&#20855;&#26377;&#22810;&#39033;&#24335;&#28151;&#21512;&#26102;&#38388;&#21644;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24046;&#20998;&#38544;&#31169;&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#39640;&#32500;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#24046;&#20998;&#38544;&#31169;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#30340;&#38382;&#39064;&#65292;&#24182;&#30740;&#31350;&#20102;&#20854;&#25928;&#29992;&#20445;&#35777;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#24191;&#20026;&#20154;&#30693;&#30340;&#25351;&#25968;&#26426;&#21046;&#26469;&#36873;&#25321;&#26368;&#20339;&#27169;&#22411;&#65292;&#24182;&#22312;&#19968;&#23450;&#36793;&#30028;&#26465;&#20214;&#19979;&#65292;&#24314;&#31435;&#20102;&#20854;&#24378;&#27169;&#22411;&#24674;&#22797;&#24615;&#36136;&#12290;&#28982;&#32780;&#65292;&#25351;&#25968;&#26426;&#21046;&#30340;&#25351;&#25968;&#25628;&#32034;&#31354;&#38388;&#23548;&#33268;&#20102;&#20005;&#37325;&#30340;&#35745;&#31639;&#29942;&#39048;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Metropolis-Hastings&#31639;&#27861;&#26469;&#36827;&#34892;&#37319;&#26679;&#27493;&#39588;&#65292;&#24182;&#22312;&#38382;&#39064;&#21442;&#25968;$n$&#12289;$p$&#21644;$s$&#20013;&#24314;&#31435;&#20102;&#20854;&#21040;&#31283;&#24577;&#20998;&#24067;&#30340;&#22810;&#39033;&#24335;&#28151;&#21512;&#26102;&#38388;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21033;&#29992;&#20854;&#28151;&#21512;&#24615;&#36136;&#24314;&#31435;&#20102;Metropolis-Hastings&#38543;&#26426;&#34892;&#36208;&#30340;&#26368;&#32456;&#20272;&#35745;&#30340;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#24615;&#36136;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#19968;&#20123;&#35828;&#26126;&#24615;&#27169;&#25311;&#65292;&#21360;&#35777;&#20102;&#25105;&#20204;&#20027;&#35201;&#32467;&#26524;&#30340;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of model selection in a high-dimensional sparse linear regression model under the differential privacy framework. In particular, we consider the problem of differentially private best subset selection and study its utility guarantee. We adopt the well-known exponential mechanism for selecting the best model, and under a certain margin condition, we establish its strong model recovery property. However, the exponential search space of the exponential mechanism poses a serious computational bottleneck. To overcome this challenge, we propose a Metropolis-Hastings algorithm for the sampling step and establish its polynomial mixing time to its stationary distribution in the problem parameters $n,p$, and $s$. Furthermore, we also establish approximate differential privacy for the final estimates of the Metropolis-Hastings random walk using its mixing property. Finally, we also perform some illustrative simulations that echo the theoretical findings of our main results
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#39046;&#22495;&#20013;&#20174;&#25945;&#24072;&#21040;&#23398;&#29983;&#20998;&#31867;&#22120;&#36827;&#34892;&#30693;&#35782;&#20256;&#36882;&#30340;&#32479;&#35745;&#25928;&#29575;&#65292;&#21457;&#29616;&#29305;&#26435;&#20449;&#24687;&#20250;&#21152;&#36895;&#20256;&#36882;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#25439;&#22833;&#20989;&#25968;&#36798;&#21040;&#20102;&#30693;&#35782;&#20256;&#36882;&#30340;&#22522;&#26412;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2310.07838</link><description>&lt;p&gt;
&#25506;&#32034;&#26377;&#38480;&#39046;&#22495;&#30693;&#35782;&#20256;&#36882;&#30340;&#22522;&#26412;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
Towards the Fundamental Limits of Knowledge Transfer over Finite Domains. (arXiv:2310.07838v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07838
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#39046;&#22495;&#20013;&#20174;&#25945;&#24072;&#21040;&#23398;&#29983;&#20998;&#31867;&#22120;&#36827;&#34892;&#30693;&#35782;&#20256;&#36882;&#30340;&#32479;&#35745;&#25928;&#29575;&#65292;&#21457;&#29616;&#29305;&#26435;&#20449;&#24687;&#20250;&#21152;&#36895;&#20256;&#36882;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#25439;&#22833;&#20989;&#25968;&#36798;&#21040;&#20102;&#30693;&#35782;&#20256;&#36882;&#30340;&#22522;&#26412;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#36890;&#36807;&#20174;&#25945;&#24072;&#21040;&#27010;&#29575;&#21270;&#23398;&#29983;&#20998;&#31867;&#22120;&#30340;n&#20010;&#26679;&#26412;&#36827;&#34892;&#30693;&#35782;&#20256;&#36882;&#30340;&#32479;&#35745;&#25928;&#29575;&#36827;&#34892;&#20102;&#34920;&#24449;&#65292;&#20854;&#20013;&#36755;&#20837;&#31354;&#38388;S&#21644;&#26631;&#31614;A&#20026;&#26377;&#38480;&#22495;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#19977;&#20010;&#28176;&#36827;&#32423;&#21035;&#19978;&#30340;&#29305;&#26435;&#20449;&#24687;&#21487;&#20197;&#21152;&#24555;&#20256;&#36882;&#30340;&#36895;&#24230;&#12290;&#22312;&#31532;&#19968;&#32423;&#21035;&#19978;&#65292;&#21482;&#26377;&#20855;&#26377;&#22256;&#38590;&#26631;&#31614;&#30340;&#26679;&#26412;&#26159;&#24050;&#30693;&#30340;&#65292;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#33021;&#22815;&#36798;&#21040;&#26368;&#23567;&#21270;&#36895;&#29575;sqrt(|S||A|/n)&#12290;&#31532;&#20108;&#32423;&#21035;&#19978;&#65292;&#38500;&#20102;&#24050;&#30693;&#30340;&#22256;&#38590;&#26631;&#31614;&#26679;&#26412;&#22806;&#65292;&#36824;&#26377;&#37319;&#26679;&#26631;&#31614;&#30340;&#25945;&#24072;&#27010;&#29575;&#21487;&#29992;&#65292;&#36825;&#23558;&#25910;&#25947;&#36895;&#24230;&#30340;&#19979;&#30028;&#25552;&#39640;&#21040;|S||A|/n&#12290;&#28982;&#32780;&#65292;&#22312;&#31532;&#20108;&#20010;&#25968;&#25454;&#37319;&#38598;&#21327;&#35758;&#19979;&#65292;&#26368;&#23567;&#21270;&#20132;&#21449;&#29109;&#25439;&#22833;&#30340;&#26420;&#32032;&#36866;&#24212;&#20250;&#23548;&#33268;&#28176;&#36817;&#20559;&#24046;&#30340;&#23398;&#29983;&#12290;&#25105;&#20204;&#20811;&#26381;&#20102;&#36825;&#20010;&#38480;&#21046;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#32463;&#39564;&#21464;&#20307;&#30340;&#24179;&#26041;&#35823;&#24046;&#36923;&#36753;&#25439;&#22833;&#26469;&#23454;&#29616;&#20102;&#22522;&#26412;&#38480;&#21046;&#12290;&#31532;&#19977;&#32423;&#21035;&#36827;&#19968;&#27493;&#36171;&#20104;&#23398;&#29983;&#36719;&#26631;&#31614;&#12290;
&lt;/p&gt;
&lt;p&gt;
We characterize the statistical efficiency of knowledge transfer through $n$ samples from a teacher to a probabilistic student classifier with input space $\mathcal S$ over labels $\mathcal A$. We show that privileged information at three progressive levels accelerates the transfer. At the first level, only samples with hard labels are known, via which the maximum likelihood estimator attains the minimax rate $\sqrt{{|{\mathcal S}||{\mathcal A}|}/{n}}$. The second level has the teacher probabilities of sampled labels available in addition, which turns out to boost the convergence rate lower bound to ${{|{\mathcal S}||{\mathcal A}|}/{n}}$. However, under this second data acquisition protocol, minimizing a naive adaptation of the cross-entropy loss results in an asymptotically biased student. We overcome this limitation and achieve the fundamental limit by using a novel empirical variant of the squared error logit loss. The third level further equips the student with the soft labels (com
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#32454;&#21270;&#20998;&#26512;&#23398;&#20064;&#29575;&#35843;&#24230;&#26469;&#35299;&#20915;&#23454;&#36341;&#20013;&#23398;&#20064;&#29575;&#35843;&#25972;&#19982;&#29702;&#35770;&#30340;&#19981;&#19968;&#33268;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#35266;&#23519;&#21040;&#30340;&#26799;&#24230;&#33539;&#25968;&#36827;&#34892;&#20998;&#26512;&#65292;&#24471;&#21040;&#20102;&#36866;&#24212;&#20110;&#29305;&#23450;&#20219;&#21153;&#30340;&#32454;&#21270;&#35843;&#24230;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25913;&#21892;&#20248;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.07831</link><description>&lt;p&gt;
&#20309;&#26102;&#65292;&#20026;&#20160;&#20040;&#20197;&#21450;&#22810;&#23569;&#65311;&#36890;&#36807;&#32454;&#21270;&#36827;&#34892;&#30340;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#35843;&#24230;
&lt;/p&gt;
&lt;p&gt;
When, Why and How Much? Adaptive Learning Rate Scheduling by Refinement. (arXiv:2310.07831v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07831
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#32454;&#21270;&#20998;&#26512;&#23398;&#20064;&#29575;&#35843;&#24230;&#26469;&#35299;&#20915;&#23454;&#36341;&#20013;&#23398;&#20064;&#29575;&#35843;&#25972;&#19982;&#29702;&#35770;&#30340;&#19981;&#19968;&#33268;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#35266;&#23519;&#21040;&#30340;&#26799;&#24230;&#33539;&#25968;&#36827;&#34892;&#20998;&#26512;&#65292;&#24471;&#21040;&#20102;&#36866;&#24212;&#20110;&#29305;&#23450;&#20219;&#21153;&#30340;&#32454;&#21270;&#35843;&#24230;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25913;&#21892;&#20248;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#36341;&#20013;&#20351;&#29992;&#30340;&#23398;&#20064;&#29575;&#35843;&#24230;&#19982;&#29702;&#35770;&#25512;&#33616;&#30340;&#20960;&#20046;&#23436;&#20840;&#19981;&#21516;&#12290;&#25105;&#20204;&#32553;&#23567;&#20102;&#22823;&#37096;&#20998;&#29702;&#35770;&#19982;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#24182;&#22240;&#27492;&#33021;&#22815;&#25512;&#23548;&#20986;&#26032;&#30340;&#38382;&#39064;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#35843;&#24230;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#25216;&#26415;&#36129;&#29486;&#26159;&#23545;&#24191;&#27867;&#31867;&#21035;&#30340;&#20248;&#21270;&#31639;&#27861;&#65288;&#21253;&#25324;SGD&#65289;&#30340;&#23398;&#20064;&#29575;&#35843;&#24230;&#36827;&#34892;&#32454;&#21270;&#20998;&#26512;&#12290;&#19982;&#22823;&#22810;&#25968;&#21069;&#26399;&#30740;&#31350;&#21482;&#30740;&#31350;&#24179;&#22343;&#36845;&#20195;&#30340;&#25910;&#25947;&#24615;&#19981;&#21516;&#65292;&#25105;&#20204;&#30740;&#31350;&#26368;&#21518;&#19968;&#27425;&#36845;&#20195;&#65292;&#36825;&#26159;&#22823;&#22810;&#25968;&#20154;&#22312;&#23454;&#36341;&#20013;&#20351;&#29992;&#30340;&#12290;&#24403;&#20165;&#32771;&#34385;&#26368;&#22351;&#24773;&#20917;&#20998;&#26512;&#26102;&#65292;&#25105;&#20204;&#30340;&#29702;&#35770;&#39044;&#27979;&#26368;&#20339;&#36873;&#25321;&#26159;&#32447;&#24615;&#34928;&#20943;&#35843;&#24230;&#65306;&#36825;&#26159;&#19968;&#31181;&#23454;&#36341;&#20013;&#24120;&#29992;&#30340;&#36873;&#25321;&#65292;&#20854;&#23558;&#27493;&#38271;&#19982;&#24403;&#21069;&#36845;&#20195;&#27425;&#25968;t&#21644;&#24635;&#27493;&#25968;T&#25104;&#27604;&#20363;&#22320;&#35774;&#32622;&#20026;1 - t/T&#12290;&#20026;&#20102;&#36229;&#36234;&#36825;&#31181;&#26368;&#22351;&#24773;&#20917;&#20998;&#26512;&#65292;&#25105;&#20204;&#20351;&#29992;&#35266;&#23519;&#21040;&#30340;&#26799;&#24230;&#33539;&#25968;&#26469;&#25512;&#23548;&#36866;&#24212;&#20110;&#29305;&#23450;&#20219;&#21153;&#30340;&#32454;&#21270;&#35843;&#24230;&#12290;&#36825;&#20123;&#32454;&#21270;&#35843;&#24230;&#34920;&#29616;&#20986;&#23398;&#20064;&#29575;&#36880;&#28176;&#22686;&#21152;&#21644;&#23398;&#20064;&#29575;&#36805;&#36895;&#36864;&#28779;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning rate schedules used in practice bear little resemblance to those recommended by theory. We close much of this theory/practice gap, and as a consequence are able to derive new problem-adaptive learning rate schedules. Our key technical contribution is a refined analysis of learning rate schedules for a wide class of optimization algorithms (including SGD). In contrast to most prior works that study the convergence of the average iterate, we study the last iterate, which is what most people use in practice. When considering only worst-case analysis, our theory predicts that the best choice is the linear decay schedule: a popular choice in practice that sets the stepsize proportionally to $1 - t/T$, where $t$ is the current iteration and $T$ is the total number of steps. To go beyond this worst-case analysis, we use the observed gradient norms to derive schedules refined for any particular task. These refined schedules exhibit learning rate warm-up and rapid learning rate anneali
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#22312;&#32447;&#24615;$q^\pi$&#21487;&#23454;&#29616;&#30340;MDPs&#21644;&#32447;&#24615;MDPs&#30340;&#24046;&#24322;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#23398;&#20064;&#24573;&#30053;&#26576;&#20123;&#29366;&#24577;&#23558;&#38382;&#39064;&#36716;&#21270;&#20026;&#32447;&#24615;MDP&#12290;</title><link>http://arxiv.org/abs/2310.07811</link><description>&lt;p&gt;
&#22312;&#32447;RL&#22312;&#32447;&#24615;$q^\pi$&#21487;&#23454;&#29616;&#30340;MDPs&#20013;&#21644;&#32447;&#24615;MDPs&#19968;&#26679;&#23481;&#26131;&#65292;&#21482;&#35201;&#20320;&#23398;&#20250;&#24573;&#30053;&#12290; (arXiv:2310.07811v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
Online RL in Linearly $q^\pi$-Realizable MDPs Is as Easy as in Linear MDPs If You Learn What to Ignore. (arXiv:2310.07811v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07811
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#22312;&#32447;&#24615;$q^\pi$&#21487;&#23454;&#29616;&#30340;MDPs&#21644;&#32447;&#24615;MDPs&#30340;&#24046;&#24322;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#23398;&#20064;&#24573;&#30053;&#26576;&#20123;&#29366;&#24577;&#23558;&#38382;&#39064;&#36716;&#21270;&#20026;&#32447;&#24615;MDP&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#22312;&#31163;&#25955;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#20013;&#65292;&#22312;&#32447;&#24615;$q^\pi$&#21487;&#23454;&#29616;&#30340;&#20551;&#35774;&#19979;&#65292;&#20551;&#35774;&#25152;&#26377;&#31574;&#30053;&#30340;&#21160;&#20316;&#20540;&#21487;&#20197;&#34920;&#31034;&#20026;&#29366;&#24577;-&#21160;&#20316;&#29305;&#24449;&#30340;&#32447;&#24615;&#20989;&#25968;&#12290;&#36825;&#20010;&#31867;&#21035;&#34987;&#35748;&#20026;&#27604;&#32447;&#24615;MDPs&#26356;&#19968;&#33324;&#21270;&#65292;&#20854;&#20013;&#36716;&#31227;&#20869;&#26680;&#21644;&#22870;&#21169;&#20989;&#25968;&#34987;&#20551;&#35774;&#20026;&#29305;&#24449;&#21521;&#37327;&#30340;&#32447;&#24615;&#20989;&#25968;&#12290;&#25105;&#20204;&#30340;&#31532;&#19968;&#20010;&#36129;&#29486;&#26159;&#23637;&#31034;&#20102;&#36825;&#20004;&#20010;&#31867;&#21035;&#20043;&#38388;&#30340;&#24046;&#24322;&#26159;&#22312;&#32447;&#24615;$q^\pi$&#21487;&#23454;&#29616;&#30340;MDPs&#20013;&#23384;&#22312;&#19968;&#20123;&#29366;&#24577;&#65292;&#22312;&#36825;&#20123;&#29366;&#24577;&#20013;&#65292;&#23545;&#20110;&#20219;&#20309;&#31574;&#30053;&#65292;&#25152;&#26377;&#30340;&#21160;&#20316;&#20540;&#37117;&#36817;&#20284;&#30456;&#31561;&#65292;&#36890;&#36807;&#36339;&#36807;&#36825;&#20123;&#29366;&#24577;&#24182;&#25353;&#29031;&#20219;&#24847;&#22266;&#23450;&#31574;&#30053;&#22312;&#36825;&#20123;&#29366;&#24577;&#20013;&#36827;&#34892;&#36716;&#25442;&#65292;&#25105;&#20204;&#21487;&#20197;&#23558;&#38382;&#39064;&#36716;&#21270;&#20026;&#32447;&#24615;MDP&#12290;&#22522;&#20110;&#36825;&#20010;&#35266;&#23519;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#31181;&#26032;&#39062;&#65288;&#35745;&#31639;&#25928;&#29575;&#36739;&#20302;&#65289;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#32447;&#24615;$q^\pi$&#21487;&#23454;&#29616;&#30340;MDPs&#20013;&#65292;&#35813;&#31639;&#27861;&#21516;&#26102;&#23398;&#20064;&#20102;&#24212;&#35813;&#36339;&#36807;&#30340;&#29366;&#24577;&#65292;&#24182;&#36816;&#34892;&#21478;&#19968;&#20010;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider online reinforcement learning (RL) in episodic Markov decision processes (MDPs) under the linear $q^\pi$-realizability assumption, where it is assumed that the action-values of all policies can be expressed as linear functions of state-action features. This class is known to be more general than linear MDPs, where the transition kernel and the reward function are assumed to be linear functions of the feature vectors. As our first contribution, we show that the difference between the two classes is the presence of states in linearly $q^\pi$-realizable MDPs where for any policy, all the actions have approximately equal values, and skipping over these states by following an arbitrarily fixed policy in those states transforms the problem to a linear MDP. Based on this observation, we derive a novel (computationally inefficient) learning algorithm for linearly $q^\pi$-realizable MDPs that simultaneously learns what states should be skipped over and runs another learning algorith
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#27491;&#20132;&#30697;&#38453;&#38598;&#21512;&#21021;&#22987;&#21270;&#26435;&#37325;&#24182;&#20351;&#29992;tanh&#28608;&#27963;&#20989;&#25968;&#65292;&#35299;&#20915;&#20102;&#20840;&#36830;&#25509;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#21021;&#22987;&#21270;&#20013;&#20855;&#26377;&#19982;&#28145;&#24230;&#26080;&#20851;&#30340;&#32447;&#24615;&#27874;&#21160;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#21450;&#20854;&#21518;&#20195;&#30340;&#25152;&#26377;&#30456;&#20851;&#20989;&#25968;&#22312;&#36870;&#23485;&#24230;&#30340;&#20027;&#23548;&#38454;&#27573;&#22312;&#28145;&#24230;&#32422;&#20026;20&#30340;&#20301;&#32622;&#39281;&#21644;&#65292;&#32780;&#19981;&#26159;&#19981;&#26029;&#22686;&#38271;&#12290;</title><link>http://arxiv.org/abs/2310.07765</link><description>&lt;p&gt;
&#20855;&#26377;&#27491;&#20132;&#26435;&#37325;&#30340;&#28145;&#24230;&#32593;&#32476;&#20013;&#30340;&#29305;&#24449;&#23398;&#20064;&#19982;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Feature Learning and Generalization in Deep Networks with Orthogonal Weights. (arXiv:2310.07765v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07765
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#27491;&#20132;&#30697;&#38453;&#38598;&#21512;&#21021;&#22987;&#21270;&#26435;&#37325;&#24182;&#20351;&#29992;tanh&#28608;&#27963;&#20989;&#25968;&#65292;&#35299;&#20915;&#20102;&#20840;&#36830;&#25509;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#21021;&#22987;&#21270;&#20013;&#20855;&#26377;&#19982;&#28145;&#24230;&#26080;&#20851;&#30340;&#32447;&#24615;&#27874;&#21160;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#21450;&#20854;&#21518;&#20195;&#30340;&#25152;&#26377;&#30456;&#20851;&#20989;&#25968;&#22312;&#36870;&#23485;&#24230;&#30340;&#20027;&#23548;&#38454;&#27573;&#22312;&#28145;&#24230;&#32422;&#20026;20&#30340;&#20301;&#32622;&#39281;&#21644;&#65292;&#32780;&#19981;&#26159;&#19981;&#26029;&#22686;&#38271;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#20174;&#27491;&#20132;&#30697;&#38453;&#38598;&#21512;&#21021;&#22987;&#21270;&#30340;&#26435;&#37325;&#21644;tanh&#28608;&#27963;&#20989;&#25968;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20840;&#36830;&#25509;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#21021;&#22987;&#21270;&#26102;&#20855;&#26377;&#19982;&#23485;&#24230;&#26080;&#20851;&#30340;&#21069;&#28608;&#27963;&#27874;&#21160;&#65292;&#36825;&#26159;&#36890;&#36807;&#35745;&#31639;&#35777;&#26126;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#21021;&#22987;&#21270;&#26102;&#65292;&#28041;&#21450;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#21450;&#20854;&#21518;&#20195;&#30340;&#25152;&#26377;&#30456;&#20851;&#20989;&#25968;&#22312;&#36870;&#23485;&#24230;&#30340;&#20027;&#23548;&#38454;&#27573;&#39281;&#21644;&#22312;&#28145;&#24230;&#32422;&#20026;20&#30340;&#20301;&#32622;&#65292;&#32780;&#19981;&#26159;&#20687;&#39640;&#26031;&#21021;&#22987;&#21270;&#30340;&#24773;&#20917;&#37027;&#26679;&#19981;&#26029;&#22686;&#38271;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fully-connected deep neural networks with weights initialized from independent Gaussian distributions can be tuned to criticality, which prevents the exponential growth or decay of signals propagating through the network. However, such networks still exhibit fluctuations that grow linearly with the depth of the network, which may impair the training of networks with width comparable to depth. We show analytically that rectangular networks with tanh activations and weights initialized from the ensemble of orthogonal matrices have corresponding preactivation fluctuations which are independent of depth, to leading order in inverse width. Moreover, we demonstrate numerically that, at initialization, all correlators involving the neural tangent kernel (NTK) and its descendants at leading order in inverse width -- which govern the evolution of observables during training -- saturate at a depth of $\sim 20$, rather than growing without bound as in the case of Gaussian initializations. We spec
&lt;/p&gt;</description></item><item><title>NECO&#26159;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#22349;&#22604;&#30340;&#26032;&#39062;&#30340;&#36229;&#20986;&#20998;&#24067;&#26816;&#27979;&#26041;&#27861;&#65292;&#21033;&#29992;&#20960;&#20309;&#23646;&#24615;&#21644;&#20027;&#25104;&#20998;&#31354;&#38388;&#35782;&#21035;OOD&#25968;&#25454;&#65292;&#22312;&#23567;&#35268;&#27169;&#21644;&#22823;&#35268;&#27169;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.06823</link><description>&lt;p&gt;
NECO: &#22522;&#20110;&#31070;&#32463;&#22349;&#22604;&#30340;&#36229;&#20986;&#20998;&#24067;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
NECO: NEural Collapse Based Out-of-distribution detection. (arXiv:2310.06823v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06823
&lt;/p&gt;
&lt;p&gt;
NECO&#26159;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#22349;&#22604;&#30340;&#26032;&#39062;&#30340;&#36229;&#20986;&#20998;&#24067;&#26816;&#27979;&#26041;&#27861;&#65292;&#21033;&#29992;&#20960;&#20309;&#23646;&#24615;&#21644;&#20027;&#25104;&#20998;&#31354;&#38388;&#35782;&#21035;OOD&#25968;&#25454;&#65292;&#22312;&#23567;&#35268;&#27169;&#21644;&#22823;&#35268;&#27169;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#27169;&#22411;&#36807;&#20110;&#33258;&#20449;&#24182;&#19988;&#27809;&#26377;&#24847;&#35782;&#21040;&#20854;&#35748;&#35782;&#35770;&#38480;&#21046;&#65292;&#26816;&#27979;&#36229;&#20986;&#20998;&#24067;&#65288;OOD&#65289;&#25968;&#25454;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#12290;&#25105;&#20204;&#20551;&#35774;&#8220;&#31070;&#32463;&#22349;&#22604;&#8221;&#65292;&#19968;&#31181;&#24433;&#21709;&#36229;&#20986;&#20998;&#24067;&#25968;&#25454;&#30340;&#29616;&#35937;&#65292;&#20063;&#20250;&#24433;&#21709;&#36229;&#20986;&#20998;&#24067;&#25968;&#25454;&#12290;&#20026;&#20102;&#20174;&#36825;&#31181;&#30456;&#20114;&#20316;&#29992;&#20013;&#21463;&#30410;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;NECO&#65292;&#19968;&#31181;&#29992;&#20110;OOD&#26816;&#27979;&#30340;&#26032;&#39062;&#30340;&#20107;&#21518;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#8220;&#31070;&#32463;&#22349;&#22604;&#8221;&#21644;&#20027;&#25104;&#20998;&#31354;&#38388;&#30340;&#20960;&#20309;&#23646;&#24615;&#26469;&#35782;&#21035;OOD&#25968;&#25454;&#12290;&#25105;&#20204;&#30340;&#22823;&#37327;&#23454;&#39564;&#34920;&#26126;&#65292;NECO&#22312;&#23567;&#35268;&#27169;&#21644;&#22823;&#35268;&#27169;OOD&#26816;&#27979;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#22312;&#19981;&#21516;&#30340;&#32593;&#32476;&#26550;&#26500;&#19978;&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;OOD&#26816;&#27979;&#20013;&#30340;&#26377;&#25928;&#24615;&#25552;&#20379;&#20102;&#29702;&#35770;&#35299;&#37322;&#12290;&#25105;&#20204;&#35745;&#21010;&#22312;&#21311;&#21517;&#26399;&#32467;&#26463;&#21518;&#21457;&#24067;&#20195;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
Detecting out-of-distribution (OOD) data is a critical challenge in machine learning due to model overconfidence, often without awareness of their epistemological limits. We hypothesize that ``neural collapse'', a phenomenon affecting in-distribution data for models trained beyond loss convergence, also influences OOD data. To benefit from this interplay, we introduce NECO, a novel post-hoc method for OOD detection, which leverages the geometric properties of ``neural collapse'' and of principal component spaces to identify OOD data. Our extensive experiments demonstrate that NECO achieves state-of-the-art results on both small and large-scale OOD detection tasks while exhibiting strong generalization capabilities across different network architectures. Furthermore, we provide a theoretical explanation for the effectiveness of our method in OOD detection. We plan to release the code after the anonymity period.
&lt;/p&gt;</description></item><item><title>Lion&#26159;&#36890;&#36807;&#31243;&#24207;&#25628;&#32034;&#21457;&#29616;&#30340;&#26032;&#20248;&#21270;&#22120;&#65292;&#22312;&#35757;&#32451;&#22823;&#22411;AI&#27169;&#22411;&#26041;&#38754;&#34920;&#29616;&#20986;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#65292;&#20855;&#26377;&#26356;&#39640;&#30340;&#20869;&#23384;&#25928;&#29575;&#12290;&#23613;&#31649;&#20854;&#29702;&#35770;&#22522;&#30784;&#19981;&#26126;&#30830;&#65292;&#20294;&#22522;&#20110;&#36830;&#32493;&#26102;&#38388;&#21644;&#31163;&#25955;&#26102;&#38388;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;Lion&#26159;&#19968;&#31181;&#29702;&#35770;&#19978;&#26032;&#39062;&#19988;&#26377;&#21407;&#21017;&#30340;&#26041;&#27861;&#65292;&#21487;&#22312;&#26368;&#23567;&#21270;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#30340;&#21516;&#26102;&#24378;&#21046;&#25191;&#34892;&#36793;&#30028;&#32422;&#26463;&#12290;</title><link>http://arxiv.org/abs/2310.05898</link><description>&lt;p&gt;
&#29422;&#23376;&#31192;&#23494;&#22320;&#35299;&#20915;&#21463;&#38480;&#21046;&#20248;&#21270;&#38382;&#39064;&#65306;&#27491;&#22914;&#26446;&#38597;&#26222;&#35834;&#22827;&#25152;&#39044;&#27979;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lion Secretly Solves Constrained Optimization: As Lyapunov Predicts. (arXiv:2310.05898v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05898
&lt;/p&gt;
&lt;p&gt;
Lion&#26159;&#36890;&#36807;&#31243;&#24207;&#25628;&#32034;&#21457;&#29616;&#30340;&#26032;&#20248;&#21270;&#22120;&#65292;&#22312;&#35757;&#32451;&#22823;&#22411;AI&#27169;&#22411;&#26041;&#38754;&#34920;&#29616;&#20986;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#65292;&#20855;&#26377;&#26356;&#39640;&#30340;&#20869;&#23384;&#25928;&#29575;&#12290;&#23613;&#31649;&#20854;&#29702;&#35770;&#22522;&#30784;&#19981;&#26126;&#30830;&#65292;&#20294;&#22522;&#20110;&#36830;&#32493;&#26102;&#38388;&#21644;&#31163;&#25955;&#26102;&#38388;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;Lion&#26159;&#19968;&#31181;&#29702;&#35770;&#19978;&#26032;&#39062;&#19988;&#26377;&#21407;&#21017;&#30340;&#26041;&#27861;&#65292;&#21487;&#22312;&#26368;&#23567;&#21270;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#30340;&#21516;&#26102;&#24378;&#21046;&#25191;&#34892;&#36793;&#30028;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#31243;&#24207;&#25628;&#32034;&#21457;&#29616;&#30340;&#26032;&#20248;&#21270;&#22120;Lion&#65288;&#36827;&#21270;&#30340;&#31526;&#21495;&#21160;&#37327;&#65289;&#22312;&#35757;&#32451;&#22823;&#22411;AI&#27169;&#22411;&#26041;&#38754;&#26174;&#31034;&#20986;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;&#23427;&#22312;&#35757;&#32451;&#25928;&#26524;&#19978;&#19982;AdamW&#30456;&#24403;&#25110;&#26356;&#22909;&#65292;&#24182;&#20855;&#26377;&#26356;&#39640;&#30340;&#20869;&#23384;&#25928;&#29575;&#12290;&#27491;&#22914;&#25105;&#20204;&#21487;&#20197;&#20174;&#38543;&#26426;&#25628;&#32034;&#31243;&#24207;&#30340;&#32467;&#26524;&#20013;&#26399;&#24453;&#30340;&#65292;Lion&#38598;&#25104;&#20102;&#20960;&#20010;&#29616;&#26377;&#31639;&#27861;&#30340;&#20803;&#32032;&#65292;&#21253;&#25324;&#31526;&#21495;&#21160;&#37327;&#12289;&#29420;&#31435;&#30340;&#26435;&#37325;&#34928;&#20943;&#12289;Polak&#21644;Nesterov&#21160;&#37327;&#65292;&#20294;&#21448;&#19981;&#23646;&#20110;&#20219;&#20309;&#29616;&#26377;&#30340;&#29702;&#35770;&#22522;&#30784;&#20248;&#21270;&#22120;&#31867;&#21035;&#12290;&#22240;&#27492;&#65292;&#23613;&#31649;Lion&#20316;&#20026;&#24191;&#27867;&#20219;&#21153;&#30340;&#36890;&#29992;&#20248;&#21270;&#22120;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#20854;&#29702;&#35770;&#22522;&#30784;&#20173;&#28982;&#19981;&#26126;&#30830;&#12290;&#36825;&#31181;&#32570;&#20047;&#29702;&#35770;&#30340;&#26126;&#30830;&#24615;&#38480;&#21046;&#20102;&#36827;&#19968;&#27493;&#22686;&#24378;&#21644;&#25193;&#23637;Lion&#30340;&#21487;&#33021;&#24615;&#12290;&#26412;&#25991;&#26088;&#22312;&#25581;&#24320;Lion&#30340;&#31070;&#31192;&#38754;&#32433;&#12290;&#22522;&#20110;&#36830;&#32493;&#26102;&#38388;&#21644;&#31163;&#25955;&#26102;&#38388;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;Lion&#26159;&#19968;&#31181;&#29702;&#35770;&#19978;&#26032;&#39062;&#19988;&#26377;&#21407;&#21017;&#30340;&#26041;&#27861;&#65292;&#21487;&#22312;&#26368;&#23567;&#21270;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;$f(x)$&#30340;&#21516;&#26102;&#24378;&#21046;&#25191;&#34892;&#36793;&#30028;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lion (Evolved Sign Momentum), a new optimizer discovered through program search, has shown promising results in training large AI models. It performs comparably or favorably to AdamW but with greater memory efficiency. As we can expect from the results of a random search program, Lion incorporates elements from several existing algorithms, including signed momentum, decoupled weight decay, Polak, and Nesterov momentum, but does not fit into any existing category of theoretically grounded optimizers. Thus, even though Lion appears to perform well as a general-purpose optimizer for a wide range of tasks, its theoretical basis remains uncertain. This lack of theoretical clarity limits opportunities to further enhance and expand Lion's efficacy.  This work aims to demystify Lion. Based on both continuous-time and discrete-time analysis, we demonstrate that Lion is a theoretically novel and principled approach for minimizing a general loss function $f(x)$ while enforcing a bound constraint 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#32858;&#31867;&#30697;&#38453;&#24418;&#24335;&#25968;&#25454;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#20854;&#20013;&#30340;&#24322;&#24120;&#20540;&#12290;</title><link>http://arxiv.org/abs/2310.05288</link><description>&lt;p&gt;
&#24102;&#26377;&#24322;&#24120;&#20540;&#30340;&#19977;&#20803;&#25968;&#25454;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Clustering Three-Way Data with Outliers. (arXiv:2310.05288v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05288
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#32858;&#31867;&#30697;&#38453;&#24418;&#24335;&#25968;&#25454;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#20854;&#20013;&#30340;&#24322;&#24120;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30697;&#38453;&#21464;&#37327;&#20998;&#24067;&#26159;&#27169;&#22411;&#32858;&#31867;&#39046;&#22495;&#30340;&#26368;&#26032;&#28155;&#21152;&#65292;&#20174;&#32780;&#21487;&#20197;&#20998;&#26512;&#20855;&#26377;&#22797;&#26434;&#32467;&#26500;&#65288;&#22914;&#22270;&#20687;&#21644;&#26102;&#38388;&#24207;&#21015;&#65289;&#30340;&#30697;&#38453;&#24418;&#24335;&#25968;&#25454;&#12290;&#30001;&#20110;&#20854;&#26368;&#36817;&#30340;&#20986;&#29616;&#65292;&#20851;&#20110;&#30697;&#38453;&#21464;&#37327;&#25968;&#25454;&#30340;&#25991;&#29486;&#26377;&#38480;&#65292;&#23545;&#20110;&#22788;&#29702;&#36825;&#20123;&#27169;&#22411;&#20013;&#30340;&#24322;&#24120;&#20540;&#30340;&#25991;&#29486;&#26356;&#23569;&#12290;&#26412;&#25991;&#35752;&#35770;&#20102;&#19968;&#31181;&#29992;&#20110;&#32858;&#31867;&#30697;&#38453;&#21464;&#37327;&#27491;&#24577;&#25968;&#25454;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#23376;&#38598;&#23545;&#25968;&#20284;&#28982;&#30340;&#20998;&#24067;&#65292;&#23558;OCLUST&#31639;&#27861;&#25193;&#23637;&#21040;&#30697;&#38453;&#21464;&#37327;&#27491;&#24577;&#25968;&#25454;&#65292;&#24182;&#20351;&#29992;&#36845;&#20195;&#26041;&#27861;&#26816;&#27979;&#21644;&#21098;&#35009;&#24322;&#24120;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Matrix-variate distributions are a recent addition to the model-based clustering field, thereby making it possible to analyze data in matrix form with complex structure such as images and time series. Due to its recent appearance, there is limited literature on matrix-variate data, with even less on dealing with outliers in these models. An approach for clustering matrix-variate normal data with outliers is discussed. The approach, which uses the distribution of subset log-likelihoods, extends the OCLUST algorithm to matrix-variate normal data and uses an iterative approach to detect and trim outliers.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#25554;&#20540;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#38543;&#26426;&#31639;&#27861;&#65292;&#22312;&#32473;&#23450;&#30340;&#25968;&#25454;&#38598;&#21644;&#20004;&#20010;&#31867;&#30340;&#24773;&#20917;&#19979;&#65292;&#33021;&#22815;&#20197;&#24456;&#39640;&#30340;&#27010;&#29575;&#26500;&#24314;&#19968;&#20010;&#25554;&#20540;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#36825;&#20123;&#32467;&#26524;&#19982;&#35757;&#32451;&#25968;&#25454;&#35268;&#27169;&#26080;&#20851;&#12290;</title><link>http://arxiv.org/abs/2310.00327</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#30340;&#35760;&#24518;&#21270;&#65306;&#36229;&#36234;&#26368;&#22351;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
Memorization with neural nets: going beyond the worst case. (arXiv:2310.00327v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00327
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#25554;&#20540;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#38543;&#26426;&#31639;&#27861;&#65292;&#22312;&#32473;&#23450;&#30340;&#25968;&#25454;&#38598;&#21644;&#20004;&#20010;&#31867;&#30340;&#24773;&#20917;&#19979;&#65292;&#33021;&#22815;&#20197;&#24456;&#39640;&#30340;&#27010;&#29575;&#26500;&#24314;&#19968;&#20010;&#25554;&#20540;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#36825;&#20123;&#32467;&#26524;&#19982;&#35757;&#32451;&#25968;&#25454;&#35268;&#27169;&#26080;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#36341;&#20013;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36890;&#24120;&#33021;&#22815;&#36731;&#26494;&#22320;&#25554;&#20540;&#20854;&#35757;&#32451;&#25968;&#25454;&#12290;&#20026;&#20102;&#29702;&#35299;&#36825;&#19968;&#29616;&#35937;&#65292;&#35768;&#22810;&#30740;&#31350;&#37117;&#26088;&#22312;&#37327;&#21270;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#35760;&#24518;&#33021;&#21147;&#65306;&#21363;&#22312;&#20219;&#24847;&#25918;&#32622;&#36825;&#20123;&#28857;&#24182;&#20219;&#24847;&#20998;&#37197;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#65292;&#26550;&#26500;&#33021;&#22815;&#25554;&#20540;&#30340;&#26368;&#22823;&#28857;&#25968;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#23454;&#38469;&#25968;&#25454;&#65292;&#20154;&#20204;&#30452;&#35273;&#22320;&#26399;&#26395;&#23384;&#22312;&#19968;&#31181;&#33391;&#24615;&#32467;&#26500;&#65292;&#20351;&#24471;&#25554;&#20540;&#22312;&#27604;&#35760;&#24518;&#33021;&#21147;&#24314;&#35758;&#30340;&#36739;&#23567;&#32593;&#32476;&#23610;&#23544;&#19978;&#24050;&#32463;&#21457;&#29983;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#37319;&#29992;&#23454;&#20363;&#29305;&#23450;&#30340;&#35266;&#28857;&#26469;&#30740;&#31350;&#25554;&#20540;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#38543;&#26426;&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#32473;&#23450;&#19968;&#20010;&#22266;&#23450;&#30340;&#26377;&#38480;&#25968;&#25454;&#38598;&#21644;&#20004;&#20010;&#31867;&#30340;&#24773;&#20917;&#19979;&#65292;&#20197;&#24456;&#39640;&#30340;&#27010;&#29575;&#26500;&#24314;&#20986;&#19968;&#20010;&#25554;&#20540;&#19977;&#23618;&#31070;&#32463;&#32593;&#32476;&#12290;&#25152;&#38656;&#30340;&#21442;&#25968;&#25968;&#37327;&#19982;&#36825;&#20004;&#20010;&#31867;&#30340;&#20960;&#20309;&#29305;&#24615;&#21450;&#20854;&#30456;&#20114;&#25490;&#21015;&#26377;&#20851;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19982;&#35757;&#32451;&#25968;&#25454;&#35268;&#27169;&#26080;&#20851;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
In practice, deep neural networks are often able to easily interpolate their training data. To understand this phenomenon, many works have aimed to quantify the memorization capacity of a neural network architecture: the largest number of points such that the architecture can interpolate any placement of these points with any assignment of labels. For real-world data, however, one intuitively expects the presence of a benign structure so that interpolation already occurs at a smaller network size than suggested by memorization capacity. In this paper, we investigate interpolation by adopting an instance-specific viewpoint. We introduce a simple randomized algorithm that, given a fixed finite dataset with two classes, with high probability constructs an interpolating three-layer neural network in polynomial time. The required number of parameters is linked to geometric properties of the two classes and their mutual arrangement. As a result, we obtain guarantees that are independent of t
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;$L^1$&#20445;&#30495;&#24230;&#26465;&#20214;&#19979;&#65292;&#20174;&#22122;&#22768;&#35266;&#27979;&#20013;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;$X$&#30340;&#38382;&#39064;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#21807;&#19968;&#33021;&#22815;&#24341;&#20837;&#32447;&#24615;&#26465;&#20214;&#20013;&#20301;&#25968;&#30340;&#20808;&#39564;&#20998;&#24067;&#26159;&#39640;&#26031;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#36824;&#30740;&#31350;&#20102;&#20854;&#20182;$L^p$&#25439;&#22833;&#65292;&#24182;&#35266;&#23519;&#21040;&#23545;&#20110;$p \in [1,2]$&#65292;&#39640;&#26031;&#20998;&#24067;&#26159;&#21807;&#19968;&#24341;&#20837;&#32447;&#24615;&#26368;&#20248;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#30340;&#20808;&#39564;&#20998;&#24067;&#12290;&#25193;&#23637;&#36824;&#28085;&#30422;&#20102;&#29305;&#23450;&#25351;&#25968;&#26063;&#26465;&#20214;&#20998;&#24067;&#30340;&#22122;&#22768;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2309.09129</link><description>&lt;p&gt;
$L^1$&#20272;&#35745;&#65306;&#32447;&#24615;&#20272;&#35745;&#22120;&#30340;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
$L^1$ Estimation: On the Optimality of Linear Estimators. (arXiv:2309.09129v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09129
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;$L^1$&#20445;&#30495;&#24230;&#26465;&#20214;&#19979;&#65292;&#20174;&#22122;&#22768;&#35266;&#27979;&#20013;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;$X$&#30340;&#38382;&#39064;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#21807;&#19968;&#33021;&#22815;&#24341;&#20837;&#32447;&#24615;&#26465;&#20214;&#20013;&#20301;&#25968;&#30340;&#20808;&#39564;&#20998;&#24067;&#26159;&#39640;&#26031;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#36824;&#30740;&#31350;&#20102;&#20854;&#20182;$L^p$&#25439;&#22833;&#65292;&#24182;&#35266;&#23519;&#21040;&#23545;&#20110;$p \in [1,2]$&#65292;&#39640;&#26031;&#20998;&#24067;&#26159;&#21807;&#19968;&#24341;&#20837;&#32447;&#24615;&#26368;&#20248;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#30340;&#20808;&#39564;&#20998;&#24067;&#12290;&#25193;&#23637;&#36824;&#28085;&#30422;&#20102;&#29305;&#23450;&#25351;&#25968;&#26063;&#26465;&#20214;&#20998;&#24067;&#30340;&#22122;&#22768;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;$L^1$&#20445;&#30495;&#24230;&#26465;&#20214;&#19979;&#65292;&#32771;&#34385;&#20174;&#22122;&#22768;&#35266;&#27979;$Y=X+Z$&#20013;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;$X$&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;$Z$&#26159;&#26631;&#20934;&#27491;&#24577;&#20998;&#24067;&#12290;&#20247;&#25152;&#21608;&#30693;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#30340;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#26159;&#26465;&#20214;&#20013;&#20301;&#25968;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#22312;&#26465;&#20214;&#20013;&#20301;&#25968;&#20013;&#24341;&#20837;&#32447;&#24615;&#30340;&#21807;&#19968;&#20808;&#39564;&#20998;&#24067;&#26159;&#39640;&#26031;&#20998;&#24067;&#12290;&#21516;&#26102;&#65292;&#36824;&#25552;&#20379;&#20102;&#20854;&#20182;&#20960;&#20010;&#32467;&#26524;&#12290;&#29305;&#21035;&#22320;&#65292;&#35777;&#26126;&#20102;&#22914;&#26524;&#23545;&#20110;&#25152;&#26377;$y$&#65292;&#26465;&#20214;&#20998;&#24067;$P_{X|Y=y}$&#37117;&#26159;&#23545;&#31216;&#30340;&#65292;&#21017;$X$&#24517;&#39035;&#26381;&#20174;&#39640;&#26031;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20854;&#20182;&#30340;$L^p$&#25439;&#22833;&#65292;&#24182;&#35266;&#23519;&#21040;&#20197;&#19979;&#29616;&#35937;&#65306;&#23545;&#20110;$p \in [1,2]$&#65292;&#39640;&#26031;&#20998;&#24067;&#26159;&#21807;&#19968;&#24341;&#20837;&#32447;&#24615;&#26368;&#20248;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#30340;&#20808;&#39564;&#20998;&#24067;&#65292;&#23545;&#20110;$p \in (2,\infty)$&#65292;&#26377;&#26080;&#31351;&#22810;&#20010;&#20808;&#39564;&#20998;&#24067;&#21487;&#20197;&#24341;&#20837;&#32447;&#24615;&#24615;&#12290;&#26368;&#21518;&#65292;&#36824;&#25552;&#20379;&#20102;&#25193;&#23637;&#65292;&#20197;&#28085;&#30422;&#23548;&#33268;&#29305;&#23450;&#25351;&#25968;&#26063;&#26465;&#20214;&#20998;&#24067;&#30340;&#22122;&#22768;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consider the problem of estimating a random variable $X$ from noisy observations $Y = X+ Z$, where $Z$ is standard normal, under the $L^1$ fidelity criterion. It is well known that the optimal Bayesian estimator in this setting is the conditional median. This work shows that the only prior distribution on $X$ that induces linearity in the conditional median is Gaussian.  Along the way, several other results are presented. In particular, it is demonstrated that if the conditional distribution $P_{X|Y=y}$ is symmetric for all $y$, then $X$ must follow a Gaussian distribution. Additionally, we consider other $L^p$ losses and observe the following phenomenon: for $p \in [1,2]$, Gaussian is the only prior distribution that induces a linear optimal Bayesian estimator, and for $p \in (2,\infty)$, infinitely many prior distributions on $X$ can induce linearity. Finally, extensions are provided to encompass noise models leading to conditional distributions from certain exponential families.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#35299;&#20915;&#27491;&#21017;&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;$\ell_1$&#27491;&#21017;&#21270;&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#21644;&#19968;&#20123;&#28385;&#36275;&#20808;&#20915;&#26465;&#20214;&#30340;&#38750;&#20984;&#24809;&#32602;&#27491;&#21017;&#21270;&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#12290;&#32463;&#39564;&#23454;&#39564;&#34920;&#26126;&#65292;&#36825;&#20123;&#31639;&#27861;&#33021;&#22815;&#20197;&#36739;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#26377;&#25928;&#22320;&#36827;&#34892;&#20998;&#31867;&#21644;&#29305;&#24449;&#36873;&#25321;&#12290;</title><link>http://arxiv.org/abs/2309.05925</link><description>&lt;p&gt;
&#20851;&#20110;&#27491;&#21017;&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Regularized Sparse Logistic Regression. (arXiv:2309.05925v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05925
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#35299;&#20915;&#27491;&#21017;&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;$\ell_1$&#27491;&#21017;&#21270;&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#21644;&#19968;&#20123;&#28385;&#36275;&#20808;&#20915;&#26465;&#20214;&#30340;&#38750;&#20984;&#24809;&#32602;&#27491;&#21017;&#21270;&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#12290;&#32463;&#39564;&#23454;&#39564;&#34920;&#26126;&#65292;&#36825;&#20123;&#31639;&#27861;&#33021;&#22815;&#20197;&#36739;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#26377;&#25928;&#22320;&#36827;&#34892;&#20998;&#31867;&#21644;&#29305;&#24449;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#26088;&#22312;&#21516;&#26102;&#36827;&#34892;&#39640;&#32500;&#25968;&#25454;&#30340;&#20998;&#31867;&#21644;&#29305;&#24449;&#36873;&#25321;&#12290;&#34429;&#28982;&#26377;&#35768;&#22810;&#30740;&#31350;&#35299;&#20915;&#20102;$\ell_1$&#27491;&#21017;&#21270;&#36923;&#36753;&#22238;&#24402;&#38382;&#39064;&#65292;&#20294;&#23545;&#20110;&#19982;&#38750;&#20984;&#24809;&#32602;&#30456;&#20851;&#30340;&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#35299;&#20915;&#26041;&#26696;&#24182;&#27809;&#26377;&#31561;&#37327;&#30340;&#25991;&#29486;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#35299;&#20915;$\ell_1$&#27491;&#21017;&#21270;&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#21644;&#19968;&#20123;&#28385;&#36275;&#19968;&#23450;&#20808;&#20915;&#26465;&#20214;&#30340;&#38750;&#20984;&#24809;&#32602;&#27491;&#21017;&#21270;&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#24182;&#37319;&#29992;&#31867;&#20284;&#30340;&#20248;&#21270;&#26694;&#26550;&#12290;&#22312;&#25552;&#20986;&#30340;&#20248;&#21270;&#26694;&#26550;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#19981;&#21516;&#30340;&#32447;&#25628;&#32034;&#20934;&#21017;&#26469;&#20445;&#35777;&#19981;&#21516;&#27491;&#21017;&#21270;&#39033;&#30340;&#33391;&#22909;&#25910;&#25947;&#24615;&#33021;&#12290;&#36890;&#36807;&#23545;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#30340;&#20108;&#20803;&#20998;&#31867;&#20219;&#21153;&#36827;&#34892;&#32463;&#39564;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#33021;&#22815;&#20197;&#36739;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#26377;&#25928;&#22320;&#36827;&#34892;&#20998;&#31867;&#21644;&#29305;&#24449;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse logistic regression aims to perform classification and feature selection simultaneously for high-dimensional data. Although many studies have been done to solve $\ell_1$-regularized logistic regression, there is no equivalently abundant literature about solving sparse logistic regression associated with nonconvex penalties. In this paper, we propose to solve $\ell_1$-regularized sparse logistic regression and some nonconvex penalties-regularized sparse logistic regression, when the nonconvex penalties satisfy some prerequisites, with similar optimization frameworks. In the proposed optimization frameworks, we utilize different line search criteria to guarantee good convergence performance for different regularization terms. Empirical experiments on binary classification tasks with real-world datasets demonstrate our proposed algorithms are capable of performing classification and feature selection effectively with a lower computational cost.
&lt;/p&gt;</description></item><item><title>&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#22312;&#23454;&#29616;&#32479;&#35745;&#20445;&#35777;&#30028;&#38480;&#26102;&#23384;&#22312;&#38480;&#21046;&#21644;&#20445;&#23432;&#24615;&#38382;&#39064;&#65292;&#20294;&#24179;&#28369;&#30340;$f$-&#25955;&#24230;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#21487;&#22312;&#25351;&#25968;&#34928;&#20943;&#29575;&#26041;&#38754;&#23454;&#29616;&#26368;&#32039;&#23494;&#30340;&#32479;&#35745;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.14041</link><description>&lt;p&gt;
&#24179;&#28369;&#30340;$f$-&#25955;&#24230;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65306;&#25351;&#25968;&#29575;&#25928;&#29575;&#21644;&#19981;&#24102;&#22797;&#26434;&#24615;&#30340;&#26657;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
Smoothed $f$-Divergence Distributionally Robust Optimization: Exponential Rate Efficiency and Complexity-Free Calibration. (arXiv:2306.14041v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14041
&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#22312;&#23454;&#29616;&#32479;&#35745;&#20445;&#35777;&#30028;&#38480;&#26102;&#23384;&#22312;&#38480;&#21046;&#21644;&#20445;&#23432;&#24615;&#38382;&#39064;&#65292;&#20294;&#24179;&#28369;&#30340;$f$-&#25955;&#24230;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#21487;&#22312;&#25351;&#25968;&#34928;&#20943;&#29575;&#26041;&#38754;&#23454;&#29616;&#26368;&#32039;&#23494;&#30340;&#32479;&#35745;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#25454;&#39537;&#21160;&#30340;&#20248;&#21270;&#20013;&#65292;&#26679;&#26412;&#24179;&#22343;&#36924;&#36817;&#24050;&#30693;&#23384;&#22312;&#19968;&#20010;&#25152;&#35859;&#30340;&#20248;&#21270;&#32773;&#35781;&#21650;&#65292;&#20250;&#23548;&#33268;&#22312;&#35780;&#20272;&#35299;&#20915;&#26041;&#26696;&#24615;&#33021;&#26102;&#20135;&#29983;&#20048;&#35266;&#20559;&#24046;&#12290;&#21487;&#20197;&#36890;&#36807;&#22312;&#20272;&#35745;&#30340;&#30446;&#26631;&#20540;&#20013;&#22686;&#21152;&#8220;&#20445;&#35777;&#31354;&#38388;&#8221;&#25110;&#36890;&#36807;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#21518;&#32773;&#26159;&#19968;&#31181;&#24555;&#36895;&#22686;&#38271;&#30340;&#26041;&#27861;&#65292;&#22522;&#20110;&#26368;&#22351;&#24773;&#20917;&#20998;&#26512;&#65292;&#20026;&#33719;&#24471;&#30340;&#30446;&#26631;&#20215;&#20540;&#25552;&#20379;&#20102;&#20445;&#25252;&#30028;&#38480;&#12290;&#28982;&#32780;&#65292;&#22312;&#25152;&#26377;&#36825;&#20123;&#29616;&#26377;&#26041;&#27861;&#20013;&#65292;&#23545;&#30495;&#23454;&#35299;&#20915;&#26041;&#26696;&#24615;&#33021;&#30340;&#32479;&#35745;&#20445;&#35777;&#30028;&#38480;&#35201;&#20040;&#38656;&#35201;&#23545;&#30446;&#26631;&#20989;&#25968;&#22797;&#26434;&#24615;&#26377;&#38480;&#21046;&#24615;&#26465;&#20214;&#21644;&#30693;&#35782;&#65292;&#35201;&#20040;&#20250;&#34920;&#29616;&#20986;&#21462;&#20915;&#20110;&#20998;&#24067;&#32500;&#24230;&#30340;&#36807;&#20110;&#20445;&#23432;&#30340;&#36895;&#29575;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#22312;&#36825;&#20123;&#25361;&#25112;&#26041;&#38754;&#65292;&#19968;&#31181;&#29305;&#27530;&#31867;&#22411;&#30340;DRO&#22312;&#29702;&#35770;&#19978;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#20248;&#21183;&#65306;&#23545;&#20110;&#19968;&#22823;&#31867;&#30446;&#26631;&#20989;&#25968;&#65292;&#23427;&#33719;&#24471;&#20102;&#23545;&#30495;&#23454;&#35299;&#30340;&#35299;&#20915;&#26041;&#26696;&#24615;&#33021;&#30340;&#32479;&#35745;&#30028;&#38480;&#65292;&#36825;&#22312;&#25351;&#25968;&#34928;&#20943;&#29575;&#26041;&#38754;&#26159;&#21487;&#33021;&#30340;&#65292;&#23601;&#20854;&#32039;&#32553;&#31243;&#24230;&#32780;&#35328;&#65292;&#35201;&#32039;&#23494;&#24471;&#22810;&#12290;
&lt;/p&gt;
&lt;p&gt;
In data-driven optimization, sample average approximation is known to suffer from the so-called optimizer's curse that causes optimistic bias in evaluating the solution performance. This can be tackled by adding a "margin" to the estimated objective value, or via distributionally robust optimization (DRO), a fast-growing approach based on worst-case analysis, which gives a protective bound on the attained objective value. However, in all these existing approaches, a statistically guaranteed bound on the true solution performance either requires restrictive conditions and knowledge on the objective function complexity, or otherwise exhibits an over-conservative rate that depends on the distribution dimension. We argue that a special type of DRO offers strong theoretical advantages in regard to these challenges: It attains a statistical bound on the true solution performance that is the tightest possible in terms of exponential decay rate, for a wide class of objective functions that not
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#30340;&#21464;&#20998;&#19981;&#24179;&#34913;&#22238;&#24402;&#65288;VIR&#65289;&#27169;&#22411;&#36890;&#36807;&#24341;&#20837;Probabilistic Reweighting&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#24179;&#34913;&#22238;&#24402;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#33258;&#28982;&#20135;&#29983;&#21512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2306.06599</link><description>&lt;p&gt;
&#21464;&#20998;&#19981;&#24179;&#34913;&#22238;&#24402;(Variational Imbalanced Regression)
&lt;/p&gt;
&lt;p&gt;
Variational Imbalanced Regression. (arXiv:2306.06599v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06599
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#30340;&#21464;&#20998;&#19981;&#24179;&#34913;&#22238;&#24402;&#65288;VIR&#65289;&#27169;&#22411;&#36890;&#36807;&#24341;&#20837;Probabilistic Reweighting&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#24179;&#34913;&#22238;&#24402;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#33258;&#28982;&#20135;&#29983;&#21512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#26631;&#31614;&#20998;&#24067;&#19981;&#24179;&#34913;&#26102;&#65292;&#29616;&#26377;&#30340;&#22238;&#24402;&#27169;&#22411;&#24448;&#24448;&#22312;&#20934;&#30830;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26041;&#38754;&#34920;&#29616;&#19981;&#20339;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#29575;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#8212;&#8212;&#21464;&#20998;&#19981;&#24179;&#34913;&#22238;&#24402;&#65288;VIR&#65289;&#65292;&#23427;&#19981;&#20165;&#22312;&#19981;&#24179;&#34913;&#22238;&#24402;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#32780;&#19988;&#33258;&#28982;&#22320;&#20135;&#29983;&#21512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#19982;&#20856;&#22411;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#20551;&#35774;I.I.D.&#34920;&#31034;&#65288;&#25968;&#25454;&#28857;&#30340;&#34920;&#31034;&#19981;&#30452;&#25509;&#21463;&#20854;&#20182;&#25968;&#25454;&#28857;&#30340;&#24433;&#21709;&#65289;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;VIR&#20511;&#29992;&#20855;&#26377;&#31867;&#20284;&#22238;&#24402;&#26631;&#31614;&#30340;&#25968;&#25454;&#26469;&#35745;&#31639;&#28508;&#22312;&#34920;&#31034;&#30340;&#21464;&#20998;&#20998;&#24067;&#65307;&#27492;&#22806;&#65292;&#19981;&#21516;&#20110;&#20135;&#29983;&#28857;&#20272;&#35745;&#30340;&#30830;&#23450;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292; VIR&#39044;&#27979;&#25972;&#20010;&#27491;&#24577;&#21453;-&#20285;&#29595;&#20998;&#24067;&#24182;&#35843;&#33410;&#30456;&#20851;&#32852;&#30340;&#20849;&#36717;&#20998;&#24067;&#65292;&#23545;&#19981;&#24179;&#34913;&#25968;&#25454;&#26045;&#21152;&#27010;&#29575;&#37325;&#26032;&#21152;&#26435;&#65292;&#20174;&#32780;&#25552;&#20379;&#26356;&#22909;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#22312;&#20960;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing regression models tend to fall short in both accuracy and uncertainty estimation when the label distribution is imbalanced. In this paper, we propose a probabilistic deep learning model, dubbed variational imbalanced regression (VIR), which not only performs well in imbalanced regression but naturally produces reasonable uncertainty estimation as a byproduct. Different from typical variational autoencoders assuming I.I.D. representations (a data point's representation is not directly affected by other data points), our VIR borrows data with similar regression labels to compute the latent representation's variational distribution; furthermore, different from deterministic regression models producing point estimates, VIR predicts the entire normal-inverse-gamma distributions and modulates the associated conjugate distributions to impose probabilistic reweighting on the imbalanced data, thereby providing better uncertainty estimation. Experiments in several real-world datasets sh
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#21450;&#20854;&#21464;&#20307;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#28085;&#30422;&#20102;&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#65292;&#20854;&#27867;&#21270;&#30028;&#38480;&#19982;&#36830;&#32493;&#26435;&#37325;&#24046;&#24322;&#22823;&#23567;&#26377;&#20851;&#12290;</title><link>http://arxiv.org/abs/2305.06648</link><description>&lt;p&gt;
&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#19982;&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#30340;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Generalization bounds for neural ordinary differential equations and deep residual networks. (arXiv:2305.06648v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06648
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#21450;&#20854;&#21464;&#20307;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#28085;&#30422;&#20102;&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#65292;&#20854;&#27867;&#21270;&#30028;&#38480;&#19982;&#36830;&#32493;&#26435;&#37325;&#24046;&#24322;&#22823;&#23567;&#26377;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;Neural ODEs&#65289;&#26159;&#19968;&#31867;&#27969;&#34892;&#30340;&#36830;&#32493;&#28145;&#24230;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#20010;&#30001;&#36830;&#32493;&#26102;&#38388;&#21442;&#25968;&#21270;&#30340;ODE&#21450;&#26102;&#21464;&#30340;&#31070;&#32463;ODE&#32452;&#25104;&#30340;&#22823;&#31867;&#12290;&#25105;&#20204;&#36890;&#36807;Lipschitz&#26041;&#27861;&#25512;&#23548;&#20102;&#36825;&#20010;&#31867;&#21035;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#36890;&#36807;&#21033;&#29992;&#31070;&#32463;ODE&#21644;&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#20043;&#38388;&#30340;&#31867;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24471;&#21040;&#20102;&#19968;&#20010;&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#36825;&#20010;&#30028;&#38480;&#19982;&#36830;&#32493;&#26435;&#37325;&#20043;&#38388;&#30340;&#24046;&#24322;&#30340;&#22823;&#23567;&#26377;&#20851;&#12290;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#32467;&#26524;&#28436;&#31034;&#20102;&#36825;&#20010;&#37327;&#26159;&#22914;&#20309;&#24433;&#21709;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural ordinary differential equations (neural ODEs) are a popular family of continuous-depth deep learning models. In this work, we consider a large family of parameterized ODEs with continuous-in-time parameters, which include time-dependent neural ODEs. We derive a generalization bound for this class by a Lipschitz-based argument. By leveraging the analogy between neural ODEs and deep residual networks, our approach yields in particular a generalization bound for a class of deep residual networks. The bound involves the magnitude of the difference between successive weight matrices. We illustrate numerically how this quantity affects the generalization capability of neural networks.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#22312;&#36716;&#31227;&#23398;&#20064;&#19979;&#27169;&#22411;&#36873;&#25321;&#23384;&#22312;&#30340;&#38480;&#21046;&#65292;&#20854;&#36716;&#31227;&#36317;&#31163;&#20250;&#24433;&#21709;&#33258;&#36866;&#24212;&#36895;&#29575;&#65292;&#21487;&#33021;&#23548;&#33268;&#36895;&#29575;&#36739;&#24930;&#12290;</title><link>http://arxiv.org/abs/2305.00152</link><description>&lt;p&gt;
&#36716;&#31227;&#23398;&#20064;&#19979;&#30340;&#27169;&#22411;&#36873;&#25321;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
Limits of Model Selection under Transfer Learning. (arXiv:2305.00152v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00152
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#22312;&#36716;&#31227;&#23398;&#20064;&#19979;&#27169;&#22411;&#36873;&#25321;&#23384;&#22312;&#30340;&#38480;&#21046;&#65292;&#20854;&#36716;&#31227;&#36317;&#31163;&#20250;&#24433;&#21709;&#33258;&#36866;&#24212;&#36895;&#29575;&#65292;&#21487;&#33021;&#23548;&#33268;&#36895;&#29575;&#36739;&#24930;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#65292;&#20851;&#20110;&#36716;&#31227;&#23398;&#20064;&#25110;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#29702;&#35770;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#24050;&#30693;&#20551;&#35774;&#31867;&#25110;&#27169;&#22411;&#30340;&#24773;&#20917;&#65307;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#36890;&#24120;&#28041;&#21450;&#19968;&#23450;&#31243;&#24230;&#30340;&#27169;&#22411;&#36873;&#25321;&#65292;&#36825;&#32463;&#24120;&#20986;&#29616;&#22312;&#36229;&#21442;&#25968;&#35843;&#25972;&#30340;&#24635;&#20307;&#33539;&#30068;&#19979;&#65306;&#20363;&#22914;&#65292;&#25105;&#20204;&#21487;&#20197;&#32771;&#34385;&#35843;&#25972;&#38024;&#23545;&#30446;&#26631;&#20219;&#21153;&#30340;&#27491;&#30830;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#21033;&#29992;&#26469;&#33258;&#30456;&#20851;&#28304;&#20219;&#21153;&#30340;&#25968;&#25454;&#12290;&#38500;&#20102;&#19982;&#27169;&#22411;&#36873;&#25321;&#26377;&#20851;&#30340;&#36817;&#20284;&#19982;&#20272;&#35745;&#35823;&#24046;&#30340;&#36890;&#24120;&#26435;&#34913;&#20043;&#22806;&#65292;&#36825;&#20010;&#38382;&#39064;&#36824;&#24102;&#26469;&#20102;&#26032;&#30340;&#22797;&#26434;&#24230;&#65292;&#21363;&#28304;&#20998;&#24067;&#19982;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#30340;&#36716;&#31227;&#36317;&#31163;&#65292;&#36825;&#20010;&#36317;&#31163;&#38543;&#30528;&#20551;&#35774;&#31867;&#30340;&#36873;&#25321;&#32780;&#21457;&#29983;&#21464;&#21270;&#12290;&#25105;&#20204;&#39318;&#27425;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#37325;&#28857;&#20851;&#27880;&#20998;&#31867;&#38382;&#39064;&#12290;&#29305;&#21035;&#30340;&#65292;&#20998;&#26512;&#25581;&#31034;&#20102;&#19968;&#20123;&#24341;&#20154;&#27880;&#30446;&#30340;&#29616;&#35937;&#65306;&#33258;&#36866;&#24212;&#36895;&#29575;&#65292;&#21363;&#27809;&#26377;&#20998;&#24067;&#24335;&#20449;&#24687;&#26102;&#21487;&#36798;&#21040;&#30340;&#36895;&#29575;&#65292;&#21487;&#20197;&#20219;&#24847;&#24930;&#20110;oracle&#36895;&#29575;&#65292;&#21363;&#22312;&#32473;&#23450;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Theoretical studies on transfer learning or domain adaptation have so far focused on situations with a known hypothesis class or model; however in practice, some amount of model selection is usually involved, often appearing under the umbrella term of hyperparameter-tuning: for example, one may think of the problem of tuning for the right neural network architecture towards a target task, while leveraging data from a related source task.  Now, in addition to the usual tradeoffs on approximation vs estimation errors involved in model selection, this problem brings in a new complexity term, namely, the transfer distance between source and target distributions, which is known to vary with the choice of hypothesis class.  We present a first study of this problem, focusing on classification; in particular, the analysis reveals some remarkable phenomena: adaptive rates, i.e., those achievable with no distributional information, can be arbitrarily slower than oracle rates, i.e., when given kn
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#20248;&#36755;&#36816;&#21644;&#25237;&#24433;&#36861;&#36394;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20415;&#23452;&#12289;&#39640;&#25928;&#22320;&#29983;&#25104;&#26102;&#24577;&#23494;&#24230;&#24314;&#27169;&#65292;&#20854;&#26368;&#20248;&#26144;&#23556;&#19982;&#24658;&#31561;&#26144;&#23556;&#25509;&#36817;&#65292;&#35757;&#32451;&#36807;&#31243;&#39640;&#24230;&#24182;&#34892;&#21270;&#12290;</title><link>http://arxiv.org/abs/2304.09663</link><description>&lt;p&gt;
&#36890;&#36807;&#26368;&#20248;&#36755;&#36816;&#21644;&#25237;&#24433;&#36861;&#36394;&#30340;&#26102;&#21464;&#23494;&#24230;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Generative Modeling of Time-Dependent Densities via Optimal Transport and Projection Pursuit. (arXiv:2304.09663v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09663
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#20248;&#36755;&#36816;&#21644;&#25237;&#24433;&#36861;&#36394;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20415;&#23452;&#12289;&#39640;&#25928;&#22320;&#29983;&#25104;&#26102;&#24577;&#23494;&#24230;&#24314;&#27169;&#65292;&#20854;&#26368;&#20248;&#26144;&#23556;&#19982;&#24658;&#31561;&#26144;&#23556;&#25509;&#36817;&#65292;&#35757;&#32451;&#36807;&#31243;&#39640;&#24230;&#24182;&#34892;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#21040;&#27969;&#34892;&#30340;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#23545;&#20110;&#26102;&#24577;&#23494;&#24230;&#29983;&#25104;&#24314;&#27169;&#25152;&#24102;&#26469;&#30340;&#35745;&#31639;&#22256;&#38590;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20415;&#23452;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#23427;&#38656;&#35201;&#26368;&#23569;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#24182;&#19988;&#21487;&#20197;&#24456;&#22909;&#22320;&#25193;&#23637;&#21040;&#39640;&#32500;&#38382;&#39064;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#25237;&#24433;&#30340;&#26368;&#20248;&#36755;&#36816;&#27714;&#35299;&#22120; [Meng&#31561;&#65292;2019] &#26469;&#36830;&#25509;&#36830;&#32493;&#30340;&#26679;&#26412;&#65292;&#28982;&#21518;&#20351;&#29992;&#20256;&#36755;&#26679;&#26465; [Chewi&#31561;&#65292;2020] &#26469;&#25554;&#20540;&#28436;&#21270;&#30340;&#23494;&#24230;&#12290;&#24403;&#37319;&#26679;&#39057;&#29575;&#36275;&#22815;&#39640;&#26102;&#65292;&#26368;&#20248;&#26144;&#23556;&#25509;&#36817;&#20110;&#24658;&#31561;&#26144;&#23556;&#65292;&#22240;&#27492;&#35745;&#31639;&#25928;&#29575;&#39640;&#12290;&#27492;&#22806;&#65292;&#35757;&#32451;&#36807;&#31243;&#21487;&#20197;&#39640;&#24230;&#24182;&#34892;&#21270;&#65292;&#22240;&#20026;&#25152;&#26377;&#26368;&#20248;&#26144;&#23556;&#26159;&#29420;&#31435;&#30340;&#65292;&#22240;&#27492;&#21487;&#20197;&#21516;&#26102;&#23398;&#20064;&#12290;&#26368;&#21518;&#65292;&#35813;&#26041;&#27861;&#20165;&#22522;&#20110;&#25968;&#20540;&#32447;&#24615;&#20195;&#25968;&#32780;&#19981;&#26159;&#26368;&#23567;&#21270;&#38750;&#20984;&#30446;&#26631;&#20989;&#25968;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#36731;&#26494;&#20998;&#26512;&#21644;&#25511;&#21046;&#31639;&#27861;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#20960;&#20010;&#25968;&#20540;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the computational difficulties incurred by popular deep learning algorithms for the generative modeling of temporal densities, we propose a cheap alternative which requires minimal hyperparameter tuning and scales favorably to high dimensional problems. In particular, we use a projection-based optimal transport solver [Meng et al., 2019] to join successive samples and subsequently use transport splines [Chewi et al., 2020] to interpolate the evolving density. When the sampling frequency is sufficiently high, the optimal maps are close to the identity and are thus computationally efficient to compute. Moreover, the training process is highly parallelizable as all optimal maps are independent and can thus be learned simultaneously. Finally, the approach is based solely on numerical linear algebra rather than minimizing a nonconvex objective function, allowing us to easily analyze and control the algorithm. We present several numerical experiments on both synthetic and real-w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21487;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#27604;&#20363;&#36180;&#29575;&#27169;&#22411; (N$^3$POM) &#29992;&#20110;&#26377;&#24207;&#22238;&#24402;&#65292;&#21487;&#20197;&#23545;&#36830;&#32493;&#21464;&#37327;&#36827;&#34892;&#39044;&#27979;&#65292;&#21516;&#26102;&#20445;&#30041;&#20102;&#21487;&#35299;&#37322;&#24615;&#65292;&#20855;&#26377;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.17823</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#21487;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#30340;&#36830;&#32493;&#22238;&#24212;&#26377;&#24207;&#22238;&#24402;&#38750;&#27604;&#20363;&#36180;&#29575;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
An interpretable neural network-based non-proportional odds model for ordinal regression with continuous response. (arXiv:2303.17823v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17823
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21487;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#27604;&#20363;&#36180;&#29575;&#27169;&#22411; (N$^3$POM) &#29992;&#20110;&#26377;&#24207;&#22238;&#24402;&#65292;&#21487;&#20197;&#23545;&#36830;&#32493;&#21464;&#37327;&#36827;&#34892;&#39044;&#27979;&#65292;&#21516;&#26102;&#20445;&#30041;&#20102;&#21487;&#35299;&#37322;&#24615;&#65292;&#20855;&#26377;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21487;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#27604;&#20363;&#36180;&#29575;&#27169;&#22411;&#65288;N$^3$POM) &#29992;&#20110;&#26377;&#24207;&#22238;&#24402;&#65292;&#20854;&#20013;&#21453;&#24212;&#21464;&#37327;&#19981;&#20165;&#21487;&#20197;&#21462;&#31163;&#25955;&#20540;&#65292;&#20063;&#21487;&#20197;&#21462;&#36830;&#32493;&#20540;&#65292;&#32780;&#22238;&#24402;&#31995;&#25968;&#26681;&#25454;&#39044;&#27979;&#39034;&#24207;&#21453;&#24212;&#20063;&#19981;&#21516;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#30452;&#25509;&#20174;&#31163;&#25955;&#21453;&#24212;&#20272;&#35745;&#32447;&#24615;&#31995;&#25968;&#19981;&#21516;&#65292;&#25105;&#20204;&#35757;&#32451;&#20102;&#19968;&#20010;&#38750;&#32447;&#24615;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#20197;&#21453;&#24212;&#20026;&#36755;&#20837;&#20135;&#29983;&#32447;&#24615;&#31995;&#25968;&#12290;&#30001;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21183;&#65292;N$^3$POM&#21487;&#20197;&#22312;&#20445;&#30041;&#20256;&#32479;&#26377;&#24207;&#22238;&#24402;&#30340;&#21487;&#35299;&#37322;&#24615;&#30340;&#21516;&#26102;&#20855;&#26377;&#28789;&#27963;&#24615;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#20805;&#20998;&#30340;&#26465;&#20214;&#65292;&#20351;&#24471;&#22312;&#25351;&#23450;&#30340;&#29992;&#25143;&#21306;&#22495;&#20869;&#65292;&#39044;&#27979;&#30340;&#26465;&#20214;&#32047;&#31215;&#27010;&#29575;&#65288;CCP&#65289;&#28385;&#36275;&#23616;&#37096;&#21333;&#35843;&#24615;&#32422;&#26463;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#20445;&#25345;&#21333;&#35843;&#24615;&#30340;&#38543;&#26426;&#65288;MPS&#65289;&#31639;&#27861;&#26469;&#20805;&#20998;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes an interpretable neural network-based non-proportional odds model (N$^3$POM) for ordinal regression, where the response variable can take not only discrete but also continuous values, and the regression coefficients vary depending on the predicting ordinal response. In contrast to conventional approaches estimating the linear coefficients of regression directly from the discrete response, we train a non-linear neural network that outputs the linear coefficients by taking the response as its input. By virtue of the neural network, N$^3$POM may have flexibility while preserving the interpretability of the conventional ordinal regression. We show a sufficient condition so that the predicted conditional cumulative probability~(CCP) satisfies the monotonicity constraint locally over a user-specified region in the covariate space; we also provide a monotonicity-preserving stochastic (MPS) algorithm for training the neural network adequately.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#25972;&#30340;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#30340;&#37197;&#26041;&#65292;&#21033;&#29992;&#21487;&#25193;&#23637;&#30340;&#36125;&#21494;&#26031;&#21518;&#39564;&#37319;&#26679;&#22120;&#30340;&#35265;&#35299;&#65292;&#30830;&#20445;&#25910;&#25947;&#21040;&#25152;&#38656;&#30340;&#30446;&#26631;&#20998;&#24067;&#12290;&#22312;&#36825;&#20010;&#26041;&#27861;&#30340;&#22522;&#30784;&#19978;&#65292;&#24341;&#20837;&#20102;&#30456;&#31354;&#38388;Langevin&#25193;&#25955;&#65288;PSLD&#65289;&#65292;&#22312;&#25193;&#23637;&#31354;&#38388;&#20013;&#36827;&#34892;&#22522;&#20110;&#35780;&#20998;&#30340;&#24314;&#27169;&#65292;&#23637;&#29616;&#20986;&#26356;&#20248;&#36136;&#30340;&#26679;&#26412;&#36136;&#37327;&#21644;&#25913;&#36827;&#30340;&#36895;&#24230;-&#36136;&#37327;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2303.01748</link><description>&lt;p&gt;
&#19968;&#31181;&#23436;&#25972;&#30340;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#30340;&#37197;&#26041;
&lt;/p&gt;
&lt;p&gt;
A Complete Recipe for Diffusion Generative Models. (arXiv:2303.01748v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.01748
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#25972;&#30340;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#30340;&#37197;&#26041;&#65292;&#21033;&#29992;&#21487;&#25193;&#23637;&#30340;&#36125;&#21494;&#26031;&#21518;&#39564;&#37319;&#26679;&#22120;&#30340;&#35265;&#35299;&#65292;&#30830;&#20445;&#25910;&#25947;&#21040;&#25152;&#38656;&#30340;&#30446;&#26631;&#20998;&#24067;&#12290;&#22312;&#36825;&#20010;&#26041;&#27861;&#30340;&#22522;&#30784;&#19978;&#65292;&#24341;&#20837;&#20102;&#30456;&#31354;&#38388;Langevin&#25193;&#25955;&#65288;PSLD&#65289;&#65292;&#22312;&#25193;&#23637;&#31354;&#38388;&#20013;&#36827;&#34892;&#22522;&#20110;&#35780;&#20998;&#30340;&#24314;&#27169;&#65292;&#23637;&#29616;&#20986;&#26356;&#20248;&#36136;&#30340;&#26679;&#26412;&#36136;&#37327;&#21644;&#25913;&#36827;&#30340;&#36895;&#24230;-&#36136;&#37327;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#35780;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;SGMs&#65289;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#20986;&#33394;&#30340;&#21512;&#25104;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#21069;&#21521;&#25193;&#25955;&#36807;&#31243;&#30340;&#35774;&#35745;&#39046;&#22495;&#20173;&#28982;&#36739;&#23569;&#24320;&#21457;&#65292;&#24182;&#19988;&#36890;&#24120;&#20381;&#36182;&#29289;&#29702;&#21551;&#21457;&#27861;&#25110;&#31616;&#21270;&#20551;&#35774;&#12290;&#21033;&#29992;&#21487;&#25193;&#23637;&#30340;&#36125;&#21494;&#26031;&#21518;&#39564;&#37319;&#26679;&#22120;&#30340;&#35265;&#35299;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#25972;&#30340;&#37197;&#26041;&#65292;&#29992;&#20110;&#22312;SGMs&#20013;&#21046;&#23450;&#21069;&#21521;&#36807;&#31243;&#65292;&#30830;&#20445;&#25910;&#25947;&#21040;&#25152;&#38656;&#30340;&#30446;&#26631;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25581;&#31034;&#20102;&#20960;&#20010;&#29616;&#26377;&#30340;SGMs&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#25105;&#20204;&#26694;&#26550;&#30340;&#29305;&#23450;&#34920;&#29616;&#24418;&#24335;&#12290;&#22312;&#36825;&#20010;&#26041;&#27861;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#30456;&#31354;&#38388;Langevin&#25193;&#25955;&#65288;PSLD&#65289;&#65292;&#23427;&#20381;&#36182;&#20110;&#22522;&#20110;&#35780;&#20998;&#30340;&#24314;&#27169;&#65292;&#22312;&#30001;&#36741;&#21161;&#21464;&#37327;&#22686;&#24378;&#30340;&#31867;&#20284;&#29289;&#29702;&#30456;&#31354;&#38388;&#30340;&#25193;&#23637;&#31354;&#38388;&#20013;&#36827;&#34892;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#24050;&#24314;&#31435;&#30340;&#22270;&#20687;&#21512;&#25104;&#22522;&#20934;&#19978;&#30340;&#21508;&#31181;&#31454;&#20105;&#26041;&#27861;&#30456;&#27604;&#65292;PSLD&#23637;&#29616;&#20102;&#26356;&#20248;&#36136;&#30340;&#26679;&#26412;&#36136;&#37327;&#21644;&#25913;&#36827;&#30340;&#36895;&#24230;-&#36136;&#37327;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based Generative Models (SGMs) have demonstrated exceptional synthesis outcomes across various tasks. However, the current design landscape of the forward diffusion process remains largely untapped and often relies on physical heuristics or simplifying assumptions. Utilizing insights from the development of scalable Bayesian posterior samplers, we present a complete recipe for formulating forward processes in SGMs, ensuring convergence to the desired target distribution. Our approach reveals that several existing SGMs can be seen as specific manifestations of our framework. Building upon this method, we introduce Phase Space Langevin Diffusion (PSLD), which relies on score-based modeling within an augmented space enriched by auxiliary variables akin to physical phase space. Empirical results exhibit the superior sample quality and improved speed-quality trade-off of PSLD compared to various competing approaches on established image synthesis benchmarks. Remarkably, PSLD achieves 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#21452;&#26679;&#26412;&#26816;&#39564;&#20013;&#21464;&#37327;&#36873;&#25321;&#38382;&#39064;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#26680;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#32479;&#35745;&#37327;&#65292;&#20197;&#26368;&#22823;&#21270;&#26041;&#24046;&#27491;&#21017;&#21270;&#30340;MMD&#32479;&#35745;&#37327;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20854;&#36229;&#32676;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2302.07415</link><description>&lt;p&gt;
&#21464;&#37327;&#36873;&#25321;&#22312;&#26680;&#21452;&#26679;&#26412;&#26816;&#39564;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Variable Selection for Kernel Two-Sample Tests. (arXiv:2302.07415v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07415
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#21452;&#26679;&#26412;&#26816;&#39564;&#20013;&#21464;&#37327;&#36873;&#25321;&#38382;&#39064;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#26680;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#32479;&#35745;&#37327;&#65292;&#20197;&#26368;&#22823;&#21270;&#26041;&#24046;&#27491;&#21017;&#21270;&#30340;MMD&#32479;&#35745;&#37327;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20854;&#36229;&#32676;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#20004;&#26679;&#26412;&#26816;&#39564;&#20013;&#30340;&#21464;&#37327;&#36873;&#25321;&#38382;&#39064;&#65292;&#26088;&#22312;&#36873;&#25321;&#21306;&#20998;&#20004;&#32452;&#26679;&#26412;&#30340;&#26368;&#26377;&#20449;&#24687;&#21464;&#37327;&#12290;&#20026;&#20102;&#35299;&#20915;&#35813;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65288;MMD&#65289;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23547;&#27714;&#19968;&#32452;&#21464;&#37327;&#65292;&#20854;&#39044;&#20808;&#30830;&#23450;&#30340;&#22823;&#23567;&#26368;&#22823;&#21270;&#26041;&#24046;&#27491;&#21017;&#21270;&#30340;MMD&#32479;&#35745;&#37327;&#12290;&#36825;&#31181;&#35745;&#31639;&#24418;&#24335;&#20063;&#23545;&#24212;&#20110;&#22312;&#25991;&#29486;&#20013;&#30740;&#31350;&#30340;&#25511;&#21046;&#31867;&#22411;I&#38169;&#35823;&#30340;&#21516;&#26102;&#26368;&#23567;&#21270;&#24322;&#36136;&#31867;&#22411;II&#38169;&#35823;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#28151;&#21512;&#25972;&#25968;&#32534;&#31243;&#20844;&#24335;&#65292;&#24182;&#25552;&#20379;&#20102;&#32447;&#24615;&#21644;&#20108;&#27425;&#31867;&#22411;&#20869;&#26680;&#20989;&#25968;&#30340;&#31934;&#30830;&#21644;&#36817;&#20284;&#31639;&#27861;&#65292;&#24182;&#20855;&#26377;&#24615;&#33021;&#20445;&#35777;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#30340;&#21331;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the variable selection problem for two-sample tests, aiming to select the most informative variables to distinguish samples from two groups. To solve this problem, we propose a framework based on the kernel maximum mean discrepancy (MMD). Our approach seeks a group of variables with a pre-specified size that maximizes the variance-regularized MMD statistics. This formulation also corresponds to the minimization of asymptotic type-II error while controlling type-I error, as studied in the literature. We present mixed-integer programming formulations and offer exact and approximation algorithms with performance guarantees for linear and quadratic types of kernel functions. Experimental results demonstrate the superior performance of our framework.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26465;&#20214;&#26041;&#27861;&#26469;&#35843;&#21644;&#20219;&#20309;&#31867;&#22411;&#30340;&#39044;&#27979;&#20998;&#24067;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#33258;&#19979;&#32780;&#19978;&#37325;&#35201;&#24615;&#25277;&#26679;&#8221;&#30340;&#39640;&#25928;&#25277;&#26679;&#31639;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#22810;&#20010;&#26102;&#38388;&#23618;&#27425;&#30340;&#23454;&#39564;&#20013;&#26174;&#31034;&#20986;&#19982;&#22522;&#26412;&#27010;&#29575;&#39044;&#27979;&#30456;&#27604;&#30340;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2210.02286</link><description>&lt;p&gt;
&#23454;&#25968;&#20540;&#21644;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#30340;&#39640;&#25928;&#27010;&#29575;&#35843;&#21644;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Efficient probabilistic reconciliation of forecasts for real-valued and count time series. (arXiv:2210.02286v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.02286
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26465;&#20214;&#26041;&#27861;&#26469;&#35843;&#21644;&#20219;&#20309;&#31867;&#22411;&#30340;&#39044;&#27979;&#20998;&#24067;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#33258;&#19979;&#32780;&#19978;&#37325;&#35201;&#24615;&#25277;&#26679;&#8221;&#30340;&#39640;&#25928;&#25277;&#26679;&#31639;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#22810;&#20010;&#26102;&#38388;&#23618;&#27425;&#30340;&#23454;&#39564;&#20013;&#26174;&#31034;&#20986;&#19982;&#22522;&#26412;&#27010;&#29575;&#39044;&#27979;&#30456;&#27604;&#30340;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23618;&#27425;&#26102;&#38388;&#24207;&#21015;&#22312;&#35768;&#22810;&#24212;&#29992;&#39046;&#22495;&#20013;&#24456;&#24120;&#35265;&#12290;&#36825;&#20123;&#26102;&#38388;&#24207;&#21015;&#30340;&#39044;&#27979;&#38656;&#35201;&#26159;&#19968;&#33268;&#30340;&#65292;&#20063;&#23601;&#26159;&#28385;&#36275;&#23618;&#27425;&#32467;&#26500;&#30340;&#32422;&#26463;&#26465;&#20214;&#12290;&#24378;&#21046;&#19968;&#33268;&#24615;&#30340;&#26368;&#27969;&#34892;&#25216;&#26415;&#34987;&#31216;&#20026;&#35843;&#21644;&#65292;&#23427;&#35843;&#25972;&#20102;&#20026;&#27599;&#20010;&#26102;&#38388;&#24207;&#21015;&#35745;&#31639;&#30340;&#22522;&#26412;&#39044;&#27979;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#20851;&#20110;&#27010;&#29575;&#35843;&#21644;&#30340;&#30740;&#31350;&#23384;&#22312;&#20960;&#20010;&#23616;&#38480;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#26465;&#20214;&#26041;&#27861;&#26469;&#35843;&#21644;&#20219;&#20309;&#31867;&#22411;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#33258;&#19979;&#32780;&#19978;&#37325;&#35201;&#24615;&#25277;&#26679;&#8221;&#30340;&#26032;&#31639;&#27861;&#65292;&#26469;&#39640;&#25928;&#22320;&#20174;&#35843;&#21644;&#21518;&#30340;&#20998;&#24067;&#20013;&#36827;&#34892;&#25277;&#26679;&#12290;&#23427;&#21487;&#20197;&#29992;&#20110;&#20219;&#20309;&#22522;&#26412;&#39044;&#27979;&#20998;&#24067;&#65306;&#31163;&#25955;&#30340;&#12289;&#36830;&#32493;&#30340;&#65292;&#25110;&#32773;&#20197;&#26679;&#26412;&#24418;&#24335;&#25552;&#20379;&#30340;&#65292;&#30456;&#23545;&#20110;&#24403;&#21069;&#26041;&#27861;&#65292;&#23427;&#25552;&#20379;&#20102;&#24456;&#22823;&#30340;&#36895;&#24230;&#25552;&#21319;&#12290;&#22312;&#20960;&#20010;&#26102;&#38388;&#23618;&#27425;&#30340;&#23454;&#39564;&#20013;&#65292;&#26174;&#31034;&#20986;&#19982;&#22522;&#26412;&#27010;&#29575;&#39044;&#27979;&#30456;&#27604;&#30340;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hierarchical time series are common in several applied fields. The forecasts for these time series are required to be coherent, that is, to satisfy the constraints given by the hierarchy. The most popular technique to enforce coherence is called reconciliation, which adjusts the base forecasts computed for each time series. However, recent works on probabilistic reconciliation present several limitations. In this paper, we propose a new approach based on conditioning to reconcile any type of forecast distribution. We then introduce a new algorithm, called Bottom-Up Importance Sampling, to efficiently sample from the reconciled distribution. It can be used for any base forecast distribution: discrete, continuous, or in the form of samples, providing a major speedup compared to the current methods. Experiments on several temporal hierarchies show a significant improvement over base probabilistic forecasts.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;AEnbMIMOCQR&#30340;&#26032;&#39062;&#31639;&#27861;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#38598;&#25104;&#30340;&#26041;&#24335;&#65292;&#22312;&#19981;&#38656;&#35201;&#25968;&#25454;&#25286;&#20998;&#30340;&#24773;&#20917;&#19979;&#65292;&#20197;&#20998;&#24067;&#26080;&#20851;&#30340;&#26041;&#24335;&#29983;&#25104;&#22810;&#27493;&#40077;&#22411;&#39044;&#27979;&#21306;&#38388;&#12290;&#35813;&#26041;&#27861;&#32771;&#34385;&#20102;&#24322;&#26041;&#24046;&#24615;&#65292;&#24182;&#23545;&#20998;&#24067;&#36716;&#21464;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#31454;&#20105;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2207.14219</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#22810;&#27493;&#40077;&#22411;&#33258;&#36866;&#24212;&#24322;&#26041;&#24046;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#36890;&#29992;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A general framework for multi-step ahead adaptive conformal heteroscedastic time series forecasting. (arXiv:2207.14219v7 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.14219
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;AEnbMIMOCQR&#30340;&#26032;&#39062;&#31639;&#27861;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#38598;&#25104;&#30340;&#26041;&#24335;&#65292;&#22312;&#19981;&#38656;&#35201;&#25968;&#25454;&#25286;&#20998;&#30340;&#24773;&#20917;&#19979;&#65292;&#20197;&#20998;&#24067;&#26080;&#20851;&#30340;&#26041;&#24335;&#29983;&#25104;&#22810;&#27493;&#40077;&#22411;&#39044;&#27979;&#21306;&#38388;&#12290;&#35813;&#26041;&#27861;&#32771;&#34385;&#20102;&#24322;&#26041;&#24046;&#24615;&#65292;&#24182;&#23545;&#20998;&#24067;&#36716;&#21464;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#31454;&#20105;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;&#26080;&#20851;&#31639;&#27861;&#65292;&#21517;&#20026;&#33258;&#36866;&#24212;&#38598;&#25104;&#25209;&#37327;&#22810;&#36755;&#20837;&#22810;&#36755;&#20986;&#40077;&#22411;&#20998;&#20301;&#25968;&#22238;&#24402;&#65288;AEnbMIMOCQR&#65289;&#65292;&#20351;&#24471;&#39044;&#27979;&#32773;&#33021;&#22815;&#20197;&#20998;&#24067;&#26080;&#20851;&#30340;&#26041;&#24335;&#29983;&#25104;&#22266;&#23450;&#39044;&#35774;&#22833;&#37197;&#29575;&#30340;&#22810;&#27493;&#40077;&#22411;&#39044;&#27979;&#21306;&#38388;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#40077;&#22411;&#39044;&#27979;&#21407;&#29702;&#65292;&#20294;&#19981;&#38656;&#35201;&#25968;&#25454;&#25286;&#20998;&#65292;&#24182;&#19988;&#21363;&#20351;&#22312;&#25968;&#25454;&#19981;&#21487;&#20114;&#25442;&#30340;&#24773;&#20917;&#19979;&#20063;&#33021;&#25552;&#20379;&#25509;&#36817;&#31934;&#30830;&#30340;&#35206;&#30422;&#29575;&#12290;&#27492;&#22806;&#65292;&#25152;&#24471;&#21040;&#30340;&#39044;&#27979;&#21306;&#38388;&#22312;&#39044;&#27979;&#26102;&#38388;&#33539;&#22260;&#20869;&#32463;&#39564;&#35777;&#26126;&#26377;&#25928;&#65292;&#24182;&#19988;&#32771;&#34385;&#20102;&#24322;&#26041;&#24046;&#24615;&#12290;AEnbMIMOCQR&#34987;&#35774;&#35745;&#25104;&#23545;&#20998;&#24067;&#36716;&#21464;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#36825;&#24847;&#21619;&#30528;&#20854;&#39044;&#27979;&#21306;&#38388;&#22312;&#26080;&#38480;&#30340;&#26102;&#38388;&#33539;&#22260;&#20869;&#20445;&#25345;&#21487;&#38752;&#65292;&#32780;&#26080;&#38656;&#37325;&#26032;&#35757;&#32451;&#25110;&#23545;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#36827;&#34892;&#19981;&#20999;&#23454;&#38469;&#30340;&#20005;&#26684;&#20551;&#35774;&#12290;&#36890;&#36807;&#31995;&#32479;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#40077;&#22411;&#39044;&#27979;&#20013;&#20248;&#20110;&#20854;&#20182;&#31454;&#20105;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a novel model-agnostic algorithm called adaptive ensemble batch multi-input multi-output conformalized quantile regression (AEnbMIMOCQR} that enables forecasters to generate multi-step ahead prediction intervals for a fixed pre-specified miscoverage rate in a distribution-free manner. Our method is grounded on conformal prediction principles, however, it does not require data splitting and provides close to exact coverage even when the data is not exchangeable. Moreover, the resulting prediction intervals, besides being empirically valid along the forecast horizon, do not neglect heteroscedasticity. AEnbMIMOCQR is designed to be robust to distribution shifts, which means that its prediction intervals remain reliable over an unlimited period of time, without entailing retraining or imposing unrealistic strict assumptions on the data-generating process. Through methodically experimentation, we demonstrate that our approach outperforms other competitive methods on bo
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#26465;&#20214;&#30340;Sig-Wasserstein GANs&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;WGANs&#19982;&#36335;&#24452;&#29305;&#24449;&#25552;&#21462;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#29992;&#20110;&#35299;&#20915;&#26102;&#38388;&#24207;&#21015;&#29983;&#25104;&#20013;&#30340;&#25361;&#25112;&#12290;&#36335;&#24452;&#30340;&#31614;&#21517;&#20316;&#20026;&#19968;&#31181;&#36890;&#29992;&#25551;&#36848;&#25968;&#25454;&#27969;&#30340;&#32479;&#35745;&#29305;&#24449;&#65292;&#21487;&#20197;&#21051;&#30011;&#26102;&#24207;&#27169;&#22411;&#30340;&#20998;&#24067;&#29305;&#24449;&#12290;</title><link>http://arxiv.org/abs/2006.05421</link><description>&lt;p&gt;
&#26377;&#26465;&#20214;Sig-Wasserstein GANs&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Conditional Sig-Wasserstein GANs for Time Series Generation. (arXiv:2006.05421v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.05421
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#26465;&#20214;&#30340;Sig-Wasserstein GANs&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;WGANs&#19982;&#36335;&#24452;&#29305;&#24449;&#25552;&#21462;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#29992;&#20110;&#35299;&#20915;&#26102;&#38388;&#24207;&#21015;&#29983;&#25104;&#20013;&#30340;&#25361;&#25112;&#12290;&#36335;&#24452;&#30340;&#31614;&#21517;&#20316;&#20026;&#19968;&#31181;&#36890;&#29992;&#25551;&#36848;&#25968;&#25454;&#27969;&#30340;&#32479;&#35745;&#29305;&#24449;&#65292;&#21487;&#20197;&#21051;&#30011;&#26102;&#24207;&#27169;&#22411;&#30340;&#20998;&#24067;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#22312;&#29983;&#25104;&#26679;&#26412;&#26041;&#38754;&#21462;&#24471;&#20102;&#26497;&#22823;&#30340;&#25104;&#21151;&#65292;&#20174;&#30475;&#20284;&#39640;&#32500;&#30340;&#27010;&#29575;&#20998;&#24067;&#20013;&#29983;&#25104;&#26679;&#26412;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#25429;&#25417;&#30001;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#24341;&#36215;&#30340;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#30340;&#26102;&#24207;&#20381;&#36182;&#24615;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#12290;&#27492;&#22806;&#65292;&#38271;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#27969;&#20250;&#26497;&#22823;&#22320;&#22686;&#21152;&#30446;&#26631;&#31354;&#38388;&#30340;&#32500;&#24230;&#65292;&#21487;&#33021;&#20351;&#29983;&#25104;&#24314;&#27169;&#21464;&#24471;&#19981;&#21487;&#34892;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#25361;&#25112;&#65292;&#21463;&#35745;&#37327;&#32463;&#27982;&#23398;&#20013;&#33258;&#22238;&#24402;&#27169;&#22411;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#23545;&#32473;&#23450;&#36807;&#21435;&#20449;&#24687;&#30340;&#26410;&#26469;&#26102;&#38388;&#24207;&#21015;&#30340;&#26465;&#20214;&#20998;&#24067;&#38750;&#24120;&#24863;&#20852;&#36259;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#26465;&#20214;Sig-WGAN&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;Wasserstein-GANs&#65288;WGANs&#65289;&#19982;&#25968;&#23398;&#19978;&#26377;&#21407;&#21017;&#19988;&#39640;&#25928;&#30340;&#36335;&#24452;&#29305;&#24449;&#25552;&#21462;&#25216;&#26415;&#8212;&#8212;&#36335;&#24452;&#30340;&#31614;&#21517;&#30456;&#32467;&#21512;&#12290;&#36335;&#24452;&#30340;&#31614;&#21517;&#26159;&#19968;&#31995;&#21015;&#20998;&#32423;&#32479;&#35745;&#37327;&#65292;&#20026;&#25968;&#25454;&#27969;&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#25551;&#36848;&#65292;&#20854;&#26399;&#26395;&#20540;&#21051;&#30011;&#20102;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#30340;&#20998;&#24067;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative adversarial networks (GANs) have been extremely successful in generating samples, from seemingly high dimensional probability measures. However, these methods struggle to capture the temporal dependence of joint probability distributions induced by time-series data. Furthermore, long time-series data streams hugely increase the dimension of the target space, which may render generative modelling infeasible. To overcome these challenges, motivated by the autoregressive models in econometric, we are interested in the conditional distribution of future time series given the past information. We propose the generic conditional Sig-WGAN framework by integrating Wasserstein-GANs (WGANs) with mathematically principled and efficient path feature extraction called the signature of a path. The signature of a path is a graded sequence of statistics that provides a universal description for a stream of data, and its expected value characterises the law of the time-series model. In parti
&lt;/p&gt;</description></item><item><title>L2P&#26159;&#19968;&#31181;&#21033;&#29992;&#23454;&#20363;&#20043;&#38388;&#25104;&#23545;&#20851;&#31995;&#36827;&#34892;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#37325;&#23614;&#20998;&#24067;&#29305;&#24449;&#30340;&#39044;&#27979;&#20219;&#21153;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;L2P&#22312;&#20934;&#30830;&#24230;&#21644;&#33021;&#21147;&#26041;&#38754;&#20248;&#20110;&#31454;&#20105;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/1908.04628</link><description>&lt;p&gt;
L2P: &#23398;&#20064;&#25918;&#32622;&#29992;&#20110;&#20272;&#35745;&#37325;&#23614;&#20998;&#24067;&#32467;&#26524;
&lt;/p&gt;
&lt;p&gt;
L2P: Learning to Place for Estimating Heavy-Tailed Distributed Outcomes. (arXiv:1908.04628v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1908.04628
&lt;/p&gt;
&lt;p&gt;
L2P&#26159;&#19968;&#31181;&#21033;&#29992;&#23454;&#20363;&#20043;&#38388;&#25104;&#23545;&#20851;&#31995;&#36827;&#34892;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#37325;&#23614;&#20998;&#24067;&#29305;&#24449;&#30340;&#39044;&#27979;&#20219;&#21153;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;L2P&#22312;&#20934;&#30830;&#24230;&#21644;&#33021;&#21147;&#26041;&#38754;&#20248;&#20110;&#31454;&#20105;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#30340;&#39044;&#27979;&#20219;&#21153;&#20855;&#26377;&#20855;&#26377;&#37325;&#23614;&#20998;&#24067;&#29305;&#24449;&#30340;&#32467;&#26524;&#21464;&#37327;&#12290;&#20363;&#22914;&#65292;&#38144;&#21806;&#30340;&#22270;&#20070;&#21103;&#26412;&#65292;&#33402;&#26415;&#21697;&#25293;&#21334;&#20215;&#26684;&#65292;&#20179;&#24211;&#20013;&#21830;&#21697;&#30340;&#38656;&#27714;&#31561;&#12290;&#36890;&#36807;&#23398;&#20064;&#37325;&#23614;&#20998;&#24067;&#65292;"&#22823;&#32780;&#32597;&#35265;"&#30340;&#23454;&#20363;&#65288;&#20363;&#22914;&#65292;&#30021;&#38144;&#20070;&#65289;&#23558;&#20855;&#26377;&#20934;&#30830;&#30340;&#39044;&#27979;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#24182;&#19981;&#19987;&#27880;&#20110;&#23398;&#20064;&#37325;&#23614;&#20998;&#24067;&#65307;&#22240;&#27492;&#65292;&#23427;&#20204;&#24448;&#24448;&#20250;&#23545;&#36825;&#20123;&#23454;&#20363;&#36827;&#34892;&#20005;&#37325;&#20302;&#20272;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#23398;&#20064;&#25918;&#32622;&#65288;L2P&#65289;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#23454;&#20363;&#20043;&#38388;&#30340;&#25104;&#23545;&#20851;&#31995;&#36827;&#34892;&#23398;&#20064;&#12290;&#22312;&#35757;&#32451;&#38454;&#27573;&#65292;L2P&#23398;&#20064;&#19968;&#23545;&#19968;&#20559;&#22909;&#20998;&#31867;&#22120;&#65306;&#23454;&#20363;A&#26159;&#21542;&#22823;&#20110;&#23454;&#20363;B&#65311;&#22312;&#25918;&#32622;&#38454;&#27573;&#65292;L2P&#36890;&#36807;&#23558;&#26032;&#23454;&#20363;&#25918;&#32622;&#22312;&#24050;&#30693;&#23454;&#20363;&#20043;&#38388;&#26469;&#33719;&#24471;&#39044;&#27979;&#32467;&#26524;&#12290;&#26681;&#25454;&#20854;&#25918;&#32622;&#20301;&#32622;&#65292;&#26032;&#23454;&#20363;&#34987;&#20998;&#37197;&#19968;&#20010;&#32467;&#26524;&#21464;&#37327;&#30340;&#20540;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;L2P&#22312;&#20934;&#30830;&#24230;&#21644;&#33021;&#21147;&#26041;&#38754;&#20248;&#20110;&#31454;&#20105;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many real-world prediction tasks have outcome variables that have characteristic heavy-tail distributions. Examples include copies of books sold, auction prices of art pieces, demand for commodities in warehouses, etc. By learning heavy-tailed distributions, "big and rare" instances (e.g., the best-sellers) will have accurate predictions. Most existing approaches are not dedicated to learning heavy-tailed distribution; thus, they heavily under-predict such instances. To tackle this problem, we introduce Learning to Place (L2P), which exploits the pairwise relationships between instances for learning. In its training phase, L2P learns a pairwise preference classifier: is instance A &gt; instance B? In its placing phase, L2P obtains a prediction by placing the new instance among the known instances. Based on its placement, the new instance is then assigned a value for its outcome variable. Experiments on real data show that L2P outperforms competing approaches in terms of accuracy and abili
&lt;/p&gt;</description></item></channel></rss>