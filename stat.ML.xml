<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#36817;&#20284;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#23376;&#31354;&#38388;&#25512;&#29702;&#26469;&#35299;&#20915;&#21322;&#32467;&#26500;&#22238;&#24402;&#27169;&#22411;&#20013;&#35299;&#37322;&#24615;&#19981;&#30830;&#23450;&#24615;&#30340;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#25512;&#26029;&#36755;&#20837;-&#36755;&#20986;&#20851;&#31995;&#21644;&#25429;&#25417;&#22810;&#37325;&#35201;&#32032;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.12950</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#21322;&#32467;&#26500;&#23376;&#31354;&#38388;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Bayesian Semi-structured Subspace Inference. (arXiv:2401.12950v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12950
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#36817;&#20284;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#23376;&#31354;&#38388;&#25512;&#29702;&#26469;&#35299;&#20915;&#21322;&#32467;&#26500;&#22238;&#24402;&#27169;&#22411;&#20013;&#35299;&#37322;&#24615;&#19981;&#30830;&#23450;&#24615;&#30340;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#25512;&#26029;&#36755;&#20837;-&#36755;&#20986;&#20851;&#31995;&#21644;&#25429;&#25417;&#22810;&#37325;&#35201;&#32032;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21322;&#32467;&#26500;&#22238;&#24402;&#27169;&#22411;&#33021;&#22815;&#32852;&#21512;&#24314;&#27169;&#21487;&#35299;&#37322;&#30340;&#32467;&#26500;&#21270;&#29305;&#24449;&#25928;&#24212;&#21644;&#22797;&#26434;&#30340;&#38750;&#32467;&#26500;&#21270;&#29305;&#24449;&#25928;&#24212;&#12290;&#32467;&#26500;&#21270;&#27169;&#22411;&#37096;&#20998;&#21463;&#32479;&#35745;&#27169;&#22411;&#30340;&#21551;&#21457;&#65292;&#21487;&#29992;&#20110;&#25512;&#26029;&#37325;&#35201;&#29305;&#24449;&#30340;&#36755;&#20837;-&#36755;&#20986;&#20851;&#31995;&#12290;&#38750;&#32467;&#26500;&#21270;&#37096;&#20998;&#23450;&#20041;&#20102;&#19968;&#20010;&#20219;&#24847;&#28145;&#24230;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#20174;&#32780;&#25552;&#20379;&#20102;&#36275;&#22815;&#30340;&#28789;&#27963;&#24615;&#65292;&#20197;&#23454;&#29616;&#31454;&#20105;&#24615;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#34429;&#28982;&#36825;&#20123;&#27169;&#22411;&#20063;&#21487;&#20197;&#35299;&#37322;&#38543;&#26426;&#19981;&#30830;&#23450;&#24615;&#65292;&#20294;&#22312;&#35299;&#37322;&#24615;&#19981;&#30830;&#23450;&#24615;&#26041;&#38754;&#20173;&#28982;&#32570;&#20047;&#24037;&#20316;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#23376;&#31354;&#38388;&#25512;&#29702;&#65292;&#38024;&#23545;&#21322;&#32467;&#26500;&#22238;&#24402;&#27169;&#22411;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#36817;&#20284;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#23545;&#32467;&#26500;&#21270;&#25928;&#24212;&#30340;&#23436;&#25972;&#21442;&#25968;&#31354;&#38388;&#21644;&#38750;&#32467;&#26500;&#21270;&#25928;&#24212;&#30340;&#23376;&#31354;&#38388;&#30340;&#32852;&#21512;&#21518;&#39564;&#37319;&#26679;&#30340;&#23376;&#31354;&#38388;&#25512;&#29702;&#12290;&#38500;&#20102;&#36825;&#31181;&#28151;&#21512;&#37319;&#26679;&#26041;&#26696;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36824;&#20801;&#35768;&#23376;&#31354;&#38388;&#30340;&#21487;&#35843;&#22797;&#26434;&#24615;&#65292;&#24182;&#33021;&#25429;&#25417;&#22810;&#37325;&#35201;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;
Semi-structured regression models enable the joint modeling of interpretable structured and complex unstructured feature effects. The structured model part is inspired by statistical models and can be used to infer the input-output relationship for features of particular importance. The complex unstructured part defines an arbitrary deep neural network and thereby provides enough flexibility to achieve competitive prediction performance. While these models can also account for aleatoric uncertainty, there is still a lack of work on accounting for epistemic uncertainty. In this paper, we address this problem by presenting a Bayesian approximation for semi-structured regression models using subspace inference. To this end, we extend subspace inference for joint posterior sampling from a full parameter space for structured effects and a subspace for unstructured effects. Apart from this hybrid sampling scheme, our method allows for tunable complexity of the subspace and can capture multip
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#20915;&#31574;&#29702;&#35770;&#29615;&#22659;&#20013;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22870;&#21169;&#30456;&#20851;&#24615;&#36807;&#28388;&#30340;&#26041;&#27861;&#65292;&#23558;&#29366;&#24577;-&#21160;&#20316;&#20540;&#20989;&#25968;&#30340;&#20272;&#35745;&#38480;&#21046;&#22312;&#31232;&#30095;&#32452;&#20214;&#19978;&#65292;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#19988;&#26679;&#26412;&#22797;&#26434;&#24230;&#20165;&#21462;&#20915;&#20110;&#31232;&#30095;&#32452;&#20214;&#30340;&#22823;&#23567;&#12290;</title><link>http://arxiv.org/abs/2401.12934</link><description>&lt;p&gt;
&#22522;&#20110;&#22870;&#21169;&#30456;&#20851;&#24615;&#36807;&#28388;&#30340;&#32447;&#24615;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Reward-Relevance-Filtered Linear Offline Reinforcement Learning. (arXiv:2401.12934v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12934
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#20915;&#31574;&#29702;&#35770;&#29615;&#22659;&#20013;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22870;&#21169;&#30456;&#20851;&#24615;&#36807;&#28388;&#30340;&#26041;&#27861;&#65292;&#23558;&#29366;&#24577;-&#21160;&#20316;&#20540;&#20989;&#25968;&#30340;&#20272;&#35745;&#38480;&#21046;&#22312;&#31232;&#30095;&#32452;&#20214;&#19978;&#65292;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#19988;&#26679;&#26412;&#22797;&#26434;&#24230;&#20165;&#21462;&#20915;&#20110;&#31232;&#30095;&#32452;&#20214;&#30340;&#22823;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#20915;&#31574;&#29702;&#35770;&#29615;&#22659;&#20013;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65292;&#20854;&#20013;&#20551;&#35774;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20855;&#26377;&#20915;&#31574;&#29702;&#35770;&#31232;&#30095;&#24615;&#32780;&#19981;&#26159;&#20272;&#35745;&#31232;&#30095;&#24615;&#12290;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#32467;&#26500;&#24615;&#38480;&#21046;&#39044;&#35774;&#20102;&#36716;&#31227;&#21487;&#20197;&#20998;&#35299;&#20026;&#19968;&#20010;&#24433;&#21709;&#22870;&#21169;&#30340;&#31232;&#30095;&#32452;&#20214;&#65292;&#24182;&#19988;&#21487;&#33021;&#24433;&#21709;&#19981;&#24433;&#21709;&#22870;&#21169;&#30340;&#20854;&#20182;&#22806;&#29983;&#21160;&#21147;&#23398;&#12290;&#34429;&#28982;&#29992;&#20110;&#20272;&#35745;&#20840;&#29366;&#24577;&#36807;&#28193;&#23646;&#24615;&#30340;&#26368;&#23567;&#21487;&#35843;&#25972;&#38598;&#21512;&#21462;&#20915;&#20110;&#25972;&#20010;&#29366;&#24577;&#65292;&#20294;&#26368;&#20248;&#31574;&#30053;&#65292;&#22240;&#27492;&#29366;&#24577;-&#21160;&#20316;&#20540;&#20989;&#25968;&#21482;&#20381;&#36182;&#20110;&#31232;&#30095;&#32452;&#20214;&#65306;&#25105;&#20204;&#23558;&#20854;&#31216;&#20026;&#22240;&#26524;/&#20915;&#31574;&#35770;&#31232;&#30095;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#20462;&#25913;&#38408;&#20540;&#23725;&#22238;&#24402;&#22312;&#26368;&#23567;&#20108;&#20056;&#31574;&#30053;&#35780;&#20272;&#20013;&#30340;&#24212;&#29992;&#25552;&#20986;&#20102;&#19968;&#31181;&#36807;&#28388;&#22870;&#21169;&#30340;&#26041;&#27861;&#65292;&#23558;&#29366;&#24577;-&#21160;&#20316;&#20540;&#20989;&#25968;&#30340;&#20272;&#35745;&#38480;&#21046;&#22312;&#31232;&#30095;&#32452;&#20214;&#19978;&#12290;&#25105;&#20204;&#20026;&#22870;&#21169;&#36807;&#28388;&#30340;&#32447;&#24615;&#25311;&#21512;Q-&#36845;&#20195;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#20165;&#21462;&#20915;&#20110;&#31232;&#30095;&#32452;&#20214;&#30340;&#22823;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies offline reinforcement learning with linear function approximation in a setting with decision-theoretic, but not estimation sparsity. The structural restrictions of the data-generating process presume that the transitions factor into a sparse component that affects the reward and could affect additional exogenous dynamics that do not affect the reward. Although the minimally sufficient adjustment set for estimation of full-state transition properties depends on the whole state, the optimal policy and therefore state-action value function depends only on the sparse component: we call this causal/decision-theoretic sparsity. We develop a method for reward-filtering the estimation of the state-action value function to the sparse component by a modification of thresholded lasso in least-squares policy evaluation. We provide theoretical guarantees for our reward-filtered linear fitted-Q-iteration, with sample complexity depending only on the size of the sparse component.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#24863;&#30693;&#30340;&#25968;&#25454;&#38598;&#36873;&#25321;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#25968;&#25454;&#38598;&#36873;&#25321;&#35270;&#20026;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#26469;&#35299;&#20915;&#65292;&#24182;&#26126;&#30830;&#22320;&#24314;&#27169;&#20102;&#23398;&#20064;&#36807;&#31243;&#22914;&#20309;&#20351;&#29992;&#35757;&#32451;&#25968;&#25454;&#28857;&#26469;&#39044;&#27979;&#30446;&#26631;&#20219;&#21153;&#12290;&#35813;&#26041;&#27861;&#22312;&#25552;&#39640;&#35821;&#35328;&#27169;&#22411;&#24615;&#33021;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2401.12926</link><description>&lt;p&gt;
DsDm&#65306;&#20855;&#26377;&#25968;&#25454;&#27169;&#22411;&#30340;&#27169;&#22411;&#24863;&#30693;&#25968;&#25454;&#38598;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
DsDm: Model-Aware Dataset Selection with Datamodels. (arXiv:2401.12926v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12926
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#24863;&#30693;&#30340;&#25968;&#25454;&#38598;&#36873;&#25321;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#25968;&#25454;&#38598;&#36873;&#25321;&#35270;&#20026;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#26469;&#35299;&#20915;&#65292;&#24182;&#26126;&#30830;&#22320;&#24314;&#27169;&#20102;&#23398;&#20064;&#36807;&#31243;&#22914;&#20309;&#20351;&#29992;&#35757;&#32451;&#25968;&#25454;&#28857;&#26469;&#39044;&#27979;&#30446;&#26631;&#20219;&#21153;&#12290;&#35813;&#26041;&#27861;&#22312;&#25552;&#39640;&#35821;&#35328;&#27169;&#22411;&#24615;&#33021;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36873;&#25321;&#29992;&#20110;&#35757;&#32451;&#22823;&#35268;&#27169;&#27169;&#22411;&#30340;&#25968;&#25454;&#26102;&#65292;&#26631;&#20934;&#20570;&#27861;&#26159;&#26681;&#25454;&#20154;&#31867;&#23545;&#25968;&#25454;&#36136;&#37327;&#30340;&#35748;&#30693;&#36827;&#34892;&#31579;&#36873;&#12290;&#36825;&#31181;&#31579;&#36873;&#21487;&#20197;&#24471;&#21040;&#30452;&#35266;&#19978;&#33021;&#25552;&#39640;&#27169;&#22411;&#34892;&#20026;&#30340;&#25968;&#25454;&#28857;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#36890;&#24120;&#30456;&#21453;&#30340;&#24773;&#20917;&#21487;&#33021;&#21457;&#29983;&#65306;&#25105;&#20204;&#21457;&#29616;&#26681;&#25454;&#19982;&#8220;&#39640;&#36136;&#37327;&#8221;&#25968;&#25454;&#28304;&#30340;&#30456;&#20284;&#24615;&#36827;&#34892;&#36873;&#25321;&#21487;&#33021;&#19981;&#20250;&#22686;&#21152;&#65288;&#29978;&#33267;&#21487;&#33021;&#21066;&#24369;&#65289;&#19982;&#38543;&#26426;&#36873;&#25321;&#25968;&#25454;&#30456;&#27604;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#24320;&#21457;&#26356;&#22909;&#30340;&#25968;&#25454;&#36873;&#25321;&#26041;&#27861;&#65292;&#25105;&#20204;&#39318;&#20808;&#23558;&#25968;&#25454;&#38598;&#36873;&#25321;&#20316;&#20026;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#26469;&#35299;&#20915;&#65306;&#32473;&#23450;&#30446;&#26631;&#20219;&#21153;&#12289;&#23398;&#20064;&#31639;&#27861;&#21644;&#20505;&#36873;&#25968;&#25454;&#65292;&#36873;&#25321;&#26368;&#22823;&#21270;&#27169;&#22411;&#24615;&#33021;&#30340;&#23376;&#38598;&#12290;&#36825;&#20010;&#26694;&#26550;&#36991;&#20813;&#20102;&#25163;&#21160;&#36873;&#25321;&#25968;&#25454;&#36136;&#37327;&#30340;&#27010;&#24565;&#65292;&#24182;&#26126;&#30830;&#22320;&#24314;&#27169;&#20102;&#23398;&#20064;&#36807;&#31243;&#22914;&#20309;&#20351;&#29992;&#35757;&#32451;&#25968;&#25454;&#28857;&#26469;&#39044;&#27979;&#30446;&#26631;&#20219;&#21153;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;&#35821;&#35328;&#27169;&#22411;&#65288;LM&#65289;&#22312;&#39044;&#20808;&#25351;&#23450;&#30340;&#20219;&#21153;&#21644;&#20197;&#21069;&#19981;&#21253;&#25324;&#30340;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
When selecting data for training large-scale models, standard practice is to filter for examples that match human notions of data quality. Such filtering yields qualitatively clean datapoints that intuitively should improve model behavior. However, in practice the opposite can often happen: we find that selecting according to similarity with "high quality" data sources may not increase (and can even hurt) performance compared to randomly selecting data.  To develop better methods for selecting data, we start by framing dataset selection as an optimization problem that we can directly solve for: given target tasks, a learning algorithm, and candidate data, select the subset that maximizes model performance. This framework thus avoids handpicked notions of data quality, and instead models explicitly how the learning process uses train datapoints to predict on the target tasks. Our resulting method greatly improves language model (LM) performance on both pre-specified tasks and previously
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#20110;&#20351;&#29992;&#22270;&#20687;&#25968;&#25454;&#38598;&#36827;&#34892;&#26862;&#26519;&#28779;&#28798;&#26816;&#27979;&#30340;&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#36827;&#34892;&#20102;&#24615;&#33021;&#20998;&#26512;&#65292;&#24182;&#30740;&#31350;&#20102;&#20851;&#38190;&#22240;&#32032;&#22914;&#25968;&#25454;&#39044;&#22788;&#29702;&#12289;&#29305;&#24449;&#25552;&#21462;&#21644;&#27169;&#22411;&#35757;&#32451;&#12290;&#36825;&#39033;&#30740;&#31350;&#26377;&#21161;&#20110;&#24320;&#21457;&#39640;&#25928;&#30340;&#26862;&#26519;&#28779;&#28798;&#26816;&#27979;&#31995;&#32479;&#12290;</title><link>http://arxiv.org/abs/2401.12924</link><description>&lt;p&gt;
&#23545;&#20110;&#26862;&#26519;&#28779;&#28798;&#26816;&#27979;&#20013;&#20855;&#26377;&#25361;&#25112;&#24615;&#25968;&#25454;&#38598;&#30340;&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#30340;&#24615;&#33021;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Performance Analysis of Support Vector Machine (SVM) on Challenging Datasets for Forest Fire Detection. (arXiv:2401.12924v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12924
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#20110;&#20351;&#29992;&#22270;&#20687;&#25968;&#25454;&#38598;&#36827;&#34892;&#26862;&#26519;&#28779;&#28798;&#26816;&#27979;&#30340;&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#36827;&#34892;&#20102;&#24615;&#33021;&#20998;&#26512;&#65292;&#24182;&#30740;&#31350;&#20102;&#20851;&#38190;&#22240;&#32032;&#22914;&#25968;&#25454;&#39044;&#22788;&#29702;&#12289;&#29305;&#24449;&#25552;&#21462;&#21644;&#27169;&#22411;&#35757;&#32451;&#12290;&#36825;&#39033;&#30740;&#31350;&#26377;&#21161;&#20110;&#24320;&#21457;&#39640;&#25928;&#30340;&#26862;&#26519;&#28779;&#28798;&#26816;&#27979;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#28145;&#20837;&#20998;&#26512;&#20102;&#20351;&#29992;&#22270;&#20687;&#25968;&#25454;&#38598;&#36827;&#34892;&#26862;&#26519;&#28779;&#28798;&#26816;&#27979;&#30340;&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#30340;&#24615;&#33021;&#21644;&#21033;&#29992;&#24773;&#20917;&#12290;&#38543;&#30528;&#26862;&#26519;&#28779;&#28798;&#23545;&#29983;&#24577;&#31995;&#32479;&#21644;&#20154;&#31867;&#23450;&#23621;&#28857;&#30340;&#23041;&#32961;&#26085;&#30410;&#22686;&#21152;&#65292;&#36805;&#36895;&#20934;&#30830;&#30340;&#26816;&#27979;&#31995;&#32479;&#30340;&#38656;&#27714;&#33267;&#20851;&#37325;&#35201;&#12290;SVM&#20197;&#20854;&#24378;&#22823;&#30340;&#20998;&#31867;&#33021;&#21147;&#32780;&#38395;&#21517;&#65292;&#22312;&#22270;&#20687;&#20013;&#35782;&#21035;&#19982;&#28779;&#28798;&#30456;&#20851;&#30340;&#27169;&#24335;&#26041;&#38754;&#34920;&#29616;&#20986;&#29087;&#32451;&#24230;&#12290;&#36890;&#36807;&#22312;&#26631;&#35760;&#25968;&#25454;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;SVM&#33719;&#24471;&#20102;&#35782;&#21035;&#19982;&#28779;&#28798;&#30456;&#20851;&#30340;&#29420;&#29305;&#23646;&#24615;&#30340;&#33021;&#21147;&#65292;&#22914;&#28779;&#28976;&#12289;&#28895;&#38654;&#25110;&#26862;&#26519;&#21306;&#22495;&#35270;&#35273;&#29305;&#24449;&#30340;&#21464;&#21270;&#12290;&#26412;&#25991;&#20840;&#38754;&#30740;&#31350;&#20102;&#20351;&#29992;SVM&#30340;&#21508;&#20010;&#35201;&#32032;&#65292;&#21253;&#25324;&#25968;&#25454;&#39044;&#22788;&#29702;&#12289;&#29305;&#24449;&#25552;&#21462;&#21644;&#27169;&#22411;&#35757;&#32451;&#12290;&#20005;&#26684;&#35780;&#20272;&#20102;&#20934;&#30830;&#24615;&#12289;&#25928;&#29575;&#21644;&#23454;&#38469;&#36866;&#29992;&#24615;&#31561;&#21442;&#25968;&#12290;&#20174;&#36825;&#39033;&#30740;&#31350;&#20013;&#33719;&#24471;&#30340;&#30693;&#35782;&#26377;&#21161;&#20110;&#24320;&#21457;&#39640;&#25928;&#30340;&#26862;&#26519;&#28779;&#28798;&#26816;&#27979;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article delves into the analysis of performance and utilization of Support Vector Machines (SVMs) for the critical task of forest fire detection using image datasets. With the increasing threat of forest fires to ecosystems and human settlements, the need for rapid and accurate detection systems is of utmost importance. SVMs, renowned for their strong classification capabilities, exhibit proficiency in recognizing patterns associated with fire within images. By training on labeled data, SVMs acquire the ability to identify distinctive attributes associated with fire, such as flames, smoke, or alterations in the visual characteristics of the forest area. The document thoroughly examines the use of SVMs, covering crucial elements like data preprocessing, feature extraction, and model training. It rigorously evaluates parameters such as accuracy, efficiency, and practical applicability. The knowledge gained from this study aids in the development of efficient forest fire detection sy
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#26576;&#20123;&#38590;&#20197;&#27169;&#25311;&#24213;&#23618;&#29366;&#24577;&#21464;&#37327;&#30340;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;&#20351;&#29992;&#22810;&#20219;&#21153;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#25928;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.12923</link><description>&lt;p&gt;
&#29992;&#20110;&#35299;&#20915;&#19968;&#20123;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#30340;&#28145;&#24230;&#22810;&#20219;&#21153;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Deep multitask neural networks for solving some stochastic optimal control problems. (arXiv:2401.12923v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12923
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#26576;&#20123;&#38590;&#20197;&#27169;&#25311;&#24213;&#23618;&#29366;&#24577;&#21464;&#37327;&#30340;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;&#20351;&#29992;&#22810;&#20219;&#21153;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#25928;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#29992;&#20110;&#20351;&#29992;&#30456;&#20851;&#30340;&#21453;&#21521;&#21160;&#24577;&#35268;&#21010;&#21407;&#29702;&#35299;&#20915;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#65292;&#36825;&#20123;&#26041;&#27861;&#20381;&#36182;&#20110;&#27169;&#25311;&#24213;&#23618;&#29366;&#24577;&#21464;&#37327;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#22312;&#26576;&#20123;&#38382;&#39064;&#20013;&#65292;&#36825;&#31181;&#27169;&#25311;&#26159;&#19981;&#21487;&#34892;&#30340;&#65292;&#23548;&#33268;&#29366;&#24577;&#21464;&#37327;&#31354;&#38388;&#30340;&#31163;&#25955;&#21270;&#21644;&#38656;&#35201;&#20026;&#27599;&#20010;&#25968;&#25454;&#28857;&#35757;&#32451;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#12290;&#24403;&#22788;&#29702;&#22823;&#30340;&#29366;&#24577;&#21464;&#37327;&#31354;&#38388;&#26102;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#35745;&#31639;&#19978;&#21464;&#24471;&#20302;&#25928;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31867;&#36825;&#31181;&#31867;&#22411;&#30340;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#20351;&#29992;&#22810;&#20219;&#21153;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#25928;&#35299;&#20915;&#26041;&#26696;&#12290;&#20026;&#20102;&#35757;&#32451;&#25105;&#20204;&#30340;&#22810;&#20219;&#21153;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#26696;&#65292;&#22312;&#20219;&#21153;&#20043;&#38388;&#21160;&#24577;&#24179;&#34913;&#23398;&#20064;&#12290;&#36890;&#36807;&#23545;&#30495;&#23454;&#19990;&#30028;&#30340;&#34893;&#29983;&#21697;&#23450;&#20215;&#38382;&#39064;&#36827;&#34892;&#25968;&#20540;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most existing neural network-based approaches for solving stochastic optimal control problems using the associated backward dynamic programming principle rely on the ability to simulate the underlying state variables. However, in some problems, this simulation is infeasible, leading to the discretization of state variable space and the need to train one neural network for each data point. This approach becomes computationally inefficient when dealing with large state variable spaces. In this paper, we consider a class of this type of stochastic optimal control problems and introduce an effective solution employing multitask neural networks. To train our multitask neural network, we introduce a novel scheme that dynamically balances the learning across tasks. Through numerical experiments on real-world derivatives pricing problems, we prove that our method outperforms state-of-the-art approaches.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26377;&#38480;&#25935;&#24863;&#20449;&#24687;&#27844;&#38706;&#30340;&#21435;&#20559;&#32622;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20844;&#24179;&#33410;&#28857;&#20998;&#31867;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20811;&#26381;&#20102;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#22270;&#32467;&#26500;&#20013;&#30340;&#25299;&#25169;&#20381;&#36182;&#38382;&#39064;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#27169;&#22411;&#26080;&#20851;&#30340;&#21435;&#20559;&#32622;&#26694;&#26550;&#65292;&#20197;&#38450;&#27490;&#19979;&#28216;&#35823;&#29992;&#24182;&#25552;&#39640;&#35757;&#32451;&#30340;&#21487;&#38752;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.12824</link><description>&lt;p&gt;
MAPPING: &#20351;&#29992;&#26377;&#38480;&#25935;&#24863;&#20449;&#24687;&#27844;&#38706;&#30340;&#21435;&#20559;&#32622;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20844;&#24179;&#33410;&#28857;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
MAPPING: Debiasing Graph Neural Networks for Fair Node Classification with Limited Sensitive Information Leakage. (arXiv:2401.12824v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12824
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26377;&#38480;&#25935;&#24863;&#20449;&#24687;&#27844;&#38706;&#30340;&#21435;&#20559;&#32622;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20844;&#24179;&#33410;&#28857;&#20998;&#31867;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20811;&#26381;&#20102;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#22270;&#32467;&#26500;&#20013;&#30340;&#25299;&#25169;&#20381;&#36182;&#38382;&#39064;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#27169;&#22411;&#26080;&#20851;&#30340;&#21435;&#20559;&#32622;&#26694;&#26550;&#65292;&#20197;&#38450;&#27490;&#19979;&#28216;&#35823;&#29992;&#24182;&#25552;&#39640;&#35757;&#32451;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22312;&#21508;&#31181;&#22522;&#20110;&#32593;&#32476;&#30340;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#20294;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#32487;&#25215;&#24182;&#36827;&#19968;&#27493;&#21152;&#21095;&#20102;&#21382;&#21490;&#19978;&#30340;&#20559;&#35265;&#21644;&#31038;&#20250;&#21051;&#26495;&#21360;&#35937;&#65292;&#36825;&#20005;&#37325;&#38459;&#30861;&#20102;&#23427;&#20204;&#22312;&#22312;&#32447;&#20020;&#24202;&#35786;&#26029;&#12289;&#37329;&#34701;&#20449;&#36151;&#31561;&#39640;&#39118;&#38505;&#39046;&#22495;&#30340;&#37096;&#32626;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#20844;&#24179;&#24615;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#19978;&#65292;&#24182;&#19981;&#33021;&#31616;&#21333;&#22320;&#22797;&#21046;&#21040;&#20855;&#26377;&#25299;&#25169;&#20381;&#36182;&#30340;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#22270;&#32467;&#26500;&#20013;&#12290;&#29616;&#26377;&#30340;&#20844;&#24179;&#22270;&#23398;&#20064;&#36890;&#24120;&#20559;&#22909;&#20110;&#20351;&#29992;&#25104;&#23545;&#32422;&#26463;&#26469;&#23454;&#29616;&#20844;&#24179;&#24615;&#65292;&#20294;&#26080;&#27861;&#20811;&#26381;&#32500;&#24230;&#38480;&#21046;&#24182;&#23558;&#20854;&#25512;&#24191;&#21040;&#22810;&#20010;&#25935;&#24863;&#23646;&#24615;&#65307;&#27492;&#22806;&#65292;&#22823;&#22810;&#25968;&#30740;&#31350;&#38598;&#20013;&#22312;&#22788;&#29702;&#25216;&#26415;&#19978;&#26469;&#24378;&#21046;&#24182;&#35843;&#25972;&#20844;&#24179;&#24615;&#65292;&#22312;&#39044;&#22788;&#29702;&#38454;&#27573;&#26500;&#24314;&#19968;&#20010;&#27169;&#22411;&#26080;&#20851;&#30340;&#21435;&#20559;&#32622;GNN&#26694;&#26550;&#65292;&#20197;&#38450;&#27490;&#19979;&#28216;&#35823;&#29992;&#24182;&#25552;&#39640;&#35757;&#32451;&#30340;&#21487;&#38752;&#24615;&#22312;&#20808;&#21069;&#30340;&#24037;&#20316;&#20013;&#65292;GNN&#24448;&#24448;&#20542;&#21521;&#20110;&#22686;&#24378;&#20844;&#24179;&#24615;&#25110;&#22686;&#21152;&#39044;&#27979;&#24615;&#33021;&#65292;&#22240;&#27492;&#22312;&#20108;&#32773;&#20043;&#38388;&#36827;&#34892;&#20840;&#38754;&#26435;&#34913;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite remarkable success in diverse web-based applications, Graph Neural Networks(GNNs) inherit and further exacerbate historical discrimination and social stereotypes, which critically hinder their deployments in high-stake domains such as online clinical diagnosis, financial crediting, etc. However, current fairness research that primarily craft on i.i.d data, cannot be trivially replicated to non-i.i.d. graph structures with topological dependence among samples. Existing fair graph learning typically favors pairwise constraints to achieve fairness but fails to cast off dimensional limitations and generalize them into multiple sensitive attributes; besides, most studies focus on in-processing techniques to enforce and calibrate fairness, constructing a model-agnostic debiasing GNN framework at the pre-processing stage to prevent downstream misuses and improve training reliability is still largely under-explored. Furthermore, previous work on GNNs tend to enhance either fairness or 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#29992;&#20110;&#36873;&#25321;&#24615;&#20998;&#31867;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#30446;&#30340;&#26159;&#35774;&#35745;&#19968;&#31181;&#36873;&#25321;&#26426;&#21046;&#26469;&#24179;&#34913;&#34987;&#25298;&#32477;&#30340;&#39044;&#27979;&#27604;&#20363;&#21644;&#25152;&#36873;&#39044;&#27979;&#30340;&#39044;&#27979;&#24615;&#33021;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2401.12708</link><description>&lt;p&gt;
&#29992;&#20110;&#36873;&#25321;&#24615;&#20998;&#31867;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
Deep Neural Network Benchmarks for Selective Classification. (arXiv:2401.12708v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12708
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#29992;&#20110;&#36873;&#25321;&#24615;&#20998;&#31867;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#30446;&#30340;&#26159;&#35774;&#35745;&#19968;&#31181;&#36873;&#25321;&#26426;&#21046;&#26469;&#24179;&#34913;&#34987;&#25298;&#32477;&#30340;&#39044;&#27979;&#27604;&#20363;&#21644;&#25152;&#36873;&#39044;&#27979;&#30340;&#39044;&#27979;&#24615;&#33021;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#35768;&#22810;&#20855;&#26377;&#31038;&#20250;&#25935;&#24863;&#24615;&#30340;&#20219;&#21153;&#20013;&#30340;&#37096;&#32626;&#22686;&#21152;&#65292;&#23545;&#21487;&#38752;&#21644;&#21487;&#20449;&#39044;&#27979;&#30340;&#38656;&#27714;&#20063;&#26085;&#30410;&#22686;&#38271;&#12290;&#23454;&#29616;&#36825;&#20123;&#35201;&#27714;&#30340;&#19968;&#31181;&#26041;&#27861;&#26159;&#20801;&#35768;&#27169;&#22411;&#22312;&#23384;&#22312;&#39640;&#38169;&#35823;&#39118;&#38505;&#26102;&#25918;&#24323;&#36827;&#34892;&#39044;&#27979;&#12290;&#36825;&#38656;&#35201;&#20026;&#27169;&#22411;&#28155;&#21152;&#36873;&#25321;&#26426;&#21046;&#65292;&#35813;&#26426;&#21046;&#36873;&#25321;&#27169;&#22411;&#23558;&#25552;&#20379;&#39044;&#27979;&#30340;&#20363;&#23376;&#12290;&#36873;&#25321;&#24615;&#20998;&#31867;&#26694;&#26550;&#26088;&#22312;&#35774;&#35745;&#19968;&#20010;&#24179;&#34913;&#34987;&#25298;&#32477;&#39044;&#27979;&#27604;&#20363;&#65288;&#21363;&#27169;&#22411;&#19981;&#36827;&#34892;&#39044;&#27979;&#30340;&#20363;&#23376;&#27604;&#20363;&#65289;&#19982;&#22312;&#25152;&#36873;&#39044;&#27979;&#19978;&#30340;&#39044;&#27979;&#24615;&#33021;&#25913;&#36827;&#20043;&#38388;&#30340;&#26426;&#21046;&#12290;&#23384;&#22312;&#22810;&#20010;&#36873;&#25321;&#24615;&#20998;&#31867;&#26694;&#26550;&#65292;&#20854;&#20013;&#22823;&#22810;&#25968;&#20381;&#36182;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#30340;&#23454;&#35777;&#35780;&#20272;&#20173;&#23616;&#38480;&#20110;&#37096;&#20998;&#26041;&#27861;&#21644;&#35774;&#32622;&#20043;&#38388;&#30340;&#27604;&#36739;&#65292;&#32473;&#23454;&#36341;&#32773;&#25552;&#20379;&#20102;&#24456;&#23569;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the increasing deployment of machine learning models in many socially-sensitive tasks, there is a growing demand for reliable and trustworthy predictions. One way to accomplish these requirements is to allow a model to abstain from making a prediction when there is a high risk of making an error. This requires adding a selection mechanism to the model, which selects those examples for which the model will provide a prediction. The selective classification framework aims to design a mechanism that balances the fraction of rejected predictions (i.e., the proportion of examples for which the model does not make a prediction) versus the improvement in predictive performance on the selected predictions. Multiple selective classification frameworks exist, most of which rely on deep neural network architectures. However, the empirical evaluation of the existing approaches is still limited to partial comparisons among methods and settings, providing practitioners with little insight into 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#22522;&#22240;&#34920;&#36798;&#20108;&#20998;&#31867;&#38382;&#39064;&#30340;&#31283;&#20581;&#21152;&#26435;&#20998;&#25968;&#65288;ROWSU&#65289;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#22522;&#22240;&#34920;&#36798;&#25968;&#25454;&#20013;&#39640;&#24230;&#20542;&#26012;&#30340;&#31867;&#21035;&#20998;&#24067;&#23545;&#20998;&#31867;&#31639;&#27861;&#24615;&#33021;&#30340;&#19981;&#21033;&#24433;&#21709;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.12667</link><description>&lt;p&gt;
&#20351;&#29992;&#31283;&#20581;&#21152;&#26435;&#20998;&#25968;&#36827;&#34892;&#39640;&#32500;&#20108;&#20998;&#31867;&#19981;&#24179;&#34913;&#22522;&#22240;&#34920;&#36798;&#25968;&#25454;&#30340;&#29305;&#24449;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Feature Selection via Robust Weighted Score for High Dimensional Binary Class-Imbalanced Gene Expression Data. (arXiv:2401.12667v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12667
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#22522;&#22240;&#34920;&#36798;&#20108;&#20998;&#31867;&#38382;&#39064;&#30340;&#31283;&#20581;&#21152;&#26435;&#20998;&#25968;&#65288;ROWSU&#65289;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#22522;&#22240;&#34920;&#36798;&#25968;&#25454;&#20013;&#39640;&#24230;&#20542;&#26012;&#30340;&#31867;&#21035;&#20998;&#24067;&#23545;&#20998;&#31867;&#31639;&#27861;&#24615;&#33021;&#30340;&#19981;&#21033;&#24433;&#21709;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#22522;&#22240;&#34920;&#36798;&#20108;&#20998;&#31867;&#38382;&#39064;&#30340;&#31283;&#20581;&#21152;&#26435;&#20998;&#25968;&#65288;ROWSU&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#36873;&#25321;&#26368;&#20855;&#26377;&#21306;&#20998;&#24615;&#30340;&#29305;&#24449;&#12290;&#35813;&#26041;&#27861;&#35299;&#20915;&#20102;&#22522;&#22240;&#34920;&#36798;&#25968;&#25454;&#20013;&#39640;&#24230;&#20542;&#26012;&#30340;&#31867;&#21035;&#20998;&#24067;&#23545;&#20998;&#31867;&#31639;&#27861;&#24615;&#33021;&#30340;&#19981;&#21033;&#24433;&#21709;&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#36890;&#36807;&#20174;&#23569;&#25968;&#31867;&#21035;&#35266;&#27979;&#25968;&#25454;&#20013;&#21512;&#25104;&#29983;&#25104;&#25968;&#25454;&#28857;&#26469;&#24179;&#34913;&#35757;&#32451;&#25968;&#25454;&#38598;&#12290;&#20854;&#27425;&#65292;&#37319;&#29992;&#36138;&#23146;&#25628;&#32034;&#26041;&#27861;&#36873;&#25321;&#26368;&#23567;&#30340;&#22522;&#22240;&#23376;&#38598;&#12290;&#28982;&#21518;&#65292;&#24341;&#20837;&#19968;&#31181;&#26032;&#39062;&#30340;&#21152;&#26435;&#31283;&#20581;&#20998;&#25968;&#65292;&#20854;&#20013;&#26435;&#37325;&#30001;&#25903;&#25345;&#21521;&#37327;&#35745;&#31639;&#65292;&#20197;&#33719;&#24471;&#19968;&#32452;&#31934;&#28860;&#30340;&#22522;&#22240;&#12290;&#22522;&#20110;&#36825;&#31181;&#26041;&#27861;&#24471;&#21040;&#30340;&#26368;&#39640;&#20998;&#25968;&#22522;&#22240;&#19982;&#36138;&#23146;&#25628;&#32034;&#26041;&#27861;&#36873;&#25321;&#30340;&#26368;&#23567;&#22522;&#22240;&#23376;&#38598;&#30456;&#32467;&#21512;&#65292;&#24418;&#25104;&#26368;&#32456;&#30340;&#22522;&#22240;&#38598;&#21512;&#12290;&#36825;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#30830;&#20445;&#22312;&#23384;&#22312;&#20559;&#26012;&#31867;&#21035;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#36873;&#25321;&#26368;&#20855;&#26377;&#21306;&#20998;&#24615;&#30340;&#22522;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, a robust weighted score for unbalanced data (ROWSU) is proposed for selecting the most discriminative feature for high dimensional gene expression binary classification with class-imbalance problem. The method addresses one of the most challenging problems of highly skewed class distributions in gene expression datasets that adversely affect the performance of classification algorithms. First, the training dataset is balanced by synthetically generating data points from minority class observations. Second, a minimum subset of genes is selected using a greedy search approach. Third, a novel weighted robust score, where the weights are computed by support vectors, is introduced to obtain a refined set of genes. The highest-scoring genes based on this approach are combined with the minimum subset of genes selected by the greedy search approach to form the final set of genes. The novel method ensures the selection of the most discriminative genes, even in the presence of ske
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28508;&#22312;&#34920;&#31034;&#30340;&#31561;&#21464;&#24615;&#20197;&#21450;&#22312;&#20351;&#29992;&#20013;&#32771;&#34385;&#31561;&#21464;&#27169;&#22411;&#30340;&#24402;&#32435;&#20559;&#24046;&#30340;&#37325;&#35201;&#24615;&#65292;&#25552;&#20986;&#20102;&#36873;&#25321;&#19981;&#21464;&#25237;&#24433;&#30340;&#21407;&#21017;&#65292;&#24182;&#23637;&#31034;&#20102;&#20004;&#20010;&#23454;&#20363;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2401.12588</link><description>&lt;p&gt;
&#35299;&#35835;&#31561;&#21464;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Interpreting Equivariant Representations. (arXiv:2401.12588v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12588
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28508;&#22312;&#34920;&#31034;&#30340;&#31561;&#21464;&#24615;&#20197;&#21450;&#22312;&#20351;&#29992;&#20013;&#32771;&#34385;&#31561;&#21464;&#27169;&#22411;&#30340;&#24402;&#32435;&#20559;&#24046;&#30340;&#37325;&#35201;&#24615;&#65292;&#25552;&#20986;&#20102;&#36873;&#25321;&#19981;&#21464;&#25237;&#24433;&#30340;&#21407;&#21017;&#65292;&#24182;&#23637;&#31034;&#20102;&#20004;&#20010;&#23454;&#20363;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#21487;&#35270;&#21270;&#12289;&#25554;&#20540;&#25110;&#29305;&#24449;&#25552;&#21462;&#31561;&#19979;&#28216;&#20219;&#21153;&#65292;&#28508;&#22312;&#34920;&#31034;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#19981;&#21464;&#21644;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#26159;&#29992;&#20110;&#24378;&#21046;&#25191;&#34892;&#24402;&#32435;&#20559;&#24046;&#30340;&#24378;&#22823;&#19988;&#24050;&#24314;&#31435;&#30340;&#27169;&#22411;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#22312;&#20351;&#29992;&#28508;&#22312;&#34920;&#31034;&#26102;&#65292;&#24517;&#39035;&#21516;&#26102;&#32771;&#34385;&#31561;&#21464;&#27169;&#22411;&#26045;&#21152;&#30340;&#24402;&#32435;&#20559;&#24046;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19981;&#32771;&#34385;&#24402;&#32435;&#20559;&#24046;&#20250;&#23548;&#33268;&#19979;&#28216;&#20219;&#21153;&#24615;&#33021;&#19979;&#38477;&#65292;&#30456;&#21453;&#65292;&#36890;&#36807;&#20351;&#29992;&#28508;&#22312;&#34920;&#31034;&#30340;&#19981;&#21464;&#25237;&#24433;&#21487;&#20197;&#26377;&#25928;&#22320;&#32771;&#34385;&#24402;&#32435;&#20559;&#24046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#36873;&#25321;&#36825;&#26679;&#19968;&#20010;&#25237;&#24433;&#30340;&#21407;&#21017;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#20004;&#20010;&#24120;&#35265;&#20363;&#23376;&#20013;&#20351;&#29992;&#36825;&#20123;&#21407;&#21017;&#30340;&#24433;&#21709;&#65306;&#39318;&#20808;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#29992;&#20110;&#20998;&#23376;&#22270;&#29983;&#25104;&#30340;&#32622;&#25442;&#31561;&#21464;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65307;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#35774;&#35745;&#20986;&#19981;&#20135;&#29983;&#20449;&#24687;&#25439;&#22833;&#30340;&#19981;&#21464;&#25237;&#24433;&#12290;
&lt;/p&gt;
&lt;p&gt;
Latent representations are used extensively for downstream tasks, such as visualization, interpolation or feature extraction of deep learning models. Invariant and equivariant neural networks are powerful and well-established models for enforcing inductive biases. In this paper, we demonstrate that the inductive bias imposed on the by an equivariant model must also be taken into account when using latent representations. We show how not accounting for the inductive biases leads to decreased performance on downstream tasks, and vice versa, how accounting for inductive biases can be done effectively by using an invariant projection of the latent representations. We propose principles for how to choose such a projection, and show the impact of using these principles in two common examples: First, we study a permutation equivariant variational auto-encoder trained for molecule graph generation; here we show that invariant projections can be designed that incur no loss of information in the
&lt;/p&gt;</description></item><item><title>DDMI&#26159;&#19968;&#31181;&#38754;&#21521;&#39046;&#22495;&#26080;&#20851;&#30340;&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#30340;&#39640;&#36136;&#37327;&#21512;&#25104;&#30340;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#29983;&#25104;&#33258;&#36866;&#24212;&#20301;&#32622;&#23884;&#20837;&#32780;&#19981;&#26159;&#32593;&#32476;&#26435;&#37325;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#29983;&#25104;&#36136;&#37327;&#36739;&#20302;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.12517</link><description>&lt;p&gt;
DDMI: &#38754;&#21521;&#39046;&#22495;&#26080;&#20851;&#30340;&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#30340;&#39640;&#36136;&#37327;&#21512;&#25104;&#30340;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
DDMI: Domain-Agnostic Latent Diffusion Models for Synthesizing High-Quality Implicit Neural Representations. (arXiv:2401.12517v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12517
&lt;/p&gt;
&lt;p&gt;
DDMI&#26159;&#19968;&#31181;&#38754;&#21521;&#39046;&#22495;&#26080;&#20851;&#30340;&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#30340;&#39640;&#36136;&#37327;&#21512;&#25104;&#30340;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#29983;&#25104;&#33258;&#36866;&#24212;&#20301;&#32622;&#23884;&#20837;&#32780;&#19981;&#26159;&#32593;&#32476;&#26435;&#37325;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#29983;&#25104;&#36136;&#37327;&#36739;&#20302;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31867;&#29992;&#20110;&#21512;&#25104;&#21508;&#20010;&#39046;&#22495;&#20013;&#20219;&#24847;&#36830;&#32493;&#20449;&#21495;&#30340;&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#29983;&#25104;&#27169;&#22411;&#65292;&#20026;&#39046;&#22495;&#26080;&#20851;&#30340;&#29983;&#25104;&#27169;&#22411;&#25171;&#24320;&#20102;&#22823;&#38376;&#65292;&#20294;&#24448;&#24448;&#26080;&#27861;&#23454;&#29616;&#39640;&#36136;&#37327;&#30340;&#29983;&#25104;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#29616;&#26377;&#26041;&#27861;&#36890;&#36807;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#30340;&#26435;&#37325;&#26469;&#21442;&#25968;&#21270;&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#65292;&#24182;&#20351;&#29992;&#22266;&#23450;&#30340;&#20301;&#32622;&#23884;&#20837;&#26469;&#35780;&#20272;&#32593;&#32476;&#12290;&#21487;&#20197;&#35828;&#65292;&#36825;&#31181;&#26550;&#26500;&#38480;&#21046;&#20102;&#29983;&#25104;&#27169;&#22411;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#23548;&#33268;&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#29983;&#25104;&#30340;&#36136;&#37327;&#36739;&#20302;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#39046;&#22495;&#26080;&#20851;&#30340;&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#30340;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411; (DDMI)&#65292;&#20854;&#29983;&#25104;&#33258;&#36866;&#24212;&#20301;&#32622;&#23884;&#20837;&#32780;&#19981;&#26159;&#32593;&#32476;&#26435;&#37325;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#31163;&#25955;&#21040;&#36830;&#32493;&#31354;&#38388;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120; (D2C-VAE)&#65292;&#23427;&#22312;&#20849;&#20139;&#30340;&#28508;&#22312;&#31354;&#38388;&#20013;&#26080;&#32541;&#36830;&#25509;&#31163;&#25955;&#25968;&#25454;&#21644;&#36830;&#32493;&#20449;&#21495;&#20989;&#25968;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;...
&lt;/p&gt;
&lt;p&gt;
Recent studies have introduced a new class of generative models for synthesizing implicit neural representations (INRs) that capture arbitrary continuous signals in various domains. These models opened the door for domain-agnostic generative models, but they often fail to achieve high-quality generation. We observed that the existing methods generate the weights of neural networks to parameterize INRs and evaluate the network with fixed positional embeddings (PEs). Arguably, this architecture limits the expressive power of generative models and results in low-quality INR generation. To address this limitation, we propose Domain-agnostic Latent Diffusion Model for INRs (DDMI) that generates adaptive positional embeddings instead of neural networks' weights. Specifically, we develop a Discrete-to-continuous space Variational AutoEncoder (D2C-VAE), which seamlessly connects discrete data and the continuous signal functions in the shared latent space. Additionally, we introduce a novel con
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25551;&#36848;&#20102;&#19968;&#31181;&#29992;&#20110;&#35757;&#32451;&#25903;&#25345;&#21521;&#37327;&#26426;&#30340;&#32477;&#28909;&#37327;&#23376;&#26041;&#27861;&#65292;&#19982;&#32463;&#20856;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26102;&#38388;&#22797;&#26434;&#24230;&#19978;&#21462;&#24471;&#20102;&#19968;&#20010;&#25968;&#37327;&#32423;&#30340;&#25913;&#36827;&#65292;&#24182;&#19988;&#22312;&#20116;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#19982;&#32463;&#20856;&#26041;&#27861;&#30456;&#24403;&#30340;&#27979;&#35797;&#20934;&#30830;&#29575;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#33391;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.12485</link><description>&lt;p&gt;
&#32477;&#28909;&#37327;&#23376;&#25903;&#25345;&#21521;&#37327;&#26426;
&lt;/p&gt;
&lt;p&gt;
Adiabatic Quantum Support Vector Machines. (arXiv:2401.12485v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12485
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25551;&#36848;&#20102;&#19968;&#31181;&#29992;&#20110;&#35757;&#32451;&#25903;&#25345;&#21521;&#37327;&#26426;&#30340;&#32477;&#28909;&#37327;&#23376;&#26041;&#27861;&#65292;&#19982;&#32463;&#20856;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26102;&#38388;&#22797;&#26434;&#24230;&#19978;&#21462;&#24471;&#20102;&#19968;&#20010;&#25968;&#37327;&#32423;&#30340;&#25913;&#36827;&#65292;&#24182;&#19988;&#22312;&#20116;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#19982;&#32463;&#20856;&#26041;&#27861;&#30456;&#24403;&#30340;&#27979;&#35797;&#20934;&#30830;&#29575;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#33391;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32477;&#28909;&#37327;&#23376;&#35745;&#31639;&#26426;&#21487;&#20197;&#35299;&#20915;&#22256;&#38590;&#30340;&#20248;&#21270;&#38382;&#39064;&#65288;&#20363;&#22914;&#20108;&#27425;&#26080;&#32422;&#26463;&#20108;&#36827;&#21046;&#20248;&#21270;&#38382;&#39064;&#65289;&#65292;&#24182;&#19988;&#23427;&#20204;&#20284;&#20046;&#38750;&#24120;&#36866;&#21512;&#29992;&#20110;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#31181;&#29992;&#20110;&#35757;&#32451;&#25903;&#25345;&#21521;&#37327;&#26426;&#30340;&#32477;&#28909;&#37327;&#23376;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#37327;&#23376;&#26041;&#27861;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#27604;&#32463;&#20856;&#26041;&#27861;&#22909;&#19968;&#20010;&#25968;&#37327;&#32423;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#22312;&#20116;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#65288;Iris&#65292;Wisconsin&#20083;&#33146;&#30284;&#65288;WBC&#65289;&#65292;Wine&#65292;Digits&#21644;Lambeq&#65289;&#19978;&#23558;&#25105;&#20204;&#30340;&#37327;&#23376;&#26041;&#27861;&#30340;&#27979;&#35797;&#20934;&#30830;&#29575;&#19982;&#20351;&#29992;Python&#20013;&#30340;Scikit-learn&#24211;&#30340;&#32463;&#20856;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#37327;&#23376;&#26041;&#27861;&#33719;&#24471;&#20102;&#19982;&#32463;&#20856;&#26041;&#27861;&#30456;&#24403;&#30340;&#20934;&#30830;&#24230;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#21487;&#25193;&#23637;&#24615;&#30740;&#31350;&#65292;&#20854;&#20013;&#25105;&#20204;&#35745;&#31639;&#20102;&#37327;&#23376;&#26041;&#27861;&#21644;&#32463;&#20856;&#26041;&#27861;&#22312;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#29305;&#24449;&#25968;&#37327;&#21644;&#25968;&#25454;&#28857;&#25968;&#37327;&#22686;&#21152;&#26102;&#30340;&#24635;&#35757;&#32451;&#26102;&#38388;&#12290;&#25105;&#20204;&#30340;&#21487;&#25193;&#23637;&#24615;&#32467;&#26524;&#26174;&#31034;&#65292;&#37327;&#23376;&#26041;&#27861;&#20855;&#26377;&#33391;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adiabatic quantum computers can solve difficult optimization problems (e.g., the quadratic unconstrained binary optimization problem), and they seem well suited to train machine learning models. In this paper, we describe an adiabatic quantum approach for training support vector machines. We show that the time complexity of our quantum approach is an order of magnitude better than the classical approach. Next, we compare the test accuracy of our quantum approach against a classical approach that uses the Scikit-learn library in Python across five benchmark datasets (Iris, Wisconsin Breast Cancer (WBC), Wine, Digits, and Lambeq). We show that our quantum approach obtains accuracies on par with the classical approach. Finally, we perform a scalability study in which we compute the total training times of the quantum approach and the classical approach with increasing number of features and number of data points in the training dataset. Our scalability results show that the quantum approa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#20998;&#26512;&#38750;&#21442;&#25968; logistic &#22238;&#24402;&#38382;&#39064;&#65292;&#36890;&#36807;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#22312; Hellinger &#36317;&#31163;&#19979;&#25512;&#23548;&#20986;&#20102;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2401.12482</link><description>&lt;p&gt;
&#38750;&#21442;&#25968; logistic &#22238;&#24402;&#19982;&#28145;&#24230;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Nonparametric logistic regression with deep learning. (arXiv:2401.12482v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12482
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#20998;&#26512;&#38750;&#21442;&#25968; logistic &#22238;&#24402;&#38382;&#39064;&#65292;&#36890;&#36807;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#22312; Hellinger &#36317;&#31163;&#19979;&#25512;&#23548;&#20986;&#20102;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32771;&#34385;&#38750;&#21442;&#25968; logistic &#22238;&#24402;&#38382;&#39064;&#12290;&#22312; logistic &#22238;&#24402;&#20013;&#65292;&#25105;&#20204;&#36890;&#24120;&#32771;&#34385;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#65292;&#32780;&#36807;&#24230;&#39118;&#38505;&#26159;&#30495;&#23454;&#26465;&#20214;&#31867;&#27010;&#29575;&#21644;&#20272;&#35745;&#26465;&#20214;&#31867;&#27010;&#29575;&#20043;&#38388; Kullback-Leibler (KL) &#25955;&#24230;&#30340;&#26399;&#26395;&#12290;&#28982;&#32780;&#65292;&#22312;&#38750;&#21442;&#25968; logistic &#22238;&#24402;&#20013;&#65292;KL &#25955;&#24230;&#24456;&#23481;&#26131;&#21457;&#25955;&#65292;&#22240;&#27492;&#65292;&#36807;&#24230;&#39118;&#38505;&#30340;&#25910;&#25947;&#24456;&#38590;&#35777;&#26126;&#25110;&#19981;&#25104;&#31435;&#12290;&#33509;&#24178;&#29616;&#26377;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#24378;&#20551;&#35774;&#19979; KL &#25955;&#24230;&#30340;&#25910;&#25947;&#24615;&#12290;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20272;&#35745;&#30495;&#23454;&#30340;&#26465;&#20214;&#31867;&#27010;&#29575;&#12290;&#22240;&#27492;&#65292;&#19981;&#38656;&#35201;&#20998;&#26512;&#36807;&#24230;&#39118;&#38505;&#26412;&#36523;&#65292;&#21482;&#38656;&#22312;&#26576;&#20123;&#21512;&#36866;&#30340;&#24230;&#37327;&#19979;&#35777;&#26126;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#30340;&#19968;&#33268;&#24615;&#21363;&#21487;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#31616;&#21333;&#32479;&#19968;&#30340;&#26041;&#27861;&#20998;&#26512;&#38750;&#21442;&#25968;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120; (NPMLE)&#65292;&#30452;&#25509;&#25512;&#23548;&#20986; NPMLE &#22312; Hellinger &#36317;&#31163;&#19979;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consider the nonparametric logistic regression problem. In the logistic regression, we usually consider the maximum likelihood estimator, and the excess risk is the expectation of the Kullback-Leibler (KL) divergence between the true and estimated conditional class probabilities. However, in the nonparametric logistic regression, the KL divergence could diverge easily, and thus, the convergence of the excess risk is difficult to prove or does not hold. Several existing studies show the convergence of the KL divergence under strong assumptions. In most cases, our goal is to estimate the true conditional class probabilities. Thus, instead of analyzing the excess risk itself, it suffices to show the consistency of the maximum likelihood estimator in some suitable metric. In this paper, using a simple unified approach for analyzing the nonparametric maximum likelihood estimator (NPMLE), we directly derive the convergence rates of the NPMLE in the Hellinger distance under mild assumptions. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#38750;&#20998;&#31163;&#21704;&#23494;&#39039;&#31995;&#32479;&#30340;&#32467;&#26500;&#20445;&#25345;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#32479;&#35745;&#30456;&#20851;&#30340;&#21152;&#24615;&#21644;&#20056;&#24615;&#22122;&#22768;&#65292;&#24182;&#19988;&#36890;&#36807;&#23558;&#32467;&#26500;&#20445;&#25345;&#26041;&#27861;&#32435;&#20837;&#26694;&#26550;&#20013;&#65292;&#25552;&#20379;&#20102;&#23545;&#39640;&#32500;&#31995;&#32479;&#30340;&#39640;&#25928;&#35782;&#21035;&#12290;</title><link>http://arxiv.org/abs/2401.12476</link><description>&lt;p&gt;
&#29992;&#28145;&#24230;&#23398;&#20064;&#21644;&#38477;&#38454;&#24314;&#27169;&#36827;&#34892;&#36125;&#21494;&#26031;&#38750;&#20998;&#31163;&#21704;&#23494;&#39039;&#31995;&#32479;&#30340;&#35782;&#21035;&#21644;&#22810;&#39033;&#24335;&#22122;&#22768; (arXiv:2401.12476v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
Bayesian identification of nonseparable Hamiltonians with multiplicative noise using deep learning and reduced-order modeling. (arXiv:2401.12476v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12476
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#38750;&#20998;&#31163;&#21704;&#23494;&#39039;&#31995;&#32479;&#30340;&#32467;&#26500;&#20445;&#25345;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#32479;&#35745;&#30456;&#20851;&#30340;&#21152;&#24615;&#21644;&#20056;&#24615;&#22122;&#22768;&#65292;&#24182;&#19988;&#36890;&#36807;&#23558;&#32467;&#26500;&#20445;&#25345;&#26041;&#27861;&#32435;&#20837;&#26694;&#26550;&#20013;&#65292;&#25552;&#20379;&#20102;&#23545;&#39640;&#32500;&#31995;&#32479;&#30340;&#39640;&#25928;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#26500;&#20445;&#25345;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#20351;&#29992;&#38543;&#26426;&#21160;&#21147;&#27169;&#22411;&#30340;&#38750;&#20998;&#31163;&#21704;&#23494;&#39039;&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#20801;&#35768;&#32479;&#35745;&#30456;&#20851;&#30340;&#65292;&#30690;&#37327;&#20540;&#30340;&#21152;&#24615;&#21644;&#20056;&#24615;&#27979;&#37327;&#22122;&#22768;&#12290;&#35813;&#26041;&#27861;&#30001;&#19977;&#20010;&#20027;&#35201;&#26041;&#38754;&#32452;&#25104;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#36125;&#21494;&#26031;&#21518;&#39564;&#20013;&#30340;&#20284;&#28982;&#20989;&#25968;&#25152;&#38656;&#30340;&#32479;&#35745;&#30456;&#20851;&#30340;&#65292;&#30690;&#37327;&#20540;&#30340;&#21152;&#24615;&#21644;&#20056;&#24615;&#22122;&#22768;&#27169;&#22411;&#30340;&#39640;&#26031;&#28388;&#27874;&#22120;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#29992;&#20110;&#23545;&#39640;&#32500;&#31995;&#32479;&#36827;&#34892;&#39640;&#25928;&#30340;&#36125;&#21494;&#26031;&#31995;&#32479;&#35782;&#21035;&#12290;&#31532;&#19977;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;&#22914;&#20309;&#23558;&#32467;&#26500;&#20445;&#25345;&#26041;&#27861;&#32435;&#20837;&#25152;&#25552;&#35758;&#30340;&#26694;&#26550;&#20013;&#65292;&#20351;&#29992;&#38750;&#20998;&#31163;&#21704;&#23494;&#39039;&#31995;&#32479;&#20316;&#20026;&#19968;&#20010;&#20030;&#20363;&#30340;&#31995;&#32479;&#31867;&#21035;&#12290;&#25105;&#20204;&#23558;&#36125;&#21494;&#26031;&#26041;&#27861;&#19982;&#19968;&#31181;&#26368;&#20808;&#36827;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#19968;&#20010;&#20856;&#22411;&#30340;&#38750;&#20998;&#31163;&#21704;&#23494;&#39039;&#27169;&#22411;&#21644;&#24102;&#26377;&#23567;&#22411;&#22122;&#22768;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#28151;&#27788;&#21452;&#25670;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;
&lt;/p&gt;
&lt;p&gt;
This paper presents a structure-preserving Bayesian approach for learning nonseparable Hamiltonian systems using stochastic dynamic models allowing for statistically-dependent, vector-valued additive and multiplicative measurement noise. The approach is comprised of three main facets. First, we derive a Gaussian filter for a statistically-dependent, vector-valued, additive and multiplicative noise model that is needed to evaluate the likelihood within the Bayesian posterior. Second, we develop a novel algorithm for cost-effective application of Bayesian system identification to high-dimensional systems. Third, we demonstrate how structure-preserving methods can be incorporated into the proposed framework, using nonseparable Hamiltonians as an illustrative system class. We compare the Bayesian method to a state-of-the-art machine learning method on a canonical nonseparable Hamiltonian model and a chaotic double pendulum model with small, noisy training datasets. The results show that us
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#25913;&#36827;&#28145;&#24230;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#65292;&#26088;&#22312;&#35299;&#20915;&#28145;&#24230;&#27169;&#22411;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#36807;&#24230;&#33258;&#20449;&#21644;&#19981;&#20934;&#30830;&#39044;&#27979;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;&#21464;&#20998;&#25512;&#26029;&#25552;&#20379;&#30340;&#21518;&#39564;&#36817;&#20284;&#21644;&#36793;&#32536;&#20284;&#28982;&#19979;&#30028;&#65292;&#21487;&#20197;&#20248;&#21270;&#36229;&#21442;&#25968;&#24182;&#23454;&#29616;&#27169;&#22411;&#36873;&#25321;&#12290;</title><link>http://arxiv.org/abs/2401.12418</link><description>&lt;p&gt;
&#25913;&#36827;&#28145;&#24230;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Towards Improved Variational Inference for Deep Bayesian Models. (arXiv:2401.12418v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12418
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#25913;&#36827;&#28145;&#24230;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#65292;&#26088;&#22312;&#35299;&#20915;&#28145;&#24230;&#27169;&#22411;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#36807;&#24230;&#33258;&#20449;&#21644;&#19981;&#20934;&#30830;&#39044;&#27979;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;&#21464;&#20998;&#25512;&#26029;&#25552;&#20379;&#30340;&#21518;&#39564;&#36817;&#20284;&#21644;&#36793;&#32536;&#20284;&#28982;&#19979;&#30028;&#65292;&#21487;&#20197;&#20248;&#21270;&#36229;&#21442;&#25968;&#24182;&#23454;&#29616;&#27169;&#22411;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#20013;&#65292;&#28145;&#24230;&#23398;&#20064;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#24378;&#21270;&#23398;&#20064;&#31561;&#22810;&#20010;&#39046;&#22495;&#21462;&#24471;&#20102;&#37325;&#22823;&#31361;&#30772;&#12290;&#28982;&#32780;&#65292;&#20247;&#25152;&#21608;&#30693;&#65292;&#36890;&#36807;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#35757;&#32451;&#30340;&#28145;&#24230;&#27169;&#22411;&#24448;&#24448;&#36807;&#20110;&#33258;&#20449;&#65292;&#24182;&#19988;&#32473;&#20986;&#30340;&#39044;&#27979;&#19981;&#20934;&#30830;&#12290;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#35797;&#22270;&#36890;&#36807;&#32473;&#27169;&#22411;&#21442;&#25968;&#35774;&#32622;&#20808;&#39564;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#28982;&#21518;&#23558;&#20808;&#39564;&#19982;&#20284;&#28982;&#20989;&#25968;&#32467;&#21512;&#36827;&#34892;&#21518;&#39564;&#25512;&#26029;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#28145;&#24230;&#27169;&#22411;&#26469;&#35828;&#65292;&#30495;&#23454;&#30340;&#21518;&#39564;&#26159;&#26080;&#27861;&#35745;&#31639;&#30340;&#65292;&#22240;&#27492;&#38656;&#35201;&#20351;&#29992;&#36817;&#20284;&#26041;&#27861;&#12290;&#22312;&#26412;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#20351;&#29992;&#21464;&#20998;&#25512;&#26029;&#20316;&#20026;&#36817;&#20284;&#30340;&#26041;&#27861;&#65292;&#22240;&#20026;&#23427;&#26082;&#21487;&#20197;&#36817;&#20284;&#21518;&#39564;&#20998;&#24067;&#21448;&#21487;&#20197;&#25552;&#20379;&#36793;&#32536;&#20284;&#28982;&#30340;&#19979;&#30028;&#12290;&#22914;&#26524;&#19979;&#30028;&#36275;&#22815;&#32039;&#33268;&#65292;&#36825;&#20010;&#19979;&#30028;&#21487;&#20197;&#29992;&#26469;&#20248;&#21270;&#36229;&#21442;&#25968;&#21644;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#33021;&#21147;&#24456;&#23569;&#21463;&#21040;&#37325;&#35270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning has revolutionized the last decade, being at the forefront of extraordinary advances in a wide range of tasks including computer vision, natural language processing, and reinforcement learning, to name but a few. However, it is well-known that deep models trained via maximum likelihood estimation tend to be overconfident and give poorly-calibrated predictions. Bayesian deep learning attempts to address this by placing priors on the model parameters, which are then combined with a likelihood to perform posterior inference. Unfortunately, for deep models, the true posterior is intractable, forcing the user to resort to approximations. In this thesis, we explore the use of variational inference (VI) as an approximation, as it is unique in simultaneously approximating the posterior and providing a lower bound to the marginal likelihood. If tight enough, this lower bound can be used to optimize hyperparameters and to facilitate model selection. However, this capacity has rarel
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#20013;&#20351;&#29992;&#19981;&#21516;&#24120;&#29992;&#28608;&#27963;&#20989;&#25968;&#65288;&#22914;sigmoid&#21644;&#21452;&#26354;&#27491;&#20999;&#65289;&#26102;&#30340;VC&#32500;&#24230;&#65292;&#37319;&#29992;&#20102;Pfaffian&#20989;&#25968;&#29702;&#35770;&#26694;&#26550;&#65292;&#36890;&#36807;&#26550;&#26500;&#21442;&#25968;&#21644;&#21512;&#20316;&#25968;&#37327;&#25552;&#20379;&#20102;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2401.12362</link><description>&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#24102;&#26377;Pfaffian&#28608;&#27963;&#20989;&#25968;&#30340;VC&#32500;&#24230;
&lt;/p&gt;
&lt;p&gt;
VC dimension of Graph Neural Networks with Pfaffian activation functions. (arXiv:2401.12362v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12362
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#20013;&#20351;&#29992;&#19981;&#21516;&#24120;&#29992;&#28608;&#27963;&#20989;&#25968;&#65288;&#22914;sigmoid&#21644;&#21452;&#26354;&#27491;&#20999;&#65289;&#26102;&#30340;VC&#32500;&#24230;&#65292;&#37319;&#29992;&#20102;Pfaffian&#20989;&#25968;&#29702;&#35770;&#26694;&#26550;&#65292;&#36890;&#36807;&#26550;&#26500;&#21442;&#25968;&#21644;&#21512;&#20316;&#25968;&#37327;&#25552;&#20379;&#20102;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#36817;&#24180;&#26469;&#20316;&#20026;&#19968;&#31181;&#24378;&#22823;&#30340;&#24037;&#20855;&#20986;&#29616;&#65292;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#23398;&#20064;&#21508;&#31181;&#22270;&#39046;&#22495;&#30340;&#20219;&#21153;&#65307;&#22522;&#20110;&#28040;&#24687;&#20256;&#36882;&#26426;&#21046;&#65292;GNN&#30001;&#20110;&#20854;&#19982;Weisfeiler-Lehman&#65288;WL&#65289;&#22270;&#21516;&#26500;&#27979;&#35797;&#23494;&#20999;&#30456;&#20851;&#30340;&#30452;&#35266;&#34920;&#36798;&#32780;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#65292;&#23427;&#20204;&#24050;&#34987;&#35777;&#26126;&#31561;&#20215;&#12290;&#20174;&#29702;&#35770;&#35282;&#24230;&#30475;&#65292;GNN&#34987;&#35777;&#26126;&#26159;&#36890;&#29992;&#36924;&#36817;&#22120;&#65292;&#24182;&#19988;&#26368;&#36817;&#23545;&#20855;&#26377;&#20998;&#27573;&#22810;&#39033;&#24335;&#28608;&#27963;&#20989;&#25968;&#30340;GNN&#30340;&#27867;&#21270;&#33021;&#21147;&#65288;&#21363;&#65292;&#23545;Vapnik Cherovenikis&#65288;VC&#65289;&#32500;&#24230;&#30340;&#30028;&#38480;&#65289;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#30446;&#26631;&#26159;&#23558;&#23545;GNN&#30340;VC&#32500;&#24230;&#30340;&#20998;&#26512;&#25193;&#23637;&#21040;&#20854;&#20182;&#24120;&#29992;&#28608;&#27963;&#20989;&#25968;&#65292;&#22914;sigmoid&#21644;&#21452;&#26354;&#27491;&#20999;&#65292;&#20351;&#29992;Pfaffian&#20989;&#25968;&#29702;&#35770;&#26694;&#26550;&#12290;&#25552;&#20379;&#20102;&#19982;&#26550;&#26500;&#21442;&#25968;&#65288;&#28145;&#24230;&#65292;&#31070;&#32463;&#20803;&#25968;&#37327;&#65292;&#36755;&#20837;&#23610;&#23544;&#65289;&#20197;&#21450;&#19982;&#21512;&#20316;&#25968;&#37327;&#26377;&#20851;&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) have emerged in recent years as a powerful tool to learn tasks across a wide range of graph domains in a data-driven fashion; based on a message passing mechanism, GNNs have gained increasing popularity due to their intuitive formulation, closely linked with the Weisfeiler-Lehman (WL) test for graph isomorphism, to which they have proven equivalent. From a theoretical point of view, GNNs have been shown to be universal approximators, and their generalization capability (namely, bounds on the Vapnik Chervonekis (VC) dimension) has recently been investigated for GNNs with piecewise polynomial activation functions. The aim of our work is to extend this analysis on the VC dimension of GNNs to other commonly used activation functions, such as sigmoid and hyperbolic tangent, using the framework of Pfaffian function theory. Bounds are provided with respect to architecture parameters (depth, number of neurons, input size) as well as with respect to the number of co
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#21644;&#24490;&#29615;&#19968;&#33268;&#24615;&#30340;&#28151;&#21512;&#38750;&#37197;&#23545;&#22495;&#36716;&#25442;&#32593;&#32476;&#65288;H-CUT&#65289;&#26469;&#35299;&#20915;&#33258;&#21160;&#30446;&#26631;&#35782;&#21035;&#65288;ATR&#65289;&#20013;&#26631;&#35760;&#25968;&#25454;&#19981;&#36275;&#30340;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#22312;&#36328;&#39046;&#22495;&#36716;&#23548;&#36801;&#31227;&#23398;&#20064;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#20302;&#30340;FID&#20998;&#25968;&#65292;&#24182;&#36890;&#36807;&#27880;&#24847;&#21147;&#21644;&#29109;&#26469;&#24378;&#35843;&#39046;&#22495;&#29305;&#23450;&#21306;&#22495;&#65292;&#20197;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#21512;&#25104;&#22270;&#20687;&#12290;</title><link>http://arxiv.org/abs/2401.12340</link><description>&lt;p&gt;
&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#21644;&#24490;&#29615;&#19968;&#33268;&#24615;&#30340;&#36328;&#39046;&#22495;&#36716;&#23548;&#36801;&#31227;&#23398;&#20064;&#29992;&#20110;&#30446;&#26631;&#26631;&#27880;
&lt;/p&gt;
&lt;p&gt;
Contrastive Learning and Cycle Consistency-based Transductive Transfer Learning for Target Annotation. (arXiv:2401.12340v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12340
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#21644;&#24490;&#29615;&#19968;&#33268;&#24615;&#30340;&#28151;&#21512;&#38750;&#37197;&#23545;&#22495;&#36716;&#25442;&#32593;&#32476;&#65288;H-CUT&#65289;&#26469;&#35299;&#20915;&#33258;&#21160;&#30446;&#26631;&#35782;&#21035;&#65288;ATR&#65289;&#20013;&#26631;&#35760;&#25968;&#25454;&#19981;&#36275;&#30340;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#22312;&#36328;&#39046;&#22495;&#36716;&#23548;&#36801;&#31227;&#23398;&#20064;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#20302;&#30340;FID&#20998;&#25968;&#65292;&#24182;&#36890;&#36807;&#27880;&#24847;&#21147;&#21644;&#29109;&#26469;&#24378;&#35843;&#39046;&#22495;&#29305;&#23450;&#21306;&#22495;&#65292;&#20197;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#21512;&#25104;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#30446;&#26631;&#35782;&#21035;&#65288;ATR&#65289;&#30340;&#27880;&#37322;&#26159;&#19968;&#39033;&#26497;&#20855;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#20027;&#35201;&#30001;&#20110;&#30446;&#26631;&#22495;&#20013;&#26631;&#35760;&#25968;&#25454;&#30340;&#32570;&#20047;&#12290;&#22240;&#27492;&#65292;&#36890;&#36807;&#21033;&#29992;&#28304;&#22495;&#22270;&#20687;&#30340;&#26631;&#35760;&#20449;&#24687;&#26469;&#26500;&#24314;&#26368;&#20339;&#30446;&#26631;&#22495;&#20998;&#31867;&#22120;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#20808;&#21069;&#22312;&#25991;&#29486;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#21253;&#21547;&#22522;&#20110;CycleGAN&#30340;&#38750;&#37197;&#23545;&#22495;&#36716;&#25442;&#32593;&#32476;&#30340;&#36328;&#39046;&#22495;&#36716;&#23548;&#36801;&#31227;&#23398;&#20064;&#65288;TTL&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#26377;&#25928;&#30340;ATR&#26631;&#27880;&#12290;&#23613;&#31649;&#35813;&#26041;&#27861;&#26174;&#31034;&#20986;&#20102;ATR&#30340;&#24040;&#22823;&#28508;&#21147;&#65292;&#20294;&#23427;&#20005;&#37325;&#21463;&#21040;&#27880;&#37322;&#24615;&#33021;&#36739;&#20302;&#12289;&#26356;&#39640;&#30340;Fr\'echet Inception Distance&#65288;FID&#65289;&#20998;&#25968;&#20197;&#21450;&#21512;&#25104;&#22270;&#20687;&#20013;&#23384;&#22312;&#30340;&#35270;&#35273;&#20266;&#24433;&#30340;&#22256;&#25200;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#21644;&#24490;&#29615;&#19968;&#33268;&#24615;&#30340;&#28151;&#21512;&#38750;&#37197;&#23545;&#22495;&#36716;&#25442;&#65288;H-CUT&#65289;&#32593;&#32476;&#65292;&#23427;&#23454;&#29616;&#20102;&#26174;&#33879;&#36739;&#20302;&#30340;FID&#20998;&#25968;&#12290;&#23427;&#32467;&#21512;&#20102;&#27880;&#24847;&#21147;&#21644;&#29109;&#26469;&#24378;&#35843;&#39046;&#22495;&#29305;&#23450;&#30340;&#21306;&#22495;&#65292;&#22122;&#22768;&#29305;&#24449;&#28151;&#21512;&#27169;&#22359;&#29992;&#20110;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#21512;&#25104;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Annotating automatic target recognition (ATR) is a highly challenging task, primarily due to the unavailability of labeled data in the target domain. Hence, it is essential to construct an optimal target domain classifier by utilizing the labeled information of the source domain images. The transductive transfer learning (TTL) method that incorporates a CycleGAN-based unpaired domain translation network has been previously proposed in the literature for effective ATR annotation. Although this method demonstrates great potential for ATR, it severely suffers from lower annotation performance, higher Fr\'echet Inception Distance (FID) score, and the presence of visual artifacts in the synthetic images. To address these issues, we propose a hybrid contrastive learning base unpaired domain translation (H-CUT) network that achieves a significantly lower FID score. It incorporates both attention and entropy to emphasize the domain-specific region, a noisy feature mixup module to generate high
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#36801;&#31227;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32622;&#20449;&#38408;&#20540;&#20272;&#35745;&#22120;&#26469;&#23454;&#29616;&#28176;&#36817;&#26368;&#23567;&#39118;&#38505;&#65292;&#24182;&#21457;&#29616;&#20102;&#36801;&#31227;&#23398;&#20064;&#20013;&#30340;&#20004;&#20010;&#29420;&#29305;&#29616;&#35937;&#65306;&#33258;&#21160;&#24179;&#28369;&#21644;&#36229;&#21152;&#36895;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#31639;&#27861;&#65292;&#21487;&#20197;&#36866;&#24212;&#24191;&#27867;&#30340;&#21442;&#25968;&#31354;&#38388;&#65292;&#24182;&#22312;&#20223;&#30495;&#30740;&#31350;&#21644;&#30495;&#23454;&#19990;&#30028;&#30340;&#20363;&#23376;&#20013;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2401.12272</link><description>&lt;p&gt;
&#38024;&#23545;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#36801;&#31227;&#23398;&#20064;&#65306;&#38750;&#28176;&#36817;&#26497;&#23567;&#21270;&#20998;&#26512;&#21644;&#33258;&#36866;&#24212;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Transfer Learning for Nonparametric Regression: Non-asymptotic Minimax Analysis and Adaptive Procedure. (arXiv:2401.12272v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12272
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#36801;&#31227;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32622;&#20449;&#38408;&#20540;&#20272;&#35745;&#22120;&#26469;&#23454;&#29616;&#28176;&#36817;&#26368;&#23567;&#39118;&#38505;&#65292;&#24182;&#21457;&#29616;&#20102;&#36801;&#31227;&#23398;&#20064;&#20013;&#30340;&#20004;&#20010;&#29420;&#29305;&#29616;&#35937;&#65306;&#33258;&#21160;&#24179;&#28369;&#21644;&#36229;&#21152;&#36895;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#31639;&#27861;&#65292;&#21487;&#20197;&#36866;&#24212;&#24191;&#27867;&#30340;&#21442;&#25968;&#31354;&#38388;&#65292;&#24182;&#22312;&#20223;&#30495;&#30740;&#31350;&#21644;&#30495;&#23454;&#19990;&#30028;&#30340;&#20363;&#23376;&#20013;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#36801;&#31227;&#23398;&#20064;&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#35813;&#38382;&#39064;&#30340;&#38750;&#28176;&#36817;&#26497;&#23567;&#39118;&#38505;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#20272;&#35745;&#22120;&#65292;&#31216;&#20026;&#32622;&#20449;&#38408;&#20540;&#20272;&#35745;&#22120;&#65292;&#35777;&#26126;&#35813;&#20272;&#35745;&#22120;&#22312;&#19968;&#20010;&#23545;&#25968;&#22240;&#23376;&#30340;&#33539;&#22260;&#20869;&#23454;&#29616;&#20102;&#28176;&#36817;&#26497;&#23567;&#30340;&#39118;&#38505;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#23637;&#31034;&#20102;&#36801;&#31227;&#23398;&#20064;&#20013;&#30340;&#20004;&#20010;&#29420;&#29305;&#29616;&#35937;&#65306;&#33258;&#21160;&#24179;&#28369;&#21644;&#36229;&#21152;&#36895;&#65292;&#36825;&#20351;&#20854;&#19982;&#20256;&#32479;&#35774;&#32622;&#20013;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#26377;&#25152;&#21306;&#21035;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#31639;&#27861;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#22320;&#22312;&#24191;&#27867;&#30340;&#21442;&#25968;&#31354;&#38388;&#20013;&#23454;&#29616;&#20102;&#23545;&#25968;&#22240;&#23376;&#30340;&#28176;&#36817;&#26368;&#23567;&#39118;&#38505;&#12290;&#36890;&#36807;&#20223;&#30495;&#30740;&#31350;&#35780;&#20272;&#20102;&#33258;&#36866;&#24212;&#36801;&#31227;&#23398;&#20064;&#31639;&#27861;&#30340;&#25968;&#20540;&#24615;&#33021;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#20363;&#23376;&#26469;&#23637;&#31034;&#35813;&#26041;&#27861;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transfer learning for nonparametric regression is considered. We first study the non-asymptotic minimax risk for this problem and develop a novel estimator called the confidence thresholding estimator, which is shown to achieve the minimax optimal risk up to a logarithmic factor. Our results demonstrate two unique phenomena in transfer learning: auto-smoothing and super-acceleration, which differentiate it from nonparametric regression in a traditional setting. We then propose a data-driven algorithm that adaptively achieves the minimax risk up to a logarithmic factor across a wide range of parameter spaces. Simulation studies are conducted to evaluate the numerical performance of the adaptive transfer learning algorithm, and a real-world example is provided to demonstrate the benefits of the proposed method.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#30340;Sinkhorn&#31639;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#25552;&#21069;&#20572;&#27490;&#21644;&#29275;&#39039;&#36845;&#20195;&#23376;&#31243;&#24207;&#65292;&#23454;&#29616;&#20102;&#21487;&#33021;&#30340;&#36229;&#25351;&#25968;&#25910;&#25947;&#12290;&#20182;&#20204;&#21033;&#29992;&#20102;Sinkhorn&#31639;&#27861;&#26368;&#22823;&#21270;&#20985;&#24615;&#26446;&#38597;&#26222;&#35834;&#22827;&#21183;&#30340;&#29305;&#24615;&#65292;&#21457;&#29616;&#20102;&#21183;&#20989;&#25968;&#30340;Hessian&#30697;&#38453;&#36817;&#20284;&#31232;&#30095;&#65292;&#20174;&#32780;&#23558;&#27599;&#27425;&#36845;&#20195;&#30340;&#22797;&#26434;&#24615;&#38477;&#20302;&#21040;&#20102;$O(n^2)$&#12290;</title><link>http://arxiv.org/abs/2401.12253</link><description>&lt;p&gt;
&#20351;&#29992;&#31232;&#30095;&#29275;&#39039;&#36845;&#20195;&#21152;&#36895;Sinkhorn&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Accelerating Sinkhorn Algorithm with Sparse Newton Iterations. (arXiv:2401.12253v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12253
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#30340;Sinkhorn&#31639;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#25552;&#21069;&#20572;&#27490;&#21644;&#29275;&#39039;&#36845;&#20195;&#23376;&#31243;&#24207;&#65292;&#23454;&#29616;&#20102;&#21487;&#33021;&#30340;&#36229;&#25351;&#25968;&#25910;&#25947;&#12290;&#20182;&#20204;&#21033;&#29992;&#20102;Sinkhorn&#31639;&#27861;&#26368;&#22823;&#21270;&#20985;&#24615;&#26446;&#38597;&#26222;&#35834;&#22827;&#21183;&#30340;&#29305;&#24615;&#65292;&#21457;&#29616;&#20102;&#21183;&#20989;&#25968;&#30340;Hessian&#30697;&#38453;&#36817;&#20284;&#31232;&#30095;&#65292;&#20174;&#32780;&#23558;&#27599;&#27425;&#36845;&#20195;&#30340;&#22797;&#26434;&#24615;&#38477;&#20302;&#21040;&#20102;$O(n^2)$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#35745;&#31639;&#32479;&#35745;&#20998;&#24067;&#20043;&#38388;&#30340;&#26368;&#20248;&#20256;&#36755;&#36317;&#31163;&#26159;&#19968;&#39033;&#22522;&#26412;&#20219;&#21153;&#12290;&#26368;&#36817;&#30340;&#19968;&#39033;&#31361;&#30772;&#24615;&#36827;&#23637;&#26159;&#29109;&#27491;&#21017;&#21270;&#21644;Sinkhorn&#31639;&#27861;&#65292;&#23427;&#21482;&#20351;&#29992;&#30697;&#38453;&#32553;&#25918;&#24182;&#20445;&#35777;&#36817;&#20284;&#35299;&#30340;&#32447;&#24615;&#36816;&#34892;&#26102;&#38388;&#12290;&#23613;&#31649;Sinkhorn&#31639;&#27861;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#30001;&#20110;&#21487;&#33021;&#38656;&#35201;&#22823;&#37327;&#36845;&#20195;&#26469;&#36798;&#21040;&#25910;&#25947;&#65292;&#23427;&#30340;&#36816;&#34892;&#26102;&#38388;&#20173;&#21487;&#33021;&#36739;&#24930;&#12290;&#20026;&#20102;&#23454;&#29616;&#21487;&#33021;&#30340;&#36229;&#25351;&#25968;&#25910;&#25947;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Sinkhorn-Newton-Sparse&#65288;SNS&#65289;&#65292;&#36825;&#26159;Sinkhorn&#31639;&#27861;&#30340;&#19968;&#20010;&#25193;&#23637;&#65292;&#36890;&#36807;&#24341;&#20837;&#30697;&#38453;&#32553;&#25918;&#27493;&#39588;&#30340;&#25552;&#21069;&#20572;&#27490;&#21644;&#19968;&#20010;&#29305;&#24449;&#29275;&#39039;&#23376;&#31243;&#24207;&#30340;&#31532;&#20108;&#38454;&#27573;&#26469;&#23454;&#29616;&#12290;&#37319;&#29992;Sinkhorn&#31639;&#27861;&#26368;&#22823;&#21270;&#20985;&#24615;&#26446;&#38597;&#26222;&#35834;&#22827;&#21183;&#30340;&#21464;&#20998;&#35270;&#35282;&#65292;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65292;&#21183;&#20989;&#25968;&#30340;Hessian&#30697;&#38453;&#36817;&#20284;&#31232;&#30095;&#12290;&#31232;&#30095;&#21270;Hessian&#30697;&#38453;&#23548;&#33268;&#27599;&#27425;&#36845;&#20195;&#30340;&#22797;&#26434;&#24615;&#20026;&#24555;&#36895;&#30340;$O(n^2)$&#65292;&#19982;&#20256;&#32479;Sinkhorn&#31639;&#27861;&#30456;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
Computing the optimal transport distance between statistical distributions is a fundamental task in machine learning. One remarkable recent advancement is entropic regularization and the Sinkhorn algorithm, which utilizes only matrix scaling and guarantees an approximated solution with near-linear runtime. Despite the success of the Sinkhorn algorithm, its runtime may still be slow due to the potentially large number of iterations needed for convergence. To achieve possibly super-exponential convergence, we present Sinkhorn-Newton-Sparse (SNS), an extension to the Sinkhorn algorithm, by introducing early stopping for the matrix scaling steps and a second stage featuring a Newton-type subroutine. Adopting the variational viewpoint that the Sinkhorn algorithm maximizes a concave Lyapunov potential, we offer the insight that the Hessian matrix of the potential function is approximately sparse. Sparsification of the Hessian results in a fast $O(n^2)$ per-iteration complexity, the same as t
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#35777;&#26126;&#20102;&#21363;&#20351;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#23545;&#22122;&#22768;&#25968;&#25454;&#25311;&#21512;&#24471;&#24456;&#22909;&#65292;&#23545;&#25932;&#23545;&#31034;&#20363;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#20294;&#24403;&#38754;&#20020;&#25932;&#23545;&#25805;&#32437;&#30340;&#25968;&#25454;&#26102;&#65292;&#36807;&#24230;&#25311;&#21512;&#30340;&#27169;&#22411;&#21487;&#33021;&#20250;&#32473;&#31995;&#32479;&#24102;&#26469;&#24847;&#22806;&#30340;&#21361;&#23475;&#12290;</title><link>http://arxiv.org/abs/2401.12236</link><description>&lt;p&gt;
&#26080;&#23475;&#36807;&#24230;&#25311;&#21512;&#23545;&#25932;&#23545;&#40065;&#26834;&#24615;&#30340;&#24847;&#22806;&#21361;&#23475;
&lt;/p&gt;
&lt;p&gt;
The Surprising Harmfulness of Benign Overfitting for Adversarial Robustness. (arXiv:2401.12236v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12236
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#35777;&#26126;&#20102;&#21363;&#20351;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#23545;&#22122;&#22768;&#25968;&#25454;&#25311;&#21512;&#24471;&#24456;&#22909;&#65292;&#23545;&#25932;&#23545;&#31034;&#20363;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#20294;&#24403;&#38754;&#20020;&#25932;&#23545;&#25805;&#32437;&#30340;&#25968;&#25454;&#26102;&#65292;&#36807;&#24230;&#25311;&#21512;&#30340;&#27169;&#22411;&#21487;&#33021;&#20250;&#32473;&#31995;&#32479;&#24102;&#26469;&#24847;&#22806;&#30340;&#21361;&#23475;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#23454;&#35777;&#21644;&#29702;&#35770;&#30740;&#31350;&#24050;&#32463;&#35777;&#26126;&#20102;&#22823;&#35268;&#27169;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#23545;&#35757;&#32451;&#22122;&#22768;&#25968;&#25454;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#20196;&#20154;&#24778;&#35766;&#30340;&#32467;&#26524;&#65306;&#21363;&#20351;&#30495;&#27491;&#30340;&#25968;&#25454;&#26412;&#36523;&#23545;&#25932;&#23545;&#31034;&#20363;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#32780;&#19988;&#36807;&#24230;&#25311;&#21512;&#30340;&#27169;&#22411;&#22312;&#8220;&#26631;&#20934;&#8221;&#30340;&#26679;&#26412;&#22806;&#39118;&#38505;&#30446;&#26631;&#19978;&#26159;&#26080;&#23475;&#30340;&#65292;&#20294;&#22312;&#26679;&#26412;&#22806;&#25968;&#25454;&#21463;&#21040;&#25932;&#23545;&#25805;&#32437;&#26102;&#65292;&#36825;&#31181;&#26080;&#23475;&#30340;&#36807;&#24230;&#25311;&#21512;&#36807;&#31243;&#21487;&#33021;&#26159;&#26377;&#23475;&#30340;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#21253;&#21547;&#20004;&#20010;&#37096;&#20998;&#65306;&#65288;i&#65289;&#22312;&#36807;&#24230;&#21442;&#25968;&#21270;&#32447;&#24615;&#27169;&#22411;&#20013;&#65292;&#26368;&#23567;&#33539;&#25968;&#20272;&#35745;&#24635;&#26159;&#22312;&#8220;&#26080;&#23475;&#36807;&#24230;&#25311;&#21512;&#8221;&#35774;&#32622;&#20013;&#23548;&#33268;&#25932;&#23545;&#26131;&#21463;&#25915;&#20987;&#65307;&#65288;ii&#65289;&#25105;&#20204;&#39564;&#35777;&#20102;&#27599;&#20010;&#23725;&#22238;&#24402;&#20272;&#35745;&#22120;&#30340;&#26631;&#20934;&#39118;&#38505;&#21644;&#8220;&#25932;&#23545;&#8221;&#39118;&#38505;&#20043;&#38388;&#30340;&#28176;&#36827;&#26435;&#34913;&#32467;&#26524;&#65292;&#36825;&#24847;&#21619;&#30528;&#22312;&#36866;&#24403;&#30340;&#26465;&#20214;&#19979;&#65292;&#36825;&#20004;&#20010;&#39033;&#30446;&#19981;&#33021;&#21516;&#26102;&#36890;&#36807;&#20219;&#20309;&#21333;&#20010;&#23725;&#27491;&#21017;&#21270;&#21442;&#25968;&#30340;&#36873;&#25321;&#26469;&#20445;&#25345;&#24456;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent empirical and theoretical studies have established the generalization capabilities of large machine learning models that are trained to (approximately or exactly) fit noisy data. In this work, we prove a surprising result that even if the ground truth itself is robust to adversarial examples, and the benignly overfitted model is benign in terms of the ``standard'' out-of-sample risk objective, this benign overfitting process can be harmful when out-of-sample data are subject to adversarial manipulation. More specifically, our main results contain two parts: (i) the min-norm estimator in overparameterized linear model always leads to adversarial vulnerability in the ``benign overfitting'' setting; (ii) we verify an asymptotic trade-off result between the standard risk and the ``adversarial'' risk of every ridge regression estimator, implying that under suitable conditions these two items cannot both be small at the same time by any single choice of the ridge regularization parame
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35780;&#20272;&#20102;&#22810;&#31181;&#26102;&#38388;&#21040;&#20107;&#20214;&#32467;&#26524;&#30340;&#20122;&#32452;&#20998;&#26512;&#31639;&#27861;&#65292;&#22635;&#34917;&#20102;&#36825;&#19968;&#39046;&#22495;&#30340;&#30740;&#31350;&#31354;&#30333;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#65292;&#21487;&#20197;&#25506;&#32034;&#19981;&#21516;&#30340;&#24322;&#36136;&#24615;&#24773;&#26223;&#12290;</title><link>http://arxiv.org/abs/2401.11842</link><description>&lt;p&gt;
&#24322;&#36136;&#24615;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#20013;&#26102;&#38388;&#21040;&#20107;&#20214;&#32467;&#26524;&#30340;&#20122;&#32452;&#20998;&#26512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Subgroup analysis methods for time-to-event outcomes in heterogeneous randomized controlled trials. (arXiv:2401.11842v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11842
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35780;&#20272;&#20102;&#22810;&#31181;&#26102;&#38388;&#21040;&#20107;&#20214;&#32467;&#26524;&#30340;&#20122;&#32452;&#20998;&#26512;&#31639;&#27861;&#65292;&#22635;&#34917;&#20102;&#36825;&#19968;&#39046;&#22495;&#30340;&#30740;&#31350;&#31354;&#30333;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#65292;&#21487;&#20197;&#25506;&#32034;&#19981;&#21516;&#30340;&#24322;&#36136;&#24615;&#24773;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#26174;&#33879;&#30340;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#21487;&#33021;&#38544;&#34255;&#20102;&#23545;&#23454;&#39564;&#24615;&#33647;&#29289;&#26377;&#33391;&#22909;&#21453;&#24212;&#30340;&#20122;&#32452;&#65292;&#20174;&#32780;&#38459;&#30861;&#20102;&#21518;&#32493;&#30340;&#21457;&#23637;&#12290;&#37492;&#23450;&#36825;&#31181;&#24322;&#36136;&#24615;&#27835;&#30103;&#25928;&#24212;&#23545;&#20110;&#31934;&#20934;&#21307;&#23398;&#33267;&#20851;&#37325;&#35201;&#65292;&#20026;&#27492;&#24050;&#32463;&#24320;&#21457;&#20986;&#35768;&#22810;&#20107;&#21518;&#20998;&#26512;&#26041;&#27861;&#12290;&#34429;&#28982;&#24050;&#32463;&#36827;&#34892;&#20102;&#20960;&#20010;&#22522;&#20934;&#27979;&#35797;&#26469;&#37492;&#23450;&#36825;&#20123;&#26041;&#27861;&#30340;&#20248;&#28857;&#21644;&#32570;&#28857;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#20108;&#36827;&#21046;&#21644;&#36830;&#32493;&#32456;&#28857;&#65292;&#20294;&#26159;&#23545;&#20110;&#26102;&#38388;&#21040;&#20107;&#20214;&#32456;&#28857;&#30340;&#20122;&#32452;&#20998;&#26512;&#32570;&#20047;&#31867;&#20284;&#30340;&#31995;&#32479;&#23454;&#35777;&#35780;&#20272;&#12290;&#26412;&#24037;&#20316;&#26088;&#22312;&#36890;&#36807;&#35780;&#20272;&#20960;&#31181;&#26102;&#38388;&#21040;&#20107;&#20214;&#32467;&#26524;&#30340;&#20122;&#32452;&#20998;&#26512;&#31639;&#27861;&#26469;&#22635;&#34917;&#36825;&#20010;&#31354;&#30333;&#65292;&#36890;&#36807;&#19977;&#20010;&#19981;&#21516;&#30340;&#30740;&#31350;&#38382;&#39064;&#65306;&#26159;&#21542;&#23384;&#22312;&#24322;&#36136;&#24615;&#65311;&#20160;&#20040;&#29983;&#29289;&#26631;&#24535;&#29289;&#26159;&#23548;&#33268;&#36825;&#31181;&#24322;&#36136;&#24615;&#30340;&#21407;&#22240;&#65311;&#35841;&#26159;&#23545;&#27835;&#30103;&#26377;&#33391;&#22909;&#21453;&#24212;&#30340;&#20154;&#65311;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21512;&#25104;&#21644;&#21322;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#65292;&#20351;&#20154;&#20204;&#33021;&#22815;&#25506;&#32034;&#24191;&#27867;&#30340;&#24322;&#36136;&#24615;&#24773;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
Non-significant randomized control trials can hide subgroups of good responders to experimental drugs, thus hindering subsequent development. Identifying such heterogeneous treatment effects is key for precision medicine and many post-hoc analysis methods have been developed for that purpose. While several benchmarks have been carried out to identify the strengths and weaknesses of these methods, notably for binary and continuous endpoints, similar systematic empirical evaluation of subgroup analysis for time-to-event endpoints are lacking. This work aims to fill this gap by evaluating several subgroup analysis algorithms in the context of time-to-event outcomes, by means of three different research questions: Is there heterogeneity? What are the biomarkers responsible for such heterogeneity? Who are the good responders to treatment? In this context, we propose a new synthetic and semi-synthetic data generation process that allows one to explore a wide range of heterogeneity scenarios 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#23618;&#20248;&#21270;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#29992;&#20110;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#65292;&#36890;&#36807;&#32852;&#21512;&#26080;&#30417;&#30563;&#21644;&#30417;&#30563;&#35757;&#32451;&#26469;&#25552;&#39640;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.06980</link><description>&lt;p&gt;
&#36890;&#36807;&#21452;&#23618;&#20248;&#21270;&#36827;&#34892;&#32852;&#21512;&#26080;&#30417;&#30563;&#21644;&#30417;&#30563;&#35757;&#32451;&#30340;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Joint Unsupervised and Supervised Training for Automatic Speech Recognition via Bilevel Optimization. (arXiv:2401.06980v1 [cs.CL] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06980
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#23618;&#20248;&#21270;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#29992;&#20110;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#65292;&#36890;&#36807;&#32852;&#21512;&#26080;&#30417;&#30563;&#21644;&#30417;&#30563;&#35757;&#32451;&#26469;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#21452;&#23618;&#20248;&#21270;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#29992;&#20110;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#65288;ASR&#65289;&#20219;&#21153;&#20013;&#30340;&#22768;&#23398;&#27169;&#22411;&#35757;&#32451;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#8220;&#21452;&#23618;&#32852;&#21512;&#26080;&#30417;&#30563;&#21644;&#30417;&#30563;&#35757;&#32451;&#65288;BL-JUST&#65289;&#8221;&#12290;BL-JUST&#37319;&#29992;&#19979;&#23618;&#21644;&#19978;&#23618;&#20248;&#21270;&#65292;&#20998;&#21035;&#20351;&#29992;&#26080;&#30417;&#30563;&#25439;&#22833;&#21644;&#30417;&#30563;&#25439;&#22833;&#65292;&#21033;&#29992;&#26368;&#36817;&#22312;&#24809;&#32602;&#22411;&#21452;&#23618;&#20248;&#21270;&#26041;&#38754;&#21462;&#24471;&#30340;&#36827;&#23637;&#26469;&#35299;&#20915;&#36825;&#19968;&#20855;&#26377;&#21487;&#25215;&#21463;&#22797;&#26434;&#24230;&#21644;&#20005;&#26684;&#25910;&#25947;&#24615;&#20445;&#35777;&#30340;&#25361;&#25112;&#24615;ASR&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present a novel bilevel optimization-based training approach to training acoustic models for automatic speech recognition (ASR) tasks that we term {bi-level joint unsupervised and supervised training (BL-JUST)}. {BL-JUST employs a lower and upper level optimization with an unsupervised loss and a supervised loss respectively, leveraging recent advances in penalty-based bilevel optimization to solve this challenging ASR problem with affordable complexity and rigorous convergence guarantees.} To evaluate BL-JUST, extensive experiments on the LibriSpeech and TED-LIUM v2 datasets have been conducted. BL-JUST achieves superior performance over the commonly used pre-training followed by fine-tuning strategy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23450;&#20215;&#29615;&#22659;&#19979;&#36827;&#34892;&#38656;&#27714;&#39044;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#22240;&#26524;&#25512;&#26029;&#30340;&#21452;&#37325;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#21644;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;&#21464;&#21387;&#22120;&#30340;&#39044;&#27979;&#27169;&#22411;&#32467;&#21512;&#22312;&#19968;&#36215;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23436;&#20840;&#25511;&#21046;&#30340;&#24773;&#20917;&#19979;&#26356;&#22909;&#22320;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#22312;&#31163;&#32447;&#25919;&#31574;&#35774;&#32622;&#20013;&#20248;&#20110;&#20854;&#20182;&#39044;&#27979;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2312.15282</link><description>&lt;p&gt;
&#23450;&#20215;&#30340;&#22240;&#26524;&#39044;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Causal Forecasting for Pricing. (arXiv:2312.15282v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.15282
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23450;&#20215;&#29615;&#22659;&#19979;&#36827;&#34892;&#38656;&#27714;&#39044;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#22240;&#26524;&#25512;&#26029;&#30340;&#21452;&#37325;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#21644;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;&#21464;&#21387;&#22120;&#30340;&#39044;&#27979;&#27169;&#22411;&#32467;&#21512;&#22312;&#19968;&#36215;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23436;&#20840;&#25511;&#21046;&#30340;&#24773;&#20917;&#19979;&#26356;&#22909;&#22320;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#22312;&#31163;&#32447;&#25919;&#31574;&#35774;&#32622;&#20013;&#20248;&#20110;&#20854;&#20182;&#39044;&#27979;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23450;&#20215;&#29615;&#22659;&#19979;&#36827;&#34892;&#38656;&#27714;&#39044;&#27979;&#30340;&#26032;&#26041;&#27861;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#24314;&#27169;&#20215;&#26684;&#20316;&#20026;&#38656;&#27714;&#30340;&#36755;&#20837;&#21464;&#37327;&#20043;&#38388;&#30340;&#22240;&#26524;&#20851;&#31995;&#33267;&#20851;&#37325;&#35201;&#65292;&#22240;&#20026;&#38646;&#21806;&#21830;&#30340;&#30446;&#26631;&#26159;&#20197;&#65288;&#21033;&#28070;&#65289;&#26368;&#20339;&#26041;&#24335;&#35774;&#23450;&#20215;&#26684;&#65292;&#20197;&#35299;&#20915;&#19979;&#28216;&#20915;&#31574;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#22240;&#26524;&#25512;&#26029;&#30340;&#21452;&#37325;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#21644;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;&#21464;&#21387;&#22120;&#30340;&#39044;&#27979;&#27169;&#22411;&#32467;&#21512;&#22312;&#19968;&#36215;&#12290;&#36890;&#36807;&#22823;&#37327;&#30340;&#23454;&#35777;&#23454;&#39564;&#65292;&#25105;&#20204;&#19968;&#26041;&#38754;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23436;&#20840;&#25511;&#21046;&#30340;&#24773;&#20917;&#19979;&#23545;&#21512;&#25104;&#30340;&#12289;&#20294;&#29616;&#23454;&#30340;&#25968;&#25454;&#26356;&#22909;&#22320;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22312;&#23454;&#38469;&#25968;&#25454;&#20013;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#31163;&#32447;&#25919;&#31574;&#35774;&#32622;&#65288;&#21363;&#23450;&#20215;&#25919;&#31574;&#21457;&#29983;&#21464;&#21270;&#26102;&#65289;&#20013;&#20248;&#20110;&#20854;&#20182;&#39044;&#27979;&#26041;&#27861;&#65292;&#32780;&#22312;&#22312;&#32447;&#25919;&#31574;&#35774;&#32622;&#20013;&#30053;&#26377;&#33853;&#21518;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a novel method for demand forecasting in a pricing context. Here, modeling the causal relationship between price as an input variable to demand is crucial because retailers aim to set prices in a (profit) optimal manner in a downstream decision making problem. Our methods bring together the Double Machine Learning methodology for causal inference and state-of-the-art transformer-based forecasting models. In extensive empirical experiments, we show on the one hand that our method estimates the causal effect better in a fully controlled setting via synthetic, yet realistic data. On the other hand, we demonstrate on real-world data that our method outperforms forecasting methods in off-policy settings (i.e., when there's a change in the pricing policy) while only slightly trailing in the on-policy setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#25968;&#25454;&#19978;&#35757;&#32451;&#20915;&#31574;&#26641;&#30340;&#40065;&#26834;&#25439;&#22833;&#20989;&#25968;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#20027;&#35201;&#26377;&#19977;&#20010;&#36129;&#29486;&#65306;&#25552;&#20379;&#20102;&#23545;&#29616;&#26377;&#25439;&#22833;&#20989;&#25968;&#40065;&#26834;&#24615;&#30340;&#26032;&#27934;&#23519;&#65292;&#24341;&#20837;&#20102;&#20998;&#24067;&#25439;&#22833;&#20989;&#25968;&#30340;&#26694;&#26550;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#36138;&#23146;&#20943;&#23569;&#19981;&#32431;&#24230;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2312.12937</link><description>&lt;p&gt;
&#35757;&#32451;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#20915;&#31574;&#26641;&#30340;&#40065;&#26834;&#25439;&#22833;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Robust Loss Functions for Training Decision Trees with Noisy Labels. (arXiv:2312.12937v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.12937
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#25968;&#25454;&#19978;&#35757;&#32451;&#20915;&#31574;&#26641;&#30340;&#40065;&#26834;&#25439;&#22833;&#20989;&#25968;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#20027;&#35201;&#26377;&#19977;&#20010;&#36129;&#29486;&#65306;&#25552;&#20379;&#20102;&#23545;&#29616;&#26377;&#25439;&#22833;&#20989;&#25968;&#40065;&#26834;&#24615;&#30340;&#26032;&#27934;&#23519;&#65292;&#24341;&#20837;&#20102;&#20998;&#24067;&#25439;&#22833;&#20989;&#25968;&#30340;&#26694;&#26550;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#36138;&#23146;&#20943;&#23569;&#19981;&#32431;&#24230;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#25968;&#25454;&#35757;&#32451;&#20915;&#31574;&#26641;&#65292;&#37325;&#28857;&#30740;&#31350;&#21487;&#20197;&#23548;&#33268;&#40065;&#26834;&#23398;&#20064;&#31639;&#27861;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#26377;&#19977;&#20010;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23545;&#20915;&#31574;&#26641;&#23398;&#20064;&#32972;&#26223;&#19979;&#35768;&#22810;&#29616;&#26377;&#25439;&#22833;&#20989;&#25968;&#30340;&#40065;&#26834;&#24615;&#25552;&#20379;&#20102;&#26032;&#39062;&#30340;&#29702;&#35770;&#27934;&#23519;&#21147;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20123;&#25439;&#22833;&#23646;&#20110;&#25105;&#20204;&#25152;&#31216;&#30340;&#20445;&#23432;&#25439;&#22833;&#31867;&#21035;&#65292;&#24182;&#19988;&#20445;&#23432;&#25439;&#22833;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#20250;&#20986;&#29616;&#25552;&#21069;&#20572;&#27490;&#34892;&#20026;&#65292;&#32780;&#22312;&#27979;&#35797;&#36807;&#31243;&#20013;&#20855;&#26377;&#23481;&#24525;&#22122;&#22768;&#30340;&#39044;&#27979;&#33021;&#21147;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26500;&#24314;&#40065;&#26834;&#25439;&#22833;&#20989;&#25968;&#30340;&#26694;&#26550;&#65292;&#31216;&#20026;&#20998;&#24067;&#25439;&#22833;&#12290;&#36825;&#20123;&#25439;&#22833;&#22522;&#20110;&#20551;&#35774;&#30340;&#36793;&#32536;&#20998;&#24067;&#24212;&#29992;&#22522;&#20110;&#30334;&#20998;&#20301;&#30340;&#24809;&#32602;&#65292;&#23427;&#20204;&#36890;&#36807;&#40065;&#26834;&#24615;&#21442;&#25968;&#33258;&#28982;&#22320;&#20801;&#35768;&#36866;&#24212;&#19981;&#21516;&#30340;&#22122;&#22768;&#29575;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#36127;&#25351;&#25968;&#25439;&#22833;&#30340;&#26032;&#25439;&#22833;&#65292;&#23427;&#21487;&#20197;&#23548;&#33268;&#39640;&#25928;&#30340;&#36138;&#23146;&#20943;&#23569;&#19981;&#32431;&#24230;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#21644;&#22122;&#22768;&#26465;&#20214;&#19979;&#36827;&#34892;&#20102;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider training decision trees using noisily labeled data, focusing on loss functions that can lead to robust learning algorithms. Our contributions are threefold. First, we offer novel theoretical insights on the robustness of many existing loss functions in the context of decision tree learning. We show that some of the losses belong to a class of what we call conservative losses, and the conservative losses lead to an early stopping behavior during training and noise-tolerant predictions during testing. Second, we introduce a framework for constructing robust loss functions, called distribution losses. These losses apply percentile-based penalties based on an assumed margin distribution, and they naturally allow adapting to different noise rates via a robustness parameter. In particular, we introduce a new loss called the negative exponential loss, which leads to an efficient greedy impurity-reduction learning algorithm. Lastly, our experiments on multiple datasets and noise se
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#26680;&#26426;&#22120;&#39044;&#22788;&#29702;&#20013;&#20351;&#29992;Nystrom&#36924;&#36817;&#30340;&#26435;&#34913;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#20351;&#29992;&#23545;&#25968;&#22823;&#23567;&#30340;&#26679;&#26412;&#33021;&#22815;&#35753;Nystrom&#36924;&#36817;&#30340;&#39044;&#22788;&#29702;&#22120;&#20960;&#20046;&#19982;&#26799;&#24230;&#19979;&#38477;&#21516;&#26679;&#26377;&#25928;&#22320;&#21152;&#36895;&#12290;</title><link>http://arxiv.org/abs/2312.03311</link><description>&lt;p&gt;
&#23545;&#20110;&#26680;&#26426;&#22120;&#22312;&#39044;&#22788;&#29702;&#20013;&#30340;Nystrom&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
On the Nystrom Approximation for Preconditioning in Kernel Machines. (arXiv:2312.03311v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.03311
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#26680;&#26426;&#22120;&#39044;&#22788;&#29702;&#20013;&#20351;&#29992;Nystrom&#36924;&#36817;&#30340;&#26435;&#34913;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#20351;&#29992;&#23545;&#25968;&#22823;&#23567;&#30340;&#26679;&#26412;&#33021;&#22815;&#35753;Nystrom&#36924;&#36817;&#30340;&#39044;&#22788;&#29702;&#22120;&#20960;&#20046;&#19982;&#26799;&#24230;&#19979;&#38477;&#21516;&#26679;&#26377;&#25928;&#22320;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#26041;&#27861;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#19968;&#31867;&#27969;&#34892;&#30340;&#38750;&#32447;&#24615;&#39044;&#27979;&#27169;&#22411;&#12290;&#23398;&#20064;&#26680;&#27169;&#22411;&#30340;&#21487;&#25193;&#23637;&#31639;&#27861;&#38656;&#35201;&#20855;&#26377;&#36845;&#20195;&#24615;&#36136;&#65292;&#20294;&#30001;&#20110;&#31967;&#31957;&#30340;&#26465;&#20214;&#65292;&#25910;&#25947;&#21487;&#33021;&#24456;&#24930;&#12290;&#35889;&#39044;&#22788;&#29702;&#26159;&#21152;&#24555;&#35757;&#32451;&#26680;&#27169;&#22411;&#36845;&#20195;&#31639;&#27861;&#25910;&#25947;&#36895;&#24230;&#30340;&#37325;&#35201;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#35745;&#31639;&#21644;&#23384;&#20648;&#35889;&#39044;&#22788;&#29702;&#22120;&#21487;&#33021;&#20195;&#20215;&#39640;&#26114;&#65292;&#20250;&#23548;&#33268;&#22823;&#37327;&#30340;&#35745;&#31639;&#21644;&#23384;&#20648;&#24320;&#38144;&#65292;&#38480;&#21046;&#20102;&#26680;&#26041;&#27861;&#22312;&#22823;&#22411;&#25968;&#25454;&#38598;&#38382;&#39064;&#19978;&#30340;&#24212;&#29992;&#12290;Nystrom&#36924;&#36817;&#30340;&#35889;&#39044;&#22788;&#29702;&#22120;&#36890;&#24120;&#26356;&#20415;&#23452;&#21644;&#26356;&#23481;&#26131;&#35745;&#31639;&#21644;&#23384;&#20648;&#65292;&#24182;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#20351;&#29992;&#36825;&#31181;&#36924;&#36817;&#39044;&#22788;&#29702;&#22120;&#30340;&#26435;&#34913;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#34920;&#26126;&#19982;&#25968;&#25454;&#38598;&#22823;&#23567;&#30456;&#20851;&#30340;&#23545;&#25968;&#26679;&#26412;&#25968;&#37327;&#33021;&#22815;&#35753;&#22522;&#20110;Nystrom&#36924;&#36817;&#30340;&#39044;&#22788;&#29702;&#22120;&#20960;&#20046;&#19982;&#26799;&#24230;&#19979;&#38477;&#21516;&#26679;&#26377;&#25928;&#22320;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernel methods are a popular class of nonlinear predictive models in machine learning. Scalable algorithms for learning kernel models need to be iterative in nature, but convergence can be slow due to poor conditioning. Spectral preconditioning is an important tool to speed-up the convergence of such iterative algorithms for training kernel models. However computing and storing a spectral preconditioner can be expensive which can lead to large computational and storage overheads, precluding the application of kernel methods to problems with large datasets. A Nystrom approximation of the spectral preconditioner is often cheaper to compute and store, and has demonstrated success in practical applications. In this paper we analyze the trade-offs of using such an approximated preconditioner. Specifically, we show that a sample of logarithmic size (as a function of the size of the dataset) enables the Nystrom-based approximated preconditioner to accelerate gradient descent nearly as well as
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26465;&#20214;&#21464;&#20998;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#35843;&#24230;&#20316;&#20026;&#35757;&#32451;&#36807;&#31243;&#30340;&#19968;&#37096;&#20998;&#65292;&#35299;&#20915;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#25935;&#24863;&#24615;&#38382;&#39064;&#65292;&#24182;&#19988;&#33021;&#22815;&#36866;&#24212;&#19981;&#21516;&#30340;&#24212;&#29992;&#22330;&#26223;&#65292;&#25552;&#20379;&#39640;&#36136;&#37327;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2312.02246</link><description>&lt;p&gt;
&#26465;&#20214;&#21464;&#20998;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Conditional Variational Diffusion Models. (arXiv:2312.02246v3 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.02246
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26465;&#20214;&#21464;&#20998;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#35843;&#24230;&#20316;&#20026;&#35757;&#32451;&#36807;&#31243;&#30340;&#19968;&#37096;&#20998;&#65292;&#35299;&#20915;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#25935;&#24863;&#24615;&#38382;&#39064;&#65292;&#24182;&#19988;&#33021;&#22815;&#36866;&#24212;&#19981;&#21516;&#30340;&#24212;&#29992;&#22330;&#26223;&#65292;&#25552;&#20379;&#39640;&#36136;&#37327;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36870;&#38382;&#39064;&#26088;&#22312;&#20174;&#35266;&#27979;&#20013;&#30830;&#23450;&#21442;&#25968;&#65292;&#36825;&#26159;&#24037;&#31243;&#21644;&#31185;&#23398;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#20219;&#21153;&#12290;&#26368;&#36817;&#65292;&#29983;&#25104;&#27169;&#22411;&#65292;&#29305;&#21035;&#26159;&#25193;&#25955;&#27169;&#22411;&#65292;&#22240;&#20854;&#33021;&#22815;&#20135;&#29983;&#36924;&#30495;&#30340;&#35299;&#20915;&#26041;&#26696;&#21644;&#33391;&#22909;&#30340;&#25968;&#23398;&#29305;&#24615;&#32780;&#22312;&#36825;&#19968;&#39046;&#22495;&#20013;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#25193;&#25955;&#27169;&#22411;&#30340;&#19968;&#20010;&#37325;&#35201;&#32570;&#28857;&#26159;&#23545;&#26041;&#24046;&#35843;&#24230;&#30340;&#36873;&#25321;&#25935;&#24863;&#65292;&#35813;&#35843;&#24230;&#25511;&#21046;&#30528;&#25193;&#25955;&#36807;&#31243;&#30340;&#21160;&#24577;&#12290;&#20026;&#29305;&#23450;&#24212;&#29992;&#31243;&#24207;&#24494;&#35843;&#36825;&#20010;&#35843;&#24230;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#65292;&#20294;&#26102;&#38388;&#25104;&#26412;&#39640;&#26114;&#65292;&#24182;&#19988;&#19981;&#33021;&#20445;&#35777;&#26368;&#20248;&#32467;&#26524;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#23558;&#23398;&#20064;&#35843;&#24230;&#20316;&#20026;&#35757;&#32451;&#36807;&#31243;&#30340;&#19968;&#37096;&#20998;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25903;&#25345;&#23545;&#25968;&#25454;&#30340;&#27010;&#29575;&#26465;&#20214;&#65292;&#25552;&#20379;&#39640;&#36136;&#37327;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#19988;&#20855;&#26377;&#28789;&#27963;&#24615;&#65292;&#33021;&#22815;&#22312;&#26368;&#23567;&#30340;&#24320;&#38144;&#19979;&#36866;&#24212;&#19981;&#21516;&#30340;&#24212;&#29992;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#20004;&#20010;&#19981;&#30456;&#20851;&#30340;&#36870;&#38382;&#39064;&#20013;&#36827;&#34892;&#20102;&#27979;&#35797;&#65306;&#36229;&#20998;&#36776;&#29575;&#26174;&#24494;&#38236;&#21644;&#23450;&#37327;&#30456;&#20301;&#25104;&#20687;&#65292;&#32467;&#26524;&#34920;&#26126;&#27604;&#36739;&#25110;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inverse problems aim to determine parameters from observations, a crucial task in engineering and science. Lately, generative models, especially diffusion models, have gained popularity in this area for their ability to produce realistic solutions and their good mathematical properties. Despite their success, an important drawback of diffusion models is their sensitivity to the choice of variance schedule, which controls the dynamics of the diffusion process. Fine-tuning this schedule for specific applications is crucial but time-costly and does not guarantee an optimal result. We propose a novel approach for learning the schedule as part of the training process. Our method supports probabilistic conditioning on data, provides high-quality solutions, and is flexible, proving able to adapt to different applications with minimum overhead. This approach is tested in two unrelated inverse problems: super-resolution microscopy and quantitative phase imaging, yielding comparable or superior 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#38750;&#31283;&#24577;&#29615;&#22659;&#30340;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#24212;&#29992;&#31283;&#23450;&#24615;&#21407;&#21017;&#36873;&#25321;&#22238;&#28335;&#31383;&#21475;&#26469;&#26368;&#22823;&#21270;&#21382;&#21490;&#25968;&#25454;&#21033;&#29992;&#65292;&#24182;&#20445;&#25345;&#32047;&#31215;&#20559;&#24046;&#22312;&#21487;&#25509;&#21463;&#33539;&#22260;&#20869;&#12290;&#35813;&#26041;&#27861;&#23637;&#31034;&#20102;&#23545;&#26410;&#30693;&#38750;&#31283;&#24577;&#30340;&#36866;&#24212;&#24615;&#65292;&#36951;&#25022;&#30028;&#22312;&#24378;&#20984;&#25110;&#28385;&#36275;Lipschitz&#26465;&#20214;&#19979;&#26159;&#26497;&#23567;&#21270;&#30340;&#26368;&#20248;&#35299;&#12290;&#35813;&#30740;&#31350;&#30340;&#21019;&#26032;&#28857;&#26159;&#20989;&#25968;&#30456;&#20284;&#24230;&#24230;&#37327;&#21644;&#38750;&#31283;&#24577;&#25968;&#25454;&#24207;&#21015;&#21010;&#20998;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2310.18304</link><description>&lt;p&gt;
&#23398;&#20064;&#38750;&#31283;&#24577;&#26465;&#20214;&#19979;&#30340;&#31283;&#23450;&#24615;&#21407;&#21017;
&lt;/p&gt;
&lt;p&gt;
A Stability Principle for Learning under Non-Stationarity. (arXiv:2310.18304v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18304
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#38750;&#31283;&#24577;&#29615;&#22659;&#30340;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#24212;&#29992;&#31283;&#23450;&#24615;&#21407;&#21017;&#36873;&#25321;&#22238;&#28335;&#31383;&#21475;&#26469;&#26368;&#22823;&#21270;&#21382;&#21490;&#25968;&#25454;&#21033;&#29992;&#65292;&#24182;&#20445;&#25345;&#32047;&#31215;&#20559;&#24046;&#22312;&#21487;&#25509;&#21463;&#33539;&#22260;&#20869;&#12290;&#35813;&#26041;&#27861;&#23637;&#31034;&#20102;&#23545;&#26410;&#30693;&#38750;&#31283;&#24577;&#30340;&#36866;&#24212;&#24615;&#65292;&#36951;&#25022;&#30028;&#22312;&#24378;&#20984;&#25110;&#28385;&#36275;Lipschitz&#26465;&#20214;&#19979;&#26159;&#26497;&#23567;&#21270;&#30340;&#26368;&#20248;&#35299;&#12290;&#35813;&#30740;&#31350;&#30340;&#21019;&#26032;&#28857;&#26159;&#20989;&#25968;&#30456;&#20284;&#24230;&#24230;&#37327;&#21644;&#38750;&#31283;&#24577;&#25968;&#25454;&#24207;&#21015;&#21010;&#20998;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#38750;&#31283;&#23450;&#29615;&#22659;&#20013;&#24320;&#21457;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#12290;&#22312;&#27599;&#20010;&#26102;&#38388;&#27573;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#31283;&#23450;&#24615;&#21407;&#21017;&#26469;&#36873;&#25321;&#19968;&#20010;&#22238;&#28335;&#31383;&#21475;&#65292;&#26368;&#22823;&#38480;&#24230;&#22320;&#21033;&#29992;&#21382;&#21490;&#25968;&#25454;&#65292;&#21516;&#26102;&#23558;&#32047;&#31215;&#20559;&#24046;&#20445;&#25345;&#22312;&#19982;&#38543;&#26426;&#35823;&#24046;&#30456;&#23545;&#21487;&#25509;&#21463;&#30340;&#33539;&#22260;&#20869;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#23545;&#26410;&#30693;&#38750;&#31283;&#23450;&#24615;&#30340;&#36866;&#24212;&#24615;&#12290;&#24403;&#20154;&#21475;&#25439;&#22833;&#20989;&#25968;&#24378;&#20984;&#25110;&#20165;&#28385;&#36275;Lipschitz&#26465;&#20214;&#26102;&#65292;&#36951;&#25022;&#30028;&#26159;&#26497;&#23567;&#21270;&#30340;&#26368;&#20248;&#35299;&#65292;&#20165;&#21463;&#23545;&#25968;&#22240;&#23376;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#26680;&#24515;&#26159;&#20004;&#20010;&#26032;&#39062;&#30340;&#32452;&#25104;&#37096;&#20998;&#65306;&#20989;&#25968;&#20043;&#38388;&#30340;&#30456;&#20284;&#24230;&#24230;&#37327;&#21644;&#23558;&#38750;&#31283;&#24577;&#25968;&#25454;&#24207;&#21015;&#21010;&#20998;&#20026;&#20934;&#31283;&#24577;&#29255;&#27573;&#30340;&#20998;&#21106;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a versatile framework for statistical learning in non-stationary environments. In each time period, our approach applies a stability principle to select a look-back window that maximizes the utilization of historical data while keeping the cumulative bias within an acceptable range relative to the stochastic error. Our theory showcases the adaptability of this approach to unknown non-stationarity. The regret bound is minimax optimal up to logarithmic factors when the population losses are strongly convex, or Lipschitz only. At the heart of our analysis lie two novel components: a measure of similarity between functions and a segmentation technique for dividing the non-stationary data sequence into quasi-stationary pieces.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#31070;&#32463;&#29305;&#24449;&#23398;&#20064;&#30340;&#20960;&#20309;&#26694;&#26550;&#65292;&#22312;&#29305;&#24449;&#31354;&#38388;&#20013;&#21033;&#29992;&#20960;&#20309;&#32467;&#26500;&#35299;&#20915;&#23398;&#20064;&#38382;&#39064;&#12290;&#36890;&#36807;&#24341;&#20837;&#29305;&#24449;&#20960;&#20309;&#65292;&#23558;&#32479;&#35745;&#20381;&#36182;&#21644;&#29305;&#24449;&#32479;&#19968;&#21040;&#21516;&#19968;&#31354;&#38388;&#20013;&#65292;&#24182;&#20351;&#29992;&#23884;&#22871;&#25216;&#26415;&#35774;&#35745;&#23398;&#20064;&#31639;&#27861;&#65292;&#23637;&#31034;&#20102;&#20854;&#22312;&#22810;&#21464;&#37327;&#23398;&#20064;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2309.10140</link><description>&lt;p&gt;
&#19968;&#20010;&#22522;&#20110;&#31070;&#32463;&#29305;&#24449;&#23398;&#20064;&#30340;&#20960;&#20309;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Geometric Framework for Neural Feature Learning. (arXiv:2309.10140v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10140
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#31070;&#32463;&#29305;&#24449;&#23398;&#20064;&#30340;&#20960;&#20309;&#26694;&#26550;&#65292;&#22312;&#29305;&#24449;&#31354;&#38388;&#20013;&#21033;&#29992;&#20960;&#20309;&#32467;&#26500;&#35299;&#20915;&#23398;&#20064;&#38382;&#39064;&#12290;&#36890;&#36807;&#24341;&#20837;&#29305;&#24449;&#20960;&#20309;&#65292;&#23558;&#32479;&#35745;&#20381;&#36182;&#21644;&#29305;&#24449;&#32479;&#19968;&#21040;&#21516;&#19968;&#31354;&#38388;&#20013;&#65292;&#24182;&#20351;&#29992;&#23884;&#22871;&#25216;&#26415;&#35774;&#35745;&#23398;&#20064;&#31639;&#27861;&#65292;&#23637;&#31034;&#20102;&#20854;&#22312;&#22810;&#21464;&#37327;&#23398;&#20064;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#31070;&#32463;&#29305;&#24449;&#25552;&#21462;&#22120;&#30340;&#23398;&#20064;&#31995;&#32479;&#35774;&#35745;&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#29305;&#24449;&#31354;&#38388;&#20013;&#30340;&#20960;&#20309;&#32467;&#26500;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#29305;&#24449;&#20960;&#20309;&#65292;&#23427;&#23558;&#32479;&#35745;&#20381;&#36182;&#21644;&#29305;&#24449;&#32479;&#19968;&#21040;&#21516;&#19968;&#20010;&#20855;&#26377;&#20960;&#20309;&#32467;&#26500;&#30340;&#20989;&#25968;&#31354;&#38388;&#20013;&#12290;&#36890;&#36807;&#24212;&#29992;&#29305;&#24449;&#20960;&#20309;&#65292;&#25105;&#20204;&#23558;&#27599;&#20010;&#23398;&#20064;&#38382;&#39064;&#24418;&#24335;&#21270;&#20026;&#35299;&#20915;&#30001;&#23398;&#20064;&#35774;&#32622;&#25351;&#23450;&#30340;&#20381;&#36182;&#32452;&#20214;&#30340;&#26368;&#20339;&#29305;&#24449;&#36817;&#20284;&#35299;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23884;&#22871;&#25216;&#26415;&#26469;&#35774;&#35745;&#23398;&#20064;&#31639;&#27861;&#65292;&#20174;&#25968;&#25454;&#26679;&#26412;&#20013;&#23398;&#20064;&#26368;&#20339;&#29305;&#24449;&#65292;&#36825;&#21487;&#20197;&#24212;&#29992;&#20110;&#29616;&#26377;&#30340;&#32593;&#32476;&#26550;&#26500;&#21644;&#20248;&#21270;&#22120;&#12290;&#20026;&#20102;&#23637;&#31034;&#23884;&#22871;&#25216;&#26415;&#30340;&#24212;&#29992;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35752;&#35770;&#20102;&#22810;&#21464;&#37327;&#23398;&#20064;&#38382;&#39064;&#65292;&#21253;&#25324;&#26465;&#20214;&#25512;&#29702;&#21644;&#22810;&#27169;&#24577;&#23398;&#20064;&#65292;&#22312;&#36825;&#20123;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26368;&#20339;&#29305;&#24449;&#24182;&#25581;&#31034;&#20102;&#23427;&#20204;&#19982;&#32463;&#20856;&#26041;&#27861;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel framework for learning system design based on neural feature extractors by exploiting geometric structures in feature spaces. First, we introduce the feature geometry, which unifies statistical dependence and features in the same functional space with geometric structures. By applying the feature geometry, we formulate each learning problem as solving the optimal feature approximation of the dependence component specified by the learning setting. We propose a nesting technique for designing learning algorithms to learn the optimal features from data samples, which can be applied to off-the-shelf network architectures and optimizers. To demonstrate the application of the nesting technique, we further discuss multivariate learning problems, including conditioned inference and multimodal learning, where we present the optimal features and reveal their connections to classical approaches.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#39640;&#32500;&#24230;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#20013;&#24322;&#26041;&#24046;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22522;&#20110;&#20998;&#21306;&#32463;&#39564;&#36125;&#21494;&#26031;ECM&#31639;&#27861;&#30340;&#24322;&#26041;&#24046;&#39640;&#32500;&#24230;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#26469;&#23454;&#29616;&#12290;&#36825;&#20010;&#27169;&#22411;&#21487;&#20197;&#22788;&#29702;&#27531;&#24046;&#26041;&#24046;&#19981;&#24658;&#23450;&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#25554;&#20540;&#30340;&#32463;&#39564;&#36125;&#21494;&#26031;&#20272;&#35745;&#36229;&#21442;&#25968;&#26469;&#28789;&#27963;&#22320;&#35843;&#25972;&#26041;&#24046;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2309.08783</link><description>&lt;p&gt;
&#39640;&#32500;&#24230;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#24322;&#26041;&#24046;&#38382;&#39064;&#21450;&#22522;&#20110;&#20998;&#21306;&#32463;&#39564;&#36125;&#21494;&#26031;ECM&#31639;&#27861;&#30340;&#35299;&#20915;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Heteroscedastic sparse high-dimensional linear regression with a partitioned empirical Bayes ECM algorithm. (arXiv:2309.08783v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08783
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#39640;&#32500;&#24230;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#20013;&#24322;&#26041;&#24046;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22522;&#20110;&#20998;&#21306;&#32463;&#39564;&#36125;&#21494;&#26031;ECM&#31639;&#27861;&#30340;&#24322;&#26041;&#24046;&#39640;&#32500;&#24230;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#26469;&#23454;&#29616;&#12290;&#36825;&#20010;&#27169;&#22411;&#21487;&#20197;&#22788;&#29702;&#27531;&#24046;&#26041;&#24046;&#19981;&#24658;&#23450;&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#25554;&#20540;&#30340;&#32463;&#39564;&#36125;&#21494;&#26031;&#20272;&#35745;&#36229;&#21442;&#25968;&#26469;&#28789;&#27963;&#22320;&#35843;&#25972;&#26041;&#24046;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#24230;&#25968;&#25454;&#30340;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#26041;&#27861;&#36890;&#24120;&#20551;&#35774;&#27531;&#24046;&#20855;&#26377;&#24120;&#25968;&#26041;&#24046;&#12290;&#24403;&#36825;&#19968;&#20551;&#35774;&#34987;&#36829;&#32972;&#26102;&#65292;&#20250;&#23548;&#33268;&#20272;&#35745;&#31995;&#25968;&#30340;&#20559;&#24046;&#65292;&#39044;&#27979;&#21306;&#38388;&#38271;&#24230;&#19981;&#21512;&#36866;&#20197;&#21450;&#22686;&#21152;I&#22411;&#38169;&#35823;&#12290;&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20998;&#21306;&#32463;&#39564;&#36125;&#21494;&#26031;&#26399;&#26395;&#26465;&#20214;&#26368;&#22823;&#21270;(H-PROBE)&#31639;&#27861;&#30340;&#24322;&#26041;&#24046;&#39640;&#32500;&#24230;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#12290;H-PROBE&#26159;&#19968;&#31181;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#26041;&#27861;&#65292;&#22522;&#20110;&#21442;&#25968;&#25193;&#23637;&#30340;&#26399;&#26395;&#26465;&#20214;&#26368;&#22823;&#21270;(PX-ECM)&#31639;&#27861;&#12290;&#23427;&#36890;&#36807;&#25554;&#20540;&#30340;&#32463;&#39564;&#36125;&#21494;&#26031;&#20272;&#35745;&#36229;&#21442;&#25968;&#65292;&#22312;&#22238;&#24402;&#21442;&#25968;&#19978;&#20551;&#35774;&#26368;&#23567;&#12290;&#26041;&#24046;&#27169;&#22411;&#20351;&#29992;&#20102;&#22810;&#20803;&#23545;&#25968;&#20285;&#39532;&#20998;&#24067;&#29702;&#35770;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24182;&#21487;&#20197;&#21253;&#21547;&#20551;&#35774;&#20250;&#24433;&#21709;&#24322;&#36136;&#24615;&#30340;&#21327;&#21464;&#37327;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#21160;&#26426;&#26159;&#36890;&#36807;T2&#39640;&#20998;&#36776;&#29575;&#31070;&#32463;&#24433;&#20687;&#30740;&#31350;&#19982;&#22833;&#35821;&#25351;&#25968;(AQ)&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse linear regression methods for high-dimensional data often assume that residuals have constant variance. When this assumption is violated, it can lead to bias in estimated coefficients, prediction intervals with improper length, and increased type I errors. This paper proposes a heteroscedastic (H) high-dimensional linear regression model through a partitioned empirical Bayes Expectation Conditional Maximization (H-PROBE) algorithm. H-PROBE is a computationally efficient maximum a posteriori (MAP) estimation approach based on a Parameter-Expanded Expectation-Conditional-Maximization (PX-ECM) algorithm. It requires minimal prior assumptions on the regression parameters through plug-in empirical Bayes estimates of hyperparameters. The variance model uses recent advances in multivariate log-Gamma distribution theory and can include covariates hypothesized to impact heterogeneity. The motivation of our approach is a study relating Aphasia Quotient (AQ) to high-resolution T2 neuroimag
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#26088;&#22312;&#25506;&#35752;&#20309;&#26102;&#22522;&#20110;&#32622;&#20449;&#24230;&#30340;&#32423;&#32852;&#24310;&#36831;&#21487;&#33021;&#22833;&#36133;&#65292;&#20197;&#21450;&#20309;&#26102;&#22791;&#36873;&#30340;&#24310;&#36831;&#31574;&#30053;&#21487;&#33021;&#34920;&#29616;&#26356;&#22909;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#39564;&#35777;&#26126;&#20107;&#21518;&#24310;&#36831;&#26426;&#21046;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.02764</link><description>&lt;p&gt;
&#20309;&#26102;&#20351;&#29992;&#22522;&#20110;&#32622;&#20449;&#24230;&#30340;&#32423;&#32852;&#24310;&#36831;&#36275;&#22815;&#65311;
&lt;/p&gt;
&lt;p&gt;
When Does Confidence-Based Cascade Deferral Suffice?. (arXiv:2307.02764v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02764
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#25506;&#35752;&#20309;&#26102;&#22522;&#20110;&#32622;&#20449;&#24230;&#30340;&#32423;&#32852;&#24310;&#36831;&#21487;&#33021;&#22833;&#36133;&#65292;&#20197;&#21450;&#20309;&#26102;&#22791;&#36873;&#30340;&#24310;&#36831;&#31574;&#30053;&#21487;&#33021;&#34920;&#29616;&#26356;&#22909;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#39564;&#35777;&#26126;&#20107;&#21518;&#24310;&#36831;&#26426;&#21046;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32423;&#32852;&#26159;&#19968;&#31181;&#32463;&#20856;&#30340;&#31574;&#30053;&#65292;&#21487;&#20197;&#23454;&#29616;&#36866;&#24212;&#24615;&#22320;&#22312;&#26679;&#26412;&#20043;&#38388;&#21464;&#21270;&#30340;&#25512;&#29702;&#25104;&#26412;&#65292;&#20854;&#20013;&#25353;&#39034;&#24207;&#35843;&#29992;&#19968;&#31995;&#21015;&#20998;&#31867;&#22120;&#12290;&#24310;&#36831;&#35268;&#21017;&#30830;&#23450;&#26159;&#21542;&#35843;&#29992;&#24207;&#21015;&#20013;&#30340;&#19979;&#19968;&#20010;&#20998;&#31867;&#22120;&#65292;&#25110;&#32773;&#32456;&#27490;&#39044;&#27979;&#12290;&#19968;&#31181;&#31616;&#21333;&#30340;&#24310;&#36831;&#35268;&#21017;&#21033;&#29992;&#24403;&#21069;&#20998;&#31867;&#22120;&#30340;&#32622;&#20449;&#24230;&#65292;&#20363;&#22914;&#22522;&#20110;&#26368;&#22823;&#39044;&#27979;&#30340;softmax&#27010;&#29575;&#12290;&#23613;&#31649;&#23545;&#32423;&#32852;&#32467;&#26500;&#19981;&#25935;&#24863;&#8212;&#8212;&#20363;&#22914;&#19981;&#24314;&#27169;&#19979;&#28216;&#27169;&#22411;&#30340;&#38169;&#35823;&#8212;&#8212;&#20294;&#36825;&#31181;&#22522;&#20110;&#32622;&#20449;&#24230;&#30340;&#24310;&#36831;&#32463;&#24120;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#26356;&#22909;&#22320;&#29702;&#35299;&#22522;&#20110;&#32622;&#20449;&#24230;&#30340;&#24310;&#36831;&#21487;&#33021;&#22833;&#36133;&#30340;&#26465;&#20214;&#65292;&#20197;&#21450;&#20309;&#26102;&#22791;&#36873;&#30340;&#24310;&#36831;&#31574;&#30053;&#21487;&#33021;&#26356;&#22909;&#12290;&#25105;&#20204;&#39318;&#20808;&#23545;&#26368;&#20248;&#24310;&#36831;&#35268;&#21017;&#36827;&#34892;&#20102;&#29702;&#35770;&#34920;&#24449;&#65292;&#31934;&#30830;&#22320;&#25551;&#36848;&#20102;&#22522;&#20110;&#32622;&#20449;&#24230;&#30340;&#24310;&#36831;&#21487;&#33021;&#21463;&#21040;&#24433;&#21709;&#30340;&#35774;&#32622;&#12290;&#28982;&#21518;&#25105;&#20204;&#30740;&#31350;&#20102;&#20107;&#21518;&#24310;&#36831;&#26426;&#21046;&#65292;&#24182;&#39564;&#35777;&#23427;&#20204;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cascades are a classical strategy to enable inference cost to vary adaptively across samples, wherein a sequence of classifiers are invoked in turn. A deferral rule determines whether to invoke the next classifier in the sequence, or to terminate prediction. One simple deferral rule employs the confidence of the current classifier, e.g., based on the maximum predicted softmax probability. Despite being oblivious to the structure of the cascade -- e.g., not modelling the errors of downstream models -- such confidence-based deferral often works remarkably well in practice. In this paper, we seek to better understand the conditions under which confidence-based deferral may fail, and when alternate deferral strategies can perform better. We first present a theoretical characterisation of the optimal deferral rule, which precisely characterises settings under which confidence-based deferral may suffer. We then study post-hoc deferral mechanisms, and demonstrate they can significantly improv
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36731;&#37327;&#32423;&#26041;&#27861;&#26469;&#35843;&#25972;&#32852;&#37030;&#24179;&#22343;&#20013;&#30340;&#32858;&#21512;&#26435;&#37325;&#65292;&#36890;&#36807;&#26681;&#25454;&#27599;&#20010;&#23458;&#25143;&#30340;&#21442;&#19982;&#21382;&#21490;&#26469;&#22788;&#29702;&#20855;&#26377;&#19981;&#21516;&#21442;&#19982;&#29575;&#30340;&#23458;&#25143;&#65292;&#35299;&#20915;&#20102;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#26410;&#30693;&#21442;&#19982;&#27010;&#29575;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.03401</link><description>&lt;p&gt;
&#22788;&#29702;&#32852;&#37030;&#24179;&#22343;&#20013;&#26410;&#30693;&#21442;&#19982;&#27010;&#29575;&#30340;&#36731;&#37327;&#32423;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Lightweight Method for Tackling Unknown Participation Probabilities in Federated Averaging. (arXiv:2306.03401v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03401
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36731;&#37327;&#32423;&#26041;&#27861;&#26469;&#35843;&#25972;&#32852;&#37030;&#24179;&#22343;&#20013;&#30340;&#32858;&#21512;&#26435;&#37325;&#65292;&#36890;&#36807;&#26681;&#25454;&#27599;&#20010;&#23458;&#25143;&#30340;&#21442;&#19982;&#21382;&#21490;&#26469;&#22788;&#29702;&#20855;&#26377;&#19981;&#21516;&#21442;&#19982;&#29575;&#30340;&#23458;&#25143;&#65292;&#35299;&#20915;&#20102;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#26410;&#30693;&#21442;&#19982;&#27010;&#29575;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#65292;&#23458;&#25143;&#31471;&#36890;&#24120;&#20855;&#26377;&#20808;&#39564;&#26410;&#30693;&#30340;&#19981;&#21516;&#21442;&#19982;&#29575;&#65292;&#22914;&#26524;&#19981;&#36866;&#24403;&#22788;&#29702;&#65292;&#21017;&#21487;&#33021;&#20250;&#23545;&#32852;&#37030;&#23398;&#20064;&#30340;&#24615;&#33021;&#36896;&#25104;&#37325;&#22823;&#24433;&#21709;&#12290;&#29616;&#26377;&#30340;&#35299;&#20915;&#26041;&#27861;&#36890;&#24120;&#22522;&#20110;&#20840;&#23616;&#26041;&#24046;&#32553;&#20943;&#65292;&#36825;&#38656;&#35201;&#22823;&#37327;&#39069;&#22806;&#30340;&#20869;&#23384;&#65292;&#20854;&#20056;&#27861;&#22240;&#23376;&#31561;&#20110;&#23458;&#25143;&#24635;&#25968;&#12290;&#19968;&#20010;&#37325;&#35201;&#30340;&#26410;&#35299;&#20915;&#38382;&#39064;&#26159;&#25214;&#21040;&#19968;&#31181;&#36731;&#37327;&#32423;&#26041;&#27861;&#26469;&#22788;&#29702;&#20855;&#22791;&#19981;&#21516;&#21442;&#19982;&#29575;&#23458;&#25143;&#30340;&#32852;&#37030;&#23398;&#20064;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#26681;&#25454;&#27599;&#20010;&#23458;&#25143;&#30340;&#21442;&#19982;&#21382;&#21490;&#26469;&#35843;&#25972;&#32852;&#37030;&#24179;&#22343;&#65288;FedAvg&#65289;&#20013;&#30340;&#32858;&#21512;&#26435;&#37325;&#26469;&#35299;&#20915;&#27492;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#22312;&#20855;&#26377;&#24322;&#26500;&#21442;&#19982;&#27010;&#29575;&#30340;&#24773;&#20917;&#19979;&#65292;&#38750;&#26368;&#20248;&#32858;&#21512;&#26435;&#37325;&#30340;FedAvg&#21487;&#33021;&#20250;&#20174;&#21407;&#22987;FL&#30446;&#26631;&#30340;&#26368;&#20248;&#35299;&#20559;&#31163;&#65292;&#36825;&#34920;&#26126;&#38656;&#35201;&#25214;&#21040;&#26368;&#20248;&#32858;&#21512;&#26435;&#37325;&#12290;&#28982;&#32780;&#65292;&#24403;&#21442;&#19982;&#27010;&#29575;&#19981;&#21487;&#30693;&#26102;&#35745;&#31639;&#26368;&#20248;&#26435;&#37325;&#38750;&#24120;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;
In federated learning (FL), clients usually have diverse participation probabilities that are unknown a priori, which can significantly harm the performance of FL if not handled properly. Existing works aiming at addressing this problem are usually based on global variance reduction, which requires a substantial amount of additional memory in a multiplicative factor equal to the total number of clients. An important open problem is to find a lightweight method for FL in the presence of clients with unknown participation rates. In this paper, we address this problem by adapting the aggregation weights in federated averaging (FedAvg) based on the participation history of each client. We first show that, with heterogeneous participation probabilities, FedAvg with non-optimal aggregation weights can diverge from the optimal solution of the original FL objective, indicating the need of finding optimal aggregation weights. However, it is difficult to compute the optimal weights when the part
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#35752;&#35770;&#22312;&#20855;&#26377;&#36172;&#21338;&#21453;&#39304;&#30340;&#38543;&#26426;&#29615;&#22659;&#20013;&#36827;&#34892;&#36873;&#25321;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#25968;&#25454;&#30340;&#27169;&#22411;&#36873;&#25321;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#20445;&#35777;&#12290;&#36890;&#36807;&#21033;&#29992;&#23454;&#38469;&#36951;&#25022;&#65292;&#36825;&#20123;&#31639;&#27861;&#22312;&#23454;&#38469;&#20013;&#21462;&#24471;&#20102;&#22909;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.02869</link><description>&lt;p&gt;
&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#36951;&#25022;&#24179;&#34913;&#22312;&#32447;&#27169;&#22411;&#36873;&#25321;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Data-Driven Regret Balancing for Online Model Selection in Bandits. (arXiv:2306.02869v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02869
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#35752;&#35770;&#22312;&#20855;&#26377;&#36172;&#21338;&#21453;&#39304;&#30340;&#38543;&#26426;&#29615;&#22659;&#20013;&#36827;&#34892;&#36873;&#25321;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#25968;&#25454;&#30340;&#27169;&#22411;&#36873;&#25321;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#20445;&#35777;&#12290;&#36890;&#36807;&#21033;&#29992;&#23454;&#38469;&#36951;&#25022;&#65292;&#36825;&#20123;&#31639;&#27861;&#22312;&#23454;&#38469;&#20013;&#21462;&#24471;&#20102;&#22909;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#20855;&#26377;&#36172;&#21338;&#21453;&#39304;&#30340;&#38543;&#26426;&#29615;&#22659;&#20013;&#36827;&#34892;&#39034;&#24207;&#20915;&#31574;&#27169;&#22411;&#36873;&#25321;&#65292;&#20854;&#20013;&#20803;&#23398;&#20064;&#22120;&#21487;&#20197;&#20351;&#29992;&#19968;&#32452;&#22522;&#26412;&#23398;&#20064;&#22120;&#65292;&#24182;&#26681;&#25454;&#27599;&#20010;&#22522;&#26412;&#23398;&#20064;&#22120;&#25512;&#33616;&#30340;&#31574;&#30053;&#21160;&#24577;&#20915;&#31574;&#12290;&#25105;&#20204;&#36890;&#36807;&#36951;&#25022;&#24179;&#34913;&#26469;&#25191;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#20294;&#19982;&#27492;&#30456;&#20851;&#30340;&#26368;&#36817;&#25991;&#29486;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#27809;&#26377;&#20551;&#35774;&#20219;&#20309;&#20851;&#20110;&#22522;&#26412;&#23398;&#20064;&#22120;&#30340;&#20808;&#39564;&#30693;&#35782;&#65292;&#22914;&#20505;&#36873;&#36951;&#25022;&#20445;&#35777;&#65307;&#30456;&#21453;&#65292;&#25105;&#20204;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#25581;&#31034;&#36825;&#20123;&#25968;&#37327;&#12290;&#22240;&#27492;&#65292;&#20803;&#23398;&#20064;&#22120;&#33021;&#22815;&#21033;&#29992;&#27599;&#20010;&#22522;&#26412;&#23398;&#20064;&#22120;&#22312;&#32473;&#23450;&#30340;&#23398;&#20064;&#29615;&#22659;&#20013;&#20135;&#29983;&#30340;&#23454;&#38469;&#36951;&#25022;&#65288;&#32780;&#19981;&#26159;&#26399;&#26395;&#36951;&#25022;&#65289;&#65292;&#24182;&#25361;&#36873;&#20986;&#26368;&#20339;&#30340;&#36951;&#25022;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#20010;&#27169;&#22411;&#36873;&#25321;&#31639;&#27861;&#65292;&#25805;&#20316;&#26356;&#20026;&#38596;&#24515;&#21187;&#21187;&#30340;&#36951;&#25022;&#27010;&#24565;&#65292;&#24182;&#19988;&#38500;&#20102;&#36890;&#36807;&#36951;&#25022;&#24179;&#34913;&#35777;&#26126;&#27169;&#22411;&#36873;&#25321;&#20445;&#35777;&#22806;&#65292;&#25105;&#20204;&#36824;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#22788;&#29702;&#23454;&#38469;&#36951;&#25022;&#30340;&#20196;&#20154;&#20449;&#26381;&#30340;&#23454;&#38469;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider model selection for sequential decision making in stochastic environments with bandit feedback, where a meta-learner has at its disposal a pool of base learners, and decides on the fly which action to take based on the policies recommended by each base learner. Model selection is performed by regret balancing but, unlike the recent literature on this subject, we do not assume any prior knowledge about the base learners like candidate regret guarantees; instead, we uncover these quantities in a data-driven manner. The meta-learner is therefore able to leverage the realized regret incurred by each base learner for the learning environment at hand (as opposed to the expected regret), and single out the best such regret. We design two model selection algorithms operating with this more ambitious notion of regret and, besides proving model selection guarantees via regret balancing, we experimentally demonstrate the compelling practical benefits of dealing with actual regrets ins
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;Sparse Gaussian Process attention (SGPA)&#26469;&#26657;&#20934;Transformer&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;&#26041;&#27861;&#12290;&#22312;&#25991;&#26412;&#12289;&#22270;&#20687;&#21644;&#22270;&#24418;&#30340;&#39044;&#27979;&#20219;&#21153;&#20013;&#65292;SGPA-based Transformers&#22312;&#39044;&#27979;&#20934;&#30830;&#24615;&#19978;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#65292;&#24182;&#26174;&#33879;&#25913;&#21892;&#20102;&#20869;&#20998;&#24067;&#26657;&#20934;&#21644;&#22806;&#20998;&#24067;&#30340;&#40065;&#26834;&#24615;&#21644;&#26816;&#27979;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2303.02444</link><description>&lt;p&gt;
&#36890;&#36807;&#31232;&#30095;&#39640;&#26031;&#36807;&#31243;&#26657;&#20934;Transformer
&lt;/p&gt;
&lt;p&gt;
Calibrating Transformers via Sparse Gaussian Processes. (arXiv:2303.02444v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.02444
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;Sparse Gaussian Process attention (SGPA)&#26469;&#26657;&#20934;Transformer&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;&#26041;&#27861;&#12290;&#22312;&#25991;&#26412;&#12289;&#22270;&#20687;&#21644;&#22270;&#24418;&#30340;&#39044;&#27979;&#20219;&#21153;&#20013;&#65292;SGPA-based Transformers&#22312;&#39044;&#27979;&#20934;&#30830;&#24615;&#19978;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#65292;&#24182;&#26174;&#33879;&#25913;&#21892;&#20102;&#20869;&#20998;&#24067;&#26657;&#20934;&#21644;&#22806;&#20998;&#24067;&#30340;&#40065;&#26834;&#24615;&#21644;&#26816;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#27169;&#22411;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#12289;&#35821;&#38899;&#35782;&#21035;&#21644;&#35745;&#31639;&#26426;&#35270;&#35273;&#31561;&#24191;&#27867;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#23558;Transformer&#30340;&#25104;&#21151;&#25193;&#23637;&#21040;&#23433;&#20840;&#20851;&#38190;&#39046;&#22495;&#38656;&#35201;&#20934;&#30830;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#36825;&#26041;&#38754;&#30340;&#30740;&#31350;&#36739;&#23569;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31232;&#30095;&#39640;&#26031;&#36807;&#31243;&#27880;&#24847;&#21147;&#65288;SGPA&#65289;&#65292;&#23427;&#30452;&#25509;&#22312;Transformer&#30340;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#22359;&#65288;MHA&#65289;&#30340;&#36755;&#20986;&#31354;&#38388;&#20013;&#36827;&#34892;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#20197;&#26657;&#20934;&#20854;&#19981;&#30830;&#23450;&#24615;&#12290;&#23427;&#29992;&#19968;&#20010;&#26377;&#25928;&#30340;&#23545;&#31216;&#26680;&#26367;&#20195;&#20102;&#32553;&#25918;&#28857;&#31215;&#25805;&#20316;&#65292;&#24182;&#20351;&#29992;&#31232;&#30095;&#39640;&#26031;&#36807;&#31243;&#65288;SGP&#65289;&#25216;&#26415;&#26469;&#36817;&#20284;MHA&#36755;&#20986;&#30340;&#21518;&#39564;&#36807;&#31243;&#12290;&#32463;&#39564;&#19978;&#65292;&#22312;&#25991;&#26412;&#12289;&#22270;&#20687;&#21644;&#22270;&#24418;&#30340;&#19968;&#31995;&#21015;&#39044;&#27979;&#20219;&#21153;&#20013;&#65292;&#22522;&#20110;SGPA&#30340;Transformer&#27169;&#22411;&#23454;&#29616;&#20102;&#26377;&#31454;&#20105;&#21147;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#65292;&#21516;&#26102;&#26174;&#33879;&#25913;&#21892;&#20102;&#20869;&#20998;&#24067;&#26657;&#20934;&#21644;&#22806;&#20998;&#24067;&#30340;&#40065;&#26834;&#24615;&#21644;&#26816;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformer models have achieved profound success in prediction tasks in a wide range of applications in natural language processing, speech recognition and computer vision. Extending Transformer's success to safety-critical domains requires calibrated uncertainty estimation which remains under-explored. To address this, we propose Sparse Gaussian Process attention (SGPA), which performs Bayesian inference directly in the output space of multi-head attention blocks (MHAs) in transformer to calibrate its uncertainty. It replaces the scaled dot-product operation with a valid symmetric kernel and uses sparse Gaussian processes (SGP) techniques to approximate the posterior processes of MHA outputs. Empirically, on a suite of prediction tasks on text, images and graphs, SGPA-based Transformers achieve competitive predictive accuracy, while noticeably improving both in-distribution calibration and out-of-distribution robustness and detection.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#32479;&#35745;&#29289;&#29702;&#21644;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#20998;&#26512;&#24037;&#20855;&#65292;&#31934;&#30830;&#22320;&#34920;&#24449;&#20102;&#31616;&#21333;&#22270;&#21367;&#31215;&#32593;&#32476;&#22312;&#32972;&#26223;&#38543;&#26426;&#22359;&#27169;&#22411;&#19978;&#30340;&#27867;&#21270;&#65292;&#25552;&#20986;&#20102;&#21516;&#36136;&#24615;&#22312;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#27867;&#21270;&#20013;&#30340;&#35843;&#21046;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2212.13069</link><description>&lt;p&gt;
&#21516;&#36136;&#24615;&#22312;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#21452;&#19979;&#38477;&#27867;&#21270;&#20013;&#30340;&#35843;&#21046;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Homophily modulates double descent generalization in graph convolution networks. (arXiv:2212.13069v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.13069
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#32479;&#35745;&#29289;&#29702;&#21644;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#20998;&#26512;&#24037;&#20855;&#65292;&#31934;&#30830;&#22320;&#34920;&#24449;&#20102;&#31616;&#21333;&#22270;&#21367;&#31215;&#32593;&#32476;&#22312;&#32972;&#26223;&#38543;&#26426;&#22359;&#27169;&#22411;&#19978;&#30340;&#27867;&#21270;&#65292;&#25552;&#20986;&#20102;&#21516;&#36136;&#24615;&#22312;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#27867;&#21270;&#20013;&#30340;&#35843;&#21046;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#26159;&#29992;&#20110;&#20851;&#31995;&#25968;&#25454;&#38598;&#65288;&#22914;&#20195;&#35874;&#12289;&#20132;&#36890;&#21644;&#31038;&#20132;&#32593;&#32476;&#65289;&#30340;&#26368;&#25104;&#21151;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#23545;&#25968;&#25454;&#20013;&#32534;&#30721;&#30340;&#21508;&#31181;&#20132;&#20114;&#30340;&#24378;&#22823;&#27867;&#21270;&#30340;&#20915;&#23450;&#22240;&#32032;&#24182;&#19981;&#20026;&#20154;&#25152;&#30693;&#12290;&#26469;&#33258;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#30340;&#26041;&#27861;&#26080;&#27861;&#35299;&#37322;&#20986;&#29616;&#30340;&#29616;&#35937;&#65292;&#22914;&#21452;&#19979;&#38477;&#25110;&#39118;&#38505;&#21462;&#20915;&#20110;&#20132;&#20114;&#24615;&#36136;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#32479;&#35745;&#29289;&#29702;&#21644;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#20998;&#26512;&#24037;&#20855;&#26469;&#31934;&#30830;&#22320;&#34920;&#24449;&#31616;&#21333;&#22270;&#21367;&#31215;&#32593;&#32476;&#22312;&#32972;&#26223;&#38543;&#26426;&#22359;&#27169;&#22411;&#19978;&#30340;&#27867;&#21270;&#12290;&#23548;&#20986;&#30340;&#26354;&#32447;&#29616;&#35937;&#23398;&#19978;&#21313;&#20998;&#20016;&#23500;&#65306;&#23427;&#20204;&#35299;&#37322;&#20102;&#21516;&#36136;&#24615;&#21644;&#24322;&#36136;&#24615;&#23398;&#20064;&#20043;&#38388;&#30340;&#21306;&#21035;&#65292;&#24182;&#39044;&#27979;&#20102;&#26368;&#36817;&#20316;&#21697;&#25152;&#36136;&#30097;&#30340;GNN&#20013;&#21452;&#19979;&#38477;&#29616;&#35937;&#30340;&#23384;&#22312;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#39118;&#38505;&#22914;&#20309;&#21462;&#20915;&#20110;&#22270;&#20013;&#30340;&#22122;&#22768;&#12289;&#29305;&#24449;&#20013;&#30340;&#22122;&#22768;&#21644;&#29992;&#20110;&#35757;&#32451;&#30340;&#33410;&#28857;&#27604;&#20363;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#20026;&#29702;&#35299;&#21516;&#36136;&#24615;&#22914;&#20309;&#35843;&#21046;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#25552;&#20379;&#20102;&#31532;&#19968;&#27493;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks are among the most successful machine learning models for relational datasets like metabolic, transportation, and social networks. Yet the determinants of their strong generalization for diverse interactions encoded in the data are not well understood. Methods from statistical learning theory do not explain emergent phenomena such as double descent or the dependence of risk on the nature of interactions. We use analytical tools from statistical physics and random matrix theory to precisely characterize generalization in simple graph convolution networks on the contextual stochastic block model. The derived curves are phenomenologically rich: they explain the distinction between learning on homophilic and heterophilic and they predict double descent whose existence in GNNs has been questioned by recent work. We show how risk depends on the interplay between the noise in the graph, noise in the features, and the proportion of nodes used for training. Our analysis pr
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20351;&#29992;&#26631;&#20934;&#21270;&#27969;&#26469;&#35299;&#20915;&#36880;&#28176;&#39046;&#22495;&#36866;&#24212;&#20013;&#20013;&#38388;&#22495;&#26377;&#38480;&#19988;&#36317;&#31163;&#36739;&#22823;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#20174;&#28304;&#22495;&#21040;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#23398;&#20064;&#30446;&#26631;&#22495;&#30340;&#20998;&#24067;&#21464;&#25442;&#12290;</title><link>http://arxiv.org/abs/2206.11492</link><description>&lt;p&gt;
&#36890;&#36807;&#26631;&#20934;&#21270;&#27969;&#36827;&#34892;&#36880;&#28176;&#39046;&#22495;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
Gradual Domain Adaptation via Normalizing Flows. (arXiv:2206.11492v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.11492
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20351;&#29992;&#26631;&#20934;&#21270;&#27969;&#26469;&#35299;&#20915;&#36880;&#28176;&#39046;&#22495;&#36866;&#24212;&#20013;&#20013;&#38388;&#22495;&#26377;&#38480;&#19988;&#36317;&#31163;&#36739;&#22823;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#20174;&#28304;&#22495;&#21040;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#23398;&#20064;&#30446;&#26631;&#22495;&#30340;&#20998;&#24067;&#21464;&#25442;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#20043;&#38388;&#23384;&#22312;&#36739;&#22823;&#24046;&#36317;&#26102;&#65292;&#20256;&#32479;&#30340;&#39046;&#22495;&#36866;&#24212;&#26041;&#27861;&#25928;&#26524;&#19981;&#20339;&#12290;&#36880;&#28176;&#39046;&#22495;&#36866;&#24212;&#26159;&#35299;&#20915;&#35813;&#38382;&#39064;&#30340;&#19968;&#31181;&#26041;&#27861;&#65292;&#23427;&#28041;&#21450;&#21033;&#29992;&#36880;&#28176;&#20174;&#28304;&#22495;&#36716;&#31227;&#21040;&#30446;&#26631;&#22495;&#30340;&#20013;&#38388;&#22495;&#12290;&#22312;&#20808;&#21069;&#30340;&#24037;&#20316;&#20013;&#65292;&#20551;&#35774;&#20013;&#38388;&#22495;&#30340;&#25968;&#37327;&#36739;&#22823;&#19988;&#30456;&#37051;&#22495;&#20043;&#38388;&#30340;&#36317;&#31163;&#36739;&#23567;&#65292;&#22240;&#27492;&#65292;&#28041;&#21450;&#20351;&#29992;&#26080;&#26631;&#31614;&#25968;&#25454;&#38598;&#36827;&#34892;&#33258;&#25105;&#35757;&#32451;&#30340;&#36880;&#28176;&#39046;&#22495;&#36866;&#24212;&#31639;&#27861;&#26159;&#21487;&#34892;&#30340;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#36880;&#28176;&#33258;&#25105;&#35757;&#32451;&#23558;&#22833;&#36133;&#65292;&#22240;&#20026;&#20013;&#38388;&#22495;&#30340;&#25968;&#37327;&#26377;&#38480;&#19988;&#30456;&#37051;&#22495;&#20043;&#38388;&#30340;&#36317;&#31163;&#36739;&#22823;&#12290;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#26631;&#20934;&#21270;&#27969;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#21516;&#26102;&#20445;&#25345;&#26080;&#30417;&#30563;&#39046;&#22495;&#36866;&#24212;&#30340;&#26694;&#26550;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#36890;&#36807;&#20174;&#28304;&#22495;&#21040;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#23398;&#20064;&#30446;&#26631;&#22495;&#30340;&#20998;&#24067;&#21464;&#25442;&#12290;
&lt;/p&gt;
&lt;p&gt;
Standard domain adaptation methods do not work well when a large gap exists between the source and target domains. Gradual domain adaptation is one of the approaches used to address the problem. It involves leveraging the intermediate domain, which gradually shifts from the source domain to the target domain. In previous work, it is assumed that the number of intermediate domains is large and the distance between adjacent domains is small; hence, the gradual domain adaptation algorithm, involving self-training with unlabeled datasets, is applicable. In practice, however, gradual self-training will fail because the number of intermediate domains is limited and the distance between adjacent domains is large. We propose the use of normalizing flows to deal with this problem while maintaining the framework of unsupervised domain adaptation. The proposed method learns a transformation from the distribution of the target domain to the Gaussian mixture distribution via the source domain. We e
&lt;/p&gt;</description></item></channel></rss>