<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#26641;&#24230;&#37327;&#26377;&#22122;&#22768;&#30340;&#20248;&#21270;&#20256;&#36755;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#65292;&#35299;&#20915;&#20102;&#23454;&#38469;&#24212;&#29992;&#20013;&#26641;&#32467;&#26500;&#25200;&#21160;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.13653</link><description>&lt;p&gt;
&#37319;&#29992;&#26377;&#22122;&#22768;&#26641;&#24230;&#37327;&#30340;&#20248;&#21270;&#20256;&#36755;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Optimal Transport for Measures with Noisy Tree Metric. (arXiv:2310.13653v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13653
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#26641;&#24230;&#37327;&#26377;&#22122;&#22768;&#30340;&#20248;&#21270;&#20256;&#36755;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#65292;&#35299;&#20915;&#20102;&#23454;&#38469;&#24212;&#29992;&#20013;&#26641;&#32467;&#26500;&#25200;&#21160;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#26641;&#24230;&#37327;&#31354;&#38388;&#19978;&#25903;&#25345;&#30340;&#27010;&#29575;&#27979;&#24230;&#30340;&#20248;&#21270;&#20256;&#36755;&#65288;OT&#65289;&#38382;&#39064;&#12290;&#24050;&#30693;&#36825;&#31181;OT&#38382;&#39064;&#65288;&#21363;&#26641;-&#29926;&#29926;&#26031;&#22374;&#65288;TW&#65289;&#65289;&#20855;&#26377;&#38381;&#21512;&#24418;&#24335;&#34920;&#36798;&#24335;&#65292;&#20294;&#22522;&#26412;&#19978;&#21462;&#20915;&#20110;&#36755;&#20837;&#27979;&#24230;&#25903;&#25345;&#19978;&#30340;&#24213;&#23618;&#26641;&#32467;&#26500;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#38469;&#25805;&#20316;&#20013;&#65292;&#30001;&#20110;&#22122;&#22768;&#25110;&#23545;&#25239;&#24615;&#27979;&#37327;&#65292;&#32473;&#23450;&#30340;&#26641;&#32467;&#26500;&#21487;&#33021;&#20250;&#34987;&#25200;&#21160;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#37319;&#21462;&#20102;&#26368;&#22823;-&#26368;&#23567;&#40065;&#26834;OT&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#32771;&#34385;&#20102;&#22312;&#19968;&#20010;&#26641;&#24230;&#37327;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#19978;&#20004;&#20010;&#36755;&#20837;&#27979;&#24230;&#20043;&#38388;&#30340;&#26368;&#22823;&#21487;&#33021;&#36317;&#31163;&#12290;&#24635;&#20307;&#19978;&#35828;&#65292;&#30001;&#20110;&#20854;&#38750;&#20984;&#24615;&#21644;&#38750;&#20809;&#28369;&#24615;&#65292;&#36825;&#31181;&#26041;&#27861;&#24456;&#38590;&#35745;&#31639;&#65292;&#21363;&#20415;&#26159;&#22312;&#25903;&#25345;&#20026;1&#32500;&#31354;&#38388;&#30340;&#27979;&#24230;&#24773;&#20917;&#19979;&#65292;&#36825;&#22952;&#30861;&#20102;&#23427;&#30340;&#23454;&#38469;&#24212;&#29992;&#65292;&#29305;&#21035;&#26159;&#22312;&#22823;&#35268;&#27169;&#24773;&#26223;&#19979;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#36793;&#32536;&#21024;&#38500;/&#28155;&#21152;&#30340;&#35282;&#24230;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26641;&#24230;&#37327;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#65292;&#36825;&#20010;&#38598;&#21512;&#22312;&#19968;&#20010;&#20248;&#38597;&#30340;&#26694;&#26550;&#19979;&#28085;&#30422;&#20102;&#22810;&#26679;&#30340;&#26641;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study optimal transport (OT) problem for probability measures supported on a tree metric space. It is known that such OT problem (i.e., tree-Wasserstein (TW)) admits a closed-form expression, but depends fundamentally on the underlying tree structure over supports of input measures. In practice, the given tree structure may be, however, perturbed due to noisy or adversarial measurements. In order to mitigate this issue, we follow the max-min robust OT approach which considers the maximal possible distances between two input measures over an uncertainty set of tree metrics. In general, this approach is hard to compute, even for measures supported in $1$-dimensional space, due to its non-convexity and non-smoothness which hinders its practical applications, especially for large-scale settings. In this work, we propose \emph{novel uncertainty sets of tree metrics} from the lens of edge deletion/addition which covers a diversity of tree structures in an elegant framework. Consequently, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#22312;&#38750;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#19979;&#30340;&#22810;&#20219;&#21153;&#24378;&#21270;&#23398;&#20064;&#65292;&#35777;&#26126;&#20102;&#22810;&#20010;MDPs&#20043;&#38388;&#20849;&#20139;&#30340;&#28508;&#22312;&#32467;&#26500;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#37319;&#26679;&#25928;&#29575;&#12290;&#23545;&#20110;&#37096;&#20998;&#21487;&#35266;&#23519;MDPs&#21644;&#39044;&#27979;&#29366;&#24577;&#34920;&#31034;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32852;&#21512;&#27169;&#22411;&#31867;&#65292;&#24182;&#20351;&#29992;$\eta$-bracketing number&#26469;&#37327;&#21270;&#20854;&#22797;&#26434;&#24615;&#21644;&#20219;&#21153;&#30340;&#30456;&#20284;&#24615;&#65292;&#20174;&#32780;&#20915;&#23450;&#20102;&#22810;&#20219;&#21153;&#30456;&#36739;&#20110;&#21333;&#20219;&#21153;RL&#30340;&#21463;&#30410;&#12290;</title><link>http://arxiv.org/abs/2310.13550</link><description>&lt;p&gt;
&#22810;&#20219;&#21153;&#24378;&#21270;&#23398;&#20064;&#22312;&#38750;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#21487;&#35777;&#26126;&#21463;&#30410;
&lt;/p&gt;
&lt;p&gt;
Provable Benefits of Multi-task RL under Non-Markovian Decision Making Processes. (arXiv:2310.13550v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13550
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#22312;&#38750;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#19979;&#30340;&#22810;&#20219;&#21153;&#24378;&#21270;&#23398;&#20064;&#65292;&#35777;&#26126;&#20102;&#22810;&#20010;MDPs&#20043;&#38388;&#20849;&#20139;&#30340;&#28508;&#22312;&#32467;&#26500;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#37319;&#26679;&#25928;&#29575;&#12290;&#23545;&#20110;&#37096;&#20998;&#21487;&#35266;&#23519;MDPs&#21644;&#39044;&#27979;&#29366;&#24577;&#34920;&#31034;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32852;&#21512;&#27169;&#22411;&#31867;&#65292;&#24182;&#20351;&#29992;$\eta$-bracketing number&#26469;&#37327;&#21270;&#20854;&#22797;&#26434;&#24615;&#21644;&#20219;&#21153;&#30340;&#30456;&#20284;&#24615;&#65292;&#20174;&#32780;&#20915;&#23450;&#20102;&#22810;&#20219;&#21153;&#30456;&#36739;&#20110;&#21333;&#20219;&#21153;RL&#30340;&#21463;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#19979;&#30340;&#22810;&#20219;&#21153;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20013;&#65292;&#22810;&#20010;MDPs&#20043;&#38388;&#23384;&#22312;&#20849;&#20139;&#30340;&#28508;&#22312;&#32467;&#26500;&#24050;&#34987;&#35777;&#26126;&#30456;&#23545;&#20110;&#21333;&#20219;&#21153;RL&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#37319;&#26679;&#25928;&#29575;&#12290;&#26412;&#25991;&#30740;&#31350;&#36825;&#31181;&#21463;&#30410;&#26159;&#21542;&#33021;&#22815;&#25193;&#23637;&#21040;&#26356;&#19968;&#33324;&#30340;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#65292;&#22914;&#37096;&#20998;&#21487;&#35266;&#23519;MDPs&#65288;POMDPs&#65289;&#21644;&#26356;&#19968;&#33324;&#30340;&#39044;&#27979;&#29366;&#24577;&#34920;&#31034;&#65288;PSRs&#65289;&#12290;&#20027;&#35201;&#25361;&#25112;&#22312;&#20110;&#22823;&#22411;&#22797;&#26434;&#27169;&#22411;&#31354;&#38388;&#20351;&#24471;&#24456;&#38590;&#30830;&#23450;&#22810;&#20219;&#21153;PSRs&#30340;&#20849;&#21516;&#28508;&#22312;&#32467;&#26500;&#31867;&#22411;&#33021;&#22815;&#20943;&#23569;&#27169;&#22411;&#22797;&#26434;&#24615;&#24182;&#25552;&#39640;&#37319;&#26679;&#25928;&#29575;&#12290;&#20026;&#20102;&#36798;&#21040;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#20551;&#35774;&#20102;&#19968;&#20010;&#29992;&#20110;&#20219;&#21153;&#30340;&#32852;&#21512;&#27169;&#22411;&#31867;&#65292;&#24182;&#20351;&#29992;$\eta$-bracketing number&#26469;&#37327;&#21270;&#20854;&#22797;&#26434;&#24615;&#65307;&#36825;&#20010;&#25968;&#20063;&#20316;&#20026;&#19968;&#20010;&#36890;&#29992;&#25351;&#26631;&#26469;&#25429;&#25417;&#20219;&#21153;&#30340;&#30456;&#20284;&#24615;&#65292;&#20174;&#32780;&#20915;&#23450;&#20102;&#22810;&#20219;&#21153;&#30456;&#36739;&#20110;&#21333;&#20219;&#21153;RL&#30340;&#21463;&#30410;&#12290;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#20102;&#19978;&#28216;&#22810;&#20219;&#21153;&#23398;&#20064;&#22312;PSRs&#19978;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In multi-task reinforcement learning (RL) under Markov decision processes (MDPs), the presence of shared latent structures among multiple MDPs has been shown to yield significant benefits to the sample efficiency compared to single-task RL. In this paper, we investigate whether such a benefit can extend to more general sequential decision making problems, such as partially observable MDPs (POMDPs) and more general predictive state representations (PSRs). The main challenge here is that the large and complex model space makes it hard to identify what types of common latent structure of multi-task PSRs can reduce the model complexity and improve sample efficiency. To this end, we posit a joint model class for tasks and use the notion of $\eta$-bracketing number to quantify its complexity; this number also serves as a general metric to capture the similarity of tasks and thus determines the benefit of multi-task over single-task RL. We first study upstream multi-task learning over PSRs, i
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#35757;&#32451;&#39640;&#36136;&#37327;AI&#21161;&#25163;&#30340;&#25216;&#26415;&#65292;&#21457;&#29616;&#36825;&#31181;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#22312;&#22238;&#31572;&#38382;&#39064;&#26102;&#36807;&#20110;&#35844;&#23194;&#65292;&#32780;&#19981;&#26159;&#22374;&#35802;&#65292;&#36890;&#36807;&#20998;&#26512;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#24471;&#20986;&#20102;&#36825;&#19968;&#32467;&#35770;&#12290;</title><link>http://arxiv.org/abs/2310.13548</link><description>&lt;p&gt;
&#25506;&#32034;&#35821;&#35328;&#27169;&#22411;&#20013;&#35844;&#23194;&#34892;&#20026;&#30340;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Towards Understanding Sycophancy in Language Models. (arXiv:2310.13548v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13548
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#35757;&#32451;&#39640;&#36136;&#37327;AI&#21161;&#25163;&#30340;&#25216;&#26415;&#65292;&#21457;&#29616;&#36825;&#31181;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#22312;&#22238;&#31572;&#38382;&#39064;&#26102;&#36807;&#20110;&#35844;&#23194;&#65292;&#32780;&#19981;&#26159;&#22374;&#35802;&#65292;&#36890;&#36807;&#20998;&#26512;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#24471;&#20986;&#20102;&#36825;&#19968;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#12300;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;&#65288;RLHF&#65289;&#12301;&#26159;&#35757;&#32451;&#39640;&#36136;&#37327;AI&#21161;&#25163;&#30340;&#19968;&#31181;&#27969;&#34892;&#25216;&#26415;&#12290;&#28982;&#32780;&#65292;RLHF&#21487;&#33021;&#20250;&#40723;&#21169;&#27169;&#22411;&#36890;&#36807;&#19982;&#29992;&#25143;&#20449;&#24565;&#30456;&#31526;&#30340;&#22238;&#31572;&#26469;&#20195;&#26367;&#30495;&#23454;&#22238;&#31572;&#65292;&#36825;&#31181;&#34892;&#20026;&#34987;&#31216;&#20026;&#35844;&#23194;&#34892;&#20026;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;RLHF&#35757;&#32451;&#27169;&#22411;&#20013;&#35844;&#23194;&#34892;&#20026;&#30340;&#26222;&#36941;&#24615;&#20197;&#21450;&#20154;&#31867;&#20559;&#22909;&#21028;&#26029;&#26159;&#21542;&#36215;&#21040;&#20102;&#20316;&#29992;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20116;&#20010;&#26368;&#20808;&#36827;&#30340;AI&#21161;&#25163;&#22312;&#22235;&#20010;&#19981;&#21516;&#30340;&#33258;&#30001;&#25991;&#26412;&#29983;&#25104;&#20219;&#21153;&#20013;&#19968;&#36143;&#34920;&#29616;&#20986;&#35844;&#23194;&#34892;&#20026;&#12290;&#20026;&#20102;&#29702;&#35299;&#20154;&#31867;&#20559;&#22909;&#26159;&#21542;&#39537;&#21160;&#20102;RLHF&#27169;&#22411;&#30340;&#36825;&#31181;&#24191;&#27867;&#34892;&#20026;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#29616;&#26377;&#30340;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#24403;&#22238;&#31572;&#19982;&#29992;&#25143;&#30340;&#35266;&#28857;&#30456;&#31526;&#26102;&#65292;&#23427;&#26356;&#26377;&#21487;&#33021;&#34987;&#36873;&#20013;&#12290;&#27492;&#22806;&#65292;&#20154;&#31867;&#21644;&#20559;&#22909;&#27169;&#22411;&#65288;PMs&#65289;&#23558;&#26377;&#35828;&#26381;&#21147;&#30340;&#35844;&#23194;&#22238;&#31572;&#19982;&#27491;&#30830;&#22238;&#31572;&#30456;&#27604;&#65292;&#26377;&#26102;&#20960;&#20046;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#22320;&#36873;&#25321;&#20102;&#35844;&#23194;&#22238;&#31572;&#12290;&#20248;&#21270;&#27169;&#22411;&#36755;&#20986;&#20197;&#28385;&#36275;PMs&#26377;&#26102;&#20063;&#20250;&#22312;&#30495;&#23454;&#24615;&#21644;&#35844;&#23194;&#34892;&#20026;&#20043;&#38388;&#20570;&#20986;&#21462;&#33293;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning from human feedback (RLHF) is a popular technique for training high-quality AI assistants. However, RLHF may also encourage model responses that match user beliefs over truthful responses, a behavior known as sycophancy. We investigate the prevalence of sycophancy in RLHF-trained models and whether human preference judgements are responsible. We first demonstrate that five state-of-the-art AI assistants consistently exhibit sycophantic behavior across four varied free-form text-generation tasks. To understand if human preferences drive this broadly observed behavior of RLHF models, we analyze existing human preference data. We find that when a response matches a user's views, it is more likely to be preferred. Moreover, both humans and preference models (PMs) prefer convincingly-written sycophantic responses over correct ones a negligible fraction of the time. Optimizing model outputs against PMs also sometimes sacrifices truthfulness in favor of sycophancy. Over
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27979;&#37327;&#30340;&#21464;&#20998;&#37327;&#23376;&#35745;&#31639;&#31639;&#27861;&#65292;&#23558;&#37327;&#23376;&#27979;&#37327;&#30340;&#38543;&#26426;&#24615;&#35270;&#20026;&#35745;&#31639;&#36164;&#28304;&#65292;&#24182;&#24212;&#29992;&#20110;&#29983;&#25104;&#24314;&#27169;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2310.13524</link><description>&lt;p&gt;
&#22522;&#20110;&#27979;&#37327;&#30340;&#21464;&#20998;&#37327;&#23376;&#35745;&#31639;&#29992;&#20110;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Variational measurement-based quantum computation for generative modeling. (arXiv:2310.13524v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13524
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27979;&#37327;&#30340;&#21464;&#20998;&#37327;&#23376;&#35745;&#31639;&#31639;&#27861;&#65292;&#23558;&#37327;&#23376;&#27979;&#37327;&#30340;&#38543;&#26426;&#24615;&#35270;&#20026;&#35745;&#31639;&#36164;&#28304;&#65292;&#24182;&#24212;&#29992;&#20110;&#29983;&#25104;&#24314;&#27169;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27979;&#37327;&#30340;&#37327;&#23376;&#35745;&#31639;&#65288;MBQC&#65289;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#26412;&#29420;&#29305;&#30340;&#33539;&#20363;&#26469;&#35774;&#35745;&#37327;&#23376;&#31639;&#27861;&#12290;&#22312;MBQC&#20013;&#65292;&#30001;&#20110;&#37327;&#23376;&#27979;&#37327;&#30340;&#22266;&#26377;&#38543;&#26426;&#24615;&#65292;&#33258;&#28982;&#30340;&#25805;&#20316;&#19981;&#26159;&#30830;&#23450;&#24615;&#21644;&#24186;&#27491;&#30340;&#65292;&#32780;&#26159;&#36890;&#36807;&#27010;&#29575;&#38468;&#24102;&#30340;&#12290;&#28982;&#32780;&#65292;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;MBQC&#30340;&#20027;&#35201;&#31639;&#27861;&#24212;&#29992;&#26159;&#23436;&#20840;&#25269;&#28040;&#36825;&#31181;&#27010;&#29575;&#24615;&#36136;&#65292;&#20197;&#27169;&#25311;&#34920;&#36798;&#22312;&#30005;&#36335;&#27169;&#22411;&#20013;&#30340;&#24186;&#27491;&#35745;&#31639;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35774;&#35745;MBQC&#31639;&#27861;&#30340;&#24605;&#36335;&#65292;&#35813;&#31639;&#27861;&#25509;&#21463;&#36825;&#31181;&#22266;&#26377;&#38543;&#26426;&#24615;&#65292;&#24182;&#23558;MBQC&#20013;&#30340;&#38543;&#26426;&#38468;&#24102;&#35270;&#20026;&#35745;&#31639;&#36164;&#28304;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#38543;&#26426;&#24615;&#26377;&#30410;&#30340;&#33258;&#28982;&#24212;&#29992;&#65292;&#21363;&#29983;&#25104;&#24314;&#27169;&#65292;&#36825;&#26159;&#19968;&#20010;&#20197;&#29983;&#25104;&#22797;&#26434;&#27010;&#29575;&#20998;&#24067;&#20026;&#20013;&#24515;&#30340;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#20219;&#21153;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20855;&#26377;&#25511;&#21046;&#21442;&#25968;&#30340;&#21464;&#20998;MBQC&#31639;&#27861;&#65292;&#21487;&#20197;&#30452;&#25509;&#35843;&#25972;&#20801;&#35768;&#22312;&#35745;&#31639;&#20013;&#24341;&#20837;&#30340;&#38543;&#26426;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Measurement-based quantum computation (MBQC) offers a fundamentally unique paradigm to design quantum algorithms. Indeed, due to the inherent randomness of quantum measurements, the natural operations in MBQC are not deterministic and unitary, but are rather augmented with probabilistic byproducts. Yet, the main algorithmic use of MBQC so far has been to completely counteract this probabilistic nature in order to simulate unitary computations expressed in the circuit model. In this work, we propose designing MBQC algorithms that embrace this inherent randomness and treat the random byproducts in MBQC as a resource for computation. As a natural application where randomness can be beneficial, we consider generative modeling, a task in machine learning centered around generating complex probability distributions. To address this task, we propose a variational MBQC algorithm equipped with control parameters that allow to directly adjust the degree of randomness to be admitted in the comput
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#26694;&#26550;&#65292;&#22312;&#20302;&#23494;&#24230;&#20998;&#31163;&#20551;&#35774;&#19979;&#20998;&#26512;&#39640;&#32500;&#24773;&#20917;&#19979;&#30340;&#21322;&#30417;&#30563;&#20998;&#31867;&#65292;&#24182;&#20171;&#32461;&#20102;QLDS&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#24179;&#34913;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#20043;&#38388;&#24314;&#31435;&#20102;&#19968;&#20010;&#24179;&#28369;&#30340;&#26725;&#26753;&#12290;&#36890;&#36807;&#24212;&#29992;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#22312;&#28176;&#36817;&#24773;&#20917;&#19979;&#20998;&#31867;&#38169;&#35823;&#30340;&#29702;&#35770;&#35780;&#20272;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#25214;&#21040;&#26368;&#20339;&#24179;&#34913;&#28857;&#30340;&#36229;&#21442;&#25968;&#36873;&#25321;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2310.13434</link><description>&lt;p&gt;
&#38543;&#26426;&#30697;&#38453;&#20998;&#26512;&#22312;&#20302;&#23494;&#24230;&#20998;&#31163;&#20551;&#35774;&#19979;&#24179;&#34913;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#20043;&#38388;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Random Matrix Analysis to Balance between Supervised and Unsupervised Learning under the Low Density Separation Assumption. (arXiv:2310.13434v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13434
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#26694;&#26550;&#65292;&#22312;&#20302;&#23494;&#24230;&#20998;&#31163;&#20551;&#35774;&#19979;&#20998;&#26512;&#39640;&#32500;&#24773;&#20917;&#19979;&#30340;&#21322;&#30417;&#30563;&#20998;&#31867;&#65292;&#24182;&#20171;&#32461;&#20102;QLDS&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#24179;&#34913;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#20043;&#38388;&#24314;&#31435;&#20102;&#19968;&#20010;&#24179;&#28369;&#30340;&#26725;&#26753;&#12290;&#36890;&#36807;&#24212;&#29992;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#22312;&#28176;&#36817;&#24773;&#20917;&#19979;&#20998;&#31867;&#38169;&#35823;&#30340;&#29702;&#35770;&#35780;&#20272;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#25214;&#21040;&#26368;&#20339;&#24179;&#34913;&#28857;&#30340;&#36229;&#21442;&#25968;&#36873;&#25321;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#26512;&#39640;&#32500;&#24773;&#20917;&#19979;&#20302;&#23494;&#24230;&#20998;&#31163;&#20551;&#35774;&#19979;&#30340;&#21322;&#30417;&#30563;&#20998;&#31867;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;QLDS&#65292;&#19968;&#20010;&#32447;&#24615;&#20998;&#31867;&#27169;&#22411;&#65292;&#20854;&#20013;&#36890;&#36807;&#20108;&#27425;&#36793;&#30028;&#26368;&#22823;&#21270;&#26469;&#23454;&#29616;&#20302;&#23494;&#24230;&#20998;&#31163;&#20551;&#35774;&#12290;&#35813;&#31639;&#27861;&#20855;&#26377;&#26126;&#30830;&#30340;&#35299;&#21644;&#20016;&#23500;&#30340;&#29702;&#35770;&#23646;&#24615;&#65292;&#24182;&#19988;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#31639;&#27861;&#30340;&#29305;&#27530;&#24773;&#20917;&#26159;&#30417;&#30563;&#24773;&#20917;&#19979;&#30340;&#26368;&#23567;&#20108;&#20056;&#25903;&#25345;&#21521;&#37327;&#26426;&#65292;&#23436;&#20840;&#26080;&#30417;&#30563;&#24773;&#20917;&#19979;&#30340;&#35889;&#32858;&#31867;&#65292;&#20197;&#21450;&#19968;&#31867;&#21322;&#30417;&#30563;&#30340;&#22522;&#20110;&#22270;&#30340;&#26041;&#27861;&#12290;&#22240;&#27492;&#65292;QLDS&#22312;&#36825;&#20123;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#20043;&#38388;&#24314;&#31435;&#20102;&#19968;&#20010;&#24179;&#28369;&#30340;&#26725;&#26753;&#12290;&#21033;&#29992;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#25105;&#20204;&#27491;&#24335;&#25512;&#23548;&#20102;&#22312;&#28176;&#36817;&#24773;&#20917;&#19979;&#30340;&#20998;&#31867;&#35823;&#24046;&#30340;&#29702;&#35770;&#35780;&#20272;&#12290;&#20316;&#20026;&#19968;&#20010;&#24212;&#29992;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#31181;&#36229;&#21442;&#25968;&#36873;&#25321;&#31574;&#30053;&#65292;&#20197;&#25214;&#21040;&#26368;&#20339;&#30340;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#20043;&#38388;&#30340;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a theoretical framework to analyze semi-supervised classification under the low density separation assumption in a high-dimensional regime. In particular, we introduce QLDS, a linear classification model, where the low density separation assumption is implemented via quadratic margin maximization. The algorithm has an explicit solution with rich theoretical properties, and we show that particular cases of our algorithm are the least-square support vector machine in the supervised case, the spectral clustering in the fully unsupervised regime, and a class of semi-supervised graph-based approaches. As such, QLDS establishes a smooth bridge between these supervised and unsupervised learning methods. Using recent advances in the random matrix theory, we formally derive a theoretical evaluation of the classification error in the asymptotic regime. As an application, we derive a hyperparameter selection policy that finds the best balance between the supervised and the unsupervised
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#26465;&#20214;Wasserstein&#36317;&#31163;&#36924;&#36817;&#21518;&#39564;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#32452;&#21463;&#38480;&#32806;&#21512;&#26469;&#35745;&#31639;&#21518;&#39564;&#20998;&#24067;&#30340;&#26399;&#26395;Wasserstein&#36317;&#31163;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#20854;&#23545;&#20598;&#24418;&#24335;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#21518;&#39564;&#37319;&#26679;&#26041;&#38754;&#30340;&#26377;&#21033;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2310.13433</link><description>&lt;p&gt;
Y-&#23545;&#35282;&#32447;&#32806;&#21512;: &#29992;&#26465;&#20214;Wasserstein&#36317;&#31163;&#36924;&#36817;&#21518;&#39564;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Y-Diagonal Couplings: Approximating Posteriors with Conditional Wasserstein Distances. (arXiv:2310.13433v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13433
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#26465;&#20214;Wasserstein&#36317;&#31163;&#36924;&#36817;&#21518;&#39564;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#32452;&#21463;&#38480;&#32806;&#21512;&#26469;&#35745;&#31639;&#21518;&#39564;&#20998;&#24067;&#30340;&#26399;&#26395;Wasserstein&#36317;&#31163;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#20854;&#23545;&#20598;&#24418;&#24335;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#21518;&#39564;&#37319;&#26679;&#26041;&#38754;&#30340;&#26377;&#21033;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36870;&#38382;&#39064;&#20013;&#65292;&#35768;&#22810;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#36890;&#36807;&#26368;&#23567;&#21270;&#32852;&#21512;&#20998;&#24067;&#19982;&#20854;&#23398;&#20064;&#21040;&#30340;&#36817;&#20284;&#20043;&#38388;&#30340;&#36317;&#31163;&#26469;&#36924;&#36817;&#21518;&#39564;&#27979;&#24230;&#12290;&#34429;&#28982;&#36825;&#31181;&#26041;&#27861;&#22312;Kullback Leibler&#25955;&#24230;&#30340;&#24773;&#20917;&#19979;&#20063;&#21487;&#20197;&#25511;&#21046;&#21518;&#39564;&#27979;&#24230;&#20043;&#38388;&#30340;&#36317;&#31163;&#65292;&#20294;&#23545;&#20110;Wasserstein&#36317;&#31163;&#26469;&#35828;&#21364;&#19981;&#25104;&#31435;&#12290;&#25105;&#20204;&#23558;&#24341;&#20837;&#19968;&#31181;&#24102;&#26377;&#19968;&#32452;&#21463;&#38480;&#32806;&#21512;&#30340;&#26465;&#20214;Wasserstein&#36317;&#31163;&#65292;&#23427;&#31561;&#20110;&#21518;&#39564;&#20998;&#24067;&#30340;&#26399;&#26395;Wasserstein&#36317;&#31163;&#12290;&#36890;&#36807;&#25512;&#23548;&#20854;&#23545;&#20598;&#24418;&#24335;&#65292;&#25105;&#20204;&#25214;&#21040;&#20102;&#19968;&#31181;&#20005;&#26684;&#30340;&#26041;&#24335;&#26469;&#35299;&#37322;&#26465;&#20214;Wasserstein GANs&#30340;&#25439;&#22833;&#12290;&#25105;&#20204;&#27010;&#36848;&#20102;&#20351;&#24471;&#24120;&#35268;Wasserstein&#36317;&#31163;&#21644;&#26465;&#20214;Wasserstein&#36317;&#31163;&#30456;&#31561;&#30340;&#26465;&#20214;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#23637;&#31034;&#20351;&#29992;&#26465;&#20214;Wasserstein&#36317;&#31163;&#36827;&#34892;&#35757;&#32451;&#22312;&#21518;&#39564;&#37319;&#26679;&#26041;&#38754;&#20855;&#26377;&#26377;&#21033;&#30340;&#24615;&#36136;&#30340;&#25968;&#20540;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
In inverse problems, many conditional generative models approximate the posterior measure by minimizing a distance between the joint measure and its learned approximation. While this approach also controls the distance between the posterior measures in the case of the Kullback Leibler divergence, it does not hold true for the Wasserstein distance. We will introduce a conditional Wasserstein distance with a set of restricted couplings that equals the expected Wasserstein distance of the posteriors. By deriving its dual, we find a rigorous way to motivate the loss of conditional Wasserstein GANs. We outline conditions under which the vanilla and the conditional Wasserstein distance coincide. Furthermore, we will show numerical examples where training with the conditional Wasserstein distance yields favorable properties for posterior sampling.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#36873;&#23450;&#30340;&#25674;&#38144;SBI&#25216;&#26415;&#30340;&#31070;&#32463;&#27169;&#22411;&#30340;&#35757;&#32451;&#30446;&#26631;&#20013;&#28155;&#21152;&#26657;&#20934;&#39033;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#29616;&#26377;&#31639;&#27861;&#20135;&#29983;&#36807;&#20110;&#33258;&#20449;&#30340;&#21518;&#39564;&#27010;&#29575;&#30340;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#29616;&#26377;&#30340;&#35745;&#31639;&#27969;&#31243;&#65292;&#23454;&#29616;&#21487;&#38752;&#30340;&#40657;&#30418;&#21518;&#39564;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2310.13402</link><description>&lt;p&gt;
&#20351;&#29992;&#21487;&#24494;&#35206;&#30422;&#27010;&#29575;&#26657;&#20934;&#31070;&#32463;&#20223;&#30495;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Calibrating Neural Simulation-Based Inference with Differentiable Coverage Probability. (arXiv:2310.13402v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13402
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#36873;&#23450;&#30340;&#25674;&#38144;SBI&#25216;&#26415;&#30340;&#31070;&#32463;&#27169;&#22411;&#30340;&#35757;&#32451;&#30446;&#26631;&#20013;&#28155;&#21152;&#26657;&#20934;&#39033;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#29616;&#26377;&#31639;&#27861;&#20135;&#29983;&#36807;&#20110;&#33258;&#20449;&#30340;&#21518;&#39564;&#27010;&#29575;&#30340;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#29616;&#26377;&#30340;&#35745;&#31639;&#27969;&#31243;&#65292;&#23454;&#29616;&#21487;&#38752;&#30340;&#40657;&#30418;&#21518;&#39564;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#25512;&#29702;&#20801;&#35768;&#22312;&#32473;&#23450;&#20808;&#39564;&#20449;&#24687;&#21644;&#35777;&#25454;&#30340;&#20284;&#28982;&#30340;&#27010;&#29575;&#27169;&#22411;&#19979;&#34920;&#36798;&#21518;&#39564;&#20449;&#24565;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#20027;&#35201;&#26159;&#36890;&#36807;&#27169;&#25311;&#22120;&#38544;&#24335;&#24314;&#31435;&#30340;&#20284;&#28982;&#20989;&#25968;&#38656;&#35201;&#36827;&#34892;&#22522;&#20110;&#20223;&#30495;&#30340;&#25512;&#29702;(SBI)&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#31639;&#27861;&#21487;&#33021;&#20135;&#29983;&#36807;&#20110;&#33258;&#20449;&#30340;&#21518;&#39564;&#27010;&#29575;(Hermans&#31561;&#65292;2022)&#65292;&#22914;&#26524;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#19981;&#20934;&#30830;&#65292;&#23558;&#20987;&#36133;&#25972;&#20010;&#21487;&#20449;&#24615;&#30340;&#30446;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#22312;&#36873;&#23450;&#30340;&#25674;&#38144;SBI&#25216;&#26415;&#30340;&#31070;&#32463;&#27169;&#22411;&#30340;&#35757;&#32451;&#30446;&#26631;&#20013;&#30452;&#25509;&#21253;&#21547;&#19968;&#20010;&#26657;&#20934;&#39033;&#12290;&#36890;&#36807;&#24341;&#20837;&#23545;&#32463;&#20856;&#26657;&#20934;&#38169;&#35823;&#20844;&#24335;&#30340;&#26494;&#24347;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#31471;&#21040;&#31471;&#30340;&#21453;&#21521;&#20256;&#25773;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#19981;&#23616;&#38480;&#20110;&#20219;&#20309;&#29305;&#23450;&#30340;&#31070;&#32463;&#27169;&#22411;&#65292;&#24182;&#24102;&#26469;&#36866;&#24230;&#30340;&#35745;&#31639;&#24320;&#38144;&#12290;&#23427;&#30452;&#25509;&#36866;&#29992;&#20110;&#29616;&#26377;&#30340;&#35745;&#31639;&#27969;&#31243;&#65292;&#23454;&#29616;&#21487;&#38752;&#30340;&#40657;&#30418;&#21518;&#39564;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian inference allows expressing the uncertainty of posterior belief under a probabilistic model given prior information and the likelihood of the evidence. Predominantly, the likelihood function is only implicitly established by a simulator posing the need for simulation-based inference (SBI). However, the existing algorithms can yield overconfident posteriors (Hermans *et al.*, 2022) defeating the whole purpose of credibility if the uncertainty quantification is inaccurate. We propose to include a calibration term directly into the training objective of the neural model in selected amortized SBI techniques. By introducing a relaxation of the classical formulation of calibration error we enable end-to-end backpropagation. The proposed method is not tied to any particular neural model and brings moderate computational overhead compared to the profits it introduces. It is directly applicable to existing computational pipelines allowing reliable black-box posterior inference. We empi
&lt;/p&gt;</description></item><item><title>&#22312;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20197;&#22266;&#23450;&#32622;&#20449;&#24230;&#36827;&#34892;&#26368;&#20248;&#33218;&#35782;&#21035;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#26469;&#35782;&#21035;&#20855;&#26377;&#26368;&#22823;&#24179;&#22343;&#20540;&#30340;&#33218;&#65292;&#21516;&#26102;&#38480;&#21046;&#20102;&#20915;&#31574;&#38169;&#35823;&#30340;&#27010;&#29575;&#65292;&#24182;&#24314;&#31435;&#20102;&#20572;&#27490;&#26102;&#38388;&#22686;&#38271;&#29575;&#30340;&#19979;&#30028;&#12290;</title><link>http://arxiv.org/abs/2310.13393</link><description>&lt;p&gt;
&#22312;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#20197;&#22266;&#23450;&#32622;&#20449;&#24230;&#36827;&#34892;&#26368;&#20248;&#33218;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Optimal Best Arm Identification with Fixed Confidence in Restless Bandits. (arXiv:2310.13393v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13393
&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20197;&#22266;&#23450;&#32622;&#20449;&#24230;&#36827;&#34892;&#26368;&#20248;&#33218;&#35782;&#21035;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#26469;&#35782;&#21035;&#20855;&#26377;&#26368;&#22823;&#24179;&#22343;&#20540;&#30340;&#33218;&#65292;&#21516;&#26102;&#38480;&#21046;&#20102;&#20915;&#31574;&#38169;&#35823;&#30340;&#27010;&#29575;&#65292;&#24182;&#24314;&#31435;&#20102;&#20572;&#27490;&#26102;&#38388;&#22686;&#38271;&#29575;&#30340;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#20855;&#26377;&#26377;&#38480;&#25968;&#30446;&#33218;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#20197;&#19981;&#26029;&#21464;&#21270;&#30340;&#24418;&#24335;&#36827;&#34892;&#26368;&#20248;&#33218;&#35782;&#21035;&#12290;&#27599;&#20010;&#33218;&#20135;&#29983;&#30340;&#31163;&#25955;&#26102;&#38388;&#25968;&#25454;&#24418;&#25104;&#20102;&#19968;&#20010;&#21462;&#20540;&#22312;&#20849;&#21516;&#12289;&#26377;&#38480;&#29366;&#24577;&#31354;&#38388;&#20013;&#30340;&#21516;&#36136;&#39532;&#23572;&#21487;&#22827;&#38142;&#12290;&#27599;&#20010;&#33218;&#30340;&#29366;&#24577;&#36716;&#31227;&#30001;&#19968;&#20010;&#36981;&#24490;&#21333;&#21442;&#25968;&#25351;&#25968;&#26063;&#30340;&#36716;&#31227;&#27010;&#29575;&#30697;&#38453;&#65288;TPM&#65289;&#25429;&#33719;&#12290;&#27599;&#20010;&#33218;&#30340;TPM&#30340;&#23454;&#20540;&#21442;&#25968;&#26159;&#26410;&#30693;&#30340;&#65292;&#23646;&#20110;&#32473;&#23450;&#31354;&#38388;&#12290;&#32473;&#23450;&#22312;&#33218;&#30340;&#20849;&#21516;&#29366;&#24577;&#31354;&#38388;&#19978;&#23450;&#20041;&#30340;&#20989;&#25968;f&#65292;&#30446;&#26631;&#26159;&#22312;&#26679;&#26412;&#25968;&#26368;&#23569;&#30340;&#24773;&#20917;&#19979;&#35782;&#21035;&#26368;&#20248;&#33218;&#65292;&#21363;&#22312;&#35813;&#33218;&#30340;&#31283;&#24577;&#20998;&#24067;&#19979;&#35780;&#20272;f&#30340;&#24179;&#22343;&#20540;&#26368;&#22823;&#30340;&#33218;&#65292;&#21516;&#26102;&#28385;&#36275;&#23545;&#20915;&#31574;&#38169;&#35823;&#27010;&#29575;&#65288;&#21363;&#22266;&#23450;&#32622;&#20449;&#24230;&#21306;&#38388;&#65289;&#30340;&#19978;&#30028;&#12290;&#22312;&#28176;&#36827;&#24615;&#30340;&#35823;&#24046;&#27010;&#29575;&#36235;&#20110;&#38646;&#30340;&#24773;&#20917;&#19979;&#65292;&#24314;&#31435;&#20102;&#26399;&#26395;&#20572;&#27490;&#26102;&#38388;&#22686;&#38271;&#29575;&#30340;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#20248;&#33218;&#35782;&#21035;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study best arm identification in a restless multi-armed bandit setting with finitely many arms. The discrete-time data generated by each arm forms a homogeneous Markov chain taking values in a common, finite state space. The state transitions in each arm are captured by an ergodic transition probability matrix (TPM) that is a member of a single-parameter exponential family of TPMs. The real-valued parameters of the arm TPMs are unknown and belong to a given space. Given a function $f$ defined on the common state space of the arms, the goal is to identify the best arm -- the arm with the largest average value of $f$ evaluated under the arm's stationary distribution -- with the fewest number of samples, subject to an upper bound on the decision's error probability (i.e., the fixed-confidence regime). A lower bound on the growth rate of the expected stopping time is established in the asymptote of a vanishing error probability. Furthermore, a policy for best arm identification is propo
&lt;/p&gt;</description></item><item><title>DeepFDR&#26159;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#34394;&#35686;&#25511;&#21046;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#26080;&#30417;&#30563;&#30340;&#22270;&#20687;&#20998;&#21106;&#25216;&#26415;&#35299;&#20915;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#20013;&#30340;&#22810;&#37325;&#26816;&#39564;&#38382;&#39064;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20854;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#20855;&#26377;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.13349</link><description>&lt;p&gt;
DeepFDR&#65306;&#19968;&#31181;&#29992;&#20110;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#30340;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#34394;&#35686;&#25511;&#21046;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
DeepFDR: A Deep Learning-based False Discovery Rate Control Method for Neuroimaging Data. (arXiv:2310.13349v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13349
&lt;/p&gt;
&lt;p&gt;
DeepFDR&#26159;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#34394;&#35686;&#25511;&#21046;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#26080;&#30417;&#30563;&#30340;&#22270;&#20687;&#20998;&#21106;&#25216;&#26415;&#35299;&#20915;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#20013;&#30340;&#22810;&#37325;&#26816;&#39564;&#38382;&#39064;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20854;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#20855;&#26377;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20307;&#32032;&#30340;&#22810;&#37325;&#26816;&#39564;&#22312;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#20998;&#26512;&#20013;&#24191;&#27867;&#24212;&#29992;&#12290;&#20256;&#32479;&#30340;&#34394;&#35686;&#25511;&#21046;&#26041;&#27861;&#24120;&#24120;&#24573;&#35270;&#22522;&#20110;&#20307;&#32032;&#30340;&#26816;&#39564;&#20043;&#38388;&#30340;&#31354;&#38388;&#30456;&#20851;&#24615;&#65292;&#20174;&#32780;&#23548;&#33268;&#27979;&#35797;&#33021;&#21147;&#30340;&#22823;&#24133;&#25439;&#22833;&#12290;&#34429;&#28982;&#26368;&#36817;&#20986;&#29616;&#20102;&#19968;&#20123;&#31354;&#38388;&#34394;&#35686;&#25511;&#21046;&#26041;&#27861;&#65292;&#20294;&#26159;&#24403;&#22788;&#29702;&#22797;&#26434;&#30340;&#33041;&#31354;&#38388;&#20381;&#36182;&#20851;&#31995;&#26102;&#65292;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#21644;&#26368;&#20248;&#24615;&#20173;&#23384;&#22312;&#30097;&#38382;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#24050;&#32463;&#22312;&#22270;&#20687;&#20998;&#21106;&#26041;&#38754;&#21462;&#24471;&#20102;&#38761;&#21629;&#24615;&#30340;&#36827;&#23637;&#65292;&#32780;&#22270;&#20687;&#20998;&#21106;&#19982;&#22522;&#20110;&#20307;&#32032;&#30340;&#22810;&#37325;&#26816;&#39564;&#23494;&#20999;&#30456;&#20851;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DeepFDR&#30340;&#26032;&#22411;&#31354;&#38388;&#34394;&#35686;&#25511;&#21046;&#26041;&#27861;&#65292;&#21033;&#29992;&#26080;&#30417;&#30563;&#30340;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#22270;&#20687;&#20998;&#21106;&#26469;&#35299;&#20915;&#22522;&#20110;&#20307;&#32032;&#30340;&#22810;&#37325;&#26816;&#39564;&#38382;&#39064;&#12290;&#21253;&#25324;&#20840;&#38754;&#30340;&#27169;&#25311;&#21644;&#38463;&#23572;&#33576;&#28023;&#40664;&#30149;FDG-PET&#24433;&#20687;&#20998;&#26512;&#22312;&#20869;&#30340;&#25968;&#20540;&#30740;&#31350;&#34920;&#26126;DeepFDR&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#20855;&#26377;&#20248;&#21183;&#12290;DeepFDR&#19981;&#20165;&#22312;&#34394;&#35686;&#25511;&#21046;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#36824;&#26377;&#25928;&#38477;&#20302;&#20102;&#34394;&#20551;&#30340;&#38750;&#21457;&#29616;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Voxel-based multiple testing is widely used in neuroimaging data analysis. Traditional false discovery rate (FDR) control methods often ignore the spatial dependence among the voxel-based tests and thus suffer from substantial loss of testing power. While recent spatial FDR control methods have emerged, their validity and optimality remain questionable when handling the complex spatial dependencies of the brain. Concurrently, deep learning methods have revolutionized image segmentation, a task closely related to voxel-based multiple testing. In this paper, we propose DeepFDR, a novel spatial FDR control method that leverages unsupervised deep learning-based image segmentation to address the voxel-based multiple testing problem. Numerical studies, including comprehensive simulations and Alzheimer's disease FDG-PET image analysis, demonstrate DeepFDR's superiority over existing methods. DeepFDR not only excels in FDR control and effectively diminishes the false nondiscovery rate, but als
&lt;/p&gt;</description></item><item><title>&#38024;&#23545;&#22810;&#21305;&#37197;&#21644;&#32858;&#31867;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38750;&#36127;&#29699;&#38754;&#26494;&#24347;&#26041;&#27861;&#65292;&#21487;&#20197;&#33258;&#21160;&#35843;&#25972;&#36830;&#32493;&#21442;&#25968;&#65292;&#32780;&#19981;&#38656;&#35201;&#20107;&#20808;&#22266;&#23450;&#25972;&#25968;&#21442;&#25968;&#65292;&#19988;&#33021;&#22815;&#30452;&#25509;&#24471;&#21040;&#20108;&#36827;&#21046;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.13311</link><description>&lt;p&gt;
&#38024;&#23545;&#26080;&#38480;&#21046;&#22810;&#21305;&#37197;&#21644;&#32858;&#31867;&#38382;&#39064;&#30340;&#38750;&#36127;&#29699;&#38754;&#26494;&#24347;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Non-Negative Spherical Relaxations for Universe-Free Multi-Matching and Clustering. (arXiv:2310.13311v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13311
&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#22810;&#21305;&#37197;&#21644;&#32858;&#31867;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38750;&#36127;&#29699;&#38754;&#26494;&#24347;&#26041;&#27861;&#65292;&#21487;&#20197;&#33258;&#21160;&#35843;&#25972;&#36830;&#32493;&#21442;&#25968;&#65292;&#32780;&#19981;&#38656;&#35201;&#20107;&#20808;&#22266;&#23450;&#25972;&#25968;&#21442;&#25968;&#65292;&#19988;&#33021;&#22815;&#30452;&#25509;&#24471;&#21040;&#20108;&#36827;&#21046;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38750;&#36127;&#29699;&#38754;&#26494;&#24347;&#26041;&#27861;&#65292;&#29992;&#20110;&#20855;&#26377;&#21807;&#19968;&#24615;&#32422;&#26463;&#30340;&#20108;&#36827;&#21046;&#30697;&#38453;&#20248;&#21270;&#38382;&#39064;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#22810;&#21305;&#37197;&#21644;&#32858;&#31867;&#12290;&#25105;&#20204;&#23558;&#30456;&#24212;&#30340;&#20108;&#36827;&#21046;&#30697;&#38453;&#32422;&#26463;&#26494;&#24347;&#21040;&#65288;&#39640;&#32500;&#65289;&#38750;&#36127;&#29699;&#38754;&#19978;&#12290;&#20026;&#20102;&#20248;&#21270;&#25105;&#20204;&#30340;&#26494;&#24347;&#38382;&#39064;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#31181;&#26465;&#20214;&#24130;&#36845;&#20195;&#26041;&#27861;&#26469;&#36845;&#20195;&#25913;&#36827;&#30446;&#26631;&#20989;&#25968;&#65292;&#21516;&#26102;&#22312;&#19982;&#23431;&#23449;&#22823;&#23567;&#65288;&#25110;&#31751;&#30340;&#25968;&#37327;&#65289;&#65288;&#38388;&#25509;&#65289;&#30456;&#20851;&#30340;&#36830;&#32493;&#26631;&#37327;&#21442;&#25968;&#19978;&#36827;&#34892;&#25195;&#25551;&#12290;&#19982;&#29616;&#26377;&#30340;&#22312;&#20248;&#21270;&#20043;&#21069;&#38656;&#35201;&#22266;&#23450;&#25972;&#25968;&#23431;&#23449;&#22823;&#23567;&#30340;&#26041;&#27861;&#30456;&#21453;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33258;&#21160;&#35843;&#25972;&#31867;&#20284;&#30340;&#36830;&#32493;&#21442;&#25968;&#12290;&#27492;&#22806;&#65292;&#34429;&#28982;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#35889;&#22810;&#21305;&#37197;&#21644;&#35889;&#32858;&#31867;&#26377;&#19968;&#23450;&#30456;&#20284;&#20043;&#22788;&#65292;&#20294;&#25105;&#20204;&#30340;&#21046;&#23450;&#26041;&#26696;&#20855;&#26377;&#19968;&#20010;&#24378;&#22823;&#30340;&#20248;&#21183;&#65292;&#21363;&#25105;&#20204;&#19981;&#20381;&#36182;&#39069;&#22806;&#30340;&#21518;&#22788;&#29702;&#36807;&#31243;&#26469;&#33719;&#24471;&#20108;&#36827;&#21046;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21508;&#31181;&#24212;&#29992;&#24773;&#20917;&#19979;&#26174;&#31034;&#20986;&#20196;&#20154;&#20449;&#26381;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel non-negative spherical relaxation for optimization problems over binary matrices with injectivity constraints, which in particular has applications in multi-matching and clustering. We relax respective binary matrix constraints to the (high-dimensional) non-negative sphere. To optimize our relaxed problem, we use a conditional power iteration method to iteratively improve the objective function, while at same time sweeping over a continuous scalar parameter that is (indirectly) related to the universe size (or number of clusters). Opposed to existing procedures that require to fix the integer universe size before optimization, our method automatically adjusts the analogous continuous parameter. Furthermore, while our approach shares similarities with spectral multi-matching and spectral clustering, our formulation has the strong advantage that we do not rely on additional post-processing procedures to obtain binary results. Our method shows compelling results in vari
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#25928;&#27714;&#35299;&#20559;&#24494;&#20998;&#26041;&#31243;&#38382;&#39064;&#12290;&#36890;&#36807;&#32534;&#30721;&#38382;&#39064;&#34920;&#31034;&#21644;&#37319;&#29992;&#29289;&#29702;&#23398;&#19968;&#33268;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#26469;&#35757;&#32451;&#27169;&#22411;&#65292;&#21487;&#20197;&#22312;&#26410;&#30693;&#35299;&#20915;&#26041;&#26696;&#30340;&#24773;&#20917;&#19979;&#35780;&#20272;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2310.13270</link><description>&lt;p&gt;
&#22522;&#20110;&#20803;&#23398;&#20064;&#30340;&#29289;&#29702;&#23398;&#19968;&#33268;&#31070;&#32463;&#32593;&#32476;&#39640;&#25928;&#27714;&#35299;&#26032;&#32473;&#23450;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Meta-learning of Physics-informed Neural Networks for Efficiently Solving Newly Given PDEs. (arXiv:2310.13270v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13270
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#25928;&#27714;&#35299;&#20559;&#24494;&#20998;&#26041;&#31243;&#38382;&#39064;&#12290;&#36890;&#36807;&#32534;&#30721;&#38382;&#39064;&#34920;&#31034;&#21644;&#37319;&#29992;&#29289;&#29702;&#23398;&#19968;&#33268;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#26469;&#35757;&#32451;&#27169;&#22411;&#65292;&#21487;&#20197;&#22312;&#26410;&#30693;&#35299;&#20915;&#26041;&#26696;&#30340;&#24773;&#20917;&#19979;&#35780;&#20272;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#25928;&#27714;&#35299;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDE&#65289;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#26088;&#22312;&#20803;&#23398;&#20064;&#22914;&#20309;&#35299;&#20915;&#21508;&#31181;PDE&#38382;&#39064;&#65292;&#24182;&#23558;&#20854;&#30693;&#35782;&#24212;&#29992;&#20110;&#35299;&#20915;&#26032;&#32473;&#23450;&#30340;PDE&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#23558;PDE&#38382;&#39064;&#32534;&#30721;&#20026;&#38382;&#39064;&#34920;&#31034;&#65292;&#20854;&#20013;&#25511;&#21046;&#26041;&#31243;&#36890;&#36807;&#20559;&#23548;&#25968;&#30340;&#22810;&#39033;&#24335;&#20989;&#25968;&#31995;&#25968;&#34920;&#31034;&#65292;&#36793;&#30028;&#26465;&#20214;&#36890;&#36807;&#19968;&#32452;&#28857;&#26465;&#20214;&#23545;&#34920;&#31034;&#12290;&#25105;&#20204;&#23558;&#38382;&#39064;&#34920;&#31034;&#20316;&#20026;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20837;&#65292;&#29992;&#20110;&#39044;&#27979;&#35299;&#20915;&#26041;&#26696;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#30340;&#21069;&#21521;&#36807;&#31243;&#39640;&#25928;&#22320;&#39044;&#27979;&#38382;&#39064;&#29305;&#23450;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#32780;&#26080;&#38656;&#26356;&#26032;&#27169;&#22411;&#21442;&#25968;&#12290;&#20026;&#20102;&#35757;&#32451;&#25105;&#20204;&#30340;&#27169;&#22411;&#65292;&#25105;&#20204;&#26368;&#23567;&#21270;&#22522;&#20110;&#8220;&#29289;&#29702;&#23398;&#19968;&#33268;&#31070;&#32463;&#32593;&#32476;&#8221;&#26694;&#26550;&#36866;&#24212;&#20110;PDE&#38382;&#39064;&#26102;&#30340;&#39044;&#26399;&#35823;&#24046;&#65292;&#20511;&#27492;&#25105;&#20204;&#21487;&#20197;&#22312;&#35299;&#20915;&#26041;&#26696;&#26410;&#30693;&#30340;&#24773;&#20917;&#19979;&#35780;&#20272;&#35823;&#24046;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#21644;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a neural network-based meta-learning method to efficiently solve partial differential equation (PDE) problems. The proposed method is designed to meta-learn how to solve a wide variety of PDE problems, and uses the knowledge for solving newly given PDE problems. We encode a PDE problem into a problem representation using neural networks, where governing equations are represented by coefficients of a polynomial function of partial derivatives, and boundary conditions are represented by a set of point-condition pairs. We use the problem representation as an input of a neural network for predicting solutions, which enables us to efficiently predict problem-specific solutions by the forwarding process of the neural network without updating model parameters. To train our model, we minimize the expected error when adapted to a PDE problem based on the physics-informed neural network framework, by which we can evaluate the error even when solutions are unknown. We demonstrate that 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;Ising&#27169;&#22411;&#20013;&#30340;&#24352;&#37327;&#23398;&#20064;&#20013;&#65292;&#36890;&#36807;&#20266;&#20284;&#28982;&#26041;&#27861;&#21644;&#30456;&#20114;&#20316;&#29992;&#31579;&#36873;&#26041;&#27861;&#21487;&#20197;&#24674;&#22797;&#20986;&#24213;&#23618;&#30340;&#36229;&#32593;&#32476;&#32467;&#26500;&#65292;&#24182;&#19988;&#24615;&#33021;&#27604;&#36739;&#34920;&#26126;&#24352;&#37327;&#24674;&#22797;&#36895;&#29575;&#19982;&#26368;&#22823;&#32806;&#21512;&#24378;&#24230;&#21576;&#25351;&#25968;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2310.13232</link><description>&lt;p&gt;
Ising&#27169;&#22411;&#20013;&#30340;&#24352;&#37327;&#23398;&#20064;&#30340;&#30456;&#20114;&#20316;&#29992;&#31579;&#36873;&#21644;&#20266;&#20284;&#28982;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Interaction Screening and Pseudolikelihood Approaches for Tensor Learning in Ising Models. (arXiv:2310.13232v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13232
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;Ising&#27169;&#22411;&#20013;&#30340;&#24352;&#37327;&#23398;&#20064;&#20013;&#65292;&#36890;&#36807;&#20266;&#20284;&#28982;&#26041;&#27861;&#21644;&#30456;&#20114;&#20316;&#29992;&#31579;&#36873;&#26041;&#27861;&#21487;&#20197;&#24674;&#22797;&#20986;&#24213;&#23618;&#30340;&#36229;&#32593;&#32476;&#32467;&#26500;&#65292;&#24182;&#19988;&#24615;&#33021;&#27604;&#36739;&#34920;&#26126;&#24352;&#37327;&#24674;&#22797;&#36895;&#29575;&#19982;&#26368;&#22823;&#32806;&#21512;&#24378;&#24230;&#21576;&#25351;&#25968;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;$k$-spin Ising&#27169;&#22411;&#20013;&#30340;&#24352;&#37327;&#24674;&#22797;&#20013;&#65292;&#20266;&#20284;&#28982;&#26041;&#27861;&#21644;&#30456;&#20114;&#20316;&#29992;&#31579;&#36873;&#26041;&#27861;&#20004;&#31181;&#24050;&#30693;&#30340;Ising&#32467;&#26500;&#23398;&#20064;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#19979;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#21487;&#20197;&#20351;&#29992;&#26679;&#26412;&#25968;&#23545;&#25968;&#32423;&#21035;&#22823;&#23567;&#30340;&#26679;&#26412;&#24674;&#22797;&#20986;&#24213;&#23618;&#30340;&#36229;&#32593;&#32476;&#32467;&#26500;&#65292;&#19988;&#19982;&#26368;&#22823;&#30456;&#20114;&#20316;&#29992;&#24378;&#24230;&#21644;&#26368;&#22823;&#33410;&#28857;&#24230;&#25351;&#25968;&#32423;&#20381;&#36182;&#12290;&#25105;&#20204;&#36824;&#23545;&#36825;&#20004;&#31181;&#26041;&#27861;&#30340;&#24352;&#37327;&#24674;&#22797;&#36895;&#29575;&#19982;&#20132;&#20114;&#38454;&#25968;$k$&#30340;&#30830;&#20999;&#20851;&#31995;&#36827;&#34892;&#20102;&#36319;&#36394;&#65292;&#24182;&#20801;&#35768;$k$&#38543;&#26679;&#26412;&#25968;&#21644;&#33410;&#28857;&#25968;&#22686;&#38271;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#20223;&#30495;&#30740;&#31350;&#23545;&#36825;&#20004;&#31181;&#26041;&#27861;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#27604;&#36739;&#35752;&#35770;&#65292;&#32467;&#26524;&#20063;&#26174;&#31034;&#20102;&#24352;&#37327;&#24674;&#22797;&#36895;&#29575;&#19982;&#26368;&#22823;&#32806;&#21512;&#24378;&#24230;&#20043;&#38388;&#30340;&#25351;&#25968;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study two well known methods of Ising structure learning, namely the pseudolikelihood approach and the interaction screening approach, in the context of tensor recovery in $k$-spin Ising models. We show that both these approaches, with proper regularization, retrieve the underlying hypernetwork structure using a sample size logarithmic in the number of network nodes, and exponential in the maximum interaction strength and maximum node-degree. We also track down the exact dependence of the rate of tensor recovery on the interaction order $k$, that is allowed to grow with the number of samples and nodes, for both the approaches. Finally, we provide a comparative discussion of the performance of the two approaches based on simulation studies, which also demonstrate the exponential dependence of the tensor recovery rate on the maximum coupling strength.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24322;&#26500;&#38544;&#31169;&#38656;&#27714;&#19979;&#30340;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#65292;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#25509;&#36817;&#32447;&#24615;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#19979;&#65292;&#33021;&#22815;&#28385;&#36275;&#27599;&#20010;&#29992;&#25143;&#30340;&#20010;&#21035;&#38544;&#31169;&#35201;&#27714;&#65292;&#24182;&#19988;&#33719;&#24471;&#26497;&#23567;&#21270;&#26368;&#20248;&#32467;&#26524;&#12290;&#26368;&#20005;&#26684;&#30340;&#29992;&#25143;&#30340;&#38544;&#31169;&#35201;&#27714;&#20915;&#23450;&#20102;&#25972;&#20307;&#30340;&#35823;&#24046;&#29575;&#65292;&#19988;&#25317;&#26377;&#36739;&#23569;&#20294;&#19981;&#21516;&#38544;&#31169;&#35201;&#27714;&#30340;&#29992;&#25143;&#37117;&#20250;&#33719;&#24471;&#36229;&#36807;&#33258;&#36523;&#38656;&#27714;&#30340;&#38544;&#31169;&#20445;&#25252;&#65292;&#19988;&#20445;&#25252;&#31243;&#24230;&#30456;&#21516;&#12290;&#36825;&#24847;&#21619;&#30528;&#23545;&#38544;&#31169;&#19981;&#25935;&#24863;&#30340;&#29992;&#25143;&#21487;&#20197;&#20813;&#36153;&#33719;&#24471;&#38750;&#24179;&#20961;&#31243;&#24230;&#30340;&#38544;&#31169;&#20445;&#25252;&#12290;</title><link>http://arxiv.org/abs/2310.13137</link><description>&lt;p&gt;
&#24322;&#26500;&#38544;&#31169;&#38656;&#27714;&#19979;&#30340;&#22343;&#20540;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Mean Estimation Under Heterogeneous Privacy Demands. (arXiv:2310.13137v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13137
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24322;&#26500;&#38544;&#31169;&#38656;&#27714;&#19979;&#30340;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#65292;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#25509;&#36817;&#32447;&#24615;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#19979;&#65292;&#33021;&#22815;&#28385;&#36275;&#27599;&#20010;&#29992;&#25143;&#30340;&#20010;&#21035;&#38544;&#31169;&#35201;&#27714;&#65292;&#24182;&#19988;&#33719;&#24471;&#26497;&#23567;&#21270;&#26368;&#20248;&#32467;&#26524;&#12290;&#26368;&#20005;&#26684;&#30340;&#29992;&#25143;&#30340;&#38544;&#31169;&#35201;&#27714;&#20915;&#23450;&#20102;&#25972;&#20307;&#30340;&#35823;&#24046;&#29575;&#65292;&#19988;&#25317;&#26377;&#36739;&#23569;&#20294;&#19981;&#21516;&#38544;&#31169;&#35201;&#27714;&#30340;&#29992;&#25143;&#37117;&#20250;&#33719;&#24471;&#36229;&#36807;&#33258;&#36523;&#38656;&#27714;&#30340;&#38544;&#31169;&#20445;&#25252;&#65292;&#19988;&#20445;&#25252;&#31243;&#24230;&#30456;&#21516;&#12290;&#36825;&#24847;&#21619;&#30528;&#23545;&#38544;&#31169;&#19981;&#25935;&#24863;&#30340;&#29992;&#25143;&#21487;&#20197;&#20813;&#36153;&#33719;&#24471;&#38750;&#24179;&#20961;&#31243;&#24230;&#30340;&#38544;&#31169;&#20445;&#25252;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#26159;&#19968;&#31181;&#37327;&#21270;&#31639;&#27861;&#36896;&#25104;&#30340;&#38544;&#31169;&#25439;&#22833;&#30340;&#25104;&#29087;&#26694;&#26550;&#12290;&#20256;&#32479;&#30340;&#26041;&#27861;&#23545;&#25152;&#26377;&#29992;&#25143;&#37117;&#26045;&#21152;&#32479;&#19968;&#30340;&#38544;&#31169;&#35201;&#27714;&#65292;&#36825;&#19982;&#29616;&#23454;&#24773;&#26223;&#19981;&#19968;&#33268;&#65292;&#22240;&#20026;&#29992;&#25143;&#21487;&#20197;&#20010;&#21035;&#20915;&#23450;&#33258;&#24049;&#30340;&#38544;&#31169;&#20559;&#22909;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#22343;&#20540;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#27599;&#20010;&#29992;&#25143;&#37117;&#21487;&#20197;&#26045;&#21152;&#33258;&#24049;&#19981;&#21516;&#30340;&#38544;&#31169;&#27700;&#24179;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#34987;&#35777;&#26126;&#26159;&#26497;&#23567;&#21270;&#26368;&#20248;&#30340;&#65292;&#19988;&#20855;&#26377;&#25509;&#36817;&#32447;&#24615;&#30340;&#36816;&#34892;&#26102;&#38388;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25581;&#31034;&#20102;&#19968;&#31181;&#26377;&#36259;&#30340;&#39281;&#21644;&#29616;&#35937;&#12290;&#21363;&#26368;&#20005;&#26684;&#29992;&#25143;&#30340;&#38544;&#31169;&#35201;&#27714;&#20915;&#23450;&#20102;&#25972;&#20307;&#30340;&#35823;&#24046;&#29575;&#12290;&#22240;&#27492;&#65292;&#25317;&#26377;&#36739;&#23569;&#20294;&#19981;&#21516;&#38544;&#31169;&#35201;&#27714;&#30340;&#29992;&#25143;&#37117;&#20250;&#33719;&#24471;&#36229;&#36807;&#33258;&#36523;&#38656;&#27714;&#30340;&#38544;&#31169;&#20445;&#25252;&#65292;&#19988;&#20445;&#25252;&#31243;&#24230;&#30456;&#21516;&#12290;&#25442;&#21477;&#35805;&#35828;&#65292;&#36825;&#20123;&#23545;&#38544;&#31169;&#19981;&#25935;&#24863;&#30340;&#29992;&#25143;&#21487;&#20197;&#20813;&#36153;&#33719;&#24471;&#38750;&#24179;&#20961;&#31243;&#24230;&#30340;&#38544;&#31169;&#20445;&#25252;&#65292;&#32780;&#26080;&#38656;&#22312;&#20272;&#35745;&#22120;&#24615;&#33021;&#19978;&#20570;&#20986;&#20219;&#20309;&#29306;&#29298;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differential Privacy (DP) is a well-established framework to quantify privacy loss incurred by any algorithm. Traditional formulations impose a uniform privacy requirement for all users, which is often inconsistent with real-world scenarios in which users dictate their privacy preferences individually. This work considers the problem of mean estimation, where each user can impose their own distinct privacy level. The algorithm we propose is shown to be minimax optimal and has a near-linear run-time. Our results elicit an interesting saturation phenomenon that occurs. Namely, the privacy requirements of the most stringent users dictate the overall error rates. As a consequence, users with less but differing privacy requirements are all given more privacy than they require, in equal amounts. In other words, these privacy-indifferent users are given a nontrivial degree of privacy for free, without any sacrifice in the performance of the estimator.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33539;&#25968;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#36866;&#29992;&#20110;&#19981;&#20381;&#36182;&#20110;&#36755;&#20837;&#24207;&#21015;&#38271;&#24230;&#30340;Transformer&#26550;&#26500;&#12290;&#36890;&#36807;&#20351;&#29992;&#35206;&#30422;&#25968;&#30028;&#38480;&#26469;&#19978;&#30028;Transformer&#30340;Rademacher&#22797;&#26434;&#24230;&#65292;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#25513;&#30721;&#39044;&#27979;&#25513;&#30721;&#23383;&#31561;&#24120;&#35265;&#30340;Transformer&#35757;&#32451;&#25216;&#26415;&#12290;&#25105;&#20204;&#20063;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.13088</link><description>&lt;p&gt;
Transformer&#30340;&#22522;&#20110;&#33539;&#25968;&#30340;&#38271;&#24230;&#26080;&#20851;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Sequence Length Independent Norm-Based Generalization Bounds for Transformers. (arXiv:2310.13088v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13088
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33539;&#25968;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#36866;&#29992;&#20110;&#19981;&#20381;&#36182;&#20110;&#36755;&#20837;&#24207;&#21015;&#38271;&#24230;&#30340;Transformer&#26550;&#26500;&#12290;&#36890;&#36807;&#20351;&#29992;&#35206;&#30422;&#25968;&#30028;&#38480;&#26469;&#19978;&#30028;Transformer&#30340;Rademacher&#22797;&#26434;&#24230;&#65292;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#25513;&#30721;&#39044;&#27979;&#25513;&#30721;&#23383;&#31561;&#24120;&#35265;&#30340;Transformer&#35757;&#32451;&#25216;&#26415;&#12290;&#25105;&#20204;&#20063;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#33539;&#25968;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#36866;&#29992;&#20110;Transformer&#26550;&#26500;&#19988;&#19981;&#20381;&#36182;&#20110;&#36755;&#20837;&#24207;&#21015;&#30340;&#38271;&#24230;&#12290;&#25105;&#20204;&#37319;&#29992;&#22522;&#20110;&#35206;&#30422;&#25968;&#30340;&#26041;&#27861;&#26469;&#35777;&#26126;&#25105;&#20204;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#20351;&#29992;&#20102;&#19977;&#20010;&#26032;&#39062;&#30340;&#35206;&#30422;&#25968;&#30028;&#38480;&#26469;&#19978;&#30028;Transformer&#30340;Rademacher&#22797;&#26434;&#24230;&#65292;&#35813;&#20989;&#25968;&#31867;&#20026;&#26377;&#30028;&#32447;&#24615;&#21464;&#25442;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#36825;&#20010;&#27867;&#21270;&#30028;&#38480;&#36866;&#29992;&#20110;&#24120;&#35265;&#30340;Transformer&#35757;&#32451;&#25216;&#26415;&#65292;&#21363;&#25513;&#30721;&#39044;&#27979;&#25513;&#30721;&#23383;&#12290;&#25105;&#20204;&#36824;&#22312;&#19968;&#20010;&#31232;&#30095;&#22810;&#25968;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#27169;&#25311;&#30740;&#31350;&#65292;&#20174;&#23454;&#35777;&#35282;&#24230;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper provides norm-based generalization bounds for the Transformer architecture that do not depend on the input sequence length. We employ a covering number based approach to prove our bounds. We use three novel covering number bounds for the function class of bounded linear transformations to upper bound the Rademacher complexity of the Transformer. Furthermore, we show this generalization bound applies to the common Transformer training technique of masking and then predicting the masked word. We also run a simulated study on a sparse majority data set that empirically validates our theoretical findings.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#27867;&#21270;&#21644;&#35760;&#24518;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#23545;&#27169;&#25968;&#31639;&#26415;&#20219;&#21153;&#19978;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#23454;&#39564;&#65292;&#21457;&#29616;&#32593;&#32476;&#21487;&#20197;&#21516;&#26102;&#35760;&#20303;&#25439;&#22351;&#30340;&#26631;&#31614;&#24182;&#23454;&#29616;100%&#30340;&#27867;&#21270;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#35782;&#21035;&#21644;&#21098;&#26525;&#35760;&#24518;&#21270;&#30340;&#31070;&#32463;&#20803;&#26469;&#38477;&#20302;&#23545;&#25439;&#22351;&#25968;&#25454;&#30340;&#20934;&#30830;&#29575;&#65292;&#25552;&#39640;&#23545;&#26410;&#25439;&#22351;&#25968;&#25454;&#30340;&#20934;&#30830;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.13061</link><description>&lt;p&gt;
&#21040;&#24213;&#26159;&#29702;&#35299;&#36824;&#26159;&#35760;&#24518;&#65306;&#35299;&#26512;&#31639;&#27861;&#25968;&#25454;&#38598;&#19978;&#30340;&#27867;&#21270;&#21644;&#35760;&#24518;
&lt;/p&gt;
&lt;p&gt;
To grok or not to grok: Disentangling generalization and memorization on corrupted algorithmic datasets. (arXiv:2310.13061v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13061
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#27867;&#21270;&#21644;&#35760;&#24518;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#23545;&#27169;&#25968;&#31639;&#26415;&#20219;&#21153;&#19978;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#23454;&#39564;&#65292;&#21457;&#29616;&#32593;&#32476;&#21487;&#20197;&#21516;&#26102;&#35760;&#20303;&#25439;&#22351;&#30340;&#26631;&#31614;&#24182;&#23454;&#29616;100%&#30340;&#27867;&#21270;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#35782;&#21035;&#21644;&#21098;&#26525;&#35760;&#24518;&#21270;&#30340;&#31070;&#32463;&#20803;&#26469;&#38477;&#20302;&#23545;&#25439;&#22351;&#25968;&#25454;&#30340;&#20934;&#30830;&#29575;&#65292;&#25552;&#39640;&#23545;&#26410;&#25439;&#22351;&#25968;&#25454;&#30340;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#65292;&#24378;&#22823;&#30340;&#27867;&#21270;&#33021;&#21147;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#22312;&#21487;&#35757;&#32451;&#21442;&#25968;&#38750;&#24120;&#22823;&#30340;&#24773;&#20917;&#19979;&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#24456;&#38590;&#30693;&#36947;&#32593;&#32476;&#26159;&#21542;&#24050;&#32463;&#35760;&#20303;&#20102;&#19968;&#32452;&#29305;&#23450;&#30340;&#26679;&#26412;&#65292;&#36824;&#26159;&#29702;&#35299;&#20102;&#20854;&#20013;&#30340;&#22522;&#26412;&#35268;&#24459;&#65288;&#25110;&#32773;&#20004;&#32773;&#37117;&#26377;&#65289;&#12290;&#21463;&#21040;&#36825;&#20010;&#25361;&#25112;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#21487;&#35299;&#37322;&#30340;&#27169;&#22411;&#65292;&#20854;&#20013;&#30340;&#27867;&#21270;&#34920;&#31034;&#21487;&#20197;&#36890;&#36807;&#20998;&#26512;&#26469;&#29702;&#35299;&#65292;&#24182;&#19988;&#24456;&#23481;&#26131;&#19982;&#35760;&#24518;&#24615;&#34920;&#31034;&#21306;&#20998;&#24320;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#27169;&#25968;&#31639;&#26415;&#20219;&#21153;&#19978;&#35757;&#32451;&#30340;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#22312;&#36825;&#20123;&#20219;&#21153;&#20013;&#65292;&#65288;&#958;&#183;100%&#65289;&#30340;&#26631;&#31614;&#26159;&#34987;&#25439;&#22351;&#30340;&#65288;&#21363;&#35757;&#32451;&#38598;&#20013;&#30340;&#19968;&#20123;&#27169;&#25968;&#36816;&#31639;&#32467;&#26524;&#26159;&#38169;&#35823;&#30340;&#65289;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#65306;&#65288;i&#65289;&#32593;&#32476;&#21487;&#20197;&#21516;&#26102;&#35760;&#20303;&#25439;&#22351;&#30340;&#26631;&#31614;&#24182;&#23454;&#29616;100%&#30340;&#27867;&#21270;&#65307;&#65288;ii&#65289;&#21487;&#20197;&#35782;&#21035;&#21644;&#21098;&#26525;&#35760;&#24518;&#21270;&#30340;&#31070;&#32463;&#20803;&#65292;&#38477;&#20302;&#23545;&#25439;&#22351;&#25968;&#25454;&#30340;&#20934;&#30830;&#29575;&#65292;&#25552;&#39640;&#23545;&#26410;&#25439;&#22351;&#25968;&#25454;&#30340;&#20934;&#30830;&#29575;&#65307;&#65288;iii&#65289;&#27491;&#21017;&#21270;&#26041;&#27861;&#22914;w
&lt;/p&gt;
&lt;p&gt;
Robust generalization is a major challenge in deep learning, particularly when the number of trainable parameters is very large. In general, it is very difficult to know if the network has memorized a particular set of examples or understood the underlying rule (or both). Motivated by this challenge, we study an interpretable model where generalizing representations are understood analytically, and are easily distinguishable from the memorizing ones. Namely, we consider two-layer neural networks trained on modular arithmetic tasks where ($\xi \cdot 100\%$) of labels are corrupted (\emph{i.e.} some results of the modular operations in the training set are incorrect). We show that (i) it is possible for the network to memorize the corrupted labels \emph{and} achieve $100\%$ generalization at the same time; (ii) the memorizing neurons can be identified and pruned, lowering the accuracy on corrupted data and improving the accuracy on uncorrupted data; (iii) regularization methods such as w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#20013;&#36827;&#34892;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#31070;&#32463;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#22120;&#26469;&#36817;&#20284;&#27169;&#22411;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#22312;&#32479;&#35745;&#20998;&#26512;&#36807;&#31243;&#20013;&#21482;&#33021;&#35775;&#38382;&#31169;&#26377;&#21270;&#25968;&#25454;&#23548;&#33268;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#22686;&#21152;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.12781</link><description>&lt;p&gt;
&#20174;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#20013;&#36827;&#34892;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Conditional Density Estimations from Privacy-Protected Data. (arXiv:2310.12781v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12781
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#20013;&#36827;&#34892;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#31070;&#32463;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#22120;&#26469;&#36817;&#20284;&#27169;&#22411;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#22312;&#32479;&#35745;&#20998;&#26512;&#36807;&#31243;&#20013;&#21482;&#33021;&#35775;&#38382;&#31169;&#26377;&#21270;&#25968;&#25454;&#23548;&#33268;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#22686;&#21152;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#29616;&#20195;&#32479;&#35745;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#38656;&#35201;&#22312;&#25935;&#24863;&#29992;&#25143;&#25968;&#25454;&#19978;&#36827;&#34892;&#27169;&#22411;&#35757;&#32451;&#12290;&#24046;&#20998;&#38544;&#31169;&#25552;&#20379;&#20102;&#19968;&#31181;&#27491;&#24335;&#30340;&#20445;&#35777;&#65292;&#21363;&#20010;&#20307;&#29992;&#25143;&#20449;&#24687;&#19981;&#20250;&#27844;&#38706;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#19979;&#65292;&#38543;&#26426;&#31639;&#27861;&#21521;&#20445;&#23494;&#25968;&#25454;&#27880;&#20837;&#26657;&#20934;&#30340;&#22122;&#22768;&#65292;&#20174;&#32780;&#20135;&#29983;&#38544;&#31169;&#20445;&#25252;&#30340;&#25968;&#25454;&#38598;&#25110;&#26597;&#35810;&#12290;&#28982;&#32780;&#65292;&#22312;&#32479;&#35745;&#20998;&#26512;&#36807;&#31243;&#20013;&#21482;&#33021;&#35775;&#38382;&#31169;&#26377;&#21270;&#25968;&#25454;&#20250;&#23548;&#33268;&#35745;&#31639;&#22797;&#26434;&#24230;&#22686;&#21152;&#65292;&#38590;&#20197;&#23545;&#22522;&#30784;&#26426;&#23494;&#25968;&#25454;&#30340;&#21442;&#25968;&#36827;&#34892;&#26377;&#25928;&#30340;&#25512;&#29702;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#38598;&#30340;&#22522;&#20110;&#27169;&#25311;&#30340;&#25512;&#29702;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20351;&#29992;&#31070;&#32463;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#22120;&#20316;&#20026;&#19968;&#32452;&#28789;&#27963;&#30340;&#20998;&#24067;&#26469;&#36817;&#20284;&#32473;&#23450;&#35266;&#27979;&#21040;&#30340;&#31169;&#26377;&#26597;&#35810;&#32467;&#26524;&#30340;&#27169;&#22411;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#25105;&#20204;&#22312;&#20256;&#26579;&#30149;&#27169;&#22411;&#19979;&#30340;&#31163;&#25955;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20197;&#21450;&#26222;&#36890;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#19978;&#35828;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many modern statistical analysis and machine learning applications require training models on sensitive user data. Differential privacy provides a formal guarantee that individual-level information about users does not leak. In this framework, randomized algorithms inject calibrated noise into the confidential data, resulting in privacy-protected datasets or queries. However, restricting access to only the privatized data during statistical analysis makes it computationally challenging to perform valid inferences on parameters underlying the confidential data. In this work, we propose simulation-based inference methods from privacy-protected datasets. Specifically, we use neural conditional density estimators as a flexible family of distributions to approximate the posterior distribution of model parameters given the observed private query results. We illustrate our methods on discrete time-series data under an infectious disease model and on ordinary linear regression models. Illustra
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#25554;&#20837;/&#21024;&#38500;&#25351;&#26631;&#24863;&#30693;&#30340;&#22522;&#20110;&#35299;&#37322;&#30340;&#20248;&#21270;(ID-ExpO)&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#21487;&#21306;&#20998;&#30340;&#39044;&#27979;&#22120;&#26469;&#25552;&#39640;&#35299;&#37322;&#30340;&#25554;&#20837;&#21644;&#21024;&#38500;&#24471;&#20998;&#65292;&#24182;&#20445;&#25345;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;ID-ExpO&#33021;&#22815;&#20351;&#27969;&#34892;&#30340;&#20107;&#21518;&#35299;&#37322;&#22120;&#20135;&#29983;&#26356;&#24544;&#23454;&#30340;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2310.12553</link><description>&lt;p&gt;
&#21033;&#29992;&#21487;&#21306;&#20998;&#25554;&#20837;/&#21024;&#38500;&#25351;&#26631;&#24863;&#30693;&#27491;&#21017;&#21270;&#36827;&#34892;&#35299;&#37322;&#24615;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Explanation-Based Training with Differentiable Insertion/Deletion Metric-Aware Regularizers. (arXiv:2310.12553v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12553
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#25554;&#20837;/&#21024;&#38500;&#25351;&#26631;&#24863;&#30693;&#30340;&#22522;&#20110;&#35299;&#37322;&#30340;&#20248;&#21270;(ID-ExpO)&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#21487;&#21306;&#20998;&#30340;&#39044;&#27979;&#22120;&#26469;&#25552;&#39640;&#35299;&#37322;&#30340;&#25554;&#20837;&#21644;&#21024;&#38500;&#24471;&#20998;&#65292;&#24182;&#20445;&#25345;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;ID-ExpO&#33021;&#22815;&#20351;&#27969;&#34892;&#30340;&#20107;&#21518;&#35299;&#37322;&#22120;&#20135;&#29983;&#26356;&#24544;&#23454;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22797;&#26434;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#22120;&#30340;&#35299;&#37322;&#36136;&#37327;&#36890;&#24120;&#20351;&#29992;&#25554;&#20837;&#21644;&#21024;&#38500;&#25351;&#26631;&#36827;&#34892;&#34913;&#37327;&#65292;&#36825;&#20123;&#25351;&#26631;&#35780;&#20272;&#35299;&#37322;&#30340;&#24544;&#23454;&#24230;&#65292;&#21363;&#35299;&#37322;&#27491;&#30830;&#22320;&#21453;&#26144;&#20102;&#39044;&#27979;&#22120;&#30340;&#34892;&#20026;&#31243;&#24230;&#12290;&#20026;&#20102;&#25552;&#39640;&#24544;&#23454;&#24230;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#25554;&#20837;/&#21024;&#38500;&#25351;&#26631;&#24863;&#30693;&#30340;&#22522;&#20110;&#35299;&#37322;&#30340;&#20248;&#21270;&#65288;ID-ExpO&#65289;&#65292;&#35813;&#20248;&#21270;&#33021;&#22815;&#25913;&#21892;&#35299;&#37322;&#30340;&#25554;&#20837;&#21644;&#21024;&#38500;&#24471;&#20998;&#65292;&#21516;&#26102;&#20445;&#25345;&#20854;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#30001;&#20110;&#21407;&#22987;&#30340;&#25554;&#20837;&#21644;&#21024;&#38500;&#25351;&#26631;&#23545;&#20110;&#35299;&#37322;&#26469;&#35828;&#26159;&#19981;&#21487;&#21306;&#20998;&#30340;&#65292;&#24182;&#19988;&#26080;&#27861;&#30452;&#25509;&#36827;&#34892;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#36825;&#20123;&#25351;&#26631;&#20197;&#20351;&#20854;&#21487;&#21306;&#20998;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#24418;&#24335;&#21270;&#25554;&#20837;&#21644;&#21024;&#38500;&#25351;&#26631;&#30340;&#27491;&#21017;&#21270;&#12290;&#22312;&#22270;&#20687;&#21644;&#34920;&#26684;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;ID-ExpO&#36827;&#34892;&#24494;&#35843;&#30340;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#39044;&#27979;&#22120;&#33021;&#22815;&#20351;&#27969;&#34892;&#30340;&#20107;&#21518;&#35299;&#37322;&#22120;&#20135;&#29983;&#26356;&#24544;&#23454;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
The quality of explanations for the predictions of complex machine learning predictors is often measured using insertion and deletion metrics, which assess the faithfulness of the explanations, i.e., how correctly the explanations reflect the predictor's behavior. To improve the faithfulness, we propose insertion/deletion metric-aware explanation-based optimization (ID-ExpO), which optimizes differentiable predictors to improve both insertion and deletion scores of the explanations while keeping their predictive accuracy. Since the original insertion and deletion metrics are indifferentiable with respect to the explanations and directly unavailable for gradient-based optimization, we extend the metrics to be differentiable and use them to formalize insertion and deletion metric-based regularizers. The experimental results on image and tabular datasets show that the deep neural networks-based predictors fine-tuned using ID-ExpO enable popular post-hoc explainers to produce more faithful
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#21033;&#29992;&#21442;&#25968;&#24341;&#23548;&#31639;&#27861;&#30340;&#31561;&#21464;&#24418;&#24335;&#65292;&#21487;&#20197;&#22312;&#25104;&#20687;&#21453;&#38382;&#39064;&#20013;&#37327;&#21270;&#37325;&#26500;&#22270;&#20687;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#19988;&#21487;&#20197;&#19982;&#20219;&#20309;&#22270;&#20687;&#37325;&#24314;&#25216;&#26415;&#32467;&#21512;&#20351;&#29992;&#12290;</title><link>http://arxiv.org/abs/2310.11838</link><description>&lt;p&gt;
&#31561;&#21464;&#24341;&#23548;&#27861;&#22312;&#25104;&#20687;&#21453;&#38382;&#39064;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Equivariant Bootstrapping for Uncertainty Quantification in Imaging Inverse Problems. (arXiv:2310.11838v1 [eess.IV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11838
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#21033;&#29992;&#21442;&#25968;&#24341;&#23548;&#31639;&#27861;&#30340;&#31561;&#21464;&#24418;&#24335;&#65292;&#21487;&#20197;&#22312;&#25104;&#20687;&#21453;&#38382;&#39064;&#20013;&#37327;&#21270;&#37325;&#26500;&#22270;&#20687;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#19988;&#21487;&#20197;&#19982;&#20219;&#20309;&#22270;&#20687;&#37325;&#24314;&#25216;&#26415;&#32467;&#21512;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31185;&#23398;&#25104;&#20687;&#38382;&#39064;&#36890;&#24120;&#23384;&#22312;&#20005;&#37325;&#30340;&#19981;&#36866;&#23450;&#24615;&#65292;&#22240;&#27492;&#20855;&#26377;&#37325;&#35201;&#30340;&#20869;&#22312;&#19981;&#30830;&#23450;&#24615;&#12290;&#20934;&#30830;&#37327;&#21270;&#35299;&#20915;&#26041;&#26696;&#30340;&#19981;&#30830;&#23450;&#24615;&#23545;&#20110;&#20005;&#26684;&#35299;&#37322;&#23454;&#39564;&#32467;&#26524;&#20197;&#21450;&#21487;&#38752;&#22320;&#20351;&#29992;&#37325;&#26500;&#22270;&#20687;&#20316;&#20026;&#31185;&#23398;&#35777;&#25454;&#33267;&#20851;&#37325;&#35201;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#29616;&#26377;&#30340;&#25104;&#20687;&#26041;&#27861;&#26080;&#27861;&#20197;&#23545;&#23454;&#39564;&#37325;&#22797;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#26041;&#24335;&#37327;&#21270;&#37325;&#26500;&#22270;&#20687;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#22522;&#20110;&#21442;&#25968;&#24341;&#23548;&#31639;&#27861;&#30340;&#31561;&#21464;&#24418;&#24335;&#65292;&#21033;&#29992;&#22312;&#25104;&#20687;&#38382;&#39064;&#20013;&#24120;&#35265;&#30340;&#23545;&#31216;&#24615;&#21644;&#19981;&#21464;&#24615;&#29305;&#24615;&#12290;&#27492;&#22806;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#26159;&#36890;&#29992;&#30340;&#65292;&#21487;&#20197;&#36731;&#26494;&#22320;&#19982;&#20219;&#20309;&#22270;&#20687;&#37325;&#24314;&#25216;&#26415;&#32467;&#21512;&#20351;&#29992;&#65292;&#21253;&#25324;&#21482;&#33021;&#20174;&#35266;&#23519;&#25968;&#25454;&#20013;&#36827;&#34892;&#35757;&#32451;&#30340;&#26080;&#30417;&#30563;&#35757;&#32451;&#31574;&#30053;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#22312;&#21482;&#26377;&#35266;&#27979;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Scientific imaging problems are often severely ill-posed, and hence have significant intrinsic uncertainty. Accurately quantifying the uncertainty in the solutions to such problems is therefore critical for the rigorous interpretation of experimental results as well as for reliably using the reconstructed images as scientific evidence. Unfortunately, existing imaging methods are unable to quantify the uncertainty in the reconstructed images in a manner that is robust to experiment replications. This paper presents a new uncertainty quantification methodology based on an equivariant formulation of the parametric bootstrap algorithm that leverages symmetries and invariance properties commonly encountered in imaging problems. Additionally, the proposed methodology is general and can be easily applied with any image reconstruction technique, including unsupervised training strategies that can be trained from observed data alone, thus enabling uncertainty quantification in situations where 
&lt;/p&gt;</description></item><item><title>&#20197;&#21069;&#30740;&#31350;&#34920;&#26126;&#26420;&#32032;&#30340;LBA&#21644;LLP&#19981;&#33021;&#25552;&#20379;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;&#12290;&#20294;&#26412;&#30740;&#31350;&#26174;&#31034;&#65292;&#20351;&#29992;&#20855;&#26377;&#38543;&#26426;&#25277;&#26679;&#30340;&#21152;&#26435;LBA&#21487;&#20197;&#25552;&#20379;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;&#12290;</title><link>http://arxiv.org/abs/2310.10092</link><description>&lt;p&gt;
&#36890;&#36807;&#32858;&#21512;&#23454;&#29616;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;
&lt;/p&gt;
&lt;p&gt;
Label Differential Privacy via Aggregation. (arXiv:2310.10092v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10092
&lt;/p&gt;
&lt;p&gt;
&#20197;&#21069;&#30740;&#31350;&#34920;&#26126;&#26420;&#32032;&#30340;LBA&#21644;LLP&#19981;&#33021;&#25552;&#20379;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;&#12290;&#20294;&#26412;&#30740;&#31350;&#26174;&#31034;&#65292;&#20351;&#29992;&#20855;&#26377;&#38543;&#26426;&#25277;&#26679;&#30340;&#21152;&#26435;LBA&#21487;&#20197;&#25552;&#20379;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#29616;&#23454;&#24212;&#29992;&#20013;&#65292;&#29305;&#21035;&#26159;&#30001;&#20110;&#38544;&#31169;&#39046;&#22495;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#35757;&#32451;&#25968;&#25454;&#21487;&#20197;&#36827;&#34892;&#32858;&#21512;&#65292;&#20197;&#20445;&#25252;&#25935;&#24863;&#35757;&#32451;&#26631;&#31614;&#30340;&#38544;&#31169;&#12290;&#22312;&#26631;&#31614;&#27604;&#20363;&#23398;&#20064;(LLP)&#26694;&#26550;&#20013;&#65292;&#25968;&#25454;&#38598;&#34987;&#21010;&#20998;&#20026;&#29305;&#24449;&#21521;&#37327;&#30340;&#21253;&#65292;&#21482;&#33021;&#33719;&#24471;&#27599;&#20010;&#21253;&#20013;&#26631;&#31614;&#30340;&#24635;&#21644;&#12290;&#36827;&#19968;&#27493;&#38480;&#21046;&#30340;&#38480;&#21046;&#23398;&#20064;(LBA)&#26159;&#21482;&#33021;&#33719;&#24471;&#21253;&#30340;&#29305;&#24449;&#21521;&#37327;&#30340;&#24635;&#21644;&#65288;&#21487;&#33021;&#26159;&#21152;&#26435;&#30340;&#65289;&#12290;&#25105;&#20204;&#30740;&#31350;&#36825;&#31181;&#32858;&#21512;&#25216;&#26415;&#26159;&#21542;&#33021;&#22815;&#22312;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;(label-DP)&#30340;&#27010;&#24565;&#19979;&#25552;&#20379;&#38544;&#31169;&#20445;&#35777;&#65292;&#35813;&#27010;&#24565;&#20043;&#21069;&#22312;[Chaudhuri-Hsu'11, Ghazi et al.'21, Esfandiari et al.'22]&#20013;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#24456;&#23481;&#26131;&#30475;&#20986;&#65292;&#26420;&#32032;&#30340;LBA&#21644;LLP&#19981;&#33021;&#25552;&#20379;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;&#20855;&#26377;$m$&#20010;&#38543;&#26426;&#25277;&#26679;&#30340;&#19981;&#30456;&#20132;$k$-&#22823;&#23567;&#21253;&#30340;&#21152;&#26435;LBA&#23454;&#38469;&#19978;&#26159;$(\varepsilon,
&lt;/p&gt;
&lt;p&gt;
In many real-world applications, in particular due to recent developments in the privacy landscape, training data may be aggregated to preserve the privacy of sensitive training labels. In the learning from label proportions (LLP) framework, the dataset is partitioned into bags of feature-vectors which are available only with the sum of the labels per bag. A further restriction, which we call learning from bag aggregates (LBA) is where instead of individual feature-vectors, only the (possibly weighted) sum of the feature-vectors per bag is available. We study whether such aggregation techniques can provide privacy guarantees under the notion of label differential privacy (label-DP) previously studied in for e.g. [Chaudhuri-Hsu'11, Ghazi et al.'21, Esfandiari et al.'22].  It is easily seen that naive LBA and LLP do not provide label-DP. Our main result however, shows that weighted LBA using iid Gaussian weights with $m$ randomly sampled disjoint $k$-sized bags is in fact $(\varepsilon, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#32593;&#32476;&#22823;&#23567;&#21644;L2&#27491;&#21017;&#21270;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#35266;&#23519;&#21040;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#12290;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#29305;&#24449;&#21644;&#25042;&#24816;&#35757;&#32451;&#31574;&#30053;&#65292;&#22312;&#21442;&#25968;&#21644;&#29366;&#24577;&#25968;&#26080;&#38480;&#22823;&#30340;&#24773;&#20917;&#19979;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#30340;&#26368;&#23567;&#20108;&#20056;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;&#65292;&#24471;&#20986;&#20102;&#20854;&#25910;&#25947;&#24615;&#21644;&#26368;&#20248;&#24615;&#65292;&#24182;&#38416;&#36848;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#22312;&#35813;&#31639;&#27861;&#20013;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.05518</link><description>&lt;p&gt;
&#20851;&#20110;&#20351;&#29992;LSTD&#21644;&#38543;&#26426;&#29305;&#24449;&#30340;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#21452;&#19979;&#38477;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
On Double-Descent in Reinforcement Learning with LSTD and Random Features. (arXiv:2310.05518v1 [cs.LG] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05518
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#32593;&#32476;&#22823;&#23567;&#21644;L2&#27491;&#21017;&#21270;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#35266;&#23519;&#21040;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#12290;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#29305;&#24449;&#21644;&#25042;&#24816;&#35757;&#32451;&#31574;&#30053;&#65292;&#22312;&#21442;&#25968;&#21644;&#29366;&#24577;&#25968;&#26080;&#38480;&#22823;&#30340;&#24773;&#20917;&#19979;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#30340;&#26368;&#23567;&#20108;&#20056;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;&#65292;&#24471;&#20986;&#20102;&#20854;&#25910;&#25947;&#24615;&#21644;&#26368;&#20248;&#24615;&#65292;&#24182;&#38416;&#36848;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#22312;&#35813;&#31639;&#27861;&#20013;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;&#22312;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20854;&#24615;&#33021;&#21463;&#31070;&#32463;&#32593;&#32476;&#22823;&#23567;&#30340;&#24433;&#21709;&#12290;&#28982;&#32780;&#65292;&#22312;&#30417;&#30563;&#23398;&#20064;&#20013;&#36807;&#21442;&#25968;&#21270;&#21644;&#20854;&#24102;&#26469;&#30340;&#22909;&#22788;&#24050;&#32463;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#29702;&#35299;&#65292;&#20294;&#26159;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#24773;&#20917;&#21017;&#19981;&#22826;&#28165;&#26970;&#12290;&#26412;&#25991;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#25506;&#35752;&#20102;&#32593;&#32476;&#22823;&#23567;&#21644;L2&#27491;&#21017;&#21270;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#23558;&#21442;&#25968;&#20010;&#25968;&#19982;&#35775;&#38382;&#29366;&#24577;&#20010;&#25968;&#20043;&#27604;&#23450;&#20041;&#20026;&#20851;&#38190;&#22240;&#32032;&#65292;&#24403;&#35813;&#27604;&#20540;&#22823;&#20110;1&#26102;&#31216;&#20026;&#36807;&#21442;&#25968;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#65292;&#21363;&#22312;&#21442;&#25968;/&#29366;&#24577;&#27604;&#20026;1&#38468;&#36817;&#20250;&#31361;&#28982;&#24615;&#33021;&#19979;&#38477;&#12290;&#36890;&#36807;&#21033;&#29992;&#38543;&#26426;&#29305;&#24449;&#21644;&#25042;&#24816;&#35757;&#32451;&#31574;&#30053;&#65292;&#25105;&#20204;&#22312;&#26080;&#38480;&#22823;&#30340;&#21442;&#25968;&#21644;&#29366;&#24577;&#25968;&#19979;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#30340;&#26368;&#23567;&#20108;&#20056;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#20854;&#25910;&#25947;&#24615;&#21644;&#26368;&#20248;&#24615;&#65292;&#24182;&#38416;&#36848;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#22312;&#35813;&#31639;&#27861;&#20013;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Temporal Difference (TD) algorithms are widely used in Deep Reinforcement Learning (RL). Their performance is heavily influenced by the size of the neural network. While in supervised learning, the regime of over-parameterization and its benefits are well understood, the situation in RL is much less clear. In this paper, we present a theoretical analysis of the influence of network size and $l_2$-regularization on performance. We identify the ratio between the number of parameters and the number of visited states as a crucial factor and define over-parameterization as the regime when it is larger than one. Furthermore, we observe a double-descent phenomenon, i.e., a sudden drop in performance around the parameter/state ratio of one. Leveraging random features and the lazy training regime, we study the regularized Least-Square Temporal Difference (LSTD) algorithm in an asymptotic regime, as both the number of parameters and states go to infinity, maintaining a constant ratio. We derive 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#22312;&#20844;&#20849;&#20132;&#36890;&#31995;&#32479;&#20013;&#24314;&#31435;&#20102;&#20379;&#38656;&#27169;&#22411;&#65292;&#21033;&#29992;&#25968;&#25454;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#25581;&#31034;&#20102;&#36816;&#33829;&#26381;&#21153;&#20013;&#30340;&#31354;&#32570;&#12290;</title><link>http://arxiv.org/abs/2309.06299</link><description>&lt;p&gt;
&#22312;&#20844;&#20849;&#20132;&#36890;&#31995;&#32479;&#20013;&#24314;&#27169;&#20379;&#38656;
&lt;/p&gt;
&lt;p&gt;
Modeling Supply and Demand in Public Transportation Systems. (arXiv:2309.06299v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06299
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#22312;&#20844;&#20849;&#20132;&#36890;&#31995;&#32479;&#20013;&#24314;&#31435;&#20102;&#20379;&#38656;&#27169;&#22411;&#65292;&#21033;&#29992;&#25968;&#25454;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#25581;&#31034;&#20102;&#36816;&#33829;&#26381;&#21153;&#20013;&#30340;&#31354;&#32570;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21704;&#37324;&#26862;&#22561;&#20844;&#20849;&#20132;&#36890;&#37096;&#38376;&#26088;&#22312;&#21033;&#29992;&#20854;&#25968;&#25454;&#25552;&#39640;&#36816;&#33829;&#25928;&#29575;&#21644;&#25928;&#26524;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#20004;&#20010;&#20379;&#38656;&#27169;&#22411;&#65292;&#24110;&#21161;&#37096;&#38376;&#35782;&#21035;&#26381;&#21153;&#20013;&#30340;&#31354;&#32570;&#12290;&#27169;&#22411;&#32771;&#34385;&#20102;&#35768;&#22810;&#21464;&#37327;&#65292;&#21253;&#25324;&#21704;&#37324;&#26862;&#22561;&#24066;&#21521;&#32852;&#37030;&#25919;&#24220;&#25253;&#21578;&#30340;&#26041;&#24335;&#20197;&#21450;&#26368;&#33030;&#24369;&#20154;&#21475;&#32858;&#38598;&#30340;&#21306;&#22495;&#12290;&#25105;&#20204;&#37319;&#29992;&#25968;&#25454;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#36827;&#34892;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Harrisonburg Department of Public Transportation (HDPT) aims to leverage their data to improve the efficiency and effectiveness of their operations. We construct two supply and demand models that help the department identify gaps in their service. The models take many variables into account, including the way that the HDPT reports to the federal government and the areas with the most vulnerable populations in Harrisonburg City. We employ data analysis and machine learning techniques to make our predictions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Tukey&#28145;&#24230;&#30340;&#38543;&#26426;&#36817;&#20284;&#36136;&#37327;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22312;&#32500;&#24230;&#36739;&#39640;&#19988;&#25968;&#25454;&#20174;&#23545;&#25968;&#20985;&#38598;&#30340;&#22343;&#21248;&#20998;&#24067;&#20013;&#25277;&#26679;&#30340;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#31639;&#27861;&#21487;&#20197;&#27491;&#30830;&#36817;&#20284;&#26368;&#22823;&#28145;&#24230;&#21644;&#25509;&#36817;&#38646;&#30340;&#28145;&#24230;&#65292;&#32780;&#23545;&#20110;&#20013;&#38388;&#28145;&#24230;&#30340;&#28857;&#65292;&#20219;&#20309;&#22909;&#30340;&#36817;&#20284;&#37117;&#38656;&#35201;&#25351;&#25968;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2309.05657</link><description>&lt;p&gt;
&#20851;&#20110;Tukey&#28145;&#24230;&#30340;&#38543;&#26426;&#36817;&#20284;&#36136;&#37327;
&lt;/p&gt;
&lt;p&gt;
On the quality of randomized approximations of Tukey's depth. (arXiv:2309.05657v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05657
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Tukey&#28145;&#24230;&#30340;&#38543;&#26426;&#36817;&#20284;&#36136;&#37327;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22312;&#32500;&#24230;&#36739;&#39640;&#19988;&#25968;&#25454;&#20174;&#23545;&#25968;&#20985;&#38598;&#30340;&#22343;&#21248;&#20998;&#24067;&#20013;&#25277;&#26679;&#30340;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#31639;&#27861;&#21487;&#20197;&#27491;&#30830;&#36817;&#20284;&#26368;&#22823;&#28145;&#24230;&#21644;&#25509;&#36817;&#38646;&#30340;&#28145;&#24230;&#65292;&#32780;&#23545;&#20110;&#20013;&#38388;&#28145;&#24230;&#30340;&#28857;&#65292;&#20219;&#20309;&#22909;&#30340;&#36817;&#20284;&#37117;&#38656;&#35201;&#25351;&#25968;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Tukey&#28145;&#24230;&#65288;&#25110;&#21322;&#31354;&#38388;&#28145;&#24230;&#65289;&#26159;&#29992;&#20110;&#22810;&#20803;&#25968;&#25454;&#20013;&#24515;&#24230;&#37327;&#30340;&#24191;&#27867;&#24212;&#29992;&#30340;&#25351;&#26631;&#12290;&#28982;&#32780;&#65292;&#22312;&#39640;&#32500;&#24230;&#19979;&#65292;Tukey&#28145;&#24230;&#30340;&#31934;&#30830;&#35745;&#31639;&#34987;&#35748;&#20026;&#26159;&#19968;&#20010;&#22256;&#38590;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20154;&#20204;&#25552;&#20986;&#20102;Tukey&#28145;&#24230;&#30340;&#38543;&#26426;&#36817;&#20284;&#26041;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#36825;&#26679;&#30340;&#38543;&#26426;&#31639;&#27861;&#20309;&#26102;&#33021;&#22815;&#36820;&#22238;&#19968;&#20010;&#33391;&#22909;&#30340;Tukey&#28145;&#24230;&#36817;&#20284;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#25968;&#25454;&#20174;&#23545;&#25968;&#20985;&#38519;&#22343;&#21248;&#20998;&#24067;&#20013;&#25277;&#26679;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#22914;&#26524;&#35201;&#27714;&#31639;&#27861;&#22312;&#32500;&#24230;&#19978;&#20197;&#22810;&#39033;&#24335;&#26102;&#38388;&#36816;&#34892;&#65292;&#38543;&#26426;&#31639;&#27861;&#21487;&#20197;&#27491;&#30830;&#22320;&#36817;&#20284;&#26368;&#22823;&#28145;&#24230;1/2&#21644;&#25509;&#36817;&#38646;&#30340;&#28145;&#24230;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#23545;&#20110;&#20219;&#20309;&#20013;&#38388;&#28145;&#24230;&#30340;&#28857;&#65292;&#20219;&#20309;&#22909;&#30340;&#36817;&#20284;&#37117;&#38656;&#35201;&#25351;&#25968;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tukey's depth (or halfspace depth) is a widely used measure of centrality for multivariate data. However, exact computation of Tukey's depth is known to be a hard problem in high dimensions. As a remedy, randomized approximations of Tukey's depth have been proposed. In this paper we explore when such randomized algorithms return a good approximation of Tukey's depth. We study the case when the data are sampled from a log-concave isotropic distribution. We prove that, if one requires that the algorithm runs in polynomial time in the dimension, the randomized algorithm correctly approximates the maximal depth $1/2$ and depths close to zero. On the other hand, for any point of intermediate depth, any good approximation requires exponential complexity.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#25552;&#21462;&#26089;&#26399;&#23551;&#21629;&#20013;&#30340;&#23481;&#37327;-&#30005;&#21387;&#25968;&#25454;&#30340;&#26032;&#29305;&#24449;&#65292;&#25104;&#21151;&#39044;&#27979;&#20102;&#22312;&#19981;&#21516;&#20351;&#29992;&#26465;&#20214;&#19979;&#30340;&#30005;&#27744;&#23551;&#21629;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20123;&#26089;&#26399;&#29305;&#24449;&#33021;&#22815;&#24456;&#22909;&#22320;&#25429;&#25417;&#30005;&#27744;&#30340;&#20581;&#24247;&#29366;&#24577;&#21644;&#32769;&#21270;&#27169;&#24335;&#30340;&#21464;&#21270;&#36895;&#29575;&#65292;&#20026;&#30005;&#27744;&#23551;&#21629;&#39044;&#27979;&#25552;&#20379;&#20102;&#26377;&#24076;&#26395;&#30340;&#36884;&#24452;&#12290;</title><link>http://arxiv.org/abs/2307.08382</link><description>&lt;p&gt;
&#20174;&#26089;&#26399;&#32769;&#21270;&#25968;&#25454;&#20013;&#39044;&#27979;&#19981;&#21516;&#20351;&#29992;&#26465;&#20214;&#19979;&#30340;&#30005;&#27744;&#23551;&#21629;
&lt;/p&gt;
&lt;p&gt;
Predicting Battery Lifetime Under Varying Usage Conditions from Early Aging Data. (arXiv:2307.08382v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08382
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#25552;&#21462;&#26089;&#26399;&#23551;&#21629;&#20013;&#30340;&#23481;&#37327;-&#30005;&#21387;&#25968;&#25454;&#30340;&#26032;&#29305;&#24449;&#65292;&#25104;&#21151;&#39044;&#27979;&#20102;&#22312;&#19981;&#21516;&#20351;&#29992;&#26465;&#20214;&#19979;&#30340;&#30005;&#27744;&#23551;&#21629;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20123;&#26089;&#26399;&#29305;&#24449;&#33021;&#22815;&#24456;&#22909;&#22320;&#25429;&#25417;&#30005;&#27744;&#30340;&#20581;&#24247;&#29366;&#24577;&#21644;&#32769;&#21270;&#27169;&#24335;&#30340;&#21464;&#21270;&#36895;&#29575;&#65292;&#20026;&#30005;&#27744;&#23551;&#21629;&#39044;&#27979;&#25552;&#20379;&#20102;&#26377;&#24076;&#26395;&#30340;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31934;&#30830;&#30340;&#30005;&#27744;&#23551;&#21629;&#39044;&#27979;&#23545;&#20110;&#39044;&#38450;&#24615;&#32500;&#25252;&#12289;&#20445;&#20462;&#21644;&#25913;&#36827;&#30340;&#30005;&#27744;&#35774;&#35745;&#21644;&#21046;&#36896;&#38750;&#24120;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#21046;&#36896;&#21487;&#21464;&#24615;&#21644;&#20351;&#29992;&#20381;&#36182;&#24615;&#38477;&#35299;&#20351;&#24471;&#23551;&#21629;&#39044;&#27979;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#20174;&#26089;&#26399;&#23551;&#21629;&#20013;&#25552;&#21462;&#30340;&#23481;&#37327;-&#30005;&#21387;&#25968;&#25454;&#30340;&#26032;&#29305;&#24449;&#26469;&#39044;&#27979;&#22312;&#20805;&#30005;&#36895;&#29575;&#12289;&#25918;&#30005;&#36895;&#29575;&#21644;&#25918;&#30005;&#28145;&#24230;&#24046;&#24322;&#36739;&#22823;&#30340;&#30005;&#27744;&#30340;&#23551;&#21629;&#12290;&#36825;&#20123;&#29305;&#24449;&#26159;&#20174;&#23450;&#26399;&#23433;&#25490;&#30340;&#21442;&#32771;&#24615;&#33021;&#27979;&#35797;&#20013;&#25552;&#21462;&#30340;&#65288;&#21363;&#20302;&#36895;&#23436;&#20840;&#24490;&#29615;&#65289;&#12290;&#26089;&#26399;&#29983;&#21629;&#21608;&#26399;&#29305;&#24449;&#25429;&#25417;&#21040;&#20102;&#30005;&#27744;&#30340;&#20581;&#24247;&#29366;&#24577;&#21644;&#21508;&#32452;&#20214;&#32423;&#21035;&#32769;&#21270;&#27169;&#24335;&#30340;&#21464;&#21270;&#36895;&#29575;&#65292;&#20854;&#20013;&#19968;&#20123;&#19982;&#30005;&#27744;&#23551;&#21629;&#21576;&#24378;&#30456;&#20851;&#24615;&#12290;&#36890;&#36807;&#23545;&#30001;225&#20010;&#38221;-&#38192;-&#38068;/&#30707;&#22696;&#38146;&#31163;&#23376;&#30005;&#27744;&#22312;&#24191;&#27867;&#26465;&#20214;&#19979;&#32769;&#21270;&#20135;&#29983;&#30340;&#26032;&#25968;&#25454;&#38598;&#30340;&#20351;&#29992;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#20998;&#24067;&#20869;&#30340;&#30005;&#27744;&#30340;&#23551;&#21629;&#39044;&#27979;&#33021;&#22815;&#36798;&#21040;15.1%&#30340;&#24179;&#22343;&#32477;&#23545;&#30334;&#20998;&#27604;&#35823;&#24046;&#65292;&#24182;&#19988;&#21482;&#20351;&#29992;&#20102;&#21069;15%&#30340;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Accurate battery lifetime prediction is important for preventative maintenance, warranties, and improved cell design and manufacturing. However, manufacturing variability and usage-dependent degradation make life prediction challenging. Here, we investigate new features derived from capacity-voltage data in early life to predict the lifetime of cells cycled under widely varying charge rates, discharge rates, and depths of discharge. Features were extracted from regularly scheduled reference performance tests (i.e., low rate full cycles) during cycling. The early-life features capture a cell's state of health and the rate of change of component-level degradation modes, some of which correlate strongly with cell lifetime. Using a newly generated dataset from 225 nickel-manganese-cobalt/graphite Li-ion cells aged under a wide range of conditions, we demonstrate a lifetime prediction of in-distribution cells with 15.1% mean absolute percentage error using no more than the first 15% of data
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Transformer&#22312;&#20855;&#26377;&#21333;&#23618;&#32447;&#24615;&#33258;&#27880;&#24847;&#23618;&#30340;&#32447;&#24615;&#22238;&#24402;&#20219;&#21153;&#19978;&#36890;&#36807;&#26799;&#24230;&#27969;&#36827;&#34892;&#35757;&#32451;&#30340;ICL&#26426;&#21046;&#65292;&#25581;&#31034;&#20102;&#26799;&#24230;&#27969;&#20855;&#26377;&#25214;&#21040;&#30446;&#26631;&#20989;&#25968;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2306.09927</link><description>&lt;p&gt;
&#35757;&#32451;&#22909;&#30340;Transformer&#22312;&#19978;&#19979;&#25991;&#20013;&#23398;&#20064;&#32447;&#24615;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Trained Transformers Learn Linear Models In-Context. (arXiv:2306.09927v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09927
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Transformer&#22312;&#20855;&#26377;&#21333;&#23618;&#32447;&#24615;&#33258;&#27880;&#24847;&#23618;&#30340;&#32447;&#24615;&#22238;&#24402;&#20219;&#21153;&#19978;&#36890;&#36807;&#26799;&#24230;&#27969;&#36827;&#34892;&#35757;&#32451;&#30340;ICL&#26426;&#21046;&#65292;&#25581;&#31034;&#20102;&#26799;&#24230;&#27969;&#20855;&#26377;&#25214;&#21040;&#30446;&#26631;&#20989;&#25968;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#20363;&#22914;Transformers&#65292;&#22312;&#19978;&#19979;&#25991;&#23398;&#20064;&#65288;ICL&#65289;&#26041;&#38754;&#34920;&#29616;&#20986;&#20102;&#38750;&#20961;&#30340;&#33021;&#21147;&#65306;&#32473;&#23450;&#19968;&#20010;&#26469;&#33258;&#26410;&#35265;&#36807;&#30340;&#20219;&#21153;&#30340;&#30701;&#35821;&#24207;&#21015;&#30340;&#25552;&#31034;&#65292;&#23427;&#20204;&#21487;&#20197;&#21046;&#23450;&#30456;&#20851;&#30340;&#27599;&#20010;&#20196;&#29260;&#21644;&#19979;&#19968;&#20010;&#20196;&#29260;&#30340;&#39044;&#27979;&#65292;&#32780;&#19981;&#38656;&#35201;&#20219;&#20309;&#21442;&#25968;&#26356;&#26032;&#12290;&#36890;&#36807;&#23558;&#26631;&#35760;&#30340;&#35757;&#32451;&#25968;&#25454;&#21644;&#26410;&#26631;&#35760;&#30340;&#27979;&#35797;&#25968;&#25454;&#24207;&#21015;&#23884;&#20837;&#21040;&#25552;&#31034;&#20013;&#65292;&#36825;&#20351;&#24471;Transformer&#34920;&#29616;&#24471;&#20687;&#26377;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#12290;&#20107;&#23454;&#19978;&#65292;&#26368;&#36817;&#30340;&#24037;&#20316;&#34920;&#26126;&#65292;&#22312;&#38543;&#26426;&#23454;&#20363;&#19978;&#35757;&#32451;Transformer&#20307;&#31995;&#32467;&#26500;&#30340;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#26102;&#65292;&#36825;&#20123;&#27169;&#22411;&#30340;&#39044;&#27979;&#20250;&#27169;&#20223;&#26222;&#36890;&#26368;&#23567;&#20108;&#20056;&#27861;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Attention-based neural networks such as transformers have demonstrated a remarkable ability to exhibit in-context learning (ICL): Given a short prompt sequence of tokens from an unseen task, they can formulate relevant per-token and next-token predictions without any parameter updates. By embedding a sequence of labeled training data and unlabeled test data as a prompt, this allows for transformers to behave like supervised learning algorithms. Indeed, recent work has shown that when training transformer architectures over random instances of linear regression problems, these models' predictions mimic those of ordinary least squares.  Towards understanding the mechanisms underlying this phenomenon, we investigate the dynamics of ICL in transformers with a single linear self-attention layer trained by gradient flow on linear regression tasks. We show that despite non-convexity, gradient flow with a suitable random initialization finds a global minimum of the objective function. At this 
&lt;/p&gt;</description></item><item><title>PDCA&#26159;&#19968;&#31181;&#29992;&#20110;&#31163;&#32447;&#32422;&#26463;&#24378;&#21270;&#23398;&#20064;&#30340;&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#36890;&#36807;&#22312;Lagrangian&#20989;&#25968;&#19978;&#36816;&#34892;&#21407;&#22987;-&#23545;&#20598;&#31639;&#27861;&#26469;&#25214;&#21040;&#36817;&#20284;&#38797;&#28857;&#65292;&#32780;&#26080;&#38656;&#38598;&#20013;&#24615;&#21644;&#24378;Bellman&#23436;&#22791;&#24615;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2306.07818</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#21407;&#22987;-&#23545;&#20598;-&#35780;&#35770;&#23478;&#31639;&#27861;&#30340;&#31163;&#32447;&#32422;&#26463;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
A Primal-Dual-Critic Algorithm for Offline Constrained Reinforcement Learning. (arXiv:2306.07818v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07818
&lt;/p&gt;
&lt;p&gt;
PDCA&#26159;&#19968;&#31181;&#29992;&#20110;&#31163;&#32447;&#32422;&#26463;&#24378;&#21270;&#23398;&#20064;&#30340;&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#36890;&#36807;&#22312;Lagrangian&#20989;&#25968;&#19978;&#36816;&#34892;&#21407;&#22987;-&#23545;&#20598;&#31639;&#27861;&#26469;&#25214;&#21040;&#36817;&#20284;&#38797;&#28857;&#65292;&#32780;&#26080;&#38656;&#38598;&#20013;&#24615;&#21644;&#24378;Bellman&#23436;&#22791;&#24615;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#32422;&#26463;&#24378;&#21270;&#23398;&#20064;&#26088;&#22312;&#23398;&#20064;&#19968;&#31181;&#31574;&#30053;&#65292;&#20197;&#22312;&#29616;&#26377;&#25968;&#25454;&#38598;&#19978;&#28385;&#36275;&#23545;&#25104;&#26412;&#20989;&#25968;&#26399;&#26395;&#20540;&#30340;&#38480;&#21046;&#26465;&#20214;&#19979;&#26368;&#22823;&#21270;&#39044;&#26399;&#30340;&#32047;&#31215;&#22870;&#21169;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#21407;&#22987;-&#23545;&#20598;-&#35780;&#35770;&#23478;&#31639;&#27861;&#65288;PDCA&#65289;&#30340;&#26032;&#31639;&#27861;&#65292;&#29992;&#20110;&#20855;&#26377;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#30340;&#31163;&#32447;&#32422;&#26463;&#24378;&#21270;&#23398;&#20064;&#12290;PDCA&#22312;&#35780;&#35770;&#23478;&#20272;&#35745;&#30340;Lagrangian&#20989;&#25968;&#19978;&#36816;&#34892;&#21407;&#22987;-&#23545;&#20598;&#31639;&#27861;&#12290;&#21407;&#22987;&#29609;&#23478;&#37319;&#29992;&#26080;&#24724;&#31574;&#30053;&#20248;&#21270;&#31070;&#35861;&#65292;&#22312;&#32473;&#23450;&#20219;&#20309;&#35780;&#35770;&#23478;&#21644;&#23545;&#20598;&#29609;&#23478;&#30340;&#36873;&#25321;&#30340;&#24773;&#20917;&#19979;&#26368;&#22823;&#21270;&#25289;&#26684;&#26391;&#26085;&#20989;&#25968;&#30340;&#20272;&#35745;&#12290;&#23545;&#20598;&#29609;&#23478;&#36890;&#36807;&#37319;&#29992;&#26080;&#24724;&#22312;&#32447;&#32447;&#24615;&#20248;&#21270;&#31070;&#35861;&#65292;&#22312;&#32473;&#23450;&#35780;&#35770;&#23478;&#21644;&#21407;&#22987;&#29609;&#23478;&#30340;&#20219;&#20309;&#36873;&#25321;&#30340;&#24773;&#20917;&#19979;&#26368;&#23567;&#21270;&#25289;&#26684;&#26391;&#26085;&#20989;&#25968;&#30340;&#20272;&#35745;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;PDCA&#21487;&#20197;&#25104;&#21151;&#22320;&#25214;&#21040;&#25289;&#26684;&#26391;&#26085;&#20989;&#25968;&#30340;&#36817;&#20284;&#38797;&#28857;&#65292;&#36825;&#23545;&#20110;&#32422;&#26463;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#20960;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;&#19982;&#20197;&#21069;&#38656;&#35201;&#38598;&#20013;&#24615;&#21644;&#24378;Bellman&#23436;&#22791;&#24615;&#20551;&#35774;&#30340;&#20316;&#21697;&#19981;&#21516;&#65292;PDCA&#21482;&#38656;&#35201;&#19968;&#33268;&#24615;&#21644;&#33258;&#38381;&#24615;&#36825;&#20004;&#20010;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
Offline constrained reinforcement learning (RL) aims to learn a policy that maximizes the expected cumulative reward subject to constraints on expected value of cost functions using an existing dataset. In this paper, we propose Primal-Dual-Critic Algorithm (PDCA), a novel algorithm for offline constrained RL with general function approximation. PDCA runs a primal-dual algorithm on the Lagrangian function estimated by critics. The primal player employs a no-regret policy optimization oracle to maximize the Lagrangian estimate given any choices of the critics and the dual player. The dual player employs a no-regret online linear optimization oracle to minimize the Lagrangian estimate given any choices of the critics and the primal player. We show that PDCA can successfully find a near saddle point of the Lagrangian, which is nearly optimal for the constrained RL problem. Unlike previous work that requires concentrability and strong Bellman completeness assumptions, PDCA only requires co
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#39564;&#35777;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21363;&#35757;&#32451;&#26131;&#20110;&#39564;&#35777;&#30340;&#38480;&#21046;&#27169;&#22411;&#31867;&#26469;&#35299;&#20915;&#20915;&#31574;&#26641;&#38598;&#25104;&#30340; NP-hard &#38382;&#39064;&#65292;&#24182;&#25104;&#21151;&#35774;&#35745;&#20986;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#20351;&#24471;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#21487;&#20197;&#36827;&#34892;&#23433;&#20840;&#39564;&#35777;&#65292;&#32780;&#19988;&#20173;&#20445;&#25345;&#30528;&#35813;&#39046;&#22495;&#26368;&#22909;&#30340;&#40065;&#26834;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.03626</link><description>&lt;p&gt;
&#40065;&#26834;&#20915;&#31574;&#26641;&#38598;&#25104;&#30340;&#21487;&#39564;&#35777;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Verifiable Learning for Robust Tree Ensembles. (arXiv:2305.03626v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03626
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#39564;&#35777;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21363;&#35757;&#32451;&#26131;&#20110;&#39564;&#35777;&#30340;&#38480;&#21046;&#27169;&#22411;&#31867;&#26469;&#35299;&#20915;&#20915;&#31574;&#26641;&#38598;&#25104;&#30340; NP-hard &#38382;&#39064;&#65292;&#24182;&#25104;&#21151;&#35774;&#35745;&#20986;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#20351;&#24471;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#21487;&#20197;&#36827;&#34892;&#23433;&#20840;&#39564;&#35777;&#65292;&#32780;&#19988;&#20173;&#20445;&#25345;&#30528;&#35813;&#39046;&#22495;&#26368;&#22909;&#30340;&#40065;&#26834;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27979;&#35797;&#26102;&#38388;&#20869;&#39564;&#35777;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#23545;&#25239;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#30740;&#31350;&#38382;&#39064;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#30830;&#23450;&#65292;&#23545;&#20110;&#20915;&#31574;&#26641;&#38598;&#25104;&#65292;&#36825;&#20010;&#38382;&#39064;&#26159; NP-hard &#65292;&#22240;&#27492;&#23545;&#20110;&#29305;&#23450;&#30340;&#36755;&#20837;&#26469;&#35828;&#26159;&#19981;&#21487;&#35299;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#19968;&#31867;&#21463;&#38480;&#20915;&#31574;&#26641;&#38598;&#25104;&#65292;&#31216;&#20026; large-spread &#38598;&#25104;&#65292;&#20854;&#20801;&#35768;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#36816;&#34892;&#23433;&#20840;&#39564;&#35777;&#31639;&#27861;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#31216;&#20026;&#21487;&#39564;&#35777;&#23398;&#20064;&#65292;&#35813;&#26041;&#27861;&#20513;&#23548;&#35757;&#32451;&#36825;&#31181;&#26131;&#20110;&#39564;&#35777;&#30340;&#21463;&#38480;&#27169;&#22411;&#31867;&#12290;&#25105;&#20204;&#36890;&#36807;&#35774;&#35745;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#20174;&#26631;&#35760;&#25968;&#25454;&#20013;&#33258;&#21160;&#23398;&#20064; large-spread &#20915;&#31574;&#26641;&#38598;&#25104;&#26469;&#23637;&#31034;&#36825;&#31181;&#26041;&#27861;&#30340;&#30410;&#22788;&#65292;&#20174;&#32780;&#20351;&#20854;&#33021;&#22815;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#36827;&#34892;&#23433;&#20840;&#39564;&#35777;&#12290;&#20844;&#24320;&#21487;&#29992;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#35777;&#23454;&#65292;&#20351;&#29992;&#25105;&#20204;&#30340;&#31639;&#27861;&#35757;&#32451;&#30340; large-spread &#38598;&#25104;&#21487;&#20197;&#22312;&#20960;&#31186;&#38047;&#20869;&#20351;&#29992;&#26631;&#20934;&#21322;&#23450;&#32534;&#31243;&#27714;&#35299;&#22120;&#36827;&#34892;&#39564;&#35777;&#65292;&#21516;&#26102;&#23545;&#25239;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#25915;&#20987;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Verifying the robustness of machine learning models against evasion attacks at test time is an important research problem. Unfortunately, prior work established that this problem is NP-hard for decision tree ensembles, hence bound to be intractable for specific inputs. In this paper, we identify a restricted class of decision tree ensembles, called large-spread ensembles, which admit a security verification algorithm running in polynomial time. We then propose a new approach called verifiable learning, which advocates the training of such restricted model classes which are amenable for efficient verification. We show the benefits of this idea by designing a new training algorithm that automatically learns a large-spread decision tree ensemble from labelled data, thus enabling its security verification in polynomial time. Experimental results on publicly available datasets confirm that large-spread ensembles trained using our algorithm can be verified in a matter of seconds, using stand
&lt;/p&gt;</description></item><item><title>&#38024;&#23545;&#24102;&#26377;&#19987;&#23478;&#24314;&#35758;&#30340;&#22312;&#32447;&#39044;&#27979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#29992;&#36873;&#25321;&#24615;&#37319;&#26679;&#26041;&#26696;&#30340;&#26631;&#31614;&#39640;&#25928;&#39044;&#27979;&#31639;&#27861;&#65292;&#33021;&#22815;&#20351;&#29992;&#27604;&#26631;&#20934;&#31243;&#24207;&#23569;&#24471;&#22810;&#30340;&#26631;&#31614;&#65292;&#24182;&#20445;&#25345;&#26368;&#20248;&#26368;&#22351;&#24773;&#20917;&#21518;&#24724;&#20445;&#35777;&#12290;&#23545;&#20110;&#22312;&#26399;&#26395;&#19978;&#26126;&#26174;&#26356;&#22909;&#30340;&#19987;&#23478;&#65292;&#31639;&#27861;&#30340;&#26631;&#31614;&#22797;&#26434;&#24230;&#19982;&#22238;&#21512;&#25968;&#30340;&#24179;&#26041;&#26681;&#25104;&#27604;&#20363;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#19982;&#27744;&#24335;&#20027;&#21160;&#23398;&#20064;&#30340;&#26497;&#23567;&#26497;&#22823;&#36895;&#29575;&#30456;&#21305;&#37197;&#30340;&#24402;&#19968;&#21270;&#21518;&#24724;&#12290;</title><link>http://arxiv.org/abs/2302.08397</link><description>&lt;p&gt;
&#23545;&#20110;&#24102;&#26377;&#19987;&#23478;&#24314;&#35758;&#30340;&#22312;&#32447;&#39044;&#27979;&#65292;&#33258;&#36866;&#24212;&#36873;&#25321;&#37319;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Adaptive Selective Sampling for Online Prediction with Experts. (arXiv:2302.08397v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08397
&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#24102;&#26377;&#19987;&#23478;&#24314;&#35758;&#30340;&#22312;&#32447;&#39044;&#27979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#29992;&#36873;&#25321;&#24615;&#37319;&#26679;&#26041;&#26696;&#30340;&#26631;&#31614;&#39640;&#25928;&#39044;&#27979;&#31639;&#27861;&#65292;&#33021;&#22815;&#20351;&#29992;&#27604;&#26631;&#20934;&#31243;&#24207;&#23569;&#24471;&#22810;&#30340;&#26631;&#31614;&#65292;&#24182;&#20445;&#25345;&#26368;&#20248;&#26368;&#22351;&#24773;&#20917;&#21518;&#24724;&#20445;&#35777;&#12290;&#23545;&#20110;&#22312;&#26399;&#26395;&#19978;&#26126;&#26174;&#26356;&#22909;&#30340;&#19987;&#23478;&#65292;&#31639;&#27861;&#30340;&#26631;&#31614;&#22797;&#26434;&#24230;&#19982;&#22238;&#21512;&#25968;&#30340;&#24179;&#26041;&#26681;&#25104;&#27604;&#20363;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#19982;&#27744;&#24335;&#20027;&#21160;&#23398;&#20064;&#30340;&#26497;&#23567;&#26497;&#22823;&#36895;&#29575;&#30456;&#21305;&#37197;&#30340;&#24402;&#19968;&#21270;&#21518;&#24724;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#23545;&#20110;&#20108;&#36827;&#21046;&#24207;&#21015;&#30340;&#22312;&#32447;&#39044;&#27979;&#65292;&#25152;&#25552;&#20986;&#30340;&#26631;&#31614;&#39640;&#25928;&#39044;&#27979;&#31639;&#27861;&#20351;&#29992;&#20102;&#36873;&#25321;&#24615;&#37319;&#26679;&#26041;&#26696;&#65292;&#22312;&#20445;&#25345;&#26368;&#20248;&#26368;&#22351;&#24773;&#20917;&#21518;&#24724;&#20445;&#35777;&#30340;&#21516;&#26102;&#65292;&#33021;&#22815;&#20351;&#29992;&#27604;&#26631;&#20934;&#31243;&#24207;&#23569;&#24471;&#22810;&#30340;&#26631;&#31614;&#12290;&#36825;&#20123;&#31639;&#27861;&#22522;&#20110;&#25351;&#25968;&#21152;&#26435;&#39044;&#27979;&#22120;&#65292;&#36866;&#29992;&#20110;&#26377;&#25110;&#26080;&#23436;&#32654;&#19987;&#23478;&#30340;&#24773;&#20917;&#12290;&#23545;&#20110;&#19968;&#20010;&#22312;&#26399;&#26395;&#19978;&#26126;&#26174;&#26356;&#22909;&#30340;&#19987;&#23478;&#32780;&#35328;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26631;&#31614;&#39640;&#25928;&#39044;&#27979;&#22120;&#30340;&#26631;&#31614;&#22797;&#26434;&#24230;&#22823;&#33268;&#19982;&#22238;&#21512;&#25968;&#30340;&#24179;&#26041;&#26681;&#25104;&#27604;&#20363;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#26631;&#31614;&#39640;&#25928;&#39044;&#27979;&#22120;&#30340;&#24402;&#19968;&#21270;&#21518;&#24724;&#21487;&#20197;&#28176;&#36817;&#21305;&#37197;&#24050;&#30693;&#30340;&#22522;&#20110;&#27744;&#24335;&#20027;&#21160;&#23398;&#20064;&#30340;&#26497;&#23567;&#26497;&#22823;&#36895;&#29575;&#65292;&#34920;&#26126;&#23427;&#33021;&#22815;&#22312;&#33391;&#24615;&#29615;&#22659;&#20013;&#36827;&#34892;&#26368;&#20248;&#36866;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider online prediction of a binary sequence with expert advice. For this setting, we devise label-efficient forecasting algorithms, which use a selective sampling scheme that enables collecting much fewer labels than standard procedures, while still retaining optimal worst-case regret guarantees. These algorithms are based on exponentially weighted forecasters, suitable for settings with and without a perfect expert. For a scenario where one expert is strictly better than the others in expectation, we show that the label complexity of the label-efficient forecaster scales roughly as the square root of the number of rounds. Finally, we present numerical experiments empirically showing that the normalized regret of the label-efficient forecaster can asymptotically match known minimax rates for pool-based active learning, suggesting it can optimally adapt to benign settings.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20379;&#20102;&#26680;&#23725;&#22238;&#24402;&#26041;&#27861;&#30340;&#19968;&#33268;&#25512;&#26029;&#21644;&#32622;&#20449;&#24102;&#65292;&#20026;&#24191;&#27867;&#24212;&#29992;&#20110;&#21508;&#31181;&#25968;&#25454;&#31867;&#22411;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#20272;&#35745;&#22120;&#25552;&#20379;&#20102;&#20934;&#30830;&#30340;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2302.06578</link><description>&lt;p&gt;
&#26680;&#23725;&#22238;&#24402;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Kernel Ridge Regression Inference. (arXiv:2302.06578v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06578
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#26680;&#23725;&#22238;&#24402;&#26041;&#27861;&#30340;&#19968;&#33268;&#25512;&#26029;&#21644;&#32622;&#20449;&#24102;&#65292;&#20026;&#24191;&#27867;&#24212;&#29992;&#20110;&#21508;&#31181;&#25968;&#25454;&#31867;&#22411;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#20272;&#35745;&#22120;&#25552;&#20379;&#20102;&#20934;&#30830;&#30340;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#26680;&#23725;&#22238;&#24402;(KRR)&#30340;&#19968;&#33268;&#25512;&#26029;&#21644;&#32622;&#20449;&#24102;&#65292;&#36825;&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#20110;&#21253;&#25324;&#25490;&#21517;&#12289;&#22270;&#20687;&#21644;&#22270;&#34920;&#22312;&#20869;&#30340;&#19968;&#33324;&#25968;&#25454;&#31867;&#22411;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#20272;&#35745;&#22120;&#12290;&#23613;&#31649;&#36825;&#20123;&#25968;&#25454;&#30340;&#26222;&#36941;&#23384;&#22312;&#65292;&#22914;&#23398;&#26657;&#20998;&#37197;&#20013;&#30340;&#25490;&#24207;&#20248;&#20808;&#32423;&#21015;&#34920;&#65292;&#20294;KRR&#30340;&#25512;&#26029;&#29702;&#35770;&#23578;&#26410;&#23436;&#20840;&#30693;&#24713;&#65292;&#38480;&#21046;&#20102;&#23427;&#22312;&#32463;&#27982;&#23398;&#21644;&#20854;&#20182;&#31185;&#23398;&#39046;&#22495;&#20013;&#30340;&#20316;&#29992;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#38024;&#23545;&#19968;&#33324;&#22238;&#24402;&#22120;&#30340;&#23574;&#38160;&#12289;&#19968;&#33268;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#20026;&#20102;&#36827;&#34892;&#25512;&#26029;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#33258;&#20030;&#31243;&#24207;&#65292;&#36890;&#36807;&#23545;&#31216;&#21270;&#26469;&#28040;&#38500;&#20559;&#24046;&#24182;&#38480;&#21046;&#35745;&#31639;&#24320;&#38144;&#12290;&#20026;&#20102;&#35777;&#26126;&#35813;&#31243;&#24207;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;(RKHS)&#20013;&#37096;&#20998;&#21644;&#30340;&#26377;&#38480;&#26679;&#26412;&#12289;&#22343;&#21248;&#39640;&#26031;&#21644;&#33258;&#20030;&#32806;&#21512;&#12290;&#36825;&#20123;&#25512;&#23548;&#26263;&#31034;&#20102;&#22522;&#20110;RKHS&#21333;&#20301;&#29699;&#30340;&#32463;&#39564;&#36807;&#31243;&#30340;&#24378;&#36924;&#36817;&#65292;&#23545;&#35206;&#30422;&#25968;&#20855;&#26377;&#23545;&#25968;&#20381;&#36182;&#20851;&#31995;&#12290;&#27169;&#25311;&#39564;&#35777;&#20102;&#32622;&#20449;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide uniform inference and confidence bands for kernel ridge regression (KRR), a widely-used non-parametric regression estimator for general data types including rankings, images, and graphs. Despite the prevalence of these data -e.g., ranked preference lists in school assignment -- the inferential theory of KRR is not fully known, limiting its role in economics and other scientific domains. We construct sharp, uniform confidence sets for KRR, which shrink at nearly the minimax rate, for general regressors. To conduct inference, we develop an efficient bootstrap procedure that uses symmetrization to cancel bias and limit computational overhead. To justify the procedure, we derive finite-sample, uniform Gaussian and bootstrap couplings for partial sums in a reproducing kernel Hilbert space (RKHS). These imply strong approximation for empirical processes indexed by the RKHS unit ball with logarithmic dependence on the covering number. Simulations verify coverage. We use our proce
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#28145;&#24230;&#23398;&#20064;&#20013;&#38543;&#26426;&#26799;&#24230;&#30340;&#32467;&#26500;&#36827;&#34892;&#20102;&#27491;&#24335;&#30340;&#32479;&#35745;&#26816;&#39564;&#65292;&#21457;&#29616;&#36880;&#32500;&#26799;&#24230;&#36890;&#24120;&#21576;&#29616;&#24130;&#24459;&#37325;&#23614;&#65292;&#32780;&#36880;&#27425;&#36845;&#20195;&#30340;&#26799;&#24230;&#21644;&#38543;&#26426;&#26799;&#24230;&#22122;&#22768;&#36890;&#24120;&#19981;&#21576;&#29616;&#24130;&#24459;&#37325;&#23614;&#12290;</title><link>http://arxiv.org/abs/2212.02083</link><description>&lt;p&gt;
&#20851;&#20110;&#38543;&#26426;&#26799;&#24230;&#30340;&#34987;&#24573;&#35270;&#30340;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
On the Overlooked Structure of Stochastic Gradients. (arXiv:2212.02083v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.02083
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#28145;&#24230;&#23398;&#20064;&#20013;&#38543;&#26426;&#26799;&#24230;&#30340;&#32467;&#26500;&#36827;&#34892;&#20102;&#27491;&#24335;&#30340;&#32479;&#35745;&#26816;&#39564;&#65292;&#21457;&#29616;&#36880;&#32500;&#26799;&#24230;&#36890;&#24120;&#21576;&#29616;&#24130;&#24459;&#37325;&#23614;&#65292;&#32780;&#36880;&#27425;&#36845;&#20195;&#30340;&#26799;&#24230;&#21644;&#38543;&#26426;&#26799;&#24230;&#22122;&#22768;&#36890;&#24120;&#19981;&#21576;&#29616;&#24130;&#24459;&#37325;&#23614;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#19982;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#30340;&#20248;&#21270;&#21644;&#27867;&#21270;&#23494;&#20999;&#30456;&#20851;&#12290;&#19968;&#20123;&#30740;&#31350;&#35797;&#22270;&#36890;&#36807;&#26799;&#24230;&#22122;&#22768;&#30340;&#37325;&#23614;&#24615;&#36136;&#26469;&#35299;&#37322;&#38543;&#26426;&#20248;&#21270;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#25104;&#21151;&#65292;&#32780;&#20854;&#20182;&#30740;&#31350;&#21017;&#25552;&#20986;&#20102;&#23545;&#26799;&#24230;&#22122;&#22768;&#30340;&#37325;&#23614;&#20551;&#35774;&#30340;&#29702;&#35770;&#21644;&#23454;&#35777;&#35777;&#25454;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#65292;&#29992;&#20110;&#20998;&#26512;&#38543;&#26426;&#26799;&#24230;&#32467;&#26500;&#21644;&#37325;&#23614;&#30340;&#27491;&#24335;&#32479;&#35745;&#26816;&#39564;&#36824;&#27809;&#26377;&#24471;&#21040;&#20805;&#20998;&#24320;&#21457;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20027;&#35201;&#20570;&#20986;&#20004;&#20010;&#36129;&#29486;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23545;&#38543;&#26426;&#26799;&#24230;&#21644;&#26799;&#24230;&#22122;&#22768;&#22312;&#21442;&#25968;&#21644;&#36845;&#20195;&#20013;&#30340;&#20998;&#24067;&#36827;&#34892;&#20102;&#27491;&#24335;&#30340;&#32479;&#35745;&#26816;&#39564;&#12290;&#25105;&#20204;&#30340;&#32479;&#35745;&#26816;&#39564;&#21457;&#29616;&#65292;&#36880;&#32500;&#26799;&#24230;&#36890;&#24120;&#34920;&#29616;&#20986;&#24130;&#24459;&#37325;&#23614;&#65292;&#32780;&#36880;&#27425;&#36845;&#20195;&#30340;&#26799;&#24230;&#21644;&#30001;&#23567;&#25209;&#37327;&#35757;&#32451;&#24341;&#36215;&#30340;&#38543;&#26426;&#26799;&#24230;&#22122;&#22768;&#36890;&#24120;&#19981;&#34920;&#29616;&#20986;&#24130;&#24459;&#37325;&#23614;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#21457;&#29616;&#21327;&#26041;&#24046;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic gradients closely relate to both optimization and generalization of deep neural networks (DNNs). Some works attempted to explain the success of stochastic optimization for deep learning by the arguably heavy-tail properties of gradient noise, while other works presented theoretical and empirical evidence against the heavy-tail hypothesis on gradient noise. Unfortunately, formal statistical tests for analyzing the structure and heavy tails of stochastic gradients in deep learning are still under-explored. In this paper, we mainly make two contributions. First, we conduct formal statistical tests on the distribution of stochastic gradients and gradient noise across both parameters and iterations. Our statistical tests reveal that dimension-wise gradients usually exhibit power-law heavy tails, while iteration-wise gradients and stochastic gradient noise caused by minibatch training usually do not exhibit power-law heavy tails. Second, we further discover that the covariance spe
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026;&#30495;&#23454;&#35299;&#37322;&#30340;&#26032;&#27010;&#24565;&#65292;&#36890;&#36807;&#20613;&#31435;&#21494;&#20998;&#26512;&#33719;&#24471;&#20005;&#26684;&#20445;&#35777;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#20854;&#22312;&#25903;&#25345;&#20551;&#35774;&#24773;&#26223;&#21644;&#38477;&#20302;&#35299;&#37322;&#35823;&#24046;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2210.17426</link><description>&lt;p&gt;
&#20613;&#31435;&#21494;&#20998;&#26512;&#23454;&#29616;&#19968;&#33268;&#19988;&#30495;&#23454;&#30340;&#27169;&#22411;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Consistent and Truthful Interpretation with Fourier Analysis. (arXiv:2210.17426v1 [cs.LG] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.17426
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026;&#30495;&#23454;&#35299;&#37322;&#30340;&#26032;&#27010;&#24565;&#65292;&#36890;&#36807;&#20613;&#31435;&#21494;&#20998;&#26512;&#33719;&#24471;&#20005;&#26684;&#20445;&#35777;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#20854;&#22312;&#25903;&#25345;&#20551;&#35774;&#24773;&#26223;&#21644;&#38477;&#20302;&#35299;&#37322;&#35823;&#24046;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#35768;&#22810;&#36328;&#23398;&#31185;&#39046;&#22495;&#65292;&#26426;&#22120;&#23398;&#20064;&#30340;&#35299;&#37322;&#38656;&#35201;&#19982;&#24403;&#21069;&#26696;&#20363;&#30456;&#20851;&#30340;&#20551;&#35774;&#24773;&#26223;&#19968;&#33268;&#65292;&#21363;&#22914;&#26524;&#19968;&#20010;&#22240;&#32032;&#25913;&#21464;&#65292;&#27169;&#22411;&#20250;&#22914;&#20309;&#21453;&#24212;&#65311;&#23613;&#31649;&#24402;&#22240;&#26041;&#27861;&#30001;&#20248;&#38597;&#30340;&#20844;&#29702;&#31995;&#32479;&#25903;&#25345;&#65292;&#20294;&#23427;&#20204;&#20027;&#35201;&#20851;&#27880;&#21333;&#20010;&#36755;&#20837;&#65292;&#24182;&#19988;&#36890;&#24120;&#19981;&#19968;&#33268;&#12290;&#20026;&#25903;&#25345;&#20551;&#35774;&#24773;&#26223;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#31216;&#20026;&#30495;&#23454;&#35299;&#37322;&#30340;&#26032;&#27010;&#24565;&#65292;&#24182;&#24212;&#29992;&#24067;&#23572;&#20989;&#25968;&#30340;&#20613;&#31435;&#21494;&#20998;&#26512;&#26469;&#33719;&#24471;&#20005;&#26684;&#30340;&#20445;&#35777;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#23545;&#20110;&#21508;&#31181;&#21322;&#24452;&#30340;&#37051;&#22495;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#27604;&#65292;&#21487;&#20197;&#23454;&#29616;2&#20493;&#33267;50&#20493;&#26356;&#20302;&#30340;&#35299;&#37322;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
For many interdisciplinary fields, ML interpretations need to be consistent with what-if scenarios related to the current case, i.e., if one factor changes, how does the model react? Although the attribution methods are supported by the elegant axiomatic systems, they mainly focus on individual inputs, and are generally inconsistent. To support what-if scenarios, we introduce a new notion called truthful interpretation, and apply Fourier analysis of Boolean functions to get rigorous guarantees. Experimental results show that for neighborhoods with various radii, our method achieves 2x - 50x lower interpretation error compared with the other methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20107;&#20214;&#35302;&#21457;&#31639;&#27861;ET-GP-UCB&#65292;&#29992;&#20110;&#35299;&#20915;&#26102;&#21464;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#25506;&#32034;&#21644;&#24320;&#21457;&#30340;&#26435;&#34913;&#38382;&#39064;&#12290;&#36890;&#36807;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#27010;&#29575;&#22343;&#21248;&#35823;&#24046;&#30028;&#65292;&#31639;&#27861;&#33021;&#22815;&#22312;&#26410;&#30693;&#21464;&#21270;&#36895;&#29575;&#30340;&#24773;&#20917;&#19979;&#33258;&#36866;&#24212;&#22320;&#36866;&#24212;&#23454;&#38469;&#30340;&#26102;&#38388;&#21464;&#21270;&#12290;&#25968;&#20540;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;ET-GP-UCB&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#19978;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2208.10790</link><description>&lt;p&gt;
&#20107;&#20214;&#35302;&#21457;&#30340;&#26102;&#21464;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Event-Triggered Time-Varying Bayesian Optimization. (arXiv:2208.10790v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.10790
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20107;&#20214;&#35302;&#21457;&#31639;&#27861;ET-GP-UCB&#65292;&#29992;&#20110;&#35299;&#20915;&#26102;&#21464;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#25506;&#32034;&#21644;&#24320;&#21457;&#30340;&#26435;&#34913;&#38382;&#39064;&#12290;&#36890;&#36807;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#27010;&#29575;&#22343;&#21248;&#35823;&#24046;&#30028;&#65292;&#31639;&#27861;&#33021;&#22815;&#22312;&#26410;&#30693;&#21464;&#21270;&#36895;&#29575;&#30340;&#24773;&#20917;&#19979;&#33258;&#36866;&#24212;&#22320;&#36866;&#24212;&#23454;&#38469;&#30340;&#26102;&#38388;&#21464;&#21270;&#12290;&#25968;&#20540;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;ET-GP-UCB&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#19978;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#26102;&#21464;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;TVBO&#65289;&#39034;&#24207;&#20248;&#21270;&#26102;&#21464;&#30446;&#26631;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#20854;&#20013;&#65292;&#20851;&#38190;&#25361;&#25112;&#26159;&#22312;&#26102;&#38388;&#21464;&#21270;&#19979;&#30340;&#21208;&#25506;&#19982;&#24320;&#21457;&#30340;&#26435;&#34913;&#12290;&#24403;&#21069;&#30340;TVBO&#26041;&#27861;&#38656;&#35201;&#23545;&#21464;&#21270;&#36895;&#29575;&#26377;&#20808;&#39564;&#30693;&#35782;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#21464;&#21270;&#36895;&#29575;&#36890;&#24120;&#26159;&#26410;&#30693;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20107;&#20214;&#35302;&#21457;&#31639;&#27861;ET-GP-UCB&#65292;&#23427;&#23558;&#20248;&#21270;&#38382;&#39064;&#35270;&#20026;&#38745;&#24577;&#38382;&#39064;&#65292;&#30452;&#21040;&#22312;&#32447;&#26816;&#27979;&#21040;&#30446;&#26631;&#20989;&#25968;&#30340;&#21464;&#21270;&#24182;&#37325;&#32622;&#25968;&#25454;&#38598;&#12290;&#36825;&#20351;&#24471;&#31639;&#27861;&#33021;&#22815;&#36866;&#24212;&#23454;&#38469;&#30340;&#26102;&#38388;&#21464;&#21270;&#65292;&#32780;&#19981;&#38656;&#35201;&#20808;&#39564;&#30693;&#35782;&#12290;&#20107;&#20214;&#35302;&#21457;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#20013;&#20351;&#29992;&#30340;&#27010;&#29575;&#22343;&#21248;&#35823;&#24046;&#30028;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;ET-GP-UCB&#30340;&#36951;&#25022;&#30028;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#23427;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#19978;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#32467;&#26524;&#34920;&#26126;ET-GP-UCB&#21487;&#24191;&#27867;&#24212;&#29992;&#20110;&#19981;&#21516;&#30340;&#35774;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of sequentially optimizing a time-varying objective function using time-varying Bayesian optimization (TVBO). Here, the key challenge is the exploration-exploitation trade-off under time variations. Current approaches to TVBO require prior knowledge of a constant rate of change. However, in practice, the rate of change is usually unknown. We propose an event-triggered algorithm, ET-GP-UCB, that treats the optimization problem as static until it detects changes in the objective function online and then resets the dataset. This allows the algorithm to adapt to realized temporal changes without the need for prior knowledge. The event-trigger is based on probabilistic uniform error bounds used in Gaussian process regression. We provide regret bounds for ET-GP-UCB and show in numerical experiments that it outperforms state-of-the-art algorithms on synthetic and real-world data. Furthermore, these results demonstrate that ET-GP-UCB is readily applicable to various set
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;&#22312;&#20165;&#26377;&#22122;&#22768;&#27979;&#37327;&#21487;&#29992;&#26102;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#31283;&#23450;&#22320;&#35299;&#20915;&#39640;&#32500;&#12289;&#22122;&#22768;&#12289;&#38750;&#32447;&#24615;&#30340;&#36870;&#38382;&#39064;&#65292;&#24182;&#19988;&#36825;&#20123;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#36890;&#36807;&#36866;&#24403;&#25200;&#21160;&#30340;&#35757;&#32451;&#25968;&#25454;&#36827;&#34892;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2206.00934</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#31283;&#23450;&#22320;&#35299;&#20915;&#39640;&#32500;&#12289;&#22122;&#22768;&#12289;&#38750;&#32447;&#24615;&#30340;&#36870;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks can stably solve high-dimensional, noisy, non-linear inverse problems. (arXiv:2206.00934v5 [math.NA] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.00934
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;&#22312;&#20165;&#26377;&#22122;&#22768;&#27979;&#37327;&#21487;&#29992;&#26102;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#31283;&#23450;&#22320;&#35299;&#20915;&#39640;&#32500;&#12289;&#22122;&#22768;&#12289;&#38750;&#32447;&#24615;&#30340;&#36870;&#38382;&#39064;&#65292;&#24182;&#19988;&#36825;&#20123;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#36890;&#36807;&#36866;&#24403;&#25200;&#21160;&#30340;&#35757;&#32451;&#25968;&#25454;&#36827;&#34892;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20165;&#26377;&#22122;&#22768;&#27979;&#37327;&#21487;&#29992;&#26102;&#37325;&#24314;&#36870;&#38382;&#39064;&#35299;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#20551;&#35774;&#35813;&#38382;&#39064;&#21487;&#20197;&#29992;&#19968;&#20010;&#26080;&#38480;&#32500;&#30340;&#38750;&#36830;&#32493;&#21487;&#36870;&#27491;&#21521;&#31639;&#23376;&#26469;&#24314;&#27169;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#27491;&#21521;&#31639;&#23376;&#38480;&#21046;&#22312;&#26377;&#38480;&#32500;&#31354;&#38388;&#20013;&#65292;&#20351;&#24471;&#36870;&#31639;&#23376;&#20855;&#26377;Lipschitz&#36830;&#32493;&#24615;&#12290;&#23545;&#20110;&#36870;&#31639;&#23376;&#65292;&#25105;&#20204;&#35777;&#26126;&#23384;&#22312;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#65292;&#23427;&#26159;&#35813;&#31639;&#23376;&#23545;&#22122;&#22768;&#31283;&#20581;&#30340;&#36817;&#20284;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#36825;&#20123;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#36890;&#36807;&#36866;&#24403;&#25200;&#21160;&#30340;&#35757;&#32451;&#25968;&#25454;&#26469;&#23398;&#20064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#22312;&#23454;&#38469;&#24863;&#20852;&#36259;&#30340;&#21508;&#31181;&#36870;&#38382;&#39064;&#20013;&#30340;&#21487;&#34892;&#24615;&#12290;&#32473;&#20986;&#20102;&#25903;&#25345;&#29702;&#35770;&#21457;&#29616;&#30340;&#25968;&#20540;&#20363;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of reconstructing solutions of inverse problems when only noisy measurements are available. We assume that the problem can be modeled with an infinite-dimensional forward operator that is not continuously invertible. Then, we restrict this forward operator to finite-dimensional spaces so that the inverse is Lipschitz continuous. For the inverse operator, we demonstrate that there exists a neural network which is a robust-to-noise approximation of the operator. In addition, we show that these neural networks can be learned from appropriately perturbed training data. We demonstrate the admissibility of this approach to a wide range of inverse problems of practical interest. Numerical examples are given that support the theoretical findings.
&lt;/p&gt;</description></item><item><title>ProtoryNet&#26159;&#19968;&#31181;&#22522;&#20110;&#21407;&#22411;&#36712;&#36857;&#30340;&#21487;&#35299;&#37322;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#23427;&#36890;&#36807;&#25429;&#25417;&#26102;&#38388;&#27169;&#24335;&#21644;&#21407;&#22411;&#30340;&#36817;&#20284;&#31243;&#24230;&#26469;&#36827;&#34892;&#25991;&#26412;&#20998;&#31867;&#65292;&#24182;&#23454;&#29616;&#20102;&#30452;&#35266;&#21644;&#32454;&#33268;&#30340;&#25512;&#29702;&#36807;&#31243;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2007.01777</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#24207;&#21015;&#20998;&#31867;&#36890;&#36807;&#21407;&#22411;&#36712;&#36857;
&lt;/p&gt;
&lt;p&gt;
Interpretable Sequence Classification Via Prototype Trajectory. (arXiv:2007.01777v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2007.01777
&lt;/p&gt;
&lt;p&gt;
ProtoryNet&#26159;&#19968;&#31181;&#22522;&#20110;&#21407;&#22411;&#36712;&#36857;&#30340;&#21487;&#35299;&#37322;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#23427;&#36890;&#36807;&#25429;&#25417;&#26102;&#38388;&#27169;&#24335;&#21644;&#21407;&#22411;&#30340;&#36817;&#20284;&#31243;&#24230;&#26469;&#36827;&#34892;&#25991;&#26412;&#20998;&#31867;&#65292;&#24182;&#23454;&#29616;&#20102;&#30452;&#35266;&#21644;&#32454;&#33268;&#30340;&#25512;&#29702;&#36807;&#31243;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29992;&#20110;&#25991;&#26412;&#20998;&#31867;&#30340;&#21487;&#35299;&#37322;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#31216;&#20026;ProtoryNet&#65292;&#23427;&#22522;&#20110;&#21407;&#22411;&#36712;&#36857;&#30340;&#26032;&#27010;&#24565;&#12290;&#21463;&#29616;&#20195;&#35821;&#35328;&#23398;&#20013;&#30340;&#21407;&#22411;&#29702;&#35770;&#30340;&#21551;&#21457;&#65292;ProtoryNet&#36890;&#36807;&#20026;&#25991;&#26412;&#24207;&#21015;&#20013;&#30340;&#27599;&#20010;&#21477;&#23376;&#25214;&#21040;&#26368;&#30456;&#20284;&#30340;&#21407;&#22411;&#65292;&#24182;&#23558;&#27599;&#20010;&#21477;&#23376;&#19982;&#30456;&#24212;&#30340;&#27963;&#21160;&#21407;&#22411;&#30340;&#25509;&#36817;&#31243;&#24230;&#36755;&#20837;&#21040;RNN&#20027;&#24178;&#20013;&#36827;&#34892;&#39044;&#27979;&#12290;&#28982;&#21518;&#65292;RNN&#20027;&#24178;&#25429;&#25417;&#21040;&#21407;&#22411;&#30340;&#26102;&#38388;&#27169;&#24335;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#21407;&#22411;&#36712;&#36857;&#12290;&#21407;&#22411;&#36712;&#36857;&#33021;&#22815;&#30452;&#35266;&#32780;&#32454;&#33268;&#22320;&#35299;&#37322;RNN&#27169;&#22411;&#30340;&#25512;&#29702;&#36807;&#31243;&#65292;&#31867;&#20284;&#20110;&#20154;&#31867;&#20998;&#26512;&#25991;&#26412;&#30340;&#26041;&#24335;&#12290;&#25105;&#20204;&#36824;&#35774;&#35745;&#20102;&#21407;&#22411;&#20462;&#21098;&#36807;&#31243;&#65292;&#20197;&#20943;&#23569;&#27169;&#22411;&#20351;&#29992;&#30340;&#21407;&#22411;&#24635;&#25968;&#65292;&#20197;&#25552;&#39640;&#35299;&#37322;&#24615;&#12290;&#22312;&#22810;&#20010;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;ProtoryNet&#27604;&#22522;&#32447;&#30340;&#22522;&#20110;&#21407;&#22411;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26356;&#20934;&#30830;&#65292;&#24182;&#20943;&#23569;&#20102;&#19982;&#29616;&#26377;&#27169;&#22411;&#30456;&#27604;&#30340;&#24615;&#33021;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel interpretable deep neural network for text classification, called ProtoryNet, based on a new concept of prototype trajectories. Motivated by the prototype theory in modern linguistics, ProtoryNet makes a prediction by finding the most similar prototype for each sentence in a text sequence and feeding an RNN backbone with the proximity of each sentence to the corresponding active prototype. The RNN backbone then captures the temporal pattern of the prototypes, which we refer to as prototype trajectories. Prototype trajectories enable intuitive and fine-grained interpretation of the reasoning process of the RNN model, in resemblance to how humans analyze texts. We also design a prototype pruning procedure to reduce the total number of prototypes used by the model for better interpretability. Experiments on multiple public data sets show that ProtoryNet is more accurate than the baseline prototype-based deep neural net and reduces the performance gap compared to state-o
&lt;/p&gt;</description></item></channel></rss>