<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#38543;&#26426;&#32447;&#24615;Bandit&#31639;&#27861;&#65292;&#21033;&#29992;&#38797;&#28857;&#36793;&#30028;&#30340;&#39532;&#19969;&#26684;&#23572;&#28151;&#21512;&#26500;&#24314;&#20102;&#36866;&#29992;&#20110;&#38543;&#26426;Bandit&#30340;&#32622;&#20449;&#24207;&#21015;&#65292;&#24182;&#35777;&#26126;&#35813;&#31639;&#27861;&#33021;&#22815;&#20197;&#31454;&#20105;&#24615;&#30340;&#26368;&#22351;&#24773;&#20917;&#19979;&#36951;&#25022;&#20445;&#35777;&#23454;&#29616;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.14298</link><description>&lt;p&gt;
&#20351;&#29992;&#38797;&#28857;&#36793;&#30028;&#30340;&#39532;&#19969;&#26684;&#23572;&#28151;&#21512;&#25913;&#36827;&#38543;&#26426;&#32447;&#24615;Bandit&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Improved Algorithms for Stochastic Linear Bandits Using Tail Bounds for Martingale Mixtures. (arXiv:2309.14298v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14298
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#38543;&#26426;&#32447;&#24615;Bandit&#31639;&#27861;&#65292;&#21033;&#29992;&#38797;&#28857;&#36793;&#30028;&#30340;&#39532;&#19969;&#26684;&#23572;&#28151;&#21512;&#26500;&#24314;&#20102;&#36866;&#29992;&#20110;&#38543;&#26426;Bandit&#30340;&#32622;&#20449;&#24207;&#21015;&#65292;&#24182;&#35777;&#26126;&#35813;&#31639;&#27861;&#33021;&#22815;&#20197;&#31454;&#20105;&#24615;&#30340;&#26368;&#22351;&#24773;&#20917;&#19979;&#36951;&#25022;&#20445;&#35777;&#23454;&#29616;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#38543;&#26426;&#32447;&#24615;Bandit&#38382;&#39064;&#20855;&#26377;&#26368;&#22351;&#24773;&#20917;&#19979;&#36951;&#25022;&#20445;&#35777;&#30340;&#25913;&#36827;&#31639;&#27861;&#12290;&#24191;&#27867;&#20351;&#29992;&#30340;"&#38754;&#23545;&#19981;&#30830;&#23450;&#24615;&#26102;&#30340;&#20048;&#35266;&#21407;&#21017;"&#21487;&#20197;&#23558;&#38543;&#26426;Bandit&#38382;&#39064;&#36716;&#21270;&#20026;&#23545;&#26410;&#30693;&#22870;&#21169;&#20989;&#25968;&#26500;&#24314;&#32622;&#20449;&#24207;&#21015;&#30340;&#38382;&#39064;&#12290;&#32467;&#26524;&#31639;&#27861;&#30340;&#24615;&#33021;&#21462;&#20915;&#20110;&#32622;&#20449;&#24207;&#21015;&#30340;&#22823;&#23567;&#65292;&#32622;&#20449;&#38598;&#36739;&#23567;&#21487;&#25552;&#20379;&#26356;&#22909;&#30340;&#32463;&#39564;&#24615;&#33021;&#21644;&#26356;&#24378;&#30340;&#36951;&#25022;&#20445;&#35777;&#12290;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#31181;&#23545;&#33258;&#36866;&#24212;&#39532;&#19969;&#26684;&#23572;&#28151;&#21512;&#30340;&#23614;&#37096;&#36793;&#30028;&#26469;&#26500;&#24314;&#36866;&#29992;&#20110;&#38543;&#26426;Bandit&#30340;&#32622;&#20449;&#24207;&#21015;&#12290;&#36825;&#20123;&#32622;&#20449;&#24207;&#21015;&#20801;&#35768;&#36890;&#36807;&#20984;&#35268;&#21010;&#36827;&#34892;&#39640;&#25928;&#30340;&#21160;&#20316;&#36873;&#25321;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22522;&#20110;&#25105;&#20204;&#30340;&#32622;&#20449;&#24207;&#21015;&#30340;&#32447;&#24615;Bandit&#31639;&#27861;&#33021;&#22815;&#20445;&#35777;&#36798;&#21040;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#26368;&#22351;&#24773;&#20917;&#19979;&#36951;&#25022;&#12290;&#25105;&#20204;&#23454;&#35777;&#21644;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#32622;&#20449;&#24207;&#21015;&#27604;&#31454;&#20105;&#23545;&#25163;&#26356;&#32039;&#33268;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#32039;&#33268;&#32622;&#20449;&#24207;&#21015;&#21487;&#20197;&#25552;&#20379;&#21644;&#32622;&#20449;&#38598;&#27604;&#36739;&#23481;&#26131;&#37197;&#32622;&#30340;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present improved algorithms with worst-case regret guarantees for the stochastic linear bandit problem. The widely used "optimism in the face of uncertainty" principle reduces a stochastic bandit problem to the construction of a confidence sequence for the unknown reward function. The performance of the resulting bandit algorithm depends on the size of the confidence sequence, with smaller confidence sets yielding better empirical performance and stronger regret guarantees. In this work, we use a novel tail bound for adaptive martingale mixtures to construct confidence sequences which are suitable for stochastic bandits. These confidence sequences allow for efficient action selection via convex programming. We prove that a linear bandit algorithm based on our confidence sequences is guaranteed to achieve competitive worst-case regret. We show that our confidence sequences are tighter than competitors, both empirically and theoretically. Finally, we demonstrate that our tighter confi
&lt;/p&gt;</description></item><item><title>&#19968;&#31181;&#26032;&#39062;&#32780;&#39640;&#25928;&#30340;&#26041;&#27861;&#65292;&#23558;&#29983;&#25104;&#30340;&#20154;&#24037;&#26234;&#33021;&#31639;&#27861;&#39044;&#27979;&#32435;&#20837;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#30340;&#21327;&#21464;&#37327;&#35843;&#25972;&#20013;&#65292;&#21487;&#20197;&#25552;&#39640;&#27835;&#30103;&#25928;&#26524;&#25512;&#26029;&#30340;&#36136;&#37327;&#21644;&#21487;&#20449;&#24230;&#12290;</title><link>http://arxiv.org/abs/2309.14256</link><description>&lt;p&gt;
&#19968;&#31181;&#22312;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#20013;&#23454;&#29616;&#39640;&#25928;&#21644;&#24378;&#22823;&#27835;&#30103;&#25928;&#26524;&#25512;&#26029;&#30340;&#21152;&#26435;&#39044;&#21518;&#21327;&#21464;&#37327;&#35843;&#25972;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Weighted Prognostic Covariate Adjustment Method for Efficient and Powerful Treatment Effect Inferences in Randomized Controlled Trials. (arXiv:2309.14256v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14256
&lt;/p&gt;
&lt;p&gt;
&#19968;&#31181;&#26032;&#39062;&#32780;&#39640;&#25928;&#30340;&#26041;&#27861;&#65292;&#23558;&#29983;&#25104;&#30340;&#20154;&#24037;&#26234;&#33021;&#31639;&#27861;&#39044;&#27979;&#32435;&#20837;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#30340;&#21327;&#21464;&#37327;&#35843;&#25972;&#20013;&#65292;&#21487;&#20197;&#25552;&#39640;&#27835;&#30103;&#25928;&#26524;&#25512;&#26029;&#30340;&#36136;&#37327;&#21644;&#21487;&#20449;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;(RCT)&#30340;&#19968;&#20010;&#37325;&#35201;&#20219;&#21153;&#26159;&#30830;&#23450;&#19968;&#31181;&#33021;&#22815;&#20135;&#29983;&#39640;&#25928;&#20272;&#35745;&#21644;&#26377;&#21147;&#27979;&#35797;&#27835;&#30103;&#25928;&#26524;&#30340;&#32479;&#35745;&#26041;&#27861;&#12290;&#19968;&#31181;&#26032;&#39062;&#32780;&#26377;&#25928;&#30340;&#31574;&#30053;&#65292;&#20197;&#33719;&#24471;&#39640;&#25928;&#21644;&#24378;&#22823;&#30340;&#27835;&#30103;&#25928;&#26524;&#25512;&#26029;&#65292;&#26159;&#23558;&#29983;&#25104;&#30340;&#20154;&#24037;&#26234;&#33021;(AI)&#31639;&#27861;&#30340;&#39044;&#27979;&#32435;&#20837;&#21040;RCT&#30340;&#21327;&#21464;&#37327;&#35843;&#25972;&#20013;&#65292;&#20197;&#36827;&#34892;&#22238;&#24402;&#20998;&#26512;&#12290;&#35757;&#32451;&#29983;&#25104;&#24335;AI&#31639;&#27861;&#20351;&#29992;&#21382;&#21490;&#23545;&#29031;&#25968;&#25454;&#21487;&#20197;&#26500;&#24314;RCT&#21442;&#19982;&#32773;&#30340;&#25968;&#23383;&#23402;&#29983;&#29983;&#25104;&#22120;(DTG)&#65292;&#23427;&#21033;&#29992;&#21442;&#19982;&#32773;&#30340;&#22522;&#32447;&#21327;&#21464;&#37327;&#29983;&#25104;&#28508;&#22312;&#23545;&#29031;&#32467;&#26524;&#30340;&#27010;&#29575;&#20998;&#24067;&#12290;DTG&#30340;&#27010;&#29575;&#20998;&#24067;&#25688;&#35201;&#23545;&#35797;&#39564;&#32467;&#26524;&#26377;&#24456;&#39640;&#30340;&#39044;&#27979;&#21147;&#65292;&#36890;&#36807;&#22238;&#24402;&#23545;&#36825;&#20123;&#29305;&#24449;&#36827;&#34892;&#35843;&#25972;&#21487;&#20197;&#25552;&#39640;&#27835;&#30103;&#25928;&#26524;&#25512;&#26029;&#30340;&#36136;&#37327;&#65292;&#24182;&#28385;&#36275;RCT&#30340;&#32479;&#35745;&#20998;&#26512;&#26041;&#38754;&#30340;&#30417;&#31649;&#25351;&#23548;&#26041;&#38024;&#12290;&#28982;&#32780;&#65292;&#35813;&#26041;&#27861;&#30340;&#20851;&#38190;&#20551;&#35774;&#26159;...
&lt;/p&gt;
&lt;p&gt;
A crucial task for a randomized controlled trial (RCT) is to specify a statistical method that can yield an efficient estimator and powerful test for the treatment effect. A novel and effective strategy to obtain efficient and powerful treatment effect inferences is to incorporate predictions from generative artificial intelligence (AI) algorithms into covariate adjustment for the regression analysis of a RCT. Training a generative AI algorithm on historical control data enables one to construct a digital twin generator (DTG) for RCT participants, which utilizes a participant's baseline covariates to generate a probability distribution for their potential control outcome. Summaries of the probability distribution from the DTG are highly predictive of the trial outcome, and adjusting for these features via regression can thus improve the quality of treatment effect inferences, while satisfying regulatory guidelines on statistical analyses, for a RCT. However, a critical assumption in th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21463;&#38480;&#29992;&#25143;&#21487;&#29992;&#24615;&#19979;&#30340;&#32852;&#37030;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;FL&#38382;&#39064;&#30340;&#20844;&#24335;&#21270;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#39118;&#38505;&#24863;&#30693;&#30446;&#26631;&#35774;&#35745;&#20102;&#19968;&#31181;&#39640;&#25928;&#35757;&#32451;&#31639;&#27861;&#65292;&#23436;&#20840;&#19981;&#21463;&#38543;&#26426;&#35775;&#38382;&#27169;&#22411;&#65288;RAM&#65289;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2309.14176</link><description>&lt;p&gt;
&#21463;&#38480;&#29992;&#25143;&#21487;&#29992;&#24615;&#19979;&#30340;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Federated Learning Under Restricted User Availability. (arXiv:2309.14176v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14176
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21463;&#38480;&#29992;&#25143;&#21487;&#29992;&#24615;&#19979;&#30340;&#32852;&#37030;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;FL&#38382;&#39064;&#30340;&#20844;&#24335;&#21270;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#39118;&#38505;&#24863;&#30693;&#30446;&#26631;&#35774;&#35745;&#20102;&#19968;&#31181;&#39640;&#25928;&#35757;&#32451;&#31639;&#27861;&#65292;&#23436;&#20840;&#19981;&#21463;&#38543;&#26426;&#35775;&#38382;&#27169;&#22411;&#65288;RAM&#65289;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#26159;&#19968;&#31181;&#20998;&#25955;&#30340;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#23562;&#37325;&#25968;&#25454;&#38544;&#31169;&#30340;&#21516;&#26102;&#36827;&#34892;&#21327;&#20316;&#27169;&#22411;&#35757;&#32451;&#12290;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#65292;&#30001;&#20110;&#19981;&#21033;&#25110;&#38543;&#26426;&#29615;&#22659;&#65292;&#29992;&#25143;&#30340;&#21487;&#29992;&#24615;&#25110;&#21442;&#19982;&#24230;&#19981;&#22343;&#21248;&#26159;&#19981;&#21487;&#36991;&#20813;&#30340;&#65292;&#21518;&#32773;&#22312;&#23398;&#20064;&#26399;&#38388;&#24448;&#24448;&#26159;&#19981;&#21487;&#25511;&#21046;&#30340;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#29992;&#25143;&#36873;&#25321;&#26426;&#21046;&#65292;&#23454;&#26045;&#21487;&#33021;&#26159;&#38543;&#26426;&#21270;&#30340;&#22266;&#23450;&#36873;&#25321;&#31574;&#30053;&#65292;&#26242;&#26102;&#31216;&#20026;&#38543;&#26426;&#35775;&#38382;&#27169;&#22411;&#65288;RAM&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;FL&#38382;&#39064;&#30340;&#26032;&#30340;&#20844;&#24335;&#21270;&#65292;&#26377;&#25928;&#22320;&#25429;&#25417;&#24182;&#20943;&#36731;&#28304;&#33258;&#19981;&#39057;&#32321;&#25110;&#21463;&#38480;&#29992;&#25143;&#30340;&#25968;&#25454;&#26377;&#38480;&#21442;&#19982;&#30340;&#24773;&#20917;&#19979;&#65292;&#23384;&#22312;RAM&#30340;&#24773;&#20917;&#19979;&#12290;&#36890;&#36807;&#22312;&#65288;&#26410;&#30693;&#30340;&#65289;RAM&#20998;&#24067;&#19978;&#20351;&#29992;&#26465;&#20214;&#39118;&#38505;&#20215;&#20540;&#65288;CVaR&#65289;&#65292;&#25105;&#20204;&#23558;&#26399;&#26395;&#25439;&#22833;FL&#30446;&#26631;&#25193;&#23637;&#21040;&#39118;&#38505;&#24863;&#30693;&#30446;&#26631;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#19968;&#31181;&#23436;&#20840;&#19981;&#21463;RAM&#24433;&#21709;&#30340;&#39640;&#25928;&#35757;&#32451;&#31639;&#27861;&#30340;&#35774;&#35745;&#65292;&#24182;&#19988;&#22797;&#26434;&#24615;&#19982;FedAvg&#22522;&#26412;&#30456;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated Learning (FL) is a decentralized machine learning framework that enables collaborative model training while respecting data privacy. In various applications, non-uniform availability or participation of users is unavoidable due to an adverse or stochastic environment, the latter often being uncontrollable during learning. Here, we posit a generic user selection mechanism implementing a possibly randomized, stationary selection policy, suggestively termed as a Random Access Model (RAM). We propose a new formulation of the FL problem which effectively captures and mitigates limited participation of data originating from infrequent, or restricted users, at the presence of a RAM. By employing the Conditional Value-at-Risk (CVaR) over the (unknown) RAM distribution, we extend the expected loss FL objective to a risk-aware objective, enabling the design of an efficient training algorithm that is completely oblivious to the RAM, and with essentially identical complexity as FedAvg. O
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#24418;&#32467;&#26500;&#65292;&#29992;&#20110;&#22312;&#32447;&#24615;&#21644;&#39640;&#26031;&#24615;&#20551;&#35774;&#19979;&#31283;&#23450;&#30340;&#28508;&#21464;&#37327;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35745;&#31639;&#35813;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#31561;&#20215;&#20110;&#35757;&#32451;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#23454;&#29616;&#20102;&#19968;&#20010;&#22522;&#20110;GPU&#30340;&#31639;&#27861;&#26469;&#36827;&#34892;&#35745;&#31639;&#12290;</title><link>http://arxiv.org/abs/2309.14073</link><description>&lt;p&gt;
&#28508;&#21464;&#37327;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65306;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Maximum Likelihood Estimation of Latent Variable Structural Equation Models: A Neural Network Approach. (arXiv:2309.14073v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14073
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#24418;&#32467;&#26500;&#65292;&#29992;&#20110;&#22312;&#32447;&#24615;&#21644;&#39640;&#26031;&#24615;&#20551;&#35774;&#19979;&#31283;&#23450;&#30340;&#28508;&#21464;&#37327;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35745;&#31639;&#35813;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#31561;&#20215;&#20110;&#35757;&#32451;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#23454;&#29616;&#20102;&#19968;&#20010;&#22522;&#20110;GPU&#30340;&#31639;&#27861;&#26469;&#36827;&#34892;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#24615;&#21644;&#39640;&#26031;&#24615;&#20551;&#35774;&#19979;&#31283;&#23450;&#30340;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#30340;&#22270;&#24418;&#32467;&#26500;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#35745;&#31639;&#36825;&#20010;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#31561;&#20215;&#20110;&#35757;&#32451;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#12290;&#25105;&#20204;&#23454;&#29616;&#20102;&#19968;&#20010;&#22522;&#20110;GPU&#30340;&#31639;&#27861;&#26469;&#35745;&#31639;&#36825;&#20123;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a graphical structure for structural equation models that is stable under marginalization under linearity and Gaussianity assumptions. We show that computing the maximum likelihood estimation of this model is equivalent to training a neural network. We implement a GPU-based algorithm that computes the maximum likelihood estimation of these models.
&lt;/p&gt;</description></item><item><title>TomOpt&#26159;&#19968;&#20010;&#36719;&#20214;&#21253;&#65292;&#29992;&#20110;&#20248;&#21270;&#23431;&#23449;&#23556;&#32447;&#956;&#23376;&#26029;&#23618;&#25195;&#25551;&#35774;&#35745;&#20013;&#30340;&#24494;&#31890;&#25506;&#27979;&#22120;&#30340;&#20960;&#20309;&#24067;&#23616;&#21644;&#35268;&#26684;&#12290;&#23427;&#21033;&#29992;&#21487;&#24494;&#20998;&#32534;&#31243;&#27169;&#25311;&#956;&#23376;&#19982;&#25506;&#27979;&#22120;&#21644;&#25195;&#25551;&#20307;&#31215;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#36890;&#36807;&#25439;&#22833;&#26368;&#23567;&#21270;&#30340;&#20248;&#21270;&#24490;&#29615;&#36827;&#34892;&#25512;&#26029;&#24863;&#30693;&#20248;&#21270;&#12290;</title><link>http://arxiv.org/abs/2309.14027</link><description>&lt;p&gt;
TomOpt&#65306;&#22312;&#23431;&#23449;&#23556;&#32447;&#956;&#23376;&#26029;&#23618;&#25195;&#25551;&#20013;&#38754;&#21521;&#20219;&#21153;&#21644;&#32422;&#26463;&#24863;&#30693;&#35774;&#35745;&#30340;&#24494;&#31890;&#25506;&#27979;&#22120;&#30340;&#24046;&#20998;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
TomOpt: Differential optimisation for task- and constraint-aware design of particle detectors in the context of muon tomography. (arXiv:2309.14027v1 [physics.ins-det])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14027
&lt;/p&gt;
&lt;p&gt;
TomOpt&#26159;&#19968;&#20010;&#36719;&#20214;&#21253;&#65292;&#29992;&#20110;&#20248;&#21270;&#23431;&#23449;&#23556;&#32447;&#956;&#23376;&#26029;&#23618;&#25195;&#25551;&#35774;&#35745;&#20013;&#30340;&#24494;&#31890;&#25506;&#27979;&#22120;&#30340;&#20960;&#20309;&#24067;&#23616;&#21644;&#35268;&#26684;&#12290;&#23427;&#21033;&#29992;&#21487;&#24494;&#20998;&#32534;&#31243;&#27169;&#25311;&#956;&#23376;&#19982;&#25506;&#27979;&#22120;&#21644;&#25195;&#25551;&#20307;&#31215;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#36890;&#36807;&#25439;&#22833;&#26368;&#23567;&#21270;&#30340;&#20248;&#21270;&#24490;&#29615;&#36827;&#34892;&#25512;&#26029;&#24863;&#30693;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#20010;&#21517;&#20026;TomOpt&#30340;&#36719;&#20214;&#21253;&#65292;&#29992;&#20110;&#20248;&#21270;&#20960;&#20309;&#24067;&#23616;&#21644;&#25506;&#27979;&#22120;&#35268;&#26684;&#65292;&#20197;&#36827;&#34892;&#23431;&#23449;&#23556;&#32447;&#956;&#23376;&#30340;&#25955;&#23556;&#26029;&#23618;&#25195;&#25551;&#35774;&#35745;&#12290;&#35813;&#36719;&#20214;&#21033;&#29992;&#21487;&#24494;&#20998;&#32534;&#31243;&#26469;&#27169;&#25311;&#956;&#23376;&#19982;&#25506;&#27979;&#22120;&#21644;&#25195;&#25551;&#20307;&#31215;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#25512;&#26029;&#20307;&#31215;&#23646;&#24615;&#65292;&#24182;&#36827;&#34892;&#25439;&#22833;&#26368;&#23567;&#21270;&#30340;&#20248;&#21270;&#24490;&#29615;&#12290;&#36890;&#36807;&#36825;&#26679;&#20570;&#65292;&#25105;&#20204;&#39318;&#27425;&#28436;&#31034;&#20102;&#31890;&#23376;&#29289;&#29702;&#20202;&#22120;&#30340;&#31471;&#21040;&#31471;&#21487;&#24494;&#20998;&#21644;&#25512;&#26029;&#24863;&#30693;&#20248;&#21270;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#35813;&#36719;&#20214;&#22312;&#30456;&#20851;&#22522;&#20934;&#22330;&#26223;&#19978;&#30340;&#24615;&#33021;&#65292;&#24182;&#35752;&#35770;&#20102;&#20854;&#28508;&#22312;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We describe a software package, TomOpt, developed to optimise the geometrical layout and specifications of detectors designed for tomography by scattering of cosmic-ray muons. The software exploits differentiable programming for the modeling of muon interactions with detectors and scanned volumes, the inference of volume properties, and the optimisation cycle performing the loss minimisation. In doing so, we provide the first demonstration of end-to-end-differentiable and inference-aware optimisation of particle physics instruments. We study the performance of the software on a relevant benchmark scenarios and discuss its potential applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22238;&#24402;&#27169;&#22411;&#20013;&#28155;&#21152;&#20132;&#20114;&#20316;&#29992;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#23616;&#37096;&#25910;&#32553;&#27169;&#22411;&#23454;&#29616;&#20102;&#23545;&#20027;&#25928;&#24212;&#21644;&#20132;&#20114;&#25928;&#24212;&#20043;&#38388;&#30340;&#36739;&#20026;&#28789;&#27963;&#30340;&#20851;&#32852;&#65292;&#22823;&#22823;&#25552;&#39640;&#20102;&#22238;&#24402;&#31995;&#25968;&#30340;&#20272;&#35745;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2309.13998</link><description>&lt;p&gt;
&#23545;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#20132;&#20114;&#20316;&#29992;&#30340;&#20272;&#35745;&#36827;&#34892;&#36830;&#32467;&#25910;&#32553;&#20197;&#25913;&#36827; (arXiv:2309.13998v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
Linked shrinkage to improve estimation of interaction effects in regression models. (arXiv:2309.13998v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13998
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22238;&#24402;&#27169;&#22411;&#20013;&#28155;&#21152;&#20132;&#20114;&#20316;&#29992;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#23616;&#37096;&#25910;&#32553;&#27169;&#22411;&#23454;&#29616;&#20102;&#23545;&#20027;&#25928;&#24212;&#21644;&#20132;&#20114;&#25928;&#24212;&#20043;&#38388;&#30340;&#36739;&#20026;&#28789;&#27963;&#30340;&#20851;&#32852;&#65292;&#22823;&#22823;&#25552;&#39640;&#20102;&#22238;&#24402;&#31995;&#25968;&#30340;&#20272;&#35745;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#32479;&#35745;&#23398;&#20013;&#19968;&#20010;&#32463;&#20856;&#38382;&#39064;&#65306;&#22914;&#20309;&#22312;&#22238;&#24402;&#27169;&#22411;&#20013;&#28155;&#21152;&#20108;&#38454;&#20132;&#20114;&#39033;&#12290;&#38543;&#30528;&#21327;&#21464;&#37327;&#32500;&#24230;&#30340;&#24179;&#26041;&#22686;&#38271;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#36866;&#24212;&#36825;&#31181;&#22686;&#38271;&#30340;&#20272;&#35745;&#22120;&#65292;&#21516;&#26102;&#25552;&#20379;&#20934;&#30830;&#30340;&#20272;&#35745;&#21644;&#36866;&#24403;&#30340;&#25512;&#29702;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#36890;&#36807;&#20165;&#20801;&#35768;&#30456;&#20851;&#20027;&#25928;&#24212;&#20043;&#38388;&#30340;&#20132;&#20114;&#26469;&#20811;&#26381;&#32500;&#24230;&#38382;&#39064;&#12290;&#22312;&#36825;&#19968;&#29702;&#24565;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#20351;&#29992;&#23616;&#37096;&#25910;&#32553;&#27169;&#22411;&#22312;&#20004;&#31181;&#25928;&#24212;&#20043;&#38388;&#23454;&#29616;&#20102;&#36739;&#20026;&#28789;&#27963;&#30340;&#20851;&#32852;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#20026;&#20027;&#25928;&#24212;&#21644;&#20132;&#20114;&#25928;&#24212;&#20511;&#29992;&#25910;&#32553;&#30340;&#24378;&#24230;&#21487;&#20197;&#22823;&#22823;&#25552;&#39640;&#22238;&#24402;&#31995;&#25968;&#30340;&#20272;&#35745;&#31934;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#35813;&#27169;&#22411;&#22312;&#25512;&#29702;&#26041;&#38754;&#30340;&#28508;&#21147;&#65292;&#23545;&#20110;&#36873;&#25321;&#31574;&#30053;&#26469;&#35828;&#36825;&#26159;&#19968;&#20010;&#26126;&#26174;&#22256;&#38590;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#22823;&#35268;&#27169;&#38431;&#21015;&#25968;&#25454;&#25552;&#20379;&#20102;&#30495;&#23454;&#30340;&#31034;&#20363;&#21644;&#35780;&#20272;&#65292;&#24182;&#19982;&#20854;&#20182;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#21464;&#37327;&#37325;&#35201;&#24615;&#30340;&#35780;&#20272;&#22312;&#22238;&#24402;&#26041;&#31243;&#20013;&#24182;&#19981;&#23481;&#26131;&#12290;
&lt;/p&gt;
&lt;p&gt;
We address a classical problem in statistics: adding two-way interaction terms to a regression model. As the covariate dimension increases quadratically, we develop an estimator that adapts well to this increase, while providing accurate estimates and appropriate inference. Existing strategies overcome the dimensionality problem by only allowing interactions between relevant main effects. Building on this philosophy, we implement a softer link between the two types of effects using a local shrinkage model. We empirically show that borrowing strength between the amount of shrinkage for main effects and their interactions can strongly improve estimation of the regression coefficients. Moreover, we evaluate the potential of the model for inference, which is notoriously hard for selection strategies. Large-scale cohort data are used to provide realistic illustrations and evaluations. Comparisons with other methods are provided. The evaluation of variable importance is not trivial in regres
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35299;&#20915;&#20102;&#35782;&#21035;&#31163;&#25955;&#38543;&#26426;&#21464;&#37327;&#28151;&#21512;&#20135;&#21697;&#20998;&#24067;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#32452;&#21512;&#32463;&#20856;&#30340;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;&#21644;&#19968;&#31181;&#26032;&#39062;&#30340;&#26465;&#20214;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#21644;&#36816;&#34892;&#26102;&#22797;&#26434;&#24230;&#19978;&#30340;&#25913;&#36827;&#65292;&#24182;&#25193;&#23637;&#20102;&#24050;&#30693;&#30340;&#19979;&#30028;&#26469;&#21305;&#37197;&#25105;&#20204;&#30340;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2309.13993</link><description>&lt;p&gt;
&#22312;&#36817;&#20284;&#26368;&#20248;&#30340;&#26679;&#26412;&#21644;&#26102;&#38388;&#22797;&#26434;&#24230;&#20013;&#35782;&#21035;&#31163;&#25955;&#20135;&#21697;&#20998;&#24067;&#30340;&#28151;&#21512;&#29289;
&lt;/p&gt;
&lt;p&gt;
Identification of Mixtures of Discrete Product Distributions in Near-Optimal Sample and Time Complexity. (arXiv:2309.13993v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13993
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35299;&#20915;&#20102;&#35782;&#21035;&#31163;&#25955;&#38543;&#26426;&#21464;&#37327;&#28151;&#21512;&#20135;&#21697;&#20998;&#24067;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#32452;&#21512;&#32463;&#20856;&#30340;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;&#21644;&#19968;&#31181;&#26032;&#39062;&#30340;&#26465;&#20214;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#21644;&#36816;&#34892;&#26102;&#22797;&#26434;&#24230;&#19978;&#30340;&#25913;&#36827;&#65292;&#24182;&#25193;&#23637;&#20102;&#24050;&#30693;&#30340;&#19979;&#30028;&#26469;&#21305;&#37197;&#25105;&#20204;&#30340;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#32479;&#35745;&#23398;&#20013;&#35782;&#21035;&#31163;&#25955;&#38543;&#26426;&#21464;&#37327;$X_1,\ldots,X_n$&#30340;&#20998;&#24067;&#65292;&#35813;&#20998;&#24067;&#26159;$k$&#20010;&#20056;&#31215;&#20998;&#24067;&#30340;&#28151;&#21512;&#29289;&#30340;&#38382;&#39064;&#12290;&#23545;&#20110;$n \in O(k)$&#65292;&#20197;&#21069;&#30340;&#26368;&#20339;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$(1/\zeta)^{O(k^2 \log k)}$&#65288;&#22312;&#30001;$\zeta$&#21442;&#25968;&#21270;&#30340;&#36731;&#24494;&#20998;&#31163;&#20551;&#35774;&#19979;&#65289;&#12290;&#24050;&#30693;&#26368;&#20339;&#19979;&#30028;&#20026;$\exp(\Omega(k))$&#12290;&#24050;&#30693;$n\geq 2k-1$&#23545;&#20110;&#35782;&#21035;&#26159;&#24517;&#35201;&#19988;&#20805;&#20998;&#30340;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#23545;&#20110;&#20219;&#24847;$n\geq 2k-1$&#65292;&#22914;&#20309;&#23454;&#29616;&#26679;&#26412;&#22797;&#26434;&#24230;&#21644;&#36816;&#34892;&#26102;&#22797;&#26434;&#24230;$(1/\zeta)^{O(k)}$&#12290;&#25105;&#20204;&#36824;&#23558;&#24050;&#30693;&#30340;&#19979;&#30028;$e^{\Omega(k)}$&#25193;&#23637;&#21040;&#20102;&#24191;&#27867;&#33539;&#22260;&#30340;$\zeta$&#21305;&#37197;&#25105;&#20204;&#30340;&#19978;&#30028;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36890;&#36807;&#32452;&#21512;&#65288;a&#65289;&#19968;&#31181;&#29992;&#20110;&#24378;&#22823;&#24352;&#37327;&#20998;&#35299;&#30340;&#32463;&#20856;&#26041;&#27861;&#21644;&#65288;b&#65289;&#36890;&#36807;&#20165;&#30740;&#31350;&#23427;&#20204;&#22312;&#25153;&#24179;&#21270;&#31209;&#20026;1&#30340;&#24352;&#37327;&#19978;&#30340;&#20316;&#29992;&#26469;&#20272;&#35745;&#34987;&#31216;&#20026;Hadamard&#25193;&#23637;&#30340;&#20851;&#38190;&#30697;&#38453;&#30340;&#26465;&#20214;&#25968;&#30340;&#19968;&#31181;&#26032;&#39062;&#26041;&#27861;&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of identifying, from statistics, a distribution of discrete random variables $X_1,\ldots,X_n$ that is a mixture of $k$ product distributions. The best previous sample complexity for $n \in O(k)$ was $(1/\zeta)^{O(k^2 \log k)}$ (under a mild separation assumption parameterized by $\zeta$). The best known lower bound was $\exp(\Omega(k))$. It is known that $n\geq 2k-1$ is necessary and sufficient for identification. We show, for any $n\geq 2k-1$, how to achieve sample complexity and run-time complexity $(1/\zeta)^{O(k)}$. We also extend the known lower bound of $e^{\Omega(k)}$ to match our upper bound across a broad range of $\zeta$. Our results are obtained by combining (a) a classic method for robust tensor decomposition, (b) a novel way of bounding the condition number of key matrices called Hadamard extensions, by studying their action only on flattened rank-1 tensors.
&lt;/p&gt;</description></item><item><title>&#20266;&#26631;&#31614;&#36873;&#25321;&#26159;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#23884;&#20837;&#20915;&#31574;&#29702;&#35770;&#65292;&#25552;&#20986;&#20102;BPLS&#26694;&#26550;&#26469;&#35299;&#20915;&#20266;&#26631;&#31614;&#36873;&#25321;&#20013;&#30340;&#30830;&#35748;&#20559;&#24046;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.13926</link><description>&lt;p&gt;
&#20266;&#26631;&#31614;&#36873;&#25321;&#26159;&#19968;&#20010;&#20915;&#31574;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Pseudo Label Selection is a Decision Problem. (arXiv:2309.13926v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13926
&lt;/p&gt;
&lt;p&gt;
&#20266;&#26631;&#31614;&#36873;&#25321;&#26159;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#23884;&#20837;&#20915;&#31574;&#29702;&#35770;&#65292;&#25552;&#20986;&#20102;BPLS&#26694;&#26550;&#26469;&#35299;&#20915;&#20266;&#26631;&#31614;&#36873;&#25321;&#20013;&#30340;&#30830;&#35748;&#20559;&#24046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20266;&#26631;&#31614;&#36873;&#25321;&#26159;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#23427;&#38656;&#35201;&#19968;&#20123;&#20934;&#21017;&#26469;&#25351;&#23548;&#20266;&#26631;&#31614;&#25968;&#25454;&#30340;&#36873;&#25321;&#12290;&#36825;&#20123;&#20934;&#21017;&#34987;&#35777;&#26126;&#21487;&#20197;&#22312;&#23454;&#36341;&#20013;&#24037;&#20316;&#24471;&#30456;&#24403;&#22909;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#24615;&#33021;&#24448;&#24448;&#21462;&#20915;&#20110;&#26631;&#35760;&#25968;&#25454;&#19978;&#21021;&#22987;&#27169;&#22411;&#30340;&#25311;&#21512;&#24773;&#20917;&#12290;&#26089;&#26399;&#36807;&#25311;&#21512;&#21487;&#33021;&#36890;&#36807;&#36873;&#25321;&#20855;&#26377;&#33258;&#20449;&#20294;&#38169;&#35823;&#39044;&#27979;&#30340;&#23454;&#20363;&#65288;&#36890;&#24120;&#34987;&#31216;&#20026;&#30830;&#35748;&#20559;&#24046;&#65289;&#32780;&#20256;&#25773;&#21040;&#26368;&#32456;&#27169;&#22411;&#12290;&#22312;&#20004;&#39033;&#26368;&#36817;&#30340;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20266;&#26631;&#31614;&#36873;&#25321;&#65288;PLS&#65289;&#21487;&#20197;&#33258;&#28982;&#22320;&#23884;&#20837;&#21040;&#20915;&#31574;&#29702;&#35770;&#20013;&#12290;&#36825;&#20026;BPLS&#38138;&#24179;&#20102;&#36947;&#36335;&#65292;&#23427;&#26159;&#19968;&#31181;&#29992;&#20110;PLS&#30340;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#21487;&#20197;&#32531;&#35299;&#30830;&#35748;&#20559;&#24046;&#30340;&#38382;&#39064;&#12290;&#20854;&#26680;&#24515;&#26159;&#19968;&#31181;&#26032;&#30340;&#36873;&#25321;&#20934;&#21017;&#65306;&#20266;&#26679;&#26412;&#21644;&#26631;&#35760;&#25968;&#25454;&#30340;&#21518;&#39564;&#39044;&#27979;&#30340;&#35299;&#26512;&#36817;&#20284;&#12290;&#25105;&#20204;&#36890;&#36807;&#35777;&#26126;&#36825;&#20010;&#8220;&#20266;POS&#8221;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#24615;&#26469;&#25512;&#23548;&#20986;&#36825;&#20010;&#36873;&#25321;&#20934;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pseudo-Labeling is a simple and effective approach to semi-supervised learning. It requires criteria that guide the selection of pseudo-labeled data. The latter have been shown to crucially affect pseudo-labeling's generalization performance. Several such criteria exist and were proven to work reasonably well in practice. However, their performance often depends on the initial model fit on labeled data. Early overfitting can be propagated to the final model by choosing instances with overconfident but wrong predictions, often called confirmation bias. In two recent works, we demonstrate that pseudo-label selection (PLS) can be naturally embedded into decision theory. This paves the way for BPLS, a Bayesian framework for PLS that mitigates the issue of confirmation bias. At its heart is a novel selection criterion: an analytical approximation of the posterior predictive of pseudo-samples and labeled data. We derive this selection criterion by proving Bayes-optimality of this "pseudo pos
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#31070;&#32463;&#31574;&#30053;&#38236;&#20687;&#26799;&#24230;&#31639;&#27861;&#22312;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#30740;&#31350;&#21457;&#29616;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#65292;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#24456;&#22909;&#22320;&#36924;&#36817;&#20215;&#20540;&#20989;&#25968;&#21644;&#31574;&#30053;&#65292;&#19988;&#36924;&#36817;&#35823;&#24046;&#21463;&#32593;&#32476;&#22823;&#23567;&#30340;&#24433;&#21709;&#65292;&#24182;&#19988;&#21487;&#20197;&#32487;&#25215;&#20043;&#21069;&#32593;&#32476;&#30340;&#24179;&#28369;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.13915</link><description>&lt;p&gt;
&#31070;&#32463;&#31574;&#30053;&#38236;&#20687;&#26799;&#24230;&#22312;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#31574;&#30053;&#20248;&#21270;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Sample Complexity of Neural Policy Mirror Descent for Policy Optimization on Low-Dimensional Manifolds. (arXiv:2309.13915v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13915
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#31070;&#32463;&#31574;&#30053;&#38236;&#20687;&#26799;&#24230;&#31639;&#27861;&#22312;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#30740;&#31350;&#21457;&#29616;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#65292;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#24456;&#22909;&#22320;&#36924;&#36817;&#20215;&#20540;&#20989;&#25968;&#21644;&#31574;&#30053;&#65292;&#19988;&#36924;&#36817;&#35823;&#24046;&#21463;&#32593;&#32476;&#22823;&#23567;&#30340;&#24433;&#21709;&#65292;&#24182;&#19988;&#21487;&#20197;&#32487;&#25215;&#20043;&#21069;&#32593;&#32476;&#30340;&#24179;&#28369;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#37197;&#22791;&#26377;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#22312;&#35299;&#20915;&#39640;&#32500;&#24230;&#30340;&#38382;&#39064;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#30340;&#20998;&#26512;&#26080;&#27861;&#35299;&#37322;&#23427;&#20204;&#20026;&#20309;&#33021;&#25269;&#25239;&#32500;&#24230;&#35781;&#21650;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#20989;&#25968;&#36924;&#36817;&#22120;&#30340;&#31070;&#32463;&#31574;&#30053;&#38236;&#20687;&#26799;&#24230;&#65288;NPMD&#65289;&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#21463;&#21040;&#35768;&#22810;&#39640;&#32500;&#29615;&#22659;&#20855;&#26377;&#20302;&#32500;&#32467;&#26500;&#30340;&#32463;&#39564;&#35266;&#23519;&#30340;&#21551;&#21457;&#65292;&#20363;&#22914;&#23558;&#22270;&#20687;&#20316;&#20026;&#29366;&#24577;&#65292;&#25105;&#20204;&#23558;&#29366;&#24577;&#31354;&#38388;&#35270;&#20026;&#23884;&#20837;&#22312;$D$&#32500;&#27431;&#27663;&#31354;&#38388;&#20013;&#30340;$d$&#32500;&#27969;&#24418;&#65292;&#20854;&#20013;$d\ll D$&#26159;&#20869;&#22312;&#32500;&#24230;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;NPMD&#30340;&#27599;&#27425;&#36845;&#20195;&#20013;&#65292;&#20215;&#20540;&#20989;&#25968;&#21644;&#31574;&#30053;&#37117;&#21487;&#20197;&#24456;&#22909;&#22320;&#30001;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#36924;&#36817;&#12290;&#36924;&#36817;&#35823;&#24046;&#30001;&#32593;&#32476;&#30340;&#22823;&#23567;&#25511;&#21046;&#65292;&#24182;&#19988;&#21069;&#19968;&#20010;&#32593;&#32476;&#30340;&#24179;&#28369;&#24615;&#21487;&#20197;&#20445;&#30041;&#12290;
&lt;/p&gt;
&lt;p&gt;
Policy-based algorithms equipped with deep neural networks have achieved great success in solving high-dimensional policy optimization problems in reinforcement learning. However, current analyses cannot explain why they are resistant to the curse of dimensionality. In this work, we study the sample complexity of the neural policy mirror descent (NPMD) algorithm with convolutional neural networks (CNN) as function approximators. Motivated by the empirical observation that many high-dimensional environments have state spaces possessing low-dimensional structures, such as those taking images as states, we consider the state space to be a $d$-dimensional manifold embedded in the $D$-dimensional Euclidean space with intrinsic dimension $d\ll D$. We show that in each iteration of NPMD, both the value function and the policy can be well approximated by CNNs. The approximation errors are controlled by the size of the networks, and the smoothness of the previous networks can be inherited. As a
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#21518;&#26399;&#26381;&#21153;&#19978;&#19979;&#25991;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;poLinUCB&#20197;&#25552;&#39640;&#19978;&#19979;&#25991;&#25512;&#33616;&#20013;&#30340;&#22312;&#32447;&#23398;&#20064;&#25928;&#29575;&#65292;&#24182;&#36890;&#36807;&#40065;&#26834;&#21270;&#30340;&#26925;&#22278;&#28508;&#21147;&#24341;&#29702;&#23454;&#29616;&#20102;&#20005;&#26684;&#30340;&#36951;&#25022;&#25511;&#21046;&#12290;</title><link>http://arxiv.org/abs/2309.13896</link><description>&lt;p&gt;
&#21518;&#32493;&#20063;&#24456;&#37325;&#35201;&#65306;&#36890;&#36807;&#21518;&#26399;&#26381;&#21153;&#19978;&#19979;&#25991;&#25913;&#36827;&#19978;&#19979;&#25991;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Follow-ups Also Matter: Improving Contextual Bandits via Post-serving Contexts. (arXiv:2309.13896v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13896
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#21518;&#26399;&#26381;&#21153;&#19978;&#19979;&#25991;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;poLinUCB&#20197;&#25552;&#39640;&#19978;&#19979;&#25991;&#25512;&#33616;&#20013;&#30340;&#22312;&#32447;&#23398;&#20064;&#25928;&#29575;&#65292;&#24182;&#36890;&#36807;&#40065;&#26834;&#21270;&#30340;&#26925;&#22278;&#28508;&#21147;&#24341;&#29702;&#23454;&#29616;&#20102;&#20005;&#26684;&#30340;&#36951;&#25022;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;&#30340;&#19978;&#19979;&#25991;&#25512;&#33616;&#38382;&#39064;&#20551;&#35774;&#31639;&#27861;&#22312;&#36873;&#25321;&#19968;&#20010;&#36873;&#39033;&#20043;&#21069;&#35266;&#23519;&#21040;&#25152;&#26377;&#30456;&#20851;&#30340;&#19978;&#19979;&#25991;&#12290;&#28982;&#32780;&#65292;&#22312;&#22788;&#29702;&#19968;&#20123;&#38382;&#39064;&#26102;&#65292;&#36825;&#31181;&#24314;&#27169;&#26041;&#24335;&#36890;&#24120;&#19981;&#22815;&#29992;&#65292;&#22240;&#20026;&#22312;&#36873;&#25321;&#36873;&#39033;&#21518;&#21487;&#20197;&#35266;&#23519;&#21040;&#26377;&#20215;&#20540;&#30340;&#38468;&#21152;&#19978;&#19979;&#25991;&#12290;&#20026;&#20102;&#25552;&#39640;&#36825;&#20123;&#24212;&#29992;&#20013;&#30340;&#22312;&#32447;&#23398;&#20064;&#25928;&#29575;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#20855;&#26377;&#21518;&#26399;&#26381;&#21153;&#19978;&#19979;&#25991;&#30340;&#26032;&#22411;&#19978;&#19979;&#25991;&#25512;&#33616;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;poLinUCB&#65292;&#35813;&#31639;&#27861;&#22312;&#26631;&#20934;&#20551;&#35774;&#19979;&#23454;&#29616;&#20102;&#20005;&#26684;&#30340;&#36951;&#25022;&#25511;&#21046;&#12290;&#25105;&#20204;&#30340;&#25216;&#26415;&#35777;&#26126;&#30340;&#26680;&#24515;&#26159;&#33879;&#21517;&#30340;&#26925;&#22278;&#28508;&#21147;&#24341;&#29702;&#65288;EPL&#65289;&#30340;&#19968;&#20010;&#40065;&#26834;&#21270;&#21644;&#24191;&#20041;&#21270;&#29256;&#26412;&#65292;&#23427;&#21487;&#20197;&#23481;&#32435;&#25968;&#25454;&#20013;&#30340;&#22122;&#22768;&#12290;&#36825;&#31181;&#40065;&#26834;&#21270;&#23545;&#20110;&#35299;&#20915;&#25105;&#20204;&#30340;&#38382;&#39064;&#26159;&#24517;&#35201;&#30340;&#65292;&#25105;&#20204;&#30456;&#20449;&#23427;&#20063;&#21487;&#20197;&#24212;&#29992;&#20110;&#20854;&#20182;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Standard contextual bandit problem assumes that all the relevant contexts are observed before the algorithm chooses an arm. This modeling paradigm, while useful, often falls short when dealing with problems in which valuable additional context can be observed after arm selection. For example, content recommendation platforms like Youtube, Instagram, Tiktok also observe valuable follow-up information pertinent to the user's reward after recommendation (e.g., how long the user stayed, what is the user's watch speed, etc.). To improve online learning efficiency in these applications, we study a novel contextual bandit problem with post-serving contexts and design a new algorithm, poLinUCB, that achieves tight regret under standard assumptions. Core to our technical proof is a robustified and generalized version of the well-known Elliptical Potential Lemma (EPL), which can accommodate noise in data. Such robustification is necessary for tackling our problem, and we believe it could also be
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#21069;K&#31232;&#30095;softmax&#38376;&#25511;&#28151;&#21512;&#19987;&#23478;&#22312;&#23494;&#24230;&#21644;&#21442;&#25968;&#20272;&#35745;&#26041;&#38754;&#30340;&#20316;&#29992;&#65292;&#36890;&#36807;&#23450;&#20041;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#25506;&#35752;&#20102;&#36755;&#20837;&#21306;&#22495;&#30340;&#19981;&#21516;&#34892;&#20026;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#30495;&#23454;&#19987;&#23478;&#25968;&#37327;&#24050;&#30693;&#30340;&#24773;&#20917;&#19979;&#65292;&#23494;&#24230;&#21644;&#21442;&#25968;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#24230;&#19982;&#26679;&#26412;&#37327;&#25104;&#27491;&#27604;&#65292;&#20294;&#24403;&#30495;&#23454;&#27169;&#24335;&#26410;&#30693;&#26102;</title><link>http://arxiv.org/abs/2309.13850</link><description>&lt;p&gt;
&#32479;&#35745;&#35282;&#24230;&#19979;&#30340;&#21069;K&#31232;&#30095;Softmax&#38376;&#25511;&#28151;&#21512;&#19987;&#23478;
&lt;/p&gt;
&lt;p&gt;
Statistical Perspective of Top-K Sparse Softmax Gating Mixture of Experts. (arXiv:2309.13850v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13850
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#21069;K&#31232;&#30095;softmax&#38376;&#25511;&#28151;&#21512;&#19987;&#23478;&#22312;&#23494;&#24230;&#21644;&#21442;&#25968;&#20272;&#35745;&#26041;&#38754;&#30340;&#20316;&#29992;&#65292;&#36890;&#36807;&#23450;&#20041;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#25506;&#35752;&#20102;&#36755;&#20837;&#21306;&#22495;&#30340;&#19981;&#21516;&#34892;&#20026;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#30495;&#23454;&#19987;&#23478;&#25968;&#37327;&#24050;&#30693;&#30340;&#24773;&#20917;&#19979;&#65292;&#23494;&#24230;&#21644;&#21442;&#25968;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#24230;&#19982;&#26679;&#26412;&#37327;&#25104;&#27491;&#27604;&#65292;&#20294;&#24403;&#30495;&#23454;&#27169;&#24335;&#26410;&#30693;&#26102;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21069;K&#31232;&#30095;softmax&#38376;&#25511;&#28151;&#21512;&#19987;&#23478;&#34987;&#24191;&#27867;&#29992;&#20110;&#22312;&#19981;&#22686;&#21152;&#35745;&#31639;&#25104;&#26412;&#30340;&#24773;&#20917;&#19979;&#25193;&#23637;&#22823;&#35268;&#27169;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#12290;&#23613;&#31649;&#22312;&#29616;&#23454;&#24212;&#29992;&#20013;&#38750;&#24120;&#21463;&#27426;&#36814;&#65292;&#20294;&#23545;&#35813;&#38376;&#25511;&#20989;&#25968;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#20027;&#35201;&#25361;&#25112;&#26469;&#33258;&#20110;&#21069;K&#31232;&#30095;softmax&#38376;&#25511;&#20989;&#25968;&#30340;&#32467;&#26500;&#65292;&#23427;&#23558;&#36755;&#20837;&#31354;&#38388;&#21010;&#20998;&#20026;&#20855;&#26377;&#19981;&#21516;&#34892;&#20026;&#30340;&#22810;&#20010;&#21306;&#22495;&#12290;&#36890;&#36807;&#19987;&#27880;&#20110;&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#65292;&#25105;&#20204;&#23545;&#21069;K&#31232;&#30095;softmax&#38376;&#25511;&#20989;&#25968;&#23545;&#23494;&#24230;&#21644;&#21442;&#25968;&#20272;&#35745;&#30340;&#24433;&#21709;&#24314;&#31435;&#20102;&#29702;&#35770;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20381;&#36182;&#20110;&#23450;&#20041;&#21442;&#25968;&#20043;&#38388;&#30340;&#26032;&#25439;&#22833;&#20989;&#25968;&#65292;&#20197;&#25429;&#25417;&#36755;&#20837;&#21306;&#22495;&#30340;&#19981;&#21516;&#34892;&#20026;&#12290;&#24403;&#30495;&#23454;&#19987;&#23478;&#25968;&#37327;$k_{\ast}$&#24050;&#30693;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23494;&#24230;&#21644;&#21442;&#25968;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#24230;&#37117;&#19982;&#26679;&#26412;&#37327;&#25104;&#27491;&#27604;&#12290;&#28982;&#32780;&#65292;&#24403;$k_{\ast}$&#21464;&#20026;&#26410;&#30693;&#19988;&#30495;&#23454;&#27169;&#24335;&#26102;
&lt;/p&gt;
&lt;p&gt;
Top-K sparse softmax gating mixture of experts has been widely used for scaling up massive deep-learning architectures without increasing the computational cost. Despite its popularity in real-world applications, the theoretical understanding of that gating function has remained an open problem. The main challenge comes from the structure of the top-K sparse softmax gating function, which partitions the input space into multiple regions with distinct behaviors. By focusing on a Gaussian mixture of experts, we establish theoretical results on the effects of the top-K sparse softmax gating function on both density and parameter estimations. Our results hinge upon defining novel loss functions among parameters to capture different behaviors of the input regions. When the true number of experts $k_{\ast}$ is known, we demonstrate that the convergence rates of density and parameter estimations are both parametric on the sample size. However, when $k_{\ast}$ becomes unknown and the true mode
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;NSOTree&#30340;&#31070;&#32463;&#23384;&#27963;&#26012;&#26641;&#65292;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#31070;&#32463;&#32593;&#32476;&#21644;&#22522;&#20110;&#26641;&#30340;&#26041;&#27861;&#30340;&#20248;&#21183;&#65292;&#23454;&#29616;&#20102;&#23545;&#22797;&#26434;&#20989;&#25968;&#30340;&#36924;&#36817;&#33021;&#21147;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#29992;&#20110;&#23384;&#27963;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2309.13825</link><description>&lt;p&gt;
NSOTree&#65306;&#31070;&#32463;&#23384;&#27963;&#26012;&#26641;
&lt;/p&gt;
&lt;p&gt;
NSOTree: Neural Survival Oblique Tree. (arXiv:2309.13825v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13825
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;NSOTree&#30340;&#31070;&#32463;&#23384;&#27963;&#26012;&#26641;&#65292;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#31070;&#32463;&#32593;&#32476;&#21644;&#22522;&#20110;&#26641;&#30340;&#26041;&#27861;&#30340;&#20248;&#21183;&#65292;&#23454;&#29616;&#20102;&#23545;&#22797;&#26434;&#20989;&#25968;&#30340;&#36924;&#36817;&#33021;&#21147;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#29992;&#20110;&#23384;&#27963;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23384;&#27963;&#20998;&#26512;&#26159;&#19968;&#31181;&#32479;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#30740;&#31350;&#29305;&#23450;&#20107;&#20214;&#21457;&#29983;&#20043;&#21069;&#30340;&#25345;&#32493;&#26102;&#38388;&#65292;&#31216;&#20026;&#20197;&#26102;&#38388;&#20026;&#20107;&#20214;&#20449;&#24687;&#20026;&#29305;&#24449;&#30340;&#26816;&#39564;&#29366;&#24577;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#30001;&#20110;&#20854;&#34920;&#24449;&#33021;&#21147;&#21644;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#32780;&#22312;&#35813;&#39046;&#22495;&#21344;&#20027;&#23548;&#22320;&#20301;&#12290;&#28982;&#32780;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#40657;&#30418;&#24615;&#36136;&#38459;&#30861;&#20102;&#20854;&#21487;&#35299;&#37322;&#24615;&#65292;&#32780;&#22312;&#23454;&#38469;&#30340;&#23384;&#27963;&#24212;&#29992;&#20013;&#65292;&#21487;&#35299;&#37322;&#24615;&#26159;&#34987;&#26399;&#26395;&#30340;&#20294;&#26159;&#36807;&#21435;&#30340;&#24037;&#20316;&#22522;&#26412;&#19978;&#24573;&#35270;&#20102;&#36825;&#19968;&#28857;&#12290;&#30456;&#21453;&#65292;&#20256;&#32479;&#30340;&#22522;&#20110;&#26641;&#30340;&#26041;&#27861;&#22312;&#21487;&#35299;&#37322;&#24615;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#65292;&#20294;&#30001;&#20110;&#36138;&#23146;&#25193;&#23637;&#23548;&#33268;&#38590;&#20197;&#36924;&#36817;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#21644;&#22522;&#20110;&#26641;&#30340;&#26041;&#27861;&#30340;&#20248;&#21183;&#65292;&#21033;&#29992;&#23427;&#20204;&#36924;&#36817;&#22797;&#26434;&#20989;&#25968;&#30340;&#33021;&#21147;&#21516;&#26102;&#20445;&#25345;&#21487;&#35299;&#37322;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#23384;&#27963;&#26012;&#26641;&#65288;NSOTree&#65289;&#29992;&#20110;&#23384;&#27963;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Survival analysis is a statistical method employed to scrutinize the duration until a specific event of interest transpires, known as time-to-event information characterized by censorship. Recently, deep learning-based methods have dominated this field due to their representational capacity and state-of-the-art performance. However, the black-box nature of the deep neural network hinders its interpretability, which is desired in real-world survival applications but has been largely neglected by previous works. In contrast, conventional tree-based methods are advantageous with respect to interpretability, while consistently grappling with an inability to approximate the global optima due to greedy expansion. In this paper, we leverage the strengths of both neural networks and tree-based methods, capitalizing on their ability to approximate intricate functions while maintaining interpretability. To this end, we propose a Neural Survival Oblique Tree (NSOTree) for survival analysis. Speci
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#20855;&#26377;&#31038;&#20250;&#24847;&#20041;&#30340;&#26080;&#20998;&#24067;&#32479;&#35745;&#31163;&#25955;&#24230;&#25511;&#21046;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#39640;&#39118;&#38505;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2309.13786</link><description>&lt;p&gt;
&#31038;&#20250;&#24212;&#29992;&#30340;&#26080;&#20998;&#24067;&#32479;&#35745;&#31163;&#25955;&#24230;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Distribution-Free Statistical Dispersion Control for Societal Applications. (arXiv:2309.13786v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13786
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#20855;&#26377;&#31038;&#20250;&#24847;&#20041;&#30340;&#26080;&#20998;&#24067;&#32479;&#35745;&#31163;&#25955;&#24230;&#25511;&#21046;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#39640;&#39118;&#38505;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36127;&#36131;&#20219;&#30340;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#23545;&#27169;&#22411;&#24615;&#33021;&#30340;&#26174;&#24335;&#26377;&#38480;&#26679;&#26412;&#32479;&#35745;&#20445;&#35777;&#26159;&#19968;&#20010;&#37325;&#35201;&#22240;&#32032;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#20110;&#30028;&#23450;&#39044;&#27979;&#22120;&#30340;&#26399;&#26395;&#25439;&#22833;&#25110;&#32773;&#20010;&#20307;&#39044;&#27979;&#23558;&#25215;&#21463;&#30340;&#25439;&#22833;&#20540;&#22312;&#19968;&#20010;&#25351;&#23450;&#33539;&#22260;&#20869;&#30340;&#27010;&#29575;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#35768;&#22810;&#39640;&#39118;&#38505;&#24212;&#29992;&#32780;&#35328;&#65292;&#29702;&#35299;&#21644;&#25511;&#21046;&#25439;&#22833;&#20998;&#24067;&#30340;&#31163;&#25955;&#24230;&#65292;&#25110;&#32773;&#35828;&#20154;&#32676;&#20013;&#19981;&#21516;&#20010;&#20307;&#23545;&#31639;&#27861;&#20915;&#31574;&#30340;&#24433;&#21709;&#31243;&#24230;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#25105;&#20204;&#24320;&#22987;&#30740;&#31350;&#20855;&#26377;&#31038;&#20250;&#24847;&#20041;&#30340;&#26080;&#20998;&#24067;&#32479;&#35745;&#31163;&#25955;&#24230;&#25511;&#21046;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#20294;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#22788;&#29702;&#27604;&#20197;&#21069;&#30340;&#24037;&#20316;&#26356;&#20016;&#23500;&#30340;&#32479;&#35745;&#21151;&#33021;&#31867;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#26377;&#27602;&#35780;&#35770;&#26816;&#27979;&#12289;&#21307;&#23398;&#24433;&#20687;&#21644;&#30005;&#24433;&#25512;&#33616;&#31561;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Explicit finite-sample statistical guarantees on model performance are an important ingredient in responsible machine learning. Previous work has focused mainly on bounding either the expected loss of a predictor or the probability that an individual prediction will incur a loss value in a specified range. However, for many high-stakes applications, it is crucial to understand and control the dispersion of a loss distribution, or the extent to which different members of a population experience unequal effects of algorithmic decisions. We initiate the study of distribution-free control of statistical dispersion measures with societal implications and propose a simple yet flexible framework that allows us to handle a much richer class of statistical functionals beyond previous work. Our methods are verified through experiments in toxic comment detection, medical imaging, and film recommendation.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#22312;&#25968;&#25454;&#20998;&#24067;&#19978;&#26159;&#31283;&#23450;&#30340;&#65292;&#24182;&#21487;&#20197;&#19982;&#29616;&#26377;&#30340;&#27169;&#22411;&#31867;&#21644;&#20840;&#23616;&#21464;&#37327;&#37325;&#35201;&#24615;&#25351;&#26631;&#32467;&#21512;&#20351;&#29992;&#12290;</title><link>http://arxiv.org/abs/2309.13775</link><description>&lt;p&gt;
&#35770;&#25991;&#26631;&#39064;&#65306;The Rashomon Importance Distribution: &#25670;&#33073;&#19981;&#31283;&#23450;&#30340;&#22522;&#20110;&#21333;&#19968;&#27169;&#22411;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;
&lt;/p&gt;
&lt;p&gt;
The Rashomon Importance Distribution: Getting RID of Unstable, Single Model-based Variable Importance. (arXiv:2309.13775v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13775
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#22312;&#25968;&#25454;&#20998;&#24067;&#19978;&#26159;&#31283;&#23450;&#30340;&#65292;&#24182;&#21487;&#20197;&#19982;&#29616;&#26377;&#30340;&#27169;&#22411;&#31867;&#21644;&#20840;&#23616;&#21464;&#37327;&#37325;&#35201;&#24615;&#25351;&#26631;&#32467;&#21512;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#21270;&#21464;&#37327;&#37325;&#35201;&#24615;&#23545;&#20110;&#22238;&#31572;&#36951;&#20256;&#23398;&#12289;&#20844;&#20849;&#25919;&#31574;&#21644;&#21307;&#23398;&#31561;&#39046;&#22495;&#30340;&#37325;&#22823;&#38382;&#39064;&#33267;&#20851;&#37325;&#35201;&#12290;&#24403;&#21069;&#30340;&#26041;&#27861;&#36890;&#24120;&#35745;&#31639;&#32473;&#23450;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#32473;&#23450;&#27169;&#22411;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#32473;&#23450;&#25968;&#25454;&#38598;&#65292;&#21487;&#33021;&#26377;&#35768;&#22810;&#27169;&#22411;&#21516;&#26679;&#33021;&#35299;&#37322;&#30446;&#26631;&#32467;&#26524;;&#22914;&#26524;&#19981;&#32771;&#34385;&#25152;&#26377;&#21487;&#33021;&#30340;&#35299;&#37322;&#65292;&#19981;&#21516;&#30340;&#30740;&#31350;&#32773;&#21487;&#33021;&#20250;&#24471;&#20986;&#35768;&#22810;&#20914;&#31361;&#20294;&#21516;&#26679;&#26377;&#25928;&#30340;&#32467;&#35770;&#12290;&#27492;&#22806;&#65292;&#21363;&#20351;&#32771;&#34385;&#20102;&#32473;&#23450;&#25968;&#25454;&#38598;&#30340;&#25152;&#26377;&#21487;&#33021;&#35299;&#37322;&#65292;&#36825;&#20123;&#27934;&#23519;&#21147;&#21487;&#33021;&#19981;&#20855;&#26377;&#26222;&#36866;&#24615;&#65292;&#22240;&#20026;&#24182;&#38750;&#25152;&#26377;&#22909;&#30340;&#35299;&#37322;&#22312;&#21512;&#29702;&#30340;&#25968;&#25454;&#25200;&#21160;&#19979;&#37117;&#26159;&#31283;&#23450;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#37327;&#21270;&#20102;&#22312;&#25152;&#26377;&#22909;&#30340;&#27169;&#22411;&#38598;&#21512;&#20013;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#65292;&#24182;&#19988;&#22312;&#25968;&#25454;&#20998;&#24067;&#19978;&#26159;&#31283;&#23450;&#30340;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#38750;&#24120;&#28789;&#27963;&#65292;&#21487;&#20197;&#19982;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#27169;&#22411;&#31867;&#21644;&#20840;&#23616;&#21464;&#37327;&#37325;&#35201;&#24615;&#25351;&#26631;&#32467;&#21512;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantifying variable importance is essential for answering high-stakes questions in fields like genetics, public policy, and medicine. Current methods generally calculate variable importance for a given model trained on a given dataset. However, for a given dataset, there may be many models that explain the target outcome equally well; without accounting for all possible explanations, different researchers may arrive at many conflicting yet equally valid conclusions given the same data. Additionally, even when accounting for all possible explanations for a given dataset, these insights may not generalize because not all good explanations are stable across reasonable data perturbations. We propose a new variable importance framework that quantifies the importance of a variable across the set of all good models and is stable across the data distribution. Our framework is extremely flexible and can be integrated with most existing model classes and global variable importance metrics. We d
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26080;&#38656;&#35843;&#21442;&#30340;&#26368;&#23567;&#20307;&#31215;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#24179;&#26041;&#26681;&#22871;&#32034;&#30340;&#21551;&#21457;&#21644;&#26080;&#38656;&#35843;&#21442;&#30340;&#29305;&#24615;&#65292;&#35299;&#20915;&#20102;&#26082;&#26377;&#26041;&#27861;&#22312;&#36873;&#25321;&#35843;&#33410;&#21442;&#25968;&#26041;&#38754;&#30340;&#20381;&#36182;&#24615;&#38382;&#39064;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#23545;&#25968;&#25454;&#20013;&#30340;&#22122;&#22768;&#27700;&#24179;&#19981;&#25935;&#24863;&#12290;</title><link>http://arxiv.org/abs/2309.13733</link><description>&lt;p&gt;
&#26080;&#38656;&#35843;&#21442;&#30340;&#26368;&#23567;&#20307;&#31215;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
Towards Tuning-Free Minimum-Volume Nonnegative Matrix Factorization. (arXiv:2309.13733v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13733
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26080;&#38656;&#35843;&#21442;&#30340;&#26368;&#23567;&#20307;&#31215;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#24179;&#26041;&#26681;&#22871;&#32034;&#30340;&#21551;&#21457;&#21644;&#26080;&#38656;&#35843;&#21442;&#30340;&#29305;&#24615;&#65292;&#35299;&#20915;&#20102;&#26082;&#26377;&#26041;&#27861;&#22312;&#36873;&#25321;&#35843;&#33410;&#21442;&#25968;&#26041;&#38754;&#30340;&#20381;&#36182;&#24615;&#38382;&#39064;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#23545;&#25968;&#25454;&#20013;&#30340;&#22122;&#22768;&#27700;&#24179;&#19981;&#25935;&#24863;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#65288;NMF&#65289;&#26159;&#19968;&#31181;&#22810;&#21151;&#33021;&#19988;&#24378;&#22823;&#30340;&#24037;&#20855;&#65292;&#29992;&#20110;&#21457;&#29616;&#25968;&#25454;&#30697;&#38453;&#20013;&#30340;&#28508;&#22312;&#32467;&#26500;&#65292;&#22312;&#25991;&#29486;&#20013;&#25552;&#20986;&#20102;&#35768;&#22810;&#21464;&#20307;&#12290;&#26368;&#36817;&#65292;Leplat&#31561;&#20154;&#65288;2019&#24180;&#65289;&#24341;&#20837;&#20102;&#26368;&#23567;&#20307;&#31215;NMF&#65292;&#29992;&#20110;&#22312;&#23384;&#22312;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#21487;&#35782;&#21035;&#22320;&#24674;&#22797;&#31209;&#32570;&#22833;&#30697;&#38453;&#12290;&#28982;&#32780;&#65292;&#20182;&#20204;&#30340;&#27169;&#22411;&#24615;&#33021;&#38656;&#35201;&#36873;&#25321;&#19968;&#20010;&#35843;&#33410;&#21442;&#25968;&#65292;&#20854;&#26368;&#20248;&#20540;&#20381;&#36182;&#20110;&#26410;&#30693;&#30340;&#22122;&#22768;&#27700;&#24179;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#24179;&#26041;&#26681;&#22871;&#32034;&#21551;&#21457;&#24182;&#20855;&#26377;&#26080;&#38656;&#35843;&#21442;&#29305;&#24615;&#30340;&#26368;&#23567;&#20307;&#31215;NMF&#26367;&#20195;&#24335;&#12290;&#25105;&#20204;&#30340;&#26367;&#20195;&#24335;&#20063;&#38656;&#35201;&#36873;&#25321;&#19968;&#20010;&#35843;&#33410;&#21442;&#25968;&#65292;&#20294;&#20854;&#26368;&#20248;&#20540;&#19981;&#21462;&#20915;&#20110;&#22122;&#22768;&#27700;&#24179;&#12290;&#20026;&#20102;&#25311;&#21512;&#25105;&#20204;&#30340;NMF&#27169;&#22411;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377;&#20840;&#23616;&#25910;&#25947;&#24615;&#20445;&#35777;&#30340;&#20027;&#23548;&#26368;&#23567;&#21270;&#65288;MM&#65289;&#31639;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#35843;&#33410;&#21442;&#25968;&#30340;&#26368;&#20248;&#36873;&#25321;&#23545;&#25968;&#25454;&#20013;&#30340;&#22122;&#22768;&#27700;&#24179;&#19981;&#25935;&#24863;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nonnegative Matrix Factorization (NMF) is a versatile and powerful tool for discovering latent structures in data matrices, with many variations proposed in the literature. Recently, Leplat et al.\@ (2019) introduced a minimum-volume NMF for the identifiable recovery of rank-deficient matrices in the presence of noise. The performance of their formulation, however, requires the selection of a tuning parameter whose optimal value depends on the unknown noise level. In this work, we propose an alternative formulation of minimum-volume NMF inspired by the square-root lasso and its tuning-free properties. Our formulation also requires the selection of a tuning parameter, but its optimal value does not depend on the noise level. To fit our NMF model, we propose a majorization-minimization (MM) algorithm that comes with global convergence guarantees. We show empirically that the optimal choice of our tuning parameter is insensitive to the noise level in the data.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#26088;&#22312;&#30740;&#31350;&#27491;&#21017;&#21270;&#22312;&#22810;&#31867;&#21035;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;&#65292;&#20197;&#21450;&#20854;&#22312;&#19968;&#20123;&#29305;&#23450;&#24773;&#26223;&#19979;&#30340;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#23545;&#19968;&#21253;&#21547;&#22270;(OIGs)&#23637;&#31034;&#20102;&#32467;&#26500;&#39118;&#38505;&#26368;&#23567;&#21270;&#12289;&#26368;&#22823;&#29109;&#21407;&#21017;&#21644;&#36125;&#21494;&#26031;&#25512;&#29702;&#31561;&#31639;&#27861;&#21407;&#21017;&#30340;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.13692</link><description>&lt;p&gt;
&#27491;&#21017;&#21270;&#19982;&#26368;&#20248;&#22810;&#31867;&#21035;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Regularization and Optimal Multiclass Learning. (arXiv:2309.13692v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13692
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#30740;&#31350;&#27491;&#21017;&#21270;&#22312;&#22810;&#31867;&#21035;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;&#65292;&#20197;&#21450;&#20854;&#22312;&#19968;&#20123;&#29305;&#23450;&#24773;&#26223;&#19979;&#30340;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#23545;&#19968;&#21253;&#21547;&#22270;(OIGs)&#23637;&#31034;&#20102;&#32467;&#26500;&#39118;&#38505;&#26368;&#23567;&#21270;&#12289;&#26368;&#22823;&#29109;&#21407;&#21017;&#21644;&#36125;&#21494;&#26031;&#25512;&#29702;&#31561;&#31639;&#27861;&#21407;&#21017;&#30340;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20197;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;ERM&#65289;&#20026;&#20195;&#34920;&#30340;&#20856;&#22411;&#23398;&#20064;&#31639;&#27861;&#24050;&#34987;&#21457;&#29616;&#22312;&#19968;&#20123;&#23398;&#20064;&#38750;&#22343;&#21248;&#25910;&#25947;&#30340;&#24773;&#26223;&#20013;&#26080;&#27861;&#25104;&#21151;&#24212;&#29992;&#12290;&#22240;&#27492;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#23454;&#36341;&#20013;&#23384;&#22312;&#35768;&#22810;&#26356;&#20016;&#23500;&#30340;&#31639;&#27861;&#25216;&#26415;&#26469;&#25511;&#21046;&#27169;&#22411;&#23481;&#37327;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#20123;&#26356;&#19968;&#33324;&#30340;&#24773;&#22659;&#20013;&#65292;&#27809;&#26377;&#19968;&#31181;&#25216;&#26415;&#25110;&#21407;&#21017;&#33021;&#22815;&#33073;&#39062;&#32780;&#20986;&#26469;&#25551;&#36848;&#26368;&#20248;&#23398;&#20064;&#30340;&#29305;&#24449;&#12290;&#26412;&#25991;&#26088;&#22312;&#34920;&#24449;&#27491;&#21017;&#21270;&#22312;&#22810;&#31867;&#21035;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;&#65292;&#36825;&#21487;&#33021;&#26159;ERM&#22833;&#36133;&#30340;&#26368;&#31616;&#21333;&#24773;&#26223;&#65292;&#32780;&#26631;&#31614;&#38598;&#26159;&#20219;&#24847;&#30340;&#12290;&#25105;&#20204;&#21033;&#29992;&#19968;&#23545;&#19968;&#21253;&#21547;&#22270;&#65288;OIGs&#65289;&#23637;&#31034;&#20102;&#19982;&#20256;&#32479;&#31639;&#27861;&#21407;&#21017;&#30456;&#32467;&#21512;&#30340;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#65306;&#22885;&#21345;&#22982;&#21059;&#20992;&#21407;&#21017;&#25152;&#20307;&#29616;&#30340;&#32467;&#26500;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;SRM&#65289;&#65292;&#26368;&#22823;&#29109;&#21407;&#21017;&#21644;&#36125;&#21494;&#26031;&#25512;&#29702;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22312;&#32467;&#26500;&#39118;&#38505;&#26368;&#23567;&#21270;&#19978;&#36827;&#34892;&#25918;&#26494;&#30340;&#26368;&#20248;&#23398;&#20064;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
The quintessential learning algorithm of empirical risk minimization (ERM) is known to fail in various settings for which uniform convergence does not characterize learning. It is therefore unsurprising that the practice of machine learning is rife with considerably richer algorithmic techniques for successfully controlling model capacity. Nevertheless, no such technique or principle has broken away from the pack to characterize optimal learning in these more general settings.  The purpose of this work is to characterize the role of regularization in perhaps the simplest setting for which ERM fails: multiclass learning with arbitrary label sets. Using one-inclusion graphs (OIGs), we exhibit optimal learning algorithms that dovetail with tried-and-true algorithmic principles: Occam's Razor as embodied by structural risk minimization (SRM), the principle of maximum entropy, and Bayesian reasoning. Most notably, we introduce an optimal learner which relaxes structural risk minimization on
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;&#27867;&#21270;&#30028;&#38480;&#38382;&#39064;&#65292;&#36890;&#36807;&#20998;&#26512;&#22810;&#20010;&#30028;&#38480;&#21457;&#29616;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#26080;&#27861;&#25214;&#21040;&#32039;&#33268;&#30340;&#30028;&#38480;&#26469;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#30340;&#20986;&#33394;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.13658</link><description>&lt;p&gt;
&#26080;&#27861;&#25214;&#21040;&#20986;&#33394;&#30340;&#27867;&#21270;&#24230;&#37327;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Fantastic Generalization Measures are Nowhere to be Found. (arXiv:2309.13658v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13658
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;&#27867;&#21270;&#30028;&#38480;&#38382;&#39064;&#65292;&#36890;&#36807;&#20998;&#26512;&#22810;&#20010;&#30028;&#38480;&#21457;&#29616;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#26080;&#27861;&#25214;&#21040;&#32039;&#33268;&#30340;&#30028;&#38480;&#26469;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#30340;&#20986;&#33394;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21435;&#30340;&#25991;&#29486;&#20013;&#25552;&#20986;&#20102;&#35768;&#22810;&#27867;&#21270;&#30028;&#38480;&#20316;&#20026;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#22312;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#27867;&#21270;&#33021;&#21147;&#30340;&#28508;&#22312;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30028;&#38480;&#37117;&#19981;&#26159;&#32039;&#33268;&#30340;&#12290;&#20363;&#22914;&#65292;&#22312;&#20182;&#20204;&#30340;&#35770;&#25991;&#8220;Fantastic Generalization Measures and Where to Find Them&#8221;&#20013;&#65292;Jiang&#31561;&#20154;&#65288;2020&#65289;&#26816;&#26597;&#20102;&#21313;&#20960;&#20010;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#27809;&#26377;&#19968;&#20010;&#33021;&#22815;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;&#36825;&#24341;&#20986;&#20102;&#19968;&#20010;&#38382;&#39064;&#65292;&#21363;&#26159;&#21542;&#26377;&#21487;&#33021;&#25214;&#21040;&#32039;&#33268;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#25991;&#29486;&#20013;&#24120;&#35265;&#30340;&#20004;&#31181;&#27867;&#21270;&#30028;&#38480;&#65306;&#65288;1&#65289;&#20381;&#36182;&#20110;&#35757;&#32451;&#38598;&#21644;&#23398;&#20064;&#31639;&#27861;&#36755;&#20986;&#30340;&#30028;&#38480;&#12290;&#25991;&#29486;&#20013;&#26377;&#22810;&#20010;&#36825;&#31181;&#31867;&#22411;&#30340;&#30028;&#38480;&#65288;&#20363;&#22914;&#22522;&#20110;&#33539;&#25968;&#21644;&#22522;&#20110;&#38388;&#38548;&#30340;&#30028;&#38480;&#65289;&#65292;&#20294;&#25105;&#20204;&#35777;&#26126;&#22312;&#36807;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#27809;&#26377;&#36825;&#26679;&#30340;&#30028;&#38480;&#33021;&#22815;&#19968;&#33268;&#22320;&#32039;&#33268;&#65307;&#65288;2&#65289;&#20381;&#36182;&#20110;&#35757;&#32451;&#38598;&#21644;&#27979;&#35797;&#38598;&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Numerous generalization bounds have been proposed in the literature as potential explanations for the ability of neural networks to generalize in the overparameterized setting. However, none of these bounds are tight. For instance, in their paper ``Fantastic Generalization Measures and Where to Find Them'', Jiang et al. (2020) examine more than a dozen generalization bounds, and show empirically that none of them imply guarantees that can explain the remarkable performance of neural networks. This raises the question of whether tight generalization bounds are at all possible. We consider two types of generalization bounds common in the literature: (1) bounds that depend on the training set and the output of the learning algorithm. There are multiple bounds of this type in the literature (e.g., norm-based and margin-based bounds), but we prove mathematically that no such bound can be uniformly tight in the overparameterized setting; (2) bounds that depend on the training set and on the 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#21435;&#22122;&#20013;&#30340;&#21518;&#39564;&#20998;&#24067;&#21450;&#20854;&#19982;&#21518;&#39564;&#22343;&#20540;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#24212;&#29992;&#20110;&#39044;&#35757;&#32451;&#21435;&#22122;&#22120;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#35745;&#31639;&#21518;&#39564;&#20998;&#24067;&#20027;&#25104;&#20998;&#21644;&#36817;&#20284;&#36793;&#38469;&#20998;&#24067;&#30340;&#26041;&#27861;&#12290;&#19981;&#38656;&#35201;&#26174;&#24335;&#35745;&#31639;&#39640;&#38454;&#30697;&#24352;&#37327;&#25110;&#36827;&#34892;&#35757;&#32451;&#25110;&#24494;&#35843;&#12290;</title><link>http://arxiv.org/abs/2309.13598</link><description>&lt;p&gt;
&#20851;&#20110;&#21435;&#22122;&#20013;&#30340;&#21518;&#39564;&#20998;&#24067;&#65306;&#22312;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
On the Posterior Distribution in Denoising: Application to Uncertainty Quantification. (arXiv:2309.13598v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13598
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#21435;&#22122;&#20013;&#30340;&#21518;&#39564;&#20998;&#24067;&#21450;&#20854;&#19982;&#21518;&#39564;&#22343;&#20540;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#24212;&#29992;&#20110;&#39044;&#35757;&#32451;&#21435;&#22122;&#22120;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#35745;&#31639;&#21518;&#39564;&#20998;&#24067;&#20027;&#25104;&#20998;&#21644;&#36817;&#20284;&#36793;&#38469;&#20998;&#24067;&#30340;&#26041;&#27861;&#12290;&#19981;&#38656;&#35201;&#26174;&#24335;&#35745;&#31639;&#39640;&#38454;&#30697;&#24352;&#37327;&#25110;&#36827;&#34892;&#35757;&#32451;&#25110;&#24494;&#35843;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21435;&#22122;&#31639;&#27861;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#36215;&#30528;&#26680;&#24515;&#20316;&#29992;&#65292;&#20174;&#38477;&#22122;&#20302;&#32423;&#21035;&#25104;&#20687;&#20256;&#24863;&#22120;&#21040;&#25552;&#21319;&#22522;&#20110;&#35780;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#21518;&#19968;&#31867;&#26041;&#27861;&#20351;&#29992;Tweedie&#20844;&#24335;&#65292;&#23558;&#39640;&#26031;&#21435;&#22122;&#30340;&#21518;&#39564;&#22343;&#20540;&#65288;&#21363;&#26368;&#23567;&#22343;&#26041;&#35823;&#24046;&#21435;&#22122;&#22120;&#65289;&#19982;&#25968;&#25454;&#20998;&#24067;&#30340;&#35780;&#20998;&#38142;&#25509;&#36215;&#26469;&#12290;&#25105;&#20204;&#22312;&#36825;&#37324;&#25512;&#23548;&#20102;&#21518;&#39564;&#20998;&#24067;&#30340;&#39640;&#38454;&#20013;&#24515;&#30697;&#19982;&#21518;&#39564;&#22343;&#20540;&#30340;&#39640;&#38454;&#23548;&#25968;&#20043;&#38388;&#30340;&#22522;&#26412;&#20851;&#31995;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20010;&#32467;&#26524;&#36827;&#34892;&#39044;&#35757;&#32451;&#21435;&#22122;&#22120;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#39640;&#25928;&#35745;&#31639;&#22270;&#20687;&#20219;&#20309;&#25152;&#38656;&#21306;&#22495;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;&#20027;&#25104;&#20998;&#65292;&#20197;&#21450;&#22914;&#20309;&#36817;&#20284;&#27839;&#36825;&#20123;&#65288;&#25110;&#20219;&#20309;&#20854;&#20182;&#65289;&#19968;&#32500;&#26041;&#21521;&#30340;&#23436;&#25972;&#36793;&#38469;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#24555;&#36895;&#19988;&#20869;&#23384;&#39640;&#25928;&#65292;&#22240;&#20026;&#23427;&#19981;&#38656;&#35201;&#26174;&#24335;&#35745;&#31639;&#25110;&#23384;&#20648;&#39640;&#38454;&#30697;&#24352;&#37327;&#65292;&#24182;&#19988;&#26080;&#38656;&#35757;&#32451;&#25110;&#24494;&#35843;&#12290;
&lt;/p&gt;
&lt;p&gt;
Denoisers play a central role in many applications, from noise suppression in low-grade imaging sensors, to empowering score-based generative models. The latter category of methods makes use of Tweedie's formula, which links the posterior mean in Gaussian denoising (i.e., the minimum MSE denoiser) with the score of the data distribution. Here, we derive a fundamental relation between the higher-order central moments of the posterior distribution, and the higher-order derivatives of the posterior mean. We harness this result for uncertainty quantification of pre-trained denoisers. Particularly, we show how to efficiently compute the principal components of the posterior distribution for any desired region of an image, as well as to approximate the full marginal distribution along those (or any other) one-dimensional directions. Our method is fast and memory efficient, as it does not explicitly compute or store the high-order moment tensors and it requires no training or fine tuning of t
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#26368;&#23567;&#23494;&#24230;&#21151;&#29575;&#24046;&#24322;&#20272;&#35745;&#30340;&#40065;&#26834;&#20027;&#25104;&#20998;&#20998;&#26512;&#26041;&#27861;&#22312;&#39640;&#32500;&#25968;&#25454;&#20013;&#20855;&#26377;&#29702;&#35770;&#20248;&#21183;&#19988;&#20855;&#22791;&#39640;&#40065;&#26834;&#24615;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2309.13531</link><description>&lt;p&gt;
&#20351;&#29992;&#23494;&#24230;&#21151;&#29575;&#24046;&#24322;&#30340;&#40065;&#26834;&#20027;&#25104;&#20998;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Robust Principal Component Analysis using Density Power Divergence. (arXiv:2309.13531v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13531
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#26368;&#23567;&#23494;&#24230;&#21151;&#29575;&#24046;&#24322;&#20272;&#35745;&#30340;&#40065;&#26834;&#20027;&#25104;&#20998;&#20998;&#26512;&#26041;&#27861;&#22312;&#39640;&#32500;&#25968;&#25454;&#20013;&#20855;&#26377;&#29702;&#35770;&#20248;&#21183;&#19988;&#20855;&#22791;&#39640;&#40065;&#26834;&#24615;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#25104;&#20998;&#20998;&#26512;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#32479;&#35745;&#24037;&#20855;&#65292;&#20027;&#35201;&#29992;&#20110;&#38477;&#32500;&#12290;&#28982;&#32780;&#65292;&#24050;&#30693;&#26679;&#26412;&#20013;&#23384;&#22312;&#24322;&#24120;&#35266;&#27979;&#20250;&#23545;&#20027;&#25104;&#20998;&#20998;&#26512;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#65292;&#32780;&#36825;&#31181;&#24773;&#20917;&#30456;&#24403;&#26222;&#36941;&#12290;&#20351;&#29992;M&#20272;&#35745;&#30340;&#40065;&#26834;&#20027;&#25104;&#20998;&#20998;&#26512;&#26041;&#27861;&#20855;&#26377;&#29702;&#35770;&#19978;&#30340;&#20248;&#28857;&#65292;&#20294;&#22312;&#39640;&#32500;&#25968;&#25454;&#26102;&#20854;&#40065;&#26834;&#24615;&#26174;&#33879;&#19979;&#38477;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#35299;&#20915;&#20027;&#25104;&#20998;&#36861;&#36394;&#25110;&#31867;&#20284;&#20248;&#21270;&#38382;&#39064;&#30340;&#40065;&#26834;&#20027;&#25104;&#20998;&#20998;&#26512;&#31639;&#27861;&#20855;&#26377;&#36739;&#39640;&#30340;&#40065;&#26834;&#24615;&#65292;&#20294;&#32570;&#20047;&#29702;&#35770;&#20016;&#23500;&#24615;&#65292;&#24182;&#19988;&#19982;M&#20272;&#35745;&#30456;&#27604;&#35201;&#27714;&#26356;&#39640;&#30340;&#35745;&#31639;&#33021;&#21147;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#23567;&#23494;&#24230;&#21151;&#29575;&#24046;&#24322;&#20272;&#35745;&#30340;&#26032;&#22411;&#40065;&#26834;&#20027;&#25104;&#20998;&#20998;&#26512;&#20272;&#35745;&#37327;&#65292;&#23427;&#32467;&#21512;&#20102;M&#20272;&#35745;&#21644;&#26368;&#23567;&#24046;&#24322;&#20272;&#35745;&#30340;&#29702;&#35770;&#20248;&#21183;&#65292;&#24182;&#19988;&#26080;&#35770;&#25968;&#25454;&#32500;&#24230;&#22914;&#20309;&#37117;&#20855;&#26377;&#24456;&#39640;&#30340;&#40065;&#26834;&#24615;&#20445;&#35777;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#39640;&#25928;&#30340;&#31639;&#27861;&#26469;&#33719;&#21462;&#36825;&#20010;&#20272;&#35745;&#20540;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#24471;&#21040;&#20102;&#24191;&#27867;&#30340;&#20223;&#30495;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
Principal component analysis (PCA) is a widely employed statistical tool used primarily for dimensionality reduction. However, it is known to be adversely affected by the presence of outlying observations in the sample, which is quite common. Robust PCA methods using M-estimators have theoretical benefits, but their robustness drop substantially for high dimensional data. On the other end of the spectrum, robust PCA algorithms solving principal component pursuit or similar optimization problems have high breakdown, but lack theoretical richness and demand high computational power compared to the M-estimators. We introduce a novel robust PCA estimator based on the minimum density power divergence estimator. This combines the theoretical strength of the M-estimators and the minimum divergence estimators with a high breakdown guarantee regardless of data dimension. We present a computationally efficient algorithm for this estimate. Our theoretical findings are supported by extensive simul
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#32467;&#21512;&#20102;&#26426;&#22120;&#23398;&#20064;&#12289;&#35745;&#37327;&#32463;&#27982;&#23398;&#21644;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#26041;&#27861;&#65292;&#23545;&#33521;&#22269;&#36947;&#36335;&#20132;&#36890;&#20107;&#25925;&#30340;&#20005;&#37325;&#31243;&#24230;&#36827;&#34892;&#20102;&#39044;&#27979;&#21644;&#20998;&#26512;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#20248;&#21270;&#21518;&#30340;&#27169;&#22411;&#22312;&#39044;&#27979;&#20934;&#30830;&#24615;&#26041;&#38754;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#65292;&#24182;&#35782;&#21035;&#20986;&#20102;&#24433;&#21709;&#20107;&#25925;&#20005;&#37325;&#31243;&#24230;&#30340;&#20851;&#38190;&#21464;&#37327;&#12290;</title><link>http://arxiv.org/abs/2309.13483</link><description>&lt;p&gt;
&#20351;&#29992;&#20154;&#24037;&#26234;&#33021;&#22686;&#24378;&#23545;&#33521;&#22269;&#36947;&#36335;&#20132;&#36890;&#20107;&#25925;&#20005;&#37325;&#31243;&#24230;&#30340;&#39044;&#27979;&#19982;&#20998;&#26512;&#65306;&#32467;&#21512;&#26426;&#22120;&#23398;&#20064;&#12289;&#35745;&#37327;&#32463;&#27982;&#23398;&#25216;&#26415;&#21644;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#20844;&#20849;&#21355;&#29983;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Enhancing Prediction and Analysis of UK Road Traffic Accident Severity Using AI: Integration of Machine Learning, Econometric Techniques, and Time Series Forecasting in Public Health Research. (arXiv:2309.13483v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13483
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#32467;&#21512;&#20102;&#26426;&#22120;&#23398;&#20064;&#12289;&#35745;&#37327;&#32463;&#27982;&#23398;&#21644;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#26041;&#27861;&#65292;&#23545;&#33521;&#22269;&#36947;&#36335;&#20132;&#36890;&#20107;&#25925;&#30340;&#20005;&#37325;&#31243;&#24230;&#36827;&#34892;&#20102;&#39044;&#27979;&#21644;&#20998;&#26512;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#20248;&#21270;&#21518;&#30340;&#27169;&#22411;&#22312;&#39044;&#27979;&#20934;&#30830;&#24615;&#26041;&#38754;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#65292;&#24182;&#35782;&#21035;&#20986;&#20102;&#24433;&#21709;&#20107;&#25925;&#20005;&#37325;&#31243;&#24230;&#30340;&#20851;&#38190;&#21464;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#21382;&#21490;&#25968;&#25454;&#65292;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#12289;&#35745;&#37327;&#32463;&#27982;&#23398;&#21644;&#32479;&#35745;&#26041;&#27861;&#23545;&#33521;&#22269;&#36947;&#36335;&#20132;&#36890;&#20107;&#25925;&#30340;&#20005;&#37325;&#31243;&#24230;&#36827;&#34892;&#20102;&#35843;&#26597;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#30456;&#20851;&#24615;&#20998;&#26512;&#12289;&#22238;&#24402;&#27169;&#22411;&#12289;GMM&#22788;&#29702;&#35823;&#24046;&#39033;&#38382;&#39064;&#20197;&#21450;VAR&#21644;ARIMA&#27169;&#22411;&#36827;&#34892;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#31561;&#22810;&#31181;&#25216;&#26415;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#26420;&#32032;&#39044;&#27979;&#65292;MASE&#20026;0.800&#65292;ME&#20026;-73.80&#12290;&#25105;&#20204;&#36824;&#26500;&#24314;&#20102;&#19968;&#20010;&#38543;&#26426;&#26862;&#26519;&#20998;&#31867;&#22120;&#65292;&#31934;&#30830;&#24230;&#20026;73%&#65292;&#21484;&#22238;&#29575;&#20026;78%&#65292;F1&#20998;&#25968;&#20026;73%&#12290;&#36890;&#36807;H2O AutoML&#36827;&#34892;&#20248;&#21270;&#21518;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#19968;&#20010;XGBoost&#27169;&#22411;&#65292;RMSE&#20026;0.176&#65292;MAE&#20026;0.087&#12290;&#22240;&#23376;&#20998;&#26512;&#30830;&#23450;&#20102;&#20851;&#38190;&#21464;&#37327;&#65292;&#25105;&#20204;&#20351;&#29992;SHAP&#36827;&#34892;&#21487;&#35299;&#37322;&#24615;&#20154;&#24037;&#26234;&#33021;&#20998;&#26512;&#65292;&#31361;&#20986;&#20102;Driver_Home_Area_Type&#21644;Road_Type&#31561;&#26377;&#24433;&#21709;&#21147;&#30340;&#22240;&#32032;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25552;&#39640;&#20102;&#23545;&#20107;&#25925;&#20005;&#37325;&#31243;&#24230;&#30340;&#29702;&#35299;&#65292;&#24182;&#20026;&#22522;&#20110;&#35777;&#25454;&#30340;&#36947;&#36335;&#23433;&#20840;&#25919;&#31574;&#25552;&#20379;&#20102;&#21551;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
This research investigates road traffic accident severity in the UK, using a combination of machine learning, econometric, and statistical methods on historical data. We employed various techniques, including correlation analysis, regression models, GMM for error term issues, and time-series forecasting with VAR and ARIMA models. Our approach outperforms naive forecasting with an MASE of 0.800 and ME of -73.80. We also built a random forest classifier with 73% precision, 78% recall, and a 73% F1-score. Optimizing with H2O AutoML led to an XGBoost model with an RMSE of 0.176 and MAE of 0.087. Factor Analysis identified key variables, and we used SHAP for Explainable AI, highlighting influential factors like Driver_Home_Area_Type and Road_Type. Our study enhances understanding of accident severity and offers insights for evidence-based road safety policies.
&lt;/p&gt;</description></item><item><title>&#36825;&#26159;&#19968;&#31687;&#20851;&#20110;&#23558;softmax&#22238;&#24402;&#21644;ResNet&#30456;&#32467;&#21512;&#30340;&#32479;&#19968;&#26041;&#26696;&#30340;&#35770;&#25991;&#65292;&#25552;&#20379;&#20102;&#23545;&#22238;&#24402;&#38382;&#39064;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#24182;&#25512;&#23548;&#20102;&#26799;&#24230;...</title><link>http://arxiv.org/abs/2309.13482</link><description>&lt;p&gt;
ResNet&#21644;Softmax&#30340;&#32479;&#19968;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
A Unified Scheme of ResNet and Softmax. (arXiv:2309.13482v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13482
&lt;/p&gt;
&lt;p&gt;
&#36825;&#26159;&#19968;&#31687;&#20851;&#20110;&#23558;softmax&#22238;&#24402;&#21644;ResNet&#30456;&#32467;&#21512;&#30340;&#32479;&#19968;&#26041;&#26696;&#30340;&#35770;&#25991;&#65292;&#25552;&#20379;&#20102;&#23545;&#22238;&#24402;&#38382;&#39064;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#24182;&#25512;&#23548;&#20102;&#26799;&#24230;...
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#23545;&#20154;&#31867;&#31038;&#20250;&#24102;&#26469;&#20102;&#37325;&#22823;&#21464;&#38761;&#12290;Softmax&#22238;&#24402;&#21644;&#27531;&#24046;&#31070;&#32463;&#32593;&#32476;&#65288;ResNet&#65289;&#26159;&#28145;&#24230;&#23398;&#20064;&#20013;&#20004;&#20010;&#37325;&#35201;&#30340;&#25216;&#26415;&#65306;&#23427;&#20204;&#19981;&#20165;&#20316;&#20026;&#25903;&#25345;LLM&#21151;&#33021;&#30340;&#37325;&#35201;&#29702;&#35770;&#32452;&#25104;&#37096;&#20998;&#65292;&#32780;&#19988;&#19982;&#35768;&#22810;&#20854;&#20182;&#26426;&#22120;&#23398;&#20064;&#21644;&#29702;&#35770;&#35745;&#31639;&#26426;&#31185;&#23398;&#39046;&#22495;&#30456;&#20851;&#65292;&#21253;&#25324;&#20294;&#19981;&#38480;&#20110;&#22270;&#20687;&#20998;&#31867;&#65292;&#30446;&#26631;&#26816;&#27979;&#65292;&#35821;&#20041;&#20998;&#21106;&#21644;&#24352;&#37327;&#12290;&#20197;&#24448;&#30340;&#30740;&#31350;&#23545;&#36825;&#20004;&#20010;&#27010;&#24565;&#36827;&#34892;&#20102;&#20998;&#21035;&#30740;&#31350;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22238;&#24402;&#38382;&#39064;&#30340;&#29702;&#35770;&#20998;&#26512;&#65306;$\| \langle \exp(Ax) + A x , {\bf 1}_n \rangle^{-1} ( \exp(Ax) + Ax ) - b \|_2^2$&#65292;&#20854;&#20013;$A$&#26159;&#19968;&#20010;$n \times d$&#32500;&#23454;&#30697;&#38453;&#65292;$b$&#26159;&#19968;&#20010;$n$&#32500;&#23454;&#21521;&#37327;&#65292;${\bf 1}_n$&#26159;&#25152;&#26377;&#20803;&#32032;&#37117;&#20026;1&#30340;$n$&#32500;&#21521;&#37327;&#12290;&#36825;&#20010;&#22238;&#24402;&#38382;&#39064;&#26159;&#23558;softmax&#22238;&#24402;&#21644;ResNet&#30456;&#32467;&#21512;&#30340;&#32479;&#19968;&#26041;&#26696;&#65292;&#36825;&#22312;&#20197;&#21069;&#20174;&#26410;&#20570;&#36807;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#26799;&#24230;...
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have brought significant changes to human society. Softmax regression and residual neural networks (ResNet) are two important techniques in deep learning: they not only serve as significant theoretical components supporting the functionality of LLMs but also are related to many other machine learning and theoretical computer science fields, including but not limited to image classification, object detection, semantic segmentation, and tensors.  Previous research works studied these two concepts separately. In this paper, we provide a theoretical analysis of the regression problem: $\| \langle \exp(Ax) + A x , {\bf 1}_n \rangle^{-1} ( \exp(Ax) + Ax ) - b \|_2^2$, where $A$ is a matrix in $\mathbb{R}^{n \times d}$, $b$ is a vector in $\mathbb{R}^n$, and ${\bf 1}_n$ is the $n$-dimensional vector whose entries are all $1$. This regression problem is a unified scheme that combines softmax regression and ResNet, which has never been done before. We derive the gra
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;CA-PCA&#31639;&#27861;&#65292;&#23427;&#22522;&#20110;&#26354;&#29575;&#26657;&#20934;&#30340;&#23616;&#37096;PCA&#29256;&#26412;&#65292;&#36890;&#36807;&#32771;&#34385;&#24213;&#23618;&#27969;&#24418;&#30340;&#26354;&#29575;&#65292;&#25913;&#36827;&#20102;&#32500;&#24230;&#20272;&#35745;&#22120;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.13478</link><description>&lt;p&gt;
CA-PCA: &#27979;&#37327;&#26354;&#29575;&#30340;&#27969;&#24418;&#32500;&#24230;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
CA-PCA: Manifold Dimension Estimation, Adapted for Curvature. (arXiv:2309.13478v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13478
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;CA-PCA&#31639;&#27861;&#65292;&#23427;&#22522;&#20110;&#26354;&#29575;&#26657;&#20934;&#30340;&#23616;&#37096;PCA&#29256;&#26412;&#65292;&#36890;&#36807;&#32771;&#34385;&#24213;&#23618;&#27969;&#24418;&#30340;&#26354;&#29575;&#65292;&#25913;&#36827;&#20102;&#32500;&#24230;&#20272;&#35745;&#22120;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#25968;&#25454;&#20998;&#26512;&#31639;&#27861;&#30340;&#25104;&#21151;&#24120;&#24402;&#22240;&#20110;&#27969;&#24418;&#20551;&#35774;&#65292;&#21363;&#20551;&#35774;&#25968;&#25454;&#20998;&#24067;&#22312;&#25110;&#25509;&#36817;&#20302;&#32500;&#27969;&#24418;&#19978;&#12290;&#22312;&#36827;&#34892;&#32500;&#24230;&#32422;&#31616;&#20043;&#21069;&#65292;&#30830;&#23450;&#25110;&#20272;&#35745;&#35813;&#27969;&#24418;&#30340;&#32500;&#24230;&#36890;&#24120;&#26159;&#26377;&#29992;&#30340;&#12290;&#29616;&#26377;&#30340;&#32500;&#24230;&#20272;&#35745;&#26041;&#27861;&#20351;&#29992;&#24179;&#22374;&#21333;&#20301;&#29699;&#36827;&#34892;&#26657;&#20934;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;CA-PCA&#65292;&#19968;&#31181;&#22522;&#20110;&#20108;&#27425;&#23884;&#20837;&#26657;&#20934;&#30340;&#23616;&#37096;PCA&#29256;&#26412;&#65292;&#20197;&#32771;&#34385;&#24213;&#23618;&#27969;&#24418;&#30340;&#26354;&#29575;&#12290;&#22823;&#37327;&#30340;&#31934;&#24515;&#23454;&#39564;&#34920;&#26126;&#65292;&#36825;&#31181;&#36866;&#24212;&#24615;&#25913;&#36827;&#20102;&#20272;&#35745;&#22120;&#22312;&#21508;&#31181;&#35774;&#32622;&#19979;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The success of algorithms in the analysis of high-dimensional data is often attributed to the manifold hypothesis, which supposes that this data lie on or near a manifold of much lower dimension. It is often useful to determine or estimate the dimension of this manifold before performing dimension reduction, for instance. Existing methods for dimension estimation are calibrated using a flat unit ball. In this paper, we develop CA-PCA, a version of local PCA based instead on a calibration of a quadratic embedding, acknowledging the curvature of the underlying manifold. Numerous careful experiments show that this adaptation improves the estimator in a wide range of settings.
&lt;/p&gt;</description></item><item><title>MaGNet&#26159;&#19968;&#31181;&#27169;&#22411;&#26080;&#20851;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#33021;&#22815;&#39034;&#24207;&#22320;&#25972;&#21512;&#19981;&#21516;&#39034;&#24207;&#30340;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#35782;&#21035;&#26377;&#24433;&#21709;&#21147;&#30340;&#32039;&#20945;&#22270;&#32467;&#26500;&#25552;&#20379;&#26377;&#24847;&#20041;&#19988;&#21487;&#35299;&#37322;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.13459</link><description>&lt;p&gt;
&#27169;&#22411;&#26080;&#20851;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#25972;&#21512;&#23616;&#37096;&#21644;&#20840;&#23616;&#20449;&#24687;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Model-Agnostic Graph Neural Network for Integrating Local and Global Information. (arXiv:2309.13459v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13459
&lt;/p&gt;
&lt;p&gt;
MaGNet&#26159;&#19968;&#31181;&#27169;&#22411;&#26080;&#20851;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#33021;&#22815;&#39034;&#24207;&#22320;&#25972;&#21512;&#19981;&#21516;&#39034;&#24207;&#30340;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#35782;&#21035;&#26377;&#24433;&#21709;&#21147;&#30340;&#32039;&#20945;&#22270;&#32467;&#26500;&#25552;&#20379;&#26377;&#24847;&#20041;&#19988;&#21487;&#35299;&#37322;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#22312;&#21508;&#31181;&#20197;&#22270;&#20026;&#37325;&#28857;&#30340;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#20196;&#20154;&#28385;&#24847;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#29616;&#26377;&#30340;GNN&#23384;&#22312;&#20004;&#20010;&#37325;&#35201;&#38480;&#21046;&#65306;&#30001;&#20110;&#40657;&#30418;&#29305;&#24615;&#65292;&#32467;&#26524;&#32570;&#20047;&#21487;&#35299;&#37322;&#24615;&#65307;&#26080;&#27861;&#23398;&#20064;&#19981;&#21516;&#39034;&#24207;&#30340;&#34920;&#31034;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;&#26080;&#20851;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;MaGNet&#65289;&#26694;&#26550;&#65292;&#33021;&#22815;&#39034;&#24207;&#22320;&#25972;&#21512;&#19981;&#21516;&#39034;&#24207;&#30340;&#20449;&#24687;&#65292;&#20174;&#39640;&#38454;&#37051;&#23621;&#20013;&#25552;&#21462;&#30693;&#35782;&#65292;&#24182;&#36890;&#36807;&#35782;&#21035;&#26377;&#24433;&#21709;&#21147;&#30340;&#32039;&#20945;&#22270;&#32467;&#26500;&#25552;&#20379;&#26377;&#24847;&#20041;&#19988;&#21487;&#35299;&#37322;&#30340;&#32467;&#26524;&#12290;&#29305;&#21035;&#22320;&#65292;MaGNet&#30001;&#20004;&#20010;&#32452;&#20214;&#32452;&#25104;&#65306;&#22270;&#25299;&#25169;&#19979;&#22797;&#26434;&#20851;&#31995;&#30340;&#28508;&#22312;&#34920;&#31034;&#30340;&#20272;&#35745;&#27169;&#22411;&#21644;&#35782;&#21035;&#26377;&#24433;&#21709;&#21147;&#30340;&#33410;&#28857;&#12289;&#36793;&#21644;&#37325;&#35201;&#33410;&#28857;&#29305;&#24449;&#30340;&#35299;&#37322;&#27169;&#22411;&#12290;&#20174;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#36890;&#36807;&#32463;&#39564;Rademacher&#22797;&#26434;&#24230;&#24314;&#31435;&#20102;MaGNet&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#24378;&#22823;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) have achieved promising performance in a variety of graph-focused tasks. Despite their success, existing GNNs suffer from two significant limitations: a lack of interpretability in results due to their black-box nature, and an inability to learn representations of varying orders. To tackle these issues, we propose a novel Model-agnostic Graph Neural Network (MaGNet) framework, which is able to sequentially integrate information of various orders, extract knowledge from high-order neighbors, and provide meaningful and interpretable results by identifying influential compact graph structures. In particular, MaGNet consists of two components: an estimation model for the latent representation of complex relationships under graph topology, and an interpretation model that identifies influential nodes, edges, and important node features. Theoretically, we establish the generalization error bound for MaGNet via empirical Rademacher complexity, and showcase its pow
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#36827;&#21270;&#31639;&#27861;&#25191;&#34892;&#20013;&#36873;&#25321;&#36866;&#24403;&#30340;&#36817;&#20284;&#20989;&#25968;&#25104;&#26412;&#30340;&#25216;&#26415;&#65292;&#29992;&#20110;&#21152;&#36895;&#35299;&#20915;&#40657;&#30418;&#20248;&#21270;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.13349</link><description>&lt;p&gt;
&#21152;&#36895;&#28436;&#21270;&#31639;&#27861;&#35299;&#20915;&#40657;&#30418;&#20248;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Speeding-up Evolutionary Algorithms to solve Black-Box Optimization Problems. (arXiv:2309.13349v1 [cs.NE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13349
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#36827;&#21270;&#31639;&#27861;&#25191;&#34892;&#20013;&#36873;&#25321;&#36866;&#24403;&#30340;&#36817;&#20284;&#20989;&#25968;&#25104;&#26412;&#30340;&#25216;&#26415;&#65292;&#29992;&#20110;&#21152;&#36895;&#35299;&#20915;&#40657;&#30418;&#20248;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22788;&#29702;&#35745;&#31639;&#22797;&#26434;&#30340;&#40657;&#30418;&#20248;&#21270;&#38382;&#39064;&#26102;&#65292;&#24120;&#24120;&#20351;&#29992;&#22522;&#20110;&#32676;&#20307;&#30340;&#28436;&#21270;&#31639;&#27861;&#12290;&#23427;&#20204;&#36890;&#36807;&#36873;&#25321;&#26426;&#21046;&#20174;&#32473;&#23450;&#30340;&#32676;&#20307;&#20013;&#36873;&#25321;&#26368;&#20339;&#35299;&#20915;&#26041;&#26696;&#65292;&#27604;&#36739;&#23427;&#20204;&#30340;&#30446;&#26631;&#20540;&#65292;&#28982;&#21518;&#29992;&#36825;&#20123;&#30446;&#26631;&#20540;&#29983;&#25104;&#19979;&#19968;&#20195;&#32676;&#20307;&#12290;&#36825;&#20010;&#36845;&#20195;&#36807;&#31243;&#33021;&#22815;&#39640;&#25928;&#22320;&#25506;&#32034;&#35299;&#31354;&#38388;&#65292;&#36880;&#27493;&#25913;&#21892;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31639;&#27861;&#38656;&#35201;&#22823;&#37327;&#30340;&#35780;&#20272;&#25165;&#33021;&#25552;&#20379;&#19968;&#20010;&#20248;&#36136;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#24403;&#35780;&#20272;&#25104;&#26412;&#24456;&#39640;&#26102;&#65292;&#21487;&#33021;&#20250;&#36896;&#25104;&#35745;&#31639;&#19978;&#30340;&#36127;&#25285;&#12290;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#29992;&#25104;&#26412;&#36739;&#20302;&#30340;&#19981;&#22826;&#20934;&#30830;&#30340;&#36817;&#20284;&#20989;&#25968;&#26367;&#25442;&#21407;&#22987;&#30446;&#26631;&#20989;&#25968;&#12290;&#36825;&#23601;&#24341;&#20837;&#20102;&#35780;&#20272;&#25104;&#26412;&#19982;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#20248;&#21270;&#31639;&#27861;&#25191;&#34892;&#36807;&#31243;&#20013;&#36873;&#25321;&#36866;&#24403;&#30340;&#36817;&#20284;&#20989;&#25968;&#25104;&#26412;&#30340;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Population-based evolutionary algorithms are often considered when approaching computationally expensive black-box optimization problems. They employ a selection mechanism to choose the best solutions from a given population after comparing their objective values, which are then used to generate the next population. This iterative process explores the solution space efficiently, leading to improved solutions over time. However, these algorithms require a large number of evaluations to provide a quality solution, which might be computationally expensive when the evaluation cost is high. In some cases, it is possible to replace the original objective function with a less accurate approximation of lower cost. This introduces a trade-off between the evaluation cost and its accuracy.  In this paper, we propose a technique capable of choosing an appropriate approximate function cost during the execution of the optimization algorithm. The proposal finds the minimum evaluation cost at which th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#29420;&#31435;&#25237;&#24433;&#8221;&#30340;&#26500;&#36896;&#65292;&#23427;&#22312;&#21464;&#20998;&#25512;&#26029;&#21644;&#26368;&#20248;&#22343;&#22330;&#36924;&#36817;&#20013;&#20855;&#26377;&#26368;&#20248;&#30340;&#25928;&#26524;&#65292;&#21487;&#20197;&#23454;&#29616;&#39640;&#32500;&#25193;&#25955;&#36807;&#31243;&#30340;&#29420;&#31435;&#22352;&#26631;&#30340;&#26368;&#20248;&#36924;&#36817;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#38271;&#26102;&#38388;&#25910;&#25947;&#24615;&#21644;&#24930;&#30340;&#36335;&#24452;&#22686;&#38271;&#29575;&#12290;</title><link>http://arxiv.org/abs/2309.13332</link><description>&lt;p&gt;
&#29420;&#31435;&#25237;&#24433;&#30340;&#25193;&#25955;&#65306;&#21464;&#20998;&#25512;&#26029;&#21644;&#26368;&#20248;&#22343;&#22330;&#36924;&#36817;&#30340;&#26799;&#24230;&#27969;
&lt;/p&gt;
&lt;p&gt;
Independent projections of diffusions: Gradient flows for variational inference and optimal mean field approximations. (arXiv:2309.13332v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13332
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#29420;&#31435;&#25237;&#24433;&#8221;&#30340;&#26500;&#36896;&#65292;&#23427;&#22312;&#21464;&#20998;&#25512;&#26029;&#21644;&#26368;&#20248;&#22343;&#22330;&#36924;&#36817;&#20013;&#20855;&#26377;&#26368;&#20248;&#30340;&#25928;&#26524;&#65292;&#21487;&#20197;&#23454;&#29616;&#39640;&#32500;&#25193;&#25955;&#36807;&#31243;&#30340;&#29420;&#31435;&#22352;&#26631;&#30340;&#26368;&#20248;&#36924;&#36817;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#38271;&#26102;&#38388;&#25910;&#25947;&#24615;&#21644;&#24930;&#30340;&#36335;&#24452;&#22686;&#38271;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#20309;&#29992;&#29420;&#31435;&#22352;&#26631;&#30340;&#36807;&#31243;&#26469;&#26368;&#20248;&#22320;&#36924;&#36817;&#39640;&#32500;&#25193;&#25955;&#36807;&#31243;&#65311;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#29420;&#31435;&#25237;&#24433;&#8221;&#30340;&#26500;&#36896;&#65292;&#23427;&#22312;&#20004;&#20010;&#33258;&#28982;&#20934;&#21017;&#19979;&#26159;&#26368;&#20248;&#30340;&#12290;&#39318;&#20808;&#65292;&#24403;&#21407;&#22987;&#25193;&#25955;&#36807;&#31243;&#26159;&#21487;&#36870;&#30340;&#19988;&#20855;&#26377;&#19981;&#21464;&#27979;&#24230;&#961;&#8727;&#26102;&#65292;&#29420;&#31435;&#25237;&#24433;&#20316;&#20026;&#29420;&#31435;&#22352;&#26631;&#30340;&#31354;&#38388;&#19978;&#30456;&#23545;&#29109;H(&#8901;|&#961;&#8727;)&#30340;Wasserstein&#26799;&#24230;&#27969;&#12290;&#36825;&#19982;&#32479;&#35745;&#25991;&#29486;&#20013;&#20851;&#20110;&#22343;&#22330;&#21464;&#20998;&#25512;&#26029;&#30340;Langevin&#37319;&#26679;&#26041;&#26696;&#26377;&#20851;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#20851;&#20110;&#29420;&#31435;&#25237;&#24433;&#30340;&#38271;&#26102;&#38388;&#25910;&#25947;&#30340;&#23450;&#24615;&#21644;&#23450;&#37327;&#32467;&#26524;&#65292;&#20854;&#20013;&#22312;&#23545;&#25968;&#20985;&#24773;&#20917;&#19979;&#30340;&#23450;&#37327;&#32467;&#26524;&#26159;&#36890;&#36807;&#19968;&#31181;&#26032;&#30340;&#23545;&#25968;Sobolev&#19981;&#31561;&#24335;&#30340;&#21464;&#20307;&#25512;&#23548;&#20986;&#26469;&#30340;&#12290;&#20854;&#27425;&#65292;&#22312;&#25152;&#26377;&#20855;&#26377;&#29420;&#31435;&#22352;&#26631;&#30340;&#36807;&#31243;&#20013;&#65292;&#29420;&#31435;&#25237;&#24433;&#26174;&#31034;&#20986;&#20102;&#36335;&#24452;&#22686;&#38271;&#29575;&#26368;&#24930;&#12290;
&lt;/p&gt;
&lt;p&gt;
What is the optimal way to approximate a high-dimensional diffusion process by one in which the coordinates are independent? This paper presents a construction, called the \emph{independent projection}, which is optimal for two natural criteria. First, when the original diffusion is reversible with invariant measure $\rho_*$, the independent projection serves as the Wasserstein gradient flow for the relative entropy $H(\cdot\,|\,\rho_*)$ constrained to the space of product measures. This is related to recent Langevin-based sampling schemes proposed in the statistical literature on mean field variational inference. In addition, we provide both qualitative and quantitative results on the long-time convergence of the independent projection, with quantitative results in the log-concave case derived via a new variant of the logarithmic Sobolev inequality. Second, among all processes with independent coordinates, the independent projection is shown to exhibit the slowest growth rate of path-
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;C$^2$VAE&#27169;&#22411;&#65292;&#36890;&#36807;&#32852;&#21512;&#23398;&#20064;&#38750;&#32806;&#21512;&#19988;&#30456;&#20851;&#30340;&#38544;&#34255;&#22240;&#32032;&#65292;&#24182;&#36890;&#36807;&#33258;&#30417;&#30563;&#20998;&#31867;&#22120;&#28040;&#38500;&#32806;&#21512;&#34920;&#31034;&#65292;&#20197;&#22686;&#24378;&#38750;&#32806;&#21512;&#34920;&#31034;&#23398;&#20064;&#12290;&#35813;&#27169;&#22411;&#22312;&#19981;&#20381;&#36182;&#20808;&#39564;&#30693;&#35782;&#21644;&#24378;&#24314;&#27169;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#24635;&#30456;&#20851;&#39537;&#21160;&#20998;&#35299;&#21518;&#39564;&#26469;&#23398;&#20064;&#22240;&#23376;&#21270;&#30340;&#38750;&#32806;&#21512;&#34920;&#31034;&#65292;&#24182;&#21033;&#29992;&#31070;&#32463;&#39640;&#26031;Copula&#27169;&#22411;&#25552;&#21462;&#38544;&#34255;&#29305;&#24449;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#26469;&#33719;&#24471;&#32806;&#21512;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2309.13303</link><description>&lt;p&gt;
C$^2$VAE&#65306;&#22522;&#20110;&#39640;&#26031;Copula&#30340;VAE&#19982;&#23545;&#27604;&#21518;&#39564;&#30340;&#38750;&#32806;&#21512;&#19982;&#38750;&#32806;&#21512;&#34920;&#31034;&#26377;&#24046;&#24322;&#30340;&#32852;&#21512;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
C$^2$VAE: Gaussian Copula-based VAE Differing Disentangled from Coupled Representations with Contrastive Posterior. (arXiv:2309.13303v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13303
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;C$^2$VAE&#27169;&#22411;&#65292;&#36890;&#36807;&#32852;&#21512;&#23398;&#20064;&#38750;&#32806;&#21512;&#19988;&#30456;&#20851;&#30340;&#38544;&#34255;&#22240;&#32032;&#65292;&#24182;&#36890;&#36807;&#33258;&#30417;&#30563;&#20998;&#31867;&#22120;&#28040;&#38500;&#32806;&#21512;&#34920;&#31034;&#65292;&#20197;&#22686;&#24378;&#38750;&#32806;&#21512;&#34920;&#31034;&#23398;&#20064;&#12290;&#35813;&#27169;&#22411;&#22312;&#19981;&#20381;&#36182;&#20808;&#39564;&#30693;&#35782;&#21644;&#24378;&#24314;&#27169;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#24635;&#30456;&#20851;&#39537;&#21160;&#20998;&#35299;&#21518;&#39564;&#26469;&#23398;&#20064;&#22240;&#23376;&#21270;&#30340;&#38750;&#32806;&#21512;&#34920;&#31034;&#65292;&#24182;&#21033;&#29992;&#31070;&#32463;&#39640;&#26031;Copula&#27169;&#22411;&#25552;&#21462;&#38544;&#34255;&#29305;&#24449;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#26469;&#33719;&#24471;&#32806;&#21512;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#30417;&#30563;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#65292;&#20197;&#32852;&#21512;&#23398;&#20064;&#38750;&#32806;&#21512;&#19988;&#30456;&#20851;&#30340;&#38544;&#34255;&#22240;&#32032;&#65292;&#28982;&#21518;&#36890;&#36807;&#33258;&#30417;&#30563;&#20998;&#31867;&#22120;&#22686;&#24378;&#38750;&#32806;&#21512;&#34920;&#31034;&#23398;&#20064;&#65292;&#20197;&#23545;&#27604;&#26041;&#24335;&#28040;&#38500;&#32806;&#21512;&#34920;&#31034;&#12290;&#20026;&#27492;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#26080;&#38656;&#20381;&#36182;&#20808;&#39564;&#30693;&#35782;&#21644;&#22312;&#31070;&#32463;&#26550;&#26500;&#20013;&#28041;&#21450;&#21518;&#39564;&#30340;&#24378;&#24314;&#27169;&#20551;&#35774;&#30340;&#23545;&#27604;Copula VAE&#65288;C$^2$VAE&#65289;&#12290;C$^2$VAE&#20351;&#29992;&#24635;&#30456;&#20851;&#65288;TC&#65289;&#39537;&#21160;&#20998;&#35299;&#26469;&#22240;&#23376;&#21270;&#21518;&#39564;&#65288;ELBO&#65289;&#65292;&#20197;&#23398;&#20064;&#22240;&#23376;&#21270;&#30340;&#38750;&#32806;&#21512;&#34920;&#31034;&#65292;&#24182;&#36890;&#36807;&#31070;&#32463;&#39640;&#26031;Copula&#25552;&#21462;&#38544;&#34255;&#29305;&#24449;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#20197;&#33719;&#24471;&#32806;&#21512;&#34920;&#31034;&#12290;&#28982;&#21518;&#65292;&#33258;&#30417;&#30563;&#23545;&#27604;&#20998;&#31867;&#22120;&#21306;&#20998;&#38750;&#32806;&#21512;&#34920;&#31034;&#21644;&#32806;&#21512;&#34920;&#31034;&#65292;&#20854;&#20013;&#23545;&#27604;&#25439;&#22833;&#29992;&#20110;&#27491;&#21017;&#21270;&#35813;&#23545;&#27604;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a self-supervised variational autoencoder (VAE) to jointly learn disentangled and dependent hidden factors and then enhance disentangled representation learning by a self-supervised classifier to eliminate coupled representations in a contrastive manner. To this end, a Contrastive Copula VAE (C$^2$VAE) is introduced without relying on prior knowledge about data in the probabilistic principle and involving strong modeling assumptions on the posterior in the neural architecture. C$^2$VAE simultaneously factorizes the posterior (evidence lower bound, ELBO) with total correlation (TC)-driven decomposition for learning factorized disentangled representations and extracts the dependencies between hidden features by a neural Gaussian copula for copula coupled representations. Then, a self-supervised contrastive classifier differentiates the disentangled representations from the coupled representations, where a contrastive loss regularizes this contrastive classification together wi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#23545;&#20110;&#24378;&#21270;&#23398;&#20064;&#38750;&#21516;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#30340;&#32479;&#19968;&#35823;&#24046;&#37327;&#21270;&#26694;&#26550;&#65292;&#24182;&#35299;&#20915;&#20102;&#20998;&#24067;&#20559;&#31227;&#30340;&#25361;&#25112;&#12290;&#36890;&#36807;&#22312;&#19968;&#20010;&#21333;&#19968;&#30340;&#21306;&#38388;&#20869;&#20849;&#21516;&#37327;&#21270;&#20004;&#20010;&#20272;&#35745;&#35823;&#24046;&#28304;&#65292;&#35813;&#26694;&#26550;&#25581;&#31034;&#20102;&#20043;&#21069;&#38544;&#34255;&#30340;&#35823;&#24046;&#26435;&#34913;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#32622;&#20449;&#21306;&#38388;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.13278</link><description>&lt;p&gt;
&#20998;&#24067;&#20559;&#31227;&#24863;&#30693;&#30340;&#24378;&#21270;&#23398;&#20064;&#38750;&#21516;&#31574;&#30053;&#21306;&#38388;&#20272;&#35745;&#26041;&#27861;&#65306;&#19968;&#20010;&#32479;&#19968;&#30340;&#35823;&#24046;&#37327;&#21270;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Distributional Shift-Aware Off-Policy Interval Estimation: A Unified Error Quantification Framework. (arXiv:2309.13278v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13278
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#23545;&#20110;&#24378;&#21270;&#23398;&#20064;&#38750;&#21516;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#30340;&#32479;&#19968;&#35823;&#24046;&#37327;&#21270;&#26694;&#26550;&#65292;&#24182;&#35299;&#20915;&#20102;&#20998;&#24067;&#20559;&#31227;&#30340;&#25361;&#25112;&#12290;&#36890;&#36807;&#22312;&#19968;&#20010;&#21333;&#19968;&#30340;&#21306;&#38388;&#20869;&#20849;&#21516;&#37327;&#21270;&#20004;&#20010;&#20272;&#35745;&#35823;&#24046;&#28304;&#65292;&#35813;&#26694;&#26550;&#25581;&#31034;&#20102;&#20043;&#21069;&#38544;&#34255;&#30340;&#35823;&#24046;&#26435;&#34913;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#32622;&#20449;&#21306;&#38388;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26080;&#38480;&#26102;&#38388;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#39640;&#32622;&#20449;&#24230;&#38750;&#21516;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#20854;&#30446;&#26631;&#26159;&#20165;&#21033;&#29992;&#20174;&#26410;&#30693;&#34892;&#20026;&#31574;&#30053;&#39044;&#20808;&#25910;&#38598;&#30340;&#31163;&#32447;&#25968;&#25454;&#20026;&#30446;&#26631;&#31574;&#30053;&#30340;&#20540;&#24314;&#31435;&#19968;&#20010;&#32622;&#20449;&#21306;&#38388;&#65288;CI&#65289;&#12290;&#35813;&#20219;&#21153;&#38754;&#20020;&#20004;&#20010;&#20027;&#35201;&#25361;&#25112;&#65306;&#22312;CI&#20272;&#35745;&#20013;&#25552;&#20379;&#20840;&#38754;&#19988;&#20005;&#26684;&#30340;&#35823;&#24046;&#37327;&#21270;&#65292;&#24182;&#35299;&#20915;&#30001;&#30446;&#26631;&#31574;&#30053;&#20135;&#29983;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65292;&#35813;&#20998;&#24067;&#19982;&#31163;&#32447;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20043;&#38388;&#23384;&#22312;&#24046;&#24322;&#12290;&#21463;&#21040;&#21019;&#26032;&#30340;&#32479;&#19968;&#35823;&#24046;&#20998;&#26512;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#22312;&#19968;&#20010;&#21333;&#19968;&#30340;&#21306;&#38388;&#20869;&#20849;&#21516;&#37327;&#21270;&#20004;&#20010;&#20272;&#35745;&#35823;&#24046;&#26469;&#28304;&#65306;&#22312;&#24314;&#27169;&#36793;&#38469;&#21270;&#37325;&#35201;&#24615;&#26435;&#37325;&#26102;&#30340;&#35268;&#33539;&#19981;&#20934;&#30830;&#35823;&#24046;&#21644;&#25277;&#26679;&#23548;&#33268;&#30340;&#32479;&#35745;&#19981;&#30830;&#23450;&#24615;&#12290;&#36825;&#19968;&#32479;&#19968;&#30340;&#26694;&#26550;&#25581;&#31034;&#20102;&#35823;&#24046;&#20043;&#38388;&#20197;&#21069;&#38544;&#34255;&#30340;&#26435;&#34913;&#65292;&#20174;&#32780;&#21066;&#24369;&#20102;CI&#30340;&#32039;&#23494;&#24615;&#12290;&#36890;&#36807;&#20381;&#38752;&#31934;&#24515;&#35774;&#35745;&#30340;&#21028;&#21035;&#20989;&#25968;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35299;&#20915;&#26041;&#26696;&#26469;&#20811;&#26381;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study high-confidence off-policy evaluation in the context of infinite-horizon Markov decision processes, where the objective is to establish a confidence interval (CI) for the target policy value using only offline data pre-collected from unknown behavior policies. This task faces two primary challenges: providing a comprehensive and rigorous error quantification in CI estimation, and addressing the distributional shift that results from discrepancies between the distribution induced by the target policy and the offline data-generating process. Motivated by an innovative unified error analysis, we jointly quantify the two sources of estimation errors: the misspecification error on modeling marginalized importance weights and the statistical uncertainty due to sampling, within a single interval. This unified framework reveals a previously hidden tradeoff between the errors, which undermines the tightness of the CI. Relying on a carefully designed discriminator function, the proposed
&lt;/p&gt;</description></item><item><title>BART-SIMP&#26159;&#19968;&#31181;&#28789;&#27963;&#30340;&#31354;&#38388;&#21327;&#21464;&#24314;&#27169;&#21644;&#39044;&#27979;&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#39640;&#26031;&#36807;&#31243;&#31354;&#38388;&#27169;&#22411;&#21644;&#36125;&#21494;&#26031;&#21152;&#27861;&#22238;&#24402;&#26641;&#27169;&#22411;&#65292;&#21487;&#20197;&#25552;&#20379;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#24182;&#25104;&#21151;&#24212;&#29992;&#20110;&#32943;&#23612;&#20122;&#23478;&#24237;&#38598;&#32676;&#26679;&#26412;&#20013;&#30340;&#20154;&#20307;&#27979;&#37327;&#21709;&#24212;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2309.13270</link><description>&lt;p&gt;
BART-SIMP&#65306;&#19968;&#31181;&#28789;&#27963;&#30340;&#31354;&#38388;&#21327;&#21464;&#24314;&#27169;&#21644;&#39044;&#27979;&#30340;&#26032;&#26694;&#26550;&#20351;&#29992;&#36125;&#21494;&#26031;&#21152;&#27861;&#22238;&#24402;&#26641;
&lt;/p&gt;
&lt;p&gt;
BART-SIMP: a novel framework for flexible spatial covariate modeling and prediction using Bayesian additive regression trees. (arXiv:2309.13270v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13270
&lt;/p&gt;
&lt;p&gt;
BART-SIMP&#26159;&#19968;&#31181;&#28789;&#27963;&#30340;&#31354;&#38388;&#21327;&#21464;&#24314;&#27169;&#21644;&#39044;&#27979;&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#39640;&#26031;&#36807;&#31243;&#31354;&#38388;&#27169;&#22411;&#21644;&#36125;&#21494;&#26031;&#21152;&#27861;&#22238;&#24402;&#26641;&#27169;&#22411;&#65292;&#21487;&#20197;&#25552;&#20379;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#24182;&#25104;&#21151;&#24212;&#29992;&#20110;&#32943;&#23612;&#20122;&#23478;&#24237;&#38598;&#32676;&#26679;&#26412;&#20013;&#30340;&#20154;&#20307;&#27979;&#37327;&#21709;&#24212;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31354;&#38388;&#32479;&#35745;&#23398;&#20013;&#65292;&#39044;&#27979;&#26159;&#19968;&#20010;&#32463;&#20856;&#30340;&#25361;&#25112;&#65292;&#23558;&#31354;&#38388;&#21327;&#21464;&#37327;&#32435;&#20837;&#20855;&#26377;&#28508;&#22312;&#31354;&#38388;&#25928;&#24212;&#30340;&#27169;&#22411;&#20013;&#21487;&#20197;&#26497;&#22823;&#22320;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#12290;&#25105;&#20204;&#24076;&#26395;&#24320;&#21457;&#20986;&#28789;&#27963;&#30340;&#22238;&#24402;&#27169;&#22411;&#65292;&#20801;&#35768;&#22312;&#21327;&#21464;&#37327;&#32467;&#26500;&#20013;&#23384;&#22312;&#38750;&#32447;&#24615;&#21644;&#20132;&#20114;&#20316;&#29992;&#12290;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#24050;&#32463;&#22312;&#31354;&#38388;&#29615;&#22659;&#20013;&#25552;&#20986;&#65292;&#20801;&#35768;&#27531;&#24046;&#20013;&#23384;&#22312;&#31354;&#38388;&#20381;&#36182;&#24615;&#65292;&#20294;&#26080;&#27861;&#25552;&#20379;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#39640;&#26031;&#36807;&#31243;&#31354;&#38388;&#27169;&#22411;&#21644;&#36125;&#21494;&#26031;&#21152;&#27861;&#22238;&#24402;&#26641;&#65288;BART&#65289;&#27169;&#22411;&#30340;&#26032;&#32452;&#21512;&#12290;&#36890;&#36807;&#23558;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#65288;MCMC&#65289;&#19982;&#23884;&#22871;&#25289;&#26222;&#25289;&#26031;&#36817;&#20284;&#65288;INLA&#65289;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#38477;&#20302;&#20102;&#26041;&#27861;&#30340;&#35745;&#31639;&#36127;&#25285;&#12290;&#25105;&#20204;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#20102;&#35813;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#24182;&#20351;&#29992;&#35813;&#27169;&#22411;&#39044;&#27979;&#22312;&#32943;&#23612;&#20122;&#23478;&#24237;&#38598;&#32676;&#26679;&#26412;&#20013;&#25910;&#38598;&#30340;&#20154;&#20307;&#27979;&#37327;&#21709;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
Prediction is a classic challenge in spatial statistics and the inclusion of spatial covariates can greatly improve predictive performance when incorporated into a model with latent spatial effects. It is desirable to develop flexible regression models that allow for nonlinearities and interactions in the covariate structure. Machine learning models have been suggested in the spatial context, allowing for spatial dependence in the residuals, but fail to provide reliable uncertainty estimates. In this paper, we investigate a novel combination of a Gaussian process spatial model and a Bayesian Additive Regression Tree (BART) model. The computational burden of the approach is reduced by combining Markov chain Monte Carlo (MCMC) with the Integrated Nested Laplace Approximation (INLA) technique. We study the performance of the method via simulations and use the model to predict anthropometric responses, collected via household cluster samples in Kenya.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20449;&#24687;&#20215;&#20540;&#65288;IV&#65289;&#30340;&#32479;&#35745;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#20026;&#27169;&#22411;&#24314;&#31435;&#21069;&#30340;&#29305;&#24449;&#36873;&#25321;&#25552;&#20379;&#20102;&#29702;&#35770;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.13183</link><description>&lt;p&gt;
&#20449;&#24687;&#20215;&#20540;&#65288;IV&#65289;&#30340;&#32479;&#35745;&#20551;&#35774;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Statistical Hypothesis Testing for Information Value (IV). (arXiv:2309.13183v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13183
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20449;&#24687;&#20215;&#20540;&#65288;IV&#65289;&#30340;&#32479;&#35745;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#20026;&#27169;&#22411;&#24314;&#31435;&#21069;&#30340;&#29305;&#24449;&#36873;&#25321;&#25552;&#20379;&#20102;&#29702;&#35770;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#20215;&#20540;&#65288;IV&#65289;&#26159;&#27169;&#22411;&#24314;&#31435;&#21069;&#36827;&#34892;&#29305;&#24449;&#36873;&#25321;&#30340;&#19968;&#31181;&#24120;&#29992;&#25216;&#26415;&#12290;&#30446;&#21069;&#23384;&#22312;&#19968;&#20123;&#23454;&#38469;&#26631;&#20934;&#65292;&#20294;&#22522;&#20110;IV&#30340;&#21028;&#26029;&#26159;&#21542;&#19968;&#20010;&#39044;&#27979;&#22240;&#23376;&#20855;&#26377;&#36275;&#22815;&#30340;&#39044;&#27979;&#33021;&#21147;&#30340;&#29702;&#35770;&#20381;&#25454;&#20381;&#28982;&#31070;&#31192;&#19988;&#32570;&#20047;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#35813;&#25216;&#26415;&#30340;&#25968;&#23398;&#21457;&#23637;&#21644;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#22312;&#25991;&#29486;&#20013;&#20960;&#20046;&#27809;&#26377;&#25552;&#21450;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20851;&#20110;IV&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#26469;&#27979;&#35797;&#39044;&#27979;&#33021;&#21147;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#39640;&#25928;&#35745;&#31639;&#26816;&#39564;&#32479;&#35745;&#37327;&#65292;&#24182;&#22312;&#27169;&#25311;&#25968;&#25454;&#19978;&#30740;&#31350;&#20854;&#34920;&#29616;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#36825;&#19968;&#26041;&#27861;&#24212;&#29992;&#20110;&#38134;&#34892;&#27450;&#35784;&#25968;&#25454;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#23454;&#29616;&#25105;&#20204;&#32467;&#26524;&#30340;Python&#24211;&#12290;
&lt;/p&gt;
&lt;p&gt;
Information value (IV) is a quite popular technique for feature selection prior to the modeling phase. There are practical criteria, but at the same time mysterious and lacking theoretical arguments, based on the IV, to decide if a predictor has sufficient predictive power to be considered in the modeling phase. However, the mathematical development and statistical inference methods for this technique is almost non-existent in the literature. In this work we present a theoretical framework for the IV and propose a non-parametric hypothesis test to test the predictive power. We show how to efficiently calculate the test statistic and study its performance on simulated data. Additionally, we apply our test on bank fraud data and provide a Python library where we implement our results.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#38750;&#21442;&#25968;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#36827;&#34892;&#22522;&#20110;&#27169;&#22411;&#30340;&#32858;&#31867;&#26102;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#65292;&#24182;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#32858;&#31867;&#26041;&#27861;&#12290;&#36890;&#36807;&#30740;&#31350;&#20998;&#31867;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#21644;&#32858;&#31867;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#30830;&#23450;&#20102;&#32858;&#31867;&#20219;&#21153;&#30340;&#38590;&#24230;&#12290;&#21516;&#26102;&#65292;&#22312;&#25554;&#20540;&#20998;&#31867;&#22120;&#21644;&#22312;&#32447;&#35774;&#32622;&#20013;&#30340;&#32467;&#26524;&#20063;&#24471;&#21040;&#20102;&#35777;&#26126;&#12290;&#27169;&#25311;&#23454;&#39564;&#39564;&#35777;&#20102;&#36825;&#20123;&#21457;&#29616;&#12290;</title><link>http://arxiv.org/abs/2309.12238</link><description>&lt;p&gt;
&#20351;&#29992;&#38750;&#21442;&#25968;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Model-based Clustering using Non-parametric Hidden Markov Models. (arXiv:2309.12238v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12238
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#38750;&#21442;&#25968;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#36827;&#34892;&#22522;&#20110;&#27169;&#22411;&#30340;&#32858;&#31867;&#26102;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#65292;&#24182;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#32858;&#31867;&#26041;&#27861;&#12290;&#36890;&#36807;&#30740;&#31350;&#20998;&#31867;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#21644;&#32858;&#31867;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#30830;&#23450;&#20102;&#32858;&#31867;&#20219;&#21153;&#30340;&#38590;&#24230;&#12290;&#21516;&#26102;&#65292;&#22312;&#25554;&#20540;&#20998;&#31867;&#22120;&#21644;&#22312;&#32447;&#35774;&#32622;&#20013;&#30340;&#32467;&#26524;&#20063;&#24471;&#21040;&#20102;&#35777;&#26126;&#12290;&#27169;&#25311;&#23454;&#39564;&#39564;&#35777;&#20102;&#36825;&#20123;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#21442;&#25968;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#65288;HMM&#65289;&#30001;&#20110;&#20854;&#20381;&#36182;&#32467;&#26500;&#65292;&#21487;&#20197;&#22312;&#19981;&#25351;&#23450;&#32676;&#32452;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#22522;&#20110;&#27169;&#22411;&#30340;&#32858;&#31867;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20351;&#29992;HMM&#36827;&#34892;&#32858;&#31867;&#26102;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#65292;&#24182;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#32858;&#31867;&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#23558;&#20998;&#31867;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#19982;&#32858;&#31867;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#32852;&#31995;&#36215;&#26469;&#30340;&#32467;&#26524;&#65292;&#29992;&#20197;&#30830;&#23450;&#32858;&#31867;&#20219;&#21153;&#30340;&#38590;&#24230;&#30340;&#20851;&#38190;&#25968;&#37327;&#12290;&#25105;&#20204;&#36824;&#22312;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#26694;&#26550;&#19979;&#35777;&#26126;&#20102;&#36825;&#19968;&#32467;&#26524;&#65292;&#36825;&#21487;&#33021;&#20855;&#26377;&#29420;&#31435;&#30340;&#20852;&#36259;&#12290;&#28982;&#21518;&#25105;&#20204;&#30740;&#31350;&#20102;&#25554;&#20540;&#20998;&#31867;&#22120;&#30340;&#36807;&#24230;&#39118;&#38505;&#12290;&#25152;&#26377;&#36825;&#20123;&#32467;&#26524;&#37117;&#34987;&#35777;&#26126;&#22312;&#22312;&#32447;&#35774;&#32622;&#20013;&#20173;&#28982;&#26377;&#25928;&#65292;&#22312;&#35813;&#35774;&#32622;&#19979;&#65292;&#35266;&#27979;&#32467;&#26524;&#34987;&#39034;&#24207;&#32858;&#31867;&#12290;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Thanks to their dependency structure, non-parametric Hidden Markov Models (HMMs) are able to handle model-based clustering without specifying group distributions. The aim of this work is to study the Bayes risk of clustering when using HMMs and to propose associated clustering procedures. We first give a result linking the Bayes risk of classification and the Bayes risk of clustering, which we use to identify the key quantity determining the difficulty of the clustering task. We also give a proof of this result in the i.i.d. framework, which might be of independent interest. Then we study the excess risk of the plugin classifier. All these results are shown to remain valid in the online setting where observations are clustered sequentially. Simulations illustrate our findings.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23450;&#20041;&#22312;&#32039;&#33268;Riemannian&#27969;&#24418;&#19978;&#30340;&#20869;&#22312;Matern&#39640;&#26031;&#36807;&#31243;&#21644;&#22806;&#22312;&#36807;&#31243;&#20043;&#38388;&#30340;&#25910;&#32553;&#36895;&#29575;&#65292;&#24182;&#21457;&#29616;&#23427;&#20204;&#30340;&#36895;&#29575;&#22312;&#36866;&#24403;&#21305;&#37197;&#24179;&#28369;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#26159;&#30456;&#31561;&#30340;&#12290;</title><link>http://arxiv.org/abs/2309.10918</link><description>&lt;p&gt;
Riemannian&#27969;&#24418;&#19978;Matern&#39640;&#26031;&#36807;&#31243;&#30340;&#21518;&#39564;&#25910;&#32553;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Posterior Contraction Rates for Mat\'ern Gaussian Processes on Riemannian Manifolds. (arXiv:2309.10918v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10918
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23450;&#20041;&#22312;&#32039;&#33268;Riemannian&#27969;&#24418;&#19978;&#30340;&#20869;&#22312;Matern&#39640;&#26031;&#36807;&#31243;&#21644;&#22806;&#22312;&#36807;&#31243;&#20043;&#38388;&#30340;&#25910;&#32553;&#36895;&#29575;&#65292;&#24182;&#21457;&#29616;&#23427;&#20204;&#30340;&#36895;&#29575;&#22312;&#36866;&#24403;&#21305;&#37197;&#24179;&#28369;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#26159;&#30456;&#31561;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#22312;&#35768;&#22810;&#20381;&#36182;&#20110;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#34987;&#20351;&#29992;&#12290;&#26368;&#36817;&#65292;&#24050;&#32463;&#24320;&#21457;&#20102;&#22312;&#20960;&#20309;&#35774;&#32622;&#19979;&#22788;&#29702;&#36825;&#20123;&#27169;&#22411;&#30340;&#35745;&#31639;&#24037;&#20855;&#65292;&#20363;&#22914;&#65292;&#24403;&#36755;&#20837;&#20301;&#20110;Riemannian&#27969;&#24418;&#19978;&#26102;&#12290;&#36825;&#24341;&#20986;&#20102;&#19968;&#20010;&#38382;&#39064;&#65306;&#36825;&#20123;&#20869;&#22312;&#27169;&#22411;&#22312;&#29702;&#35770;&#19978;&#26159;&#21542;&#21487;&#20197;&#35777;&#26126;&#30456;&#27604;&#20110;&#23558;&#25152;&#26377;&#30456;&#20851;&#37327;&#23884;&#20837;&#21040;$\mathbb{R}^d$&#24182;&#20351;&#29992;&#26222;&#36890;&#27431;&#20960;&#37324;&#24503;&#39640;&#26031;&#36807;&#31243;&#30340;&#38480;&#21046;&#65292;&#21487;&#20197;&#24102;&#26469;&#26356;&#22909;&#30340;&#24615;&#33021;&#65311;&#20026;&#20102;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23450;&#20041;&#22312;&#32039;&#33268;Riemannian&#27969;&#24418;&#19978;&#30340;&#20869;&#22312;Matern&#39640;&#26031;&#36807;&#31243;&#30340;&#26368;&#20248;&#25910;&#32553;&#36895;&#29575;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#27969;&#24418;&#21644;&#29615;&#22659;Sobolev&#31354;&#38388;&#20043;&#38388;&#30340;&#36857;&#21644;&#25193;&#23637;&#23450;&#29702;&#35777;&#26126;&#20102;&#22806;&#22312;&#36807;&#31243;&#30340;&#31867;&#20284;&#36895;&#29575;&#65306;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25152;&#24471;&#21040;&#30340;&#36895;&#29575;&#19982;&#20869;&#22312;&#36807;&#31243;&#30340;&#36895;&#29575;&#30456;&#31526;&#65292;&#21069;&#25552;&#26159;&#23427;&#20204;&#30340;&#24179;&#28369;&#21442;&#25968;&#36866;&#24403;&#21305;&#37197;&#12290;&#25105;&#20204;&#22312;&#19968;&#20123;&#23454;&#35777;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#23545;&#36825;&#20123;&#36895;&#29575;&#30340;&#28436;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes are used in many machine learning applications that rely on uncertainty quantification. Recently, computational tools for working with these models in geometric settings, such as when inputs lie on a Riemannian manifold, have been developed. This raises the question: can these intrinsic models be shown theoretically to lead to better performance, compared to simply embedding all relevant quantities into $\mathbb{R}^d$ and using the restriction of an ordinary Euclidean Gaussian process? To study this, we prove optimal contraction rates for intrinsic Mat\'ern Gaussian processes defined on compact Riemannian manifolds. We also prove analogous rates for extrinsic processes using trace and extension theorems between manifold and ambient Sobolev spaces: somewhat surprisingly, the rates obtained turn out to coincide with those of the intrinsic processes, provided that their smoothness parameters are matched appropriately. We illustrate these rates empirically on a number of
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#28145;&#24230;&#23398;&#20064;&#32593;&#32476;&#32467;&#26500;&#30340;&#20960;&#20309;&#35299;&#37322;&#65292;&#24182;&#19988;&#26500;&#24314;&#20102;&#20840;&#23616;&#26368;&#23567;&#21270;&#22120;&#26063;&#65292;&#35813;&#26063;&#33021;&#22815;&#20840;&#23616;&#26368;&#23567;&#21270;&#25104;&#26412;&#20989;&#25968;&#12290;&#27492;&#22806;&#65292;&#36824;&#30830;&#23450;&#20102;&#21508;&#31181;&#36864;&#21270;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;</title><link>http://arxiv.org/abs/2309.10639</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#32593;&#32476;&#30340;&#20960;&#20309;&#32467;&#26500;&#21644;&#20840;&#23616;${\mathcal L}^2$&#26368;&#23567;&#21270;&#22120;&#30340;&#26500;&#24314;
&lt;/p&gt;
&lt;p&gt;
Geometric structure of Deep Learning networks and construction of global ${\mathcal L}^2$ minimizers. (arXiv:2309.10639v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10639
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#28145;&#24230;&#23398;&#20064;&#32593;&#32476;&#32467;&#26500;&#30340;&#20960;&#20309;&#35299;&#37322;&#65292;&#24182;&#19988;&#26500;&#24314;&#20102;&#20840;&#23616;&#26368;&#23567;&#21270;&#22120;&#26063;&#65292;&#35813;&#26063;&#33021;&#22815;&#20840;&#23616;&#26368;&#23567;&#21270;&#25104;&#26412;&#20989;&#25968;&#12290;&#27492;&#22806;&#65292;&#36824;&#30830;&#23450;&#20102;&#21508;&#31181;&#36864;&#21270;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#32593;&#32476;&#32467;&#26500;&#30340;&#20960;&#20309;&#35299;&#37322;&#65292;&#35813;&#32593;&#32476;&#20855;&#26377;$L$&#20010;&#38544;&#34255;&#23618;&#65292;&#26012;&#22369;&#28608;&#27963;&#20989;&#25968;&#65292;${\mathcal L}^2$ Schatten&#31867;&#65288;&#25110;Hilbert-Schmidt&#65289;&#25104;&#26412;&#20989;&#25968;&#65292;&#20197;&#21450;&#30456;&#31561;&#32500;&#24230;$Q\geq1$&#30340;&#36755;&#20837;&#21644;&#36755;&#20986;&#31354;&#38388;${\mathbb R}^Q$&#12290;&#38544;&#34255;&#23618;&#20063;&#23450;&#20041;&#22312;${\mathbb R}^{Q}$&#30340;&#31354;&#38388;&#19978;&#12290;&#25105;&#20204;&#21033;&#29992;&#25105;&#20204;&#26368;&#26032;&#30340;&#20851;&#20110;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#32467;&#26524;&#65292;&#22312;$L\geq Q$&#30340;&#24773;&#20917;&#19979;&#26500;&#36896;&#20102;&#19968;&#20010;&#26126;&#30830;&#30340;&#26368;&#23567;&#21270;&#22120;&#26063;&#65292;&#35813;&#26063;&#33021;&#22815;&#20840;&#23616;&#26368;&#23567;&#21270;&#25104;&#26412;&#20989;&#25968;&#65292;&#24182;&#19988;&#25105;&#20204;&#35777;&#26126;&#36825;&#20010;&#26063;&#26159;&#36864;&#21270;&#30340;&#12290;&#22312;&#36825;&#37324;&#25552;&#21040;&#30340;&#19978;&#19979;&#25991;&#20013;&#65292;DL&#32593;&#32476;&#30340;&#38544;&#34255;&#23618;&#36890;&#36807;&#23545;&#35757;&#32451;&#36755;&#20837;&#30340;&#36882;&#24402;&#25130;&#26029;&#26144;&#23556;&#30340;&#24212;&#29992;&#26469;&#8220;&#25972;&#29702;&#8221;&#35757;&#32451;&#36755;&#20837;&#65292;&#20197;&#26368;&#23567;&#21270;&#22122;&#22768;&#19982;&#20449;&#21495;&#30340;&#27604;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;$2^Q-1$&#20010;&#19981;&#21516;&#30340;&#36864;&#21270;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we provide a geometric interpretation of the structure of Deep Learning (DL) networks, characterized by $L$ hidden layers, a ramp activation function, an ${\mathcal L}^2$ Schatten class (or Hilbert-Schmidt) cost function, and input and output spaces ${\mathbb R}^Q$ with equal dimension $Q\geq1$. The hidden layers are defined on spaces ${\mathbb R}^{Q}$, as well. We apply our recent results on shallow neural networks to construct an explicit family of minimizers for the global minimum of the cost function in the case $L\geq Q$, which we show to be degenerate. In the context presented here, the hidden layers of the DL network "curate" the training inputs by recursive application of a truncation map that minimizes the noise to signal ratio of the training inputs. Moreover, we determine a set of $2^Q-1$ distinct degenerate local minima of the cost function.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#25237;&#24433; Langevin &#21160;&#21147;&#23398;&#21644;&#26799;&#24230;&#27969;&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#32463;&#29109;&#27491;&#21017;&#21270;&#30340;&#20248;&#21270;&#36755;&#36816;&#20013;&#36827;&#34892;&#37319;&#26679;&#21644;&#27714;&#35299;&#12290;&#35813;&#26041;&#27861;&#22312;&#23567;&#30340;&#27491;&#21017;&#21270;&#21442;&#25968;&#19979;&#38598;&#20013;&#20110;&#26368;&#20248;&#36755;&#36816;&#32806;&#21512;&#28857;&#65292;&#24182;&#19988;&#20445;&#25345;&#22312;&#32422;&#26463;&#26465;&#20214;&#19979;&#30340;&#35299;&#12290;&#23545;&#24212;&#30340;&#38271;&#26102;&#38388;&#26497;&#38480;&#26159;&#29109;&#20248;&#21270;&#36755;&#36816;&#38382;&#39064;&#30340;&#21807;&#19968;&#35299;&#12290;</title><link>http://arxiv.org/abs/2309.08598</link><description>&lt;p&gt;
&#25237;&#24433; Langevin &#21160;&#21147;&#23398;&#21644;&#26799;&#24230;&#27969;&#30340;&#29109;&#20248;&#21270;&#36755;&#36816;
&lt;/p&gt;
&lt;p&gt;
Projected Langevin dynamics and a gradient flow for entropic optimal transport. (arXiv:2309.08598v1 [math.PR] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08598
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#25237;&#24433; Langevin &#21160;&#21147;&#23398;&#21644;&#26799;&#24230;&#27969;&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#32463;&#29109;&#27491;&#21017;&#21270;&#30340;&#20248;&#21270;&#36755;&#36816;&#20013;&#36827;&#34892;&#37319;&#26679;&#21644;&#27714;&#35299;&#12290;&#35813;&#26041;&#27861;&#22312;&#23567;&#30340;&#27491;&#21017;&#21270;&#21442;&#25968;&#19979;&#38598;&#20013;&#20110;&#26368;&#20248;&#36755;&#36816;&#32806;&#21512;&#28857;&#65292;&#24182;&#19988;&#20445;&#25345;&#22312;&#32422;&#26463;&#26465;&#20214;&#19979;&#30340;&#35299;&#12290;&#23545;&#24212;&#30340;&#38271;&#26102;&#38388;&#26497;&#38480;&#26159;&#29109;&#20248;&#21270;&#36755;&#36816;&#38382;&#39064;&#30340;&#21807;&#19968;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32463;&#20856;&#30340;&#65288;&#36807;&#38459;&#23612;&#30340;&#65289; Langevin &#21160;&#21147;&#23398;&#20026;&#20174;&#20854;&#19981;&#21464;&#27979;&#24230;&#20013;&#37319;&#26679;&#25552;&#20379;&#20102;&#19968;&#31181;&#33258;&#28982;&#30340;&#31639;&#27861;&#65292;&#35813;&#27979;&#24230;&#22312;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#19978;&#21807;&#19968;&#26368;&#23567;&#21270;&#19968;&#20010;&#33021;&#37327;&#27867;&#20989;&#65292;&#24182;&#19988;&#22312;&#22122;&#22768;&#21442;&#25968;&#24456;&#23567;&#26102;&#38598;&#20013;&#20110;&#30456;&#20851;&#21183;&#33021;&#30340;&#26497;&#23567;&#20540;&#28857;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#31867;&#20284;&#30340;&#25193;&#25955;&#21160;&#21147;&#23398;&#65292;&#20174;&#32463;&#29109;&#27491;&#21017;&#21270;&#30340;&#20248;&#21270;&#36755;&#36816;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#22312;&#20004;&#20010;&#32473;&#23450;&#36793;&#32536;&#27010;&#29575;&#27979;&#24230; $\mu$ &#21644; $\nu$ &#19978;&#32422;&#26463;&#19979;&#21807;&#19968;&#26368;&#23567;&#21270;&#30456;&#21516;&#30340;&#33021;&#37327;&#27867;&#20989;&#65292;&#24182;&#22312;&#23567;&#30340;&#27491;&#21017;&#21270;&#21442;&#25968;&#19979;&#38598;&#20013;&#20110;&#26368;&#20248;&#36755;&#36816;&#32806;&#21512;&#28857;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#36807;&#31243;&#28385;&#36275;&#20004;&#20010;&#20851;&#38190;&#24615;&#36136;&#65306;&#39318;&#20808;&#65292;&#22914;&#26524;&#22312;&#20854;&#19978;&#21021;&#22987;&#21270;&#65292;&#35299;&#22312;&#27599;&#20010;&#26102;&#38388;&#28857;&#30340;&#20998;&#24067;&#37117;&#20445;&#25345;&#22312; $\Pi(\mu,\nu)$ &#20013;&#12290;&#20854;&#27425;&#65292;&#38271;&#26102;&#38388;&#26497;&#38480;&#26159;&#19968;&#20010;&#29109;&#20248;&#21270;&#36755;&#36816;&#38382;&#39064;&#30340;&#21807;&#19968;&#35299;&#12290;&#21478;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#26032;&#30340; log-Sobolev &#31867;&#22411;&#30340;&#32467;&#26524;&#35777;&#26126;...
&lt;/p&gt;
&lt;p&gt;
The classical (overdamped) Langevin dynamics provide a natural algorithm for sampling from its invariant measure, which uniquely minimizes an energy functional over the space of probability measures, and which concentrates around the minimizer(s) of the associated potential when the noise parameter is small. We introduce analogous diffusion dynamics that sample from an entropy-regularized optimal transport, which uniquely minimizes the same energy functional but constrained to the set $\Pi(\mu,\nu)$ of couplings of two given marginal probability measures $\mu$ and $\nu$ on $\mathbb{R}^d$, and which concentrates around the optimal transport coupling(s) for small regularization parameter. More specifically, our process satisfies two key properties: First, the law of the solution at each time stays in $\Pi(\mu,\nu)$ if it is initialized there. Second, the long-time limit is the unique solution of an entropic optimal transport problem. In addition, we show by means of a new log-Sobolev-typ
&lt;/p&gt;</description></item><item><title>TML&#36719;&#20214;&#21253;&#26159;&#31532;&#19968;&#20010;&#21253;&#21547;&#19968;&#22871;&#20840;&#38754;&#24037;&#20855;&#21644;&#26041;&#27861;&#30340;R&#36719;&#20214;&#21253;&#65292;&#29992;&#20110;&#22788;&#29702;&#19982;&#28909;&#24102;&#20984;&#24615;&#30456;&#20851;&#30340;&#22522;&#26412;&#35745;&#31639;&#21644;&#21487;&#35270;&#21270;&#65292;&#20197;&#21450;&#20351;&#29992;&#28909;&#24102;&#24230;&#37327;&#36827;&#34892;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#30340;&#32479;&#35745;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2309.01082</link><description>&lt;p&gt;
&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#28909;&#24102;&#20960;&#20309;&#24037;&#20855;&#65306;TML&#36719;&#20214;&#21253;
&lt;/p&gt;
&lt;p&gt;
Tropical Geometric Tools for Machine Learning: the TML package. (arXiv:2309.01082v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01082
&lt;/p&gt;
&lt;p&gt;
TML&#36719;&#20214;&#21253;&#26159;&#31532;&#19968;&#20010;&#21253;&#21547;&#19968;&#22871;&#20840;&#38754;&#24037;&#20855;&#21644;&#26041;&#27861;&#30340;R&#36719;&#20214;&#21253;&#65292;&#29992;&#20110;&#22788;&#29702;&#19982;&#28909;&#24102;&#20984;&#24615;&#30456;&#20851;&#30340;&#22522;&#26412;&#35745;&#31639;&#21644;&#21487;&#35270;&#21270;&#65292;&#20197;&#21450;&#20351;&#29992;&#28909;&#24102;&#24230;&#37327;&#36827;&#34892;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#30340;&#32479;&#35745;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#20013;&#65292;&#28909;&#24102;&#20960;&#20309;&#23398;&#30340;&#21457;&#23637;&#25552;&#20379;&#20102;&#35768;&#22810;&#30452;&#25509;&#24212;&#29992;&#20110;&#32479;&#35745;&#23398;&#20064;&#38382;&#39064;&#30340;&#24037;&#20855;&#12290;TML&#36719;&#20214;&#21253;&#26159;&#31532;&#19968;&#20010;&#21253;&#21547;&#19968;&#22871;&#20840;&#38754;&#30340;&#24037;&#20855;&#21644;&#26041;&#27861;&#30340;R&#36719;&#20214;&#21253;&#65292;&#29992;&#20110;&#22788;&#29702;&#19982;&#28909;&#24102;&#20984;&#24615;&#30456;&#20851;&#30340;&#22522;&#26412;&#35745;&#31639;&#12289;&#28909;&#24102;&#20984;&#38598;&#30340;&#21487;&#35270;&#21270;&#65292;&#20197;&#21450;&#20351;&#29992;&#28909;&#24102;&#24230;&#37327;&#21644;&#28909;&#24102;&#25237;&#24433;&#29615;&#19978;&#30340;max-plus&#20195;&#25968;&#36827;&#34892;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#12290;&#20027;&#35201;&#30340;&#65292;TML&#36719;&#20214;&#21253;&#20351;&#29992;Hit and Run Markov chain Monte Carlo&#37319;&#26679;&#22120;&#19982;&#28909;&#24102;&#24230;&#37327;&#20316;&#20026;&#32479;&#35745;&#25512;&#26029;&#30340;&#20027;&#35201;&#24037;&#20855;&#12290;&#38500;&#20102;&#22522;&#26412;&#35745;&#31639;&#21644;&#28909;&#24102;HAR&#37319;&#26679;&#22120;&#30340;&#21508;&#31181;&#24212;&#29992;&#20043;&#22806;&#65292;&#25105;&#20204;&#36824;&#20851;&#27880;TML&#36719;&#20214;&#21253;&#20013;&#21253;&#21547;&#30340;&#20960;&#31181;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#26041;&#27861;&#65292;&#21253;&#25324;&#28909;&#24102;&#20027;&#25104;&#20998;&#20998;&#26512;&#12289;&#28909;&#24102;&#36923;&#36753;&#22238;&#24402;&#21644;&#28909;&#24102;&#26680;&#23494;&#24230;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the last decade, developments in tropical geometry have provided a number of uses directly applicable to problems in statistical learning. The TML package is the first R package which contains a comprehensive set of tools and methods used for basic computations related to tropical convexity, visualization of tropically convex sets, as well as supervised and unsupervised learning models using the tropical metric under the max-plus algebra over the tropical projective torus. Primarily, the TML package employs a Hit and Run Markov chain Monte Carlo sampler in conjunction with the tropical metric as its main tool for statistical inference. In addition to basic computation and various applications of the tropical HAR sampler, we also focus on several supervised and unsupervised methods incorporated in the TML package including tropical principal component analysis, tropical logistic regression and tropical kernel density estimation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26410;&#35265;&#29366;&#24577;&#22686;&#24378;&#30340;&#31574;&#30053;&#65292;&#22312;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#36890;&#36807;&#22522;&#20110;&#20215;&#20540;&#30340;&#25200;&#21160;&#21644;&#36807;&#28388;&#65292;&#23454;&#29616;&#20102;&#23545;&#31163;&#32447;&#25968;&#25454;&#20043;&#22806;&#30340;&#29366;&#24577;&#30340;&#21033;&#29992;&#21644;&#27867;&#21270;&#12290;</title><link>http://arxiv.org/abs/2308.03882</link><description>&lt;p&gt;
&#36890;&#36807;&#26410;&#35265;&#36807;&#30340;&#29366;&#24577;&#22686;&#24378;&#21033;&#29992;&#24191;&#20041;&#21270;&#22312;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;
&lt;/p&gt;
&lt;p&gt;
Exploiting Generalization in Offline Reinforcement Learning via Unseen State Augmentations. (arXiv:2308.03882v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03882
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26410;&#35265;&#29366;&#24577;&#22686;&#24378;&#30340;&#31574;&#30053;&#65292;&#22312;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#36890;&#36807;&#22522;&#20110;&#20215;&#20540;&#30340;&#25200;&#21160;&#21644;&#36807;&#28388;&#65292;&#23454;&#29616;&#20102;&#23545;&#31163;&#32447;&#25968;&#25454;&#20043;&#22806;&#30340;&#29366;&#24577;&#30340;&#21033;&#29992;&#21644;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#36890;&#36807;&#23545;&#26410;&#35265;&#36807;&#30340;&#29366;&#24577;&#21644;&#21160;&#20316;&#36827;&#34892;&#20445;&#23432;&#20215;&#20540;&#35780;&#20272;&#26469;&#24179;&#34913;&#25506;&#32034;&#21644;&#21033;&#29992;&#12290;&#26080;&#27169;&#22411;&#26041;&#27861;&#20250;&#23545;&#25152;&#26377;&#26410;&#35265;&#36807;&#30340;&#21160;&#20316;&#36827;&#34892;&#24809;&#32602;&#65292;&#32780;&#26377;&#27169;&#22411;&#26041;&#27861;&#21487;&#20197;&#36827;&#19968;&#27493;&#36890;&#36807;&#27169;&#22411;&#23637;&#24320;&#23545;&#26410;&#35265;&#36807;&#30340;&#29366;&#24577;&#36827;&#34892;&#21033;&#29992;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20004;&#20010;&#22240;&#32032;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#25214;&#21040;&#31163;&#32447;&#25968;&#25454;&#20043;&#22806;&#30340;&#26410;&#35265;&#36807;&#30340;&#29366;&#24577;&#26102;&#23384;&#22312;&#22256;&#38590;&#65306;(a)&#30001;&#20110;&#32423;&#32852;&#27169;&#22411;&#35823;&#24046;&#65292;&#27169;&#22411;&#30340;&#23637;&#24320;&#33539;&#22260;&#38750;&#24120;&#30701;&#65292;(b)&#27169;&#22411;&#23637;&#24320;&#20165;&#20197;&#31163;&#32447;&#25968;&#25454;&#20013;&#35266;&#23519;&#21040;&#30340;&#29366;&#24577;&#20026;&#36215;&#28857;&#12290;&#25105;&#20204;&#25918;&#23485;&#20102;&#31532;&#20108;&#20010;&#20551;&#35774;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26410;&#35265;&#36807;&#29366;&#24577;&#22686;&#24378;&#31574;&#30053;&#65292;&#20197;&#20801;&#35768;&#23398;&#24471;&#30340;&#27169;&#22411;&#21644;&#20215;&#20540;&#20272;&#35745;&#22312;&#26410;&#35265;&#29366;&#24577;&#20013;&#27867;&#21270;&#12290;&#25105;&#20204;&#30340;&#31574;&#30053;&#36890;&#36807;&#23545;&#35266;&#23519;&#21040;&#30340;&#29366;&#24577;&#36827;&#34892;&#22522;&#20110;&#20215;&#20540;&#30340;&#25200;&#21160;&#26469;&#25214;&#21040;&#26410;&#35265;&#36807;&#30340;&#29366;&#24577;&#65292;&#28982;&#21518;&#36890;&#36807;&#36807;&#28388;&#20855;&#26377;&#36807;&#39640;&#30340;&#21551;&#21457;&#24615;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65288;&#39640;&#35823;&#24046;&#65289;&#25110;&#36807;&#20302;&#30340;&#65288;&#36807;&#20110;&#30456;&#20284;&#65289;
&lt;/p&gt;
&lt;p&gt;
Offline reinforcement learning (RL) methods strike a balance between exploration and exploitation by conservative value estimation -- penalizing values of unseen states and actions. Model-free methods penalize values at all unseen actions, while model-based methods are able to further exploit unseen states via model rollouts. However, such methods are handicapped in their ability to find unseen states far away from the available offline data due to two factors -- (a) very short rollout horizons in models due to cascading model errors, and (b) model rollouts originating solely from states observed in offline data. We relax the second assumption and present a novel unseen state augmentation strategy to allow exploitation of unseen states where the learned model and value estimates generalize. Our strategy finds unseen states by value-informed perturbations of seen states followed by filtering out states with epistemic uncertainty estimates too high (high error) or too low (too similar to
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#30740;&#31350;&#20102;&#22312;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#20013;&#27169;&#20223;&#22797;&#26434;&#19987;&#23478;&#28436;&#31034;&#30340;&#34892;&#20026;&#12290;&#36890;&#36807;&#31283;&#23450;&#27169;&#20223;&#31574;&#30053;&#24182;&#30830;&#20445;&#20934;&#30830;&#20272;&#35745;&#28436;&#31034;&#32773;&#20998;&#24067;&#65292;&#21487;&#20197;&#20351;&#27169;&#20223;&#32773;&#19982;&#28436;&#31034;&#32773;&#30340;&#36712;&#36857;&#20998;&#24067;&#30456;&#36817;&#12290;</title><link>http://arxiv.org/abs/2307.14619</link><description>&lt;p&gt;
&#27169;&#20223;&#22797;&#26434;&#36712;&#36857;&#65306;&#26725;&#25509;&#20302;&#23618;&#31283;&#23450;&#24615;&#19982;&#39640;&#23618;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Imitating Complex Trajectories: Bridging Low-Level Stability and High-Level Behavior. (arXiv:2307.14619v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14619
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#30740;&#31350;&#20102;&#22312;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#20013;&#27169;&#20223;&#22797;&#26434;&#19987;&#23478;&#28436;&#31034;&#30340;&#34892;&#20026;&#12290;&#36890;&#36807;&#31283;&#23450;&#27169;&#20223;&#31574;&#30053;&#24182;&#30830;&#20445;&#20934;&#30830;&#20272;&#35745;&#28436;&#31034;&#32773;&#20998;&#24067;&#65292;&#21487;&#20197;&#20351;&#27169;&#20223;&#32773;&#19982;&#28436;&#31034;&#32773;&#30340;&#36712;&#36857;&#20998;&#24067;&#30456;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#30740;&#31350;&#22312;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#20013;&#27169;&#20223;&#38543;&#26426;&#12289;&#38750;&#39532;&#23572;&#21487;&#22827;&#12289;&#28508;&#22312;&#22810;&#27169;&#24577;&#65288;&#21363;&#8220;&#22797;&#26434;&#8221;&#65289;&#19987;&#23478;&#28436;&#31034;&#30340;&#34892;&#20026;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#20351;&#29992;&#20302;&#23618;&#25511;&#21046;&#22120;&#65288;&#26080;&#35770;&#26159;&#23398;&#20064;&#30340;&#36824;&#26159;&#38544;&#21547;&#30340;&#65289;&#26469;&#31283;&#23450;&#22260;&#32469;&#19987;&#23478;&#28436;&#31034;&#30340;&#27169;&#20223;&#31574;&#30053;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#65288;a&#65289;&#21512;&#36866;&#30340;&#20302;&#23618;&#31283;&#23450;&#24615;&#20445;&#35777;&#21644;&#65288;b&#65289;&#23398;&#20064;&#31574;&#30053;&#30340;&#38543;&#26426;&#36830;&#32493;&#24615;&#23646;&#24615;&#65288;&#25105;&#20204;&#31216;&#20043;&#20026;&#8220;&#24635;&#21464;&#24046;&#36830;&#32493;&#24615;&#8221;&#65289;&#65288;TVC&#65289;&#30340;&#24773;&#20917;&#19979;&#65292;&#19968;&#20010;&#31934;&#30830;&#20272;&#35745;&#28436;&#31034;&#32773;&#29366;&#24577;&#20998;&#24067;&#19978;&#30340;&#34892;&#21160;&#30340;&#27169;&#20223;&#32773;&#20250;&#19982;&#28436;&#31034;&#32773;&#23545;&#25972;&#20010;&#36712;&#36857;&#30340;&#20998;&#24067;&#30456;&#36817;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#21487;&#20197;&#36890;&#36807;&#23558;&#27969;&#34892;&#30340;&#25968;&#25454;&#22686;&#24378;&#35268;&#21017;&#19982;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#25216;&#24039;&#30456;&#32467;&#21512;&#65288;&#21363;&#22312;&#25191;&#34892;&#26102;&#28155;&#21152;&#22686;&#24378;&#22122;&#22768;&#65289;&#26469;&#30830;&#20445;TVC&#24182;&#19988;&#26368;&#23567;&#31243;&#24230;&#19978;&#38477;&#20302;&#31934;&#24230;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#20445;&#35777;&#23454;&#20363;&#21270;&#20026;&#30001;&#25193;&#25955;&#27169;&#22411;&#21442;&#25968;&#21270;&#30340;&#31574;&#30053;&#65292;&#24182;&#35777;&#26126;&#22914;&#26524;&#23398;&#20064;&#32773;&#20934;&#30830;&#22320;&#20272;&#35745;&#20102;&#28436;&#31034;&#32773;&#30340;&#20998;&#24067;&#65292;&#21017;&#26368;&#32456;&#23436;&#25104;&#36825;&#31181;&#23454;&#20363;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a theoretical framework for studying the imitation of stochastic, non-Markovian, potentially multi-modal (i.e. "complex" ) expert demonstrations in nonlinear dynamical systems. Our framework invokes low-level controllers either learned or implicit in position-command control - to stabilize imitation policies around expert demonstrations. We show that with (a) a suitable low-level stability guarantee and (b) a stochastic continuity property of the learned policy we call "total variation continuity" (TVC), an imitator that accurately estimates actions on the demonstrator's state distribution closely matches the demonstrator's distribution over entire trajectories. We then show that TVC can be ensured with minimal degradation of accuracy by combining a popular data-augmentation regimen with a novel algorithmic trick: adding augmentation noise at execution time. We instantiate our guarantees for policies parameterized by diffusion models and prove that if the learner accuratel
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#27169;&#25311;&#21453;&#20107;&#23454;&#20998;&#24067;&#20013;&#30340;&#20540;&#65292;&#21487;&#23545;&#31163;&#25955;&#21644;&#36830;&#32493;&#21464;&#37327;&#35774;&#23450;&#26465;&#20214;&#65292;&#24182;&#24212;&#29992;&#20110;&#20449;&#29992;&#35780;&#20998;&#20013;&#30340;&#20844;&#24179;&#24615;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2306.15328</link><description>&lt;p&gt;
&#27169;&#25311;&#21453;&#20107;&#23454;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
Simulating counterfactuals. (arXiv:2306.15328v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15328
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#27169;&#25311;&#21453;&#20107;&#23454;&#20998;&#24067;&#20013;&#30340;&#20540;&#65292;&#21487;&#23545;&#31163;&#25955;&#21644;&#36830;&#32493;&#21464;&#37327;&#35774;&#23450;&#26465;&#20214;&#65292;&#24182;&#24212;&#29992;&#20110;&#20449;&#29992;&#35780;&#20998;&#20013;&#30340;&#20844;&#24179;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#25512;&#26029;&#32771;&#34385;&#20102;&#22312;&#19982;&#23454;&#38469;&#19990;&#30028;&#23384;&#22312;&#19968;&#20123;&#35777;&#25454;&#30340;&#24179;&#34892;&#19990;&#30028;&#20013;&#36827;&#34892;&#30340;&#20551;&#35774;&#24615;&#24178;&#39044;&#12290;&#22914;&#26524;&#35777;&#25454;&#22312;&#27969;&#24418;&#19978;&#25351;&#23450;&#20102;&#26465;&#20214;&#20998;&#24067;&#65292;&#21453;&#20107;&#23454;&#21487;&#33021;&#26159;&#35299;&#26512;&#38590;&#35299;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#21453;&#20107;&#23454;&#20998;&#24067;&#20013;&#27169;&#25311;&#20540;&#65292;&#20854;&#20013;&#21487;&#20197;&#23545;&#31163;&#25955;&#21644;&#36830;&#32493;&#21464;&#37327;&#35774;&#23450;&#26465;&#20214;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#21487;&#20197;&#34987;&#21576;&#29616;&#20026;&#31890;&#23376;&#28388;&#27874;&#22120;&#65292;&#20174;&#32780;&#23548;&#33268;&#28176;&#36817;&#26377;&#25928;&#30340;&#25512;&#26029;&#12290;&#35813;&#31639;&#27861;&#34987;&#24212;&#29992;&#20110;&#20449;&#29992;&#35780;&#20998;&#20013;&#30340;&#20844;&#24179;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactual inference considers a hypothetical intervention in a parallel world that shares some evidence with the factual world. If the evidence specifies a conditional distribution on a manifold, counterfactuals may be analytically intractable. We present an algorithm for simulating values from a counterfactual distribution where conditions can be set on both discrete and continuous variables. We show that the proposed algorithm can be presented as a particle filter leading to asymptotically valid inference. The algorithm is applied to fairness analysis in credit scoring.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23567;&#25439;&#22833;&#36793;&#30028;&#30340;&#35270;&#35282;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20998;&#24067;&#24335;RL&#22909;&#22788;&#30340;&#19968;&#20010;&#35299;&#37322;&#65292;&#35813;&#36793;&#30028;&#19982;&#23454;&#20363;&#30456;&#20851;&#30340;&#26368;&#20248;&#25104;&#26412;&#25104;&#27604;&#20363;&#12290;&#22914;&#26524;&#26368;&#20248;&#25104;&#26412;&#24456;&#23567;&#65292;&#20998;&#24067;&#24335;&#26041;&#27861;&#20248;&#20110;&#38750;&#20998;&#24067;&#24335;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.15703</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#30340;&#22909;&#22788;&#65306;&#23567;&#25439;&#22833;&#36793;&#30028;
&lt;/p&gt;
&lt;p&gt;
The Benefits of Being Distributional: Small-Loss Bounds for Reinforcement Learning. (arXiv:2305.15703v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15703
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23567;&#25439;&#22833;&#36793;&#30028;&#30340;&#35270;&#35282;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20998;&#24067;&#24335;RL&#22909;&#22788;&#30340;&#19968;&#20010;&#35299;&#37322;&#65292;&#35813;&#36793;&#30028;&#19982;&#23454;&#20363;&#30456;&#20851;&#30340;&#26368;&#20248;&#25104;&#26412;&#25104;&#27604;&#20363;&#12290;&#22914;&#26524;&#26368;&#20248;&#25104;&#26412;&#24456;&#23567;&#65292;&#20998;&#24067;&#24335;&#26041;&#27861;&#20248;&#20110;&#38750;&#20998;&#24067;&#24335;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#24050;&#32463;&#21462;&#24471;&#20102;&#23454;&#35777;&#25104;&#26524;&#65292;&#20294;&#20854;&#20309;&#26102;&#20309;&#22320;&#26377;&#30410;&#30340;&#38382;&#39064;&#23578;&#26410;&#24471;&#21040;&#22238;&#31572;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#36890;&#36807;&#23567;&#25439;&#22833;&#36793;&#30028;&#30340;&#35270;&#35282;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20998;&#24067;&#24335;RL&#22909;&#22788;&#30340;&#19968;&#20010;&#35299;&#37322;&#65292;&#35813;&#36793;&#30028;&#19982;&#23454;&#20363;&#30456;&#20851;&#30340;&#26368;&#20248;&#25104;&#26412;&#25104;&#27604;&#20363;&#12290;&#22914;&#26524;&#26368;&#20248;&#25104;&#26412;&#24456;&#23567;&#65292;&#25105;&#20204;&#30340;&#36793;&#30028;&#20250;&#27604;&#38750;&#20998;&#24067;&#24335;&#26041;&#27861;&#26356;&#24378;&#12290;&#20316;&#20026;&#28909;&#36523;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23398;&#20064;&#25104;&#26412;&#20998;&#24067;&#20250;&#22312;&#24773;&#22659;&#23637;&#24320;&#65288;CB&#65289;&#20013;&#23548;&#33268;&#23567;&#25439;&#22833;&#21518;&#24724;&#36793;&#30028;&#65292;&#25105;&#20204;&#21457;&#29616;&#20998;&#24067;&#24335;CB&#22312;&#19977;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#19978;&#27604;&#26368;&#20808;&#36827;&#30340;&#25216;&#26415;&#22312;&#23454;&#35777;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;&#23545;&#20110;&#22312;&#32447;RL&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#24067;&#24335;&#29256;&#26412;&#31354;&#38388;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20351;&#29992;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#22312;&#34920;&#26684;MDP&#20013;&#23454;&#29616;&#20102;&#23567;&#25439;&#22833;&#21518;&#24724;&#65292;&#21516;&#26102;&#22312;&#28508;&#21464;&#37327;&#27169;&#22411;&#20013;&#20139;&#26377;&#23567;&#25439;&#22833;PAC&#36793;&#30028;&#12290;&#20197;&#31867;&#20284;&#30340;&#35265;&#35299;&#20026;&#22522;&#30784;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#24067;&#24335;&#31163;&#32447;RL&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
While distributional reinforcement learning (RL) has demonstrated empirical success, the question of when and why it is beneficial has remained unanswered. In this work, we provide one explanation for the benefits of distributional RL through the lens of small-loss bounds, which scale with the instance-dependent optimal cost. If the optimal cost is small, our bounds are stronger than those from non-distributional approaches. As warmup, we show that learning the cost distribution leads to small-loss regret bounds in contextual bandits (CB), and we find that distributional CB empirically outperforms the state-of-the-art on three challenging tasks. For online RL, we propose a distributional version-space algorithm that constructs confidence sets using maximum likelihood estimation, and we prove that it achieves small-loss regret in the tabular MDPs and enjoys small-loss PAC bounds in latent variable models. Building on similar insights, we propose a distributional offline RL algorithm bas
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#65288;BBVI&#65289;&#30340;&#20998;&#26512;&#65292;&#21457;&#29616;&#19968;&#20123;&#24120;&#35265;&#30340;&#31639;&#27861;&#35774;&#35745;&#36873;&#25321;&#21487;&#33021;&#20250;&#23548;&#33268;&#27425;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#20294;&#20351;&#29992;&#24102;&#26377;&#36817;&#31471;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;BBVI&#21487;&#20197;&#23454;&#29616;&#26368;&#24378;&#25910;&#25947;&#29575;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.15349</link><description>&lt;p&gt;
&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#25910;&#25947;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Black-Box Variational Inference Converges. (arXiv:2305.15349v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15349
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#65288;BBVI&#65289;&#30340;&#20998;&#26512;&#65292;&#21457;&#29616;&#19968;&#20123;&#24120;&#35265;&#30340;&#31639;&#27861;&#35774;&#35745;&#36873;&#25321;&#21487;&#33021;&#20250;&#23548;&#33268;&#27425;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#20294;&#20351;&#29992;&#24102;&#26377;&#36817;&#31471;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;BBVI&#21487;&#20197;&#23454;&#29616;&#26368;&#24378;&#25910;&#25947;&#29575;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#23436;&#25972;&#30340;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#65288;BBVI&#65289;&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#20063;&#31216;&#20026;&#33945;&#29305;&#21345;&#32599;&#21464;&#20998;&#25512;&#26029;&#12290;&#23613;&#31649;&#26089;&#26399;&#30340;&#30740;&#31350;&#21482;&#38024;&#23545;&#31616;&#21270;&#29256;&#26412;&#30340;BBVI&#36827;&#34892;&#20102;&#30740;&#31350;&#65288;&#20363;&#22914;&#65292;&#26377;&#30028;&#22495;&#12289;&#26377;&#30028;&#25903;&#25345;&#12289;&#20165;&#38024;&#23545;&#23610;&#24230;&#36827;&#34892;&#20248;&#21270;&#31561;&#65289;&#65292;&#20294;&#25105;&#20204;&#30340;&#35774;&#32622;&#19981;&#38656;&#35201;&#20219;&#20309;&#36825;&#26679;&#30340;&#31639;&#27861;&#20462;&#25913;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#23545;&#25968;&#24179;&#28369;&#21518;&#39564;&#23494;&#24230;&#65292;&#26080;&#35770;&#26159;&#21542;&#24378;&#23545;&#25968;&#20985;&#24615;&#20197;&#21450;&#20301;&#32622;-&#23610;&#24230;&#21464;&#20998;&#26063;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20986;&#20102;&#19968;&#20123;&#24120;&#35265;&#30340;&#31639;&#27861;&#35774;&#35745;&#36873;&#25321;&#65292;&#29305;&#21035;&#26159;&#21464;&#20998;&#36817;&#20284;&#23610;&#24230;&#30340;&#38750;&#32447;&#24615;&#21442;&#25968;&#21270;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#27425;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;&#24184;&#36816;&#30340;&#26159;&#65292;&#36816;&#34892;&#24102;&#26377;&#36817;&#31471;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;BBVI&#21487;&#20197;&#32416;&#27491;&#36825;&#20123;&#38480;&#21046;&#65292;&#20174;&#32780;&#23454;&#29616;&#24050;&#30693;&#30340;&#26368;&#24378;&#25910;&#25947;&#29575;&#20445;&#35777;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#36817;&#31471;SGD&#19982;&#20854;&#20182;&#26631;&#20934;&#30340;BBVI&#23454;&#29616;&#36827;&#34892;&#27604;&#36739;&#65292;&#39564;&#35777;&#20102;&#36825;&#19968;&#29702;&#35770;&#32467;&#35770;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide the first convergence guarantee for full black-box variational inference (BBVI), also known as Monte Carlo variational inference. While preliminary investigations worked on simplified versions of BBVI (e.g., bounded domain, bounded support, only optimizing for the scale, and such), our setup does not need any such algorithmic modifications. Our results hold for log-smooth posterior densities with and without strong log-concavity and the location-scale variational family. Also, our analysis reveals that certain algorithm design choices commonly employed in practice, particularly, nonlinear parameterizations of the scale of the variational approximation, can result in suboptimal convergence rates. Fortunately, running BBVI with proximal stochastic gradient descent fixes these limitations, and thus achieves the strongest known convergence rate guarantees. We evaluate this theoretical insight by comparing proximal SGD against other standard implementations of BBVI on large-scale
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#26465;&#20214;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65292;&#26681;&#25454;cGAN&#30340;&#21028;&#21035;&#22120;&#25968;&#25454;&#35782;&#21035;&#20986;&#26368;&#25509;&#36817;&#30446;&#26631;&#30340;&#29616;&#26377;&#27169;&#24335;&#65292;&#24182;&#36890;&#36807;&#25193;&#23637;&#36830;&#32493;&#23398;&#20064;&#27169;&#22411;&#65292;&#20351;&#29992;&#22238;&#25918;&#29983;&#25104;&#30340;&#25968;&#25454;&#26469;&#35757;&#32451;&#30446;&#26631;&#27169;&#24335;&#30340;cGAN&#27169;&#22411;&#65292;&#20197;&#36991;&#20813;&#28798;&#38590;&#24615;&#36951;&#24536;&#65292;&#25552;&#39640;&#20102;&#29983;&#25104;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.11400</link><description>&lt;p&gt;
&#38754;&#21521;&#26377;&#26465;&#20214;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#23569;&#26679;&#26412;&#36830;&#32493;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Few-Shot Continual Learning for Conditional Generative Adversarial Networks. (arXiv:2305.11400v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11400
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#26465;&#20214;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65292;&#26681;&#25454;cGAN&#30340;&#21028;&#21035;&#22120;&#25968;&#25454;&#35782;&#21035;&#20986;&#26368;&#25509;&#36817;&#30446;&#26631;&#30340;&#29616;&#26377;&#27169;&#24335;&#65292;&#24182;&#36890;&#36807;&#25193;&#23637;&#36830;&#32493;&#23398;&#20064;&#27169;&#22411;&#65292;&#20351;&#29992;&#22238;&#25918;&#29983;&#25104;&#30340;&#25968;&#25454;&#26469;&#35757;&#32451;&#30446;&#26631;&#27169;&#24335;&#30340;cGAN&#27169;&#22411;&#65292;&#20197;&#36991;&#20813;&#28798;&#38590;&#24615;&#36951;&#24536;&#65292;&#25552;&#39640;&#20102;&#29983;&#25104;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29983;&#25104;&#27169;&#22411;&#30340;&#23569;&#26679;&#26412;&#36830;&#32493;&#23398;&#20064;&#20013;&#65292;&#24517;&#39035;&#23398;&#20064;&#30446;&#26631;&#27169;&#24335;&#65292;&#24182;&#22312;&#19981;&#24433;&#21709;&#20808;&#21069;&#23398;&#20064;&#21040;&#30340;&#27169;&#24335;&#30340;&#24773;&#20917;&#19979;&#20165;&#20351;&#29992;&#26377;&#38480;&#30340;&#26679;&#26412;&#12290;&#26412;&#25991;&#38024;&#23545;&#26465;&#20214;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#65292;&#22522;&#20110;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#29983;&#25104;&#24314;&#27169;&#30340;&#27169;&#24335;&#20146;&#21644;&#21147;&#37327;&#24230;&#12290;&#25105;&#20204;&#30340;&#24230;&#37327;&#23436;&#20840;&#22522;&#20110;cGAN&#30340;&#21028;&#21035;&#22120;&#65292;&#21487;&#20197;&#35782;&#21035;&#26368;&#25509;&#36817;&#30446;&#26631;&#30340;&#29616;&#26377;&#27169;&#24335;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#21253;&#21547;&#22522;&#20110;&#26368;&#25509;&#36817;&#27169;&#24335;&#30340;&#21152;&#26435;&#26631;&#31614;&#26469;&#25193;&#23637;&#36830;&#32493;&#23398;&#20064;&#27169;&#22411;&#12290;&#20026;&#20102;&#39044;&#38450;&#28798;&#38590;&#24615;&#36951;&#24536;&#65292;&#25105;&#20204;&#39318;&#20808;&#20351;&#29992;cGAN&#30340;&#29983;&#25104;&#22120;&#29983;&#25104;&#24102;&#26631;&#31614;&#30340;&#25968;&#25454;&#26679;&#26412;&#65292;&#28982;&#21518;&#36890;&#36807;&#22238;&#25918;&#29983;&#25104;&#30340;&#25968;&#25454;&#26469;&#35757;&#32451;&#30446;&#26631;&#27169;&#24335;&#30340;cGAN&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25552;&#39640;&#29983;&#25104;&#24615;&#33021;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#36229;&#36234;&#20102;&#21508;&#31181;&#26631;&#20934;&#21644;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In few-shot continual learning for generative models, a target mode must be learned with limited samples without adversely affecting the previously learned modes. In this paper, we propose a new continual learning approach for conditional generative adversarial networks (cGAN) based on a new mode-affinity measure for generative modeling. Our measure is entirely based on the cGAN's discriminator and can identify the existing modes that are most similar to the target. Subsequently, we expand the continual learning model by including the target mode using a weighted label derived from those of the closest modes. To prevent catastrophic forgetting, we first generate labeled data samples using the cGAN's generator, and then train the cGAN model for the target mode while memory replaying with the generated data. Our experimental results demonstrate the efficacy of our approach in improving the generation performance over the baselines and the state-of-the-art approaches for various standard 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#22343;&#22330;&#25511;&#21046;(MFC)&#21644;&#22343;&#22330;&#21338;&#24328;(MFG)&#20013;&#30340;&#24378;&#21270;&#23398;&#20064;&#30340;&#32479;&#35745;&#25928;&#29575;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#20048;&#35266;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#31639;&#27861;&#65292;&#24182;&#20165;&#23545;&#36716;&#31227;&#21160;&#21147;&#23398;&#20855;&#26377;Lipschitz&#36830;&#32493;&#24615;&#30340;&#20551;&#35774;&#65292;&#26368;&#21518;&#24314;&#31435;&#20102;&#19968;&#20010;&#25351;&#25968;&#32423;&#30340;&#19979;&#30028;&#25903;&#25345;MFC&#35774;&#32622;&#12290;</title><link>http://arxiv.org/abs/2305.11283</link><description>&lt;p&gt;
&#20851;&#20110;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#22343;&#22330;&#24378;&#21270;&#23398;&#20064;&#30340;&#32479;&#35745;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
On the Statistical Efficiency of Mean Field Reinforcement Learning with General Function Approximation. (arXiv:2305.11283v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11283
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#22343;&#22330;&#25511;&#21046;(MFC)&#21644;&#22343;&#22330;&#21338;&#24328;(MFG)&#20013;&#30340;&#24378;&#21270;&#23398;&#20064;&#30340;&#32479;&#35745;&#25928;&#29575;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#20048;&#35266;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#31639;&#27861;&#65292;&#24182;&#20165;&#23545;&#36716;&#31227;&#21160;&#21147;&#23398;&#20855;&#26377;Lipschitz&#36830;&#32493;&#24615;&#30340;&#20551;&#35774;&#65292;&#26368;&#21518;&#24314;&#31435;&#20102;&#19968;&#20010;&#25351;&#25968;&#32423;&#30340;&#19979;&#30028;&#25903;&#25345;MFC&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#22343;&#22330;&#25511;&#21046;&#65288;MFC&#65289;&#21644;&#22343;&#22330;&#21338;&#24328;&#65288;MFG&#65289;&#20013;&#24378;&#21270;&#23398;&#20064;&#30340;&#32479;&#35745;&#25928;&#29575;&#12290;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;Mean-Field Model-Based Eluder Dimension (MBED)&#30340;&#26032;&#27010;&#24565;&#65292;&#21253;&#21547;&#20102;&#19968;&#31995;&#21015;&#20016;&#23500;&#30340;&#22343;&#22330;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#20048;&#35266;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#36820;&#22238;&#19968;&#20010;$\epsilon$&#20248;&#30340;&#31574;&#30053;&#65292;&#36866;&#29992;&#20110;MFC&#25110;$\epsilon$&#32435;&#20160;&#22343;&#34913;&#31574;&#30053;&#36866;&#29992;&#20110;MFG&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#22810;&#39033;&#24335;&#19982;&#30456;&#20851;&#21442;&#25968;&#26080;&#20851;&#65292;&#19982;&#29366;&#24577;&#12289;&#21160;&#20316;&#21644;&#20195;&#29702;&#25968;&#37327;&#26080;&#20851;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#20165;&#23545;&#36716;&#31227;&#21160;&#21147;&#23398;&#20855;&#26377;Lipschitz&#36830;&#32493;&#24615;&#30340;&#20551;&#35774;&#65292;&#36991;&#20813;&#20102;&#20197;&#21069;&#30340;&#24378;&#32467;&#26500;&#20551;&#35774;&#12290;&#26368;&#21518;&#65292;&#22312;tabular&#35774;&#32622;&#19979;&#65292;&#20551;&#35774;&#26377;&#19968;&#20010;&#29983;&#25104;&#27169;&#22411;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#25351;&#25968;&#32423;&#30340;&#19979;&#30028;&#25903;&#25345;MFC&#35774;&#32622;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26679;&#26412;&#39640;&#25928;&#30340;&#27169;&#22411;&#28040;&#38500;&#31639;&#27861;&#20197;&#36924;&#36817;&#26368;&#20248;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the statistical efficiency of Reinforcement Learning in Mean-Field Control (MFC) and Mean-Field Game (MFG) with general function approximation. We introduce a new concept called Mean-Field Model-Based Eluder Dimension (MBED), which subsumes a rich family of Mean-Field RL problems. Additionally, we propose algorithms based on Optimistic Maximal Likelihood Estimation, which can return an $\epsilon$-optimal policy for MFC or an $\epsilon$-Nash Equilibrium policy for MFG, with sample complexity polynomial w.r.t. relevant parameters and independent of the number of states, actions and the number of agents. Notably, our results only require a mild assumption of Lipschitz continuity on transition dynamics and avoid strong structural assumptions in previous work. Finally, in the tabular setting, given the access to a generative model, we establish an exponential lower bound for MFC setting, while providing a novel sample-efficient model elimination algorithm to approxim
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#12289;&#32431;&#24046;&#20998;&#38544;&#31169;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#22312;$\{0,1\}^d$&#19978;&#20934;&#30830;&#20272;&#35745;&#20108;&#20803;&#31215;&#20998;&#24067;&#30340;&#22343;&#20540;&#65292;&#36798;&#21040;&#20102;&#26368;&#20248;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2304.06787</link><description>&lt;p&gt;
&#20108;&#20803;&#31215;&#20998;&#24067;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#21644;&#32431;&#24046;&#20998;&#38544;&#31169;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
A Polynomial Time, Pure Differentially Private Estimator for Binary Product Distributions. (arXiv:2304.06787v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06787
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#12289;&#32431;&#24046;&#20998;&#38544;&#31169;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#22312;$\{0,1\}^d$&#19978;&#20934;&#30830;&#20272;&#35745;&#20108;&#20803;&#31215;&#20998;&#24067;&#30340;&#22343;&#20540;&#65292;&#36798;&#21040;&#20102;&#26368;&#20248;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#949;-&#24046;&#20998;&#38544;&#31169;&#12289;&#35745;&#31639;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#24635;&#21464;&#21270;&#36317;&#31163;&#19979;&#20934;&#30830;&#22320;&#20272;&#35745;$\{0,1\}^d$&#19978;&#30340;&#20056;&#31215;&#20998;&#24067;&#30340;&#22343;&#20540;&#65292;&#21516;&#26102;&#22312;&#22810;&#39033;&#24335;&#23545;&#25968;&#22240;&#23376;&#20869;&#33719;&#24471;&#20102;&#26368;&#20248;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#20043;&#21069;&#30340;&#24037;&#20316;&#35201;&#20040;&#22312;&#26356;&#24369;&#30340;&#38544;&#31169;&#27010;&#24565;&#19979;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#35201;&#20040;&#22312;&#25351;&#25968;&#32423;&#36816;&#34892;&#26102;&#38388;&#20869;&#26368;&#20248;&#22320;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present the first $\varepsilon$-differentially private, computationally efficient algorithm that estimates the means of product distributions over $\{0,1\}^d$ accurately in total-variation distance, whilst attaining the optimal sample complexity to within polylogarithmic factors. The prior work had either solved this problem efficiently and optimally under weaker notions of privacy, or had solved it optimally while having exponential running times.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#26377;&#25928;&#32780;&#20934;&#30830;&#22320;&#36817;&#20284;&#31232;&#30095;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;&#65288;GAMs&#65289;&#30340;Rashomon&#38598;&#30340;&#25216;&#26415;&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;&#36817;&#20284;&#27169;&#22411;&#26469;&#35299;&#20915;&#23454;&#38469;&#24212;&#29992;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2303.16047</link><description>&lt;p&gt;
&#29702;&#35299;&#21644;&#25506;&#32034;&#31232;&#30095;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;&#30340;&#25972;&#20010;&#20248;&#31168;&#38598;&#21512;
&lt;/p&gt;
&lt;p&gt;
Understanding and Exploring the Whole Set of Good Sparse Generalized Additive Models. (arXiv:2303.16047v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16047
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#26377;&#25928;&#32780;&#20934;&#30830;&#22320;&#36817;&#20284;&#31232;&#30095;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;&#65288;GAMs&#65289;&#30340;Rashomon&#38598;&#30340;&#25216;&#26415;&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;&#36817;&#20284;&#27169;&#22411;&#26469;&#35299;&#20915;&#23454;&#38469;&#24212;&#29992;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19982;&#39046;&#22495;&#19987;&#23478;&#20043;&#38388;&#30340;&#20132;&#20114;&#33267;&#20851;&#37325;&#35201;&#65307;&#28982;&#32780;&#65292;&#36890;&#24120;&#21482;&#29983;&#25104;&#21333;&#20010;&#27169;&#22411;&#30340;&#32463;&#20856;&#26426;&#22120;&#23398;&#20064;&#33539;&#24335;&#19981;&#21033;&#20110;&#27492;&#31867;&#20132;&#20114;&#12290;&#36817;&#20284;&#21644;&#25506;&#32034;Rashomon&#38598;&#65292;&#21363;&#25152;&#26377;&#36817;&#20046;&#26368;&#20248;&#27169;&#22411;&#30340;&#38598;&#21512;&#65292;&#36890;&#36807;&#25552;&#20379;&#29992;&#25143;&#21487;&#25628;&#32034;&#30340;&#31354;&#38388;&#21253;&#21547;&#22810;&#26679;&#24615;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#36825;&#19968;&#23454;&#38469;&#25361;&#25112;&#65292;&#39046;&#22495;&#19987;&#23478;&#21487;&#20197;&#20174;&#20013;&#36873;&#25321;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#32780;&#20934;&#30830;&#22320;&#36817;&#20284;&#31232;&#30095;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;&#65288;GAMs&#65289;&#30340;Rashomon&#38598;&#30340;&#25216;&#26415;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29992;&#20110;&#36817;&#20284;&#20855;&#26377;&#22266;&#23450;&#25903;&#25345;&#38598;&#30340;GAMs&#30340;Rashomon&#38598;&#30340;&#26925;&#29699;&#24418;&#31639;&#27861;&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;&#26925;&#29699;&#24418;&#36817;&#20284;&#20102;&#35768;&#22810;&#19981;&#21516;&#25903;&#25345;&#38598;&#30340;Rashomon&#38598;&#12290;&#36817;&#20284;&#30340;Rashomon&#38598;&#20026;&#35299;&#20915;&#23454;&#38469;&#25361;&#25112;&#65292;&#20363;&#22914;&#65288;1&#65289;&#30740;&#31350;&#27169;&#22411;&#31867;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#65307;&#65288;2&#65289;&#22312;&#29992;&#25143;&#25351;&#23450;&#32422;&#26463;&#26465;&#20214;&#19979;&#26597;&#25214;&#27169;&#22411;&#65292;&#25552;&#20379;&#20102;&#37325;&#35201;&#30340;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
In real applications, interaction between machine learning model and domain experts is critical; however, the classical machine learning paradigm that usually produces only a single model does not facilitate such interaction. Approximating and exploring the Rashomon set, i.e., the set of all near-optimal models, addresses this practical challenge by providing the user with a searchable space containing a diverse set of models from which domain experts can choose. We present a technique to efficiently and accurately approximate the Rashomon set of sparse, generalized additive models (GAMs). We present algorithms to approximate the Rashomon set of GAMs with ellipsoids for fixed support sets and use these ellipsoids to approximate Rashomon sets for many different support sets. The approximated Rashomon set serves as a cornerstone to solve practical challenges such as (1) studying the variable importance for the model class; (2) finding models under user-specified constraints (monotonicity
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#32602;&#20989;&#25968;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#28145;&#24230;&#37096;&#20998;&#32447;&#24615;Cox&#27169;&#22411;&#65292;&#29992;&#20110;&#22312;&#32954;&#30284;&#24739;&#32773;&#30340;CT&#25195;&#25551;&#20013;&#20998;&#26512;&#27515;&#20129;&#39118;&#38505;&#12290;&#35813;&#27169;&#22411;&#33021;&#26377;&#25928;&#22320;&#25972;&#21512;&#24050;&#30693;&#21644;&#26032;&#20852;&#30340;&#39118;&#38505;&#22240;&#32032;&#65292;&#35299;&#20915;&#20102;&#21442;&#25968;&#32500;&#24230;&#36229;&#20986;&#26679;&#26412;&#22823;&#23567;&#21644;&#38750;&#21442;&#25968;&#24314;&#27169;&#20013;&#32500;&#24230;&#28798;&#38590;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2303.05341</link><description>&lt;p&gt;
&#21033;&#29992;&#32602;&#20989;&#25968;&#30340;&#28145;&#24230;&#37096;&#20998;&#32447;&#24615;Cox&#27169;&#22411;&#21450;&#20854;&#22312;&#32954;&#30284;&#24739;&#32773;CT&#25195;&#25551;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Penalized Deep Partially Linear Cox Models with Application to CT Scans of Lung Cancer Patients. (arXiv:2303.05341v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.05341
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#32602;&#20989;&#25968;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#28145;&#24230;&#37096;&#20998;&#32447;&#24615;Cox&#27169;&#22411;&#65292;&#29992;&#20110;&#22312;&#32954;&#30284;&#24739;&#32773;&#30340;CT&#25195;&#25551;&#20013;&#20998;&#26512;&#27515;&#20129;&#39118;&#38505;&#12290;&#35813;&#27169;&#22411;&#33021;&#26377;&#25928;&#22320;&#25972;&#21512;&#24050;&#30693;&#21644;&#26032;&#20852;&#30340;&#39118;&#38505;&#22240;&#32032;&#65292;&#35299;&#20915;&#20102;&#21442;&#25968;&#32500;&#24230;&#36229;&#20986;&#26679;&#26412;&#22823;&#23567;&#21644;&#38750;&#21442;&#25968;&#24314;&#27169;&#20013;&#32500;&#24230;&#28798;&#38590;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32954;&#30284;&#26159;&#20840;&#29699;&#30284;&#30151;&#27515;&#20129;&#29575;&#30340;&#20027;&#35201;&#21407;&#22240;&#65292;&#31361;&#20986;&#20102;&#29702;&#35299;&#20854;&#27515;&#20129;&#39118;&#38505;&#23545;&#35774;&#35745;&#26377;&#25928;&#30340;&#20197;&#24739;&#32773;&#20026;&#20013;&#24515;&#30340;&#27835;&#30103;&#30340;&#37325;&#35201;&#24615;&#12290;&#22269;&#23478;&#32954;&#37096;&#31579;&#26597;&#35797;&#39564;&#65288;NLST&#65289;&#37319;&#29992;&#20102;&#35745;&#31639;&#26426;&#26029;&#23618;&#25195;&#25551;&#32441;&#29702;&#20998;&#26512;&#65292;&#25552;&#20379;&#20102;CT&#25195;&#25551;&#19978;&#32441;&#29702;&#27169;&#24335;&#30340;&#23458;&#35266;&#27979;&#37327;&#65292;&#29992;&#20110;&#37327;&#21270;&#32954;&#30284;&#24739;&#32773;&#30340;&#27515;&#20129;&#39118;&#38505;&#12290;&#37096;&#20998;&#32447;&#24615;Cox&#27169;&#22411;&#36890;&#36807;&#23558;&#39118;&#38505;&#20989;&#25968;&#20998;&#35299;&#20026;&#21442;&#25968;&#21644;&#38750;&#21442;&#25968;&#20998;&#37327;&#65292;&#25104;&#20026;&#29983;&#23384;&#20998;&#26512;&#20013;&#22791;&#21463;&#38738;&#30544;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#23558;&#24050;&#30693;&#39118;&#38505;&#22240;&#32032;&#65288;&#22914;&#24180;&#40836;&#21644;&#20020;&#24202;&#21464;&#37327;&#65289;&#21644;&#26032;&#20852;&#39118;&#38505;&#22240;&#32032;&#65288;&#22914;&#22270;&#20687;&#29305;&#24449;&#65289;&#25972;&#21512;&#22312;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#20013;&#12290;&#28982;&#32780;&#65292;&#24403;&#21442;&#25968;&#20998;&#37327;&#30340;&#32500;&#24230;&#36229;&#36807;&#26679;&#26412;&#22823;&#23567;&#26102;&#65292;&#27169;&#22411;&#25311;&#21512;&#21464;&#24471;&#22256;&#38590;&#65292;&#32780;&#38750;&#21442;&#25968;&#24314;&#27169;&#21017;&#38754;&#20020;&#32500;&#24230;&#28798;&#38590;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#32602;&#20989;&#25968;&#28145;&#24230;&#37096;&#20998;&#32447;&#24615;Cox&#27169;&#22411;&#65288;Penali
&lt;/p&gt;
&lt;p&gt;
Lung cancer is a leading cause of cancer mortality globally, highlighting the importance of understanding its mortality risks to design effective patient-centered therapies. The National Lung Screening Trial (NLST) employed computed tomography texture analysis, which provides objective measurements of texture patterns on CT scans, to quantify the mortality risks of lung cancer patients. Partially linear Cox models have gained popularity for survival analysis by dissecting the hazard function into parametric and nonparametric components, allowing for the effective incorporation of both well-established risk factors (such as age and clinical variables) and emerging risk factors (e.g., image features) within a unified framework. However, when the dimension of parametric components exceeds the sample size, the task of model fitting becomes formidable, while nonparametric modeling grapples with the curse of dimensionality. We propose a novel Penalized Deep Partially Linear Cox Model (Penali
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#19968;&#33324;&#28608;&#27963;&#20989;&#25968;&#30340;&#28145;&#24230;&#24179;&#34913;&#27169;&#22411;&#65288;DEQ&#65289;&#30340;&#20840;&#23616;&#25910;&#25947;&#36895;&#24230;&#65292;&#35777;&#26126;&#20102;&#26799;&#24230;&#19979;&#38477;&#20197;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#20248;&#35299;&#65292;&#24182;&#35299;&#20915;&#20102;&#38480;&#21046;&#24179;&#34913;&#28857;Gram&#30697;&#38453;&#26368;&#23567;&#29305;&#24449;&#20540;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2302.05797</link><description>&lt;p&gt;
&#20855;&#26377;&#19968;&#33324;&#28608;&#27963;&#20989;&#25968;&#30340;&#28145;&#24230;&#24179;&#34913;&#27169;&#22411;&#30340;&#20840;&#23616;&#25910;&#25947;&#36895;&#24230;
&lt;/p&gt;
&lt;p&gt;
Global Convergence Rate of Deep Equilibrium Models with General Activations. (arXiv:2302.05797v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05797
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#19968;&#33324;&#28608;&#27963;&#20989;&#25968;&#30340;&#28145;&#24230;&#24179;&#34913;&#27169;&#22411;&#65288;DEQ&#65289;&#30340;&#20840;&#23616;&#25910;&#25947;&#36895;&#24230;&#65292;&#35777;&#26126;&#20102;&#26799;&#24230;&#19979;&#38477;&#20197;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#20248;&#35299;&#65292;&#24182;&#35299;&#20915;&#20102;&#38480;&#21046;&#24179;&#34913;&#28857;Gram&#30697;&#38453;&#26368;&#23567;&#29305;&#24449;&#20540;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26368;&#36817;&#30340;&#19968;&#31687;&#35770;&#25991;&#20013;&#65292;Ling&#31561;&#20154;&#30740;&#31350;&#20102;&#20855;&#26377;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;&#36807;&#21442;&#25968;&#21270;&#28145;&#24230;&#24179;&#34913;&#27169;&#22411;&#65288;DEQ&#65289;&#12290;&#20182;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20108;&#27425;&#25439;&#22833;&#20989;&#25968;&#65292;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#20197;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#23545;&#20110;&#20855;&#26377;&#20219;&#20309;&#20855;&#26377;&#26377;&#30028;&#19968;&#38454;&#21644;&#20108;&#38454;&#23548;&#25968;&#30340;&#28608;&#27963;&#20989;&#25968;&#30340;DEQ&#65292;&#35813;&#20107;&#23454;&#20173;&#28982;&#25104;&#31435;&#12290;&#30001;&#20110;&#26032;&#30340;&#28608;&#27963;&#20989;&#25968;&#36890;&#24120;&#26159;&#38750;&#32447;&#24615;&#30340;&#65292;&#38480;&#21046;&#24179;&#34913;&#28857;&#30340;Gram&#30697;&#38453;&#30340;&#26368;&#23567;&#29305;&#24449;&#20540;&#23588;&#20854;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#23436;&#25104;&#36825;&#20010;&#20219;&#21153;&#65292;&#25105;&#20204;&#38656;&#35201;&#21019;&#24314;&#19968;&#20010;&#26032;&#30340;&#24635;&#20307;Gram&#30697;&#38453;&#65292;&#24182;&#24320;&#21457;&#19968;&#31181;&#20855;&#26377;Hermite&#22810;&#39033;&#24335;&#23637;&#24320;&#30340;&#26032;&#24418;&#24335;&#30340;&#21452;&#37325;&#28608;&#27963;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
In a recent paper, Ling et al. investigated the over-parametrized Deep Equilibrium Model (DEQ) with ReLU activation. They proved that the gradient descent converges to a globally optimal solution at a linear convergence rate for the quadratic loss function. This paper shows that this fact still holds for DEQs with any general activation that has bounded first and second derivatives. Since the new activation function is generally non-linear, bounding the least eigenvalue of the Gram matrix of the equilibrium point is particularly challenging. To accomplish this task, we need to create a novel population Gram matrix and develop a new form of dual activation with Hermite polynomial expansion.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20122;&#28176;&#36817;&#26497;&#22823;&#20540;&#30340;&#39640;&#32500;&#21464;&#37327;&#32858;&#31867;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21033;&#29992;&#32676;&#38598;&#38388;&#22810;&#21464;&#37327;&#38543;&#26426;&#36807;&#31243;&#30340;&#26497;&#22823;&#20540;&#30340;&#29420;&#31435;&#24615;&#23450;&#20041;&#31181;&#32676;&#27700;&#24179;&#30340;&#32676;&#38598;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#26080;&#38656;&#39044;&#20808;&#25351;&#23450;&#32676;&#38598;&#25968;&#37327;&#30340;&#31639;&#27861;&#26469;&#24674;&#22797;&#21464;&#37327;&#30340;&#32676;&#38598;&#12290;&#35813;&#31639;&#27861;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#33021;&#22815;&#26377;&#25928;&#22320;&#35782;&#21035;&#25968;&#25454;&#20013;&#30340;&#32676;&#38598;&#65292;&#24182;&#33021;&#22815;&#20197;&#22810;&#39033;&#24335;&#22797;&#26434;&#24230;&#36827;&#34892;&#35745;&#31639;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#23545;&#20110;&#29702;&#35299;&#20381;&#36182;&#36807;&#31243;&#30340;&#22359;&#26368;&#22823;&#20540;&#30340;&#38750;&#21442;&#25968;&#23398;&#20064;&#26377;&#37325;&#35201;&#24847;&#20041;&#65292;&#24182;&#19988;&#22312;&#31070;&#32463;&#31185;&#23398;&#39046;&#22495;&#26377;&#30528;&#24212;&#29992;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2302.00934</link><description>&lt;p&gt;
&#22522;&#20110;&#24369;&#30456;&#20851;&#38543;&#26426;&#36807;&#31243;&#30340;&#20122;&#28176;&#36817;&#26497;&#22823;&#20540;&#30340;&#39640;&#32500;&#21464;&#37327;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
High-dimensional variable clustering based on sub-asymptotic maxima of a weakly dependent random process. (arXiv:2302.00934v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00934
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20122;&#28176;&#36817;&#26497;&#22823;&#20540;&#30340;&#39640;&#32500;&#21464;&#37327;&#32858;&#31867;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21033;&#29992;&#32676;&#38598;&#38388;&#22810;&#21464;&#37327;&#38543;&#26426;&#36807;&#31243;&#30340;&#26497;&#22823;&#20540;&#30340;&#29420;&#31435;&#24615;&#23450;&#20041;&#31181;&#32676;&#27700;&#24179;&#30340;&#32676;&#38598;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#26080;&#38656;&#39044;&#20808;&#25351;&#23450;&#32676;&#38598;&#25968;&#37327;&#30340;&#31639;&#27861;&#26469;&#24674;&#22797;&#21464;&#37327;&#30340;&#32676;&#38598;&#12290;&#35813;&#31639;&#27861;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#33021;&#22815;&#26377;&#25928;&#22320;&#35782;&#21035;&#25968;&#25454;&#20013;&#30340;&#32676;&#38598;&#65292;&#24182;&#33021;&#22815;&#20197;&#22810;&#39033;&#24335;&#22797;&#26434;&#24230;&#36827;&#34892;&#35745;&#31639;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#23545;&#20110;&#29702;&#35299;&#20381;&#36182;&#36807;&#31243;&#30340;&#22359;&#26368;&#22823;&#20540;&#30340;&#38750;&#21442;&#25968;&#23398;&#20064;&#26377;&#37325;&#35201;&#24847;&#20041;&#65292;&#24182;&#19988;&#22312;&#31070;&#32463;&#31185;&#23398;&#39046;&#22495;&#26377;&#30528;&#24212;&#29992;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21464;&#37327;&#32858;&#31867;&#27169;&#22411;&#65292;&#31216;&#20026;&#28176;&#36817;&#29420;&#31435;&#22359; (AI-block) &#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22522;&#20110;&#32676;&#38598;&#38388;&#22810;&#21464;&#37327;&#24179;&#31283;&#28151;&#21512;&#38543;&#26426;&#36807;&#31243;&#30340;&#26497;&#22823;&#20540;&#30340;&#29420;&#31435;&#24615;&#26469;&#23450;&#20041;&#31181;&#32676;&#27700;&#24179;&#30340;&#32676;&#38598;&#12290;&#35813;&#27169;&#22411;&#31867;&#26159;&#21487;&#35782;&#21035;&#30340;&#65292;&#24847;&#21619;&#30528;&#23384;&#22312;&#19968;&#31181;&#20559;&#24207;&#20851;&#31995;&#65292;&#20801;&#35768;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#26080;&#38656;&#20107;&#20808;&#25351;&#23450;&#32676;&#38598;&#30340;&#25968;&#37327;&#21363;&#21487;&#24674;&#22797;&#21464;&#37327;&#30340;&#32676;&#38598;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#25552;&#20379;&#20102;&#19968;&#20123;&#29702;&#35770;&#27934;&#23519;&#65292;&#35777;&#26126;&#20102;&#22312;&#26576;&#20123;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#33021;&#22815;&#22312;&#35745;&#31639;&#22797;&#26434;&#24615;&#22312;&#32500;&#24230;&#20013;&#26159;&#22810;&#39033;&#24335;&#30340;&#24773;&#20917;&#19979;&#26377;&#25928;&#22320;&#35782;&#21035;&#25968;&#25454;&#20013;&#30340;&#32676;&#38598;&#12290;&#36825;&#24847;&#21619;&#30528;&#21487;&#20197;&#38750;&#21442;&#25968;&#22320;&#23398;&#20064;&#20986;&#20165;&#20165;&#26159;&#20122;&#28176;&#36817;&#30340;&#20381;&#36182;&#36807;&#31243;&#30340;&#22359;&#26368;&#22823;&#20540;&#30340;&#32676;&#32452;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#35828;&#26126;&#25105;&#20204;&#30340;&#24037;&#20316;&#30340;&#37325;&#35201;&#24615;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#31070;&#32463;&#31185;&#23398;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new class of models for variable clustering called Asymptotic Independent block (AI-block) models, which defines population-level clusters based on the independence of the maxima of a multivariate stationary mixing random process among clusters. This class of models is identifiable, meaning that there exists a maximal element with a partial order between partitions, allowing for statistical inference. We also present an algorithm for recovering the clusters of variables without specifying the number of clusters \emph{a priori}. Our work provides some theoretical insights into the consistency of our algorithm, demonstrating that under certain conditions it can effectively identify clusters in the data with a computational complexity that is polynomial in the dimension. This implies that groups can be learned nonparametrically in which block maxima of a dependent process are only sub-asymptotic. To further illustrate the significance of our work, we applied our method to neu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#38543;&#26426;&#20048;&#35266;&#26799;&#24230;&#31639;&#27861;&#26469;&#35299;&#20915;&#22823;&#35268;&#27169;&#24773;&#20917;&#19979;&#30340;&#26681;&#26597;&#25214;&#38382;&#39064;&#12290;&#31532;&#19968;&#31181;&#31639;&#27861;&#22312;&#24213;&#23618;&#31639;&#23376;&#28385;&#36275;&#19968;&#23450;&#26465;&#20214;&#26102;&#21487;&#20197;&#36798;&#21040;&#36739;&#22909;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#31532;&#20108;&#31181;&#31639;&#27861;&#26159;&#19968;&#31181;&#21152;&#36895;&#31639;&#27861;&#65292;&#21487;&#20197;&#26356;&#24555;&#22320;&#25910;&#25947;&#12290;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#21644;&#35299;&#30340;&#23384;&#22312;&#24615;&#20063;&#24471;&#21040;&#20102;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2301.03113</link><description>&lt;p&gt;
&#38543;&#26426;&#22359;&#22352;&#26631;&#20048;&#35266;&#26799;&#24230;&#31639;&#27861;&#35299;&#20915;&#26681;&#26597;&#25214;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Randomized Block-Coordinate Optimistic Gradient Algorithms for Root-Finding Problems. (arXiv:2301.03113v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.03113
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#38543;&#26426;&#20048;&#35266;&#26799;&#24230;&#31639;&#27861;&#26469;&#35299;&#20915;&#22823;&#35268;&#27169;&#24773;&#20917;&#19979;&#30340;&#26681;&#26597;&#25214;&#38382;&#39064;&#12290;&#31532;&#19968;&#31181;&#31639;&#27861;&#22312;&#24213;&#23618;&#31639;&#23376;&#28385;&#36275;&#19968;&#23450;&#26465;&#20214;&#26102;&#21487;&#20197;&#36798;&#21040;&#36739;&#22909;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#31532;&#20108;&#31181;&#31639;&#27861;&#26159;&#19968;&#31181;&#21152;&#36895;&#31639;&#27861;&#65292;&#21487;&#20197;&#26356;&#24555;&#22320;&#25910;&#25947;&#12290;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#21644;&#35299;&#30340;&#23384;&#22312;&#24615;&#20063;&#24471;&#21040;&#20102;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#38543;&#26426;&#22359;&#22352;&#26631;&#20048;&#35266;&#26799;&#24230;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#22823;&#35268;&#27169;&#24773;&#20917;&#19979;&#36817;&#20284;&#27714;&#35299;&#38750;&#32447;&#24615;&#26041;&#31243;&#65292;&#20063;&#31216;&#20026;&#26681;&#26597;&#25214;&#38382;&#39064;&#12290;&#31532;&#19968;&#31181;&#31639;&#27861;&#20351;&#29992;&#24658;&#23450;&#30340;&#27493;&#38271;&#65292;&#38750;&#21152;&#36895;&#31639;&#27861;&#65292;&#22312;&#24213;&#23618;&#31639;&#23376;G&#28385;&#36275;Lipschitz&#36830;&#32493;&#24615;&#21644;&#24369;Minty&#35299;&#26465;&#20214;&#26102;&#65292;&#23427;&#22312;&#25968;&#23398;&#26399;&#26395;E[||Gx^k||^2]&#19978;&#36798;&#21040;O(1/k)&#30340;&#26368;&#20248;&#36845;&#20195;&#25910;&#25947;&#36895;&#24230;&#65292;&#20854;&#20013;E[&#183;]&#34920;&#31034;&#26399;&#26395;&#65292;k&#20026;&#36845;&#20195;&#35745;&#25968;&#22120;&#12290;&#31532;&#20108;&#31181;&#26041;&#27861;&#26159;&#19968;&#31181;&#26032;&#30340;&#21152;&#36895;&#38543;&#26426;&#22359;&#22352;&#26631;&#20048;&#35266;&#26799;&#24230;&#31639;&#27861;&#65292;&#22312;G&#30340;&#22841;&#36924;&#24615;&#26465;&#20214;&#19979;&#65292;&#35813;&#31639;&#27861;&#22312;E[||Gx^k||^2]&#21644;E[||x^{k+1} x^{k}||^2]&#19978;&#20998;&#21035;&#36798;&#21040;O(1/k^2)&#21644;o(1/k^2)&#30340;&#36845;&#20195;&#25910;&#25947;&#36895;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#36845;&#20195;&#24207;&#21015;{x^k}&#20960;&#20046;&#24517;&#28982;&#25910;&#25947;&#21040;&#19968;&#20010;&#35299;&#65292;&#20197;&#21450;&#22312;&#27492;&#35299;&#22788;Gx^k&#30340;&#27169;&#30340;&#24179;&#26041;&#22312;...
&lt;/p&gt;
&lt;p&gt;
In this paper, we develop two new randomized block-coordinate optimistic gradient algorithms to approximate a solution of nonlinear equations in large-scale settings, which are called root-finding problems. Our first algorithm is non-accelerated with constant stepsizes, and achieves $\mathcal{O}(1/k)$ best-iterate convergence rate on $\mathbb{E}[ \Vert Gx^k\Vert^2]$ when the underlying operator $G$ is Lipschitz continuous and satisfies a weak Minty solution condition, where $\mathbb{E}[\cdot]$ is the expectation and $k$ is the iteration counter. Our second method is a new accelerated randomized block-coordinate optimistic gradient algorithm. We establish both $\mathcal{O}(1/k^2)$ and $o(1/k^2)$ last-iterate convergence rates on both $\mathbb{E}[ \Vert Gx^k\Vert^2]$ and $\mathbb{E}[ \Vert x^{k+1} x^{k}\Vert^2]$ for this algorithm under the co-coerciveness of $G$. In addition, we prove that the iterate sequence $\{x^k\}$ converges to a solution almost surely, and $\Vert Gx^k\Vert^2$ at
&lt;/p&gt;</description></item><item><title>&#20316;&#32773;&#21457;&#29616;&#20165;&#20351;&#29992;&#31070;&#32463;&#20803;&#23545;&#40784;&#26041;&#27861;&#19981;&#33021;&#26377;&#25928;&#35299;&#20915;&#32447;&#24615;&#25554;&#20540;&#20013;&#28608;&#27963;&#26041;&#24046;&#22349;&#32553;&#30340;&#38382;&#39064;&#65292;&#22240;&#27492;&#25552;&#20986;&#20102;REPAIR&#26041;&#27861;&#26469;&#20462;&#22797;&#25554;&#20540;&#30340;&#24402;&#19968;&#21270;&#32622;&#25442;&#28608;&#27963;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#21508;&#31181;&#26550;&#26500;&#20013;&#23558;REPAIR&#19982;&#31070;&#32463;&#20803;&#23545;&#40784;&#26041;&#27861;&#32467;&#21512;&#20351;&#29992;&#21487;&#20197;&#22823;&#24133;&#38477;&#20302;&#38556;&#30861;&#12290;</title><link>http://arxiv.org/abs/2211.08403</link><description>&lt;p&gt;
REPAIR: &#20462;&#22797;&#25554;&#20540;&#30340;&#24402;&#19968;&#21270;&#32622;&#25442;&#28608;&#27963;
&lt;/p&gt;
&lt;p&gt;
REPAIR: REnormalizing Permuted Activations for Interpolation Repair. (arXiv:2211.08403v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.08403
&lt;/p&gt;
&lt;p&gt;
&#20316;&#32773;&#21457;&#29616;&#20165;&#20351;&#29992;&#31070;&#32463;&#20803;&#23545;&#40784;&#26041;&#27861;&#19981;&#33021;&#26377;&#25928;&#35299;&#20915;&#32447;&#24615;&#25554;&#20540;&#20013;&#28608;&#27963;&#26041;&#24046;&#22349;&#32553;&#30340;&#38382;&#39064;&#65292;&#22240;&#27492;&#25552;&#20986;&#20102;REPAIR&#26041;&#27861;&#26469;&#20462;&#22797;&#25554;&#20540;&#30340;&#24402;&#19968;&#21270;&#32622;&#25442;&#28608;&#27963;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#21508;&#31181;&#26550;&#26500;&#20013;&#23558;REPAIR&#19982;&#31070;&#32463;&#20803;&#23545;&#40784;&#26041;&#27861;&#32467;&#21512;&#20351;&#29992;&#21487;&#20197;&#22823;&#24133;&#38477;&#20302;&#38556;&#30861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;Entezari&#31561;&#20154;&#65288;2021&#65289;&#30340;&#29468;&#24819;&#65292;&#21363;&#22914;&#26524;&#32771;&#34385;&#31070;&#32463;&#32593;&#32476;&#30340;&#32622;&#25442;&#19981;&#21464;&#24615;&#65292;&#37027;&#20040;&#32447;&#24615;&#25554;&#20540;&#20043;&#38388;&#21487;&#33021;&#27809;&#26377;&#25439;&#22833;&#38556;&#30861;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#20165;&#20351;&#29992;&#31070;&#32463;&#20803;&#23545;&#40784;&#26041;&#27861;&#26080;&#27861;&#24314;&#31435;&#20302;&#38556;&#30861;&#32447;&#24615;&#36830;&#25509;&#30340;&#21407;&#22240;&#26159;&#19968;&#31181;&#25105;&#20204;&#31216;&#20043;&#20026;&#26041;&#24046;&#22349;&#32553;&#30340;&#29616;&#35937;&#65306;&#25554;&#20540;&#28145;&#23618;&#32593;&#32476;&#30340;&#28608;&#27963;&#26041;&#24046;&#23849;&#28291;&#65292;&#23548;&#33268;&#24615;&#33021;&#36739;&#24046;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;REPAIR&#65288;&#20462;&#22797;&#25554;&#20540;&#30340;&#24402;&#19968;&#21270;&#32622;&#25442;&#28608;&#27963;&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#37325;&#26032;&#32553;&#25918;&#36825;&#20123;&#25554;&#20540;&#32593;&#32476;&#30340;&#39044;&#28608;&#27963;&#26469;&#32531;&#35299;&#26041;&#24046;&#23849;&#28291;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#25105;&#20204;&#26041;&#27861;&#19982;&#24402;&#19968;&#21270;&#23618;&#12289;&#32593;&#32476;&#23485;&#24230;&#21644;&#28145;&#24230;&#36873;&#25321;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#28436;&#31034;&#20102;&#22312;&#21508;&#31181;&#26550;&#26500;&#26063;&#20013;&#20351;&#29992;REPAIR&#20316;&#20026;&#31070;&#32463;&#20803;&#23545;&#40784;&#26041;&#27861;&#30340;&#25193;&#23637;&#65292;&#21487;&#20197;&#23558;&#38556;&#30861;&#38477;&#20302;60%&#33267;100%&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we look into the conjecture of Entezari et al. (2021) which states that if the permutation invariance of neural networks is taken into account, then there is likely no loss barrier to the linear interpolation between SGD solutions. First, we observe that neuron alignment methods alone are insufficient to establish low-barrier linear connectivity between SGD solutions due to a phenomenon we call variance collapse: interpolated deep networks suffer a collapse in the variance of their activations, causing poor performance. Next, we propose REPAIR (REnormalizing Permuted Activations for Interpolation Repair) which mitigates variance collapse by rescaling the preactivations of such interpolated networks. We explore the interaction between our method and the choice of normalization layer, network width, and depth, and demonstrate that using REPAIR on top of neuron alignment methods leads to 60%-100% relative barrier reduction across a wide variety of architecture families and t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;p$^3$VAE&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#23558;&#19968;&#20010;&#23436;&#32654;&#30340;&#29289;&#29702;&#27169;&#22411;&#38598;&#25104;&#21040;&#27169;&#22411;&#20013;&#65292;&#24182;&#24212;&#29992;&#20110;&#39640;&#20998;&#36776;&#29575;&#39640;&#20809;&#35889;&#36965;&#24863;&#22270;&#20687;&#30340;&#35821;&#20041;&#20998;&#21106;&#12290;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#22806;&#25512;&#33021;&#21147;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#21516;&#26102;&#20855;&#26377;&#39640;&#24230;&#35299;&#32533;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2210.10418</link><description>&lt;p&gt;
p$^3$VAE&#65306;&#19968;&#20010;&#29289;&#29702;&#38598;&#25104;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#24212;&#29992;&#20110;&#20809;&#23398;&#36965;&#24863;&#22270;&#20687;&#30340;&#35821;&#20041;&#20998;&#21106;
&lt;/p&gt;
&lt;p&gt;
p$^3$VAE: a physics-integrated generative model. Application to the semantic segmentation of optical remote sensing images. (arXiv:2210.10418v3 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.10418
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;p$^3$VAE&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#23558;&#19968;&#20010;&#23436;&#32654;&#30340;&#29289;&#29702;&#27169;&#22411;&#38598;&#25104;&#21040;&#27169;&#22411;&#20013;&#65292;&#24182;&#24212;&#29992;&#20110;&#39640;&#20998;&#36776;&#29575;&#39640;&#20809;&#35889;&#36965;&#24863;&#22270;&#20687;&#30340;&#35821;&#20041;&#20998;&#21106;&#12290;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#22806;&#25512;&#33021;&#21147;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#21516;&#26102;&#20855;&#26377;&#39640;&#24230;&#35299;&#32533;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19982;&#29289;&#29702;&#27169;&#22411;&#30456;&#32467;&#21512;&#26159;&#23398;&#20064;&#24378;&#22823;&#25968;&#25454;&#34920;&#31034;&#30340;&#26368;&#26032;&#30740;&#31350;&#26041;&#21521;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;p$^3$VAE&#65292;&#36825;&#26159;&#19968;&#20010;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#38598;&#25104;&#20102;&#19968;&#20010;&#23436;&#32654;&#30340;&#29289;&#29702;&#27169;&#22411;&#65292;&#37096;&#20998;&#35299;&#37322;&#20102;&#25968;&#25454;&#20013;&#30495;&#23454;&#30340;&#21464;&#21270;&#22240;&#32032;&#12290;&#20026;&#20102;&#20805;&#20998;&#21033;&#29992;&#25105;&#20204;&#30340;&#28151;&#21512;&#35774;&#35745;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#30417;&#30563;&#20248;&#21270;&#36807;&#31243;&#21644;&#19968;&#31181;&#25512;&#26029;&#26041;&#26696;&#65292;&#21516;&#26102;&#20276;&#38543;&#30528;&#26377;&#24847;&#20041;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#25105;&#20204;&#23558;p$^3$VAE&#24212;&#29992;&#20110;&#39640;&#20998;&#36776;&#29575;&#39640;&#20809;&#35889;&#36965;&#24863;&#22270;&#20687;&#30340;&#35821;&#20041;&#20998;&#21106;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#27169;&#25311;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#19982;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#28151;&#21512;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#22806;&#25512;&#33021;&#21147;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;p$^3$VAE&#33258;&#28982;&#20855;&#26377;&#39640;&#24230;&#35299;&#32533;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#21644;&#25968;&#25454;&#24050;&#22312;https://github.com/Romain3Ch216/p3VAE&#19978;&#20844;&#24320;&#21457;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
The combination of machine learning models with physical models is a recent research path to learn robust data representations. In this paper, we introduce p$^3$VAE, a generative model that integrates a perfect physical model which partially explains the true underlying factors of variation in the data. To fully leverage our hybrid design, we propose a semi-supervised optimization procedure and an inference scheme that comes along meaningful uncertainty estimates. We apply p$^3$VAE to the semantic segmentation of high-resolution hyperspectral remote sensing images. Our experiments on a simulated data set demonstrated the benefits of our hybrid model against conventional machine learning models in terms of extrapolation capabilities and interpretability. In particular, we show that p$^3$VAE naturally has high disentanglement capabilities. Our code and data have been made publicly available at https://github.com/Romain3Ch216/p3VAE.
&lt;/p&gt;</description></item><item><title>&#27450;&#35784;&#25968;&#25454;&#38598;&#22522;&#20934;&#65288;FDB&#65289;&#26159;&#19968;&#20010;&#38024;&#23545;&#27450;&#35784;&#26816;&#27979;&#30340;&#20844;&#24320;&#21487;&#29992;&#25968;&#25454;&#38598;&#30340;&#27719;&#32534;&#65292;&#28085;&#30422;&#20102;&#21508;&#31181;&#27450;&#35784;&#30456;&#20851;&#20219;&#21153;&#65292;&#20026;&#35299;&#20915;&#27450;&#35784;&#26816;&#27979;&#20013;&#30340;&#29420;&#29305;&#25361;&#25112;&#25552;&#20379;&#20102;&#26631;&#20934;&#21270;&#30340;&#25968;&#25454;&#38598;&#21644;&#22522;&#20934;&#12290; (arXiv:2208.14417v3 [cs.LG] UPDATED)</title><link>http://arxiv.org/abs/2208.14417</link><description>&lt;p&gt;
&#27450;&#35784;&#25968;&#25454;&#38598;&#22522;&#20934;&#21644;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Fraud Dataset Benchmark and Applications. (arXiv:2208.14417v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.14417
&lt;/p&gt;
&lt;p&gt;
&#27450;&#35784;&#25968;&#25454;&#38598;&#22522;&#20934;&#65288;FDB&#65289;&#26159;&#19968;&#20010;&#38024;&#23545;&#27450;&#35784;&#26816;&#27979;&#30340;&#20844;&#24320;&#21487;&#29992;&#25968;&#25454;&#38598;&#30340;&#27719;&#32534;&#65292;&#28085;&#30422;&#20102;&#21508;&#31181;&#27450;&#35784;&#30456;&#20851;&#20219;&#21153;&#65292;&#20026;&#35299;&#20915;&#27450;&#35784;&#26816;&#27979;&#20013;&#30340;&#29420;&#29305;&#25361;&#25112;&#25552;&#20379;&#20102;&#26631;&#20934;&#21270;&#30340;&#25968;&#25454;&#38598;&#21644;&#22522;&#20934;&#12290; (arXiv:2208.14417v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;&#21270;&#30340;&#25968;&#25454;&#38598;&#21644;&#22522;&#20934;&#24050;&#32463;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#12289;&#22810;&#27169;&#24577;&#21644;&#34920;&#26684;&#35774;&#32622;&#26041;&#38754;&#25512;&#21160;&#20102;&#21019;&#26032;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#19982;&#20854;&#20182;&#30740;&#31350;&#39046;&#22495;&#30456;&#27604;&#65292;&#27450;&#35784;&#26816;&#27979;&#38754;&#20020;&#30528;&#29420;&#29305;&#30340;&#25361;&#25112;&#65306;&#39640;&#32423;&#21035;&#30340;&#19981;&#24179;&#34913;&#12289;&#22810;&#26679;&#21270;&#30340;&#29305;&#24449;&#31867;&#22411;&#12289;&#39057;&#32321;&#21464;&#21270;&#30340;&#27450;&#35784;&#27169;&#24335;&#21644;&#38382;&#39064;&#30340;&#23545;&#25239;&#24615;&#12290;&#30001;&#20110;&#36825;&#20123;&#25361;&#25112;&#65292;&#23545;&#20854;&#20182;&#30740;&#31350;&#39046;&#22495;&#30340;&#25968;&#25454;&#38598;&#35780;&#20272;&#30340;&#24314;&#27169;&#26041;&#27861;&#21487;&#33021;&#23545;&#27450;&#35784;&#26816;&#27979;&#25928;&#26524;&#19981;&#20339;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#27450;&#35784;&#25968;&#25454;&#38598;&#22522;&#20934;&#65288;FDB&#65289;&#65292;&#23427;&#26159;&#19968;&#20010;&#38024;&#23545;&#27450;&#35784;&#26816;&#27979;&#30340;&#20844;&#24320;&#21487;&#29992;&#25968;&#25454;&#38598;&#30340;&#27719;&#32534;&#65292;&#28085;&#30422;&#20102;&#21508;&#31181;&#27450;&#35784;&#30456;&#20851;&#20219;&#21153;&#65292;&#21253;&#25324;&#35782;&#21035;&#26080;&#21345;&#20132;&#26131;&#12289;&#26816;&#27979;&#26426;&#22120;&#20154;&#25915;&#20987;&#12289;&#20998;&#31867;&#24694;&#24847;URL&#12289;&#20272;&#35745;&#36151;&#27454;&#36829;&#32422;&#39118;&#38505;&#21644;&#20869;&#23481;&#23457;&#26680;&#31561;&#12290;&#22522;&#20110;Python&#30340;FDB&#24211;&#25552;&#20379;&#20102;&#19968;&#33268;&#30340;API&#29992;&#20110;&#25968;&#25454;&#21152;&#36733;&#21644;&#26631;&#20934;&#21270;&#30340;&#35757;&#32451;&#21644;&#27979;&#35797;&#38598;&#21010;&#20998;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#20960;&#31181;&#24212;&#29992;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
Standardized datasets and benchmarks have spurred innovations in computer vision, natural language processing, multi-modal and tabular settings. We note that, as compared to other well researched fields, fraud detection has unique challenges: high-class imbalance, diverse feature types, frequently changing fraud patterns, and adversarial nature of the problem. Due to these, the modeling approaches evaluated on datasets from other research fields may not work well for the fraud detection. In this paper, we introduce Fraud Dataset Benchmark (FDB), a compilation of publicly available datasets catered to fraud detection FDB comprises variety of fraud related tasks, ranging from identifying fraudulent card-not-present transactions, detecting bot attacks, classifying malicious URLs, estimating risk of loan default to content moderation. The Python based library for FDB provides a consistent API for data loading with standardized training and testing splits. We demonstrate several application
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25193;&#23637;&#20102;&#39063;&#31890;&#24037;&#20855;&#21464;&#37327;&#65288;GIV&#65289;&#26041;&#27861;&#65292;&#21253;&#25324;&#22312;&#22823;&#32500;&#24230;&#19979;&#30340;&#35782;&#21035;&#36807;&#31243;&#65292;&#22788;&#29702;&#26410;&#30693;&#30340;&#22240;&#23376;&#21644;&#21152;&#36733;&#65292;&#20197;&#21450;&#36890;&#36807;&#39069;&#22806;&#26500;&#24314;&#30340;&#24037;&#20855;&#21464;&#37327;&#36807;&#24230;&#35782;&#21035;&#32467;&#26500;&#21442;&#25968;&#65292;&#20174;&#32780;&#25552;&#39640;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2201.06605</link><description>&lt;p&gt;
&#39640;&#32500;&#24230;&#19979;&#39063;&#31890;&#24037;&#20855;&#21464;&#37327;&#30340;&#25512;&#26029;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Inferential Theory for Granular Instrumental Variables in High Dimensions. (arXiv:2201.06605v2 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.06605
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25193;&#23637;&#20102;&#39063;&#31890;&#24037;&#20855;&#21464;&#37327;&#65288;GIV&#65289;&#26041;&#27861;&#65292;&#21253;&#25324;&#22312;&#22823;&#32500;&#24230;&#19979;&#30340;&#35782;&#21035;&#36807;&#31243;&#65292;&#22788;&#29702;&#26410;&#30693;&#30340;&#22240;&#23376;&#21644;&#21152;&#36733;&#65292;&#20197;&#21450;&#36890;&#36807;&#39069;&#22806;&#26500;&#24314;&#30340;&#24037;&#20855;&#21464;&#37327;&#36807;&#24230;&#35782;&#21035;&#32467;&#26500;&#21442;&#25968;&#65292;&#20174;&#32780;&#25552;&#39640;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39063;&#31890;&#24037;&#20855;&#21464;&#37327;&#65288;GIV&#65289;&#26041;&#27861;&#21033;&#29992;&#20855;&#26377;&#22240;&#23376;&#35823;&#24046;&#32467;&#26500;&#30340;&#38754;&#26495;&#25968;&#25454;&#26500;&#24314;&#24037;&#20855;&#21464;&#37327;&#65292;&#20197;&#20272;&#35745;&#21363;&#20351;&#22312;&#25511;&#21046;&#28508;&#22312;&#22240;&#23376;&#21518;&#20173;&#23384;&#22312;&#20869;&#29983;&#24615;&#30340;&#32467;&#26500;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#32500;&#24230;&#19978;&#25193;&#23637;&#20102;GIV&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23558;&#35782;&#21035;&#36807;&#31243;&#25193;&#23637;&#21040;&#22823;$N$&#21644;&#22823;$T$&#30340;&#26694;&#26550;&#20013;&#65292;&#36825;&#21462;&#20915;&#20110;$N$&#20010;&#25130;&#38754;&#21333;&#20301;&#35268;&#27169;&#20998;&#24067;&#30340;&#28176;&#36817;Herfindahl&#25351;&#25968;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#23558;&#22240;&#23376;&#21644;&#21152;&#36733;&#35270;&#20026;&#26410;&#30693;&#65292;&#24182;&#19988;&#22312;&#32771;&#34385;&#32467;&#26500;&#21442;&#25968;&#30340;&#26497;&#38480;&#20998;&#24067;&#26102;&#65292;&#35777;&#26126;&#20102;&#20272;&#35745;&#24037;&#20855;&#21464;&#37327;&#21644;&#22240;&#23376;&#30340;&#25277;&#26679;&#35823;&#24046;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#12290;&#31532;&#19977;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#20272;&#35745;&#31639;&#27861;&#20013;&#39640;&#32500;&#24230;&#31934;&#24230;&#30697;&#38453;&#30340;&#25277;&#26679;&#35823;&#24046;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#12290;&#31532;&#22235;&#65292;&#25105;&#20204;&#36890;&#36807;&#39069;&#22806;&#26500;&#24314;&#30340;&#24037;&#20855;&#21464;&#37327;&#36807;&#24230;&#35782;&#21035;&#32467;&#26500;&#21442;&#25968;&#65292;&#20174;&#32780;&#23454;&#29616;&#25928;&#29575;&#30340;&#25552;&#39640;&#12290;&#25552;&#20379;&#33945;&#29305;&#21345;&#27931;&#35777;&#25454;&#26469;&#25903;&#25345;&#25105;&#20204;&#30340;&#28176;&#36817;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Granular Instrumental Variables (GIV) methodology exploits panels with factor error structures to construct instruments to estimate structural time series models with endogeneity even after controlling for latent factors. We extend the GIV methodology in several dimensions. First, we extend the identification procedure to a large $N$ and large $T$ framework, which depends on the asymptotic Herfindahl index of the size distribution of $N$ cross-sectional units. Second, we treat both the factors and loadings as unknown and show that the sampling error in the estimated instrument and factors is negligible when considering the limiting distribution of the structural parameters. Third, we show that the sampling error in the high-dimensional precision matrix is negligible in our estimation algorithm. Fourth, we overidentify the structural parameters with additional constructed instruments, which leads to efficiency gains. Monte Carlo evidence is presented to support our asymptotic theory
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#24418;&#24335;&#27169;&#22411;&#21644;&#23454;&#39564;&#23460;&#23454;&#39564;&#32771;&#23519;&#20102;&#26426;&#22120;&#39044;&#27979;&#30340;&#24615;&#36136;&#22914;&#20309;&#24433;&#21709;&#20154;&#31867;&#26368;&#32456;&#20915;&#31574;&#12290;&#23454;&#39564;&#21457;&#29616;&#65292;&#21253;&#21547;&#26377;&#20559;&#35265;&#30340;&#20154;&#31867;&#20915;&#31574;&#32773;&#21487;&#33021;&#36870;&#36716;&#31639;&#27861;&#32467;&#26500;&#19982;&#20915;&#31574;&#36136;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#19988;&#25490;&#38500;&#21463;&#20445;&#25252;&#32676;&#20307;&#20449;&#24687;&#21487;&#33021;&#26080;&#27861;&#20943;&#23569;&#24046;&#24322;&#29978;&#33267;&#21487;&#33021;&#22686;&#21152;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2110.15310</link><description>&lt;p&gt;
&#20851;&#20110;&#26426;&#22120;&#36741;&#21161;&#20154;&#31867;&#20915;&#31574;&#30340;&#20844;&#27491;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Fairness of Machine-Assisted Human Decisions. (arXiv:2110.15310v2 [cs.CY] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.15310
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#24418;&#24335;&#27169;&#22411;&#21644;&#23454;&#39564;&#23460;&#23454;&#39564;&#32771;&#23519;&#20102;&#26426;&#22120;&#39044;&#27979;&#30340;&#24615;&#36136;&#22914;&#20309;&#24433;&#21709;&#20154;&#31867;&#26368;&#32456;&#20915;&#31574;&#12290;&#23454;&#39564;&#21457;&#29616;&#65292;&#21253;&#21547;&#26377;&#20559;&#35265;&#30340;&#20154;&#31867;&#20915;&#31574;&#32773;&#21487;&#33021;&#36870;&#36716;&#31639;&#27861;&#32467;&#26500;&#19982;&#20915;&#31574;&#36136;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#19988;&#25490;&#38500;&#21463;&#20445;&#25252;&#32676;&#20307;&#20449;&#24687;&#21487;&#33021;&#26080;&#27861;&#20943;&#23569;&#24046;&#24322;&#29978;&#33267;&#21487;&#33021;&#22686;&#21152;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#22312;&#39640;&#39118;&#38505;&#20915;&#31574;&#20013;&#34987;&#20351;&#29992;&#26102;&#65292;&#25105;&#20204;&#24076;&#26395;&#30830;&#20445;&#23427;&#20204;&#30340;&#37096;&#32626;&#33021;&#22815;&#20135;&#29983;&#20844;&#24179;&#21644;&#20844;&#27491;&#30340;&#32467;&#26524;&#12290;&#36825;&#20010;&#20851;&#27880;&#28857;&#20419;&#20351;&#20102;&#19968;&#20010;&#36805;&#36895;&#22686;&#38271;&#30340;&#25991;&#29486;&#65292;&#19987;&#27880;&#20110;&#35786;&#26029;&#21644;&#35299;&#20915;&#26426;&#22120;&#39044;&#27979;&#20013;&#30340;&#24046;&#24322;&#24615;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#26426;&#22120;&#39044;&#27979;&#34987;&#37096;&#32626;&#26469;&#21327;&#21161;&#20154;&#31867;&#20915;&#31574;&#32773;&#20445;&#30041;&#26368;&#32456;&#20915;&#31574;&#26435;&#12290;&#22240;&#27492;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22312;&#19968;&#20010;&#24418;&#24335;&#27169;&#22411;&#21644;&#23454;&#39564;&#23460;&#23454;&#39564;&#20013;&#32771;&#34385;&#20102;&#26426;&#22120;&#39044;&#27979;&#30340;&#24615;&#36136;&#22914;&#20309;&#24433;&#21709;&#26368;&#32456;&#30340;&#20154;&#31867;&#20915;&#31574;&#12290;&#22312;&#25105;&#20204;&#30340;&#32479;&#35745;&#20915;&#31574;&#24418;&#24335;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21253;&#21547;&#19968;&#20010;&#26377;&#20559;&#35265;&#30340;&#20154;&#31867;&#20915;&#31574;&#32773;&#21487;&#33021;&#36870;&#36716;&#31639;&#27861;&#32467;&#26500;&#19982;&#26368;&#32456;&#20915;&#31574;&#36136;&#37327;&#20043;&#38388;&#30340;&#24120;&#35268;&#20851;&#31995;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#35760;&#24405;&#20102;&#20174;&#39044;&#27979;&#20013;&#25490;&#38500;&#21463;&#20445;&#25252;&#32676;&#20307;&#20449;&#24687;&#21487;&#33021;&#26080;&#27861;&#20943;&#23569;&#29978;&#33267;&#21487;&#33021;&#22686;&#21152;&#26368;&#32456;&#24046;&#24322;&#30340;&#24773;&#20917;&#12290;&#22312;&#23454;&#39564;&#23460;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;...
&lt;/p&gt;
&lt;p&gt;
When machine-learning algorithms are used in high-stakes decisions, we want to ensure that their deployment leads to fair and equitable outcomes. This concern has motivated a fast-growing literature that focuses on diagnosing and addressing disparities in machine predictions. However, many machine predictions are deployed to assist in decisions where a human decision-maker retains the ultimate decision authority. In this article, we therefore consider in a formal model and in a lab experiment how properties of machine predictions affect the resulting human decisions. In our formal model of statistical decision-making, we show that the inclusion of a biased human decision-maker can revert common relationships between the structure of the algorithm and the qualities of resulting decisions. Specifically, we document that excluding information about protected groups from the prediction may fail to reduce, and may even increase, ultimate disparities. In the lab experiment, we demonstrate ho
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#33041;&#21147;&#39118;&#26292;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;BGAN&#65289;&#26550;&#26500;&#65292;&#23454;&#29616;&#22810;&#20010;&#20195;&#29702;&#22312;&#23436;&#20840;&#20998;&#24067;&#24335;&#30340;&#26041;&#24335;&#19979;&#29983;&#25104;&#31867;&#20284;&#30495;&#23454;&#25968;&#25454;&#30340;&#26679;&#26412;&#65292;&#35299;&#20915;&#20102;&#22810;&#20010;&#20195;&#29702;&#20849;&#20139;&#26377;&#38480;&#19988;&#20998;&#24067;&#24335;&#25968;&#25454;&#38598;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2002.00306</link><description>&lt;p&gt;
&#22522;&#20110;&#33041;&#21147;&#39118;&#26292;&#30340;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;BGAN&#65289;&#65306;&#38754;&#21521;&#20855;&#26377;&#20998;&#24067;&#24335;&#31169;&#26377;&#25968;&#25454;&#38598;&#30340;&#22810;&#20195;&#29702;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Brainstorming Generative Adversarial Networks (BGANs): Towards Multi-Agent Generative Models with Distributed Private Datasets. (arXiv:2002.00306v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2002.00306
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#33041;&#21147;&#39118;&#26292;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;BGAN&#65289;&#26550;&#26500;&#65292;&#23454;&#29616;&#22810;&#20010;&#20195;&#29702;&#22312;&#23436;&#20840;&#20998;&#24067;&#24335;&#30340;&#26041;&#24335;&#19979;&#29983;&#25104;&#31867;&#20284;&#30495;&#23454;&#25968;&#25454;&#30340;&#26679;&#26412;&#65292;&#35299;&#20915;&#20102;&#22810;&#20010;&#20195;&#29702;&#20849;&#20139;&#26377;&#38480;&#19988;&#20998;&#24067;&#24335;&#25968;&#25454;&#38598;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35201;&#23454;&#29616;&#39640;&#23398;&#20064;&#20934;&#30830;&#24615;&#65292;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#24517;&#39035;&#20197;&#20805;&#20998;&#20195;&#34920;&#25968;&#25454;&#31354;&#38388;&#30340;&#22823;&#22411;&#25968;&#25454;&#38598;&#20316;&#20026;&#36755;&#20837;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#21487;&#29992;&#30340;&#25968;&#25454;&#38598;&#21487;&#33021;&#26159;&#26377;&#38480;&#30340;&#65292;&#24182;&#19988;&#20998;&#24067;&#22312;&#22810;&#20010;&#20195;&#29702;&#20043;&#38388;&#65292;&#27599;&#20010;&#20195;&#29702;&#37117;&#35797;&#22270;&#21333;&#29420;&#23398;&#20064;&#25968;&#25454;&#30340;&#20998;&#24067;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20195;&#29702;&#36890;&#24120;&#19981;&#24895;&#20849;&#20139;&#20182;&#20204;&#30340;&#26412;&#22320;&#25968;&#25454;&#65292;&#22240;&#20026;&#36825;&#21487;&#33021;&#23548;&#33268;&#22823;&#22411;&#25968;&#25454;&#38598;&#30340;&#36890;&#20449;&#24320;&#38144;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#33041;&#21147;&#39118;&#26292;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;BGAN&#65289;&#26550;&#26500;&#65292;&#29992;&#20110;&#35299;&#20915;&#36825;&#20010;&#22810;&#20195;&#29702;GAN&#38382;&#39064;&#65292;&#22810;&#20010;&#20195;&#29702;&#21487;&#20197;&#22312;&#23436;&#20840;&#20998;&#24067;&#24335;&#30340;&#26041;&#24335;&#19979;&#29983;&#25104;&#31867;&#20284;&#30495;&#23454;&#25968;&#25454;&#30340;&#26679;&#26412;&#12290;BGAN&#20801;&#35768;&#20195;&#29702;&#36890;&#36807;&#20849;&#20139;&#29983;&#25104;&#30340;&#25968;&#25454;&#26679;&#26412;&#32780;&#19981;&#26159;&#23454;&#38469;&#25968;&#25454;&#38598;&#36827;&#34892;&#8220;&#33041;&#21147;&#39118;&#26292;&#8221;&#26469;&#33719;&#21462;&#26469;&#33258;&#20854;&#20182;&#20195;&#29702;&#30340;&#20449;&#24687;&#12290;&#19982;&#29616;&#26377;&#30340;&#20998;&#24067;&#24335;GAN&#35299;&#20915;&#26041;&#26696;&#30456;&#27604;&#65292;&#25152;&#25552;&#20986;&#30340;BGAN&#26550;&#26500;&#34987;&#35774;&#35745;&#20026;&#23436;&#20840;&#20998;&#24067;&#24335;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#21442;&#19982;&#26041;&#24444;&#27492;&#36890;&#20449;&#12290;
&lt;/p&gt;
&lt;p&gt;
To achieve a high learning accuracy, generative adversarial networks (GANs) must be fed by large datasets that adequately represent the data space. However, in many scenarios, the available datasets may be limited and distributed across multiple agents, each of which is seeking to learn the distribution of the data on its own. In such scenarios, the agents often do not wish to share their local data as it can cause communication overhead for large datasets. In this paper, to address this multi-agent GAN problem, a novel brainstorming GAN (BGAN) architecture is proposed using which multiple agents can generate real-like data samples while operating in a fully distributed manner. BGAN allows the agents to gain information from other agents without sharing their real datasets but by ``brainstorming'' via the sharing of their generated data samples. In contrast to existing distributed GAN solutions, the proposed BGAN architecture is designed to be fully distributed, and it does not need an
&lt;/p&gt;</description></item></channel></rss>