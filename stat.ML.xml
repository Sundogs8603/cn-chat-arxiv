<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#23383;&#20856;&#23398;&#20064;&#20013;&#20004;&#31181;&#20132;&#26367;&#26497;&#23567;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#65292;&#22312;&#33391;&#22909;&#30340;&#21021;&#22987;&#21270;&#19979;&#65292;&#36825;&#20004;&#31181;&#31639;&#27861;&#33021;&#22815;&#20197;&#20960;&#20309;&#25910;&#25947;&#36895;&#29575;&#25910;&#25947;&#20110;&#29983;&#25104;&#30340;&#23383;&#20856;&#65292;&#19988;&#21487;&#36866;&#29992;&#20110;&#38750;&#22343;&#21248;&#20998;&#24067;&#30340;&#25968;&#25454;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2304.01768</link><description>&lt;p&gt;
&#23383;&#20856;&#23398;&#20064;&#20013;&#20132;&#26367;&#26497;&#23567;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Convergence of alternating minimisation algorithms for dictionary learning. (arXiv:2304.01768v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01768
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#23383;&#20856;&#23398;&#20064;&#20013;&#20004;&#31181;&#20132;&#26367;&#26497;&#23567;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#65292;&#22312;&#33391;&#22909;&#30340;&#21021;&#22987;&#21270;&#19979;&#65292;&#36825;&#20004;&#31181;&#31639;&#27861;&#33021;&#22815;&#20197;&#20960;&#20309;&#25910;&#25947;&#36895;&#29575;&#25910;&#25947;&#20110;&#29983;&#25104;&#30340;&#23383;&#20856;&#65292;&#19988;&#21487;&#36866;&#29992;&#20110;&#38750;&#22343;&#21248;&#20998;&#24067;&#30340;&#25968;&#25454;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23548;&#20986;&#20102;&#38024;&#23545;&#23383;&#20856;&#23398;&#20064;&#20004;&#31181;&#27969;&#34892;&#30340;&#20132;&#26367;&#26497;&#23567;&#21270;&#31639;&#27861; - &#26368;&#20248;&#26041;&#21521;&#27861;&#65288;MOD&#65289;&#21644;&#22312;&#32447;&#23383;&#20856;&#23398;&#20064;&#65288;ODL&#65289;&#30340;&#25910;&#25947;&#24615;&#36275;&#22815;&#30340;&#26465;&#20214;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#21482;&#35201;&#21021;&#22987;&#20540;&#33391;&#22909;&#65292;&#21363;&#36317;&#31163;&#29983;&#25104;&#30340;&#23383;&#20856;&#19981;&#36229;&#36807;$1/\log(K)$&#25110;&#20855;&#26377;&#19968;&#23450;&#30340;&#32467;&#26500;&#65292;&#30830;&#20445;&#21021;&#22987;&#20540;&#20013;&#30340;&#27599;&#20010;&#20803;&#32032;&#21482;&#25351;&#21521;&#19968;&#20010;&#29983;&#25104;&#20803;&#65292;&#20004;&#31181;&#31639;&#27861;&#23558;&#20197;&#20960;&#20309;&#25910;&#25947;&#36895;&#29575;&#25910;&#25947;&#20110;&#29983;&#25104;&#30340;&#23383;&#20856;&#12290;&#36825;&#22312;&#20855;&#26377;&#38750;&#22343;&#21248;&#20998;&#24067;&#30340;&#25968;&#25454;&#27169;&#22411;&#19978;&#20063;&#33021;&#23454;&#29616;&#65292;&#35813;&#27169;&#22411;&#20013;&#31232;&#30095;&#31995;&#25968;&#30340;&#25903;&#25745;&#38598;&#30340;&#20986;&#29616;&#39057;&#29575;&#21487;&#20197;&#21464;&#21270;&#24456;&#22823;&#65292;&#20174;&#32780;&#26356;&#25509;&#36817;&#30495;&#23454;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we derive sufficient conditions for the convergence of two popular alternating minimisation algorithms for dictionary learning - the Method of Optimal Directions (MOD) and Online Dictionary Learning (ODL), which can also be thought of as approximative K-SVD. We show that given a well-behaved initialisation that is either within distance at most $1/\log(K)$ to the generating dictionary or has a special structure ensuring that each element of the initialisation only points to one generating element, both algorithms will converge with geometric convergence rate to the generating dictionary. This is done even for data models with non-uniform distributions on the supports of the sparse coefficients. These allow the appearance frequency of the dictionary elements to vary heavily and thus model real data more closely.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#23398;&#20064;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNNs&#65289;&#30340;&#23545;&#27604;&#26694;&#26550;&#65292;&#36890;&#36807;&#35813;&#26694;&#26550;&#25552;&#20986;&#20102;&#19968;&#31181;&#21516;&#26102;&#20855;&#22791;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#26631;&#31614;&#25928;&#29575;&#21644;&#36125;&#21494;&#26031;&#26041;&#27861;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#23454;&#29992;BNN&#31639;&#27861;&#12290;&#26368;&#21518;&#65292;&#35813;&#26041;&#27861;&#22312;&#21322;&#30417;&#30563;&#21644;&#20302;&#39044;&#31639;&#20027;&#21160;&#23398;&#20064;&#38382;&#39064;&#20013;&#23637;&#29616;&#20986;&#20102;&#25968;&#25454;&#39640;&#25928;&#23398;&#20064;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2304.01762</link><description>&lt;p&gt;
&#23558;&#26410;&#26631;&#35760;&#25968;&#25454;&#32435;&#20837;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20013;
&lt;/p&gt;
&lt;p&gt;
Incorporating Unlabelled Data into Bayesian Neural Networks. (arXiv:2304.01762v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01762
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#23398;&#20064;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNNs&#65289;&#30340;&#23545;&#27604;&#26694;&#26550;&#65292;&#36890;&#36807;&#35813;&#26694;&#26550;&#25552;&#20986;&#20102;&#19968;&#31181;&#21516;&#26102;&#20855;&#22791;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#26631;&#31614;&#25928;&#29575;&#21644;&#36125;&#21494;&#26031;&#26041;&#27861;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#23454;&#29992;BNN&#31639;&#27861;&#12290;&#26368;&#21518;&#65292;&#35813;&#26041;&#27861;&#22312;&#21322;&#30417;&#30563;&#21644;&#20302;&#39044;&#31639;&#20027;&#21160;&#23398;&#20064;&#38382;&#39064;&#20013;&#23637;&#29616;&#20986;&#20102;&#25968;&#25454;&#39640;&#25928;&#23398;&#20064;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23545;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNNs&#65289;&#20013;&#20808;&#39564;&#20998;&#24067;&#36827;&#34892;&#23398;&#20064;&#30340;&#23545;&#27604;&#26694;&#26550;&#65292;&#21033;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#26469;&#20248;&#21270;&#12290;&#22522;&#20110;&#35813;&#26694;&#26550;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;BNN&#31639;&#27861;&#65292;&#21516;&#26102;&#20855;&#22791;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#26631;&#31614;&#25928;&#29575;&#21644;&#36125;&#21494;&#26031;&#26041;&#27861;&#20013;&#30340;&#26681;&#25454;&#21407;&#21017;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21322;&#30417;&#30563;&#21644;&#20302;&#39044;&#31639;&#20027;&#21160;&#23398;&#20064;&#38382;&#39064;&#20013;&#30340;&#25968;&#25454;&#39640;&#25928;&#23398;&#20064;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a contrastive framework for learning better prior distributions for Bayesian Neural Networks (BNNs) using unlabelled data. With this framework, we propose a practical BNN algorithm that offers the label-efficiency of self-supervised learning and the principled uncertainty estimates of Bayesian methods. Finally, we demonstrate the advantages of our approach for data-efficient learning in semi-supervised and low-budget active learning problems.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25506;&#35752;&#20102;&#22312;XAI&#26041;&#27861;&#20013;&#32771;&#34385;&#39044;&#27979;&#21464;&#37327;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#24555;&#36895;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20854;&#27169;&#22411;&#26080;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.01717</link><description>&lt;p&gt;
&#25581;&#31034;XAI&#26041;&#27861;&#20013;&#20381;&#36182;&#29305;&#24449;&#30340;&#36129;&#29486;
&lt;/p&gt;
&lt;p&gt;
Characterizing the contribution of dependent features in XAI methods. (arXiv:2304.01717v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01717
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25506;&#35752;&#20102;&#22312;XAI&#26041;&#27861;&#20013;&#32771;&#34385;&#39044;&#27979;&#21464;&#37327;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#24555;&#36895;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20854;&#27169;&#22411;&#26080;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#25552;&#20379;&#20102;&#24037;&#20855;&#65292;&#24110;&#21161;&#29702;&#35299;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#24037;&#20316;&#21407;&#29702;&#21644;&#23454;&#29616;&#29305;&#23450;&#32467;&#26524;&#30340;&#26041;&#27861;&#12290;&#23427;&#26377;&#21161;&#20110;&#22686;&#21152;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#20351;&#24471;&#27169;&#22411;&#26356;&#20026;&#21487;&#20449;&#21644;&#36879;&#26126;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#35768;&#22810;XAI&#26041;&#27861;&#34987;&#25552;&#20986;&#65292;&#20854;&#20013;SHAP&#21644;LIME&#26368;&#24191;&#20026;&#20154;&#30693;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#20551;&#35774;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#20351;&#29992;&#30340;&#39044;&#27979;&#21464;&#37327;&#30456;&#20114;&#29420;&#31435;&#65292;&#36825;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#24182;&#19981;&#19968;&#23450;&#25104;&#31435;&#12290;&#36825;&#31181;&#20551;&#35774;&#20351;&#24471;XAI&#32467;&#26524;&#30340;&#31283;&#20581;&#24615;&#21463;&#21040;&#24433;&#21709;&#65292;&#27604;&#22914;&#20449;&#24687;&#39044;&#27979;&#21464;&#37327;&#30340;&#21015;&#34920;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#20294;&#26377;&#29992;&#30340;&#20195;&#29702;&#65292;&#20462;&#25913;&#20219;&#20309;XAI&#29305;&#24449;&#25490;&#21517;&#26041;&#27861;&#30340;&#32467;&#26524;&#65292;&#20351;&#20854;&#33021;&#22815;&#32771;&#34385;&#39044;&#27979;&#21464;&#37327;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20855;&#26377;&#27169;&#22411;&#26080;&#20851;&#24615;&#65292;&#24182;&#19988;&#21487;&#20197;&#31616;&#21333;&#22320;&#35745;&#31639;&#22312;&#20849;&#32447;&#24615;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#27599;&#20010;&#39044;&#27979;&#21464;&#37327;&#22312;&#27169;&#22411;&#20013;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Explainable Artificial Intelligence (XAI) provides tools to help understanding how the machine learning models work and reach a specific outcome. It helps to increase the interpretability of models and makes the models more trustworthy and transparent. In this context, many XAI methods were proposed being SHAP and LIME the most popular. However, the proposed methods assume that used predictors in the machine learning models are independent which in general is not necessarily true. Such assumption casts shadows on the robustness of the XAI outcomes such as the list of informative predictors. Here, we propose a simple, yet useful proxy that modifies the outcome of any XAI feature ranking method allowing to account for the dependency among the predictors. The proposed approach has the advantage of being model-agnostic as well as simple to calculate the impact of each predictor in the model in presence of collinearity.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#38750;&#32447;&#24615;&#31995;&#32479;&#21160;&#24577;&#30340;&#21453;&#21521;&#26080;&#21619;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;I-UKF&#65289;&#20197;&#21450;&#22522;&#20110;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;UKF&#65288;RKHS-UKF&#65289;&#65292;&#29992;&#20110;&#23398;&#20064;&#26410;&#30693;&#30340;&#31995;&#32479;&#27169;&#22411;&#24182;&#20272;&#35745;&#29366;&#24577;&#12290;</title><link>http://arxiv.org/abs/2304.01698</link><description>&lt;p&gt;
&#21453;&#21521;&#26080;&#21619;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;
&lt;/p&gt;
&lt;p&gt;
Inverse Unscented Kalman Filter. (arXiv:2304.01698v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01698
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#38750;&#32447;&#24615;&#31995;&#32479;&#21160;&#24577;&#30340;&#21453;&#21521;&#26080;&#21619;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;I-UKF&#65289;&#20197;&#21450;&#22522;&#20110;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;UKF&#65288;RKHS-UKF&#65289;&#65292;&#29992;&#20110;&#23398;&#20064;&#26410;&#30693;&#30340;&#31995;&#32479;&#27169;&#22411;&#24182;&#20272;&#35745;&#29366;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35774;&#35745;&#35748;&#30693;&#21644;&#21453;&#23545;&#25163;&#31995;&#32479;&#30340;&#24555;&#36895;&#36827;&#27493;&#20419;&#36827;&#20102;&#21453;&#36125;&#21494;&#26031;&#28388;&#27874;&#22120;&#30340;&#21457;&#23637;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#35748;&#30693;&#8220;&#23545;&#25163;&#8221;&#36890;&#36807;&#38543;&#26426;&#26694;&#26550;&#65288;&#22914;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;KF&#65289;&#65289;&#36319;&#36394;&#20854;&#24863;&#20852;&#36259;&#30340;&#30446;&#26631;&#12290;&#28982;&#21518;&#65292;&#30446;&#26631;&#25110;&#8220;&#38450;&#24481;&#32773;&#8221;&#20351;&#29992;&#21478;&#19968;&#20010;&#36870;&#38543;&#26426;&#28388;&#27874;&#22120;&#26469;&#25512;&#26029;&#36890;&#36807;&#23545;&#25163;&#35745;&#31639;&#30340;&#38450;&#24481;&#32773;&#30340;&#21069;&#21521;&#28388;&#27874;&#22120;&#20272;&#35745;&#12290;&#23545;&#20110;&#32447;&#24615;&#31995;&#32479;&#65292;&#26368;&#36817;&#24050;&#32463;&#35777;&#26126;&#20102;&#36870;Kalman&#28388;&#27874;&#22120;&#65288;I-KF&#65289;&#22312;&#36825;&#20123;&#21453;&#23545;&#25239;&#24212;&#29992;&#20013;&#26159;&#26377;&#25928;&#30340;&#12290;&#26412;&#25991;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;&#30456;&#21453;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#38750;&#32447;&#24615;&#31995;&#32479;&#21160;&#24577;&#24182;&#21046;&#23450;&#36870;&#38750;&#32447;&#24615;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;I-UKF&#65289;&#65292;&#20197;&#20272;&#35745;&#38450;&#24481;&#32773;&#30340;&#29366;&#24577;&#24182;&#20943;&#23567;&#32447;&#24615;&#21270;&#35823;&#24046;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#19968;&#26694;&#26550;&#25512;&#24191;&#21040;&#26410;&#30693;&#31995;&#32479;&#27169;&#22411;&#65292;&#36890;&#36807;&#25552;&#20986;&#22522;&#20110;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;UKF&#65288;RKHS-UKF&#65289;&#26469;&#23398;&#20064;&#31995;&#32479;&#21160;&#24577;&#24182;&#22522;&#20110;&#20854;&#35266;&#27979;&#26469;&#20272;&#35745;&#29366;&#24577;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#26088;&#22312;&#20445;&#35777;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#38543;&#26426;&#31283;&#23450;&#24615;&#65292;&#24182;&#36827;&#34892;&#25968;&#20540;&#27169;&#25311;&#20197;&#35777;&#23454;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Rapid advances in designing cognitive and counter-adversarial systems have motivated the development of inverse Bayesian filters. In this setting, a cognitive `adversary' tracks its target of interest via a stochastic framework such as a Kalman filter (KF). The target or `defender' then employs another inverse stochastic filter to infer the forward filter estimates of the defender computed by the adversary. For linear systems, inverse Kalman filter (I-KF) has been recently shown to be effective in these counter-adversarial applications. In the paper, contrary to prior works, we focus on non-linear system dynamics and formulate the inverse unscented KF (I-UKF) to estimate the defender's state with reduced linearization errors. We then generalize this framework to an unknown system model by proposing reproducing kernel Hilbert space-based UKF (RKHS-UKF) to learn the system dynamics and estimate the state based on its observations. Our theoretical analyses to guarantee the stochastic stab
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Shallow ReLU$^k$&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#23481;&#37327;&#65292;&#35777;&#26126;&#20102;&#20854;&#26368;&#20248;&#36924;&#36817;&#36895;&#29575;&#12290;&#24212;&#29992;&#21040;&#38750;&#21442;&#25968;&#22238;&#24402;&#19978;&#65292;&#35777;&#26126;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23454;&#29616;&#23398;&#20064;H\"older&#20989;&#25968;&#30340;&#26368;&#20248;&#28176;&#36827;&#36895;&#29575;&#65292;&#34917;&#20805;&#20102;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#36817;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.01561</link><description>&lt;p&gt;
Shallow ReLU$^k$&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#36895;&#29575;&#21450;&#20854;&#22312;&#38750;&#21442;&#25968;&#22238;&#24402;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Optimal rates of approximation by shallow ReLU$^k$ neural networks and applications to nonparametric regression. (arXiv:2304.01561v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01561
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Shallow ReLU$^k$&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#23481;&#37327;&#65292;&#35777;&#26126;&#20102;&#20854;&#26368;&#20248;&#36924;&#36817;&#36895;&#29575;&#12290;&#24212;&#29992;&#21040;&#38750;&#21442;&#25968;&#22238;&#24402;&#19978;&#65292;&#35777;&#26126;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23454;&#29616;&#23398;&#20064;H\"older&#20989;&#25968;&#30340;&#26368;&#20248;&#28176;&#36827;&#36895;&#29575;&#65292;&#34917;&#20805;&#20102;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#36817;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#19982;Shallow ReLU$^k$&#31070;&#32463;&#32593;&#32476;&#30456;&#20851;&#30340;&#21464;&#24322;&#31354;&#38388;&#30340;&#36924;&#36817;&#23481;&#37327;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#26377;&#38480;&#21464;&#24322;&#33539;&#25968;&#19979;&#65292;&#23481;&#32435;&#20102;&#36275;&#22815;&#24179;&#28369;&#30340;&#20989;&#25968;&#12290;&#23545;&#20110;&#36739;&#23569;&#24179;&#28369;&#30340;&#20989;&#25968;&#65292;&#26681;&#25454;&#21464;&#24322;&#33539;&#25968;&#24314;&#31435;&#20102;&#36924;&#36817;&#36895;&#29575;&#12290;&#36816;&#29992;&#36825;&#20123;&#32467;&#26524;&#65292;&#25105;&#20204;&#21487;&#20197;&#35777;&#26126;Shallow ReLU$^k$&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#20248;&#36924;&#36817;&#36895;&#29575;&#12290;&#21516;&#26102;&#38416;&#26126;&#20102;&#36825;&#20123;&#32467;&#26524;&#22914;&#20309;&#29992;&#20110;&#25512;&#23548;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#21644;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(CNNs)&#30340;&#36924;&#36817;&#30028;&#38480;&#12290;&#20026;&#24212;&#29992;&#30740;&#31350;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#19977;&#31181;ReLU&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65306;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#36229;&#21442;&#25968;&#31070;&#32463;&#32593;&#32476;&#21644;CNN&#36827;&#34892;&#38750;&#21442;&#25968;&#22238;&#24402;&#25910;&#25947;&#36895;&#29575;&#30740;&#31350;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23454;&#29616;&#23398;&#20064;H\"older&#20989;&#25968;&#30340;&#26368;&#20248;&#28176;&#36827;&#36895;&#29575;&#65292;&#36825;&#34917;&#20805;&#20102;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#36817;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the approximation capacity of some variation spaces corresponding to shallow ReLU$^k$ neural networks. It is shown that sufficiently smooth functions are contained in these spaces with finite variation norms. For functions with less smoothness, the approximation rates in terms of the variation norm are established. Using these results, we are able to prove the optimal approximation rates in terms of the number of neurons for shallow ReLU$^k$ neural networks. It is also shown how these results can be used to derive approximation bounds for deep neural networks and convolutional neural networks (CNNs). As applications, we study convergence rates for nonparametric regression using three ReLU neural network models: shallow neural network, over-parameterized neural network, and CNN. In particular, we show that shallow neural networks can achieve the minimax optimal rates for learning H\"older functions, which complements recent results for deep neural networks. It is also proven th
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#36890;&#20449;&#21644;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#19979;&#65292;&#24179;&#22343;&#20540;&#21644;&#39057;&#29575;&#20272;&#35745;&#30340;&#26368;&#20248;&#20934;&#30830;&#24615;&#65292;&#35777;&#26126;&#27599;&#20010;&#23458;&#25143;&#31471;&#21482;&#38656;&#21457;&#36865;$\Theta\left( n \min\left(\varepsilon, \varepsilon^2\right)\right)$&#27604;&#29305;&#30340;FL&#38382;&#39064;&#21644;$\Theta\left(\log\left( n\min\left(\varepsilon, \varepsilon^2\right) \right)\right)$&#27604;&#29305;&#30340;FA&#38382;&#39064;&#21363;&#21487;&#23454;&#29616;&#26368;&#20248;&#35823;&#24046;&#65292;&#20174;&#32780;&#22312;&#32852;&#21512;&#23398;&#20064;&#21644;&#20998;&#26512;&#20013;&#23454;&#29616;&#20102;&#38544;&#31169;&#12289;&#31934;&#30830;&#24615;&#21644;&#36890;&#20449;&#30340;&#26368;&#20248;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2304.01541</link><description>&lt;p&gt;
&#36890;&#36807;&#21387;&#32553;&#23454;&#29616;&#38544;&#31169;&#25918;&#22823;&#65306;&#22312;&#20998;&#24067;&#24335;&#22343;&#20540;&#20272;&#35745;&#20013;&#23454;&#29616;&#26368;&#20248;&#38544;&#31169;-&#31934;&#24230;-&#36890;&#20449;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
Privacy Amplification via Compression: Achieving the Optimal Privacy-Accuracy-Communication Trade-off in Distributed Mean Estimation. (arXiv:2304.01541v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01541
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#36890;&#20449;&#21644;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#19979;&#65292;&#24179;&#22343;&#20540;&#21644;&#39057;&#29575;&#20272;&#35745;&#30340;&#26368;&#20248;&#20934;&#30830;&#24615;&#65292;&#35777;&#26126;&#27599;&#20010;&#23458;&#25143;&#31471;&#21482;&#38656;&#21457;&#36865;$\Theta\left( n \min\left(\varepsilon, \varepsilon^2\right)\right)$&#27604;&#29305;&#30340;FL&#38382;&#39064;&#21644;$\Theta\left(\log\left( n\min\left(\varepsilon, \varepsilon^2\right) \right)\right)$&#27604;&#29305;&#30340;FA&#38382;&#39064;&#21363;&#21487;&#23454;&#29616;&#26368;&#20248;&#35823;&#24046;&#65292;&#20174;&#32780;&#22312;&#32852;&#21512;&#23398;&#20064;&#21644;&#20998;&#26512;&#20013;&#23454;&#29616;&#20102;&#38544;&#31169;&#12289;&#31934;&#30830;&#24615;&#21644;&#36890;&#20449;&#30340;&#26368;&#20248;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38544;&#31169;&#21644;&#36890;&#20449;&#32422;&#26463;&#26159;&#32852;&#21512;&#23398;&#20064;&#65288;FL&#65289;&#21644;&#20998;&#26512;&#65288;FA&#65289;&#20013;&#30340;&#20004;&#20010;&#20027;&#35201;&#29942;&#39048;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32852;&#21512;&#36890;&#20449;&#21644;$(\varepsilon, \delta)$-&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#32422;&#26463;&#19979;&#24179;&#22343;&#20540;&#21644;&#39057;&#29575;&#20272;&#35745;&#65288;FL&#21644;FA&#30340;&#26631;&#20934;&#27169;&#22411;&#65289;&#30340;&#26368;&#20248;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20026;&#20102;&#22312;$(\varepsilon, \delta)$-DP&#19979;&#36798;&#21040;&#26368;&#20248;&#35823;&#24046;&#65292;&#27599;&#20010;&#23458;&#25143;&#31471;&#21482;&#38656;&#35201;&#21521;&#26381;&#21153;&#22120;&#21457;&#36865;$\Theta\left( n \min\left(\varepsilon, \varepsilon^2\right)\right)$&#27604;&#29305;&#30340;FL&#38382;&#39064;&#21644;$\Theta\left(\log\left( n\min\left(\varepsilon, \varepsilon^2\right) \right)\right)$&#27604;&#29305;&#30340;FA&#38382;&#39064;&#12290;&#22914;&#26524;&#27809;&#26377;&#21387;&#32553;&#65292;&#27599;&#20010;&#23458;&#25143;&#26426;&#38656;&#35201;$O(d)$&#27604;&#29305;&#21644;$\log d$&#27604;&#29305;&#26469;&#35299;&#20915;&#24179;&#22343;&#20540;&#20272;&#35745;&#21644;&#39057;&#29575;&#20272;&#35745;&#38382;&#39064;&#65288;&#20854;&#20013;$d$&#23545;&#24212;&#20110;FL&#20013;&#21487;&#35757;&#32451;&#21442;&#25968;&#30340;&#25968;&#37327;&#25110;FA&#20013;&#22495;&#30340;&#22823;&#23567;&#65289;&#65292;&#36825;&#24847;&#21619;&#30528;&#25105;&#20204;&#21487;&#20197;&#33719;&#24471;&#22312;$n\min\left(\varepsilon,\varepsilon^2\right)$&#30340;&#21306;&#38388;&#20013;&#33719;&#24471;&#26174;&#33879;&#30340;&#33410;&#30465;&#12290;
&lt;/p&gt;
&lt;p&gt;
Privacy and communication constraints are two major bottlenecks in federated learning (FL) and analytics (FA). We study the optimal accuracy of mean and frequency estimation (canonical models for FL and FA respectively) under joint communication and $(\varepsilon, \delta)$-differential privacy (DP) constraints. We show that in order to achieve the optimal error under $(\varepsilon, \delta)$-DP, it is sufficient for each client to send $\Theta\left( n \min\left(\varepsilon, \varepsilon^2\right)\right)$ bits for FL and $\Theta\left(\log\left( n\min\left(\varepsilon, \varepsilon^2\right) \right)\right)$ bits for FA to the server, where $n$ is the number of participating clients. Without compression, each client needs $O(d)$ bits and $\log d$ bits for the mean and frequency estimation problems respectively (where $d$ corresponds to the number of trainable parameters in FL or the domain size in FA), which means that we can get significant savings in the regime $ n \min\left(\varepsilon, \va
&lt;/p&gt;</description></item><item><title>OneShotSTL&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#20934;&#30830;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#32447;&#26102;&#38388;&#24207;&#21015;&#20998;&#35299;&#65292;&#22312;&#22788;&#29702;&#26102;&#38388;&#19978;&#20165;&#38656;O(1)&#30340;&#26356;&#26032;&#26102;&#38388;&#22797;&#26434;&#24230;&#65292;&#24182;&#21487;&#21516;&#26102;&#20445;&#25345;&#36739;&#39640;&#30340;&#31934;&#24230;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#25209;&#22788;&#29702;&#26041;&#27861;&#26080;&#27861;&#25903;&#25345;&#23454;&#26102;&#20998;&#26512;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2304.01506</link><description>&lt;p&gt;
OneShotSTL&#65306;&#19968;&#31181;&#21333;&#27425;&#23395;&#33410;&#36235;&#21183;&#20998;&#35299;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#32447;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#21644;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
OneShotSTL: One-Shot Seasonal-Trend Decomposition For Online Time Series Anomaly Detection And Forecasting. (arXiv:2304.01506v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01506
&lt;/p&gt;
&lt;p&gt;
OneShotSTL&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#20934;&#30830;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#32447;&#26102;&#38388;&#24207;&#21015;&#20998;&#35299;&#65292;&#22312;&#22788;&#29702;&#26102;&#38388;&#19978;&#20165;&#38656;O(1)&#30340;&#26356;&#26032;&#26102;&#38388;&#22797;&#26434;&#24230;&#65292;&#24182;&#21487;&#21516;&#26102;&#20445;&#25345;&#36739;&#39640;&#30340;&#31934;&#24230;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#25209;&#22788;&#29702;&#26041;&#27861;&#26080;&#27861;&#25903;&#25345;&#23454;&#26102;&#20998;&#26512;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23395;&#33410;&#36235;&#21183;&#20998;&#35299;&#26159;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#20013;&#26368;&#22522;&#26412;&#30340;&#27010;&#24565;&#20043;&#19968;&#65292;&#23427;&#25903;&#25345;&#21253;&#25324;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#21644;&#39044;&#27979;&#22312;&#20869;&#30340;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#20998;&#35299;&#26041;&#27861;&#20381;&#36182;&#20110;&#25209;&#22788;&#29702;&#65292;&#26102;&#38388;&#22797;&#26434;&#24230;&#20026;O(W)&#65292;&#20854;&#20013;W&#26159;&#26102;&#38388;&#31383;&#21475;&#20869;&#30340;&#25968;&#25454;&#28857;&#25968;&#12290;&#22240;&#27492;&#65292;&#23427;&#20204;&#19981;&#33021;&#22987;&#32456;&#26377;&#25928;&#22320;&#25903;&#25345;&#38656;&#35201;&#20302;&#22788;&#29702;&#24310;&#36831;&#30340;&#23454;&#26102;&#20998;&#26512;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;OneShotSTL&#65292;&#36825;&#26159;&#19968;&#31181;&#39640;&#25928;&#21644;&#20934;&#30830;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#32447;&#19978;&#23545;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#20998;&#35299;&#65292;&#26356;&#26032;&#26102;&#38388;&#22797;&#26434;&#24230;&#20026;O(1)&#12290;OneShotSTL&#27604;&#25209;&#22788;&#29702;&#26041;&#27861;&#24555;10&#20493;&#20197;&#19978;&#65292;&#31934;&#24230;&#19982;&#26368;&#20339;&#23545;&#25163;&#30456;&#24403;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#22312;&#19979;&#28216;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#21644;&#39044;&#27979;&#20219;&#21153;&#30340;&#30495;&#23454;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#26126;&#65292;OneShotSTL&#27604;&#29616;&#26377;&#25216;&#26415;&#24555;10&#20493;&#20197;&#19978;&#65292;&#21516;&#26102;&#20173;&#25552;&#20379;&#30456;&#24403;&#29978;&#33267;&#26356;&#22909;&#30340;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Seasonal-trend decomposition is one of the most fundamental concepts in time series analysis that supports various downstream tasks, including time series anomaly detection and forecasting. However, existing decomposition methods rely on batch processing with a time complexity of O(W), where W is the number of data points within a time window. Therefore, they cannot always efficiently support real-time analysis that demands low processing delay. To address this challenge, we propose OneShotSTL, an efficient and accurate algorithm that can decompose time series online with an update time complexity of O(1). OneShotSTL is more than $1,000$ times faster than the batch methods, with accuracy comparable to the best counterparts. Extensive experiments on real-world benchmark datasets for downstream time series anomaly detection and forecasting tasks demonstrate that OneShotSTL is from 10 to over 1,000 times faster than the state-of-the-art methods, while still providing comparable or even be
&lt;/p&gt;</description></item><item><title>&#24102;&#26377;&#32467;&#26500;&#24615;&#32570;&#22833;&#30340;&#25968;&#25454;&#23398;&#20064;&#26159;&#19968;&#20010;&#23578;&#26410;&#34987;&#31995;&#32479;&#35299;&#20915;&#30340;&#38382;&#39064;&#65292;&#23427;&#23545;&#35268;&#27169;&#21270;&#30340;&#26426;&#22120;&#23398;&#20064;&#26500;&#25104;&#20102;&#37325;&#35201;&#38459;&#30861;&#65292;&#24182;&#19988;&#38656;&#35201;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#21644;&#35299;&#20915;&#12290;</title><link>http://arxiv.org/abs/2304.01429</link><description>&lt;p&gt;
&#24102;&#26377;&#32467;&#26500;&#24615;&#32570;&#22833;&#30340;&#25968;&#25454;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning from data with structured missingness. (arXiv:2304.01429v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01429
&lt;/p&gt;
&lt;p&gt;
&#24102;&#26377;&#32467;&#26500;&#24615;&#32570;&#22833;&#30340;&#25968;&#25454;&#23398;&#20064;&#26159;&#19968;&#20010;&#23578;&#26410;&#34987;&#31995;&#32479;&#35299;&#20915;&#30340;&#38382;&#39064;&#65292;&#23427;&#23545;&#35268;&#27169;&#21270;&#30340;&#26426;&#22120;&#23398;&#20064;&#26500;&#25104;&#20102;&#37325;&#35201;&#38459;&#30861;&#65292;&#24182;&#19988;&#38656;&#35201;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#21644;&#35299;&#20915;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32570;&#22833;&#25968;&#25454;&#26159;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#19981;&#21487;&#36991;&#20813;&#30340;&#22797;&#26434;&#38382;&#39064;&#12290;&#24403;&#25968;&#25454;&#26159;&#8220;&#38543;&#26426;&#32570;&#22833;&#8221;&#26102;&#65292;&#23384;&#22312;&#19968;&#31995;&#21015;&#30340;&#24037;&#20855;&#21644;&#25216;&#26415;&#26469;&#35299;&#20915;&#27492;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#21464;&#24471;&#26356;&#21152;&#38596;&#24515;&#21187;&#21187;&#65292;&#24182;&#19988;&#35797;&#22270;&#20174;&#36234;&#26469;&#36234;&#22823;&#37327;&#30340;&#24322;&#26500;&#25968;&#25454;&#20013;&#23398;&#20064;&#65292;&#36234;&#26469;&#36234;&#26222;&#36941;&#30340;&#38382;&#39064;&#26159;&#20986;&#29616;&#20102;&#32570;&#22833;&#20540;&#30340;&#20851;&#32852;&#25110;&#32467;&#26500;&#65292;&#26080;&#35770;&#26159;&#26126;&#30830;&#36824;&#26159;&#38544;&#21547;&#12290;&#36825;&#31181;&#8220;&#32467;&#26500;&#24615;&#32570;&#22833;&#8221;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#23578;&#26410;&#31995;&#32479;&#35299;&#20915;&#30340;&#25361;&#25112;&#65292;&#24182;&#23545;&#35268;&#27169;&#21270;&#30340;&#26426;&#22120;&#23398;&#20064;&#26500;&#25104;&#20102;&#37325;&#35201;&#38459;&#30861;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#27010;&#36848;&#20102;&#24403;&#21069;&#30340;&#25991;&#29486;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#32452;&#20851;&#20110;&#22914;&#20309;&#22312;&#24102;&#26377;&#32467;&#26500;&#24615;&#32570;&#22833;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Missing data are an unavoidable complication in many machine learning tasks. When data are `missing at random' there exist a range of tools and techniques to deal with the issue. However, as machine learning studies become more ambitious, and seek to learn from ever-larger volumes of heterogeneous data, an increasingly encountered problem arises in which missing values exhibit an association or structure, either explicitly or implicitly. Such `structured missingness' raises a range of challenges that have not yet been systematically addressed, and presents a fundamental hindrance to machine learning at scale. Here, we outline the current literature and propose a set of grand challenges in learning from data with structured missingness.
&lt;/p&gt;</description></item><item><title>&#21305;&#37197;&#26426;&#22120;&#23398;&#20064;&#32467;&#21512;&#20102;&#26426;&#22120;&#23398;&#20064;&#30340;&#28789;&#27963;&#24615;&#21644;&#21305;&#37197;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#36890;&#36807;&#23398;&#20064;&#26368;&#20339;&#24230;&#37327;&#29992;&#20110;&#21305;&#37197;&#21333;&#20301;&#21644;&#20272;&#35745;&#32467;&#26524;&#65292;&#26088;&#22312;&#23454;&#29616;&#26426;&#22120;&#23398;&#20064;&#40657;&#30418;&#23376;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#21487;&#35299;&#37322;&#32467;&#26524;&#65292;&#24182;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#21069;&#26223;&#12290;</title><link>http://arxiv.org/abs/2304.01316</link><description>&lt;p&gt;
&#21305;&#37197;&#26426;&#22120;&#23398;&#20064;&#65306;&#22522;&#20110;&#23398;&#20064;&#24230;&#37327;&#30340;&#27835;&#30103;&#25928;&#26524;&#25512;&#26029;&#30340;&#24191;&#20041;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Matched Machine Learning: A Generalized Framework for Treatment Effect Inference With Learned Metrics. (arXiv:2304.01316v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01316
&lt;/p&gt;
&lt;p&gt;
&#21305;&#37197;&#26426;&#22120;&#23398;&#20064;&#32467;&#21512;&#20102;&#26426;&#22120;&#23398;&#20064;&#30340;&#28789;&#27963;&#24615;&#21644;&#21305;&#37197;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#36890;&#36807;&#23398;&#20064;&#26368;&#20339;&#24230;&#37327;&#29992;&#20110;&#21305;&#37197;&#21333;&#20301;&#21644;&#20272;&#35745;&#32467;&#26524;&#65292;&#26088;&#22312;&#23454;&#29616;&#26426;&#22120;&#23398;&#20064;&#40657;&#30418;&#23376;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#21487;&#35299;&#37322;&#32467;&#26524;&#65292;&#24182;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#21069;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#21305;&#37197;&#26426;&#22120;&#23398;&#20064;&#65292;&#36825;&#26159;&#19968;&#31181;&#23558;&#26426;&#22120;&#23398;&#20064;&#40657;&#30418;&#30340;&#28789;&#27963;&#24615;&#19982;&#21305;&#37197;&#30340;&#21487;&#35299;&#37322;&#24615;&#30456;&#32467;&#21512;&#30340;&#26694;&#26550;&#65292;&#21305;&#37197;&#26159;&#35266;&#23519;&#24615;&#22240;&#26524;&#25512;&#26029;&#20013;&#38271;&#26399;&#20197;&#26469;&#30340;&#19968;&#31181;&#24037;&#20855;&#12290;&#22312;&#35768;&#22810;&#39640;&#39118;&#38505;&#30340;&#22240;&#26524;&#25512;&#26029;&#24212;&#29992;&#20013;&#65292;&#21487;&#35299;&#37322;&#24615;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#24403;&#21069;&#38750;&#21442;&#25968;&#20272;&#35745;&#24179;&#22343;&#21644;&#20010;&#24615;&#21270;&#27835;&#30103;&#25928;&#26524;&#30340;&#24037;&#20855;&#37117;&#26159;&#40657;&#30418;&#23376;&#65292;&#19981;&#20801;&#35768;&#20154;&#31867;&#23457;&#35745;&#20272;&#35745;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#26469;&#23398;&#20064;&#29992;&#20110;&#21305;&#37197;&#21333;&#20301;&#21644;&#20272;&#35745;&#32467;&#26524;&#30340;&#26368;&#20339;&#24230;&#37327;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#26426;&#22120;&#23398;&#20064;&#40657;&#30418;&#23376;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#20445;&#25345;&#21487;&#35299;&#37322;&#24615;&#12290;&#25105;&#20204;&#30340;&#24191;&#20041;&#26694;&#26550;&#21253;&#21547;&#22810;&#20010;&#24050;&#21457;&#34920;&#20316;&#21697;&#20316;&#20026;&#29305;&#27530;&#24773;&#20917;&#12290;&#25105;&#20204;&#20026;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#25552;&#20379;&#28176;&#36817;&#25512;&#26029;&#29702;&#35770;&#65292;&#20351;&#29992;&#25143;&#33021;&#22815;&#22312;&#20010;&#24615;&#21270;&#21644;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#30340;&#32467;&#26524;&#21608;&#22260;&#26500;&#24314;&#36817;&#20284;&#32622;&#20449;&#21306;&#38388;&#12290;&#25105;&#20204;&#23454;&#35777;&#34920;&#26126;&#21305;&#37197;&#26426;&#22120;&#23398;&#20064;&#30340;&#23454;&#20363;&#20855;&#26377;&#26497;&#39640;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce Matched Machine Learning, a framework that combines the flexibility of machine learning black boxes with the interpretability of matching, a longstanding tool in observational causal inference. Interpretability is paramount in many high-stakes application of causal inference. Current tools for nonparametric estimation of both average and individualized treatment effects are black-boxes that do not allow for human auditing of estimates. Our framework uses machine learning to learn an optimal metric for matching units and estimating outcomes, thus achieving the performance of machine learning black-boxes, while being interpretable. Our general framework encompasses several published works as special cases. We provide asymptotic inference theory for our proposed framework, enabling users to construct approximate confidence intervals around estimates of both individualized and average treatment effects. We show empirically that instances of Matched Machine Learning perform on 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24182;&#34892;&#36864;&#28779;&#30340;&#19979;&#30028;&#65292;&#23545;&#38500;$\log L$&#20043;&#22806;&#30340;&#25152;&#26377;&#21442;&#25968;&#20855;&#26377;&#22810;&#39033;&#24335;&#20381;&#36182;&#24615;&#65292;&#20854;&#25913;&#36827;&#20102;&#29616;&#26377;&#30028;&#38480;&#12290;&#22240;&#27492;&#65292;&#35813;&#31639;&#27861;&#30340;&#28151;&#21512;&#26102;&#38388;&#21487;&#33021;&#26356;&#20248;&#12290;</title><link>http://arxiv.org/abs/2304.01303</link><description>&lt;p&gt;
&#24182;&#34892;&#36864;&#28779;&#28151;&#21512;&#26102;&#38388;&#30340;&#25913;&#36827;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Improved Bound for Mixing Time of Parallel Tempering. (arXiv:2304.01303v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01303
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24182;&#34892;&#36864;&#28779;&#30340;&#19979;&#30028;&#65292;&#23545;&#38500;$\log L$&#20043;&#22806;&#30340;&#25152;&#26377;&#21442;&#25968;&#20855;&#26377;&#22810;&#39033;&#24335;&#20381;&#36182;&#24615;&#65292;&#20854;&#25913;&#36827;&#20102;&#29616;&#26377;&#30028;&#38480;&#12290;&#22240;&#27492;&#65292;&#35813;&#31639;&#27861;&#30340;&#28151;&#21512;&#26102;&#38388;&#21487;&#33021;&#26356;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#37319;&#26679;&#31639;&#27861;&#39046;&#22495;&#20013;&#65292;&#24403;&#30452;&#25509;&#37319;&#26679;&#19981;&#21487;&#34892;&#26102;&#65292;MCMC&#65288;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#65289;&#26041;&#27861;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#28982;&#32780;&#65292;&#30446;&#26631;&#20998;&#24067;&#30340;&#22810;&#27169;&#24577;&#36890;&#24120;&#23548;&#33268;&#25910;&#25947;&#36895;&#24230;&#32531;&#24930;&#21644;&#28151;&#21512;&#19981;&#20339;&#12290;&#19968;&#31181;&#24120;&#35265;&#30340;&#35299;&#20915;&#26041;&#26696;&#26159;&#24182;&#34892;&#36864;&#28779;&#12290;&#23613;&#31649;&#20854;&#22312;&#23454;&#36341;&#20013;&#38750;&#24120;&#26377;&#25928;&#65292;&#20294;&#20854;&#24615;&#33021;&#30340;&#29702;&#35770;&#20445;&#35777;&#26377;&#38480;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20851;&#20110;&#24182;&#34892;&#36864;&#28779;&#35889;&#38388;&#38553;&#30340;&#19979;&#30028;&#65292;&#20854;&#23545;&#38500;$\log L$&#20043;&#22806;&#30340;&#25152;&#26377;&#21442;&#25968;&#20855;&#26377;&#22810;&#39033;&#24335;&#20381;&#36182;&#24615;&#65292;&#20854;&#20013;$(L + 1)$&#26159;&#32423;&#25968;&#30340;&#25968;&#37327;&#12290;&#36825;&#25913;&#36827;&#20102;&#29616;&#26377;&#30028;&#38480;&#65292;&#20854;&#19982;&#27169;&#24577;&#25968;&#21576;&#25351;&#25968;&#20851;&#31995;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#29992;&#35889;&#38388;&#38553;&#30340;&#20551;&#35774;&#19978;&#30028;&#26469;&#34917;&#20805;&#25105;&#20204;&#30340;&#32467;&#26524;&#65292;&#20854;&#23545;$\log L$&#20855;&#26377;&#25351;&#25968;&#20381;&#36182;&#24615;&#65292;&#36825;&#34920;&#26126;&#22312;&#26576;&#31181;&#24847;&#20041;&#19978;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#26159;&#32039;&#23494;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the field of sampling algorithms, MCMC (Markov Chain Monte Carlo) methods are widely used when direct sampling is not possible. However, multimodality of target distributions often leads to slow convergence and mixing. One common solution is parallel tempering. Though highly effective in practice, theoretical guarantees on its performance are limited. In this paper, we present a new lower bound for parallel tempering on the spectral gap that has a polynomial dependence on all parameters except $\log L$, where $(L + 1)$ is the number of levels. This improves the best existing bound which depends exponentially on the number of modes. Moreover, we complement our result with a hypothetical upper bound on spectral gap that has an exponential dependence on $\log L$, which shows that, in some sense, our bound is tight.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;Cholesky&#20998;&#35299;&#31639;&#27861;&#65292;&#29992;&#20110;&#39640;&#26031;&#36807;&#31243;&#27714;&#35299;&#38750;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#65292;&#33021;&#22815;&#26377;&#25928;&#22788;&#29702;&#39640;&#32500;&#21644;&#30072;&#24418;&#22495;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.01294</link><description>&lt;p&gt;
&#36890;&#36807;&#39640;&#26031;&#36807;&#31243;&#27714;&#35299;&#38750;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#31232;&#30095;Cholesky&#20998;&#35299;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sparse Cholesky Factorization for Solving Nonlinear PDEs via Gaussian Processes. (arXiv:2304.01294v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01294
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;Cholesky&#20998;&#35299;&#31639;&#27861;&#65292;&#29992;&#20110;&#39640;&#26031;&#36807;&#31243;&#27714;&#35299;&#38750;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#65292;&#33021;&#22815;&#26377;&#25928;&#22788;&#29702;&#39640;&#32500;&#21644;&#30072;&#24418;&#22495;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#39640;&#26031;&#36807;&#31243;&#26694;&#26550;&#27714;&#35299;&#19968;&#33324;&#38750;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#35745;&#31639;&#21487;&#20280;&#32553;&#24615;&#12290;&#36825;&#20010;&#26694;&#26550;&#25226;&#27714;&#35299;PDE&#36716;&#21270;&#20026;&#35299;&#38750;&#32447;&#24615;&#32422;&#26463;&#19979;&#30340;&#20108;&#27425;&#20248;&#21270;&#38382;&#39064;&#12290;&#20854;&#22797;&#26434;&#24230;&#30340;&#29942;&#39048;&#22312;&#20110;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#30340;&#21327;&#26041;&#24046;&#26680;&#21450;&#20854;&#22312;&#25311;&#21512;&#28857;&#30340;&#20559;&#23548;&#25968;&#36827;&#34892;&#28857;&#23545;&#28857;&#35745;&#31639;&#25152;&#24471;&#21040;&#30340;&#23494;&#38598;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#35745;&#31639;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Diracs&#21644;&#23548;&#25968;&#27979;&#37327;&#30340;&#26032;&#25490;&#21015;&#39034;&#24207;&#30340;&#31232;&#30095;Cholesky&#20998;&#35299;&#31639;&#27861;&#29992;&#20110;&#35745;&#31639;&#27492;&#31867;&#21327;&#26041;&#24046;&#30697;&#38453;&#12290;&#25105;&#20204;&#20005;&#26684;&#22320;&#30830;&#23450;&#20102;&#35813;Cholesky&#20998;&#35299;&#30340;&#31232;&#30095;&#27169;&#24335;&#65292;&#24182;&#37327;&#21270;&#20102;&#30456;&#24212;Vecchia&#36817;&#20284;&#30340;&#25351;&#25968;&#25910;&#25947;&#31934;&#24230;&#65292;&#22312;Kullback-Leibler&#36317;&#31163;&#24230;&#37327;&#19979;&#36798;&#21040;&#26368;&#20248;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#20197;$O(N\log^d(N/\epsilon))$&#30340;&#31354;&#38388;&#22797;&#26434;&#24230;&#21644;$O(N\log^{d+2}(N/\epsilon))$&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#35745;&#31639;$\epsilon$-&#36817;&#20284;&#30340;&#36870;Cholesky&#22240;&#23376;&#12290;&#20854;&#20013;&#65292;$N$&#34920;&#31034;&#25311;&#21512;&#28857;&#30340;&#25968;&#37327;&#65292;$d$&#20026;&#29289;&#29702;&#22495;&#30340;&#32500;&#25968;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#39640;&#32500;&#65288;&#26368;&#39640;&#21487;&#36798;&#21040;$d=50$&#65289;&#21644;&#30072;&#24418;&#22495;&#30340;&#22522;&#20934;&#38382;&#39064;&#19978;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the computational scalability of a Gaussian process (GP) framework for solving general nonlinear partial differential equations (PDEs). This framework transforms solving PDEs to solving quadratic optimization problem with nonlinear constraints. Its complexity bottleneck lies in computing with dense kernel matrices obtained from pointwise evaluations of the covariance kernel of the GP and its partial derivatives at collocation points.  We present a sparse Cholesky factorization algorithm for such kernel matrices based on the near-sparsity of the Cholesky factor under a new ordering of Diracs and derivative measurements. We rigorously identify the sparsity pattern and quantify the exponentially convergent accuracy of the corresponding Vecchia approximation of the GP, which is optimal in the Kullback-Leibler divergence. This enables us to compute $\epsilon$-approximate inverse Cholesky factors of the kernel matrices with complexity $O(N\log^d(N/\epsilon))$ in space and $O(N\log^{
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#32447;&#24615;&#12289;&#24120;&#25968;&#22240;&#23376;&#33609;&#22270;&#65292;&#36866;&#29992;&#20110;$\ell_1$&#21644;logistic&#22238;&#24402;&#65292;&#20855;&#26377;&#23567;&#30340;&#33609;&#22270;&#32500;&#24230;&#21644;&#39640;&#31934;&#24230;&#65292;&#36825;&#31181;&#33609;&#22270;&#36824;&#22312;&#33609;&#22270;&#31354;&#38388;&#20869;&#25552;&#20379;&#20102;&#39640;&#25928;&#30340;&#20248;&#21270;&#38382;&#39064;&#27714;&#35299;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.00051</link><description>&lt;p&gt;
$\ell_1$&#21644;logistic&#22238;&#24402;&#30340;&#36817;&#32447;&#24615;&#24120;&#25968;&#22240;&#23376;&#33609;&#22270;
&lt;/p&gt;
&lt;p&gt;
Almost Linear Constant-Factor Sketching for $\ell_1$ and Logistic Regression. (arXiv:2304.00051v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00051
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#32447;&#24615;&#12289;&#24120;&#25968;&#22240;&#23376;&#33609;&#22270;&#65292;&#36866;&#29992;&#20110;$\ell_1$&#21644;logistic&#22238;&#24402;&#65292;&#20855;&#26377;&#23567;&#30340;&#33609;&#22270;&#32500;&#24230;&#21644;&#39640;&#31934;&#24230;&#65292;&#36825;&#31181;&#33609;&#22270;&#36824;&#22312;&#33609;&#22270;&#31354;&#38388;&#20869;&#25552;&#20379;&#20102;&#39640;&#25928;&#30340;&#20248;&#21270;&#38382;&#39064;&#27714;&#35299;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25913;&#36827;&#20102;&#20197;&#21069;&#20851;&#20110;$\ell_1$&#21644;Logistic&#22238;&#24402;&#30340;&#33609;&#22270;&#31639;&#27861;&#32467;&#26524;&#65292;&#24471;&#21040;&#20102;&#26356;&#23567;&#30340;&#33609;&#22270;&#32500;&#24230;&#21644;&#26356;&#39640;&#30340;&#31934;&#24230;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#22312;&#33609;&#22270;&#31354;&#38388;&#20869;&#20135;&#29983;&#20102;&#39640;&#25928;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23545;&#20110;&#20219;&#20309;&#24120;&#25968;$c&gt;0$&#65292;&#23454;&#29616;&#20102;$\ell_1$&#22238;&#24402;&#30340;&#33609;&#22270;&#32500;&#24230;&#20026;$\tilde{O}(d^{1+c})$&#65292;&#32780;&#23545;&#20110;Logistic&#22238;&#24402;&#21017;&#20026;$\tilde{O}(\mu d^{1+c})$&#65292;&#20854;&#20013;$\mu$&#26159;&#19968;&#20010;&#26631;&#20934;&#30340;&#24230;&#37327;&#65292;&#25429;&#33719;&#20102;&#21387;&#32553;&#25968;&#25454;&#30340;&#22797;&#26434;&#24615;&#12290;&#23545;&#20110;$\ell_1$&#22238;&#24402;&#65292;&#25105;&#20204;&#30340;&#33609;&#22270;&#32500;&#24230;&#26159;&#36817;&#32447;&#24615;&#30340;&#65292;&#20855;&#26377;&#27604;&#20808;&#21069;&#30340;&#24037;&#20316;&#26356;&#39640;&#30340;&#31934;&#24230;&#21644;&#26356;&#23567;&#30340;&#33609;&#22270;&#32500;&#24230;&#12290;&#31867;&#20284;&#22320;&#65292;&#23545;&#20110;Logistic&#22238;&#24402;&#65292;&#20197;&#21069;&#30340;&#24037;&#20316;&#22312;&#20854;&#33609;&#22270;&#32500;&#24230;&#19978;&#26377;&#26356;&#24046;&#30340;$\operatorname{poly}(\mu d)$&#22240;&#23376;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#25240;&#34935;&#26041;&#26696;&#65292;&#36890;&#36807;&#22686;&#21152;&#24635;&#22823;&#23567;&#21040;$(d\log$&#65292;&#22312;&#36755;&#20837;&#31232;&#30095;&#24615;&#26102;&#38388;&#20869;&#20135;&#29983;&#20102;$1+\varepsilon$&#30340;&#36817;&#20284;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
We improve upon previous oblivious sketching and turnstile streaming results for $\ell_1$ and logistic regression, giving a much smaller sketching dimension achieving $O(1)$-approximation and yielding an efficient optimization problem in the sketch space. Namely, we achieve for any constant $c&gt;0$ a sketching dimension of $\tilde{O}(d^{1+c})$ for $\ell_1$ regression and $\tilde{O}(\mu d^{1+c})$ for logistic regression, where $\mu$ is a standard measure that captures the complexity of compressing the data. For $\ell_1$-regression our sketching dimension is near-linear and improves previous work which either required $\Omega(\log d)$-approximation with this sketching dimension, or required a larger $\operatorname{poly}(d)$ number of rows. Similarly, for logistic regression previous work had worse $\operatorname{poly}(\mu d)$ factors in its sketching dimension. We also give a tradeoff that yields a $1+\varepsilon$ approximation in input sparsity time by increasing the total size to $(d\log
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#24314;&#31435;&#28176;&#36817;&#25512;&#26029;&#38750;&#23545;&#31216;&#30697;&#38453;&#29305;&#24449;&#21521;&#37327;&#31243;&#24207;&#30340;&#24517;&#35201;&#26465;&#20214;&#65292;&#24182;&#38024;&#23545;&#23436;&#20840;&#21521;&#37327;&#21644;&#27599;&#20010;&#31995;&#25968;&#20551;&#35774;&#20998;&#21035;&#24314;&#31435;&#20102; Wald &#21644; t &#26816;&#39564;&#30340;&#20998;&#24067;&#29702;&#35770;&#65292;&#26159;&#22810;&#20803;&#32479;&#35745;&#23398;&#20013;&#30340;&#19968;&#31181;&#26377;&#29992;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2303.18233</link><description>&lt;p&gt;
&#38750;&#23545;&#31216;&#30697;&#38453;&#29305;&#24449;&#21521;&#37327;&#30340;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Inference on eigenvectors of non-symmetric matrices. (arXiv:2303.18233v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.18233
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#24314;&#31435;&#28176;&#36817;&#25512;&#26029;&#38750;&#23545;&#31216;&#30697;&#38453;&#29305;&#24449;&#21521;&#37327;&#31243;&#24207;&#30340;&#24517;&#35201;&#26465;&#20214;&#65292;&#24182;&#38024;&#23545;&#23436;&#20840;&#21521;&#37327;&#21644;&#27599;&#20010;&#31995;&#25968;&#20551;&#35774;&#20998;&#21035;&#24314;&#31435;&#20102; Wald &#21644; t &#26816;&#39564;&#30340;&#20998;&#24067;&#29702;&#35770;&#65292;&#26159;&#22810;&#20803;&#32479;&#35745;&#23398;&#20013;&#30340;&#19968;&#31181;&#26377;&#29992;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35748;&#20026;&#65292;Tyler&#65288;1981&#65289;&#30340;&#21487;&#23545;&#31216;&#21270;&#26465;&#20214;&#24182;&#38750;&#24314;&#31435;&#28176;&#36817;&#25512;&#26029;&#29305;&#24449;&#21521;&#37327;&#31243;&#24207;&#25152;&#24517;&#38656;&#30340;&#12290; &#25105;&#20204;&#20026;&#23436;&#20840;&#21521;&#37327;&#21644;&#27599;&#20010;&#31995;&#25968;&#20551;&#35774;&#20998;&#21035;&#24314;&#31435;&#20102; Wald &#21644; t &#26816;&#39564;&#30340;&#20998;&#24067;&#29702;&#35770;&#12290; &#25105;&#20204;&#30340;&#26816;&#39564;&#32479;&#35745;&#37327;&#26469;&#28304;&#20110;&#38750;&#23545;&#31216;&#30697;&#38453;&#30340;&#29305;&#24449;&#25237;&#24433;&#12290; &#36890;&#36807;&#23558;&#25237;&#24433;&#34920;&#31034;&#20026;&#20174;&#22522;&#30784;&#30697;&#38453;&#21040;&#20854;&#35889;&#25968;&#25454;&#30340;&#26144;&#23556;&#65292;&#25105;&#20204;&#36890;&#36807;&#35299;&#26512;&#25668;&#21160;&#29702;&#35770;&#25214;&#21040;&#20102;&#23548;&#25968;&#12290; &#36825;&#20123;&#32467;&#26524;&#28436;&#31034;&#20102; Sun&#65288;1991&#65289;&#30340;&#35299;&#26512;&#25668;&#21160;&#29702;&#35770;&#26159;&#22810;&#20803;&#32479;&#35745;&#23398;&#20013;&#30340;&#19968;&#31181;&#26377;&#29992;&#24037;&#20855;&#65292;&#24182;&#19988;&#20855;&#26377;&#29420;&#31435;&#30340;&#20852;&#36259;&#12290;&#20316;&#20026;&#19968;&#31181;&#24212;&#29992;&#65292;&#25105;&#20204;&#20026;&#30001;&#26377;&#21521;&#22270;&#24341;&#21457;&#30340;&#37051;&#25509;&#30697;&#38453;&#20272;&#35745;&#30340; Bonacich &#20013;&#24515;&#24615;&#23450;&#20041;&#32622;&#20449;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper argues that the symmetrisability condition in Tyler(1981) is not necessary to establish asymptotic inference procedures for eigenvectors. We establish distribution theory for a Wald and t-test for full-vector and individual coefficient hypotheses, respectively. Our test statistics originate from eigenprojections of non-symmetric matrices. Representing projections as a mapping from the underlying matrix to its spectral data, we find derivatives through analytic perturbation theory. These results demonstrate how the analytic perturbation theory of Sun(1991) is a useful tool in multivariate statistics and are of independent interest. As an application, we define confidence sets for Bonacich centralities estimated from adjacency matrices induced by directed graphs.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#28508;&#22312;&#20301;&#32622;&#27169;&#22411;&#19978;&#30340;&#22270;&#24418;Nadaraya-Watson&#20272;&#35745;&#22120;&#30340;&#24615;&#36136;&#65292;&#23545;&#20110;&#26356;&#22797;&#26434;&#30340;&#26041;&#27861;&#26377;&#29702;&#35770;&#25351;&#23548;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2303.17229</link><description>&lt;p&gt;
&#28508;&#22312;&#20301;&#32622;&#27169;&#22411;&#19978;&#30340;&#22270;&#24418;Nadaraya-Watson&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
The Graphical Nadaraya-Watson Estimator on Latent Position Models. (arXiv:2303.17229v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17229
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#28508;&#22312;&#20301;&#32622;&#27169;&#22411;&#19978;&#30340;&#22270;&#24418;Nadaraya-Watson&#20272;&#35745;&#22120;&#30340;&#24615;&#36136;&#65292;&#23545;&#20110;&#26356;&#22797;&#26434;&#30340;&#26041;&#27861;&#26377;&#29702;&#35770;&#25351;&#23548;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#26377;&#26631;&#35760;&#33410;&#28857;&#30340;&#22270;&#24418;&#65292;&#25105;&#20204;&#23545;&#20272;&#35745;&#22120;&#30340;&#36136;&#37327;&#24863;&#20852;&#36259;&#65292;&#35813;&#20272;&#35745;&#22120;&#38024;&#23545;&#26410;&#26631;&#35760;&#33410;&#28857;&#39044;&#27979;&#20854;&#26631;&#35760;&#37051;&#23621;&#30340;&#35266;&#27979;&#20540;&#30340;&#24179;&#22343;&#20540;&#12290;&#25105;&#20204;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#20005;&#26684;&#30740;&#31350;&#20102;&#27987;&#24230;&#23646;&#24615;&#12289;&#26041;&#24046;&#30028;&#21644;&#39118;&#38505;&#30028;&#12290;&#34429;&#28982;&#20272;&#35745;&#22120;&#26412;&#36523;&#38750;&#24120;&#31616;&#21333;&#65292;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#23545;&#20110;&#23454;&#38469;&#24212;&#29992;&#36807;&#20110;&#29702;&#24819;&#65292;&#20294;&#25105;&#20204;&#30456;&#20449;&#25105;&#20204;&#30340;&#23567;&#27493;&#39588;&#23558;&#26377;&#21161;&#20110;&#26356;&#22797;&#26434;&#26041;&#27861;&#65288;&#22914;&#22270;&#24418;&#31070;&#32463;&#32593;&#32476;&#65289;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given a graph with a subset of labeled nodes, we are interested in the quality of the averaging estimator which for an unlabeled node predicts the average of the observations of its labeled neighbours. We rigorously study concentration properties, variance bounds and risk bounds in this context. While the estimator itself is very simple and the data generating process is too idealistic for practical applications, we believe that our small steps will contribute towards the theoretical understanding of more sophisticated methods such as Graph Neural Networks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#26631;&#31614;&#21015;&#34920;&#30340;&#22312;&#32447;&#39044;&#27979;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102; $b$-ary Littlestone &#32500;&#24230;&#21487;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#19988;&#22312;&#25077;&#25026;&#30340;&#24773;&#20917;&#19979;&#25506;&#32034;&#19981;&#21516;&#30340;&#24773;&#20917;&#12290;&#21487;&#20197;&#20351;&#29992;&#25913;&#32534;&#33258; Littlestone &#30340; SOA &#21644; Rosenblatt &#30340;&#24863;&#30693;&#22120;&#31561;&#31639;&#27861;&#36827;&#34892;&#39044;&#27979;&#65292;&#21516;&#26102;&#36824;&#24314;&#31435;&#20102;&#21015;&#34920;&#21487;&#23398;&#20064;&#30340;&#32452;&#21512;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2303.15383</link><description>&lt;p&gt;
&#22522;&#20110;&#21015;&#34920;&#30340;&#22312;&#32447;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
List Online Classification. (arXiv:2303.15383v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15383
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#26631;&#31614;&#21015;&#34920;&#30340;&#22312;&#32447;&#39044;&#27979;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102; $b$-ary Littlestone &#32500;&#24230;&#21487;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#19988;&#22312;&#25077;&#25026;&#30340;&#24773;&#20917;&#19979;&#25506;&#32034;&#19981;&#21516;&#30340;&#24773;&#20917;&#12290;&#21487;&#20197;&#20351;&#29992;&#25913;&#32534;&#33258; Littlestone &#30340; SOA &#21644; Rosenblatt &#30340;&#24863;&#30693;&#22120;&#31561;&#31639;&#27861;&#36827;&#34892;&#39044;&#27979;&#65292;&#21516;&#26102;&#36824;&#24314;&#31435;&#20102;&#21015;&#34920;&#21487;&#23398;&#20064;&#30340;&#32452;&#21512;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#22810;&#20998;&#31867;&#22312;&#32447;&#39044;&#27979;&#65292;&#20854;&#20013;&#23398;&#20064;&#32773;&#21487;&#20197;&#20351;&#29992;&#22810;&#20010;&#26631;&#31614;&#30340;&#21015;&#34920;&#36827;&#34892;&#39044;&#27979;&#65288;&#19982;&#20256;&#32479;&#35774;&#32622;&#20013;&#20165;&#20351;&#29992;&#19968;&#31181;&#26631;&#31614;&#19981;&#21516;&#65289;&#12290;&#25105;&#20204;&#20351;&#29992; $b$-ary Littlestone &#32500;&#24230;&#34920;&#24449;&#20102;&#35813;&#27169;&#22411;&#20013;&#30340;&#21487;&#23398;&#20064;&#24615;&#12290;&#35813;&#32500;&#24230;&#26159;&#32463;&#20856; Littlestone &#32500;&#24230;&#30340;&#21464;&#20307;&#65292;&#20854;&#20013;&#20108;&#36827;&#21046;&#38169;&#35823;&#26641;&#34987;&#26367;&#25442;&#20026; $(k+1)$-ary &#38169;&#35823;&#26641;&#65292;&#20854;&#20013; k &#26159;&#21015;&#34920;&#20013;&#26631;&#31614;&#30340;&#25968;&#37327;&#12290;&#22312;&#25077;&#25026;&#30340;&#22330;&#26223;&#20013;&#65292;&#25105;&#20204;&#26681;&#25454;&#27604;&#36739;&#31867;&#20013;&#26159;&#21542;&#21253;&#21547;&#21333;&#26631;&#31614;&#25110;&#22810;&#26631;&#31614;&#20989;&#25968;&#20197;&#21450;&#23427;&#19982;&#31639;&#27861;&#20351;&#29992;&#30340;&#21015;&#34920;&#22823;&#23567;&#20043;&#38388;&#30340;&#26435;&#34913;&#26469;&#25506;&#32034;&#19981;&#21516;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#21487;&#20197;&#23454;&#29616;&#36127;&#24724;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#20160;&#20040;&#24773;&#20917;&#19979;&#23454;&#29616;&#36127;&#24724;&#30340;&#23436;&#25972;&#29305;&#24615;&#21270;&#12290;&#20316;&#20026;&#25105;&#20204;&#24037;&#20316;&#30340;&#19968;&#37096;&#20998;&#65292;&#25105;&#20204;&#25913;&#32534;&#20102;&#32463;&#20856;&#31639;&#27861;&#65292;&#22914; Littlestone &#30340; SOA &#21644; Rosenblatt &#30340;&#24863;&#30693;&#22120;&#65292;&#20197;&#20351;&#29992;&#26631;&#31614;&#21015;&#34920;&#36827;&#34892;&#39044;&#27979;&#12290;&#25105;&#20204;&#36824;&#20026;&#21487;&#20197;&#36827;&#34892;&#21015;&#34920;&#23398;&#20064;&#30340;&#32452;&#21512;&#32467;&#26524;&#24314;&#31435;&#20102;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study multiclass online prediction where the learner can predict using a list of multiple labels (as opposed to just one label in the traditional setting). We characterize learnability in this model using the $b$-ary Littlestone dimension. This dimension is a variation of the classical Littlestone dimension with the difference that binary mistake trees are replaced with $(k+1)$-ary mistake trees, where $k$ is the number of labels in the list. In the agnostic setting, we explore different scenarios depending on whether the comparator class consists of single-labeled or multi-labeled functions and its tradeoff with the size of the lists the algorithm uses. We find that it is possible to achieve negative regret in some cases and provide a complete characterization of when this is possible. As part of our work, we adapt classical algorithms such as Littlestone's SOA and Rosenblatt's Perceptron to predict using lists of labels. We also establish combinatorial results for list-learnable c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#20998;&#20301;&#38543;&#26426;&#26862;&#26519;&#27169;&#22411;&#22806;&#25512;&#23436;&#22791;&#22522;&#32452;&#26497;&#38480;&#65292;&#24182;&#25552;&#20379;&#20102;&#39044;&#27979;&#21306;&#38388;&#20197;&#37327;&#21270;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.14760</link><description>&lt;p&gt;
&#29992;&#20998;&#20301;&#38543;&#26426;&#26862;&#26519;&#27169;&#22411;&#22312;&#23494;&#24230;&#27867;&#20989;&#29702;&#35770;&#20013;&#22806;&#25512;&#23436;&#22791;&#22522;&#32452;&#26497;&#38480;
&lt;/p&gt;
&lt;p&gt;
Extrapolation to complete basis-set limit in density-functional theory by quantile random-forest models. (arXiv:2303.14760v2 [physics.comp-ph] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14760
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#20998;&#20301;&#38543;&#26426;&#26862;&#26519;&#27169;&#22411;&#22806;&#25512;&#23436;&#22791;&#22522;&#32452;&#26497;&#38480;&#65292;&#24182;&#25552;&#20379;&#20102;&#39044;&#27979;&#21306;&#38388;&#20197;&#37327;&#21270;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23494;&#24230;&#27867;&#20989;&#29702;&#35770;&#65288;DFT&#65289;&#35745;&#31639;&#30340;&#25968;&#20540;&#31934;&#24230;&#21462;&#20915;&#20110;&#21508;&#31181;&#35745;&#31639;&#21442;&#25968;&#65292;&#20854;&#20013;&#26368;&#20851;&#38190;&#30340;&#20043;&#19968;&#26159;&#22522;&#32452;&#22823;&#23567;&#12290;&#29702;&#35770;&#19978;&#65292;&#20351;&#29992;&#26080;&#38480;&#22823;&#30340;&#22522;&#32452;&#65292;&#21363;&#23436;&#22791;&#22522;&#32452;&#38598;&#65292;&#21487;&#20197;&#36798;&#21040;&#26368;&#39640;&#31934;&#24230;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#25214;&#21040;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#23558;&#26377;&#38480;&#22522;&#32452;&#22823;&#23567;&#35745;&#31639;&#22806;&#25512;&#21040;&#23436;&#22791;&#22522;&#32452;&#26497;&#38480;&#12290;&#25105;&#20204;&#20174;63&#20010;&#20108;&#20803;&#22266;&#20307;&#30340;&#25968;&#25454;&#38598;&#24320;&#22987;&#65292;&#36825;&#20123;&#22266;&#20307;&#20351;&#29992;&#20004;&#31181;&#20840;&#30005;&#23376;DFT&#20195;&#30721;&#65292;&#21363;exciting&#21644;FHI-aims&#65292;&#36825;&#20004;&#31181;&#20195;&#30721;&#20351;&#29992;&#38750;&#24120;&#19981;&#21516;&#31867;&#22411;&#30340;&#22522;&#32452;&#12290;&#20351;&#29992;&#20998;&#20301;&#38543;&#26426;&#26862;&#26519;&#27169;&#22411;&#26469;&#20272;&#35745;&#22522;&#32452;&#22823;&#23567;&#20851;&#20110;&#20840;&#25910;&#25947;&#35745;&#31639;&#30340;&#24635;&#33021;&#37327;&#20462;&#27491;&#12290;&#35813;&#38543;&#26426;&#26862;&#26519;&#27169;&#22411;&#23545;&#20110;&#20004;&#31181;&#20195;&#30721;&#37117;&#23454;&#29616;&#20102;&#23567;&#20110;25%&#30340;&#23545;&#31216;&#24179;&#22343;&#32477;&#23545;&#30334;&#20998;&#27604;&#35823;&#24046;&#65292;&#32780;&#19988;&#32988;&#36807;&#20102;&#25991;&#29486;&#20013;&#20043;&#21069;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36824;&#25552;&#20379;&#20102;&#39044;&#27979;&#21306;&#38388;&#65292;&#21487;&#20197;&#37327;&#21270;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The numerical precision of density-functional-theory (DFT) calculations depends on a variety of computational parameters, one of the most critical being the basis-set size. The ultimate precision is reached with an infinitely large basis set, i.e., in the limit of a complete basis set (CBS). Our aim in this work is to find a machine-learning model that extrapolates finite basis-size calculations to the CBS limit. We start with a data set of 63 binary solids investigated with two all-electron DFT codes, exciting and FHI-aims, which employ very different types of basis sets. A quantile-random-forest model is used to estimate the total-energy correction with respect to a fully converged calculation as a function of the basis-set size. The random-forest model achieves a symmetric mean absolute percentage error of lower than 25% for both codes and outperforms previous approaches in the literature. Our approach also provides prediction intervals, which quantify the uncertainty of the models'
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27604;&#36739;&#20102;&#35768;&#22810;&#20986;&#29616;&#22312;&#25991;&#29486;&#20013;&#30340;&#22240;&#26524;&#21059;&#20992;&#65292;&#24182;&#29305;&#21035;&#30740;&#31350;&#20102;&#22312;&#22810;&#39033;&#24335;&#22240;&#26524;&#27169;&#22411;&#20013;&#19981;&#22826;&#21463;&#27426;&#36814;&#30340;&#22240;&#26524;&#21059;&#20992;&#8212;&#8212;&#21442;&#25968;&#26368;&#23567;&#24615;&#12290;&#36923;&#36753;&#32467;&#26524;&#25581;&#31034;&#20102;&#36873;&#25321;&#21512;&#29702;&#24471;&#20998;&#26631;&#20934;&#26102;&#30340;&#22256;&#22659;&#12290;</title><link>http://arxiv.org/abs/2302.10331</link><description>&lt;p&gt;
&#22240;&#26524;&#21059;&#20992;
&lt;/p&gt;
&lt;p&gt;
Causal Razors. (arXiv:2302.10331v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10331
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27604;&#36739;&#20102;&#35768;&#22810;&#20986;&#29616;&#22312;&#25991;&#29486;&#20013;&#30340;&#22240;&#26524;&#21059;&#20992;&#65292;&#24182;&#29305;&#21035;&#30740;&#31350;&#20102;&#22312;&#22810;&#39033;&#24335;&#22240;&#26524;&#27169;&#22411;&#20013;&#19981;&#22826;&#21463;&#27426;&#36814;&#30340;&#22240;&#26524;&#21059;&#20992;&#8212;&#8212;&#21442;&#25968;&#26368;&#23567;&#24615;&#12290;&#36923;&#36753;&#32467;&#26524;&#25581;&#31034;&#20102;&#36873;&#25321;&#21512;&#29702;&#24471;&#20998;&#26631;&#20934;&#26102;&#30340;&#22256;&#22659;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#26102;&#65292;&#24517;&#39035;&#23545;&#30495;&#23454;&#22240;&#26524;&#26426;&#21046;&#22914;&#20309;&#19982;&#24213;&#23618;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#30456;&#23545;&#24212;&#20570;&#20986;&#20551;&#35774;&#12290;&#26412;&#25991;&#23558;&#36825;&#20123;&#20551;&#35774;&#31216;&#20026;&#22240;&#26524;&#21059;&#20992;&#12290;&#25105;&#20204;&#22238;&#39038;&#20102;&#35768;&#22810;&#20986;&#29616;&#22312;&#25991;&#29486;&#20013;&#30340;&#22240;&#26524;&#21059;&#20992;&#65292;&#23545;&#23427;&#20204;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#36923;&#36753;&#27604;&#36739;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23545;&#22312;&#22810;&#39033;&#24335;&#22240;&#26524;&#27169;&#22411;&#20013;&#19981;&#22826;&#21463;&#27426;&#36814;&#30340;&#22240;&#26524;&#21059;&#20992;&#8212;&#8212;&#21442;&#25968;&#26368;&#23567;&#24615;&#36827;&#34892;&#20102;&#28145;&#20837;&#30340;&#30740;&#31350;&#65292;&#24182;&#30740;&#31350;&#20102;&#23427;&#19982;&#20854;&#20182;&#24191;&#27867;&#30740;&#31350;&#30340;&#22240;&#26524;&#21059;&#20992;&#20043;&#38388;&#30340;&#36923;&#36753;&#20851;&#31995;&#12290;&#25105;&#20204;&#30340;&#36923;&#36753;&#32467;&#26524;&#22312;&#20026;&#22522;&#20110;&#20998;&#25968;&#30340;&#22240;&#26524;&#25628;&#32034;&#31639;&#27861;&#36873;&#25321;&#21512;&#29702;&#24471;&#20998;&#26631;&#20934;&#26102;&#25552;&#20986;&#20102;&#22256;&#22659;&#12290;
&lt;/p&gt;
&lt;p&gt;
When performing causal discovery, assumptions have to be made on how the true causal mechanism corresponds to the underlying joint probability distribution. These assumptions are labeled as causal razors in this work. We review numerous causal razors that appeared in the literature, and offer a comprehensive logical comparison of them. In particular, we scrutinize an unpopular causal razor, namely parameter minimality, in multinomial causal models and its logical relations with other well-studied causal razors. Our logical result poses a dilemma in selecting a reasonable scoring criterion for score-based casual search algorithms.
&lt;/p&gt;</description></item><item><title>D-Adaptation&#26159;&#19968;&#31181;&#21487;&#20197;&#33258;&#21160;&#35774;&#32622;&#23398;&#20064;&#29575;&#30340;&#26041;&#27861;&#65292;&#38024;&#23545;&#26368;&#23567;&#21270;&#20984;&#24615;Lipschitz&#20989;&#25968;&#65292;&#29992;&#20110;&#23454;&#29616;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#32780;&#26080;&#38656;&#36229;&#21442;&#25968;&#65292;&#20063;&#26080;&#38656;&#39069;&#22806;&#23545;&#25968;&#22240;&#23376;&#25913;&#36827;&#65292;&#33021;&#22815;&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#33258;&#21160;&#21305;&#37197;&#25163;&#21160;&#35843;&#25972;&#30340;&#23398;&#20064;&#29575;&#12290;</title><link>http://arxiv.org/abs/2301.07733</link><description>&lt;p&gt;
&#36890;&#36807;D&#36866;&#24212;&#23454;&#29616;&#23398;&#20064;&#29575;&#33258;&#30001;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning-Rate-Free Learning by D-Adaptation. (arXiv:2301.07733v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.07733
&lt;/p&gt;
&lt;p&gt;
D-Adaptation&#26159;&#19968;&#31181;&#21487;&#20197;&#33258;&#21160;&#35774;&#32622;&#23398;&#20064;&#29575;&#30340;&#26041;&#27861;&#65292;&#38024;&#23545;&#26368;&#23567;&#21270;&#20984;&#24615;Lipschitz&#20989;&#25968;&#65292;&#29992;&#20110;&#23454;&#29616;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#32780;&#26080;&#38656;&#36229;&#21442;&#25968;&#65292;&#20063;&#26080;&#38656;&#39069;&#22806;&#23545;&#25968;&#22240;&#23376;&#25913;&#36827;&#65292;&#33021;&#22815;&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#33258;&#21160;&#21305;&#37197;&#25163;&#21160;&#35843;&#25972;&#30340;&#23398;&#20064;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
D&#36866;&#24212;&#26159;&#19968;&#31181;&#33258;&#21160;&#35774;&#32622;&#23398;&#20064;&#29575;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#28176;&#36817;&#22320;&#23454;&#29616;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#29992;&#20110;&#26368;&#23567;&#21270;&#20984;&#24615;Lipschitz&#20989;&#25968;&#65292;&#26080;&#38656;&#22238;&#28335;&#25110;&#32447;&#24615;&#25628;&#32034;&#65292;&#24182;&#19988;&#27599;&#27493;&#26080;&#38656;&#36827;&#34892;&#39069;&#22806;&#30340;&#20989;&#25968;&#20540;&#25110;&#26799;&#24230;&#35780;&#20272;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#36825;&#19968;&#31867;&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#26080;&#36229;&#21442;&#25968;&#19988;&#25910;&#25947;&#36895;&#29575;&#26080;&#38656;&#39069;&#22806;&#23545;&#25968;&#22240;&#23376;&#25913;&#36827;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#38024;&#23545;SGD&#21644;Adam&#21464;&#20307;&#23637;&#31034;&#20102;&#24191;&#27867;&#30340;&#23454;&#39564;&#65292;&#20854;&#20013;&#35813;&#26041;&#27861;&#33258;&#21160;&#21305;&#37197;&#25163;&#21160;&#35843;&#25972;&#30340;&#23398;&#20064;&#29575;&#65292;&#22312;&#21313;&#22810;&#20010;&#19981;&#21516;&#30340;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#24212;&#29992;&#65292;&#21253;&#25324;&#22823;&#35268;&#27169;&#30340;&#35270;&#35273;&#21644;&#35821;&#35328;&#38382;&#39064;&#12290;&#24320;&#28304;&#23454;&#29616;&#22312; \url{https://github.com/facebookresearch/dadaptation}.
&lt;/p&gt;
&lt;p&gt;
D-Adaptation is an approach to automatically setting the learning rate which asymptotically achieves the optimal rate of convergence for minimizing convex Lipschitz functions, with no back-tracking or line searches, and no additional function value or gradient evaluations per step. Our approach is the first hyper-parameter free method for this class without additional multiplicative log factors in the convergence rate. We present extensive experiments for SGD and Adam variants of our method, where the method automatically matches hand-tuned learning rates across more than a dozen diverse machine learning problems, including large-scale vision and language problems.  An open-source implementation is available at \url{https://github.com/facebookresearch/dadaptation}.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22788;&#29702;&#27979;&#35797;&#36755;&#20837;&#20998;&#24067;&#38543;&#26102;&#38388;&#25345;&#32493;&#21464;&#21270;&#30340;&#27010;&#29575;&#26694;&#26550;PETAL&#65292;&#36890;&#36807;&#25552;&#20379;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#21644;&#20351;&#29992;&#28304;&#27169;&#22411;&#20316;&#20026;&#27491;&#21017;&#21270;&#39033;&#26469;&#25512;&#26029;&#26102;&#27491;&#21017;&#21270;&#27169;&#22411;&#26356;&#26032;&#65292;&#23454;&#29616;&#20102;&#32456;&#36523;TTA&#12290;</title><link>http://arxiv.org/abs/2212.09713</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#32456;&#36523;&#27979;&#35797;&#26102;&#38388;&#33258;&#36866;&#24212;&#30340;&#27010;&#29575;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Probabilistic Framework for Lifelong Test-Time Adaptation. (arXiv:2212.09713v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.09713
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22788;&#29702;&#27979;&#35797;&#36755;&#20837;&#20998;&#24067;&#38543;&#26102;&#38388;&#25345;&#32493;&#21464;&#21270;&#30340;&#27010;&#29575;&#26694;&#26550;PETAL&#65292;&#36890;&#36807;&#25552;&#20379;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#21644;&#20351;&#29992;&#28304;&#27169;&#22411;&#20316;&#20026;&#27491;&#21017;&#21270;&#39033;&#26469;&#25512;&#26029;&#26102;&#27491;&#21017;&#21270;&#27169;&#22411;&#26356;&#26032;&#65292;&#23454;&#29616;&#20102;&#32456;&#36523;TTA&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27979;&#35797;&#26102;&#38388;&#36866;&#24212;&#65288;TTA&#65289;&#26159;&#22312;&#25512;&#29702;&#26102;&#38024;&#23545;&#26469;&#33258;&#19981;&#21516;&#30446;&#26631;&#22495;&#30340;&#27979;&#35797;&#36755;&#20837;&#26356;&#26032;&#39044;&#20808;&#35757;&#32451;&#30340;&#28304;&#27169;&#22411;&#30340;&#38382;&#39064;&#12290;&#30446;&#21069;&#22823;&#22810;&#25968;TTA&#26041;&#27861;&#37117;&#20551;&#35774;&#30446;&#26631;&#22495;&#26159;&#38745;&#24577;&#30340;&#65292;&#21363;&#25152;&#26377;&#27979;&#35797;&#36755;&#20837;&#37117;&#26469;&#33258;&#21333;&#20010;&#30446;&#26631;&#22495;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#22330;&#26223;&#20013;&#65292;&#27979;&#35797;&#36755;&#20837;&#20998;&#24067;&#21487;&#33021;&#38543;&#30528;&#26102;&#38388;&#30340;&#25512;&#31227;&#32780;&#21457;&#29983;&#32456;&#36523;/&#25345;&#32493;&#21464;&#21270;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#30340;TTA&#26041;&#27861;&#20063;&#32570;&#20047;&#25552;&#20379;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#33021;&#21147;&#65292;&#32780;&#22312;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#20043;&#38388;&#21457;&#29983;&#20998;&#24067;&#21464;&#21270;&#26102;&#65292;&#36825;&#19968;&#28857;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;PETAL&#65288;&#20855;&#26377;&#33258;&#25105;&#35757;&#32451;&#20808;&#39564;&#30693;&#35782;&#30340;&#27010;&#29575;&#32456;&#36523;&#27979;&#35797;&#26102;&#38388;&#33258;&#36866;&#24212;&#65289;&#65292;&#23427;&#20351;&#29992;&#27010;&#29575;&#26041;&#27861;&#35299;&#20915;&#20102;&#32456;&#36523;TTA&#38382;&#39064;&#65292;&#33258;&#28982;&#22320;&#24471;&#21040;&#20102;&#65288;1&#65289;&#23398;&#29983;-&#25945;&#24072;&#26694;&#26550;&#65292;&#20854;&#20013;&#25945;&#24072;&#27169;&#22411;&#26159;&#23398;&#29983;&#27169;&#22411;&#30340;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#20540;&#65292;&#20197;&#21450;&#65288;2&#65289;&#20351;&#29992;&#28304;&#27169;&#22411;&#20316;&#20026;&#27491;&#21017;&#21270;&#39033;&#26469;&#25512;&#26029;&#26102;&#27491;&#21017;&#21270;&#27169;&#22411;&#26356;&#26032;&#12290;
&lt;/p&gt;
&lt;p&gt;
Test-time adaptation (TTA) is the problem of updating a pre-trained source model at inference time given test input(s) from a different target domain. Most existing TTA approaches assume the setting in which the target domain is stationary, i.e., all the test inputs come from a single target domain. However, in many practical settings, the test input distribution might exhibit a lifelong/continual shift over time. Moreover, existing TTA approaches also lack the ability to provide reliable uncertainty estimates, which is crucial when distribution shifts occur between the source and target domain. To address these issues, we present PETAL (Probabilistic lifElong Test-time Adaptation with seLf-training prior), which solves lifelong TTA using a probabilistic approach, and naturally results in (1) a student-teacher framework, where the teacher model is an exponential moving average of the student model, and (2) regularizing the model updates at inference time using the source model as a reg
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21363;&#20351;&#29992;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#38598;&#21512;&#26469;&#36817;&#20284;&#36125;&#21494;&#26031;&#21518;&#39564;&#65292;&#24182;&#36890;&#36807;&#21464;&#20998;&#25512;&#26029;&#36827;&#34892;&#35757;&#32451;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#27604;&#20854;&#20182;&#27969;&#34892;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#22522;&#32447;&#25552;&#20379;&#20102;&#26356;&#20934;&#30830;&#30340;&#21518;&#39564;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2212.08123</link><description>&lt;p&gt;
&#24102;&#26377;&#38543;&#26426;&#38598;&#21512;&#30340;&#36125;&#21494;&#26031;&#21518;&#39564;&#36817;&#20284;
&lt;/p&gt;
&lt;p&gt;
Bayesian posterior approximation with stochastic ensembles. (arXiv:2212.08123v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.08123
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21363;&#20351;&#29992;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#38598;&#21512;&#26469;&#36817;&#20284;&#36125;&#21494;&#26031;&#21518;&#39564;&#65292;&#24182;&#36890;&#36807;&#21464;&#20998;&#25512;&#26029;&#36827;&#34892;&#35757;&#32451;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#27604;&#20854;&#20182;&#27969;&#34892;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#22522;&#32447;&#25552;&#20379;&#20102;&#26356;&#20934;&#30830;&#30340;&#21518;&#39564;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#38598;&#30340;&#26041;&#27861;&#26469;&#36817;&#20284;&#36125;&#21494;&#26031;&#21518;&#39564;&#12290;&#23427;&#23558;&#38543;&#26426;&#26041;&#27861;&#65288;&#22914;dropout&#65289;&#19982;&#28145;&#24230;&#38598;&#25104;&#30456;&#32467;&#21512;&#65292;&#24182;&#23558;&#38543;&#26426;&#38598;&#21512;&#20844;&#24335;&#21270;&#20026;&#20998;&#24067;&#26063;&#65292;&#24182;&#20351;&#29992;&#21464;&#20998;&#25512;&#26029;&#35757;&#32451;&#20197;&#36817;&#20284;&#36125;&#21494;&#26031;&#21518;&#39564;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#29609;&#20855;&#38382;&#39064;&#21644;CIFAR&#22270;&#20687;&#20998;&#31867;&#19978;&#23454;&#29616;&#20102;&#22522;&#20110;Monte Carlo Dropout&#65292;DropConnect&#21644;&#26032;&#39062;&#30340;&#38750;&#21442;&#25968;&#29256;&#26412;&#30340;&#38543;&#26426;&#38598;&#21512;&#65292;&#24182;&#30452;&#25509;&#19982;&#21704;&#23494;&#39039;&#39532;&#23572;&#21487;&#22827;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#27604;&#36739;&#36136;&#37327;&#26469;&#27979;&#35797;&#21518;&#39564;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#38543;&#26426;&#38598;&#21512;&#25552;&#20379;&#20102;&#27604;&#20854;&#20182;&#27969;&#34892;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#22522;&#32447;&#26356;&#20934;&#30830;&#30340;&#21518;&#39564;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce ensembles of stochastic neural networks to approximate the Bayesian posterior, combining stochastic methods such as dropout with deep ensembles. The stochastic ensembles are formulated as families of distributions and trained to approximate the Bayesian posterior with variational inference. We implement stochastic ensembles based on Monte Carlo dropout, DropConnect and a novel non-parametric version of dropout and evaluate them on a toy problem and CIFAR image classification. For both tasks, we test the quality of the posteriors directly against Hamiltonian Monte Carlo simulations. Our results show that stochastic ensembles provide more accurate posterior estimates than other popular baselines for Bayesian inference.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;FaiREE&#31639;&#27861;&#65292;&#23427;&#26159;&#19968;&#31181;&#21487;&#28385;&#36275;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#30340;&#20844;&#24179;&#20998;&#31867;&#31639;&#27861;&#65292;&#24182;&#19988;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#21644;&#26080;&#20998;&#24067;&#29702;&#35770;&#20445;&#35777;&#12290;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2211.15072</link><description>&lt;p&gt;
FaiREE&#65306;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#21644;&#26080;&#20998;&#24067;&#20445;&#35777;&#30340;&#20844;&#24179;&#20998;&#31867;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
FaiREE: Fair Classification with Finite-Sample and Distribution-Free Guarantee. (arXiv:2211.15072v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.15072
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;FaiREE&#31639;&#27861;&#65292;&#23427;&#26159;&#19968;&#31181;&#21487;&#28385;&#36275;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#30340;&#20844;&#24179;&#20998;&#31867;&#31639;&#27861;&#65292;&#24182;&#19988;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#21644;&#26080;&#20998;&#24067;&#29702;&#35770;&#20445;&#35777;&#12290;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31639;&#27861;&#20844;&#24179;&#24615;&#22312;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#20013;&#21457;&#25381;&#30528;&#36234;&#26469;&#36234;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#20960;&#31181;&#32676;&#20307;&#20844;&#24179;&#24615;&#27010;&#24565;&#21644;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#20844;&#24179;&#20998;&#31867;&#26041;&#27861;&#30340;&#20844;&#24179;&#20445;&#35777;&#20027;&#35201;&#20381;&#36182;&#20110;&#29305;&#23450;&#30340;&#25968;&#25454;&#20998;&#24067;&#20551;&#35774;&#65292;&#36890;&#24120;&#38656;&#35201;&#22823;&#26679;&#26412;&#37327;&#65292;&#24182;&#19988;&#22312;&#26679;&#26412;&#37327;&#36739;&#23567;&#30340;&#24773;&#20917;&#19979;&#21487;&#33021;&#20250;&#36829;&#21453;&#20844;&#24179;&#24615;&#65292;&#32780;&#36825;&#22312;&#23454;&#36341;&#20013;&#32463;&#24120;&#21457;&#29983;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;FaiREE&#31639;&#27861;&#65292;&#23427;&#26159;&#19968;&#31181;&#20844;&#24179;&#20998;&#31867;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#26377;&#38480;&#26679;&#26412;&#21644;&#26080;&#20998;&#24067;&#29702;&#35770;&#20445;&#35777;&#19979;&#28385;&#36275;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#12290;FaiREE&#21487;&#20197;&#36866;&#24212;&#21508;&#31181;&#32676;&#20307;&#20844;&#24179;&#24615;&#27010;&#24565;&#65288;&#20363;&#22914;&#65292;&#26426;&#20250;&#24179;&#31561;&#65292;&#24179;&#34913;&#20960;&#29575;&#65292;&#20154;&#21475;&#32479;&#35745;&#23398;&#24179;&#34913;&#31561;&#65289;&#24182;&#23454;&#29616;&#26368;&#20339;&#20934;&#30830;&#24615;&#12290;&#36825;&#20123;&#29702;&#35770;&#20445;&#35777;&#36827;&#19968;&#27493;&#24471;&#21040;&#20102;&#23545;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#30340;&#23454;&#39564;&#25903;&#25345;&#12290;FaiREE&#34920;&#29616;&#20986;&#27604;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithmic fairness plays an increasingly critical role in machine learning research. Several group fairness notions and algorithms have been proposed. However, the fairness guarantee of existing fair classification methods mainly depends on specific data distributional assumptions, often requiring large sample sizes, and fairness could be violated when there is a modest number of samples, which is often the case in practice. In this paper, we propose FaiREE, a fair classification algorithm that can satisfy group fairness constraints with finite-sample and distribution-free theoretical guarantees. FaiREE can be adapted to satisfy various group fairness notions (e.g., Equality of Opportunity, Equalized Odds, Demographic Parity, etc.) and achieve the optimal accuracy. These theoretical guarantees are further supported by experiments on both synthetic and real data. FaiREE is shown to have favorable performance over state-of-the-art algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24322;&#24120;&#40065;&#26834;&#31232;&#30095;&#20272;&#35745;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#32447;&#24615;&#22238;&#24402;&#31995;&#25968;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#24050;&#30693;&#25110;&#26410;&#30693;&#30340;&#24773;&#20917;&#19979;&#65292;&#20855;&#26377;&#36739;&#23574;&#38160;&#30340;&#35823;&#24046;&#30028;&#65292;&#36866;&#29992;&#20110;&#37319;&#26679;&#33258;$\mathfrak{L}$-subGaussian&#20998;&#24067;&#21644;&#37325;&#23614;&#20998;&#24067;&#30340;&#21327;&#21464;&#37327;&#21521;&#37327;&#21644;&#22122;&#22768;&#12290;</title><link>http://arxiv.org/abs/2208.11592</link><description>&lt;p&gt;
&#32447;&#24615;&#22238;&#24402;&#31995;&#25968;&#30340;&#24322;&#24120;&#40065;&#26834;&#31232;&#30095;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Outlier Robust and Sparse Estimation of Linear Regression Coefficients. (arXiv:2208.11592v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.11592
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24322;&#24120;&#40065;&#26834;&#31232;&#30095;&#20272;&#35745;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#32447;&#24615;&#22238;&#24402;&#31995;&#25968;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#24050;&#30693;&#25110;&#26410;&#30693;&#30340;&#24773;&#20917;&#19979;&#65292;&#20855;&#26377;&#36739;&#23574;&#38160;&#30340;&#35823;&#24046;&#30028;&#65292;&#36866;&#29992;&#20110;&#37319;&#26679;&#33258;$\mathfrak{L}$-subGaussian&#20998;&#24067;&#21644;&#37325;&#23614;&#20998;&#24067;&#30340;&#21327;&#21464;&#37327;&#21521;&#37327;&#21644;&#22122;&#22768;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#24403;&#21327;&#21464;&#37327;&#21521;&#37327;&#21644;&#22122;&#22768;&#20998;&#21035;&#20174;$\mathfrak{L}$-subGaussian&#20998;&#24067;&#21644;&#37325;&#23614;&#20998;&#24067;&#20013;&#38543;&#26426;&#37319;&#26679;&#26102;&#65292;&#23545;&#32447;&#24615;&#22238;&#24402;&#31995;&#25968;&#36827;&#34892;&#24322;&#24120;&#40065;&#26834;&#31232;&#30095;&#20272;&#35745;&#12290;&#27492;&#22806;&#65292;&#21327;&#21464;&#37327;&#21521;&#37327;&#21644;&#22122;&#22768;&#21463;&#21040;&#23545;&#25239;&#24615;&#24322;&#24120;&#20540;&#30340;&#27745;&#26579;&#12290;&#25105;&#20204;&#22788;&#29702;&#20004;&#31181;&#24773;&#20917;&#65306;&#21327;&#21464;&#37327;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#24050;&#30693;&#25110;&#26410;&#30693;&#12290;&#29305;&#21035;&#22320;&#65292;&#22312;&#24050;&#30693;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#21487;&#20197;&#36798;&#21040;&#36817;&#20284;&#20449;&#24687;&#29702;&#35770;&#26368;&#20248;&#30340;&#35823;&#24046;&#30028;&#65292;&#19988;&#25105;&#20204;&#30340;&#35823;&#24046;&#30028;&#27604;&#26089;&#26399;&#22788;&#29702;&#31867;&#20284;&#24773;&#20917;&#30340;&#30740;&#31350;&#26356;&#21152;&#23574;&#38160;&#12290;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#20998;&#26512;&#22312;&#25512;&#23548;&#23574;&#38160;&#30340;&#35823;&#24046;&#30028;&#26041;&#38754;&#20005;&#37325;&#20381;&#36182;&#20110;&#36890;&#29992;&#38142;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider outlier-robust and sparse estimation of linear regression coefficients, when covariate vectors and noises are sampled, respectively, from an $\mathfrak{L}$-subGaussian distribution and a heavy-tailed distribution. Additionally, the covariate vectors and noises are contaminated by adversarial outliers. We deal with two cases: the covariance matrix of the covariates is known or unknown. Particularly, in the known case, our estimator can attain a nearly information theoretical optimal error bound, and our error bound is sharper than those of earlier studies dealing with similar situations. Our estimator analysis relies heavily on generic chaining to derive sharp error bounds.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#31070;&#32463;&#32593;&#32476;&#21644;&#26497;&#20540;&#29702;&#35770;&#30340;EQRN&#27169;&#22411;&#65292;&#23427;&#33021;&#22815;&#22312;&#23384;&#22312;&#22797;&#26434;&#39044;&#27979;&#21464;&#37327;&#30456;&#20851;&#24615;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#22806;&#25512;&#65292;&#24182;&#19988;&#33021;&#22815;&#24212;&#29992;&#20110;&#27946;&#27700;&#39118;&#38505;&#39044;&#27979;&#20013;&#65292;&#25552;&#20379;&#19968;&#22825;&#21069;&#22238;&#24402;&#27700;&#24179;&#21644;&#36229;&#20986;&#27010;&#29575;&#30340;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2208.07590</link><description>&lt;p&gt;
&#26497;&#31471;&#20998;&#20301;&#25968;&#22238;&#24402;&#30340;&#31070;&#32463;&#32593;&#32476;&#19982;&#27946;&#27700;&#39118;&#38505;&#39044;&#27979;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Neural Networks for Extreme Quantile Regression with an Application to Forecasting of Flood Risk. (arXiv:2208.07590v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.07590
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#31070;&#32463;&#32593;&#32476;&#21644;&#26497;&#20540;&#29702;&#35770;&#30340;EQRN&#27169;&#22411;&#65292;&#23427;&#33021;&#22815;&#22312;&#23384;&#22312;&#22797;&#26434;&#39044;&#27979;&#21464;&#37327;&#30456;&#20851;&#24615;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#22806;&#25512;&#65292;&#24182;&#19988;&#33021;&#22815;&#24212;&#29992;&#20110;&#27946;&#27700;&#39118;&#38505;&#39044;&#27979;&#20013;&#65292;&#25552;&#20379;&#19968;&#22825;&#21069;&#22238;&#24402;&#27700;&#24179;&#21644;&#36229;&#20986;&#27010;&#29575;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#26497;&#31471;&#20107;&#20214;&#30340;&#39118;&#38505;&#35780;&#20272;&#38656;&#35201;&#20934;&#30830;&#20272;&#35745;&#36229;&#20986;&#21382;&#21490;&#35266;&#27979;&#33539;&#22260;&#30340;&#39640;&#20998;&#20301;&#25968;&#12290;&#24403;&#39118;&#38505;&#20381;&#36182;&#20110;&#35266;&#27979;&#39044;&#27979;&#21464;&#37327;&#30340;&#20540;&#26102;&#65292;&#22238;&#24402;&#25216;&#26415;&#29992;&#20110;&#22312;&#39044;&#27979;&#31354;&#38388;&#20013;&#36827;&#34892;&#25554;&#20540;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;EQRN&#27169;&#22411;&#65292;&#23427;&#23558;&#31070;&#32463;&#32593;&#32476;&#21644;&#26497;&#20540;&#29702;&#35770;&#30340;&#24037;&#20855;&#32467;&#21512;&#36215;&#26469;&#65292;&#24418;&#25104;&#19968;&#31181;&#33021;&#22815;&#22312;&#22797;&#26434;&#39044;&#27979;&#21464;&#37327;&#30456;&#20851;&#24615;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#22806;&#25512;&#30340;&#26041;&#27861;&#12290;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#33258;&#28982;&#22320;&#23558;&#25968;&#25454;&#20013;&#30340;&#38468;&#21152;&#32467;&#26500;&#32435;&#20837;&#20854;&#20013;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;EQRN&#30340;&#24490;&#29615;&#29256;&#26412;&#65292;&#33021;&#22815;&#25429;&#25417;&#26102;&#38388;&#24207;&#21015;&#20013;&#22797;&#26434;&#30340;&#39034;&#24207;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#26041;&#27861;&#24212;&#29992;&#20110;&#29790;&#22763;Aare&#27969;&#22495;&#30340;&#27946;&#27700;&#39118;&#38505;&#39044;&#27979;&#12290;&#23427;&#21033;&#29992;&#31354;&#38388;&#21644;&#26102;&#38388;&#19978;&#30340;&#22810;&#20010;&#21327;&#21464;&#37327;&#20449;&#24687;&#65292;&#25552;&#20379;&#19968;&#22825;&#21069;&#22238;&#24402;&#27700;&#24179;&#21644;&#36229;&#20986;&#27010;&#29575;&#30340;&#39044;&#27979;&#12290;&#36825;&#20010;&#36755;&#20986;&#34917;&#20805;&#20102;&#20256;&#32479;&#26497;&#20540;&#20998;&#26512;&#30340;&#38745;&#24577;&#22238;&#24402;&#27700;&#24179;&#65292;&#24182;&#19988;&#39044;&#27979;&#33021;&#22815;&#36866;&#24212;&#20998;&#24067;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Risk assessment for extreme events requires accurate estimation of high quantiles that go beyond the range of historical observations. When the risk depends on the values of observed predictors, regression techniques are used to interpolate in the predictor space. We propose the EQRN model that combines tools from neural networks and extreme value theory into a method capable of extrapolation in the presence of complex predictor dependence. Neural networks can naturally incorporate additional structure in the data. We develop a recurrent version of EQRN that is able to capture complex sequential dependence in time series. We apply this method to forecasting of flood risk in the Swiss Aare catchment. It exploits information from multiple covariates in space and time to provide one-day-ahead predictions of return levels and exceedances probabilities. This output complements the static return level from a traditional extreme value analysis and the predictions are able to adapt to distribu
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#28145;&#24230;&#25209;&#37327;&#20027;&#21160;&#23398;&#20064;&#22238;&#24402;&#30340;&#26694;&#26550;&#21644;&#22522;&#20934;&#27979;&#35797;&#65292;&#20854;&#20013;&#21253;&#25324;&#35768;&#22810;&#29616;&#26377;&#30340;&#36125;&#21494;&#26031;&#21644;&#38750;&#36125;&#21494;&#26031;&#26041;&#27861;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#25442;&#24120;&#29992;&#26368;&#21518;&#19968;&#23618;&#29305;&#24449;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#32467;&#21512;&#19968;&#31181;&#26032;&#39062;&#30340;&#32858;&#31867;&#26041;&#27861;&#12290;&#22312;15&#20010;&#22823;&#22411;&#34920;&#26684;&#22238;&#24402;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#27979;&#35797;&#65292;&#35813;&#26041;&#27861;&#22312;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20248;&#24322;&#65292;&#36866;&#29992;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#19988;&#26131;&#20110;&#20351;&#29992;&#12290;</title><link>http://arxiv.org/abs/2203.09410</link><description>&lt;p&gt;
&#28145;&#24230;&#25209;&#37327;&#20027;&#21160;&#23398;&#20064;&#22238;&#24402;&#30340;&#26694;&#26550;&#21644;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
A Framework and Benchmark for Deep Batch Active Learning for Regression. (arXiv:2203.09410v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.09410
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#28145;&#24230;&#25209;&#37327;&#20027;&#21160;&#23398;&#20064;&#22238;&#24402;&#30340;&#26694;&#26550;&#21644;&#22522;&#20934;&#27979;&#35797;&#65292;&#20854;&#20013;&#21253;&#25324;&#35768;&#22810;&#29616;&#26377;&#30340;&#36125;&#21494;&#26031;&#21644;&#38750;&#36125;&#21494;&#26031;&#26041;&#27861;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#25442;&#24120;&#29992;&#26368;&#21518;&#19968;&#23618;&#29305;&#24449;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#32467;&#21512;&#19968;&#31181;&#26032;&#39062;&#30340;&#32858;&#31867;&#26041;&#27861;&#12290;&#22312;15&#20010;&#22823;&#22411;&#34920;&#26684;&#22238;&#24402;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#27979;&#35797;&#65292;&#35813;&#26041;&#27861;&#22312;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20248;&#24322;&#65292;&#36866;&#29992;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#19988;&#26131;&#20110;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#27880;&#30417;&#30563;&#23398;&#20064;&#25968;&#25454;&#30340;&#33719;&#21462;&#25104;&#26412;&#36739;&#39640;&#12290;&#20026;&#20102;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#22238;&#24402;&#30340;&#26679;&#26412;&#25928;&#29575;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#33258;&#36866;&#24212;&#36873;&#25321;&#26080;&#26631;&#31614;&#25968;&#25454;&#25209;&#27425;&#36827;&#34892;&#26631;&#27880;&#30340;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#26500;&#24314;&#36825;&#26679;&#30340;&#26041;&#27861;&#65292;&#22522;&#20110;(&#32593;&#32476;&#30456;&#20851;&#30340;)&#22522;&#30784;&#26680;&#12289;&#26680;&#21464;&#25442;&#21644;&#36873;&#25321;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21253;&#25324;&#35768;&#22810;&#29616;&#26377;&#30340;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#36924;&#36817;&#31070;&#32463;&#32593;&#32476;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#20197;&#21450;&#38750;&#36125;&#21494;&#26031;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24314;&#35758;&#29992;&#25551;&#32472;&#26377;&#38480;&#23485;&#24230;&#31070;&#32463;&#27491;&#20999;&#26680;&#26367;&#25442;&#24120;&#29992;&#30340;&#26368;&#21518;&#19968;&#23618;&#29305;&#24449;&#65292;&#24182;&#23558;&#23427;&#20204;&#19982;&#19968;&#31181;&#26032;&#39062;&#30340;&#32858;&#31867;&#26041;&#27861;&#30456;&#32467;&#21512;&#12290;&#20026;&#20102;&#35780;&#20272;&#19981;&#21516;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#30001;15&#20010;&#22823;&#22411;&#34920;&#26684;&#22238;&#24402;&#25968;&#25454;&#38598;&#32452;&#25104;&#30340;&#24320;&#25918;&#28304;&#20195;&#30721;&#30340;&#22522;&#20934;&#27979;&#35797;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#22522;&#20934;&#27979;&#35797;&#20013;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#27700;&#24179;&#65292;&#36866;&#29992;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#65292;&#24182;&#19988;&#21487;&#20197;&#30452;&#25509;&#20351;&#29992;&#65292;&#26080;&#38656;&#35843;&#25972;&#32593;&#32476;&#26550;&#26500;&#25110;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
The acquisition of labels for supervised learning can be expensive. In order to improve the sample-efficiency of neural network regression, we study active learning methods that adaptively select batches of unlabeled data for labeling. We present a framework for constructing such methods out of (network-dependent) base kernels, kernel transformations and selection methods. Our framework encompasses many existing Bayesian methods based on Gaussian Process approximations of neural networks as well as non-Bayesian methods. Additionally, we propose to replace the commonly used last-layer features with sketched finite-width Neural Tangent Kernels, and to combine them with a novel clustering method. To evaluate different methods, we introduce an open-source benchmark consisting of 15 large tabular regression data sets. Our proposed method outperforms the state-of-the-art on our benchmark, scales to large data sets, and works out-of-the-box without adjusting the network architecture or traini
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36845;&#20195;&#20998;&#22359;&#31890;&#23376;&#28388;&#27874;&#31639;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#39640;&#32500;&#21442;&#25968;&#12290;&#35813;&#31639;&#27861;&#20811;&#26381;&#20102;&#32500;&#24230;&#28798;&#38590;&#65292;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#25910;&#25947;&#24615;&#21644;&#20284;&#28982;&#26368;&#22823;&#21270;&#65292;&#25104;&#21151;&#22320;&#22312;&#38750;&#32447;&#24615;&#21644;&#38750;&#39640;&#26031;&#31354;&#38388;&#26102;&#38388;&#27169;&#22411;&#19978;&#23454;&#29616;&#20102;&#21442;&#25968;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2110.10745</link><description>&lt;p&gt;
&#39640;&#32500;&#21442;&#25968;&#23398;&#20064;&#30340;&#36845;&#20195;&#20998;&#22359;&#31890;&#23376;&#28388;&#27874;&#31639;&#27861;&#65306;&#25670;&#33073;&#32500;&#24230;&#28798;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;
Iterated Block Particle Filter for High-dimensional Parameter Learning: Beating the Curse of Dimensionality. (arXiv:2110.10745v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.10745
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36845;&#20195;&#20998;&#22359;&#31890;&#23376;&#28388;&#27874;&#31639;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#39640;&#32500;&#21442;&#25968;&#12290;&#35813;&#31639;&#27861;&#20811;&#26381;&#20102;&#32500;&#24230;&#28798;&#38590;&#65292;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#25910;&#25947;&#24615;&#21644;&#20284;&#28982;&#26368;&#22823;&#21270;&#65292;&#25104;&#21151;&#22320;&#22312;&#38750;&#32447;&#24615;&#21644;&#38750;&#39640;&#26031;&#31354;&#38388;&#26102;&#38388;&#27169;&#22411;&#19978;&#23454;&#29616;&#20102;&#21442;&#25968;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#12289;&#37096;&#20998;&#35266;&#27979;&#21644;&#38750;&#32447;&#24615;&#38543;&#26426;&#36807;&#31243;&#30340;&#21442;&#25968;&#23398;&#20064;&#26159;&#19968;&#31181;&#26041;&#27861;&#35770;&#19978;&#30340;&#25361;&#25112;&#12290;&#31354;&#38388;&#26102;&#38388;&#30142;&#30149;&#20256;&#25773;&#31995;&#32479;&#25552;&#20379;&#20102;&#36825;&#31181;&#20135;&#29983;&#24320;&#25918;&#25512;&#26029;&#38382;&#39064;&#30340;&#36807;&#31243;&#30340;&#31034;&#20363;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#36845;&#20195;&#20998;&#22359;&#31890;&#23376;&#28388;&#27874;&#31639;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#20855;&#26377;&#19968;&#33324;&#29366;&#24577;&#31354;&#38388;&#12289;&#27979;&#37327;&#12289;&#36716;&#31227;&#23494;&#24230;&#21644;&#22270;&#32467;&#26500;&#30340;&#22270;&#24418;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#39640;&#32500;&#21442;&#25968;&#12290;&#23545;&#20987;&#36133;&#32500;&#24230;&#28798;&#38590; (COD)&#12289;&#31639;&#27861;&#25910;&#25947;&#21644;&#20284;&#28982;&#26368;&#22823;&#21270;&#33719;&#24471;&#20102;&#29702;&#35770;&#24615;&#33021;&#20445;&#35777;&#12290;&#23545;&#40635;&#30137;&#20256;&#25773;&#30340;&#39640;&#24230;&#38750;&#32447;&#24615;&#21644;&#38750;&#39640;&#26031;&#31354;&#38388;&#26102;&#38388;&#27169;&#22411;&#36827;&#34892;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#36845;&#20195;&#38598;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#31639;&#27861; (Li et al. (2020)) &#26159;&#26080;&#25928;&#30340;&#65292;&#32780;&#36845;&#20195;&#28388;&#27874;&#31639;&#27861; (Ionides et al. (2015)) &#21463;&#21040;&#32500;&#24230;&#28798;&#38590;&#30340;&#22256;&#25200;&#65292;&#32780;&#25105;&#20204;&#30340;IBPF&#31639;&#27861;&#22312;&#21508;&#31181;&#20855;&#26377;&#19981;&#21516;&#24230;&#37327;&#30340;&#23454;&#39564;&#20013;&#22987;&#32456;&#20987;&#36133;&#20102;COD&#12290;
&lt;/p&gt;
&lt;p&gt;
Parameter learning for high-dimensional, partially observed, and nonlinear stochastic processes is a methodological challenge. Spatiotemporal disease transmission systems provide examples of such processes giving rise to open inference problems. We propose the iterated block particle filter (IBPF) algorithm for learning high-dimensional parameters over graphical state space models with general state spaces, measures, transition densities and graph structure. Theoretical performance guarantees are obtained on beating the curse of dimensionality (COD), algorithm convergence, and likelihood maximization. Experiments on a highly nonlinear and non-Gaussian spatiotemporal model for measles transmission reveal that the iterated ensemble Kalman filter algorithm (Li et al. (2020)) is ineffective and the iterated filtering algorithm (Ionides et al. (2015)) suffers from the COD, while our IBPF algorithm beats COD consistently across various experiments with different metrics.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#32852;&#21512;&#20998;&#24067;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#20174;&#22823;&#37327;&#25968;&#25454;&#28857;&#20013;&#20272;&#35745;&#20302;&#32500;&#12289;&#24402;&#19968;&#21270;&#21644;&#27491;&#30340;Radon-Nikodym&#23548;&#25968;&#27169;&#22411;&#65292;&#24182;&#22312;&#19981;&#21516;&#23398;&#20064;&#38382;&#39064;&#19978;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2110.04829</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#32852;&#21512;&#20998;&#24067;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Adaptive joint distribution learning. (arXiv:2110.04829v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.04829
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#32852;&#21512;&#20998;&#24067;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#20174;&#22823;&#37327;&#25968;&#25454;&#28857;&#20013;&#20272;&#35745;&#20302;&#32500;&#12289;&#24402;&#19968;&#21270;&#21644;&#27491;&#30340;Radon-Nikodym&#23548;&#25968;&#27169;&#22411;&#65292;&#24182;&#22312;&#19981;&#21516;&#23398;&#20064;&#38382;&#39064;&#19978;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23558;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#23884;&#20837;&#24352;&#37327;&#31215;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#20013;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#23481;&#32435;&#19968;&#20010;&#20302;&#32500;&#12289;&#24402;&#19968;&#21270;&#21644;&#27491;&#30340;Radon-Nikodym&#23548;&#25968;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#20174;&#22810;&#36798;&#25968;&#30334;&#19975;&#20010;&#25968;&#25454;&#28857;&#30340;&#26679;&#26412;&#22823;&#23567;&#20013;&#36827;&#34892;&#20272;&#35745;&#65292;&#20943;&#36731;&#20102;RKHS&#24314;&#27169;&#30340;&#22266;&#26377;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#33258;&#28982;&#20135;&#29983;&#20102;&#23450;&#20041;&#33391;&#22909;&#30340;&#24402;&#19968;&#21270;&#21644;&#27491;&#30340;&#26465;&#20214;&#20998;&#24067;&#12290;&#23884;&#20837;&#35745;&#31639;&#36895;&#24230;&#24555;&#19988;&#36866;&#29992;&#20110;&#20174;&#39044;&#27979;&#21040;&#20998;&#31867;&#30340;&#21508;&#31181;&#23398;&#20064;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#24471;&#21040;&#20102;&#26377;&#30410;&#30340;&#25968;&#20540;&#32467;&#26524;&#30340;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a new framework for embedding joint probability distributions in tensor product reproducing kernel Hilbert spaces (RKHS). Our framework accommodates a low-dimensional, normalized and positive model of a Radon-Nikodym derivative, which we estimate from sample sizes of up to several million data points, alleviating the inherent limitations of RKHS modeling. Well-defined normalized and positive conditional distributions are natural by-products to our approach. The embedding is fast to compute and accommodates learning problems ranging from prediction to classification. Our theoretical findings are supplemented by favorable numerical results.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#21487;&#34892;&#21644;&#26041;&#27861;&#23398;&#19978;&#21512;&#29702;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#21333;&#20010;&#34987;&#35797;&#21644;&#20302;&#20449;&#21495;&#32972;&#26223;&#19979;&#30340;&#21151;&#33021;&#24615;&#30913;&#20849;&#25391;&#25104;&#20687;&#30340;&#28608;&#27963;&#26816;&#27979;&#38382;&#39064;&#65292;&#24182;&#33021;&#22815;&#21306;&#20998;&#19981;&#21516;&#24378;&#24230;&#30340;&#28608;&#27963;&#65292;&#36890;&#36807;&#22312; R &#21253; MixfMRI &#20013;&#23454;&#29616;&#21487;&#20197;&#24471;&#21040;&#20855;&#20307;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2102.03639</link><description>&lt;p&gt;
&#19968;&#31181;&#23454;&#29992;&#30340;&#27169;&#22411;&#20998;&#26512;&#26041;&#27861;&#22312;&#21333;&#20010;&#34987;&#35797;&#21151;&#33021;&#24615;&#30913;&#20849;&#25391;&#25104;&#20687;&#30740;&#31350;&#20013;&#25552;&#39640;&#28608;&#27963;&#26816;&#27979;&#30340;&#31934;&#24230;
&lt;/p&gt;
&lt;p&gt;
A practical model-based segmentation approach for improved activation detection in single-subject functional Magnetic Resonance Imaging studies. (arXiv:2102.03639v3 [stat.AP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.03639
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#21487;&#34892;&#21644;&#26041;&#27861;&#23398;&#19978;&#21512;&#29702;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#21333;&#20010;&#34987;&#35797;&#21644;&#20302;&#20449;&#21495;&#32972;&#26223;&#19979;&#30340;&#21151;&#33021;&#24615;&#30913;&#20849;&#25391;&#25104;&#20687;&#30340;&#28608;&#27963;&#26816;&#27979;&#38382;&#39064;&#65292;&#24182;&#33021;&#22815;&#21306;&#20998;&#19981;&#21516;&#24378;&#24230;&#30340;&#28608;&#27963;&#65292;&#36890;&#36807;&#22312; R &#21253; MixfMRI &#20013;&#23454;&#29616;&#21487;&#20197;&#24471;&#21040;&#20855;&#20307;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21151;&#33021;&#24615;&#30913;&#20849;&#25391;&#25104;&#20687;&#65288;fMRI&#65289;&#29992;&#20110;&#23545;&#21050;&#28608;&#30340;&#22823;&#33041;&#28608;&#27963;&#36827;&#34892;&#25104;&#20687;&#65292;&#20294;&#26159;&#22312;&#20302;&#20449;&#21495;&#29615;&#22659;&#21644;&#21333;&#20010;&#21463;&#35797;&#30740;&#31350;&#20013;&#24448;&#24448;&#38590;&#20197;&#26816;&#27979;&#21040;&#36825;&#31181;&#28608;&#27963;&#12290;&#32771;&#34385;&#21040;&#23454;&#38469;&#19978;&#21482;&#26377;&#26497;&#23569;&#25968;&#20307;&#32032;&#30495;&#27491;&#34987;&#28608;&#27963;&#65292;&#32780;&#19988;&#36825;&#20123;&#20307;&#32032;&#22312;&#31354;&#38388;&#19978;&#26159;&#23616;&#37096;&#21270;&#30340;&#65292;&#22240;&#27492;&#21487;&#20197;&#36890;&#36807;&#20934;&#30830;&#30340;&#28608;&#27963;&#26816;&#27979;&#26469;&#25351;&#23548;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#21457;&#23637;&#19968;&#31181;&#35745;&#31639;&#21487;&#34892;&#21644;&#26041;&#27861;&#23398;&#19978;&#21512;&#29702;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#26469;&#24212;&#23545;&#36825;&#20010;&#25361;&#25112;&#65292;&#22312; R &#21253; MixfMRI &#20013;&#23454;&#29616;&#65292;&#20854;&#38480;&#21046;&#20102;&#20808;&#39564;&#39044;&#26399;&#30340;&#28608;&#27963;&#20307;&#32032;&#27604;&#20363;&#65292;&#24182;&#32467;&#21512;&#20102;&#31354;&#38388;&#19978;&#19979;&#25991;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#19968;&#20010;&#38468;&#21152;&#20248;&#21183;&#26159;&#33021;&#22815;&#21306;&#20998;&#19981;&#21516;&#24378;&#24230;&#28608;&#27963;&#30340;&#20307;&#32032;&#21644;&#21306;&#22495;&#12290;&#26412;&#30740;&#31350;&#30340;&#26041;&#27861;&#22312;&#29616;&#23454;&#30340;&#20108;&#32500;&#21644;&#19977;&#32500;&#27169;&#25311;&#23454;&#39564;&#20197;&#21450;&#22810;&#20010;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#20013;&#24471;&#21040;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Functional Magnetic Resonance Imaging (fMRI) maps cerebral activation in response to stimuli but this activation is often difficult to detect, especially in low-signal contexts and single-subject studies. Accurate activation detection can be guided by the fact that very few voxels are, in reality, truly activated and that these voxels are spatially localized, but it is challenging to incorporate both these facts. We address these twin challenges to single-subject and low-signal fMRI by developing a computationally feasible and methodologically sound model-based approach, implemented in the R package MixfMRI, that bounds the a priori expected proportion of activated voxels while also incorporating spatial context. An added benefit of our methodology is the ability to distinguish voxels and regions having different intensities of activation. Our suggested approach is evaluated in realistic two- and three-dimensional simulation experiments as well as on multiple real-world datasets. Final
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;MARS&#30340;&#26032;&#22411;&#39640;&#25928;&#26041;&#27861;&#65292;&#22312;&#19968;&#33324;&#30340;&#24352;&#37327;&#20998;&#35299;&#20013;&#33258;&#21160;&#36873;&#25321;&#31209;&#65292;&#23398;&#20064;&#20108;&#20540;&#25513;&#30721;&#26469;&#36873;&#25321;&#26368;&#20339;&#30340;&#24352;&#37327;&#32467;&#26500;&#65292;&#22312;&#23454;&#39564;&#20013;&#26174;&#31034;&#20986;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2006.10859</link><description>&lt;p&gt;
MARS:&#24352;&#37327;&#20998;&#35299;&#20013;&#30340;&#33258;&#21160;&#25490;&#21517;&#36873;&#25321;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
MARS: Masked Automatic Ranks Selection in Tensor Decompositions. (arXiv:2006.10859v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.10859
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;MARS&#30340;&#26032;&#22411;&#39640;&#25928;&#26041;&#27861;&#65292;&#22312;&#19968;&#33324;&#30340;&#24352;&#37327;&#20998;&#35299;&#20013;&#33258;&#21160;&#36873;&#25321;&#31209;&#65292;&#23398;&#20064;&#20108;&#20540;&#25513;&#30721;&#26469;&#36873;&#25321;&#26368;&#20339;&#30340;&#24352;&#37327;&#32467;&#26500;&#65292;&#22312;&#23454;&#39564;&#20013;&#26174;&#31034;&#20986;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;&#24050;&#34987;&#35777;&#26126;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#20855;&#26377;&#24456;&#22909;&#30340;&#25928;&#26524;&#65292;&#21253;&#25324;&#31070;&#32463;&#32593;&#32476;&#30340;&#21387;&#32553;&#21644;&#21152;&#36895;&#12290;&#21516;&#26102;&#65292;&#30830;&#23450;&#26368;&#20248;&#20998;&#35299;&#31209;&#30340;&#38382;&#39064;&#20173;&#28982;&#24456;&#20005;&#23803;&#65292;&#22240;&#20026;&#23427;&#26159;&#25511;&#21046;&#21387;&#32553;-&#20934;&#30830;&#24615;&#24179;&#34913;&#30340;&#20851;&#38190;&#21442;&#25968;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;MARS&#30340;&#26032;&#22411;&#39640;&#25928;&#26041;&#27861;&#65292;&#22312;&#19968;&#33324;&#30340;&#24352;&#37327;&#20998;&#35299;&#20013;&#33258;&#21160;&#36873;&#25321;&#31209;&#12290;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#35813;&#26041;&#27861;&#23398;&#20064;&#20108;&#20540;&#25513;&#30721;&#65292;&#36825;&#20123;&#25513;&#30721;&#21487;&#20197;&#36873;&#25321;&#26368;&#20339;&#30340;&#24352;&#37327;&#32467;&#26500;&#12290;&#23398;&#20064;&#26159;&#36890;&#36807;&#29305;&#23450;&#30340;&#36125;&#21494;&#26031;&#27169;&#22411;&#20013;&#30340;&#26494;&#24347;&#26368;&#22823;&#21518;&#39564;(MAP)&#20272;&#35745;&#26469;&#23436;&#25104;&#30340;&#65292;&#24182;&#21487;&#20197;&#33258;&#28982;&#22320;&#23884;&#20837;&#21040;&#26631;&#20934;&#30340;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#36807;&#31243;&#20013;&#12290;&#21508;&#31181;&#23454;&#39564;&#34920;&#26126;&#65292;&#19982;&#20808;&#21069;&#30340;&#24037;&#20316;&#30456;&#27604;&#65292;MARS&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#37117;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tensor decomposition methods have proven effective in various applications, including compression and acceleration of neural networks. At the same time, the problem of determining optimal decomposition ranks, which present the crucial parameter controlling the compression-accuracy trade-off, is still acute. In this paper, we introduce MARS -- a new efficient method for the automatic selection of ranks in general tensor decompositions. During training, the procedure learns binary masks over decomposition cores that "select" the optimal tensor structure. The learning is performed via relaxed maximum a posteriori (MAP) estimation in a specific Bayesian model and can be naturally embedded into the standard neural network training routine. Diverse experiments demonstrate that MARS achieves better results compared to previous works in various tasks.
&lt;/p&gt;</description></item></channel></rss>