<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24754;&#35266;&#38750;&#32447;&#24615;&#26368;&#23567;&#20108;&#20056;&#20540;&#36845;&#20195;&#31639;&#27861;&#65288;PNLSVI&#65289;&#65292;&#29992;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#38382;&#39064;&#12290;&#35813;&#31639;&#27861;&#20855;&#26377;&#21019;&#26032;&#30340;&#26041;&#24046;&#21152;&#26435;&#22238;&#24402;&#26041;&#26696;&#12289;&#26041;&#24046;&#20272;&#35745;&#23376;&#31243;&#24207;&#21644;&#24754;&#35266;&#20540;&#36845;&#20195;&#26041;&#27861;&#30340;&#35268;&#21010;&#38454;&#27573;&#12290;</title><link>http://arxiv.org/abs/2310.01380</link><description>&lt;p&gt;
&#24754;&#35266;&#38750;&#32447;&#24615;&#26368;&#23567;&#20108;&#20056;&#20540;&#36845;&#20195;&#31639;&#27861;&#29992;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning. (arXiv:2310.01380v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01380
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24754;&#35266;&#38750;&#32447;&#24615;&#26368;&#23567;&#20108;&#20056;&#20540;&#36845;&#20195;&#31639;&#27861;&#65288;PNLSVI&#65289;&#65292;&#29992;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#38382;&#39064;&#12290;&#35813;&#31639;&#27861;&#20855;&#26377;&#21019;&#26032;&#30340;&#26041;&#24046;&#21152;&#26435;&#22238;&#24402;&#26041;&#26696;&#12289;&#26041;&#24046;&#20272;&#35745;&#23376;&#31243;&#24207;&#21644;&#24754;&#35266;&#20540;&#36845;&#20195;&#26041;&#27861;&#30340;&#35268;&#21010;&#38454;&#27573;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65288;Offline RL&#65289;&#26159;&#25351;&#26234;&#33021;&#20307;&#26681;&#25454;&#30001;&#34892;&#20026;&#31574;&#30053;&#25910;&#38598;&#30340;&#25968;&#25454;&#23398;&#20064;&#26368;&#20248;&#31574;&#30053;&#30340;&#20219;&#21153;&#65292;&#36817;&#24180;&#26469;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#34429;&#28982;&#22312;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#24050;&#32463;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#24182;&#22312;&#19968;&#23450;&#20551;&#35774;&#19979;&#21462;&#24471;&#20102;&#26368;&#20248;&#32467;&#26524;&#65292;&#20294;&#24456;&#22810;&#30740;&#31350;&#23558;&#20852;&#36259;&#36716;&#21521;&#20102;&#38750;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#38750;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#20855;&#26377;&#23454;&#20363;&#20381;&#36182;&#21518;&#24724;&#20445;&#35777;&#30340;&#30740;&#31350;&#24037;&#20316;&#21364;&#24456;&#26377;&#38480;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#24754;&#35266;&#38750;&#32447;&#24615;&#26368;&#23567;&#20108;&#20056;&#20540;&#36845;&#20195;&#65288;PNLSVI&#65289;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#29992;&#20110;&#38750;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#35774;&#35745;&#21253;&#25324;&#19977;&#20010;&#21019;&#26032;&#30340;&#32452;&#25104;&#37096;&#20998;&#65306;&#65288;1&#65289;&#19968;&#31181;&#22522;&#20110;&#26041;&#24046;&#21152;&#26435;&#22238;&#24402;&#30340;&#26041;&#26696;&#65292;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#20989;&#25968;&#31867;&#65307;&#65288;2&#65289;&#19968;&#31181;&#26041;&#24046;&#20272;&#35745;&#23376;&#31243;&#24207;&#65307;&#21644;&#65288;3&#65289;&#19968;&#20010;&#21033;&#29992;&#24754;&#35266;&#20540;&#36845;&#20195;&#26041;&#27861;&#30340;&#35268;&#21010;&#38454;&#27573;&#12290;
&lt;/p&gt;
&lt;p&gt;
Offline reinforcement learning (RL), where the agent aims to learn the optimal policy based on the data collected by a behavior policy, has attracted increasing attention in recent years. While offline RL with linear function approximation has been extensively studied with optimal results achieved under certain assumptions, many works shift their interest to offline RL with non-linear function approximation. However, limited works on offline RL with non-linear function approximation have instance-dependent regret guarantees. In this paper, we propose an oracle-efficient algorithm, dubbed Pessimistic Nonlinear Least-Square Value Iteration (PNLSVI), for offline RL with non-linear function approximation. Our algorithmic design comprises three innovative components: (1) a variance-based weighted regression scheme that can be applied to a wide range of function classes, (2) a subroutine for variance estimation, and (3) a planning phase that utilizes a pessimistic value iteration approach. O
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24191;&#20041;&#20132;&#21449;&#39564;&#35777;&#65288;GCV&#65289;&#22312;&#26377;&#38480;&#24809;&#32602;&#20272;&#35745;&#22120;&#38598;&#21512;&#20013;&#20272;&#35745;&#39044;&#27979;&#39118;&#38505;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#27491;&#26041;&#27861;&#65288;CGCV&#65289;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.01374</link><description>&lt;p&gt;
&#26377;&#38480;&#24809;&#32602;&#20272;&#35745;&#22120;&#38598;&#21512;&#30340;&#20462;&#27491;&#24191;&#20041;&#20132;&#21449;&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;
Corrected generalized cross-validation for finite ensembles of penalized estimators. (arXiv:2310.01374v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01374
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24191;&#20041;&#20132;&#21449;&#39564;&#35777;&#65288;GCV&#65289;&#22312;&#26377;&#38480;&#24809;&#32602;&#20272;&#35745;&#22120;&#38598;&#21512;&#20013;&#20272;&#35745;&#39044;&#27979;&#39118;&#38505;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#27491;&#26041;&#27861;&#65288;CGCV&#65289;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24191;&#20041;&#20132;&#21449;&#39564;&#35777;&#65288;GCV&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#22312;&#26679;&#26412;&#22806;&#36827;&#34892;&#39044;&#27979;&#30340;&#39118;&#38505;&#24179;&#26041;&#65292;&#24182;&#37319;&#29992;&#26631;&#37327;&#33258;&#30001;&#24230;&#35843;&#25972;&#65288;&#20197;&#20056;&#27861;&#22686;&#21152;&#65289;&#26469;&#35843;&#25972;&#35757;&#32451;&#35823;&#24046;&#30340;&#24179;&#26041;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;GCV&#19968;&#33268;&#20272;&#35745;&#20219;&#24847;&#24809;&#32602;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#38598;&#21512;&#39044;&#27979;&#39118;&#38505;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23545;&#20110;&#20219;&#20309;&#22823;&#20110;&#19968;&#30340;&#26377;&#38480;&#22823;&#23567;&#30340;&#20272;&#35745;&#22120;&#38598;&#21512;&#65292;GCV&#26159;&#19981;&#19968;&#33268;&#30340;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#20010;&#32570;&#28857;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32416;&#27491;&#65292;&#23427;&#28041;&#21450;&#21040;&#23545;&#27599;&#20010;&#38598;&#21512;&#25104;&#20998;&#30340;&#33258;&#30001;&#24230;&#35843;&#25972;&#35757;&#32451;&#35823;&#24046;&#30340;&#39069;&#22806;&#26631;&#37327;&#20462;&#27491;&#65288;&#20197;&#21152;&#27861;&#22686;&#21152;&#65289;&#12290;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#65288;&#31216;&#20026;CGCV&#65289;&#20445;&#25345;&#20102;GCV&#30340;&#35745;&#31639;&#20248;&#21183;&#65292;&#26082;&#19981;&#38656;&#35201;&#26679;&#26412;&#20998;&#35010;&#65292;&#27169;&#22411;&#37325;&#25311;&#65292;&#20063;&#19981;&#38656;&#35201;&#21253;&#22806;&#39118;&#38505;&#20272;&#35745;&#12290;&#35813;&#20272;&#35745;&#22120;&#28304;&#33258;&#23545;&#38598;&#21512;&#39118;&#38505;&#20998;&#35299;&#30340;&#32454;&#33268;&#26816;&#26597;&#21644;&#35813;&#20998;&#35299;&#20013;&#21508;&#20010;&#25104;&#20998;&#30340;&#20004;&#31181;&#20013;&#38388;&#39118;&#38505;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generalized cross-validation (GCV) is a widely-used method for estimating the squared out-of-sample prediction risk that employs a scalar degrees of freedom adjustment (in a multiplicative sense) to the squared training error. In this paper, we examine the consistency of GCV for estimating the prediction risk of arbitrary ensembles of penalized least squares estimators. We show that GCV is inconsistent for any finite ensemble of size greater than one. Towards repairing this shortcoming, we identify a correction that involves an additional scalar correction (in an additive sense) based on degrees of freedom adjusted training errors from each ensemble component. The proposed estimator (termed CGCV) maintains the computational advantages of GCV and requires neither sample splitting, model refitting, or out-of-bag risk estimation. The estimator stems from a finer inspection of ensemble risk decomposition and two intermediate risk estimators for the components in this decomposition. We prov
&lt;/p&gt;</description></item><item><title>TACTiS-2&#26159;&#19968;&#31181;&#25913;&#36827;&#30340;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#20851;&#27880;&#32852;&#21512;&#20998;&#24067;&#27169;&#22411;&#65292;&#37319;&#29992;&#20102;&#31616;&#21270;&#30340;&#30446;&#26631;&#20989;&#25968;&#21644;&#32447;&#24615;&#21442;&#25968;&#25968;&#37327;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#35757;&#32451;&#21160;&#24577;&#21644;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.01327</link><description>&lt;p&gt;
TACTiS-2&#65306;&#26356;&#22909;&#12289;&#26356;&#24555;&#12289;&#26356;&#31616;&#21333;&#30340;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#20851;&#27880;&#32852;&#21512;&#20998;&#24067;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
TACTiS-2: Better, Faster, Simpler Attentional Copulas for Multivariate Time Series. (arXiv:2310.01327v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01327
&lt;/p&gt;
&lt;p&gt;
TACTiS-2&#26159;&#19968;&#31181;&#25913;&#36827;&#30340;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#20851;&#27880;&#32852;&#21512;&#20998;&#24067;&#27169;&#22411;&#65292;&#37319;&#29992;&#20102;&#31616;&#21270;&#30340;&#30446;&#26631;&#20989;&#25968;&#21644;&#32447;&#24615;&#21442;&#25968;&#25968;&#37327;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#35757;&#32451;&#21160;&#24577;&#21644;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;&#29992;&#20110;&#22810;&#21464;&#37327;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#65292;&#26088;&#22312;&#28789;&#27963;&#22320;&#22788;&#29702;&#21253;&#25324;&#39044;&#27979;&#12289;&#25554;&#20540;&#21644;&#23427;&#20204;&#30340;&#32452;&#21512;&#31561;&#19968;&#31995;&#21015;&#20219;&#21153;&#12290;&#22522;&#20110;&#32852;&#21512;&#20998;&#24067;&#29702;&#35770;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21270;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#29992;&#20110;&#26368;&#36817;&#24341;&#20837;&#30340;&#22522;&#20110;Transformer&#30340;&#20851;&#27880;&#32852;&#21512;&#20998;&#24067;&#27169;&#22411;&#65288;TACTiS&#65289;&#12290;&#26032;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;&#20998;&#24067;&#21442;&#25968;&#25968;&#37327;&#19982;&#21464;&#37327;&#25968;&#37327;&#21576;&#32447;&#24615;&#32780;&#38750;&#38454;&#20056;&#20851;&#31995;&#12290;&#26032;&#30340;&#30446;&#26631;&#20989;&#25968;&#38656;&#35201;&#24341;&#20837;&#19968;&#31181;&#35757;&#32451;&#35838;&#31243;&#65292;&#24182;&#19988;&#38656;&#35201;&#23545;&#21407;&#22987;&#26550;&#26500;&#36827;&#34892;&#24517;&#35201;&#30340;&#25913;&#21160;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24471;&#21040;&#30340;&#27169;&#22411;&#20855;&#26377;&#26174;&#33879;&#25913;&#21892;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#24182;&#22312;&#22810;&#26679;&#30340;&#30495;&#23454;&#19990;&#30028;&#39044;&#27979;&#20219;&#21153;&#20013;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#20808;&#21069;&#24037;&#20316;&#30340;&#28789;&#27963;&#24615;&#65292;&#22914;&#26080;&#32541;&#22788;&#29702;&#19981;&#23545;&#40784;&#21644;&#37319;&#26679;&#19981;&#22343;&#21248;&#30340;&#26102;&#38388;&#24207;&#21015;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new model for multivariate probabilistic time series prediction, designed to flexibly address a range of tasks including forecasting, interpolation, and their combinations. Building on copula theory, we propose a simplified objective for the recently-introduced transformer-based attentional copulas (TACTiS), wherein the number of distributional parameters now scales linearly with the number of variables instead of factorially. The new objective requires the introduction of a training curriculum, which goes hand-in-hand with necessary changes to the original architecture. We show that the resulting model has significantly better training dynamics and achieves state-of-the-art performance across diverse real-world forecasting tasks, while maintaining the flexibility of prior work, such as seamless handling of unaligned and unevenly-sampled time series.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#25171;&#20081;&#26631;&#31614;&#30340;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#30340;&#26368;&#20248;&#20272;&#35745;&#22120;&#12290;&#35813;&#20272;&#35745;&#22120;&#30340;&#22797;&#26434;&#24230;&#19981;&#36229;&#36807;&#32447;&#24615;&#20998;&#37197;&#31639;&#27861;&#21644;&#26368;&#23567;&#20108;&#20056;&#31639;&#27861;&#65292;&#24182;&#23545;&#20449;&#22122;&#27604;&#35201;&#27714;&#36827;&#34892;&#20102;&#32454;&#20998;&#12290;</title><link>http://arxiv.org/abs/2310.01326</link><description>&lt;p&gt;
&#20855;&#26377;&#25171;&#20081;&#26631;&#31614;&#30340;&#32447;&#24615;&#22238;&#24402;&#30340;&#26368;&#20248;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
Optimal Estimator for Linear Regression with Shuffled Labels. (arXiv:2310.01326v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01326
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#25171;&#20081;&#26631;&#31614;&#30340;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#30340;&#26368;&#20248;&#20272;&#35745;&#22120;&#12290;&#35813;&#20272;&#35745;&#22120;&#30340;&#22797;&#26434;&#24230;&#19981;&#36229;&#36807;&#32447;&#24615;&#20998;&#37197;&#31639;&#27861;&#21644;&#26368;&#23567;&#20108;&#20056;&#31639;&#27861;&#65292;&#24182;&#23545;&#20449;&#22122;&#27604;&#35201;&#27714;&#36827;&#34892;&#20102;&#32454;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#20855;&#26377;&#25171;&#20081;&#26631;&#31614;&#30340;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#65292;&#21363; $\mathbf Y = \mathbf \Pi \mathbf X \mathbf B + \mathbf W$&#65292;&#20854;&#20013; $\mathbf Y \in \mathbb R^{n\times m}, \mathbf Pi \in \mathbb R^{n\times n}, \mathbf X\in \mathbb R^{n\times p}, \mathbf B \in \mathbb R^{p\times m}$&#65292;&#21644; $\mathbf W\in \mathbb R^{n\times m}$ &#20998;&#21035;&#34920;&#31034;&#20256;&#24863;&#32467;&#26524;&#65292;&#65288;&#26410;&#30693;&#25110;&#32570;&#22833;&#30340;&#65289;&#23545;&#24212;&#20449;&#24687;&#65292;&#20256;&#24863;&#30697;&#38453;&#65292;&#24863;&#20852;&#36259;&#30340;&#20449;&#21495;&#21644;&#38468;&#21152;&#30340;&#24863;&#30693;&#22122;&#22768;&#12290;&#32473;&#23450;&#35266;&#27979;&#20540; $\mathbf Y$ &#21644;&#24863;&#30693;&#30697;&#38453; $\mathbf X$&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#19968;&#27493;&#20272;&#35745;&#22120;&#26469;&#37325;&#26500; $(\mathbf \Pi, \mathbf B)$&#12290;&#20174;&#35745;&#31639;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#25105;&#20204;&#20272;&#35745;&#22120;&#30340;&#22797;&#26434;&#24230;&#20026; $O(n^3 + np^2m)$&#65292;&#19981;&#22823;&#20110;&#32447;&#24615;&#20998;&#37197;&#31639;&#27861;&#65288;&#20363;&#22914; $O(n^3)$&#65289;&#21644;&#26368;&#23567;&#20108;&#20056;&#31639;&#27861;&#65288;&#20363;&#22914; $O(np^2 m)$&#65289;&#30340;&#26368;&#22823;&#22797;&#26434;&#24230;&#12290;&#20174;&#32479;&#35745;&#23398;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#25105;&#20204;&#23558;&#26368;&#23567;&#20449;&#22122;&#27604;&#35201;&#27714;&#20998;&#20026;&#22235;&#20010;&#21306;&#38388;&#65292;&#21363;&#26410;&#30693;&#12289;&#22256;&#38590;&#12289;&#20013;&#31561;&#21644;&#31616;&#21333;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper considers the task of linear regression with shuffled labels, i.e., $\mathbf Y = \mathbf \Pi \mathbf X \mathbf B + \mathbf W$, where $\mathbf Y \in \mathbb R^{n\times m}, \mathbf Pi \in \mathbb R^{n\times n}, \mathbf X\in \mathbb R^{n\times p}, \mathbf B \in \mathbb R^{p\times m}$, and $\mathbf W\in \mathbb R^{n\times m}$, respectively, represent the sensing results, (unknown or missing) corresponding information, sensing matrix, signal of interest, and additive sensing noise. Given the observation $\mathbf Y$ and sensing matrix $\mathbf X$, we propose a one-step estimator to reconstruct $(\mathbf \Pi, \mathbf B)$. From the computational perspective, our estimator's complexity is $O(n^3 + np^2m)$, which is no greater than the maximum complexity of a linear assignment algorithm (e.g., $O(n^3)$) and a least square algorithm (e.g., $O(np^2 m)$). From the statistical perspective, we divide the minimum $snr$ requirement into four regimes, e.g., unknown, hard, medium, and easy reg
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#20351;&#29992;Wasserstein k-means&#32858;&#31867;&#31639;&#27861;&#22312;&#19968;&#32500;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#30340;&#34892;&#20026;&#65292;&#24182;&#23558;&#20854;&#25193;&#23637;&#21040;&#22810;&#32500;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#36890;&#36807;&#20999;&#29255;Wasserstein&#36317;&#31163;&#36827;&#34892;&#22810;&#32500;&#21046;&#24230;&#26816;&#27979;&#12290;</title><link>http://arxiv.org/abs/2310.01285</link><description>&lt;p&gt;
&#20351;&#29992;&#20999;&#29255;Wasserstein k-means&#32858;&#31867;&#22312;&#22810;&#32500;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#33258;&#21160;&#26816;&#27979;&#21046;&#24230;
&lt;/p&gt;
&lt;p&gt;
Automated regime detection in multidimensional time series data using sliced Wasserstein k-means clustering. (arXiv:2310.01285v1 [q-fin.CP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01285
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#20351;&#29992;Wasserstein k-means&#32858;&#31867;&#31639;&#27861;&#22312;&#19968;&#32500;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#30340;&#34892;&#20026;&#65292;&#24182;&#23558;&#20854;&#25193;&#23637;&#21040;&#22810;&#32500;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#36890;&#36807;&#20999;&#29255;Wasserstein&#36317;&#31163;&#36827;&#34892;&#22810;&#32500;&#21046;&#24230;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;Wasserstein k-means (Wk-means)&#32858;&#31867;&#20316;&#20026;&#19968;&#31181;&#24378;&#22823;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#30340;&#21046;&#24230;&#65292;&#23588;&#20854;&#26159;&#19968;&#32500;&#36164;&#20135;&#25910;&#30410;&#12290;&#26412;&#25991;&#39318;&#20808;&#35814;&#32454;&#30740;&#31350;&#20102;&#24212;&#29992;&#20110;&#21512;&#25104;&#19968;&#32500;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;Wasserstein k-means&#32858;&#31867;&#31639;&#27861;&#30340;&#34892;&#20026;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#31639;&#27861;&#30340;&#21160;&#24577;&#24615;&#65292;&#24182;&#35843;&#26597;&#20102;&#19981;&#21516;&#36229;&#21442;&#25968;&#23545;&#19981;&#21516;&#38543;&#26426;&#21021;&#22987;&#21270;&#19979;&#32858;&#31867;&#31639;&#27861;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#35745;&#31639;&#20102;&#19968;&#20123;&#31616;&#21333;&#30340;&#25351;&#26631;&#65292;&#21457;&#29616;&#23427;&#20204;&#23545;&#20110;&#35782;&#21035;&#39640;&#36136;&#37327;&#30340;&#32858;&#31867;&#26159;&#26377;&#29992;&#30340;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#23558;&#22810;&#32500;Wasserstein&#36317;&#31163;&#36817;&#20284;&#20026;&#20999;&#29255;Wasserstein&#36317;&#31163;&#65292;&#23558;Wasserstein k-means&#32858;&#31867;&#25216;&#26415;&#25193;&#23637;&#21040;&#22810;&#32500;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#24471;&#21040;&#19968;&#31181;&#25105;&#20204;&#31216;&#20043;&#20026;`sliced Wasserstein k-means (sWk-means)&#32858;&#31867;'&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#23558;sWk-means&#32858;&#31867;&#26041;&#27861;&#24212;&#29992;&#20110;&#22810;&#32500;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#33258;&#21160;&#21046;&#24230;&#26816;&#27979;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work has proposed Wasserstein k-means (Wk-means) clustering as a powerful method to identify regimes in time series data, and one-dimensional asset returns in particular. In this paper, we begin by studying in detail the behaviour of the Wasserstein k-means clustering algorithm applied to synthetic one-dimensional time series data. We study the dynamics of the algorithm and investigate how varying different hyperparameters impacts the performance of the clustering algorithm for different random initialisations. We compute simple metrics that we find are useful in identifying high-quality clusterings. Then, we extend the technique of Wasserstein k-means clustering to multidimensional time series data by approximating the multidimensional Wasserstein distance as a sliced Wasserstein distance, resulting in a method we call `sliced Wasserstein k-means (sWk-means) clustering'. We apply the sWk-means clustering method to the problem of automated regime detection in multidimensional ti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#20132;&#25442;&#24335;&#20849;&#24418;&#39118;&#38505;&#25511;&#21046;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#25968;&#25454;&#19981;&#21487;&#20132;&#25442;&#30340;&#24773;&#20917;&#19979;&#25511;&#21046;&#20219;&#20309;&#21333;&#35843;&#25439;&#22833;&#20989;&#25968;&#30340;&#26399;&#26395;&#20540;&#12290;</title><link>http://arxiv.org/abs/2310.01262</link><description>&lt;p&gt;
&#38750;&#20132;&#25442;&#24335;&#20849;&#24418;&#39118;&#38505;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Non-Exchangeable Conformal Risk Control. (arXiv:2310.01262v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01262
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#20132;&#25442;&#24335;&#20849;&#24418;&#39118;&#38505;&#25511;&#21046;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#25968;&#25454;&#19981;&#21487;&#20132;&#25442;&#30340;&#24773;&#20917;&#19979;&#25511;&#21046;&#20219;&#20309;&#21333;&#35843;&#25439;&#22833;&#20989;&#25968;&#30340;&#26399;&#26395;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#30001;&#20110;&#20854;&#33021;&#22815;&#20026;&#40657;&#21283;&#23376;&#31070;&#32463;&#27169;&#22411;&#30340;&#39044;&#27979;&#25552;&#20379;&#24418;&#24335;&#19978;&#20445;&#35777;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#25110;&#21306;&#38388;&#65292;&#30830;&#20445;&#21253;&#21547;&#23454;&#38469;&#30495;&#23454;&#20540;&#30340;&#39044;&#23450;&#20041;&#27010;&#29575;&#65292;&#25286;&#20998;&#20849;&#24418;&#39044;&#27979;&#24341;&#21457;&#20102;&#26497;&#22823;&#30340;&#20852;&#36259;&#12290;&#34429;&#28982;&#26368;&#21021;&#30340;&#20844;&#24335;&#20551;&#35774;&#25968;&#25454;&#21487;&#20132;&#25442;&#65292;&#20294;&#19968;&#20123;&#25193;&#23637;&#22788;&#29702;&#19981;&#21487;&#20132;&#25442;&#30340;&#25968;&#25454;&#65292;&#22312;&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#30340;&#22330;&#26223;&#20013;&#32463;&#24120;&#21457;&#29983;&#12290;&#21516;&#26102;&#65292;&#19968;&#20123;&#36827;&#23637;&#24050;&#32463;&#22312;&#20849;&#24418;&#26041;&#27861;&#20013;&#21462;&#24471;&#65292;&#36825;&#20123;&#26041;&#27861;&#23545;&#26356;&#24191;&#27867;&#30340;&#30446;&#26631;&#25552;&#20379;&#32479;&#35745;&#20445;&#35777;&#65292;&#20363;&#22914;&#38480;&#21046;&#26368;&#20339;F1&#20998;&#25968;&#25110;&#20197;&#26399;&#26395;&#26368;&#23567;&#21270;&#35823;&#25253;&#29575;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#21644;&#25193;&#23637;&#36825;&#20004;&#20010;&#24037;&#20316;&#32447;&#36335;&#65292;&#25552;&#20986;&#20102;&#38750;&#20132;&#25442;&#24335;&#20849;&#24418;&#39118;&#38505;&#25511;&#21046;&#65292;&#21487;&#20197;&#22312;&#25968;&#25454;&#19981;&#21487;&#20132;&#25442;&#30340;&#24773;&#20917;&#19979;&#25511;&#21046;&#20219;&#20309;&#21333;&#35843;&#25439;&#22833;&#20989;&#25968;&#30340;&#26399;&#26395;&#20540;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#28789;&#27963;&#65292;&#20551;&#35774;&#24456;&#23569;&#65292;&#24182;&#20801;&#35768;&#26681;&#25454;&#25968;&#25454;&#30340;&#32479;&#35745;&#30456;&#20284;&#24615;&#36827;&#34892;&#21152;&#26435;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Split conformal prediction has recently sparked great interest due to its ability to provide formally guaranteed uncertainty sets or intervals for predictions made by black-box neural models, ensuring a predefined probability of containing the actual ground truth. While the original formulation assumes data exchangeability, some extensions handle non-exchangeable data, which is often the case in many real-world scenarios. In parallel, some progress has been made in conformal methods that provide statistical guarantees for a broader range of objectives, such as bounding the best F1-score or minimizing the false negative rate in expectation. In this paper, we leverage and extend these two lines of work by proposing non-exchangeable conformal risk control, which allows controlling the expected value of any monotone loss function when the data is not exchangeable. Our framework is flexible, makes very few assumptions, and allows weighting the data based on its statistical similarity with t
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38236;&#20687;&#25193;&#25955;&#27169;&#22411;&#65288;MDM&#65289;&#65292;&#21487;&#20197;&#22312;&#21463;&#38480;&#21046;&#38598;&#21512;&#19978;&#29983;&#25104;&#25968;&#25454;&#32780;&#19981;&#20007;&#22833;&#21487;&#36861;&#28335;&#24615;&#12290;&#36825;&#36890;&#36807;&#22312;&#19968;&#20010;&#26631;&#20934;&#30340;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#23398;&#20064;&#25193;&#25955;&#36807;&#31243;&#65292;&#24182;&#21033;&#29992;&#38236;&#20687;&#26144;&#23556;&#26469;&#23454;&#29616;&#12290;</title><link>http://arxiv.org/abs/2310.01236</link><description>&lt;p&gt;
&#21463;&#38480;&#21046;&#21644;&#24102;&#27700;&#21360;&#29983;&#25104;&#30340;&#38236;&#20687;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Mirror Diffusion Models for Constrained and Watermarked Generation. (arXiv:2310.01236v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01236
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38236;&#20687;&#25193;&#25955;&#27169;&#22411;&#65288;MDM&#65289;&#65292;&#21487;&#20197;&#22312;&#21463;&#38480;&#21046;&#38598;&#21512;&#19978;&#29983;&#25104;&#25968;&#25454;&#32780;&#19981;&#20007;&#22833;&#21487;&#36861;&#28335;&#24615;&#12290;&#36825;&#36890;&#36807;&#22312;&#19968;&#20010;&#26631;&#20934;&#30340;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#23398;&#20064;&#25193;&#25955;&#36807;&#31243;&#65292;&#24182;&#21033;&#29992;&#38236;&#20687;&#26144;&#23556;&#26469;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#25193;&#25955;&#27169;&#22411;&#22312;&#23398;&#20064;&#22797;&#26434;&#30340;&#39640;&#32500;&#25968;&#25454;&#20998;&#24067;&#26041;&#38754;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#36825;&#37096;&#20998;&#24402;&#21151;&#20110;&#20854;&#33021;&#22815;&#26500;&#24314;&#20855;&#26377;&#35299;&#26512;&#36716;&#31227;&#26680;&#20989;&#25968;&#21644;&#35780;&#20998;&#20989;&#25968;&#30340;&#25193;&#25955;&#36807;&#31243;&#12290;&#36825;&#31181;&#21487;&#36861;&#28335;&#24615;&#32467;&#26524;&#22312;&#19981;&#38656;&#35201;&#27169;&#25311;&#30340;&#26694;&#26550;&#20013;&#20855;&#26377;&#31283;&#23450;&#30340;&#22238;&#24402;&#25439;&#22833;&#65292;&#20174;&#32780;&#21487;&#20197;&#23398;&#20064;&#21040;&#21487;&#20197;&#25193;&#23637;&#30340;&#36870;&#21521;&#29983;&#25104;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#24403;&#25968;&#25454;&#34987;&#38480;&#21046;&#22312;&#21463;&#38480;&#21046;&#38598;&#21512;&#32780;&#19981;&#26159;&#26631;&#20934;&#30340;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#26102;&#65292;&#26681;&#25454;&#20043;&#21069;&#30340;&#23581;&#35797;&#65292;&#36825;&#20123;&#29702;&#24819;&#30340;&#29305;&#24615;&#20284;&#20046;&#20007;&#22833;&#20102;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#38236;&#20687;&#25193;&#25955;&#27169;&#22411;&#65288;MDM&#65289;&#65292;&#19968;&#31181;&#26032;&#30340;&#25193;&#25955;&#27169;&#22411;&#31867;&#65292;&#21487;&#20197;&#22312;&#20984;&#32422;&#26463;&#38598;&#21512;&#19978;&#29983;&#25104;&#25968;&#25454;&#32780;&#19981;&#20007;&#22833;&#20219;&#20309;&#21487;&#36861;&#28335;&#24615;&#12290;&#36825;&#26159;&#36890;&#36807;&#22312;&#20174;&#38236;&#20687;&#26144;&#23556;&#26500;&#24314;&#30340;&#23545;&#20598;&#31354;&#38388;&#20013;&#23398;&#20064;&#25193;&#25955;&#36807;&#31243;&#26469;&#23454;&#29616;&#30340;&#65292;&#20851;&#38190;&#30340;&#26159;&#65292;&#36825;&#26159;&#19968;&#20010;&#26631;&#20934;&#30340;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#27969;&#34892;&#30340;&#32422;&#26463;&#38598;&#21512;&#65288;&#22914;&#21333;&#32431;&#24418;&#21644;$\ell_2$-&#29699;&#65289;&#30340;&#38236;&#20687;&#26144;&#23556;&#30340;&#26377;&#25928;&#35745;&#31639;&#65292;&#26174;&#31034;&#26126;&#26174;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern successes of diffusion models in learning complex, high-dimensional data distributions are attributed, in part, to their capability to construct diffusion processes with analytic transition kernels and score functions. The tractability results in a simulation-free framework with stable regression losses, from which reversed, generative processes can be learned at scale. However, when data is confined to a constrained set as opposed to a standard Euclidean space, these desirable characteristics appear to be lost based on prior attempts. In this work, we propose Mirror Diffusion Models (MDM), a new class of diffusion models that generate data on convex constrained sets without losing any tractability. This is achieved by learning diffusion processes in a dual space constructed from a mirror map, which, crucially, is a standard Euclidean space. We derive efficient computation of mirror maps for popular constrained sets, such as simplices and $\ell_2$-balls, showing significantly im
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#36866;&#29992;&#20110;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#30340;&#36335;&#24452;&#33539;&#25968;&#24037;&#20855;&#21253;&#65292;&#21487;&#20197;&#21253;&#25324;&#20855;&#26377;&#20559;&#24046;&#12289;&#36339;&#36291;&#36830;&#25509;&#21644;&#26368;&#22823;&#27744;&#21270;&#30340;&#36890;&#29992;DAG ReLU&#32593;&#32476;&#12290;&#36825;&#20010;&#24037;&#20855;&#21253;&#24674;&#22797;&#25110;&#36229;&#36234;&#20102;&#24050;&#30693;&#30340;&#36335;&#24452;&#33539;&#25968;&#30028;&#38480;&#65292;&#24182;&#25361;&#25112;&#20102;&#22522;&#20110;&#36335;&#24452;&#33539;&#25968;&#30340;&#19968;&#20123;&#20855;&#20307;&#25215;&#35834;&#12290;</title><link>http://arxiv.org/abs/2310.01225</link><description>&lt;p&gt;
&#19968;&#31181;&#36866;&#29992;&#20110;&#29616;&#20195;&#32593;&#32476;&#30340;&#36335;&#24452;&#33539;&#25968;&#24037;&#20855;&#21253;&#65306;&#24433;&#21709;&#12289;&#21069;&#26223;&#21644;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
A path-norm toolkit for modern networks: consequences, promises and challenges. (arXiv:2310.01225v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01225
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#36866;&#29992;&#20110;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#30340;&#36335;&#24452;&#33539;&#25968;&#24037;&#20855;&#21253;&#65292;&#21487;&#20197;&#21253;&#25324;&#20855;&#26377;&#20559;&#24046;&#12289;&#36339;&#36291;&#36830;&#25509;&#21644;&#26368;&#22823;&#27744;&#21270;&#30340;&#36890;&#29992;DAG ReLU&#32593;&#32476;&#12290;&#36825;&#20010;&#24037;&#20855;&#21253;&#24674;&#22797;&#25110;&#36229;&#36234;&#20102;&#24050;&#30693;&#30340;&#36335;&#24452;&#33539;&#25968;&#30028;&#38480;&#65292;&#24182;&#25361;&#25112;&#20102;&#22522;&#20110;&#36335;&#24452;&#33539;&#25968;&#30340;&#19968;&#20123;&#20855;&#20307;&#25215;&#35834;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#31532;&#19968;&#20010;&#23436;&#20840;&#33021;&#22815;&#21253;&#25324;&#20855;&#26377;&#20559;&#24046;&#12289;&#36339;&#36291;&#36830;&#25509;&#21644;&#26368;&#22823;&#27744;&#21270;&#30340;&#36890;&#29992;DAG ReLU&#32593;&#32476;&#30340;&#36335;&#24452;&#33539;&#25968;&#24037;&#20855;&#21253;&#12290;&#36825;&#20010;&#24037;&#20855;&#21253;&#19981;&#20165;&#36866;&#29992;&#20110;&#26368;&#24191;&#27867;&#30340;&#22522;&#20110;&#36335;&#24452;&#33539;&#25968;&#30340;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#65292;&#36824;&#21487;&#20197;&#24674;&#22797;&#25110;&#36229;&#36234;&#24050;&#30693;&#30340;&#27492;&#31867;&#33539;&#25968;&#30340;&#26368;&#23574;&#38160;&#30028;&#38480;&#12290;&#36825;&#20123;&#25193;&#23637;&#30340;&#36335;&#24452;&#33539;&#25968;&#36824;&#20139;&#26377;&#36335;&#24452;&#33539;&#25968;&#30340;&#24120;&#35268;&#20248;&#28857;&#65306;&#35745;&#31639;&#31616;&#20415;&#12289;&#23545;&#32593;&#32476;&#30340;&#23545;&#31216;&#24615;&#20855;&#26377;&#19981;&#21464;&#24615;&#65292;&#22312;&#21069;&#39304;&#32593;&#32476;&#19978;&#27604;&#25805;&#20316;&#31526;&#33539;&#25968;&#30340;&#20056;&#31215;&#65288;&#21478;&#19968;&#31181;&#24120;&#29992;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65289;&#20855;&#26377;&#26356;&#22909;&#30340;&#38160;&#24230;&#12290;&#24037;&#20855;&#21253;&#30340;&#22810;&#21151;&#33021;&#24615;&#21644;&#26131;&#20110;&#23454;&#26045;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#25968;&#20540;&#35780;&#20272;&#22312;ImageNet&#19978;&#23545;ResNet&#30340;&#26368;&#23574;&#38160;&#30028;&#38480;&#26469;&#25361;&#25112;&#22522;&#20110;&#36335;&#24452;&#33539;&#25968;&#30340;&#20855;&#20307;&#25215;&#35834;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work introduces the first toolkit around path-norms that is fully able to encompass general DAG ReLU networks with biases, skip connections and max pooling. This toolkit notably allows us to establish generalization bounds for real modern neural networks that are not only the most widely applicable path-norm based ones, but also recover or beat the sharpest known bounds of this type. These extended path-norms further enjoy the usual benefits of path-norms: ease of computation, invariance under the symmetries of the network, and improved sharpness on feedforward networks compared to the product of operators' norms, another complexity measure most commonly used.  The versatility of the toolkit and its ease of implementation allow us to challenge the concrete promises of path-norm-based generalization bounds, by numerically evaluating the sharpest known bounds for ResNets on ImageNet.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;&#19981;&#30830;&#23450;&#24615;&#26657;&#20934;&#65288;U2C&#65289;&#26694;&#26550;&#65292;&#29992;&#20110;&#21512;&#24182;&#21487;&#30693;&#21644;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#65292;&#23454;&#29616;&#20102;&#38754;&#23545;&#22256;&#38590;&#26679;&#20363;&#26102;&#30340;&#20934;&#30830;&#39044;&#27979;&#21644;&#26657;&#20934;&#12290;</title><link>http://arxiv.org/abs/2310.01202</link><description>&lt;p&gt;
&#32479;&#19968;&#30340;&#19981;&#30830;&#23450;&#24615;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Unified Uncertainty Calibration. (arXiv:2310.01202v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01202
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;&#19981;&#30830;&#23450;&#24615;&#26657;&#20934;&#65288;U2C&#65289;&#26694;&#26550;&#65292;&#29992;&#20110;&#21512;&#24182;&#21487;&#30693;&#21644;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#65292;&#23454;&#29616;&#20102;&#38754;&#23545;&#22256;&#38590;&#26679;&#20363;&#26102;&#30340;&#20934;&#30830;&#39044;&#27979;&#21644;&#26657;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#26500;&#24314;&#20581;&#22766;&#65292;&#20844;&#24179;&#21644;&#23433;&#20840;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#65292;&#25105;&#20204;&#24076;&#26395;&#22312;&#38754;&#23545;&#22256;&#38590;&#25110;&#36229;&#20986;&#35757;&#32451;&#31867;&#21035;&#30340;&#27979;&#35797;&#26679;&#20363;&#26102;&#65292;&#20998;&#31867;&#22120;&#33021;&#22815;&#35828;&#8220;&#25105;&#19981;&#30693;&#36947;&#8221;&#12290;&#26222;&#36941;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#31574;&#30053;&#26159;&#31616;&#21333;&#30340;&#8220;&#25298;&#32477;&#25110;&#20998;&#31867;&#8221;&#35268;&#21017;&#65306;&#22914;&#26524;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#39640;&#65292;&#21017;&#25918;&#24323;&#39044;&#27979;&#65292;&#21542;&#21017;&#36827;&#34892;&#20998;&#31867;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#19981;&#20801;&#35768;&#19981;&#21516;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#30456;&#20114;&#36890;&#20449;&#65292;&#20250;&#20135;&#29983;&#26410;&#26657;&#20934;&#30340;&#39044;&#27979;&#65292;&#24182;&#19988;&#19981;&#33021;&#32416;&#27491;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#20013;&#30340;&#38169;&#35823;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19977;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#32479;&#19968;&#30340;&#19981;&#30830;&#23450;&#24615;&#26657;&#20934;&#65288;U2C&#65289;&#30340;&#25972;&#20307;&#26694;&#26550;&#65292;&#29992;&#20110;&#21512;&#24182;&#21487;&#30693;&#21644;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#12290;U2C&#33021;&#22815;&#36827;&#34892;&#28165;&#26224;&#30340;&#23398;&#20064;&#29702;&#35770;&#20998;&#26512;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#24182;&#19988;&#22312;&#21508;&#31181;ImageNet&#22522;&#20934;&#27979;&#35797;&#20013;&#20248;&#20110;&#25298;&#32477;&#25110;&#20998;&#31867;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
To build robust, fair, and safe AI systems, we would like our classifiers to say ``I don't know'' when facing test examples that are difficult or fall outside of the training classes.The ubiquitous strategy to predict under uncertainty is the simplistic \emph{reject-or-classify} rule: abstain from prediction if epistemic uncertainty is high, classify otherwise.Unfortunately, this recipe does not allow different sources of uncertainty to communicate with each other, produces miscalibrated predictions, and it does not allow to correct for misspecifications in our uncertainty estimates. To address these three issues, we introduce \emph{unified uncertainty calibration (U2C)}, a holistic framework to combine aleatoric and epistemic uncertainties. U2C enables a clean learning-theoretical analysis of uncertainty estimation, and outperforms reject-or-classify across a variety of ImageNet benchmarks.
&lt;/p&gt;</description></item><item><title>SWoTTeD&#26159;&#19968;&#31181;&#25193;&#23637;&#30340;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;&#65292;&#29992;&#20110;&#21457;&#29616;&#22797;&#26434;&#26102;&#38388;&#27169;&#24335;&#19979;&#30340;&#38544;&#34255;&#34920;&#24449;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;SWoTTeD&#19981;&#20165;&#33021;&#19982;&#26368;&#26032;&#30340;&#22522;&#20110;&#24352;&#37327;&#20998;&#35299;&#30340;&#26041;&#27861;&#19968;&#26679;&#20934;&#30830;&#22320;&#37325;&#24314;&#25968;&#25454;&#65292;&#36824;&#33021;&#25552;&#21462;&#20986;&#23545;&#20020;&#24202;&#21307;&#29983;&#26377;&#24847;&#20041;&#30340;&#26102;&#38388;&#34920;&#24449;&#12290;</title><link>http://arxiv.org/abs/2310.01201</link><description>&lt;p&gt;
SWoTTeD:&#24352;&#37327;&#20998;&#35299;&#22312;&#26102;&#38388;&#34920;&#24449;&#20013;&#30340;&#25193;&#23637;
&lt;/p&gt;
&lt;p&gt;
SWoTTeD: An Extension of Tensor Decomposition to Temporal Phenotyping. (arXiv:2310.01201v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01201
&lt;/p&gt;
&lt;p&gt;
SWoTTeD&#26159;&#19968;&#31181;&#25193;&#23637;&#30340;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;&#65292;&#29992;&#20110;&#21457;&#29616;&#22797;&#26434;&#26102;&#38388;&#27169;&#24335;&#19979;&#30340;&#38544;&#34255;&#34920;&#24449;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;SWoTTeD&#19981;&#20165;&#33021;&#19982;&#26368;&#26032;&#30340;&#22522;&#20110;&#24352;&#37327;&#20998;&#35299;&#30340;&#26041;&#27861;&#19968;&#26679;&#20934;&#30830;&#22320;&#37325;&#24314;&#25968;&#25454;&#65292;&#36824;&#33021;&#25552;&#21462;&#20986;&#23545;&#20020;&#24202;&#21307;&#29983;&#26377;&#24847;&#20041;&#30340;&#26102;&#38388;&#34920;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24352;&#37327;&#20998;&#35299;&#26368;&#36817;&#22312;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#23545;&#20110;&#20010;&#20307;&#36861;&#36394;&#25968;&#25454;&#30340;&#20998;&#26512;&#65292;&#22914;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;(EHR)&#65292;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#24403;&#25968;&#25454;&#36981;&#24490;&#22797;&#26434;&#30340;&#26102;&#38388;&#27169;&#24335;&#26102;&#65292;&#36825;&#20010;&#20219;&#21153;&#21464;&#24471;&#26356;&#21152;&#22256;&#38590;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#26102;&#38388;&#34920;&#24449;&#30340;&#27010;&#24565;&#65292;&#21363;&#19968;&#32452;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#29305;&#24449;&#65292;&#24182;&#25552;&#20986;&#20102;SWoTTeD (Sliding Window for Temporal Tensor Decomposition)&#26041;&#27861;&#65292;&#19968;&#31181;&#21457;&#29616;&#38544;&#34255;&#26102;&#38388;&#27169;&#24335;&#30340;&#26032;&#26041;&#27861;&#12290;SWoTTeD&#38598;&#25104;&#20102;&#22810;&#31181;&#32422;&#26463;&#21644;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#20197;&#22686;&#24378;&#25552;&#21462;&#21040;&#30340;&#34920;&#24449;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#36827;&#34892;&#39564;&#35777;&#65292;&#24182;&#25552;&#20379;&#20102;&#20351;&#29992;&#24052;&#40654;&#22823;&#23398;&#21307;&#38498;&#30340;&#25968;&#25454;&#30340;&#21407;&#22987;&#29992;&#20363;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;SWoTTeD&#33021;&#22815;&#33267;&#23569;&#19982;&#26368;&#26032;&#30340;&#22522;&#20110;&#24352;&#37327;&#20998;&#35299;&#30340;&#27169;&#22411;&#19968;&#26679;&#20934;&#30830;&#22320;&#37325;&#24314;&#25968;&#25454;&#65292;&#24182;&#25552;&#21462;&#21040;&#23545;&#20020;&#24202;&#21307;&#29983;&#26377;&#24847;&#20041;&#30340;&#26102;&#38388;&#34920;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tensor decomposition has recently been gaining attention in the machine learning community for the analysis of individual traces, such as Electronic Health Records (EHR). However, this task becomes significantly more difficult when the data follows complex temporal patterns. This paper introduces the notion of a temporal phenotype as an arrangement of features over time and it proposes SWoTTeD (Sliding Window for Temporal Tensor Decomposition), a novel method to discover hidden temporal patterns. SWoTTeD integrates several constraints and regularizations to enhance the interpretability of the extracted phenotypes. We validate our proposal using both synthetic and real-world datasets, and we present an original usecase using data from the Greater Paris University Hospital. The results show that SWoTTeD achieves at least as accurate reconstruction as recent state-of-the-art tensor decomposition models, and extracts temporal phenotypes that are meaningful for clinicians.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#65292;&#24403;&#36125;&#21494;&#26031;&#21518;&#39564;&#27424;&#25311;&#21512;&#26102;&#65292;&#27169;&#22411;&#22833;&#37197;&#20250;&#23548;&#33268;&#20919;&#21518;&#39564;&#25928;&#24212;(CPE)&#22312;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#20013;&#20986;&#29616;&#12290;</title><link>http://arxiv.org/abs/2310.01189</link><description>&lt;p&gt;
&#22914;&#26524;&#27809;&#26377;&#27424;&#25311;&#21512;&#65292;&#23601;&#27809;&#26377;&#20919;&#21518;&#39564;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
If there is no underfitting, there is no Cold Posterior Effect. (arXiv:2310.01189v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01189
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#65292;&#24403;&#36125;&#21494;&#26031;&#21518;&#39564;&#27424;&#25311;&#21512;&#26102;&#65292;&#27169;&#22411;&#22833;&#37197;&#20250;&#23548;&#33268;&#20919;&#21518;&#39564;&#25928;&#24212;(CPE)&#22312;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#20013;&#20986;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#20919;&#21518;&#39564;&#25928;&#24212;(CPE)&#34920;&#26126;&#65292;&#23545;&#20110;&#28201;&#24230;$T&lt;1$&#30340;&#21518;&#39564;&#65292;&#24471;&#21040;&#30340;&#21518;&#39564;&#39044;&#27979;&#24615;&#33021;&#21487;&#33021;&#20248;&#20110;&#36125;&#21494;&#26031;&#21518;&#39564;($T=1$)&#12290;&#30001;&#20110;&#36125;&#21494;&#26031;&#21518;&#39564;&#22312;&#23436;&#32654;&#27169;&#22411;&#35268;&#33539;&#19979;&#34987;&#35748;&#20026;&#26159;&#26368;&#20248;&#30340;&#65292;&#35768;&#22810;&#26368;&#36817;&#30340;&#30740;&#31350;&#23558;CPE&#30340;&#23384;&#22312;&#35270;&#20026;&#27169;&#22411;&#35268;&#33539;&#38169;&#35823;&#30340;&#38382;&#39064;&#65292;&#26469;&#33258;&#20808;&#39564;&#25110;&#20284;&#28982;&#20989;&#25968;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;CPE&#26356;&#32454;&#33268;&#30340;&#29702;&#35299;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#24471;&#21040;&#30340;&#36125;&#21494;&#26031;&#21518;&#39564;&#27424;&#25311;&#21512;&#26102;&#65292;&#27169;&#22411;&#22833;&#37197;&#25165;&#20250;&#23548;&#33268;CPE&#12290;&#20107;&#23454;&#19978;&#65292;&#25105;&#20204;&#29702;&#35770;&#19978;&#35777;&#26126;&#27809;&#26377;&#27424;&#25311;&#21512;&#21017;&#27809;&#26377;CPE&#12290;
&lt;/p&gt;
&lt;p&gt;
The cold posterior effect (CPE) (Wenzel et al., 2020) in Bayesian deep learning shows that, for posteriors with a temperature $T&lt;1$, the resulting posterior predictive could have better performances than the Bayesian posterior ($T=1$). As the Bayesian posterior is known to be optimal under perfect model specification, many recent works have studied the presence of CPE as a model misspecification problem, arising from the prior and/or from the likelihood function. In this work, we provide a more nuanced understanding of the CPE as we show that misspecification leads to CPE only when the resulting Bayesian posterior underfits. In fact, we theoretically show that if there is no underfitting, there is no CPE.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24182;&#34892;&#26102;&#38388;&#27010;&#29575;&#25968;&#20540;ODE&#27714;&#35299;&#22120;&#65292;&#36890;&#36807;&#23558;&#25968;&#20540;&#27169;&#25311;&#38382;&#39064;&#35270;&#20026;&#36125;&#21494;&#26031;&#29366;&#24577;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#36125;&#21494;&#26031;&#28388;&#27874;&#21644;&#24179;&#28369;&#30340;&#26694;&#26550;&#65292;&#23454;&#29616;&#20102;&#22312;&#24182;&#34892;&#22788;&#29702;&#25152;&#26377;&#26102;&#38388;&#27493;&#39588;&#30340;&#21516;&#26102;&#23558;&#26102;&#38388;&#24320;&#38144;&#38477;&#20302;&#21040;&#23545;&#25968;&#32423;&#21035;&#12290;</title><link>http://arxiv.org/abs/2310.01145</link><description>&lt;p&gt;
&#24182;&#34892;&#26102;&#38388;&#27010;&#29575;&#25968;&#20540;ODE&#27714;&#35299;&#22120;
&lt;/p&gt;
&lt;p&gt;
Parallel-in-Time Probabilistic Numerical ODE Solvers. (arXiv:2310.01145v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01145
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24182;&#34892;&#26102;&#38388;&#27010;&#29575;&#25968;&#20540;ODE&#27714;&#35299;&#22120;&#65292;&#36890;&#36807;&#23558;&#25968;&#20540;&#27169;&#25311;&#38382;&#39064;&#35270;&#20026;&#36125;&#21494;&#26031;&#29366;&#24577;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#36125;&#21494;&#26031;&#28388;&#27874;&#21644;&#24179;&#28369;&#30340;&#26694;&#26550;&#65292;&#23454;&#29616;&#20102;&#22312;&#24182;&#34892;&#22788;&#29702;&#25152;&#26377;&#26102;&#38388;&#27493;&#39588;&#30340;&#21516;&#26102;&#23558;&#26102;&#38388;&#24320;&#38144;&#38477;&#20302;&#21040;&#23545;&#25968;&#32423;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#24120;&#24494;&#20998;&#26041;&#31243;(ODE)&#30340;&#27010;&#29575;&#25968;&#20540;&#27714;&#35299;&#22120;&#23558;&#21160;&#21147;&#31995;&#32479;&#30340;&#25968;&#20540;&#20223;&#30495;&#38382;&#39064;&#35270;&#20026;&#36125;&#21494;&#26031;&#29366;&#24577;&#20272;&#35745;&#38382;&#39064;&#12290;&#38500;&#20102;&#29983;&#25104;ODE&#35299;&#30340;&#21518;&#39564;&#20998;&#24067;&#24182;&#22240;&#27492;&#37327;&#21270;&#26041;&#27861;&#26412;&#36523;&#30340;&#25968;&#20540;&#36924;&#36817;&#35823;&#24046;&#20043;&#22806;&#65292;&#36825;&#31181;&#24418;&#24335;&#21270;&#26041;&#27861;&#30340;&#19968;&#20010;&#19981;&#24120;&#34987;&#27880;&#24847;&#21040;&#30340;&#20248;&#21183;&#26159;&#36890;&#36807;&#22312;&#36125;&#21494;&#26031;&#28388;&#27874;&#21644;&#24179;&#28369;&#30340;&#26694;&#26550;&#20013;&#36827;&#34892;&#25968;&#20540;&#27169;&#25311;&#32780;&#33719;&#24471;&#30340;&#31639;&#27861;&#28789;&#27963;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#31181;&#28789;&#27963;&#24615;&#65292;&#22522;&#20110;&#26102;&#38388;&#24182;&#34892;&#36845;&#20195;&#25193;&#23637;&#21345;&#23572;&#26364;&#24179;&#28369;&#22120;&#30340;&#20844;&#24335;&#21270;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#24182;&#34892;&#26102;&#38388;&#27010;&#29575;&#25968;&#20540;ODE&#27714;&#35299;&#22120;&#12290;&#19982;&#24403;&#21069;&#30340;&#27010;&#29575;&#27714;&#35299;&#22120;&#20381;&#27425;&#25353;&#26102;&#38388;&#39034;&#24207;&#27169;&#25311;&#21160;&#21147;&#31995;&#32479;&#19981;&#21516;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20197;&#24182;&#34892;&#26041;&#24335;&#22788;&#29702;&#25152;&#26377;&#26102;&#38388;&#27493;&#39588;&#65292;&#20174;&#32780;&#23558;&#26102;&#38388;&#24320;&#38144;&#20174;&#32447;&#24615;&#38477;&#20302;&#21040;&#23545;&#25968;&#32423;&#21035;&#30340;&#26102;&#38388;&#27493;&#39588;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#22810;&#31181;&#38382;&#39064;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Probabilistic numerical solvers for ordinary differential equations (ODEs) treat the numerical simulation of dynamical systems as problems of Bayesian state estimation. Aside from producing posterior distributions over ODE solutions and thereby quantifying the numerical approximation error of the method itself, one less-often noted advantage of this formalism is the algorithmic flexibility gained by formulating numerical simulation in the framework of Bayesian filtering and smoothing. In this paper, we leverage this flexibility and build on the time-parallel formulation of iterated extended Kalman smoothers to formulate a parallel-in-time probabilistic numerical ODE solver. Instead of simulating the dynamical system sequentially in time, as done by current probabilistic solvers, the proposed method processes all time steps in parallel and thereby reduces the span cost from linear to logarithmic in the number of time steps. We demonstrate the effectiveness of our approach on a variety o
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25991;&#26412;&#21040;&#22270;&#20687;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#36890;&#29992;&#20808;&#39564;&#35299;&#20915;&#25104;&#20687;&#36870;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;Prompt-tuning&#23558;&#25991;&#26412;&#23884;&#20837;&#36827;&#34892;&#23454;&#26102;&#20248;&#21270;&#65292;&#21516;&#26102;&#36890;&#36807;&#25237;&#24433;&#20445;&#25345;&#28508;&#22312;&#21464;&#37327;&#30340;&#28436;&#21270;&#22312;&#32534;&#30721;&#22120;&#30340;&#33539;&#22260;&#31354;&#38388;&#20869;&#65292;&#20351;&#29983;&#25104;&#22270;&#20687;&#26356;&#31526;&#21512;&#25193;&#25955;&#20808;&#39564;&#12290;&#36825;&#31181;&#32508;&#21512;&#26041;&#27861;&#65292;&#22312;&#36229;&#20998;&#36776;&#29575;&#12289;&#21435;&#27169;&#31946;&#21644;&#20462;&#22797;&#31561;&#21508;&#31181;&#20219;&#21153;&#20013;&#65292;&#20248;&#20110;&#22522;&#20110;&#22270;&#20687;&#21644;&#22522;&#20110;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#30340;&#36870;&#38382;&#39064;&#27714;&#35299;&#22120;&#12290;</title><link>http://arxiv.org/abs/2310.01110</link><description>&lt;p&gt;
&#29992;&#20110;&#36870;&#38382;&#39064;&#30340;Prompt-tuning&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Prompt-tuning latent diffusion models for inverse problems. (arXiv:2310.01110v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01110
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25991;&#26412;&#21040;&#22270;&#20687;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#36890;&#29992;&#20808;&#39564;&#35299;&#20915;&#25104;&#20687;&#36870;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;Prompt-tuning&#23558;&#25991;&#26412;&#23884;&#20837;&#36827;&#34892;&#23454;&#26102;&#20248;&#21270;&#65292;&#21516;&#26102;&#36890;&#36807;&#25237;&#24433;&#20445;&#25345;&#28508;&#22312;&#21464;&#37327;&#30340;&#28436;&#21270;&#22312;&#32534;&#30721;&#22120;&#30340;&#33539;&#22260;&#31354;&#38388;&#20869;&#65292;&#20351;&#29983;&#25104;&#22270;&#20687;&#26356;&#31526;&#21512;&#25193;&#25955;&#20808;&#39564;&#12290;&#36825;&#31181;&#32508;&#21512;&#26041;&#27861;&#65292;&#22312;&#36229;&#20998;&#36776;&#29575;&#12289;&#21435;&#27169;&#31946;&#21644;&#20462;&#22797;&#31561;&#21508;&#31181;&#20219;&#21153;&#20013;&#65292;&#20248;&#20110;&#22522;&#20110;&#22270;&#20687;&#21644;&#22522;&#20110;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#30340;&#36870;&#38382;&#39064;&#27714;&#35299;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25991;&#26412;&#21040;&#22270;&#20687;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#36890;&#29992;&#20808;&#39564;&#35299;&#20915;&#25104;&#20687;&#36870;&#38382;&#39064;&#30340;&#26032;&#26041;&#27861;&#12290;&#29616;&#26377;&#30340;&#20351;&#29992;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#35299;&#20915;&#36870;&#38382;&#39064;&#30340;&#26041;&#27861;&#36890;&#24120;&#20381;&#36182;&#31616;&#21333;&#30340;&#31354;&#25991;&#26412;&#25552;&#31034;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#24615;&#33021;&#19981;&#20339;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;Prompt-tuning&#26041;&#27861;&#65292;&#22312;&#36816;&#34892;&#21453;&#21521;&#25193;&#25955;&#36807;&#31243;&#26102;&#23454;&#26102;&#20248;&#21270;&#25991;&#26412;&#23884;&#20837;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#29983;&#25104;&#26356;&#31526;&#21512;&#25193;&#25955;&#20808;&#39564;&#30340;&#22270;&#20687;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#25237;&#24433;&#23558;&#28508;&#22312;&#21464;&#37327;&#30340;&#28436;&#21270;&#20445;&#25345;&#22312;&#32534;&#30721;&#22120;&#30340;&#33539;&#22260;&#31354;&#38388;&#20869;&#30340;&#26041;&#27861;&#12290;&#36825;&#26377;&#21161;&#20110;&#20943;&#23569;&#20351;&#29992;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#32780;&#19981;&#26159;&#22522;&#20110;&#20687;&#32032;&#30340;&#25193;&#25955;&#27169;&#22411;&#26102;&#20135;&#29983;&#30340;&#22270;&#20687;&#20266;&#24433;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#32508;&#21512;&#26041;&#27861;&#31216;&#20026;P2L&#65292;&#22312;&#21508;&#31181;&#20219;&#21153;&#65288;&#22914;&#36229;&#20998;&#36776;&#29575;&#12289;&#21435;&#27169;&#31946;&#21644;&#20462;&#22797;&#65289;&#20013;&#20248;&#20110;&#22522;&#20110;&#22270;&#20687;&#21644;&#22522;&#20110;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#30340;&#36870;&#38382;&#39064;&#27714;&#35299;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new method for solving imaging inverse problems using text-to-image latent diffusion models as general priors. Existing methods using latent diffusion models for inverse problems typically rely on simple null text prompts, which can lead to suboptimal performance. To address this limitation, we introduce a method for prompt tuning, which jointly optimizes the text embedding on-the-fly while running the reverse diffusion process. This allows us to generate images that are more faithful to the diffusion prior. In addition, we propose a method to keep the evolution of latent variables within the range space of the encoder, by projection. This helps to reduce image artifacts, a major problem when using latent diffusion models instead of pixel-based diffusion models. Our combined method, called P2L, outperforms both image- and latent-diffusion model-based inverse problem solvers on a variety of tasks, such as super-resolution, deblurring, and inpainting.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; Ground-A-Video &#30340;&#22522;&#20110;&#24341;&#23548;&#30340;&#35270;&#39057;&#21040;&#35270;&#39057;&#36716;&#25442;&#26694;&#26550;&#65292;&#29992;&#20110;&#22810;&#23646;&#24615;&#35270;&#39057;&#32534;&#36753;&#12290;&#35813;&#26041;&#27861;&#22312;&#27809;&#26377;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#36755;&#20837;&#35270;&#39057;&#30340;&#26102;&#38388;&#19968;&#33268;&#30340;&#22810;&#23646;&#24615;&#32534;&#36753;&#65292;&#24182;&#19988;&#35299;&#20915;&#20102;&#20854;&#20182;&#26041;&#27861;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.01107</link><description>&lt;p&gt;
Ground-A-Video: &#20351;&#29992;&#25991;&#26412;&#21040;&#22270;&#20687;&#25193;&#25955;&#27169;&#22411;&#30340;&#38646;&#26679;&#26412;&#35270;&#39057;&#32534;&#36753;
&lt;/p&gt;
&lt;p&gt;
Ground-A-Video: Zero-shot Grounded Video Editing using Text-to-image Diffusion Models. (arXiv:2310.01107v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01107
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; Ground-A-Video &#30340;&#22522;&#20110;&#24341;&#23548;&#30340;&#35270;&#39057;&#21040;&#35270;&#39057;&#36716;&#25442;&#26694;&#26550;&#65292;&#29992;&#20110;&#22810;&#23646;&#24615;&#35270;&#39057;&#32534;&#36753;&#12290;&#35813;&#26041;&#27861;&#22312;&#27809;&#26377;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#36755;&#20837;&#35270;&#39057;&#30340;&#26102;&#38388;&#19968;&#33268;&#30340;&#22810;&#23646;&#24615;&#32534;&#36753;&#65292;&#24182;&#19988;&#35299;&#20915;&#20102;&#20854;&#20182;&#26041;&#27861;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22312;&#35270;&#39057;&#32534;&#36753;&#39046;&#22495;&#21462;&#24471;&#20102;&#20196;&#20154;&#26399;&#24453;&#30340;&#25104;&#26524;&#65292;&#23454;&#29616;&#20102;&#21333;&#23646;&#24615;&#32534;&#36753;&#25110;&#39118;&#26684;&#20256;&#36882;&#30340;&#20219;&#21153;&#65292;&#19981;&#35770;&#36890;&#36807;&#22312;&#25991;&#26412;-&#35270;&#39057;&#25968;&#25454;&#19978;&#35757;&#32451;&#25991;&#26412;&#21040;&#35270;&#39057;&#65288;T2V&#65289;&#27169;&#22411;&#36824;&#26159;&#37319;&#29992;&#26080;&#38656;&#35757;&#32451;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#24403;&#38754;&#23545;&#22810;&#23646;&#24615;&#32534;&#36753;&#24773;&#26223;&#30340;&#22797;&#26434;&#24615;&#26102;&#65292;&#23427;&#20204;&#23384;&#22312;&#19968;&#20123;&#32570;&#28857;&#65292;&#27604;&#22914;&#24573;&#30053;&#25110;&#24573;&#35270;&#25152;&#26399;&#26395;&#30340;&#23646;&#24615;&#21464;&#21270;&#65292;&#20462;&#25913;&#36755;&#20837;&#35270;&#39057;&#30340;&#38169;&#35823;&#20803;&#32032;&#65292;&#20197;&#21450;&#26080;&#27861;&#20445;&#30041;&#24212;&#35813;&#20445;&#25345;&#21407;&#26679;&#30340;&#36755;&#20837;&#35270;&#39057;&#21306;&#22495;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#24341;&#23548;&#30340;&#35270;&#39057;&#21040;&#35270;&#39057;&#36716;&#25442;&#26694;&#26550;&#65292;&#21517;&#20026; Ground-A-Video&#65292;&#29992;&#20110;&#22810;&#23646;&#24615;&#35270;&#39057;&#32534;&#36753;&#12290;Ground-A-Video&#20197;&#26080;&#38656;&#35757;&#32451;&#30340;&#26041;&#24335;&#23454;&#29616;&#20102;&#36755;&#20837;&#35270;&#39057;&#30340;&#26102;&#38388;&#19968;&#33268;&#30340;&#22810;&#23646;&#24615;&#32534;&#36753;&#65292;&#24182;&#19988;&#27809;&#26377;&#19978;&#36848;&#32570;&#28857;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#26680;&#24515;&#26159;&#24341;&#20837;&#20102;&#20132;&#21449;&#24103;&#38376;&#25511;&#27880;&#24847;&#21147;&#65292;&#20197;&#19968;&#31181;&#26102;&#38388;&#19978;&#19968;&#33268;&#30340;&#26041;&#24335;&#23558;&#23450;&#20301;&#20449;&#24687;&#34701;&#20837;&#21040;&#28508;&#22312;&#34920;&#31034;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent endeavors in video editing have showcased promising results in single-attribute editing or style transfer tasks, either by training text-to-video (T2V) models on text-video data or adopting training-free methods. However, when confronted with the complexities of multi-attribute editing scenarios, they exhibit shortcomings such as omitting or overlooking intended attribute changes, modifying the wrong elements of the input video, and failing to preserve regions of the input video that should remain intact. To address this, here we present a novel grounding-guided video-to-video translation framework called Ground-A-Video for multi-attribute video editing. Ground-A-Video attains temporally consistent multi-attribute editing of input videos in a training-free manner without aforementioned shortcomings. Central to our method is the introduction of Cross-Frame Gated Attention which incorporates groundings information into the latent representations in a temporally consistent fashion,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33021;&#37327;&#23548;&#21521;&#30340;&#26041;&#27861;&#29992;&#20110;&#36817;&#20284;&#35745;&#31639;&#20219;&#24847;OT&#25104;&#26412;&#20989;&#25968;&#30340;&#36830;&#32493;&#29109;OT&#24052;&#27663;&#20013;&#24515;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#20248;&#36234;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#33021;&#19982;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#65288;EBMs&#65289;&#23398;&#20064;&#36807;&#31243;&#26080;&#32541;&#36830;&#25509;&#12290;</title><link>http://arxiv.org/abs/2310.01105</link><description>&lt;p&gt;
&#22522;&#20110;&#33021;&#37327;&#23548;&#21521;&#30340;&#36830;&#32493;&#29109;&#24052;&#27663;&#20013;&#24515;&#20272;&#35745;&#26041;&#27861;&#21450;&#20854;&#22312;&#19968;&#33324;&#25104;&#26412;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Energy-Guided Continuous Entropic Barycenter Estimation for General Costs. (arXiv:2310.01105v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01105
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33021;&#37327;&#23548;&#21521;&#30340;&#26041;&#27861;&#29992;&#20110;&#36817;&#20284;&#35745;&#31639;&#20219;&#24847;OT&#25104;&#26412;&#20989;&#25968;&#30340;&#36830;&#32493;&#29109;OT&#24052;&#27663;&#20013;&#24515;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#20248;&#36234;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#33021;&#19982;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#65288;EBMs&#65289;&#23398;&#20064;&#36807;&#31243;&#26080;&#32541;&#36830;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20248;&#21270;&#36755;&#36816;&#65288;OT&#65289;&#24052;&#27663;&#20013;&#24515;&#26159;&#19968;&#31181;&#22312;&#25429;&#25417;&#27010;&#29575;&#20998;&#24067;&#20960;&#20309;&#29305;&#24615;&#30340;&#21516;&#26102;&#23545;&#20854;&#36827;&#34892;&#24179;&#22343;&#30340;&#25968;&#23398;&#26041;&#27861;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#35745;&#31639;&#20219;&#24847;OT&#25104;&#26412;&#20989;&#25968;&#30340;&#36830;&#32493;&#29109;OT&#24052;&#27663;&#20013;&#24515;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#26368;&#36817;&#22312;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#20013;&#21463;&#21040;&#20851;&#27880;&#30340;&#22522;&#20110;&#24369;OT&#30340;&#36830;&#32493;&#29109;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#30340;&#23545;&#20598;&#37325;&#26500;&#12290;&#38500;&#20102;&#21019;&#26032;&#24615;&#20043;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36824;&#20855;&#26377;&#20197;&#19979;&#33509;&#24178;&#20248;&#21183;&#29305;&#28857;&#65306;&#65288;i&#65289;&#25105;&#20204;&#24314;&#31435;&#20102;&#23545;&#24674;&#22797;&#35299;&#30340;&#36136;&#37327;&#30028;&#38480;&#65307;&#65288;ii&#65289;&#35813;&#26041;&#27861;&#19982;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#65288;EBMs&#65289;&#23398;&#20064;&#36807;&#31243;&#26080;&#32541;&#36830;&#25509;&#65292;&#21487;&#20197;&#20351;&#29992;&#32463;&#36807;&#33391;&#22909;&#35843;&#25972;&#30340;&#31639;&#27861;&#35299;&#20915;&#24863;&#20852;&#36259;&#30340;&#38382;&#39064;&#65307;&#65288;iii&#65289;&#23427;&#25552;&#20379;&#20102;&#19968;&#31181;&#30452;&#35266;&#30340;&#20248;&#21270;&#26041;&#26696;&#65292;&#36991;&#20813;&#20351;&#29992;&#26497;&#23567;-&#26497;&#22823;&#12289;&#24378;&#21270;&#31561;&#22797;&#26434;&#25216;&#24039;&#12290;&#20026;&#20102;&#39564;&#35777;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;s
&lt;/p&gt;
&lt;p&gt;
Optimal transport (OT) barycenters are a mathematically grounded way of averaging probability distributions while capturing their geometric properties. In short, the barycenter task is to take the average of a collection of probability distributions w.r.t. given OT discrepancies. We propose a novel algorithm for approximating the continuous Entropic OT (EOT) barycenter for arbitrary OT cost functions. Our approach is built upon the dual reformulation of the EOT problem based on weak OT, which has recently gained the attention of the ML community. Beyond its novelty, our method enjoys several advantageous properties: (i) we establish quality bounds for the recovered solution; (ii) this approach seemlessly interconnects with the Energy-Based Models (EBMs) learning procedure enabling the use of well-tuned algorithms for the problem of interest; (iii) it provides an intuitive optimization scheme avoiding min-max, reinforce and other intricate technical tricks. For validation, we consider s
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#36153;&#33293;&#23572;-&#25289;&#22885;&#20449;&#24687;&#20960;&#20309;&#22312;&#26925;&#22278;&#20998;&#24067;&#20013;&#30340;&#24212;&#29992;&#65292;&#21253;&#25324;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#12289;&#20869;&#34164;Cram\'er-Rao&#30028;&#38480;&#21644;&#20351;&#29992;&#40654;&#26364;&#36317;&#31163;&#36827;&#34892;&#20998;&#31867;&#12290;</title><link>http://arxiv.org/abs/2310.01032</link><description>&lt;p&gt;
CES&#20998;&#24067;&#30340;&#36153;&#33293;&#23572;-&#25289;&#22885;&#65288;Fisher-Rao&#65289;&#20960;&#20309;
&lt;/p&gt;
&lt;p&gt;
The Fisher-Rao geometry of CES distributions. (arXiv:2310.01032v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01032
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#36153;&#33293;&#23572;-&#25289;&#22885;&#20449;&#24687;&#20960;&#20309;&#22312;&#26925;&#22278;&#20998;&#24067;&#20013;&#30340;&#24212;&#29992;&#65292;&#21253;&#25324;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#12289;&#20869;&#34164;Cram\'er-Rao&#30028;&#38480;&#21644;&#20351;&#29992;&#40654;&#26364;&#36317;&#31163;&#36827;&#34892;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22788;&#29702;&#21442;&#25968;&#32479;&#35745;&#27169;&#22411;&#26102;&#65292;&#33258;&#28982;&#20250;&#22312;&#21442;&#25968;&#31354;&#38388;&#19978;&#36171;&#20104;&#36153;&#33293;&#23572;&#20449;&#24687;&#24230;&#37327;&#65292;&#20174;&#32780;&#20135;&#29983;&#19968;&#20010;&#40654;&#26364;&#27969;&#24418;&#12290;&#36825;&#20010;&#24230;&#37327;&#35825;&#23548;&#22312;&#21442;&#25968;&#19978;&#30340;&#20960;&#20309;&#31216;&#20026;&#36153;&#33293;&#23572;-&#25289;&#22885;&#20449;&#24687;&#20960;&#20309;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#36825;&#31181;&#35266;&#28857;&#21487;&#20197;&#21033;&#29992;&#24494;&#20998;&#20960;&#20309;&#20013;&#30340;&#35768;&#22810;&#24037;&#20855;&#12290;&#22312;&#31616;&#35201;&#20171;&#32461;&#36825;&#20123;&#27010;&#24565;&#21518;&#65292;&#25105;&#20204;&#23558;&#20171;&#32461;&#36825;&#20123;&#20960;&#20309;&#24037;&#20855;&#22312;&#26925;&#22278;&#20998;&#24067;&#26694;&#26550;&#20013;&#30340;&#19968;&#20123;&#23454;&#38469;&#24212;&#29992;&#12290;&#36825;&#20010;&#38416;&#36848;&#30340;&#31532;&#20108;&#37096;&#20998;&#20998;&#20026;&#19977;&#20010;&#20027;&#35201;&#26041;&#38754;&#65306;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#30340;&#40654;&#26364;&#20248;&#21270;&#12289;&#20869;&#34164;Cram\'er-Rao&#30028;&#38480;&#21644;&#20351;&#29992;&#40654;&#26364;&#36317;&#31163;&#36827;&#34892;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
When dealing with a parametric statistical model, a Riemannian manifold can naturally appear by endowing the parameter space with the Fisher information metric. The geometry induced on the parameters by this metric is then referred to as the Fisher-Rao information geometry. Interestingly, this yields a point of view that allows for leveragingmany tools from differential geometry. After a brief introduction about these concepts, we will present some practical uses of these geometric tools in the framework of elliptical distributions. This second part of the exposition is divided into three main axes: Riemannian optimization for covariance matrix estimation, Intrinsic Cram\'er-Rao bounds, and classification using Riemannian distances.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26080;&#32422;&#26463;&#30446;&#26631;&#65292;&#36890;&#36807;&#24212;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#21040;CCA&#30446;&#26631;&#65292;&#23454;&#29616;&#20102;&#19968;&#31995;&#21015;&#24555;&#36895;&#31639;&#27861;&#65292;&#21253;&#25324;&#38543;&#26426;PLS&#12289;&#38543;&#26426;CCA&#21644;&#28145;&#24230;CCA&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#21508;&#31181;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#27604;&#20808;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#26356;&#39640;&#30340;&#30456;&#20851;&#24615;&#24674;&#22797;&#12290;</title><link>http://arxiv.org/abs/2310.01012</link><description>&lt;p&gt;
CCA&#23478;&#26063;&#30340;&#39640;&#25928;&#31639;&#27861;&#65306;&#26080;&#32422;&#26463;&#30446;&#26631;&#19982;&#26080;&#20559;&#26799;&#24230;
&lt;/p&gt;
&lt;p&gt;
Efficient Algorithms for the CCA Family: Unconstrained Objectives with Unbiased Gradients. (arXiv:2310.01012v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01012
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26080;&#32422;&#26463;&#30446;&#26631;&#65292;&#36890;&#36807;&#24212;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#21040;CCA&#30446;&#26631;&#65292;&#23454;&#29616;&#20102;&#19968;&#31995;&#21015;&#24555;&#36895;&#31639;&#27861;&#65292;&#21253;&#25324;&#38543;&#26426;PLS&#12289;&#38543;&#26426;CCA&#21644;&#28145;&#24230;CCA&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#21508;&#31181;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#27604;&#20808;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#26356;&#39640;&#30340;&#30456;&#20851;&#24615;&#24674;&#22797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20856;&#22411;&#30456;&#20851;&#20998;&#26512;&#65288;CCA&#65289;&#26041;&#27861;&#22312;&#22810;&#35270;&#35282;&#23398;&#20064;&#20013;&#20855;&#26377;&#22522;&#30784;&#24615;&#20316;&#29992;&#12290;&#27491;&#21017;&#21270;&#32447;&#24615;CCA&#26041;&#27861;&#21487;&#20197;&#30475;&#20316;&#26159;&#20559;&#26368;&#23567;&#20108;&#20056;&#65288;PLS&#65289;&#30340;&#25512;&#24191;&#65292;&#24182;&#19982;&#24191;&#20041;&#29305;&#24449;&#20540;&#38382;&#39064;&#65288;GEP&#65289;&#26694;&#26550;&#32479;&#19968;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#32447;&#24615;&#26041;&#27861;&#30340;&#20256;&#32479;&#31639;&#27861;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#19978;&#35745;&#31639;&#19978;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#28145;&#24230;CCA&#30340;&#25193;&#23637;&#26174;&#31034;&#20986;&#24456;&#22823;&#30340;&#28508;&#21147;&#65292;&#20294;&#30446;&#21069;&#30340;&#35757;&#32451;&#36807;&#31243;&#32531;&#24930;&#19988;&#22797;&#26434;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#20010;&#25551;&#36848;GEPs&#30340;&#39030;&#32423;&#23376;&#31354;&#38388;&#30340;&#26032;&#39062;&#26080;&#32422;&#26463;&#30446;&#26631;&#12290;&#25105;&#20204;&#30340;&#26680;&#24515;&#36129;&#29486;&#26159;&#19968;&#31995;&#21015;&#24555;&#36895;&#31639;&#27861;&#65292;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#24212;&#29992;&#20110;&#30456;&#24212;&#30340;CCA&#30446;&#26631;&#65292;&#20174;&#32780;&#33719;&#24471;&#38543;&#26426;PLS&#12289;&#38543;&#26426;CCA&#21644;&#28145;&#24230;CCA&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#25152;&#26377;&#26631;&#20934;CCA&#21644;&#28145;&#24230;CCA&#22522;&#20934;&#27979;&#35797;&#20013;&#26174;&#31034;&#20986;&#27604;&#20808;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#26356;&#39640;&#30340;&#30456;&#20851;&#24615;&#24674;&#22797;&#12290;&#36825;&#26679;&#30340;&#36895;&#24230;&#20351;&#25105;&#20204;&#33021;&#22815;&#39318;&#27425;&#36827;&#34892;&#22823;&#35268;&#27169;&#29983;&#29289;&#25968;&#25454;&#30340;PLS&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Canonical Correlation Analysis (CCA) family of methods is foundational in multi-view learning. Regularised linear CCA methods can be seen to generalise Partial Least Squares (PLS) and unified with a Generalized Eigenvalue Problem (GEP) framework. However, classical algorithms for these linear methods are computationally infeasible for large-scale data. Extensions to Deep CCA show great promise, but current training procedures are slow and complicated. First we propose a novel unconstrained objective that characterizes the top subspace of GEPs. Our core contribution is a family of fast algorithms for stochastic PLS, stochastic CCA, and Deep CCA, simply obtained by applying stochastic gradient descent (SGD) to the corresponding CCA objectives. These methods show far faster convergence and recover higher correlations than the previous state-of-the-art on all standard CCA and Deep CCA benchmarks. This speed allows us to perform a first-of-its-kind PLS analysis of an extremely large bio
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#25512;&#23548;&#20219;&#24847;&#26377;&#38480;&#31209;&#26680;&#23725;&#22238;&#24402;&#27169;&#22411;&#30340;&#23574;&#38160;&#30340;&#38750;&#28176;&#36817;&#24615;&#19978;&#30028;&#21644;&#19979;&#30028;&#65292;&#22635;&#34917;&#20102;&#26377;&#38480;&#31209;&#26680;&#23725;&#22238;&#24402;&#20445;&#35777;&#30340;&#31354;&#30333;&#12290;</title><link>http://arxiv.org/abs/2310.00987</link><description>&lt;p&gt;
&#26377;&#38480;&#31209;&#26680;&#23725;&#22238;&#24402;&#30340;&#27979;&#35797;&#35823;&#24046;&#30340;&#29702;&#35770;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Theoretical Analysis of the Test Error of Finite-Rank Kernel Ridge Regression. (arXiv:2310.00987v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00987
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#25512;&#23548;&#20219;&#24847;&#26377;&#38480;&#31209;&#26680;&#23725;&#22238;&#24402;&#27169;&#22411;&#30340;&#23574;&#38160;&#30340;&#38750;&#28176;&#36817;&#24615;&#19978;&#30028;&#21644;&#19979;&#30028;&#65292;&#22635;&#34917;&#20102;&#26377;&#38480;&#31209;&#26680;&#23725;&#22238;&#24402;&#20445;&#35777;&#30340;&#31354;&#30333;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#23545;&#20110;&#19968;&#33324;&#26680;&#22238;&#24402;&#27169;&#22411;&#30340;&#32479;&#35745;&#23398;&#23398;&#20064;&#20445;&#35777;&#22312;&#20351;&#29992;&#26377;&#38480;&#31209;&#26680;&#26102;&#24448;&#24448;&#20250;&#24471;&#21040;&#23485;&#26494;&#30340;&#36793;&#30028;&#12290;&#28982;&#32780;&#65292;&#22312;&#20960;&#20010;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#65292;&#22914;&#22312;&#25191;&#34892;&#36801;&#31227;&#23398;&#20064;&#26102;&#65292;&#23558;&#39044;&#35757;&#32451;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#21518;&#19968;&#23618;&#24494;&#35843;&#20197;&#36866;&#24212;&#26032;&#20219;&#21153;&#26102;&#65292;&#26377;&#38480;&#31209;&#26680;&#20250;&#33258;&#28982;&#22320;&#20986;&#29616;&#12290;&#26412;&#25991;&#36890;&#36807;&#25512;&#23548;&#20219;&#24847;&#26377;&#38480;&#31209;&#26680;&#23725;&#22238;&#24402;&#27169;&#22411;&#30340;&#23574;&#38160;&#30340;&#38750;&#28176;&#36817;&#24615;&#19978;&#30028;&#21644;&#19979;&#30028;&#65292;&#22635;&#34917;&#20102;&#26377;&#38480;&#31209;&#26680;&#23725;&#22238;&#24402;&#20445;&#35777;&#30340;&#31354;&#30333;&#12290;&#25105;&#20204;&#30340;&#36793;&#30028;&#27604;&#20043;&#21069;&#38024;&#23545;&#26377;&#38480;&#31209;&#26680;&#23725;&#22238;&#24402;&#27169;&#22411;&#25512;&#23548;&#30340;&#36793;&#30028;&#26356;&#32039;&#65292;&#24182;&#19988;&#19982;&#31867;&#20284;&#32467;&#26524;&#19981;&#21516;&#30340;&#26159;&#65292;&#23427;&#20204;&#20063;&#36866;&#29992;&#20110;&#20219;&#20309;&#27491;&#21017;&#21270;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing statistical learning guarantees for general kernel regressors often yield loose bounds when used with finite-rank kernels. Yet, finite-rank kernels naturally appear in several machine learning problems, e.g.\ when fine-tuning a pre-trained deep neural network's last layer to adapt it to a novel task when performing transfer learning. We address this gap for finite-rank kernel ridge regression (KRR) by deriving sharp non-asymptotic upper and lower bounds for the KRR test error of any finite-rank KRR. Our bounds are tighter than previously derived bounds on finite-rank KRR, and unlike comparable results, they also remain valid for any regularization parameters.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#23545;&#20915;&#20105;&#22842;&#20013;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#38382;&#39064;&#65292;&#31639;&#27861;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#21644;&#26041;&#24046;&#24863;&#30693;&#36951;&#25022;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2310.00968</link><description>&lt;p&gt;
&#38543;&#26426;&#24773;&#22659;&#23545;&#20915;&#20105;&#22842;&#20915;&#31574;&#30340;&#26041;&#24046;&#24863;&#30693;&#36951;&#25022;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Variance-Aware Regret Bounds for Stochastic Contextual Dueling Bandits. (arXiv:2310.00968v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00968
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#23545;&#20915;&#20105;&#22842;&#20013;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#38382;&#39064;&#65292;&#31639;&#27861;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#21644;&#26041;&#24046;&#24863;&#30693;&#36951;&#25022;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20915;&#20105;&#22842;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#20915;&#31574;&#26694;&#26550;&#65292;&#28041;&#21450;&#21040;&#20559;&#22909;&#21453;&#39304;&#30340;&#20915;&#31574;&#65292;&#36825;&#26159;&#19968;&#20010;&#36866;&#29992;&#20110;&#20154;&#26426;&#20132;&#20114;&#30340;&#21508;&#31181;&#24212;&#29992;&#22330;&#26223;&#30340;&#26377;&#20215;&#20540;&#29305;&#24615;&#65292;&#20363;&#22914;&#25490;&#21517;&#12289;&#20449;&#24687;&#26816;&#32034;&#21644;&#25512;&#33616;&#31995;&#32479;&#12290;&#34429;&#28982;&#22312;&#23545;&#20915;&#20105;&#22842;&#20013;&#24050;&#32463;&#20570;&#20986;&#20102;&#22823;&#37327;&#30340;&#21162;&#21147;&#26469;&#26368;&#23567;&#21270;&#32047;&#35745;&#36951;&#25022;&#65292;&#20294;&#30446;&#21069;&#30740;&#31350;&#20013;&#23384;&#22312;&#19968;&#20010;&#26126;&#26174;&#30340;&#31354;&#30333;&#65292;&#21363;&#36951;&#25022;&#30028;&#38480;&#26410;&#32771;&#34385;&#21040;&#23545;&#20915;&#25163;&#34920;&#38388;&#25104;&#23545;&#27604;&#36739;&#30340;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#12290;&#30452;&#35266;&#22320;&#35828;&#65292;&#26356;&#22823;&#30340;&#19981;&#30830;&#23450;&#24615;&#24847;&#21619;&#30528;&#38382;&#39064;&#30340;&#38590;&#24230;&#26356;&#39640;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#20010;&#31354;&#30333;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#24773;&#22659;&#23545;&#20915;&#20105;&#22842;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#20915;&#31574;&#25163;&#34920;&#30340;&#20108;&#20803;&#23545;&#27604;&#26159;&#30001;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;GLM&#65289;&#29983;&#25104;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;SupLinUCB&#31867;&#22411;&#30340;&#31639;&#27861;&#65292;&#36825;&#20010;&#31639;&#27861;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#21644;&#19968;&#20010;&#24863;&#30693;&#26041;&#24046;&#36951;&#25022;&#30028;&#38480;$\tilde O\big(d\sqrt{\sum_{t=1}^T\sigma_t^2} + d\big)$&#65292;&#20854;&#20013;$\sigma_t$&#26159;&#27599;&#36718;&#25104;&#23545;&#27604;&#36739;&#30340;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dueling bandits is a prominent framework for decision-making involving preferential feedback, a valuable feature that fits various applications involving human interaction, such as ranking, information retrieval, and recommendation systems. While substantial efforts have been made to minimize the cumulative regret in dueling bandits, a notable gap in the current research is the absence of regret bounds that account for the inherent uncertainty in pairwise comparisons between the dueling arms. Intuitively, greater uncertainty suggests a higher level of difficulty in the problem. To bridge this gap, this paper studies the problem of contextual dueling bandits, where the binary comparison of dueling arms is generated from a generalized linear model (GLM). We propose a new SupLinUCB-type algorithm that enjoys computational efficiency and a variance-aware regret bound $\tilde O\big(d\sqrt{\sum_{t=1}^T\sigma_t^2} + d\big)$, where $\sigma_t$ is the variance of the pairwise comparison in round
&lt;/p&gt;</description></item><item><title>VBPI-Mixtures&#26159;&#19968;&#31181;&#25913;&#36827;&#30340;&#21464;&#20998;&#36125;&#21494;&#26031;&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#28151;&#21512;&#23398;&#20064;&#25216;&#26415;&#26469;&#25552;&#39640;&#31995;&#32479;&#21457;&#32946;&#21518;&#39564;&#20998;&#24067;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#33021;&#22815;&#25429;&#25417;&#21040;&#20256;&#32479;&#31639;&#27861;&#26410;&#33021;&#24314;&#27169;&#30340;&#26641;&#24418;&#25299;&#25169;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2310.00941</link><description>&lt;p&gt;
&#25913;&#36827;&#30340;&#21464;&#20998;&#36125;&#21494;&#26031;&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;&#31639;&#27861;&#8212;&#8212;&#28151;&#21512;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Improved Variational Bayesian Phylogenetic Inference using Mixtures. (arXiv:2310.00941v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00941
&lt;/p&gt;
&lt;p&gt;
VBPI-Mixtures&#26159;&#19968;&#31181;&#25913;&#36827;&#30340;&#21464;&#20998;&#36125;&#21494;&#26031;&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#28151;&#21512;&#23398;&#20064;&#25216;&#26415;&#26469;&#25552;&#39640;&#31995;&#32479;&#21457;&#32946;&#21518;&#39564;&#20998;&#24067;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#33021;&#22815;&#25429;&#25417;&#21040;&#20256;&#32479;&#31639;&#27861;&#26410;&#33021;&#24314;&#27169;&#30340;&#26641;&#24418;&#25299;&#25169;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;VBPI-Mixtures&#31639;&#27861;&#65292;&#26088;&#22312;&#25552;&#39640;&#31995;&#32479;&#21457;&#32946;&#21518;&#39564;&#20998;&#24067;&#30340;&#20934;&#30830;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#26641;&#24418;&#25299;&#25169;&#21644;&#20998;&#25903;&#38271;&#24230;&#36817;&#20284;&#26041;&#38754;&#12290;&#23613;&#31649;&#21464;&#20998;&#36125;&#21494;&#26031;&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;&#65288;VBPI&#65289;&#20316;&#20026;&#19968;&#20010;&#39046;&#20808;&#30340;&#40657;&#30418;&#21464;&#20998;&#25512;&#29702;&#65288;BBVI&#65289;&#26694;&#26550;&#65292;&#22312;&#36825;&#20123;&#20998;&#24067;&#30340;&#36817;&#20284;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#26524;&#65292;&#20294;&#26641;&#24418;&#25299;&#25169;&#21518;&#39564;&#30340;&#22810;&#27169;&#24615;&#23545;&#20110;&#26679;&#26412;&#37319;&#29992;&#23398;&#20064;&#25216;&#26415;&#65288;&#22914;BBVI&#65289;&#26469;&#35828;&#26159;&#19968;&#20010;&#20005;&#23803;&#30340;&#25361;&#25112;&#12290;&#20808;&#36827;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#22914;&#26631;&#20934;&#27969;&#21644;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#24050;&#32463;&#34987;&#24212;&#29992;&#20110;&#25913;&#21892;&#20998;&#25903;&#38271;&#24230;&#21518;&#39564;&#30340;&#36817;&#20284;&#65292;&#20294;&#22312;&#25913;&#36827;&#26641;&#24418;&#25299;&#25169;&#21518;&#39564;&#30340;&#26041;&#38754;&#30340;&#21162;&#21147;&#36824;&#19981;&#36275;&#12290;&#25105;&#20204;&#30340;&#26032;&#39062;&#31639;&#27861;VBPI-Mixtures&#22635;&#34917;&#20102;&#36825;&#19968;&#31354;&#30333;&#65292;&#23558;BBVI&#22495;&#20869;&#28151;&#21512;&#23398;&#20064;&#30340;&#26368;&#26032;&#31361;&#30772;&#24212;&#29992;&#20854;&#20013;&#12290;&#22240;&#27492;&#65292;VBPI-Mixtures&#33021;&#22815;&#25429;&#25417;VBPI&#26410;&#33021;&#24314;&#27169;&#30340;&#26641;&#24418;&#25299;&#25169;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present VBPI-Mixtures, an algorithm designed to enhance the accuracy of phylogenetic posterior distributions, particularly for tree-topology and branch-length approximations. Despite the Variational Bayesian Phylogenetic Inference (VBPI), a leading-edge black-box variational inference (BBVI) framework, achieving remarkable approximations of these distributions, the multimodality of the tree-topology posterior presents a formidable challenge to sampling-based learning techniques such as BBVI. Advanced deep learning methodologies such as normalizing flows and graph neural networks have been explored to refine the branch-length posterior approximation, yet efforts to ameliorate the posterior approximation over tree topologies have been lacking. Our novel VBPI-Mixtures algorithm bridges this gap by harnessing the latest breakthroughs in mixture learning within the BBVI domain. As a result, VBPI-Mixtures is capable of capturing distributions over tree-topologies that VBPI fails to model.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;CLIP&#20013;&#30340;&#21487;&#36716;&#31227;&#34920;&#31034;&#23398;&#20064;&#21644;&#38646;&#26679;&#26412;&#20256;&#36882;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;CLIP&#31867;&#22411;&#26041;&#27861;&#65292;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.00927</link><description>&lt;p&gt;
&#29702;&#35299;CLIP&#20013;&#30340;&#21487;&#36716;&#31227;&#34920;&#31034;&#23398;&#20064;&#21644;&#38646;&#26679;&#26412;&#20256;&#36882;
&lt;/p&gt;
&lt;p&gt;
Understanding Transferable Representation Learning and Zero-shot Transfer in CLIP. (arXiv:2310.00927v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00927
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;CLIP&#20013;&#30340;&#21487;&#36716;&#31227;&#34920;&#31034;&#23398;&#20064;&#21644;&#38646;&#26679;&#26412;&#20256;&#36882;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;CLIP&#31867;&#22411;&#26041;&#27861;&#65292;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#23398;&#20064;&#22240;&#20854;&#33021;&#22815;&#21033;&#29992;&#19981;&#21516;&#25968;&#25454;&#28304;&#65288;&#20363;&#22914;&#25991;&#26412;&#21644;&#22270;&#20687;&#65289;&#30340;&#20449;&#24687;&#26469;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#32780;&#26085;&#30410;&#21463;&#21040;&#20851;&#27880;&#12290;&#36817;&#24180;&#26469;&#65292;CLIP&#20316;&#20026;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#37319;&#29992;&#35270;&#35273;-&#35821;&#35328;&#23545;&#27604;&#39044;&#35757;&#32451;&#26469;&#23398;&#20064;&#32852;&#21512;&#22270;&#20687;&#21644;&#25991;&#26412;&#34920;&#31034;&#65292;&#24182;&#22312;&#38646;&#26679;&#26412;&#23398;&#20064;&#21644;&#25991;&#26412;&#24341;&#23548;&#30340;&#33258;&#28982;&#22270;&#20687;&#29983;&#25104;&#26041;&#38754;&#34920;&#29616;&#20986;&#38750;&#20961;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;CLIP&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#65292;&#20294;&#20854;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#22256;&#38590;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#27491;&#24335;&#30740;&#31350;&#20102;CLIP&#20013;&#30340;&#21487;&#36716;&#31227;&#34920;&#31034;&#23398;&#20064;&#65292;&#24182;&#23637;&#31034;&#20102;&#19981;&#21516;&#27169;&#24577;&#30340;&#29305;&#24449;&#22914;&#20309;&#23545;&#40784;&#12290;&#25105;&#20204;&#36824;&#20998;&#26512;&#20102;&#20854;&#22312;&#19979;&#28216;&#20219;&#21153;&#20013;&#30340;&#38646;&#26679;&#26412;&#20256;&#36882;&#24615;&#33021;&#12290;&#21463;&#21040;&#25105;&#20204;&#20998;&#26512;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;CLIP&#31867;&#22411;&#26041;&#27861;&#65292;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#27604;CLIP&#21644;&#20854;&#20182;&#26368;&#20808;&#36827;&#26041;&#27861;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-modal learning has become increasingly popular due to its ability to leverage information from different data sources (e.g., text and images) to improve the model performance. Recently, CLIP has emerged as an effective approach that employs vision-language contrastive pretraining to learn joint image and text representations and exhibits remarkable performance in zero-shot learning and text-guided natural image generation. Despite the huge practical success of CLIP, its theoretical understanding remains elusive. In this paper, we formally study transferrable representation learning underlying CLIP and demonstrate how features from different modalities get aligned. We also analyze its zero-shot transfer performance on the downstream tasks. Inspired by our analysis, we propose a new CLIP-type approach, which achieves better performance than CLIP and other state-of-the-art methods on benchmark datasets.
&lt;/p&gt;</description></item><item><title>DataInf&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#24433;&#21709;&#21147;&#36817;&#20284;&#26041;&#27861;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#29983;&#25104;&#22411;AI&#27169;&#22411;&#65292;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#22312;&#35745;&#31639;&#21644;&#20869;&#23384;&#25928;&#29575;&#19978;&#26377;&#26126;&#26174;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2310.00902</link><description>&lt;p&gt;
DataInf&#65306;&#22312;LLMs&#21644;&#25193;&#25955;&#27169;&#22411;&#20013;&#39640;&#25928;&#20272;&#35745;&#25968;&#25454;&#24433;&#21709;&#21147;
&lt;/p&gt;
&lt;p&gt;
DataInf: Efficiently Estimating Data Influence in LoRA-tuned LLMs and Diffusion Models. (arXiv:2310.00902v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00902
&lt;/p&gt;
&lt;p&gt;
DataInf&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#24433;&#21709;&#21147;&#36817;&#20284;&#26041;&#27861;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#29983;&#25104;&#22411;AI&#27169;&#22411;&#65292;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#22312;&#35745;&#31639;&#21644;&#20869;&#23384;&#25928;&#29575;&#19978;&#26377;&#26126;&#26174;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#21270;&#35757;&#32451;&#25968;&#25454;&#28857;&#30340;&#24433;&#21709;&#21147;&#23545;&#20110;&#29702;&#35299;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#36755;&#20986;&#21644;&#25552;&#39640;AI&#31649;&#36947;&#30340;&#36879;&#26126;&#24230;&#33267;&#20851;&#37325;&#35201;&#12290;&#24433;&#21709;&#20989;&#25968;&#26159;&#19968;&#31181;&#21407;&#21017;&#24615;&#21644;&#27969;&#34892;&#30340;&#25968;&#25454;&#24402;&#23646;&#26041;&#27861;&#65292;&#20294;&#20854;&#35745;&#31639;&#25104;&#26412;&#20351;&#20854;&#38590;&#20197;&#20351;&#29992;&#12290;&#36825;&#20010;&#38382;&#39064;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#25991;&#26412;&#21040;&#22270;&#20687;&#27169;&#22411;&#30340;&#35774;&#32622;&#20013;&#26356;&#21152;&#31361;&#20986;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;DataInf&#65292;&#19968;&#31181;&#39640;&#25928;&#30340;&#24433;&#21709;&#21147;&#36817;&#20284;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#29983;&#25104;&#22411;AI&#27169;&#22411;&#12290;&#36890;&#36807;&#21033;&#29992;&#26131;&#20110;&#35745;&#31639;&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#65292;DataInf&#22312;&#35745;&#31639;&#21644;&#20869;&#23384;&#25928;&#29575;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#30340;&#24433;&#21709;&#35745;&#31639;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;DataInf&#29305;&#21035;&#36866;&#29992;&#20110;&#35832;&#22914;LoRA&#30340;&#21442;&#25968;&#26377;&#25928;&#24494;&#35843;&#25216;&#26415;&#12290;&#36890;&#36807;&#31995;&#32479;&#30340;&#23454;&#35777;&#35780;&#20272;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;DataInf&#33021;&#22815;&#20934;&#30830;&#22320;&#36817;&#20284;&#24433;&#21709;&#20998;&#25968;&#65292;&#24182;&#19988;&#27604;&#29616;&#26377;&#26041;&#27861;&#24555;&#20960;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantifying the impact of training data points is crucial for understanding the outputs of machine learning models and for improving the transparency of the AI pipeline. The influence function is a principled and popular data attribution method, but its computational cost often makes it challenging to use. This issue becomes more pronounced in the setting of large language models and text-to-image models. In this work, we propose DataInf, an efficient influence approximation method that is practical for large-scale generative AI models. Leveraging an easy-to-compute closed-form expression, DataInf outperforms existing influence computation algorithms in terms of computational and memory efficiency. Our theoretical analysis shows that DataInf is particularly well-suited for parameter-efficient fine-tuning techniques such as LoRA. Through systematic empirical evaluations, we show that DataInf accurately approximates influence scores and is orders of magnitude faster than existing methods
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#21644;&#38598;&#25104;&#26041;&#27861;&#30340;&#20117;&#19979;&#29305;&#24615;&#34920;&#24449;&#26041;&#27861;&#12290;&#36890;&#36807;&#32467;&#21512;WGAN-GP&#21644;ES-MDA&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#20934;&#30830;&#19988;&#39640;&#25928;&#30340;K&#22330;&#20272;&#35745;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#20960;&#20010;&#20117;&#19979;&#23454;&#20363;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#26410;&#30693;K&#23383;&#27573;&#30340;&#20027;&#35201;&#29305;&#24449;&#12290;</title><link>http://arxiv.org/abs/2310.00839</link><description>&lt;p&gt;
&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#22522;&#20110;&#38598;&#25104;&#26041;&#27861;&#30340;&#20117;&#19979;&#29305;&#24615;&#34920;&#24449;
&lt;/p&gt;
&lt;p&gt;
Subsurface Characterization using Ensemble-based Approaches with Deep Generative Models. (arXiv:2310.00839v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00839
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#21644;&#38598;&#25104;&#26041;&#27861;&#30340;&#20117;&#19979;&#29305;&#24615;&#34920;&#24449;&#26041;&#27861;&#12290;&#36890;&#36807;&#32467;&#21512;WGAN-GP&#21644;ES-MDA&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#20934;&#30830;&#19988;&#39640;&#25928;&#30340;K&#22330;&#20272;&#35745;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#20960;&#20010;&#20117;&#19979;&#23454;&#20363;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#26410;&#30693;K&#23383;&#27573;&#30340;&#20027;&#35201;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20272;&#35745;&#22914;&#27700;&#21147;&#20256;&#23548;&#29575;&#65288;K&#65289;&#31561;&#31354;&#38388;&#20998;&#24067;&#23646;&#24615;&#26159;&#20117;&#19979;&#29305;&#24615;&#34920;&#24449;&#20013;&#30340;&#37325;&#22823;&#25361;&#25112;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#35745;&#31639;&#25104;&#26412;&#39640;&#21644;&#31232;&#30095;&#25968;&#25454;&#38598;&#30340;&#39044;&#27979;&#31934;&#24230;&#20302;&#65292;&#36870;&#21521;&#24314;&#27169;&#22312;&#19981;&#36866;&#23450;&#30340;&#39640;&#32500;&#24212;&#29992;&#20013;&#21463;&#38480;&#12290;&#26412;&#25991;&#23558;Wasserstein&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#19982;&#26799;&#24230;&#24809;&#32602;&#65288;WGAN-GP&#65289;&#21644;&#22522;&#20110;&#38598;&#25104;&#30340;&#22810;&#20803;&#25968;&#25454;&#21516;&#21270;&#65288;ES-MDA&#65289;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#20934;&#30830;&#19988;&#39640;&#25928;&#30340;&#20117;&#19979;&#29305;&#24615;&#34920;&#24449;&#12290;WGAN-GP&#36890;&#36807;&#35757;&#32451;&#20174;&#20302;&#32500;&#28508;&#21464;&#37327;&#31354;&#38388;&#29983;&#25104;&#39640;&#32500;K&#22330;&#65292;ES-MDA&#36890;&#36807;&#21516;&#21270;&#21487;&#29992;&#27979;&#37327;&#32467;&#26524;&#26469;&#26356;&#26032;&#28508;&#21464;&#37327;&#12290;&#21033;&#29992;&#20960;&#20010;&#20117;&#19979;&#23454;&#20363;&#35780;&#20272;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#65292;&#20197;&#21450;&#26410;&#30693;K&#23383;&#27573;&#30340;&#20027;&#35201;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating spatially distributed properties such as hydraulic conductivity (K) from available sparse measurements is a great challenge in subsurface characterization. However, the use of inverse modeling is limited for ill-posed, high-dimensional applications due to computational costs and poor prediction accuracy with sparse datasets. In this paper, we combine Wasserstein Generative Adversarial Network with Gradient Penalty (WGAN-GP), a deep generative model that can accurately capture complex subsurface structure, and Ensemble Smoother with Multiple Data Assimilation (ES-MDA), an ensemble-based inversion method, for accurate and accelerated subsurface characterization. WGAN-GP is trained to generate high-dimensional K fields from a low-dimensional latent space and ES-MDA then updates the latent variables by assimilating available measurements. Several subsurface examples are used to evaluate the accuracy and efficiency of the proposed method and the main features of the unknown K fie
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39034;&#24207;&#20915;&#31574;&#27169;&#22411;&#65292;&#32771;&#34385;&#20102;&#20154;&#30340;&#20381;&#20174;&#31243;&#24230;&#21644;&#26426;&#22120;&#25552;&#20379;&#24314;&#35758;&#30340;&#26102;&#26426;&#65292;&#24182;&#25552;&#20379;&#20102;&#23398;&#20064;&#31639;&#27861;&#26469;&#23398;&#20064;&#26368;&#20339;&#30340;&#24314;&#35758;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2310.00817</link><description>&lt;p&gt;
&#23398;&#20064;&#22914;&#20309;&#25552;&#20379;&#27880;&#37325;&#20381;&#20174;&#24615;&#30340;&#24314;&#35758;
&lt;/p&gt;
&lt;p&gt;
Learning to Make Adherence-Aware Advice. (arXiv:2310.00817v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00817
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39034;&#24207;&#20915;&#31574;&#27169;&#22411;&#65292;&#32771;&#34385;&#20102;&#20154;&#30340;&#20381;&#20174;&#31243;&#24230;&#21644;&#26426;&#22120;&#25552;&#20379;&#24314;&#35758;&#30340;&#26102;&#26426;&#65292;&#24182;&#25552;&#20379;&#20102;&#23398;&#20064;&#31639;&#27861;&#26469;&#23398;&#20064;&#26368;&#20339;&#30340;&#24314;&#35758;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#22312;&#20154;&#31867;&#20915;&#31574;&#20013;&#25198;&#28436;&#36234;&#26469;&#36234;&#37325;&#35201;&#30340;&#35282;&#33394;&#65292;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#20043;&#38388;&#30340;&#20132;&#20114;&#23384;&#22312;&#25361;&#25112;&#12290;&#30001;&#20110;&#27809;&#26377;&#20805;&#20998;&#32771;&#34385;&#21040;&#20154;&#31867;&#24573;&#35270;&#20154;&#24037;&#26234;&#33021;&#24314;&#35758;&#21644;&#20154;&#24037;&#26234;&#33021;&#36873;&#25321;&#24615;&#25552;&#20379;&#24314;&#35758;&#30340;&#38656;&#27714;&#65292;&#19968;&#20010;&#25361;&#25112;&#23601;&#26469;&#33258;&#20110;&#24213;&#23618;&#20154;&#24037;&#26234;&#33021;&#31574;&#30053;&#30340;&#19981;&#20339;&#34920;&#29616;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#39034;&#24207;&#20915;&#31574;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#32771;&#34385;&#20102;&#20154;&#31867;&#30340;&#20381;&#20174;&#31243;&#24230;&#65288;&#21363;&#20154;&#31867;&#36981;&#24490;/&#25298;&#32477;&#26426;&#22120;&#24314;&#35758;&#30340;&#27010;&#29575;&#65289;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#25512;&#36831;&#36873;&#39033;&#65292;&#20351;&#24471;&#26426;&#22120;&#22312;&#26368;&#21512;&#36866;&#30340;&#26102;&#20505;&#21487;&#20197;&#26242;&#26102;&#19981;&#25552;&#20379;&#24314;&#35758;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#20197;&#23398;&#20064;&#26368;&#20339;&#30340;&#24314;&#35758;&#31574;&#30053;&#65292;&#24182;&#20165;&#22312;&#20851;&#38190;&#26102;&#21051;&#25552;&#20379;&#24314;&#35758;&#12290;&#19982;&#38382;&#39064;&#19981;&#21487;&#30693;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#19987;&#38376;&#21270;&#23398;&#20064;&#31639;&#27861;&#19981;&#20165;&#20855;&#26377;&#26356;&#22909;&#30340;&#29702;&#35770;&#25910;&#25947;&#24615;&#33021;&#65292;&#32780;&#19988;&#22312;&#23454;&#35777;&#24615;&#33021;&#19978;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;
As artificial intelligence (AI) systems play an increasingly prominent role in human decision-making, challenges surface in the realm of human-AI interactions. One challenge arises from the suboptimal AI policies due to the inadequate consideration of humans disregarding AI recommendations, as well as the need for AI to provide advice selectively when it is most pertinent. This paper presents a sequential decision-making model that (i) takes into account the human's adherence level (the probability that the human follows/rejects machine advice) and (ii) incorporates a defer option so that the machine can temporarily refrain from making advice. We provide learning algorithms that learn the optimal advice policy and make advice only at critical time stamps. Compared to problem-agnostic reinforcement learning algorithms, our specialized learning algorithms not only enjoy better theoretical convergence properties but also show strong empirical performance.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Causal Inference with Attention (CInA)&#30340;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#22240;&#26524;&#25512;&#26029;&#21644;&#27880;&#24847;&#21147;&#30340;&#23545;&#20598;&#20851;&#31995;&#65292;&#22312;&#22797;&#26434;&#20219;&#21153;&#20013;&#23454;&#29616;&#20102;&#38646;&#26679;&#26412;&#30340;&#22240;&#26524;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2310.00809</link><description>&lt;p&gt;
&#25351;&#21521;&#22240;&#26524;&#22522;&#30784;&#27169;&#22411;: &#22240;&#26524;&#25512;&#26029;&#19982;&#27880;&#24847;&#21147;&#30340;&#23545;&#20598;&#20851;&#31995;
&lt;/p&gt;
&lt;p&gt;
Towards Causal Foundation Model: on Duality between Causal Inference and Attention. (arXiv:2310.00809v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00809
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Causal Inference with Attention (CInA)&#30340;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#22240;&#26524;&#25512;&#26029;&#21644;&#27880;&#24847;&#21147;&#30340;&#23545;&#20598;&#20851;&#31995;&#65292;&#22312;&#22797;&#26434;&#20219;&#21153;&#20013;&#23454;&#29616;&#20102;&#38646;&#26679;&#26412;&#30340;&#22240;&#26524;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22240;&#26524;&#25512;&#26029;&#21644;&#27880;&#24847;&#21147;&#20043;&#38388;&#30340;&#23545;&#20598;&#36830;&#25509;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Causal Inference with Attention (CInA)&#30340;&#29702;&#35770;&#19978;&#23436;&#22791;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22810;&#20010;&#26080;&#26631;&#31614;&#25968;&#25454;&#38598;&#36827;&#34892;&#33258;&#30417;&#30563;&#22240;&#26524;&#23398;&#20064;&#65292;&#24182;&#22312;&#26032;&#25968;&#25454;&#30340;&#26410;&#35265;&#20219;&#21153;&#19978;&#23454;&#29616;&#38646;&#26679;&#26412;&#22240;&#26524;&#25512;&#26029;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22797;&#26434;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Foundation models have brought changes to the landscape of machine learning, demonstrating sparks of human-level intelligence across a diverse array of tasks. However, a gap persists in complex tasks such as causal inference, primarily due to challenges associated with intricate reasoning steps and high numerical precision requirements. In this work, we take a first step towards building causally-aware foundation models for complex tasks. We propose a novel, theoretically sound method called Causal Inference with Attention (CInA), which utilizes multiple unlabeled datasets to perform self-supervised causal learning, and subsequently enables zero-shot causal inference on unseen tasks with new data. This is based on our theoretical results that demonstrate the primal-dual connection between optimal covariate balancing and self-attention, facilitating zero-shot causal inference through the final layer of a trained transformer-type architecture. We demonstrate empirically that our approach
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35299;&#20915;&#20102;&#20915;&#26007;&#23545;&#27604;&#20013;&#30340; Copeland &#33719;&#32988;&#32773;&#35782;&#21035;&#38382;&#39064;&#65292;&#21033;&#29992;&#19977;&#20803;&#21453;&#39304;&#35299;&#20915;&#20102;&#20256;&#32479;&#20915;&#26007;&#23545;&#27604;&#38382;&#39064;&#20013;&#26410;&#34987;&#20805;&#20998;&#30740;&#31350;&#30340;&#21464;&#20307;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#19979;&#30028;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861; POCOWISTA&#65292;&#35813;&#31639;&#27861;&#20960;&#20046;&#36798;&#21040;&#20102;&#19979;&#30028;&#65292;&#23637;&#29616;&#20986;&#24456;&#22909;&#30340;&#23454;&#35777;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.00750</link><description>&lt;p&gt;
&#29992;&#20110;&#20915;&#26007;&#23545;&#27604;&#20013;&#30340; Copeland &#33719;&#32988;&#32773;&#30340;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Identifying Copeland Winners in Dueling Bandits with Indifferences. (arXiv:2310.00750v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00750
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#20915;&#26007;&#23545;&#27604;&#20013;&#30340; Copeland &#33719;&#32988;&#32773;&#35782;&#21035;&#38382;&#39064;&#65292;&#21033;&#29992;&#19977;&#20803;&#21453;&#39304;&#35299;&#20915;&#20102;&#20256;&#32479;&#20915;&#26007;&#23545;&#27604;&#38382;&#39064;&#20013;&#26410;&#34987;&#20805;&#20998;&#30740;&#31350;&#30340;&#21464;&#20307;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#19979;&#30028;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861; POCOWISTA&#65292;&#35813;&#31639;&#27861;&#20960;&#20046;&#36798;&#21040;&#20102;&#19979;&#30028;&#65292;&#23637;&#29616;&#20986;&#24456;&#22909;&#30340;&#23454;&#35777;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#19977;&#20803;&#21453;&#39304;&#26469;&#35782;&#21035;&#20915;&#26007;&#23545;&#27604;&#38382;&#39064;&#20013;&#30340; Copeland &#33719;&#32988;&#32773;&#12290;&#36825;&#26159;&#20256;&#32479;&#20915;&#26007;&#23545;&#27604;&#38382;&#39064;&#30340;&#19968;&#20010;&#26410;&#34987;&#20805;&#20998;&#30740;&#31350;&#20294;&#22312;&#23454;&#38469;&#20013;&#26377;&#24847;&#20041;&#30340;&#21464;&#20307;&#65292;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#38500;&#20102;&#22312;&#20004;&#20010;&#36873;&#39033;&#20043;&#38388;&#26377;&#26126;&#30830;&#30340;&#20559;&#22909;&#20043;&#22806;&#65292;&#25105;&#20204;&#36824;&#21487;&#20197;&#35266;&#23519;&#21040;&#22240;&#20026;&#28448;&#19981;&#20851;&#24515;&#32780;&#24418;&#25104;&#30340;&#21453;&#39304;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#20219;&#20309;&#23398;&#20064;&#31639;&#27861;&#22312;&#22266;&#23450;&#38169;&#35823;&#27010;&#29575;&#19979;&#25214;&#21040; Copeland &#33719;&#32988;&#32773;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; POCOWISTA &#30340;&#31639;&#27861;&#65292;&#20854;&#26679;&#26412;&#22797;&#26434;&#24230;&#20960;&#20046;&#19982;&#36825;&#20010;&#19979;&#30028;&#30456;&#21305;&#37197;&#65292;&#24182;&#19988;&#22312;&#20256;&#32479;&#20915;&#26007;&#23545;&#27604;&#38382;&#39064;&#20013;&#23637;&#29616;&#20102;&#20986;&#33394;&#30340;&#23454;&#35777;&#24615;&#33021;&#12290;&#23545;&#20110;&#20559;&#22909;&#27010;&#29575;&#28385;&#36275;&#29305;&#23450;&#31867;&#22411;&#30340;&#38543;&#26426;&#20256;&#36882;&#24615;&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#25913;&#36827;&#21518;&#30340;&#31934;&#28860;&#29256;&#26412;&#65292;&#20855;&#26377;&#25913;&#36827;&#30340;&#26368;&#22351;&#24773;&#20917;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the task of identifying the Copeland winner(s) in a dueling bandits problem with ternary feedback. This is an underexplored but practically relevant variant of the conventional dueling bandits problem, in which, in addition to strict preference between two arms, one may observe feedback in the form of an indifference. We provide a lower bound on the sample complexity for any learning algorithm finding the Copeland winner(s) with a fixed error probability. Moreover, we propose POCOWISTA, an algorithm with a sample complexity that almost matches this lower bound, and which shows excellent empirical performance, even for the conventional dueling bandits problem. For the case where the preference probabilities satisfy a specific type of stochastic transitivity, we provide a refined version with an improved worst case sample complexity.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#32034;&#20102;&#20809;&#35889;&#31070;&#32463;&#32593;&#32476;&#65288;SNN&#65289;&#30340;&#20851;&#38190;&#29702;&#35770;&#26041;&#38754;&#65292;&#21253;&#25324;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#20809;&#35889;&#20960;&#20309;&#20449;&#24687;&#30340;&#26435;&#34913;&#21644;SNN&#20248;&#21270;&#36335;&#24452;&#30340;&#29702;&#35770;&#25506;&#32034;&#12290;</title><link>http://arxiv.org/abs/2310.00729</link><description>&lt;p&gt;
&#20809;&#35889;&#31070;&#32463;&#32593;&#32476;&#65306;&#36924;&#36817;&#29702;&#35770;&#21644;&#20248;&#21270;&#36335;&#24452;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Spectral Neural Networks: Approximation Theory and Optimization Landscape. (arXiv:2310.00729v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00729
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#32034;&#20102;&#20809;&#35889;&#31070;&#32463;&#32593;&#32476;&#65288;SNN&#65289;&#30340;&#20851;&#38190;&#29702;&#35770;&#26041;&#38754;&#65292;&#21253;&#25324;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#20809;&#35889;&#20960;&#20309;&#20449;&#24687;&#30340;&#26435;&#34913;&#21644;SNN&#20248;&#21270;&#36335;&#24452;&#30340;&#29702;&#35770;&#25506;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26377;&#35768;&#22810;&#22522;&#20110;&#20174;&#25968;&#25454;&#20013;&#25552;&#21462;&#20809;&#35889;&#20960;&#20309;&#20449;&#24687;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#36825;&#20123;&#26041;&#27861;&#30340;&#23454;&#29616;&#24448;&#24448;&#20381;&#36182;&#20110;&#20256;&#32479;&#30340;&#29305;&#24449;&#27714;&#35299;&#22120;&#65292;&#22312;&#23454;&#38469;&#30340;&#22312;&#32447;&#22823;&#25968;&#25454;&#22330;&#26223;&#20013;&#23384;&#22312;&#19968;&#20123;&#38480;&#21046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#30740;&#31350;&#20154;&#21592;&#25552;&#20986;&#20102;&#19981;&#21516;&#30340;&#31574;&#30053;&#26469;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#20256;&#32479;&#29305;&#24449;&#27714;&#35299;&#22120;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#20854;&#20013;&#19968;&#31181;&#26041;&#27861;&#34987;&#31216;&#20026;&#20809;&#35889;&#31070;&#32463;&#32593;&#32476;&#65288;SNN&#65289;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;SNN&#30340;&#20851;&#38190;&#29702;&#35770;&#26041;&#38754;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23545;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#20809;&#35889;&#20960;&#20309;&#20449;&#24687;&#30340;&#31070;&#32463;&#20803;&#25968;&#37327;&#21644;&#37327;&#20043;&#38388;&#30340;&#26435;&#34913;&#25552;&#20986;&#20102;&#23450;&#37327;&#27934;&#23519;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#23545;SNN&#30446;&#26631;&#30340;&#20248;&#21270;&#36335;&#24452;&#36827;&#34892;&#20102;&#29702;&#35770;&#25506;&#32034;&#65292;&#20197;&#25581;&#31034;SNN&#30340;&#35757;&#32451;&#21160;&#24577;&#12290;&#19982;&#20856;&#22411;&#30340;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#21160;&#24577;&#25910;&#25947;&#21040;&#20840;&#23616;&#35299;&#30340;&#30740;&#31350;&#19981;&#21516;&#65292;SNN&#21576;&#29616;&#20102;&#26576;&#31181;&#31243;&#24230;&#19978;&#30340;&#20445;&#23432;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is a large variety of machine learning methodologies that are based on the extraction of spectral geometric information from data. However, the implementations of many of these methods often depend on traditional eigensolvers, which present limitations when applied in practical online big data scenarios. To address some of these challenges, researchers have proposed different strategies for training neural networks as alternatives to traditional eigensolvers, with one such approach known as Spectral Neural Network (SNN). In this paper, we investigate key theoretical aspects of SNN. First, we present quantitative insights into the tradeoff between the number of neurons and the amount of spectral geometric information a neural network learns. Second, we initiate a theoretical exploration of the optimization landscape of SNN's objective to shed light on the training dynamics of SNN. Unlike typical studies of convergence to global solutions of NN training dynamics, SNN presents an ad
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26694;&#26550;GraPhyR&#65292;&#29992;&#20110;&#35299;&#20915;&#30005;&#21147;&#31995;&#32479;&#30340;&#21160;&#24577;&#37325;&#26500;&#65288;DyR&#65289;&#38382;&#39064;&#12290;&#35813;&#26694;&#26550;&#23558;&#36816;&#33829;&#21644;&#36830;&#25509;&#32422;&#26463;&#30452;&#25509;&#34701;&#20837;GNN&#26694;&#26550;&#20013;&#65292;&#24182;&#36827;&#34892;&#31471;&#21040;&#31471;&#30340;&#35757;&#32451;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#20248;&#21270;DyR&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2310.00728</link><description>&lt;p&gt;
&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#30005;&#21147;&#31995;&#32479;&#30340;&#21160;&#24577;&#37325;&#26500;
&lt;/p&gt;
&lt;p&gt;
Physics-Informed Graph Neural Network for Dynamic Reconfiguration of Power Systems. (arXiv:2310.00728v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00728
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26694;&#26550;GraPhyR&#65292;&#29992;&#20110;&#35299;&#20915;&#30005;&#21147;&#31995;&#32479;&#30340;&#21160;&#24577;&#37325;&#26500;&#65288;DyR&#65289;&#38382;&#39064;&#12290;&#35813;&#26694;&#26550;&#23558;&#36816;&#33829;&#21644;&#36830;&#25509;&#32422;&#26463;&#30452;&#25509;&#34701;&#20837;GNN&#26694;&#26550;&#20013;&#65292;&#24182;&#36827;&#34892;&#31471;&#21040;&#31471;&#30340;&#35757;&#32451;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#20248;&#21270;DyR&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#20445;&#25345;&#21487;&#38752;&#30340;&#30005;&#32593;&#65292;&#25105;&#20204;&#38656;&#35201;&#24555;&#36895;&#30340;&#20915;&#31574;&#31639;&#27861;&#26469;&#35299;&#20915;&#21160;&#24577;&#37325;&#26500;&#65288;DyR&#65289;&#31561;&#22797;&#26434;&#38382;&#39064;&#12290;DyR&#23454;&#26102;&#20248;&#21270;&#37197;&#30005;&#32593;&#24320;&#20851;&#35774;&#32622;&#65292;&#20197;&#26368;&#23567;&#21270;&#30005;&#32593;&#25439;&#32791;&#65292;&#24182;&#20998;&#27966;&#36164;&#28304;&#20197;&#28385;&#36275;&#21487;&#29992;&#21457;&#30005;&#37327;&#30340;&#36127;&#36733;&#38656;&#27714;&#12290;DyR&#26159;&#19968;&#20010;&#28151;&#21512;&#25972;&#25968;&#38382;&#39064;&#65292;&#23545;&#20110;&#22823;&#35268;&#27169;&#30005;&#32593;&#21644;&#24555;&#36895;&#26102;&#38388;&#23610;&#24230;&#26469;&#35828;&#65292;&#21487;&#33021;&#35745;&#31639;&#38590;&#20197;&#35299;&#20915;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;GraPhyR&#65292;&#19968;&#31181;&#19987;&#20026;DyR&#32780;&#35774;&#35745;&#30340;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26694;&#26550;&#12290;&#25105;&#20204;&#30452;&#25509;&#23558;&#22522;&#26412;&#30340;&#36816;&#33829;&#21644;&#36830;&#25509;&#32422;&#26463;&#34701;&#20837;&#21040;GNN&#26694;&#26550;&#20013;&#65292;&#24182;&#36827;&#34892;&#31471;&#21040;&#31471;&#30340;&#35757;&#32451;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;GraPhyR&#33021;&#22815;&#23398;&#20064;&#20248;&#21270;DyR&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
To maintain a reliable grid we need fast decision-making algorithms for complex problems like Dynamic Reconfiguration (DyR). DyR optimizes distribution grid switch settings in real-time to minimize grid losses and dispatches resources to supply loads with available generation. DyR is a mixed-integer problem and can be computationally intractable to solve for large grids and at fast timescales. We propose GraPhyR, a Physics-Informed Graph Neural Network (GNNs) framework tailored for DyR. We incorporate essential operational and connectivity constraints directly within the GNN framework and train it end-to-end. Our results show that GraPhyR is able to learn to optimize the DyR task.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20219;&#21153;&#25552;&#31034;&#30340;&#26041;&#27861;&#65292;&#22312;&#21464;&#21387;&#22120;&#27169;&#22411;&#20013;&#25913;&#21892;&#20102;&#38271;&#24230;&#27867;&#21270;&#33021;&#21147;&#12290;&#36890;&#36807;&#21516;&#26102;&#35757;&#32451;&#27169;&#22411;&#22788;&#29702;&#31616;&#21333;&#20294;&#30456;&#20851;&#30340;&#36741;&#21161;&#20219;&#21153;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#27169;&#22411;&#22312;&#38271;&#24207;&#21015;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.00726</link><description>&lt;p&gt;
&#36890;&#36807;&#20219;&#21153;&#25552;&#31034;&#22312;&#21464;&#21387;&#22120;&#20013;&#25913;&#21892;&#38271;&#24230;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Improving Length-Generalization in Transformers via Task Hinting. (arXiv:2310.00726v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00726
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20219;&#21153;&#25552;&#31034;&#30340;&#26041;&#27861;&#65292;&#22312;&#21464;&#21387;&#22120;&#27169;&#22411;&#20013;&#25913;&#21892;&#20102;&#38271;&#24230;&#27867;&#21270;&#33021;&#21147;&#12290;&#36890;&#36807;&#21516;&#26102;&#35757;&#32451;&#27169;&#22411;&#22788;&#29702;&#31616;&#21333;&#20294;&#30456;&#20851;&#30340;&#36741;&#21161;&#20219;&#21153;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#27169;&#22411;&#22312;&#38271;&#24207;&#21015;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#35266;&#23519;&#21040;&#65292;&#23545;&#20110;&#26576;&#20123;&#31867;&#22411;&#30340;&#25512;&#29702;&#21644;&#31639;&#26415;&#20219;&#21153;&#65292;&#21464;&#21387;&#22120;&#22312;&#38271;&#24230;&#27867;&#21270;&#26041;&#38754;&#23384;&#22312;&#38382;&#39064;&#12290;&#29305;&#21035;&#26159;&#65292;&#22312;&#20219;&#21153;&#65288;&#20363;&#22914;&#21152;&#27861;&#65289;&#30340;&#35757;&#32451;&#20013;&#65292;&#24403;&#24212;&#29992;&#20110;&#30456;&#21516;&#38382;&#39064;&#30340;&#26356;&#38271;&#23454;&#20363;&#26102;&#65292;&#21464;&#21387;&#22120;&#27169;&#22411;&#30340;&#24615;&#33021;&#20250;&#24613;&#21095;&#19979;&#38477;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20219;&#21153;&#25552;&#31034;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#38271;&#24230;&#27867;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#24605;&#24819;&#26159;&#65292;&#22312;&#35757;&#32451;&#27169;&#22411;&#22788;&#29702;&#29305;&#23450;&#20219;&#21153;&#30340;&#25968;&#25454;&#26102;&#65292;&#21516;&#26102;&#35757;&#32451;&#27169;&#22411;&#22788;&#29702;&#19968;&#20010;&#26356;&#31616;&#21333;&#20294;&#30456;&#20851;&#30340;&#36741;&#21161;&#20219;&#21153;&#12290;&#25105;&#20204;&#20197;&#32463;&#20856;&#30340;&#25490;&#24207;&#38382;&#39064;&#20026;&#20363;&#26469;&#35780;&#20272;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#22810;&#20219;&#21153;&#35757;&#32451;&#26694;&#26550;&#65292;&#24182;&#23637;&#31034;&#20102;&#20219;&#21153;&#25552;&#31034;&#22312;&#25913;&#21892;&#38271;&#24230;&#27867;&#21270;&#33021;&#21147;&#26041;&#38754;&#30340;&#26174;&#33879;&#25928;&#26524;&#12290;&#23545;&#20110;&#25490;&#24207;&#38382;&#39064;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#35757;&#32451;&#27169;&#22411;&#22788;&#29702;&#38271;&#24230;&#26368;&#22810;&#20026;20&#30340;&#24207;&#21015;&#25968;&#25454;&#65292;&#24182;&#23558;&#22312;&#38271;&#24230;&#20026;100&#30340;&#24207;&#21015;&#19978;&#30340;&#27979;&#35797;&#20934;&#30830;&#29575;&#25552;&#39640;&#33267;
&lt;/p&gt;
&lt;p&gt;
It has been observed in recent years that transformers have problems with length generalization for certain types of reasoning and arithmetic tasks. In particular, the performance of a transformer model trained on tasks (say addition) up to a certain length (e.g., 5 digit numbers) drops sharply when applied to longer instances of the same problem. This work proposes an approach based on task hinting towards addressing length generalization. Our key idea is that while training the model on task-specific data, it is helpful to simultaneously train the model to solve a simpler but related auxiliary task as well.  We study the classical sorting problem as a canonical example to evaluate our approach. We design a multitask training framework and show that task hinting significantly improve length generalization. For sorting we show that it is possible to train models on data consisting of sequences having length at most $20$, and improve the test accuracy on sequences of length $100$ from l
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#20013;&#30340;&#22122;&#22768;&#20960;&#20309;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#29702;&#35770;&#30740;&#31350;&#65292;&#21457;&#29616;&#22122;&#22768;&#19982;&#25439;&#22833;&#20989;&#25968;&#30340;&#23616;&#37096;&#20960;&#20309;&#29305;&#24449;&#26377;&#21033;&#30340;&#19968;&#33268;&#24615;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;SGD&#22312;&#36867;&#33073;&#23574;&#38160;&#26497;&#23567;&#20540;&#26102;&#19982;GD&#24418;&#25104;&#40092;&#26126;&#23545;&#27604;&#65292;&#36867;&#33073;&#26041;&#21521;&#22312;&#24179;&#22374;&#26041;&#21521;&#19978;&#26377;&#26174;&#33879;&#20998;&#37327;&#12290;</title><link>http://arxiv.org/abs/2310.00692</link><description>&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#22122;&#22768;&#20960;&#20309;&#65306;&#23450;&#37327;&#21644;&#20998;&#26512;&#29305;&#24449;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
The Noise Geometry of Stochastic Gradient Descent: A Quantitative and Analytical Characterization. (arXiv:2310.00692v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00692
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#20013;&#30340;&#22122;&#22768;&#20960;&#20309;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#29702;&#35770;&#30740;&#31350;&#65292;&#21457;&#29616;&#22122;&#22768;&#19982;&#25439;&#22833;&#20989;&#25968;&#30340;&#23616;&#37096;&#20960;&#20309;&#29305;&#24449;&#26377;&#21033;&#30340;&#19968;&#33268;&#24615;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;SGD&#22312;&#36867;&#33073;&#23574;&#38160;&#26497;&#23567;&#20540;&#26102;&#19982;GD&#24418;&#25104;&#40092;&#26126;&#23545;&#27604;&#65292;&#36867;&#33073;&#26041;&#21521;&#22312;&#24179;&#22374;&#26041;&#21521;&#19978;&#26377;&#26174;&#33879;&#20998;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#20013;&#30340;&#22122;&#22768;&#19982;&#25439;&#22833;&#20989;&#25968;&#30340;&#23616;&#37096;&#20960;&#20309;&#29305;&#24449;&#26377;&#21033;&#30340;&#19968;&#33268;&#24615;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#36825;&#31181;&#29616;&#35937;&#30340;&#29702;&#35770;&#21644;&#23450;&#37327;&#35299;&#37322;&#20173;&#28982;&#19981;&#36275;&#12290;&#26412;&#25991;&#23545;&#36807;&#21442;&#25968;&#21270;&#32447;&#24615;&#27169;&#22411;&#21644;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#19978;&#36848;&#8220;&#22122;&#22768;&#20960;&#20309;&#8221;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#29702;&#35770;&#30740;&#31350;&#12290;&#25105;&#20204;&#32454;&#33268;&#22320;&#30740;&#31350;&#20102;&#24179;&#22343;&#21644;&#26041;&#21521;&#30340;&#19968;&#33268;&#24615;&#65292;&#29305;&#21035;&#20851;&#27880;&#26679;&#26412;&#22823;&#23567;&#21644;&#36755;&#20837;&#25968;&#25454;&#36864;&#21270;&#23545;&#19968;&#33268;&#24615;&#24378;&#24230;&#30340;&#24433;&#21709;&#12290;&#20316;&#20026;&#29305;&#23450;&#24212;&#29992;&#65292;&#25105;&#20204;&#21033;&#29992;&#22122;&#22768;&#20960;&#20309;&#29305;&#24449;&#30740;&#31350;&#20102;SGD&#22914;&#20309;&#20174;&#23574;&#38160;&#26497;&#23567;&#20540;&#20013;&#36867;&#33073;&#65292;&#21457;&#29616;&#36867;&#33073;&#26041;&#21521;&#22312;&#24179;&#22374;&#26041;&#21521;&#19978;&#26377;&#26174;&#33879;&#20998;&#37327;&#65292;&#36825;&#19982;&#21482;&#22312;&#26368;&#23574;&#38160;&#26041;&#21521;&#36867;&#33073;&#30340;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;GD&#24418;&#25104;&#40092;&#26126;&#23545;&#27604;&#12290;&#20026;&#20102;&#39564;&#35777;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#30340;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Empirical studies have demonstrated that the noise in stochastic gradient descent (SGD) aligns favorably with the local geometry of loss landscape. However, theoretical and quantitative explanations for this phenomenon remain sparse. In this paper, we offer a comprehensive theoretical investigation into the aforementioned {\em noise geometry} for over-parameterized linear (OLMs) models and two-layer neural networks. We scrutinize both average and directional alignments, paying special attention to how factors like sample size and input data degeneracy affect the alignment strength. As a specific application, we leverage our noise geometry characterizations to study how SGD escapes from sharp minima, revealing that the escape direction has significant components along flat directions. This is in stark contrast to GD, which escapes only along the sharpest directions. To substantiate our theoretical findings, both synthetic and real-world experiments are provided.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27700;&#21360;&#30340;&#26694;&#26550;WASA&#65292;&#36890;&#36807;&#20801;&#35768;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#24102;&#26377;&#23884;&#20837;&#28304;&#20449;&#24687;&#30340;&#21512;&#25104;&#25991;&#26412;&#27700;&#21360;&#26469;&#35299;&#20915;&#28304;&#24402;&#23646;&#21644;&#25968;&#25454;&#26469;&#28304;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.00646</link><description>&lt;p&gt;
WASA&#65306;&#22522;&#20110;&#27700;&#21360;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#25968;&#25454;&#30340;&#28304;&#24402;&#23646;
&lt;/p&gt;
&lt;p&gt;
WASA: WAtermark-based Source Attribution for Large Language Model-Generated Data. (arXiv:2310.00646v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00646
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27700;&#21360;&#30340;&#26694;&#26550;WASA&#65292;&#36890;&#36807;&#20801;&#35768;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#24102;&#26377;&#23884;&#20837;&#28304;&#20449;&#24687;&#30340;&#21512;&#25104;&#25991;&#26412;&#27700;&#21360;&#26469;&#35299;&#20915;&#28304;&#24402;&#23646;&#21644;&#25968;&#25454;&#26469;&#28304;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#20986;&#33394;&#24615;&#33021;&#21644;&#20854;&#21830;&#19994;&#21270;&#30340;&#24040;&#22823;&#28508;&#21147;&#24341;&#21457;&#20102;&#23545;&#20854;&#35757;&#32451;&#25968;&#25454;&#30693;&#35782;&#20135;&#26435;&#65288;IP&#65289;&#30340;&#20005;&#37325;&#20851;&#27880;&#12290;&#29305;&#21035;&#26159;&#65292;LLM&#29983;&#25104;&#30340;&#21512;&#25104;&#25991;&#26412;&#21487;&#33021;&#20405;&#29359;&#34987;&#29992;&#20110;&#35757;&#32451;LLM&#30340;&#25968;&#25454;&#30340;&#30693;&#35782;&#20135;&#26435;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#33021;&#22815;&#65288;a&#65289;&#36890;&#36807;&#27700;&#21360;&#35782;&#21035;&#20986;&#23545;LLM&#29983;&#25104;&#30340;&#21512;&#25104;&#25991;&#26412;&#20570;&#20986;&#36129;&#29486;&#30340;&#25968;&#25454;&#25552;&#20379;&#32773;&#65288;&#28304;&#24402;&#23646;&#65289;&#65307;&#20197;&#21450;&#65288;b&#65289;&#39564;&#35777;&#25991;&#26412;&#25968;&#25454;&#26159;&#21542;&#26469;&#33258;&#20110;&#26576;&#20010;&#25968;&#25454;&#25552;&#20379;&#32773;&#23545;LLM&#36827;&#34892;&#20102;&#35757;&#32451;&#65288;&#25968;&#25454;&#26469;&#28304;&#65289;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#27700;&#21360;&#25216;&#26415;&#21487;&#20197;&#35299;&#20915;&#36825;&#20004;&#20010;&#38382;&#39064;&#65292;&#21363;&#36890;&#36807;&#35753;LLM&#29983;&#25104;&#20855;&#26377;&#23884;&#20837;&#28304;&#20449;&#24687;&#30340;&#21512;&#25104;&#25991;&#26412;&#27700;&#21360;&#26469;&#23454;&#29616;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#36825;&#31181;&#27700;&#21360;&#25216;&#26415;&#26694;&#26550;&#30340;&#20851;&#38190;&#29305;&#24615;&#65288;&#20363;&#22914;&#28304;&#24402;&#23646;&#20934;&#30830;&#24615;&#12289;&#25269;&#25239;&#23545;&#25163;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#65289;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#28385;&#36275;&#36825;&#20123;&#35201;&#27714;&#30340;WAtermarking for Source Attribution&#65288;WASA&#65289;&#26694;&#26550;.
&lt;/p&gt;
&lt;p&gt;
The impressive performances of large language models (LLMs) and their immense potential for commercialization have given rise to serious concerns over the intellectual property (IP) of their training data. In particular, the synthetic texts generated by LLMs may infringe the IP of the data being used to train the LLMs. To this end, it is imperative to be able to (a) identify the data provider who contributed to the generation of a synthetic text by an LLM (source attribution) and (b) verify whether the text data from a data provider has been used to train an LLM (data provenance). In this paper, we show that both problems can be solved by watermarking, i.e., by enabling an LLM to generate synthetic texts with embedded watermarks that contain information about their source(s). We identify the key properties of such watermarking frameworks (e.g., source attribution accuracy, robustness against adversaries), and propose a WAtermarking for Source Attribution (WASA) framework that satisfies
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#31163;&#25955;&#36873;&#25321;&#27169;&#22411;&#21644;&#22312;&#32447;&#23398;&#20064;&#21644;&#22810;&#33218;&#36172;&#21338;&#31639;&#27861;&#20043;&#38388;&#24314;&#31435;&#20102;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#20855;&#26377;&#27425;&#32447;&#24615;&#36951;&#25022;&#30028;&#38480;&#30340;&#31639;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#28789;&#27963;&#35843;&#25972;&#27169;&#22411;&#30340;&#26032;&#39062;&#23545;&#25239;&#24615;&#22810;&#33218;&#36172;&#21338;&#31639;&#27861;&#23478;&#26063;&#12290;</title><link>http://arxiv.org/abs/2310.00562</link><description>&lt;p&gt;
&#31163;&#25955;&#36873;&#25321;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
Discrete Choice Multi-Armed Bandits. (arXiv:2310.00562v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00562
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#31163;&#25955;&#36873;&#25321;&#27169;&#22411;&#21644;&#22312;&#32447;&#23398;&#20064;&#21644;&#22810;&#33218;&#36172;&#21338;&#31639;&#27861;&#20043;&#38388;&#24314;&#31435;&#20102;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#20855;&#26377;&#27425;&#32447;&#24615;&#36951;&#25022;&#30028;&#38480;&#30340;&#31639;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#28789;&#27963;&#35843;&#25972;&#27169;&#22411;&#30340;&#26032;&#39062;&#23545;&#25239;&#24615;&#22810;&#33218;&#36172;&#21338;&#31639;&#27861;&#23478;&#26063;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24314;&#31435;&#20102;&#31163;&#25955;&#36873;&#25321;&#27169;&#22411;&#19982;&#22312;&#32447;&#23398;&#20064;&#21644;&#22810;&#33218;&#36172;&#21338;&#31639;&#27861;&#39046;&#22495;&#30340;&#32852;&#31995;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#21487;&#20197;&#24635;&#32467;&#20026;&#20004;&#20010;&#20851;&#38190;&#26041;&#38754;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#31995;&#21015;&#31639;&#27861;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#30028;&#38480;&#65292;&#20854;&#20013;&#21253;&#25324;&#20102;Exp3&#31639;&#27861;&#20316;&#20026;&#19968;&#20010;&#29305;&#20363;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23545;&#25239;&#24615;&#22810;&#33218;&#36172;&#21338;&#31639;&#27861;&#23478;&#26063;&#65292;&#21463;&#21040;wen&#31561;&#20154;&#24341;&#20837;&#30340;&#24191;&#20041;&#23884;&#22871;&#23545;&#25968;&#27169;&#22411;&#30340;&#21551;&#21457;&#12290;&#36825;&#20123;&#31639;&#27861;&#36890;&#36807;&#38381;&#24335;&#37319;&#26679;&#20998;&#24067;&#27010;&#29575;&#65292;&#20026;&#29992;&#25143;&#25552;&#20379;&#20102;&#24191;&#27867;&#35843;&#25972;&#27169;&#22411;&#30340;&#28789;&#27963;&#24615;&#65292;&#24182;&#33021;&#22815;&#39640;&#25928;&#22320;&#23454;&#29616;&#12290;&#20026;&#20102;&#23637;&#31034;&#25105;&#20204;&#31639;&#27861;&#30340;&#23454;&#38469;&#24212;&#29992;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#25968;&#20540;&#23454;&#39564;&#65292;&#37325;&#28857;&#20851;&#27880;&#38543;&#26426;&#36172;&#21338;&#26426;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper establishes a connection between a category of discrete choice models and the realms of online learning and multiarmed bandit algorithms. Our contributions can be summarized in two key aspects. Firstly, we furnish sublinear regret bounds for a comprehensive family of algorithms, encompassing the Exp3 algorithm as a particular case. Secondly, we introduce a novel family of adversarial multiarmed bandit algorithms, drawing inspiration from the generalized nested logit models initially introduced by \citet{wen:2001}. These algorithms offer users the flexibility to fine-tune the model extensively, as they can be implemented efficiently due to their closed-form sampling distribution probabilities. To demonstrate the practical implementation of our algorithms, we present numerical experiments, focusing on the stochastic bandit case.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#40065;&#26834;&#38750;&#21442;&#25968;&#20551;&#35774;&#26816;&#39564;&#26694;&#26550;&#30340;&#26032;&#25351;&#26631;&#65292;&#29992;&#20110;&#34913;&#37327;&#20998;&#31867;&#27169;&#22411;&#20043;&#38388;&#30340;&#30456;&#20284;&#24230;&#65292;&#35813;&#25351;&#26631;&#33021;&#22815;&#36866;&#29992;&#20110;&#20174;&#35757;&#32451;&#27169;&#22411;&#20013;&#27966;&#29983;&#30340;&#20854;&#20182;&#37327;&#12290;</title><link>http://arxiv.org/abs/2310.00541</link><description>&lt;p&gt;
&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#21487;&#21464;&#24615;&#30340;&#40065;&#26834;&#38750;&#21442;&#25968;&#20551;&#35774;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Robust Nonparametric Hypothesis Testing to Understand Variability in Training Neural Networks. (arXiv:2310.00541v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00541
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#40065;&#26834;&#38750;&#21442;&#25968;&#20551;&#35774;&#26816;&#39564;&#26694;&#26550;&#30340;&#26032;&#25351;&#26631;&#65292;&#29992;&#20110;&#34913;&#37327;&#20998;&#31867;&#27169;&#22411;&#20043;&#38388;&#30340;&#30456;&#20284;&#24230;&#65292;&#35813;&#25351;&#26631;&#33021;&#22815;&#36866;&#29992;&#20110;&#20174;&#35757;&#32451;&#27169;&#22411;&#20013;&#27966;&#29983;&#30340;&#20854;&#20182;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#36890;&#24120;&#28041;&#21450;&#38543;&#26426;&#20248;&#21270;&#65292;&#36825;&#24847;&#21619;&#30528;&#27599;&#27425;&#36816;&#34892;&#23558;&#20135;&#29983;&#19981;&#21516;&#30340;&#27169;&#22411;&#12290;&#20960;&#39033;&#30740;&#31350;&#34920;&#26126;&#65292;&#24403;&#27169;&#22411;&#20855;&#26377;&#30456;&#21516;&#30340;&#24615;&#33021;&#26102;&#65292;&#36825;&#31181;&#21487;&#21464;&#24615;&#26159;&#21487;&#20197;&#24573;&#30053;&#30340;&#65292;&#22312;&#20998;&#31867;&#38382;&#39064;&#20013;&#21363;&#27979;&#35797;&#20934;&#30830;&#24230;&#12290;&#28982;&#32780;&#65292;&#20855;&#26377;&#31867;&#20284;&#27979;&#35797;&#20934;&#30830;&#24230;&#30340;&#27169;&#22411;&#21487;&#33021;&#27809;&#26377;&#35745;&#31639;&#30456;&#21516;&#30340;&#20989;&#25968;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32593;&#32476;&#36755;&#20986;&#22312;&#38408;&#20540;&#21270;&#20043;&#21069;&#30340;&#20998;&#31867;&#27169;&#22411;&#20043;&#38388;&#30456;&#20284;&#24230;&#30340;&#26032;&#25351;&#26631;&#12290;&#25105;&#20204;&#30340;&#25351;&#26631;&#22522;&#20110;&#19968;&#20010;&#40065;&#26834;&#30340;&#20551;&#35774;&#26816;&#39564;&#26694;&#26550;&#65292;&#24182;&#21487;&#36866;&#29992;&#20110;&#20174;&#35757;&#32451;&#27169;&#22411;&#20013;&#27966;&#29983;&#30340;&#20854;&#20182;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training a deep neural network (DNN) often involves stochastic optimization, which means each run will produce a different model. Several works suggest this variability is negligible when models have the same performance, which in the case of classification is test accuracy. However, models with similar test accuracy may not be computing the same function. We propose a new measure of closeness between classification models based on the output of the network before thresholding. Our measure is based on a robust hypothesis-testing framework and can be adapted to other quantities derived from trained models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#23558;Thompson&#37319;&#26679;&#19982;&#26368;&#20339;&#20505;&#36873;&#35268;&#21017;&#30456;&#32467;&#21512;&#65292;&#29992;&#20110;&#35299;&#20915;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#35813;&#31574;&#30053;&#22312;&#28176;&#36817;&#24773;&#20917;&#19979;&#26159;&#26368;&#20248;&#30340;&#65292;&#24182;&#22312;&#19968;&#33324;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#36798;&#21040;&#25509;&#36817;&#26368;&#20248;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.00539</link><description>&lt;p&gt;
&#26368;&#20339;&#20505;&#36873;&#35268;&#21017;&#19979;&#30340;Thompson&#25506;&#32034;&#22312;&#26368;&#20339;&#33218;&#35782;&#21035;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Thompson Exploration with Best Challenger Rule in Best Arm Identification. (arXiv:2310.00539v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00539
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#23558;Thompson&#37319;&#26679;&#19982;&#26368;&#20339;&#20505;&#36873;&#35268;&#21017;&#30456;&#32467;&#21512;&#65292;&#29992;&#20110;&#35299;&#20915;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#35813;&#31574;&#30053;&#22312;&#28176;&#36817;&#24773;&#20917;&#19979;&#26159;&#26368;&#20248;&#30340;&#65292;&#24182;&#22312;&#19968;&#33324;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#36798;&#21040;&#25509;&#36817;&#26368;&#20248;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32463;&#20856;&#21333;&#21442;&#25968;&#25351;&#25968;&#27169;&#22411;&#19979;&#65292;&#22266;&#23450;&#32622;&#20449;&#24230;&#19979;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;BAI&#65289;&#38382;&#39064;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#30446;&#21069;&#24050;&#26377;&#24456;&#22810;&#31574;&#30053;&#34987;&#25552;&#20986;&#65292;&#20294;&#22823;&#22810;&#25968;&#38656;&#35201;&#22312;&#27599;&#19968;&#36718;&#35299;&#20915;&#19968;&#20010;&#26368;&#20248;&#21270;&#38382;&#39064;&#21644;/&#25110;&#32773;&#38656;&#35201;&#25506;&#32034;&#19968;&#20010;&#33218;&#33267;&#23569;&#19968;&#23450;&#27425;&#25968;&#65292;&#38500;&#38750;&#26159;&#38024;&#23545;&#39640;&#26031;&#27169;&#22411;&#30340;&#38480;&#21046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#23558;Thompson&#37319;&#26679;&#19982;&#19968;&#20010;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#26041;&#27861;&#8212;&#8212;&#26368;&#20339;&#20505;&#36873;&#35268;&#21017;&#30456;&#32467;&#21512;&#12290;&#34429;&#28982;Thompson&#37319;&#26679;&#26368;&#21021;&#34987;&#32771;&#34385;&#29992;&#20110;&#26368;&#22823;&#21270;&#32047;&#31215;&#22870;&#21169;&#65292;&#20294;&#25105;&#20204;&#35777;&#26126;&#23427;&#20063;&#21487;&#20197;&#33258;&#28982;&#22320;&#29992;&#20110;&#22312;BAI&#20013;&#25506;&#32034;&#33218;&#32780;&#19981;&#24378;&#36843;&#26368;&#22823;&#21270;&#22870;&#21169;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31574;&#30053;&#22312;&#20219;&#24847;&#20004;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#19978;&#26159;&#28176;&#36817;&#26368;&#20248;&#30340;&#65292;&#24182;&#19988;&#22312;&#19968;&#33324;&#30340;$K$&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#19978;&#65288;$K\geq 3$&#65289;&#36798;&#21040;&#25509;&#36817;&#26368;&#20248;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#31574;&#30053;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#34920;&#29616;&#20986;&#20102;&#31454;&#20105;&#24615;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the fixed-confidence best arm identification (BAI) problem in the bandit framework in the canonical single-parameter exponential models. For this problem, many policies have been proposed, but most of them require solving an optimization problem at every round and/or are forced to explore an arm at least a certain number of times except those restricted to the Gaussian model. To address these limitations, we propose a novel policy that combines Thompson sampling with a computationally efficient approach known as the best challenger rule. While Thompson sampling was originally considered for maximizing the cumulative reward, we demonstrate that it can be used to naturally explore arms in BAI without forcing it. We show that our policy is asymptotically optimal for any two-armed bandit problems and achieves near optimality for general $K$-armed bandit problems for $K\geq 3$. Nevertheless, in numerical experiments, our policy shows competitive performance compared to as
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#35777;&#26126;&#20102;&#22312;infoGAN&#20013;&#65292;&#36776;&#21035;&#22120;&#21644;&#29983;&#25104;&#22120;&#30340;&#26679;&#26412;&#25968;&#37327;&#36235;&#21521;&#26080;&#31351;&#26102;&#65292;&#20004;&#20010;&#30446;&#26631;&#20989;&#25968;&#21464;&#24471;&#31561;&#20215;&#12290;</title><link>http://arxiv.org/abs/2310.00443</link><description>&lt;p&gt;
infoGAN&#30340;&#20004;&#23618;&#32593;&#32476;&#30340;&#30446;&#26631;&#20989;&#25968;&#31561;&#24335;&#23646;&#24615;
&lt;/p&gt;
&lt;p&gt;
The objective function equality property of infoGAN for two-layer network. (arXiv:2310.00443v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00443
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#35777;&#26126;&#20102;&#22312;infoGAN&#20013;&#65292;&#36776;&#21035;&#22120;&#21644;&#29983;&#25104;&#22120;&#30340;&#26679;&#26412;&#25968;&#37327;&#36235;&#21521;&#26080;&#31351;&#26102;&#65292;&#20004;&#20010;&#30446;&#26631;&#20989;&#25968;&#21464;&#24471;&#31561;&#20215;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#26368;&#22823;&#21270;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;(infoGAN)&#21487;&#20197;&#29702;&#35299;&#20026;&#28041;&#21450;&#20004;&#20010;&#32593;&#32476;(&#36776;&#21035;&#22120;&#21644;&#29983;&#25104;&#22120;)&#30340;&#26497;&#23567;&#21270;&#26497;&#22823;&#38382;&#39064;&#65292;&#20854;&#20013;&#21253;&#21547;&#20102;&#20114;&#20449;&#24687;&#20989;&#25968;&#12290;infoGAN&#21253;&#25324;&#22810;&#31181;&#32452;&#20214;&#65292;&#21253;&#25324;&#28508;&#22312;&#21464;&#37327;&#12289;&#20114;&#20449;&#24687;&#21644;&#30446;&#26631;&#20989;&#25968;&#12290;&#26412;&#30740;&#31350;&#35777;&#26126;&#65292;&#22312;&#36776;&#21035;&#22120;&#21644;&#29983;&#25104;&#22120;&#26679;&#26412;&#25968;&#37327;&#36235;&#21521;&#26080;&#31351;&#26102;&#65292;infoGAN&#20013;&#30340;&#20004;&#20010;&#30446;&#26631;&#20989;&#25968;&#21464;&#24471;&#31561;&#20215;&#12290;&#36825;&#31181;&#31561;&#20215;&#20851;&#31995;&#26159;&#36890;&#36807;&#32771;&#34385;&#30446;&#26631;&#20989;&#25968;&#30340;&#32463;&#39564;&#29256;&#26412;&#21644;&#24635;&#20307;&#29256;&#26412;&#20043;&#38388;&#30340;&#24046;&#24322;&#26469;&#24314;&#31435;&#30340;&#12290;&#36825;&#20010;&#24046;&#24322;&#30340;&#30028;&#38480;&#30001;&#36776;&#21035;&#22120;&#21644;&#29983;&#25104;&#22120;&#20989;&#25968;&#31867;&#30340;Rademacher&#22797;&#26434;&#24230;&#20915;&#23450;&#12290;&#27492;&#22806;&#65292;&#20351;&#29992;&#20855;&#26377;Lipschitz&#21644;&#38750;&#36882;&#20943;&#28608;&#27963;&#20989;&#25968;&#30340;&#20004;&#23618;&#32593;&#32476;&#26469;&#39564;&#35777;&#36825;&#20010;&#31561;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Information Maximizing Generative Adversarial Network (infoGAN) can be understood as a minimax problem involving two networks: discriminators and generators with mutual information functions. The infoGAN incorporates various components, including latent variables, mutual information, and objective function. This research demonstrates that the two objective functions in infoGAN become equivalent as the discriminator and generator sample size approaches infinity. This equivalence is established by considering the disparity between the empirical and population versions of the objective function. The bound on this difference is determined by the Rademacher complexity of the discriminator and generator function class. Furthermore, the utilization of a two-layer network for both the discriminator and generator, featuring Lipschitz and non-decreasing activation functions, validates this equality
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#32858;&#31867;&#22810;&#20219;&#21153;&#21387;&#32553;&#24863;&#30693;&#30340;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#36991;&#20813;&#37325;&#22797;&#35745;&#31639;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#24615;&#33021;&#19978;&#26174;&#33879;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#65292;&#36895;&#24230;&#21487;&#25552;&#21319;&#19978;&#21315;&#20493;&#65292;&#20869;&#23384;&#25928;&#29575;&#26356;&#39640;&#19968;&#20010;&#25968;&#37327;&#32423;&#12290;</title><link>http://arxiv.org/abs/2310.00420</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#32858;&#31867;&#22810;&#20219;&#21153;&#21387;&#32553;&#24863;&#30693;&#30340;&#39640;&#25928;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Efficient Algorithm for Clustered Multi-Task Compressive Sensing. (arXiv:2310.00420v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00420
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#32858;&#31867;&#22810;&#20219;&#21153;&#21387;&#32553;&#24863;&#30693;&#30340;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#36991;&#20813;&#37325;&#22797;&#35745;&#31639;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#24615;&#33021;&#19978;&#26174;&#33879;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#65292;&#36895;&#24230;&#21487;&#25552;&#21319;&#19978;&#21315;&#20493;&#65292;&#20869;&#23384;&#25928;&#29575;&#26356;&#39640;&#19968;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32858;&#31867;&#22810;&#20219;&#21153;&#21387;&#32553;&#24863;&#30693;&#65292;&#36825;&#26159;&#19968;&#31181;&#36890;&#36807;&#25214;&#21040;&#21033;&#29992;&#20849;&#20139;&#20449;&#24687;&#30456;&#20114;&#25913;&#36827;&#20449;&#21495;&#37325;&#24314;&#30340;&#20219;&#21153;&#38598;&#32676;&#26469;&#35299;&#20915;&#22810;&#20010;&#21387;&#32553;&#24863;&#30693;&#20219;&#21153;&#30340;&#23618;&#27425;&#27169;&#22411;&#12290;&#29616;&#26377;&#30340;&#25512;&#26029;&#31639;&#27861;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#35745;&#31639;&#20195;&#20215;&#24456;&#22823;&#65292;&#24182;&#19988;&#26080;&#27861;&#24456;&#22909;&#22320;&#25193;&#23637;&#12290;&#20027;&#35201;&#29942;&#39048;&#26159;&#28041;&#21450;&#21040;&#22810;&#20010;&#22823;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#37325;&#22797;&#30697;&#38453;&#27714;&#36870;&#21644;&#23545;&#25968;&#34892;&#21015;&#24335;&#35745;&#31639;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#36991;&#20813;&#26174;&#24335;&#35745;&#31639;&#36825;&#20123;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#26174;&#33879;&#21152;&#36895;&#20102;&#27169;&#22411;&#25512;&#26029;&#36807;&#31243;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#32467;&#21512;&#20102;&#33945;&#29305;&#21345;&#32599;&#37319;&#26679;&#21644;&#36845;&#20195;&#32447;&#24615;&#27714;&#35299;&#22120;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;&#29616;&#26377;&#22522;&#32447;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#24555;&#19978;&#25968;&#21315;&#20493;&#65292;&#19988;&#20869;&#23384;&#25928;&#29575;&#26356;&#39640;&#19968;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper considers clustered multi-task compressive sensing, a hierarchical model that solves multiple compressive sensing tasks by finding clusters of tasks that leverage shared information to mutually improve signal reconstruction. The existing inference algorithm for this model is computationally expensive and does not scale well in high dimensions. The main bottleneck involves repeated matrix inversion and log-determinant computation for multiple large covariance matrices. We propose a new algorithm that substantially accelerates model inference by avoiding the need to explicitly compute these covariance matrices. Our approach combines Monte Carlo sampling with iterative linear solvers. Our experiments reveal that compared to the existing baseline, our algorithm can be up to thousands of times faster and an order of magnitude more memory-efficient.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#28857;&#23545;&#28857;&#22810;&#26234;&#33021;&#20307;&#32593;&#32476;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27604;&#20363;&#31215;&#20998;&#65288;PI&#65289;&#25511;&#21046;&#31574;&#30053;&#30340;&#39044;&#26465;&#20214;PI&#20849;&#35782;&#31639;&#27861;&#65292;&#20445;&#35777;&#20102;&#20854;&#22312;&#21463;&#38480;&#24378;&#20984;&#20989;&#25968;&#19979;&#30340;&#32447;&#24615;&#25910;&#25947;&#24615;&#65292;&#26080;&#38656;&#20010;&#20307;&#23616;&#37096;&#20195;&#20215;&#20989;&#25968;&#30340;&#20984;&#24615;&#65292;&#24182;&#19988;&#36890;&#36807;&#24341;&#20837;&#23616;&#37096;&#39044;&#26465;&#20214;&#36827;&#19968;&#27493;&#21152;&#36895;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.00419</link><description>&lt;p&gt;
&#21463;&#38480;&#24378;&#20984;&#24615;&#19979;&#30340;&#39044;&#26465;&#20214;PI&#20849;&#35782;&#31639;&#27861;&#30340;&#32447;&#24615;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Linear Convergence of Pre-Conditioned PI Consensus Algorithm under Restricted Strong Convexity. (arXiv:2310.00419v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00419
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#28857;&#23545;&#28857;&#22810;&#26234;&#33021;&#20307;&#32593;&#32476;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27604;&#20363;&#31215;&#20998;&#65288;PI&#65289;&#25511;&#21046;&#31574;&#30053;&#30340;&#39044;&#26465;&#20214;PI&#20849;&#35782;&#31639;&#27861;&#65292;&#20445;&#35777;&#20102;&#20854;&#22312;&#21463;&#38480;&#24378;&#20984;&#20989;&#25968;&#19979;&#30340;&#32447;&#24615;&#25910;&#25947;&#24615;&#65292;&#26080;&#38656;&#20010;&#20307;&#23616;&#37096;&#20195;&#20215;&#20989;&#25968;&#30340;&#20984;&#24615;&#65292;&#24182;&#19988;&#36890;&#36807;&#24341;&#20837;&#23616;&#37096;&#39044;&#26465;&#20214;&#36827;&#19968;&#27493;&#21152;&#36895;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#28857;&#23545;&#28857;&#22810;&#26234;&#33021;&#20307;&#32593;&#32476;&#20013;&#35299;&#20915;&#20998;&#24067;&#24335;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#32593;&#32476;&#34987;&#20551;&#23450;&#20026;&#21516;&#27493;&#21644;&#36830;&#36890;&#30340;&#12290;&#37319;&#29992;&#27604;&#20363;&#31215;&#20998;&#65288;PI&#65289;&#25511;&#21046;&#31574;&#30053;&#65292;&#24320;&#21457;&#20102;&#22810;&#31181;&#20855;&#26377;&#22266;&#23450;&#27493;&#38271;&#30340;&#31639;&#27861;&#65292;&#20854;&#20013;&#26368;&#26089;&#30340;&#26159;PI&#20849;&#35782;&#31639;&#27861;&#12290;&#21033;&#29992;&#26446;&#38597;&#26222;&#35834;&#22827;&#29702;&#35770;&#65292;&#25105;&#20204;&#39318;&#27425;&#20445;&#35777;&#20102;&#20855;&#26377;&#36895;&#29575;&#21305;&#37197;&#31163;&#25955;&#21270;&#30340;&#21463;&#38480;&#24378;&#20984;&#20989;&#25968;&#30340;PI&#20849;&#35782;&#31639;&#27861;&#30340;&#25351;&#25968;&#25910;&#25947;&#24615;&#65292;&#32780;&#19981;&#38656;&#35201;&#20010;&#20307;&#23616;&#37096;&#20195;&#20215;&#20989;&#25968;&#30340;&#20984;&#24615;&#12290;&#20026;&#20102;&#21152;&#36895;PI&#20849;&#35782;&#31639;&#27861;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#23616;&#37096;&#39044;&#26465;&#20214;&#30340;&#24418;&#24335;&#65292;&#21363;&#24120;&#25968;&#27491;&#23450;&#30697;&#38453;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#39564;&#35777;&#20854;&#30456;&#27604;&#20110;&#31361;&#20986;&#30340;&#20998;&#24067;&#24335;&#20984;&#20248;&#21270;&#31639;&#27861;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper considers solving distributed convex optimization problems in peer-to-peer multi-agent networks. The network is assumed to be synchronous and connected. By using the proportional-integral (PI) control strategy, various algorithms with fixed stepsize have been developed. The earliest among them is the PI consensus algorithm. Using Lyapunov theory, we guarantee exponential convergence of the PI consensus algorithm for restricted strongly convex functions with rate-matching discretization, without requiring convexity of individual local cost functions, for the first time. In order to accelerate the PI consensus algorithm, we incorporate local pre-conditioning in the form of constant positive definite matrices and numerically validate its efficiency compared to the prominent distributed convex optimization algorithms. Unlike classical pre-conditioning, where only the gradients are multiplied by a pre-conditioner, the proposed pre-conditioning modifies both the gradients and the 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20445;&#24207;GFlowNets&#65288;OP-GFNs&#65289;&#65292;&#36890;&#36807;&#23398;&#20064;&#22870;&#21169;&#20989;&#25968;&#19982;&#20505;&#36873;&#32773;&#30340;&#25490;&#24207;&#30456;&#19968;&#33268;&#30340;&#27010;&#29575;&#36827;&#34892;&#37319;&#26679;&#65292;&#35299;&#20915;&#20102;&#20351;&#29992;&#39044;&#23450;&#20041;&#26631;&#37327;&#22870;&#21169;&#30340;&#23616;&#38480;&#24615;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#35777;&#26126;&#35757;&#32451;&#36807;&#31243;&#31232;&#30095;&#22870;&#21169;&#26223;&#35266;&#30340;&#29702;&#35770;&#25903;&#25345;&#12290;</title><link>http://arxiv.org/abs/2310.00386</link><description>&lt;p&gt;
&#20445;&#24207;GFlowNets
&lt;/p&gt;
&lt;p&gt;
Order-Preserving GFlowNets. (arXiv:2310.00386v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00386
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20445;&#24207;GFlowNets&#65288;OP-GFNs&#65289;&#65292;&#36890;&#36807;&#23398;&#20064;&#22870;&#21169;&#20989;&#25968;&#19982;&#20505;&#36873;&#32773;&#30340;&#25490;&#24207;&#30456;&#19968;&#33268;&#30340;&#27010;&#29575;&#36827;&#34892;&#37319;&#26679;&#65292;&#35299;&#20915;&#20102;&#20351;&#29992;&#39044;&#23450;&#20041;&#26631;&#37327;&#22870;&#21169;&#30340;&#23616;&#38480;&#24615;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#35777;&#26126;&#35757;&#32451;&#36807;&#31243;&#31232;&#30095;&#22870;&#21169;&#26223;&#35266;&#30340;&#29702;&#35770;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27969;&#32593;&#32476;&#65288;GFlowNets&#65289;&#34987;&#24341;&#20837;&#20316;&#20026;&#19968;&#31181;&#26681;&#25454;&#32473;&#23450;&#22870;&#21169;&#27010;&#29575;&#37319;&#26679;&#22810;&#26679;&#21270;&#30340;&#20505;&#36873;&#38598;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;GFlowNets&#21482;&#33021;&#19982;&#39044;&#23450;&#20041;&#30340;&#26631;&#37327;&#22870;&#21169;&#19968;&#36215;&#20351;&#29992;&#65292;&#22312;&#22810;&#30446;&#26631;&#20248;&#21270;&#65288;MOO&#65289;&#20219;&#21153;&#20013;&#65292;&#36825;&#21487;&#33021;&#26159;&#35745;&#31639;&#26114;&#36149;&#30340;&#25110;&#32773;&#30452;&#25509;&#19981;&#21487;&#35775;&#38382;&#30340;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#20248;&#20808;&#35782;&#21035;&#39640;&#22870;&#21169;&#20505;&#36873;&#32773;&#65292;&#20256;&#32479;&#20570;&#27861;&#26159;&#23558;&#22870;&#21169;&#25552;&#39640;&#21040;&#26356;&#39640;&#30340;&#25351;&#25968;&#65292;&#32780;&#36825;&#20010;&#26368;&#20248;&#36873;&#25321;&#22312;&#19981;&#21516;&#29615;&#22659;&#19979;&#21487;&#33021;&#20250;&#26377;&#25152;&#19981;&#21516;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20445;&#24207;GFlowNets&#65288;OP-GFNs&#65289;&#65292;&#23427;&#20204;&#20197;&#19982;&#25552;&#20379;&#30340;&#65288;&#37096;&#20998;&#65289;&#20505;&#36873;&#32773;&#25490;&#24207;&#19968;&#33268;&#30340;&#23398;&#20064;&#22870;&#21169;&#20989;&#25968;&#30340;&#27010;&#29575;&#36827;&#34892;&#37319;&#26679;&#65292;&#20174;&#32780;&#28040;&#38500;&#20102;&#23545;&#22870;&#21169;&#20989;&#25968;&#30340;&#26174;&#24335;&#34920;&#36798;&#30340;&#38656;&#27714;&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;OP-GFNs&#30340;&#35757;&#32451;&#36807;&#31243;&#36880;&#28176;&#31232;&#30095;&#20102;&#23398;&#20064;&#21040;&#30340;&#22870;&#21169;&#26223;&#35266;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative Flow Networks (GFlowNets) have been introduced as a method to sample a diverse set of candidates with probabilities proportional to a given reward. However, GFlowNets can only be used with a predefined scalar reward, which can be either computationally expensive or not directly accessible, in the case of multi-objective optimization (MOO) tasks for example. Moreover, to prioritize identifying high-reward candidates, the conventional practice is to raise the reward to a higher exponent, the optimal choice of which may vary across different environments. To address these issues, we propose Order-Preserving GFlowNets (OP-GFNs), which sample with probabilities in proportion to a learned reward function that is consistent with a provided (partial) order on the candidates, thus eliminating the need for an explicit formulation of the reward function. We theoretically prove that the training process of OP-GFNs gradually sparsifies the learned reward landscape in single-objective max
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#20351;&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#36827;&#34892;&#30005;&#21147;&#21457;&#30005;&#21378;&#24322;&#24120;&#26816;&#27979;&#65292;&#32467;&#26524;&#34920;&#26126;GANs&#22312;&#36825;&#19968;&#39046;&#22495;&#20855;&#26377;&#26377;&#25928;&#24615;&#65292;&#24182;&#33021;&#24110;&#21161;&#35782;&#21035;&#29123;&#26009;&#28040;&#32791;&#27169;&#24335;&#20013;&#30340;&#24322;&#24120;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2310.00335</link><description>&lt;p&gt;
&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#36827;&#34892;&#30005;&#21147;&#21457;&#30005;&#21378;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Anomaly Detection in Power Generation Plants with Generative Adversarial Networks. (arXiv:2310.00335v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00335
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#20351;&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#36827;&#34892;&#30005;&#21147;&#21457;&#30005;&#21378;&#24322;&#24120;&#26816;&#27979;&#65292;&#32467;&#26524;&#34920;&#26126;GANs&#22312;&#36825;&#19968;&#39046;&#22495;&#20855;&#26377;&#26377;&#25928;&#24615;&#65292;&#24182;&#33021;&#24110;&#21161;&#35782;&#21035;&#29123;&#26009;&#28040;&#32791;&#27169;&#24335;&#20013;&#30340;&#24322;&#24120;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24322;&#24120;&#26816;&#27979;&#26159;&#19968;&#39033;&#20851;&#38190;&#20219;&#21153;&#65292;&#28041;&#21450;&#23545;&#19982;&#39044;&#23450;&#20041;&#27169;&#24335;&#20559;&#31163;&#30340;&#25968;&#25454;&#28857;&#30340;&#35782;&#21035;&#65292;&#23545;&#20110;&#27450;&#35784;&#26816;&#27979;&#21644;&#30456;&#20851;&#27963;&#21160;&#38750;&#24120;&#26377;&#29992;&#12290;&#21508;&#31181;&#25216;&#26415;&#34987;&#29992;&#20110;&#24322;&#24120;&#26816;&#27979;&#65292;&#20294;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#20973;&#20511;&#20854;&#36776;&#21035;&#22797;&#26434;&#25968;&#25454;&#27169;&#24335;&#30340;&#33021;&#21147;&#65292;&#38750;&#24120;&#36866;&#21512;&#36825;&#39033;&#20219;&#21153;&#12290;&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#22312;&#30005;&#21147;&#21457;&#30005;&#21378;&#20013;&#20351;&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#12290;&#26412;&#27425;&#30740;&#31350;&#20351;&#29992;&#30340;&#25968;&#25454;&#38598;&#21253;&#25324;&#26469;&#33258;&#30005;&#20449;&#20844;&#21496;&#36816;&#33829;&#30340;&#21457;&#30005;&#21378;&#30340;&#29123;&#26009;&#28040;&#32791;&#35760;&#24405;&#12290;&#26368;&#21021;&#65292;&#36825;&#20123;&#25968;&#25454;&#26159;&#22522;&#20110;&#20844;&#21496;&#22522;&#31449;&#19978;&#30340;&#21457;&#30005;&#26426;&#32452;&#29123;&#26009;&#28040;&#32791;&#27169;&#24335;&#20013;&#35266;&#23519;&#21040;&#30340;&#19981;&#35268;&#21017;&#24615;&#32780;&#37319;&#38598;&#30340;&#12290;&#25968;&#25454;&#38598;&#26681;&#25454;&#29305;&#23450;&#21464;&#37327;&#34987;&#20998;&#20026;&#27491;&#24120;&#21644;&#24322;&#24120;&#25968;&#25454;&#28857;&#65292;&#20854;&#20013;64.88%&#34987;&#20998;&#31867;&#20026;&#27491;&#24120;&#65292;35.12%&#34987;&#20998;&#31867;&#20026;&#24322;&#24120;&#12290;&#29305;&#24449;&#37325;&#35201;&#24615;&#30340;&#20998;&#26512;&#32467;&#26524;&#34920;&#26126;&#20102;GANs&#22312;&#30005;&#21147;&#21457;&#30005;&#21378;&#24322;&#24120;&#26816;&#27979;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Anomaly detection is a critical task that involves the identification of data points that deviate from a predefined pattern, useful for fraud detection and related activities. Various techniques are employed for anomaly detection, but recent research indicates that deep learning methods, with their ability to discern intricate data patterns, are well-suited for this task. This study explores the use of Generative Adversarial Networks (GANs) for anomaly detection in power generation plants. The dataset used in this investigation comprises fuel consumption records obtained from power generation plants operated by a telecommunications company. The data was initially collected in response to observed irregularities in the fuel consumption patterns of the generating sets situated at the company's base stations. The dataset was divided into anomalous and normal data points based on specific variables, with 64.88% classified as normal and 35.12% as anomalous. An analysis of feature importance
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#25554;&#20540;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#38543;&#26426;&#31639;&#27861;&#65292;&#22312;&#32473;&#23450;&#30340;&#25968;&#25454;&#38598;&#21644;&#20004;&#20010;&#31867;&#30340;&#24773;&#20917;&#19979;&#65292;&#33021;&#22815;&#20197;&#24456;&#39640;&#30340;&#27010;&#29575;&#26500;&#24314;&#19968;&#20010;&#25554;&#20540;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#36825;&#20123;&#32467;&#26524;&#19982;&#35757;&#32451;&#25968;&#25454;&#35268;&#27169;&#26080;&#20851;&#12290;</title><link>http://arxiv.org/abs/2310.00327</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#30340;&#35760;&#24518;&#21270;&#65306;&#36229;&#36234;&#26368;&#22351;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
Memorization with neural nets: going beyond the worst case. (arXiv:2310.00327v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00327
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#25554;&#20540;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#38543;&#26426;&#31639;&#27861;&#65292;&#22312;&#32473;&#23450;&#30340;&#25968;&#25454;&#38598;&#21644;&#20004;&#20010;&#31867;&#30340;&#24773;&#20917;&#19979;&#65292;&#33021;&#22815;&#20197;&#24456;&#39640;&#30340;&#27010;&#29575;&#26500;&#24314;&#19968;&#20010;&#25554;&#20540;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#36825;&#20123;&#32467;&#26524;&#19982;&#35757;&#32451;&#25968;&#25454;&#35268;&#27169;&#26080;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#36341;&#20013;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36890;&#24120;&#33021;&#22815;&#36731;&#26494;&#22320;&#25554;&#20540;&#20854;&#35757;&#32451;&#25968;&#25454;&#12290;&#20026;&#20102;&#29702;&#35299;&#36825;&#19968;&#29616;&#35937;&#65292;&#35768;&#22810;&#30740;&#31350;&#37117;&#26088;&#22312;&#37327;&#21270;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#35760;&#24518;&#33021;&#21147;&#65306;&#21363;&#22312;&#20219;&#24847;&#25918;&#32622;&#36825;&#20123;&#28857;&#24182;&#20219;&#24847;&#20998;&#37197;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#65292;&#26550;&#26500;&#33021;&#22815;&#25554;&#20540;&#30340;&#26368;&#22823;&#28857;&#25968;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#23454;&#38469;&#25968;&#25454;&#65292;&#20154;&#20204;&#30452;&#35273;&#22320;&#26399;&#26395;&#23384;&#22312;&#19968;&#31181;&#33391;&#24615;&#32467;&#26500;&#65292;&#20351;&#24471;&#25554;&#20540;&#22312;&#27604;&#35760;&#24518;&#33021;&#21147;&#24314;&#35758;&#30340;&#36739;&#23567;&#32593;&#32476;&#23610;&#23544;&#19978;&#24050;&#32463;&#21457;&#29983;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#37319;&#29992;&#23454;&#20363;&#29305;&#23450;&#30340;&#35266;&#28857;&#26469;&#30740;&#31350;&#25554;&#20540;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#38543;&#26426;&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#32473;&#23450;&#19968;&#20010;&#22266;&#23450;&#30340;&#26377;&#38480;&#25968;&#25454;&#38598;&#21644;&#20004;&#20010;&#31867;&#30340;&#24773;&#20917;&#19979;&#65292;&#20197;&#24456;&#39640;&#30340;&#27010;&#29575;&#26500;&#24314;&#20986;&#19968;&#20010;&#25554;&#20540;&#19977;&#23618;&#31070;&#32463;&#32593;&#32476;&#12290;&#25152;&#38656;&#30340;&#21442;&#25968;&#25968;&#37327;&#19982;&#36825;&#20004;&#20010;&#31867;&#30340;&#20960;&#20309;&#29305;&#24615;&#21450;&#20854;&#30456;&#20114;&#25490;&#21015;&#26377;&#20851;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19982;&#35757;&#32451;&#25968;&#25454;&#35268;&#27169;&#26080;&#20851;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
In practice, deep neural networks are often able to easily interpolate their training data. To understand this phenomenon, many works have aimed to quantify the memorization capacity of a neural network architecture: the largest number of points such that the architecture can interpolate any placement of these points with any assignment of labels. For real-world data, however, one intuitively expects the presence of a benign structure so that interpolation already occurs at a smaller network size than suggested by memorization capacity. In this paper, we investigate interpolation by adopting an instance-specific viewpoint. We introduce a simple randomized algorithm that, given a fixed finite dataset with two classes, with high probability constructs an interpolating three-layer neural network in polynomial time. The required number of parameters is linked to geometric properties of the two classes and their mutual arrangement. As a result, we obtain guarantees that are independent of t
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#26368;&#22823;&#38388;&#38548;&#20998;&#31867;&#22120;&#22312;&#38750;&#39640;&#26031;&#29305;&#24449;&#26144;&#23556;&#21644;&#39640;&#32500;&#28176;&#36817;&#26465;&#20214;&#19979;&#30340;&#26222;&#36866;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.00176</link><description>&lt;p&gt;
&#26368;&#22823;&#38388;&#38548;&#20998;&#31867;&#22120;&#30340;&#26222;&#36866;&#24615;
&lt;/p&gt;
&lt;p&gt;
Universality of max-margin classifiers. (arXiv:2310.00176v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00176
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#26368;&#22823;&#38388;&#38548;&#20998;&#31867;&#22120;&#22312;&#38750;&#39640;&#26031;&#29305;&#24449;&#26144;&#23556;&#21644;&#39640;&#32500;&#28176;&#36817;&#26465;&#20214;&#19979;&#30340;&#26222;&#36866;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#22823;&#38388;&#38548;&#20108;&#20803;&#20998;&#31867;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#22522;&#30784;&#30340;&#31639;&#27861;&#20043;&#19968;&#65292;&#28982;&#32780;&#23545;&#20110;&#38750;&#39640;&#26031;&#29305;&#24449;&#30340;&#26144;&#23556;&#20989;&#25968;&#21644;&#39640;&#32500;&#28176;&#36817;&#26465;&#20214;&#19979;&#30340;&#35823;&#20998;&#31867;&#38169;&#35823;&#30340;&#20316;&#29992;&#20173;&#28982;&#30693;&#20043;&#29978;&#23569;&#12290;&#25105;&#20204;&#32771;&#34385;&#35266;&#27979;&#21040;&#20108;&#20803;&#26631;&#31614; $y_i$&#65292;&#36890;&#36807;&#38543;&#26426;&#26144;&#23556;&#20989;&#25968; ${\boldsymbol \phi}:\mathbb{R}^d \to\mathbb{R}^p$&#65292;&#23558; $d$ &#32500;&#21327;&#21464;&#37327; ${\boldsymbol z}_i$ &#26144;&#23556;&#21040; $p$ &#32500;&#31354;&#38388;&#65292;&#25110;&#32773;&#23545;&#20110;&#38750;&#39640;&#26031;&#29420;&#31435;&#30340; $p$ &#32500;&#29305;&#24449;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#20010;&#22522;&#26412;&#38382;&#39064;&#65306;$(i)$ &#25968;&#25454;&#22312;&#36807;&#21442;&#25968;&#21270;&#27604;&#29575; $p/n$ &#19979;&#20309;&#26102;&#21464;&#20026;&#32447;&#24615;&#21487;&#20998;&#65311;$(ii)$ &#26368;&#22823;&#38388;&#38548;&#20998;&#31867;&#22120;&#30340;&#27867;&#21270;&#35823;&#24046;&#26159;&#22810;&#23569;&#65311;&#22312;&#39640;&#32500;&#26465;&#20214;&#19979;&#65292;&#29305;&#24449;&#25968; $p$&#12289;&#26679;&#26412;&#25968; $n$ &#21644;&#36755;&#20837;&#32500;&#24230; $d$&#65288;&#38750;&#32447;&#24615;&#29305;&#24449;&#21270;&#35774;&#32622;&#19979;&#65289;&#21457;&#25955;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#26222;&#36866;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Maximum margin binary classification is one of the most fundamental algorithms in machine learning, yet the role of featurization maps and the high-dimensional asymptotics of the misclassification error for non-Gaussian features are still poorly understood. We consider settings in which we observe binary labels $y_i$ and either $d$-dimensional covariates ${\boldsymbol z}_i$ that are mapped to a $p$-dimension space via a randomized featurization map ${\boldsymbol \phi}:\mathbb{R}^d \to\mathbb{R}^p$, or $p$-dimensional features of non-Gaussian independent entries. In this context, we study two fundamental questions: $(i)$ At what overparametrization ratio $p/n$ do the data become linearly separable? $(ii)$ What is the generalization error of the max-margin classifier?  Working in the high-dimensional regime in which the number of features $p$, the number of samples $n$ and the input dimension $d$ (in the nonlinear featurization setting) diverge, with ratios of order one, we prove a unive
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#26080;&#31351;&#23485;&#24230;&#26497;&#38480;&#19979;&#30340;&#34892;&#20026;&#65292;&#24182;&#19982;&#26680;&#26041;&#27861;&#24314;&#31435;&#20102;&#32852;&#31995;&#12290;&#34429;&#28982;&#22312;&#21512;&#25104;&#26550;&#26500;&#20013;&#23637;&#31034;&#20102;&#19968;&#20123;&#20248;&#21183;&#65292;&#22914;&#26356;&#24555;&#30340;&#20248;&#21270;&#21644;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#20294;&#23454;&#38469;&#30456;&#20851;&#30340;&#26550;&#26500;&#38656;&#35201;&#27604;&#28145;&#24230;&#22823;&#24456;&#22810;&#20493;&#30340;&#23485;&#24230;&#25165;&#33021;&#23454;&#29616;&#36825;&#20123;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2310.00137</link><description>&lt;p&gt;
&#20851;&#20110;&#36807;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#29702;&#35770;&#19982;&#23454;&#36341;&#30340;&#33073;&#33410;
&lt;/p&gt;
&lt;p&gt;
On the Disconnect Between Theory and Practice of Overparametrized Neural Networks. (arXiv:2310.00137v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00137
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#26080;&#31351;&#23485;&#24230;&#26497;&#38480;&#19979;&#30340;&#34892;&#20026;&#65292;&#24182;&#19982;&#26680;&#26041;&#27861;&#24314;&#31435;&#20102;&#32852;&#31995;&#12290;&#34429;&#28982;&#22312;&#21512;&#25104;&#26550;&#26500;&#20013;&#23637;&#31034;&#20102;&#19968;&#20123;&#20248;&#21183;&#65292;&#22914;&#26356;&#24555;&#30340;&#20248;&#21270;&#21644;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#20294;&#23454;&#38469;&#30456;&#20851;&#30340;&#26550;&#26500;&#38656;&#35201;&#27604;&#28145;&#24230;&#22823;&#24456;&#22810;&#20493;&#30340;&#23485;&#24230;&#25165;&#33021;&#23454;&#29616;&#36825;&#20123;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#65288;NNs&#65289;&#30340;&#26080;&#31351;&#23485;&#24230;&#26497;&#38480;&#20316;&#20026;&#20998;&#26512;&#22823;&#35268;&#27169;&#12289;&#36807;&#21442;&#25968;&#21270;&#32593;&#32476;&#34892;&#20026;&#30340;&#29702;&#35770;&#26694;&#26550;&#24050;&#32463;&#24341;&#36215;&#20102;&#37325;&#35201;&#20851;&#27880;&#12290;&#36890;&#36807;&#25509;&#36817;&#26080;&#38480;&#23485;&#24230;&#65292;NNs&#21487;&#20197;&#26377;&#25928;&#22320;&#25910;&#25947;&#21040;&#19968;&#20010;&#20855;&#26377;&#30001;&#31070;&#32463;&#20999;&#32447;&#26680;(NTK)&#29305;&#24449;&#21270;&#30340;&#32447;&#24615;&#27169;&#22411;&#12290;&#36825;&#24314;&#31435;&#20102;NNs&#21644;&#26680;&#26041;&#27861;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#21518;&#32773;&#26159;&#34987;&#20805;&#20998;&#29702;&#35299;&#30340;&#12290;&#22522;&#20110;&#36825;&#31181;&#32852;&#31995;&#65292;&#24050;&#32463;&#20551;&#35774;&#24182;&#22312;&#21512;&#25104;&#26550;&#26500;&#20013;&#20174;&#29702;&#35770;&#19978;&#21644;&#31639;&#27861;&#19978;&#39564;&#35777;&#20102;&#19968;&#20123;&#20248;&#21183;&#12290;&#36825;&#20123;&#20248;&#21183;&#21253;&#25324;&#26356;&#24555;&#30340;&#20248;&#21270;&#12289;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#25913;&#36827;&#30340;&#25345;&#32493;&#23398;&#20064;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#37327;&#21270;&#21521;&#26680;&#24515;&#39046;&#22495;&#25910;&#25947;&#36895;&#24230;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#21033;&#29992;&#36825;&#20123;&#20248;&#21183;&#38656;&#35201;&#27604;&#28145;&#24230;&#22823;&#20960;&#20010;&#25968;&#37327;&#32423;&#30340;&#26550;&#26500;&#12290;&#36825;&#20010;&#20551;&#35774;&#24341;&#21457;&#20102;&#23545;&#23454;&#38469;&#30456;&#20851;&#26550;&#26500;&#26159;&#21542;&#34920;&#29616;&#22914;&#39044;&#27979;&#30340;&#25285;&#24551;&#12290;
&lt;/p&gt;
&lt;p&gt;
The infinite-width limit of neural networks (NNs) has garnered significant attention as a theoretical framework for analyzing the behavior of large-scale, overparametrized networks. By approaching infinite width, NNs effectively converge to a linear model with features characterized by the neural tangent kernel (NTK). This establishes a connection between NNs and kernel methods, the latter of which are well understood. Based on this link, theoretical benefits and algorithmic improvements have been hypothesized and empirically demonstrated in synthetic architectures. These advantages include faster optimization, reliable uncertainty quantification and improved continual learning. However, current results quantifying the rate of convergence to the kernel regime suggest that exploiting these benefits requires architectures that are orders of magnitude wider than they are deep. This assumption raises concerns that practically relevant architectures do not exhibit behavior as predicted via 
&lt;/p&gt;</description></item><item><title>GUESS is a new sampling strategy for global fit that combines predictive posterior uncertainty and higher-order Taylor expansion values to reduce the number of samples needed for accurate surrogate modeling. - GUESS &#26159;&#19968;&#31181;&#26032;&#30340;&#20840;&#23616;&#25311;&#21512;&#37319;&#26679;&#31574;&#30053;&#65292;&#32467;&#21512;&#20102;&#39044;&#27979;&#21518;&#39564;&#19981;&#30830;&#23450;&#24615;&#21644;&#39640;&#38454;&#27888;&#21202;&#23637;&#24320;&#20540;&#65292;&#21487;&#20197;&#20943;&#23569;&#20934;&#30830;&#30340;&#20195;&#29702;&#27169;&#22411;&#25152;&#38656;&#30340;&#26679;&#26412;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2310.00110</link><description>&lt;p&gt;
Gradient and Uncertainty Enhanced Sequential Sampling for Global Fit. (arXiv:2310.00110v1 [stat.ML]) - &#20840;&#23616;&#25311;&#21512;&#20013;&#30340;&#26799;&#24230;&#21644;&#19981;&#30830;&#23450;&#24615;&#22686;&#24378;&#30340;&#39034;&#24207;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Gradient and Uncertainty Enhanced Sequential Sampling for Global Fit. (arXiv:2310.00110v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00110
&lt;/p&gt;
&lt;p&gt;
GUESS is a new sampling strategy for global fit that combines predictive posterior uncertainty and higher-order Taylor expansion values to reduce the number of samples needed for accurate surrogate modeling. - GUESS &#26159;&#19968;&#31181;&#26032;&#30340;&#20840;&#23616;&#25311;&#21512;&#37319;&#26679;&#31574;&#30053;&#65292;&#32467;&#21512;&#20102;&#39044;&#27979;&#21518;&#39564;&#19981;&#30830;&#23450;&#24615;&#21644;&#39640;&#38454;&#27888;&#21202;&#23637;&#24320;&#20540;&#65292;&#21487;&#20197;&#20943;&#23569;&#20934;&#30830;&#30340;&#20195;&#29702;&#27169;&#22411;&#25152;&#38656;&#30340;&#26679;&#26412;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#20195;&#29702;&#27169;&#22411;&#24050;&#25104;&#20026;&#29616;&#20195;&#24037;&#31243;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#29992;&#20197;&#21462;&#20195;&#26114;&#36149;&#30340;&#35745;&#31639;&#26426;&#27169;&#25311;&#12290;&#21019;&#24314;&#20195;&#29702;&#27169;&#22411;&#25152;&#20351;&#29992;&#30340;&#25968;&#25454;&#23545;&#20110;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#24448;&#24448;&#21463;&#21040;&#25104;&#26412;&#21644;&#26102;&#38388;&#38480;&#21046;&#30340;&#38480;&#21046;&#12290;&#33258;&#36866;&#24212;&#37319;&#26679;&#31574;&#30053;&#24050;&#34987;&#35777;&#26126;&#21487;&#20197;&#20943;&#23569;&#21019;&#24314;&#20934;&#30830;&#27169;&#22411;&#25152;&#38656;&#30340;&#26679;&#26412;&#25968;&#37327;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20840;&#23616;&#25311;&#21512;&#37319;&#26679;&#31574;&#30053;&#65292;&#31216;&#20026;Gradient and Uncertainty Enhanced Sequential Sampling (GUESS)&#12290;&#37319;&#29992;&#20004;&#20010;&#26415;&#35821;&#30340;&#25910;&#36141;&#21151;&#33021;&#65306;&#29992;&#20110;&#25506;&#32034;&#26410;&#35265;&#21306;&#22495;&#30340;&#20195;&#29702;&#27169;&#22411;&#30340;&#39044;&#27979;&#21518;&#39564;&#19981;&#30830;&#23450;&#24615;&#21450;&#29992;&#20110;&#24320;&#21457;&#30340;&#20108;&#38454;&#21450;&#26356;&#39640;&#38454;&#27888;&#21202;&#23637;&#24320;&#20540;&#30340;&#21152;&#26435;&#36924;&#36817;&#20540;&#12290;&#23613;&#31649;&#36804;&#20170;&#20026;&#27490;&#24050;&#25552;&#20986;&#20102;&#21508;&#31181;&#37319;&#26679;&#31574;&#30053;&#65292;&#20294;&#36873;&#25321;&#21512;&#36866;&#30340;&#26041;&#27861;&#24182;&#19981;&#23481;&#26131;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#25552;&#20986;&#30340;&#31574;&#30053;&#19982;&#22522;&#20110;26&#20010;&#19981;&#21516;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;9&#31181;&#33258;&#36866;&#24212;&#37319;&#26679;&#31574;&#30053;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Surrogate models based on machine learning methods have become an important part of modern engineering to replace costly computer simulations. The data used for creating a surrogate model are essential for the model accuracy and often restricted due to cost and time constraints. Adaptive sampling strategies have been shown to reduce the number of samples needed to create an accurate model. This paper proposes a new sampling strategy for global fit called Gradient and Uncertainty Enhanced Sequential Sampling (GUESS). The acquisition function uses two terms: the predictive posterior uncertainty of the surrogate model for exploration of unseen regions and a weighted approximation of the second and higher-order Taylor expansion values for exploitation. Although various sampling strategies have been proposed so far, the selection of a suitable method is not trivial. Therefore, we compared our proposed strategy to 9 adaptive sampling strategies for global surrogate modeling, based on 26 diff
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32852;&#37030;&#23398;&#20064;&#21644;&#24046;&#20998;&#38544;&#31169;&#30340;&#31471;&#21040;&#31471;&#35821;&#38899;&#35782;&#21035;&#26041;&#27861;&#65292;&#25506;&#32034;&#20102;&#22823;&#22411;Transformer&#27169;&#22411;&#30340;&#19981;&#21516;&#26041;&#38754;&#65292;&#24182;&#24314;&#31435;&#20102;&#22522;&#32447;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.00098</link><description>&lt;p&gt;
&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#30340;&#32852;&#37030;&#23398;&#20064;&#36827;&#34892;&#31471;&#21040;&#31471;&#35821;&#38899;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Federated Learning with Differential Privacy for End-to-End Speech Recognition. (arXiv:2310.00098v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00098
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32852;&#37030;&#23398;&#20064;&#21644;&#24046;&#20998;&#38544;&#31169;&#30340;&#31471;&#21040;&#31471;&#35821;&#38899;&#35782;&#21035;&#26041;&#27861;&#65292;&#25506;&#32034;&#20102;&#22823;&#22411;Transformer&#27169;&#22411;&#30340;&#19981;&#21516;&#26041;&#38754;&#65292;&#24182;&#24314;&#31435;&#20102;&#22522;&#32447;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26159;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20294;&#22312;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#39046;&#22495;&#20165;&#38480;&#20110;&#21021;&#27493;&#25506;&#32034;&#12290;&#27492;&#22806;&#65292;&#32852;&#37030;&#23398;&#20064;&#19981;&#33021;&#26412;&#36136;&#19978;&#20445;&#35777;&#29992;&#25143;&#38544;&#31169;&#65292;&#24182;&#38656;&#35201;&#24046;&#20998;&#38544;&#31169;&#26469;&#25552;&#20379;&#31283;&#20581;&#30340;&#38544;&#31169;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#36824;&#19981;&#28165;&#26970;&#22312;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#20013;&#24212;&#29992;&#24046;&#20998;&#38544;&#31169;&#30340;&#20808;&#21069;&#24037;&#20316;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#20026;&#32852;&#37030;&#23398;&#20064;&#25552;&#20379;&#24046;&#20998;&#38544;&#31169;&#30340;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#22522;&#20934;&#65292;&#24182;&#24314;&#31435;&#31532;&#19968;&#20010;&#22522;&#32447;&#26469;&#22635;&#34917;&#36825;&#19968;&#30740;&#31350;&#31354;&#30333;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;&#32852;&#37030;&#23398;&#20064;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#30740;&#31350;&#65292;&#25506;&#32034;&#20102;&#26368;&#26032;&#30340;&#22823;&#22411;&#31471;&#21040;&#31471;Transformer&#27169;&#22411;&#30340;&#19981;&#21516;&#26041;&#38754;&#65306;&#26550;&#26500;&#35774;&#35745;&#65292;&#31181;&#23376;&#27169;&#22411;&#65292;&#25968;&#25454;&#24322;&#36136;&#24615;&#65292;&#39046;&#22495;&#36716;&#31227;&#65292;&#20197;&#21450;cohort&#22823;&#23567;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#21512;&#29702;&#30340;&#20013;&#22830;&#32858;&#21512;&#25968;&#37327;&#65292;&#25105;&#20204;&#33021;&#22815;&#35757;&#32451;&#20986;&#21363;&#20351;&#22312;&#24322;&#26500;&#25968;&#25454;&#12289;&#26469;&#33258;&#21478;&#19968;&#20010;&#39046;&#22495;&#30340;&#31181;&#23376;&#27169;&#22411;&#25110;&#26080;&#39044;&#20808;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#25509;&#36817;&#26368;&#20248;&#30340;&#32852;&#37030;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
While federated learning (FL) has recently emerged as a promising approach to train machine learning models, it is limited to only preliminary explorations in the domain of automatic speech recognition (ASR). Moreover, FL does not inherently guarantee user privacy and requires the use of differential privacy (DP) for robust privacy guarantees. However, we are not aware of prior work on applying DP to FL for ASR. In this paper, we aim to bridge this research gap by formulating an ASR benchmark for FL with DP and establishing the first baselines. First, we extend the existing research on FL for ASR by exploring different aspects of recent $\textit{large end-to-end transformer models}$: architecture design, seed models, data heterogeneity, domain shift, and impact of cohort size. With a $\textit{practical}$ number of central aggregations we are able to train $\textbf{FL models}$ that are \textbf{nearly optimal} even with heterogeneous data, a seed model from another domain, or no pre-trai
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31232;&#30095;&#21464;&#20998;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#20013;&#28857;&#20272;&#35745;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#24067;&#26391;&#36816;&#21160;&#20808;&#39564;&#21644;&#29305;&#24449;&#21521;&#37327;&#24341;&#23548;&#21464;&#37327;&#65292;&#25512;&#23548;&#20102;&#39057;&#29575;&#27966;&#21487;&#20449;&#21306;&#38388;&#30340;&#29702;&#35770;&#20445;&#35777;&#21644;&#38480;&#21046;&#65292;&#24182;&#22312;&#36275;&#22815;&#22810;&#30340;&#24341;&#23548;&#21464;&#37327;&#30340;&#24773;&#20917;&#19979;&#31934;&#30830;&#23450;&#20041;&#20102;&#28176;&#36817;&#39057;&#29575;&#27966;&#35206;&#30422;&#65292;&#20174;&#32780;&#25512;&#26029;&#20986;&#36825;&#20010;&#21464;&#20998;&#26041;&#27861;&#30340;&#21487;&#20449;&#21306;&#38388;&#20309;&#26102;&#20445;&#23432;&#65292;&#20309;&#26102;&#36807;&#20110;&#33258;&#20449;/&#35823;&#23548;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#32467;&#26524;&#30340;&#36866;&#29992;&#24615;&#65292;&#24182;&#35752;&#35770;&#20102;&#19982;&#20854;&#20182;&#24120;&#35265;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#30340;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.00097</link><description>&lt;p&gt;
&#31232;&#30095;&#21464;&#20998;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#28857;&#20272;&#35745;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#19982;&#24067;&#26391;&#36816;&#21160;&#20808;&#39564;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Pointwise uncertainty quantification for sparse variational Gaussian process regression with a Brownian motion prior. (arXiv:2310.00097v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00097
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31232;&#30095;&#21464;&#20998;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#20013;&#28857;&#20272;&#35745;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#24067;&#26391;&#36816;&#21160;&#20808;&#39564;&#21644;&#29305;&#24449;&#21521;&#37327;&#24341;&#23548;&#21464;&#37327;&#65292;&#25512;&#23548;&#20102;&#39057;&#29575;&#27966;&#21487;&#20449;&#21306;&#38388;&#30340;&#29702;&#35770;&#20445;&#35777;&#21644;&#38480;&#21046;&#65292;&#24182;&#22312;&#36275;&#22815;&#22810;&#30340;&#24341;&#23548;&#21464;&#37327;&#30340;&#24773;&#20917;&#19979;&#31934;&#30830;&#23450;&#20041;&#20102;&#28176;&#36817;&#39057;&#29575;&#27966;&#35206;&#30422;&#65292;&#20174;&#32780;&#25512;&#26029;&#20986;&#36825;&#20010;&#21464;&#20998;&#26041;&#27861;&#30340;&#21487;&#20449;&#21306;&#38388;&#20309;&#26102;&#20445;&#23432;&#65292;&#20309;&#26102;&#36807;&#20110;&#33258;&#20449;/&#35823;&#23548;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#32467;&#26524;&#30340;&#36866;&#29992;&#24615;&#65292;&#24182;&#35752;&#35770;&#20102;&#19982;&#20854;&#20182;&#24120;&#35265;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#29305;&#24449;&#21521;&#37327;&#24341;&#23548;&#21464;&#37327;&#30340;&#31232;&#30095;&#21464;&#20998;&#39640;&#26031;&#36807;&#31243;&#26041;&#27861;&#30340;&#28857;&#20272;&#35745;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#23545;&#20110;&#20855;&#26377;&#37325;&#26631;&#23450;&#24067;&#26391;&#36816;&#21160;&#20808;&#39564;&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#28857;&#21270;&#21487;&#20449;&#21306;&#38388;&#30340;&#39057;&#29575;&#27966;&#22823;&#23567;&#21644;&#35206;&#30422;&#30340;&#29702;&#35770;&#20445;&#35777;&#21644;&#38480;&#21046;&#12290;&#36890;&#36807;&#20805;&#20998;&#30340;&#24341;&#23548;&#21464;&#37327;&#65292;&#25105;&#20204;&#31934;&#30830;&#22320;&#25551;&#36848;&#20102;&#28176;&#36817;&#39057;&#29575;&#27966;&#35206;&#30422;&#65292;&#25512;&#26029;&#20102;&#36825;&#20010;&#21464;&#20998;&#26041;&#27861;&#30340;&#21487;&#20449;&#21306;&#38388;&#20309;&#26102;&#20445;&#23432;&#65292;&#20309;&#26102;&#36807;&#20110;&#33258;&#20449;/&#35823;&#23548;&#12290;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#35828;&#26126;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#30340;&#36866;&#29992;&#24615;&#65292;&#24182;&#35752;&#35770;&#20102;&#19982;&#20854;&#20182;&#24120;&#35265;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study pointwise estimation and uncertainty quantification for a sparse variational Gaussian process method with eigenvector inducing variables. For a rescaled Brownian motion prior, we derive theoretical guarantees and limitations for the frequentist size and coverage of pointwise credible sets. For sufficiently many inducing variables, we precisely characterize the asymptotic frequentist coverage, deducing when credible sets from this variational method are conservative and when overconfident/misleading. We numerically illustrate the applicability of our results and discuss connections with other common Gaussian process priors.
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#23558;&#26080;&#26631;&#35760;&#30340;&#22495;&#22806;&#25968;&#25454;&#32435;&#20837;&#21322;&#30417;&#30563;&#20998;&#31867;&#38382;&#39064;&#65292;&#20174;&#32780;&#25913;&#21892;&#27867;&#21270;&#33021;&#21147;&#12290;&#35813;&#26694;&#26550;&#32467;&#21512;&#20102;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#19982;&#33258;&#30417;&#30563;&#35757;&#32451;&#65292;&#24182;&#21033;&#29992;&#20102;&#39640;&#25928;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#35813;&#26694;&#26550;&#22312;&#39640;&#26031;&#28151;&#21512;&#20998;&#31867;&#38382;&#39064;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.00027</link><description>&lt;p&gt;
&#26080;&#26631;&#35760;&#30340;&#22495;&#22806;&#25968;&#25454;&#25913;&#21892;&#20102;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Unlabeled Out-Of-Domain Data Improves Generalization. (arXiv:2310.00027v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00027
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#23558;&#26080;&#26631;&#35760;&#30340;&#22495;&#22806;&#25968;&#25454;&#32435;&#20837;&#21322;&#30417;&#30563;&#20998;&#31867;&#38382;&#39064;&#65292;&#20174;&#32780;&#25913;&#21892;&#27867;&#21270;&#33021;&#21147;&#12290;&#35813;&#26694;&#26550;&#32467;&#21512;&#20102;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#19982;&#33258;&#30417;&#30563;&#35757;&#32451;&#65292;&#24182;&#21033;&#29992;&#20102;&#39640;&#25928;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#35813;&#26694;&#26550;&#22312;&#39640;&#26031;&#28151;&#21512;&#20998;&#31867;&#38382;&#39064;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#26080;&#26631;&#35760;&#25968;&#25454;&#32435;&#20837;&#21322;&#30417;&#30563;&#20998;&#31867;&#38382;&#39064;&#30340;&#26032;&#26694;&#26550;&#65292;&#20854;&#20013;&#32771;&#34385;&#20102;&#26368;&#23567;&#21270;&#40065;&#26834;&#24615;&#25439;&#22833;&#20989;&#25968;&#25110;&#38750;&#40065;&#26834;&#24615;&#25439;&#22833;&#20989;&#25968;&#30340;&#24773;&#26223;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#20801;&#35768;&#26080;&#26631;&#35760;&#26679;&#26412;&#22312;&#24635;&#21464;&#24046;&#24847;&#20041;&#19978;&#30053;&#24494;&#20559;&#31163;&#22495;&#20869;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#30340;&#26680;&#24515;&#24605;&#24819;&#26159;&#23558;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#19982;&#33258;&#30417;&#30563;&#35757;&#32451;&#30456;&#32467;&#21512;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#36824;&#21033;&#29992;&#20102;&#35757;&#32451;&#38454;&#27573;&#30340;&#39640;&#25928;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#12290;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26694;&#26550;&#24212;&#29992;&#20110;&#22312;$\mathbb{R}^d$&#20013;&#30340;&#20004;&#20010;&#39640;&#26031;&#28151;&#21512;&#20998;&#31867;&#38382;&#39064;&#65292;&#38500;&#20102;&#26469;&#33258;&#30495;&#23454;&#20998;&#24067;&#30340;$m$&#20010;&#29420;&#31435;&#26631;&#35760;&#26679;&#26412;&#20043;&#22806;&#65292;&#36824;&#32473;&#20986;&#20102;&#19968;&#32452;$n$&#20010;&#65288;&#36890;&#24120;$n\gg m$&#65289;&#22495;&#22806;&#21644;&#26080;&#26631;&#35760;&#26679;&#26412;&#12290;&#24050;&#30693;&#20165;&#20351;&#29992;&#26631;&#35760;&#25968;&#25454;&#65292;&#27867;&#21270;&#35823;&#24046;&#21487;&#20197;&#36890;&#36807;$\propto\left(d/m\right)$&#36827;&#34892;&#30028;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel framework for incorporating unlabeled data into semi-supervised classification problems, where scenarios involving the minimization of either i) adversarially robust or ii) non-robust loss functions have been considered. Notably, we allow the unlabeled samples to deviate slightly (in total variation sense) from the in-domain distribution. The core idea behind our framework is to combine Distributionally Robust Optimization (DRO) with self-supervised training. As a result, we also leverage efficient polynomial-time algorithms for the training stage. From a theoretical standpoint, we apply our framework on the classification problem of a mixture of two Gaussians in $\mathbb{R}^d$, where in addition to the $m$ independent and labeled samples from the true distribution, a set of $n$ (usually with $n\gg m$) out of domain and unlabeled samples are gievn as well. Using only the labeled data, it is known that the generalization error can be bounded by $\propto\left(d/m\right
&lt;/p&gt;</description></item><item><title>Stackelberg&#25209;&#37327;&#31574;&#30053;&#23398;&#20064;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#38543;&#26426;&#26799;&#24230;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#37319;&#29992;&#21338;&#24328;&#35770;&#30340;&#35266;&#28857;&#65292;&#23545;&#31574;&#30053;&#23398;&#20064;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#32771;&#34385;&#20102;&#20248;&#21270;&#26223;&#35266;&#20013;&#30340;&#20998;&#23618;&#20915;&#31574;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2309.16188</link><description>&lt;p&gt;
Stackelberg&#25209;&#37327;&#31574;&#30053;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Stackelberg Batch Policy Learning. (arXiv:2309.16188v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16188
&lt;/p&gt;
&lt;p&gt;
Stackelberg&#25209;&#37327;&#31574;&#30053;&#23398;&#20064;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#38543;&#26426;&#26799;&#24230;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#37319;&#29992;&#21338;&#24328;&#35770;&#30340;&#35266;&#28857;&#65292;&#23545;&#31574;&#30053;&#23398;&#20064;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#32771;&#34385;&#20102;&#20248;&#21270;&#26223;&#35266;&#20013;&#30340;&#20998;&#23618;&#20915;&#31574;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25209;&#37327;&#24378;&#21270;&#23398;&#20064;&#23450;&#20041;&#20102;&#20174;&#22266;&#23450;&#30340;&#25968;&#25454;&#25209;&#27425;&#20013;&#36827;&#34892;&#23398;&#20064;&#65292;&#32570;&#20047;&#35814;&#23613;&#30340;&#25506;&#32034;&#12290;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#26368;&#20248;&#31639;&#27861;&#20351;&#29992;&#32463;&#39564;&#25968;&#25454;&#26469;&#26657;&#20934;&#20215;&#20540;&#20989;&#25968;&#27169;&#22411;&#65292;&#24182;&#22312;&#23398;&#20064;&#27169;&#22411;&#19979;&#25191;&#34892;&#26576;&#31181;&#24754;&#35266;&#35780;&#20272;&#65292;&#24050;&#32463;&#25104;&#20026;&#25209;&#37327;&#24378;&#21270;&#23398;&#20064;&#20013;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#33539;&#24335;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#36825;&#20010;&#27969;&#27966;&#30340;&#29616;&#20195;&#30740;&#31350;&#36890;&#24120;&#24573;&#35270;&#20102;&#20248;&#21270;&#26223;&#35266;&#20013;&#38544;&#34255;&#30340;&#20998;&#23618;&#20915;&#31574;&#32467;&#26500;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#21338;&#24328;&#35770;&#30340;&#35266;&#28857;&#65292;&#23558;&#31574;&#30053;&#23398;&#20064;&#22270;&#34920;&#24314;&#27169;&#20026;&#20855;&#26377;&#39046;&#23548;&#32773;-&#36319;&#38543;&#32773;&#32467;&#26500;&#30340;&#20004;&#20154;&#38646;&#21644;&#21338;&#24328;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#38543;&#26426;&#26799;&#24230;&#30340;&#23398;&#20064;&#31639;&#27861;&#65306;StackelbergLearner&#65292;&#39046;&#23548;&#32773;&#26681;&#25454;&#20854;&#30446;&#26631;&#30340;&#20840;&#23548;&#25968;&#36827;&#34892;&#26356;&#26032;&#65292;&#32780;&#19981;&#26159;&#36890;&#24120;&#30340;&#20010;&#20307;&#26799;&#24230;&#65292;&#32780;&#36319;&#38543;&#32773;&#36827;&#34892;&#20010;&#20307;&#26356;&#26032;&#24182;&#30830;&#20445;&#36807;&#28193;&#19968;&#33268;&#30340;&#24754;&#35266;&#25512;&#29702;&#12290;&#25512;&#23548;&#20986;&#30340;&#23398;&#20064;&#21160;&#21147;
&lt;/p&gt;
&lt;p&gt;
Batch reinforcement learning (RL) defines the task of learning from a fixed batch of data lacking exhaustive exploration. Worst-case optimality algorithms, which calibrate a value-function model class from logged experience and perform some type of pessimistic evaluation under the learned model, have emerged as a promising paradigm for batch RL. However, contemporary works on this stream have commonly overlooked the hierarchical decision-making structure hidden in the optimization landscape. In this paper, we adopt a game-theoretical viewpoint and model the policy learning diagram as a two-player general-sum game with a leader-follower structure. We propose a novel stochastic gradient-based learning algorithm: StackelbergLearner, in which the leader player updates according to the total derivative of its objective instead of the usual individual gradient, and the follower player makes individual updates and ensures transition-consistent pessimistic reasoning. The derived learning dynam
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#22312;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#19978;&#20351;&#29992;&#23567;&#25209;&#37327;SGD&#31639;&#27861;&#65292;&#22312;&#20855;&#26377;&#20108;&#27425;&#30495;&#23454;&#20989;&#25968;&#20998;&#38548;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#35757;&#32451;&#25968;&#37327;&#32423;&#20026;$d \:\text{polylog}(d)$&#30340;&#26679;&#26412;&#65292;&#23558;&#32593;&#32476;&#35757;&#32451;&#21040;&#20102;&#20154;&#21475;&#35823;&#24046;&#20026;$o(1)$&#30340;&#31243;&#24230;&#12290;&#36825;&#26159;&#39318;&#27425;&#22312;&#26631;&#20934;&#31070;&#32463;&#32593;&#32476;&#19978;&#20197;&#21450;&#26631;&#20934;&#35757;&#32451;&#19979;&#65292;&#23637;&#31034;&#20102;&#22312;&#21508;&#21521;&#21516;&#24615;&#25968;&#25454;&#19978;&#39640;&#25928;&#23398;&#20064;XOR&#20989;&#25968;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\tilde{O}(d)$&#12290;</title><link>http://arxiv.org/abs/2309.15111</link><description>&lt;p&gt;
SGD&#22312;&#20855;&#26377;&#25509;&#36817;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#23547;&#25214;&#24182;&#35843;&#25972;&#29305;&#24449;&#65306;&#20197;XOR&#38382;&#39064;&#20026;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
SGD Finds then Tunes Features in Two-Layer Neural Networks with near-Optimal Sample Complexity: A Case Study in the XOR problem. (arXiv:2309.15111v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15111
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#22312;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#19978;&#20351;&#29992;&#23567;&#25209;&#37327;SGD&#31639;&#27861;&#65292;&#22312;&#20855;&#26377;&#20108;&#27425;&#30495;&#23454;&#20989;&#25968;&#20998;&#38548;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#35757;&#32451;&#25968;&#37327;&#32423;&#20026;$d \:\text{polylog}(d)$&#30340;&#26679;&#26412;&#65292;&#23558;&#32593;&#32476;&#35757;&#32451;&#21040;&#20102;&#20154;&#21475;&#35823;&#24046;&#20026;$o(1)$&#30340;&#31243;&#24230;&#12290;&#36825;&#26159;&#39318;&#27425;&#22312;&#26631;&#20934;&#31070;&#32463;&#32593;&#32476;&#19978;&#20197;&#21450;&#26631;&#20934;&#35757;&#32451;&#19979;&#65292;&#23637;&#31034;&#20102;&#22312;&#21508;&#21521;&#21516;&#24615;&#25968;&#25454;&#19978;&#39640;&#25928;&#23398;&#20064;XOR&#20989;&#25968;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\tilde{O}(d)$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23567;&#25209;&#37327;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#22312;&#20855;&#26377;&#20108;&#27425;&#30495;&#23454;&#20989;&#25968;&#20998;&#38548;&#25968;&#25454;&#30340;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#19978;&#30340;&#20248;&#21270;&#36807;&#31243;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#23545;&#20110;&#20174;$d$&#32500;&#24067;&#23572;&#36229;&#31435;&#26041;&#20307;&#20013;&#30001;&#20108;&#27425;&#8220;XOR&#8221;&#20989;&#25968;$y = -x_ix_j$&#26631;&#35760;&#30340;&#25968;&#25454;&#65292;&#21487;&#20197;&#36890;&#36807;&#26631;&#20934;&#23567;&#25209;&#37327;SGD&#22312;&#36923;&#36753;&#25439;&#22833;&#19978;&#21516;&#26102;&#35757;&#32451;&#20004;&#23618;ReLU&#28608;&#27963;&#30340;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#29992;$d \:\text{polylog}(d)$&#20010;&#26679;&#26412;&#23558;&#20854;&#35757;&#32451;&#21040;&#20154;&#21475;&#35823;&#24046;&#20026;$o(1)$&#30340;&#31243;&#24230;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#39318;&#27425;&#32473;&#20986;&#20102;&#22312;&#26631;&#20934;&#31070;&#32463;&#32593;&#32476;&#19978;&#20197;&#21450;&#26631;&#20934;&#35757;&#32451;&#19979;&#65292;&#23545;&#20110;&#22312;&#21508;&#21521;&#21516;&#24615;&#25968;&#25454;&#19978;&#39640;&#25928;&#23398;&#20064;XOR&#20989;&#25968;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\tilde{O}(d)$&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#25216;&#26415;&#26159;&#23637;&#31034;&#32593;&#32476;&#28436;&#21270;&#26377;&#20004;&#20010;&#38454;&#27573;&#65306;&#19968;&#20010;&#8221;&#20449;&#21495;&#21457;&#29616;&#8220;&#38454;&#27573;&#65292;&#22312;&#27492;&#32593;&#32476;&#35268;&#27169;&#36739;&#23567;&#19988;&#35768;&#22810;&#31070;&#32463;&#20803;&#29420;&#31435;&#28436;&#21270;&#20197;&#23547;&#25214;&#29305;&#24449;&#65292;&#20197;&#21450;&#19968;&#20010;&#8221;&#20449;&#21495;&#23494;&#38598;&#8220;&#38454;&#27573;&#65292;&#20854;&#20013;&#35768;&#22810;&#31070;&#32463;&#20803;&#30456;&#20114;&#20316;&#29992;&#20197;&#20248;&#21270;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we consider the optimization process of minibatch stochastic gradient descent (SGD) on a 2-layer neural network with data separated by a quadratic ground truth function. We prove that with data drawn from the $d$-dimensional Boolean hypercube labeled by the quadratic ``XOR'' function $y = -x_ix_j$, it is possible to train to a population error $o(1)$ with $d \:\text{polylog}(d)$ samples. Our result considers simultaneously training both layers of the two-layer-neural network with ReLU activations via standard minibatch SGD on the logistic loss. To our knowledge, this work is the first to give a sample complexity of $\tilde{O}(d)$ for efficiently learning the XOR function on isotropic data on a standard neural network with standard training. Our main technique is showing that the network evolves in two phases: a $\textit{signal-finding}$ phase where the network is small and many of the neurons evolve independently to find features, and a $\textit{signal-heavy}$ phase, wher
&lt;/p&gt;</description></item><item><title>MaGNet&#26159;&#19968;&#31181;&#27169;&#22411;&#26080;&#20851;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#33021;&#22815;&#39034;&#24207;&#22320;&#25972;&#21512;&#19981;&#21516;&#39034;&#24207;&#30340;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#35782;&#21035;&#26377;&#24433;&#21709;&#21147;&#30340;&#32039;&#20945;&#22270;&#32467;&#26500;&#25552;&#20379;&#26377;&#24847;&#20041;&#19988;&#21487;&#35299;&#37322;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.13459</link><description>&lt;p&gt;
&#27169;&#22411;&#26080;&#20851;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#25972;&#21512;&#23616;&#37096;&#21644;&#20840;&#23616;&#20449;&#24687;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Model-Agnostic Graph Neural Network for Integrating Local and Global Information. (arXiv:2309.13459v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13459
&lt;/p&gt;
&lt;p&gt;
MaGNet&#26159;&#19968;&#31181;&#27169;&#22411;&#26080;&#20851;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#33021;&#22815;&#39034;&#24207;&#22320;&#25972;&#21512;&#19981;&#21516;&#39034;&#24207;&#30340;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#35782;&#21035;&#26377;&#24433;&#21709;&#21147;&#30340;&#32039;&#20945;&#22270;&#32467;&#26500;&#25552;&#20379;&#26377;&#24847;&#20041;&#19988;&#21487;&#35299;&#37322;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#22312;&#21508;&#31181;&#20197;&#22270;&#20026;&#37325;&#28857;&#30340;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#20196;&#20154;&#28385;&#24847;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#29616;&#26377;&#30340;GNN&#23384;&#22312;&#20004;&#20010;&#37325;&#35201;&#38480;&#21046;&#65306;&#30001;&#20110;&#40657;&#30418;&#29305;&#24615;&#65292;&#32467;&#26524;&#32570;&#20047;&#21487;&#35299;&#37322;&#24615;&#65307;&#26080;&#27861;&#23398;&#20064;&#19981;&#21516;&#39034;&#24207;&#30340;&#34920;&#31034;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;&#26080;&#20851;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;MaGNet&#65289;&#26694;&#26550;&#65292;&#33021;&#22815;&#39034;&#24207;&#22320;&#25972;&#21512;&#19981;&#21516;&#39034;&#24207;&#30340;&#20449;&#24687;&#65292;&#20174;&#39640;&#38454;&#37051;&#23621;&#20013;&#25552;&#21462;&#30693;&#35782;&#65292;&#24182;&#36890;&#36807;&#35782;&#21035;&#26377;&#24433;&#21709;&#21147;&#30340;&#32039;&#20945;&#22270;&#32467;&#26500;&#25552;&#20379;&#26377;&#24847;&#20041;&#19988;&#21487;&#35299;&#37322;&#30340;&#32467;&#26524;&#12290;&#29305;&#21035;&#22320;&#65292;MaGNet&#30001;&#20004;&#20010;&#32452;&#20214;&#32452;&#25104;&#65306;&#22270;&#25299;&#25169;&#19979;&#22797;&#26434;&#20851;&#31995;&#30340;&#28508;&#22312;&#34920;&#31034;&#30340;&#20272;&#35745;&#27169;&#22411;&#21644;&#35782;&#21035;&#26377;&#24433;&#21709;&#21147;&#30340;&#33410;&#28857;&#12289;&#36793;&#21644;&#37325;&#35201;&#33410;&#28857;&#29305;&#24449;&#30340;&#35299;&#37322;&#27169;&#22411;&#12290;&#20174;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#36890;&#36807;&#32463;&#39564;Rademacher&#22797;&#26434;&#24230;&#24314;&#31435;&#20102;MaGNet&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#24378;&#22823;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) have achieved promising performance in a variety of graph-focused tasks. Despite their success, existing GNNs suffer from two significant limitations: a lack of interpretability in results due to their black-box nature, and an inability to learn representations of varying orders. To tackle these issues, we propose a novel Model-agnostic Graph Neural Network (MaGNet) framework, which is able to sequentially integrate information of various orders, extract knowledge from high-order neighbors, and provide meaningful and interpretable results by identifying influential compact graph structures. In particular, MaGNet consists of two components: an estimation model for the latent representation of complex relationships under graph topology, and an interpretation model that identifies influential nodes, edges, and important node features. Theoretically, we establish the generalization error bound for MaGNet via empirical Rademacher complexity, and showcase its pow
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#23545;&#20110;&#24378;&#21270;&#23398;&#20064;&#38750;&#21516;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#30340;&#32479;&#19968;&#35823;&#24046;&#37327;&#21270;&#26694;&#26550;&#65292;&#24182;&#35299;&#20915;&#20102;&#20998;&#24067;&#20559;&#31227;&#30340;&#25361;&#25112;&#12290;&#36890;&#36807;&#22312;&#19968;&#20010;&#21333;&#19968;&#30340;&#21306;&#38388;&#20869;&#20849;&#21516;&#37327;&#21270;&#20004;&#20010;&#20272;&#35745;&#35823;&#24046;&#28304;&#65292;&#35813;&#26694;&#26550;&#25581;&#31034;&#20102;&#20043;&#21069;&#38544;&#34255;&#30340;&#35823;&#24046;&#26435;&#34913;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#32622;&#20449;&#21306;&#38388;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.13278</link><description>&lt;p&gt;
&#20998;&#24067;&#20559;&#31227;&#24863;&#30693;&#30340;&#24378;&#21270;&#23398;&#20064;&#38750;&#21516;&#31574;&#30053;&#21306;&#38388;&#20272;&#35745;&#26041;&#27861;&#65306;&#19968;&#20010;&#32479;&#19968;&#30340;&#35823;&#24046;&#37327;&#21270;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Distributional Shift-Aware Off-Policy Interval Estimation: A Unified Error Quantification Framework. (arXiv:2309.13278v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13278
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#23545;&#20110;&#24378;&#21270;&#23398;&#20064;&#38750;&#21516;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#30340;&#32479;&#19968;&#35823;&#24046;&#37327;&#21270;&#26694;&#26550;&#65292;&#24182;&#35299;&#20915;&#20102;&#20998;&#24067;&#20559;&#31227;&#30340;&#25361;&#25112;&#12290;&#36890;&#36807;&#22312;&#19968;&#20010;&#21333;&#19968;&#30340;&#21306;&#38388;&#20869;&#20849;&#21516;&#37327;&#21270;&#20004;&#20010;&#20272;&#35745;&#35823;&#24046;&#28304;&#65292;&#35813;&#26694;&#26550;&#25581;&#31034;&#20102;&#20043;&#21069;&#38544;&#34255;&#30340;&#35823;&#24046;&#26435;&#34913;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#32622;&#20449;&#21306;&#38388;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26080;&#38480;&#26102;&#38388;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#39640;&#32622;&#20449;&#24230;&#38750;&#21516;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#20854;&#30446;&#26631;&#26159;&#20165;&#21033;&#29992;&#20174;&#26410;&#30693;&#34892;&#20026;&#31574;&#30053;&#39044;&#20808;&#25910;&#38598;&#30340;&#31163;&#32447;&#25968;&#25454;&#20026;&#30446;&#26631;&#31574;&#30053;&#30340;&#20540;&#24314;&#31435;&#19968;&#20010;&#32622;&#20449;&#21306;&#38388;&#65288;CI&#65289;&#12290;&#35813;&#20219;&#21153;&#38754;&#20020;&#20004;&#20010;&#20027;&#35201;&#25361;&#25112;&#65306;&#22312;CI&#20272;&#35745;&#20013;&#25552;&#20379;&#20840;&#38754;&#19988;&#20005;&#26684;&#30340;&#35823;&#24046;&#37327;&#21270;&#65292;&#24182;&#35299;&#20915;&#30001;&#30446;&#26631;&#31574;&#30053;&#20135;&#29983;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65292;&#35813;&#20998;&#24067;&#19982;&#31163;&#32447;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20043;&#38388;&#23384;&#22312;&#24046;&#24322;&#12290;&#21463;&#21040;&#21019;&#26032;&#30340;&#32479;&#19968;&#35823;&#24046;&#20998;&#26512;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#22312;&#19968;&#20010;&#21333;&#19968;&#30340;&#21306;&#38388;&#20869;&#20849;&#21516;&#37327;&#21270;&#20004;&#20010;&#20272;&#35745;&#35823;&#24046;&#26469;&#28304;&#65306;&#22312;&#24314;&#27169;&#36793;&#38469;&#21270;&#37325;&#35201;&#24615;&#26435;&#37325;&#26102;&#30340;&#35268;&#33539;&#19981;&#20934;&#30830;&#35823;&#24046;&#21644;&#25277;&#26679;&#23548;&#33268;&#30340;&#32479;&#35745;&#19981;&#30830;&#23450;&#24615;&#12290;&#36825;&#19968;&#32479;&#19968;&#30340;&#26694;&#26550;&#25581;&#31034;&#20102;&#35823;&#24046;&#20043;&#38388;&#20197;&#21069;&#38544;&#34255;&#30340;&#26435;&#34913;&#65292;&#20174;&#32780;&#21066;&#24369;&#20102;CI&#30340;&#32039;&#23494;&#24615;&#12290;&#36890;&#36807;&#20381;&#38752;&#31934;&#24515;&#35774;&#35745;&#30340;&#21028;&#21035;&#20989;&#25968;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35299;&#20915;&#26041;&#26696;&#26469;&#20811;&#26381;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study high-confidence off-policy evaluation in the context of infinite-horizon Markov decision processes, where the objective is to establish a confidence interval (CI) for the target policy value using only offline data pre-collected from unknown behavior policies. This task faces two primary challenges: providing a comprehensive and rigorous error quantification in CI estimation, and addressing the distributional shift that results from discrepancies between the distribution induced by the target policy and the offline data-generating process. Motivated by an innovative unified error analysis, we jointly quantify the two sources of estimation errors: the misspecification error on modeling marginalized importance weights and the statistical uncertainty due to sampling, within a single interval. This unified framework reveals a previously hidden tradeoff between the errors, which undermines the tightness of the CI. Relying on a carefully designed discriminator function, the proposed
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20449;&#24687;&#20215;&#20540;&#65288;IV&#65289;&#30340;&#32479;&#35745;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#20026;&#27169;&#22411;&#24314;&#31435;&#21069;&#30340;&#29305;&#24449;&#36873;&#25321;&#25552;&#20379;&#20102;&#29702;&#35770;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.13183</link><description>&lt;p&gt;
&#20449;&#24687;&#20215;&#20540;&#65288;IV&#65289;&#30340;&#32479;&#35745;&#20551;&#35774;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Statistical Hypothesis Testing for Information Value (IV). (arXiv:2309.13183v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13183
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20449;&#24687;&#20215;&#20540;&#65288;IV&#65289;&#30340;&#32479;&#35745;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#20026;&#27169;&#22411;&#24314;&#31435;&#21069;&#30340;&#29305;&#24449;&#36873;&#25321;&#25552;&#20379;&#20102;&#29702;&#35770;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#20215;&#20540;&#65288;IV&#65289;&#26159;&#27169;&#22411;&#24314;&#31435;&#21069;&#36827;&#34892;&#29305;&#24449;&#36873;&#25321;&#30340;&#19968;&#31181;&#24120;&#29992;&#25216;&#26415;&#12290;&#30446;&#21069;&#23384;&#22312;&#19968;&#20123;&#23454;&#38469;&#26631;&#20934;&#65292;&#20294;&#22522;&#20110;IV&#30340;&#21028;&#26029;&#26159;&#21542;&#19968;&#20010;&#39044;&#27979;&#22240;&#23376;&#20855;&#26377;&#36275;&#22815;&#30340;&#39044;&#27979;&#33021;&#21147;&#30340;&#29702;&#35770;&#20381;&#25454;&#20381;&#28982;&#31070;&#31192;&#19988;&#32570;&#20047;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#35813;&#25216;&#26415;&#30340;&#25968;&#23398;&#21457;&#23637;&#21644;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#22312;&#25991;&#29486;&#20013;&#20960;&#20046;&#27809;&#26377;&#25552;&#21450;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20851;&#20110;IV&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#26469;&#27979;&#35797;&#39044;&#27979;&#33021;&#21147;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#39640;&#25928;&#35745;&#31639;&#26816;&#39564;&#32479;&#35745;&#37327;&#65292;&#24182;&#22312;&#27169;&#25311;&#25968;&#25454;&#19978;&#30740;&#31350;&#20854;&#34920;&#29616;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#36825;&#19968;&#26041;&#27861;&#24212;&#29992;&#20110;&#38134;&#34892;&#27450;&#35784;&#25968;&#25454;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#23454;&#29616;&#25105;&#20204;&#32467;&#26524;&#30340;Python&#24211;&#12290;
&lt;/p&gt;
&lt;p&gt;
Information value (IV) is a quite popular technique for feature selection prior to the modeling phase. There are practical criteria, but at the same time mysterious and lacking theoretical arguments, based on the IV, to decide if a predictor has sufficient predictive power to be considered in the modeling phase. However, the mathematical development and statistical inference methods for this technique is almost non-existent in the literature. In this work we present a theoretical framework for the IV and propose a non-parametric hypothesis test to test the predictive power. We show how to efficiently calculate the test statistic and study its performance on simulated data. Additionally, we apply our test on bank fraud data and provide a Python library where we implement our results.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#31867;&#20284;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#20026;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;(SAM)&#65292;&#19968;&#31181;&#25913;&#36827;&#27867;&#21270;&#24615;&#33021;&#30340;&#26799;&#24230;&#19979;&#38477;&#21464;&#31181;&#65292;&#30830;&#23450;&#20102;&#19968;&#20010;&#31283;&#23450;&#24615;&#36793;&#30028;&#65292;&#35813;&#36793;&#30028;&#21462;&#20915;&#20110;&#26799;&#24230;&#30340;&#33539;&#25968;&#12290;</title><link>http://arxiv.org/abs/2309.12488</link><description>&lt;p&gt;
&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#21644;&#31283;&#23450;&#24615;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sharpness-Aware Minimization and the Edge of Stability. (arXiv:2309.12488v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12488
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#31867;&#20284;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#20026;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;(SAM)&#65292;&#19968;&#31181;&#25913;&#36827;&#27867;&#21270;&#24615;&#33021;&#30340;&#26799;&#24230;&#19979;&#38477;&#21464;&#31181;&#65292;&#30830;&#23450;&#20102;&#19968;&#20010;&#31283;&#23450;&#24615;&#36793;&#30028;&#65292;&#35813;&#36793;&#30028;&#21462;&#20915;&#20110;&#26799;&#24230;&#30340;&#33539;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#24403;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;(GD)&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26102;&#65292;&#25439;&#22833;&#20989;&#25968;&#30340;Hessian&#30697;&#38453;&#30340;&#25805;&#20316;&#31526;&#33539;&#25968;&#20250;&#22686;&#38271;&#65292;&#30452;&#21040;&#25509;&#36817;$2/\eta$&#65292;&#20043;&#21518;&#20250;&#22312;&#35813;&#20540;&#21608;&#22260;&#27874;&#21160;&#12290;&#26681;&#25454;&#23545;&#25439;&#22833;&#20989;&#25968;&#30340;&#23616;&#37096;&#20108;&#27425;&#36924;&#36817;&#65292;$2/\eta$&#34987;&#31216;&#20026;&#8220;&#31283;&#23450;&#24615;&#36793;&#30028;&#8221;&#12290;&#25105;&#20204;&#20351;&#29992;&#31867;&#20284;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#20026;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;(SAM)&#30830;&#23450;&#20102;&#19968;&#20010;&#8220;&#31283;&#23450;&#24615;&#36793;&#30028;&#8221;&#65292;SAM&#26159;&#19968;&#31181;&#25913;&#36827;&#27867;&#21270;&#24615;&#33021;&#30340;GD&#21464;&#31181;&#12290;&#19982;GD&#19981;&#21516;&#65292;SAM&#30340;&#31283;&#23450;&#24615;&#36793;&#30028;&#21462;&#20915;&#20110;&#26799;&#24230;&#30340;&#33539;&#25968;&#12290;&#36890;&#36807;&#19977;&#20010;&#28145;&#24230;&#23398;&#20064;&#20219;&#21153;&#30340;&#23454;&#35777;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;SAM&#22312;&#36825;&#20010;&#20998;&#26512;&#20013;&#30830;&#23450;&#30340;&#31283;&#23450;&#24615;&#36793;&#30028;&#19978;&#36816;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent experiments have shown that, often, when training a neural network with gradient descent (GD) with a step size $\eta$, the operator norm of the Hessian of the loss grows until it approximately reaches $2/\eta$, after which it fluctuates around this value.  The quantity $2/\eta$ has been called the "edge of stability" based on consideration of a local quadratic approximation of the loss. We perform a similar calculation to arrive at an "edge of stability" for Sharpness-Aware Minimization (SAM), a variant of GD which has been shown to improve its generalization. Unlike the case for GD, the resulting SAM-edge depends on the norm of the gradient. Using three deep learning training tasks, we see empirically that SAM operates on the edge of stability identified by this analysis.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31038;&#20132;&#32593;&#32476;&#20013;&#23618;&#27425;&#32858;&#31867;&#30340;&#32479;&#35745;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#27169;&#22411;$\mathbb{T}$-&#38543;&#26426;&#22270;&#65292;&#29992;&#20110;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#20013;&#23384;&#22312;&#30340;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.01301</link><description>&lt;p&gt;
$\mathbb{T}$-&#38543;&#26426;&#22270;
&lt;/p&gt;
&lt;p&gt;
$\mathbb{T}$-Stochastic Graphs. (arXiv:2309.01301v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01301
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31038;&#20132;&#32593;&#32476;&#20013;&#23618;&#27425;&#32858;&#31867;&#30340;&#32479;&#35745;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#27169;&#22411;$\mathbb{T}$-&#38543;&#26426;&#22270;&#65292;&#29992;&#20110;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#20013;&#23384;&#22312;&#30340;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#30340;&#31038;&#20132;&#32593;&#32476;&#20998;&#26512;&#20013;&#20851;&#20110;&#23618;&#27425;&#32858;&#31867;&#30340;&#32479;&#35745;&#26041;&#27861;&#37117;&#26500;&#24314;&#20102;&#19968;&#20010;&#8220;&#36229;&#24230;&#37327;&#8221;&#30340;&#23618;&#27425;&#32467;&#26500;&#12290;&#34429;&#28982;&#36229;&#24230;&#37327;&#24615;&#30340;&#20551;&#35774;&#22312;&#31995;&#32479;&#21457;&#29983;&#23398;&#25991;&#29486;&#20013;&#24050;&#32463;&#24471;&#21040;&#20102;&#35752;&#35770;&#21644;&#30740;&#31350;&#65292;&#20294;&#22312;&#31038;&#20132;&#32593;&#32476;&#25991;&#29486;&#20013;&#23578;&#26410;&#24471;&#21040;&#25215;&#35748;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#32593;&#32476;&#20013;&#30340;&#8220;&#38750;&#36229;&#24230;&#37327;&#32467;&#26500;&#8221;&#24341;&#20837;&#20102;&#29616;&#26377;&#33258;&#19978;&#32780;&#19979;&#24674;&#22797;&#31639;&#27861;&#30340;&#26174;&#33879;&#19981;&#31283;&#23450;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#19981;&#31283;&#23450;&#24615;&#35786;&#26029;&#22270;&#24182;&#20351;&#29992;&#23427;&#26469;&#26816;&#26597;&#19968;&#31995;&#21015;&#32463;&#39564;&#32593;&#32476;&#12290;&#36825;&#20123;&#32593;&#32476;&#20284;&#20046;&#36829;&#21453;&#20102;&#8220;&#36229;&#24230;&#37327;&#8221;&#20551;&#35774;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#30475;&#20284;&#31616;&#21333;&#20294;&#21448;&#24456;&#36890;&#29992;&#30340;&#27010;&#29575;&#27169;&#22411;&#31867;&#65292;&#31216;&#20026;$\mathbb{T}$-&#38543;&#26426;&#22270;&#65292;&#23427;&#23545;&#28508;&#22312;&#23618;&#27425;&#32467;&#26500;&#19981;&#26045;&#21152;&#25299;&#25169;&#38480;&#21046;&#12290;&#20026;&#20102;&#35828;&#26126;&#36825;&#20010;&#27169;&#22411;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20845;&#31181;&#26367;&#20195;&#24615;&#30340;&#23618;&#27425;&#32593;&#32476;&#27169;&#22411;&#65292;&#28982;&#21518;&#35777;&#26126;&#20102;&#25152;&#26377;&#20845;&#31181;&#27169;&#22411;&#37117;&#31561;&#20215;&#20110;$\mathbb{T}$-&#38543;&#26426;&#22270;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Previous statistical approaches to hierarchical clustering for social network analysis all construct an "ultrametric" hierarchy. While the assumption of ultrametricity has been discussed and studied in the phylogenetics literature, it has not yet been acknowledged in the social network literature. We show that "non-ultrametric structure" in the network introduces significant instabilities in the existing top-down recovery algorithms. To address this issue, we introduce an instability diagnostic plot and use it to examine a collection of empirical networks. These networks appear to violate the "ultrametric" assumption. We propose a deceptively simple and yet general class of probabilistic models called $\mathbb{T}$-Stochastic Graphs which impose no topological restrictions on the latent hierarchy. To illustrate this model, we propose six alternative forms of hierarchical network models and then show that all six are equivalent to the $\mathbb{T}$-Stochastic Graph model. These alternativ
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;RMSProp&#21644;Adam&#23384;&#22312;&#38544;&#24335;&#35268;&#33539;&#21270;&#20316;&#29992;&#65292;&#20854;&#21462;&#20915;&#20110;&#36229;&#21442;&#25968;&#21644;&#35757;&#32451;&#38454;&#27573;&#65292;&#24182;&#35752;&#35770;&#20102;&#36825;&#20123;&#35777;&#26126;&#20107;&#23454;&#23545;&#27867;&#21270;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2309.00079</link><description>&lt;p&gt;
&#20851;&#20110;Adam&#30340;&#38544;&#24335;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
On the Implicit Bias of Adam. (arXiv:2309.00079v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00079
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;RMSProp&#21644;Adam&#23384;&#22312;&#38544;&#24335;&#35268;&#33539;&#21270;&#20316;&#29992;&#65292;&#20854;&#21462;&#20915;&#20110;&#36229;&#21442;&#25968;&#21644;&#35757;&#32451;&#38454;&#27573;&#65292;&#24182;&#35752;&#35770;&#20102;&#36825;&#20123;&#35777;&#26126;&#20107;&#23454;&#23545;&#27867;&#21270;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20197;&#21069;&#30340;&#25991;&#29486;&#20013;&#65292;&#21518;&#21521;&#35823;&#24046;&#20998;&#26512;&#34987;&#29992;&#26469;&#25214;&#21040;&#36817;&#20284;&#26799;&#24230;&#19979;&#38477;&#36712;&#36857;&#30340;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODEs&#65289;&#12290;&#21457;&#29616;&#26377;&#38480;&#27493;&#38271;&#20250;&#38544;&#24335;&#22320;&#35268;&#33539;&#21270;&#35299;&#20915;&#26041;&#26696;&#65292;&#22240;&#20026;&#20986;&#29616;&#22312;ODE&#20013;&#30340;&#39033;&#20250;&#24809;&#32602;&#25439;&#22833;&#26799;&#24230;&#30340;&#20108;&#33539;&#25968;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;RMSProp&#21644;Adam&#20013;&#26159;&#21542;&#23384;&#22312;&#31867;&#20284;&#30340;&#38544;&#24335;&#35268;&#33539;&#21270;&#21462;&#20915;&#20110;&#23427;&#20204;&#30340;&#36229;&#21442;&#25968;&#21644;&#35757;&#32451;&#38454;&#27573;&#65292;&#20294;&#28041;&#21450;&#30340;&#8220;&#33539;&#25968;&#8221;&#19981;&#21516;&#65306;&#23545;&#24212;&#30340;ODE&#39033;&#35201;&#20040;&#24809;&#32602;&#65288;&#25200;&#21160;&#30340;&#65289;&#25439;&#22833;&#26799;&#24230;&#30340;&#19968;&#33539;&#25968;&#65292;&#35201;&#20040;&#30456;&#21453;&#22320;&#38459;&#27490;&#20854;&#20943;&#23567;&#65288;&#21518;&#19968;&#31181;&#24773;&#20917;&#26159;&#20856;&#22411;&#30340;&#65289;&#12290;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#25968;&#20540;&#23454;&#39564;&#65292;&#24182;&#35752;&#35770;&#20102;&#36825;&#20123;&#35777;&#26126;&#20107;&#23454;&#22914;&#20309;&#24433;&#21709;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In previous literature, backward error analysis was used to find ordinary differential equations (ODEs) approximating the gradient descent trajectory. It was found that finite step sizes implicitly regularize solutions because terms appearing in the ODEs penalize the two-norm of the loss gradients. We prove that the existence of similar implicit regularization in RMSProp and Adam depends on their hyperparameters and the training stage, but with a different "norm" involved: the corresponding ODE terms either penalize the (perturbed) one-norm of the loss gradients or, on the contrary, hinder its decrease (the latter case being typical). We also conduct numerical experiments and discuss how the proven facts can influence generalization.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#27491;&#21017;&#21270;Wasserstein Proximal&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#22122;&#22768;&#30340;&#25277;&#26679;&#31639;&#27861;&#65292;&#36890;&#36807;&#32473;&#23450;&#30340;&#28508;&#21183;&#20989;&#25968;&#30830;&#23450;&#24615;&#22320;&#36827;&#34892;&#31890;&#23376;&#28436;&#21270;&#65292;&#24182;&#25552;&#20379;&#20102;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#30340;&#32500;&#24230;&#20381;&#36182;&#24615;&#21644;&#36895;&#24230;&#25910;&#25947;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.14945</link><description>&lt;p&gt;
&#36890;&#36807;&#27491;&#21017;&#21270;Wasserstein Proximals&#23454;&#29616;&#26080;&#22122;&#22768;&#30340;&#25277;&#26679;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Noise-Free Sampling Algorithms via Regularized Wasserstein Proximals. (arXiv:2308.14945v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14945
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#27491;&#21017;&#21270;Wasserstein Proximal&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#22122;&#22768;&#30340;&#25277;&#26679;&#31639;&#27861;&#65292;&#36890;&#36807;&#32473;&#23450;&#30340;&#28508;&#21183;&#20989;&#25968;&#30830;&#23450;&#24615;&#22320;&#36827;&#34892;&#31890;&#23376;&#28436;&#21270;&#65292;&#24182;&#25552;&#20379;&#20102;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#30340;&#32500;&#24230;&#20381;&#36182;&#24615;&#21644;&#36895;&#24230;&#25910;&#25947;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#30001;&#28508;&#21183;&#20989;&#25968;&#25511;&#21046;&#30340;&#20998;&#24067;&#25277;&#26679;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26174;&#24335;&#30340;&#22522;&#20110;&#35780;&#20998;&#30340;&#30830;&#23450;&#24615;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#65292;&#20351;&#24471;&#31890;&#23376;&#30340;&#28436;&#21270;&#21464;&#20026;&#30830;&#23450;&#24615;&#30340;&#65292;&#32780;&#19981;&#26159;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#28436;&#21270;&#12290;&#35780;&#20998;&#39033;&#30001;&#27491;&#21017;&#21270;&#30340;Wasserstein proximal&#20197;&#38381;&#21512;&#24418;&#24335;&#32473;&#20986;&#65292;&#20351;&#29992;&#37319;&#26679;&#26469;&#36817;&#20284;&#26680;&#21367;&#31215;&#12290;&#25105;&#20204;&#22312;&#19981;&#21516;&#38382;&#39064;&#19978;&#23637;&#31034;&#20102;&#24555;&#36895;&#25910;&#25947;&#65292;&#24182;&#19988;&#19982;&#26410;&#35843;&#25972;Langevin&#31639;&#27861;&#21644;Metropolis&#35843;&#25972;Langevin&#31639;&#27861;&#30456;&#27604;&#65292;&#26174;&#31034;&#20102;&#39640;&#26031;&#20998;&#24067;&#30340;&#28151;&#21512;&#26102;&#38388;&#36793;&#30028;&#30340;&#25913;&#21892;&#32500;&#24230;&#20381;&#36182;&#24615;&#12290;&#25105;&#20204;&#36824;&#25512;&#23548;&#20102;&#20108;&#27425;&#28508;&#21183;&#20989;&#25968;&#27599;&#27425;&#36845;&#20195;&#30340;&#20998;&#24067;&#30340;&#38381;&#21512;&#24418;&#24335;&#34920;&#36798;&#24335;&#65292;&#34920;&#24449;&#20102;&#26041;&#24046;&#38477;&#20302;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#31890;&#23376;&#30340;&#34892;&#20026;&#26159;&#26377;&#32452;&#32455;&#30340;&#65292;&#20301;&#20110;&#28508;&#21183;&#30340;&#31561;&#20540;&#32447;&#19978;&#12290;&#27492;&#22806;&#65292;&#21518;&#39564;&#22343;&#20540;&#20272;&#35745;&#32467;&#26524;&#26174;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of sampling from a distribution governed by a potential function. This work proposes an explicit score-based MCMC method that is deterministic, resulting in a deterministic evolution for particles rather than a stochastic differential equation evolution. The score term is given in closed form by a regularized Wasserstein proximal, using a kernel convolution that is approximated by sampling. We demonstrate fast convergence on various problems and show improved dimensional dependence of mixing time bounds for the case of Gaussian distributions compared to the unadjusted Langevin algorithm (ULA) and the Metropolis-adjusted Langevin algorithm (MALA). We additionally derive closed form expressions for the distributions at each iterate for quadratic potential functions, characterizing the variance reduction. Empirical results demonstrate that the particles behave in an organized manner, lying on level set contours of the potential. Moreover, the posterior mean estimat
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#31561;&#28183;&#24615;&#30340;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#36870;&#25193;&#25955;&#36807;&#31243;&#23454;&#29616;&#20102;&#26032;&#39062;&#30340;&#21518;&#39564;&#37319;&#26679;&#31639;&#27861;&#65292;&#22312;&#39640;&#32500;&#37319;&#26679;&#20013;&#34920;&#29616;&#20986;&#26356;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.02037</link><description>&lt;p&gt;
&#26080;&#31561;&#28183;&#24615;&#30340;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#65306;&#19968;&#31181;&#36870;&#25193;&#25955;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Monte Carlo Sampling without Isoperimetry: A Reverse Diffusion Approach. (arXiv:2307.02037v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02037
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#31561;&#28183;&#24615;&#30340;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#36870;&#25193;&#25955;&#36807;&#31243;&#23454;&#29616;&#20102;&#26032;&#39062;&#30340;&#21518;&#39564;&#37319;&#26679;&#31639;&#27861;&#65292;&#22312;&#39640;&#32500;&#37319;&#26679;&#20013;&#34920;&#29616;&#20986;&#26356;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#29983;&#25104;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#36890;&#24120;&#21462;&#20915;&#20110;&#25193;&#25955;&#36335;&#24452;&#19978;&#24471;&#20998;&#20272;&#35745;&#30340;&#31934;&#24230;&#65292;&#37325;&#28857;&#20851;&#27880;&#25193;&#25955;&#27169;&#22411;&#21450;&#20854;&#29983;&#25104;&#39640;&#36136;&#37327;&#25968;&#25454;&#26679;&#26412;&#30340;&#33021;&#21147;&#12290;&#26412;&#30740;&#31350;&#28145;&#20837;&#25506;&#35752;&#20102;&#36890;&#36807;&#36870;&#25193;&#25955;&#36827;&#34892;&#21518;&#39564;&#37319;&#26679;&#30340;&#28508;&#21147;&#12290;&#36890;&#36807;&#23545;&#37319;&#26679;&#25991;&#29486;&#36827;&#34892;&#30740;&#31350;&#65292;&#21457;&#29616;&#21487;&#20197;&#36890;&#36807;&#36716;&#31227;&#26680;&#30340;&#20998;&#35299;&#23558;&#24471;&#20998;&#20272;&#35745;&#36716;&#21270;&#20026;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#12290;&#36890;&#36807;&#20272;&#35745;&#36741;&#21161;&#20998;&#24067;&#30340;&#22343;&#20540;&#65292;&#36870;&#25193;&#25955;&#36807;&#31243;&#21487;&#20197;&#20135;&#29983;&#19968;&#31181;&#26032;&#39062;&#30340;&#21518;&#39564;&#37319;&#26679;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#19982;&#20256;&#32479;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#65288;MCMC&#65289;&#26041;&#27861;&#19981;&#21516;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#24635;&#21464;&#24046;&#36317;&#31163;&#19979;&#30340;&#25910;&#25947;&#20998;&#26512;&#65292;&#24182;&#35777;&#26126;&#20102;&#25152;&#25552;&#31639;&#27861;&#30340;&#31561;&#28183;&#24615;&#20381;&#36182;&#24615;&#30456;&#23545;&#36739;&#20302;&#65292;&#27604;&#20256;&#32479;&#30340;MCMC&#25216;&#26415;&#34920;&#29616;&#20986;&#26356;&#39640;&#30340;&#39640;&#32500;&#37319;&#26679;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The efficacy of modern generative models is commonly contingent upon the precision of score estimation along the diffusion path, with a focus on diffusion models and their ability to generate high-quality data samples. This study delves into the potentialities of posterior sampling through reverse diffusion. An examination of the sampling literature reveals that score estimation can be transformed into a mean estimation problem via the decomposition of the transition kernel. By estimating the mean of the auxiliary distribution, the reverse diffusion process can give rise to a novel posterior sampling algorithm, which diverges from traditional gradient-based Markov Chain Monte Carlo (MCMC) methods. We provide the convergence analysis in total variation distance and demonstrate that the isoperimetric dependency of the proposed algorithm is comparatively lower than that observed in conventional MCMC techniques, which justifies the superior performance for high dimensional sampling with er
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22797;&#26434;&#25968;&#25454;&#38598;&#20013;&#30340;&#24213;&#23618;&#32553;&#25918;&#23450;&#24459;&#21644;&#26222;&#36866;&#32479;&#35745;&#32467;&#26500;&#12290;&#36890;&#36807;&#23558;&#25968;&#25454;&#31867;&#27604;&#20026;&#29289;&#29702;&#31995;&#32479;&#65292;&#24182;&#24212;&#29992;&#32479;&#35745;&#29289;&#29702;&#23398;&#21644;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#26041;&#27861;&#65292;&#25581;&#31034;&#20102;&#29305;&#24449;-&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#23616;&#37096;&#21644;&#20840;&#23616;&#29305;&#24449;&#20540;&#32479;&#35745;&#37327;&#30340;&#35268;&#24459;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#26080;&#20851;&#38543;&#26426;&#25968;&#25454;&#21644;&#30495;&#23454;&#25968;&#25454;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#24341;&#20837;&#38271;&#31243;&#30456;&#20851;&#24615;&#23436;&#20840;&#24674;&#22797;&#32553;&#25918;&#34892;&#20026;&#12290;&#21516;&#26102;&#65292;&#29983;&#25104;&#30340;&#25968;&#25454;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#37117;&#23646;&#20110;&#28151;&#27788;&#31995;&#32479;&#65292;&#24182;&#22312;&#36739;&#23567;&#30340;&#25968;&#25454;&#38598;&#22823;&#23567;&#19978;&#21363;&#21487;&#20307;&#29616;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#32479;&#35745;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2306.14975</link><description>&lt;p&gt;
&#22797;&#26434;&#25968;&#25454;&#38598;&#30340;&#24213;&#23618;&#32553;&#25918;&#23450;&#24459;&#21644;&#26222;&#36866;&#32479;&#35745;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
The Underlying Scaling Laws and Universal Statistical Structure of Complex Datasets. (arXiv:2306.14975v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14975
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22797;&#26434;&#25968;&#25454;&#38598;&#20013;&#30340;&#24213;&#23618;&#32553;&#25918;&#23450;&#24459;&#21644;&#26222;&#36866;&#32479;&#35745;&#32467;&#26500;&#12290;&#36890;&#36807;&#23558;&#25968;&#25454;&#31867;&#27604;&#20026;&#29289;&#29702;&#31995;&#32479;&#65292;&#24182;&#24212;&#29992;&#32479;&#35745;&#29289;&#29702;&#23398;&#21644;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#26041;&#27861;&#65292;&#25581;&#31034;&#20102;&#29305;&#24449;-&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#23616;&#37096;&#21644;&#20840;&#23616;&#29305;&#24449;&#20540;&#32479;&#35745;&#37327;&#30340;&#35268;&#24459;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#26080;&#20851;&#38543;&#26426;&#25968;&#25454;&#21644;&#30495;&#23454;&#25968;&#25454;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#24341;&#20837;&#38271;&#31243;&#30456;&#20851;&#24615;&#23436;&#20840;&#24674;&#22797;&#32553;&#25918;&#34892;&#20026;&#12290;&#21516;&#26102;&#65292;&#29983;&#25104;&#30340;&#25968;&#25454;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#37117;&#23646;&#20110;&#28151;&#27788;&#31995;&#32479;&#65292;&#24182;&#22312;&#36739;&#23567;&#30340;&#25968;&#25454;&#38598;&#22823;&#23567;&#19978;&#21363;&#21487;&#20307;&#29616;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#32479;&#35745;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#22797;&#26434;&#25968;&#25454;&#38598;&#21644;&#20154;&#24037;&#29983;&#25104;&#30340;&#25968;&#25454;&#38598;&#20013;&#37117;&#20986;&#29616;&#30340;&#26222;&#36941;&#29305;&#24449;&#12290;&#25105;&#20204;&#23558;&#25968;&#25454;&#31867;&#27604;&#20026;&#29289;&#29702;&#31995;&#32479;&#65292;&#24182;&#21033;&#29992;&#32479;&#35745;&#29289;&#29702;&#23398;&#21644;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#24037;&#20855;&#25581;&#31034;&#20854;&#24213;&#23618;&#32467;&#26500;&#12290;&#25105;&#20204;&#37325;&#28857;&#20998;&#26512;&#20102;&#29305;&#24449;-&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#20998;&#26512;&#20102;&#20854;&#23616;&#37096;&#21644;&#20840;&#23616;&#29305;&#24449;&#20540;&#32479;&#35745;&#37327;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#35266;&#23519;&#32467;&#26524;&#26159;&#65306;(i) &#22823;&#37096;&#20998;&#29305;&#24449;&#20540;&#21576;&#29616;&#30340;&#24130;&#24459;&#32553;&#25918;&#22312;&#26080;&#30456;&#20851;&#38543;&#26426;&#25968;&#25454;&#21644;&#30495;&#23454;&#25968;&#25454;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;(ii) &#36890;&#36807;&#31616;&#21333;&#22320;&#24341;&#20837;&#38271;&#31243;&#30456;&#20851;&#24615;&#65292;&#21487;&#20197;&#23436;&#20840;&#24674;&#22797;&#36825;&#31181;&#32553;&#25918;&#34892;&#20026;&#21040;&#21512;&#25104;&#25968;&#25454;&#20013;&#65292;(iii) &#20174;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#35282;&#24230;&#30475;&#65292;&#29983;&#25104;&#30340;&#25968;&#25454;&#38598;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#23646;&#20110;&#21516;&#19968;&#20010;&#26222;&#36866;&#24615;&#31867;&#21035;&#65292;&#37117;&#26159;&#28151;&#27788;&#31995;&#32479;&#32780;&#38750;&#21487;&#31215;&#31995;&#32479;&#65292;(iv) &#39044;&#26399;&#30340;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#32479;&#35745;&#34892;&#20026;&#22312;&#30456;&#23545;&#36739;&#23567;&#30340;&#25968;&#25454;&#38598;&#22823;&#23567;&#19978;&#23601;&#24050;&#32463;&#22312;&#32463;&#39564;&#21327;&#26041;&#24046;&#30697;&#38453;&#20013;&#24471;&#21040;&#20307;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study universal traits which emerge both in real-world complex datasets, as well as in artificially generated ones. Our approach is to analogize data to a physical system and employ tools from statistical physics and Random Matrix Theory (RMT) to reveal their underlying structure. We focus on the feature-feature covariance matrix, analyzing both its local and global eigenvalue statistics. Our main observations are: (i) The power-law scalings that the bulk of its eigenvalues exhibit are vastly different for uncorrelated random data compared to real-world data, (ii) this scaling behavior can be completely recovered by introducing long range correlations in a simple way to the synthetic data, (iii) both generated and real-world datasets lie in the same universality class from the RMT perspective, as chaotic rather than integrable systems, (iv) the expected RMT statistical behavior already manifests for empirical covariance matrices at dataset sizes significantly smaller than those conv
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#38024;&#23545;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#35774;&#35745;&#20102;&#38750;&#28176;&#36827;&#29702;&#35770;&#65292;&#25552;&#20986;&#20102;&#38024;&#23545;&#20004;&#31181;&#20027;&#27969;&#37319;&#26679;&#22120;&#30340;&#26032;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#25552;&#39640;&#20102;&#24635;&#27493;&#25968;&#19982;&#25910;&#25947;&#36895;&#24230;&#30340;&#27604;&#20363;&#12290;</title><link>http://arxiv.org/abs/2306.09251</link><description>&lt;p&gt;
&#38754;&#21521;&#25193;&#25955;&#24335;&#29983;&#25104;&#27169;&#22411;&#30340;&#38750;&#28176;&#36827;&#24555;&#36895;&#25910;&#25947;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Towards Faster Non-Asymptotic Convergence for Diffusion-Based Generative Models. (arXiv:2306.09251v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09251
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#38024;&#23545;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#35774;&#35745;&#20102;&#38750;&#28176;&#36827;&#29702;&#35770;&#65292;&#25552;&#20986;&#20102;&#38024;&#23545;&#20004;&#31181;&#20027;&#27969;&#37319;&#26679;&#22120;&#30340;&#26032;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#25552;&#39640;&#20102;&#24635;&#27493;&#25968;&#19982;&#25910;&#25947;&#36895;&#24230;&#30340;&#27604;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#36890;&#36807;&#23398;&#20064;&#21453;&#36716;&#39532;&#23572;&#21487;&#22827;&#25193;&#25955;&#36807;&#31243;&#23558;&#22122;&#38899;&#36716;&#21270;&#20026;&#26032;&#25968;&#25454;&#23454;&#20363;&#65292;&#22312;&#24403;&#20195;&#29983;&#25104;&#24314;&#27169;&#39046;&#22495;&#20013;&#24050;&#25104;&#20026;&#22522;&#30707;&#12290;&#34429;&#28982;&#23427;&#20204;&#30340;&#23454;&#29992;&#24615;&#29616;&#22312;&#24050;&#34987;&#24191;&#27867;&#35748;&#21487;&#65292;&#20294;&#20854;&#29702;&#35770;&#22522;&#30784;&#20173;&#28982;&#19981;&#22815;&#25104;&#29087;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#22871;&#38750;&#28176;&#36827;&#29702;&#35770;&#65292;&#20197;&#29702;&#35299;&#31163;&#25955;&#26102;&#38388;&#19979;&#25193;&#25955;&#27169;&#22411;&#30340;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#65292;&#20551;&#35774;&#21487;&#20197;&#33719;&#24471;&#65288;Stein&#65289;&#24471;&#20998;&#20989;&#25968;&#30340;&#21487;&#38752;&#20272;&#35745;&#12290;&#38024;&#23545;&#19968;&#31181;&#27969;&#34892;&#30340;&#30830;&#23450;&#24615;&#37319;&#26679;&#22120;&#65288;&#22522;&#20110;&#27010;&#29575;&#27969;ODE&#65289;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#19982; $T$&#65288;&#24635;&#27493;&#25968;&#65289;&#25104;&#27604;&#20363;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#25913;&#36827;&#20102;&#36807;&#21435;&#30340;&#32467;&#26524;&#65307;&#23545;&#20110;&#21478;&#19968;&#31181;&#20027;&#27969;&#30340;&#38543;&#26426;&#37319;&#26679;&#22120;&#65288;&#21363;&#19968;&#31181;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DDPM&#65289;&#65289;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;&#19968;&#20010;&#19982; $1/\sqrt{T}$ &#25104;&#27604;&#20363;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#19982;&#26368;&#20808;&#36827;&#30340;&#29702;&#35770;&#30456;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#23545;&#30446;&#26631;&#25968;&#25454;&#20998;&#24067;&#21482;&#20316;&#20986;&#26368;&#23567;&#30340;&#20551;&#35774;&#65288;&#20363;&#22914;&#65292;&#27809;&#26377;&#24179;&#28369;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models, which convert noise into new data instances by learning to reverse a Markov diffusion process, have become a cornerstone in contemporary generative modeling. While their practical power has now been widely recognized, the theoretical underpinnings remain far from mature. In this work, we develop a suite of non-asymptotic theory towards understanding the data generation process of diffusion models in discrete time, assuming access to reliable estimates of the (Stein) score functions. For a popular deterministic sampler (based on the probability flow ODE), we establish a convergence rate proportional to $1/T$ (with $T$ the total number of steps), improving upon past results; for another mainstream stochastic sampler (i.e., a type of the denoising diffusion probabilistic model (DDPM)), we derive a convergence rate proportional to $1/\sqrt{T}$, matching the state-of-the-art theory. Our theory imposes only minimal assumptions on the target data distribution (e.g., no smoot
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;SGD-like&#31639;&#27861;&#65292;&#27880;&#20837;&#38543;&#26426;&#22122;&#22768;&#24182;&#21033;&#29992;&#20998;&#24067;&#23545;&#31216;&#24615;&#26469;&#20943;&#23569;&#26041;&#24046;&#65292;&#20197;&#23547;&#25214;&#20855;&#26377;&#20302;&#28023;&#26862;&#30697;&#38453;&#36857;&#30340;&#24179;&#22374;&#26497;&#23567;&#20540;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#25910;&#25947;&#36895;&#29575;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2306.08553</link><description>&lt;p&gt;
&#22122;&#22768;&#31283;&#23450;&#20248;&#21270;&#23545;&#20110;&#20855;&#26377;&#26368;&#20248;&#25910;&#25947;&#29575;&#30340;&#24179;&#22374;&#26497;&#23567;&#20540;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Noise Stability Optimization for Flat Minima with Optimal Convergence Rates. (arXiv:2306.08553v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08553
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;SGD-like&#31639;&#27861;&#65292;&#27880;&#20837;&#38543;&#26426;&#22122;&#22768;&#24182;&#21033;&#29992;&#20998;&#24067;&#23545;&#31216;&#24615;&#26469;&#20943;&#23569;&#26041;&#24046;&#65292;&#20197;&#23547;&#25214;&#20855;&#26377;&#20302;&#28023;&#26862;&#30697;&#38453;&#36857;&#30340;&#24179;&#22374;&#26497;&#23567;&#20540;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#25910;&#25947;&#36895;&#29575;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#36890;&#36807;&#21152;&#20837;&#21152;&#26435;&#25200;&#21160;&#26469;&#25214;&#21040;&#24179;&#22374;&#30340;&#26497;&#23567;&#20540;&#12290;&#32473;&#23450;&#19968;&#20010;&#38750;&#20984;&#20989;&#25968;$f:\mathbb{R}^d\rightarrow \mathbb{R}$&#21644;&#19968;&#20010;$d$&#32500;&#20998;&#24067;$\mathcal{P}$&#65292;&#25105;&#20204;&#25200;&#21160;$f$&#30340;&#26435;&#37325;&#65292;&#24182;&#23450;&#20041;$F(W)=\mathbb{E}[f({W+U})]$&#65292;&#20854;&#20013;$U$&#26159;&#19968;&#20010;&#20174;$\mathcal{P}$&#20013;&#38543;&#26426;&#25277;&#21462;&#30340;&#26679;&#26412;&#12290;&#36825;&#20010;&#36807;&#31243;&#36890;&#36807;$f$&#30340;&#28023;&#26862;&#30697;&#38453;&#30340;&#36857;&#26469;&#35825;&#23548;&#27491;&#21017;&#21270;&#65292;&#20197;&#36866;&#24212;&#20110;&#23567;&#30340;&#12289;&#21508;&#21521;&#21516;&#24615;&#30340;&#39640;&#26031;&#25200;&#21160;&#12290;&#22240;&#27492;&#65292;&#21152;&#26435;&#25200;&#21160;&#30340;&#20989;&#25968;&#20559;&#21521;&#20110;&#24102;&#26377;&#20302;&#28023;&#26862;&#30697;&#38453;&#36857;&#30340;&#26497;&#23567;&#20540;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31867;&#20284;&#20110;SGD&#30340;&#31639;&#27861;&#65292;&#22312;&#35745;&#31639;&#26799;&#24230;&#20043;&#21069;&#27880;&#20837;&#38543;&#26426;&#22122;&#22768;&#65292;&#21516;&#26102;&#21033;&#29992;$\mathcal{P}$&#30340;&#23545;&#31216;&#24615;&#26469;&#20943;&#23569;&#26041;&#24046;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;...
&lt;/p&gt;
&lt;p&gt;
We consider finding flat, local minimizers by adding average weight perturbations. Given a nonconvex function $f: \mathbb{R}^d \rightarrow \mathbb{R}$ and a $d$-dimensional distribution $\mathcal{P}$ which is symmetric at zero, we perturb the weight of $f$ and define $F(W) = \mathbb{E}[f({W + U})]$, where $U$ is a random sample from $\mathcal{P}$. This injection induces regularization through the Hessian trace of $f$ for small, isotropic Gaussian perturbations. Thus, the weight-perturbed function biases to minimizers with low Hessian trace. Several prior works have studied settings related to this weight-perturbed function by designing algorithms to improve generalization. Still, convergence rates are not known for finding minima under the average perturbations of the function $F$. This paper considers an SGD-like algorithm that injects random noise before computing gradients while leveraging the symmetry of $\mathcal{P}$ to reduce variance. We then provide a rigorous analysis, showing
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#30340;&#21464;&#20998;&#19981;&#24179;&#34913;&#22238;&#24402;&#65288;VIR&#65289;&#27169;&#22411;&#36890;&#36807;&#24341;&#20837;Probabilistic Reweighting&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#24179;&#34913;&#22238;&#24402;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#33258;&#28982;&#20135;&#29983;&#21512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2306.06599</link><description>&lt;p&gt;
&#21464;&#20998;&#19981;&#24179;&#34913;&#22238;&#24402;(Variational Imbalanced Regression)
&lt;/p&gt;
&lt;p&gt;
Variational Imbalanced Regression. (arXiv:2306.06599v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06599
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#30340;&#21464;&#20998;&#19981;&#24179;&#34913;&#22238;&#24402;&#65288;VIR&#65289;&#27169;&#22411;&#36890;&#36807;&#24341;&#20837;Probabilistic Reweighting&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#24179;&#34913;&#22238;&#24402;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#33258;&#28982;&#20135;&#29983;&#21512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#26631;&#31614;&#20998;&#24067;&#19981;&#24179;&#34913;&#26102;&#65292;&#29616;&#26377;&#30340;&#22238;&#24402;&#27169;&#22411;&#24448;&#24448;&#22312;&#20934;&#30830;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26041;&#38754;&#34920;&#29616;&#19981;&#20339;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#29575;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#8212;&#8212;&#21464;&#20998;&#19981;&#24179;&#34913;&#22238;&#24402;&#65288;VIR&#65289;&#65292;&#23427;&#19981;&#20165;&#22312;&#19981;&#24179;&#34913;&#22238;&#24402;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#32780;&#19988;&#33258;&#28982;&#22320;&#20135;&#29983;&#21512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#19982;&#20856;&#22411;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#20551;&#35774;I.I.D.&#34920;&#31034;&#65288;&#25968;&#25454;&#28857;&#30340;&#34920;&#31034;&#19981;&#30452;&#25509;&#21463;&#20854;&#20182;&#25968;&#25454;&#28857;&#30340;&#24433;&#21709;&#65289;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;VIR&#20511;&#29992;&#20855;&#26377;&#31867;&#20284;&#22238;&#24402;&#26631;&#31614;&#30340;&#25968;&#25454;&#26469;&#35745;&#31639;&#28508;&#22312;&#34920;&#31034;&#30340;&#21464;&#20998;&#20998;&#24067;&#65307;&#27492;&#22806;&#65292;&#19981;&#21516;&#20110;&#20135;&#29983;&#28857;&#20272;&#35745;&#30340;&#30830;&#23450;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292; VIR&#39044;&#27979;&#25972;&#20010;&#27491;&#24577;&#21453;-&#20285;&#29595;&#20998;&#24067;&#24182;&#35843;&#33410;&#30456;&#20851;&#32852;&#30340;&#20849;&#36717;&#20998;&#24067;&#65292;&#23545;&#19981;&#24179;&#34913;&#25968;&#25454;&#26045;&#21152;&#27010;&#29575;&#37325;&#26032;&#21152;&#26435;&#65292;&#20174;&#32780;&#25552;&#20379;&#26356;&#22909;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#22312;&#20960;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing regression models tend to fall short in both accuracy and uncertainty estimation when the label distribution is imbalanced. In this paper, we propose a probabilistic deep learning model, dubbed variational imbalanced regression (VIR), which not only performs well in imbalanced regression but naturally produces reasonable uncertainty estimation as a byproduct. Different from typical variational autoencoders assuming I.I.D. representations (a data point's representation is not directly affected by other data points), our VIR borrows data with similar regression labels to compute the latent representation's variational distribution; furthermore, different from deterministic regression models producing point estimates, VIR predicts the entire normal-inverse-gamma distributions and modulates the associated conjugate distributions to impose probabilistic reweighting on the imbalanced data, thereby providing better uncertainty estimation. Experiments in several real-world datasets sh
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;RKHS&#36924;&#36817;&#26041;&#27861;&#65292;&#25581;&#31034;&#20102;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#20013;&#22909;&#30340;&#25968;&#25454;&#22686;&#24378;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#38416;&#36848;&#20102;&#23545;&#20110;&#20219;&#24847;&#32534;&#30721;&#22120;&#65292;&#22686;&#24191;&#20989;&#25968;&#36136;&#37327;&#30340;&#25552;&#21319;&#21487;&#20197;&#25552;&#39640;&#32534;&#30721;&#22120;&#30340;&#34920;&#31034;&#33021;&#21147;&#65292;&#21516;&#26102;&#20998;&#26512;&#20102;&#25209;&#37327;&#24402;&#19968;&#21270;&#21644;&#25968;&#25454;&#22686;&#24378;&#22312;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2306.00788</link><description>&lt;p&gt;
&#36890;&#36807;RKHS&#36924;&#36817;&#29702;&#35299;&#22522;&#20110;&#22686;&#24191;&#30340;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Understanding Augmentation-based Self-Supervised Representation Learning via RKHS Approximation. (arXiv:2306.00788v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00788
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;RKHS&#36924;&#36817;&#26041;&#27861;&#65292;&#25581;&#31034;&#20102;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#20013;&#22909;&#30340;&#25968;&#25454;&#22686;&#24378;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#38416;&#36848;&#20102;&#23545;&#20110;&#20219;&#24847;&#32534;&#30721;&#22120;&#65292;&#22686;&#24191;&#20989;&#25968;&#36136;&#37327;&#30340;&#25552;&#21319;&#21487;&#20197;&#25552;&#39640;&#32534;&#30721;&#22120;&#30340;&#34920;&#31034;&#33021;&#21147;&#65292;&#21516;&#26102;&#20998;&#26512;&#20102;&#25209;&#37327;&#24402;&#19968;&#21270;&#21644;&#25968;&#25454;&#22686;&#24378;&#22312;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22909;&#30340;&#25968;&#25454;&#22686;&#24378;&#26159;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#65288;&#22914;&#23545;&#27604;&#23398;&#20064;&#21644;&#25513;&#30721;&#35821;&#35328;&#24314;&#27169;&#65289;&#23454;&#29616;&#32463;&#39564;&#25104;&#21151;&#30340;&#20851;&#38190;&#22240;&#32032;&#20043;&#19968;&#65292;&#20294;&#20854;&#22312;&#23398;&#20064;&#22909;&#30340;&#34920;&#31034;&#26041;&#38754;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#26377;&#38480;&#12290;&#26368;&#36817;&#30340;&#24037;&#20316;&#24314;&#31435;&#20102;&#33258;&#30417;&#30563;&#23398;&#20064;&#21644;&#36924;&#36817;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#30340;&#39030;&#37096;&#29305;&#24449;&#31354;&#38388;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#19968;&#27934;&#23519;&#21147;&#23545;&#22522;&#20110;&#22686;&#24191;&#30340;&#39044;&#35757;&#32451;&#36827;&#34892;&#32479;&#35745;&#20998;&#26512;&#12290;&#25105;&#20204;&#20174;&#20445;&#25345;&#31561;&#36317;&#30340;&#23646;&#24615;&#20986;&#21457;&#65292;&#36825;&#26159;&#30001;&#22686;&#24378;&#32473;&#20986;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;&#20851;&#38190;&#20960;&#20309;&#29305;&#24449;&#12290;&#25105;&#20204;&#30340;&#31532;&#19968;&#20027;&#35201;&#23450;&#29702;&#20026;&#20219;&#24847;&#32534;&#30721;&#22120;&#25552;&#20379;&#20102;&#25509;&#36817;&#32039;&#23494;&#30340;&#19978;&#38480;&#65292;&#29992;&#20110;&#20272;&#35745;&#36890;&#36807;&#22312;&#32534;&#30721;&#22120;&#20043;&#19978;&#25311;&#21512;&#32447;&#24615;&#25506;&#27979;&#22120;&#32780;&#20135;&#29983;&#30340;&#20272;&#35745;&#35823;&#24046;&#21644;&#32534;&#30721;&#22120;&#23398;&#20064;&#30340;RKHS&#30340;&#36924;&#36817;&#35823;&#24046;&#12290;&#25105;&#20204;&#30340;&#31532;&#20108;&#20010;&#20027;&#35201;&#23450;&#29702;&#34920;&#26126;&#65292;&#22312;&#28201;&#21644;&#26465;&#20214;&#19979;&#65292;&#21487;&#20197;&#36890;&#36807;RKHS&#20989;&#25968;&#20219;&#24847;&#31934;&#30830;&#22320;&#36924;&#36817;&#22686;&#24191;&#20989;&#25968;&#12290;&#36825;&#20010;&#32467;&#26524;&#24847;&#21619;&#30528;&#65292;&#38543;&#30528;&#22686;&#24191;&#20989;&#25968;&#36136;&#37327;&#30340;&#25552;&#39640;&#65292;&#23398;&#20064;&#30340;&#32534;&#30721;&#22120;&#30340;&#34920;&#31034;&#33021;&#21147;&#20063;&#20250;&#25552;&#39640;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#36824;&#25581;&#31034;&#20102;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#25209;&#37327;&#24402;&#19968;&#21270;&#21644;&#25968;&#25454;&#22686;&#24378;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Good data augmentation is one of the key factors that lead to the empirical success of self-supervised representation learning such as contrastive learning and masked language modeling, yet theoretical understanding of its role in learning good representations remains limited. Recent work has built the connection between self-supervised learning and approximating the top eigenspace of a graph Laplacian operator. Learning a linear probe on top of such features can naturally be connected to RKHS regression. In this work, we use this insight to perform a statistical analysis of augmentation-based pretraining. We start from the isometry property, a key geometric characterization of the target function given by the augmentation. Our first main theorem provides, for an arbitrary encoder, near tight bounds for both the estimation error incurred by fitting the linear probe on top of the encoder, and the approximation error entailed by the fitness of the RKHS the encoder learns. Our second main
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#20960;&#20309;&#32467;&#26500;&#65292;&#21457;&#29616;&#36890;&#36807;&#19968;&#20010;&#26126;&#30830;&#30340;&#20934;&#32447;&#24615;&#37319;&#26679;&#36712;&#36857;&#21644;&#21478;&#19968;&#20010;&#38544;&#24335;&#30340;&#21435;&#22122;&#36712;&#36857;&#24179;&#28369;&#36830;&#25509;&#20102;&#25968;&#25454;&#20998;&#24067;&#21644;&#22122;&#22768;&#20998;&#24067;&#65292;&#24314;&#31435;&#20102;&#22522;&#20110;ODE&#30340;&#26368;&#20248;&#37319;&#26679;&#21644;&#32463;&#20856;&#30340;&#22343;&#20540;&#28418;&#31227;&#31639;&#27861;&#20043;&#38388;&#30340;&#29702;&#35770;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2305.19947</link><description>&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#30340;&#20960;&#20309;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
A Geometric Perspective on Diffusion Models. (arXiv:2305.19947v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19947
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#20960;&#20309;&#32467;&#26500;&#65292;&#21457;&#29616;&#36890;&#36807;&#19968;&#20010;&#26126;&#30830;&#30340;&#20934;&#32447;&#24615;&#37319;&#26679;&#36712;&#36857;&#21644;&#21478;&#19968;&#20010;&#38544;&#24335;&#30340;&#21435;&#22122;&#36712;&#36857;&#24179;&#28369;&#36830;&#25509;&#20102;&#25968;&#25454;&#20998;&#24067;&#21644;&#22122;&#22768;&#20998;&#24067;&#65292;&#24314;&#31435;&#20102;&#22522;&#20110;ODE&#30340;&#26368;&#20248;&#37319;&#26679;&#21644;&#32463;&#20856;&#30340;&#22343;&#20540;&#28418;&#31227;&#31639;&#27861;&#20043;&#38388;&#30340;&#29702;&#35770;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#38024;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#39640;&#25928;&#35757;&#32451;&#21644;&#24555;&#36895;&#37319;&#26679;&#26041;&#27861;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#12290;&#26368;&#36817;&#30340;&#19968;&#20010;&#37325;&#35201;&#36827;&#23637;&#26159;&#20351;&#29992;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#26469;&#25551;&#36848;&#25968;&#25454;&#25200;&#21160;&#21644;&#29983;&#25104;&#24314;&#27169;&#65292;&#20197;&#23454;&#29616;&#32479;&#19968;&#30340;&#25968;&#23398;&#26694;&#26550;&#12290;&#26412;&#25991;&#25581;&#31034;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#20960;&#20010;&#26377;&#36259;&#30340;&#20960;&#20309;&#32467;&#26500;&#65292;&#24182;&#20026;&#20854;&#37319;&#26679;&#21160;&#21147;&#23398;&#25552;&#20379;&#20102;&#31616;&#21333;&#32780;&#24378;&#22823;&#30340;&#35299;&#37322;&#12290;&#36890;&#36807;&#20180;&#32454;&#26816;&#26597;&#19968;&#31181;&#27969;&#34892;&#30340;&#26041;&#24046;&#29190;&#28856;SDE&#21450;&#20854;&#20445;&#25345;&#36793;&#38469;&#30340;&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#29992;&#20110;&#37319;&#26679;&#65292;&#25105;&#20204;&#21457;&#29616;&#25968;&#25454;&#20998;&#24067;&#21644;&#22122;&#22768;&#20998;&#24067;&#36890;&#36807;&#19968;&#20010;&#26126;&#30830;&#30340;&#20934;&#32447;&#24615;&#37319;&#26679;&#36712;&#36857;&#21644;&#21478;&#19968;&#20010;&#38544;&#24335;&#30340;&#21435;&#22122;&#36712;&#36857;&#24179;&#28369;&#36830;&#25509;&#65292;&#21363;&#20351;&#22312;&#35270;&#35273;&#36136;&#37327;&#26041;&#38754;&#20063;&#25910;&#25947;&#26356;&#24555;&#12290;&#25105;&#20204;&#36824;&#24314;&#31435;&#36215;&#22522;&#20110;ODE&#30340;&#26368;&#20248;&#37319;&#26679;&#21644;&#32463;&#20856;&#30340;&#22343;&#20540;&#28418;&#31227;&#65288;&#23547;&#25214;&#27169;&#24335;&#65289;&#31639;&#27861;&#20043;&#38388;&#30340;&#29702;&#35770;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent years have witnessed significant progress in developing efficient training and fast sampling approaches for diffusion models. A recent remarkable advancement is the use of stochastic differential equations (SDEs) to describe data perturbation and generative modeling in a unified mathematical framework. In this paper, we reveal several intriguing geometric structures of diffusion models and contribute a simple yet powerful interpretation to their sampling dynamics. Through carefully inspecting a popular variance-exploding SDE and its marginal-preserving ordinary differential equation (ODE) for sampling, we discover that the data distribution and the noise distribution are smoothly connected with an explicit, quasi-linear sampling trajectory, and another implicit denoising trajectory, which even converges faster in terms of visual quality. We also establish a theoretical relationship between the optimal ODE-based sampling and the classic mean-shift (mode-seeking) algorithm, with w
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;PAC-Bayes&#35757;&#32451;&#26694;&#26550;&#65292;&#26080;&#38656;&#39069;&#22806;&#27491;&#21017;&#21270;&#21644;&#32593;&#26684;&#25628;&#32034;&#35843;&#25972;&#36229;&#21442;&#25968;&#21363;&#21487;&#36798;&#21040;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#23218;&#32654;&#30340;&#27979;&#35797;&#24615;&#33021;&#65292;&#26174;&#33879;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#33021;&#21147;&#24182;&#20855;&#26377;&#23454;&#38469;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2305.19243</link><description>&lt;p&gt;
Auto-tune: &#31070;&#32463;&#32593;&#32476;&#30340;&#20808;&#39564;&#19982;&#21518;&#39564;PAC-Bayes&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Auto-tune: PAC-Bayes Optimization over Prior and Posterior for Neural Networks. (arXiv:2305.19243v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19243
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;PAC-Bayes&#35757;&#32451;&#26694;&#26550;&#65292;&#26080;&#38656;&#39069;&#22806;&#27491;&#21017;&#21270;&#21644;&#32593;&#26684;&#25628;&#32034;&#35843;&#25972;&#36229;&#21442;&#25968;&#21363;&#21487;&#36798;&#21040;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#23218;&#32654;&#30340;&#27979;&#35797;&#24615;&#33021;&#65292;&#26174;&#33879;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#33021;&#21147;&#24182;&#20855;&#26377;&#23454;&#38469;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#31934;&#24515;&#35774;&#35745;&#35757;&#32451;&#36807;&#31243;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;&#35757;&#32451;&#26041;&#27861;&#28041;&#21450;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#25110;Adam&#20248;&#21270;&#31639;&#27861;&#65292;&#20197;&#21450;&#39069;&#22806;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#22914;&#26435;&#37325;&#34928;&#20943;&#12289;Dropout&#25110;&#22122;&#22768;&#27880;&#20837;&#12290;&#36890;&#36807;&#32593;&#26684;&#25628;&#32034;&#35843;&#25972;&#25968;&#37327;&#20247;&#22810;&#30340;&#36229;&#21442;&#25968;&#25165;&#33021;&#36798;&#21040;&#26368;&#20248;&#27867;&#21270;&#65292;&#36825;&#21487;&#33021;&#32791;&#26102;&#65292;&#24182;&#38656;&#35201;&#39069;&#22806;&#30340;&#39564;&#35777;&#25968;&#25454;&#38598;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20999;&#23454;&#21487;&#34892;&#30340;PAC-Bayes&#35757;&#32451;&#26694;&#26550;&#65292;&#20960;&#20046;&#26159;&#26080;&#38656;&#35843;&#25972;&#65292;&#20063;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#27491;&#21017;&#21270;&#65292;&#32780;&#22312;&#23436;&#25104;&#32593;&#26684;&#25628;&#32034;&#21644;&#21152;&#20837;&#39069;&#22806;&#27491;&#21017;&#21270;&#21518;&#65292;&#36798;&#21040;&#20102;&#19982;SGD/Adam&#21487;&#27604;&#36739;&#30340;&#27979;&#35797;&#24615;&#33021;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#23637;&#31034;&#20102;PAC&#35757;&#32451;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#19978;&#23454;&#29616;&#26368;&#20808;&#36827;&#24615;&#33021;&#30340;&#26174;&#33879;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is widely recognized that the generalization ability of neural networks can be greatly enhanced through carefully designing the training procedure. The current state-of-the-art training approach involves utilizing stochastic gradient descent (SGD) or Adam optimization algorithms along with a combination of additional regularization techniques such as weight decay, dropout, or noise injection. Optimal generalization can only be achieved by tuning a multitude of hyperparameters through grid search, which can be time-consuming and necessitates additional validation datasets. To address this issue, we introduce a practical PAC-Bayes training framework that is nearly tuning-free and requires no additional regularization while achieving comparable testing performance to that of SGD/Adam after a complete grid search and with extra regularizations. Our proposed algorithm demonstrates the remarkable potential of PAC training to achieve state-of-the-art performance on deep neural networks wit
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#24378;&#21270;&#23398;&#20064;&#20013;&#20154;&#31867;&#21453;&#39304;&#26597;&#35810;&#30340;&#26377;&#25928;&#37319;&#26679;&#26041;&#27861;&#65292;&#20197;&#22312;&#26368;&#23569;&#30340;&#20154;&#31867;&#21453;&#39304;&#19979;&#23398;&#20064;&#26368;&#20339;&#31574;&#30053;&#65292;&#24182;&#21487;&#24212;&#29992;&#20110;&#20855;&#26377;&#32447;&#24615;&#21442;&#25968;&#21270;&#21644;&#26410;&#30693;&#36807;&#28193;&#30340;&#20559;&#22909;&#27169;&#22411;&#65292;&#24182;&#24341;&#20837;&#20102;&#22522;&#20110;&#34892;&#21160;&#27604;&#36739;&#21453;&#39304;&#30340;RLHF&#12290;</title><link>http://arxiv.org/abs/2305.18505</link><description>&lt;p&gt;
&#22914;&#20309;&#26377;&#25928;&#22320;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#36827;&#34892;&#20154;&#31867;&#21453;&#39304;&#26597;&#35810;&#65311;
&lt;/p&gt;
&lt;p&gt;
How to Query Human Feedback Efficiently in RL?. (arXiv:2305.18505v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18505
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#24378;&#21270;&#23398;&#20064;&#20013;&#20154;&#31867;&#21453;&#39304;&#26597;&#35810;&#30340;&#26377;&#25928;&#37319;&#26679;&#26041;&#27861;&#65292;&#20197;&#22312;&#26368;&#23569;&#30340;&#20154;&#31867;&#21453;&#39304;&#19979;&#23398;&#20064;&#26368;&#20339;&#31574;&#30053;&#65292;&#24182;&#21487;&#24212;&#29992;&#20110;&#20855;&#26377;&#32447;&#24615;&#21442;&#25968;&#21270;&#21644;&#26410;&#30693;&#36807;&#28193;&#30340;&#20559;&#22909;&#27169;&#22411;&#65292;&#24182;&#24341;&#20837;&#20102;&#22522;&#20110;&#34892;&#21160;&#27604;&#36739;&#21453;&#39304;&#30340;RLHF&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#31867;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;&#65288;RLHF&#65289;&#26159;&#19968;&#31181;&#33539;&#20363;&#65292;&#22312;&#27492;&#33539;&#20363;&#19979;&#65292;RL&#20195;&#29702;&#23398;&#20064;&#20351;&#29992;&#23545;&#36712;&#36857;&#30340;&#25104;&#23545;&#20248;&#20808;&#32423;&#21453;&#39304;&#26469;&#26368;&#20248;&#21270;&#20219;&#21153;&#65292;&#32780;&#19981;&#26159;&#20351;&#29992;&#26126;&#30830;&#30340;&#22870;&#21169;&#20449;&#21495;&#12290;&#23613;&#31649;RLHF&#22312;&#24494;&#35843;&#35821;&#35328;&#27169;&#22411;&#26041;&#38754;&#24050;&#32463;&#21462;&#24471;&#20102;&#23454;&#29992;&#25104;&#21151;&#65292;&#20294;&#29616;&#26377;&#30340;&#23454;&#35777;&#30740;&#31350;&#24182;&#26410;&#35299;&#20915;&#22914;&#20309;&#39640;&#25928;&#37319;&#26679;&#36712;&#36857;&#23545;&#20197;&#26597;&#35810;&#20154;&#31867;&#21453;&#39304;&#30340;&#25361;&#25112;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#37319;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#33719;&#21462;&#25506;&#32034;&#24615;&#36712;&#36857;&#65292;&#22312;&#25910;&#38598;&#20219;&#20309;&#20154;&#31867;&#21453;&#39304;&#20043;&#21069;&#65292;&#20351;&#23398;&#20064;&#38544;&#34255;&#30340;&#22870;&#21169;&#20989;&#25968;&#26356;&#21152;&#20934;&#30830;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#19982;&#29616;&#26377;&#25991;&#29486;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#32447;&#24615;&#21442;&#25968;&#21270;&#21644;&#26410;&#30693;&#36807;&#28193;&#30340;&#22522;&#20110;&#20559;&#22909;&#27169;&#22411;&#19979;&#23398;&#20064;&#26368;&#20248;&#31574;&#30053;&#25152;&#38656;&#30340;&#20154;&#31867;&#21453;&#39304;&#26356;&#23569;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#32435;&#20837;&#32447;&#24615;&#21644;&#20302;&#31209;MDPs&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#22522;&#20110;&#34892;&#21160;&#27604;&#36739;&#30340;&#21453;&#39304;&#30340;RLHF&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#37319;&#26679;&#26041;&#27861;&#65292;&#20197;&#22312;&#20248;&#21270;&#20855;&#26377;&#26377;&#38480;&#21453;&#39304;&#30340;&#20219;&#21153;&#26102;&#33719;&#24471;&#25506;&#32034;&#24615;&#36712;&#36857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning with Human Feedback (RLHF) is a paradigm in which an RL agent learns to optimize a task using pair-wise preference-based feedback over trajectories, rather than explicit reward signals. While RLHF has demonstrated practical success in fine-tuning language models, existing empirical work does not address the challenge of how to efficiently sample trajectory pairs for querying human feedback. In this study, we propose an efficient sampling approach to acquiring exploratory trajectories that enable accurate learning of hidden reward functions before collecting any human feedback. Theoretical analysis demonstrates that our algorithm requires less human feedback for learning the optimal policy under preference-based models with linear parameterization and unknown transitions, compared to the existing literature. Specifically, our framework can incorporate linear and low-rank MDPs. Additionally, we investigate RLHF with action-based comparison feedback and introduce an
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19982;NMF&#31639;&#27861;&#19968;&#26679;&#31616;&#21333;&#19988;&#21487;&#25193;&#23637;&#30340;K&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#35299;&#20915;&#38750;&#36127;&#20302;&#31209;&#21322;&#23450;&#35268;&#21010;&#38382;&#39064;&#33719;&#24471;&#20102;&#24378;&#22823;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#20445;&#35777;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#31639;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2305.18436</link><description>&lt;p&gt;
&#36890;&#36807;&#38750;&#36127;&#20302;&#31209;&#21322;&#23450;&#35268;&#21010;&#23454;&#29616;&#26368;&#20248;K&#22343;&#20540;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Statistically Optimal K-means Clustering via Nonnegative Low-rank Semidefinite Programming. (arXiv:2305.18436v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18436
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19982;NMF&#31639;&#27861;&#19968;&#26679;&#31616;&#21333;&#19988;&#21487;&#25193;&#23637;&#30340;K&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#35299;&#20915;&#38750;&#36127;&#20302;&#31209;&#21322;&#23450;&#35268;&#21010;&#38382;&#39064;&#33719;&#24471;&#20102;&#24378;&#22823;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#20445;&#35777;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#31639;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
K&#22343;&#20540;&#32858;&#31867;&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#20110;&#22823;&#25968;&#25454;&#38598;&#20013;&#21457;&#29616;&#27169;&#24335;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#12290;&#21322;&#23450;&#35268;&#21010;&#65288;SDP&#65289;&#26494;&#24347;&#26368;&#36817;&#34987;&#25552;&#20986;&#29992;&#20110;&#35299;&#20915;K&#22343;&#20540;&#20248;&#21270;&#38382;&#39064;&#65292;&#20855;&#26377;&#24456;&#24378;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#20445;&#35777;&#12290;&#20294;&#23454;&#29616;SDP&#27714;&#35299;&#22120;&#30340;&#24040;&#22823;&#25104;&#26412;&#20351;&#24471;&#36825;&#20123;&#20445;&#35777;&#26080;&#27861;&#24212;&#29992;&#20110;&#23454;&#38469;&#25968;&#25454;&#38598;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#65288;NMF&#65289;&#26159;&#19968;&#31181;&#31616;&#21333;&#30340;&#32858;&#31867;&#31639;&#27861;&#65292;&#34987;&#26426;&#22120;&#23398;&#20064;&#20174;&#19994;&#32773;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#32570;&#20047;&#22362;&#23454;&#30340;&#32479;&#35745;&#22522;&#30784;&#25110;&#20005;&#26684;&#30340;&#20445;&#35777;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#31181;&#31867;&#20284;&#20110;NMF&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#38750;&#20984;Burer-Monteiro&#20998;&#35299;&#26041;&#27861;&#35299;&#20915;&#21322;&#23450;&#35268;&#21010;&#26494;&#24347;&#30340;K&#22343;&#20540;&#20844;&#24335;&#30340;&#38750;&#36127;&#20302;&#31209;&#38480;&#21046;&#12290;&#25152;&#24471;&#21040;&#30340;&#31639;&#27861;&#19982;&#26368;&#20808;&#36827;&#30340;NMF&#31639;&#27861;&#19968;&#26679;&#31616;&#21333;&#21644;&#21487;&#25193;&#23637;&#65292;&#21516;&#26102;&#20063;&#20139;&#26377;&#19982;SDP&#30456;&#21516;&#30340;&#24378;&#22823;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#20445;&#35777;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;NMF&#31639;&#27861;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#19982;&#26368;&#20808;&#36827;&#30340;SDP&#27714;&#35299;&#22120;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
$K$-means clustering is a widely used machine learning method for identifying patterns in large datasets. Semidefinite programming (SDP) relaxations have recently been proposed for solving the $K$-means optimization problem that enjoy strong statistical optimality guarantees, but the prohibitive cost of implementing an SDP solver renders these guarantees inaccessible to practical datasets. By contrast, nonnegative matrix factorization (NMF) is a simple clustering algorithm that is widely used by machine learning practitioners, but without a solid statistical underpinning nor rigorous guarantees. In this paper, we describe an NMF-like algorithm that works by solving a nonnegative low-rank restriction of the SDP relaxed $K$-means formulation using a nonconvex Burer--Monteiro factorization approach. The resulting algorithm is just as simple and scalable as state-of-the-art NMF algorithms, while also enjoying the same strong statistical optimality guarantees as the SDP. In our experiments,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#21450;&#20854;&#26465;&#20214;&#65292;&#35777;&#26126;&#20102;&#21160;&#24577;&#19979;&#26799;&#24230;&#19979;&#38477;&#21487;&#20197;&#36890;&#36807;&#26377;&#38480;&#25968;&#37327;&#30340;&#22823;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#26469;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#65292;&#24182;&#25214;&#21040;&#20102;&#22810;&#20010;&#21644;&#21333;&#19968;&#26041;&#21521;&#30340;&#26368;&#20339;&#25209;&#37327;&#22823;&#23567;&#65292;&#26377;&#21161;&#20110;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#21644;&#26041;&#21521;&#30340;&#19987;&#19994;&#21270;&#12290;</title><link>http://arxiv.org/abs/2305.18270</link><description>&lt;p&gt;
&#23398;&#20064;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#65306;&#19968;&#27425;(&#24040;&#22823;)&#30340;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning Two-Layer Neural Networks, One (Giant) Step at a Time. (arXiv:2305.18270v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18270
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#21450;&#20854;&#26465;&#20214;&#65292;&#35777;&#26126;&#20102;&#21160;&#24577;&#19979;&#26799;&#24230;&#19979;&#38477;&#21487;&#20197;&#36890;&#36807;&#26377;&#38480;&#25968;&#37327;&#30340;&#22823;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#26469;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#65292;&#24182;&#25214;&#21040;&#20102;&#22810;&#20010;&#21644;&#21333;&#19968;&#26041;&#21521;&#30340;&#26368;&#20339;&#25209;&#37327;&#22823;&#23567;&#65292;&#26377;&#21161;&#20110;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#21644;&#26041;&#21521;&#30340;&#19987;&#19994;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#30740;&#31350;&#20102;&#26377;&#38480;&#25968;&#37327;&#30340;&#22823;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#26377;&#21161;&#20110;&#22312;&#26680;&#24515;&#33539;&#22260;&#20043;&#22806;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#30340;&#26465;&#20214;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#25209;&#37327;&#22823;&#23567;&#21644;&#22810;&#20010;(&#20294;&#26377;&#38480;&#30340;)&#27493;&#39588;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#21333;&#27493;&#39588;&#36807;&#31243;&#65292;&#21457;&#29616;&#25209;&#37327;&#22823;&#23567;&#20026;$n=O(d)$&#21487;&#20197;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#65292;&#20294;&#21482;&#36866;&#21512;&#23398;&#20064;&#21333;&#19968;&#26041;&#21521;&#25110;&#21333;&#32034;&#24341;&#27169;&#22411;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;$n=O(d^2)$&#23545;&#20110;&#23398;&#20064;&#22810;&#20010;&#26041;&#21521;&#21644;&#19987;&#19994;&#21270;&#33267;&#20851;&#37325;&#35201;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#8220;&#30828;&#8221;&#26041;&#21521;&#32570;&#20047;&#21069;$\ell$&#20010;Hermite&#31995;&#25968;&#65292;&#20173;&#26410;&#34987;&#21457;&#29616;&#65292;&#24182;&#19988;&#38656;&#35201;&#25209;&#37327;&#22823;&#23567;&#20026;$n=O(d^\ell)$&#25165;&#33021;&#34987;&#26799;&#24230;&#19979;&#38477;&#25429;&#33719;&#12290;&#32463;&#36807;&#20960;&#27425;&#36845;&#20195;&#65292;&#24773;&#20917;&#21457;&#29983;&#21464;&#21270;&#65306;&#25209;&#37327;&#22823;&#23567;&#20026;$n=O(d)$&#36275;&#20197;&#23398;&#20064;&#26032;&#30340;&#30446;&#26631;&#26041;&#21521;&#65292;&#36825;&#20123;&#26041;&#21521;&#22312;Hermite&#22522;&#30784;&#19978;&#32447;&#24615;&#36830;&#25509;&#21040;&#20043;&#21069;&#23398;&#20064;&#30340;&#26041;&#21521;&#25152;&#28085;&#30422;&#30340;&#23376;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the training dynamics of shallow neural networks, investigating the conditions under which a limited number of large batch gradient descent steps can facilitate feature learning beyond the kernel regime. We compare the influence of batch size and that of multiple (but finitely many) steps. Our analysis of a single-step process reveals that while a batch size of $n = O(d)$ enables feature learning, it is only adequate for learning a single direction, or a single-index model. In contrast, $n = O(d^2)$ is essential for learning multiple directions and specialization. Moreover, we demonstrate that ``hard'' directions, which lack the first $\ell$ Hermite coefficients, remain unobserved and require a batch size of $n = O(d^\ell)$ for being captured by gradient descent. Upon iterating a few steps, the scenario changes: a batch-size of $n = O(d)$ is enough to learn new target directions spanning the subspace linearly connected in the Hermite basis to the previously learned directions,
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#31163;&#25955;&#20998;&#24067;&#26679;&#26412;&#23545;&#20110;&#31867;&#21035;&#38388;&#30340;&#22343;&#21248;&#20998;&#24067;&#25311;&#21512;&#38382;&#39064;&#19979;&#30340;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;&#65292;&#22312;&#32570;&#23569;&#29699;&#24418;&#26367;&#20195;&#26041;&#26696;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20102;&#35752;&#35770;&#65292;&#36890;&#36807;&#31163;&#25955;&#30452;&#26041;&#22270;&#36827;&#34892;&#26816;&#39564;&#65292;&#33719;&#24471;&#20102;&#19968;&#31181;&#20855;&#26377;&#31934;&#30830;&#21051;&#30011;&#30340;&#26816;&#39564;&#26041;&#27861;&#65292;&#24182;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#20102;&#26174;&#33879;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.18111</link><description>&lt;p&gt;
&#22312;&#32570;&#23569;&#29699;&#24418;&#26367;&#20195;&#26041;&#26696;&#19979;&#27979;&#35797;&#31163;&#25955;&#20998;&#24067;&#30452;&#26041;&#22270;&#22343;&#21248;&#24615;&#30340;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
The minimax risk in testing the histogram of discrete distributions for uniformity under missing ball alternatives. (arXiv:2305.18111v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18111
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#31163;&#25955;&#20998;&#24067;&#26679;&#26412;&#23545;&#20110;&#31867;&#21035;&#38388;&#30340;&#22343;&#21248;&#20998;&#24067;&#25311;&#21512;&#38382;&#39064;&#19979;&#30340;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;&#65292;&#22312;&#32570;&#23569;&#29699;&#24418;&#26367;&#20195;&#26041;&#26696;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20102;&#35752;&#35770;&#65292;&#36890;&#36807;&#31163;&#25955;&#30452;&#26041;&#22270;&#36827;&#34892;&#26816;&#39564;&#65292;&#33719;&#24471;&#20102;&#19968;&#31181;&#20855;&#26377;&#31934;&#30830;&#21051;&#30011;&#30340;&#26816;&#39564;&#26041;&#27861;&#65292;&#24182;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#20102;&#26174;&#33879;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#27979;&#35797;&#19968;&#20010;&#26469;&#33258;&#35768;&#22810;&#31867;&#21035;&#30340;&#31163;&#25955;&#26679;&#26412;&#23545;&#20110;&#31867;&#21035;&#38388;&#30340;&#22343;&#21248;&#20998;&#24067;&#25311;&#21512;&#30340;&#38382;&#39064;&#12290;&#20316;&#20026;&#21478;&#19968;&#31867;&#26367;&#20195;&#20551;&#35774;&#65292;&#25105;&#20204;&#32771;&#34385;&#21435;&#38500;&#21322;&#24452;&#20026;$\epsilon$&#30340;$\ell_p$&#29699;&#24418;&#26367;&#20195;&#26041;&#26696;&#65292;&#20854;&#20013;$p\leq 2$&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#22522;&#20110;&#30452;&#26041;&#22270;&#65288;&#32570;&#22833;&#31867;&#21035;&#12289;&#21333;&#20363;&#12289;&#30896;&#25758;&#30340;&#25968;&#37327;&#65289;&#30340;&#26816;&#39564;&#22312;&#26679;&#26412;&#25968;&#21644;&#32500;&#25968;&#36235;&#21521;&#26080;&#31351;&#22823;&#65292;$\epsilon\to0$&#26102;&#65292;&#28176;&#36827;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;&#30340;&#19968;&#20010;&#31934;&#30830;&#21051;&#30011;&#12290;&#20363;&#22914;&#65292;&#24403;$p=1$&#19988;&#26399;&#26395;&#26679;&#26412;&#25968;$n$&#19982;&#31867;&#21035;&#25968;$N$&#30340;&#27604;&#20540;&#24456;&#23567;&#65288;&#20063;&#31216;&#20026;&#8220;&#27425;&#32447;&#24615;&#8221;&#21306;&#22495;&#65289;&#26102;&#65292;&#28176;&#36827;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;$R^*_\epsilon$&#36235;&#36817;&#20110;$2\bar{\Phi}\left(n\epsilon^2/\sqrt{8N}\right)$&#65292;&#20854;&#20013;$\bar{\Phi}(x)$&#26159;&#27491;&#24577;&#27531;&#23384;&#20989;&#25968;&#12290;&#22312;&#19968;&#31995;&#21015;&#38382;&#39064;&#21442;&#25968;&#33539;&#22260;&#20869;&#30340;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;&#36825;&#20010;&#20272;&#35745;&#22312;&#26377;&#38480;&#26679;&#26412;&#20013;&#24456;&#31934;&#30830;&#65292;&#24182;&#19988;&#25105;&#20204;&#30340;&#26816;&#39564;&#26174;&#33879;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of testing the fit of a discrete sample of items from many categories to the uniform distribution over the categories. As a class of alternative hypotheses, we consider the removal of an $\ell_p$ ball of radius $\epsilon$ around the uniform rate sequence for $p \leq 2$. We deliver a sharp characterization of the asymptotic minimax risk when $\epsilon \to 0$ as the number of samples and number of dimensions go to infinity, for testing based on the occurrences' histogram (number of absent categories, singletons, collisions, ...). For example, for $p=1$ and in the limit of a small expected number of samples $n$ compared to the number of categories $N$ (aka "sub-linear" regime), the minimax risk $R^*_\epsilon$ asymptotes to $2 \bar{\Phi}\left(n \epsilon^2/\sqrt{8N}\right) $, with $\bar{\Phi}(x)$ the normal survival function. Empirical studies over a range of problem parameters show that this estimate is accurate in finite samples, and that our test is significantly 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#33609;&#22270;&#25216;&#26415;&#23558;&#31890;&#23376;&#26041;&#27861;&#21644;&#24352;&#37327;&#32593;&#32476;&#26041;&#27861;&#32467;&#21512;&#30340;&#26041;&#27861;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#36825;&#31181;&#26041;&#27861;&#21253;&#25324;&#31890;&#23376;&#27169;&#25311;&#21644;&#24352;&#37327;&#32593;&#32476;&#37325;&#26032;&#20272;&#35745;&#65292;&#24182;&#21487;&#29992;&#20316;&#31890;&#23376;&#25968;&#25511;&#21046;&#30340;&#21487;&#26367;&#20195;&#26041;&#27861;&#12290;&#22312;&#27169;&#25311;Fokker-Planck&#26041;&#31243;&#21644;&#37327;&#23376;&#34394;&#26102;&#38388;&#28436;&#21270;&#26041;&#38754;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#36890;&#29992;&#24615;&#21644;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.17884</link><description>&lt;p&gt;
&#36890;&#36807;&#33609;&#22270;&#25216;&#26415;&#65292;&#23558;&#31890;&#23376;&#26041;&#27861;&#21644;&#24352;&#37327;&#32593;&#32476;&#26041;&#27861;&#32467;&#21512;&#29992;&#20110;&#20559;&#24494;&#20998;&#26041;&#31243;&#27714;&#35299;
&lt;/p&gt;
&lt;p&gt;
Combining Particle and Tensor-network Methods for Partial Differential Equations via Sketching. (arXiv:2305.17884v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17884
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#33609;&#22270;&#25216;&#26415;&#23558;&#31890;&#23376;&#26041;&#27861;&#21644;&#24352;&#37327;&#32593;&#32476;&#26041;&#27861;&#32467;&#21512;&#30340;&#26041;&#27861;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#36825;&#31181;&#26041;&#27861;&#21253;&#25324;&#31890;&#23376;&#27169;&#25311;&#21644;&#24352;&#37327;&#32593;&#32476;&#37325;&#26032;&#20272;&#35745;&#65292;&#24182;&#21487;&#29992;&#20316;&#31890;&#23376;&#25968;&#25511;&#21046;&#30340;&#21487;&#26367;&#20195;&#26041;&#27861;&#12290;&#22312;&#27169;&#25311;Fokker-Planck&#26041;&#31243;&#21644;&#37327;&#23376;&#34394;&#26102;&#38388;&#28436;&#21270;&#26041;&#38754;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#36890;&#29992;&#24615;&#21644;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#24352;&#37327;&#32593;&#32476;&#26694;&#26550;&#65292;&#20854;&#20013;&#25105;&#20204;&#37319;&#29992;&#31890;&#23376;&#27169;&#25311;&#26356;&#26032;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#20351;&#29992;&#26368;&#36817;&#25552;&#20986;&#30340;&#24352;&#37327;&#21015;&#36710;&#33609;&#22270;&#25216;&#26415;&#23558;&#26032;&#35299;&#20915;&#26041;&#26696;&#37325;&#26032;&#20272;&#35745;&#20026;&#24352;&#37327;&#32593;&#32476;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36824;&#21487;&#20197;&#34987;&#35299;&#37322;&#20026;&#36890;&#36807;&#20551;&#35774;&#31890;&#23376;&#26469;&#33258;&#24213;&#23618;&#24352;&#37327;&#32593;&#32476;&#26469;&#25191;&#34892;&#31890;&#23376;&#25968;&#25511;&#21046;&#30340;&#21487;&#26367;&#20195;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#20854;&#24212;&#29992;&#20110;&#20004;&#31181;&#29305;&#23450;&#30340;&#24773;&#26223;&#26469;&#23637;&#31034;&#25105;&#20204;&#26041;&#27861;&#30340;&#36890;&#29992;&#24615;&#21644;&#28789;&#27963;&#24615;&#65306;&#36890;&#36807;Langevin&#21160;&#21147;&#23398;&#27169;&#25311;Fokker-Planck&#26041;&#31243;&#21644;&#36890;&#36807;&#36741;&#21161;&#22330;&#37327;&#23376;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#37327;&#23376;&#34394;&#26102;&#38388;&#28436;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a general framework for solving high-dimensional partial differential equations with tensor networks. Our approach offers a comprehensive solution methodology, wherein we employ a combination of particle simulations to update the solution and re-estimations of the new solution as a tensor-network using a recently proposed tensor train sketching technique. Our method can also be interpreted as an alternative approach for performing particle number control by assuming the particles originate from an underlying tensor network. We demonstrate the versatility and flexibility of our approach by applying it to two specific scenarios: simulating the Fokker-Planck equation through Langevin dynamics and quantum imaginary time evolution via auxiliary-field quantum Monte Carlo.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20154;&#31867;&#21453;&#39304;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#22914;&#20309;&#20272;&#35745;&#38544;&#24335;&#22870;&#21169;&#20197;&#21450;&#22312;&#32622;&#20449;&#38598;&#21608;&#22260;&#35299;&#20915;&#35268;&#21010;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#20010;&#33021;&#22815;&#20351;&#29992;&#22810;&#39033;&#24335;&#25968;&#37327;&#30340;&#26679;&#26412;&#23398;&#20064;&#20219;&#20309;&#30446;&#26631;&#31574;&#30053;&#30340;&#26032;&#20445;&#35777;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#21333;&#31574;&#30053;&#38598;&#20013;&#31995;&#25968;&#26469;&#34913;&#37327;&#30446;&#26631;&#31574;&#30053;&#30340;&#35206;&#30422;&#33539;&#22260;&#12290;</title><link>http://arxiv.org/abs/2305.14816</link><description>&lt;p&gt;
&#20855;&#26377;&#20154;&#31867;&#21453;&#39304;&#30340;&#21487;&#35777;&#26126;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Provable Offline Reinforcement Learning with Human Feedback. (arXiv:2305.14816v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14816
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20154;&#31867;&#21453;&#39304;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#22914;&#20309;&#20272;&#35745;&#38544;&#24335;&#22870;&#21169;&#20197;&#21450;&#22312;&#32622;&#20449;&#38598;&#21608;&#22260;&#35299;&#20915;&#35268;&#21010;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#20010;&#33021;&#22815;&#20351;&#29992;&#22810;&#39033;&#24335;&#25968;&#37327;&#30340;&#26679;&#26412;&#23398;&#20064;&#20219;&#20309;&#30446;&#26631;&#31574;&#30053;&#30340;&#26032;&#20445;&#35777;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#21333;&#31574;&#30053;&#38598;&#20013;&#31995;&#25968;&#26469;&#34913;&#37327;&#30446;&#26631;&#31574;&#30053;&#30340;&#35206;&#30422;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#21453;&#39304;&#26159;&#20197;&#36712;&#36857;&#23545;&#20043;&#38388;&#30340;&#20559;&#22909;&#24418;&#24335;&#25552;&#20379;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#21253;&#25324;&#20004;&#20010;&#20027;&#35201;&#27493;&#39588;&#65306;&#65288;1&#65289;&#20351;&#29992;&#36890;&#29992;&#20989;&#25968;&#36924;&#36817;&#20174;&#31163;&#32447;&#25968;&#25454;&#20272;&#35745;&#38544;&#24335;&#22870;&#21169;&#65292;&#21644;&#65288;2&#65289;&#22312;MLE&#21608;&#22260;&#30340;&#32622;&#20449;&#38598;&#19978;&#35299;&#20915;&#20998;&#24067;&#40065;&#26834;&#30340;&#35268;&#21010;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#36890;&#29992;&#30340;&#22870;&#21169;&#35774;&#32622;&#65292;&#20854;&#20013;&#22870;&#21169;&#21487;&#20197;&#22312;&#25972;&#20010;&#36712;&#36857;&#19978;&#23450;&#20041;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#20445;&#35777;&#65292;&#21482;&#35201;&#30446;&#26631;&#31574;&#30053;&#34987;&#31163;&#32447;&#25968;&#25454;&#35206;&#30422;&#65292;&#25105;&#20204;&#23601;&#21487;&#20197;&#20351;&#29992;&#22810;&#39033;&#24335;&#25968;&#37327;&#30340;&#26679;&#26412;&#26469;&#23398;&#20064;&#20219;&#20309;&#30446;&#26631;&#31574;&#30053;&#12290;&#20026;&#20102;&#34913;&#37327;&#30446;&#26631;&#31574;&#30053;&#30340;&#35206;&#30422;&#33539;&#22260;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#21333;&#31574;&#30053;&#38598;&#20013;&#31995;&#25968;&#65292;&#21487;&#20197;&#36890;&#36807;&#27599;&#20010;&#36712;&#36857;&#30340;&#38598;&#20013;&#31995;&#25968;&#19978;&#30028;&#26469;&#19978;&#30028;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we investigate the problem of offline reinforcement learning with human feedback where feedback is available in the form of preference between trajectory pairs rather than explicit rewards. Our proposed algorithm consists of two main steps: (1) estimate the implicit reward using Maximum Likelihood Estimation (MLE) with general function approximation from offline data and (2) solve a distributionally robust planning problem over a confidence set around the MLE. We consider the general reward setting where the reward can be defined over the whole trajectory and provide a novel guarantee that allows us to learn any target policy with a polynomial number of samples, as long as the target policy is covered by the offline data. This guarantee is the first of its kind with general function approximation. To measure the coverage of the target policy, we introduce a new single-policy concentrability coefficient, which can be upper bounded by the per-trajectory concentrability coe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;&#35270;&#35273;&#35821;&#35328;&#22522;&#30784;&#27169;&#22411;&#36827;&#34892;&#25968;&#25454;&#39537;&#21160;&#31163;&#32447;&#35757;&#32451;&#30340; Web &#20195;&#29702;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#25351;&#20196;&#36319;&#38543;&#22810;&#27169;&#24577;&#20195;&#29702;WebGUM&#65292;&#23558;&#24494;&#35843;&#25351;&#20196;&#24494;&#35843;&#35821;&#35328;&#27169;&#22411;&#21644;&#35270;&#35273;&#36716;&#25442;&#22120;&#65292;&#33021;&#22815;&#26377;&#25928;&#25552;&#39640;&#20195;&#29702;&#30340;&#22522;&#20110;&#35270;&#35273;&#24863;&#30693;&#12289;HTML &#29702;&#35299;&#21644;&#22810;&#27493;&#25512;&#29702;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2305.11854</link><description>&lt;p&gt;
&#20351;&#29992;&#25351;&#20196;&#24494;&#35843;&#22522;&#30784;&#27169;&#22411;&#30340;&#22810;&#27169;&#24577; Web &#23548;&#33322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multimodal Web Navigation with Instruction-Finetuned Foundation Models. (arXiv:2305.11854v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11854
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;&#35270;&#35273;&#35821;&#35328;&#22522;&#30784;&#27169;&#22411;&#36827;&#34892;&#25968;&#25454;&#39537;&#21160;&#31163;&#32447;&#35757;&#32451;&#30340; Web &#20195;&#29702;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#25351;&#20196;&#36319;&#38543;&#22810;&#27169;&#24577;&#20195;&#29702;WebGUM&#65292;&#23558;&#24494;&#35843;&#25351;&#20196;&#24494;&#35843;&#35821;&#35328;&#27169;&#22411;&#21644;&#35270;&#35273;&#36716;&#25442;&#22120;&#65292;&#33021;&#22815;&#26377;&#25928;&#25552;&#39640;&#20195;&#29702;&#30340;&#22522;&#20110;&#35270;&#35273;&#24863;&#30693;&#12289;HTML &#29702;&#35299;&#21644;&#22810;&#27493;&#25512;&#29702;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#20027; Web &#23548;&#33322;&#30340;&#36827;&#23637;&#21463;&#21040;&#20102;&#20381;&#36182;&#25968;&#21313;&#20159;&#27425;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#25506;&#32034;&#24615;&#20132;&#20114;&#21644;&#20855;&#26377;&#39046;&#22495;&#29305;&#23450;&#27169;&#22411;&#35774;&#35745;&#30340;&#24433;&#21709;&#65292;&#36825;&#20351;&#24471;&#38590;&#20197;&#21033;&#29992;&#26469;&#33258;&#20016;&#23500;&#39046;&#22495;&#22806;&#25968;&#25454;&#30340;&#27867;&#21270;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#33073;&#26426;&#35757;&#32451;&#65292;&#29992;&#20110;&#20351;&#29992;&#35270;&#35273;&#35821;&#35328;&#22522;&#30784;&#27169;&#22411;&#30340; Web &#20195;&#29702;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25351;&#20196;&#36319;&#38543;&#22810;&#27169;&#24577;&#20195;&#29702;&#65292; WebGUM&#65292;&#23427;&#35266;&#23519;&#20102;&#32593;&#39029;&#25130;&#22270;&#21644; HTML &#39029;&#38754;&#65292;&#24182;&#36755;&#20986; Web &#23548;&#33322;&#25805;&#20316;&#65292;&#22914;&#21333;&#20987;&#21644;&#36755;&#20837;&#12290;WebGUM &#26159;&#36890;&#36807;&#32852;&#21512;&#24494;&#35843;&#25351;&#20196;&#24494;&#35843;&#35821;&#35328;&#27169;&#22411;&#21644;&#35270;&#35273;&#36716;&#25442;&#22120;&#22312;&#22823;&#37327;&#30340;&#28436;&#31034;&#35821;&#26009;&#24211;&#19978;&#35757;&#32451;&#30340;&#12290;&#25105;&#20204;&#20973;&#32463;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#20195;&#29702;&#30340;&#22522;&#20110;&#35270;&#35273;&#24863;&#30693;&#12289;HTML &#29702;&#35299;&#21644;&#22810;&#27493;&#25512;&#29702;&#30340;&#33021;&#21147;&#65292;&#26126;&#26174;&#20248;&#20110;&#20043;&#21069;&#30340;&#24037;&#20316;&#12290;&#22312; MiniWoB &#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#25105;&#20204;&#36229;&#36807;&#20043;&#21069;&#26368;&#20339;&#33073;&#26426;&#26041;&#27861; 31.9% &#20197;&#19978;&#65292;&#25509;&#36817;&#23454;&#29616;&#22312;&#32447;&#20132;&#20114;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
The progress of autonomous web navigation has been hindered by the dependence on billions of exploratory interactions via online reinforcement learning, and domain-specific model designs that make it difficult to leverage generalization from rich out-of-domain data. In this work, we study data-driven offline training for web agents with vision-language foundation models. We propose an instruction-following multimodal agent, WebGUM, that observes both webpage screenshots and HTML pages and outputs web navigation actions, such as click and type. WebGUM is trained by jointly finetuning an instruction-finetuned language model and a vision transformer on a large corpus of demonstrations. We empirically demonstrate this recipe improves the agent's ability of grounded visual perception, HTML comprehension and multi-step reasoning, outperforming prior works by a significant margin. On the MiniWoB benchmark, we improve over the previous best offline methods by more than 31.9%, being close to re
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21435;&#22122;&#25193;&#25955;&#36807;&#31243;&#33258;&#28982;&#22320;&#23548;&#33268;&#27491;&#21017;&#21270;&#30340;&#21464;&#20998;&#26041;&#27861;&#65288;RED-Diff&#65289;&#65292;&#21487;&#29992;&#20110;&#35299;&#20915;&#19981;&#21516;&#21453;&#38382;&#39064;&#12290;&#21152;&#26435;&#26426;&#21046;&#21487;&#20197;&#34913;&#37327;&#19981;&#21516;&#26102;&#38388;&#27493;&#38271;&#30340;&#21435;&#22122;&#22120;&#30340;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2305.04391</link><description>&lt;p&gt;
&#29992;&#25193;&#25955;&#27169;&#22411;&#35299;&#20915;&#21453;&#38382;&#39064;&#30340;&#21464;&#20998;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
A Variational Perspective on Solving Inverse Problems with Diffusion Models. (arXiv:2305.04391v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04391
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21435;&#22122;&#25193;&#25955;&#36807;&#31243;&#33258;&#28982;&#22320;&#23548;&#33268;&#27491;&#21017;&#21270;&#30340;&#21464;&#20998;&#26041;&#27861;&#65288;RED-Diff&#65289;&#65292;&#21487;&#29992;&#20110;&#35299;&#20915;&#19981;&#21516;&#21453;&#38382;&#39064;&#12290;&#21152;&#26435;&#26426;&#21046;&#21487;&#20197;&#34913;&#37327;&#19981;&#21516;&#26102;&#38388;&#27493;&#38271;&#30340;&#21435;&#22122;&#22120;&#30340;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#24050;&#25104;&#20026;&#35270;&#35273;&#39046;&#22495;&#22522;&#30784;&#27169;&#22411;&#30340;&#20851;&#38190;&#25903;&#26609;&#20043;&#19968;&#12290;&#20854;&#20013;&#19968;&#20010;&#20851;&#38190;&#24212;&#29992;&#26159;&#36890;&#36807;&#21333;&#20010;&#25193;&#25955;&#20808;&#39564;&#26222;&#36941;&#35299;&#20915;&#19981;&#21516;&#30340;&#21453;&#38382;&#39064;&#65292;&#32780;&#26080;&#38656;&#20026;&#27599;&#20010;&#20219;&#21153;&#37325;&#26032;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#25193;&#25955;&#36807;&#31243;&#30340;&#38750;&#32447;&#24615;&#21644;&#36845;&#20195;&#24615;&#36136;&#20351;&#24471;&#21518;&#39564;&#38590;&#20197;&#22788;&#29702;&#65292;&#22240;&#27492;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21464;&#20998;&#26041;&#27861;&#65292;&#26088;&#22312;&#36817;&#20284;&#30495;&#23454;&#21518;&#39564;&#20998;&#24067;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#21435;&#22122;&#25193;&#25955;&#36807;&#31243;&#65288;RED-Diff&#65289;&#33258;&#28982;&#22320;&#23548;&#33268;&#27491;&#21017;&#21270;&#65292;&#20854;&#20013;&#26469;&#33258;&#19981;&#21516;&#26102;&#38388;&#27493;&#38271;&#30340;&#21435;&#22122;&#22120;&#21516;&#26102;&#23545;&#22270;&#20687;&#26045;&#21152;&#19981;&#21516;&#30340;&#32467;&#26500;&#32422;&#26463;&#12290;&#20026;&#20102;&#34913;&#37327;&#19981;&#21516;&#26102;&#38388;&#27493;&#38271;&#30340;&#21435;&#22122;&#22120;&#30340;&#36129;&#29486;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20449;&#21495;-t&#30340;&#21152;&#26435;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models have emerged as a key pillar of foundation models in visual domains. One of their critical applications is to universally solve different downstream inverse tasks via a single diffusion prior without re-training for each task. Most inverse tasks can be formulated as inferring a posterior distribution over data (e.g., a full image) given a measurement (e.g., a masked image). This is however challenging in diffusion models since the nonlinear and iterative nature of the diffusion process renders the posterior intractable. To cope with this challenge, we propose a variational approach that by design seeks to approximate the true posterior distribution. We show that our approach naturally leads to regularization by denoising diffusion process (RED-Diff) where denoisers at different timesteps concurrently impose different structural constraints over the image. To gauge the contribution of denoisers from different timesteps, we propose a weighting mechanism based on signal-t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#36125;&#21494;&#26031;&#20998;&#23618;&#24314;&#27169;&#65292;&#21160;&#24577;&#24179;&#34913;&#25506;&#32034;-&#24320;&#21457;&#26435;&#34913;&#65292;&#20197;&#26356;&#22909;&#22320;&#26597;&#35810;&#25968;&#25454;&#28857;&#12290;</title><link>http://arxiv.org/abs/2304.07665</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#20998;&#23618;&#24314;&#27169;&#20013;&#20027;&#21160;&#23398;&#20064;&#22238;&#24402;&#20013;&#30340;&#21160;&#24577;&#25506;&#32034;-&#24320;&#21457;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
Dynamic Exploration-Exploitation Trade-Off in Active Learning Regression with Bayesian Hierarchical Modeling. (arXiv:2304.07665v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07665
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#36125;&#21494;&#26031;&#20998;&#23618;&#24314;&#27169;&#65292;&#21160;&#24577;&#24179;&#34913;&#25506;&#32034;-&#24320;&#21457;&#26435;&#34913;&#65292;&#20197;&#26356;&#22909;&#22320;&#26597;&#35810;&#25968;&#25454;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#21160;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#37319;&#26679;&#26368;&#20855;&#20449;&#24687;&#30340;&#23454;&#39564;&#20197;&#23398;&#20064;&#26410;&#30693;&#30340;&#40657;&#30418;&#20989;&#25968;&#30340;&#26694;&#26550;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#20998;&#23618;&#26041;&#27861;&#26469;&#21160;&#24577;&#24179;&#34913;&#25506;&#32034;-&#24320;&#21457;&#26435;&#34913;&#65292;&#20197;&#26356;&#22909;&#22320;&#26597;&#35810;&#25968;&#25454;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Active learning provides a framework to adaptively sample the most informative experiments towards learning an unknown black-box function. Various approaches of active learning have been proposed in the literature, however, they either focus on exploration or exploitation in the design space. Methods that do consider exploration-exploitation simultaneously employ fixed or ad-hoc measures to control the trade-off that may not be optimal. In this paper, we develop a Bayesian hierarchical approach to dynamically balance the exploration-exploitation trade-off as more data points are queried. We subsequently formulate an approximate Bayesian computation approach based on the linear dependence of data samples in the feature space to sample from the posterior distribution of the trade-off parameter obtained from the Bayesian hierarchical model. Simulated and real-world examples show the proposed approach achieves at least 6% and 11% average improvement when compared to pure exploration and ex
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; OKRidge &#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#30830;&#23450;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#31232;&#30095;&#25511;&#21046;&#26041;&#31243;&#65292;&#24182;&#36890;&#36807;&#27714;&#35299;&#31232;&#30095;&#23725;&#22238;&#24402;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#21487;&#25193;&#23637;&#24615;&#21644;&#24555;&#36895;&#24615;&#65292;&#21644;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#26377;&#30528;&#26356;&#39640;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2304.06686</link><description>&lt;p&gt;
OKRidge: &#29992;&#20110;&#23398;&#20064;&#21160;&#24577;&#31995;&#32479;&#30340;&#21487;&#25193;&#23637; k &#31232;&#30095;&#23725;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
OKRidge: Scalable Optimal k-Sparse Ridge Regression for Learning Dynamical Systems. (arXiv:2304.06686v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06686
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; OKRidge &#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#30830;&#23450;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#31232;&#30095;&#25511;&#21046;&#26041;&#31243;&#65292;&#24182;&#36890;&#36807;&#27714;&#35299;&#31232;&#30095;&#23725;&#22238;&#24402;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#21487;&#25193;&#23637;&#24615;&#21644;&#24555;&#36895;&#24615;&#65292;&#21644;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#26377;&#30528;&#26356;&#39640;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#31185;&#23398;&#21457;&#29616;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65292;&#21363;&#65292;&#30830;&#23450;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#31232;&#30095;&#25511;&#21046;&#26041;&#31243;&#65292;&#36890;&#36807;&#27714;&#35299;&#31232;&#30095;&#23725;&#22238;&#24402;&#38382;&#39064;&#21487;&#20197;&#35777;&#26126;&#26368;&#20248;&#24615;&#65292;&#20197;&#30830;&#23450;&#39537;&#21160;&#22522;&#30784;&#21160;&#24577;&#30340;&#39033;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026; OKRidge &#30340;&#24555;&#36895;&#31639;&#27861;&#65292;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#19979;&#30028;&#35745;&#31639;&#26041;&#27861;&#65292;&#28041;&#21450;&#38797;&#28857;&#20844;&#24335;&#65292;&#28982;&#21518;&#20351;&#29992;&#32447;&#24615;&#31995;&#32479;&#25110;&#22522;&#20110; ADMM &#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#65292;&#20854;&#20013;&#21487;&#20197;&#36890;&#36807;&#35299;&#20915;&#21478;&#19968;&#20010;&#32447;&#24615;&#31995;&#32479;&#21644;&#21333;&#35843;&#22238;&#24402;&#38382;&#39064;&#26469;&#26377;&#25928;&#22320;&#35745;&#31639;&#36817;&#31471;&#31639;&#23376;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#21551;&#21160;&#25105;&#20204;&#27714;&#35299;&#22120;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#20102;&#27874;&#26463;&#25628;&#32034;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36798;&#21040;&#21487;&#35777;&#26126;&#30340;&#26368;&#20248;&#24615;&#65292;&#24182;&#19988;&#36816;&#34892;&#26102;&#38388;&#27604;&#21830;&#19994;&#27714;&#35299;&#22120; Gurobi &#35299;&#20915;&#30340;&#29616;&#26377; MIP&#20844;&#24335;&#36816;&#34892;&#26102;&#38388;&#24555;&#20960;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider an important problem in scientific discovery, identifying sparse governing equations for nonlinear dynamical systems. This involves solving sparse ridge regression problems to provable optimality in order to determine which terms drive the underlying dynamics. We propose a fast algorithm, OKRidge, for sparse ridge regression, using a novel lower bound calculation involving, first, a saddle point formulation, and from there, either solving (i) a linear system or (ii) using an ADMM-based approach, where the proximal operators can be efficiently evaluated by solving another linear system and an isotonic regression problem. We also propose a method to warm-start our solver, which leverages a beam search. Experimentally, our methods attain provable optimality with run times that are orders of magnitude faster than those of the existing MIP formulations solved by the commercial solver Gurobi.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#33021;&#37327;&#22522;&#30784;&#27169;&#22411;&#21644;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#35299;&#20915;&#29983;&#25104;&#24314;&#27169;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;2D&#24773;&#26223;&#21644;&#22270;&#20687;&#21040;&#22270;&#20687;&#32763;&#35793;&#38382;&#39064;&#20013;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.06094</link><description>&lt;p&gt;
&#33021;&#37327;&#24341;&#23548;&#30340;&#29109;&#31070;&#32463;&#26368;&#20248;&#36755;&#36816;
&lt;/p&gt;
&lt;p&gt;
Energy-guided Entropic Neural Optimal Transport. (arXiv:2304.06094v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06094
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#33021;&#37327;&#22522;&#30784;&#27169;&#22411;&#21644;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#35299;&#20915;&#29983;&#25104;&#24314;&#27169;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;2D&#24773;&#26223;&#21644;&#22270;&#20687;&#21040;&#22270;&#20687;&#32763;&#35793;&#38382;&#39064;&#20013;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#37327;&#22522;&#30784;&#27169;&#22411;&#65288;EBMs&#65289;&#22312;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#24050;&#32463;&#26377;&#25968;&#21313;&#24180;&#30340;&#21382;&#21490;&#12290;&#33258;&#20004;&#21315;&#24180;&#20195;&#36215;&#65292;&#19968;&#30452;&#26377;&#24456;&#22810;&#39640;&#25928;&#30340;&#26041;&#27861;&#36890;&#36807;&#33021;&#37327;&#21183;&#65288;&#38750;&#24402;&#19968;&#21270;&#30340;&#20284;&#28982;&#20989;&#25968;&#65289;&#26469;&#35299;&#20915;&#29983;&#25104;&#24314;&#27169;&#38382;&#39064;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#26368;&#20248;&#36755;&#36816;&#65288;OT&#65289;&#39046;&#22495;&#65292;&#23588;&#20854;&#26159;&#31070;&#32463;OT&#27714;&#35299;&#22120;&#65292;&#21463;&#21040;&#30340;&#25506;&#32034;&#35201;&#23569;&#24471;&#22810;&#65292;&#20165;&#26377;&#19968;&#20123;&#36817;&#26399;&#30340;&#30740;&#31350;&#65288;&#19981;&#21253;&#25324;&#21033;&#29992;OT&#20316;&#20026;&#25439;&#22833;&#20989;&#25968;&#26469;&#35299;&#20915;&#38382;&#39064;&#30340;WGAN&#26041;&#27861;&#65289;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24357;&#21512;&#20102;EBMs&#21644;&#29109;&#27491;&#21017;&#21270;OT&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#20801;&#35768;&#21033;&#29992;&#21069;&#32773;&#30340;&#26368;&#26032;&#21457;&#23637;&#21644;&#25216;&#26415;&#25913;&#36827;&#26469;&#20016;&#23500;&#21518;&#32773;&#12290;&#25105;&#20204;&#22312;2D&#24773;&#26223;&#21644;&#26631;&#20934;&#30340;&#22270;&#20687;&#21040;&#22270;&#20687;&#32763;&#35793;&#38382;&#39064;&#20013;&#39564;&#35777;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#12290;&#20026;&#31616;&#21333;&#36215;&#35265;&#65292;&#25105;&#20204;&#36873;&#25321;&#20102;&#31616;&#30701;&#21644;&#38271;&#36305;&#30340;EBMs&#12290;
&lt;/p&gt;
&lt;p&gt;
Energy-Based Models (EBMs) are known in the Machine Learning community for the decades. Since the seminal works devoted to EBMs dating back to the noughties there have been appearing a lot of efficient methods which solve the generative modelling problem by means of energy potentials (unnormalized likelihood functions). In contrast, the realm of Optimal Transport (OT) and, in particular, neural OT solvers is much less explored and limited by few recent works (excluding WGAN based approaches which utilize OT as a loss function and do not model OT maps themselves). In our work, we bridge the gap between EBMs and Entropy-regularized OT. We present the novel methodology which allows utilizing the recent developments and technical improvements of the former in order to enrich the latter. We validate the applicability of our method on toy 2D scenarios as well as standard unpaired image-to-image translation problems. For the sake of simplicity, we choose simple short- and long- run EBMs as a 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;ChemCrow&#65292;&#19968;&#31181;LLM&#21270;&#23398;&#20195;&#29702;&#65292;&#36890;&#36807;&#25972;&#21512;13&#20010;&#19987;&#23478;&#35774;&#35745;&#30340;&#24037;&#20855;&#20174;&#32780;&#22686;&#24378;LLM&#22312;&#21270;&#23398;&#39046;&#22495;&#30340;&#24615;&#33021;&#65292;&#22312;&#21270;&#23398;&#20219;&#21153;&#20013;&#23454;&#29616;&#33258;&#21160;&#21270;&#65292;&#25552;&#39640;&#20102;&#25928;&#29575;&#21644;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.05376</link><description>&lt;p&gt;
ChemCrow:&#29992;&#21270;&#23398;&#24037;&#20855;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
ChemCrow: Augmenting large-language models with chemistry tools. (arXiv:2304.05376v1 [physics.chem-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05376
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;ChemCrow&#65292;&#19968;&#31181;LLM&#21270;&#23398;&#20195;&#29702;&#65292;&#36890;&#36807;&#25972;&#21512;13&#20010;&#19987;&#23478;&#35774;&#35745;&#30340;&#24037;&#20855;&#20174;&#32780;&#22686;&#24378;LLM&#22312;&#21270;&#23398;&#39046;&#22495;&#30340;&#24615;&#33021;&#65292;&#22312;&#21270;&#23398;&#20219;&#21153;&#20013;&#23454;&#29616;&#33258;&#21160;&#21270;&#65292;&#25552;&#39640;&#20102;&#25928;&#29575;&#21644;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#36328;&#39046;&#22495;&#30340;&#20219;&#21153;&#34920;&#29616;&#20986;&#19968;&#23450;&#30340;&#20248;&#21183;&#65292;&#20294;&#22312;&#21270;&#23398;&#30456;&#20851;&#38382;&#39064;&#19978;&#21364;&#34920;&#29616;&#19981;&#20339;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#27169;&#22411;&#32570;&#20047;&#35775;&#38382;&#22806;&#37096;&#30693;&#35782;&#28304;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#31185;&#23398;&#24212;&#29992;&#20013;&#30340;&#26377;&#29992;&#24615;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;ChemCrow&#65292;&#19968;&#31181;LLM&#21270;&#23398;&#20195;&#29702;&#65292;&#26088;&#22312;&#23436;&#25104;&#26377;&#26426;&#21512;&#25104;&#12289;&#33647;&#29289;&#21457;&#29616;&#21644;&#26448;&#26009;&#35774;&#35745;&#31561;&#20219;&#21153;&#12290;&#36890;&#36807;&#25972;&#21512;13&#20010;&#19987;&#23478;&#35774;&#35745;&#30340;&#24037;&#20855;&#65292;ChemCrow&#25552;&#39640;&#20102;LLM&#22312;&#21270;&#23398;&#20013;&#30340;&#24615;&#33021;&#65292;&#24182;&#20135;&#29983;&#20102;&#26032;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#65292;&#21253;&#25324;LLM&#21644;&#20154;&#31867;&#19987;&#23478;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;ChemCrow&#22312;&#33258;&#21160;&#21270;&#21508;&#31181;&#21270;&#23398;&#20219;&#21153;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;GPT-4&#20316;&#20026;&#35780;&#20272;&#22120;&#26080;&#27861;&#21306;&#20998;&#26126;&#26174;&#38169;&#35823;&#30340;GPT-4&#23436;&#25104;&#21644;GPT-4 + ChemCrow&#24615;&#33021;&#12290;&#36825;&#31181;&#24037;&#20855;&#30340;&#28389;&#29992;&#26377;&#24456;&#22823;&#30340;&#39118;&#38505;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#23427;&#20204;&#30340;&#28508;&#22312;&#21361;&#23475;&#12290;&#22312;&#36127;&#36131;&#20219;&#30340;&#24773;&#20917;&#19979;&#65292;ChemCrow&#19981;&#20165;&#21487;&#20197;&#24110;&#21161;&#19987;&#19994;&#21270;&#23398;&#23478;&#24182;&#38477;&#20302;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large-language models (LLMs) have recently shown strong performance in tasks across domains, but struggle with chemistry-related problems. Moreover, these models lack access to external knowledge sources, limiting their usefulness in scientific applications. In this study, we introduce ChemCrow, an LLM chemistry agent designed to accomplish tasks across organic synthesis, drug discovery, and materials design. By integrating 13 expert-designed tools, ChemCrow augments the LLM performance in chemistry, and new capabilities emerge. Our evaluation, including both LLM and expert human assessments, demonstrates ChemCrow's effectiveness in automating a diverse set of chemical tasks. Surprisingly, we find that GPT-4 as an evaluator cannot distinguish between clearly wrong GPT-4 completions and GPT-4 + ChemCrow performance. There is a significant risk of misuse of tools like ChemCrow and we discuss their potential harms. Employed responsibly, ChemCrow not only aids expert chemists and lowers ba
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38598;&#25104;&#23398;&#20064;&#21644;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#30340;&#24212;&#29992;&#65292;&#38024;&#23545;&#31867;&#21035;&#19981;&#24179;&#34913;&#38382;&#39064;&#65292;&#36890;&#36807;&#35745;&#31639;&#35780;&#20272;&#65292;&#25214;&#21040;&#20102;&#26368;&#26377;&#25928;&#30340;&#32452;&#21512;&#12290;</title><link>http://arxiv.org/abs/2304.02858</link><description>&lt;p&gt;
&#38754;&#21521;&#31867;&#21035;&#19981;&#22343;&#38382;&#39064;&#30340;&#38598;&#25104;&#23398;&#20064;&#21644;&#25968;&#25454;&#22686;&#24378;&#27169;&#22411;&#32508;&#36848;&#65306;&#32452;&#21512;&#12289;&#23454;&#29616;&#21644;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
A review of ensemble learning and data augmentation models for class imbalanced problems: combination, implementation and evaluation. (arXiv:2304.02858v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02858
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38598;&#25104;&#23398;&#20064;&#21644;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#30340;&#24212;&#29992;&#65292;&#38024;&#23545;&#31867;&#21035;&#19981;&#24179;&#34913;&#38382;&#39064;&#65292;&#36890;&#36807;&#35745;&#31639;&#35780;&#20272;&#65292;&#25214;&#21040;&#20102;&#26368;&#26377;&#25928;&#30340;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#31867;&#21035;&#19981;&#24179;&#34913;&#65288;CI&#65289;&#26159;&#25351;&#23646;&#20110;&#19968;&#20010;&#31867;&#30340;&#35266;&#27979;&#20540;&#25968;&#37327;&#20302;&#20110;&#20854;&#20182;&#31867;&#30340;&#25968;&#37327;&#12290;&#38598;&#25104;&#23398;&#20064;&#32467;&#21512;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#24050;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#35299;&#20915;&#31867;&#21035;&#19981;&#24179;&#34913;&#38382;&#39064;&#12290;&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#37324;&#65292;&#19968;&#20123;&#31574;&#30053;&#24050;&#32463;&#34987;&#24212;&#29992;&#20110;&#22686;&#24378;&#38598;&#25104;&#23398;&#20064;&#21644;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#65292;&#21516;&#26102;&#36824;&#24320;&#21457;&#20102;&#19968;&#20123;&#26032;&#26041;&#27861;&#65292;&#22914;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#12290;&#26412;&#25991;&#23545;&#29992;&#20110;&#35299;&#20915;&#22522;&#20934;CI&#38382;&#39064;&#30340;&#25968;&#25454;&#22686;&#24378;&#21644;&#38598;&#25104;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#35745;&#31639;&#35780;&#20272;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#35780;&#20272;CI&#38382;&#39064;&#30340;10&#20010;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#21644;10&#20010;&#38598;&#25104;&#23398;&#20064;&#26041;&#27861;&#30340;&#36890;&#29992;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#35782;&#21035;&#25552;&#39640;&#20998;&#31867;&#25928;&#26524;&#26368;&#26377;&#25928;&#30340;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Class imbalance (CI) in classification problems arises when the number of observations belonging to one class is lower than the other classes. Ensemble learning that combines multiple models to obtain a robust model has been prominently used with data augmentation methods to address class imbalance problems. In the last decade, a number of strategies have been added to enhance ensemble learning and data augmentation methods, along with new methods such as generative adversarial networks (GANs). A combination of these has been applied in many studies, but the true rank of different combinations would require a computational review. In this paper, we present a computational review to evaluate data augmentation and ensemble learning methods used to address prominent benchmark CI problems. We propose a general framework that evaluates 10 data augmentation and 10 ensemble learning methods for CI problems. Our objective was to identify the most effective combination for improving classificat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26368;&#22823;&#20284;&#28982;&#26041;&#27861;&#20013;&#36827;&#34892;&#27491;&#21017;&#21270;&#30340;&#29702;&#35770;&#19978;&#20445;&#35777;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20851;&#27880; Kullback - Leibler &#25955;&#24230;&#20013;&#30340;&#35268;&#33539;&#23545;&#31216;&#24615;&#65292;&#21487;&#20197;&#33719;&#24471;&#26368;&#20248;&#30340;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#19981;&#38656;&#35201;&#39057;&#32321;&#25628;&#32034;&#27491;&#21017;&#21270;&#30340;&#36229;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2303.16721</link><description>&lt;p&gt;
&#26368;&#22823;&#20284;&#28982;&#26041;&#27861;&#20877;&#25506;&#65306;Kullback - Leibler &#25955;&#24230;&#20013;&#30340;&#35268;&#33539;&#23545;&#31216;&#24615;&#21644;&#24615;&#33021;&#20445;&#35777;&#30340;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Maximum likelihood method revisited: Gauge symmetry in Kullback -- Leibler divergence and performance-guaranteed regularization. (arXiv:2303.16721v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16721
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26368;&#22823;&#20284;&#28982;&#26041;&#27861;&#20013;&#36827;&#34892;&#27491;&#21017;&#21270;&#30340;&#29702;&#35770;&#19978;&#20445;&#35777;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20851;&#27880; Kullback - Leibler &#25955;&#24230;&#20013;&#30340;&#35268;&#33539;&#23545;&#31216;&#24615;&#65292;&#21487;&#20197;&#33719;&#24471;&#26368;&#20248;&#30340;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#19981;&#38656;&#35201;&#39057;&#32321;&#25628;&#32034;&#27491;&#21017;&#21270;&#30340;&#36229;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#22823;&#20284;&#28982;&#26041;&#27861;&#26159;&#20272;&#35745;&#25968;&#25454;&#32972;&#21518;&#27010;&#29575;&#30340;&#26368;&#30693;&#21517;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#26041;&#27861;&#33719;&#24471;&#19982;&#32463;&#39564;&#20998;&#24067;&#26368;&#25509;&#36817;&#30340;&#27010;&#29575;&#27169;&#22411;&#65292;&#23548;&#33268;&#36807;&#24230;&#25311;&#21512;&#12290;&#28982;&#21518;&#65292;&#27491;&#21017;&#21270;&#26041;&#27861;&#21487;&#20197;&#38450;&#27490;&#27169;&#22411;&#36807;&#24230;&#25509;&#36817;&#38169;&#35823;&#30340;&#27010;&#29575;&#65292;&#20294;&#26159;&#23545;&#23427;&#20204;&#30340;&#24615;&#33021;&#30693;&#20043;&#29978;&#23569;&#12290;&#27491;&#21017;&#21270;&#30340;&#24605;&#24819;&#31867;&#20284;&#20110;&#32416;&#38169;&#20195;&#30721;&#65292;&#36890;&#36807;&#23558;&#27425;&#20248;&#35299;&#19982;&#38169;&#35823;&#25509;&#25910;&#21040;&#30340;&#20195;&#30721;&#28151;&#21512;&#65292;&#33719;&#24471;&#26368;&#20248;&#35299;&#30721;&#12290;&#32416;&#38169;&#20195;&#30721;&#20013;&#30340;&#26368;&#20248;&#35299;&#30721;&#26159;&#22522;&#20110;&#35268;&#33539;&#23545;&#31216;&#24615;&#23454;&#29616;&#30340;&#12290;&#25105;&#20204;&#36890;&#36807;&#20851;&#27880; Kullback - Leibler &#25955;&#24230;&#20013;&#30340;&#35268;&#33539;&#23545;&#31216;&#24615;&#65292;&#25552;&#20986;&#20102;&#26368;&#22823;&#20284;&#28982;&#26041;&#27861;&#20013;&#30340;&#29702;&#35770;&#19978;&#20445;&#35777;&#30340;&#27491;&#21017;&#21270;&#12290;&#22312;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#21487;&#20197;&#33719;&#24471;&#26368;&#20248;&#30340;&#27169;&#22411;&#65292;&#32780;&#26080;&#38656;&#39057;&#32321;&#25628;&#32034;&#27491;&#21017;&#21270;&#20013;&#32463;&#24120;&#20986;&#29616;&#30340;&#36229;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
The maximum likelihood method is the best-known method for estimating the probabilities behind the data. However, the conventional method obtains the probability model closest to the empirical distribution, resulting in overfitting. Then regularization methods prevent the model from being excessively close to the wrong probability, but little is known systematically about their performance. The idea of regularization is similar to error-correcting codes, which obtain optimal decoding by mixing suboptimal solutions with an incorrectly received code. The optimal decoding in error-correcting codes is achieved based on gauge symmetry. We propose a theoretically guaranteed regularization in the maximum likelihood method by focusing on a gauge symmetry in Kullback -- Leibler divergence. In our approach, we obtain the optimal model without the need to search for hyperparameters frequently appearing in regularization.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#32602;&#20989;&#25968;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#28145;&#24230;&#37096;&#20998;&#32447;&#24615;Cox&#27169;&#22411;&#65292;&#29992;&#20110;&#22312;&#32954;&#30284;&#24739;&#32773;&#30340;CT&#25195;&#25551;&#20013;&#20998;&#26512;&#27515;&#20129;&#39118;&#38505;&#12290;&#35813;&#27169;&#22411;&#33021;&#26377;&#25928;&#22320;&#25972;&#21512;&#24050;&#30693;&#21644;&#26032;&#20852;&#30340;&#39118;&#38505;&#22240;&#32032;&#65292;&#35299;&#20915;&#20102;&#21442;&#25968;&#32500;&#24230;&#36229;&#20986;&#26679;&#26412;&#22823;&#23567;&#21644;&#38750;&#21442;&#25968;&#24314;&#27169;&#20013;&#32500;&#24230;&#28798;&#38590;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2303.05341</link><description>&lt;p&gt;
&#21033;&#29992;&#32602;&#20989;&#25968;&#30340;&#28145;&#24230;&#37096;&#20998;&#32447;&#24615;Cox&#27169;&#22411;&#21450;&#20854;&#22312;&#32954;&#30284;&#24739;&#32773;CT&#25195;&#25551;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Penalized Deep Partially Linear Cox Models with Application to CT Scans of Lung Cancer Patients. (arXiv:2303.05341v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.05341
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#32602;&#20989;&#25968;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#28145;&#24230;&#37096;&#20998;&#32447;&#24615;Cox&#27169;&#22411;&#65292;&#29992;&#20110;&#22312;&#32954;&#30284;&#24739;&#32773;&#30340;CT&#25195;&#25551;&#20013;&#20998;&#26512;&#27515;&#20129;&#39118;&#38505;&#12290;&#35813;&#27169;&#22411;&#33021;&#26377;&#25928;&#22320;&#25972;&#21512;&#24050;&#30693;&#21644;&#26032;&#20852;&#30340;&#39118;&#38505;&#22240;&#32032;&#65292;&#35299;&#20915;&#20102;&#21442;&#25968;&#32500;&#24230;&#36229;&#20986;&#26679;&#26412;&#22823;&#23567;&#21644;&#38750;&#21442;&#25968;&#24314;&#27169;&#20013;&#32500;&#24230;&#28798;&#38590;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32954;&#30284;&#26159;&#20840;&#29699;&#30284;&#30151;&#27515;&#20129;&#29575;&#30340;&#20027;&#35201;&#21407;&#22240;&#65292;&#31361;&#20986;&#20102;&#29702;&#35299;&#20854;&#27515;&#20129;&#39118;&#38505;&#23545;&#35774;&#35745;&#26377;&#25928;&#30340;&#20197;&#24739;&#32773;&#20026;&#20013;&#24515;&#30340;&#27835;&#30103;&#30340;&#37325;&#35201;&#24615;&#12290;&#22269;&#23478;&#32954;&#37096;&#31579;&#26597;&#35797;&#39564;&#65288;NLST&#65289;&#37319;&#29992;&#20102;&#35745;&#31639;&#26426;&#26029;&#23618;&#25195;&#25551;&#32441;&#29702;&#20998;&#26512;&#65292;&#25552;&#20379;&#20102;CT&#25195;&#25551;&#19978;&#32441;&#29702;&#27169;&#24335;&#30340;&#23458;&#35266;&#27979;&#37327;&#65292;&#29992;&#20110;&#37327;&#21270;&#32954;&#30284;&#24739;&#32773;&#30340;&#27515;&#20129;&#39118;&#38505;&#12290;&#37096;&#20998;&#32447;&#24615;Cox&#27169;&#22411;&#36890;&#36807;&#23558;&#39118;&#38505;&#20989;&#25968;&#20998;&#35299;&#20026;&#21442;&#25968;&#21644;&#38750;&#21442;&#25968;&#20998;&#37327;&#65292;&#25104;&#20026;&#29983;&#23384;&#20998;&#26512;&#20013;&#22791;&#21463;&#38738;&#30544;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#23558;&#24050;&#30693;&#39118;&#38505;&#22240;&#32032;&#65288;&#22914;&#24180;&#40836;&#21644;&#20020;&#24202;&#21464;&#37327;&#65289;&#21644;&#26032;&#20852;&#39118;&#38505;&#22240;&#32032;&#65288;&#22914;&#22270;&#20687;&#29305;&#24449;&#65289;&#25972;&#21512;&#22312;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#20013;&#12290;&#28982;&#32780;&#65292;&#24403;&#21442;&#25968;&#20998;&#37327;&#30340;&#32500;&#24230;&#36229;&#36807;&#26679;&#26412;&#22823;&#23567;&#26102;&#65292;&#27169;&#22411;&#25311;&#21512;&#21464;&#24471;&#22256;&#38590;&#65292;&#32780;&#38750;&#21442;&#25968;&#24314;&#27169;&#21017;&#38754;&#20020;&#32500;&#24230;&#28798;&#38590;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#32602;&#20989;&#25968;&#28145;&#24230;&#37096;&#20998;&#32447;&#24615;Cox&#27169;&#22411;&#65288;Penali
&lt;/p&gt;
&lt;p&gt;
Lung cancer is a leading cause of cancer mortality globally, highlighting the importance of understanding its mortality risks to design effective patient-centered therapies. The National Lung Screening Trial (NLST) employed computed tomography texture analysis, which provides objective measurements of texture patterns on CT scans, to quantify the mortality risks of lung cancer patients. Partially linear Cox models have gained popularity for survival analysis by dissecting the hazard function into parametric and nonparametric components, allowing for the effective incorporation of both well-established risk factors (such as age and clinical variables) and emerging risk factors (e.g., image features) within a unified framework. However, when the dimension of parametric components exceeds the sample size, the task of model fitting becomes formidable, while nonparametric modeling grapples with the curse of dimensionality. We propose a novel Penalized Deep Partially Linear Cox Model (Penali
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#26694;&#26550;&#8220;ConLinUCB&#8221;&#26469;&#35299;&#20915;&#23545;&#35805;&#24335;&#24773;&#22659;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#20449;&#24687;&#25972;&#21512;&#21644;&#25506;&#32034;&#24615;&#20851;&#38190;&#35789;&#36873;&#25321;&#30340;&#38382;&#39064;&#65292;&#20197;&#21152;&#36895;&#29992;&#25143;&#20559;&#22909;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2303.00315</link><description>&lt;p&gt;
&#23545;&#35805;&#24335;&#24773;&#22659;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#39640;&#25928;&#25506;&#32034;&#24615;&#20851;&#38190;&#35789;&#36873;&#25321;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Efficient Explorative Key-term Selection Strategies for Conversational Contextual Bandits. (arXiv:2303.00315v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.00315
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#26694;&#26550;&#8220;ConLinUCB&#8221;&#26469;&#35299;&#20915;&#23545;&#35805;&#24335;&#24773;&#22659;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#20449;&#24687;&#25972;&#21512;&#21644;&#25506;&#32034;&#24615;&#20851;&#38190;&#35789;&#36873;&#25321;&#30340;&#38382;&#39064;&#65292;&#20197;&#21152;&#36895;&#29992;&#25143;&#20559;&#22909;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#35805;&#24335;&#24773;&#22659;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#36890;&#36807;&#20598;&#23572;&#35810;&#38382;&#26174;&#24335;&#21453;&#39304;&#20013;&#30340;&#20851;&#38190;&#35789;&#26469;&#21152;&#24555;&#23398;&#20064;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#23384;&#22312;&#19968;&#20123;&#23616;&#38480;&#24615;&#12290;&#39318;&#20808;&#65292;&#20851;&#20110;&#20851;&#38190;&#35789;&#23618;&#38754;&#30340;&#23545;&#35805;&#21644;&#33218;&#32423;&#25512;&#33616;&#30340;&#20449;&#24687;&#27809;&#26377;&#34987;&#22949;&#21892;&#22320;&#32467;&#21512;&#36215;&#26469;&#20197;&#21152;&#36895;&#23398;&#20064;&#12290;&#20854;&#27425;&#65292;&#37325;&#35201;&#30340;&#26159;&#38382;&#19968;&#20123;&#25506;&#32034;&#24615;&#30340;&#20851;&#38190;&#35789;&#65292;&#20197;&#36805;&#36895;&#20102;&#35299;&#29992;&#25143;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#28508;&#22312;&#20852;&#36259;&#65292;&#20174;&#32780;&#21152;&#36895;&#29992;&#25143;&#20559;&#22909;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#32780;&#36825;&#22312;&#29616;&#26377;&#30740;&#31350;&#20013;&#20174;&#26410;&#34987;&#32771;&#34385;&#36807;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#8220;ConLinUCB&#8221;&#36825;&#19968;&#23545;&#35805;&#24335;&#20915;&#31574;&#36807;&#31243;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#23427;&#33021;&#22815;&#26356;&#22909;&#22320;&#23558;&#20851;&#38190;&#35789;&#23618;&#38754;&#21644;&#33218;&#32423;&#21453;&#39304;&#32467;&#21512;&#36215;&#26469;&#65292;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#19978;&#19968;&#27493;&#20272;&#35745;&#29992;&#25143;&#20559;&#22909;&#12290;&#22522;&#20110;&#36825;&#20010;&#26694;&#26550;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35774;&#35745;&#20102;&#20004;&#31181;&#24102;&#26377;&#25506;&#32034;&#24615;&#20851;&#38190;&#35789;&#36873;&#25321;&#31574;&#30053;&#30340;&#20915;&#31574;&#36807;&#31243;&#31639;&#27861;&#65292;&#21363;ConLinUCB-BS&#21644;ConLinUCB-MCR&#12290;
&lt;/p&gt;
&lt;p&gt;
Conversational contextual bandits elicit user preferences by occasionally querying for explicit feedback on key-terms to accelerate learning. However, there are aspects of existing approaches which limit their performance. First, information gained from key-term-level conversations and arm-level recommendations is not appropriately incorporated to speed up learning. Second, it is important to ask explorative key-terms to quickly elicit the user's potential interests in various domains to accelerate the convergence of user preference estimation, which has never been considered in existing works. To tackle these issues, we first propose ``ConLinUCB", a general framework for conversational bandits with better information incorporation, combining arm-level and key-term-level feedback to estimate user preference in one step at each time. Based on this framework, we further design two bandit algorithms with explorative key-term selection strategies, ConLinUCB-BS and ConLinUCB-MCR. We prove t
&lt;/p&gt;</description></item><item><title>mSAM&#26159;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#32858;&#21512;&#23545;&#25239;&#24615;&#25200;&#21160;&#24471;&#21040;&#30340;&#26356;&#26032;&#65292;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#27604;&#20256;&#32479;&#26041;&#27861;&#26356;&#24179;&#30340;&#26497;&#23567;&#20540;&#28857;&#65292;&#23454;&#39564;&#35777;&#23454;&#20102;&#20854;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2302.09693</link><description>&lt;p&gt;
mSAM: &#24494;&#25209;&#37327;&#24179;&#22343;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;
&lt;/p&gt;
&lt;p&gt;
mSAM: Micro-Batch-Averaged Sharpness-Aware Minimization. (arXiv:2302.09693v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09693
&lt;/p&gt;
&lt;p&gt;
mSAM&#26159;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#32858;&#21512;&#23545;&#25239;&#24615;&#25200;&#21160;&#24471;&#21040;&#30340;&#26356;&#26032;&#65292;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#27604;&#20256;&#32479;&#26041;&#27861;&#26356;&#24179;&#30340;&#26497;&#23567;&#20540;&#28857;&#65292;&#23454;&#39564;&#35777;&#23454;&#20102;&#20854;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26159;&#36807;&#21442;&#25968;&#21270;&#30340;&#65292;&#19981;&#21516;&#30340;&#26497;&#20540;&#21487;&#33021;&#23548;&#33268;&#24191;&#27867;&#21464;&#21270;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#65288;Sharpness-Aware Minimization&#65292;SAM&#65289;&#25216;&#26415;&#20462;&#25913;&#20102;&#22522;&#26412;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#20351;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26397;&#30528;&#26356;&#24179;&#30340;&#26497;&#23567;&#20540;&#28857;&#21069;&#36827;&#65292;&#36825;&#34987;&#35748;&#20026;&#33021;&#22815;&#23637;&#29616;&#20986;&#22686;&#24378;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#28145;&#20837;&#25506;&#35752;&#20102;&#19968;&#31181;&#29305;&#23450;&#30340;SAM&#21464;&#20307;&#65292;&#21363;&#24494;&#25209;&#37327;SAM&#65288;mSAM&#65289;&#12290;&#36825;&#31181;&#21464;&#20307;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36890;&#36807;&#23545;&#26469;&#33258;&#22810;&#20010;&#20998;&#29255;&#65288;&#24494;&#25209;&#37327;&#65289;&#30340;&#23545;&#25239;&#24615;&#25200;&#21160;&#24471;&#21040;&#30340;&#26356;&#26032;&#36827;&#34892;&#32858;&#21512;&#12290;&#25105;&#20204;&#23558;&#26368;&#36817;&#24320;&#21457;&#21644;&#30740;&#31350;&#30340;&#29992;&#20110;&#24179;&#22374;&#24615;&#20998;&#26512;&#30340;&#36890;&#29992;&#26694;&#26550;&#25193;&#23637;&#21040;&#29702;&#35770;&#19978;&#35777;&#26126;SAM&#23454;&#29616;&#20102;&#27604;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26356;&#24179;&#30340;&#26497;&#23567;&#20540;&#28857;&#65292;&#32780;mSAM&#27604;SAM&#23454;&#29616;&#20102;&#26356;&#21152;&#24179;&#22374;&#30340;&#26497;&#23567;&#20540;&#28857;&#12290;&#25105;&#20204;&#23545;&#21508;&#31181;&#22270;&#20687;&#20998;&#31867;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#36827;&#34892;&#20102;&#24443;&#24213;&#30340;&#23454;&#35777;&#35780;&#20272;&#20197;&#39564;&#35777;&#36825;&#19968;&#29702;&#35770;&#36827;&#23637;&#12290;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#19982;&#20197;&#21069;&#30340;&#24037;&#20316;&#30456;&#21453;&#65292;mSAM&#21487;&#20197;&#34987;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern deep learning models are over-parameterized, where different optima can result in widely varying generalization performance. The Sharpness-Aware Minimization (SAM) technique modifies the fundamental loss function that steers gradient descent methods toward flatter minima, which are believed to exhibit enhanced generalization prowess. Our study delves into a specific variant of SAM known as micro-batch SAM (mSAM). This variation involves aggregating updates derived from adversarial perturbations across multiple shards (micro-batches) of a mini-batch during training. We extend a recently developed and well-studied general framework for flatness analysis to theoretically show that SAM achieves flatter minima than SGD, and mSAM achieves even flatter minima than SAM. We provide a thorough empirical evaluation of various image classification and natural language processing tasks to substantiate this theoretical advancement. We also show that contrary to previous work, mSAM can be impl
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#23545;&#20110;&#28151;&#21512;&#25240;&#25187;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#24378;&#21270;&#23398;&#20064;&#30340;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#29702;&#35770;&#12290;&#20316;&#32773;&#21457;&#29616;&#65292;&#22312;&#28151;&#21512;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#20381;&#36182;&#20110;&#24635;&#21464;&#24322;&#28151;&#21512;&#26102;&#38388;&#12289;&#25240;&#25187;&#22240;&#23376;&#21644;&#35299;&#35823;&#24046;&#23481;&#24525;&#24230;&#12290;</title><link>http://arxiv.org/abs/2302.07477</link><description>&lt;p&gt;
&#23545;&#20110;&#28151;&#21512;&#25240;&#25187;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#24378;&#21270;&#23398;&#20064;&#30340;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Optimal Sample Complexity of Reinforcement Learning for Mixing Discounted Markov Decision Processes. (arXiv:2302.07477v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07477
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#23545;&#20110;&#28151;&#21512;&#25240;&#25187;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#24378;&#21270;&#23398;&#20064;&#30340;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#29702;&#35770;&#12290;&#20316;&#32773;&#21457;&#29616;&#65292;&#22312;&#28151;&#21512;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#20381;&#36182;&#20110;&#24635;&#21464;&#24322;&#28151;&#21512;&#26102;&#38388;&#12289;&#25240;&#25187;&#22240;&#23376;&#21644;&#35299;&#35823;&#24046;&#23481;&#24525;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#34920;&#26684;&#22411;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#23545;&#20110;&#22312;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#20013;&#26368;&#22823;&#21270;&#26080;&#31351;&#26102;&#38388;&#25240;&#25187;&#22870;&#21169;&#30340;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#29702;&#35770;&#12290;&#22312;&#36825;&#31181;&#35774;&#23450;&#19979;&#65292;&#24050;&#32463;&#20026;&#34920;&#26684;&#22411;&#38382;&#39064;&#24320;&#21457;&#20102;&#26368;&#20248;&#26368;&#22351;&#24773;&#20917;&#22797;&#26434;&#24230;&#32467;&#26524;&#65292;&#23548;&#33268;&#26679;&#26412;&#22797;&#26434;&#24230;&#20381;&#36182;&#20110;&#25240;&#25187;&#31995;&#25968;$\gamma$&#21644;&#35299;&#35823;&#24046;&#23481;&#24525;&#24230;$\epsilon$&#30340;&#24418;&#24335;&#20026;$\tilde \Theta((1-\gamma)^{-3}\epsilon^{-2})$&#65292;&#20854;&#20013;$\gamma$&#34920;&#31034;&#25240;&#25187;&#22240;&#23376;&#65292;$\epsilon$&#20026;&#35299;&#35823;&#24046;&#23481;&#24525;&#24230;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24863;&#20852;&#36259;&#30340;&#24212;&#29992;&#20013;&#65292;&#26368;&#20248;&#31574;&#30053;&#65288;&#25110;&#25152;&#26377;&#31574;&#30053;&#65289;&#20250;&#20135;&#29983;&#28151;&#21512;&#12290;&#25105;&#20204;&#30830;&#23450;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#20381;&#36182;&#20851;&#31995;&#20026;$\tilde \Theta(t_{\text{mix}}(1-\gamma)^{-2}\epsilon^{-2})$&#65292;&#20854;&#20013;$t_{\text{mix}}$&#26159;&#24635;&#21464;&#24322;&#28151;&#21512;&#26102;&#38388;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#22522;&#20110;&#20877;&#29983;&#22411;&#24605;&#24819;&#65292;&#25105;&#20204;&#35748;&#20026;&#36825;&#20123;&#24605;&#24819;&#23545;&#20110;&#30740;&#31350;&#19968;&#33324;&#29366;&#24577;&#31354;&#38388;MDPs&#30340;RL&#38382;&#39064;&#20855;&#26377;&#29420;&#31435;&#30340;&#20852;&#36259;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the optimal sample complexity theory of tabular reinforcement learning (RL) for maximizing the infinite horizon discounted reward in a Markov decision process (MDP). Optimal worst-case complexity results have been developed for tabular RL problems in this setting, leading to a sample complexity dependence on $\gamma$ and $\epsilon$ of the form $\tilde \Theta((1-\gamma)^{-3}\epsilon^{-2})$, where $\gamma$ denotes the discount factor and $\epsilon$ is the solution error tolerance. However, in many applications of interest, the optimal policy (or all policies) induces mixing. We establish that in such settings, the optimal sample complexity dependence is $\tilde \Theta(t_{\text{mix}}(1-\gamma)^{-2}\epsilon^{-2})$, where $t_{\text{mix}}$ is the total variation mixing time. Our analysis is grounded in regeneration-type ideas, which we believe are of independent interest, as they can be used to study RL problems for general state space MDPs.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20934;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#20013;&#36830;&#32493;&#21160;&#20316;&#29615;&#22659;&#19979;&#30340;&#20915;&#31574;&#38382;&#39064;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#21307;&#30103;&#24212;&#29992;&#20013;&#30830;&#23450;&#26368;&#20339;&#21058;&#37327;&#27700;&#24179;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2301.08940</link><description>&lt;p&gt;
&#20855;&#26377;&#36830;&#32493;&#21160;&#20316;&#30340;&#20934;&#26368;&#20248;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Quasi-optimal Reinforcement Learning with Continuous Actions. (arXiv:2301.08940v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.08940
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20934;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#20013;&#36830;&#32493;&#21160;&#20316;&#29615;&#22659;&#19979;&#30340;&#20915;&#31574;&#38382;&#39064;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#21307;&#30103;&#24212;&#29992;&#20013;&#30830;&#23450;&#26368;&#20339;&#21058;&#37327;&#27700;&#24179;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#22312;&#35768;&#22810;&#29616;&#23454;&#24212;&#29992;&#20013;&#38656;&#35201;&#22312;&#36830;&#32493;&#21160;&#20316;&#29615;&#22659;&#20013;&#20570;&#20986;&#20915;&#31574;&#12290;&#22312;&#21307;&#30103;&#27835;&#30103;&#26041;&#26696;&#30340;&#24320;&#21457;&#20013;&#65292;&#30830;&#23450;&#26368;&#20339;&#21058;&#37327;&#27700;&#24179;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#23558;&#29616;&#26377;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#24212;&#29992;&#20110;&#21307;&#30103;&#24212;&#29992;&#20013;&#30340;&#19968;&#20010;&#25361;&#25112;&#26159;&#65292;&#27969;&#34892;&#30340;&#26080;&#31351;&#25903;&#25345;&#38543;&#26426;&#31574;&#30053;&#65288;&#20363;&#22914;&#39640;&#26031;&#31574;&#30053;&#65289;&#21487;&#33021;&#20250;&#20998;&#37197;&#36807;&#39640;&#30340;&#21058;&#37327;&#65292;&#20005;&#37325;&#21361;&#23475;&#24739;&#32773;&#12290;&#22240;&#27492;&#65292;&#24341;&#23548;&#19968;&#20010;&#25903;&#25345;&#20165;&#21253;&#21547;&#36817;&#20284;&#26368;&#20248;&#21160;&#20316;&#30340;&#31574;&#30053;&#31867;&#21035;&#65292;&#24182;&#32553;&#23567;&#25928;&#26524;&#21644;&#21487;&#38752;&#24615;&#30340;&#21160;&#20316;&#25628;&#32034;&#21306;&#22495;&#26159;&#24456;&#37325;&#35201;&#30340;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#8220;&#20934;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#8221;&#65292;&#35813;&#31639;&#27861;&#22312;&#31163;&#32447;&#31574;&#30053;&#35774;&#32622;&#19979;&#21487;&#20197;&#36731;&#26494;&#20248;&#21270;&#65292;&#24182;&#22312;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#19979;&#20445;&#35777;&#25910;&#25947;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#25152;&#25552;&#20986;&#31639;&#27861;&#30340;&#19968;&#33268;&#24615;&#12289;&#26679;&#26412;&#22797;&#26434;&#24230;&#12289;&#36866;&#24212;&#24615;&#21644;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#20840;&#38754;&#30340;&#27169;&#25311;&#23454;&#39564;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many real-world applications of reinforcement learning (RL) require making decisions in continuous action environments. In particular, determining the optimal dose level plays a vital role in developing medical treatment regimes. One challenge in adapting existing RL algorithms to medical applications, however, is that the popular infinite support stochastic policies, e.g., Gaussian policy, may assign riskily high dosages and harm patients seriously. Hence, it is important to induce a policy class whose support only contains near-optimal actions, and shrink the action-searching area for effectiveness and reliability. To achieve this, we develop a novel \emph{quasi-optimal learning algorithm}, which can be easily optimized in off-policy settings with guaranteed convergence under general function approximations. Theoretically, we analyze the consistency, sample complexity, adaptability, and convergence of the proposed algorithm. We evaluate our algorithm with comprehensive simulated expe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32467;&#21512;&#39118;&#38505;&#22235;&#26041;&#29702;&#35770;&#65292;&#30740;&#31350;&#20102;&#25903;&#25345;&#21521;&#37327;&#22238;&#24402;&#65288;SVR&#65289;&#12290;&#30740;&#31350;&#32467;&#26524;&#21457;&#29616;&#65292;SVR&#30340;&#20004;&#31181;&#24418;&#24335;&#23545;&#24212;&#20110;&#31561;&#25928;&#35823;&#24046;&#24230;&#37327;&#30340;&#26368;&#23567;&#21270;&#65292;&#21516;&#26102;&#21152;&#19978;&#27491;&#21017;&#21270;&#24809;&#32602;&#39033;&#12290;&#36890;&#36807;&#26500;&#36896;&#22522;&#26412;&#39118;&#38505;&#22235;&#26041;&#26694;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;SVR&#26159;&#23545;&#20004;&#20010;&#23545;&#31216;&#26465;&#20214;&#20998;&#20301;&#25968;&#30340;&#24179;&#22343;&#25968;&#30340;&#28176;&#36817;&#26080;&#20559;&#20272;&#35745;&#37327;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;$\varepsilon$-SVR&#21644;$\nu$-SVR&#22312;&#19968;&#33324;&#38543;&#26426;&#29615;&#22659;&#19979;&#30340;&#31561;&#20215;&#24615;&#12290;</title><link>http://arxiv.org/abs/2212.09178</link><description>&lt;p&gt;
&#25903;&#25345;&#21521;&#37327;&#22238;&#24402;: &#39118;&#38505;&#22235;&#26041;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Support Vector Regression: Risk Quadrangle Framework. (arXiv:2212.09178v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.09178
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32467;&#21512;&#39118;&#38505;&#22235;&#26041;&#29702;&#35770;&#65292;&#30740;&#31350;&#20102;&#25903;&#25345;&#21521;&#37327;&#22238;&#24402;&#65288;SVR&#65289;&#12290;&#30740;&#31350;&#32467;&#26524;&#21457;&#29616;&#65292;SVR&#30340;&#20004;&#31181;&#24418;&#24335;&#23545;&#24212;&#20110;&#31561;&#25928;&#35823;&#24046;&#24230;&#37327;&#30340;&#26368;&#23567;&#21270;&#65292;&#21516;&#26102;&#21152;&#19978;&#27491;&#21017;&#21270;&#24809;&#32602;&#39033;&#12290;&#36890;&#36807;&#26500;&#36896;&#22522;&#26412;&#39118;&#38505;&#22235;&#26041;&#26694;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;SVR&#26159;&#23545;&#20004;&#20010;&#23545;&#31216;&#26465;&#20214;&#20998;&#20301;&#25968;&#30340;&#24179;&#22343;&#25968;&#30340;&#28176;&#36817;&#26080;&#20559;&#20272;&#35745;&#37327;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;$\varepsilon$-SVR&#21644;$\nu$-SVR&#22312;&#19968;&#33324;&#38543;&#26426;&#29615;&#22659;&#19979;&#30340;&#31561;&#20215;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#22522;&#26412;&#30340;&#39118;&#38505;&#22235;&#26041;&#29702;&#35770;&#30340;&#32972;&#26223;&#19979;&#30740;&#31350;&#20102;&#25903;&#25345;&#21521;&#37327;&#22238;&#24402;&#65288;SVR&#65289;&#65292;&#35813;&#29702;&#35770;&#23558;&#20248;&#21270;&#12289;&#39118;&#38505;&#31649;&#29702;&#21644;&#32479;&#35745;&#20272;&#35745;&#32852;&#31995;&#36215;&#26469;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;SVR&#30340;&#20004;&#31181;&#24418;&#24335;&#65292;$\varepsilon$-SVR&#21644;$\nu$-SVR&#65292;&#37117;&#23545;&#24212;&#20110;&#31561;&#25928;&#35823;&#24046;&#24230;&#37327;&#65288;&#20998;&#21035;&#20026;Vapnik&#35823;&#24046;&#21644;CVaR&#33539;&#25968;&#65289;&#30340;&#26368;&#23567;&#21270;&#65292;&#21516;&#26102;&#21152;&#19978;&#27491;&#21017;&#21270;&#24809;&#32602;&#39033;&#12290;&#36825;&#20123;&#35823;&#24046;&#24230;&#37327;&#21448;&#23450;&#20041;&#20102;&#30456;&#24212;&#30340;&#39118;&#38505;&#22235;&#26041;&#26694;&#12290;&#36890;&#36807;&#26500;&#36896;&#19982;SVR&#23545;&#24212;&#30340;&#22522;&#26412;&#39118;&#38505;&#22235;&#26041;&#26694;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;SVR&#26159;&#20004;&#20010;&#23545;&#31216;&#26465;&#20214;&#20998;&#20301;&#25968;&#30340;&#24179;&#22343;&#25968;&#30340;&#28176;&#36817;&#26080;&#20559;&#20272;&#35745;&#37327;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;&#19968;&#33324;&#38543;&#26426;&#29615;&#22659;&#20013;&#35777;&#26126;&#20102;$\varepsilon$-SVR&#21644;$\nu$-SVR&#30340;&#31561;&#20215;&#24615;&#12290;&#27492;&#22806;&#65292;SVR&#34987;&#34920;&#36848;&#20026;&#24102;&#26377;&#27491;&#21017;&#21270;&#24809;&#32602;&#39033;&#30340;&#27491;&#21017;&#20559;&#31163;&#26368;&#23567;&#21270;&#38382;&#39064;&#12290;&#26368;&#21518;&#65292;&#25512;&#23548;&#20102;&#22312;&#39118;&#38505;&#22235;&#26041;&#26694;&#26550;&#20013;&#30340;SVR&#30340;&#23545;&#20598;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates Support Vector Regression (SVR) in the context of the fundamental risk quadrangle theory, which links optimization, risk management, and statistical estimation. It is shown that both formulations of SVR, $\varepsilon$-SVR and $\nu$-SVR, correspond to the minimization of equivalent error measures (Vapnik error and CVaR norm, respectively) with a regularization penalty. These error measures, in turn, define the corresponding risk quadrangles. By constructing the fundamental risk quadrangle, which corresponds to SVR, we show that SVR is the asymptotically unbiased estimator of the average of two symmetric conditional quantiles. Further, we prove the equivalence of the $\varepsilon$-SVR and $\nu$-SVR in a general stochastic setting. Additionally, SVR is formulated as a regular deviation minimization problem with a regularization penalty. Finally, the dual formulation of SVR in the risk quadrangle framework is derived.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#22312;&#23384;&#22312;&#38750;&#39640;&#26031;&#22122;&#22768;&#24773;&#20917;&#19979;&#22833;&#25928;&#30340;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21363;&#36890;&#36807;&#21516;&#26102;&#35757;&#32451;&#19968;&#20010;&#33021;&#37327;&#27169;&#22411;&#26469;&#23398;&#20064;&#27491;&#30830;&#30340;&#22122;&#22768;&#20998;&#24067;&#12290;&#36890;&#36807;&#22810;&#20010;&#20363;&#23376;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#25913;&#36827;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2211.15498</link><description>&lt;p&gt;
&#20855;&#26377;&#26410;&#30693;&#27979;&#37327;&#22122;&#22768;&#30340;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Physics-informed neural networks with unknown measurement noise. (arXiv:2211.15498v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.15498
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#22312;&#23384;&#22312;&#38750;&#39640;&#26031;&#22122;&#22768;&#24773;&#20917;&#19979;&#22833;&#25928;&#30340;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21363;&#36890;&#36807;&#21516;&#26102;&#35757;&#32451;&#19968;&#20010;&#33021;&#37327;&#27169;&#22411;&#26469;&#23398;&#20064;&#27491;&#30830;&#30340;&#22122;&#22768;&#20998;&#24067;&#12290;&#36890;&#36807;&#22810;&#20010;&#20363;&#23376;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#25913;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;(PINNs)&#26159;&#19968;&#31181;&#26082;&#33021;&#25214;&#21040;&#35299;&#20915;&#26041;&#26696;&#21448;&#33021;&#35782;&#21035;&#20559;&#24494;&#20998;&#26041;&#31243;&#21442;&#25968;&#30340;&#28789;&#27963;&#26041;&#27861;&#12290;&#22823;&#22810;&#25968;&#30456;&#20851;&#30340;&#30740;&#31350;&#37117;&#20551;&#35774;&#25968;&#25454;&#26159;&#26080;&#22122;&#22768;&#30340;&#65292;&#25110;&#32773;&#26159;&#21463;&#24369;&#39640;&#26031;&#22122;&#22768;&#27745;&#26579;&#30340;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26631;&#20934;PINN&#26694;&#26550;&#22312;&#38750;&#39640;&#26031;&#22122;&#22768;&#24773;&#20917;&#19979;&#22833;&#25928;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#36825;&#20010;&#26681;&#26412;&#24615;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21363;&#21516;&#26102;&#35757;&#32451;&#19968;&#20010;&#33021;&#37327;&#27169;&#22411;(Energy-Based Model, EBM)&#26469;&#23398;&#20064;&#27491;&#30830;&#30340;&#22122;&#22768;&#20998;&#24067;&#12290;&#25105;&#20204;&#36890;&#36807;&#22810;&#20010;&#20363;&#23376;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#25913;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Physics-informed neural networks (PINNs) constitute a flexible approach to both finding solutions and identifying parameters of partial differential equations. Most works on the topic assume noiseless data, or data contaminated by weak Gaussian noise. We show that the standard PINN framework breaks down in case of non-Gaussian noise. We give a way of resolving this fundamental issue and we propose to jointly train an energy-based model (EBM) to learn the correct noise distribution. We illustrate the improved performance of our approach using multiple examples.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22686;&#24378;&#22411;&#29289;&#29702;&#30693;&#35782;&#32534;&#30721;&#31070;&#32463;&#32593;&#32476;(APINN)&#65292;&#37319;&#29992;&#36719;&#39046;&#22495;&#20998;&#35299;&#21644;&#21442;&#25968;&#20849;&#20139;&#65292;&#36890;&#36807;&#38376;&#25511;&#32593;&#32476;&#21021;&#22987;&#21270;&#21644;&#19968;&#33324;&#39046;&#22495;&#21644;&#20989;&#25968;&#20998;&#35299;&#26469;&#25913;&#36827;&#20102;&#25193;&#23637;&#29289;&#29702;&#30693;&#35782;&#32534;&#30721;&#31070;&#32463;&#32593;&#32476;(XPINN)&#21644;&#22522;&#26412;&#29289;&#29702;&#30693;&#35782;&#32534;&#30721;&#31070;&#32463;&#32593;&#32476;(PINN)&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2211.08939</link><description>&lt;p&gt;
&#22686;&#24378;&#22411;&#29289;&#29702;&#30693;&#35782;&#32534;&#30721;&#31070;&#32463;&#32593;&#32476; (APINNs)&#65306;&#22522;&#20110;&#38376;&#25511;&#32593;&#32476;&#30340;&#36719;&#39046;&#22495;&#20998;&#35299;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Augmented Physics-Informed Neural Networks (APINNs): A gating network-based soft domain decomposition methodology. (arXiv:2211.08939v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.08939
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22686;&#24378;&#22411;&#29289;&#29702;&#30693;&#35782;&#32534;&#30721;&#31070;&#32463;&#32593;&#32476;(APINN)&#65292;&#37319;&#29992;&#36719;&#39046;&#22495;&#20998;&#35299;&#21644;&#21442;&#25968;&#20849;&#20139;&#65292;&#36890;&#36807;&#38376;&#25511;&#32593;&#32476;&#21021;&#22987;&#21270;&#21644;&#19968;&#33324;&#39046;&#22495;&#21644;&#20989;&#25968;&#20998;&#35299;&#26469;&#25913;&#36827;&#20102;&#25193;&#23637;&#29289;&#29702;&#30693;&#35782;&#32534;&#30721;&#31070;&#32463;&#32593;&#32476;(XPINN)&#21644;&#22522;&#26412;&#29289;&#29702;&#30693;&#35782;&#32534;&#30721;&#31070;&#32463;&#32593;&#32476;(PINN)&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22686;&#24378;&#22411;&#29289;&#29702;&#30693;&#35782;&#32534;&#30721;&#31070;&#32463;&#32593;&#32476; (APINN)&#65292;&#37319;&#29992;&#36719;&#21487;&#35757;&#32451;&#30340;&#39046;&#22495;&#20998;&#35299;&#21644;&#28789;&#27963;&#30340;&#21442;&#25968;&#20849;&#20139;&#20197;&#36827;&#19968;&#27493;&#25913;&#36827;&#25193;&#23637;&#29289;&#29702;&#30693;&#35782;&#32534;&#30721;&#31070;&#32463;&#32593;&#32476; (XPINN) &#21644;&#22522;&#26412;&#29289;&#29702;&#30693;&#35782;&#32534;&#30721;&#31070;&#32463;&#32593;&#32476; (PINN) &#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#20351;&#29992;&#21487;&#35757;&#32451;&#30340;&#38376;&#25511;&#32593;&#32476;&#26469;&#27169;&#25311; XPINN &#30340;&#30828;&#20998;&#35299;&#65292;&#21487;&#20197;&#28789;&#27963;&#22320;&#24494;&#35843;&#20197;&#21457;&#29616;&#26356;&#22909;&#30340;&#20998;&#21306;&#12290;APINN&#30340;&#36755;&#20986;&#26159;&#20960;&#20010;&#23376;&#32593;&#32476;&#30340;&#26435;&#37325;&#24179;&#22343;&#20540;&#12290;APINN&#19981;&#38656;&#35201;&#22797;&#26434;&#30340;&#30028;&#38754;&#26465;&#20214;&#65292;&#24182;&#19988;&#20854;&#23376;&#32593;&#32476;&#21487;&#20197;&#21033;&#29992;&#25152;&#26377;&#35757;&#32451;&#26679;&#26412;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#20854;&#23376;&#22495;&#20013;&#30340;&#19968;&#37096;&#20998;&#35757;&#32451;&#25968;&#25454;&#12290;&#26368;&#21518;&#65292;&#27599;&#20010;&#23376;&#32593;&#32476;&#20849;&#20139;&#19968;&#37096;&#20998;&#20849;&#21516;&#21442;&#25968;&#65292;&#20197;&#25429;&#25417;&#27599;&#20010;&#20998;&#35299;&#20989;&#25968;&#20013;&#30340;&#30456;&#20284;&#32452;&#20214;&#12290;&#27492;&#22806;&#65292;&#26681;&#25454;&#32993;&#31561;&#20154;[2021]&#30340;PINN&#27867;&#21270;&#29702;&#35770;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;APINN&#21487;&#20197;&#36890;&#36807;&#36866;&#24403;&#30340;&#38376;&#25511;&#32593;&#32476;&#21021;&#22987;&#21270;&#21644;&#19968;&#33324;&#39046;&#22495;&#21644;&#20989;&#25968;&#20998;&#35299;&#26469;&#25913;&#21892;&#27867;&#21270;&#33021;&#21147;&#12290;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;APINN&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose the augmented physics-informed neural network (APINN), which adopts soft and trainable domain decomposition and flexible parameter sharing to further improve the extended PINN (XPINN) as well as the vanilla PINN methods. In particular, a trainable gate network is employed to mimic the hard decomposition of XPINN, which can be flexibly fine-tuned for discovering a potentially better partition. It weight-averages several sub-nets as the output of APINN. APINN does not require complex interface conditions, and its sub-nets can take advantage of all training samples rather than just part of the training data in their subdomains. Lastly, each sub-net shares part of the common parameters to capture the similar components in each decomposed function. Furthermore, following the PINN generalization theory in Hu et al. [2021], we show that APINN can improve generalization by proper gate network initialization and general domain &amp; function decomposition. Extensive experi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#28508;&#22312;&#22810;&#27169;&#24577;&#21151;&#33021;&#22270;&#27169;&#22411;&#20272;&#35745;&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#21516;&#26102;&#20272;&#35745;&#36716;&#25442;&#31639;&#23376;&#21644;&#28508;&#22312;&#22270;&#26469;&#22635;&#34917;&#24403;&#21069;&#31185;&#23398;&#26041;&#27861;&#22312;&#20272;&#35745;&#22810;&#27169;&#24577;&#21151;&#33021;&#25968;&#25454;&#22270;&#27169;&#22411;&#26041;&#38754;&#30340;&#31354;&#30333;</title><link>http://arxiv.org/abs/2210.17237</link><description>&lt;p&gt;
&#28508;&#22312;&#22810;&#27169;&#24577;&#21151;&#33021;&#22270;&#27169;&#22411;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Latent Multimodal Functional Graphical Model Estimation. (arXiv:2210.17237v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.17237
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#28508;&#22312;&#22810;&#27169;&#24577;&#21151;&#33021;&#22270;&#27169;&#22411;&#20272;&#35745;&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#21516;&#26102;&#20272;&#35745;&#36716;&#25442;&#31639;&#23376;&#21644;&#28508;&#22312;&#22270;&#26469;&#22635;&#34917;&#24403;&#21069;&#31185;&#23398;&#26041;&#27861;&#22312;&#20272;&#35745;&#22810;&#27169;&#24577;&#21151;&#33021;&#25968;&#25454;&#22270;&#27169;&#22411;&#26041;&#38754;&#30340;&#31354;&#30333;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20849;&#21516;&#22810;&#27169;&#24577;&#21151;&#33021;&#25968;&#25454;&#37319;&#38598;&#26159;&#19968;&#31181;&#29616;&#20195;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#36817;&#22312;&#31070;&#32463;&#23398;&#21644;&#29983;&#29289;&#31185;&#23398;&#20013;&#30340;&#24037;&#31243;&#31361;&#30772;&#65292;&#21487;&#20197;&#21516;&#26102;&#20174;&#21516;&#19968;&#20027;&#20307;&#20013;&#27979;&#37327;&#26469;&#33258;&#22810;&#31181;&#27169;&#24335;&#30340;&#21151;&#33021;&#25968;&#25454;&#12290;&#33719;&#21462;&#36825;&#26679;&#30340;&#25968;&#25454;&#30340;&#19968;&#20010;&#37325;&#35201;&#21160;&#26426;&#26159;&#36890;&#36807;&#32467;&#21512;&#22810;&#27169;&#24577;&#20449;&#21495;&#26469;&#21457;&#29616;&#28508;&#22312;&#30340;&#36830;&#25509;&#24615;&#12290;&#23613;&#31649;&#23384;&#22312;&#31185;&#23398;&#20852;&#36259;&#65292;&#20294;&#22312;&#20272;&#35745;&#22810;&#27169;&#24577;&#21151;&#33021;&#25968;&#25454;&#19979;&#30340;&#22270;&#27169;&#22411;&#26041;&#38754;&#20173;&#23384;&#22312;&#24046;&#36317;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#32508;&#21512;&#26694;&#26550;&#65292;&#23545;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#35782;&#21035;&#20174;&#35266;&#27979;&#31354;&#38388;&#21040;&#28508;&#22312;&#31354;&#38388;&#30340;&#31639;&#23376;&#26144;&#23556;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#21516;&#26102;&#20272;&#35745;&#36716;&#25442;&#31639;&#23376;&#21644;&#28508;&#22312;&#22270;&#12290;&#36825;&#20010;&#20272;&#35745;&#22120;&#22522;&#20110;&#20559;&#30456;&#20851;&#31639;&#23376;&#65292;&#25105;&#20204;&#20174;&#22810;&#20803;&#21040;&#21151;&#33021;&#35774;&#32622;&#20013;&#20005;&#26684;&#25512;&#24191;&#20102;&#23427;&#12290;&#25105;&#20204;&#30340;&#31243;&#24207;&#26159;pr&#23553;&#38381;&#30340;
&lt;/p&gt;
&lt;p&gt;
Joint multimodal functional data acquisition, where functional data from multiple modes are measured simultaneously from the same subject, has emerged as an exciting modern approach enabled by recent engineering breakthroughs in the neurological and biological sciences. One prominent motivation to acquire such data is to enable new discoveries of the underlying connectivity by combining multimodal signals. Despite the scientific interest, there remains a gap in principled statistical methods for estimating the graph underlying multimodal functional data. To this end, we propose a new integrative framework that models the data generation process and identifies operators mapping from the observation space to the latent space. We then develop an estimator that simultaneously estimates the transformation operators and the latent graph. This estimator is based on the partial correlation operator, which we rigorously extend from the multivariate to the functional setting. Our procedure is pr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#35299;&#20915;&#22823;&#26102;&#38388;&#38271;&#24230;&#19979;&#30340;&#36125;&#21494;&#26031;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#26368;&#20248;&#31574;&#30053;&#65292;&#24182;&#19988;&#20854;&#35745;&#31639;&#25104;&#26412;&#19981;&#21253;&#25324;&#20381;&#36182;&#20110;&#26102;&#38388;&#38271;&#24230;&#30340;&#39033;&#12290;</title><link>http://arxiv.org/abs/2210.07513</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#36830;&#32493;&#26102;&#38388;&#26497;&#38480;
&lt;/p&gt;
&lt;p&gt;
Continuous-in-time Limit for Bayesian Bandits. (arXiv:2210.07513v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.07513
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#35299;&#20915;&#22823;&#26102;&#38388;&#38271;&#24230;&#19979;&#30340;&#36125;&#21494;&#26031;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#26368;&#20248;&#31574;&#30053;&#65292;&#24182;&#19988;&#20854;&#35745;&#31639;&#25104;&#26412;&#19981;&#21253;&#25324;&#20381;&#36182;&#20110;&#26102;&#38388;&#38271;&#24230;&#30340;&#39033;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#36125;&#21494;&#26031;&#35774;&#32622;&#19979;&#30340;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#36125;&#21494;&#26031;&#26041;&#27861;&#23558;&#36172;&#21338;&#26426;&#38382;&#39064;&#21046;&#23450;&#20026;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#65292;&#26088;&#22312;&#23547;&#25214;&#26368;&#20248;&#31574;&#30053;&#20197;&#26368;&#23567;&#21270;&#36125;&#21494;&#26031;&#36951;&#25022;&#12290;&#38754;&#23545;&#30340;&#20027;&#35201;&#25361;&#25112;&#20043;&#19968;&#26159;&#65292;&#24403;&#38382;&#39064;&#30340;&#26102;&#38388;&#38271;&#24230;&#25110;&#33218;&#25968;&#36739;&#22823;&#26102;&#65292;&#35745;&#31639;&#26368;&#20248;&#31574;&#30053;&#36890;&#24120;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#22312;&#36866;&#24403;&#30340;&#37325;&#32553;&#25918;&#19979;&#65292;&#36125;&#21494;&#26031;&#36172;&#21338;&#26426;&#38382;&#39064;&#25910;&#25947;&#20110;&#19968;&#20010;&#36830;&#32493;&#30340;&#21704;&#23494;&#23572;&#39039; - &#38597;&#21508;&#27604; - &#36125;&#23572;&#26364;&#65288;HJB&#65289;&#26041;&#31243;&#12290;&#23545;&#20110;&#24120;&#35265;&#30340;&#19968;&#20123;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#21487;&#20197;&#26126;&#30830;&#33719;&#24471;&#26497;&#38480;HJB&#26041;&#31243;&#30340;&#26368;&#20248;&#31574;&#30053;&#65292;&#24182;&#19988;&#22312;&#26080;&#27861;&#26126;&#30830;&#35299;&#20915;&#26041;&#26696;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#35299;&#20915;HJB&#26041;&#31243;&#30340;&#25968;&#23383;&#26041;&#27861;&#12290;&#22522;&#20110;&#36825;&#20123;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#35299;&#20915;&#22823;&#26102;&#38388;&#38271;&#24230;&#19979;&#30340;&#36125;&#21494;&#26031;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#26368;&#20248;&#31574;&#30053;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#35745;&#31639;&#25104;&#26412;&#19981;&#21253;&#25324;&#20381;&#36182;&#20110;&#26102;&#38388;&#38271;&#24230;&#30340;&#39033;&#65292;&#36825;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#12290;&#25968;&#20540;&#27169;&#25311;&#34920;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper revisits the bandit problem in the Bayesian setting. The Bayesian approach formulates the bandit problem as an optimization problem, and the goal is to find the optimal policy which minimizes the Bayesian regret. One of the main challenges facing the Bayesian approach is that computation of the optimal policy is often intractable, especially when the length of the problem horizon or the number of arms is large. In this paper, we first show that under a suitable rescaling, the Bayesian bandit problem converges toward a continuous Hamilton-Jacobi-Bellman (HJB) equation. The optimal policy for the limiting HJB equation can be explicitly obtained for several common bandit problems, and we give numerical methods to solve the HJB equation when an explicit solution is not available. Based on these results, we propose an approximate Bayes-optimal policy for solving Bayesian bandit problems with large horizons. Our method has the added benefit that its computational cost does not inc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#23545;&#31216;&#30340;&#22806;&#37096;&#32858;&#31867;&#26377;&#25928;&#24230;&#37327;&#26041;&#27861;&#65292;&#26088;&#22312;&#21306;&#20998;&#19981;&#21516;&#20219;&#21153;&#31867;&#22411;&#19978;&#34920;&#29616;&#33391;&#22909;&#21644;&#31995;&#32479;&#24615;&#34920;&#29616;&#19981;&#20339;&#30340;&#32858;&#31867;&#31639;&#27861;&#12290;&#19982;&#20256;&#32479;&#30340;&#20869;&#37096;&#24230;&#37327;&#19981;&#21516;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#21442;&#32771;&#30495;&#23454;&#20998;&#32452;&#36827;&#34892;&#35780;&#20272;&#65292;&#24182;&#24357;&#34917;&#20102;&#29616;&#26377;&#26041;&#27861;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2209.02935</link><description>&lt;p&gt;
&#35268;&#33539;&#21270;&#32858;&#31867;&#20934;&#30830;&#24230;&#65306;&#19968;&#31181;&#38750;&#23545;&#31216;&#30340;&#22806;&#37096;&#32858;&#31867;&#26377;&#25928;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
Normalised clustering accuracy: An asymmetric external cluster validity measure. (arXiv:2209.02935v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.02935
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#23545;&#31216;&#30340;&#22806;&#37096;&#32858;&#31867;&#26377;&#25928;&#24230;&#37327;&#26041;&#27861;&#65292;&#26088;&#22312;&#21306;&#20998;&#19981;&#21516;&#20219;&#21153;&#31867;&#22411;&#19978;&#34920;&#29616;&#33391;&#22909;&#21644;&#31995;&#32479;&#24615;&#34920;&#29616;&#19981;&#20339;&#30340;&#32858;&#31867;&#31639;&#27861;&#12290;&#19982;&#20256;&#32479;&#30340;&#20869;&#37096;&#24230;&#37327;&#19981;&#21516;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#21442;&#32771;&#30495;&#23454;&#20998;&#32452;&#36827;&#34892;&#35780;&#20272;&#65292;&#24182;&#24357;&#34917;&#20102;&#29616;&#26377;&#26041;&#27861;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27809;&#26377;&#19968;&#20010;&#26368;&#22909;&#30340;&#32858;&#31867;&#31639;&#27861;&#65292;&#25105;&#20204;&#20173;&#28982;&#24076;&#26395;&#33021;&#22815;&#21306;&#20998;&#20986;&#22312;&#26576;&#20123;&#20219;&#21153;&#31867;&#22411;&#19978;&#34920;&#29616;&#33391;&#22909;&#21644;&#31995;&#32479;&#24615;&#34920;&#29616;&#19981;&#20339;&#30340;&#26041;&#27861;&#12290;&#20256;&#32479;&#19978;&#65292;&#32858;&#31867;&#31639;&#27861;&#20351;&#29992;&#20869;&#37096;&#25110;&#22806;&#37096;&#26377;&#25928;&#24230;&#37327;&#36827;&#34892;&#35780;&#20272;&#12290;&#20869;&#37096;&#24230;&#37327;&#37327;&#21270;&#25152;&#24471;&#20998;&#21306;&#30340;&#19981;&#21516;&#26041;&#38754;&#65292;&#20363;&#22914;&#65292;&#31751;&#32039;&#23494;&#24230;&#30340;&#24179;&#22343;&#31243;&#24230;&#25110;&#28857;&#30340;&#21487;&#20998;&#31163;&#24615;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#26159;&#26377;&#38382;&#39064;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#20419;&#20351;&#30340;&#32858;&#31867;&#26377;&#26102;&#21487;&#33021;&#26159;&#26080;&#24847;&#20041;&#30340;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#22806;&#37096;&#24230;&#37327;&#23558;&#31639;&#27861;&#30340;&#36755;&#20986;&#19982;&#30001;&#19987;&#23478;&#25552;&#20379;&#30340;&#21442;&#32771;&#30495;&#23454;&#20998;&#32452;&#36827;&#34892;&#27604;&#36739;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35748;&#20026;&#24120;&#29992;&#30340;&#32463;&#20856;&#20998;&#21306;&#30456;&#20284;&#24615;&#35780;&#20998;&#65292;&#20363;&#22914;&#35268;&#33539;&#21270;&#20114;&#20449;&#24687;&#12289;Fowlkes-Mallows&#25110;&#35843;&#25972;&#20848;&#24503;&#25351;&#25968;&#65292;&#32570;&#23569;&#19968;&#20123;&#21487;&#21462;&#30340;&#23646;&#24615;&#65292;&#20363;&#22914;&#65292;&#23427;&#20204;&#19981;&#33021;&#27491;&#30830;&#35782;&#21035;&#26368;&#22351;&#24773;&#20917;&#65292;&#20063;&#19981;&#26131;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is no, nor will there ever be, single best clustering algorithm, but we would still like to be able to distinguish between methods which work well on certain task types and those that systematically underperform. Clustering algorithms are traditionally evaluated using either internal or external validity measures. Internal measures quantify different aspects of the obtained partitions, e.g., the average degree of cluster compactness or point separability. Yet, their validity is questionable, because the clusterings they promote can sometimes be meaningless. External measures, on the other hand, compare the algorithms' outputs to the reference, ground truth groupings that are provided by experts. In this paper, we argue that the commonly-used classical partition similarity scores, such as the normalised mutual information, Fowlkes-Mallows, or adjusted Rand index, miss some desirable properties, e.g., they do not identify worst-case scenarios correctly or are not easily interpretab
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#37030;&#23398;&#20064;&#30340;&#19981;&#30830;&#23450;&#24615;&#26694;&#26550;&#65292;&#27599;&#20010;&#23458;&#25143;&#31471;&#22312;&#27599;&#36718;&#20013;&#25512;&#26029;&#20854;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#21644;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#65292;&#24182;&#23558;&#20854;&#33976;&#39311;&#20026;&#21333;&#19968;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21457;&#36865;&#32473;&#26381;&#21153;&#22120;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#35299;&#20915;&#29616;&#26377;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#26080;&#27861;&#20272;&#35745;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#26377;&#38480;&#25968;&#25454;&#29615;&#22659;&#19979;&#21462;&#24471;&#26356;&#20934;&#30830;&#30340;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2206.07562</link><description>&lt;p&gt;
&#36890;&#36807;&#33976;&#39311;&#39044;&#27979;&#20998;&#24067;&#30340;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Federated Learning with Uncertainty via Distilled Predictive Distributions. (arXiv:2206.07562v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.07562
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#37030;&#23398;&#20064;&#30340;&#19981;&#30830;&#23450;&#24615;&#26694;&#26550;&#65292;&#27599;&#20010;&#23458;&#25143;&#31471;&#22312;&#27599;&#36718;&#20013;&#25512;&#26029;&#20854;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#21644;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#65292;&#24182;&#23558;&#20854;&#33976;&#39311;&#20026;&#21333;&#19968;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21457;&#36865;&#32473;&#26381;&#21153;&#22120;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#35299;&#20915;&#29616;&#26377;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#26080;&#27861;&#20272;&#35745;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#26377;&#38480;&#25968;&#25454;&#29615;&#22659;&#19979;&#21462;&#24471;&#26356;&#20934;&#30830;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#26080;&#27861;&#20272;&#35745;&#27169;&#22411;/&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#22240;&#20026;&#23458;&#25143;&#31471;&#27169;&#22411;&#20351;&#29992;&#26631;&#20934;&#25439;&#22833;&#20989;&#25968;&#26368;&#23567;&#21270;&#26041;&#27861;&#36827;&#34892;&#35757;&#32451;&#65292;&#24573;&#30053;&#20102;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#29305;&#21035;&#26159;&#22312;&#26377;&#38480;&#25968;&#25454;&#29615;&#22659;&#20013;&#65292;&#32771;&#34385;&#27599;&#20010;&#23458;&#25143;&#31471;&#27169;&#22411;&#21442;&#25968;&#30340;&#19981;&#30830;&#23450;&#24615;&#26159;&#26377;&#30410;&#30340;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#23548;&#33268;&#26356;&#20934;&#30830;&#30340;&#39044;&#27979;&#65292;&#24182;&#19988;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#21487;&#20197;&#29992;&#20110;&#35832;&#22914;&#20998;&#24067;&#22806;&#65288;OOD&#65289;&#26816;&#27979;&#21644;&#24207;&#36143;&#20915;&#31574;&#20219;&#21153;&#65288;&#22914;&#20027;&#21160;&#23398;&#20064;&#65289;&#31561;&#20219;&#21153;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#24102;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#65292;&#22312;&#27599;&#19968;&#36718;&#20013;&#65292;&#27599;&#20010;&#23458;&#25143;&#31471;&#25512;&#26029;&#20854;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#21644;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#65288;PPD&#65289;&#65292;&#23558;PPD&#33976;&#39311;&#25104;&#19968;&#20010;&#21333;&#19968;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#23558;&#35813;&#32593;&#32476;&#21457;&#36865;&#21040;&#26381;&#21153;&#22120;&#12290;&#19982;&#26368;&#36817;&#19968;&#20123;&#36125;&#21494;&#26031;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#35201;&#27714;&#21457;&#36865;&#25152;&#26377;&#21407;&#22987;&#25968;&#25454;&#33267;&#26381;&#21153;&#22120;&#65292;&#20445;&#25252;&#20102;&#23458;&#25143;&#38544;&#31169;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most existing federated learning methods are unable to estimate model/predictive uncertainty since the client models are trained using the standard loss function minimization approach which ignores such uncertainties. In many situations, however, especially in limited data settings, it is beneficial to take into account the uncertainty in the model parameters at each client as it leads to more accurate predictions and also because reliable estimates of uncertainty can be used for tasks, such as out-of-distribution (OOD) detection, and sequential decision-making tasks, such as active learning. We present a framework for federated learning with uncertainty where, in each round, each client infers the posterior distribution over its parameters as well as the posterior predictive distribution (PPD), distills the PPD into a single deep neural network, and sends this network to the server. Unlike some of the recent Bayesian approaches to federated learning, our approach does not require send
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;GNN&#22312;&#33410;&#28857;&#20998;&#31867;&#20013;&#25554;&#20540;&#24102;&#38480;&#20989;&#25968;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;GNN&#32467;&#26500;&#20197;&#30456;&#21516;&#30340;&#31934;&#24230;&#25554;&#20540;&#24102;&#38480;&#20989;&#25968;&#25152;&#38656;&#30340;&#26435;&#37325;&#27604;&#20351;&#29992;&#23436;&#20840;&#36830;&#25509;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#23569;&#24471;&#22810;&#12290;</title><link>http://arxiv.org/abs/2206.05904</link><description>&lt;p&gt;
GNN&#22312;&#25512;&#24191;&#24102;&#38480;&#20989;&#25968;&#26041;&#38754;&#30340;&#20248;&#36234;&#24615;&#27604;NN&#26356;&#21152;&#26126;&#26174;
&lt;/p&gt;
&lt;p&gt;
Superiority of GNN over NN in generalizing bandlimited functions. (arXiv:2206.05904v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.05904
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;GNN&#22312;&#33410;&#28857;&#20998;&#31867;&#20013;&#25554;&#20540;&#24102;&#38480;&#20989;&#25968;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;GNN&#32467;&#26500;&#20197;&#30456;&#21516;&#30340;&#31934;&#24230;&#25554;&#20540;&#24102;&#38480;&#20989;&#25968;&#25152;&#38656;&#30340;&#26435;&#37325;&#27604;&#20351;&#29992;&#23436;&#20840;&#36830;&#25509;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#23569;&#24471;&#22810;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#20197;&#20854;&#25972;&#21512;&#22270;&#24418;&#20449;&#24687;&#30340;&#33021;&#21147;&#34987;&#24191;&#27867;&#29992;&#20110;&#25968;&#25454;&#20998;&#26512;&#12290;&#28982;&#32780;&#65292;GNN&#30340;&#34920;&#36798;&#33021;&#21147;&#20165;&#38024;&#23545;&#22270;&#32423;&#20219;&#21153;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#32780;&#19981;&#26159;&#38024;&#23545;&#33410;&#28857;&#32423;&#20219;&#21153;&#65292;&#20363;&#22914;&#33410;&#28857;&#20998;&#31867;&#65292;&#20854;&#20013;&#35797;&#22270;&#20174;&#35266;&#23519;&#21040;&#30340;&#33410;&#28857;&#26631;&#31614;&#20013;&#25554;&#20540;&#20986;&#32570;&#22833;&#30340;&#26631;&#31614;&#20449;&#24687;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;GNN&#22312;&#25152;&#36848;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#23427;&#23454;&#36136;&#19978;&#26159;&#19968;&#20010;&#20989;&#25968;&#25554;&#20540;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;GNN&#25554;&#20540;$\mathbb{R}^d$&#20013;&#24102;&#38480;&#20989;&#25968;&#25152;&#38656;&#30340;&#26435;&#37325;&#21644;&#23618;&#25968;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;&#20351;&#29992;GNN&#26550;&#26500;&#20197;$\epsilon$-&#36817;&#20284;&#31163;&#25955;&#24102;&#38480;&#20449;&#21495;&#20165;&#38656;&#35201;$O((\log \epsilon^{-1})^{d})$&#20010;&#26435;&#37325;&#65292;&#36825;&#27604;&#20351;&#29992;&#23436;&#20840;&#36830;&#25509;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#24471;&#21040;&#30340;&#26368;&#20339;&#32467;&#26524;&#30340;&#25152;&#38656;&#26435;&#37325;&#23569;&#24471;&#22810; - &#29305;&#21035;&#22320;&#65292;&#20351;&#29992;&#20351;&#29992;$O((\log \epsilon^{-1})^{d})$&#20010;&#26679;&#26412;&#26469;&#35757;&#32451;GNN&#20197;$\epsilon$-&#36924;&#36817;&#24102;&#38480;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Network (GNN) with its ability to integrate graph information has been widely used for data analyses. However, the expressive power of GNN has only been studied for graph-level tasks but not for node-level tasks, such as node classification, where one tries to interpolate missing nodal labels from the observed ones. In this paper, we study the expressive power of GNN for the said classification task, which is in essence a function interpolation problem. Explicitly, we derive the number of weights and layers needed for a GNN to interpolate a band-limited function in $\mathbb{R}^d$. Our result shows that, the number of weights needed to $\epsilon$-approximate a bandlimited function using the GNN architecture is much fewer than the best known one using a fully connected neural network (NN) - in particular, one only needs $O((\log \epsilon^{-1})^{d})$ weights using a GNN trained by $O((\log \epsilon^{-1})^{d})$ samples to $\epsilon$-approximate a discretized bandlimited signal
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#38750;&#21516;&#24577;&#22270;&#30340;&#35299;&#32806;&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;DSSL&#65289;&#26694;&#26550;&#12290;&#36890;&#36807;&#27169;&#25311;&#33410;&#28857;&#21644;&#38142;&#25509;&#30340;&#29983;&#25104;&#36807;&#31243;&#65292;&#23558;&#19981;&#21516;&#37051;&#22495;&#20043;&#38388;&#30340;&#19981;&#21516;&#28508;&#22312;&#35821;&#20041;&#35299;&#32806;&#21040;&#33258;&#30417;&#30563;&#23398;&#20064;&#36807;&#31243;&#20013;&#12290;&#35813;&#26694;&#26550;&#23545;&#32534;&#30721;&#22120;&#19981;&#25935;&#24863;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#39044;&#21046;&#30340;&#22686;&#24378;&#65292;&#23545;&#19981;&#21516;&#30340;&#22270;&#20855;&#26377;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/2206.03601</link><description>&lt;p&gt;
&#38750;&#21516;&#24577;&#22270;&#30340;&#35299;&#32806;&#33258;&#30417;&#30563;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Decoupled Self-supervised Learning for Non-Homophilous Graphs. (arXiv:2206.03601v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.03601
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#38750;&#21516;&#24577;&#22270;&#30340;&#35299;&#32806;&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;DSSL&#65289;&#26694;&#26550;&#12290;&#36890;&#36807;&#27169;&#25311;&#33410;&#28857;&#21644;&#38142;&#25509;&#30340;&#29983;&#25104;&#36807;&#31243;&#65292;&#23558;&#19981;&#21516;&#37051;&#22495;&#20043;&#38388;&#30340;&#19981;&#21516;&#28508;&#22312;&#35821;&#20041;&#35299;&#32806;&#21040;&#33258;&#30417;&#30563;&#23398;&#20064;&#36807;&#31243;&#20013;&#12290;&#35813;&#26694;&#26550;&#23545;&#32534;&#30721;&#22120;&#19981;&#25935;&#24863;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#39044;&#21046;&#30340;&#22686;&#24378;&#65292;&#23545;&#19981;&#21516;&#30340;&#22270;&#20855;&#26377;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22270;&#19978;&#36827;&#34892;&#33410;&#28857;&#34920;&#31034;&#23398;&#20064;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#38382;&#39064;&#12290;&#22823;&#37096;&#20998;&#29616;&#26377;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#37117;&#20551;&#35774;&#22270;&#26159;&#21516;&#36136;&#30340;&#65292;&#21363;&#36830;&#25509;&#30340;&#33410;&#28857;&#36890;&#24120;&#23646;&#20110;&#21516;&#19968;&#31867;&#25110;&#20855;&#26377;&#30456;&#20284;&#30340;&#29305;&#24449;&#12290;&#28982;&#32780;&#65292;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#22270;&#20013;&#65292;&#36825;&#31181;&#21516;&#36136;&#24615;&#30340;&#20551;&#35774;&#24182;&#19981;&#24635;&#26159;&#25104;&#31435;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#35299;&#32806;&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;DSSL&#65289;&#26694;&#26550;&#12290;DSSL&#36890;&#36807;&#20174;&#35821;&#20041;&#32467;&#26500;&#30340;&#28508;&#21464;&#37327;&#24314;&#27169;&#20013;&#27169;&#25311;&#33410;&#28857;&#21644;&#38142;&#25509;&#30340;&#29983;&#25104;&#36807;&#31243;&#65292;&#23558;&#19981;&#21516;&#37051;&#22495;&#20043;&#38388;&#30340;&#19981;&#21516;&#28508;&#22312;&#35821;&#20041;&#35299;&#32806;&#21040;&#33258;&#30417;&#30563;&#23398;&#20064;&#36807;&#31243;&#20013;&#12290;&#25105;&#20204;&#30340;DSSL&#26694;&#26550;&#23545;&#32534;&#30721;&#22120;&#19981;&#25935;&#24863;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#39044;&#21046;&#30340;&#22686;&#24378;&#65292;&#22240;&#27492;&#36866;&#29992;&#20110;&#19981;&#21516;&#30340;&#22270;&#12290;&#20026;&#20102;&#26377;&#25928;&#20248;&#21270;&#35813;&#26694;&#26550;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#33258;&#30417;&#30563;&#30446;&#26631;&#30340;&#35777;&#25454;&#19979;&#30028;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#20855;&#26377;&#21464;&#20998;&#29305;&#24615;&#30340;&#21487;&#25193;&#23637;&#35757;&#32451;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the problem of conducting self-supervised learning for node representation learning on graphs. Most existing self-supervised learning methods assume the graph is homophilous, where linked nodes often belong to the same class or have similar features. However, such assumptions of homophily do not always hold in real-world graphs. We address this problem by developing a decoupled self-supervised learning (DSSL) framework for graph neural networks. DSSL imitates a generative process of nodes and links from latent variable modeling of the semantic structure, which decouples different underlying semantics between different neighborhoods into the self-supervised learning process. Our DSSL framework is agnostic to the encoders and does not need prefabricated augmentations, thus is flexible to different graphs. To effectively optimize the framework, we derive the evidence lower bound of the self-supervised objective and develop a scalable training algorithm with variational 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20174;&#22823;&#22411;&#25968;&#25454;&#38598;&#20013;&#25552;&#21462;&#20302;&#32500;&#25688;&#35201;&#32479;&#35745;&#37327;&#30340;&#37325;&#35201;&#24615;&#65292;&#25552;&#20986;&#20102;&#36890;&#36807;&#26368;&#23567;&#21270;&#21518;&#39564;&#29109;&#26469;&#33719;&#21462;&#26368;&#20248;&#25688;&#35201;&#32479;&#35745;&#37327;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#36341;&#24314;&#35758;&#21644;&#31034;&#20363;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2206.02340</link><description>&lt;p&gt;
&#26368;&#23567;&#21270;&#21518;&#39564;&#29109;&#20135;&#29983;&#20102;&#26368;&#20248;&#25688;&#35201;&#32479;&#35745;&#37327;
&lt;/p&gt;
&lt;p&gt;
Minimising the Expected Posterior Entropy Yields Optimal Summary Statistics. (arXiv:2206.02340v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.02340
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20174;&#22823;&#22411;&#25968;&#25454;&#38598;&#20013;&#25552;&#21462;&#20302;&#32500;&#25688;&#35201;&#32479;&#35745;&#37327;&#30340;&#37325;&#35201;&#24615;&#65292;&#25552;&#20986;&#20102;&#36890;&#36807;&#26368;&#23567;&#21270;&#21518;&#39564;&#29109;&#26469;&#33719;&#21462;&#26368;&#20248;&#25688;&#35201;&#32479;&#35745;&#37327;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#36341;&#24314;&#35758;&#21644;&#31034;&#20363;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#22823;&#22411;&#25968;&#25454;&#38598;&#20013;&#25552;&#21462;&#20302;&#32500;&#25688;&#35201;&#32479;&#35745;&#37327;&#23545;&#20110;&#39640;&#25928;&#65288;&#26080;&#20284;&#28982;&#65289;&#25512;&#26029;&#38750;&#24120;&#37325;&#35201;&#12290;&#25105;&#20204;&#23545;&#19981;&#21516;&#31867;&#21035;&#30340;&#25688;&#35201;&#36827;&#34892;&#20102;&#34920;&#24449;&#65292;&#24182;&#35777;&#26126;&#23427;&#20204;&#23545;&#20110;&#27491;&#30830;&#20998;&#26512;&#38477;&#32500;&#31639;&#27861;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#24314;&#35758;&#36890;&#36807;&#22312;&#27169;&#22411;&#30340;&#20808;&#39564;&#39044;&#27979;&#20998;&#24067;&#19979;&#26368;&#23567;&#21270;&#26399;&#26395;&#21518;&#39564;&#29109;&#65288;EPE&#65289;&#26469;&#33719;&#21462;&#25688;&#35201;&#12290;&#35768;&#22810;&#29616;&#26377;&#26041;&#27861;&#31561;&#25928;&#20110;&#25110;&#26159;&#26368;&#23567;&#21270;EPE&#30340;&#29305;&#27530;&#25110;&#26497;&#38480;&#24773;&#20917;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#33719;&#21462;&#26368;&#23567;&#21270;EPE&#30340;&#39640;&#20445;&#30495;&#25688;&#35201;&#65307;&#25105;&#20204;&#23558;&#20854;&#24212;&#29992;&#20110;&#22522;&#20934;&#21644;&#30495;&#23454;&#19990;&#30028;&#30340;&#31034;&#20363;&#12290;&#25105;&#20204;&#26082;&#25552;&#20379;&#20102;&#33719;&#21462;&#26377;&#25928;&#25688;&#35201;&#30340;&#32479;&#19968;&#35270;&#35282;&#65292;&#21448;&#20026;&#23454;&#36341;&#32773;&#25552;&#20379;&#20102;&#20855;&#20307;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
Extracting low-dimensional summary statistics from large datasets is essential for efficient (likelihood-free) inference. We characterise different classes of summaries and demonstrate their importance for correctly analysing dimensionality reduction algorithms. We propose obtaining summaries by minimising the expected posterior entropy (EPE) under the prior predictive distribution of the model. Many existing methods are equivalent to or are special or limiting cases of minimising the EPE. We develop a method to obtain high-fidelity summaries that minimise the EPE; we apply it to benchmark and real-world examples. We both offer a unifying perspective for obtaining informative summaries and provide concrete recommendations for practitioners.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#38750;&#21442;&#25968;&#22238;&#24402;&#35774;&#32622;&#20013;&#21033;&#29992;&#31232;&#30095;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;Gibbs&#21518;&#39564;&#20998;&#24067;&#65292;&#36890;&#36807;Metropolis-adjusted Langevin&#31639;&#27861;&#21487;&#20197;&#35775;&#38382;&#21518;&#39564;&#20998;&#24067;&#12290;&#36890;&#36807;&#23545;&#32593;&#32476;&#26435;&#37325;&#30340;&#31232;&#30095;&#38598;&#21512;&#36827;&#34892;&#32479;&#19968;&#20808;&#39564;&#30340;&#28151;&#21512;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#33021;&#22815;&#36866;&#24212;&#26410;&#30693;&#30340;&#27491;&#21017;&#24615;&#21644;&#23618;&#27425;&#32467;&#26500;&#30340;&#22238;&#24402;&#20989;&#25968;&#65292;&#24182;&#36798;&#21040;&#20102;&#26497;&#23567;&#21270;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#65288;&#38500;&#20102;&#23545;&#25968;&#22240;&#23376;&#65289;&#12290;</title><link>http://arxiv.org/abs/2204.12392</link><description>&lt;p&gt;
&#31232;&#30095;&#31070;&#32463;&#32593;&#32476;&#30340;PAC-Bayes&#39044;&#27979;&#30028;
&lt;/p&gt;
&lt;p&gt;
A PAC-Bayes oracle inequality for sparse neural networks. (arXiv:2204.12392v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.12392
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#38750;&#21442;&#25968;&#22238;&#24402;&#35774;&#32622;&#20013;&#21033;&#29992;&#31232;&#30095;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;Gibbs&#21518;&#39564;&#20998;&#24067;&#65292;&#36890;&#36807;Metropolis-adjusted Langevin&#31639;&#27861;&#21487;&#20197;&#35775;&#38382;&#21518;&#39564;&#20998;&#24067;&#12290;&#36890;&#36807;&#23545;&#32593;&#32476;&#26435;&#37325;&#30340;&#31232;&#30095;&#38598;&#21512;&#36827;&#34892;&#32479;&#19968;&#20808;&#39564;&#30340;&#28151;&#21512;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#33021;&#22815;&#36866;&#24212;&#26410;&#30693;&#30340;&#27491;&#21017;&#24615;&#21644;&#23618;&#27425;&#32467;&#26500;&#30340;&#22238;&#24402;&#20989;&#25968;&#65292;&#24182;&#36798;&#21040;&#20102;&#26497;&#23567;&#21270;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#65288;&#38500;&#20102;&#23545;&#25968;&#22240;&#23376;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#38750;&#21442;&#25968;&#22238;&#24402;&#35774;&#32622;&#20013;&#31232;&#30095;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;Gibbs&#21518;&#39564;&#20998;&#24067;&#12290;&#36890;&#36807;Metropolis-adjusted Langevin&#31639;&#27861;&#21487;&#20197;&#35775;&#38382;&#21518;&#39564;&#20998;&#24067;&#12290;&#36890;&#36807;&#23545;&#32593;&#32476;&#26435;&#37325;&#30340;&#31232;&#30095;&#38598;&#21512;&#36827;&#34892;&#32479;&#19968;&#20808;&#39564;&#30340;&#28151;&#21512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#39044;&#27979;&#30028;&#65292;&#35813;&#30028;&#34920;&#26126;&#35813;&#26041;&#27861;&#33021;&#22815;&#36866;&#24212;&#26410;&#30693;&#30340;&#27491;&#21017;&#24615;&#21644;&#23618;&#27425;&#32467;&#26500;&#30340;&#22238;&#24402;&#20989;&#25968;&#12290;&#35813;&#20272;&#35745;&#22120;&#36798;&#21040;&#20102;&#26497;&#23567;&#21270;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#65288;&#38500;&#20102;&#23545;&#25968;&#22240;&#23376;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the Gibbs posterior distribution for sparse deep neural nets in a nonparametric regression setting. The posterior can be accessed via Metropolis-adjusted Langevin algorithms. Using a mixture over uniform priors on sparse sets of network weights, we prove an oracle inequality which shows that the method adapts to the unknown regularity and hierarchical structure of the regression function. The estimator achieves the minimax-optimal rate of convergence (up to a logarithmic factor).
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;Kriging&#29702;&#35770;&#30340;&#22810;&#23618;&#27425;&#38543;&#26426;&#20248;&#21270;&#22635;&#34917;&#26041;&#27861;&#65292;&#33021;&#22815;&#26356;&#20934;&#30830;&#12289;&#26356;&#24555;&#36895;&#21644;&#26356;&#31283;&#23450;&#22320;&#22788;&#29702;&#22823;&#35268;&#27169;&#21307;&#30103;&#25968;&#25454;&#35760;&#24405;&#20013;&#30340;&#32570;&#22833;&#25968;&#20540;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2110.09680</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#21307;&#30103;&#25968;&#25454;&#35760;&#24405;&#20013;&#30340;&#22810;&#23618;&#27425;&#38543;&#26426;&#20248;&#21270;&#22635;&#34917;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Multilevel Stochastic Optimization for Imputation in Massive Medical Data Records. (arXiv:2110.09680v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.09680
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;Kriging&#29702;&#35770;&#30340;&#22810;&#23618;&#27425;&#38543;&#26426;&#20248;&#21270;&#22635;&#34917;&#26041;&#27861;&#65292;&#33021;&#22815;&#26356;&#20934;&#30830;&#12289;&#26356;&#24555;&#36895;&#21644;&#26356;&#31283;&#23450;&#22320;&#22788;&#29702;&#22823;&#35268;&#27169;&#21307;&#30103;&#25968;&#25454;&#35760;&#24405;&#20013;&#30340;&#32570;&#22833;&#25968;&#20540;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25506;&#32034;&#21644;&#20998;&#26512;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#26368;&#36817;&#22312;&#30740;&#31350;&#21644;&#21457;&#23637;&#31038;&#21306;&#20013;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#38271;&#26399;&#20197;&#26469;&#65292;&#20154;&#20204;&#19968;&#30452;&#35748;&#35782;&#21040;&#35768;&#22810;&#25968;&#25454;&#38598;&#20013;&#21253;&#21547;&#22823;&#37327;&#32570;&#22833;&#30340;&#25968;&#20540;&#25968;&#25454;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;Kriging&#29702;&#35770;&#30340;&#25968;&#23398;&#21407;&#21017;&#38543;&#26426;&#20248;&#21270;&#22635;&#34917;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#34987;&#35777;&#26126;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#22635;&#34917;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#20854;&#35745;&#31639;&#25104;&#26412;&#21644;&#28508;&#22312;&#30340;&#25968;&#20540;&#19981;&#31283;&#23450;&#24615;&#20250;&#23548;&#33268;&#26114;&#36149;&#21644;/&#25110;&#19981;&#21487;&#38752;&#30340;&#39044;&#27979;&#65292;&#21487;&#33021;&#38480;&#21046;&#20854;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#30340;&#20351;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#26368;&#36817;&#24320;&#21457;&#30340;&#22810;&#23618;&#27425;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#24212;&#29992;&#20110;&#22823;&#35268;&#27169;&#21307;&#30103;&#35760;&#24405;&#20013;&#30340;&#22635;&#34917;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#35745;&#31639;&#24212;&#29992;&#25968;&#23398;&#25216;&#26415;&#65292;&#24182;&#20855;&#26377;&#39640;&#31934;&#24230;&#12290;&#29305;&#21035;&#22320;&#65292;&#23545;&#20110;&#26368;&#20339;&#32447;&#24615;&#26080;&#20559;&#39044;&#27979;&#22120;&#65288;BLUP&#65289;&#65292;&#35813;&#22810;&#23618;&#27425;&#24418;&#24335;&#21270;&#26159;&#31934;&#30830;&#30340;&#65292;&#32780;&#19988;&#35745;&#31639;&#36895;&#24230;&#26356;&#24555;&#65292;&#25968;&#20540;&#31283;&#23450;&#24615;&#26356;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
Exploration and analysis of massive datasets has recently generated increasing interest in the research and development communities. It has long been a recognized problem that many datasets contain significant levels of missing numerical data. We introduce a mathematically principled stochastic optimization imputation method based on the theory of Kriging. This is shown to be a powerful method for imputation. However, its computational effort and potential numerical instabilities produce costly and/or unreliable predictions, potentially limiting its use on large scale datasets. In this paper, we apply a recently developed multi-level stochastic optimization approach to the problem of imputation in massive medical records. The approach is based on computational applied mathematics techniques and is highly accurate. In particular, for the Best Linear Unbiased Predictor (BLUP) this multi-level formulation is exact, and is also significantly faster and more numerically stable. This permits
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#31232;&#30095;&#21152;&#20302;&#31209;&#30697;&#38453;&#20998;&#35299;&#38382;&#39064;(SLR)&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31163;&#25955;&#27169;&#22411;&#21644;&#27714;&#35299;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22810;&#31181;&#24212;&#29992;&#22330;&#26223;&#12290;</title><link>http://arxiv.org/abs/2109.12701</link><description>&lt;p&gt;
&#31232;&#30095;&#21152;&#20302;&#31209;&#30697;&#38453;&#20998;&#35299;: &#19968;&#31181;&#31163;&#25955;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sparse Plus Low Rank Matrix Decomposition: A Discrete Optimization Approach. (arXiv:2109.12701v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.12701
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#31232;&#30095;&#21152;&#20302;&#31209;&#30697;&#38453;&#20998;&#35299;&#38382;&#39064;(SLR)&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31163;&#25955;&#27169;&#22411;&#21644;&#27714;&#35299;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22810;&#31181;&#24212;&#29992;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#31232;&#30095;&#21152;&#20302;&#31209;&#20998;&#35299;&#38382;&#39064;(SLR)&#65292;&#21363;&#23558;&#25439;&#22351;&#30340;&#25968;&#25454;&#30697;&#38453;&#20998;&#35299;&#20026;&#21253;&#21547;&#22522;&#26412;&#30495;&#20540;&#30340;&#20302;&#31209;&#30697;&#38453;&#21644;&#21253;&#21547;&#25200;&#21160;&#30340;&#31232;&#30095;&#30697;&#38453;&#12290; SLR&#26159;&#36816;&#31609;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30340;&#22522;&#30784;&#38382;&#39064;&#65292;&#22312;&#25968;&#25454;&#21387;&#32553;&#12289;&#28508;&#22312;&#35821;&#20041;&#32034;&#24341;&#12289;&#21327;&#21516;&#36807;&#28388;&#21644;&#21307;&#23398;&#25104;&#20687;&#31561;&#21508;&#31181;&#24212;&#29992;&#20013;&#20986;&#29616;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31163;&#25955;&#27169;&#22411;&#65292;&#24182;&#35774;&#35745;&#20102;&#20132;&#26367;&#26368;&#23567;&#21270;&#21551;&#21457;&#24335;&#31639;&#27861;&#20197;&#21450;&#26032;&#30340;&#21322;&#23450;&#26494;&#24347;&#31639;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#20010;&#33258;&#23450;&#20041;&#20998;&#25903;&#23450;&#30028;&#31639;&#27861;&#65292;&#21033;&#29992;&#25105;&#20204;&#30340;&#21551;&#21457;&#24335;&#31639;&#27861;&#21644;&#20984;&#26494;&#24347;&#26469;&#35299;&#20915;&#23567;&#35268;&#27169;&#30340;SLR&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#21551;&#21457;&#24335;&#31639;&#27861;&#21487;&#20197;&#35299;&#20915; $n=10000$ &#30340;&#38382;&#39064;&#35268;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the Sparse Plus Low-Rank decomposition problem (SLR), which is the problem of decomposing a corrupted data matrix into a sparse matrix of perturbations plus a low-rank matrix containing the ground truth. SLR is a fundamental problem in Operations Research and Machine Learning which arises in various applications, including data compression, latent semantic indexing, collaborative filtering, and medical imaging. We introduce a novel formulation for SLR that directly models its underlying discreteness. For this formulation, we develop an alternating minimization heuristic that computes high-quality solutions and a novel semidefinite relaxation that provides meaningful bounds for the solutions returned by our heuristic. We also develop a custom branch-and-bound algorithm that leverages our heuristic and convex relaxations to solve small instances of SLR to certifiable (near) optimality. Given an input $n$-by-$n$ matrix, our heuristic scales to solve instances where $n=10000$ in m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24212;&#29992;LSTM&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#30740;&#31350;&#20102;&#39044;&#27979;&#36890;&#36135;&#33192;&#32960;&#30340;&#33021;&#21147;&#65292;&#24182;&#21457;&#29616;&#22312;&#38271;&#26399;&#39044;&#27979;&#21644;&#23439;&#35266;&#32463;&#27982;&#19981;&#30830;&#23450;&#24615;&#21152;&#21095;&#26399;&#38388;&#34920;&#29616;&#33391;&#22909;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;LSTM&#25152;&#28041;&#21450;&#30340;&#22240;&#32032;&#19982;&#21830;&#19994;&#21608;&#26399;&#25351;&#26631;&#39640;&#24230;&#30456;&#20851;&#65292;&#36825;&#35828;&#26126;&#36825;&#20123;&#20449;&#21495;&#20316;&#20026;&#36890;&#32960;&#39044;&#27979;&#22240;&#23376;&#30340;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2104.03757</link><description>&lt;p&gt;
&#29992;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#36890;&#36135;&#33192;&#32960;
&lt;/p&gt;
&lt;p&gt;
Predicting Inflation with Recurrent Neural Networks. (arXiv:2104.03757v2 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2104.03757
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24212;&#29992;LSTM&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#30740;&#31350;&#20102;&#39044;&#27979;&#36890;&#36135;&#33192;&#32960;&#30340;&#33021;&#21147;&#65292;&#24182;&#21457;&#29616;&#22312;&#38271;&#26399;&#39044;&#27979;&#21644;&#23439;&#35266;&#32463;&#27982;&#19981;&#30830;&#23450;&#24615;&#21152;&#21095;&#26399;&#38388;&#34920;&#29616;&#33391;&#22909;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;LSTM&#25152;&#28041;&#21450;&#30340;&#22240;&#32032;&#19982;&#21830;&#19994;&#21608;&#26399;&#25351;&#26631;&#39640;&#24230;&#30456;&#20851;&#65292;&#36825;&#35828;&#26126;&#36825;&#20123;&#20449;&#21495;&#20316;&#20026;&#36890;&#32960;&#39044;&#27979;&#22240;&#23376;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24212;&#29992;&#20102;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65288;LSTM&#65289;&#26469;&#39044;&#27979;&#36890;&#36135;&#33192;&#32960;&#12290;&#20316;&#20026;&#26102;&#38388;&#24207;&#21015;&#30340;&#19968;&#31181;&#21560;&#24341;&#20154;&#30340;&#27169;&#22411;&#65292;LSTM&#25353;&#29031;&#26102;&#38388;&#27493;&#39588;&#39034;&#24207;&#22788;&#29702;&#25968;&#25454;&#65292;&#24182;&#26126;&#30830;&#23398;&#20064;&#21160;&#24577;&#20381;&#36182;&#20851;&#31995;&#12290;&#26412;&#25991;&#36824;&#25506;&#35752;&#20102;&#35813;&#27169;&#22411;&#30340;&#38477;&#32500;&#33021;&#21147;&#65292;&#20197;&#25581;&#31034;&#21487;&#20197;&#35299;&#37322;&#36890;&#36135;&#33192;&#32960;&#36807;&#31243;&#30340;&#32463;&#27982;&#24847;&#20041;&#22240;&#32032;&#12290;&#23545;&#32654;&#22269;&#25968;&#25454;&#36827;&#34892;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#20272;&#35745;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;&#24120;&#35265;&#22522;&#20934;&#27169;&#22411;&#65288;&#21253;&#25324;&#20854;&#20182;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65289;&#20013;&#34920;&#29616;&#20855;&#26377;&#31454;&#20105;&#21147;&#20294;&#24182;&#19981;&#31361;&#20986;&#12290;&#29305;&#21035;&#26159;LSTM&#22312;&#38271;&#26399;&#39044;&#27979;&#21644;&#23439;&#35266;&#32463;&#27982;&#19981;&#30830;&#23450;&#24615;&#21152;&#21095;&#26399;&#38388;&#34920;&#29616;&#33391;&#22909;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;LSTM&#25152;&#28041;&#21450;&#30340;&#22240;&#32032;&#19982;&#21830;&#19994;&#21608;&#26399;&#25351;&#26631;&#39640;&#24230;&#30456;&#20851;&#65292;&#36825;&#35828;&#26126;&#36825;&#20123;&#20449;&#21495;&#20316;&#20026;&#36890;&#32960;&#39044;&#27979;&#22240;&#23376;&#30340;&#23454;&#29992;&#24615;&#12290;&#26412;&#25991;&#36824;&#25581;&#31034;&#20102;&#32593;&#32476;&#21021;&#22987;&#21270;&#21644;&#26550;&#26500;&#23545;&#39044;&#27979;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper applies a recurrent neural network, the LSTM, to forecast inflation. This is an appealing model for time series as it processes each time step sequentially and explicitly learns dynamic dependencies. The paper also explores the dimension reduction capability of the model to uncover economically-meaningful factors that can explain the inflation process. Results from an exercise with US data indicate that the estimated neural nets present competitive, but not outstanding, performance against common benchmarks (including other machine learning models). The LSTM in particular is found to perform well at long horizons and during periods of heightened macroeconomic uncertainty. Interestingly, LSTM-implied factors present high correlation with business cycle indicators, informing on the usefulness of such signals as inflation predictors. The paper also sheds light on the impact of network initialization and architecture on forecast performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37325;&#23457;&#20102;&#36229;&#21442;&#25968;&#27169;&#22411;&#20013;&#30340;&#26368;&#23567;&#25551;&#36848;&#38271;&#24230;&#22797;&#26434;&#24230;&#12290;&#36890;&#36807;&#23450;&#20041;&#19968;&#20010;&#26032;&#30340;&#22522;&#20110;MDL&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#25105;&#20204;&#21457;&#29616;&#22797;&#26434;&#24230;&#19981;&#20165;&#21462;&#20915;&#20110;&#21442;&#25968;&#25968;&#37327;&#65292;&#36824;&#19982;&#35774;&#35745;&#30697;&#38453;&#25110;&#26680;&#30697;&#38453;&#30340;&#22855;&#24322;&#20540;&#21644;&#20449;&#22122;&#27604;&#26377;&#20851;&#12290;</title><link>http://arxiv.org/abs/2006.10189</link><description>&lt;p&gt;
&#37325;&#23457;&#36229;&#21442;&#25968;&#27169;&#22411;&#20013;&#30340;&#26368;&#23567;&#25551;&#36848;&#38271;&#24230;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
Revisiting minimum description length complexity in overparameterized models. (arXiv:2006.10189v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.10189
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#23457;&#20102;&#36229;&#21442;&#25968;&#27169;&#22411;&#20013;&#30340;&#26368;&#23567;&#25551;&#36848;&#38271;&#24230;&#22797;&#26434;&#24230;&#12290;&#36890;&#36807;&#23450;&#20041;&#19968;&#20010;&#26032;&#30340;&#22522;&#20110;MDL&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#25105;&#20204;&#21457;&#29616;&#22797;&#26434;&#24230;&#19981;&#20165;&#21462;&#20915;&#20110;&#21442;&#25968;&#25968;&#37327;&#65292;&#36824;&#19982;&#35774;&#35745;&#30697;&#38453;&#25110;&#26680;&#30697;&#38453;&#30340;&#22855;&#24322;&#20540;&#21644;&#20449;&#22122;&#27604;&#26377;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22797;&#26434;&#24230;&#26159;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#27010;&#24565;&#65292;&#26088;&#22312;&#25552;&#20379;&#26377;&#20851;&#27867;&#21270;&#24615;&#33021;&#30340;&#20449;&#24687;&#12290;&#22312;&#20302;&#32500;&#24230;&#24773;&#20917;&#19979;&#65292;&#21442;&#25968;&#25968;&#37327;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#26159;&#25104;&#21151;&#30340;&#65292;&#20294;&#22312;&#36229;&#21442;&#25968;&#27169;&#22411;&#20013;&#65292;&#24403;&#21442;&#25968;&#25968;&#37327;&#36229;&#36807;&#35757;&#32451;&#26679;&#26412;&#25968;&#37327;&#26102;&#65292;&#20854;&#21512;&#29702;&#24615;&#19981;&#36275;&#12290;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#22522;&#20110;Rissanen&#26368;&#23567;&#25551;&#36848;&#38271;&#24230;&#65288;MDL&#65289;&#21407;&#29702;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#24182;&#23450;&#20041;&#20102;&#19968;&#31181;&#26032;&#30340;&#36866;&#29992;&#20110;&#36229;&#21442;&#25968;&#27169;&#22411;&#30340;&#22522;&#20110;MDL&#30340;&#22797;&#26434;&#24230;&#65288;MDL-COMP&#65289;&#12290;MDL-COMP&#36890;&#36807;&#23545;&#19968;&#20010;&#33391;&#22909;&#30340;Ridge&#20272;&#35745;&#31867;&#25152;&#24341;&#36215;&#30340;&#32534;&#30721;&#32780;&#23450;&#20041;&#20986;&#26469;&#30340;&#26368;&#20248;&#24615;&#20934;&#21017;&#12290;&#25105;&#20204;&#23545;&#32447;&#24615;&#27169;&#22411;&#21644;&#26680;&#26041;&#27861;&#30340;MDL-COMP&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#29702;&#35770;&#21051;&#30011;&#65292;&#24182;&#34920;&#26126;&#23427;&#19981;&#20165;&#26159;&#21442;&#25968;&#25968;&#37327;&#30340;&#20989;&#25968;&#65292;&#32780;&#26159;&#35774;&#35745;&#25110;&#26680;&#30697;&#38453;&#30340;&#22855;&#24322;&#20540;&#21644;&#20449;&#22122;&#27604;&#30340;&#20989;&#25968;&#12290;&#23545;&#20110;&#20855;&#26377;n&#20010;&#35266;&#27979;&#20540;&#65292;d&#20010;&#21442;&#25968;&#21644;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#39640;&#26031;&#39044;&#27979;&#22240;&#23376;&#30340;&#32447;&#24615;&#27169;&#22411;&#65292;MDL-COMP&#30340;&#23610;&#24230;&#26159;&#32447;&#24615;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Complexity is a fundamental concept underlying statistical learning theory that aims to inform generalization performance. Parameter count, while successful in low-dimensional settings, is not well-justified for overparameterized settings when the number of parameters is more than the number of training samples. We revisit complexity measures based on Rissanen's principle of minimum description length (MDL) and define a novel MDL-based complexity (MDL-COMP) that remains valid for overparameterized models. MDL-COMP is defined via an optimality criterion over the encodings induced by a good Ridge estimator class. We provide an extensive theoretical characterization of MDL-COMP for linear models and kernel methods and show that it is not just a function of parameter count, but rather a function of the singular values of the design or the kernel matrix and the signal-to-noise ratio. For a linear model with $n$ observations, $d$ parameters, and i.i.d. Gaussian predictors, MDL-COMP scales li
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;Transformer&#35757;&#32451;&#30340;&#22256;&#38590;&#12290;&#20182;&#20204;&#21457;&#29616;&#19981;&#24179;&#34913;&#30340;&#26799;&#24230;&#19981;&#26159;&#35757;&#32451;&#19981;&#31283;&#23450;&#30340;&#26681;&#26412;&#21407;&#22240;&#65292;&#32780;&#26159;&#27599;&#19968;&#23618;&#30340;&#25918;&#22823;&#25928;&#24212;&#23548;&#33268;&#35757;&#32451;&#19981;&#31283;&#23450;&#12290;&#20182;&#20204;&#35266;&#23519;&#21040;&#36731;&#37327;&#32423;&#30340;&#20381;&#36182;&#38480;&#21046;&#20102;&#27169;&#22411;&#28508;&#21147;&#65292;&#23548;&#33268;&#34920;&#29616;&#36739;&#24046;&#30340;&#35757;&#32451;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2004.08249</link><description>&lt;p&gt;
&#29702;&#35299;Transformer&#35757;&#32451;&#30340;&#22256;&#38590;
&lt;/p&gt;
&lt;p&gt;
Understanding the Difficulty of Training Transformers. (arXiv:2004.08249v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2004.08249
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;Transformer&#35757;&#32451;&#30340;&#22256;&#38590;&#12290;&#20182;&#20204;&#21457;&#29616;&#19981;&#24179;&#34913;&#30340;&#26799;&#24230;&#19981;&#26159;&#35757;&#32451;&#19981;&#31283;&#23450;&#30340;&#26681;&#26412;&#21407;&#22240;&#65292;&#32780;&#26159;&#27599;&#19968;&#23618;&#30340;&#25918;&#22823;&#25928;&#24212;&#23548;&#33268;&#35757;&#32451;&#19981;&#31283;&#23450;&#12290;&#20182;&#20204;&#35266;&#23519;&#21040;&#36731;&#37327;&#32423;&#30340;&#20381;&#36182;&#38480;&#21046;&#20102;&#27169;&#22411;&#28508;&#21147;&#65292;&#23548;&#33268;&#34920;&#29616;&#36739;&#24046;&#30340;&#35757;&#32451;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#22312;&#35768;&#22810;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#34987;&#35777;&#26126;&#26159;&#26377;&#25928;&#30340;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#35757;&#32451;&#38656;&#35201;&#35774;&#35745;&#20808;&#36827;&#30340;&#20248;&#21270;&#22120;&#21644;&#23398;&#20064;&#29575;&#35843;&#24230;&#22120;&#30340;&#38750;&#24179;&#20961;&#24037;&#20316;&#65288;&#20363;&#22914;&#65292;&#20256;&#32479;&#30340;SGD&#26080;&#27861;&#26377;&#25928;&#35757;&#32451;Transformer&#65289;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20174;&#32463;&#39564;&#21644;&#29702;&#35770;&#30340;&#35282;&#24230;&#29702;&#35299;$\textit{&#20160;&#20040;&#20351;&#24471;Transformer&#30340;&#35757;&#32451;&#21464;&#24471;&#22256;&#38590;}$&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#19981;&#24179;&#34913;&#30340;&#26799;&#24230;&#24182;&#19981;&#26159;&#35757;&#32451;&#19981;&#31283;&#23450;&#30340;&#26681;&#26412;&#21407;&#22240;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#19968;&#31181;&#24433;&#21709;&#35757;&#32451;&#30340;&#25918;&#22823;&#25928;&#24212;--&#23545;&#20110;&#22810;&#23618;Transformer&#27169;&#22411;&#20013;&#30340;&#27599;&#19968;&#23618;&#65292;&#23427;&#23545;&#20854;&#27531;&#24046;&#20998;&#25903;&#30340;&#20381;&#36182;&#31243;&#24230;&#36739;&#39640;&#65292;&#23548;&#33268;&#35757;&#32451;&#19981;&#31283;&#23450;&#65292;&#22240;&#20026;&#23427;&#25918;&#22823;&#20102;&#23567;&#30340;&#21442;&#25968;&#25200;&#21160;&#65288;&#20363;&#22914;&#21442;&#25968;&#26356;&#26032;&#65289;&#65292;&#24182;&#23548;&#33268;&#27169;&#22411;&#36755;&#20986;&#20013;&#30340;&#26174;&#33879;&#25200;&#21160;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#36731;&#37327;&#32423;&#30340;&#20381;&#36182;&#38480;&#21046;&#20102;&#27169;&#22411;&#30340;&#28508;&#21147;&#65292;&#24182;&#23548;&#33268;&#34920;&#29616;&#36739;&#24046;&#30340;&#35757;&#32451;&#27169;&#22411;&#12290;&#22312;&#25105;&#20204;&#30340;&#20998;&#26512;&#21551;&#21457;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Admin&#65288;$\textbf{Ad}$aptive &#37325;&#36848;&#37096;&#20998;
&lt;/p&gt;
&lt;p&gt;
Transformers have proved effective in many NLP tasks. However, their training requires non-trivial efforts regarding designing cutting-edge optimizers and learning rate schedulers carefully (e.g., conventional SGD fails to train Transformers effectively). Our objective here is to understand $\textit{what complicates Transformer training}$ from both empirical and theoretical perspectives. Our analysis reveals that unbalanced gradients are not the root cause of the instability of training. Instead, we identify an amplification effect that influences training substantially -- for each layer in a multi-layer Transformer model, heavy dependency on its residual branch makes training unstable, since it amplifies small parameter perturbations (e.g., parameter updates) and results in significant disturbances in the model output. Yet we observe that a light dependency limits the model potential and leads to inferior trained models. Inspired by our analysis, we propose Admin ($\textbf{Ad}$aptive 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#24067;&#24335;&#22810;&#20803;&#22238;&#24402;&#24314;&#27169;&#30340;&#36873;&#25321;&#29983;&#29289;&#26631;&#24535;&#29289;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#25968;&#25454;&#20445;&#25252;&#32422;&#26463;&#30340;&#38382;&#39064;&#65292;&#24182;&#20811;&#26381;&#20102;&#20256;&#32479;&#26041;&#27861;&#22312;&#22788;&#29702;&#22823;&#37327;&#29983;&#29289;&#26631;&#24535;&#29289;&#26102;&#20002;&#22833;&#20449;&#24687;&#30340;&#23616;&#38480;&#24615;&#12290;</title><link>http://arxiv.org/abs/1803.00422</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#24067;&#24335;&#22810;&#20803;&#22238;&#24402;&#24314;&#27169;&#30340;&#36873;&#25321;&#21463;&#25968;&#25454;&#20445;&#25252;&#32422;&#26463;&#30340;&#29983;&#29289;&#26631;&#24535;&#29289;
&lt;/p&gt;
&lt;p&gt;
Distributed Multivariate Regression Modeling For Selecting Biomarkers Under Data Protection Constraints. (arXiv:1803.00422v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1803.00422
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#24067;&#24335;&#22810;&#20803;&#22238;&#24402;&#24314;&#27169;&#30340;&#36873;&#25321;&#29983;&#29289;&#26631;&#24535;&#29289;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#25968;&#25454;&#20445;&#25252;&#32422;&#26463;&#30340;&#38382;&#39064;&#65292;&#24182;&#20811;&#26381;&#20102;&#20256;&#32479;&#26041;&#27861;&#22312;&#22788;&#29702;&#22823;&#37327;&#29983;&#29289;&#26631;&#24535;&#29289;&#26102;&#20002;&#22833;&#20449;&#24687;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20020;&#24202;&#29983;&#29289;&#26631;&#24535;&#29289;&#30340;&#21457;&#29616;&#38656;&#35201;&#22823;&#37327;&#30340;&#24739;&#32773;&#38431;&#21015;&#65292;&#24182;&#19988;&#36890;&#36807;&#36328;&#26426;&#26500;&#38388;&#30340;&#27719;&#24635;&#25968;&#25454;&#26041;&#27861;&#36827;&#34892;&#36741;&#21161;&#12290;&#22312;&#35768;&#22810;&#22269;&#23478;&#65292;&#29305;&#21035;&#26159;&#22312;&#20020;&#24202;&#29615;&#22659;&#20013;&#65292;&#25968;&#25454;&#20445;&#25252;&#32422;&#26463;&#31105;&#27490;&#19981;&#21516;&#30740;&#31350;&#26426;&#26500;&#20043;&#38388;&#20132;&#25442;&#20010;&#20307;&#32423;&#25968;&#25454;&#65292;&#20174;&#32780;&#38459;&#30861;&#20102;&#32852;&#21512;&#20998;&#26512;&#30340;&#36827;&#34892;&#12290;&#20026;&#20102;&#35268;&#36991;&#36825;&#20010;&#38382;&#39064;&#65292;&#21482;&#33021;&#20132;&#25442;&#38750;&#25259;&#38706;&#24335;&#30340;&#27719;&#24635;&#25968;&#25454;&#65292;&#36825;&#36890;&#24120;&#26159;&#36890;&#36807;&#25163;&#21160;&#36827;&#34892;&#65292;&#24182;&#19988;&#22312;&#36716;&#31227;&#20043;&#21069;&#38656;&#35201;&#26126;&#30830;&#30340;&#35768;&#21487;&#65292;&#20063;&#23601;&#26159;&#25968;&#25454;&#35843;&#29992;&#30340;&#25968;&#37327;&#21644;&#25968;&#25454;&#37327;&#24212;&#35813;&#21463;&#21040;&#38480;&#21046;&#12290;&#36825;&#19981;&#20801;&#35768;&#36827;&#34892;&#26356;&#22797;&#26434;&#30340;&#20219;&#21153;&#65292;&#20363;&#22914;&#21464;&#37327;&#36873;&#25321;&#65292;&#22240;&#20026;&#36890;&#24120;&#21482;&#20256;&#36755;&#31616;&#21333;&#30340;&#27719;&#24635;&#32479;&#35745;&#25968;&#25454;&#12290;&#20854;&#20182;&#26041;&#27861;&#25552;&#20986;&#20102;&#38656;&#35201;&#26356;&#22797;&#26434;&#30340;&#27719;&#24635;&#25968;&#25454;&#25110;&#20351;&#29992;&#36755;&#20837;&#25968;&#25454;&#25200;&#21160;&#30340;&#26041;&#27861;&#65292;&#20294;&#26159;&#36825;&#20123;&#26041;&#27861;&#35201;&#20040;&#19981;&#33021;&#22788;&#29702;&#22823;&#37327;&#30340;&#29983;&#29289;&#26631;&#24535;&#29289;&#65292;&#35201;&#20040;&#20250;&#20002;&#22833;&#20449;&#24687;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#21464;&#37327;&#22238;&#24402;&#26041;&#27861;&#26469;&#35782;&#21035;&#29983;&#29289;&#26631;&#24535;&#29289;&#12290;
&lt;/p&gt;
&lt;p&gt;
The discovery of clinical biomarkers requires large patient cohorts and is aided by a pooled data approach across institutions. In many countries, data protection constraints, especially in the clinical environment, forbid the exchange of individual-level data between different research institutes, impeding the conduct of a joint analyses. To circumvent this problem, only non-disclosive aggregated data is exchanged, which is often done manually and requires explicit permission before transfer, i.e., the number of data calls and the amount of data should be limited. This does not allow for more complex tasks such as variable selection, as only simple aggregated summary statistics are typically transferred. Other methods have been proposed that require more complex aggregated data or use input data perturbation, but these methods can either not deal with a high number of biomarkers or lose information. Here, we propose a multivariable regression approach for identifying biomarkers by aut
&lt;/p&gt;</description></item></channel></rss>