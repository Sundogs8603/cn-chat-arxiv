<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#30340;&#20027;&#35201;&#21457;&#29616;&#26159;&#23545;&#20110;&#23398;&#20064;&#25130;&#26029;&#39640;&#26031;&#20998;&#24067;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23384;&#22312;&#19968;&#20010;&#32479;&#35745;&#26597;&#35810;&#19979;&#30028;&#65292;&#34920;&#26126;&#22312;&#36825;&#20010;&#20219;&#21153;&#20013;&#23384;&#22312;&#30528;&#36229;&#22810;&#39033;&#24335;&#20449;&#24687;-&#35745;&#31639;&#24046;&#36317;&#12290;</title><link>https://arxiv.org/abs/2403.02300</link><description>&lt;p&gt;
&#23545;&#23398;&#20064;&#25130;&#26029;&#39640;&#26031;&#20998;&#24067;&#20272;&#35745;&#30340;&#32479;&#35745;&#26597;&#35810;&#19979;&#30028;
&lt;/p&gt;
&lt;p&gt;
Statistical Query Lower Bounds for Learning Truncated Gaussians
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02300
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30340;&#20027;&#35201;&#21457;&#29616;&#26159;&#23545;&#20110;&#23398;&#20064;&#25130;&#26029;&#39640;&#26031;&#20998;&#24067;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23384;&#22312;&#19968;&#20010;&#32479;&#35745;&#26597;&#35810;&#19979;&#30028;&#65292;&#34920;&#26126;&#22312;&#36825;&#20010;&#20219;&#21153;&#20013;&#23384;&#22312;&#30528;&#36229;&#22810;&#39033;&#24335;&#20449;&#24687;-&#35745;&#31639;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#25130;&#26029;&#35774;&#32622;&#20013;&#20272;&#35745;&#22343;&#20540;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#25130;&#26029;&#38598;&#26469;&#33258;&#19968;&#20010;&#20302;&#22797;&#26434;&#24230;&#38598;&#21512;$\mathcal{C}$&#12290;&#20855;&#20307;&#22320;&#65292;&#23545;&#20110;&#19968;&#20010;&#22266;&#23450;&#20294;&#26410;&#30693;&#30340;&#25130;&#26029;&#38598;$S \subseteq \mathbb{R}^d$&#65292;&#25105;&#20204;&#21487;&#20197;&#35775;&#38382;&#20174;&#20998;&#24067;$\mathcal{N}(\boldsymbol{ \mu}, \mathbf{ I})$&#25130;&#26029;&#21040;&#38598;&#21512;$S$&#30340;&#26679;&#26412;&#12290;&#30446;&#26631;&#26159;&#22312;$\ell_2$-&#33539;&#25968;&#20869;&#20197;&#31934;&#24230;$\epsilon&gt;0$&#20272;&#35745;$\boldsymbol\mu$&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#19968;&#20010;&#32479;&#35745;&#26597;&#35810;&#65288;SQ&#65289;&#19979;&#30028;&#65292;&#34920;&#26126;&#20102;&#22312;&#36825;&#20010;&#20219;&#21153;&#20013;&#23384;&#22312;&#30528;&#36229;&#22810;&#39033;&#24335;&#20449;&#24687;-&#35745;&#31639;&#24046;&#36317;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23545;&#20110;&#36825;&#20010;&#38382;&#39064;&#30340;&#20219;&#20309;SQ&#31639;&#27861;&#30340;&#22797;&#26434;&#24230;&#22343;&#20026;$d^{\mathrm{poly}(1/\epsilon)}$&#65292;&#21363;&#20351;&#31867;$\mathcal{C}$&#26159;&#31616;&#21333;&#30340;&#65292;&#25152;&#20197;&#20449;&#24687;&#35770;&#19978;$\mathrm{poly}(d/\epsilon)$&#20010;&#26679;&#26412;&#36275;&#22815;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#30340;SQ&#19979;&#30028;&#36866;&#29992;&#20110;&#24403;$\mathcal{C}$&#26159;&#26377;&#30028;&#20010;&#25968;&#30340;&#24182;&#38598;&#26102;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02300v1 Announce Type: cross  Abstract: We study the problem of estimating the mean of an identity covariance Gaussian in the truncated setting, in the regime when the truncation set comes from a low-complexity family $\mathcal{C}$ of sets. Specifically, for a fixed but unknown truncation set $S \subseteq \mathbb{R}^d$, we are given access to samples from the distribution $\mathcal{N}(\boldsymbol{ \mu}, \mathbf{ I})$ truncated to the set $S$. The goal is to estimate $\boldsymbol\mu$ within accuracy $\epsilon&gt;0$ in $\ell_2$-norm. Our main result is a Statistical Query (SQ) lower bound suggesting a super-polynomial information-computation gap for this task. In more detail, we show that the complexity of any SQ algorithm for this problem is $d^{\mathrm{poly}(1/\epsilon)}$, even when the class $\mathcal{C}$ is simple so that $\mathrm{poly}(d/\epsilon)$ samples information-theoretically suffice. Concretely, our SQ lower bound applies when $\mathcal{C}$ is a union of a bounded num
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#35299;&#20915;&#21463;&#38480;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#8220;&#39044;&#27979;&#21018;&#24615;&#8221;&#20316;&#20026;&#19968;&#31181;&#33719;&#24471;&#20219;&#24847;&#39044;&#20808;&#35757;&#32451;&#22238;&#24402;&#22120;&#19981;&#30830;&#23450;&#24615;&#30340;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#26041;&#27861;&#24212;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#22312;&#22810;&#31181;&#22238;&#24402;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.02251</link><description>&lt;p&gt;
&#19968;&#20010;&#29992;&#20110;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#20013;&#20302;&#25104;&#26412;&#19981;&#30830;&#23450;&#24615;&#30340;&#39044;&#27979;&#21018;&#24615;&#24418;&#24335;&#20027;&#20041;
&lt;/p&gt;
&lt;p&gt;
A prediction rigidity formalism for low-cost uncertainties in trained neural networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02251
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#35299;&#20915;&#21463;&#38480;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#8220;&#39044;&#27979;&#21018;&#24615;&#8221;&#20316;&#20026;&#19968;&#31181;&#33719;&#24471;&#20219;&#24847;&#39044;&#20808;&#35757;&#32451;&#22238;&#24402;&#22120;&#19981;&#30830;&#23450;&#24615;&#30340;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#26041;&#27861;&#24212;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#22312;&#22810;&#31181;&#22238;&#24402;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22238;&#24402;&#26041;&#27861;&#23545;&#31185;&#23398;&#21644;&#25216;&#26415;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#25311;&#21512;&#27169;&#22411;&#22312;&#20854;&#35757;&#32451;&#39046;&#22495;&#20043;&#22806;&#21487;&#33021;&#26497;&#19981;&#21487;&#38752;&#65292;&#22240;&#27492;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#37327;&#21270;&#20854;&#19981;&#30830;&#23450;&#24615;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#22522;&#20110;&#21463;&#38480;&#20248;&#21270;&#38382;&#39064;&#30340;&#35299;&#65292;&#25105;&#20204;&#25552;&#20986;&#8220;&#39044;&#27979;&#21018;&#24615;&#8221;&#20316;&#20026;&#19968;&#31181;&#33719;&#24471;&#20219;&#24847;&#39044;&#20808;&#35757;&#32451;&#22238;&#24402;&#22120;&#19981;&#30830;&#23450;&#24615;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#19982;&#36125;&#21494;&#26031;&#25512;&#26029;&#20043;&#38388;&#30340;&#24378;&#36830;&#25509;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#20801;&#35768;&#26032;&#26041;&#27861;&#24212;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#21518;&#19968;&#23618;&#36924;&#36817;&#12290;&#36825;&#31181;&#25193;&#23637;&#25552;&#20379;&#20102;&#19981;&#38656;&#35201;&#23545;&#31070;&#32463;&#32593;&#32476;&#26412;&#36523;&#25110;&#20854;&#35757;&#32451;&#36807;&#31243;&#36827;&#34892;&#20219;&#20309;&#20462;&#25913;&#30340;&#20302;&#25104;&#26412;&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20174;&#31616;&#21333;&#29609;&#20855;&#27169;&#22411;&#21040;&#21270;&#23398;&#21644;&#27668;&#35937;&#23398;&#24212;&#29992;&#30340;&#24191;&#27867;&#22238;&#24402;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02251v1 Announce Type: cross  Abstract: Regression methods are fundamental for scientific and technological applications. However, fitted models can be highly unreliable outside of their training domain, and hence the quantification of their uncertainty is crucial in many of their applications. Based on the solution of a constrained optimization problem, we propose "prediction rigidities" as a method to obtain uncertainties of arbitrary pre-trained regressors. We establish a strong connection between our framework and Bayesian inference, and we develop a last-layer approximation that allows the new method to be applied to neural networks. This extension affords cheap uncertainties without any modification to the neural network itself or its training procedure. We show the effectiveness of our method on a wide range of regression tasks, ranging from simple toy models to applications in chemistry and meteorology.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#20351;&#29992;MIM&#33258;&#30417;&#30563;&#39044;&#35757;&#32451;&#23398;&#20064;transformers&#30340;&#39318;&#20010;&#31471;&#21040;&#31471;&#29702;&#35770;&#65292;&#25581;&#31034;&#20102;transformers&#22914;&#20309;&#23398;&#20064;&#21040;&#22312;&#20855;&#26377;&#31354;&#38388;&#32467;&#26500;&#30340;&#25968;&#25454;&#20998;&#24067;&#19978;&#31361;&#26174;&#29305;&#24449;-&#20301;&#32622;&#30456;&#20851;&#24615;&#30340;&#26412;&#22320;&#21644;&#22810;&#26679;&#21270;&#27880;&#24847;&#27169;&#24335;</title><link>https://arxiv.org/abs/2403.02233</link><description>&lt;p&gt;
Transformers&#22312;Masked Image Modeling&#20013;&#33021;&#22815;&#35777;&#26126;&#23398;&#20064;&#29305;&#24449;-&#20301;&#32622;&#30456;&#20851;&#24615;
&lt;/p&gt;
&lt;p&gt;
Transformers Provably Learn Feature-Position Correlations in Masked Image Modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02233
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#20351;&#29992;MIM&#33258;&#30417;&#30563;&#39044;&#35757;&#32451;&#23398;&#20064;transformers&#30340;&#39318;&#20010;&#31471;&#21040;&#31471;&#29702;&#35770;&#65292;&#25581;&#31034;&#20102;transformers&#22914;&#20309;&#23398;&#20064;&#21040;&#22312;&#20855;&#26377;&#31354;&#38388;&#32467;&#26500;&#30340;&#25968;&#25454;&#20998;&#24067;&#19978;&#31361;&#26174;&#29305;&#24449;-&#20301;&#32622;&#30456;&#20851;&#24615;&#30340;&#26412;&#22320;&#21644;&#22810;&#26679;&#21270;&#27880;&#24847;&#27169;&#24335;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Masked image modeling (MIM)&#26159;&#19968;&#31181;&#26032;&#20852;&#30340;&#33258;&#30417;&#30563;&#35270;&#35273;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#23427;&#20174;&#26410;&#23631;&#34109;&#30340;&#22270;&#20687;&#20013;&#39044;&#27979;&#38543;&#26426;&#23631;&#34109;&#30340;&#34917;&#19969;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#22522;&#20110;transformers&#30340;MIM&#30340;&#29702;&#35770;&#29702;&#35299;&#30456;&#24403;&#26377;&#38480;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#26377;&#20851;&#20351;&#29992;MIM&#33258;&#30417;&#30563;&#39044;&#35757;&#32451;&#23398;&#20064;&#19968;&#23618;transformers&#30340;&#39318;&#20010;&#31471;&#21040;&#31471;&#29702;&#35770;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;transformers&#22914;&#20309;&#23398;&#20064;&#21040;&#22312;&#20855;&#26377;&#31354;&#38388;&#32467;&#26500;&#30340;&#25968;&#25454;&#20998;&#24067;&#19978;&#31361;&#26174;&#29305;&#24449;-&#20301;&#32622;&#30456;&#20851;&#24615;&#30340;&#26412;&#22320;&#21644;&#22810;&#26679;&#21270;&#27880;&#24847;&#27169;&#24335;&#30340;&#29702;&#35770;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02233v1 Announce Type: new  Abstract: Masked image modeling (MIM), which predicts randomly masked patches from unmasked ones, has emerged as a promising approach in self-supervised vision pretraining. However, the theoretical understanding of MIM is rather limited, especially with the foundational architecture of transformers. In this paper, to the best of our knowledge, we provide the first end-to-end theory of learning one-layer transformers with softmax attention in MIM self-supervised pretraining. On the conceptual side, we posit a theoretical mechanism of how transformers, pretrained with MIM, produce empirically observed local and diverse attention patterns on data distributions with spatial structures that highlight feature-position correlations. On the technical side, our end-to-end analysis of the training dynamics of softmax-based transformers accommodates both input and position embeddings simultaneously, which is developed based on a novel approach to track the i
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#27491;&#21017;&#21270;&#27969;&#30340;&#20272;&#35745;&#22120;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#23454;&#29616;&#23545;&#21407;&#22987;&#25968;&#25454;&#36827;&#34892;&#20114;&#20449;&#24687;&#20272;&#35745;&#65292;&#24182;&#19988;&#22312;&#39640;&#32500;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20986;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2403.02187</link><description>&lt;p&gt;
&#36890;&#36807;&#27491;&#21017;&#21270;&#27969;&#36827;&#34892;&#20114;&#20449;&#24687;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Mutual Information Estimation via Normalizing Flows
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02187
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#27491;&#21017;&#21270;&#27969;&#30340;&#20272;&#35745;&#22120;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#23454;&#29616;&#23545;&#21407;&#22987;&#25968;&#25454;&#36827;&#34892;&#20114;&#20449;&#24687;&#20272;&#35745;&#65292;&#24182;&#19988;&#22312;&#39640;&#32500;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20986;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#20114;&#20449;&#24687;&#65288;MI&#65289;&#20272;&#35745;&#38382;&#39064;&#65292;&#21363;&#24341;&#20837;&#22522;&#20110;&#27491;&#21017;&#21270;&#27969;&#30340;&#20272;&#35745;&#22120;&#12290;&#35813;&#20272;&#35745;&#22120;&#23558;&#21407;&#22987;&#25968;&#25454;&#26144;&#23556;&#21040;&#20855;&#26377;&#24050;&#30693;&#20114;&#20449;&#24687;&#38381;&#21512;&#24418;&#24335;&#34920;&#36798;&#24335;&#30340;&#30446;&#26631;&#20998;&#24067;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20135;&#29983;&#20102;&#21407;&#22987;&#25968;&#25454;&#30340;&#20114;&#20449;&#24687;&#20272;&#35745;&#12290;&#36890;&#36807;&#39640;&#32500;&#25968;&#25454;&#30340;&#23454;&#39564;&#32467;&#26524;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#20272;&#35745;&#22120;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02187v1 Announce Type: new  Abstract: We propose a novel approach to the problem of mutual information (MI) estimation via introducing normalizing flows-based estimator. The estimator maps original data to the target distribution with known closed-form expression for MI. We demonstrate that our approach yields MI estimates for the original data. Experiments with high-dimensional data are provided to show the advantages of the proposed estimator.
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;Recency-Weighted Temporally-Segmented&#65288;ReWTS&#65289;&#38598;&#25104;&#27169;&#22411;&#65292;&#21033;&#29992;&#22359;&#29366;&#26041;&#27861;&#36827;&#34892;&#22810;&#27493;&#39044;&#27979;&#65292;&#21487;&#20197;&#19987;&#38376;&#21270;&#27169;&#22411;&#24182;&#20248;&#21270;&#39044;&#27979;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.02150</link><description>&lt;p&gt;
&#25913;&#36827;&#30340;&#26102;&#38388;&#20998;&#27573;&#38598;&#25104;&#26041;&#27861;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Recency-Weighted Temporally-Segmented Ensemble for Time-Series Modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02150
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;Recency-Weighted Temporally-Segmented&#65288;ReWTS&#65289;&#38598;&#25104;&#27169;&#22411;&#65292;&#21033;&#29992;&#22359;&#29366;&#26041;&#27861;&#36827;&#34892;&#22810;&#27493;&#39044;&#27979;&#65292;&#21487;&#20197;&#19987;&#38376;&#21270;&#27169;&#22411;&#24182;&#20248;&#21270;&#39044;&#27979;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24037;&#33402;&#34892;&#19994;&#20013;&#65292;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#38754;&#23545;&#22788;&#29702;&#22797;&#26434;&#12289;&#22810;&#26041;&#38754;&#21644;&#19981;&#26029;&#28436;&#21464;&#30340;&#25968;&#25454;&#29305;&#24449;&#30340;&#25361;&#25112;&#12290;&#20256;&#32479;&#30340;&#21333;&#19968;&#27169;&#22411;&#26041;&#27861;&#24448;&#24448;&#38590;&#20197;&#25429;&#25417;&#22810;&#26679;&#21160;&#24577;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#23548;&#33268;&#39044;&#27979;&#19981;&#22815;&#20248;&#21270;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;Recency-Weighted Temporally-Segmented&#65288;ReWTS&#65292;&#21457;&#38899;&#20026;`roots'&#65289;&#38598;&#25104;&#27169;&#22411;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#22359;&#30340;&#22810;&#27493;&#39044;&#27979;&#26041;&#27861;&#12290;ReWTS&#27169;&#22411;&#30340;&#20851;&#38190;&#29305;&#24449;&#26377;&#20004;&#20010;&#65306;1&#65289;&#36890;&#36807;&#23558;&#35757;&#32451;&#25968;&#25454;&#21010;&#20998;&#20026;&#25968;&#25454;&#22359;&#24182;&#23545;&#27599;&#20010;&#22359;&#35757;&#32451;&#19968;&#20010;&#27169;&#22411;&#65292;&#26377;&#21161;&#20110;&#23558;&#27169;&#22411;&#19987;&#38376;&#21270;&#20026;&#19981;&#21516;&#30340;&#21160;&#24577;&#12290;2&#65289;&#22312;&#25512;&#26029;&#38454;&#27573;&#65292;&#19968;&#20010;&#20248;&#21270;&#36807;&#31243;&#35780;&#20272;&#26368;&#36817;&#30340;&#36807;&#21435;&#20013;&#30340;&#27599;&#20010;&#27169;&#22411;&#65292;&#24182;&#36873;&#25321;&#27963;&#21160;&#27169;&#22411;&#65292;&#20197;&#20415;&#33021;&#22815;&#21484;&#22238;&#20197;&#21069;&#23398;&#20064;&#30340;&#21160;&#24577;&#30340;&#36866;&#24403;&#28151;&#21512;&#26469;&#39044;&#27979;&#26410;&#26469;&#12290;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#25429;&#25417;&#20102;&#27599;&#20010;&#26102;&#26399;&#30340;&#32454;&#24494;&#24046;&#24322;&#65292;&#32780;&#19988;&#33021;&#22815;&#33258;&#36866;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02150v1 Announce Type: cross  Abstract: Time-series modeling in process industries faces the challenge of dealing with complex, multi-faceted, and evolving data characteristics. Conventional single model approaches often struggle to capture the interplay of diverse dynamics, resulting in suboptimal forecasts. Addressing this, we introduce the Recency-Weighted Temporally-Segmented (ReWTS, pronounced `roots') ensemble model, a novel chunk-based approach for multi-step forecasting. The key characteristics of the ReWTS model are twofold: 1) It facilitates specialization of models into different dynamics by segmenting the training data into `chunks' of data and training one model per chunk. 2) During inference, an optimization procedure assesses each model on the recent past and selects the active models, such that the appropriate mixture of previously learned dynamics can be recalled to forecast the future. This method not only captures the nuances of each period, but also adapt
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#30456;&#21516;&#25216;&#26415;&#33719;&#24471;&#20102;&#32039;&#25903;&#25745;&#23545;&#31216;&#27010;&#29575;&#27979;&#24230;&#19982;&#20854;&#23545;&#31216;&#32463;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#26399;&#26395;&#26368;&#22823;&#20999;&#29255;2-&#29926;&#22622;&#26031;&#22374;&#36317;&#31163;&#30340;&#19978;&#30028;</title><link>https://arxiv.org/abs/2403.02142</link><description>&lt;p&gt;
&#26368;&#22823;&#20999;&#29255;2-&#29926;&#22622;&#26031;&#22374;&#36317;&#31163;
&lt;/p&gt;
&lt;p&gt;
Max-sliced 2-Wasserstein distance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02142
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#30456;&#21516;&#25216;&#26415;&#33719;&#24471;&#20102;&#32039;&#25903;&#25745;&#23545;&#31216;&#27010;&#29575;&#27979;&#24230;&#19982;&#20854;&#23545;&#31216;&#32463;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#26399;&#26395;&#26368;&#22823;&#20999;&#29255;2-&#29926;&#22622;&#26031;&#22374;&#36317;&#31163;&#30340;&#19978;&#30028;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#31508;&#35760;&#26159;&#20316;&#32773;&#22312;&#8220;&#26368;&#22823;&#20999;&#29255;&#29926;&#22622;&#26031;&#22374;&#36317;&#31163;&#30340;&#23574;&#38160;&#30028;&#38480;&#8221;&#26041;&#38754;&#20043;&#21069;&#24037;&#20316;&#30340;&#24310;&#32493;&#12290;&#25105;&#20204;&#20351;&#29992;&#30456;&#21516;&#30340;&#25216;&#26415;&#33719;&#24471;&#32039;&#25903;&#25745;&#23545;&#31216;&#27010;&#29575;&#27979;&#24230;&#19982;&#20854;&#23545;&#31216;&#32463;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#26399;&#26395;&#26368;&#22823;&#20999;&#29255;2-&#29926;&#22622;&#26031;&#22374;&#36317;&#31163;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02142v1 Announce Type: cross  Abstract: This note is a continuation of the author's previous work on ``Sharp bounds for the max-sliced Wasserstein distance." We use the same technique to obtain an upper bound for the expected max-sliced 2-Wasserstein distance between a compactly supported symmetric probability measure on a Euclidean space and its symmetrized empirical distribution.
&lt;/p&gt;</description></item><item><title>&#22312;&#37325;&#23614;&#25200;&#21160;&#19979;&#65292;&#22122;&#22768;SGD&#23454;&#29616;&#20102;&#24046;&#20998;&#38544;&#31169;&#20445;&#35777;&#65292;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#25439;&#22833;&#20989;&#25968;&#31867;&#65292;&#29305;&#21035;&#26159;&#38750;&#20984;&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2403.02051</link><description>&lt;p&gt;
&#22312;&#37325;&#23614;&#25200;&#21160;&#19979;&#22122;&#22768;(S)GD&#30340;&#24046;&#20998;&#38544;&#31169;
&lt;/p&gt;
&lt;p&gt;
Differential Privacy of Noisy (S)GD under Heavy-Tailed Perturbations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02051
&lt;/p&gt;
&lt;p&gt;
&#22312;&#37325;&#23614;&#25200;&#21160;&#19979;&#65292;&#22122;&#22768;SGD&#23454;&#29616;&#20102;&#24046;&#20998;&#38544;&#31169;&#20445;&#35777;&#65292;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#25439;&#22833;&#20989;&#25968;&#31867;&#65292;&#29305;&#21035;&#26159;&#38750;&#20984;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#37325;&#23614;&#22122;&#22768;&#27880;&#20837;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;(SGD)&#30340;&#36845;&#20195;&#20013;&#24050;&#32463;&#24341;&#36215;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#23613;&#31649;&#23545;&#23548;&#33268;&#30340;&#31639;&#27861;&#30340;&#21508;&#31181;&#29702;&#35770;&#24615;&#36136;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#20027;&#35201;&#26469;&#33258;&#23398;&#20064;&#29702;&#35770;&#21644;&#20248;&#21270;&#35270;&#35282;&#65292;&#20294;&#23427;&#20204;&#30340;&#38544;&#31169;&#20445;&#25252;&#24615;&#36136;&#23578;&#26410;&#24314;&#31435;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#32570;&#21475;&#65292;&#25105;&#20204;&#20026;&#22122;&#22768;SGD&#25552;&#20379;&#24046;&#20998;&#38544;&#31169;(DP)&#20445;&#35777;&#65292;&#24403;&#27880;&#20837;&#30340;&#22122;&#22768;&#36981;&#24490;$\alpha$-&#31283;&#23450;&#20998;&#24067;&#26102;&#65292;&#35813;&#20998;&#24067;&#21253;&#25324;&#19968;&#31995;&#21015;&#37325;&#23614;&#20998;&#24067;(&#20855;&#26377;&#26080;&#38480;&#26041;&#24046;)&#20197;&#21450;&#39640;&#26031;&#20998;&#24067;&#12290;&#32771;&#34385;$(\epsilon,\delta)$-DP&#26694;&#26550;&#65292;&#25105;&#20204;&#34920;&#26126;&#24102;&#26377;&#37325;&#23614;&#25200;&#21160;&#30340;SGD&#23454;&#29616;&#20102;$(0,\tilde{\mathcal{O}}(1/n))$-DP&#30340;&#24191;&#27867;&#25439;&#22833;&#20989;&#25968;&#31867;&#65292;&#36825;&#20123;&#20989;&#25968;&#21487;&#20197;&#26159;&#38750;&#20984;&#30340;&#65292;&#36825;&#37324;$n$&#26159;&#25968;&#25454;&#28857;&#30340;&#25968;&#37327;&#12290;&#20316;&#20026;&#19968;&#39033;&#26174;&#30528;&#30340;&#21103;&#20135;&#21697;&#65292;&#19982;&#20197;&#24448;&#30340;&#24037;&#20316;&#30456;&#21453;&#65292;&#35813;&#24037;&#20316;&#35201;&#27714;&#26377;&#30028;se
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02051v1 Announce Type: cross  Abstract: Injecting heavy-tailed noise to the iterates of stochastic gradient descent (SGD) has received increasing attention over the past few years. While various theoretical properties of the resulting algorithm have been analyzed mainly from learning theory and optimization perspectives, their privacy preservation properties have not yet been established. Aiming to bridge this gap, we provide differential privacy (DP) guarantees for noisy SGD, when the injected noise follows an $\alpha$-stable distribution, which includes a spectrum of heavy-tailed distributions (with infinite variance) as well as the Gaussian distribution. Considering the $(\epsilon, \delta)$-DP framework, we show that SGD with heavy-tailed perturbations achieves $(0, \tilde{\mathcal{O}}(1/n))$-DP for a broad class of loss functions which can be non-convex, where $n$ is the number of data points. As a remarkable byproduct, contrary to prior work that necessitates bounded se
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20844;&#24179;&#28508;&#22312;&#34920;&#31034;&#30340;&#20108;&#20998;&#22270;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#29983;&#24577;&#32593;&#32476;&#20013;&#30340;&#25277;&#26679;&#20559;&#24046;&#38382;&#39064;&#65292;&#36890;&#36807;&#22312;&#25439;&#22833;&#20989;&#25968;&#20013;&#24341;&#20837;&#39069;&#22806;&#30340;HSIC&#24809;&#32602;&#39033;&#65292;&#30830;&#20445;&#20102;&#28508;&#22312;&#31354;&#38388;&#32467;&#26500;&#19982;&#36830;&#32493;&#21464;&#37327;&#30340;&#29420;&#31435;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.02011</link><description>&lt;p&gt;
&#20844;&#24179;&#28508;&#22312;&#34920;&#31034;&#30340;&#20108;&#20998;&#22270;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#20197;&#35299;&#20915;&#29983;&#24577;&#32593;&#32476;&#20013;&#30340;&#25277;&#26679;&#20559;&#24046;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Bipartite Graph Variational Auto-Encoder with Fair Latent Representation to Account for Sampling Bias in Ecological Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02011
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20844;&#24179;&#28508;&#22312;&#34920;&#31034;&#30340;&#20108;&#20998;&#22270;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#29983;&#24577;&#32593;&#32476;&#20013;&#30340;&#25277;&#26679;&#20559;&#24046;&#38382;&#39064;&#65292;&#36890;&#36807;&#22312;&#25439;&#22833;&#20989;&#25968;&#20013;&#24341;&#20837;&#39069;&#22806;&#30340;HSIC&#24809;&#32602;&#39033;&#65292;&#30830;&#20445;&#20102;&#28508;&#22312;&#31354;&#38388;&#32467;&#26500;&#19982;&#36830;&#32493;&#21464;&#37327;&#30340;&#29420;&#31435;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#26041;&#27861;&#65292;&#20351;&#29992;&#22270;&#23884;&#20837;&#26469;&#34920;&#31034;&#20108;&#20998;&#32593;&#32476;&#65292;&#20197;&#35299;&#20915;&#30740;&#31350;&#29983;&#24577;&#32593;&#32476;&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#65292;&#27604;&#22914;&#36830;&#25509;&#26893;&#29289;&#21644;&#20256;&#31881;&#32773;&#31561;&#32593;&#32476;&#65292;&#38656;&#32771;&#34385;&#35768;&#22810;&#21327;&#21464;&#37327;&#65292;&#23588;&#20854;&#35201;&#25511;&#21046;&#25277;&#26679;&#20559;&#24046;&#12290;&#25105;&#20204;&#23558;&#21464;&#20998;&#22270;&#33258;&#21160;&#32534;&#30721;&#22120;&#26041;&#27861;&#35843;&#25972;&#20026;&#20108;&#20998;&#24773;&#20917;&#65292;&#20174;&#32780;&#33021;&#22815;&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#29983;&#25104;&#23884;&#20837;&#65292;&#20854;&#20013;&#20004;&#32452;&#33410;&#28857;&#30340;&#20301;&#32622;&#22522;&#20110;&#23427;&#20204;&#30340;&#36830;&#25509;&#27010;&#29575;&#12290;&#25105;&#20204;&#23558;&#22312;&#31038;&#20250;&#23398;&#20013;&#24120;&#32771;&#34385;&#30340;&#20844;&#24179;&#24615;&#26694;&#26550;&#36716;&#21270;&#20026;&#29983;&#24577;&#23398;&#20013;&#30340;&#25277;&#26679;&#20559;&#24046;&#38382;&#39064;&#12290;&#36890;&#36807;&#22312;&#25439;&#22833;&#20989;&#25968;&#20013;&#28155;&#21152;Hilbert-Schmidt&#29420;&#31435;&#20934;&#21017;&#65288;HSIC&#65289;&#20316;&#20026;&#39069;&#22806;&#24809;&#32602;&#39033;&#65292;&#25105;&#20204;&#30830;&#20445;&#28508;&#22312;&#31354;&#38388;&#32467;&#26500;&#19982;&#36830;&#32493;&#21464;&#37327;&#65288;&#19982;&#25277;&#26679;&#36807;&#31243;&#30456;&#20851;&#65289;&#26080;&#20851;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22914;&#20309;&#25913;&#21464;&#25105;&#20204;&#23545;&#29983;&#24577;&#32593;&#32476;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02011v1 Announce Type: cross  Abstract: We propose a method to represent bipartite networks using graph embeddings tailored to tackle the challenges of studying ecological networks, such as the ones linking plants and pollinators, where many covariates need to be accounted for, in particular to control for sampling bias. We adapt the variational graph auto-encoder approach to the bipartite case, which enables us to generate embeddings in a latent space where the two sets of nodes are positioned based on their probability of connection. We translate the fairness framework commonly considered in sociology in order to address sampling bias in ecology. By incorporating the Hilbert-Schmidt independence criterion (HSIC) as an additional penalty term in the loss we optimize, we ensure that the structure of the latent space is independent of continuous variables, which are related to the sampling process. Finally, we show how our approach can change our understanding of ecological n
&lt;/p&gt;</description></item><item><title>&#35777;&#26126;&#20102;&#31890;&#23376;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#23545;&#20110;&#19968;&#33324;&#21270;&#30340;log-Sobolev&#21644;Polyak-Lojasiewicz&#19981;&#31561;&#24335;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#20197;&#21450;&#25512;&#24191;&#20102;Bakry-Emery&#23450;&#29702;&#12290;</title><link>https://arxiv.org/abs/2403.02004</link><description>&lt;p&gt;
&#31890;&#23376;&#26799;&#24230;&#19979;&#38477;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#20197;&#21450;log-Sobolev&#21644;Talagrand&#19981;&#31561;&#24335;&#30340;&#25512;&#24191;
&lt;/p&gt;
&lt;p&gt;
Error bounds for particle gradient descent, and extensions of the log-Sobolev and Talagrand inequalities
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02004
&lt;/p&gt;
&lt;p&gt;
&#35777;&#26126;&#20102;&#31890;&#23376;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#23545;&#20110;&#19968;&#33324;&#21270;&#30340;log-Sobolev&#21644;Polyak-Lojasiewicz&#19981;&#31561;&#24335;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#20197;&#21450;&#25512;&#24191;&#20102;Bakry-Emery&#23450;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#31890;&#23376;&#26799;&#24230;&#19979;&#38477;(PGD)~(Kuntz&#31561;&#20154;&#65292;2023)&#30340;&#38750;&#28176;&#36817;&#35823;&#24046;&#30028;&#38480;&#65292;&#36825;&#26159;&#19968;&#31181;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#31163;&#25955;&#21270;&#33258;&#30001;&#33021;&#26799;&#24230;&#27969;&#33719;&#24471;&#30340;&#22823;&#22411;&#28508;&#21464;&#37327;&#27169;&#22411;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#23545;&#20110;&#28385;&#36275;&#19968;&#33324;&#21270;log-Sobolev&#21644;Polyak-Lojasiewicz&#19981;&#31561;&#24335;&#65288;LSI&#21644;PLI&#65289;&#30340;&#27169;&#22411;&#65292;&#27969;&#20197;&#25351;&#25968;&#36895;&#24230;&#25910;&#25947;&#21040;&#33258;&#30001;&#33021;&#30340;&#26497;&#23567;&#21270;&#38598;&#21512;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#26368;&#20248;&#36755;&#36816;&#25991;&#29486;&#20013;&#20247;&#25152;&#21608;&#30693;&#30340;&#32467;&#26524;&#65288;LSI&#24847;&#21619;&#30528;Talagrand&#19981;&#31561;&#24335;&#65289;&#21450;&#20854;&#22312;&#20248;&#21270;&#25991;&#29486;&#20013;&#30340;&#23545;&#24212;&#29289;&#65288;PLI&#24847;&#21619;&#30528;&#25152;&#35859;&#30340;&#20108;&#27425;&#22686;&#38271;&#26465;&#20214;&#65289;&#25193;&#23637;&#24182;&#24212;&#29992;&#21040;&#25105;&#20204;&#30340;&#26032;&#35774;&#32622;&#65292;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#12290;&#25105;&#20204;&#36824;&#25512;&#24191;&#20102;Bakry-Emery&#23450;&#29702;&#65292;&#24182;&#23637;&#31034;&#20102;&#23545;&#20110;&#20855;&#26377;&#24378;&#20985;&#23545;&#25968;&#20284;&#28982;&#30340;&#27169;&#22411;&#65292;LSI/PLI&#30340;&#27010;&#25324;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02004v1 Announce Type: new  Abstract: We prove non-asymptotic error bounds for particle gradient descent (PGD)~(Kuntz et al., 2023), a recently introduced algorithm for maximum likelihood estimation of large latent variable models obtained by discretizing a gradient flow of the free energy. We begin by showing that, for models satisfying a condition generalizing both the log-Sobolev and the Polyak--{\L}ojasiewicz inequalities (LSI and P{\L}I, respectively), the flow converges exponentially fast to the set of minimizers of the free energy. We achieve this by extending a result well-known in the optimal transport literature (that the LSI implies the Talagrand inequality) and its counterpart in the optimization literature (that the P{\L}I implies the so-called quadratic growth condition), and applying it to our new setting. We also generalize the Bakry--\'Emery Theorem and show that the LSI/P{\L}I generalization holds for models with strongly concave log-likelihoods. For such m
&lt;/p&gt;</description></item><item><title>Hopfield&#25552;&#20986;&#20102;&#19968;&#31181;Hebbian&#23398;&#20064;&#35268;&#21017;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#30740;&#31350;&#20102;&#20851;&#32852;&#35760;&#24518;&#30340;&#23481;&#37327;&#65292;&#25351;&#20986;&#32593;&#32476;&#30340;&#23481;&#37327;&#19982;&#27169;&#24335;&#22823;&#23567;&#32447;&#24615;&#30456;&#20851;&#65292;&#25552;&#20986;&#20102;&#23481;&#37327;&#39044;&#27979;&#20540;&#65292;&#24182;&#20351;&#29992;&#20004;&#20010;&#33879;&#21517;&#27169;&#24335;&#30340;&#21560;&#24341;&#30406;&#22320;&#26469;&#25506;&#35752;&#30456;&#20851;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.01907</link><description>&lt;p&gt;
Hebbian-Hopfield&#32593;&#32476;&#20851;&#32852;&#35760;&#24518;&#30340;&#23481;&#37327;
&lt;/p&gt;
&lt;p&gt;
Capacity of the Hebbian-Hopfield network associative memory
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01907
&lt;/p&gt;
&lt;p&gt;
Hopfield&#25552;&#20986;&#20102;&#19968;&#31181;Hebbian&#23398;&#20064;&#35268;&#21017;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#30740;&#31350;&#20102;&#20851;&#32852;&#35760;&#24518;&#30340;&#23481;&#37327;&#65292;&#25351;&#20986;&#32593;&#32476;&#30340;&#23481;&#37327;&#19982;&#27169;&#24335;&#22823;&#23567;&#32447;&#24615;&#30456;&#20851;&#65292;&#25552;&#20986;&#20102;&#23481;&#37327;&#39044;&#27979;&#20540;&#65292;&#24182;&#20351;&#29992;&#20004;&#20010;&#33879;&#21517;&#27169;&#24335;&#30340;&#21560;&#24341;&#30406;&#22320;&#26469;&#25506;&#35752;&#30456;&#20851;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;Hopfield&#30340;&#35770;&#25991;&#20013;&#65292;&#20182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Hebbian&#23398;&#20064;&#35268;&#21017;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#23427;&#22914;&#20309;&#21487;&#20197;&#39640;&#25928;&#22320;&#20316;&#20026;&#19968;&#20010;&#20851;&#32852;&#35760;&#24518;&#12290;&#22312;&#30740;&#31350;&#38543;&#26426;&#20108;&#36827;&#21046;&#27169;&#24335;&#26102;&#65292;&#20182;&#36824;&#21457;&#29616;&#65292;&#22914;&#26524;&#23384;&#20648;&#27169;&#24335;&#26816;&#32034;&#20013;&#23481;&#24525;&#19968;&#23567;&#37096;&#20998;&#38169;&#35823;&#65292;&#32593;&#32476;&#30340;&#23481;&#37327;&#65288;&#26368;&#22823;&#35760;&#24518;&#27169;&#24335;&#25968;&#65292;$m$&#65289;&#19982;&#27599;&#20010;&#27169;&#24335;&#30340;&#22823;&#23567;$n$&#21576;&#32447;&#24615;&#20851;&#31995;&#12290;&#27492;&#22806;&#65292;&#20182;&#33879;&#21517;&#22320;&#39044;&#27979;&#20102;$\alpha_c=\lim_{n\rightarrow\infty}\frac{m}{n}\approx 0.14$&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#36825;&#20010;&#38750;&#24120;&#30456;&#21516;&#30340;&#24773;&#26223;&#65292;&#20351;&#29992;&#20102;&#20004;&#31181;&#33879;&#21517;&#27169;&#24335;&#30340;&#21560;&#24341;&#30406;&#22320;&#65306;\textbf{\emph{(i)}}&#26469;&#33258;\cite{AmiGutSom85}&#30340;AGS&#65307;&#20197;&#21450;\textbf{\emph{(ii)}}&#26469;&#33258;\cite{Newman88,Louk94,Louk94a,Louk97,Tal98}&#30340;NLT&#12290;&#20381;&#36182;&#20110;&#26469;&#33258;\cite{Stojnicflrdt23}&#30340;\emph{&#23436;&#20840;&#25552;&#21319;&#30340;&#38543;&#26426;&#23545;&#20598;&#29702;&#35770;}&#65288;fl RDT&#65289;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#22312;&#31532;&#19968;&#23618;&#25552;&#21319;&#19978;&#30340;&#20197;&#19979;&#26126;&#30830;&#23481;&#37327;&#29305;&#24615;&#25551;&#36848;&#65306;\begin{equation} \alpha ...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01907v1 Announce Type: cross  Abstract: In \cite{Hop82}, Hopfield introduced a \emph{Hebbian} learning rule based neural network model and suggested how it can efficiently operate as an associative memory. Studying random binary patterns, he also uncovered that, if a small fraction of errors is tolerated in the stored patterns retrieval, the capacity of the network (maximal number of memorized patterns, $m$) scales linearly with each pattern's size, $n$. Moreover, he famously predicted $\alpha_c=\lim_{n\rightarrow\infty}\frac{m}{n}\approx 0.14$. We study this very same scenario with two famous pattern's basins of attraction: \textbf{\emph{(i)}} The AGS one from \cite{AmiGutSom85}; and \textbf{\emph{(ii)}} The NLT one from \cite{Newman88,Louk94,Louk94a,Louk97,Tal98}. Relying on the \emph{fully lifted random duality theory} (fl RDT) from \cite{Stojnicflrdt23}, we obtain the following explicit capacity characterizations on the first level of lifting:   \begin{equation}   \alpha
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25104;&#21151;&#23545;&#25239;&#26679;&#26412;&#27010;&#29575;&#19978;&#38480;&#30340;&#29702;&#35770;&#30028;&#38480;&#65292;&#21462;&#20915;&#20110;&#25200;&#21160;&#33539;&#25968;&#12289;&#26680;&#20989;&#25968;&#20197;&#21450;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#26368;&#25509;&#36817;&#30340;&#19981;&#21516;&#26631;&#31614;&#23545;&#20043;&#38388;&#30340;&#36317;&#31163;&#65292;&#24182;&#19988;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#29702;&#35770;&#32467;&#26524;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.01896</link><description>&lt;p&gt;
&#25104;&#21151;&#23545;&#25239;&#26679;&#26412;&#30340;&#24378;&#40065;&#26834;&#24615;&#30028;&#38480;&#65306;&#29702;&#35770;&#19982;&#23454;&#36341;
&lt;/p&gt;
&lt;p&gt;
Robustness Bounds on the Successful Adversarial Examples: Theory and Practice
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01896
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25104;&#21151;&#23545;&#25239;&#26679;&#26412;&#27010;&#29575;&#19978;&#38480;&#30340;&#29702;&#35770;&#30028;&#38480;&#65292;&#21462;&#20915;&#20110;&#25200;&#21160;&#33539;&#25968;&#12289;&#26680;&#20989;&#25968;&#20197;&#21450;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#26368;&#25509;&#36817;&#30340;&#19981;&#21516;&#26631;&#31614;&#23545;&#20043;&#38388;&#30340;&#36317;&#31163;&#65292;&#24182;&#19988;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#29702;&#35770;&#32467;&#26524;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#26679;&#26412;&#65288;AE&#65289;&#26159;&#19968;&#31181;&#38024;&#23545;&#26426;&#22120;&#23398;&#20064;&#30340;&#25915;&#20987;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#25968;&#25454;&#28155;&#21152;&#19981;&#21487;&#24863;&#30693;&#30340;&#25200;&#21160;&#26469;&#35825;&#20351;&#38169;&#20998;&#12290;&#26412;&#25991;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#20998;&#31867;&#65292;&#30740;&#31350;&#20102;&#25104;&#21151;AE&#30340;&#27010;&#29575;&#19978;&#38480;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#26032;&#30340;&#19978;&#30028;&#65292;&#21462;&#20915;&#20110;AE&#30340;&#25200;&#21160;&#33539;&#25968;&#12289;GP&#20013;&#20351;&#29992;&#30340;&#26680;&#20989;&#25968;&#20197;&#21450;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#20855;&#26377;&#19981;&#21516;&#26631;&#31614;&#30340;&#26368;&#25509;&#36817;&#23545;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#35813;&#19978;&#38480;&#19981;&#21463;&#26679;&#26412;&#25968;&#25454;&#38598;&#20998;&#24067;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;ImageNet&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25913;&#21464;&#26680;&#20989;&#25968;&#21442;&#25968;&#20250;&#23548;&#33268;&#25104;&#21151;AE&#27010;&#29575;&#19978;&#38480;&#30340;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01896v1 Announce Type: new  Abstract: Adversarial example (AE) is an attack method for machine learning, which is crafted by adding imperceptible perturbation to the data inducing misclassification. In the current paper, we investigated the upper bound of the probability of successful AEs based on the Gaussian Process (GP) classification. We proved a new upper bound that depends on AE's perturbation norm, the kernel function used in GP, and the distance of the closest pair with different labels in the training dataset. Surprisingly, the upper bound is determined regardless of the distribution of the sample dataset. We showed that our theoretical result was confirmed through the experiment using ImageNet. In addition, we showed that changing the parameters of the kernel function induces a change of the upper bound of the probability of successful AEs.
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#22240;&#26524;&#27491;&#21017;&#21270;&#25193;&#23637;&#21040;&#38170;&#22238;&#24402;&#65288;AR&#65289;&#20013;&#65292;&#25552;&#20986;&#20102;&#19982;&#38170;&#26694;&#26550;&#30456;&#21305;&#37197;&#30340;&#25439;&#22833;&#20989;&#25968;&#30830;&#20445;&#31283;&#20581;&#24615;&#65292;&#21508;&#31181;&#22810;&#20803;&#20998;&#26512;&#31639;&#27861;&#22343;&#22312;&#38170;&#26694;&#26550;&#20869;&#65292;&#31616;&#21333;&#27491;&#21017;&#21270;&#22686;&#24378;&#20102;OOD&#35774;&#32622;&#20013;&#30340;&#31283;&#20581;&#24615;&#65292;&#39564;&#35777;&#20102;&#38170;&#27491;&#21017;&#21270;&#30340;&#22810;&#21151;&#33021;&#24615;&#21644;&#23545;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#35770;&#30340;&#25512;&#36827;&#12290;</title><link>https://arxiv.org/abs/2403.01865</link><description>&lt;p&gt;
&#36890;&#36807;&#38170;&#22810;&#20803;&#20998;&#26512;&#25913;&#21892;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Improving generalisation via anchor multivariate analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01865
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#22240;&#26524;&#27491;&#21017;&#21270;&#25193;&#23637;&#21040;&#38170;&#22238;&#24402;&#65288;AR&#65289;&#20013;&#65292;&#25552;&#20986;&#20102;&#19982;&#38170;&#26694;&#26550;&#30456;&#21305;&#37197;&#30340;&#25439;&#22833;&#20989;&#25968;&#30830;&#20445;&#31283;&#20581;&#24615;&#65292;&#21508;&#31181;&#22810;&#20803;&#20998;&#26512;&#31639;&#27861;&#22343;&#22312;&#38170;&#26694;&#26550;&#20869;&#65292;&#31616;&#21333;&#27491;&#21017;&#21270;&#22686;&#24378;&#20102;OOD&#35774;&#32622;&#20013;&#30340;&#31283;&#20581;&#24615;&#65292;&#39564;&#35777;&#20102;&#38170;&#27491;&#21017;&#21270;&#30340;&#22810;&#21151;&#33021;&#24615;&#21644;&#23545;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#35770;&#30340;&#25512;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#38170;&#22238;&#24402;&#65288;AR&#65289;&#20013;&#24341;&#20837;&#22240;&#26524;&#27491;&#21017;&#21270;&#25193;&#23637;&#65292;&#20197;&#25913;&#21892;&#36229;&#20986;&#20998;&#24067;&#65288;OOD&#65289;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19982;&#38170;&#26694;&#26550;&#30456;&#21305;&#37197;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#20197;&#30830;&#20445;&#23545;&#20998;&#24067;&#36716;&#31227;&#30340;&#31283;&#20581;&#24615;&#12290;&#21508;&#31181;&#22810;&#20803;&#20998;&#26512;&#65288;MVA&#65289;&#31639;&#27861;&#65292;&#22914;&#65288;&#27491;&#20132;&#21270;&#65289;PLS&#12289;RRR&#21644;MLR&#65292;&#22343;&#22312;&#38170;&#26694;&#26550;&#20869;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#31616;&#21333;&#30340;&#27491;&#21017;&#21270;&#22686;&#24378;&#20102;OOD&#35774;&#32622;&#20013;&#30340;&#31283;&#20581;&#24615;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#30340;&#27668;&#20505;&#31185;&#23398;&#38382;&#39064;&#20013;&#65292;&#20026;&#25152;&#36873;&#31639;&#27861;&#25552;&#20379;&#20102;&#20272;&#35745;&#22120;&#65292;&#23637;&#31034;&#20102;&#20854;&#19968;&#33268;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;&#32463;&#39564;&#39564;&#35777;&#31361;&#26174;&#20102;&#38170;&#27491;&#21017;&#21270;&#30340;&#22810;&#21151;&#33021;&#24615;&#65292;&#24378;&#35843;&#20854;&#19982;MVA&#26041;&#27861;&#30340;&#20860;&#23481;&#24615;&#65292;&#24182;&#24378;&#35843;&#20854;&#22312;&#22686;&#24378;&#21487;&#22797;&#21046;&#24615;&#30340;&#21516;&#26102;&#25269;&#24481;&#20998;&#24067;&#36716;&#31227;&#20013;&#30340;&#20316;&#29992;&#12290;&#25193;&#23637;&#30340;AR&#26694;&#26550;&#25512;&#36827;&#20102;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#35770;&#65292;&#35299;&#20915;&#20102;&#21487;&#38752;OOD&#27867;&#21270;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01865v1 Announce Type: cross  Abstract: We introduce a causal regularisation extension to anchor regression (AR) for improved out-of-distribution (OOD) generalisation. We present anchor-compatible losses, aligning with the anchor framework to ensure robustness against distribution shifts. Various multivariate analysis (MVA) algorithms, such as (Orthonormalized) PLS, RRR, and MLR, fall within the anchor framework. We observe that simple regularisation enhances robustness in OOD settings. Estimators for selected algorithms are provided, showcasing consistency and efficacy in synthetic and real-world climate science problems. The empirical validation highlights the versatility of anchor regularisation, emphasizing its compatibility with MVA approaches and its role in enhancing replicability while guarding against distribution shifts. The extended AR framework advances causal inference methodologies, addressing the need for reliable OOD generalisation.
&lt;/p&gt;</description></item><item><title>&#28145;&#39532;&#36420;&#39640;&#26031;&#36807;&#31243;Deep-HGP&#26159;&#19968;&#31181;&#31616;&#21333;&#30340;&#20808;&#39564;&#65292;&#37319;&#29992;&#28145;&#39640;&#26031;&#36807;&#31243;&#24182;&#20801;&#35768;&#25968;&#25454;&#39537;&#21160;&#36873;&#25321;&#20851;&#38190;&#38271;&#24230;&#23610;&#24230;&#21442;&#25968;&#65292;&#23545;&#20110;&#38750;&#21442;&#25968;&#22238;&#24402;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#65292;&#23454;&#29616;&#20102;&#23545;&#26410;&#30693;&#30495;&#23454;&#22238;&#24402;&#26354;&#32447;&#30340;&#20248;&#21270;&#22238;&#22797;&#65292;&#20855;&#26377;&#33258;&#36866;&#24212;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.01737</link><description>&lt;p&gt;
&#28145;&#39532;&#36420;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Deep Horseshoe Gaussian Processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01737
&lt;/p&gt;
&lt;p&gt;
&#28145;&#39532;&#36420;&#39640;&#26031;&#36807;&#31243;Deep-HGP&#26159;&#19968;&#31181;&#31616;&#21333;&#30340;&#20808;&#39564;&#65292;&#37319;&#29992;&#28145;&#39640;&#26031;&#36807;&#31243;&#24182;&#20801;&#35768;&#25968;&#25454;&#39537;&#21160;&#36873;&#25321;&#20851;&#38190;&#38271;&#24230;&#23610;&#24230;&#21442;&#25968;&#65292;&#23545;&#20110;&#38750;&#21442;&#25968;&#22238;&#24402;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#65292;&#23454;&#29616;&#20102;&#23545;&#26410;&#30693;&#30495;&#23454;&#22238;&#24402;&#26354;&#32447;&#30340;&#20248;&#21270;&#22238;&#22797;&#65292;&#20855;&#26377;&#33258;&#36866;&#24212;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#25552;&#20986;&#28145;&#39640;&#26031;&#36807;&#31243;&#20316;&#20026;&#19968;&#31181;&#33258;&#28982;&#23545;&#35937;&#65292;&#31867;&#20284;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#33021;&#25311;&#21512;&#29616;&#20195;&#25968;&#25454;&#26679;&#26412;&#20013;&#23384;&#22312;&#30340;&#22797;&#26434;&#29305;&#24449;&#65292;&#22914;&#32452;&#21512;&#32467;&#26500;&#12290;&#37319;&#29992;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#33258;&#28982;&#22320;&#21033;&#29992;&#28145;&#39640;&#26031;&#36807;&#31243;&#20316;&#20026;&#20808;&#39564;&#20998;&#24067;&#65292;&#24182;&#23558;&#30456;&#24212;&#30340;&#21518;&#39564;&#20998;&#24067;&#29992;&#20110;&#32479;&#35745;&#25512;&#26029;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#28145;&#39532;&#36420;&#39640;&#26031;&#36807;&#31243;Deep-HGP&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#24102;&#26377;&#24179;&#26041;&#25351;&#25968;&#26680;&#30340;&#28145;&#39640;&#26031;&#36807;&#31243;&#30340;&#26032;&#31616;&#21333;&#20808;&#39564;&#65292;&#29305;&#21035;&#26159;&#20351;&#24471;&#21487;&#20197;&#23545;&#20851;&#38190;&#38271;&#24230;&#23610;&#24230;&#21442;&#25968;&#36827;&#34892;&#25968;&#25454;&#39537;&#21160;&#36873;&#25321;&#12290;&#23545;&#20110;&#38543;&#26426;&#35774;&#35745;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#30456;&#24212;&#30340;&#35843;&#33410;&#21518;&#39564;&#20998;&#24067;&#20197;&#19968;&#31181;&#33258;&#36866;&#24212;&#26041;&#24335;&#65292;&#26368;&#20248;&#22320;&#22312;&#20108;&#27425;&#25439;&#22833;&#30340;&#24847;&#20041;&#19979;&#24674;&#22797;&#26410;&#30693;&#30340;&#30495;&#22238;&#24402;&#26354;&#32447;&#65292;&#26368;&#22810;&#21482;&#26377;&#19968;&#20010;&#23545;&#25968;&#22240;&#23376;&#12290;&#25910;&#25947;&#36895;&#29575;&#21516;&#26102;&#23545;&#22238;&#24402;&#30340;&#24179;&#28369;&#24230;&#21644;&#35774;&#35745;&#32500;&#24230;&#33258;&#36866;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01737v1 Announce Type: cross  Abstract: Deep Gaussian processes have recently been proposed as natural objects to fit, similarly to deep neural networks, possibly complex features present in modern data samples, such as compositional structures. Adopting a Bayesian nonparametric approach, it is natural to use deep Gaussian processes as prior distributions, and use the corresponding posterior distributions for statistical inference. We introduce the deep Horseshoe Gaussian process Deep-HGP, a new simple prior based on deep Gaussian processes with a squared-exponential kernel, that in particular enables data-driven choices of the key lengthscale parameters. For nonparametric regression with random design, we show that the associated tempered posterior distribution recovers the unknown true regression curve optimally in terms of quadratic loss, up to a logarithmic factor, in an adaptive way. The convergence rates are simultaneously adaptive to both the smoothness of the regress
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#36719;&#32422;&#26463;&#34203;&#23450;&#35860;&#26725;(SSB)&#25511;&#21046;&#38382;&#39064;&#65292;&#22312;&#20801;&#35768;&#32456;&#31471;&#20998;&#24067;&#19982;&#39044;&#20808;&#25351;&#23450;&#20998;&#24067;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#65292;&#24809;&#32602;&#20004;&#32773;&#20043;&#38388;&#30340;Kullback-Leibler&#25955;&#24230;&#12290;&#29702;&#35770;&#19978;&#25512;&#23548;&#20986;&#20102;SSB&#35299;&#65292;&#26174;&#31034;&#26368;&#20248;&#25511;&#21046;&#36807;&#31243;&#30340;&#32456;&#31471;&#20998;&#24067;&#26159;&#956;T&#21644;&#20854;&#20182;&#20998;&#24067;&#30340;&#20960;&#20309;&#28151;&#21512;&#65292;&#24182;&#23558;&#32467;&#26524;&#25193;&#23637;&#21040;&#26102;&#38388;&#24207;&#21015;&#35774;&#32622;&#12290;</title><link>https://arxiv.org/abs/2403.01717</link><description>&lt;p&gt;
&#36719;&#32422;&#26463;&#34203;&#23450;&#35860;&#26725;&#65306;&#19968;&#31181;&#38543;&#26426;&#25511;&#21046;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Soft-constrained Schrodinger Bridge: a Stochastic Control Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01717
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#36719;&#32422;&#26463;&#34203;&#23450;&#35860;&#26725;(SSB)&#25511;&#21046;&#38382;&#39064;&#65292;&#22312;&#20801;&#35768;&#32456;&#31471;&#20998;&#24067;&#19982;&#39044;&#20808;&#25351;&#23450;&#20998;&#24067;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#65292;&#24809;&#32602;&#20004;&#32773;&#20043;&#38388;&#30340;Kullback-Leibler&#25955;&#24230;&#12290;&#29702;&#35770;&#19978;&#25512;&#23548;&#20986;&#20102;SSB&#35299;&#65292;&#26174;&#31034;&#26368;&#20248;&#25511;&#21046;&#36807;&#31243;&#30340;&#32456;&#31471;&#20998;&#24067;&#26159;&#956;T&#21644;&#20854;&#20182;&#20998;&#24067;&#30340;&#20960;&#20309;&#28151;&#21512;&#65292;&#24182;&#23558;&#32467;&#26524;&#25193;&#23637;&#21040;&#26102;&#38388;&#24207;&#21015;&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34203;&#23450;&#35860;&#26725;&#21487;&#20197;&#34987;&#35270;&#20026;&#19968;&#20010;&#36830;&#32493;&#26102;&#38388;&#30340;&#38543;&#26426;&#25511;&#21046;&#38382;&#39064;&#65292;&#30446;&#26631;&#26159;&#25214;&#21040;&#19968;&#20010;&#26368;&#20248;&#25511;&#21046;&#25193;&#25955;&#36807;&#31243;&#65292;&#20854;&#20855;&#26377;&#39044;&#20808;&#25351;&#23450;&#30340;&#32456;&#31471;&#20998;&#24067;&#956;T&#12290;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#20801;&#35768;&#32456;&#31471;&#20998;&#24067;&#19982;&#956;T&#19981;&#21516;&#20294;&#24809;&#32602;&#20004;&#20010;&#20998;&#24067;&#20043;&#38388;&#30340;Kullback-Leibler&#25955;&#24230;&#26469;&#27867;&#21270;&#36825;&#20010;&#38543;&#26426;&#25511;&#21046;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#26032;&#30340;&#25511;&#21046;&#38382;&#39064;&#31216;&#20026;&#36719;&#32422;&#26463;&#34203;&#23450;&#35860;&#26725;(SSB)&#12290;&#36825;&#39033;&#24037;&#20316;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#23545;SSB&#35299;&#30340;&#29702;&#35770;&#25512;&#23548;&#65292;&#34920;&#26126;&#26368;&#20248;&#25511;&#21046;&#36807;&#31243;&#30340;&#32456;&#31471;&#20998;&#24067;&#26159;&#956;T&#21644;&#21478;&#19968;&#20123;&#20998;&#24067;&#30340;&#20960;&#20309;&#28151;&#21512;&#12290;&#36825;&#20010;&#32467;&#26524;&#36827;&#19968;&#27493;&#25193;&#23637;&#21040;&#26102;&#38388;&#24207;&#21015;&#35774;&#32622;&#12290;SSB&#30340;&#19968;&#20010;&#24212;&#29992;&#26159;&#40065;&#26834;&#29983;&#25104;&#25193;&#25955;&#27169;&#22411;&#30340;&#24320;&#21457;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#20998;&#25968;&#21305;&#37197;&#30340;&#31639;&#27861;&#26469;&#20174;&#20960;&#20309;&#28151;&#21512;&#20013;&#36827;&#34892;&#25277;&#26679;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#29992;&#36884;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01717v1 Announce Type: cross  Abstract: Schr\"{o}dinger bridge can be viewed as a continuous-time stochastic control problem where the goal is to find an optimally controlled diffusion process with a pre-specified terminal distribution $\mu_T$. We propose to generalize this stochastic control problem by allowing the terminal distribution to differ from $\mu_T$ but penalizing the Kullback-Leibler divergence between the two distributions. We call this new control problem soft-constrained Schr\"{o}dinger bridge (SSB). The main contribution of this work is a theoretical derivation of the solution to SSB, which shows that the terminal distribution of the optimally controlled process is a geometric mixture of $\mu_T$ and some other distribution. This result is further extended to a time series setting. One application of SSB is the development of robust generative diffusion models. We propose a score matching-based algorithm for sampling from geometric mixtures and showcase its us
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#28151;&#21512;&#27169;&#22411;&#30340;&#28508;&#22312;&#28151;&#21512;&#24230;&#37327;&#30340;&#26641;&#29366;&#22270;&#65292;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#26041;&#24335;&#26469;&#24635;&#32467;&#21644;&#36873;&#25321;&#28151;&#21512;&#27169;&#22411;&#65292;&#33021;&#22815;&#22312;&#27169;&#22411;&#21442;&#25968;&#20165;&#20855;&#26377;&#36739;&#24369;&#21487;&#35782;&#21035;&#24615;&#26102;&#19968;&#33268;&#22320;&#36873;&#25321;&#30495;&#23454;&#28151;&#21512;&#32452;&#20998;&#30340;&#25968;&#37327;&#65292;&#24182;&#20174;&#26641;&#20013;&#33719;&#24471;&#21442;&#25968;&#20272;&#35745;&#30340;&#36880;&#28857;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.01684</link><description>&lt;p&gt;
&#28151;&#21512;&#24230;&#37327;&#30340;&#26641;&#29366;&#22270;&#65306;&#23398;&#20064;&#28508;&#22312;&#23618;&#27425;&#32467;&#26500;&#21644;&#26377;&#38480;&#28151;&#21512;&#27169;&#22411;&#30340;&#27169;&#22411;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Dendrogram of mixing measures: Learning latent hierarchy and model selection for finite mixture models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01684
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28151;&#21512;&#27169;&#22411;&#30340;&#28508;&#22312;&#28151;&#21512;&#24230;&#37327;&#30340;&#26641;&#29366;&#22270;&#65292;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#26041;&#24335;&#26469;&#24635;&#32467;&#21644;&#36873;&#25321;&#28151;&#21512;&#27169;&#22411;&#65292;&#33021;&#22815;&#22312;&#27169;&#22411;&#21442;&#25968;&#20165;&#20855;&#26377;&#36739;&#24369;&#21487;&#35782;&#21035;&#24615;&#26102;&#19968;&#33268;&#22320;&#36873;&#25321;&#30495;&#23454;&#28151;&#21512;&#32452;&#20998;&#30340;&#25968;&#37327;&#65292;&#24182;&#20174;&#26641;&#20013;&#33719;&#24471;&#21442;&#25968;&#20272;&#35745;&#30340;&#36880;&#28857;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#24335;&#65292;&#36890;&#36807;&#36807;&#24230;&#25311;&#21512;&#30340;&#28508;&#22312;&#28151;&#21512;&#24230;&#37327;&#30340;&#23618;&#27425;&#32858;&#31867;&#26641;&#65288;&#26641;&#29366;&#22270;&#65289;&#26469;&#27719;&#24635;&#21644;&#36873;&#25321;&#28151;&#21512;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#36830;&#25509;&#20102;&#20957;&#32858;&#24335;&#23618;&#27425;&#32858;&#31867;&#21644;&#28151;&#21512;&#24314;&#27169;&#12290;&#26641;&#29366;&#22270;&#30340;&#26500;&#24314;&#28304;&#33258;&#28151;&#21512;&#24230;&#37327;&#30340;&#25910;&#25947;&#29702;&#35770;&#65292;&#22240;&#27492;&#65292;&#25105;&#20204;&#26082;&#21487;&#20197;&#19968;&#33268;&#22320;&#36873;&#25321;&#30495;&#23454;&#28151;&#21512;&#32452;&#20998;&#30340;&#25968;&#37327;&#65292;&#20063;&#21487;&#20197;&#20174;&#26641;&#20013;&#33719;&#24471;&#21442;&#25968;&#20272;&#35745;&#30340;&#36880;&#28857;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#21363;&#20351;&#27169;&#22411;&#21442;&#25968;&#20165;&#20855;&#26377;&#36739;&#24369;&#21487;&#35782;&#21035;&#24615;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#23427;&#38416;&#36848;&#20102;&#22312;&#23618;&#27425;&#32858;&#31867;&#20013;&#36873;&#25321;&#26368;&#20339;&#32676;&#38598;&#25968;&#30340;&#36873;&#25321;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#19982;&#20256;&#32479;&#30340;&#28151;&#21512;&#27169;&#22411;&#27719;&#24635;&#26041;&#24335;&#30456;&#27604;&#65292;&#26641;&#29366;&#22270;&#25581;&#31034;&#20102;&#26377;&#20851;&#20122;&#32676;&#23618;&#27425;&#30340;&#26356;&#22810;&#20449;&#24687;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#20960;&#39033;&#27169;&#25311;&#30740;&#31350;&#26469;&#25903;&#25345;&#25105;&#20204;&#30340;&#29702;&#35770;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#24212;&#29992;&#31243;&#24207;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01684v1 Announce Type: cross  Abstract: We present a new way to summarize and select mixture models via the hierarchical clustering tree (dendrogram) of an overfitted latent mixing measure. Our proposed method bridges agglomerative hierarchical clustering and mixture modeling. The dendrogram's construction is derived from the theory of convergence of the mixing measures, and as a result, we can both consistently select the true number of mixing components and obtain the pointwise optimal convergence rate for parameter estimation from the tree, even when the model parameters are only weakly identifiable. In theory, it explicates the choice of the optimal number of clusters in hierarchical clustering. In practice, the dendrogram reveals more information on the hierarchy of subpopulations compared to traditional ways of summarizing mixture models. Several simulation studies are carried out to support our theory. We also illustrate the methodology with an application to single-c
&lt;/p&gt;</description></item><item><title>CATS&#36890;&#36807;&#26500;&#24314;&#36741;&#21161;&#26102;&#38388;&#24207;&#21015;&#20316;&#20026;&#22806;&#29983;&#21464;&#37327;&#65292;&#26377;&#25928;&#22320;&#34920;&#31034;&#21644;&#25972;&#21512;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25552;&#39640;&#20102;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#25928;&#26524;&#65292;&#24182;&#19988;&#30456;&#36739;&#20110;&#20043;&#21069;&#30340;&#27169;&#22411;&#22823;&#24133;&#20943;&#23569;&#20102;&#22797;&#26434;&#24615;&#21644;&#21442;&#25968;&#12290;</title><link>https://arxiv.org/abs/2403.01673</link><description>&lt;p&gt;
CATS&#65306;&#36890;&#36807;&#26500;&#24314;&#36741;&#21161;&#26102;&#38388;&#24207;&#21015;&#20316;&#20026;&#22806;&#29983;&#21464;&#37327;&#22686;&#24378;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
CATS: Enhancing Multivariate Time Series Forecasting by Constructing Auxiliary Time Series as Exogenous Variables
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01673
&lt;/p&gt;
&lt;p&gt;
CATS&#36890;&#36807;&#26500;&#24314;&#36741;&#21161;&#26102;&#38388;&#24207;&#21015;&#20316;&#20026;&#22806;&#29983;&#21464;&#37327;&#65292;&#26377;&#25928;&#22320;&#34920;&#31034;&#21644;&#25972;&#21512;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25552;&#39640;&#20102;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#25928;&#26524;&#65292;&#24182;&#19988;&#30456;&#36739;&#20110;&#20043;&#21069;&#30340;&#27169;&#22411;&#22823;&#24133;&#20943;&#23569;&#20102;&#22797;&#26434;&#24615;&#21644;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#65288;MTSF&#65289;&#65292;&#26368;&#36817;&#30340;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#26174;&#31034;&#65292;&#21333;&#21464;&#37327;&#27169;&#22411;&#32463;&#24120;&#20248;&#20110;&#22810;&#20803;&#27169;&#22411;&#12290;&#20026;&#20102;&#35299;&#20915;&#22810;&#20803;&#27169;&#22411;&#30340;&#19981;&#36275;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21363;&#26500;&#24314;&#36741;&#21161;&#26102;&#38388;&#24207;&#21015;&#65288;CATS&#65289;&#65292;&#23427;&#31867;&#20284;&#20110;2D&#26102;&#38388;&#19978;&#19979;&#25991;&#20851;&#27880;&#26426;&#21046;&#65292;&#20174;&#21407;&#22987;&#26102;&#38388;&#24207;&#21015;&#65288;OTS&#65289;&#29983;&#25104;&#36741;&#21161;&#26102;&#38388;&#24207;&#21015;&#65288;ATS&#65289;&#65292;&#20197;&#26377;&#25928;&#34920;&#31034;&#21644;&#25972;&#21512;&#31995;&#21015;&#38388;&#20851;&#31995;&#29992;&#20110;&#39044;&#27979;&#12290;ATS&#30340;&#20851;&#38190;&#21407;&#21017;-&#36830;&#32493;&#24615;&#65292;&#31232;&#30095;&#24615;&#21644;&#21464;&#24322;&#24615;-&#36890;&#36807;&#19981;&#21516;&#27169;&#22359;&#36827;&#34892;&#35782;&#21035;&#21644;&#23454;&#29616;&#12290;&#21363;&#20351;&#26159;&#22522;&#26412;&#30340;2&#23618;MLP&#20316;&#20026;&#26680;&#24515;&#39044;&#27979;&#22120;&#65292;CATS&#20063;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#25104;&#26524;&#65292;&#30456;&#23545;&#20110;&#20808;&#21069;&#30340;&#22810;&#20803;&#27169;&#22411;&#65292;&#23427;&#26174;&#33879;&#20943;&#23569;&#20102;&#22797;&#26434;&#24615;&#21644;&#21442;&#25968;&#65292;&#20351;&#20854;&#25104;&#20026;&#39640;&#25928;&#19988;&#21487;&#36716;&#31227;&#30340;MTSF&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01673v1 Announce Type: cross  Abstract: For Multivariate Time Series Forecasting (MTSF), recent deep learning applications show that univariate models frequently outperform multivariate ones. To address the difficiency in multivariate models, we introduce a method to Construct Auxiliary Time Series (CATS) that functions like a 2D temporal-contextual attention mechanism, which generates Auxiliary Time Series (ATS) from Original Time Series (OTS) to effectively represent and incorporate inter-series relationships for forecasting. Key principles of ATS - continuity, sparsity, and variability - are identified and implemented through different modules. Even with a basic 2-layer MLP as core predictor, CATS achieves state-of-the-art, significantly reducing complexity and parameters compared to previous multivariate models, marking it an efficient and transferable MTSF solution.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#39318;&#27425;&#22312;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#32972;&#26223;&#19979;&#36827;&#34892;&#29702;&#35770;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#23558;&#25193;&#25955;&#25351;&#23548;&#32435;&#20837;&#19981;&#20165;&#25552;&#21319;&#20102;&#20998;&#31867;&#32622;&#20449;&#24230;&#65292;&#32780;&#19988;&#20943;&#23569;&#20102;&#20998;&#24067;&#22810;&#26679;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.01639</link><description>&lt;p&gt;
Gaussian Mixture Models&#30340;&#25193;&#25955;&#25351;&#23548;&#30340;&#29702;&#35770;&#27934;&#35265;
&lt;/p&gt;
&lt;p&gt;
Theoretical Insights for Diffusion Guidance: A Case Study for Gaussian Mixture Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01639
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#22312;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#32972;&#26223;&#19979;&#36827;&#34892;&#29702;&#35770;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#23558;&#25193;&#25955;&#25351;&#23548;&#32435;&#20837;&#19981;&#20165;&#25552;&#21319;&#20102;&#20998;&#31867;&#32622;&#20449;&#24230;&#65292;&#32780;&#19988;&#20943;&#23569;&#20102;&#20998;&#24067;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#21463;&#30410;&#20110;&#23558;&#29305;&#23450;&#20219;&#21153;&#20449;&#24687;&#27880;&#20837;&#35780;&#20998;&#20989;&#25968;&#20197;&#24341;&#23548;&#26679;&#26412;&#29983;&#25104;&#26397;&#21521;&#25152;&#38656;&#23646;&#24615;&#12290;&#36825;&#31181;&#20449;&#24687;&#34987;&#31216;&#20026;&#25351;&#23548;&#12290;&#20363;&#22914;&#65292;&#22312;&#25991;&#26412;&#21040;&#22270;&#20687;&#21512;&#25104;&#20013;&#65292;&#25991;&#26412;&#36755;&#20837;&#34987;&#32534;&#30721;&#20026;&#25351;&#23548;&#20197;&#29983;&#25104;&#35821;&#20041;&#23545;&#40784;&#30340;&#22270;&#20687;&#12290;&#36866;&#24403;&#30340;&#25351;&#23548;&#36755;&#20837;&#19982;&#25193;&#25955;&#27169;&#22411;&#30340;&#24615;&#33021;&#23494;&#20999;&#30456;&#20851;&#12290;&#19968;&#20010;&#24120;&#35265;&#30340;&#35266;&#23519;&#26159;&#65292;&#24378;&#26377;&#21147;&#30340;&#25351;&#23548;&#20419;&#36827;&#20102;&#19982;&#20219;&#21153;&#29305;&#23450;&#20449;&#24687;&#30340;&#32039;&#23494;&#23545;&#40784;&#65292;&#21516;&#26102;&#20943;&#23569;&#20102;&#29983;&#25104;&#26679;&#26412;&#30340;&#22810;&#26679;&#24615;&#12290;&#26412;&#25991;&#39318;&#27425;&#22312;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#32972;&#26223;&#19979;&#25552;&#20379;&#20102;&#23545;&#29702;&#35299;&#25351;&#23548;&#23545;&#25193;&#25955;&#27169;&#22411;&#24433;&#21709;&#30340;&#29702;&#35770;&#30740;&#31350;&#12290;&#22312;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23558;&#25193;&#25955;&#25351;&#23548;&#32435;&#20837;&#19981;&#20165;&#25552;&#21319;&#20102;&#20998;&#31867;&#32622;&#20449;&#24230;&#65292;&#32780;&#19988;&#20943;&#23569;&#20102;&#20998;&#24067;&#22810;&#26679;&#24615;&#65292;&#23548;&#33268;&#36755;&#20986;&#20998;&#24067;&#30340;&#24046;&#24322;&#29109;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01639v1 Announce Type: new  Abstract: Diffusion models benefit from instillation of task-specific information into the score function to steer the sample generation towards desired properties. Such information is coined as guidance. For example, in text-to-image synthesis, text input is encoded as guidance to generate semantically aligned images. Proper guidance inputs are closely tied to the performance of diffusion models. A common observation is that strong guidance promotes a tight alignment to the task-specific information, while reducing the diversity of the generated samples. In this paper, we provide the first theoretical study towards understanding the influence of guidance on diffusion models in the context of Gaussian mixture models. Under mild conditions, we prove that incorporating diffusion guidance not only boosts classification confidence but also diminishes distribution diversity, leading to a reduction in the differential entropy of the output distribution.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30740;&#31350;&#21457;&#29616;&#65292;&#24403;&#20195;&#29702;&#22312;&#22810;&#26679;&#21270;&#20219;&#21153;&#19978;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;&#20855;&#26377;&#30701;&#35270;&#25506;&#32034;&#35774;&#35745;&#30340;&#36890;&#29992;&#31574;&#30053;&#20849;&#20139;&#31639;&#27861;&#21487;&#20197;&#22312;&#22810;&#20219;&#21153;&#24378;&#21270;&#23398;&#20064;&#20013;&#26174;&#33879;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.01636</link><description>&lt;p&gt;
&#36890;&#36807;&#22810;&#20219;&#21153;&#24378;&#21270;&#23398;&#20064;&#23454;&#29616;&#39640;&#25928;&#30340;&#30701;&#35270;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Sample Efficient Myopic Exploration Through Multitask Reinforcement Learning with Diverse Tasks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01636
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#21457;&#29616;&#65292;&#24403;&#20195;&#29702;&#22312;&#22810;&#26679;&#21270;&#20219;&#21153;&#19978;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;&#20855;&#26377;&#30701;&#35270;&#25506;&#32034;&#35774;&#35745;&#30340;&#36890;&#29992;&#31574;&#30053;&#20849;&#20139;&#31639;&#27861;&#21487;&#20197;&#22312;&#22810;&#20219;&#21153;&#24378;&#21270;&#23398;&#20064;&#20013;&#26174;&#33879;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20219;&#21153;&#24378;&#21270;&#23398;&#20064;&#65288;MTRL&#65289;&#26041;&#27861;&#22312;&#35768;&#22810;&#37325;&#35201;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20219;&#21153;&#20013;&#24212;&#29992;&#24191;&#27867;&#65292;&#20294;&#36817;&#26399;MTRL&#29702;&#35770;&#30340;&#36827;&#23637;&#20027;&#35201;&#38598;&#20013;&#22312;&#36890;&#36807;&#20551;&#35774;&#20219;&#21153;&#38388;&#20849;&#20139;&#32467;&#26500;&#26469;&#25552;&#39640;&#32479;&#35745;&#25928;&#29575;&#65292;&#23545;&#20110;RL&#20013;&#33267;&#20851;&#37325;&#35201;&#30340;&#25506;&#32034;&#36825;&#19968;&#20851;&#38190;&#26041;&#38754;&#21364;&#22823;&#22810;&#34987;&#24573;&#35270;&#12290;&#26412;&#25991;&#36890;&#36807;&#23637;&#31034;&#65292;&#24403;&#20195;&#29702;&#22312;&#36275;&#22815;&#22810;&#26679;&#21270;&#30340;&#20219;&#21153;&#38598;&#19978;&#35757;&#32451;&#26102;&#65292;&#20855;&#26377;&#30701;&#35270;&#25506;&#32034;&#35774;&#35745;&#65288;&#22914;$\epsilon$-&#36138;&#24515;&#65289;&#30340;&#36890;&#29992;&#31574;&#30053;&#20849;&#20139;&#31639;&#27861;&#21487;&#20197;&#22312;MTRL&#20013;&#20855;&#26377;&#39640;&#26679;&#26412;&#25928;&#29575;&#65292;&#20174;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#23545;&#8220;&#25506;&#32034;&#25910;&#30410;&#8221;&#22312;MTRL&#20013;&#30340;&#39318;&#27425;&#29702;&#35770;&#35777;&#26126;&#65292;&#20063;&#26377;&#21161;&#20110;&#35299;&#37322;&#30701;&#35270;&#25506;&#32034;&#22312;&#23454;&#36341;&#20013;&#24212;&#29992;&#24191;&#27867;&#30340;&#25104;&#21151;&#12290;&#20026;&#20102;&#39564;&#35777;&#22810;&#26679;&#24615;&#30340;&#20316;&#29992;&#65292;&#25105;&#20204;&#22312;&#21512;&#25104;&#26426;&#22120;&#20154;&#25511;&#21046;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01636v1 Announce Type: cross  Abstract: Multitask Reinforcement Learning (MTRL) approaches have gained increasing attention for its wide applications in many important Reinforcement Learning (RL) tasks. However, while recent advancements in MTRL theory have focused on the improved statistical efficiency by assuming a shared structure across tasks, exploration--a crucial aspect of RL--has been largely overlooked. This paper addresses this gap by showing that when an agent is trained on a sufficiently diverse set of tasks, a generic policy-sharing algorithm with myopic exploration design like $\epsilon$-greedy that are inefficient in general can be sample-efficient for MTRL. To the best of our knowledge, this is the first theoretical demonstration of the "exploration benefits" of MTRL. It may also shed light on the enigmatic success of the wide applications of myopic exploration in practice. To validate the role of diversity, we conduct experiments on synthetic robotic control
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#30740;&#31350;&#25193;&#25955;&#27169;&#22411;&#20013;&#30340;&#8220;&#25209;&#21028;&#24615;&#31383;&#21475;&#8221;&#65292;&#24182;&#23637;&#31034;&#20102;&#38024;&#23545;&#24378;&#23545;&#25968;&#20985;&#23494;&#24230;&#28151;&#21512;&#25968;&#25454;&#65292;&#36825;&#20123;&#31383;&#21475;&#26159;&#21487;&#20197;&#26126;&#30830;&#22320;&#21463;&#21040;&#19968;&#23450;&#30340;&#20998;&#31163;&#24230;&#37327;&#32422;&#26463;&#30340;&#12290;</title><link>https://arxiv.org/abs/2403.01633</link><description>&lt;p&gt;
&#25209;&#21028;&#24615;&#31383;&#21475;&#65306;&#25193;&#25955;&#27169;&#22411;&#20013;&#29305;&#24449;&#20986;&#29616;&#30340;&#38750;&#28176;&#36827;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Critical windows: non-asymptotic theory for feature emergence in diffusion models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01633
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#30740;&#31350;&#25193;&#25955;&#27169;&#22411;&#20013;&#30340;&#8220;&#25209;&#21028;&#24615;&#31383;&#21475;&#8221;&#65292;&#24182;&#23637;&#31034;&#20102;&#38024;&#23545;&#24378;&#23545;&#25968;&#20985;&#23494;&#24230;&#28151;&#21512;&#25968;&#25454;&#65292;&#36825;&#20123;&#31383;&#21475;&#26159;&#21487;&#20197;&#26126;&#30830;&#22320;&#21463;&#21040;&#19968;&#23450;&#30340;&#20998;&#31163;&#24230;&#37327;&#32422;&#26463;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#21457;&#23637;&#29702;&#35770;&#26469;&#29702;&#35299;&#22270;&#20687;&#29983;&#25104;&#25193;&#25955;&#27169;&#22411;&#20013;&#19968;&#20010;&#26377;&#36259;&#30340;&#23646;&#24615;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#25209;&#21028;&#24615;&#31383;&#21475;&#12290;&#23454;&#35777;&#19978;&#35266;&#23519;&#21040;&#22312;&#37319;&#26679;&#36807;&#31243;&#20013;&#23384;&#22312;&#29421;&#31364;&#30340;&#26102;&#38388;&#38388;&#38548;&#65292;&#22312;&#27492;&#26399;&#38388;&#20250;&#20986;&#29616;&#26368;&#32456;&#22270;&#20687;&#30340;&#29305;&#23450;&#29305;&#24449;&#65292;&#20363;&#22914;&#22270;&#20687;&#31867;&#21035;&#25110;&#32972;&#26223;&#39068;&#33394;&#12290;&#32780;&#36825;&#31181;&#29305;&#24615;&#23545;&#20110;&#35299;&#37322;&#24615;&#26159;&#26377;&#21033;&#30340;&#65292;&#22240;&#20026;&#24847;&#21619;&#30528;&#21487;&#20197;&#23558;&#29983;&#25104;&#30340;&#29305;&#24615;&#23450;&#20301;&#21040;&#36712;&#36857;&#30340;&#19968;&#20010;&#23567;&#29255;&#27573;&#65292;&#20294;&#36825;&#20284;&#20046;&#19982;&#25193;&#25955;&#30340;&#36830;&#32493;&#24615;&#36136;&#30456;&#30683;&#30462;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#24418;&#24335;&#21270;&#26694;&#26550;&#26469;&#30740;&#31350;&#36825;&#20123;&#31383;&#21475;&#65292;&#24182;&#34920;&#26126;&#23545;&#20110;&#26469;&#33258;&#28151;&#21512;&#24378;&#23545;&#25968;&#20985;&#23494;&#24230;&#20998;&#24067;&#30340;&#25968;&#25454;&#65292;&#36825;&#20123;&#31383;&#21475;&#21487;&#20197;&#29992;&#19968;&#23450;&#30340;&#36328;&#32452;&#21644;&#32452;&#20869;&#20998;&#31163;&#24230;&#37327;&#26469;&#26174;&#24335;&#22320;&#32422;&#26463;&#12290;&#25105;&#20204;&#36824;&#20026;&#35832;&#22914;&#33391;&#26465;&#20214;G&#30340;&#20855;&#20307;&#31034;&#20363;&#23454;&#20363;&#21270;&#20102;&#36825;&#20123;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01633v1 Announce Type: new  Abstract: We develop theory to understand an intriguing property of diffusion models for image generation that we term critical windows. Empirically, it has been observed that there are narrow time intervals in sampling during which particular features of the final image emerge, e.g. the image class or background color (Ho et al., 2020b; Georgiev et al., 2023; Raya &amp; Ambrogioni, 2023; Sclocchi et al., 2024; Biroli et al., 2024). While this is advantageous for interpretability as it implies one can localize properties of the generation to a small segment of the trajectory, it seems at odds with the continuous nature of the diffusion. We propose a formal framework for studying these windows and show that for data coming from a mixture of strongly log-concave densities, these windows can be provably bounded in terms of certain measures of inter- and intra-group separation. We also instantiate these bounds for concrete examples like well-conditioned G
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#23545;&#25968;&#23494;&#24230;&#26799;&#24230;&#26041;&#27861;&#26469;&#20272;&#35745;&#31574;&#30053;&#26799;&#24230;&#65292;&#20462;&#27491;&#27531;&#24046;&#35823;&#24046;&#65292;&#26377;&#26395;&#25913;&#21892;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;</title><link>https://arxiv.org/abs/2403.01605</link><description>&lt;p&gt;
&#26397;&#21521;&#21487;&#35777;&#26126;&#30340;&#23545;&#25968;&#23494;&#24230;&#31574;&#30053;&#26799;&#24230;
&lt;/p&gt;
&lt;p&gt;
Towards Provable Log Density Policy Gradient
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01605
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#23545;&#25968;&#23494;&#24230;&#26799;&#24230;&#26041;&#27861;&#26469;&#20272;&#35745;&#31574;&#30053;&#26799;&#24230;&#65292;&#20462;&#27491;&#27531;&#24046;&#35823;&#24046;&#65292;&#26377;&#26395;&#25913;&#21892;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#26159;&#29616;&#20195;&#24378;&#21270;&#23398;&#20064;&#25104;&#21151;&#30340;&#20851;&#38190;&#35201;&#32032;&#12290;&#29616;&#20195;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#34429;&#28982;&#25104;&#21151;&#65292;&#20294;&#22312;&#26799;&#24230;&#20272;&#35745;&#20013;&#24341;&#20837;&#20102;&#19968;&#20010;&#27531;&#24046;&#35823;&#24046;&#12290;&#26412;&#25991;&#35748;&#20026;&#36825;&#20010;&#27531;&#24046;&#39033;&#24456;&#37325;&#35201;&#65292;&#32416;&#27491;&#23427;&#26377;&#21487;&#33021;&#25913;&#21892;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#25968;&#23494;&#24230;&#26799;&#24230;&#26469;&#20272;&#35745;&#31574;&#30053;&#26799;&#24230;&#65292;&#21487;&#20197;&#32416;&#27491;&#36825;&#20010;&#27531;&#24046;&#35823;&#24046;&#39033;&#12290;&#23545;&#25968;&#23494;&#24230;&#26799;&#24230;&#26041;&#27861;&#36890;&#36807;&#21033;&#29992;&#29366;&#24577;-&#21160;&#20316;&#25240;&#25187;&#20998;&#24067;&#24418;&#24335;&#26469;&#35745;&#31639;&#31574;&#30053;&#26799;&#24230;&#12290;&#25105;&#20204;&#39318;&#20808;&#32473;&#20986;&#20102;&#20934;&#30830;&#25214;&#21040;&#26631;&#31614;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#30340;&#23545;&#25968;&#23494;&#24230;&#26799;&#24230;&#25152;&#38656;&#30340;&#26041;&#31243;&#24335;&#12290;&#23545;&#20110;&#26356;&#22797;&#26434;&#30340;&#29615;&#22659;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#21518;&#21521;&#21363;&#26102;&#65288;TD&#65289;&#26041;&#27861;&#26469;&#36817;&#20284;&#35745;&#31639;&#23545;&#25968;&#23494;&#24230;&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21518;&#21521;&#30340;&#21516;&#31574;&#30053;&#26679;&#26412;&#12290;&#30001;&#20110;&#20174;&#39532;&#23572;&#21487;&#22827;&#38142;&#20013;&#36827;&#34892;&#21518;&#21521;&#37319;&#26679;&#26159;&#39640;&#24230;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01605v1 Announce Type: cross  Abstract: Policy gradient methods are a vital ingredient behind the success of modern reinforcement learning. Modern policy gradient methods, although successful, introduce a residual error in gradient estimation. In this work, we argue that this residual term is significant and correcting for it could potentially improve sample-complexity of reinforcement learning methods. To that end, we propose log density gradient to estimate the policy gradient, which corrects for this residual error term. Log density gradient method computes policy gradient by utilising the state-action discounted distributional formulation. We first present the equations needed to exactly find the log density gradient for a tabular Markov Decision Processes (MDPs). For more complex environments, we propose a temporal difference (TD) method that approximates log density gradient by utilizing backward on-policy samples. Since backward sampling from a Markov chain is highly 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;DML&#20272;&#35745;&#22120;&#25193;&#23637;&#65292;&#36890;&#36807;&#23545;&#27010;&#29575;&#24471;&#20998;&#24314;&#27169;&#36827;&#34892;&#27424;&#37319;&#26679;&#65292;&#24182;&#26657;&#20934;&#20998;&#25968;&#20197;&#21305;&#37197;&#21407;&#22987;&#20998;&#24067;&#65292;&#20197;&#35299;&#20915;&#22788;&#29702;&#20998;&#37197;&#19981;&#24179;&#34913;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.01585</link><description>&lt;p&gt;
&#20351;&#29992;&#19981;&#24179;&#34913;&#30340;&#22788;&#29702;&#20998;&#37197;&#26657;&#20934;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
Calibrating doubly-robust estimators with unbalanced treatment assignment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01585
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;DML&#20272;&#35745;&#22120;&#25193;&#23637;&#65292;&#36890;&#36807;&#23545;&#27010;&#29575;&#24471;&#20998;&#24314;&#27169;&#36827;&#34892;&#27424;&#37319;&#26679;&#65292;&#24182;&#26657;&#20934;&#20998;&#25968;&#20197;&#21305;&#37197;&#21407;&#22987;&#20998;&#24067;&#65292;&#20197;&#35299;&#20915;&#22788;&#29702;&#20998;&#37197;&#19981;&#24179;&#34913;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#23588;&#20854;&#26159;&#21452;&#26426;&#22120;&#23398;&#20064;&#65288;DML&#65289;&#20272;&#35745;&#22120;&#65288;Chernozhukov&#31561;&#65292;2018&#65289;&#65292;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#22320;&#29992;&#20110;&#20272;&#35745;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#12290;&#28982;&#32780;&#65292;&#25968;&#25454;&#38598;&#36890;&#24120;&#34920;&#29616;&#20986;&#22788;&#29702;&#20998;&#37197;&#19981;&#24179;&#34913;&#65292;&#21482;&#26377;&#23569;&#25968;&#35266;&#27979;&#20540;&#34987;&#22788;&#29702;&#65292;&#23548;&#33268;&#31283;&#20581;&#27010;&#29575;&#24471;&#20998;&#20272;&#35745;&#19981;&#31283;&#23450;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;DML&#20272;&#35745;&#22120;&#30340;&#31616;&#21333;&#25193;&#23637;&#65292;&#35813;&#25193;&#23637;&#23545;&#27010;&#29575;&#24471;&#20998;&#24314;&#27169;&#36827;&#34892;&#20102;&#27424;&#37319;&#26679;&#65292;&#24182;&#26657;&#20934;&#20998;&#25968;&#20197;&#21305;&#37197;&#21407;&#22987;&#20998;&#24067;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#29702;&#35770;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#20272;&#35745;&#22120;&#20445;&#30041;&#20102;DML&#20272;&#35745;&#22120;&#30340;&#28176;&#36817;&#29305;&#24615;&#12290;&#27169;&#25311;&#30740;&#31350;&#35828;&#26126;&#20102;&#20272;&#35745;&#22120;&#30340;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01585v1 Announce Type: new  Abstract: Machine learning methods, particularly the double machine learning (DML) estimator (Chernozhukov et al., 2018), are increasingly popular for the estimation of the average treatment effect (ATE). However, datasets often exhibit unbalanced treatment assignments where only a few observations are treated, leading to unstable propensity score estimations. We propose a simple extension of the DML estimator which undersamples data for propensity score modeling and calibrates scores to match the original distribution. The paper provides theoretical results showing that the estimator retains the DML estimator's asymptotic properties. A simulation study illustrates the finite sample performance of the estimator.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23558;Kullback-Leibler&#25955;&#24230;&#19982;Cohen's Kappa&#30456;&#20851;&#32852;&#65292;&#38480;&#21046;&#20102;&#20998;&#31867;&#24615;&#33021;&#30340;&#26368;&#22823;&#38480;&#24230;</title><link>https://arxiv.org/abs/2403.01571</link><description>&lt;p&gt;
&#23558;Kullback-Leibler&#25955;&#24230;&#19982;Cohen's Kappa&#30456;&#20851;&#32852;&#65292;&#38480;&#21046;&#20998;&#31867;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Limits to classification performance by relating Kullback-Leibler divergence to Cohen's Kappa
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01571
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23558;Kullback-Leibler&#25955;&#24230;&#19982;Cohen's Kappa&#30456;&#20851;&#32852;&#65292;&#38480;&#21046;&#20102;&#20998;&#31867;&#24615;&#33021;&#30340;&#26368;&#22823;&#38480;&#24230;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#31639;&#27861;&#30340;&#24615;&#33021;&#26159;&#36890;&#36807;&#20272;&#35745;&#25351;&#26631;&#26469;&#35780;&#20272;&#30340;&#65292;&#36890;&#24120;&#26159;&#20174;&#28151;&#28102;&#30697;&#38453;&#20013;&#20351;&#29992;&#35757;&#32451;&#25968;&#25454;&#21644;&#20132;&#21449;&#39564;&#35777;&#24471;&#20986;&#30340;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#24182;&#19981;&#35777;&#26126;&#24050;&#32463;&#23454;&#29616;&#20102;&#26368;&#20339;&#24615;&#33021;&#12290;&#21487;&#20197;&#20351;&#29992;&#20449;&#24687;&#36317;&#31163;&#24230;&#37327;&#26469;&#20272;&#35745;&#38169;&#35823;&#29575;&#30340;&#22522;&#26412;&#38480;&#21046;&#12290;&#20026;&#27492;&#65292;&#28151;&#28102;&#30697;&#38453;&#24050;&#34987;&#21046;&#23450;&#20026;&#31526;&#21512;Chernoff-Stein&#24341;&#29702;&#12290;&#36825;&#23558;&#38169;&#35823;&#29575;&#19982;&#25551;&#36848;&#20004;&#20010;&#31867;&#21035;&#30340;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#20043;&#38388;&#30340;Kullback-Leibler&#25955;&#24230;&#30456;&#20851;&#32852;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#20010;&#20851;&#38190;&#32467;&#26524;&#65292;&#23558;Cohen's Kappa&#19982;&#30005;&#38459;&#22120;&#24179;&#22343;&#36317;&#31163;&#32852;&#31995;&#36215;&#26469;&#65292;&#36825;&#26159;&#20004;&#20010;Kullback-Leibler&#25955;&#24230;&#30340;&#24182;&#32852;&#30005;&#38459;&#22120;&#32452;&#21512;&#12290;&#30005;&#38459;&#22120;&#24179;&#22343;&#36317;&#31163;&#20855;&#26377;&#27604;&#29305;&#21333;&#20301;&#65292;&#21487;&#20197;&#20174;&#21516;&#19968;&#35757;&#32451;&#25968;&#25454;&#20013;&#20351;&#29992;&#20998;&#31867;&#31639;&#27861;&#20272;&#35745;&#30340;KullBack-Leibler&#25955;&#24230;&#30340;kNN&#20272;&#35745;&#20013;&#24471;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01571v1 Announce Type: cross  Abstract: The performance of machine learning classification algorithms are evaluated by estimating metrics, often from the confusion matrix, using training data and cross-validation. However, these do not prove that the best possible performance has been achieved. Fundamental limits to error rates can be estimated using information distance measures. To this end, the confusion matrix has been formulated to comply with the Chernoff-Stein Lemma. This links the error rates to the Kullback-Leibler divergences between the probability density functions describing the two classes. This leads to a key result that relates Cohen's Kappa to the Resistor Average Distance which is the parallel resistor combination of the two Kullback-Leibler divergences. The Resistor Average Distance has units of bits and is estimated from the same training data used by the classification algorithm, using kNN estimates of the KullBack-Leibler divergences. The classification
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#19968;&#31181;&#20351;&#29992;&#25968;&#25454;&#28857;&#20851;&#20110;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#21442;&#25968;&#30340;&#26799;&#24230;&#36827;&#34892;&#31163;&#32676;&#20998;&#24067;&#26816;&#27979;&#30340;&#26041;&#27861;&#65292;&#22522;&#20110;&#23545;OOD&#25968;&#25454;&#24212;&#20855;&#26377;&#26356;&#22823;&#26799;&#24230;&#33539;&#25968;&#30340;&#31616;&#21333;&#30452;&#35273;&#65292;&#36890;&#36807;&#36817;&#20284;&#36153;&#33293;&#23572;&#20449;&#24687;&#24230;&#37327;&#23454;&#29616;&#35813;&#26041;&#27861;</title><link>https://arxiv.org/abs/2403.01485</link><description>&lt;p&gt;
&#23545;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#36153;&#33293;&#23572;&#20449;&#24687;&#24230;&#37327;&#36827;&#34892;&#36817;&#20284;&#29992;&#20110;&#26816;&#27979;&#31163;&#32676;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Approximations to the Fisher Information Metric of Deep Generative Models for Out-Of-Distribution Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01485
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#19968;&#31181;&#20351;&#29992;&#25968;&#25454;&#28857;&#20851;&#20110;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#21442;&#25968;&#30340;&#26799;&#24230;&#36827;&#34892;&#31163;&#32676;&#20998;&#24067;&#26816;&#27979;&#30340;&#26041;&#27861;&#65292;&#22522;&#20110;&#23545;OOD&#25968;&#25454;&#24212;&#20855;&#26377;&#26356;&#22823;&#26799;&#24230;&#33539;&#25968;&#30340;&#31616;&#21333;&#30452;&#35273;&#65292;&#36890;&#36807;&#36817;&#20284;&#36153;&#33293;&#23572;&#20449;&#24687;&#24230;&#37327;&#23454;&#29616;&#35813;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27010;&#29575;&#20284;&#28982;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#22914;&#22522;&#20110;&#35780;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#21644;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#26159;&#36817;&#24180;&#26469;&#29992;&#20110;&#25311;&#21512;&#39640;&#32500;&#25968;&#25454;&#20998;&#24067;&#65288;&#22914;&#22270;&#20687;&#12289;&#25991;&#26412;&#25110;&#38899;&#39057;&#65289;&#30340;&#20808;&#36827;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20043;&#19968;&#12290;&#23427;&#20204;&#21487;&#20197;&#33258;&#28982;&#22320;&#24212;&#29992;&#20110;&#35768;&#22810;&#19979;&#28216;&#20219;&#21153;&#20043;&#19968;&#65292;&#21363;&#31163;&#32676;&#20998;&#24067;&#65288;OOD&#65289;&#26816;&#27979;&#12290;&#28982;&#32780;&#65292;Nalisnick&#31561;&#20154;&#30340;&#24320;&#21019;&#24615;&#24037;&#20316;&#34920;&#26126;&#65292;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#22987;&#32456;&#20026;OOD&#25968;&#25454;&#25512;&#26029;&#20986;&#27604;&#23427;&#20204;&#35757;&#32451;&#36807;&#30340;&#25968;&#25454;&#26356;&#39640;&#30340;&#23545;&#25968;&#20284;&#28982;&#65292;&#26631;&#24535;&#30528;&#19968;&#20010;&#24748;&#32780;&#26410;&#20915;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#20351;&#29992;&#25968;&#25454;&#28857;&#23545;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#21442;&#25968;&#26799;&#24230;&#36827;&#34892;OOD&#26816;&#27979;&#65292;&#22522;&#20110;&#36825;&#26679;&#30340;&#31616;&#21333;&#30452;&#35273;&#65292;&#21363;OOD&#25968;&#25454;&#30340;&#26799;&#24230;&#33539;&#25968;&#24212;&#35813;&#22823;&#20110;&#35757;&#32451;&#25968;&#25454;&#12290;&#25105;&#20204;&#24418;&#24335;&#21270;&#22320;&#23558;&#26799;&#24230;&#22823;&#23567;&#30340;&#24230;&#37327;&#37327;&#21270;&#20026;&#36817;&#20284;&#36153;&#33293;&#23572;&#20449;&#24687;&#24230;&#37327;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36153;&#33293;&#23572;&#20449;&#24687;&#30697;&#38453;&#65288;FIM&#65289;&#20855;&#26377;&#36739;&#22823;&#30340;&#32477;&#23545;&#20540;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01485v1 Announce Type: cross  Abstract: Likelihood-based deep generative models such as score-based diffusion models and variational autoencoders are state-of-the-art machine learning models approximating high-dimensional distributions of data such as images, text, or audio. One of many downstream tasks they can be naturally applied to is out-of-distribution (OOD) detection. However, seminal work by Nalisnick et al. which we reproduce showed that deep generative models consistently infer higher log-likelihoods for OOD data than data they were trained on, marking an open problem. In this work, we analyse using the gradient of a data point with respect to the parameters of the deep generative model for OOD detection, based on the simple intuition that OOD data should have larger gradient norms than training data. We formalise measuring the size of the gradient as approximating the Fisher information metric. We show that the Fisher information matrix (FIM) has large absolute di
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#39640;&#26031;&#36807;&#31243;&#39044;&#27979;&#36890;&#36807;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#36827;&#34892;&#34701;&#21512;&#30340;&#26032;&#26041;&#27861;&#65292;&#26088;&#22312;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.01389</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#39044;&#27979;&#19982;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#30340;&#34701;&#21512;
&lt;/p&gt;
&lt;p&gt;
Fusion of Gaussian Processes Predictions with Monte Carlo Sampling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01389
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#39640;&#26031;&#36807;&#31243;&#39044;&#27979;&#36890;&#36807;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#36827;&#34892;&#34701;&#21512;&#30340;&#26032;&#26041;&#27861;&#65292;&#26088;&#22312;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31185;&#23398;&#21644;&#24037;&#31243;&#39046;&#22495;&#65292;&#25105;&#20204;&#32463;&#24120;&#20351;&#29992;&#26088;&#22312;&#20934;&#30830;&#39044;&#27979;&#24863;&#20852;&#36259;&#21464;&#37327;&#30340;&#27169;&#22411;&#12290;&#35748;&#35782;&#21040;&#36825;&#20123;&#27169;&#22411;&#26159;&#23545;&#29616;&#23454;&#30340;&#36817;&#20284;&#65292;&#25105;&#20204;&#24076;&#26395;&#23558;&#22810;&#20010;&#27169;&#22411;&#24212;&#29992;&#20110;&#30456;&#21516;&#30340;&#25968;&#25454;&#24182;&#25972;&#21512;&#23427;&#20204;&#30340;&#32467;&#26524;&#12290;&#26412;&#25991;&#22312;&#36125;&#21494;&#26031;&#33539;&#24335;&#20869;&#36816;&#34892;&#65292;&#20381;&#36182;&#20110;&#39640;&#26031;&#36807;&#31243;&#20316;&#20026;&#25105;&#20204;&#30340;&#27169;&#22411;&#12290;&#36825;&#20123;&#27169;&#22411;&#29983;&#25104;&#39044;&#27979;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#65288;pdf&#65289;&#65292;&#30446;&#26631;&#26159;&#31995;&#32479;&#22320;&#25972;&#21512;&#23427;&#20204;&#65292;&#20351;&#29992;&#32447;&#24615;&#21644;&#23545;&#25968;&#32447;&#24615;&#27719;&#24635;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#23545;&#20110;&#23545;&#25968;&#32447;&#24615;&#27719;&#24635;&#30340;&#26032;&#26041;&#27861;&#65292;&#30830;&#23450;&#20102;&#39640;&#26031;&#36807;&#31243;&#39044;&#27979;pdf&#30340;&#36755;&#20837;&#30456;&#20851;&#26435;&#37325;&#12290;&#36890;&#36807;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#20174;&#20854;&#21518;&#39564;&#20013;&#25277;&#21462;&#26435;&#37325;&#26679;&#26412;&#23454;&#29616;pdf&#30340;&#32858;&#21512;&#12290;&#36890;&#36807;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#38598;&#23637;&#31034;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#20197;&#21450;&#22522;&#20110;&#32447;&#24615;&#27719;&#24635;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01389v1 Announce Type: new  Abstract: In science and engineering, we often work with models designed for accurate prediction of variables of interest. Recognizing that these models are approximations of reality, it becomes desirable to apply multiple models to the same data and integrate their outcomes. In this paper, we operate within the Bayesian paradigm, relying on Gaussian processes as our models. These models generate predictive probability density functions (pdfs), and the objective is to integrate them systematically, employing both linear and log-linear pooling. We introduce novel approaches for log-linear pooling, determining input-dependent weights for the predictive pdfs of the Gaussian processes. The aggregation of the pdfs is realized through Monte Carlo sampling, drawing samples of weights from their posterior. The performance of these methods, as well as those based on linear pooling, is demonstrated using a synthetic dataset.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;&#39640;&#26031;&#22122;&#22768;&#39537;&#21160;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#30340;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#21464;&#20998;&#31639;&#27861;&#21644;&#32467;&#26500;&#21270;&#36924;&#36817;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#35780;&#20272;ELBO&#21644;&#33719;&#21462;&#20302;&#26041;&#24046;&#30340;&#38543;&#26426;&#26799;&#24230;&#20272;&#35745;&#65292;&#36890;&#36807;&#21033;&#29992;&#20302;&#31209;&#33945;&#29305;&#21345;&#32599;&#36924;&#36817;&#21644;&#25512;&#26029;&#32593;&#32476;&#30340;&#31934;&#24230;&#30697;&#38453;&#26356;&#26032;&#65292;&#23558;&#36817;&#20284;&#24179;&#28369;&#38382;&#39064;&#36716;&#21270;&#20026;&#36817;&#20284;&#28388;&#27874;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.01371</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#21464;&#20998;&#39640;&#26031;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Large-scale variational Gaussian state-space models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01371
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;&#39640;&#26031;&#22122;&#22768;&#39537;&#21160;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#30340;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#21464;&#20998;&#31639;&#27861;&#21644;&#32467;&#26500;&#21270;&#36924;&#36817;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#35780;&#20272;ELBO&#21644;&#33719;&#21462;&#20302;&#26041;&#24046;&#30340;&#38543;&#26426;&#26799;&#24230;&#20272;&#35745;&#65292;&#36890;&#36807;&#21033;&#29992;&#20302;&#31209;&#33945;&#29305;&#21345;&#32599;&#36924;&#36817;&#21644;&#25512;&#26029;&#32593;&#32476;&#30340;&#31934;&#24230;&#30697;&#38453;&#26356;&#26032;&#65292;&#23558;&#36817;&#20284;&#24179;&#28369;&#38382;&#39064;&#36716;&#21270;&#20026;&#36817;&#20284;&#28388;&#27874;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#23884;&#22871;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#21644;&#32467;&#26500;&#21270;&#21464;&#20998;&#36924;&#36817;&#26041;&#27861;&#65292;&#20854;&#20013;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#30001;&#39640;&#26031;&#22122;&#22768;&#39537;&#21160;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#20801;&#35768;&#22312;&#27809;&#26377;&#37319;&#29992;&#23545;&#35282;&#39640;&#26031;&#36924;&#36817;&#30340;&#24773;&#20917;&#19979;&#26377;&#25928;&#22320;&#35780;&#20272;ELBO&#21644;&#20302;&#26041;&#24046;&#38543;&#26426;&#26799;&#24230;&#20272;&#35745;&#65292;&#36890;&#36807;&#21033;&#29992;&#65288;i&#65289;&#36890;&#36807;&#21160;&#21147;&#23398;&#23545;&#38544;&#29366;&#24577;&#36827;&#34892;&#36793;&#32536;&#21270;&#30340;&#33945;&#29305;&#21345;&#32599;&#36924;&#36817;&#30340;&#20302;&#31209;&#32467;&#26500;&#65292;&#65288;ii&#65289;&#19968;&#20010;&#25512;&#26029;&#32593;&#32476;&#65292;&#35813;&#32593;&#32476;&#36890;&#36807;&#20302;&#31209;&#31934;&#24230;&#30697;&#38453;&#26356;&#26032;&#26469;&#36817;&#20284;&#26356;&#26032;&#27493;&#39588;&#65292;&#65288;iii&#65289;&#23558;&#24403;&#21069;&#21644;&#26410;&#26469;&#35266;&#27979;&#32534;&#30721;&#20026;&#20266;&#35266;&#27979;--&#23558;&#36817;&#20284;&#24179;&#28369;&#38382;&#39064;&#36716;&#25442;&#20026;&#65288;&#26356;&#31616;&#21333;&#30340;&#65289;&#36817;&#20284;&#28388;&#27874;&#38382;&#39064;&#12290;&#25972;&#20307;&#32780;&#35328;&#65292;&#24517;&#35201;&#30340;&#32479;&#35745;&#20449;&#24687;&#21644;ELBO&#21487;&#20197;&#22312;$O&#65288;TL&#65288;Sr+S^2+r^2&#65289;&#65289;$&#26102;&#38388;&#20869;&#35745;&#31639;&#65292;&#20854;&#20013;$T$&#26159;&#31995;&#21015;&#38271;&#24230;&#65292;$L$&#26159;&#29366;&#24577;&#31354;&#38388;&#32500;&#25968;&#65292;$S$&#26159;&#29992;&#20110;&#36924;&#36817;&#30340;&#26679;&#26412;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01371v1 Announce Type: cross  Abstract: We introduce an amortized variational inference algorithm and structured variational approximation for state-space models with nonlinear dynamics driven by Gaussian noise. Importantly, the proposed framework allows for efficient evaluation of the ELBO and low-variance stochastic gradient estimates without resorting to diagonal Gaussian approximations by exploiting (i) the low-rank structure of Monte-Carlo approximations to marginalize the latent state through the dynamics (ii) an inference network that approximates the update step with low-rank precision matrix updates (iii) encoding current and future observations into pseudo observations -- transforming the approximate smoothing problem into an (easier) approximate filtering problem. Overall, the necessary statistics and ELBO can be computed in $O(TL(Sr + S^2 + r^2))$ time where $T$ is the series length, $L$ is the state-space dimensionality, $S$ are the number of samples used to app
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#39640;&#32500;&#23614;&#25351;&#25968;&#22238;&#24402;&#26041;&#27861;&#65292;&#21033;&#29992;&#27491;&#21017;&#21270;&#20272;&#35745;&#21644;&#21435;&#20559;&#26041;&#27861;&#36827;&#34892;&#25512;&#26029;&#65292;&#25903;&#25345;&#29702;&#35770;&#30340;&#20223;&#30495;&#30740;&#31350;&#65292;&#24182;&#22312;&#31038;&#20132;&#23186;&#20307;&#30149;&#27602;&#24086;&#23376;&#25991;&#26412;&#20998;&#26512;&#20013;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2403.01318</link><description>&lt;p&gt;
&#39640;&#32500;&#23614;&#25351;&#25968;&#22238;&#24402;&#65306;&#20197;&#31038;&#20132;&#23186;&#20307;&#30149;&#27602;&#24086;&#23376;&#25991;&#26412;&#20998;&#26512;&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
High-Dimensional Tail Index Regression: with An Application to Text Analyses of Viral Posts in Social Media
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01318
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#39640;&#32500;&#23614;&#25351;&#25968;&#22238;&#24402;&#26041;&#27861;&#65292;&#21033;&#29992;&#27491;&#21017;&#21270;&#20272;&#35745;&#21644;&#21435;&#20559;&#26041;&#27861;&#36827;&#34892;&#25512;&#26029;&#65292;&#25903;&#25345;&#29702;&#35770;&#30340;&#20223;&#30495;&#30740;&#31350;&#65292;&#24182;&#22312;&#31038;&#20132;&#23186;&#20307;&#30149;&#27602;&#24086;&#23376;&#25991;&#26412;&#20998;&#26512;&#20013;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#31038;&#20132;&#23186;&#20307;&#30149;&#27602;&#24086;&#23376;&#30340;&#28857;&#36190;&#20998;&#24067;&#65288;&#22914;&#28857;&#36190;&#25968;&#37327;&#65289;&#32463;&#39564;&#24615;&#24130;&#24459;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#39640;&#32500;&#23614;&#25351;&#25968;&#22238;&#24402;&#21450;&#20854;&#21442;&#25968;&#30340;&#20272;&#35745;&#21644;&#25512;&#26029;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#27491;&#21017;&#21270;&#20272;&#35745;&#37327;&#65292;&#35777;&#26126;&#20102;&#23427;&#30340;&#19968;&#33268;&#24615;&#65292;&#24182;&#25512;&#23548;&#20102;&#20854;&#25910;&#25947;&#36895;&#24230;&#12290;&#20026;&#20102;&#36827;&#34892;&#25512;&#26029;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21435;&#20559;&#27491;&#21017;&#21270;&#20272;&#35745;&#65292;&#35777;&#26126;&#20102;&#21435;&#20559;&#20272;&#35745;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;&#20223;&#30495;&#30740;&#31350;&#25903;&#25345;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#12290;&#36825;&#20123;&#26041;&#27861;&#34987;&#24212;&#29992;&#20110;&#23545;&#28041;&#21450; LGBTQ+ &#35805;&#39064;&#30340; X&#65288;&#21407; Twitter&#65289;&#30149;&#27602;&#24086;&#23376;&#30340;&#25991;&#26412;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01318v1 Announce Type: cross  Abstract: Motivated by the empirical power law of the distributions of credits (e.g., the number of "likes") of viral posts in social media, we introduce the high-dimensional tail index regression and methods of estimation and inference for its parameters. We propose a regularized estimator, establish its consistency, and derive its convergence rate. To conduct inference, we propose to debias the regularized estimate, and establish the asymptotic normality of the debiased estimator. Simulation studies support our theory. These methods are applied to text analyses of viral posts in X (formerly Twitter) concerning LGBTQ+.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#30561;&#30496;&#33218;&#20915;&#31574;&#38382;&#39064;&#30340;&#25509;&#36817;&#26368;&#20248;&#27599;&#27425;&#34892;&#21160;&#36951;&#25022;&#30028;&#65292;&#36890;&#36807;&#30452;&#25509;&#26368;&#23567;&#21270;&#27599;&#27425;&#34892;&#21160;&#36951;&#25022;&#65292;&#20351;&#29992;Generalized EXP3&#12289;EXP3-IX&#21644;Tsallis entropy&#19979;&#30340;FTRL&#26041;&#27861;&#65292;&#33719;&#24471;&#20102;&#36739;&#20043;&#29616;&#26377;&#26041;&#27861;&#26356;&#22909;&#30340;&#30028;&#12290;</title><link>https://arxiv.org/abs/2403.01315</link><description>&lt;p&gt;
&#30561;&#30496;&#33218;&#20915;&#31574;&#38382;&#39064;&#20013;&#25509;&#36817;&#26368;&#20248;&#30340;&#27599;&#27425;&#34892;&#21160;&#36951;&#25022;&#30028;
&lt;/p&gt;
&lt;p&gt;
Near-optimal Per-Action Regret Bounds for Sleeping Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01315
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#30561;&#30496;&#33218;&#20915;&#31574;&#38382;&#39064;&#30340;&#25509;&#36817;&#26368;&#20248;&#27599;&#27425;&#34892;&#21160;&#36951;&#25022;&#30028;&#65292;&#36890;&#36807;&#30452;&#25509;&#26368;&#23567;&#21270;&#27599;&#27425;&#34892;&#21160;&#36951;&#25022;&#65292;&#20351;&#29992;Generalized EXP3&#12289;EXP3-IX&#21644;Tsallis entropy&#19979;&#30340;FTRL&#26041;&#27861;&#65292;&#33719;&#24471;&#20102;&#36739;&#20043;&#29616;&#26377;&#26041;&#27861;&#26356;&#22909;&#30340;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25512;&#23548;&#20102;&#38024;&#23545;&#30561;&#30496;&#33218;&#20915;&#31574;&#38382;&#39064;&#30340;&#25509;&#36817;&#26368;&#20248;&#27599;&#27425;&#34892;&#21160;&#36951;&#25022;&#30028;&#65292;&#20854;&#20013;&#25932;&#25163;&#36873;&#25321;&#27599;&#36718;&#21487;&#29992;&#33218;&#30340;&#38598;&#21512;&#21644;&#23427;&#20204;&#30340;&#25439;&#22833;&#12290;&#22312;&#27599;&#36718;&#33267;&#22810;&#26377; $A$ &#20010;&#21487;&#29992;&#33218;&#30340; $K$ &#20010;&#24635;&#33218;&#30340;&#24773;&#20917;&#19979;&#65292;&#24050;&#30693;&#30340;&#26368;&#22909;&#19978;&#30028;&#20026; $O(K\sqrt{TA\ln{K}})$&#65292;&#36890;&#36807;&#38388;&#25509;&#26368;&#23567;&#21270;&#20869;&#37096;&#30561;&#30496;&#36951;&#25022;&#33719;&#24471;&#12290;&#19982;&#26497;&#23567;&#20540; $\Omega(\sqrt{TA})$ &#19979;&#30028;&#30456;&#27604;&#65292;&#36825;&#20010;&#19978;&#30028;&#21253;&#21547;&#39069;&#22806;&#30340;&#20056;&#25968;&#22240;&#23376; $K\ln{K}$&#12290;&#25105;&#20204;&#36890;&#36807;&#30452;&#25509;&#26368;&#23567;&#21270;&#27599;&#27425;&#34892;&#21160;&#36951;&#25022;&#65292;&#20351;&#29992;EXP3&#12289;EXP3-IX&#21644;&#24102;&#26377;Tsallis&#29109;&#30340;FTRL&#30340;&#25512;&#24191;&#29256;&#26412;&#65292;&#20174;&#32780;&#33719;&#24471;&#20102;&#39034;&#24207;&#20026; $O(\sqrt{TA\ln{K}})$ &#21644; $O(\sqrt{T\sqrt{AK}})$ &#30340;&#25509;&#36817;&#26368;&#20248;&#30028;&#12290;&#25105;&#20204;&#23558;&#32467;&#26524;&#25193;&#23637;&#21040;&#20102;&#20174;&#30561;&#30496;&#19987;&#23478;&#33719;&#24471;&#24314;&#35758;&#30340;&#33218;&#20915;&#31574;&#38382;&#39064;&#35774;&#32622;&#65292;&#21516;&#26102;&#25512;&#24191;&#20102;EXP4&#12290;&#36825;&#20026;&#29616;&#26377;&#30340;&#22810;&#20010;&#33258;&#36866;&#24212;&#21644;&#36319;&#36394;&#36951;&#25022;&#30028;&#30340;&#26032;&#35777;&#26126;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01315v1 Announce Type: new  Abstract: We derive near-optimal per-action regret bounds for sleeping bandits, in which both the sets of available arms and their losses in every round are chosen by an adversary. In a setting with $K$ total arms and at most $A$ available arms in each round over $T$ rounds, the best known upper bound is $O(K\sqrt{TA\ln{K}})$, obtained indirectly via minimizing internal sleeping regrets. Compared to the minimax $\Omega(\sqrt{TA})$ lower bound, this upper bound contains an extra multiplicative factor of $K\ln{K}$. We address this gap by directly minimizing the per-action regret using generalized versions of EXP3, EXP3-IX and FTRL with Tsallis entropy, thereby obtaining near-optimal bounds of order $O(\sqrt{TA\ln{K}})$ and $O(\sqrt{T\sqrt{AK}})$. We extend our results to the setting of bandits with advice from sleeping experts, generalizing EXP4 along the way. This leads to new proofs for a number of existing adaptive and tracking regret bounds for 
&lt;/p&gt;</description></item><item><title>&#25506;&#35752;&#20102;&#23558;&#21518;&#39564;&#35843;&#25972;&#26367;&#25442;&#20026;&#22686;&#21152;&#20449;&#24515;&#30340;&#20808;&#39564;&#20998;&#24067;&#30340;&#21487;&#34892;&#24615;&#65292;&#24341;&#20837;&#20102;&#23454;&#29992;&#30340;&#8220;DirClip&#8221;&#20808;&#39564;&#21644;&#8220;&#20449;&#24515;&#20808;&#39564;&#8221;&#65292;&#25552;&#20379;&#20102;&#23545;&#20449;&#24515;&#20808;&#39564;&#30340;&#19968;&#33324;&#35265;&#35299;&#12290;</title><link>https://arxiv.org/abs/2403.01272</link><description>&lt;p&gt;
&#21487;&#20197;&#29992;&#33258;&#20449;&#20808;&#39564;&#26367;&#20195;&#20919;&#21364;&#21518;&#39564;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can a Confident Prior Replace a Cold Posterior?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01272
&lt;/p&gt;
&lt;p&gt;
&#25506;&#35752;&#20102;&#23558;&#21518;&#39564;&#35843;&#25972;&#26367;&#25442;&#20026;&#22686;&#21152;&#20449;&#24515;&#30340;&#20808;&#39564;&#20998;&#24067;&#30340;&#21487;&#34892;&#24615;&#65292;&#24341;&#20837;&#20102;&#23454;&#29992;&#30340;&#8220;DirClip&#8221;&#20808;&#39564;&#21644;&#8220;&#20449;&#24515;&#20808;&#39564;&#8221;&#65292;&#25552;&#20379;&#20102;&#23545;&#20449;&#24515;&#20808;&#39564;&#30340;&#19968;&#33324;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29992;&#20110;&#22270;&#20687;&#20998;&#31867;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#24448;&#24448;&#20855;&#26377;&#38750;&#24120;&#20302;&#30340;&#26631;&#31614;&#22122;&#22768;&#27700;&#24179;&#12290;&#24403;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#22312;&#36825;&#20123;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#26102;&#65292;&#23427;&#20204;&#32463;&#24120;&#27424;&#25311;&#21512;&#65292;&#38169;&#35823;&#22320;&#34920;&#31034;&#25968;&#25454;&#30340;&#38543;&#26426;&#19981;&#30830;&#23450;&#24615;&#12290;&#19968;&#31181;&#24120;&#35265;&#30340;&#35299;&#20915;&#26041;&#26696;&#26159;&#35843;&#25972;&#21518;&#39564;&#27010;&#29575;&#65292;&#36825;&#26679;&#21487;&#20197;&#25913;&#21892;&#23545;&#35757;&#32451;&#25968;&#25454;&#30340;&#25311;&#21512;&#65292;&#20294;&#20174;&#36125;&#21494;&#26031;&#35282;&#24230;&#35299;&#37322;&#36215;&#26469;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#21518;&#39564;&#35843;&#25972;&#26159;&#21542;&#21487;&#20197;&#34987;&#19968;&#31181;&#25552;&#39640;&#20449;&#24515;&#30340;&#20808;&#39564;&#20998;&#24067;&#26367;&#20195;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#23454;&#29992;&#30340;&#37319;&#26679;&#8220;DirClip&#8221;&#20808;&#39564;&#65292;&#24182;&#19988;&#20960;&#20046;&#19982;&#20919;&#21364;&#21518;&#39564;&#30340;&#24615;&#33021;&#30456;&#21305;&#37197;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#8220;&#20449;&#24515;&#20808;&#39564;&#8221;&#65292;&#23427;&#22312;&#28201;&#24230;&#36235;&#20110;&#38646;&#26102;&#30452;&#25509;&#36817;&#20284;&#20110;&#20919;&#24067;&#23616;&#65292;&#20294;&#19981;&#33021;&#36731;&#26494;&#25277;&#26679;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20123;&#20851;&#20110;&#25552;&#39640;&#20449;&#24515;&#30340;&#20808;&#39564;&#30340;&#19968;&#33324;&#35265;&#35299;&#65292;&#20363;&#22914;&#20309;&#26102;&#21487;&#33021;&#20986;&#29616;&#20998;&#27495;&#20197;&#21450;&#22914;&#20309;&#36890;&#36807;&#24494;&#35843;&#26469;&#32531;&#35299;&#25968;&#20540;&#19981;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01272v1 Announce Type: new  Abstract: Benchmark datasets used for image classification tend to have very low levels of label noise. When Bayesian neural networks are trained on these datasets, they often underfit, misrepresenting the aleatoric uncertainty of the data. A common solution is to cool the posterior, which improves fit to the training data but is challenging to interpret from a Bayesian perspective. We explore whether posterior tempering can be replaced by a confidence-inducing prior distribution. First, we introduce a "DirClip" prior that is practical to sample and nearly matches the performance of a cold posterior. Second, we introduce a "confidence prior" that directly approximates a cold likelihood in the limit of decreasing temperature but cannot be easily sampled. Lastly, we provide several general insights into confidence-inducing priors, such as when they might diverge and how fine-tuning can mitigate numerical instability.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;Massart&#22122;&#22768;&#30340;&#32447;&#24615;&#21644;ReLU&#22238;&#24402;&#38382;&#39064;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#20855;&#26377;&#26032;&#39062;&#30340;&#36817;&#20046;&#32447;&#24615;&#25910;&#25947;&#20445;&#35777;&#65292;&#39318;&#27425;&#22312;&#27969;&#24335;&#35774;&#32622;&#20013;&#20026;&#40065;&#26834;ReLU&#22238;&#24402;&#25552;&#20379;&#20102;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#30456;&#27604;&#20110;&#20197;&#21069;&#30340;&#26041;&#27861;&#26377;&#25913;&#36827;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.01204</link><description>&lt;p&gt;
&#20855;&#26377;Massart&#22122;&#22768;&#30340;&#27969;&#24335;&#32447;&#24615;&#21644;&#20462;&#27491;&#32447;&#24615;&#31995;&#32479;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;
&lt;/p&gt;
&lt;p&gt;
Stochastic gradient descent for streaming linear and rectified linear systems with Massart noise
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01204
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;Massart&#22122;&#22768;&#30340;&#32447;&#24615;&#21644;ReLU&#22238;&#24402;&#38382;&#39064;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#20855;&#26377;&#26032;&#39062;&#30340;&#36817;&#20046;&#32447;&#24615;&#25910;&#25947;&#20445;&#35777;&#65292;&#39318;&#27425;&#22312;&#27969;&#24335;&#35774;&#32622;&#20013;&#20026;&#40065;&#26834;ReLU&#22238;&#24402;&#25552;&#20379;&#20102;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#30456;&#27604;&#20110;&#20197;&#21069;&#30340;&#26041;&#27861;&#26377;&#25913;&#36827;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;SGD-exp&#65292;&#19968;&#31181;&#29992;&#20110;&#32447;&#24615;&#21644;ReLU&#22238;&#24402;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#22312;Massart&#22122;&#22768;&#65288;&#23545;&#25239;&#24615;&#21322;&#38543;&#26426;&#30772;&#22351;&#27169;&#22411;&#65289;&#19979;&#65292;&#23436;&#20840;&#27969;&#24335;&#35774;&#32622;&#19979;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;SGD-exp&#23545;&#30495;&#23454;&#21442;&#25968;&#30340;&#36817;&#20046;&#32447;&#24615;&#25910;&#25947;&#20445;&#35777;&#65292;&#26368;&#39640;&#21487;&#36798;50%&#30340;Massart&#30772;&#22351;&#29575;&#65292;&#22312;&#23545;&#31216;&#26080;&#24551;&#30772;&#22351;&#24773;&#20917;&#19979;&#65292;&#20219;&#24847;&#30772;&#22351;&#29575;&#20063;&#26377;&#20445;&#35777;&#12290;&#36825;&#26159;&#27969;&#24335;&#35774;&#32622;&#20013;&#40065;&#26834;ReLU&#22238;&#24402;&#30340;&#31532;&#19968;&#20010;&#25910;&#25947;&#20445;&#35777;&#32467;&#26524;&#65292;&#23427;&#26174;&#31034;&#20102;&#30456;&#27604;&#20110;&#20197;&#21069;&#30340;&#40065;&#26834;&#26041;&#27861;&#23545;&#20110;L1&#32447;&#24615;&#22238;&#24402;&#20855;&#26377;&#25913;&#36827;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#36825;&#26159;&#30001;&#20110;&#36873;&#25321;&#20102;&#25351;&#25968;&#34928;&#20943;&#27493;&#38271;&#65292;&#36825;&#22312;&#23454;&#36341;&#20013;&#24050;&#34987;&#35777;&#26126;&#26159;&#26377;&#25928;&#30340;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#22522;&#20110;&#31163;&#25955;&#38543;&#26426;&#36807;&#31243;&#30340;&#28418;&#31227;&#20998;&#26512;&#65292;&#36825;&#26412;&#36523;&#20063;&#21487;&#33021;&#26159;&#26377;&#36259;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01204v1 Announce Type: new  Abstract: We propose SGD-exp, a stochastic gradient descent approach for linear and ReLU regressions under Massart noise (adversarial semi-random corruption model) for the fully streaming setting. We show novel nearly linear convergence guarantees of SGD-exp to the true parameter with up to $50\%$ Massart corruption rate, and with any corruption rate in the case of symmetric oblivious corruptions. This is the first convergence guarantee result for robust ReLU regression in the streaming setting, and it shows the improved convergence rate over previous robust methods for $L_1$ linear regression due to a choice of an exponentially decaying step size, known for its efficiency in practice. Our analysis is based on the drift analysis of a discrete stochastic process, which could also be interesting on its own.
&lt;/p&gt;</description></item><item><title>&#35777;&#26126;&#22312;1-D&#25968;&#25454;&#19978;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#31561;&#20215;&#20110;&#35299;&#20915;&#19968;&#20010;&#20855;&#26377;&#22266;&#23450;&#29305;&#24449;&#23383;&#20856;&#30697;&#38453;&#30340;&#20984;Lasso&#38382;&#39064;&#65292;&#20026;&#20840;&#23616;&#26368;&#20248;&#32593;&#32476;&#21644;&#35299;&#31354;&#38388;&#25552;&#20379;&#20102;&#27934;&#23519;&#12290;</title><link>https://arxiv.org/abs/2403.01046</link><description>&lt;p&gt;
&#19968;&#20010;&#38236;&#23376;&#30340;&#24211;&#65306;&#20302;&#32500;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26159;&#20855;&#26377;&#21453;&#23556;&#29305;&#24449;&#30340;&#20984;Lasso&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Library of Mirrors: Deep Neural Nets in Low Dimensions are Convex Lasso Models with Reflection Features
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01046
&lt;/p&gt;
&lt;p&gt;
&#35777;&#26126;&#22312;1-D&#25968;&#25454;&#19978;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#31561;&#20215;&#20110;&#35299;&#20915;&#19968;&#20010;&#20855;&#26377;&#22266;&#23450;&#29305;&#24449;&#23383;&#20856;&#30697;&#38453;&#30340;&#20984;Lasso&#38382;&#39064;&#65292;&#20026;&#20840;&#23616;&#26368;&#20248;&#32593;&#32476;&#21644;&#35299;&#31354;&#38388;&#25552;&#20379;&#20102;&#27934;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#22312;1-D&#25968;&#25454;&#19978;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#31561;&#20215;&#20110;&#35299;&#20915;&#19968;&#20010;&#24102;&#26377;&#22266;&#23450;&#12289;&#26126;&#30830;&#23450;&#20041;&#30340;&#29305;&#24449;&#23383;&#20856;&#30697;&#38453;&#30340;&#20984;Lasso&#38382;&#39064;&#12290;&#20855;&#20307;&#30340;&#23383;&#20856;&#21462;&#20915;&#20110;&#28608;&#27963;&#20989;&#25968;&#21644;&#28145;&#24230;&#12290;&#25105;&#20204;&#32771;&#34385;&#20855;&#26377;&#20998;&#27573;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#30340;&#20004;&#23618;&#32593;&#32476;&#65292;&#28145;&#31364;&#30340;ReLU&#32593;&#32476;&#26368;&#22810;&#26377;4&#23618;&#65292;&#20197;&#21450;&#20855;&#26377;&#31526;&#21495;&#28608;&#27963;&#21644;&#20219;&#24847;&#28145;&#24230;&#30340;&#30697;&#24418;&#21644;&#26641;&#32593;&#32476;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#22312;ReLU&#32593;&#32476;&#20013;&#65292;&#31532;&#22235;&#23618;&#21019;&#24314;&#20195;&#34920;&#35757;&#32451;&#25968;&#25454;&#20851;&#20110;&#33258;&#36523;&#30340;&#21453;&#23556;&#30340;&#29305;&#24449;&#12290;Lasso&#34920;&#31034;&#27861;&#25581;&#31034;&#20102;&#20840;&#23616;&#26368;&#20248;&#32593;&#32476;&#21644;&#35299;&#31354;&#38388;&#30340;&#27934;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01046v1 Announce Type: cross  Abstract: We prove that training neural networks on 1-D data is equivalent to solving a convex Lasso problem with a fixed, explicitly defined dictionary matrix of features. The specific dictionary depends on the activation and depth. We consider 2-layer networks with piecewise linear activations, deep narrow ReLU networks with up to 4 layers, and rectangular and tree networks with sign activation and arbitrary depth. Interestingly in ReLU networks, a fourth layer creates features that represent reflections of training data about themselves. The Lasso representation sheds insight to globally optimal networks and the solution landscape.
&lt;/p&gt;</description></item><item><title>&#26126;&#30830;&#34920;&#31034;&#20449;&#24687;&#32467;&#26500;&#26159;&#20998;&#26512;&#21644;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;</title><link>https://arxiv.org/abs/2403.00993</link><description>&lt;p&gt;
&#35770;&#37096;&#20998;&#21487;&#35266;&#23519;&#24207;&#21015;&#22242;&#38431;&#21644;&#28216;&#25103;&#20013;&#20449;&#24687;&#32467;&#26500;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
On the Role of Information Structure in Reinforcement Learning for Partially-Observable Sequential Teams and Games
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00993
&lt;/p&gt;
&lt;p&gt;
&#26126;&#30830;&#34920;&#31034;&#20449;&#24687;&#32467;&#26500;&#26159;&#20998;&#26512;&#21644;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#20013;&#65292;&#20449;&#24687;&#32467;&#26500;&#25551;&#36848;&#20102;&#31995;&#32479;&#20013;&#19981;&#21516;&#26102;&#21051;&#20107;&#20214;&#22914;&#20309;&#30456;&#20114;&#24433;&#21709;&#12290;&#26412;&#25991;&#20027;&#24352;&#26126;&#30830;&#34920;&#31034;&#20449;&#24687;&#32467;&#26500;&#26159;&#20998;&#26512;&#21644;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#24182;&#25552;&#20986;&#20855;&#26377;&#26126;&#30830;&#20449;&#24687;&#32467;&#26500;&#34920;&#31034;&#30340;&#26032;&#22411;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00993v1 Announce Type: cross  Abstract: In a sequential decision-making problem, the information structure is the description of how events in the system occurring at different points in time affect each other. Classical models of reinforcement learning (e.g., MDPs, POMDPs, Dec-POMDPs, and POMGs) assume a very simple and highly regular information structure, while more general models like predictive state representations do not explicitly model the information structure. By contrast, real-world sequential decision-making problems typically involve a complex and time-varying interdependence of system variables, requiring a rich and flexible representation of information structure.   In this paper, we argue for the perspective that explicit representation of information structures is an important component of analyzing and solving reinforcement learning problems. We propose novel reinforcement learning models with an explicit representation of information structure, capturing 
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;CDAM&#21644;TAM&#27169;&#22411;&#20197;&#25913;&#36827;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#20887;&#20313;&#20449;&#24687;&#24182;&#22686;&#24378;&#20114;&#20449;&#24687;&#65292;&#21033;&#29992;&#26102;&#38388;&#30456;&#20851;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.00869</link><description>&lt;p&gt;
&#21033;&#29992;&#20114;&#20449;&#24687;&#39537;&#21160;&#30340;&#36328;&#21464;&#37327;&#21644;&#26102;&#38388;&#24314;&#27169;&#26469;&#22686;&#24378;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Enhancing Multivariate Time Series Forecasting with Mutual Information-driven Cross-Variable and Temporal Modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00869
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;CDAM&#21644;TAM&#27169;&#22411;&#20197;&#25913;&#36827;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#20887;&#20313;&#20449;&#24687;&#24182;&#22686;&#24378;&#20114;&#20449;&#24687;&#65292;&#21033;&#29992;&#26102;&#38388;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#36827;&#23637;&#24378;&#35843;&#20102;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#23545;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#65288;MTSF&#65289;&#30340;&#24433;&#21709;&#12290;&#36890;&#24120;&#65292;&#36825;&#20123;&#25216;&#26415;&#34987;&#20998;&#20026;&#20004;&#31867;&#65306;&#36890;&#36947;&#29420;&#31435;&#21644;&#36890;&#36947;&#28151;&#21512;&#26041;&#27861;&#12290;&#34429;&#28982;&#36890;&#36947;&#29420;&#31435;&#26041;&#27861;&#36890;&#24120;&#20135;&#29983;&#26356;&#22909;&#30340;&#32467;&#26524;&#65292;&#20294;&#36890;&#36947;&#28151;&#21512;&#29702;&#35770;&#19978;&#21487;&#20197;&#36890;&#36807;&#21033;&#29992;&#21464;&#37327;&#38388;&#30340;&#30456;&#20851;&#24615;&#26469;&#25552;&#20379;&#25913;&#36827;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35748;&#20026;&#22312;&#36890;&#36947;&#28151;&#21512;&#26041;&#27861;&#20013;&#25972;&#21512;&#19981;&#30456;&#20851;&#20449;&#24687;&#21487;&#33021;&#20250;&#21066;&#24369;MTSF&#27169;&#22411;&#24615;&#33021;&#30340;&#28508;&#22312;&#22686;&#24378;&#12290;&#20026;&#20102;&#35777;&#23454;&#36825;&#19968;&#35266;&#28857;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#29992;&#20110;&#36890;&#36947;&#28151;&#21512;&#26041;&#27861;&#30340;&#36328;&#21464;&#37327;&#21435;&#30456;&#20851;&#24863;&#30693;&#29305;&#24449;&#24314;&#27169;&#65288;CDAM&#65289;&#65292;&#26088;&#22312;&#36890;&#36807;&#26368;&#23567;&#21270;&#36890;&#36947;&#38388;&#30340;&#20887;&#20313;&#20449;&#24687;&#21516;&#26102;&#22686;&#24378;&#30456;&#20851;&#30340;&#20114;&#20449;&#24687;&#26469;&#25913;&#36827;&#36890;&#36947;&#28151;&#21512;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#26102;&#24207;&#30456;&#20851;&#24863;&#30693;&#24314;&#27169;&#65288;TAM&#65289;&#26469;&#21033;&#29992;&#26102;&#38388;&#30456;&#20851;&#24615;&#65292;&#36825;&#26159;&#19968;&#20010;&#27493;&#39588;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00869v1 Announce Type: new  Abstract: Recent advancements have underscored the impact of deep learning techniques on multivariate time series forecasting (MTSF). Generally, these techniques are bifurcated into two categories: Channel-independence and Channel-mixing approaches. Although Channel-independence methods typically yield better results, Channel-mixing could theoretically offer improvements by leveraging inter-variable correlations. Nonetheless, we argue that the integration of uncorrelated information in channel-mixing methods could curtail the potential enhancement in MTSF model performance. To substantiate this claim, we introduce the Cross-variable Decorrelation Aware feature Modeling (CDAM) for Channel-mixing approaches, aiming to refine Channel-mixing by minimizing redundant information between channels while enhancing relevant mutual information. Furthermore, we introduce the Temporal correlation Aware Modeling (TAM) to exploit temporal correlations, a step be
&lt;/p&gt;</description></item><item><title>&#25913;&#36827;&#20102;FPGA&#21152;&#36895;&#31070;&#32463;&#32593;&#32476;&#25512;&#26029;&#20219;&#21153;&#30340;&#26041;&#27861;&#65292;&#25552;&#20986;&#23558;&#25972;&#20010;&#23376;&#32593;&#32476;&#26144;&#23556;&#21040;&#21333;&#20010;LUT&#20013;&#65292;&#20351;&#24471;&#31070;&#32463;&#32593;&#32476;&#25299;&#25169;&#21644;&#31934;&#24230;&#19981;&#20877;&#24433;&#21709;&#29983;&#25104;&#30340;&#26597;&#25214;&#34920;&#30340;&#22823;&#23567;&#12290;</title><link>https://arxiv.org/abs/2403.00849</link><description>&lt;p&gt;
NeuraLUT: &#22312;Boolean&#21512;&#25104;&#20989;&#25968;&#20013;&#38544;&#34255;&#31070;&#32463;&#32593;&#32476;&#23494;&#24230;
&lt;/p&gt;
&lt;p&gt;
NeuraLUT: Hiding Neural Network Density in Boolean Synthesizable Functions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00849
&lt;/p&gt;
&lt;p&gt;
&#25913;&#36827;&#20102;FPGA&#21152;&#36895;&#31070;&#32463;&#32593;&#32476;&#25512;&#26029;&#20219;&#21153;&#30340;&#26041;&#27861;&#65292;&#25552;&#20986;&#23558;&#25972;&#20010;&#23376;&#32593;&#32476;&#26144;&#23556;&#21040;&#21333;&#20010;LUT&#20013;&#65292;&#20351;&#24471;&#31070;&#32463;&#32593;&#32476;&#25299;&#25169;&#21644;&#31934;&#24230;&#19981;&#20877;&#24433;&#21709;&#29983;&#25104;&#30340;&#26597;&#25214;&#34920;&#30340;&#22823;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#32534;&#31243;&#38376;&#38453;&#21015;&#65288;FPGA&#65289;&#21152;&#36895;&#22120;&#24050;&#32463;&#35777;&#26126;&#22312;&#22788;&#29702;&#24310;&#36831;&#21644;&#36164;&#28304;&#20851;&#38190;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#25512;&#26029;&#20219;&#21153;&#26041;&#38754;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;&#31070;&#32463;&#32593;&#32476;&#20013;&#35745;&#31639;&#23494;&#38598;&#24230;&#26368;&#39640;&#30340;&#25805;&#20316;&#20043;&#19968;&#26159;&#29305;&#24449;&#21644;&#26435;&#37325;&#21521;&#37327;&#20043;&#38388;&#30340;&#28857;&#31215;&#12290;&#22240;&#27492;&#65292;&#19968;&#20123;&#20808;&#21069;&#30340;FPGA&#21152;&#36895;&#24037;&#20316;&#25552;&#20986;&#23558;&#20855;&#26377;&#37327;&#21270;&#36755;&#20837;&#21644;&#36755;&#20986;&#30340;&#31070;&#32463;&#20803;&#30452;&#25509;&#26144;&#23556;&#21040;&#26597;&#25214;&#34920;&#65288;LUTs&#65289;&#20197;&#36827;&#34892;&#30828;&#20214;&#23454;&#29616;&#12290;&#22312;&#36825;&#20123;&#24037;&#20316;&#20013;&#65292;&#31070;&#32463;&#20803;&#30340;&#36793;&#30028;&#19982;LUTs&#30340;&#36793;&#30028;&#37325;&#21512;&#12290;&#25105;&#20204;&#24314;&#35758;&#25918;&#23485;&#36825;&#20123;&#36793;&#30028;&#65292;&#23558;&#25972;&#20010;&#23376;&#32593;&#32476;&#26144;&#23556;&#21040;&#21333;&#20010;LUT&#12290;&#30001;&#20110;&#23376;&#32593;&#32476;&#34987;&#21560;&#25910;&#21040;LUT&#20013;&#65292;&#20998;&#21306;&#20869;&#30340;&#31070;&#32463;&#32593;&#32476;&#25299;&#25169;&#21644;&#31934;&#24230;&#19981;&#20250;&#24433;&#21709;&#29983;&#25104;&#30340;&#26597;&#25214;&#34920;&#30340;&#22823;&#23567;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#22312;&#27599;&#20010;&#20998;&#21306;&#20869;&#20351;&#29992;&#20855;&#26377;&#28014;&#28857;&#31934;&#24230;&#30340;&#20840;&#36830;&#25509;&#23618;&#65292;&#36825;&#20123;&#23618;&#21463;&#30410;&#20110;&#25104;&#20026;&#36890;&#29992;&#20989;&#25968;&#36924;&#36817;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00849v1 Announce Type: cross  Abstract: Field-Programmable Gate Array (FPGA) accelerators have proven successful in handling latency- and resource-critical deep neural network (DNN) inference tasks. Among the most computationally intensive operations in a neural network (NN) is the dot product between the feature and weight vectors. Thus, some previous FPGA acceleration works have proposed mapping neurons with quantized inputs and outputs directly to lookup tables (LUTs) for hardware implementation. In these works, the boundaries of the neurons coincide with the boundaries of the LUTs. We propose relaxing these boundaries and mapping entire sub-networks to a single LUT. As the sub-networks are absorbed within the LUT, the NN topology and precision within a partition do not affect the size of the lookup tables generated. Therefore, we utilize fully connected layers with floating-point precision inside each partition, which benefit from being universal function approximators, 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#22312;&#37329;&#34701;&#39044;&#27979;&#20013;&#25506;&#32034;&#21151;&#33021;&#21644;&#22686;&#24378;&#25968;&#25454;&#32467;&#26500;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#33021;&#22815;&#39044;&#27979;&#25972;&#20010;&#27010;&#29575;&#20998;&#24067;&#24182;&#36827;&#34892;&#38271;&#26399;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#23545;&#20110;&#20934;&#30830;&#39044;&#27979;&#21644;&#20915;&#31574;&#21046;&#23450;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;</title><link>https://arxiv.org/abs/2403.00796</link><description>&lt;p&gt;
&#29992;&#39640;&#26031;&#36807;&#31243;&#22686;&#24378;&#22343;&#20540;&#22238;&#24402;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#65306;&#37329;&#34701;&#39044;&#27979;&#20013;&#30340;&#21151;&#33021;&#21644;&#22686;&#24378;&#25968;&#25454;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
Enhancing Mean-Reverting Time Series Prediction with Gaussian Processes: Functional and Augmented Data Structures in Financial Forecasting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00796
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#22312;&#37329;&#34701;&#39044;&#27979;&#20013;&#25506;&#32034;&#21151;&#33021;&#21644;&#22686;&#24378;&#25968;&#25454;&#32467;&#26500;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#33021;&#22815;&#39044;&#27979;&#25972;&#20010;&#27010;&#29575;&#20998;&#24067;&#24182;&#36827;&#34892;&#38271;&#26399;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#23545;&#20110;&#20934;&#30830;&#39044;&#27979;&#21644;&#20915;&#31574;&#21046;&#23450;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#65288;GPs&#65289;&#26469;&#39044;&#27979;&#20855;&#26377;&#28508;&#22312;&#32467;&#26500;&#30340;&#22343;&#20540;&#22238;&#24402;&#26102;&#38388;&#24207;&#21015;&#65292;&#20351;&#29992;&#30456;&#23545;&#26410;&#34987;&#25506;&#32034;&#30340;&#21151;&#33021;&#21644;&#22686;&#24378;&#25968;&#25454;&#32467;&#26500;&#12290;&#34429;&#28982;&#35768;&#22810;&#20256;&#32479;&#30340;&#39044;&#27979;&#26041;&#27861;&#19987;&#27880;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#30701;&#26399;&#21160;&#24577;&#65292;&#20294;GPs&#25552;&#20379;&#20102;&#28508;&#21147;&#65292;&#19981;&#20165;&#21487;&#20197;&#39044;&#27979;&#24179;&#22343;&#39044;&#27979;&#20540;&#65292;&#36824;&#21487;&#20197;&#39044;&#27979;&#26410;&#26469;&#36712;&#36857;&#19978;&#25972;&#20010;&#27010;&#29575;&#20998;&#24067;&#12290;&#36825;&#22312;&#37329;&#34701;&#29615;&#22659;&#20013;&#29305;&#21035;&#26377;&#30410;&#65292;&#22240;&#20026;&#22914;&#26524;&#19981;&#27491;&#30830;&#30340;&#27874;&#21160;&#29575;&#35780;&#20272;&#23548;&#33268;&#36164;&#26412;&#25439;&#22833;&#65292;&#20165;&#20934;&#30830;&#30340;&#39044;&#27979;&#21487;&#33021;&#19981;&#36275;&#22815;&#12290;&#27492;&#22806;&#65292;&#22312;&#20132;&#26131;&#36873;&#25321;&#20013;&#65292;GPs&#20801;&#35768;&#39044;&#27979;&#22810;&#20010;&#22799;&#26222;&#27604;&#29575;&#65292;&#32771;&#34385;&#20132;&#26131;&#25104;&#26412;&#21518;&#36827;&#34892;&#35843;&#25972;&#65292;&#26377;&#21161;&#20110;&#20915;&#31574;&#12290;&#26412;&#30740;&#31350;&#20013;&#20351;&#29992;&#30340;&#21151;&#33021;&#25968;&#25454;&#34920;&#31034;&#36890;&#36807;&#21033;&#29992;&#36807;&#21435;&#20960;&#24180;&#30340;&#20449;&#24687;&#20351;&#24471;&#21487;&#20197;&#36827;&#34892;&#26356;&#38271;&#26399;&#30340;&#39044;&#27979;&#65292;&#21363;&#20351;&#39044;&#27979;&#33073;&#31163;&#20102;&#24403;&#21069;&#24180;&#20221;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00796v1 Announce Type: cross  Abstract: In this paper, we explore the application of Gaussian Processes (GPs) for predicting mean-reverting time series with an underlying structure, using relatively unexplored functional and augmented data structures. While many conventional forecasting methods concentrate on the short-term dynamics of time series data, GPs offer the potential to forecast not just the average prediction but the entire probability distribution over a future trajectory. This is particularly beneficial in financial contexts, where accurate predictions alone may not suffice if incorrect volatility assessments lead to capital losses. Moreover, in trade selection, GPs allow for the forecasting of multiple Sharpe ratios adjusted for transaction costs, aiding in decision-making. The functional data representation utilized in this study enables longer-term predictions by leveraging information from previous years, even as the forecast moves away from the current year
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#37327;&#23376;&#36817;&#20284;&#20248;&#21270;&#31639;&#27861;&#22312;&#23574;&#23792;&#24352;&#37327;&#27169;&#22411;&#20013;&#30340;&#32479;&#35745;&#20272;&#35745;&#38382;&#39064;&#65292;&#21457;&#29616;&#20102;QAOA&#22312;&#24674;&#22797;&#38408;&#20540;&#26041;&#38754;&#30340;&#21305;&#37197;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#28176;&#36817;&#37325;&#21472;&#20998;&#24067;&#30340;&#27491;&#24358;-&#39640;&#26031;&#23450;&#24459;&#12290;</title><link>https://arxiv.org/abs/2402.19456</link><description>&lt;p&gt;
&#36890;&#36807;&#37327;&#23376;&#36817;&#20284;&#20248;&#21270;&#31639;&#27861;&#22312;&#23574;&#23792;&#24352;&#37327;&#27169;&#22411;&#20013;&#30340;&#32479;&#35745;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Statistical Estimation in the Spiked Tensor Model via the Quantum Approximate Optimization Algorithm
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.19456
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#37327;&#23376;&#36817;&#20284;&#20248;&#21270;&#31639;&#27861;&#22312;&#23574;&#23792;&#24352;&#37327;&#27169;&#22411;&#20013;&#30340;&#32479;&#35745;&#20272;&#35745;&#38382;&#39064;&#65292;&#21457;&#29616;&#20102;QAOA&#22312;&#24674;&#22797;&#38408;&#20540;&#26041;&#38754;&#30340;&#21305;&#37197;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#28176;&#36817;&#37325;&#21472;&#20998;&#24067;&#30340;&#27491;&#24358;-&#39640;&#26031;&#23450;&#24459;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#37327;&#23376;&#36817;&#20284;&#20248;&#21270;&#31639;&#27861;&#65288;QAOA&#65289;&#22312;&#32479;&#35745;&#20272;&#35745;&#38382;&#39064;&#65292;&#21363;&#23574;&#23792;&#24352;&#37327;&#27169;&#22411;&#19978;&#30340;&#34920;&#29616;&#65292;&#35813;&#27169;&#22411;&#22312;&#32463;&#20856;&#24773;&#20917;&#19979;&#23637;&#29616;&#20986;&#32479;&#35745;&#35745;&#31639;&#24046;&#36317;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;1&#27493;QAOA&#30340;&#24369;&#24674;&#22797;&#38408;&#20540;&#19982;1&#27493;&#24352;&#37327;&#24130;&#36845;&#20195;&#30340;&#30456;&#21305;&#37197;&#12290;&#39069;&#22806;&#30340;&#21551;&#21457;&#24335;&#35745;&#31639;&#34920;&#26126;&#65292;&#24403;$p$&#20026;&#19968;&#20010;&#22266;&#23450;&#24120;&#25968;&#26102;&#65292;$p$&#27493;QAOA&#30340;&#24369;&#24674;&#22797;&#38408;&#20540;&#19982;$p$&#27493;&#24352;&#37327;&#24130;&#36845;&#20195;&#30340;&#30456;&#21305;&#37197;&#12290;&#36825;&#36827;&#19968;&#27493;&#24847;&#21619;&#30528;&#36890;&#36807;&#24352;&#37327;&#23637;&#24320;&#30340;&#22810;&#27493;QAOA&#21487;&#20197;&#23454;&#29616;&#32463;&#20856;&#35745;&#31639;&#38408;&#20540;$\Theta(n^{(q-2)/4})$&#65292;&#20294;&#19981;&#20250;&#36229;&#36234;&#23574;&#23792;$q$-&#24352;&#37327;&#30340;&#32463;&#20856;&#35745;&#31639;&#38408;&#20540;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#34920;&#24449;&#20102;$p$&#27493;QAOA&#30340;&#28176;&#36817;&#37325;&#21472;&#20998;&#24067;&#65292;&#21457;&#29616;&#20102;&#36890;&#36807;&#20223;&#30495;&#39564;&#35777;&#30340;&#26377;&#36259;&#30340;&#27491;&#24358;-&#39640;&#26031;&#23450;&#24459;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.19456v1 Announce Type: cross  Abstract: The quantum approximate optimization algorithm (QAOA) is a general-purpose algorithm for combinatorial optimization. In this paper, we analyze the performance of the QAOA on a statistical estimation problem, namely, the spiked tensor model, which exhibits a statistical-computational gap classically. We prove that the weak recovery threshold of $1$-step QAOA matches that of $1$-step tensor power iteration. Additional heuristic calculations suggest that the weak recovery threshold of $p$-step QAOA matches that of $p$-step tensor power iteration when $p$ is a fixed constant. This further implies that multi-step QAOA with tensor unfolding could achieve, but not surpass, the classical computation threshold $\Theta(n^{(q-2)/4})$ for spiked $q$-tensors.   Meanwhile, we characterize the asymptotic overlap distribution for $p$-step QAOA, finding an intriguing sine-Gaussian law verified through simulations. For some $p$ and $q$, the QAOA attains
&lt;/p&gt;</description></item><item><title>&#21487;&#20197;&#30452;&#25509;&#20174;&#24102;&#26377;&#32570;&#22833;&#20540;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#20934;&#30830;&#27169;&#22411;&#65292;&#26500;&#24314;&#20102;&#26816;&#26597;&#25968;&#25454;&#22635;&#20805;&#24517;&#35201;&#24615;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#24182;&#22312;&#19981;&#38656;&#35201;&#22635;&#20805;&#30340;&#24773;&#20917;&#19979;&#36820;&#22238;&#20934;&#30830;&#27169;&#22411;&#65292;&#26174;&#33879;&#20943;&#23569;&#25968;&#25454;&#22635;&#20805;&#25152;&#38656;&#30340;&#26102;&#38388;&#21644;&#31934;&#21147;</title><link>https://arxiv.org/abs/2402.17926</link><description>&lt;p&gt;
&#32479;&#35745;&#23398;&#20064;&#30340;&#30830;&#23450;&#24615;&#21644;&#36817;&#20284;&#30830;&#23450;&#24615;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Certain and Approximately Certain Models for Statistical Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17926
&lt;/p&gt;
&lt;p&gt;
&#21487;&#20197;&#30452;&#25509;&#20174;&#24102;&#26377;&#32570;&#22833;&#20540;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#20934;&#30830;&#27169;&#22411;&#65292;&#26500;&#24314;&#20102;&#26816;&#26597;&#25968;&#25454;&#22635;&#20805;&#24517;&#35201;&#24615;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#24182;&#22312;&#19981;&#38656;&#35201;&#22635;&#20805;&#30340;&#24773;&#20917;&#19979;&#36820;&#22238;&#20934;&#30830;&#27169;&#22411;&#65292;&#26174;&#33879;&#20943;&#23569;&#25968;&#25454;&#22635;&#20805;&#25152;&#38656;&#30340;&#26102;&#38388;&#21644;&#31934;&#21147;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#25968;&#25454;&#36890;&#24120;&#26159;&#19981;&#23436;&#25972;&#30340;&#65292;&#24182;&#19988;&#21253;&#21547;&#32570;&#22833;&#20540;&#12290;&#20026;&#20102;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#20934;&#30830;&#30340;&#27169;&#22411;&#65292;&#29992;&#25143;&#38656;&#35201;&#33457;&#36153;&#22823;&#37327;&#26102;&#38388;&#21644;&#36164;&#28304;&#22635;&#20805;&#21644;&#25214;&#21040;&#32570;&#22833;&#25968;&#25454;&#39033;&#30340;&#27491;&#30830;&#20540;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#23545;&#20110;&#26576;&#20123;&#35757;&#32451;&#25968;&#25454;&#21644;&#30446;&#26631;&#27169;&#22411;&#65292;&#21487;&#20197;&#30452;&#25509;&#20174;&#20855;&#26377;&#32570;&#22833;&#20540;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#20934;&#30830;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#26816;&#26597;&#25968;&#25454;&#22635;&#20805;&#30340;&#24517;&#35201;&#24615;&#65292;&#20197;&#20415;&#22312;&#21508;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#26426;&#22120;&#23398;&#20064;&#33539;&#20363;&#20013;&#23398;&#20064;&#20934;&#30830;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#30340;&#39640;&#25928;&#31639;&#27861;&#26469;&#26816;&#26597;&#27492;&#24517;&#35201;&#24615;&#65292;&#24182;&#22312;&#19981;&#38656;&#35201;&#22635;&#20805;&#30340;&#24773;&#20917;&#19979;&#36820;&#22238;&#20934;&#30830;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#24191;&#27867;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#26174;&#33879;&#20943;&#23569;&#20102;&#25968;&#25454;&#22635;&#20805;&#25152;&#38656;&#30340;&#26102;&#38388;&#21644;&#31934;&#21147;&#65292;&#32780;&#27809;&#26377;&#24102;&#26469;&#30456;&#24403;&#22823;&#30340;&#35745;&#31639;&#24320;&#38144;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17926v1 Announce Type: cross  Abstract: Real-world data is often incomplete and contains missing values. To train accurate models over real-world datasets, users need to spend a substantial amount of time and resources imputing and finding proper values for missing data items. In this paper, we demonstrate that it is possible to learn accurate models directly from data with missing values for certain training data and target models. We propose a unified approach for checking the necessity of data imputation to learn accurate models across various widely-used machine learning paradigms. We build efficient algorithms with theoretical guarantees to check this necessity and return accurate models in cases where imputation is unnecessary. Our extensive experiments indicate that our proposed algorithms significantly reduce the amount of time and effort needed for data imputation without imposing considerable computational overhead.
&lt;/p&gt;</description></item><item><title>RLHF&#22312;&#32771;&#34385;&#37096;&#20998;&#35266;&#23519;&#24615;&#26102;&#21487;&#33021;&#23548;&#33268;&#31574;&#30053;&#27450;&#39575;&#24615;&#22320;&#22840;&#22823;&#24615;&#33021;&#25110;&#36807;&#24230;&#36777;&#25252;&#34892;&#20026;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#25968;&#23398;&#26465;&#20214;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#35686;&#21578;&#19981;&#35201;&#30450;&#30446;&#24212;&#29992;RLHF&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#24773;&#20917;&#19979;&#12290;</title><link>https://arxiv.org/abs/2402.17747</link><description>&lt;p&gt;
&#24403;&#20320;&#30340;AI&#27450;&#39575;&#20320;&#65306;&#22312;&#22870;&#21169;&#23398;&#20064;&#20013;&#20154;&#31867;&#35780;&#20272;&#32773;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#30340;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
When Your AI Deceives You: Challenges with Partial Observability of Human Evaluators in Reward Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17747
&lt;/p&gt;
&lt;p&gt;
RLHF&#22312;&#32771;&#34385;&#37096;&#20998;&#35266;&#23519;&#24615;&#26102;&#21487;&#33021;&#23548;&#33268;&#31574;&#30053;&#27450;&#39575;&#24615;&#22320;&#22840;&#22823;&#24615;&#33021;&#25110;&#36807;&#24230;&#36777;&#25252;&#34892;&#20026;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#25968;&#23398;&#26465;&#20214;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#35686;&#21578;&#19981;&#35201;&#30450;&#30446;&#24212;&#29992;RLHF&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#65288;RLHF&#65289;&#30340;&#36807;&#21435;&#20998;&#26512;&#20551;&#35774;&#20154;&#31867;&#23436;&#20840;&#35266;&#23519;&#21040;&#29615;&#22659;&#12290;&#24403;&#20154;&#31867;&#21453;&#39304;&#20165;&#22522;&#20110;&#37096;&#20998;&#35266;&#23519;&#26102;&#20250;&#21457;&#29983;&#20160;&#20040;&#65311;&#25105;&#20204;&#23545;&#20004;&#31181;&#22833;&#36133;&#24773;&#20917;&#36827;&#34892;&#20102;&#27491;&#24335;&#23450;&#20041;&#65306;&#27450;&#39575;&#21644;&#36807;&#24230;&#36777;&#25252;&#12290;&#36890;&#36807;&#23558;&#20154;&#31867;&#24314;&#27169;&#20026;&#23545;&#36712;&#36857;&#20449;&#24565;&#30340;Boltzmann-&#29702;&#24615;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;RLHF&#20445;&#35777;&#20250;&#23548;&#33268;&#31574;&#30053;&#27450;&#39575;&#24615;&#22320;&#22840;&#22823;&#20854;&#24615;&#33021;&#12289;&#20026;&#20102;&#30041;&#19979;&#21360;&#35937;&#32780;&#36807;&#24230;&#36777;&#25252;&#25110;&#32773;&#20004;&#32773;&#20860;&#32780;&#26377;&#20043;&#30340;&#26465;&#20214;&#12290;&#20026;&#20102;&#24110;&#21161;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25968;&#23398;&#22320;&#21051;&#30011;&#20102;&#29615;&#22659;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#22914;&#20309;&#36716;&#21270;&#20026;&#65288;&#32570;&#20047;&#65289;&#23398;&#21040;&#30340;&#22238;&#25253;&#20989;&#25968;&#20013;&#30340;&#27169;&#31946;&#24615;&#12290;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#32771;&#34385;&#29615;&#22659;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#20351;&#24471;&#22312;&#29702;&#35770;&#19978;&#21487;&#33021;&#24674;&#22797;&#22238;&#25253;&#20989;&#25968;&#21644;&#26368;&#20248;&#31574;&#30053;&#65292;&#32780;&#22312;&#20854;&#20182;&#24773;&#20917;&#19979;&#65292;&#23384;&#22312;&#19981;&#21487;&#20943;&#23569;&#30340;&#27169;&#31946;&#24615;&#12290;&#25105;&#20204;&#35686;&#21578;&#19981;&#35201;&#30450;&#30446;&#24212;&#29992;RLHF&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17747v1 Announce Type: cross  Abstract: Past analyses of reinforcement learning from human feedback (RLHF) assume that the human fully observes the environment. What happens when human feedback is based only on partial observations? We formally define two failure cases: deception and overjustification. Modeling the human as Boltzmann-rational w.r.t. a belief over trajectories, we prove conditions under which RLHF is guaranteed to result in policies that deceptively inflate their performance, overjustify their behavior to make an impression, or both. To help address these issues, we mathematically characterize how partial observability of the environment translates into (lack of) ambiguity in the learned return function. In some cases, accounting for partial observability makes it theoretically possible to recover the return function and thus the optimal policy, while in other cases, there is irreducible ambiguity. We caution against blindly applying RLHF in partially observa
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#21521;&#37327;&#23450;&#20041;&#27880;&#24847;&#21147;&#30340;&#26041;&#27861;&#65292;&#23558;&#26631;&#20934;transformer&#20013;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#20174;&#20108;&#27425;&#26041;&#38477;&#20302;&#21040;&#19982;&#26102;&#38388;&#32447;&#24615;&#30456;&#20851;&#65292;&#34920;&#29616;&#19982;&#26631;&#20934;&#27880;&#24847;&#21147;&#23218;&#32654;&#65292;&#20294;&#20801;&#35768;&#19978;&#19979;&#25991;&#31383;&#21475;&#25193;&#23637;&#21040;&#36828;&#36828;&#36229;&#20986;&#26631;&#20934;&#30340;&#33539;&#22260;&#12290;</title><link>https://arxiv.org/abs/2402.17512</link><description>&lt;p&gt;
Latent Attention for Linear Time Transformers
&lt;/p&gt;
&lt;p&gt;
Latent Attention for Linear Time Transformers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17512
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#21521;&#37327;&#23450;&#20041;&#27880;&#24847;&#21147;&#30340;&#26041;&#27861;&#65292;&#23558;&#26631;&#20934;transformer&#20013;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#20174;&#20108;&#27425;&#26041;&#38477;&#20302;&#21040;&#19982;&#26102;&#38388;&#32447;&#24615;&#30456;&#20851;&#65292;&#34920;&#29616;&#19982;&#26631;&#20934;&#27880;&#24847;&#21147;&#23218;&#32654;&#65292;&#20294;&#20801;&#35768;&#19978;&#19979;&#25991;&#31383;&#21475;&#25193;&#23637;&#21040;&#36828;&#36828;&#36229;&#20986;&#26631;&#20934;&#30340;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;transformer&#20013;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#38543;&#30528;&#24207;&#21015;&#38271;&#24230;&#30340;&#22686;&#21152;&#21576;&#20108;&#27425;&#26041;&#22686;&#38271;&#12290;&#25105;&#20204;&#24341;&#20837;&#19968;&#31181;&#36890;&#36807;&#23450;&#20041;&#28508;&#22312;&#21521;&#37327;&#30340;&#27880;&#24847;&#21147;&#26469;&#23558;&#20854;&#38477;&#20302;&#21040;&#19982;&#26102;&#38388;&#32447;&#24615;&#30456;&#20851;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#36731;&#26494;&#20316;&#20026;&#26631;&#20934;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26367;&#20195;&#21697;&#12290;&#25105;&#20204;&#30340;&#8220;Latte Transformer&#8221;&#27169;&#22411;&#21487;&#29992;&#20110;&#21452;&#21521;&#21644;&#21333;&#21521;&#20219;&#21153;&#65292;&#22240;&#26524;&#29256;&#26412;&#20801;&#35768;&#19968;&#31181;&#22312;&#25512;&#29702;&#35821;&#35328;&#29983;&#25104;&#20219;&#21153;&#20013;&#20869;&#23384;&#21644;&#26102;&#38388;&#39640;&#25928;&#30340;&#36882;&#24402;&#23454;&#29616;&#12290;&#26631;&#20934;transformer&#30340;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#38543;&#30528;&#24207;&#21015;&#38271;&#24230;&#32447;&#24615;&#22686;&#38271;&#65292;&#32780;Latte Transformer&#35745;&#31639;&#19979;&#19968;&#20010;&#26631;&#35760;&#25152;&#38656;&#30340;&#26102;&#38388;&#26159;&#24658;&#23450;&#30340;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#23454;&#35777;&#34920;&#29616;&#21487;&#19982;&#26631;&#20934;&#27880;&#24847;&#21147;&#23218;&#32654;&#65292;&#20294;&#20801;&#35768;&#23558;&#19978;&#19979;&#25991;&#31383;&#21475;&#25193;&#23637;&#21040;&#36828;&#36828;&#36229;&#20986;&#26631;&#20934;&#27880;&#24847;&#21147;&#23454;&#38469;&#21487;&#34892;&#30340;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17512v1 Announce Type: new  Abstract: The time complexity of the standard attention mechanism in a transformer scales quadratically with the length of the sequence. We introduce a method to reduce this to linear scaling with time, based on defining attention via latent vectors. The method is readily usable as a drop-in replacement for the standard attention mechanism. Our "Latte Transformer" model can be implemented for both bidirectional and unidirectional tasks, with the causal version allowing a recurrent implementation which is memory and time-efficient during inference of language generation tasks. Whilst next token prediction scales linearly with the sequence length for a standard transformer, a Latte Transformer requires constant time to compute the next token. The empirical performance of our method is comparable to standard attention, yet allows scaling to context windows much larger than practical in standard attention.
&lt;/p&gt;</description></item><item><title>&#25193;&#25955;&#27169;&#22411;&#22312;&#30740;&#31350;&#25968;&#25454;&#30340;&#20998;&#23618;&#29983;&#25104;&#27169;&#22411;&#20013;&#23637;&#31034;&#20986;&#20102;&#22312;&#38408;&#20540;&#26102;&#38388;&#21457;&#29983;&#30456;&#21464;&#30340;&#29305;&#24615;&#65292;&#36825;&#24433;&#21709;&#20102;&#39640;&#32423;&#29305;&#24449;&#21644;&#20302;&#32423;&#29305;&#24449;&#30340;&#37325;&#24314;&#36807;&#31243;&#12290;</title><link>https://arxiv.org/abs/2402.16991</link><description>&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#20013;&#30340;&#30456;&#21464;&#25581;&#31034;&#20102;&#25968;&#25454;&#30340;&#20998;&#23618;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
A Phase Transition in Diffusion Models Reveals the Hierarchical Nature of Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16991
&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#30740;&#31350;&#25968;&#25454;&#30340;&#20998;&#23618;&#29983;&#25104;&#27169;&#22411;&#20013;&#23637;&#31034;&#20986;&#20102;&#22312;&#38408;&#20540;&#26102;&#38388;&#21457;&#29983;&#30456;&#21464;&#30340;&#29305;&#24615;&#65292;&#36825;&#24433;&#21709;&#20102;&#39640;&#32423;&#29305;&#24449;&#21644;&#20302;&#32423;&#29305;&#24449;&#30340;&#37325;&#24314;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#30495;&#23454;&#25968;&#25454;&#30340;&#32467;&#26500;&#22312;&#25512;&#21160;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#26041;&#38754;&#33267;&#20851;&#37325;&#35201;&#12290;&#33258;&#28982;&#25968;&#25454;&#65292;&#22914;&#22270;&#20687;&#65292;&#34987;&#35748;&#20026;&#26159;&#30001;&#20197;&#23618;&#27425;&#21644;&#32452;&#21512;&#26041;&#24335;&#32452;&#32455;&#30340;&#29305;&#24449;&#32452;&#25104;&#30340;&#65292;&#31070;&#32463;&#32593;&#32476;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#25429;&#25417;&#21040;&#36825;&#20123;&#29305;&#24449;&#12290;&#26368;&#36817;&#30340;&#36827;&#23637;&#26174;&#31034;&#65292;&#25193;&#25955;&#27169;&#22411;&#33021;&#22815;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#22270;&#20687;&#65292;&#26263;&#31034;&#20102;&#23427;&#20204;&#25429;&#25417;&#21040;&#36825;&#31181;&#28508;&#22312;&#32467;&#26500;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#25968;&#25454;&#30340;&#20998;&#23618;&#29983;&#25104;&#27169;&#22411;&#20013;&#30340;&#36825;&#19968;&#29616;&#35937;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#26102;&#38388;$t$&#21518;&#20316;&#29992;&#30340;&#21453;&#21521;&#25193;&#25955;&#36807;&#31243;&#21463;&#21040;&#26576;&#20010;&#38408;&#20540;&#26102;&#38388;&#22788;&#30340;&#30456;&#21464;&#25511;&#21046;&#65292;&#27492;&#26102;&#37325;&#24314;&#39640;&#32423;&#29305;&#24449;&#65288;&#22914;&#22270;&#20687;&#30340;&#31867;&#21035;&#65289;&#30340;&#27010;&#29575;&#31361;&#28982;&#19979;&#38477;&#12290;&#30456;&#21453;&#65292;&#20302;&#32423;&#29305;&#24449;&#65288;&#22914;&#22270;&#20687;&#30340;&#20855;&#20307;&#32454;&#33410;&#65289;&#30340;&#37325;&#24314;&#22312;&#25972;&#20010;&#25193;&#25955;&#36807;&#31243;&#20013;&#24179;&#31283;&#28436;&#21464;&#12290;&#36825;&#19968;&#32467;&#26524;&#26263;&#31034;&#65292;&#22312;&#36229;&#20986;&#36716;&#21464;&#26102;&#38388;&#30340;&#26102;&#21051;&#65292;&#31867;&#21035;&#24050;&#21464;&#21270;&#65292;&#20294;&#26159;&#22522;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16991v1 Announce Type: cross  Abstract: Understanding the structure of real data is paramount in advancing modern deep-learning methodologies. Natural data such as images are believed to be composed of features organised in a hierarchical and combinatorial manner, which neural networks capture during learning. Recent advancements show that diffusion models can generate high-quality images, hinting at their ability to capture this underlying structure. We study this phenomenon in a hierarchical generative model of data. We find that the backward diffusion process acting after a time $t$ is governed by a phase transition at some threshold time, where the probability of reconstructing high-level features, like the class of an image, suddenly drops. Instead, the reconstruction of low-level features, such as specific details of an image, evolves smoothly across the whole diffusion process. This result implies that at times beyond the transition, the class has changed but the gene
&lt;/p&gt;</description></item><item><title>&#38024;&#23545;&#24322;&#24120;&#26816;&#27979;&#31995;&#32479;&#20013;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#38656;&#27714;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#31216;&#20026;&#20132;&#21449;&#19968;&#33268;&#24322;&#24120;&#26816;&#27979;&#65292;&#36890;&#36807;&#26657;&#20934;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#25552;&#20379;&#32479;&#35745;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.16388</link><description>&lt;p&gt;
&#20855;&#26377;&#20132;&#21449;&#19968;&#33268;$p$-&#20540;&#30340;&#24322;&#24120;&#26816;&#27979;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Uncertainty Quantification in Anomaly Detection with Cross-Conformal $p$-Values
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16388
&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#24322;&#24120;&#26816;&#27979;&#31995;&#32479;&#20013;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#38656;&#27714;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#31216;&#20026;&#20132;&#21449;&#19968;&#33268;&#24322;&#24120;&#26816;&#27979;&#65292;&#36890;&#36807;&#26657;&#20934;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#25552;&#20379;&#32479;&#35745;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#21487;&#38752;&#12289;&#21487;&#20449;&#21644;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#30340;&#37325;&#35201;&#24615;&#26085;&#30410;&#22686;&#21152;&#65292;&#23545;&#24322;&#24120;&#26816;&#27979;&#31995;&#32479;&#36827;&#34892;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#35201;&#27714;&#21464;&#24471;&#24840;&#21457;&#37325;&#35201;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26377;&#25928;&#25511;&#21046;&#31867;&#22411;I&#38169;&#35823;&#29575;($\alpha$)&#32780;&#21448;&#19981;&#25439;&#23475;&#31995;&#32479;&#30340;&#32479;&#35745;&#21151;&#29575;($1-\beta$)&#21487;&#20197;&#24314;&#31435;&#20449;&#20219;&#65292;&#24182;&#20943;&#23569;&#19982;&#20551;&#21457;&#29616;&#30456;&#20851;&#30340;&#25104;&#26412;&#65292;&#29305;&#21035;&#26159;&#24403;&#21518;&#32493;&#31243;&#24207;&#26114;&#36149;&#26102;&#12290;&#21033;&#29992;&#31526;&#21512;&#39044;&#27979;&#21407;&#21017;&#30340;&#26041;&#27861;&#26377;&#26395;&#36890;&#36807;&#26657;&#20934;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#20026;&#24322;&#24120;&#26816;&#27979;&#25552;&#20379;&#30456;&#24212;&#30340;&#32479;&#35745;&#20445;&#35777;&#12290;&#35813;&#24037;&#20316;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#24322;&#24120;&#26816;&#27979;&#26694;&#26550;&#65292;&#31216;&#20026;&#20132;&#21449;&#19968;&#33268;&#24322;&#24120;&#26816;&#27979;&#65292;&#24314;&#31435;&#22312;&#20026;&#39044;&#27979;&#20219;&#21153;&#35774;&#35745;&#30340;&#33879;&#21517;&#20132;&#21449;&#19968;&#33268;&#26041;&#27861;&#20043;&#19978;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#20182;&#22635;&#34917;&#20102;&#22312;&#24402;&#32435;&#19968;&#33268;&#24322;&#24120;&#26816;&#27979;&#29615;&#22659;&#20013;&#25193;&#23637;&#20808;&#21069;&#30740;&#31350;&#30340;&#33258;&#28982;&#30740;&#31350;&#31354;&#30333;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16388v1 Announce Type: cross  Abstract: Given the growing significance of reliable, trustworthy, and explainable machine learning, the requirement of uncertainty quantification for anomaly detection systems has become increasingly important. In this context, effectively controlling Type I error rates ($\alpha$) without compromising the statistical power ($1-\beta$) of these systems can build trust and reduce costs related to false discoveries, particularly when follow-up procedures are expensive. Leveraging the principles of conformal prediction emerges as a promising approach for providing respective statistical guarantees by calibrating a model's uncertainty. This work introduces a novel framework for anomaly detection, termed cross-conformal anomaly detection, building upon well-known cross-conformal methods designed for prediction tasks. With that, it addresses a natural research gap by extending previous works in the context of inductive conformal anomaly detection, rel
&lt;/p&gt;</description></item><item><title>&#37319;&#29992;&#32467;&#26500;&#19981;&#21487;&#30693;&#30340;&#32479;&#35745;&#19979;&#30028;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#21452;&#31283;&#20581;&#20272;&#35745;&#22120;&#22312;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#21644;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#26041;&#38754;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;</title><link>https://arxiv.org/abs/2402.14264</link><description>&lt;p&gt;
&#21452;&#31283;&#20581;&#23398;&#20064;&#22312;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#20013;&#30340;&#32467;&#26500;&#19981;&#21487;&#30693;&#24615;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
Structure-agnostic Optimality of Doubly Robust Learning for Treatment Effect Estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14264
&lt;/p&gt;
&lt;p&gt;
&#37319;&#29992;&#32467;&#26500;&#19981;&#21487;&#30693;&#30340;&#32479;&#35745;&#19979;&#30028;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#21452;&#31283;&#20581;&#20272;&#35745;&#22120;&#22312;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#21644;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#26041;&#38754;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#26159;&#22240;&#26524;&#25512;&#26029;&#20013;&#26368;&#26680;&#24515;&#30340;&#38382;&#39064;&#65292;&#24212;&#29992;&#24191;&#27867;&#12290;&#34429;&#28982;&#25991;&#29486;&#20013;&#25552;&#20986;&#20102;&#35768;&#22810;&#20272;&#35745;&#31574;&#30053;&#65292;&#26368;&#36817;&#36824;&#32435;&#20837;&#20102;&#36890;&#29992;&#30340;&#26426;&#22120;&#23398;&#20064;&#20272;&#35745;&#22120;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#26412;&#25991;&#37319;&#29992;&#26368;&#36817;&#24341;&#20837;&#30340;&#32479;&#35745;&#19979;&#30028;&#32467;&#26500;&#19981;&#21487;&#30693;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#23545;&#24178;&#25200;&#20989;&#25968;&#27809;&#26377;&#32467;&#26500;&#24615;&#36136;&#20551;&#35774;&#65292;&#38500;&#20102;&#35775;&#38382;&#40657;&#30418;&#20272;&#35745;&#22120;&#20197;&#36798;&#21040;&#23567;&#35823;&#24046;&#65307;&#24403;&#21482;&#24895;&#24847;&#32771;&#34385;&#20351;&#29992;&#38750;&#21442;&#25968;&#22238;&#24402;&#21644;&#20998;&#31867;&#31070;&#35861;&#20316;&#20026;&#40657;&#30418;&#23376;&#36807;&#31243;&#30340;&#20272;&#35745;&#31574;&#30053;&#26102;&#65292;&#36825;&#19968;&#28857;&#23588;&#20854;&#21560;&#24341;&#20154;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20869;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21452;&#31283;&#20581;&#20272;&#35745;&#22120;&#23545;&#20110;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#21644;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14264v1 Announce Type: cross  Abstract: Average treatment effect estimation is the most central problem in causal inference with application to numerous disciplines. While many estimation strategies have been proposed in the literature, recently also incorporating generic machine learning estimators, the statistical optimality of these methods has still remained an open area of investigation. In this paper, we adopt the recently introduced structure-agnostic framework of statistical lower bounds, which poses no structural properties on the nuisance functions other than access to black-box estimators that attain small errors; which is particularly appealing when one is only willing to consider estimation strategies that use non-parametric regression and classification oracles as a black-box sub-process. Within this framework, we prove the statistical optimality of the celebrated and widely used doubly robust estimators for both the Average Treatment Effect (ATE) and the Avera
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#31232;&#30095;&#35299;&#37322;&#20540;(SEV)&#65292;&#29992;&#20110;&#34913;&#37327;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20915;&#31574;&#31232;&#30095;&#24615;&#12290;&#21363;&#20351;&#27169;&#22411;&#19981;&#26159;&#31232;&#30095;&#30340;&#65292;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;SEV&#30340;&#34913;&#37327;&#19979;&#20173;&#20855;&#26377;&#20302;&#20915;&#31574;&#31232;&#30095;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.09702</link><description>&lt;p&gt;
&#26080;&#38656;&#31232;&#30095;&#27169;&#22411;&#30340;&#31232;&#30095;&#19988;&#20934;&#30830;&#30340;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Sparse and Faithful Explanations Without Sparse Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09702
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#31232;&#30095;&#35299;&#37322;&#20540;(SEV)&#65292;&#29992;&#20110;&#34913;&#37327;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20915;&#31574;&#31232;&#30095;&#24615;&#12290;&#21363;&#20351;&#27169;&#22411;&#19981;&#26159;&#31232;&#30095;&#30340;&#65292;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;SEV&#30340;&#34913;&#37327;&#19979;&#20173;&#20855;&#26377;&#20302;&#20915;&#31574;&#31232;&#30095;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21363;&#20351;&#27169;&#22411;&#19981;&#28385;&#36275;&#20840;&#23616;&#30340;&#31232;&#30095;&#24615;&#65292;&#20915;&#31574;&#20173;&#28982;&#21487;&#20197;&#29992;&#23569;&#37327;&#30340;&#29305;&#24449;&#20934;&#30830;&#22320;&#25551;&#36848;&#12290;&#20363;&#22914;&#65292;&#23545;&#20110;&#26576;&#20154;&#32780;&#35328;&#65292;&#23613;&#31649;&#27809;&#26377;&#20449;&#29992;&#21382;&#21490;&#65292;&#20294;&#30003;&#35831;&#22823;&#31508;&#36151;&#27454;&#21487;&#33021;&#20250;&#34987;&#25298;&#32477;&#65292;&#36825;&#23601;&#24573;&#35270;&#20102;&#19982;&#20854;&#20449;&#29992;&#20215;&#20540;&#30456;&#20851;&#30340;&#20219;&#20309;&#35777;&#25454;&#12290;&#22312;&#26412;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31232;&#30095;&#35299;&#37322;&#20540;&#65288;SEV&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#34913;&#37327;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#31232;&#30095;&#24615;&#30340;&#26032;&#26041;&#27861;&#12290;&#22312;&#20197;&#19978;&#36151;&#27454;&#25298;&#32477;&#30340;&#20363;&#23376;&#20013;&#65292;SEV&#20026;1&#65292;&#22240;&#20026;&#21482;&#38656;&#35201;&#19968;&#20010;&#22240;&#32032;&#26469;&#35299;&#37322;&#20026;&#20160;&#20040;&#36151;&#27454;&#34987;&#25298;&#32477;&#12290;SEV&#26159;&#23545;&#20915;&#31574;&#31232;&#30095;&#24615;&#30340;&#34913;&#37327;&#65292;&#32780;&#19981;&#26159;&#23545;&#25972;&#20307;&#27169;&#22411;&#31232;&#30095;&#24615;&#30340;&#34913;&#37327;&#65292;&#24182;&#19988;&#25105;&#20204;&#33021;&#22815;&#35777;&#26126;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#8212;&#8212;&#21363;&#20351;&#23427;&#20204;&#19981;&#26159;&#31232;&#30095;&#30340;&#8212;&#8212;&#23454;&#38469;&#19978;&#22312;SEV&#30340;&#34913;&#37327;&#19979;&#20855;&#26377;&#20302;&#20915;&#31574;&#31232;&#30095;&#24615;&#12290;SEV&#20351;&#29992;&#36229;&#31435;&#26041;&#20307;&#19978;&#30340;&#31227;&#21160;&#36827;&#34892;&#23450;&#20041;&#65292;&#20351;&#24471;SEV&#33021;&#22815;&#22312;&#21508;&#31181;&#27169;&#22411;&#31867;&#21035;&#19978;&#19968;&#33268;&#22320;&#23450;&#20041;&#65292;&#20854;&#20013;&#31227;&#21160;&#38480;&#21046;&#21453;&#26144;&#20102;&#27169;&#22411;&#30340;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09702v1 Announce Type: new  Abstract: Even if a model is not globally sparse, it is possible for decisions made from that model to be accurately and faithfully described by a small number of features. For instance, an application for a large loan might be denied to someone because they have no credit history, which overwhelms any evidence towards their creditworthiness. In this work, we introduce the Sparse Explanation Value (SEV), a new way of measuring sparsity in machine learning models. In the loan denial example above, the SEV is 1 because only one factor is needed to explain why the loan was denied. SEV is a measure of decision sparsity rather than overall model sparsity, and we are able to show that many machine learning models -- even if they are not sparse -- actually have low decision sparsity, as measured by SEV. SEV is defined using movements over a hypercube, allowing SEV to be defined consistently over various model classes, with movement restrictions reflectin
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#26377;&#38480;&#25968;&#25454;&#37327;&#22238;&#31572;&#31639;&#27861;&#24615;&#33021;&#38382;&#39064;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#35777;&#26126;&#20102;&#40657;&#30418;&#27979;&#35797;&#26041;&#27861;&#26080;&#27861;&#20934;&#30830;&#22238;&#31572;&#31639;&#27861;&#22312;&#19981;&#21516;&#35757;&#32451;&#38598;&#19978;&#30340;&#25972;&#20307;&#24615;&#33021;&#21644;&#29305;&#23450;&#27169;&#22411;&#30340;&#24615;&#33021;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.07388</link><description>&lt;p&gt;
&#26080;&#20551;&#35774;&#27979;&#35797;&#31639;&#27861;&#24615;&#33021;&#30340;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
The Limits of Assumption-free Tests for Algorithm Performance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07388
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#26377;&#38480;&#25968;&#25454;&#37327;&#22238;&#31572;&#31639;&#27861;&#24615;&#33021;&#38382;&#39064;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#35777;&#26126;&#20102;&#40657;&#30418;&#27979;&#35797;&#26041;&#27861;&#26080;&#27861;&#20934;&#30830;&#22238;&#31572;&#31639;&#27861;&#22312;&#19981;&#21516;&#35757;&#32451;&#38598;&#19978;&#30340;&#25972;&#20307;&#24615;&#33021;&#21644;&#29305;&#23450;&#27169;&#22411;&#30340;&#24615;&#33021;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31639;&#27861;&#35780;&#20215;&#21644;&#27604;&#36739;&#26159;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#23398;&#20013;&#22522;&#26412;&#30340;&#38382;&#39064;&#65292;&#19968;&#20010;&#31639;&#27861;&#22312;&#32473;&#23450;&#30340;&#24314;&#27169;&#20219;&#21153;&#20013;&#34920;&#29616;&#22914;&#20309;&#65292;&#21738;&#20010;&#31639;&#27861;&#34920;&#29616;&#26368;&#20339;&#65311;&#35768;&#22810;&#26041;&#27861;&#24050;&#32463;&#24320;&#21457;&#20986;&#26469;&#35780;&#20272;&#31639;&#27861;&#24615;&#33021;&#65292;&#36890;&#24120;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#31574;&#30053;&#65292;&#23558;&#24863;&#20852;&#36259;&#30340;&#31639;&#27861;&#22312;&#19981;&#21516;&#30340;&#25968;&#25454;&#23376;&#38598;&#19978;&#37325;&#26032;&#35757;&#32451;&#65292;&#24182;&#35780;&#20272;&#20854;&#22312;&#30041;&#20986;&#25968;&#25454;&#28857;&#19978;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#24191;&#27867;&#20351;&#29992;&#36825;&#20123;&#31243;&#24207;&#65292;&#20294;&#23545;&#20110;&#36825;&#20123;&#26041;&#27861;&#30340;&#29702;&#35770;&#24615;&#36136;&#23578;&#26410;&#23436;&#20840;&#29702;&#35299;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#22312;&#26377;&#38480;&#30340;&#25968;&#25454;&#37327;&#19979;&#22238;&#31572;&#36825;&#20123;&#38382;&#39064;&#30340;&#19968;&#20123;&#22522;&#26412;&#38480;&#21046;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#21306;&#20998;&#20102;&#20004;&#20010;&#38382;&#39064;: &#31639;&#27861;$A$&#22312;&#22823;&#23567;&#20026;$n$&#30340;&#35757;&#32451;&#38598;&#19978;&#23398;&#20064;&#38382;&#39064;&#26377;&#22810;&#22909;&#65292;&#20197;&#21450;&#22312;&#29305;&#23450;&#22823;&#23567;&#20026;$n$&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#19978;&#36816;&#34892;$A$&#25152;&#20135;&#29983;&#30340;&#29305;&#23450;&#25311;&#21512;&#27169;&#22411;&#26377;&#22810;&#22909;&#65311;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#35777;&#26126;&#65292;&#23545;&#20110;&#20219;&#20309;&#23558;&#31639;&#27861;&#35270;&#20026;&#40657;&#30418;&#30340;&#27979;&#35797;&#26041;&#27861;&#65292;&#26080;&#27861;&#20934;&#30830;&#22320;&#22238;&#31572;&#36825;&#20004;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithm evaluation and comparison are fundamental questions in machine learning and statistics -- how well does an algorithm perform at a given modeling task, and which algorithm performs best? Many methods have been developed to assess algorithm performance, often based around cross-validation type strategies, retraining the algorithm of interest on different subsets of the data and assessing its performance on the held-out data points. Despite the broad use of such procedures, the theoretical properties of these methods are not yet fully understood. In this work, we explore some fundamental limits for answering these questions with limited amounts of data. In particular, we make a distinction between two questions: how good is an algorithm $A$ at the problem of learning from a training set of size $n$, versus, how good is a particular fitted model produced by running $A$ on a particular training data set of size $n$?   Our main results prove that, for any test that treats the algor
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102; Hutchinson &#36857;&#20272;&#35745;&#65288;HTE&#65289;&#65292;&#36890;&#36807;&#23558;&#25972;&#20010; Hessian &#30697;&#38453;&#30340;&#35745;&#31639;&#36716;&#25442;&#20026; Hessian &#30690;&#37327;&#20056;&#31215;&#65288;HVP&#65289;&#65292;&#35299;&#20915;&#20102; PINNs &#22788;&#29702;&#39640;&#32500;&#21644;&#39640;&#38454; PDE &#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2312.14499</link><description>&lt;p&gt;
&#39640;&#32500;&#21644;&#39640;&#38454;&#29289;&#29702;&#21551;&#21457;&#31070;&#32463;&#32593;&#32476;&#30340; Hutchinson &#36857;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Hutchinson Trace Estimation for High-Dimensional and High-Order Physics-Informed Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.14499
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102; Hutchinson &#36857;&#20272;&#35745;&#65288;HTE&#65289;&#65292;&#36890;&#36807;&#23558;&#25972;&#20010; Hessian &#30697;&#38453;&#30340;&#35745;&#31639;&#36716;&#25442;&#20026; Hessian &#30690;&#37327;&#20056;&#31215;&#65288;HVP&#65289;&#65292;&#35299;&#20915;&#20102; PINNs &#22788;&#29702;&#39640;&#32500;&#21644;&#39640;&#38454; PDE &#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2312.14499v2 &#20844;&#21578;&#31867;&#22411;&#65306;&#26367;&#20195;&#20132;&#21449; &#25688;&#35201;&#65306;&#29289;&#29702;&#21551;&#21457;&#31070;&#32463;&#32593;&#32476;&#65288;PINNs&#65289;&#24050;&#34987;&#35777;&#26126;&#22312;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDEs&#65289;&#26041;&#38754;&#38750;&#24120;&#26377;&#25928;&#65292;&#29305;&#21035;&#26159;&#24403;&#19968;&#20123;&#25968;&#25454;&#21487;&#29992;&#26102;&#65292;&#36890;&#36807;&#26080;&#32541;&#34701;&#21512;&#25968;&#25454;&#21644;&#29289;&#29702;&#23398;&#12290;&#28982;&#32780;&#65292;&#23558;PINNs&#25193;&#23637;&#21040;&#39640;&#32500;&#29978;&#33267;&#39640;&#38454;PDE&#22312;&#33258;&#21160;&#24494;&#20998;&#22312;&#27531;&#24046;&#25439;&#22833;&#20013;&#30340;&#35745;&#31639;&#25104;&#26412;&#26041;&#38754;&#36935;&#21040;&#20102;&#37325;&#22823;&#25361;&#25112;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837; Hutchinson &#36857;&#20272;&#35745;&#65288;HTE&#65289;&#26469;&#35299;&#20915;PINNs&#22788;&#29702;&#39640;&#32500;&#21644;&#39640;&#38454;PDE&#30340;&#23616;&#38480;&#24615;&#12290;&#20174;&#31185;&#23398;&#35745;&#31639;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#20108;&#38454;&#39640;&#32500;PDE&#20837;&#25163;&#65292;HTE&#23558;&#25972;&#20010;Hessian&#30697;&#38453;&#30340;&#35745;&#31639;&#36716;&#25442;&#20026;Hessian&#30690;&#37327;&#20056;&#31215;&#65288;HVP&#65289;&#12290;&#36825;&#31181;&#26041;&#27861;&#36890;&#36807; Taylor &#27169;&#24335;&#33258;&#21160;&#24494;&#20998;&#20943;&#36731;&#20102;&#35745;&#31639;&#29942;&#39048;&#65292;&#24182;&#23558;&#20869;&#23384;&#28040;&#32791;&#20174;Hessian&#30697;&#38453;&#20943;&#23569;&#21040;HVP&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;HTE&#25910;&#25947;&#21040;&#25110;&#32773;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.14499v2 Announce Type: replace-cross  Abstract: Physics-Informed Neural Networks (PINNs) have proven effective in solving partial differential equations (PDEs), especially when some data are available by seamlessly blending data and physics. However, extending PINNs to high-dimensional and even high-order PDEs encounters significant challenges due to the computational cost associated with automatic differentiation in the residual loss. Herein, we address the limitations of PINNs in handling high-dimensional and high-order PDEs by introducing Hutchinson Trace Estimation (HTE). Starting with the second-order high-dimensional PDEs ubiquitous in scientific computing, HTE transforms the calculation of the entire Hessian matrix into a Hessian vector product (HVP). This approach alleviates the computational bottleneck via Taylor-mode automatic differentiation and significantly reduces memory consumption from the Hessian matrix to HVP. We further showcase HTE's convergence to the or
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#22238;&#25253;&#20998;&#24067;&#30340;&#26377;&#38480;&#32500;&#22343;&#20540;&#23884;&#20837;&#30340;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#26694;&#26550;&#65292;&#25512;&#23548;&#20986;&#26032;&#31639;&#27861;&#24182;&#23637;&#31034;&#21487;&#19982;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#32467;&#21512;&#65292;&#25552;&#39640;&#34920;&#29616;&#12290;</title><link>https://arxiv.org/abs/2312.07358</link><description>&lt;p&gt;
&#22522;&#20110;&#22343;&#20540;&#23884;&#20837;&#30340;&#20998;&#24067;&#24335;&#36125;&#23572;&#26364;&#31639;&#23376;
&lt;/p&gt;
&lt;p&gt;
Distributional Bellman Operators over Mean Embeddings
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.07358
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#22238;&#25253;&#20998;&#24067;&#30340;&#26377;&#38480;&#32500;&#22343;&#20540;&#23884;&#20837;&#30340;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#26694;&#26550;&#65292;&#25512;&#23548;&#20986;&#26032;&#31639;&#27861;&#24182;&#23637;&#31034;&#21487;&#19982;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#32467;&#21512;&#65292;&#25552;&#39640;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#22238;&#25253;&#20998;&#24067;&#30340;&#26377;&#38480;&#32500;&#22343;&#20540;&#23884;&#20837;&#30340;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#26694;&#26550;&#12290; &#25105;&#20204;&#22522;&#20110;&#36825;&#19968;&#26694;&#26550;&#25512;&#23548;&#20986;&#20102;&#20960;&#31181;&#26032;&#30340;&#21160;&#24577;&#35268;&#21010;&#21644;&#26102;&#24207;&#24046;&#20998;&#23398;&#20064;&#31639;&#27861;&#65292;&#25552;&#20379;&#20102;&#28176;&#36817;&#25910;&#25947;&#29702;&#35770;&#65292;&#24182;&#23545;&#36825;&#20123;&#31639;&#27861;&#22312;&#19968;&#31995;&#21015;&#34920;&#26684;&#20219;&#21153;&#19978;&#30340;&#23454;&#35777;&#34920;&#29616;&#36827;&#34892;&#20102;&#26816;&#39564;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#19982;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30452;&#25509;&#32467;&#21512;&#65292;&#24471;&#21040;&#19968;&#31181;&#26032;&#30340;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#65292;&#35813;&#20195;&#29702;&#22312; Arcade Learning Environment &#19978;&#20248;&#20110;&#22522;&#32447;&#20998;&#24067;&#24335;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.07358v2 Announce Type: replace-cross  Abstract: We propose a novel algorithmic framework for distributional reinforcement learning, based on learning finite-dimensional mean embeddings of return distributions. We derive several new algorithms for dynamic programming and temporal-difference learning based on this framework, provide asymptotic convergence theory, and examine the empirical performance of the algorithms on a suite of tabular tasks. Further, we show that this approach can be straightforwardly combined with deep reinforcement learning, and obtain a new deep RL agent that improves over baseline distributional approaches on the Arcade Learning Environment.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#23398;&#29983;t&#20998;&#24067;&#21644;&#24130;&#20998;&#27495;&#65292;&#25552;&#20986;&#20102;$t^3$VAE&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#26694;&#26550;&#65292;&#20197;&#26356;&#22909;&#22320;&#22788;&#29702;&#37325;&#23614;&#25968;&#25454;&#65292;&#24182;&#25512;&#23548;&#20986;&#26032;&#30340;&#20248;&#21270;&#30446;&#26631;&#12290;</title><link>https://arxiv.org/abs/2312.01133</link><description>&lt;p&gt;
$t^3$-&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65306;&#21033;&#29992;&#23398;&#29983;t&#20998;&#24067;&#21644;&#24130;&#20998;&#27495;&#23398;&#20064;&#37325;&#23614;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
$t^3$-Variational Autoencoder: Learning Heavy-tailed Data with Student's t and Power Divergence
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.01133
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#23398;&#29983;t&#20998;&#24067;&#21644;&#24130;&#20998;&#27495;&#65292;&#25552;&#20986;&#20102;$t^3$VAE&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#26694;&#26550;&#65292;&#20197;&#26356;&#22909;&#22320;&#22788;&#29702;&#37325;&#23614;&#25968;&#25454;&#65292;&#24182;&#25512;&#23548;&#20986;&#26032;&#30340;&#20248;&#21270;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#36890;&#24120;&#37319;&#29992;&#26631;&#20934;&#27491;&#24577;&#20808;&#39564;&#20316;&#20026;&#27010;&#29575;&#28508;&#22312;&#32534;&#30721;&#22120;&#30340;&#27491;&#21017;&#21270;&#22120;&#12290;&#28982;&#32780;&#65292;&#39640;&#26031;&#23614;&#37096;&#24448;&#24448;&#34928;&#20943;&#24471;&#22826;&#24555;&#65292;&#26080;&#27861;&#26377;&#25928;&#23481;&#32435;&#32534;&#30721;&#28857;&#65292;&#26080;&#27861;&#20445;&#30041;&#25968;&#25454;&#20013;&#38544;&#34255;&#30340;&#20851;&#38190;&#32467;&#26500;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#20351;&#29992;&#37325;&#23614;&#27169;&#22411;&#26469;&#25269;&#25239;&#36807;&#24230;&#27491;&#21017;&#21270;&#30340;&#26041;&#27861;&#12290;&#20511;&#37492;&#20449;&#24687;&#20960;&#20309;&#30340;&#35265;&#35299;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;$t^3$VAE&#65292;&#19968;&#31181;&#20462;&#25913;&#21518;&#30340;VAE&#26694;&#26550;&#65292;&#23427;&#23558;&#23398;&#29983;t&#20998;&#24067;&#32467;&#21512;&#21040;&#20808;&#39564;&#12289;&#32534;&#30721;&#22120;&#21644;&#35299;&#30721;&#22120;&#20013;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#20010;&#24130;&#24418;&#24335;&#30340;&#32852;&#21512;&#27169;&#22411;&#20998;&#24067;&#65292;&#25105;&#20204;&#35748;&#20026;&#36825;&#21487;&#20197;&#26356;&#22909;&#22320;&#25311;&#21512;&#30495;&#23454;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#36890;&#36807;&#37325;&#26032;&#34920;&#36798;&#35777;&#25454;&#19979;&#30028;&#20026;&#20004;&#20010;&#32479;&#35745;&#27969;&#24418;&#20043;&#38388;KL&#25955;&#24230;&#30340;&#32852;&#21512;&#20248;&#21270;&#65292;&#23558;&#20854;&#26367;&#25442;&#20026;$\gamma$-&#24130;&#20998;&#27495;&#65292;&#36825;&#26159;&#24130;&#26063;&#30340;&#19968;&#20010;&#33258;&#28982;&#26367;&#20195;&#26041;&#27861;&#12290;$t^3$VAE&#23637;&#29616;&#20986;&#21331;&#36234;&#30340;&#20302;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.01133v2 Announce Type: replace-cross  Abstract: The variational autoencoder (VAE) typically employs a standard normal prior as a regularizer for the probabilistic latent encoder. However, the Gaussian tail often decays too quickly to effectively accommodate the encoded points, failing to preserve crucial structures hidden in the data. In this paper, we explore the use of heavy-tailed models to combat over-regularization. Drawing upon insights from information geometry, we propose $t^3$VAE, a modified VAE framework that incorporates Student's t-distributions for the prior, encoder, and decoder. This results in a joint model distribution of a power form which we argue can better fit real-world datasets. We derive a new objective by reformulating the evidence lower bound as joint optimization of KL divergence between two statistical manifolds and replacing with $\gamma$-power divergence, a natural alternative for power families. $t^3$VAE demonstrates superior generation of low-
&lt;/p&gt;</description></item><item><title>&#33258;&#36866;&#24212;&#23454;&#39564;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#21442;&#25968;&#39640;&#25928;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#32622;&#20449;&#24207;&#21015;&#23454;&#29616;&#20102;&#26356;&#32039;&#20945;&#30340;&#25512;&#26029;&#65292;&#20855;&#26377;&#26356;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#12290;</title><link>https://arxiv.org/abs/2311.18274</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#23454;&#39564;&#20013;&#21322;&#21442;&#25968;&#39640;&#25928;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Semiparametric Efficient Inference in Adaptive Experiments
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.18274
&lt;/p&gt;
&lt;p&gt;
&#33258;&#36866;&#24212;&#23454;&#39564;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#21442;&#25968;&#39640;&#25928;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#32622;&#20449;&#24207;&#21015;&#23454;&#29616;&#20102;&#26356;&#32039;&#20945;&#30340;&#25512;&#26029;&#65292;&#20855;&#26377;&#26356;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#38382;&#39064;&#65292;&#21363;&#22312;&#19968;&#20010;&#39034;&#24207;&#23454;&#39564;&#20013;&#65292;&#27835;&#30103;&#25928;&#24212;&#30340;&#39640;&#25928;&#25512;&#26029;&#65292;&#20854;&#20013;&#20027;&#23548;&#23558;&#21463;&#35797;&#39564;&#23545;&#35937;&#20998;&#37197;&#32473;&#27835;&#30103;&#25110;&#23545;&#29031;&#32452;&#30340;&#31574;&#30053;&#21487;&#20197;&#38543;&#26102;&#38388;&#21464;&#21270;&#12290;&#25105;&#20204;&#39318;&#20808;&#20026;&#33258;&#36866;&#24212;&#22686;&#24378;&#21453;&#21521;&#27010;&#29575;&#21152;&#26435;&#20272;&#35745;&#22120;&#25552;&#20379;&#20102;&#19968;&#20010;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65292;&#35813;&#20272;&#35745;&#22120;&#22312;&#25991;&#29486;&#20013;&#30340;&#20551;&#35774;&#27604;&#20197;&#24448;&#26356;&#24369;&#12290;&#35813;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#20351;&#24471;&#22312;&#22266;&#23450;&#26679;&#26412;&#37327;&#19979;&#36827;&#34892;&#39640;&#25928;&#25512;&#26029;&#25104;&#20026;&#21487;&#33021;&#12290;&#25105;&#20204;&#38543;&#21518;&#32771;&#34385;&#20102;&#39034;&#24207;&#25512;&#26029;&#35774;&#23450;&#65292;&#25512;&#23548;&#20986;&#26082;&#21253;&#21547;&#28176;&#36817;&#24615;&#36136;&#21448;&#21253;&#21547;&#38750;&#28176;&#36817;&#24615;&#36136;&#30340;&#32622;&#20449;&#24207;&#21015;&#65292;&#36825;&#20123;&#24207;&#21015;&#26126;&#26174;&#27604;&#20197;&#21069;&#30340;&#26041;&#27861;&#26356;&#32039;&#20945;&#12290;&#36825;&#20123;&#20219;&#24847;&#26377;&#25928;&#30340;&#26041;&#27861;&#20351;&#24471;&#33021;&#22815;&#22312;&#25968;&#25454;&#30456;&#20851;&#30340;&#20572;&#27490;&#26102;&#38388;&#65288;&#26679;&#26412;&#37327;&#65289;&#19979;&#36827;&#34892;&#25512;&#26029;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#26368;&#36817;&#30340;&#31163;&#32447;&#31574;&#30053;&#20272;&#35745;&#25991;&#29486;&#20013;&#30340;&#20542;&#21521;&#20998;&#25968;&#25130;&#26029;&#25216;&#26415;&#65292;&#20197;&#38477;&#20302;&#20272;&#35745;&#22120;&#30340;&#26377;&#38480;&#26679;&#26412;&#26041;&#24046;&#32780;&#19981;&#24433;&#21709;&#20854;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.18274v3 Announce Type: replace-cross  Abstract: We consider the problem of efficient inference of the Average Treatment Effect in a sequential experiment where the policy governing the assignment of subjects to treatment or control can change over time. We first provide a central limit theorem for the Adaptive Augmented Inverse-Probability Weighted estimator, which is semiparametric efficient, under weaker assumptions than those previously made in the literature. This central limit theorem enables efficient inference at fixed sample sizes. We then consider a sequential inference setting, deriving both asymptotic and nonasymptotic confidence sequences that are considerably tighter than previous methods. These anytime-valid methods enable inference under data-dependent stopping times (sample sizes). Additionally, we use propensity score truncation techniques from the recent off-policy estimation literature to reduce the finite sample variance of our estimator without affecting
&lt;/p&gt;</description></item><item><title>&#23637;&#31034;&#20102;&#26925;&#22278;&#23545;&#31216;&#20998;&#24067;&#28151;&#21512;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#19968;&#33268;&#24615;&#65292;&#20026;&#22522;&#20110;&#38750;&#21442;&#25968;&#20998;&#24067;&#30340;&#32858;&#31867;&#25552;&#20379;&#20102;&#29702;&#35770;&#20381;&#25454;&#12290;</title><link>https://arxiv.org/abs/2311.06108</link><description>&lt;p&gt;
&#22522;&#20110;&#26925;&#22278;&#23545;&#31216;&#20998;&#24067;&#28151;&#21512;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#21644;&#32858;&#31867;&#30340;&#38750;&#21442;&#25968;&#19968;&#33268;&#24615;
&lt;/p&gt;
&lt;p&gt;
Nonparametric consistency for maximum likelihood estimation and clustering based on mixtures of elliptically-symmetric distributions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.06108
&lt;/p&gt;
&lt;p&gt;
&#23637;&#31034;&#20102;&#26925;&#22278;&#23545;&#31216;&#20998;&#24067;&#28151;&#21512;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#19968;&#33268;&#24615;&#65292;&#20026;&#22522;&#20110;&#38750;&#21442;&#25968;&#20998;&#24067;&#30340;&#32858;&#31867;&#25552;&#20379;&#20102;&#29702;&#35770;&#20381;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#23637;&#31034;&#20102;&#26925;&#22278;&#23545;&#31216;&#20998;&#24067;&#28151;&#21512;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#23545;&#20854;&#24635;&#20307;&#29256;&#26412;&#30340;&#19968;&#33268;&#24615;&#65292;&#20854;&#20013;&#28508;&#22312;&#20998;&#24067;P&#26159;&#38750;&#21442;&#25968;&#30340;&#65292;&#24182;&#19981;&#19968;&#23450;&#23646;&#20110;&#20272;&#35745;&#22120;&#25152;&#22522;&#20110;&#30340;&#28151;&#21512;&#31867;&#21035;&#12290;&#24403;P&#26159;&#36275;&#22815;&#20998;&#31163;&#20294;&#38750;&#21442;&#25968;&#30340;&#20998;&#24067;&#28151;&#21512;&#26102;&#65292;&#34920;&#26126;&#20102;&#20272;&#35745;&#22120;&#30340;&#24635;&#20307;&#29256;&#26412;&#30340;&#32452;&#20998;&#23545;&#24212;&#20110;P&#30340;&#33391;&#22909;&#20998;&#31163;&#32452;&#20998;&#12290;&#36825;&#20026;&#22312;P&#20855;&#26377;&#33391;&#22909;&#20998;&#31163;&#23376;&#24635;&#20307;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;&#36825;&#26679;&#30340;&#20272;&#35745;&#22120;&#36827;&#34892;&#32858;&#31867;&#20998;&#26512;&#25552;&#20379;&#20102;&#19968;&#20123;&#29702;&#35770;&#19978;&#30340;&#29702;&#25454;&#65292;&#21363;&#20351;&#36825;&#20123;&#23376;&#24635;&#20307;&#19982;&#28151;&#21512;&#27169;&#22411;&#25152;&#20551;&#35774;&#30340;&#19981;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.06108v2 Announce Type: replace-cross  Abstract: The consistency of the maximum likelihood estimator for mixtures of elliptically-symmetric distributions for estimating its population version is shown, where the underlying distribution $P$ is nonparametric and does not necessarily belong to the class of mixtures on which the estimator is based. In a situation where $P$ is a mixture of well enough separated but nonparametric distributions it is shown that the components of the population version of the estimator correspond to the well separated components of $P$. This provides some theoretical justification for the use of such estimators for cluster analysis in case that $P$ has well separated subpopulations even if these subpopulations differ from what the mixture model assumes.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39640;&#26031;&#36807;&#31243;&#38376;&#25511;&#30340;&#20998;&#23618;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;GPs&#26500;&#24314;&#38376;&#25511;&#20989;&#25968;&#21644;&#19987;&#23478;&#65292;&#20248;&#20110;&#20256;&#32479;&#22522;&#20110;&#26641;&#30340;&#27169;&#22411;&#65292;&#21516;&#26102;&#22312;&#22797;&#26434;&#24615;&#36739;&#20302;&#30340;&#24773;&#20917;&#19979;&#34920;&#29616;&#20986;&#33391;&#22909;&#24615;&#33021;&#65292;&#36824;&#25552;&#20379;&#20102;&#28145;&#23618;GPs&#21644;&#28145;&#24230;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>https://arxiv.org/abs/2302.04947</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#38376;&#25511;&#30340;&#20998;&#23618;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Gaussian Process-Gated Hierarchical Mixtures of Experts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.04947
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39640;&#26031;&#36807;&#31243;&#38376;&#25511;&#30340;&#20998;&#23618;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;GPs&#26500;&#24314;&#38376;&#25511;&#20989;&#25968;&#21644;&#19987;&#23478;&#65292;&#20248;&#20110;&#20256;&#32479;&#22522;&#20110;&#26641;&#30340;&#27169;&#22411;&#65292;&#21516;&#26102;&#22312;&#22797;&#26434;&#24615;&#36739;&#20302;&#30340;&#24773;&#20917;&#19979;&#34920;&#29616;&#20986;&#33391;&#22909;&#24615;&#33021;&#65292;&#36824;&#25552;&#20379;&#20102;&#28145;&#23618;GPs&#21644;&#28145;&#24230;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39640;&#26031;&#36807;&#31243;&#38376;&#25511;&#30340;&#20998;&#23618;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#65288;Gaussian Process-Gated Hierarchical Mixtures of Experts&#65292;GPHMEs&#65289;&#12290;&#19982;&#20854;&#20182;&#37319;&#29992;&#36755;&#20837;&#32447;&#24615;&#38376;&#25511;&#27169;&#22411;&#30340;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#37319;&#29992;&#20102;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#65288;GPs&#65289;&#26500;&#24314;&#30340;&#38376;&#25511;&#20989;&#25968;&#12290;&#36825;&#20123;&#36807;&#31243;&#22522;&#20110;&#36755;&#20837;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#38543;&#26426;&#29305;&#24449;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#27169;&#22411;&#20013;&#30340;&#19987;&#23478;&#20063;&#26159;&#29992;GPs&#26500;&#24314;&#30340;&#12290;GPHMEs&#30340;&#20248;&#21270;&#36890;&#36807;&#21464;&#20998;&#25512;&#26029;&#26469;&#23454;&#29616;&#12290;&#25152;&#25552;&#20986;&#30340;GPHMEs&#20855;&#26377;&#20960;&#20010;&#20248;&#28857;&#12290;&#23427;&#20204;&#20248;&#20110;&#22312;&#36755;&#20837;&#31354;&#38388;&#20013;&#23545;&#25968;&#25454;&#36827;&#34892;&#20998;&#21306;&#30340;&#22522;&#20110;&#26641;&#30340;HME&#22522;&#20934;&#65292;&#24182;&#19988;&#33021;&#22815;&#22312;&#20943;&#23569;&#22797;&#26434;&#24615;&#30340;&#21516;&#26102;&#23454;&#29616;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;&#21478;&#19968;&#20010;&#20248;&#28857;&#26159;&#23427;&#20204;&#20026;&#28145;&#23618;GPs&#20197;&#21450;&#26356;&#19968;&#33324;&#30340;&#28145;&#24230;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#25552;&#20379;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;&#25105;&#20204;&#30340;GPHMEs&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#23637;&#29616;&#20102;&#20986;&#33394;&#30340;&#24615;&#33021;&#65292;&#21363;&#20351;&#25968;&#25454;&#35268;&#27169;&#30456;&#24403;&#36866;&#20013;&#20063;&#26159;&#22914;&#27492;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2302.04947v2 Announce Type: replace  Abstract: In this paper, we propose novel Gaussian process-gated hierarchical mixtures of experts (GPHMEs). Unlike other mixtures of experts with gating models linear in the input, our model employs gating functions built with Gaussian processes (GPs). These processes are based on random features that are non-linear functions of the inputs. Furthermore, the experts in our model are also constructed with GPs. The optimization of the GPHMEs is performed by variational inference. The proposed GPHMEs have several advantages. They outperform tree-based HME benchmarks that partition the data in the input space, and they achieve good performance with reduced complexity. Another advantage is the interpretability they provide for deep GPs, and more generally, for deep Bayesian neural networks. Our GPHMEs demonstrate excellent performance for large-scale data sets, even with quite modest sizes.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#29992;&#20110;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#38750;&#20809;&#28369;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#20004;&#31181;&#31639;&#27861;&#65292;&#20998;&#21035;&#20855;&#26377;&#36845;&#20195;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2212.04672</link><description>&lt;p&gt;
Primal Dual Alternating Proximal Gradient&#31639;&#27861;&#29992;&#20110;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#38750;&#20809;&#28369;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Primal Dual Alternating Proximal Gradient Algorithms for Nonsmooth Nonconvex Minimax Problems with Coupled Linear Constraints
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2212.04672
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#29992;&#20110;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#38750;&#20809;&#28369;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#20004;&#31181;&#31639;&#27861;&#65292;&#20998;&#21035;&#20855;&#26377;&#36845;&#20195;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#36817;&#24180;&#26469;&#22312;&#26426;&#22120;&#23398;&#20064;&#12289;&#20449;&#21495;&#22788;&#29702;&#21644;&#35768;&#22810;&#20854;&#20182;&#39046;&#22495;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#38750;&#20809;&#28369;&#38750;&#20984;&#65288;&#24378;&#65289;&#20985;&#21644;&#38750;&#20984;&#32447;&#24615;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#21407;&#22987;&#23545;&#20598;&#20132;&#26367;&#36817;&#31471;&#26799;&#24230;&#65288;PDAPG&#65289;&#31639;&#27861;&#21644;&#21407;&#22987;&#23545;&#20598;&#36817;&#31471;&#26799;&#24230;&#65288;PDPG-L&#65289;&#31639;&#27861;&#65292;&#20998;&#21035;&#29992;&#20110;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#24773;&#20917;&#12290;&#36825;&#20004;&#31181;&#31639;&#27861;&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#35777;&#26126;&#20026; $\mathcal{O}\left( \varepsilon ^{-2} \right)$ &#65288;&#23545;&#24212; $\mathcal{O}\left( \varepsilon ^{-4} \right)$&#65289;&#22312;&#38750;&#20984;&#24378;&#20985; &#65288;&#23545;&#24212;&#38750;&#20984;&#20985;&#65289;&#24773;&#20917;&#19979;&#65292;&#20197;&#21450; $\mathcal{O}\left( \varepsilon ^{-3} \right)$ &#22312;&#38750;&#20984;&#32447;&#24615;&#24773;&#20917;&#19979;&#65292;&#20998;&#21035;&#36798;&#21040; $\varepsilon$-&#31283;&#24577;&#28857;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#23427;&#20204;&#26159;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#31532;&#19968;&#25209;&#20855;&#26377;&#36845;&#20195;&#22797;&#26434;&#24230;&#20445;&#35777;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2212.04672v3 Announce Type: replace-cross  Abstract: Nonconvex minimax problems have attracted wide attention in machine learning, signal processing and many other fields in recent years. In this paper, we propose a primal-dual alternating proximal gradient (PDAPG) algorithm and a primal-dual proximal gradient (PDPG-L) algorithm for solving nonsmooth nonconvex-(strongly) concave and nonconvex-linear minimax problems with coupled linear constraints, respectively. The iteration complexity of the two algorithms are proved to be $\mathcal{O}\left( \varepsilon ^{-2} \right)$ (resp. $\mathcal{O}\left( \varepsilon ^{-4} \right)$) under nonconvex-strongly concave (resp. nonconvex-concave) setting and $\mathcal{O}\left( \varepsilon ^{-3} \right)$ under nonconvex-linear setting to reach an $\varepsilon$-stationary point, respectively. To our knowledge, they are the first two algorithms with iteration complexity guarantees for solving the nonconvex minimax problems with coupled linear const
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#23637;&#31034;&#20102;&#22522;&#20110;&#27169;&#22411;&#30340;&#65288;&#25110;&#8220;&#25554;&#20214;&#8221;&#65289;&#26041;&#27861;&#22312;&#26631;&#31614;&#21270;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#20013;&#23454;&#29616;&#20102;&#26080;&#28903;&#24405;&#25104;&#26412;&#30340;&#26497;&#23567;&#26497;&#20248;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;</title><link>https://arxiv.org/abs/2204.05275</link><description>&lt;p&gt;
&#35299;&#20915;&#27169;&#22411;&#20026;&#22522;&#30784;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Settling the Sample Complexity of Model-Based Offline Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2204.05275
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#23637;&#31034;&#20102;&#22522;&#20110;&#27169;&#22411;&#30340;&#65288;&#25110;&#8220;&#25554;&#20214;&#8221;&#65289;&#26041;&#27861;&#22312;&#26631;&#31614;&#21270;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#20013;&#23454;&#29616;&#20102;&#26080;&#28903;&#24405;&#25104;&#26412;&#30340;&#26497;&#23567;&#26497;&#20248;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#65292;&#23427;&#21033;&#29992;&#39044;&#20808;&#25910;&#38598;&#30340;&#25968;&#25454;&#36827;&#34892;&#23398;&#20064;&#65292;&#26080;&#38656;&#36827;&#19968;&#27493;&#25506;&#32034;&#12290;&#26377;&#25928;&#30340;&#31163;&#32447;RL&#24212;&#33021;&#36866;&#24212;&#20998;&#24067;&#36716;&#31227;&#21644;&#26377;&#38480;&#30340;&#25968;&#25454;&#35206;&#30422;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;&#31639;&#27861;&#25110;&#20998;&#26512;&#35201;&#20040;&#21463;&#21040;&#27425;&#20248;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#22256;&#25200;&#65292;&#35201;&#20040;&#20135;&#29983;&#39640;&#26114;&#30340;&#28903;&#24405;&#25104;&#26412;&#20197;&#36798;&#21040;&#26679;&#26412;&#26368;&#20248;&#24615;&#65292;&#20174;&#32780;&#23545;&#26679;&#26412;&#21294;&#20047;&#24212;&#29992;&#20013;&#30340;&#39640;&#25928;&#31163;&#32447;RL&#26500;&#25104;&#38556;&#30861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2204.05275v3 Announce Type: replace-cross  Abstract: This paper is concerned with offline reinforcement learning (RL), which learns using pre-collected data without further exploration. Effective offline RL would be able to accommodate distribution shift and limited data coverage. However, prior algorithms or analyses either suffer from suboptimal sample complexities or incur high burn-in cost to reach sample optimality, thus posing an impediment to efficient offline RL in sample-starved applications.   We demonstrate that the model-based (or "plug-in") approach achieves minimax-optimal sample complexity without burn-in cost for tabular Markov decision processes (MDPs). Concretely, consider a finite-horizon (resp. $\gamma$-discounted infinite-horizon) MDP with $S$ states and horizon $H$ (resp. effective horizon $\frac{1}{1-\gamma}$), and suppose the distribution shift of data is reflected by some single-policy clipped concentrability coefficient $C^{\star}_{\text{clipped}}$. We p
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#36793;&#24418;&#26410;&#35843;&#25972;&#30340;&#26391;&#20043;&#19975;&#31639;&#27861;&#30340;&#26032;&#31867;&#21035;&#31639;&#27861;&#65292;&#21517;&#20026;TH$\varepsilon$O POULA&#65288;&#25110;&#31616;&#31216;&#20026;TheoPouLa&#65289;&#65292;&#36890;&#36807;&#31283;&#23450;&#24615;&#12289;&#38750;&#28176;&#36827;&#20998;&#26512;&#21644;&#23454;&#39564;&#34920;&#26126;&#20854;&#22312;&#31070;&#32463;&#32593;&#32476;&#20248;&#21270;&#20013;&#20855;&#26377;&#21331;&#36234;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2105.13937</link><description>&lt;p&gt;
&#22810;&#36793;&#24418;&#26410;&#35843;&#25972;&#30340;&#26391;&#20043;&#19975;&#31639;&#27861;&#65306;&#20026;&#31070;&#32463;&#32593;&#32476;&#21019;&#24314;&#31283;&#23450;&#39640;&#25928;&#30340;&#33258;&#36866;&#24212;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Polygonal Unadjusted Langevin Algorithms: Creating stable and efficient adaptive algorithms for neural networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2105.13937
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#36793;&#24418;&#26410;&#35843;&#25972;&#30340;&#26391;&#20043;&#19975;&#31639;&#27861;&#30340;&#26032;&#31867;&#21035;&#31639;&#27861;&#65292;&#21517;&#20026;TH$\varepsilon$O POULA&#65288;&#25110;&#31616;&#31216;&#20026;TheoPouLa&#65289;&#65292;&#36890;&#36807;&#31283;&#23450;&#24615;&#12289;&#38750;&#28176;&#36827;&#20998;&#26512;&#21644;&#23454;&#39564;&#34920;&#26126;&#20854;&#22312;&#31070;&#32463;&#32593;&#32476;&#20248;&#21270;&#20013;&#20855;&#26377;&#21331;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#26391;&#20043;&#19975;&#31639;&#27861;&#30340;&#31639;&#27861;&#31867;&#21035;&#65292;&#20811;&#26381;&#20102;&#24403;&#21069;&#29992;&#20110;&#24494;&#35843;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#27969;&#34892;&#33258;&#36866;&#24212;&#20248;&#21270;&#22120;&#30340;&#35768;&#22810;&#24050;&#30693;&#32570;&#38519;&#12290;&#20854;&#29702;&#35770;&#22522;&#30784;&#20381;&#36182;&#20110;&#36817;&#26399;&#23545;&#20110;&#20855;&#26377;&#21333;&#35843;&#31995;&#25968;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDEs&#65289;&#30340;&#27431;&#25289;&#22810;&#36793;&#24418;&#36924;&#36817;&#30340;&#21457;&#23637;&#12290;&#22240;&#27492;&#65292;&#23427;&#32487;&#25215;&#20102;&#28201;&#21644;&#31639;&#27861;&#30340;&#31283;&#23450;&#24615;&#29305;&#24615;&#65292;&#21516;&#26102;&#35299;&#20915;&#20102;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20854;&#20182;&#24050;&#30693;&#38382;&#39064;&#65292;&#20363;&#22914;&#26799;&#24230;&#28040;&#22833;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23545;&#36825;&#20010;&#26032;&#31867;&#21035;&#31639;&#27861;&#30340;&#25910;&#25947;&#29305;&#24615;&#36827;&#34892;&#20102;&#38750;&#28176;&#36827;&#20998;&#26512;&#21644;&#20840;&#38754;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#31639;&#27861;&#21629;&#21517;&#20026;TH$\varepsilon$O POULA&#65288;&#25110;&#31616;&#31216;&#20026;TheoPouLa&#65289;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#19981;&#21516;&#31867;&#22411;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#30340;&#20960;&#20010;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;TheoPouLa&#30456;&#23545;&#20110;&#35768;&#22810;&#27969;&#34892;&#30340;&#33258;&#36866;&#24212;&#20248;&#21270;&#31639;&#27861;&#20855;&#26377;&#21331;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2105.13937v3 Announce Type: replace  Abstract: We present a new class of Langevin based algorithms, which overcomes many of the known shortcomings of popular adaptive optimizers that are currently used for the fine tuning of deep learning models. Its underpinning theory relies on recent advances of Euler's polygonal approximations for stochastic differential equations (SDEs) with monotone coefficients. As a result, it inherits the stability properties of tamed algorithms, while it addresses other known issues, e.g. vanishing gradients in neural networks. In particular, we provide a nonasymptotic analysis and full theoretical guarantees for the convergence properties of an algorithm of this novel class, which we named TH$\varepsilon$O POULA (or, simply, TheoPouLa). Finally, several experiments are presented with different types of deep learning models, which show the superior performance of TheoPouLa over many popular adaptive optimization algorithms.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#20445;&#25252;&#20010;&#20154;&#38544;&#31169;&#30340;&#21516;&#26102;&#36820;&#22238;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#39044;&#27979;&#38598;&#12290;</title><link>https://arxiv.org/abs/2102.06202</link><description>&lt;p&gt;
&#31169;&#20154;&#39044;&#27979;&#38598;
&lt;/p&gt;
&lt;p&gt;
Private Prediction Sets
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2102.06202
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#20445;&#25252;&#20010;&#20154;&#38544;&#31169;&#30340;&#21516;&#26102;&#36820;&#22238;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#39044;&#27979;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28041;&#21450;&#37325;&#35201;&#20915;&#31574;&#30340;&#29616;&#23454;&#29615;&#22659;&#20013;&#65292;&#37096;&#32626;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#36890;&#24120;&#38656;&#35201;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#20445;&#25252;&#20010;&#20154;&#38544;&#31169;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#23558;&#36825;&#20004;&#20010;&#30446;&#26631;&#21516;&#26102;&#35270;&#20026;&#37325;&#35201;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#22522;&#20110;&#31526;&#21512;&#24615;&#39044;&#27979;&#65292;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#25193;&#23637;&#39044;&#27979;&#27169;&#22411;&#65292;&#36820;&#22238;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#39044;&#27979;&#38598;&#65292;&#36825;&#20123;&#38598;&#21512;&#21487;&#20197;&#35777;&#26126;&#20197;&#29992;&#25143;&#25351;&#23450;&#30340;&#27010;&#29575;&#65288;&#22914;90%&#65289;&#35206;&#30422;&#30495;&#23454;&#21709;&#24212;&#12290;&#24403;&#19982;&#32463;&#36807;&#31169;&#20154;&#35757;&#32451;&#30340;&#27169;&#22411;&#19968;&#36215;&#20351;&#29992;&#26102;&#65292;&#20154;&#20204;&#21487;&#33021;&#24076;&#26395;&#31526;&#21512;&#24615;&#39044;&#27979;&#20250;&#20026;&#29983;&#25104;&#30340;&#39044;&#27979;&#38598;&#25552;&#20379;&#38544;&#31169;&#20445;&#35777;&#65307;&#19981;&#24184;&#30340;&#26159;&#65292;&#24773;&#20917;&#24182;&#38750;&#22914;&#27492;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#20851;&#38190;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#20174;&#20219;&#20309;&#39044;&#20808;&#35757;&#32451;&#30340;&#39044;&#27979;&#27169;&#22411;&#20013;&#36755;&#20986;&#24046;&#20998;&#31169;&#20154;&#39044;&#27979;&#38598;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36981;&#24490;&#20998;&#35010;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#19968;&#33324;&#26041;&#27861;&#65307;&#25105;&#20204;&#20351;&#29992;&#20445;&#30041;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
arXiv:2102.06202v3 Announce Type: replace-cross  Abstract: In real-world settings involving consequential decision-making, the deployment of machine learning systems generally requires both reliable uncertainty quantification and protection of individuals' privacy. We present a framework that treats these two desiderata jointly. Our framework is based on conformal prediction, a methodology that augments predictive models to return prediction sets that provide uncertainty quantification -- they provably cover the true response with a user-specified probability, such as 90%. One might hope that when used with privately-trained models, conformal prediction would yield privacy guarantees for the resulting prediction sets; unfortunately, this is not the case. To remedy this key problem, we develop a method that takes any pre-trained predictive model and outputs differentially private prediction sets. Our method follows the general approach of split conformal prediction; we use holdout data 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#29992;&#20110;&#23545;&#36793;&#32536;&#38598;&#21512;&#19978;&#30340;&#20989;&#25968;&#36827;&#34892;&#24314;&#27169;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;Hodge&#20998;&#35299;&#24320;&#21457;&#20102;&#36866;&#29992;&#20110;&#19981;&#21516;&#24212;&#29992;&#22330;&#26223;&#30340;&#26080;&#25955;&#24230;&#21644;&#26080;&#26059;&#24230;&#30340;&#39640;&#26031;&#36807;&#31243;&#65292;&#24182;&#36890;&#36807;&#32452;&#21512;&#23427;&#20204;&#26469;&#34920;&#31034;&#20219;&#24847;&#36793;&#32536;&#20989;&#25968;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#36825;&#31181;&#26041;&#27861;&#22312;&#27969;&#21160;&#25968;&#25454;&#25512;&#26029;&#20013;&#20855;&#26377;&#28508;&#22312;&#30340;&#23454;&#38469;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2310.19450</link><description>&lt;p&gt;
Hodge-Compositional &#36793;&#32536;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Hodge-Compositional Edge Gaussian Processes. (arXiv:2310.19450v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19450
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#29992;&#20110;&#23545;&#36793;&#32536;&#38598;&#21512;&#19978;&#30340;&#20989;&#25968;&#36827;&#34892;&#24314;&#27169;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;Hodge&#20998;&#35299;&#24320;&#21457;&#20102;&#36866;&#29992;&#20110;&#19981;&#21516;&#24212;&#29992;&#22330;&#26223;&#30340;&#26080;&#25955;&#24230;&#21644;&#26080;&#26059;&#24230;&#30340;&#39640;&#26031;&#36807;&#31243;&#65292;&#24182;&#36890;&#36807;&#32452;&#21512;&#23427;&#20204;&#26469;&#34920;&#31034;&#20219;&#24847;&#36793;&#32536;&#20989;&#25968;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#36825;&#31181;&#26041;&#27861;&#22312;&#27969;&#21160;&#25968;&#25454;&#25512;&#26029;&#20013;&#20855;&#26377;&#28508;&#22312;&#30340;&#23454;&#38469;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36793;&#32536;&#38598;&#21512;&#30340;2-&#22797;&#24418;&#32467;&#26500;&#65288;&#31867;&#20284;&#20110;&#22270;&#24418;&#65292;&#20854;&#20013;&#36793;&#32536;&#21487;&#24418;&#25104;&#19977;&#35282;&#38754;&#65289;&#30340;&#20989;&#25968;&#24314;&#27169;&#30340;&#26377;&#21407;&#21017;&#30340;&#39640;&#26031;&#36807;&#31243;&#65288;GPs&#65289;&#12290;&#36825;&#31181;&#26041;&#27861;&#36866;&#29992;&#20110;&#23398;&#20064;&#32593;&#32476;&#19978;&#30340;&#27969;&#21160;&#31867;&#22411;&#25968;&#25454;&#65292;&#20854;&#20013;&#36793;&#32536;&#27969;&#21487;&#20197;&#36890;&#36807;&#31163;&#25955;&#30340;&#25955;&#24230;&#21644;&#26059;&#24230;&#26469;&#34920;&#24449;&#12290;&#20511;&#37492;Hodge&#20998;&#35299;&#65292;&#25105;&#20204;&#39318;&#20808;&#24320;&#21457;&#20102;&#36866;&#29992;&#20110;&#21508;&#31181;&#24212;&#29992;&#30340;&#26080;&#25955;&#24230;&#21644;&#26080;&#26059;&#28216;&#30340;&#36793;&#32536;GPs&#12290;&#28982;&#21518;&#23558;&#23427;&#20204;&#32452;&#21512;&#36215;&#26469;&#21019;&#24314;Hodge-&#32452;&#21512;&#36793;&#32536;GPs&#65292;&#36825;&#20123;GPs&#36275;&#22815;&#34920;&#36798;&#20219;&#20309;&#36793;&#32536;&#20989;&#25968;&#12290;&#36825;&#20123;GPs&#20415;&#20110;&#23545;&#36793;&#32536;&#20989;&#25968;&#30340;&#19981;&#21516;Hodge&#20998;&#37327;&#36827;&#34892;&#30452;&#25509;&#21644;&#29420;&#31435;&#30340;&#23398;&#20064;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;&#36229;&#21442;&#25968;&#20248;&#21270;&#36807;&#31243;&#20013;&#25429;&#25417;&#23427;&#20204;&#30340;&#30456;&#20851;&#24615;&#12290;&#20026;&#20102;&#31361;&#26174;&#23427;&#20204;&#30340;&#23454;&#38469;&#28508;&#21147;&#65292;&#25105;&#20204;&#23558;&#23427;&#20204;&#24212;&#29992;&#20110;&#36135;&#24065;&#20817;&#25442;&#12289;&#28023;&#27915;&#27969;&#21160;&#21644;&#20379;&#27700;&#32593;&#32476;&#20013;&#30340;&#27969;&#21160;&#25968;&#25454;&#25512;&#26029;&#65292;&#24182;&#23558;&#20854;&#19982;&#26367;&#20195;&#27169;&#22411;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose principled Gaussian processes (GPs) for modeling functions defined over the edge set of a simplicial 2-complex, a structure similar to a graph in which edges may form triangular faces. This approach is intended for learning flow-type data on networks where edge flows can be characterized by the discrete divergence and curl. Drawing upon the Hodge decomposition, we first develop classes of divergence-free and curl-free edge GPs, suitable for various applications. We then combine them to create \emph{Hodge-compositional edge GPs} that are expressive enough to represent any edge function. These GPs facilitate direct and independent learning for the different Hodge components of edge functions, enabling us to capture their relevance during hyperparameter optimization. To highlight their practical potential, we apply them for flow data inference in currency exchange, ocean flows and water supply networks, comparing them to alternative models.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#25805;&#20316;&#21592;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#36138;&#23146;&#31639;&#27861;&#36873;&#25321;&#33258;&#36866;&#24212;&#28857;&#23545;&#39044;&#35757;&#32451;&#30340;&#36817;&#20284;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#65292;&#36880;&#28176;&#20943;&#23569;&#24314;&#27169;&#35823;&#24046;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22312;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#65292;&#26377;&#21161;&#20110;&#26377;&#25928;&#35299;&#20915;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#20013;&#30340;&#35745;&#31639;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.17844</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#25805;&#20316;&#21592;&#23398;&#20064;&#29992;&#20110;&#26080;&#38480;&#32500;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Adaptive operator learning for infinite-dimensional Bayesian inverse problems. (arXiv:2310.17844v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17844
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#25805;&#20316;&#21592;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#36138;&#23146;&#31639;&#27861;&#36873;&#25321;&#33258;&#36866;&#24212;&#28857;&#23545;&#39044;&#35757;&#32451;&#30340;&#36817;&#20284;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#65292;&#36880;&#28176;&#20943;&#23569;&#24314;&#27169;&#35823;&#24046;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22312;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#65292;&#26377;&#21161;&#20110;&#26377;&#25928;&#35299;&#20915;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#20013;&#30340;&#35745;&#31639;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;(BIPs)&#20013;&#30340;&#22522;&#26412;&#35745;&#31639;&#38382;&#39064;&#28304;&#20110;&#38656;&#35201;&#37325;&#22797;&#36827;&#34892;&#27491;&#21521;&#27169;&#22411;&#35780;&#20272;&#30340;&#35201;&#27714;&#12290;&#20943;&#23569;&#36825;&#31181;&#25104;&#26412;&#30340;&#19968;&#31181;&#24120;&#35265;&#31574;&#30053;&#26159;&#36890;&#36807;&#25805;&#20316;&#21592;&#23398;&#20064;&#20351;&#29992;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#36817;&#20284;&#26041;&#27861;&#26367;&#20195;&#26114;&#36149;&#30340;&#27169;&#22411;&#27169;&#25311;&#65292;&#36825;&#21463;&#21040;&#20102;&#28145;&#24230;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#30340;&#21551;&#21457;&#12290;&#28982;&#32780;&#65292;&#30452;&#25509;&#20351;&#29992;&#36817;&#20284;&#27169;&#22411;&#21487;&#33021;&#24341;&#20837;&#24314;&#27169;&#35823;&#24046;&#65292;&#21152;&#21095;&#20102;&#36870;&#38382;&#39064;&#24050;&#32463;&#23384;&#22312;&#30340;&#30149;&#24577;&#24615;&#12290;&#22240;&#27492;&#65292;&#22312;&#26377;&#25928;&#23454;&#26045;&#36825;&#20123;&#26041;&#27861;&#20013;&#65292;&#24179;&#34913;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#33258;&#36866;&#24212;&#25805;&#20316;&#21592;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#36890;&#36807;&#24378;&#21046;&#22312;&#23616;&#37096;&#21306;&#22495;&#20013;&#20934;&#30830;&#25311;&#21512;&#30340;&#20195;&#29702;&#36880;&#28176;&#20943;&#23569;&#24314;&#27169;&#35823;&#24046;&#12290;&#36825;&#26159;&#36890;&#36807;&#20351;&#29992;&#36138;&#23146;&#31639;&#27861;&#36873;&#25321;&#30340;&#33258;&#36866;&#24212;&#28857;&#22312;&#21453;&#28436;&#36807;&#31243;&#20013;&#23545;&#39044;&#35757;&#32451;&#30340;&#36817;&#20284;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#26469;&#23454;&#29616;&#30340;&#65292;&#35813;&#31639;&#27861;&#21482;&#38656;&#35201;&#23569;&#37327;&#30340;&#27491;&#21521;&#27169;&#22411;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
The fundamental computational issues in Bayesian inverse problems (BIPs) governed by partial differential equations (PDEs) stem from the requirement of repeated forward model evaluations. A popular strategy to reduce such cost is to replace expensive model simulations by computationally efficient approximations using operator learning, motivated by recent progresses in deep learning. However, using the approximated model directly may introduce a modeling error, exacerbating the already ill-posedness of inverse problems. Thus, balancing between accuracy and efficiency is essential for the effective implementation of such approaches. To this end, we develop an adaptive operator learning framework that can reduce modeling error gradually by forcing the surrogate to be accurate in local areas. This is accomplished by fine-tuning the pre-trained approximate model during the inversion process with adaptive points selected by a greedy algorithm, which requires only a few forward model evaluat
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36864;&#28779;&#65288;&#38024;&#23545;&#39034;&#24207;&#33945;&#29305;&#21345;&#32599;; SMC&#65289;&#21644;&#29109;&#38236;&#20687;&#19979;&#38477;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#35777;&#26126;&#20102;&#36864;&#28779;SMC&#26159;&#24212;&#29992;&#20110;Kullback-Leibler&#65288;KL&#65289;&#25955;&#24230;&#30340;&#29109;&#38236;&#20687;&#19979;&#38477;&#30340;&#25968;&#20540;&#36817;&#20284;&#65292;&#24182;&#25552;&#20986;&#20102;&#25913;&#36827;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2310.11914</link><description>&lt;p&gt;
&#36864;&#28779;&#21644;&#29109;&#38236;&#20687;&#19979;&#38477;&#20043;&#38388;&#30340;&#32852;&#31995;
&lt;/p&gt;
&lt;p&gt;
A connection between Tempering and Entropic Mirror Descent. (arXiv:2310.11914v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11914
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36864;&#28779;&#65288;&#38024;&#23545;&#39034;&#24207;&#33945;&#29305;&#21345;&#32599;; SMC&#65289;&#21644;&#29109;&#38236;&#20687;&#19979;&#38477;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#35777;&#26126;&#20102;&#36864;&#28779;SMC&#26159;&#24212;&#29992;&#20110;Kullback-Leibler&#65288;KL&#65289;&#25955;&#24230;&#30340;&#29109;&#38236;&#20687;&#19979;&#38477;&#30340;&#25968;&#20540;&#36817;&#20284;&#65292;&#24182;&#25552;&#20986;&#20102;&#25913;&#36827;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#36864;&#28779;&#65288;&#38024;&#23545;&#39034;&#24207;&#33945;&#29305;&#21345;&#32599;; SMC&#65289;&#21644;&#29109;&#38236;&#20687;&#19979;&#38477;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#20197;&#20174;&#24050;&#30693;&#26410;&#24402;&#19968;&#21270;&#27010;&#29575;&#23494;&#24230;&#30340;&#30446;&#26631;&#27010;&#29575;&#20998;&#24067;&#20013;&#37319;&#26679;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36864;&#28779;SMC&#26159;&#24212;&#29992;&#20110;Kullback-Leibler&#65288;KL&#65289;&#25955;&#24230;&#30340;&#29109;&#38236;&#20687;&#19979;&#38477;&#30340;&#25968;&#20540;&#36817;&#20284;&#65292;&#24182;&#33719;&#24471;&#20102;&#36864;&#28779;&#36845;&#20195;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20174;&#20248;&#21270;&#35282;&#24230;&#25512;&#21160;&#20102;&#36864;&#28779;&#36845;&#20195;&#65292;&#34920;&#26126;&#36864;&#28779;&#21487;&#20197;&#29992;&#20316;Langevin&#31639;&#27861;&#30340;&#26367;&#20195;&#36873;&#25321;&#65292;&#20197;&#26368;&#23567;&#21270;KL&#25955;&#24230;&#12290;&#25105;&#20204;&#21033;&#29992;&#36864;&#28779;&#21644;&#38236;&#20687;&#19979;&#38477;&#36845;&#20195;&#20043;&#38388;&#30340;&#32852;&#31995;&#26469;&#35777;&#26126;SMC&#20013;&#24120;&#35265;&#30340;&#20570;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#25991;&#29486;&#20013;&#31639;&#27861;&#30340;&#25913;&#36827;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores the connections between tempering (for Sequential Monte Carlo; SMC) and entropic mirror descent to sample from a target probability distribution whose unnormalized density is known.  We establish that tempering SMC is a numerical approximation of entropic mirror descent applied to the Kullback-Leibler (KL) divergence and obtain convergence rates for the tempering iterates.  Our result motivates the tempering iterates from an optimization point of view, showing that tempering can be used as an alternative to Langevin-based algorithms to minimize the KL divergence.  We exploit the connection between tempering and mirror descent iterates to justify common practices in SMC and propose improvements to algorithms in literature.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25216;&#26415;&#65292;&#36890;&#36807;&#37325;&#26032;&#23450;&#20041;&#20248;&#21270;&#36807;&#31243;&#20026;&#38024;&#23545;&#26131;&#20110;&#35745;&#31639;&#33258;&#28982;&#26799;&#24230;&#30340;&#26367;&#20195;&#20998;&#24067;&#30340;&#21442;&#25968;&#20248;&#21270;&#26469;&#35299;&#20915;&#35745;&#31639;&#33258;&#28982;&#26799;&#24230;&#30340;&#25361;&#25112;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25193;&#23637;&#21487;&#24212;&#29992;&#33258;&#28982;&#26799;&#24230;&#30340;&#20998;&#24067;&#33539;&#22260;&#65292;&#36895;&#24230;&#24555;&#19988;&#26131;&#20110;&#23454;&#29616;&#12290;</title><link>http://arxiv.org/abs/2310.11837</link><description>&lt;p&gt;
&#20351;&#29992;&#33258;&#28982;&#26799;&#24230;&#26367;&#20195;&#21697;&#20248;&#21270;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Optimising Distributions with Natural Gradient Surrogates. (arXiv:2310.11837v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11837
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25216;&#26415;&#65292;&#36890;&#36807;&#37325;&#26032;&#23450;&#20041;&#20248;&#21270;&#36807;&#31243;&#20026;&#38024;&#23545;&#26131;&#20110;&#35745;&#31639;&#33258;&#28982;&#26799;&#24230;&#30340;&#26367;&#20195;&#20998;&#24067;&#30340;&#21442;&#25968;&#20248;&#21270;&#26469;&#35299;&#20915;&#35745;&#31639;&#33258;&#28982;&#26799;&#24230;&#30340;&#25361;&#25112;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25193;&#23637;&#21487;&#24212;&#29992;&#33258;&#28982;&#26799;&#24230;&#30340;&#20998;&#24067;&#33539;&#22260;&#65292;&#36895;&#24230;&#24555;&#19988;&#26131;&#20110;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#28982;&#26799;&#24230;&#26041;&#27861;&#24050;&#32463;&#34987;&#29992;&#20110;&#20248;&#21270;&#21508;&#31181;&#24773;&#20917;&#19979;&#30340;&#27010;&#29575;&#20998;&#24067;&#21442;&#25968;&#65292;&#36890;&#24120;&#33021;&#24471;&#21040;&#24555;&#36895;&#25910;&#25947;&#30340;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#35768;&#22810;&#24863;&#20852;&#36259;&#30340;&#20998;&#24067;&#65292;&#35745;&#31639;&#33258;&#28982;&#26799;&#24230;&#23384;&#22312;&#19968;&#20123;&#25361;&#25112;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25216;&#26415;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#36825;&#28041;&#21450;&#23558;&#20248;&#21270;&#37325;&#26032;&#23450;&#20041;&#20026;&#20851;&#20110;&#26367;&#20195;&#20998;&#24067;&#21442;&#25968;&#30340;&#20248;&#21270;&#65292;&#35745;&#31639;&#33258;&#28982;&#26799;&#24230;&#24456;&#23481;&#26131;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#20960;&#20010;&#21487;&#20197;&#35299;&#37322;&#20026;&#24212;&#29992;&#36825;&#31181;&#25216;&#26415;&#30340;&#29616;&#26377;&#26041;&#27861;&#30340;&#20363;&#23376;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#20854;&#24212;&#29992;&#20110;&#21508;&#31181;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25193;&#23637;&#20102;&#21487;&#20197;&#26377;&#25928;&#20351;&#29992;&#33258;&#28982;&#26799;&#24230;&#30340;&#20998;&#24067;&#38598;&#21512;&#12290;&#27492;&#22806;&#65292;&#23427;&#24555;&#36895;&#12289;&#26131;&#20110;&#29702;&#35299;&#65292;&#21487;&#20197;&#20351;&#29992;&#26631;&#20934;&#30340;&#33258;&#21160;&#24494;&#20998;&#36719;&#20214;&#36827;&#34892;&#31616;&#21333;&#23454;&#29616;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#20887;&#38271;&#30340;&#27169;&#22411;&#29305;&#23450;&#23548;&#25968;&#35745;&#31639;&#12290;&#25105;&#20204;&#22312;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#21644;&#21464;&#20998;&#25512;&#26029;&#19978;&#28436;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Natural gradient methods have been used to optimise the parameters of probability distributions in a variety of settings, often resulting in fast-converging procedures. Unfortunately, for many distributions of interest, computing the natural gradient has a number of challenges. In this work we propose a novel technique for tackling such issues, which involves reframing the optimisation as one with respect to the parameters of a surrogate distribution, for which computing the natural gradient is easy. We give several examples of existing methods that can be interpreted as applying this technique, and propose a new method for applying it to a wide variety of problems. Our method expands the set of distributions that can be efficiently targeted with natural gradients. Furthermore, it is fast, easy to understand, simple to implement using standard autodiff software, and does not require lengthy model-specific derivations. We demonstrate our method on maximum likelihood estimation and varia
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22122;&#22768;&#33410;&#28857;&#26631;&#31614;&#20316;&#20026;&#39069;&#22806;&#33410;&#28857;&#20449;&#24687;&#30340;&#23616;&#37096;&#22270;&#32858;&#31867;&#26041;&#27861;&#65292;&#24182;&#25506;&#31350;&#20102;&#23558;&#22122;&#22768;&#26631;&#31614;&#32435;&#20837;&#23616;&#37096;&#22270;&#32858;&#31867;&#30340;&#22909;&#22788;&#12290;</title><link>http://arxiv.org/abs/2310.08031</link><description>&lt;p&gt;
&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#23616;&#37096;&#22270;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Local Graph Clustering with Noisy Labels. (arXiv:2310.08031v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08031
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22122;&#22768;&#33410;&#28857;&#26631;&#31614;&#20316;&#20026;&#39069;&#22806;&#33410;&#28857;&#20449;&#24687;&#30340;&#23616;&#37096;&#22270;&#32858;&#31867;&#26041;&#27861;&#65292;&#24182;&#25506;&#31350;&#20102;&#23558;&#22122;&#22768;&#26631;&#31614;&#32435;&#20837;&#23616;&#37096;&#22270;&#32858;&#31867;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#65292;&#23545;&#20110;&#24102;&#26377;&#39069;&#22806;&#33410;&#28857;&#20449;&#24687;&#65288;&#22914;&#25991;&#26412;&#12289;&#22270;&#20687;&#25110;&#26631;&#31614;&#65289;&#30340;&#22270;&#24418;&#30340;&#22686;&#21152;&#20852;&#36259;&#65292;&#20419;&#20351;&#20102;&#38656;&#35201;&#32791;&#36153;&#22823;&#37327;&#36164;&#28304;&#22788;&#29702;&#25972;&#20010;&#22270;&#24418;&#30340;&#26041;&#27861;&#30340;&#27969;&#34892;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#20174;&#36825;&#26679;&#30340;&#25968;&#25454;&#20013;&#25552;&#21462;&#26377;&#29992;&#20449;&#24687;&#30340;&#24555;&#36895;&#23616;&#37096;&#26041;&#27861;&#65288;&#21363;&#19981;&#38656;&#35201;&#35775;&#38382;&#25972;&#20010;&#22270;&#24418;&#65289;&#30340;&#21457;&#23637;&#36824;&#24456;&#23569;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#29992;&#22122;&#22768;&#33410;&#28857;&#26631;&#31614;&#20316;&#20026;&#39069;&#22806;&#33410;&#28857;&#20449;&#24687;&#30340;&#23616;&#37096;&#22270;&#32858;&#31867;&#30340;&#30740;&#31350;&#12290;&#22312;&#36825;&#31181;&#35774;&#32622;&#19979;&#65292;&#33410;&#28857;&#26681;&#25454;&#25152;&#23646;&#31751;&#30340;&#32852;&#23646;&#20851;&#31995;&#25509;&#25910;&#21021;&#22987;&#20108;&#36827;&#21046;&#26631;&#31614;&#65306;&#22914;&#26524;&#23427;&#20204;&#23646;&#20110;&#30446;&#26631;&#31751;&#65292;&#21017;&#20026;1&#65307;&#21542;&#21017;&#20026;0&#12290;&#38543;&#21518;&#65292;&#36825;&#20123;&#26631;&#31614;&#30340;&#19968;&#37096;&#20998;&#20250;&#34987;&#32763;&#36716;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#23558;&#22122;&#22768;&#26631;&#31614;&#32435;&#20837;&#23616;&#37096;&#22270;&#32858;&#31867;&#30340;&#22909;&#22788;&#12290;&#36890;&#36807;&#26500;&#24314;&#24102;&#26377;&#36825;&#20123;&#26631;&#31614;&#30340;&#21152;&#26435;&#22270;&#24418;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#22270;&#25193;&#25955;&#30340;&#23616;&#37096;&#32858;&#31867;&#26041;&#27861;&#22312;&#21407;&#22987;&#22270;&#24418;&#21644;&#21152;&#26435;&#22270;&#24418;&#19978;&#30340;&#24615;&#33021;&#12290;&#20174;&#29702;&#35770;&#35282;&#24230;&#20986;&#21457;&#65292;
&lt;/p&gt;
&lt;p&gt;
The growing interest in machine learning problems over graphs with additional node information such as texts, images, or labels has popularized methods that require the costly operation of processing the entire graph. Yet, little effort has been made to the development of fast local methods (i.e. without accessing the entire graph) that extract useful information from such data. To that end, we propose a study of local graph clustering using noisy node labels as a proxy for additional node information. In this setting, nodes receive initial binary labels based on cluster affiliation: 1 if they belong to the target cluster and 0 otherwise. Subsequently, a fraction of these labels is flipped. We investigate the benefits of incorporating noisy labels for local graph clustering. By constructing a weighted graph with such labels, we study the performance of graph diffusion-based local clustering method on both the original and the weighted graphs. From a theoretical perspective, we consider
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;Orlicz&#21518;&#24724;&#26041;&#27861;&#65292;&#29992;&#20110;&#19968;&#33268;&#22320;&#30028;&#23450;&#38543;&#26426;&#21464;&#37327;&#30340;&#32479;&#35745;&#37327;&#19978;&#19979;&#30028;&#65292;&#36890;&#36807;&#28789;&#27963;&#35780;&#20272;&#38543;&#26426;&#21464;&#37327;&#30340;&#23614;&#34892;&#20026;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#65292;&#27492;&#26041;&#27861;&#37319;&#29992;&#20102;&#19968;&#33268;&#24615;&#35780;&#20272;&#65292;&#24182;&#24471;&#21040;&#20102;&#23558;&#20854;&#19982;&#21457;&#25955;&#39118;&#38505;&#24230;&#37327;&#31561;&#25928;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2310.05168</link><description>&lt;p&gt;
Orlicz&#21518;&#24724;&#32479;&#19968;&#36793;&#30028;&#38543;&#26426;&#21464;&#37327;&#32479;&#35745;&#30340;&#26041;&#27861;&#21450;&#20854;&#22312;&#29615;&#22659;&#25351;&#26631;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Orlicz regrets to consistently bound statistics of random variables with an application to environmental indicators. (arXiv:2310.05168v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05168
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;Orlicz&#21518;&#24724;&#26041;&#27861;&#65292;&#29992;&#20110;&#19968;&#33268;&#22320;&#30028;&#23450;&#38543;&#26426;&#21464;&#37327;&#30340;&#32479;&#35745;&#37327;&#19978;&#19979;&#30028;&#65292;&#36890;&#36807;&#28789;&#27963;&#35780;&#20272;&#38543;&#26426;&#21464;&#37327;&#30340;&#23614;&#34892;&#20026;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#65292;&#27492;&#26041;&#27861;&#37319;&#29992;&#20102;&#19968;&#33268;&#24615;&#35780;&#20272;&#65292;&#24182;&#24471;&#21040;&#20102;&#23558;&#20854;&#19982;&#21457;&#25955;&#39118;&#38505;&#24230;&#37327;&#31561;&#25928;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#38543;&#26426;&#21464;&#37327;&#30340;&#32479;&#35745;&#35780;&#20272;&#26159;&#35774;&#35745;&#26356;&#22909;&#30340;&#29615;&#22659;&#31649;&#29702;&#21644;&#24674;&#22797;&#26041;&#26696;&#30340;&#20027;&#35201;&#35758;&#39064;&#12290;&#23545;&#20110;&#27700;&#36136;&#25351;&#26631;&#12289;&#27946;&#28061;&#21644;&#24178;&#26097;&#27700;&#20301;&#31561;&#36825;&#20123;&#21464;&#37327;&#30340;&#19978;&#19979;&#30028;&#20272;&#35745;&#37117;&#24456;&#37325;&#35201;&#65292;&#24212;&#24403;&#22312;&#19968;&#20010;&#32479;&#19968;&#30340;&#25968;&#23398;&#26694;&#26550;&#20013;&#36827;&#34892;&#19968;&#33268;&#30340;&#35780;&#20272;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;Orlicz&#21518;&#24724;&#26041;&#27861;&#65292;&#29992;&#20110;&#19968;&#33268;&#22320;&#30028;&#23450;&#38543;&#26426;&#21464;&#37327;&#30340;&#32479;&#35745;&#37327;&#19978;&#19979;&#30028;&#12290;&#36825;&#37324;&#30340;&#19968;&#33268;&#24615;&#25351;&#30340;&#26159;&#19978;&#30028;&#21644;&#19979;&#30028;&#20351;&#29992;&#30456;&#21516;&#30340;&#31995;&#25968;&#21644;&#21442;&#25968;&#20540;&#36827;&#34892;&#35780;&#20272;&#65292;&#19982;&#36804;&#20170;&#20026;&#27490;&#25552;&#20986;&#30340;&#26576;&#20123;&#39118;&#38505;&#24230;&#37327;&#19981;&#21516;&#12290;Orlicz&#21518;&#24724;&#33021;&#22815;&#26681;&#25454;&#38543;&#26426;&#21464;&#37327;&#30340;&#23614;&#34892;&#20026;&#28789;&#27963;&#22320;&#35780;&#20272;&#20854;&#32479;&#35745;&#37327;&#12290;&#25105;&#20204;&#36890;&#36807;&#26126;&#30830;&#22320;&#23558;Orlicz&#21518;&#24724;&#19982;&#21457;&#25955;&#39118;&#38505;&#24230;&#37327;&#32852;&#31995;&#36215;&#26469;&#65292;&#20197;&#26356;&#22909;&#22320;&#29702;&#35299;&#23427;&#20204;&#12290;&#25105;&#20204;&#24471;&#21040;&#20102;&#23558;Orlicz&#21518;&#24724;&#21644;&#21457;&#25955;&#39118;&#38505;&#24230;&#37327;&#31561;&#25928;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evaluating environmental variables that vary stochastically is the principal topic for designing better environmental management and restoration schemes. Both the upper and lower estimates of these variables, such as water quality indices and flood and drought water levels, are important and should be consistently evaluated within a unified mathematical framework. We propose a novel pair of Orlicz regrets to consistently bound the statistics of random variables both from below and above. Here, consistency indicates that the upper and lower bounds are evaluated with common coefficients and parameter values being different from some of the risk measures proposed thus far. Orlicz regrets can flexibly evaluate the statistics of random variables based on their tail behavior. The explicit linkage between Orlicz regrets and divergence risk measures was exploited to better comprehend them. We obtain sufficient conditions to pose the Orlicz regrets as well as divergence risk measures, and furth
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#31216;&#20026;&#38750;&#20809;&#28369;&#24369;&#20984;&#26377;&#38480;&#21644;&#32806;&#21512;&#32452;&#21512;&#20248;&#21270;(NSWC FCCO)&#65292;&#36890;&#36807;&#25193;&#23637;&#24050;&#26377;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38750;&#20809;&#28369;&#24369;&#20984;FCCO&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#31639;&#27861;&#26469;&#25214;&#21040;Moreau&#29615;&#30340;&#949;-&#31283;&#23450;&#28857;&#12290;</title><link>http://arxiv.org/abs/2310.03234</link><description>&lt;p&gt;
&#38750;&#20809;&#28369;&#24369;&#20984;&#26377;&#38480;&#21644;&#32806;&#21512;&#32452;&#21512;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Non-Smooth Weakly-Convex Finite-sum Coupled Compositional Optimization. (arXiv:2310.03234v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03234
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#31216;&#20026;&#38750;&#20809;&#28369;&#24369;&#20984;&#26377;&#38480;&#21644;&#32806;&#21512;&#32452;&#21512;&#20248;&#21270;(NSWC FCCO)&#65292;&#36890;&#36807;&#25193;&#23637;&#24050;&#26377;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38750;&#20809;&#28369;&#24369;&#20984;FCCO&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#31639;&#27861;&#26469;&#25214;&#21040;Moreau&#29615;&#30340;&#949;-&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#26032;&#30340;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#31216;&#20026;&#38750;&#20809;&#28369;&#24369;&#20984;&#26377;&#38480;&#21644;&#32806;&#21512;&#32452;&#21512;&#20248;&#21270;(NSWC FCCO)&#12290;&#30001;&#20110;&#20854;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#30340;&#24191;&#27867;&#24212;&#29992;&#20197;&#21450;&#20854;&#35299;&#20915;&#22522;&#20110;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#38543;&#26426;&#31639;&#27861;&#30340;&#23616;&#38480;&#24615;&#65292;FCCO&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23545;&#20110;FCCO&#30340;&#30740;&#31350;&#20551;&#35774;&#20869;&#22806;&#20989;&#25968;&#37117;&#26159;&#20809;&#28369;&#30340;&#65292;&#38480;&#21046;&#20102;&#20854;&#33021;&#22815;&#35299;&#20915;&#26356;&#22810;&#31181;&#31867;&#30340;&#38382;&#39064;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#20174;&#38750;&#20809;&#28369;&#24369;&#20984;FCCO&#30340;&#35282;&#24230;&#36827;&#34892;&#20102;&#25193;&#23637;&#65292;&#20854;&#20013;&#22806;&#20989;&#25968;&#26159;&#24369;&#20984;&#19988;&#38750;&#36882;&#20943;&#30340;&#65292;&#20869;&#20989;&#25968;&#26159;&#24369;&#20984;&#30340;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#31639;&#27861;&#65292;&#24182;&#30830;&#23450;&#20854;&#22312;&#25214;&#21040;Moreau&#29615;&#30340;&#949;-&#31283;&#23450;&#28857;&#30340;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates new families of compositional optimization problems, called $\underline{\bf n}$on-$\underline{\bf s}$mooth $\underline{\bf w}$eakly-$\underline{\bf c}$onvex $\underline{\bf f}$inite-sum $\underline{\bf c}$oupled $\underline{\bf c}$ompositional $\underline{\bf o}$ptimization (NSWC FCCO). There has been a growing interest in FCCO due to its wide-ranging applications in machine learning and AI, as well as its ability to address the shortcomings of stochastic algorithms based on empirical risk minimization. However, current research on FCCO presumes that both the inner and outer functions are smooth, limiting their potential to tackle a more diverse set of problems. Our research expands on this area by examining non-smooth weakly-convex FCCO, where the outer function is weakly convex and non-decreasing, and the inner function is weakly-convex. We analyze a single-loop algorithm and establish its complexity for finding an $\epsilon$-stationary point of the Moreau env
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#32479;&#35745;&#26816;&#39564;&#21644;&#32858;&#31867;&#31639;&#27861;&#30340;&#20248;&#21270;Mapper&#22270;&#35206;&#30422;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20998;&#21106;&#35206;&#30422;&#36873;&#25321;&#29983;&#25104;&#20102;&#20445;&#30041;&#25968;&#25454;&#38598;&#26412;&#36136;&#30340;Mapper&#22270;&#12290;</title><link>http://arxiv.org/abs/2309.06634</link><description>&lt;p&gt;
$G$-Mapper&#65306;&#23398;&#20064;Mapper&#26500;&#36896;&#20013;&#30340;&#35206;&#30422;
&lt;/p&gt;
&lt;p&gt;
$G$-Mapper: Learning a Cover in the Mapper Construction. (arXiv:2309.06634v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06634
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#32479;&#35745;&#26816;&#39564;&#21644;&#32858;&#31867;&#31639;&#27861;&#30340;&#20248;&#21270;Mapper&#22270;&#35206;&#30422;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20998;&#21106;&#35206;&#30422;&#36873;&#25321;&#29983;&#25104;&#20102;&#20445;&#30041;&#25968;&#25454;&#38598;&#26412;&#36136;&#30340;Mapper&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Mapper&#31639;&#27861;&#26159;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;(TDA)&#20013;&#19968;&#31181;&#21453;&#26144;&#32473;&#23450;&#25968;&#25454;&#38598;&#32467;&#26500;&#30340;&#21487;&#35270;&#21270;&#25216;&#26415;&#12290;Mapper&#31639;&#27861;&#38656;&#35201;&#35843;&#25972;&#22810;&#20010;&#21442;&#25968;&#20197;&#29983;&#25104;&#19968;&#20010;"&#22909;&#30475;&#30340;"Mapper&#22270;&#12290;&#35813;&#35770;&#25991;&#20851;&#27880;&#20110;&#36873;&#25321;&#35206;&#30422;&#21442;&#25968;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26681;&#25454;&#27491;&#24577;&#24615;&#30340;&#32479;&#35745;&#26816;&#39564;&#21453;&#22797;&#20998;&#21106;&#35206;&#30422;&#26469;&#20248;&#21270;Mapper&#22270;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22522;&#20110;$G$-means&#32858;&#31867;&#65292;&#36890;&#36807;&#36845;&#20195;&#22320;&#36827;&#34892;Anderson-Darling&#26816;&#39564;&#26469;&#23547;&#25214;$k$-means&#20013;&#26368;&#20339;&#30340;&#31751;&#25968;&#12290;&#25105;&#20204;&#30340;&#20998;&#21106;&#36807;&#31243;&#21033;&#29992;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65292;&#26681;&#25454;&#32473;&#23450;&#25968;&#25454;&#30340;&#20998;&#24067;&#31934;&#24515;&#36873;&#25321;&#35206;&#30422;&#12290;&#23545;&#20110;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#29983;&#25104;&#30340;&#35206;&#30422;&#20351;Mapper&#22270;&#20445;&#30041;&#20102;&#25968;&#25454;&#38598;&#30340;&#26412;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Mapper algorithm is a visualization technique in topological data analysis (TDA) that outputs a graph reflecting the structure of a given dataset. The Mapper algorithm requires tuning several parameters in order to generate a "nice" Mapper graph. The paper focuses on selecting the cover parameter. We present an algorithm that optimizes the cover of a Mapper graph by splitting a cover repeatedly according to a statistical test for normality. Our algorithm is based on $G$-means clustering which searches for the optimal number of clusters in $k$-means by conducting iteratively the Anderson-Darling test. Our splitting procedure employs a Gaussian mixture model in order to choose carefully the cover based on the distribution of a given data. Experiments for synthetic and real-world datasets demonstrate that our algorithm generates covers so that the Mapper graphs retain the essence of the datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#39640;&#25928;&#38543;&#26426;&#20122;&#24403;&#26041;&#27861;SA-Solver&#65292;&#29992;&#20110;&#35299;&#25193;&#25955;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20197;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#23427;&#22312;&#23569;&#27493;&#37319;&#26679;&#20013;&#30456;&#36739;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#26377;&#25913;&#36827;&#25110;&#21487;&#27604;&#30340;&#24615;&#33021;&#65292;&#24182;&#36798;&#21040;&#20102;SOTA FID&#20998;&#25968;&#12290;</title><link>http://arxiv.org/abs/2309.05019</link><description>&lt;p&gt;
SA-Solver&#65306;&#29992;&#20110;&#24555;&#36895;&#37319;&#26679;&#25193;&#25955;&#27169;&#22411;&#30340;&#38543;&#26426;&#20122;&#24403;&#27714;&#35299;&#22120;
&lt;/p&gt;
&lt;p&gt;
SA-Solver: Stochastic Adams Solver for Fast Sampling of Diffusion Models. (arXiv:2309.05019v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05019
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#39640;&#25928;&#38543;&#26426;&#20122;&#24403;&#26041;&#27861;SA-Solver&#65292;&#29992;&#20110;&#35299;&#25193;&#25955;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20197;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#23427;&#22312;&#23569;&#27493;&#37319;&#26679;&#20013;&#30456;&#36739;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#26377;&#25913;&#36827;&#25110;&#21487;&#27604;&#30340;&#24615;&#33021;&#65292;&#24182;&#36798;&#21040;&#20102;SOTA FID&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#22312;&#29983;&#25104;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#30456;&#24403;&#22823;&#30340;&#25104;&#21151;&#12290;&#30001;&#20110;&#20174;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#20013;&#36827;&#34892;&#37319;&#26679;&#30456;&#24403;&#20110;&#35299;&#25193;&#25955;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#25110;&#24120;&#24494;&#20998;&#26041;&#31243;&#65292;&#36825;&#26159;&#19968;&#39033;&#32791;&#26102;&#30340;&#24037;&#20316;&#65292;&#22240;&#27492;&#25552;&#20986;&#20102;&#35768;&#22810;&#22522;&#20110;&#25913;&#36827;&#30340;&#24494;&#20998;&#26041;&#31243;&#27714;&#35299;&#22120;&#30340;&#24555;&#36895;&#37319;&#26679;&#26041;&#27861;&#12290;&#36825;&#20123;&#25216;&#26415;&#20013;&#30340;&#22823;&#37096;&#20998;&#26041;&#27861;&#37117;&#32771;&#34385;&#35299;&#25193;&#25955;&#24120;&#24494;&#20998;&#26041;&#31243;&#65292;&#22240;&#20026;&#23427;&#20855;&#26377;&#26356;&#22909;&#30340;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#38543;&#26426;&#37319;&#26679;&#21487;&#20197;&#22312;&#29983;&#25104;&#22810;&#26679;&#21270;&#21644;&#39640;&#36136;&#37327;&#25968;&#25454;&#26041;&#38754;&#25552;&#20379;&#39069;&#22806;&#30340;&#20248;&#21183;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20174;&#20004;&#20010;&#26041;&#38754;&#36827;&#34892;&#20102;&#23545;&#38543;&#26426;&#37319;&#26679;&#30340;&#32508;&#21512;&#20998;&#26512;&#65306;&#26041;&#24046;&#25511;&#21046;&#30340;&#25193;&#25955;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#21644;&#32447;&#24615;&#22810;&#27493;&#25193;&#25955;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#27714;&#35299;&#22120;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;SA-Solver&#65292;&#23427;&#26159;&#19968;&#31181;&#25913;&#36827;&#30340;&#39640;&#25928;&#38543;&#26426;&#20122;&#24403;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#25193;&#25955;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20197;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;SA-Solver&#23454;&#29616;&#20102;&#65306;1&#65289;&#22312;&#23569;&#27493;&#37319;&#26679;&#20013;&#19982;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#26041;&#27861;&#30456;&#27604;&#65292;&#26377;&#25913;&#36827;&#25110;&#21487;&#27604;&#24615;&#33021;&#65307;2&#65289;SOTA FID&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion Probabilistic Models (DPMs) have achieved considerable success in generation tasks. As sampling from DPMs is equivalent to solving diffusion SDE or ODE which is time-consuming, numerous fast sampling methods built upon improved differential equation solvers are proposed. The majority of such techniques consider solving the diffusion ODE due to its superior efficiency. However, stochastic sampling could offer additional advantages in generating diverse and high-quality data. In this work, we engage in a comprehensive analysis of stochastic sampling from two aspects: variance-controlled diffusion SDE and linear multi-step SDE solver. Based on our analysis, we propose SA-Solver, which is an improved efficient stochastic Adams method for solving diffusion SDE to generate data with high quality. Our experiments show that SA-Solver achieves: 1) improved or comparable performance compared with the existing state-of-the-art sampling methods for few-step sampling; 2) SOTA FID scores o
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;&#20989;&#25968;&#24615;&#25688;&#35201;&#26426;&#21046;&#65292;&#36890;&#36807;&#20351;&#29992;&#29420;&#31435;&#20998;&#37327;&#25289;&#26222;&#25289;&#26031;&#36807;&#31243;&#23545;&#26080;&#38480;&#32500;&#30340;&#20989;&#25968;&#24615;&#25688;&#35201;&#36827;&#34892;&#25200;&#21160;&#65292;&#25918;&#23485;&#20102;&#23545;&#25968;&#25454;&#36712;&#36857;&#30340;&#20551;&#35774;&#65292;&#24182;&#30456;&#23545;&#20110;&#20256;&#32479;&#30340;&#26377;&#38480;&#32500;&#23376;&#31354;&#38388;&#23884;&#20837;&#26041;&#27861;&#20445;&#30041;&#20102;&#26356;&#39640;&#30340;&#25928;&#29992;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26426;&#21046;&#30340;&#21487;&#34892;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.00125</link><description>&lt;p&gt;
&#36890;&#36807;&#29420;&#31435;&#20998;&#37327;&#25289;&#26222;&#25289;&#26031;&#36807;&#31243;&#23454;&#29616;&#24046;&#20998;&#38544;&#31169;&#30340;&#20989;&#25968;&#24615;&#25688;&#35201;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Functional Summaries via the Independent Component Laplace Process. (arXiv:2309.00125v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00125
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;&#20989;&#25968;&#24615;&#25688;&#35201;&#26426;&#21046;&#65292;&#36890;&#36807;&#20351;&#29992;&#29420;&#31435;&#20998;&#37327;&#25289;&#26222;&#25289;&#26031;&#36807;&#31243;&#23545;&#26080;&#38480;&#32500;&#30340;&#20989;&#25968;&#24615;&#25688;&#35201;&#36827;&#34892;&#25200;&#21160;&#65292;&#25918;&#23485;&#20102;&#23545;&#25968;&#25454;&#36712;&#36857;&#30340;&#20551;&#35774;&#65292;&#24182;&#30456;&#23545;&#20110;&#20256;&#32479;&#30340;&#26377;&#38480;&#32500;&#23376;&#31354;&#38388;&#23884;&#20837;&#26041;&#27861;&#20445;&#30041;&#20102;&#26356;&#39640;&#30340;&#25928;&#29992;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26426;&#21046;&#30340;&#21487;&#34892;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#29420;&#31435;&#20998;&#37327;&#25289;&#26222;&#25289;&#26031;&#36807;&#31243;&#65288;ICLP&#65289;&#26426;&#21046;&#30340;&#24046;&#20998;&#38544;&#31169;&#20989;&#25968;&#24615;&#25688;&#35201;&#30340;&#26032;&#26426;&#21046;&#12290;&#36890;&#36807;&#23558;&#24863;&#20852;&#36259;&#30340;&#20989;&#25968;&#24615;&#25688;&#35201;&#35270;&#20026;&#30495;&#27491;&#26080;&#38480;&#32500;&#23545;&#35937;&#65292;&#24182;&#20351;&#29992;ICLP&#22122;&#22768;&#26469;&#25200;&#21160;&#23427;&#20204;&#65292;&#35813;&#26032;&#26426;&#21046;&#25918;&#23485;&#20102;&#20851;&#20110;&#25968;&#25454;&#36712;&#36857;&#30340;&#20551;&#35774;&#65292;&#24182;&#30456;&#23545;&#20110;&#25991;&#29486;&#20013;&#30340;&#32463;&#20856;&#26377;&#38480;&#32500;&#23376;&#31354;&#38388;&#23884;&#20837;&#26041;&#27861;&#20445;&#30041;&#20102;&#26356;&#39640;&#30340;&#25928;&#29992;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#20989;&#25968;&#31354;&#38388;&#20013;&#39564;&#35777;&#20102;&#25152;&#25552;&#20986;&#26426;&#21046;&#30340;&#21487;&#34892;&#24615;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#20960;&#20010;&#32479;&#35745;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#36731;&#24494;&#36807;&#24179;&#28369;&#25688;&#35201;&#26469;&#35777;&#26126;&#38544;&#31169;&#25104;&#26412;&#19981;&#20250;&#20027;&#23548;&#32479;&#35745;&#35823;&#24046;&#65292;&#24182;&#19988;&#22312;&#28176;&#36817;&#24773;&#20917;&#19979;&#21487;&#20197;&#24573;&#30053;&#12290;&#23545;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#26426;&#21046;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we propose a new mechanism for releasing differentially private functional summaries called the Independent Component Laplace Process, or ICLP, mechanism. By treating the functional summaries of interest as truly infinite-dimensional objects and perturbing them with the ICLP noise, this new mechanism relaxes assumptions on data trajectories and preserves higher utility compared to classical finite-dimensional subspace embedding approaches in the literature. We establish the feasibility of the proposed mechanism in multiple function spaces. Several statistical estimation problems are considered, and we demonstrate by slightly over-smoothing the summary, the privacy cost will not dominate the statistical error and is asymptotically negligible. Numerical experiments on synthetic and real datasets demonstrate the efficacy of the proposed mechanism.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#29289;&#29702;&#20449;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;(PINNs)&#35299;&#20915;&#39640;&#32500;&#24230;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;(PDEs)&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#25910;&#25947;&#24615;&#21644;&#20854;&#20182;&#26399;&#26395;&#23646;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.12306</link><description>&lt;p&gt;
&#29992;&#29289;&#29702;&#20449;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;&#35299;&#20915;&#32500;&#24230;&#35781;&#21650;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Tackling the Curse of Dimensionality with Physics-Informed Neural Networks. (arXiv:2307.12306v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12306
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#29289;&#29702;&#20449;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;(PINNs)&#35299;&#20915;&#39640;&#32500;&#24230;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;(PDEs)&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#25910;&#25947;&#24615;&#21644;&#20854;&#20182;&#26399;&#26395;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32500;&#24230;&#35781;&#21650;(CoD)&#38543;&#30528;&#32500;&#24230;&#30340;&#22686;&#21152;&#65292;&#20197;&#25351;&#25968;&#32423;&#22686;&#38271;&#30340;&#35745;&#31639;&#25104;&#26412;&#26469;&#26497;&#24230;&#31246;&#36153;&#35745;&#31639;&#36164;&#28304;&#12290;&#36825;&#22312;&#35299;&#20915;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;(PDEs)&#20013;&#38754;&#20020;&#26497;&#22823;&#25361;&#25112;&#65292;&#27491;&#22914;Richard Bellman&#22312;60&#24180;&#21069;&#39318;&#27425;&#25351;&#20986;&#30340;&#37027;&#26679;&#12290;&#23613;&#31649;&#36817;&#24180;&#26469;&#22312;&#39640;&#32500;&#24230;&#19978;&#25968;&#20540;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;(PDEs)&#21462;&#24471;&#20102;&#19968;&#20123;&#25104;&#21151;&#65292;&#20294;&#36825;&#26679;&#30340;&#35745;&#31639;&#20195;&#20215;&#36807;&#39640;&#65292;&#32780;&#23558;&#19968;&#33324;&#38750;&#32447;&#24615;PDEs&#25193;&#23637;&#21040;&#39640;&#32500;&#24230;&#20174;&#26410;&#23454;&#29616;&#36807;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#23558;&#29289;&#29702;&#20449;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;(PINNs)&#25193;&#23637;&#21040;&#35299;&#20915;&#20219;&#24847;&#39640;&#32500;PDEs&#12290;&#35813;&#26032;&#26041;&#27861;&#31216;&#20026;&#38543;&#26426;&#32500;&#24230;&#26799;&#24230;&#19979;&#38477;(SDGD)&#65292;&#23558;PDE&#30340;&#26799;&#24230;&#20998;&#35299;&#20026;&#19982;&#19981;&#21516;&#32500;&#24230;&#23545;&#24212;&#30340;&#37096;&#20998;&#65292;&#24182;&#22312;&#35757;&#32451;PINNs&#30340;&#27599;&#27425;&#36845;&#20195;&#20013;&#38543;&#26426;&#36873;&#25321;&#36825;&#20123;&#32500;&#24230;&#37096;&#20998;&#30340;&#23376;&#38598;&#36827;&#34892;&#37319;&#26679;&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#25910;&#25947;&#20445;&#35777;&#21644;&#20854;&#20182;&#26399;&#26395;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The curse-of-dimensionality (CoD) taxes computational resources heavily with exponentially increasing computational cost as the dimension increases. This poses great challenges in solving high-dimensional PDEs as Richard Bellman first pointed out over 60 years ago. While there has been some recent success in solving numerically partial differential equations (PDEs) in high dimensions, such computations are prohibitively expensive, and true scaling of general nonlinear PDEs to high dimensions has never been achieved. In this paper, we develop a new method of scaling up physics-informed neural networks (PINNs) to solve arbitrary high-dimensional PDEs. The new method, called Stochastic Dimension Gradient Descent (SDGD), decomposes a gradient of PDEs into pieces corresponding to different dimensions and samples randomly a subset of these dimensional pieces in each iteration of training PINNs. We theoretically prove the convergence guarantee and other desired properties of the proposed meth
&lt;/p&gt;</description></item><item><title>FaIRGP&#26159;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#20195;&#29702;&#27169;&#22411;&#65292;&#23427;&#28385;&#36275;&#33021;&#37327;&#24179;&#34913;&#27169;&#22411;&#30340;&#29289;&#29702;&#28201;&#24230;&#21709;&#24212;&#26041;&#31243;&#65292;&#21516;&#26102;&#20855;&#22791;&#20102;&#20174;&#35266;&#27979;&#20013;&#23398;&#20064;&#21644;&#36827;&#34892;&#25512;&#26029;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.10052</link><description>&lt;p&gt;
FaIRGP:&#38754;&#21521;&#34920;&#38754;&#28201;&#24230;&#27169;&#25311;&#30340;&#36125;&#21494;&#26031;&#33021;&#37327;&#24179;&#34913;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
FaIRGP: A Bayesian Energy Balance Model for Surface Temperatures Emulation. (arXiv:2307.10052v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10052
&lt;/p&gt;
&lt;p&gt;
FaIRGP&#26159;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#20195;&#29702;&#27169;&#22411;&#65292;&#23427;&#28385;&#36275;&#33021;&#37327;&#24179;&#34913;&#27169;&#22411;&#30340;&#29289;&#29702;&#28201;&#24230;&#21709;&#24212;&#26041;&#31243;&#65292;&#21516;&#26102;&#20855;&#22791;&#20102;&#20174;&#35266;&#27979;&#20013;&#23398;&#20064;&#21644;&#36827;&#34892;&#25512;&#26029;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20195;&#29702;&#27169;&#22411;&#25110;&#31616;&#21270;&#22797;&#26434;&#27668;&#20505;&#27169;&#22411;&#26159;&#36890;&#36807;&#26368;&#23567;&#30340;&#35745;&#31639;&#36164;&#28304;&#29983;&#25104;&#20851;&#38190;&#27668;&#20505;&#37327;&#39044;&#27979;&#30340;&#22320;&#29699;&#31995;&#32479;&#27169;&#22411;&#12290;&#36890;&#36807;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#25110;&#26356;&#20808;&#36827;&#30340;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#65292;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#20195;&#29702;&#27169;&#22411;&#24050;&#25104;&#20026;&#19968;&#20010;&#26377;&#24076;&#26395;&#30340;&#30740;&#31350;&#26041;&#21521;&#65292;&#33021;&#22815;&#29983;&#25104;&#19982;&#26368;&#20808;&#36827;&#30340;&#22320;&#29699;&#31995;&#32479;&#27169;&#22411;&#22312;&#35270;&#35273;&#19978;&#38590;&#20197;&#21306;&#20998;&#30340;&#31354;&#38388;&#20998;&#36776;&#29575;&#27668;&#20505;&#21709;&#24212;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#32570;&#20047;&#29289;&#29702;&#19978;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#24191;&#27867;&#24212;&#29992;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#20195;&#29702;&#27169;&#22411;FaIRGP&#65292;&#23427;&#28385;&#36275;&#33021;&#37327;&#24179;&#34913;&#27169;&#22411;&#30340;&#29289;&#29702;&#28201;&#24230;&#21709;&#24212;&#26041;&#31243;&#12290;&#32467;&#26524;&#26159;&#19968;&#20010;&#26082;&#33021;&#22815;&#20174;&#35266;&#27979;&#20013;&#23398;&#20064;&#21448;&#20855;&#26377;&#22362;&#23454;&#29289;&#29702;&#22522;&#30784;&#30340;&#20195;&#29702;&#27169;&#22411;&#65292;&#21487;&#29992;&#20110;&#23545;&#27668;&#20505;&#31995;&#32479;&#36827;&#34892;&#25512;&#26029;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#21407;&#21017;&#19988;&#25968;&#23398;&#21487;&#34892;&#30340;&#26041;&#27861;&#26469;&#36827;&#34892;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Emulators, or reduced complexity climate models, are surrogate Earth system models that produce projections of key climate quantities with minimal computational resources. Using time-series modeling or more advanced machine learning techniques, data-driven emulators have emerged as a promising avenue of research, producing spatially resolved climate responses that are visually indistinguishable from state-of-the-art Earth system models. Yet, their lack of physical interpretability limits their wider adoption. In this work, we introduce FaIRGP, a data-driven emulator that satisfies the physical temperature response equations of an energy balance model. The result is an emulator that (i) enjoys the flexibility of statistical machine learning models and can learn from observations, and (ii) has a robust physical grounding with interpretable parameters that can be used to make inference about the climate system. Further, our Bayesian approach allows a principled and mathematically tractabl
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#22522;&#20110;&#22270;&#24418;&#24179;&#28369;&#30340;Gibbs&#37319;&#26679;&#26041;&#27861;&#65288;GGS&#65289;&#20248;&#21270;&#34507;&#30333;&#36136;&#36866;&#24212;&#24615;&#65292;&#28040;&#38500;&#20102;&#31361;&#21464;&#36317;&#31163;&#30340;&#38480;&#21046;&#65292;&#21516;&#26102;&#25552;&#39640;&#20102;&#25628;&#32034;&#25928;&#29575;&#12290;&#35813;&#26041;&#27861;&#22312;&#21457;&#29616;&#39640;&#36866;&#24212;&#24615;&#34507;&#30333;&#36136;&#26041;&#38754;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;</title><link>http://arxiv.org/abs/2307.00494</link><description>&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;&#22270;&#24418;&#24179;&#28369;&#30340;Gibbs&#37319;&#26679;&#20248;&#21270;&#34507;&#30333;&#36136;&#36866;&#24212;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Optimizing protein fitness using Gibbs sampling with Graph-based Smoothing. (arXiv:2307.00494v1 [q-bio.BM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00494
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;&#22270;&#24418;&#24179;&#28369;&#30340;Gibbs&#37319;&#26679;&#26041;&#27861;&#65288;GGS&#65289;&#20248;&#21270;&#34507;&#30333;&#36136;&#36866;&#24212;&#24615;&#65292;&#28040;&#38500;&#20102;&#31361;&#21464;&#36317;&#31163;&#30340;&#38480;&#21046;&#65292;&#21516;&#26102;&#25552;&#39640;&#20102;&#25628;&#32034;&#25928;&#29575;&#12290;&#35813;&#26041;&#27861;&#22312;&#21457;&#29616;&#39640;&#36866;&#24212;&#24615;&#34507;&#30333;&#36136;&#26041;&#38754;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#22815;&#35774;&#35745;&#20986;&#22312;&#32473;&#23450;&#20219;&#21153;&#19978;&#20855;&#26377;&#26356;&#39640;&#36866;&#24212;&#24615;&#30340;&#26032;&#22411;&#34507;&#30333;&#36136;&#23545;&#35768;&#22810;&#21307;&#23398;&#39046;&#22495;&#26469;&#35828;&#37117;&#26159;&#38761;&#21629;&#24615;&#30340;&#12290;&#28982;&#32780;&#65292;&#36890;&#36807;&#31351;&#20030;&#25628;&#32034;&#28023;&#37327;&#24207;&#21015;&#31354;&#38388;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#20197;&#21069;&#30340;&#26041;&#27861;&#23558;&#25628;&#32034;&#38480;&#21046;&#22312;&#20174;&#21442;&#32771;&#24207;&#21015;&#30340;&#23567;&#31361;&#21464;&#21322;&#24452;&#33539;&#22260;&#20869;&#65292;&#20294;&#36825;&#26679;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#26497;&#22823;&#22320;&#38480;&#21046;&#20102;&#35774;&#35745;&#31354;&#38388;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#26088;&#22312;&#28040;&#38500;&#31361;&#21464;&#36317;&#31163;&#30340;&#38480;&#21046;&#65292;&#21516;&#26102;&#23454;&#29616;&#39640;&#25928;&#30340;&#25506;&#32034;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#22270;&#24418;&#24179;&#28369;&#30340;Gibbs&#37319;&#26679;&#65288;GGS&#65289;&#65292;&#23427;&#36890;&#36807;&#36845;&#20195;&#24212;&#29992;&#24102;&#26377;&#26799;&#24230;&#30340;Gibbs&#26469;&#25552;&#20986;&#26377;&#21033;&#30340;&#31361;&#21464;&#65292;&#24182;&#20351;&#29992;&#22522;&#20110;&#22270;&#24418;&#24179;&#28369;&#30340;&#26041;&#27861;&#21435;&#38500;&#23548;&#33268;&#20551;&#38451;&#24615;&#30340;&#22122;&#22768;&#26799;&#24230;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#35757;&#32451;&#38598;&#20013;&#21457;&#29616;&#20102;&#39640;&#36866;&#24212;&#24615;&#34507;&#30333;&#36136;&#65292;&#26368;&#22810;&#20855;&#26377;8&#20010;&#31361;&#21464;&#12290;&#25105;&#20204;&#36890;&#36807;&#30740;&#31350;GFP&#21644;AAV&#35774;&#35745;&#38382;&#39064;&#12289;&#28040;&#34701;&#35797;&#39564;&#21644;&#22522;&#20934;&#27169;&#22411;&#26469;&#38416;&#26126;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ability to design novel proteins with higher fitness on a given task would be revolutionary for many fields of medicine. However, brute-force search through the combinatorially large space of sequences is infeasible. Prior methods constrain search to a small mutational radius from a reference sequence, but such heuristics drastically limit the design space. Our work seeks to remove the restriction on mutational distance while enabling efficient exploration. We propose Gibbs sampling with Graph-based Smoothing (GGS) which iteratively applies Gibbs with gradients to propose advantageous mutations using graph-based smoothing to remove noisy gradients that lead to false positives. Our method is state-of-the-art in discovering high-fitness proteins with up to 8 mutations from the training set. We study the GFP and AAV design problems, ablations, and baselines to elucidate the results. Code: https://github.com/kirjner/GGS
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#23545;&#20110;&#20855;&#26377;&#23616;&#37096;&#21487;&#21464;&#27979;&#37327;&#23610;&#24230;&#30340;&#38543;&#26426;&#21464;&#37327;&#30340;&#24191;&#20041;&#38543;&#26426;&#20248;&#21183;&#65288;GSD&#65289;&#39034;&#24207;&#65292;&#24182;&#36890;&#36807;&#32447;&#24615;&#20248;&#21270;&#21644;&#19981;&#31934;&#30830;&#27010;&#29575;&#27169;&#22411;&#25552;&#20986;&#20102;&#27491;&#21017;&#21270;&#30340;&#32479;&#35745;&#26816;&#39564;&#65292;&#35299;&#20915;&#20102;&#22312;&#36825;&#20123;&#38750;&#26631;&#20934;&#31354;&#38388;&#20013;&#22914;&#20309;&#27491;&#30830;&#21033;&#29992;&#20840;&#37096;&#20449;&#24687;&#26469;&#36827;&#34892;&#27604;&#36739;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.12803</link><description>&lt;p&gt;
&#20855;&#26377;&#23616;&#37096;&#21487;&#21464;&#27979;&#37327;&#23610;&#24230;&#30340;&#38543;&#26426;&#21464;&#37327;&#30340;&#40065;&#26834;&#32479;&#35745;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Robust Statistical Comparison of Random Variables with Locally Varying Scale of Measurement. (arXiv:2306.12803v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12803
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#23545;&#20110;&#20855;&#26377;&#23616;&#37096;&#21487;&#21464;&#27979;&#37327;&#23610;&#24230;&#30340;&#38543;&#26426;&#21464;&#37327;&#30340;&#24191;&#20041;&#38543;&#26426;&#20248;&#21183;&#65288;GSD&#65289;&#39034;&#24207;&#65292;&#24182;&#36890;&#36807;&#32447;&#24615;&#20248;&#21270;&#21644;&#19981;&#31934;&#30830;&#27010;&#29575;&#27169;&#22411;&#25552;&#20986;&#20102;&#27491;&#21017;&#21270;&#30340;&#32479;&#35745;&#26816;&#39564;&#65292;&#35299;&#20915;&#20102;&#22312;&#36825;&#20123;&#38750;&#26631;&#20934;&#31354;&#38388;&#20013;&#22914;&#20309;&#27491;&#30830;&#21033;&#29992;&#20840;&#37096;&#20449;&#24687;&#26469;&#36827;&#34892;&#27604;&#36739;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;&#23616;&#37096;&#21487;&#21464;&#27979;&#37327;&#23610;&#24230;&#30340;&#31354;&#38388;&#65292;&#22312;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#26159;&#30456;&#24403;&#26222;&#36941;&#30340;&#65292;&#27604;&#22914;&#35828;&#65292;&#20855;&#26377;&#19981;&#21516;&#32553;&#25918;&#32500;&#24230;&#30340;&#22810;&#32500;&#32467;&#26500;&#12290;&#28982;&#32780;&#65292;&#22914;&#20309;&#27491;&#30830;&#22320;&#21033;&#29992;&#36825;&#20123;&#31354;&#38388;&#20013;&#32534;&#30721;&#30340;&#20840;&#37096;&#20449;&#24687;&#65292;&#20173;&#28982;&#34987;&#35748;&#20026;&#26159;&#19968;&#20010;&#24320;&#25918;&#24615;&#38382;&#39064;&#12290;&#25105;&#20204;&#36890;&#36807;&#32771;&#34385;&#19968;&#20010;&#22522;&#20110;&#38543;&#26426;&#21464;&#37327;&#26399;&#26395;&#30340;&#65288;&#38598;&#21512;&#65289;&#20559;&#24207;&#20851;&#31995;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#36825;&#20123;&#38543;&#26426;&#21464;&#37327;&#26144;&#23556;&#21040;&#36825;&#20123;&#38750;&#26631;&#20934;&#31354;&#38388;&#20013;&#12290;&#24403;&#27809;&#26377;&#25110;&#23436;&#20840;&#30340;&#22522;&#25968;&#32467;&#26500;&#26102;&#65292;&#36825;&#20010;&#20559;&#24207;&#20851;&#31995;&#21253;&#21547;&#38543;&#26426;&#20248;&#21183;&#21644;&#26399;&#26395;&#39034;&#24207;&#20316;&#20026;&#26497;&#31471;&#24773;&#20917;&#12290;&#25105;&#20204;&#36890;&#36807;&#32447;&#24615;&#20248;&#21270;&#23548;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#25105;&#20204;&#25552;&#20986;&#30340;&#24191;&#20041;&#38543;&#26426;&#20248;&#21183;&#65288;GSD&#65289;&#39034;&#24207;&#30340;&#65288;&#27491;&#21017;&#21270;&#30340;&#65289;&#32479;&#35745;&#26816;&#39564;&#65292;&#24182;&#36890;&#36807;&#19981;&#31934;&#30830;&#27010;&#29575;&#27169;&#22411;&#20351;&#20854;&#26356;&#20026;&#40065;&#26834;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#29992;&#22810;&#32500;&#36139;&#22256;&#24230;&#37327;&#12289;&#37329;&#34701;&#21644;&#21307;&#23398;&#25968;&#25454;&#36827;&#34892;&#35828;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Spaces with locally varying scale of measurement, like multidimensional structures with differently scaled dimensions, are pretty common in statistics and machine learning. Nevertheless, it is still understood as an open question how to exploit the entire information encoded in them properly. We address this problem by considering an order based on (sets of) expectations of random variables mapping into such non-standard spaces. This order contains stochastic dominance and expectation order as extreme cases when no, or respectively perfect, cardinal structure is given. We derive a (regularized) statistical test for our proposed generalized stochastic dominance (GSD) order, operationalize it by linear optimization, and robustify it by imprecise probability models. Our findings are illustrated with data from multidimensional poverty measurement, finance, and medicine.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;SGD&#35757;&#32451;&#25439;&#22833;&#20013;&#30340;&#23574;&#23792;&#29616;&#35937;&#65292;&#25552;&#20986;&#20102;&#8220;&#25237;&#30707;&#26426;&#8221;&#20248;&#21270;&#29616;&#35937;&#65292;&#36890;&#36807;&#22686;&#21152;&#19982;&#30495;&#23454;&#39044;&#27979;&#22120;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#23545;&#40784;&#26469;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#65292;&#24182;&#35777;&#26126;&#36739;&#23567;&#30340;&#25209;&#37327;&#22823;&#23567;&#21487;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.04815</link><description>&lt;p&gt;
SGD&#20013;&#30340;&#25237;&#30707;&#26426;&#65306;&#35757;&#32451;&#25439;&#22833;&#20013;&#30340;&#23574;&#23792;&#21450;&#20854;&#36890;&#36807;&#29305;&#24449;&#23398;&#20064;&#23545;&#27867;&#21270;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Catapults in SGD: spikes in the training loss and their impact on generalization through feature learning. (arXiv:2306.04815v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04815
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;SGD&#35757;&#32451;&#25439;&#22833;&#20013;&#30340;&#23574;&#23792;&#29616;&#35937;&#65292;&#25552;&#20986;&#20102;&#8220;&#25237;&#30707;&#26426;&#8221;&#20248;&#21270;&#29616;&#35937;&#65292;&#36890;&#36807;&#22686;&#21152;&#19982;&#30495;&#23454;&#39044;&#27979;&#22120;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#23545;&#40784;&#26469;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#65292;&#24182;&#35777;&#26126;&#36739;&#23567;&#30340;&#25209;&#37327;&#22823;&#23567;&#21487;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#20808;&#35299;&#37322;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#36827;&#34892;&#35757;&#32451;&#26102;&#20026;&#20160;&#20040;&#32463;&#24120;&#20986;&#29616;&#35757;&#32451;&#25439;&#22833;&#23574;&#23792;&#30340;&#29616;&#35937;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#35777;&#25454;&#34920;&#26126;&#65292;SGD&#35757;&#32451;&#25439;&#22833;&#20013;&#30340;&#23574;&#23792;&#26159;&#8220;&#25237;&#30707;&#26426;&#8221;&#65292;&#36825;&#26159;&#19968;&#31181;&#20248;&#21270;&#29616;&#35937;&#65292;&#26368;&#21021;&#22312;[Lewkowycz&#31561;&#20154;&#65292;2020&#24180;]&#30340;&#22823;&#23398;&#20064;&#29575;GD&#20013;&#35266;&#23519;&#21040;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#36825;&#20123;&#25237;&#30707;&#26426;&#20986;&#29616;&#22312;&#30001;&#27491;&#20999;&#20869;&#26680;&#30340;&#21069;&#20960;&#20010;&#29305;&#24449;&#21521;&#37327;&#25152;&#24352;&#25104;&#30340;&#20302;&#32500;&#23376;&#31354;&#38388;&#20013;&#65292;&#36866;&#29992;&#20110;GD&#21644;SGD&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#35299;&#37322;&#65292;&#21363;&#25237;&#30707;&#26426;&#22914;&#20309;&#36890;&#36807;&#22686;&#21152;&#19982;&#30495;&#23454;&#39044;&#27979;&#22120;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#65288;AGOP&#65289;&#23545;&#40784;&#26469;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#22909;&#30340;&#27867;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;SGD&#20013;&#65292;&#26356;&#23567;&#30340;&#25209;&#37327;&#22823;&#23567;&#20250;&#23548;&#33268;&#26356;&#22810;&#30340;&#25237;&#30707;&#26426;&#20986;&#29616;&#65292;&#20174;&#32780;&#25552;&#39640;AGOP&#23545;&#40784;&#21644;&#27979;&#35797;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we first present an explanation regarding the common occurrence of spikes in the training loss when neural networks are trained with stochastic gradient descent (SGD). We provide evidence that the spikes in the training loss of SGD are "catapults", an optimization phenomenon originally observed in GD with large learning rates in [Lewkowycz et al. 2020]. We empirically show that these catapults occur in a low-dimensional subspace spanned by the top eigenvectors of the tangent kernel, for both GD and SGD. Second, we posit an explanation for how catapults lead to better generalization by demonstrating that catapults promote feature learning by increasing alignment with the Average Gradient Outer Product (AGOP) of the true predictor. Furthermore, we demonstrate that a smaller batch size in SGD induces a larger number of catapults, thereby improving AGOP alignment and test performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;&#20107;&#23454;&#39044;&#27979;&#38598;&#30340;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#35774;&#35745;&#26041;&#27861;&#65292;&#19981;&#21516;&#20110;&#20256;&#32479;&#30340;&#21333;&#19968;&#26631;&#31614;&#39044;&#27979;&#65292;&#23427;&#20351;&#29992;&#31526;&#21512;&#39044;&#27979;&#22120;&#26500;&#24314;&#39044;&#27979;&#38598;&#65292;&#24182;&#24341;&#23548;&#20154;&#31867;&#19987;&#23478;&#20174;&#20013;&#36873;&#25321;&#26631;&#31614;&#20540;&#12290;</title><link>http://arxiv.org/abs/2306.03928</link><description>&lt;p&gt;
&#20351;&#29992;&#21453;&#20107;&#23454;&#39044;&#27979;&#38598;&#35774;&#35745;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Designing Decision Support Systems Using Counterfactual Prediction Sets. (arXiv:2306.03928v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03928
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;&#20107;&#23454;&#39044;&#27979;&#38598;&#30340;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#35774;&#35745;&#26041;&#27861;&#65292;&#19981;&#21516;&#20110;&#20256;&#32479;&#30340;&#21333;&#19968;&#26631;&#31614;&#39044;&#27979;&#65292;&#23427;&#20351;&#29992;&#31526;&#21512;&#39044;&#27979;&#22120;&#26500;&#24314;&#39044;&#27979;&#38598;&#65292;&#24182;&#24341;&#23548;&#20154;&#31867;&#19987;&#23478;&#20174;&#20013;&#36873;&#25321;&#26631;&#31614;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#31867;&#20219;&#21153;&#30340;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#36890;&#24120;&#34987;&#35774;&#35745;&#29992;&#20110;&#39044;&#27979;&#22320;&#38754;&#23454;&#20917;&#26631;&#31614;&#30340;&#20540;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23427;&#20204;&#30340;&#39044;&#27979;&#24182;&#19981;&#23436;&#32654;&#65292;&#36825;&#20123;&#31995;&#32479;&#36824;&#38656;&#35201;&#35753;&#20154;&#31867;&#19987;&#23478;&#20102;&#35299;&#20309;&#26102;&#20197;&#21450;&#22914;&#20309;&#20351;&#29992;&#36825;&#20123;&#39044;&#27979;&#26469;&#26356;&#26032;&#33258;&#24049;&#30340;&#39044;&#27979;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#34987;&#35777;&#26126;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#26368;&#36817;&#26377;&#20154;&#35748;&#20026;&#65292;&#21478;&#19968;&#31181;&#31867;&#22411;&#30340;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#21487;&#33021;&#20250;&#36991;&#24320;&#36825;&#20010;&#25361;&#25112;&#12290;&#36825;&#20123;&#31995;&#32479;&#19981;&#26159;&#25552;&#20379;&#21333;&#20010;&#26631;&#31614;&#39044;&#27979;&#65292;&#32780;&#26159;&#20351;&#29992;&#31526;&#21512;&#39044;&#27979;&#22120;&#26500;&#24314;&#19968;&#32452;&#26631;&#31614;&#39044;&#27979;&#20540;&#65292;&#21363;&#39044;&#27979;&#38598;&#65292;&#24182;&#24378;&#21046;&#35201;&#27714;&#19987;&#23478;&#20174;&#39044;&#27979;&#38598;&#20013;&#39044;&#27979;&#19968;&#20010;&#26631;&#31614;&#20540;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31995;&#32479;&#30340;&#35774;&#35745;&#21644;&#35780;&#20272;&#36804;&#20170;&#20173;&#20381;&#36182;&#20110;&#26679;&#24335;&#21270;&#30340;&#19987;&#23478;&#27169;&#22411;&#65292;&#36825;&#24341;&#21457;&#20102;&#20154;&#20204;&#23545;&#23427;&#20204;&#30340;&#25215;&#35834;&#30340;&#36136;&#30097;&#12290;&#26412;&#25991;&#20174;&#22312;&#32447;&#23398;&#20064;&#30340;&#35282;&#24230;&#37325;&#26032;&#23457;&#35270;&#20102;&#36825;&#31181;&#31995;&#32479;&#30340;&#35774;&#35745;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#19981;&#38656;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
Decision support systems for classification tasks are predominantly designed to predict the value of the ground truth labels. However, since their predictions are not perfect, these systems also need to make human experts understand when and how to use these predictions to update their own predictions. Unfortunately, this has been proven challenging. In this context, it has been recently argued that an alternative type of decision support systems may circumvent this challenge. Rather than providing a single label prediction, these systems provide a set of label prediction values constructed using a conformal predictor, namely a prediction set, and forcefully ask experts to predict a label value from the prediction set. However, the design and evaluation of these systems have so far relied on stylized expert models, questioning their promise. In this paper, we revisit the design of this type of systems from the perspective of online learning and develop a methodology that does not requi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19982;NMF&#31639;&#27861;&#19968;&#26679;&#31616;&#21333;&#19988;&#21487;&#25193;&#23637;&#30340;K&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#35299;&#20915;&#38750;&#36127;&#20302;&#31209;&#21322;&#23450;&#35268;&#21010;&#38382;&#39064;&#33719;&#24471;&#20102;&#24378;&#22823;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#20445;&#35777;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#31639;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2305.18436</link><description>&lt;p&gt;
&#36890;&#36807;&#38750;&#36127;&#20302;&#31209;&#21322;&#23450;&#35268;&#21010;&#23454;&#29616;&#26368;&#20248;K&#22343;&#20540;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Statistically Optimal K-means Clustering via Nonnegative Low-rank Semidefinite Programming. (arXiv:2305.18436v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18436
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19982;NMF&#31639;&#27861;&#19968;&#26679;&#31616;&#21333;&#19988;&#21487;&#25193;&#23637;&#30340;K&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#35299;&#20915;&#38750;&#36127;&#20302;&#31209;&#21322;&#23450;&#35268;&#21010;&#38382;&#39064;&#33719;&#24471;&#20102;&#24378;&#22823;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#20445;&#35777;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#31639;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
K&#22343;&#20540;&#32858;&#31867;&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#20110;&#22823;&#25968;&#25454;&#38598;&#20013;&#21457;&#29616;&#27169;&#24335;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#12290;&#21322;&#23450;&#35268;&#21010;&#65288;SDP&#65289;&#26494;&#24347;&#26368;&#36817;&#34987;&#25552;&#20986;&#29992;&#20110;&#35299;&#20915;K&#22343;&#20540;&#20248;&#21270;&#38382;&#39064;&#65292;&#20855;&#26377;&#24456;&#24378;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#20445;&#35777;&#12290;&#20294;&#23454;&#29616;SDP&#27714;&#35299;&#22120;&#30340;&#24040;&#22823;&#25104;&#26412;&#20351;&#24471;&#36825;&#20123;&#20445;&#35777;&#26080;&#27861;&#24212;&#29992;&#20110;&#23454;&#38469;&#25968;&#25454;&#38598;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#65288;NMF&#65289;&#26159;&#19968;&#31181;&#31616;&#21333;&#30340;&#32858;&#31867;&#31639;&#27861;&#65292;&#34987;&#26426;&#22120;&#23398;&#20064;&#20174;&#19994;&#32773;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#32570;&#20047;&#22362;&#23454;&#30340;&#32479;&#35745;&#22522;&#30784;&#25110;&#20005;&#26684;&#30340;&#20445;&#35777;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#31181;&#31867;&#20284;&#20110;NMF&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#38750;&#20984;Burer-Monteiro&#20998;&#35299;&#26041;&#27861;&#35299;&#20915;&#21322;&#23450;&#35268;&#21010;&#26494;&#24347;&#30340;K&#22343;&#20540;&#20844;&#24335;&#30340;&#38750;&#36127;&#20302;&#31209;&#38480;&#21046;&#12290;&#25152;&#24471;&#21040;&#30340;&#31639;&#27861;&#19982;&#26368;&#20808;&#36827;&#30340;NMF&#31639;&#27861;&#19968;&#26679;&#31616;&#21333;&#21644;&#21487;&#25193;&#23637;&#65292;&#21516;&#26102;&#20063;&#20139;&#26377;&#19982;SDP&#30456;&#21516;&#30340;&#24378;&#22823;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#20445;&#35777;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;NMF&#31639;&#27861;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#19982;&#26368;&#20808;&#36827;&#30340;SDP&#27714;&#35299;&#22120;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
$K$-means clustering is a widely used machine learning method for identifying patterns in large datasets. Semidefinite programming (SDP) relaxations have recently been proposed for solving the $K$-means optimization problem that enjoy strong statistical optimality guarantees, but the prohibitive cost of implementing an SDP solver renders these guarantees inaccessible to practical datasets. By contrast, nonnegative matrix factorization (NMF) is a simple clustering algorithm that is widely used by machine learning practitioners, but without a solid statistical underpinning nor rigorous guarantees. In this paper, we describe an NMF-like algorithm that works by solving a nonnegative low-rank restriction of the SDP relaxed $K$-means formulation using a nonconvex Burer--Monteiro factorization approach. The resulting algorithm is just as simple and scalable as state-of-the-art NMF algorithms, while also enjoying the same strong statistical optimality guarantees as the SDP. In our experiments,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#19982;&#31070;&#32463;&#32593;&#32476;&#23436;&#20840;&#23545;&#24212;&#30340;&#26080;&#38480;&#26641;&#29366;PGMs&#26469;&#35299;&#20915;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#32570;&#20047;PGMs&#30340;&#31934;&#30830;&#35821;&#20041;&#21644;&#26126;&#30830;&#23450;&#20041;&#30340;&#27010;&#29575;&#35299;&#37322;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#21457;&#29616;DNNs&#22312;&#21069;&#21521;&#20256;&#25773;&#26102;&#30830;&#23454;&#25191;&#34892;PGM&#25512;&#26029;&#30340;&#36817;&#20284;&#65292;&#36825;&#19982;&#29616;&#26377;&#30740;&#31350;&#19981;&#21516;&#65292;&#23427;&#38416;&#26126;&#20102;DNNs&#23545;PGMs&#20013;&#30340;&#31934;&#30830;&#25512;&#29702;&#30340;&#26356;&#30452;&#25509;&#36817;&#20284;&#65292;&#28508;&#22312;&#30340;&#22909;&#22788;&#21253;&#25324;&#25913;&#36827;DNNs&#30340;&#25945;&#23398;&#21644;&#35299;&#37322;&#65292;&#20197;&#21450;&#33021;&#22815;&#21512;&#24182;PGMs&#21644;DNNs&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.17583</link><description>&lt;p&gt;
&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#26080;&#38480;&#26641;&#29366;&#27010;&#29575;&#22270;&#27169;&#22411;&#30340;&#35770;&#25991;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Neural Networks as Infinite Tree-Structured Probabilistic Graphical Models. (arXiv:2305.17583v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17583
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#19982;&#31070;&#32463;&#32593;&#32476;&#23436;&#20840;&#23545;&#24212;&#30340;&#26080;&#38480;&#26641;&#29366;PGMs&#26469;&#35299;&#20915;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#32570;&#20047;PGMs&#30340;&#31934;&#30830;&#35821;&#20041;&#21644;&#26126;&#30830;&#23450;&#20041;&#30340;&#27010;&#29575;&#35299;&#37322;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#21457;&#29616;DNNs&#22312;&#21069;&#21521;&#20256;&#25773;&#26102;&#30830;&#23454;&#25191;&#34892;PGM&#25512;&#26029;&#30340;&#36817;&#20284;&#65292;&#36825;&#19982;&#29616;&#26377;&#30740;&#31350;&#19981;&#21516;&#65292;&#23427;&#38416;&#26126;&#20102;DNNs&#23545;PGMs&#20013;&#30340;&#31934;&#30830;&#25512;&#29702;&#30340;&#26356;&#30452;&#25509;&#36817;&#20284;&#65292;&#28508;&#22312;&#30340;&#22909;&#22788;&#21253;&#25324;&#25913;&#36827;DNNs&#30340;&#25945;&#23398;&#21644;&#35299;&#37322;&#65292;&#20197;&#21450;&#33021;&#22815;&#21512;&#24182;PGMs&#21644;DNNs&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#32570;&#20047;&#27010;&#29575;&#22270;&#27169;&#22411;(PGMs)&#30340;&#31934;&#30830;&#35821;&#20041;&#21644;&#26126;&#30830;&#23450;&#20041;&#30340;&#27010;&#29575;&#35299;&#37322;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#19982;&#31070;&#32463;&#32593;&#32476;&#23436;&#20840;&#23545;&#24212;&#30340;&#26080;&#38480;&#26641;&#29366;PGMs&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;DNNs&#22312;&#21069;&#21521;&#20256;&#25773;&#26399;&#38388;&#30830;&#23454;&#25191;&#34892;PGM&#25512;&#26029;&#30340;&#36817;&#20284;&#65292;&#36825;&#19982;&#26366;&#32463;&#30340;&#31070;&#32463;&#32593;&#32476;&#25551;&#36848;&#20026;&#26680;&#26426;&#22120;&#25110;&#26080;&#38480;&#22823;&#23567;&#30340;&#39640;&#26031;&#36807;&#31243;&#30340;&#29616;&#26377;&#30740;&#31350;&#19981;&#21516;&#65292;&#23427;&#38416;&#26126;&#20102;DNNs&#23545;PGMs&#20013;&#30340;&#31934;&#30830;&#25512;&#29702;&#30340;&#26356;&#30452;&#25509;&#36817;&#20284;&#12290;&#28508;&#22312;&#30340;&#22909;&#22788;&#21253;&#25324;&#25913;&#36827;DNNs&#30340;&#25945;&#23398;&#21644;&#35299;&#37322;&#65292;&#20197;&#21450;&#33021;&#22815;&#21512;&#24182;PGMs&#21644;DNNs&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks (DNNs) lack the precise semantics and definitive probabilistic interpretation of probabilistic graphical models (PGMs). In this paper, we propose an innovative solution by constructing infinite tree-structured PGMs that correspond exactly to neural networks. Our research reveals that DNNs, during forward propagation, indeed perform approximations of PGM inference that are precise in this alternative PGM structure. Not only does our research complement existing studies that describe neural networks as kernel machines or infinite-sized Gaussian processes, it also elucidates a more direct approximation that DNNs make to exact inference in PGMs. Potential benefits include improved pedagogy and interpretation of DNNs, and algorithms that can merge the strengths of PGMs and DNNs.
&lt;/p&gt;</description></item><item><title>CoCoRL&#26159;&#19968;&#31181;&#20174;&#19981;&#30693;&#36947;&#22870;&#21169;&#30340;&#24050;&#30693;&#23433;&#20840;&#28436;&#31034;&#20013;&#25512;&#26029;&#32422;&#26463;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;Constrained Markov Decision Process&#65288;CMDP&#65289;&#65292;&#24182;&#19988;&#23545;&#20110;&#20960;&#20046;&#26368;&#20248;&#28436;&#31034;&#33021;&#22815;&#26080;&#35823;&#24046;&#25910;&#25947;&#20110;&#30495;&#23454;&#30340;&#23433;&#20840;&#38598;&#12290;</title><link>http://arxiv.org/abs/2305.16147</link><description>&lt;p&gt;
&#20174;&#26410;&#30693;&#22870;&#21169;&#30340;&#28436;&#31034;&#20013;&#23398;&#20064;&#23433;&#20840;&#32422;&#26463;
&lt;/p&gt;
&lt;p&gt;
Learning Safety Constraints from Demonstrations with Unknown Rewards. (arXiv:2305.16147v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16147
&lt;/p&gt;
&lt;p&gt;
CoCoRL&#26159;&#19968;&#31181;&#20174;&#19981;&#30693;&#36947;&#22870;&#21169;&#30340;&#24050;&#30693;&#23433;&#20840;&#28436;&#31034;&#20013;&#25512;&#26029;&#32422;&#26463;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;Constrained Markov Decision Process&#65288;CMDP&#65289;&#65292;&#24182;&#19988;&#23545;&#20110;&#20960;&#20046;&#26368;&#20248;&#28436;&#31034;&#33021;&#22815;&#26080;&#35823;&#24046;&#25910;&#25947;&#20110;&#30495;&#23454;&#30340;&#23433;&#20840;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;Convex Constraint Learning for Reinforcement Learning (CoCoRL)&#65292;&#29992;&#20110;&#20174;&#19968;&#32452;&#24050;&#30693;&#23433;&#20840;&#28436;&#31034;&#20013;&#25512;&#26029;Constrained Markov Decision Process (CMDP)&#30340;&#20849;&#20139;&#32422;&#26463;&#12290;&#19982;&#20197;&#21069;&#30340;&#26041;&#27861;&#21482;&#38480;&#20110;&#24050;&#30693;&#22870;&#21169;&#25110;&#23436;&#20840;&#24050;&#30693;&#29615;&#22659;&#21160;&#24577;&#30340;&#28436;&#31034;&#30456;&#27604;&#65292;CoCoRL&#21487;&#20197;&#20174;&#20855;&#26377;&#19981;&#21516;&#26410;&#30693;&#22870;&#21169;&#30340;&#28436;&#31034;&#20013;&#23398;&#20064;&#32422;&#26463;&#65292;&#32780;&#26080;&#38656;&#20102;&#35299;&#29615;&#22659;&#21160;&#24577;&#12290;CoCoRL&#22522;&#20110;&#28436;&#31034;&#26500;&#24314;&#20102;&#19968;&#20010;&#20984;&#23433;&#20840;&#38598;&#65292;&#21363;&#20351;&#26159;&#28508;&#22312;&#30340;&#27425;&#20248;&#28436;&#31034;&#20063;&#33021;&#20445;&#35777;&#23433;&#20840;&#12290;&#23545;&#20110;&#20960;&#20046;&#26368;&#20248;&#28436;&#31034;&#65292;CoCoRL&#33021;&#22815;&#26080;&#35823;&#24046;&#25910;&#25947;&#20110;&#30495;&#23454;&#30340;&#23433;&#20840;&#38598;&#12290;&#25105;&#20204;&#22312;&#34920;&#26684;&#29615;&#22659;&#21644;&#19968;&#20010;&#21253;&#21547;&#22810;&#20010;&#32422;&#26463;&#30340;&#36830;&#32493;&#39550;&#39542;&#20223;&#30495;&#20013;&#35780;&#20272;CoCoRL&#12290;CoCoRL&#23398;&#20064;&#21040;&#30340;&#38480;&#21046;&#23548;&#33268;&#20102;&#23433;&#20840;&#30340;&#39550;&#39542;&#34892;&#20026;&#65292;&#24182;&#21487;&#20197;&#36716;&#31227;&#21040;&#19981;&#21516;&#30340;&#20219;&#21153;&#21644;&#29615;&#22659;&#12290;&#19982;&#20043;&#30456;&#21453;&#65292;&#22522;&#20110;&#23398;&#20064;&#24050;&#30693;&#22238;&#25253;&#30340;&#26367;&#20195;&#26041;&#27861;&#26080;&#27861;&#25512;&#24191;&#21040;&#20855;&#26377;&#19981;&#21516;&#22238;&#25253;&#30340;&#26032;&#29615;&#22659;&#65292;&#31361;&#26174;&#20102;CoCoRL&#22312;&#19981;&#30693;&#36947;&#22238;&#25253;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#32422;&#26463;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose Convex Constraint Learning for Reinforcement Learning (CoCoRL), a novel approach for inferring shared constraints in a Constrained Markov Decision Process (CMDP) from a set of safe demonstrations with possibly different reward functions. While previous work is limited to demonstrations with known rewards or fully known environment dynamics, CoCoRL can learn constraints from demonstrations with different unknown rewards without knowledge of the environment dynamics. CoCoRL constructs a convex safe set based on demonstrations, which provably guarantees safety even for potentially sub-optimal (but safe) demonstrations. For near-optimal demonstrations, CoCoRL converges to the true safe set with no policy regret. We evaluate CoCoRL in tabular environments and a continuous driving simulation with multiple constraints. CoCoRL learns constraints that lead to safe driving behavior and that can be transferred to different tasks and environments. In contrast, alternative methods based 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#8212;&#8212;&#38750;&#37197;&#23545;&#31070;&#32463;&#34203;&#23450;&#35860;&#26725; (UNSB)&#65292;&#23427;&#32467;&#21512;&#20102;&#34203;&#23450;&#35860;&#26725;&#12289;&#23545;&#25239;&#35757;&#32451;&#21644;&#27491;&#21017;&#21270;&#65292;&#29992;&#20110;&#22312;&#38750;&#37197;&#23545;&#25968;&#25454;&#20043;&#38388;&#23398;&#20064; SDE&#65292;&#24182;&#25104;&#21151;&#35299;&#20915;&#20102;&#35768;&#22810;&#38750;&#37197;&#23545;&#22270;&#20687;&#36716;&#25442;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2305.15086</link><description>&lt;p&gt;
&#20351;&#29992;&#31070;&#32463;&#34203;&#23450;&#35860;&#26725;&#23454;&#29616;&#38750;&#37197;&#23545;&#22270;&#20687;&#36716;&#25442;
&lt;/p&gt;
&lt;p&gt;
Unpaired Image-to-Image Translation via Neural Schr\"odinger Bridge. (arXiv:2305.15086v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15086
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#8212;&#8212;&#38750;&#37197;&#23545;&#31070;&#32463;&#34203;&#23450;&#35860;&#26725; (UNSB)&#65292;&#23427;&#32467;&#21512;&#20102;&#34203;&#23450;&#35860;&#26725;&#12289;&#23545;&#25239;&#35757;&#32451;&#21644;&#27491;&#21017;&#21270;&#65292;&#29992;&#20110;&#22312;&#38750;&#37197;&#23545;&#25968;&#25454;&#20043;&#38388;&#23398;&#20064; SDE&#65292;&#24182;&#25104;&#21151;&#35299;&#20915;&#20102;&#35768;&#22810;&#38750;&#37197;&#23545;&#22270;&#20687;&#36716;&#25442;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#26159;&#19968;&#31867;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;&#27169;&#25311;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#20174;&#22122;&#22768;&#29983;&#25104;&#25968;&#25454;&#12290;&#23613;&#31649;&#25193;&#25955;&#27169;&#22411;&#22312;&#26368;&#36817;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#20294;&#30001;&#20110;&#39640;&#26031;&#20808;&#39564;&#20551;&#35774;&#65292;&#23427;&#20204;&#22312;&#38750;&#37197;&#23545;&#30340;&#22270;&#20687;&#36716;&#25442;&#20219;&#21153;&#20013;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#34203;&#23450;&#35860;&#26725;&#26159;&#19968;&#31181;&#23398;&#20064; SDE &#20197;&#22312;&#20004;&#20010;&#20219;&#24847;&#20998;&#24067;&#20043;&#38388;&#36716;&#25442;&#30340;&#26041;&#27861;&#65292;&#34987;&#35270;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#31181;&#26377;&#21560;&#24341;&#21147;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#36804;&#20170;&#20026;&#27490;&#65292;&#34203;&#23450;&#35860;&#26725;&#27169;&#22411;&#22312;&#39640;&#20998;&#36776;&#29575;&#22270;&#20687;&#20043;&#38388;&#30340;&#38750;&#37197;&#23545;&#36716;&#25442;&#26041;&#38754;&#24182;&#19981;&#25104;&#21151;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#38750;&#37197;&#23545;&#31070;&#32463;&#34203;&#23450;&#35860;&#26725;&#65288;UNSB&#65289;&#65292;&#23427;&#23558;&#34203;&#23450;&#35860;&#26725;&#19982;&#23545;&#25239;&#24615;&#35757;&#32451;&#21644;&#27491;&#21017;&#21270;&#30456;&#32467;&#21512;&#65292;&#20197;&#23398;&#20064;&#38750;&#37197;&#23545;&#25968;&#25454;&#20043;&#38388;&#30340; SDE&#12290;&#25105;&#20204;&#35777;&#26126;&#20102; UNSB &#26159;&#21487;&#20280;&#32553;&#30340;&#65292;&#24182;&#19988;&#25104;&#21151;&#35299;&#20915;&#20102;&#21508;&#31181;&#38750;&#37197;&#23545;&#22270;&#20687;&#36716;&#25442;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models are a powerful class of generative models which simulate stochastic differential equations (SDEs) to generate data from noise. Although diffusion models have achieved remarkable progress in recent years, they have limitations in the unpaired image-to-image translation tasks due to the Gaussian prior assumption. Schr\"odinger Bridge (SB), which learns an SDE to translate between two arbitrary distributions, have risen as an attractive solution to this problem. However, none of SB models so far have been successful at unpaired translation between high-resolution images. In this work, we propose the Unpaired Neural Schr\"odinger Bridge (UNSB), which combines SB with adversarial training and regularization to learn a SB between unpaired data. We demonstrate that UNSB is scalable, and that it successfully solves various unpaired image-to-image translation tasks. Code: \url{https://github.com/cyclomon/UNSB}
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Fisher&#32447;&#24615;&#21028;&#21035;&#30340;&#39046;&#22495;&#33258;&#36866;&#24212;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#26159;&#20004;&#20010;&#20551;&#35774;&#30340;&#20984;&#32452;&#21512;&#65292;&#21487;&#20197;&#22312;&#19981;&#35775;&#38382;&#20219;&#20309;&#21333;&#20010;&#28304;&#20219;&#21153;&#30340;&#30452;&#25509;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#35745;&#31639;&#26368;&#20248;&#20998;&#31867;&#22120;&#65292;&#24182;&#22312;&#22522;&#20110;EEG&#21644;ECG&#30340;&#20998;&#31867;&#35774;&#32622;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.14186</link><description>&lt;p&gt;
&#24102;&#26377;Fisher&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#30340;&#36817;&#20284;&#26368;&#20248;&#39046;&#22495;&#33258;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
Approximately optimal domain adaptation with Fisher's Linear Discriminant Analysis. (arXiv:2302.14186v2 [eess.SP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.14186
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Fisher&#32447;&#24615;&#21028;&#21035;&#30340;&#39046;&#22495;&#33258;&#36866;&#24212;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#26159;&#20004;&#20010;&#20551;&#35774;&#30340;&#20984;&#32452;&#21512;&#65292;&#21487;&#20197;&#22312;&#19981;&#35775;&#38382;&#20219;&#20309;&#21333;&#20010;&#28304;&#20219;&#21153;&#30340;&#30452;&#25509;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#35745;&#31639;&#26368;&#20248;&#20998;&#31867;&#22120;&#65292;&#24182;&#22312;&#22522;&#20110;EEG&#21644;ECG&#30340;&#20998;&#31867;&#35774;&#32622;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31867;&#22522;&#20110;Fisher&#32447;&#24615;&#21028;&#21035;&#65288;FLD&#65289;&#30340;&#27169;&#22411;&#65292;&#29992;&#20110;&#39046;&#22495;&#33258;&#36866;&#24212;&#12290;&#35813;&#31867;&#27169;&#22411;&#26159;&#20004;&#20010;&#20551;&#35774;&#30340;&#20984;&#32452;&#21512;&#65306;i&#65289;&#20195;&#34920;&#20808;&#21069;&#30475;&#21040;&#30340;&#28304;&#20219;&#21153;&#30340;&#24179;&#22343;&#20551;&#35774;&#21644;ii&#65289;&#22312;&#26032;&#30340;&#30446;&#26631;&#20219;&#21153;&#19978;&#35757;&#32451;&#30340;&#20551;&#35774;&#12290;&#23545;&#20110;&#29305;&#23450;&#30340;&#29983;&#25104;&#35774;&#32622;&#65292;&#25105;&#20204;&#22312;0-1&#25439;&#22833;&#19979;&#23548;&#20986;&#20102;&#20004;&#31181;&#27169;&#22411;&#30340;&#26368;&#20248;&#20984;&#32452;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35745;&#31639;&#30340;&#36924;&#36817;&#65292;&#24182;&#30740;&#31350;&#20102;&#21508;&#31181;&#21442;&#25968;&#35774;&#32622;&#23545;&#26368;&#20248;&#20551;&#35774;&#12289;&#20551;&#35774;i&#65289;&#21644;&#20551;&#35774;ii&#65289;&#20043;&#38388;&#30456;&#23545;&#39118;&#38505;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#26368;&#20248;&#20998;&#31867;&#22120;&#22312;&#22522;&#20110;EEG&#21644;ECG&#30340;&#20998;&#31867;&#35774;&#32622;&#20013;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#35748;&#20026;&#21487;&#20197;&#22312;&#19981;&#35775;&#38382;&#20219;&#20309;&#21333;&#20010;&#28304;&#20219;&#21153;&#30340;&#30452;&#25509;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#35745;&#31639;&#26368;&#20248;&#20998;&#31867;&#22120;&#12290;&#26368;&#21518;&#25105;&#20204;&#35752;&#35770;&#20102;&#36827;&#19968;&#27493;&#30340;&#24212;&#29992;&#12289;&#38480;&#21046;&#21644;&#21487;&#33021;&#30340;&#26410;&#26469;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a class of models based on Fisher's Linear Discriminant (FLD) in the context of domain adaptation. The class is the convex combination of two hypotheses: i) an average hypothesis representing previously seen source tasks and ii) a hypothesis trained on a new target task. For a particular generative setting we derive the optimal convex combination of the two models under 0-1 loss, propose a computable approximation, and study the effect of various parameter settings on the relative risks between the optimal hypothesis, hypothesis i), and hypothesis ii). We demonstrate the effectiveness of the proposed optimal classifier in the context of EEG- and ECG-based classification settings and argue that the optimal classifier can be computed without access to direct information from any of the individual source tasks. We conclude by discussing further applications, limitations, and possible future directions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20960;&#20309;&#29256;&#26412;&#30340;Weisfeiler-Leman&#27979;&#35797;(GWL)&#65292;&#21487;&#20197;&#21306;&#20998;&#20960;&#20309;&#22270;&#24418;&#65292;&#25581;&#31034;&#20102;&#20851;&#38190;&#35774;&#35745;&#36873;&#25321;&#22914;&#20309;&#24433;&#21709;&#20960;&#20309;GNN&#30340;&#34920;&#29616;&#21147;</title><link>http://arxiv.org/abs/2301.09308</link><description>&lt;p&gt;
&#35770;&#20960;&#20309;&#22270;&#31070;&#32463;&#32593;&#32476;&#34920;&#29616;&#21147;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Expressive Power of Geometric Graph Neural Networks. (arXiv:2301.09308v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.09308
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20960;&#20309;&#29256;&#26412;&#30340;Weisfeiler-Leman&#27979;&#35797;(GWL)&#65292;&#21487;&#20197;&#21306;&#20998;&#20960;&#20309;&#22270;&#24418;&#65292;&#25581;&#31034;&#20102;&#20851;&#38190;&#35774;&#35745;&#36873;&#25321;&#22914;&#20309;&#24433;&#21709;&#20960;&#20309;GNN&#30340;&#34920;&#29616;&#21147;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807; Weisfeiler-Leman (WL) &#22270;&#21516;&#26500;&#27979;&#35797;&#65292;&#24050;&#32463;&#24191;&#27867;&#30740;&#31350;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476; (GNNs) &#30340;&#34920;&#29616;&#21147;&#12290;&#28982;&#32780;&#65292;&#26631;&#20934;&#30340; GNNs &#21644; WL &#26694;&#26550;&#19981;&#36866;&#29992;&#20110;&#23884;&#20837;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#30340;&#20960;&#20309;&#22270;&#24418;&#65292;&#20363;&#22914;&#29983;&#29289;&#20998;&#23376;&#12289;&#26448;&#26009;&#21644;&#20854;&#20182;&#29289;&#29702;&#31995;&#32479;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102; WL &#27979;&#35797;&#30340;&#20960;&#20309;&#29256;&#26412; (GWL)&#65292;&#20197;&#21306;&#20998;&#20960;&#20309;&#22270;&#24418;&#65292;&#21516;&#26102;&#23562;&#37325;&#24213;&#23618;&#29289;&#29702;&#23545;&#31216;&#24615;&#65306;&#25490;&#21015;&#12289;&#26059;&#36716;&#12289;&#21453;&#23556;&#21644;&#24179;&#31227;&#12290;&#25105;&#20204;&#20351;&#29992; GWL &#26469;&#34920;&#24449;&#20855;&#26377;&#19981;&#21464;&#25110;&#31561;&#21464;&#20110;&#29289;&#29702;&#23545;&#31216;&#24615;&#30340;&#20960;&#20309; GNN &#30340;&#34920;&#29616;&#21147;&#65292;&#20197;&#21306;&#20998;&#20960;&#20309;&#22270;&#24418;&#12290;GWL &#25581;&#31034;&#20102;&#20851;&#38190;&#35774;&#35745;&#36873;&#25321;&#22914;&#20309;&#24433;&#21709;&#20960;&#20309; GNN &#30340;&#34920;&#29616;&#21147;&#65306;(1) &#19981;&#21464;&#23618;&#34920;&#29616;&#21147;&#26377;&#38480;&#65292;&#22240;&#20026;&#23427;&#20204;&#26080;&#27861;&#21306;&#20998;&#19968;&#36339;&#30456;&#21516;&#30340;&#20960;&#20309;&#22270;&#24418;&#65307;(2) &#31561;&#21464;&#23618;&#36890;&#36807;&#20256;&#25773;&#23616;&#37096;&#37051;&#22495;&#20043;&#22806;&#30340;&#20960;&#20309;&#20449;&#24687;&#65292;&#21306;&#20998;&#26356;&#22823;&#31867;&#21035;&#30340;&#22270;&#24418;&#65307;(3)
&lt;/p&gt;
&lt;p&gt;
The expressive power of Graph Neural Networks (GNNs) has been studied extensively through the Weisfeiler-Leman (WL) graph isomorphism test. However, standard GNNs and the WL framework are inapplicable for geometric graphs embedded in Euclidean space, such as biomolecules, materials, and other physical systems. In this work, we propose a geometric version of the WL test (GWL) for discriminating geometric graphs while respecting the underlying physical symmetries: permutations, rotation, reflection, and translation. We use GWL to characterise the expressive power of geometric GNNs that are invariant or equivariant to physical symmetries in terms of distinguishing geometric graphs. GWL unpacks how key design choices influence geometric GNN expressivity: (1) Invariant layers have limited expressivity as they cannot distinguish one-hop identical geometric graphs; (2) Equivariant layers distinguish a larger class of graphs by propagating geometric information beyond local neighbourhoods; (3)
&lt;/p&gt;</description></item></channel></rss>