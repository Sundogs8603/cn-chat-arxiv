<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25105;&#20204;&#36890;&#36807;&#25512;&#23548;&#26680;&#30697;&#38453;&#30340;&#29305;&#24449;&#25968;&#30028;&#38480;&#65292;&#22686;&#24378;&#20102;&#26680;&#23725;&#22238;&#24402;&#30340;&#27979;&#35797;&#35823;&#24046;&#30028;&#38480;&#12290;&#23545;&#20110;&#22810;&#39033;&#24335;&#35889;&#34928;&#20943;&#30340;&#26680;&#65292;&#25105;&#20204;&#24674;&#22797;&#20102;&#20808;&#21069;&#30340;&#32467;&#26524;&#65307;&#23545;&#20110;&#25351;&#25968;&#35889;&#34928;&#20943;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#38750;&#24179;&#20961;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#29305;&#24449;&#35889;&#34928;&#20943;&#22810;&#39033;&#24335;&#30340;&#26680;&#22238;&#24402;&#22120;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#32780;&#29305;&#24449;&#35889;&#25351;&#25968;&#34928;&#20943;&#30340;&#26680;&#22238;&#24402;&#22120;&#21017;&#20855;&#26377;&#28798;&#38590;&#24615;&#30340;&#36807;&#25311;&#21512;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01297</link><description>&lt;p&gt;
&#36890;&#36807;&#29305;&#24449;&#35889;&#34920;&#24449;&#26680;&#23725;&#22238;&#24402;&#30340;&#36807;&#25311;&#21512;
&lt;/p&gt;
&lt;p&gt;
Characterizing Overfitting in Kernel Ridgeless Regression Through the Eigenspectrum
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01297
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#25512;&#23548;&#26680;&#30697;&#38453;&#30340;&#29305;&#24449;&#25968;&#30028;&#38480;&#65292;&#22686;&#24378;&#20102;&#26680;&#23725;&#22238;&#24402;&#30340;&#27979;&#35797;&#35823;&#24046;&#30028;&#38480;&#12290;&#23545;&#20110;&#22810;&#39033;&#24335;&#35889;&#34928;&#20943;&#30340;&#26680;&#65292;&#25105;&#20204;&#24674;&#22797;&#20102;&#20808;&#21069;&#30340;&#32467;&#26524;&#65307;&#23545;&#20110;&#25351;&#25968;&#35889;&#34928;&#20943;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#38750;&#24179;&#20961;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#29305;&#24449;&#35889;&#34928;&#20943;&#22810;&#39033;&#24335;&#30340;&#26680;&#22238;&#24402;&#22120;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#32780;&#29305;&#24449;&#35889;&#25351;&#25968;&#34928;&#20943;&#30340;&#26680;&#22238;&#24402;&#22120;&#21017;&#20855;&#26377;&#28798;&#38590;&#24615;&#30340;&#36807;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25512;&#23548;&#20102;&#26680;&#30697;&#38453;&#30340;&#26465;&#20214;&#25968;&#30340;&#26032;&#30028;&#38480;&#65292;&#28982;&#21518;&#21033;&#29992;&#36825;&#20123;&#30028;&#38480;&#22686;&#24378;&#20102;&#22312;&#22266;&#23450;&#36755;&#20837;&#32500;&#24230;&#30340;&#36807;&#21442;&#25968;&#21270;&#21306;&#22495;&#20013;&#26680;&#23725;&#22238;&#24402;&#30340;&#29616;&#26377;&#38750;&#28176;&#36817;&#27979;&#35797;&#35823;&#24046;&#30028;&#38480;&#12290;&#23545;&#20110;&#20855;&#26377;&#22810;&#39033;&#24335;&#35889;&#34928;&#20943;&#30340;&#26680;&#65292;&#25105;&#20204;&#24674;&#22797;&#20102;&#20808;&#21069;&#24037;&#20316;&#30340;&#30028;&#38480;&#65307;&#23545;&#20110;&#25351;&#25968;&#34928;&#20943;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#26159;&#38750;&#24179;&#20961;&#21644;&#26032;&#39062;&#30340;&#12290;&#25105;&#20204;&#23545;&#36807;&#25311;&#21512;&#30340;&#32467;&#35770;&#26159;&#21452;&#37325;&#30340;&#65306;(i) &#35889;&#34928;&#20943;&#22810;&#39033;&#24335;&#30340;&#26680;&#22238;&#24402;&#22120;&#24517;&#39035;&#22312;&#23384;&#22312;&#22122;&#22768;&#26631;&#35760;&#30340;&#35757;&#32451;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#24471;&#21040;&#24456;&#22909;&#30340;&#27867;&#21270;&#65307;&#36825;&#20123;&#27169;&#22411;&#34920;&#29616;&#20986;&#25152;&#35859;&#30340;&#28201;&#21644;&#36807;&#25311;&#21512;&#65307;(ii) &#22914;&#26524;&#20219;&#20309;&#26680;&#23725;&#22238;&#24402;&#22120;&#30340;&#29305;&#24449;&#35889;&#25351;&#25968;&#34928;&#20943;&#65292;&#21017;&#20854;&#27867;&#21270;&#24046;&#65292;&#21363;&#34920;&#29616;&#20986;&#28798;&#38590;&#24615;&#36807;&#25311;&#21512;&#12290;&#36825;&#22686;&#21152;&#20102;&#26680;&#23725;&#22238;&#24402;&#22120;&#34920;&#29616;&#20986;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#21487;&#29992;&#29305;&#24449;&#35889;&#34928;&#20943;&#27425;&#22810;&#39033;&#24335;&#30340;&#26497;&#31471;&#24773;&#20917;&#30340;&#34920;&#24449;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#32467;&#21512;&#20102;&#26032;&#30340;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;(RMT)&#12290;
&lt;/p&gt;
&lt;p&gt;
We derive new bounds for the condition number of kernel matrices, which we then use to enhance existing non-asymptotic test error bounds for kernel ridgeless regression in the over-parameterized regime for a fixed input dimension. For kernels with polynomial spectral decay, we recover the bound from previous work; for exponential decay, our bound is non-trivial and novel.   Our conclusion on overfitting is two-fold: (i) kernel regressors whose eigenspectrum decays polynomially must generalize well, even in the presence of noisy labeled training data; these models exhibit so-called tempered overfitting; (ii) if the eigenspectrum of any kernel ridge regressor decays exponentially, then it generalizes poorly, i.e., it exhibits catastrophic overfitting. This adds to the available characterization of kernel ridge regressors exhibiting benign overfitting as the extremal case where the eigenspectrum of the kernel decays sub-polynomially. Our analysis combines new random matrix theory (RMT) te
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#38024;&#23545;&#30446;&#26631;&#20989;&#25968;&#30340;&#27927;&#29260;&#26799;&#24230;&#26041;&#27861;&#26368;&#21518;&#36845;&#20195;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24357;&#21512;&#20102;&#22312;&#19981;&#21516;&#35774;&#32622;&#20013;&#26368;&#21518;&#36845;&#20195;&#30340;&#33391;&#22909;&#24615;&#33021;&#19982;&#29616;&#26377;&#29702;&#35770;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>https://arxiv.org/abs/2403.07723</link><description>&lt;p&gt;
&#20851;&#20110;&#27927;&#29260;&#26799;&#24230;&#26041;&#27861;&#30340;&#26368;&#21518;&#36845;&#20195;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Last-Iterate Convergence of Shuffling Gradient Methods
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07723
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#38024;&#23545;&#30446;&#26631;&#20989;&#25968;&#30340;&#27927;&#29260;&#26799;&#24230;&#26041;&#27861;&#26368;&#21518;&#36845;&#20195;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24357;&#21512;&#20102;&#22312;&#19981;&#21516;&#35774;&#32622;&#20013;&#26368;&#21518;&#36845;&#20195;&#30340;&#33391;&#22909;&#24615;&#33021;&#19982;&#29616;&#26377;&#29702;&#35770;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27927;&#29260;&#26799;&#24230;&#26041;&#27861;&#65292;&#20063;&#34987;&#31216;&#20026;&#26080;&#26367;&#25442;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#65292;&#22312;&#23454;&#36341;&#20013;&#34987;&#24191;&#27867;&#24212;&#29992;&#65292;&#29305;&#21035;&#21253;&#25324;&#19977;&#31181;&#27969;&#34892;&#31639;&#27861;&#65306;Random Reshuffle&#65288;RR&#65289;&#12289;Shuffle Once&#65288;SO&#65289;&#21644;Incremental Gradient&#65288;IG&#65289;&#12290;&#19982;&#32463;&#39564;&#25104;&#21151;&#30456;&#27604;&#65292;&#38271;&#26399;&#20197;&#26469;&#23545;&#20110;&#27927;&#29260;&#26799;&#24230;&#26041;&#27861;&#30340;&#29702;&#35770;&#20445;&#35777;&#24182;&#19981;&#20805;&#20998;&#20102;&#35299;&#12290;&#26368;&#36817;&#65292;&#21482;&#20026;&#20984;&#20989;&#25968;&#30340;&#24179;&#22343;&#36845;&#20195;&#21644;&#24378;&#20984;&#38382;&#39064;&#30340;&#26368;&#21518;&#36845;&#20195;&#65288;&#20197;&#24179;&#26041;&#36317;&#31163;&#20026;&#24230;&#37327;&#65289;&#24314;&#31435;&#20102;&#25910;&#25947;&#36895;&#29575;&#12290;&#28982;&#32780;&#65292;&#24403;&#23558;&#20989;&#25968;&#20540;&#24046;&#20316;&#20026;&#25910;&#25947;&#20934;&#21017;&#26102;&#65292;&#29616;&#26377;&#29702;&#35770;&#26080;&#27861;&#35299;&#37322;&#22312;&#19981;&#21516;&#35774;&#32622;&#20013;&#65288;&#20363;&#22914;&#21463;&#32422;&#26463;&#30340;&#20248;&#21270;&#65289;&#26368;&#21518;&#36845;&#20195;&#30340;&#33391;&#22909;&#24615;&#33021;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#31181;&#23454;&#36341;&#19982;&#29702;&#35770;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#25105;&#20204;&#38024;&#23545;&#30446;&#26631;&#20989;&#25968;&#35777;&#26126;&#20102;&#27927;&#29260;&#26799;&#24230;&#26041;&#27861;&#26368;&#21518;&#36845;&#20195;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07723v1 Announce Type: new  Abstract: Shuffling gradient methods, which are also known as stochastic gradient descent (SGD) without replacement, are widely implemented in practice, particularly including three popular algorithms: Random Reshuffle (RR), Shuffle Once (SO), and Incremental Gradient (IG). Compared to the empirical success, the theoretical guarantee of shuffling gradient methods was not well-understanding for a long time. Until recently, the convergence rates had just been established for the average iterate for convex functions and the last iterate for strongly convex problems (using squared distance as the metric). However, when using the function value gap as the convergence criterion, existing theories cannot interpret the good performance of the last iterate in different settings (e.g., constrained optimization). To bridge this gap between practice and theory, we prove last-iterate convergence rates for shuffling gradient methods with respect to the objectiv
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#30561;&#30496;&#33218;&#20915;&#31574;&#38382;&#39064;&#30340;&#25509;&#36817;&#26368;&#20248;&#27599;&#27425;&#34892;&#21160;&#36951;&#25022;&#30028;&#65292;&#36890;&#36807;&#30452;&#25509;&#26368;&#23567;&#21270;&#27599;&#27425;&#34892;&#21160;&#36951;&#25022;&#65292;&#20351;&#29992;Generalized EXP3&#12289;EXP3-IX&#21644;Tsallis entropy&#19979;&#30340;FTRL&#26041;&#27861;&#65292;&#33719;&#24471;&#20102;&#36739;&#20043;&#29616;&#26377;&#26041;&#27861;&#26356;&#22909;&#30340;&#30028;&#12290;</title><link>https://arxiv.org/abs/2403.01315</link><description>&lt;p&gt;
&#30561;&#30496;&#33218;&#20915;&#31574;&#38382;&#39064;&#20013;&#25509;&#36817;&#26368;&#20248;&#30340;&#27599;&#27425;&#34892;&#21160;&#36951;&#25022;&#30028;
&lt;/p&gt;
&lt;p&gt;
Near-optimal Per-Action Regret Bounds for Sleeping Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01315
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#30561;&#30496;&#33218;&#20915;&#31574;&#38382;&#39064;&#30340;&#25509;&#36817;&#26368;&#20248;&#27599;&#27425;&#34892;&#21160;&#36951;&#25022;&#30028;&#65292;&#36890;&#36807;&#30452;&#25509;&#26368;&#23567;&#21270;&#27599;&#27425;&#34892;&#21160;&#36951;&#25022;&#65292;&#20351;&#29992;Generalized EXP3&#12289;EXP3-IX&#21644;Tsallis entropy&#19979;&#30340;FTRL&#26041;&#27861;&#65292;&#33719;&#24471;&#20102;&#36739;&#20043;&#29616;&#26377;&#26041;&#27861;&#26356;&#22909;&#30340;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25512;&#23548;&#20102;&#38024;&#23545;&#30561;&#30496;&#33218;&#20915;&#31574;&#38382;&#39064;&#30340;&#25509;&#36817;&#26368;&#20248;&#27599;&#27425;&#34892;&#21160;&#36951;&#25022;&#30028;&#65292;&#20854;&#20013;&#25932;&#25163;&#36873;&#25321;&#27599;&#36718;&#21487;&#29992;&#33218;&#30340;&#38598;&#21512;&#21644;&#23427;&#20204;&#30340;&#25439;&#22833;&#12290;&#22312;&#27599;&#36718;&#33267;&#22810;&#26377; $A$ &#20010;&#21487;&#29992;&#33218;&#30340; $K$ &#20010;&#24635;&#33218;&#30340;&#24773;&#20917;&#19979;&#65292;&#24050;&#30693;&#30340;&#26368;&#22909;&#19978;&#30028;&#20026; $O(K\sqrt{TA\ln{K}})$&#65292;&#36890;&#36807;&#38388;&#25509;&#26368;&#23567;&#21270;&#20869;&#37096;&#30561;&#30496;&#36951;&#25022;&#33719;&#24471;&#12290;&#19982;&#26497;&#23567;&#20540; $\Omega(\sqrt{TA})$ &#19979;&#30028;&#30456;&#27604;&#65292;&#36825;&#20010;&#19978;&#30028;&#21253;&#21547;&#39069;&#22806;&#30340;&#20056;&#25968;&#22240;&#23376; $K\ln{K}$&#12290;&#25105;&#20204;&#36890;&#36807;&#30452;&#25509;&#26368;&#23567;&#21270;&#27599;&#27425;&#34892;&#21160;&#36951;&#25022;&#65292;&#20351;&#29992;EXP3&#12289;EXP3-IX&#21644;&#24102;&#26377;Tsallis&#29109;&#30340;FTRL&#30340;&#25512;&#24191;&#29256;&#26412;&#65292;&#20174;&#32780;&#33719;&#24471;&#20102;&#39034;&#24207;&#20026; $O(\sqrt{TA\ln{K}})$ &#21644; $O(\sqrt{T\sqrt{AK}})$ &#30340;&#25509;&#36817;&#26368;&#20248;&#30028;&#12290;&#25105;&#20204;&#23558;&#32467;&#26524;&#25193;&#23637;&#21040;&#20102;&#20174;&#30561;&#30496;&#19987;&#23478;&#33719;&#24471;&#24314;&#35758;&#30340;&#33218;&#20915;&#31574;&#38382;&#39064;&#35774;&#32622;&#65292;&#21516;&#26102;&#25512;&#24191;&#20102;EXP4&#12290;&#36825;&#20026;&#29616;&#26377;&#30340;&#22810;&#20010;&#33258;&#36866;&#24212;&#21644;&#36319;&#36394;&#36951;&#25022;&#30028;&#30340;&#26032;&#35777;&#26126;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01315v1 Announce Type: new  Abstract: We derive near-optimal per-action regret bounds for sleeping bandits, in which both the sets of available arms and their losses in every round are chosen by an adversary. In a setting with $K$ total arms and at most $A$ available arms in each round over $T$ rounds, the best known upper bound is $O(K\sqrt{TA\ln{K}})$, obtained indirectly via minimizing internal sleeping regrets. Compared to the minimax $\Omega(\sqrt{TA})$ lower bound, this upper bound contains an extra multiplicative factor of $K\ln{K}$. We address this gap by directly minimizing the per-action regret using generalized versions of EXP3, EXP3-IX and FTRL with Tsallis entropy, thereby obtaining near-optimal bounds of order $O(\sqrt{TA\ln{K}})$ and $O(\sqrt{T\sqrt{AK}})$. We extend our results to the setting of bandits with advice from sleeping experts, generalizing EXP4 along the way. This leads to new proofs for a number of existing adaptive and tracking regret bounds for 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#25968;&#25454;&#38598;&#29305;&#24615;&#37327;&#36523;&#23450;&#21046;&#30340;&#36817;&#20284;&#20844;&#24179;&#24615;-&#20934;&#30830;&#24615;&#26435;&#34913;&#26354;&#32447;&#35745;&#31639;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#20943;&#36731;&#35757;&#32451;&#22810;&#20010;&#27169;&#22411;&#30340;&#35745;&#31639;&#36127;&#25285;&#24182;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#32479;&#35745;&#20445;&#35777;</title><link>https://arxiv.org/abs/2402.17106</link><description>&lt;p&gt;
&#25968;&#25454;&#38598;&#20844;&#24179;&#24615;&#65306;&#22312;&#24744;&#30340;&#25968;&#25454;&#19978;&#23454;&#29616;&#20855;&#26377;&#25928;&#29992;&#20445;&#35777;&#30340;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Dataset Fairness: Achievable Fairness on Your Data With Utility Guarantees
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17106
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#25968;&#25454;&#38598;&#29305;&#24615;&#37327;&#36523;&#23450;&#21046;&#30340;&#36817;&#20284;&#20844;&#24179;&#24615;-&#20934;&#30830;&#24615;&#26435;&#34913;&#26354;&#32447;&#35745;&#31639;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#20943;&#36731;&#35757;&#32451;&#22810;&#20010;&#27169;&#22411;&#30340;&#35745;&#31639;&#36127;&#25285;&#24182;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#32479;&#35745;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#20844;&#24179;&#24615;&#20013;&#65292;&#35757;&#32451;&#33021;&#22815;&#26368;&#23567;&#21270;&#19981;&#21516;&#25935;&#24863;&#32676;&#20307;&#20043;&#38388;&#24046;&#24322;&#30340;&#27169;&#22411;&#36890;&#24120;&#20250;&#23548;&#33268;&#20934;&#30830;&#24615;&#19979;&#38477;&#65292;&#36825;&#31181;&#29616;&#35937;&#34987;&#31216;&#20026;&#20844;&#24179;&#24615;-&#20934;&#30830;&#24615;&#26435;&#34913;&#12290;&#36825;&#31181;&#26435;&#34913;&#30340;&#20005;&#37325;&#31243;&#24230;&#22522;&#26412;&#21462;&#20915;&#20110;&#25968;&#25454;&#38598;&#30340;&#29305;&#24615;&#65292;&#22914;&#25968;&#25454;&#38598;&#30340;&#19981;&#22343;&#34913;&#25110;&#20559;&#35265;&#12290;&#22240;&#27492;&#65292;&#22312;&#25968;&#25454;&#38598;&#20043;&#38388;&#20351;&#29992;&#32479;&#19968;&#30340;&#20844;&#24179;&#24615;&#35201;&#27714;&#20173;&#28982;&#20540;&#24471;&#24576;&#30097;&#65292;&#24182;&#19988;&#24448;&#24448;&#20250;&#23548;&#33268;&#25928;&#29992;&#26497;&#20302;&#30340;&#27169;&#22411;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#21333;&#20010;&#25968;&#25454;&#38598;&#37327;&#36523;&#23450;&#21046;&#30340;&#36817;&#20284;&#20844;&#24179;&#24615;-&#20934;&#30830;&#24615;&#26435;&#34913;&#26354;&#32447;&#30340;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#25903;&#25345;&#20005;&#26684;&#30340;&#32479;&#35745;&#20445;&#35777;&#12290;&#36890;&#36807;&#21033;&#29992;You-Only-Train-Once&#65288;YOTO&#65289;&#26694;&#26550;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20943;&#36731;&#20102;&#22312;&#36924;&#36817;&#26435;&#34913;&#26354;&#32447;&#26102;&#38656;&#35201;&#35757;&#32451;&#22810;&#20010;&#27169;&#22411;&#30340;&#35745;&#31639;&#36127;&#25285;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#35813;&#26354;&#32447;&#21608;&#22260;&#24341;&#20837;&#32622;&#20449;&#21306;&#38388;&#26469;&#37327;&#21270;&#25105;&#20204;&#36817;&#20284;&#20540;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17106v1 Announce Type: cross  Abstract: In machine learning fairness, training models which minimize disparity across different sensitive groups often leads to diminished accuracy, a phenomenon known as the fairness-accuracy trade-off. The severity of this trade-off fundamentally depends on dataset characteristics such as dataset imbalances or biases. Therefore using a uniform fairness requirement across datasets remains questionable and can often lead to models with substantially low utility. To address this, we present a computationally efficient approach to approximate the fairness-accuracy trade-off curve tailored to individual datasets, backed by rigorous statistical guarantees. By utilizing the You-Only-Train-Once (YOTO) framework, our approach mitigates the computational burden of having to train multiple models when approximating the trade-off curve. Moreover, we quantify the uncertainty in our approximation by introducing confidence intervals around this curve, offe
&lt;/p&gt;</description></item><item><title>&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#23558;&#25299;&#25169;&#29305;&#24449;&#24341;&#20837;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#21487;&#20316;&#20026;&#22270;&#34920;&#31034;&#23398;&#20064;&#21644;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#30340;&#34917;&#20805;&#65292;&#32473;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#29615;&#22659;&#25552;&#20379;&#20102;&#33258;&#28982;&#36873;&#25321;&#12290;&#26412;&#25991;&#35752;&#35770;&#20102;&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#24320;&#25918;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26426;&#20250;&#12290;</title><link>https://arxiv.org/abs/2402.08871</link><description>&lt;p&gt;
&#20301;&#32622;&#35770;&#25991;&#65306;&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#25361;&#25112;&#19982;&#26426;&#36935;
&lt;/p&gt;
&lt;p&gt;
Position Paper: Challenges and Opportunities in Topological Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08871
&lt;/p&gt;
&lt;p&gt;
&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#23558;&#25299;&#25169;&#29305;&#24449;&#24341;&#20837;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#21487;&#20316;&#20026;&#22270;&#34920;&#31034;&#23398;&#20064;&#21644;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#30340;&#34917;&#20805;&#65292;&#32473;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#29615;&#22659;&#25552;&#20379;&#20102;&#33258;&#28982;&#36873;&#25321;&#12290;&#26412;&#25991;&#35752;&#35770;&#20102;&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#24320;&#25918;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#26159;&#19968;&#20010;&#24555;&#36895;&#21457;&#23637;&#30340;&#39046;&#22495;&#65292;&#23427;&#21033;&#29992;&#25299;&#25169;&#29305;&#24449;&#26469;&#29702;&#35299;&#21644;&#35774;&#35745;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#12290;&#26412;&#25991;&#35748;&#20026;&#65292;&#36890;&#36807;&#34701;&#20837;&#25299;&#25169;&#27010;&#24565;&#65292;&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#21487;&#20197;&#34917;&#20805;&#22270;&#34920;&#31034;&#23398;&#20064;&#21644;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#65292;&#24182;&#25104;&#20026;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#29615;&#22659;&#19979;&#30340;&#33258;&#28982;&#36873;&#25321;&#12290;&#20026;&#27492;&#65292;&#26412;&#25991;&#35752;&#35770;&#20102;&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#24320;&#25918;&#38382;&#39064;&#65292;&#28085;&#30422;&#20102;&#20174;&#23454;&#29992;&#30410;&#22788;&#21040;&#29702;&#35770;&#22522;&#30784;&#30340;&#21508;&#20010;&#26041;&#38754;&#12290;&#38024;&#23545;&#27599;&#20010;&#38382;&#39064;&#65292;&#23427;&#27010;&#36848;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#21644;&#26410;&#26469;&#30340;&#30740;&#31350;&#26426;&#20250;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#20063;&#26159;&#23545;&#31185;&#23398;&#30028;&#30340;&#36992;&#35831;&#65292;&#24076;&#26395;&#31215;&#26497;&#21442;&#19982;&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#30740;&#31350;&#65292;&#24320;&#21457;&#36825;&#20010;&#26032;&#20852;&#39046;&#22495;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08871v1 Announce Type: new Abstract: Topological deep learning (TDL) is a rapidly evolving field that uses topological features to understand and design deep learning models. This paper posits that TDL may complement graph representation learning and geometric deep learning by incorporating topological concepts, and can thus provide a natural choice for various machine learning settings. To this end, this paper discusses open problems in TDL, ranging from practical benefits to theoretical foundations. For each problem, it outlines potential solutions and future research opportunities. At the same time, this paper serves as an invitation to the scientific community to actively participate in TDL research to unlock the potential of this emerging field.
&lt;/p&gt;</description></item><item><title>&#38408;&#20540;&#21644;&#37325;&#26032;&#24402;&#19968;&#21270;Oja&#31639;&#27861;&#30340;&#36755;&#20986;&#21487;&#33719;&#24471;&#19968;&#20010;&#25509;&#36817;&#26368;&#20248;&#30340;&#38169;&#35823;&#29575;&#65292;&#19982;&#26410;&#32463;&#38408;&#20540;&#22788;&#29702;&#30340;Oja&#21521;&#37327;&#30456;&#27604;&#65292;&#36825;&#22823;&#22823;&#20943;&#23567;&#20102;&#35823;&#24046;&#12290;</title><link>https://arxiv.org/abs/2402.07240</link><description>&lt;p&gt;
&#38408;&#20540;Oja&#26159;&#21542;&#36866;&#29992;&#20110;&#31232;&#30095;PCA&#65311;
&lt;/p&gt;
&lt;p&gt;
Thresholded Oja does Sparse PCA?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07240
&lt;/p&gt;
&lt;p&gt;
&#38408;&#20540;&#21644;&#37325;&#26032;&#24402;&#19968;&#21270;Oja&#31639;&#27861;&#30340;&#36755;&#20986;&#21487;&#33719;&#24471;&#19968;&#20010;&#25509;&#36817;&#26368;&#20248;&#30340;&#38169;&#35823;&#29575;&#65292;&#19982;&#26410;&#32463;&#38408;&#20540;&#22788;&#29702;&#30340;Oja&#21521;&#37327;&#30456;&#27604;&#65292;&#36825;&#22823;&#22823;&#20943;&#23567;&#20102;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#24403;&#27604;&#20540;$d/n \rightarrow c &gt; 0$&#26102;&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#30340;&#38382;&#39064;&#12290;&#22312;&#31163;&#32447;&#35774;&#32622;&#19979;&#65292;&#20851;&#20110;&#31232;&#30095;PCA&#30340;&#26368;&#20248;&#29575;&#24050;&#32463;&#26377;&#24456;&#22810;&#30740;&#31350;&#65292;&#20854;&#20013;&#25152;&#26377;&#25968;&#25454;&#37117;&#21487;&#20197;&#29992;&#20110;&#22810;&#27425;&#20256;&#36882;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#24403;&#20154;&#21475;&#29305;&#24449;&#21521;&#37327;&#26159;$s$-&#31232;&#30095;&#26102;&#65292;&#20855;&#26377;$O(d)$&#23384;&#20648;&#21644;$O(nd)$&#26102;&#38388;&#22797;&#26434;&#24230;&#30340;&#27969;&#31639;&#27861;&#36890;&#24120;&#35201;&#27714;&#24378;&#21021;&#22987;&#21270;&#26465;&#20214;&#65292;&#21542;&#21017;&#20250;&#26377;&#27425;&#20248;&#38169;&#35823;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#31639;&#27861;&#65292;&#23545;Oja&#31639;&#27861;&#30340;&#36755;&#20986;&#65288;Oja&#21521;&#37327;&#65289;&#36827;&#34892;&#38408;&#20540;&#21644;&#37325;&#26032;&#24402;&#19968;&#21270;&#65292;&#20174;&#32780;&#33719;&#24471;&#25509;&#36817;&#26368;&#20248;&#30340;&#38169;&#35823;&#29575;&#12290;&#36825;&#38750;&#24120;&#20196;&#20154;&#24778;&#35766;&#65292;&#22240;&#20026;&#27809;&#26377;&#38408;&#20540;&#65292;Oja&#21521;&#37327;&#30340;&#35823;&#24046;&#24456;&#22823;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#38598;&#20013;&#22312;&#38480;&#21046;&#26410;&#24402;&#19968;&#21270;&#30340;Oja&#21521;&#37327;&#30340;&#39033;&#19978;&#65292;&#36825;&#28041;&#21450;&#23558;&#19968;&#32452;&#29420;&#31435;&#38543;&#26426;&#30697;&#38453;&#30340;&#20056;&#31215;&#22312;&#38543;&#26426;&#21021;&#22987;&#21521;&#37327;&#19978;&#30340;&#25237;&#24433;&#12290; &#36825;&#26159;&#38750;&#24179;&#20961;&#19988;&#26032;&#39062;&#30340;&#65292;&#22240;&#20026;&#20197;&#21069;&#30340;Oja&#31639;&#27861;&#20998;&#26512;&#27809;&#26377;&#32771;&#34385;&#36825;&#19968;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.07240v2 Announce Type: cross  Abstract: We consider the problem of Sparse Principal Component Analysis (PCA) when the ratio $d/n \rightarrow c &gt; 0$. There has been a lot of work on optimal rates on sparse PCA in the offline setting, where all the data is available for multiple passes. In contrast, when the population eigenvector is $s$-sparse, streaming algorithms that have $O(d)$ storage and $O(nd)$ time complexity either typically require strong initialization conditions or have a suboptimal error. We show that a simple algorithm that thresholds and renormalizes the output of Oja's algorithm (the Oja vector) obtains a near-optimal error rate. This is very surprising because, without thresholding, the Oja vector has a large error. Our analysis centers around bounding the entries of the unnormalized Oja vector, which involves the projection of a product of independent random matrices on a random initial vector. This is nontrivial and novel since previous analyses of Oja's al
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20381;&#36182;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#23574;&#38160;&#29575;&#65292;&#20027;&#35201;&#26159;&#20026;&#20102;&#36991;&#20813;&#26679;&#26412;&#22823;&#23567;&#32553;&#20943;&#23545;&#26041;&#24046;&#20135;&#29983;&#24433;&#21709;&#12290;&#24403;&#20551;&#35774;&#31867;&#21035;&#30340;&#25299;&#25169;&#32467;&#26500;&#31526;&#21512;&#26576;&#20123;&#26465;&#20214;&#26102;&#65292;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#32773;&#30340;&#24615;&#33021;&#19982;&#31867;&#21035;&#30340;&#22797;&#26434;&#24615;&#21644;&#20108;&#38454;&#32479;&#35745;&#37327;&#26377;&#20851;&#12290;</title><link>https://arxiv.org/abs/2402.05928</link><description>&lt;p&gt;
&#20381;&#36182;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#23574;&#38160;&#29575;&#65306;&#36991;&#20813;&#26679;&#26412;&#22823;&#23567;&#32553;&#20943;&#30340;&#24179;&#26041;&#25439;&#22833;
&lt;/p&gt;
&lt;p&gt;
Sharp Rates in Dependent Learning Theory: Avoiding Sample Size Deflation for the Square Loss
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05928
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20381;&#36182;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#23574;&#38160;&#29575;&#65292;&#20027;&#35201;&#26159;&#20026;&#20102;&#36991;&#20813;&#26679;&#26412;&#22823;&#23567;&#32553;&#20943;&#23545;&#26041;&#24046;&#20135;&#29983;&#24433;&#21709;&#12290;&#24403;&#20551;&#35774;&#31867;&#21035;&#30340;&#25299;&#25169;&#32467;&#26500;&#31526;&#21512;&#26576;&#20123;&#26465;&#20214;&#26102;&#65292;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#32773;&#30340;&#24615;&#33021;&#19982;&#31867;&#21035;&#30340;&#22797;&#26434;&#24615;&#21644;&#20108;&#38454;&#32479;&#35745;&#37327;&#26377;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20381;&#36182;&#24615;&#65288;&#946;-&#28151;&#21512;&#65289;&#25968;&#25454;&#21644;&#24179;&#26041;&#25439;&#22833;&#30340;&#32479;&#35745;&#23398;&#20064;&#65292;&#22312;&#19968;&#20010;&#20551;&#35774;&#31867;&#21035;&#934;_p&#30340;&#23376;&#38598;F&#20013;&#65292;&#20854;&#20013;&#934;_p&#26159;&#33539;&#25968;&#8741;f&#8741;_&#934;_p&#8801;sup_m&#8805;1 m^{-1/p}&#8741;f&#8741;_L^m&#65292;&#20854;&#20013;p&#8712;[2&#65292;&#8734;]&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21160;&#26426;&#26159;&#22312;&#20855;&#26377;&#20381;&#36182;&#24615;&#25968;&#25454;&#30340;&#23398;&#20064;&#20013;&#23547;&#25214;&#23574;&#38160;&#30340;&#22122;&#22768;&#20132;&#20114;&#39033;&#25110;&#26041;&#24046;&#20195;&#29702;&#12290;&#22312;&#27809;&#26377;&#20219;&#20309;&#21487;&#23454;&#29616;&#24615;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#20856;&#22411;&#30340;&#38750;&#28176;&#36817;&#32467;&#26524;&#26174;&#31034;&#20986;&#26041;&#24046;&#20195;&#29702;&#36890;&#36807;&#24213;&#23618;&#21327;&#21464;&#37327;&#36807;&#31243;&#30340;&#28151;&#21512;&#26102;&#38388;&#36827;&#34892;&#20102;&#20056;&#31215;&#32553;&#20943;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#21482;&#35201;&#22312;&#25105;&#20204;&#30340;&#20551;&#35774;&#31867;&#21035;F&#19978;&#65292;L^2&#21644;&#934;_p&#30340;&#25299;&#25169;&#26159;&#21487;&#27604;&#36739;&#30340;&#65292;&#21363;&#934;_p&#26159;&#19968;&#20010;&#24369;&#20122;&#39640;&#26031;&#31867;&#21035;&#65306;&#8741;f&#8741;_&#934;_p&#8818;&#8741;f&#8741;_L^2^&#951;&#65292;&#20854;&#20013;&#951;&#8712;(0&#65292;1]&#65292;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#32773;&#22312;&#20854;&#20027;&#23548;&#39033;&#20013;&#21482;&#23454;&#29616;&#20102;&#19968;&#31181;&#21482;&#20381;&#36182;&#20110;&#31867;&#21035;&#22797;&#26434;&#24615;&#21644;&#20108;&#38454;&#32479;&#35745;&#37327;&#30340;&#36895;&#29575;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#35768;&#22810;&#20381;&#36182;&#24615;&#25968;&#25454;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we study statistical learning with dependent ($\beta$-mixing) data and square loss in a hypothesis class $\mathscr{F}\subset L_{\Psi_p}$ where $\Psi_p$ is the norm $\|f\|_{\Psi_p} \triangleq \sup_{m\geq 1} m^{-1/p} \|f\|_{L^m} $ for some $p\in [2,\infty]$. Our inquiry is motivated by the search for a sharp noise interaction term, or variance proxy, in learning with dependent data. Absent any realizability assumption, typical non-asymptotic results exhibit variance proxies that are deflated \emph{multiplicatively} by the mixing time of the underlying covariates process. We show that whenever the topologies of $L^2$ and $\Psi_p$ are comparable on our hypothesis class $\mathscr{F}$ -- that is, $\mathscr{F}$ is a weakly sub-Gaussian class: $\|f\|_{\Psi_p} \lesssim \|f\|_{L^2}^\eta$ for some $\eta\in (0,1]$ -- the empirical risk minimizer achieves a rate that only depends on the complexity of the class and second order statistics in its leading term. Our result holds whether t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; ROBAI &#30340;&#31639;&#27861;&#65292;&#26088;&#22312;&#24555;&#36895;&#35782;&#21035;&#24182;&#36873;&#25321;&#26368;&#20339;&#33218;&#65292;&#24182;&#22312;&#19968;&#31995;&#21015;&#36830;&#32493;&#22238;&#21512;&#20013;&#26368;&#22823;&#21270;&#22870;&#21169;&#12290;&#35813;&#31639;&#27861;&#22312;&#39044;&#23450;&#20572;&#27490;&#26102;&#38388;&#21644;&#33258;&#36866;&#24212;&#20572;&#27490;&#26102;&#38388;&#35201;&#27714;&#19979;&#22343;&#23454;&#29616;&#20102;&#28176;&#36827;&#26368;&#20248;&#36951;&#25022;&#65292;&#24182;&#19988;&#22312;&#39044;&#23450;&#20572;&#27490;&#26102;&#38388;&#19979;&#20165;&#38656; $\mathcal{O}(\log T)$ &#22238;&#21512;&#21363;&#21487;&#36873;&#25321;&#26368;&#20339;&#33218;&#65292;&#22312;&#33258;&#36866;&#24212;&#20572;&#27490;&#26102;&#38388;&#19979;&#20165;&#38656; $\mathcal{O}(\log^2 T)$ &#22238;&#21512;&#21363;&#21487;&#36873;&#25321;&#26368;&#20339;&#33218;&#12290;</title><link>http://arxiv.org/abs/2309.00591</link><description>&lt;p&gt;
&#24555;&#36895;&#21644;&#36951;&#25022;&#26368;&#23567;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#65306;&#22522;&#26412;&#38480;&#21046;&#21644;&#20302;&#22797;&#26434;&#24230;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Fast and Regret Optimal Best Arm Identification: Fundamental Limits and Low-Complexity Algorithms. (arXiv:2309.00591v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00591
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; ROBAI &#30340;&#31639;&#27861;&#65292;&#26088;&#22312;&#24555;&#36895;&#35782;&#21035;&#24182;&#36873;&#25321;&#26368;&#20339;&#33218;&#65292;&#24182;&#22312;&#19968;&#31995;&#21015;&#36830;&#32493;&#22238;&#21512;&#20013;&#26368;&#22823;&#21270;&#22870;&#21169;&#12290;&#35813;&#31639;&#27861;&#22312;&#39044;&#23450;&#20572;&#27490;&#26102;&#38388;&#21644;&#33258;&#36866;&#24212;&#20572;&#27490;&#26102;&#38388;&#35201;&#27714;&#19979;&#22343;&#23454;&#29616;&#20102;&#28176;&#36827;&#26368;&#20248;&#36951;&#25022;&#65292;&#24182;&#19988;&#22312;&#39044;&#23450;&#20572;&#27490;&#26102;&#38388;&#19979;&#20165;&#38656; $\mathcal{O}(\log T)$ &#22238;&#21512;&#21363;&#21487;&#36873;&#25321;&#26368;&#20339;&#33218;&#65292;&#22312;&#33258;&#36866;&#24212;&#20572;&#27490;&#26102;&#38388;&#19979;&#20165;&#38656; $\mathcal{O}(\log^2 T)$ &#22238;&#21512;&#21363;&#21487;&#36873;&#25321;&#26368;&#20339;&#33218;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20855;&#26377;&#21452;&#37325;&#30446;&#26631;&#30340;&#38543;&#26426;&#22810;&#33218;&#32769;&#34382;&#26426;(MAB)&#38382;&#39064;&#65306;(i) &#24555;&#36895;&#35782;&#21035;&#24182;&#36873;&#25321;&#26368;&#20339;&#33218;&#65292;&#20197;&#21450;(ii) &#22312;&#19968;&#31995;&#21015;T&#20010;&#36830;&#32493;&#22238;&#21512;&#20013;&#26368;&#22823;&#21270;&#22870;&#21169;&#12290;&#23613;&#31649;&#27599;&#20010;&#30446;&#26631;&#37117;&#24050;&#32463;&#24471;&#21040;&#20102;&#29420;&#31435;&#30340;&#28145;&#20837;&#30740;&#31350;&#65292;&#21363;(i)&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#21644;(ii)&#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#65292;&#20294;&#26159;&#21516;&#26102;&#23454;&#29616;&#36825;&#20004;&#20010;&#30446;&#26631;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#38382;&#39064;&#65292;&#23613;&#31649;&#23427;&#22312;&#23454;&#36341;&#20013;&#38750;&#24120;&#37325;&#35201;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#8220;&#36951;&#25022;&#26368;&#23567;&#21270;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#8221;(ROBAI)&#65292;&#26088;&#22312;&#23454;&#29616;&#36825;&#20004;&#20010;&#21452;&#37325;&#30446;&#26631;&#12290;&#20026;&#20102;&#35299;&#20915;&#20855;&#26377;&#39044;&#23450;&#20572;&#27490;&#26102;&#38388;&#21644;&#33258;&#36866;&#24212;&#20572;&#27490;&#26102;&#38388;&#35201;&#27714;&#30340;ROBAI&#65292;&#25105;&#20204;&#20998;&#21035;&#25552;&#20986;&#20102;$\mathsf{EOCP}$&#31639;&#27861;&#21450;&#20854;&#21464;&#20307;&#65292;&#19981;&#20165;&#22312;&#39640;&#26031;&#32769;&#34382;&#26426;&#21644;&#19968;&#33324;&#32769;&#34382;&#26426;&#20013;&#36798;&#21040;&#20102;&#28176;&#36827;&#26368;&#20248;&#36951;&#25022;&#65292;&#32780;&#19988;&#22312;&#39044;&#23450;&#20572;&#27490;&#26102;&#38388;&#19979;&#65292;&#22312;$\mathcal{O}(\log T)$&#22238;&#21512;&#20869;&#36873;&#25321;&#20102;&#26368;&#20339;&#33218;&#65292;&#22312;&#33258;&#36866;&#24212;&#20572;&#27490;&#26102;&#38388;&#19979;&#65292;&#36873;&#25321;&#20102;&#26368;&#20339;&#33218;&#22312;$\mathcal{O}(\log^2 T)$&#22238;&#21512;&#20869;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper considers a stochastic multi-armed bandit (MAB) problem with dual objectives: (i) quick identification and commitment to the optimal arm, and (ii) reward maximization throughout a sequence of $T$ consecutive rounds. Though each objective has been individually well-studied, i.e., best arm identification for (i) and regret minimization for (ii), the simultaneous realization of both objectives remains an open problem, despite its practical importance. This paper introduces \emph{Regret Optimal Best Arm Identification} (ROBAI) which aims to achieve these dual objectives. To solve ROBAI with both pre-determined stopping time and adaptive stopping time requirements, we present the $\mathsf{EOCP}$ algorithm and its variants respectively, which not only achieve asymptotic optimal regret in both Gaussian and general bandits, but also commit to the optimal arm in $\mathcal{O}(\log T)$ rounds with pre-determined stopping time and $\mathcal{O}(\log^2 T)$ rounds with adaptive stopping ti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#31070;&#32463;&#32593;&#32476;&#21644;&#26497;&#20540;&#29702;&#35770;&#30340;EQRN&#27169;&#22411;&#65292;&#23427;&#33021;&#22815;&#22312;&#23384;&#22312;&#22797;&#26434;&#39044;&#27979;&#21464;&#37327;&#30456;&#20851;&#24615;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#22806;&#25512;&#65292;&#24182;&#19988;&#33021;&#22815;&#24212;&#29992;&#20110;&#27946;&#27700;&#39118;&#38505;&#39044;&#27979;&#20013;&#65292;&#25552;&#20379;&#19968;&#22825;&#21069;&#22238;&#24402;&#27700;&#24179;&#21644;&#36229;&#20986;&#27010;&#29575;&#30340;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2208.07590</link><description>&lt;p&gt;
&#26497;&#31471;&#20998;&#20301;&#25968;&#22238;&#24402;&#30340;&#31070;&#32463;&#32593;&#32476;&#19982;&#27946;&#27700;&#39118;&#38505;&#39044;&#27979;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Neural Networks for Extreme Quantile Regression with an Application to Forecasting of Flood Risk. (arXiv:2208.07590v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.07590
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#31070;&#32463;&#32593;&#32476;&#21644;&#26497;&#20540;&#29702;&#35770;&#30340;EQRN&#27169;&#22411;&#65292;&#23427;&#33021;&#22815;&#22312;&#23384;&#22312;&#22797;&#26434;&#39044;&#27979;&#21464;&#37327;&#30456;&#20851;&#24615;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#22806;&#25512;&#65292;&#24182;&#19988;&#33021;&#22815;&#24212;&#29992;&#20110;&#27946;&#27700;&#39118;&#38505;&#39044;&#27979;&#20013;&#65292;&#25552;&#20379;&#19968;&#22825;&#21069;&#22238;&#24402;&#27700;&#24179;&#21644;&#36229;&#20986;&#27010;&#29575;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#26497;&#31471;&#20107;&#20214;&#30340;&#39118;&#38505;&#35780;&#20272;&#38656;&#35201;&#20934;&#30830;&#20272;&#35745;&#36229;&#20986;&#21382;&#21490;&#35266;&#27979;&#33539;&#22260;&#30340;&#39640;&#20998;&#20301;&#25968;&#12290;&#24403;&#39118;&#38505;&#20381;&#36182;&#20110;&#35266;&#27979;&#39044;&#27979;&#21464;&#37327;&#30340;&#20540;&#26102;&#65292;&#22238;&#24402;&#25216;&#26415;&#29992;&#20110;&#22312;&#39044;&#27979;&#31354;&#38388;&#20013;&#36827;&#34892;&#25554;&#20540;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;EQRN&#27169;&#22411;&#65292;&#23427;&#23558;&#31070;&#32463;&#32593;&#32476;&#21644;&#26497;&#20540;&#29702;&#35770;&#30340;&#24037;&#20855;&#32467;&#21512;&#36215;&#26469;&#65292;&#24418;&#25104;&#19968;&#31181;&#33021;&#22815;&#22312;&#22797;&#26434;&#39044;&#27979;&#21464;&#37327;&#30456;&#20851;&#24615;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#22806;&#25512;&#30340;&#26041;&#27861;&#12290;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#33258;&#28982;&#22320;&#23558;&#25968;&#25454;&#20013;&#30340;&#38468;&#21152;&#32467;&#26500;&#32435;&#20837;&#20854;&#20013;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;EQRN&#30340;&#24490;&#29615;&#29256;&#26412;&#65292;&#33021;&#22815;&#25429;&#25417;&#26102;&#38388;&#24207;&#21015;&#20013;&#22797;&#26434;&#30340;&#39034;&#24207;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#26041;&#27861;&#24212;&#29992;&#20110;&#29790;&#22763;Aare&#27969;&#22495;&#30340;&#27946;&#27700;&#39118;&#38505;&#39044;&#27979;&#12290;&#23427;&#21033;&#29992;&#31354;&#38388;&#21644;&#26102;&#38388;&#19978;&#30340;&#22810;&#20010;&#21327;&#21464;&#37327;&#20449;&#24687;&#65292;&#25552;&#20379;&#19968;&#22825;&#21069;&#22238;&#24402;&#27700;&#24179;&#21644;&#36229;&#20986;&#27010;&#29575;&#30340;&#39044;&#27979;&#12290;&#36825;&#20010;&#36755;&#20986;&#34917;&#20805;&#20102;&#20256;&#32479;&#26497;&#20540;&#20998;&#26512;&#30340;&#38745;&#24577;&#22238;&#24402;&#27700;&#24179;&#65292;&#24182;&#19988;&#39044;&#27979;&#33021;&#22815;&#36866;&#24212;&#20998;&#24067;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Risk assessment for extreme events requires accurate estimation of high quantiles that go beyond the range of historical observations. When the risk depends on the values of observed predictors, regression techniques are used to interpolate in the predictor space. We propose the EQRN model that combines tools from neural networks and extreme value theory into a method capable of extrapolation in the presence of complex predictor dependence. Neural networks can naturally incorporate additional structure in the data. We develop a recurrent version of EQRN that is able to capture complex sequential dependence in time series. We apply this method to forecasting of flood risk in the Swiss Aare catchment. It exploits information from multiple covariates in space and time to provide one-day-ahead predictions of return levels and exceedances probabilities. This output complements the static return level from a traditional extreme value analysis and the predictions are able to adapt to distribu
&lt;/p&gt;</description></item></channel></rss>