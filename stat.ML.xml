<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#20989;&#25968;&#25968;&#25454;&#26144;&#23556;&#21040;&#26377;&#38480;&#32500;&#21442;&#25968;&#31354;&#38388;&#65292;&#24182;&#20351;&#29992;&#26032;&#30340;&#33258;&#30001;&#33410;&#28857;&#25918;&#32622;&#31639;&#27861;&#26469;&#21516;&#26102;&#36817;&#20284;&#22810;&#20010;&#20989;&#25968;&#12290;&#35813;&#31639;&#27861;&#26681;&#25454;&#36755;&#20837;&#25110;&#36755;&#20986;&#20989;&#25968;&#30340;&#23616;&#37096;&#22797;&#26434;&#24615;&#26469;&#20915;&#23450;&#33410;&#28857;&#20301;&#32622;&#65292;&#24615;&#33021;&#31283;&#20581;&#12290;</title><link>http://arxiv.org/abs/2401.14989</link><description>&lt;p&gt;
&#20351;&#29992;&#26032;&#22411;B&#26679;&#26465;&#33258;&#30001;&#33410;&#28857;&#25918;&#32622;&#31639;&#27861;&#30340;&#26144;&#23556;&#21040;&#21442;&#25968;&#38750;&#32447;&#24615;&#20989;&#25968;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Mapping-to-Parameter Nonlinear Functional Regression with Novel B-spline Free Knot Placement Algorithm. (arXiv:2401.14989v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14989
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#20989;&#25968;&#25968;&#25454;&#26144;&#23556;&#21040;&#26377;&#38480;&#32500;&#21442;&#25968;&#31354;&#38388;&#65292;&#24182;&#20351;&#29992;&#26032;&#30340;&#33258;&#30001;&#33410;&#28857;&#25918;&#32622;&#31639;&#27861;&#26469;&#21516;&#26102;&#36817;&#20284;&#22810;&#20010;&#20989;&#25968;&#12290;&#35813;&#31639;&#27861;&#26681;&#25454;&#36755;&#20837;&#25110;&#36755;&#20986;&#20989;&#25968;&#30340;&#23616;&#37096;&#22797;&#26434;&#24615;&#26469;&#20915;&#23450;&#33410;&#28857;&#20301;&#32622;&#65292;&#24615;&#33021;&#31283;&#20581;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#22238;&#24402;&#26041;&#27861;&#65292;&#31216;&#20026;&#26144;&#23556;&#21040;&#21442;&#25968;&#20989;&#25968;&#27169;&#22411;&#65292;&#36890;&#36807;&#37319;&#29992;&#20219;&#20309;&#30417;&#30563;&#23398;&#20064;&#25216;&#26415;&#22788;&#29702;&#21442;&#25968;&#31354;&#38388;&#20013;&#30340;&#22797;&#26434;&#21644;&#38750;&#32447;&#24615;&#20989;&#25968;&#22238;&#24402;&#38382;&#39064;&#12290;&#35813;&#27169;&#22411;&#30340;&#26680;&#24515;&#26159;&#23558;&#20989;&#25968;&#25968;&#25454;&#20174;&#26080;&#38480;&#32500;&#20989;&#25968;&#31354;&#38388;&#26144;&#23556;&#21040;&#26377;&#38480;&#32500;&#21442;&#25968;&#31354;&#38388;&#12290;&#36825;&#26159;&#36890;&#36807;&#20351;&#29992;&#19968;&#32452;&#20844;&#29992;&#30340;B&#26679;&#26465;&#22522;&#20989;&#25968;&#21516;&#26102;&#36817;&#20284;&#22810;&#20010;&#20989;&#25968;&#26469;&#23454;&#29616;&#30340;&#65292;&#20854;&#33410;&#28857;&#20998;&#24067;&#30001;&#36845;&#20195;&#23616;&#37096;&#25918;&#32622;&#31639;&#27861;&#30830;&#23450;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#25552;&#20986;&#30340;&#33258;&#30001;&#33410;&#28857;&#25918;&#32622;&#31639;&#27861;&#12290;&#19982;&#20256;&#32479;&#30340;&#31561;&#36317;&#33410;&#28857;&#25918;&#32622;&#31574;&#30053;&#30456;&#27604;&#65292;&#21518;&#32773;&#26681;&#25454;&#36755;&#20837;&#25110;&#36755;&#20986;&#20989;&#25968;&#30340;&#23616;&#37096;&#22797;&#26434;&#24615;&#26469;&#30830;&#23450;&#33410;&#28857;&#20301;&#32622;&#65292;&#32780;&#19981;&#26159;&#22522;&#20110;&#39044;&#23450;&#20041;&#30340;&#33410;&#28857;&#25968;&#22343;&#21248;&#20998;&#24067;&#33410;&#28857;&#20301;&#32622;&#12290;&#25105;&#20204;&#30340;&#33410;&#28857;&#25918;&#32622;&#31639;&#27861;&#30340;&#24615;&#33021;&#22312;&#20004;&#20010;&#26041;&#38754;&#37117;&#34920;&#29616;&#20986;&#20102;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel approach to nonlinear functional regression, called the Mapping-to-Parameter function model, which addresses complex and nonlinear functional regression problems in parameter space by employing any supervised learning technique. Central to this model is the mapping of function data from an infinite-dimensional function space to a finite-dimensional parameter space. This is accomplished by concurrently approximating multiple functions with a common set of B-spline basis functions by any chosen order, with their knot distribution determined by the Iterative Local Placement Algorithm, a newly proposed free knot placement algorithm. In contrast to the conventional equidistant knot placement strategy that uniformly distributes knot locations based on a predefined number of knots, our proposed algorithms determine knot location according to the local complexity of the input or output functions. The performance of our knot placement algorithms is shown to be robust in both 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20998;&#23618;&#30340;&#24490;&#29615;&#20999;&#25442;&#29366;&#24577;&#27169;&#22411;&#65292;&#25105;&#20204;&#21487;&#20197;&#26080;&#30417;&#30563;&#22320;&#21516;&#26102;&#35299;&#37322;&#31995;&#32479;&#32423;&#21644;&#20010;&#20307;&#32423;&#30340;&#21160;&#24577;&#65292;&#20174;&#32780;&#26356;&#22909;&#22320;&#24314;&#27169;&#21516;&#27493;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#32676;&#20307;&#21160;&#24577;&#12290;</title><link>http://arxiv.org/abs/2401.14973</link><description>&lt;p&gt;
&#36890;&#36807;&#20998;&#23618;&#24490;&#29615;&#20999;&#25442;&#29366;&#24577;&#27169;&#22411;&#21457;&#29616;&#21516;&#27493;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#32676;&#20307;&#21160;&#24577;
&lt;/p&gt;
&lt;p&gt;
Discovering group dynamics in synchronous time series via hierarchical recurrent switching-state models. (arXiv:2401.14973v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14973
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20998;&#23618;&#30340;&#24490;&#29615;&#20999;&#25442;&#29366;&#24577;&#27169;&#22411;&#65292;&#25105;&#20204;&#21487;&#20197;&#26080;&#30417;&#30563;&#22320;&#21516;&#26102;&#35299;&#37322;&#31995;&#32479;&#32423;&#21644;&#20010;&#20307;&#32423;&#30340;&#21160;&#24577;&#65292;&#20174;&#32780;&#26356;&#22909;&#22320;&#24314;&#27169;&#21516;&#27493;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#32676;&#20307;&#21160;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#33268;&#21147;&#20110;&#23545;&#21516;&#19968;&#26102;&#38388;&#27573;&#20869;&#22810;&#20010;&#23454;&#20307;&#30456;&#20114;&#20316;&#29992;&#32780;&#20135;&#29983;&#30340;&#26102;&#38388;&#24207;&#21015;&#38598;&#21512;&#36827;&#34892;&#24314;&#27169;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#38598;&#20013;&#22312;&#24314;&#27169;&#20010;&#20307;&#26102;&#38388;&#24207;&#21015;&#26041;&#38754;&#23545;&#25105;&#20204;&#30340;&#39044;&#26399;&#24212;&#29992;&#26159;&#19981;&#36275;&#22815;&#30340;&#65292;&#20854;&#20013;&#38598;&#20307;&#31995;&#32479;&#32423;&#34892;&#20026;&#24433;&#21709;&#30528;&#20010;&#20307;&#23454;&#20307;&#30340;&#36712;&#36857;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#31867;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#23618;&#20999;&#25442;&#29366;&#24577;&#27169;&#22411;&#65292;&#21487;&#20197;&#20197;&#26080;&#30417;&#30563;&#30340;&#26041;&#24335;&#35757;&#32451;&#65292;&#21516;&#26102;&#35299;&#37322;&#31995;&#32479;&#32423;&#21644;&#20010;&#20307;&#32423;&#30340;&#21160;&#24577;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#19968;&#20010;&#38544;&#21547;&#30340;&#31995;&#32479;&#32423;&#31163;&#25955;&#29366;&#24577;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#39537;&#21160;&#30528;&#38544;&#21547;&#30340;&#23454;&#20307;&#32423;&#38142;&#65292;&#36827;&#32780;&#25511;&#21046;&#27599;&#20010;&#35266;&#27979;&#26102;&#38388;&#24207;&#21015;&#30340;&#21160;&#24577;&#12290;&#35266;&#27979;&#32467;&#26524;&#22312;&#23454;&#20307;&#21644;&#31995;&#32479;&#32423;&#30340;&#38142;&#20043;&#38388;&#36827;&#34892;&#21453;&#39304;&#65292;&#36890;&#36807;&#20381;&#36182;&#20110;&#19978;&#19979;&#25991;&#30340;&#29366;&#24577;&#36716;&#25442;&#26469;&#25552;&#39640;&#28789;&#27963;&#24615;&#12290;&#25105;&#20204;&#30340;&#20998;&#23618;&#20999;&#25442;&#24490;&#29615;&#21160;&#21147;&#23398;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#23553;&#38381;&#24418;&#24335;&#30340;&#21464;&#20998;&#22352;&#26631;&#19978;&#21319;&#26356;&#26032;&#26469;&#23398;&#20064;&#65292;&#20854;&#22312;&#20010;&#20307;&#25968;&#37327;&#19978;&#21576;&#32447;&#24615;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
We seek to model a collection of time series arising from multiple entities interacting over the same time period. Recent work focused on modeling individual time series is inadequate for our intended applications, where collective system-level behavior influences the trajectories of individual entities. To address such problems, we present a new hierarchical switching-state model that can be trained in an unsupervised fashion to simultaneously explain both system-level and individual-level dynamics. We employ a latent system-level discrete state Markov chain that drives latent entity-level chains which in turn govern the dynamics of each observed time series. Feedback from the observations to the chains at both the entity and system levels improves flexibility via context-dependent state transitions. Our hierarchical switching recurrent dynamical models can be learned via closed-form variational coordinate ascent updates to all latent chains that scale linearly in the number of indivi
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#32467;&#26500;&#22238;&#24402;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#27169;&#22411;&#22312;&#19981;&#21516;&#20132;&#21449;&#23376;&#32676;&#20307;&#38388;&#30340;&#24615;&#33021;&#12290;&#23427;&#21487;&#20197;&#25552;&#20379;&#21487;&#38752;&#30340;&#31995;&#32479;&#24615;&#33021;&#20272;&#35745;&#65292;&#21363;&#20351;&#23545;&#20110;&#24456;&#23567;&#30340;&#23376;&#32676;&#20307;&#12290;</title><link>http://arxiv.org/abs/2401.14893</link><description>&lt;p&gt;
&#35780;&#20272;&#27169;&#22411;&#22312;&#20132;&#21449;&#23376;&#32676;&#20307;&#38388;&#24615;&#33021;&#30340;&#32467;&#26500;&#22238;&#24402;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A structured regression approach for evaluating model performance across intersectional subgroups. (arXiv:2401.14893v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14893
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#32467;&#26500;&#22238;&#24402;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#27169;&#22411;&#22312;&#19981;&#21516;&#20132;&#21449;&#23376;&#32676;&#20307;&#38388;&#30340;&#24615;&#33021;&#12290;&#23427;&#21487;&#20197;&#25552;&#20379;&#21487;&#38752;&#30340;&#31995;&#32479;&#24615;&#33021;&#20272;&#35745;&#65292;&#21363;&#20351;&#23545;&#20110;&#24456;&#23567;&#30340;&#23376;&#32676;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20154;&#24037;&#26234;&#33021;&#20844;&#24179;&#24615;&#35780;&#20272;&#20013;&#65292;&#20998;&#35299;&#24335;&#35780;&#20272;&#26159;&#19968;&#39033;&#26680;&#24515;&#20219;&#21153;&#65292;&#30446;&#26631;&#26159;&#34913;&#37327;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#22312;&#30001;&#20154;&#21475;&#32479;&#35745;&#23398;&#25110;&#20854;&#20182;&#25935;&#24863;&#23646;&#24615;&#32452;&#21512;&#23450;&#20041;&#30340;&#19981;&#21516;&#23376;&#32676;&#20307;&#20013;&#30340;&#24615;&#33021;&#12290;&#26631;&#20934;&#26041;&#27861;&#26159;&#23558;&#35780;&#20272;&#25968;&#25454;&#20998;&#23618;&#21040;&#23376;&#32676;&#20307;&#20013;&#65292;&#24182;&#20998;&#21035;&#35745;&#31639;&#27599;&#20010;&#32452;&#30340;&#24615;&#33021;&#25351;&#26631;&#12290;&#28982;&#32780;&#65292;&#21363;&#20351;&#23545;&#20110;&#20013;&#31561;&#35268;&#27169;&#30340;&#35780;&#20272;&#25968;&#25454;&#38598;&#26469;&#35828;&#65292;&#22312;&#32771;&#34385;&#21040;&#20132;&#21449;&#23376;&#32676;&#20307;&#26102;&#26679;&#26412;&#25968;&#37327;&#20063;&#20250;&#36805;&#36895;&#21464;&#23567;&#65292;&#36825;&#22823;&#22823;&#38480;&#21046;&#20102;&#35768;&#22810;&#20998;&#35299;&#35780;&#20272;&#20013;&#23545;&#20132;&#21449;&#32676;&#20307;&#30340;&#32771;&#34385;&#31243;&#24230;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#32467;&#26500;&#22238;&#24402;&#26041;&#27861;&#26469;&#36827;&#34892;&#20998;&#35299;&#35780;&#20272;&#65292;&#25105;&#20204;&#35777;&#26126;&#21363;&#20351;&#23545;&#20110;&#38750;&#24120;&#23567;&#30340;&#23376;&#32676;&#20307;&#65292;&#35813;&#26041;&#27861;&#20063;&#33021;&#20135;&#29983;&#21487;&#38752;&#30340;&#31995;&#32479;&#24615;&#33021;&#20272;&#35745;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#30456;&#24212;&#30340;&#25512;&#26029;&#31574;&#30053;&#26469;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#65292;&#24182;&#25506;&#32034;&#20102;&#25311;&#21512;&#20248;&#24230;&#27979;&#35797;&#22914;&#20309;&#25581;&#31034;&#20132;&#21449;&#23376;&#32676;&#20307;&#25152;&#32463;&#21382;&#30340;&#19982;&#20844;&#24179;&#30456;&#20851;&#30340;&#20260;&#23475;&#30340;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Disaggregated evaluation is a central task in AI fairness assessment, with the goal to measure an AI system's performance across different subgroups defined by combinations of demographic or other sensitive attributes. The standard approach is to stratify the evaluation data across subgroups and compute performance metrics separately for each group. However, even for moderately-sized evaluation datasets, sample sizes quickly get small once considering intersectional subgroups, which greatly limits the extent to which intersectional groups are considered in many disaggregated evaluations. In this work, we introduce a structured regression approach to disaggregated evaluation that we demonstrate can yield reliable system performance estimates even for very small subgroups. We also provide corresponding inference strategies for constructing confidence intervals and explore how goodness-of-fit testing can yield insight into the structure of fairness-related harms experienced by intersectio
&lt;/p&gt;</description></item><item><title>P3LS&#26159;&#19968;&#31181;&#38544;&#31169;&#20445;&#25252;&#30340;&#20559;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#25216;&#26415;&#65292;&#36890;&#36807;&#20351;&#29992;&#21487;&#31227;&#21160;&#30340;&#38543;&#26426;&#25513;&#30721;&#20445;&#25252;&#27599;&#20010;&#25968;&#25454;&#25345;&#26377;&#32773;&#30340;&#38544;&#31169;&#65292;&#23454;&#29616;&#20102;&#36328;&#32452;&#32455;&#25968;&#25454;&#38598;&#25104;&#21644;&#36807;&#31243;&#24314;&#27169;&#12290;</title><link>http://arxiv.org/abs/2401.14884</link><description>&lt;p&gt;
P3LS: &#38544;&#31169;&#20445;&#25252;&#19979;&#30340;&#20559;&#26368;&#23567;&#20108;&#20056;&#27861;
&lt;/p&gt;
&lt;p&gt;
P3LS: Partial Least Squares under Privacy Preservation. (arXiv:2401.14884v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14884
&lt;/p&gt;
&lt;p&gt;
P3LS&#26159;&#19968;&#31181;&#38544;&#31169;&#20445;&#25252;&#30340;&#20559;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#25216;&#26415;&#65292;&#36890;&#36807;&#20351;&#29992;&#21487;&#31227;&#21160;&#30340;&#38543;&#26426;&#25513;&#30721;&#20445;&#25252;&#27599;&#20010;&#25968;&#25454;&#25345;&#26377;&#32773;&#30340;&#38544;&#31169;&#65292;&#23454;&#29616;&#20102;&#36328;&#32452;&#32455;&#25968;&#25454;&#38598;&#25104;&#21644;&#36807;&#31243;&#24314;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#21046;&#36896;&#19994;&#20215;&#20540;&#38142;&#38656;&#35201;&#36328;&#20844;&#21496;&#36793;&#30028;&#26234;&#33021;&#21327;&#35843;&#27969;&#31243;&#65292;&#20197;&#26368;&#22823;&#21270;&#21033;&#28070;&#21516;&#26102;&#20419;&#36827;&#31038;&#20250;&#21644;&#29615;&#22659;&#21487;&#25345;&#32493;&#24615;&#12290;&#28982;&#32780;&#65292;&#22522;&#20110;&#25968;&#25454;&#30340;&#20215;&#20540;&#38142;&#20915;&#31574;&#30340;&#38598;&#25104;&#24335;&#31995;&#32479;&#32423;&#26041;&#27861;&#30340;&#23454;&#26045;&#65292;&#30446;&#21069;&#21463;&#21040;&#19982;&#36328;&#32452;&#32455;&#25968;&#25454;&#20132;&#25442;&#21644;&#38598;&#25104;&#30456;&#20851;&#30340;&#38544;&#31169;&#20851;&#27880;&#30340;&#38459;&#30861;&#12290;&#25105;&#20204;&#22312;&#36825;&#37324;&#25552;&#20986;&#20102;&#38544;&#31169;&#20445;&#25252;&#30340;&#20559;&#26368;&#23567;&#20108;&#20056;&#65288;P3LS&#65289;&#22238;&#24402;&#65292;&#19968;&#31181;&#33021;&#22815;&#22312;&#26377;&#38544;&#31169;&#20445;&#35777;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#36328;&#32452;&#32455;&#25968;&#25454;&#38598;&#25104;&#21644;&#36807;&#31243;&#24314;&#27169;&#30340;&#26032;&#22411;&#32852;&#37030;&#23398;&#20064;&#25216;&#26415;&#12290;P3LS&#28041;&#21450;&#19968;&#31181;&#22522;&#20110;&#22855;&#24322;&#20540;&#20998;&#35299;&#65288;SVD&#65289;&#30340;PLS&#31639;&#27861;&#65292;&#24182;&#37319;&#29992;&#30001;&#21487;&#20449;&#26426;&#26500;&#29983;&#25104;&#30340;&#21487;&#31227;&#21160;&#30340;&#38543;&#26426;&#25513;&#30721;&#26469;&#20445;&#25252;&#27599;&#20010;&#25968;&#25454;&#25345;&#26377;&#32773;&#36129;&#29486;&#30340;&#25968;&#25454;&#30340;&#38544;&#31169;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;P3LS&#22312;&#30001;&#19977;&#20010;&#21442;&#19982;&#26041;&#32452;&#25104;&#30340;&#20551;&#24819;&#20215;&#20540;&#38142;&#19978;&#22402;&#30452;&#25972;&#21512;&#36807;&#31243;&#25968;&#25454;&#24182;&#25552;&#39640;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern manufacturing value chains require intelligent orchestration of processes across company borders in order to maximize profits while fostering social and environmental sustainability. However, the implementation of integrated, systems-level approaches for data-informed decision-making along value chains is currently hampered by privacy concerns associated with cross-organizational data exchange and integration. We here propose Privacy-Preserving Partial Least Squares (P3LS) regression, a novel federated learning technique that enables cross-organizational data integration and process modeling with privacy guarantees. P3LS involves a singular value decomposition (SVD) based PLS algorithm and employs removable, random masks generated by a trusted authority in order to protect the privacy of the data contributed by each data holder. We demonstrate the capability of P3LS to vertically integrate process data along a hypothetical value chain consisting of three parties and to improve t
&lt;/p&gt;</description></item><item><title>&#31890;&#23376;-MALA&#21644;&#31890;&#23376;-mGRAD&#26159;&#22522;&#20110;&#26799;&#24230;&#30340;MCMC&#26041;&#27861;&#65292;&#32508;&#21512;&#20102;&#26465;&#20214;&#39034;&#24207;Monte Carlo (CSMC)&#31639;&#27861;&#30340;&#26102;&#38388;&#21487;&#25193;&#23637;&#24615;&#21644;MALA&#25110;mGRAD&#30340;&#32500;&#24230;&#21487;&#25193;&#23637;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.14868</link><description>&lt;p&gt;
&#31890;&#23376;-MALA&#21644;&#31890;&#23376;-mGRAD: &#38754;&#21521;&#39640;&#32500;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;MCMC&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Particle-MALA and Particle-mGRAD: Gradient-based MCMC methods for high-dimensional state-space models. (arXiv:2401.14868v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14868
&lt;/p&gt;
&lt;p&gt;
&#31890;&#23376;-MALA&#21644;&#31890;&#23376;-mGRAD&#26159;&#22522;&#20110;&#26799;&#24230;&#30340;MCMC&#26041;&#27861;&#65292;&#32508;&#21512;&#20102;&#26465;&#20214;&#39034;&#24207;Monte Carlo (CSMC)&#31639;&#27861;&#30340;&#26102;&#38388;&#21487;&#25193;&#23637;&#24615;&#21644;MALA&#25110;mGRAD&#30340;&#32500;&#24230;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#20013;&#65292;&#29616;&#26377;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#21253;&#25324;&#26465;&#20214;&#39034;&#24207;Monte Carlo (CSMC)&#31639;&#27861;&#21644;&#20808;&#36827;&#30340;&#8220;&#32463;&#20856;&#8221;MCMC&#31639;&#27861;&#65292;&#22914;MALA&#25110;&#26469;&#33258;Titsias&#21644;Papaspiliopoulos (2018)&#30340;mGRAD&#12290;&#21069;&#32773;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#20013;&#25552;&#20986;N&#20010;&#31890;&#23376;&#26469;&#21033;&#29992;&#27169;&#22411;&#30340;&#8220;&#38543;&#26102;&#38388;&#30456;&#20851;&#24615;&#8221;&#23646;&#24615;&#65292;&#24182;&#19988;&#38543;&#30528;&#26102;&#38388;&#33539;&#22260;T&#30340;&#22686;&#21152;&#32780;&#21487;&#25193;&#23637;&#65292;&#20294;&#22914;&#26524;&#28508;&#22312;&#29366;&#24577;&#30340;&#32500;&#24230;D&#36739;&#22823;&#65292;&#21017;&#20250;&#22833;&#36133;&#12290;&#21518;&#32773;&#21033;&#29992;&#26799;&#24230;/&#20808;&#39564;&#20449;&#24687;&#33258;&#36866;&#24212;&#35843;&#25972;&#23616;&#37096;&#25552;&#35758;&#65292;&#20197;&#22312;&#32500;&#24230;D&#26041;&#38754;&#26377;&#33391;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#20294;&#30001;&#20110;&#32570;&#20047;&#27169;&#22411;&#32467;&#26500;&#30340;&#21033;&#29992;&#32780;&#22312;&#26102;&#38388;&#33539;&#22260;T&#26041;&#38754;&#26174;&#31034;&#20986;&#20122;&#20248;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#32467;&#21512;&#20102;&#20004;&#31181;&#26041;&#27861;&#20248;&#28857;&#30340;&#26041;&#27861;&#12290;&#31532;&#19968;&#31181;&#26159;&#31890;&#23376;-MALA&#65292;&#20351;&#29992;&#26799;&#24230;&#20449;&#24687;&#22312;&#24403;&#21069;&#29366;&#24577;&#21608;&#22260;&#23616;&#37096;&#25193;&#25955;N&#20010;&#31890;&#23376;&#65292;&#20174;&#32780;&#23558;MALA&#25193;&#23637;&#21040;T&gt;1&#21644;N&gt;1&#30340;&#25552;&#35758;&#12290;&#31532;&#20108;&#31181;&#26159;&#31890;&#23376;-mGRAD&#65292;&#27492;&#22806;&#36824;&#24341;&#20837;&#20102;&#65288;&#26465;&#20214;&#65289;Ga
&lt;/p&gt;
&lt;p&gt;
State-of-the-art methods for Bayesian inference in state-space models are (a) conditional sequential Monte Carlo (CSMC) algorithms; (b) sophisticated 'classical' MCMC algorithms like MALA, or mGRAD from Titsias and Papaspiliopoulos (2018, arXiv:1610.09641v3 [stat.ML]). The former propose $N$ particles at each time step to exploit the model's 'decorrelation-over-time' property and thus scale favourably with the time horizon, $T$ , but break down if the dimension of the latent states, $D$, is large. The latter leverage gradient-/prior-informed local proposals to scale favourably with $D$ but exhibit sub-optimal scalability with $T$ due to a lack of model-structure exploitation. We introduce methods which combine the strengths of both approaches. The first, Particle-MALA, spreads $N$ particles locally around the current state using gradient information, thus extending MALA to $T &gt; 1$ time steps and $N &gt; 1$ proposals. The second, Particle-mGRAD, additionally incorporates (conditionally) Ga
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#20197;&#20934;&#30830;&#39044;&#27979;&#22312;&#32447;&#27963;&#21160;&#30340;&#29992;&#25143;&#25968;&#37327;&#21644;&#36798;&#21040;&#25152;&#38656;&#29992;&#25143;&#21442;&#19982;&#38376;&#27099;&#25152;&#38656;&#30340;&#26102;&#38388;&#36712;&#36857;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#25429;&#25417;&#29992;&#25143;&#21442;&#19982;&#30340;&#28508;&#22312;&#24322;&#36136;&#24615;&#65292;&#25552;&#20379;&#20102;&#23454;&#39564;&#32773;&#22312;&#22312;&#32447;&#23454;&#39564;&#20013;&#37325;&#35201;&#30340;&#20915;&#31574;&#25903;&#25345;&#12290;</title><link>http://arxiv.org/abs/2401.14722</link><description>&lt;p&gt;
&#19968;&#31181;&#38750;&#21442;&#25968;&#36125;&#21494;&#26031;&#26041;&#27861;&#29992;&#20110;&#22312;&#32447;&#27963;&#21160;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
A Nonparametric Bayes Approach to Online Activity Prediction. (arXiv:2401.14722v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14722
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#20197;&#20934;&#30830;&#39044;&#27979;&#22312;&#32447;&#27963;&#21160;&#30340;&#29992;&#25143;&#25968;&#37327;&#21644;&#36798;&#21040;&#25152;&#38656;&#29992;&#25143;&#21442;&#19982;&#38376;&#27099;&#25152;&#38656;&#30340;&#26102;&#38388;&#36712;&#36857;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#25429;&#25417;&#29992;&#25143;&#21442;&#19982;&#30340;&#28508;&#22312;&#24322;&#36136;&#24615;&#65292;&#25552;&#20379;&#20102;&#23454;&#39564;&#32773;&#22312;&#22312;&#32447;&#23454;&#39564;&#20013;&#37325;&#35201;&#30340;&#20915;&#31574;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20934;&#30830;&#39044;&#27979;&#29305;&#23450;&#27963;&#21160;&#30340;&#21457;&#29983;&#26102;&#38388;&#20869;&#20855;&#26377;&#37325;&#35201;&#24212;&#29992;&#32972;&#26223;&#12290;&#23545;&#20110;&#36816;&#34892;&#22312;&#32447;&#23454;&#39564;&#65288;A/B&#27979;&#35797;&#65289;&#30340;&#23454;&#39564;&#32773;&#26469;&#35828;&#65292;&#20934;&#30830;&#39044;&#27979;&#26410;&#26469;&#23558;&#25509;&#21463;&#24178;&#39044;&#30340;&#29992;&#25143;&#25968;&#37327;&#26159;&#19968;&#39033;&#37325;&#35201;&#20449;&#24687;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#39044;&#27979;&#32473;&#23450;&#26102;&#38388;&#27573;&#20869;&#27963;&#21160;&#29992;&#25143;&#25968;&#37327;&#20197;&#21450;&#36798;&#21040;&#25152;&#38656;&#29992;&#25143;&#21442;&#19982;&#38376;&#27099;&#25152;&#38656;&#30340;&#26102;&#38388;&#36712;&#36857;&#12290;&#25105;&#20204;&#20351;&#29992;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#26469;&#24314;&#27169;&#29992;&#25143;&#27963;&#21160;&#65292;&#20197;&#25429;&#25417;&#29992;&#25143;&#21442;&#19982;&#30340;&#28508;&#22312;&#24322;&#36136;&#24615;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#22312;&#32473;&#23450;&#26102;&#38388;&#27573;&#20869;&#26399;&#26395;&#30340;&#26032;&#29992;&#25143;&#25968;&#37327;&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#33945;&#29305;&#21345;&#32599;&#31639;&#27861;&#26469;&#20272;&#35745;&#36798;&#21040;&#25152;&#38656;&#29992;&#25143;&#25968;&#37327;&#25152;&#38656;&#30340;&#22825;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#65307;&#21518;&#32773;&#23545;&#20110;&#23454;&#39564;&#35268;&#21010;&#38750;&#24120;&#37325;&#35201;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#39044;&#27979;&#29992;&#25143;&#27963;&#21160;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Accurately predicting the onset of specific activities within defined timeframes holds significant importance in several applied contexts. In particular, accurate prediction of the number of future users that will be exposed to an intervention is an important piece of information for experimenters running online experiments (A/B tests). In this work, we propose a novel approach to predict the number of users that will be active in a given time period, as well as the temporal trajectory needed to attain a desired user participation threshold. We model user activity using a Bayesian nonparametric approach which allows us to capture the underlying heterogeneity in user engagement. We derive closed-form expressions for the number of new users expected in a given period, and a simple Monte Carlo algorithm targeting the posterior distribution of the number of days needed to attain a desired number of users; the latter is important for experimental planning. We illustrate the performance of o
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#29699;&#38754;&#21367;&#31215;Wasserstein&#36317;&#31163;&#26469;&#39564;&#35777;&#27668;&#20505;&#27169;&#22411;&#65292;&#30456;&#27604;&#20256;&#32479;&#26041;&#27861;&#26356;&#20840;&#38754;&#22320;&#34913;&#37327;&#27668;&#20505;&#27169;&#22411;&#21644;&#20877;&#20998;&#26512;&#25968;&#25454;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#24182;&#24212;&#29992;&#20110;&#35780;&#20272;CMIP&#25104;&#21592;&#30340;&#27169;&#22411;&#36755;&#20986;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#21457;&#29616;CMIP&#31532;6&#38454;&#27573;&#27169;&#22411;&#30456;&#36739;&#20110;&#31532;5&#38454;&#27573;&#26377;&#36866;&#24230;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2401.14657</link><description>&lt;p&gt;
&#29992;&#29699;&#38754;&#21367;&#31215;Wasserstein&#36317;&#31163;&#39564;&#35777;&#27668;&#20505;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Validating Climate Models with Spherical Convolutional Wasserstein Distance. (arXiv:2401.14657v1 [physics.ao-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14657
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#29699;&#38754;&#21367;&#31215;Wasserstein&#36317;&#31163;&#26469;&#39564;&#35777;&#27668;&#20505;&#27169;&#22411;&#65292;&#30456;&#27604;&#20256;&#32479;&#26041;&#27861;&#26356;&#20840;&#38754;&#22320;&#34913;&#37327;&#27668;&#20505;&#27169;&#22411;&#21644;&#20877;&#20998;&#26512;&#25968;&#25454;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#24182;&#24212;&#29992;&#20110;&#35780;&#20272;CMIP&#25104;&#21592;&#30340;&#27169;&#22411;&#36755;&#20986;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#21457;&#29616;CMIP&#31532;6&#38454;&#27573;&#27169;&#22411;&#30456;&#36739;&#20110;&#31532;5&#38454;&#27573;&#26377;&#36866;&#24230;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39564;&#35777;&#20840;&#29699;&#27668;&#20505;&#27169;&#22411;&#23545;&#20110;&#30830;&#20445;&#27169;&#22411;&#36755;&#20986;&#30340;&#20934;&#30830;&#24615;&#21644;&#26377;&#25928;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#24341;&#20837;&#29699;&#38754;&#21367;&#31215;Wasserstein&#36317;&#31163;&#26469;&#26356;&#20840;&#38754;&#22320;&#34913;&#37327;&#27668;&#20505;&#27169;&#22411;&#21644;&#20877;&#20998;&#26512;&#25968;&#25454;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#36825;&#20010;&#26032;&#30340;&#30456;&#20284;&#24230;&#27979;&#37327;&#26041;&#27861;&#21033;&#29992;&#21367;&#31215;&#25237;&#24433;&#32771;&#34385;&#20102;&#31354;&#38388;&#21464;&#24322;&#24615;&#65292;&#24182;&#37327;&#21270;&#20102;&#27668;&#20505;&#21464;&#37327;&#20998;&#24067;&#30340;&#23616;&#37096;&#24046;&#24322;&#12290;&#25105;&#20204;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#35780;&#20272;&#32806;&#21512;&#27169;&#24335;&#27604;&#36739;&#39033;&#30446;&#65288;CMIP&#65289;&#25104;&#21592;&#30340;&#21382;&#21490;&#27169;&#22411;&#36755;&#20986;&#65292;&#23558;&#20854;&#19982;&#35266;&#27979;&#25968;&#25454;&#21644;&#20877;&#20998;&#26512;&#25968;&#25454;&#20135;&#21697;&#36827;&#34892;&#27604;&#36739;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20174;CMIP&#31532;5&#38454;&#27573;&#21040;&#31532;6&#38454;&#27573;&#30340;&#36827;&#23637;&#65292;&#24182;&#21457;&#29616;&#31532;6&#38454;&#27573;&#27169;&#22411;&#22312;&#29983;&#25104;&#30495;&#23454;&#27668;&#20505;&#23398;&#33021;&#21147;&#26041;&#38754;&#26377;&#36866;&#24230;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
The validation of global climate models is crucial to ensure the accuracy and efficacy of model output. We introduce the spherical convolutional Wasserstein distance to more comprehensively measure differences between climate models and reanalysis data. This new similarity measure accounts for spatial variability using convolutional projections and quantifies local differences in the distribution of climate variables. We apply this method to evaluate the historical model outputs of the Coupled Model Intercomparison Project (CMIP) members by comparing them to observational and reanalysis data products. Additionally, we investigate the progression from CMIP phase 5 to phase 6 and find modest improvements in the phase 6 models regarding their ability to produce realistic climatologies.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#31283;&#20581;&#20272;&#35745;&#26041;&#27861;&#65288;MTuM&#65289;&#65292;&#29992;&#20110;&#20174;&#20998;&#32452;&#25968;&#25454;&#20013;&#20272;&#35745;Pareto&#20998;&#24067;&#30340;&#23614;&#25351;&#25968;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#24212;&#29992;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#27169;&#25311;&#30740;&#31350;&#39564;&#35777;&#20102;&#20854;&#25512;&#29702;&#21512;&#29702;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.14593</link><description>&lt;p&gt;
&#20174;&#20998;&#32452;&#25968;&#25454;&#20013;&#31283;&#20581;&#20272;&#35745;Pareto&#30340;&#23610;&#24230;&#21442;&#25968;
&lt;/p&gt;
&lt;p&gt;
Robust Estimation of Pareto's Scale Parameter from Grouped Data. (arXiv:2401.14593v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14593
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#31283;&#20581;&#20272;&#35745;&#26041;&#27861;&#65288;MTuM&#65289;&#65292;&#29992;&#20110;&#20174;&#20998;&#32452;&#25968;&#25454;&#20013;&#20272;&#35745;Pareto&#20998;&#24067;&#30340;&#23614;&#25351;&#25968;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#24212;&#29992;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#27169;&#25311;&#30740;&#31350;&#39564;&#35777;&#20102;&#20854;&#25512;&#29702;&#21512;&#29702;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21487;&#33719;&#21462;&#30340;&#23436;&#20840;&#35266;&#27979;&#21040;&#30340;&#20174;&#22836;&#33267;&#23614;&#30340;&#25439;&#22833;&#20005;&#37325;&#24615;&#26679;&#26412;&#25968;&#25454;&#38598;&#23384;&#22312;&#26102;&#65292;&#23384;&#22312;&#35768;&#22810;&#31283;&#20581;&#20272;&#35745;&#22120;&#20316;&#20026;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#65288;MLE&#65289;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#24403;&#22788;&#29702;&#20998;&#32452;&#25439;&#22833;&#20005;&#37325;&#24615;&#25968;&#25454;&#26102;&#65292;&#31283;&#20581;&#30340;MLE&#26367;&#20195;&#26041;&#26696;&#30340;&#36873;&#25321;&#21464;&#24471;&#38750;&#24120;&#26377;&#38480;&#65292;&#21482;&#26377;&#23569;&#25968;&#26041;&#27861;&#21487;&#29992;&#65292;&#20363;&#22914;&#26368;&#23567;&#20108;&#20056;&#27861;&#12289;&#26368;&#23567;Hellinger&#36317;&#31163;&#21644;&#26368;&#20248;&#26377;&#30028;&#24433;&#21709;&#20989;&#25968;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#25130;&#26029;&#30697;&#27861;&#30340;&#26032;&#22411;&#31283;&#20581;&#20272;&#35745;&#25216;&#26415;&#65292;&#35813;&#26041;&#27861;&#19987;&#38376;&#29992;&#20110;&#20174;&#20998;&#32452;&#25968;&#25454;&#20272;&#35745;Pareto&#20998;&#24067;&#30340;&#23614;&#25351;&#25968;&#12290;&#36890;&#36807;&#24212;&#29992;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#36890;&#36807;&#20840;&#38754;&#30340;&#27169;&#25311;&#30740;&#31350;&#39564;&#35777;&#20102;MTuM&#30340;&#25512;&#29702;&#21512;&#29702;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Numerous robust estimators exist as alternatives to the maximum likelihood estimator (MLE) when a completely observed ground-up loss severity sample dataset is available. However, the options for robust alternatives to MLE become significantly limited when dealing with grouped loss severity data, with only a handful of methods like least squares, minimum Hellinger distance, and optimal bounded influence function available. This paper introduces a novel robust estimation technique, the Method of Truncated Moments (MTuM), specifically designed to estimate the tail index of a Pareto distribution from grouped data. Inferential justification of MTuM is established by employing the central limit theorem and validating them through a comprehensive simulation study.
&lt;/p&gt;</description></item><item><title>&#21033;&#29992;Ricci&#27969;&#24341;&#23548;&#30340;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#33021;&#22815;&#23398;&#20064;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#65292;&#23588;&#20854;&#26159;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;&#35757;&#32451;&#20013;&#23398;&#20064;&#27969;&#24418;&#65292;&#24182;&#20351;&#29992;Ricci&#27969;&#20351;&#27969;&#24418;&#28508;&#31354;&#38388;&#36880;&#27493;&#36866;&#24212;&#21160;&#21147;&#23398;&#30340;&#21464;&#21270;&#65292;&#20174;&#32780;&#33719;&#24471;&#26356;&#22909;&#30340;&#34920;&#31034;&#33021;&#21147;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#20855;&#26377;&#21608;&#26399;&#24615;&#21644;&#38543;&#26426;&#24615;&#30340;PDE&#19978;&#30340;&#24212;&#29992;&#65292;&#24182;&#35780;&#20272;&#20102;&#22312;&#20998;&#24067;&#20869;&#21644;&#22806;&#25512;&#22330;&#26223;&#20013;&#30340;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2401.14591</link><description>&lt;p&gt;
&#21033;&#29992;Ricci&#27969;&#24341;&#23548;&#30340;&#33258;&#32534;&#30721;&#22120;&#23398;&#20064;&#26102;&#21464;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Ricci flow-guided autoencoders in learning time-dependent dynamics. (arXiv:2401.14591v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14591
&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;Ricci&#27969;&#24341;&#23548;&#30340;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#33021;&#22815;&#23398;&#20064;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#65292;&#23588;&#20854;&#26159;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;&#35757;&#32451;&#20013;&#23398;&#20064;&#27969;&#24418;&#65292;&#24182;&#20351;&#29992;Ricci&#27969;&#20351;&#27969;&#24418;&#28508;&#31354;&#38388;&#36880;&#27493;&#36866;&#24212;&#21160;&#21147;&#23398;&#30340;&#21464;&#21270;&#65292;&#20174;&#32780;&#33719;&#24471;&#26356;&#22909;&#30340;&#34920;&#31034;&#33021;&#21147;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#20855;&#26377;&#21608;&#26399;&#24615;&#21644;&#38543;&#26426;&#24615;&#30340;PDE&#19978;&#30340;&#24212;&#29992;&#65292;&#24182;&#35780;&#20272;&#20102;&#22312;&#20998;&#24067;&#20869;&#21644;&#22806;&#25512;&#22330;&#26223;&#20013;&#30340;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27969;&#24418;&#30340;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#26102;&#38388;&#19978;&#30340;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#65292;&#23588;&#20854;&#26159;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDE&#65289;&#65292;&#20854;&#20013;&#27969;&#24418;&#28508;&#31354;&#38388;&#26681;&#25454;Ricci&#27969;&#21457;&#23637;&#12290;&#36825;&#21487;&#20197;&#36890;&#36807;&#22312;&#29289;&#29702;&#20449;&#24687;&#35774;&#32622;&#20013;&#27169;&#25311;Ricci&#27969;&#26469;&#23454;&#29616;&#65292;&#24182;&#19988;&#21487;&#20197;&#21305;&#37197;&#27969;&#24418;&#37327;&#65292;&#20197;&#20415;&#23454;&#29616;Ricci&#27969;&#12290;&#20351;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#27969;&#24418;&#26159;&#20316;&#20026;&#35757;&#32451;&#36807;&#31243;&#30340;&#19968;&#37096;&#20998;&#23398;&#20064;&#30340;&#65292;&#22240;&#27492;&#21487;&#20197;&#35782;&#21035;&#20986;&#29702;&#24819;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#21516;&#26102;&#28436;&#21464;&#20063;&#33021;&#22312;&#38745;&#24577;&#26041;&#27861;&#19978;&#24341;&#36215;&#26356;&#23485;&#23481;&#30340;&#28508;&#22312;&#34920;&#31034;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#25968;&#20540;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#20855;&#26377;&#21608;&#26399;&#24615;&#21644;&#38543;&#26426;&#24615;&#31561;&#29702;&#24819;&#29305;&#24449;&#30340;PDE&#65292;&#24182;&#22312;&#20998;&#24067;&#20869;&#21644;&#22806;&#25512;&#22330;&#26223;&#20013;&#36827;&#34892;&#35823;&#24046;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a manifold-based autoencoder method for learning nonlinear dynamics in time, notably partial differential equations (PDEs), in which the manifold latent space evolves according to Ricci flow. This can be accomplished by simulating Ricci flow in a physics-informed setting, and manifold quantities can be matched so that Ricci flow is empirically achieved. With our methodology, the manifold is learned as part of the training procedure, so ideal geometries may be discerned, while the evolution simultaneously induces a more accommodating latent representation over static methods. We present our method on a range of numerical experiments consisting of PDEs that encompass desirable characteristics such as periodicity and randomness, remarking error on in-distribution and extrapolation scenarios.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#36890;&#36807;&#27169;&#25311;&#21644;&#23454;&#39564;&#35780;&#20272;&#20102;&#20107;&#21518;&#26426;&#22120;&#23398;&#20064;&#35299;&#37322;&#20013;&#30340;&#24046;&#24322;&#65292;&#24182;&#21457;&#29616;&#21327;&#21464;&#37327;&#20559;&#31227;&#12289;&#27010;&#24565;&#36716;&#21464;&#21644;&#30465;&#30053;&#21327;&#21464;&#37327;&#20250;&#22686;&#21152;&#35299;&#37322;&#24046;&#24322;&#65292;&#23545;&#31070;&#32463;&#32593;&#32476;&#24433;&#21709;&#26356;&#22823;&#12290;</title><link>http://arxiv.org/abs/2401.14539</link><description>&lt;p&gt;
&#29702;&#35299;&#20107;&#21518;&#26426;&#22120;&#23398;&#20064;&#35299;&#37322;&#20013;&#30340;&#24046;&#24322;
&lt;/p&gt;
&lt;p&gt;
Understanding Disparities in Post Hoc Machine Learning Explanation. (arXiv:2401.14539v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14539
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#36890;&#36807;&#27169;&#25311;&#21644;&#23454;&#39564;&#35780;&#20272;&#20102;&#20107;&#21518;&#26426;&#22120;&#23398;&#20064;&#35299;&#37322;&#20013;&#30340;&#24046;&#24322;&#65292;&#24182;&#21457;&#29616;&#21327;&#21464;&#37327;&#20559;&#31227;&#12289;&#27010;&#24565;&#36716;&#21464;&#21644;&#30465;&#30053;&#21327;&#21464;&#37327;&#20250;&#22686;&#21152;&#35299;&#37322;&#24046;&#24322;&#65292;&#23545;&#31070;&#32463;&#32593;&#32476;&#24433;&#21709;&#26356;&#22823;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#25351;&#20986;&#65292;&#29616;&#26377;&#30340;&#20107;&#21518;&#35299;&#37322;&#26041;&#27861;&#22312;&#35299;&#37322;&#20934;&#30830;&#24615;&#19978;&#23384;&#22312;&#24046;&#24322;&#65288;&#28041;&#21450;&#8220;&#31181;&#26063;&#8221;&#21644;&#8220;&#24615;&#21035;&#8221;&#31561;&#25935;&#24863;&#23646;&#24615;&#65289;&#65292;&#34429;&#28982;&#24050;&#26377;&#22823;&#37327;&#30740;&#31350;&#33268;&#21147;&#20110;&#22312;&#35299;&#37322;&#24230;&#37327;&#27700;&#24179;&#19978;&#20943;&#23569;&#36825;&#20123;&#38382;&#39064;&#65292;&#20294;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#21644;&#40657;&#30418;&#27169;&#22411;&#19982;&#35299;&#37322;&#24046;&#24322;&#20043;&#38388;&#30340;&#20851;&#31995;&#20173;&#28982;&#26410;&#34987;&#24191;&#27867;&#25506;&#35752;&#12290;&#22240;&#27492;&#65292;&#36890;&#36807;&#27169;&#25311;&#21644;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#29305;&#21035;&#35780;&#20272;&#20102;&#35299;&#37322;&#24046;&#24322;&#38754;&#20020;&#30340;&#25361;&#25112;&#65306;&#25968;&#25454;&#24615;&#36136;&#24341;&#36215;&#30340;&#23616;&#38480;&#26679;&#26412;&#37327;&#12289;&#21327;&#21464;&#37327;&#20559;&#31227;&#12289;&#27010;&#24565;&#36716;&#21464;&#12289;&#34987;&#30465;&#30053;&#30340;&#21464;&#37327;&#20559;&#24046;&#65292;&#20197;&#21450;&#27169;&#22411;&#24615;&#36136;&#24341;&#36215;&#30340;&#25361;&#25112;&#65306;&#25935;&#24863;&#23646;&#24615;&#30340;&#21253;&#21547;&#21644;&#36866;&#24403;&#30340;&#20989;&#25968;&#24418;&#24335;&#12290;&#36890;&#36807;&#21463;&#25511;&#27169;&#25311;&#20998;&#26512;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#35777;&#26126;&#22686;&#21152;&#21327;&#21464;&#37327;&#20559;&#31227;&#12289;&#27010;&#24565;&#36716;&#21464;&#21644;&#30465;&#30053;&#21327;&#21464;&#37327;&#20250;&#22686;&#21152;&#35299;&#37322;&#24046;&#24322;&#65292;&#23545;&#20110;&#31070;&#32463;&#32593;&#32476;&#32780;&#35328;&#65292;&#36825;&#31181;&#25928;&#24212;&#26356;&#21152;&#26174;&#33879;&#12290;
&lt;/p&gt;
&lt;p&gt;
Previous work has highlighted that existing post-hoc explanation methods exhibit disparities in explanation fidelity (across 'race' and 'gender' as sensitive attributes), and while a large body of work focuses on mitigating these issues at the explanation metric level, the role of the data generating process and black box model in relation to explanation disparities remains largely unexplored. Accordingly, through both simulations as well as experiments on a real-world dataset, we specifically assess challenges to explanation disparities that originate from properties of the data: limited sample size, covariate shift, concept shift, omitted variable bias, and challenges based on model properties: inclusion of the sensitive attribute and appropriate functional form. Through controlled simulation analyses, our study demonstrates that increased covariate shift, concept shift, and omission of covariates increase explanation disparities, with the effect pronounced higher for neural network 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#31181;&#20855;&#26377;&#31454;&#20105;&#39044;&#27979;&#21644;&#20998;&#31867;&#33021;&#21147;&#30340;&#28207;&#21475;&#36816;&#33829;&#35299;&#20915;&#26041;&#26696;&#65292;&#29992;&#20110;&#20934;&#30830;&#20272;&#35745;&#33337;&#33334;&#22312;&#28207;&#21475;&#30340;&#24635;&#26102;&#38388;&#21644;&#24310;&#36831;&#26102;&#38388;&#65292;&#22635;&#34917;&#20102;&#28207;&#21475;&#20998;&#26512;&#27169;&#22411;&#22312;&#36825;&#26041;&#38754;&#30340;&#31354;&#30333;&#65292;&#24182;&#20026;&#28023;&#20107;&#29289;&#27969;&#39046;&#22495;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2401.14498</link><description>&lt;p&gt;
&#20248;&#21270;&#28207;&#21475;&#36816;&#33829;&#30340;&#39044;&#27979;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Predictive Analysis for Optimizing Port Operations. (arXiv:2401.14498v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14498
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#31181;&#20855;&#26377;&#31454;&#20105;&#39044;&#27979;&#21644;&#20998;&#31867;&#33021;&#21147;&#30340;&#28207;&#21475;&#36816;&#33829;&#35299;&#20915;&#26041;&#26696;&#65292;&#29992;&#20110;&#20934;&#30830;&#20272;&#35745;&#33337;&#33334;&#22312;&#28207;&#21475;&#30340;&#24635;&#26102;&#38388;&#21644;&#24310;&#36831;&#26102;&#38388;&#65292;&#22635;&#34917;&#20102;&#28207;&#21475;&#20998;&#26512;&#27169;&#22411;&#22312;&#36825;&#26041;&#38754;&#30340;&#31354;&#30333;&#65292;&#24182;&#20026;&#28023;&#20107;&#29289;&#27969;&#39046;&#22495;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28023;&#36816;&#26159;&#36828;&#36317;&#31163;&#21644;&#22823;&#23447;&#36135;&#29289;&#36816;&#36755;&#30340;&#37325;&#35201;&#29289;&#27969;&#26041;&#24335;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#36816;&#36755;&#27169;&#24335;&#20013;&#22797;&#26434;&#30340;&#35268;&#21010;&#32463;&#24120;&#21463;&#21040;&#19981;&#30830;&#23450;&#24615;&#30340;&#24433;&#21709;&#65292;&#21253;&#25324;&#22825;&#27668;&#26465;&#20214;&#12289;&#36135;&#29289;&#22810;&#26679;&#24615;&#21644;&#28207;&#21475;&#21160;&#24577;&#65292;&#23548;&#33268;&#25104;&#26412;&#22686;&#21152;&#12290;&#22240;&#27492;&#65292;&#20934;&#30830;&#20272;&#35745;&#33337;&#33334;&#22312;&#28207;&#21475;&#20572;&#30041;&#30340;&#24635;&#26102;&#38388;&#21644;&#28508;&#22312;&#24310;&#36831;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#65292;&#20197;&#20415;&#22312;&#28207;&#21475;&#36816;&#33829;&#20013;&#36827;&#34892;&#26377;&#25928;&#30340;&#35268;&#21010;&#21644;&#23433;&#25490;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#24320;&#21457;&#20855;&#26377;&#31454;&#20105;&#39044;&#27979;&#21644;&#20998;&#31867;&#33021;&#21147;&#30340;&#28207;&#21475;&#36816;&#33829;&#35299;&#20915;&#26041;&#26696;&#65292;&#29992;&#20110;&#20272;&#35745;&#33337;&#33334;&#30340;&#24635;&#26102;&#38388;&#21644;&#24310;&#36831;&#26102;&#38388;&#12290;&#35813;&#30740;&#31350;&#22635;&#34917;&#20102;&#28207;&#21475;&#20998;&#26512;&#27169;&#22411;&#22312;&#33337;&#33334;&#20572;&#30041;&#21644;&#24310;&#36831;&#26102;&#38388;&#26041;&#38754;&#30340;&#37325;&#35201;&#31354;&#30333;&#65292;&#20026;&#28023;&#20107;&#29289;&#27969;&#39046;&#22495;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#36129;&#29486;&#12290;&#25152;&#25552;&#20986;&#30340;&#35299;&#20915;&#26041;&#26696;&#26088;&#22312;&#21327;&#21161;&#28207;&#21475;&#29615;&#22659;&#19979;&#30340;&#20915;&#31574;&#21046;&#23450;&#65292;&#24182;&#39044;&#27979;&#26381;&#21153;&#24310;&#36831;&#12290;&#36890;&#36807;&#23545;&#24052;&#35199;&#28207;&#21475;&#30340;&#26696;&#20363;&#30740;&#31350;&#36827;&#34892;&#39564;&#35777;&#65292;&#21516;&#26102;&#20351;&#29992;&#29305;&#24449;&#20998;&#26512;&#26469;&#29702;&#35299;...
&lt;/p&gt;
&lt;p&gt;
Maritime transport is a pivotal logistics mode for the long-distance and bulk transportation of goods. However, the intricate planning involved in this mode is often hindered by uncertainties, including weather conditions, cargo diversity, and port dynamics, leading to increased costs. Consequently, accurately estimating vessel total (stay) time at port and potential delays becomes imperative for effective planning and scheduling in port operations. This study aims to develop a port operation solution with competitive prediction and classification capabilities for estimating vessel Total and Delay times. This research addresses a significant gap in port analysis models for vessel Stay and Delay times, offering a valuable contribution to the field of maritime logistics. The proposed solution is designed to assist decision-making in port environments and predict service delays. This is demonstrated through a case study on Brazil ports. Additionally, feature analysis is used to understand
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23637;&#31034;&#20102;&#26657;&#20934;&#21644;&#36951;&#25022;&#22312;&#35780;&#20272;&#39044;&#27979;&#20013;&#30340;&#27010;&#24565;&#31561;&#20215;&#24615;&#65292;&#23558;&#35780;&#20272;&#38382;&#39064;&#26500;&#24314;&#20026;&#19968;&#20010;&#39044;&#27979;&#32773;&#12289;&#19968;&#20010;&#36172;&#24466;&#21644;&#33258;&#28982;&#20043;&#38388;&#30340;&#21338;&#24328;&#65292;&#24182;&#23558;&#39044;&#27979;&#30340;&#35780;&#20272;&#19982;&#32467;&#26524;&#30340;&#38543;&#26426;&#24615;&#32852;&#31995;&#36215;&#26469;&#12290;</title><link>http://arxiv.org/abs/2401.14483</link><description>&lt;p&gt;
&#39044;&#27979;&#30340;&#22235;&#20010;&#26041;&#38754;&#65306;&#26657;&#20934;&#12289;&#39044;&#27979;&#24615;&#12289;&#38543;&#26426;&#24615;&#21644;&#36951;&#25022;
&lt;/p&gt;
&lt;p&gt;
Four Facets of Forecast Felicity: Calibration, Predictiveness, Randomness and Regret. (arXiv:2401.14483v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14483
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;&#26657;&#20934;&#21644;&#36951;&#25022;&#22312;&#35780;&#20272;&#39044;&#27979;&#20013;&#30340;&#27010;&#24565;&#31561;&#20215;&#24615;&#65292;&#23558;&#35780;&#20272;&#38382;&#39064;&#26500;&#24314;&#20026;&#19968;&#20010;&#39044;&#27979;&#32773;&#12289;&#19968;&#20010;&#36172;&#24466;&#21644;&#33258;&#28982;&#20043;&#38388;&#30340;&#21338;&#24328;&#65292;&#24182;&#23558;&#39044;&#27979;&#30340;&#35780;&#20272;&#19982;&#32467;&#26524;&#30340;&#38543;&#26426;&#24615;&#32852;&#31995;&#36215;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#26159;&#20851;&#20110;&#39044;&#27979;&#30340;&#12290;&#28982;&#32780;&#65292;&#39044;&#27979;&#21482;&#26377;&#32463;&#36807;&#35780;&#20272;&#21518;&#25165;&#20855;&#26377;&#20854;&#26377;&#29992;&#24615;&#12290;&#26426;&#22120;&#23398;&#20064;&#20256;&#32479;&#19978;&#20851;&#27880;&#25439;&#22833;&#31867;&#22411;&#21450;&#20854;&#30456;&#24212;&#30340;&#36951;&#25022;&#12290;&#30446;&#21069;&#65292;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#37325;&#26032;&#23545;&#26657;&#20934;&#20135;&#29983;&#20102;&#20852;&#36259;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26657;&#20934;&#21644;&#36951;&#25022;&#22312;&#35780;&#20272;&#39044;&#27979;&#20013;&#30340;&#27010;&#24565;&#31561;&#20215;&#24615;&#12290;&#25105;&#20204;&#23558;&#35780;&#20272;&#38382;&#39064;&#26500;&#24314;&#20026;&#19968;&#20010;&#39044;&#27979;&#32773;&#12289;&#19968;&#20010;&#36172;&#24466;&#21644;&#33258;&#28982;&#20043;&#38388;&#30340;&#21338;&#24328;&#12290;&#36890;&#36807;&#23545;&#36172;&#24466;&#21644;&#39044;&#27979;&#32773;&#26045;&#21152;&#30452;&#35266;&#30340;&#38480;&#21046;&#65292;&#26657;&#20934;&#21644;&#36951;&#25022;&#33258;&#28982;&#22320;&#25104;&#20026;&#20102;&#36825;&#20010;&#26694;&#26550;&#30340;&#19968;&#37096;&#20998;&#12290;&#27492;&#22806;&#65292;&#36825;&#20010;&#21338;&#24328;&#23558;&#39044;&#27979;&#30340;&#35780;&#20272;&#19982;&#32467;&#26524;&#30340;&#38543;&#26426;&#24615;&#32852;&#31995;&#36215;&#26469;&#12290;&#30456;&#23545;&#20110;&#39044;&#27979;&#32780;&#35328;&#65292;&#32467;&#26524;&#30340;&#38543;&#26426;&#24615;&#31561;&#21516;&#20110;&#20851;&#20110;&#32467;&#26524;&#30340;&#22909;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#31216;&#36825;&#20004;&#20010;&#26041;&#38754;&#20026;&#26657;&#20934;&#21644;&#36951;&#25022;&#12289;&#39044;&#27979;&#24615;&#21644;&#38543;&#26426;&#24615;&#65292;&#21363;&#39044;&#27979;&#30340;&#22235;&#20010;&#26041;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning is about forecasting. Forecasts, however, obtain their usefulness only through their evaluation. Machine learning has traditionally focused on types of losses and their corresponding regret. Currently, the machine learning community regained interest in calibration. In this work, we show the conceptual equivalence of calibration and regret in evaluating forecasts. We frame the evaluation problem as a game between a forecaster, a gambler and nature. Putting intuitive restrictions on gambler and forecaster, calibration and regret naturally fall out of the framework. In addition, this game links evaluation of forecasts to randomness of outcomes. Random outcomes with respect to forecasts are equivalent to good forecasts with respect to outcomes. We call those dual aspects, calibration and regret, predictiveness and randomness, the four facets of forecast felicity.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#19987;&#21033;&#25968;&#25454;&#25552;&#39640;&#20102;&#25239;&#20307;&#20154;&#24615;&#39044;&#27979;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#22810;&#38454;&#27573;&#12289;&#22810;&#25439;&#22833;&#30340;&#35757;&#32451;&#36807;&#31243;&#20197;&#21450;&#24369;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#25104;&#21151;&#22320;&#39044;&#27979;&#20102;&#25239;&#20307;&#24207;&#21015;&#30340;&#20154;&#24615;&#35780;&#20998;&#12290;</title><link>http://arxiv.org/abs/2401.14442</link><description>&lt;p&gt;
&#21033;&#29992;&#19987;&#21033;&#25968;&#25454;&#25552;&#39640;&#25239;&#20307;&#20154;&#24615;&#39044;&#27979;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Improving Antibody Humanness Prediction using Patent Data. (arXiv:2401.14442v1 [q-bio.QM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14442
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#19987;&#21033;&#25968;&#25454;&#25552;&#39640;&#20102;&#25239;&#20307;&#20154;&#24615;&#39044;&#27979;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#22810;&#38454;&#27573;&#12289;&#22810;&#25439;&#22833;&#30340;&#35757;&#32451;&#36807;&#31243;&#20197;&#21450;&#24369;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#25104;&#21151;&#22320;&#39044;&#27979;&#20102;&#25239;&#20307;&#24207;&#21015;&#30340;&#20154;&#24615;&#35780;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#21033;&#29992;&#19987;&#21033;&#25968;&#25454;&#26469;&#25552;&#39640;&#25239;&#20307;&#20154;&#24615;&#39044;&#27979;&#30340;&#28508;&#21147;&#65292;&#37319;&#29992;&#20102;&#22810;&#38454;&#27573;&#12289;&#22810;&#25439;&#22833;&#30340;&#35757;&#32451;&#36807;&#31243;&#12290;&#25239;&#20307;&#20154;&#24615;&#20316;&#20026;&#23545;&#25239;&#20307;&#27835;&#30103;&#30340;&#20813;&#30123;&#21453;&#24212;&#30340;&#20195;&#29702;&#65292;&#26159;&#33647;&#29289;&#21457;&#29616;&#20013;&#30340;&#20027;&#35201;&#21407;&#22240;&#20043;&#19968;&#65292;&#22312;&#20020;&#24202;&#29615;&#22659;&#20013;&#20351;&#29992;&#25239;&#20307;&#27835;&#30103;&#38754;&#20020;&#30528;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38556;&#30861;&#12290;&#25105;&#20204;&#23558;&#21021;&#22987;&#23398;&#20064;&#38454;&#27573;&#35270;&#20026;&#19968;&#20010;&#24369;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#38382;&#39064;&#65292;&#27599;&#20010;&#25239;&#20307;&#24207;&#21015;&#19982;&#21487;&#33021;&#26377;&#22810;&#20010;&#21151;&#33021;&#26631;&#35782;&#31526;&#30456;&#20851;&#32852;&#65292;&#30446;&#26631;&#26159;&#23398;&#20064;&#19968;&#20010;&#32534;&#30721;&#22120;&#65292;&#26681;&#25454;&#20854;&#19987;&#21033;&#23646;&#24615;&#23558;&#23427;&#20204;&#20998;&#32452;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20923;&#32467;&#23545;&#27604;&#32534;&#30721;&#22120;&#30340;&#19968;&#37096;&#20998;&#65292;&#24182;&#32487;&#32493;&#20351;&#29992;&#20132;&#21449;&#29109;&#25439;&#22833;&#22312;&#19987;&#21033;&#25968;&#25454;&#19978;&#35757;&#32451;&#65292;&#20197;&#39044;&#27979;&#32473;&#23450;&#25239;&#20307;&#24207;&#21015;&#30340;&#20154;&#24615;&#35780;&#20998;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#19977;&#20010;&#19981;&#21516;&#30340;&#20813;&#30123;&#21407;&#24615;&#25968;&#25454;&#38598;&#36827;&#34892;&#25512;&#29702;&#65292;&#23637;&#31034;&#20102;&#19987;&#21033;&#25968;&#25454;&#21644;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#25928;&#29992;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;l
&lt;/p&gt;
&lt;p&gt;
We investigate the potential of patent data for improving the antibody humanness prediction using a multi-stage, multi-loss training process. Humanness serves as a proxy for the immunogenic response to antibody therapeutics, one of the major causes of attrition in drug discovery and a challenging obstacle for their use in clinical settings. We pose the initial learning stage as a weakly-supervised contrastive-learning problem, where each antibody sequence is associated with possibly multiple identifiers of function and the objective is to learn an encoder that groups them according to their patented properties. We then freeze a part of the contrastive encoder and continue training it on the patent data using the cross-entropy loss to predict the humanness score of a given antibody sequence. We illustrate the utility of the patent data and our approach by performing inference on three different immunogenicity datasets, unseen during training. Our empirical results demonstrate that the l
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#32447;&#24615;&#21644;&#38750;&#39640;&#26031;&#35266;&#27979;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#28388;&#27874;&#30340;&#21028;&#21035;&#24335;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65292;&#24182;&#22312;&#31070;&#32463;&#31185;&#23398;&#32972;&#26223;&#19979;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.14429</link><description>&lt;p&gt;
[&#20877;&#35770;] &#38750;&#32447;&#24615;&#21644;&#38750;&#39640;&#26031;&#35266;&#27979;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#28388;&#27874;&#30340;&#21028;&#21035;&#24335;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;
&lt;/p&gt;
&lt;p&gt;
[Re] The Discriminative Kalman Filter for Bayesian Filtering with Nonlinear and Non-Gaussian Observation Models. (arXiv:2401.14429v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14429
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#32447;&#24615;&#21644;&#38750;&#39640;&#26031;&#35266;&#27979;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#28388;&#27874;&#30340;&#21028;&#21035;&#24335;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65292;&#24182;&#22312;&#31070;&#32463;&#31185;&#23398;&#32972;&#26223;&#19979;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#20026;&#20272;&#35745;&#38544;&#34255;&#25110;&#28508;&#22312;&#21464;&#37327;&#25552;&#20379;&#20102;&#19968;&#31181;&#30452;&#35266;&#19988;&#26131;&#20110;&#29702;&#35299;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#25511;&#21046;&#12289;&#26426;&#22120;&#20154;&#12289;&#20449;&#21495;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#31561;&#39046;&#22495;&#24212;&#29992;&#24191;&#27867;&#12290;&#20854;&#20013;&#19968;&#31181;&#24212;&#29992;&#26159;&#31070;&#32463;&#33041;&#26426;&#25509;&#21475;&#30340;&#31070;&#32463;&#35299;&#30721;&#12290;2020&#24180;&#65292;Burkhart&#31561;&#20154;&#23545;&#20182;&#20204;&#30340;&#26032;&#29256;&#26412;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#36827;&#34892;&#20102;&#28145;&#20837;&#35780;&#20272;&#65292;&#21033;&#29992;&#36125;&#21494;&#26031;&#23450;&#29702;&#25913;&#21892;&#20102;&#23545;&#39640;&#24230;&#38750;&#32447;&#24615;&#25110;&#38750;&#39640;&#26031;&#35266;&#27979;&#27169;&#22411;&#30340;&#28388;&#27874;&#24615;&#33021;&#12290;&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#20316;&#32773;MATLAB&#31639;&#27861;&#30340;Python&#24320;&#28304;&#26367;&#20195;&#26041;&#26696;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#37325;&#26032;&#22797;&#29616;&#20102;&#20182;&#20204;&#22312;&#31070;&#32463;&#31185;&#23398;&#32972;&#26223;&#19979;&#26368;&#26174;&#33879;&#30340;&#32467;&#26524;&#65292;&#24182;&#20351;&#29992;&#22810;&#20010;&#38543;&#26426;&#31181;&#23376;&#21644;&#20316;&#32773;&#25968;&#25454;&#38598;&#20013;&#26410;&#20351;&#29992;&#30340;&#35797;&#39564;&#36827;&#19968;&#27493;&#26816;&#39564;&#20102;&#28388;&#27874;&#22120;&#30340;&#25928;&#26524;&#12290;&#25152;&#26377;&#23454;&#39564;&#22312;&#19968;&#21488;&#35745;&#31639;&#26426;&#19978;&#31163;&#32447;&#36827;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kalman filters provide a straightforward and interpretable means to estimate hidden or latent variables, and have found numerous applications in control, robotics, signal processing, and machine learning. One such application is neural decoding for neuroprostheses. In 2020, Burkhart et al. thoroughly evaluated their new version of the Kalman filter that leverages Bayes' theorem to improve filter performance for highly non-linear or non-Gaussian observation models. This work provides an open-source Python alternative to the authors' MATLAB algorithm. Specifically, we reproduce their most salient results for neuroscientific contexts and further examine the efficacy of their filter using multiple random seeds and previously unused trials from the authors' dataset. All experiments were performed offline on a single computer.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#26234;&#33021;&#20307;&#30340;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#65292;&#21033;&#29992;MA-BERT&#27169;&#22411;&#21644;&#39044;&#35757;&#32451;&#24494;&#35843;&#26694;&#26550;&#26469;&#35299;&#20915;&#31354;&#20013;&#20132;&#36890;&#31649;&#29702;&#20013;&#30340;&#38271;&#35757;&#32451;&#26102;&#38388;&#21644;&#22823;&#25968;&#25454;&#38598;&#38656;&#27714;&#30340;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#20855;&#26377;&#23569;&#37327;&#25968;&#25454;&#25110;&#26080;&#21382;&#21490;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#39640;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.14421</link><description>&lt;p&gt;
&#22810;&#26234;&#33021;&#20307;&#22522;&#20110;&#36801;&#31227;&#23398;&#20064;&#30340;&#25968;&#25454;&#39537;&#21160;&#31354;&#20013;&#20132;&#36890;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Multi-Agent Based Transfer Learning for Data-Driven Air Traffic Applications. (arXiv:2401.14421v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14421
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#26234;&#33021;&#20307;&#30340;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#65292;&#21033;&#29992;MA-BERT&#27169;&#22411;&#21644;&#39044;&#35757;&#32451;&#24494;&#35843;&#26694;&#26550;&#26469;&#35299;&#20915;&#31354;&#20013;&#20132;&#36890;&#31649;&#29702;&#20013;&#30340;&#38271;&#35757;&#32451;&#26102;&#38388;&#21644;&#22823;&#25968;&#25454;&#38598;&#38656;&#27714;&#30340;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#20855;&#26377;&#23569;&#37327;&#25968;&#25454;&#25110;&#26080;&#21382;&#21490;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#24320;&#21457;&#31354;&#20013;&#20132;&#36890;&#31649;&#29702;(ATM)&#30340;&#25968;&#25454;&#39537;&#21160;&#27169;&#22411;&#30340;&#30740;&#31350;&#24341;&#36215;&#20102;&#24040;&#22823;&#30340;&#20852;&#36259;&#12290;&#28982;&#32780;&#65292;&#20247;&#25152;&#21608;&#30693;&#65292;&#25968;&#25454;&#39537;&#21160;&#27169;&#22411;&#20855;&#26377;&#36739;&#38271;&#30340;&#35757;&#32451;&#26102;&#38388;&#65292;&#24182;&#19988;&#38656;&#35201;&#22823;&#37327;&#30340;&#25968;&#25454;&#38598;&#25165;&#33021;&#36798;&#21040;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20004;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#38754;&#32771;&#34385;ATM&#31995;&#32479;&#22810;&#26234;&#33021;&#20307;&#29305;&#24615;&#30340;Multi-Agent Bidirectional Encoder Representations from Transformers (MA-BERT)&#27169;&#22411;&#65292;&#24182;&#37319;&#29992;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#36801;&#31227;&#23398;&#20064;&#26694;&#26550;&#12290;&#36890;&#36807;&#23558;MA-BERT&#22312;&#19968;&#20010;&#20027;&#35201;&#26426;&#22330;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#65292;&#24182;&#22312;&#20854;&#20182;&#26426;&#22330;&#21644;&#29305;&#23450;&#31354;&#20013;&#20132;&#36890;&#24212;&#29992;&#19978;&#36827;&#34892;&#24494;&#35843;&#65292;&#21487;&#20197;&#33410;&#30465;&#22823;&#37327;&#30340;&#24635;&#35757;&#32451;&#26102;&#38388;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#26032;&#37319;&#29992;&#30340;&#31243;&#24207;&#21644;&#24314;&#31435;&#30340;&#26426;&#22330;&#65292;&#27809;&#26377;&#21382;&#21490;&#25968;&#25454;&#21487;&#29992;&#65292;&#26412;&#25991;&#23637;&#31034;&#20102;&#39044;&#35757;&#32451;&#30340;MA-BERT&#21487;&#20197;&#36890;&#36807;&#23569;&#37327;&#25968;&#25454;&#30340;&#23450;&#26399;&#26356;&#26032;&#23454;&#29616;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Research in developing data-driven models for Air Traffic Management (ATM) has gained a tremendous interest in recent years. However, data-driven models are known to have long training time and require large datasets to achieve good performance. To address the two issues, this paper proposes a Multi-Agent Bidirectional Encoder Representations from Transformers (MA-BERT) model that fully considers the multi-agent characteristic of the ATM system and learns air traffic controllers' decisions, and a pre-training and fine-tuning transfer learning framework. By pre-training the MA-BERT on a large dataset from a major airport and then fine-tuning it to other airports and specific air traffic applications, a large amount of the total training time can be saved. In addition, for newly adopted procedures and constructed airports where no historical data is available, this paper shows that the pre-trained MA-BERT can achieve high performance by updating regularly with little data. The proposed t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#20132;&#25442;&#24335;&#20849;&#24418;&#39118;&#38505;&#25511;&#21046;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#25968;&#25454;&#19981;&#21487;&#20132;&#25442;&#30340;&#24773;&#20917;&#19979;&#25511;&#21046;&#20219;&#20309;&#21333;&#35843;&#25439;&#22833;&#20989;&#25968;&#30340;&#26399;&#26395;&#20540;&#12290;</title><link>http://arxiv.org/abs/2310.01262</link><description>&lt;p&gt;
&#38750;&#20132;&#25442;&#24335;&#20849;&#24418;&#39118;&#38505;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Non-Exchangeable Conformal Risk Control. (arXiv:2310.01262v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01262
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#20132;&#25442;&#24335;&#20849;&#24418;&#39118;&#38505;&#25511;&#21046;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#25968;&#25454;&#19981;&#21487;&#20132;&#25442;&#30340;&#24773;&#20917;&#19979;&#25511;&#21046;&#20219;&#20309;&#21333;&#35843;&#25439;&#22833;&#20989;&#25968;&#30340;&#26399;&#26395;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#30001;&#20110;&#20854;&#33021;&#22815;&#20026;&#40657;&#21283;&#23376;&#31070;&#32463;&#27169;&#22411;&#30340;&#39044;&#27979;&#25552;&#20379;&#24418;&#24335;&#19978;&#20445;&#35777;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#25110;&#21306;&#38388;&#65292;&#30830;&#20445;&#21253;&#21547;&#23454;&#38469;&#30495;&#23454;&#20540;&#30340;&#39044;&#23450;&#20041;&#27010;&#29575;&#65292;&#25286;&#20998;&#20849;&#24418;&#39044;&#27979;&#24341;&#21457;&#20102;&#26497;&#22823;&#30340;&#20852;&#36259;&#12290;&#34429;&#28982;&#26368;&#21021;&#30340;&#20844;&#24335;&#20551;&#35774;&#25968;&#25454;&#21487;&#20132;&#25442;&#65292;&#20294;&#19968;&#20123;&#25193;&#23637;&#22788;&#29702;&#19981;&#21487;&#20132;&#25442;&#30340;&#25968;&#25454;&#65292;&#22312;&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#30340;&#22330;&#26223;&#20013;&#32463;&#24120;&#21457;&#29983;&#12290;&#21516;&#26102;&#65292;&#19968;&#20123;&#36827;&#23637;&#24050;&#32463;&#22312;&#20849;&#24418;&#26041;&#27861;&#20013;&#21462;&#24471;&#65292;&#36825;&#20123;&#26041;&#27861;&#23545;&#26356;&#24191;&#27867;&#30340;&#30446;&#26631;&#25552;&#20379;&#32479;&#35745;&#20445;&#35777;&#65292;&#20363;&#22914;&#38480;&#21046;&#26368;&#20339;F1&#20998;&#25968;&#25110;&#20197;&#26399;&#26395;&#26368;&#23567;&#21270;&#35823;&#25253;&#29575;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#21644;&#25193;&#23637;&#36825;&#20004;&#20010;&#24037;&#20316;&#32447;&#36335;&#65292;&#25552;&#20986;&#20102;&#38750;&#20132;&#25442;&#24335;&#20849;&#24418;&#39118;&#38505;&#25511;&#21046;&#65292;&#21487;&#20197;&#22312;&#25968;&#25454;&#19981;&#21487;&#20132;&#25442;&#30340;&#24773;&#20917;&#19979;&#25511;&#21046;&#20219;&#20309;&#21333;&#35843;&#25439;&#22833;&#20989;&#25968;&#30340;&#26399;&#26395;&#20540;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#28789;&#27963;&#65292;&#20551;&#35774;&#24456;&#23569;&#65292;&#24182;&#20801;&#35768;&#26681;&#25454;&#25968;&#25454;&#30340;&#32479;&#35745;&#30456;&#20284;&#24615;&#36827;&#34892;&#21152;&#26435;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Split conformal prediction has recently sparked great interest due to its ability to provide formally guaranteed uncertainty sets or intervals for predictions made by black-box neural models, ensuring a predefined probability of containing the actual ground truth. While the original formulation assumes data exchangeability, some extensions handle non-exchangeable data, which is often the case in many real-world scenarios. In parallel, some progress has been made in conformal methods that provide statistical guarantees for a broader range of objectives, such as bounding the best F1-score or minimizing the false negative rate in expectation. In this paper, we leverage and extend these two lines of work by proposing non-exchangeable conformal risk control, which allows controlling the expected value of any monotone loss function when the data is not exchangeable. Our framework is flexible, makes very few assumptions, and allows weighting the data based on its statistical similarity with t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32771;&#34385;&#22240;&#26524;&#32467;&#26500;&#30340;&#20449;&#24687;&#35770;&#37327;&#65292;&#29992;&#20110;&#35780;&#20272;&#26576;&#20010;&#29305;&#23450;&#32467;&#26524;&#21464;&#37327;&#30340;&#22240;&#26524;&#37325;&#35201;&#24615;&#65292;&#35299;&#20915;&#20102;&#22240;&#26524;&#21487;&#35299;&#37322;&#24615;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2309.07703</link><description>&lt;p&gt;
&#27979;&#37327;&#22240;&#26524;&#25511;&#21046;&#30340;&#22240;&#26524;&#29109;&#21644;&#20449;&#24687;&#22686;&#30410;
&lt;/p&gt;
&lt;p&gt;
Causal Entropy and Information Gain for Measuring Causal Control. (arXiv:2309.07703v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07703
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32771;&#34385;&#22240;&#26524;&#32467;&#26500;&#30340;&#20449;&#24687;&#35770;&#37327;&#65292;&#29992;&#20110;&#35780;&#20272;&#26576;&#20010;&#29305;&#23450;&#32467;&#26524;&#21464;&#37327;&#30340;&#22240;&#26524;&#37325;&#35201;&#24615;&#65292;&#35299;&#20915;&#20102;&#22240;&#26524;&#21487;&#35299;&#37322;&#24615;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#21644;&#26041;&#27861;&#36890;&#24120;&#32570;&#20047;&#22240;&#26524;&#21487;&#35299;&#37322;&#24615;&#12290;&#23613;&#31649;&#35299;&#37322;&#24615;&#26426;&#22120;&#23398;&#20064;&#65288;IML&#65289;&#26041;&#27861;&#21462;&#24471;&#20102;&#36827;&#23637;&#65292;&#20294;&#23427;&#20204;&#32463;&#24120;&#23558;&#37325;&#35201;&#24615;&#36171;&#20104;&#37027;&#20123;&#23545;&#32467;&#26524;&#21464;&#37327;&#27809;&#26377;&#22240;&#26524;&#24433;&#21709;&#30340;&#29305;&#24449;&#12290;&#22312;&#27169;&#22411;&#35757;&#32451;&#20043;&#21069;&#25110;&#20043;&#21518;&#65292;&#36873;&#25321;&#22240;&#26524;&#30456;&#20851;&#30340;&#29305;&#24449;&#23558;&#25552;&#20379;&#19968;&#31181;&#35299;&#20915;&#26041;&#26696;&#12290;&#21033;&#29992;&#20449;&#24687;&#35770;&#37327;&#36827;&#34892;&#29305;&#24449;&#36873;&#25321;&#30340;&#26041;&#27861;&#22312;&#35782;&#21035;&#32479;&#35745;&#30456;&#20851;&#29305;&#24449;&#26041;&#38754;&#38750;&#24120;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#25152;&#22522;&#20110;&#30340;&#20449;&#24687;&#35770;&#37327;&#19981;&#21253;&#21547;&#22240;&#26524;&#20851;&#31995;&#65292;&#22240;&#27492;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#19981;&#36866;&#29992;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#33021;&#22815;&#32771;&#34385;&#31995;&#32479;&#22240;&#26524;&#32467;&#26500;&#30340;&#20449;&#24687;&#35770;&#37327;&#65292;&#21487;&#20197;&#29992;&#20110;&#35780;&#20272;&#26576;&#20010;&#32473;&#23450;&#32467;&#26524;&#21464;&#37327;&#30340;&#22240;&#26524;&#37325;&#35201;&#24615;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22240;&#26524;&#29109;&#21644;&#22240;&#26524;&#20114;&#20449;&#24687;&#30340;&#22240;&#26524;&#29256;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Artificial intelligence models and methods commonly lack causal interpretability. Despite the advancements in interpretable machine learning (IML) methods, they frequently assign importance to features which lack causal influence on the outcome variable. Selecting causally relevant features among those identified as relevant by these methods, or even before model training, would offer a solution. Feature selection methods utilizing information theoretical quantities have been successful in identifying statistically relevant features. However, the information theoretical quantities they are based on do not incorporate causality, rendering them unsuitable for such scenarios. To address this challenge, this article proposes information theoretical quantities that incorporate the causal structure of the system, which can be used to evaluate causal importance of features for some given outcome variable. Specifically, we introduce causal versions of entropy and mutual information, termed cau
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#30446;&#26631;&#24310;&#32493;&#26041;&#27861;&#65292;&#29992;&#20110;&#35745;&#31639;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27491;&#21017;&#21270;&#36335;&#24452;&#65292;&#20197;&#35299;&#20915;DNNs&#20013;&#31232;&#30095;&#24615;&#21644;&#25968;&#20540;&#25928;&#29575;&#20043;&#38388;&#30340;&#20914;&#31361;&#12290;</title><link>http://arxiv.org/abs/2308.12044</link><description>&lt;p&gt;
&#29992;&#20110;&#35745;&#31639;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#27491;&#21017;&#21270;&#36335;&#24452;&#30340;&#22810;&#30446;&#26631;&#24310;&#32493;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A multiobjective continuation method to compute the regularization path of deep neural networks. (arXiv:2308.12044v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12044
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#30446;&#26631;&#24310;&#32493;&#26041;&#27861;&#65292;&#29992;&#20110;&#35745;&#31639;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27491;&#21017;&#21270;&#36335;&#24452;&#65292;&#20197;&#35299;&#20915;DNNs&#20013;&#31232;&#30095;&#24615;&#21644;&#25968;&#20540;&#25928;&#29575;&#20043;&#38388;&#30340;&#20914;&#31361;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#24615;&#26159;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#20013;&#38750;&#24120;&#29702;&#24819;&#30340;&#29305;&#24449;&#65292;&#22240;&#20026;&#23427;&#30830;&#20445;&#20102;&#25968;&#20540;&#25928;&#29575;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;(&#30001;&#20110;&#30456;&#20851;&#29305;&#24449;&#30340;&#25968;&#37327;&#36739;&#23569;)&#21644;&#40065;&#26834;&#24615;&#12290;&#22312;&#22522;&#20110;&#32447;&#24615;&#27169;&#22411;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20013;&#65292;&#20247;&#25152;&#21608;&#30693;&#22312;$\ell^1$&#33539;&#25968;(&#21363;&#38646;&#26435;&#37325;)&#30340;&#26368;&#31232;&#30095;&#35299;&#21644;&#38750;&#27491;&#21017;&#21270;&#35299;&#20043;&#38388;&#23384;&#22312;&#19968;&#26465;&#36830;&#25509;&#36335;&#24452;&#65292;&#36825;&#26465;&#36335;&#24452;&#34987;&#31216;&#20026;&#27491;&#21017;&#21270;&#36335;&#24452;&#12290;&#26368;&#36817;&#65292;&#36890;&#36807;&#23558;&#32463;&#39564;&#25439;&#22833;&#21644;&#31232;&#30095;&#24615;($\ell^1$&#33539;&#25968;)&#20316;&#20026;&#20004;&#20010;&#20914;&#31361;&#30340;&#26631;&#20934;&#65292;&#24182;&#35299;&#20915;&#30001;&#27492;&#20135;&#29983;&#30340;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#65292;&#39318;&#27425;&#23581;&#35797;&#23558;&#27491;&#21017;&#21270;&#36335;&#24452;&#30340;&#27010;&#24565;&#25193;&#23637;&#21040;DNNs&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;$\ell^1$&#33539;&#25968;&#30340;&#19981;&#20809;&#28369;&#24615;&#21644;&#21442;&#25968;&#25968;&#37327;&#30340;&#39640;&#24230;&#65292;&#20174;&#35745;&#31639;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#36825;&#31181;&#26041;&#27861;&#24182;&#19981;&#26159;&#24456;&#26377;&#25928;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#36817;&#20284;&#35745;&#31639;&#25972;&#20010;&#24085;&#32047;&#25176;&#26354;&#32447;
&lt;/p&gt;
&lt;p&gt;
Sparsity is a highly desired feature in deep neural networks (DNNs) since it ensures numerical efficiency, improves the interpretability of models (due to the smaller number of relevant features), and robustness. In machine learning approaches based on linear models, it is well known that there exists a connecting path between the sparsest solution in terms of the $\ell^1$ norm (i.e., zero weights) and the non-regularized solution, which is called the regularization path. Very recently, there was a first attempt to extend the concept of regularization paths to DNNs by means of treating the empirical loss and sparsity ($\ell^1$ norm) as two conflicting criteria and solving the resulting multiobjective optimization problem. However, due to the non-smoothness of the $\ell^1$ norm and the high number of parameters, this approach is not very efficient from a computational perspective. To overcome this limitation, we present an algorithm that allows for the approximation of the entire Pareto
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#37325;&#26032;&#34920;&#36848;&#20302;&#31209;&#30697;&#38453;&#22635;&#34917;&#38382;&#39064;&#20026;&#25237;&#24433;&#30697;&#38453;&#30340;&#38750;&#20984;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#33021;&#22815;&#30830;&#23450;&#26368;&#20248;&#35299;&#30340;&#20998;&#31163;&#20998;&#25903;&#23450;&#30028;&#26041;&#26696;&#65292;&#24182;&#19988;&#36890;&#36807;&#26032;&#39062;&#21644;&#32039;&#23494;&#30340;&#20984;&#26494;&#24347;&#26041;&#27861;&#65292;&#20351;&#24471;&#26368;&#20248;&#24615;&#24046;&#36317;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#20943;&#23569;&#20102;&#20004;&#20010;&#25968;&#37327;&#32423;&#12290;</title><link>http://arxiv.org/abs/2305.12292</link><description>&lt;p&gt;
&#26368;&#20248;&#20302;&#31209;&#30697;&#38453;&#22635;&#34917;&#65306;&#21322;&#23450;&#26494;&#24347;&#21644;&#29305;&#24449;&#21521;&#37327;&#20998;&#31163;
&lt;/p&gt;
&lt;p&gt;
Optimal Low-Rank Matrix Completion: Semidefinite Relaxations and Eigenvector Disjunctions. (arXiv:2305.12292v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12292
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#37325;&#26032;&#34920;&#36848;&#20302;&#31209;&#30697;&#38453;&#22635;&#34917;&#38382;&#39064;&#20026;&#25237;&#24433;&#30697;&#38453;&#30340;&#38750;&#20984;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#33021;&#22815;&#30830;&#23450;&#26368;&#20248;&#35299;&#30340;&#20998;&#31163;&#20998;&#25903;&#23450;&#30028;&#26041;&#26696;&#65292;&#24182;&#19988;&#36890;&#36807;&#26032;&#39062;&#21644;&#32039;&#23494;&#30340;&#20984;&#26494;&#24347;&#26041;&#27861;&#65292;&#20351;&#24471;&#26368;&#20248;&#24615;&#24046;&#36317;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#20943;&#23569;&#20102;&#20004;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#31209;&#30697;&#38453;&#22635;&#34917;&#30340;&#30446;&#30340;&#26159;&#35745;&#31639;&#19968;&#20010;&#22797;&#26434;&#24230;&#26368;&#23567;&#30340;&#30697;&#38453;&#65292;&#20197;&#23613;&#21487;&#33021;&#20934;&#30830;&#22320;&#24674;&#22797;&#32473;&#23450;&#30340;&#19968;&#32452;&#35266;&#27979;&#25968;&#25454;&#65292;&#24182;&#19988;&#20855;&#26377;&#20247;&#22810;&#24212;&#29992;&#65292;&#22914;&#20135;&#21697;&#25512;&#33616;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#29616;&#26377;&#30340;&#35299;&#20915;&#20302;&#31209;&#30697;&#38453;&#22635;&#34917;&#30340;&#26041;&#27861;&#26159;&#21551;&#21457;&#24335;&#30340;&#65292;&#34429;&#28982;&#39640;&#24230;&#21487;&#25193;&#23637;&#24182;&#19988;&#36890;&#24120;&#33021;&#22815;&#30830;&#23450;&#39640;&#36136;&#37327;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#19981;&#20855;&#22791;&#20219;&#20309;&#26368;&#20248;&#24615;&#20445;&#35777;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#20302;&#31209;&#38382;&#39064;&#37325;&#26032;&#34920;&#36848;&#20026;&#25237;&#24433;&#30697;&#38453;&#30340;&#38750;&#20984;&#38382;&#39064;&#65292;&#24182;&#23454;&#29616;&#19968;&#31181;&#20998;&#31163;&#20998;&#25903;&#23450;&#30028;&#26041;&#26696;&#26469;&#37325;&#26032;&#23457;&#35270;&#30697;&#38453;&#22635;&#34917;&#38382;&#39064;&#65292;&#20197;&#23454;&#29616;&#26368;&#20248;&#24615;&#23548;&#21521;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#23558;&#20302;&#31209;&#30697;&#38453;&#20998;&#35299;&#20026;&#19968;&#32452;&#31209;&#19968;&#30697;&#38453;&#30340;&#21644;&#65292;&#24182;&#36890;&#36807; Shor &#26494;&#24347;&#26469;&#28608;&#21169;&#27599;&#20010;&#31209;&#19968;&#30697;&#38453;&#20013;&#30340;&#27599;&#20010; 2*2 &#23567;&#30697;&#38453;&#30340;&#34892;&#21015;&#24335;&#20026;&#38646;&#65292;&#20174;&#32780;&#25512;&#23548;&#20986;&#19968;&#31181;&#26032;&#39062;&#19988;&#36890;&#24120;&#24456;&#32039;&#30340;&#20984;&#26494;&#24347;&#31867;&#12290;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#65292;&#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26032;&#20984;&#26494;&#24347;&#26041;&#27861;&#23558;&#26368;&#20248;&#24615;&#24046;&#36317;&#20943;&#23569;&#20102;&#20004;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;
Low-rank matrix completion consists of computing a matrix of minimal complexity that recovers a given set of observations as accurately as possible, and has numerous applications such as product recommendation. Unfortunately, existing methods for solving low-rank matrix completion are heuristics that, while highly scalable and often identifying high-quality solutions, do not possess any optimality guarantees. We reexamine matrix completion with an optimality-oriented eye, by reformulating low-rank problems as convex problems over the non-convex set of projection matrices and implementing a disjunctive branch-and-bound scheme that solves them to certifiable optimality. Further, we derive a novel and often tight class of convex relaxations by decomposing a low-rank matrix as a sum of rank-one matrices and incentivizing, via a Shor relaxation, that each two-by-two minor in each rank-one matrix has determinant zero. In numerical experiments, our new convex relaxations decrease the optimali
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#12289;&#32431;&#24046;&#20998;&#38544;&#31169;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#22312;$\{0,1\}^d$&#19978;&#20934;&#30830;&#20272;&#35745;&#20108;&#20803;&#31215;&#20998;&#24067;&#30340;&#22343;&#20540;&#65292;&#36798;&#21040;&#20102;&#26368;&#20248;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2304.06787</link><description>&lt;p&gt;
&#20108;&#20803;&#31215;&#20998;&#24067;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#21644;&#32431;&#24046;&#20998;&#38544;&#31169;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
A Polynomial Time, Pure Differentially Private Estimator for Binary Product Distributions. (arXiv:2304.06787v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06787
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#12289;&#32431;&#24046;&#20998;&#38544;&#31169;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#22312;$\{0,1\}^d$&#19978;&#20934;&#30830;&#20272;&#35745;&#20108;&#20803;&#31215;&#20998;&#24067;&#30340;&#22343;&#20540;&#65292;&#36798;&#21040;&#20102;&#26368;&#20248;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#949;-&#24046;&#20998;&#38544;&#31169;&#12289;&#35745;&#31639;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#24635;&#21464;&#21270;&#36317;&#31163;&#19979;&#20934;&#30830;&#22320;&#20272;&#35745;$\{0,1\}^d$&#19978;&#30340;&#20056;&#31215;&#20998;&#24067;&#30340;&#22343;&#20540;&#65292;&#21516;&#26102;&#22312;&#22810;&#39033;&#24335;&#23545;&#25968;&#22240;&#23376;&#20869;&#33719;&#24471;&#20102;&#26368;&#20248;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#20043;&#21069;&#30340;&#24037;&#20316;&#35201;&#20040;&#22312;&#26356;&#24369;&#30340;&#38544;&#31169;&#27010;&#24565;&#19979;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#35201;&#20040;&#22312;&#25351;&#25968;&#32423;&#36816;&#34892;&#26102;&#38388;&#20869;&#26368;&#20248;&#22320;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present the first $\varepsilon$-differentially private, computationally efficient algorithm that estimates the means of product distributions over $\{0,1\}^d$ accurately in total-variation distance, whilst attaining the optimal sample complexity to within polylogarithmic factors. The prior work had either solved this problem efficiently and optimally under weaker notions of privacy, or had solved it optimally while having exponential running times.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#21333;&#26102;&#38388;&#23610;&#24230;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26041;&#27861;&#65292;&#36890;&#36807;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#21644;&#39532;&#23572;&#21487;&#22827;&#26679;&#26412;&#26356;&#26032;&#65292;&#22312;&#36830;&#32493;&#29366;&#24577;&#31354;&#38388;&#20013;&#25214;&#21040;&#20102;&#19968;&#20010;$\epsilon$-&#36817;&#20284;&#30340;&#31283;&#23450;&#28857;&#65292;&#24182;&#19988;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\widetilde{\mathcal{O}}(\epsilon^{-2})$&#30340;&#24773;&#20917;&#19979;&#35777;&#26126;&#20102;&#20854;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2210.09921</link><description>&lt;p&gt;
&#21333;&#26102;&#38388;&#23610;&#24230;&#28436;&#21592;-&#35780;&#35770;&#23478;&#27861;&#30340;&#26377;&#38480;&#26102;&#38388;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Finite-time analysis of single-timescale actor-critic. (arXiv:2210.09921v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.09921
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#21333;&#26102;&#38388;&#23610;&#24230;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26041;&#27861;&#65292;&#36890;&#36807;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#21644;&#39532;&#23572;&#21487;&#22827;&#26679;&#26412;&#26356;&#26032;&#65292;&#22312;&#36830;&#32493;&#29366;&#24577;&#31354;&#38388;&#20013;&#25214;&#21040;&#20102;&#19968;&#20010;$\epsilon$-&#36817;&#20284;&#30340;&#31283;&#23450;&#28857;&#65292;&#24182;&#19988;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\widetilde{\mathcal{O}}(\epsilon^{-2})$&#30340;&#24773;&#20917;&#19979;&#35777;&#26126;&#20102;&#20854;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24212;&#29992;&#20013;&#65292;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26041;&#27861;&#21462;&#24471;&#20102;&#26174;&#30528;&#30340;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#22312;&#26368;&#23454;&#38469;&#30340;&#21333;&#26102;&#38388;&#23610;&#24230;&#24418;&#24335;&#19979;&#65292;&#20854;&#26377;&#38480;&#26102;&#38388;&#25910;&#25947;&#24615;&#20173;&#28982;&#19981;&#22815;&#29702;&#35299;&#12290;&#29616;&#26377;&#30340;&#21333;&#26102;&#38388;&#23610;&#24230;&#28436;&#21592;-&#35780;&#35770;&#23478;&#20998;&#26512;&#24037;&#20316;&#20165;&#38480;&#20110;&#31616;&#21270;&#30340;i.i.d.&#37319;&#26679;&#25110;&#34920;&#26684;&#35774;&#32622;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#26356;&#23454;&#38469;&#30340;&#22312;&#32447;&#21333;&#26102;&#38388;&#23610;&#24230;&#28436;&#21592;-&#35780;&#35770;&#23478;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#36830;&#32493;&#29366;&#24577;&#31354;&#38388;&#20013;&#65292;&#35780;&#35770;&#23478;&#37319;&#29992;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#65292;&#24182;&#22312;&#27599;&#20010;&#28436;&#21592;&#27493;&#39588;&#20013;&#20351;&#29992;&#21333;&#20010;&#39532;&#23572;&#21487;&#22827;&#26679;&#26412;&#36827;&#34892;&#26356;&#26032;&#12290;&#20808;&#21069;&#30340;&#20998;&#26512;&#26080;&#27861;&#22312;&#36825;&#31181;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22330;&#26223;&#20013;&#23454;&#29616;&#25910;&#25947;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#26631;&#20934;&#20551;&#35774;&#19979;&#65292;&#22312;&#32447;&#21333;&#26102;&#38388;&#23610;&#24230;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26041;&#27861;&#33021;&#22815;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\widetilde{\mathcal{O}}(\epsilon^{-2})$&#30340;&#24773;&#20917;&#19979;&#25214;&#21040;&#19968;&#20010;$\epsilon$-&#36817;&#20284;&#30340;&#31283;&#23450;&#28857;&#65292;&#32780;&#22312;i.i.d.&#37319;&#26679;&#19979;&#65292;&#36825;&#20010;&#22797;&#26434;&#24230;&#21487;&#20197;&#36827;&#19968;&#27493;&#25913;&#36827;&#20026;$\mathcal{O}(\epsilon^{-2})$&#12290;&#25105;&#20204;&#30340;&#26032;&#26694;&#26550;&#31995;&#32479;&#22320;&#35780;&#20272;&#20102;&#19968;&#20010;
&lt;/p&gt;
&lt;p&gt;
Actor-critic methods have achieved significant success in many challenging applications. However, its finite-time convergence is still poorly understood in the most practical single-timescale form. Existing works on analyzing single-timescale actor-critic have been limited to i.i.d. sampling or tabular setting for simplicity. We investigate the more practical online single-timescale actor-critic algorithm on continuous state space, where the critic assumes linear function approximation and updates with a single Markovian sample per actor step. Previous analysis has been unable to establish the convergence for such a challenging scenario. We demonstrate that the online single-timescale actor-critic method provably finds an $\epsilon$-approximate stationary point with $\widetilde{\mathcal{O}}(\epsilon^{-2})$ sample complexity under standard assumptions, which can be further improved to $\mathcal{O}(\epsilon^{-2})$ under the i.i.d. sampling. Our novel framework systematically evaluates an
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#20171;&#32461;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#24212;&#29992;&#30340;&#31614;&#21517;&#26041;&#27861;&#65292;&#36890;&#36807;&#25968;&#23398;&#27934;&#23519;&#21147;&#29702;&#35299;&#22797;&#26434;&#30340;&#27969;&#24335;&#25968;&#25454;&#20043;&#38388;&#30340;&#20132;&#20114;&#65292;&#24182;&#25552;&#20379;&#20102;&#29992;&#20110;&#20998;&#26512;&#38750;&#35268;&#21017;&#12289;&#38750;&#24179;&#31283;&#30340;&#27969;&#24335;&#25968;&#25454;&#30340;&#25968;&#20540;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2206.14674</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#31614;&#21517;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Signature Methods in Machine Learning. (arXiv:2206.14674v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.14674
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#20171;&#32461;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#24212;&#29992;&#30340;&#31614;&#21517;&#26041;&#27861;&#65292;&#36890;&#36807;&#25968;&#23398;&#27934;&#23519;&#21147;&#29702;&#35299;&#22797;&#26434;&#30340;&#27969;&#24335;&#25968;&#25454;&#20043;&#38388;&#30340;&#20132;&#20114;&#65292;&#24182;&#25552;&#20379;&#20102;&#29992;&#20110;&#20998;&#26512;&#38750;&#35268;&#21017;&#12289;&#38750;&#24179;&#31283;&#30340;&#27969;&#24335;&#25968;&#25454;&#30340;&#25968;&#20540;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#31614;&#21517;&#30340;&#25216;&#26415;&#20026;&#29702;&#35299;&#22797;&#26434;&#30340;&#27969;&#24335;&#25968;&#25454;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#25552;&#20379;&#20102;&#25968;&#23398;&#27934;&#23519;&#21147;&#12290;&#36825;&#20123;&#27934;&#23519;&#21147;&#21487;&#20197;&#24456;&#33258;&#28982;&#22320;&#36716;&#21270;&#20026;&#29702;&#35299;&#27969;&#24335;&#25968;&#25454;&#30340;&#25968;&#20540;&#26041;&#27861;&#65292;&#20063;&#35768;&#26159;&#22240;&#20026;&#23427;&#20204;&#20855;&#26377;&#25968;&#23398;&#30340;&#31934;&#30830;&#24615;&#65292;&#23427;&#20204;&#22312;&#20998;&#26512;&#38750;&#35268;&#21017;&#12289;&#38750;&#24179;&#31283;&#30340;&#27969;&#24335;&#25968;&#25454;&#20197;&#21450;&#25968;&#25454;&#32500;&#24230;&#21644;&#26679;&#26412;&#22823;&#23567;&#37117;&#36866;&#20013;&#30340;&#24773;&#20917;&#19979;&#34920;&#29616;&#20986;&#20102;&#24456;&#26377;&#29992;&#30340;&#24615;&#36136;&#12290;&#23545;&#20110;&#29702;&#35299;&#27969;&#24335;&#22810;&#27169;&#24577;&#25968;&#25454;&#26159;&#25351;&#25968;&#32423;&#30340;&#38382;&#39064;&#65306;&#38271;&#24230;&#20026;$n$&#30340;&#23383;&#27597;&#20018;&#65292;&#26469;&#33258;&#22823;&#23567;&#20026;$d$&#30340;&#23383;&#27597;&#34920;&#65292;&#21487;&#20197;&#26159;$d^n$&#31181;&#19981;&#21516;&#30340;&#28040;&#24687;&#12290;&#31614;&#21517;&#28040;&#38500;&#20102;&#30001;&#20110;&#37319;&#26679;&#19981;&#35268;&#21017;&#24615;&#32780;&#20135;&#29983;&#30340;&#25351;&#25968;&#32423;&#30340;&#22122;&#22768;&#65292;&#20294;&#20173;&#28982;&#23384;&#22312;&#25351;&#25968;&#32423;&#30340;&#20449;&#24687;&#37327;&#12290;&#26412;&#32508;&#36848;&#26088;&#22312;&#20445;&#25345;&#22312;&#21487;&#20197;&#30452;&#25509;&#31649;&#29702;&#36825;&#31181;&#25351;&#25968;&#32423;&#32553;&#25918;&#30340;&#39046;&#22495;&#20869;&#12290;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#26159;&#35768;&#22810;&#38382;&#39064;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#65292;&#20294;&#38656;&#35201;&#21478;&#19968;&#31687;&#32508;&#36848;&#25991;&#31456;&#21644;&#36827;&#19968;&#27493;&#30340;&#24605;&#36335;&#12290;&#26412;&#32508;&#36848;&#25551;&#36848;&#20102;&#19968;&#31995;&#21015;&#19978;&#19979;&#25991;&#12290;
&lt;/p&gt;
&lt;p&gt;
Signature-based techniques give mathematical insight into the interactions between complex streams of evolving data. These insights can be quite naturally translated into numerical approaches to understanding streamed data, and perhaps because of their mathematical precision, have proved useful in analysing streamed data in situations where the data is irregular, and not stationary, and the dimension of the data and the sample sizes are both moderate. Understanding streamed multi-modal data is exponential: a word in $n$ letters from an alphabet of size $d$ can be any one of $d^n$ messages. Signatures remove the exponential amount of noise that arises from sampling irregularity, but an exponential amount of information still remain. This survey aims to stay in the domain where that exponential scaling can be managed directly. Scalability issues are an important challenge in many problems but would require another survey article and further ideas. This survey describes a range of context
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23558;&#26799;&#24230; Langevin &#21160;&#21147;&#23398;&#21644;&#21453;&#23556;&#26799;&#24230; Langevin &#21160;&#21147;&#23398;&#25193;&#23637;&#21040;&#38750;&#20984;&#38382;&#39064;&#19978;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#36793;&#30028;&#21453;&#23556;&#21644;&#27010;&#29575;&#34920;&#31034;&#27861;&#65292;&#22312;&#38750;&#20984;&#32422;&#26463;&#38382;&#39064;&#20013;&#25552;&#20986;&#20102;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2203.10215</link><description>&lt;p&gt;
&#21453;&#23556;&#26799;&#24230; Langevin &#21160;&#21147;&#23398;&#25910;&#25947;&#35823;&#24046;&#20998;&#26512;&#65292;&#29992;&#20110;&#20840;&#23616;&#20248;&#21270;&#38750;&#20984;&#32422;&#26463;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Convergence Error Analysis of Reflected Gradient Langevin Dynamics for Globally Optimizing Non-Convex Constrained Problems. (arXiv:2203.10215v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.10215
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#26799;&#24230; Langevin &#21160;&#21147;&#23398;&#21644;&#21453;&#23556;&#26799;&#24230; Langevin &#21160;&#21147;&#23398;&#25193;&#23637;&#21040;&#38750;&#20984;&#38382;&#39064;&#19978;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#36793;&#30028;&#21453;&#23556;&#21644;&#27010;&#29575;&#34920;&#31034;&#27861;&#65292;&#22312;&#38750;&#20984;&#32422;&#26463;&#38382;&#39064;&#20013;&#25552;&#20986;&#20102;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26799;&#24230; Langevin &#21160;&#21147;&#23398;&#21450;&#20854;&#21508;&#31181;&#21464;&#20307;&#30001;&#20110;&#22312;&#26080;&#32422;&#26463;&#20984;&#26694;&#26550;&#20013;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#32780;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#65292;&#26368;&#36817;&#29978;&#33267;&#22312;&#20984;&#32422;&#26463;&#38750;&#20984;&#38382;&#39064;&#20013;&#20063;&#26159;&#22914;&#27492;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#26694;&#26550;&#25193;&#23637;&#21040;&#20855;&#26377;&#20840;&#23616;&#20248;&#21270;&#31639;&#27861;&#30340;&#38750;&#20984;&#38382;&#39064;&#19978;&#65292;&#35813;&#31639;&#27861;&#24314;&#31435;&#22312;&#21453;&#23556;&#26799;&#24230; Langevin &#21160;&#21147;&#23398;&#30340;&#22522;&#30784;&#19978;&#65292;&#24182;&#25512;&#23548;&#20986;&#20854;&#25910;&#25947;&#36895;&#24230;&#12290;&#36890;&#36807;&#26377;&#25928;&#22320;&#21033;&#29992;&#36793;&#30028;&#22788;&#30340;&#21453;&#23556;&#21644;&#24102;&#26377;&#32445;&#26364;&#36793;&#30028;&#26465;&#20214;&#30340;&#27850;&#26494;&#26041;&#31243;&#30340;&#27010;&#29575;&#34920;&#31034;&#65292;&#25105;&#20204;&#21576;&#29616;&#20102;&#26377;&#24076;&#26395;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#20984;&#32422;&#26463;&#38750;&#20984;&#38382;&#39064;&#65292;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#24555;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gradient Langevin dynamics and a variety of its variants have attracted increasing attention owing to their convergence towards the global optimal solution, initially in the unconstrained convex framework while recently even in convex constrained non-convex problems. In the present work, we extend those frameworks to non-convex problems on a non-convex feasible region with a global optimization algorithm built upon reflected gradient Langevin dynamics and derive its convergence rates. By effectively making use of its reflection at the boundary in combination with the probabilistic representation for the Poisson equation with the Neumann boundary condition, we present promising convergence rates, particularly faster than the existing one for convex constrained non-convex problems.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#31232;&#30095;&#38543;&#26426;&#36229;&#22270;&#20013;&#30340;&#31038;&#21306;&#26816;&#27979;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22522;&#20110;&#38750;&#22238;&#36864;&#31639;&#23376;&#30340;&#35889;&#26041;&#27861;&#33021;&#22815;&#39640;&#27010;&#29575;&#19979;&#36798;&#21040;&#29468;&#27979;&#38408;&#20540;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#32500;&#24230;&#32422;&#20943;&#36807;&#31243;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#33021;&#22815;&#35777;&#26126;&#24182;&#39640;&#25928;&#23454;&#29616;HSBM&#29468;&#27979;&#38408;&#20540;&#30340;&#35889;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2203.07346</link><description>&lt;p&gt;
&#31232;&#30095;&#38543;&#26426;&#36229;&#22270;&#65306;&#38750;&#22238;&#36864;&#35889;&#21644;&#31038;&#21306;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Sparse random hypergraphs: Non-backtracking spectra and community detection. (arXiv:2203.07346v4 [math.PR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.07346
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#31232;&#30095;&#38543;&#26426;&#36229;&#22270;&#20013;&#30340;&#31038;&#21306;&#26816;&#27979;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22522;&#20110;&#38750;&#22238;&#36864;&#31639;&#23376;&#30340;&#35889;&#26041;&#27861;&#33021;&#22815;&#39640;&#27010;&#29575;&#19979;&#36798;&#21040;&#29468;&#27979;&#38408;&#20540;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#32500;&#24230;&#32422;&#20943;&#36807;&#31243;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#33021;&#22815;&#35777;&#26126;&#24182;&#39640;&#25928;&#23454;&#29616;HSBM&#29468;&#27979;&#38408;&#20540;&#30340;&#35889;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#22312;&#19968;&#20010;&#31232;&#30095;&#30340;$q$-uniform&#36229;&#22270;$G$&#20013;&#36827;&#34892;&#31038;&#21306;&#26816;&#27979;&#30340;&#38382;&#39064;&#65292;&#20551;&#35774;$G$&#26159;&#26681;&#25454;&#36229;&#22270;&#38543;&#26426;&#22359;&#27169;&#22411;(HSBM)&#29983;&#25104;&#30340;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22522;&#20110;&#36229;&#22270;&#38750;&#22238;&#36864;&#31639;&#23376;&#30340;&#35889;&#26041;&#27861;&#22312;&#39640;&#27010;&#29575;&#19979;&#33021;&#22815;&#36798;&#21040;Angelini&#31561;&#20154;(2015)&#29468;&#27979;&#30340;&#24191;&#20041;Kesten-Stigum&#26816;&#27979;&#38408;&#20540;&#12290;&#25105;&#20204;&#23545;&#31232;&#30095;HSBM&#30340;&#38750;&#22238;&#36864;&#31639;&#23376;&#30340;&#35889;&#36827;&#34892;&#20102;&#34920;&#24449;&#65292;&#24182;&#21033;&#29992;&#36229;&#22270;&#30340;Ihara-Bass&#20844;&#24335;&#25552;&#20379;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#32500;&#24230;&#32422;&#20943;&#36807;&#31243;&#12290;&#22240;&#27492;&#65292;&#23545;&#20110;&#26377;$n$&#20010;&#39030;&#28857;&#30340;&#31232;&#30095;HSBM&#65292;&#31038;&#21306;&#26816;&#27979;&#21487;&#20197;&#32422;&#21270;&#20026;&#19968;&#20010;$2n\times 2n$&#30340;&#38750;&#27491;&#24120;&#30697;&#38453;&#30340;&#29305;&#24449;&#21521;&#37327;&#38382;&#39064;&#65292;&#35813;&#30697;&#38453;&#30001;&#36229;&#22270;&#30340;&#37051;&#25509;&#30697;&#38453;&#21644;&#24230;&#30697;&#38453;&#26500;&#25104;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#33021;&#22815;&#35777;&#26126;&#24182;&#39640;&#25928;&#23454;&#29616;HSBM&#29468;&#27979;&#38408;&#20540;&#30340;&#35889;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the community detection problem in a sparse $q$-uniform hypergraph $G$, assuming that $G$ is generated according to the Hypergraph Stochastic Block Model (HSBM). We prove that a spectral method based on the non-backtracking operator for hypergraphs works with high probability down to the generalized Kesten-Stigum detection threshold conjectured by Angelini et al. (2015). We characterize the spectrum of the non-backtracking operator for the sparse HSBM and provide an efficient dimension reduction procedure using the Ihara-Bass formula for hypergraphs. As a result, community detection for the sparse HSBM on $n$ vertices can be reduced to an eigenvector problem of a $2n\times 2n$ non-normal matrix constructed from the adjacency matrix and the degree matrix of the hypergraph. To the best of our knowledge, this is the first provable and efficient spectral algorithm that achieves the conjectured threshold for HSBMs with $r$ blocks generated according to a general symmetric probab
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#37051;&#22495;&#36873;&#25321;&#26041;&#27861;&#30340;&#39640;&#32500;&#20989;&#25968;&#22270;&#27169;&#22411;&#32467;&#26500;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#20989;&#25968;&#23545;&#20989;&#25968;&#22238;&#24402;&#20272;&#35745;&#33410;&#28857;&#37051;&#22495;&#65292;&#28982;&#21518;&#32467;&#21512;&#36825;&#20123;&#20272;&#35745;&#30340;&#37051;&#22495;&#24674;&#22797;&#25972;&#20010;&#22270;&#32467;&#26500;&#65292;&#20174;&#32780;&#30452;&#25509;&#20272;&#35745;&#26465;&#20214;&#29420;&#31435;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2105.02487</link><description>&lt;p&gt;
&#22522;&#20110;&#37051;&#22495;&#36873;&#25321;&#26041;&#27861;&#30340;&#39640;&#32500;&#20989;&#25968;&#22270;&#27169;&#22411;&#32467;&#26500;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
High-dimensional Functional Graphical Model Structure Learning via Neighborhood Selection Approach. (arXiv:2105.02487v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.02487
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#37051;&#22495;&#36873;&#25321;&#26041;&#27861;&#30340;&#39640;&#32500;&#20989;&#25968;&#22270;&#27169;&#22411;&#32467;&#26500;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#20989;&#25968;&#23545;&#20989;&#25968;&#22238;&#24402;&#20272;&#35745;&#33410;&#28857;&#37051;&#22495;&#65292;&#28982;&#21518;&#32467;&#21512;&#36825;&#20123;&#20272;&#35745;&#30340;&#37051;&#22495;&#24674;&#22797;&#25972;&#20010;&#22270;&#32467;&#26500;&#65292;&#20174;&#32780;&#30452;&#25509;&#20272;&#35745;&#26465;&#20214;&#29420;&#31435;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#21521;&#22270;&#27169;&#22411;&#24191;&#27867;&#29992;&#20110;&#24314;&#27169;&#21521;&#37327;&#20540;&#25968;&#25454;&#30340;&#26465;&#20214;&#29420;&#31435;&#32467;&#26500;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#29616;&#20195;&#24212;&#29992;&#20013;&#65292;&#20363;&#22914;&#28041;&#21450;EEG&#21644;fMRI&#25968;&#25454;&#30340;&#24212;&#29992;&#20013;&#65292;&#35266;&#27979;&#26356;&#36866;&#21512;&#34987;&#24314;&#27169;&#20026;&#22810;&#21464;&#37327;&#38543;&#26426;&#20989;&#25968;&#32780;&#19981;&#26159;&#21521;&#37327;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#20989;&#25968;&#22270;&#27169;&#22411;&#26469;&#24314;&#27169;&#36825;&#31181;&#20989;&#25968;&#25968;&#25454;&#30340;&#26465;&#20214;&#29420;&#31435;&#32467;&#26500;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#37051;&#22495;&#36873;&#25321;&#26041;&#27861;&#26469;&#20272;&#35745;&#39640;&#26031;&#20989;&#25968;&#22270;&#27169;&#22411;&#30340;&#32467;&#26500;&#65292;&#39318;&#20808;&#36890;&#36807;&#20989;&#25968;&#23545;&#20989;&#25968;&#22238;&#24402;&#20272;&#35745;&#27599;&#20010;&#33410;&#28857;&#30340;&#37051;&#22495;&#65292;&#28982;&#21518;&#36890;&#36807;&#32452;&#21512;&#20272;&#35745;&#30340;&#37051;&#22495;&#24674;&#22797;&#25972;&#20010;&#22270;&#32467;&#26500;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20165;&#38656;&#35201;&#23545;&#38543;&#26426;&#20989;&#25968;&#30340;&#26465;&#20214;&#20998;&#24067;&#36827;&#34892;&#20551;&#35774;&#65292;&#24182;&#30452;&#25509;&#20272;&#35745;&#26465;&#20214;&#29420;&#31435;&#32467;&#26500;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#36991;&#20813;&#20102;&#23545;&#21487;&#33021;&#19981;&#23384;&#22312;&#30340;&#31934;&#24230;&#31639;&#23376;&#36827;&#34892;&#26126;&#30830;&#23450;&#20041;&#30340;&#38656;&#35201;&#65292;&#23588;&#20854;&#26159;&#24403;&#20989;&#25968;&#20855;&#26377;&#26080;&#38480;&#32500;&#26102;&#12290;
&lt;/p&gt;
&lt;p&gt;
Undirected graphical models are widely used to model the conditional independence structure of vector-valued data. However, in many modern applications, for example those involving EEG and fMRI data, observations are more appropriately modeled as multivariate random functions rather than vectors. Functional graphical models have been proposed to model the conditional independence structure of such functional data. We propose a neighborhood selection approach to estimate the structure of Gaussian functional graphical models, where we first estimate the neighborhood of each node via a function-on-function regression and subsequently recover the entire graph structure by combining the estimated neighborhoods. Our approach only requires assumptions on the conditional distributions of random functions, and we estimate the conditional independence structure directly. We thus circumvent the need for a well-defined precision operator that may not exist when the functions are infinite dimension
&lt;/p&gt;</description></item></channel></rss>