<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#37325;&#26032;&#24605;&#32771;&#23545;&#25239;&#36870;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#31574;&#30053;&#27169;&#20223;&#21644;&#21487;&#36716;&#31227;&#22870;&#21169;&#24674;&#22797;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#28151;&#21512;&#26694;&#26550;PPO-AIRL + SAC&#20197;&#35299;&#20915;SAC&#31639;&#27861;&#22312;AIRL&#35757;&#32451;&#20013;&#26080;&#27861;&#20840;&#38754;&#35299;&#24320;&#22870;&#21169;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.14593</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#23545;&#25239;&#36870;&#24378;&#21270;&#23398;&#20064;&#65306;&#20174;&#31574;&#30053;&#27169;&#20223;&#21644;&#21487;&#36716;&#31227;&#22870;&#21169;&#24674;&#22797;&#30340;&#35282;&#24230;
&lt;/p&gt;
&lt;p&gt;
Rethinking Adversarial Inverse Reinforcement Learning: From the Angles of Policy Imitation and Transferable Reward Recovery
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14593
&lt;/p&gt;
&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#23545;&#25239;&#36870;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#31574;&#30053;&#27169;&#20223;&#21644;&#21487;&#36716;&#31227;&#22870;&#21169;&#24674;&#22797;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#28151;&#21512;&#26694;&#26550;PPO-AIRL + SAC&#20197;&#35299;&#20915;SAC&#31639;&#27861;&#22312;AIRL&#35757;&#32451;&#20013;&#26080;&#27861;&#20840;&#38754;&#35299;&#24320;&#22870;&#21169;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#36870;&#24378;&#21270;&#23398;&#20064;&#65288;AIRL&#65289;&#20316;&#20026;&#27169;&#20223;&#23398;&#20064;&#20013;&#30340;&#22522;&#30707;&#26041;&#27861;&#12290;&#26412;&#25991;&#37325;&#26032;&#24605;&#32771;&#20102;AIRL&#30340;&#20004;&#20010;&#19981;&#21516;&#35282;&#24230;&#65306;&#31574;&#30053;&#27169;&#20223;&#21644;&#21487;&#36716;&#31227;&#22870;&#21169;&#24674;&#22797;&#12290;&#25105;&#20204;&#20174;&#29992;Soft Actor-Critic&#65288;SAC&#65289;&#26367;&#25442;AIRL&#20013;&#30340;&#20869;&#32622;&#31639;&#27861;&#24320;&#22987;&#65292;&#20197;&#22686;&#24378;&#26679;&#26412;&#25928;&#29575;&#65292;&#36825;&#35201;&#24402;&#21151;&#20110;SAC&#30340;&#31163;&#31574;&#30053;&#24418;&#24335;&#21644;&#30456;&#23545;&#20110;AIRL&#32780;&#35328;&#21487;&#35782;&#21035;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#27169;&#22411;&#12290;&#36825;&#30830;&#23454;&#22312;&#31574;&#30053;&#27169;&#20223;&#26041;&#38754;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;&#20294;&#19981;&#24910;&#32473;&#21487;&#36716;&#31227;&#22870;&#21169;&#24674;&#22797;&#24102;&#26469;&#20102;&#32570;&#28857;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#38416;&#36848;&#20102;SAC&#31639;&#27861;&#26412;&#36523;&#22312;AIRL&#35757;&#32451;&#36807;&#31243;&#20013;&#26080;&#27861;&#20840;&#38754;&#35299;&#24320;&#22870;&#21169;&#20989;&#25968;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#28151;&#21512;&#26694;&#26550;&#65292;PPO-AIRL + SAC&#65292;&#20197;&#33719;&#24471;&#20196;&#20154;&#28385;&#24847;&#30340;&#36716;&#31227;&#25928;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#29615;&#22659;&#25552;&#21462;&#35299;&#24320;&#30340;&#22870;&#21169;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14593v1 Announce Type: new  Abstract: Adversarial inverse reinforcement learning (AIRL) stands as a cornerstone approach in imitation learning. This paper rethinks the two different angles of AIRL: policy imitation and transferable reward recovery. We begin with substituting the built-in algorithm in AIRL with soft actor-critic (SAC) during the policy optimization process to enhance sample efficiency, thanks to the off-policy formulation of SAC and identifiable Markov decision process (MDP) models with respect to AIRL. It indeed exhibits a significant improvement in policy imitation but accidentally brings drawbacks to transferable reward recovery. To learn this issue, we illustrate that the SAC algorithm itself is not feasible to disentangle the reward function comprehensively during the AIRL training process, and propose a hybrid framework, PPO-AIRL + SAC, for satisfactory transfer effect. Additionally, we analyze the capability of environments to extract disentangled rewa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#21487;&#38752;&#24615;&#20998;&#26512;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#20960;&#20010;&#23450;&#29702;&#25506;&#35752;&#20102;&#26368;&#20248;&#23398;&#20064;&#31574;&#30053;&#65292;&#21253;&#25324;&#32771;&#34385;&#21644;&#24573;&#30053;&#26679;&#26412;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#20197;&#21450;&#39034;&#24207;&#22810;&#20010;&#35757;&#32451;&#26679;&#26412;&#22686;&#30410;&#30340;&#29702;&#35770;&#26368;&#20248;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2403.11125</link><description>&lt;p&gt;
&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#21487;&#38752;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Machine learning-based system reliability analysis with Gaussian Process Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11125
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#21487;&#38752;&#24615;&#20998;&#26512;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#20960;&#20010;&#23450;&#29702;&#25506;&#35752;&#20102;&#26368;&#20248;&#23398;&#20064;&#31574;&#30053;&#65292;&#21253;&#25324;&#32771;&#34385;&#21644;&#24573;&#30053;&#26679;&#26412;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#20197;&#21450;&#39034;&#24207;&#22810;&#20010;&#35757;&#32451;&#26679;&#26412;&#22686;&#30410;&#30340;&#29702;&#35770;&#26368;&#20248;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11125v1 &#20844;&#21578;&#31867;&#22411;: &#20132;&#21449; &#25688;&#35201;: &#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#21487;&#38752;&#24615;&#20998;&#26512;&#26041;&#27861;&#22312;&#35745;&#31639;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#24040;&#22823;&#36827;&#23637;&#12290;&#26368;&#36817;&#65292;&#24050;&#32463;&#25552;&#20986;&#35768;&#22810;&#26377;&#25928;&#30340;&#23398;&#20064;&#31574;&#30053;&#26469;&#22686;&#24378;&#35745;&#31639;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#20854;&#20013;&#24456;&#23569;&#26377;&#20154;&#25506;&#35752;&#20102;&#29702;&#35770;&#19978;&#30340;&#26368;&#20248;&#23398;&#20064;&#31574;&#30053;&#12290;&#22312;&#36825;&#31687;&#25991;&#31456;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#20010;&#23450;&#29702;&#26469;&#20419;&#36827;&#36825;&#31181;&#25506;&#32034;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#35814;&#32454;&#38416;&#36848;&#20102;&#32771;&#34385;&#21644;&#24573;&#30053;&#20505;&#36873;&#35774;&#35745;&#26679;&#26412;&#20043;&#38388;&#30456;&#20851;&#24615;&#30340;&#24773;&#20917;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20247;&#25152;&#21608;&#30693;&#30340; U &#23398;&#20064;&#20989;&#25968;&#21487;&#20197;&#37325;&#26032;&#21046;&#23450;&#20026;&#22312;&#24573;&#30053; Kriging &#30456;&#20851;&#24615;&#30340;&#24773;&#20917;&#19979;&#30340;&#26368;&#20248;&#23398;&#20064;&#20989;&#25968;&#12290;&#27492;&#22806;&#65292;&#36824;&#36890;&#36807;&#24102;&#26377;&#30456;&#24212;&#25439;&#22833;&#20989;&#25968;&#30340;&#36125;&#21494;&#26031;&#20272;&#35745;&#25968;&#23398;&#19978;&#25506;&#35752;&#20102;&#39034;&#24207;&#22810;&#20010;&#35757;&#32451;&#26679;&#26412;&#22686;&#30410;&#30340;&#29702;&#35770;&#19978;&#26368;&#20248;&#23398;&#20064;&#31574;&#30053;&#12290;&#27169;&#25311;&#32467;&#26524;&#34920;&#26126;&#26368;&#20248;&#23398;&#20064;&#31574;&#30053;&#8230;&#8230;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11125v1 Announce Type: cross  Abstract: Machine learning-based reliability analysis methods have shown great advancements for their computational efficiency and accuracy. Recently, many efficient learning strategies have been proposed to enhance the computational performance. However, few of them explores the theoretical optimal learning strategy. In this article, we propose several theorems that facilitates such exploration. Specifically, cases that considering and neglecting the correlations among the candidate design samples are well elaborated. Moreover, we prove that the well-known U learning function can be reformulated to the optimal learning function for the case neglecting the Kriging correlation. In addition, the theoretical optimal learning strategy for sequential multiple training samples enrichment is also mathematically explored through the Bayesian estimate with the corresponding lost functions. Simulation results show that the optimal learning strategy consid
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#36719;&#32422;&#26463;&#34203;&#23450;&#35860;&#26725;(SSB)&#25511;&#21046;&#38382;&#39064;&#65292;&#22312;&#20801;&#35768;&#32456;&#31471;&#20998;&#24067;&#19982;&#39044;&#20808;&#25351;&#23450;&#20998;&#24067;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#65292;&#24809;&#32602;&#20004;&#32773;&#20043;&#38388;&#30340;Kullback-Leibler&#25955;&#24230;&#12290;&#29702;&#35770;&#19978;&#25512;&#23548;&#20986;&#20102;SSB&#35299;&#65292;&#26174;&#31034;&#26368;&#20248;&#25511;&#21046;&#36807;&#31243;&#30340;&#32456;&#31471;&#20998;&#24067;&#26159;&#956;T&#21644;&#20854;&#20182;&#20998;&#24067;&#30340;&#20960;&#20309;&#28151;&#21512;&#65292;&#24182;&#23558;&#32467;&#26524;&#25193;&#23637;&#21040;&#26102;&#38388;&#24207;&#21015;&#35774;&#32622;&#12290;</title><link>https://arxiv.org/abs/2403.01717</link><description>&lt;p&gt;
&#36719;&#32422;&#26463;&#34203;&#23450;&#35860;&#26725;&#65306;&#19968;&#31181;&#38543;&#26426;&#25511;&#21046;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Soft-constrained Schrodinger Bridge: a Stochastic Control Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01717
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#36719;&#32422;&#26463;&#34203;&#23450;&#35860;&#26725;(SSB)&#25511;&#21046;&#38382;&#39064;&#65292;&#22312;&#20801;&#35768;&#32456;&#31471;&#20998;&#24067;&#19982;&#39044;&#20808;&#25351;&#23450;&#20998;&#24067;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#65292;&#24809;&#32602;&#20004;&#32773;&#20043;&#38388;&#30340;Kullback-Leibler&#25955;&#24230;&#12290;&#29702;&#35770;&#19978;&#25512;&#23548;&#20986;&#20102;SSB&#35299;&#65292;&#26174;&#31034;&#26368;&#20248;&#25511;&#21046;&#36807;&#31243;&#30340;&#32456;&#31471;&#20998;&#24067;&#26159;&#956;T&#21644;&#20854;&#20182;&#20998;&#24067;&#30340;&#20960;&#20309;&#28151;&#21512;&#65292;&#24182;&#23558;&#32467;&#26524;&#25193;&#23637;&#21040;&#26102;&#38388;&#24207;&#21015;&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34203;&#23450;&#35860;&#26725;&#21487;&#20197;&#34987;&#35270;&#20026;&#19968;&#20010;&#36830;&#32493;&#26102;&#38388;&#30340;&#38543;&#26426;&#25511;&#21046;&#38382;&#39064;&#65292;&#30446;&#26631;&#26159;&#25214;&#21040;&#19968;&#20010;&#26368;&#20248;&#25511;&#21046;&#25193;&#25955;&#36807;&#31243;&#65292;&#20854;&#20855;&#26377;&#39044;&#20808;&#25351;&#23450;&#30340;&#32456;&#31471;&#20998;&#24067;&#956;T&#12290;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#20801;&#35768;&#32456;&#31471;&#20998;&#24067;&#19982;&#956;T&#19981;&#21516;&#20294;&#24809;&#32602;&#20004;&#20010;&#20998;&#24067;&#20043;&#38388;&#30340;Kullback-Leibler&#25955;&#24230;&#26469;&#27867;&#21270;&#36825;&#20010;&#38543;&#26426;&#25511;&#21046;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#26032;&#30340;&#25511;&#21046;&#38382;&#39064;&#31216;&#20026;&#36719;&#32422;&#26463;&#34203;&#23450;&#35860;&#26725;(SSB)&#12290;&#36825;&#39033;&#24037;&#20316;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#23545;SSB&#35299;&#30340;&#29702;&#35770;&#25512;&#23548;&#65292;&#34920;&#26126;&#26368;&#20248;&#25511;&#21046;&#36807;&#31243;&#30340;&#32456;&#31471;&#20998;&#24067;&#26159;&#956;T&#21644;&#21478;&#19968;&#20123;&#20998;&#24067;&#30340;&#20960;&#20309;&#28151;&#21512;&#12290;&#36825;&#20010;&#32467;&#26524;&#36827;&#19968;&#27493;&#25193;&#23637;&#21040;&#26102;&#38388;&#24207;&#21015;&#35774;&#32622;&#12290;SSB&#30340;&#19968;&#20010;&#24212;&#29992;&#26159;&#40065;&#26834;&#29983;&#25104;&#25193;&#25955;&#27169;&#22411;&#30340;&#24320;&#21457;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#20998;&#25968;&#21305;&#37197;&#30340;&#31639;&#27861;&#26469;&#20174;&#20960;&#20309;&#28151;&#21512;&#20013;&#36827;&#34892;&#25277;&#26679;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#29992;&#36884;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01717v1 Announce Type: cross  Abstract: Schr\"{o}dinger bridge can be viewed as a continuous-time stochastic control problem where the goal is to find an optimally controlled diffusion process with a pre-specified terminal distribution $\mu_T$. We propose to generalize this stochastic control problem by allowing the terminal distribution to differ from $\mu_T$ but penalizing the Kullback-Leibler divergence between the two distributions. We call this new control problem soft-constrained Schr\"{o}dinger bridge (SSB). The main contribution of this work is a theoretical derivation of the solution to SSB, which shows that the terminal distribution of the optimally controlled process is a geometric mixture of $\mu_T$ and some other distribution. This result is further extended to a time series setting. One application of SSB is the development of robust generative diffusion models. We propose a score matching-based algorithm for sampling from geometric mixtures and showcase its us
&lt;/p&gt;</description></item><item><title>&#33258;&#27965;&#30340;&#31526;&#21512;&#39044;&#27979;&#26041;&#27861;&#33021;&#22815;&#25552;&#20379;&#26082;&#31526;&#21512;&#26657;&#20934;&#30340;&#39044;&#27979;&#21448;&#31526;&#21512;&#20197;&#27169;&#22411;&#39044;&#27979;&#30340;&#21160;&#20316;&#20026;&#26465;&#20214;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#20026;&#20915;&#31574;&#32773;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#12289;&#38024;&#23545;&#20855;&#20307;&#21160;&#20316;&#30340;&#20915;&#31574;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.07307</link><description>&lt;p&gt;
&#33258;&#27965;&#30340;&#31526;&#21512;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Self-Consistent Conformal Prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07307
&lt;/p&gt;
&lt;p&gt;
&#33258;&#27965;&#30340;&#31526;&#21512;&#39044;&#27979;&#26041;&#27861;&#33021;&#22815;&#25552;&#20379;&#26082;&#31526;&#21512;&#26657;&#20934;&#30340;&#39044;&#27979;&#21448;&#31526;&#21512;&#20197;&#27169;&#22411;&#39044;&#27979;&#30340;&#21160;&#20316;&#20026;&#26465;&#20214;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#20026;&#20915;&#31574;&#32773;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#12289;&#38024;&#23545;&#20855;&#20307;&#21160;&#20316;&#30340;&#20915;&#31574;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#25351;&#23548;&#19979;&#30340;&#20915;&#31574;&#20013;&#65292;&#20915;&#31574;&#32773;&#36890;&#24120;&#22312;&#20855;&#26377;&#30456;&#21516;&#39044;&#27979;&#32467;&#26524;&#30340;&#24773;&#22659;&#20013;&#37319;&#21462;&#30456;&#21516;&#30340;&#34892;&#21160;&#12290;&#31526;&#21512;&#39044;&#27979;&#24110;&#21161;&#20915;&#31574;&#32773;&#37327;&#21270;&#21160;&#20316;&#30340;&#32467;&#26524;&#19981;&#30830;&#23450;&#24615;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#22909;&#30340;&#39118;&#38505;&#31649;&#29702;&#12290;&#21463;&#36825;&#31181;&#35266;&#28857;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#33258;&#27965;&#30340;&#31526;&#21512;&#39044;&#27979;&#65292;&#23427;&#20135;&#29983;&#20102;&#26082;&#31526;&#21512;Venn-Abers&#26657;&#20934;&#30340;&#39044;&#27979;&#65292;&#21448;&#31526;&#21512;&#20197;&#27169;&#22411;&#39044;&#27979;&#24341;&#21457;&#30340;&#21160;&#20316;&#20026;&#26465;&#20214;&#30340;&#31526;&#21512;&#39044;&#27979;&#21306;&#38388;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#21518;&#39564;&#22320;&#24212;&#29992;&#20110;&#20219;&#20309;&#40657;&#30418;&#39044;&#27979;&#22120;&#65292;&#25552;&#20379;&#20005;&#26684;&#30340;&#12289;&#38024;&#23545;&#20855;&#20307;&#21160;&#20316;&#30340;&#20915;&#31574;&#20445;&#35777;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21306;&#38388;&#30340;&#25928;&#29575;&#21644;&#26465;&#20214;&#30340;&#26377;&#25928;&#24615;&#20043;&#38388;&#36798;&#21040;&#20102;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
In decision-making guided by machine learning, decision-makers often take identical actions in contexts with identical predicted outcomes. Conformal prediction helps decision-makers quantify outcome uncertainty for actions, allowing for better risk management. Inspired by this perspective, we introduce self-consistent conformal prediction, which yields both Venn-Abers calibrated predictions and conformal prediction intervals that are valid conditional on actions prompted by model predictions. Our procedure can be applied post-hoc to any black-box predictor to provide rigorous, action-specific decision-making guarantees. Numerical experiments show our approach strikes a balance between interval efficiency and conditional validity.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#20110;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#24378;&#23545;&#25968;&#20985;&#25968;&#25454;&#20998;&#24067;&#20551;&#35774;&#19979;&#30340;&#23436;&#25972;&#25910;&#25947;&#29702;&#35770;&#20445;&#35777;&#65292;&#33719;&#24471;&#20102;&#23545;&#20110;&#21442;&#25968;&#20272;&#35745;&#21644;&#37319;&#26679;&#31639;&#27861;&#30340;&#26368;&#20248;&#19978;&#38480;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2311.13584</link><description>&lt;p&gt;
&#20851;&#20110;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#21450;&#20854;&#35823;&#24046;&#30028;&#38480;&#65306;&#23436;&#20840;&#25910;&#25947;&#20272;&#35745;&#19979;&#30340;&#23545;&#25968;&#20985;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
On diffusion-based generative models and their error bounds: The log-concave case with full convergence estimates
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.13584
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#20110;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#24378;&#23545;&#25968;&#20985;&#25968;&#25454;&#20998;&#24067;&#20551;&#35774;&#19979;&#30340;&#23436;&#25972;&#25910;&#25947;&#29702;&#35770;&#20445;&#35777;&#65292;&#33719;&#24471;&#20102;&#23545;&#20110;&#21442;&#25968;&#20272;&#35745;&#21644;&#37319;&#26679;&#31639;&#27861;&#30340;&#26368;&#20248;&#19978;&#38480;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#24378;&#23545;&#25968;&#20985;&#25968;&#25454;&#20998;&#24067;&#30340;&#20551;&#35774;&#19979;&#20026;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#25910;&#25947;&#34892;&#20026;&#25552;&#20379;&#20102;&#23436;&#25972;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#32780;&#25105;&#20204;&#29992;&#20110;&#24471;&#20998;&#20272;&#35745;&#30340;&#36924;&#36817;&#20989;&#25968;&#31867;&#30001;Lipschitz&#36830;&#32493;&#20989;&#25968;&#32452;&#25104;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#28608;&#21169;&#24615;&#20363;&#23376;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#24378;&#22823;&#20043;&#22788;&#65292;&#21363;&#20174;&#20855;&#26377;&#26410;&#30693;&#22343;&#20540;&#30340;&#39640;&#26031;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23545;&#30456;&#20851;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#21363;&#24471;&#20998;&#20272;&#35745;&#65292;&#25552;&#20379;&#20102;&#26126;&#30830;&#30340;&#20272;&#35745;&#65292;&#21516;&#26102;&#23558;&#20854;&#19982;&#30456;&#24212;&#30340;&#37319;&#26679;&#20272;&#35745;&#32467;&#21512;&#36215;&#26469;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#26368;&#22909;&#30340;&#24050;&#30693;&#19978;&#38480;&#20272;&#35745;&#65292;&#28041;&#21450;&#20851;&#38190;&#24863;&#20852;&#36259;&#30340;&#25968;&#37327;&#65292;&#22914;&#25968;&#25454;&#20998;&#24067;&#65288;&#20855;&#26377;&#26410;&#30693;&#22343;&#20540;&#30340;&#39640;&#26031;&#20998;&#24067;&#65289;&#19982;&#25105;&#20204;&#30340;&#37319;&#26679;&#31639;&#27861;&#20043;&#38388;&#30340;Wasserstein-2&#36317;&#31163;&#30340;&#32500;&#24230;&#21644;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.13584v2 Announce Type: replace  Abstract: We provide full theoretical guarantees for the convergence behaviour of diffusion-based generative models under the assumption of strongly log-concave data distributions while our approximating class of functions used for score estimation is made of Lipschitz continuous functions. We demonstrate via a motivating example, sampling from a Gaussian distribution with unknown mean, the powerfulness of our approach. In this case, explicit estimates are provided for the associated optimization problem, i.e. score approximation, while these are combined with the corresponding sampling estimates. As a result, we obtain the best known upper bound estimates in terms of key quantities of interest, such as the dimension and rates of convergence, for the Wasserstein-2 distance between the data distribution (Gaussian with unknown mean) and our sampling algorithm.   Beyond the motivating example and in order to allow for the use of a diverse range o
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20351;&#29992;&#27169;&#25311;&#25512;&#26029;&#26041;&#27861;&#32467;&#21512;&#33033;&#20914;&#26143;&#31181;&#32676;&#21512;&#25104;&#65292;&#26469;&#38480;&#21046;&#23396;&#31435;&#38134;&#27827;&#23556;&#30005;&#33033;&#20914;&#26143;&#30340;&#30913;&#26059;&#36716;&#29305;&#24615;&#12290;</title><link>http://arxiv.org/abs/2312.14848</link><description>&lt;p&gt;
&#29992;&#22522;&#20110;&#27169;&#25311;&#25512;&#26029;&#30340;&#23396;&#31435;&#33033;&#20914;&#26143;&#31181;&#32676;&#21512;&#25104;
&lt;/p&gt;
&lt;p&gt;
Isolated pulsar population synthesis with simulation-based inference. (arXiv:2312.14848v1 [astro-ph.HE] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.14848
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20351;&#29992;&#27169;&#25311;&#25512;&#26029;&#26041;&#27861;&#32467;&#21512;&#33033;&#20914;&#26143;&#31181;&#32676;&#21512;&#25104;&#65292;&#26469;&#38480;&#21046;&#23396;&#31435;&#38134;&#27827;&#23556;&#30005;&#33033;&#20914;&#26143;&#30340;&#30913;&#26059;&#36716;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#33033;&#20914;&#26143;&#31181;&#32676;&#21512;&#25104;&#19982;&#22522;&#20110;&#27169;&#25311;&#25512;&#26029;&#30456;&#32467;&#21512;&#65292;&#20197;&#38480;&#21046;&#23396;&#31435;&#38134;&#27827;&#23556;&#30005;&#33033;&#20914;&#26143;&#30340;&#30913;&#26059;&#36716;&#29305;&#24615;&#12290;&#25105;&#20204;&#39318;&#20808;&#26500;&#24314;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#26694;&#26550;&#26469;&#27169;&#25311;&#20013;&#23376;&#26143;&#30340;&#35806;&#29983;&#29305;&#24615;&#21644;&#28436;&#21270;&#65292;&#37325;&#28857;&#26159;&#23427;&#20204;&#30340;&#21160;&#21147;&#23398;&#12289;&#26059;&#36716;&#21644;&#30913;&#24615;&#29305;&#24449;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#20174;&#23545;&#25968;&#27491;&#24577;&#20998;&#24067;&#20013;&#37319;&#26679;&#21021;&#22987;&#30913;&#22330;&#24378;&#24230;B&#21644;&#33258;&#36716;&#21608;&#26399;P&#65292;&#24182;&#29992;&#24130;&#24459;&#26469;&#25429;&#25417;&#21518;&#26399;&#30913;&#22330;&#30340;&#34928;&#20943;&#12290;&#27599;&#20010;&#23545;&#25968;&#27491;&#24577;&#20998;&#24067;&#30001;&#22343;&#20540;&#956;logB&#65292;&#956;logP&#21644;&#26631;&#20934;&#24046;&#963;logB&#65292;&#963;logP&#25551;&#36848;&#65292;&#32780;&#24130;&#24459;&#30001;&#25351;&#25968;a_late&#25551;&#36848;&#65292;&#20849;&#35745;&#20116;&#20010;&#33258;&#30001;&#21442;&#25968;&#12290;&#28982;&#21518;&#25105;&#20204;&#27169;&#25311;&#20102;&#26143;&#20307;&#30340;&#23556;&#30005;&#21457;&#23556;&#21644;&#35266;&#27979;&#20559;&#24046;&#65292;&#20197;&#27169;&#25311;&#19977;&#20010;&#23556;&#30005;&#35843;&#26597;&#20013;&#30340;&#25506;&#27979;&#65292;&#24182;&#36890;&#36807;&#25913;&#21464;&#36755;&#20837;&#21442;&#25968;&#20135;&#29983;&#20102;&#19968;&#20010;&#22823;&#22411;&#30340;&#21512;&#25104;P-&#7766;&#22270;&#25968;&#25454;&#24211;&#12290;&#25509;&#30528;&#25105;&#20204;&#37319;&#29992;&#22522;&#20110;&#27169;&#25311;&#25512;&#26029;&#30340;&#26041;&#27861;&#36827;&#34892;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
We combine pulsar population synthesis with simulation-based inference to constrain the magneto-rotational properties of isolated Galactic radio pulsars. We first develop a flexible framework to model neutron-star birth properties and evolution, focusing on their dynamical, rotational and magnetic characteristics. In particular, we sample initial magnetic-field strengths, $B$, and spin periods, $P$, from log-normal distributions and capture the late-time magnetic-field decay with a power law. Each log-normal is described by a mean, $\mu_{\log B}, \mu_{\log P}$, and standard deviation, $\sigma_{\log B}, \sigma_{\log P}$, while the power law is characterized by the index, $a_{\rm late}$, resulting in five free parameters. We subsequently model the stars' radio emission and observational biases to mimic detections with three radio surveys, and produce a large database of synthetic $P$-$\dot{P}$ diagrams by varying our input parameters. We then follow a simulation-based inference approach 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#20998;&#26512;&#20102;&#20581;&#24247;&#20010;&#20307;&#30340;&#24515;&#30005;&#22270;&#25968;&#25454;&#65292;&#24182;&#35782;&#21035;&#20986;&#38543;&#24180;&#40836;&#22686;&#38271;&#21628;&#21560;&#29575;&#30340;&#19979;&#38477;&#21450;SDANN&#20540;&#24322;&#24120;&#39640;&#20316;&#20026;&#32769;&#24180;&#20154;&#30340;&#25351;&#26631;&#12290;</title><link>http://arxiv.org/abs/2310.07463</link><description>&lt;p&gt;
&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#25581;&#31034;&#20581;&#24247;&#34928;&#32769;&#36807;&#31243;&#20013;&#30340;&#24515;&#30005;&#22270;&#21464;&#21270;
&lt;/p&gt;
&lt;p&gt;
Uncovering ECG Changes during Healthy Aging using Explainable AI. (arXiv:2310.07463v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07463
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#20998;&#26512;&#20102;&#20581;&#24247;&#20010;&#20307;&#30340;&#24515;&#30005;&#22270;&#25968;&#25454;&#65292;&#24182;&#35782;&#21035;&#20986;&#38543;&#24180;&#40836;&#22686;&#38271;&#21628;&#21560;&#29575;&#30340;&#19979;&#38477;&#21450;SDANN&#20540;&#24322;&#24120;&#39640;&#20316;&#20026;&#32769;&#24180;&#20154;&#30340;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24515;&#34880;&#31649;&#30142;&#30149;&#20173;&#28982;&#26159;&#20840;&#29699;&#39046;&#20808;&#30340;&#27515;&#22240;&#12290;&#36825;&#38656;&#35201;&#23545;&#24515;&#33039;&#34928;&#32769;&#36807;&#31243;&#26377;&#28145;&#20837;&#30340;&#20102;&#35299;&#65292;&#20197;&#35786;&#26029;&#24515;&#34880;&#31649;&#20581;&#24247;&#29366;&#20917;&#30340;&#38480;&#21046;&#12290;&#20256;&#32479;&#19978;&#65292;&#23545;&#20010;&#20307;&#24515;&#30005;&#22270;&#65288;ECG&#65289;&#29305;&#24449;&#38543;&#24180;&#40836;&#21464;&#21270;&#30340;&#20998;&#26512;&#25552;&#20379;&#20102;&#36825;&#20123;&#35265;&#35299;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#29305;&#24449;&#34429;&#28982;&#26377;&#20449;&#24687;&#37327;&#65292;&#20294;&#21487;&#33021;&#25513;&#30422;&#20102;&#24213;&#23618;&#25968;&#25454;&#20851;&#31995;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21644;&#22522;&#20110;&#26641;&#30340;&#27169;&#22411;&#20998;&#26512;&#26469;&#33258;&#20581;&#24247;&#20010;&#20307;&#30340;ECG&#25968;&#25454;&#65292;&#21253;&#25324;&#21407;&#22987;&#20449;&#21495;&#21644;ECG&#29305;&#24449;&#26684;&#24335;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;AI&#25216;&#26415;&#26469;&#35782;&#21035;&#23545;&#20110;&#21306;&#20998;&#24180;&#40836;&#32452;&#21035;&#26368;&#26377;&#36776;&#21035;&#21147;&#30340;ECG&#29305;&#24449;&#25110;&#21407;&#22987;&#20449;&#21495;&#29305;&#24449;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#19982;&#22522;&#20110;&#26641;&#30340;&#20998;&#31867;&#22120;&#25581;&#31034;&#20102;&#38543;&#24180;&#40836;&#22686;&#38271;&#21628;&#21560;&#29575;&#19979;&#38477;&#65292;&#24182;&#35782;&#21035;&#20986;SDANN&#20540;&#24322;&#24120;&#39640;&#20316;&#20026;&#32769;&#24180;&#20154;&#30340;&#25351;&#26631;&#65292;&#21487;&#23558;&#20854;&#19982;&#24180;&#36731;&#20154;&#21306;&#20998;&#24320;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cardiovascular diseases remain the leading global cause of mortality. This necessitates a profound understanding of heart aging processes to diagnose constraints in cardiovascular fitness. Traditionally, most of such insights have been drawn from the analysis of electrocardiogram (ECG) feature changes of individuals as they age. However, these features, while informative, may potentially obscure underlying data relationships. In this paper, we employ a deep-learning model and a tree-based model to analyze ECG data from a robust dataset of healthy individuals across varying ages in both raw signals and ECG feature format. Explainable AI techniques are then used to identify ECG features or raw signal characteristics are most discriminative for distinguishing between age groups. Our analysis with tree-based classifiers reveal age-related declines in inferred breathing rates and identifies notably high SDANN values as indicative of elderly individuals, distinguishing them from younger adul
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#26368;&#20248;&#36755;&#36816;&#26469;&#34701;&#21512;&#22522;&#20110;Transformer&#30340;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23545;&#40784;&#21508;&#31181;&#26550;&#26500;&#32452;&#20214;&#24182;&#20801;&#35768;&#19981;&#21516;&#22823;&#23567;&#30340;&#27169;&#22411;&#30340;&#34701;&#21512;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#25928;&#21387;&#32553;Transformer&#30340;&#26041;&#24335;&#12290;</title><link>http://arxiv.org/abs/2310.05719</link><description>&lt;p&gt;
&#20351;&#29992;&#26368;&#20248;&#36755;&#36816;&#22120;&#21512;&#24182;Transformer
&lt;/p&gt;
&lt;p&gt;
Transformer Fusion with Optimal Transport. (arXiv:2310.05719v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05719
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#26368;&#20248;&#36755;&#36816;&#26469;&#34701;&#21512;&#22522;&#20110;Transformer&#30340;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23545;&#40784;&#21508;&#31181;&#26550;&#26500;&#32452;&#20214;&#24182;&#20801;&#35768;&#19981;&#21516;&#22823;&#23567;&#30340;&#27169;&#22411;&#30340;&#34701;&#21512;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#25928;&#21387;&#32553;Transformer&#30340;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34701;&#21512;&#26159;&#19968;&#31181;&#23558;&#22810;&#20010;&#29420;&#31435;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#21512;&#24182;&#20197;&#32467;&#21512;&#23427;&#20204;&#30340;&#33021;&#21147;&#30340;&#25216;&#26415;&#12290;&#36807;&#21435;&#30340;&#23581;&#35797;&#20165;&#38480;&#20110;&#20840;&#36830;&#25509;&#12289;&#21367;&#31215;&#21644;&#27531;&#24046;&#32593;&#32476;&#30340;&#24773;&#20917;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31995;&#32479;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#26368;&#20248;&#36755;&#36816;&#26469;&#34701;&#21512;&#20004;&#20010;&#25110;&#22810;&#20010;&#22522;&#20110;Transformer&#30340;&#32593;&#32476;&#65292;&#20197;&#65288;&#36719;&#65289;&#23545;&#40784;&#21508;&#31181;&#26550;&#26500;&#32452;&#20214;&#12290;&#25105;&#20204;&#35814;&#32454;&#25551;&#36848;&#20102;&#19968;&#31181;&#23618;&#23545;&#40784;&#30340;&#25277;&#35937;&#26041;&#27861;&#65292;&#21487;&#20197;&#25512;&#24191;&#21040;&#20219;&#24847;&#26550;&#26500;&#65292;&#20363;&#22914;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#12289;&#23618;&#24402;&#19968;&#21270;&#21644;&#27531;&#24046;&#36830;&#25509;&#12290;&#25105;&#20204;&#36890;&#36807;&#21508;&#31181;&#28040;&#34701;&#30740;&#31350;&#35752;&#35770;&#20102;&#22914;&#20309;&#22788;&#29702;&#36825;&#20123;&#26550;&#26500;&#32452;&#20214;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#19981;&#21516;&#22823;&#23567;&#30340;&#27169;&#22411;&#36827;&#34892;&#34701;&#21512;&#65288;&#24322;&#26500;&#34701;&#21512;&#65289;&#65292;&#20026;Transformer&#30340;&#21387;&#32553;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#25928;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;Vision Transformer&#36827;&#34892;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#20197;&#21450;&#33258;&#28982;&#35821;&#35328;
&lt;/p&gt;
&lt;p&gt;
Fusion is a technique for merging multiple independently-trained neural networks in order to combine their capabilities. Past attempts have been restricted to the case of fully-connected, convolutional, and residual networks. In this paper, we present a systematic approach for fusing two or more transformer-based networks exploiting Optimal Transport to (soft-)align the various architectural components. We flesh out an abstraction for layer alignment, that can generalize to arbitrary architectures -- in principle -and we apply this to the key ingredients of Transformers such as multi-head self-attention, layer-normalization, and residual connections, and we discuss how to handle them via various ablation studies. Furthermore, our method allows the fusion of models of different sizes (heterogeneous fusion), providing a new and efficient way for compression of Transformers. The proposed approach is evaluated on both image classification tasks via Vision Transformer and natural language
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#23398;&#20064;&#21644;&#36125;&#21494;&#26031;Spike-and-Slab&#20808;&#39564;&#30340;&#26041;&#31243;&#24335;&#21457;&#29616;&#26041;&#27861;&#65292;&#36890;&#36807;&#26680;&#22238;&#24402;&#21644;&#36125;&#21494;&#26031;&#31232;&#30095;&#20998;&#24067;&#65292;&#33021;&#22815;&#26377;&#25928;&#22788;&#29702;&#25968;&#25454;&#31232;&#30095;&#24615;&#21644;&#22122;&#22768;&#38382;&#39064;&#65292;&#24182;&#36827;&#34892;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#39640;&#25928;&#30340;&#21518;&#39564;&#25512;&#26029;&#21644;&#20989;&#25968;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2310.05387</link><description>&lt;p&gt;
&#22522;&#20110;&#36125;&#21494;&#26031;Spike-and-Slab&#20808;&#39564;&#21644;&#39640;&#25928;&#26680;&#20989;&#25968;&#30340;&#26041;&#31243;&#24335;&#21457;&#29616;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Equation Discovery with Bayesian Spike-and-Slab Priors and Efficient Kernels. (arXiv:2310.05387v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05387
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#23398;&#20064;&#21644;&#36125;&#21494;&#26031;Spike-and-Slab&#20808;&#39564;&#30340;&#26041;&#31243;&#24335;&#21457;&#29616;&#26041;&#27861;&#65292;&#36890;&#36807;&#26680;&#22238;&#24402;&#21644;&#36125;&#21494;&#26031;&#31232;&#30095;&#20998;&#24067;&#65292;&#33021;&#22815;&#26377;&#25928;&#22788;&#29702;&#25968;&#25454;&#31232;&#30095;&#24615;&#21644;&#22122;&#22768;&#38382;&#39064;&#65292;&#24182;&#36827;&#34892;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#39640;&#25928;&#30340;&#21518;&#39564;&#25512;&#26029;&#21644;&#20989;&#25968;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#25968;&#25454;&#20013;&#21457;&#29616;&#25511;&#21046;&#26041;&#31243;&#23545;&#20110;&#35768;&#22810;&#31185;&#23398;&#21644;&#24037;&#31243;&#24212;&#29992;&#38750;&#24120;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#26377;&#19968;&#20123;&#26377;&#24076;&#26395;&#30340;&#25104;&#21151;&#26696;&#20363;&#65292;&#29616;&#26377;&#26041;&#27861;&#20173;&#28982;&#38754;&#20020;&#30528;&#25968;&#25454;&#31232;&#30095;&#24615;&#21644;&#22122;&#22768;&#38382;&#39064;&#30340;&#25361;&#25112;&#65292;&#36825;&#22312;&#23454;&#36341;&#20013;&#38543;&#22788;&#21487;&#35265;&#12290;&#27492;&#22806;&#65292;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#32570;&#20047;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;/&#25110;&#35757;&#32451;&#25104;&#26412;&#39640;&#26114;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#23398;&#20064;&#21644;&#36125;&#21494;&#26031;Spike-and-Slab&#20808;&#39564;&#65288;KBASS&#65289;&#30340;&#26032;&#22411;&#26041;&#31243;&#24335;&#21457;&#29616;&#26041;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;&#26680;&#22238;&#24402;&#26469;&#20272;&#35745;&#30446;&#26631;&#20989;&#25968;&#65292;&#36825;&#31181;&#26041;&#27861;&#20855;&#26377;&#28789;&#27963;&#24615;&#12289;&#34920;&#36798;&#21147;&#65292;&#24182;&#19988;&#23545;&#20110;&#25968;&#25454;&#31232;&#30095;&#24615;&#21644;&#22122;&#22768;&#26356;&#21152;&#31283;&#20581;&#12290;&#25105;&#20204;&#23558;&#20854;&#19982;&#36125;&#21494;&#26031;Spike-and-Slab&#20808;&#39564;&#32467;&#21512;&#20351;&#29992;&#65292;&#21518;&#32773;&#26159;&#19968;&#31181;&#29702;&#24819;&#30340;&#36125;&#21494;&#26031;&#31232;&#30095;&#20998;&#24067;&#65292;&#29992;&#20110;&#26377;&#25928;&#30340;&#31639;&#23376;&#36873;&#25321;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#26399;&#26395;&#20256;&#25773;&#26399;&#26395;&#26368;&#22823;&#21270;&#65288;EP-EM&#65289;&#31639;&#27861;&#30340;&#26377;&#25928;&#21518;&#39564;&#25512;&#26029;&#21644;&#20989;&#25968;&#20272;&#35745;&#26041;&#27861;&#12290;&#20026;&#20102;&#20811;&#26381;&#26680;&#22238;&#24402;&#30340;&#35745;&#31639;&#25361;&#25112;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#31181;&#24555;&#36895;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Discovering governing equations from data is important to many scientific and engineering applications. Despite promising successes, existing methods are still challenged by data sparsity as well as noise issues, both of which are ubiquitous in practice. Moreover, state-of-the-art methods lack uncertainty quantification and/or are costly in training. To overcome these limitations, we propose a novel equation discovery method based on Kernel learning and BAyesian Spike-and-Slab priors (KBASS). We use kernel regression to estimate the target function, which is flexible, expressive, and more robust to data sparsity and noises. We combine it with a Bayesian spike-and-slab prior -- an ideal Bayesian sparse distribution -- for effective operator selection and uncertainty quantification. We develop an expectation propagation expectation-maximization (EP-EM) algorithm for efficient posterior inference and function estimation. To overcome the computational challenge of kernel regression, we pla
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24191;&#20041;&#20132;&#21449;&#39564;&#35777;&#65288;GCV&#65289;&#22312;&#26377;&#38480;&#24809;&#32602;&#20272;&#35745;&#22120;&#38598;&#21512;&#20013;&#20272;&#35745;&#39044;&#27979;&#39118;&#38505;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#27491;&#26041;&#27861;&#65288;CGCV&#65289;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.01374</link><description>&lt;p&gt;
&#26377;&#38480;&#24809;&#32602;&#20272;&#35745;&#22120;&#38598;&#21512;&#30340;&#20462;&#27491;&#24191;&#20041;&#20132;&#21449;&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;
Corrected generalized cross-validation for finite ensembles of penalized estimators. (arXiv:2310.01374v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01374
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24191;&#20041;&#20132;&#21449;&#39564;&#35777;&#65288;GCV&#65289;&#22312;&#26377;&#38480;&#24809;&#32602;&#20272;&#35745;&#22120;&#38598;&#21512;&#20013;&#20272;&#35745;&#39044;&#27979;&#39118;&#38505;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#27491;&#26041;&#27861;&#65288;CGCV&#65289;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24191;&#20041;&#20132;&#21449;&#39564;&#35777;&#65288;GCV&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#22312;&#26679;&#26412;&#22806;&#36827;&#34892;&#39044;&#27979;&#30340;&#39118;&#38505;&#24179;&#26041;&#65292;&#24182;&#37319;&#29992;&#26631;&#37327;&#33258;&#30001;&#24230;&#35843;&#25972;&#65288;&#20197;&#20056;&#27861;&#22686;&#21152;&#65289;&#26469;&#35843;&#25972;&#35757;&#32451;&#35823;&#24046;&#30340;&#24179;&#26041;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;GCV&#19968;&#33268;&#20272;&#35745;&#20219;&#24847;&#24809;&#32602;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#38598;&#21512;&#39044;&#27979;&#39118;&#38505;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23545;&#20110;&#20219;&#20309;&#22823;&#20110;&#19968;&#30340;&#26377;&#38480;&#22823;&#23567;&#30340;&#20272;&#35745;&#22120;&#38598;&#21512;&#65292;GCV&#26159;&#19981;&#19968;&#33268;&#30340;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#20010;&#32570;&#28857;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32416;&#27491;&#65292;&#23427;&#28041;&#21450;&#21040;&#23545;&#27599;&#20010;&#38598;&#21512;&#25104;&#20998;&#30340;&#33258;&#30001;&#24230;&#35843;&#25972;&#35757;&#32451;&#35823;&#24046;&#30340;&#39069;&#22806;&#26631;&#37327;&#20462;&#27491;&#65288;&#20197;&#21152;&#27861;&#22686;&#21152;&#65289;&#12290;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#65288;&#31216;&#20026;CGCV&#65289;&#20445;&#25345;&#20102;GCV&#30340;&#35745;&#31639;&#20248;&#21183;&#65292;&#26082;&#19981;&#38656;&#35201;&#26679;&#26412;&#20998;&#35010;&#65292;&#27169;&#22411;&#37325;&#25311;&#65292;&#20063;&#19981;&#38656;&#35201;&#21253;&#22806;&#39118;&#38505;&#20272;&#35745;&#12290;&#35813;&#20272;&#35745;&#22120;&#28304;&#33258;&#23545;&#38598;&#21512;&#39118;&#38505;&#20998;&#35299;&#30340;&#32454;&#33268;&#26816;&#26597;&#21644;&#35813;&#20998;&#35299;&#20013;&#21508;&#20010;&#25104;&#20998;&#30340;&#20004;&#31181;&#20013;&#38388;&#39118;&#38505;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generalized cross-validation (GCV) is a widely-used method for estimating the squared out-of-sample prediction risk that employs a scalar degrees of freedom adjustment (in a multiplicative sense) to the squared training error. In this paper, we examine the consistency of GCV for estimating the prediction risk of arbitrary ensembles of penalized least squares estimators. We show that GCV is inconsistent for any finite ensemble of size greater than one. Towards repairing this shortcoming, we identify a correction that involves an additional scalar correction (in an additive sense) based on degrees of freedom adjusted training errors from each ensemble component. The proposed estimator (termed CGCV) maintains the computational advantages of GCV and requires neither sample splitting, model refitting, or out-of-bag risk estimation. The estimator stems from a finer inspection of ensemble risk decomposition and two intermediate risk estimators for the components in this decomposition. We prov
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23384;&#22312;&#28151;&#28102;&#25928;&#24212;&#26102;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27491;&#20132;&#32467;&#26500;&#21644;&#32447;&#24615;&#25237;&#24433;&#30340;&#32479;&#35745;&#20272;&#35745;&#21644;&#25512;&#26029;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#30001;&#20110;&#26410;&#27979;&#28151;&#28102;&#22240;&#32032;&#24341;&#36215;&#30340;&#20559;&#24046;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.07261</link><description>&lt;p&gt;
&#20855;&#26377;&#26410;&#27979;&#28151;&#28102;&#22240;&#32032;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#21516;&#26102;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Simultaneous inference for generalized linear models with unmeasured confounders. (arXiv:2309.07261v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07261
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23384;&#22312;&#28151;&#28102;&#25928;&#24212;&#26102;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27491;&#20132;&#32467;&#26500;&#21644;&#32447;&#24615;&#25237;&#24433;&#30340;&#32479;&#35745;&#20272;&#35745;&#21644;&#25512;&#26029;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#30001;&#20110;&#26410;&#27979;&#28151;&#28102;&#22240;&#32032;&#24341;&#36215;&#30340;&#20559;&#24046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#22240;&#32452;&#30740;&#31350;&#20013;&#65292;&#24120;&#24120;&#36827;&#34892;&#25104;&#21315;&#19978;&#19975;&#20010;&#21516;&#26102;&#20551;&#35774;&#26816;&#39564;&#65292;&#20197;&#30830;&#23450;&#24046;&#24322;&#34920;&#36798;&#30340;&#22522;&#22240;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23384;&#22312;&#26410;&#27979;&#28151;&#28102;&#22240;&#32032;&#65292;&#35768;&#22810;&#26631;&#20934;&#32479;&#35745;&#26041;&#27861;&#21487;&#33021;&#23384;&#22312;&#20005;&#37325;&#30340;&#20559;&#24046;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#23384;&#22312;&#28151;&#28102;&#25928;&#24212;&#26102;&#30340;&#22810;&#20803;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#12290;&#22312;&#20219;&#24847;&#28151;&#28102;&#26426;&#21046;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#32479;&#35745;&#20272;&#35745;&#21644;&#25512;&#26029;&#26041;&#27861;&#65292;&#21033;&#29992;&#27491;&#20132;&#32467;&#26500;&#24182;&#23558;&#32447;&#24615;&#25237;&#24433;&#25972;&#21512;&#21040;&#19977;&#20010;&#20851;&#38190;&#38454;&#27573;&#20013;&#12290;&#39318;&#20808;&#65292;&#21033;&#29992;&#22810;&#20803;&#21709;&#24212;&#21464;&#37327;&#20998;&#31163;&#36793;&#38469;&#21644;&#19981;&#30456;&#20851;&#30340;&#28151;&#28102;&#25928;&#24212;&#65292;&#24674;&#22797;&#28151;&#28102;&#31995;&#25968;&#30340;&#21015;&#31354;&#38388;&#12290;&#38543;&#21518;&#65292;&#21033;&#29992;$\ell_1$&#27491;&#21017;&#21270;&#36827;&#34892;&#31232;&#30095;&#24615;&#20272;&#35745;&#65292;&#24182;&#24378;&#21152;&#27491;&#20132;&#24615;&#38480;&#21046;&#20110;&#28151;&#28102;&#31995;&#25968;&#65292;&#32852;&#21512;&#20272;&#35745;&#28508;&#22312;&#22240;&#23376;&#21644;&#20027;&#35201;&#25928;&#24212;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#32467;&#21512;&#25237;&#24433;&#21644;&#21152;&#26435;&#20559;&#24046;&#26657;&#27491;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tens of thousands of simultaneous hypothesis tests are routinely performed in genomic studies to identify differentially expressed genes. However, due to unmeasured confounders, many standard statistical approaches may be substantially biased. This paper investigates the large-scale hypothesis testing problem for multivariate generalized linear models in the presence of confounding effects. Under arbitrary confounding mechanisms, we propose a unified statistical estimation and inference framework that harnesses orthogonal structures and integrates linear projections into three key stages. It first leverages multivariate responses to separate marginal and uncorrelated confounding effects, recovering the confounding coefficients' column space. Subsequently, latent factors and primary effects are jointly estimated, utilizing $\ell_1$-regularization for sparsity while imposing orthogonality onto confounding coefficients. Finally, we incorporate projected and weighted bias-correction steps 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;oracle&#22411;&#19981;&#31561;&#24335;&#65292;&#36890;&#36807;&#35299;&#20915;&#36923;&#36753;&#25439;&#22833;&#30340;&#30446;&#26631;&#20989;&#25968;&#26080;&#30028;&#24615;&#38480;&#21046;&#65292;&#25512;&#23548;&#20986;&#20351;&#29992;&#36923;&#36753;&#25439;&#22833;&#35757;&#32451;&#30340;&#20840;&#36830;&#25509;ReLU&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#20165;&#35201;&#27714;&#25968;&#25454;&#30340;&#26465;&#20214;&#31867;&#27010;&#29575;&#20855;&#26377;H\"older&#24179;&#28369;&#24615;&#65292;&#24182;&#19988;&#32771;&#34385;&#20102;&#32452;&#21512;&#20551;&#35774;&#65292;&#20351;&#24471;&#35813;&#26041;&#27861;&#20855;&#26377;&#26356;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.16792</link><description>&lt;p&gt;
&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#36923;&#36753;&#25439;&#22833;&#36827;&#34892;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Classification with Deep Neural Networks and Logistic Loss. (arXiv:2307.16792v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16792
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;oracle&#22411;&#19981;&#31561;&#24335;&#65292;&#36890;&#36807;&#35299;&#20915;&#36923;&#36753;&#25439;&#22833;&#30340;&#30446;&#26631;&#20989;&#25968;&#26080;&#30028;&#24615;&#38480;&#21046;&#65292;&#25512;&#23548;&#20986;&#20351;&#29992;&#36923;&#36753;&#25439;&#22833;&#35757;&#32451;&#30340;&#20840;&#36830;&#25509;ReLU&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#20165;&#35201;&#27714;&#25968;&#25454;&#30340;&#26465;&#20214;&#31867;&#27010;&#29575;&#20855;&#26377;H\"older&#24179;&#28369;&#24615;&#65292;&#24182;&#19988;&#32771;&#34385;&#20102;&#32452;&#21512;&#20551;&#35774;&#65292;&#20351;&#24471;&#35813;&#26041;&#27861;&#20855;&#26377;&#26356;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#36923;&#36753;&#25439;&#22833;&#65288;&#21363;&#20132;&#21449;&#29109;&#25439;&#22833;&#65289;&#35757;&#32451;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#21508;&#31181;&#20108;&#20998;&#31867;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#36923;&#36753;&#25439;&#22833;&#36827;&#34892;&#20108;&#20998;&#31867;&#30340;&#27867;&#21270;&#20998;&#26512;&#20173;&#28982;&#24456;&#23569;&#12290;&#36923;&#36753;&#25439;&#22833;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;&#26080;&#30028;&#24615;&#26159;&#23548;&#33268;&#25512;&#23548;&#20986;&#20196;&#20154;&#28385;&#24847;&#30340;&#27867;&#21270;&#30028;&#38480;&#30340;&#20027;&#35201;&#38556;&#30861;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#24314;&#31435;&#19968;&#31181;&#26032;&#39062;&#32780;&#20248;&#38597;&#30340;oracle&#22411;&#19981;&#31561;&#24335;&#26469;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#35813;&#19981;&#31561;&#24335;&#20351;&#25105;&#20204;&#33021;&#22815;&#22788;&#29702;&#30446;&#26631;&#20989;&#25968;&#30340;&#26377;&#30028;&#24615;&#38480;&#21046;&#65292;&#24182;&#21033;&#29992;&#23427;&#25512;&#23548;&#20986;&#20351;&#29992;&#36923;&#36753;&#25439;&#22833;&#35757;&#32451;&#30340;&#20840;&#36830;&#25509;ReLU&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#20165;&#38656;&#35201;&#25968;&#25454;&#30340;&#26465;&#20214;&#31867;&#27010;&#29575;$\eta$&#30340;H\"older&#24179;&#28369;&#24615;&#65292;&#23601;&#21487;&#20197;&#33719;&#24471;&#26368;&#20248;&#30340;&#25910;&#25947;&#36895;&#29575;&#65288;&#20165;&#38480;&#20110;&#23545;&#25968;&#22240;&#23376;&#65289;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#32452;&#21512;&#20551;&#35774;&#65292;&#35201;&#27714;$\eta$&#26159;&#33509;&#24178;&#21521;&#37327;&#20540;&#20989;&#25968;&#30340;&#22797;&#21512;&#20989;&#25968;&#65292;&#20854;&#20013;&#27599;&#20010;&#21521;&#37327;&#20540;&#20989;&#25968;&#37117;&#26159;&#29420;&#31435;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks (DNNs) trained with the logistic loss (i.e., the cross entropy loss) have made impressive advancements in various binary classification tasks. However, generalization analysis for binary classification with DNNs and logistic loss remains scarce. The unboundedness of the target function for the logistic loss is the main obstacle to deriving satisfying generalization bounds. In this paper, we aim to fill this gap by establishing a novel and elegant oracle-type inequality, which enables us to deal with the boundedness restriction of the target function, and using it to derive sharp convergence rates for fully connected ReLU DNN classifiers trained with logistic loss. In particular, we obtain optimal convergence rates (up to log factors) only requiring the H\"older smoothness of the conditional class probability $\eta$ of data. Moreover, we consider a compositional assumption that requires $\eta$ to be the composition of several vector-valued functions of which each co
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#37325;&#35201;&#24615;&#25277;&#26679;&#23454;&#29616;&#26377;&#25928;&#36890;&#20449;&#30340;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#65292;&#22823;&#22823;&#38477;&#20302;&#20102;&#21457;&#36865;&#27169;&#22411;&#26356;&#26032;&#30340;&#39640;&#36890;&#20449;&#25104;&#26412;&#65292;&#21033;&#29992;&#26381;&#21153;&#22120;&#31471;&#23458;&#25143;&#31471;&#20998;&#24067;&#21644;&#38468;&#21152;&#20449;&#24687;&#30340;&#25509;&#36817;&#20851;&#31995;&#65292;&#21482;&#38656;&#35201;&#36739;&#23569;&#30340;&#36890;&#20449;&#37327;&#21363;&#21487;&#23454;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.12625</link><description>&lt;p&gt;
&#36890;&#36807;&#37325;&#35201;&#24615;&#25277;&#26679;&#23454;&#29616;&#26377;&#25928;&#36890;&#20449;&#30340;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Communication-Efficient Federated Learning through Importance Sampling. (arXiv:2306.12625v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12625
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#37325;&#35201;&#24615;&#25277;&#26679;&#23454;&#29616;&#26377;&#25928;&#36890;&#20449;&#30340;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#65292;&#22823;&#22823;&#38477;&#20302;&#20102;&#21457;&#36865;&#27169;&#22411;&#26356;&#26032;&#30340;&#39640;&#36890;&#20449;&#25104;&#26412;&#65292;&#21033;&#29992;&#26381;&#21153;&#22120;&#31471;&#23458;&#25143;&#31471;&#20998;&#24067;&#21644;&#38468;&#21152;&#20449;&#24687;&#30340;&#25509;&#36817;&#20851;&#31995;&#65292;&#21482;&#38656;&#35201;&#36739;&#23569;&#30340;&#36890;&#20449;&#37327;&#21363;&#21487;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23458;&#25143;&#31471;&#21521;&#26381;&#21153;&#22120;&#21457;&#36865;&#27169;&#22411;&#26356;&#26032;&#30340;&#39640;&#36890;&#20449;&#25104;&#26412;&#26159;&#21487;&#25193;&#23637;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#30340;&#37325;&#35201;&#29942;&#39048;&#12290;&#29616;&#26377;&#26041;&#27861;&#20013;&#65292;&#20351;&#29992;&#38543;&#26426;&#21387;&#32553;&#26041;&#27861;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#27604;&#29305;&#29575;-&#20934;&#30830;&#24615;&#25240;&#34935;&#8212;&#8212;&#20854;&#20013;&#23458;&#25143;&#31471;n&#21457;&#36865;&#26469;&#33258;&#20165;&#20026;&#35813;&#23458;&#25143;&#31471;&#30340;&#27010;&#29575;&#20998;&#24067;q&#966;&#65288;n&#65289;&#30340;&#26679;&#26412;&#65292;&#26381;&#21153;&#22120;&#20351;&#29992;&#36825;&#20123;&#26679;&#26412;&#20272;&#35745;&#23458;&#25143;&#31471;&#20998;&#24067;&#30340;&#24179;&#22343;&#20540;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#27809;&#26377;&#20805;&#20998;&#21033;&#29992;FL&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#26381;&#21153;&#22120;&#22312;&#25972;&#20010;&#35757;&#32451;&#36807;&#31243;&#20013;&#20855;&#26377;&#39044;&#25968;&#25454;&#20998;&#24067;p&#952;&#30340;&#38468;&#21152;&#20449;&#24687;&#65292;&#35813;&#20998;&#24067;&#19982;&#23458;&#25143;&#31471;&#20998;&#24067;q&#966;&#65288;n&#65289;&#22312;Kullback-Leibler&#65288;KL&#65289;&#21457;&#25955;&#26041;&#38754;&#25509;&#36817;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#26381;&#21153;&#22120;&#31471;&#23458;&#25143;&#31471;&#20998;&#24067;q&#966;&#65288;n)&#19982;&#38468;&#21152;&#20449;&#24687;p&#952;&#20043;&#38388;&#30340;&#36825;&#31181;&#25509;&#36817;&#20851;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#38656;&#35201;&#22823;&#32422;Dkl&#65288;q&#966;&#65288;n&#65289;|| p&#952;&#65289;&#20301;&#30340;&#36890;&#20449;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
The high communication cost of sending model updates from the clients to the server is a significant bottleneck for scalable federated learning (FL). Among existing approaches, state-of-the-art bitrate-accuracy tradeoffs have been achieved using stochastic compression methods -- in which the client $n$ sends a sample from a client-only probability distribution $q_{\phi^{(n)}}$, and the server estimates the mean of the clients' distributions using these samples. However, such methods do not take full advantage of the FL setup where the server, throughout the training process, has side information in the form of a pre-data distribution $p_{\theta}$ that is close to the client's distribution $q_{\phi^{(n)}}$ in Kullback-Leibler (KL) divergence. In this work, we exploit this closeness between the clients' distributions $q_{\phi^{(n)}}$'s and the side information $p_{\theta}$ at the server, and propose a framework that requires approximately $D_{KL}(q_{\phi^{(n)}}|| p_{\theta})$ bits of com
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;RePU&#28608;&#27963;&#20989;&#25968;&#30340;&#21487;&#24494;&#20998;&#31070;&#32463;&#32593;&#32476;&#65292;&#22312;&#36817;&#20284;$C^s$&#24179;&#28369;&#20989;&#25968;&#21450;&#20854;&#23548;&#25968;&#30340;&#21516;&#26102;&#24314;&#31435;&#20102;&#19979;&#38480;&#35823;&#24046;&#30028;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22312;&#38477;&#20302;&#32500;&#24230;&#28798;&#38590;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#27492;&#22806;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;RePU&#32593;&#32476;&#30340;&#24809;&#32602;&#20445;&#24207;&#22238;&#24402;(PDIR)&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.00608</link><description>&lt;p&gt;
&#20351;&#29992;RePU&#28608;&#27963;&#20989;&#25968;&#30340;&#21487;&#24494;&#20998;&#31070;&#32463;&#32593;&#32476;&#65306;&#22312;&#24471;&#20998;&#20272;&#35745;&#21644;&#20445;&#24207;&#22238;&#24402;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differentiable Neural Networks with RePU Activation: with Applications to Score Estimation and Isotonic Regression. (arXiv:2305.00608v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00608
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;RePU&#28608;&#27963;&#20989;&#25968;&#30340;&#21487;&#24494;&#20998;&#31070;&#32463;&#32593;&#32476;&#65292;&#22312;&#36817;&#20284;$C^s$&#24179;&#28369;&#20989;&#25968;&#21450;&#20854;&#23548;&#25968;&#30340;&#21516;&#26102;&#24314;&#31435;&#20102;&#19979;&#38480;&#35823;&#24046;&#30028;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22312;&#38477;&#20302;&#32500;&#24230;&#28798;&#38590;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#27492;&#22806;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;RePU&#32593;&#32476;&#30340;&#24809;&#32602;&#20445;&#24207;&#22238;&#24402;(PDIR)&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#30001;&#20462;&#27491;&#21518;&#30340;&#24130;&#21333;&#20803;&#65288;RePU&#65289;&#20989;&#25968;&#28608;&#27963;&#30340;&#21487;&#24494;&#20998;&#31070;&#32463;&#32593;&#32476;&#30340;&#23646;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;RePU&#31070;&#32463;&#32593;&#32476;&#30340;&#20559;&#23548;&#25968;&#21487;&#20197;&#30001;&#28151;&#21512;&#28608;&#27963;RePU&#32593;&#32476;&#26469;&#34920;&#31034;&#65292;&#24182;&#25512;&#23548;&#20102;&#23548;&#25968;RePU&#32593;&#32476;&#20989;&#25968;&#31867;&#30340;&#22797;&#26434;&#24230;&#30340;&#19978;&#30028;&#12290;&#22312;&#20351;&#29992;RePU&#28608;&#27963;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#21516;&#26102;&#36817;&#20284;$C^s$&#24179;&#28369;&#20989;&#25968;&#21450;&#20854;&#23548;&#25968;&#30340;&#35823;&#24046;&#30028;&#12290;&#27492;&#22806;&#65292;&#24403;&#25968;&#25454;&#20855;&#26377;&#36817;&#20284;&#20302;&#32500;&#25903;&#25345;&#26102;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#25913;&#36827;&#30340;&#36924;&#36817;&#35823;&#24046;&#30028;&#65292;&#35777;&#26126;&#20102;RePU&#32593;&#32476;&#20943;&#32531;&#32500;&#24230;&#28798;&#38590;&#30340;&#33021;&#21147;&#12290;&#20026;&#20102;&#35828;&#26126;&#25105;&#20204;&#30340;&#32467;&#26524;&#30340;&#23454;&#29992;&#24615;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#28145;&#24230;&#24471;&#20998;&#21305;&#37197;&#20272;&#35745;&#22120;(DSME)&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;RePU&#32593;&#32476;&#30340;&#24809;&#32602;&#20445;&#24207;&#22238;&#24402;(PDIR)&#12290;&#25105;&#20204;&#22312;&#20551;&#23450;&#30446;&#26631;&#20989;&#25968;&#23646;&#20110;$C^s$&#24179;&#28369;&#20989;&#25968;&#31867;&#30340;&#24773;&#20917;&#19979;&#20026;DSME&#21644;PDIR&#24314;&#31435;&#38750;&#28176;&#36817;&#36229;&#39069;&#39118;&#38505;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the properties of differentiable neural networks activated by rectified power unit (RePU) functions. We show that the partial derivatives of RePU neural networks can be represented by RePUs mixed-activated networks and derive upper bounds for the complexity of the function class of derivatives of RePUs networks. We establish error bounds for simultaneously approximating $C^s$ smooth functions and their derivatives using RePU-activated deep neural networks. Furthermore, we derive improved approximation error bounds when data has an approximate low-dimensional support, demonstrating the ability of RePU networks to mitigate the curse of dimensionality. To illustrate the usefulness of our results, we consider a deep score matching estimator (DSME) and propose a penalized deep isotonic regression (PDIR) using RePU networks. We establish non-asymptotic excess risk bounds for DSME and PDIR under the assumption that the target functions belong to a class of $C^s$ smooth functions. We 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#26102;&#21464;&#22270;&#19978;&#30340;&#20998;&#25955;&#22312;&#32447;&#27491;&#21017;&#21270;&#32447;&#24615;&#22238;&#24402;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#38750;&#36127;&#36229;-&#38789;&#19981;&#31561;&#24335;&#30340;&#20272;&#35745;&#35823;&#24046;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#22312;&#28385;&#36275;&#26679;&#26412;&#36335;&#24452;&#26102;&#31354;&#20852;&#22859;&#26465;&#20214;&#26102;&#65292;&#33410;&#28857;&#30340;&#20272;&#35745;&#21487;&#20197;&#25910;&#25947;&#20110;&#26410;&#30693;&#30340;&#30495;&#23454;&#21442;&#25968;&#21521;&#37327;&#12290;</title><link>http://arxiv.org/abs/2206.03861</link><description>&lt;p&gt;
&#38543;&#26426;&#26102;&#21464;&#22270;&#19978;&#30340;&#20998;&#25955;&#22312;&#32447;&#27491;&#21017;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Decentralized Online Regularized Learning Over Random Time-Varying Graphs. (arXiv:2206.03861v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.03861
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#26102;&#21464;&#22270;&#19978;&#30340;&#20998;&#25955;&#22312;&#32447;&#27491;&#21017;&#21270;&#32447;&#24615;&#22238;&#24402;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#38750;&#36127;&#36229;-&#38789;&#19981;&#31561;&#24335;&#30340;&#20272;&#35745;&#35823;&#24046;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#22312;&#28385;&#36275;&#26679;&#26412;&#36335;&#24452;&#26102;&#31354;&#20852;&#22859;&#26465;&#20214;&#26102;&#65292;&#33410;&#28857;&#30340;&#20272;&#35745;&#21487;&#20197;&#25910;&#25947;&#20110;&#26410;&#30693;&#30340;&#30495;&#23454;&#21442;&#25968;&#21521;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38543;&#26426;&#26102;&#21464;&#22270;&#19978;&#30340;&#20998;&#25955;&#22312;&#32447;&#27491;&#21017;&#21270;&#32447;&#24615;&#22238;&#24402;&#31639;&#27861;&#12290;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#20013;&#65292;&#27599;&#20010;&#33410;&#28857;&#37117;&#36816;&#34892;&#19968;&#20010;&#22312;&#32447;&#20272;&#35745;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21253;&#25324;&#21019;&#26032;&#39033;&#65288;&#22788;&#29702;&#33258;&#36523;&#26032;&#27979;&#37327;&#20540;&#65289;&#12289;&#20849;&#35782;&#39033;&#65288;&#21152;&#26435;&#24179;&#22343;&#33258;&#36523;&#21450;&#20854;&#37051;&#23621;&#30340;&#20272;&#35745;&#65292;&#24102;&#26377;&#21152;&#24615;&#21644;&#20056;&#24615;&#36890;&#20449;&#22122;&#22768;&#65289;&#21644;&#27491;&#21017;&#21270;&#39033;&#65288;&#38450;&#27490;&#36807;&#24230;&#25311;&#21512;&#65289;&#12290;&#19981;&#35201;&#27714;&#22238;&#24402;&#30697;&#38453;&#21644;&#22270;&#28385;&#36275;&#29305;&#27530;&#30340;&#32479;&#35745;&#20551;&#35774;&#65292;&#22914;&#30456;&#20114;&#29420;&#31435;&#12289;&#26102;&#31354;&#29420;&#31435;&#25110;&#24179;&#31283;&#24615;&#12290;&#25105;&#20204;&#21457;&#23637;&#20102;&#38750;&#36127;&#36229;-&#38789;&#19981;&#31561;&#24335;&#30340;&#20272;&#35745;&#35823;&#24046;&#65292;&#24182;&#35777;&#26126;&#20102;&#22914;&#26524;&#31639;&#27861;&#22686;&#30410;&#12289;&#22270;&#21644;&#22238;&#24402;&#30697;&#38453;&#20849;&#21516;&#28385;&#36275;&#26679;&#26412;&#36335;&#24452;&#26102;&#31354;&#20852;&#22859;&#26465;&#20214;&#65292;&#33410;&#28857;&#30340;&#20272;&#35745;&#20960;&#20046;&#21487;&#20197;&#32943;&#23450;&#22320;&#25910;&#25947;&#20110;&#26410;&#30693;&#30340;&#30495;&#23454;&#21442;&#25968;&#21521;&#37327;&#12290;&#29305;&#21035;&#22320;&#65292;&#36890;&#36807;&#36873;&#25321;&#36866;&#24403;&#30340;&#31639;&#27861;&#22686;&#30410;&#65292;&#35813;&#26465;&#20214;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the decentralized online regularized linear regression algorithm over random time-varying graphs. At each time step, every node runs an online estimation algorithm consisting of an innovation term processing its own new measurement, a consensus term taking a weighted sum of estimations of its own and its neighbors with additive and multiplicative communication noises and a regularization term preventing over-fitting. It is not required that the regression matrices and graphs satisfy special statistical assumptions such as mutual independence, spatio-temporal independence or stationarity. We develop the nonnegative supermartingale inequality of the estimation error, and prove that the estimations of all nodes converge to the unknown true parameter vector almost surely if the algorithm gains, graphs and regression matrices jointly satisfy the sample path spatio-temporal persistence of excitation condition. Especially, this condition holds by choosing appropriate algorithm gains 
&lt;/p&gt;</description></item></channel></rss>