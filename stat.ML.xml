<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#38024;&#23545;&#30446;&#26631;&#20989;&#25968;&#30340;&#27927;&#29260;&#26799;&#24230;&#26041;&#27861;&#26368;&#21518;&#36845;&#20195;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24357;&#21512;&#20102;&#22312;&#19981;&#21516;&#35774;&#32622;&#20013;&#26368;&#21518;&#36845;&#20195;&#30340;&#33391;&#22909;&#24615;&#33021;&#19982;&#29616;&#26377;&#29702;&#35770;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>https://arxiv.org/abs/2403.07723</link><description>&lt;p&gt;
&#20851;&#20110;&#27927;&#29260;&#26799;&#24230;&#26041;&#27861;&#30340;&#26368;&#21518;&#36845;&#20195;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Last-Iterate Convergence of Shuffling Gradient Methods
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07723
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#38024;&#23545;&#30446;&#26631;&#20989;&#25968;&#30340;&#27927;&#29260;&#26799;&#24230;&#26041;&#27861;&#26368;&#21518;&#36845;&#20195;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24357;&#21512;&#20102;&#22312;&#19981;&#21516;&#35774;&#32622;&#20013;&#26368;&#21518;&#36845;&#20195;&#30340;&#33391;&#22909;&#24615;&#33021;&#19982;&#29616;&#26377;&#29702;&#35770;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27927;&#29260;&#26799;&#24230;&#26041;&#27861;&#65292;&#20063;&#34987;&#31216;&#20026;&#26080;&#26367;&#25442;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#65292;&#22312;&#23454;&#36341;&#20013;&#34987;&#24191;&#27867;&#24212;&#29992;&#65292;&#29305;&#21035;&#21253;&#25324;&#19977;&#31181;&#27969;&#34892;&#31639;&#27861;&#65306;Random Reshuffle&#65288;RR&#65289;&#12289;Shuffle Once&#65288;SO&#65289;&#21644;Incremental Gradient&#65288;IG&#65289;&#12290;&#19982;&#32463;&#39564;&#25104;&#21151;&#30456;&#27604;&#65292;&#38271;&#26399;&#20197;&#26469;&#23545;&#20110;&#27927;&#29260;&#26799;&#24230;&#26041;&#27861;&#30340;&#29702;&#35770;&#20445;&#35777;&#24182;&#19981;&#20805;&#20998;&#20102;&#35299;&#12290;&#26368;&#36817;&#65292;&#21482;&#20026;&#20984;&#20989;&#25968;&#30340;&#24179;&#22343;&#36845;&#20195;&#21644;&#24378;&#20984;&#38382;&#39064;&#30340;&#26368;&#21518;&#36845;&#20195;&#65288;&#20197;&#24179;&#26041;&#36317;&#31163;&#20026;&#24230;&#37327;&#65289;&#24314;&#31435;&#20102;&#25910;&#25947;&#36895;&#29575;&#12290;&#28982;&#32780;&#65292;&#24403;&#23558;&#20989;&#25968;&#20540;&#24046;&#20316;&#20026;&#25910;&#25947;&#20934;&#21017;&#26102;&#65292;&#29616;&#26377;&#29702;&#35770;&#26080;&#27861;&#35299;&#37322;&#22312;&#19981;&#21516;&#35774;&#32622;&#20013;&#65288;&#20363;&#22914;&#21463;&#32422;&#26463;&#30340;&#20248;&#21270;&#65289;&#26368;&#21518;&#36845;&#20195;&#30340;&#33391;&#22909;&#24615;&#33021;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#31181;&#23454;&#36341;&#19982;&#29702;&#35770;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#25105;&#20204;&#38024;&#23545;&#30446;&#26631;&#20989;&#25968;&#35777;&#26126;&#20102;&#27927;&#29260;&#26799;&#24230;&#26041;&#27861;&#26368;&#21518;&#36845;&#20195;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07723v1 Announce Type: new  Abstract: Shuffling gradient methods, which are also known as stochastic gradient descent (SGD) without replacement, are widely implemented in practice, particularly including three popular algorithms: Random Reshuffle (RR), Shuffle Once (SO), and Incremental Gradient (IG). Compared to the empirical success, the theoretical guarantee of shuffling gradient methods was not well-understanding for a long time. Until recently, the convergence rates had just been established for the average iterate for convex functions and the last iterate for strongly convex problems (using squared distance as the metric). However, when using the function value gap as the convergence criterion, existing theories cannot interpret the good performance of the last iterate in different settings (e.g., constrained optimization). To bridge this gap between practice and theory, we prove last-iterate convergence rates for shuffling gradient methods with respect to the objectiv
&lt;/p&gt;</description></item><item><title>&#21464;&#20998;&#23398;&#20064;&#22312;&#22823;&#22411;&#28145;&#24230;&#32593;&#32476;&#20013;&#23637;&#29616;&#20986;&#38750;&#24120;&#22909;&#30340;&#25928;&#26524;&#65292;IVON&#20248;&#21270;&#22120;&#22312;&#35757;&#32451;&#22823;&#22411;&#32593;&#32476;&#26102;&#20960;&#20046;&#33021;&#19982;Adam&#30456;&#23218;&#32654;&#29978;&#33267;&#32988;&#36807;&#23427;&#65292;&#19988;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#26356;&#20934;&#30830;&#65292;&#23545;&#27169;&#22411;&#24494;&#35843;&#12289;&#27867;&#21270;&#35823;&#24046;&#39044;&#27979;&#21644;&#25968;&#25454;&#25935;&#24863;&#24615;&#20272;&#35745;&#22343;&#26377;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2402.17641</link><description>&lt;p&gt;
&#21464;&#20998;&#23398;&#20064;&#23545;&#22823;&#22411;&#28145;&#24230;&#32593;&#32476;&#26377;&#25928;
&lt;/p&gt;
&lt;p&gt;
Variational Learning is Effective for Large Deep Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17641
&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#23398;&#20064;&#22312;&#22823;&#22411;&#28145;&#24230;&#32593;&#32476;&#20013;&#23637;&#29616;&#20986;&#38750;&#24120;&#22909;&#30340;&#25928;&#26524;&#65292;IVON&#20248;&#21270;&#22120;&#22312;&#35757;&#32451;&#22823;&#22411;&#32593;&#32476;&#26102;&#20960;&#20046;&#33021;&#19982;Adam&#30456;&#23218;&#32654;&#29978;&#33267;&#32988;&#36807;&#23427;&#65292;&#19988;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#26356;&#20934;&#30830;&#65292;&#23545;&#27169;&#22411;&#24494;&#35843;&#12289;&#27867;&#21270;&#35823;&#24046;&#39044;&#27979;&#21644;&#25968;&#25454;&#25935;&#24863;&#24615;&#20272;&#35745;&#22343;&#26377;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#22823;&#37327;&#23454;&#35777;&#35777;&#25454;&#65292;&#21453;&#39539;&#20102;&#21464;&#20998;&#23398;&#20064;&#23545;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#26080;&#25928;&#30340;&#26222;&#36941;&#30475;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#21517;&#20026;Improved Variational Online Newton (IVON)&#30340;&#20248;&#21270;&#22120;&#65292;&#22312;&#35757;&#32451;&#22823;&#22411;&#32593;&#32476;&#65288;&#22914;GPT-2&#21644;ResNets&#65289;&#26102;&#22987;&#32456;&#33021;&#22815;&#19982;Adam&#30456;&#21305;&#37197;&#25110;&#32988;&#36807;&#23427;&#12290;IVON&#30340;&#35745;&#31639;&#25104;&#26412;&#20960;&#20046;&#19982;Adam&#30456;&#21516;&#65292;&#20294;&#20854;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#26356;&#22909;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;IVON&#30340;&#20960;&#31181;&#26032;&#29992;&#20363;&#65292;&#20854;&#20013;&#25105;&#20204;&#25913;&#36827;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24494;&#35843;&#21644;&#27169;&#22411;&#21512;&#24182;&#65292;&#22312;&#20934;&#30830;&#39044;&#27979;&#27867;&#21270;&#35823;&#24046;&#21644;&#24544;&#23454;&#20272;&#35745;&#23545;&#25968;&#25454;&#30340;&#25935;&#24863;&#24615;&#26041;&#38754;&#12290;&#25105;&#20204;&#25214;&#21040;&#20102;&#22823;&#37327;&#25903;&#25345;&#21464;&#20998;&#23398;&#20064;&#26377;&#25928;&#24615;&#30340;&#35777;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17641v1 Announce Type: cross  Abstract: We give extensive empirical evidence against the common belief that variational learning is ineffective for large neural networks. We show that an optimizer called Improved Variational Online Newton (IVON) consistently matches or outperforms Adam for training large networks such as GPT-2 and ResNets from scratch. IVON's computational costs are nearly identical to Adam but its predictive uncertainty is better. We show several new use cases of IVON where we improve fine-tuning and model merging in Large Language Models, accurately predict generalization error, and faithfully estimate sensitivity to data. We find overwhelming evidence in support of effectiveness of variational learning.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#30340;&#20195;&#25968;&#29702;&#35770;&#65292;&#24212;&#29992;&#33539;&#30068;&#35770;&#26500;&#24314;&#20102;&#19968;&#20010;&#26725;&#26753;&#65292;&#26377;&#25928;&#22320;&#28085;&#30422;&#20102;&#31070;&#32463;&#32593;&#32476;&#35774;&#35745;&#30340;&#19981;&#21516;&#39118;&#26684;&#65292;&#21516;&#26102;&#33258;&#28982;&#22320;&#32534;&#30721;&#20102;&#35745;&#31639;&#26426;&#31185;&#23398;&#21644;&#33258;&#21160;&#26426;&#29702;&#35770;&#20013;&#30340;&#35768;&#22810;&#26631;&#20934;&#32467;&#26500;&#12290;</title><link>https://arxiv.org/abs/2402.15332</link><description>&lt;p&gt;
&#20998;&#31867;&#28145;&#24230;&#23398;&#20064;&#65306;&#19968;&#31181;&#20851;&#20110;&#26550;&#26500;&#30340;&#20195;&#25968;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Categorical Deep Learning: An Algebraic Theory of Architectures
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15332
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#30340;&#20195;&#25968;&#29702;&#35770;&#65292;&#24212;&#29992;&#33539;&#30068;&#35770;&#26500;&#24314;&#20102;&#19968;&#20010;&#26725;&#26753;&#65292;&#26377;&#25928;&#22320;&#28085;&#30422;&#20102;&#31070;&#32463;&#32593;&#32476;&#35774;&#35745;&#30340;&#19981;&#21516;&#39118;&#26684;&#65292;&#21516;&#26102;&#33258;&#28982;&#22320;&#32534;&#30721;&#20102;&#35745;&#31639;&#26426;&#31185;&#23398;&#21644;&#33258;&#21160;&#26426;&#29702;&#35770;&#20013;&#30340;&#35768;&#22810;&#26631;&#20934;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20851;&#20110;&#25351;&#23450;&#21644;&#30740;&#31350;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#30340;&#36890;&#29992;&#26694;&#26550;&#30340;&#31435;&#22330;&#12290;&#25105;&#20204;&#35748;&#20026;&#21040;&#30446;&#21069;&#20026;&#27490;&#20851;&#20110;&#36825;&#19968;&#39046;&#22495;&#30340;&#20851;&#38190;&#23581;&#35797;&#32570;&#20047;&#19968;&#31181;&#19968;&#33268;&#30340;&#26725;&#26753;&#65292;&#33021;&#22815;&#25351;&#23450;&#27169;&#22411;&#24517;&#39035;&#28385;&#36275;&#30340;&#32422;&#26463;&#24182;&#35268;&#23450;&#23427;&#20204;&#30340;&#23454;&#29616;&#26041;&#24335;&#12290;&#19987;&#27880;&#20110;&#26500;&#24314;&#36825;&#26679;&#19968;&#20010;&#26725;&#26753;&#65292;&#25105;&#20204;&#24314;&#35758;&#24212;&#29992;&#33539;&#30068;&#35770;&#8212;&#8212;&#20934;&#30830;&#22320;&#35828;&#65292;&#21333;&#23376;&#20540;&#20110;&#21442;&#25968;&#26144;&#23556;&#30340;&#20108;&#33539;&#30068;&#30340;&#36890;&#29992;&#20195;&#25968;&#8212;&#8212;&#20316;&#20026;&#19968;&#31181;&#21333;&#19968;&#29702;&#35770;&#65292;&#20248;&#38597;&#22320;&#21253;&#21547;&#20102;&#31070;&#32463;&#32593;&#32476;&#35774;&#35745;&#30340;&#36825;&#20004;&#31181;&#39118;&#26684;&#12290;&#20026;&#20102;&#25903;&#25345;&#25105;&#20204;&#30340;&#35266;&#28857;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#19968;&#29702;&#35770;&#22914;&#20309;&#24674;&#22797;&#30001;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#23548;&#33268;&#30340;&#32422;&#26463;&#65292;&#20197;&#21450;&#20174;&#31070;&#32463;&#32593;&#32476;&#19981;&#21516;&#39046;&#22495;&#30340;&#22810;&#31181;&#26550;&#26500;&#65288;&#22914;RNNs&#65289;&#30340;&#23454;&#29616;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#36825;&#19968;&#29702;&#35770;&#22914;&#20309;&#33258;&#28982;&#22320;&#32534;&#30721;&#20102;&#35745;&#31639;&#26426;&#31185;&#23398;&#21644;&#33258;&#21160;&#26426;&#29702;&#35770;&#20013;&#30340;&#35768;&#22810;&#26631;&#20934;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15332v1 Announce Type: cross  Abstract: We present our position on the elusive quest for a general-purpose framework for specifying and studying deep learning architectures. Our opinion is that the key attempts made so far lack a coherent bridge between specifying constraints which models must satisfy and specifying their implementations. Focusing on building a such a bridge, we propose to apply category theory -- precisely, the universal algebra of monads valued in a 2-category of parametric maps -- as a single theory elegantly subsuming both of these flavours of neural network design. To defend our position, we show how this theory recovers constraints induced by geometric deep learning, as well as implementations of many architectures drawn from the diverse landscape of neural networks, such as RNNs. We also illustrate how the theory naturally encodes many standard constructs in computer science and automata theory.
&lt;/p&gt;</description></item><item><title>Equilibrium K-Means&#65288;EKM&#65289;&#26159;&#19968;&#31181;&#26032;&#39062;&#19988;&#31616;&#21333;&#30340;K&#22343;&#20540;&#31867;&#22411;&#31639;&#27861;&#65292;&#36890;&#36807;&#20943;&#23569;&#32858;&#31867;&#20013;&#24515;&#22312;&#22823;&#31867;&#31751;&#20013;&#24515;&#32858;&#38598;&#30340;&#20542;&#21521;&#65292;&#26174;&#33879;&#25913;&#21892;&#20102;&#19981;&#24179;&#34913;&#25968;&#25454;&#30340;&#32858;&#31867;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.14490</link><description>&lt;p&gt;
&#20351;&#29992;Equilibrium K-Means&#36827;&#34892;&#19981;&#24179;&#34913;&#25968;&#25454;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Imbalanced Data Clustering using Equilibrium K-Means
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14490
&lt;/p&gt;
&lt;p&gt;
Equilibrium K-Means&#65288;EKM&#65289;&#26159;&#19968;&#31181;&#26032;&#39062;&#19988;&#31616;&#21333;&#30340;K&#22343;&#20540;&#31867;&#22411;&#31639;&#27861;&#65292;&#36890;&#36807;&#20943;&#23569;&#32858;&#31867;&#20013;&#24515;&#22312;&#22823;&#31867;&#31751;&#20013;&#24515;&#32858;&#38598;&#30340;&#20542;&#21521;&#65292;&#26174;&#33879;&#25913;&#21892;&#20102;&#19981;&#24179;&#34913;&#25968;&#25454;&#30340;&#32858;&#31867;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#24179;&#34913;&#25968;&#25454;&#25351;&#30340;&#26159;&#25968;&#25454;&#28857;&#22312;&#19981;&#21516;&#31867;&#21035;&#20043;&#38388;&#20998;&#24067;&#19981;&#22343;&#34913;&#65292;&#36825;&#32473;&#20256;&#32479;&#30340;&#30828;&#32858;&#31867;&#31639;&#27861;&#21644;&#27169;&#31946;&#32858;&#31867;&#31639;&#27861;&#65288;&#22914;&#30828;K&#22343;&#20540;&#65288;HKM&#65292;&#25110;&#32773;Lloyd&#31639;&#27861;&#65289;&#21644;&#27169;&#31946;K&#22343;&#20540;&#65288;FKM&#65292;&#25110;&#32773;Bezdek&#31639;&#27861;&#65289;&#65289;&#24102;&#26469;&#20102;&#25361;&#25112;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#19988;&#31616;&#21333;&#30340;K&#22343;&#20540;&#31867;&#22411;&#31639;&#27861;&#8212;&#8212;Equilibrium K-Means&#65288;EKM&#65289;&#65292;&#23427;&#22312;&#20004;&#20010;&#27493;&#39588;&#20043;&#38388;&#20132;&#26367;&#36827;&#34892;&#65292;&#26174;&#33879;&#25913;&#21892;&#20102;&#19981;&#24179;&#34913;&#25968;&#25454;&#30340;&#32858;&#31867;&#32467;&#26524;&#65292;&#20943;&#23569;&#20102;&#32858;&#31867;&#20013;&#24515;&#21521;&#22823;&#31867;&#31751;&#20013;&#24515;&#32858;&#38598;&#30340;&#20542;&#21521;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#23545;HKM&#12289;FKM&#21644;EKM&#30340;&#32479;&#19968;&#35270;&#35282;&#65292;&#34920;&#26126;&#23427;&#20204;&#26412;&#36136;&#19978;&#26159;&#20855;&#26377;&#26126;&#30830;&#20851;&#31995;&#30340;&#29275;&#39039;&#26041;&#27861;&#30340;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#12290;EKM&#20855;&#26377;&#19982;FKM&#30456;&#21516;&#30340;&#26102;&#38388;&#21644;&#31354;&#38388;&#22797;&#26434;&#24230;&#65292;&#20294;&#23545;&#20854;&#25104;&#21592;&#23450;&#20041;&#25552;&#20379;&#20102;&#26356;&#28165;&#26224;&#30340;&#29289;&#29702;&#24847;&#20041;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#21313;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;EKM&#30340;&#24615;&#33021;&#65292;&#24182;&#23558;&#20854;&#19982;&#21508;&#31181;&#32858;&#31867;&#31639;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14490v1 Announce Type: new  Abstract: Imbalanced data, characterized by an unequal distribution of data points across different clusters, poses a challenge for traditional hard and fuzzy clustering algorithms, such as hard K-means (HKM, or Lloyd's algorithm) and fuzzy K-means (FKM, or Bezdek's algorithm). This paper introduces equilibrium K-means (EKM), a novel and simple K-means-type algorithm that alternates between just two steps, yielding significantly improved clustering results for imbalanced data by reducing the tendency of centroids to crowd together in the center of large clusters. We also present a unifying perspective for HKM, FKM, and EKM, showing they are essentially gradient descent algorithms with an explicit relationship to Newton's method. EKM has the same time and space complexity as FKM but offers a clearer physical meaning for its membership definition. We illustrate the performance of EKM on two synthetic and ten real datasets, comparing it to various cl
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#39118;&#38505;&#20998;&#35299;&#21644;&#36866;&#24403;&#35780;&#20998;&#35268;&#21017;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#26469;&#37327;&#21270;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#19981;&#21516;&#26469;&#28304;&#65292;&#24182;&#28548;&#28165;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2402.10727</link><description>&lt;p&gt;
&#36890;&#36807;&#39118;&#38505;&#20998;&#35299;&#23454;&#29616;&#20005;&#26684;&#36866;&#24403;&#35780;&#20998;&#35268;&#21017;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Predictive Uncertainty Quantification via Risk Decompositions for Strictly Proper Scoring Rules
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10727
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#39118;&#38505;&#20998;&#35299;&#21644;&#36866;&#24403;&#35780;&#20998;&#35268;&#21017;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#26469;&#37327;&#21270;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#19981;&#21516;&#26469;&#28304;&#65292;&#24182;&#28548;&#28165;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#39044;&#27979;&#27169;&#22411;&#24212;&#29992;&#20013;&#65292;&#21306;&#20998;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#26469;&#28304;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;&#25552;&#20986;&#20102;&#35768;&#22810;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#20294;&#24182;&#27809;&#26377;&#20005;&#26684;&#30340;&#23450;&#20041;&#26469;&#35299;&#24320;&#23427;&#20204;&#12290;&#27492;&#22806;&#65292;&#19981;&#21516;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#25514;&#26045;&#20043;&#38388;&#30340;&#20851;&#31995;&#20173;&#28982;&#26377;&#20123;&#19981;&#28165;&#26224;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26681;&#26893;&#20110;&#32479;&#35745;&#25512;&#29702;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#19981;&#20165;&#20801;&#35768;&#21019;&#24314;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#36824;&#28548;&#28165;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#31995;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#32479;&#35745;&#39118;&#38505;&#26469;&#21306;&#20998;aleatoric&#21644;epistemic&#19981;&#30830;&#23450;&#24615;&#25104;&#20998;&#65292;&#24182;&#21033;&#29992;&#36866;&#24403;&#30340;&#35780;&#20998;&#35268;&#21017;&#23545;&#20854;&#36827;&#34892;&#37327;&#21270;&#12290;&#20026;&#20102;&#20351;&#20854;&#22312;&#23454;&#36341;&#20013;&#26131;&#20110;&#22788;&#29702;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#36825;&#19968;&#26694;&#26550;&#20013;&#25972;&#21512;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#24819;&#27861;&#65292;&#24182;&#35752;&#35770;&#20102;&#25152;&#25552;&#36817;&#20284;&#30340;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10727v1 Announce Type: cross  Abstract: Distinguishing sources of predictive uncertainty is of crucial importance in the application of forecasting models across various domains. Despite the presence of a great variety of proposed uncertainty measures, there are no strict definitions to disentangle them. Furthermore, the relationship between different measures of uncertainty quantification remains somewhat unclear. In this work, we introduce a general framework, rooted in statistical reasoning, which not only allows the creation of new uncertainty measures but also clarifies their interrelations. Our approach leverages statistical risk to distinguish aleatoric and epistemic uncertainty components and utilizes proper scoring rules to quantify them. To make it practically tractable, we propose an idea to incorporate Bayesian reasoning into this framework and discuss the properties of the proposed approximation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#28378;&#21160;&#25193;&#25955;&#27169;&#22411;&#65292;&#29992;&#20110;&#22788;&#29702;&#26102;&#38388;&#25968;&#25454;&#65292;&#36890;&#36807;&#28369;&#21160;&#31383;&#21475;&#21435;&#22122;&#24182;&#26681;&#25454;&#24103;&#22312;&#24207;&#21015;&#20013;&#30340;&#26102;&#38388;&#20808;&#21518;&#20998;&#37197;&#19981;&#21516;&#30340;&#22122;&#22768;&#37327;&#65292;&#26356;&#22909;&#22320;&#25429;&#25417;&#21040;&#22797;&#26434;&#30340;&#26102;&#38388;&#21160;&#24577;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#35270;&#39057;&#39044;&#27979;&#21644;&#28151;&#27788;&#27969;&#20307;&#21160;&#21147;&#23398;&#39044;&#27979;&#20219;&#21153;&#20013;&#65292;&#35813;&#27169;&#22411;&#20248;&#20110;&#20256;&#32479;&#25193;&#25955;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.09470</link><description>&lt;p&gt;
&#28378;&#21160;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Rolling Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09470
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#28378;&#21160;&#25193;&#25955;&#27169;&#22411;&#65292;&#29992;&#20110;&#22788;&#29702;&#26102;&#38388;&#25968;&#25454;&#65292;&#36890;&#36807;&#28369;&#21160;&#31383;&#21475;&#21435;&#22122;&#24182;&#26681;&#25454;&#24103;&#22312;&#24207;&#21015;&#20013;&#30340;&#26102;&#38388;&#20808;&#21518;&#20998;&#37197;&#19981;&#21516;&#30340;&#22122;&#22768;&#37327;&#65292;&#26356;&#22909;&#22320;&#25429;&#25417;&#21040;&#22797;&#26434;&#30340;&#26102;&#38388;&#21160;&#24577;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#35270;&#39057;&#39044;&#27979;&#21644;&#28151;&#27788;&#27969;&#20307;&#21160;&#21147;&#23398;&#39044;&#27979;&#20219;&#21153;&#20013;&#65292;&#35813;&#27169;&#22411;&#20248;&#20110;&#20256;&#32479;&#25193;&#25955;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#25193;&#25955;&#27169;&#22411;&#36234;&#26469;&#36234;&#22810;&#22320;&#24212;&#29992;&#20110;&#26102;&#38388;&#25968;&#25454;&#65292;&#22914;&#35270;&#39057;&#12289;&#27969;&#20307;&#21147;&#23398;&#27169;&#25311;&#25110;&#27668;&#20505;&#25968;&#25454;&#12290;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#23558;&#21518;&#32493;&#24103;&#22312;&#25193;&#25955;&#36807;&#31243;&#20013;&#30340;&#22122;&#22768;&#37327;&#35270;&#20026;&#30456;&#31561;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#28378;&#21160;&#25193;&#25955;&#65306;&#19968;&#31181;&#20351;&#29992;&#28369;&#21160;&#31383;&#21475;&#21435;&#22122;&#30340;&#26032;&#26041;&#27861;&#12290;&#23427;&#30830;&#20445;&#25193;&#25955;&#36807;&#31243;&#36880;&#28176;&#36890;&#36807;&#26102;&#38388;&#36827;&#34892;&#30772;&#22351;&#65292;&#36890;&#36807;&#23558;&#26356;&#22810;&#30340;&#22122;&#22768;&#20998;&#37197;&#32473;&#24207;&#21015;&#20013;&#20986;&#29616;&#36739;&#26202;&#30340;&#24103;&#65292;&#21453;&#26144;&#20986;&#38543;&#30528;&#29983;&#25104;&#36807;&#31243;&#30340;&#23637;&#24320;&#65292;&#23545;&#26410;&#26469;&#30340;&#19981;&#30830;&#23450;&#24615;&#36234;&#26469;&#36234;&#22823;&#12290;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#65292;&#25105;&#20204;&#34920;&#26126;&#24403;&#26102;&#38388;&#21160;&#24577;&#22797;&#26434;&#26102;&#65292;&#28378;&#21160;&#25193;&#25955;&#20248;&#20110;&#26631;&#20934;&#25193;&#25955;&#12290;&#29305;&#21035;&#26159;&#22312;&#20351;&#29992;Kinetics-600&#35270;&#39057;&#25968;&#25454;&#38598;&#36827;&#34892;&#35270;&#39057;&#39044;&#27979;&#20219;&#21153;&#21644;&#28151;&#27788;&#27969;&#20307;&#21160;&#21147;&#23398;&#39044;&#27979;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#36825;&#19968;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09470v1 Announce Type: new  Abstract: Diffusion models have recently been increasingly applied to temporal data such as video, fluid mechanics simulations, or climate data. These methods generally treat subsequent frames equally regarding the amount of noise in the diffusion process. This paper explores Rolling Diffusion: a new approach that uses a sliding window denoising process. It ensures that the diffusion process progressively corrupts through time by assigning more noise to frames that appear later in a sequence, reflecting greater uncertainty about the future as the generation process unfolds. Empirically, we show that when the temporal dynamics are complex, Rolling Diffusion is superior to standard diffusion. In particular, this result is demonstrated in a video prediction task using the Kinetics-600 video dataset and in a chaotic fluid dynamics forecasting experiment.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20174;&#31639;&#23376;&#23398;&#20064;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#21442;&#25968;&#21040;&#21487;&#35266;&#27979;&#26144;&#23556;&#65292;&#25552;&#20986;&#20102;&#36866;&#24212;&#26377;&#38480;&#32500;&#36755;&#20837;&#21644;&#36755;&#20986;&#30340;&#20613;&#37324;&#21494;&#31070;&#32463;&#26144;&#23556;&#26694;&#26550;&#65292;&#24182;&#21457;&#23637;&#20102;&#36890;&#29992;&#36924;&#36817;&#23450;&#29702;&#26469;&#25903;&#25345;&#35813;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#35752;&#35770;&#20102;&#23398;&#20064;PtO&#26144;&#23556;&#30340;&#31471;&#21040;&#31471;&#26041;&#27861;&#21644;&#20808;&#23398;&#20064;&#35299;&#31639;&#23376;&#20877;&#35745;&#31639;&#21487;&#35266;&#27979;&#20540;&#30340;&#25928;&#29575;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.06031</link><description>&lt;p&gt;
&#21442;&#25968;&#21040;&#21487;&#35266;&#27979;&#26144;&#23556;&#30340;&#31639;&#23376;&#23398;&#20064;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
An operator learning perspective on parameter-to-observable maps
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06031
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20174;&#31639;&#23376;&#23398;&#20064;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#21442;&#25968;&#21040;&#21487;&#35266;&#27979;&#26144;&#23556;&#65292;&#25552;&#20986;&#20102;&#36866;&#24212;&#26377;&#38480;&#32500;&#36755;&#20837;&#21644;&#36755;&#20986;&#30340;&#20613;&#37324;&#21494;&#31070;&#32463;&#26144;&#23556;&#26694;&#26550;&#65292;&#24182;&#21457;&#23637;&#20102;&#36890;&#29992;&#36924;&#36817;&#23450;&#29702;&#26469;&#25903;&#25345;&#35813;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#35752;&#35770;&#20102;&#23398;&#20064;PtO&#26144;&#23556;&#30340;&#31471;&#21040;&#31471;&#26041;&#27861;&#21644;&#20808;&#23398;&#20064;&#35299;&#31639;&#23376;&#20877;&#35745;&#31639;&#21487;&#35266;&#27979;&#20540;&#30340;&#25928;&#29575;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35745;&#31639;&#39640;&#25928;&#30340;&#21442;&#25968;&#21270;&#29289;&#29702;&#27169;&#22411;&#26367;&#20195;&#21697;&#22312;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#31639;&#23376;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#21487;&#20197;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#36827;&#34892;&#26144;&#23556;&#12290;&#28982;&#32780;&#65292;&#36890;&#24120;&#21482;&#26377;&#26377;&#38480;&#32500;&#30340;&#27169;&#22411;&#36755;&#20837;&#21442;&#25968;&#21270;&#25110;&#26377;&#38480;&#32500;&#30340;&#27169;&#22411;&#36755;&#20986;&#21487;&#35266;&#27979;&#25968;&#25454;&#21487;&#29992;&#65292;&#32780;&#19981;&#26159;&#20840;&#22330;&#27979;&#37327;&#25968;&#25454;&#12290;&#26412;&#25991;&#22522;&#20110;&#20613;&#37324;&#21494;&#31070;&#32463;&#31639;&#23376;&#65292;&#24341;&#20837;&#20102;&#20613;&#37324;&#21494;&#31070;&#32463;&#26144;&#23556;&#65288;Fourier Neural Mappings&#65292;FNMs&#65289;&#26694;&#26550;&#65292;&#33021;&#22815;&#36866;&#24212;&#36825;&#26679;&#30340;&#26377;&#38480;&#32500;&#36755;&#20837;&#21644;&#36755;&#20986;&#12290;&#26412;&#25991;&#20026;&#35813;&#26041;&#27861;&#21457;&#23637;&#20102;&#36890;&#29992;&#36924;&#36817;&#23450;&#29702;&#12290;&#27492;&#22806;&#65292;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#24213;&#23618;&#30340;&#21442;&#25968;&#21040;&#21487;&#35266;&#27979;&#65288;PtO&#65289;&#26144;&#23556;&#26159;&#36890;&#36807;&#26080;&#31351;&#32500;&#31639;&#23376;&#26469;&#38544;&#24335;&#23450;&#20041;&#30340;&#65292;&#20363;&#22914;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#35299;&#31639;&#23376;&#12290;&#19968;&#20010;&#33258;&#28982;&#30340;&#38382;&#39064;&#26159;&#65292;&#26159;&#26356;&#26377;&#25928;&#22320;&#23398;&#20064;PtO&#26144;&#23556;&#30340;&#31471;&#21040;&#31471;&#26041;&#27861;&#65292;&#36824;&#26159;&#39318;&#20808;&#23398;&#20064;&#35299;&#31639;&#23376;&#65292;&#28982;&#21518;&#35745;&#31639;&#21487;&#35266;&#27979;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Computationally efficient surrogates for parametrized physical models play a crucial role in science and engineering. Operator learning provides data-driven surrogates that map between function spaces. However, instead of full-field measurements, often the available data are only finite-dimensional parametrizations of model inputs or finite observables of model outputs. Building off of Fourier Neural Operators, this paper introduces the Fourier Neural Mappings (FNMs) framework that is able to accommodate such finite-dimensional inputs and outputs. The paper develops universal approximation theorems for the method. Moreover, in many applications the underlying parameter-to-observable (PtO) map is defined implicitly through an infinite-dimensional operator, such as the solution operator of a partial differential equation. A natural question is whether it is more data-efficient to learn the PtO map end-to-end or first learn the solution operator and subsequently compute the observable fro
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#31163;&#25955;&#27969;&#27169;&#22411;&#65288;DFMs&#65289;&#65292;&#36890;&#36807;&#36830;&#32493;&#26102;&#38388;&#39532;&#23572;&#21487;&#22827;&#38142;&#23454;&#29616;&#31163;&#25955;&#31354;&#38388;&#27969;&#21305;&#37197;&#30340;&#31163;&#25955;&#31561;&#25928;&#65292;&#20026;&#23558;&#22522;&#20110;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#24212;&#29992;&#20110;&#22810;&#27169;&#24577;&#36830;&#32493;&#21644;&#31163;&#25955;&#25968;&#25454;&#38382;&#39064;&#25552;&#20379;&#20102;&#35299;&#20915;&#26041;&#26696;&#12290;&#27492;&#26041;&#27861;&#22312;&#34507;&#30333;&#36136;&#20849;&#35774;&#35745;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.04997</link><description>&lt;p&gt;
&#22312;&#31163;&#25955;&#29366;&#24577;&#31354;&#38388;&#19978;&#30340;&#29983;&#25104;&#22411;&#27969;&#65306;&#23454;&#29616;&#22810;&#27169;&#24577;&#27969;&#24182;&#24212;&#29992;&#20110;&#34507;&#30333;&#36136;&#20849;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Generative Flows on Discrete State-Spaces: Enabling Multimodal Flows with Applications to Protein Co-Design
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04997
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#31163;&#25955;&#27969;&#27169;&#22411;&#65288;DFMs&#65289;&#65292;&#36890;&#36807;&#36830;&#32493;&#26102;&#38388;&#39532;&#23572;&#21487;&#22827;&#38142;&#23454;&#29616;&#31163;&#25955;&#31354;&#38388;&#27969;&#21305;&#37197;&#30340;&#31163;&#25955;&#31561;&#25928;&#65292;&#20026;&#23558;&#22522;&#20110;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#24212;&#29992;&#20110;&#22810;&#27169;&#24577;&#36830;&#32493;&#21644;&#31163;&#25955;&#25968;&#25454;&#38382;&#39064;&#25552;&#20379;&#20102;&#35299;&#20915;&#26041;&#26696;&#12290;&#27492;&#26041;&#27861;&#22312;&#34507;&#30333;&#36136;&#20849;&#35774;&#35745;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#31163;&#25955;&#21644;&#36830;&#32493;&#25968;&#25454;&#30456;&#32467;&#21512;&#23545;&#20110;&#29983;&#25104;&#27169;&#22411;&#26469;&#35828;&#26159;&#19968;&#39033;&#37325;&#35201;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#31163;&#25955;&#27969;&#27169;&#22411;&#65288;DFMs&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27969;&#30340;&#31163;&#25955;&#25968;&#25454;&#27169;&#22411;&#65292;&#21487;&#20197;&#23454;&#29616;&#23558;&#22522;&#20110;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#24212;&#29992;&#20110;&#22810;&#27169;&#24577;&#36830;&#32493;&#21644;&#31163;&#25955;&#25968;&#25454;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#35265;&#35299;&#26159;&#65292;&#31163;&#25955;&#31354;&#38388;&#27969;&#21305;&#37197;&#30340;&#31163;&#25955;&#31561;&#25928;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#36830;&#32493;&#26102;&#38388;&#39532;&#23572;&#21487;&#22827;&#38142;&#26469;&#23454;&#29616;&#12290;DFMs&#36890;&#36807;&#31616;&#21333;&#30340;&#25512;&#23548;&#21253;&#25324;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#29305;&#23450;&#23454;&#20363;&#65292;&#21516;&#26102;&#20801;&#35768;&#22312;&#29616;&#26377;&#22522;&#20110;&#25193;&#25955;&#30340;&#26041;&#27861;&#19978;&#25913;&#36827;&#24615;&#33021;&#12290;&#25105;&#20204;&#21033;&#29992;DFMs&#26041;&#27861;&#26500;&#24314;&#20102;&#19968;&#20010;&#22810;&#27169;&#24577;&#22522;&#20110;&#27969;&#30340;&#24314;&#27169;&#26694;&#26550;&#12290;&#25105;&#20204;&#23558;&#27492;&#33021;&#21147;&#24212;&#29992;&#20110;&#34507;&#30333;&#36136;&#20849;&#35774;&#35745;&#30340;&#20219;&#21153;&#65292;&#20854;&#20013;&#25105;&#20204;&#23398;&#20064;&#20102;&#19968;&#20010;&#33021;&#22815;&#21516;&#26102;&#29983;&#25104;&#34507;&#30333;&#36136;&#32467;&#26500;&#21644;&#24207;&#21015;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20849;&#35774;&#35745;&#24615;&#33021;&#19978;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#27700;&#24179;&#65292;&#21516;&#26102;&#20801;&#35768;&#20351;&#29992;&#21516;&#19968;&#20010;&#22810;&#27169;&#24577;&#27169;&#22411;&#36827;&#34892;&#24207;&#21015;&#25110;&#32467;&#26500;&#30340;&#28789;&#27963;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
Combining discrete and continuous data is an important capability for generative models. We present Discrete Flow Models (DFMs), a new flow-based model of discrete data that provides the missing link in enabling flow-based generative models to be applied to multimodal continuous and discrete data problems. Our key insight is that the discrete equivalent of continuous space flow matching can be realized using Continuous Time Markov Chains. DFMs benefit from a simple derivation that includes discrete diffusion models as a specific instance while allowing improved performance over existing diffusion-based approaches. We utilize our DFMs method to build a multimodal flow-based modeling framework. We apply this capability to the task of protein co-design, wherein we learn a model for jointly generating protein structure and sequence. Our approach achieves state-of-the-art co-design performance while allowing the same multimodal model to be used for flexible generation of the sequence or str
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#37319;&#29992;&#38543;&#26426;&#30697;&#38453;&#26041;&#27861;&#65292;&#22312;&#20302;&#22810;&#32447;&#24615;&#31209;&#24352;&#37327;&#36924;&#36817;&#20013;&#23637;&#31034;&#20102;&#23545;&#31181;&#26893;&#30340;&#20302;&#31209;&#20449;&#21495;&#30340;&#20272;&#35745;&#65292;&#24182;&#26681;&#25454;&#22823;&#32500;&#35889;&#34892;&#20026;&#21644;&#20449;&#22122;&#27604;&#20934;&#30830;&#39044;&#27979;&#20102;&#37325;&#24314;&#24615;&#33021;&#65292;&#24182;&#32473;&#20986;&#20102;HOOI&#25910;&#25947;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;</title><link>https://arxiv.org/abs/2402.03169</link><description>&lt;p&gt;
&#20302;&#22810;&#32447;&#24615;&#31209;&#24352;&#37327;&#36924;&#36817;&#30340;&#38543;&#26426;&#30697;&#38453;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Random Matrix Approach to Low-Multilinear-Rank Tensor Approximation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03169
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#37319;&#29992;&#38543;&#26426;&#30697;&#38453;&#26041;&#27861;&#65292;&#22312;&#20302;&#22810;&#32447;&#24615;&#31209;&#24352;&#37327;&#36924;&#36817;&#20013;&#23637;&#31034;&#20102;&#23545;&#31181;&#26893;&#30340;&#20302;&#31209;&#20449;&#21495;&#30340;&#20272;&#35745;&#65292;&#24182;&#26681;&#25454;&#22823;&#32500;&#35889;&#34892;&#20026;&#21644;&#20449;&#22122;&#27604;&#20934;&#30830;&#39044;&#27979;&#20102;&#37325;&#24314;&#24615;&#33021;&#65292;&#24182;&#32473;&#20986;&#20102;HOOI&#25910;&#25947;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20174;&#35745;&#31639;&#38408;&#20540;&#38468;&#36817;&#30340;&#19968;&#33324;&#23574;&#23792;&#24352;&#37327;&#27169;&#22411;&#65292;&#23545;&#31181;&#26893;&#30340;&#20302;&#31209;&#20449;&#21495;&#20272;&#35745;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35748;&#35782;&#12290;&#20381;&#38752;&#22823;&#22411;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#26631;&#20934;&#24037;&#20855;&#65292;&#25105;&#20204;&#34920;&#24449;&#20102;&#25968;&#25454;&#24352;&#37327;&#30340;&#23637;&#24320;&#30340;&#22823;&#32500;&#35889;&#34892;&#20026;&#65292;&#24182;&#23637;&#31034;&#20102;&#20915;&#23450;&#20027;&#35201;&#20449;&#21495;&#26041;&#21521;&#21487;&#26816;&#27979;&#24615;&#30340;&#30456;&#20851;&#20449;&#22122;&#27604;&#12290;&#36825;&#20123;&#32467;&#26524;&#21487;&#20197;&#20934;&#30830;&#22320;&#39044;&#27979;&#22312;&#38750;&#24179;&#20961;&#21306;&#22495;&#30340;&#25130;&#26029;&#22810;&#32447;&#24615;&#22855;&#24322;&#20540;&#20998;&#35299;(MLSVD)&#30340;&#37325;&#24314;&#24615;&#33021;&#12290;&#36825;&#19968;&#28857;&#23588;&#20854;&#37325;&#35201;&#65292;&#22240;&#20026;&#23427;&#20316;&#20026;&#26356;&#39640;&#38454;&#27491;&#20132;&#36845;&#20195;(HOOI)&#26041;&#26696;&#30340;&#21021;&#22987;&#21270;&#65292;&#20854;&#25910;&#25947;&#21040;&#26368;&#20339;&#20302;&#22810;&#32447;&#24615;&#31209;&#36924;&#36817;&#23436;&#20840;&#21462;&#20915;&#20110;&#20854;&#21021;&#22987;&#21270;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;HOOI&#25910;&#25947;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#35777;&#26126;&#22312;&#22823;&#32500;&#26497;&#38480;&#19979;&#25910;&#25947;&#21069;&#30340;&#36845;&#20195;&#27425;&#25968;&#36235;&#20110;1&#12290;
&lt;/p&gt;
&lt;p&gt;
This work presents a comprehensive understanding of the estimation of a planted low-rank signal from a general spiked tensor model near the computational threshold. Relying on standard tools from the theory of large random matrices, we characterize the large-dimensional spectral behavior of the unfoldings of the data tensor and exhibit relevant signal-to-noise ratios governing the detectability of the principal directions of the signal. These results allow to accurately predict the reconstruction performance of truncated multilinear SVD (MLSVD) in the non-trivial regime. This is particularly important since it serves as an initialization of the higher-order orthogonal iteration (HOOI) scheme, whose convergence to the best low-multilinear-rank approximation depends entirely on its initialization. We give a sufficient condition for the convergence of HOOI and show that the number of iterations before convergence tends to $1$ in the large-dimensional limit.
&lt;/p&gt;</description></item><item><title>&#31070;&#32463;&#32593;&#32476;&#22312;&#39640;&#32500;&#25968;&#25454;&#20013;&#21457;&#29616;&#32479;&#35745;&#27169;&#24335;&#65292;&#30740;&#31350;&#20102;&#22914;&#20309;&#39640;&#25928;&#22320;&#20174;&#39640;&#38454;&#32047;&#31215;&#37327;&#20013;&#25552;&#21462;&#29305;&#24449;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#23574;&#23792;&#32047;&#31215;&#37327;&#27169;&#22411;&#20013;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2312.14922</link><description>&lt;p&gt;
&#20174;&#39640;&#38454;&#32479;&#35745;&#37327;&#20013;&#39640;&#25928;&#23398;&#20064;&#65306;&#20551;&#35774;&#26816;&#39564;&#12289;&#38543;&#26426;&#29305;&#24449;&#21644;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Learning from higher-order statistics, efficiently: hypothesis tests, random features, and neural networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.14922
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#22312;&#39640;&#32500;&#25968;&#25454;&#20013;&#21457;&#29616;&#32479;&#35745;&#27169;&#24335;&#65292;&#30740;&#31350;&#20102;&#22914;&#20309;&#39640;&#25928;&#22320;&#20174;&#39640;&#38454;&#32047;&#31215;&#37327;&#20013;&#25552;&#21462;&#29305;&#24449;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#23574;&#23792;&#32047;&#31215;&#37327;&#27169;&#22411;&#20013;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#25797;&#38271;&#21457;&#29616;&#39640;&#32500;&#25968;&#25454;&#38598;&#20013;&#30340;&#32479;&#35745;&#27169;&#24335;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#24230;&#37327;&#19977;&#20010;&#25110;&#26356;&#22810;&#21464;&#37327;&#38388;&#30340;&#38750;&#39640;&#26031;&#30456;&#20851;&#24615;&#30340;&#39640;&#38454;&#32047;&#31215;&#37327;&#23545;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#29305;&#21035;&#37325;&#35201;&#12290;&#20294;&#31070;&#32463;&#32593;&#32476;&#26377;&#22810;&#26377;&#25928;&#22320;&#20174;&#39640;&#38454;&#32047;&#31215;&#37327;&#20013;&#25552;&#21462;&#29305;&#24449;&#65311;&#25105;&#20204;&#22312;&#23574;&#23792;&#32047;&#31215;&#37327;&#27169;&#22411;&#20013;&#25506;&#35752;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#36825;&#37324;&#32479;&#35745;&#23398;&#23478;&#38656;&#35201;&#20174;$d$&#32500;&#36755;&#20837;&#30340;&#38454;-$p\ge 4$&#32047;&#31215;&#37327;&#20013;&#24674;&#22797;&#20986;&#19968;&#20010;&#29305;&#26435;&#26041;&#21521;&#25110;&#8220;&#23574;&#23792;&#8221;&#12290;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;&#20998;&#26512;&#25152;&#38656;&#26679;&#26412;&#25968;$n$&#26469;&#34920;&#24449;&#24674;&#22797;&#23574;&#23792;&#30340;&#22522;&#26412;&#32479;&#35745;&#21644;&#35745;&#31639;&#38480;&#21046;&#65292;&#20197;&#24378;&#28872;&#21306;&#20998;&#26469;&#33258;&#23574;&#23792;&#32047;&#31215;&#37327;&#27169;&#22411;&#21644;&#21508;&#21521;&#21516;&#24615;&#39640;&#26031;&#36755;&#20837;&#30340;&#36755;&#20837;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#32479;&#35745;&#19978;&#30340;&#21487;&#21306;&#20998;&#24615;&#38656;&#35201;$n\gtrsim d$&#20010;&#26679;&#26412;&#65292;&#32780;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#21306;&#20998;&#36825;&#20004;&#20010;&#20998;&#24067;&#21017;&#38656;&#35201;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.14922v2 Announce Type: replace-cross  Abstract: Neural networks excel at discovering statistical patterns in high-dimensional data sets. In practice, higher-order cumulants, which quantify the non-Gaussian correlations between three or more variables, are particularly important for the performance of neural networks. But how efficient are neural networks at extracting features from higher-order cumulants? We study this question in the spiked cumulant model, where the statistician needs to recover a privileged direction or "spike" from the order-$p\ge 4$ cumulants of $d$-dimensional inputs. We first characterise the fundamental statistical and computational limits of recovering the spike by analysing the number of samples $n$ required to strongly distinguish between inputs from the spiked cumulant model and isotropic Gaussian inputs. We find that statistical distinguishability requires $n\gtrsim d$ samples, while distinguishing the two distributions in polynomial time require
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20132;&#21449;&#29109;&#31867;&#21035;&#19981;&#24179;&#34913;&#23398;&#20064;&#20013;&#30340;&#31070;&#32463;&#25240;&#21472;&#29616;&#35937;&#65292;&#35777;&#26126;&#20102;&#22312;&#23384;&#22312;&#31867;&#21035;&#19981;&#24179;&#34913;&#24773;&#20917;&#19979;&#65292;&#31070;&#32463;&#25240;&#21472;&#20173;&#28982;&#23384;&#22312;&#65292;&#20294;&#31867;&#22343;&#20540;&#30340;&#20960;&#20309;&#29305;&#24615;&#20250;&#21457;&#29983;&#20559;&#31227;&#12290;</title><link>http://arxiv.org/abs/2401.02058</link><description>&lt;p&gt;
&#20351;&#29992;&#26080;&#32422;&#26463;ReLU&#29305;&#24449;&#27169;&#22411;&#36827;&#34892;&#20132;&#21449;&#29109;&#31867;&#21035;&#19981;&#24179;&#34913;&#23398;&#20064;&#30340;&#31070;&#32463;&#25240;&#21472;
&lt;/p&gt;
&lt;p&gt;
Neural Collapse for Cross-entropy Class-Imbalanced Learning with Unconstrained ReLU Feature Model. (arXiv:2401.02058v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02058
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20132;&#21449;&#29109;&#31867;&#21035;&#19981;&#24179;&#34913;&#23398;&#20064;&#20013;&#30340;&#31070;&#32463;&#25240;&#21472;&#29616;&#35937;&#65292;&#35777;&#26126;&#20102;&#22312;&#23384;&#22312;&#31867;&#21035;&#19981;&#24179;&#34913;&#24773;&#20917;&#19979;&#65292;&#31070;&#32463;&#25240;&#21472;&#20173;&#28982;&#23384;&#22312;&#65292;&#20294;&#31867;&#22343;&#20540;&#30340;&#20960;&#20309;&#29305;&#24615;&#20250;&#21457;&#29983;&#20559;&#31227;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20998;&#31867;&#20219;&#21153;&#30340;&#33539;&#24335;&#21253;&#25324;&#26368;&#23567;&#21270;&#32463;&#39564;&#39118;&#38505;&#65292;&#23558;&#35757;&#32451;&#25439;&#22833;&#20540;&#25512;&#21521;&#38646;&#65292;&#21363;&#20351;&#35757;&#32451;&#35823;&#24046;&#24050;&#32463;&#28040;&#22833;&#12290;&#22312;&#35757;&#32451;&#30340;&#26368;&#21518;&#38454;&#27573;&#65292;&#35266;&#23519;&#21040;&#26368;&#21518;&#19968;&#23618;&#29305;&#24449;&#20250;&#25240;&#21472;&#21040;&#23427;&#20204;&#30340;&#31867;&#22343;&#20540;&#65292;&#24182;&#19988;&#36825;&#20123;&#31867;&#22343;&#20540;&#20250;&#25910;&#25947;&#21040;&#19968;&#20010;&#31616;&#21333;&#20856;&#22411;&#31561;&#35282;&#32039;&#26694;&#65288;ETF&#65289;&#30340;&#39030;&#28857;&#12290;&#36825;&#19968;&#29616;&#35937;&#34987;&#31216;&#20026;&#31070;&#32463;&#25240;&#21472;&#65288;NC&#65289;&#12290;&#20026;&#20102;&#20174;&#29702;&#35770;&#19978;&#29702;&#35299;&#36825;&#19968;&#29616;&#35937;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#20351;&#29992;&#20102;&#19968;&#20010;&#31616;&#21270;&#30340;&#26080;&#32422;&#26463;&#29305;&#24449;&#27169;&#22411;&#26469;&#35777;&#26126;NC&#20986;&#29616;&#22312;&#35757;&#32451;&#38382;&#39064;&#30340;&#20840;&#23616;&#35299;&#20013;&#12290;&#28982;&#32780;&#65292;&#24403;&#35757;&#32451;&#25968;&#25454;&#38598;&#23384;&#22312;&#31867;&#21035;&#19981;&#24179;&#34913;&#26102;&#65292;&#19968;&#20123;NC&#29305;&#24615;&#23558;&#19981;&#20877;&#25104;&#31435;&#12290;&#20363;&#22914;&#65292;&#24403;&#25439;&#22833;&#25910;&#25947;&#26102;&#65292;&#31867;&#22343;&#20540;&#20960;&#20309;&#20250;&#20559;&#31163;&#31616;&#21333;&#20856;&#22411;&#31561;&#35282;&#32039;&#26694;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;NC&#25512;&#24191;&#21040;&#19981;&#24179;&#34913;&#24773;&#20917;&#19979;&#30340;&#20132;&#21449;&#29109;&#25439;&#22833;&#21644;&#26080;&#32422;&#26463;ReLU&#29305;&#24449;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#35757;&#32451;&#38382;&#39064;&#30340;&#20840;&#23616;&#35299;&#20013;&#65292;&#24403;&#23384;&#22312;&#31867;&#21035;&#19981;&#24179;&#34913;&#26102;&#65292;NC&#20173;&#28982;&#23384;&#22312;&#65292;&#20294;&#23545;&#20110;&#31867;&#22343;&#20540;&#30340;&#20960;&#20309;&#29305;&#24615;&#20250;&#21457;&#29983;&#20559;&#31227;&#12290;
&lt;/p&gt;
&lt;p&gt;
The current paradigm of training deep neural networks for classification tasks includes minimizing the empirical risk that pushes the training loss value towards zero, even after the training error has been vanished. In this terminal phase of training, it has been observed that the last-layer features collapse to their class-means and these class-means converge to the vertices of a simplex Equiangular Tight Frame (ETF). This phenomenon is termed as Neural Collapse (NC). To theoretically understand this phenomenon, recent works employ a simplified unconstrained feature model to prove that NC emerges at the global solutions of the training problem. However, when the training dataset is class-imbalanced, some NC properties will no longer be true. For example, the class-means geometry will skew away from the simplex ETF when the loss converges. In this paper, we generalize NC to imbalanced regime for cross-entropy loss under the unconstrained ReLU feature model. We prove that, while the wi
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;DPZero&#31639;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#19982;&#32500;&#24230;&#26080;&#20851;&#19988;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#30340;&#38646;&#38454;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;&#32454;&#35843;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26102;&#38754;&#20020;&#30340;&#20869;&#23384;&#21644;&#38544;&#31169;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2310.09639</link><description>&lt;p&gt;
DPZero&#65306;&#19982;&#32500;&#24230;&#26080;&#20851;&#19988;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#30340;&#38646;&#38454;&#20248;&#21270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
DPZero: Dimension-Independent and Differentially Private Zeroth-Order Optimization. (arXiv:2310.09639v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09639
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;DPZero&#31639;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#19982;&#32500;&#24230;&#26080;&#20851;&#19988;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#30340;&#38646;&#38454;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;&#32454;&#35843;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26102;&#38754;&#20020;&#30340;&#20869;&#23384;&#21644;&#38544;&#31169;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32454;&#35843;&#39044;&#35757;&#32451;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20197;&#36866;&#24212;&#29305;&#23450;&#39046;&#22495;&#25968;&#25454;&#30340;&#24191;&#27867;&#23454;&#36341;&#20013;&#65292;&#38754;&#20020;&#30528;&#20869;&#23384;&#21644;&#38544;&#31169;&#20004;&#20010;&#20027;&#35201;&#25361;&#25112;&#12290;&#39318;&#20808;&#65292;&#38543;&#30528;LLM&#30340;&#35268;&#27169;&#19981;&#26029;&#22686;&#38271;&#65292;&#36798;&#21040;&#25968;&#21313;&#20159;&#20010;&#21442;&#25968;&#65292;&#22522;&#20110;&#26799;&#24230;&#30340;&#21453;&#21521;&#20256;&#25773;&#35757;&#32451;&#26041;&#27861;&#25152;&#38656;&#30340;&#20869;&#23384;&#28040;&#32791;&#21464;&#24471;&#38590;&#20197;&#25215;&#21463;&#12290;&#20854;&#27425;&#65292;&#32771;&#34385;&#21040;LLM&#20542;&#21521;&#20110;&#35760;&#24518;&#21644;&#27844;&#38706;&#25935;&#24863;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#24517;&#39035;&#20445;&#25252;&#32454;&#35843;&#25968;&#25454;&#30340;&#38544;&#31169;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#23558;&#38646;&#38454;&#26041;&#27861;&#19982;&#24046;&#20998;&#38544;&#31169;&#20248;&#21270;&#30456;&#32467;&#21512;&#29992;&#20110;LLM&#30340;&#32454;&#35843;&#30340;&#28508;&#21147;&#12290;&#38646;&#38454;&#26041;&#27861;&#20165;&#20381;&#36182;&#21069;&#21521;&#20256;&#36882;&#65292;&#22823;&#22823;&#20943;&#23569;&#20102;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#20869;&#23384;&#28040;&#32791;&#12290;&#28982;&#32780;&#65292;&#30452;&#25509;&#23558;&#23427;&#20204;&#19982;&#26631;&#20934;&#30340;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#32467;&#21512;&#22312;&#19968;&#36215;&#20250;&#23548;&#33268;&#32500;&#24230;&#30456;&#20851;&#30340;&#22797;&#26434;&#24615;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;DPZero&#65292;&#19968;&#31181;&#20855;&#26377;&#36817;&#20046;&#32500;&#24230;&#26080;&#20851;&#29575;&#30340;&#26032;&#22411;&#24046;&#20998;&#38544;&#31169;&#38646;&#38454;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#25581;&#31034;&#20986;&#20102;
&lt;/p&gt;
&lt;p&gt;
The widespread practice of fine-tuning pretrained large language models (LLMs) on domain-specific data faces two major challenges in memory and privacy. First, as the size of LLMs continue to grow, encompassing billions of parameters, the memory demands of gradient-based training methods via backpropagation become prohibitively high. Second, given the tendency of LLMs to memorize and disclose sensitive training data, the privacy of fine-tuning data must be respected. To this end, we explore the potential of zeroth-order methods in differentially private optimization for fine-tuning LLMs. Zeroth-order methods, which rely solely on forward passes, substantially reduce memory consumption during training. However, directly combining them with standard differential privacy mechanism poses dimension-dependent complexity. To bridge the gap, we introduce DPZero, a novel differentially private zeroth-order algorithm with nearly dimension-independent rates. Our theoretical analysis reveals that 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#33258;&#30001;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#38646;&#21644;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#20013;&#23454;&#29616;&#19982;&#27169;&#22411;&#20026;&#22522;&#30784;&#31639;&#27861;&#30456;&#21516;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#39318;&#27425;&#35777;&#26126;&#20102;&#27169;&#22411;&#33258;&#30001;&#31639;&#27861;&#21487;&#20197;&#22312;&#26102;&#38388;&#27573;&#20381;&#36182;&#24615;&#26041;&#38754;&#36798;&#21040;&#21516;&#26679;&#30340;&#20248;&#21270;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.08858</link><description>&lt;p&gt;
&#27809;&#26377;&#27169;&#22411;&#30340;&#31639;&#27861;&#22312;&#38646;&#21644;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#20013;&#25552;&#39640;&#20102;&#26679;&#26412;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
Model-Free Algorithm with Improved Sample Efficiency for Zero-Sum Markov Games. (arXiv:2308.08858v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08858
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#33258;&#30001;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#38646;&#21644;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#20013;&#23454;&#29616;&#19982;&#27169;&#22411;&#20026;&#22522;&#30784;&#31639;&#27861;&#30456;&#21516;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#39318;&#27425;&#35777;&#26126;&#20102;&#27169;&#22411;&#33258;&#30001;&#31639;&#27861;&#21487;&#20197;&#22312;&#26102;&#38388;&#27573;&#20381;&#36182;&#24615;&#26041;&#38754;&#36798;&#21040;&#21516;&#26679;&#30340;&#20248;&#21270;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#20004;&#20154;&#38646;&#21644;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#38382;&#39064;&#22312;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;&#29702;&#35770;&#30740;&#31350;&#20013;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20852;&#36259;&#12290;&#29305;&#21035;&#26159;&#23545;&#20110;&#26377;&#38480;&#26102;&#38388;&#27573;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65292;&#24050;&#32463;&#35777;&#26126;&#20102;&#27169;&#22411;&#20026;&#22522;&#30784;&#30340;&#31639;&#27861;&#21487;&#20197;&#36890;&#36807;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$O(H^3SAB/\epsilon^2)$&#25214;&#21040;$\epsilon$-&#26368;&#20248;&#30340;&#32435;&#20160;&#22343;&#34913;&#65288;NE&#65289;&#65292;&#20854;&#20013;$H$&#26159;&#26102;&#38388;&#27573;&#65292;$S$&#26159;&#29366;&#24577;&#25968;&#37327;&#65288;$A$&#21644;$B$&#20998;&#21035;&#34920;&#31034;&#20004;&#20010;&#29609;&#23478;&#30340;&#21160;&#20316;&#25968;&#37327;&#65289;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#27809;&#26377;&#19968;&#31181;&#29616;&#26377;&#30340;&#27169;&#22411;&#33258;&#30001;&#31639;&#27861;&#21487;&#20197;&#36798;&#21040;&#36825;&#26679;&#30340;&#20248;&#21270;&#25928;&#26524;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#33258;&#30001;&#30340;&#38454;&#27573;&#24615;Q&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#23637;&#31034;&#23427;&#23454;&#29616;&#20102;&#19982;&#26368;&#20339;&#27169;&#22411;&#20026;&#22522;&#30784;&#31639;&#27861;&#30456;&#21516;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#22240;&#27492;&#39318;&#27425;&#35777;&#26126;&#20102;&#27169;&#22411;&#33258;&#30001;&#31639;&#27861;&#21487;&#20197;&#22312;&#26102;&#38388;&#27573;&#20381;&#36182;&#24615;&#26041;&#38754;&#20139;&#21463;&#19982;&#27169;&#22411;&#20026;&#22522;&#30784;&#31639;&#27861;&#30456;&#21516;&#30340;&#20248;&#21270;&#25928;&#26524;&#12290;&#23545;&#20110;$H$&#30340;&#20381;&#36182;&#24615;&#30340;&#20027;&#35201;&#25913;&#36827;&#26469;&#28304;&#20110;...
&lt;/p&gt;
&lt;p&gt;
The problem of two-player zero-sum Markov games has recently attracted increasing interests in theoretical studies of multi-agent reinforcement learning (RL). In particular, for finite-horizon episodic Markov decision processes (MDPs), it has been shown that model-based algorithms can find an $\epsilon$-optimal Nash Equilibrium (NE) with the sample complexity of $O(H^3SAB/\epsilon^2)$, which is optimal in the dependence of the horizon $H$ and the number of states $S$ (where $A$ and $B$ denote the number of actions of the two players, respectively). However, none of the existing model-free algorithms can achieve such an optimality. In this work, we propose a model-free stage-based Q-learning algorithm and show that it achieves the same sample complexity as the best model-based algorithm, and hence for the first time demonstrate that model-free algorithms can enjoy the same optimality in the $H$ dependence as model-based algorithms. The main improvement of the dependency on $H$ arises by
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#29702;&#35770;&#26041;&#27861;&#26469;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#65292;&#30830;&#20445;&#20854;&#22312;&#26679;&#26412;&#22823;&#23567;&#36235;&#36817;&#26080;&#31351;&#26102;&#19982;&#30495;&#23454;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#30340;&#35823;&#24046;&#25910;&#25947;&#20026;&#38646;&#65292;&#24182;&#19988;&#36828;&#31163;&#22797;&#21046;&#35757;&#32451;&#25968;&#25454;&#20013;&#31034;&#20363;&#30340;&#20219;&#20309;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2307.16422</link><description>&lt;p&gt;
&#20445;&#35777;&#20174;&#32463;&#39564;&#20998;&#24067;&#20013;&#26368;&#22823;&#20559;&#24046;&#30340;&#26368;&#20339;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Guaranteed Optimal Generative Modeling with Maximum Deviation from the Empirical Distribution. (arXiv:2307.16422v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16422
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#29702;&#35770;&#26041;&#27861;&#26469;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#65292;&#30830;&#20445;&#20854;&#22312;&#26679;&#26412;&#22823;&#23567;&#36235;&#36817;&#26080;&#31351;&#26102;&#19982;&#30495;&#23454;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#30340;&#35823;&#24046;&#25910;&#25947;&#20026;&#38646;&#65292;&#24182;&#19988;&#36828;&#31163;&#22797;&#21046;&#35757;&#32451;&#25968;&#25454;&#20013;&#31034;&#20363;&#30340;&#20219;&#20309;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24314;&#27169;&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#20110;&#31185;&#23398;&#21644;&#24037;&#19994;&#39046;&#22495;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#12290;&#20854;&#20027;&#35201;&#30446;&#26631;&#26159;&#22312;&#32473;&#23450;&#35757;&#32451;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#27169;&#25311;&#20174;&#26410;&#30693;&#20998;&#24067;&#20013;&#25277;&#21462;&#30340;&#26032;&#31034;&#20363;&#65292;&#21516;&#26102;&#30830;&#20445;&#22810;&#26679;&#24615;&#24182;&#36991;&#20813;&#20174;&#35757;&#32451;&#25968;&#25454;&#20013;&#22797;&#21046;&#31034;&#20363;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20851;&#20110;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#30340;&#29702;&#35770;&#35265;&#35299;&#65292;&#35813;&#27169;&#22411;&#20855;&#26377;&#20004;&#20010;&#23646;&#24615;&#65306;&#65288;i&#65289;&#23558;&#30495;&#23454;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#19982;&#35757;&#32451;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#26367;&#25442;&#30340;&#35823;&#24046;&#22312;&#26679;&#26412;&#22823;&#23567;&#36235;&#36817;&#26080;&#31351;&#26102;&#24212;&#26368;&#20339;&#25910;&#25947;&#20110;&#38646;&#65307;&#65288;ii&#65289;&#35757;&#32451;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#24212;&#36828;&#31163;&#22797;&#21046;&#35757;&#32451;&#25968;&#25454;&#20013;&#31034;&#20363;&#30340;&#20219;&#20309;&#20998;&#24067;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20197;&#26377;&#38480;&#26679;&#26412;&#39118;&#38505;&#30028;&#20026;&#24418;&#24335;&#30340;&#38750;&#28176;&#36817;&#32467;&#26524;&#65292;&#37327;&#21270;&#20102;&#36825;&#20123;&#23646;&#24615;&#65292;&#24182;&#21462;&#20915;&#20110;&#30456;&#20851;&#21442;&#25968;&#65292;&#22914;&#26679;&#26412;&#22823;&#23567;&#12289;&#29615;&#22659;&#31354;&#38388;&#30340;&#32500;&#25968;&#21644;&#28508;&#31354;&#38388;&#30340;&#32500;&#25968;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#29983;&#25104;&#27169;&#22411;&#30340;&#21508;&#31181;&#24212;&#29992;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative modeling is a widely-used machine learning method with various applications in scientific and industrial fields. Its primary objective is to simulate new examples drawn from an unknown distribution given training data while ensuring diversity and avoiding replication of examples from the training data.  This paper presents theoretical insights into training a generative model with two properties: (i) the error of replacing the true data-generating distribution with the trained data-generating distribution should optimally converge to zero as the sample size approaches infinity, and (ii) the trained data-generating distribution should be far enough from any distribution replicating examples in the training data.  We provide non-asymptotic results in the form of finite sample risk bounds that quantify these properties and depend on relevant parameters such as sample size, the dimension of the ambient space, and the dimension of the latent space. Our results are applicable to g
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#20855;&#26377;&#22810;&#23618;&#30340;&#36229;&#22270;&#946;&#27169;&#22411;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#25512;&#23548;&#20102;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#29575;&#21644;&#26497;&#38480;&#20998;&#24067;&#65292;&#24182;&#26500;&#24314;&#20102;&#27169;&#22411;&#21442;&#25968;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;&#36229;&#22270;&#946;&#27169;&#22411;&#20013;&#20284;&#28982;&#27604;&#26816;&#39564;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.02818</link><description>&lt;p&gt;
&#39640;&#38454;&#32593;&#32476;&#20013;&#30340;&#24230;&#24322;&#36136;&#24615;&#65306;&#36229;&#22270;&#946;&#27169;&#22411;&#30340;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Degree Heterogeneity in Higher-Order Networks: Inference in the Hypergraph $\boldsymbol{\beta}$-Model. (arXiv:2307.02818v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02818
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#20855;&#26377;&#22810;&#23618;&#30340;&#36229;&#22270;&#946;&#27169;&#22411;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#25512;&#23548;&#20102;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#29575;&#21644;&#26497;&#38480;&#20998;&#24067;&#65292;&#24182;&#26500;&#24314;&#20102;&#27169;&#22411;&#21442;&#25968;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;&#36229;&#22270;&#946;&#27169;&#22411;&#20013;&#20284;&#28982;&#27604;&#26816;&#39564;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#22270;&#20013;&#30340;&#946;&#27169;&#22411;&#36890;&#24120;&#29992;&#20110;&#34920;&#31034;&#20855;&#26377;&#24230;&#24322;&#36136;&#24615;&#30340;&#32593;&#32476;&#20013;&#30340;&#37197;&#23545;&#20132;&#20114;&#12290;&#36229;&#22270;&#946;&#27169;&#22411;&#36229;&#36234;&#20102;&#37197;&#23545;&#20132;&#20114;&#65292;Stasi&#31561;&#20154;&#20110;2014&#24180;&#24341;&#20837;&#20102;&#36229;&#22270;&#946;&#27169;&#22411;&#65292;&#29992;&#20110;&#25429;&#25417;&#20855;&#26377;&#39640;&#38454;&#65288;&#22810;&#21521;&#65289;&#20132;&#20114;&#30340;&#32593;&#32476;&#20013;&#30340;&#24230;&#24322;&#36136;&#24615;&#12290;&#26412;&#25991;&#39318;&#27425;&#23545;&#20855;&#26377;&#22810;&#23618;&#30340;&#36229;&#22270;&#946;&#27169;&#22411;&#36827;&#34892;&#20102;&#20005;&#26684;&#30740;&#31350;&#65292;&#23427;&#20801;&#35768;&#22312;&#19981;&#21516;&#23618;&#27425;&#20013;&#23384;&#22312;&#19981;&#21516;&#22823;&#23567;&#30340;&#36229;&#36793;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#26368;&#22823;&#20284;&#28982;&#65288;ML&#65289;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#30830;&#23450;&#20102;&#23427;&#20204;&#30340;&#26368;&#23567;&#26497;&#23567;&#36895;&#29575;&#12290;&#25105;&#20204;&#36824;&#25512;&#23548;&#20102;ML&#20272;&#35745;&#30340;&#26497;&#38480;&#20998;&#24067;&#65292;&#24182;&#26500;&#24314;&#20102;&#27169;&#22411;&#21442;&#25968;&#30340;&#28176;&#36817;&#26377;&#25928;&#32622;&#20449;&#21306;&#38388;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#36229;&#22270;&#946;&#27169;&#22411;&#20013;&#30340;&#25311;&#21512;&#20248;&#24230;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22312;&#38646;&#20551;&#35774;&#19979;&#24314;&#31435;&#20102;&#20284;&#28982;&#27604;&#65288;LR&#65289;&#26816;&#39564;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The $\boldsymbol{\beta}$-model for random graphs is commonly used for representing pairwise interactions in a network with degree heterogeneity. Going beyond pairwise interactions, Stasi et al. (2014) introduced the hypergraph $\boldsymbol{\beta}$-model for capturing degree heterogeneity in networks with higher-order (multi-way) interactions. In this paper we initiate the rigorous study of the hypergraph $\boldsymbol{\beta}$-model with multiple layers, which allows for hyperedges of different sizes across the layers. To begin with, we derive the rates of convergence of the maximum likelihood (ML) estimate and establish their minimax rate optimality. We also derive the limiting distribution of the ML estimate and construct asymptotically valid confidence intervals for the model parameters. Next, we consider the goodness-of-fit problem in the hypergraph $\boldsymbol{\beta}$-model. Specifically, we establish the asymptotic normality of the likelihood ratio (LR) test under the null hypothe
&lt;/p&gt;</description></item><item><title>&#38024;&#23545;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#24120;&#35265;&#30340;&#25968;&#25454;&#20559;&#24046;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#22312;&#26080;&#38656;&#20107;&#20808;&#30693;&#36947;&#30495;&#23454;&#39640;&#26031;&#36807;&#31243;&#36229;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#22810;&#33218;&#32769;&#34382;&#26426;&#25216;&#26415;&#21521;BO&#36807;&#31243;&#20013;&#28155;&#21152;&#38543;&#26426;&#25968;&#25454;&#28857;&#65292;&#37319;&#29992;&#26032;&#30340;&#35757;&#32451;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#36229;&#21442;&#25968;&#20272;&#35745;&#65292;&#20197;&#36798;&#21040;&#27425;&#32447;&#24615;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#30446;&#30340;&#12290;</title><link>http://arxiv.org/abs/2306.06844</link><description>&lt;p&gt;
&#20855;&#26377;&#26080;&#20559;&#39640;&#26031;&#36807;&#31243;&#36229;&#21442;&#25968;&#20272;&#35745;&#30340;&#21487;&#35777;&#26126;&#39640;&#25928;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Provably Efficient Bayesian Optimization with Unbiased Gaussian Process Hyperparameter Estimation. (arXiv:2306.06844v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06844
&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#24120;&#35265;&#30340;&#25968;&#25454;&#20559;&#24046;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#22312;&#26080;&#38656;&#20107;&#20808;&#30693;&#36947;&#30495;&#23454;&#39640;&#26031;&#36807;&#31243;&#36229;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#22810;&#33218;&#32769;&#34382;&#26426;&#25216;&#26415;&#21521;BO&#36807;&#31243;&#20013;&#28155;&#21152;&#38543;&#26426;&#25968;&#25454;&#28857;&#65292;&#37319;&#29992;&#26032;&#30340;&#35757;&#32451;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#36229;&#21442;&#25968;&#20272;&#35745;&#65292;&#20197;&#36798;&#21040;&#27425;&#32447;&#24615;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#30446;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31181;&#26377;&#25928;&#20248;&#21270;&#40657;&#30418;&#20989;&#25968;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#30340;&#23454;&#38469;&#24615;&#33021;&#21644;&#29702;&#35770;&#20445;&#35777;&#65292;&#21462;&#20915;&#20110;&#27491;&#30830;&#20272;&#35745;&#39640;&#26031;&#36807;&#31243;&#36229;&#21442;&#25968;&#20540;&#12290;&#20294;&#22312;&#23454;&#36341;&#20013;&#65292;&#30001;&#20110;&#24120;&#29992;&#20110;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#25968;&#25454;&#37319;&#26679;&#31574;&#30053;&#21487;&#33021;&#20250;&#24341;&#36215;&#25968;&#25454;&#20559;&#24046;&#65292;&#20174;&#32780;&#23548;&#33268;&#36229;&#21442;&#25968;&#20272;&#35745;&#38169;&#35823;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#21363;&#20351;&#22312;&#20107;&#20808;&#19981;&#30693;&#36947;&#30495;&#23454;&#39640;&#26031;&#36807;&#31243;&#36229;&#21442;&#25968;&#24182;&#38656;&#35201;&#20174;&#35266;&#23519;&#25968;&#25454;&#20013;&#36827;&#34892;&#20272;&#35745;&#26102;&#65292;&#35813;&#26041;&#27861;&#20063;&#33021;&#22815;&#27425;&#32447;&#24615;&#25910;&#25947;&#21040;&#30446;&#26631;&#20989;&#25968;&#30340;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#29992;&#22810;&#33218;&#32769;&#34382;&#26426;&#25216;&#26415;(EXP3)&#21521;BO&#36807;&#31243;&#20013;&#28155;&#21152;&#38543;&#26426;&#25968;&#25454;&#28857;&#65292;&#24182;&#20351;&#29992;&#26032;&#30340;&#35757;&#32451;&#25439;&#22833;&#20989;&#25968;&#29992;&#20110;&#39640;&#26031;&#36807;&#31243;&#36229;&#21442;&#25968;&#20272;&#35745;&#36807;&#31243;&#30340;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian process (GP) based Bayesian optimization (BO) is a powerful method for optimizing black-box functions efficiently. The practical performance and theoretical guarantees associated with this approach depend on having the correct GP hyperparameter values, which are usually unknown in advance and need to be estimated from the observed data. However, in practice, these estimations could be incorrect due to biased data sampling strategies commonly used in BO. This can lead to degraded performance and break the sub-linear global convergence guarantee of BO. To address this issue, we propose a new BO method that can sub-linearly converge to the global optimum of the objective function even when the true GP hyperparameters are unknown in advance and need to be estimated from the observed data. Our method uses a multi-armed bandit technique (EXP3) to add random data points to the BO process, and employs a novel training loss function for the GP hyperparameter estimation process that ens
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;SGD&#35757;&#32451;&#25439;&#22833;&#20013;&#30340;&#23574;&#23792;&#29616;&#35937;&#65292;&#25552;&#20986;&#20102;&#8220;&#25237;&#30707;&#26426;&#8221;&#20248;&#21270;&#29616;&#35937;&#65292;&#36890;&#36807;&#22686;&#21152;&#19982;&#30495;&#23454;&#39044;&#27979;&#22120;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#23545;&#40784;&#26469;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#65292;&#24182;&#35777;&#26126;&#36739;&#23567;&#30340;&#25209;&#37327;&#22823;&#23567;&#21487;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.04815</link><description>&lt;p&gt;
SGD&#20013;&#30340;&#25237;&#30707;&#26426;&#65306;&#35757;&#32451;&#25439;&#22833;&#20013;&#30340;&#23574;&#23792;&#21450;&#20854;&#36890;&#36807;&#29305;&#24449;&#23398;&#20064;&#23545;&#27867;&#21270;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Catapults in SGD: spikes in the training loss and their impact on generalization through feature learning. (arXiv:2306.04815v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04815
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;SGD&#35757;&#32451;&#25439;&#22833;&#20013;&#30340;&#23574;&#23792;&#29616;&#35937;&#65292;&#25552;&#20986;&#20102;&#8220;&#25237;&#30707;&#26426;&#8221;&#20248;&#21270;&#29616;&#35937;&#65292;&#36890;&#36807;&#22686;&#21152;&#19982;&#30495;&#23454;&#39044;&#27979;&#22120;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#23545;&#40784;&#26469;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#65292;&#24182;&#35777;&#26126;&#36739;&#23567;&#30340;&#25209;&#37327;&#22823;&#23567;&#21487;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#20808;&#35299;&#37322;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#36827;&#34892;&#35757;&#32451;&#26102;&#20026;&#20160;&#20040;&#32463;&#24120;&#20986;&#29616;&#35757;&#32451;&#25439;&#22833;&#23574;&#23792;&#30340;&#29616;&#35937;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#35777;&#25454;&#34920;&#26126;&#65292;SGD&#35757;&#32451;&#25439;&#22833;&#20013;&#30340;&#23574;&#23792;&#26159;&#8220;&#25237;&#30707;&#26426;&#8221;&#65292;&#36825;&#26159;&#19968;&#31181;&#20248;&#21270;&#29616;&#35937;&#65292;&#26368;&#21021;&#22312;[Lewkowycz&#31561;&#20154;&#65292;2020&#24180;]&#30340;&#22823;&#23398;&#20064;&#29575;GD&#20013;&#35266;&#23519;&#21040;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#36825;&#20123;&#25237;&#30707;&#26426;&#20986;&#29616;&#22312;&#30001;&#27491;&#20999;&#20869;&#26680;&#30340;&#21069;&#20960;&#20010;&#29305;&#24449;&#21521;&#37327;&#25152;&#24352;&#25104;&#30340;&#20302;&#32500;&#23376;&#31354;&#38388;&#20013;&#65292;&#36866;&#29992;&#20110;GD&#21644;SGD&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#35299;&#37322;&#65292;&#21363;&#25237;&#30707;&#26426;&#22914;&#20309;&#36890;&#36807;&#22686;&#21152;&#19982;&#30495;&#23454;&#39044;&#27979;&#22120;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#65288;AGOP&#65289;&#23545;&#40784;&#26469;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#22909;&#30340;&#27867;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;SGD&#20013;&#65292;&#26356;&#23567;&#30340;&#25209;&#37327;&#22823;&#23567;&#20250;&#23548;&#33268;&#26356;&#22810;&#30340;&#25237;&#30707;&#26426;&#20986;&#29616;&#65292;&#20174;&#32780;&#25552;&#39640;AGOP&#23545;&#40784;&#21644;&#27979;&#35797;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we first present an explanation regarding the common occurrence of spikes in the training loss when neural networks are trained with stochastic gradient descent (SGD). We provide evidence that the spikes in the training loss of SGD are "catapults", an optimization phenomenon originally observed in GD with large learning rates in [Lewkowycz et al. 2020]. We empirically show that these catapults occur in a low-dimensional subspace spanned by the top eigenvectors of the tangent kernel, for both GD and SGD. Second, we posit an explanation for how catapults lead to better generalization by demonstrating that catapults promote feature learning by increasing alignment with the Average Gradient Outer Product (AGOP) of the true predictor. Furthermore, we demonstrate that a smaller batch size in SGD induces a larger number of catapults, thereby improving AGOP alignment and test performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#23616;&#37096;&#32447;&#24615;&#27169;&#22411;&#23454;&#29616;&#30446;&#26631;&#21644;&#31890;&#23376;&#20998;&#24067;KL&#25955;&#24230;&#38477;&#20302;&#30340;&#26032;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#20351;&#29992;&#26679;&#26412;&#36827;&#34892;&#35745;&#31639;&#32780;&#19981;&#38656;&#35201;&#30446;&#26631;&#24471;&#20998;&#20989;&#25968;&#65292;&#20855;&#26377;&#27604;SVGD&#26356;&#31616;&#21333;&#26377;&#25928;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#23545;&#20110;&#39640;&#32500;&#24230;&#24773;&#20917;&#19979;&#30340;&#27169;&#22411;&#20063;&#26377;&#20248;&#21270;&#65292;&#25552;&#21319;&#20272;&#35745;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.15577</link><description>&lt;p&gt;
&#37319;&#29992;&#23616;&#37096;&#32447;&#24615;&#27169;&#22411;&#30340;&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;
&lt;/p&gt;
&lt;p&gt;
Variational Gradient Descent using Local Linear Models. (arXiv:2305.15577v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15577
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#23616;&#37096;&#32447;&#24615;&#27169;&#22411;&#23454;&#29616;&#30446;&#26631;&#21644;&#31890;&#23376;&#20998;&#24067;KL&#25955;&#24230;&#38477;&#20302;&#30340;&#26032;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#20351;&#29992;&#26679;&#26412;&#36827;&#34892;&#35745;&#31639;&#32780;&#19981;&#38656;&#35201;&#30446;&#26631;&#24471;&#20998;&#20989;&#25968;&#65292;&#20855;&#26377;&#27604;SVGD&#26356;&#31616;&#21333;&#26377;&#25928;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#23545;&#20110;&#39640;&#32500;&#24230;&#24773;&#20917;&#19979;&#30340;&#27169;&#22411;&#20063;&#26377;&#20248;&#21270;&#65292;&#25552;&#21319;&#20272;&#35745;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Stein Variational Gradient Descent (SVGD) &#33021;&#22815;&#27839;&#30528;&#36712;&#36857;&#20256;&#36755;&#31890;&#23376;&#65292;&#20174;&#32780;&#20943;&#23569;&#30446;&#26631;&#21644;&#31890;&#23376;&#20998;&#24067;&#20043;&#38388;&#30340;KL&#25955;&#24230;&#65292;&#20294;&#38656;&#35201;&#30446;&#26631;&#24471;&#20998;&#20989;&#25968;&#26469;&#35745;&#31639;&#26356;&#26032;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;SVGD&#35270;&#35282;&#65292;&#23558;&#20854;&#35270;&#20026;&#21453;&#21521;KL&#26799;&#24230;&#27969;&#30340;&#23616;&#37096;&#20272;&#35745;&#22120;&#12290;&#36825;&#31181;&#35270;&#35282;&#21551;&#21457;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#29992;&#23616;&#37096;&#32447;&#24615;&#27169;&#22411;&#26469;&#23454;&#29616;&#30456;&#21516;&#30446;&#30340;&#30340;&#26032;&#20272;&#35745;&#22120;&#12290;&#36825;&#20123;&#25552;&#35758;&#30340;&#20272;&#35745;&#22120;&#21487;&#20197;&#20165;&#20351;&#29992;&#30446;&#26631;&#21644;&#31890;&#23376;&#20998;&#24067;&#30340;&#26679;&#26412;&#36827;&#34892;&#35745;&#31639;&#65292;&#32780;&#19981;&#38656;&#35201;&#30446;&#26631;&#24471;&#20998;&#20989;&#25968;&#12290;&#25105;&#20204;&#25552;&#35758;&#30340;&#21464;&#20998;&#26799;&#24230;&#20272;&#35745;&#22120;&#21033;&#29992;&#20102;&#23616;&#37096;&#32447;&#24615;&#27169;&#22411;&#65292;&#20174;&#32780;&#22312;&#20445;&#25345;&#20272;&#35745;&#20559;&#24046;&#19982;SVGD&#30456;&#24403;&#30340;&#25928;&#26524;&#30340;&#21516;&#26102;&#20855;&#26377;&#35745;&#31639;&#31616;&#20415;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#39640;&#32500;&#26799;&#24230;&#27969;&#30340;&#20272;&#35745;&#21487;&#20197;&#36716;&#21270;&#20026;&#19968;&#20010;&#20302;&#32500;&#20272;&#35745;&#38382;&#39064;&#65292;&#20174;&#32780;&#23548;&#33268;&#26356;&#22909;&#30340;&#20272;&#35745;&#31934;&#24230;&#12290;&#25105;&#20204;&#23545;&#25552;&#35758;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#39564;&#35777;&#65292;&#24182;&#23545;&#20854;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stein Variational Gradient Descent (SVGD) can transport particles along trajectories that reduce the KL divergence between the target and particle distribution but requires the target score function to compute the update. We introduce a new perspective on SVGD that views it as a local estimator of the reversed KL gradient flow. This perspective inspires us to propose new estimators that use local linear models to achieve the same purpose. The proposed estimators can be computed using only samples from the target and particle distribution without needing the target score function. Our proposed variational gradient estimators utilize local linear models, resulting in computational simplicity while maintaining effectiveness comparable to SVGD in terms of estimation biases. Additionally, we demonstrate that under a mild assumption, the estimation of high-dimensional gradient flow can be translated into a lower-dimensional estimation problem, leading to improved estimation accuracy. We vali
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#33258;&#21160;&#21435;&#20559;&#37325;&#37325;&#37197;&#30340;&#26032;&#39062;&#29305;&#24449;&#25551;&#36848;&#65292;&#24182;&#23558;&#20854;&#31561;&#21516;&#20110;&#22522;&#20110;&#20869;&#26680;&#23725;&#22238;&#24402;&#30340;&#21333;&#20010;&#27424;&#24179;&#28369;&#23725;&#22238;&#24402;&#65292;&#36827;&#19968;&#27493;&#23558;&#36825;&#31181;&#26041;&#27861;&#25512;&#24191;&#21040;&#29305;&#23450;&#30340;&#32467;&#26524;&#21644;&#37325;&#37197;&#27169;&#22411;&#36873;&#25321;&#19978;&#12290;</title><link>http://arxiv.org/abs/2304.14545</link><description>&lt;p&gt;
&#33258;&#21160;&#21435;&#20559;&#37325;&#37325;&#37197;&#20316;&#20026;&#32447;&#24615;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Augmented balancing weights as linear regression. (arXiv:2304.14545v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14545
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#33258;&#21160;&#21435;&#20559;&#37325;&#37325;&#37197;&#30340;&#26032;&#39062;&#29305;&#24449;&#25551;&#36848;&#65292;&#24182;&#23558;&#20854;&#31561;&#21516;&#20110;&#22522;&#20110;&#20869;&#26680;&#23725;&#22238;&#24402;&#30340;&#21333;&#20010;&#27424;&#24179;&#28369;&#23725;&#22238;&#24402;&#65292;&#36827;&#19968;&#27493;&#23558;&#36825;&#31181;&#26041;&#27861;&#25512;&#24191;&#21040;&#29305;&#23450;&#30340;&#32467;&#26524;&#21644;&#37325;&#37197;&#27169;&#22411;&#36873;&#25321;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#20110;&#33258;&#21160;&#21435;&#20559;&#37325;&#37325;&#37197;(AutoDML)&#30340;&#26032;&#39062;&#29305;&#24449;&#25551;&#36848;&#12290;&#36825;&#20123;&#20272;&#31639;&#22120;&#23558;&#32467;&#26524;&#24314;&#27169;&#19982;&#37325;&#37197;&#30456;&#32467;&#21512;&#65292;&#30452;&#25509;&#20272;&#35745;&#21453;&#21521;&#20542;&#21521;&#31215;&#20998;&#26435;&#37325;&#12290;&#24403;&#32467;&#26524;&#19982;&#26435;&#37325;&#27169;&#22411;&#37117;&#26159;&#26576;&#20123;&#65288;&#21487;&#33021;&#26159;&#26080;&#38480;&#30340;&#65289;&#22522;&#30784;&#20013;&#30340;&#32447;&#24615;&#26102;&#65292;&#25105;&#20204;&#34920;&#26126;&#22686;&#24378;&#30340;&#20272;&#31639;&#22120;&#31561;&#21516;&#20110;&#20855;&#26377;&#23558;&#21407;&#22987;&#32467;&#26524;&#27169;&#22411;&#31995;&#25968;&#21644;OLS&#30456;&#32467;&#21512;&#30340;&#31995;&#25968;&#30340;&#21333;&#20010;&#32447;&#24615;&#27169;&#22411;&#65307;&#22312;&#35768;&#22810;&#35774;&#32622;&#20013;&#65292;&#22686;&#24378;&#20272;&#31639;&#22120;&#21512;&#24182;&#20026;&#20165;&#20351;&#29992;OLS. &#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#32467;&#26524;&#25193;&#23637;&#21040;&#29305;&#23450;&#30340;&#32467;&#26524;&#21644;&#37325;&#37197;&#27169;&#22411;&#36873;&#25321;&#19978;&#12290;&#25105;&#20204;&#39318;&#20808;&#34920;&#26126;&#65292;&#20351;&#29992;(&#20869;&#26680;)&#23725;&#22238;&#24402;&#20316;&#20026;&#32467;&#26524;&#21644;&#37325;&#37197;&#27169;&#22411;&#30340;&#32852;&#21512;&#20272;&#31639;&#22120;&#31561;&#21516;&#20110;&#21333;&#20010;&#12289;&#27424;&#24179;&#28369;(&#20869;&#26680;)&#23725;&#22238;&#24402;&#65307;&#24403;&#32771;&#34385;&#21040;&#28176;&#36817;&#36895;&#29575;&#26102;&#65292;&#36825;&#19968;&#32467;&#26524;&#20063;&#25104;&#31435;&#12290;&#24403;&#20195;&#26367;&#26435;&#37325;&#27169;&#22411;&#20026;&#22871;&#32034;&#22238;&#24402;&#26102;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#29305;&#27530;&#24773;&#20917;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#24182;&#19988;&#28436;&#31034;&#20102;&#8230;
&lt;/p&gt;
&lt;p&gt;
We provide a novel characterization of augmented balancing weights, also known as Automatic Debiased Machine Learning (AutoDML). These estimators combine outcome modeling with balancing weights, which estimate inverse propensity score weights directly. When the outcome and weighting models are both linear in some (possibly infinite) basis, we show that the augmented estimator is equivalent to a single linear model with coefficients that combine the original outcome model coefficients and OLS; in many settings, the augmented estimator collapses to OLS alone. We then extend these results to specific choices of outcome and weighting models. We first show that the combined estimator that uses (kernel) ridge regression for both outcome and weighting models is equivalent to a single, undersmoothed (kernel) ridge regression; this also holds when considering asymptotic rates. When the weighting model is instead lasso regression, we give closed-form expressions for special cases and demonstrate
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#40065;&#26834;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#23545;&#20110;&#20165;&#20855;&#26377;&#23545;&#27491;&#24120;&#26680;&#24515;&#30340;&#29983;&#25104;&#27169;&#22411;&#35775;&#38382;&#26435;&#38480;&#26102;&#65292;&#33719;&#24471;&#949;-&#26368;&#20248;&#31574;&#30053;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#23545;&#20110;sa&#65288;s-&#65289;&#30697;&#24418;&#19981;&#30830;&#23450;&#38598;&#21512;&#65292;&#24050;&#30693;&#26368;&#20339;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;&#949;^2/&#65288;H^4 * |S|^2 * |A|&#65289;&#65288;&#21709;&#24212;&#20026;&#949;^2/&#65288;H^4 * |S|^2 * |A|^2&#65289;&#65289;&#65292;&#23545;&#20110;&#29305;&#23450;&#31639;&#27861;&#21644;&#22522;&#20110;&#24635;&#21464;&#24046;&#65288;TV&#65289;&#12289;KL&#25110;&#21345;&#26041;&#25955;&#24230;&#30340;&#19981;&#30830;&#23450;&#38598;&#21512;&#12290;</title><link>http://arxiv.org/abs/2302.05372</link><description>&lt;p&gt;
&#36808;&#21521;&#27169;&#22411;&#22522;&#30784;&#40065;&#26834;&#24378;&#21270;&#23398;&#20064;&#30340;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Towards Minimax Optimality of Model-based Robust Reinforcement Learning. (arXiv:2302.05372v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05372
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#40065;&#26834;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#23545;&#20110;&#20165;&#20855;&#26377;&#23545;&#27491;&#24120;&#26680;&#24515;&#30340;&#29983;&#25104;&#27169;&#22411;&#35775;&#38382;&#26435;&#38480;&#26102;&#65292;&#33719;&#24471;&#949;-&#26368;&#20248;&#31574;&#30053;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#23545;&#20110;sa&#65288;s-&#65289;&#30697;&#24418;&#19981;&#30830;&#23450;&#38598;&#21512;&#65292;&#24050;&#30693;&#26368;&#20339;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;&#949;^2/&#65288;H^4 * |S|^2 * |A|&#65289;&#65288;&#21709;&#24212;&#20026;&#949;^2/&#65288;H^4 * |S|^2 * |A|^2&#65289;&#65289;&#65292;&#23545;&#20110;&#29305;&#23450;&#31639;&#27861;&#21644;&#22522;&#20110;&#24635;&#21464;&#24046;&#65288;TV&#65289;&#12289;KL&#25110;&#21345;&#26041;&#25955;&#24230;&#30340;&#19981;&#30830;&#23450;&#38598;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#21482;&#26377;&#23545;&#27491;&#24120;&#26680;&#24515;&#30340;&#29983;&#25104;&#27169;&#22411;&#35775;&#38382;&#26435;&#38480;&#26102;&#65292;&#33719;&#24471;&#949;-&#26368;&#20248;&#31574;&#30053;&#30340;&#37319;&#26679;&#22797;&#26434;&#24230;&#12290;&#36825;&#20010;&#38382;&#39064;&#22312;&#38750;&#40065;&#26834;&#24773;&#20917;&#19979;&#24050;&#32463;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#24182;&#19988;&#24050;&#30693;&#20219;&#20309;&#24212;&#29992;&#20110;&#32463;&#39564;MDP&#30340;&#35268;&#21010;&#26041;&#27861;&#65292;&#21482;&#38656;&#35201;&#29992;&#949;^2/&#65288;H^3 * |S| * |A|&#65289;&#20010;&#26679;&#26412;&#26469;&#20272;&#35745;&#65292;&#22343;&#21487;&#25552;&#20379;&#949;-&#26368;&#20248;&#31574;&#30053;&#65292;&#20174;&#32780;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#12290;&#40065;&#26834;&#24773;&#20917;&#19979;&#30340;&#32467;&#26524;&#26356;&#21152;&#23569;&#35265;&#12290;&#23545;&#20110;sa&#65288;s-&#65289;&#30697;&#24418;&#19981;&#30830;&#23450;&#38598;&#21512;&#65292;&#24050;&#30693;&#26368;&#20339;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;&#949;^2/&#65288;H^4 * |S|^2 * |A|&#65289;&#65288;&#21709;&#24212;&#20026;&#949;^2/&#65288;H^4 * |S|^2 * |A|^2&#65289;&#65289;&#65292;&#23545;&#20110;&#29305;&#23450;&#31639;&#27861;&#21644;&#22522;&#20110;&#24635;&#21464;&#24046;&#65288;TV&#65289;&#12289;KL&#25110;&#21345;&#26041;&#25955;&#24230;&#30340;&#19981;&#30830;&#23450;&#38598;&#21512;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#29992;Lp&#29699;&#23450;&#20041;&#30340;&#19981;&#30830;&#23450;&#38598;&#21512;&#65288;&#22238;&#22797;&#21040;TV&#24773;&#20917;&#65289;&#65292;&#24182;&#19988;...
&lt;/p&gt;
&lt;p&gt;
We study the sample complexity of obtaining an $\epsilon$-optimal policy in \emph{Robust} discounted Markov Decision Processes (RMDPs), given only access to a generative model of the nominal kernel. This problem is widely studied in the non-robust case, and it is known that any planning approach applied to an empirical MDP estimated with $\tilde{\mathcal{O}}(\frac{H^3 \mid S \mid\mid A \mid}{\epsilon^2})$ samples provides an $\epsilon$-optimal policy, which is minimax optimal. Results in the robust case are much more scarce. For $sa$(resp $s$-)rectangular uncertainty sets, the best known sample complexity is $\tilde{\mathcal{O}}(\frac{H^4 \mid S \mid^2\mid A \mid}{\epsilon^2})$ (resp. $\tilde{\mathcal{O}}(\frac{H^4 \mid S \mid^2\mid A \mid^2}{\epsilon^2})$), for specific algorithms and when the uncertainty set is based on the total variation (TV), the KL or the Chi-square divergences. In this paper, we consider uncertainty sets defined with an $L_p$-ball (recovering the TV case), and
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#31574;&#30053;&#30340;&#37327;&#21270;&#38598;&#21453;&#28436;&#26041;&#27861;&#65292;&#36890;&#36807;&#39640;&#26031;&#36807;&#31243;&#24314;&#27169;&#21644;&#36880;&#27493;&#19981;&#30830;&#23450;&#24615;&#20943;&#23569;&#21407;&#29702;&#65292;&#39034;&#24207;&#36873;&#25321;&#35780;&#20272;&#20989;&#25968;&#30340;&#28857;&#65292;&#20174;&#32780;&#26377;&#25928;&#36817;&#20284;&#24863;&#20852;&#36259;&#30340;&#38598;&#21512;&#12290;</title><link>http://arxiv.org/abs/2211.01008</link><description>&lt;p&gt;
&#22522;&#20110;&#36125;&#21494;&#26031;&#24207;&#36143;&#35774;&#35745;&#30340;&#35745;&#31639;&#26426;&#23454;&#39564;&#37327;&#21270;&#38598;&#21453;&#28436;
&lt;/p&gt;
&lt;p&gt;
Bayesian sequential design of computer experiments for quantile set inversion. (arXiv:2211.01008v2 [stat.ML] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.01008
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#31574;&#30053;&#30340;&#37327;&#21270;&#38598;&#21453;&#28436;&#26041;&#27861;&#65292;&#36890;&#36807;&#39640;&#26031;&#36807;&#31243;&#24314;&#27169;&#21644;&#36880;&#27493;&#19981;&#30830;&#23450;&#24615;&#20943;&#23569;&#21407;&#29702;&#65292;&#39034;&#24207;&#36873;&#25321;&#35780;&#20272;&#20989;&#25968;&#30340;&#28857;&#65292;&#20174;&#32780;&#26377;&#25928;&#36817;&#20284;&#24863;&#20852;&#36259;&#30340;&#38598;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;&#26410;&#30693;&#30340;&#22810;&#20803;&#20989;&#25968;&#65292;&#23427;&#20195;&#34920;&#30528;&#19968;&#20010;&#31995;&#32479;&#65292;&#22914;&#19968;&#20010;&#22797;&#26434;&#30340;&#25968;&#20540;&#27169;&#25311;&#22120;&#65292;&#21516;&#26102;&#20855;&#26377;&#30830;&#23450;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#30340;&#36755;&#20837;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20272;&#35745;&#30830;&#23450;&#24615;&#36755;&#20837;&#38598;&#65292;&#36825;&#20123;&#36755;&#20837;&#23548;&#33268;&#30340;&#36755;&#20986;&#65288;&#23601;&#19981;&#30830;&#23450;&#24615;&#36755;&#20837;&#30340;&#20998;&#24067;&#32780;&#35328;&#65289;&#23646;&#20110;&#32473;&#23450;&#38598;&#21512;&#30340;&#27010;&#29575;&#23567;&#20110;&#32473;&#23450;&#38408;&#20540;&#12290;&#36825;&#20010;&#38382;&#39064;&#34987;&#31216;&#20026;&#37327;&#21270;&#38598;&#21453;&#28436;&#65288;QSI&#65289;&#65292;&#20363;&#22914;&#22312;&#31283;&#20581;&#65288;&#22522;&#20110;&#21487;&#38752;&#24615;&#65289;&#20248;&#21270;&#38382;&#39064;&#30340;&#32972;&#26223;&#19979;&#65292;&#24403;&#23547;&#25214;&#28385;&#36275;&#32422;&#26463;&#26465;&#20214;&#19988;&#20855;&#26377;&#36275;&#22815;&#22823;&#27010;&#29575;&#30340;&#35299;&#38598;&#26102;&#20250;&#21457;&#29983;&#12290;&#20026;&#20102;&#35299;&#20915;QSI&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#24314;&#27169;&#21644;&#36880;&#27493;&#19981;&#30830;&#23450;&#24615;&#20943;&#23569;&#65288;SUR&#65289;&#21407;&#29702;&#30340;&#36125;&#21494;&#26031;&#31574;&#30053;&#65292;&#20197;&#39034;&#24207;&#36873;&#25321;&#24212;&#35813;&#35780;&#20272;&#20989;&#25968;&#30340;&#28857;&#65292;&#20197;&#20415;&#39640;&#25928;&#36817;&#20284;&#24863;&#20852;&#36259;&#30340;&#38598;&#21512;&#12290;&#36890;&#36807;&#20960;&#20010;&#25968;&#20540;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;SUR&#31574;&#30053;&#30340;&#24615;&#33021;&#21644;&#20215;&#20540;
&lt;/p&gt;
&lt;p&gt;
We consider an unknown multivariate function representing a system-such as a complex numerical simulator-taking both deterministic and uncertain inputs. Our objective is to estimate the set of deterministic inputs leading to outputs whose probability (with respect to the distribution of the uncertain inputs) of belonging to a given set is less than a given threshold. This problem, which we call Quantile Set Inversion (QSI), occurs for instance in the context of robust (reliability-based) optimization problems, when looking for the set of solutions that satisfy the constraints with sufficiently large probability. To solve the QSI problem, we propose a Bayesian strategy based on Gaussian process modeling and the Stepwise Uncertainty Reduction (SUR) principle, to sequentially choose the points at which the function should be evaluated to efficiently approximate the set of interest. We illustrate the performance and interest of the proposed SUR strategy through several numerical experiment
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20107;&#20214;&#35302;&#21457;&#31639;&#27861;ET-GP-UCB&#65292;&#29992;&#20110;&#35299;&#20915;&#26102;&#21464;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#25506;&#32034;&#21644;&#24320;&#21457;&#30340;&#26435;&#34913;&#38382;&#39064;&#12290;&#36890;&#36807;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#27010;&#29575;&#22343;&#21248;&#35823;&#24046;&#30028;&#65292;&#31639;&#27861;&#33021;&#22815;&#22312;&#26410;&#30693;&#21464;&#21270;&#36895;&#29575;&#30340;&#24773;&#20917;&#19979;&#33258;&#36866;&#24212;&#22320;&#36866;&#24212;&#23454;&#38469;&#30340;&#26102;&#38388;&#21464;&#21270;&#12290;&#25968;&#20540;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;ET-GP-UCB&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#19978;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2208.10790</link><description>&lt;p&gt;
&#20107;&#20214;&#35302;&#21457;&#30340;&#26102;&#21464;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Event-Triggered Time-Varying Bayesian Optimization. (arXiv:2208.10790v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.10790
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20107;&#20214;&#35302;&#21457;&#31639;&#27861;ET-GP-UCB&#65292;&#29992;&#20110;&#35299;&#20915;&#26102;&#21464;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#25506;&#32034;&#21644;&#24320;&#21457;&#30340;&#26435;&#34913;&#38382;&#39064;&#12290;&#36890;&#36807;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#27010;&#29575;&#22343;&#21248;&#35823;&#24046;&#30028;&#65292;&#31639;&#27861;&#33021;&#22815;&#22312;&#26410;&#30693;&#21464;&#21270;&#36895;&#29575;&#30340;&#24773;&#20917;&#19979;&#33258;&#36866;&#24212;&#22320;&#36866;&#24212;&#23454;&#38469;&#30340;&#26102;&#38388;&#21464;&#21270;&#12290;&#25968;&#20540;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;ET-GP-UCB&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#19978;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#26102;&#21464;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;TVBO&#65289;&#39034;&#24207;&#20248;&#21270;&#26102;&#21464;&#30446;&#26631;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#20854;&#20013;&#65292;&#20851;&#38190;&#25361;&#25112;&#26159;&#22312;&#26102;&#38388;&#21464;&#21270;&#19979;&#30340;&#21208;&#25506;&#19982;&#24320;&#21457;&#30340;&#26435;&#34913;&#12290;&#24403;&#21069;&#30340;TVBO&#26041;&#27861;&#38656;&#35201;&#23545;&#21464;&#21270;&#36895;&#29575;&#26377;&#20808;&#39564;&#30693;&#35782;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#21464;&#21270;&#36895;&#29575;&#36890;&#24120;&#26159;&#26410;&#30693;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20107;&#20214;&#35302;&#21457;&#31639;&#27861;ET-GP-UCB&#65292;&#23427;&#23558;&#20248;&#21270;&#38382;&#39064;&#35270;&#20026;&#38745;&#24577;&#38382;&#39064;&#65292;&#30452;&#21040;&#22312;&#32447;&#26816;&#27979;&#21040;&#30446;&#26631;&#20989;&#25968;&#30340;&#21464;&#21270;&#24182;&#37325;&#32622;&#25968;&#25454;&#38598;&#12290;&#36825;&#20351;&#24471;&#31639;&#27861;&#33021;&#22815;&#36866;&#24212;&#23454;&#38469;&#30340;&#26102;&#38388;&#21464;&#21270;&#65292;&#32780;&#19981;&#38656;&#35201;&#20808;&#39564;&#30693;&#35782;&#12290;&#20107;&#20214;&#35302;&#21457;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#20013;&#20351;&#29992;&#30340;&#27010;&#29575;&#22343;&#21248;&#35823;&#24046;&#30028;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;ET-GP-UCB&#30340;&#36951;&#25022;&#30028;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#23427;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#19978;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#32467;&#26524;&#34920;&#26126;ET-GP-UCB&#21487;&#24191;&#27867;&#24212;&#29992;&#20110;&#19981;&#21516;&#30340;&#35774;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of sequentially optimizing a time-varying objective function using time-varying Bayesian optimization (TVBO). Here, the key challenge is the exploration-exploitation trade-off under time variations. Current approaches to TVBO require prior knowledge of a constant rate of change. However, in practice, the rate of change is usually unknown. We propose an event-triggered algorithm, ET-GP-UCB, that treats the optimization problem as static until it detects changes in the objective function online and then resets the dataset. This allows the algorithm to adapt to realized temporal changes without the need for prior knowledge. The event-trigger is based on probabilistic uniform error bounds used in Gaussian process regression. We provide regret bounds for ET-GP-UCB and show in numerical experiments that it outperforms state-of-the-art algorithms on synthetic and real-world data. Furthermore, these results demonstrate that ET-GP-UCB is readily applicable to various set
&lt;/p&gt;</description></item></channel></rss>