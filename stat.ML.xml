<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#23376;&#31354;&#38388;&#32422;&#26463;&#30340;Tyler&#20272;&#35745;&#22120;&#29992;&#20110;&#22312;&#39640;&#24230;&#21463;&#21040;&#31163;&#32676;&#20540;&#27745;&#26579;&#30340;&#25968;&#25454;&#38598;&#20013;&#24674;&#22797;&#20302;&#32500;&#23376;&#31354;&#38388;&#30340;&#24773;&#20917;&#65292;&#24182;&#23637;&#31034;&#20102;&#24403;&#21021;&#22987;&#21270;&#26465;&#20214;&#24471;&#21040;&#28385;&#36275;&#26102;&#65292;&#35813;&#20272;&#35745;&#22120;&#21487;&#20197;&#26377;&#25928;&#22320;&#24674;&#22797;&#28508;&#22312;&#30340;&#23376;&#31354;&#38388;&#12290;</title><link>https://arxiv.org/abs/2403.18658</link><description>&lt;p&gt;
&#23545;&#23376;&#31354;&#38388;&#32422;&#26463;&#30340;Tyler&#20272;&#35745;&#22120;&#30340;&#29702;&#35770;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Theoretical Guarantees for the Subspace-Constrained Tyler's Estimator
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18658
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#23376;&#31354;&#38388;&#32422;&#26463;&#30340;Tyler&#20272;&#35745;&#22120;&#29992;&#20110;&#22312;&#39640;&#24230;&#21463;&#21040;&#31163;&#32676;&#20540;&#27745;&#26579;&#30340;&#25968;&#25454;&#38598;&#20013;&#24674;&#22797;&#20302;&#32500;&#23376;&#31354;&#38388;&#30340;&#24773;&#20917;&#65292;&#24182;&#23637;&#31034;&#20102;&#24403;&#21021;&#22987;&#21270;&#26465;&#20214;&#24471;&#21040;&#28385;&#36275;&#26102;&#65292;&#35813;&#20272;&#35745;&#22120;&#21487;&#20197;&#26377;&#25928;&#22320;&#24674;&#22797;&#28508;&#22312;&#30340;&#23376;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#29992;&#20110;&#24674;&#22797;&#21487;&#33021;&#21463;&#21040;&#20005;&#37325;&#27745;&#26579;&#30340;&#25968;&#25454;&#38598;&#20013;&#30340;&#20302;&#32500;&#23376;&#31354;&#38388;&#30340;&#23376;&#31354;&#38388;&#32422;&#26463;&#30340;Tyler&#20272;&#35745;&#22120;&#65288;STE&#65289;&#12290;&#23427;&#20551;&#35774;&#19968;&#20010;&#24369;&#30340;&#20869;&#28857;-&#22806;&#28857;&#27169;&#22411;&#65292;&#24182;&#20801;&#35768;&#20869;&#28857;&#30340;&#27604;&#20363;&#23567;&#20110;&#23548;&#33268;&#40065;&#26834;&#23376;&#31354;&#38388;&#24674;&#22797;&#38382;&#39064;&#35745;&#31639;&#22256;&#38590;&#30340;&#27604;&#20363;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#23427;&#26174;&#31034;&#22914;&#26524;STE&#30340;&#21021;&#22987;&#21270;&#28385;&#36275;&#26576;&#20123;&#26465;&#20214;&#65292;&#37027;&#20040;STE&#21487;&#20197;&#26377;&#25928;&#22320;&#24674;&#22797;&#28508;&#22312;&#30340;&#23376;&#31354;&#38388;&#12290;&#27492;&#22806;&#65292;&#23427;&#36824;&#34920;&#26126;&#22312;&#24191;&#20041;&#30340;&#24178;&#33609;&#22534;&#27169;&#22411;&#19979;&#65292;&#30001;Tyler&#30340;M-&#20272;&#35745;&#22120;&#65288;TME&#65289;&#21021;&#22987;&#21270;&#30340;STE&#21487;&#20197;&#22312;&#20869;&#28857;&#30340;&#27604;&#20363;&#22826;&#23567;&#20197;&#33267;&#20110;TME&#26080;&#27861;&#22788;&#29702;&#26102;&#24674;&#22797;&#23376;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18658v1 Announce Type: cross  Abstract: This work analyzes the subspace-constrained Tyler's estimator (STE) designed for recovering a low-dimensional subspace within a dataset that may be highly corrupted with outliers. It assumes a weak inlier-outlier model and allows the fraction of inliers to be smaller than a fraction that leads to computational hardness of the robust subspace recovery problem. It shows that in this setting, if the initialization of STE, which is an iterative algorithm, satisfies a certain condition, then STE can effectively recover the underlying subspace. It further shows that under the generalized haystack model, STE initialized by the Tyler's M-estimator (TME), can recover the subspace when the fraction of iniliers is too small for TME to handle.
&lt;/p&gt;</description></item><item><title>&#21452;&#20132;&#21449;&#22266;&#23450;&#21452;&#31283;&#20581;&#20272;&#35745;&#22120;&#38024;&#23545;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#39044;&#26399;&#26465;&#20214;&#21327;&#26041;&#24046;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#36890;&#36807;&#25286;&#20998;&#35757;&#32451;&#25968;&#25454;&#24182;&#22312;&#29420;&#31435;&#26679;&#26412;&#19978;&#19979;&#35843;nuisance&#20989;&#25968;&#20272;&#35745;&#22120;&#65292;&#32467;&#26500;&#26080;&#20851;&#30340;&#38169;&#35823;&#20998;&#26512;&#20197;&#21450;&#26356;&#24378;&#20551;&#35774;&#30340;&#32467;&#26524;&#65292;&#25552;&#20986;&#20102;&#26356;&#31934;&#30830;&#30340;DCDR&#20272;&#35745;&#22120;&#12290;</title><link>https://arxiv.org/abs/2403.15175</link><description>&lt;p&gt;
&#21452;&#20132;&#21449;&#22266;&#23450;&#21452;&#31283;&#20581;&#20272;&#35745;&#22120;&#65306;&#36229;&#36234;&#20018;&#34892;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Double Cross-fit Doubly Robust Estimators: Beyond Series Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15175
&lt;/p&gt;
&lt;p&gt;
&#21452;&#20132;&#21449;&#22266;&#23450;&#21452;&#31283;&#20581;&#20272;&#35745;&#22120;&#38024;&#23545;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#39044;&#26399;&#26465;&#20214;&#21327;&#26041;&#24046;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#36890;&#36807;&#25286;&#20998;&#35757;&#32451;&#25968;&#25454;&#24182;&#22312;&#29420;&#31435;&#26679;&#26412;&#19978;&#19979;&#35843;nuisance&#20989;&#25968;&#20272;&#35745;&#22120;&#65292;&#32467;&#26500;&#26080;&#20851;&#30340;&#38169;&#35823;&#20998;&#26512;&#20197;&#21450;&#26356;&#24378;&#20551;&#35774;&#30340;&#32467;&#26524;&#65292;&#25552;&#20986;&#20102;&#26356;&#31934;&#30830;&#30340;DCDR&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;&#36328;&#25311;&#21512;&#20132;&#21449;&#30340;&#21452;&#31283;&#20581;&#20272;&#35745;&#22120;&#22240;&#20854;&#33391;&#22909;&#30340;&#32467;&#26500;&#26080;&#20851;&#38169;&#35823;&#20445;&#35777;&#32780;&#22312;&#22240;&#26524;&#25512;&#26029;&#20013;&#22791;&#21463;&#38738;&#30544;&#12290;&#28982;&#32780;&#65292;&#24403;&#23384;&#22312;&#39069;&#22806;&#32467;&#26500;&#65292;&#20363;&#22914;H\"{o}lder&#24179;&#28369;&#26102;&#65292;&#21487;&#20197;&#36890;&#36807;&#22312;&#29420;&#31435;&#26679;&#26412;&#19978;&#23545;&#35757;&#32451;&#25968;&#25454;&#36827;&#34892;&#25286;&#20998;&#21644;&#19979;&#35843;nuisance&#20989;&#25968;&#20272;&#35745;&#22120;&#26469;&#26500;&#24314;&#26356;&#31934;&#30830;&#30340;&#8220;&#21452;&#20132;&#21449;&#22266;&#23450;&#21452;&#31283;&#20581;&#8221;&#65288;DCDR&#65289;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#39044;&#26399;&#26465;&#20214;&#21327;&#26041;&#24046;&#30340;DCDR&#20272;&#35745;&#22120;&#65292;&#22312;&#22240;&#26524;&#25512;&#26029;&#21644;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#20013;&#26159;&#19968;&#20010;&#24863;&#20852;&#36259;&#30340;&#20989;&#25968;&#65292;&#24182;&#24471;&#20986;&#20102;&#19968;&#31995;&#21015;&#36880;&#28176;&#26356;&#24378;&#20551;&#35774;&#30340;&#32467;&#26524;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23545;DCDR&#20272;&#35745;&#22120;&#25552;&#20379;&#26080;&#38656;&#23545;nuisance&#20989;&#25968;&#25110;&#23427;&#20204;&#30340;&#20272;&#35745;&#22120;&#20570;&#20986;&#20551;&#35774;&#30340;&#32467;&#26500;&#26080;&#20851;&#38169;&#35823;&#20998;&#26512;&#12290;&#28982;&#21518;&#65292;&#20551;&#35774;nuisance&#20989;&#25968;&#26159;H\"{o}lder&#24179;&#28369;&#65292;&#20294;&#19981;&#20551;&#35774;&#30693;&#26195;&#30495;&#23454;&#24179;&#28369;&#32423;&#21035;&#25110;&#21327;&#21464;&#37327;&#23494;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15175v1 Announce Type: cross  Abstract: Doubly robust estimators with cross-fitting have gained popularity in causal inference due to their favorable structure-agnostic error guarantees. However, when additional structure, such as H\"{o}lder smoothness, is available then more accurate "double cross-fit doubly robust" (DCDR) estimators can be constructed by splitting the training data and undersmoothing nuisance function estimators on independent samples. We study a DCDR estimator of the Expected Conditional Covariance, a functional of interest in causal inference and conditional independence testing, and derive a series of increasingly powerful results with progressively stronger assumptions. We first provide a structure-agnostic error analysis for the DCDR estimator with no assumptions on the nuisance functions or their estimators. Then, assuming the nuisance functions are H\"{o}lder smooth, but without assuming knowledge of the true smoothness level or the covariate densit
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#38543;&#26426;Halpern&#36845;&#20195;&#22312;&#36171;&#33539;&#31354;&#38388;&#20013;&#30340;Oracle&#22797;&#26434;&#24230;&#65292;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#31639;&#27861;&#22797;&#26434;&#24230;&#65292;&#36827;&#32780;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#25552;&#20986;&#20102;&#26032;&#30340;&#21516;&#27493;&#31639;&#27861;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2403.12338</link><description>&lt;p&gt;
&#38543;&#26426;Halpern&#36845;&#20195;&#22312;&#36171;&#33539;&#31354;&#38388;&#20013;&#30340;&#24212;&#29992;&#21450;&#20854;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Stochastic Halpern iteration in normed spaces and applications to reinforcement learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12338
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#38543;&#26426;Halpern&#36845;&#20195;&#22312;&#36171;&#33539;&#31354;&#38388;&#20013;&#30340;Oracle&#22797;&#26434;&#24230;&#65292;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#31639;&#27861;&#22797;&#26434;&#24230;&#65292;&#36827;&#32780;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#25552;&#20986;&#20102;&#26032;&#30340;&#21516;&#27493;&#31639;&#27861;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#20102;&#20855;&#26377;&#26041;&#24046;&#20943;&#23569;&#30340;&#38543;&#26426;Halpern&#36845;&#20195;&#30340;Oracle&#22797;&#26434;&#24230;&#65292;&#26088;&#22312;&#36817;&#20284;&#26377;&#30028;&#21644;&#25910;&#32553;&#31639;&#23376;&#30340;&#19981;&#21160;&#28857;&#22312;&#19968;&#20010;&#26377;&#38480;&#32500;&#36171;&#33539;&#31354;&#38388;&#20013;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22914;&#26524;&#24213;&#23618;&#30340;&#38543;&#26426;Oracle&#20855;&#26377;&#19968;&#33268;&#26377;&#30028;&#30340;&#26041;&#24046;&#65292;&#21017;&#25105;&#20204;&#30340;&#26041;&#27861;&#23637;&#29616;&#20986;&#24635;&#30340;Oracle&#22797;&#26434;&#24230;&#20026;$ \tilde{O} (\varepsilon^{-5})$&#65292;&#25913;&#36827;&#20102;&#26368;&#36817;&#20026;&#38543;&#26426;Krasnoselskii-Mann&#36845;&#20195;&#24314;&#31435;&#30340;&#36895;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102; $\Omega (\varepsilon^{-3})$&#30340;&#19979;&#30028;&#65292;&#36866;&#29992;&#20110;&#24191;&#27867;&#33539;&#22260;&#30340;&#31639;&#27861;&#65292;&#21253;&#25324;&#25152;&#26377;&#24102;&#26377;&#23567;&#25209;&#22788;&#29702;&#30340;&#24179;&#22343;&#36845;&#20195;&#12290;&#36890;&#36807;&#36866;&#24403;&#20462;&#25913;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#22312;&#31639;&#23376;&#20026; $\gamma$-&#25910;&#32553;&#30340;&#24773;&#20917;&#19979;&#19968;&#20010; $O(\varepsilon^{-2}(1-\gamma)^{-3})$&#22797;&#26434;&#24230;&#19978;&#30028;&#12290;&#20316;&#20026;&#19968;&#20010;&#24212;&#29992;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#29992;&#20110;&#24179;&#22343;&#22870;&#21169;&#21644;&#25240;&#25187;&#22870;&#21169;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#21516;&#27493;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12338v1 Announce Type: cross  Abstract: We analyze the oracle complexity of the stochastic Halpern iteration with variance reduction, where we aim to approximate fixed-points of nonexpansive and contractive operators in a normed finite-dimensional space. We show that if the underlying stochastic oracle is with uniformly bounded variance, our method exhibits an overall oracle complexity of $\tilde{O}(\varepsilon^{-5})$, improving recent rates established for the stochastic Krasnoselskii-Mann iteration. Also, we establish a lower bound of $\Omega(\varepsilon^{-3})$, which applies to a wide range of algorithms, including all averaged iterations even with minibatching. Using a suitable modification of our approach, we derive a $O(\varepsilon^{-2}(1-\gamma)^{-3})$ complexity bound in the case in which the operator is a $\gamma$-contraction. As an application, we propose new synchronous algorithms for average reward and discounted reward Markov decision processes. In particular, f
&lt;/p&gt;</description></item><item><title>DTOR&#26159;&#19968;&#31181;&#20915;&#31574;&#26641;&#24322;&#24120;&#20540;&#22238;&#24402;&#22120;&#65292;&#36890;&#36807;&#20272;&#35745;&#24322;&#24120;&#26816;&#27979;&#27169;&#22411;&#29983;&#25104;&#30340;&#24322;&#24120;&#20998;&#25968;&#26469;&#20135;&#29983;&#22522;&#20110;&#35268;&#21017;&#30340;&#35299;&#37322;&#65292;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#22823;&#37327;&#29305;&#24449;&#25968;&#25454;&#38598;&#12290;</title><link>https://arxiv.org/abs/2403.10903</link><description>&lt;p&gt;
DTOR&#65306;&#20915;&#31574;&#26641;&#24322;&#24120;&#20540;&#22238;&#24402;&#22120;&#29992;&#20110;&#35299;&#37322;&#24322;&#24120;
&lt;/p&gt;
&lt;p&gt;
DTOR: Decision Tree Outlier Regressor to explain anomalies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10903
&lt;/p&gt;
&lt;p&gt;
DTOR&#26159;&#19968;&#31181;&#20915;&#31574;&#26641;&#24322;&#24120;&#20540;&#22238;&#24402;&#22120;&#65292;&#36890;&#36807;&#20272;&#35745;&#24322;&#24120;&#26816;&#27979;&#27169;&#22411;&#29983;&#25104;&#30340;&#24322;&#24120;&#20998;&#25968;&#26469;&#20135;&#29983;&#22522;&#20110;&#35268;&#21017;&#30340;&#35299;&#37322;&#65292;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#22823;&#37327;&#29305;&#24449;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#37322;&#24322;&#24120;&#20540;&#30340;&#20986;&#29616;&#20197;&#21450;&#20854;&#20135;&#29983;&#26426;&#21046;&#22312;&#21508;&#31181;&#39046;&#22495;&#20013;&#21487;&#33021;&#38750;&#24120;&#37325;&#35201;&#12290;&#25925;&#38556;&#12289;&#27450;&#35784;&#12289;&#23041;&#32961;&#31561;&#38382;&#39064;&#65292;&#38500;&#20102;&#34987;&#27491;&#30830;&#35782;&#21035;&#20043;&#22806;&#65292;&#36890;&#24120;&#38656;&#35201;&#26377;&#25928;&#30340;&#35299;&#37322;&#20197;&#26377;&#25928;&#25191;&#34892;&#21487;&#25805;&#20316;&#30340;&#23545;&#25239;&#25514;&#26045;&#12290;&#36234;&#26469;&#36234;&#24191;&#27867;&#22320;&#20351;&#29992;&#22797;&#26434;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#26469;&#35782;&#21035;&#24322;&#24120;&#20540;&#65292;&#20351;&#24471;&#36825;&#26679;&#30340;&#35299;&#37322;&#26356;&#20855;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20915;&#31574;&#26641;&#24322;&#24120;&#20540;&#22238;&#24402;&#22120;&#65288;DTOR&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#36890;&#36807;&#20272;&#35745;&#24322;&#24120;&#26816;&#27979;&#27169;&#22411;&#29983;&#25104;&#30340;&#24322;&#24120;&#20998;&#25968;&#26469;&#20026;&#21333;&#20010;&#25968;&#25454;&#28857;&#29983;&#25104;&#22522;&#20110;&#35268;&#21017;&#30340;&#35299;&#37322;&#30340;&#25216;&#26415;&#12290;&#36825;&#26159;&#36890;&#36807;&#39318;&#20808;&#24212;&#29992;&#20915;&#31574;&#26641;&#22238;&#24402;&#22120;&#26469;&#35745;&#31639;&#20272;&#35745;&#20998;&#25968;&#65292;&#28982;&#21518;&#25552;&#21462;&#19982;&#25968;&#25454;&#28857;&#20998;&#25968;&#30456;&#20851;&#32852;&#30340;&#30456;&#23545;&#36335;&#24452;&#26469;&#23454;&#29616;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#21363;&#20351;&#22312;&#20855;&#26377;&#22823;&#37327;&#29305;&#24449;&#30340;&#25968;&#25454;&#38598;&#20013;&#65292;DTOR&#30340;&#40065;&#26834;&#24615;&#20063;&#24471;&#21040;&#20102;&#35777;&#23454;&#12290;&#27492;&#22806;&#65292;&#19982;&#20854;&#20182;&#22522;&#20110;&#35268;&#21017;&#30340;&#26041;&#27861;&#30456;&#27604;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10903v1 Announce Type: cross  Abstract: Explaining outliers occurrence and mechanism of their occurrence can be extremely important in a variety of domains. Malfunctions, frauds, threats, in addition to being correctly identified, oftentimes need a valid explanation in order to effectively perform actionable counteracts. The ever more widespread use of sophisticated Machine Learning approach to identify anomalies make such explanations more challenging. We present the Decision Tree Outlier Regressor (DTOR), a technique for producing rule-based explanations for individual data points by estimating anomaly scores generated by an anomaly detection model. This is accomplished by first applying a Decision Tree Regressor, which computes the estimation score, and then extracting the relative path associated with the data point score. Our results demonstrate the robustness of DTOR even in datasets with a large number of features. Additionally, in contrast to other rule-based approac
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#32771;&#34385;&#36716;&#31227;&#23433;&#20840;&#30340;&#20840;&#23616;&#39034;&#24207;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#21152;&#36895;&#23433;&#20840;&#23398;&#20064;&#65292;&#24182;&#36890;&#36807;&#39044;&#20808;&#35745;&#31639;&#28304;&#32452;&#20214;&#26469;&#20943;&#23569;&#39069;&#22806;&#30340;&#35745;&#31639;&#36127;&#36733;&#12290;</title><link>https://arxiv.org/abs/2402.14402</link><description>&lt;p&gt;
&#20840;&#23616;&#23433;&#20840;&#39034;&#24207;&#23398;&#20064;&#36890;&#36807;&#39640;&#25928;&#30693;&#35782;&#36716;&#31227;
&lt;/p&gt;
&lt;p&gt;
Global Safe Sequential Learning via Efficient Knowledge Transfer
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14402
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#32771;&#34385;&#36716;&#31227;&#23433;&#20840;&#30340;&#20840;&#23616;&#39034;&#24207;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#21152;&#36895;&#23433;&#20840;&#23398;&#20064;&#65292;&#24182;&#36890;&#36807;&#39044;&#20808;&#35745;&#31639;&#28304;&#32452;&#20214;&#26469;&#20943;&#23569;&#39069;&#22806;&#30340;&#35745;&#31639;&#36127;&#36733;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14402v1 &#20844;&#21578;&#31867;&#22411;: &#26032;&#25688;&#35201;: &#39034;&#24207;&#23398;&#20064;&#26041;&#27861;&#20363;&#22914;&#20027;&#21160;&#23398;&#20064;&#21644;&#36125;&#21494;&#26031;&#20248;&#21270;&#36873;&#25321;&#26368;&#20855;&#20449;&#24687;&#37327;&#30340;&#25968;&#25454;&#26469;&#23398;&#20064;&#19968;&#20010;&#20219;&#21153;&#12290;&#22312;&#35768;&#22810;&#21307;&#23398;&#25110;&#24037;&#31243;&#24212;&#29992;&#20013;&#65292;&#25968;&#25454;&#36873;&#25321;&#21463;&#20808;&#39564;&#26410;&#30693;&#30340;&#23433;&#20840;&#26465;&#20214;&#38480;&#21046;&#12290;&#19968;&#26465;&#26377;&#21069;&#36884;&#30340;&#23433;&#20840;&#23398;&#20064;&#26041;&#27861;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#65288;GPs&#65289;&#26469;&#24314;&#27169;&#23433;&#20840;&#27010;&#29575;&#65292;&#24182;&#22312;&#20855;&#26377;&#36739;&#39640;&#23433;&#20840;&#32622;&#20449;&#24230;&#30340;&#21306;&#22495;&#20013;&#36827;&#34892;&#25968;&#25454;&#36873;&#25321;&#12290;&#28982;&#32780;&#65292;&#20934;&#30830;&#30340;&#23433;&#20840;&#24314;&#27169;&#38656;&#35201;&#20808;&#39564;&#30693;&#35782;&#25110;&#28040;&#32791;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#23433;&#20840;&#32622;&#20449;&#24230;&#38598;&#20013;&#22312;&#32473;&#23450;&#30340;&#35266;&#27979;&#20540;&#21608;&#22260;&#65292;&#23548;&#33268;&#23616;&#37096;&#25506;&#32034;&#12290;&#30001;&#20110;&#22312;&#23433;&#20840;&#20851;&#38190;&#23454;&#39564;&#20013;&#36890;&#24120;&#23384;&#22312;&#21487;&#36716;&#31227;&#30340;&#28304;&#30693;&#35782;&#65292;&#25105;&#20204;&#25552;&#20986;&#32771;&#34385;&#36716;&#31227;&#23433;&#20840;&#39034;&#24207;&#23398;&#20064;&#26469;&#21152;&#36895;&#23433;&#20840;&#23398;&#20064;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#32771;&#34385;&#20808;&#35745;&#31639;&#28304;&#32452;&#20214;&#65292;&#20197;&#20943;&#23569;&#24341;&#20837;&#28304;&#25968;&#25454;&#24102;&#26469;&#30340;&#39069;&#22806;&#35745;&#31639;&#36127;&#36733;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14402v1 Announce Type: new  Abstract: Sequential learning methods such as active learning and Bayesian optimization select the most informative data to learn about a task. In many medical or engineering applications, the data selection is constrained by a priori unknown safety conditions. A promissing line of safe learning methods utilize Gaussian processes (GPs) to model the safety probability and perform data selection in areas with high safety confidence. However, accurate safety modeling requires prior knowledge or consumes data. In addition, the safety confidence centers around the given observations which leads to local exploration. As transferable source knowledge is often available in safety critical experiments, we propose to consider transfer safe sequential learning to accelerate the learning of safety. We further consider a pre-computation of source components to reduce the additional computational load that is introduced by incorporating source data. In this pap
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38543;&#26426;Hessian-&#21521;&#37327;&#20056;&#31215;&#19978;&#25311;&#21512;Hessian&#25110;&#20854;&#36870;&#65292;&#25581;&#31034;&#20102;&#19981;&#21516;Hessian&#25311;&#21512;&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#29305;&#23450;&#26446;&#32676;&#19978;&#30340;Hessian&#25311;&#21512;&#38382;&#39064;&#22312;&#36731;&#24494;&#26465;&#20214;&#19979;&#26159;&#24378;&#20984;&#30340;&#12290;</title><link>https://arxiv.org/abs/2402.11858</link><description>&lt;p&gt;
&#22312;&#26446;&#32676;&#19978;&#30340;&#38543;&#26426;Hessian&#25311;&#21512;
&lt;/p&gt;
&lt;p&gt;
Stochastic Hessian Fitting on Lie Group
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11858
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38543;&#26426;Hessian-&#21521;&#37327;&#20056;&#31215;&#19978;&#25311;&#21512;Hessian&#25110;&#20854;&#36870;&#65292;&#25581;&#31034;&#20102;&#19981;&#21516;Hessian&#25311;&#21512;&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#29305;&#23450;&#26446;&#32676;&#19978;&#30340;Hessian&#25311;&#21512;&#38382;&#39064;&#22312;&#36731;&#24494;&#26465;&#20214;&#19979;&#26159;&#24378;&#20984;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38543;&#26426;Hessian-&#21521;&#37327;&#20056;&#31215;&#19978;&#25311;&#21512;Hessian&#25110;&#20854;&#36870;&#12290;&#20351;&#29992;&#20102;&#19968;&#20010;Hessian&#25311;&#21512;&#20934;&#21017;&#65292;&#21487;&#29992;&#20110;&#25512;&#23548;&#22823;&#37096;&#20998;&#24120;&#29992;&#26041;&#27861;&#65292;&#22914;BFGS&#12289;&#39640;&#26031;&#29275;&#39039;&#12289;AdaGrad&#31561;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#19981;&#21516;Hessian&#25311;&#21512;&#26041;&#27861;&#30340;&#19981;&#21516;&#25910;&#25947;&#36895;&#29575;&#65292;&#20363;&#22914;&#65292;&#22312;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#20013;&#30340;&#26799;&#24230;&#19979;&#38477;&#30340;&#27425;&#32447;&#24615;&#36895;&#29575;&#21644;&#23545;&#31216;&#27491;&#23450;&#65288;SPL&#65289;&#30697;&#38453;&#21644;&#26576;&#20123;&#26446;&#32676;&#19978;&#30340;&#26799;&#24230;&#19979;&#38477;&#30340;&#32447;&#24615;&#36895;&#29575;&#12290;&#22312;&#29305;&#23450;&#19988;&#36275;&#22815;&#19968;&#33324;&#30340;&#26446;&#32676;&#19978;&#30340;Hessian&#25311;&#21512;&#38382;&#39064;&#22312;&#36731;&#24494;&#26465;&#20214;&#19979;&#34987;&#35777;&#26126;&#26159;&#24378;&#20984;&#30340;&#12290;&#20026;&#20102;&#30830;&#35748;&#25105;&#20204;&#30340;&#20998;&#26512;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#19981;&#21516;&#35774;&#32622;&#19979;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#22914;&#26377;&#22122;&#22768;&#30340;Hessian-&#21521;&#37327;&#20056;&#31215;&#12289;&#26102;&#21464;&#30340;Hessians&#21644;&#20302;&#31934;&#24230;&#31639;&#26415;&#12290;&#36825;&#20123;&#21457;&#29616;&#23545;&#20381;&#36182;&#20110;&#38543;&#26426;&#20108;&#38454;&#20248;&#21270;&#30340;&#26041;&#27861;&#26159;&#26377;&#29992;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11858v1 Announce Type: cross  Abstract: This paper studies the fitting of Hessian or its inverse with stochastic Hessian-vector products. A Hessian fitting criterion, which can be used to derive most of the commonly used methods, e.g., BFGS, Gaussian-Newton, AdaGrad, etc., is used for the analysis. Our studies reveal different convergence rates for different Hessian fitting methods, e.g., sublinear rates for gradient descent in the Euclidean space and a commonly used closed-form solution, linear rates for gradient descent on the manifold of symmetric positive definite (SPL) matrices and certain Lie groups. The Hessian fitting problem is further shown to be strongly convex under mild conditions on a specific yet general enough Lie group. To confirm our analysis, these methods are tested under different settings like noisy Hessian-vector products, time varying Hessians, and low precision arithmetic. These findings are useful for stochastic second order optimizations that rely 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#31283;&#20581;&#30340;&#20272;&#35745;&#37327;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#29616;&#20195;&#25968;&#25454;&#20016;&#23500;&#30340;&#29615;&#22659;&#20013;&#20272;&#35745;&#23384;&#22312;&#26410;&#35266;&#23519;&#28151;&#26434;&#22240;&#32032;&#19979;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#26377;&#38480;&#26679;&#26412;&#21644;&#28176;&#36817;&#24615;&#36136;&#65292;&#24182;&#22312;&#21442;&#25968;&#36895;&#29575;&#19979;&#23558;&#20854;&#35823;&#24046;&#25910;&#25947;&#20026;&#38646;&#22343;&#20540;&#39640;&#26031;&#20998;&#24067;&#12290;</title><link>https://arxiv.org/abs/2402.11652</link><description>&lt;p&gt;
&#22240;&#26524;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#20013;&#30340;&#21452;&#37325;&#31283;&#20581;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Doubly Robust Inference in Causal Latent Factor Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11652
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#31283;&#20581;&#30340;&#20272;&#35745;&#37327;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#29616;&#20195;&#25968;&#25454;&#20016;&#23500;&#30340;&#29615;&#22659;&#20013;&#20272;&#35745;&#23384;&#22312;&#26410;&#35266;&#23519;&#28151;&#26434;&#22240;&#32032;&#19979;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#26377;&#38480;&#26679;&#26412;&#21644;&#28176;&#36817;&#24615;&#36136;&#65292;&#24182;&#22312;&#21442;&#25968;&#36895;&#29575;&#19979;&#23558;&#20854;&#35823;&#24046;&#25910;&#25947;&#20026;&#38646;&#22343;&#20540;&#39640;&#26031;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#29616;&#20195;&#25968;&#25454;&#20016;&#23500;&#29615;&#22659;&#20013;&#20272;&#35745;&#23384;&#22312;&#26410;&#35266;&#23519;&#28151;&#26434;&#22240;&#32032;&#19979;&#30340;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#30340;&#26032;&#26694;&#26550;&#65292;&#35813;&#29615;&#22659;&#20855;&#26377;&#22823;&#37327;&#21333;&#20301;&#21644;&#32467;&#26524;&#12290;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#37327;&#26159;&#21452;&#37325;&#31283;&#20581;&#30340;&#65292;&#32467;&#21512;&#20102;&#32467;&#26524;&#22635;&#34917;&#12289;&#20498;&#25968;&#27010;&#29575;&#21152;&#26435;&#20197;&#21450;&#19968;&#31181;&#29992;&#20110;&#30697;&#38453;&#34917;&#20840;&#30340;&#26032;&#22411;&#20132;&#21449;&#37197;&#23545;&#31243;&#24207;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#26377;&#38480;&#26679;&#26412;&#21644;&#28176;&#36817;&#20445;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#26032;&#20272;&#35745;&#37327;&#30340;&#35823;&#24046;&#25910;&#25947;&#21040;&#21442;&#25968;&#36895;&#29575;&#19979;&#30340;&#38646;&#22343;&#20540;&#39640;&#26031;&#20998;&#24067;&#12290;&#27169;&#25311;&#32467;&#26524;&#23637;&#31034;&#20102;&#26412;&#25991;&#20998;&#26512;&#30340;&#20272;&#35745;&#37327;&#30340;&#24418;&#24335;&#29305;&#24615;&#30340;&#23454;&#38469;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11652v1 Announce Type: cross  Abstract: This article introduces a new framework for estimating average treatment effects under unobserved confounding in modern data-rich environments featuring large numbers of units and outcomes. The proposed estimator is doubly robust, combining outcome imputation, inverse probability weighting, and a novel cross-fitting procedure for matrix completion. We derive finite-sample and asymptotic guarantees, and show that the error of the new estimator converges to a mean-zero Gaussian distribution at a parametric rate. Simulation results demonstrate the practical relevance of the formal properties of the estimators analyzed in this article.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#25351;&#25968;&#26426;&#21046;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#24182;&#25552;&#20986;&#20102;Metropolis-Hastings&#31639;&#27861;&#26469;&#20811;&#26381;&#25351;&#25968;&#25628;&#32034;&#31354;&#38388;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#19968;&#23450;&#36793;&#30028;&#26465;&#20214;&#19979;&#33021;&#22815;&#23454;&#29616;&#24378;&#27169;&#22411;&#24674;&#22797;&#24615;&#36136;&#65292;&#24182;&#20855;&#26377;&#22810;&#39033;&#24335;&#28151;&#21512;&#26102;&#38388;&#21644;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2310.07852</link><description>&lt;p&gt;
&#20851;&#20110;&#36890;&#36807;&#25351;&#25968;&#26426;&#21046;&#36827;&#34892;&#39640;&#32500;&#31169;&#26377;&#27169;&#22411;&#36873;&#25321;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Computational Complexity of Private High-dimensional Model Selection via the Exponential Mechanism. (arXiv:2310.07852v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07852
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#25351;&#25968;&#26426;&#21046;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#24182;&#25552;&#20986;&#20102;Metropolis-Hastings&#31639;&#27861;&#26469;&#20811;&#26381;&#25351;&#25968;&#25628;&#32034;&#31354;&#38388;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#19968;&#23450;&#36793;&#30028;&#26465;&#20214;&#19979;&#33021;&#22815;&#23454;&#29616;&#24378;&#27169;&#22411;&#24674;&#22797;&#24615;&#36136;&#65292;&#24182;&#20855;&#26377;&#22810;&#39033;&#24335;&#28151;&#21512;&#26102;&#38388;&#21644;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24046;&#20998;&#38544;&#31169;&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#39640;&#32500;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#24046;&#20998;&#38544;&#31169;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#30340;&#38382;&#39064;&#65292;&#24182;&#30740;&#31350;&#20102;&#20854;&#25928;&#29992;&#20445;&#35777;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#24191;&#20026;&#20154;&#30693;&#30340;&#25351;&#25968;&#26426;&#21046;&#26469;&#36873;&#25321;&#26368;&#20339;&#27169;&#22411;&#65292;&#24182;&#22312;&#19968;&#23450;&#36793;&#30028;&#26465;&#20214;&#19979;&#65292;&#24314;&#31435;&#20102;&#20854;&#24378;&#27169;&#22411;&#24674;&#22797;&#24615;&#36136;&#12290;&#28982;&#32780;&#65292;&#25351;&#25968;&#26426;&#21046;&#30340;&#25351;&#25968;&#25628;&#32034;&#31354;&#38388;&#23548;&#33268;&#20102;&#20005;&#37325;&#30340;&#35745;&#31639;&#29942;&#39048;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Metropolis-Hastings&#31639;&#27861;&#26469;&#36827;&#34892;&#37319;&#26679;&#27493;&#39588;&#65292;&#24182;&#22312;&#38382;&#39064;&#21442;&#25968;$n$&#12289;$p$&#21644;$s$&#20013;&#24314;&#31435;&#20102;&#20854;&#21040;&#31283;&#24577;&#20998;&#24067;&#30340;&#22810;&#39033;&#24335;&#28151;&#21512;&#26102;&#38388;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21033;&#29992;&#20854;&#28151;&#21512;&#24615;&#36136;&#24314;&#31435;&#20102;Metropolis-Hastings&#38543;&#26426;&#34892;&#36208;&#30340;&#26368;&#32456;&#20272;&#35745;&#30340;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#24615;&#36136;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#19968;&#20123;&#35828;&#26126;&#24615;&#27169;&#25311;&#65292;&#21360;&#35777;&#20102;&#25105;&#20204;&#20027;&#35201;&#32467;&#26524;&#30340;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of model selection in a high-dimensional sparse linear regression model under the differential privacy framework. In particular, we consider the problem of differentially private best subset selection and study its utility guarantee. We adopt the well-known exponential mechanism for selecting the best model, and under a certain margin condition, we establish its strong model recovery property. However, the exponential search space of the exponential mechanism poses a serious computational bottleneck. To overcome this challenge, we propose a Metropolis-Hastings algorithm for the sampling step and establish its polynomial mixing time to its stationary distribution in the problem parameters $n,p$, and $s$. Furthermore, we also establish approximate differential privacy for the final estimates of the Metropolis-Hastings random walk using its mixing property. Finally, we also perform some illustrative simulations that echo the theoretical findings of our main results
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20869;&#22312;&#32500;&#24230;&#23545;&#21387;&#32553;&#19979;&#30340;&#24230;&#37327;&#23398;&#20064;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#22312;&#23545;&#25968;&#25454;&#36827;&#34892;&#38543;&#26426;&#21387;&#32553;&#21518;&#22312;&#20302;&#32500;&#31354;&#38388;&#20869;&#35757;&#32451;&#20840;&#31209;&#24230;&#37327;&#30340;&#26041;&#27861;&#12290;&#29702;&#35770;&#20445;&#35777;&#20102;&#22312;&#19981;&#20381;&#36182;&#29615;&#22659;&#32500;&#24230;&#30340;&#24773;&#20917;&#19979;&#65292;&#24230;&#37327;&#23398;&#20064;&#30340;&#35823;&#24046;&#21487;&#20197;&#34987;&#25511;&#21046;&#65292;&#24182;&#19988;&#22312;&#23384;&#22312;&#33391;&#24615;&#20960;&#20309;&#32467;&#26500;&#26102;&#25928;&#26524;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2309.05751</link><description>&lt;p&gt;
&#20869;&#22312;&#32500;&#24230;&#23545;&#21387;&#32553;&#19979;&#30340;&#24230;&#37327;&#23398;&#20064;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
The Effect of Intrinsic Dimension on Metric Learning under Compression. (arXiv:2309.05751v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05751
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20869;&#22312;&#32500;&#24230;&#23545;&#21387;&#32553;&#19979;&#30340;&#24230;&#37327;&#23398;&#20064;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#22312;&#23545;&#25968;&#25454;&#36827;&#34892;&#38543;&#26426;&#21387;&#32553;&#21518;&#22312;&#20302;&#32500;&#31354;&#38388;&#20869;&#35757;&#32451;&#20840;&#31209;&#24230;&#37327;&#30340;&#26041;&#27861;&#12290;&#29702;&#35770;&#20445;&#35777;&#20102;&#22312;&#19981;&#20381;&#36182;&#29615;&#22659;&#32500;&#24230;&#30340;&#24773;&#20917;&#19979;&#65292;&#24230;&#37327;&#23398;&#20064;&#30340;&#35823;&#24046;&#21487;&#20197;&#34987;&#25511;&#21046;&#65292;&#24182;&#19988;&#22312;&#23384;&#22312;&#33391;&#24615;&#20960;&#20309;&#32467;&#26500;&#26102;&#25928;&#26524;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24230;&#37327;&#23398;&#20064;&#26088;&#22312;&#22312;&#36755;&#20837;&#31354;&#38388;&#20013;&#25214;&#21040;&#36866;&#24403;&#30340;&#36317;&#31163;&#24230;&#37327;&#65292;&#20197;&#25913;&#21892;&#22522;&#20110;&#36317;&#31163;&#30340;&#23398;&#20064;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;&#22312;&#39640;&#32500;&#29615;&#22659;&#20013;&#65292;&#24230;&#37327;&#23398;&#20064;&#36824;&#21487;&#20197;&#20316;&#20026;&#38477;&#32500;&#30340;&#25163;&#27573;&#65292;&#36890;&#36807;&#23545;&#23398;&#20064;&#30340;&#24230;&#37327;&#26045;&#21152;&#19968;&#20010;&#20302;&#31209;&#32422;&#26463;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#30340;&#26159;&#23545;&#25968;&#25454;&#30340;&#19968;&#20010;&#38543;&#26426;&#21387;&#32553;&#29256;&#26412;&#65292;&#28982;&#21518;&#22312;&#20854;&#20013;&#35757;&#32451;&#19968;&#20010;&#20840;&#31209;&#30340;&#24230;&#37327;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#20851;&#20110;&#36317;&#31163;&#24230;&#37327;&#23398;&#20064;&#30340;&#35823;&#24046;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#36825;&#20123;&#20445;&#35777;&#19981;&#20381;&#36182;&#20110;&#29615;&#22659;&#32500;&#24230;&#12290;&#25105;&#20204;&#30340;&#36793;&#30028;&#38500;&#20102;&#23545;&#26469;&#33258;&#26377;&#30028;&#25903;&#25345;&#30340;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#27809;&#26377;&#26174;&#24335;&#30340;&#20551;&#35774;&#20043;&#22806;&#65292;&#24182;&#19988;&#22312;&#23384;&#22312;&#33391;&#24615;&#20960;&#20309;&#32467;&#26500;&#26102;&#33258;&#21160;&#25910;&#25947;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#25903;&#25345;&#25105;&#20204;&#22312;&#39640;&#32500;&#29615;&#22659;&#20013;&#30340;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Metric learning aims at finding a suitable distance metric over the input space, to improve the performance of distance-based learning algorithms. In high-dimensional settings, metric learning can also play the role of dimensionality reduction, by imposing a low-rank restriction to the learnt metric. In this paper, instead of training a low-rank metric on high-dimensional data, we consider a randomly compressed version of the data, and train a full-rank metric there. We give theoretical guarantees on the error of distance-based metric learning, with respect to the random compression, which do not depend on the ambient dimension. Our bounds do not make any explicit assumptions, aside from i.i.d. data from a bounded support, and automatically tighten when benign geometrical structures are present. Experimental results on both synthetic and real data sets support our theoretical findings in high-dimensional settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20132;&#20114;&#23398;&#20064;&#21644;&#25512;&#33616;&#31995;&#32479;&#20013;&#38544;&#31169;&#20445;&#25252;&#30340;Bandit&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#38598;&#20013;&#24046;&#20998;&#38544;&#31169;&#30340;&#27010;&#24565;&#12290;&#36890;&#36807;&#25552;&#20379;&#20851;&#20110;&#26377;&#38480;&#33218;&#21644;&#32447;&#24615;Bandit&#38382;&#39064;&#36951;&#25022;&#30340;&#19979;&#30028;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#19981;&#21516;&#38544;&#31169;&#39044;&#31639;&#19979;&#30340;&#38590;&#24230;&#21306;&#22495;&#65292;&#24182;&#21457;&#29616;&#38598;&#20013;&#24046;&#20998;&#38544;&#31169;&#21487;&#20197;&#27604;&#20840;&#23616;&#24046;&#20998;&#38544;&#31169;&#26356;&#26377;&#25928;&#22320;&#20445;&#25252;&#38544;&#31169;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#30456;&#24212;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.00557</link><description>&lt;p&gt;
&#20132;&#20114;&#24335;&#21644;&#38598;&#20013;&#24335;&#24046;&#20998;&#38544;&#31169;&#22312;Bandit&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Interactive and Concentrated Differential Privacy for Bandits. (arXiv:2309.00557v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00557
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20132;&#20114;&#23398;&#20064;&#21644;&#25512;&#33616;&#31995;&#32479;&#20013;&#38544;&#31169;&#20445;&#25252;&#30340;Bandit&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#38598;&#20013;&#24046;&#20998;&#38544;&#31169;&#30340;&#27010;&#24565;&#12290;&#36890;&#36807;&#25552;&#20379;&#20851;&#20110;&#26377;&#38480;&#33218;&#21644;&#32447;&#24615;Bandit&#38382;&#39064;&#36951;&#25022;&#30340;&#19979;&#30028;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#19981;&#21516;&#38544;&#31169;&#39044;&#31639;&#19979;&#30340;&#38590;&#24230;&#21306;&#22495;&#65292;&#24182;&#21457;&#29616;&#38598;&#20013;&#24046;&#20998;&#38544;&#31169;&#21487;&#20197;&#27604;&#20840;&#23616;&#24046;&#20998;&#38544;&#31169;&#26356;&#26377;&#25928;&#22320;&#20445;&#25252;&#38544;&#31169;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#30456;&#24212;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Bandit&#38382;&#39064;&#22312;&#20132;&#20114;&#24335;&#23398;&#20064;&#26041;&#26696;&#21644;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#20013;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31995;&#32479;&#36890;&#24120;&#20381;&#36182;&#20110;&#25935;&#24863;&#30340;&#29992;&#25143;&#25968;&#25454;&#65292;&#22240;&#27492;&#38544;&#31169;&#26159;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;&#26412;&#25991;&#36890;&#36807;&#20132;&#20114;&#24335;&#24046;&#20998;&#38544;&#31169;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#22522;&#20110;&#21487;&#20449;&#38598;&#20013;&#24335;&#20915;&#31574;&#32773;&#30340;Bandit&#38382;&#39064;&#30340;&#38544;&#31169;&#24615;&#12290;&#34429;&#28982;&#24050;&#32463;&#23545;&#32431;&#949;-&#20840;&#23616;&#24046;&#20998;&#38544;&#31169;&#30340;Bandit&#38382;&#39064;&#36827;&#34892;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#25105;&#20204;&#22312;&#29702;&#35299;&#38646;&#38598;&#20013;&#24046;&#20998;&#38544;&#31169;(zCDP)&#30340;Bandit&#38382;&#39064;&#26041;&#38754;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;&#38024;&#23545;&#26377;&#38480;&#33218;&#21644;&#32447;&#24615;Bandit&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#36951;&#25022;&#30340;&#26368;&#23567;&#26368;&#22823;&#21644;&#38382;&#39064;&#30456;&#20851;&#19979;&#30028;&#65292;&#20174;&#32780;&#37327;&#21270;&#20102;&#36825;&#20123;&#24773;&#20917;&#19979;&#961;-&#20840;&#23616;zCDP&#30340;&#20195;&#20215;&#12290;&#36825;&#20123;&#19979;&#30028;&#25581;&#31034;&#20102;&#22522;&#20110;&#38544;&#31169;&#39044;&#31639;&#961;&#30340;&#20004;&#20010;&#22256;&#38590;&#21306;&#22495;&#65292;&#24182;&#34920;&#26126;&#961;-&#20840;&#23616;zCDP&#27604;&#32431;&#949;-&#20840;&#23616;&#24046;&#20998;&#38544;&#31169;&#20135;&#29983;&#30340;&#36951;&#25022;&#26356;&#23567;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26377;&#38480;&#33218;&#21644;&#32447;&#24615;Bandit&#38382;&#39064;&#30340;&#961;-&#20840;&#23616;zCDP&#31639;&#27861;&#65292;&#21363;AdaC-UCB&#21644;AdaC-GOPE&#12290;&#36825;&#20004;&#20010;&#31639;&#27861;&#37117;&#20351;&#29992;&#20102;&#39640;&#26031;&#26426;&#21046;&#30340;&#20849;&#21516;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bandits play a crucial role in interactive learning schemes and modern recommender systems. However, these systems often rely on sensitive user data, making privacy a critical concern. This paper investigates privacy in bandits with a trusted centralized decision-maker through the lens of interactive Differential Privacy (DP). While bandits under pure $\epsilon$-global DP have been well-studied, we contribute to the understanding of bandits under zero Concentrated DP (zCDP). We provide minimax and problem-dependent lower bounds on regret for finite-armed and linear bandits, which quantify the cost of $\rho$-global zCDP in these settings. These lower bounds reveal two hardness regimes based on the privacy budget $\rho$ and suggest that $\rho$-global zCDP incurs less regret than pure $\epsilon$-global DP. We propose two $\rho$-global zCDP bandit algorithms, AdaC-UCB and AdaC-GOPE, for finite-armed and linear bandits respectively. Both algorithms use a common recipe of Gaussian mechanism 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20223;&#30495;&#30340;&#20808;&#39564;&#30693;&#35782;&#24341;&#23548;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#39046;&#22495;&#19987;&#23478;&#30340;&#30693;&#35782;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#21046;&#23450;&#19982;&#19987;&#23478;&#39044;&#26399;&#19968;&#33268;&#30340;&#27169;&#22411;&#21442;&#25968;&#20808;&#39564;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2308.11672</link><description>&lt;p&gt;
&#22522;&#20110;&#20223;&#30495;&#30340;&#20808;&#39564;&#30693;&#35782;&#24341;&#23548;&#21442;&#25968;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Simulation-Based Prior Knowledge Elicitation for Parametric Bayesian Models. (arXiv:2308.11672v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11672
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20223;&#30495;&#30340;&#20808;&#39564;&#30693;&#35782;&#24341;&#23548;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#39046;&#22495;&#19987;&#23478;&#30340;&#30693;&#35782;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#21046;&#23450;&#19982;&#19987;&#23478;&#39044;&#26399;&#19968;&#33268;&#30340;&#27169;&#22411;&#21442;&#25968;&#20808;&#39564;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#32479;&#35745;&#23398;&#30340;&#19968;&#20010;&#20851;&#38190;&#29305;&#28857;&#26159;&#33021;&#22815;&#23558;&#20808;&#39564;&#30693;&#35782;&#19968;&#33268;&#22320;&#32435;&#20837;&#21508;&#31181;&#24314;&#27169;&#36807;&#31243;&#20013;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20851;&#27880;&#23558;&#39046;&#22495;&#19987;&#23478;&#30693;&#35782;&#36716;&#21270;&#20026;&#30456;&#24212;&#30340;&#27169;&#22411;&#21442;&#25968;&#20808;&#39564;&#20998;&#24067;&#30340;&#36807;&#31243;&#65292;&#21363;&#20808;&#39564;&#24341;&#23548;&#12290;&#19987;&#23478;&#30693;&#35782;&#21487;&#20197;&#20855;&#20307;&#34920;&#29616;&#20026;&#21407;&#22987;&#25968;&#25454;&#12289;&#25688;&#35201;&#32479;&#35745;&#20449;&#24687;&#25110;&#27169;&#22411;&#21442;&#25968;&#30340;&#20449;&#24687;&#31561;&#22810;&#31181;&#26684;&#24335;&#12290;&#29616;&#26377;&#30340;&#24341;&#23548;&#26041;&#27861;&#38754;&#20020;&#30340;&#20027;&#35201;&#25361;&#25112;&#26159;&#22914;&#20309;&#26377;&#25928;&#22320;&#21033;&#29992;&#25152;&#26377;&#36825;&#20123;&#19981;&#21516;&#30340;&#26684;&#24335;&#65292;&#20197;&#21046;&#23450;&#19982;&#19987;&#23478;&#39044;&#26399;&#19968;&#33268;&#30340;&#20808;&#39564;&#20998;&#24067;&#65292;&#32780;&#19981;&#21463;&#27169;&#22411;&#32467;&#26500;&#30340;&#24433;&#21709;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#20223;&#30495;&#30340;&#24341;&#23548;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20174;&#24191;&#27867;&#30340;&#19987;&#23478;&#30693;&#35782;&#20013;&#23398;&#20064;&#21487;&#33021;&#30340;&#20219;&#20309;&#21442;&#25968;&#21270;&#20808;&#39564;&#20998;&#24067;&#30340;&#36229;&#21442;&#25968;&#12290;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#24341;&#23548;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
A central characteristic of Bayesian statistics is the ability to consistently incorporate prior knowledge into various modeling processes. In this paper, we focus on translating domain expert knowledge into corresponding prior distributions over model parameters, a process known as prior elicitation. Expert knowledge can manifest itself in diverse formats, including information about raw data, summary statistics, or model parameters. A major challenge for existing elicitation methods is how to effectively utilize all of these different formats in order to formulate prior distributions that align with the expert's expectations, regardless of the model structure. To address these challenges, we develop a simulation-based elicitation method that can learn the hyperparameters of potentially any parametric prior distribution from a wide spectrum of expert knowledge using stochastic gradient descent. We validate the effectiveness and robustness of our elicitation method in four representati
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27010;&#29575;&#21644;&#25968;&#25454;&#39537;&#21160;&#30340;&#38381;&#21512;&#27169;&#22411;&#65292;&#29992;&#20110;RANS&#27169;&#25311;&#20013;&#32771;&#34385;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#35813;&#27169;&#22411;&#21253;&#25324;&#21442;&#25968;&#21270;&#37096;&#20998;&#21644;&#38543;&#26426;&#21464;&#37327;&#37096;&#20998;&#65292;&#24182;&#36890;&#36807;&#36125;&#21494;&#26031;&#20844;&#24335;&#21644;&#31232;&#30095;&#20808;&#39564;&#26469;&#35782;&#21035;&#27169;&#22411;&#19981;&#36275;&#30340;&#21306;&#22495;&#65292;&#20197;&#36827;&#34892;&#20462;&#27491;&#12290;&#35757;&#32451;&#20351;&#29992;&#38388;&#25509;&#31232;&#30095;&#25968;&#25454;&#65292;&#25512;&#26029;&#21644;&#23398;&#20064;&#20351;&#29992;&#38543;&#26426;&#21464;&#20998;&#25512;&#26029;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2307.02432</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#27010;&#29575;&#21644;&#25968;&#25454;&#39537;&#21160;&#30340;RANS&#27169;&#25311;&#30340;&#38381;&#21512;&#27169;&#22411;&#65292;&#32771;&#34385;&#21040;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
A probabilistic, data-driven closure model for RANS simulations with aleatoric, model uncertainty. (arXiv:2307.02432v1 [physics.flu-dyn])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02432
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27010;&#29575;&#21644;&#25968;&#25454;&#39537;&#21160;&#30340;&#38381;&#21512;&#27169;&#22411;&#65292;&#29992;&#20110;RANS&#27169;&#25311;&#20013;&#32771;&#34385;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#35813;&#27169;&#22411;&#21253;&#25324;&#21442;&#25968;&#21270;&#37096;&#20998;&#21644;&#38543;&#26426;&#21464;&#37327;&#37096;&#20998;&#65292;&#24182;&#36890;&#36807;&#36125;&#21494;&#26031;&#20844;&#24335;&#21644;&#31232;&#30095;&#20808;&#39564;&#26469;&#35782;&#21035;&#27169;&#22411;&#19981;&#36275;&#30340;&#21306;&#22495;&#65292;&#20197;&#36827;&#34892;&#20462;&#27491;&#12290;&#35757;&#32451;&#20351;&#29992;&#38388;&#25509;&#31232;&#30095;&#25968;&#25454;&#65292;&#25512;&#26029;&#21644;&#23398;&#20064;&#20351;&#29992;&#38543;&#26426;&#21464;&#20998;&#25512;&#26029;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27010;&#29575;&#21644;&#25968;&#25454;&#39537;&#21160;&#30340;&#38381;&#21512;&#27169;&#22411;&#65292;&#29992;&#20110;Reynolds&#24179;&#22343;Navier-Stokes (RANS)&#27169;&#25311;&#20013;&#32771;&#34385;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#35813;&#38381;&#21512;&#27169;&#22411;&#21253;&#25324;&#20004;&#37096;&#20998;&#12290;&#31532;&#19968;&#37096;&#20998;&#26159;&#21442;&#25968;&#21270;&#30340;&#65292;&#21033;&#29992;&#20102;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#24352;&#37327;&#22522;&#20989;&#25968;&#65292;&#36825;&#20123;&#20989;&#25968;&#20381;&#36182;&#20110;&#24212;&#21464;&#29575;&#21644;&#26059;&#36716;&#24352;&#37327;&#30340;&#19981;&#21464;&#37327;&#12290;&#31532;&#20108;&#37096;&#20998;&#21017;&#26159;&#38543;&#26426;&#21464;&#37327;&#65292;&#29992;&#20110;&#32771;&#34385;&#27169;&#22411;&#35823;&#24046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#36125;&#21494;&#26031;&#30340;&#20844;&#24335;&#65292;&#24182;&#32467;&#21512;&#20102;&#19968;&#31181;&#31232;&#30095;&#20808;&#39564;&#65292;&#20197;&#35782;&#21035;&#38382;&#39064;&#39046;&#22495;&#20013;&#21442;&#25968;&#21270;&#38381;&#21512;&#27169;&#22411;&#19981;&#36275;&#30340;&#22320;&#26041;&#65292;&#36827;&#32780;&#38656;&#35201;&#23545;&#38647;&#35834;&#24212;&#21147;&#24352;&#37327;&#36827;&#34892;&#38543;&#26426;&#20462;&#27491;&#12290;&#35757;&#32451;&#20351;&#29992;&#38388;&#25509;&#31232;&#30095;&#25968;&#25454;&#65292;&#22914;&#24179;&#22343;&#36895;&#24230;&#21644;&#21387;&#21147;&#65292;&#32780;&#19981;&#38656;&#35201;&#30452;&#25509;&#30340;&#38647;&#35834;&#24212;&#21147;&#25968;&#25454;&#65292;&#19982;&#22823;&#22810;&#25968;&#20854;&#20182;&#26041;&#27861;&#19981;&#21516;&#12290;&#20026;&#20102;&#25512;&#26029;&#21644;&#23398;&#20064;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#19968;&#31181;&#22522;&#20110;&#33945;&#29305;&#21345;&#27931;&#20272;&#35745;&#30340;&#38543;&#26426;&#21464;&#20998;&#25512;&#26029;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a data-driven, closure model for Reynolds-averaged Navier-Stokes (RANS) simulations that incorporates aleatoric, model uncertainty. The proposed closure consists of two parts. A parametric one, which utilizes previously proposed, neural-network-based tensor basis functions dependent on the rate of strain and rotation tensor invariants. This is complemented by latent, random variables which account for aleatoric model errors. A fully Bayesian formulation is proposed, combined with a sparsity-inducing prior in order to identify regions in the problem domain where the parametric closure is insufficient and where stochastic corrections to the Reynolds stress tensor are needed. Training is performed using sparse, indirect data, such as mean velocities and pressures, in contrast to the majority of alternatives that require direct Reynolds stress data. For inference and learning, a Stochastic Variational Inference scheme is employed, which is based on Monte Carlo estimates of the p
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#32467;&#21512;&#21333;&#27493;&#30340;Fisher&#24471;&#20998;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#28176;&#36827;&#39640;&#25928;&#30340;&#21442;&#25968;&#20272;&#35745;&#65292;&#26159;&#19968;&#31181;&#20248;&#31168;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.05896</link><description>&lt;p&gt;
&#28176;&#36827;&#39640;&#25928;&#21333;&#27493;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#27861;
&lt;/p&gt;
&lt;p&gt;
Asymptotically efficient one-step stochastic gradient descent. (arXiv:2306.05896v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05896
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#32467;&#21512;&#21333;&#27493;&#30340;Fisher&#24471;&#20998;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#28176;&#36827;&#39640;&#25928;&#30340;&#21442;&#25968;&#20272;&#35745;&#65292;&#26159;&#19968;&#31181;&#20248;&#31168;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25551;&#36848;&#20102;&#19968;&#31181;&#36890;&#29992;&#12289;&#24555;&#36895;&#21644;&#28176;&#36827;&#39640;&#25928;&#30340;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#12290;&#23427;&#22522;&#20110;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65292;&#32416;&#27491;&#20102;Fisher&#24471;&#20998;&#31639;&#27861;&#30340;&#21333;&#19968;&#27493;&#39588;&#12290;&#25105;&#20204;&#22312;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#29702;&#35770;&#19978;&#21644;&#27169;&#25311;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#23427;&#26159;&#19982;&#36890;&#24120;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#24179;&#22343;&#25110;&#33258;&#36866;&#24212;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26377;&#36259;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
A generic, fast and asymptotically efficient method for parametric estimation is described. It is based on the stochastic gradient descent on the loglikelihood function corrected by a single step of the Fisher scoring algorithm. We show theoretically and by simulations in the i.i.d. setting that it is an interesting alternative to the usual stochastic gradient descent with averaging or the adaptative stochastic gradient descent.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36731;&#37327;&#32423;&#26041;&#27861;&#26469;&#35843;&#25972;&#32852;&#37030;&#24179;&#22343;&#20013;&#30340;&#32858;&#21512;&#26435;&#37325;&#65292;&#36890;&#36807;&#26681;&#25454;&#27599;&#20010;&#23458;&#25143;&#30340;&#21442;&#19982;&#21382;&#21490;&#26469;&#22788;&#29702;&#20855;&#26377;&#19981;&#21516;&#21442;&#19982;&#29575;&#30340;&#23458;&#25143;&#65292;&#35299;&#20915;&#20102;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#26410;&#30693;&#21442;&#19982;&#27010;&#29575;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.03401</link><description>&lt;p&gt;
&#22788;&#29702;&#32852;&#37030;&#24179;&#22343;&#20013;&#26410;&#30693;&#21442;&#19982;&#27010;&#29575;&#30340;&#36731;&#37327;&#32423;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Lightweight Method for Tackling Unknown Participation Probabilities in Federated Averaging. (arXiv:2306.03401v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03401
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36731;&#37327;&#32423;&#26041;&#27861;&#26469;&#35843;&#25972;&#32852;&#37030;&#24179;&#22343;&#20013;&#30340;&#32858;&#21512;&#26435;&#37325;&#65292;&#36890;&#36807;&#26681;&#25454;&#27599;&#20010;&#23458;&#25143;&#30340;&#21442;&#19982;&#21382;&#21490;&#26469;&#22788;&#29702;&#20855;&#26377;&#19981;&#21516;&#21442;&#19982;&#29575;&#30340;&#23458;&#25143;&#65292;&#35299;&#20915;&#20102;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#26410;&#30693;&#21442;&#19982;&#27010;&#29575;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#65292;&#23458;&#25143;&#31471;&#36890;&#24120;&#20855;&#26377;&#20808;&#39564;&#26410;&#30693;&#30340;&#19981;&#21516;&#21442;&#19982;&#29575;&#65292;&#22914;&#26524;&#19981;&#36866;&#24403;&#22788;&#29702;&#65292;&#21017;&#21487;&#33021;&#20250;&#23545;&#32852;&#37030;&#23398;&#20064;&#30340;&#24615;&#33021;&#36896;&#25104;&#37325;&#22823;&#24433;&#21709;&#12290;&#29616;&#26377;&#30340;&#35299;&#20915;&#26041;&#27861;&#36890;&#24120;&#22522;&#20110;&#20840;&#23616;&#26041;&#24046;&#32553;&#20943;&#65292;&#36825;&#38656;&#35201;&#22823;&#37327;&#39069;&#22806;&#30340;&#20869;&#23384;&#65292;&#20854;&#20056;&#27861;&#22240;&#23376;&#31561;&#20110;&#23458;&#25143;&#24635;&#25968;&#12290;&#19968;&#20010;&#37325;&#35201;&#30340;&#26410;&#35299;&#20915;&#38382;&#39064;&#26159;&#25214;&#21040;&#19968;&#31181;&#36731;&#37327;&#32423;&#26041;&#27861;&#26469;&#22788;&#29702;&#20855;&#22791;&#19981;&#21516;&#21442;&#19982;&#29575;&#23458;&#25143;&#30340;&#32852;&#37030;&#23398;&#20064;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#26681;&#25454;&#27599;&#20010;&#23458;&#25143;&#30340;&#21442;&#19982;&#21382;&#21490;&#26469;&#35843;&#25972;&#32852;&#37030;&#24179;&#22343;&#65288;FedAvg&#65289;&#20013;&#30340;&#32858;&#21512;&#26435;&#37325;&#26469;&#35299;&#20915;&#27492;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#22312;&#20855;&#26377;&#24322;&#26500;&#21442;&#19982;&#27010;&#29575;&#30340;&#24773;&#20917;&#19979;&#65292;&#38750;&#26368;&#20248;&#32858;&#21512;&#26435;&#37325;&#30340;FedAvg&#21487;&#33021;&#20250;&#20174;&#21407;&#22987;FL&#30446;&#26631;&#30340;&#26368;&#20248;&#35299;&#20559;&#31163;&#65292;&#36825;&#34920;&#26126;&#38656;&#35201;&#25214;&#21040;&#26368;&#20248;&#32858;&#21512;&#26435;&#37325;&#12290;&#28982;&#32780;&#65292;&#24403;&#21442;&#19982;&#27010;&#29575;&#19981;&#21487;&#30693;&#26102;&#35745;&#31639;&#26368;&#20248;&#26435;&#37325;&#38750;&#24120;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;
In federated learning (FL), clients usually have diverse participation probabilities that are unknown a priori, which can significantly harm the performance of FL if not handled properly. Existing works aiming at addressing this problem are usually based on global variance reduction, which requires a substantial amount of additional memory in a multiplicative factor equal to the total number of clients. An important open problem is to find a lightweight method for FL in the presence of clients with unknown participation rates. In this paper, we address this problem by adapting the aggregation weights in federated averaging (FedAvg) based on the participation history of each client. We first show that, with heterogeneous participation probabilities, FedAvg with non-optimal aggregation weights can diverge from the optimal solution of the original FL objective, indicating the need of finding optimal aggregation weights. However, it is difficult to compute the optimal weights when the part
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Wasserstein&#36317;&#31163;&#30340;&#25439;&#22833;&#20989;&#25968;hinge-Wasserstein&#65292;&#29992;&#20110;&#32531;&#35299;&#22238;&#24402;&#20219;&#21153;&#20013;&#30001;&#20110;&#36807;&#24230;&#33258;&#20449;&#23548;&#33268;&#30340;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#12290;&#36825;&#31181;&#25439;&#22833;&#20989;&#25968;&#26377;&#25928;&#25552;&#39640;&#20102;aleatoric&#21644;epistemic&#19981;&#30830;&#23450;&#24615;&#30340;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2306.00560</link><description>&lt;p&gt;
Hinge-Wasserstein: &#36890;&#36807;&#20998;&#31867;&#36991;&#20813;&#22238;&#24402;&#20013;&#30340;&#36807;&#24230;&#33258;&#20449;
&lt;/p&gt;
&lt;p&gt;
Hinge-Wasserstein: Mitigating Overconfidence in Regression by Classification. (arXiv:2306.00560v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00560
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Wasserstein&#36317;&#31163;&#30340;&#25439;&#22833;&#20989;&#25968;hinge-Wasserstein&#65292;&#29992;&#20110;&#32531;&#35299;&#22238;&#24402;&#20219;&#21153;&#20013;&#30001;&#20110;&#36807;&#24230;&#33258;&#20449;&#23548;&#33268;&#30340;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#12290;&#36825;&#31181;&#25439;&#22833;&#20989;&#25968;&#26377;&#25928;&#25552;&#39640;&#20102;aleatoric&#21644;epistemic&#19981;&#30830;&#23450;&#24615;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#24615;&#33021;&#26041;&#38754;&#24471;&#21040;&#20102;&#24040;&#22823;&#30340;&#25552;&#39640;&#65292;&#20294;&#23427;&#20204;&#23481;&#26131;&#20135;&#29983;&#36807;&#24230;&#33258;&#20449;&#12290;&#22312;&#27169;&#31946;&#29978;&#33267;&#19981;&#21487;&#39044;&#27979;&#30340;&#29616;&#23454;&#19990;&#30028;&#22330;&#26223;&#20013;&#65292;&#36825;&#31181;&#36807;&#24230;&#33258;&#20449;&#21487;&#33021;&#23545;&#24212;&#29992;&#31243;&#24207;&#30340;&#23433;&#20840;&#24615;&#26500;&#25104;&#37325;&#22823;&#39118;&#38505;&#12290;&#38024;&#23545;&#22238;&#24402;&#20219;&#21153;&#65292;&#37319;&#29992;&#22238;&#24402;-&#20998;&#31867;&#26041;&#27861;&#26377;&#28508;&#21147;&#32531;&#35299;&#36825;&#20123;&#27495;&#20041;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#39044;&#27979;&#25152;&#38656;&#36755;&#20986;&#30340;&#31163;&#25955;&#27010;&#29575;&#23494;&#24230;&#12290;&#28982;&#32780;&#65292;&#23494;&#24230;&#20272;&#35745;&#20173;&#28982;&#20542;&#21521;&#20110;&#36807;&#24230;&#33258;&#20449;&#65292;&#23588;&#20854;&#26159;&#22312;&#20351;&#29992;&#24120;&#35265;&#30340;NLL&#25439;&#22833;&#20989;&#25968;&#35757;&#32451;&#26102;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#31181;&#36807;&#24230;&#33258;&#20449;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Wasserstein&#36317;&#31163;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;hinge-Wasserstein&#12290;&#19982;&#20197;&#21069;&#30340;&#24037;&#20316;&#30456;&#27604;&#65292;&#27492;&#25439;&#22833;&#26174;&#30528;&#25552;&#39640;&#20102;&#20004;&#31181;&#19981;&#30830;&#23450;&#24615;&#30340;&#36136;&#37327;&#65306; aleatoric&#19981;&#30830;&#23450;&#24615;&#21644;epistemic&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#26032;&#25439;&#22833;&#30340;&#33021;&#21147;&#65292;&#20854;&#20013;&#20004;&#31181;&#31867;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#21487;&#20197;&#20998;&#21035;&#25511;&#21046;&#12290;&#27492;&#22806;&#65292;&#20316;&#20026;&#29616;&#23454;&#19990;&#30028;&#22330;&#26223;&#30340;&#28436;&#31034;&#65292;&#25105;&#20204;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern deep neural networks are prone to being overconfident despite their drastically improved performance. In ambiguous or even unpredictable real-world scenarios, this overconfidence can pose a major risk to the safety of applications. For regression tasks, the regression-by-classification approach has the potential to alleviate these ambiguities by instead predicting a discrete probability density over the desired output. However, a density estimator still tends to be overconfident when trained with the common NLL loss. To mitigate the overconfidence problem, we propose a loss function, hinge-Wasserstein, based on the Wasserstein Distance. This loss significantly improves the quality of both aleatoric and epistemic uncertainty, compared to previous work. We demonstrate the capabilities of the new loss on a synthetic dataset, where both types of uncertainty are controlled separately. Moreover, as a demonstration for real-world scenarios, we evaluate our approach on the benchmark dat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19982;NMF&#31639;&#27861;&#19968;&#26679;&#31616;&#21333;&#19988;&#21487;&#25193;&#23637;&#30340;K&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#35299;&#20915;&#38750;&#36127;&#20302;&#31209;&#21322;&#23450;&#35268;&#21010;&#38382;&#39064;&#33719;&#24471;&#20102;&#24378;&#22823;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#20445;&#35777;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#31639;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2305.18436</link><description>&lt;p&gt;
&#36890;&#36807;&#38750;&#36127;&#20302;&#31209;&#21322;&#23450;&#35268;&#21010;&#23454;&#29616;&#26368;&#20248;K&#22343;&#20540;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Statistically Optimal K-means Clustering via Nonnegative Low-rank Semidefinite Programming. (arXiv:2305.18436v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18436
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19982;NMF&#31639;&#27861;&#19968;&#26679;&#31616;&#21333;&#19988;&#21487;&#25193;&#23637;&#30340;K&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#35299;&#20915;&#38750;&#36127;&#20302;&#31209;&#21322;&#23450;&#35268;&#21010;&#38382;&#39064;&#33719;&#24471;&#20102;&#24378;&#22823;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#20445;&#35777;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#31639;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
K&#22343;&#20540;&#32858;&#31867;&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#20110;&#22823;&#25968;&#25454;&#38598;&#20013;&#21457;&#29616;&#27169;&#24335;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#12290;&#21322;&#23450;&#35268;&#21010;&#65288;SDP&#65289;&#26494;&#24347;&#26368;&#36817;&#34987;&#25552;&#20986;&#29992;&#20110;&#35299;&#20915;K&#22343;&#20540;&#20248;&#21270;&#38382;&#39064;&#65292;&#20855;&#26377;&#24456;&#24378;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#20445;&#35777;&#12290;&#20294;&#23454;&#29616;SDP&#27714;&#35299;&#22120;&#30340;&#24040;&#22823;&#25104;&#26412;&#20351;&#24471;&#36825;&#20123;&#20445;&#35777;&#26080;&#27861;&#24212;&#29992;&#20110;&#23454;&#38469;&#25968;&#25454;&#38598;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#65288;NMF&#65289;&#26159;&#19968;&#31181;&#31616;&#21333;&#30340;&#32858;&#31867;&#31639;&#27861;&#65292;&#34987;&#26426;&#22120;&#23398;&#20064;&#20174;&#19994;&#32773;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#32570;&#20047;&#22362;&#23454;&#30340;&#32479;&#35745;&#22522;&#30784;&#25110;&#20005;&#26684;&#30340;&#20445;&#35777;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#31181;&#31867;&#20284;&#20110;NMF&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#38750;&#20984;Burer-Monteiro&#20998;&#35299;&#26041;&#27861;&#35299;&#20915;&#21322;&#23450;&#35268;&#21010;&#26494;&#24347;&#30340;K&#22343;&#20540;&#20844;&#24335;&#30340;&#38750;&#36127;&#20302;&#31209;&#38480;&#21046;&#12290;&#25152;&#24471;&#21040;&#30340;&#31639;&#27861;&#19982;&#26368;&#20808;&#36827;&#30340;NMF&#31639;&#27861;&#19968;&#26679;&#31616;&#21333;&#21644;&#21487;&#25193;&#23637;&#65292;&#21516;&#26102;&#20063;&#20139;&#26377;&#19982;SDP&#30456;&#21516;&#30340;&#24378;&#22823;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#20445;&#35777;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;NMF&#31639;&#27861;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#19982;&#26368;&#20808;&#36827;&#30340;SDP&#27714;&#35299;&#22120;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
$K$-means clustering is a widely used machine learning method for identifying patterns in large datasets. Semidefinite programming (SDP) relaxations have recently been proposed for solving the $K$-means optimization problem that enjoy strong statistical optimality guarantees, but the prohibitive cost of implementing an SDP solver renders these guarantees inaccessible to practical datasets. By contrast, nonnegative matrix factorization (NMF) is a simple clustering algorithm that is widely used by machine learning practitioners, but without a solid statistical underpinning nor rigorous guarantees. In this paper, we describe an NMF-like algorithm that works by solving a nonnegative low-rank restriction of the SDP relaxed $K$-means formulation using a nonconvex Burer--Monteiro factorization approach. The resulting algorithm is just as simple and scalable as state-of-the-art NMF algorithms, while also enjoying the same strong statistical optimality guarantees as the SDP. In our experiments,
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;Transformer&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23454;&#29616;&#31526;&#21495;&#28040;&#24687;&#20256;&#36882;&#21644;&#20851;&#31995;&#25512;&#29702;&#65292;&#24182;&#36890;&#36807;&#20851;&#31995;&#20132;&#21449;&#27880;&#24847;&#21147;&#26426;&#21046;&#23454;&#29616;&#24863;&#24615;&#29366;&#24577;&#19982;&#25277;&#35937;&#29366;&#24577;&#20043;&#38388;&#30340;&#32465;&#23450;&#12290;</title><link>http://arxiv.org/abs/2304.00195</link><description>&lt;p&gt;
&#25277;&#35937;&#22120;&#65306;&#22522;&#20110;Transformer&#30340;&#31526;&#21495;&#28040;&#24687;&#20256;&#36882;&#21644;&#20851;&#31995;&#25512;&#29702;&#27169;&#22359;
&lt;/p&gt;
&lt;p&gt;
Abstractors: Transformer Modules for Symbolic Message Passing and Relational Reasoning. (arXiv:2304.00195v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00195
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;Transformer&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23454;&#29616;&#31526;&#21495;&#28040;&#24687;&#20256;&#36882;&#21644;&#20851;&#31995;&#25512;&#29702;&#65292;&#24182;&#36890;&#36807;&#20851;&#31995;&#20132;&#21449;&#27880;&#24847;&#21147;&#26426;&#21046;&#23454;&#29616;&#24863;&#24615;&#29366;&#24577;&#19982;&#25277;&#35937;&#29366;&#24577;&#20043;&#38388;&#30340;&#32465;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#23558;&#20851;&#31995;&#23398;&#20064;&#36716;&#21270;&#20026;Transformer&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#20851;&#31995;&#20132;&#21449;&#27880;&#24847;&#21147;&#26426;&#21046;&#23454;&#29616;&#24863;&#24615;&#29366;&#24577;&#19982;&#25277;&#35937;&#29366;&#24577;&#20043;&#38388;&#30340;&#32465;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
A framework is proposed that casts relational learning in terms of transformers, implementing binding between sensory states and abstract states with relational cross attention mechanisms.
&lt;/p&gt;</description></item><item><title>&#26412;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#31561;&#24335;&#32422;&#26463;&#30340;&#38543;&#26426;&#38750;&#32447;&#24615;&#20248;&#21270;&#38382;&#39064;&#30340;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#22522;&#20110;&#33609;&#22270;&#30340;&#39034;&#24207;&#20108;&#27425;&#35268;&#21010;&#65288;StoSQP&#65289;&#36827;&#34892;&#27714;&#35299;&#65292;&#24182;&#19988;&#20801;&#35768;&#33258;&#36866;&#24212;&#36873;&#25321;&#38543;&#26426;&#27493;&#38271;&#21644;&#20351;&#29992;&#39640;&#25928;&#38543;&#26426;&#36845;&#20195;&#27714;&#35299;&#22120;&#26469;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2205.13687</link><description>&lt;p&gt;
&#36890;&#36807;&#22522;&#20110;&#33609;&#22270;&#30340;&#39034;&#24207;&#20108;&#27425;&#35268;&#21010;&#23545;&#32422;&#26463;&#30340;&#38543;&#26426;&#20248;&#21270;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Statistical Inference of Constrained Stochastic Optimization via Sketched Sequential Quadratic Programming. (arXiv:2205.13687v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.13687
&lt;/p&gt;
&lt;p&gt;
&#26412;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#31561;&#24335;&#32422;&#26463;&#30340;&#38543;&#26426;&#38750;&#32447;&#24615;&#20248;&#21270;&#38382;&#39064;&#30340;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#22522;&#20110;&#33609;&#22270;&#30340;&#39034;&#24207;&#20108;&#27425;&#35268;&#21010;&#65288;StoSQP&#65289;&#36827;&#34892;&#27714;&#35299;&#65292;&#24182;&#19988;&#20801;&#35768;&#33258;&#36866;&#24212;&#36873;&#25321;&#38543;&#26426;&#27493;&#38271;&#21644;&#20351;&#29992;&#39640;&#25928;&#38543;&#26426;&#36845;&#20195;&#27714;&#35299;&#22120;&#26469;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#23545;&#31561;&#24335;&#32422;&#26463;&#30340;&#38543;&#26426;&#38750;&#32447;&#24615;&#20248;&#21270;&#38382;&#39064;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#20840;&#22312;&#32447;&#38543;&#26426;&#39034;&#24207;&#20108;&#27425;&#35268;&#21010;&#65288;StoSQP&#65289;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#21487;&#20197;&#23558;&#20854;&#35270;&#20026;&#23558;&#29275;&#39039;&#27861;&#24212;&#29992;&#20110;&#19968;&#38454;&#26368;&#20248;&#24615;&#26465;&#20214;&#65288;&#21363;KKT&#26465;&#20214;&#65289;&#12290;&#21463;&#26368;&#36817;&#25968;&#20540;&#20108;&#38454;&#26041;&#27861;&#35774;&#35745;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#20801;&#35768;StoSQP&#33258;&#36866;&#24212;&#22320;&#36873;&#25321;&#20219;&#24847;&#38543;&#26426;&#27493;&#38271;$ \bar {\ alpha} _t $&#65292;&#21482;&#35201;$ \ beta _t \ leq \ bar {\ alpha} _t \ leq \ beta _t + \ chi _t $&#65292;&#20854;&#20013; $ \ beta_t $ &#21644; $ \ chi_t = o(\beta_t) $ &#26159;&#26576;&#20123;&#25511;&#21046;&#24207;&#21015;&#12290;&#20026;&#20102;&#38477;&#20302;&#20108;&#38454;&#26041;&#27861;&#30340;&#20027;&#35201;&#35745;&#31639;&#25104;&#26412;&#65292;&#25105;&#20204;&#36824;&#20801;&#35768;StoSQP&#36890;&#36807;&#20351;&#29992;&#33609;&#22270;&#25216;&#26415;&#30340;&#39640;&#25928;&#38543;&#26426;&#36845;&#20195;&#27714;&#35299;&#22120;&#26469;&#19981;&#31934;&#30830;&#22320;&#35299;&#20915;&#20108;&#27425;&#35268;&#21010;&#38382;&#39064;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#19981;&#35201;&#27714;&#36924;&#36817;&#35823;&#24046;&#38543;&#30528;&#36845;&#20195;&#30340;&#36827;&#34892;&#32780;&#20943;&#23567;&#12290;&#23545;&#20110;&#24320;&#21457;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#65288;i&#65289;&#19979;&#65292;&#23427;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#26368;&#22810;&#20026;$ O(1 / \ ep&#65289;$&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider statistical inference of equality-constrained stochastic nonlinear optimization problems. We develop a fully online stochastic sequential quadratic programming (StoSQP) method to solve the problems, which can be regarded as applying Newton's method to the first-order optimality conditions (i.e., the KKT conditions). Motivated by recent designs of numerical second-order methods, we allow StoSQP to adaptively select any random stepsize $\bar{\alpha}_t$, as long as $\beta_t\leq \bar{\alpha}_t \leq \beta_t+\chi_t$, for some control sequences $\beta_t$ and $\chi_t=o(\beta_t)$. To reduce the dominant computational cost of second-order methods, we additionally allow StoSQP to inexactly solve quadratic programs via efficient randomized iterative solvers that utilize sketching techniques. Notably, we do not require the approximation error to diminish as iteration proceeds. For the developed method, we show that under mild assumptions (i) computationally, it can take at most $O(1/\ep
&lt;/p&gt;</description></item><item><title>&#36873;&#25321;&#21512;&#36866;&#30340;&#20803;&#23398;&#20064;&#22120;&#23545;&#20110;&#22810;&#35270;&#35282;&#22534;&#21472;&#20013;&#30340;&#35270;&#22270;&#36873;&#25321;&#21644;&#20998;&#31867;&#20934;&#30830;&#24615;&#26159;&#38750;&#24120;&#37325;&#35201;&#30340;&#65292;&#36890;&#36807;&#23545;&#19971;&#31181;&#19981;&#21516;&#30340;&#31639;&#27861;&#36827;&#34892;&#35780;&#20272;&#65292;&#38750;&#36127;&#22871;&#32034;&#12289;&#38750;&#36127;&#33258;&#36866;&#24212;&#22871;&#32034;&#21644;&#38750;&#36127;&#24377;&#24615;&#32593;&#32476;&#34987;&#35748;&#20026;&#26159;&#26368;&#21512;&#36866;&#30340;&#20803;&#23398;&#20064;&#22120;&#12290;</title><link>http://arxiv.org/abs/2010.16271</link><description>&lt;p&gt;
&#22810;&#35270;&#35282;&#22534;&#21472;&#20013;&#30340;&#35270;&#22270;&#36873;&#25321;&#65306;&#36873;&#25321;&#20803;&#23398;&#20064;&#22120;
&lt;/p&gt;
&lt;p&gt;
View selection in multi-view stacking: Choosing the meta-learner. (arXiv:2010.16271v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2010.16271
&lt;/p&gt;
&lt;p&gt;
&#36873;&#25321;&#21512;&#36866;&#30340;&#20803;&#23398;&#20064;&#22120;&#23545;&#20110;&#22810;&#35270;&#35282;&#22534;&#21472;&#20013;&#30340;&#35270;&#22270;&#36873;&#25321;&#21644;&#20998;&#31867;&#20934;&#30830;&#24615;&#26159;&#38750;&#24120;&#37325;&#35201;&#30340;&#65292;&#36890;&#36807;&#23545;&#19971;&#31181;&#19981;&#21516;&#30340;&#31639;&#27861;&#36827;&#34892;&#35780;&#20272;&#65292;&#38750;&#36127;&#22871;&#32034;&#12289;&#38750;&#36127;&#33258;&#36866;&#24212;&#22871;&#32034;&#21644;&#38750;&#36127;&#24377;&#24615;&#32593;&#32476;&#34987;&#35748;&#20026;&#26159;&#26368;&#21512;&#36866;&#30340;&#20803;&#23398;&#20064;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#35270;&#35282;&#22534;&#21472;&#26159;&#19968;&#31181;&#23558;&#26469;&#33258;&#19981;&#21516;&#35270;&#22270;&#65288;&#21363;&#19981;&#21516;&#30340;&#29305;&#24449;&#38598;&#65289;&#25551;&#36848;&#30456;&#21516;&#23545;&#35937;&#30340;&#20449;&#24687;&#30456;&#32467;&#21512;&#30340;&#26694;&#26550;&#12290;&#22312;&#35813;&#26694;&#26550;&#20013;&#65292;&#22522;&#23398;&#20064;&#31639;&#27861;&#20998;&#21035;&#22312;&#27599;&#20010;&#35270;&#22270;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#23427;&#20204;&#30340;&#39044;&#27979;&#32467;&#26524;&#30001;&#20803;&#23398;&#20064;&#31639;&#27861;&#32452;&#21512;&#12290;&#22312;&#20043;&#21069;&#30340;&#30740;&#31350;&#20013;&#65292;&#22534;&#21472;&#30340;&#32602;&#20998;&#36923;&#36753;&#22238;&#24402;&#65292;&#20316;&#20026;&#22810;&#35270;&#35282;&#22534;&#21472;&#30340;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#65292;&#24050;&#34987;&#35777;&#26126;&#22312;&#35782;&#21035;&#23545;&#39044;&#27979;&#26368;&#37325;&#35201;&#30340;&#35270;&#22270;&#26041;&#38754;&#26159;&#26377;&#29992;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#32771;&#34385;&#19971;&#31181;&#19981;&#21516;&#30340;&#31639;&#27861;&#20316;&#20026;&#20803;&#23398;&#20064;&#22120;&#65292;&#24182;&#22312;&#27169;&#25311;&#21644;&#20004;&#20010;&#30495;&#23454;&#30340;&#22522;&#22240;&#34920;&#36798;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#23427;&#20204;&#30340;&#35270;&#22270;&#36873;&#25321;&#21644;&#20998;&#31867;&#24615;&#33021;&#65292;&#25193;&#23637;&#20102;&#36825;&#39033;&#30740;&#31350;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22914;&#26524;&#35270;&#22270;&#36873;&#25321;&#21644;&#20998;&#31867;&#20934;&#30830;&#24615;&#23545;&#30740;&#31350;&#37117;&#24456;&#37325;&#35201;&#65292;&#37027;&#20040;&#38750;&#36127;&#22871;&#32034;&#12289;&#38750;&#36127;&#33258;&#36866;&#24212;&#22871;&#32034;&#21644;&#38750;&#36127;&#24377;&#24615;&#32593;&#32476;&#37117;&#26159;&#21512;&#36866;&#30340;&#20803;&#23398;&#20064;&#22120;&#12290;&#20855;&#20307;&#22312;&#36825;&#19977;&#31181;&#26041;&#27861;&#20013;&#35813;&#36873;&#25321;&#21738;&#19968;&#31181;&#21462;&#20915;&#20110;...
&lt;/p&gt;
&lt;p&gt;
Multi-view stacking is a framework for combining information from different views (i.e. different feature sets) describing the same set of objects. In this framework, a base-learner algorithm is trained on each view separately, and their predictions are then combined by a meta-learner algorithm. In a previous study, stacked penalized logistic regression, a special case of multi-view stacking, has been shown to be useful in identifying which views are most important for prediction. In this article we expand this research by considering seven different algorithms to use as the meta-learner, and evaluating their view selection and classification performance in simulations and two applications on real gene-expression data sets. Our results suggest that if both view selection and classification accuracy are important to the research at hand, then the nonnegative lasso, nonnegative adaptive lasso and nonnegative elastic net are suitable meta-learners. Exactly which among these three is to be
&lt;/p&gt;</description></item></channel></rss>