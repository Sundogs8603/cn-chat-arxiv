<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#21516;&#36136;&#31181;&#32676;&#30340;&#38543;&#26426;&#23454;&#39564;&#20013;&#36873;&#25321;&#26368;&#20248;&#30340;&#20195;&#29702;&#25351;&#26631;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#23558;&#26368;&#20248;&#20195;&#29702;&#25351;&#26631;&#30340;&#26500;&#24314;&#36827;&#34892;&#20102;&#24402;&#32422;&#65292;&#24182;&#23545;&#35266;&#23519;&#21040;&#30340;&#27835;&#30103;&#25928;&#26524;&#36827;&#34892;&#20102;&#38477;&#22122;&#22788;&#29702;&#12290;</title><link>http://arxiv.org/abs/2309.07893</link><description>&lt;p&gt;
&#20174;&#36807;&#21435;&#30340;&#23454;&#39564;&#20013;&#36873;&#25321;&#20195;&#29702;&#25351;&#26631;
&lt;/p&gt;
&lt;p&gt;
Choosing a Proxy Metric from Past Experiments. (arXiv:2309.07893v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07893
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#21516;&#36136;&#31181;&#32676;&#30340;&#38543;&#26426;&#23454;&#39564;&#20013;&#36873;&#25321;&#26368;&#20248;&#30340;&#20195;&#29702;&#25351;&#26631;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#23558;&#26368;&#20248;&#20195;&#29702;&#25351;&#26631;&#30340;&#26500;&#24314;&#36827;&#34892;&#20102;&#24402;&#32422;&#65292;&#24182;&#23545;&#35266;&#23519;&#21040;&#30340;&#27835;&#30103;&#25928;&#26524;&#36827;&#34892;&#20102;&#38477;&#22122;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#38543;&#26426;&#23454;&#39564;&#20013;&#65292;&#24448;&#24448;&#24456;&#38590;&#25110;&#19981;&#21487;&#34892;&#22320;&#27979;&#37327;&#38271;&#26399;&#25351;&#26631;&#65288;&#21363;&#24863;&#20852;&#36259;&#30340;&#20027;&#35201;&#32467;&#26524;&#65289;&#12290;&#36825;&#20123;&#38271;&#26399;&#25351;&#26631;&#24448;&#24448;&#21453;&#24212;&#21464;&#21270;&#36739;&#24930;&#65292;&#19988;&#22122;&#22768;&#36739;&#22823;&#65292;&#20351;&#24471;&#22312;&#30701;&#26399;&#23454;&#39564;&#20013;&#38590;&#20197;&#20934;&#30830;&#20272;&#35745;&#12290;&#19968;&#31181;&#24120;&#35265;&#30340;&#26367;&#20195;&#26041;&#27861;&#26159;&#27979;&#37327;&#20960;&#20010;&#30701;&#26399;&#20195;&#29702;&#25351;&#26631;&#65292;&#24076;&#26395;&#23427;&#20204;&#33021;&#22815;&#32039;&#23494;&#36861;&#36394;&#38271;&#26399;&#25351;&#26631;&#65292;&#20174;&#32780;&#22312;&#36817;&#26399;&#26377;&#25928;&#22320;&#25351;&#23548;&#20915;&#31574;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#32479;&#35745;&#26694;&#26550;&#65292;&#29992;&#20110;&#23450;&#20041;&#21644;&#26500;&#24314;&#19968;&#20010;&#36866;&#29992;&#20110;&#21516;&#36136;&#31181;&#32676;&#38543;&#26426;&#23454;&#39564;&#30340;&#26368;&#20248;&#20195;&#29702;&#25351;&#26631;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#39318;&#20808;&#23558;&#32473;&#23450;&#23454;&#39564;&#20013;&#26368;&#20248;&#20195;&#29702;&#25351;&#26631;&#30340;&#26500;&#24314;&#24402;&#32422;&#20026;&#19968;&#20010;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#21462;&#20915;&#20110;&#32771;&#34385;&#20013;&#23454;&#39564;&#30340;&#30495;&#23454;&#28508;&#22312;&#27835;&#30103;&#25928;&#26524;&#21644;&#22122;&#22768;&#27700;&#24179;&#12290;&#28982;&#21518;&#25105;&#20204;&#23545;&#38271;&#26399;&#25351;&#26631;&#21644;&#19968;&#32452;&#20195;&#29702;&#30340;&#35266;&#23519;&#21040;&#30340;&#27835;&#30103;&#25928;&#26524;&#36827;&#34892;&#38477;&#22122;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many randomized experiments, the treatment effect of the long-term metric (i.e. the primary outcome of interest) is often difficult or infeasible to measure. Such long-term metrics are often slow to react to changes and sufficiently noisy they are challenging to faithfully estimate in short-horizon experiments. A common alternative is to measure several short-term proxy metrics in the hope they closely track the long-term metric -- so they can be used to effectively guide decision-making in the near-term. We introduce a new statistical framework to both define and construct an optimal proxy metric for use in a homogeneous population of randomized experiments. Our procedure first reduces the construction of an optimal proxy metric in a given experiment to a portfolio optimization problem which depends on the true latent treatment effects and noise level of experiment under consideration. We then denoise the observed treatment effects of the long-term metric and a set of proxies in a 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#39640;&#26031;&#36807;&#31243;&#32858;&#31867;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#32858;&#31867;&#20219;&#21153;&#20013;&#24341;&#20837;Vecchia&#36924;&#36817;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#20851;&#38190;&#30340;&#29702;&#35770;&#25903;&#25345;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;EM&#31639;&#27861;&#65292;&#36890;&#36807;&#27169;&#25311;&#21644;&#20998;&#26512;&#39564;&#35777;&#20102;&#20854;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.07882</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#39640;&#26031;&#36807;&#31243;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Scalable Model-Based Gaussian Process Clustering. (arXiv:2309.07882v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07882
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#39640;&#26031;&#36807;&#31243;&#32858;&#31867;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#32858;&#31867;&#20219;&#21153;&#20013;&#24341;&#20837;Vecchia&#36924;&#36817;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#20851;&#38190;&#30340;&#29702;&#35770;&#25903;&#25345;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;EM&#31639;&#27861;&#65292;&#36890;&#36807;&#27169;&#25311;&#21644;&#20998;&#26512;&#39564;&#35777;&#20102;&#20854;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#22312;&#32858;&#31867;&#21151;&#33021;&#25968;&#25454;&#20013;&#26159;&#19981;&#21487;&#25110;&#32570;&#30340;&#24037;&#20855;&#65292;&#22240;&#20854;&#28789;&#27963;&#24615;&#21644;&#20869;&#22312;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#28982;&#32780;&#65292;&#24403;&#21151;&#33021;&#25968;&#25454;&#22312;&#19968;&#20010;&#22823;&#30340;&#32593;&#26684;&#19978;&#35266;&#27979;&#21040;&#26102;&#65288;&#27604;&#22914;&#38271;&#24230;&#20026;p&#65289;&#65292;&#39640;&#26031;&#36807;&#31243;&#32858;&#31867;&#24456;&#24555;&#21464;&#24471;&#19981;&#21487;&#34892;&#65292;&#27599;&#27425;&#36845;&#20195;&#30340;&#31354;&#38388;&#22797;&#26434;&#24230;&#20026;O&#65288;p^2&#65289;&#21644;&#26102;&#38388;&#22797;&#26434;&#24230;&#20026;O(p^3)&#65307;&#22240;&#27492;&#65292;&#38459;&#30861;&#20102;&#20854;&#22312;&#22823;&#22411;&#29615;&#22659;&#24212;&#29992;&#20013;&#30340;&#33258;&#28982;&#36866;&#24212;&#24615;&#12290;&#20026;&#20102;&#30830;&#20445;&#22312;&#36825;&#20123;&#24212;&#29992;&#20013;&#39640;&#26031;&#36807;&#31243;&#32858;&#31867;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#23558;&#24191;&#27867;&#37319;&#29992;&#30340;Vecchia&#36924;&#36817;&#26041;&#27861;&#23884;&#20837;&#21040;&#32858;&#31867;&#20219;&#21153;&#30340;&#26680;&#24515;&#65292;&#25552;&#20379;&#23545;&#31639;&#27861;&#35774;&#35745;&#30340;&#20851;&#38190;&#29702;&#35770;&#27934;&#35265;&#65292;&#26368;&#32456;&#24320;&#21457;&#20986;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#26399;&#26395;&#26368;&#22823;&#21270;&#65288;EM&#65289;&#31639;&#27861;&#12290;&#36890;&#36807;&#27169;&#25311;&#21644;&#26497;&#22320;&#28201;&#24230;&#24322;&#24120;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#25105;&#20204;&#30340;&#25552;&#26696;&#30340;&#23454;&#35777;&#35777;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian process is an indispensable tool in clustering functional data, owing to it's flexibility and inherent uncertainty quantification. However, when the functional data is observed over a large grid (say, of length $p$), Gaussian process clustering quickly renders itself infeasible, incurring $O(p^2)$ space complexity and $O(p^3)$ time complexity per iteration; and thus prohibiting it's natural adaptation to large environmental applications. To ensure scalability of Gaussian process clustering in such applications, we propose to embed the popular Vecchia approximation for Gaussian processes at the heart of the clustering task, provide crucial theoretical insights towards algorithmic design, and finally develop a computationally efficient expectation maximization (EM) algorithm. Empirical evidence of the utility of our proposal is provided via simulations and analysis of polar temperature anomaly (\href{https://www.ncei.noaa.gov/access/monitoring/climate-at-a-glance/global/time-ser
&lt;/p&gt;</description></item><item><title>beta&#25193;&#25955;&#26159;&#19968;&#31181;&#26032;&#22411;&#29983;&#25104;&#27169;&#22411;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#21435;&#25513;&#30422;&#21644;&#21435;&#22122;&#30340;&#25216;&#26415;&#65292;&#21033;&#29992;&#32553;&#25918;&#21644;&#20559;&#31227;&#30340;beta&#20998;&#24067;&#36827;&#34892;&#20056;&#27861;&#36716;&#25442;&#65292;&#23454;&#29616;&#22312;&#26377;&#30028;&#33539;&#22260;&#20869;&#29983;&#25104;&#25968;&#25454;&#12290;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;KL&#25955;&#24230;&#19978;&#30028;&#36827;&#34892;&#20248;&#21270;&#65292;&#35777;&#26126;&#20102;&#25928;&#26524;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2309.07867</link><description>&lt;p&gt;
Beta Diffusion. (arXiv:2309.07867v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
Beta Diffusion. (arXiv:2309.07867v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07867
&lt;/p&gt;
&lt;p&gt;
beta&#25193;&#25955;&#26159;&#19968;&#31181;&#26032;&#22411;&#29983;&#25104;&#27169;&#22411;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#21435;&#25513;&#30422;&#21644;&#21435;&#22122;&#30340;&#25216;&#26415;&#65292;&#21033;&#29992;&#32553;&#25918;&#21644;&#20559;&#31227;&#30340;beta&#20998;&#24067;&#36827;&#34892;&#20056;&#27861;&#36716;&#25442;&#65292;&#23454;&#29616;&#22312;&#26377;&#30028;&#33539;&#22260;&#20869;&#29983;&#25104;&#25968;&#25454;&#12290;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;KL&#25955;&#24230;&#19978;&#30028;&#36827;&#34892;&#20248;&#21270;&#65292;&#35777;&#26126;&#20102;&#25928;&#26524;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;beta&#25193;&#25955;&#65292;&#19968;&#31181;&#23558;&#21435;&#25513;&#30422;&#21644;&#21435;&#22122;&#38598;&#25104;&#21040;&#19968;&#36215;&#30340;&#26032;&#22411;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#26377;&#30028;&#33539;&#22260;&#20869;&#29983;&#25104;&#25968;&#25454;&#12290;&#20351;&#29992;&#20102;&#32553;&#25918;&#21644;&#20559;&#31227;&#30340;beta&#20998;&#24067;&#65292;beta&#25193;&#25955;&#21033;&#29992;&#20102;&#38543;&#26102;&#38388;&#30340;&#20056;&#27861;&#36716;&#25442;&#26469;&#21019;&#24314;&#27491;&#21521;&#21644;&#21453;&#21521;&#30340;&#25193;&#25955;&#36807;&#31243;&#65292;&#21516;&#26102;&#32500;&#25345;&#30528;&#27491;&#21521;&#36793;&#32536;&#20998;&#24067;&#21644;&#21453;&#21521;&#26465;&#20214;&#20998;&#24067;&#65292;&#32473;&#23450;&#20219;&#24847;&#26102;&#38388;&#28857;&#30340;&#25968;&#25454;&#12290;&#19982;&#20256;&#32479;&#30340;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#19981;&#21516;&#65292;&#20256;&#32479;&#27169;&#22411;&#20381;&#36182;&#20110;&#21152;&#24615;&#39640;&#26031;&#22122;&#22768;&#21644;&#37325;&#26032;&#21152;&#26435;&#30340;&#35777;&#25454;&#19979;&#30028;&#65288;ELBO&#65289;&#65292;beta&#25193;&#25955;&#26159;&#20056;&#27861;&#30340;&#65292;&#24182;&#19988;&#36890;&#36807;&#20174;KL&#25955;&#24230;&#30340;&#20984;&#24615;&#25512;&#23548;&#20986;&#26469;&#30340;KL&#25955;&#24230;&#19978;&#30028;&#65288;KLUB&#65289;&#36827;&#34892;&#20248;&#21270;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;KLUB&#30456;&#23545;&#20110;&#36127;ELBO&#26469;&#35828;&#23545;&#20110;&#20248;&#21270;beta&#25193;&#25955;&#26356;&#21152;&#26377;&#25928;&#65292;&#36127;ELBO&#20063;&#21487;&#20197;&#20316;&#20026;&#30456;&#21516;KL&#25955;&#24230;&#30340;KLUB&#65292;&#21482;&#26159;&#20854;&#20004;&#20010;&#21442;&#25968;&#20132;&#25442;&#20102;&#20301;&#32622;&#12290;beta&#25193;&#25955;&#30340;&#25439;&#22833;&#20989;&#25968;&#20197;Bregman&#25955;&#24230;&#20026;&#25351;&#26631;&#26469;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce beta diffusion, a novel generative modeling method that integrates demasking and denoising to generate data within bounded ranges. Using scaled and shifted beta distributions, beta diffusion utilizes multiplicative transitions over time to create both forward and reverse diffusion processes, maintaining beta distributions in both the forward marginals and the reverse conditionals, given the data at any point in time. Unlike traditional diffusion-based generative models relying on additive Gaussian noise and reweighted evidence lower bounds (ELBOs), beta diffusion is multiplicative and optimized with KL-divergence upper bounds (KLUBs) derived from the convexity of the KL divergence. We demonstrate that the proposed KLUBs are more effective for optimizing beta diffusion compared to negative ELBOs, which can also be derived as the KLUBs of the same KL divergence with its two arguments swapped. The loss function of beta diffusion, expressed in terms of Bregman divergence, furt
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#26377;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#38480;&#21046;&#38382;&#39064;&#12290;&#30740;&#31350;&#32773;&#20204;&#21457;&#29616;&#65292;&#29616;&#26377;&#26041;&#27861;&#22312;&#22788;&#29702;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#24322;&#36136;&#24615;&#35774;&#35745;&#30697;&#38453;&#21644;&#32570;&#20047;&#21487;&#38752;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20182;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#21033;&#29992;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#36827;&#34892;&#21435;&#20559;&#26657;&#27491;&#12290;</title><link>http://arxiv.org/abs/2309.07810</link><description>&lt;p&gt;
Spectrum-Aware Adjustment: &#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#21450;&#20854;&#22312;&#20027;&#25104;&#20998;&#22238;&#24402;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Spectrum-Aware Adjustment: A New Debiasing Framework with Applications to Principal Components Regression. (arXiv:2309.07810v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07810
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#26377;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#38480;&#21046;&#38382;&#39064;&#12290;&#30740;&#31350;&#32773;&#20204;&#21457;&#29616;&#65292;&#29616;&#26377;&#26041;&#27861;&#22312;&#22788;&#29702;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#24322;&#36136;&#24615;&#35774;&#35745;&#30697;&#38453;&#21644;&#32570;&#20047;&#21487;&#38752;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20182;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#21033;&#29992;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#36827;&#34892;&#21435;&#20559;&#26657;&#27491;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#20195;&#21435;&#20559;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#32422;&#26463;&#38382;&#39064;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#29305;&#24449;&#25968;&#21644;&#26679;&#26412;&#25968;&#37117;&#24456;&#22823;&#19988;&#30456;&#36817;&#30340;&#26222;&#36941;&#24773;&#20917;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#29616;&#20195;&#21435;&#20559;&#25216;&#26415;&#20351;&#29992;&#33258;&#30001;&#24230;&#26657;&#27491;&#26469;&#38500;&#21435;&#27491;&#21017;&#21270;&#20272;&#35745;&#37327;&#30340;&#25910;&#32553;&#20559;&#24046;&#24182;&#36827;&#34892;&#25512;&#26029;&#12290;&#28982;&#32780;&#65292;&#35813;&#26041;&#27861;&#35201;&#27714;&#35266;&#27979;&#26679;&#26412;&#26159;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65292;&#21327;&#21464;&#37327;&#36981;&#24490;&#22343;&#20540;&#20026;&#38646;&#30340;&#39640;&#26031;&#20998;&#24067;&#65292;&#24182;&#19988;&#33021;&#22815;&#33719;&#24471;&#21487;&#38752;&#30340;&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#12290;&#24403;&#65288;i&#65289;&#21327;&#21464;&#37327;&#20855;&#26377;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#37325;&#23614;&#25110;&#38750;&#23545;&#31216;&#20998;&#24067;&#65292;&#65288;ii&#65289;&#35774;&#35745;&#30697;&#38453;&#30340;&#34892;&#21576;&#24322;&#36136;&#24615;&#25110;&#23384;&#22312;&#20381;&#36182;&#24615;&#65292;&#20197;&#21450;&#65288;iii&#65289;&#32570;&#20047;&#21487;&#38752;&#30340;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#65292;&#36825;&#31181;&#26041;&#27861;&#23601;&#20250;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#20854;&#20013;&#21435;&#20559;&#26657;&#27491;&#26159;&#19968;&#27493;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#65288;&#36866;&#24403;&#32553;&#25918;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new debiasing framework for high-dimensional linear regression that bypasses the restrictions on covariate distributions imposed by modern debiasing technology. We study the prevalent setting where the number of features and samples are both large and comparable. In this context, state-of-the-art debiasing technology uses a degrees-of-freedom correction to remove shrinkage bias of regularized estimators and conduct inference. However, this method requires that the observed samples are i.i.d., the covariates follow a mean zero Gaussian distribution, and reliable covariance matrix estimates for observed features are available. This approach struggles when (i) covariates are non-Gaussian with heavy tails or asymmetric distributions, (ii) rows of the design exhibit heterogeneity or dependencies, and (iii) reliable feature covariance estimates are lacking.  To address these, we develop a new strategy where the debiasing correction is a rescaled gradient descent step (suitably
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32771;&#34385;&#20102;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#22312;&#21521;&#37327;&#20540;&#20869;&#26680;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#25910;&#25947;&#24615;&#33021;&#65292;&#35777;&#26126;&#20102;&#22312;RKHS&#33539;&#25968;&#20013;&#30340;&#26399;&#26395;&#24179;&#26041;&#35823;&#24046;&#21487;&#20197;&#34987;&#19968;&#20010;&#29305;&#23450;&#20844;&#24335;&#25152;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2309.07779</link><description>&lt;p&gt;
&#22312;&#21521;&#37327;&#20540;&#20869;&#26680;&#22238;&#24402;&#30340;&#22312;&#32447;&#31639;&#27861;&#30340;&#25910;&#25947;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Convergence analysis of online algorithms for vector-valued kernel regression. (arXiv:2309.07779v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07779
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#22312;&#21521;&#37327;&#20540;&#20869;&#26680;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#25910;&#25947;&#24615;&#33021;&#65292;&#35777;&#26126;&#20102;&#22312;RKHS&#33539;&#25968;&#20013;&#30340;&#26399;&#26395;&#24179;&#26041;&#35823;&#24046;&#21487;&#20197;&#34987;&#19968;&#20010;&#29305;&#23450;&#20844;&#24335;&#25152;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#36866;&#24403;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#20316;&#20026;&#20808;&#39564;&#65292;&#36890;&#36807;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#20174;&#22122;&#22768;&#21521;&#37327;&#20540;&#25968;&#25454;&#20013;&#36924;&#36817;&#22238;&#24402;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#22312;&#22312;&#32447;&#31639;&#27861;&#20013;&#65292;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#26679;&#26412;&#36890;&#36807;&#38543;&#26426;&#36807;&#31243;&#36880;&#20010;&#21487;&#29992;&#65292;&#24182;&#20381;&#27425;&#22788;&#29702;&#20197;&#26500;&#24314;&#23545;&#22238;&#24402;&#20989;&#25968;&#30340;&#36817;&#20284;&#12290;&#25105;&#20204;&#20851;&#27880;&#36825;&#31181;&#22312;&#32447;&#36924;&#36817;&#31639;&#27861;&#30340;&#28176;&#36817;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;RKHS&#33539;&#25968;&#20013;&#30340;&#26399;&#26395;&#24179;&#26041;&#35823;&#24046;&#21487;&#20197;&#34987;$C^2(m+1)^{-s/(2+s)}$&#32465;&#23450;&#65292;&#20854;&#20013;$m$&#20026;&#24403;&#19979;&#22788;&#29702;&#30340;&#25968;&#25454;&#25968;&#37327;&#65292;&#21442;&#25968;$0&lt;s\leq 1$&#34920;&#31034;&#23545;&#22238;&#24402;&#20989;&#25968;&#30340;&#39069;&#22806;&#20809;&#28369;&#24615;&#20551;&#35774;&#65292;&#24120;&#25968;$C$&#21462;&#20915;&#20110;&#36755;&#20837;&#22122;&#22768;&#30340;&#26041;&#24046;&#12289;&#22238;&#24402;&#20989;&#25968;&#30340;&#20809;&#28369;&#24615;&#20197;&#21450;&#31639;&#27861;&#30340;&#20854;&#20182;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of approximating the regression function from noisy vector-valued data by an online learning algorithm using an appropriate reproducing kernel Hilbert space (RKHS) as prior. In an online algorithm, i.i.d. samples become available one by one by a random process and are successively processed to build approximations to the regression function. We are interested in the asymptotic performance of such online approximation algorithms and show that the expected squared error in the RKHS norm can be bounded by $C^2 (m+1)^{-s/(2+s)}$, where $m$ is the current number of processed data, the parameter $0&lt;s\leq 1$ expresses an additional smoothness assumption on the regression function and the constant $C$ depends on the variance of the input noise, the smoothness of the regression function and further parameters of the algorithm.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32771;&#34385;&#22240;&#26524;&#32467;&#26500;&#30340;&#20449;&#24687;&#35770;&#37327;&#65292;&#29992;&#20110;&#35780;&#20272;&#26576;&#20010;&#29305;&#23450;&#32467;&#26524;&#21464;&#37327;&#30340;&#22240;&#26524;&#37325;&#35201;&#24615;&#65292;&#35299;&#20915;&#20102;&#22240;&#26524;&#21487;&#35299;&#37322;&#24615;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2309.07703</link><description>&lt;p&gt;
&#27979;&#37327;&#22240;&#26524;&#25511;&#21046;&#30340;&#22240;&#26524;&#29109;&#21644;&#20449;&#24687;&#22686;&#30410;
&lt;/p&gt;
&lt;p&gt;
Causal Entropy and Information Gain for Measuring Causal Control. (arXiv:2309.07703v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07703
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32771;&#34385;&#22240;&#26524;&#32467;&#26500;&#30340;&#20449;&#24687;&#35770;&#37327;&#65292;&#29992;&#20110;&#35780;&#20272;&#26576;&#20010;&#29305;&#23450;&#32467;&#26524;&#21464;&#37327;&#30340;&#22240;&#26524;&#37325;&#35201;&#24615;&#65292;&#35299;&#20915;&#20102;&#22240;&#26524;&#21487;&#35299;&#37322;&#24615;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#21644;&#26041;&#27861;&#36890;&#24120;&#32570;&#20047;&#22240;&#26524;&#21487;&#35299;&#37322;&#24615;&#12290;&#23613;&#31649;&#35299;&#37322;&#24615;&#26426;&#22120;&#23398;&#20064;&#65288;IML&#65289;&#26041;&#27861;&#21462;&#24471;&#20102;&#36827;&#23637;&#65292;&#20294;&#23427;&#20204;&#32463;&#24120;&#23558;&#37325;&#35201;&#24615;&#36171;&#20104;&#37027;&#20123;&#23545;&#32467;&#26524;&#21464;&#37327;&#27809;&#26377;&#22240;&#26524;&#24433;&#21709;&#30340;&#29305;&#24449;&#12290;&#22312;&#27169;&#22411;&#35757;&#32451;&#20043;&#21069;&#25110;&#20043;&#21518;&#65292;&#36873;&#25321;&#22240;&#26524;&#30456;&#20851;&#30340;&#29305;&#24449;&#23558;&#25552;&#20379;&#19968;&#31181;&#35299;&#20915;&#26041;&#26696;&#12290;&#21033;&#29992;&#20449;&#24687;&#35770;&#37327;&#36827;&#34892;&#29305;&#24449;&#36873;&#25321;&#30340;&#26041;&#27861;&#22312;&#35782;&#21035;&#32479;&#35745;&#30456;&#20851;&#29305;&#24449;&#26041;&#38754;&#38750;&#24120;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#25152;&#22522;&#20110;&#30340;&#20449;&#24687;&#35770;&#37327;&#19981;&#21253;&#21547;&#22240;&#26524;&#20851;&#31995;&#65292;&#22240;&#27492;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#19981;&#36866;&#29992;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#33021;&#22815;&#32771;&#34385;&#31995;&#32479;&#22240;&#26524;&#32467;&#26500;&#30340;&#20449;&#24687;&#35770;&#37327;&#65292;&#21487;&#20197;&#29992;&#20110;&#35780;&#20272;&#26576;&#20010;&#32473;&#23450;&#32467;&#26524;&#21464;&#37327;&#30340;&#22240;&#26524;&#37325;&#35201;&#24615;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22240;&#26524;&#29109;&#21644;&#22240;&#26524;&#20114;&#20449;&#24687;&#30340;&#22240;&#26524;&#29256;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Artificial intelligence models and methods commonly lack causal interpretability. Despite the advancements in interpretable machine learning (IML) methods, they frequently assign importance to features which lack causal influence on the outcome variable. Selecting causally relevant features among those identified as relevant by these methods, or even before model training, would offer a solution. Feature selection methods utilizing information theoretical quantities have been successful in identifying statistically relevant features. However, the information theoretical quantities they are based on do not incorporate causality, rendering them unsuitable for such scenarios. To address this challenge, this article proposes information theoretical quantities that incorporate the causal structure of the system, which can be used to evaluate causal importance of features for some given outcome variable. Specifically, we introduce causal versions of entropy and mutual information, termed cau
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#38382;&#39064;&#65292;&#31216;&#20026;&#22810;&#28304;&#39046;&#22495;&#36866;&#24212;&#36890;&#36807;&#25968;&#25454;&#38598;&#23383;&#20856;&#23398;&#20064;&#36935;&#35265;&#25968;&#25454;&#38598;&#33976;&#39311;&#65288;MSDA-DD&#65289;&#65292;&#36890;&#36807;&#36866;&#24212;&#20808;&#21069;&#30340;&#26041;&#27861;&#20197;&#21450;&#20998;&#37197;&#21305;&#37197;&#26041;&#27861;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#20165;&#20351;&#29992;&#27599;&#31867;1&#20010;&#26679;&#26412;&#21363;&#21487;&#23454;&#29616;&#26368;&#20808;&#36827;&#30340;&#36866;&#24212;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.07666</link><description>&lt;p&gt;
&#22810;&#28304;&#39046;&#22495;&#36866;&#24212;&#36890;&#36807;&#25968;&#25454;&#38598;&#23383;&#20856;&#23398;&#20064;&#36935;&#35265;&#25968;&#25454;&#38598;&#33976;&#39311;
&lt;/p&gt;
&lt;p&gt;
Multi-Source Domain Adaptation meets Dataset Distillation through Dataset Dictionary Learning. (arXiv:2309.07666v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07666
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#38382;&#39064;&#65292;&#31216;&#20026;&#22810;&#28304;&#39046;&#22495;&#36866;&#24212;&#36890;&#36807;&#25968;&#25454;&#38598;&#23383;&#20856;&#23398;&#20064;&#36935;&#35265;&#25968;&#25454;&#38598;&#33976;&#39311;&#65288;MSDA-DD&#65289;&#65292;&#36890;&#36807;&#36866;&#24212;&#20808;&#21069;&#30340;&#26041;&#27861;&#20197;&#21450;&#20998;&#37197;&#21305;&#37197;&#26041;&#27861;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#20165;&#20351;&#29992;&#27599;&#31867;1&#20010;&#26679;&#26412;&#21363;&#21487;&#23454;&#29616;&#26368;&#20808;&#36827;&#30340;&#36866;&#24212;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#20004;&#20010;&#38382;&#39064;&#30340;&#20132;&#38598;&#65306;&#22810;&#28304;&#39046;&#22495;&#36866;&#24212;&#65288;MSDA&#65289;&#21644;&#25968;&#25454;&#38598;&#33976;&#39311;&#65288;DD&#65289;&#12290;&#19968;&#26041;&#38754;&#65292;&#21069;&#32773;&#32771;&#34385;&#20102;&#23558;&#22810;&#20010;&#24322;&#36136;&#30340;&#26631;&#27880;&#28304;&#39046;&#22495;&#36866;&#24212;&#21040;&#19968;&#20010;&#26410;&#26631;&#27880;&#30340;&#30446;&#26631;&#39046;&#22495;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#21518;&#32773;&#25915;&#20987;&#20102;&#20851;&#20110;&#21512;&#25104;&#19968;&#20010;&#21253;&#21547;&#26377;&#20851;&#25968;&#25454;&#38598;&#30340;&#25152;&#26377;&#20449;&#24687;&#30340;&#23567;&#25688;&#35201;&#30340;&#38382;&#39064;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#38382;&#39064;&#31216;&#20026;MSDA-DD&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#36866;&#24212;&#20102;MSDA&#25991;&#29486;&#20013;&#30340;&#20808;&#21069;&#20316;&#21697;&#65292;&#22914;Wasserstein Barycenter Transport&#21644;&#25968;&#25454;&#38598;&#23383;&#20856;&#23398;&#20064;&#65292;&#20197;&#21450;DD&#26041;&#27861;Distribution Matching&#12290;&#25105;&#20204;&#22312;&#22235;&#20010;&#22522;&#20934;&#27979;&#35797;&#38598;&#19978;&#23545;&#36825;&#20010;&#26032;&#38382;&#39064;&#36827;&#34892;&#20102;&#24443;&#24213;&#30340;&#23454;&#39564;&#65288;Caltech-Office 10&#65292; Tennessee-Eastman Process&#65292; Continuous Stirred Tank Reactor&#21644;Case Western Reserve University&#65289;&#65292;&#22312;&#36825;&#20123;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21363;&#20351;&#27599;&#31867;&#21482;&#26377;1&#20010;&#26679;&#26412;&#65292;&#25105;&#20204;&#20063;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#36866;&#24212;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider the intersection of two problems in machine learning: Multi-Source Domain Adaptation (MSDA) and Dataset Distillation (DD). On the one hand, the first considers adapting multiple heterogeneous labeled source domains to an unlabeled target domain. On the other hand, the second attacks the problem of synthesizing a small summary containing all the information about the datasets. We thus consider a new problem called MSDA-DD. To solve it, we adapt previous works in the MSDA literature, such as Wasserstein Barycenter Transport and Dataset Dictionary Learning, as well as DD method Distribution Matching. We thoroughly experiment with this novel problem on four benchmarks (Caltech-Office 10, Tennessee-Eastman Process, Continuous Stirred Tank Reactor, and Case Western Reserve University), where we show that, even with as little as 1 sample per class, one achieves state-of-the-art adaptation performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20998;&#26512;&#22312;&#39640;&#32500;&#38480;&#21046;&#19979;&#30340;&#26368;&#31616;&#21270;&#30340;VAE&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#38381;&#24335;&#34920;&#36798;&#24335;&#65292;&#35780;&#20272;&#20102;beta&#19982;VAE&#20013;&#25968;&#25454;&#38598;&#22823;&#23567;&#12289;&#21518;&#39564;&#22349;&#32553;&#21644;&#29575;&#22833;&#30495;&#26354;&#32447;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#38543;&#30528;beta&#30340;&#22686;&#21152;&#65292;&#20135;&#29983;&#36739;&#22823;&#30340;&#24191;&#20041;&#35823;&#24046;&#24179;&#21488;&#65292;&#24182;&#19988;&#36873;&#25321;&#19968;&#20010;&#23567;&#20110;&#29305;&#23450;&#38408;&#20540;&#30340;beta&#20540;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.07663</link><description>&lt;p&gt;
&#32447;&#24615;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#20013;&#25968;&#25454;&#38598;&#22823;&#23567;&#23545;&#29575;&#22833;&#30495;&#26354;&#32447;&#21644;&#21518;&#39564;&#22349;&#32553;&#38408;&#20540;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Dataset Size Dependence of Rate-Distortion Curve and Threshold of Posterior Collapse in Linear VAE. (arXiv:2309.07663v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07663
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20998;&#26512;&#22312;&#39640;&#32500;&#38480;&#21046;&#19979;&#30340;&#26368;&#31616;&#21270;&#30340;VAE&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#38381;&#24335;&#34920;&#36798;&#24335;&#65292;&#35780;&#20272;&#20102;beta&#19982;VAE&#20013;&#25968;&#25454;&#38598;&#22823;&#23567;&#12289;&#21518;&#39564;&#22349;&#32553;&#21644;&#29575;&#22833;&#30495;&#26354;&#32447;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#38543;&#30528;beta&#30340;&#22686;&#21152;&#65292;&#20135;&#29983;&#36739;&#22823;&#30340;&#24191;&#20041;&#35823;&#24046;&#24179;&#21488;&#65292;&#24182;&#19988;&#36873;&#25321;&#19968;&#20010;&#23567;&#20110;&#29305;&#23450;&#38408;&#20540;&#30340;beta&#20540;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#20013;&#65292;&#21464;&#20998;&#21518;&#39564;&#32463;&#24120;&#19982;&#20808;&#39564;&#23494;&#20999;&#21563;&#21512;&#65292;&#36825;&#34987;&#31216;&#20026;&#21518;&#39564;&#22349;&#32553;&#65292;&#24433;&#21709;&#20102;&#34920;&#31034;&#23398;&#20064;&#30340;&#36136;&#37327;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;VAE&#20013;&#24341;&#20837;&#20102;&#19968;&#20010;&#21487;&#35843;&#33410;&#30340;&#36229;&#21442;&#25968;beta&#12290;&#26412;&#25991;&#36890;&#36807;&#22312;&#39640;&#32500;&#38480;&#21046;&#19979;&#20998;&#26512;&#26368;&#31616;&#21270;&#30340;VAE&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#38381;&#24335;&#34920;&#36798;&#24335;&#65292;&#35780;&#20272;&#20102;beta&#19982;VAE&#20013;&#25968;&#25454;&#38598;&#22823;&#23567;&#12289;&#21518;&#39564;&#22349;&#32553;&#21644;&#29575;&#22833;&#30495;&#26354;&#32447;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#36825;&#20123;&#32467;&#26524;&#34920;&#26126;&#65292;&#19968;&#20010;&#36739;&#22823;&#30340;beta&#20250;&#20135;&#29983;&#19968;&#20010;&#38271;&#30340;&#24191;&#20041;&#35823;&#24046;&#24179;&#21488;&#12290;&#38543;&#30528;beta&#30340;&#22686;&#21152;&#65292;&#24179;&#21488;&#30340;&#38271;&#24230;&#24310;&#38271;&#65292;&#36229;&#36807;&#19968;&#23450;&#30340;&#38408;&#20540;&#21518;&#21464;&#20026;&#26080;&#31351;&#12290;&#36825;&#24847;&#21619;&#30528;&#19982;&#36890;&#24120;&#30340;&#27491;&#21017;&#21270;&#21442;&#25968;&#19981;&#21516;&#65292;beta&#30340;&#36873;&#25321;&#21487;&#33021;&#20250;&#23548;&#33268;&#21518;&#39564;&#22349;&#32553;&#65292;&#32780;&#19982;&#25968;&#25454;&#38598;&#22823;&#23567;&#26080;&#20851;&#12290;&#22240;&#27492;&#65292;beta&#26159;&#19968;&#20010;&#38656;&#35201;&#35880;&#24910;&#35843;&#25972;&#30340;&#39118;&#38505;&#21442;&#25968;&#12290;&#27492;&#22806;&#65292;&#32771;&#34385;&#21040;&#25968;&#25454;&#38598;&#22823;&#23567;&#23545;&#29575;&#22833;&#30495;&#26354;&#32447;&#30340;&#20381;&#36182;&#24615;&#65292;&#25105;&#20204;&#21457;&#29616;&#23384;&#22312;&#19968;&#20010;&#19982;&#25968;&#25454;&#38598;&#22823;&#23567;&#30456;&#20851;&#30340;&#38408;&#20540;&#65292;&#36873;&#25321;&#23567;&#20110;&#36825;&#20010;&#38408;&#20540;&#30340;beta&#20540;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the Variational Autoencoder (VAE), the variational posterior often aligns closely with the prior, which is known as posterior collapse and hinders the quality of representation learning. To mitigate this problem, an adjustable hyperparameter beta has been introduced in the VAE. This paper presents a closed-form expression to assess the relationship between the beta in VAE, the dataset size, the posterior collapse, and the rate-distortion curve by analyzing a minimal VAE in a high-dimensional limit. These results clarify that a long plateau in the generalization error emerges with a relatively larger beta. As the beta increases, the length of the plateau extends and then becomes infinite beyond a certain beta threshold. This implies that the choice of beta, unlike the usual regularization parameters, can induce posterior collapse regardless of the dataset size. Thus, beta is a risky parameter that requires careful tuning. Furthermore, considering the dataset-size dependence on the ra
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26465;&#20214;&#32622;&#25442;&#36827;&#34892;&#32479;&#35745;&#26377;&#25928;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#35780;&#20272;&#30340;&#26041;&#27861;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#31181;&#26041;&#27861;&#20811;&#26381;&#20102;&#26631;&#20934;&#32622;&#25442;&#37325;&#35201;&#24615;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#34920;&#29616;&#20986;&#26368;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.07593</link><description>&lt;p&gt;
&#36890;&#36807;&#26465;&#20214;&#32622;&#25442;&#36827;&#34892;&#32479;&#35745;&#26377;&#25928;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Statistically Valid Variable Importance Assessment through Conditional Permutations. (arXiv:2309.07593v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07593
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26465;&#20214;&#32622;&#25442;&#36827;&#34892;&#32479;&#35745;&#26377;&#25928;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#35780;&#20272;&#30340;&#26041;&#27861;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#31181;&#26041;&#27861;&#20811;&#26381;&#20102;&#26631;&#20934;&#32622;&#25442;&#37325;&#35201;&#24615;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#34920;&#29616;&#20986;&#26368;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20351;&#29992;&#22797;&#26434;&#23398;&#20064;&#22120;&#65288;&#22914;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65289;&#22788;&#29702;&#22823;&#35268;&#27169;&#25968;&#25454;&#26102;&#65292;&#21464;&#37327;&#37325;&#35201;&#24615;&#35780;&#20272;&#24050;&#25104;&#20026;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#30340;&#20851;&#38190;&#27493;&#39588;&#12290;&#30446;&#21069;&#65292;&#22522;&#20110;&#31227;&#38500;&#30340;&#37325;&#35201;&#24615;&#35780;&#20272;&#26159;&#21442;&#32771;&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#22312;&#38656;&#35201;&#32479;&#35745;&#20445;&#35777;&#26469;&#39564;&#35777;&#21464;&#37327;&#21253;&#21547;&#24615;&#26102;&#12290;&#36890;&#24120;&#65292;&#23427;&#20204;&#20351;&#29992;&#21464;&#37327;&#32622;&#25442;&#26041;&#26696;&#26469;&#23454;&#29616;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#23384;&#22312;&#21327;&#21464;&#37327;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#26102;&#23481;&#26131;&#23558;&#19981;&#37325;&#35201;&#30340;&#21464;&#37327;&#35823;&#35782;&#21035;&#20026;&#37325;&#35201;&#21464;&#37327;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31995;&#32479;&#26041;&#27861;&#26469;&#30740;&#31350;&#26465;&#20214;&#32622;&#25442;&#37325;&#35201;&#24615;&#65288;Conditional Permutation Importance&#65292;CPI&#65289;&#65292;&#23427;&#26159;&#27169;&#22411;&#26080;&#20851;&#19988;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#35780;&#20272;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#20272;&#35745;&#22120;&#12290;&#29702;&#35770;&#21644;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;CPI&#36890;&#36807;&#25552;&#20379;&#20934;&#30830;&#30340;I&#22411;&#38169;&#35823;&#25511;&#21046;&#65292;&#20811;&#26381;&#20102;&#26631;&#20934;&#32622;&#25442;&#37325;&#35201;&#24615;&#30340;&#23616;&#38480;&#24615;&#12290;&#24403;&#19982;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#19968;&#36215;&#20351;&#29992;&#26102;&#65292;CPI&#22987;&#32456;&#26174;&#31034;&#20986;&#26368;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variable importance assessment has become a crucial step in machine-learning applications when using complex learners, such as deep neural networks, on large-scale data. Removal-based importance assessment is currently the reference approach, particularly when statistical guarantees are sought to justify variable inclusion. It is often implemented with variable permutation schemes. On the flip side, these approaches risk misidentifying unimportant variables as important in the presence of correlations among covariates. Here we develop a systematic approach for studying Conditional Permutation Importance (CPI) that is model agnostic and computationally lean, as well as reusable benchmarks of state-of-the-art variable importance estimators. We show theoretically and empirically that $\textit{CPI}$ overcomes the limitations of standard permutation importance by providing accurate type-I error control. When used with a deep neural network, $\textit{CPI}$ consistently showed top accuracy ac
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SC-MAD&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#28151;&#21512;&#39640;&#38454;&#32593;&#32476;&#23545;&#25968;&#25454;&#36827;&#34892;&#22686;&#24378;&#12290;&#36890;&#36807;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#28151;&#21512;&#26426;&#21046;&#36820;&#22238;&#29616;&#26377;&#26631;&#35760;&#26679;&#26412;&#30340;&#28151;&#21512;&#29289;&#65292;&#20197;&#21450;&#19968;&#31181;&#20984;&#32858;&#31867;&#28151;&#21512;&#26041;&#27861;&#29992;&#20110;&#25551;&#36848;&#22810;&#20010;&#22797;&#24418;&#22797;&#26434;&#32593;&#32476;&#20043;&#38388;&#30340;&#25968;&#25454;&#39537;&#21160;&#20851;&#31995;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#22797;&#24418;&#22797;&#26434;&#20998;&#31867;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.07453</link><description>&lt;p&gt;
SC-MAD: &#28151;&#21512;&#39640;&#38454;&#32593;&#32476;&#29992;&#20110;&#25968;&#25454;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
SC-MAD: Mixtures of Higher-order Networks for Data Augmentation. (arXiv:2309.07453v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07453
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SC-MAD&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#28151;&#21512;&#39640;&#38454;&#32593;&#32476;&#23545;&#25968;&#25454;&#36827;&#34892;&#22686;&#24378;&#12290;&#36890;&#36807;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#28151;&#21512;&#26426;&#21046;&#36820;&#22238;&#29616;&#26377;&#26631;&#35760;&#26679;&#26412;&#30340;&#28151;&#21512;&#29289;&#65292;&#20197;&#21450;&#19968;&#31181;&#20984;&#32858;&#31867;&#28151;&#21512;&#26041;&#27861;&#29992;&#20110;&#25551;&#36848;&#22810;&#20010;&#22797;&#24418;&#22797;&#26434;&#32593;&#32476;&#20043;&#38388;&#30340;&#25968;&#25454;&#39537;&#21160;&#20851;&#31995;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#22797;&#24418;&#22797;&#26434;&#20998;&#31867;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#22810;&#22797;&#26434;&#31995;&#32479;&#20013;&#23384;&#22312;&#30528;&#22810;&#32500;&#20132;&#20114;&#65292;&#36825;&#20419;&#20351;&#25105;&#20204;&#23558;&#22522;&#20110;&#22270;&#30340;&#25104;&#23545;&#36830;&#25509;&#25299;&#23637;&#21040;&#39640;&#38454;&#20851;&#31995;&#12290;&#29305;&#21035;&#22320;&#65292;&#22797;&#24418;&#22797;&#26434;&#32593;&#32476;&#24050;&#32463;&#21551;&#21457;&#20102;&#22522;&#20110;&#22797;&#24418;&#22797;&#26434;&#27169;&#22411;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#12290;&#22312;&#36825;&#31181;&#31995;&#32479;&#19978;&#30340;&#23398;&#20064;&#38656;&#35201;&#22823;&#37327;&#30340;&#25968;&#25454;&#65292;&#32780;&#36825;&#20123;&#25968;&#25454;&#21487;&#33021;&#38590;&#20197;&#33719;&#21462;&#25110;&#32773;&#25104;&#26412;&#39640;&#26114;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#36890;&#36807;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#28151;&#21512;&#26426;&#21046;&#23545;&#22797;&#24418;&#22797;&#26434;&#32593;&#32476;&#36827;&#34892;&#25968;&#25454;&#22686;&#24378;&#30340;&#26041;&#27861;&#65292;&#36820;&#22238;&#29616;&#26377;&#26631;&#35760;&#26679;&#26412;&#30340;&#28151;&#21512;&#29289;&#12290;&#38500;&#20102;&#20256;&#32479;&#30340;&#25104;&#23545;&#28151;&#21512;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#20984;&#32858;&#31867;&#28151;&#21512;&#26041;&#27861;&#65292;&#29992;&#20110;&#25551;&#36848;&#22810;&#20010;&#22797;&#24418;&#22797;&#26434;&#32593;&#32476;&#20043;&#38388;&#30340;&#25968;&#25454;&#39537;&#21160;&#20851;&#31995;&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#29983;&#25104;&#30340;&#21512;&#25104;&#22797;&#24418;&#22797;&#26434;&#32593;&#32476;&#22312;&#21516;&#24577;&#23494;&#24230;&#26041;&#38754;&#25554;&#20540;&#20102;&#29616;&#26377;&#25968;&#25454;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22797;&#24418;&#22797;&#26434;&#20998;&#31867;&#30340;&#23454;&#35777;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
The myriad complex systems with multiway interactions motivate the extension of graph-based pairwise connections to higher-order relations. In particular, the simplicial complex has inspired generalizations of graph neural networks (GNNs) to simplicial complex-based models. Learning on such systems requires large amounts of data, which can be expensive or impossible to obtain. We propose data augmentation of simplicial complexes through both linear and nonlinear mixup mechanisms that return mixtures of existing labeled samples. In addition to traditional pairwise mixup, we present a convex clustering mixup approach for a data-driven relationship among several simplicial complexes. We theoretically demonstrate that the resultant synthetic simplicial complexes interpolate among existing data with respect to homomorphism densities. Our method is demonstrated on both synthetic and real-world datasets for simplicial complex classification.
&lt;/p&gt;</description></item><item><title>&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#24352;&#37327;&#21644;SVM Trick&#37325;&#26032;&#26500;&#24314;&#20102;&#21333;&#23618;LLM&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#24212;&#30340;&#20248;&#21270;&#35270;&#35282;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#21487;&#20197;&#22312;&#30697;&#38453;&#20056;&#27861;&#26102;&#38388;&#20869;&#35299;&#20915;&#27880;&#24847;&#21147;&#22238;&#24402;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.07418</link><description>&lt;p&gt;
&#22312;&#24352;&#37327;&#21644;SVM Trick&#22522;&#30784;&#19978;&#37325;&#26032;&#26500;&#24314;&#21333;&#23618;LLM&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#24182;&#22312;&#30697;&#38453;&#20056;&#27861;&#26102;&#38388;&#20869;&#35299;&#20915;&#23427;&#30340;&#24555;&#36895;&#20248;&#21270;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
A Fast Optimization View: Reformulating Single Layer Attention in LLM Based on Tensor and SVM Trick, and Solving It in Matrix Multiplication Time. (arXiv:2309.07418v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07418
&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#24352;&#37327;&#21644;SVM Trick&#37325;&#26032;&#26500;&#24314;&#20102;&#21333;&#23618;LLM&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#24212;&#30340;&#20248;&#21270;&#35270;&#35282;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#21487;&#20197;&#22312;&#30697;&#38453;&#20056;&#27861;&#26102;&#38388;&#20869;&#35299;&#20915;&#27880;&#24847;&#21147;&#22238;&#24402;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#25105;&#20204;&#26085;&#24120;&#29983;&#27963;&#30340;&#21508;&#20010;&#26041;&#38754;&#37117;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#35299;&#20915;LLMs&#20013;&#30340;&#27880;&#24847;&#21147;&#22238;&#24402;&#26159;&#20248;&#21270;LLMs&#30340;&#22522;&#26412;&#20219;&#21153;&#12290;&#26412;&#25991;&#33268;&#21147;&#20110;&#20026;&#19968;&#23618;&#27880;&#24847;&#21147;&#32593;&#32476;&#30446;&#26631;&#20989;&#25968; $L(X,Y) = \sum_{j_0 = 1}^n \sum_{i_0 = 1}^d ( \langle \langle \exp( \mathsf{A}_{j_0} x ) , {\bf 1}_n \rangle^{-1} \exp( \mathsf{A}_{j_0} x ), A_{3} Y_{*,i_0} \rangle - b_{j_0,i_0} )^2$ &#25552;&#20379;&#21487;&#35777;&#26126;&#30340;&#20445;&#35777;&#12290;&#36825;&#37324; $\mathsf{A} \in \mathbb{R}^{n^2 \times d^2}$ &#26159;$A_1 \in \mathbb{R}^{n \times d}$ &#21644; $A_2 \in \mathbb{R}^{n \times d}$ &#30340;Kronecker&#31215;&#12290;$A_3$ &#26159;$\mathbb{R}^{n \times d}$ &#20013;&#30340;&#19968;&#20010;&#30697;&#38453;&#65292;$\mathsf{A}_{j_0} \in \mathbb{R}^{n \times d^2}$ &#26159;$\mathsf{A}$ &#30340;&#31532;$j_0$&#20010;&#22359;&#12290;$X, Y \in \mathbb{R}^{d \times d}$ &#26159;&#25105;&#20204;&#35201;&#23398;&#20064;&#30340;&#21464;&#37327;&#12290;$B \in \mathbb{R}^{n \times d}$ &#21644; $b_{j_0,i_0} \in \mathbb{R}$ &#26159;$B$ &#30340;&#31532;$j_0$&#34892;&#21644;&#31532;$i_0$&#21015;&#30340;&#19968;&#20010;&#20803;&#32032;&#65292;$Y_{*,i_0} \in \mathbb{R}^d$ &#26159;$Y$ &#30340;&#31532;$i_0$&#21015;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have played a pivotal role in revolutionizing various facets of our daily existence. Solving attention regression is a fundamental task in optimizing LLMs. In this work, we focus on giving a provable guarantee for the one-layer attention network objective function $L(X,Y) = \sum_{j_0 = 1}^n \sum_{i_0 = 1}^d ( \langle \langle \exp( \mathsf{A}_{j_0} x ) , {\bf 1}_n \rangle^{-1} \exp( \mathsf{A}_{j_0} x ), A_{3} Y_{*,i_0} \rangle - b_{j_0,i_0} )^2$. Here $\mathsf{A} \in \mathbb{R}^{n^2 \times d^2}$ is Kronecker product between $A_1 \in \mathbb{R}^{n \times d}$ and $A_2 \in \mathbb{R}^{n \times d}$. $A_3$ is a matrix in $\mathbb{R}^{n \times d}$, $\mathsf{A}_{j_0} \in \mathbb{R}^{n \times d^2}$ is the $j_0$-th block of $\mathsf{A}$. The $X, Y \in \mathbb{R}^{d \times d}$ are variables we want to learn. $B \in \mathbb{R}^{n \times d}$ and $b_{j_0,i_0} \in \mathbb{R}$ is one entry at $j_0$-th row and $i_0$-th column of $B$, $Y_{*,i_0} \in \mathbb{R}^d$ is the $i_
&lt;/p&gt;</description></item><item><title>&#21019;&#26032;&#28857;&#65306;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21487;&#38752;&#24615;&#30340;&#35757;&#32451;&#25968;&#25454;&#28165;&#27927;&#26041;&#27861;&#65292;&#21033;&#29992;&#24402;&#32435;&#24615;&#31526;&#21512;&#39044;&#27979;&#26469;&#32416;&#27491;&#22122;&#22768;&#35757;&#32451;&#25968;&#25454;&#20013;&#30340;&#38169;&#35823;&#26631;&#35760;&#21644;&#24322;&#24120;&#20540;&#12290;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#20998;&#31867;&#20219;&#21153;&#20013;&#39564;&#35777;&#26377;&#25928;&#24615;&#65292;&#24182;&#26174;&#33879;&#25552;&#21319;&#20102;&#20998;&#31867;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.07332</link><description>&lt;p&gt;
&#22810;&#27169;&#24577;&#29983;&#29289;&#21307;&#23398;&#25968;&#25454;&#25366;&#25496;&#20013;&#30340;&#22522;&#20110;&#21487;&#38752;&#24615;&#30340;&#22122;&#22768;&#35757;&#32451;&#26631;&#31614;&#28165;&#27927;&#26041;&#27861;&#19982;&#24402;&#32435;&#24615;&#31526;&#21512;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Reliability-based cleaning of noisy training labels with inductive conformal prediction in multi-modal biomedical data mining. (arXiv:2309.07332v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07332
&lt;/p&gt;
&lt;p&gt;
&#21019;&#26032;&#28857;&#65306;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21487;&#38752;&#24615;&#30340;&#35757;&#32451;&#25968;&#25454;&#28165;&#27927;&#26041;&#27861;&#65292;&#21033;&#29992;&#24402;&#32435;&#24615;&#31526;&#21512;&#39044;&#27979;&#26469;&#32416;&#27491;&#22122;&#22768;&#35757;&#32451;&#25968;&#25454;&#20013;&#30340;&#38169;&#35823;&#26631;&#35760;&#21644;&#24322;&#24120;&#20540;&#12290;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#20998;&#31867;&#20219;&#21153;&#20013;&#39564;&#35777;&#26377;&#25928;&#24615;&#65292;&#24182;&#26174;&#33879;&#25552;&#21319;&#20102;&#20998;&#31867;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20934;&#30830;&#26631;&#35760;&#29983;&#29289;&#21307;&#23398;&#25968;&#25454;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#20256;&#32479;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#36890;&#24120;&#27809;&#26377;&#20805;&#20998;&#21033;&#29992;&#21487;&#29992;&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#21487;&#38752;&#24615;&#30340;&#35757;&#32451;&#25968;&#25454;&#28165;&#27927;&#26041;&#27861;&#65292;&#37319;&#29992;&#20102;&#24402;&#32435;&#24615;&#31526;&#21512;&#39044;&#27979;&#65288;ICP&#65289;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#19968;&#23567;&#37096;&#20998;&#20934;&#30830;&#26631;&#35760;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#24182;&#21033;&#29992;ICP&#35745;&#31639;&#30340;&#21487;&#38752;&#24615;&#25351;&#26631;&#26469;&#32416;&#27491;&#28023;&#37327;&#22122;&#22768;&#35757;&#32451;&#25968;&#25454;&#20013;&#30340;&#38169;&#35823;&#26631;&#35760;&#21644;&#24322;&#24120;&#20540;&#12290;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#22312;&#19977;&#20010;&#20998;&#31867;&#20219;&#21153;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#65306;&#20351;&#29992;&#26631;&#39064;&#21644;&#25688;&#35201;&#23545;&#33647;&#29289;&#35825;&#23548;&#30340;&#32925;&#25439;&#20260;&#65288;DILI&#65289;&#25991;&#29486;&#36827;&#34892;&#36807;&#28388;&#65292;&#36890;&#36807;CT&#24433;&#20687;&#23398;&#21644;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#39044;&#27979;COVID-19&#24739;&#32773;&#30340;&#37325;&#30151;&#30417;&#25252;&#30149;&#25151;&#65288;ICU&#65289;&#20837;&#38498;&#24773;&#20917;&#65292;&#20197;&#21450;&#20351;&#29992;RNA&#27979;&#24207;&#25968;&#25454;&#23545;&#20083;&#33146;&#30284;&#36827;&#34892;&#20122;&#22411;&#20998;&#22411;&#12290;&#36890;&#36807;&#26631;&#31614;&#25490;&#21015;&#24341;&#20837;&#20102;&#19981;&#21516;&#31243;&#24230;&#30340;&#35757;&#32451;&#26631;&#31614;&#22122;&#22768;&#12290;&#32467;&#26524;&#26174;&#31034;&#20998;&#31867;&#24615;&#33021;&#26174;&#33879;&#25552;&#21319;&#65306;&#20934;&#30830;&#24230;&#25552;&#39640;
&lt;/p&gt;
&lt;p&gt;
Accurately labeling biomedical data presents a challenge. Traditional semi-supervised learning methods often under-utilize available unlabeled data. To address this, we propose a novel reliability-based training data cleaning method employing inductive conformal prediction (ICP). This method capitalizes on a small set of accurately labeled training data and leverages ICP-calculated reliability metrics to rectify mislabeled data and outliers within vast quantities of noisy training data. The efficacy of the method is validated across three classification tasks within distinct modalities: filtering drug-induced-liver-injury (DILI) literature with title and abstract, predicting ICU admission of COVID-19 patients through CT radiomics and electronic health records, and subtyping breast cancer using RNA-sequencing data. Varying levels of noise to the training labels were introduced through label permutation. Results show significant enhancements in classification performance: accuracy enhanc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23384;&#22312;&#28151;&#28102;&#25928;&#24212;&#26102;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27491;&#20132;&#32467;&#26500;&#21644;&#32447;&#24615;&#25237;&#24433;&#30340;&#32479;&#35745;&#20272;&#35745;&#21644;&#25512;&#26029;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#30001;&#20110;&#26410;&#27979;&#28151;&#28102;&#22240;&#32032;&#24341;&#36215;&#30340;&#20559;&#24046;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.07261</link><description>&lt;p&gt;
&#20855;&#26377;&#26410;&#27979;&#28151;&#28102;&#22240;&#32032;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#21516;&#26102;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Simultaneous inference for generalized linear models with unmeasured confounders. (arXiv:2309.07261v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07261
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23384;&#22312;&#28151;&#28102;&#25928;&#24212;&#26102;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27491;&#20132;&#32467;&#26500;&#21644;&#32447;&#24615;&#25237;&#24433;&#30340;&#32479;&#35745;&#20272;&#35745;&#21644;&#25512;&#26029;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#30001;&#20110;&#26410;&#27979;&#28151;&#28102;&#22240;&#32032;&#24341;&#36215;&#30340;&#20559;&#24046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#22240;&#32452;&#30740;&#31350;&#20013;&#65292;&#24120;&#24120;&#36827;&#34892;&#25104;&#21315;&#19978;&#19975;&#20010;&#21516;&#26102;&#20551;&#35774;&#26816;&#39564;&#65292;&#20197;&#30830;&#23450;&#24046;&#24322;&#34920;&#36798;&#30340;&#22522;&#22240;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23384;&#22312;&#26410;&#27979;&#28151;&#28102;&#22240;&#32032;&#65292;&#35768;&#22810;&#26631;&#20934;&#32479;&#35745;&#26041;&#27861;&#21487;&#33021;&#23384;&#22312;&#20005;&#37325;&#30340;&#20559;&#24046;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#23384;&#22312;&#28151;&#28102;&#25928;&#24212;&#26102;&#30340;&#22810;&#20803;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#12290;&#22312;&#20219;&#24847;&#28151;&#28102;&#26426;&#21046;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#32479;&#35745;&#20272;&#35745;&#21644;&#25512;&#26029;&#26041;&#27861;&#65292;&#21033;&#29992;&#27491;&#20132;&#32467;&#26500;&#24182;&#23558;&#32447;&#24615;&#25237;&#24433;&#25972;&#21512;&#21040;&#19977;&#20010;&#20851;&#38190;&#38454;&#27573;&#20013;&#12290;&#39318;&#20808;&#65292;&#21033;&#29992;&#22810;&#20803;&#21709;&#24212;&#21464;&#37327;&#20998;&#31163;&#36793;&#38469;&#21644;&#19981;&#30456;&#20851;&#30340;&#28151;&#28102;&#25928;&#24212;&#65292;&#24674;&#22797;&#28151;&#28102;&#31995;&#25968;&#30340;&#21015;&#31354;&#38388;&#12290;&#38543;&#21518;&#65292;&#21033;&#29992;$\ell_1$&#27491;&#21017;&#21270;&#36827;&#34892;&#31232;&#30095;&#24615;&#20272;&#35745;&#65292;&#24182;&#24378;&#21152;&#27491;&#20132;&#24615;&#38480;&#21046;&#20110;&#28151;&#28102;&#31995;&#25968;&#65292;&#32852;&#21512;&#20272;&#35745;&#28508;&#22312;&#22240;&#23376;&#21644;&#20027;&#35201;&#25928;&#24212;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#32467;&#21512;&#25237;&#24433;&#21644;&#21152;&#26435;&#20559;&#24046;&#26657;&#27491;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tens of thousands of simultaneous hypothesis tests are routinely performed in genomic studies to identify differentially expressed genes. However, due to unmeasured confounders, many standard statistical approaches may be substantially biased. This paper investigates the large-scale hypothesis testing problem for multivariate generalized linear models in the presence of confounding effects. Under arbitrary confounding mechanisms, we propose a unified statistical estimation and inference framework that harnesses orthogonal structures and integrates linear projections into three key stages. It first leverages multivariate responses to separate marginal and uncorrelated confounding effects, recovering the confounding coefficients' column space. Subsequently, latent factors and primary effects are jointly estimated, utilizing $\ell_1$-regularization for sparsity while imposing orthogonality onto confounding coefficients. Finally, we incorporate projected and weighted bias-correction steps 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#33258;&#26059;&#32593;&#32476;&#26500;&#24314;SU(2)&#31561;&#20215;&#37327;&#23376;&#30005;&#36335;&#65292;&#36890;&#36807;&#32534;&#30721;&#32676;&#32467;&#26500;&#26469;&#38480;&#21046;&#20248;&#21270;&#31354;&#38388;&#65292; &#20855;&#26377;&#26059;&#36716;&#23545;&#31216;&#24615;&#65292;&#27604;&#20854;&#20182;&#24050;&#30693;&#30340;&#26500;&#36896;&#26356;&#30452;&#25509;&#23454;&#29616;&#22312;&#37327;&#23376;&#30828;&#20214;&#19978;&#12290;</title><link>http://arxiv.org/abs/2309.07250</link><description>&lt;p&gt;
&#20320;&#25152;&#38656;&#35201;&#30340;&#21482;&#26159;&#26059;&#36716;&#65306;&#22522;&#20110;&#33258;&#26059;&#32593;&#32476;&#30340;SU(2)&#31561;&#20215;&#21464;&#20998;&#37327;&#23376;&#30005;&#36335;
&lt;/p&gt;
&lt;p&gt;
All you need is spin: SU(2) equivariant variational quantum circuits based on spin networks. (arXiv:2309.07250v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07250
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#33258;&#26059;&#32593;&#32476;&#26500;&#24314;SU(2)&#31561;&#20215;&#37327;&#23376;&#30005;&#36335;&#65292;&#36890;&#36807;&#32534;&#30721;&#32676;&#32467;&#26500;&#26469;&#38480;&#21046;&#20248;&#21270;&#31354;&#38388;&#65292; &#20855;&#26377;&#26059;&#36716;&#23545;&#31216;&#24615;&#65292;&#27604;&#20854;&#20182;&#24050;&#30693;&#30340;&#26500;&#36896;&#26356;&#30452;&#25509;&#23454;&#29616;&#22312;&#37327;&#23376;&#30828;&#20214;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#31639;&#27861;&#35201;&#27714;&#23558;&#20248;&#21270;&#31354;&#38388;&#33258;&#28982;&#22320;&#38480;&#21046;&#22312;&#19968;&#20010;&#26377;&#25928;&#30340;&#33539;&#22260;&#20869;&#12290;&#22312;&#20960;&#20309;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#23558;&#32676;&#32467;&#26500;&#32534;&#30721;&#21040;&#21442;&#25968;&#21270;&#30340;&#37327;&#23376;&#30005;&#36335;&#20013;&#65292;&#23558;&#38382;&#39064;&#30340;&#23545;&#31216;&#24615;&#20316;&#20026;&#24402;&#32435;&#20559;&#32622;&#26469;&#32771;&#34385;&#65292;&#21487;&#20197;&#23454;&#29616;&#36825;&#19968;&#28857;&#12290;&#28982;&#32780;&#65292;&#26500;&#24314;&#36825;&#26679;&#30340;&#30005;&#36335;&#26159;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#23578;&#26410;&#20986;&#29616;&#26126;&#30830;&#30340;&#25351;&#23548;&#21407;&#21017;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#33258;&#26059;&#32593;&#32476;&#65292;&#19968;&#31181;&#22312;&#32676;&#21464;&#25442;&#19979;&#20445;&#25345;&#19981;&#21464;&#30340;&#26377;&#21521;&#24352;&#37327;&#32593;&#32476;&#24418;&#24335;&#65292;&#26469;&#35774;&#35745;SU(2)&#31561;&#20215;&#37327;&#23376;&#30005;&#36335;ansatz - &#20855;&#26377;&#26059;&#36716;&#23545;&#31216;&#24615;&#30340;&#30005;&#36335;&#12290;&#36890;&#36807;&#25913;&#21464;&#20351;SU(2)&#32676;&#20316;&#29992;&#22359;&#23545;&#35282;&#21270;&#30340;&#22522;&#30784;&#65292;&#36825;&#20123;&#32593;&#32476;&#20026;&#26500;&#24314;&#21442;&#25968;&#21270;&#31561;&#20215;&#37327;&#23376;&#30005;&#36335;&#25552;&#20379;&#20102;&#19968;&#20010;&#33258;&#28982;&#30340;&#26500;&#24314;&#27169;&#22359;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26500;&#36896;&#22312;&#25968;&#23398;&#19978;&#31561;&#25928;&#20110;&#20854;&#20182;&#24050;&#30693;&#30340;&#26500;&#36896;&#65292;&#20363;&#22914;&#22522;&#20110;&#20132;&#38169;&#21644;&#24191;&#20041;&#25490;&#21015;&#30340;&#26500;&#36896;&#65292;&#20294;&#22312;&#37327;&#23376;&#30828;&#20214;&#19978;&#23454;&#29616;&#26356;&#30452;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational algorithms require architectures that naturally constrain the optimisation space to run efficiently. In geometric quantum machine learning, one achieves this by encoding group structure into parameterised quantum circuits to include the symmetries of a problem as an inductive bias. However, constructing such circuits is challenging as a concrete guiding principle has yet to emerge. In this paper, we propose the use of spin networks, a form of directed tensor network invariant under a group transformation, to devise SU(2) equivariant quantum circuit ans\"atze -- circuits possessing spin rotation symmetry. By changing to the basis that block diagonalises SU(2) group action, these networks provide a natural building block for constructing parameterised equivariant quantum circuits. We prove that our construction is mathematically equivalent to other known constructions, such as those based on twirling and generalised permutations, but more direct to implement on quantum hardwa
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#20851;&#38190;&#39046;&#22495;&#20013;&#38024;&#23545;&#40723;&#21169;&#25919;&#31574;&#30340;&#26368;&#20248;&#21644;&#20844;&#24179;&#35780;&#20272;&#20197;&#21450;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#30740;&#31350;&#21457;&#29616;&#22312;&#20154;&#31867;&#19981;&#36981;&#24490;&#27835;&#30103;&#24314;&#35758;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#31574;&#30053;&#35268;&#21017;&#21482;&#26159;&#24314;&#35758;&#12290;&#21516;&#26102;&#65292;&#38024;&#23545;&#27835;&#30103;&#30340;&#24322;&#36136;&#24615;&#21644;&#20844;&#24179;&#32771;&#34385;&#22240;&#32032;&#65292;&#20915;&#31574;&#32773;&#30340;&#26435;&#34913;&#21644;&#20915;&#31574;&#35268;&#21017;&#20063;&#20250;&#21457;&#29983;&#21464;&#21270;&#12290;&#22312;&#31038;&#20250;&#26381;&#21153;&#39046;&#22495;&#65292;&#30740;&#31350;&#26174;&#31034;&#23384;&#22312;&#19968;&#20010;&#20351;&#29992;&#24046;&#36317;&#38382;&#39064;&#65292;&#37027;&#20123;&#26368;&#26377;&#21487;&#33021;&#21463;&#30410;&#30340;&#20154;&#21364;&#26080;&#27861;&#33719;&#24471;&#36825;&#20123;&#30410;&#26381;&#21153;&#12290;</title><link>http://arxiv.org/abs/2309.07176</link><description>&lt;p&gt;
&#26368;&#20248;&#21644;&#20844;&#24179;&#30340;&#40723;&#21169;&#25919;&#31574;&#35780;&#20272;&#19982;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Optimal and Fair Encouragement Policy Evaluation and Learning. (arXiv:2309.07176v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07176
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#20851;&#38190;&#39046;&#22495;&#20013;&#38024;&#23545;&#40723;&#21169;&#25919;&#31574;&#30340;&#26368;&#20248;&#21644;&#20844;&#24179;&#35780;&#20272;&#20197;&#21450;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#30740;&#31350;&#21457;&#29616;&#22312;&#20154;&#31867;&#19981;&#36981;&#24490;&#27835;&#30103;&#24314;&#35758;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#31574;&#30053;&#35268;&#21017;&#21482;&#26159;&#24314;&#35758;&#12290;&#21516;&#26102;&#65292;&#38024;&#23545;&#27835;&#30103;&#30340;&#24322;&#36136;&#24615;&#21644;&#20844;&#24179;&#32771;&#34385;&#22240;&#32032;&#65292;&#20915;&#31574;&#32773;&#30340;&#26435;&#34913;&#21644;&#20915;&#31574;&#35268;&#21017;&#20063;&#20250;&#21457;&#29983;&#21464;&#21270;&#12290;&#22312;&#31038;&#20250;&#26381;&#21153;&#39046;&#22495;&#65292;&#30740;&#31350;&#26174;&#31034;&#23384;&#22312;&#19968;&#20010;&#20351;&#29992;&#24046;&#36317;&#38382;&#39064;&#65292;&#37027;&#20123;&#26368;&#26377;&#21487;&#33021;&#21463;&#30410;&#30340;&#20154;&#21364;&#26080;&#27861;&#33719;&#24471;&#36825;&#20123;&#30410;&#26381;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20851;&#38190;&#39046;&#22495;&#20013;&#65292;&#24378;&#21046;&#20010;&#20307;&#25509;&#21463;&#27835;&#30103;&#36890;&#24120;&#26159;&#19981;&#21487;&#33021;&#30340;&#65292;&#22240;&#27492;&#22312;&#20154;&#31867;&#19981;&#36981;&#24490;&#27835;&#30103;&#24314;&#35758;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#31574;&#30053;&#35268;&#21017;&#21482;&#26159;&#24314;&#35758;&#12290;&#22312;&#36825;&#20123;&#39046;&#22495;&#20013;&#65292;&#25509;&#21463;&#27835;&#30103;&#30340;&#20010;&#20307;&#21487;&#33021;&#23384;&#22312;&#24322;&#36136;&#24615;&#65292;&#27835;&#30103;&#25928;&#26524;&#20063;&#21487;&#33021;&#23384;&#22312;&#24322;&#36136;&#24615;&#12290;&#34429;&#28982;&#26368;&#20248;&#27835;&#30103;&#35268;&#21017;&#21487;&#20197;&#26368;&#22823;&#21270;&#25972;&#20010;&#20154;&#32676;&#30340;&#22240;&#26524;&#32467;&#26524;&#65292;&#20294;&#22312;&#40723;&#21169;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#20110;&#35775;&#38382;&#24179;&#31561;&#38480;&#21046;&#25110;&#20854;&#20182;&#20844;&#24179;&#32771;&#34385;&#22240;&#32032;&#21487;&#33021;&#26159;&#30456;&#20851;&#30340;&#12290;&#20363;&#22914;&#65292;&#22312;&#31038;&#20250;&#26381;&#21153;&#39046;&#22495;&#65292;&#19968;&#20010;&#25345;&#20037;&#30340;&#38590;&#39064;&#26159;&#37027;&#20123;&#26368;&#26377;&#21487;&#33021;&#20174;&#20013;&#21463;&#30410;&#30340;&#20154;&#20013;&#37027;&#20123;&#33719;&#30410;&#26381;&#21153;&#30340;&#20351;&#29992;&#24046;&#36317;&#12290;&#24403;&#20915;&#31574;&#32773;&#23545;&#35775;&#38382;&#21644;&#24179;&#22343;&#32467;&#26524;&#37117;&#26377;&#20998;&#37197;&#20559;&#22909;&#26102;&#65292;&#26368;&#20248;&#20915;&#31574;&#35268;&#21017;&#20250;&#21457;&#29983;&#21464;&#21270;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22240;&#26524;&#35782;&#21035;&#12289;&#32479;&#35745;&#26041;&#24046;&#20943;&#23569;&#20272;&#35745;&#21644;&#31283;&#20581;&#20272;&#35745;&#30340;&#26368;&#20248;&#27835;&#30103;&#35268;&#21017;&#65292;&#21253;&#25324;&#22312;&#36829;&#21453;&#38451;&#24615;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
In consequential domains, it is often impossible to compel individuals to take treatment, so that optimal policy rules are merely suggestions in the presence of human non-adherence to treatment recommendations. In these same domains, there may be heterogeneity both in who responds in taking-up treatment, and heterogeneity in treatment efficacy. While optimal treatment rules can maximize causal outcomes across the population, access parity constraints or other fairness considerations can be relevant in the case of encouragement. For example, in social services, a persistent puzzle is the gap in take-up of beneficial services among those who may benefit from them the most. When in addition the decision-maker has distributional preferences over both access and average outcomes, the optimal decision rule changes. We study causal identification, statistical variance-reduced estimation, and robust estimation of optimal treatment rules, including under potential violations of positivity. We c
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#23558;&#29289;&#29702;&#20449;&#24687;&#19982;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#25512;&#26029;&#32463;&#20856;&#23494;&#24230;&#27867;&#20989;&#29702;&#35770;&#20013;&#22810;&#31890;&#23376;&#31995;&#32479;&#30340;&#22806;&#37096;&#21183;&#33021;&#12290;&#35813;&#26694;&#26550;&#22312;&#20855;&#26377;&#25490;&#38500;&#20307;&#31215;&#30456;&#20114;&#20316;&#29992;&#30340;&#21463;&#38480;&#20960;&#20309;&#20013;&#36827;&#34892;&#20102;&#23454;&#39564;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2309.07065</link><description>&lt;p&gt;
&#32463;&#20856;&#23494;&#24230;&#27867;&#20989;&#29702;&#35770;&#20013;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#22806;&#37096;&#21183;&#33021;
&lt;/p&gt;
&lt;p&gt;
Physics-informed Bayesian inference of external potentials in classical density-functional theory. (arXiv:2309.07065v1 [cond-mat.stat-mech])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07065
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#23558;&#29289;&#29702;&#20449;&#24687;&#19982;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#25512;&#26029;&#32463;&#20856;&#23494;&#24230;&#27867;&#20989;&#29702;&#35770;&#20013;&#22810;&#31890;&#23376;&#31995;&#32479;&#30340;&#22806;&#37096;&#21183;&#33021;&#12290;&#35813;&#26694;&#26550;&#22312;&#20855;&#26377;&#25490;&#38500;&#20307;&#31215;&#30456;&#20114;&#20316;&#29992;&#30340;&#21463;&#38480;&#20960;&#20309;&#20013;&#36827;&#34892;&#20102;&#23454;&#39564;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#22312;&#32479;&#35745;&#21147;&#23398;&#39046;&#22495;&#20013;&#24050;&#32463;&#21462;&#24471;&#20102;&#24555;&#36895;&#21457;&#23637;&#12290;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#21560;&#24341;&#20102;&#32463;&#20856;&#23494;&#24230;&#27867;&#20989;&#29702;&#35770;&#65288;DFT&#65289;&#31038;&#21306;&#30340;&#27880;&#24847;&#65292;&#22240;&#20026;&#23427;&#20204;&#33021;&#22815;&#21457;&#29616;&#33258;&#30001;&#33021;&#27867;&#20989;&#65292;&#20197;&#30830;&#23450;&#22810;&#31890;&#23376;&#31995;&#32479;&#30340;&#24179;&#34913;&#23494;&#24230;&#20998;&#24067;&#12290;&#22312;DFT&#20013;&#65292;&#22806;&#37096;&#21183;&#33021;&#32771;&#34385;&#20102;&#22810;&#31890;&#23376;&#31995;&#32479;&#19982;&#22806;&#37096;&#22330;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#20174;&#32780;&#24433;&#21709;&#23494;&#24230;&#20998;&#24067;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#25512;&#26029;&#20316;&#29992;&#20110;&#22810;&#31890;&#23376;&#31995;&#32479;&#30340;&#22806;&#37096;&#21183;&#33021;&#12290;&#25105;&#20204;&#23558;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#19982;&#32463;&#20856;&#30340;DFT&#24037;&#20855;&#32467;&#21512;&#36215;&#26469;&#65292;&#37325;&#26500;&#22806;&#37096;&#21183;&#33021;&#65292;&#24471;&#21040;&#20855;&#26377;&#20869;&#22312;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#22806;&#37096;&#21183;&#33021;&#30340;&#27010;&#29575;&#25551;&#36848;&#24418;&#24335;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#20197;&#22312;&#21463;&#38480;&#20960;&#20309;&#20013;&#20855;&#26377;&#25490;&#38500;&#20307;&#31215;&#30456;&#20114;&#20316;&#29992;&#30340;&#24040;&#27491;&#21017;&#19968;&#32500;&#31890;&#23376;&#38598;&#21512;&#20026;&#20363;&#36827;&#34892;&#20102;&#35828;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
The swift progression of machine learning (ML) have not gone unnoticed in the realm of statistical mechanics. ML techniques have attracted attention by the classical density-functional theory (DFT) community, as they enable discovery of free-energy functionals to determine the equilibrium-density profile of a many-particle system. Within DFT, the external potential accounts for the interaction of the many-particle system with an external field, thus, affecting the density distribution. In this context, we introduce a statistical-learning framework to infer the external potential exerted on a many-particle system. We combine a Bayesian inference approach with the classical DFT apparatus to reconstruct the external potential, yielding a probabilistic description of the external potential functional form with inherent uncertainty quantification. Our framework is exemplified with a grand-canonical one-dimensional particle ensemble with excluded volume interactions in a confined geometry. T
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#38750;&#21442;&#25968;&#20984;&#21270;&#28388;&#27874;&#65288;DNCF&#65289;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#35745;&#31639;&#25668;&#24433;&#39046;&#22495;&#20013;&#30340;&#22270;&#20687;&#24674;&#22797;&#12290;DNCF&#20855;&#26377;&#24378;&#22823;&#30340;&#27867;&#21270;&#24615;&#21644;&#23545;&#25239;&#24615;&#22270;&#20687;&#22788;&#29702;&#30340;&#40065;&#26834;&#24615;&#65292;&#21516;&#26102;&#33021;&#22815;&#23454;&#29616;&#23454;&#26102;&#30340;&#23545;&#25239;&#24615;&#22270;&#20687;&#20998;&#31867;&#32593;&#32476;&#38450;&#24481;&#12290;</title><link>http://arxiv.org/abs/2309.06724</link><description>&lt;p&gt;
&#28145;&#24230;&#38750;&#21442;&#25968;&#20984;&#21270;&#28388;&#27874;&#22312;&#35745;&#31639;&#25668;&#24433;&#65292;&#22270;&#20687;&#21512;&#25104;&#21644;&#23545;&#25239;&#24615;&#38450;&#24481;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Deep Nonparametric Convexified Filtering for Computational Photography, Image Synthesis and Adversarial Defense. (arXiv:2309.06724v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06724
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#38750;&#21442;&#25968;&#20984;&#21270;&#28388;&#27874;&#65288;DNCF&#65289;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#35745;&#31639;&#25668;&#24433;&#39046;&#22495;&#20013;&#30340;&#22270;&#20687;&#24674;&#22797;&#12290;DNCF&#20855;&#26377;&#24378;&#22823;&#30340;&#27867;&#21270;&#24615;&#21644;&#23545;&#25239;&#24615;&#22270;&#20687;&#22788;&#29702;&#30340;&#40065;&#26834;&#24615;&#65292;&#21516;&#26102;&#33021;&#22815;&#23454;&#29616;&#23454;&#26102;&#30340;&#23545;&#25239;&#24615;&#22270;&#20687;&#20998;&#31867;&#32593;&#32476;&#38450;&#24481;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#26088;&#22312;&#25552;&#20379;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#20174;&#19981;&#23436;&#32654;&#30340;&#22270;&#20687;&#20013;&#24674;&#22797;&#30495;&#23454;&#22330;&#26223;&#30340;&#35745;&#31639;&#25668;&#24433;&#65292;&#36890;&#36807;&#28145;&#24230;&#38750;&#21442;&#25968;&#20984;&#21270;&#28388;&#27874;&#65288;DNCF&#65289;&#12290;&#23427;&#30001;&#19968;&#20010;&#38750;&#21442;&#25968;&#28145;&#24230;&#32593;&#32476;&#32452;&#25104;&#65292;&#20197;&#27169;&#25311;&#22270;&#20687;&#24418;&#25104;&#32972;&#21518;&#30340;&#29289;&#29702;&#26041;&#31243;&#65292;&#22914;&#38477;&#22122;&#12289;&#36229;&#20998;&#36776;&#29575;&#12289;&#20462;&#22797;&#21644;&#38378;&#20809;&#12290;DNCF&#27809;&#26377;&#20381;&#36182;&#20110;&#35757;&#32451;&#25968;&#25454;&#30340;&#21442;&#25968;&#21270;&#65292;&#22240;&#27492;&#20855;&#26377;&#24378;&#22823;&#30340;&#27867;&#21270;&#24615;&#21644;&#23545;&#25239;&#24615;&#22270;&#20687;&#22788;&#29702;&#30340;&#40065;&#26834;&#24615;&#12290;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#36824;&#40723;&#21169;&#32593;&#32476;&#21442;&#25968;&#20026;&#38750;&#36127;&#65292;&#24182;&#22312;&#36755;&#20837;&#21644;&#21442;&#25968;&#19978;&#21019;&#24314;&#19968;&#20010;&#21452;&#20984;&#20989;&#25968;&#65292;&#36825;&#36866;&#24212;&#20110;&#36816;&#34892;&#26102;&#38388;&#19981;&#36275;&#30340;&#20108;&#38454;&#20248;&#21270;&#31639;&#27861;&#65292;&#30456;&#23545;&#20110;Deep Image Prior&#26377;10&#20493;&#30340;&#21152;&#36895;&#12290;&#36890;&#36807;&#36825;&#20123;&#24037;&#20855;&#65292;&#25105;&#20204;&#22312;&#23454;&#26102;&#20013;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#23545;&#25239;&#22270;&#20687;&#20998;&#31867;&#28145;&#24230;&#32593;&#32476;&#25915;&#20987;&#31639;&#27861;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We aim to provide a general framework of for computational photography that recovers the real scene from imperfect images, via the Deep Nonparametric Convexified Filtering (DNCF). It is consists of a nonparametric deep network to resemble the physical equations behind the image formation, such as denoising, super-resolution, inpainting, and flash. DNCF has no parameterization dependent on training data, therefore has a strong generalization and robustness to adversarial image manipulation. During inference, we also encourage the network parameters to be nonnegative and create a bi-convex function on the input and parameters, and this adapts to second-order optimization algorithms with insufficient running time, having 10X acceleration over Deep Image Prior. With these tools, we empirically verify its capability to defend image classification deep networks against adversary attack algorithms in real-time.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#39640;&#38454;HSIC&#30340;&#26041;&#27861;&#65292;&#22312;&#23398;&#20064;Bayesian&#32593;&#32476;&#20013;&#35299;&#20915;&#20102;&#23616;&#37096;&#21464;&#37327;&#21516;&#26102;&#20855;&#26377;&#30452;&#25509;&#21644;&#38388;&#25509;&#20381;&#36182;&#20851;&#31995;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#30830;&#23450;&#23376;&#38598;&#21644;&#20004;&#38454;&#27573;&#31639;&#27861;&#26469;&#36827;&#34892;&#23616;&#37096;&#20462;&#27491;&#65292;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.05969</link><description>&lt;p&gt;
&#36890;&#36807;&#39640;&#38454;HSIC&#23398;&#20064;&#20855;&#26377;&#22686;&#37327;&#20449;&#24687;&#30340;&#38750;&#21442;&#25968;DAGs
&lt;/p&gt;
&lt;p&gt;
Learning nonparametric DAGs with incremental information via high-order HSIC. (arXiv:2308.05969v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05969
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#39640;&#38454;HSIC&#30340;&#26041;&#27861;&#65292;&#22312;&#23398;&#20064;Bayesian&#32593;&#32476;&#20013;&#35299;&#20915;&#20102;&#23616;&#37096;&#21464;&#37327;&#21516;&#26102;&#20855;&#26377;&#30452;&#25509;&#21644;&#38388;&#25509;&#20381;&#36182;&#20851;&#31995;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#30830;&#23450;&#23376;&#38598;&#21644;&#20004;&#38454;&#27573;&#31639;&#27861;&#26469;&#36827;&#34892;&#23616;&#37096;&#20462;&#27491;&#65292;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#23398;&#20064;&#36125;&#21494;&#26031;&#32593;&#32476;&#65288;BN&#65289;&#30340;&#22522;&#20110;&#35780;&#20998;&#30340;&#26041;&#27861;&#65292;&#30446;&#26631;&#26159;&#26368;&#22823;&#21270;&#20840;&#23616;&#35780;&#20998;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#22914;&#26524;&#23616;&#37096;&#21464;&#37327;&#21516;&#26102;&#20855;&#26377;&#30452;&#25509;&#21644;&#38388;&#25509;&#20381;&#36182;&#20851;&#31995;&#65292;&#37027;&#20040;&#22522;&#20110;&#35780;&#20998;&#20989;&#25968;&#30340;&#20840;&#23616;&#20248;&#21270;&#23558;&#24573;&#30053;&#20855;&#26377;&#38388;&#25509;&#20381;&#36182;&#20851;&#31995;&#30340;&#21464;&#37327;&#20043;&#38388;&#30340;&#36793;&#32536;&#65292;&#20854;&#24471;&#20998;&#23567;&#20110;&#20855;&#26377;&#30452;&#25509;&#20381;&#36182;&#20851;&#31995;&#30340;&#36793;&#32536;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#30830;&#23450;&#23376;&#38598;&#30340;&#21487;&#36776;&#35782;&#24615;&#26465;&#20214;&#65292;&#20197;&#35782;&#21035;&#28508;&#22312;&#30340;DAG&#12290;&#36890;&#36807;&#21487;&#36776;&#35782;&#24615;&#26465;&#20214;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#31639;&#27861;&#65292;&#21363;&#26368;&#20248;&#35843;&#25972;&#65288;OT&#65289;&#31639;&#27861;&#65292;&#20197;&#22312;&#20840;&#23616;&#20248;&#21270;&#30340;&#22522;&#30784;&#19978;&#36827;&#34892;&#23616;&#37096;&#20462;&#27491;&#12290;&#22312;&#26368;&#20248;&#38454;&#27573;&#65292;&#22522;&#20110;&#19968;&#38454;Hilbert-Schmidt&#29420;&#31435;&#24615;&#20934;&#21017;&#65288;HSIC&#65289;&#30340;&#20248;&#21270;&#38382;&#39064;&#32473;&#20986;&#20102;&#19968;&#20010;&#20272;&#35745;&#30340;&#39592;&#26550;&#20316;&#20026;&#21021;&#22987;&#30830;&#23450;&#30340;&#29238;&#33410;&#28857;&#23376;&#38598;&#12290;&#22312;&#35843;&#25972;&#38454;&#27573;&#65292;&#26681;&#25454;&#39640;&#38454;HSIC&#30340;&#29702;&#35770;&#35777;&#26126;&#22686;&#37327;&#29305;&#24615;&#65292;&#23545;&#39592;&#26550;&#36827;&#34892;&#23616;&#37096;&#35843;&#25972;&#65292;&#21253;&#25324;&#21024;&#38500;&#12289;&#28155;&#21152;&#21644;DAG&#26684;&#24335;&#21270;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based methods for learning Bayesain networks(BN) aim to maximizing the global score functions. However, if local variables have direct and indirect dependence simultaneously, the global optimization on score functions misses edges between variables with indirect dependent relationship, of which scores are smaller than those with direct dependent relationship. In this paper, we present an identifiability condition based on a determined subset of parents to identify the underlying DAG. By the identifiability condition, we develop a two-phase algorithm namely optimal-tuning (OT) algorithm to locally amend the global optimization. In the optimal phase, an optimization problem based on first-order Hilbert-Schmidt independence criterion (HSIC) gives an estimated skeleton as the initial determined parents subset. In the tuning phase, the skeleton is locally tuned by deletion, addition and DAG-formalization strategies using the theoretically proved incremental properties of high-order HS
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36712;&#36857;&#30340;&#20248;&#21270;&#26041;&#27861;&#26469;&#22788;&#29702;&#38543;&#26426;&#27969;&#34892;&#30149;&#23398;&#27169;&#22411;&#65292;&#21487;&#20197;&#25214;&#21040;&#19982;&#23454;&#38469;&#35266;&#27979;&#20540;&#25509;&#36817;&#30340;&#23454;&#38469;&#36712;&#36857;&#65292;&#32780;&#19981;&#26159;&#20165;&#20351;&#24179;&#22343;&#27169;&#25311;&#32467;&#26524;&#19982;&#23454;&#27979;&#25968;&#25454;&#30456;&#31526;&#12290;</title><link>http://arxiv.org/abs/2305.03926</link><description>&lt;p&gt;
&#22522;&#20110;&#36712;&#36857;&#30340;&#38543;&#26426;&#27969;&#34892;&#30149;&#23398;&#27169;&#22411;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Trajectory-oriented optimization of stochastic epidemiological models. (arXiv:2305.03926v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03926
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36712;&#36857;&#30340;&#20248;&#21270;&#26041;&#27861;&#26469;&#22788;&#29702;&#38543;&#26426;&#27969;&#34892;&#30149;&#23398;&#27169;&#22411;&#65292;&#21487;&#20197;&#25214;&#21040;&#19982;&#23454;&#38469;&#35266;&#27979;&#20540;&#25509;&#36817;&#30340;&#23454;&#38469;&#36712;&#36857;&#65292;&#32780;&#19981;&#26159;&#20165;&#20351;&#24179;&#22343;&#27169;&#25311;&#32467;&#26524;&#19982;&#23454;&#27979;&#25968;&#25454;&#30456;&#31526;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#38543;&#26426;&#27169;&#22411;&#65292;&#20026;&#20102;&#36827;&#34892;&#39044;&#27979;&#21644;&#36816;&#34892;&#27169;&#25311;&#65292;&#38656;&#35201;&#36827;&#34892;&#22320;&#38754;&#23454;&#27979;&#26631;&#23450;&#12290;&#30001;&#20110;&#36755;&#20986;&#32467;&#26524;&#36890;&#24120;&#26159;&#36890;&#36807;&#38598;&#25104;&#25110;&#20998;&#24067;&#26469;&#25551;&#36848;&#65292;&#22240;&#27492;&#38656;&#35201;&#23545;&#27599;&#20010;&#25104;&#21592;&#36827;&#34892;&#26631;&#23450;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#20195;&#29702;&#21644;Thompson&#37319;&#26679;&#30340;&#20248;&#21270;&#31574;&#30053;&#26469;&#23547;&#25214;&#19982;&#20107;&#23454;&#30456;&#19968;&#33268;&#30340;&#36755;&#20837;&#21442;&#25968;&#35774;&#32622;&#21644;&#38543;&#26426;&#25968;&#31181;&#23376;&#65292;&#35813;Trajectory Oriented Optimization&#65288;TOO&#65289;&#26041;&#27861;&#21487;&#20197;&#20135;&#29983;&#19982;&#23454;&#38469;&#35266;&#27979;&#20540;&#25509;&#36817;&#30340;&#23454;&#38469;&#36712;&#36857;&#65292;&#32780;&#19981;&#26159;&#20165;&#34429;&#28982;&#27169;&#25311;&#30340;&#24179;&#22343;&#34892;&#20026;&#19982;&#20107;&#23454;&#30456;&#31526;&#12290;
&lt;/p&gt;
&lt;p&gt;
Epidemiological models must be calibrated to ground truth for downstream tasks such as producing forward projections or running what-if scenarios. The meaning of calibration changes in case of a stochastic model since output from such a model is generally described via an ensemble or a distribution. Each member of the ensemble is usually mapped to a random number seed (explicitly or implicitly). With the goal of finding not only the input parameter settings but also the random seeds that are consistent with the ground truth, we propose a class of Gaussian process (GP) surrogates along with an optimization strategy based on Thompson sampling. This Trajectory Oriented Optimization (TOO) approach produces actual trajectories close to the empirical observations instead of a set of parameter settings where only the mean simulation behavior matches with the ground truth.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21457;&#29616;&#65292;&#20855;&#26377;&#23545;&#25968;S&#22411;&#28608;&#27963;&#20989;&#25968;&#30340;&#20219;&#24847;&#28145;&#24230;&#30340;&#19968;&#32500;&#31070;&#32463;&#32593;&#32476;&#26368;&#22810;&#21482;&#26377;&#19977;&#20010;&#19981;&#21160;&#28857;&#65292;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24212;&#29992;&#21644;&#29702;&#35770;&#20043;&#38388;&#26500;&#24314;&#20102;&#19968;&#20010;&#24517;&#35201;&#30340;&#26725;&#26753;&#12290;</title><link>http://arxiv.org/abs/2303.12814</link><description>&lt;p&gt;
&#20219;&#24847;&#28145;&#24230;&#30340;&#19968;&#32500;&#31070;&#32463;&#32593;&#32476;&#30340;&#19981;&#21160;&#28857;
&lt;/p&gt;
&lt;p&gt;
Fixed points of arbitrarily deep 1-dimensional neural networks. (arXiv:2303.12814v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12814
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21457;&#29616;&#65292;&#20855;&#26377;&#23545;&#25968;S&#22411;&#28608;&#27963;&#20989;&#25968;&#30340;&#20219;&#24847;&#28145;&#24230;&#30340;&#19968;&#32500;&#31070;&#32463;&#32593;&#32476;&#26368;&#22810;&#21482;&#26377;&#19977;&#20010;&#19981;&#21160;&#28857;&#65292;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24212;&#29992;&#21644;&#29702;&#35770;&#20043;&#38388;&#26500;&#24314;&#20102;&#19968;&#20010;&#24517;&#35201;&#30340;&#26725;&#26753;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#22312;$\mathbb{R}$&#19978;&#20855;&#26377;&#21512;&#25104;&#24615;&#19988;&#21253;&#21547;&#23545;&#25968;S&#22411;&#20989;&#25968;&#30340;&#26032;&#20989;&#25968;&#31867;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#20010;&#31867;&#26469;&#35777;&#26126;&#20855;&#26377;&#23545;&#25968;S&#22411;&#28608;&#27963;&#20989;&#25968;&#30340;&#20219;&#24847;&#28145;&#24230;&#30340;&#19968;&#32500;&#31070;&#32463;&#32593;&#32476;&#26368;&#22810;&#21482;&#26377;&#19977;&#20010;&#19981;&#21160;&#28857;&#12290;&#34429;&#28982;&#36825;&#26679;&#30340;&#31070;&#32463;&#32593;&#32476;&#36828;&#31163;&#23454;&#38469;&#24212;&#29992;&#65292;&#20294;&#25105;&#20204;&#33021;&#22815;&#23436;&#20840;&#29702;&#35299;&#23427;&#20204;&#30340;&#19981;&#21160;&#28857;&#65292;&#24182;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24212;&#29992;&#21644;&#29702;&#35770;&#20043;&#38388;&#26500;&#24314;&#20102;&#19968;&#20010;&#24517;&#35201;&#30340;&#26725;&#26753;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce a new class of functions on $\mathbb{R}$ that is closed under composition, and contains the logistic sigmoid function. We use this class to show that any 1-dimensional neural network of arbitrary depth with logistic sigmoid activation functions has at most three fixed points. While such neural networks are far from real world applications, we are able to completely understand their fixed points, providing a foundation to the much needed connection between application and theory of deep neural networks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24212;&#23545;&#28151;&#28102;&#22240;&#32032;&#30340;&#26680;&#26465;&#20214;&#30697;&#32422;&#26463;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#26680;&#26041;&#27861;&#24471;&#21040;&#30340;&#26465;&#20214;&#30697;&#32422;&#26463;&#30340;&#36817;&#20284;&#20272;&#35745;&#22120;&#65292;&#23454;&#29616;&#20102;&#23545;&#25919;&#31574;&#35780;&#20272;&#30340;&#23574;&#38160;&#19979;&#30028;&#20272;&#35745;&#65292;&#24182;&#33021;&#23545;&#32463;&#20856;&#36793;&#38469;&#25935;&#24863;&#24230;&#27169;&#22411;&#36827;&#34892;&#26032;&#39062;&#25193;&#23637;&#12290;</title><link>http://arxiv.org/abs/2302.13348</link><description>&lt;p&gt;
Kernel Conditional Moment Constraints for Confounding Robust Inference. (arXiv:2302.13348v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
Kernel Conditional Moment Constraints for Confounding Robust Inference. (arXiv:2302.13348v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.13348
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24212;&#23545;&#28151;&#28102;&#22240;&#32032;&#30340;&#26680;&#26465;&#20214;&#30697;&#32422;&#26463;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#26680;&#26041;&#27861;&#24471;&#21040;&#30340;&#26465;&#20214;&#30697;&#32422;&#26463;&#30340;&#36817;&#20284;&#20272;&#35745;&#22120;&#65292;&#23454;&#29616;&#20102;&#23545;&#25919;&#31574;&#35780;&#20272;&#30340;&#23574;&#38160;&#19979;&#30028;&#20272;&#35745;&#65292;&#24182;&#33021;&#23545;&#32463;&#20856;&#36793;&#38469;&#25935;&#24863;&#24230;&#27169;&#22411;&#36827;&#34892;&#26032;&#39062;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#31163;&#32447;&#24773;&#22659;&#25512;&#26029;&#20013;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#23545;&#25919;&#31574;&#35780;&#20272;&#30340;&#24433;&#21709;&#12290;&#25935;&#24863;&#24615;&#20998;&#26512;&#26041;&#27861;&#36890;&#24120;&#29992;&#20110;&#22312;&#32473;&#23450;&#19981;&#30830;&#23450;&#24615;&#38598;&#19978;&#20272;&#35745;&#26368;&#22351;&#28151;&#28102;&#24773;&#20917;&#19979;&#30340;&#25919;&#31574;&#20215;&#20540;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#24037;&#20316;&#24448;&#24448;&#20026;&#20102;&#21487;&#34892;&#24615;&#32780;&#37319;&#29992;&#19968;&#20123;&#31895;&#30053;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#30340;&#25918;&#26494;&#65292;&#23548;&#33268;&#23545;&#25919;&#31574;&#20215;&#20540;&#30340;&#36807;&#24230;&#20445;&#23432;&#20272;&#35745;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#20272;&#35745;&#22120;&#65292;&#23427;&#25552;&#20379;&#20102;&#25919;&#31574;&#20215;&#20540;&#30340;&#23574;&#38160;&#19979;&#30028;&#12290;&#21487;&#20197;&#35777;&#26126;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#21253;&#21547;&#20102;Dorn&#21644;Guo&#65288;2022&#24180;&#65289;&#26368;&#36817;&#25552;&#20986;&#30340;&#23574;&#38160;&#20272;&#35745;&#22120;&#20316;&#20026;&#19968;&#20010;&#29305;&#20363;&#65292;&#32780;&#25105;&#20204;&#30340;&#26041;&#27861;&#21017;&#21033;&#29992;f-&#25955;&#24230;&#26469;&#23454;&#29616;&#23545;&#32463;&#20856;&#36793;&#38469;&#25935;&#24863;&#24230;&#27169;&#22411;&#30340;&#26032;&#39062;&#25193;&#23637;&#12290;&#20026;&#20102;&#26500;&#24314;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#65292;&#25105;&#20204;&#21033;&#29992;&#26680;&#26041;&#27861;&#24471;&#21040;&#20102;&#26465;&#20214;&#30697;&#32422;&#26463;&#30340;&#21487;&#34892;&#36817;&#20284;&#65292;&#32780;&#20256;&#32479;&#30340;&#38750;&#23574;&#38160;&#20272;&#35745;&#22120;&#21017;&#26410;&#33021;&#32771;&#34385;&#21040;&#36825;&#19968;&#28857;&#12290;&#22312;&#29702;&#35770;&#20998;&#26512;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#26465;&#20214;&#65292;&#29992;&#20110;&#38477;&#20302;&#20256;&#32479;&#38750;&#23574;&#38160;&#20272;&#35745;&#22120;&#21463;&#28151;&#28102;&#22240;&#32032;&#24433;&#21709;&#30340;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study policy evaluation of offline contextual bandits subject to unobserved confounders. Sensitivity analysis methods are commonly used to estimate the policy value under the worst-case confounding over a given uncertainty set. However, existing work often resorts to some coarse relaxation of the uncertainty set for the sake of tractability, leading to overly conservative estimation of the policy value. In this paper, we propose a general estimator that provides a sharp lower bound of the policy value. It can be shown that our estimator contains the recently proposed sharp estimator by Dorn and Guo (2022) as a special case, and our method enables a novel extension of the classical marginal sensitivity model using f-divergence. To construct our estimator, we leverage the kernel method to obtain a tractable approximation to the conditional moment constraints, which traditional non-sharp estimators failed to take into account. In the theoretical analysis, we provide a condition for the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#24102;&#38543;&#26426;&#20808;&#39564;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#29992;&#20110;&#39640;&#32500;&#36755;&#20986;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#21487;&#26377;&#25928;&#22320;&#22788;&#29702;&#20840;&#23616;&#20248;&#21270;&#38382;&#39064;&#65292;&#21363;&#20351;&#22312;&#39640;&#32500;&#24230;&#21521;&#37327;&#31354;&#38388;&#25110;&#26080;&#38480;&#32500;&#20989;&#25968;&#31354;&#38388;&#20013;&#20063;&#33021;&#36817;&#20284;&#21151;&#33021;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2302.07260</link><description>&lt;p&gt;
&#22522;&#20110;&#38543;&#26426;&#20808;&#39564;&#32593;&#32476;&#30340;&#39640;&#32500;&#36755;&#20986;&#21487;&#25193;&#23637;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Scalable Bayesian optimization with high-dimensional outputs using randomized prior networks. (arXiv:2302.07260v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07260
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#24102;&#38543;&#26426;&#20808;&#39564;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#29992;&#20110;&#39640;&#32500;&#36755;&#20986;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#21487;&#26377;&#25928;&#22320;&#22788;&#29702;&#20840;&#23616;&#20248;&#21270;&#38382;&#39064;&#65292;&#21363;&#20351;&#22312;&#39640;&#32500;&#24230;&#21521;&#37327;&#31354;&#38388;&#25110;&#26080;&#38480;&#32500;&#20989;&#25968;&#31354;&#38388;&#20013;&#20063;&#33021;&#36817;&#20284;&#21151;&#33021;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#30340;&#19968;&#20123;&#22522;&#26412;&#38382;&#39064;&#28041;&#21450;&#21040;&#26410;&#30693;&#30340;&#39640;&#32500;&#24230;&#26144;&#23556;&#19968;&#32452;&#21487;&#25511;&#21464;&#37327;&#21040;&#26114;&#36149;&#23454;&#39564;&#32467;&#26524;&#30340;&#40657;&#30418;&#20989;&#25968;&#30340;&#20840;&#23616;&#20248;&#21270;&#20219;&#21153;&#12290;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#25216;&#26415;&#24050;&#34987;&#35777;&#26126;&#22312;&#20351;&#29992;&#30456;&#23545;&#36739;&#23569;&#30340;&#30446;&#26631;&#20989;&#25968;&#35780;&#20272;&#26102;&#22788;&#29702;&#20840;&#23616;&#20248;&#21270;&#38382;&#39064;&#26102;&#38750;&#24120;&#26377;&#25928;&#65292;&#20294;&#24403;&#22788;&#29702;&#39640;&#32500;&#36755;&#20986;&#26102;&#65292;&#20854;&#24615;&#33021;&#21463;&#21040;&#24433;&#21709;&#12290;&#20026;&#20811;&#26381;&#32500;&#24230;&#20027;&#35201;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#24102;&#38543;&#26426;&#20808;&#39564;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#33258;&#20030;&#38598;&#25104;&#30340;BO&#21644;&#24207;&#36143;&#20915;&#31574;&#21046;&#23450;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#12290;&#20351;&#29992;&#36866;&#24403;&#30340;&#20307;&#31995;&#32467;&#26500;&#36873;&#25321;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#21487;&#20197;&#36817;&#20284;&#35774;&#35745;&#21464;&#37327;&#21644;&#24863;&#20852;&#36259;&#37327;&#20043;&#38388;&#30340;&#21151;&#33021;&#20851;&#31995;&#65292;&#21363;&#20351;&#22312;&#21518;&#32773;&#21462;&#20540;&#20110;&#39640;&#32500;&#21521;&#37327;&#31354;&#38388;&#25110;&#29978;&#33267;&#26080;&#38480;&#32500;&#20989;&#25968;&#31354;&#38388;&#30340;&#24773;&#20917;&#19979;&#12290;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#32972;&#26223;&#19979;&#65292;&#35813;&#26041;&#27861;&#20801;&#35768;&#39640;&#25928;&#21644;&#21487;&#25193;&#23637;&#30340;&#22788;&#29702;&#39640;&#32500;&#24230;&#40657;&#30418;&#20989;&#25968;&#30340;&#20840;&#23616;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several fundamental problems in science and engineering consist of global optimization tasks involving unknown high-dimensional (black-box) functions that map a set of controllable variables to the outcomes of an expensive experiment. Bayesian Optimization (BO) techniques are known to be effective in tackling global optimization problems using a relatively small number objective function evaluations, but their performance suffers when dealing with high-dimensional outputs. To overcome the major challenge of dimensionality, here we propose a deep learning framework for BO and sequential decision making based on bootstrapped ensembles of neural architectures with randomized priors. Using appropriate architecture choices, we show that the proposed framework can approximate functional relationships between design variables and quantities of interest, even in cases where the latter take values in high-dimensional vector spaces or even infinite-dimensional function spaces. In the context of 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36830;&#32493;&#26102;&#38388;&#27969;&#27169;&#22411;&#8212;&#8212;&#20027;&#35201;&#27969;&#65288;PF&#65289;&#65292;&#36890;&#36807;&#23545;Hessian&#30697;&#38453;&#29305;&#24449;&#20998;&#35299;&#30340;&#20381;&#36182;&#65292;&#25429;&#25417;&#21040;&#20102;&#26799;&#24230;&#19979;&#38477;&#20013;&#30340;&#21457;&#25955;&#21644;&#25391;&#33633;&#34892;&#20026;&#12289;&#36867;&#36920;&#23616;&#37096;&#26497;&#23567;&#20540;&#21644;&#38797;&#28857;&#30340;&#36830;&#32493;&#24615;&#27969;&#65292;&#24182;&#35299;&#37322;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#31283;&#23450;&#36793;&#32536;&#29616;&#35937;&#12290;&#36890;&#36807;&#23545;&#19981;&#31283;&#23450;&#24615;&#30340;&#26032;&#29702;&#35299;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#29575;&#36866;&#24212;&#26041;&#27861;&#65292;&#21487;&#20197;&#25511;&#21046;&#35757;&#32451;&#31283;&#23450;&#24615;&#21644;&#27979;&#35797;&#38598;&#35780;&#20272;&#24615;&#33021;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2302.01952</link><description>&lt;p&gt;
&#20851;&#20110;&#26799;&#24230;&#19979;&#38477;&#21160;&#24577;&#21644;&#28145;&#24230;&#23398;&#20064;&#19981;&#31283;&#23450;&#24615;&#30340;&#36830;&#32493;&#26102;&#38388;&#27169;&#22411;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On a continuous time model of gradient descent dynamics and instability in deep learning. (arXiv:2302.01952v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.01952
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36830;&#32493;&#26102;&#38388;&#27969;&#27169;&#22411;&#8212;&#8212;&#20027;&#35201;&#27969;&#65288;PF&#65289;&#65292;&#36890;&#36807;&#23545;Hessian&#30697;&#38453;&#29305;&#24449;&#20998;&#35299;&#30340;&#20381;&#36182;&#65292;&#25429;&#25417;&#21040;&#20102;&#26799;&#24230;&#19979;&#38477;&#20013;&#30340;&#21457;&#25955;&#21644;&#25391;&#33633;&#34892;&#20026;&#12289;&#36867;&#36920;&#23616;&#37096;&#26497;&#23567;&#20540;&#21644;&#38797;&#28857;&#30340;&#36830;&#32493;&#24615;&#27969;&#65292;&#24182;&#35299;&#37322;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#31283;&#23450;&#36793;&#32536;&#29616;&#35937;&#12290;&#36890;&#36807;&#23545;&#19981;&#31283;&#23450;&#24615;&#30340;&#26032;&#29702;&#35299;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#29575;&#36866;&#24212;&#26041;&#27861;&#65292;&#21487;&#20197;&#25511;&#21046;&#35757;&#32451;&#31283;&#23450;&#24615;&#21644;&#27979;&#35797;&#38598;&#35780;&#20272;&#24615;&#33021;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#25104;&#21151;&#30340;&#31192;&#35776;&#22312;&#20110;&#31070;&#32463;&#32593;&#32476;&#21644;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#30340;&#32467;&#21512;&#12290;&#28982;&#32780;&#65292;&#29702;&#35299;&#26799;&#24230;&#19979;&#38477;&#30340;&#34892;&#20026;&#65292;&#29305;&#21035;&#26159;&#20854;&#19981;&#31283;&#23450;&#24615;&#65292;&#33853;&#21518;&#20110;&#20854;&#32463;&#39564;&#25104;&#21151;&#12290;&#20026;&#20102;&#22686;&#21152;&#30740;&#31350;&#26799;&#24230;&#19979;&#38477;&#30340;&#29702;&#35770;&#24037;&#20855;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20027;&#35201;&#27969;&#65288;PF&#65289;&#65292;&#19968;&#31181;&#36817;&#20284;&#26799;&#24230;&#19979;&#38477;&#21160;&#24577;&#30340;&#36830;&#32493;&#26102;&#38388;&#27969;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;PF&#26159;&#21807;&#19968;&#25429;&#25417;&#21040;&#26799;&#24230;&#19979;&#38477;&#30340;&#21457;&#25955;&#21644;&#25391;&#33633;&#34892;&#20026;&#65292;&#21253;&#25324;&#36867;&#36920;&#23616;&#37096;&#26497;&#23567;&#20540;&#21644;&#38797;&#28857;&#30340;&#36830;&#32493;&#24615;&#27969;&#12290;&#36890;&#36807;&#20854;&#23545;&#20110;Hessian&#29305;&#24449;&#20998;&#35299;&#30340;&#20381;&#36182;&#65292;PF&#35299;&#37322;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#26368;&#36817;&#35266;&#23519;&#21040;&#30340;&#31283;&#23450;&#36793;&#32536;&#29616;&#35937;&#12290;&#36890;&#36807;&#23545;&#19981;&#31283;&#23450;&#24615;&#30340;&#26032;&#29702;&#35299;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#29575;&#36866;&#24212;&#26041;&#27861;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#25511;&#21046;&#35757;&#32451;&#31283;&#23450;&#24615;&#21644;&#27979;&#35797;&#38598;&#35780;&#20272;&#24615;&#33021;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recipe behind the success of deep learning has been the combination of neural networks and gradient-based optimization. Understanding the behavior of gradient descent however, and particularly its instability, has lagged behind its empirical success. To add to the theoretical tools available to study gradient descent we propose the principal flow (PF), a continuous time flow that approximates gradient descent dynamics. To our knowledge, the PF is the only continuous flow that captures the divergent and oscillatory behaviors of gradient descent, including escaping local minima and saddle points. Through its dependence on the eigendecomposition of the Hessian the PF sheds light on the recently observed edge of stability phenomena in deep learning. Using our new understanding of instability we propose a learning rate adaptation method which enables us to control the trade-off between training stability and test set evaluation performance.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;&#30340;&#20195;&#29702;&#27169;&#22411;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#28145;&#24230;&#23398;&#20064;&#31995;&#32479;&#34892;&#20026;&#39044;&#27979;&#21644;&#26550;&#26500;&#31639;&#27861;&#36873;&#25321;&#30340;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#27169;&#22411;&#22312;&#25429;&#25417;&#29616;&#35937;&#12289;&#30830;&#23450;&#20851;&#38190;&#25968;&#25454;&#28857;&#21644;&#39044;&#27979;&#27867;&#21270;&#33021;&#21147;&#26041;&#38754;&#30340;&#23454;&#38469;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2208.06028</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#20195;&#29702;&#27169;&#22411;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Gaussian Process Surrogate Models for Neural Networks. (arXiv:2208.06028v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.06028
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;&#30340;&#20195;&#29702;&#27169;&#22411;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#28145;&#24230;&#23398;&#20064;&#31995;&#32479;&#34892;&#20026;&#39044;&#27979;&#21644;&#26550;&#26500;&#31639;&#27861;&#36873;&#25321;&#30340;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#27169;&#22411;&#22312;&#25429;&#25417;&#29616;&#35937;&#12289;&#30830;&#23450;&#20851;&#38190;&#25968;&#25454;&#28857;&#21644;&#39044;&#27979;&#27867;&#21270;&#33021;&#21147;&#26041;&#38754;&#30340;&#23454;&#38469;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#27861;&#29702;&#35299;&#21644;&#39044;&#27979;&#28145;&#24230;&#23398;&#20064;&#31995;&#32479;&#30340;&#34892;&#20026;&#20351;&#24471;&#24456;&#38590;&#20915;&#23450;&#38024;&#23545;&#32473;&#23450;&#38382;&#39064;&#20351;&#29992;&#20160;&#20040;&#26550;&#26500;&#21644;&#31639;&#27861;&#12290;&#22312;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#65292;&#24314;&#27169;&#26159;&#19968;&#31181;&#29992;&#20110;&#29702;&#35299;&#22797;&#26434;&#31995;&#32479;&#30340;&#26041;&#27861;&#35770;&#65292;&#20854;&#20869;&#37096;&#36807;&#31243;&#26159;&#19981;&#36879;&#26126;&#30340;&#12290;&#24314;&#27169;&#29992;&#31616;&#21270;&#30340;&#12289;&#21487;&#35299;&#37322;&#30340;&#26367;&#20195;&#31616;&#21270;&#31995;&#32479;&#12290;&#21463;&#27492;&#21551;&#21457;&#65292;&#25105;&#20204;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#26500;&#24314;&#20102;&#19968;&#31867;&#31070;&#32463;&#32593;&#32476;&#30340;&#20195;&#29702;&#27169;&#22411;&#12290;&#25105;&#20204;&#19981;&#26159;&#20174;&#26080;&#38480;&#31070;&#32463;&#32593;&#32476;&#25512;&#23548;&#20869;&#26680;&#65292;&#32780;&#26159;&#20174;&#26377;&#38480;&#31070;&#32463;&#32593;&#32476;&#30340;&#33258;&#28982;&#34892;&#20026;&#20013;&#32463;&#39564;&#24615;&#22320;&#23398;&#20064;&#20869;&#26680;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#25429;&#25417;&#21040;&#20102;&#19982;&#31070;&#32463;&#32593;&#32476;&#39057;&#35889;&#20559;&#24046;&#30456;&#20851;&#30340;&#29616;&#35937;&#65292;&#24182;&#19988;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#20195;&#29702;&#27169;&#22411;&#21487;&#20197;&#29992;&#20110;&#35299;&#20915;&#23454;&#38469;&#38382;&#39064;&#65292;&#22914;&#30830;&#23450;&#21738;&#20123;&#28857;&#23545;&#29305;&#23450;&#31070;&#32463;&#32593;&#32476;&#30340;&#34892;&#20026;&#24433;&#21709;&#26368;&#22823;&#65292;&#24182;&#39044;&#27979;&#21738;&#20123;&#26550;&#26500;&#21644;&#31639;&#27861;&#23545;&#29305;&#23450;&#25968;&#25454;&#38598;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Not being able to understand and predict the behavior of deep learning systems makes it hard to decide what architecture and algorithm to use for a given problem. In science and engineering, modeling is a methodology used to understand complex systems whose internal processes are opaque. Modeling replaces a complex system with a simpler, more interpretable surrogate. Drawing inspiration from this, we construct a class of surrogate models for neural networks using Gaussian processes. Rather than deriving kernels for infinite neural networks, we learn kernels empirically from the naturalistic behavior of finite neural networks. We demonstrate our approach captures existing phenomena related to the spectral bias of neural networks, and then show that our surrogate models can be used to solve practical problems such as identifying which points most influence the behavior of specific neural networks and predicting which architectures and algorithms will generalize well for specific datasets
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20998;&#26512;&#22312;&#38543;&#26426;&#21021;&#22987;&#21270;&#21518;&#36890;&#36807;&#36923;&#36753;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#20004;&#23618;ReLU&#32593;&#32476;&#22312;&#29305;&#24449;&#23398;&#20064;&#36807;&#31243;&#20013;&#30340;&#34920;&#24449;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#20855;&#26377;&#20108;&#20803;&#26631;&#31614;&#30340;&#30001;XOR-like&#20989;&#25968;&#29983;&#25104;&#30340;&#25968;&#25454;&#65292;&#23613;&#31649;&#32447;&#24615;&#20998;&#31867;&#22120;&#22312;&#35813;&#20998;&#24067;&#19978;&#26080;&#27861;&#26356;&#22909;&#22320;&#24037;&#20316;&#65292;&#20294;&#35813;&#32593;&#32476;&#30340;&#27867;&#21270;&#35823;&#24046;&#25509;&#36817;&#20110;&#26631;&#31614;&#22122;&#22768;&#29575;&#12290;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#35777;&#26126;&#25216;&#24039;&#65292;&#25581;&#31034;&#20102;&#21021;&#22987;&#21270;&#26102;&#22823;&#22810;&#25968;&#31070;&#32463;&#20803;&#20316;&#20026;&#38543;&#26426;&#29305;&#24449;&#65292;&#38543;&#21518;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#21160;&#21147;&#23398;&#23558;&#36825;&#20123;&#24369;&#30340;&#38543;&#26426;&#29305;&#24449;&#25918;&#22823;&#20026;&#26377;&#29992;&#30340;&#29305;&#24449;&#12290;</title><link>http://arxiv.org/abs/2202.07626</link><description>&lt;p&gt;
&#38543;&#26426;&#29305;&#24449;&#25918;&#22823;&#65306;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#29305;&#24449;&#23398;&#20064;&#21644;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Random Feature Amplification: Feature Learning and Generalization in Neural Networks. (arXiv:2202.07626v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.07626
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20998;&#26512;&#22312;&#38543;&#26426;&#21021;&#22987;&#21270;&#21518;&#36890;&#36807;&#36923;&#36753;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#20004;&#23618;ReLU&#32593;&#32476;&#22312;&#29305;&#24449;&#23398;&#20064;&#36807;&#31243;&#20013;&#30340;&#34920;&#24449;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#20855;&#26377;&#20108;&#20803;&#26631;&#31614;&#30340;&#30001;XOR-like&#20989;&#25968;&#29983;&#25104;&#30340;&#25968;&#25454;&#65292;&#23613;&#31649;&#32447;&#24615;&#20998;&#31867;&#22120;&#22312;&#35813;&#20998;&#24067;&#19978;&#26080;&#27861;&#26356;&#22909;&#22320;&#24037;&#20316;&#65292;&#20294;&#35813;&#32593;&#32476;&#30340;&#27867;&#21270;&#35823;&#24046;&#25509;&#36817;&#20110;&#26631;&#31614;&#22122;&#22768;&#29575;&#12290;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#35777;&#26126;&#25216;&#24039;&#65292;&#25581;&#31034;&#20102;&#21021;&#22987;&#21270;&#26102;&#22823;&#22810;&#25968;&#31070;&#32463;&#20803;&#20316;&#20026;&#38543;&#26426;&#29305;&#24449;&#65292;&#38543;&#21518;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#21160;&#21147;&#23398;&#23558;&#36825;&#20123;&#24369;&#30340;&#38543;&#26426;&#29305;&#24449;&#25918;&#22823;&#20026;&#26377;&#29992;&#30340;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#30001;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#20004;&#23618;ReLU&#32593;&#32476;&#22312;&#38543;&#26426;&#21021;&#22987;&#21270;&#21518;&#65292;&#36890;&#36807;&#36923;&#36753;&#25439;&#22833;&#20989;&#25968;&#23545;&#29305;&#24449;&#23398;&#20064;&#36807;&#31243;&#30340;&#34920;&#24449;&#12290;&#25105;&#20204;&#32771;&#34385;&#30001;&#36755;&#20837;&#29305;&#24449;&#30340;XOR-like&#20989;&#25968;&#29983;&#25104;&#30340;&#20855;&#26377;&#20108;&#20803;&#26631;&#31614;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#20801;&#35768;&#19968;&#20010;&#22266;&#23450;&#27604;&#20363;&#30340;&#35757;&#32451;&#26631;&#31614;&#34987;&#23545;&#25163;&#25439;&#22351;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#23613;&#31649;&#32447;&#24615;&#20998;&#31867;&#22120;&#23545;&#20110;&#25105;&#20204;&#32771;&#34385;&#30340;&#20998;&#24067;&#32780;&#35328;&#19981;&#27604;&#38543;&#26426;&#29468;&#27979;&#26356;&#22909;&#65292;&#20294;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#20004;&#23618;ReLU&#32593;&#32476;&#30340;&#27867;&#21270;&#35823;&#24046;&#25509;&#36817;&#20110;&#26631;&#31614;&#22122;&#22768;&#29575;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#35777;&#26126;&#25216;&#24039;&#65292;&#34920;&#26126;&#22312;&#21021;&#22987;&#21270;&#26102;&#65292;&#32477;&#22823;&#22810;&#25968;&#31070;&#32463;&#20803;&#20316;&#20026;&#20165;&#19982;&#26377;&#29992;&#29305;&#24449;&#24369;&#30456;&#20851;&#30340;&#38543;&#26426;&#29305;&#24449;&#65292;&#32780;&#26799;&#24230;&#19979;&#38477;&#21160;&#21147;&#23398;&#23558;&#36825;&#20123;&#24369;&#30340;&#38543;&#26426;&#29305;&#24449;&#25918;&#22823;&#20026;&#24378;&#26377;&#29992;&#30340;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we provide a characterization of the feature-learning process in two-layer ReLU networks trained by gradient descent on the logistic loss following random initialization. We consider data with binary labels that are generated by an XOR-like function of the input features. We permit a constant fraction of the training labels to be corrupted by an adversary. We show that, although linear classifiers are no better than random guessing for the distribution we consider, two-layer ReLU networks trained by gradient descent achieve generalization error close to the label noise rate. We develop a novel proof technique that shows that at initialization, the vast majority of neurons function as random features that are only weakly correlated with useful features, and the gradient descent dynamics 'amplify' these weak, random features to strong, useful features.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;&#27867;&#21270;&#26102;&#33021;&#22815;&#24456;&#22909;&#24212;&#23545;&#22122;&#22768;&#25968;&#25454;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#29616;&#35937;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#65292;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#23558;&#35757;&#32451;&#35823;&#24046;&#38477;&#33267;&#38646;&#24182;&#23436;&#32654;&#22320;&#36866;&#24212;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#25968;&#25454;&#65292;&#24182;&#21516;&#26102;&#36798;&#21040;&#26368;&#20248;&#30340;&#27979;&#35797;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2202.05928</link><description>&lt;p&gt;
&#19981;&#38656;&#35201;&#32447;&#24615;&#20851;&#31995;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#65306;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#29992;&#20110;&#22122;&#22768;&#32447;&#24615;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Benign Overfitting without Linearity: Neural Network Classifiers Trained by Gradient Descent for Noisy Linear Data. (arXiv:2202.05928v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.05928
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;&#27867;&#21270;&#26102;&#33021;&#22815;&#24456;&#22909;&#24212;&#23545;&#22122;&#22768;&#25968;&#25454;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#29616;&#35937;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#65292;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#23558;&#35757;&#32451;&#35823;&#24046;&#38477;&#33267;&#38646;&#24182;&#23436;&#32654;&#22320;&#36866;&#24212;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#25968;&#25454;&#65292;&#24182;&#21516;&#26102;&#36798;&#21040;&#26368;&#20248;&#30340;&#27979;&#35797;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33391;&#24615;&#36807;&#25311;&#21512;&#26159;&#25351;&#25554;&#20540;&#27169;&#22411;&#22312;&#23384;&#22312;&#22122;&#22768;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#33021;&#22815;&#24456;&#22909;&#22320;&#27867;&#21270;&#30340;&#29616;&#35937;&#65292;&#26368;&#26089;&#20986;&#29616;&#22312;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20013;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#19968;&#23454;&#35777;&#35266;&#23519;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#38543;&#26426;&#21021;&#22987;&#21270;&#21518;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#22312;&#36923;&#36753;&#25439;&#22833;&#20989;&#25968;&#19978;&#36827;&#34892;&#25554;&#20540;&#35757;&#32451;&#30340;&#27867;&#21270;&#35823;&#24046;&#12290;&#25105;&#20204;&#20551;&#35774;&#25968;&#25454;&#26469;&#33258;&#20110;&#26126;&#26174;&#20998;&#31163;&#30340;&#31867;&#26465;&#20214;&#23545;&#25968;&#20985;&#20998;&#24067;&#65292;&#24182;&#20801;&#35768;&#35757;&#32451;&#26631;&#31614;&#20013;&#30340;&#19968;&#23450;&#27604;&#20363;&#34987;&#23545;&#25163;&#31713;&#25913;&#12290;&#25105;&#20204;&#35777;&#26126;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#31070;&#32463;&#32593;&#32476;&#34920;&#29616;&#20986;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#29305;&#28857;&#65306;&#23427;&#20204;&#21487;&#20197;&#34987;&#39537;&#21160;&#21040;&#38646;&#35757;&#32451;&#35823;&#24046;&#65292;&#23436;&#32654;&#22320;&#25311;&#21512;&#20219;&#20309;&#26377;&#22122;&#22768;&#30340;&#35757;&#32451;&#26631;&#31614;&#65292;&#24182;&#21516;&#26102;&#36798;&#21040;&#26497;&#23567;&#21270;&#26368;&#22823;&#21270;&#26368;&#20248;&#27979;&#35797;&#35823;&#24046;&#12290;&#19982;&#20043;&#21069;&#20851;&#20110;&#33391;&#24615;&#36807;&#25311;&#21512;&#38656;&#35201;&#32447;&#24615;&#25110;&#22522;&#20110;&#26680;&#30340;&#39044;&#27979;&#22120;&#30340;&#24037;&#20316;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#22312;&#27169;&#22411;&#21644;&#23398;&#20064;&#21160;&#24577;&#37117;&#26159;&#22522;&#26412;&#38750;&#32447;&#24615;&#30340;&#24773;&#20917;&#19979;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;
Benign overfitting, the phenomenon where interpolating models generalize well in the presence of noisy data, was first observed in neural network models trained with gradient descent. To better understand this empirical observation, we consider the generalization error of two-layer neural networks trained to interpolation by gradient descent on the logistic loss following random initialization. We assume the data comes from well-separated class-conditional log-concave distributions and allow for a constant fraction of the training labels to be corrupted by an adversary. We show that in this setting, neural networks exhibit benign overfitting: they can be driven to zero training error, perfectly fitting any noisy training labels, and simultaneously achieve minimax optimal test error. In contrast to previous work on benign overfitting that require linear or kernel-based predictors, our analysis holds in a setting where both the model and learning dynamics are fundamentally nonlinear.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24314;&#31435;$S_n$-&#31561;&#21464;&#21367;&#31215;&#37327;&#23376;Ansatze&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20854;&#33021;&#22815;&#22312;&#20855;&#26377;SU($d$)&#23545;&#31216;&#24615;&#30340;&#24191;&#27867;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#29983;&#25104;&#20219;&#24847;&#24186;&#27491;&#30697;&#38453;&#65292;&#21516;&#26102;&#39564;&#35777;&#20102;4-local SU($d$)&#23545;&#31216;&#24186;&#27491;&#30697;&#38453;&#30340;&#21487;&#23454;&#29616;&#24615;&#12290;</title><link>http://arxiv.org/abs/2112.07611</link><description>&lt;p&gt;
&#36890;&#36807;&#32676;&#31561;&#21464;&#21367;&#31215;&#37327;&#23376;Ansatze&#21152;&#36895;&#23398;&#20064;&#37327;&#23376;&#24577;
&lt;/p&gt;
&lt;p&gt;
Speeding up Learning Quantum States through Group Equivariant Convolutional Quantum Ans\"atze. (arXiv:2112.07611v3 [quant-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.07611
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24314;&#31435;$S_n$-&#31561;&#21464;&#21367;&#31215;&#37327;&#23376;Ansatze&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20854;&#33021;&#22815;&#22312;&#20855;&#26377;SU($d$)&#23545;&#31216;&#24615;&#30340;&#24191;&#27867;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#29983;&#25104;&#20219;&#24847;&#24186;&#27491;&#30697;&#38453;&#65292;&#21516;&#26102;&#39564;&#35777;&#20102;4-local SU($d$)&#23545;&#31216;&#24186;&#27491;&#30697;&#38453;&#30340;&#21487;&#23454;&#29616;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22522;&#20110;Schur-Weyl&#23545;&#20598;&#65292;&#24314;&#31435;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#29992;&#20110;$S_n$-&#31561;&#21464;&#21367;&#31215;&#37327;&#23376;&#30005;&#36335;&#21644;SU$(d)$&#23545;&#31216;&#24615;&#65292;&#23558;Jordan&#30340;&#32622;&#25442;&#37327;&#23376;&#35745;&#31639;(PQC)&#24418;&#24335;&#20027;&#20041;&#25193;&#23637;&#21644;&#27867;&#21270;&#12290;&#25105;&#20204;&#21033;&#29992;Okounkov-Vershik&#26041;&#27861;&#26469;&#35777;&#26126;Harrow&#22312;&#22855;&#24322;&#36793;&#34920;&#31034;&#22522;&#20043;&#38388;&#30340;&#31561;&#20215;&#24615;&#65292;&#24182;&#21033;&#29992;Young-Jucys-Murphy(YJM)&#20803;&#32032;&#24314;&#31435;&#20102;$S_n$-&#31561;&#21464;&#21367;&#31215;&#37327;&#23376;&#20132;&#26367;Ansatze($S_n$-CQA)&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;$S_n$-CQA&#33021;&#22815;&#22312;&#20219;&#20309;&#32473;&#23450;&#30340;$S_n$ irrep&#25159;&#21306;&#20013;&#29983;&#25104;&#20219;&#24847;&#24186;&#27491;&#30697;&#38453;&#65292;&#36825;&#21487;&#20197;&#20316;&#20026;&#20855;&#26377;SU($d$)&#23545;&#31216;&#24615;&#30340;&#24191;&#27867;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#30340;&#36890;&#29992;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#21478;&#19968;&#31181;&#35777;&#26126;&#37327;&#23376;&#36817;&#20284;&#20248;&#21270;&#31639;&#27861;(QAOA)&#30340;&#26222;&#36866;&#24615;&#30340;&#26041;&#24335;&#65292;&#24182;&#39564;&#35777;&#20102;4-local SU($d$)&#23545;&#31216;&#24186;&#27491;&#30697;&#38453;&#26159;&#21487;&#23454;&#29616;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a theoretical framework for $S_n$-equivariant convolutional quantum circuits with SU$(d)$-symmetry, building on and significantly generalizing Jordan's Permutational Quantum Computing (PQC) formalism based on Schur-Weyl duality connecting both SU$(d)$ and $S_n$ actions on qudits. In particular, we utilize the Okounkov-Vershik approach to prove Harrow's statement (Ph.D. Thesis 2005 p.160) on the equivalence between $\operatorname{SU}(d)$ and $S_n$ irrep bases and to establish the $S_n$-equivariant Convolutional Quantum Alternating Ans\"atze ($S_n$-CQA) using Young-Jucys-Murphy (YJM) elements. We prove that $S_n$-CQA is able to generate any unitary in any given $S_n$ irrep sector, which may serve as a universal model for a wide array of quantum machine learning problems with the presence of SU($d$) symmetry. Our method provides another way to prove the universality of Quantum Approximate Optimization Algorithm (QAOA) and verifies that 4-local SU($d$) symmetric unitaries are su
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21322;&#23450;&#35268;&#21010;&#26469;&#32852;&#21512;&#31038;&#21306;&#26816;&#27979;&#21644;&#26059;&#36716;&#21516;&#27493;&#30340;&#26041;&#27861;&#65292;&#22312;&#23384;&#22312;&#24322;&#26500;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#33021;&#22815;&#20934;&#30830;&#24674;&#22797;&#20986;&#26059;&#36716;&#21644;&#32858;&#31867;&#36523;&#20221;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#21644;&#20934;&#30830;&#24674;&#22797;&#24615;&#30340;&#30456;&#21464;&#29616;&#35937;&#12290;</title><link>http://arxiv.org/abs/2105.06031</link><description>&lt;p&gt;
&#36890;&#36807;&#21322;&#23450;&#35268;&#21010;&#65292;&#32852;&#21512;&#31038;&#21306;&#26816;&#27979;&#21644;&#26059;&#36716;&#21516;&#27493;
&lt;/p&gt;
&lt;p&gt;
Joint Community Detection and Rotational Synchronization via Semidefinite Programming. (arXiv:2105.06031v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.06031
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21322;&#23450;&#35268;&#21010;&#26469;&#32852;&#21512;&#31038;&#21306;&#26816;&#27979;&#21644;&#26059;&#36716;&#21516;&#27493;&#30340;&#26041;&#27861;&#65292;&#22312;&#23384;&#22312;&#24322;&#26500;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#33021;&#22815;&#20934;&#30830;&#24674;&#22797;&#20986;&#26059;&#36716;&#21644;&#32858;&#31867;&#36523;&#20221;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#21644;&#20934;&#30830;&#24674;&#22797;&#24615;&#30340;&#30456;&#21464;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23384;&#22312;&#24322;&#26500;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#26059;&#36716;&#30340;&#23545;&#35937;&#33853;&#20837;&#22810;&#20010;&#28508;&#22312;&#31867;&#21035;&#20013;&#65292;&#21516;&#26102;&#23545;&#23427;&#20204;&#36827;&#34892;&#32858;&#31867;&#21644;&#22522;&#20110;&#20004;&#20004;&#20851;&#31995;&#36827;&#34892;&#21516;&#27493;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#36825;&#23548;&#33268;&#20102;&#31038;&#21306;&#26816;&#27979;&#21644;&#21516;&#27493;&#30340;&#32852;&#21512;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#21322;&#23450;&#26494;&#24347;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#22312;&#23558;&#33879;&#21517;&#30340;&#38543;&#26426;&#22359;&#27169;&#22411;&#25193;&#23637;&#21040;&#26059;&#36716;&#21644;&#32858;&#31867;&#36523;&#20221;&#37117;&#38656;&#35201;&#30830;&#23450;&#30340;&#26032;&#24773;&#20917;&#26102;&#30340;&#31934;&#30830;&#24674;&#22797;&#24615;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#35777;&#23454;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#34920;&#26126;&#20102;&#20934;&#30830;&#24674;&#22797;&#24615;&#30340;&#26126;&#26174;&#30456;&#21464;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the presence of heterogeneous data, where randomly rotated objects fall into multiple underlying categories, it is challenging to simultaneously classify them into clusters and synchronize them based on pairwise relations. This gives rise to the joint problem of community detection and synchronization. We propose a series of semidefinite relaxations, and prove their exact recovery when extending the celebrated stochastic block model to this new setting where both rotations and cluster identities are to be determined. Numerical experiments demonstrate the efficacy of our proposed algorithms and confirm our theoretical result which indicates a sharp phase transition for exact recovery.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Copula&#27169;&#22411;&#30340;&#26032;&#30340;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#22788;&#29702;&#32570;&#22833;&#38750;&#38543;&#26426;&#25130;&#23614;&#25351;&#26631;&#19979;&#30340;&#26465;&#20214;&#29983;&#23384;&#20989;&#25968;&#20272;&#35745;&#38382;&#39064;&#12290;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#21644;&#30495;&#23454;&#25968;&#25454;&#20998;&#26512;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#35813;&#20272;&#35745;&#22120;&#30340;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2009.01726</link><description>&lt;p&gt;
&#22522;&#20110;Copula&#27169;&#22411;&#30340;&#32570;&#22833;&#38750;&#38543;&#26426;&#25130;&#23614;&#25351;&#26631;&#30340;&#29983;&#23384;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Survival Estimation for Missing not at Random Censoring Indicators based on Copula Models. (arXiv:2009.01726v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2009.01726
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Copula&#27169;&#22411;&#30340;&#26032;&#30340;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#22788;&#29702;&#32570;&#22833;&#38750;&#38543;&#26426;&#25130;&#23614;&#25351;&#26631;&#19979;&#30340;&#26465;&#20214;&#29983;&#23384;&#20989;&#25968;&#20272;&#35745;&#38382;&#39064;&#12290;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#21644;&#30495;&#23454;&#25968;&#25454;&#20998;&#26512;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#35813;&#20272;&#35745;&#22120;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20855;&#26377;&#21327;&#21464;&#37327;&#30340;&#21491;&#25130;&#23614;&#25968;&#25454;&#20013;&#65292;&#26465;&#20214;Kaplan-Meier&#20272;&#35745;&#22120;&#65288;&#20063;&#31216;&#20026;Beran&#20272;&#35745;&#22120;&#65289;&#19968;&#33268;&#20272;&#35745;&#24863;&#20852;&#36259;&#20107;&#20214;&#30340;&#38543;&#26426;&#36861;&#36394;&#30340;&#26465;&#20214;&#29983;&#23384;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#24517;&#35201;&#26465;&#20214;&#26159;&#23545;&#27599;&#20010;&#20010;&#20307;&#26159;&#21542;&#34987;&#25130;&#23614;&#26377;&#26126;&#30830;&#30340;&#20102;&#35299;&#65292;&#32780;&#22312;&#23454;&#36341;&#20013;&#21487;&#33021;&#26159;&#19981;&#23436;&#25972;&#30340;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24403;&#25130;&#23614;&#25351;&#26631;&#26159;&#19968;&#33324;&#38543;&#26426;&#21464;&#37327;&#26102;&#23545;Beran&#20272;&#35745;&#22120;&#36827;&#34892;&#30740;&#31350;&#65292;&#24182;&#35752;&#35770;&#20102;Beran&#20272;&#35745;&#22120;&#25928;&#29575;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;&#22522;&#20110;&#32570;&#22833;&#38750;&#38543;&#26426;&#65288;MNAR&#65289;&#25130;&#23614;&#25351;&#26631;&#30340;&#26465;&#20214;Copula&#27169;&#22411;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#26465;&#20214;&#29983;&#23384;&#20989;&#25968;&#20272;&#35745;&#22120;&#12290;&#38500;&#20102;&#29702;&#35770;&#32467;&#26524;&#65292;&#25105;&#20204;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#23545;&#23567;&#26679;&#26412;&#20013;&#30340;&#20272;&#35745;&#22120;&#36827;&#34892;&#20102;&#28436;&#31034;&#65292;&#24182;&#36890;&#36807;&#20998;&#26512;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#23637;&#31034;&#20102;&#23427;&#20204;&#30340;&#23454;&#38469;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the presence of right-censored data with covariates, the conditional Kaplan-Meier estimator (also known as the Beran estimator) consistently estimates the conditional survival function of the random follow-up for the event of interest. However, a necessary condition is the unambiguous knowledge of whether each individual is censored or not, which may be incomplete in practice. We therefore propose a study of the Beran estimator when the censoring indicators are generic random variables and discuss necessary conditions for the efficiency of the Beran estimator. From this, we provide a new estimator for the conditional survival function with missing not at random (MNAR) censoring indicators based on a conditional copula model for the missingness mechanism. In addition to the theoretical results, we illustrate how the estimators work for small samples through a simulation study and show their practical applicability by analyzing synthetic and real data.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#24182;&#36827;&#34892;&#20102;&#22797;&#26434;&#24615;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#21487;&#20197;&#39640;&#25928;&#22320;&#25214;&#21040;&#20989;&#25968;&#30340;&#31283;&#23450;&#28857;&#12290;&#35813;&#30740;&#31350;&#23545;&#20110;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#38750;&#28176;&#36827;&#20998;&#26512;&#26159;&#39318;&#27425;&#36827;&#34892;&#30340;&#12290;</title><link>http://arxiv.org/abs/1906.00331</link><description>&lt;p&gt;
&#20851;&#20110;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
On Gradient Descent Ascent for Nonconvex-Concave Minimax Problems. (arXiv:1906.00331v9 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1906.00331
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#24182;&#36827;&#34892;&#20102;&#22797;&#26434;&#24615;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#21487;&#20197;&#39640;&#25928;&#22320;&#25214;&#21040;&#20989;&#25968;&#30340;&#31283;&#23450;&#28857;&#12290;&#35813;&#30740;&#31350;&#23545;&#20110;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#38750;&#28176;&#36827;&#20998;&#26512;&#26159;&#39318;&#27425;&#36827;&#34892;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#21363;$\min_{\mathbf{x}} \max_{\mathbf{y} \in \mathcal{Y}} f(\mathbf{x}, \mathbf{y})$&#65292;&#20854;&#20013;$f$&#22312;$\mathbf{x}$&#19978;&#26159;&#38750;&#20984;&#30340;&#20294;&#22312;$\mathbf{y}$&#19978;&#26159;&#20985;&#30340;&#65292;$\mathcal{Y}$&#26159;&#19968;&#20010;&#20984;&#19988;&#26377;&#30028;&#30340;&#38598;&#21512;&#12290;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#26368;&#24120;&#29992;&#30340;&#31639;&#27861;&#20043;&#19968;&#26159;&#33879;&#21517;&#30340;&#26799;&#24230;&#19979;&#38477;&#19978;&#21319;&#65288;GDA&#65289;&#31639;&#27861;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#12289;&#25511;&#21046;&#29702;&#35770;&#21644;&#32463;&#27982;&#23398;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#24212;&#29992;&#12290;&#23613;&#31649;&#20984;-&#20985;&#35774;&#32622;&#19979;&#26377;&#30528;&#24191;&#27867;&#30340;&#25910;&#25947;&#32467;&#26524;&#65292;&#20294;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#65292;&#30456;&#21516;&#27493;&#38271;&#30340;GDA&#21487;&#33021;&#20250;&#25910;&#25947;&#21040;&#26497;&#38480;&#29615;&#65292;&#29978;&#33267;&#21457;&#25955;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#35299;&#20915;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#20004;&#26102;&#38388;&#23610;&#24230;GDA&#30340;&#22797;&#26434;&#24230;&#32467;&#26524;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#21487;&#20197;&#39640;&#25928;&#22320;&#25214;&#21040;&#20989;&#25968;$\Phi(\cdot) := \max_{\mathbf{y} \in \mathcal{Y}} f(\cdot, \mathbf{y})$&#30340;&#19968;&#20010;&#31283;&#23450;&#28857;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#30340;&#38750;&#28176;&#36827;&#20998;&#26512;&#32467;&#26524;&#65292;&#25581;&#31034;&#20102;&#26377;&#20851;&#20004;&#26102;&#38388;&#23610;&#24230;GDA&#30340;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider nonconvex-concave minimax problems, $\min_{\mathbf{x}} \max_{\mathbf{y} \in \mathcal{Y}} f(\mathbf{x}, \mathbf{y})$, where $f$ is nonconvex in $\mathbf{x}$ but concave in $\mathbf{y}$ and $\mathcal{Y}$ is a convex and bounded set. One of the most popular algorithms for solving this problem is the celebrated gradient descent ascent (GDA) algorithm, which has been widely used in machine learning, control theory and economics. Despite the extensive convergence results for the convex-concave setting, GDA with equal stepsize can converge to limit cycles or even diverge in a general setting. In this paper, we present the complexity results on two-time-scale GDA for solving nonconvex-concave minimax problems, showing that the algorithm can find a stationary point of the function $\Phi(\cdot) := \max_{\mathbf{y} \in \mathcal{Y}} f(\cdot, \mathbf{y})$ efficiently. To the best our knowledge, this is the first nonasymptotic analysis for two-time-scale GDA in this setting, shedding lig
&lt;/p&gt;</description></item></channel></rss>