<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#30740;&#31350;&#35757;&#32451;&#21160;&#24577;&#21644;&#32463;&#39564;&#28023;&#26862;&#30697;&#38453;&#20197;&#21450;&#26799;&#24230;&#30697;&#38453;&#30340;&#35889;&#30340;&#32852;&#21512;&#28436;&#21270;&#65292;&#35777;&#26126;&#20102;&#22312;&#39640;&#32500;&#28151;&#21512;&#21644;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;SGD&#36712;&#36857;&#19982;&#28023;&#26862;&#30697;&#38453;&#21644;&#26799;&#24230;&#30697;&#38453;&#30340;&#26032;&#20852;&#20302;&#31209;&#24322;&#24120;&#29305;&#24449;&#31354;&#38388;&#21563;&#21512;&#12290;&#22312;&#22810;&#23618;&#35774;&#32622;&#20013;&#65292;&#36825;&#31181;&#23545;&#40784;&#20250;&#22312;&#27599;&#19968;&#23618;&#21457;&#29983;&#65292;&#24182;&#19988;&#22312;&#25910;&#25947;&#21040;&#20122;&#20248;&#20998;&#31867;&#22120;&#26102;&#20250;&#34920;&#29616;&#20986;&#31209;&#32570;&#20047;&#12290;</title><link>http://arxiv.org/abs/2310.03010</link><description>&lt;p&gt;
&#39640;&#32500;&#24230; SGD &#19982;&#26032;&#20852;&#30340;&#24322;&#24120;&#29305;&#24449;&#31354;&#38388;&#30456;&#21563;&#21512;
&lt;/p&gt;
&lt;p&gt;
High-dimensional SGD aligns with emerging outlier eigenspaces. (arXiv:2310.03010v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03010
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#30740;&#31350;&#35757;&#32451;&#21160;&#24577;&#21644;&#32463;&#39564;&#28023;&#26862;&#30697;&#38453;&#20197;&#21450;&#26799;&#24230;&#30697;&#38453;&#30340;&#35889;&#30340;&#32852;&#21512;&#28436;&#21270;&#65292;&#35777;&#26126;&#20102;&#22312;&#39640;&#32500;&#28151;&#21512;&#21644;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;SGD&#36712;&#36857;&#19982;&#28023;&#26862;&#30697;&#38453;&#21644;&#26799;&#24230;&#30697;&#38453;&#30340;&#26032;&#20852;&#20302;&#31209;&#24322;&#24120;&#29305;&#24449;&#31354;&#38388;&#21563;&#21512;&#12290;&#22312;&#22810;&#23618;&#35774;&#32622;&#20013;&#65292;&#36825;&#31181;&#23545;&#40784;&#20250;&#22312;&#27599;&#19968;&#23618;&#21457;&#29983;&#65292;&#24182;&#19988;&#22312;&#25910;&#25947;&#21040;&#20122;&#20248;&#20998;&#31867;&#22120;&#26102;&#20250;&#34920;&#29616;&#20986;&#31209;&#32570;&#20047;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#21644;&#32463;&#39564;&#28023;&#26862;&#30697;&#38453;&#21644;&#26799;&#24230;&#30697;&#38453;&#30340;&#35889;&#30340;&#32852;&#21512;&#28436;&#21270;&#65292;&#23545;&#35757;&#32451;&#21160;&#24577;&#36827;&#34892;&#20102;&#20005;&#26684;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#35777;&#26126;&#22312;&#22810;&#31867;&#39640;&#32500;&#28151;&#21512;&#21644;1&#25110;2&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#20004;&#20010;&#20856;&#22411;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;SGD&#36712;&#36857;&#36805;&#36895;&#19982;&#28023;&#26862;&#30697;&#38453;&#21644;&#26799;&#24230;&#30697;&#38453;&#30340;&#26032;&#20852;&#20302;&#31209;&#24322;&#24120;&#29305;&#24449;&#31354;&#38388;&#30456;&#21563;&#21512;&#12290;&#27492;&#22806;&#65292;&#22312;&#22810;&#23618;&#35774;&#32622;&#20013;&#65292;&#36825;&#31181;&#23545;&#40784;&#21457;&#29983;&#22312;&#27599;&#19968;&#23618;&#65292;&#26368;&#21518;&#19968;&#23618;&#30340;&#24322;&#24120;&#29305;&#24449;&#31354;&#38388;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#28436;&#21270;&#65292;&#24182;&#19988;&#22312;SGD&#25910;&#25947;&#21040;&#20122;&#20248;&#20998;&#31867;&#22120;&#26102;&#34920;&#29616;&#20986;&#31209;&#32570;&#20047;&#12290;&#36825;&#20026;&#36807;&#21435;&#21313;&#24180;&#20013;&#20851;&#20110;&#22312;&#36229;&#21442;&#25968;&#21270;&#32593;&#32476;&#20013;&#35757;&#32451;&#36807;&#31243;&#20013;&#28023;&#26862;&#30697;&#38453;&#21644;&#20449;&#24687;&#30697;&#38453;&#30340;&#35889;&#30340;&#24191;&#27867;&#25968;&#20540;&#30740;&#31350;&#25552;&#20379;&#20102;&#20016;&#23500;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
We rigorously study the joint evolution of training dynamics via stochastic gradient descent (SGD) and the spectra of empirical Hessian and gradient matrices. We prove that in two canonical classification tasks for multi-class high-dimensional mixtures and either 1 or 2-layer neural networks, the SGD trajectory rapidly aligns with emerging low-rank outlier eigenspaces of the Hessian and gradient matrices. Moreover, in multi-layer settings this alignment occurs per layer, with the final layer's outlier eigenspace evolving over the course of training, and exhibiting rank deficiency when the SGD converges to sub-optimal classifiers. This establishes some of the rich predictions that have arisen from extensive numerical studies in the last decade about the spectra of Hessian and information matrices over the course of training in overparametrized networks.
&lt;/p&gt;</description></item><item><title>&#22810;&#29289;&#29702;&#23398;&#39044;&#35757;&#32451;&#26159;&#19968;&#31181;&#29992;&#20110;&#29289;&#29702;&#20195;&#29702;&#24314;&#27169;&#30340;&#33258;&#22238;&#24402;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#22823;&#22411;&#20195;&#29702;&#27169;&#22411;&#21516;&#26102;&#39044;&#27979;&#22810;&#20010;&#24322;&#26500;&#29289;&#29702;&#31995;&#32479;&#30340;&#21160;&#21147;&#23398;&#65292;&#23398;&#20064;&#22312;&#19981;&#21516;&#29289;&#29702;&#20219;&#21153;&#20013;&#24191;&#27867;&#36866;&#29992;&#30340;&#29305;&#24449;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#21333;&#20010;MPP&#39044;&#35757;&#32451;&#30340;&#21464;&#25442;&#22120;&#21487;&#20197;&#22312;&#25152;&#26377;&#39044;&#35757;&#32451;&#23376;&#20219;&#21153;&#19978;&#19982;&#25110;&#36229;&#36807;&#29305;&#23450;&#20219;&#21153;&#30340;&#22522;&#20934;&#32467;&#26524;&#65292;&#26080;&#38656;&#24494;&#35843;&#65292;&#24182;&#19988;&#22312;&#19979;&#28216;&#20219;&#21153;&#20013;&#65292;&#24494;&#35843;MPP&#35757;&#32451;&#30340;&#27169;&#22411;&#30456;&#36739;&#20110;&#20174;&#22836;&#35757;&#32451;&#30340;&#27169;&#22411;&#65292;&#23545;&#26032;&#29289;&#29702;&#30340;&#39044;&#27979;&#32467;&#26524;&#26356;&#20934;&#30830;&#12290;</title><link>http://arxiv.org/abs/2310.02994</link><description>&lt;p&gt;
&#22810;&#29289;&#29702;&#23398;&#39044;&#35757;&#32451;&#29992;&#20110;&#29289;&#29702;&#20195;&#29702;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Multiple Physics Pretraining for Physical Surrogate Models. (arXiv:2310.02994v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02994
&lt;/p&gt;
&lt;p&gt;
&#22810;&#29289;&#29702;&#23398;&#39044;&#35757;&#32451;&#26159;&#19968;&#31181;&#29992;&#20110;&#29289;&#29702;&#20195;&#29702;&#24314;&#27169;&#30340;&#33258;&#22238;&#24402;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#22823;&#22411;&#20195;&#29702;&#27169;&#22411;&#21516;&#26102;&#39044;&#27979;&#22810;&#20010;&#24322;&#26500;&#29289;&#29702;&#31995;&#32479;&#30340;&#21160;&#21147;&#23398;&#65292;&#23398;&#20064;&#22312;&#19981;&#21516;&#29289;&#29702;&#20219;&#21153;&#20013;&#24191;&#27867;&#36866;&#29992;&#30340;&#29305;&#24449;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#21333;&#20010;MPP&#39044;&#35757;&#32451;&#30340;&#21464;&#25442;&#22120;&#21487;&#20197;&#22312;&#25152;&#26377;&#39044;&#35757;&#32451;&#23376;&#20219;&#21153;&#19978;&#19982;&#25110;&#36229;&#36807;&#29305;&#23450;&#20219;&#21153;&#30340;&#22522;&#20934;&#32467;&#26524;&#65292;&#26080;&#38656;&#24494;&#35843;&#65292;&#24182;&#19988;&#22312;&#19979;&#28216;&#20219;&#21153;&#20013;&#65292;&#24494;&#35843;MPP&#35757;&#32451;&#30340;&#27169;&#22411;&#30456;&#36739;&#20110;&#20174;&#22836;&#35757;&#32451;&#30340;&#27169;&#22411;&#65292;&#23545;&#26032;&#29289;&#29702;&#30340;&#39044;&#27979;&#32467;&#26524;&#26356;&#20934;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22810;&#29289;&#29702;&#23398;&#39044;&#35757;&#32451;&#65288;MPP&#65289;&#30340;&#26041;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#33258;&#22238;&#24402;&#20219;&#21153;&#19981;&#21487;&#30693;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#29992;&#20110;&#29289;&#29702;&#20195;&#29702;&#24314;&#27169;&#12290;MPP&#36890;&#36807;&#35757;&#32451;&#22823;&#22411;&#20195;&#29702;&#27169;&#22411;&#21516;&#26102;&#39044;&#27979;&#22810;&#20010;&#24322;&#26500;&#29289;&#29702;&#31995;&#32479;&#30340;&#21160;&#21147;&#23398;&#65292;&#23398;&#20064;&#22312;&#19981;&#21516;&#29289;&#29702;&#20219;&#21153;&#20013;&#24191;&#27867;&#36866;&#29992;&#30340;&#29305;&#24449;&#12290;&#20026;&#20102;&#26377;&#25928;&#23398;&#20064;&#65292;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#20849;&#20139;&#23884;&#20837;&#21644;&#24402;&#19968;&#21270;&#31574;&#30053;&#65292;&#23558;&#22810;&#20010;&#31995;&#32479;&#30340;&#23383;&#27573;&#25237;&#24433;&#21040;&#19968;&#20010;&#20849;&#20139;&#23884;&#20837;&#31354;&#38388;&#20013;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#28041;&#21450;&#27969;&#20307;&#21147;&#23398;&#30340;&#24191;&#27867;&#22522;&#20934;&#27979;&#35797;&#20013;&#39564;&#35777;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#21333;&#20010;MPP&#39044;&#35757;&#32451;&#30340;&#21464;&#25442;&#22120;&#33021;&#22815;&#22312;&#25152;&#26377;&#39044;&#35757;&#32451;&#23376;&#20219;&#21153;&#19978;&#19982;&#25110;&#36229;&#36807;&#29305;&#23450;&#20219;&#21153;&#30340;&#22522;&#20934;&#32467;&#26524;&#65292;&#32780;&#26080;&#38656;&#24494;&#35843;&#12290;&#23545;&#20110;&#19979;&#28216;&#20219;&#21153;&#65292;&#25105;&#20204;&#35777;&#26126;&#24494;&#35843;MPP&#35757;&#32451;&#30340;&#27169;&#22411;&#30456;&#36739;&#20110;&#20174;&#22836;&#35757;&#32451;&#30340;&#27169;&#22411;&#65292;&#22312;&#22810;&#20010;&#26102;&#38388;&#27493;&#39588;&#19978;&#23545;&#26032;&#29289;&#29702;&#30340;&#39044;&#27979;&#32467;&#26524;&#26356;&#20934;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce multiple physics pretraining (MPP), an autoregressive task-agnostic pretraining approach for physical surrogate modeling. MPP involves training large surrogate models to predict the dynamics of multiple heterogeneous physical systems simultaneously by learning features that are broadly useful across diverse physical tasks. In order to learn effectively in this setting, we introduce a shared embedding and normalization strategy that projects the fields of multiple systems into a single shared embedding space. We validate the efficacy of our approach on both pretraining and downstream tasks over a broad fluid mechanics-oriented benchmark. We show that a single MPP-pretrained transformer is able to match or outperform task-specific baselines on all pretraining sub-tasks without the need for finetuning. For downstream tasks, we demonstrate that finetuning MPP-trained models results in more accurate predictions across multiple time-steps on new physics compared to training from
&lt;/p&gt;</description></item><item><title>xVal&#26159;&#19968;&#31181;&#36830;&#32493;&#25968;&#23383;&#32534;&#30721;&#26041;&#26696;&#65292;&#36890;&#36807;&#20351;&#29992;&#21333;&#20010;&#26631;&#35760;&#26469;&#34920;&#31034;&#20219;&#20309;&#23454;&#25968;&#12290;&#19982;&#29616;&#26377;&#30340;&#25968;&#23383;&#32534;&#30721;&#26041;&#26696;&#30456;&#27604;&#65292;xVal&#26356;&#21152;&#39640;&#25928;&#65292;&#24182;&#19988;&#22312;&#27867;&#21270;&#24615;&#33021;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2310.02989</link><description>&lt;p&gt;
xVal: &#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36830;&#32493;&#25968;&#23383;&#32534;&#30721;
&lt;/p&gt;
&lt;p&gt;
xVal: A Continuous Number Encoding for Large Language Models. (arXiv:2310.02989v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02989
&lt;/p&gt;
&lt;p&gt;
xVal&#26159;&#19968;&#31181;&#36830;&#32493;&#25968;&#23383;&#32534;&#30721;&#26041;&#26696;&#65292;&#36890;&#36807;&#20351;&#29992;&#21333;&#20010;&#26631;&#35760;&#26469;&#34920;&#31034;&#20219;&#20309;&#23454;&#25968;&#12290;&#19982;&#29616;&#26377;&#30340;&#25968;&#23383;&#32534;&#30721;&#26041;&#26696;&#30456;&#27604;&#65292;xVal&#26356;&#21152;&#39640;&#25928;&#65292;&#24182;&#19988;&#22312;&#27867;&#21270;&#24615;&#33021;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#25968;&#23383;&#20196;&#29260;&#21270;&#30340;&#29420;&#29305;&#22256;&#38590;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23578;&#26410;&#24191;&#27867;&#29992;&#20110;&#31185;&#23398;&#25968;&#25454;&#38598;&#30340;&#20998;&#26512;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;xVal&#65292;&#19968;&#31181;&#25968;&#23383;&#32534;&#30721;&#26041;&#26696;&#65292;&#21487;&#20197;&#20351;&#29992;&#21333;&#20010;&#26631;&#35760;&#26469;&#34920;&#31034;&#20219;&#20309;&#23454;&#25968;&#12290;xVal&#36890;&#36807;&#23558;&#19987;&#29992;&#23884;&#20837;&#21521;&#37327;&#25353;&#25968;&#23383;&#20540;&#36827;&#34892;&#32553;&#25918;&#26469;&#34920;&#31034;&#32473;&#23450;&#30340;&#23454;&#25968;&#12290;&#32467;&#21512;&#20462;&#25913;&#21518;&#30340;&#25968;&#23383;&#25512;&#26029;&#26041;&#27861;&#65292;&#35813;&#31574;&#30053;&#20351;&#27169;&#22411;&#22312;&#32771;&#34385;&#20316;&#20026;&#20174;&#36755;&#20837;&#23383;&#31526;&#20018;&#30340;&#25968;&#23383;&#21040;&#36755;&#20986;&#23383;&#31526;&#20018;&#30340;&#25968;&#23383;&#30340;&#26144;&#23556;&#26102;&#25104;&#20026;&#31471;&#21040;&#31471;&#36830;&#32493;&#30340;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#31181;&#26356;&#36866;&#29992;&#20110;&#31185;&#23398;&#39046;&#22495;&#24212;&#29992;&#30340;&#24402;&#32435;&#20559;&#24046;&#12290;&#25105;&#20204;&#22312;&#35768;&#22810;&#21512;&#25104;&#21644;&#29616;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#12290;&#19982;&#29616;&#26377;&#30340;&#25968;&#23383;&#32534;&#30721;&#26041;&#26696;&#30456;&#27604;&#65292;&#25105;&#20204;&#21457;&#29616;xVal&#22312;&#20196;&#29260;&#25928;&#29575;&#21644;&#27867;&#21270;&#24615;&#33021;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models have not yet been broadly adapted for the analysis of scientific datasets due in part to the unique difficulties of tokenizing numbers. We propose xVal, a numerical encoding scheme that represents any real number using just a single token. xVal represents a given real number by scaling a dedicated embedding vector by the number value. Combined with a modified number-inference approach, this strategy renders the model end-to-end continuous when considered as a map from the numbers of the input string to those of the output string. This leads to an inductive bias that is generally more suitable for applications in scientific domains. We empirically evaluate our proposal on a number of synthetic and real-world datasets. Compared with existing number encoding schemes, we find that xVal is more token-efficient and demonstrates improved generalization.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24212;&#29992;&#20110;&#32852;&#24819;&#35760;&#24518;&#20013;&#30340;&#32553;&#25918;&#23450;&#24459;&#65292;&#36890;&#36807;&#39640;&#32500;&#30697;&#38453;&#21644;&#23884;&#20837;&#30340;&#22806;&#31215;&#26469;&#27169;&#25311;&#20869;&#23618;Transformer&#35821;&#35328;&#27169;&#22411;&#12290;&#20316;&#32773;&#25512;&#23548;&#20986;&#20102;&#19982;&#26679;&#26412;&#25968;&#37327;&#21644;&#21442;&#25968;&#22823;&#23567;&#30456;&#20851;&#30340;&#31934;&#30830;&#32553;&#25918;&#23450;&#24459;&#65292;&#24182;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#30340;&#26377;&#25928;&#24615;&#12290;&#21516;&#26102;&#65292;&#20316;&#32773;&#36824;&#36890;&#36807;&#22823;&#37327;&#23454;&#39564;&#23637;&#31034;&#20102;&#23384;&#20648;&#35760;&#24518;&#20851;&#32852;&#30340;&#32454;&#31890;&#24230;&#21487;&#35270;&#21270;&#12290;</title><link>http://arxiv.org/abs/2310.02984</link><description>&lt;p&gt;
&#32553;&#25918;&#23450;&#24459;&#22312;&#32852;&#24819;&#35760;&#24518;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Scaling Laws for Associative Memories. (arXiv:2310.02984v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02984
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24212;&#29992;&#20110;&#32852;&#24819;&#35760;&#24518;&#20013;&#30340;&#32553;&#25918;&#23450;&#24459;&#65292;&#36890;&#36807;&#39640;&#32500;&#30697;&#38453;&#21644;&#23884;&#20837;&#30340;&#22806;&#31215;&#26469;&#27169;&#25311;&#20869;&#23618;Transformer&#35821;&#35328;&#27169;&#22411;&#12290;&#20316;&#32773;&#25512;&#23548;&#20986;&#20102;&#19982;&#26679;&#26412;&#25968;&#37327;&#21644;&#21442;&#25968;&#22823;&#23567;&#30456;&#20851;&#30340;&#31934;&#30830;&#32553;&#25918;&#23450;&#24459;&#65292;&#24182;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#30340;&#26377;&#25928;&#24615;&#12290;&#21516;&#26102;&#65292;&#20316;&#32773;&#36824;&#36890;&#36807;&#22823;&#37327;&#23454;&#39564;&#23637;&#31034;&#20102;&#23384;&#20648;&#35760;&#24518;&#20851;&#32852;&#30340;&#32454;&#31890;&#24230;&#21487;&#35270;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#24456;&#21487;&#33021;&#28041;&#21450;&#21040;&#25277;&#35937;&#35268;&#21017;&#30340;&#21457;&#29616;&#21644;&#35760;&#24518;&#12290;&#26412;&#25991;&#26088;&#22312;&#30740;&#31350;&#32852;&#24819;&#35760;&#24518;&#26426;&#21046;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#22522;&#20110;&#39640;&#32500;&#30697;&#38453;&#65292;&#30001;&#23884;&#20837;&#30340;&#22806;&#31215;&#32452;&#25104;&#65292;&#19982;Transformer&#35821;&#35328;&#27169;&#22411;&#30340;&#20869;&#23618;&#30456;&#20851;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#20851;&#20110;&#26679;&#26412;&#25968;&#37327;&#21644;&#21442;&#25968;&#35268;&#27169;&#30340;&#31934;&#30830;&#32553;&#25918;&#23450;&#24459;&#65292;&#24182;&#35752;&#35770;&#20102;&#19981;&#21516;&#20272;&#35745;&#22120;&#30340;&#32479;&#35745;&#25928;&#29575;&#65292;&#21253;&#25324;&#22522;&#20110;&#20248;&#21270;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#37327;&#30340;&#25968;&#20540;&#23454;&#39564;&#65292;&#20197;&#39564;&#35777;&#21644;&#35299;&#37322;&#29702;&#35770;&#32467;&#26524;&#65292;&#21253;&#25324;&#23545;&#23384;&#20648;&#35760;&#24518;&#20851;&#32852;&#30340;&#32454;&#31890;&#24230;&#21487;&#35270;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning arguably involves the discovery and memorization of abstract rules. The aim of this paper is to study associative memory mechanisms. Our model is based on high-dimensional matrices consisting of outer products of embeddings, which relates to the inner layers of transformer language models. We derive precise scaling laws with respect to sample size and parameter size, and discuss the statistical efficiency of different estimators, including optimization-based algorithms. We provide extensive numerical experiments to validate and interpret theoretical results, including fine-grained visualizations of the stored memory associations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#32447;&#23398;&#20064;&#38543;&#26426;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;&#20013;&#30340;&#32422;&#26463;&#21152;&#32039;&#21442;&#25968;&#12290;&#36890;&#36807;&#23558;&#32422;&#26463;&#21152;&#32039;&#21442;&#25968;&#36873;&#25321;&#38382;&#39064;&#37325;&#26032;&#34920;&#36848;&#20026;&#20108;&#36827;&#21046;&#22238;&#24402;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#36827;&#34892;&#23398;&#20064;&#65292;&#23454;&#29616;&#20102;&#22312;&#32447;&#23398;&#20064;&#32422;&#26463;&#21152;&#32039;&#21442;&#25968;&#30340;&#30446;&#26631;&#12290;</title><link>http://arxiv.org/abs/2310.02942</link><description>&lt;p&gt;
&#22312;&#38543;&#26426;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;&#20013;&#22312;&#32447;&#32422;&#26463;&#21152;&#32039;&#65306;&#19968;&#31181;&#22238;&#24402;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online Constraint Tightening in Stochastic Model Predictive Control: A Regression Approach. (arXiv:2310.02942v1 [eess.SY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02942
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#32447;&#23398;&#20064;&#38543;&#26426;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;&#20013;&#30340;&#32422;&#26463;&#21152;&#32039;&#21442;&#25968;&#12290;&#36890;&#36807;&#23558;&#32422;&#26463;&#21152;&#32039;&#21442;&#25968;&#36873;&#25321;&#38382;&#39064;&#37325;&#26032;&#34920;&#36848;&#20026;&#20108;&#36827;&#21046;&#22238;&#24402;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#36827;&#34892;&#23398;&#20064;&#65292;&#23454;&#29616;&#20102;&#22312;&#32447;&#23398;&#20064;&#32422;&#26463;&#21152;&#32039;&#21442;&#25968;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#20915;&#27010;&#29575;&#32422;&#26463;&#30340;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#26159;&#25511;&#21046;&#39046;&#22495;&#30340;&#19968;&#39033;&#37325;&#35201;&#25361;&#25112;&#65292;&#22240;&#20026;&#22312;&#24456;&#23569;&#30340;&#29305;&#27530;&#24773;&#20917;&#19979;&#19981;&#23384;&#22312;&#35299;&#26512;&#35299;&#12290;&#19968;&#31181;&#24120;&#35265;&#19988;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#26041;&#27861;&#26159;&#23558;&#27010;&#29575;&#32422;&#26463;&#37325;&#26032;&#34920;&#36848;&#20026;&#20855;&#26377;&#32422;&#26463;&#21152;&#32039;&#21442;&#25968;&#30340;&#30828;&#32422;&#26463;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#31181;&#26041;&#27861;&#20013;&#65292;&#36873;&#21462;&#32422;&#26463;&#21152;&#32039;&#21442;&#25968;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#24182;&#19988;&#21482;&#33021;&#22312;&#24050;&#30693;&#36807;&#31243;&#22122;&#22768;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#33719;&#24471;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#27010;&#29575;&#32422;&#26463;&#36890;&#24120;&#26080;&#27861;&#24471;&#21040;&#20005;&#26684;&#28385;&#36275;&#65292;&#23548;&#33268;&#25104;&#26412;&#36807;&#39640;&#12290;&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22312;&#32447;&#23398;&#20064;&#32422;&#26463;&#21152;&#32039;&#21442;&#25968;&#30340;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#23558;&#38381;&#29615;&#30340;&#32422;&#26463;&#21152;&#32039;&#21442;&#25968;&#36873;&#25321;&#38382;&#39064;&#37325;&#26032;&#34920;&#36848;&#20026;&#20108;&#36827;&#21046;&#22238;&#24402;&#38382;&#39064;&#12290;&#25509;&#30528;&#65292;&#25105;&#20204;&#21033;&#29992;&#39640;&#24230;&#34920;&#36798;&#33021;&#21147;&#30340;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#36827;&#34892;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Solving chance-constrained stochastic optimal control problems is a significant challenge in control. This is because no analytical solutions exist for up to a handful of special cases. A common and computationally efficient approach for tackling chance-constrained stochastic optimal control problems consists of reformulating the chance constraints as hard constraints with a constraint-tightening parameter. However, in such approaches, the choice of constraint-tightening parameter remains challenging, and guarantees can mostly be obtained assuming that the process noise distribution is known a priori. Moreover, the chance constraints are often not tightly satisfied, leading to unnecessarily high costs. This work proposes a data-driven approach for learning the constraint-tightening parameters online during control. To this end, we reformulate the choice of constraint-tightening parameter for the closed-loop as a binary regression problem. We then leverage a highly expressive \gls{gp} m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#24191;&#20041;&#21487;&#38598;&#20013;&#26465;&#20214;&#19979;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;Hoeffding&#19981;&#31561;&#24335;&#65292;&#25299;&#23637;&#20102;&#29616;&#26377;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;Hoeffding&#22411;&#19981;&#31561;&#24335;&#30340;&#24212;&#29992;&#33539;&#22260;&#12290;&#36890;&#36807;&#24212;&#29992;&#35813;&#26694;&#26550;&#21040;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#20960;&#20010;&#38750;&#28176;&#36817;&#20998;&#26512;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.02941</link><description>&lt;p&gt;
Hoeffding&#19981;&#31561;&#24335;&#22312;&#20855;&#26377;&#24191;&#20041;&#21487;&#38598;&#20013;&#26465;&#20214;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Hoeffding's Inequality for Markov Chains under Generalized Concentrability Condition. (arXiv:2310.02941v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02941
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#24191;&#20041;&#21487;&#38598;&#20013;&#26465;&#20214;&#19979;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;Hoeffding&#19981;&#31561;&#24335;&#65292;&#25299;&#23637;&#20102;&#29616;&#26377;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;Hoeffding&#22411;&#19981;&#31561;&#24335;&#30340;&#24212;&#29992;&#33539;&#22260;&#12290;&#36890;&#36807;&#24212;&#29992;&#35813;&#26694;&#26550;&#21040;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#20960;&#20010;&#38750;&#28176;&#36817;&#20998;&#26512;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36890;&#36807;&#31215;&#20998;&#27010;&#29575;&#24230;&#37327;(IPM)&#23450;&#20041;&#30340;&#24191;&#20041;&#21487;&#38598;&#20013;&#26465;&#20214;&#19979;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;Hoeffding&#19981;&#31561;&#24335;&#12290;&#24191;&#20041;&#21487;&#38598;&#20013;&#26465;&#20214;&#24314;&#31435;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#21487;&#20197;&#25554;&#20540;&#21644;&#25193;&#23637;&#29616;&#26377;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;Hoeffding&#22411;&#19981;&#31561;&#24335;&#30340;&#20551;&#35774;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#30340;&#28789;&#27963;&#24615;&#20351;&#24471;Hoeffding&#19981;&#31561;&#24335;&#21487;&#20197;&#24212;&#29992;&#20110;&#20256;&#32479;&#24847;&#20041;&#19978;&#30340;&#38750;&#33258;&#20851;&#39532;&#23572;&#21487;&#22827;&#38142;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#25105;&#20204;&#30340;&#26694;&#26550;&#24212;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#20013;&#30340;&#20960;&#20010;&#38750;&#28176;&#36817;&#20998;&#26512;&#26469;&#35777;&#26126;&#20854;&#23454;&#29992;&#24615;&#65292;&#21253;&#25324;&#65306;(i) &#24102;&#26377;&#39532;&#23572;&#21487;&#22827;&#26679;&#26412;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#19968;&#33324;&#21270;&#30028;&#38480;&#65292;(ii) SGD&#30340;Ployak-Ruppert&#24179;&#22343;&#30340;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#65292;&#20197;&#21450;(iii) &#20855;&#26377;&#24191;&#20041;&#29366;&#24577;&#31354;&#38388;&#30340;&#20241;&#24687;&#39532;&#23572;&#21487;&#22827;&#36172;&#21338;&#26426;&#30340;&#26032;&#30340;&#21518;&#24724;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies Hoeffding's inequality for Markov chains under the generalized concentrability condition defined via integral probability metric (IPM). The generalized concentrability condition establishes a framework that interpolates and extends the existing hypotheses of Markov chain Hoeffding-type inequalities. The flexibility of our framework allows Hoeffding's inequality to be applied beyond the ergodic Markov chains in the traditional sense. We demonstrate the utility by applying our framework to several non-asymptotic analyses arising from the field of machine learning, including (i) a generalization bound for empirical risk minimization with Markovian samples, (ii) a finite sample guarantee for Ployak-Ruppert averaging of SGD, and (iii) a new regret bound for rested Markovian bandits with general state space.
&lt;/p&gt;</description></item><item><title>ELUQuant&#26159;&#19968;&#31181;&#33021;&#22815;&#22312;&#28145;&#24230;&#38750;&#24377;&#24615;&#25955;&#23556;&#20013;&#23545;&#20107;&#20214;&#32423;&#21035;&#30340;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#37327;&#21270;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22522;&#20110;&#29289;&#29702;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#21644;&#24402;&#19968;&#21270;&#27969;&#36817;&#20284;&#35745;&#31639;&#21518;&#39564;&#20998;&#24067;&#65292;&#33021;&#22815;&#25552;&#20379;&#35814;&#32454;&#30340;&#19981;&#30830;&#23450;&#24615;&#25551;&#36848;&#12290;&#36825;&#20026;&#20915;&#31574;&#21046;&#23450;&#21644;&#20943;&#23569;&#30495;&#23454;&#19981;&#20934;&#30830;&#24615;&#25552;&#20379;&#20102;&#23453;&#36149;&#30340;&#24110;&#21161;&#12290;</title><link>http://arxiv.org/abs/2310.02913</link><description>&lt;p&gt;
ELUQuant: &#28145;&#24230;&#38750;&#24377;&#24615;&#25955;&#23556;&#20013;&#20107;&#20214;&#32423;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
ELUQuant: Event-Level Uncertainty Quantification in Deep Inelastic Scattering. (arXiv:2310.02913v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02913
&lt;/p&gt;
&lt;p&gt;
ELUQuant&#26159;&#19968;&#31181;&#33021;&#22815;&#22312;&#28145;&#24230;&#38750;&#24377;&#24615;&#25955;&#23556;&#20013;&#23545;&#20107;&#20214;&#32423;&#21035;&#30340;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#37327;&#21270;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22522;&#20110;&#29289;&#29702;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#21644;&#24402;&#19968;&#21270;&#27969;&#36817;&#20284;&#35745;&#31639;&#21518;&#39564;&#20998;&#24067;&#65292;&#33021;&#22815;&#25552;&#20379;&#35814;&#32454;&#30340;&#19981;&#30830;&#23450;&#24615;&#25551;&#36848;&#12290;&#36825;&#20026;&#20915;&#31574;&#21046;&#23450;&#21644;&#20943;&#23569;&#30495;&#23454;&#19981;&#20934;&#30830;&#24615;&#25552;&#20379;&#20102;&#23453;&#36149;&#30340;&#24110;&#21161;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNN&#65289;&#65292;&#36890;&#36807;&#20351;&#29992;&#20056;&#27861;&#24402;&#19968;&#21270;&#27969;&#65288;MNF&#65289;&#26469;&#36817;&#20284;&#21518;&#39564;&#20998;&#24067;&#65292;&#20197;&#23545;&#29289;&#29702;&#20107;&#20214;&#32423;&#21035;&#36827;&#34892;&#35814;&#32454;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65288;UQ&#65289;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#35782;&#21035;&#24322;&#26041;&#24046;&#30340;&#21807;&#26377;&#24615;&#21644;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#65292;&#25552;&#20379;&#20102;&#31934;&#32454;&#30340;&#29289;&#29702;&#27934;&#23519;&#21147;&#12290;&#24212;&#29992;&#20110;&#28145;&#24230;&#38750;&#24377;&#24615;&#25955;&#23556;&#65288;DIS&#65289;&#20107;&#20214;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#26377;&#25928;&#25552;&#21462;&#20102;&#21160;&#21147;&#23398;&#21464;&#37327;$x$&#65292;$Q^2$&#21644;$y$&#65292;&#19982;&#26368;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#22238;&#24402;&#25216;&#26415;&#22312;&#24615;&#33021;&#19978;&#30456;&#21305;&#37197;&#65292;&#20294;&#20855;&#26377;&#20107;&#20214;&#32423;&#21035;UQ&#30340;&#20851;&#38190;&#22686;&#24378;&#12290;&#23545;&#22522;&#20110;HERA&#30340;H1&#25506;&#27979;&#22120;&#36827;&#34892;&#30340;DIS&#27169;&#25311;&#34920;&#26126;&#20102;&#26410;&#26469;EIC&#30340;&#21487;&#33021;&#24212;&#29992;&#12290;&#27492;&#22806;&#65292;&#36825;&#20026;&#30456;&#20851;&#20219;&#21153;&#38138;&#24179;&#20102;&#36947;&#36335;&#65292;&#22914;&#20107;&#20214;&#36807;&#28388;&#31561;&#20915;&#31574;&#21046;&#23450;&#20013;&#30340;&#31934;&#32454;&#19981;&#30830;&#23450;&#24615;&#25551;&#36848;&#23545;&#20110;&#20915;&#31574;&#21046;&#23450;&#38750;&#24120;&#23453;&#36149;&#65292;&#29305;&#21035;&#26159;&#22312;&#19981;&#30452;&#25509;&#35775;&#38382;&#22522;&#26412;&#20107;&#23454;&#30340;&#24773;&#20917;&#19979;&#65292;&#36824;&#21487;&#20197;&#20943;&#23569;&#30495;&#23454;&#19981;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a physics-informed Bayesian Neural Network (BNN) with flow approximated posteriors using multiplicative normalizing flows (MNF) for detailed uncertainty quantification (UQ) at the physics event-level. Our method is capable of identifying both heteroskedastic aleatoric and epistemic uncertainties, providing granular physical insights. Applied to Deep Inelastic Scattering (DIS) events, our model effectively extracts the kinematic variables $x$, $Q^2$, and $y$, matching the performance of recent deep learning regression techniques but with the critical enhancement of event-level UQ. This detailed description of the underlying uncertainty proves invaluable for decision-making, especially in tasks like event filtering. It also allows for the reduction of true inaccuracies without directly accessing the ground truth. A thorough DIS simulation using the H1 detector at HERA indicates possible applications for the future EIC. Additionally, this paves the way for related tasks such 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#23637;&#31034;&#20102;&#20351;&#29992;&#20855;&#26377;&#26080;&#38480;&#26041;&#24046;&#30340;&#19981;&#24688;&#24403;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#26469;&#23450;&#20041;&#38745;&#27490;&#20294;&#19981;&#22343;&#20540;&#22238;&#24402;&#36807;&#31243;&#30340;&#21487;&#33021;&#24615;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31867;&#29305;&#27530;&#30340;&#19981;&#24688;&#24403;&#26680;&#20989;&#25968;&#26469;&#23454;&#29616;&#27492;&#30446;&#30340;&#12290;</title><link>http://arxiv.org/abs/2310.02877</link><description>&lt;p&gt;
&#26080;&#22343;&#20540;&#22238;&#24402;&#65306;&#19981;&#24688;&#24403;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#21644;&#19981;&#24688;&#24403;&#26680;
&lt;/p&gt;
&lt;p&gt;
Stationarity without mean reversion: Improper Gaussian process regression and improper kernels. (arXiv:2310.02877v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02877
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#23637;&#31034;&#20102;&#20351;&#29992;&#20855;&#26377;&#26080;&#38480;&#26041;&#24046;&#30340;&#19981;&#24688;&#24403;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#26469;&#23450;&#20041;&#38745;&#27490;&#20294;&#19981;&#22343;&#20540;&#22238;&#24402;&#36807;&#31243;&#30340;&#21487;&#33021;&#24615;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31867;&#29305;&#27530;&#30340;&#19981;&#24688;&#24403;&#26680;&#20989;&#25968;&#26469;&#23454;&#29616;&#27492;&#30446;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#22238;&#24402;&#22312;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#24050;&#32463;&#24191;&#27867;&#27969;&#34892;&#12290;GP&#22238;&#24402;&#30340;&#34892;&#20026;&#21462;&#20915;&#20110;&#21327;&#26041;&#24046;&#20989;&#25968;&#30340;&#36873;&#25321;&#12290;&#22312;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#65292;&#38745;&#27490;&#21327;&#26041;&#24046;&#20989;&#25968;&#26159;&#39318;&#36873;&#12290;&#28982;&#32780;&#65292;&#65288;&#38750;&#21608;&#26399;&#24615;&#30340;&#65289;&#38745;&#27490;&#21327;&#26041;&#24046;&#20989;&#25968;&#24635;&#26159;&#22343;&#20540;&#22238;&#24402;&#30340;&#65292;&#22240;&#27492;&#22312;&#24212;&#29992;&#20110;&#19981;&#36890;&#36807;&#21040;&#22266;&#23450;&#20840;&#23616;&#22343;&#20540;&#20540;&#30340;&#25968;&#25454;&#26102;&#21487;&#33021;&#34920;&#29616;&#20986;&#30149;&#24577;&#34892;&#20026;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#20855;&#26377;&#26080;&#38480;&#26041;&#24046;&#30340;&#19981;&#24688;&#24403;GP&#20808;&#39564;&#26469;&#23450;&#20041;&#38745;&#27490;&#20294;&#19981;&#22343;&#20540;&#22238;&#24402;&#36807;&#31243;&#26159;&#21487;&#33021;&#30340;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#22823;&#31867;&#21482;&#33021;&#22312;&#36825;&#31181;&#19981;&#24688;&#24403;&#30340;&#33539;&#22260;&#20869;&#23450;&#20041;&#30340;&#19981;&#24688;&#24403;&#26680;&#20989;&#25968;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#24179;&#28369;&#34892;&#36208;&#26680;&#65292;&#23427;&#20135;&#29983;&#26080;&#38480;&#24179;&#28369;&#30340;&#26679;&#26412;&#65292;&#20197;&#21450;&#19968;&#31867;&#19981;&#24688;&#24403;&#30340;Matern&#26680;&#65292;&#23427;&#21487;&#20197;&#34987;&#23450;&#20041;&#20026;&#20219;&#24847;&#25972;&#25968;j&#20493;&#21487;&#24494;&#12290;&#25152;&#24471;&#21040;&#30340;&#21518;&#39564;&#20998;&#24067;&#21487;&#20197;&#29992;&#35299;&#26512;&#30340;&#26041;&#24335;&#35745;&#31639;&#20986;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes (GP) regression has gained substantial popularity in machine learning applications. The behavior of a GP regression depends on the choice of covariance function. Stationary covariance functions are favorite in machine learning applications. However, (non-periodic) stationary covariance functions are always mean reverting and can therefore exhibit pathological behavior when applied to data that does not relax to a fixed global mean value. In this paper, we show that it is possible to use improper GP prior with infinite variance to define processes that are stationary but not mean reverting. To this aim, we introduce a large class of improper kernels that can only be defined in this improper regime. Specifically, we introduce the Smooth Walk kernel, which produces infinitely smooth samples, and a family of improper Mat\'ern kernels, which can be defined to be $j$-times differentiable for any integer $j$. The resulting posterior distributions can be computed analyticall
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#20998;&#24067;&#30340;&#20849;&#24418;&#39044;&#27979;&#31639;&#27861;LPCI&#65292;&#29992;&#20110;&#22788;&#29702;&#38271;&#26399;&#25968;&#25454;&#12290;&#36890;&#36807;&#23558;&#21097;&#20313;&#25968;&#25454;&#24314;&#27169;&#20026;&#20998;&#20301;&#25968;&#22266;&#23450;&#25928;&#24212;&#22238;&#24402;&#38382;&#39064;&#65292;&#24182;&#20351;&#29992;&#35757;&#32451;&#22909;&#30340;&#22238;&#24402;&#22120;&#26500;&#24314;&#39044;&#27979;&#21306;&#38388;&#65292;LPCI&#23454;&#29616;&#20102;&#26377;&#25928;&#30340;&#27178;&#25130;&#38754;&#35206;&#30422;&#65292;&#24182;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#20934;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2310.02863</link><description>&lt;p&gt;
&#38271;&#26399;&#25968;&#25454;&#30340;&#20849;&#24418;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Conformal Predictions for Longitudinal Data. (arXiv:2310.02863v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02863
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#20998;&#24067;&#30340;&#20849;&#24418;&#39044;&#27979;&#31639;&#27861;LPCI&#65292;&#29992;&#20110;&#22788;&#29702;&#38271;&#26399;&#25968;&#25454;&#12290;&#36890;&#36807;&#23558;&#21097;&#20313;&#25968;&#25454;&#24314;&#27169;&#20026;&#20998;&#20301;&#25968;&#22266;&#23450;&#25928;&#24212;&#22238;&#24402;&#38382;&#39064;&#65292;&#24182;&#20351;&#29992;&#35757;&#32451;&#22909;&#30340;&#22238;&#24402;&#22120;&#26500;&#24314;&#39044;&#27979;&#21306;&#38388;&#65292;LPCI&#23454;&#29616;&#20102;&#26377;&#25928;&#30340;&#27178;&#25130;&#38754;&#35206;&#30422;&#65292;&#24182;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#20934;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#20998;&#24067;&#30340;&#20849;&#24418;&#39044;&#27979;&#31639;&#27861;&#65292;&#31216;&#20026;&#38271;&#26399;&#39044;&#27979;&#20849;&#24418;&#25512;&#26029;&#65288;LPCI&#65289;&#65292;&#29992;&#20110;&#22788;&#29702;&#38271;&#26399;&#25968;&#25454;&#12290;&#30446;&#21069;&#38024;&#23545;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#20849;&#24418;&#39044;&#27979;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#21333;&#21464;&#37327;&#35774;&#32622;&#19978;&#65292;&#22240;&#27492;&#22312;&#24212;&#29992;&#20110;&#38271;&#26399;&#25968;&#25454;&#38598;&#20013;&#30340;&#27599;&#20010;&#26102;&#38388;&#24207;&#21015;&#26102;&#32570;&#20047;&#27178;&#25130;&#38754;&#35206;&#30422;&#12290;&#30446;&#21069;&#38271;&#26399;&#25968;&#25454;&#30340;&#26368;&#26032;&#26041;&#27861;&#20381;&#36182;&#20110;&#21019;&#24314;&#26080;&#38480;&#23485;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#20197;&#20445;&#35777;&#27178;&#25130;&#38754;&#21644;&#28176;&#36817;&#38271;&#26399;&#35206;&#30422;&#29575;&#12290;&#25152;&#25552;&#20986;&#30340;LPCI&#26041;&#27861;&#36890;&#36807;&#30830;&#20445;&#21516;&#26102;&#20445;&#35777;&#32437;&#21521;&#21644;&#27178;&#25130;&#38754;&#35206;&#30422;&#32780;&#26080;&#38656;&#20351;&#29992;&#26080;&#38480;&#23485;&#30340;&#21306;&#38388;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#22312;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#23558;&#21097;&#20313;&#25968;&#25454;&#24314;&#27169;&#20026;&#19968;&#20010;&#20998;&#20301;&#25968;&#22266;&#23450;&#25928;&#24212;&#22238;&#24402;&#38382;&#39064;&#65292;&#24182;&#20351;&#29992;&#35757;&#32451;&#22909;&#30340;&#20998;&#20301;&#25968;&#22238;&#24402;&#22120;&#26500;&#24314;&#39044;&#27979;&#21306;&#38388;&#12290;&#25105;&#20204;&#24191;&#27867;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;LPCI&#23454;&#29616;&#20102;&#26377;&#25928;&#30340;&#27178;&#25130;&#38754;&#35206;&#30422;&#65292;&#24182;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#20934;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce Longitudinal Predictive Conformal Inference (LPCI), a novel distribution-free conformal prediction algorithm for longitudinal data. Current conformal prediction approaches for time series data predominantly focus on the univariate setting, and thus lack cross-sectional coverage when applied individually to each time series in a longitudinal dataset. The current state-of-the-art for longitudinal data relies on creating infinitely-wide prediction intervals to guarantee both cross-sectional and asymptotic longitudinal coverage. The proposed LPCI method addresses this by ensuring that both longitudinal and cross-sectional coverages are guaranteed without resorting to infinitely wide intervals. In our approach, we model the residual data as a quantile fixed-effects regression problem, constructing prediction intervals with a trained quantile regressor. Our extensive experiments demonstrate that LPCI achieves valid cross-sectional coverage and outperforms existing benchmarks in 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24369;&#20998;&#24067;&#19981;&#21464;&#24615;&#36827;&#34892;&#22810;&#39046;&#22495;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#34701;&#20837;&#36825;&#31181;&#19981;&#21464;&#24615;&#30340;&#33258;&#32534;&#30721;&#22120;&#33021;&#22815;&#21487;&#38752;&#22320;&#35782;&#21035;&#20986;&#31283;&#23450;&#30340;&#21464;&#37327;&#38598;&#21512;&#12290;</title><link>http://arxiv.org/abs/2310.02854</link><description>&lt;p&gt;
&#36890;&#36807;&#24369;&#20998;&#24067;&#19981;&#21464;&#24615;&#23454;&#29616;&#22810;&#39046;&#22495;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Multi-Domain Causal Representation Learning via Weak Distributional Invariances. (arXiv:2310.02854v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02854
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24369;&#20998;&#24067;&#19981;&#21464;&#24615;&#36827;&#34892;&#22810;&#39046;&#22495;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#34701;&#20837;&#36825;&#31181;&#19981;&#21464;&#24615;&#30340;&#33258;&#32534;&#30721;&#22120;&#33021;&#22815;&#21487;&#38752;&#22320;&#35782;&#21035;&#20986;&#31283;&#23450;&#30340;&#21464;&#37327;&#38598;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#24050;&#25104;&#20026;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#30340;&#26680;&#24515;&#12290;&#29305;&#21035;&#26159;&#65292;&#22810;&#39046;&#22495;&#25968;&#25454;&#38598;&#20026;&#23637;&#31034;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#30456;&#23545;&#20110;&#26631;&#20934;&#26080;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#30340;&#20248;&#21183;&#25552;&#20379;&#20102;&#33258;&#28982;&#26426;&#20250;&#12290;&#34429;&#28982;&#26368;&#36817;&#30340;&#30740;&#31350;&#22312;&#23398;&#20064;&#22240;&#26524;&#34920;&#31034;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#65292;&#20294;&#30001;&#20110;&#36807;&#20110;&#31616;&#21270;&#25968;&#25454;&#30340;&#20551;&#35774;&#65292;&#23427;&#20204;&#24448;&#24448;&#19981;&#33021;&#36866;&#29992;&#20110;&#22810;&#39046;&#22495;&#25968;&#25454;&#38598;&#65307;&#20363;&#22914;&#65292;&#27599;&#20010;&#39046;&#22495;&#37117;&#26469;&#33258;&#19981;&#21516;&#30340;&#21333;&#33410;&#28857;&#23436;&#32654;&#24178;&#39044;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25918;&#23485;&#20102;&#36825;&#20123;&#20551;&#35774;&#65292;&#24182;&#21033;&#29992;&#20197;&#19979;&#35266;&#23519;&#32467;&#26524;&#65306;&#22312;&#22810;&#39046;&#22495;&#25968;&#25454;&#20013;&#65292;&#24448;&#24448;&#23384;&#22312;&#19968;&#37096;&#20998;&#28508;&#21464;&#37327;&#30340;&#26576;&#20123;&#20998;&#24067;&#23646;&#24615;&#65288;&#20363;&#22914;&#25903;&#25345;&#24230;&#12289;&#26041;&#24046;&#65289;&#22312;&#19981;&#21516;&#39046;&#22495;&#20043;&#38388;&#20445;&#25345;&#31283;&#23450;&#65307;&#24403;&#27599;&#20010;&#39046;&#22495;&#26469;&#33258;&#22810;&#33410;&#28857;&#19981;&#23436;&#32654;&#24178;&#39044;&#26102;&#65292;&#36825;&#20010;&#23646;&#24615;&#25104;&#31435;&#12290;&#21033;&#29992;&#36825;&#20010;&#35266;&#23519;&#32467;&#26524;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#34701;&#20837;&#36825;&#31181;&#19981;&#21464;&#24615;&#30340;&#33258;&#32534;&#30721;&#22120;&#33021;&#22815;&#21487;&#38752;&#22320;&#35782;&#21035;&#20986;&#31283;&#23450;&#30340;&#21464;&#37327;&#38598;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal representation learning has emerged as the center of action in causal machine learning research. In particular, multi-domain datasets present a natural opportunity for showcasing the advantages of causal representation learning over standard unsupervised representation learning. While recent works have taken crucial steps towards learning causal representations, they often lack applicability to multi-domain datasets due to over-simplifying assumptions about the data; e.g. each domain comes from a different single-node perfect intervention. In this work, we relax these assumptions and capitalize on the following observation: there often exists a subset of latents whose certain distributional properties (e.g., support, variance) remain stable across domains; this property holds when, for example, each domain comes from a multi-node imperfect intervention. Leveraging this observation, we show that autoencoders that incorporate such invariances can provably identify the stable set o
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LSL-GFN&#30340;&#26032;&#22411;&#26550;&#26500;&#35774;&#35745;&#65292;&#21487;&#20197;&#22823;&#22823;&#21152;&#36895;&#28201;&#24230;&#26465;&#20214;&#19979;GFlowNets&#30340;&#35757;&#32451;&#65292;&#20174;&#32780;&#25552;&#39640;GFlowNets&#30340;&#25506;&#32034;&#21644;&#21033;&#29992;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.02823</link><description>&lt;p&gt;
&#23398;&#20064;&#28201;&#24230;&#26465;&#20214;&#19979;&#23610;&#24230;&#26631;&#37327;&#21270;&#30340;GFlowNets
&lt;/p&gt;
&lt;p&gt;
Learning to Scale Logits for Temperature-Conditional GFlowNets. (arXiv:2310.02823v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02823
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LSL-GFN&#30340;&#26032;&#22411;&#26550;&#26500;&#35774;&#35745;&#65292;&#21487;&#20197;&#22823;&#22823;&#21152;&#36895;&#28201;&#24230;&#26465;&#20214;&#19979;GFlowNets&#30340;&#35757;&#32451;&#65292;&#20174;&#32780;&#25552;&#39640;GFlowNets&#30340;&#25506;&#32034;&#21644;&#21033;&#29992;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
GFlowNets&#26159;&#19968;&#31181;&#27010;&#29575;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#38543;&#26426;&#31574;&#30053;&#26469;&#39034;&#24207;&#29983;&#25104;&#32452;&#21512;&#32467;&#26500;&#65292;&#20363;&#22914;&#20998;&#23376;&#22270;&#12290;&#23427;&#20204;&#30340;&#35757;&#32451;&#30446;&#26631;&#26159;&#25353;&#27604;&#20363;&#37319;&#26679;&#20855;&#26377;&#30456;&#24212;&#28201;&#24230;&#35843;&#33410;&#30340;&#23545;&#35937;&#30340;&#22870;&#21169;&#12290;&#22312;GFlowNets&#20013;&#65292;&#28201;&#24230;&#26465;&#20214;&#19979;&#30340;GFlowNets&#20195;&#34920;&#20102;&#19968;&#31995;&#21015;&#30001;&#28201;&#24230;&#32034;&#24341;&#30340;&#31574;&#30053;&#65292;&#27599;&#20010;&#31574;&#30053;&#19982;&#30456;&#24212;&#30340;&#28201;&#24230;&#35843;&#33410;&#22870;&#21169;&#20989;&#25968;&#30456;&#20851;&#32852;&#12290;&#28201;&#24230;&#26465;&#20214;&#19979;&#30340;GFlowNets&#30340;&#20027;&#35201;&#20248;&#21183;&#22312;&#20110;&#36890;&#36807;&#35843;&#25972;&#28201;&#24230;&#26469;&#25511;&#21046;&#23545;GFlowNets&#30340;&#25506;&#32034;&#21644;&#21033;&#29992;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#23398;&#20064;&#28201;&#24230;&#26465;&#20214;&#19979;&#23610;&#24230;&#26631;&#37327;&#21270;&#30340;GFlowNets&#65288;LSL-GFN&#65289;&#30340;&#26032;&#22411;&#26550;&#26500;&#35774;&#35745;&#65292;&#23427;&#26497;&#22823;&#22320;&#21152;&#36895;&#20102;&#28201;&#24230;&#26465;&#20214;&#19979;GFlowNets&#30340;&#35757;&#32451;&#12290;&#23427;&#22522;&#20110;&#19968;&#20010;&#24605;&#24819;&#65292;&#21363;&#20043;&#21069;&#25552;&#20986;&#30340;&#28201;&#24230;&#26465;&#20214;&#26041;&#27861;&#22312;&#28145;&#24230;&#32593;&#32476;&#30340;&#35757;&#32451;&#20013;&#24341;&#20837;&#20102;&#25968;&#20540;&#25361;&#25112;&#65292;&#22240;&#20026;&#19981;&#21516;&#30340;&#28201;&#24230;&#21487;&#33021;&#23548;&#33268;&#38750;&#24120;&#19981;&#21516;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
GFlowNets are probabilistic models that learn a stochastic policy that sequentially generates compositional structures, such as molecular graphs. They are trained with the objective of sampling such objects with probability proportional to the object's reward. Among GFlowNets, the temperature-conditional GFlowNets represent a family of policies indexed by temperature, and each is associated with the correspondingly tempered reward function. The major benefit of temperature-conditional GFlowNets is the controllability of GFlowNets' exploration and exploitation through adjusting temperature. We propose Learning to Scale Logits for temperature-conditional GFlowNets (LSL-GFN), a novel architectural design that greatly accelerates the training of temperature-conditional GFlowNets. It is based on the idea that previously proposed temperature-conditioning approaches introduced numerical challenges in the training of the deep network because different temperatures may give rise to very differe
&lt;/p&gt;</description></item><item><title>&#20316;&#32773;&#35748;&#20026;&#27431;&#30431;AI&#27861;&#26696;&#23545;AI&#31995;&#32479;&#30340;&#36136;&#37327;&#20445;&#35777;&#26041;&#24335;&#23384;&#22312;&#19981;&#36275;&#65292;&#24182;&#25351;&#20986;&#22522;&#20110;&#32479;&#35745;&#23398;&#26377;&#25928;&#27979;&#35797;&#21450;&#20934;&#30830;&#23450;&#20041;&#24212;&#29992;&#26159;&#30830;&#20445;AI&#31995;&#32479;&#21151;&#33021;&#21487;&#20449;&#24230;&#30340;&#26680;&#24515;&#12290;</title><link>http://arxiv.org/abs/2310.02727</link><description>&lt;p&gt;
AI&#31995;&#32479;&#30340;&#21151;&#33021;&#21487;&#20449;&#24230;&#36890;&#36807;&#32479;&#35745;&#23398;&#26377;&#25928;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Functional trustworthiness of AI systems by statistically valid testing. (arXiv:2310.02727v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02727
&lt;/p&gt;
&lt;p&gt;
&#20316;&#32773;&#35748;&#20026;&#27431;&#30431;AI&#27861;&#26696;&#23545;AI&#31995;&#32479;&#30340;&#36136;&#37327;&#20445;&#35777;&#26041;&#24335;&#23384;&#22312;&#19981;&#36275;&#65292;&#24182;&#25351;&#20986;&#22522;&#20110;&#32479;&#35745;&#23398;&#26377;&#25928;&#27979;&#35797;&#21450;&#20934;&#30830;&#23450;&#20041;&#24212;&#29992;&#26159;&#30830;&#20445;AI&#31995;&#32479;&#21151;&#33021;&#21487;&#20449;&#24230;&#30340;&#26680;&#24515;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20316;&#32773;&#20851;&#27880;&#27431;&#27954;&#20844;&#27665;&#30340;&#23433;&#20840;&#12289;&#20581;&#24247;&#21644;&#26435;&#30410;&#38382;&#39064;&#65292;&#22240;&#20026;&#24403;&#21069;&#27431;&#30431;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#27861;&#26696;&#30340;&#33609;&#26696;&#23545;AI&#31995;&#32479;&#30340;&#31526;&#21512;&#24615;&#35780;&#20272;&#25152;&#38656;&#30340;&#25514;&#26045;&#21644;&#31243;&#24207;&#19981;&#36275;&#12290;&#25105;&#20204;&#27880;&#24847;&#21040;&#65292;&#27431;&#30431;AI&#27861;&#26696;&#30340;&#24403;&#21069;&#33609;&#26696;&#20197;&#21450;&#22312;CEN/CENELEC&#36827;&#34892;&#30340;&#37197;&#22871;&#26631;&#20934;&#21270;&#24037;&#20316;&#65292;&#37117;&#37319;&#21462;&#20102;&#19968;&#20010;&#35266;&#28857;&#65292;&#21363;AI&#31995;&#32479;&#30340;&#23454;&#38469;&#21151;&#33021;&#20445;&#35777;&#20284;&#20046;&#26159;&#19981;&#20999;&#23454;&#38469;&#19988;&#36807;&#20110;&#22797;&#26434;&#30340;&#12290;&#28982;&#32780;&#65292;&#21046;&#23450;&#19968;&#20010;&#31526;&#21512;&#24615;&#35780;&#20272;&#31243;&#24207;&#65292;&#20351;&#26410;&#32463;&#20805;&#20998;&#35780;&#20272;&#30340;AI&#31995;&#32479;&#20135;&#29983;&#34394;&#20551;&#30340;&#20449;&#20219;&#24187;&#35937;&#65292;&#20805;&#20854;&#37327;&#26159;&#24188;&#31258;&#30340;&#65292;&#20805;&#20854;&#26356;&#31967;&#30340;&#24773;&#20917;&#26159;&#20005;&#37325;&#30095;&#24573;&#30340;&#12290;&#22240;&#27492;&#65292;&#27431;&#30431;AI&#27861;&#26696;&#38169;&#36807;&#20102;&#30830;&#20445;&#36890;&#36807;&#21151;&#33021;&#21487;&#20449;&#24230;&#26469;&#30830;&#20445;&#36136;&#37327;&#21644;&#27491;&#30830;&#20998;&#37197;&#36131;&#20219;&#30340;&#30446;&#30340;&#12290;AI&#20915;&#31574;&#31995;&#32479;&#30340;&#21487;&#20449;&#24230;&#39318;&#20808;&#22312;&#20110;&#23545;&#38543;&#26426;&#36873;&#25321;&#30340;&#26679;&#26412;&#36827;&#34892;&#27491;&#30830;&#30340;&#32479;&#35745;&#27979;&#35797;&#65292;&#24182;&#22312;&#23450;&#20041;&#24212;&#29992;&#30340;&#20934;&#30830;&#24615;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
The authors are concerned about the safety, health, and rights of the European citizens due to inadequate measures and procedures required by the current draft of the EU Artificial Intelligence (AI) Act for the conformity assessment of AI systems. We observe that not only the current draft of the EU AI Act, but also the accompanying standardization efforts in CEN/CENELEC, have resorted to the position that real functional guarantees of AI systems supposedly would be unrealistic and too complex anyways. Yet enacting a conformity assessment procedure that creates the false illusion of trust in insufficiently assessed AI systems is at best naive and at worst grossly negligent. The EU AI Act thus misses the point of ensuring quality by functional trustworthiness and correctly attributing responsibilities.  The trustworthiness of an AI decision system lies first and foremost in the correct statistical testing on randomly selected samples and in the precision of the definition of the applica
&lt;/p&gt;</description></item><item><title>ED-NeRF &#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340; 3D &#22330;&#26223;&#32534;&#36753;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#22330;&#26223;&#23884;&#20837;&#21040;&#28508;&#31354;&#38388;&#20013;&#65292;&#24471;&#21040;&#26356;&#24555;&#36895;&#19988;&#26356;&#26131;&#20110;&#32534;&#36753;&#30340; NeRF &#39592;&#24178;&#12290;</title><link>http://arxiv.org/abs/2310.02712</link><description>&lt;p&gt;
ED-NeRF: &#20351;&#29992;&#28508;&#31354;&#38388; NeRF &#23454;&#29616;&#39640;&#25928;&#30340;&#25991;&#26412;&#24341;&#23548;&#30340; 3D &#22330;&#26223;&#32534;&#36753;
&lt;/p&gt;
&lt;p&gt;
ED-NeRF: Efficient Text-Guided Editing of 3D Scene using Latent Space NeRF. (arXiv:2310.02712v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02712
&lt;/p&gt;
&lt;p&gt;
ED-NeRF &#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340; 3D &#22330;&#26223;&#32534;&#36753;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#22330;&#26223;&#23884;&#20837;&#21040;&#28508;&#31354;&#38388;&#20013;&#65292;&#24471;&#21040;&#26356;&#24555;&#36895;&#19988;&#26356;&#26131;&#20110;&#32534;&#36753;&#30340; NeRF &#39592;&#24178;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#25991;&#26412;&#21040;&#22270;&#20687;&#25193;&#25955;&#27169;&#22411;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#22312;&#20108;&#32500;&#22270;&#20687;&#29983;&#25104;&#26041;&#38754;&#21462;&#24471;&#20102;&#31361;&#30772;&#24615;&#30340;&#24615;&#33021;&#12290;&#36825;&#20123;&#36827;&#23637;&#24050;&#32463;&#25193;&#23637;&#21040;&#19977;&#32500;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#20174;&#25991;&#26412;&#25551;&#36848;&#20013;&#29983;&#25104;&#26032;&#30340;&#19977;&#32500;&#23545;&#35937;&#12290;&#36825;&#28436;&#21464;&#25104;&#20102; NeRF &#32534;&#36753;&#26041;&#27861;&#65292;&#36890;&#36807;&#25991;&#26412;&#26465;&#20214;&#20801;&#35768;&#23545;&#29616;&#26377;&#30340;&#19977;&#32500;&#23545;&#35937;&#36827;&#34892;&#25805;&#20316;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340; NeRF &#32534;&#36753;&#25216;&#26415;&#22312;&#24615;&#33021;&#19978;&#38754;&#20020;&#30528;&#19968;&#20123;&#38480;&#21046;&#65292;&#22914;&#35757;&#32451;&#36895;&#24230;&#24930;&#21644;&#20351;&#29992;&#30340;&#25439;&#22833;&#20989;&#25968;&#19981;&#20805;&#20998;&#32771;&#34385;&#32534;&#36753;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340; 3D NeRF &#32534;&#36753;&#26041;&#27861;&#65292;&#31216;&#20026; ED-NeRF&#65292;&#36890;&#36807;&#23558;&#30495;&#23454;&#19990;&#30028;&#22330;&#26223;&#25104;&#21151;&#23884;&#20837;&#21040;&#28508;&#25193;&#25955;&#27169;&#22411; (LDM) &#30340;&#28508;&#31354;&#38388;&#20013;&#65292;&#36890;&#36807;&#29420;&#29305;&#30340;&#32454;&#21270;&#23618;&#12290;&#36825;&#31181;&#26041;&#27861;&#20351;&#25105;&#20204;&#33021;&#22815;&#33719;&#24471;&#19968;&#20010;&#19981;&#20165;&#26356;&#24555;&#65292;&#32780;&#19988;&#26356;&#36866;&#21512;&#20110;&#32534;&#36753;&#30340; NeRF &#39592;&#24178;&#65292;&#19982;&#20256;&#32479;&#30340;&#22270;&#20687;&#31354;&#38388; NeRF &#32534;&#36753;&#30456;&#27604;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, there has been a significant advancement in text-to-image diffusion models, leading to groundbreaking performance in 2D image generation. These advancements have been extended to 3D models, enabling the generation of novel 3D objects from textual descriptions. This has evolved into NeRF editing methods, which allow the manipulation of existing 3D objects through textual conditioning. However, existing NeRF editing techniques have faced limitations in their performance due to slow training speeds and the use of loss functions that do not adequately consider editing. To address this, here we present a novel 3D NeRF editing approach dubbed ED-NeRF by successfully embedding real-world scenes into the latent space of the latent diffusion model (LDM) through a unique refinement layer. This approach enables us to obtain a NeRF backbone that is not only faster but also more amenable to editing compared to traditional image space NeRF editing. Furthermore, we propose an improved loss 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#23616;&#37096;&#25628;&#32034;&#35757;&#32451;GFlowNets&#65292;&#36890;&#36807;&#30772;&#22351;&#21644;&#37325;&#26500;&#30340;&#26041;&#24335;&#25506;&#32034;&#23616;&#37096;&#37051;&#22495;&#65292;&#20998;&#21035;&#30001;&#21453;&#21521;&#21644;&#27491;&#21521;&#31574;&#30053;&#24341;&#23548;&#65292;&#20351;&#24471;&#26679;&#26412;&#20559;&#21521;&#39640;&#22870;&#21169;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2310.02710</link><description>&lt;p&gt;
&#26412;&#22320;&#25628;&#32034;GFlowNets
&lt;/p&gt;
&lt;p&gt;
Local Search GFlowNets. (arXiv:2310.02710v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02710
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#23616;&#37096;&#25628;&#32034;&#35757;&#32451;GFlowNets&#65292;&#36890;&#36807;&#30772;&#22351;&#21644;&#37325;&#26500;&#30340;&#26041;&#24335;&#25506;&#32034;&#23616;&#37096;&#37051;&#22495;&#65292;&#20998;&#21035;&#30001;&#21453;&#21521;&#21644;&#27491;&#21521;&#31574;&#30053;&#24341;&#23548;&#65292;&#20351;&#24471;&#26679;&#26412;&#20559;&#21521;&#39640;&#22870;&#21169;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27969;&#32593;&#32476;(GFlowNets)&#26159;&#19968;&#31181;&#23398;&#20064;&#19982;&#22870;&#21169;&#25104;&#27604;&#20363;&#30340;&#31163;&#25955;&#23545;&#35937;&#20998;&#24067;&#30340;&#25674;&#36824;&#37319;&#26679;&#26041;&#27861;&#12290;GFlowNets&#20855;&#26377;&#29983;&#25104;&#22810;&#26679;&#26679;&#26412;&#30340;&#26174;&#33879;&#33021;&#21147;&#65292;&#20294;&#30001;&#20110;&#24191;&#27867;&#26679;&#26412;&#31354;&#38388;&#19978;&#30340;&#36807;&#24230;&#25506;&#32034;&#65292;&#26377;&#26102;&#38590;&#20197;&#19968;&#33268;&#22320;&#29983;&#25104;&#39640;&#22870;&#21169;&#30340;&#26679;&#26412;&#12290;&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#23616;&#37096;&#25628;&#32034;&#35757;&#32451;GFlowNets&#65292;&#36890;&#36807;&#30772;&#22351;&#21644;&#37325;&#26500;&#30340;&#26041;&#24335;&#25506;&#32034;&#23616;&#37096;&#37051;&#22495;&#65292;&#20998;&#21035;&#30001;&#21453;&#21521;&#21644;&#27491;&#21521;&#31574;&#30053;&#24341;&#23548;&#12290;&#36825;&#20351;&#24471;&#26679;&#26412;&#20559;&#21521;&#39640;&#22870;&#21169;&#35299;&#20915;&#26041;&#26696;&#65292;&#32780;&#20256;&#32479;&#30340;GFlowNet&#35299;&#20915;&#26041;&#26696;&#29983;&#25104;&#26041;&#26696;&#21017;&#20351;&#29992;&#27491;&#21521;&#31574;&#30053;&#20174;&#22836;&#29983;&#25104;&#35299;&#20915;&#26041;&#26696;&#12290;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#22312;&#20960;&#20010;&#29983;&#21270;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative Flow Networks (GFlowNets) are amortized sampling methods that learn a distribution over discrete objects proportional to their rewards. GFlowNets exhibit a remarkable ability to generate diverse samples, yet occasionally struggle to consistently produce samples with high rewards due to over-exploration on wide sample space. This paper proposes to train GFlowNets with local search which focuses on exploiting high rewarded sample space to resolve this issue. Our main idea is to explore the local neighborhood via destruction and reconstruction guided by backward and forward policies, respectively. This allows biasing the samples toward high-reward solutions, which is not possible for a typical GFlowNet solution generation scheme which uses the forward policy to generate the solution from scratch. Extensive experiments demonstrate a remarkable performance improvement in several biochemical tasks. Source code is available: \url{https://github.com/dbsxodud-11/ls_gfn}.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#21464;&#20998;&#36125;&#21494;&#26031;&#27010;&#29575;&#22359;&#39033;&#20998;&#35299;&#65288;pBTD&#65289;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#39640;&#38454;&#25968;&#32452;&#30340;&#24314;&#27169;&#65292;&#36890;&#36807;&#20351;&#29992;von-Mises Fisher&#30697;&#38453;&#20998;&#24067;&#26469;&#23454;&#29616;&#27491;&#20132;&#24615;&#32422;&#26463;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;pBTD&#22312;&#22122;&#22768;&#25968;&#25454;&#21644;&#27169;&#22411;&#39034;&#24207;&#37327;&#21270;&#26041;&#38754;&#20855;&#26377;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.02694</link><description>&lt;p&gt;
&#39640;&#38454;&#25968;&#32452;&#24314;&#27169;&#30340;&#27010;&#29575;&#22359;&#39033;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Block Term Decomposition for the Modelling of Higher-Order Arrays. (arXiv:2310.02694v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02694
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#21464;&#20998;&#36125;&#21494;&#26031;&#27010;&#29575;&#22359;&#39033;&#20998;&#35299;&#65288;pBTD&#65289;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#39640;&#38454;&#25968;&#32452;&#30340;&#24314;&#27169;&#65292;&#36890;&#36807;&#20351;&#29992;von-Mises Fisher&#30697;&#38453;&#20998;&#24067;&#26469;&#23454;&#29616;&#27491;&#20132;&#24615;&#32422;&#26463;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;pBTD&#22312;&#22122;&#22768;&#25968;&#25454;&#21644;&#27169;&#22411;&#39034;&#24207;&#37327;&#21270;&#26041;&#38754;&#20855;&#26377;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24352;&#37327;&#22312;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#26080;&#22788;&#19981;&#22312;&#65292;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;&#24050;&#32463;&#25104;&#20026;&#34920;&#24449;&#39640;&#38454;&#32467;&#26500;&#30340;&#37325;&#35201;&#24037;&#20855;&#12290;&#20998;&#35299;&#21253;&#25324;&#22806;&#31215;&#31209;&#26631;&#20934;&#22810;&#39033;&#24335;&#20998;&#35299;&#65288;CPD&#65289;&#20197;&#21450;&#22810;&#32447;&#24615;&#31209;&#22270;&#23572;&#20811;&#20998;&#35299;&#65292;&#20854;&#20013;&#22359;&#39033;&#20998;&#35299;&#65288;BTD&#65289;&#26159;&#20004;&#31181;&#34920;&#31034;&#20043;&#38388;&#30340;&#32467;&#26500;&#21270;&#20013;&#38388;&#25554;&#20540;&#12290;&#34429;&#28982;CPD&#12289;&#22270;&#23572;&#20811;&#21644;BTD&#20256;&#32479;&#19978;&#20381;&#36182;&#20110;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65292;&#20294;&#24050;&#32463;&#20351;&#29992;&#36125;&#21494;&#26031;&#25512;&#26029;&#24418;&#25104;&#20102;&#27010;&#29575;CPD&#21644;&#22270;&#23572;&#20811;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#21464;&#20998;&#36125;&#21494;&#26031;&#27010;&#29575;BTD&#65292;&#23427;&#20351;&#29992;von-Mises Fisher&#30697;&#38453;&#20998;&#24067;&#22312;&#24418;&#25104;BTD&#30340;&#22810;&#32447;&#24615;&#22270;&#23572;&#20811;&#37096;&#20998;&#20013;&#26045;&#21152;&#27491;&#20132;&#24615;&#12290;&#22312;&#21512;&#25104;&#21644;&#20004;&#20010;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#65292;&#25105;&#20204;&#31361;&#20986;&#20102;&#36125;&#21494;&#26031;&#25512;&#26029;&#36807;&#31243;&#65292;&#24182;&#20351;&#29992;&#25552;&#35758;&#30340;pBTD&#23545;&#22122;&#22768;&#25968;&#25454;&#36827;&#34892;&#20102;&#28436;&#31034;&#21644;&#27169;&#22411;&#39034;&#24207;&#37327;&#21270;&#12290;&#25105;&#20204;&#21457;&#29616;&#27010;&#29575;BTD&#33021;&#22815;&#37327;&#21270;...
&lt;/p&gt;
&lt;p&gt;
Tensors are ubiquitous in science and engineering and tensor factorization approaches have become important tools for the characterization of higher order structure. Factorizations includes the outer-product rank Canonical Polyadic Decomposition (CPD) as well as the multi-linear rank Tucker decomposition in which the Block-Term Decomposition (BTD) is a structured intermediate interpolating between these two representations. Whereas CPD, Tucker, and BTD have traditionally relied on maximum-likelihood estimation, Bayesian inference has been use to form probabilistic CPD and Tucker. We propose, an efficient variational Bayesian probabilistic BTD, which uses the von-Mises Fisher matrix distribution to impose orthogonality in the multi-linear Tucker parts forming the BTD. On synthetic and two real datasets, we highlight the Bayesian inference procedure and demonstrate using the proposed pBTD on noisy data and for model order quantification. We find that the probabilistic BTD can quantify su
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#25193;&#25955;&#29983;&#25104;&#27969;&#37319;&#26679;&#22120;&#65288;DGFS&#65289;&#30340;&#37319;&#26679;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#23398;&#20064;&#36807;&#31243;&#20998;&#35299;&#20026;&#30701;&#30340;&#37096;&#20998;&#36712;&#36857;&#27573;&#65292;&#23454;&#29616;&#20174;&#38590;&#20197;&#22788;&#29702;&#30340;&#39640;&#32500;&#23494;&#24230;&#20989;&#25968;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#23427;&#36890;&#36807;&#21033;&#29992;&#20013;&#38388;&#30340;&#23398;&#20064;&#20449;&#21495;&#21644;&#38750;&#31574;&#30053;&#25506;&#32034;&#33021;&#21147;&#26469;&#25913;&#21892;&#23398;&#20064;&#20449;&#21495;&#30340;&#20998;&#37197;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.02679</link><description>&lt;p&gt;
&#25193;&#25955;&#29983;&#25104;&#27969;&#37319;&#26679;&#22120;&#65306;&#36890;&#36807;&#37096;&#20998;&#36712;&#36857;&#20248;&#21270;&#25913;&#21892;&#23398;&#20064;&#20449;&#21495;
&lt;/p&gt;
&lt;p&gt;
Diffusion Generative Flow Samplers: Improving learning signals through partial trajectory optimization. (arXiv:2310.02679v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02679
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#25193;&#25955;&#29983;&#25104;&#27969;&#37319;&#26679;&#22120;&#65288;DGFS&#65289;&#30340;&#37319;&#26679;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#23398;&#20064;&#36807;&#31243;&#20998;&#35299;&#20026;&#30701;&#30340;&#37096;&#20998;&#36712;&#36857;&#27573;&#65292;&#23454;&#29616;&#20174;&#38590;&#20197;&#22788;&#29702;&#30340;&#39640;&#32500;&#23494;&#24230;&#20989;&#25968;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#23427;&#36890;&#36807;&#21033;&#29992;&#20013;&#38388;&#30340;&#23398;&#20064;&#20449;&#21495;&#21644;&#38750;&#31574;&#30053;&#25506;&#32034;&#33021;&#21147;&#26469;&#25913;&#21892;&#23398;&#20064;&#20449;&#21495;&#30340;&#20998;&#37197;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#20174;&#38590;&#20197;&#22788;&#29702;&#30340;&#39640;&#32500;&#23494;&#24230;&#20989;&#25968;&#20013;&#36827;&#34892;&#37319;&#26679;&#30340;&#38382;&#39064;&#65292;&#36825;&#26159;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#20013;&#32463;&#24120;&#20986;&#29616;&#30340;&#22522;&#26412;&#20219;&#21153;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;&#26368;&#36817;&#30340;&#22522;&#20110;&#37319;&#26679;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#25511;&#21046;&#30340;&#38543;&#26426;&#36807;&#31243;&#26469;&#27169;&#25311;&#36825;&#20123;&#30446;&#26631;&#23494;&#24230;&#30340;&#36817;&#20284;&#26679;&#26412;&#12290;&#36825;&#20123;&#26041;&#27861;&#30340;&#20027;&#35201;&#32570;&#28857;&#26159;&#35757;&#32451;&#30446;&#26631;&#38656;&#35201;&#35745;&#31639;&#23436;&#25972;&#30340;&#36712;&#36857;&#65292;&#23548;&#33268;&#30001;&#20110;&#20351;&#29992;&#23436;&#25972;&#36712;&#36857;&#21644;&#21482;&#22312;&#32456;&#31471;&#26102;&#38388;&#23384;&#22312;&#30340;&#23398;&#20064;&#20449;&#21495;&#30340;&#20351;&#29992;&#32780;&#20135;&#29983;&#32531;&#24930;&#30340;&#20449;&#29992;&#20998;&#37197;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#25193;&#25955;&#29983;&#25104;&#27969;&#37319;&#26679;&#22120;&#65288;DGFS&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;&#37319;&#26679;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#23558;&#23398;&#20064;&#36807;&#31243;&#21487;&#34892;&#22320;&#20998;&#35299;&#20026;&#30701;&#30340;&#37096;&#20998;&#36712;&#36857;&#27573;&#65292;&#36890;&#36807;&#21442;&#25968;&#21270;&#19968;&#20010;&#39069;&#22806;&#30340;&#8220;&#27969;&#20989;&#25968;&#8221;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20511;&#37492;&#20102;&#29983;&#25104;&#27969;&#32593;&#32476;&#65288;GFlowNets&#65289;&#30340;&#29702;&#35770;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#21033;&#29992;&#20013;&#38388;&#30340;&#23398;&#20064;&#20449;&#21495;&#65292;&#24182;&#20174;&#38750;&#31574;&#30053;&#25506;&#32034;&#33021;&#21147;&#20013;&#21463;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
We tackle the problem of sampling from intractable high-dimensional density functions, a fundamental task that often appears in machine learning and statistics. We extend recent sampling-based approaches that leverage controlled stochastic processes to model approximate samples from these target densities. The main drawback of these approaches is that the training objective requires full trajectories to compute, resulting in sluggish credit assignment issues due to use of entire trajectories and a learning signal present only at the terminal time. In this work, we present Diffusion Generative Flow Samplers (DGFS), a sampling-based framework where the learning process can be tractably broken down into short partial trajectory segments, via parameterizing an additional "flow function". Our method takes inspiration from the theory developed for generative flow networks (GFlowNets), allowing us to make use of intermediate learning signals and benefit from off-policy exploration capabilitie
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#30005;&#32593;&#25299;&#25169;&#20248;&#21270;&#30340;&#20998;&#23618;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65288;MARL&#65289;&#26694;&#26550;&#65292;&#26377;&#25928;&#22788;&#29702;&#38543;&#30528;&#32593;&#32476;&#22686;&#38271;&#32780;&#25193;&#22823;&#30340;&#22823;&#22411;&#34892;&#21160;&#31354;&#38388;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26694;&#26550;&#22312;&#24615;&#33021;&#19978;&#19982;&#21333;&#19968;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#30456;&#24403;&#65292;&#24182;&#27604;&#36739;&#20102;&#19981;&#21516;&#30340;RL&#31639;&#27861;&#21644;&#19981;&#21516;&#30340;&#39640;&#38454;&#26234;&#33021;&#20307;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2310.02605</link><description>&lt;p&gt;
&#29992;&#20110;&#30005;&#32593;&#25299;&#25169;&#20248;&#21270;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Multi-Agent Reinforcement Learning for Power Grid Topology Optimization. (arXiv:2310.02605v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02605
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#30005;&#32593;&#25299;&#25169;&#20248;&#21270;&#30340;&#20998;&#23618;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65288;MARL&#65289;&#26694;&#26550;&#65292;&#26377;&#25928;&#22788;&#29702;&#38543;&#30528;&#32593;&#32476;&#22686;&#38271;&#32780;&#25193;&#22823;&#30340;&#22823;&#22411;&#34892;&#21160;&#31354;&#38388;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26694;&#26550;&#22312;&#24615;&#33021;&#19978;&#19982;&#21333;&#19968;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#30456;&#24403;&#65292;&#24182;&#27604;&#36739;&#20102;&#19981;&#21516;&#30340;RL&#31639;&#27861;&#21644;&#19981;&#21516;&#30340;&#39640;&#38454;&#26234;&#33021;&#20307;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#38754;&#20020;&#30528;&#33021;&#28304;&#38656;&#27714;&#22686;&#21152;&#21644;&#39118;&#33021;&#12289;&#22826;&#38451;&#33021;&#31561;&#19981;&#21487;&#39044;&#27979;&#21487;&#20877;&#29983;&#33021;&#28304;&#30340;&#25361;&#25112;&#65292;&#25805;&#20316;&#30005;&#32593;&#25104;&#20026;&#19968;&#20010;&#38382;&#39064;&#12290;&#24378;&#21270;&#23398;&#20064;&#22312;&#31649;&#29702;&#36825;&#20123;&#32593;&#32476;&#20013;&#26174;&#31034;&#20986;&#28508;&#21147;&#65292;&#36890;&#36807;&#24635;&#32447;&#21644;&#32447;&#36335;&#20999;&#25442;&#31561;&#25299;&#25169;&#25805;&#20316;&#65292;&#20294;&#23545;&#20110;&#38543;&#30528;&#32593;&#32476;&#22686;&#38271;&#32780;&#25193;&#22823;&#30340;&#22823;&#22411;&#34892;&#21160;&#31354;&#38388;&#30340;&#39640;&#25928;&#22788;&#29702;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#36825;&#31181;&#25193;&#23637;&#34892;&#21160;&#31354;&#38388;&#30340;&#20998;&#23618;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65288;MARL&#65289;&#26694;&#26550;&#65292;&#21033;&#29992;&#30005;&#32593;&#22266;&#26377;&#30340;&#20998;&#23618;&#29305;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;MARL&#26694;&#26550;&#19982;&#21333;&#19968;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#24615;&#33021;&#19978;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;&#25105;&#20204;&#36824;&#27604;&#36739;&#20102;&#19981;&#21516;&#30340;RL&#31639;&#27861;&#21644;&#19981;&#21516;&#30340;&#39640;&#38454;&#26234;&#33021;&#20307;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent challenges in operating power networks arise from increasing energy demands and unpredictable renewable sources like wind and solar. While reinforcement learning (RL) shows promise in managing these networks, through topological actions like bus and line switching, efficiently handling large action spaces as networks grow is crucial. This paper presents a hierarchical multi-agent reinforcement learning (MARL) framework tailored for these expansive action spaces, leveraging the power grid's inherent hierarchical nature. Experimental results indicate the MARL framework's competitive performance with single-agent RL methods. We also compare different RL algorithms for lower-level agents alongside different policies for higher-order agents.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#38750;&#35268;&#21017;&#31354;&#38388;&#25968;&#25454;&#30340;&#21442;&#25968;&#20272;&#35745;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#31070;&#32463;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#30340;&#24212;&#29992;&#33539;&#22260;&#65292;&#24182;&#24102;&#26469;&#20102;&#26174;&#33879;&#30340;&#35745;&#31639;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2310.02600</link><description>&lt;p&gt;
&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#35268;&#21017;&#31354;&#38388;&#25968;&#25454;&#30340;&#31070;&#32463;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
Neural Bayes Estimators for Irregular Spatial Data using Graph Neural Networks. (arXiv:2310.02600v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02600
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#38750;&#35268;&#21017;&#31354;&#38388;&#25968;&#25454;&#30340;&#21442;&#25968;&#20272;&#35745;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#31070;&#32463;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#30340;&#24212;&#29992;&#33539;&#22260;&#65292;&#24182;&#24102;&#26469;&#20102;&#26174;&#33879;&#30340;&#35745;&#31639;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#26159;&#19968;&#31181;&#20197;&#24555;&#36895;&#21644;&#20813;&#20284;&#28982;&#26041;&#24335;&#36924;&#36817;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#23427;&#20204;&#22312;&#31354;&#38388;&#27169;&#22411;&#21644;&#25968;&#25454;&#20013;&#30340;&#20351;&#29992;&#38750;&#24120;&#21560;&#24341;&#20154;&#65292;&#22240;&#20026;&#20272;&#35745;&#32463;&#24120;&#26159;&#35745;&#31639;&#19978;&#30340;&#29942;&#39048;&#12290;&#28982;&#32780;&#65292;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#31354;&#38388;&#24212;&#29992;&#20013;&#30340;&#31070;&#32463;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#20165;&#38480;&#20110;&#22312;&#35268;&#21017;&#30340;&#32593;&#26684;&#19978;&#25910;&#38598;&#30340;&#25968;&#25454;&#12290;&#36825;&#20123;&#20272;&#35745;&#22120;&#30446;&#21069;&#36824;&#20381;&#36182;&#20110;&#39044;&#20808;&#35268;&#23450;&#30340;&#31354;&#38388;&#20301;&#32622;&#65292;&#36825;&#24847;&#21619;&#30528;&#31070;&#32463;&#32593;&#32476;&#38656;&#35201;&#37325;&#26032;&#35757;&#32451;&#20197;&#36866;&#24212;&#26032;&#30340;&#25968;&#25454;&#38598;&#65307;&#36825;&#20351;&#23427;&#20204;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#21464;&#24471;&#19981;&#23454;&#29992;&#65292;&#24182;&#38459;&#30861;&#20102;&#23427;&#20204;&#30340;&#24191;&#27867;&#24212;&#29992;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#35299;&#20915;&#20174;&#20219;&#24847;&#31354;&#38388;&#20301;&#32622;&#25910;&#38598;&#30340;&#25968;&#25454;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#30340;&#37325;&#35201;&#38382;&#39064;&#12290;&#38500;&#20102;&#23558;&#31070;&#32463;&#36125;&#21494;&#26031;&#20272;&#35745;&#25193;&#23637;&#21040;&#38750;&#35268;&#21017;&#31354;&#38388;&#25968;&#25454;&#20043;&#22806;&#65292;&#25105;&#20204;&#30340;&#26550;&#26500;&#36824;&#24102;&#26469;&#20102;&#26174;&#30528;&#30340;&#35745;&#31639;&#20248;&#21183;&#65292;&#22240;&#20026;&#35813;&#20272;&#35745;&#22120;&#21487;&#20197;&#29992;&#20110;&#20219;&#20309;&#25490;&#21015;&#25110;&#25968;&#37327;&#30340;&#20301;&#32622;&#21644;&#29420;&#31435;&#30340;&#37325;&#22797;&#23454;&#39564;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural Bayes estimators are neural networks that approximate Bayes estimators in a fast and likelihood-free manner. They are appealing to use with spatial models and data, where estimation is often a computational bottleneck. However, neural Bayes estimators in spatial applications have, to date, been restricted to data collected over a regular grid. These estimators are also currently dependent on a prescribed set of spatial locations, which means that the neural network needs to be re-trained for new data sets; this renders them impractical in many applications and impedes their widespread adoption. In this work, we employ graph neural networks to tackle the important problem of parameter estimation from data collected over arbitrary spatial locations. In addition to extending neural Bayes estimation to irregular spatial data, our architecture leads to substantial computational benefits, since the estimator can be used with any arrangement or number of locations and independent repli
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#40065;&#26834;&#31574;&#30053;&#35780;&#20272;&#30340;&#22312;&#32447;&#20272;&#35745;&#21644;&#25512;&#26029;&#26041;&#27861;&#65292;&#22312;&#35299;&#20915;&#24322;&#24120;&#20540;&#27745;&#26579;&#21644;&#37325;&#23614;&#22870;&#21169;&#30340;&#38382;&#39064;&#26041;&#38754;&#24341;&#20837;&#20102;&#40065;&#26834;&#32479;&#35745;&#23398;&#30340;&#27010;&#24565;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#22312;&#32447;&#30340;&#32479;&#35745;&#25512;&#26029;&#36807;&#31243;&#65292;&#24182;&#24314;&#31435;&#20102;&#20272;&#35745;&#37327;&#30340;&#26497;&#38480;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2310.02581</link><description>&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#40065;&#26834;&#31574;&#30053;&#35780;&#20272;&#30340;&#22312;&#32447;&#20272;&#35745;&#21644;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Online Estimation and Inference for Robust Policy Evaluation in Reinforcement Learning. (arXiv:2310.02581v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02581
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#40065;&#26834;&#31574;&#30053;&#35780;&#20272;&#30340;&#22312;&#32447;&#20272;&#35745;&#21644;&#25512;&#26029;&#26041;&#27861;&#65292;&#22312;&#35299;&#20915;&#24322;&#24120;&#20540;&#27745;&#26579;&#21644;&#37325;&#23614;&#22870;&#21169;&#30340;&#38382;&#39064;&#26041;&#38754;&#24341;&#20837;&#20102;&#40065;&#26834;&#32479;&#35745;&#23398;&#30340;&#27010;&#24565;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#22312;&#32447;&#30340;&#32479;&#35745;&#25512;&#26029;&#36807;&#31243;&#65292;&#24182;&#24314;&#31435;&#20102;&#20272;&#35745;&#37327;&#30340;&#26497;&#38480;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#24378;&#21270;&#23398;&#20064;&#22312;&#29616;&#20195;&#32479;&#35745;&#23398;&#20013;&#22791;&#21463;&#20851;&#27880;&#65292;&#31574;&#30053;&#35780;&#20272;&#26159;&#20854;&#20013;&#19968;&#20010;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#12290;&#19982;&#20256;&#32479;&#26426;&#22120;&#23398;&#20064;&#25991;&#29486;&#19978;&#23545;&#35813;&#20027;&#39064;&#30340;&#30740;&#31350;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#24378;&#35843;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#35745;&#31639;&#30340;&#21442;&#25968;&#20272;&#35745;&#30340;&#32479;&#35745;&#25512;&#26029;&#12290;&#23613;&#31649;&#22823;&#22810;&#25968;&#29616;&#26377;&#20998;&#26512;&#20551;&#35774;&#38543;&#26426;&#22870;&#21169;&#36981;&#24490;&#26631;&#20934;&#20998;&#24067;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#36866;&#29992;&#24615;&#65292;&#20294;&#25105;&#20204;&#22312;&#32479;&#19968;&#26694;&#26550;&#20013;&#21516;&#26102;&#35299;&#20915;&#20102;&#24322;&#24120;&#20540;&#27745;&#26579;&#21644;&#37325;&#23614;&#22870;&#21169;&#30340;&#38382;&#39064;&#65292;&#20174;&#32780;&#25317;&#25265;&#20102;&#40065;&#26834;&#32479;&#35745;&#23398;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#27010;&#24565;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22312;&#32447;&#40065;&#26834;&#31574;&#30053;&#35780;&#20272;&#36807;&#31243;&#65292;&#24182;&#26681;&#25454;&#20854;Bahadur&#34920;&#31034;&#24314;&#31435;&#20102;&#25105;&#20204;&#20272;&#35745;&#37327;&#30340;&#26497;&#38480;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#23436;&#20840;&#22312;&#32447;&#30340;&#36807;&#31243;&#65292;&#20197;&#39640;&#25928;&#22320;&#36827;&#34892;&#22522;&#20110;&#28176;&#36817;&#20998;&#24067;&#30340;&#32479;&#35745;&#25512;&#26029;&#12290;&#36825;&#31687;&#35770;&#25991;&#22635;&#34917;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#40065;&#26834;&#32479;&#35745;&#23398;&#21644;&#32479;&#35745;&#25512;&#26029;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, reinforcement learning has gained prominence in modern statistics, with policy evaluation being a key component. Unlike traditional machine learning literature on this topic, our work places emphasis on statistical inference for the parameter estimates computed using reinforcement learning algorithms. While most existing analyses assume random rewards to follow standard distributions, limiting their applicability, we embrace the concept of robust statistics in reinforcement learning by simultaneously addressing issues of outlier contamination and heavy-tailed rewards within a unified framework. In this paper, we develop an online robust policy evaluation procedure, and establish the limiting distribution of our estimator, based on its Bahadur representation. Furthermore, we develop a fully-online procedure to efficiently conduct statistical inference based on the asymptotic distribution. This paper bridges the gap between robust statistics and statistical inference in reinfor
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;ReLU&#32593;&#32476;&#22312;XOR&#38598;&#32676;&#25968;&#25454;&#19978;&#20250;&#20135;&#29983;&#33391;&#24615;&#36807;&#25311;&#21512;&#21644;&#29702;&#35299;&#29616;&#35937;&#65292;&#21363;&#22312;&#35757;&#32451;&#38454;&#27573;&#23454;&#29616;&#22122;&#22768;&#26631;&#31614;&#30340;&#23436;&#32654;&#25311;&#21512;&#20294;&#22312;&#27979;&#35797;&#38454;&#27573;&#34920;&#29616;&#38543;&#26426;&#65292;&#22312;&#21518;&#32493;&#38454;&#27573;&#21487;&#20197;&#23454;&#29616;&#36817;&#20046;&#26368;&#20248;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.02541</link><description>&lt;p&gt;
&#38024;&#23545;XOR&#38598;&#32676;&#25968;&#25454;&#20013;&#30340;ReLU&#32593;&#32476;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#21644;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Benign Overfitting and Grokking in ReLU Networks for XOR Cluster Data. (arXiv:2310.02541v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02541
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;ReLU&#32593;&#32476;&#22312;XOR&#38598;&#32676;&#25968;&#25454;&#19978;&#20250;&#20135;&#29983;&#33391;&#24615;&#36807;&#25311;&#21512;&#21644;&#29702;&#35299;&#29616;&#35937;&#65292;&#21363;&#22312;&#35757;&#32451;&#38454;&#27573;&#23454;&#29616;&#22122;&#22768;&#26631;&#31614;&#30340;&#23436;&#32654;&#25311;&#21512;&#20294;&#22312;&#27979;&#35797;&#38454;&#27573;&#34920;&#29616;&#38543;&#26426;&#65292;&#22312;&#21518;&#32493;&#38454;&#27573;&#21487;&#20197;&#23454;&#29616;&#36817;&#20046;&#26368;&#20248;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;(GD)&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#23637;&#29616;&#20102;&#35768;&#22810;&#20196;&#20154;&#24778;&#35766;&#30340;&#27867;&#21270;&#34892;&#20026;&#12290;&#39318;&#20808;&#65292;&#23427;&#20204;&#21487;&#20197;&#23545;&#22122;&#22768;&#35757;&#32451;&#25968;&#25454;&#23454;&#29616;&#23436;&#32654;&#25311;&#21512;&#65292;&#24182;&#19988;&#20173;&#28982;&#33021;&#22815;&#36817;&#20046;&#26368;&#20248;&#22320;&#36827;&#34892;&#27867;&#21270;&#65292;&#34920;&#26126;&#36807;&#25311;&#21512;&#26377;&#26102;&#21487;&#33021;&#26159;&#33391;&#24615;&#30340;&#12290;&#20854;&#27425;&#65292;&#22312;&#35757;&#32451;&#30340;&#26089;&#26399;&#38454;&#27573;&#65292;&#23427;&#20204;&#21487;&#33021;&#20250;&#32463;&#21382;&#19968;&#27573;&#32463;&#20856;&#19988;&#26377;&#23475;&#30340;&#36807;&#25311;&#21512;&#26399;&#65292;&#21363;&#22312;&#35757;&#32451;&#25968;&#25454;&#19978;&#23454;&#29616;&#23436;&#32654;&#25311;&#21512;&#20294;&#22312;&#27979;&#35797;&#25968;&#25454;&#19978;&#34920;&#29616;&#38543;&#26426;&#65292;&#38543;&#21518;&#36807;&#28193;&#21040;&#36817;&#20046;&#26368;&#20248;&#30340;&#27867;&#21270;&#34892;&#20026;&#65288;&#21363;&#8220;&#29702;&#35299;&#8221;&#65289;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20004;&#20010;&#29616;&#35937;&#22312;&#36890;&#36807;GD&#23545;XOR&#38598;&#32676;&#25968;&#25454;&#19978;&#30340;&#20004;&#23618;ReLU&#32593;&#32476;&#36827;&#34892;&#35757;&#32451;&#26102;&#30830;&#23454;&#20250;&#20986;&#29616;&#65292;&#20854;&#20013;&#35757;&#32451;&#26631;&#31614;&#30340;&#19968;&#37096;&#20998;&#20250;&#34987;&#32763;&#36716;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;GD&#30340;&#31532;&#19968;&#27493;&#20043;&#21518;&#65292;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#23454;&#29616;100%&#30340;&#35757;&#32451;&#20934;&#30830;&#24230;&#65292;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#23436;&#32654;&#25311;&#21512;&#22122;&#22768;&#26631;&#31614;&#65292;&#20294;&#22312;&#27979;&#35797;&#19978;&#34920;&#29616;&#25509;&#36817;&#38543;&#26426;&#12290;&#22312;&#38543;&#21518;&#30340;&#35757;&#32451;&#27493;&#39588;&#20013;&#65292;&#32593;&#32476;&#33021;&#22815;&#23454;&#29616;&#36817;&#20046;&#26368;&#20248;&#30340;&#27979;&#35797;&#20934;&#30830;&#24230;&#65292;&#21516;&#26102;&#20173;&#28982;&#25311;&#21512;&#38543;&#26426;&#26631;&#31614;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural networks trained by gradient descent (GD) have exhibited a number of surprising generalization behaviors. First, they can achieve a perfect fit to noisy training data and still generalize near-optimally, showing that overfitting can sometimes be benign. Second, they can undergo a period of classical, harmful overfitting -- achieving a perfect fit to training data with near-random performance on test data -- before transitioning ("grokking") to near-optimal generalization later in training. In this work, we show that both of these phenomena provably occur in two-layer ReLU networks trained by GD on XOR cluster data where a constant fraction of the training labels are flipped. In this setting, we show that after the first step of GD, the network achieves 100% training accuracy, perfectly fitting the noisy labels in the training data, but achieves near-random test accuracy. At a later training step, the network achieves near-optimal test accuracy while still fitting the random labe
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#37327;&#21270;&#21644;&#20943;&#36731;&#20102;&#26631;&#31614;&#38169;&#35823;&#23545;&#27169;&#22411;&#24046;&#24322;&#24230;&#37327;&#30340;&#24433;&#21709;&#65292;&#24182;&#19988;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#35757;&#32451;&#36755;&#20837;&#26631;&#31614;&#23545;&#27169;&#22411;&#24046;&#24322;&#24230;&#37327;&#24433;&#21709;&#30340;&#26041;&#27861;&#65292;&#26377;&#25928;&#22320;&#25913;&#36827;&#20102;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.02533</link><description>&lt;p&gt;
&#37327;&#21270;&#21644;&#20943;&#36731;&#26631;&#31614;&#38169;&#35823;&#23545;&#27169;&#22411;&#24046;&#24322;&#24230;&#37327;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Quantifying and mitigating the impact of label errors on model disparity metrics. (arXiv:2310.02533v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02533
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#37327;&#21270;&#21644;&#20943;&#36731;&#20102;&#26631;&#31614;&#38169;&#35823;&#23545;&#27169;&#22411;&#24046;&#24322;&#24230;&#37327;&#30340;&#24433;&#21709;&#65292;&#24182;&#19988;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#35757;&#32451;&#36755;&#20837;&#26631;&#31614;&#23545;&#27169;&#22411;&#24046;&#24322;&#24230;&#37327;&#24433;&#21709;&#30340;&#26041;&#27861;&#65292;&#26377;&#25928;&#22320;&#25913;&#36827;&#20102;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20154;&#24037;&#27880;&#37322;&#33719;&#21462;&#30340;&#26631;&#31614;&#38169;&#35823;&#20250;&#23545;&#27169;&#22411;&#30340;&#24615;&#33021;&#20135;&#29983;&#36127;&#38754;&#24433;&#21709;&#12290;&#29616;&#26377;&#26041;&#27861;&#25552;&#20986;&#20102;&#20943;&#36731;&#26631;&#31614;&#38169;&#35823;&#23545;&#27169;&#22411;&#19979;&#28216;&#20934;&#30830;&#24615;&#24433;&#21709;&#30340;&#26041;&#27861;&#65292;&#20294;&#23545;&#27169;&#22411;&#30340;&#24046;&#24322;&#24230;&#37327;&#30340;&#24433;&#21709;&#20173;&#30693;&#20043;&#29978;&#23569;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#26631;&#31614;&#38169;&#35823;&#23545;&#27169;&#22411;&#24046;&#24322;&#24230;&#37327;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#20197;&#23454;&#35777;&#26041;&#24335;&#34920;&#24449;&#20102;&#19981;&#21516;&#27700;&#24179;&#30340;&#26631;&#31614;&#38169;&#35823;&#23545;&#36825;&#20123;&#24046;&#24322;&#24230;&#37327;&#30340;&#24433;&#21709;&#65292;&#21253;&#25324;&#35757;&#32451;&#25968;&#25454;&#21644;&#27979;&#35797;&#25968;&#25454;&#20013;&#30340;&#26631;&#31614;&#38169;&#35823;&#12290;&#25105;&#20204;&#21457;&#29616;&#32676;&#20307;&#26657;&#20934;&#21644;&#20854;&#20182;&#24230;&#37327;&#23545;&#35757;&#32451;&#26102;&#21644;&#27979;&#35797;&#26102;&#30340;&#26631;&#31614;&#38169;&#35823;&#38750;&#24120;&#25935;&#24863;&#65292;&#23588;&#20854;&#23545;&#20110;&#23569;&#25968;&#32676;&#20307;&#12290;&#36825;&#31181;&#24046;&#24322;&#25928;&#24212;&#29978;&#33267;&#36866;&#29992;&#20110;&#20351;&#29992;&#22122;&#22768;&#24863;&#30693;&#31639;&#27861;&#35757;&#32451;&#30340;&#27169;&#22411;&#12290;&#20026;&#20102;&#20943;&#36731;&#35757;&#32451;&#26102;&#30340;&#26631;&#31614;&#38169;&#35823;&#24433;&#21709;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#35757;&#32451;&#36755;&#20837;&#26631;&#31614;&#23545;&#27169;&#22411;&#24046;&#24322;&#24230;&#37327;&#24433;&#21709;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#20197;&#23454;&#35777;&#26041;&#24335;&#35780;&#20272;&#20102;&#35813;&#26041;&#27861;&#65292;&#24182;&#19982;&#26367;&#20195;&#26041;&#27861;&#30456;&#27604;&#21457;&#29616;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Errors in labels obtained via human annotation adversely affect a model's performance. Existing approaches propose ways to mitigate the effect of label error on a model's downstream accuracy, yet little is known about its impact on a model's disparity metrics. Here we study the effect of label error on a model's disparity metrics. We empirically characterize how varying levels of label error, in both training and test data, affect these disparity metrics. We find that group calibration and other metrics are sensitive to train-time and test-time label error -- particularly for minority groups. This disparate effect persists even for models trained with noise-aware algorithms. To mitigate the impact of training-time label error, we present an approach to estimate the influence of a training input's label on a model's group disparity metric. We empirically assess the proposed approach on a variety of datasets and find significant improvement, compared to alternative approaches, in identif
&lt;/p&gt;</description></item><item><title>Delta-AI&#31639;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31232;&#30095;&#22270;&#27169;&#22411;&#30340;&#25674;&#36824;&#25512;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#23616;&#37096;&#20449;&#29992;&#20998;&#37197;&#21644;&#31163;&#31574;&#30053;&#35757;&#32451;&#21152;&#24555;&#20102;&#35757;&#32451;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.02423</link><description>&lt;p&gt;
Delta-AI: &#31232;&#30095;&#22270;&#27169;&#22411;&#30340;&#25674;&#36824;&#25512;&#29702;&#20013;&#30340;&#23616;&#37096;&#30446;&#26631;
&lt;/p&gt;
&lt;p&gt;
Delta-AI: Local objectives for amortized inference in sparse graphical models. (arXiv:2310.02423v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02423
&lt;/p&gt;
&lt;p&gt;
Delta-AI&#31639;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31232;&#30095;&#22270;&#27169;&#22411;&#30340;&#25674;&#36824;&#25512;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#23616;&#37096;&#20449;&#29992;&#20998;&#37197;&#21644;&#31163;&#31574;&#30053;&#35757;&#32451;&#21152;&#24555;&#20102;&#35757;&#32451;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#31232;&#30095;&#27010;&#29575;&#22270;&#27169;&#22411;&#65288;PGMs&#65289;&#30340;&#25674;&#36824;&#25512;&#29702;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;Delta-AI&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#36825;&#26679;&#30340;&#35266;&#23519;&#65306;&#24403;PGM&#20013;&#30340;&#21464;&#37327;&#37319;&#26679;&#34987;&#35270;&#20026;&#19968;&#20010;&#20195;&#29702;&#20154;&#37319;&#21462;&#30340;&#21160;&#20316;&#24207;&#21015;&#26102;&#65292;PGM&#30340;&#31232;&#30095;&#24615;&#20351;&#24471;&#20195;&#29702;&#20154;&#30340;&#31574;&#30053;&#23398;&#20064;&#30446;&#26631;&#33021;&#22815;&#36827;&#34892;&#23616;&#37096;&#20449;&#29992;&#20998;&#37197;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#20010;&#23616;&#37096;&#32422;&#26463;&#65292;&#21487;&#20197;&#36716;&#21270;&#20026;&#31867;&#20284;&#29983;&#25104;&#27969;&#32593;&#32476;&#65288;GFlowNets&#65289;&#20013;&#30340;&#23616;&#37096;&#25439;&#22833;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#31163;&#31574;&#30053;&#35757;&#32451;&#65292;&#20294;&#36991;&#20813;&#20102;&#27599;&#20010;&#21442;&#25968;&#26356;&#26032;&#38656;&#35201;&#23454;&#20363;&#21270;&#25152;&#26377;&#38543;&#26426;&#21464;&#37327;&#30340;&#38656;&#27714;&#65292;&#20174;&#32780;&#22823;&#22823;&#21152;&#24555;&#20102;&#35757;&#32451;&#36895;&#24230;&#12290;Delta-AI&#30446;&#26631;&#19982;&#19968;&#20010;&#21487;&#35745;&#31639;&#30340;&#23398;&#20064;&#37319;&#26679;&#22120;&#20013;&#30340;&#21464;&#37327;&#32473;&#23450;&#20854;&#39532;&#23572;&#21487;&#22827;&#27631;&#23376;&#30340;&#26465;&#20214;&#20998;&#24067;&#30456;&#21305;&#37197;&#65292;&#35813;&#37319;&#26679;&#22120;&#30340;&#32467;&#26500;&#31867;&#20284;&#20110;&#36125;&#21494;&#26031;&#32593;&#32476;&#65292;&#22312;&#30446;&#26631;PGM&#19979;&#20855;&#26377;&#30456;&#21516;&#30340;&#26465;&#20214;&#20998;&#24067;&#12290;&#22240;&#27492;&#65292;&#35757;&#32451;&#21518;&#30340;&#37319;&#26679;&#22120;&#21487;&#20197;&#24674;&#22797;&#24863;&#20852;&#36259;&#21464;&#37327;&#30340;&#36793;&#38469;&#20998;&#24067;&#21644;&#26465;&#20214;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new algorithm for amortized inference in sparse probabilistic graphical models (PGMs), which we call $\Delta$-amortized inference ($\Delta$-AI). Our approach is based on the observation that when the sampling of variables in a PGM is seen as a sequence of actions taken by an agent, sparsity of the PGM enables local credit assignment in the agent's policy learning objective. This yields a local constraint that can be turned into a local loss in the style of generative flow networks (GFlowNets) that enables off-policy training but avoids the need to instantiate all the random variables for each parameter update, thus speeding up training considerably. The $\Delta$-AI objective matches the conditional distribution of a variable given its Markov blanket in a tractable learned sampler, which has the structure of a Bayesian network, with the same conditional distribution under the target PGM. As such, the trained sampler recovers marginals and conditional distributions of intere
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24310;&#36831;MLMC&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#37325;&#22797;&#21033;&#29992;&#20043;&#21069;&#27493;&#39588;&#20013;&#35745;&#31639;&#36807;&#30340;&#26799;&#24230;&#20998;&#37327;&#65292;&#22823;&#22823;&#38477;&#20302;&#20102;MLMC&#30340;&#24182;&#34892;&#22797;&#26434;&#24615;&#65292;&#24182;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#20854;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#20855;&#26377;&#26356;&#22909;&#30340;&#24182;&#34892;&#22797;&#26434;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.02402</link><description>&lt;p&gt;
&#20851;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#22810;&#23618;&#33945;&#29305;&#21345;&#27931;&#30340;&#24182;&#34892;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Parallel Complexity of Multilevel Monte Carlo in Stocahstic Gradient Descent. (arXiv:2310.02402v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02402
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24310;&#36831;MLMC&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#37325;&#22797;&#21033;&#29992;&#20043;&#21069;&#27493;&#39588;&#20013;&#35745;&#31639;&#36807;&#30340;&#26799;&#24230;&#20998;&#37327;&#65292;&#22823;&#22823;&#38477;&#20302;&#20102;MLMC&#30340;&#24182;&#34892;&#22797;&#26434;&#24615;&#65292;&#24182;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#20854;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#20855;&#26377;&#26356;&#22909;&#30340;&#24182;&#34892;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29992;&#20110;&#39034;&#24207;&#27169;&#25311;&#65288;&#22914;&#31070;&#32463;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65289;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#20013;&#65292;&#22810;&#23618;&#33945;&#29305;&#21345;&#27931;&#65288;MLMC&#65289;&#26041;&#27861;&#24050;&#34987;&#35777;&#26126;&#22312;&#29702;&#35770;&#35745;&#31639;&#22797;&#26434;&#24615;&#26041;&#38754;&#20248;&#20110;&#26420;&#32032;&#30340;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#12290;&#28982;&#32780;&#22312;&#23454;&#36341;&#20013;&#65292;MLMC&#22312;&#29616;&#20195;GPU&#31561;&#22823;&#35268;&#27169;&#24182;&#34892;&#35745;&#31639;&#24179;&#21488;&#19978;&#30340;&#21487;&#25193;&#23637;&#24615;&#36739;&#24046;&#65292;&#22240;&#20026;&#20854;&#24182;&#34892;&#22797;&#26434;&#24615;&#19982;&#26420;&#32032;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#30456;&#24403;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24310;&#36831;MLMC&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#37325;&#22797;&#21033;&#29992;&#20043;&#21069;&#27493;&#39588;&#20013;&#35745;&#31639;&#36807;&#30340;&#26799;&#24230;&#20998;&#37327;&#65292;&#22823;&#22823;&#38477;&#20302;MLMC&#30340;&#24182;&#34892;&#22797;&#26434;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#33021;&#22815;&#35777;&#26126;&#38477;&#20302;&#24179;&#22343;&#24182;&#34892;&#22797;&#26434;&#24615;&#65292;&#20294;&#20195;&#20215;&#26159;&#31245;&#24046;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;&#22312;&#25105;&#20204;&#30340;&#25968;&#20540;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#28145;&#24230;&#23545;&#20914;&#30340;&#31034;&#20363;&#26469;&#35777;&#26126;&#19982;&#26631;&#20934;MLMC&#22312;SGD&#20013;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#24182;&#34892;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the stochastic gradient descent (SGD) for sequential simulations such as the neural stochastic differential equations, the Multilevel Monte Carlo (MLMC) method is known to offer better theoretical computational complexity compared to the naive Monte Carlo approach. However, in practice, MLMC scales poorly on massively parallel computing platforms such as modern GPUs, because of its large parallel complexity which is equivalent to that of the naive Monte Carlo method. To cope with this issue, we propose the delayed MLMC gradient estimator that drastically reduces the parallel complexity of MLMC by recycling previously computed gradient components from earlier steps of SGD. The proposed estimator provably reduces the average parallel complexity per iteration at the cost of a slightly worse per-iteration convergence rate. In our numerical experiments, we use an example of deep hedging to demonstrate the superior parallel complexity of our method compared to the standard MLMC in SGD.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#23398;&#20248;&#21270;&#22120;&#65288;STOP&#65289;&#65292;&#36890;&#36807;&#36882;&#24402;&#33258;&#25105;&#25913;&#36827;&#30340;&#20195;&#30721;&#29983;&#25104;&#65292;&#20351;&#29992;&#34701;&#21512;&#20102;&#35821;&#35328;&#27169;&#22411;&#30340;&#33050;&#25163;&#26550;&#31243;&#24207;&#26469;&#25913;&#36827;&#33258;&#36523;&#65292;&#20174;&#32780;&#29983;&#25104;&#24615;&#33021;&#26356;&#22909;&#30340;&#31243;&#24207;&#12290;</title><link>http://arxiv.org/abs/2310.02304</link><description>&lt;p&gt;
&#33258;&#23398;&#20248;&#21270;&#22120;&#65288;STOP&#65289;&#65306;&#36882;&#24402;&#33258;&#25105;&#25913;&#36827;&#30340;&#20195;&#30721;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Self-Taught Optimizer (STOP): Recursively Self-Improving Code Generation. (arXiv:2310.02304v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02304
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#23398;&#20248;&#21270;&#22120;&#65288;STOP&#65289;&#65292;&#36890;&#36807;&#36882;&#24402;&#33258;&#25105;&#25913;&#36827;&#30340;&#20195;&#30721;&#29983;&#25104;&#65292;&#20351;&#29992;&#34701;&#21512;&#20102;&#35821;&#35328;&#27169;&#22411;&#30340;&#33050;&#25163;&#26550;&#31243;&#24207;&#26469;&#25913;&#36827;&#33258;&#36523;&#65292;&#20174;&#32780;&#29983;&#25104;&#24615;&#33021;&#26356;&#22909;&#30340;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#24180;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#65288;&#20363;&#22914;&#24605;&#32500;&#26641;&#21644;&#31243;&#24207;&#36741;&#21161;&#35821;&#35328;&#27169;&#22411;&#65289;&#21462;&#24471;&#20102;&#19968;&#20123;&#37325;&#35201;&#36827;&#23637;&#65292;&#36890;&#36807;&#25552;&#20379;&#19968;&#20010;&#8220;&#33050;&#25163;&#26550;&#8221;&#31243;&#24207;&#26469;&#35299;&#20915;&#38382;&#39064;&#65292;&#35813;&#31243;&#24207;&#26500;&#24314;&#20102;&#22810;&#27425;&#35843;&#29992;&#35821;&#35328;&#27169;&#22411;&#20197;&#29983;&#25104;&#26356;&#22909;&#30340;&#36755;&#20986;&#12290;&#33050;&#25163;&#26550;&#31243;&#24207;&#36890;&#24120;&#20351;&#29992;Python&#31561;&#32534;&#31243;&#35821;&#35328;&#32534;&#20889;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#20010;&#34701;&#21512;&#20102;&#35821;&#35328;&#27169;&#22411;&#30340;&#33050;&#25163;&#26550;&#31243;&#24207;&#26469;&#25913;&#36827;&#33258;&#36523;&#12290;&#25105;&#20204;&#20174;&#19968;&#20010;&#31181;&#23376;&#8220;&#25913;&#36827;&#22120;&#8221;&#24320;&#22987;&#65292;&#36890;&#36807;&#22810;&#27425;&#26597;&#35810;&#35821;&#35328;&#27169;&#22411;&#24182;&#36820;&#22238;&#26368;&#20339;&#35299;&#20915;&#26041;&#26696;&#65292;&#26681;&#25454;&#32473;&#23450;&#30340;&#25928;&#29992;&#20989;&#25968;&#26469;&#25913;&#36827;&#36755;&#20837;&#31243;&#24207;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36816;&#34892;&#36825;&#20010;&#31181;&#23376;&#25913;&#36827;&#22120;&#26469;&#25913;&#36827;&#33258;&#36523;&#12290;&#22312;&#19968;&#31995;&#21015;&#32454;&#20998;&#20219;&#21153;&#20013;&#65292;&#24471;&#21040;&#30340;&#25913;&#36827;&#25913;&#36827;&#22120;&#29983;&#25104;&#30340;&#31243;&#24207;&#22312;&#24615;&#33021;&#19978;&#26126;&#26174;&#20248;&#20110;&#31181;&#23376;&#25913;&#36827;&#22120;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#23545;&#35821;&#35328;&#27169;&#22411;&#25552;&#20986;&#30340;&#21508;&#31181;&#33258;&#25105;&#25913;&#36827;&#31574;&#30053;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#21253;&#25324;&#27874;&#26463;&#25628;&#32034;&#12289;&#36951;&#20256;&#31639;&#27861;&#21644;&#27169;&#25311;&#36864;&#28779;&#12290;&#30001;&#20110;&#35821;&#35328;&#27169;&#22411;&#26412;&#36523;&#27809;&#26377;&#25913;&#21464;&#65292;&#36825;&#24182;&#19981;&#26159;&#19968;&#31181;&#22686;&#38271;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several recent advances in AI systems (e.g., Tree-of-Thoughts and Program-Aided Language Models) solve problems by providing a "scaffolding" program that structures multiple calls to language models to generate better outputs. A scaffolding program is written in a programming language such as Python. In this work, we use a language-model-infused scaffolding program to improve itself. We start with a seed "improver" that improves an input program according to a given utility function by querying a language model several times and returning the best solution. We then run this seed improver to improve itself. Across a small set of downstream tasks, the resulting improved improver generates programs with significantly better performance than its seed improver. Afterward, we analyze the variety of self-improvement strategies proposed by the language model, including beam search, genetic algorithms, and simulated annealing. Since the language models themselves are not altered, this is not fu
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#19968;&#33268;&#24615;&#36712;&#36857;&#27169;&#22411;&#65288;CTM&#65289;&#65292;&#23427;&#21487;&#20197;&#21152;&#36895;&#25193;&#25955;&#27169;&#22411;&#30340;&#37319;&#26679;&#65292;&#21516;&#26102;&#36890;&#36807;&#23545;&#25239;&#35757;&#32451;&#21644;&#21435;&#22122;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#30340;&#32452;&#21512;&#26469;&#25552;&#39640;&#24615;&#33021;&#65292;&#24182;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2310.02279</link><description>&lt;p&gt;
&#19968;&#33268;&#24615;&#36712;&#36857;&#27169;&#22411;&#65306;&#23398;&#20064;&#25193;&#25955;&#30340;&#27010;&#29575;&#27969;ODE&#36712;&#36857;
&lt;/p&gt;
&lt;p&gt;
Consistency Trajectory Models: Learning Probability Flow ODE Trajectory of Diffusion. (arXiv:2310.02279v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02279
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#19968;&#33268;&#24615;&#36712;&#36857;&#27169;&#22411;&#65288;CTM&#65289;&#65292;&#23427;&#21487;&#20197;&#21152;&#36895;&#25193;&#25955;&#27169;&#22411;&#30340;&#37319;&#26679;&#65292;&#21516;&#26102;&#36890;&#36807;&#23545;&#25239;&#35757;&#32451;&#21644;&#21435;&#22122;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#30340;&#32452;&#21512;&#26469;&#25552;&#39640;&#24615;&#33021;&#65292;&#24182;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#33268;&#24615;&#27169;&#22411;&#65288;CM&#65289;&#21152;&#36895;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#37319;&#26679;&#65292;&#20294;&#20197;&#29306;&#29298;&#26679;&#26412;&#36136;&#37327;&#20026;&#20195;&#20215;&#65292;&#32570;&#20047;&#19968;&#31181;&#33258;&#28982;&#30340;&#26041;&#27861;&#26469;&#26435;&#34913;&#36895;&#24230;&#21644;&#36136;&#37327;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#33268;&#24615;&#36712;&#36857;&#27169;&#22411;&#65288;CTM&#65289;&#65292;&#23427;&#26159;&#21253;&#25324;CM&#21644;&#22522;&#20110;&#24471;&#20998;&#27169;&#22411;&#22312;&#20869;&#30340;&#27867;&#21270;&#27169;&#22411;&#12290;CTM&#35757;&#32451;&#19968;&#20010;&#21333;&#19968;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20197;&#22312;&#21333;&#27425;&#21069;&#21521;&#20256;&#36882;&#20013;&#36755;&#20986;&#24471;&#20998;&#65288;&#21363;&#23545;&#25968;&#23494;&#24230;&#30340;&#26799;&#24230;&#65289;&#65292;&#24182;&#20801;&#35768;&#22312;&#25193;&#25955;&#36807;&#31243;&#20013;&#20219;&#24847;&#21021;&#22987;&#21644;&#26368;&#32456;&#26102;&#38388;&#20043;&#38388;&#36827;&#34892;&#19981;&#21463;&#38480;&#21046;&#30340;&#36941;&#21382;&#27010;&#29575;&#27969;&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#12290;CTM&#21033;&#29992;&#23545;&#25239;&#35757;&#32451;&#21644;&#21435;&#22122;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#30340;&#26377;&#25928;&#32452;&#21512;&#26469;&#25552;&#39640;&#24615;&#33021;&#65292;&#24182;&#22312;CIFAR-10&#65288;FID 1.73&#65289;&#21644;64X64&#20998;&#36776;&#29575;&#30340;ImageNet&#19978;&#23454;&#29616;&#26032;&#30340;&#26368;&#20808;&#36827;FID&#12290;CTM&#36824;&#23454;&#29616;&#20102;&#19968;&#31995;&#21015;&#26032;&#30340;&#37319;&#26679;&#26041;&#26696;&#65292;&#21253;&#25324;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#30340;ODE&#35299;&#20013;&#30340;&#38271;&#36339;&#36291;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consistency Models (CM) (Song et al., 2023) accelerate score-based diffusion model sampling at the cost of sample quality but lack a natural way to trade-off quality for speed. To address this limitation, we propose Consistency Trajectory Model (CTM), a generalization encompassing CM and score-based models as special cases. CTM trains a single neural network that can -- in a single forward pass -- output scores (i.e., gradients of log-density) and enables unrestricted traversal between any initial and final time along the Probability Flow Ordinary Differential Equation (ODE) in a diffusion process. CTM enables the efficient combination of adversarial training and denoising score matching loss to enhance performance and achieves new state-of-the-art FIDs for single-step diffusion model sampling on CIFAR-10 (FID 1.73) and ImageNet at 64X64 resolution (FID 2.06). CTM also enables a new family of sampling schemes, both deterministic and stochastic, involving long jumps along the ODE soluti
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#31283;&#23450;&#20272;&#35745;&#29983;&#23384;&#22240;&#26524;&#25928;&#24212;&#30340;&#38382;&#39064;&#65292;&#30740;&#31350;&#34920;&#26126;&#20256;&#32479;&#30340;&#20272;&#35745;&#26041;&#27861;&#23384;&#22312;&#20559;&#24046;&#65292;&#32780;&#36817;&#26399;&#38750;&#20542;&#26012;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#23613;&#31649;&#29702;&#35770;&#19978;&#26377;&#21560;&#24341;&#21147;&#65292;&#20294;&#22312;&#29983;&#23384;&#38382;&#39064;&#20013;&#23384;&#22312;&#19981;&#31283;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.02278</link><description>&lt;p&gt;
&#31283;&#23450;&#20272;&#35745;&#29983;&#23384;&#22240;&#26524;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
Stable Estimation of Survival Causal Effects. (arXiv:2310.02278v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02278
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#31283;&#23450;&#20272;&#35745;&#29983;&#23384;&#22240;&#26524;&#25928;&#24212;&#30340;&#38382;&#39064;&#65292;&#30740;&#31350;&#34920;&#26126;&#20256;&#32479;&#30340;&#20272;&#35745;&#26041;&#27861;&#23384;&#22312;&#20559;&#24046;&#65292;&#32780;&#36817;&#26399;&#38750;&#20542;&#26012;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#23613;&#31649;&#29702;&#35770;&#19978;&#26377;&#21560;&#24341;&#21147;&#65292;&#20294;&#22312;&#29983;&#23384;&#38382;&#39064;&#20013;&#23384;&#22312;&#19981;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20272;&#35745;&#29983;&#23384;&#22240;&#26524;&#25928;&#24212;&#30340;&#38382;&#39064;&#65292;&#21363;&#34920;&#24449;&#24178;&#39044;&#23545;&#29983;&#23384;&#26102;&#38388;&#30340;&#24433;&#21709;&#65292;&#20363;&#22914;&#33647;&#29289;&#26159;&#21542;&#32553;&#30701;&#20102;&#20837;&#20303;ICU&#30340;&#26102;&#38388;&#25110;&#24191;&#21578;&#27963;&#21160;&#26159;&#21542;&#22686;&#21152;&#20102;&#39038;&#23458;&#20572;&#30041;&#26102;&#38388;&#12290; &#36807;&#21435;&#26368;&#27969;&#34892;&#30340;&#20272;&#35745;&#26041;&#27861;&#26159;&#22522;&#20110;&#21442;&#25968;&#21270;&#25110;&#21322;&#21442;&#25968;&#21270;&#27169;&#22411;&#65288;&#20363;&#22914;&#27604;&#20363;&#39118;&#38505;&#27169;&#22411;&#65289;&#65292;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#23384;&#22312;&#26174;&#33879;&#30340;&#20559;&#24046;&#38382;&#39064;&#12290;&#26368;&#36817;&#65292;&#38750;&#20542;&#26012;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#22823;&#25968;&#25454;&#38598;&#24212;&#29992;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#27969;&#34892;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#36825;&#20123;&#20272;&#35745;&#26041;&#27861;&#20855;&#26377;&#21560;&#24341;&#20154;&#30340;&#29702;&#35770;&#24615;&#36136;&#65292;&#20294;&#23427;&#20204;&#24448;&#24448;&#26159;&#19981;&#31283;&#23450;&#30340;&#65292;&#22240;&#20026;&#38750;&#20542;&#26012;&#21270;&#27493;&#39588;&#28041;&#21450;&#20351;&#29992;&#23567;&#20272;&#35745;&#27010;&#29575;&#30340;&#20498;&#25968;-&#20272;&#35745;&#27010;&#29575;&#30340;&#23567;&#35823;&#24046;&#21487;&#33021;&#23548;&#33268;&#20498;&#25968;&#21644;&#32467;&#26524;&#20272;&#35745;&#37327;&#21457;&#29983;&#24040;&#22823;&#21464;&#21270;&#12290;&#22312;&#29983;&#23384;&#38382;&#39064;&#20013;&#65292;&#36825;&#20010;&#38382;&#39064;&#26356;&#21152;&#31361;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of estimating survival causal effects, where the aim is to characterize the impact of an intervention on survival times, i.e., how long it takes for an event to occur. Applications include determining if a drug reduces the time to ICU discharge or if an advertising campaign increases customer dwell time. Historically, the most popular estimates have been based on parametric or semiparametric (e.g. proportional hazards) models; however, these methods suffer from problematic levels of bias. Recently debiased machine learning approaches are becoming increasingly popular, especially in applications to large datasets. However, despite their appealing theoretical properties, these estimators tend to be unstable because the debiasing step involves the use of the inverses of small estimated probabilities -- small errors in the estimated probabilities can result in huge changes in their inverses and therefore the resulting estimator. This problem is exacerbated in survival 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34701;&#21512;&#27169;&#20223;&#23398;&#20064;&#21644;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#26681;&#25454;&#22312;&#32447;&#35780;&#20272;&#32467;&#26524;&#20132;&#26367;&#20351;&#29992;&#20108;&#32773;&#65292;&#20197;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#21644;&#23398;&#20064;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.01737</link><description>&lt;p&gt;
&#34701;&#21512;&#27169;&#20223;&#23398;&#20064;&#21644;&#24378;&#21270;&#23398;&#20064;&#20197;&#23454;&#29616;&#40065;&#26834;&#31574;&#30053;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
Blending Imitation and Reinforcement Learning for Robust Policy Improvement. (arXiv:2310.01737v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01737
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34701;&#21512;&#27169;&#20223;&#23398;&#20064;&#21644;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#26681;&#25454;&#22312;&#32447;&#35780;&#20272;&#32467;&#26524;&#20132;&#26367;&#20351;&#29992;&#20108;&#32773;&#65292;&#20197;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#21644;&#23398;&#20064;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#24378;&#21270;&#23398;&#20064;&#22312;&#24615;&#33021;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#20854;&#26679;&#26412;&#22797;&#26434;&#24230;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#22823;&#38556;&#30861;&#65292;&#38480;&#21046;&#20102;&#20854;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#24191;&#27867;&#24212;&#29992;&#12290;&#27169;&#20223;&#23398;&#20064;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#20248;&#21270;&#26679;&#26412;&#25928;&#29575;&#65292;&#20294;&#36890;&#24120;&#21463;&#21040;&#25152;&#20351;&#29992;&#30340;&#19987;&#23478;&#31034;&#33539;&#30340;&#36136;&#37327;&#38480;&#21046;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#34701;&#21512;&#27169;&#20223;&#23398;&#20064;&#21644;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26681;&#25454;&#22312;&#32447;&#35780;&#20272;&#32467;&#26524;&#20132;&#26367;&#20351;&#29992;&#20108;&#32773;&#65292;&#26377;&#25928;&#22320;&#25552;&#39640;&#20102;&#23398;&#20064;&#25928;&#29575;&#12290;&#36825;&#31181;&#31639;&#27861;&#33021;&#22815;&#20174;&#22810;&#31181;&#40657;&#30418;&#19987;&#23478;&#31034;&#33539;&#20013;&#23398;&#20064;&#21644;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
While reinforcement learning (RL) has shown promising performance, its sample complexity continues to be a substantial hurdle, restricting its broader application across a variety of domains. Imitation learning (IL) utilizes oracles to improve sample efficiency, yet it is often constrained by the quality of the oracles deployed. which actively interleaves between IL and RL based on an online estimate of their performance. RPI draws on the strengths of IL, using oracle queries to facilitate exploration, an aspect that is notably challenging in sparse-reward RL, particularly during the early stages of learning. As learning unfolds, RPI gradually transitions to RL, effectively treating the learned policy as an improved oracle. This algorithm is capable of learning from and improving upon a diverse set of black-box oracles. Integral to RPI are Robust Active Policy Selection (RAPS) and Robust Policy Gradient (RPG), both of which reason over whether to perform state-wise imitation from the o
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#30828;&#20214;&#36164;&#28304;&#20351;&#29992;&#30340;&#27010;&#29575;&#23398;&#20064;&#65292;&#36890;&#36807;&#35299;&#20915;&#36335;&#24452;&#32467;&#26500;&#22810;&#37325;&#36793;&#26725;&#38382;&#39064;&#65292;&#21487;&#20197;&#39044;&#27979;&#25511;&#21046;&#36719;&#20214;&#30340;&#30828;&#20214;&#36164;&#28304;&#21033;&#29992;&#24773;&#20917;&#65292;&#24182;&#22312;&#20219;&#24847;&#26102;&#38388;&#23454;&#29616;&#32447;&#24615;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2310.00604</link><description>&lt;p&gt;
&#30828;&#20214;&#36164;&#28304;&#20351;&#29992;&#30340;&#27010;&#29575;&#23398;&#20064;&#20013;&#30340;&#36335;&#24452;&#32467;&#26500;&#22810;&#37325;&#36793;&#26725;
&lt;/p&gt;
&lt;p&gt;
Path Structured Multimarginal Schr\"odinger Bridge for Probabilistic Learning of Hardware Resource Usage by Control Software. (arXiv:2310.00604v2 [eess.SY] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00604
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#30828;&#20214;&#36164;&#28304;&#20351;&#29992;&#30340;&#27010;&#29575;&#23398;&#20064;&#65292;&#36890;&#36807;&#35299;&#20915;&#36335;&#24452;&#32467;&#26500;&#22810;&#37325;&#36793;&#26725;&#38382;&#39064;&#65292;&#21487;&#20197;&#39044;&#27979;&#25511;&#21046;&#36719;&#20214;&#30340;&#30828;&#20214;&#36164;&#28304;&#21033;&#29992;&#24773;&#20917;&#65292;&#24182;&#22312;&#20219;&#24847;&#26102;&#38388;&#23454;&#29616;&#32447;&#24615;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36335;&#24452;&#32467;&#26500;&#22810;&#37325;&#36793;&#26725;&#38382;&#39064;&#65288;MSBP&#65289;&#30340;&#35299;&#20915;&#26041;&#26696;&#26159;&#19982;&#35266;&#23519;&#21040;&#30340;&#27010;&#29575;&#27979;&#24230;&#24207;&#21015;&#25110;&#20998;&#24067;&#24555;&#29031;&#19968;&#33268;&#30340;&#26368;&#21487;&#33021;&#30340;&#27979;&#24230;&#20540;&#36712;&#36857;&#12290;&#25105;&#20204;&#21033;&#29992;&#26368;&#36817;&#22312;&#35299;&#20915;&#36825;&#31181;&#32467;&#26500;&#21270;&#30340;MSBP&#26041;&#38754;&#30340;&#31639;&#27861;&#36827;&#23637;&#65292;&#29992;&#20110;&#23398;&#20064;&#25511;&#21046;&#36719;&#20214;&#30340;&#38543;&#26426;&#30828;&#20214;&#36164;&#28304;&#20351;&#29992;&#24773;&#20917;&#12290;&#35813;&#35299;&#20915;&#26041;&#26696;&#33021;&#22815;&#39044;&#27979;&#25152;&#38656;&#26102;&#38388;&#30340;&#30828;&#20214;&#36164;&#28304;&#21487;&#29992;&#24615;&#30340;&#26102;&#21464;&#20998;&#24067;&#65292;&#24182;&#20855;&#26377;&#32447;&#24615;&#25910;&#25947;&#24615;&#30340;&#20445;&#35777;&#12290;&#25105;&#20204;&#22312;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;&#36719;&#20214;&#25191;&#34892;&#26696;&#20363;&#30740;&#31350;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#27010;&#29575;&#23398;&#20064;&#26041;&#27861;&#30340;&#25928;&#21147;&#12290;&#35813;&#26041;&#27861;&#36805;&#36895;&#25910;&#25947;&#21040;&#23545;&#25511;&#21046;&#22120;&#30828;&#20214;&#36164;&#28304;&#21033;&#29992;&#30340;&#20934;&#30830;&#39044;&#27979;&#12290;&#35813;&#26041;&#27861;&#21487;&#24191;&#27867;&#24212;&#29992;&#20110;&#20219;&#20309;&#36719;&#20214;&#65292;&#20197;&#39044;&#27979;&#20219;&#24847;&#26102;&#38388;&#30340;&#32593;&#32476;&#29289;&#29702;&#19978;&#19979;&#25991;&#20381;&#36182;&#24615;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The solution of the path structured multimarginal Schr\"{o}dinger bridge problem (MSBP) is the most-likely measure-valued trajectory consistent with a sequence of observed probability measures or distributional snapshots. We leverage recent algorithmic advances in solving such structured MSBPs for learning stochastic hardware resource usage by control software. The solution enables predicting the time-varying distribution of hardware resource availability at a desired time with guaranteed linear convergence. We demonstrate the efficacy of our probabilistic learning approach in a model predictive control software execution case study. The method exhibits rapid convergence to an accurate prediction of hardware resource utilization of the controller. The method can be broadly applied to any software to predict cyber-physical context-dependent performance at arbitrary time.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#24369;&#30417;&#30563;&#19979;&#30340;&#25968;&#25454;&#36873;&#25321;&#36827;&#34892;&#20102;&#32479;&#35745;&#29702;&#35770;&#30740;&#31350;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#25968;&#25454;&#36873;&#25321;&#21487;&#20197;&#38750;&#24120;&#26377;&#25928;&#65292;&#26377;&#26102;&#29978;&#33267;&#21487;&#20197;&#25112;&#32988;&#23545;&#25972;&#20010;&#26679;&#26412;&#30340;&#35757;&#32451;&#12290;&#24182;&#20998;&#26512;&#20102;&#22312;&#19981;&#21516;&#24773;&#20917;&#19979;&#30340;&#25968;&#25454;&#36873;&#25321;&#36873;&#25321;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.14563</link><description>&lt;p&gt;
&#38754;&#21521;&#24369;&#30417;&#30563;&#19979;&#30340;&#25968;&#25454;&#36873;&#25321;&#32479;&#35745;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Towards a statistical theory of data selection under weak supervision. (arXiv:2309.14563v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14563
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#24369;&#30417;&#30563;&#19979;&#30340;&#25968;&#25454;&#36873;&#25321;&#36827;&#34892;&#20102;&#32479;&#35745;&#29702;&#35770;&#30740;&#31350;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#25968;&#25454;&#36873;&#25321;&#21487;&#20197;&#38750;&#24120;&#26377;&#25928;&#65292;&#26377;&#26102;&#29978;&#33267;&#21487;&#20197;&#25112;&#32988;&#23545;&#25972;&#20010;&#26679;&#26412;&#30340;&#35757;&#32451;&#12290;&#24182;&#20998;&#26512;&#20102;&#22312;&#19981;&#21516;&#24773;&#20917;&#19979;&#30340;&#25968;&#25454;&#36873;&#25321;&#36873;&#25321;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#19968;&#20010;&#22823;&#23567;&#20026;N&#30340;&#26679;&#26412;&#65292;&#36873;&#25321;&#19968;&#20010;&#26356;&#23567;&#30340;&#22823;&#23567;n&lt;N&#30340;&#23376;&#26679;&#26412;&#29992;&#20110;&#32479;&#35745;&#20272;&#35745;&#25110;&#23398;&#20064;&#36890;&#24120;&#26159;&#26377;&#29992;&#30340;&#12290;&#36825;&#26679;&#30340;&#25968;&#25454;&#36873;&#25321;&#27493;&#39588;&#26377;&#21161;&#20110;&#20943;&#23569;&#25968;&#25454;&#26631;&#35760;&#30340;&#35201;&#27714;&#21644;&#23398;&#20064;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#20551;&#35774;&#32473;&#23450;&#20102;N&#20010;&#26410;&#26631;&#35760;&#30340;&#26679;&#26412;{x_i}&#65292;&#24182;&#19988;&#21487;&#20197;&#35775;&#38382;&#19968;&#20010;&#8220;&#26367;&#20195;&#27169;&#22411;&#8221;&#65292;&#23427;&#21487;&#20197;&#27604;&#38543;&#26426;&#29468;&#27979;&#26356;&#22909;&#22320;&#39044;&#27979;&#26631;&#31614;y_i&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#36873;&#25321;&#19968;&#20010;&#23376;&#26679;&#26412;&#38598;{&#119857;_i}&#65292;&#20854;&#22823;&#23567;&#20026;|G|=n&lt;N&#12290;&#28982;&#21518;&#25105;&#20204;&#20026;&#36825;&#20010;&#38598;&#21512;&#33719;&#21462;&#26631;&#31614;&#65292;&#24182;&#20351;&#29992;&#23427;&#20204;&#36890;&#36807;&#27491;&#21017;&#21270;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#26469;&#35757;&#32451;&#27169;&#22411;&#12290;&#36890;&#36807;&#22312;&#30495;&#23454;&#21644;&#21512;&#25104;&#25968;&#25454;&#19978;&#36827;&#34892;&#28151;&#21512;&#30340;&#25968;&#20540;&#23454;&#39564;&#65292;&#24182;&#22312;&#20302;&#32500;&#21644;&#39640;&#32500;&#28176;&#36817;&#24773;&#20917;&#19979;&#36827;&#34892;&#25968;&#23398;&#25512;&#23548;&#65292;&#25105;&#20204;&#35777;&#26126;&#65306;(i) &#25968;&#25454;&#36873;&#25321;&#21487;&#20197;&#38750;&#24120;&#26377;&#25928;&#65292;&#29305;&#21035;&#26159;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#21487;&#20197;&#20987;&#36133;&#23545;&#25972;&#20010;&#26679;&#26412;&#30340;&#35757;&#32451;&#65307;(ii) &#22312;&#25968;&#25454;&#36873;&#25321;&#26041;&#38754;&#65292;&#26576;&#20123;&#27969;&#34892;&#30340;&#36873;&#25321;&#22312;&#19968;&#20123;&#24773;&#20917;&#19979;&#26159;&#26377;&#25928;&#30340;&#65292;&#32780;&#22312;&#20854;&#20182;&#24773;&#20917;&#19979;&#21017;&#19981;&#26159;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given a sample of size $N$, it is often useful to select a subsample of smaller size $n&lt;N$ to be used for statistical estimation or learning. Such a data selection step is useful to reduce the requirements of data labeling and the computational complexity of learning. We assume to be given $N$ unlabeled samples $\{{\boldsymbol x}_i\}_{i\le N}$, and to be given access to a `surrogate model' that can predict labels $y_i$ better than random guessing. Our goal is to select a subset of the samples, to be denoted by $\{{\boldsymbol x}_i\}_{i\in G}$, of size $|G|=n&lt;N$. We then acquire labels for this set and we use them to train a model via regularized empirical risk minimization.  By using a mixture of numerical experiments on real and synthetic data, and mathematical derivations under low- and high- dimensional asymptotics, we show that: $(i)$~Data selection can be very effective, in particular beating training on the full sample in some cases; $(ii)$~Certain popular choices in data selecti
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#38598;&#25104;&#24046;&#20998;&#36827;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#27169;&#25311;&#28151;&#21512;&#21644;&#33258;&#36866;&#24212;&#26426;&#21046;&#26469;&#35299;&#20915;&#19981;&#30830;&#23450;&#26465;&#20214;&#19979;&#30340;&#24211;&#23384;&#31649;&#29702;&#38382;&#39064;&#12290;&#23454;&#35777;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#24211;&#23384;&#31649;&#29702;&#30340;&#36130;&#21153;&#32489;&#25928;&#21644;&#20248;&#21270;&#22823;&#25628;&#32034;&#31354;&#38388;&#12290;</title><link>http://arxiv.org/abs/2309.12852</link><description>&lt;p&gt;
&#22522;&#20110;&#27169;&#25311;&#28151;&#21512;&#21644;&#33258;&#36866;&#24212;&#30340;&#38598;&#25104;&#24046;&#20998;&#36827;&#21270;&#31639;&#27861;&#29992;&#20110;&#19981;&#30830;&#23450;&#26465;&#20214;&#19979;&#30340;&#24211;&#23384;&#31649;&#29702;
&lt;/p&gt;
&lt;p&gt;
Ensemble Differential Evolution with Simulation-Based Hybridization and Self-Adaptation for Inventory Management Under Uncertainty. (arXiv:2309.12852v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12852
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#38598;&#25104;&#24046;&#20998;&#36827;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#27169;&#25311;&#28151;&#21512;&#21644;&#33258;&#36866;&#24212;&#26426;&#21046;&#26469;&#35299;&#20915;&#19981;&#30830;&#23450;&#26465;&#20214;&#19979;&#30340;&#24211;&#23384;&#31649;&#29702;&#38382;&#39064;&#12290;&#23454;&#35777;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#24211;&#23384;&#31649;&#29702;&#30340;&#36130;&#21153;&#32489;&#25928;&#21644;&#20248;&#21270;&#22823;&#25628;&#32034;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#25311;&#28151;&#21512;&#21644;&#33258;&#36866;&#24212;&#30340;&#38598;&#25104;&#24046;&#20998;&#36827;&#21270;&#31639;&#27861;&#65288;EDESH-SA&#65289;&#26469;&#35299;&#20915;&#19981;&#30830;&#23450;&#26465;&#20214;&#19979;&#30340;&#24211;&#23384;&#31649;&#29702;&#38382;&#39064;&#12290;&#35813;&#31639;&#27861;&#23558;&#24046;&#20998;&#36827;&#21270;&#31639;&#27861;&#19982;&#27169;&#25311;&#28151;&#21512;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#24182;&#36890;&#36807;&#33258;&#36866;&#24212;&#26426;&#21046;&#21160;&#24577;&#22320;&#25913;&#21464;&#21464;&#24322;&#29575;&#21644;&#20132;&#21449;&#29575;&#12290;&#30001;&#20110;&#20854;&#36866;&#24212;&#24615;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#22788;&#29702;&#24211;&#23384;&#31649;&#29702;&#20013;&#30340;&#22797;&#26434;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#12290;&#36890;&#36807;&#20351;&#29992;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#65288;MCS&#65289;&#65292;&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#36830;&#32493;&#23457;&#26597;&#65288;CR&#65289;&#24211;&#23384;&#31574;&#30053;&#65292;&#24182;&#32771;&#34385;&#20102;&#38543;&#26426;&#24615;&#21644;&#19981;&#21516;&#30340;&#38656;&#27714;&#24773;&#26223;&#12290;&#36825;&#31181;&#22522;&#20110;&#27169;&#25311;&#30340;&#26041;&#27861;&#21487;&#20197;&#30495;&#23454;&#22320;&#35780;&#20272;&#25152;&#25552;&#31639;&#27861;&#22312;&#23454;&#38469;&#29615;&#22659;&#20013;&#35299;&#20915;&#24211;&#23384;&#31649;&#29702;&#25361;&#25112;&#30340;&#36866;&#29992;&#24615;&#12290;&#23454;&#35777;&#30740;&#31350;&#30340;&#32467;&#26524;&#26174;&#31034;&#20102;&#25152;&#25552;&#26041;&#27861;&#22312;&#25552;&#39640;&#24211;&#23384;&#31649;&#29702;&#30340;&#36130;&#21153;&#32489;&#25928;&#21644;&#20248;&#21270;&#22823;&#25628;&#32034;&#31354;&#38388;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study proposes an Ensemble Differential Evolution with Simula-tion-Based Hybridization and Self-Adaptation (EDESH-SA) approach for inven-tory management (IM) under uncertainty. In this study, DE with multiple runs is combined with a simulation-based hybridization method that includes a self-adaptive mechanism that dynamically alters mutation and crossover rates based on the success or failure of each iteration. Due to its adaptability, the algorithm is able to handle the complexity and uncertainty present in IM. Utilizing Monte Carlo Simulation (MCS), the continuous review (CR) inventory strategy is ex-amined while accounting for stochasticity and various demand scenarios. This simulation-based approach enables a realistic assessment of the proposed algo-rithm's applicability in resolving the challenges faced by IM in practical settings. The empirical findings demonstrate the potential of the proposed method to im-prove the financial performance of IM and optimize large search spa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#30740;&#31350;&#20102;&#22312;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#20013;&#27169;&#20223;&#22797;&#26434;&#19987;&#23478;&#28436;&#31034;&#30340;&#34892;&#20026;&#12290;&#36890;&#36807;&#31283;&#23450;&#27169;&#20223;&#31574;&#30053;&#24182;&#30830;&#20445;&#20934;&#30830;&#20272;&#35745;&#28436;&#31034;&#32773;&#20998;&#24067;&#65292;&#21487;&#20197;&#20351;&#27169;&#20223;&#32773;&#19982;&#28436;&#31034;&#32773;&#30340;&#36712;&#36857;&#20998;&#24067;&#30456;&#36817;&#12290;</title><link>http://arxiv.org/abs/2307.14619</link><description>&lt;p&gt;
&#27169;&#20223;&#22797;&#26434;&#36712;&#36857;&#65306;&#26725;&#25509;&#20302;&#23618;&#31283;&#23450;&#24615;&#19982;&#39640;&#23618;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Imitating Complex Trajectories: Bridging Low-Level Stability and High-Level Behavior. (arXiv:2307.14619v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14619
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#30740;&#31350;&#20102;&#22312;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#20013;&#27169;&#20223;&#22797;&#26434;&#19987;&#23478;&#28436;&#31034;&#30340;&#34892;&#20026;&#12290;&#36890;&#36807;&#31283;&#23450;&#27169;&#20223;&#31574;&#30053;&#24182;&#30830;&#20445;&#20934;&#30830;&#20272;&#35745;&#28436;&#31034;&#32773;&#20998;&#24067;&#65292;&#21487;&#20197;&#20351;&#27169;&#20223;&#32773;&#19982;&#28436;&#31034;&#32773;&#30340;&#36712;&#36857;&#20998;&#24067;&#30456;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#30740;&#31350;&#22312;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#20013;&#27169;&#20223;&#38543;&#26426;&#12289;&#38750;&#39532;&#23572;&#21487;&#22827;&#12289;&#28508;&#22312;&#22810;&#27169;&#24577;&#65288;&#21363;&#8220;&#22797;&#26434;&#8221;&#65289;&#19987;&#23478;&#28436;&#31034;&#30340;&#34892;&#20026;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#20351;&#29992;&#20302;&#23618;&#25511;&#21046;&#22120;&#65288;&#26080;&#35770;&#26159;&#23398;&#20064;&#30340;&#36824;&#26159;&#38544;&#21547;&#30340;&#65289;&#26469;&#31283;&#23450;&#22260;&#32469;&#19987;&#23478;&#28436;&#31034;&#30340;&#27169;&#20223;&#31574;&#30053;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#65288;a&#65289;&#21512;&#36866;&#30340;&#20302;&#23618;&#31283;&#23450;&#24615;&#20445;&#35777;&#21644;&#65288;b&#65289;&#23398;&#20064;&#31574;&#30053;&#30340;&#38543;&#26426;&#36830;&#32493;&#24615;&#23646;&#24615;&#65288;&#25105;&#20204;&#31216;&#20043;&#20026;&#8220;&#24635;&#21464;&#24046;&#36830;&#32493;&#24615;&#8221;&#65289;&#65288;TVC&#65289;&#30340;&#24773;&#20917;&#19979;&#65292;&#19968;&#20010;&#31934;&#30830;&#20272;&#35745;&#28436;&#31034;&#32773;&#29366;&#24577;&#20998;&#24067;&#19978;&#30340;&#34892;&#21160;&#30340;&#27169;&#20223;&#32773;&#20250;&#19982;&#28436;&#31034;&#32773;&#23545;&#25972;&#20010;&#36712;&#36857;&#30340;&#20998;&#24067;&#30456;&#36817;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#21487;&#20197;&#36890;&#36807;&#23558;&#27969;&#34892;&#30340;&#25968;&#25454;&#22686;&#24378;&#35268;&#21017;&#19982;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#25216;&#24039;&#30456;&#32467;&#21512;&#65288;&#21363;&#22312;&#25191;&#34892;&#26102;&#28155;&#21152;&#22686;&#24378;&#22122;&#22768;&#65289;&#26469;&#30830;&#20445;TVC&#24182;&#19988;&#26368;&#23567;&#31243;&#24230;&#19978;&#38477;&#20302;&#31934;&#24230;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#20445;&#35777;&#23454;&#20363;&#21270;&#20026;&#30001;&#25193;&#25955;&#27169;&#22411;&#21442;&#25968;&#21270;&#30340;&#31574;&#30053;&#65292;&#24182;&#35777;&#26126;&#22914;&#26524;&#23398;&#20064;&#32773;&#20934;&#30830;&#22320;&#20272;&#35745;&#20102;&#28436;&#31034;&#32773;&#30340;&#20998;&#24067;&#65292;&#21017;&#26368;&#32456;&#23436;&#25104;&#36825;&#31181;&#23454;&#20363;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a theoretical framework for studying the imitation of stochastic, non-Markovian, potentially multi-modal (i.e. "complex" ) expert demonstrations in nonlinear dynamical systems. Our framework invokes low-level controllers either learned or implicit in position-command control - to stabilize imitation policies around expert demonstrations. We show that with (a) a suitable low-level stability guarantee and (b) a stochastic continuity property of the learned policy we call "total variation continuity" (TVC), an imitator that accurately estimates actions on the demonstrator's state distribution closely matches the demonstrator's distribution over entire trajectories. We then show that TVC can be ensured with minimal degradation of accuracy by combining a popular data-augmentation regimen with a novel algorithmic trick: adding augmentation noise at execution time. We instantiate our guarantees for policies parameterized by diffusion models and prove that if the learner accuratel
&lt;/p&gt;</description></item><item><title>UTrans&#26159;&#19968;&#31181;&#32479;&#19968;&#36716;&#31227;&#23398;&#20064;&#27169;&#22411;&#65292;&#23427;&#33021;&#26816;&#27979;&#21487;&#36716;&#31227;&#21464;&#37327;&#21644;&#28304;&#25968;&#25454;&#65292;&#24182;&#20855;&#26377;&#36739;&#20302;&#30340;&#20272;&#35745;&#21644;&#39044;&#27979;&#35823;&#24046;&#65292;&#21516;&#26102;&#20445;&#25345;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.00238</link><description>&lt;p&gt;
&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#30340;&#32479;&#19968;&#36716;&#31227;&#23398;&#20064;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Unified Transfer Learning Models for High-Dimensional Linear Regression. (arXiv:2307.00238v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00238
&lt;/p&gt;
&lt;p&gt;
UTrans&#26159;&#19968;&#31181;&#32479;&#19968;&#36716;&#31227;&#23398;&#20064;&#27169;&#22411;&#65292;&#23427;&#33021;&#26816;&#27979;&#21487;&#36716;&#31227;&#21464;&#37327;&#21644;&#28304;&#25968;&#25454;&#65292;&#24182;&#20855;&#26377;&#36739;&#20302;&#30340;&#20272;&#35745;&#21644;&#39044;&#27979;&#35823;&#24046;&#65292;&#21516;&#26102;&#20445;&#25345;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#20195;&#25968;&#25454;&#20998;&#26512;&#20013;&#65292;&#24403;&#30446;&#26631;&#25968;&#25454;&#31232;&#32570;&#32780;&#28304;&#25968;&#25454;&#20805;&#36275;&#65292;&#25110;&#32773;&#28304;&#25968;&#25454;&#21644;&#30446;&#26631;&#25968;&#25454;&#30340;&#20998;&#24067;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#65292;&#36716;&#31227;&#23398;&#20064;&#22312;&#21457;&#25381;&#37325;&#35201;&#20316;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#32479;&#19968;&#36716;&#31227;&#23398;&#20064;&#27169;&#22411;&#65292;&#31216;&#20026;UTrans&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#26816;&#27979;&#21487;&#36716;&#31227;&#21464;&#37327;&#21644;&#28304;&#25968;&#25454;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#20272;&#35745;&#35823;&#24046;&#30028;&#38480;&#65292;&#24182;&#35777;&#26126;&#25105;&#20204;&#30340;&#30028;&#38480;&#20302;&#20110;&#20165;&#26377;&#30446;&#26631;&#25968;&#25454;&#30340;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22522;&#20110;&#20551;&#35774;&#26816;&#39564;&#25552;&#20986;&#20102;&#19968;&#31181;&#28304;&#25968;&#25454;&#26816;&#27979;&#31639;&#27861;&#65292;&#29992;&#20110;&#25490;&#38500;&#19981;&#21487;&#36716;&#31227;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#23454;&#39564;&#20013;&#35780;&#20272;&#21644;&#27604;&#36739;&#20102;UTrans&#19982;&#29616;&#26377;&#31639;&#27861;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;UTrans&#22312;&#20445;&#25345;&#21487;&#35299;&#37322;&#24615;&#30340;&#21516;&#26102;&#65292;&#27604;&#29616;&#26377;&#26041;&#27861;&#20855;&#26377;&#26356;&#20302;&#30340;&#20272;&#35745;&#21644;&#39044;&#27979;&#35823;&#24046;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#20854;&#24212;&#29992;&#20110;&#32654;&#22269;&#20195;&#38469;&#27969;&#21160;&#25968;&#25454;&#65292;&#24182;&#23558;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#19982;&#32463;&#20856;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transfer learning plays a key role in modern data analysis when: (1) the target data are scarce but the source data are sufficient; (2) the distributions of the source and target data are heterogeneous. This paper develops an interpretable unified transfer learning model, termed as UTrans, which can detect both transferable variables and source data. More specifically, we establish the estimation error bounds and prove that our bounds are lower than those with target data only. Besides, we propose a source detection algorithm based on hypothesis testing to exclude the nontransferable data. We evaluate and compare UTrans to the existing algorithms in multiple experiments. It is shown that UTrans attains much lower estimation and prediction errors than the existing methods, while preserving interpretability. We finally apply it to the US intergenerational mobility data and compare our proposed algorithms to the classical machine learning algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#22270;&#25299;&#25169;&#30340;&#22270;&#28857;&#36807;&#31243;&#26041;&#27861;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#22270;&#26680;&#26469;&#25551;&#36848;&#20107;&#20214;&#20043;&#38388;&#30340;&#35302;&#21457;&#21644;&#25233;&#21046;&#25928;&#24212;&#65292;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.11313</link><description>&lt;p&gt;
&#28145;&#24230;&#22270;&#26680;&#28857;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Deep graph kernel point processes. (arXiv:2306.11313v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11313
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#22270;&#25299;&#25169;&#30340;&#22270;&#28857;&#36807;&#31243;&#26041;&#27861;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#22270;&#26680;&#26469;&#25551;&#36848;&#20107;&#20214;&#20043;&#38388;&#30340;&#35302;&#21457;&#21644;&#25233;&#21046;&#25928;&#24212;&#65292;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28857;&#36807;&#31243;&#27169;&#22411;&#24191;&#27867;&#29992;&#20110;&#20998;&#26512;&#22270;&#20013;&#24322;&#27493;&#20107;&#20214;&#65292;&#21453;&#26144;&#19981;&#21516;&#31867;&#22411;&#20107;&#20214;&#20043;&#38388;&#30340;&#30456;&#20114;&#24433;&#21709;&#12290;&#39044;&#27979;&#26410;&#26469;&#20107;&#20214;&#30340;&#26102;&#38388;&#21644;&#31867;&#22411;&#26159;&#19968;&#39033;&#20851;&#38190;&#20219;&#21153;&#65292;&#24182;&#19988;&#22270;&#30340;&#22823;&#23567;&#21644;&#25299;&#25169;&#32467;&#26500;&#22686;&#21152;&#20102;&#38382;&#39064;&#30340;&#38590;&#24230;&#12290;&#26368;&#36817;&#30340;&#31070;&#32463;&#28857;&#36807;&#31243;&#27169;&#22411;&#25581;&#31034;&#20102;&#25429;&#25417;&#22797;&#26434;&#30340;&#20107;&#20214;&#31867;&#21035;&#20043;&#38388;&#20381;&#36182;&#20851;&#31995;&#30340;&#21487;&#33021;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#27599;&#20010;&#30446;&#26631;&#20107;&#20214;&#31867;&#22411;&#30340;&#24378;&#24230;&#35745;&#31639;&#20013;&#20351;&#29992;&#20102;&#21253;&#25324;&#25152;&#26377;&#20107;&#20214;&#31867;&#21035;&#22312;&#20869;&#30340;&#26410;&#32463;&#28388;&#27874;&#30340;&#20107;&#20214;&#35760;&#24405;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#22270;&#25299;&#25169;&#30340;&#22270;&#28857;&#36807;&#31243;&#26041;&#27861;&#12290;&#23545;&#24212;&#30340;&#26080;&#21521;&#22270;&#20855;&#26377;&#20195;&#34920;&#20107;&#20214;&#31867;&#21035;&#30340;&#33410;&#28857;&#21644;&#34920;&#31034;&#28508;&#22312;&#36129;&#29486;&#20851;&#31995;&#30340;&#36793;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#22270;&#26680;&#26469;&#25551;&#36848;&#20107;&#20214;&#20043;&#38388;&#30340;&#35302;&#21457;&#21644;&#25233;&#21046;&#25928;&#24212;&#12290;&#26412;&#36136;&#24433;&#21709;&#32467;&#26500;&#36890;&#36807;&#22270;&#31070;&#32463;&#32593;&#32476;-based&#30340;&#23616;&#37096;&#37051;&#22495;&#20449;&#24687;&#32858;&#21512;&#36827;&#34892;&#20102;&#34701;&#21512;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#27604;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#26356;&#20855;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Point process models are widely used to analyze asynchronous events occurring within a graph that reflect how different types of events influence one another. Predicting future events' times and types is a crucial task, and the size and topology of the graph add to the challenge of the problem. Recent neural point process models unveil the possibility of capturing intricate inter-event-category dependencies. However, such methods utilize an unfiltered history of events, including all event categories in the intensity computation for each target event type. In this work, we propose a graph point process method where event interactions occur based on a latent graph topology. The corresponding undirected graph has nodes representing event categories and edges indicating potential contribution relationships. We then develop a novel deep graph kernel to characterize the triggering and inhibiting effects between events. The intrinsic influence structures are incorporated via the graph neural
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25968;&#20540;&#27169;&#25311;&#26102;&#38388;&#28436;&#21270;&#34203;&#23450;&#35860;&#26041;&#31243;&#65292;&#21033;&#29992;&#39532;&#23572;&#21487;&#22827;&#25193;&#25955;&#37319;&#26679;&#26469;&#36866;&#24212;&#27874;&#20989;&#25968;&#30340;&#28508;&#22312;&#20302;&#32500;&#32467;&#26500;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#38543;&#26426;&#37327;&#23376;&#21147;&#23398;&#26041;&#31243;&#65292;&#20855;&#26377;&#32447;&#24615;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#25968;&#20540;&#27169;&#25311;&#26174;&#31034;&#20986;&#26174;&#30528;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.19685</link><description>&lt;p&gt;
&#28145;&#24230;&#38543;&#26426;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Deep Stochastic Mechanics. (arXiv:2305.19685v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19685
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25968;&#20540;&#27169;&#25311;&#26102;&#38388;&#28436;&#21270;&#34203;&#23450;&#35860;&#26041;&#31243;&#65292;&#21033;&#29992;&#39532;&#23572;&#21487;&#22827;&#25193;&#25955;&#37319;&#26679;&#26469;&#36866;&#24212;&#27874;&#20989;&#25968;&#30340;&#28508;&#22312;&#20302;&#32500;&#32467;&#26500;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#38543;&#26426;&#37327;&#23376;&#21147;&#23398;&#26041;&#31243;&#65292;&#20855;&#26377;&#32447;&#24615;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#25968;&#20540;&#27169;&#25311;&#26174;&#31034;&#20986;&#26174;&#30528;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25968;&#20540;&#27169;&#25311;&#26102;&#38388;&#28436;&#21270;&#34203;&#23450;&#35860;&#26041;&#31243;&#65292;&#21463;&#38543;&#26426;&#21147;&#23398;&#21644;&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#30340;&#21551;&#21457;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#25105;&#20204;&#36890;&#36807;&#20174;&#39532;&#23572;&#21487;&#22827;&#25193;&#25955;&#20013;&#37319;&#26679;&#26469;&#36866;&#24212;&#27874;&#20989;&#25968;&#28508;&#22312;&#30340;&#20302;&#32500;&#32467;&#26500;&#65292;&#22240;&#27492;&#21487;&#20197;&#22312;&#26356;&#39640;&#30340;&#32500;&#24230;&#19978;&#38477;&#20302;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#38543;&#26426;&#37327;&#23376;&#21147;&#23398;&#26041;&#31243;&#65292;&#32467;&#26524;&#20855;&#26377;&#19982;&#32500;&#25968;&#25968;&#37327;&#32447;&#24615;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#25968;&#20540;&#27169;&#25311;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#65292;&#24182;&#26174;&#31034;&#20986;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#20854;&#20182;&#29992;&#20110;&#37327;&#23376;&#21147;&#23398;&#30340;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#30456;&#27604;&#20855;&#26377;&#26174;&#30528;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a novel deep-learning-based approach for numerical simulation of a time-evolving Schr\"odinger equation inspired by stochastic mechanics and generative diffusion models. Unlike existing approaches, which exhibit computational complexity that scales exponentially in the problem dimension, our method allows us to adapt to the latent low-dimensional structure of the wave function by sampling from the Markovian diffusion. Depending on the latent dimension, our method may have far lower computational complexity in higher dimensions. Moreover, we propose novel equations for stochastic quantum mechanics, resulting in linear computational complexity with respect to the number of dimensions. Numerical simulations verify our theoretical findings and show a significant advantage of our method compared to other deep-learning-based approaches used for quantum mechanics.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#33609;&#22270;&#25216;&#26415;&#23558;&#31890;&#23376;&#26041;&#27861;&#21644;&#24352;&#37327;&#32593;&#32476;&#26041;&#27861;&#32467;&#21512;&#30340;&#26041;&#27861;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#36825;&#31181;&#26041;&#27861;&#21253;&#25324;&#31890;&#23376;&#27169;&#25311;&#21644;&#24352;&#37327;&#32593;&#32476;&#37325;&#26032;&#20272;&#35745;&#65292;&#24182;&#21487;&#29992;&#20316;&#31890;&#23376;&#25968;&#25511;&#21046;&#30340;&#21487;&#26367;&#20195;&#26041;&#27861;&#12290;&#22312;&#27169;&#25311;Fokker-Planck&#26041;&#31243;&#21644;&#37327;&#23376;&#34394;&#26102;&#38388;&#28436;&#21270;&#26041;&#38754;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#36890;&#29992;&#24615;&#21644;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.17884</link><description>&lt;p&gt;
&#36890;&#36807;&#33609;&#22270;&#25216;&#26415;&#65292;&#23558;&#31890;&#23376;&#26041;&#27861;&#21644;&#24352;&#37327;&#32593;&#32476;&#26041;&#27861;&#32467;&#21512;&#29992;&#20110;&#20559;&#24494;&#20998;&#26041;&#31243;&#27714;&#35299;
&lt;/p&gt;
&lt;p&gt;
Combining Particle and Tensor-network Methods for Partial Differential Equations via Sketching. (arXiv:2305.17884v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17884
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#33609;&#22270;&#25216;&#26415;&#23558;&#31890;&#23376;&#26041;&#27861;&#21644;&#24352;&#37327;&#32593;&#32476;&#26041;&#27861;&#32467;&#21512;&#30340;&#26041;&#27861;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#36825;&#31181;&#26041;&#27861;&#21253;&#25324;&#31890;&#23376;&#27169;&#25311;&#21644;&#24352;&#37327;&#32593;&#32476;&#37325;&#26032;&#20272;&#35745;&#65292;&#24182;&#21487;&#29992;&#20316;&#31890;&#23376;&#25968;&#25511;&#21046;&#30340;&#21487;&#26367;&#20195;&#26041;&#27861;&#12290;&#22312;&#27169;&#25311;Fokker-Planck&#26041;&#31243;&#21644;&#37327;&#23376;&#34394;&#26102;&#38388;&#28436;&#21270;&#26041;&#38754;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#36890;&#29992;&#24615;&#21644;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#24352;&#37327;&#32593;&#32476;&#26694;&#26550;&#65292;&#20854;&#20013;&#25105;&#20204;&#37319;&#29992;&#31890;&#23376;&#27169;&#25311;&#26356;&#26032;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#20351;&#29992;&#26368;&#36817;&#25552;&#20986;&#30340;&#24352;&#37327;&#21015;&#36710;&#33609;&#22270;&#25216;&#26415;&#23558;&#26032;&#35299;&#20915;&#26041;&#26696;&#37325;&#26032;&#20272;&#35745;&#20026;&#24352;&#37327;&#32593;&#32476;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36824;&#21487;&#20197;&#34987;&#35299;&#37322;&#20026;&#36890;&#36807;&#20551;&#35774;&#31890;&#23376;&#26469;&#33258;&#24213;&#23618;&#24352;&#37327;&#32593;&#32476;&#26469;&#25191;&#34892;&#31890;&#23376;&#25968;&#25511;&#21046;&#30340;&#21487;&#26367;&#20195;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#20854;&#24212;&#29992;&#20110;&#20004;&#31181;&#29305;&#23450;&#30340;&#24773;&#26223;&#26469;&#23637;&#31034;&#25105;&#20204;&#26041;&#27861;&#30340;&#36890;&#29992;&#24615;&#21644;&#28789;&#27963;&#24615;&#65306;&#36890;&#36807;Langevin&#21160;&#21147;&#23398;&#27169;&#25311;Fokker-Planck&#26041;&#31243;&#21644;&#36890;&#36807;&#36741;&#21161;&#22330;&#37327;&#23376;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#37327;&#23376;&#34394;&#26102;&#38388;&#28436;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a general framework for solving high-dimensional partial differential equations with tensor networks. Our approach offers a comprehensive solution methodology, wherein we employ a combination of particle simulations to update the solution and re-estimations of the new solution as a tensor-network using a recently proposed tensor train sketching technique. Our method can also be interpreted as an alternative approach for performing particle number control by assuming the particles originate from an underlying tensor network. We demonstrate the versatility and flexibility of our approach by applying it to two specific scenarios: simulating the Fokker-Planck equation through Langevin dynamics and quantum imaginary time evolution via auxiliary-field quantum Monte Carlo.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#26631;&#35760;&#26102;&#38388;&#28857;&#36807;&#31243;&#20013;&#25552;&#21462;&#20854;&#32479;&#35745;&#30452;&#35273;&#30340;&#20107;&#20214;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#26465;&#20214;&#29983;&#25104;&#22120;&#20197;&#21382;&#21490;&#35266;&#23519;&#20316;&#20026;&#36755;&#20837;&#65292;&#29983;&#25104;&#21487;&#33021;&#21457;&#29983;&#30340;&#39640;&#36136;&#37327;&#38543;&#21518;&#20107;&#20214;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#39640;&#25928;&#12289;&#28789;&#27963;&#21644;&#34920;&#31034;&#33021;&#21147;&#31561;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.12569</link><description>&lt;p&gt;
&#26377;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#26159;&#26631;&#35760;&#26102;&#38388;&#28857;&#36807;&#31243;&#30340;&#24517;&#22791;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conditional Generative Modeling is All You Need for Marked Temporal Point Processes. (arXiv:2305.12569v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12569
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#26631;&#35760;&#26102;&#38388;&#28857;&#36807;&#31243;&#20013;&#25552;&#21462;&#20854;&#32479;&#35745;&#30452;&#35273;&#30340;&#20107;&#20214;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#26465;&#20214;&#29983;&#25104;&#22120;&#20197;&#21382;&#21490;&#35266;&#23519;&#20316;&#20026;&#36755;&#20837;&#65292;&#29983;&#25104;&#21487;&#33021;&#21457;&#29983;&#30340;&#39640;&#36136;&#37327;&#38543;&#21518;&#20107;&#20214;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#39640;&#25928;&#12289;&#28789;&#27963;&#21644;&#34920;&#31034;&#33021;&#21147;&#31561;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#29983;&#25104;&#24314;&#27169;&#30340;&#36827;&#27493;&#20351;&#24471;&#20174;&#19978;&#19979;&#25991;&#20449;&#24687;&#20013;&#29983;&#25104;&#39640;&#36136;&#37327;&#20869;&#23481;&#25104;&#20026;&#21487;&#33021;&#65292;&#20294;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#20173;&#28982;&#23384;&#22312;&#65306;&#22914;&#20309;&#25945;&#27169;&#22411;&#30693;&#36947;&#20309;&#26102;&#29983;&#25104;&#20869;&#23481;&#65311;&#20026;&#20102;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20107;&#20214;&#29983;&#25104;&#27169;&#22411;&#65292;&#20174;&#26631;&#35760;&#26102;&#38388;&#28857;&#36807;&#31243;&#20013;&#25552;&#21462;&#20854;&#32479;&#35745;&#30452;&#35273;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#24178;&#20928;&#12289;&#28789;&#27963;&#21644;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36866;&#29992;&#20110;&#28041;&#21450;&#22810;&#32500;&#26631;&#35760;&#30340;&#21508;&#31181;&#24212;&#29992;&#12290;&#25105;&#20204;&#26088;&#22312;&#25429;&#25417;&#28857;&#36807;&#31243;&#30340;&#20998;&#24067;&#32780;&#19981;&#38656;&#26126;&#30830;&#25351;&#23450;&#26465;&#20214;&#24378;&#24230;&#25110;&#27010;&#29575;&#23494;&#24230;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#26465;&#20214;&#29983;&#25104;&#22120;&#65292;&#20197;&#20107;&#20214;&#21382;&#21490;&#20026;&#36755;&#20837;&#24182;&#29983;&#25104;&#22312;&#20808;&#21069;&#35266;&#23519;&#21040;&#30340;&#20107;&#20214;&#19979;&#65292;&#21487;&#33021;&#21457;&#29983;&#30340;&#39640;&#36136;&#37327;&#38543;&#21518;&#20107;&#20214;&#12290;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#25552;&#20379;&#20102;&#19968;&#31995;&#21015;&#21033;&#30410;&#65292;&#21253;&#25324;&#22312;&#23398;&#20064;&#27169;&#22411;&#21644;&#29983;&#25104;&#26679;&#26412;&#26041;&#38754;&#30340;&#24322;&#24120;&#25928;&#29575;&#20197;&#21450;&#30456;&#24403;&#22823;&#30340;&#34920;&#31034;&#33021;&#21147;&#26469;&#25429;&#25417;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advancements in generative modeling have made it possible to generate high-quality content from context information, but a key question remains: how to teach models to know when to generate content? To answer this question, this study proposes a novel event generative model that draws its statistical intuition from marked temporal point processes, and offers a clean, flexible, and computationally efficient solution for a wide range of applications involving multi-dimensional marks. We aim to capture the distribution of the point process without explicitly specifying the conditional intensity or probability density. Instead, we use a conditional generator that takes the history of events as input and generates the high-quality subsequent event that is likely to occur given the prior observations. The proposed framework offers a host of benefits, including exceptional efficiency in learning the model and generating samples, as well as considerable representational power to capture
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#20174;&#19968;&#20010;&#25968;&#25454;&#20998;&#24067;P&#20256;&#36755;&#21040;&#20219;&#24847;&#35775;&#38382;&#36890;&#36807;&#26377;&#38480;&#26679;&#26412;&#30340;Q&#30340;&#27969;&#27169;&#22411;&#12290;&#36825;&#20010;&#27169;&#22411;&#36890;&#36807;&#31070;&#32463;ODE&#27169;&#22411;&#36827;&#34892;&#65292;&#21487;&#20197;&#36827;&#34892;&#26080;&#31351;&#23567;DRE&#12290;</title><link>http://arxiv.org/abs/2305.11857</link><description>&lt;p&gt;
Q-malizing&#27969;&#21644;&#26080;&#31351;&#23567;&#23494;&#24230;&#27604;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Q-malizing flow and infinitesimal density ratio estimation. (arXiv:2305.11857v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11857
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#20174;&#19968;&#20010;&#25968;&#25454;&#20998;&#24067;P&#20256;&#36755;&#21040;&#20219;&#24847;&#35775;&#38382;&#36890;&#36807;&#26377;&#38480;&#26679;&#26412;&#30340;Q&#30340;&#27969;&#27169;&#22411;&#12290;&#36825;&#20010;&#27169;&#22411;&#36890;&#36807;&#31070;&#32463;ODE&#27169;&#22411;&#36827;&#34892;&#65292;&#21487;&#20197;&#36827;&#34892;&#26080;&#31351;&#23567;DRE&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36830;&#32493;&#30340;&#27491;&#21017;&#21270;&#27969;&#22312;&#29983;&#25104;&#20219;&#21153;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20854;&#20013;&#27969;&#32593;&#32476;&#20174;&#25968;&#25454;&#20998;&#24067;P&#20256;&#36755;&#21040;&#27491;&#24577;&#20998;&#24067;&#12290;&#19968;&#31181;&#33021;&#22815;&#20174;P&#20256;&#36755;&#21040;&#20219;&#24847;Q&#30340;&#27969;&#27169;&#22411;&#65292;&#20854;&#20013;P&#21644;Q&#37117;&#21487;&#36890;&#36807;&#26377;&#38480;&#26679;&#26412;&#35775;&#38382;&#65292;&#23558;&#22312;&#21508;&#31181;&#24212;&#29992;&#20852;&#36259;&#20013;&#20351;&#29992;&#65292;&#29305;&#21035;&#26159;&#22312;&#26368;&#36817;&#24320;&#21457;&#30340;&#26395;&#36828;&#38236;&#23494;&#24230;&#27604;&#20272;&#35745;&#20013;&#65288;DRE&#65289;&#65292;&#23427;&#38656;&#35201;&#26500;&#24314;&#20013;&#38388;&#23494;&#24230;&#20197;&#22312;P&#21644;Q&#20043;&#38388;&#24314;&#31435;&#26725;&#26753;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36825;&#26679;&#30340;&#8220;Q-malizing&#27969;&#8221;&#65292;&#36890;&#36807;&#31070;&#32463;ODE&#27169;&#22411;&#36827;&#34892;&#65292;&#35813;&#27169;&#22411;&#36890;&#36807;&#32463;&#39564;&#26679;&#26412;&#30340;&#21487;&#36870;&#20256;&#36755;&#20174;P&#21040;Q&#65288;&#21453;&#20043;&#20134;&#28982;&#65289;&#65292;&#24182;&#36890;&#36807;&#26368;&#23567;&#21270;&#20256;&#36755;&#25104;&#26412;&#36827;&#34892;&#27491;&#21017;&#21270;&#12290;&#35757;&#32451;&#22909;&#30340;&#27969;&#27169;&#22411;&#20351;&#25105;&#20204;&#33021;&#22815;&#27839;&#19982;&#26102;&#38388;&#21442;&#25968;&#21270;&#30340;log&#23494;&#24230;&#36827;&#34892;&#26080;&#31351;&#23567;DRE&#65292;&#36890;&#36807;&#35757;&#32451;&#38468;&#21152;&#30340;&#36830;&#32493;&#26102;&#38388;&#27969;&#32593;&#32476;&#20351;&#29992;&#20998;&#31867;&#25439;&#22833;&#26469;&#20272;&#35745;log&#23494;&#24230;&#30340;&#26102;&#38388;&#20559;&#23548;&#25968;&#12290;&#36890;&#36807;&#31215;&#20998;&#26102;&#38388;&#24471;&#20998;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Continuous normalizing flows are widely used in generative tasks, where a flow network transports from a data distribution $P$ to a normal distribution. A flow model that can transport from $P$ to an arbitrary $Q$, where both $P$ and $Q$ are accessible via finite samples, would be of various application interests, particularly in the recently developed telescoping density ratio estimation (DRE) which calls for the construction of intermediate densities to bridge between $P$ and $Q$. In this work, we propose such a ``Q-malizing flow'' by a neural-ODE model which is trained to transport invertibly from $P$ to $Q$ (and vice versa) from empirical samples and is regularized by minimizing the transport cost. The trained flow model allows us to perform infinitesimal DRE along the time-parametrized $\log$-density by training an additional continuous-time flow network using classification loss, which estimates the time-partial derivative of the $\log$-density. Integrating the time-score network
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;Riesz&#26680;&#23637;&#31034;&#20102;&#29983;&#25104;&#24335;&#20998;&#21106;MMD&#27969;&#30340;&#39640;&#25928;&#35745;&#31639;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#22823;&#35268;&#27169;&#24212;&#29992;&#20013;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2305.11463</link><description>&lt;p&gt;
&#21033;&#29992;Riesz&#26680;&#30340;&#29983;&#25104;&#24335;&#20998;&#21106;MMD&#27969;
&lt;/p&gt;
&lt;p&gt;
Generative Sliced MMD Flows with Riesz Kernels. (arXiv:2305.11463v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11463
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;Riesz&#26680;&#23637;&#31034;&#20102;&#29983;&#25104;&#24335;&#20998;&#21106;MMD&#27969;&#30340;&#39640;&#25928;&#35745;&#31639;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#22823;&#35268;&#27169;&#24212;&#29992;&#20013;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#35268;&#27169;&#35745;&#31639;&#20013;&#65292;&#26368;&#22823;&#24179;&#22343;&#24046;&#24322;&#24230;(MMD)&#27969;&#30340;&#35745;&#31639;&#25104;&#26412;&#24456;&#39640;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;Riesz&#26680;$K(x,y)=-\|x-y\|^r$&#65292;$r \in (0,2)$&#30340;MMD&#27969;&#20855;&#26377;&#26480;&#20986;&#30340;&#24615;&#36136;&#65292;&#21487;&#20801;&#35768;&#20854;&#36827;&#34892;&#39640;&#25928;&#35745;&#31639;&#12290;&#39318;&#20808;&#65292;Riesz&#26680;&#30340;MMD&#19982;&#20854;&#20998;&#21106;&#29256;&#26412;&#30340;MMD&#37325;&#21512;&#12290;&#22240;&#27492;&#65292;&#21487;&#20197;&#22312;&#19968;&#32500;&#35774;&#32622;&#20013;&#36827;&#34892;MMD&#26799;&#24230;&#30340;&#35745;&#31639;&#12290;&#22312;&#27492;&#22788;&#65292;&#23545;&#20110;$r=1$&#65292;&#21487;&#20197;&#24212;&#29992;&#31616;&#21333;&#30340;&#25490;&#24207;&#31639;&#27861;&#23558;&#20004;&#20010;&#32463;&#39564;&#24230;&#37327;&#30340;&#22797;&#26434;&#24230;&#20174;$O(MN+N^2)$&#38477;&#20302;&#21040;$O((M+N)\log(M+N))$&#65292;&#20854;&#20013;$M$&#21644;$N$&#26159;&#25903;&#25345;&#28857;&#12290;&#23545;&#20110;&#23454;&#29616;&#65292;&#25105;&#20204;&#36890;&#36807;&#20165;&#20351;&#29992;&#26377;&#38480;&#25968;&#37327;&#30340;$P$&#20010;&#20999;&#29255;&#26469;&#36817;&#20284;&#20998;&#21106;MMD&#30340;&#26799;&#24230;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#30001;&#27492;&#20135;&#29983;&#30340;&#35823;&#24046;&#20855;&#26377;$O(\sqrt{d/P})$&#30340;&#22797;&#26434;&#24230;&#65292;&#20854;&#20013;$d$&#26159;&#25968;&#25454;&#32500;&#24230;&#12290;&#36825;&#20123;&#32467;&#26524;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;MMD&#26799;&#24230;&#27969;&#26469;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#65292;&#29978;&#33267;&#29992;&#20110;&#22823;&#35268;&#27169;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Maximum mean discrepancy (MMD) flows suffer from high computational costs in large scale computations. In this paper, we show that MMD flows with Riesz kernels $K(x,y) = - \|x-y\|^r$, $r \in (0,2)$ have exceptional properties which allow for their efficient computation. First, the MMD of Riesz kernels coincides with the MMD of their sliced version. As a consequence, the computation of gradients of MMDs can be performed in the one-dimensional setting. Here, for $r=1$, a simple sorting algorithm can be applied to reduce the complexity from $O(MN+N^2)$ to $O((M+N)\log(M+N))$ for two empirical measures with $M$ and $N$ support points. For the implementations we approximate the gradient of the sliced MMD by using only a finite number $P$ of slices. We show that the resulting error has complexity $O(\sqrt{d/P})$, where $d$ is the data dimension. These results enable us to train generative models by approximating MMD gradient flows by neural networks even for large scale applications. We demo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#29305;&#21035;&#20851;&#27880;&#20102;&#36755;&#20837;&#20998;&#24067;&#21644;&#26435;&#37325;&#30697;&#38453;&#30340;&#20551;&#35774;&#23545;&#23398;&#20064;&#31639;&#27861;&#26377;&#25928;&#24615;&#30340;&#24433;&#21709;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#39640;&#26031;&#36755;&#20837;&#20998;&#24067;&#19979;&#65292;&#23398;&#20064;&#28145;&#24230;&#20026;3&#30340;ReLU&#32593;&#32476;&#26159;&#22256;&#38590;&#30340;&#65292;&#21363;&#20351;&#26435;&#37325;&#30697;&#38453;&#26159;&#38750;&#36864;&#21270;&#30340;&#12290;&#21516;&#26102;&#65292;&#23398;&#20064;&#28145;&#24230;&#20026;2&#30340;&#32593;&#32476;&#20063;&#38754;&#20020;&#22256;&#38590;&#12290;</title><link>http://arxiv.org/abs/2302.07426</link><description>&lt;p&gt;
&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;: &#20809;&#28369;&#24615;&#21644;&#36864;&#21270;&#24615;
&lt;/p&gt;
&lt;p&gt;
Computational Complexity of Learning Neural Networks: Smoothness and Degeneracy. (arXiv:2302.07426v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07426
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#29305;&#21035;&#20851;&#27880;&#20102;&#36755;&#20837;&#20998;&#24067;&#21644;&#26435;&#37325;&#30697;&#38453;&#30340;&#20551;&#35774;&#23545;&#23398;&#20064;&#31639;&#27861;&#26377;&#25928;&#24615;&#30340;&#24433;&#21709;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#39640;&#26031;&#36755;&#20837;&#20998;&#24067;&#19979;&#65292;&#23398;&#20064;&#28145;&#24230;&#20026;3&#30340;ReLU&#32593;&#32476;&#26159;&#22256;&#38590;&#30340;&#65292;&#21363;&#20351;&#26435;&#37325;&#30697;&#38453;&#26159;&#38750;&#36864;&#21270;&#30340;&#12290;&#21516;&#26102;&#65292;&#23398;&#20064;&#28145;&#24230;&#20026;2&#30340;&#32593;&#32476;&#20063;&#38754;&#20020;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#20309;&#26102;&#21487;&#20197;&#34987;&#26377;&#25928;&#23398;&#20064;&#26159;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#12290;&#24050;&#26377;&#30340;&#38590;&#24230;&#32467;&#26524;&#34920;&#26126;&#65292;&#23545;&#36755;&#20837;&#20998;&#24067;&#21644;&#32593;&#32476;&#26435;&#37325;&#37117;&#38656;&#35201;&#20570;&#20986;&#19968;&#23450;&#30340;&#20551;&#35774;&#25165;&#33021;&#24471;&#21040;&#26377;&#25928;&#30340;&#31639;&#27861;&#12290;&#27492;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#34920;&#26126;&#65292;&#20551;&#35774;&#36755;&#20837;&#20998;&#24067;&#20026;&#39640;&#26031;&#20998;&#24067;&#19988;&#26435;&#37325;&#30697;&#38453;&#38750;&#36864;&#21270;&#26102;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#23398;&#20064;&#28145;&#24230;&#20026;2&#30340;&#32593;&#32476;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#36825;&#20123;&#20551;&#35774;&#26159;&#21542;&#36866;&#29992;&#20110;&#23398;&#20064;&#26356;&#28145;&#30340;&#32593;&#32476;&#65292;&#24182;&#32473;&#20986;&#20102;&#21542;&#23450;&#30340;&#32467;&#35770;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#20809;&#28369;&#20998;&#26512;&#26694;&#26550;&#19979;&#65292;&#21363;&#22312;&#32593;&#32476;&#21442;&#25968;&#20013;&#21152;&#20837;&#38543;&#26426;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65292;&#23398;&#20064;&#28145;&#24230;&#20026;3&#30340;ReLU&#32593;&#32476;&#22312;&#39640;&#26031;&#36755;&#20837;&#20998;&#24067;&#19979;&#26159;&#22256;&#38590;&#30340;&#12290;&#36825;&#24847;&#21619;&#30528;&#65292;&#21363;&#20351;&#26435;&#37325;&#30697;&#38453;&#26159;&#38750;&#36864;&#21270;&#30340;&#65292;&#23398;&#20064;&#28145;&#24230;&#20026;3&#30340;ReLU&#32593;&#32476;&#22312;&#39640;&#26031;&#20998;&#24067;&#19979;&#20063;&#26159;&#22256;&#38590;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#32771;&#34385;&#20102;&#28145;&#24230;&#20026;2&#30340;&#32593;&#32476;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#20809;&#28369;&#20998;&#26512;&#26694;&#26550;&#19979;&#23398;&#20064;&#30340;&#22256;&#38590;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding when neural networks can be learned efficiently is a fundamental question in learning theory. Existing hardness results suggest that assumptions on both the input distribution and the network's weights are necessary for obtaining efficient algorithms. Moreover, it was previously shown that depth-$2$ networks can be efficiently learned under the assumptions that the input distribution is Gaussian, and the weight matrix is non-degenerate. In this work, we study whether such assumptions may suffice for learning deeper networks and prove negative results. We show that learning depth-$3$ ReLU networks under the Gaussian input distribution is hard even in the smoothed-analysis framework, where a random noise is added to the network's parameters. It implies that learning depth-$3$ ReLU networks under the Gaussian distribution is hard even if the weight matrices are non-degenerate. Moreover, we consider depth-$2$ networks, and show hardness of learning in the smoothed-analysis fr
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24322;&#27493;&#26356;&#26032;&#19979;&#30340;&#20010;&#24615;&#21270;&#32852;&#37030;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#20010;&#24615;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#31227;&#38500;&#21516;&#27493;&#36890;&#20449;&#20551;&#35774;&#21644;&#21435;&#38500;&#26799;&#24230;&#33539;&#25968;&#26377;&#30028;&#24615;&#20551;&#35774;&#26469;&#25552;&#39640;&#21487;&#20280;&#32553;&#24615;&#12290;</title><link>http://arxiv.org/abs/2210.01176</link><description>&lt;p&gt;
PersA-FL&#65306;&#20010;&#24615;&#21270;&#24322;&#27493;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
PersA-FL: Personalized Asynchronous Federated Learning. (arXiv:2210.01176v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.01176
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24322;&#27493;&#26356;&#26032;&#19979;&#30340;&#20010;&#24615;&#21270;&#32852;&#37030;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#20010;&#24615;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#31227;&#38500;&#21516;&#27493;&#36890;&#20449;&#20551;&#35774;&#21644;&#21435;&#38500;&#26799;&#24230;&#33539;&#25968;&#26377;&#30028;&#24615;&#20551;&#35774;&#26469;&#25552;&#39640;&#21487;&#20280;&#32553;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#24322;&#27493;&#26356;&#26032;&#19979;&#30340;&#20010;&#24615;&#21270;&#32852;&#37030;&#23398;&#20064;&#38382;&#39064;&#12290;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#27599;&#20010;&#23458;&#25143;&#31471;&#37117;&#24076;&#26395;&#33719;&#24471;&#19968;&#20010;&#20010;&#24615;&#21270;&#27169;&#22411;&#65292;&#21516;&#26102;&#33021;&#22815;&#20248;&#20110;&#26412;&#22320;&#27169;&#22411;&#21644;&#20840;&#23616;&#27169;&#22411;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#20004;&#20010;&#22522;&#20110;&#20248;&#21270;&#30340;&#20010;&#24615;&#21270;&#26694;&#26550;&#65306;&#65288;i&#65289;&#27169;&#22411;&#26080;&#20851;&#20803;&#23398;&#20064;&#65288;MAML&#65289;&#21644;&#65288;ii&#65289;Moreau&#21253;&#32476;&#65288;ME&#65289;&#12290;MAML&#36890;&#36807;&#24494;&#35843;&#23398;&#20064;&#36866;&#24212;&#20110;&#27599;&#20010;&#23458;&#25143;&#31471;&#30340;&#32852;&#21512;&#27169;&#22411;&#65292;&#32780;ME&#36890;&#36807;&#38544;&#24335;&#26799;&#24230;&#30340;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#26469;&#36890;&#36807;&#35268;&#33539;&#21270;&#25439;&#22833;&#23454;&#29616;&#20010;&#24615;&#21270;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#25216;&#26415;&#36129;&#29486;&#26159;&#23545;&#26377;&#30028;&#28382;&#21518;&#30340;&#24322;&#27493;&#32852;&#37030;&#23398;&#20064;&#36827;&#34892;&#32479;&#19968;&#35777;&#26126;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;MAML&#21644;ME&#20010;&#24615;&#21270;&#26694;&#26550;&#12290;&#38024;&#23545;&#24179;&#28369;&#21644;&#38750;&#20984;&#20989;&#25968;&#31867;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25193;&#23637;&#20102;&#25152;&#30740;&#31350;&#30340;&#20989;&#25968;&#31867;&#65292;&#21435;&#38500;&#20102;&#26799;&#24230;&#33539;&#25968;&#30340;&#26377;&#30028;&#24615;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the personalized federated learning problem under asynchronous updates. In this problem, each client seeks to obtain a personalized model that simultaneously outperforms local and global models. We consider two optimization-based frameworks for personalization: (i) Model-Agnostic Meta-Learning (MAML) and (ii) Moreau Envelope (ME). MAML involves learning a joint model adapted for each client through fine-tuning, whereas ME requires a bi-level optimization problem with implicit gradients to enforce personalization via regularized losses. We focus on improving the scalability of personalized federated learning by removing the synchronous communication assumption. Moreover, we extend the studied function class by removing boundedness assumptions on the gradient norm. Our main technical contribution is a unified proof for asynchronous federated learning with bounded staleness that we apply to MAML and ME personalization frameworks. For the smooth and non-convex functions class, we 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24555;&#36895;&#12289;&#26080;&#38656;&#20284;&#28982;&#20989;&#25968;&#12289;&#26131;&#20110;&#36827;&#34892;&#22522;&#20110;&#33258;&#20030;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#25512;&#26029;&#24037;&#20855;&#8212;&#8212;&#31070;&#32463;&#28857;&#20272;&#35745;&#22120;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#26696;&#20363;&#20998;&#26512;&#35777;&#26126;&#20854;&#21487;&#20197;&#22312;&#24369;&#35782;&#21035;&#21644;&#39640;&#21442;&#25968;&#21270;&#27169;&#22411;&#20013;&#36827;&#34892;&#24555;&#36895;&#19988;&#26368;&#20248;&#30340;&#21442;&#25968;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2208.12942</link><description>&lt;p&gt;
&#24555;&#36895;&#26368;&#20248;&#26080;&#20284;&#28982;&#25512;&#26029;&#30340;&#31070;&#32463;&#28857;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Neural Point Estimation for Fast Optimal Likelihood-Free Inference. (arXiv:2208.12942v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.12942
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24555;&#36895;&#12289;&#26080;&#38656;&#20284;&#28982;&#20989;&#25968;&#12289;&#26131;&#20110;&#36827;&#34892;&#22522;&#20110;&#33258;&#20030;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#25512;&#26029;&#24037;&#20855;&#8212;&#8212;&#31070;&#32463;&#28857;&#20272;&#35745;&#22120;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#26696;&#20363;&#20998;&#26512;&#35777;&#26126;&#20854;&#21487;&#20197;&#22312;&#24369;&#35782;&#21035;&#21644;&#39640;&#21442;&#25968;&#21270;&#27169;&#22411;&#20013;&#36827;&#34892;&#24555;&#36895;&#19988;&#26368;&#20248;&#30340;&#21442;&#25968;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#28857;&#20272;&#35745;&#22120;&#26159;&#19968;&#31181;&#23558;&#25968;&#25454;&#26144;&#23556;&#21040;&#21442;&#25968;&#28857;&#20272;&#35745;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#23427;&#20204;&#24555;&#36895;&#12289;&#26080;&#38656;&#20284;&#28982;&#20989;&#25968;&#65292;&#24182;&#19988;&#30001;&#20110;&#23427;&#20204;&#30340;&#24179;&#22343;&#29305;&#24615;&#65292;&#26131;&#20110;&#36827;&#34892;&#22522;&#20110;&#33258;&#20030;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#26412;&#25991;&#26088;&#22312;&#25552;&#39640;&#32479;&#35745;&#23398;&#23478;&#23545;&#20110;&#36825;&#31181;&#30456;&#23545;&#36739;&#26032;&#30340;&#25512;&#26029;&#24037;&#20855;&#30340;&#35748;&#35782;&#65292;&#24182;&#36890;&#36807;&#25552;&#20379;&#29992;&#25143;&#21451;&#22909;&#30340;&#24320;&#28304;&#36719;&#20214;&#26469;&#20419;&#36827;&#20854;&#37319;&#29992;&#12290;&#25105;&#20204;&#36824;&#20851;&#27880;&#20102;&#20174;&#37325;&#22797;&#25968;&#25454;&#36827;&#34892;&#25512;&#26029;&#30340;&#24191;&#27867;&#38382;&#39064;&#65292;&#22312;&#31070;&#32463;&#35774;&#32622;&#20013;&#20351;&#29992;&#25490;&#21015;&#19981;&#21464;&#31070;&#32463;&#32593;&#32476;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#31070;&#32463;&#28857;&#20272;&#35745;&#22120;&#21487;&#20197;&#24555;&#36895;&#19988;&#26368;&#20248;&#22320;&#65288;&#20174;&#36125;&#21494;&#26031;&#24847;&#20041;&#19978;&#65289;&#22312;&#24369;&#35782;&#21035;&#21644;&#39640;&#21442;&#25968;&#21270;&#27169;&#22411;&#20013;&#36827;&#34892;&#20272;&#35745;&#65292;&#24182;&#19988;&#30456;&#23545;&#23481;&#26131;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#32418;&#28023;&#26497;&#31471;&#28023;&#34920;&#28201;&#24230;&#20998;&#26512;&#26469;&#35777;&#26126;&#23427;&#20204;&#30340;&#36866;&#29992;&#24615;&#65292;&#22312;&#35757;&#32451;&#20043;&#21518;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#21442;&#25968;&#20272;&#35745;&#21644;&#22522;&#20110;&#33258;&#20030;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural point estimators are neural networks that map data to parameter point estimates. They are fast, likelihood free and, due to their amortised nature, amenable to fast bootstrap-based uncertainty quantification. In this paper, we aim to increase the awareness of statisticians to this relatively new inferential tool, and to facilitate its adoption by providing user-friendly open-source software. We also give attention to the ubiquitous problem of making inference from replicated data, which we address in the neural setting using permutation-invariant neural networks. Through extensive simulation studies we show that these neural point estimators can quickly and optimally (in a Bayes sense) estimate parameters in weakly-identified and highly-parameterised models with relative ease. We demonstrate their applicability through an analysis of extreme sea-surface temperature in the Red Sea where, after training, we obtain parameter estimates and bootstrap-based confidence intervals from h
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20351;&#29992;&#26631;&#20934;&#21270;&#27969;&#26469;&#35299;&#20915;&#36880;&#28176;&#39046;&#22495;&#36866;&#24212;&#20013;&#20013;&#38388;&#22495;&#26377;&#38480;&#19988;&#36317;&#31163;&#36739;&#22823;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#20174;&#28304;&#22495;&#21040;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#23398;&#20064;&#30446;&#26631;&#22495;&#30340;&#20998;&#24067;&#21464;&#25442;&#12290;</title><link>http://arxiv.org/abs/2206.11492</link><description>&lt;p&gt;
&#36890;&#36807;&#26631;&#20934;&#21270;&#27969;&#36827;&#34892;&#36880;&#28176;&#39046;&#22495;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
Gradual Domain Adaptation via Normalizing Flows. (arXiv:2206.11492v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.11492
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20351;&#29992;&#26631;&#20934;&#21270;&#27969;&#26469;&#35299;&#20915;&#36880;&#28176;&#39046;&#22495;&#36866;&#24212;&#20013;&#20013;&#38388;&#22495;&#26377;&#38480;&#19988;&#36317;&#31163;&#36739;&#22823;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#20174;&#28304;&#22495;&#21040;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#23398;&#20064;&#30446;&#26631;&#22495;&#30340;&#20998;&#24067;&#21464;&#25442;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#20043;&#38388;&#23384;&#22312;&#36739;&#22823;&#24046;&#36317;&#26102;&#65292;&#20256;&#32479;&#30340;&#39046;&#22495;&#36866;&#24212;&#26041;&#27861;&#25928;&#26524;&#19981;&#20339;&#12290;&#36880;&#28176;&#39046;&#22495;&#36866;&#24212;&#26159;&#35299;&#20915;&#35813;&#38382;&#39064;&#30340;&#19968;&#31181;&#26041;&#27861;&#65292;&#23427;&#28041;&#21450;&#21033;&#29992;&#36880;&#28176;&#20174;&#28304;&#22495;&#36716;&#31227;&#21040;&#30446;&#26631;&#22495;&#30340;&#20013;&#38388;&#22495;&#12290;&#22312;&#20808;&#21069;&#30340;&#24037;&#20316;&#20013;&#65292;&#20551;&#35774;&#20013;&#38388;&#22495;&#30340;&#25968;&#37327;&#36739;&#22823;&#19988;&#30456;&#37051;&#22495;&#20043;&#38388;&#30340;&#36317;&#31163;&#36739;&#23567;&#65292;&#22240;&#27492;&#65292;&#28041;&#21450;&#20351;&#29992;&#26080;&#26631;&#31614;&#25968;&#25454;&#38598;&#36827;&#34892;&#33258;&#25105;&#35757;&#32451;&#30340;&#36880;&#28176;&#39046;&#22495;&#36866;&#24212;&#31639;&#27861;&#26159;&#21487;&#34892;&#30340;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#36880;&#28176;&#33258;&#25105;&#35757;&#32451;&#23558;&#22833;&#36133;&#65292;&#22240;&#20026;&#20013;&#38388;&#22495;&#30340;&#25968;&#37327;&#26377;&#38480;&#19988;&#30456;&#37051;&#22495;&#20043;&#38388;&#30340;&#36317;&#31163;&#36739;&#22823;&#12290;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#26631;&#20934;&#21270;&#27969;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#21516;&#26102;&#20445;&#25345;&#26080;&#30417;&#30563;&#39046;&#22495;&#36866;&#24212;&#30340;&#26694;&#26550;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#36890;&#36807;&#20174;&#28304;&#22495;&#21040;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#23398;&#20064;&#30446;&#26631;&#22495;&#30340;&#20998;&#24067;&#21464;&#25442;&#12290;
&lt;/p&gt;
&lt;p&gt;
Standard domain adaptation methods do not work well when a large gap exists between the source and target domains. Gradual domain adaptation is one of the approaches used to address the problem. It involves leveraging the intermediate domain, which gradually shifts from the source domain to the target domain. In previous work, it is assumed that the number of intermediate domains is large and the distance between adjacent domains is small; hence, the gradual domain adaptation algorithm, involving self-training with unlabeled datasets, is applicable. In practice, however, gradual self-training will fail because the number of intermediate domains is limited and the distance between adjacent domains is large. We propose the use of normalizing flows to deal with this problem while maintaining the framework of unsupervised domain adaptation. The proposed method learns a transformation from the distribution of the target domain to the Gaussian mixture distribution via the source domain. We e
&lt;/p&gt;</description></item><item><title>GFlowNets&#20351;&#29992;&#36712;&#36857;&#24179;&#34913;&#20316;&#20026;&#19968;&#31181;&#26356;&#39640;&#25928;&#30340;&#23398;&#20064;&#30446;&#26631;&#65292;&#35299;&#20915;&#20102;&#20808;&#21069;&#23398;&#20064;&#30446;&#26631;&#20013;&#20449;&#29992;&#20256;&#25773;&#25928;&#29575;&#20302;&#19979;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#20854;&#22312;&#25910;&#25947;&#24615;&#12289;&#29983;&#25104;&#26679;&#26412;&#22810;&#26679;&#24615;&#20197;&#21450;&#40065;&#26834;&#24615;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2201.13259</link><description>&lt;p&gt;
&#36712;&#36857;&#24179;&#34913;&#65306;&#25913;&#36827;&#20102;GFlowNets&#20013;&#30340;&#20449;&#29992;&#20998;&#37197;
&lt;/p&gt;
&lt;p&gt;
Trajectory balance: Improved credit assignment in GFlowNets. (arXiv:2201.13259v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.13259
&lt;/p&gt;
&lt;p&gt;
GFlowNets&#20351;&#29992;&#36712;&#36857;&#24179;&#34913;&#20316;&#20026;&#19968;&#31181;&#26356;&#39640;&#25928;&#30340;&#23398;&#20064;&#30446;&#26631;&#65292;&#35299;&#20915;&#20102;&#20808;&#21069;&#23398;&#20064;&#30446;&#26631;&#20013;&#20449;&#29992;&#20256;&#25773;&#25928;&#29575;&#20302;&#19979;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#20854;&#22312;&#25910;&#25947;&#24615;&#12289;&#29983;&#25104;&#26679;&#26412;&#22810;&#26679;&#24615;&#20197;&#21450;&#40065;&#26834;&#24615;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27969;&#32593;&#32476;&#65288;GFlowNets&#65289;&#26159;&#19968;&#31181;&#23398;&#20064;&#20351;&#29992;&#21160;&#20316;&#24207;&#21015;&#29983;&#25104;&#32452;&#21512;&#23545;&#35937;&#65288;&#22914;&#22270;&#24418;&#25110;&#23383;&#31526;&#20018;&#65289;&#30340;&#38543;&#26426;&#31574;&#30053;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#35768;&#22810;&#21487;&#33021;&#30340;&#21160;&#20316;&#24207;&#21015;&#21487;&#33021;&#23548;&#33268;&#30456;&#21516;&#30340;&#23545;&#35937;&#12290;&#25105;&#20204;&#21457;&#29616;&#20808;&#21069;&#25552;&#20986;&#30340;GFlowNets&#23398;&#20064;&#30446;&#26631;&#65292;&#21363;&#27969;&#21305;&#37197;&#21644;&#35814;&#32454;&#24179;&#34913;&#65292;&#31867;&#20284;&#20110;&#26102;&#38388;&#24046;&#20998;&#23398;&#20064;&#65292;&#23481;&#26131;&#22312;&#38271;&#30340;&#21160;&#20316;&#24207;&#21015;&#20013;&#20986;&#29616;&#20449;&#29992;&#20256;&#25773;&#25928;&#29575;&#20302;&#19979;&#30340;&#38382;&#39064;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23398;&#20064;&#30446;&#26631;&#65292;&#21363;&#36712;&#36857;&#24179;&#34913;&#65292;&#20316;&#20026;&#20808;&#21069;&#20351;&#29992;&#30446;&#26631;&#30340;&#26356;&#39640;&#25928;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36712;&#36857;&#24179;&#34913;&#30446;&#26631;&#30340;&#20219;&#20309;&#20840;&#23616;&#26497;&#23567;&#20540;&#21487;&#20197;&#23450;&#20041;&#19968;&#20010;&#20174;&#30446;&#26631;&#20998;&#24067;&#31934;&#30830;&#37319;&#26679;&#30340;&#31574;&#30053;&#12290;&#22312;&#22235;&#20010;&#19981;&#21516;&#39046;&#22495;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#20174;&#23454;&#35777;&#19978;&#35777;&#26126;&#20102;&#36712;&#36857;&#24179;&#34913;&#30446;&#26631;&#23545;&#20110;GFlowNet&#25910;&#25947;&#24615;&#12289;&#29983;&#25104;&#26679;&#26412;&#30340;&#22810;&#26679;&#24615;&#20197;&#21450;&#23545;&#38271;&#21160;&#20316;&#24207;&#21015;&#21644;&#22122;&#22768;&#30340;&#40065;&#26834;&#24615;&#30340;&#30410;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative flow networks (GFlowNets) are a method for learning a stochastic policy for generating compositional objects, such as graphs or strings, from a given unnormalized density by sequences of actions, where many possible action sequences may lead to the same object. We find previously proposed learning objectives for GFlowNets, flow matching and detailed balance, which are analogous to temporal difference learning, to be prone to inefficient credit propagation across long action sequences. We thus propose a new learning objective for GFlowNets, trajectory balance, as a more efficient alternative to previously used objectives. We prove that any global minimizer of the trajectory balance objective can define a policy that samples exactly from the target distribution. In experiments on four distinct domains, we empirically demonstrate the benefits of the trajectory balance objective for GFlowNet convergence, diversity of generated samples, and robustness to long action sequences and
&lt;/p&gt;</description></item><item><title>&#22312;&#32447;LQR&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22825;&#30495;&#30340;&#25506;&#32034;&#26159;&#26368;&#20248;&#30340;&#31574;&#30053;&#65292;&#21487;&#20197;&#22312;&#26410;&#30693;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#36798;&#21040;&#26368;&#23567;&#36951;&#25022;&#12290;&#36825;&#19968;&#32467;&#35770;&#23545;&#20110;&#35299;&#20915;&#22312;&#32447;&#33258;&#36866;&#24212;&#25511;&#21046;&#38382;&#39064;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2001.09576</link><description>&lt;p&gt;
Naive Exploration is Optimal for Online LQR&#65288;&#22312;&#32447;LQR&#38382;&#39064;&#20013;&#65292;&#22825;&#30495;&#30340;&#25506;&#32034;&#26159;&#26368;&#20248;&#30340;&#65289;
&lt;/p&gt;
&lt;p&gt;
Naive Exploration is Optimal for Online LQR. (arXiv:2001.09576v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2001.09576
&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;LQR&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22825;&#30495;&#30340;&#25506;&#32034;&#26159;&#26368;&#20248;&#30340;&#31574;&#30053;&#65292;&#21487;&#20197;&#22312;&#26410;&#30693;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#36798;&#21040;&#26368;&#23567;&#36951;&#25022;&#12290;&#36825;&#19968;&#32467;&#35770;&#23545;&#20110;&#35299;&#20915;&#22312;&#32447;&#33258;&#36866;&#24212;&#25511;&#21046;&#38382;&#39064;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#20108;&#27425;&#35843;&#33410;&#22120;&#22312;&#32447;&#33258;&#36866;&#24212;&#25511;&#21046;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#30495;&#23454;&#31995;&#32479;&#21442;&#25968;&#26159;&#26410;&#30693;&#30340;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#26032;&#30340;&#19978;&#19979;&#30028;&#65292;&#34920;&#26126;&#26368;&#20248;&#36951;&#25022;&#30340;&#23610;&#24230;&#19982;$\widetilde{\Theta}({\sqrt{d_{\mathbf{u}}^2 d_{\mathbf{x}} T}})$&#25104;&#27491;&#27604;&#65292;&#20854;&#20013;$T$&#26159;&#26102;&#38388;&#27493;&#25968;&#65292;$d_{\mathbf{u}}$&#26159;&#36755;&#20837;&#31354;&#38388;&#30340;&#32500;&#24230;&#65292;$d_{\mathbf{x}}$&#26159;&#31995;&#32479;&#29366;&#24577;&#30340;&#32500;&#24230;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#19979;&#30028;&#25490;&#38500;&#20102;&#21487;&#33021;&#23384;&#22312;&#30340;$\mathrm{poly}(\log{}T)$&#36951;&#25022;&#31639;&#27861;&#30340;&#21487;&#33021;&#24615;&#65292;&#36825;&#26159;&#30001;&#20110;&#38382;&#39064;&#26126;&#26174;&#30340;&#24378;&#20984;&#24615;&#24341;&#20986;&#30340;&#29468;&#24819;&#12290;&#25105;&#20204;&#30340;&#19978;&#30028;&#36890;&#36807;&#19968;&#31181;&#31616;&#21333;&#30340;$\textit{{&#30830;&#23450;&#24615;&#31561;&#20215;&#25511;&#21046;}}$&#30340;&#21464;&#20307;&#24471;&#21040;&#65292;&#20854;&#20013;&#23398;&#20064;&#32773;&#26681;&#25454;&#23545;&#31995;&#32479;&#30340;&#20272;&#35745;&#36873;&#25321;&#25511;&#21046;&#36755;&#20837;&#65292;&#24182;&#27880;&#20837;&#25506;&#32034;&#24615;&#30340;&#38543;&#26426;&#22122;&#22768;&#12290;&#34429;&#28982;&#36825;&#31181;&#26041;&#27861;&#24050;&#32463;&#34987;&#35777;&#26126;&#21487;&#20197;&#23454;&#29616;$\sqrt{T}$&#30340;&#36951;&#25022;(Raina et al. 2019)&#65292;&#20294;&#25105;&#20204;&#34920;&#26126;&#65292;&#22914;&#26524;&#23398;&#20064;&#32773;&#19981;&#26029;&#25913;&#36827;&#20182;&#20204;&#30340;&#20272;&#35745;&#65292;&#25214;&#21040;&#20102;&#31995;&#32479;&#30340;&#30495;&#23454;&#21442;&#25968;&#65292;&#21017;&#21487;&#20197;&#23454;&#29616;&#38646;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of online adaptive control of the linear quadratic regulator, where the true system parameters are unknown. We prove new upper and lower bounds demonstrating that the optimal regret scales as $\widetilde{\Theta}({\sqrt{d_{\mathbf{u}}^2 d_{\mathbf{x}} T}})$, where $T$ is the number of time steps, $d_{\mathbf{u}}$ is the dimension of the input space, and $d_{\mathbf{x}}$ is the dimension of the system state. Notably, our lower bounds rule out the possibility of a $\mathrm{poly}(\log{}T)$-regret algorithm, which had been conjectured due to the apparent strong convexity of the problem. Our upper bound is attained by a simple variant of $\textit{{certainty equivalent control}}$, where the learner selects control inputs according to the optimal controller for their estimate of the system while injecting exploratory random noise. While this approach was shown to achieve $\sqrt{T}$-regret by (Mania et al. 2019), we show that if the learner continually refines their esti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#32500;ReLU&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#25968;&#23398;&#20998;&#26512;&#21644;&#23454;&#39564;&#35777;&#26126;&#20102;&#23545;&#20110;&#36825;&#31181;&#32593;&#32476;&#65292;L2&#27491;&#21017;&#21270;&#22238;&#24402;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#23545;&#24212;&#20110;&#23545;&#20272;&#35745;&#30340;&#20108;&#38454;&#23548;&#25968;&#36827;&#34892;&#27491;&#21017;&#21270;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#26089;&#20572;&#27490;&#30340;&#26799;&#24230;&#19979;&#38477;&#21644;&#24179;&#28369;&#26679;&#26465;&#22238;&#24402;&#20043;&#38388;&#30340;&#26032;&#23545;&#24212;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/1911.02903</link><description>&lt;p&gt;
&#38544;&#24335;&#27491;&#21017;&#21270;ReLU&#31070;&#32463;&#32593;&#32476;&#22914;&#20309;&#21051;&#30011;&#23398;&#20064;&#20989;&#25968; - &#31532;&#19968;&#37096;&#20998;&#65306;&#38543;&#26426;&#31532;&#19968;&#23618;&#30340;&#20004;&#23618;&#19968;&#32500;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
How Implicit Regularization of ReLU Neural Networks Characterizes the Learned Function -- Part I: the 1-D Case of Two Layers with Random First Layer. (arXiv:1911.02903v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1911.02903
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#32500;ReLU&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#25968;&#23398;&#20998;&#26512;&#21644;&#23454;&#39564;&#35777;&#26126;&#20102;&#23545;&#20110;&#36825;&#31181;&#32593;&#32476;&#65292;L2&#27491;&#21017;&#21270;&#22238;&#24402;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#23545;&#24212;&#20110;&#23545;&#20272;&#35745;&#30340;&#20108;&#38454;&#23548;&#25968;&#36827;&#34892;&#27491;&#21017;&#21270;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#26089;&#20572;&#27490;&#30340;&#26799;&#24230;&#19979;&#38477;&#21644;&#24179;&#28369;&#26679;&#26465;&#22238;&#24402;&#20043;&#38388;&#30340;&#26032;&#23545;&#24212;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#32500;&#65288;&#27973;&#23618;&#65289;ReLU&#31070;&#32463;&#32593;&#32476;&#65292;&#20854;&#20013;&#26435;&#37325;&#26159;&#38543;&#26426;&#36873;&#25321;&#30340;&#65292;&#21482;&#26377;&#32456;&#31471;&#23618;&#36827;&#34892;&#35757;&#32451;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20174;&#25968;&#23398;&#19978;&#35777;&#26126;&#20102;&#23545;&#20110;&#36825;&#31181;&#32593;&#32476;&#65292;L2&#27491;&#21017;&#21270;&#22238;&#24402;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#23545;&#24212;&#20110;&#23545;&#20272;&#35745;&#30340;&#20108;&#38454;&#23548;&#25968;&#36827;&#34892;&#27491;&#21017;&#21270;&#65292;&#36866;&#29992;&#20110;&#30456;&#24403;&#19968;&#33324;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#23545;&#20110;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35757;&#32451;&#22909;&#30340;&#32593;&#32476;&#22312;&#38544;&#34255;&#33410;&#28857;&#25968;&#36235;&#21521;&#26080;&#31351;&#26102;&#25910;&#25947;&#21040;&#35757;&#32451;&#25968;&#25454;&#30340;&#24179;&#28369;&#26679;&#26465;&#25554;&#20540;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#26089;&#20572;&#27490;&#30340;&#26799;&#24230;&#19979;&#38477;&#65288;&#27809;&#26377;&#23545;&#26435;&#37325;&#36827;&#34892;&#26174;&#24335;&#27491;&#21017;&#21270;&#65289;&#19982;&#24179;&#28369;&#26679;&#26465;&#22238;&#24402;&#20043;&#38388;&#30340;&#26032;&#23545;&#24212;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider one dimensional (shallow) ReLU neural networks in which weights are chosen randomly and only the terminal layer is trained. First, we mathematically show that for such networks L2-regularized regression corresponds in function space to regularizing the estimate's second derivative for fairly general loss functionals. For least squares regression, we show that the trained network converges to the smooth spline interpolation of the training data as the number of hidden nodes tends to infinity. Moreover, we derive a novel correspondence between the early stopped gradient descent (without any explicit regularization of the weights) and the smoothing spline regression.
&lt;/p&gt;</description></item></channel></rss>