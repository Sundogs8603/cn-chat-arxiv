<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19978;&#19979;&#25991;&#21270;&#25919;&#31574;&#24674;&#22797;&#26041;&#27861;&#29992;&#20110;&#24314;&#27169;&#22797;&#26434;&#30340;&#21307;&#30103;&#20915;&#31574;&#36807;&#31243;&#65292;&#20197;&#35299;&#20915;&#29616;&#26377;&#27169;&#22411;&#22312;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#23558;&#20915;&#31574;&#31574;&#30053;&#25286;&#20998;&#20026;&#19978;&#19979;&#25991;&#29305;&#23450;&#31574;&#30053;&#65292;&#36890;&#36807;&#22810;&#20219;&#21153;&#23398;&#20064;&#26469;&#23454;&#29616;&#24314;&#27169;&#65292;&#24182;&#25552;&#20379;&#22797;&#26434;&#34892;&#20026;&#30340;&#31616;&#27905;&#25551;&#36848;&#12290;</title><link>http://arxiv.org/abs/2310.07918</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#21270;&#25919;&#31574;&#24674;&#22797;&#65306;&#36890;&#36807;&#33258;&#36866;&#24212;&#27169;&#20223;&#23398;&#20064;&#23545;&#21307;&#30103;&#20915;&#31574;&#36827;&#34892;&#24314;&#27169;&#21644;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Contextualized Policy Recovery: Modeling and Interpreting Medical Decisions with Adaptive Imitation Learning. (arXiv:2310.07918v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07918
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19978;&#19979;&#25991;&#21270;&#25919;&#31574;&#24674;&#22797;&#26041;&#27861;&#29992;&#20110;&#24314;&#27169;&#22797;&#26434;&#30340;&#21307;&#30103;&#20915;&#31574;&#36807;&#31243;&#65292;&#20197;&#35299;&#20915;&#29616;&#26377;&#27169;&#22411;&#22312;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#23558;&#20915;&#31574;&#31574;&#30053;&#25286;&#20998;&#20026;&#19978;&#19979;&#25991;&#29305;&#23450;&#31574;&#30053;&#65292;&#36890;&#36807;&#22810;&#20219;&#21153;&#23398;&#20064;&#26469;&#23454;&#29616;&#24314;&#27169;&#65292;&#24182;&#25552;&#20379;&#22797;&#26434;&#34892;&#20026;&#30340;&#31616;&#27905;&#25551;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#31574;&#30053;&#23398;&#20064;&#26088;&#22312;&#20174;&#35266;&#23519;&#21040;&#30340;&#34892;&#20026;&#20013;&#20272;&#35745;&#21487;&#29702;&#35299;&#30340;&#20915;&#31574;&#31574;&#30053;&#65307;&#28982;&#32780;&#65292;&#29616;&#26377;&#27169;&#22411;&#22312;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#20043;&#38388;&#23384;&#22312;&#26435;&#34913;&#12290;&#36825;&#31181;&#26435;&#34913;&#38480;&#21046;&#20102;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#23545;&#20154;&#31867;&#20915;&#31574;&#36807;&#31243;&#30340;&#35299;&#37322;&#65292;&#20363;&#22914;&#65292;&#23457;&#35745;&#21307;&#30103;&#20915;&#31574;&#30340;&#20559;&#35265;&#21644;&#27425;&#20248;&#23454;&#36341;&#65292;&#25105;&#20204;&#38656;&#35201;&#20915;&#31574;&#36807;&#31243;&#30340;&#27169;&#22411;&#65292;&#33021;&#22815;&#25552;&#20379;&#22797;&#26434;&#34892;&#20026;&#30340;&#31616;&#27905;&#25551;&#36848;&#12290;&#29616;&#26377;&#26041;&#27861;&#22522;&#26412;&#19978;&#30001;&#20110;&#23558;&#28508;&#22312;&#20915;&#31574;&#36807;&#31243;&#34920;&#31034;&#20026;&#36890;&#29992;&#31574;&#30053;&#32780;&#36127;&#25285;&#20102;&#36825;&#31181;&#26435;&#34913;&#65292;&#32780;&#23454;&#38469;&#19978;&#20154;&#31867;&#20915;&#31574;&#26159;&#21160;&#24577;&#30340;&#65292;&#21487;&#20197;&#38543;&#19978;&#19979;&#25991;&#20449;&#24687;&#32780;&#22823;&#24133;&#25913;&#21464;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19978;&#19979;&#25991;&#21270;&#25919;&#31574;&#24674;&#22797;&#65288;CPR&#65289;&#65292;&#23558;&#24314;&#27169;&#22797;&#26434;&#20915;&#31574;&#36807;&#31243;&#30340;&#38382;&#39064;&#37325;&#26032;&#23450;&#20041;&#20026;&#22810;&#20219;&#21153;&#23398;&#20064;&#38382;&#39064;&#65292;&#20854;&#20013;&#22797;&#26434;&#20915;&#31574;&#31574;&#30053;&#30001;&#29305;&#23450;&#19978;&#19979;&#25991;&#30340;&#31574;&#30053;&#32452;&#25104;&#12290;CPR&#23558;&#27599;&#20010;&#19978;&#19979;&#25991;&#29305;&#23450;&#31574;&#30053;&#24314;&#27169;&#20026;&#32447;&#24615;&#30340;&#35266;&#23519;-&#21160;&#20316;&#26144;&#23556;
&lt;/p&gt;
&lt;p&gt;
Interpretable policy learning seeks to estimate intelligible decision policies from observed actions; however, existing models fall short by forcing a tradeoff between accuracy and interpretability. This tradeoff limits data-driven interpretations of human decision-making process. e.g. to audit medical decisions for biases and suboptimal practices, we require models of decision processes which provide concise descriptions of complex behaviors. Fundamentally, existing approaches are burdened by this tradeoff because they represent the underlying decision process as a universal policy, when in fact human decisions are dynamic and can change drastically with contextual information. Thus, we propose Contextualized Policy Recovery (CPR), which re-frames the problem of modeling complex decision processes as a multi-task learning problem in which complex decision policies are comprised of context-specific policies. CPR models each context-specific policy as a linear observation-to-action mapp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#32593;&#32476;&#22823;&#23567;&#21644;L2&#27491;&#21017;&#21270;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#35266;&#23519;&#21040;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#12290;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#29305;&#24449;&#21644;&#25042;&#24816;&#35757;&#32451;&#31574;&#30053;&#65292;&#22312;&#21442;&#25968;&#21644;&#29366;&#24577;&#25968;&#26080;&#38480;&#22823;&#30340;&#24773;&#20917;&#19979;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#30340;&#26368;&#23567;&#20108;&#20056;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;&#65292;&#24471;&#20986;&#20102;&#20854;&#25910;&#25947;&#24615;&#21644;&#26368;&#20248;&#24615;&#65292;&#24182;&#38416;&#36848;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#22312;&#35813;&#31639;&#27861;&#20013;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.05518</link><description>&lt;p&gt;
&#20851;&#20110;&#20351;&#29992;LSTD&#21644;&#38543;&#26426;&#29305;&#24449;&#30340;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#21452;&#19979;&#38477;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
On Double-Descent in Reinforcement Learning with LSTD and Random Features. (arXiv:2310.05518v1 [cs.LG] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05518
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#32593;&#32476;&#22823;&#23567;&#21644;L2&#27491;&#21017;&#21270;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#35266;&#23519;&#21040;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#12290;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#29305;&#24449;&#21644;&#25042;&#24816;&#35757;&#32451;&#31574;&#30053;&#65292;&#22312;&#21442;&#25968;&#21644;&#29366;&#24577;&#25968;&#26080;&#38480;&#22823;&#30340;&#24773;&#20917;&#19979;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#30340;&#26368;&#23567;&#20108;&#20056;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;&#65292;&#24471;&#20986;&#20102;&#20854;&#25910;&#25947;&#24615;&#21644;&#26368;&#20248;&#24615;&#65292;&#24182;&#38416;&#36848;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#22312;&#35813;&#31639;&#27861;&#20013;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;&#22312;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20854;&#24615;&#33021;&#21463;&#31070;&#32463;&#32593;&#32476;&#22823;&#23567;&#30340;&#24433;&#21709;&#12290;&#28982;&#32780;&#65292;&#22312;&#30417;&#30563;&#23398;&#20064;&#20013;&#36807;&#21442;&#25968;&#21270;&#21644;&#20854;&#24102;&#26469;&#30340;&#22909;&#22788;&#24050;&#32463;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#29702;&#35299;&#65292;&#20294;&#26159;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#24773;&#20917;&#21017;&#19981;&#22826;&#28165;&#26970;&#12290;&#26412;&#25991;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#25506;&#35752;&#20102;&#32593;&#32476;&#22823;&#23567;&#21644;L2&#27491;&#21017;&#21270;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#23558;&#21442;&#25968;&#20010;&#25968;&#19982;&#35775;&#38382;&#29366;&#24577;&#20010;&#25968;&#20043;&#27604;&#23450;&#20041;&#20026;&#20851;&#38190;&#22240;&#32032;&#65292;&#24403;&#35813;&#27604;&#20540;&#22823;&#20110;1&#26102;&#31216;&#20026;&#36807;&#21442;&#25968;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#65292;&#21363;&#22312;&#21442;&#25968;/&#29366;&#24577;&#27604;&#20026;1&#38468;&#36817;&#20250;&#31361;&#28982;&#24615;&#33021;&#19979;&#38477;&#12290;&#36890;&#36807;&#21033;&#29992;&#38543;&#26426;&#29305;&#24449;&#21644;&#25042;&#24816;&#35757;&#32451;&#31574;&#30053;&#65292;&#25105;&#20204;&#22312;&#26080;&#38480;&#22823;&#30340;&#21442;&#25968;&#21644;&#29366;&#24577;&#25968;&#19979;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#30340;&#26368;&#23567;&#20108;&#20056;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#20854;&#25910;&#25947;&#24615;&#21644;&#26368;&#20248;&#24615;&#65292;&#24182;&#38416;&#36848;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#22312;&#35813;&#31639;&#27861;&#20013;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Temporal Difference (TD) algorithms are widely used in Deep Reinforcement Learning (RL). Their performance is heavily influenced by the size of the neural network. While in supervised learning, the regime of over-parameterization and its benefits are well understood, the situation in RL is much less clear. In this paper, we present a theoretical analysis of the influence of network size and $l_2$-regularization on performance. We identify the ratio between the number of parameters and the number of visited states as a crucial factor and define over-parameterization as the regime when it is larger than one. Furthermore, we observe a double-descent phenomenon, i.e., a sudden drop in performance around the parameter/state ratio of one. Leveraging random features and the lazy training regime, we study the regularized Least-Square Temporal Difference (LSTD) algorithm in an asymptotic regime, as both the number of parameters and states go to infinity, maintaining a constant ratio. We derive 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#31232;&#30095;&#30340;&#29616;&#20195; Hopfield &#27169;&#22411;&#65292;&#36890;&#36807;&#24341;&#20837;&#31232;&#30095;&#33021;&#37327;&#20989;&#25968;&#21644;&#31232;&#30095;&#35760;&#24518;&#26816;&#32034;&#21160;&#21147;&#23398;&#65292;&#23454;&#29616;&#20102;&#23545;&#31232;&#30095;&#27880;&#24847;&#26426;&#21046;&#30340;&#19968;&#27493;&#36817;&#20284;&#12290;&#30456;&#27604;&#23494;&#38598;&#27169;&#22411;&#65292;&#31232;&#30095;&#27169;&#22411;&#30340;&#35760;&#24518;&#26816;&#32034;&#35823;&#24046;&#19978;&#30028;&#26356;&#32039;&#20945;&#65292;&#20855;&#26377;&#26126;&#30830;&#30340;&#31232;&#30095;&#20248;&#21183;&#26465;&#20214;&#12290;&#21516;&#26102;&#65292;&#31232;&#30095;&#30340;&#29616;&#20195; Hopfield &#27169;&#22411;&#36824;&#20445;&#25345;&#20102;&#20854;&#23494;&#38598;&#23545;&#24212;&#29289;&#30340;&#31283;&#20581;&#29702;&#35770;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2309.12673</link><description>&lt;p&gt;
&#20851;&#20110;&#31232;&#30095;&#30340;&#29616;&#20195; Hopfield &#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
On Sparse Modern Hopfield Model. (arXiv:2309.12673v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12673
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#31232;&#30095;&#30340;&#29616;&#20195; Hopfield &#27169;&#22411;&#65292;&#36890;&#36807;&#24341;&#20837;&#31232;&#30095;&#33021;&#37327;&#20989;&#25968;&#21644;&#31232;&#30095;&#35760;&#24518;&#26816;&#32034;&#21160;&#21147;&#23398;&#65292;&#23454;&#29616;&#20102;&#23545;&#31232;&#30095;&#27880;&#24847;&#26426;&#21046;&#30340;&#19968;&#27493;&#36817;&#20284;&#12290;&#30456;&#27604;&#23494;&#38598;&#27169;&#22411;&#65292;&#31232;&#30095;&#27169;&#22411;&#30340;&#35760;&#24518;&#26816;&#32034;&#35823;&#24046;&#19978;&#30028;&#26356;&#32039;&#20945;&#65292;&#20855;&#26377;&#26126;&#30830;&#30340;&#31232;&#30095;&#20248;&#21183;&#26465;&#20214;&#12290;&#21516;&#26102;&#65292;&#31232;&#30095;&#30340;&#29616;&#20195; Hopfield &#27169;&#22411;&#36824;&#20445;&#25345;&#20102;&#20854;&#23494;&#38598;&#23545;&#24212;&#29289;&#30340;&#31283;&#20581;&#29702;&#35770;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#31232;&#30095;&#30340;&#29616;&#20195; Hopfield &#27169;&#22411;&#20316;&#20026;&#29616;&#20195; Hopfield &#27169;&#22411;&#30340;&#19968;&#31181;&#25193;&#23637;&#12290;&#19982;&#20854;&#23494;&#38598;&#30340;&#23545;&#24212;&#29289;&#19968;&#26679;&#65292;&#31232;&#30095;&#30340;&#29616;&#20195; Hopfield &#27169;&#22411;&#20855;&#22791;&#19968;&#31181;&#35760;&#24518;&#26816;&#32034;&#21160;&#21147;&#23398;&#65292;&#20854;&#19968;&#27493;&#36817;&#20284;&#23545;&#24212;&#20110;&#31232;&#30095;&#30340;&#27880;&#24847;&#26426;&#21046;&#12290;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;&#25105;&#20204;&#30340;&#20851;&#38190;&#36129;&#29486;&#26159;&#36890;&#36807;&#31232;&#30095;&#29109;&#27491;&#21017;&#21270;&#22120;&#30340;&#20984;&#20849;&#36717;&#23548;&#20986;&#20102;&#23553;&#38381;&#24418;&#24335;&#30340;&#31232;&#30095; Hopfield &#33021;&#37327;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#20174;&#31232;&#30095;&#33021;&#37327;&#20989;&#25968;&#20013;&#25512;&#23548;&#20986;&#31232;&#30095;&#35760;&#24518;&#26816;&#32034;&#21160;&#21147;&#23398;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#30340;&#19968;&#27493;&#36817;&#20284;&#31561;&#20215;&#20110;&#31232;&#30095;&#32467;&#26500;&#21270;&#27880;&#24847;&#21147;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#20381;&#36182;&#20110;&#31232;&#30095;&#24230;&#30340;&#35760;&#24518;&#26816;&#32034;&#35823;&#24046;&#19978;&#30028;&#65292;&#35813;&#19978;&#30028;&#22312;&#35777;&#26126;&#19978;&#35201;&#27604;&#20854;&#23494;&#38598;&#23545;&#24212;&#29289;&#26356;&#32039;&#20945;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30830;&#23450;&#24182;&#35752;&#35770;&#20102;&#31232;&#30095;&#20248;&#21183;&#20986;&#29616;&#30340;&#26465;&#20214;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#34920;&#26126;&#31232;&#30095;&#30340;&#29616;&#20195; Hopfield &#27169;&#22411;&#20445;&#25345;&#20102;&#20854;&#23494;&#38598;&#23545;&#24212;&#29289;&#30340;&#31283;&#20581;&#29702;&#35770;&#24615;&#36136;&#65292;&#21253;&#25324;&#24555;&#36895;&#30340;&#22266;&#23450;&#28857;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the sparse modern Hopfield model as a sparse extension of the modern Hopfield model. Like its dense counterpart, the sparse modern Hopfield model equips a memory-retrieval dynamics whose one-step approximation corresponds to the sparse attention mechanism. Theoretically, our key contribution is a principled derivation of a closed-form sparse Hopfield energy using the convex conjugate of the sparse entropic regularizer. Building upon this, we derive the sparse memory retrieval dynamics from the sparse energy function and show its one-step approximation is equivalent to the sparse-structured attention. Importantly, we provide a sparsity-dependent memory retrieval error bound which is provably tighter than its dense analog. The conditions for the benefits of sparsity to arise are therefore identified and discussed. In addition, we show that the sparse modern Hopfield model maintains the robust theoretical properties of its dense counterpart, including rapid fixed point conver
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24418;&#29366;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#38477;&#20302;&#35774;&#35745;&#31354;&#38388;&#32500;&#24230;&#21644;&#24314;&#27169;&#25968;&#25454;&#30340;&#29983;&#25104;&#36807;&#31243;&#65292;&#23454;&#29616;&#20102;&#25552;&#39640;&#20840;&#23616;&#20248;&#21270;&#31639;&#27861;&#25928;&#29575;&#21644;&#29983;&#25104;&#26080;&#20960;&#20309;&#24322;&#24120;&#30340;&#39640;&#36136;&#37327;&#35774;&#35745;&#12290;</title><link>http://arxiv.org/abs/2308.04051</link><description>&lt;p&gt;
&#24418;&#29366;&#20248;&#21270;&#20013;&#30340;&#24322;&#24120;&#26816;&#27979;&#21644;&#35774;&#35745;&#31354;&#38388;&#32500;&#24230;&#38477;&#20302;&#30340;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Generative Models for Anomaly Detection and Design-Space Dimensionality Reduction in Shape Optimization. (arXiv:2308.04051v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04051
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24418;&#29366;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#38477;&#20302;&#35774;&#35745;&#31354;&#38388;&#32500;&#24230;&#21644;&#24314;&#27169;&#25968;&#25454;&#30340;&#29983;&#25104;&#36807;&#31243;&#65292;&#23454;&#29616;&#20102;&#25552;&#39640;&#20840;&#23616;&#20248;&#21270;&#31639;&#27861;&#25928;&#29575;&#21644;&#29983;&#25104;&#26080;&#20960;&#20309;&#24322;&#24120;&#30340;&#39640;&#36136;&#37327;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30340;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24418;&#29366;&#20248;&#21270;&#26041;&#27861;&#65292;&#20854;&#20004;&#20010;&#30446;&#26631;&#26159;&#25552;&#39640;&#20840;&#23616;&#20248;&#21270;&#31639;&#27861;&#30340;&#25928;&#29575;&#65292;&#21516;&#26102;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#29983;&#25104;&#27809;&#26377;&#20960;&#20309;&#24322;&#24120;&#30340;&#39640;&#36136;&#37327;&#35774;&#35745;&#12290;&#36890;&#36807;&#20943;&#23569;&#23450;&#20041;&#26032;&#30340;&#20943;&#23569;&#23376;&#31354;&#38388;&#30340;&#21407;&#22987;&#35774;&#35745;&#21464;&#37327;&#30340;&#25968;&#37327;&#65292;&#24182;&#20351;&#29992;&#27010;&#29575;&#32447;&#24615;&#28508;&#21464;&#37327;&#27169;&#22411;&#26469;&#24314;&#27169;&#25968;&#25454;&#30340;&#24213;&#23618;&#29983;&#25104;&#36807;&#31243;&#65292;&#22914;&#22240;&#23376;&#20998;&#26512;&#21644;&#27010;&#29575;&#20027;&#25104;&#20998;&#20998;&#26512;&#65292;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#24418;&#29366;&#20462;&#25913;&#26041;&#27861;&#26159;&#32447;&#24615;&#30340;&#19988;&#35774;&#35745;&#21464;&#37327;&#22312;&#22343;&#21248;&#38543;&#26426;&#37319;&#26679;&#26102;&#65292;&#25968;&#25454;&#36817;&#20284;&#26381;&#20174;&#39640;&#26031;&#20998;&#24067;&#65292;&#36825;&#26159;&#30001;&#20110;&#30452;&#25509;&#24212;&#29992;&#20102;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;&#21033;&#29992;&#39532;&#27663;&#36317;&#31163;&#26469;&#34913;&#37327;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#19988;&#35770;&#25991;&#35777;&#26126;&#24322;&#24120;&#35774;&#35745;&#24448;&#24448;&#20855;&#26377;&#36739;&#39640;&#30340;&#35813;&#24230;&#37327;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Our work presents a novel approach to shape optimization, that has the twofold objective to improve the efficiency of global optimization algorithms while promoting the generation of high-quality designs during the optimization process free of geometrical anomalies. This is accomplished by reducing the number of the original design variables defining a new reduced subspace where the geometrical variance is maximized and modeling the underlying generative process of the data via probabilistic linear latent variable models such as Factor Analysis and Probabilistic Principal Component Analysis. We show that the data follows approximately a Gaussian distribution when the shape modification method is linear and the design variables are sampled uniformly at random, due to the direct application of the central limit theorem. The model uncertainty is measured in terms of Mahalanobis distance, and the paper demonstrates that anomalous designs tend to exhibit a high value of this metric. This en
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#23545;&#21160;&#24577;&#31232;&#30095;&#35757;&#32451;&#20013;&#30340;&#21098;&#26525;&#20301;&#32622;&#36827;&#34892;&#20102;&#23454;&#35777;&#20998;&#26512;&#65292;&#21457;&#29616;&#22312;&#20302;&#23494;&#24230;&#33539;&#22260;&#20869;&#65292;&#26368;&#31616;&#21333;&#30340;&#22823;&#23567;&#26041;&#27861;&#25552;&#20379;&#20102;&#26368;&#20339;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.12230</link><description>&lt;p&gt;
&#22855;&#22937;&#30340;&#26435;&#37325;&#21450;&#20854;&#26597;&#25214;&#26041;&#27861;&#65306;&#21160;&#24577;&#31232;&#30095;&#35757;&#32451;&#20013;&#30340;&#21098;&#26525;&#20301;&#32622;
&lt;/p&gt;
&lt;p&gt;
Fantastic Weights and How to Find Them: Where to Prune in Dynamic Sparse Training. (arXiv:2306.12230v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12230
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#23545;&#21160;&#24577;&#31232;&#30095;&#35757;&#32451;&#20013;&#30340;&#21098;&#26525;&#20301;&#32622;&#36827;&#34892;&#20102;&#23454;&#35777;&#20998;&#26512;&#65292;&#21457;&#29616;&#22312;&#20302;&#23494;&#24230;&#33539;&#22260;&#20869;&#65292;&#26368;&#31616;&#21333;&#30340;&#22823;&#23567;&#26041;&#27861;&#25552;&#20379;&#20102;&#26368;&#20339;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21160;&#24577;&#31232;&#30095;&#35757;&#32451;&#65288;DST&#65289;&#26159;&#19968;&#20010;&#24555;&#36895;&#21457;&#23637;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#26088;&#22312;&#36890;&#36807;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#35843;&#25972;&#31070;&#32463;&#32593;&#32476;&#30340;&#25299;&#25169;&#32467;&#26500;&#26469;&#20248;&#21270;&#20854;&#31232;&#30095;&#21021;&#22987;&#21270;&#12290;&#24050;&#32463;&#35777;&#26126;&#65292;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#65292;DST&#33021;&#22815;&#32988;&#36807;&#23494;&#38598;&#27169;&#22411;&#12290;&#35813;&#26694;&#26550;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#26159;&#21098;&#26525;&#21644;&#29983;&#38271;&#26631;&#20934;&#65292;&#36825;&#20123;&#26631;&#20934;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#34987;&#21453;&#22797;&#24212;&#29992;&#20197;&#35843;&#25972;&#32593;&#32476;&#30340;&#31232;&#30095;&#36830;&#25509;&#12290;&#34429;&#28982;&#29983;&#38271;&#26631;&#20934;&#23545;DST&#24615;&#33021;&#30340;&#24433;&#21709;&#30456;&#23545;&#36739;&#22909;&#22320;&#30740;&#31350;&#20102;&#65292;&#20294;&#21098;&#26525;&#26631;&#20934;&#30340;&#24433;&#21709;&#20173;&#28982;&#34987;&#24573;&#35270;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35774;&#35745;&#24182;&#36827;&#34892;&#20102;&#23545;&#21508;&#31181;&#21098;&#26525;&#26631;&#20934;&#30340;&#24191;&#27867;&#23454;&#35777;&#20998;&#26512;&#65292;&#20197;&#26356;&#22909;&#22320;&#20102;&#35299;&#23427;&#20204;&#23545; DST &#35299;&#20915;&#26041;&#26696;&#21160;&#24577;&#30340;&#24433;&#21709;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#22823;&#22810;&#25968;&#30740;&#31350;&#26041;&#27861;&#37117;&#20135;&#29983;&#31867;&#20284;&#30340;&#32467;&#26524;&#12290;&#22312;&#20302;&#23494;&#24230;&#33539;&#22260;&#20869;&#65292;&#26368;&#31616;&#21333;&#30340;&#25216;&#26415;&#8212;&#8212;&#22522;&#20110;&#22823;&#23567;&#30340;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#26368;&#20339;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dynamic Sparse Training (DST) is a rapidly evolving area of research that seeks to optimize the sparse initialization of a neural network by adapting its topology during training. It has been shown that under specific conditions, DST is able to outperform dense models. The key components of this framework are the pruning and growing criteria, which are repeatedly applied during the training process to adjust the network's sparse connectivity. While the growing criterion's impact on DST performance is relatively well studied, the influence of the pruning criterion remains overlooked. To address this issue, we design and perform an extensive empirical analysis of various pruning criteria to better understand their effect on the dynamics of DST solutions. Surprisingly, we find that most of the studied methods yield similar results. The differences become more significant in the low-density regime, where the best performance is predominantly given by the simplest technique: magnitude-based
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#20998;&#26512;Hugging Face&#19978;1,417&#20010;ML&#27169;&#22411;&#21450;&#30456;&#20851;&#25968;&#25454;&#38598;&#30340;&#30899;&#36275;&#36857;&#27979;&#37327;&#24773;&#20917;&#65292;&#25552;&#20986;&#20102;&#26377;&#20851;&#22914;&#20309;&#25253;&#21578;&#21644;&#20248;&#21270;ML&#27169;&#22411;&#30340;&#30899;&#25928;&#29575;&#30340;&#35265;&#35299;&#21644;&#24314;&#35758;&#12290;</title><link>http://arxiv.org/abs/2305.11164</link><description>&lt;p&gt;
&#25506;&#32034;&#25265;&#25265;&#33080;ML&#27169;&#22411;&#30340;&#30899;&#36275;&#36857;&#65306;&#19968;&#39033;&#23384;&#20648;&#24211;&#25366;&#25496;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Exploring the Carbon Footprint of Hugging Face's ML Models: A Repository Mining Study. (arXiv:2305.11164v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11164
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#20998;&#26512;Hugging Face&#19978;1,417&#20010;ML&#27169;&#22411;&#21450;&#30456;&#20851;&#25968;&#25454;&#38598;&#30340;&#30899;&#36275;&#36857;&#27979;&#37327;&#24773;&#20917;&#65292;&#25552;&#20986;&#20102;&#26377;&#20851;&#22914;&#20309;&#25253;&#21578;&#21644;&#20248;&#21270;ML&#27169;&#22411;&#30340;&#30899;&#25928;&#29575;&#30340;&#35265;&#35299;&#21644;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;(ML)&#31995;&#32479;&#30340;&#23835;&#36215;&#21152;&#21095;&#20102;&#23427;&#20204;&#30340;&#30899;&#36275;&#36857;&#65292;&#36825;&#26159;&#30001;&#20110;&#20854;&#22686;&#21152;&#30340;&#33021;&#21147;&#21644;&#27169;&#22411;&#22823;&#23567;&#25152;&#33268;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23545;ML&#27169;&#22411;&#30340;&#30899;&#36275;&#36857;&#22914;&#20309;&#23454;&#38469;&#27979;&#37327;&#12289;&#25253;&#21578;&#21644;&#35780;&#20272;&#30340;&#35748;&#35782;&#30456;&#23545;&#36739;&#23569;&#12290;&#22240;&#27492;&#65292;&#26412;&#35770;&#25991;&#26088;&#22312;&#20998;&#26512;&#22312;Hugging Face&#19978;1,417&#20010;ML&#27169;&#22411;&#21644;&#30456;&#20851;&#25968;&#25454;&#38598;&#30340;&#30899;&#36275;&#36857;&#27979;&#37327;&#24773;&#20917;&#65292;Hugging Face&#26159;&#26368;&#21463;&#27426;&#36814;&#30340;&#39044;&#35757;&#32451;ML&#27169;&#22411;&#30340;&#23384;&#20648;&#24211;&#12290;&#30446;&#26631;&#26159;&#25552;&#20379;&#26377;&#20851;&#22914;&#20309;&#25253;&#21578;&#21644;&#20248;&#21270;ML&#27169;&#22411;&#30340;&#30899;&#25928;&#29575;&#30340;&#35265;&#35299;&#21644;&#24314;&#35758;&#12290;&#35813;&#30740;&#31350;&#21253;&#25324;Hugging Face Hub API&#19978;&#26377;&#20851;&#30899;&#25490;&#25918;&#30340;&#31532;&#19968;&#39033;&#23384;&#20648;&#24211;&#25366;&#25496;&#30740;&#31350;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#22238;&#31572;&#20004;&#20010;&#30740;&#31350;&#38382;&#39064;&#65306;(1) ML&#27169;&#22411;&#30340;&#21019;&#24314;&#32773;&#22914;&#20309;&#22312;Hugging Face Hub&#19978;&#27979;&#37327;&#21644;&#25253;&#21578;&#30899;&#25490;&#25918;&#65311;(2) &#21738;&#20123;&#26041;&#38754;&#24433;&#21709;&#20102;&#35757;&#32451;ML&#27169;&#22411;&#30340;&#30899;&#25490;&#25918;&#65311;&#35813;&#30740;&#31350;&#24471;&#20986;&#20102;&#20960;&#20010;&#20851;&#38190;&#21457;&#29616;&#12290;&#20854;&#20013;&#21253;&#25324;&#30899;&#25490;&#25918;&#25253;&#21578;&#27169;&#24335;&#27604;&#20363;&#30340;&#36880;&#27493;&#19979;&#38477;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
The rise of machine learning (ML) systems has exacerbated their carbon footprint due to increased capabilities and model sizes. However, there is scarce knowledge on how the carbon footprint of ML models is actually measured, reported, and evaluated. In light of this, the paper aims to analyze the measurement of the carbon footprint of 1,417 ML models and associated datasets on Hugging Face, which is the most popular repository for pretrained ML models. The goal is to provide insights and recommendations on how to report and optimize the carbon efficiency of ML models. The study includes the first repository mining study on the Hugging Face Hub API on carbon emissions. This study seeks to answer two research questions: (1) how do ML model creators measure and report carbon emissions on Hugging Face Hub?, and (2) what aspects impact the carbon emissions of training ML models? The study yielded several key findings. These include a decreasing proportion of carbon emissions-reporting mode
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#31216;&#20026;&#8220;&#26102;&#38388;&#32534;&#30721;&#23884;&#20837;&#8221;&#65292;&#21487;&#20197;&#20197;&#32447;&#24615;&#22797;&#26434;&#24230;&#26377;&#25928;&#22320;&#23884;&#20837;&#22823;&#37327;&#22270;&#25968;&#25454;&#65292;&#24182;&#21033;&#29992;&#27492;&#26041;&#27861;&#22312;&#22823;&#22411;&#32452;&#32455;&#30340;&#36890;&#20449;&#32593;&#32476;&#20013;&#26816;&#27979;&#20986;&#20102;&#20010;&#20307;&#39030;&#28857;&#12289;&#39030;&#28857;&#31038;&#21306;&#21644;&#25972;&#20307;&#22270;&#32467;&#26500;&#30340;&#36890;&#20449;&#27169;&#24335;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2305.02381</link><description>&lt;p&gt;
&#21033;&#29992;&#32534;&#30721;&#23884;&#20837;&#21644;&#39030;&#28857;&#21160;&#24577;&#21457;&#29616;&#22823;&#35268;&#27169;&#32593;&#32476;&#20013;&#30340;&#36890;&#20449;&#27169;&#24335;&#21464;&#21270;
&lt;/p&gt;
&lt;p&gt;
Discovering Communication Pattern Shifts in Large-Scale Networks using Encoder Embedding and Vertex Dynamics. (arXiv:2305.02381v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02381
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#31216;&#20026;&#8220;&#26102;&#38388;&#32534;&#30721;&#23884;&#20837;&#8221;&#65292;&#21487;&#20197;&#20197;&#32447;&#24615;&#22797;&#26434;&#24230;&#26377;&#25928;&#22320;&#23884;&#20837;&#22823;&#37327;&#22270;&#25968;&#25454;&#65292;&#24182;&#21033;&#29992;&#27492;&#26041;&#27861;&#22312;&#22823;&#22411;&#32452;&#32455;&#30340;&#36890;&#20449;&#32593;&#32476;&#20013;&#26816;&#27979;&#20986;&#20102;&#20010;&#20307;&#39030;&#28857;&#12289;&#39030;&#28857;&#31038;&#21306;&#21644;&#25972;&#20307;&#22270;&#32467;&#26500;&#30340;&#36890;&#20449;&#27169;&#24335;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#26512;&#22823;&#35268;&#27169;&#26102;&#38388;&#24207;&#21015;&#32593;&#32476;&#25968;&#25454;&#65288;&#22914;&#31038;&#20132;&#23186;&#20307;&#21644;&#30005;&#23376;&#37038;&#20214;&#36890;&#20449;&#65289;&#20173;&#28982;&#26159;&#22270;&#20998;&#26512;&#26041;&#27861;&#23398;&#38754;&#20020;&#30340;&#37325;&#22823;&#25361;&#25112;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#26102;&#38388;&#32534;&#30721;&#23884;&#20837;&#8221;&#30340;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#20197;&#32447;&#24615;&#22797;&#26434;&#24230;&#26377;&#25928;&#22320;&#23884;&#20837;&#22823;&#37327;&#30340;&#22270;&#25968;&#25454;&#12290;&#25105;&#20204;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#19968;&#23478;&#22823;&#22411;&#26426;&#26500;&#36328;&#36234;2019&#24180;&#33267;2020&#24180;&#30340;&#21311;&#21517;&#26102;&#38388;&#24207;&#21015;&#36890;&#20449;&#32593;&#32476;&#65292;&#30001;&#36229;&#36807;10&#19975;&#20010;&#39030;&#28857;&#21644;8000&#19975;&#20010;&#36793;&#32452;&#25104;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26631;&#20934;&#35745;&#31639;&#26426;&#19978;&#20165;&#38656;10&#31186;&#21363;&#21487;&#23884;&#20837;&#25968;&#25454;&#65292;&#24182;&#33021;&#22815;&#26816;&#27979;&#20010;&#20307;&#39030;&#28857;&#12289;&#39030;&#28857;&#31038;&#21306;&#21644;&#25972;&#20307;&#22270;&#32467;&#26500;&#30340;&#36890;&#20449;&#27169;&#24335;&#21464;&#21270;&#12290;&#36890;&#36807;&#25903;&#25345;&#29702;&#35770;&#21644;&#32508;&#21512;&#30740;&#31350;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#38543;&#26426;&#22270;&#27169;&#22411;&#19979;&#30340;&#29702;&#35770;&#20581;&#20840;&#24615;&#21644;&#25968;&#20540;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
The analysis of large-scale time-series network data, such as social media and email communications, remains a significant challenge for graph analysis methodology. In particular, the scalability of graph analysis is a critical issue hindering further progress in large-scale downstream inference. In this paper, we introduce a novel approach called "temporal encoder embedding" that can efficiently embed large amounts of graph data with linear complexity. We apply this method to an anonymized time-series communication network from a large organization spanning 2019-2020, consisting of over 100 thousand vertices and 80 million edges. Our method embeds the data within 10 seconds on a standard computer and enables the detection of communication pattern shifts for individual vertices, vertex communities, and the overall graph structure. Through supporting theory and synthesis studies, we demonstrate the theoretical soundness of our approach under random graph models and its numerical effecti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#28145;&#20837;&#30740;&#31350;&#21644;&#25551;&#36848;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#30340;&#20989;&#25968;&#30340;Lipschitz&#34892;&#20026;&#65292;&#22312;&#22810;&#31181;&#35774;&#32622;&#19979;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#65292;&#24182;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#20989;&#25968;Lipschitz&#36830;&#32493;&#24615;&#30340;&#22522;&#26412;&#21644;&#26377;&#36259;&#30340;&#29305;&#24615;&#65292;&#20854;&#20013;&#26368;&#24341;&#20154;&#27880;&#30446;&#30340;&#26159;&#22312;Lipschitz&#24120;&#25968;&#30340;&#19978;&#38480;&#21644;&#19979;&#38480;&#20013;&#35782;&#21035;&#20986;&#20102;&#26126;&#26174;&#30340;&#21452;&#19979;&#38477;&#36235;&#21183;&#12290;</title><link>http://arxiv.org/abs/2302.10886</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20989;&#25968;&#30340;Lipschitz&#36830;&#32493;&#24615;&#30340;&#19968;&#20123;&#22522;&#26412;&#26041;&#38754;
&lt;/p&gt;
&lt;p&gt;
Some Fundamental Aspects about Lipschitz Continuity of Neural Network Functions. (arXiv:2302.10886v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10886
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#28145;&#20837;&#30740;&#31350;&#21644;&#25551;&#36848;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#30340;&#20989;&#25968;&#30340;Lipschitz&#34892;&#20026;&#65292;&#22312;&#22810;&#31181;&#35774;&#32622;&#19979;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#65292;&#24182;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#20989;&#25968;Lipschitz&#36830;&#32493;&#24615;&#30340;&#22522;&#26412;&#21644;&#26377;&#36259;&#30340;&#29305;&#24615;&#65292;&#20854;&#20013;&#26368;&#24341;&#20154;&#27880;&#30446;&#30340;&#26159;&#22312;Lipschitz&#24120;&#25968;&#30340;&#19978;&#38480;&#21644;&#19979;&#38480;&#20013;&#35782;&#21035;&#20986;&#20102;&#26126;&#26174;&#30340;&#21452;&#19979;&#38477;&#36235;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Lipschitz&#36830;&#32493;&#24615;&#26159;&#20219;&#20309;&#39044;&#27979;&#27169;&#22411;&#30340;&#19968;&#20010;&#31616;&#21333;&#20294;&#20851;&#38190;&#30340;&#21151;&#33021;&#24615;&#36136;&#65292;&#23427;&#22788;&#20110;&#27169;&#22411;&#30340;&#31283;&#20581;&#24615;&#12289;&#27867;&#21270;&#24615;&#21644;&#23545;&#25239;&#24615;&#33030;&#24369;&#24615;&#30340;&#26680;&#24515;&#12290;&#26412;&#25991;&#26088;&#22312;&#28145;&#20837;&#30740;&#31350;&#21644;&#25551;&#36848;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#30340;&#20989;&#25968;&#30340;Lipschitz&#34892;&#20026;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#36890;&#36807;&#32791;&#23613;&#26368;&#31616;&#21333;&#21644;&#26368;&#19968;&#33324;&#30340;&#19979;&#38480;&#21644;&#19978;&#38480;&#30340;&#26497;&#38480;&#65292;&#22312;&#21508;&#31181;&#19981;&#21516;&#35774;&#32622;&#19979;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#65288;&#21363;&#65292;&#20307;&#31995;&#32467;&#26500;&#12289;&#25439;&#22833;&#12289;&#20248;&#21270;&#22120;&#12289;&#26631;&#31614;&#22122;&#38899;&#31561;&#65289;&#65292;&#34429;&#28982;&#36825;&#19968;&#36873;&#25321;&#20027;&#35201;&#26159;&#21463;&#35745;&#31639;&#38590;&#24230;&#32467;&#26524;&#30340;&#39537;&#21160;&#65292;&#20294;&#23427;&#20063;&#38750;&#24120;&#20016;&#23500;&#65292;&#24182;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#20989;&#25968;Lipschitz&#36830;&#32493;&#24615;&#30340;&#20960;&#20010;&#22522;&#26412;&#21644;&#26377;&#36259;&#30340;&#29305;&#24615;&#65292;&#25105;&#20204;&#36824;&#34917;&#20805;&#20102;&#36866;&#24403;&#30340;&#29702;&#35770;&#35770;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lipschitz continuity is a simple yet crucial functional property of any predictive model for it lies at the core of the model's robustness, generalisation, as well as adversarial vulnerability. Our aim is to thoroughly investigate and characterise the Lipschitz behaviour of the functions realised by neural networks. Thus, we carry out an empirical investigation in a range of different settings (namely, architectures, losses, optimisers, label noise, and more) by exhausting the limits of the simplest and the most general lower and upper bounds. Although motivated primarily by computational hardness results, this choice nevertheless turns out to be rather resourceful and sheds light on several fundamental and intriguing traits of the Lipschitz continuity of neural network functions, which we also supplement with suitable theoretical arguments. As a highlight of this investigation, we identify a striking double descent trend in both upper and lower bounds to the Lipschitz constant with in
&lt;/p&gt;</description></item><item><title>&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#26159;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#33539;&#24335;&#65292;&#26088;&#22312;&#20174;&#25968;&#25454;&#27969;&#20013;&#36873;&#25321;&#26368;&#20855;&#20449;&#24687;&#37327;&#30340;&#25968;&#25454;&#28857;&#36827;&#34892;&#26631;&#27880;&#12290;&#26412;&#25991;&#32508;&#36848;&#20102;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#12289;&#22522;&#20110;&#27969;&#30340;&#20027;&#21160;&#23398;&#20064;&#30340;&#20027;&#35201;&#25361;&#25112;&#21644;&#26426;&#36935;&#12289;&#29992;&#20110;&#36873;&#25321;&#20449;&#24687;&#26679;&#26412;&#30340;&#31574;&#30053;&#20197;&#21450;&#35813;&#33539;&#24335;&#20013;&#19981;&#21516;&#30340;&#35780;&#20272;&#25351;&#26631;&#12290;</title><link>http://arxiv.org/abs/2302.08893</link><description>&lt;p&gt;
&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A survey on online active learning. (arXiv:2302.08893v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08893
&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#26159;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#33539;&#24335;&#65292;&#26088;&#22312;&#20174;&#25968;&#25454;&#27969;&#20013;&#36873;&#25321;&#26368;&#20855;&#20449;&#24687;&#37327;&#30340;&#25968;&#25454;&#28857;&#36827;&#34892;&#26631;&#27880;&#12290;&#26412;&#25991;&#32508;&#36848;&#20102;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#12289;&#22522;&#20110;&#27969;&#30340;&#20027;&#21160;&#23398;&#20064;&#30340;&#20027;&#35201;&#25361;&#25112;&#21644;&#26426;&#36935;&#12289;&#29992;&#20110;&#36873;&#25321;&#20449;&#24687;&#26679;&#26412;&#30340;&#31574;&#30053;&#20197;&#21450;&#35813;&#33539;&#24335;&#20013;&#19981;&#21516;&#30340;&#35780;&#20272;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#26159;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#33539;&#24335;&#65292;&#26088;&#22312;&#20174;&#25968;&#25454;&#27969;&#20013;&#36873;&#25321;&#26368;&#20855;&#20449;&#24687;&#37327;&#30340;&#25968;&#25454;&#28857;&#36827;&#34892;&#26631;&#27880;&#12290;&#36817;&#24180;&#26469;&#65292;&#38543;&#30528;&#25968;&#25454;&#20165;&#20197;&#26410;&#26631;&#35760;&#24418;&#24335;&#21487;&#29992;&#30340;&#23454;&#38469;&#24212;&#29992;&#26085;&#30410;&#22686;&#22810;&#65292;&#26368;&#23567;&#21270;&#19982;&#25910;&#38598;&#26631;&#35760;&#35266;&#27979;&#30456;&#20851;&#30340;&#25104;&#26412;&#38382;&#39064;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#26631;&#27880;&#27599;&#20010;&#35266;&#27979;&#21487;&#20197;&#32791;&#36153;&#22823;&#37327;&#30340;&#26102;&#38388;&#21644;&#25104;&#26412;&#65292;&#20351;&#24471;&#33719;&#21462;&#22823;&#37327;&#26631;&#35760;&#25968;&#25454;&#21464;&#24471;&#22256;&#38590;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#65292;&#35768;&#22810;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;&#24050;&#32463;&#25552;&#20986;&#65292;&#26088;&#22312;&#36873;&#25321;&#26368;&#20855;&#20449;&#24687;&#37327;&#30340;&#35266;&#27979;&#36827;&#34892;&#26631;&#35760;&#65292;&#20197;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#24191;&#27867;&#22320;&#20998;&#20026;&#20004;&#31867;&#65306;&#38745;&#24577;&#22522;&#20110;&#27744;&#30340;&#21644;&#22522;&#20110;&#27969;&#30340;&#20027;&#21160;&#23398;&#20064;&#12290;&#22522;&#20110;&#27744;&#30340;&#20027;&#21160;&#23398;&#20064;&#28041;&#21450;&#20174;&#23553;&#38381;&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#27744;&#20013;&#36873;&#25321;&#19968;&#37096;&#20998;&#35266;&#27979;&#65292;&#24050;&#25104;&#20026;&#35768;&#22810;&#35843;&#26597;&#21644;&#25991;&#29486;&#32508;&#36848;&#30340;&#37325;&#28857;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#22312;&#32447;&#25968;&#25454;&#27969;&#30340;&#19981;&#26029;&#22686;&#21152;&#65292;&#22522;&#20110;&#27969;&#30340;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;&#21464;&#24471;&#26356;&#21152;&#21560;&#24341;&#20154;&#65292;&#22240;&#20026;&#23427;&#20204;&#20801;&#35768;&#27169;&#22411;&#36866;&#24212;&#26032;&#36827;&#25968;&#25454;&#12290;&#22312;&#26412;&#32508;&#36848;&#20013;&#65292;&#25105;&#20204;&#32508;&#36848;&#20102;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#35752;&#35770;&#20102;&#22522;&#20110;&#27969;&#30340;&#20027;&#21160;&#23398;&#20064;&#30340;&#20027;&#35201;&#25361;&#25112;&#21644;&#26426;&#36935;&#12289;&#29992;&#20110;&#36873;&#25321;&#20449;&#24687;&#26679;&#26412;&#30340;&#31574;&#30053;&#20197;&#21450;&#35813;&#33539;&#20363;&#20013;&#19981;&#21516;&#30340;&#35780;&#20272;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online active learning is a paradigm in machine learning that aims to select the most informative data points to label from a data stream. The problem of minimizing the cost associated with collecting labeled observations has gained a lot of attention in recent years, particularly in real-world applications where data is only available in an unlabeled form. Annotating each observation can be time-consuming and costly, making it difficult to obtain large amounts of labeled data. To overcome this issue, many active learning strategies have been proposed in the last decades, aiming to select the most informative observations for labeling in order to improve the performance of machine learning models. These approaches can be broadly divided into two categories: static pool-based and stream-based active learning. Pool-based active learning involves selecting a subset of observations from a closed pool of unlabeled data, and it has been the focus of many surveys and literature reviews. Howev
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102; ELBO &#25910;&#25947;&#21040;&#29109;&#21644;&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#19968;&#31867;&#24191;&#27867;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;ELBO &#22312;&#25152;&#26377;&#23398;&#20064;&#30340;&#31283;&#23450;&#28857;&#22788;&#37117;&#31561;&#20110;&#19968;&#31995;&#21015;&#29109;&#30340;&#21644;&#65292;&#20026;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#23398;&#20064;&#31639;&#27861;&#30340;&#22522;&#26412;&#23646;&#24615;&#25552;&#20379;&#20102;&#28145;&#20837;&#30340;&#27934;&#23519;&#12290;</title><link>http://arxiv.org/abs/2209.03077</link><description>&lt;p&gt;
&#20851;&#20110;ELBO&#25910;&#25947;&#21040;&#29109;&#21644;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Convergence of the ELBO to Entropy Sums. (arXiv:2209.03077v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.03077
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102; ELBO &#25910;&#25947;&#21040;&#29109;&#21644;&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#19968;&#31867;&#24191;&#27867;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;ELBO &#22312;&#25152;&#26377;&#23398;&#20064;&#30340;&#31283;&#23450;&#28857;&#22788;&#37117;&#31561;&#20110;&#19968;&#31995;&#21015;&#29109;&#30340;&#21644;&#65292;&#20026;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#23398;&#20064;&#31639;&#27861;&#30340;&#22522;&#26412;&#23646;&#24615;&#25552;&#20379;&#20102;&#28145;&#20837;&#30340;&#27934;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#19979;&#30028;&#65288;&#21448;&#31216;ELBO&#25110;&#33258;&#30001;&#33021;&#65289;&#26159;&#35768;&#22810;&#32463;&#20856;&#21644;&#26032;&#39062;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#30340;&#26680;&#24515;&#30446;&#26631;&#12290;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#25913;&#21464;&#27169;&#22411;&#21442;&#25968;&#65292;&#20351;&#21464;&#20998;&#19979;&#30028;&#22686;&#21152;&#12290;&#36890;&#24120;&#65292;&#23398;&#20064;&#36827;&#34892;&#21040;&#21442;&#25968;&#25910;&#25947;&#21040;&#25509;&#36817;&#23398;&#20064;&#21160;&#24577;&#30340;&#31283;&#23450;&#28857;&#20540;&#12290;&#22312;&#26412;&#25991;&#30340;&#29702;&#35770;&#36129;&#29486;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#65288;&#23545;&#20110;&#19968;&#31867;&#38750;&#24120;&#24191;&#27867;&#30340;&#29983;&#25104;&#27169;&#22411;&#65289;&#65292;&#21464;&#20998;&#19979;&#30028;&#22312;&#25152;&#26377;&#23398;&#20064;&#30340;&#31283;&#23450;&#28857;&#22788;&#22343;&#31561;&#20110;&#19968;&#31995;&#21015;&#29109;&#30340;&#21644;&#12290;&#23545;&#20110;&#20855;&#26377;&#19968;&#32452;&#28508;&#22312;&#21464;&#37327;&#21644;&#19968;&#32452;&#35266;&#27979;&#21464;&#37327;&#30340;&#26631;&#20934;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#36825;&#20010;&#21644;&#21253;&#25324;&#19977;&#20010;&#29109;: (A) &#21464;&#20998;&#20998;&#24067;&#30340;&#29109;&#65288;&#24179;&#22343;&#29109;&#65289;&#65292;(B) &#27169;&#22411;&#20808;&#39564;&#20998;&#24067;&#30340;&#36127;&#29109;&#21644; (C) &#21487;&#35266;&#27979;&#20998;&#24067;&#30340;&#65288;&#26399;&#26395;&#65289;&#36127;&#29109;&#12290;&#25152;&#24471;&#21040;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#21253;&#25324;&#65306;&#26377;&#38480;&#25968;&#37327;&#30340;&#25968;&#25454;&#28857;&#65292;&#22312;&#23398;&#20064;&#30340;&#20219;&#24847;&#38454;&#27573;&#21644;&#21508;&#31181;&#19981;&#21516;&#30340;&#29983;&#25104;&#27169;&#22411;&#31561;&#30495;&#23454;&#26465;&#20214;&#12290;&#26412;&#30740;&#31350;&#20026;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#23398;&#20064;&#31639;&#27861;&#30340;&#22522;&#26412;&#23646;&#24615;&#25552;&#20379;&#20102;&#28145;&#20837;&#27934;&#23519;&#65292;&#26159;&#23545;&#20248;&#21270;&#25512;&#29702;&#21644;&#23398;&#20064;&#30340;&#29702;&#35770;&#20998;&#26512;&#30340;&#31532;&#19968;&#27493;&#12290;
&lt;/p&gt;
&lt;p&gt;
The variational lower bound (a.k.a. ELBO or free energy) is the central objective for many established as well as many novel algorithms for unsupervised learning. Learning algorithms change model parameters such that the variational lower bound increases. Learning usually proceeds until parameters have converged to values close to a stationary point of the learning dynamics. In this purely theoretical contribution, we show that (for a very large class of generative models) the variational lower bound is at all stationary points of learning equal to a sum of entropies. For standard machine learning models with one set of latents and one set observed variables, the sum consists of three entropies: (A) the (average) entropy of the variational distributions, (B) the negative entropy of the model's prior distribution, and (C) the (expected) negative entropy of the observable distributions. The obtained result applies under realistic conditions including: finite numbers of data points, at an
&lt;/p&gt;</description></item></channel></rss>