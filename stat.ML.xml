<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36890;&#36807;&#20351;&#29992;&#22810;&#30446;&#26631;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;(NAS)&#21644;&#36229;&#21442;&#25968;&#20248;&#21270;(HPO)&#65292;&#25105;&#20204;&#22312;&#34920;&#26684;&#25968;&#25454;&#39046;&#22495;&#39318;&#27425;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#26032;&#27169;&#22411;&#26550;&#26500;&#21644;&#36229;&#21442;&#25968;&#30340;&#31574;&#30053;&#65292;&#20197;&#23547;&#25214;&#26356;&#20844;&#24179;&#21644;&#20934;&#30830;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#20165;&#38024;&#23545;&#20934;&#30830;&#24615;&#36827;&#34892;&#20248;&#21270;&#21487;&#33021;&#20250;&#23548;&#33268;&#20844;&#24179;&#24615;&#30340;&#38477;&#20302;&#65292;&#22240;&#27492;&#38656;&#35201;&#21516;&#26102;&#32771;&#34385;&#20934;&#30830;&#24615;&#21644;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.12145</link><description>&lt;p&gt;
&#36890;&#36807;NAS&#23454;&#29616;&#26356;&#20844;&#24179;&#21644;&#20934;&#30830;&#30340;&#34920;&#26684;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Fairer and More Accurate Tabular Models Through NAS. (arXiv:2310.12145v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12145
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#22810;&#30446;&#26631;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;(NAS)&#21644;&#36229;&#21442;&#25968;&#20248;&#21270;(HPO)&#65292;&#25105;&#20204;&#22312;&#34920;&#26684;&#25968;&#25454;&#39046;&#22495;&#39318;&#27425;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#26032;&#27169;&#22411;&#26550;&#26500;&#21644;&#36229;&#21442;&#25968;&#30340;&#31574;&#30053;&#65292;&#20197;&#23547;&#25214;&#26356;&#20844;&#24179;&#21644;&#20934;&#30830;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#20165;&#38024;&#23545;&#20934;&#30830;&#24615;&#36827;&#34892;&#20248;&#21270;&#21487;&#33021;&#20250;&#23548;&#33268;&#20844;&#24179;&#24615;&#30340;&#38477;&#20302;&#65292;&#22240;&#27492;&#38656;&#35201;&#21516;&#26102;&#32771;&#34385;&#20934;&#30830;&#24615;&#21644;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38271;&#26399;&#20197;&#26469;&#65292;&#36890;&#36807;&#31639;&#27861;&#20351;&#24471;&#34920;&#26684;&#25968;&#25454;&#30340;&#27169;&#22411;&#26356;&#21152;&#20844;&#24179;&#19968;&#30452;&#26159;&#30740;&#31350;&#30340;&#35838;&#39064;&#12290;&#29616;&#26377;&#30340;&#25216;&#26415;&#36890;&#24120;&#38024;&#23545;&#23384;&#22312;&#19981;&#21487;&#21462;&#30340;&#32467;&#26524;&#30340;&#31070;&#32463;&#27169;&#22411;&#65292;&#36890;&#36807;&#25913;&#21464;&#25968;&#25454;&#30340;&#25668;&#20837;&#26041;&#24335;&#12289;&#27169;&#22411;&#26435;&#37325;&#25110;&#36755;&#20986;&#22788;&#29702;&#26041;&#24335;&#26469;&#20462;&#22797;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#26032;&#30340;&#31574;&#30053;&#65292;&#22312;&#21435;&#20559;&#36807;&#31243;&#20013;&#32771;&#34385;&#26356;&#26032;&#27169;&#22411;&#30340;&#26550;&#26500;&#21644;&#35757;&#32451;&#36229;&#21442;&#25968;&#65292;&#20197;&#25214;&#21040;&#19968;&#20010;&#20174;&#19968;&#24320;&#22987;&#22312;&#39044;&#27979;&#32467;&#26524;&#19978;&#26356;&#22909;&#30340;&#26032;&#27169;&#22411;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#23558;&#22810;&#30446;&#26631;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;(NAS)&#21644;&#36229;&#21442;&#25968;&#20248;&#21270;(HPO)&#24212;&#29992;&#20110;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#34920;&#26684;&#25968;&#25454;&#39046;&#22495;&#12290;&#25105;&#20204;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#23545;MLP&#12289;ResNet&#21644;FT-Transformer&#31561;&#19981;&#21516;&#26550;&#26500;&#21644;&#36229;&#21442;&#25968;&#31354;&#38388;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#25506;&#32034;&#65292;&#23637;&#31034;&#20102;&#27169;&#22411;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#21644;&#20844;&#24179;&#24615;&#25351;&#26631;&#23545;&#36229;&#21442;&#25968;&#32452;&#21512;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#20165;&#38024;&#23545;&#20934;&#30830;&#24615;&#36827;&#34892;&#20248;&#21270;&#30340;&#27169;&#22411;&#21487;&#33021;&#20250;&#23548;&#33268;&#20844;&#24179;&#24615;&#30340;&#38477;&#20302;&#65292;&#22240;&#27492;&#38656;&#35201;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#21516;&#26102;&#32771;&#34385;&#20934;&#30830;&#24615;&#21644;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Making models algorithmically fairer in tabular data has been long studied, with techniques typically oriented towards fixes which usually take a neural model with an undesirable outcome and make changes to how the data are ingested, what the model weights are, or how outputs are processed. We employ an emergent and different strategy where we consider updating the model's architecture and training hyperparameters to find an entirely new model with better outcomes from the beginning of the debiasing procedure. In this work, we propose using multi-objective Neural Architecture Search (NAS) and Hyperparameter Optimization (HPO) in the first application to the very challenging domain of tabular data. We conduct extensive exploration of architectural and hyperparameter spaces (MLP, ResNet, and FT-Transformer) across diverse datasets, demonstrating the dependence of accuracy and fairness metrics of model predictions on hyperparameter combinations. We show that models optimized solely for ac
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26597;&#30475;&#27010;&#24565;&#30340;&#30697;&#38453;&#32479;&#35745;&#37327;&#65292;&#29983;&#25104;&#19968;&#20010;&#27010;&#24565;&#30340;&#20855;&#20307;&#34920;&#31034;&#25110;&#31614;&#21517;&#65292;&#21487;&#20197;&#29992;&#20110;&#21457;&#29616;&#27010;&#24565;&#20043;&#38388;&#30340;&#32467;&#26500;&#24182;&#36882;&#24402;&#20135;&#29983;&#26356;&#39640;&#32423;&#30340;&#27010;&#24565;&#65292;&#21516;&#26102;&#21487;&#20197;&#36890;&#36807;&#27010;&#24565;&#30340;&#31614;&#21517;&#26469;&#25214;&#21040;&#30456;&#20851;&#30340;&#20849;&#21516;&#20027;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.12143</link><description>&lt;p&gt;
&#31616;&#21333;&#26426;&#21046;&#29992;&#20110;&#34920;&#31034;&#12289;&#32034;&#24341;&#21644;&#25805;&#20316;&#27010;&#24565;
&lt;/p&gt;
&lt;p&gt;
Simple Mechanisms for Representing, Indexing and Manipulating Concepts. (arXiv:2310.12143v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12143
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26597;&#30475;&#27010;&#24565;&#30340;&#30697;&#38453;&#32479;&#35745;&#37327;&#65292;&#29983;&#25104;&#19968;&#20010;&#27010;&#24565;&#30340;&#20855;&#20307;&#34920;&#31034;&#25110;&#31614;&#21517;&#65292;&#21487;&#20197;&#29992;&#20110;&#21457;&#29616;&#27010;&#24565;&#20043;&#38388;&#30340;&#32467;&#26500;&#24182;&#36882;&#24402;&#20135;&#29983;&#26356;&#39640;&#32423;&#30340;&#27010;&#24565;&#65292;&#21516;&#26102;&#21487;&#20197;&#36890;&#36807;&#27010;&#24565;&#30340;&#31614;&#21517;&#26469;&#25214;&#21040;&#30456;&#20851;&#30340;&#20849;&#21516;&#20027;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#32593;&#32476;&#36890;&#24120;&#36890;&#36807;&#20998;&#31867;&#22120;&#23398;&#20064;&#27010;&#24565;&#65292;&#36825;&#28041;&#21450;&#35774;&#32622;&#27169;&#22411;&#24182;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#23427;&#20197;&#36866;&#24212;&#20855;&#26377;&#26631;&#35760;&#27010;&#24565;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#23558;&#25552;&#20986;&#19968;&#20010;&#19981;&#21516;&#30340;&#35266;&#28857;&#65292;&#21363;&#21487;&#20197;&#36890;&#36807;&#26597;&#30475;&#27010;&#24565;&#30340;&#30697;&#38453;&#30697;&#38453;&#32479;&#35745;&#37327;&#26469;&#29983;&#25104;&#27010;&#24565;&#30340;&#20855;&#20307;&#34920;&#31034;&#25110;&#31614;&#21517;&#12290;&#36825;&#20123;&#31614;&#21517;&#21487;&#20197;&#29992;&#20110;&#21457;&#29616;&#19968;&#32452;&#27010;&#24565;&#30340;&#32467;&#26500;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#20174;&#36825;&#20123;&#31614;&#21517;&#20013;&#23398;&#20064;&#35813;&#32467;&#26500;&#26469;&#36882;&#24402;&#22320;&#20135;&#29983;&#26356;&#39640;&#32423;&#30340;&#27010;&#24565;&#12290;&#24403;&#27010;&#24565;"&#30456;&#20132;"&#26102;&#65292;&#27010;&#24565;&#30340;&#31614;&#21517;&#21487;&#20197;&#29992;&#20110;&#22312;&#19968;&#20123;&#30456;&#20851;&#30340;"&#30456;&#20132;"&#27010;&#24565;&#20013;&#25214;&#21040;&#19968;&#20010;&#20849;&#21516;&#30340;&#20027;&#39064;&#12290;&#36825;&#20010;&#36807;&#31243;&#21487;&#20197;&#29992;&#20110;&#20445;&#25345;&#19968;&#20010;&#27010;&#24565;&#23383;&#20856;&#65292;&#20197;&#20415;&#36755;&#20837;&#33021;&#22815;&#27491;&#30830;&#35782;&#21035;&#24182;&#34987;&#36335;&#30001;&#21040;&#19982;&#36755;&#20837;&#30340;(&#28508;&#22312;)&#29983;&#25104;&#30456;&#20851;&#30340;&#27010;&#24565;&#38598;&#21512;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep networks typically learn concepts via classifiers, which involves setting up a model and training it via gradient descent to fit the concept-labeled data. We will argue instead that learning a concept could be done by looking at its moment statistics matrix to generate a concrete representation or signature of that concept. These signatures can be used to discover structure across the set of concepts and could recursively produce higher-level concepts by learning this structure from those signatures. When the concepts are `intersected', signatures of the concepts can be used to find a common theme across a number of related `intersected' concepts. This process could be used to keep a dictionary of concepts so that inputs could correctly identify and be routed to the set of concepts involved in the (latent) generation of the input.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#21152;&#26435;&#28378;&#21160;&#39564;&#35777;&#36807;&#31243;&#26469;&#25552;&#39640;&#22522;&#26412;&#20272;&#35745;&#22120;&#30340;&#33258;&#36866;&#24212;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#37325;&#35201;&#24615;&#21644;&#25935;&#24863;&#24615;</title><link>http://arxiv.org/abs/2310.12140</link><description>&lt;p&gt;
&#22312;&#32447;&#20272;&#35745;&#19982;&#28378;&#21160;&#39564;&#35777;&#65306;&#36866;&#24212;&#24615;&#38750;&#21442;&#25968;&#20272;&#35745;&#19982;&#25968;&#25454;&#27969;
&lt;/p&gt;
&lt;p&gt;
Online Estimation with Rolling Validation: Adaptive Nonparametric Estimation with Stream Data. (arXiv:2310.12140v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12140
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#21152;&#26435;&#28378;&#21160;&#39564;&#35777;&#36807;&#31243;&#26469;&#25552;&#39640;&#22522;&#26412;&#20272;&#35745;&#22120;&#30340;&#33258;&#36866;&#24212;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#37325;&#35201;&#24615;&#21644;&#25935;&#24863;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#39640;&#25928;&#35745;&#31639;&#21644;&#31454;&#20105;&#24615;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#22312;&#32447;&#38750;&#21442;&#25968;&#20272;&#35745;&#22120;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#19968;&#20010;&#37325;&#35201;&#30340;&#20363;&#23376;&#26159;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#21464;&#20307;&#12290;&#36825;&#20123;&#31639;&#27861;&#36890;&#24120;&#19968;&#27425;&#21482;&#21462;&#19968;&#20010;&#26679;&#26412;&#28857;&#65292;&#24182;&#31435;&#21363;&#26356;&#26032;&#24863;&#20852;&#36259;&#30340;&#21442;&#25968;&#20272;&#35745;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#36825;&#20123;&#22312;&#32447;&#31639;&#27861;&#30340;&#27169;&#22411;&#36873;&#25321;&#21644;&#36229;&#21442;&#25968;&#35843;&#25972;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#28378;&#21160;&#39564;&#35777;&#36807;&#31243;&#65292;&#19968;&#31181;&#22312;&#32447;&#30340;&#30041;&#19968;&#20132;&#21449;&#39564;&#35777;&#21464;&#20307;&#65292;&#23545;&#20110;&#35768;&#22810;&#20856;&#22411;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20272;&#35745;&#22120;&#26469;&#35828;&#65292;&#39069;&#22806;&#30340;&#35745;&#31639;&#25104;&#26412;&#26368;&#23567;&#12290;&#31867;&#20284;&#20110;&#25209;&#37327;&#20132;&#21449;&#39564;&#35777;&#65292;&#23427;&#21487;&#20197;&#25552;&#21319;&#22522;&#26412;&#20272;&#35745;&#22120;&#30340;&#33258;&#36866;&#24212;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#24456;&#31616;&#21333;&#65292;&#20027;&#35201;&#20381;&#36182;&#20110;&#19968;&#20123;&#19968;&#33324;&#30340;&#32479;&#35745;&#31283;&#23450;&#24615;&#20551;&#35774;&#12290;&#27169;&#25311;&#30740;&#31350;&#24378;&#35843;&#20102;&#28378;&#21160;&#39564;&#35777;&#20013;&#21457;&#25955;&#26435;&#37325;&#22312;&#23454;&#36341;&#20013;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#21363;&#20351;&#21482;&#26377;&#19968;&#20010;&#24456;&#23567;&#30340;&#20559;&#24046;&#65292;&#23427;&#30340;&#25935;&#24863;&#24615;&#20063;&#24456;&#39640;
&lt;/p&gt;
&lt;p&gt;
Online nonparametric estimators are gaining popularity due to their efficient computation and competitive generalization abilities. An important example includes variants of stochastic gradient descent. These algorithms often take one sample point at a time and instantly update the parameter estimate of interest. In this work we consider model selection and hyperparameter tuning for such online algorithms. We propose a weighted rolling-validation procedure, an online variant of leave-one-out cross-validation, that costs minimal extra computation for many typical stochastic gradient descent estimators. Similar to batch cross-validation, it can boost base estimators to achieve a better, adaptive convergence rate. Our theoretical analysis is straightforward, relying mainly on some general statistical stability assumptions. The simulation study underscores the significance of diverging weights in rolling validation in practice and demonstrates its sensitivity even when there is only a slim
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;MMD&#36317;&#31163;&#21644;&#32463;&#20856;&#30340;drop and relearn&#21407;&#29702;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#20998;&#24067;&#38543;&#26426;&#26862;&#26519;&#20013;&#26816;&#27979;&#24433;&#21709;&#36755;&#20986;&#20998;&#24067;&#30340;&#21464;&#37327;&#65292;&#24182;&#19988;&#22312;&#23454;&#35777;&#24615;&#33021;&#19978;&#36229;&#36234;&#20102;&#31454;&#20105;&#23545;&#25163;&#12290;</title><link>http://arxiv.org/abs/2310.12115</link><description>&lt;p&gt;
&#22522;&#20110;MMD&#30340;&#20998;&#24067;&#38543;&#26426;&#26862;&#26519;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;
&lt;/p&gt;
&lt;p&gt;
MMD-based Variable Importance for Distributional Random Forest. (arXiv:2310.12115v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12115
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;MMD&#36317;&#31163;&#21644;&#32463;&#20856;&#30340;drop and relearn&#21407;&#29702;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#20998;&#24067;&#38543;&#26426;&#26862;&#26519;&#20013;&#26816;&#27979;&#24433;&#21709;&#36755;&#20986;&#20998;&#24067;&#30340;&#21464;&#37327;&#65292;&#24182;&#19988;&#22312;&#23454;&#35777;&#24615;&#33021;&#19978;&#36229;&#36234;&#20102;&#31454;&#20105;&#23545;&#25163;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#38543;&#26426;&#26862;&#26519;&#65288;DRF&#65289;&#26159;&#19968;&#31181;&#28789;&#27963;&#30340;&#22522;&#20110;&#26862;&#26519;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#32473;&#23450;&#36755;&#20837;&#21464;&#37327;&#30340;&#22810;&#20803;&#36755;&#20986;&#30340;&#20840;&#26465;&#20214;&#20998;&#24067;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#32463;&#20856;&#30340;drop and relearn&#21407;&#29702;&#21644;MMD&#36317;&#31163;&#30340;DRF&#21464;&#37327;&#37325;&#35201;&#24615;&#31639;&#27861;&#12290;&#20256;&#32479;&#30340;&#37325;&#35201;&#24615;&#24230;&#37327;&#21482;&#33021;&#21457;&#29616;&#23545;&#36755;&#20986;&#22343;&#20540;&#26377;&#24433;&#21709;&#30340;&#21464;&#37327;&#65292;&#32780;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#26356;&#26222;&#36941;&#22320;&#21457;&#29616;&#24433;&#21709;&#36755;&#20986;&#20998;&#24067;&#30340;&#21464;&#37327;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24341;&#20837;&#30340;&#37325;&#35201;&#24615;&#24230;&#37327;&#26159;&#19968;&#33268;&#30340;&#65292;&#22312;&#30495;&#23454;&#25968;&#25454;&#21644;&#27169;&#25311;&#25968;&#25454;&#19978;&#20855;&#26377;&#36739;&#39640;&#30340;&#23454;&#35777;&#24615;&#33021;&#65292;&#24182;&#19988;&#36229;&#36234;&#20102;&#31454;&#20105;&#23545;&#25163;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#36890;&#36807;&#36882;&#24402;&#29305;&#24449;&#28040;&#38500;&#39640;&#25928;&#22320;&#36873;&#25321;&#21464;&#37327;&#65292;&#22240;&#27492;&#21487;&#20197;&#25552;&#20379;&#23567;&#22411;&#21464;&#37327;&#38598;&#21512;&#26469;&#26500;&#24314;&#20934;&#30830;&#30340;&#26465;&#20214;&#36755;&#20986;&#20998;&#24067;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distributional Random Forest (DRF) is a flexible forest-based method to estimate the full conditional distribution of a multivariate output of interest given input variables. In this article, we introduce a variable importance algorithm for DRFs, based on the well-established drop and relearn principle and MMD distance. While traditional importance measures only detect variables with an influence on the output mean, our algorithm detects variables impacting the output distribution more generally. We show that the introduced importance measure is consistent, exhibits high empirical performance on both real and simulated data, and outperforms competitors. In particular, our algorithm is highly efficient to select variables through recursive feature elimination, and can therefore provide small sets of variables to build accurate estimates of conditional output distributions.
&lt;/p&gt;</description></item><item><title>&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#23545;&#20110;&#20855;&#26377;&#24418;&#29366;&#28608;&#27963;&#20989;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#20854;&#32553;&#25918;&#26497;&#38480;&#21487;&#20197;&#30001;&#24494;&#20998;&#26041;&#31243;&#25551;&#36848;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#26410;&#32463;&#24418;&#29366;&#22788;&#29702;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#20449;&#24687;&#23578;&#19981;&#26126;&#30830;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#31181;&#26410;&#32463;&#24418;&#29366;&#22788;&#29702;&#30340;&#32593;&#32476;&#65292;&#21457;&#29616;&#23427;&#20204;&#20063;&#21487;&#20197;&#30001;&#31867;&#20284;&#30340;&#24494;&#20998;&#26041;&#31243;&#26469;&#25551;&#36848;&#65292;&#24182;&#32473;&#20986;&#20102;&#23427;&#20204;&#30340;&#19968;&#20123;&#29305;&#24449;&#12290;</title><link>http://arxiv.org/abs/2310.12079</link><description>&lt;p&gt;
&#24418;&#29366;&#21644;&#38750;&#24418;&#29366;&#31070;&#32463;&#32593;&#32476;&#30340;&#24494;&#20998;&#26041;&#31243;&#32553;&#25918;&#26497;&#38480;
&lt;/p&gt;
&lt;p&gt;
Differential Equation Scaling Limits of Shaped and Unshaped Neural Networks. (arXiv:2310.12079v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12079
&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#23545;&#20110;&#20855;&#26377;&#24418;&#29366;&#28608;&#27963;&#20989;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#20854;&#32553;&#25918;&#26497;&#38480;&#21487;&#20197;&#30001;&#24494;&#20998;&#26041;&#31243;&#25551;&#36848;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#26410;&#32463;&#24418;&#29366;&#22788;&#29702;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#20449;&#24687;&#23578;&#19981;&#26126;&#30830;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#31181;&#26410;&#32463;&#24418;&#29366;&#22788;&#29702;&#30340;&#32593;&#32476;&#65292;&#21457;&#29616;&#23427;&#20204;&#20063;&#21487;&#20197;&#30001;&#31867;&#20284;&#30340;&#24494;&#20998;&#26041;&#31243;&#26469;&#25551;&#36848;&#65292;&#24182;&#32473;&#20986;&#20102;&#23427;&#20204;&#30340;&#19968;&#20123;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#23545;&#20855;&#26377;&#24418;&#29366;&#28608;&#27963;&#20989;&#25968;&#65288;&#21363;&#38543;&#30528;&#32593;&#32476;&#35268;&#27169;&#22686;&#22823;&#32780;&#32553;&#25918;&#30340;&#28608;&#27963;&#20989;&#25968;&#65289;&#30340;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#23427;&#20204;&#20855;&#26377;&#30001;&#24494;&#20998;&#26041;&#31243;&#25551;&#36848;&#30340;&#32553;&#25918;&#26497;&#38480;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#32467;&#26524;&#19981;&#39044;&#20808;&#21578;&#35785;&#25105;&#20204;&#20851;&#20110;&#8220;&#26222;&#36890;&#8221;&#38750;&#24418;&#29366;&#32593;&#32476;&#30340;&#20219;&#20309;&#20449;&#24687;&#65292;&#20854;&#20013;&#28608;&#27963;&#20989;&#25968;&#22312;&#32593;&#32476;&#35268;&#27169;&#22686;&#22823;&#26102;&#20445;&#25345;&#19981;&#21464;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#38024;&#23545;&#20004;&#31181;&#31867;&#22411;&#30340;&#38750;&#24418;&#29366;&#32593;&#32476;&#25214;&#21040;&#20102;&#31867;&#20284;&#30340;&#22522;&#20110;&#24494;&#20998;&#26041;&#31243;&#30340;&#28176;&#36817;&#29305;&#24449;&#25551;&#36848;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35777;&#26126;&#20197;&#19979;&#20004;&#31181;&#26550;&#26500;&#22312;&#21021;&#22987;&#21270;&#26102;&#20250;&#25910;&#25947;&#21040;&#30456;&#21516;&#30340;&#26080;&#38480;&#28145;&#24230;&#21644;&#23485;&#24230;&#26497;&#38480;&#65306;&#65288;i&#65289;&#24102;&#26377;&#27531;&#24046;&#20998;&#25903;&#19978;&#30340; $d^{-1/2}$ &#22240;&#23376;&#30340;&#20840;&#36830;&#25509; ResNet&#65292;&#20854;&#20013; $d$ &#26159;&#32593;&#32476;&#30340;&#28145;&#24230;&#65307;&#65288;ii&#65289;&#24102;&#26377;&#28145;&#24230; $d \ll$ &#23485;&#24230; $n$ &#21644;&#24418;&#29366; ReLU &#28608;&#27963;&#20989;&#25968; (activation) &#30340;&#22810;&#23618;&#24863;&#30693;&#26426; (MLP)&#65292;&#20197; $d^{-1/2}$ &#30340;&#36895;&#29575;&#12290;&#20854;&#27425;&#65292;&#23545;&#20110;&#21021;&#22987;&#21270;&#30340;&#38750;&#24418;&#29366; MLP&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#23618;&#38388;&#30456;&#20851;&#24615;&#30340;&#19968;&#38454;&#28176;&#36817;&#20462;&#27491;&#12290;&#29305;&#21035;&#22320;&#65292;&#22914;&#26524; $\rho_\ell$ &#26159;&#31532; $\ell$ &#23618;&#30340;&#30456;&#20851;&#24615;&#65292;&#21017;...
&lt;/p&gt;
&lt;p&gt;
Recent analyses of neural networks with shaped activations (i.e. the activation function is scaled as the network size grows) have led to scaling limits described by differential equations. However, these results do not a priori tell us anything about "ordinary" unshaped networks, where the activation is unchanged as the network size grows. In this article, we find similar differential equation based asymptotic characterization for two types of unshaped networks.  Firstly, we show that the following two architectures converge to the same infinite-depth-and-width limit at initialization: (i) a fully connected ResNet with a $d^{-1/2}$ factor on the residual branch, where $d$ is the network depth. (ii) a multilayer perceptron (MLP) with depth $d \ll$ width $n$ and shaped ReLU activation at rate $d^{-1/2}$.  Secondly, for an unshaped MLP at initialization, we derive the first order asymptotic correction to the layerwise correlation. In particular, if $\rho_\ell$ is the correlation at layer
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#20013;&#65292;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#20026;&#22522;&#30784;&#30340;&#20195;&#29702;&#27169;&#22411;&#65292;&#20197;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#21644;&#22788;&#29702;&#25968;&#20540;&#25361;&#25112;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.12046</link><description>&lt;p&gt;
&#20197;&#26426;&#22120;&#23398;&#20064;&#20026;&#22522;&#30784;&#30340;&#20195;&#29702;&#27169;&#22411;&#22312;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#26041;&#27861;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Applications of ML-Based Surrogates in Bayesian Approaches to Inverse Problems. (arXiv:2310.12046v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12046
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#20013;&#65292;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#20026;&#22522;&#30784;&#30340;&#20195;&#29702;&#27169;&#22411;&#65292;&#20197;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#21644;&#22788;&#29702;&#25968;&#20540;&#25361;&#25112;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#24050;&#25104;&#20026;&#19968;&#31181;&#24378;&#22823;&#30340;&#24037;&#20855;&#65292;&#20316;&#20026;&#20195;&#29702;&#27169;&#22411;&#65292;&#22312;&#22686;&#21152;&#35745;&#31639;&#25928;&#29575;&#30340;&#21516;&#26102;&#20026;&#31185;&#23398;&#38382;&#39064;&#25552;&#20379;&#25968;&#20540;&#35299;&#12290;&#36825;&#31181;&#25928;&#29575;&#22312;&#26102;&#38388;&#33267;&#20851;&#37325;&#35201;&#30340;&#25968;&#20540;&#25361;&#25112;&#38382;&#39064;&#25110;&#38656;&#35201;&#35780;&#20272;&#35768;&#22810;&#31867;&#20284;&#20998;&#26512;&#26041;&#26696;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#20248;&#21183;&#12290;&#19968;&#20010;&#29305;&#23450;&#30340;&#31185;&#23398;&#20852;&#36259;&#39046;&#22495;&#26159;&#36870;&#38382;&#39064;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#25105;&#20204;&#30693;&#36947;&#31995;&#32479;&#30340;&#27491;&#21521;&#21160;&#24577;&#30001;&#20559;&#24494;&#20998;&#26041;&#31243;&#25551;&#36848;&#65292;&#20219;&#21153;&#26159;&#26681;&#25454;&#36825;&#20123;&#21160;&#24577;&#30340;&#65288;&#28508;&#22312;&#26377;&#22122;&#22768;&#30340;&#65289;&#35266;&#27979;&#26469;&#25512;&#26029;&#31995;&#32479;&#30340;&#24615;&#36136;&#12290;&#25105;&#20204;&#32771;&#34385;&#25512;&#26029;&#32473;&#23450;2D&#22768;&#27874;&#26041;&#31243;&#30340;&#22024;&#26434;&#35299;&#30340;&#26041;&#22359;&#22495;&#20013;&#27874;&#28304;&#30340;&#20301;&#32622;&#30340;&#36870;&#38382;&#39064;&#12290;&#22312;&#20551;&#35774;&#20026;&#39640;&#26031;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#26500;&#36896;&#28304;&#20301;&#32622;&#30340;&#20284;&#28982;&#20989;&#25968;&#65292;&#27599;&#20010;&#35780;&#20272;&#37117;&#38656;&#35201;&#23545;&#31995;&#32479;&#36827;&#34892;&#19968;&#27425;&#27491;&#21521;&#27169;&#25311;&#12290;&#20351;&#29992;&#26631;&#20934;&#30340;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#20195;&#29702;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Neural networks have become a powerful tool as surrogate models to provide numerical solutions for scientific problems with increased computational efficiency. This efficiency can be advantageous for numerically challenging problems where time to solution is important or when evaluation of many similar analysis scenarios is required. One particular area of scientific interest is the setting of inverse problems, where one knows the forward dynamics of a system are described by a partial differential equation and the task is to infer properties of the system given (potentially noisy) observations of these dynamics. We consider the inverse problem of inferring the location of a wave source on a square domain, given a noisy solution to the 2-D acoustic wave equation. Under the assumption of Gaussian noise, a likelihood function for source location can be formulated, which requires one forward simulation of the system per evaluation. Using a standard neural network as a surrogate model make
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#20174;&#20154;&#31867;&#20559;&#22909;&#20013;&#23398;&#20064;&#30340;&#23454;&#38469;&#31639;&#27861;&#30340;&#29702;&#35770;&#22522;&#30784;&#65292;&#25512;&#23548;&#20986;&#19968;&#20010;&#26032;&#30340;&#19968;&#33324;&#30446;&#26631;&#65292;&#32469;&#36807;&#20102;&#20004;&#20010;&#37325;&#35201;&#30340;&#36817;&#20284;&#12290;&#36825;&#31181;&#26041;&#27861;&#20801;&#35768;&#30452;&#25509;&#20174;&#25910;&#38598;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#31574;&#30053;&#32780;&#26080;&#38656;&#22870;&#21169;&#27169;&#22411;&#30340;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2310.12036</link><description>&lt;p&gt;
&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#29702;&#35299;&#20174;&#20154;&#31867;&#20559;&#22909;&#20013;&#23398;&#20064;&#30340;&#19968;&#33324;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A General Theoretical Paradigm to Understand Learning from Human Preferences. (arXiv:2310.12036v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12036
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#20174;&#20154;&#31867;&#20559;&#22909;&#20013;&#23398;&#20064;&#30340;&#23454;&#38469;&#31639;&#27861;&#30340;&#29702;&#35770;&#22522;&#30784;&#65292;&#25512;&#23548;&#20986;&#19968;&#20010;&#26032;&#30340;&#19968;&#33324;&#30446;&#26631;&#65292;&#32469;&#36807;&#20102;&#20004;&#20010;&#37325;&#35201;&#30340;&#36817;&#20284;&#12290;&#36825;&#31181;&#26041;&#27861;&#20801;&#35768;&#30452;&#25509;&#20174;&#25910;&#38598;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#31574;&#30053;&#32780;&#26080;&#38656;&#22870;&#21169;&#27169;&#22411;&#30340;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#20174;&#20154;&#31867;&#20559;&#22909;&#20013;&#23398;&#20064;&#30340;&#27969;&#34892;&#26041;&#27861;&#20381;&#36182;&#20110;&#20004;&#20010;&#37325;&#35201;&#30340;&#36817;&#20284;&#65306;&#31532;&#19968;&#20551;&#35774;&#21487;&#20197;&#29992;&#36880;&#28857;&#22870;&#21169;&#26367;&#20195;&#25104;&#23545;&#20559;&#22909;&#12290;&#31532;&#20108;&#20010;&#20551;&#35774;&#26159;&#22312;&#36825;&#20123;&#36880;&#28857;&#22870;&#21169;&#19978;&#35757;&#32451;&#30340;&#22870;&#21169;&#27169;&#22411;&#21487;&#20197;&#20174;&#25910;&#38598;&#21040;&#30340;&#25968;&#25454;&#27867;&#21270;&#21040;&#31574;&#30053;&#37319;&#26679;&#30340;&#36229;&#20986;&#20998;&#24067;&#30340;&#25968;&#25454;&#12290;&#26368;&#36817;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;(DPO)&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#32469;&#36807;&#20102;&#31532;&#20108;&#20010;&#36817;&#20284;&#65292;&#24182;&#30452;&#25509;&#20174;&#25910;&#38598;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#31574;&#30053;&#32780;&#26080;&#38656;&#22870;&#21169;&#27169;&#22411;&#38454;&#27573;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#20173;&#28982;&#20005;&#37325;&#20381;&#36182;&#20110;&#31532;&#19968;&#20010;&#36817;&#20284;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35797;&#22270;&#23545;&#36825;&#20123;&#23454;&#38469;&#31639;&#27861;&#36827;&#34892;&#26356;&#28145;&#20837;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#19968;&#33324;&#30446;&#26631;&#65292;&#31216;&#20026;&#936;PO&#65292;&#29992;&#20110;&#20174;&#20154;&#31867;&#20559;&#22909;&#20013;&#23398;&#20064;&#65292;&#35813;&#30446;&#26631;&#20197;&#25104;&#23545;&#20559;&#22909;&#30340;&#24418;&#24335;&#34920;&#36798;&#65292;&#22240;&#27492;&#32469;&#36807;&#20102;&#36825;&#20004;&#20010;&#36817;&#20284;&#12290;&#36825;&#20010;&#26032;&#30340;&#19968;&#33324;&#30446;&#26631;&#20351;&#25105;&#20204;&#33021;&#22815;&#36827;&#34892;&#19968;&#31181;&#26032;&#30340;&#20174;&#35757;&#32451;&#25968;&#25454;&#30452;&#25509;&#23398;&#20064;&#31574;&#30053;&#30340;&#26041;&#27861;&#32780;&#26080;&#38656;&#36827;&#34892;&#22870;&#21169;&#27169;&#22411;&#30340;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
The prevalent deployment of learning from human preferences through reinforcement learning (RLHF) relies on two important approximations: the first assumes that pairwise preferences can be substituted with pointwise rewards. The second assumes that a reward model trained on these pointwise rewards can generalize from collected data to out-of-distribution data sampled by the policy. Recently, Direct Preference Optimisation (DPO) has been proposed as an approach that bypasses the second approximation and learn directly a policy from collected data without the reward modelling stage. However, this method still heavily relies on the first approximation.  In this paper we try to gain a deeper theoretical understanding of these practical algorithms. In particular we derive a new general objective called $\Psi$PO for learning from human preferences that is expressed in terms of pairwise preferences and therefore bypasses both approximations. This new general objective allows us to perform an 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CoDrug&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#21644;&#26680;&#23494;&#24230;&#20272;&#35745;&#26469;&#35299;&#20915;&#21327;&#21464;&#37327;&#20559;&#31227;&#38382;&#39064;&#65292;&#20174;&#32780;&#23454;&#29616;&#19968;&#33268;&#24615;&#33647;&#29289;&#23646;&#24615;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2310.12033</link><description>&lt;p&gt;
&#22312;&#21327;&#21464;&#37327;&#20559;&#31227;&#19979;&#20351;&#29992;&#23494;&#24230;&#20272;&#35745;&#36827;&#34892;&#19968;&#33268;&#24615;&#33647;&#29289;&#23646;&#24615;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Conformal Drug Property Prediction with Density Estimation under Covariate Shift. (arXiv:2310.12033v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12033
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CoDrug&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#21644;&#26680;&#23494;&#24230;&#20272;&#35745;&#26469;&#35299;&#20915;&#21327;&#21464;&#37327;&#20559;&#31227;&#38382;&#39064;&#65292;&#20174;&#32780;&#23454;&#29616;&#19968;&#33268;&#24615;&#33647;&#29289;&#23646;&#24615;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#33647;&#29289;&#21457;&#29616;&#20013;&#65292;&#36890;&#36807;&#35745;&#31639;&#27169;&#22411;&#30830;&#35748;&#33647;&#21697;&#24615;&#36136;&#30340;&#39044;&#27979;&#38656;&#35201;&#36827;&#34892;&#26114;&#36149;&#30340;&#28287;&#23454;&#39564;&#12290;&#22240;&#27492;&#65292;&#33719;&#21462;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#23545;&#20110;&#20248;&#20808;&#36873;&#25321;&#33647;&#29289;&#20998;&#23376;&#36827;&#34892;&#21518;&#32493;&#23454;&#39564;&#39564;&#35777;&#33267;&#20851;&#37325;&#35201;&#12290;&#19968;&#33268;&#24615;&#39044;&#27979;&#26159;&#19968;&#31181;&#26377;&#20445;&#35777;&#35206;&#30422;&#29575;&#30340;&#20026;&#20998;&#23376;&#24615;&#36136;&#21019;&#24314;&#39044;&#27979;&#38598;&#30340;&#26377;&#24076;&#26395;&#30340;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#22312;&#33647;&#29289;&#21457;&#29616;&#20219;&#21153;&#20013;&#65292;&#19968;&#33268;&#24615;&#39044;&#27979;&#30340;&#20132;&#25442;&#24615;&#20551;&#35774;&#24448;&#24448;&#20250;&#21463;&#21040;&#21327;&#21464;&#37327;&#20559;&#31227;&#30340;&#25361;&#25112;&#65306;&#22823;&#22810;&#25968;&#25968;&#25454;&#38598;&#21253;&#21547;&#26377;&#38480;&#30340;&#26631;&#35760;&#25968;&#25454;&#65292;&#36825;&#20123;&#25968;&#25454;&#21487;&#33021;&#19981;&#36275;&#20197;&#20195;&#34920;&#20174;&#20013;&#25552;&#21462;&#20998;&#23376;&#30340;&#24222;&#22823;&#21270;&#23398;&#31354;&#38388;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#31216;&#20026;CoDrug&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#21033;&#29992;&#35757;&#32451;&#25968;&#25454;&#21644;&#26080;&#26631;&#35760;&#25968;&#25454;&#65292;&#24182;&#20351;&#29992;&#26680;&#23494;&#24230;&#20272;&#35745;&#26469;&#35780;&#20272;&#20998;&#23376;&#38598;&#21512;&#30340;&#23494;&#24230;&#12290;&#28982;&#21518;&#65292;&#21033;&#29992;&#20272;&#35745;&#30340;&#23494;&#24230;&#26469;&#21152;&#26435;&#20998;&#23376;&#26679;&#26412;&#20197;&#26500;&#24314;&#39044;&#27979;&#38598;&#24182;&#20462;&#27491;&#20197;&#19979;&#30340;
&lt;/p&gt;
&lt;p&gt;
In drug discovery, it is vital to confirm the predictions of pharmaceutical properties from computational models using costly wet-lab experiments. Hence, obtaining reliable uncertainty estimates is crucial for prioritizing drug molecules for subsequent experimental validation. Conformal Prediction (CP) is a promising tool for creating such prediction sets for molecular properties with a coverage guarantee. However, the exchangeability assumption of CP is often challenged with covariate shift in drug discovery tasks: Most datasets contain limited labeled data, which may not be representative of the vast chemical space from which molecules are drawn. To address this limitation, we propose a method called CoDrug that employs an energy-based model leveraging both training data and unlabelled data, and Kernel Density Estimation (KDE) to assess the densities of a molecule set. The estimated densities are then used to weigh the molecule samples while building prediction sets and rectifying fo
&lt;/p&gt;</description></item><item><title>LMC&#22810;&#20219;&#21153;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#31934;&#30830;&#35299;&#20915;&#26041;&#26696;&#34920;&#26126;&#65292;&#21482;&#38656;&#23545;&#22122;&#22768;&#27169;&#22411;&#36827;&#34892;&#28201;&#21644;&#20551;&#35774;&#65292;&#21363;&#21487;&#23454;&#29616;&#39640;&#25928;&#35745;&#31639;&#12290;&#36890;&#36807;&#24341;&#20837;&#23436;&#25972;&#21442;&#25968;&#21270;&#30340;&#8220;&#25237;&#24433;LMC&#8221;&#27169;&#22411;&#21644;&#36793;&#32536;&#20284;&#28982;&#20989;&#25968;&#34920;&#36798;&#24335;&#65292;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30456;&#23545;&#20110;&#26410;&#32463;&#22788;&#29702;&#30340;&#26041;&#27861;&#30340;&#20248;&#24322;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.12032</link><description>&lt;p&gt;
LMC&#22810;&#20219;&#21153;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#31934;&#30830;&#21644;&#39640;&#25928;&#35299;&#20915;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Exact and efficient solutions of the LMC Multitask Gaussian Process model. (arXiv:2310.12032v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12032
&lt;/p&gt;
&lt;p&gt;
LMC&#22810;&#20219;&#21153;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#31934;&#30830;&#35299;&#20915;&#26041;&#26696;&#34920;&#26126;&#65292;&#21482;&#38656;&#23545;&#22122;&#22768;&#27169;&#22411;&#36827;&#34892;&#28201;&#21644;&#20551;&#35774;&#65292;&#21363;&#21487;&#23454;&#29616;&#39640;&#25928;&#35745;&#31639;&#12290;&#36890;&#36807;&#24341;&#20837;&#23436;&#25972;&#21442;&#25968;&#21270;&#30340;&#8220;&#25237;&#24433;LMC&#8221;&#27169;&#22411;&#21644;&#36793;&#32536;&#20284;&#28982;&#20989;&#25968;&#34920;&#36798;&#24335;&#65292;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30456;&#23545;&#20110;&#26410;&#32463;&#22788;&#29702;&#30340;&#26041;&#27861;&#30340;&#20248;&#24322;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32447;&#24615;&#20849;&#21516;&#20851;&#32852;&#27169;&#22411;&#65288;LMC&#65289;&#26159;&#19968;&#31181;&#38750;&#24120;&#36890;&#29992;&#30340;&#22810;&#20219;&#21153;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#29992;&#20110;&#22238;&#24402;&#25110;&#20998;&#31867;&#12290;&#34429;&#28982;&#20854;&#34920;&#36798;&#33021;&#21147;&#21644;&#27010;&#24565;&#31616;&#21333;&#24615;&#24456;&#26377;&#21560;&#24341;&#21147;&#65292;&#20294;&#26420;&#32032;&#23454;&#29616;&#22312;&#25968;&#25454;&#28857;&#25968;&#37327;&#21644;&#20219;&#21153;&#25968;&#37327;&#26041;&#38754;&#20855;&#26377;&#31435;&#26041;&#22797;&#26434;&#24230;&#65292;&#20351;&#24471;&#23545;&#22823;&#22810;&#25968;&#24212;&#29992;&#26469;&#35828;&#65292;&#24517;&#39035;&#36827;&#34892;&#36817;&#20284;&#22788;&#29702;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#26576;&#20123;&#26465;&#20214;&#19979;&#65292;&#35813;&#27169;&#22411;&#30340;&#28508;&#22312;&#36807;&#31243;&#21487;&#20197;&#35299;&#32806;&#65292;&#23548;&#33268;&#20165;&#19982;&#25152;&#36848;&#36807;&#31243;&#25968;&#37327;&#21576;&#32447;&#24615;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#22312;&#36825;&#37324;&#25193;&#23637;&#20102;&#36825;&#20123;&#32467;&#26524;&#65292;&#20174;&#26368;&#19968;&#33324;&#30340;&#20551;&#35774;&#20013;&#23637;&#31034;&#20102;&#22312;LMC&#30340;&#39640;&#25928;&#31934;&#30830;&#35745;&#31639;&#25152;&#38656;&#30340;&#21807;&#19968;&#26465;&#20214;&#26159;&#23545;&#22122;&#22768;&#27169;&#22411;&#36827;&#34892;&#28201;&#21644;&#20551;&#35774;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#32467;&#26524;&#30340;&#23436;&#25972;&#21442;&#25968;&#21270;&#8220;&#25237;&#24433;LMC&#8221;&#27169;&#22411;&#65292;&#24182;&#32473;&#20986;&#20102;&#36793;&#32536;&#20284;&#28982;&#20989;&#25968;&#30340;&#34920;&#36798;&#24335;&#65292;&#20197;&#23454;&#29616;&#39640;&#25928;&#30340;&#20248;&#21270;&#12290;&#25105;&#20204;&#23545;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#20102;&#21442;&#25968;&#30740;&#31350;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30456;&#23545;&#20110;&#26410;&#32463;&#22788;&#29702;&#30340;&#26041;&#27861;&#30340;&#20248;&#24322;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Linear Model of Co-regionalization (LMC) is a very general model of multitask gaussian process for regression or classification. While its expressivity and conceptual simplicity are appealing, naive implementations have cubic complexity in the number of datapoints and number of tasks, making approximations mandatory for most applications. However, recent work has shown that under some conditions the latent processes of the model can be decoupled, leading to a complexity that is only linear in the number of said processes. We here extend these results, showing from the most general assumptions that the only condition necessary to an efficient exact computation of the LMC is a mild hypothesis on the noise model. We introduce a full parametrization of the resulting \emph{projected LMC} model, and an expression of the marginal likelihood enabling efficient optimization. We perform a parametric study on synthetic data to show the excellent performance of our approach, compared to an unr
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#26080;&#21442;&#25968;&#31163;&#25955;&#36873;&#25321;&#23454;&#39564;&#19982;&#26426;&#22120;&#23398;&#20064;&#24341;&#23548;&#30340;&#33258;&#36866;&#24212;&#35774;&#35745;&#26041;&#27861;GBS&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#26500;&#24314;&#37197;&#23545;&#27604;&#36739;&#38382;&#39064;&#26469;&#28385;&#36275;&#28040;&#36153;&#32773;&#30340;&#20559;&#22909;&#65292;&#19981;&#38656;&#35201;&#21442;&#25968;&#21270;&#25928;&#29992;&#27169;&#22411;&#65292;&#21487;&#20197;&#25193;&#23637;&#21040;&#20855;&#26377;&#25968;&#30334;&#20010;&#23646;&#24615;&#30340;&#20135;&#21697;&#65292;&#24182;&#22312;&#20934;&#30830;&#24615;&#21644;&#26679;&#26412;&#25928;&#29575;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2310.12026</link><description>&lt;p&gt;
&#26080;&#21442;&#25968;&#31163;&#25955;&#36873;&#25321;&#23454;&#39564;&#19982;&#26426;&#22120;&#23398;&#20064;&#24341;&#23548;&#30340;&#33258;&#36866;&#24212;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Nonparametric Discrete Choice Experiments with Machine Learning Guided Adaptive Design. (arXiv:2310.12026v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12026
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#26080;&#21442;&#25968;&#31163;&#25955;&#36873;&#25321;&#23454;&#39564;&#19982;&#26426;&#22120;&#23398;&#20064;&#24341;&#23548;&#30340;&#33258;&#36866;&#24212;&#35774;&#35745;&#26041;&#27861;GBS&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#26500;&#24314;&#37197;&#23545;&#27604;&#36739;&#38382;&#39064;&#26469;&#28385;&#36275;&#28040;&#36153;&#32773;&#30340;&#20559;&#22909;&#65292;&#19981;&#38656;&#35201;&#21442;&#25968;&#21270;&#25928;&#29992;&#27169;&#22411;&#65292;&#21487;&#20197;&#25193;&#23637;&#21040;&#20855;&#26377;&#25968;&#30334;&#20010;&#23646;&#24615;&#30340;&#20135;&#21697;&#65292;&#24182;&#22312;&#20934;&#30830;&#24615;&#21644;&#26679;&#26412;&#25928;&#29575;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#28385;&#36275;&#28040;&#36153;&#32773;&#30340;&#20559;&#22909;&#65292;&#35774;&#35745;&#20135;&#21697;&#23545;&#20110;&#20225;&#19994;&#30340;&#25104;&#21151;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#26799;&#24230;&#30340;&#35843;&#26597;&#65288;GBS&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#22810;&#23646;&#24615;&#20135;&#21697;&#35774;&#35745;&#30340;&#31163;&#25955;&#36873;&#25321;&#23454;&#39564;&#12290;&#35813;&#23454;&#39564;&#36890;&#36807;&#19968;&#31995;&#21015;&#38024;&#23545;&#37096;&#20998;&#37197;&#32622;&#36827;&#34892;&#30340;&#37197;&#23545;&#27604;&#36739;&#26469;&#33719;&#21462;&#28040;&#36153;&#32773;&#30340;&#20559;&#22909;&#12290;GBS&#26681;&#25454;&#21463;&#35775;&#32773;&#30340;&#20808;&#21069;&#36873;&#25321;&#33258;&#36866;&#24212;&#22320;&#26500;&#24314;&#37197;&#23545;&#27604;&#36739;&#38382;&#39064;&#12290;&#19982;&#20256;&#32479;&#30340;&#38543;&#26426;&#25928;&#29992;&#26368;&#22823;&#21270;&#33539;&#24335;&#19981;&#21516;&#65292;GBS&#19981;&#38656;&#35201;&#21442;&#25968;&#21270;&#25928;&#29992;&#27169;&#22411;&#65292;&#22240;&#27492;&#23545;&#27169;&#22411;&#35268;&#33539;&#38169;&#35823;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#36890;&#36807;&#23558;&#26426;&#22120;&#23398;&#20064;&#21644;&#23454;&#39564;&#35774;&#35745;&#30456;&#32467;&#21512;&#65292;GBS&#21487;&#25193;&#23637;&#21040;&#20855;&#26377;&#25968;&#30334;&#20010;&#23646;&#24615;&#30340;&#20135;&#21697;&#65292;&#24182;&#19988;&#21487;&#20197;&#20026;&#24322;&#36136;&#28040;&#36153;&#32773;&#35774;&#35745;&#20010;&#24615;&#21270;&#20135;&#21697;&#12290;&#25105;&#20204;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#20102;GBS&#30456;&#27604;&#20110;&#29616;&#26377;&#30340;&#21442;&#25968;&#21270;&#21644;&#38750;&#21442;&#25968;&#21270;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;&#26679;&#26412;&#25928;&#29575;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Designing products to meet consumers' preferences is essential for a business's success. We propose the Gradient-based Survey (GBS), a discrete choice experiment for multiattribute product design. The experiment elicits consumer preferences through a sequence of paired comparisons for partial profiles. GBS adaptively constructs paired comparison questions based on the respondents' previous choices. Unlike the traditional random utility maximization paradigm, GBS is robust to model misspecification by not requiring a parametric utility model. Cross-pollinating the machine learning and experiment design, GBS is scalable to products with hundreds of attributes and can design personalized products for heterogeneous consumers. We demonstrate the advantage of GBS in accuracy and sample efficiency compared to the existing parametric and nonparametric methods in simulations.
&lt;/p&gt;</description></item><item><title>&#36830;&#32493;&#23398;&#20064;&#20013;&#30340;&#36125;&#21494;&#26031;&#27969;&#32593;&#32476;&#65288;BFNs&#65289;&#26159;&#19968;&#31181;&#20855;&#26377;&#36890;&#29992;&#29983;&#25104;&#24314;&#27169;&#33021;&#21147;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#31070;&#32463;&#32593;&#32476;&#21644;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#22312;&#38750;&#31283;&#24577;&#25968;&#25454;&#19978;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.12001</link><description>&lt;p&gt;
&#36830;&#32493;&#23398;&#20064;&#20013;&#30340;&#36125;&#21494;&#26031;&#27969;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Bayesian Flow Networks in Continual Learning. (arXiv:2310.12001v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12001
&lt;/p&gt;
&lt;p&gt;
&#36830;&#32493;&#23398;&#20064;&#20013;&#30340;&#36125;&#21494;&#26031;&#27969;&#32593;&#32476;&#65288;BFNs&#65289;&#26159;&#19968;&#31181;&#20855;&#26377;&#36890;&#29992;&#29983;&#25104;&#24314;&#27169;&#33021;&#21147;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#31070;&#32463;&#32593;&#32476;&#21644;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#22312;&#38750;&#31283;&#24577;&#25968;&#25454;&#19978;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#36125;&#21494;&#26031;&#27969;&#32593;&#32476;&#65288;BFNs&#65289;&#34987;&#25552;&#20986;&#20316;&#20026;&#36890;&#29992;&#29983;&#25104;&#24314;&#27169;&#20013;&#38750;&#24120;&#26377;&#21069;&#26223;&#30340;&#26041;&#21521;&#20043;&#19968;&#65292;&#20855;&#26377;&#23398;&#20064;&#20219;&#20309;&#25968;&#25454;&#31867;&#22411;&#30340;&#33021;&#21147;&#12290;&#20182;&#20204;&#30340;&#24378;&#22823;&#20043;&#22788;&#22312;&#20110;&#31070;&#32463;&#32593;&#32476;&#21644;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#20351;&#23427;&#20204;&#36866;&#29992;&#20110;&#36830;&#32493;&#23398;&#20064;&#30340;&#32972;&#26223;&#19979;&#12290;&#25105;&#20204;&#28145;&#20837;&#30740;&#31350;&#20102;BFNs&#30340;&#26426;&#21046;&#65292;&#24182;&#36827;&#34892;&#23454;&#39564;&#35777;&#23454;&#20102;&#23427;&#22312;&#38750;&#31283;&#24577;&#25968;&#25454;&#19978;&#30340;&#29983;&#25104;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian Flow Networks (BFNs) has been recently proposed as one of the most promising direction to universal generative modelling, having ability to learn any of the data type. Their power comes from the expressiveness of neural networks and Bayesian inference which make them suitable in the context of continual learning. We delve into the mechanics behind BFNs and conduct the experiments to empirically verify the generative capabilities on non-stationary data.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#25991;&#31456;&#20171;&#32461;&#20102;&#29992;&#20110;&#28508;&#22312;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#20013;&#30340;Vecchia-Laplace&#36817;&#20284;&#27861;&#30340;&#36845;&#20195;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;Cholesky&#20998;&#35299;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#21152;&#24555;&#35745;&#31639;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.12000</link><description>&lt;p&gt;
Vecchia-Laplace&#36817;&#20284;&#27861;&#22312;&#28508;&#22312;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#20013;&#30340;&#36845;&#20195;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Iterative Methods for Vecchia-Laplace Approximations for Latent Gaussian Process Models. (arXiv:2310.12000v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12000
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#25991;&#31456;&#20171;&#32461;&#20102;&#29992;&#20110;&#28508;&#22312;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#20013;&#30340;Vecchia-Laplace&#36817;&#20284;&#27861;&#30340;&#36845;&#20195;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;Cholesky&#20998;&#35299;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#21152;&#24555;&#35745;&#31639;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28508;&#22312;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#27169;&#22411;&#26159;&#28789;&#27963;&#30340;&#27010;&#29575;&#38750;&#21442;&#25968;&#20989;&#25968;&#27169;&#22411;&#12290;Vecchia&#36817;&#20284;&#26159;&#29992;&#20110;&#20811;&#26381;&#22823;&#25968;&#25454;&#35745;&#31639;&#29942;&#39048;&#30340;&#20934;&#30830;&#36817;&#20284;&#26041;&#27861;&#65292;Laplace&#36817;&#20284;&#26159;&#19968;&#31181;&#24555;&#36895;&#26041;&#27861;&#65292;&#21487;&#20197;&#36817;&#20284;&#38750;&#39640;&#26031;&#20284;&#28982;&#20989;&#25968;&#30340;&#36793;&#32536;&#20284;&#28982;&#21644;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#65292;&#24182;&#20855;&#26377;&#28176;&#36817;&#25910;&#25947;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#24403;&#19982;&#30452;&#25509;&#27714;&#35299;&#26041;&#27861;&#65288;&#22914;Cholesky&#20998;&#35299;&#65289;&#32467;&#21512;&#20351;&#29992;&#26102;&#65292;Vecchia-Laplace&#36817;&#20284;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#22686;&#38271;&#36229;&#32447;&#24615;&#22320;&#38543;&#26679;&#26412;&#22823;&#23567;&#22686;&#21152;&#12290;&#22240;&#27492;&#65292;&#19982;Vecchia-Laplace&#36817;&#20284;&#35745;&#31639;&#30456;&#20851;&#30340;&#36816;&#31639;&#22312;&#36890;&#24120;&#24773;&#20917;&#19979;&#26159;&#26368;&#20934;&#30830;&#30340;&#22823;&#22411;&#25968;&#25454;&#38598;&#26102;&#20250;&#21464;&#24471;&#38750;&#24120;&#32531;&#24930;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#31181;&#29992;&#20110;Vecchia-Laplace&#36817;&#20284;&#25512;&#26029;&#30340;&#36845;&#20195;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#22522;&#20110;Cholesky&#30340;&#35745;&#31639;&#65292;&#21487;&#20197;&#22823;&#22823;&#21152;&#24555;&#35745;&#31639;&#36895;&#24230;&#12290;&#25105;&#20204;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Latent Gaussian process (GP) models are flexible probabilistic non-parametric function models. Vecchia approximations are accurate approximations for GPs to overcome computational bottlenecks for large data, and the Laplace approximation is a fast method with asymptotic convergence guarantees to approximate marginal likelihoods and posterior predictive distributions for non-Gaussian likelihoods. Unfortunately, the computational complexity of combined Vecchia-Laplace approximations grows faster than linearly in the sample size when used in combination with direct solver methods such as the Cholesky decomposition. Computations with Vecchia-Laplace approximations thus become prohibitively slow precisely when the approximations are usually the most accurate, i.e., on large data sets. In this article, we present several iterative methods for inference with Vecchia-Laplace approximations which make computations considerably faster compared to Cholesky-based calculations. We analyze our propo
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#32852;&#21512;&#23376;&#31354;&#38388;&#20272;&#35745;&#20174;&#31070;&#32463;&#32593;&#32476;&#34920;&#31034;&#20013;&#28040;&#38500;&#38169;&#35823;&#27010;&#24565;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#24182;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.11991</link><description>&lt;p&gt;
&#36890;&#36807;&#32852;&#21512;&#23376;&#31354;&#38388;&#20272;&#35745;&#28040;&#38500;&#31070;&#32463;&#32593;&#32476;&#34920;&#31034;&#20013;&#30340;&#38169;&#35823;&#27010;&#24565;
&lt;/p&gt;
&lt;p&gt;
Removing Spurious Concepts from Neural Network Representations via Joint Subspace Estimation. (arXiv:2310.11991v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11991
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#32852;&#21512;&#23376;&#31354;&#38388;&#20272;&#35745;&#20174;&#31070;&#32463;&#32593;&#32476;&#34920;&#31034;&#20013;&#28040;&#38500;&#38169;&#35823;&#27010;&#24565;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#24182;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#38169;&#35823;&#30456;&#20851;&#24615;&#32463;&#24120;&#20250;&#24433;&#21709;&#21040;&#27169;&#22411;&#22312;&#26679;&#26412;&#22806;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#24120;&#35265;&#30340;&#31574;&#30053;&#26159;&#36890;&#36807;&#20174;&#31070;&#32463;&#32593;&#32476;&#34920;&#31034;&#20013;&#28040;&#38500;&#38169;&#35823;&#27010;&#24565;&#26469;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#12290;&#29616;&#26377;&#30340;&#38169;&#35823;&#27010;&#24565;&#28040;&#38500;&#26041;&#27861;&#24448;&#24448;&#36807;&#20110;&#28608;&#36827;&#65292;&#19981;&#32463;&#24847;&#38388;&#20250;&#28040;&#38500;&#19982;&#27169;&#22411;&#20027;&#35201;&#20219;&#21153;&#30456;&#20851;&#30340;&#29305;&#24449;&#65292;&#20174;&#32780;&#24433;&#21709;&#27169;&#22411;&#24615;&#33021;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36845;&#20195;&#31639;&#27861;&#65292;&#36890;&#36807;&#20849;&#21516;&#35782;&#21035;&#31070;&#32463;&#32593;&#32476;&#34920;&#31034;&#20013;&#30340;&#20004;&#20010;&#20302;&#32500;&#27491;&#20132;&#23376;&#31354;&#38388;&#26469;&#20998;&#31163;&#38169;&#35823;&#21644;&#20027;&#35201;&#20219;&#21153;&#30340;&#27010;&#24565;&#12290;&#25105;&#20204;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#65288;Waterbirds&#65292;CelebA&#65289;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;MultiNLI&#65289;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#35813;&#31639;&#27861;&#65292;&#24182;&#34920;&#26126;&#23427;&#20248;&#20110;&#29616;&#26377;&#30340;&#27010;&#24565;&#28040;&#38500;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Out-of-distribution generalization in neural networks is often hampered by spurious correlations. A common strategy is to mitigate this by removing spurious concepts from the neural network representation of the data. Existing concept-removal methods tend to be overzealous by inadvertently eliminating features associated with the main task of the model, thereby harming model performance. We propose an iterative algorithm that separates spurious from main-task concepts by jointly identifying two low-dimensional orthogonal subspaces in the neural network representation. We evaluate the algorithm on benchmark datasets for computer vision (Waterbirds, CelebA) and natural language processing (MultiNLI), and show that it outperforms existing concept removal methods
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#38480;&#26102;&#38388;&#35270;&#35282;&#19979;&#30340;&#20027;&#21160;&#27700;&#24179;&#38598;&#20272;&#35745;&#26041;&#27861;&#65292;&#22312;&#19968;&#32500;&#21644;&#39640;&#32500;&#24773;&#20917;&#19979;&#22343;&#34920;&#29616;&#20986;&#36739;&#39640;&#30340;&#25928;&#26524;&#65292;&#33021;&#22815;&#24179;&#34913;&#20272;&#35745;&#35823;&#24046;&#21644;&#24050;&#31227;&#21160;&#36317;&#31163;&#65292;&#20855;&#26377;&#25512;&#24191;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.11985</link><description>&lt;p&gt;
&#19968;&#31181;&#26377;&#38480;&#26102;&#38388;&#35270;&#35282;&#19979;&#30340;&#20027;&#21160;&#27700;&#24179;&#38598;&#20272;&#35745;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Finite-Horizon Approach to Active Level Set Estimation. (arXiv:2310.11985v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11985
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#38480;&#26102;&#38388;&#35270;&#35282;&#19979;&#30340;&#20027;&#21160;&#27700;&#24179;&#38598;&#20272;&#35745;&#26041;&#27861;&#65292;&#22312;&#19968;&#32500;&#21644;&#39640;&#32500;&#24773;&#20917;&#19979;&#22343;&#34920;&#29616;&#20986;&#36739;&#39640;&#30340;&#25928;&#26524;&#65292;&#33021;&#22815;&#24179;&#34913;&#20272;&#35745;&#35823;&#24046;&#21644;&#24050;&#31227;&#21160;&#36317;&#31163;&#65292;&#20855;&#26377;&#25512;&#24191;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#31354;&#38388;&#37319;&#26679;&#20013;&#36827;&#34892;&#20027;&#21160;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#29992;&#20110;&#27700;&#24179;&#38598;&#20272;&#35745;&#65288;LSE&#65289;&#12290;&#35813;&#38382;&#39064;&#30340;&#30446;&#26631;&#26159;&#23613;&#24555;&#23450;&#20301;&#25152;&#26377;&#31526;&#21512;&#32473;&#23450;&#38408;&#20540;&#19978;/&#19979;&#30340;&#24863;&#20852;&#36259;&#20989;&#25968;&#30340;&#21306;&#22495;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#38480;&#26102;&#38388;&#30340;&#25628;&#32034;&#36807;&#31243;&#65292;&#20197;&#22312;&#19968;&#32500;&#20013;&#25191;&#34892;LSE&#65292;&#21516;&#26102;&#22312;&#22266;&#23450;&#25968;&#37327;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#22320;&#24179;&#34913;&#26368;&#32456;&#20272;&#35745;&#35823;&#24046;&#21644;&#24050;&#31227;&#21160;&#30340;&#36317;&#31163;&#12290;&#36890;&#36807;&#35843;&#25972;&#21442;&#25968;&#26469;&#26435;&#34913;&#20272;&#35745;&#20934;&#30830;&#24615;&#21644;&#24050;&#31227;&#21160;&#30340;&#36317;&#31163;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#24471;&#20986;&#30340;&#20248;&#21270;&#38382;&#39064;&#21487;&#20197;&#38381;&#24335;&#27714;&#35299;&#65292;&#24182;&#19988;&#25152;&#24471;&#31574;&#30053;&#25512;&#24191;&#20102;&#29616;&#26377;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#27969;&#34892;&#30340;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#19979;&#20351;&#29992;&#36825;&#31181;&#26041;&#27861;&#26469;&#36827;&#34892;&#26356;&#39640;&#32500;&#24230;&#30340;&#27700;&#24179;&#38598;&#20272;&#35745;&#12290;&#23545;&#21512;&#25104;&#25968;&#25454;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#38543;&#30528;&#26053;&#34892;&#25104;&#26412;&#30340;&#22686;&#21152;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20197;&#38750;&#36845;&#20195;&#36317;&#31163;&#22788;&#29702;&#30340;&#33021;&#21147;&#20351;&#20854;&#33021;&#22815;&#26174;&#33879;&#25913;&#21892;&#24050;&#26377;&#26041;&#27861;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of active learning in the context of spatial sampling for level set estimation (LSE), where the goal is to localize all regions where a function of interest lies above/below a given threshold as quickly as possible. We present a finite-horizon search procedure to perform LSE in one dimension while optimally balancing both the final estimation error and the distance traveled for a fixed number of samples. A tuning parameter is used to trade off between the estimation accuracy and distance traveled. We show that the resulting optimization problem can be solved in closed form and that the resulting policy generalizes existing approaches to this problem. We then show how this approach can be used to perform level set estimation in higher dimensions under the popular Gaussian process model. Empirical results on synthetic data indicate that as the cost of travel increases, our method's ability to treat distance nonmyopically allows it to significantly improve on the s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#32452;&#32553;&#25918;&#26041;&#27861;&#65288;BVS&#65289;&#30340;&#20960;&#31181;&#25913;&#36827;&#26041;&#27861;&#65292;&#25506;&#32034;&#20102;&#20351;&#29992;&#26367;&#20195;&#25439;&#22833;&#20989;&#25968;&#21644;&#22522;&#20110;&#36755;&#20837;&#29305;&#24449;&#30340;&#20998;&#32452;&#26041;&#26696;&#26469;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#19968;&#33268;&#24615;&#21644;&#36866;&#24212;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.11978</link><description>&lt;p&gt;
&#21487;&#20197;&#36890;&#36807;&#20998;&#32452;&#32553;&#25918;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#19968;&#33268;&#24615;&#21644;&#36866;&#24212;&#24615;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can bin-wise scaling improve consistency and adaptivity of prediction uncertainty for machine learning regression ?. (arXiv:2310.11978v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11978
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#32452;&#32553;&#25918;&#26041;&#27861;&#65288;BVS&#65289;&#30340;&#20960;&#31181;&#25913;&#36827;&#26041;&#27861;&#65292;&#25506;&#32034;&#20102;&#20351;&#29992;&#26367;&#20195;&#25439;&#22833;&#20989;&#25968;&#21644;&#22522;&#20110;&#36755;&#20837;&#29305;&#24449;&#30340;&#20998;&#32452;&#26041;&#26696;&#26469;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#19968;&#33268;&#24615;&#21644;&#36866;&#24212;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#20998;&#32452;&#26041;&#24046;&#32553;&#25918;&#65288;BVS&#65289;&#34987;&#25552;&#20986;&#20316;&#20026;&#19968;&#31181;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#38382;&#39064;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#20107;&#21518;&#26657;&#20934;&#26041;&#27861;&#65292;&#33021;&#22815;&#27604;&#32479;&#19968;&#26041;&#24046;&#65288;&#25110;&#28201;&#24230;&#65289;&#32553;&#25918;&#26356;&#26377;&#25928;&#22320;&#36827;&#34892;&#26657;&#27491;&#12290;&#21407;&#22987;&#29256;&#26412;&#30340;BVS&#20351;&#29992;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#20998;&#32452;&#65292;&#26088;&#22312;&#25552;&#39640;&#26465;&#20214;&#19978;&#30340;&#26657;&#20934;&#24615;&#65292;&#21363;&#19968;&#33268;&#24615;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;BVS&#30340;&#20960;&#31181;&#25913;&#36827;&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#22312;&#25439;&#22833;&#20989;&#25968;&#21644;&#22522;&#20110;&#36755;&#20837;&#29305;&#24449;&#65288;X&#65289;&#30340;&#20998;&#32452;&#26041;&#26696;&#19978;&#36827;&#34892;&#25913;&#36827;&#65292;&#20197;&#25552;&#39640;&#36866;&#24212;&#24615;&#65292;&#21363;&#22312;&#32473;&#23450;X&#30340;&#26465;&#20214;&#19979;&#36827;&#34892;&#26657;&#20934;&#24615;&#12290;&#23558;BVS&#21450;&#20854;&#25913;&#36827;&#26041;&#26696;&#22312;&#39044;&#27979;&#21407;&#23376;&#21270;&#33021;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24615;&#33021;&#27979;&#35797;&#65292;&#24182;&#19982;&#20445;&#24207;&#22238;&#24402;&#30340;&#32467;&#26524;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Binwise Variance Scaling (BVS) has recently been proposed as a post hoc recalibration method for prediction uncertainties of machine learning regression problems that is able of more efficient corrections than uniform variance (or temperature) scaling. The original version of BVS uses uncertainty-based binning, which is aimed to improve calibration conditionally on uncertainty, i.e. consistency. I explore here several adaptations of BVS, in particular with alternative loss functions and a binning scheme based on an input-feature (X) in order to improve adaptivity, i.e. calibration conditional on X. The performances of BVS and its proposed variants are tested on a benchmark dataset for the prediction of atomization energies and compared to the results of isotonic regression.
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#19968;&#20010;&#21487;&#35299;&#37322;&#30340;&#29942;&#39048;&#65292;&#31216;&#20026;&#28388;&#27874;&#22120;&#32452;&#65288;FB&#65289;&#65292;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#32858;&#31867;&#30340;&#20809;&#35889;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;ISVAE&#65289;&#12290;&#36890;&#36807;&#32422;&#26463;VAE&#30340;&#36776;&#35782;&#33021;&#21147;&#65292;&#36825;&#20010;&#27169;&#22411;&#33021;&#22815;&#23398;&#20064;&#21040;&#20855;&#26377;&#22686;&#24378;&#21487;&#35299;&#37322;&#24615;&#21644;&#32858;&#31867;&#33021;&#21147;&#30340;&#26032;&#32534;&#30721;f_0&#65292;&#24182;&#21576;&#29616;&#20026;&#19968;&#20010;&#21160;&#24577;&#30340;&#20998;&#23618;&#26641;&#12290;&#21516;&#26102;&#65292;&#36824;&#25552;&#20986;&#20102;&#19982;&#28388;&#27874;&#22120;&#32452;&#32467;&#26500;&#23545;&#31216;&#23545;&#40784;&#30340;&#23450;&#21046;&#35299;&#30721;&#22120;&#32467;&#26500;&#65292;&#29992;&#20110;&#22788;&#29702;&#22797;&#26434;&#30340;&#25968;&#25454;&#37197;&#32622;&#12290;</title><link>http://arxiv.org/abs/2310.11940</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#20809;&#35889;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;ISVAE&#65289;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Interpretable Spectral Variational AutoEncoder (ISVAE) for time series clustering. (arXiv:2310.11940v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11940
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#19968;&#20010;&#21487;&#35299;&#37322;&#30340;&#29942;&#39048;&#65292;&#31216;&#20026;&#28388;&#27874;&#22120;&#32452;&#65288;FB&#65289;&#65292;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#32858;&#31867;&#30340;&#20809;&#35889;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;ISVAE&#65289;&#12290;&#36890;&#36807;&#32422;&#26463;VAE&#30340;&#36776;&#35782;&#33021;&#21147;&#65292;&#36825;&#20010;&#27169;&#22411;&#33021;&#22815;&#23398;&#20064;&#21040;&#20855;&#26377;&#22686;&#24378;&#21487;&#35299;&#37322;&#24615;&#21644;&#32858;&#31867;&#33021;&#21147;&#30340;&#26032;&#32534;&#30721;f_0&#65292;&#24182;&#21576;&#29616;&#20026;&#19968;&#20010;&#21160;&#24577;&#30340;&#20998;&#23618;&#26641;&#12290;&#21516;&#26102;&#65292;&#36824;&#25552;&#20986;&#20102;&#19982;&#28388;&#27874;&#22120;&#32452;&#32467;&#26500;&#23545;&#31216;&#23545;&#40784;&#30340;&#23450;&#21046;&#35299;&#30721;&#22120;&#32467;&#26500;&#65292;&#29992;&#20110;&#22788;&#29702;&#22797;&#26434;&#30340;&#25968;&#25454;&#37197;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#22909;&#30340;&#32534;&#30721;&#26159;&#20855;&#26377;&#21487;&#35299;&#37322;&#24615;&#30340;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;&#65292;&#22312;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#30340;&#21021;&#26399;&#24341;&#20837;&#20102;&#19968;&#20010;&#21487;&#35299;&#37322;&#30340;&#29942;&#39048;&#65292;&#31216;&#20026;&#28388;&#27874;&#22120;&#32452;&#65288;FB&#65289;&#12290;&#36825;&#31181;&#23433;&#25490;&#36843;&#20351;VAE&#20851;&#27880;&#36755;&#20837;&#20449;&#21495;&#20013;&#26368;&#26377;&#20449;&#24687;&#30340;&#29255;&#27573;&#65292;&#20419;&#36827;&#20102;&#26032;&#32534;&#30721;f_0&#30340;&#23398;&#20064;&#65292;&#20351;&#20854;&#22312;&#20256;&#32479;&#30340;&#28508;&#21464;&#37327;&#31354;&#38388;&#19978;&#20855;&#26377;&#22686;&#24378;&#30340;&#21487;&#35299;&#37322;&#24615;&#21644;&#32858;&#31867;&#33021;&#21147;&#12290;&#36890;&#36807;&#26377;&#24847;&#22320;&#32422;&#26463;VAE&#20351;&#29992;&#36825;&#20010;&#28388;&#27874;&#22120;&#32452;&#65292;&#25105;&#20204;&#26377;&#24847;&#22320;&#38480;&#21046;&#20102;&#23427;&#35775;&#38382;&#24191;&#27867;&#36755;&#20837;&#22495;&#20449;&#24687;&#30340;&#33021;&#21147;&#65292;&#20419;&#36827;&#20102;&#19968;&#20010;&#21487;&#36776;&#35782;&#12289;&#21487;&#20998;&#31163;&#19988;&#38477;&#20302;&#32500;&#24230;&#30340;&#32534;&#30721;&#30340;&#21457;&#23637;&#12290;f_0&#30340;&#36827;&#21270;&#23398;&#20064;&#36712;&#36857;&#36827;&#19968;&#27493;&#34920;&#29616;&#20026;&#19968;&#20010;&#21160;&#24577;&#30340;&#20998;&#23618;&#26641;&#65292;&#25552;&#20379;&#20102;&#23545;&#32858;&#31867;&#30456;&#20284;&#24615;&#30340;&#28145;&#21051;&#27934;&#23519;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#22788;&#29702;&#22797;&#26434;&#30340;&#25968;&#25454;&#37197;&#32622;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#19982;&#28388;&#27874;&#22120;&#32452;&#32467;&#26500;&#23545;&#31216;&#23545;&#40784;&#30340;&#23450;&#21046;&#35299;&#30721;&#22120;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
The best encoding is the one that is interpretable in nature. In this work, we introduce a novel model that incorporates an interpretable bottleneck-termed the Filter Bank (FB)-at the outset of a Variational Autoencoder (VAE). This arrangement compels the VAE to attend on the most informative segments of the input signal, fostering the learning of a novel encoding ${f_0}$ which boasts enhanced interpretability and clusterability over traditional latent spaces. By deliberately constraining the VAE with this FB, we intentionally constrict its capacity to access broad input domain information, promoting the development of an encoding that is discernible, separable, and of reduced dimensionality. The evolutionary learning trajectory of ${f_0}$ further manifests as a dynamic hierarchical tree, offering profound insights into cluster similarities. Additionally, for handling intricate data configurations, we propose a tailored decoder structure that is symmetrically aligned with FB's architec
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36864;&#28779;&#65288;&#38024;&#23545;&#39034;&#24207;&#33945;&#29305;&#21345;&#32599;; SMC&#65289;&#21644;&#29109;&#38236;&#20687;&#19979;&#38477;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#35777;&#26126;&#20102;&#36864;&#28779;SMC&#26159;&#24212;&#29992;&#20110;Kullback-Leibler&#65288;KL&#65289;&#25955;&#24230;&#30340;&#29109;&#38236;&#20687;&#19979;&#38477;&#30340;&#25968;&#20540;&#36817;&#20284;&#65292;&#24182;&#25552;&#20986;&#20102;&#25913;&#36827;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2310.11914</link><description>&lt;p&gt;
&#36864;&#28779;&#21644;&#29109;&#38236;&#20687;&#19979;&#38477;&#20043;&#38388;&#30340;&#32852;&#31995;
&lt;/p&gt;
&lt;p&gt;
A connection between Tempering and Entropic Mirror Descent. (arXiv:2310.11914v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11914
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36864;&#28779;&#65288;&#38024;&#23545;&#39034;&#24207;&#33945;&#29305;&#21345;&#32599;; SMC&#65289;&#21644;&#29109;&#38236;&#20687;&#19979;&#38477;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#35777;&#26126;&#20102;&#36864;&#28779;SMC&#26159;&#24212;&#29992;&#20110;Kullback-Leibler&#65288;KL&#65289;&#25955;&#24230;&#30340;&#29109;&#38236;&#20687;&#19979;&#38477;&#30340;&#25968;&#20540;&#36817;&#20284;&#65292;&#24182;&#25552;&#20986;&#20102;&#25913;&#36827;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#36864;&#28779;&#65288;&#38024;&#23545;&#39034;&#24207;&#33945;&#29305;&#21345;&#32599;; SMC&#65289;&#21644;&#29109;&#38236;&#20687;&#19979;&#38477;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#20197;&#20174;&#24050;&#30693;&#26410;&#24402;&#19968;&#21270;&#27010;&#29575;&#23494;&#24230;&#30340;&#30446;&#26631;&#27010;&#29575;&#20998;&#24067;&#20013;&#37319;&#26679;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36864;&#28779;SMC&#26159;&#24212;&#29992;&#20110;Kullback-Leibler&#65288;KL&#65289;&#25955;&#24230;&#30340;&#29109;&#38236;&#20687;&#19979;&#38477;&#30340;&#25968;&#20540;&#36817;&#20284;&#65292;&#24182;&#33719;&#24471;&#20102;&#36864;&#28779;&#36845;&#20195;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20174;&#20248;&#21270;&#35282;&#24230;&#25512;&#21160;&#20102;&#36864;&#28779;&#36845;&#20195;&#65292;&#34920;&#26126;&#36864;&#28779;&#21487;&#20197;&#29992;&#20316;Langevin&#31639;&#27861;&#30340;&#26367;&#20195;&#36873;&#25321;&#65292;&#20197;&#26368;&#23567;&#21270;KL&#25955;&#24230;&#12290;&#25105;&#20204;&#21033;&#29992;&#36864;&#28779;&#21644;&#38236;&#20687;&#19979;&#38477;&#36845;&#20195;&#20043;&#38388;&#30340;&#32852;&#31995;&#26469;&#35777;&#26126;SMC&#20013;&#24120;&#35265;&#30340;&#20570;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#25991;&#29486;&#20013;&#31639;&#27861;&#30340;&#25913;&#36827;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores the connections between tempering (for Sequential Monte Carlo; SMC) and entropic mirror descent to sample from a target probability distribution whose unnormalized density is known.  We establish that tempering SMC is a numerical approximation of entropic mirror descent applied to the Kullback-Leibler (KL) divergence and obtain convergence rates for the tempering iterates.  Our result motivates the tempering iterates from an optimization point of view, showing that tempering can be used as an alternative to Langevin-based algorithms to minimize the KL divergence.  We exploit the connection between tempering and mirror descent iterates to justify common practices in SMC and propose improvements to algorithms in literature.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#22810;&#26799;&#24230;&#19979;&#38477;&#65288;OMGD&#65289;&#31639;&#27861;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#20108;&#27425;&#21644;&#32447;&#24615;&#24320;&#20851;&#25104;&#26412;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#20854;&#31454;&#20105;&#27604;&#29575;&#19978;&#30028;&#65292;&#24182;&#22312;&#26377;&#38480;&#20449;&#24687;&#35774;&#32622;&#19979;&#36798;&#21040;&#20102;&#26368;&#20248;&#65288;&#25353;&#39034;&#24207;&#65289;&#30340;&#21160;&#24577;&#21518;&#24724;&#12290;</title><link>http://arxiv.org/abs/2310.11880</link><description>&lt;p&gt;
&#20855;&#26377;&#24320;&#20851;&#25104;&#26412;&#21644;&#24310;&#36831;&#26799;&#24230;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Online Convex Optimization with Switching Cost and Delayed Gradients. (arXiv:2310.11880v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11880
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#22810;&#26799;&#24230;&#19979;&#38477;&#65288;OMGD&#65289;&#31639;&#27861;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#20108;&#27425;&#21644;&#32447;&#24615;&#24320;&#20851;&#25104;&#26412;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#20854;&#31454;&#20105;&#27604;&#29575;&#19978;&#30028;&#65292;&#24182;&#22312;&#26377;&#38480;&#20449;&#24687;&#35774;&#32622;&#19979;&#36798;&#21040;&#20102;&#26368;&#20248;&#65288;&#25353;&#39034;&#24207;&#65289;&#30340;&#21160;&#24577;&#21518;&#24724;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#26377;&#38480;&#20449;&#24687;&#35774;&#32622;&#19979;&#20855;&#26377;&#20108;&#27425;&#21644;&#32447;&#24615;&#24320;&#20851;&#25104;&#26412;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#22312;&#36825;&#37324;&#22312;&#32447;&#31639;&#27861;&#20165;&#33021;&#21033;&#29992;&#20808;&#21069;&#30446;&#26631;&#20989;&#25968;&#30340;&#26799;&#24230;&#20449;&#24687;&#36827;&#34892;&#21160;&#20316;&#36873;&#25321;&#12290;&#23545;&#20110;$L$-&#20809;&#28369;&#21644;$\mu$-&#24378;&#20984;&#30446;&#26631;&#20989;&#25968;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#22810;&#26799;&#24230;&#19979;&#38477;&#65288;OMGD&#65289;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#35813;&#31639;&#27861;&#22312;&#20855;&#26377;&#20108;&#27425;&#24320;&#20851;&#25104;&#26412;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#38382;&#39064;&#19978;&#30340;&#31454;&#20105;&#27604;&#29575;&#26368;&#22810;&#20026;$4(L+5)+\frac{16(L+5)}{\mu}$&#12290;&#23545;&#20110;OMGD&#30340;&#31454;&#20105;&#27604;&#29575;&#19978;&#30028;&#20063;&#34987;&#35777;&#26126;&#22312;$L$&#21644;$\mu$&#26041;&#38754;&#26159;&#32039;&#33268;&#30340;&#12290;&#27492;&#22806;&#65292;&#24403;&#24320;&#20851;&#25104;&#26412;&#20026;&#20108;&#27425;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20219;&#20309;&#22312;&#32447;&#31639;&#27861;&#30340;&#31454;&#20105;&#27604;&#29575;&#26159;$\max\{\Omega(L), \Omega(\frac{L}{\sqrt{\mu}})\}$&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#22312;&#26377;&#38480;&#20449;&#24687;&#35774;&#32622;&#19979;&#65292;OMGD&#31639;&#27861;&#23454;&#29616;&#20102;&#26368;&#20248;&#65288;&#25353;&#39034;&#24207;&#65289;&#30340;&#21160;&#24577;&#21518;&#24724;&#12290;&#23545;&#20110;&#32447;&#24615;&#24320;&#20851;&#25104;&#26412;&#65292;
&lt;/p&gt;
&lt;p&gt;
We consider the online convex optimization (OCO) problem with quadratic and linear switching cost in the limited information setting, where an online algorithm can choose its action using only gradient information about the previous objective function. For $L$-smooth and $\mu$-strongly convex objective functions, we propose an online multiple gradient descent (OMGD) algorithm and show that its competitive ratio for the OCO problem with quadratic switching cost is at most $4(L + 5) + \frac{16(L + 5)}{\mu}$. The competitive ratio upper bound for OMGD is also shown to be order-wise tight in terms of $L,\mu$. In addition, we show that the competitive ratio of any online algorithm is $\max\{\Omega(L), \Omega(\frac{L}{\sqrt{\mu}})\}$ in the limited information setting when the switching cost is quadratic. We also show that the OMGD algorithm achieves the optimal (order-wise) dynamic regret in the limited information setting. For the linear switching cost, the competitive ratio upper bound of
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#32447;&#24615;&#20998;&#31867;&#22120;&#28151;&#21512;&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#35813;&#38382;&#39064;&#30340;&#32479;&#35745;&#26597;&#35810;&#65288;SQ&#65289;&#31639;&#27861;&#30340;&#22797;&#26434;&#24230;&#19979;&#30028;&#26159;$n^{\mathrm{poly}(1/\Delta) \log(r)}$&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#33021;&#20855;&#26377;&#29420;&#31435;&#20852;&#36259;&#30340;&#26032;&#29699;&#38754;&#35774;&#35745;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.11876</link><description>&lt;p&gt;
&#23398;&#20064;&#32447;&#24615;&#20998;&#31867;&#22120;&#28151;&#21512;&#30340;SQ&#19979;&#30028;
&lt;/p&gt;
&lt;p&gt;
SQ Lower Bounds for Learning Mixtures of Linear Classifiers. (arXiv:2310.11876v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11876
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#32447;&#24615;&#20998;&#31867;&#22120;&#28151;&#21512;&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#35813;&#38382;&#39064;&#30340;&#32479;&#35745;&#26597;&#35810;&#65288;SQ&#65289;&#31639;&#27861;&#30340;&#22797;&#26434;&#24230;&#19979;&#30028;&#26159;$n^{\mathrm{poly}(1/\Delta) \log(r)}$&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#33021;&#20855;&#26377;&#29420;&#31435;&#20852;&#36259;&#30340;&#26032;&#29699;&#38754;&#35774;&#35745;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#39640;&#26031;&#21327;&#21464;&#37327;&#19979;&#23398;&#20064;&#32447;&#24615;&#20998;&#31867;&#22120;&#28151;&#21512;&#30340;&#38382;&#39064;&#12290;&#32473;&#23450;&#23545;&#24418;&#24335;&#20026;$(\mathbf{x},y_{\ell})$&#30340;$n$&#32500;&#39640;&#26031;&#20998;&#24067;&#30340;$r$&#20010;&#28151;&#21512;&#20998;&#24067;&#26679;&#26412;&#35775;&#38382;&#26435;&#38480;&#65292;&#20854;&#20013;$\mathbf{x}\sim\mathcal{N}(0,\mathbf{I}_n)$&#65292;$y_\ell=\mathrm{sign}(\langle\mathbf{v}_\ell,\mathbf{x}\rangle)$&#65292;&#30446;&#26631;&#26159;&#20197;&#24635;&#21464;&#24322;&#36317;&#31163;&#23398;&#20064;&#28508;&#22312;&#30340;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#32479;&#35745;&#26597;&#35810;&#65288;SQ&#65289;&#30340;&#19979;&#30028;&#65292;&#34920;&#26126;&#23545;&#20110;&#36825;&#20010;&#38382;&#39064;&#30340;&#24050;&#30693;&#31639;&#27861;&#23454;&#38469;&#19978;&#26159;&#26368;&#22909;&#30340;&#65292;&#21363;&#20351;&#23545;&#20110;&#22343;&#21248;&#28151;&#21512;&#30340;&#29305;&#27530;&#24773;&#20917;&#20063;&#26159;&#22914;&#27492;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#35813;&#38382;&#39064;&#30340;&#20219;&#20309;SQ&#31639;&#27861;&#30340;&#22797;&#26434;&#24230;&#37117;&#26159;$n^{\mathrm{poly}(1/\Delta) \log(r)}$&#65292;&#20854;&#20013;$\Delta$&#26159;$\mathbf{v}_\ell$&#20043;&#38388;&#30340;&#20004;&#20004;$\ell_2$-&#20998;&#31163;&#30340;&#19979;&#30028;&#12290;&#25105;&#20204;&#32467;&#26524;&#30340;&#20851;&#38190;&#25216;&#26415;&#26500;&#24314;&#26159;&#19968;&#31181;&#21487;&#33021;&#20855;&#26377;&#29420;&#31435;&#20852;&#36259;&#30340;&#26032;&#29699;&#38754;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of learning mixtures of linear classifiers under Gaussian covariates. Given sample access to a mixture of $r$ distributions on $\mathbb{R}^n$ of the form $(\mathbf{x},y_{\ell})$, $\ell\in [r]$, where $\mathbf{x}\sim\mathcal{N}(0,\mathbf{I}_n)$ and $y_\ell=\mathrm{sign}(\langle\mathbf{v}_\ell,\mathbf{x}\rangle)$ for an unknown unit vector $\mathbf{v}_\ell$, the goal is to learn the underlying distribution in total variation distance. Our main result is a Statistical Query (SQ) lower bound suggesting that known algorithms for this problem are essentially best possible, even for the special case of uniform mixtures. In particular, we show that the complexity of any SQ algorithm for the problem is $n^{\mathrm{poly}(1/\Delta) \log(r)}$, where $\Delta$ is a lower bound on the pairwise $\ell_2$-separation between the $\mathbf{v}_\ell$'s. The key technical ingredient underlying our result is a new construction of spherical designs that may be of independent interest.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#21033;&#29992;&#21442;&#25968;&#24341;&#23548;&#31639;&#27861;&#30340;&#31561;&#21464;&#24418;&#24335;&#65292;&#21487;&#20197;&#22312;&#25104;&#20687;&#21453;&#38382;&#39064;&#20013;&#37327;&#21270;&#37325;&#26500;&#22270;&#20687;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#19988;&#21487;&#20197;&#19982;&#20219;&#20309;&#22270;&#20687;&#37325;&#24314;&#25216;&#26415;&#32467;&#21512;&#20351;&#29992;&#12290;</title><link>http://arxiv.org/abs/2310.11838</link><description>&lt;p&gt;
&#31561;&#21464;&#24341;&#23548;&#27861;&#22312;&#25104;&#20687;&#21453;&#38382;&#39064;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Equivariant Bootstrapping for Uncertainty Quantification in Imaging Inverse Problems. (arXiv:2310.11838v1 [eess.IV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11838
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#21033;&#29992;&#21442;&#25968;&#24341;&#23548;&#31639;&#27861;&#30340;&#31561;&#21464;&#24418;&#24335;&#65292;&#21487;&#20197;&#22312;&#25104;&#20687;&#21453;&#38382;&#39064;&#20013;&#37327;&#21270;&#37325;&#26500;&#22270;&#20687;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#19988;&#21487;&#20197;&#19982;&#20219;&#20309;&#22270;&#20687;&#37325;&#24314;&#25216;&#26415;&#32467;&#21512;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31185;&#23398;&#25104;&#20687;&#38382;&#39064;&#36890;&#24120;&#23384;&#22312;&#20005;&#37325;&#30340;&#19981;&#36866;&#23450;&#24615;&#65292;&#22240;&#27492;&#20855;&#26377;&#37325;&#35201;&#30340;&#20869;&#22312;&#19981;&#30830;&#23450;&#24615;&#12290;&#20934;&#30830;&#37327;&#21270;&#35299;&#20915;&#26041;&#26696;&#30340;&#19981;&#30830;&#23450;&#24615;&#23545;&#20110;&#20005;&#26684;&#35299;&#37322;&#23454;&#39564;&#32467;&#26524;&#20197;&#21450;&#21487;&#38752;&#22320;&#20351;&#29992;&#37325;&#26500;&#22270;&#20687;&#20316;&#20026;&#31185;&#23398;&#35777;&#25454;&#33267;&#20851;&#37325;&#35201;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#29616;&#26377;&#30340;&#25104;&#20687;&#26041;&#27861;&#26080;&#27861;&#20197;&#23545;&#23454;&#39564;&#37325;&#22797;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#26041;&#24335;&#37327;&#21270;&#37325;&#26500;&#22270;&#20687;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#22522;&#20110;&#21442;&#25968;&#24341;&#23548;&#31639;&#27861;&#30340;&#31561;&#21464;&#24418;&#24335;&#65292;&#21033;&#29992;&#22312;&#25104;&#20687;&#38382;&#39064;&#20013;&#24120;&#35265;&#30340;&#23545;&#31216;&#24615;&#21644;&#19981;&#21464;&#24615;&#29305;&#24615;&#12290;&#27492;&#22806;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#26159;&#36890;&#29992;&#30340;&#65292;&#21487;&#20197;&#36731;&#26494;&#22320;&#19982;&#20219;&#20309;&#22270;&#20687;&#37325;&#24314;&#25216;&#26415;&#32467;&#21512;&#20351;&#29992;&#65292;&#21253;&#25324;&#21482;&#33021;&#20174;&#35266;&#23519;&#25968;&#25454;&#20013;&#36827;&#34892;&#35757;&#32451;&#30340;&#26080;&#30417;&#30563;&#35757;&#32451;&#31574;&#30053;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#22312;&#21482;&#26377;&#35266;&#27979;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Scientific imaging problems are often severely ill-posed, and hence have significant intrinsic uncertainty. Accurately quantifying the uncertainty in the solutions to such problems is therefore critical for the rigorous interpretation of experimental results as well as for reliably using the reconstructed images as scientific evidence. Unfortunately, existing imaging methods are unable to quantify the uncertainty in the reconstructed images in a manner that is robust to experiment replications. This paper presents a new uncertainty quantification methodology based on an equivariant formulation of the parametric bootstrap algorithm that leverages symmetries and invariance properties commonly encountered in imaging problems. Additionally, the proposed methodology is general and can be easily applied with any image reconstruction technique, including unsupervised training strategies that can be trained from observed data alone, thus enabling uncertainty quantification in situations where 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25216;&#26415;&#65292;&#36890;&#36807;&#37325;&#26032;&#23450;&#20041;&#20248;&#21270;&#36807;&#31243;&#20026;&#38024;&#23545;&#26131;&#20110;&#35745;&#31639;&#33258;&#28982;&#26799;&#24230;&#30340;&#26367;&#20195;&#20998;&#24067;&#30340;&#21442;&#25968;&#20248;&#21270;&#26469;&#35299;&#20915;&#35745;&#31639;&#33258;&#28982;&#26799;&#24230;&#30340;&#25361;&#25112;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25193;&#23637;&#21487;&#24212;&#29992;&#33258;&#28982;&#26799;&#24230;&#30340;&#20998;&#24067;&#33539;&#22260;&#65292;&#36895;&#24230;&#24555;&#19988;&#26131;&#20110;&#23454;&#29616;&#12290;</title><link>http://arxiv.org/abs/2310.11837</link><description>&lt;p&gt;
&#20351;&#29992;&#33258;&#28982;&#26799;&#24230;&#26367;&#20195;&#21697;&#20248;&#21270;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Optimising Distributions with Natural Gradient Surrogates. (arXiv:2310.11837v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11837
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25216;&#26415;&#65292;&#36890;&#36807;&#37325;&#26032;&#23450;&#20041;&#20248;&#21270;&#36807;&#31243;&#20026;&#38024;&#23545;&#26131;&#20110;&#35745;&#31639;&#33258;&#28982;&#26799;&#24230;&#30340;&#26367;&#20195;&#20998;&#24067;&#30340;&#21442;&#25968;&#20248;&#21270;&#26469;&#35299;&#20915;&#35745;&#31639;&#33258;&#28982;&#26799;&#24230;&#30340;&#25361;&#25112;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25193;&#23637;&#21487;&#24212;&#29992;&#33258;&#28982;&#26799;&#24230;&#30340;&#20998;&#24067;&#33539;&#22260;&#65292;&#36895;&#24230;&#24555;&#19988;&#26131;&#20110;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#28982;&#26799;&#24230;&#26041;&#27861;&#24050;&#32463;&#34987;&#29992;&#20110;&#20248;&#21270;&#21508;&#31181;&#24773;&#20917;&#19979;&#30340;&#27010;&#29575;&#20998;&#24067;&#21442;&#25968;&#65292;&#36890;&#24120;&#33021;&#24471;&#21040;&#24555;&#36895;&#25910;&#25947;&#30340;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#35768;&#22810;&#24863;&#20852;&#36259;&#30340;&#20998;&#24067;&#65292;&#35745;&#31639;&#33258;&#28982;&#26799;&#24230;&#23384;&#22312;&#19968;&#20123;&#25361;&#25112;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25216;&#26415;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#36825;&#28041;&#21450;&#23558;&#20248;&#21270;&#37325;&#26032;&#23450;&#20041;&#20026;&#20851;&#20110;&#26367;&#20195;&#20998;&#24067;&#21442;&#25968;&#30340;&#20248;&#21270;&#65292;&#35745;&#31639;&#33258;&#28982;&#26799;&#24230;&#24456;&#23481;&#26131;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#20960;&#20010;&#21487;&#20197;&#35299;&#37322;&#20026;&#24212;&#29992;&#36825;&#31181;&#25216;&#26415;&#30340;&#29616;&#26377;&#26041;&#27861;&#30340;&#20363;&#23376;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#20854;&#24212;&#29992;&#20110;&#21508;&#31181;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25193;&#23637;&#20102;&#21487;&#20197;&#26377;&#25928;&#20351;&#29992;&#33258;&#28982;&#26799;&#24230;&#30340;&#20998;&#24067;&#38598;&#21512;&#12290;&#27492;&#22806;&#65292;&#23427;&#24555;&#36895;&#12289;&#26131;&#20110;&#29702;&#35299;&#65292;&#21487;&#20197;&#20351;&#29992;&#26631;&#20934;&#30340;&#33258;&#21160;&#24494;&#20998;&#36719;&#20214;&#36827;&#34892;&#31616;&#21333;&#23454;&#29616;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#20887;&#38271;&#30340;&#27169;&#22411;&#29305;&#23450;&#23548;&#25968;&#35745;&#31639;&#12290;&#25105;&#20204;&#22312;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#21644;&#21464;&#20998;&#25512;&#26029;&#19978;&#28436;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Natural gradient methods have been used to optimise the parameters of probability distributions in a variety of settings, often resulting in fast-converging procedures. Unfortunately, for many distributions of interest, computing the natural gradient has a number of challenges. In this work we propose a novel technique for tackling such issues, which involves reframing the optimisation as one with respect to the parameters of a surrogate distribution, for which computing the natural gradient is easy. We give several examples of existing methods that can be interpreted as applying this technique, and propose a new method for applying it to a wide variety of problems. Our method expands the set of distributions that can be efficiently targeted with natural gradients. Furthermore, it is fast, easy to understand, simple to implement using standard autodiff software, and does not require lengthy model-specific derivations. We demonstrate our method on maximum likelihood estimation and varia
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#20013;&#26680;&#23398;&#20064;&#30340;&#20302;&#31209;&#35299;&#30340;&#24615;&#36136;&#12290;&#22312;&#21482;&#26377;&#20302;&#32500;&#23376;&#31354;&#38388;&#23545;&#21709;&#24212;&#21464;&#37327;&#26377;&#35299;&#37322;&#33021;&#21147;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#35813;&#26041;&#27861;&#21487;&#20197;&#33258;&#21160;&#24471;&#21040;&#31934;&#30830;&#30340;&#20302;&#31209;&#35299;&#65292;&#26080;&#38656;&#39069;&#22806;&#30340;&#27491;&#21017;&#21270;&#12290;</title><link>http://arxiv.org/abs/2310.11736</link><description>&lt;p&gt;
&#22312;Ridge&#22238;&#24402;&#20013;&#65292;&#26680;&#23398;&#20064;&#8220;&#33258;&#21160;&#8221;&#32473;&#20986;&#31934;&#30830;&#30340;&#20302;&#31209;&#35299;
&lt;/p&gt;
&lt;p&gt;
Kernel Learning in Ridge Regression "Automatically" Yields Exact Low Rank Solution. (arXiv:2310.11736v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11736
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#20013;&#26680;&#23398;&#20064;&#30340;&#20302;&#31209;&#35299;&#30340;&#24615;&#36136;&#12290;&#22312;&#21482;&#26377;&#20302;&#32500;&#23376;&#31354;&#38388;&#23545;&#21709;&#24212;&#21464;&#37327;&#26377;&#35299;&#37322;&#33021;&#21147;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#35813;&#26041;&#27861;&#21487;&#20197;&#33258;&#21160;&#24471;&#21040;&#31934;&#30830;&#30340;&#20302;&#31209;&#35299;&#65292;&#26080;&#38656;&#39069;&#22806;&#30340;&#27491;&#21017;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#24418;&#24335;&#20026;$(x,x') \mapsto \phi(\|x-x'\|^2_\Sigma)$&#19988;&#30001;&#21442;&#25968;$\Sigma$&#21442;&#25968;&#21270;&#30340;&#26680;&#20989;&#25968;&#12290;&#23545;&#20110;&#36825;&#26679;&#30340;&#26680;&#20989;&#25968;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#30340;&#21464;&#20307;&#65292;&#23427;&#21516;&#26102;&#20248;&#21270;&#20102;&#39044;&#27979;&#20989;&#25968;&#21644;&#20877;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;&#21442;&#25968;$\Sigma$&#12290;&#20174;&#36825;&#20010;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#20013;&#23398;&#21040;&#30340;$\Sigma$&#30340;&#29305;&#24449;&#31354;&#38388;&#21487;&#20197;&#21578;&#35785;&#25105;&#20204;&#21327;&#21464;&#37327;&#31354;&#38388;&#20013;&#21738;&#20123;&#26041;&#21521;&#23545;&#39044;&#27979;&#26159;&#37325;&#35201;&#30340;&#12290;&#20551;&#35774;&#21327;&#21464;&#37327;&#21482;&#36890;&#36807;&#20302;&#32500;&#23376;&#31354;&#38388;&#65288;&#20013;&#24515;&#22343;&#20540;&#23376;&#31354;&#38388;&#65289;&#23545;&#21709;&#24212;&#21464;&#37327;&#26377;&#38750;&#38646;&#30340;&#35299;&#37322;&#33021;&#21147;&#65292;&#25105;&#20204;&#21457;&#29616;&#26377;&#24456;&#39640;&#30340;&#27010;&#29575;&#19979;&#26377;&#38480;&#26679;&#26412;&#26680;&#23398;&#20064;&#30446;&#26631;&#30340;&#20840;&#23616;&#26368;&#23567;&#21270;&#32773;&#20063;&#26159;&#20302;&#31209;&#30340;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#26368;&#23567;&#21270;$\Sigma$&#30340;&#31209;&#26377;&#24456;&#39640;&#30340;&#27010;&#29575;&#34987;&#20013;&#24515;&#22343;&#20540;&#23376;&#31354;&#38388;&#30340;&#32500;&#24230;&#25152;&#38480;&#21046;&#12290;&#36825;&#20010;&#29616;&#35937;&#24456;&#26377;&#36259;&#65292;&#22240;&#20026;&#20302;&#31209;&#29305;&#24615;&#26159;&#22312;&#27809;&#26377;&#20351;&#29992;&#20219;&#20309;&#23545;$\Sigma$&#30340;&#26174;&#24335;&#27491;&#21017;&#21270;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#30340;&#65292;&#20363;&#22914;&#26680;&#33539;&#25968;&#27491;&#21017;&#21270;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider kernels of the form $(x,x') \mapsto \phi(\|x-x'\|^2_\Sigma)$ parametrized by $\Sigma$. For such kernels, we study a variant of the kernel ridge regression problem which simultaneously optimizes the prediction function and the parameter $\Sigma$ of the reproducing kernel Hilbert space. The eigenspace of the $\Sigma$ learned from this kernel ridge regression problem can inform us which directions in covariate space are important for prediction.  Assuming that the covariates have nonzero explanatory power for the response only through a low dimensional subspace (central mean subspace), we find that the global minimizer of the finite sample kernel learning objective is also low rank with high probability. More precisely, the rank of the minimizing $\Sigma$ is with high probability bounded by the dimension of the central mean subspace. This phenomenon is interesting because the low rankness property is achieved without using any explicit regularization of $\Sigma$, e.g., nuclear
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#35745;&#25968;&#25968;&#25454;&#30340;&#20027;&#39064;&#19987;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#24341;&#20837;&#20285;&#29595;&#38543;&#26426;&#25928;&#24212;&#26469;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#65292;&#24182;&#21516;&#26102;&#33719;&#24471;&#20102;&#22266;&#23450;&#21442;&#25968;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#21644;&#38543;&#26426;&#25928;&#24212;&#30340;&#26368;&#20339;&#26080;&#20559;&#39044;&#27979;&#22120;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#24555;&#36895;&#22788;&#29702;&#39640;&#22522;&#25968;&#20998;&#31867;&#29305;&#24449;&#30340;&#32858;&#31867;&#35745;&#25968;&#25968;&#25454;&#65292;&#24182;&#19988;&#21487;&#20197;&#36731;&#26494;&#23454;&#29616;&#26368;&#20808;&#36827;&#30340;&#32593;&#32476;&#26550;&#26500;&#12290;</title><link>http://arxiv.org/abs/2310.11654</link><description>&lt;p&gt;
&#38024;&#23545;&#20855;&#26377;&#39640;&#22522;&#25968;&#20998;&#31867;&#29305;&#24449;&#30340;&#35745;&#25968;&#25968;&#25454;&#30340;&#20027;&#39064;&#19987;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Subject-specific Deep Neural Networks for Count Data with High-cardinality Categorical Features. (arXiv:2310.11654v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11654
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#35745;&#25968;&#25968;&#25454;&#30340;&#20027;&#39064;&#19987;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#24341;&#20837;&#20285;&#29595;&#38543;&#26426;&#25928;&#24212;&#26469;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#65292;&#24182;&#21516;&#26102;&#33719;&#24471;&#20102;&#22266;&#23450;&#21442;&#25968;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#21644;&#38543;&#26426;&#25928;&#24212;&#30340;&#26368;&#20339;&#26080;&#20559;&#39044;&#27979;&#22120;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#24555;&#36895;&#22788;&#29702;&#39640;&#22522;&#25968;&#20998;&#31867;&#29305;&#24449;&#30340;&#32858;&#31867;&#35745;&#25968;&#25968;&#25454;&#65292;&#24182;&#19988;&#21487;&#20197;&#36731;&#26494;&#23454;&#29616;&#26368;&#20808;&#36827;&#30340;&#32593;&#32476;&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#23454;&#38469;&#25968;&#25454;&#36890;&#24120;&#21576;&#29616;&#20986;&#30456;&#20851;&#24615;&#65292;&#38024;&#23545;&#20027;&#39064;&#29305;&#23450;&#30340;&#39044;&#27979;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#30340;&#20852;&#36259;&#26085;&#30410;&#22686;&#38271;&#65292;&#20294;&#20256;&#32479;DNN&#26694;&#26550;&#36890;&#24120;&#24573;&#35270;&#20102;&#36825;&#19968;&#28857;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23618;&#27425;&#20284;&#28982;&#23398;&#20064;&#26694;&#26550;&#65292;&#23558;&#20285;&#29595;&#38543;&#26426;&#25928;&#24212;&#24341;&#20837;&#21040;&#27850;&#26494;DNN&#20013;&#65292;&#20197;&#36890;&#36807;&#25429;&#25417;&#36755;&#20837;&#21464;&#37327;&#30340;&#38750;&#32447;&#24615;&#25928;&#24212;&#21644;&#20027;&#39064;&#29305;&#23450;&#30340;&#32858;&#31867;&#25928;&#24212;&#26469;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#36890;&#36807;&#20248;&#21270;&#21333;&#20010;&#30446;&#26631;&#20989;&#25968;&#21516;&#26102;&#33719;&#24471;&#20102;&#22266;&#23450;&#21442;&#25968;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#21644;&#38543;&#26426;&#25928;&#24212;&#30340;&#26368;&#20339;&#26080;&#20559;&#39044;&#27979;&#22120;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#24555;&#36895;&#22788;&#29702;&#28041;&#21450;&#39640;&#22522;&#25968;&#20998;&#31867;&#29305;&#24449;&#30340;&#32858;&#31867;&#35745;&#25968;&#25968;&#25454;&#30340;&#31471;&#21040;&#31471;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#26368;&#20808;&#36827;&#30340;&#32593;&#32476;&#26550;&#26500;&#21487;&#20197;&#36731;&#26494;&#23454;&#29616;&#21040;&#25152;&#25552;&#20986;&#30340;h-likelihood&#26694;&#26550;&#24403;&#20013;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22810;&#22836;&#27880;&#24847;&#21147;&#23618;&#21644;&#19968;&#20010;&#31232;&#30095;&#23618;
&lt;/p&gt;
&lt;p&gt;
There is a growing interest in subject-specific predictions using deep neural networks (DNNs) because real-world data often exhibit correlations, which has been typically overlooked in traditional DNN frameworks. In this paper, we propose a novel hierarchical likelihood learning framework for introducing gamma random effects into the Poisson DNN, so as to improve the prediction performance by capturing both nonlinear effects of input variables and subject-specific cluster effects. The proposed method simultaneously yields maximum likelihood estimators for fixed parameters and best unbiased predictors for random effects by optimizing a single objective function. This approach enables a fast end-to-end algorithm for handling clustered count data, which often involve high-cardinality categorical features. Furthermore, state-of-the-art network architectures can be easily implemented into the proposed h-likelihood framework. As an example, we introduce multi-head attention layer and a spars
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#24102;&#26377;&#23545;&#25239;&#25439;&#22833;&#21644;&#24378;&#30423;&#21453;&#39304;&#30340;&#32447;&#24615;MDPs&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#20998;&#21035;&#36798;&#21040;&#20102;$\widetilde{\mathcal{O}}\left(\sqrt{K}\right)$&#21644;$\widetilde{\mathcal{O}}\left(K^{\frac{3}{4}} \right)$&#30340;&#36951;&#25022;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.11550</link><description>&lt;p&gt;
&#38754;&#21521;&#24102;&#26377;&#24378;&#23545;&#25239;&#25439;&#22833;&#21644;&#24378;&#30423;&#21453;&#39304;&#30340;&#23545;&#25239;&#24615;&#32447;&#24615;MDPs&#30340;&#26368;&#20248;&#36951;&#25022;
&lt;/p&gt;
&lt;p&gt;
Towards Optimal Regret in Adversarial Linear MDPs with Bandit Feedback. (arXiv:2310.11550v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11550
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#24102;&#26377;&#23545;&#25239;&#25439;&#22833;&#21644;&#24378;&#30423;&#21453;&#39304;&#30340;&#32447;&#24615;MDPs&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#20998;&#21035;&#36798;&#21040;&#20102;$\widetilde{\mathcal{O}}\left(\sqrt{K}\right)$&#21644;$\widetilde{\mathcal{O}}\left(K^{\frac{3}{4}} \right)$&#30340;&#36951;&#25022;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#32447;&#24615;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65292;&#24182;&#32771;&#34385;&#20102;&#23545;&#25239;&#24615;&#25439;&#22833;&#21644;&#24378;&#30423;&#21453;&#39304;&#65292;&#27809;&#26377;&#20107;&#20808;&#20102;&#35299;&#36716;&#25442;&#25110;&#35775;&#38382;&#27169;&#25311;&#22120;&#30340;&#20808;&#39564;&#30693;&#35782;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#30456;&#36739;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#23427;&#20204;&#37117;&#33021;&#21462;&#24471;&#26356;&#22909;&#30340;&#36951;&#25022;&#24615;&#33021;&#12290;&#31532;&#19968;&#31181;&#31639;&#27861;&#34429;&#28982;&#35745;&#31639;&#25928;&#29575;&#20302;&#65292;&#20294;&#33021;&#20445;&#35777;$\widetilde{\mathcal{O}}\left(\sqrt{K}\right)$&#30340;&#36951;&#25022;&#24615;&#33021;&#65292;&#20854;&#20013;$K$&#26159;&#22238;&#21512;&#25968;&#12290;&#36825;&#26159;&#35813;&#35774;&#32622;&#19979;&#31532;&#19968;&#20010;&#20855;&#26377;&#26368;&#20339;$K$&#20381;&#36182;&#24615;&#30340;&#32467;&#26524;&#12290;&#31532;&#20108;&#31181;&#31639;&#27861;&#22522;&#20110;&#31574;&#30053;&#20248;&#21270;&#26694;&#26550;&#65292;&#33021;&#20445;&#35777;$\widetilde{\mathcal{O}}\left(K^{\frac{3}{4}} \right)$&#30340;&#36951;&#25022;&#24615;&#33021;&#65292;&#24182;&#19988;&#35745;&#31639;&#25928;&#29575;&#39640;&#12290;&#25105;&#20204;&#30340;&#20004;&#20010;&#32467;&#26524;&#37117;&#26174;&#33879;&#25913;&#21892;&#20102;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#65306;Kong&#31561;&#20154;[2023]&#30340;&#35745;&#31639;&#25928;&#29575;&#20302;&#30340;&#31639;&#27861;&#65292;&#20854;&#36951;&#25022;&#24615;&#33021;&#20026;$\widetilde{\mathcal{O}}\left(K^{\frac{4}{5}}+poly\left(\frac{1}{\lambda_{\min}}\right) \right)$&#65292;&#20854;&#20013;$\lambda_{\min}$&#26159;&#38382;&#39064;&#30456;&#20851;&#24120;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study online reinforcement learning in linear Markov decision processes with adversarial losses and bandit feedback, without prior knowledge on transitions or access to simulators. We introduce two algorithms that achieve improved regret performance compared to existing approaches. The first algorithm, although computationally inefficient, ensures a regret of $\widetilde{\mathcal{O}}\left(\sqrt{K}\right)$, where $K$ is the number of episodes. This is the first result with the optimal $K$ dependence in the considered setting. The second algorithm, which is based on the policy optimization framework, guarantees a regret of $\widetilde{\mathcal{O}}\left(K^{\frac{3}{4}} \right)$ and is computationally efficient. Both our results significantly improve over the state-of-the-art: a computationally inefficient algorithm by Kong et al. [2023] with $\widetilde{\mathcal{O}}\left(K^{\frac{4}{5}}+poly\left(\frac{1}{\lambda_{\min}}\right) \right)$ regret, for some problem-dependent constant $\lam
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23384;&#22312;&#31163;&#32447;&#25968;&#25454;&#38598;&#30340;&#24773;&#20917;&#19979;&#65292;&#22914;&#20309;&#22312;&#26080;&#38480;&#26102;&#22495;&#36827;&#34892;&#39640;&#25928;&#30340;&#22312;&#32447;&#23398;&#20064;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#23398;&#20064;&#20195;&#29702;&#27169;&#25311;&#19987;&#23478;&#30340;&#34892;&#20026;&#31574;&#30053;&#33021;&#22815;&#26174;&#33879;&#20943;&#23567;&#32047;&#31215;&#36951;&#25022;&#12290;&#36890;&#36807;&#36125;&#21494;&#26031;&#26041;&#27861;&#36827;&#34892;&#30340;&#20808;&#39564;&#30456;&#20851;&#36951;&#25022;&#20998;&#26512;&#25552;&#20379;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#19978;&#30028;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#30340;&#27169;&#20223;&#23398;&#20064;&#31639;&#27861;&#26469;&#32467;&#21512;&#31163;&#32447;&#25968;&#25454;&#38598;&#21644;&#22312;&#32447;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2310.11531</link><description>&lt;p&gt;
&#22312;&#26080;&#38480;&#26102;&#22495;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#65292;&#21033;&#29992;&#31163;&#32447;&#25968;&#25454;&#38598;&#36827;&#34892;&#39640;&#25928;&#22312;&#32447;&#23398;&#20064;&#65306;&#19968;&#31181;&#36125;&#21494;&#26031;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient Online Learning with Offline Datasets for Infinite Horizon MDPs: A Bayesian Approach. (arXiv:2310.11531v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11531
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23384;&#22312;&#31163;&#32447;&#25968;&#25454;&#38598;&#30340;&#24773;&#20917;&#19979;&#65292;&#22914;&#20309;&#22312;&#26080;&#38480;&#26102;&#22495;&#36827;&#34892;&#39640;&#25928;&#30340;&#22312;&#32447;&#23398;&#20064;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#23398;&#20064;&#20195;&#29702;&#27169;&#25311;&#19987;&#23478;&#30340;&#34892;&#20026;&#31574;&#30053;&#33021;&#22815;&#26174;&#33879;&#20943;&#23567;&#32047;&#31215;&#36951;&#25022;&#12290;&#36890;&#36807;&#36125;&#21494;&#26031;&#26041;&#27861;&#36827;&#34892;&#30340;&#20808;&#39564;&#30456;&#20851;&#36951;&#25022;&#20998;&#26512;&#25552;&#20379;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#19978;&#30028;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#30340;&#27169;&#20223;&#23398;&#20064;&#31639;&#27861;&#26469;&#32467;&#21512;&#31163;&#32447;&#25968;&#25454;&#38598;&#21644;&#22312;&#32447;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24403;&#23384;&#22312;&#19968;&#20010;&#31163;&#32447;&#25968;&#25454;&#38598;&#26102;&#65292;&#22914;&#20309;&#22312;&#26080;&#38480;&#26102;&#22495;&#35774;&#32622;&#19979;&#36827;&#34892;&#39640;&#25928;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#12290;&#25105;&#20204;&#20551;&#35774;&#31163;&#32447;&#25968;&#25454;&#38598;&#26159;&#30001;&#19968;&#20010;&#19987;&#23478;&#29983;&#25104;&#30340;&#65292;&#20294;&#20854;&#33021;&#21147;&#27700;&#24179;&#26410;&#30693;&#65292;&#21363;&#23427;&#19981;&#26159;&#23436;&#32654;&#30340;&#65292;&#20063;&#19981;&#19968;&#23450;&#20351;&#29992;&#26368;&#20248;&#31574;&#30053;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#26524;&#23398;&#20064;&#20195;&#29702;&#27169;&#25311;&#19987;&#23478;&#20351;&#29992;&#30340;&#34892;&#20026;&#31574;&#30053;&#65288;&#30001;&#33021;&#21147;&#21442;&#25968;&#21442;&#25968;&#21270;&#65289;&#65292;&#22312;&#32047;&#31215;&#36951;&#25022;&#26368;&#23567;&#21270;&#26041;&#38754;&#33021;&#21462;&#24471;&#26126;&#26174;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#20197; $\tilde{O}(\sqrt{T})$ &#20026;&#32553;&#25918;&#30340;&#31934;&#30830;&#26377;&#29992;PSRL&#31639;&#27861;&#36951;&#25022;&#30340;&#19978;&#30028;&#12290;&#36825;&#38656;&#35201;&#23545;&#36125;&#21494;&#26031;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#22312;&#26080;&#38480;&#26102;&#22495;&#35774;&#32622;&#19979;&#36827;&#34892;&#26032;&#39062;&#30340;&#20808;&#39564;&#30456;&#20851;&#36951;&#25022;&#20998;&#26512;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#30340;Informed RLSVI&#31639;&#27861;&#65292;&#21487;&#20197;&#29702;&#35299;&#20026;&#20351;&#29992;&#31163;&#32447;&#25968;&#25454;&#38598;&#36827;&#34892;&#27169;&#20223;&#23398;&#20064;&#65292;&#28982;&#21518;&#36827;&#34892;&#22312;&#32447;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the problem of efficient online reinforcement learning in the infinite horizon setting when there is an offline dataset to start with. We assume that the offline dataset is generated by an expert but with unknown level of competence, i.e., it is not perfect and not necessarily using the optimal policy. We show that if the learning agent models the behavioral policy (parameterized by a competence parameter) used by the expert, it can do substantially better in terms of minimizing cumulative regret, than if it doesn't do that. We establish an upper bound on regret of the exact informed PSRL algorithm that scales as $\tilde{O}(\sqrt{T})$. This requires a novel prior-dependent regret analysis of Bayesian online learning algorithms for the infinite horizon setting. We then propose an approximate Informed RLSVI algorithm that we can interpret as performing imitation learning with the offline dataset, and then performing online learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34180;&#32780;&#28145;&#30340;&#39640;&#26031;&#36807;&#31243;&#26041;&#27861;&#65292;&#20811;&#26381;&#20102;&#20256;&#32479;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#22312;&#23398;&#20064;&#20302;&#32500;&#23884;&#20837;&#21644;&#35299;&#37322;&#24615;&#20043;&#38388;&#21462;&#24471;&#20102;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2310.11527</link><description>&lt;p&gt;
&#34180;&#32780;&#28145;&#30340;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Thin and Deep Gaussian Processes. (arXiv:2310.11527v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11527
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34180;&#32780;&#28145;&#30340;&#39640;&#26031;&#36807;&#31243;&#26041;&#27861;&#65292;&#20811;&#26381;&#20102;&#20256;&#32479;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#22312;&#23398;&#20064;&#20302;&#32500;&#23884;&#20837;&#21644;&#35299;&#37322;&#24615;&#20043;&#38388;&#21462;&#24471;&#20102;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#65288;GPs&#65289;&#21487;&#20197;&#25552;&#20379;&#19968;&#31181;&#21487;&#38752;&#30340;&#26041;&#27861;&#26469;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#65292;&#20855;&#26377;&#26131;&#20110;&#35299;&#37322;&#30340;&#20869;&#26680;&#36229;&#21442;&#25968;&#65292;&#22914;&#38271;&#24230;&#23610;&#24230;&#65292;&#21487;&#20197;&#25511;&#21046;&#20989;&#25968;&#20540;&#30340;&#30456;&#20851;&#36317;&#31163;&#12290;&#28982;&#32780;&#65292;&#36873;&#25321;&#21512;&#36866;&#30340;&#20869;&#26680;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#28145;&#24230;&#39640;&#26031;&#36807;&#31243;&#36890;&#36807;&#36880;&#23618;&#21442;&#25968;&#21270;GP&#23618;&#30340;&#20869;&#26680;&#65292;&#36991;&#20813;&#20102;&#25163;&#21160;&#20869;&#26680;&#24037;&#31243;&#65292;&#20351;&#20854;&#33021;&#22815;&#23398;&#20064;&#35299;&#37322;&#36755;&#20986;&#25968;&#25454;&#30340;&#20302;&#32500;&#23884;&#20837;&#26041;&#27861;&#12290;&#27839;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26550;&#26500;&#65292;&#26368;&#24120;&#35265;&#30340;&#28145;&#24230;&#39640;&#26031;&#36807;&#31243;&#36880;&#23618;&#21464;&#24418;&#36755;&#20837;&#31354;&#38388;&#65292;&#20294;&#22833;&#21435;&#20102;&#27973;&#23618;&#39640;&#26031;&#36807;&#31243;&#30340;&#25152;&#26377;&#35299;&#37322;&#24615;&#12290;&#21478;&#19968;&#31181;&#26500;&#24314;&#26041;&#27861;&#26159;&#36880;&#23618;&#21442;&#25968;&#21270;&#20869;&#26680;&#30340;&#38271;&#24230;&#23610;&#24230;&#65292;&#25552;&#39640;&#20102;&#35299;&#37322;&#24615;&#65292;&#20294;&#26368;&#32456;&#25918;&#24323;&#20102;&#23398;&#20064;&#20302;&#32500;&#23884;&#20837;&#30340;&#27010;&#24565;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#23481;&#26131;&#21463;&#21040;&#29305;&#23450;&#30340;&#30149;&#24577;&#24433;&#21709;&#65292;&#21487;&#33021;&#20250;&#38459;&#30861;&#25311;&#21512;&#24182;&#38480;&#21046;&#20854;&#21487;&#35299;&#37322;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32508;&#21512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes (GPs) can provide a principled approach to uncertainty quantification with easy-to-interpret kernel hyperparameters, such as the lengthscale, which controls the correlation distance of function values. However, selecting an appropriate kernel can be challenging. Deep GPs avoid manual kernel engineering by successively parameterizing kernels with GP layers, allowing them to learn low-dimensional embeddings of the inputs that explain the output data. Following the architecture of deep neural networks, the most common deep GPs warp the input space layer-by-layer but lose all the interpretability of shallow GPs. An alternative construction is to successively parameterize the lengthscale of a kernel, improving the interpretability but ultimately giving away the notion of learning lower-dimensional embeddings. Unfortunately, both methods are susceptible to particular pathologies which may hinder fitting and limit their interpretability. This work proposes a novel synthesis
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25506;&#35752;&#20102;&#23558;&#28201;&#24230;&#21442;&#25968;&#32435;&#20837;&#36125;&#21494;&#26031;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#19968;&#33268;&#39044;&#27979;&#20013;&#30340;&#20248;&#21183;&#65292;&#20197;&#25552;&#20379;&#26377;&#25928;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;</title><link>http://arxiv.org/abs/2310.11479</link><description>&lt;p&gt;
&#20851;&#20110;&#36125;&#21494;&#26031;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#19968;&#33268;&#39044;&#27979;&#20013;&#30340;&#28201;&#24230;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
On the Temperature of Bayesian Graph Neural Networks for Conformal Prediction. (arXiv:2310.11479v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11479
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25506;&#35752;&#20102;&#23558;&#28201;&#24230;&#21442;&#25968;&#32435;&#20837;&#36125;&#21494;&#26031;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#19968;&#33268;&#39044;&#27979;&#20013;&#30340;&#20248;&#21183;&#65292;&#20197;&#25552;&#20379;&#26377;&#25928;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#23545;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;(GNNs)&#33267;&#20851;&#37325;&#35201;&#65292;&#29305;&#21035;&#26159;&#22312;&#39640;&#39118;&#38505;&#39046;&#22495;&#20013;&#32463;&#24120;&#20351;&#29992;GNNs&#30340;&#24773;&#20917;&#19979;&#12290;&#19968;&#33268;&#39044;&#27979;(CP)&#20026;&#20219;&#20309;&#40657;&#30418;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#20010;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#30340;&#26377;&#21069;&#36884;&#30340;&#26694;&#26550;&#12290;CP&#20445;&#35777;&#20102;&#19968;&#20010;&#39044;&#27979;&#38598;&#20197;&#25152;&#38656;&#30340;&#27010;&#29575;&#21253;&#21547;&#30495;&#23454;&#26631;&#31614;&#30340;&#24418;&#24335;&#30340;&#23448;&#26041;&#27010;&#29575;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#39044;&#27979;&#38598;&#30340;&#22823;&#23567;&#65292;&#21363;"&#20302;&#25928;&#29575;"&#65292;&#21463;&#21040;&#24213;&#23618;&#27169;&#22411;&#21644;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#24433;&#21709;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#36125;&#21494;&#26031;&#23398;&#20064;&#36824;&#22522;&#20110;&#20272;&#35745;&#30340;&#21518;&#39564;&#20998;&#24067;&#25552;&#20379;&#19968;&#20010;&#21487;&#20449;&#21306;&#22495;&#65292;&#20294;&#21482;&#26377;&#22312;&#27169;&#22411;&#27491;&#30830;&#25351;&#23450;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20010;&#21306;&#22495;&#25165;&#26159;"&#33391;&#22909;&#26657;&#20934;"&#30340;&#12290;&#22312;&#19968;&#20010;&#26368;&#36817;&#30340;&#24037;&#20316;&#30340;&#22522;&#30784;&#19978;&#65292;&#35813;&#24037;&#20316;&#24341;&#20837;&#20102;&#19968;&#20010;&#32553;&#25918;&#21442;&#25968;&#65292;&#29992;&#20110;&#20174;&#21518;&#39564;&#20272;&#35745;&#20013;&#26500;&#24314;&#26377;&#25928;&#30340;&#21487;&#20449;&#21306;&#22495;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;CP&#26694;&#26550;&#20013;&#23558;&#19968;&#20010;&#28201;&#24230;&#21442;&#25968;&#32435;&#20837;&#36125;&#21494;&#26031;GNNs&#20013;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Accurate uncertainty quantification in graph neural networks (GNNs) is essential, especially in high-stakes domains where GNNs are frequently employed. Conformal prediction (CP) offers a promising framework for quantifying uncertainty by providing $\textit{valid}$ prediction sets for any black-box model. CP ensures formal probabilistic guarantees that a prediction set contains a true label with a desired probability. However, the size of prediction sets, known as $\textit{inefficiency}$, is influenced by the underlying model and data generating process. On the other hand, Bayesian learning also provides a credible region based on the estimated posterior distribution, but this region is $\textit{well-calibrated}$ only when the model is correctly specified. Building on a recent work that introduced a scaling parameter for constructing valid credible regions from posterior estimate, our study explores the advantages of incorporating a temperature parameter into Bayesian GNNs within CP fra
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37327;&#21270;&#35270;&#35273;&#21487;&#35299;&#37322;&#24615;&#30340;&#33258;&#21160;&#21270;&#26041;&#27861;&#65292;&#24182;&#25214;&#21040;&#20102;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20013;&#26377;&#24847;&#20041;&#30340;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2310.11431</link><description>&lt;p&gt;
&#22312;&#20154;&#24037;&#21644;&#29983;&#29289;&#31070;&#32463;&#31995;&#32479;&#20013;&#35782;&#21035;&#21487;&#35299;&#37322;&#30340;&#35270;&#35273;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Identifying Interpretable Visual Features in Artificial and Biological Neural Systems. (arXiv:2310.11431v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11431
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37327;&#21270;&#35270;&#35273;&#21487;&#35299;&#37322;&#24615;&#30340;&#33258;&#21160;&#21270;&#26041;&#27861;&#65292;&#24182;&#25214;&#21040;&#20102;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20013;&#26377;&#24847;&#20041;&#30340;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#21333;&#20010;&#31070;&#32463;&#20803;&#36890;&#24120;&#26159;&#8220;&#21487;&#35299;&#37322;&#30340;&#8221;&#65292;&#22240;&#20026;&#23427;&#20204;&#20195;&#34920;&#20010;&#21035;&#30452;&#35266;&#26377;&#24847;&#20041;&#30340;&#29305;&#24449;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#31070;&#32463;&#20803;&#34920;&#29616;&#20986;&#8220;&#28151;&#21512;&#36873;&#25321;&#24615;&#8221;&#65292;&#21363;&#23427;&#20204;&#20195;&#34920;&#22810;&#20010;&#19981;&#30456;&#20851;&#30340;&#29305;&#24449;&#12290;&#26368;&#36817;&#30340;&#20551;&#35774;&#35748;&#20026;&#65292;&#28145;&#24230;&#32593;&#32476;&#20013;&#30340;&#29305;&#24449;&#21487;&#33021;&#20197;&#8220;&#21472;&#21152;&#8221;&#30340;&#26041;&#24335;&#34920;&#31034;&#65292;&#21363;&#30001;&#22810;&#20010;&#31070;&#32463;&#20803;&#27839;&#38750;&#27491;&#20132;&#36724;&#34920;&#31034;&#65292;&#22240;&#20026;&#33258;&#28982;&#25968;&#25454;&#20013;&#21487;&#35299;&#37322;&#30340;&#29305;&#24449;&#25968;&#36890;&#24120;&#22823;&#20110;&#32473;&#23450;&#32593;&#32476;&#20013;&#30340;&#31070;&#32463;&#20803;&#25968;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24212;&#35813;&#33021;&#22815;&#22312;&#28608;&#27963;&#31354;&#38388;&#20013;&#25214;&#21040;&#19982;&#20010;&#21035;&#31070;&#32463;&#20803;&#19981;&#23545;&#40784;&#30340;&#26377;&#24847;&#20041;&#30340;&#26041;&#21521;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#65288;1&#65289;&#19968;&#31181;&#33258;&#21160;&#21270;&#30340;&#26041;&#27861;&#26469;&#37327;&#21270;&#35270;&#35273;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#36890;&#36807;&#19982;&#22823;&#37327;&#20154;&#31867;&#24515;&#29702;&#29289;&#29702;&#23398;&#23545;&#31070;&#32463;&#20803;&#21487;&#35299;&#37322;&#24615;&#30340;&#21028;&#26029;&#36827;&#34892;&#39564;&#35777;&#65292;&#20197;&#21450;&#65288;2&#65289;&#19968;&#31181;&#22312;&#32593;&#32476;&#28608;&#27963;&#31354;&#38388;&#20013;&#23547;&#25214;&#26377;&#24847;&#20041;&#26041;&#21521;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#26041;&#27861;&#26469;&#21457;&#29616;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Single neurons in neural networks are often ``interpretable'' in that they represent individual, intuitively meaningful features. However, many neurons exhibit $\textit{mixed selectivity}$, i.e., they represent multiple unrelated features. A recent hypothesis proposes that features in deep networks may be represented in $\textit{superposition}$, i.e., on non-orthogonal axes by multiple neurons, since the number of possible interpretable features in natural data is generally larger than the number of neurons in a given network. Accordingly, we should be able to find meaningful directions in activation space that are not aligned with individual neurons. Here, we propose (1) an automated method for quantifying visual interpretability that is validated against a large database of human psychophysics judgments of neuron interpretability, and (2) an approach for finding meaningful directions in network activation space. We leverage these methods to discover directions in convolutional neural
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#19981;&#36830;&#32493;&#20989;&#25968;&#30340;&#26367;&#20195;&#20027;&#21160;&#23376;&#31354;&#38388;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#27963;&#36291;&#23376;&#31354;&#38388;&#30340;&#24212;&#29992;&#33539;&#22260;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.10907</link><description>&lt;p&gt;
&#38024;&#23545;&#36339;&#36291;&#19981;&#36830;&#32493;&#20989;&#25968;&#30340;&#26367;&#20195;&#20027;&#21160;&#23376;&#31354;&#38388;
&lt;/p&gt;
&lt;p&gt;
Surrogate Active Subspaces for Jump-Discontinuous Functions. (arXiv:2310.10907v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10907
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#19981;&#36830;&#32493;&#20989;&#25968;&#30340;&#26367;&#20195;&#20027;&#21160;&#23376;&#31354;&#38388;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#27963;&#36291;&#23376;&#31354;&#38388;&#30340;&#24212;&#29992;&#33539;&#22260;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26367;&#20195;&#24314;&#27169;&#21644;&#27963;&#36291;&#23376;&#31354;&#38388;&#24050;&#32463;&#25104;&#20026;&#35745;&#31639;&#31185;&#23398;&#21644;&#24037;&#31243;&#39046;&#22495;&#30340;&#24378;&#22823;&#33539;&#20363;&#12290;&#23558;&#36825;&#20123;&#25216;&#26415;&#24212;&#29992;&#20110;&#31038;&#20250;&#31185;&#23398;&#20013;&#30340;&#35745;&#31639;&#27169;&#22411;&#65292;&#31361;&#26174;&#20102;&#23427;&#20204;&#22312;&#22788;&#29702;&#31163;&#25955;&#36755;&#20986;&#30340;Agent-Based&#27169;&#22411;&#31561;&#19981;&#36830;&#32493;&#27169;&#25311;&#22120;&#26102;&#30340;&#23616;&#38480;&#24615;&#12290;&#28982;&#32780;&#65292;&#20043;&#21069;&#30340;&#24212;&#29992;&#30740;&#31350;&#24050;&#32463;&#34920;&#26126;&#65292;&#23545;&#20110;&#36825;&#31867;&#20272;&#35745;&#22120;&#65292;&#26367;&#20195;&#35745;&#31639;&#30340;&#27963;&#36291;&#23376;&#31354;&#38388;&#21487;&#20197;&#20135;&#29983;&#26377;&#36259;&#30340;&#32467;&#26524;&#12290;&#20294;&#26159;&#65292;&#30001;&#20110;&#27963;&#36291;&#23376;&#31354;&#38388;&#26159;&#36890;&#36807;&#26799;&#24230;&#23450;&#20041;&#30340;&#65292;&#24403;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#19981;&#36830;&#32493;&#27169;&#25311;&#22120;&#26102;&#65292;&#20272;&#35745;&#30340;&#26159;&#20160;&#20040;&#37327;&#36824;&#19981;&#28165;&#26970;&#12290;&#26412;&#25991;&#39318;&#20808;&#23637;&#31034;&#20102;&#36827;&#34892;&#27492;&#31867;&#20998;&#26512;&#26102;&#21487;&#33021;&#20986;&#29616;&#30340;&#19968;&#20123;&#30149;&#24577;&#24773;&#20917;&#12290;&#36825;&#20419;&#20351;&#25105;&#20204;&#23558;&#27963;&#36291;&#23376;&#31354;&#38388;&#25193;&#23637;&#21040;&#19981;&#36830;&#32493;&#20989;&#25968;&#19978;&#65292;&#28548;&#28165;&#20102;&#22312;&#27492;&#31867;&#20998;&#26512;&#20013;&#23454;&#38469;&#20272;&#35745;&#30340;&#20869;&#23481;&#12290;&#25105;&#20204;&#36824;&#23545;&#21512;&#25104;&#27979;&#35797;&#20989;&#25968;&#36827;&#34892;&#20102;&#25968;&#20540;&#23454;&#39564;&#65292;&#27604;&#36739;&#20102;&#27963;&#36291;&#23376;&#31354;&#38388;&#30340;&#39640;&#26031;&#36807;&#31243;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Surrogate modeling and active subspaces have emerged as powerful paradigms in computational science and engineering. Porting such techniques to computational models in the social sciences brings into sharp relief their limitations in dealing with discontinuous simulators, such as Agent-Based Models, which have discrete outputs. Nevertheless, prior applied work has shown that surrogate estimates of active subspaces for such estimators can yield interesting results. But given that active subspaces are defined by way of gradients, it is not clear what quantity is being estimated when this methodology is applied to a discontinuous simulator. We begin this article by showing some pathologies that can arise when conducting such an analysis. This motivates an extension of active subspaces to discontinuous functions, clarifying what is actually being estimated in such analyses. We also conduct numerical experiments on synthetic test functions to compare Gaussian process estimates of active sub
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#36866;&#24212;&#24615;&#31574;&#30053;&#36873;&#25321;&#26368;&#22823;&#21270;&#31038;&#20250;&#31119;&#21033;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#36951;&#25022;&#30340;&#19979;&#30028;&#21644;&#31639;&#27861;&#30340;&#21305;&#37197;&#19978;&#30028;&#12290;&#30740;&#31350;&#21457;&#29616;&#31119;&#21033;&#26368;&#22823;&#21270;&#27604;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#26356;&#22256;&#38590;&#65292;&#20294;&#35813;&#31639;&#27861;&#36798;&#21040;&#20102;&#26368;&#20248;&#22686;&#38271;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.09597</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#26368;&#22823;&#21270;&#31038;&#20250;&#31119;&#21033;
&lt;/p&gt;
&lt;p&gt;
Adaptive maximization of social welfare. (arXiv:2310.09597v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09597
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#36866;&#24212;&#24615;&#31574;&#30053;&#36873;&#25321;&#26368;&#22823;&#21270;&#31038;&#20250;&#31119;&#21033;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#36951;&#25022;&#30340;&#19979;&#30028;&#21644;&#31639;&#27861;&#30340;&#21305;&#37197;&#19978;&#30028;&#12290;&#30740;&#31350;&#21457;&#29616;&#31119;&#21033;&#26368;&#22823;&#21270;&#27604;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#26356;&#22256;&#38590;&#65292;&#20294;&#35813;&#31639;&#27861;&#36798;&#21040;&#20102;&#26368;&#20248;&#22686;&#38271;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#37325;&#22797;&#36873;&#25321;&#25919;&#31574;&#20197;&#26368;&#22823;&#21270;&#31038;&#20250;&#31119;&#21033;&#30340;&#38382;&#39064;&#12290;&#31119;&#21033;&#26159;&#20010;&#20154;&#25928;&#29992;&#21644;&#20844;&#20849;&#25910;&#20837;&#30340;&#21152;&#26435;&#21644;&#12290;&#26089;&#26399;&#30340;&#32467;&#26524;&#24433;&#21709;&#21518;&#32493;&#30340;&#25919;&#31574;&#36873;&#25321;&#12290;&#25928;&#29992;&#19981;&#21487;&#35266;&#27979;&#65292;&#20294;&#21487;&#20197;&#38388;&#25509;&#25512;&#26029;&#12290;&#21709;&#24212;&#20989;&#25968;&#36890;&#36807;&#23454;&#39564;&#23398;&#20064;&#33719;&#24471;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#20851;&#20110;&#36951;&#25022;&#30340;&#19979;&#30028;&#65292;&#24182;&#19988;&#23545;&#20110;&#19968;&#31181;Exp3&#31639;&#27861;&#30340;&#21305;&#37197;&#23545;&#31574;&#23545;&#31435;&#19978;&#30028;&#12290;&#32047;&#31215;&#36951;&#25022;&#20197;$T^{2/3}$&#30340;&#36895;&#29575;&#22686;&#38271;&#12290;&#36825;&#24847;&#21619;&#30528;(i)&#31119;&#21033;&#26368;&#22823;&#21270;&#27604;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#26356;&#22256;&#38590;&#65288;&#23545;&#20110;&#26377;&#38480;&#30340;&#25919;&#31574;&#38598;&#26469;&#35828;&#65292;&#22686;&#38271;&#36895;&#29575;&#20026;$T^{1/2}$&#65289;&#65292;&#21644;(ii)&#25105;&#20204;&#30340;&#31639;&#27861;&#23454;&#29616;&#20102;&#26368;&#20248;&#22686;&#38271;&#36895;&#29575;&#12290;&#23545;&#20110;&#38543;&#26426;&#35774;&#32622;&#65292;&#22914;&#26524;&#31038;&#20250;&#31119;&#21033;&#26159;&#20985;&#30340;&#65292;&#25105;&#20204;&#21487;&#20197;&#20351;&#29992;&#20108;&#20998;&#25628;&#32034;&#31639;&#27861;&#22312;&#36830;&#32493;&#25919;&#31574;&#38598;&#19978;&#23454;&#29616;$T^{1/2}$&#30340;&#36895;&#29575;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#38750;&#32447;&#24615;&#25910;&#20837;&#31246;&#25193;&#23637;&#65292;&#24182;&#27010;&#36848;&#20102;&#21830;&#21697;&#31246;&#25193;&#23637;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#35774;&#32622;&#19982;&#22404;&#26029;&#23450;&#20215;&#65288;&#26356;&#23481;&#26131;&#65289;&#21644;&#21452;&#36793;&#20132;&#26131;&#30340;&#23450;&#20215;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of repeatedly choosing policies to maximize social welfare. Welfare is a weighted sum of private utility and public revenue. Earlier outcomes inform later policies. Utility is not observed, but indirectly inferred. Response functions are learned through experimentation.  We derive a lower bound on regret, and a matching adversarial upper bound for a variant of the Exp3 algorithm. Cumulative regret grows at a rate of $T^{2/3}$. This implies that (i) welfare maximization is harder than the multi-armed bandit problem (with a rate of $T^{1/2}$ for finite policy sets), and (ii) our algorithm achieves the optimal rate. For the stochastic setting, if social welfare is concave, we can achieve a rate of $T^{1/2}$ (for continuous policy sets), using a dyadic search algorithm.  We analyze an extension to nonlinear income taxation, and sketch an extension to commodity taxation. We compare our setting to monopoly pricing (which is easier), and price setting for bilateral tra
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#26041;&#24046;&#27969;&#26041;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#31163;&#25955;&#20998;&#24067;&#65292;&#36890;&#36807;&#24320;&#21457;&#19968;&#20010;&#31163;&#25955;&#19988;&#20445;&#25345;&#24230;&#37327;&#30340;&#26144;&#23556;&#65292;&#32780;&#19981;&#38656;&#35201;&#36830;&#32493;&#23884;&#20837;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;&#36830;&#32493;&#23884;&#20837;&#27969;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#20135;&#29983;&#26356;&#21487;&#38752;&#30340;&#36817;&#20284;&#12290;</title><link>http://arxiv.org/abs/2308.15613</link><description>&lt;p&gt;
&#28151;&#21512;&#26041;&#24046;&#27969;&#29992;&#20110;&#31163;&#25955;&#21464;&#37327;
&lt;/p&gt;
&lt;p&gt;
Mixed Variational Flows for Discrete Variables. (arXiv:2308.15613v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15613
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#26041;&#24046;&#27969;&#26041;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#31163;&#25955;&#20998;&#24067;&#65292;&#36890;&#36807;&#24320;&#21457;&#19968;&#20010;&#31163;&#25955;&#19988;&#20445;&#25345;&#24230;&#37327;&#30340;&#26144;&#23556;&#65292;&#32780;&#19981;&#38656;&#35201;&#36830;&#32493;&#23884;&#20837;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;&#36830;&#32493;&#23884;&#20837;&#27969;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#20135;&#29983;&#26356;&#21487;&#38752;&#30340;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#27969;&#20801;&#35768;&#20174;&#20107;&#32773;&#23398;&#20064;&#22797;&#26434;&#30340;&#36830;&#32493;&#20998;&#24067;&#65292;&#20294;&#26159;&#36817;&#20284;&#31163;&#25955;&#20998;&#24067;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#30446;&#21069;&#30340;&#26041;&#27861;&#36890;&#24120;&#23558;&#31163;&#25955;&#30446;&#26631;&#23884;&#20837;&#36830;&#32493;&#31354;&#38388;&#20013;-&#36890;&#24120;&#26159;&#36890;&#36807;&#36830;&#32493;&#26494;&#24347;&#25110;&#21435;&#37327;&#21270;-&#28982;&#21518;&#24212;&#29992;&#36830;&#32493;&#27969;&#21160;&#12290;&#36825;&#20123;&#26041;&#27861;&#28041;&#21450;&#19968;&#20010;&#21487;&#33021;&#26080;&#27861;&#25429;&#25417;&#21040;&#21407;&#22987;&#31163;&#25955;&#30446;&#26631;&#30340;&#26367;&#20195;&#30446;&#26631;&#65292;&#21487;&#33021;&#20855;&#26377;&#20559;&#20506;&#25110;&#19981;&#31283;&#23450;&#30340;&#26799;&#24230;&#65292;&#24182;&#19988;&#21487;&#33021;&#20250;&#21019;&#24314;&#19968;&#20010;&#22256;&#38590;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#38024;&#23545;&#31163;&#25955;&#20998;&#24067;&#30340;&#21464;&#20998;&#27969;&#26063;&#65292;&#32780;&#19981;&#38656;&#35201;&#20219;&#20309;&#36830;&#32493;&#23884;&#20837;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#20445;&#25345;&#24230;&#37327;&#30340;&#31163;&#25955;&#21487;&#36870;&#26144;&#23556;&#65292;&#20351;&#31163;&#25955;&#30446;&#26631;&#20445;&#25345;&#19981;&#21464;&#65292;&#28982;&#21518;&#22522;&#20110;&#35813;&#26144;&#23556;&#21019;&#24314;&#20102;&#19968;&#20010;&#28151;&#21512;&#21464;&#20998;&#27969;(MAD Mix)&#12290;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#20010;&#25193;&#23637;&#65292;&#29992;&#20110;&#22788;&#29702;&#32852;&#21512;&#31163;&#25955;&#21644;&#36830;&#32493;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;MAD Mix&#20135;&#29983;&#20102;&#27604;&#36830;&#32493;&#23884;&#20837;&#27969;&#26356;&#21487;&#38752;&#30340;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational flows allow practitioners to learn complex continuous distributions, but approximating discrete distributions remains a challenge. Current methodologies typically embed the discrete target in a continuous space - usually via continuous relaxation or dequantization - and then apply a continuous flow. These approaches involve a surrogate target that may not capture the original discrete target, might have biased or unstable gradients, and can create a difficult optimization problem. In this work, we develop a variational flow family for discrete distributions without any continuous embedding. First, we develop a measure-preserving and discrete (MAD) invertible map that leaves the discrete target invariant, and then create a mixed variational flow (MAD Mix) based on that map. We also develop an extension to MAD Mix that handles joint discrete and continuous models. Our experiments suggest that MAD Mix produces more reliable approximations than continuous-embedding flows while 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25506;&#32034;&#20102;&#19968;&#31181;&#31070;&#32463;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#24403;&#21069;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#23384;&#22312;&#30340;&#21487;&#20449;&#24230;&#38382;&#39064;&#65292;&#21253;&#25324;&#39044;&#27979;&#32467;&#26524;&#35299;&#37322;&#19981;&#36275;&#12289;&#23398;&#20064;&#27169;&#22411;&#27867;&#21270;&#24615;&#19981;&#36275;&#21644;&#19981;&#36866;&#24212;&#19981;&#30830;&#23450;&#29615;&#22659;&#30340;&#38382;&#39064;&#65292;&#20197;&#25552;&#39640;&#21487;&#20449;&#24230;&#32593;&#32476;&#30340;&#35774;&#35745;&#32423;&#21487;&#35299;&#37322;&#24615;&#21644;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.03666</link><description>&lt;p&gt;
&#26550;&#36215;&#21487;&#20449;&#24230;&#19982;&#24320;&#25918;&#19990;&#30028;&#23398;&#20064;&#30340;&#26725;&#26753;&#65306;&#19968;&#31181;&#25506;&#32034;&#24615;&#31070;&#32463;&#26041;&#27861;&#65292;&#29992;&#20110;&#22686;&#24378;&#21487;&#35299;&#37322;&#24615;&#12289;&#27867;&#21270;&#24615;&#21644;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Bridging Trustworthiness and Open-World Learning: An Exploratory Neural Approach for Enhancing Interpretability, Generalization, and Robustness. (arXiv:2308.03666v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03666
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25506;&#32034;&#20102;&#19968;&#31181;&#31070;&#32463;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#24403;&#21069;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#23384;&#22312;&#30340;&#21487;&#20449;&#24230;&#38382;&#39064;&#65292;&#21253;&#25324;&#39044;&#27979;&#32467;&#26524;&#35299;&#37322;&#19981;&#36275;&#12289;&#23398;&#20064;&#27169;&#22411;&#27867;&#21270;&#24615;&#19981;&#36275;&#21644;&#19981;&#36866;&#24212;&#19981;&#30830;&#23450;&#29615;&#22659;&#30340;&#38382;&#39064;&#65292;&#20197;&#25552;&#39640;&#21487;&#20449;&#24230;&#32593;&#32476;&#30340;&#35774;&#35745;&#32423;&#21487;&#35299;&#37322;&#24615;&#21644;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#30740;&#31350;&#20154;&#21592;&#21162;&#21147;&#32553;&#23567;&#26426;&#22120;&#26234;&#33021;&#19982;&#20154;&#31867;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#36890;&#36807;&#21457;&#23637;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#65292;&#25105;&#20204;&#24517;&#39035;&#35748;&#35782;&#21040;&#21487;&#20449;&#24230;&#22312;&#24320;&#25918;&#19990;&#30028;&#20013;&#30340;&#20851;&#38190;&#37325;&#35201;&#24615;&#65292;&#22312;&#26085;&#24120;&#29983;&#27963;&#30340;&#21508;&#20010;&#26041;&#38754;&#23545;&#27599;&#20010;&#20154;&#37117;&#24050;&#32463;&#26080;&#22788;&#19981;&#22312;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#23384;&#22312;&#20960;&#20010;&#25361;&#25112;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#20449;&#20219;&#21361;&#26426;&#65306;1&#65289;&#23545;&#39044;&#27979;&#32467;&#26524;&#30340;&#35299;&#37322;&#19981;&#36275;&#65307;2&#65289;&#23398;&#20064;&#27169;&#22411;&#30340;&#27867;&#21270;&#24615;&#19981;&#36275;&#65307;3&#65289;&#23545;&#19981;&#30830;&#23450;&#29615;&#22659;&#30340;&#36866;&#24212;&#33021;&#21147;&#24046;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#19968;&#31181;&#31070;&#32463;&#31243;&#24207;&#65292;&#29992;&#20110;&#26550;&#36215;&#21487;&#20449;&#24230;&#19982;&#24320;&#25918;&#19990;&#30028;&#23398;&#20064;&#20043;&#38388;&#30340;&#26725;&#26753;&#65292;&#20174;&#21333;&#27169;&#24577;&#25193;&#23637;&#21040;&#22810;&#27169;&#24577;&#22330;&#26223;&#65292;&#20197;&#20379;&#35835;&#32773;&#20351;&#29992;&#12290;1&#65289;&#20026;&#20102;&#22686;&#24378;&#35774;&#35745;&#32423;&#21487;&#35299;&#37322;&#24615;&#65292;&#25105;&#20204;&#39318;&#20808;&#23450;&#21046;&#20102;&#20855;&#26377;&#29305;&#23450;&#29289;&#29702;&#21547;&#20041;&#30340;&#21487;&#20449;&#32593;&#32476;&#65307;2&#65289;&#28982;&#21518;&#65292;&#36890;&#36807;&#28789;&#27963;&#30340;&#23398;&#20064;&#27491;&#21017;&#21270;&#22120;&#35774;&#35745;&#29615;&#22659;&#31119;&#31049;&#20219;&#21153;&#25509;&#21475;&#65292;&#20197;&#25913;&#21892;&#21487;&#20449;&#32593;&#32476;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
As researchers strive to narrow the gap between machine intelligence and human through the development of artificial intelligence technologies, it is imperative that we recognize the critical importance of trustworthiness in open-world, which has become ubiquitous in all aspects of daily life for everyone. However, several challenges may create a crisis of trust in current artificial intelligence systems that need to be bridged: 1) Insufficient explanation of predictive results; 2) Inadequate generalization for learning models; 3) Poor adaptability to uncertain environments. Consequently, we explore a neural program to bridge trustworthiness and open-world learning, extending from single-modal to multi-modal scenarios for readers. 1) To enhance design-level interpretability, we first customize trustworthy networks with specific physical meanings; 2) We then design environmental well-being task-interfaces via flexible learning regularizers for improving the generalization of trustworthy
&lt;/p&gt;</description></item><item><title>&#26377;&#38480;&#20869;&#23384;&#36138;&#23146;&#25311;&#29275;&#39039;&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#26631;&#20934;&#25311;&#29275;&#39039;&#26041;&#27861;&#35745;&#31639;&#25104;&#26412;&#21644;&#20869;&#23384;&#38656;&#27714;&#36807;&#39640;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#36824;&#26377;&#20855;&#26377;&#38750;&#28176;&#36827;&#36229;&#32447;&#24615;&#25910;&#25947;&#36895;&#29575;&#30340;&#24615;&#33021;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2306.15444</link><description>&lt;p&gt;
&#26377;&#38480;&#20869;&#23384;&#36138;&#23146;&#25311;&#29275;&#39039;&#26041;&#27861;&#19982;&#38750;&#28176;&#36827;&#36229;&#32447;&#24615;&#25910;&#25947;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Limited-Memory Greedy Quasi-Newton Method with Non-asymptotic Superlinear Convergence Rate. (arXiv:2306.15444v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15444
&lt;/p&gt;
&lt;p&gt;
&#26377;&#38480;&#20869;&#23384;&#36138;&#23146;&#25311;&#29275;&#39039;&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#26631;&#20934;&#25311;&#29275;&#39039;&#26041;&#27861;&#35745;&#31639;&#25104;&#26412;&#21644;&#20869;&#23384;&#38656;&#27714;&#36807;&#39640;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#36824;&#26377;&#20855;&#26377;&#38750;&#28176;&#36827;&#36229;&#32447;&#24615;&#25910;&#25947;&#36895;&#29575;&#30340;&#24615;&#33021;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#28176;&#36827;&#25910;&#25947;&#20998;&#26512;&#34920;&#26126;&#65292;&#25311;&#29275;&#39039;&#26041;&#27861;&#30340;&#26174;&#24335;&#36229;&#32447;&#24615;&#36895;&#29575;&#20026;O$((1/\sqrt{t})^t)$&#12290;&#28982;&#32780;&#65292;&#33719;&#24471;&#36825;&#19968;&#36895;&#29575;&#30340;&#26041;&#27861;&#23384;&#22312;&#19968;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#32570;&#28857;&#65306;&#23427;&#20204;&#38656;&#35201;&#23384;&#20648;&#20808;&#21069;&#30340;&#40657;&#22622;&#36817;&#20284;&#30697;&#38453;&#65292;&#25110;&#32773;&#23384;&#20648;&#25152;&#26377;&#36807;&#21435;&#30340;&#26354;&#29575;&#20449;&#24687;&#20197;&#24418;&#25104;&#24403;&#21069;&#30340;&#40657;&#22622;&#36870;&#36817;&#20284;&#12290;&#26377;&#38480;&#20869;&#23384;&#30340;&#25311;&#29275;&#39039;&#26041;&#27861;&#65288;&#22914;&#33879;&#21517;&#30340;L-BFGS&#65289;&#36890;&#36807;&#21033;&#29992;&#26377;&#38480;&#31383;&#21475;&#30340;&#36807;&#21435;&#26354;&#29575;&#20449;&#24687;&#26469;&#26500;&#36896;&#40657;&#22622;&#36870;&#36817;&#20284;&#65292;&#20174;&#32780;&#32531;&#35299;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;&#22240;&#27492;&#65292;&#23427;&#20204;&#30340;&#27599;&#27425;&#36845;&#20195;&#22797;&#26434;&#24230;&#21644;&#23384;&#20648;&#38656;&#27714;&#20026;O$(\tau d)$&#65292;&#20854;&#20013;$\tau \le d$ &#26159;&#31383;&#21475;&#30340;&#22823;&#23567;&#65292;$d$ &#26159;&#38382;&#39064;&#30340;&#32500;&#25968;&#65292;&#20174;&#32780;&#38477;&#20302;&#20102;&#26631;&#20934;&#25311;&#29275;&#39039;&#26041;&#27861;&#30340;O$(d^2)$ &#35745;&#31639;&#25104;&#26412;&#21644;&#20869;&#23384;&#38656;&#27714;&#12290;&#28982;&#32780;&#65292;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#27809;&#26377;&#32467;&#26524;&#34920;&#26126;&#26377;&#38480;&#20869;&#23384;&#25311;&#29275;&#39039;&#26041;&#27861;&#23384;&#22312;&#38750;&#28176;&#36827;&#36229;&#32447;&#24615;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Non-asymptotic convergence analysis of quasi-Newton methods has gained attention with a landmark result establishing an explicit superlinear rate of O$((1/\sqrt{t})^t)$. The methods that obtain this rate, however, exhibit a well-known drawback: they require the storage of the previous Hessian approximation matrix or instead storing all past curvature information to form the current Hessian inverse approximation. Limited-memory variants of quasi-Newton methods such as the celebrated L-BFGS alleviate this issue by leveraging a limited window of past curvature information to construct the Hessian inverse approximation. As a result, their per iteration complexity and storage requirement is O$(\tau d)$ where $\tau \le d$ is the size of the window and $d$ is the problem dimension reducing the O$(d^2)$ computational cost and memory requirement of standard quasi-Newton methods. However, to the best of our knowledge, there is no result showing a non-asymptotic superlinear convergence rate for a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#36890;&#36807;&#31283;&#20581;&#27169;&#25311;&#29983;&#25104;&#38543;&#26426;&#22270;&#24182;&#23558;&#21152;&#26435;&#25216;&#26415;&#32467;&#21512;UCB&#31639;&#27861;&#65292;&#20197;&#21327;&#20316;&#26041;&#24335;&#20943;&#23567;&#25972;&#20010;&#31995;&#32479;&#30340;&#24635;&#36951;&#25022;&#12290;</title><link>http://arxiv.org/abs/2306.05579</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#38543;&#26426;&#20998;&#24067;&#30340;&#24322;&#26500;&#22870;&#21169;&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
Decentralized Randomly Distributed Multi-agent Multi-armed Bandit with Heterogeneous Rewards. (arXiv:2306.05579v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05579
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#36890;&#36807;&#31283;&#20581;&#27169;&#25311;&#29983;&#25104;&#38543;&#26426;&#22270;&#24182;&#23558;&#21152;&#26435;&#25216;&#26415;&#32467;&#21512;UCB&#31639;&#27861;&#65292;&#20197;&#21327;&#20316;&#26041;&#24335;&#20943;&#23567;&#25972;&#20010;&#31995;&#32479;&#30340;&#24635;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#22810;&#20010;&#23458;&#25143;&#31471;&#36890;&#36807;&#30001;&#29615;&#22659;&#25552;&#20379;&#30340;&#26102;&#38388;&#20381;&#36182;&#24615;&#38543;&#26426;&#22270;&#36827;&#34892;&#36830;&#25509;&#12290;&#27599;&#20010;&#33218;&#30340;&#22870;&#21169;&#20998;&#24067;&#22240;&#23458;&#25143;&#32780;&#24322;&#65292;&#24182;&#19988;&#22870;&#21169;&#26159;&#26681;&#25454;&#21253;&#25324;&#20122;&#25351;&#25968;&#21644;&#20122;&#39640;&#26031;&#20998;&#24067;&#22312;&#20869;&#30340;&#20998;&#24067;&#65292;&#30001;&#29615;&#22659;&#29420;&#31435;&#22320;&#38543;&#26102;&#38388;&#29983;&#25104;&#30340;&#12290;&#27599;&#20010;&#23458;&#25143;&#31471;&#37117;&#20250;&#25289;&#21160;&#19968;&#20010;&#33218;&#65292;&#24182;&#26681;&#25454;&#30001;&#29615;&#22659;&#25552;&#20379;&#30340;&#22270;&#19982;&#37051;&#23621;&#36827;&#34892;&#36890;&#20449;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#21327;&#20316;&#26469;&#20943;&#23567;&#25972;&#20010;&#31995;&#32479;&#30340;&#24635;&#36951;&#25022;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#39318;&#20808;&#25552;&#20379;&#20102;&#20351;&#29992;&#24555;&#36895;&#28151;&#21512;&#39532;&#23572;&#21487;&#22827;&#38142;&#25110;&#38543;&#26426;&#22270;&#27169;&#22411;&#29983;&#25104;&#38543;&#26426;&#22270;&#30340;&#31283;&#20581;&#20223;&#30495;&#26041;&#27861;&#65292;&#28982;&#21518;&#23558;&#22522;&#20110;&#24179;&#22343;&#19968;&#33268;&#24615;&#26041;&#27861;&#21644;&#26032;&#25552;&#20986;&#30340;&#21152;&#26435;&#25216;&#26415;&#20197;&#21450;&#19978;&#32622;&#20449;&#38480;&#32467;&#21512;&#36215;&#26469;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;UCB&#31867;&#22411;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#32771;&#34385;&#21040;&#20102;&#22270;&#24418;&#20013;&#30340;&#38543;&#26426;&#24615;&#65292;&#28040;&#38500;&#20102;&#38480;&#21046;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a decentralized multi-agent multi-armed bandit problem in which multiple clients are connected by time dependent random graphs provided by an environment. The reward distributions of each arm vary across clients and rewards are generated independently over time by an environment based on distributions that include both sub-exponential and sub-gaussian distributions. Each client pulls an arm and communicates with neighbors based on the graph provided by the environment. The goal is to minimize the overall regret of the entire system through collaborations. To this end, we introduce a novel algorithmic framework, which first provides robust simulation methods for generating random graphs using rapidly mixing Markov chains or the random graph model, and then combines an averaging-based consensus approach with a newly proposed weighting technique and the upper confidence bound to deliver a UCB-type solution. Our algorithms account for the randomness in the graphs, removing the con
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;Bayesian&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#26469;&#21387;&#32553;&#25968;&#25454;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270; $\beta$-ELBO &#30452;&#25509;&#20248;&#21270;&#30721;-&#22833;&#30495;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#35843;&#25972; $\beta$ &#26469;&#38024;&#23545;&#32473;&#23450;&#30340;&#32593;&#32476;&#32467;&#26500;&#23454;&#29616;&#19981;&#21516;&#30340;&#30721;-&#22833;&#30495;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2305.19185</link><description>&lt;p&gt;
Bayesian&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#19979;&#30340;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
Compression with Bayesian Implicit Neural Representations. (arXiv:2305.19185v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19185
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;Bayesian&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#26469;&#21387;&#32553;&#25968;&#25454;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270; $\beta$-ELBO &#30452;&#25509;&#20248;&#21270;&#30721;-&#22833;&#30495;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#35843;&#25972; $\beta$ &#26469;&#38024;&#23545;&#32473;&#23450;&#30340;&#32593;&#32476;&#32467;&#26500;&#23454;&#29616;&#19981;&#21516;&#30340;&#30721;-&#22833;&#30495;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#24120;&#35265;&#31867;&#22411;&#30340;&#25968;&#25454;&#21487;&#20197;&#34920;&#31034;&#20026;&#23558;&#22352;&#26631;&#26144;&#23556;&#21040;&#20449;&#21495;&#20540;&#30340;&#20989;&#25968;&#65292;&#20363;&#22914;&#22270;&#20687;&#20013;&#30340;&#20687;&#32032;&#20301;&#32622;&#21040;RGB&#20540;&#12290;&#22522;&#20110;&#36825;&#20010;&#35266;&#28857;&#65292;&#21487;&#20197;&#36890;&#36807;&#23545;&#25968;&#25454;&#30340;&#21151;&#33021;&#34920;&#31034;&#36827;&#34892;&#36229;&#25311;&#21512;&#65292;&#28982;&#21518;&#32534;&#30721;&#32593;&#32476;&#26435;&#37325;&#26469;&#21387;&#32553;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#24403;&#21069;&#30340;&#35299;&#20915;&#26041;&#26696;&#37117;&#25928;&#29575;&#20302;&#19979;&#65292;&#22240;&#20026;&#23558;&#31934;&#24230;&#37327;&#21270;&#21040;&#20302;&#27604;&#29305;&#20250;&#22823;&#24133;&#38477;&#20302;&#37325;&#26500;&#36136;&#37327;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36807;&#24230;&#25311;&#21512;&#21464;&#20998;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26469;&#21387;&#32553;&#36817;&#20284;&#21518;&#39564;&#26435;&#37325;&#26679;&#26412;&#65292;&#32780;&#19981;&#26159;&#37327;&#21270;&#21644;&#29109;&#32534;&#30721;&#23427;&#12290;&#35813;&#31574;&#30053;&#36890;&#36807;&#26368;&#23567;&#21270; $\beta$-ELBO &#30452;&#25509;&#20248;&#21270;&#30721;-&#22833;&#30495;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#35843;&#25972; $\beta$ &#26469;&#38024;&#23545;&#32473;&#23450;&#30340;&#32593;&#32476;&#32467;&#26500;&#23454;&#29616;&#19981;&#21516;&#30340;&#30721;-&#22833;&#30495;&#24179;&#34913;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#23398;&#20064;&#20808;&#39564;&#26435;&#37325;&#20998;&#24067;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#24182;&#37319;&#29992;&#20027;&#21160;&#23610;&#23544;&#35843;&#25972;&#26469;&#36827;&#19968;&#27493;&#25552;&#39640;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many common types of data can be represented as functions that map coordinates to signal values, such as pixel locations to RGB values in the case of an image. Based on this view, data can be compressed by overfitting a compact neural network to its functional representation and then encoding the network weights. However, most current solutions for this are inefficient, as quantization to low-bit precision substantially degrades the reconstruction quality. To address this issue, we propose overfitting variational Bayesian neural networks to the data and compressing an approximate posterior weight sample using relative entropy coding instead of quantizing and entropy coding it. This strategy enables direct optimization of the rate-distortion performance by minimizing the $\beta$-ELBO, and target different rate-distortion trade-offs for a given network architecture by adjusting $\beta$. Moreover, we introduce an iterative algorithm for learning prior weight distributions and employ a pro
&lt;/p&gt;</description></item><item><title>&#27492;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#20030;&#38598;&#23725;&#20272;&#35745;&#22120;&#20013;&#23376;&#37319;&#26679;&#21644;&#23725;&#22238;&#24402;&#20043;&#38388;&#30340;&#31561;&#20215;&#24615;&#65292;&#21457;&#29616;&#20108;&#32773;&#22312;&#19968;&#23450;&#36335;&#24452;&#20013;&#26159;&#28176;&#36817;&#31561;&#20215;&#30340;&#65292;&#24182;&#25552;&#20986;&#20102;&#25968;&#25454;&#30456;&#20851;&#30340;&#26041;&#27861;&#30830;&#23450;&#31561;&#20215;&#36335;&#24452;&#65292;&#38388;&#25509;&#35299;&#20915;&#20102;&#23725;&#22238;&#24402;&#35843;&#20248;&#20013;&#39044;&#27979;&#39118;&#38505;&#21333;&#35843;&#24615;&#30340;&#24433;&#21709;&#22240;&#32032;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.18496</link><description>&lt;p&gt;
&#23376;&#37319;&#26679;&#19982;&#23725;&#22238;&#24402;&#30340;&#24191;&#20041;&#31561;&#20215;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Generalized equivalences between subsampling and ridge regularization. (arXiv:2305.18496v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18496
&lt;/p&gt;
&lt;p&gt;
&#27492;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#20030;&#38598;&#23725;&#20272;&#35745;&#22120;&#20013;&#23376;&#37319;&#26679;&#21644;&#23725;&#22238;&#24402;&#20043;&#38388;&#30340;&#31561;&#20215;&#24615;&#65292;&#21457;&#29616;&#20108;&#32773;&#22312;&#19968;&#23450;&#36335;&#24452;&#20013;&#26159;&#28176;&#36817;&#31561;&#20215;&#30340;&#65292;&#24182;&#25552;&#20986;&#20102;&#25968;&#25454;&#30456;&#20851;&#30340;&#26041;&#27861;&#30830;&#23450;&#31561;&#20215;&#36335;&#24452;&#65292;&#38388;&#25509;&#35299;&#20915;&#20102;&#23725;&#22238;&#24402;&#35843;&#20248;&#20013;&#39044;&#27979;&#39118;&#38505;&#21333;&#35843;&#24615;&#30340;&#24433;&#21709;&#22240;&#32032;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#38024;&#23545;&#20030;&#38598;&#23725;&#20272;&#35745;&#22120;&#65292;&#24314;&#31435;&#20102;&#23376;&#37319;&#26679;&#21644;&#23725;&#22238;&#24402;&#20043;&#38388;&#30340;&#31934;&#30830;&#32467;&#26500;&#21644;&#39118;&#38505;&#31561;&#20215;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#24403;&#29992;&#19981;&#21516;&#30340;&#23725;&#27491;&#21017;&#21270;&#27700;&#24179;$\lambda$&#21644;&#23376;&#37319;&#26679;&#27604;&#20363;$\psi$&#25311;&#21512;&#23376;&#26679;&#23725;&#20272;&#35745;&#22120;&#30340;&#32447;&#24615;&#21644;&#20108;&#27425;&#27867;&#20989;&#65292;&#22312;$(\lambda,\psi)$-&#24179;&#38754;&#19978;&#27839;&#30528;&#29305;&#23450;&#36335;&#24452;&#28176;&#36817;&#31561;&#20215;&#65288;&#20854;&#20013;$\psi$&#26159;&#29305;&#24449;&#32500;&#24230;&#19982;&#23376;&#37319;&#26679;&#22823;&#23567;&#30340;&#27604;&#29575;&#65289;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20165;&#35201;&#27714;&#29305;&#24449;&#21644;&#21709;&#24212;&#20998;&#24067;&#20855;&#26377;&#26377;&#30028;&#30697;&#65292;&#24182;&#20801;&#35768;&#20219;&#24847;&#32852;&#21512;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#25968;&#25454;&#30456;&#20851;&#30340;&#26041;&#27861;&#26469;&#30830;&#23450;$(\lambda,\psi)$&#30340;&#31561;&#20215;&#36335;&#24452;&#12290;&#25105;&#20204;&#32467;&#26524;&#30340;&#38388;&#25509;&#21547;&#20041;&#26159;&#65292;&#22312;&#25968;&#25454;&#26041;&#38754;&#27604;&#20363;&#20013;&#65292;&#35843;&#20248;&#30340;&#23725;&#22238;&#24402;&#21576;&#29616;&#20986;&#21333;&#35843;&#39044;&#27979;&#39118;&#38505;&#12290;&#36825;&#35299;&#20915;&#20102;Nakkiran&#31561;&#20154;&#25552;&#20986;&#30340;&#19968;&#20010;&#36817;&#26399;&#26410;&#35299;&#20915;&#30340;&#24320;&#25918;&#24615;&#38382;&#39064;&#65292;&#22312;&#19968;&#33324;&#25968;&#25454;&#20998;&#24067;&#21644;&#28201;&#21644;&#30340;&#27491;&#21017;&#26465;&#20214;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
We establish precise structural and risk equivalences between subsampling and ridge regularization for ensemble ridge estimators. Specifically, we prove that linear and quadratic functionals of subsample ridge estimators, when fitted with different ridge regularization levels $\lambda$ and subsample aspect ratios $\psi$, are asymptotically equivalent along specific paths in the $(\lambda, \psi )$-plane (where $\psi$ is the ratio of the feature dimension to the subsample size). Our results only require bounded moment assumptions on feature and response distributions and allow for arbitrary joint distributions. Furthermore, we provide a datadependent method to determine the equivalent paths of $(\lambda, \psi )$. An indirect implication of our equivalences is that optimally-tuned ridge regression exhibits a monotonic prediction risk in the data aspect ratio. This resolves a recent open problem raised by Nakkiran et al. under general data distributions and a mild regularity condition that
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38754;&#21521;&#26041;&#21521;&#30340;&#22810;&#30446;&#26631;&#38382;&#39064;&#65292;&#24182;&#32473;&#20986;&#20102;&#20004;&#31181;&#38543;&#26426;&#31639;&#27861;&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#29702;&#35770;&#19978;&#25910;&#25947;&#21040;&#24085;&#32047;&#25176;&#31283;&#23450;&#28857;&#12290;</title><link>http://arxiv.org/abs/2305.18409</link><description>&lt;p&gt;
&#38754;&#21521;&#26041;&#21521;&#30340;&#22810;&#30446;&#26631;&#23398;&#20064;&#65306;&#31616;&#21333;&#19988;&#21487;&#35777;&#26126;&#30340;&#38543;&#26426;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Direction-oriented Multi-objective Learning: Simple and Provable Stochastic Algorithms. (arXiv:2305.18409v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18409
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38754;&#21521;&#26041;&#21521;&#30340;&#22810;&#30446;&#26631;&#38382;&#39064;&#65292;&#24182;&#32473;&#20986;&#20102;&#20004;&#31181;&#38543;&#26426;&#31639;&#27861;&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#29702;&#35770;&#19978;&#25910;&#25947;&#21040;&#24085;&#32047;&#25176;&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#30446;&#26631;&#20248;&#21270;&#65288;MOO&#65289;&#24050;&#25104;&#20026;&#35768;&#22810;&#19982;&#22810;&#20010;&#30446;&#26631;&#30456;&#20851;&#30340;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#65288;&#22914;&#22810;&#26631;&#20934;&#23398;&#20064;&#21644;&#22810;&#20219;&#21153;&#23398;&#20064;&#65288;MTL&#65289;&#65289;&#20013;&#19968;&#20010;&#26377;&#24433;&#21709;&#21147;&#30340;&#26694;&#26550;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38754;&#21521;&#26041;&#21521;&#30340;&#22810;&#30446;&#26631;&#38382;&#39064;&#65292;&#36890;&#36807;&#22312;&#19968;&#20010;&#26041;&#21521;&#30340;&#37051;&#22495;&#20869;&#38480;&#21046;&#20844;&#20849;&#19979;&#38477;&#26041;&#21521;&#26469;&#35268;&#33539;&#32447;&#24615;&#32452;&#21512;&#30446;&#26631;&#30340;&#26368;&#20248;&#26041;&#21521;&#65292;&#20363;&#22914;MTL&#20013;&#30340;&#24179;&#22343;&#25439;&#22833;&#12290; &#36825;&#20010;&#20844;&#24335;&#21253;&#25324;GD&#21644;MGDA&#20316;&#20026;&#29305;&#27530;&#24773;&#20917;&#65292;&#20139;&#21463;&#20687;CAGrad&#20013;&#30340;&#38754;&#21521;&#26041;&#21521;&#30340;&#22909;&#22788;&#65292;&#20197;&#21450;&#26377;&#21033;&#20110;&#38543;&#26426;&#31639;&#27861;&#30340;&#35774;&#35745;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#38543;&#26426;&#26041;&#21521;&#23548;&#21521;&#22810;&#30446;&#26631;&#26799;&#24230;&#19979;&#38477;&#65288;SDMGrad&#65289;&#65292;&#23427;&#20351;&#29992;&#31616;&#21333;&#30340;SGD&#31867;&#22411;&#30340;&#26356;&#26032;&#31639;&#27861;&#65292;&#20197;&#21450;&#22312;&#30446;&#26631;&#25968;&#37327;&#36739;&#22810;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#39640;&#25928;&#30340;&#30446;&#26631;&#37319;&#26679;&#30340;SDMGrad-OS&#31639;&#27861;&#12290; &#23545;&#20110;&#24658;&#23450;&#30340;&#27491;&#21017;&#21270;&#21442;&#25968;&#955;&#65292;&#25105;&#20204;&#35777;&#26126;SDMGrad&#21644;SDMGrad-OS&#30830;&#23454;&#25910;&#25947;&#21040;&#24085;&#32047;&#25176;&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-objective optimization (MOO) has become an influential framework in many machine learning problems with multiple objectives such as learning with multiple criteria and multi-task learning (MTL). In this paper, we propose a new direction-oriented multi-objective problem by regularizing the common descent direction within a neighborhood of a direction that optimizes a linear combination of objectives such as the average loss in MTL. This formulation includes GD and MGDA as special cases, enjoys the direction-oriented benefit as in CAGrad, and facilitates the design of stochastic algorithms. To solve this problem, we propose Stochastic Direction-oriented Multi-objective Gradient descent (SDMGrad) with simple SGD type of updates, and its variant SDMGrad-OS with an efficient objective sampling in the setting where the number of objectives is large. For a constant-level regularization parameter $\lambda$, we show that SDMGrad and SDMGrad-OS provably converge to a Pareto stationary poin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#20445;&#30495;&#24230;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20302;&#12289;&#39640;&#20445;&#30495;&#24230;&#26679;&#26412;&#20013;&#20272;&#35745;&#29289;&#29702;&#31995;&#32479;&#20013;&#37327;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24179;&#34913;&#20102;&#35745;&#31639;&#25928;&#29575;&#21644;&#25968;&#20540;&#31934;&#24230;&#20043;&#38388;&#30340;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2305.16530</link><description>&lt;p&gt;
&#21452;&#20445;&#30495;&#24230;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#29992;&#20110;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Bi-fidelity Variational Auto-encoder for Uncertainty Quantification. (arXiv:2305.16530v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#20445;&#30495;&#24230;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20302;&#12289;&#39640;&#20445;&#30495;&#24230;&#26679;&#26412;&#20013;&#20272;&#35745;&#29289;&#29702;&#31995;&#32479;&#20013;&#37327;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24179;&#34913;&#20102;&#35745;&#31639;&#25928;&#29575;&#21644;&#25968;&#20540;&#31934;&#24230;&#20043;&#38388;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27169;&#22411;&#39564;&#35777;&#20013;&#65292;&#37327;&#21270;&#29289;&#29702;&#31995;&#32479;&#24863;&#20852;&#36259;&#30340;&#37327;&#30340;&#19981;&#30830;&#23450;&#24615;&#26159;&#19968;&#20010;&#20027;&#35201;&#30446;&#26631;&#12290;&#28982;&#32780;&#65292;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#38656;&#35201;&#24179;&#34913;&#35745;&#31639;&#25928;&#29575;&#21644;&#25968;&#20540;&#31934;&#24230;&#20043;&#38388;&#30340;&#38656;&#27714;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21452;&#20445;&#30495;&#24230;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;BF-VAE&#65289;&#20844;&#24335;&#65292;&#26088;&#22312;&#20174;&#29289;&#29702;&#31995;&#32479;&#20013;&#20302;&#12289;&#39640;&#20445;&#30495;&#24230;&#26679;&#26412;&#20013;&#20272;&#35745;&#19982;&#37327;&#24863;&#20852;&#36259;&#30340;&#37327;&#26377;&#20851;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#21033;&#29992;&#20174;&#20302;&#20445;&#30495;&#24230;&#26679;&#26412;&#24471;&#20986;&#30340;&#20449;&#24687;&#26469;&#36924;&#36817;&#39640;&#20445;&#30495;&#24230;&#37327;&#30340;&#32479;&#35745;&#20449;&#24687;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#30340;&#21452;&#20445;&#30495;&#24230;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#23558;&#20854;&#25972;&#21512;&#21040;VAE&#30340;&#27010;&#29575;&#32534;&#30721;-&#35299;&#30721;&#32467;&#26500;&#20013;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#20197;&#22312;&#23384;&#22312;&#26377;&#38480;&#39640;&#20445;&#30495;&#24230;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#22823;&#21270;&#39640;&#20445;&#30495;&#24230;&#23545;&#25968;&#20284;&#28982;&#30340;&#21464;&#20998;&#19979;&#30028;&#65292;&#20174;&#32780;&#20197;&#36739;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#21512;&#25104;&#39640;&#20445;&#30495;&#24230;&#30340;&#23454;&#29616;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;&#21508;&#31181;&#25968;&#20540;&#31034;&#20363;&#20013;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#21253;&#25324;&#38750;&#32447;&#24615;&#38543;&#26426;&#31995;&#32479;&#21644;&#35745;&#31639;&#27969;&#20307;&#21160;&#21147;&#23398;&#27169;&#25311;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantifying the uncertainty of quantities of interest (QoIs) from physical systems is a primary objective in model validation. However, achieving this goal entails balancing the need for computational efficiency with the requirement for numerical accuracy. To address this trade-off, we propose a novel bi-fidelity formulation of variational auto-encoders (BF-VAE) designed to estimate the uncertainty associated with a QoI from low-fidelity (LF) and high-fidelity (HF) samples of the QoI. This model allows for the approximation of the statistics of the HF QoI by leveraging information derived from its LF counterpart. Specifically, we design a bi-fidelity auto-regressive model in the latent space that is integrated within the VAE's probabilistic encoder-decoder structure. An effective algorithm is proposed to maximize the variational lower bound of the HF log-likelihood in the presence of limited HF data, resulting in the synthesis of HF realizations with a reduced computational cost. Addit
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#23545;176&#20010;&#25968;&#25454;&#38598;&#30340;&#27604;&#36739;&#20998;&#26512;&#21457;&#29616;&#65292;&#22312;&#35768;&#22810;&#25968;&#25454;&#38598;&#20013;&#65292;GBDT&#21644;NN&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#24322;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#65292;&#25110;&#32773;GBDT&#30340;&#36731;&#24494;&#36229;&#21442;&#25968;&#35843;&#25972;&#27604;&#36873;&#25321;&#26368;&#20339;&#31639;&#27861;&#26356;&#37325;&#35201;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#20154;&#21592;&#23545;965&#20010;&#20803;&#29305;&#24449;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#21457;&#29616;GBDT&#22312;&#39640;&#32500;&#31232;&#30095;&#25968;&#25454;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2305.02997</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20309;&#26102;&#22312;&#34920;&#26684;&#25968;&#25454;&#19978;&#32988;&#36807;&#22686;&#24378;&#26641;&#65311;
&lt;/p&gt;
&lt;p&gt;
When Do Neural Nets Outperform Boosted Trees on Tabular Data?. (arXiv:2305.02997v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02997
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#23545;176&#20010;&#25968;&#25454;&#38598;&#30340;&#27604;&#36739;&#20998;&#26512;&#21457;&#29616;&#65292;&#22312;&#35768;&#22810;&#25968;&#25454;&#38598;&#20013;&#65292;GBDT&#21644;NN&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#24322;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#65292;&#25110;&#32773;GBDT&#30340;&#36731;&#24494;&#36229;&#21442;&#25968;&#35843;&#25972;&#27604;&#36873;&#25321;&#26368;&#20339;&#31639;&#27861;&#26356;&#37325;&#35201;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#20154;&#21592;&#23545;965&#20010;&#20803;&#29305;&#24449;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#21457;&#29616;GBDT&#22312;&#39640;&#32500;&#31232;&#30095;&#25968;&#25454;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34920;&#26684;&#25968;&#25454;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#24120;&#29992;&#30340;&#25968;&#25454;&#31867;&#22411;&#20043;&#19968;&#12290;&#23613;&#31649;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#22312;&#34920;&#26684;&#25968;&#25454;&#19978;&#21462;&#24471;&#20102;&#26368;&#36817;&#30340;&#36827;&#23637;&#65292;&#20294;&#20154;&#20204;&#20173;&#22312;&#31215;&#26497;&#35752;&#35770;NN&#26159;&#21542;&#36890;&#24120;&#20248;&#20110;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#65288;GBDT&#65289;&#22312;&#34920;&#26684;&#25968;&#25454;&#19978;&#30340;&#34920;&#29616;&#65292;&#19968;&#20123;&#26368;&#36817;&#30340;&#24037;&#20316;&#35201;&#20040;&#35748;&#20026;GBDT&#22312;&#34920;&#26684;&#25968;&#25454;&#19978;&#19968;&#36143;&#20248;&#20110;NN&#65292;&#35201;&#20040;&#35748;&#20026;NN&#20248;&#20110;GBDT&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36864;&#19968;&#27493;&#38382;&#65306;'&#36825;&#37325;&#35201;&#21527;&#65311;'&#25105;&#20204;&#36890;&#36807;&#23545;176&#20010;&#25968;&#25454;&#38598;&#27604;&#36739;19&#31181;&#31639;&#27861;&#65292;&#36827;&#34892;&#20102;&#36804;&#20170;&#20026;&#27490;&#26368;&#22823;&#30340;&#34920;&#26684;&#25968;&#25454;&#20998;&#26512;&#65292;&#24182;&#21457;&#29616;'NN vs. GBDT'&#20105;&#35770;&#34987;&#36807;&#20998;&#24378;&#35843;&#65306;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#22312;&#30456;&#24403;&#22810;&#30340;&#25968;&#25454;&#38598;&#20013;&#65292;GBDT&#21644;NN&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#24322;&#35201;&#20040;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#65292;&#35201;&#20040;GBDT&#30340;&#36731;&#24494;&#36229;&#21442;&#25968;&#35843;&#25972;&#27604;&#36873;&#25321;&#26368;&#20339;&#31639;&#27861;&#26356;&#37325;&#35201;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;965&#20010;&#20803;&#29305;&#24449;&#65292;&#20197;&#30830;&#23450;&#25968;&#25454;&#38598;&#30340;&#21738;&#20123;&#29305;&#24615;&#20351;NN&#25110;GBDT&#26356;&#36866;&#21512;&#34920;&#29616;&#33391;&#22909;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#21457;&#29616;GBDT&#35201;&#27604;NN&#22312;&#39640;&#32500;&#31232;&#30095;&#25968;&#25454;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tabular data is one of the most commonly used types of data in machine learning. Despite recent advances in neural nets (NNs) for tabular data, there is still an active discussion on whether or not NNs generally outperform gradient-boosted decision trees (GBDTs) on tabular data, with several recent works arguing either that GBDTs consistently outperform NNs on tabular data, or vice versa. In this work, we take a step back and ask, 'does it matter?' We conduct the largest tabular data analysis to date, by comparing 19 algorithms across 176 datasets, and we find that the 'NN vs. GBDT' debate is overemphasized: for a surprisingly high number of datasets, either the performance difference between GBDTs and NNs is negligible, or light hyperparameter tuning on a GBDT is more important than selecting the best algorithm. Next, we analyze 965 metafeatures to determine what properties of a dataset make NNs or GBDTs better-suited to perform well. For example, we find that GBDTs are much better th
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35774;&#35745;&#20102;&#19968;&#31181;&#40657;&#30418;&#27169;&#22411;&#25552;&#21462;&#25915;&#20987;&#26041;&#27861;Marich&#65292;&#23427;&#20351;&#29992;&#20844;&#20849;&#25968;&#25454;&#38598;&#20013;&#30340;&#26368;&#23567;&#25968;&#37327;&#26597;&#35810;&#26469;&#21019;&#24314;&#19968;&#20010;&#19982;&#30446;&#26631;&#27169;&#22411;&#20855;&#26377;&#20449;&#24687;&#20016;&#23500;&#24230;&#21644;&#20998;&#24067;&#31561;&#20215;&#24615;&#30340;&#21103;&#26412;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;Marich&#33021;&#25552;&#21462;&#20855;&#26377;60-95%&#30495;&#23454;&#27169;&#22411;&#20934;&#30830;&#24615;&#30340;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2302.08466</link><description>&lt;p&gt;
Marich&#65306;&#19968;&#31181;&#20351;&#29992;&#20844;&#20849;&#25968;&#25454;&#30340;&#26597;&#35810;&#25928;&#29575;&#39640;&#30340;&#20998;&#24067;&#31561;&#20215;&#27169;&#22411;&#25552;&#21462;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Marich: A Query-efficient Distributionally Equivalent Model Extraction Attack using Public Data. (arXiv:2302.08466v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08466
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35774;&#35745;&#20102;&#19968;&#31181;&#40657;&#30418;&#27169;&#22411;&#25552;&#21462;&#25915;&#20987;&#26041;&#27861;Marich&#65292;&#23427;&#20351;&#29992;&#20844;&#20849;&#25968;&#25454;&#38598;&#20013;&#30340;&#26368;&#23567;&#25968;&#37327;&#26597;&#35810;&#26469;&#21019;&#24314;&#19968;&#20010;&#19982;&#30446;&#26631;&#27169;&#22411;&#20855;&#26377;&#20449;&#24687;&#20016;&#23500;&#24230;&#21644;&#20998;&#24067;&#31561;&#20215;&#24615;&#30340;&#21103;&#26412;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;Marich&#33021;&#25552;&#21462;&#20855;&#26377;60-95%&#30495;&#23454;&#27169;&#22411;&#20934;&#30830;&#24615;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#35774;&#35745;&#40657;&#30418;&#27169;&#22411;&#25552;&#21462;&#25915;&#20987;&#65292;&#35813;&#25915;&#20987;&#21487;&#20197;&#36890;&#36807;&#19968;&#20010;&#39044;&#27979;API&#20174;&#19968;&#20010;&#20844;&#24320;&#21487;&#29992;&#30340;&#25968;&#25454;&#38598;&#21521;&#30446;&#26631;ML&#27169;&#22411;&#21457;&#36865;&#26368;&#23567;&#25968;&#37327;&#30340;&#26597;&#35810;&#65292;&#20197;&#21019;&#24314;&#19968;&#20010;&#20855;&#26377;&#20449;&#24687;&#20016;&#23500;&#24230;&#21644;&#20998;&#24067;&#31561;&#20215;&#24615;&#30340;&#30446;&#26631;&#21103;&#26412;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23450;&#20041;&#20102;&#20998;&#24067;&#31561;&#20215;&#21644;&#26368;&#22823;&#20449;&#24687;&#27169;&#22411;&#25552;&#21462;&#25915;&#20987;&#65292;&#24182;&#23558;&#23427;&#20204;&#31616;&#21270;&#20026;&#19968;&#20010;&#21464;&#20998;&#20248;&#21270;&#38382;&#39064;&#12290;&#25915;&#20987;&#32773;&#39034;&#24207;&#35299;&#20915;&#36825;&#20010;&#20248;&#21270;&#38382;&#39064;&#65292;&#36873;&#25321;&#26368;&#20855;&#20449;&#24687;&#37327;&#30340;&#26597;&#35810;&#65292;&#21516;&#26102;&#26368;&#22823;&#21270;&#29109;&#21644;&#38477;&#20302;&#30446;&#26631;&#21644;&#30423;&#31363;&#27169;&#22411;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#31181;&#22522;&#20110;&#20027;&#21160;&#25277;&#26679;&#30340;&#26597;&#35810;&#36873;&#25321;&#31639;&#27861;Marich&#65292;&#23427;&#26159;&#27169;&#22411;&#26080;&#20851;&#30340;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#22312;&#19981;&#21516;&#30340;&#25991;&#26412;&#21644;&#22270;&#20687;&#25968;&#25454;&#38598;&#20197;&#21450;&#19981;&#21516;&#30340;&#27169;&#22411;&#19978;&#35780;&#20272;&#20102;Marich&#12290;Marich&#25552;&#21462;&#30340;&#27169;&#22411;&#23454;&#29616;&#20102;&#30495;&#23454;&#27169;&#22411;&#20934;&#30830;&#24615;&#30340;60-95&#65285;&#65292;&#24182;&#20351;&#29992;&#20102;&#26469;&#33258;&#20844;&#24320;&#21487;&#29992;&#25968;&#25454;&#38598;&#30340;1,000-8,500&#20010;&#26597;&#35810;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study design of black-box model extraction attacks that can send minimal number of queries from a publicly available dataset to a target ML model through a predictive API with an aim to create an informative and distributionally equivalent replica of the target. First, we define distributionally equivalent and Max-Information model extraction attacks, and reduce them into a variational optimisation problem. The attacker sequentially solves this optimisation problem to select the most informative queries that simultaneously maximise the entropy and reduce the mismatch between the target and the stolen models. This leads to an active sampling-based query selection algorithm, Marich, which is model-oblivious. Then, we evaluate Marich on different text and image data sets, and different models, including CNNs and BERT. Marich extracts models that achieve $\sim 60-95\%$ of true model's accuracy and uses $\sim 1,000 - 8,500$ queries from the publicly available datasets, which are differen
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#36125;&#21494;&#26031;&#30340;&#35282;&#24230;&#20272;&#35745;&#26080;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;&#20013;&#27745;&#26579;&#22240;&#23376;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#22810;&#20010;&#24322;&#24120;&#26816;&#27979;&#22120;&#30340;&#36755;&#20986;&#20316;&#20026;&#34920;&#31034;&#65292;&#24182;&#36890;&#36807;&#29305;&#23450;&#30340;&#28151;&#21512;&#24418;&#24335;&#36827;&#34892;&#20272;&#35745;&#12290;&#22312;22&#20010;&#25968;&#25454;&#38598;&#30340;&#23454;&#35777;&#30740;&#31350;&#20013;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>http://arxiv.org/abs/2210.10487</link><description>&lt;p&gt;
&#26080;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;&#20013;&#27745;&#26579;&#22240;&#23376;&#20998;&#24067;&#30340;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Estimating the Contamination Factor's Distribution in Unsupervised Anomaly Detection. (arXiv:2210.10487v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.10487
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#36125;&#21494;&#26031;&#30340;&#35282;&#24230;&#20272;&#35745;&#26080;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;&#20013;&#27745;&#26579;&#22240;&#23376;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#22810;&#20010;&#24322;&#24120;&#26816;&#27979;&#22120;&#30340;&#36755;&#20986;&#20316;&#20026;&#34920;&#31034;&#65292;&#24182;&#36890;&#36807;&#29305;&#23450;&#30340;&#28151;&#21512;&#24418;&#24335;&#36827;&#34892;&#20272;&#35745;&#12290;&#22312;22&#20010;&#25968;&#25454;&#38598;&#30340;&#23454;&#35777;&#30740;&#31350;&#20013;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#22312;&#26080;&#30417;&#30563;&#24773;&#20917;&#19979;&#36890;&#36807;&#20026;&#31034;&#20363;&#20998;&#37197;&#22522;&#20110;&#21508;&#31181;&#21551;&#21457;&#24335;&#35268;&#21017;&#30340;&#23454;&#20540;&#24322;&#24120;&#20998;&#25968;&#26469;&#35782;&#21035;&#19981;&#31526;&#21512;&#39044;&#26399;&#34892;&#20026;&#30340;&#31034;&#20363;&#12290;&#36825;&#20123;&#20998;&#25968;&#38656;&#35201;&#36890;&#36807;&#38408;&#20540;&#21270;&#36716;&#25442;&#20026;&#23454;&#38469;&#39044;&#27979;&#65292;&#20174;&#32780;&#20351;&#34987;&#26631;&#35760;&#20026;&#24322;&#24120;&#30340;&#31034;&#20363;&#27604;&#20363;&#31561;&#20110;&#39044;&#26399;&#30340;&#24322;&#24120;&#27604;&#20363;&#65292;&#31216;&#20026;&#27745;&#26579;&#22240;&#23376;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#30446;&#21069;&#27809;&#26377;&#22909;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#27745;&#26579;&#22240;&#23376;&#26412;&#36523;&#12290;&#25105;&#20204;&#20174;&#36125;&#21494;&#26031;&#30340;&#35282;&#24230;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#20272;&#35745;&#32473;&#23450;&#26080;&#26631;&#31614;&#25968;&#25454;&#38598;&#30340;&#27745;&#26579;&#22240;&#23376;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#21033;&#29992;&#22810;&#20010;&#24322;&#24120;&#26816;&#27979;&#22120;&#30340;&#36755;&#20986;&#20316;&#20026;&#24050;&#32463;&#25429;&#25417;&#21040;&#24322;&#24120;&#24615;&#30340;&#34920;&#31034;&#65292;&#24182;&#20351;&#29992;&#29305;&#23450;&#30340;&#28151;&#21512;&#24418;&#24335;&#26469;&#20272;&#35745;&#27745;&#26579;&#12290;&#22312;22&#20010;&#25968;&#25454;&#38598;&#30340;&#23454;&#35777;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#34920;&#26126;&#20272;&#35745;&#30340;&#20998;&#24067;&#26159;&#33391;&#22909;&#26657;&#20934;&#30340;&#65292;&#24182;&#19988;&#36890;&#36807;&#35774;&#32622;&#38408;&#20540;&#20351;&#29992;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#21462;&#24471;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Anomaly detection methods identify examples that do not follow the expected behaviour, typically in an unsupervised fashion, by assigning real-valued anomaly scores to the examples based on various heuristics. These scores need to be transformed into actual predictions by thresholding, so that the proportion of examples marked as anomalies equals the expected proportion of anomalies, called contamination factor. Unfortunately, there are no good methods for estimating the contamination factor itself. We address this need from a Bayesian perspective, introducing a method for estimating the posterior distribution of the contamination factor of a given unlabeled dataset. We leverage on outputs of several anomaly detectors as a representation that already captures the basic notion of anomalousness and estimate the contamination using a specific mixture formulation. Empirically on 22 datasets, we show that the estimated distribution is well-calibrated and that setting the threshold using the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#20934;&#31639;&#26415;&#28151;&#21512;&#12289;&#25955;&#24230;&#26368;&#23567;&#21270;&#21644;Bregman&#20449;&#24687;&#30340;&#20840;&#38754;&#20998;&#26512;&#12290;&#36890;&#36807;&#22312;&#23494;&#24230;&#20989;&#25968;&#30340;&#21333;&#35843;&#23884;&#20837;&#19979;&#20351;&#29992;Bregman&#25955;&#24230;&#65292;&#25105;&#20204;&#23558;&#24120;&#35265;&#30340;&#25955;&#24230;&#20989;&#25968;&#19982;&#36864;&#28779;&#36335;&#24452;&#19978;&#30340;&#20013;&#38388;&#23494;&#24230;&#20851;&#32852;&#36215;&#26469;&#12290;</title><link>http://arxiv.org/abs/2209.07481</link><description>&lt;p&gt;
&#20934;&#31639;&#26415;&#28151;&#21512;&#12289;&#25955;&#24230;&#26368;&#23567;&#21270;&#21644;Bregman&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
Quasi-Arithmetic Mixtures, Divergence Minimization, and Bregman Information. (arXiv:2209.07481v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.07481
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#20934;&#31639;&#26415;&#28151;&#21512;&#12289;&#25955;&#24230;&#26368;&#23567;&#21270;&#21644;Bregman&#20449;&#24687;&#30340;&#20840;&#38754;&#20998;&#26512;&#12290;&#36890;&#36807;&#22312;&#23494;&#24230;&#20989;&#25968;&#30340;&#21333;&#35843;&#23884;&#20837;&#19979;&#20351;&#29992;Bregman&#25955;&#24230;&#65292;&#25105;&#20204;&#23558;&#24120;&#35265;&#30340;&#25955;&#24230;&#20989;&#25968;&#19982;&#36864;&#28779;&#36335;&#24452;&#19978;&#30340;&#20013;&#38388;&#23494;&#24230;&#20851;&#32852;&#36215;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#29992;&#20110;&#20174;&#22797;&#26434;&#20998;&#24067;&#20013;&#37319;&#26679;&#21644;&#20272;&#35745;&#24402;&#19968;&#21270;&#24120;&#25968;&#36890;&#24120;&#27169;&#25311;&#27839;&#30528;&#36830;&#25509;&#21487;&#36319;&#36394;&#21021;&#22987;&#20998;&#24067;&#21644;&#30446;&#26631;&#23494;&#24230;&#30340;&#36864;&#28779;&#36335;&#24452;&#30340;&#20013;&#38388;&#20998;&#24067;&#30340;&#26679;&#26412;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#20351;&#29992;&#20934;&#31639;&#26415;&#24179;&#22343;&#26500;&#24314;&#20102;&#36864;&#28779;&#36335;&#24452;&#65292;&#24182;&#35299;&#37322;&#20102;&#30001;&#27492;&#20135;&#29983;&#30340;&#20013;&#38388;&#23494;&#24230;&#26159;&#26368;&#23567;&#21270;&#26399;&#26395;&#25955;&#24230;&#21040;&#31471;&#28857;&#30340;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#23494;&#24230;&#20989;&#25968;&#30340;&#21333;&#35843;&#23884;&#20837;&#19979;&#20351;&#29992;Bregman&#25955;&#24230;&#23545;&#36825;&#20010;&#8220;&#36136;&#24515;&#8221;&#24615;&#36136;&#36827;&#34892;&#20102;&#20840;&#38754;&#20998;&#26512;&#65292;&#20174;&#32780;&#23558;&#24120;&#35265;&#30340;&#25955;&#24230;&#65288;&#22914;Amari&#21644;Renyi&#30340;alpha&#25955;&#24230;&#12289;&#65288;alpha&#65292;beta&#65289;&#25955;&#24230;&#21644;Jensen-Shannon&#25955;&#24230;&#65289;&#19982;&#27839;&#30528;&#36864;&#28779;&#36335;&#24452;&#30340;&#20013;&#38388;&#23494;&#24230;&#20851;&#32852;&#36215;&#26469;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#31361;&#20986;&#20102;&#21442;&#25968;&#21270;&#26063;&#12289;&#20934;&#31639;&#26415;&#24179;&#22343;&#21644;&#25955;&#24230;&#20989;&#25968;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#20351;&#29992;&#20102;Zhang&#30340;rho-tau Bregman&#25955;&#24230;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Markov Chain Monte Carlo methods for sampling from complex distributions and estimating normalization constants often simulate samples from a sequence of intermediate distributions along an annealing path, which bridges between a tractable initial distribution and a target density of interest. Prior work has constructed annealing paths using quasi-arithmetic means, and interpreted the resulting intermediate densities as minimizing an expected divergence to the endpoints. We provide a comprehensive analysis of this 'centroid' property using Bregman divergences under a monotonic embedding of the density function, thereby associating common divergences such as Amari's and Renyi's ${\alpha}$-divergences, ${(\alpha,\beta)}$-divergences, and the Jensen-Shannon divergence with intermediate densities along an annealing path. Our analysis highlights the interplay between parametric families, quasi-arithmetic means, and divergence functions using the rho-tau Bregman divergence framework of Zhang
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#25340;&#25509;&#23884;&#20837;&#26041;&#27861;&#20013;&#35843;&#21442;&#21442;&#25968;&#30340;&#36873;&#25321;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#30417;&#30563;&#36873;&#25321;&#21442;&#25968;&#65292;&#24182;&#21457;&#29616;&#20102;&#26032;&#30340;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#29616;&#35937;&#12290;</title><link>http://arxiv.org/abs/2207.07218</link><description>&lt;p&gt;
&#20851;&#20110;&#25340;&#25509;&#23884;&#20837;&#26041;&#27861;&#35843;&#21442;&#21442;&#25968;&#36873;&#25321;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Selection of Tuning Parameters for Patch-Stitching Embedding Methods. (arXiv:2207.07218v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.07218
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25340;&#25509;&#23884;&#20837;&#26041;&#27861;&#20013;&#35843;&#21442;&#21442;&#25968;&#30340;&#36873;&#25321;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#30417;&#30563;&#36873;&#25321;&#21442;&#25968;&#65292;&#24182;&#21457;&#29616;&#20102;&#26032;&#30340;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#32463;&#20856;&#30340;&#32553;&#25918;&#26041;&#27861;&#21644;&#20027;&#25104;&#20998;&#20998;&#26512;&#37117;&#19981;&#38656;&#35201;&#35843;&#21442;&#65292;&#20294;&#20854;&#20182;&#23884;&#20837;&#22810;&#20803;&#25968;&#25454;&#30340;&#26041;&#27861;&#21017;&#38656;&#35201;&#36873;&#25321;&#19968;&#20010;&#25110;&#22810;&#20010;&#35843;&#21442;&#21442;&#25968;&#12290;&#30001;&#20110;&#26080;&#30417;&#30563;&#30340;&#29305;&#24615;&#65292;&#36825;&#20010;&#35843;&#21442;&#36807;&#31243;&#21487;&#33021;&#20250;&#38750;&#24120;&#22256;&#38590;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#19988;&#36817;&#20046;&#26174;&#32780;&#26131;&#35265;&#30340;&#26041;&#27861;&#26469;&#30417;&#30563;&#36873;&#25321;&#35843;&#21442;&#21442;&#25968;&#65306;&#26368;&#23567;&#21270;&#19968;&#31181;&#24212;&#21147;&#27010;&#24565;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#26041;&#27861;&#24212;&#29992;&#20110;&#20856;&#22411;&#30340;&#25340;&#25509;&#23884;&#20837;&#26041;&#27861;&#20013;&#30340;&#34917;&#19969;&#22823;&#23567;&#36873;&#25321;&#65292;&#26080;&#35770;&#26159;&#22312;&#22810;&#32500;&#32553;&#25918;&#65288;&#21448;&#31216;&#32593;&#32476;&#23450;&#20301;&#65289;&#35774;&#32622;&#20013;&#36824;&#26159;&#22312;&#38477;&#32500;&#65288;&#21448;&#31216;&#27969;&#24418;&#23398;&#20064;&#65289;&#35774;&#32622;&#20013;&#12290;&#22312;&#25105;&#20204;&#30340;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#19968;&#31181;&#26032;&#30340;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;
While classical scaling, just like principal component analysis, is parameter-free, other methods for embedding multivariate data require the selection of one or several tuning parameters. This tuning can be difficult due to the unsupervised nature of the situation. We propose a simple, almost obvious, approach to supervise the choice of tuning parameter(s): minimize a notion of stress. We apply this approach to the selection of the patch size in a prototypical patch-stitching embedding method, both in the multidimensional scaling (aka network localization) setting and in the dimensionality reduction (aka manifold learning) setting. In our study, we uncover a new bias--variance tradeoff phenomenon.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;Fr&#233;chet&#22343;&#20540;&#21644;&#24418;&#29366;&#19981;&#21464;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26816;&#27979;&#21151;&#33021;&#24615;&#36718;&#24275;&#20013;&#30340;&#24418;&#29366;&#21464;&#21270;&#65292;&#24182;&#26500;&#24314;&#20102;&#21151;&#33021;&#24615;&#25968;&#25454;&#30340;&#25511;&#21046;&#22270;&#65292;&#21487;&#35299;&#37322;&#24615;&#24378;&#19988;&#33021;&#35782;&#21035;&#28508;&#22312;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2010.02968</link><description>&lt;p&gt;
&#21151;&#33021;&#24615;&#36718;&#24275;&#24314;&#27169;&#21644;&#21487;&#35299;&#37322;&#24418;&#29366;&#21464;&#21270;&#26816;&#27979;&#65306;&#32467;&#21512;Fr&#233;chet&#22343;&#20540;&#19982;&#24418;&#29366;&#19981;&#21464;&#27169;&#22411;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Modelling of functional profiles and explainable shape shifts detection: An approach combining the notion of the Fr\'echet mean with the shape invariant model}. (arXiv:2010.02968v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2010.02968
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;Fr&#233;chet&#22343;&#20540;&#21644;&#24418;&#29366;&#19981;&#21464;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26816;&#27979;&#21151;&#33021;&#24615;&#36718;&#24275;&#20013;&#30340;&#24418;&#29366;&#21464;&#21270;&#65292;&#24182;&#26500;&#24314;&#20102;&#21151;&#33021;&#24615;&#25968;&#25454;&#30340;&#25511;&#21046;&#22270;&#65292;&#21487;&#35299;&#37322;&#24615;&#24378;&#19988;&#33021;&#35782;&#21035;&#28508;&#22312;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#26816;&#27979;&#21151;&#33021;&#24615;&#36718;&#24275;&#20013;&#24418;&#29366;&#21464;&#21270;&#30340;&#24314;&#27169;&#26694;&#26550;&#65292;&#32467;&#21512;&#20102;Fr&#233;chet&#22343;&#20540;&#27010;&#24565;&#21644;&#21464;&#24418;&#27169;&#22411;&#30340;&#27010;&#24565;&#12290;&#21033;&#29992;Fr&#233;chet&#22343;&#20540;&#25552;&#20379;&#30340;&#24191;&#20041;&#22343;&#20540;&#24863;&#30693;&#33021;&#22815;&#25429;&#25417;&#30740;&#31350;&#23545;&#35937;&#36718;&#24275;&#30340;&#20856;&#22411;&#27169;&#24335;&#65292;&#32780;&#21464;&#24418;&#27169;&#22411;&#30340;&#27010;&#24565;&#65292;&#29305;&#21035;&#26159;&#24418;&#29366;&#19981;&#21464;&#27169;&#22411;&#65292;&#20801;&#35768;&#23545;&#36718;&#24275;&#19982;&#20856;&#22411;&#24418;&#29366;&#20043;&#38388;&#30340;&#20559;&#24046;&#36827;&#34892;&#21487;&#35299;&#37322;&#30340;&#21442;&#25968;&#21270;&#12290;&#26500;&#24314;&#21644;&#25552;&#20986;&#20102;&#19982;&#25968;&#25454;&#30340;&#21151;&#33021;&#24615;&#29305;&#24615;&#21644;&#25152;&#37319;&#29992;&#30340;&#21464;&#24418;&#27169;&#22411;&#30456;&#20860;&#23481;&#30340;EWMA&#31867;&#22411;&#25511;&#21046;&#22270;&#65292;&#21033;&#29992;&#30740;&#31350;&#23545;&#35937;&#30340;&#36718;&#24275;&#22312;&#24191;&#20041;&#22343;&#20540;&#24863;&#30693;&#19979;&#30340;&#26576;&#20123;&#24418;&#29366;&#29305;&#24449;&#65292;&#23454;&#29616;&#23545;&#24418;&#29366;&#21644;/&#25110;&#21464;&#24418;&#36807;&#31243;&#28508;&#22312;&#21464;&#21270;&#30340;&#35782;&#21035;&#12290;&#36827;&#19968;&#27493;&#23558;&#24418;&#29366;&#21464;&#24418;&#36807;&#31243;&#30340;&#28508;&#22312;&#21464;&#21270;&#21306;&#20998;&#20026;&#19982;&#24133;&#24230;&#21644;/&#25110;&#30456;&#20301;&#30456;&#20851;&#30340;&#26174;&#33879;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
A modelling framework suitable for detecting shape shifts in functional profiles combining the notion of Fr\'echet mean and the concept of deformation models is developed and proposed. The generalized mean sense offerred by the Fr\'echet mean notion is employed to capture the typical pattern of the profiles under study, while the concept of deformation models, and in particular of the shape invariant model, allows for interpretable parameterizations of profile's deviations from the typical shape. EWMA-type control charts compatible with the functional nature of data and the employed deformation model are built and proposed, exploiting certain shape characteristics of the profiles under study with respect to the generalised mean sense, allowing for the identification of potential shifts concerning the shape and/or the deformation process. Potential shifts in the shape deformation process, are further distingu\-ished to significant shifts with respect to amplitude and/or the phase of the
&lt;/p&gt;</description></item></channel></rss>