<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#20219;&#21153;&#20013;&#22522;&#20110;&#26041;&#24046;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#24230;&#37327;&#30340;&#39564;&#35777;&#65292;&#21457;&#29616;&#19968;&#33268;&#24615;&#21644;&#36866;&#24212;&#24615;&#26159;&#20114;&#34917;&#30340;&#39564;&#35777;&#30446;&#26631;&#65292;&#24182;&#25552;&#20986;&#20102;&#36866;&#24212;&#24615;&#39564;&#35777;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.06240</link><description>&lt;p&gt;
&#19968;&#33268;&#24615;&#21644;&#36866;&#24212;&#24615;&#26159;&#39564;&#35777;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#20219;&#21153;&#20013;&#22522;&#20110;&#26041;&#24046;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#24230;&#37327;&#30340;&#20114;&#34917;&#30446;&#26631;
&lt;/p&gt;
&lt;p&gt;
Consistency and adaptivity are complementary targets for the validation of variance-based uncertainty quantification metrics in machine learning regression tasks. (arXiv:2309.06240v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06240
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#20219;&#21153;&#20013;&#22522;&#20110;&#26041;&#24046;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#24230;&#37327;&#30340;&#39564;&#35777;&#65292;&#21457;&#29616;&#19968;&#33268;&#24615;&#21644;&#36866;&#24212;&#24615;&#26159;&#20114;&#34917;&#30340;&#39564;&#35777;&#30446;&#26631;&#65292;&#24182;&#25552;&#20986;&#20102;&#36866;&#24212;&#24615;&#39564;&#35777;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26159;&#26448;&#26009;&#21644;&#21270;&#23398;&#31185;&#23398;&#20013;&#35768;&#22810;&#30740;&#31350;&#30340;&#28966;&#28857;&#12290;&#30446;&#21069;&#24050;&#32463;&#35748;&#35782;&#21040;&#24179;&#22343;&#26657;&#20934;&#26159;&#19981;&#36275;&#22815;&#30340;&#65292;&#22823;&#22810;&#25968;&#30740;&#31350;&#37117;&#20351;&#29992;&#39069;&#22806;&#30340;&#26041;&#27861;&#26469;&#27979;&#35797;&#26465;&#20214;&#26657;&#20934;&#65292;&#21363;&#19968;&#33268;&#24615;&#12290;&#19968;&#33268;&#24615;&#20027;&#35201;&#36890;&#36807;&#21487;&#38752;&#24615;&#22270;&#26469;&#35780;&#20272;&#12290;&#28982;&#32780;&#65292;&#38500;&#20102;&#24179;&#22343;&#26657;&#20934;&#20043;&#22806;&#36824;&#23384;&#22312;&#19968;&#31181;&#26041;&#27861;&#65292;&#21363;&#22522;&#20110;&#36755;&#20837;&#29305;&#24449;&#30340;&#26465;&#20214;&#26657;&#20934;&#65292;&#20063;&#23601;&#26159;&#36866;&#24212;&#24615;&#12290;&#23454;&#38469;&#19978;&#65292;&#36866;&#24212;&#24615;&#26159;ML-UQ&#26041;&#27861;&#30340;&#26368;&#32456;&#29992;&#25143;&#20851;&#27880;&#30340;&#20027;&#35201;&#38382;&#39064;&#65292;&#20182;&#20204;&#23547;&#27714;&#23545;&#29305;&#24449;&#31354;&#38388;&#20013;&#30340;&#20219;&#20309;&#28857;&#30340;&#39044;&#27979;&#21644;&#19981;&#30830;&#23450;&#24615;&#30340;&#21487;&#38752;&#24615;&#12290;&#26412;&#25991;&#26088;&#22312;&#23637;&#31034;&#19968;&#33268;&#24615;&#21644;&#36866;&#24212;&#24615;&#26159;&#20114;&#34917;&#30340;&#39564;&#35777;&#30446;&#26631;&#65292;&#24182;&#19988;&#22909;&#30340;&#19968;&#33268;&#24615;&#24182;&#19981;&#24847;&#21619;&#30528;&#22909;&#30340;&#36866;&#24212;&#24615;&#12290;&#25991;&#31456;&#25552;&#20986;&#24182;&#22312;&#19968;&#20010;&#20856;&#22411;&#31034;&#20363;&#19978;&#36827;&#34892;&#20102;&#36866;&#24212;&#24615;&#39564;&#35777;&#26041;&#27861;&#30340;&#35828;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reliable uncertainty quantification (UQ) in machine learning (ML) regression tasks is becoming the focus of many studies in materials and chemical science. It is now well understood that average calibration is insufficient, and most studies implement additional methods testing the conditional calibration with respect to uncertainty, i.e. consistency. Consistency is assessed mostly by so-called reliability diagrams. There exists however another way beyond average calibration, which is conditional calibration with respect to input features, i.e. adaptivity. In practice, adaptivity is the main concern of the final users of a ML-UQ method, seeking for the reliability of predictions and uncertainties for any point in features space. This article aims to show that consistency and adaptivity are complementary validation targets, and that a good consistency does not imply a good adaptivity. Adapted validation methods are proposed and illustrated on a representative example.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20805;&#28385;&#22242;&#22270;&#30340;&#27010;&#24565;&#65292;&#24182;&#19988;&#21457;&#29616;&#22312;&#31616;&#21333;&#22270;&#20013;&#65292;&#20805;&#28385;&#22242;&#22270;&#30340;&#26368;&#22823;&#25968;&#37327;&#21462;&#20915;&#20110;&#39281;&#21644;&#22797;&#21512;&#20805;&#28385;&#22242;&#22270;&#12290;&#36890;&#36807;&#20855;&#20307;&#35745;&#31639;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#22312;n&#20010;&#39030;&#28857;&#19978;&#20855;&#26377;&#26368;&#22810;&#26368;&#22823;&#22242;&#25968;&#37327;&#30340;&#22270;&#24418;&#24335;&#34920;&#36798;&#24335;&#12290;</title><link>http://arxiv.org/abs/2307.14120</link><description>&lt;p&gt;
&#20316;&#20026;&#35745;&#31639;&#31616;&#21333;&#22270;&#30340;&#26368;&#22823;&#22242;&#30340;&#26368;&#22823;&#25968;&#37327;&#30340;&#25163;&#27573;&#30340;&#20805;&#28385;&#22242;&#22270;
&lt;/p&gt;
&lt;p&gt;
Cliqueful graphs as a means of calculating the maximal number of maximum cliques of simple graphs. (arXiv:2307.14120v1 [math.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14120
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20805;&#28385;&#22242;&#22270;&#30340;&#27010;&#24565;&#65292;&#24182;&#19988;&#21457;&#29616;&#22312;&#31616;&#21333;&#22270;&#20013;&#65292;&#20805;&#28385;&#22242;&#22270;&#30340;&#26368;&#22823;&#25968;&#37327;&#21462;&#20915;&#20110;&#39281;&#21644;&#22797;&#21512;&#20805;&#28385;&#22242;&#22270;&#12290;&#36890;&#36807;&#20855;&#20307;&#35745;&#31639;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#22312;n&#20010;&#39030;&#28857;&#19978;&#20855;&#26377;&#26368;&#22810;&#26368;&#22823;&#22242;&#25968;&#37327;&#30340;&#22270;&#24418;&#24335;&#34920;&#36798;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#20010;&#31616;&#21333;&#22270;&#22312;n&#20010;&#39030;&#28857;&#19978;&#21487;&#33021;&#21253;&#21547;&#35768;&#22810;&#26368;&#22823;&#22242;&#12290;&#20294;&#23427;&#21487;&#33021;&#21253;&#21547;&#22810;&#23569;&#20010;&#21602;&#65311;&#25105;&#20204;&#23558;&#23637;&#31034;&#26368;&#22823;&#22242;&#30340;&#26368;&#22823;&#25968;&#37327;&#21462;&#20915;&#20110;&#25152;&#35859;&#30340;&#20805;&#28385;&#22242;&#22270;&#65292;&#20855;&#20307;&#22320;&#35828;&#65292;&#22914;&#26524;n&#8805;15&#65292;&#25105;&#20204;&#23558;&#23637;&#31034;&#23427;&#21462;&#20915;&#20110;&#39281;&#21644;&#22797;&#21512;&#20805;&#28385;&#22242;&#22270;&#12290;&#21033;&#29992;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#23558;&#23637;&#31034;&#21253;&#21547;3^{&#8970;n/3&#8971;}c&#20010;&#26368;&#22823;&#22242;&#30340;&#22270;&#22312;n&#20010;&#39030;&#28857;&#19978;&#20855;&#26377;&#26368;&#22810;&#30340;&#26368;&#22823;&#22242;&#25968;&#37327;&#65292;&#20854;&#20013;c&#8712;{1,4/3,2}&#65292;&#21462;&#20915;&#20110;n&#27169;3&#30340;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
A simple graph on $n$ vertices may contain a lot of maximum cliques. But how many can it potentially contain? We will show that the maximum number of maximum cliques is taken over so-called cliqueful graphs, more specifically, later we will show that it is taken over saturated composite cliqueful graphs, if $n \ge 15$. Using this we will show that the graph that contains $3^{\lfloor n/3 \rfloor}c$ maxcliques has the most number of maxcliques on $n$ vertices, where $c\in\{1,\frac{4}{3},2\}$, depending on $n \text{ mod } 3$.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20004;&#20010;&#19981;&#21516;&#32423;&#21035;&#33258;&#36866;&#24212;&#24615;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#26041;&#27861;&#65292;&#23545;&#19981;&#21516;&#31867;&#22411;&#30340;&#25439;&#22833;&#20989;&#25968;&#20855;&#26377;&#22810;&#31181;&#36951;&#25022;&#30028;&#65292;&#24182;&#22312;&#20998;&#26512;&#20013;&#30452;&#25509;&#24212;&#29992;&#20110;&#23567;&#25439;&#22833;&#30028;&#12290;&#21516;&#26102;&#65292;&#23427;&#19982;&#23545;&#25239;&#24615;/&#38543;&#26426;&#20984;&#20248;&#21270;&#21644;&#21338;&#24328;&#35770;&#26377;&#30528;&#28145;&#21051;&#30340;&#32852;&#31995;&#12290;</title><link>http://arxiv.org/abs/2307.08360</link><description>&lt;p&gt;
&#20855;&#26377;&#36880;&#28176;&#21464;&#21270;&#30340;&#36890;&#29992;&#22312;&#32447;&#23398;&#20064;&#65306;&#19968;&#31181;&#22810;&#23618;&#22312;&#32447;&#38598;&#25104;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Universal Online Learning with Gradual Variations: A Multi-layer Online Ensemble Approach. (arXiv:2307.08360v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08360
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20004;&#20010;&#19981;&#21516;&#32423;&#21035;&#33258;&#36866;&#24212;&#24615;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#26041;&#27861;&#65292;&#23545;&#19981;&#21516;&#31867;&#22411;&#30340;&#25439;&#22833;&#20989;&#25968;&#20855;&#26377;&#22810;&#31181;&#36951;&#25022;&#30028;&#65292;&#24182;&#22312;&#20998;&#26512;&#20013;&#30452;&#25509;&#24212;&#29992;&#20110;&#23567;&#25439;&#22833;&#30028;&#12290;&#21516;&#26102;&#65292;&#23427;&#19982;&#23545;&#25239;&#24615;/&#38543;&#26426;&#20984;&#20248;&#21270;&#21644;&#21338;&#24328;&#35770;&#26377;&#30528;&#28145;&#21051;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20004;&#20010;&#19981;&#21516;&#32423;&#21035;&#33258;&#36866;&#24212;&#24615;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#26041;&#27861;&#12290;&#22312;&#26356;&#39640;&#32423;&#21035;&#19978;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23545;&#25439;&#22833;&#20989;&#25968;&#30340;&#20855;&#20307;&#31867;&#22411;&#21644;&#26354;&#29575;&#19981;&#30693;&#24773;&#65292;&#32780;&#22312;&#26356;&#20302;&#32423;&#21035;&#19978;&#65292;&#23427;&#21487;&#20197;&#21033;&#29992;&#29615;&#22659;&#30340;&#33391;&#22909;&#24615;&#36136;&#24182;&#33719;&#24471;&#38382;&#39064;&#30456;&#20851;&#20445;&#35777;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#23545;&#20110;&#24378;&#20984;&#12289;&#25351;&#25968;&#20985;&#21644;&#20984;&#25439;&#22833;&#20989;&#25968;&#65292;&#25105;&#20204;&#20998;&#21035;&#33719;&#24471;&#20102;$O(\ln V_T)$&#12289;$O(d \ln V_T)$&#21644;$\hat{O}(\sqrt{V_T})$&#30340;&#36951;&#25022;&#30028;&#65292;&#20854;&#20013;$d$&#26159;&#32500;&#24230;&#65292;$V_T$&#34920;&#31034;&#38382;&#39064;&#30456;&#20851;&#30340;&#26799;&#24230;&#21464;&#21270;&#65292;$\hat{O}(\cdot)$&#34920;&#31034;&#22312;$V_T$&#19978;&#30465;&#30053;&#23545;&#25968;&#22240;&#23376;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20855;&#26377;&#24191;&#27867;&#30340;&#24433;&#21709;&#21644;&#24212;&#29992;&#12290;&#23427;&#19981;&#20165;&#20445;&#35777;&#20102;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#65292;&#36824;&#30452;&#25509;&#23548;&#20986;&#20102;&#20998;&#26512;&#20013;&#30340;&#23567;&#25439;&#22833;&#30028;&#12290;&#27492;&#22806;&#65292;&#23427;&#19982;&#23545;&#25239;&#24615;/&#38543;&#26426;&#20984;&#20248;&#21270;&#21644;&#21338;&#24328;&#35770;&#26377;&#30528;&#28145;&#21051;&#30340;&#32852;&#31995;&#65292;&#36827;&#19968;&#27493;&#39564;&#35777;&#20102;&#20854;&#23454;&#38469;&#28508;&#21147;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;...
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose an online convex optimization method with two different levels of adaptivity. On a higher level, our method is agnostic to the specific type and curvature of the loss functions, while at a lower level, it can exploit the niceness of the environments and attain problem-dependent guarantees. To be specific, we obtain $\mathcal{O}(\ln V_T)$, $\mathcal{O}(d \ln V_T)$ and $\hat{\mathcal{O}}(\sqrt{V_T})$ regret bounds for strongly convex, exp-concave and convex loss functions, respectively, where $d$ is the dimension, $V_T$ denotes problem-dependent gradient variations and $\hat{\mathcal{O}}(\cdot)$-notation omits logarithmic factors on $V_T$. Our result finds broad implications and applications. It not only safeguards the worst-case guarantees, but also implies the small-loss bounds in analysis directly. Besides, it draws deep connections with adversarial/stochastic convex optimization and game theory, further validating its practical potential. Our method is based
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#33258;&#36866;&#24212;&#30340;&#36125;&#21494;&#26031;&#28388;&#27874;&#33539;&#24335;&#26469;&#35299;&#20915;&#29616;&#26377;&#27010;&#29575;ODE&#27714;&#35299;&#22120;&#26080;&#27861;&#35299;&#20915;&#30340;&#28145;&#23618;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#38382;&#39064;&#65292;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#27604;&#29616;&#26377;&#27010;&#29575;ODE&#27714;&#35299;&#22120;&#26356;&#31934;&#30830;&#12290;</title><link>http://arxiv.org/abs/2306.05566</link><description>&lt;p&gt;
&#25968;&#25454;&#33258;&#36866;&#24212;&#27010;&#29575;&#20284;&#28982;&#36924;&#36817;&#24120;&#24494;&#20998;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
Data-Adaptive Probabilistic Likelihood Approximation for Ordinary Differential Equations. (arXiv:2306.05566v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05566
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#33258;&#36866;&#24212;&#30340;&#36125;&#21494;&#26031;&#28388;&#27874;&#33539;&#24335;&#26469;&#35299;&#20915;&#29616;&#26377;&#27010;&#29575;ODE&#27714;&#35299;&#22120;&#26080;&#27861;&#35299;&#20915;&#30340;&#28145;&#23618;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#38382;&#39064;&#65292;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#27604;&#29616;&#26377;&#27010;&#29575;ODE&#27714;&#35299;&#22120;&#26356;&#31934;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODEs&#65289;&#30340;&#21442;&#25968;&#25512;&#26029;&#22312;&#35768;&#22810;&#31185;&#23398;&#24212;&#29992;&#20013;&#20855;&#26377;&#22522;&#26412;&#37325;&#35201;&#24615;&#12290;&#34429;&#28982;ODE&#35299;&#36890;&#24120;&#30001;&#30830;&#23450;&#24615;&#31639;&#27861;&#36817;&#20284;&#65292;&#20294;&#26377;&#20851;&#27010;&#29575;&#27714;&#35299;&#22120;&#30340;&#26032;&#30740;&#31350;&#34920;&#26126;&#65292;&#23427;&#20204;&#36890;&#36807;&#26356;&#22909;&#22320;&#32771;&#34385;&#25968;&#23383;&#35823;&#24046;&#20135;&#29983;&#26356;&#21487;&#38752;&#30340;&#21442;&#25968;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;ODE&#31995;&#32479;&#23545;&#20854;&#21442;&#25968;&#20540;&#38750;&#24120;&#25935;&#24863;&#12290;&#36825;&#22312;&#20284;&#28982;&#20989;&#25968;&#20013;&#20135;&#29983;&#20102;&#28145;&#23618;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#8212;&#8212;&#29616;&#26377;&#30340;&#27010;&#29575;&#27714;&#35299;&#22120;&#23578;&#26410;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#29992;&#20110;&#27010;&#29575;ODE&#35299;&#30340;&#36125;&#21494;&#26031;&#28388;&#27874;&#33539;&#24335;&#65292;&#36890;&#36807;&#25968;&#25454;&#33258;&#36866;&#24212;&#22320;&#23398;&#20064;&#22024;&#26434;&#30340;ODE&#35266;&#23519;&#32467;&#26524;&#65292;&#21487;&#20197;&#26174;&#30528;&#38477;&#20302;&#21442;&#25968;&#30340;&#25935;&#24863;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36866;&#29992;&#20110;&#20855;&#26377;&#37096;&#20998;&#26410;&#35266;&#27979;&#20998;&#37327;&#21644;&#20219;&#24847;&#38750;&#39640;&#26031;&#22122;&#22768;&#30340;ODEs&#12290;&#20960;&#20010;&#20363;&#23376;&#34920;&#26126;&#65292;&#23427;&#27604;&#29616;&#26377;&#30340;&#27010;&#29575;ODE&#27714;&#35299;&#22120;&#26356;&#31934;&#30830;&#65292;&#29978;&#33267;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#27604;&#31934;&#30830;ODE&#20284;&#28982;&#20989;&#25968;&#26356;&#31934;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;
Parameter inference for ordinary differential equations (ODEs) is of fundamental importance in many scientific applications. While ODE solutions are typically approximated by deterministic algorithms, new research on probabilistic solvers indicates that they produce more reliable parameter estimates by better accounting for numerical errors. However, many ODE systems are highly sensitive to their parameter values. This produces deep local minima in the likelihood function -- a problem which existing probabilistic solvers have yet to resolve. Here, we show that a Bayesian filtering paradigm for probabilistic ODE solution can dramatically reduce sensitivity to parameters by learning from the noisy ODE observations in a data-adaptive manner. Our method is applicable to ODEs with partially unobserved components and with arbitrary non-Gaussian noise. Several examples demonstrate that it is more accurate than existing probabilistic ODE solvers, and even in some cases than the exact ODE likel
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32463;&#20856;&#39564;&#35777;&#37327;&#23376;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#20197;&#20415;&#32463;&#20856;&#23458;&#25143;&#22996;&#25176;&#23398;&#20064;&#32473;&#19981;&#21487;&#20449;&#30340;&#37327;&#23376;&#26381;&#21153;&#22120;&#65292;&#24182;&#25104;&#21151;&#35299;&#20915;&#20102;&#23545;&#20183;&#23398;&#20064;&#22855;&#20598;&#24615;&#21644;&#20613;&#37324;&#21494;&#31232;&#30095;&#20989;&#25968;&#19981;&#21487;&#20449;&#37327;&#23376;&#35777;&#26126;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.04843</link><description>&lt;p&gt;
&#37327;&#23376;&#23398;&#20064;&#30340;&#32463;&#20856;&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;
Classical Verification of Quantum Learning. (arXiv:2306.04843v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04843
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32463;&#20856;&#39564;&#35777;&#37327;&#23376;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#20197;&#20415;&#32463;&#20856;&#23458;&#25143;&#22996;&#25176;&#23398;&#20064;&#32473;&#19981;&#21487;&#20449;&#30340;&#37327;&#23376;&#26381;&#21153;&#22120;&#65292;&#24182;&#25104;&#21151;&#35299;&#20915;&#20102;&#23545;&#20183;&#23398;&#20064;&#22855;&#20598;&#24615;&#21644;&#20613;&#37324;&#21494;&#31232;&#30095;&#20989;&#25968;&#19981;&#21487;&#20449;&#37327;&#23376;&#35777;&#26126;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#25968;&#25454;&#35775;&#38382;&#21644;&#37327;&#23376;&#22788;&#29702;&#21487;&#20197;&#20351;&#26576;&#20123;&#32463;&#20856;&#38590;&#20197;&#22788;&#29702;&#30340;&#23398;&#20064;&#20219;&#21153;&#21464;&#24471;&#21487;&#34892;&#12290;&#28982;&#32780;&#65292;&#37327;&#23376;&#33021;&#21147;&#22312;&#19981;&#20037;&#30340;&#23558;&#26469;&#21482;&#33021;&#25552;&#20379;&#32473;&#23569;&#25968;&#20154;&#20351;&#29992;&#12290;&#22240;&#27492;&#65292;&#38656;&#35201;&#21487;&#38752;&#30340;&#26041;&#26696;&#65292;&#20801;&#35768;&#32463;&#20856;&#23458;&#25143;&#22996;&#25176;&#23398;&#20064;&#32473;&#19981;&#21487;&#20449;&#30340;&#37327;&#23376;&#26381;&#21153;&#22120;&#65292;&#20197;&#20419;&#36827;&#24191;&#27867;&#33719;&#24471;&#37327;&#23376;&#23398;&#20064;&#30340;&#20248;&#21183;&#12290;&#26412;&#25991;&#22522;&#20110;&#26368;&#36817;&#24341;&#20837;&#30340;&#21476;&#20856;&#26426;&#22120;&#23398;&#20064;&#20132;&#20114;&#35777;&#26126;&#31995;&#32479;&#26694;&#26550;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#32463;&#20856;&#39564;&#35777;&#37327;&#23376;&#23398;&#20064;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20123;&#32463;&#20856;&#23398;&#20064;&#32773;&#26080;&#27861;&#33258;&#34892;&#39640;&#25928;&#27714;&#35299;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#20294;&#24403;&#19982;&#19981;&#21487;&#20449;&#30340;&#37327;&#23376;&#35777;&#26126;&#32773;&#20132;&#20114;&#26102;&#65292;&#20182;&#20204;&#21487;&#20197;&#39640;&#25928;&#19988;&#21487;&#38752;&#22320;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20851;&#20110;&#20855;&#26377;&#22343;&#21248;&#36755;&#20837;&#36793;&#32536;&#23494;&#24230;&#30340;&#23545;&#20183;&#23398;&#20064;&#22855;&#20598;&#24615;&#21644;&#20613;&#37324;&#21494;&#31232;&#30095;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#37327;&#23376;&#25968;&#25454;&#35775;&#38382;&#27169;&#22411;&#65292;&#31216;&#20026;&#8220;&#21472;&#21152;&#28151;&#21512;&#37327;&#23376;&#26679;&#20363;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantum data access and quantum processing can make certain classically intractable learning tasks feasible. However, quantum capabilities will only be available to a select few in the near future. Thus, reliable schemes that allow classical clients to delegate learning to untrusted quantum servers are required to facilitate widespread access to quantum learning advantages. Building on a recently introduced framework of interactive proof systems for classical machine learning, we develop a framework for classical verification of quantum learning. We exhibit learning problems that a classical learner cannot efficiently solve on their own, but that they can efficiently and reliably solve when interacting with an untrusted quantum prover. Concretely, we consider the problems of agnostic learning parities and Fourier-sparse functions with respect to distributions with uniform input marginal. We propose a new quantum data access model that we call "mixture-of-superpositions" quantum example
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20351;&#29992;&#38543;&#26426;&#36873;&#25321;&#32431;&#37327;&#20998;&#35299;&#31639;&#27861;&#30340;&#26680;&#27714;&#31215;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#36798;&#21040;&#21487;&#27604;&#30340;&#27714;&#31215;&#35823;&#24046;&#36798;&#21040;&#29575;&#30340;&#21516;&#26102;&#26174;&#33879;&#38477;&#20302;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#21487;&#20197;&#24212;&#29992;&#20110;&#20219;&#24847;&#26680;&#30340;&#22797;&#26434;&#20960;&#20309;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2306.03955</link><description>&lt;p&gt;
&#38543;&#26426;&#36873;&#25321;&#32431;&#37327;&#20998;&#35299;&#30340;&#26680;&#27714;&#31215;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Kernel Quadrature with Randomly Pivoted Cholesky. (arXiv:2306.03955v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03955
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20351;&#29992;&#38543;&#26426;&#36873;&#25321;&#32431;&#37327;&#20998;&#35299;&#31639;&#27861;&#30340;&#26680;&#27714;&#31215;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#36798;&#21040;&#21487;&#27604;&#30340;&#27714;&#31215;&#35823;&#24046;&#36798;&#21040;&#29575;&#30340;&#21516;&#26102;&#26174;&#33879;&#38477;&#20302;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#21487;&#20197;&#24212;&#29992;&#20110;&#20219;&#24847;&#26680;&#30340;&#22797;&#26434;&#20960;&#20309;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#38543;&#26426;&#36873;&#25321;&#32431;&#37327;&#20998;&#35299;&#30340;&#37319;&#26679;&#31639;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37325;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20989;&#25968;&#27714;&#31215;&#35268;&#21017;&#12290;&#25152;&#24471;&#30340;&#35745;&#31639;&#36807;&#31243;&#19982;&#26082;&#26377;&#30340;&#26680;&#27714;&#31215;&#26041;&#27861;&#30456;&#27604;&#65292;&#22312;&#31934;&#24230;&#21644;&#27714;&#35299;&#22797;&#26434;&#24230;&#26041;&#38754;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#29702;&#35770;&#21644;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#38543;&#26426;&#36873;&#25321;&#32431;&#37327;&#20998;&#35299;&#30340;&#26041;&#27861;&#24555;&#36895;&#19988;&#20855;&#26377;&#21487;&#27604;&#30340;&#27714;&#31215;&#35823;&#24046;&#36798;&#21040;&#29575;&#65292;&#19982;&#22522;&#20110;&#36830;&#32493;&#20307;&#31215;&#37319;&#26679;&#12289;&#31232;&#30095;&#21270;&#21644;&#37325;&#32452;&#30340;&#26356;&#20026;&#26114;&#36149;&#30340;&#27714;&#31215;&#26041;&#26696;&#30456;&#21305;&#37197;&#12290;&#38543;&#26426;&#36873;&#25321;&#32431;&#37327;&#20998;&#35299;&#26131;&#20110;&#36866;&#24212;&#20219;&#24847;&#26680;&#30340;&#22797;&#26434;&#20960;&#20309;&#32467;&#26500;&#65292;&#20026;&#26680;&#27714;&#31215;&#24320;&#36767;&#20102;&#26032;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents new quadrature rules for functions in a reproducing kernel Hilbert space using nodes drawn by a sampling algorithm known as randomly pivoted Cholesky. The resulting computational procedure compares favorably to previous kernel quadrature methods, which either achieve low accuracy or require solving a computationally challenging sampling problem. Theoretical and numerical results show that randomly pivoted Cholesky is fast and achieves comparable quadrature error rates to more computationally expensive quadrature schemes based on continuous volume sampling, thinning, and recombination. Randomly pivoted Cholesky is easily adapted to complicated geometries with arbitrary kernels, unlocking new potential for kernel quadrature.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20026;&#25439;&#22833;&#26368;&#23567;&#21270;&#20998;&#31867;&#26641;&#30340;&#35299;&#20915;&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#22522;&#20110;&#36923;&#36753;&#26031;&#33922;&#22238;&#24402;&#30340;&#35299;&#20915;&#26041;&#24335;&#20855;&#26377;&#20855;&#26377;&#35299;&#37322;&#24615;&#29305;&#24449;&#21644;&#31454;&#20105;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2306.00857</link><description>&lt;p&gt;
&#25439;&#22833;&#26368;&#23567;&#21270;&#20998;&#31867;&#26641;&#65306;&#19968;&#20010;&#36890;&#29992;&#30340;&#26694;&#26550;&#21644;&#36923;&#36753;&#26031;&#33922;&#22238;&#24402;&#24773;&#20917;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Loss-Optimal Classification Trees: A Generalized Framework and the Logistic Case. (arXiv:2306.00857v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00857
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20026;&#25439;&#22833;&#26368;&#23567;&#21270;&#20998;&#31867;&#26641;&#30340;&#35299;&#20915;&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#22522;&#20110;&#36923;&#36753;&#26031;&#33922;&#22238;&#24402;&#30340;&#35299;&#20915;&#26041;&#24335;&#20855;&#26377;&#20855;&#26377;&#35299;&#37322;&#24615;&#29305;&#24449;&#21644;&#31454;&#20105;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#31867;&#26641;&#26159;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#24120;&#35265;&#30340;&#27169;&#22411;&#20043;&#19968;&#65292;&#23613;&#31649;&#36825;&#26679;&#30340;&#27169;&#22411;&#36890;&#24120;&#37319;&#29992;&#36138;&#23146;&#31574;&#30053;&#26500;&#24314;&#65292;&#20294;&#26159;&#36817;&#24180;&#26469;&#65292;&#30001;&#20110;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#65288;MIP&#65289;&#27714;&#35299;&#22120;&#30340;&#26174;&#33879;&#36827;&#23637;&#65292;&#24050;&#32463;&#24320;&#21457;&#20102;&#20960;&#31181;&#31934;&#30830;&#30340;&#23398;&#20064;&#38382;&#39064;&#30340;&#34920;&#36848;&#12290;&#26412;&#25991;&#35748;&#20026;&#20854;&#20013;&#19968;&#20123;&#26368;&#30456;&#20851;&#30340;&#35757;&#32451;&#27169;&#22411;&#21487;&#20197;&#23553;&#35013;&#22312;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#20869;&#65292;&#20854;&#23454;&#20363;&#30001;&#25439;&#22833;&#20989;&#25968;&#21644;&#27491;&#21017;&#21270;&#22120;&#30340;&#35268;&#23450;&#22609;&#36896;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#36825;&#20010;&#26694;&#26550;&#30340;&#26032;&#39062;&#23454;&#29616;&#65306;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#32771;&#34385;&#36923;&#36753;&#25439;&#22833;&#65292;&#23427;&#22312;MIP&#35774;&#32622;&#20013;&#36890;&#36807;&#32447;&#24615;&#20998;&#27573;&#36924;&#36817;&#22788;&#29702;&#65292;&#24182;&#19982;$\ell_1$-&#35268;&#21017;&#21270;&#39033;&#30456;&#32467;&#21512;&#12290;&#26368;&#32456;&#30340;&#26368;&#20248;&#36923;&#36753;&#26641;&#27169;&#22411;&#22312;&#25968;&#20540;&#19978;&#34987;&#35777;&#26126;&#33021;&#22815;&#35825;&#23548;&#20855;&#26377;&#22686;&#24378;&#21487;&#35299;&#37322;&#24615;&#29305;&#24449;&#21644;&#31454;&#20105;&#24615;&#27867;&#21270;&#33021;&#21147;&#30340;&#26641;&#65292;&#19982;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;MIP&#30340;&#26041;&#27861;&#30456;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Classification Tree (CT) is one of the most common models in interpretable machine learning. Although such models are usually built with greedy strategies, in recent years, thanks to remarkable advances in Mixer-Integer Programming (MIP) solvers, several exact formulations of the learning problem have been developed. In this paper, we argue that some of the most relevant ones among these training models can be encapsulated within a general framework, whose instances are shaped by the specification of loss functions and regularizers. Next, we introduce a novel realization of this framework: specifically, we consider the logistic loss, handled in the MIP setting by a linear piece-wise approximation, and couple it with $\ell_1$-regularization terms. The resulting Optimal Logistic Tree model numerically proves to be able to induce trees with enhanced interpretability features and competitive generalization capabilities, compared to the state-of-the-art MIP-based approaches.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#38454; Langevin &#21160;&#21147;&#23398;&#30340;&#31639;&#27861;&#65292;&#21487;&#26356;&#39640;&#25928;&#22320;&#37319;&#26679;&#26410;&#30693;&#21464;&#37327;&#21518;&#39564;&#20998;&#24067;&#65292;&#21516;&#26102;&#21152;&#20837;&#28140;&#28779;&#36807;&#31243;&#65292;&#33021;&#24212;&#29992;&#20110;&#31163;&#25955;&#26410;&#30693;&#21464;&#37327;&#24773;&#20917;&#65292;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#22312;&#22810;&#20010;&#20219;&#21153;&#20013;&#30456;&#23545;&#31454;&#20105;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.05014</link><description>&lt;p&gt;
&#20351;&#29992;&#39640;&#38454;&#28140;&#28779;&#38543;&#26426;&#28418;&#31227;&#35299;&#20915;&#32447;&#24615;&#21453;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Solving Linear Inverse Problems using Higher-Order Annealed Langevin Diffusion. (arXiv:2305.05014v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05014
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#38454; Langevin &#21160;&#21147;&#23398;&#30340;&#31639;&#27861;&#65292;&#21487;&#26356;&#39640;&#25928;&#22320;&#37319;&#26679;&#26410;&#30693;&#21464;&#37327;&#21518;&#39564;&#20998;&#24067;&#65292;&#21516;&#26102;&#21152;&#20837;&#28140;&#28779;&#36807;&#31243;&#65292;&#33021;&#24212;&#29992;&#20110;&#31163;&#25955;&#26410;&#30693;&#21464;&#37327;&#24773;&#20917;&#65292;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#22312;&#22810;&#20010;&#20219;&#21153;&#20013;&#30456;&#23545;&#31454;&#20105;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#38454; Langevin &#28418;&#31227;&#30340;&#32447;&#24615;&#21453;&#38382;&#39064;&#35299;&#20915;&#26041;&#26696;&#12290;&#26356;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#39044;&#22788;&#29702;&#30340;&#20108;&#38454;&#21644;&#19977;&#38454; Langevin &#21160;&#21147;&#23398;&#65292;&#36825;&#20123;&#21160;&#21147;&#23398;&#26126;&#26174;&#22320;&#20174;&#25105;&#20204;&#24863;&#20852;&#36259;&#30340;&#26410;&#30693;&#21464;&#37327;&#30340;&#21518;&#39564;&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#21516;&#26102;&#27604;&#20854;&#19968;&#38454;&#23545;&#24212;&#29289;&#21644;&#20004;&#31181;&#21160;&#21147;&#23398;&#30340;&#38750;&#39044;&#22788;&#29702;&#29256;&#26412;&#26356;&#20855;&#35745;&#31639;&#25928;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20004;&#31181;&#39044;&#22788;&#29702;&#21160;&#21147;&#23398;&#26159;&#33391;&#23450;&#20041;&#30340;&#65292;&#24182;&#19988;&#20855;&#26377;&#19982;&#38750;&#39044;&#22788;&#29702;&#24773;&#20917;&#30456;&#21516;&#30340;&#21807;&#19968;&#19981;&#21464;&#20998;&#24067;&#12290;&#25105;&#20204;&#36824;&#21152;&#20837;&#20102;&#19968;&#20010;&#28140;&#28779;&#36807;&#31243;&#65292;&#36825;&#20855;&#26377;&#21452;&#37325;&#20248;&#28857;&#65292;&#19968;&#26041;&#38754;&#36827;&#19968;&#27493;&#21152;&#36895;&#20102;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#21478;&#19968;&#26041;&#38754;&#65292;&#20801;&#35768;&#25105;&#20204;&#36866;&#24212;&#26410;&#30693;&#21464;&#37327;&#20026;&#31163;&#25955;&#30340;&#24773;&#20917;&#12290;&#22312;&#20004;&#20010;&#19981;&#21516;&#30340;&#20219;&#21153;&#65288;MIMO &#31526;&#21495;&#26816;&#27979;&#21644;&#36890;&#36947;&#20272;&#35745;&#65289;&#30340;&#25968;&#20540;&#23454;&#39564;&#20013;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#36890;&#29992;&#24615;&#65292;&#24182;&#35828;&#26126;&#20102;&#30456;&#23545;&#20110;&#31454;&#20105;&#26041;&#27861;&#65288;&#21253;&#25324;&#22522;&#20110;&#23398;&#20064;&#30340;&#26041;&#27861;&#65289;&#25152;&#23454;&#29616;&#30340;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a solution for linear inverse problems based on higher-order Langevin diffusion. More precisely, we propose pre-conditioned second-order and third-order Langevin dynamics that provably sample from the posterior distribution of our unknown variables of interest while being computationally more efficient than their first-order counterpart and the non-conditioned versions of both dynamics. Moreover, we prove that both pre-conditioned dynamics are well-defined and have the same unique invariant distributions as the non-conditioned cases. We also incorporate an annealing procedure that has the double benefit of further accelerating the convergence of the algorithm and allowing us to accommodate the case where the unknown variables are discrete. Numerical experiments in two different tasks (MIMO symbol detection and channel estimation) showcase the generality of our method and illustrate the high performance achieved relative to competing approaches (including learning-based ones)
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#40654;&#26364;&#23376;&#31354;&#38388;&#19979;&#38477;&#31639;&#27861;&#30340;&#23545;&#31216;&#27491;&#23450;&#27969;&#24418;&#19978;&#30340;&#20989;&#25968;&#26368;&#23567;&#21270;&#26041;&#27861;&#65292;&#20854;&#20855;&#26377;&#20302;&#22797;&#26434;&#24230;&#21644;&#36991;&#20813;&#26114;&#36149;&#30697;&#38453;&#25805;&#20316;&#21644;&#35745;&#31639;&#40654;&#26364;&#26799;&#24230;&#30340;&#20248;&#28857;&#12290;</title><link>http://arxiv.org/abs/2305.02041</link><description>&lt;p&gt;
&#23545;&#31216;&#27491;&#23450;&#27969;&#24418;&#19978;&#20302;&#22797;&#26434;&#24230;&#30340;&#23376;&#31354;&#38388;&#19979;&#38477;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Low-complexity subspace-descent over symmetric positive definite manifold. (arXiv:2305.02041v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02041
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#40654;&#26364;&#23376;&#31354;&#38388;&#19979;&#38477;&#31639;&#27861;&#30340;&#23545;&#31216;&#27491;&#23450;&#27969;&#24418;&#19978;&#30340;&#20989;&#25968;&#26368;&#23567;&#21270;&#26041;&#27861;&#65292;&#20854;&#20855;&#26377;&#20302;&#22797;&#26434;&#24230;&#21644;&#36991;&#20813;&#26114;&#36149;&#30697;&#38453;&#25805;&#20316;&#21644;&#35745;&#31639;&#40654;&#26364;&#26799;&#24230;&#30340;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20302;&#22797;&#26434;&#24230;&#30340;&#40654;&#26364;&#23376;&#31354;&#38388;&#19979;&#38477;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#23545;&#31216;&#27491;&#23450;&#65288;SPD&#65289;&#27969;&#24418;&#19978;&#23545;&#20989;&#25968;&#36827;&#34892;&#26368;&#23567;&#21270;&#12290;&#19982;&#29616;&#26377;&#30340;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#21464;&#20307;&#19981;&#21516;&#30340;&#26159;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21033;&#29992; carefully chosen &#30340;&#23376;&#31354;&#38388;&#65292;&#20351;&#24471;&#26356;&#26032;&#21487;&#20197;&#20889;&#25104;&#36845;&#20195;&#30340; Cholesky &#22240;&#23376;&#21644;&#19968;&#20010;&#31232;&#30095;&#30697;&#38453;&#30340;&#20056;&#31215;&#24418;&#24335;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#26356;&#26032;&#36991;&#20813;&#20102;&#26114;&#36149;&#30340;&#30697;&#38453;&#25805;&#20316;&#65292;&#22914;&#30697;&#38453;&#25351;&#25968;&#21644;&#23494;&#38598;&#30697;&#38453;&#20056;&#27861;&#65292;&#36825;&#20123;&#25805;&#20316;&#36890;&#24120;&#22312;&#20960;&#20046;&#25152;&#26377;&#20854;&#20182; Riemannian &#20248;&#21270;&#31639;&#27861;&#20013;&#37117;&#26159;&#24517;&#38656;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work puts forth low-complexity Riemannian subspace descent algorithms for the minimization of functions over the symmetric positive definite (SPD) manifold. Different from the existing Riemannian gradient descent variants, the proposed approach utilizes carefully chosen subspaces that allow the update to be written as a product of the Cholesky factor of the iterate and a sparse matrix. The resulting updates avoid the costly matrix operations like matrix exponentiation and dense matrix multiplication, which are generally required in almost all other Riemannian optimization algorithms on SPD manifold. We further identify a broad class of functions, arising in diverse applications, such as kernel matrix learning, covariance estimation of Gaussian distributions, maximum likelihood parameter estimation of elliptically contoured distributions, and parameter estimation in Gaussian mixture model problems, over which the Riemannian gradients can be calculated efficiently. The proposed uni-
&lt;/p&gt;</description></item><item><title>LAVA&#26159;&#19968;&#20010;&#23398;&#20064;&#31639;&#27861;&#26080;&#20851;&#30340;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#26041;&#27861;&#65292;&#23427;&#32467;&#21512;&#20102;&#23398;&#20064;&#31639;&#27861;&#30340;&#32479;&#35745;&#29305;&#24615;&#21644;&#35757;&#32451;&#25968;&#25454;&#30340;&#23646;&#24615;&#65292;&#36890;&#36807;&#36845;&#20195;&#20272;&#35745;&#25968;&#25454;&#20540;&#26469;&#23454;&#29616;&#12290;LAVA&#27604;&#29616;&#26377;&#26041;&#27861;&#35745;&#31639;&#36895;&#24230;&#26356;&#24555;&#65292;&#31934;&#24230;&#26356;&#39640;&#65292;&#24182;&#19988;&#21487;&#20197;&#20026;&#19981;&#21516;&#30340;&#24212;&#29992;&#25552;&#20379;&#26377;&#24847;&#20041;&#30340;&#25968;&#25454;&#25490;&#21517;&#12290;</title><link>http://arxiv.org/abs/2305.00054</link><description>&lt;p&gt;
LAVA: &#26080;&#38656;&#39044;&#23450;&#23398;&#20064;&#31639;&#27861;&#30340;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
LAVA: Data Valuation without Pre-Specified Learning Algorithms. (arXiv:2305.00054v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00054
&lt;/p&gt;
&lt;p&gt;
LAVA&#26159;&#19968;&#20010;&#23398;&#20064;&#31639;&#27861;&#26080;&#20851;&#30340;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#26041;&#27861;&#65292;&#23427;&#32467;&#21512;&#20102;&#23398;&#20064;&#31639;&#27861;&#30340;&#32479;&#35745;&#29305;&#24615;&#21644;&#35757;&#32451;&#25968;&#25454;&#30340;&#23646;&#24615;&#65292;&#36890;&#36807;&#36845;&#20195;&#20272;&#35745;&#25968;&#25454;&#20540;&#26469;&#23454;&#29616;&#12290;LAVA&#27604;&#29616;&#26377;&#26041;&#27861;&#35745;&#31639;&#36895;&#24230;&#26356;&#24555;&#65292;&#31934;&#24230;&#26356;&#39640;&#65292;&#24182;&#19988;&#21487;&#20197;&#20026;&#19981;&#21516;&#30340;&#24212;&#29992;&#25552;&#20379;&#26377;&#24847;&#20041;&#30340;&#25968;&#25454;&#25490;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#38382;&#39064;&#26159;&#22914;&#20309;&#20844;&#24179;&#22320;&#20998;&#37197;&#23398;&#20064;&#31639;&#27861;&#30340;&#39564;&#35777;&#24615;&#33021;&#65292;&#33268;&#20351;&#35745;&#31639;&#24471;&#21040;&#30340;&#25968;&#25454;&#20215;&#20540;&#20381;&#36182;&#20110;&#24213;&#23618;&#23398;&#20064;&#31639;&#27861;&#30340;&#35768;&#22810;&#35774;&#35745;&#36873;&#25321;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;LAVA&#65292;&#35813;&#26694;&#26550;&#32467;&#21512;&#20102;&#23398;&#20064;&#31639;&#27861;&#30340;&#32479;&#35745;&#29305;&#24615;&#21644;&#35757;&#32451;&#25968;&#25454;&#30340;&#23646;&#24615;&#65292;&#36845;&#20195;&#20272;&#35745;&#25968;&#25454;&#20540;&#65292;&#20351;&#20854;&#26080;&#35270;&#19979;&#28216;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;LAVA&#27604;&#29616;&#26377;&#26041;&#27861;&#35745;&#31639;&#36895;&#24230;&#26356;&#24555;&#65292;&#31934;&#24230;&#26356;&#39640;&#65292;&#24182;&#19988;&#23427;&#21487;&#20197;&#20026;&#19981;&#21516;&#30340;&#24212;&#29992;&#25552;&#20379;&#26377;&#24847;&#20041;&#30340;&#25968;&#25454;&#25490;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;
Traditionally, data valuation is posed as a problem of equitably splitting the validation performance of a learning algorithm among the training data. As a result, the calculated data values depend on many design choices of the underlying learning algorithm. However, this dependence is undesirable for many use cases of data valuation, such as setting priorities over different data sources in a data acquisition process and informing pricing mechanisms in a data marketplace. In these scenarios, data needs to be valued before the actual analysis and the choice of the learning algorithm is still undetermined then. Another side-effect of the dependence is that to assess the value of individual points, one needs to re-run the learning algorithm with and without a point, which incurs a large computation burden.  This work leapfrogs over the current limits of data valuation methods by introducing a new framework that can value training data in a way that is oblivious to the downstream learning
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#25968;&#25454;&#27745;&#26579;&#30340;&#26102;&#24207;&#23041;&#32961;&#27169;&#22411;&#65292;&#36890;&#36807;&#21033;&#29992;&#25968;&#25454;&#30340;&#26102;&#38388;&#25139;&#65292;&#24341;&#20837;&#20102;&#25552;&#21069;&#26102;&#38388;&#21644;&#25345;&#32493;&#26102;&#38388;&#36825;&#20004;&#20010;&#25351;&#26631;&#65292;&#20174;&#32780;&#23450;&#20041;&#20102;&#25968;&#25454;&#27745;&#26579;&#30340;&#26102;&#24207;&#40065;&#26834;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#20445;&#25252;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2302.03684</link><description>&lt;p&gt;
&#25968;&#25454;&#27745;&#26579;&#20013;&#30340;&#26102;&#24207;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Temporal Robustness against Data Poisoning. (arXiv:2302.03684v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03684
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#25968;&#25454;&#27745;&#26579;&#30340;&#26102;&#24207;&#23041;&#32961;&#27169;&#22411;&#65292;&#36890;&#36807;&#21033;&#29992;&#25968;&#25454;&#30340;&#26102;&#38388;&#25139;&#65292;&#24341;&#20837;&#20102;&#25552;&#21069;&#26102;&#38388;&#21644;&#25345;&#32493;&#26102;&#38388;&#36825;&#20004;&#20010;&#25351;&#26631;&#65292;&#20174;&#32780;&#23450;&#20041;&#20102;&#25968;&#25454;&#27745;&#26579;&#30340;&#26102;&#24207;&#40065;&#26834;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#20445;&#25252;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#27745;&#26579;&#32771;&#34385;&#20102;&#36890;&#36807;&#24694;&#24847;&#35757;&#32451;&#25968;&#25454;&#25805;&#32437;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#34892;&#20026;&#30340;&#24773;&#20917;&#12290;&#29616;&#26377;&#30340;&#25968;&#25454;&#27745;&#26579;&#23041;&#32961;&#27169;&#22411;&#37117;&#22260;&#32469;&#30528;&#19968;&#20010;&#21333;&#19968;&#25351;&#26631;&#65292;&#21363;&#34987;&#27745;&#26579;&#26679;&#26412;&#30340;&#25968;&#37327;&#12290;&#22240;&#27492;&#65292;&#22914;&#26524;&#25915;&#20987;&#32773;&#33021;&#22815;&#20197;&#21487;&#25215;&#21463;&#30340;&#20195;&#20215;&#27745;&#26579;&#27604;&#39044;&#26399;&#26356;&#22810;&#30340;&#26679;&#26412;&#65292;&#23601;&#20687;&#35768;&#22810;&#23454;&#38469;&#22330;&#26223;&#20013;&#19968;&#26679;&#65292;&#20182;&#20204;&#21487;&#33021;&#33021;&#22815;&#22312;&#24456;&#30701;&#30340;&#26102;&#38388;&#20869;&#20351;&#29616;&#26377;&#30340;&#38450;&#24481;&#25514;&#26045;&#22833;&#25928;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#21033;&#29992;&#25968;&#25454;&#30340;&#20986;&#29983;&#26085;&#26399;&#26102;&#38388;&#25139;&#65292;&#36825;&#20123;&#26102;&#38388;&#25139;&#36890;&#24120;&#26159;&#21487;&#29992;&#30340;&#20294;&#36807;&#21435;&#34987;&#24573;&#30053;&#12290;&#21033;&#29992;&#36825;&#20123;&#26102;&#38388;&#25139;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#24102;&#26377;&#20004;&#20010;&#26032;&#22411;&#25351;&#26631;&#65288;&#25552;&#21069;&#26102;&#38388;&#21644;&#25345;&#32493;&#26102;&#38388;&#65289;&#30340;&#25968;&#25454;&#27745;&#26579;&#30340;&#26102;&#24207;&#23041;&#32961;&#27169;&#22411;&#65292;&#20998;&#21035;&#34913;&#37327;&#25915;&#20987;&#25552;&#21069;&#24320;&#22987;&#30340;&#26102;&#38388;&#21644;&#25915;&#20987;&#25345;&#32493;&#30340;&#26102;&#38388;&#12290;&#21033;&#29992;&#36825;&#20123;&#25351;&#26631;&#65292;&#25105;&#20204;&#23450;&#20041;&#20102;&#25968;&#25454;&#27745;&#26579;&#30340;&#26102;&#24207;&#40065;&#26834;&#24615;&#30340;&#27010;&#24565;&#65292;&#21363;&#20351;&#26377;&#22823;&#37327;&#34987;&#27745;&#26579;&#30340;&#26679;&#26412;&#65292;&#20063;&#33021;&#25552;&#20379;&#26377;&#24847;&#20041;&#30340;&#20445;&#25252;&#12290;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Data poisoning considers cases when an adversary manipulates the behavior of machine learning algorithms through malicious training data. Existing threat models of data poisoning center around a single metric, the number of poisoned samples. In consequence, if attackers can poison more samples than expected with affordable overhead, as in many practical scenarios, they may be able to render existing defenses ineffective in a short time. To address this issue, we leverage timestamps denoting the birth dates of data, which are often available but neglected in the past. Benefiting from these timestamps, we propose a temporal threat model of data poisoning with two novel metrics, earliness and duration, which respectively measure how long an attack started in advance and how long an attack lasted. Using these metrics, we define the notions of temporal robustness against data poisoning, providing a meaningful sense of protection even with unbounded amounts of poisoned samples. We present a 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;NN-Turb&#30340;&#20840;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#38543;&#26426;&#27169;&#22411;&#65292;&#29992;&#20110;&#20197;&#28237;&#27969;&#36895;&#24230;&#32479;&#35745;&#29305;&#24615;&#29983;&#25104;1&#32500;&#22330;&#65292;&#32780;&#26080;&#38656;&#25509;&#35302;&#28237;&#27969;&#25968;&#25454;&#12290;&#29983;&#25104;&#30340;&#36807;&#31243;&#28385;&#36275;Kolmogorov 2/3&#32467;&#26500;&#20989;&#25968;&#23450;&#24459;&#65292;&#21516;&#26102;&#36824;&#34920;&#29616;&#20986;&#36127;&#20559;&#26012;&#24230;&#21644;&#38388;&#27463;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.11580</link><description>&lt;p&gt;
&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;1&#32500;&#38543;&#26426;&#22330;&#29983;&#25104;&#65292;&#20855;&#26377;&#28237;&#27969;&#36895;&#24230;&#32479;&#35745;&#29305;&#24615;
&lt;/p&gt;
&lt;p&gt;
Neural network based generation of 1-dimensional stochastic fields with turbulent velocity statistics. (arXiv:2211.11580v2 [eess.SP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.11580
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;NN-Turb&#30340;&#20840;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#38543;&#26426;&#27169;&#22411;&#65292;&#29992;&#20110;&#20197;&#28237;&#27969;&#36895;&#24230;&#32479;&#35745;&#29305;&#24615;&#29983;&#25104;1&#32500;&#22330;&#65292;&#32780;&#26080;&#38656;&#25509;&#35302;&#28237;&#27969;&#25968;&#25454;&#12290;&#29983;&#25104;&#30340;&#36807;&#31243;&#28385;&#36275;Kolmogorov 2/3&#32467;&#26500;&#20989;&#25968;&#23450;&#24459;&#65292;&#21516;&#26102;&#36824;&#34920;&#29616;&#20986;&#36127;&#20559;&#26012;&#24230;&#21644;&#38388;&#27463;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23450;&#20041;&#24182;&#30740;&#31350;&#20102;&#19968;&#20010;&#20840;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#38543;&#26426;&#27169;&#22411;&#65292;&#21517;&#20026;NN-Turb&#65292;&#29992;&#20110;&#29983;&#25104;&#20855;&#26377;&#28237;&#27969;&#36895;&#24230;&#32479;&#35745;&#29305;&#24615;&#30340;1&#32500;&#22330;&#12290;&#36825;&#26679;&#65292;&#29983;&#25104;&#30340;&#36807;&#31243;&#28385;&#36275;Kolmogorov 2/3&#32467;&#26500;&#20989;&#25968;&#23450;&#24459;&#12290;&#23427;&#36824;&#21576;&#29616;&#20986;&#21508;&#20010;&#23610;&#24230;&#19978;&#30340;&#36127;&#20559;&#26012;&#24230;&#65288;&#21363;Kolmogorov 4/5&#23450;&#24459;&#65289;&#21644;&#38388;&#27463;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#20174;&#19981;&#25509;&#35302;&#28237;&#27969;&#25968;&#25454;&#65292;&#21482;&#38656;&#35201;&#35757;&#32451;&#25152;&#38656;&#30340;&#32467;&#26500;&#20989;&#25968;&#22312;&#21508;&#20010;&#23610;&#24230;&#19978;&#30340;&#32479;&#35745;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
We define and study a fully-convolutional neural network stochastic model, NN-Turb, which generates 1-dimensional fields with turbulent velocity statistics. Thus, the generated process satisfies the Kolmogorov 2/3 law for second order structure function. It also presents negative skewness across scales (i.e. Kolmogorov 4/5 law) and exhibits intermittency. Furthermore, our model is never in contact with turbulent data and only needs the desired statistical behavior of the structure functions across scales for training.
&lt;/p&gt;</description></item></channel></rss>