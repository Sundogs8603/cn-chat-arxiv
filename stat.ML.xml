<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#19981;&#21516;&#30340;&#25955;&#24230;&#25490;&#24207;&#21487;&#20197;&#36890;&#36807;&#23427;&#20204;&#30340;&#21464;&#20998;&#36817;&#20284;&#35823;&#20272;&#19981;&#30830;&#23450;&#24615;&#30340;&#21508;&#31181;&#24230;&#37327;&#65292;&#24182;&#19988;&#22240;&#23376;&#21270;&#36817;&#20284;&#26080;&#27861;&#21516;&#26102;&#21305;&#37197;&#36825;&#20123;&#24230;&#37327;&#20013;&#30340;&#20219;&#24847;&#20004;&#20010;</title><link>https://arxiv.org/abs/2403.13748</link><description>&lt;p&gt;
&#21464;&#20998;&#25512;&#26029;&#20013;&#22240;&#23376;&#21270;&#39640;&#26031;&#36817;&#20284;&#30340;&#24046;&#24322;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
An Ordering of Divergences for Variational Inference with Factorized Gaussian Approximations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13748
&lt;/p&gt;
&lt;p&gt;
&#19981;&#21516;&#30340;&#25955;&#24230;&#25490;&#24207;&#21487;&#20197;&#36890;&#36807;&#23427;&#20204;&#30340;&#21464;&#20998;&#36817;&#20284;&#35823;&#20272;&#19981;&#30830;&#23450;&#24615;&#30340;&#21508;&#31181;&#24230;&#37327;&#65292;&#24182;&#19988;&#22240;&#23376;&#21270;&#36817;&#20284;&#26080;&#27861;&#21516;&#26102;&#21305;&#37197;&#36825;&#20123;&#24230;&#37327;&#20013;&#30340;&#20219;&#24847;&#20004;&#20010;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21464;&#20998;&#25512;&#26029;&#65288;VI&#65289;&#20013;&#65292;&#32473;&#23450;&#19968;&#20010;&#38590;&#20197;&#22788;&#29702;&#30340;&#20998;&#24067;$p$&#65292;&#38382;&#39064;&#26159;&#20174;&#19968;&#20123;&#26356;&#26131;&#22788;&#29702;&#30340;&#26063;$\mathcal{Q}$&#20013;&#35745;&#31639;&#26368;&#20339;&#36817;&#20284;$q$&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#36825;&#31181;&#36817;&#20284;&#26159;&#36890;&#36807;&#26368;&#23567;&#21270;Kullback-Leibler (KL)&#25955;&#24230;&#26469;&#25214;&#21040;&#30340;&#12290;&#28982;&#32780;&#65292;&#23384;&#22312;&#20854;&#20182;&#26377;&#25928;&#30340;&#25955;&#24230;&#36873;&#25321;&#65292;&#24403;$\mathcal{Q}$&#19981;&#21253;&#21547;$p$&#26102;&#65292;&#27599;&#20010;&#25955;&#24230;&#37117;&#25903;&#25345;&#19981;&#21516;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#22312;&#39640;&#26031;&#30340;&#23494;&#38598;&#21327;&#26041;&#24046;&#30697;&#38453;&#34987;&#23545;&#35282;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#39640;&#26031;&#36817;&#20284;&#25152;&#24433;&#21709;&#30340;VI&#32467;&#26524;&#20013;&#65292;&#25955;&#24230;&#36873;&#25321;&#22914;&#20309;&#24433;&#21709;VI&#32467;&#26524;&#12290;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19981;&#21516;&#30340;&#25955;&#24230;&#21487;&#20197;&#36890;&#36807;&#23427;&#20204;&#30340;&#21464;&#20998;&#36817;&#20284;&#35823;&#20272;&#19981;&#30830;&#23450;&#24615;&#30340;&#21508;&#31181;&#24230;&#37327;&#65292;&#22914;&#26041;&#24046;&#12289;&#31934;&#24230;&#21644;&#29109;&#65292;&#36827;&#34892;\textit{&#25490;&#24207;}&#12290;&#25105;&#20204;&#36824;&#24471;&#20986;&#19968;&#20010;&#19981;&#21487;&#33021;&#23450;&#29702;&#65292;&#34920;&#26126;&#26080;&#27861;&#36890;&#36807;&#22240;&#23376;&#21270;&#36817;&#20284;&#21516;&#26102;&#21305;&#37197;&#36825;&#20123;&#24230;&#37327;&#20013;&#30340;&#20219;&#24847;&#20004;&#20010;&#65307;&#22240;&#27492;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13748v1 Announce Type: cross  Abstract: Given an intractable distribution $p$, the problem of variational inference (VI) is to compute the best approximation $q$ from some more tractable family $\mathcal{Q}$. Most commonly the approximation is found by minimizing a Kullback-Leibler (KL) divergence. However, there exist other valid choices of divergences, and when $\mathcal{Q}$ does not contain~$p$, each divergence champions a different solution. We analyze how the choice of divergence affects the outcome of VI when a Gaussian with a dense covariance matrix is approximated by a Gaussian with a diagonal covariance matrix. In this setting we show that different divergences can be \textit{ordered} by the amount that their variational approximations misestimate various measures of uncertainty, such as the variance, precision, and entropy. We also derive an impossibility theorem showing that no two of these measures can be simultaneously matched by a factorized approximation; henc
&lt;/p&gt;</description></item><item><title>Transformer&#22312;&#36924;&#36817;&#36830;&#32493;&#20989;&#25968;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#65292;&#26159;&#21542;&#30495;&#27491;&#26159;&#36890;&#29992;&#20989;&#25968;&#36924;&#36817;&#22120;&#20173;&#26377;&#24453;&#32771;&#35777;</title><link>https://arxiv.org/abs/2402.15478</link><description>&lt;p&gt;
Transformer&#26159;&#34920;&#29616;&#21147;&#24378;&#22823;&#30340;&#65292;&#20294;&#26159;&#23545;&#20110;&#22238;&#24402;&#20219;&#21153;&#26469;&#35828;&#34920;&#29616;&#21147;&#36275;&#22815;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Transformers are Expressive, But Are They Expressive Enough for Regression?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15478
&lt;/p&gt;
&lt;p&gt;
Transformer&#22312;&#36924;&#36817;&#36830;&#32493;&#20989;&#25968;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#65292;&#26159;&#21542;&#30495;&#27491;&#26159;&#36890;&#29992;&#20989;&#25968;&#36924;&#36817;&#22120;&#20173;&#26377;&#24453;&#32771;&#35777;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#24050;&#25104;&#20026;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#33267;&#20851;&#37325;&#35201;&#30340;&#25216;&#26415;&#65292;&#22312;&#26426;&#22120;&#32763;&#35793;&#21644;&#25688;&#35201;&#31561;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;&#38543;&#30528;&#23427;&#20204;&#30340;&#24191;&#27867;&#24212;&#29992;&#65292;&#19968;&#20123;&#30740;&#31350;&#23581;&#35797;&#20998;&#26512;Transformer&#30340;&#34920;&#29616;&#21147;&#12290;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#29616;&#21147;&#25351;&#30340;&#26159;&#23427;&#33021;&#22815;&#36924;&#36817;&#30340;&#20989;&#25968;&#31867;&#12290;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#26159;&#23436;&#20840;&#34920;&#29616;&#21147;&#30340;&#65292;&#22914;&#26524;&#23427;&#21487;&#20197;&#20805;&#24403;&#36890;&#29992;&#20989;&#25968;&#36924;&#36817;&#22120;&#12290;&#25105;&#20204;&#23581;&#35797;&#20998;&#26512;Transformer&#30340;&#34920;&#29616;&#21147;&#12290;&#19982;&#29616;&#26377;&#35266;&#28857;&#30456;&#21453;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;Transformer&#22312;&#21487;&#38752;&#36924;&#36817;&#36830;&#32493;&#20989;&#25968;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#65292;&#20381;&#36182;&#20110;&#20855;&#26377;&#21487;&#35266;&#21306;&#38388;&#30340;&#20998;&#27573;&#24120;&#25968;&#36924;&#36817;&#12290;&#20851;&#38190;&#38382;&#39064;&#26159;&#65306;&#8220;Transformer&#26159;&#21542;&#30495;&#27491;&#26159;&#36890;&#29992;&#20989;&#25968;&#36924;&#36817;&#22120;&#65311;&#8221;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#24443;&#24213;&#30340;&#35843;&#26597;&#65292;&#36890;&#36807;&#23454;&#39564;&#25552;&#20379;&#29702;&#35770;&#35265;&#35299;&#21644;&#25903;&#25345;&#35777;&#25454;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#21253;&#25324;&#20102;&#19968;&#20010;&#29702;&#35770;&#20998;&#26512;&#8230;&#8230;&#65288;&#25688;&#35201;&#26410;&#23436;&#25972;&#65289;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15478v1 Announce Type: new  Abstract: Transformers have become pivotal in Natural Language Processing, demonstrating remarkable success in applications like Machine Translation and Summarization. Given their widespread adoption, several works have attempted to analyze the expressivity of Transformers. Expressivity of a neural network is the class of functions it can approximate. A neural network is fully expressive if it can act as a universal function approximator. We attempt to analyze the same for Transformers. Contrary to existing claims, our findings reveal that Transformers struggle to reliably approximate continuous functions, relying on piecewise constant approximations with sizable intervals. The central question emerges as: "\textit{Are Transformers truly Universal Function Approximators}?" To address this, we conduct a thorough investigation, providing theoretical insights and supporting evidence through experiments. Our contributions include a theoretical analysi
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#31283;&#23450;&#20102;&#38543;&#26426;&#38797;&#28857;&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#26799;&#24230;&#19981;&#26029;&#22686;&#38271;&#30340;&#38382;&#39064;&#65292;&#33021;&#22815;&#22312;&#26080;&#30028;&#26799;&#24230;&#21644;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#26377;&#24847;&#20041;&#30340;&#24615;&#33021;&#20445;&#35777;</title><link>https://arxiv.org/abs/2402.13903</link><description>&lt;p&gt;
&#22788;&#29702;&#38543;&#26426;&#38797;&#28857;&#20248;&#21270;&#20013;&#30340;&#26080;&#30028;&#26799;&#24230;
&lt;/p&gt;
&lt;p&gt;
Dealing with unbounded gradients in stochastic saddle-point optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13903
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#31283;&#23450;&#20102;&#38543;&#26426;&#38797;&#28857;&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#26799;&#24230;&#19981;&#26029;&#22686;&#38271;&#30340;&#38382;&#39064;&#65292;&#33021;&#22815;&#22312;&#26080;&#30028;&#26799;&#24230;&#21644;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#26377;&#24847;&#20041;&#30340;&#24615;&#33021;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#29992;&#20110;&#23547;&#25214;&#20984;&#20985;&#20989;&#25968;&#38797;&#28857;&#30340;&#38543;&#26426;&#19968;&#38454;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#36825;&#31867;&#26041;&#27861;&#38754;&#20020;&#30340;&#19968;&#20010;&#20030;&#19990;&#38395;&#21517;&#30340;&#25361;&#25112;&#26159;&#65292;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#26799;&#24230;&#21487;&#33021;&#20250;&#20219;&#24847;&#22686;&#38271;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#19981;&#31283;&#23450;&#24615;&#21644;&#21457;&#25955;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#31283;&#23450;&#20102;&#36845;&#20195;&#24182;&#20135;&#29983;&#20102;&#26377;&#24847;&#20041;&#30340;&#24615;&#33021;&#20445;&#35777;&#65292;&#21363;&#20351;&#23450;&#20041;&#22495;&#21644;&#26799;&#24230;&#22122;&#22768;&#38543;&#36845;&#20195;&#30340;&#35268;&#27169;&#32447;&#24615;&#21464;&#21270;&#65288;&#22240;&#27492;&#21487;&#33021;&#26159;&#26080;&#30028;&#30340;&#65289;&#12290;&#38500;&#20102;&#25552;&#20379;&#19968;&#31995;&#21015;&#19968;&#33324;&#24615;&#32467;&#26524;&#22806;&#65292;&#25105;&#20204;&#36824;&#23558;&#25105;&#20204;&#30340;&#31639;&#27861;&#24212;&#29992;&#21040;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20855;&#20307;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#23548;&#33268;&#22312;&#19981;&#38656;&#35201;&#26377;&#20851;&#20559;&#32622;&#36328;&#24230;&#20808;&#39564;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#65292;&#25214;&#21040;&#24179;&#22343;&#22870;&#21169;MDP&#20013;&#25509;&#36817;&#26368;&#20248;&#31574;&#30053;&#30340;&#24615;&#33021;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13903v1 Announce Type: new  Abstract: We study the performance of stochastic first-order methods for finding saddle points of convex-concave functions. A notorious challenge faced by such methods is that the gradients can grow arbitrarily large during optimization, which may result in instability and divergence. In this paper, we propose a simple and effective regularization technique that stabilizes the iterates and yields meaningful performance guarantees even if the domain and the gradient noise scales linearly with the size of the iterates (and is thus potentially unbounded). Besides providing a set of general results, we also apply our algorithm to a specific problem in reinforcement learning, where it leads to performance guarantees for finding near-optimal policies in an average-reward MDP without prior knowledge of the bias span.
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31070;&#32463;&#25511;&#21046;&#31995;&#32479;&#65292;&#29992;&#20110;&#36830;&#32493;&#33889;&#33796;&#31958;&#30417;&#27979;&#21644;&#32500;&#25252;&#65292;&#23454;&#26102;&#21160;&#24577;&#35843;&#25972;&#33008;&#23707;&#32032;&#36755;&#36865;&#65292;&#22686;&#24378;&#33889;&#33796;&#31958;&#20248;&#21270;&#65292;&#26368;&#22823;&#21270;&#25928;&#29575;&#24182;&#30830;&#20445;&#20010;&#24615;&#21270;&#25252;&#29702;&#12290;</title><link>https://arxiv.org/abs/2402.13852</link><description>&lt;p&gt;
&#36830;&#32493;&#33889;&#33796;&#31958;&#30417;&#27979;&#21644;&#32500;&#25252;&#30340;&#31070;&#32463;&#25511;&#21046;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Neural Control System for Continuous Glucose Monitoring and Maintenance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13852
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31070;&#32463;&#25511;&#21046;&#31995;&#32479;&#65292;&#29992;&#20110;&#36830;&#32493;&#33889;&#33796;&#31958;&#30417;&#27979;&#21644;&#32500;&#25252;&#65292;&#23454;&#26102;&#21160;&#24577;&#35843;&#25972;&#33008;&#23707;&#32032;&#36755;&#36865;&#65292;&#22686;&#24378;&#33889;&#33796;&#31958;&#20248;&#21270;&#65292;&#26368;&#22823;&#21270;&#25928;&#29575;&#24182;&#30830;&#20445;&#20010;&#24615;&#21270;&#25252;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31934;&#30830;&#30340;&#33889;&#33796;&#31958;&#27700;&#24179;&#31649;&#29702;&#23545;&#20110;&#31958;&#23615;&#30149;&#24739;&#32773;&#33267;&#20851;&#37325;&#35201;&#65292;&#21487;&#20197;&#36991;&#20813;&#20005;&#37325;&#24182;&#21457;&#30151;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31070;&#32463;&#25511;&#21046;&#31995;&#32479;&#65292;&#29992;&#20110;&#36830;&#32493;&#33889;&#33796;&#31958;&#30417;&#27979;&#21644;&#32500;&#25252;&#65292;&#21033;&#29992;&#24494;&#20998;&#39044;&#27979;&#25511;&#21046;&#12290;&#25105;&#20204;&#30340;&#31995;&#32479;&#21463;&#21040;&#22797;&#26434;&#31070;&#32463;&#31574;&#30053;&#21644;&#21487;&#21306;&#20998;&#24314;&#27169;&#30340;&#25351;&#23548;&#65292;&#23454;&#26102;&#21160;&#24577;&#35843;&#25972;&#33008;&#23707;&#32032;&#36755;&#36865;&#65292;&#22686;&#24378;&#33889;&#33796;&#31958;&#20248;&#21270;&#12290;&#36825;&#31181;&#31471;&#21040;&#31471;&#26041;&#27861;&#26368;&#22823;&#21270;&#25928;&#29575;&#65292;&#30830;&#20445;&#20010;&#24615;&#21270;&#25252;&#29702;&#21644;&#25913;&#21892;&#20581;&#24247;&#32467;&#26524;&#65292;&#22914;&#32463;&#39564;&#21457;&#29616;&#25152;&#35777;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13852v1 Announce Type: cross  Abstract: Precise glucose level management is pivotal for individuals with diabetes, averting severe complications. In this work, we introduce a novel neural control system for continuous glucose monitoring and maintenance, utilizing differential predictive control. Our system, guided by a sophisticated neural policy and differentiable modeling, dynamically adjusts insulin delivery in real-time, enhancing glucose optimization. This end-to-end approach maximizes efficiency, ensuring personalized care and improved health outcomes, as affirmed by empirical findings.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;&#65292;&#20256;&#32479;&#30340;&#38236;&#20687;&#26144;&#23556;&#36873;&#25321;&#65288;NPG&#65289;&#22312;&#26631;&#20934;&#22522;&#20934;&#29615;&#22659;&#20013;&#24120;&#24120;&#23548;&#33268;&#19981;&#29702;&#24819;&#30340;&#32467;&#26524;&#12290;&#36890;&#36807;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#25214;&#21040;&#20102;&#26356;&#39640;&#25928;&#30340;&#38236;&#20687;&#26144;&#23556;&#65292;&#25552;&#21319;&#20102;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.05187</link><description>&lt;p&gt;
&#22312;&#31574;&#30053;&#38236;&#20687;&#19979;&#38477;&#20013;&#20803;&#23398;&#20064;&#38236;&#20687;&#26144;&#23556;
&lt;/p&gt;
&lt;p&gt;
Meta-learning the mirror map in policy mirror descent
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05187
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;&#65292;&#20256;&#32479;&#30340;&#38236;&#20687;&#26144;&#23556;&#36873;&#25321;&#65288;NPG&#65289;&#22312;&#26631;&#20934;&#22522;&#20934;&#29615;&#22659;&#20013;&#24120;&#24120;&#23548;&#33268;&#19981;&#29702;&#24819;&#30340;&#32467;&#26524;&#12290;&#36890;&#36807;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#25214;&#21040;&#20102;&#26356;&#39640;&#25928;&#30340;&#38236;&#20687;&#26144;&#23556;&#65292;&#25552;&#21319;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31574;&#30053;&#38236;&#20687;&#19979;&#38477;&#65288;PMD&#65289;&#26159;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#19968;&#31181;&#27969;&#34892;&#26694;&#26550;&#65292;&#20316;&#20026;&#19968;&#31181;&#32479;&#19968;&#35270;&#35282;&#65292;&#23427;&#21253;&#21547;&#20102;&#35768;&#22810;&#31639;&#27861;&#12290;&#36825;&#20123;&#31639;&#27861;&#26159;&#36890;&#36807;&#36873;&#25321;&#19968;&#20010;&#38236;&#20687;&#26144;&#23556;&#32780;&#23548;&#20986;&#30340;&#65292;&#24182;&#19988;&#20855;&#26377;&#26377;&#38480;&#26102;&#38388;&#30340;&#25910;&#25947;&#20445;&#35777;&#12290;&#23613;&#31649;&#23427;&#24456;&#21463;&#27426;&#36814;&#65292;&#20294;&#23545;PMD&#30340;&#20840;&#38754;&#28508;&#21147;&#30340;&#25506;&#32034;&#26159;&#26377;&#38480;&#30340;&#65292;&#22823;&#37096;&#20998;&#30740;&#31350;&#38598;&#20013;&#22312;&#19968;&#20010;&#29305;&#23450;&#30340;&#38236;&#20687;&#26144;&#23556;&#19978;&#65292;&#21363;&#36127;&#29109;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#33879;&#21517;&#30340;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#65288;NPG&#65289;&#26041;&#27861;&#12290;&#30446;&#21069;&#30340;&#29702;&#35770;&#30740;&#31350;&#36824;&#19981;&#30830;&#23450;&#38236;&#20687;&#26144;&#23556;&#30340;&#36873;&#25321;&#26159;&#21542;&#20250;&#23545;PMD&#30340;&#26377;&#25928;&#24615;&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#12290;&#22312;&#25105;&#20204;&#30340;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#23454;&#35777;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#20256;&#32479;&#30340;&#38236;&#20687;&#26144;&#23556;&#36873;&#25321;&#65288;NPG&#65289;&#22312;&#20960;&#20010;&#26631;&#20934;&#22522;&#20934;&#29615;&#22659;&#20013;&#32463;&#24120;&#20135;&#29983;&#19981;&#29702;&#24819;&#30340;&#32467;&#26524;&#12290;&#36890;&#36807;&#24212;&#29992;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#26356;&#39640;&#25928;&#30340;&#38236;&#20687;&#26144;&#23556;&#65292;&#25552;&#39640;&#20102;&#24615;&#33021;&#65292;&#26080;&#35770;&#26159;&#24179;&#22343;&#24615;&#33021;&#36824;&#26159;&#26368;&#20339;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Policy Mirror Descent (PMD) is a popular framework in reinforcement learning, serving as a unifying perspective that encompasses numerous algorithms. These algorithms are derived through the selection of a mirror map and enjoy finite-time convergence guarantees. Despite its popularity, the exploration of PMD's full potential is limited, with the majority of research focusing on a particular mirror map -- namely, the negative entropy -- which gives rise to the renowned Natural Policy Gradient (NPG) method. It remains uncertain from existing theoretical studies whether the choice of mirror map significantly influences PMD's efficacy. In our work, we conduct empirical investigations to show that the conventional mirror map choice (NPG) often yields less-than-optimal outcomes across several standard benchmark environments. By applying a meta-learning approach, we identify more efficient mirror maps that enhance performance, both on average and in terms of best performance achieved along th
&lt;/p&gt;</description></item><item><title>$C^*$-&#20195;&#25968;&#26426;&#22120;&#23398;&#20064;&#26159;&#23558;$C^*$-&#20195;&#25968;&#19982;&#26426;&#22120;&#23398;&#20064;&#32467;&#21512;&#30340;&#26032;&#30740;&#31350;&#26041;&#21521;&#65292;&#23427;&#36890;&#36807;&#32479;&#19968;&#29616;&#26377;&#30340;&#23398;&#20064;&#31574;&#30053;&#65292;&#24182;&#26500;&#24314;&#26356;&#22810;&#20803;&#21270;&#21644;&#20449;&#24687;&#20016;&#23500;&#30340;&#25968;&#25454;&#27169;&#22411;&#30340;&#26032;&#26694;&#26550;&#65292;&#20026;&#26426;&#22120;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.02637</link><description>&lt;p&gt;
$C^*$-&#20195;&#25968;&#26426;&#22120;&#23398;&#20064;&#65306;&#36808;&#21521;&#26032;&#30340;&#26041;&#21521;
&lt;/p&gt;
&lt;p&gt;
$C^*$-Algebraic Machine Learning: Moving in a New Direction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02637
&lt;/p&gt;
&lt;p&gt;
$C^*$-&#20195;&#25968;&#26426;&#22120;&#23398;&#20064;&#26159;&#23558;$C^*$-&#20195;&#25968;&#19982;&#26426;&#22120;&#23398;&#20064;&#32467;&#21512;&#30340;&#26032;&#30740;&#31350;&#26041;&#21521;&#65292;&#23427;&#36890;&#36807;&#32479;&#19968;&#29616;&#26377;&#30340;&#23398;&#20064;&#31574;&#30053;&#65292;&#24182;&#26500;&#24314;&#26356;&#22810;&#20803;&#21270;&#21644;&#20449;&#24687;&#20016;&#23500;&#30340;&#25968;&#25454;&#27169;&#22411;&#30340;&#26032;&#26694;&#26550;&#65292;&#20026;&#26426;&#22120;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#19982;&#25968;&#23398;&#30340;&#20960;&#20010;&#39046;&#22495;&#65288;&#22914;&#32479;&#35745;&#23398;&#12289;&#27010;&#29575;&#35770;&#21644;&#32447;&#24615;&#20195;&#25968;&#65289;&#26377;&#30528;&#38271;&#26399;&#30340;&#21512;&#20316;&#20256;&#32479;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#30340;&#19968;&#20010;&#26032;&#26041;&#21521;&#65306;$C^*$-&#20195;&#25968;&#26426;&#22120;&#23398;&#20064;&#65292;&#36825;&#26159;$C^*$-&#20195;&#25968;&#21644;&#26426;&#22120;&#23398;&#20064;&#20043;&#38388;&#30340;&#20132;&#27969;&#21644;&#30456;&#20114;&#28363;&#20859;&#12290;$C^*$-&#20195;&#25968;&#26159;&#22797;&#25968;&#31354;&#38388;&#30340;&#33258;&#28982;&#25512;&#24191;&#30340;&#25968;&#23398;&#27010;&#24565;&#65292;&#23427;&#20351;&#25105;&#20204;&#33021;&#22815;&#32479;&#19968;&#29616;&#26377;&#30340;&#23398;&#20064;&#31574;&#30053;&#65292;&#24182;&#26500;&#24314;&#19968;&#20010;&#26356;&#22810;&#20803;&#21270;&#21644;&#20449;&#24687;&#20016;&#23500;&#30340;&#25968;&#25454;&#27169;&#22411;&#30340;&#26032;&#26694;&#26550;&#12290;&#25105;&#20204;&#35299;&#37322;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#20351;&#29992;$C^*$-&#20195;&#25968;&#30340;&#21407;&#22240;&#21644;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#22312;&#26680;&#26041;&#27861;&#21644;&#31070;&#32463;&#32593;&#32476;&#32972;&#26223;&#19979;&#35774;&#35745;$C^*$-&#20195;&#25968;&#23398;&#20064;&#27169;&#22411;&#30340;&#25216;&#26415;&#32771;&#34385;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;$C^*$-&#20195;&#25968;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24320;&#25918;&#38382;&#39064;&#21644;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#25105;&#20204;&#23545;&#26410;&#26469;&#21457;&#23637;&#21644;&#24212;&#29992;&#30340;&#24605;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning has a long collaborative tradition with several fields of mathematics, such as statistics, probability and linear algebra. We propose a new direction for machine learning research: $C^*$-algebraic ML $-$ a cross-fertilization between $C^*$-algebra and machine learning. The mathematical concept of $C^*$-algebra is a natural generalization of the space of complex numbers. It enables us to unify existing learning strategies, and construct a new framework for more diverse and information-rich data models. We explain why and how to use $C^*$-algebras in machine learning, and provide technical considerations that go into the design of $C^*$-algebraic learning models in the contexts of kernel methods and neural networks. Furthermore, we discuss open questions and challenges in $C^*$-algebraic ML and give our thoughts for future development and applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#24471;&#20998;&#29109;&#36825;&#19968;&#26032;&#39062;&#30340;&#31163;&#25955;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#65292;&#24357;&#34917;&#20102;&#31163;&#25955;&#25968;&#25454;&#39046;&#22495;&#20013;&#29616;&#26377;&#26041;&#27861;&#30340;&#19981;&#36275;&#65292;&#25552;&#20986;&#20102;&#24471;&#20998;&#29109;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;(SEDD)&#24182;&#22312;GPT-2&#23454;&#39564;&#20013;&#21462;&#24471;&#20102;&#26377;&#31454;&#20105;&#21147;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.16834</link><description>&lt;p&gt;
&#36890;&#36807;&#20272;&#35745;&#25968;&#25454;&#20998;&#24067;&#27604;&#20363;&#30340;&#31163;&#25955;&#25193;&#25955;&#35821;&#35328;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Discrete Diffusion Language Modeling by Estimating the Ratios of the Data Distribution. (arXiv:2310.16834v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16834
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#24471;&#20998;&#29109;&#36825;&#19968;&#26032;&#39062;&#30340;&#31163;&#25955;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#65292;&#24357;&#34917;&#20102;&#31163;&#25955;&#25968;&#25454;&#39046;&#22495;&#20013;&#29616;&#26377;&#26041;&#27861;&#30340;&#19981;&#36275;&#65292;&#25552;&#20986;&#20102;&#24471;&#20998;&#29109;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;(SEDD)&#24182;&#22312;GPT-2&#23454;&#39564;&#20013;&#21462;&#24471;&#20102;&#26377;&#31454;&#20105;&#21147;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#25193;&#25955;&#27169;&#22411;&#22312;&#35768;&#22810;&#29983;&#25104;&#24314;&#27169;&#20219;&#21153;&#20013;&#20855;&#26377;&#31361;&#30772;&#24615;&#30340;&#24615;&#33021;&#65292;&#20294;&#22312;&#33258;&#28982;&#35821;&#35328;&#31561;&#31163;&#25955;&#25968;&#25454;&#39046;&#22495;&#20013;&#21364;&#34920;&#29616;&#19981;&#20339;&#12290;&#20851;&#38190;&#26159;&#65292;&#26631;&#20934;&#30340;&#25193;&#25955;&#27169;&#22411;&#20381;&#36182;&#20110;&#25104;&#29087;&#30340;&#24471;&#20998;&#21305;&#37197;&#29702;&#35770;&#65292;&#20294;&#26159;&#23558;&#20854;&#25512;&#24191;&#21040;&#31163;&#25955;&#32467;&#26500;&#24182;&#27809;&#26377;&#21462;&#24471;&#30456;&#21516;&#30340;&#32463;&#39564;&#25910;&#30410;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#24471;&#20998;&#29109;&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#31163;&#25955;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#65292;&#26469;&#24357;&#34917;&#36825;&#20010;&#24046;&#36317;&#65292;&#23427;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#31283;&#23450;&#65292;&#21487;&#20197;&#24418;&#25104;&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#30340;ELBO&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#21435;&#22122;&#21464;&#20307;&#39640;&#25928;&#20248;&#21270;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#24471;&#20998;&#29109;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;&#65288;SEDD&#65289;&#25193;&#23637;&#21040;GPT-2&#30340;&#23454;&#39564;&#35774;&#32622;&#20013;&#65292;&#23454;&#29616;&#20102;&#26497;&#20855;&#31454;&#20105;&#21147;&#30340;&#20284;&#28982;&#24230;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#29420;&#29305;&#30340;&#31639;&#27861;&#20248;&#21183;&#12290;&#29305;&#21035;&#26159;&#65292;&#22312;&#27604;&#36739;&#22823;&#23567;&#30456;&#20284;&#30340;SEDD&#21644;GPT-2&#27169;&#22411;&#26102;&#65292;SEDD&#36798;&#21040;&#20102;&#21487;&#27604;&#36739;&#30340;&#22256;&#24785;&#24230;&#65288;&#36890;&#24120;&#22312;&#22522;&#32447;&#30340;+$10\%$&#20869;&#65292;&#24182;&#19988;&#26377;&#26102;&#36229;&#36807;&#22522;&#32447;&#65289;&#12290;&#27492;&#22806;&#65292;SEDD&#27169;&#22411;&#23398;&#21040;&#20102;...
&lt;/p&gt;
&lt;p&gt;
Despite their groundbreaking performance for many generative modeling tasks, diffusion models have fallen short on discrete data domains such as natural language. Crucially, standard diffusion models rely on the well-established theory of score matching, but efforts to generalize this to discrete structures have not yielded the same empirical gains. In this work, we bridge this gap by proposing score entropy, a novel discrete score matching loss that is more stable than existing methods, forms an ELBO for maximum likelihood training, and can be efficiently optimized with a denoising variant. We scale our Score Entropy Discrete Diffusion models (SEDD) to the experimental setting of GPT-2, achieving highly competitive likelihoods while also introducing distinct algorithmic advantages. In particular, when comparing similarly sized SEDD and GPT-2 models, SEDD attains comparable perplexities (normally within $+10\%$ of and sometimes outperforming the baseline). Furthermore, SEDD models lear
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#65288;CRL&#65289;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35266;&#27979;&#21464;&#37327;&#20998;&#32452;&#30340;&#26032;&#22411;&#24369;&#32422;&#26463;&#30340;&#21487;&#36776;&#35782;&#24615;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#19981;&#20381;&#36182;&#20110;&#26102;&#38388;&#32467;&#26500;&#12289;&#24178;&#39044;&#25110;&#30417;&#30563;&#65292;&#20855;&#26377;&#23454;&#38469;&#24212;&#29992;&#30340;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2310.15709</link><description>&lt;p&gt;
&#36890;&#36807;&#35266;&#27979;&#21464;&#37327;&#30340;&#20998;&#32452;&#20351;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#21487;&#36776;&#35782;&#21270;
&lt;/p&gt;
&lt;p&gt;
Causal Representation Learning Made Identifiable by Grouping of Observational Variables. (arXiv:2310.15709v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15709
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#65288;CRL&#65289;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35266;&#27979;&#21464;&#37327;&#20998;&#32452;&#30340;&#26032;&#22411;&#24369;&#32422;&#26463;&#30340;&#21487;&#36776;&#35782;&#24615;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#19981;&#20381;&#36182;&#20110;&#26102;&#38388;&#32467;&#26500;&#12289;&#24178;&#39044;&#25110;&#30417;&#30563;&#65292;&#20855;&#26377;&#23454;&#38469;&#24212;&#29992;&#30340;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20170;&#24456;&#26377;&#24847;&#20041;&#30340;&#35805;&#39064;&#26159;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#65288;Causal Representation Learning&#65292;&#31616;&#31216;CRL&#65289;&#65292;&#20854;&#30446;&#26631;&#26159;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#23398;&#20064;&#38544;&#34255;&#29305;&#24449;&#30340;&#22240;&#26524;&#27169;&#22411;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;CRL&#23384;&#22312;&#20005;&#37325;&#30340;&#19981;&#36866;&#38382;&#39064;&#65292;&#22240;&#20026;&#23427;&#32467;&#21512;&#20102;&#34920;&#31034;&#23398;&#20064;&#21644;&#22240;&#26524;&#21457;&#29616;&#36825;&#20004;&#20010;&#23481;&#26131;&#19981;&#36866;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#35201;&#25214;&#21040;&#33021;&#20445;&#35777;&#21807;&#19968;&#35299;&#30340;&#23454;&#38469;&#21487;&#35782;&#21035;&#24615;&#26465;&#20214;&#23545;&#20110;&#20854;&#23454;&#38469;&#24212;&#29992;&#38750;&#24120;&#37325;&#35201;&#12290;&#30446;&#21069;&#22823;&#22810;&#25968;&#26041;&#27861;&#37117;&#22522;&#20110;&#23545;&#28508;&#22312;&#22240;&#26524;&#26426;&#21046;&#30340;&#20551;&#35774;&#65292;&#27604;&#22914;&#26102;&#38388;&#22240;&#26524;&#24615;&#12289;&#30417;&#30563;&#25110;&#24178;&#39044;&#30340;&#23384;&#22312;&#65307;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#36825;&#20123;&#20551;&#35774;&#21487;&#33021;&#36807;&#20110;&#38480;&#21046;&#24615;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#36890;&#36807;&#23545;&#35266;&#27979;&#28151;&#21512;&#34920;&#29616;&#20986;&#21512;&#36866;&#30340;&#21464;&#37327;&#20998;&#32452;&#30340;&#26032;&#22411;&#24369;&#32422;&#26463;&#65292;&#23637;&#31034;&#20102;&#21487;&#36776;&#35782;&#24615;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#19982;&#27169;&#22411;&#19968;&#33268;&#30340;&#26032;&#22411;&#33258;&#25105;&#30417;&#30563;&#20272;&#35745;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
A topic of great current interest is Causal Representation Learning (CRL), whose goal is to learn a causal model for hidden features in a data-driven manner. Unfortunately, CRL is severely ill-posed since it is a combination of the two notoriously ill-posed problems of representation learning and causal discovery. Yet, finding practical identifiability conditions that guarantee a unique solution is crucial for its practical applicability. Most approaches so far have been based on assumptions on the latent causal mechanisms, such as temporal causality, or existence of supervision or interventions; these can be too restrictive in actual applications. Here, we show identifiability based on novel, weak constraints, which requires no temporal structure, intervention, nor weak supervision. The approach is based assuming the observational mixing exhibits a suitable grouping of the observational variables. We also propose a novel self-supervised estimation framework consistent with the model, 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#20960;&#20309;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#65288;GTA&#65289;&#65292;&#29992;&#20110;&#23558;&#20960;&#20309;&#32467;&#26500;&#32534;&#30721;&#20026;&#30456;&#23545;&#21464;&#25442;&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;&#22810;&#35270;&#22270;Transformer&#30340;&#23398;&#20064;&#25928;&#29575;&#21644;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.10375</link><description>&lt;p&gt;
GTA&#65306;&#19968;&#31181;&#38754;&#21521;&#20960;&#20309;&#30340;&#22810;&#35270;&#22270;Transformer&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
GTA: A Geometry-Aware Attention Mechanism for Multi-View Transformers. (arXiv:2310.10375v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10375
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#20960;&#20309;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#65288;GTA&#65289;&#65292;&#29992;&#20110;&#23558;&#20960;&#20309;&#32467;&#26500;&#32534;&#30721;&#20026;&#30456;&#23545;&#21464;&#25442;&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;&#22810;&#35270;&#22270;Transformer&#30340;&#23398;&#20064;&#25928;&#29575;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;transformers&#23545;&#36755;&#20837;&#26631;&#35760;&#30340;&#25490;&#21015;&#20855;&#26377;&#31561;&#21464;&#24615;&#65292;&#23545;&#26631;&#35760;&#30340;&#20301;&#32622;&#20449;&#24687;&#36827;&#34892;&#32534;&#30721;&#23545;&#35768;&#22810;&#20219;&#21153;&#26159;&#24517;&#35201;&#30340;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#29616;&#26377;&#30340;&#20301;&#32622;&#32534;&#30721;&#26041;&#26696;&#26368;&#21021;&#26159;&#20026;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#35774;&#35745;&#30340;&#65292;&#23545;&#20110;&#36890;&#24120;&#22312;&#20854;&#25968;&#25454;&#20013;&#34920;&#29616;&#20986;&#19981;&#21516;&#32467;&#26500;&#29305;&#24615;&#30340;&#35270;&#35273;&#20219;&#21153;&#26469;&#35828;&#65292;&#23427;&#20204;&#30340;&#36866;&#29992;&#24615;&#20540;&#24471;&#24576;&#30097;&#12290;&#25105;&#20204;&#35748;&#20026;&#29616;&#26377;&#30340;&#20301;&#32622;&#32534;&#30721;&#26041;&#26696;&#23545;&#20110;3D&#35270;&#35273;&#20219;&#21153;&#26469;&#35828;&#26159;&#27425;&#20248;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#19981;&#23562;&#37325;&#20854;&#24213;&#23618;&#30340;3D&#20960;&#20309;&#32467;&#26500;&#12290;&#22522;&#20110;&#36825;&#20010;&#20551;&#35774;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#20960;&#20309;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#23427;&#23558;&#26631;&#35760;&#30340;&#20960;&#20309;&#32467;&#26500;&#32534;&#30721;&#20026;&#30001;&#26597;&#35810;&#21644;&#38190;&#20540;&#23545;&#20043;&#38388;&#30340;&#20960;&#20309;&#20851;&#31995;&#25152;&#30830;&#23450;&#30340;&#30456;&#23545;&#21464;&#25442;&#12290;&#36890;&#36807;&#22312;&#31232;&#30095;&#23485;&#22522;&#32447;&#22810;&#35270;&#22270;&#35774;&#32622;&#20013;&#35780;&#20272;&#22810;&#20010;&#26032;&#39062;&#35270;&#22270;&#21512;&#25104;&#65288;NVS&#65289;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#8212;&#8212;&#20960;&#20309;&#21464;&#25442;&#27880;&#24847;&#21147;&#65288;GTA&#65289;&#22914;&#20309;&#25552;&#39640;&#20102;&#26368;&#20808;&#36827;&#30340;Transformer&#30340;&#23398;&#20064;&#25928;&#29575;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
As transformers are equivariant to the permutation of input tokens, encoding the positional information of tokens is necessary for many tasks. However, since existing positional encoding schemes have been initially designed for NLP tasks, their suitability for vision tasks, which typically exhibit different structural properties in their data, is questionable. We argue that existing positional encoding schemes are suboptimal for 3D vision tasks, as they do not respect their underlying 3D geometric structure. Based on this hypothesis, we propose a geometry-aware attention mechanism that encodes the geometric structure of tokens as relative transformation determined by the geometric relationship between queries and key-value pairs. By evaluating on multiple novel view synthesis (NVS) datasets in the sparse wide-baseline multi-view setting, we show that our attention, called Geometric Transform Attention (GTA), improves learning efficiency and performance of state-of-the-art transformer-b
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23454;&#38469;&#25968;&#25454;&#30340;&#20840;&#38754;&#23454;&#35777;&#20998;&#26512;&#35777;&#26126;&#20102;&#22312;&#22312;&#32447;&#23398;&#20064;&#20013;&#65292;&#22823;&#23398;&#20064;&#29575;&#21644;&#23567;&#25209;&#37327;&#22823;&#23567;&#24182;&#19981;&#20250;&#24102;&#26469;&#20219;&#20309;&#38544;&#24615;&#20559;&#24046;&#30340;&#20248;&#21183;&#12290;&#22312;&#32447;&#23398;&#20064;&#20013;SGD&#22122;&#38899;&#30340;&#22909;&#22788;&#21482;&#26159;&#35745;&#31639;&#19978;&#30340;&#20415;&#21033;&#65292;&#21487;&#20197;&#20419;&#36827;&#26356;&#22823;&#25110;&#26356;&#20855;&#25104;&#26412;&#25928;&#30410;&#30340;&#26799;&#24230;&#27493;&#39588;&#12290;</title><link>http://arxiv.org/abs/2306.08590</link><description>&lt;p&gt;
&#36229;&#36234;&#38544;&#24615;&#20559;&#24046;&#65306;SGD&#22122;&#22768;&#22312;&#22312;&#32447;&#23398;&#20064;&#20013;&#30340;&#19981;&#37325;&#35201;&#24615;
&lt;/p&gt;
&lt;p&gt;
Beyond Implicit Bias: The Insignificance of SGD Noise in Online Learning. (arXiv:2306.08590v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08590
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23454;&#38469;&#25968;&#25454;&#30340;&#20840;&#38754;&#23454;&#35777;&#20998;&#26512;&#35777;&#26126;&#20102;&#22312;&#22312;&#32447;&#23398;&#20064;&#20013;&#65292;&#22823;&#23398;&#20064;&#29575;&#21644;&#23567;&#25209;&#37327;&#22823;&#23567;&#24182;&#19981;&#20250;&#24102;&#26469;&#20219;&#20309;&#38544;&#24615;&#20559;&#24046;&#30340;&#20248;&#21183;&#12290;&#22312;&#32447;&#23398;&#20064;&#20013;SGD&#22122;&#38899;&#30340;&#22909;&#22788;&#21482;&#26159;&#35745;&#31639;&#19978;&#30340;&#20415;&#21033;&#65292;&#21487;&#20197;&#20419;&#36827;&#26356;&#22823;&#25110;&#26356;&#20855;&#25104;&#26412;&#25928;&#30410;&#30340;&#26799;&#24230;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#30340;&#30740;&#31350;&#35748;&#20026;&#65292;SGD&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#25104;&#21151;&#24402;&#22240;&#20110;&#39640;&#23398;&#20064;&#29575;&#25110;&#23567;&#25209;&#37327;&#22823;&#23567;&#25152;&#24341;&#36215;&#30340;&#38544;&#24615;&#20559;&#24046;&#65288;&#8220;SGD&#22122;&#22768;&#8221;&#65289;&#12290;&#32780;&#25105;&#20204;&#30740;&#31350;&#20102;SGD&#22122;&#22768;&#22312;&#22312;&#32447;&#65288;&#21363;&#21333;&#20010;epoch&#65289;&#23398;&#20064;&#20013;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#23545;&#22270;&#20687;&#21644;&#35821;&#35328;&#25968;&#25454;&#30340;&#20840;&#38754;&#23454;&#35777;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#22312;&#32447;&#23398;&#20064;&#20013;&#65292;&#22823;&#23398;&#20064;&#29575;&#21644;&#23567;&#25209;&#37327;&#22823;&#23567;&#24182;&#19981;&#20250;&#24102;&#26469;&#20219;&#20309;&#38544;&#24615;&#20559;&#24046;&#30340;&#20248;&#21183;&#12290;&#19982;&#31163;&#32447;&#23398;&#20064;&#30456;&#21453;&#65292;&#22312;&#32447;&#23398;&#20064;&#20013;SGD&#22122;&#22768;&#30340;&#22909;&#22788;&#20005;&#26684;&#26469;&#35828;&#21482;&#26159;&#35745;&#31639;&#19978;&#30340;&#20415;&#21033;&#65292;&#21487;&#20197;&#20419;&#36827;&#26356;&#22823;&#25110;&#26356;&#20855;&#25104;&#26412;&#25928;&#30410;&#30340;&#26799;&#24230;&#27493;&#39588;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;SGD&#22312;&#22312;&#32447;&#27169;&#24335;&#19979;&#21487;&#20197;&#34987;&#35270;&#20026;&#26159;&#22312;&#8220;&#26080;&#22122;&#22768;&#26799;&#24230;&#27969;&#31639;&#27861;&#8221;&#30340;&#8220;&#40644;&#37329;&#36335;&#24452;&#8221;&#19978;&#36393;&#36367;&#22024;&#26434;&#27493;&#20240;&#12290;&#36890;&#36807;&#20943;&#23569;&#35757;&#32451;&#26399;&#38388;&#30340;SGD&#22122;&#22768;&#21644;&#27979;&#37327;&#27169;&#22411;&#20043;&#38388;&#30340;&#36880;&#28857;&#21151;&#33021;&#36317;&#31163;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#25903;&#25345;&#27492;&#20551;&#35774;&#30340;&#35777;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
The success of SGD in deep learning has been ascribed by prior works to the implicit bias induced by high learning rate or small batch size ("SGD noise"). While prior works that focused on offline learning (i.e., multiple-epoch training), we study the impact of SGD noise on online (i.e., single epoch) learning. Through an extensive empirical analysis of image and language data, we demonstrate that large learning rate and small batch size do not confer any implicit bias advantages in online learning. In contrast to offline learning, the benefits of SGD noise in online learning are strictly computational, facilitating larger or more cost-effective gradient steps. Our work suggests that SGD in the online regime can be construed as taking noisy steps along the "golden path" of the noiseless gradient flow algorithm. We provide evidence to support this hypothesis by conducting experiments that reduce SGD noise during training and by measuring the pointwise functional distance between models 
&lt;/p&gt;</description></item><item><title>BOtied &#26159;&#19968;&#31181;&#24102;&#26377;&#30456;&#20851;&#22810;&#20803;&#31561;&#32423;&#30340;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#65292;&#30456;&#36739;&#20110;&#29616;&#26377;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#26679;&#26412;&#25928;&#29575;&#21644;&#36739;&#22909;&#30340;&#36817;&#20284;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2306.00344</link><description>&lt;p&gt;
BOtied: &#24102;&#26377;&#30456;&#20851;&#22810;&#20803;&#31561;&#32423;&#30340;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
BOtied: Multi-objective Bayesian optimization with tied multivariate ranks. (arXiv:2306.00344v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00344
&lt;/p&gt;
&lt;p&gt;
BOtied &#26159;&#19968;&#31181;&#24102;&#26377;&#30456;&#20851;&#22810;&#20803;&#31561;&#32423;&#30340;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#65292;&#30456;&#36739;&#20110;&#29616;&#26377;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#26679;&#26412;&#25928;&#29575;&#21644;&#36739;&#22909;&#30340;&#36817;&#20284;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#31185;&#23398;&#21644;&#24037;&#19994;&#24212;&#29992;&#38656;&#35201;&#21516;&#26102;&#20248;&#21270;&#22810;&#20010;&#28508;&#22312;&#30340;&#30456;&#20114;&#20914;&#31361;&#30340;&#30446;&#26631;&#12290;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270; (MOBO) &#26159;&#19968;&#31181;&#39640;&#25928;&#22320;&#35782;&#21035; Pareto &#26368;&#20248;&#35299;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26080;&#25903;&#37197;&#35299;&#21644;&#26368;&#39640;&#22810;&#20803;&#31561;&#32423;&#20043;&#38388;&#30340;&#33258;&#28982;&#32852;&#31995;&#65292;&#23427;&#19982;&#32852;&#21512;&#32047;&#31215;&#20998;&#24067;&#20989;&#25968;&#30340;&#26368;&#22806;&#23618;&#31561;&#39640;&#32447;&#37325;&#21512;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102; CDF indicator&#65292;&#36825;&#26159;&#19968;&#31181; Pareto &#21512;&#35268;&#30340;&#24230;&#37327;&#65292;&#29992;&#20110;&#35780;&#20272;&#36817;&#20284; Pareto &#38598;&#21512;&#30340;&#36136;&#37327;&#65292;&#23427;&#34917;&#20805;&#20102;&#27969;&#34892;&#30340; hypervolume indicator&#12290;MOBO &#30340;&#26680;&#24515;&#26159;&#37319;&#38598;&#20989;&#25968;&#65292;&#23427;&#36890;&#36807;&#23548;&#33322;&#30446;&#26631;&#20043;&#38388;&#30340;&#26368;&#20339;&#25240;&#20013;&#26469;&#30830;&#23450;&#19979;&#19968;&#20010;&#35201;&#35780;&#20272;&#30340;&#20505;&#36873;&#39033;&#12290; &#22522;&#20110;&#30418;&#23376;&#20998;&#35299;&#30446;&#26631;&#31354;&#38388;&#30340;&#22810;&#30446;&#26631;&#37319;&#38598;&#20989;&#25968;&#65288;&#20363;&#22914;&#26399;&#26395;&#30340; hypervolume &#25913;&#36827;&#65288;EHVI&#65289;&#21644;&#29109;&#25628;&#32034;&#65289;&#22312;&#23384;&#22312;&#22823;&#37327;&#30446;&#26631;&#26102;&#30340;&#24615;&#33021;&#32553;&#25918;&#24456;&#24046;&#12290;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#37319;&#38598;&#20989;&#25968;&#65292;&#31216;&#20026; BOtied&#65292;&#23427;&#21033;&#29992;&#30456;&#20851;&#22810;&#20803;&#31561;&#32423;&#26469;&#39640;&#25928;&#25628;&#32034; Pareto frontier&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;BOtied &#22312;&#26679;&#26412;&#25928;&#29575;&#21644;&#36817;&#20284;&#36136;&#37327;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many scientific and industrial applications require joint optimization of multiple, potentially competing objectives. Multi-objective Bayesian optimization (MOBO) is a sample-efficient framework for identifying Pareto-optimal solutions. We show a natural connection between non-dominated solutions and the highest multivariate rank, which coincides with the outermost level line of the joint cumulative distribution function (CDF). We propose the CDF indicator, a Pareto-compliant metric for evaluating the quality of approximate Pareto sets that complements the popular hypervolume indicator. At the heart of MOBO is the acquisition function, which determines the next candidate to evaluate by navigating the best compromises among the objectives. Multi-objective acquisition functions that rely on box decomposition of the objective space, such as the expected hypervolume improvement (EHVI) and entropy search, scale poorly to a large number of objectives. We propose an acquisition function, call
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#38750;&#20984;&#38750;&#20809;&#28369;&#38382;&#39064;&#30340;&#38750;&#31934;&#30830;&#32447;&#24615;&#21270;&#36817;&#31471;&#31639;&#27861;&#65292;&#24182;&#24212;&#29992;&#20110;&#40065;&#26834;&#20998;&#35299;&#20013;&#30340;&#20004;&#20010;&#38382;&#39064;&#65292;&#24471;&#21040;&#20102;&#26377;&#25928;&#30340;&#25968;&#20540;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2303.16822</link><description>&lt;p&gt;
&#19968;&#31867;DC&#22797;&#21512;&#20248;&#21270;&#38382;&#39064;&#30340;&#38750;&#31934;&#30830;&#32447;&#24615;&#36817;&#20284;&#36817;&#31471;&#31639;&#27861;&#21450;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
An inexact linearized proximal algorithm for a class of DC composite optimization problems and applications. (arXiv:2303.16822v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16822
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#38750;&#20984;&#38750;&#20809;&#28369;&#38382;&#39064;&#30340;&#38750;&#31934;&#30830;&#32447;&#24615;&#21270;&#36817;&#31471;&#31639;&#27861;&#65292;&#24182;&#24212;&#29992;&#20110;&#40065;&#26834;&#20998;&#35299;&#20013;&#30340;&#20004;&#20010;&#38382;&#39064;&#65292;&#24471;&#21040;&#20102;&#26377;&#25928;&#30340;&#25968;&#20540;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;DC&#22797;&#21512;&#20248;&#21270;&#38382;&#39064;&#12290;&#36825;&#31867;&#38382;&#39064;&#36890;&#24120;&#30001;&#20302;&#31209;&#30697;&#38453;&#24674;&#22797;&#30340;&#40065;&#26834;&#20998;&#35299;&#27169;&#22411;&#25512;&#23548;&#32780;&#26469;&#65292;&#26159;&#20984;&#22797;&#21512;&#20248;&#21270;&#38382;&#39064;&#21644;&#20855;&#26377;&#38750;&#20809;&#28369;&#20998;&#37327;&#30340;DC&#35268;&#21010;&#30340;&#25193;&#23637;&#12290;&#38024;&#23545;&#36825;&#31867;&#38750;&#20984;&#21644;&#38750;&#20809;&#28369;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#31934;&#30830;&#32447;&#24615;&#21270;&#36817;&#31471;&#31639;&#27861;&#65288;iLPA&#65289;&#12290;&#31639;&#27861;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#30446;&#26631;&#20989;&#25968;&#30340;&#37096;&#20998;&#32447;&#24615;&#21270;&#65292;&#35745;&#31639;&#24378;&#20984;&#20027;&#23548;&#30340;&#38750;&#31934;&#30830;&#26368;&#23567;&#21270;&#20540;&#12290;&#36845;&#20195;&#24207;&#21015;&#30340;&#29983;&#25104;&#25910;&#25947;&#20110;&#28508;&#22312;&#20989;&#25968;&#30340;Kurdyka-{\L}ojasiewicz&#65288;KL&#65289;&#24615;&#36136;&#65292;&#22914;&#26524;&#28508;&#22312;&#20989;&#25968;&#22312;&#26497;&#38480;&#28857;&#22788;&#20855;&#26377;KL&#25351;&#25968;$1/2$&#30340;KL&#24615;&#36136;&#65292;&#21017;&#25910;&#25947;&#20855;&#26377;&#23616;&#37096;R&#32447;&#24615;&#36895;&#29575;&#12290;&#23545;&#20110;&#21518;&#19968;&#31181;&#20551;&#35774;&#65292;&#25105;&#20204;&#21033;&#29992;&#22797;&#21512;&#32467;&#26500;&#25552;&#20379;&#20102;&#19968;&#20010;&#21487;&#39564;&#35777;&#30340;&#26465;&#20214;&#65292;&#24182;&#38416;&#26126;&#20102;&#19982;&#20984;&#22797;&#21512;&#20248;&#21270;&#25152;&#20351;&#29992;&#30340;&#27491;&#21017;&#24615;&#30340;&#20851;&#31995;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#25152;&#25552;&#20986;&#30340;&#38750;&#31934;&#30830;&#32447;&#24615;&#36817;&#31471;&#31639;&#27861;&#24212;&#29992;&#20110;&#35299;&#20915;&#40065;&#26834;&#20998;&#35299;&#20013;&#30340;&#20004;&#20010;&#37325;&#35201;&#38382;&#39064;&#65306;&#24352;&#37327;&#40065;&#26834;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;TRPCA&#65289;&#21644;&#24352;&#37327;&#40065;&#26834;&#20302;&#31209;&#24352;&#37327;&#23436;&#25104;&#65288;TRLRTC&#65289;&#12290;&#23545;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#30340;&#25968;&#20540;&#32467;&#26524;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#30456;&#23545;&#20110;&#29616;&#26377;&#26368;&#26032;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is concerned with a class of DC composite optimization problems which, as an extension of the convex composite optimization problem and the DC program with nonsmooth components, often arises from robust factorization models of low-rank matrix recovery. For this class of nonconvex and nonsmooth problems, we propose an inexact linearized proximal algorithm (iLPA) which in each step computes an inexact minimizer of a strongly convex majorization constructed by the partial linearization of their objective functions. The generated iterate sequence is shown to be convergent under the Kurdyka-{\L}ojasiewicz (KL) property of a potential function, and the convergence admits a local R-linear rate if the potential function has the KL property of exponent $1/2$ at the limit point. For the latter assumption, we provide a verifiable condition by leveraging the composite structure, and clarify its relation with the regularity used for the convex composite optimization. Finally, the propose
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;PDExplain&#65292;&#19968;&#31181;&#35299;&#37322;&#24615;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#35813;&#31639;&#27861;&#33021;&#22815;&#36890;&#36807;&#25552;&#20379;&#23569;&#37327;&#26679;&#26412;&#30340;&#26041;&#24335;&#65292;&#39044;&#27979;&#26410;&#26469;&#26102;&#38388;&#27493;&#30340;PDE&#35299;&#65292;&#26497;&#22823;&#22320;&#21327;&#21161;&#20102;&#24314;&#31435;&#29289;&#29702;&#31185;&#23398;&#20013;&#22522;&#20110;&#25968;&#25454;&#30340;&#29616;&#35937;&#24314;&#27169;&#12290;</title><link>http://arxiv.org/abs/2303.15827</link><description>&lt;p&gt;
PDExplain&#65306;PDEs &#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#24773;&#22659;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
PDExplain: Contextual Modeling of PDEs in the Wild. (arXiv:2303.15827v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15827
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;PDExplain&#65292;&#19968;&#31181;&#35299;&#37322;&#24615;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#35813;&#31639;&#27861;&#33021;&#22815;&#36890;&#36807;&#25552;&#20379;&#23569;&#37327;&#26679;&#26412;&#30340;&#26041;&#24335;&#65292;&#39044;&#27979;&#26410;&#26469;&#26102;&#38388;&#27493;&#30340;PDE&#35299;&#65292;&#26497;&#22823;&#22320;&#21327;&#21161;&#20102;&#24314;&#31435;&#29289;&#29702;&#31185;&#23398;&#20013;&#22522;&#20110;&#25968;&#25454;&#30340;&#29616;&#35937;&#24314;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#37322;&#24615;&#30340;&#26041;&#27861;PDExplain&#29992;&#20110;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#22312;&#35757;&#32451;&#38454;&#27573;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#19968;&#20010;&#25805;&#20316;&#21592;&#23450;&#20041;&#30340;PDE&#23478;&#26063;&#30340;&#25968;&#25454;&#20197;&#21450;&#36825;&#20010;&#23478;&#26063;&#30340;&#19968;&#33324;&#24418;&#24335;&#36827;&#34892;&#39304;&#36865;&#12290;&#22312;&#25512;&#26029;&#38454;&#27573;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#20174;&#29616;&#35937;&#20013;&#25910;&#38598;&#21040;&#30340;&#26368;&#23567;&#26679;&#26412;&#65292;&#20854;&#20013;&#26679;&#26412;&#19982; PDE &#23478;&#26063;&#30456;&#20851;&#65292;&#20294;&#19981;&#19968;&#23450;&#23646;&#20110;&#35757;&#32451;&#38454;&#27573;&#30475;&#21040;&#30340;&#20855;&#20307; PDE &#38598;&#21512;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#31639;&#27861;&#22914;&#20309;&#39044;&#27979;&#26410;&#26469;&#26102;&#38388;&#27493;&#30340;PDE&#35299;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;PDE&#30340;&#21487;&#35299;&#37322;&#24418;&#24335;&#65292;&#36825;&#31181;&#29305;&#24449;&#21487;&#20197;&#21327;&#21161;&#36890;&#36807;&#29289;&#29702;&#31185;&#23398;&#25968;&#25454;&#26469;&#23545;&#29616;&#35937;&#36827;&#34892;&#24314;&#27169;&#12290;&#20026;&#20102;&#39564;&#35777;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#32771;&#23519;&#20102;&#20854;&#22312;&#39044;&#27979;&#35823;&#24046;&#21644;&#21487;&#35299;&#37322;&#24615;&#26041;&#38754;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an explainable method for solving Partial Differential Equations by using a contextual scheme called PDExplain. During the training phase, our method is fed with data collected from an operator-defined family of PDEs accompanied by the general form of this family. In the inference phase, a minimal sample collected from a phenomenon is provided, where the sample is related to the PDE family but not necessarily to the set of specific PDEs seen in the training phase. We show how our algorithm can predict the PDE solution for future timesteps. Moreover, our method provides an explainable form of the PDE, a trait that can assist in modelling phenomena based on data in physical sciences. To verify our method, we conduct extensive experimentation, examining its quality both in terms of prediction error and explainability.
&lt;/p&gt;</description></item></channel></rss>