<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22686;&#37327;&#35745;&#31639;&#30340;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#36890;&#36807;&#31163;&#25955;&#21270;&#20013;&#38388;&#20540;&#24182;&#36807;&#28388;&#19981;&#24517;&#35201;&#30340;&#20462;&#25913;&#65292;&#23454;&#29616;&#20102;&#23545;&#21160;&#24577;&#36755;&#20837;&#30340;&#39640;&#25928;&#25512;&#29702;&#12290;</title><link>http://arxiv.org/abs/2307.14988</link><description>&lt;p&gt;
&#22686;&#37327;&#35745;&#31639;&#30340;&#31070;&#32463;&#32593;&#32476;&#65306;&#22788;&#29702;&#21160;&#24577;&#36755;&#20837;&#30340;&#39640;&#25928;&#25512;&#29702;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Incrementally-Computable Neural Networks: Efficient Inference for Dynamic Inputs. (arXiv:2307.14988v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14988
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22686;&#37327;&#35745;&#31639;&#30340;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#36890;&#36807;&#31163;&#25955;&#21270;&#20013;&#38388;&#20540;&#24182;&#36807;&#28388;&#19981;&#24517;&#35201;&#30340;&#20462;&#25913;&#65292;&#23454;&#29616;&#20102;&#23545;&#21160;&#24577;&#36755;&#20837;&#30340;&#39640;&#25928;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#22312;&#22788;&#29702;&#21160;&#24577;&#36755;&#20837;&#65288;&#20363;&#22914;&#20256;&#24863;&#22120;&#25968;&#25454;&#25110;&#29992;&#25143;&#36755;&#20837;&#65289;&#26102;&#24120;&#38754;&#20020;&#30528;&#39640;&#25928;&#22788;&#29702;&#30340;&#25361;&#25112;&#12290;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22686;&#37327;&#35745;&#31639;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#37325;&#22797;&#20351;&#29992;&#35745;&#31639;&#26469;&#36866;&#24212;&#36755;&#20837;&#21464;&#21270;&#65292;&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#21521;&#37327;&#37327;&#21270;&#26469;&#31163;&#25955;&#21270;&#32593;&#32476;&#20013;&#30340;&#20013;&#38388;&#20540;&#65292;&#24182;&#36807;&#28388;&#22122;&#22768;&#21644;&#19981;&#24517;&#35201;&#30340;&#38544;&#34255;&#31070;&#32463;&#20803;&#20462;&#25913;&#65292;&#20174;&#32780;&#20419;&#36827;&#20540;&#30340;&#37325;&#29992;&#12290;&#25105;&#20204;&#23558;&#27492;&#26041;&#27861;&#24212;&#29992;&#20110;Transformer&#26550;&#26500;&#65292;&#21019;&#24314;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#22686;&#37327;&#25512;&#29702;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning often faces the challenge of efficiently processing dynamic inputs, such as sensor data or user inputs. For example, an AI writing assistant is required to update its suggestions in real time as a document is edited. Re-running the model each time is expensive, even with compression techniques like knowledge distillation, pruning, or quantization. Instead, we take an incremental computing approach, looking to reuse calculations as the inputs change. However, the dense connectivity of conventional architectures poses a major obstacle to incremental computation, as even minor input changes cascade through the network and restrict information reuse. To address this, we use vector quantization to discretize intermediate values in the network, which filters out noisy and unnecessary modifications to hidden neurons, facilitating the reuse of their values. We apply this approach to the transformers architecture, creating an efficient incremental inference algorithm with complexi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23383;&#20856;&#23398;&#20064;&#21644;&#26368;&#20248;&#20256;&#36755;&#30340;MSDA&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#27599;&#20010;&#22495;&#34920;&#31034;&#20026;&#23383;&#20856;&#21407;&#23376;&#30340;Wasserstein&#37325;&#24515;&#26469;&#32531;&#35299;&#25968;&#25454;&#20998;&#24067;&#20559;&#31227;&#12290;&#26681;&#25454;&#35813;&#23383;&#20856;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;MSDA&#26041;&#27861;&#65292;&#20998;&#21035;&#22522;&#20110;&#30446;&#26631;&#22495;&#26631;&#35760;&#26679;&#26412;&#30340;&#37325;&#26500;&#21644;&#22312;&#21407;&#23376;&#20998;&#24067;&#19978;&#23398;&#20064;&#30340;&#20998;&#31867;&#22120;&#30340;&#38598;&#25104;&#12290;&#22312;&#22810;&#20010;&#22522;&#20934;&#27979;&#35797;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#20998;&#31867;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.14953</link><description>&lt;p&gt;
&#22312;Wasserstein&#31354;&#38388;&#20013;&#36890;&#36807;&#25968;&#25454;&#38598;&#23383;&#20856;&#23398;&#20064;&#36827;&#34892;&#22810;&#28304;&#22495;&#33258;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
Multi-Source Domain Adaptation through Dataset Dictionary Learning in Wasserstein Space. (arXiv:2307.14953v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14953
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23383;&#20856;&#23398;&#20064;&#21644;&#26368;&#20248;&#20256;&#36755;&#30340;MSDA&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#27599;&#20010;&#22495;&#34920;&#31034;&#20026;&#23383;&#20856;&#21407;&#23376;&#30340;Wasserstein&#37325;&#24515;&#26469;&#32531;&#35299;&#25968;&#25454;&#20998;&#24067;&#20559;&#31227;&#12290;&#26681;&#25454;&#35813;&#23383;&#20856;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;MSDA&#26041;&#27861;&#65292;&#20998;&#21035;&#22522;&#20110;&#30446;&#26631;&#22495;&#26631;&#35760;&#26679;&#26412;&#30340;&#37325;&#26500;&#21644;&#22312;&#21407;&#23376;&#20998;&#24067;&#19978;&#23398;&#20064;&#30340;&#20998;&#31867;&#22120;&#30340;&#38598;&#25104;&#12290;&#22312;&#22810;&#20010;&#22522;&#20934;&#27979;&#35797;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#20998;&#31867;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#35299;&#20915;&#22810;&#28304;&#22495;&#33258;&#36866;&#24212;&#65288;MSDA&#65289;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#26088;&#22312;&#22312;&#20174;&#22810;&#20010;&#26631;&#35760;&#30340;&#28304;&#22495;&#36716;&#31227;&#30693;&#35782;&#21040;&#26410;&#26631;&#35760;&#30340;&#30446;&#26631;&#22495;&#26102;&#32531;&#35299;&#25968;&#25454;&#20998;&#24067;&#20559;&#31227;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23383;&#20856;&#23398;&#20064;&#21644;&#26368;&#20248;&#20256;&#36755;&#30340;&#26032;&#22411;MSDA&#26694;&#26550;&#12290;&#25105;&#20204;&#23558;MSDA&#20013;&#30340;&#27599;&#20010;&#22495;&#35299;&#37322;&#20026;&#32463;&#39564;&#20998;&#24067;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#23558;&#27599;&#20010;&#22495;&#34920;&#36798;&#20026;&#23383;&#20856;&#21407;&#23376;&#30340;Wasserstein&#37325;&#24515;&#65292;&#36825;&#20123;&#21407;&#23376;&#26159;&#32463;&#39564;&#20998;&#24067;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36890;&#36807;&#23567;&#25209;&#37327;&#23398;&#20064;&#30340;&#31639;&#27861;DaDiL&#65306;&#65288;i&#65289;&#21407;&#23376;&#20998;&#24067;&#65307;&#65288;ii&#65289;&#37325;&#24515;&#22352;&#26631;&#30697;&#38453;&#12290;&#26681;&#25454;&#25105;&#20204;&#30340;&#23383;&#20856;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;MSDA&#26041;&#27861;&#65306;DaDiL-R&#65292;&#22522;&#20110;&#30446;&#26631;&#22495;&#26631;&#35760;&#26679;&#26412;&#30340;&#37325;&#26500;&#65307;DaDiL-E&#65292;&#22522;&#20110;&#22312;&#21407;&#23376;&#20998;&#24067;&#19978;&#23398;&#20064;&#30340;&#20998;&#31867;&#22120;&#30340;&#38598;&#25104;&#12290;&#25105;&#20204;&#22312;3&#20010;&#22522;&#20934;&#27979;&#35797;&#38598;&#20013;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65306;Caltech-Office&#12289;Office 31&#21644;CRWU&#65292;&#22312;&#20998;&#31867;&#19978;&#25913;&#36827;&#20102;&#20197;&#21069;&#30340;&#26368;&#20808;&#36827;&#25216;&#26415;3.15&#65285;&#12289;2.29&#65285;&#21644;7.71&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper seeks to solve Multi-Source Domain Adaptation (MSDA), which aims to mitigate data distribution shifts when transferring knowledge from multiple labeled source domains to an unlabeled target domain. We propose a novel MSDA framework based on dictionary learning and optimal transport. We interpret each domain in MSDA as an empirical distribution. As such, we express each domain as a Wasserstein barycenter of dictionary atoms, which are empirical distributions. We propose a novel algorithm, DaDiL, for learning via mini-batches: (i) atom distributions; (ii) a matrix of barycentric coordinates. Based on our dictionary, we propose two novel methods for MSDA: DaDil-R, based on the reconstruction of labeled samples in the target domain, and DaDiL-E, based on the ensembling of classifiers learned on atom distributions. We evaluate our methods in 3 benchmarks: Caltech-Office, Office 31, and CRWU, where we improved previous state-of-the-art by 3.15%, 2.29%, and 7.71% in classification 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26680;&#21270;&#24402;&#19968;&#21270;&#27969;&#33539;&#24335;&#65292;&#31216;&#20026;Ferumal&#27969;&#65292;&#23427;&#23558;&#26680;&#20989;&#25968;&#38598;&#25104;&#21040;&#24402;&#19968;&#21270;&#27969;&#30340;&#26694;&#26550;&#20013;&#12290;&#30456;&#23545;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#27969;&#65292;&#26680;&#21270;&#27969;&#21487;&#20197;&#22312;&#20302;&#25968;&#25454;&#29615;&#22659;&#20013;&#20135;&#29983;&#31454;&#20105;&#21147;&#25110;&#20248;&#36234;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#20445;&#25345;&#21442;&#25968;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2307.14839</link><description>&lt;p&gt;
&#26680;&#21270;&#24402;&#19968;&#21270;&#27969;
&lt;/p&gt;
&lt;p&gt;
Kernelised Normalising Flows. (arXiv:2307.14839v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14839
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26680;&#21270;&#24402;&#19968;&#21270;&#27969;&#33539;&#24335;&#65292;&#31216;&#20026;Ferumal&#27969;&#65292;&#23427;&#23558;&#26680;&#20989;&#25968;&#38598;&#25104;&#21040;&#24402;&#19968;&#21270;&#27969;&#30340;&#26694;&#26550;&#20013;&#12290;&#30456;&#23545;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#27969;&#65292;&#26680;&#21270;&#27969;&#21487;&#20197;&#22312;&#20302;&#25968;&#25454;&#29615;&#22659;&#20013;&#20135;&#29983;&#31454;&#20105;&#21147;&#25110;&#20248;&#36234;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#20445;&#25345;&#21442;&#25968;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24402;&#19968;&#21270;&#27969;&#26159;&#20197;&#20854;&#21487;&#36870;&#30340;&#26550;&#26500;&#32780;&#34987;&#25551;&#36848;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#21487;&#36870;&#24615;&#35201;&#27714;&#23545;&#20854;&#34920;&#36798;&#33021;&#21147;&#26045;&#21152;&#38480;&#21046;&#65292;&#38656;&#35201;&#22823;&#37327;&#30340;&#21442;&#25968;&#21644;&#21019;&#26032;&#30340;&#26550;&#26500;&#35774;&#35745;&#26469;&#36798;&#21040;&#28385;&#24847;&#30340;&#32467;&#26524;&#12290;&#34429;&#28982;&#22522;&#20110;&#27969;&#30340;&#27169;&#22411;&#20027;&#35201;&#20381;&#36182;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#36716;&#25442;&#26469;&#23454;&#29616;&#34920;&#36798;&#33021;&#21147;&#65292;&#20294;&#26367;&#20195;&#30340;&#36716;&#25442;&#26041;&#27861;&#21364;&#21463;&#21040;&#20102;&#26377;&#38480;&#30340;&#20851;&#27880;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26680;&#21270;&#24402;&#19968;&#21270;&#27969;&#33539;&#24335;&#65292;&#31216;&#20026;Ferumal&#27969;&#65292;&#23427;&#23558;&#26680;&#20989;&#25968;&#38598;&#25104;&#21040;&#26694;&#26550;&#20013;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#27604;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#27969;&#65292;&#26680;&#21270;&#27969;&#21487;&#20197;&#20135;&#29983;&#26377;&#31454;&#20105;&#21147;&#25110;&#20248;&#36234;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#20445;&#25345;&#21442;&#25968;&#25928;&#29575;&#12290;&#26680;&#21270;&#27969;&#22312;&#20302;&#25968;&#25454;&#29615;&#22659;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#21487;&#20197;&#22312;&#25968;&#25454;&#31232;&#32570;&#30340;&#24212;&#29992;&#20013;&#36827;&#34892;&#28789;&#27963;&#30340;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Normalising Flows are generative models characterised by their invertible architecture. However, the requirement of invertibility imposes constraints on their expressiveness, necessitating a large number of parameters and innovative architectural designs to achieve satisfactory outcomes. Whilst flow-based models predominantly rely on neural-network-based transformations for expressive designs, alternative transformation methods have received limited attention. In this work, we present Ferumal flow, a novel kernelised normalising flow paradigm that integrates kernels into the framework. Our results demonstrate that a kernelised flow can yield competitive or superior results compared to neural network-based flows whilst maintaining parameter efficiency. Kernelised flows excel especially in the low-data regime, enabling flexible non-parametric density estimation in applications with sparse data availability.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20351;&#29992;&#38543;&#26426;&#28909;&#21147;&#23398;&#26041;&#27861;&#65292;&#26681;&#25454;&#26435;&#37325;&#20998;&#24067;&#38388;&#30340;Wasserstein-2&#36317;&#31163;&#21644;&#29109;&#20135;&#29983;&#36895;&#29575;&#65292;&#25552;&#20379;&#20102;&#23545;&#28145;&#24230;&#23398;&#20064;&#32593;&#32476;&#20174;&#21021;&#22987;&#29366;&#24577;&#21040;&#23436;&#20840;&#35757;&#32451;&#30340;&#26368;&#22823;&#36895;&#24230;&#38480;&#21046;&#12290;&#36890;&#36807;&#24212;&#29992;&#20110;&#32447;&#24615;&#21644;&#21487;&#32447;&#24615;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#26576;&#20123;&#32553;&#25918;&#20551;&#35774;&#19979;&#65292;&#23398;&#20064;&#22312;&#26576;&#31181;&#31243;&#24230;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2307.14653</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#36895;&#24230;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
Speed Limits for Deep Learning. (arXiv:2307.14653v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14653
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20351;&#29992;&#38543;&#26426;&#28909;&#21147;&#23398;&#26041;&#27861;&#65292;&#26681;&#25454;&#26435;&#37325;&#20998;&#24067;&#38388;&#30340;Wasserstein-2&#36317;&#31163;&#21644;&#29109;&#20135;&#29983;&#36895;&#29575;&#65292;&#25552;&#20379;&#20102;&#23545;&#28145;&#24230;&#23398;&#20064;&#32593;&#32476;&#20174;&#21021;&#22987;&#29366;&#24577;&#21040;&#23436;&#20840;&#35757;&#32451;&#30340;&#26368;&#22823;&#36895;&#24230;&#38480;&#21046;&#12290;&#36890;&#36807;&#24212;&#29992;&#20110;&#32447;&#24615;&#21644;&#21487;&#32447;&#24615;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#26576;&#20123;&#32553;&#25918;&#20551;&#35774;&#19979;&#65292;&#23398;&#20064;&#22312;&#26576;&#31181;&#31243;&#24230;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#38454;&#27573;&#30340;&#31070;&#32463;&#32593;&#32476;&#38656;&#35201;&#26497;&#22823;&#30340;&#35745;&#31639;&#33021;&#21147;&#25165;&#33021;&#36827;&#34892;&#35757;&#32451;&#12290;&#22240;&#27492;&#24456;&#33258;&#28982;&#22320;&#24819;&#30693;&#36947;&#23427;&#20204;&#26159;&#21542;&#34987;&#26368;&#20248;&#21270;&#22320;&#35757;&#32451;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24212;&#29992;&#20102;&#26368;&#36817;&#22312;&#38543;&#26426;&#28909;&#21147;&#23398;&#20013;&#30340;&#19968;&#20010;&#36827;&#23637;&#65292;&#20801;&#35768;&#26681;&#25454;&#23427;&#20204;&#30340;Wasserstein-2&#36317;&#31163;&#30340;&#27604;&#29575;&#21644;&#36830;&#25509;&#23427;&#20204;&#30340;&#21160;&#24577;&#36807;&#31243;&#30340;&#29109;&#20135;&#29983;&#36895;&#29575;&#65292;&#23545;&#20174;&#21021;&#22987;&#26435;&#37325;&#20998;&#24067;&#21040;&#23436;&#20840;&#35757;&#32451;&#30340;&#32593;&#32476;&#30340;&#26368;&#22823;&#36895;&#24230;&#36827;&#34892;&#30028;&#23450;&#12290;&#32771;&#34385;&#20102;&#26799;&#24230;&#27969;&#21644;Langevin&#35757;&#32451;&#21160;&#21147;&#23398;&#65292;&#25105;&#20204;&#20026;&#32447;&#24615;&#21644;&#21487;&#32447;&#24615;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;&#20363;&#22914;&#31070;&#32463;&#20999;&#21521;&#26680;(NTK)&#65289;&#25552;&#20379;&#20102;&#36825;&#20123;&#36895;&#24230;&#38480;&#21046;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#22914;&#26524;&#23545;NTK&#35889;&#21644;&#26631;&#31614;&#30340;&#35889;&#20998;&#35299;&#20570;&#20986;&#19968;&#20123;&#21512;&#29702;&#30340;&#32553;&#25918;&#20551;&#35774;&#65292;&#23398;&#20064;&#22312;&#26576;&#31181;&#31243;&#24230;&#19978;&#26159;&#26368;&#20248;&#21270;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#19982;&#22312;CIFAR-10&#19978;&#20351;&#29992;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(CNNs)&#21644;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;(FCNs)&#36827;&#34892;&#30340;&#23567;&#35268;&#27169;&#23454;&#39564;&#19968;&#33268;&#65292;&#26174;&#31034;&#20102;
&lt;/p&gt;
&lt;p&gt;
State-of-the-art neural networks require extreme computational power to train. It is therefore natural to wonder whether they are optimally trained. Here we apply a recent advancement in stochastic thermodynamics which allows bounding the speed at which one can go from the initial weight distribution to the final distribution of the fully trained network, based on the ratio of their Wasserstein-2 distance and the entropy production rate of the dynamical process connecting them. Considering both gradient-flow and Langevin training dynamics, we provide analytical expressions for these speed limits for linear and linearizable neural networks e.g. Neural Tangent Kernel (NTK). Remarkably, given some plausible scaling assumptions on the NTK spectra and spectral decomposition of the labels -- learning is optimal in a scaling sense. Our results are consistent with small-scale experiments with Convolutional Neural Networks (CNNs) and Fully Connected Neural networks (FCNs) on CIFAR-10, showing a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#24102;&#26377;&#25511;&#21046;&#21464;&#37327;&#30340;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#22312;&#23436;&#32654;&#21464;&#20998;&#26063;&#35268;&#33539;&#19979;&#20197;&#20960;&#20309;&#36895;&#24230;&#25910;&#25947;&#65292;&#20026;BBVI&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#23545;&#29109;&#26799;&#24230;&#20272;&#35745;&#22120;&#30340;&#25913;&#36827;&#65292;&#23545;&#27604;&#20102;STL&#20272;&#35745;&#22120;&#65292;&#24182;&#32473;&#20986;&#20102;&#26126;&#30830;&#30340;&#38750;&#28176;&#36817;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2307.14642</link><description>&lt;p&gt;
&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#30340;&#32447;&#24615;&#25910;&#25947;&#24615;&#65306;&#25105;&#20204;&#24212;&#35813;&#22362;&#25345;&#21040;&#24213;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Linear Convergence of Black-Box Variational Inference: Should We Stick the Landing?. (arXiv:2307.14642v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14642
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#24102;&#26377;&#25511;&#21046;&#21464;&#37327;&#30340;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#22312;&#23436;&#32654;&#21464;&#20998;&#26063;&#35268;&#33539;&#19979;&#20197;&#20960;&#20309;&#36895;&#24230;&#25910;&#25947;&#65292;&#20026;BBVI&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#23545;&#29109;&#26799;&#24230;&#20272;&#35745;&#22120;&#30340;&#25913;&#36827;&#65292;&#23545;&#27604;&#20102;STL&#20272;&#35745;&#22120;&#65292;&#24182;&#32473;&#20986;&#20102;&#26126;&#30830;&#30340;&#38750;&#28176;&#36817;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#24102;&#26377;&#25511;&#21046;&#21464;&#37327;&#30340;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#65288;BBVI&#65289;&#65292;&#29305;&#21035;&#26159;&#30528;&#38470;&#31283;&#23450;&#65288;STL&#65289;&#20272;&#35745;&#22120;&#65292;&#22312;&#23436;&#32654;&#21464;&#20998;&#26063;&#35268;&#33539;&#19979;&#25910;&#25947;&#20110;&#20960;&#20309;&#65288;&#20256;&#32479;&#19978;&#31216;&#20026;&#8220;&#32447;&#24615;&#8221;&#65289;&#36895;&#24230;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;STL&#20272;&#35745;&#22120;&#30340;&#26799;&#24230;&#26041;&#24046;&#30340;&#20108;&#27425;&#30028;&#38480;&#65292;&#35813;&#30028;&#38480;&#21253;&#25324;&#20102;&#35823;&#25351;&#23450;&#30340;&#21464;&#20998;&#26063;&#12290;&#32467;&#21512;&#20808;&#21069;&#20851;&#20110;&#20108;&#27425;&#26041;&#24046;&#26465;&#20214;&#30340;&#24037;&#20316;&#65292;&#36825;&#30452;&#25509;&#26263;&#31034;&#20102;&#22312;&#20351;&#29992;&#25237;&#24433;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#24773;&#20917;&#19979;BBVI&#30340;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#36824;&#25913;&#36827;&#20102;&#29616;&#26377;&#23545;&#20110;&#27491;&#24120;&#23553;&#38381;&#24418;&#24335;&#29109;&#26799;&#24230;&#20272;&#35745;&#22120;&#30340;&#20998;&#26512;&#65292;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#23558;&#20854;&#19982;STL&#20272;&#35745;&#22120;&#36827;&#34892;&#27604;&#36739;&#65292;&#24182;&#20026;&#20004;&#32773;&#25552;&#20379;&#26126;&#30830;&#30340;&#38750;&#28176;&#36827;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We prove that black-box variational inference (BBVI) with control variates, particularly the sticking-the-landing (STL) estimator, converges at a geometric (traditionally called "linear") rate under perfect variational family specification. In particular, we prove a quadratic bound on the gradient variance of the STL estimator, one which encompasses misspecified variational families. Combined with previous works on the quadratic variance condition, this directly implies convergence of BBVI with the use of projected stochastic gradient descent. We also improve existing analysis on the regular closed-form entropy gradient estimators, which enables comparison against the STL estimator and provides explicit non-asymptotic complexity guarantees for both.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#30740;&#31350;&#20102;&#22312;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#20013;&#27169;&#20223;&#22797;&#26434;&#19987;&#23478;&#28436;&#31034;&#30340;&#34892;&#20026;&#12290;&#36890;&#36807;&#31283;&#23450;&#27169;&#20223;&#31574;&#30053;&#24182;&#30830;&#20445;&#20934;&#30830;&#20272;&#35745;&#28436;&#31034;&#32773;&#20998;&#24067;&#65292;&#21487;&#20197;&#20351;&#27169;&#20223;&#32773;&#19982;&#28436;&#31034;&#32773;&#30340;&#36712;&#36857;&#20998;&#24067;&#30456;&#36817;&#12290;</title><link>http://arxiv.org/abs/2307.14619</link><description>&lt;p&gt;
&#27169;&#20223;&#22797;&#26434;&#36712;&#36857;&#65306;&#26725;&#25509;&#20302;&#23618;&#31283;&#23450;&#24615;&#19982;&#39640;&#23618;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Imitating Complex Trajectories: Bridging Low-Level Stability and High-Level Behavior. (arXiv:2307.14619v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14619
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#30740;&#31350;&#20102;&#22312;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#20013;&#27169;&#20223;&#22797;&#26434;&#19987;&#23478;&#28436;&#31034;&#30340;&#34892;&#20026;&#12290;&#36890;&#36807;&#31283;&#23450;&#27169;&#20223;&#31574;&#30053;&#24182;&#30830;&#20445;&#20934;&#30830;&#20272;&#35745;&#28436;&#31034;&#32773;&#20998;&#24067;&#65292;&#21487;&#20197;&#20351;&#27169;&#20223;&#32773;&#19982;&#28436;&#31034;&#32773;&#30340;&#36712;&#36857;&#20998;&#24067;&#30456;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#30740;&#31350;&#22312;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#20013;&#27169;&#20223;&#38543;&#26426;&#12289;&#38750;&#39532;&#23572;&#21487;&#22827;&#12289;&#28508;&#22312;&#22810;&#27169;&#24577;&#65288;&#21363;&#8220;&#22797;&#26434;&#8221;&#65289;&#19987;&#23478;&#28436;&#31034;&#30340;&#34892;&#20026;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#20351;&#29992;&#20302;&#23618;&#25511;&#21046;&#22120;&#65288;&#26080;&#35770;&#26159;&#23398;&#20064;&#30340;&#36824;&#26159;&#38544;&#21547;&#30340;&#65289;&#26469;&#31283;&#23450;&#22260;&#32469;&#19987;&#23478;&#28436;&#31034;&#30340;&#27169;&#20223;&#31574;&#30053;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#65288;a&#65289;&#21512;&#36866;&#30340;&#20302;&#23618;&#31283;&#23450;&#24615;&#20445;&#35777;&#21644;&#65288;b&#65289;&#23398;&#20064;&#31574;&#30053;&#30340;&#38543;&#26426;&#36830;&#32493;&#24615;&#23646;&#24615;&#65288;&#25105;&#20204;&#31216;&#20043;&#20026;&#8220;&#24635;&#21464;&#24046;&#36830;&#32493;&#24615;&#8221;&#65289;&#65288;TVC&#65289;&#30340;&#24773;&#20917;&#19979;&#65292;&#19968;&#20010;&#31934;&#30830;&#20272;&#35745;&#28436;&#31034;&#32773;&#29366;&#24577;&#20998;&#24067;&#19978;&#30340;&#34892;&#21160;&#30340;&#27169;&#20223;&#32773;&#20250;&#19982;&#28436;&#31034;&#32773;&#23545;&#25972;&#20010;&#36712;&#36857;&#30340;&#20998;&#24067;&#30456;&#36817;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#21487;&#20197;&#36890;&#36807;&#23558;&#27969;&#34892;&#30340;&#25968;&#25454;&#22686;&#24378;&#35268;&#21017;&#19982;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#25216;&#24039;&#30456;&#32467;&#21512;&#65288;&#21363;&#22312;&#25191;&#34892;&#26102;&#28155;&#21152;&#22686;&#24378;&#22122;&#22768;&#65289;&#26469;&#30830;&#20445;TVC&#24182;&#19988;&#26368;&#23567;&#31243;&#24230;&#19978;&#38477;&#20302;&#31934;&#24230;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#20445;&#35777;&#23454;&#20363;&#21270;&#20026;&#30001;&#25193;&#25955;&#27169;&#22411;&#21442;&#25968;&#21270;&#30340;&#31574;&#30053;&#65292;&#24182;&#35777;&#26126;&#22914;&#26524;&#23398;&#20064;&#32773;&#20934;&#30830;&#22320;&#20272;&#35745;&#20102;&#28436;&#31034;&#32773;&#30340;&#20998;&#24067;&#65292;&#21017;&#26368;&#32456;&#23436;&#25104;&#36825;&#31181;&#23454;&#20363;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a theoretical framework for studying the imitation of stochastic, non-Markovian, potentially multi-modal (i.e. "complex" ) expert demonstrations in nonlinear dynamical systems. Our framework invokes low-level controllers either learned or implicit in position-command control - to stabilize imitation policies around expert demonstrations. We show that with (a) a suitable low-level stability guarantee and (b) a stochastic continuity property of the learned policy we call "total variation continuity" (TVC), an imitator that accurately estimates actions on the demonstrator's state distribution closely matches the demonstrator's distribution over entire trajectories. We then show that TVC can be ensured with minimal degradation of accuracy by combining a popular data-augmentation regimen with a novel algorithmic trick: adding augmentation noise at execution time. We instantiate our guarantees for policies parameterized by diffusion models and prove that if the learner accuratel
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#37325;&#21472;&#31038;&#21306;&#26816;&#27979;&#38382;&#39064;&#65292;&#22312;&#28151;&#21512;&#25104;&#21592;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20272;&#35745;&#22120;&#65292;&#24182;&#24314;&#31435;&#20102;&#20272;&#35745;&#35823;&#24046;&#30340;&#26497;&#23567;&#19979;&#30028;&#12290;</title><link>http://arxiv.org/abs/2307.14530</link><description>&lt;p&gt;
&#28151;&#21512;&#25104;&#21592;&#38543;&#26426;&#22359;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Optimal Estimation in Mixed-Membership Stochastic Block Models. (arXiv:2307.14530v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#37325;&#21472;&#31038;&#21306;&#26816;&#27979;&#38382;&#39064;&#65292;&#22312;&#28151;&#21512;&#25104;&#21592;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20272;&#35745;&#22120;&#65292;&#24182;&#24314;&#31435;&#20102;&#20272;&#35745;&#35823;&#24046;&#30340;&#26497;&#23567;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#21306;&#26816;&#27979;&#26159;&#29616;&#20195;&#32593;&#32476;&#31185;&#23398;&#20013;&#26368;&#20851;&#38190;&#30340;&#38382;&#39064;&#20043;&#19968;&#12290;&#20854;&#24212;&#29992;&#21487;&#20197;&#22312;&#21508;&#20010;&#39046;&#22495;&#25214;&#21040;&#65292;&#20174;&#34507;&#30333;&#36136;&#24314;&#27169;&#21040;&#31038;&#20132;&#32593;&#32476;&#20998;&#26512;&#12290;&#26368;&#36817;&#65292;&#20986;&#29616;&#20102;&#35768;&#22810;&#35770;&#25991;&#30740;&#31350;&#37325;&#21472;&#31038;&#21306;&#26816;&#27979;&#38382;&#39064;&#65292;&#21363;&#32593;&#32476;&#20013;&#30340;&#27599;&#20010;&#33410;&#28857;&#21487;&#33021;&#23646;&#20110;&#22810;&#20010;&#31038;&#21306;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#30001;Airoldi&#31561;&#20154;&#65288;2008&#65289;&#39318;&#27425;&#25552;&#20986;&#30340;&#28151;&#21512;&#25104;&#21592;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;MMSB&#65289;&#12290;MMSB&#22312;&#22270;&#20013;&#23545;&#37325;&#21472;&#31038;&#21306;&#32467;&#26500;&#25552;&#20379;&#20102;&#30456;&#24403;&#19968;&#33324;&#30340;&#35774;&#32622;&#12290;&#26412;&#25991;&#30340;&#26680;&#24515;&#38382;&#39064;&#26159;&#22312;&#35266;&#23519;&#21040;&#30340;&#32593;&#32476;&#20013;&#37325;&#24314;&#31038;&#21306;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#19981;&#21516;&#30340;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#20272;&#35745;&#35823;&#24046;&#30340;&#26497;&#23567;&#19979;&#30028;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#19982;&#36825;&#20010;&#19979;&#30028;&#21305;&#37197;&#30340;&#26032;&#20272;&#35745;&#22120;&#12290;&#29702;&#35770;&#32467;&#26524;&#22312;&#23545;&#25152;&#32771;&#34385;&#30340;&#27169;&#22411;&#30340;&#30456;&#24403;&#26222;&#36941;&#26465;&#20214;&#19979;&#24471;&#21040;&#35777;&#26126;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#31995;&#21015;&#23454;&#39564;&#26469;&#35828;&#26126;&#36825;&#20010;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Community detection is one of the most critical problems in modern network science. Its applications can be found in various fields, from protein modeling to social network analysis. Recently, many papers appeared studying the problem of overlapping community detection, where each node of a network may belong to several communities. In this work, we consider Mixed-Membership Stochastic Block Model (MMSB) first proposed by Airoldi et al. (2008). MMSB provides quite a general setting for modeling overlapping community structure in graphs. The central question of this paper is to reconstruct relations between communities given an observed network. We compare different approaches and establish the minimax lower bound on the estimation error. Then, we propose a new estimator that matches this lower bound. Theoretical results are proved under fairly general conditions on the considered model. Finally, we illustrate the theory in a series of experiments.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#22312;&#23384;&#22312;&#27169;&#22411;EMA&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20248;&#21270;&#30340;&#32553;&#25918;&#35268;&#21017;&#65292;&#20197;&#20445;&#25345;&#35757;&#32451;&#21160;&#24577;&#30340;&#19968;&#33268;&#24615;&#12290;&#36825;&#23545;&#20110;&#23454;&#38469;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#26435;&#34913;&#25209;&#37327;&#22823;&#23567;&#21644;&#22681;&#38047;&#26102;&#38388;&#38750;&#24120;&#37325;&#35201;&#12290;&#27169;&#22411;EMA&#33021;&#22815;&#25552;&#39640;&#27169;&#22411;&#30340;&#24615;&#33021;&#20197;&#21450;&#31283;&#23450;&#35757;&#32451;&#36807;&#31243;&#65292;&#24182;&#20026;&#33258;&#30417;&#30563;&#23398;&#20064;&#25552;&#20379;&#23398;&#20064;&#20449;&#21495;&#12290;</title><link>http://arxiv.org/abs/2307.13813</link><description>&lt;p&gt;
&#22914;&#20309;&#25193;&#23637;&#24744;&#30340;EMA&#65288;arXiv:2307.13813v1 [stat.ML]&#65289;
&lt;/p&gt;
&lt;p&gt;
How to Scale Your EMA. (arXiv:2307.13813v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13813
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#22312;&#23384;&#22312;&#27169;&#22411;EMA&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20248;&#21270;&#30340;&#32553;&#25918;&#35268;&#21017;&#65292;&#20197;&#20445;&#25345;&#35757;&#32451;&#21160;&#24577;&#30340;&#19968;&#33268;&#24615;&#12290;&#36825;&#23545;&#20110;&#23454;&#38469;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#26435;&#34913;&#25209;&#37327;&#22823;&#23567;&#21644;&#22681;&#38047;&#26102;&#38388;&#38750;&#24120;&#37325;&#35201;&#12290;&#27169;&#22411;EMA&#33021;&#22815;&#25552;&#39640;&#27169;&#22411;&#30340;&#24615;&#33021;&#20197;&#21450;&#31283;&#23450;&#35757;&#32451;&#36807;&#31243;&#65292;&#24182;&#20026;&#33258;&#30417;&#30563;&#23398;&#20064;&#25552;&#20379;&#23398;&#20064;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#20445;&#25345;&#35757;&#32451;&#21160;&#24577;&#22312;&#25209;&#37327;&#22823;&#23567;&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#26159;&#19968;&#31181;&#37325;&#35201;&#24037;&#20855;&#65292;&#23427;&#33021;&#22815;&#22312;&#25209;&#37327;&#22823;&#23567;&#21644;&#22681;&#38047;&#26102;&#38388;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#12290;&#36825;&#31181;&#26435;&#34913;&#36890;&#24120;&#36890;&#36807;&#19968;&#20010;&#32553;&#25918;&#35268;&#21017;&#26469;&#23454;&#29616;&#65292;&#20363;&#22914;&#65292;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#65292;&#24212;&#35813;&#23558;&#23398;&#20064;&#29575;&#19982;&#25209;&#37327;&#22823;&#23567;&#21576;&#32447;&#24615;&#20851;&#31995;&#12290;&#21478;&#19968;&#20010;&#23454;&#38469;&#26426;&#22120;&#23398;&#20064;&#30340;&#37325;&#35201;&#24037;&#20855;&#26159;&#27169;&#22411;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#65288;EMA&#65289;&#65292;&#23427;&#26159;&#19968;&#20010;&#19981;&#25509;&#25910;&#26799;&#24230;&#20449;&#24687;&#30340;&#27169;&#22411;&#21103;&#26412;&#65292;&#32780;&#26159;&#20197;&#19968;&#23450;&#30340;&#21160;&#37327;&#36319;&#38543;&#20854;&#30446;&#26631;&#27169;&#22411;&#12290;&#36825;&#20010;&#27169;&#22411;EMA&#21487;&#20197;&#25552;&#39640;&#30417;&#30563;&#23398;&#20064;&#30340;&#31283;&#20581;&#24615;&#21644;&#27867;&#21270;&#24615;&#33021;&#65292;&#31283;&#23450;&#20266;&#26631;&#35760;&#65292;&#20026;&#33258;&#30417;&#30563;&#23398;&#20064;&#25552;&#20379;&#23398;&#20064;&#20449;&#21495;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#23558;&#27169;&#22411;EMA&#19982;&#20248;&#21270;&#20998;&#24320;&#22788;&#29702;&#65292;&#23548;&#33268;&#25209;&#37327;&#22823;&#23567;&#20043;&#38388;&#23384;&#22312;&#19981;&#21516;&#30340;&#35757;&#32451;&#21160;&#24577;&#21644;&#36739;&#20302;&#30340;&#27169;&#22411;&#24615;&#33021;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#22312;&#23384;&#22312;&#27169;&#22411;EMA&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20248;&#21270;&#30340;&#32553;&#25918;&#35268;&#21017;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Preserving training dynamics across batch sizes is an important tool for practical machine learning as it enables the trade-off between batch size and wall-clock time. This trade-off is typically enabled by a scaling rule, for example, in stochastic gradient descent, one should scale the learning rate linearly with the batch size. Another important tool for practical machine learning is the model Exponential Moving Average (EMA), which is a model copy that does not receive gradient information, but instead follows its target model with some momentum. This model EMA can improve the robustness and generalization properties of supervised learning, stabilize pseudo-labeling, and provide a learning signal for Self-Supervised Learning (SSL). Prior works have treated the model EMA separately from optimization, leading to different training dynamics across batch sizes and lower model performance. In this work, we provide a scaling rule for optimization in the presence of model EMAs and demonst
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#24402;&#19968;&#21270;&#22788;&#29702;&#65292;&#23454;&#29616;&#20132;&#36890;&#39044;&#27979;&#27169;&#22411;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#26356;&#39640;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.05946</link><description>&lt;p&gt;
&#19968;&#31181;&#36125;&#21494;&#26031;&#26041;&#27861;&#29992;&#20110;&#37327;&#21270;&#20132;&#36890;&#39044;&#27979;&#27169;&#22411;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#25913;&#21892;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
A Bayesian approach to quantifying uncertainties and improving generalizability in traffic prediction models. (arXiv:2307.05946v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05946
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#24402;&#19968;&#21270;&#22788;&#29702;&#65292;&#23454;&#29616;&#20132;&#36890;&#39044;&#27979;&#27169;&#22411;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#26356;&#39640;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20132;&#36890;&#25968;&#25454;&#39044;&#27979;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#22810;&#23618;&#26550;&#26500;&#23545;&#22797;&#26434;&#20989;&#25968;&#36827;&#34892;&#20248;&#21270;&#24314;&#27169;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#30340;&#19968;&#20010;&#20027;&#35201;&#32570;&#28857;&#26159;&#22823;&#22810;&#25968;&#26041;&#27861;&#19981;&#25552;&#20379;&#24102;&#26377;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#39044;&#27979;&#32467;&#26524;&#65292;&#32780;&#36825;&#23545;&#20110;&#20132;&#36890;&#36816;&#33829;&#21644;&#25511;&#21046;&#26159;&#24517;&#38656;&#30340;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#35889;&#24402;&#19968;&#21270;&#21040;&#20854;&#38544;&#34255;&#23618;&#65292;&#23454;&#29616;&#20132;&#36890;&#39044;&#27979;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#26356;&#39640;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#35770;&#25991;&#34920;&#26126;&#65292;&#24402;&#19968;&#21270;&#36890;&#36807;&#25511;&#21046;&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#24182;&#20943;&#23569;&#23545;&#35757;&#32451;&#25968;&#25454;&#30340;&#36807;&#24230;&#25311;&#21512;&#39118;&#38505;&#65292;&#25913;&#21892;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep-learning models for traffic data prediction can have superior performance in modeling complex functions using a multi-layer architecture. However, a major drawback of these approaches is that most of these approaches do not offer forecasts with uncertainty estimates, which are essential for traffic operations and control. Without uncertainty estimates, it is difficult to place any level of trust to the model predictions, and operational strategies relying on overconfident predictions can lead to worsening traffic conditions. In this study, we propose a Bayesian recurrent neural network framework for uncertainty quantification in traffic prediction with higher generalizability by introducing spectral normalization to its hidden layers. In our paper, we have shown that normalization alters the training process of deep neural networks by controlling the model's complexity and reducing the risk of overfitting to the training data. This, in turn, helps improve the generalization perfor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22522;&#20110;&#33258;&#23450;&#20041;&#28151;&#21512;&#33410;&#28857; Forney &#26679;&#24335;&#30340;&#22240;&#23376;&#22270;&#28040;&#24687;&#20256;&#36882;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#33258;&#21160;&#21270;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#12289;&#36873;&#25321;&#21644;&#32452;&#21512;&#65292;&#24182;&#32553;&#30701;&#20102;&#27169;&#22411;&#35774;&#35745;&#21608;&#26399;&#12290;</title><link>http://arxiv.org/abs/2306.05965</link><description>&lt;p&gt;
&#22312;&#22240;&#23376;&#22270;&#20013;&#33258;&#21160;&#36827;&#34892;&#27169;&#22411;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Automating Model Comparison in Factor Graphs. (arXiv:2306.05965v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05965
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22522;&#20110;&#33258;&#23450;&#20041;&#28151;&#21512;&#33410;&#28857; Forney &#26679;&#24335;&#30340;&#22240;&#23376;&#22270;&#28040;&#24687;&#20256;&#36882;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#33258;&#21160;&#21270;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#12289;&#36873;&#25321;&#21644;&#32452;&#21512;&#65292;&#24182;&#32553;&#30701;&#20102;&#27169;&#22411;&#35774;&#35745;&#21608;&#26399;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25991;&#29486;&#20013;&#65292;&#36125;&#21494;&#26031;&#29366;&#24577;&#21644;&#21442;&#25968;&#20272;&#35745;&#24050;&#32463;&#34987;&#26377;&#25928;&#33258;&#21160;&#21270;&#65292;&#20294;&#23545;&#20110;&#27169;&#22411;&#27604;&#36739;&#23578;&#26410;&#22914;&#27492;&#65292;&#22240;&#27492;&#20173;&#38656;&#35201;&#23481;&#26131;&#20986;&#38169;&#21644;&#32791;&#26102;&#30340;&#25163;&#21160;&#25512;&#23548;&#12290;&#22240;&#27492;&#65292;&#27169;&#22411;&#27604;&#36739;&#32463;&#24120;&#34987;&#24573;&#35270;&#21644;&#24573;&#30053;&#65292;&#23613;&#31649;&#23427;&#24456;&#37325;&#35201;&#12290;&#26412;&#25991;&#36890;&#36807;&#22312;Forney&#26679;&#24335;&#30340;&#22240;&#23376;&#22270;&#19978;&#20351;&#29992;&#33258;&#23450;&#20041;&#28151;&#21512;&#33410;&#28857;&#19978;&#30340;&#28040;&#24687;&#20256;&#36882;&#26469;&#39640;&#25928;&#22320;&#33258;&#21160;&#21270;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#12289;&#36873;&#25321;&#21644;&#32452;&#21512;&#12290;&#36827;&#32780;&#21487;&#20351;&#29992;&#32553;&#25918;&#22240;&#23376;&#21516;&#26102;&#25191;&#34892;&#21442;&#25968;&#21644;&#29366;&#24577;&#25512;&#26029;&#20197;&#21450;&#27169;&#22411;&#27604;&#36739;&#12290;&#36825;&#31181;&#26041;&#27861;&#32553;&#30701;&#20102;&#27169;&#22411;&#35774;&#35745;&#21608;&#26399;&#65292;&#21516;&#26102;&#20801;&#35768;&#31616;&#21333;&#22320;&#25193;&#23637;&#21040;&#20998;&#23618;&#21644;&#26102;&#38388;&#27169;&#22411;&#20808;&#39564;&#65292;&#20197;&#36866;&#24212;&#24314;&#27169;&#22797;&#26434;&#30340;&#26102;&#21464;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian state and parameter estimation have been automated effectively in the literature, however, this has not yet been the case for model comparison, which therefore still requires error-prone and time-consuming manual derivations. As a result, model comparison is often overlooked and ignored, despite its importance. This paper efficiently automates Bayesian model averaging, selection, and combination by message passing on a Forney-style factor graph with a custom mixture node. Parameter and state inference, and model comparison can then be executed simultaneously using message passing with scale factors. This approach shortens the model design cycle and allows for the straightforward extension to hierarchical and temporal model priors to accommodate for modeling complicated time-varying processes.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#24555;&#36895;&#12289;&#39640;&#25928;&#25311;&#21512;&#27010;&#29575;&#27874;-&#20271;&#21162;&#21033;&#28508;&#22312;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#27169;&#22411;&#30340;&#35889;&#23398;&#20064;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#36890;&#36807;&#36716;&#25442;&#26679;&#26412;&#30697;&#30340;&#26041;&#24335;&#23558;&#20256;&#32479;&#30340;&#23376;&#31354;&#38388;&#35782;&#21035;&#26041;&#27861;&#25193;&#23637;&#21040;&#20102;&#20271;&#21162;&#21033;&#35774;&#32622;&#20013;&#65292;&#24471;&#21040;&#20102;&#19968;&#20010;&#40065;&#26834;&#30340;&#22266;&#23450;&#25104;&#26412;&#20272;&#35745;&#22120;&#12290;&#22312;&#25968;&#25454;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#65292;&#35889;&#20272;&#35745;&#21487;&#20197;&#20026;Laplace-EM&#25311;&#21512;&#25552;&#20379;&#33391;&#22909;&#30340;&#21021;&#22987;&#21270;&#12290;</title><link>http://arxiv.org/abs/2303.02060</link><description>&lt;p&gt;
Bernoulli&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#27169;&#22411;&#30340;&#35889;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Spectral learning of Bernoulli linear dynamical systems models. (arXiv:2303.02060v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.02060
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#24555;&#36895;&#12289;&#39640;&#25928;&#25311;&#21512;&#27010;&#29575;&#27874;-&#20271;&#21162;&#21033;&#28508;&#22312;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#27169;&#22411;&#30340;&#35889;&#23398;&#20064;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#36890;&#36807;&#36716;&#25442;&#26679;&#26412;&#30697;&#30340;&#26041;&#24335;&#23558;&#20256;&#32479;&#30340;&#23376;&#31354;&#38388;&#35782;&#21035;&#26041;&#27861;&#25193;&#23637;&#21040;&#20102;&#20271;&#21162;&#21033;&#35774;&#32622;&#20013;&#65292;&#24471;&#21040;&#20102;&#19968;&#20010;&#40065;&#26834;&#30340;&#22266;&#23450;&#25104;&#26412;&#20272;&#35745;&#22120;&#12290;&#22312;&#25968;&#25454;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#65292;&#35889;&#20272;&#35745;&#21487;&#20197;&#20026;Laplace-EM&#25311;&#21512;&#25552;&#20379;&#33391;&#22909;&#30340;&#21021;&#22987;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;Bernoulli&#35266;&#27979;&#30340;&#28508;&#22312;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#20026;&#35782;&#21035;&#20108;&#36827;&#21046;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#26102;&#38388;&#21160;&#24577;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#24314;&#27169;&#26694;&#26550;&#65292;&#36825;&#20123;&#25968;&#25454;&#22312;&#20108;&#36827;&#21046;&#20915;&#31574;&#21644;&#31163;&#25955;&#38543;&#26426;&#36807;&#31243;&#65288;&#20363;&#22914;&#31163;&#25955;&#31070;&#32463;&#23574;&#23792;&#35757;&#32451;&#65289;&#31561;&#21508;&#31181;&#24773;&#20917;&#19979;&#20135;&#29983;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#24555;&#36895;&#26377;&#25928;&#30340;&#27010;&#29575;&#27874;/Bernoulli&#28508;&#22312;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#65288;LDS&#65289;&#27169;&#22411;&#30340;&#35889;&#23398;&#20064;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#23545;&#31532;&#19968;&#21644;&#31532;&#20108;&#20010;&#26679;&#26412;&#30697;&#30340;&#36716;&#25442;&#23558;&#20256;&#32479;&#30340;&#23376;&#31354;&#38388;&#35782;&#21035;&#26041;&#27861;&#25193;&#23637;&#21040;Bernoulli&#35774;&#32622;&#20013;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#20010;&#20581;&#22766;&#30340;&#22266;&#23450;&#25104;&#26412;&#20272;&#35745;&#22120;&#65292;&#36991;&#20813;&#20102;&#23616;&#37096;&#26368;&#20248;&#35299;&#30340;&#21361;&#38505;&#20197;&#21450;&#26399;&#26395;&#26368;&#22823;&#21270;&#65288;EM&#65289;&#31639;&#27861;&#31561;&#36845;&#20195;&#25311;&#21512;&#36807;&#31243;&#30340;&#38271;&#26102;&#38388;&#35745;&#31639;&#12290;&#22312;&#25968;&#25454;&#26377;&#38480;&#25110;&#25968;&#25454;&#30340;&#32479;&#35745;&#32467;&#26500;&#19981;&#28385;&#36275;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35889;&#20272;&#35745;&#20026;Laplace-EM&#25311;&#21512;&#25552;&#20379;&#20102;&#33391;&#22909;&#30340;&#21021;&#22987;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Latent linear dynamical systems with Bernoulli observations provide a powerful modeling framework for identifying the temporal dynamics underlying binary time series data, which arise in a variety of contexts such as binary decision-making and discrete stochastic processes (e.g., binned neural spike trains). Here we develop a spectral learning method for fast, efficient fitting of probit-Bernoulli latent linear dynamical system (LDS) models. Our approach extends traditional subspace identification methods to the Bernoulli setting via a transformation of the first and second sample moments. This results in a robust, fixed-cost estimator that avoids the hazards of local optima and the long computation time of iterative fitting procedures like the expectation-maximization (EM) algorithm. In regimes where data is limited or assumptions about the statistical structure of the data are not met, we demonstrate that the spectral estimate provides a good initialization for Laplace-EM fitting. Fi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#31532;&#19968;&#20010;&#33021;&#22815;&#22788;&#29702;&#38142;&#36335;&#39044;&#27979;&#20013;&#36335;&#24452;&#20381;&#36182;&#30340;&#22240;&#26524;&#27169;&#22411;&#65292;&#24182;&#20171;&#32461;&#20102;&#22240;&#26524;&#25552;&#21319;&#30340;&#27010;&#24565;&#65292;&#36890;&#36807;&#26377;&#38480;&#30340;&#24178;&#39044;&#25968;&#25454;&#35782;&#21035;&#22240;&#26524;&#38142;&#36335;&#39044;&#27979;&#26597;&#35810;&#12290;</title><link>http://arxiv.org/abs/2302.01198</link><description>&lt;p&gt;
&#22240;&#26524;&#25552;&#21319;&#19982;&#38142;&#36335;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Causal Lifting and Link Prediction. (arXiv:2302.01198v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.01198
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#31532;&#19968;&#20010;&#33021;&#22815;&#22788;&#29702;&#38142;&#36335;&#39044;&#27979;&#20013;&#36335;&#24452;&#20381;&#36182;&#30340;&#22240;&#26524;&#27169;&#22411;&#65292;&#24182;&#20171;&#32461;&#20102;&#22240;&#26524;&#25552;&#21319;&#30340;&#27010;&#24565;&#65292;&#36890;&#36807;&#26377;&#38480;&#30340;&#24178;&#39044;&#25968;&#25454;&#35782;&#21035;&#22240;&#26524;&#38142;&#36335;&#39044;&#27979;&#26597;&#35810;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#38142;&#36335;&#39044;&#27979;&#22240;&#26524;&#27169;&#22411;&#20551;&#35774;&#23384;&#22312;&#19968;&#32452;&#22266;&#26377;&#30340;&#33410;&#28857;&#22240;&#23376;&#65292;&#21363;&#22312;&#33410;&#28857;&#20986;&#29983;&#26102;&#23601;&#23450;&#20041;&#30340;&#22266;&#26377;&#29305;&#24449;&#65292;&#23427;&#20204;&#25511;&#21046;&#30528;&#22270;&#20013;&#38142;&#36335;&#30340;&#22240;&#26524;&#28436;&#21270;&#12290;&#28982;&#32780;&#65292;&#22312;&#26576;&#20123;&#22240;&#26524;&#20219;&#21153;&#20013;&#65292;&#38142;&#36335;&#24418;&#25104;&#26159;&#36335;&#24452;&#20381;&#36182;&#30340;&#65306;&#38142;&#36335;&#24178;&#39044;&#30340;&#32467;&#26524;&#21462;&#20915;&#20110;&#29616;&#26377;&#30340;&#38142;&#36335;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#20123;&#29616;&#26377;&#30340;&#22240;&#26524;&#26041;&#27861;&#24182;&#19981;&#36866;&#29992;&#20110;&#36335;&#24452;&#20381;&#36182;&#30340;&#38142;&#36335;&#24418;&#25104;&#65292;&#22240;&#20026;&#38142;&#36335;&#20043;&#38388;&#30340;&#32423;&#32852;&#21151;&#33021;&#20381;&#36182;&#65288;&#30001;&#36335;&#24452;&#20381;&#36182;&#24615;&#20135;&#29983;&#65289;&#35201;&#20040;&#26080;&#27861;&#35782;&#21035;&#65292;&#35201;&#20040;&#38656;&#35201;&#22823;&#37327;&#19981;&#20999;&#23454;&#38469;&#30340;&#25511;&#21046;&#21464;&#37327;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#31532;&#19968;&#20010;&#33021;&#22815;&#22788;&#29702;&#38142;&#36335;&#39044;&#27979;&#20013;&#36335;&#24452;&#20381;&#36182;&#30340;&#22240;&#26524;&#27169;&#22411;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22240;&#26524;&#25552;&#21319;&#30340;&#27010;&#24565;&#65292;&#36825;&#26159;&#19968;&#31181;&#29420;&#31435;&#20110;&#22270;&#30340;&#22240;&#26524;&#27169;&#22411;&#30340;&#19981;&#21464;&#24615;&#65292;&#21487;&#20197;&#21033;&#29992;&#26377;&#38480;&#30340;&#24178;&#39044;&#25968;&#25454;&#26469;&#35782;&#21035;&#22240;&#26524;&#38142;&#36335;&#39044;&#27979;&#26597;&#35810;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#32467;&#26500;&#23545;&#20004;&#20010;&#33410;&#28857;&#20043;&#38388;&#23884;&#20837;&#30340;&#20302;&#32500;&#34920;&#31034;&#30340;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing causal models for link prediction assume an underlying set of inherent node factors -- an innate characteristic defined at the node's birth -- that governs the causal evolution of links in the graph. In some causal tasks, however, link formation is path-dependent: The outcome of link interventions depends on existing links. Unfortunately, these existing causal methods are not designed for path-dependent link formation, as the cascading functional dependencies between links (arising from path dependence) are either unidentifiable or require an impractical number of control variables. To overcome this, we develop the first causal model capable of dealing with path dependencies in link prediction. In this work we introduce the concept of causal lifting, an invariance in causal models of independent interest that, on graphs, allows the identification of causal link prediction queries using limited interventional data. Further, we show how structural pairwise embeddings exhibit low
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#29983;&#25104;&#30340;&#25968;&#25454;&#28508;&#22312;&#29305;&#24449;&#34920;&#31034;&#30340;&#30417;&#25511;&#26041;&#27861;&#65292;&#20197;&#30830;&#23450;&#25968;&#25454;&#27969;&#24320;&#22987;&#21464;&#24471;&#38750;&#24179;&#31283;&#30340;&#26102;&#38388;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#24212;&#29992;&#22522;&#20110;&#25968;&#25454;&#28145;&#24230;&#35745;&#31639;&#21644;&#24402;&#19968;&#21270;&#25490;&#21517;&#30340;&#22810;&#20803;&#25511;&#21046;&#22270;&#36827;&#34892;&#30417;&#27979;&#65292;&#24182;&#19982;&#21508;&#31181;&#22522;&#20934;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2209.07436</link><description>&lt;p&gt;
&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#30340;&#32479;&#35745;&#36807;&#31243;&#30417;&#25511;
&lt;/p&gt;
&lt;p&gt;
Statistical process monitoring of artificial neural networks. (arXiv:2209.07436v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.07436
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#29983;&#25104;&#30340;&#25968;&#25454;&#28508;&#22312;&#29305;&#24449;&#34920;&#31034;&#30340;&#30417;&#25511;&#26041;&#27861;&#65292;&#20197;&#30830;&#23450;&#25968;&#25454;&#27969;&#24320;&#22987;&#21464;&#24471;&#38750;&#24179;&#31283;&#30340;&#26102;&#38388;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#24212;&#29992;&#22522;&#20110;&#25968;&#25454;&#28145;&#24230;&#35745;&#31639;&#21644;&#24402;&#19968;&#21270;&#25490;&#21517;&#30340;&#22810;&#20803;&#25511;&#21046;&#22270;&#36827;&#34892;&#30417;&#27979;&#65292;&#24182;&#19982;&#21508;&#31181;&#22522;&#20934;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#27169;&#22411;&#30340;&#24555;&#36895;&#21457;&#23637;&#35201;&#27714;&#21019;&#26032;&#30340;&#30417;&#25511;&#25216;&#26415;&#65292;&#36825;&#20123;&#25216;&#26415;&#21487;&#20197;&#20197;&#20302;&#35745;&#31639;&#25104;&#26412;&#23454;&#26102;&#25805;&#20316;&#12290;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#29305;&#21035;&#26159;&#32771;&#34385;&#21040;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#65288;ANNs&#65289;&#65292;&#27169;&#22411;&#36890;&#24120;&#26159;&#20197;&#30417;&#30563;&#26041;&#24335;&#36827;&#34892;&#35757;&#32451;&#30340;&#12290;&#22240;&#27492;&#65292;&#22312;&#27169;&#22411;&#37096;&#32626;&#26399;&#38388;&#65292;&#36755;&#20837;&#21644;&#36755;&#20986;&#20043;&#38388;&#23398;&#20064;&#21040;&#30340;&#20851;&#31995;&#24517;&#39035;&#20445;&#25345;&#26377;&#25928;&#12290;&#22914;&#26524;&#36825;&#20010;&#24179;&#31283;&#24615;&#20551;&#35774;&#25104;&#31435;&#65292;&#25105;&#20204;&#21487;&#20197;&#24471;&#20986;&#32467;&#35770;&#65292;ANN&#25552;&#20379;&#20934;&#30830;&#30340;&#39044;&#27979;&#12290;&#21542;&#21017;&#65292;&#38656;&#35201;&#37325;&#26032;&#35757;&#32451;&#25110;&#37325;&#24314;&#27169;&#22411;&#12290;&#25105;&#20204;&#24314;&#35758;&#32771;&#34385;&#30001;ANN&#29983;&#25104;&#30340;&#25968;&#25454;&#30340;&#28508;&#22312;&#29305;&#24449;&#34920;&#31034;&#65288;&#31216;&#20026;&#8220;&#23884;&#20837;&#8221;&#65289;&#65292;&#20197;&#30830;&#23450;&#25968;&#25454;&#27969;&#24320;&#22987;&#21464;&#24471;&#38750;&#24179;&#31283;&#30340;&#26102;&#38388;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#24212;&#29992;&#22522;&#20110;&#25968;&#25454;&#28145;&#24230;&#35745;&#31639;&#21644;&#24402;&#19968;&#21270;&#25490;&#21517;&#30340;&#22810;&#20803;&#25511;&#21046;&#22270;&#26469;&#30417;&#27979;&#23884;&#20837;&#12290;&#25105;&#20204;&#23558;&#24341;&#20837;&#30340;&#26041;&#27861;&#19982;&#21508;&#31181;ANN&#22522;&#20934;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
The rapid advancement of models based on artificial intelligence demands innovative monitoring techniques which can operate in real time with low computational costs. In machine learning, especially if we consider artificial neural networks (ANNs), the models are often trained in a supervised manner. Consequently, the learned relationship between the input and the output must remain valid during the model's deployment. If this stationarity assumption holds, we can conclude that the ANN provides accurate predictions. Otherwise, the retraining or rebuilding of the model is required. We propose considering the latent feature representation of the data (called "embedding") generated by the ANN to determine the time when the data stream starts being nonstationary. In particular, we monitor embeddings by applying multivariate control charts based on the data depth calculation and normalized ranks. The performance of the introduced method is compared with benchmark approaches for various ANN 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24555;&#36895;&#12289;&#26080;&#38656;&#20284;&#28982;&#20989;&#25968;&#12289;&#26131;&#20110;&#36827;&#34892;&#22522;&#20110;&#33258;&#20030;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#25512;&#26029;&#24037;&#20855;&#8212;&#8212;&#31070;&#32463;&#28857;&#20272;&#35745;&#22120;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#26696;&#20363;&#20998;&#26512;&#35777;&#26126;&#20854;&#21487;&#20197;&#22312;&#24369;&#35782;&#21035;&#21644;&#39640;&#21442;&#25968;&#21270;&#27169;&#22411;&#20013;&#36827;&#34892;&#24555;&#36895;&#19988;&#26368;&#20248;&#30340;&#21442;&#25968;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2208.12942</link><description>&lt;p&gt;
&#24555;&#36895;&#26368;&#20248;&#26080;&#20284;&#28982;&#25512;&#26029;&#30340;&#31070;&#32463;&#28857;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Neural Point Estimation for Fast Optimal Likelihood-Free Inference. (arXiv:2208.12942v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.12942
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24555;&#36895;&#12289;&#26080;&#38656;&#20284;&#28982;&#20989;&#25968;&#12289;&#26131;&#20110;&#36827;&#34892;&#22522;&#20110;&#33258;&#20030;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#25512;&#26029;&#24037;&#20855;&#8212;&#8212;&#31070;&#32463;&#28857;&#20272;&#35745;&#22120;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#26696;&#20363;&#20998;&#26512;&#35777;&#26126;&#20854;&#21487;&#20197;&#22312;&#24369;&#35782;&#21035;&#21644;&#39640;&#21442;&#25968;&#21270;&#27169;&#22411;&#20013;&#36827;&#34892;&#24555;&#36895;&#19988;&#26368;&#20248;&#30340;&#21442;&#25968;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#28857;&#20272;&#35745;&#22120;&#26159;&#19968;&#31181;&#23558;&#25968;&#25454;&#26144;&#23556;&#21040;&#21442;&#25968;&#28857;&#20272;&#35745;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#23427;&#20204;&#24555;&#36895;&#12289;&#26080;&#38656;&#20284;&#28982;&#20989;&#25968;&#65292;&#24182;&#19988;&#30001;&#20110;&#23427;&#20204;&#30340;&#24179;&#22343;&#29305;&#24615;&#65292;&#26131;&#20110;&#36827;&#34892;&#22522;&#20110;&#33258;&#20030;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#26412;&#25991;&#26088;&#22312;&#25552;&#39640;&#32479;&#35745;&#23398;&#23478;&#23545;&#20110;&#36825;&#31181;&#30456;&#23545;&#36739;&#26032;&#30340;&#25512;&#26029;&#24037;&#20855;&#30340;&#35748;&#35782;&#65292;&#24182;&#36890;&#36807;&#25552;&#20379;&#29992;&#25143;&#21451;&#22909;&#30340;&#24320;&#28304;&#36719;&#20214;&#26469;&#20419;&#36827;&#20854;&#37319;&#29992;&#12290;&#25105;&#20204;&#36824;&#20851;&#27880;&#20102;&#20174;&#37325;&#22797;&#25968;&#25454;&#36827;&#34892;&#25512;&#26029;&#30340;&#24191;&#27867;&#38382;&#39064;&#65292;&#22312;&#31070;&#32463;&#35774;&#32622;&#20013;&#20351;&#29992;&#25490;&#21015;&#19981;&#21464;&#31070;&#32463;&#32593;&#32476;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#31070;&#32463;&#28857;&#20272;&#35745;&#22120;&#21487;&#20197;&#24555;&#36895;&#19988;&#26368;&#20248;&#22320;&#65288;&#20174;&#36125;&#21494;&#26031;&#24847;&#20041;&#19978;&#65289;&#22312;&#24369;&#35782;&#21035;&#21644;&#39640;&#21442;&#25968;&#21270;&#27169;&#22411;&#20013;&#36827;&#34892;&#20272;&#35745;&#65292;&#24182;&#19988;&#30456;&#23545;&#23481;&#26131;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#32418;&#28023;&#26497;&#31471;&#28023;&#34920;&#28201;&#24230;&#20998;&#26512;&#26469;&#35777;&#26126;&#23427;&#20204;&#30340;&#36866;&#29992;&#24615;&#65292;&#22312;&#35757;&#32451;&#20043;&#21518;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#21442;&#25968;&#20272;&#35745;&#21644;&#22522;&#20110;&#33258;&#20030;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural point estimators are neural networks that map data to parameter point estimates. They are fast, likelihood free and, due to their amortised nature, amenable to fast bootstrap-based uncertainty quantification. In this paper, we aim to increase the awareness of statisticians to this relatively new inferential tool, and to facilitate its adoption by providing user-friendly open-source software. We also give attention to the ubiquitous problem of making inference from replicated data, which we address in the neural setting using permutation-invariant neural networks. Through extensive simulation studies we show that these neural point estimators can quickly and optimally (in a Bayes sense) estimate parameters in weakly-identified and highly-parameterised models with relative ease. We demonstrate their applicability through an analysis of extreme sea-surface temperature in the Red Sea where, after training, we obtain parameter estimates and bootstrap-based confidence intervals from h
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#26631;&#37327;&#36755;&#20837;&#21644;&#20989;&#25968;&#36755;&#20986;&#20043;&#38388;&#22238;&#24402;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#20989;&#25968;&#21709;&#24212;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#22823;&#37327;&#39044;&#27979;&#21464;&#37327;&#25110;&#38750;&#32447;&#24615;&#20851;&#31995;&#65292;&#24182;&#21487;&#20197;&#25511;&#21046;&#39044;&#27979;&#26354;&#32447;&#30340;&#24179;&#28369;&#31243;&#24230;&#12290;&#22312;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2208.05776</link><description>&lt;p&gt;
&#26631;&#37327;&#36755;&#20837;&#21644;&#20989;&#25968;&#36755;&#20986;&#30340;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Neural Networks for Scalar Input and Functional Output. (arXiv:2208.05776v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.05776
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#26631;&#37327;&#36755;&#20837;&#21644;&#20989;&#25968;&#36755;&#20986;&#20043;&#38388;&#22238;&#24402;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#20989;&#25968;&#21709;&#24212;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#22823;&#37327;&#39044;&#27979;&#21464;&#37327;&#25110;&#38750;&#32447;&#24615;&#20851;&#31995;&#65292;&#24182;&#21487;&#20197;&#25511;&#21046;&#39044;&#27979;&#26354;&#32447;&#30340;&#24179;&#28369;&#31243;&#24230;&#12290;&#22312;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19968;&#32452;&#26631;&#37327;&#39044;&#27979;&#21464;&#37327;&#19978;&#22238;&#24402;&#20989;&#25968;&#21709;&#24212;&#21487;&#20197;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#29305;&#21035;&#26159;&#24403;&#26377;&#22823;&#37327;&#39044;&#27979;&#21464;&#37327;&#25110;&#32773;&#39044;&#27979;&#21464;&#37327;&#19982;&#21709;&#24212;&#20043;&#38388;&#30340;&#20851;&#31995;&#26159;&#38750;&#32447;&#24615;&#30340;&#26102;&#20505;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#35299;&#20915;&#26041;&#26696;&#65306;&#20351;&#29992;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#39044;&#27979;&#26631;&#37327;&#36755;&#20837;&#19979;&#30340;&#20989;&#25968;&#21709;&#24212;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23558;&#20989;&#25968;&#21709;&#24212;&#36716;&#21270;&#20026;&#26377;&#38480;&#32500;&#24230;&#34920;&#31034;&#65292;&#24182;&#26500;&#24314;&#19968;&#20010;&#36755;&#20986;&#35813;&#34920;&#31034;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#30446;&#26631;&#20989;&#25968;&#20462;&#25913;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20986;&#65292;&#24182;&#24341;&#20837;&#19981;&#21516;&#30340;&#30446;&#26631;&#20989;&#25968;&#26469;&#36827;&#34892;&#32593;&#32476;&#35757;&#32451;&#12290;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#36866;&#29992;&#20110;&#22343;&#21248;&#21644;&#19981;&#22343;&#21248;&#38388;&#38548;&#30340;&#25968;&#25454;&#65292;&#24182;&#21487;&#20197;&#36827;&#19968;&#27493;&#24212;&#29992;&#24179;&#28369;&#24809;&#32602;&#39033;&#26469;&#25511;&#21046;&#39044;&#27979;&#26354;&#32447;&#30340;&#24179;&#28369;&#31243;&#24230;&#12290;&#23454;&#29616;&#36825;&#20123;&#29305;&#24615;&#30340;&#22256;&#38590;&#22312;&#20110;&#23450;&#20041;&#21487;&#20197;&#36827;&#34892;&#21453;&#21521;&#20256;&#25773;&#30340;&#30446;&#26631;&#20989;&#25968;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The regression of a functional response on a set of scalar predictors can be a challenging task, especially if there is a large number of predictors, or the relationship between those predictors and the response is nonlinear. In this work, we propose a solution to this problem: a feed-forward neural network (NN) designed to predict a functional response using scalar inputs. First, we transform the functional response to a finite-dimensional representation and construct an NN that outputs this representation. Then, we propose to modify the output of an NN via the objective function and introduce different objective functions for network training. The proposed models are suited for both regularly and irregularly spaced data, and a roughness penalty can be further applied to control the smoothness of the predicted curve. The difficulty in implementing both those features lies in the definition of objective functions that can be back-propagated. In our experiments, we demonstrate that our 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#24341;&#20837;&#26464;&#26438;&#20998;&#25968;&#31232;&#30095;&#65288;LESS&#65289;&#23884;&#20837;&#30340;&#33609;&#22270;&#25216;&#26415;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#31639;&#27861;&#26694;&#26550;&#65292;&#23454;&#29616;&#20102;&#23545;&#25968;&#25454;&#20998;&#24067;&#30340;&#39640;&#26031;&#21270;&#65292;&#20174;&#32780;&#33021;&#22815;&#39640;&#25928;&#22320;&#26500;&#24314;&#19982;&#27425;&#39640;&#26031;&#38543;&#26426;&#35774;&#35745;&#20960;&#20046;&#26080;&#27861;&#21306;&#20998;&#30340;&#25968;&#25454;&#33609;&#22270;&#12290;</title><link>http://arxiv.org/abs/2206.10291</link><description>&lt;p&gt;
&#36890;&#36807;&#33609;&#22270;&#25216;&#26415;&#23454;&#29616;&#31639;&#27861;&#39640;&#26031;&#21270;&#65306;&#23558;&#25968;&#25454;&#36716;&#25442;&#20026;&#27425;&#39640;&#26031;&#38543;&#26426;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Algorithmic Gaussianization through Sketching: Converting Data into Sub-gaussian Random Designs. (arXiv:2206.10291v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.10291
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#24341;&#20837;&#26464;&#26438;&#20998;&#25968;&#31232;&#30095;&#65288;LESS&#65289;&#23884;&#20837;&#30340;&#33609;&#22270;&#25216;&#26415;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#31639;&#27861;&#26694;&#26550;&#65292;&#23454;&#29616;&#20102;&#23545;&#25968;&#25454;&#20998;&#24067;&#30340;&#39640;&#26031;&#21270;&#65292;&#20174;&#32780;&#33021;&#22815;&#39640;&#25928;&#22320;&#26500;&#24314;&#19982;&#27425;&#39640;&#26031;&#38543;&#26426;&#35774;&#35745;&#20960;&#20046;&#26080;&#27861;&#21306;&#20998;&#30340;&#25968;&#25454;&#33609;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31639;&#27861;&#39640;&#26031;&#21270;&#26159;&#20351;&#29992;&#38543;&#26426;&#33609;&#22270;&#26041;&#27861;&#25110;&#37319;&#26679;&#26041;&#27861;&#29983;&#25104;&#22823;&#22411;&#25968;&#25454;&#38598;&#30340;&#36739;&#23567;&#34920;&#31034;&#26102;&#21487;&#33021;&#20986;&#29616;&#30340;&#29616;&#35937;&#65306;&#23545;&#20110;&#26576;&#20123;&#20219;&#21153;&#65292;&#35266;&#23519;&#21040;&#30340;&#36825;&#20123;&#33609;&#22270;&#34920;&#31034;&#20855;&#26377;&#35768;&#22810;&#31283;&#20581;&#24615;&#33021;&#29305;&#24449;&#65292;&#36825;&#20123;&#29305;&#24449;&#22312;&#25968;&#25454;&#26679;&#26412;&#26469;&#33258;&#27425;&#39640;&#26031;&#38543;&#26426;&#35774;&#35745;&#26102;&#24050;&#34987;&#30830;&#35748;&#23384;&#22312;&#65292;&#32780;&#27425;&#39640;&#26031;&#38543;&#26426;&#35774;&#35745;&#26159;&#25968;&#25454;&#20998;&#24067;&#30340;&#19968;&#20010;&#24378;&#22823;&#32479;&#35745;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#29616;&#35937;&#20165;&#22312;&#29305;&#23450;&#20219;&#21153;&#21644;&#24230;&#37327;&#26631;&#20934;&#19978;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#25110;&#32773;&#20381;&#36182;&#20110;&#35745;&#31639;&#26114;&#36149;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20379;&#19968;&#31181;&#36890;&#36807;&#24179;&#22343;&#26469;&#39640;&#26031;&#21270;&#25968;&#25454;&#20998;&#24067;&#30340;&#31639;&#27861;&#26694;&#26550;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#21487;&#20197;&#39640;&#25928;&#22320;&#26500;&#24314;&#19982;&#27425;&#39640;&#26031;&#38543;&#26426;&#35774;&#35745;&#22312;&#24635;&#21464;&#24322;&#36317;&#31163;&#19978;&#20960;&#20046;&#26080;&#27861;&#21306;&#20998;&#30340;&#25968;&#25454;&#33609;&#22270;&#12290;&#29305;&#21035;&#22320;&#65292;&#20381;&#36182;&#20110;&#26368;&#36817;&#24341;&#20837;&#30340;&#19968;&#31181;&#31216;&#20026;&#26464;&#26438;&#20998;&#25968;&#31232;&#30095;&#65288;LESS&#65289;&#23884;&#20837;&#30340;&#33609;&#22270;&#25216;&#26415;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#26500;&#24314;&#19968;&#20010;n&#36924;&#30495;&#30340;&#39640;&#26031;&#21270;&#25968;&#25454;&#33609;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithmic Gaussianization is a phenomenon that can arise when using randomized sketching or sampling methods to produce smaller representations of large datasets: For certain tasks, these sketched representations have been observed to exhibit many robust performance characteristics that are known to occur when a data sample comes from a sub-gaussian random design, which is a powerful statistical model of data distributions. However, this phenomenon has only been studied for specific tasks and metrics, or by relying on computationally expensive methods. We address this by providing an algorithmic framework for gaussianizing data distributions via averaging, proving that it is possible to efficiently construct data sketches that are nearly indistinguishable (in terms of total variation distance) from sub-gaussian random designs. In particular, relying on a recently introduced sketching technique called Leverage Score Sparsified (LESS) embeddings, we show that one can construct an $n\ti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21160;&#24577;&#21327;&#21464;&#37327;&#24179;&#34913;&#26041;&#27861;&#65292;&#22522;&#20110;&#36807;&#21435;&#21382;&#21490;&#19978;&#28508;&#22312;&#32467;&#26524;&#26399;&#26395;&#30340;&#23616;&#37096;&#25237;&#24433;&#65292;&#20272;&#35745;&#38754;&#26495;&#25968;&#25454;&#20013;&#21160;&#24577;&#21464;&#21270;&#30340;&#27835;&#30103;&#25928;&#26524;&#65292;&#24182;&#32771;&#34385;&#32467;&#26524;&#21644;&#26102;&#38388;&#21464;&#21270;&#30340;&#21327;&#21464;&#37327;&#19982;&#27835;&#30103;&#36712;&#36857;&#30340;&#20851;&#31995;&#20197;&#21450;&#27835;&#30103;&#25928;&#24212;&#30340;&#24322;&#36136;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#20855;&#26377;&#33391;&#22909;&#30340;&#28176;&#36817;&#24615;&#36136;&#21644;&#25968;&#20540;&#29305;&#24615;&#65292;&#22312;&#23454;&#35777;&#24212;&#29992;&#20013;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2103.01280</link><description>&lt;p&gt;
&#21160;&#24577;&#21327;&#21464;&#37327;&#24179;&#34913;&#65306;&#22522;&#20110;&#28508;&#22312;&#23616;&#37096;&#25237;&#24433;&#30340;&#27835;&#30103;&#25928;&#26524;&#38543;&#26102;&#38388;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Dynamic covariate balancing: estimating treatment effects over time with potential local projections. (arXiv:2103.01280v3 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2103.01280
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21160;&#24577;&#21327;&#21464;&#37327;&#24179;&#34913;&#26041;&#27861;&#65292;&#22522;&#20110;&#36807;&#21435;&#21382;&#21490;&#19978;&#28508;&#22312;&#32467;&#26524;&#26399;&#26395;&#30340;&#23616;&#37096;&#25237;&#24433;&#65292;&#20272;&#35745;&#38754;&#26495;&#25968;&#25454;&#20013;&#21160;&#24577;&#21464;&#21270;&#30340;&#27835;&#30103;&#25928;&#26524;&#65292;&#24182;&#32771;&#34385;&#32467;&#26524;&#21644;&#26102;&#38388;&#21464;&#21270;&#30340;&#21327;&#21464;&#37327;&#19982;&#27835;&#30103;&#36712;&#36857;&#30340;&#20851;&#31995;&#20197;&#21450;&#27835;&#30103;&#25928;&#24212;&#30340;&#24322;&#36136;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#20855;&#26377;&#33391;&#22909;&#30340;&#28176;&#36817;&#24615;&#36136;&#21644;&#25968;&#20540;&#29305;&#24615;&#65292;&#22312;&#23454;&#35777;&#24212;&#29992;&#20013;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38754;&#26495;&#25968;&#25454;&#20013;&#27835;&#30103;&#21382;&#21490;&#30340;&#20272;&#35745;&#21644;&#25512;&#26029;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#22312;&#27835;&#30103;&#22312;&#26102;&#38388;&#19978;&#21160;&#24577;&#21464;&#21270;&#30340;&#24773;&#20917;&#19979;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#20801;&#35768;&#27835;&#30103;&#26681;&#25454;&#39640;&#32500;&#21327;&#21464;&#37327;&#12289;&#36807;&#21435;&#30340;&#32467;&#26524;&#21644;&#27835;&#30103;&#21160;&#24577;&#20998;&#37197;&#65292;&#21516;&#26102;&#32771;&#34385;&#32467;&#26524;&#21644;&#26102;&#38388;&#21464;&#21270;&#30340;&#21327;&#21464;&#37327;&#19982;&#27835;&#30103;&#36712;&#36857;&#30340;&#20851;&#31995;&#65292;&#20197;&#21450;&#27835;&#30103;&#25928;&#24212;&#30340;&#24322;&#36136;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#22312;&#36807;&#21435;&#21382;&#21490;&#19978;&#23545;&#28508;&#22312;&#32467;&#26524;&#26399;&#26395;&#36827;&#34892;&#36882;&#24402;&#25237;&#24433;&#65292;&#28982;&#21518;&#36890;&#36807;&#24179;&#34913;&#21160;&#24577;&#21487;&#35266;&#27979;&#29305;&#24449;&#26469;&#25511;&#21046;&#20559;&#24046;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20272;&#35745;&#37327;&#30340;&#28176;&#36817;&#24615;&#36136;&#21644;&#25968;&#20540;&#29305;&#24615;&#65292;&#24182;&#22312;&#23454;&#35777;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the estimation and inference of treatment histories in panel data settings when treatments change dynamically over time.  We propose a method that allows for (i) treatments to be assigned dynamically over time based on high-dimensional covariates, past outcomes and treatments; (ii) outcomes and time-varying covariates to depend on treatment trajectories; (iii) heterogeneity of treatment effects.  Our approach recursively projects potential outcomes' expectations on past histories. It then controls the bias by balancing dynamically observable characteristics. We study the asymptotic and numerical properties of the estimator and illustrate the benefits of the procedure in an empirical application.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#32771;&#34385;&#20102;&#19968;&#31867;&#32447;&#24615;&#36716;&#25442;&#65292;&#24182;&#30740;&#31350;&#20102;&#20854;&#22312;&#36807;&#21442;&#25968;&#21270;&#32447;&#24615;&#22238;&#24402;&#35774;&#32622;&#20013;&#23545;&#23725;&#20272;&#35745;&#37327;&#30340;&#24433;&#21709;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#33021;&#22815;&#20445;&#25345;&#25968;&#25454;&#26631;&#31614;&#30340;&#36716;&#25442;&#21487;&#20197;&#36890;&#36807;&#25193;&#22823;&#35757;&#32451;&#25968;&#25454;&#30340;&#24352;&#37327;&#26469;&#25913;&#21892;&#20272;&#35745;&#32467;&#26524;&#65307;&#32780;&#28151;&#21512;&#25968;&#25454;&#30340;&#36716;&#25442;&#21017;&#36890;&#36807;&#36215;&#21040;&#27491;&#21017;&#21270;&#20316;&#29992;&#26469;&#25913;&#21892;&#20272;&#35745;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#22312;MNIST&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#39564;&#35777;&#65292;&#30740;&#31350;&#32773;&#25552;&#20986;&#20102;&#19968;&#20010;&#22686;&#24378;&#26041;&#26696;&#65292;&#35813;&#26041;&#26696;&#36890;&#36807;&#27169;&#22411;&#23545;&#36716;&#25442;&#21518;&#25968;&#25454;&#30340;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#25628;&#32034;&#36716;&#25442;&#31354;&#38388;&#65292;&#24182;&#22312;&#22270;&#20687;&#21644;&#25991;&#26412;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2005.00695</link><description>&lt;p&gt;
&#20851;&#20110;&#25968;&#25454;&#22686;&#24378;&#20013;&#32447;&#24615;&#36716;&#25442;&#30340;&#27867;&#21270;&#25928;&#26524;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Generalization Effects of Linear Transformations in Data Augmentation. (arXiv:2005.00695v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2005.00695
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#32771;&#34385;&#20102;&#19968;&#31867;&#32447;&#24615;&#36716;&#25442;&#65292;&#24182;&#30740;&#31350;&#20102;&#20854;&#22312;&#36807;&#21442;&#25968;&#21270;&#32447;&#24615;&#22238;&#24402;&#35774;&#32622;&#20013;&#23545;&#23725;&#20272;&#35745;&#37327;&#30340;&#24433;&#21709;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#33021;&#22815;&#20445;&#25345;&#25968;&#25454;&#26631;&#31614;&#30340;&#36716;&#25442;&#21487;&#20197;&#36890;&#36807;&#25193;&#22823;&#35757;&#32451;&#25968;&#25454;&#30340;&#24352;&#37327;&#26469;&#25913;&#21892;&#20272;&#35745;&#32467;&#26524;&#65307;&#32780;&#28151;&#21512;&#25968;&#25454;&#30340;&#36716;&#25442;&#21017;&#36890;&#36807;&#36215;&#21040;&#27491;&#21017;&#21270;&#20316;&#29992;&#26469;&#25913;&#21892;&#20272;&#35745;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#22312;MNIST&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#39564;&#35777;&#65292;&#30740;&#31350;&#32773;&#25552;&#20986;&#20102;&#19968;&#20010;&#22686;&#24378;&#26041;&#26696;&#65292;&#35813;&#26041;&#26696;&#36890;&#36807;&#27169;&#22411;&#23545;&#36716;&#25442;&#21518;&#25968;&#25454;&#30340;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#25628;&#32034;&#36716;&#25442;&#31354;&#38388;&#65292;&#24182;&#22312;&#22270;&#20687;&#21644;&#25991;&#26412;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#22686;&#24378;&#26159;&#19968;&#31181;&#22312;&#22270;&#20687;&#21644;&#25991;&#26412;&#20998;&#31867;&#20219;&#21153;&#31561;&#24212;&#29992;&#20013;&#25552;&#39640;&#24615;&#33021;&#30340;&#24378;&#22823;&#25216;&#26415;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#21508;&#31181;&#22686;&#24378;&#26041;&#27861;&#20026;&#20309;&#26377;&#25928;&#20197;&#21450;&#20854;&#24037;&#20316;&#21407;&#29702;&#30340;&#20005;&#26684;&#29702;&#35299;&#36824;&#24456;&#26377;&#38480;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31867;&#32447;&#24615;&#36716;&#25442;&#65292;&#24182;&#30740;&#31350;&#20102;&#20854;&#22312;&#36807;&#21442;&#25968;&#21270;&#32447;&#24615;&#22238;&#24402;&#35774;&#32622;&#20013;&#23545;&#23725;&#20272;&#35745;&#37327;&#30340;&#24433;&#21709;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#36890;&#36807;&#25193;&#22823;&#35757;&#32451;&#25968;&#25454;&#30340;&#24352;&#37327;&#26469;&#23637;&#31034;&#20102;&#33021;&#22815;&#20445;&#25345;&#25968;&#25454;&#26631;&#31614;&#30340;&#36716;&#25442;&#20250;&#25913;&#21892;&#20272;&#35745;&#32467;&#26524;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#36890;&#36807;&#28151;&#21512;&#25968;&#25454;&#30340;&#36716;&#25442;&#23637;&#31034;&#20102;&#23545;&#20272;&#35745;&#37327;&#36215;&#21040;&#20102;&#27491;&#21017;&#21270;&#30340;&#20316;&#29992;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;MNIST&#25968;&#25454;&#38598;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#27934;&#35265;&#12290;&#22522;&#20110;&#36825;&#20123;&#27934;&#35265;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#36807;&#27169;&#22411;&#23545;&#36716;&#25442;&#21518;&#30340;&#25968;&#25454;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#25628;&#32034;&#36716;&#25442;&#31354;&#38388;&#30340;&#22686;&#24378;&#26041;&#26696;&#12290;&#25105;&#20204;&#22312;&#22270;&#20687;&#21644;&#25991;&#26412;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#26696;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20351;&#29992;Wide-ResNet&#23545;CIFAR-100&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#38543;&#26426;&#37319;&#26679;&#26041;&#27861;1.24%&#12290;
&lt;/p&gt;
&lt;p&gt;
Data augmentation is a powerful technique to improve performance in applications such as image and text classification tasks. Yet, there is little rigorous understanding of why and how various augmentations work. In this work, we consider a family of linear transformations and study their effects on the ridge estimator in an over-parametrized linear regression setting. First, we show that transformations that preserve the labels of the data can improve estimation by enlarging the span of the training data. Second, we show that transformations that mix data can improve estimation by playing a regularization effect. Finally, we validate our theoretical insights on MNIST. Based on the insights, we propose an augmentation scheme that searches over the space of transformations by how uncertain the model is about the transformed data. We validate our proposed scheme on image and text datasets. For example, our method outperforms random sampling methods by 1.24% on CIFAR-100 using Wide-ResNet
&lt;/p&gt;</description></item></channel></rss>