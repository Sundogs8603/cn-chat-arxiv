<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#22312;&#26377;&#38480;&#25104;&#23545;&#20559;&#22909;&#27604;&#36739;&#19979;&#30740;&#31350;&#24230;&#37327;&#23398;&#20064;&#65292;&#34920;&#26126;&#34429;&#28982;&#26080;&#27861;&#23398;&#20064;&#21333;&#20010;&#29702;&#24819;&#39033;&#30446;&#65292;&#20294;&#24403;&#27604;&#36739;&#23545;&#35937;&#34920;&#29616;&#20986;&#20302;&#32500;&#32467;&#26500;&#26102;&#65292;&#27599;&#20010;&#29992;&#25143;&#21487;&#20197;&#24110;&#21161;&#23398;&#20064;&#38480;&#21046;&#22312;&#20302;&#32500;&#23376;&#31354;&#38388;&#20013;&#30340;&#24230;&#37327;&#12290;</title><link>https://arxiv.org/abs/2403.19629</link><description>&lt;p&gt;
&#26377;&#38480;&#25104;&#23545;&#20559;&#22909;&#27604;&#36739;&#19979;&#30340;&#24230;&#37327;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Metric Learning from Limited Pairwise Preference Comparisons
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19629
&lt;/p&gt;
&lt;p&gt;
&#22312;&#26377;&#38480;&#25104;&#23545;&#20559;&#22909;&#27604;&#36739;&#19979;&#30740;&#31350;&#24230;&#37327;&#23398;&#20064;&#65292;&#34920;&#26126;&#34429;&#28982;&#26080;&#27861;&#23398;&#20064;&#21333;&#20010;&#29702;&#24819;&#39033;&#30446;&#65292;&#20294;&#24403;&#27604;&#36739;&#23545;&#35937;&#34920;&#29616;&#20986;&#20302;&#32500;&#32467;&#26500;&#26102;&#65292;&#27599;&#20010;&#29992;&#25143;&#21487;&#20197;&#24110;&#21161;&#23398;&#20064;&#38480;&#21046;&#22312;&#20302;&#32500;&#23376;&#31354;&#38388;&#20013;&#30340;&#24230;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#29702;&#24819;&#28857;&#27169;&#22411;&#19979;&#30340;&#20559;&#22909;&#27604;&#36739;&#20013;&#30340;&#24230;&#37327;&#23398;&#20064;&#65292;&#20854;&#20013;&#29992;&#25143;&#22914;&#26524;&#19968;&#20010;&#39033;&#30446;&#27604;&#20854;&#28508;&#22312;&#29702;&#24819;&#39033;&#30446;&#26356;&#25509;&#36817;&#65292;&#21017;&#26356;&#21916;&#27426;&#35813;&#39033;&#30446;&#12290;&#36825;&#20123;&#39033;&#30446;&#23884;&#20837;&#21040;&#20855;&#26377;&#26410;&#30693;&#39532;&#27663;&#36317;&#31163;&#30340;$\mathbb{R}^d$&#20013;&#65292;&#35813;&#36317;&#31163;&#22312;&#29992;&#25143;&#38388;&#20849;&#20139;&#12290;&#23613;&#31649;&#26368;&#36817;&#30340;&#24037;&#20316;&#34920;&#26126;&#65292;&#36890;&#36807;&#27599;&#20010;&#29992;&#25143;$\mathcal{O}(d)$&#20010;&#25104;&#23545;&#27604;&#36739;&#21487;&#20197;&#21516;&#26102;&#24674;&#22797;&#24230;&#37327;&#21644;&#29702;&#24819;&#39033;&#30446;&#65292;&#20294;&#22312;&#23454;&#36341;&#20013;&#65292;&#25105;&#20204;&#32463;&#24120;&#26377;$o(d)$&#30340;&#26377;&#38480;&#27604;&#36739;&#39044;&#31639;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#21363;&#20351;&#24050;&#30693;&#23398;&#20064;&#21333;&#20010;&#29702;&#24819;&#39033;&#30446;&#29616;&#22312;&#19981;&#20877;&#21487;&#33021;&#65292;&#24230;&#37327;&#26159;&#21542;&#20173;&#28982;&#21487;&#20197;&#24674;&#22797;&#12290;&#25105;&#20204;&#21457;&#29616;&#19968;&#33324;&#26469;&#35828;&#65292;$o(d)$&#27604;&#36739;&#19981;&#20250;&#25581;&#31034;&#26377;&#20851;&#24230;&#37327;&#30340;&#20449;&#24687;&#65292;&#21363;&#20351;&#29992;&#25143;&#25968;&#37327;&#26080;&#38480;&#12290;&#28982;&#32780;&#65292;&#24403;&#27604;&#36739;&#30340;&#39033;&#30446;&#34920;&#29616;&#20986;&#20302;&#32500;&#32467;&#26500;&#26102;&#65292;&#27599;&#20010;&#29992;&#25143;&#37117;&#21487;&#20197;&#26377;&#21161;&#20110;&#23398;&#20064;&#38480;&#21046;&#22312;&#20302;&#32500;&#23376;&#31354;&#38388;&#20013;&#30340;&#24230;&#37327;&#65292;&#36825;&#26679;&#24230;&#37327;&#23601;&#21487;&#20197;&#34987;&#24674;&#22797;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19629v1 Announce Type: new  Abstract: We study metric learning from preference comparisons under the ideal point model, in which a user prefers an item over another if it is closer to their latent ideal item. These items are embedded into $\mathbb{R}^d$ equipped with an unknown Mahalanobis distance shared across users. While recent work shows that it is possible to simultaneously recover the metric and ideal items given $\mathcal{O}(d)$ pairwise comparisons per user, in practice we often have a limited budget of $o(d)$ comparisons. We study whether the metric can still be recovered, even though it is known that learning individual ideal items is now no longer possible. We show that in general, $o(d)$ comparisons reveals no information about the metric, even with infinitely many users. However, when comparisons are made over items that exhibit low-dimensional structure, each user can contribute to learning the metric restricted to a low-dimensional subspace so that the metric
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;Top-$k$&#20998;&#31867;&#20219;&#21153;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#22522;&#25968;&#24863;&#30693;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#36890;&#36807;&#23454;&#20363;&#30456;&#20851;&#30340;&#25104;&#26412;&#25935;&#24863;&#23398;&#20064;&#65292;&#24341;&#20837;&#20102;&#26032;&#30340;&#22522;&#25968;&#24863;&#30693;&#31639;&#27861;</title><link>https://arxiv.org/abs/2403.19625</link><description>&lt;p&gt;
&#22522;&#20110;Top-$k$&#20998;&#31867;&#21644;&#22522;&#25968;&#24863;&#30693;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Top-$k$ Classification and Cardinality-Aware Prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19625
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;Top-$k$&#20998;&#31867;&#20219;&#21153;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#22522;&#25968;&#24863;&#30693;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#36890;&#36807;&#23454;&#20363;&#30456;&#20851;&#30340;&#25104;&#26412;&#25935;&#24863;&#23398;&#20064;&#65292;&#24341;&#20837;&#20102;&#26032;&#30340;&#22522;&#25968;&#24863;&#30693;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35814;&#32454;&#30740;&#31350;&#20102;Top-$k$&#20998;&#31867;&#65292;&#21363;&#39044;&#27979;&#36755;&#20837;&#30340;$k$&#20010;&#26368;&#26377;&#21487;&#33021;&#30340;&#31867;&#21035;&#65292;&#36229;&#36234;&#20102;&#21333;&#31867;&#21035;&#39044;&#27979;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22810;&#31867;&#21035;&#20998;&#31867;&#20013;&#20960;&#31181;&#27969;&#34892;&#30340;&#26367;&#20195;&#25439;&#22833;&#20989;&#25968;&#65292;&#22914;comp-sum&#21644;&#32422;&#26463;&#25439;&#22833;&#65292;&#23545;&#20110;Top-$k$&#25439;&#22833;&#20855;&#26377;&#20851;&#20110;$h$-&#19968;&#33268;&#24615;&#36793;&#30028;&#30340;&#25903;&#25345;&#12290;&#36825;&#20123;&#36793;&#30028;&#20445;&#35777;&#20102;&#20851;&#20110;&#20551;&#35774;&#38598;$H$&#30340;&#19968;&#33268;&#24615;&#65292;&#30001;&#20110;&#23427;&#20204;&#30340;&#38750;&#28176;&#36817;&#21644;&#29305;&#23450;&#20551;&#35774;&#38598;&#24615;&#36136;&#65292;&#25552;&#20379;&#27604;&#36125;&#21494;&#26031;&#19968;&#33268;&#24615;&#26356;&#24378;&#30340;&#20445;&#35777;&#12290;&#20026;&#20102;&#35299;&#20915;&#20934;&#30830;&#24615;&#21644;&#22522;&#25968;$k$&#20043;&#38388;&#30340;&#25240;&#34935;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#36890;&#36807;&#23454;&#20363;&#30456;&#20851;&#30340;&#25104;&#26412;&#25935;&#24863;&#23398;&#20064;&#24341;&#20837;&#20102;&#22522;&#25968;&#24863;&#30693;&#25439;&#22833;&#20989;&#25968;&#12290;&#23545;&#20110;&#36825;&#20123;&#20989;&#25968;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#25104;&#26412;&#25935;&#24863;comp-sum&#21644;&#32422;&#26463;&#26367;&#20195;&#25439;&#22833;&#65292;&#24314;&#31435;&#20102;&#23427;&#20204;&#30340;$H$-&#19968;&#33268;&#24615;&#36793;&#30028;&#21644;&#36125;&#21494;&#26031;&#19968;&#33268;&#24615;&#12290;&#26368;&#23567;&#21270;&#36825;&#20123;&#25439;&#22833;&#23548;&#33268;&#20102;&#26032;&#30340;&#22522;&#25968;&#24863;&#30693;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19625v1 Announce Type: new  Abstract: We present a detailed study of top-$k$ classification, the task of predicting the $k$ most probable classes for an input, extending beyond single-class prediction. We demonstrate that several prevalent surrogate loss functions in multi-class classification, such as comp-sum and constrained losses, are supported by $H$-consistency bounds with respect to the top-$k$ loss. These bounds guarantee consistency in relation to the hypothesis set $H$, providing stronger guarantees than Bayes-consistency due to their non-asymptotic and hypothesis-set specific nature. To address the trade-off between accuracy and cardinality $k$, we further introduce cardinality-aware loss functions through instance-dependent cost-sensitive learning. For these functions, we derive cost-sensitive comp-sum and constrained surrogate losses, establishing their $H$-consistency bounds and Bayes-consistency. Minimizing these losses leads to new cardinality-aware algorithm
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340; tamed interactive particle Langevin algorithms&#65288;tIPLA&#65289;&#31867;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#22810;&#39033;&#24335;&#22686;&#38271;&#24773;&#20917;&#19979;&#33719;&#24471;&#31283;&#23450;&#19988;&#20855;&#26377;&#26368;&#20339;&#36895;&#29575;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#35823;&#24046;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2403.19587</link><description>&lt;p&gt;
&#39535;&#26381;&#20132;&#20114;&#24335;&#31890;&#23376; Langevin &#31639;&#27861; -- &#36229;&#32447;&#24615;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
Taming the Interactive Particle Langevin Algorithm -- the superlinear case
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19587
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340; tamed interactive particle Langevin algorithms&#65288;tIPLA&#65289;&#31867;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#22810;&#39033;&#24335;&#22686;&#38271;&#24773;&#20917;&#19979;&#33719;&#24471;&#31283;&#23450;&#19988;&#20855;&#26377;&#26368;&#20339;&#36895;&#29575;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#35823;&#24046;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22312;&#38543;&#26426;&#20248;&#21270;&#26041;&#38754;&#30340;&#36827;&#23637;&#20135;&#29983;&#20102;&#20132;&#20114;&#24335;&#31890;&#23376; Langevin &#31639;&#27861;&#65288;IPLA&#65289;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#20132;&#20114;&#31890;&#23376;&#31995;&#32479;&#65288;IPS&#65289;&#30340;&#27010;&#24565;&#26469;&#39640;&#25928;&#22320;&#20174;&#36817;&#20284;&#21518;&#39564;&#23494;&#24230;&#20013;&#25277;&#26679;&#12290;&#36825;&#22312;&#26399;&#26395;&#26368;&#22823;&#21270;&#65288;EM&#65289;&#26694;&#26550;&#20013;&#21464;&#24471;&#23588;&#20026;&#20851;&#38190;&#65292;&#20854;&#20013; E &#27493;&#39588;&#22312;&#35745;&#31639;&#19978;&#20855;&#26377;&#25361;&#25112;&#24615;&#29978;&#33267;&#26159;&#38590;&#20197;&#22788;&#29702;&#30340;&#12290;&#23613;&#31649;&#20808;&#21069;&#30340;&#30740;&#31350;&#20391;&#37325;&#20110;&#26799;&#24230;&#26368;&#22810;&#32447;&#24615;&#22686;&#38271;&#30340;&#20984;&#24773;&#20917;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#23558;&#27492;&#26694;&#26550;&#25193;&#23637;&#21040;&#21253;&#25324;&#22810;&#39033;&#24335;&#22686;&#38271;&#12290;&#37319;&#29992;&#39535;&#26381;&#25216;&#26415;&#29983;&#25104;&#26126;&#30830;&#30340;&#31163;&#25955;&#21270;&#26041;&#26696;&#65292;&#20174;&#32780;&#20135;&#29983;&#19968;&#31867;&#31283;&#23450;&#30340;&#12289;&#22312;&#36825;&#31181;&#38750;&#32447;&#24615;&#24773;&#20917;&#19979;&#65292;&#31216;&#20026;&#39535;&#26381;&#20132;&#20114;&#24335;&#31890;&#23376; Langevin &#31639;&#27861;&#65288;tIPLA&#65289;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#33719;&#24471;&#20102;&#26032;&#31867;&#22312; Wasserstein-2 &#36317;&#31163;&#19979;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#35823;&#24046;&#20272;&#35745;&#65292;&#20855;&#26377;&#26368;&#20339;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19587v1 Announce Type: cross  Abstract: Recent advances in stochastic optimization have yielded the interactive particle Langevin algorithm (IPLA), which leverages the notion of interacting particle systems (IPS) to efficiently sample from approximate posterior densities. This becomes particularly crucial within the framework of Expectation-Maximization (EM), where the E-step is computationally challenging or even intractable. Although prior research has focused on scenarios involving convex cases with gradients of log densities that grow at most linearly, our work extends this framework to include polynomial growth. Taming techniques are employed to produce an explicit discretization scheme that yields a new class of stable, under such non-linearities, algorithms which are called tamed interactive particle Langevin algorithms (tIPLA). We obtain non-asymptotic convergence error estimates in Wasserstein-2 distance for the new class under an optimal rate.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26377;&#21521;&#22270;&#32858;&#31867;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26377;&#21521;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#20004;&#31181;&#39640;&#25928;&#19988;&#21487;&#35299;&#37322;&#30340;&#26377;&#21521;&#32858;&#31867;&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.19516</link><description>&lt;p&gt;
&#38024;&#23545;&#26377;&#21521;&#22270;&#32858;&#31867;&#38382;&#39064;&#30340;&#38543;&#26426;&#22359;&#27169;&#22411;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Maximum Likelihood Estimation on Stochastic Blockmodels for Directed Graph Clustering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19516
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26377;&#21521;&#22270;&#32858;&#31867;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26377;&#21521;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#20004;&#31181;&#39640;&#25928;&#19988;&#21487;&#35299;&#37322;&#30340;&#26377;&#21521;&#32858;&#31867;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#32479;&#35745;&#23398;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#26377;&#21521;&#22270;&#32858;&#31867;&#38382;&#39064;&#65292;&#23558;&#32858;&#31867;&#38382;&#39064;&#24314;&#27169;&#20026;&#26377;&#21521;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;DSBM&#65289;&#20013;&#28508;&#22312;&#31038;&#21306;&#30340;&#20272;&#35745;&#12290;&#25105;&#20204;&#23545;DSBM&#36827;&#34892;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65288;MLE&#65289;&#65292;&#20174;&#32780;&#30830;&#23450;&#32473;&#23450;&#35266;&#23519;&#21040;&#30340;&#22270;&#32467;&#26500;&#26102;&#26368;&#21487;&#33021;&#30340;&#31038;&#21306;&#20998;&#37197;&#12290;&#38500;&#20102;&#32479;&#35745;&#35266;&#28857;&#22806;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#24314;&#31435;&#20102;&#36825;&#31181;MLE&#20844;&#24335;&#19982;&#19968;&#31181;&#26032;&#39062;&#30340;&#27969;&#20248;&#21270;&#21551;&#21457;&#24335;&#20043;&#38388;&#30340;&#31561;&#20215;&#24615;&#65292;&#35813;&#21551;&#21457;&#24335;&#21516;&#26102;&#32771;&#34385;&#20102;&#20004;&#20010;&#37325;&#35201;&#30340;&#26377;&#21521;&#22270;&#32479;&#35745;&#37327;&#65306;&#36793;&#23494;&#24230;&#21644;&#36793;&#26041;&#21521;&#12290;&#22522;&#20110;&#36825;&#31181;&#26377;&#21521;&#32858;&#31867;&#30340;&#26032;&#20844;&#24335;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31181;&#39640;&#25928;&#19988;&#21487;&#35299;&#37322;&#30340;&#26377;&#21521;&#32858;&#31867;&#31639;&#27861;&#65292;&#20998;&#21035;&#26159;&#35889;&#32858;&#31867;&#31639;&#27861;&#21644;&#22522;&#20110;&#21322;&#23450;&#35268;&#21010;&#30340;&#32858;&#31867;&#31639;&#27861;&#12290;&#25105;&#20204;&#20026;&#35889;&#32858;&#31867;&#31639;&#27861;&#30340;&#38169;&#35823;&#32858;&#31867;&#39030;&#28857;&#25968;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19516v1 Announce Type: cross  Abstract: This paper studies the directed graph clustering problem through the lens of statistics, where we formulate clustering as estimating underlying communities in the directed stochastic block model (DSBM). We conduct the maximum likelihood estimation (MLE) on the DSBM and thereby ascertain the most probable community assignment given the observed graph structure. In addition to the statistical point of view, we further establish the equivalence between this MLE formulation and a novel flow optimization heuristic, which jointly considers two important directed graph statistics: edge density and edge orientation. Building on this new formulation of directed clustering, we introduce two efficient and interpretable directed clustering algorithms, a spectral clustering algorithm and a semidefinite programming based clustering algorithm. We provide a theoretical upper bound on the number of misclustered vertices of the spectral clustering algor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;Canonical Polyadic Decomposition&#21644;Tensor Train&#32422;&#26463;&#30340;&#26680;&#26426;&#22120;&#30340;&#36755;&#20986;&#20250;&#22312;&#23545;&#21442;&#25968;&#36827;&#34892;i.i.d.&#20808;&#39564;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#24674;&#22797;&#20026;&#39640;&#26031;&#36807;&#31243;&#65292;&#24182;&#19988;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;Tensor Train&#27169;&#22411;&#30456;&#23545;&#20110;Canonical Polyadic Decomposition&#27169;&#22411;&#20855;&#26377;&#26356;&#22810;&#39640;&#26031;&#36807;&#31243;&#34892;&#20026;&#12290;</title><link>https://arxiv.org/abs/2403.19500</link><description>&lt;p&gt;
&#24352;&#37327;&#32593;&#32476;&#32422;&#26463;&#30340;&#26680;&#26426;&#22120;&#20316;&#20026;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Tensor Network-Constrained Kernel Machines as Gaussian Processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19500
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;Canonical Polyadic Decomposition&#21644;Tensor Train&#32422;&#26463;&#30340;&#26680;&#26426;&#22120;&#30340;&#36755;&#20986;&#20250;&#22312;&#23545;&#21442;&#25968;&#36827;&#34892;i.i.d.&#20808;&#39564;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#24674;&#22797;&#20026;&#39640;&#26031;&#36807;&#31243;&#65292;&#24182;&#19988;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;Tensor Train&#27169;&#22411;&#30456;&#23545;&#20110;Canonical Polyadic Decomposition&#27169;&#22411;&#20855;&#26377;&#26356;&#22810;&#39640;&#26031;&#36807;&#31243;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24352;&#37327;&#32593;&#32476;&#65288;TNs&#65289;&#26368;&#36817;&#34987;&#29992;&#26469;&#36890;&#36807;&#32422;&#26463;&#27169;&#22411;&#26435;&#37325;&#21152;&#24555;&#26680;&#26426;&#22120;&#30340;&#36895;&#24230;&#65292;&#20135;&#29983;&#20102;&#25351;&#25968;&#32423;&#30340;&#35745;&#31639;&#21644;&#23384;&#20648;&#33410;&#32422;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;Canonical Polyadic Decomposition&#65288;CPD&#65289;&#21644;Tensor Train&#65288;TT&#65289;&#32422;&#26463;&#30340;&#26680;&#26426;&#22120;&#30340;&#36755;&#20986;&#20250;&#22312;&#23545;&#21442;&#25968;&#36827;&#34892;i.i.d.&#20808;&#39564;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#24674;&#22797;&#20026;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#65292;&#25105;&#20204;&#23436;&#20840;&#34920;&#24449;&#20102;&#36825;&#19968;&#36807;&#31243;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;CPD&#21644;TT&#32422;&#26463;&#27169;&#22411;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;TT&#30456;&#23545;&#20110;CPD&#20855;&#26377;&#26356;&#22810;GP&#34892;&#20026;&#30340;&#27169;&#22411;&#65292;&#32780;&#27169;&#22411;&#21442;&#25968;&#30340;&#25968;&#37327;&#30456;&#21516;&#12290;&#25105;&#20204;&#36890;&#36807;&#20004;&#20010;&#25968;&#20540;&#23454;&#39564;&#22312;&#20004;&#20010;&#26041;&#38754;&#23454;&#35777;&#35266;&#23519;&#20102;&#36825;&#19968;&#34892;&#20026;&#65292;&#20998;&#21035;&#26159;&#20998;&#26512;&#21040;GP&#30340;&#25910;&#25947;&#24615;&#21644;&#39044;&#27979;&#24615;&#33021;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#24352;&#37327;&#32593;&#32476;&#32422;&#26463;&#30340;&#26680;&#26426;&#22120;&#21644;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19500v1 Announce Type: new  Abstract: Tensor Networks (TNs) have recently been used to speed up kernel machines by constraining the model weights, yielding exponential computational and storage savings. In this paper we prove that the outputs of Canonical Polyadic Decomposition (CPD) and Tensor Train (TT)-constrained kernel machines recover a Gaussian Process (GP), which we fully characterize, when placing i.i.d. priors over their parameters. We analyze the convergence of both CPD and TT-constrained models, and show how TT yields models exhibiting more GP behavior compared to CPD, for the same number of model parameters. We empirically observe this behavior in two numerical experiments where we respectively analyze the convergence to the GP and the performance at prediction. We thereby establish a connection between TN-constrained kernel machines and GPs.
&lt;/p&gt;</description></item><item><title>&#36825;&#26159;&#19968;&#20010;&#22238;&#24402;&#38382;&#39064;&#30340;&#26032;&#26694;&#26550;&#65292;&#28041;&#21450;&#23558;&#39044;&#27979;&#25512;&#36831;&#32473;&#22810;&#20010;&#19987;&#23478;&#65292;&#25552;&#20986;&#20102;&#21333;&#38454;&#27573;&#21644;&#21452;&#38454;&#27573;&#24773;&#26223;&#30340;&#20840;&#38754;&#20998;&#26512;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#30340;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#21450;&#20854;&#25903;&#25345;&#30340;&#19968;&#33268;&#24615;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2403.19494</link><description>&lt;p&gt;
&#20855;&#26377;&#22810;&#19987;&#23478;&#25512;&#36831;&#30340;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Regression with Multi-Expert Deferral
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19494
&lt;/p&gt;
&lt;p&gt;
&#36825;&#26159;&#19968;&#20010;&#22238;&#24402;&#38382;&#39064;&#30340;&#26032;&#26694;&#26550;&#65292;&#28041;&#21450;&#23558;&#39044;&#27979;&#25512;&#36831;&#32473;&#22810;&#20010;&#19987;&#23478;&#65292;&#25552;&#20986;&#20102;&#21333;&#38454;&#27573;&#21644;&#21452;&#38454;&#27573;&#24773;&#26223;&#30340;&#20840;&#38754;&#20998;&#26512;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#30340;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#21450;&#20854;&#25903;&#25345;&#30340;&#19968;&#33268;&#24615;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#19982;&#22810;&#20010;&#19987;&#23478;&#25512;&#36831;&#26159;&#19968;&#20010;&#26694;&#26550;&#65292;&#20854;&#20013;&#23398;&#20064;&#32773;&#21487;&#20197;&#36873;&#25321;&#23558;&#39044;&#27979;&#25512;&#36831;&#32473;&#22810;&#20010;&#19987;&#23478;&#12290;&#34429;&#28982;&#22312;&#20998;&#31867;&#24773;&#22659;&#20013;&#35813;&#38382;&#39064;&#24471;&#21040;&#20102;&#37325;&#35270;&#65292;&#20294;&#30001;&#20110;&#26631;&#31614;&#31354;&#38388;&#30340;&#26080;&#38480;&#21644;&#36830;&#32493;&#29305;&#24615;&#65292;&#23427;&#22312;&#22238;&#24402;&#20013;&#38754;&#20020;&#29420;&#29305;&#25361;&#25112;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20855;&#26377;&#25512;&#36831;&#30340;&#22238;&#24402;&#26032;&#26694;&#26550;&#65292;&#20854;&#20013;&#28041;&#21450;&#23558;&#39044;&#27979;&#25512;&#36831;&#32473;&#22810;&#20010;&#19987;&#23478;&#12290;&#25105;&#20204;&#38024;&#23545;&#21333;&#38454;&#27573;&#24773;&#26223;&#21644;&#21452;&#38454;&#27573;&#24773;&#26223;&#36827;&#34892;&#20102;&#20840;&#38754;&#20998;&#26512;&#65292;&#21069;&#32773;&#28041;&#21450;&#39044;&#27979;&#22120;&#21644;&#25512;&#36831;&#20989;&#25968;&#30340;&#21516;&#26102;&#23398;&#20064;&#65292;&#21518;&#32773;&#28041;&#21450;&#20855;&#26377;&#24050;&#35757;&#32451;&#39044;&#27979;&#22120;&#21644;&#23398;&#20064;&#25512;&#36831;&#20989;&#25968;&#12290;&#25105;&#20204;&#20026;&#20004;&#31181;&#24773;&#26223;&#24341;&#20837;&#20102;&#26032;&#30340;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#65292;&#24182;&#35777;&#26126;&#23427;&#20204;&#21463;&#21040;$H$-&#19968;&#33268;&#24615;&#30028;&#38480;&#30340;&#25903;&#25345;&#12290;&#36825;&#20123;&#30028;&#38480;&#25552;&#20379;&#20102;&#27604;&#36125;&#21494;&#26031;&#19968;&#33268;&#24615;&#26356;&#24378;&#30340;&#19968;&#33268;&#24615;&#20445;&#35777;&#65292;&#22240;&#20026;&#23427;&#20204;&#26159;&#38750;&#28176;&#36817;&#30340;&#65292;&#19988;&#20551;&#35774;&#38598;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19494v1 Announce Type: new  Abstract: Learning to defer with multiple experts is a framework where the learner can choose to defer the prediction to several experts. While this problem has received significant attention in classification contexts, it presents unique challenges in regression due to the infinite and continuous nature of the label space. In this work, we introduce a novel framework of regression with deferral, which involves deferring the prediction to multiple experts. We present a comprehensive analysis for both the single-stage scenario, where there is simultaneous learning of predictor and deferral functions, and the two-stage scenario, which involves a pre-trained predictor with a learned deferral function. We introduce new surrogate loss functions for both scenarios and prove that they are supported by $H$-consistency bounds. These bounds provide consistency guarantees that are stronger than Bayes consistency, as they are non-asymptotic and hypothesis set
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#36890;&#29992;&#30340;$H$&#19968;&#33268;&#24615;&#30028;&#24037;&#20855;&#26469;&#20998;&#26512;&#22238;&#24402;&#38382;&#39064;&#65292;&#24182;&#38024;&#23545;&#24179;&#26041;&#25439;&#22833;&#25512;&#23548;&#20986;&#19968;&#31995;&#21015;&#26032;&#39062;&#30340;$H$&#19968;&#33268;&#24615;&#30028;&#65307;&#22522;&#20110;&#23545;$H$&#19968;&#33268;&#24615;&#30340;&#20998;&#26512;&#65292;&#20026;&#23545;&#25239;&#24615;&#22238;&#24402;&#25552;&#20379;&#20102;&#26377;&#21407;&#21017;&#30340;&#20195;&#29702;&#25439;&#22833;&#12290;</title><link>https://arxiv.org/abs/2403.19480</link><description>&lt;p&gt;
&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;$H$&#19968;&#33268;&#24615;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
$H$-Consistency Guarantees for Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19480
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#36890;&#29992;&#30340;$H$&#19968;&#33268;&#24615;&#30028;&#24037;&#20855;&#26469;&#20998;&#26512;&#22238;&#24402;&#38382;&#39064;&#65292;&#24182;&#38024;&#23545;&#24179;&#26041;&#25439;&#22833;&#25512;&#23548;&#20986;&#19968;&#31995;&#21015;&#26032;&#39062;&#30340;$H$&#19968;&#33268;&#24615;&#30028;&#65307;&#22522;&#20110;&#23545;$H$&#19968;&#33268;&#24615;&#30340;&#20998;&#26512;&#65292;&#20026;&#23545;&#25239;&#24615;&#22238;&#24402;&#25552;&#20379;&#20102;&#26377;&#21407;&#21017;&#30340;&#20195;&#29702;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;$H$&#19968;&#33268;&#24615;&#30028;&#36827;&#34892;&#20102;&#35814;&#32454;&#30740;&#31350;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#20123;&#26032;&#30340;&#23450;&#29702;&#65292;&#36825;&#20123;&#23450;&#29702;&#25512;&#24191;&#20102;&#20808;&#21069;&#29992;&#20110;&#24314;&#31435;$H$&#19968;&#33268;&#24615;&#30028;&#30340;&#24037;&#20855;&#12290;&#36825;&#31181;&#27010;&#25324;&#23545;&#20110;&#20998;&#26512;&#38024;&#23545;&#22238;&#24402;&#38382;&#39064;&#29305;&#23450;&#30340;$H$&#19968;&#33268;&#24615;&#30028;&#33267;&#20851;&#37325;&#35201;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#22312;&#23545;&#31216;&#20998;&#24067;&#21644;&#26377;&#30028;&#20551;&#35774;&#38598;&#30340;&#26465;&#20214;&#19979;&#65292;&#35777;&#26126;&#20102;&#19968;&#31995;&#21015;&#20851;&#20110;&#24179;&#26041;&#25439;&#22833;&#30340;&#26032;&#39062;$H$&#19968;&#33268;&#24615;&#30028;&#65292;&#21253;&#25324;Huber&#25439;&#22833;&#12289;&#25152;&#26377;$\ell_p$&#25439;&#22833;&#65288;$p \geq 1$&#65289;&#12289;&#24179;&#26041;$\epsilon$-&#19981;&#25935;&#24863;&#25439;&#22833;&#30340;&#27491;&#32467;&#26524;&#65292;&#20197;&#21450;&#23545;&#20110;&#22312;&#24179;&#26041;&#25903;&#25345;&#21521;&#37327;&#22238;&#24402;&#65288;SVR&#65289;&#20013;&#20351;&#29992;&#30340;$\epsilon$-&#19981;&#25935;&#24863;&#25439;&#22833;&#30340;&#36127;&#32467;&#26524;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#21033;&#29992;&#23545;&#22238;&#24402;&#38382;&#39064;&#20013;$H$&#19968;&#33268;&#24615;&#30340;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#38024;&#23545;&#23545;&#25239;&#22238;&#24402;&#30340;&#26377;&#21407;&#21017;&#30340;&#20195;&#29702;&#25439;&#22833;&#65288;&#31532;5&#33410;&#65289;&#12290;&#36825;&#20026;&#23545;&#25239;&#24615;&#22238;&#24402;&#24314;&#31435;&#20102;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#25105;&#20204;&#25253;&#21578;&#20102;&#26377;&#21033;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19480v1 Announce Type: new  Abstract: We present a detailed study of $H$-consistency bounds for regression. We first present new theorems that generalize the tools previously given to establish $H$-consistency bounds. This generalization proves essential for analyzing $H$-consistency bounds specific to regression. Next, we prove a series of novel $H$-consistency bounds for surrogate loss functions of the squared loss, under the assumption of a symmetric distribution and a bounded hypothesis set. This includes positive results for the Huber loss, all $\ell_p$ losses, $p \geq 1$, the squared $\epsilon$-insensitive loss, as well as a negative result for the $\epsilon$-insensitive loss used in squared Support Vector Regression (SVR). We further leverage our analysis of $H$-consistency for regression and derive principled surrogate losses for adversarial regression (Section 5). This readily establishes novel algorithms for adversarial regression, for which we report favorable exp
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#22522;&#20110;Fisher&#20449;&#24687;&#30697;&#38453;&#30340;&#33258;&#28982;&#26799;&#24230;&#26041;&#27861;&#22312;&#32447;&#24615;&#35268;&#21010;&#20013;&#30340;&#24212;&#29992;&#65292;&#23637;&#31034;&#20102;&#32447;&#24615;&#25910;&#25947;&#24615;&#65292;&#25552;&#20986;&#20102;&#25913;&#36827;&#29616;&#26377;&#32467;&#26524;&#30340;&#29109;&#27491;&#21017;&#21270;&#35823;&#24046;&#20272;&#35745;&#65292;&#24182;&#23545;&#25200;&#21160;&#30340;Fisher-Rao&#26799;&#24230;&#27969;&#21644;&#33258;&#28982;&#26799;&#24230;&#27969;&#30340;&#27425;&#32447;&#24615;&#25910;&#25947;&#24615;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;</title><link>https://arxiv.org/abs/2403.19448</link><description>&lt;p&gt;
Fisher-Rao&#32447;&#24615;&#35268;&#21010;&#21644;&#29366;&#24577;-&#21160;&#20316;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#30340;&#26799;&#24230;&#27969;
&lt;/p&gt;
&lt;p&gt;
Fisher-Rao Gradient Flows of Linear Programs and State-Action Natural Policy Gradients
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19448
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#22522;&#20110;Fisher&#20449;&#24687;&#30697;&#38453;&#30340;&#33258;&#28982;&#26799;&#24230;&#26041;&#27861;&#22312;&#32447;&#24615;&#35268;&#21010;&#20013;&#30340;&#24212;&#29992;&#65292;&#23637;&#31034;&#20102;&#32447;&#24615;&#25910;&#25947;&#24615;&#65292;&#25552;&#20986;&#20102;&#25913;&#36827;&#29616;&#26377;&#32467;&#26524;&#30340;&#29109;&#27491;&#21017;&#21270;&#35823;&#24046;&#20272;&#35745;&#65292;&#24182;&#23545;&#25200;&#21160;&#30340;Fisher-Rao&#26799;&#24230;&#27969;&#21644;&#33258;&#28982;&#26799;&#24230;&#27969;&#30340;&#27425;&#32447;&#24615;&#25910;&#25947;&#24615;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Kakade&#30340;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#36817;&#24180;&#26469;&#24471;&#21040;&#24191;&#27867;&#30740;&#31350;&#65292;&#34920;&#26126;&#22312;&#26377;&#25110;&#26080;&#27491;&#21017;&#21270;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#32447;&#24615;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#21478;&#19968;&#31181;&#22522;&#20110;&#29366;&#24577;-&#21160;&#20316;&#20998;&#24067;&#30340;Fisher&#20449;&#24687;&#30697;&#38453;&#30340;&#33258;&#28982;&#26799;&#24230;&#26041;&#27861;&#65292;&#20294;&#22312;&#29702;&#35770;&#26041;&#38754;&#25509;&#21463;&#24230;&#36739;&#20302;&#12290;&#22312;&#36825;&#37324;&#65292;&#29366;&#24577;-&#21160;&#20316;&#20998;&#24067;&#22312;&#29366;&#24577;-&#21160;&#20316;&#22810;&#38754;&#20307;&#20869;&#36981;&#24490;Fisher-Rao&#26799;&#24230;&#27969;&#65292;&#30456;&#23545;&#20110;&#32447;&#24615;&#21183;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#26356;&#20840;&#38754;&#22320;&#30740;&#31350;&#32447;&#24615;&#35268;&#21010;&#30340;Fisher-Rao&#26799;&#24230;&#27969;&#65292;&#24182;&#26174;&#31034;&#20102;&#32447;&#24615;&#25910;&#25947;&#24615;&#65292;&#20854;&#36895;&#29575;&#21462;&#20915;&#20110;&#32447;&#24615;&#35268;&#21010;&#30340;&#20960;&#20309;&#29305;&#24615;&#12290;&#25442;&#21477;&#35805;&#35828;&#65292;&#36825;&#25552;&#20379;&#20102;&#32447;&#24615;&#35268;&#21010;&#30340;&#29109;&#27491;&#21017;&#21270;&#24341;&#36215;&#30340;&#35823;&#24046;&#20272;&#35745;&#65292;&#36825;&#25913;&#36827;&#20102;&#29616;&#26377;&#32467;&#26524;&#12290;&#25105;&#20204;&#25299;&#23637;&#20102;&#36825;&#20123;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;&#23545;&#25200;&#21160;&#30340;Fisher-Rao&#26799;&#24230;&#27969;&#21644;&#33258;&#28982;&#26799;&#24230;&#27969;&#30340;&#27425;&#32447;&#24615;&#25910;&#25947;&#24615;&#65292;&#30452;&#21040;&#36924;&#36817;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19448v1 Announce Type: cross  Abstract: Kakade's natural policy gradient method has been studied extensively in the last years showing linear convergence with and without regularization. We study another natural gradient method which is based on the Fisher information matrix of the state-action distributions and has received little attention from the theoretical side. Here, the state-action distributions follow the Fisher-Rao gradient flow inside the state-action polytope with respect to a linear potential. Therefore, we study Fisher-Rao gradient flows of linear programs more generally and show linear convergence with a rate that depends on the geometry of the linear program. Equivalently, this yields an estimate on the error induced by entropic regularization of the linear program which improves existing results. We extend these results and show sublinear convergence for perturbed Fisher-Rao gradient flows and natural gradient flows up to an approximation error. In particul
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24120;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#26368;&#20248;&#26041;&#27861;&#65292;&#21487;&#20197;&#24674;&#22797;&#30001;&#26410;&#30693;&#20219;&#21153;&#20998;&#24067;&#23450;&#20041;&#30340;&#36125;&#21494;&#26031;&#21518;&#39564;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.19381</link><description>&lt;p&gt;
&#20851;&#20110;&#36817;&#36125;&#21494;&#26031;&#26368;&#20248;&#31639;&#27861;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
On Uncertainty Quantification for Near-Bayes Optimal Algorithms
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19381
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24120;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#26368;&#20248;&#26041;&#27861;&#65292;&#21487;&#20197;&#24674;&#22797;&#30001;&#26410;&#30693;&#20219;&#21153;&#20998;&#24067;&#23450;&#20041;&#30340;&#36125;&#21494;&#26031;&#21518;&#39564;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#24314;&#27169;&#20801;&#35768;&#23545;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#37327;&#21270;&#65292;&#22312;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#20013;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#31639;&#27861;&#65292;&#26500;&#24314;&#25110;&#23454;&#29616;&#23427;&#20204;&#30340;&#36125;&#21494;&#26031;&#23545;&#24212;&#26159;&#22256;&#38590;&#30340;&#12290; &#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#30340;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#24120;&#29992;&#30340;ML&#31639;&#27861;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#39640;&#25928;&#65292;&#24182;&#19988;&#21487;&#33021;&#22312;&#26410;&#30693;&#20219;&#21153;&#20998;&#24067;&#19979;&#25509;&#36817;&#36125;&#21494;&#26031;&#26368;&#20248;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36890;&#36807;&#20351;&#29992;&#35813;&#31639;&#27861;&#26500;&#24314;&#19968;&#20010;&#38789;&#21518;&#39564;&#65292;&#21487;&#20197;&#24674;&#22797;&#30001;&#20219;&#21153;&#20998;&#24067;&#23450;&#20041;&#30340;&#36125;&#21494;&#26031;&#21518;&#39564;&#65292;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#26159;&#26410;&#30693;&#20294;&#26368;&#20248;&#30340;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#36890;&#29992;ML&#31639;&#27861;&#30340;&#23454;&#29992;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#12290;&#22522;&#20110;&#21508;&#31181;&#38750;NN&#21644;NN&#31639;&#27861;&#30340;&#23454;&#39564;&#34920;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19381v1 Announce Type: cross  Abstract: Bayesian modelling allows for the quantification of predictive uncertainty which is crucial in safety-critical applications. Yet for many machine learning (ML) algorithms, it is difficult to construct or implement their Bayesian counterpart. In this work we present a promising approach to address this challenge, based on the hypothesis that commonly used ML algorithms are efficient across a wide variety of tasks and may thus be near Bayes-optimal w.r.t. an unknown task distribution. We prove that it is possible to recover the Bayesian posterior defined by the task distribution, which is unknown but optimal in this setting, by building a martingale posterior using the algorithm. We further propose a practical uncertainty quantification method that apply to general ML algorithms. Experiments based on a variety of non-NN and NN algorithms demonstrate the efficacy of our method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#30340;&#26032;&#39062;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#39640;&#32500;&#22797;&#26434;&#25968;&#25454;&#12290;</title><link>https://arxiv.org/abs/2403.18994</link><description>&lt;p&gt;
Causal-StoNet: &#39640;&#32500;&#22797;&#26434;&#25968;&#25454;&#30340;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Causal-StoNet: Causal Inference for High-Dimensional Complex Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18994
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#30340;&#26032;&#39062;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#39640;&#32500;&#22797;&#26434;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#25968;&#25454;&#31185;&#23398;&#30340;&#21457;&#23637;&#65292;&#25910;&#38598;&#36234;&#26469;&#36234;&#22797;&#26434;&#30340;&#25968;&#25454;&#38598;&#24050;&#32463;&#21464;&#24471;&#21496;&#31354;&#35265;&#24815;&#12290;&#22312;&#36825;&#20123;&#25968;&#25454;&#38598;&#20013;&#65292;&#25968;&#25454;&#32500;&#24230;&#21487;&#33021;&#38750;&#24120;&#39640;&#65292;&#24182;&#19988;&#28508;&#22312;&#30340;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#21487;&#33021;&#26159;&#26410;&#30693;&#30340;&#65292;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#12290;&#22240;&#27492;&#65292;&#22312;&#35768;&#22810;&#39046;&#22495;&#65292;&#22914;&#21307;&#23398;&#12289;&#35745;&#37327;&#32463;&#27982;&#23398;&#21644;&#31038;&#20250;&#31185;&#23398;&#65292;&#23545;&#39640;&#32500;&#22797;&#26434;&#25968;&#25454;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#30340;&#20219;&#21153;&#24050;&#32463;&#25104;&#20026;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#36890;&#24120;&#26159;&#22312;&#20551;&#35774;&#25968;&#25454;&#32500;&#24230;&#36739;&#20302;&#25110;&#28508;&#22312;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20026;&#32447;&#24615;&#25110;&#36817;&#20284;&#32447;&#24615;&#30340;&#24773;&#20917;&#19979;&#24320;&#21457;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#39640;&#32500;&#22797;&#26434;&#25968;&#25454;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#65292;&#21253;&#25324;&#26368;&#36817;&#21457;&#23637;&#30340;&#31232;&#30095;&#28145;&#24230;&#23398;&#20064;&#29702;&#35770;&#21644;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18994v1 Announce Type: cross  Abstract: With the advancement of data science, the collection of increasingly complex datasets has become commonplace. In such datasets, the data dimension can be extremely high, and the underlying data generation process can be unknown and highly nonlinear. As a result, the task of making causal inference with high-dimensional complex data has become a fundamental problem in many disciplines, such as medicine, econometrics, and social science. However, the existing methods for causal inference are frequently developed under the assumption that the data dimension is low or that the underlying data generation process is linear or approximately linear. To address these challenges, this paper proposes a novel causal inference approach for dealing with high-dimensional complex data. The proposed approach is based on deep learning techniques, including sparse deep learning theory and stochastic neural networks, that have been developed in recent lit
&lt;/p&gt;</description></item><item><title>&#39640;&#20284;&#28982;&#21306;&#22495;&#23558;&#19981;&#20250;&#34987;&#29983;&#25104;&#22914;&#26524;&#23427;&#20204;&#21253;&#21547;&#26368;&#23567;&#27010;&#29575;&#36136;&#37327;&#65292;&#22522;&#20110;&#27492;&#35266;&#23519;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26412;&#22320;&#22266;&#26377;&#32500;&#24230;&#20272;&#35745;&#36827;&#34892;&#31163;&#32676;&#26816;&#27979;&#30340;&#26041;&#27861;</title><link>https://arxiv.org/abs/2403.18910</link><description>&lt;p&gt;
&#23545;&#31163;&#32676;&#25968;&#25454;&#26816;&#27979;&#24726;&#35770;&#30340;&#20284;&#28982;&#20960;&#20309;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
A Geometric Explanation of the Likelihood OOD Detection Paradox
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18910
&lt;/p&gt;
&lt;p&gt;
&#39640;&#20284;&#28982;&#21306;&#22495;&#23558;&#19981;&#20250;&#34987;&#29983;&#25104;&#22914;&#26524;&#23427;&#20204;&#21253;&#21547;&#26368;&#23567;&#27010;&#29575;&#36136;&#37327;&#65292;&#22522;&#20110;&#27492;&#35266;&#23519;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26412;&#22320;&#22266;&#26377;&#32500;&#24230;&#20272;&#35745;&#36827;&#34892;&#31163;&#32676;&#26816;&#27979;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20284;&#28982;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;(DGMs)&#36890;&#24120;&#34920;&#29616;&#20986;&#20196;&#20154;&#22256;&#24785;&#30340;&#34892;&#20026;&#65306;&#24403;&#22312;&#30456;&#23545;&#22797;&#26434;&#30340;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#26102;&#65292;&#23427;&#20204;&#20250;&#32473;&#26469;&#33258;&#26356;&#31616;&#21333;&#26469;&#28304;&#30340;&#31163;&#32676;&#25968;&#25454;&#36171;&#20104;&#26356;&#39640;&#30340;&#20284;&#28982;&#20540;&#12290;&#26356;&#20351;&#20154;&#24863;&#21040;&#31070;&#31192;&#30340;&#26159;&#65292;&#23613;&#31649;&#20855;&#26377;&#26356;&#39640;&#30340;&#20284;&#28982;&#20540;&#65292;&#20294;&#36825;&#20123;DGMs&#20174;&#26410;&#29983;&#25104;&#36807;&#31163;&#32676;&#26679;&#26412;&#12290;&#36825;&#20010;&#21452;&#31649;&#40784;&#19979;&#30340;&#24726;&#35770;&#23578;&#26410;&#24471;&#21040;&#26368;&#32456;&#35299;&#37322;&#65292;&#20351;&#24471;&#22522;&#20110;&#20284;&#28982;&#30340;&#31163;&#32676;&#26816;&#27979;&#19981;&#21487;&#38752;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#35266;&#23519;&#26159;&#65292;&#22914;&#26524;&#39640;&#20284;&#28982;&#21306;&#22495;&#20013;&#21253;&#21547;&#20102;&#26368;&#23567;&#27010;&#29575;&#36136;&#37327;&#65292;&#37027;&#20040;&#36825;&#20123;&#21306;&#22495;&#23558;&#19981;&#20250;&#34987;&#29983;&#25104;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#22312;&#22260;&#32469;&#20302;&#32500;&#27969;&#24418;&#25968;&#25454;&#30340;&#22320;&#26041;&#21487;&#33021;&#20986;&#29616;&#22823;&#23494;&#24230;&#20294;&#20302;&#27010;&#29575;&#36136;&#37327;&#30340;&#30475;&#20284;&#30683;&#30462;&#24773;&#20917;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#36890;&#36807;&#26412;&#22320;&#22266;&#26377;&#32500;&#24230;(LID)&#20272;&#35745;&#21487;&#20197;&#35782;&#21035;&#36825;&#31181;&#22330;&#26223;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#39044;&#35757;&#32451;&#30340;DGM&#33719;&#24471;&#30340;&#20284;&#28982;&#21644;LID&#20272;&#35745;&#30456;&#37197;&#23545;&#30340;&#31163;&#32676;&#26816;&#27979;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18910v1 Announce Type: cross  Abstract: Likelihood-based deep generative models (DGMs) commonly exhibit a puzzling behaviour: when trained on a relatively complex dataset, they assign higher likelihood values to out-of-distribution (OOD) data from simpler sources. Adding to the mystery, OOD samples are never generated by these DGMs despite having higher likelihoods. This two-pronged paradox has yet to be conclusively explained, making likelihood-based OOD detection unreliable. Our primary observation is that high-likelihood regions will not be generated if they contain minimal probability mass. We demonstrate how this seeming contradiction of large densities yet low probability mass can occur around data confined to low-dimensional manifolds. We also show that this scenario can be identified through local intrinsic dimension (LID) estimation, and propose a method for OOD detection which pairs the likelihoods and LID estimates obtained from a pre-trained DGM. Our method can b
&lt;/p&gt;</description></item><item><title>&#23558;&#33647;&#29289;SMILES&#23383;&#31526;&#20018;&#35270;&#20026;&#21477;&#23376;&#24182;&#21033;&#29992;&#25991;&#26412;&#20998;&#31867;&#26041;&#27861;&#36827;&#34892;&#33647;&#29289;&#20998;&#31867;&#65292;&#35777;&#23454;&#20102;&#36890;&#36807;&#31616;&#21333;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26041;&#27861;&#35299;&#20915;&#22797;&#26434;&#38382;&#39064;&#30340;&#21487;&#33021;&#24615;</title><link>https://arxiv.org/abs/2403.12984</link><description>&lt;p&gt;
&#24403;SMILES&#25317;&#26377;&#35821;&#35328;&#65306;&#20351;&#29992;&#25991;&#26412;&#20998;&#31867;&#26041;&#27861;&#23545;&#33647;&#29289;SMILES&#23383;&#31526;&#20018;&#36827;&#34892;&#33647;&#29289;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
When SMILES have Language: Drug Classification using Text Classification Methods on Drug SMILES Strings
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12984
&lt;/p&gt;
&lt;p&gt;
&#23558;&#33647;&#29289;SMILES&#23383;&#31526;&#20018;&#35270;&#20026;&#21477;&#23376;&#24182;&#21033;&#29992;&#25991;&#26412;&#20998;&#31867;&#26041;&#27861;&#36827;&#34892;&#33647;&#29289;&#20998;&#31867;&#65292;&#35777;&#23454;&#20102;&#36890;&#36807;&#31616;&#21333;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26041;&#27861;&#35299;&#20915;&#22797;&#26434;&#38382;&#39064;&#30340;&#21487;&#33021;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22797;&#26434;&#30340;&#21270;&#23398;&#32467;&#26500;&#65292;&#22914;&#33647;&#29289;&#65292;&#36890;&#24120;&#30001;SMILES&#23383;&#31526;&#20018;&#26469;&#23450;&#20041;&#65292;&#20316;&#20026;&#20998;&#23376;&#21644;&#38190;&#30340;&#24207;&#21015;&#12290;&#36825;&#20123;SMILES&#23383;&#31526;&#20018;&#22312;&#19981;&#21516;&#30340;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#33647;&#29289;&#30456;&#20851;&#30740;&#31350;&#21644;&#34920;&#31034;&#24037;&#20316;&#20013;&#20351;&#29992;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25670;&#33073;&#22797;&#26434;&#30340;&#34920;&#31034;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#38382;&#39064;&#65306;&#22914;&#26524;&#25105;&#20204;&#23558;&#33647;&#29289;SMILES&#35270;&#20026;&#24120;&#35268;&#21477;&#23376;&#65292;&#24182;&#36827;&#34892;&#25991;&#26412;&#20998;&#31867;&#20197;&#36827;&#34892;&#33647;&#29289;&#20998;&#31867;&#20250;&#24590;&#26679;&#65311;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#23454;&#20102;&#36825;&#31181;&#21487;&#33021;&#24615;&#65292;&#33719;&#24471;&#20102;&#38750;&#24120;&#26377;&#31454;&#20105;&#21147;&#30340;&#20998;&#25968;&#12290;&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#23558;&#27599;&#20010;&#21407;&#23376;&#21644;&#38190;&#35270;&#20026;&#21477;&#23376;&#32452;&#20214;&#30340;&#27010;&#24565;&#65292;&#21033;&#29992;&#22522;&#26412;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26041;&#27861;&#23545;&#33647;&#29289;&#31867;&#22411;&#36827;&#34892;&#20998;&#31867;&#65292;&#34920;&#26126;&#22797;&#26434;&#30340;&#38382;&#39064;&#20063;&#21487;&#20197;&#29992;&#26356;&#31616;&#21333;&#30340;&#35270;&#35282;&#26469;&#35299;&#20915;&#12290;&#25968;&#25454;&#21644;&#20195;&#30721;&#21487;&#22312;&#27492;&#22788;&#25214;&#21040;&#65306;https://github.com/azminewasi/Drug-Classification-NLP&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12984v1 Announce Type: cross  Abstract: Complex chemical structures, like drugs, are usually defined by SMILES strings as a sequence of molecules and bonds. These SMILES strings are used in different complex machine learning-based drug-related research and representation works. Escaping from complex representation, in this work, we pose a single question: What if we treat drug SMILES as conventional sentences and engage in text classification for drug classification? Our experiments affirm the possibility with very competitive scores. The study explores the notion of viewing each atom and bond as sentence components, employing basic NLP methods to categorize drug types, proving that complex problems can also be solved with simpler perspectives. The data and code are available here: https://github.com/azminewasi/Drug-Classification-NLP.
&lt;/p&gt;</description></item><item><title>&#22312;&#38750;&#20809;&#28369;&#35774;&#32622;&#19979;&#65292;&#25552;&#20986;&#20102;&#29992;&#20110;&#35745;&#31639;&#20855;&#26377;&#20869;&#26144;&#23556;&#30340;&#22806;&#26144;&#23556;&#22266;&#23450;&#28857;&#30340;&#38544;&#24335;&#23548;&#25968;&#30340;&#26032;&#26041;&#27861;NSID&#65292;&#24182;&#25552;&#20379;&#20102;&#30830;&#23450;&#24615;&#24773;&#20917;&#19979;&#36845;&#20195;&#24494;&#20998;&#65288;ITD&#65289;&#21644;&#36817;&#20284;&#38544;&#24335;&#24494;&#20998;&#65288;AID&#65289;&#30340;&#25913;&#36827;&#32447;&#24615;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.11687</link><description>&lt;p&gt;
&#38750;&#20809;&#28369;&#38544;&#24335;&#24494;&#20998;&#65306;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#25910;&#25947;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Nonsmooth Implicit Differentiation: Deterministic and Stochastic Convergence Rates
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11687
&lt;/p&gt;
&lt;p&gt;
&#22312;&#38750;&#20809;&#28369;&#35774;&#32622;&#19979;&#65292;&#25552;&#20986;&#20102;&#29992;&#20110;&#35745;&#31639;&#20855;&#26377;&#20869;&#26144;&#23556;&#30340;&#22806;&#26144;&#23556;&#22266;&#23450;&#28857;&#30340;&#38544;&#24335;&#23548;&#25968;&#30340;&#26032;&#26041;&#27861;NSID&#65292;&#24182;&#25552;&#20379;&#20102;&#30830;&#23450;&#24615;&#24773;&#20917;&#19979;&#36845;&#20195;&#24494;&#20998;&#65288;ITD&#65289;&#21644;&#36817;&#20284;&#38544;&#24335;&#24494;&#20998;&#65288;AID&#65289;&#30340;&#25913;&#36827;&#32447;&#24615;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26377;&#25928;&#35745;&#31639;&#21442;&#25968;&#21270;&#19981;&#21487;&#24494;&#25910;&#32553;&#26144;&#23556;&#22266;&#23450;&#28857;&#23548;&#25968;&#30340;&#38382;&#39064;&#12290;&#36825;&#20010;&#38382;&#39064;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#65292;&#21253;&#25324;&#36229;&#21442;&#25968;&#20248;&#21270;&#12289;&#20803;&#23398;&#20064;&#21644;&#25968;&#25454;&#27745;&#26579;&#25915;&#20987;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#20004;&#31181;&#27969;&#34892;&#30340;&#26041;&#27861;&#65306;&#36845;&#20195;&#24494;&#20998;&#65288;ITD&#65289;&#21644;&#36817;&#20284;&#38544;&#24335;&#24494;&#20998;&#65288;AID&#65289;&#12290;&#22312;&#38750;&#20809;&#28369;&#35774;&#32622;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#26159;&#38142;&#35268;&#21017;&#19981;&#20877;&#25104;&#31435;&#12290;&#22312;Bolte&#31561;&#20154;&#65288;2022&#65289;&#26368;&#36817;&#30340;&#24037;&#20316;&#22522;&#30784;&#19978;&#65292;&#20182;&#20204;&#35777;&#26126;&#20102;&#19981;&#21487;&#24494;&#20998;ITD&#30340;&#32447;&#24615;&#25910;&#25947;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#30830;&#23450;&#24615;&#24773;&#20917;&#19979;ITD&#21644;AID&#30340;&#25913;&#36827;&#32447;&#24615;&#25910;&#25947;&#36895;&#29575;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#20171;&#32461;&#20102;NSID&#65292;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22266;&#23450;&#28857;&#34987;&#23450;&#20041;&#20026;&#21482;&#36890;&#36807;&#38543;&#26426;&#26080;&#20559;&#20272;&#35745;&#22120;&#35775;&#38382;&#30340;&#22806;&#26144;&#23556;&#21644;&#20869;&#26144;&#23556;&#30340;&#32452;&#21512;&#26102;&#35745;&#31639;&#38544;&#24335;&#23548;&#25968;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#35813;&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11687v1 Announce Type: cross  Abstract: We study the problem of efficiently computing the derivative of the fixed-point of a parametric non-differentiable contraction map. This problem has wide applications in machine learning, including hyperparameter optimization, meta-learning and data poisoning attacks. We analyze two popular approaches: iterative differentiation (ITD) and approximate implicit differentiation (AID). A key challenge behind the nonsmooth setting is that the chain rule does not hold anymore. Building upon the recent work by Bolte et al. (2022), who proved the linear convergence of non-differentiable ITD, we provide refined linear convergence rates for both ITD and AID in the deterministic case. We further introduce NSID, a new method to compute the implicit derivative when the fixed point is defined as the composition of an outer map and an inner map which is accessible only through a stochastic unbiased estimator. We establish rates for the convergence of 
&lt;/p&gt;</description></item><item><title>CAS&#26694;&#26550;&#20801;&#35768;&#22312;&#22312;&#32447;&#36873;&#25321;&#24615;&#39044;&#27979;&#20013;&#25511;&#21046;FCR&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#36873;&#25321;&#21644;&#26657;&#20934;&#38598;&#26500;&#36896;&#36755;&#20986;&#31526;&#21512;&#39044;&#27979;&#21306;&#38388;</title><link>https://arxiv.org/abs/2403.07728</link><description>&lt;p&gt;
CAS: &#19968;&#31181;&#20855;&#26377;FCR&#25511;&#21046;&#30340;&#22312;&#32447;&#36873;&#25321;&#24615;&#31526;&#21512;&#39044;&#27979;&#30340;&#36890;&#29992;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
CAS: A General Algorithm for Online Selective Conformal Prediction with FCR Control
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07728
&lt;/p&gt;
&lt;p&gt;
CAS&#26694;&#26550;&#20801;&#35768;&#22312;&#22312;&#32447;&#36873;&#25321;&#24615;&#39044;&#27979;&#20013;&#25511;&#21046;FCR&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#36873;&#25321;&#21644;&#26657;&#20934;&#38598;&#26500;&#36896;&#36755;&#20986;&#31526;&#21512;&#39044;&#27979;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#26041;&#24335;&#19979;&#21518;&#36873;&#25321;&#39044;&#27979;&#25512;&#26029;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#36991;&#20813;&#23558;&#36164;&#28304;&#32791;&#36153;&#22312;&#19981;&#37325;&#35201;&#30340;&#21333;&#20301;&#19978;&#65292;&#22312;&#25253;&#21578;&#20854;&#39044;&#27979;&#21306;&#38388;&#20043;&#21069;&#23545;&#24403;&#21069;&#20010;&#20307;&#36827;&#34892;&#21021;&#27493;&#36873;&#25321;&#22312;&#22312;&#32447;&#39044;&#27979;&#20219;&#21153;&#20013;&#26159;&#24120;&#35265;&#19988;&#26377;&#24847;&#20041;&#30340;&#12290;&#30001;&#20110;&#22312;&#32447;&#36873;&#25321;&#23548;&#33268;&#25152;&#36873;&#39044;&#27979;&#21306;&#38388;&#20013;&#23384;&#22312;&#26102;&#38388;&#22810;&#37325;&#24615;&#65292;&#22240;&#27492;&#25511;&#21046;&#23454;&#26102;&#35823;&#35206;&#30422;&#38472;&#36848;&#29575;&#65288;FCR&#65289;&#26469;&#27979;&#37327;&#24179;&#22343;&#35823;&#35206;&#30422;&#35823;&#24046;&#26159;&#37325;&#35201;&#30340;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#21517;&#20026;CAS&#65288;&#36866;&#24212;&#24615;&#36873;&#25321;&#21518;&#26657;&#20934;&#65289;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#21487;&#20197;&#21253;&#35065;&#20219;&#20309;&#39044;&#27979;&#27169;&#22411;&#21644;&#22312;&#32447;&#36873;&#25321;&#35268;&#21017;&#65292;&#20197;&#36755;&#20986;&#21518;&#36873;&#25321;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;&#22914;&#26524;&#36873;&#25321;&#20102;&#24403;&#21069;&#20010;&#20307;&#65292;&#25105;&#20204;&#39318;&#20808;&#23545;&#21382;&#21490;&#25968;&#25454;&#36827;&#34892;&#33258;&#36866;&#24212;&#36873;&#25321;&#26469;&#26500;&#24314;&#26657;&#20934;&#38598;&#65292;&#28982;&#21518;&#20026;&#26410;&#35266;&#23519;&#21040;&#30340;&#26631;&#31614;&#36755;&#20986;&#31526;&#21512;&#39044;&#27979;&#21306;&#38388;&#12290;&#25105;&#20204;&#20026;&#26657;&#20934;&#38598;&#25552;&#20379;&#20102;&#21487;&#34892;&#30340;&#26500;&#36896;&#26041;&#24335;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07728v1 Announce Type: cross  Abstract: We study the problem of post-selection predictive inference in an online fashion. To avoid devoting resources to unimportant units, a preliminary selection of the current individual before reporting its prediction interval is common and meaningful in online predictive tasks. Since the online selection causes a temporal multiplicity in the selected prediction intervals, it is important to control the real-time false coverage-statement rate (FCR) to measure the averaged miscoverage error. We develop a general framework named CAS (Calibration after Adaptive Selection) that can wrap around any prediction model and online selection rule to output post-selection prediction intervals. If the current individual is selected, we first perform an adaptive selection on historical data to construct a calibration set, then output a conformal prediction interval for the unobserved label. We provide tractable constructions for the calibration set for 
&lt;/p&gt;</description></item><item><title>&#23545;&#20110;&#21487;&#20998;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#27979;&#24230;&#19982;&#20854;&#32463;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#26368;&#22823;&#20999;&#29255;1-Wasserstein&#36317;&#31163;&#65292;&#24471;&#21040;&#20102;&#23574;&#38160;&#30340;&#19978;&#19979;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2403.00666</link><description>&lt;p&gt;
&#26368;&#22823;&#20999;&#29255;Wasserstein&#36317;&#31163;&#30340;&#23574;&#38160;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Sharp bounds for the max-sliced Wasserstein distance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00666
&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#21487;&#20998;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#27979;&#24230;&#19982;&#20854;&#32463;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#26368;&#22823;&#20999;&#29255;1-Wasserstein&#36317;&#31163;&#65292;&#24471;&#21040;&#20102;&#23574;&#38160;&#30340;&#19978;&#19979;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24471;&#21040;&#20102;&#20851;&#20110;&#22312;&#21487;&#20998;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#27979;&#24230;&#19982;&#20174;$n$&#20010;&#26679;&#26412;&#20013;&#33719;&#24471;&#30340;&#32463;&#39564;&#20998;&#24067;&#20043;&#38388;&#26399;&#26395;&#30340;&#26368;&#22823;&#20999;&#29255;1-Wasserstein&#36317;&#31163;&#30340;&#23574;&#38160;&#19978;&#19979;&#30028;&#12290;&#25105;&#20204;&#36824;&#24471;&#21040;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;Banach&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#27979;&#24230;&#30340;&#29256;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00666v1 Announce Type: cross  Abstract: We obtain sharp upper and lower bounds for the expected max-sliced 1-Wasserstein distance between a probability measure on a separable Hilbert space and its empirical distribution from $n$ samples. A version of this result for probability measures on Banach spaces is also obtained.
&lt;/p&gt;</description></item><item><title>Equilibrium K-Means&#65288;EKM&#65289;&#26159;&#19968;&#31181;&#26032;&#39062;&#19988;&#31616;&#21333;&#30340;K&#22343;&#20540;&#31867;&#22411;&#31639;&#27861;&#65292;&#36890;&#36807;&#20943;&#23569;&#32858;&#31867;&#20013;&#24515;&#22312;&#22823;&#31867;&#31751;&#20013;&#24515;&#32858;&#38598;&#30340;&#20542;&#21521;&#65292;&#26174;&#33879;&#25913;&#21892;&#20102;&#19981;&#24179;&#34913;&#25968;&#25454;&#30340;&#32858;&#31867;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.14490</link><description>&lt;p&gt;
&#20351;&#29992;Equilibrium K-Means&#36827;&#34892;&#19981;&#24179;&#34913;&#25968;&#25454;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Imbalanced Data Clustering using Equilibrium K-Means
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14490
&lt;/p&gt;
&lt;p&gt;
Equilibrium K-Means&#65288;EKM&#65289;&#26159;&#19968;&#31181;&#26032;&#39062;&#19988;&#31616;&#21333;&#30340;K&#22343;&#20540;&#31867;&#22411;&#31639;&#27861;&#65292;&#36890;&#36807;&#20943;&#23569;&#32858;&#31867;&#20013;&#24515;&#22312;&#22823;&#31867;&#31751;&#20013;&#24515;&#32858;&#38598;&#30340;&#20542;&#21521;&#65292;&#26174;&#33879;&#25913;&#21892;&#20102;&#19981;&#24179;&#34913;&#25968;&#25454;&#30340;&#32858;&#31867;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#24179;&#34913;&#25968;&#25454;&#25351;&#30340;&#26159;&#25968;&#25454;&#28857;&#22312;&#19981;&#21516;&#31867;&#21035;&#20043;&#38388;&#20998;&#24067;&#19981;&#22343;&#34913;&#65292;&#36825;&#32473;&#20256;&#32479;&#30340;&#30828;&#32858;&#31867;&#31639;&#27861;&#21644;&#27169;&#31946;&#32858;&#31867;&#31639;&#27861;&#65288;&#22914;&#30828;K&#22343;&#20540;&#65288;HKM&#65292;&#25110;&#32773;Lloyd&#31639;&#27861;&#65289;&#21644;&#27169;&#31946;K&#22343;&#20540;&#65288;FKM&#65292;&#25110;&#32773;Bezdek&#31639;&#27861;&#65289;&#65289;&#24102;&#26469;&#20102;&#25361;&#25112;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#19988;&#31616;&#21333;&#30340;K&#22343;&#20540;&#31867;&#22411;&#31639;&#27861;&#8212;&#8212;Equilibrium K-Means&#65288;EKM&#65289;&#65292;&#23427;&#22312;&#20004;&#20010;&#27493;&#39588;&#20043;&#38388;&#20132;&#26367;&#36827;&#34892;&#65292;&#26174;&#33879;&#25913;&#21892;&#20102;&#19981;&#24179;&#34913;&#25968;&#25454;&#30340;&#32858;&#31867;&#32467;&#26524;&#65292;&#20943;&#23569;&#20102;&#32858;&#31867;&#20013;&#24515;&#21521;&#22823;&#31867;&#31751;&#20013;&#24515;&#32858;&#38598;&#30340;&#20542;&#21521;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#23545;HKM&#12289;FKM&#21644;EKM&#30340;&#32479;&#19968;&#35270;&#35282;&#65292;&#34920;&#26126;&#23427;&#20204;&#26412;&#36136;&#19978;&#26159;&#20855;&#26377;&#26126;&#30830;&#20851;&#31995;&#30340;&#29275;&#39039;&#26041;&#27861;&#30340;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#12290;EKM&#20855;&#26377;&#19982;FKM&#30456;&#21516;&#30340;&#26102;&#38388;&#21644;&#31354;&#38388;&#22797;&#26434;&#24230;&#65292;&#20294;&#23545;&#20854;&#25104;&#21592;&#23450;&#20041;&#25552;&#20379;&#20102;&#26356;&#28165;&#26224;&#30340;&#29289;&#29702;&#24847;&#20041;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#21313;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;EKM&#30340;&#24615;&#33021;&#65292;&#24182;&#23558;&#20854;&#19982;&#21508;&#31181;&#32858;&#31867;&#31639;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14490v1 Announce Type: new  Abstract: Imbalanced data, characterized by an unequal distribution of data points across different clusters, poses a challenge for traditional hard and fuzzy clustering algorithms, such as hard K-means (HKM, or Lloyd's algorithm) and fuzzy K-means (FKM, or Bezdek's algorithm). This paper introduces equilibrium K-means (EKM), a novel and simple K-means-type algorithm that alternates between just two steps, yielding significantly improved clustering results for imbalanced data by reducing the tendency of centroids to crowd together in the center of large clusters. We also present a unifying perspective for HKM, FKM, and EKM, showing they are essentially gradient descent algorithms with an explicit relationship to Newton's method. EKM has the same time and space complexity as FKM but offers a clearer physical meaning for its membership definition. We illustrate the performance of EKM on two synthetic and ten real datasets, comparing it to various cl
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#22522;&#20110;&#26368;&#20248;&#36755;&#36816;&#25200;&#21160;&#30340;&#23433;&#20840;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#26500;&#24314;&#26368;&#22351;&#24773;&#20917;&#30340;&#34394;&#25311;&#29366;&#24577;&#36716;&#25442;&#20197;&#25552;&#21319;&#40065;&#26834;&#24615;&#33021;&#21644;&#23433;&#20840;&#24615;&#12290;</title><link>https://arxiv.org/abs/2301.13375</link><description>&lt;p&gt;
&#20351;&#29992;&#24102;&#26377;&#40065;&#26834;&#24615;&#20445;&#35777;&#30340;&#26368;&#20248;&#36755;&#36816;&#25200;&#21160;&#36827;&#34892;&#23433;&#20840;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Optimal Transport Perturbations for Safe Reinforcement Learning with Robustness Guarantees
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2301.13375
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#22522;&#20110;&#26368;&#20248;&#36755;&#36816;&#25200;&#21160;&#30340;&#23433;&#20840;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#26500;&#24314;&#26368;&#22351;&#24773;&#20917;&#30340;&#34394;&#25311;&#29366;&#24577;&#36716;&#25442;&#20197;&#25552;&#21319;&#40065;&#26834;&#24615;&#33021;&#21644;&#23433;&#20840;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#26368;&#20248;&#36755;&#36816;&#25104;&#26412;&#19981;&#30830;&#23450;&#24615;&#38598;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;&#23433;&#20840;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#24212;&#29992;&#26368;&#20248;&#36755;&#36816;&#25200;&#21160;&#26469;&#26500;&#24314;&#26368;&#22351;&#24773;&#20917;&#30340;&#34394;&#25311;&#29366;&#24577;&#36716;&#25442;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#23454;&#29616;&#26041;&#27861;&#12290;&#22312;&#36830;&#32493;&#25511;&#21046;&#20219;&#21153;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23637;&#31034;&#20102;&#40065;&#26834;&#24615;&#33021;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#20102;&#37096;&#32626;&#26102;&#30340;&#23433;&#20840;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2301.13375v2 Announce Type: replace-cross  Abstract: Robustness and safety are critical for the trustworthy deployment of deep reinforcement learning. Real-world decision making applications require algorithms that can guarantee robust performance and safety in the presence of general environment disturbances, while making limited assumptions on the data collection process during training. In order to accomplish this goal, we introduce a safe reinforcement learning framework that incorporates robustness through the use of an optimal transport cost uncertainty set. We provide an efficient implementation based on applying Optimal Transport Perturbations to construct worst-case virtual state transitions, which does not impact data collection during training and does not require detailed simulator access. In experiments on continuous control tasks with safety constraints, our approach demonstrates robust performance while significantly improving safety at deployment time compared to 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#38543;&#26426;&#20811;&#37324;&#37329;&#30340;&#36125;&#21494;&#26031;&#21452;&#30446;&#26631;&#25490;&#24207;&#21644;&#36873;&#25321;&#26041;&#27861;&#65292;&#20197;&#20943;&#23569;&#22312;&#35782;&#21035;&#20855;&#26377;&#26368;&#20339;&#26399;&#26395;&#24615;&#33021;&#35299;&#26102;&#30340;&#38169;&#35823;&#20998;&#31867;</title><link>https://arxiv.org/abs/2209.03919</link><description>&lt;p&gt;
&#20351;&#29992;&#38543;&#26426;&#20811;&#37324;&#37329;&#30340;&#21452;&#30446;&#26631;&#25490;&#24207;&#21644;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Bi-objective Ranking and Selection Using Stochastic Kriging
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2209.03919
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#38543;&#26426;&#20811;&#37324;&#37329;&#30340;&#36125;&#21494;&#26031;&#21452;&#30446;&#26631;&#25490;&#24207;&#21644;&#36873;&#25321;&#26041;&#27861;&#65292;&#20197;&#20943;&#23569;&#22312;&#35782;&#21035;&#20855;&#26377;&#26368;&#20339;&#26399;&#26395;&#24615;&#33021;&#35299;&#26102;&#30340;&#38169;&#35823;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#21452;&#30446;&#26631;&#25490;&#24207;&#21644;&#36873;&#25321;&#38382;&#39064;&#65292;&#30446;&#26631;&#26159;&#22312;&#35266;&#23519;&#21040;&#20004;&#20010;&#30446;&#26631;&#32467;&#26524;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#20505;&#36873;&#38598;&#20013;&#27491;&#30830;&#35782;&#21035;&#24085;&#32047;&#25176;&#26368;&#20248;&#35299;&#65292;&#20363;&#22914;&#65292;&#22312;&#36816;&#34892;&#22810;&#30446;&#26631;&#38543;&#26426;&#27169;&#25311;&#20248;&#21270;&#36807;&#31243;&#20043;&#21518;&#12290;&#22312;&#35782;&#21035;&#36825;&#20123;&#35299;&#26102;&#65292;&#35266;&#27979;&#24615;&#33021;&#30340;&#22122;&#22768;&#25200;&#21160;&#21487;&#33021;&#23548;&#33268;&#20004;&#31181;&#38169;&#35823;&#65306;&#30495;&#27491;&#24085;&#32047;&#25176;&#26368;&#20248;&#30340;&#35299;&#21487;&#33021;&#34987;&#38169;&#35823;&#22320;&#35748;&#20026;&#26159;&#34987;&#25903;&#37197;&#30340;&#65292;&#32780;&#30495;&#27491;&#34987;&#25903;&#37197;&#30340;&#35299;&#21487;&#33021;&#34987;&#38169;&#35823;&#22320;&#35748;&#20026;&#26159;&#24085;&#32047;&#25176;&#26368;&#20248;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36125;&#21494;&#26031;&#21452;&#30446;&#26631;&#25490;&#24207;&#21644;&#36873;&#25321;&#26041;&#27861;&#65292;&#36890;&#36807;&#39034;&#24207;&#20998;&#37197;&#39069;&#22806;&#26679;&#26412;&#32473;&#31454;&#20105;&#35299;&#65292;&#20197;&#20943;&#23569;&#22312;&#35782;&#21035;&#20855;&#26377;&#26368;&#20339;&#26399;&#26395;&#24615;&#33021;&#30340;&#35299;&#26102;&#30340;&#38169;&#35823;&#20998;&#31867;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#38543;&#26426;&#20811;&#37324;&#37329;&#26500;&#24314;&#23458;&#35266;&#39044;&#27979;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2209.03919v3 Announce Type: replace-cross  Abstract: We consider bi-objective ranking and selection problems, where the goal is to correctly identify the Pareto optimal solutions among a finite set of candidates for which the two objective outcomes have been observed with uncertainty (e.g., after running a multiobjective stochastic simulation optimization procedure). When identifying these solutions, the noise perturbing the observed performance may lead to two types of errors: solutions that are truly Pareto-optimal can be wrongly considered dominated, and solutions that are truly dominated can be wrongly considered Pareto-optimal. We propose a novel Bayesian bi-objective ranking and selection method that sequentially allocates extra samples to competitive solutions, in view of reducing the misclassification errors when identifying the solutions with the best expected performance. The approach uses stochastic kriging to build reliable predictive distributions of the objective ou
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#26368;&#22823;&#25928;&#29992;&#30340;&#33218;&#36873;&#25321;&#31574;&#30053;&#65292;&#20197;&#20943;&#23569;&#22312;&#24207;&#21015;&#26597;&#35810;&#25512;&#33616;&#20013;&#30340;&#32047;&#31215;&#36951;&#25022;&#12290;</title><link>https://arxiv.org/abs/2108.13810</link><description>&lt;p&gt;
&#22522;&#20110;&#26368;&#22823;&#25928;&#29992;&#30340;&#24207;&#21015;&#26597;&#35810;&#25512;&#33616;&#20013;&#30340;&#33218;&#36873;&#25321;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Max-Utility Based Arm Selection Strategy For Sequential Query Recommendations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2108.13810
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#26368;&#22823;&#25928;&#29992;&#30340;&#33218;&#36873;&#25321;&#31574;&#30053;&#65292;&#20197;&#20943;&#23569;&#22312;&#24207;&#21015;&#26597;&#35810;&#25512;&#33616;&#20013;&#30340;&#32047;&#31215;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#38381;&#29615;&#20132;&#20114;&#24335;&#23398;&#20064;&#35774;&#32622;&#20013;&#30340;&#26597;&#35810;&#25512;&#33616;&#38382;&#39064;&#65292;&#20363;&#22914;&#22312;&#32447;&#20449;&#24687;&#25910;&#38598;&#21644;&#25506;&#32034;&#20998;&#26512;&#12290;&#35813;&#38382;&#39064;&#21487;&#20197;&#33258;&#28982;&#22320;&#20351;&#29992;&#22810;&#33218;&#32769;&#34382;&#26426;&#65288;MAB&#65289;&#26694;&#26550;&#26469;&#24314;&#27169;&#65292;&#20854;&#20013;&#26377;&#21487;&#25968;&#20010;&#33218;&#12290;&#26631;&#20934;&#30340;&#21487;&#25968;&#33218;MAB&#31639;&#27861;&#20174;&#36873;&#25321;&#19968;&#20010;&#38543;&#26426;&#30340;&#20505;&#36873;&#33218;&#38598;&#24320;&#22987;&#65292;&#28982;&#21518;&#22312;&#36825;&#20010;&#20505;&#36873;&#38598;&#21512;&#19978;&#24212;&#29992;&#26631;&#20934;&#30340;MAB&#31639;&#27861;&#65292;&#20363;&#22914;UCB&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#26679;&#30340;&#36873;&#25321;&#31574;&#30053;&#36890;&#24120;&#20250;&#23548;&#33268;&#26356;&#39640;&#30340;&#32047;&#31215;&#36951;&#25022;&#65292;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33218;&#30340;&#26368;&#22823;&#25928;&#29992;&#30340;&#36873;&#25321;&#31574;&#30053;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#35832;&#22914;&#22312;&#32447;&#20449;&#24687;&#25910;&#38598;&#36825;&#26679;&#30340;&#20219;&#21153;&#20013;&#65292;&#20854;&#20013;&#37319;&#29992;&#20102;&#24207;&#21015;&#26597;&#35810;&#25512;&#33616;&#65292;&#26597;&#35810;&#24207;&#21015;&#26159;&#30456;&#20851;&#30340;&#65292;&#24182;&#19988;&#36890;&#36807;&#36873;&#25321;&#30456;&#23545;&#20110;&#24403;&#21069;&#25191;&#34892;&#26597;&#35810;&#20855;&#26377;&#26368;&#22823;&#25928;&#29992;&#30340;&#26597;&#35810;&#65292;&#21487;&#20197;&#23558;&#28508;&#22312;&#26368;&#20339;&#26597;&#35810;&#30340;&#25968;&#37327;&#20943;&#23569;&#21040;&#19968;&#20010;&#21487;&#31649;&#29702;&#30340;&#22823;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2108.13810v1 Announce Type: cross  Abstract: We consider the query recommendation problem in closed loop interactive learning settings like online information gathering and exploratory analytics. The problem can be naturally modelled using the Multi-Armed Bandits (MAB) framework with countably many arms. The standard MAB algorithms for countably many arms begin with selecting a random set of candidate arms and then applying standard MAB algorithms, e.g., UCB, on this candidate set downstream. We show that such a selection strategy often results in higher cumulative regret and to this end, we propose a selection strategy based on the maximum utility of the arms. We show that in tasks like online information gathering, where sequential query recommendations are employed, the sequences of queries are correlated and the number of potentially optimal queries can be reduced to a manageable size by selecting queries with maximum utility with respect to the currently executing query. Our
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#20110;&#36830;&#32493;&#20989;&#25968;&#22312;&#32039;&#33268;&#22495;&#19978;&#30340;&#36890;&#29992;&#36924;&#36817;&#22120;&#30340;&#20005;&#26684;&#35777;&#26126;&#65292;&#22635;&#34917;&#20102;&#21333;&#23618;&#31070;&#32463;&#32593;&#32476;&#38543;&#26426;&#21521;&#37327;&#21151;&#33021;&#38142;&#25509;&#32593;&#32476;&#22312;&#23454;&#36341;&#20013;&#25104;&#21151;&#30340;&#29702;&#35770;&#32570;&#21475;</title><link>https://arxiv.org/abs/2007.15776</link><description>&lt;p&gt;
&#29992;&#20110;&#27969;&#24418;&#19978;&#20989;&#25968;&#36924;&#36817;&#30340;&#38543;&#26426;&#21521;&#37327;&#21151;&#33021;&#38142;&#25509;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Random Vector Functional Link Networks for Function Approximation on Manifolds
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2007.15776
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#20110;&#36830;&#32493;&#20989;&#25968;&#22312;&#32039;&#33268;&#22495;&#19978;&#30340;&#36890;&#29992;&#36924;&#36817;&#22120;&#30340;&#20005;&#26684;&#35777;&#26126;&#65292;&#22635;&#34917;&#20102;&#21333;&#23618;&#31070;&#32463;&#32593;&#32476;&#38543;&#26426;&#21521;&#37327;&#21151;&#33021;&#38142;&#25509;&#32593;&#32476;&#22312;&#23454;&#36341;&#20013;&#25104;&#21151;&#30340;&#29702;&#35770;&#32570;&#21475;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
feed-forward&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#36895;&#24230;&#22240;&#24930;&#32780;&#33879;&#21517;&#65292;&#22312;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#20013;&#24050;&#32463;&#25104;&#20026;&#29942;&#39048;&#25968;&#21313;&#24180;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#19968;&#38382;&#39064;&#65292;&#30740;&#31350;&#20154;&#21592;&#21644;&#23454;&#36341;&#32773;&#23581;&#35797;&#24341;&#20837;&#38543;&#26426;&#24615;&#26469;&#20943;&#23569;&#23398;&#20064;&#38656;&#27714;&#12290;&#22522;&#20110;Igelnik&#21644;Pao&#30340;&#21407;&#22987;&#26500;&#36896;&#65292;&#20855;&#26377;&#38543;&#26426;&#36755;&#20837;&#21040;&#38544;&#34255;&#23618;&#26435;&#37325;&#21644;&#20559;&#32622;&#30340;&#21333;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#25104;&#21151;&#65292;&#20294;&#32570;&#20047;&#24517;&#35201;&#30340;&#29702;&#35770;&#35777;&#26126;&#12290;&#26412;&#25991;&#22635;&#34917;&#20102;&#36825;&#19968;&#29702;&#35770;&#31354;&#30333;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#65288;&#26356;&#27491;&#30340;&#65289;&#20005;&#26684;&#35777;&#26126;&#65292;&#35777;&#26126;Igelnik&#21644;Pao&#30340;&#26500;&#36896;&#26159;&#19968;&#20010;&#36830;&#32493;&#20989;&#25968;&#22312;&#32039;&#33268;&#22495;&#19978;&#30340;&#36890;&#29992;&#36924;&#36817;&#22120;&#65292;&#36924;&#36817;&#35823;&#24046;&#20687;&#28176;&#36817;&#34928;&#20943;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2007.15776v3 Announce Type: replace-cross  Abstract: The learning speed of feed-forward neural networks is notoriously slow and has presented a bottleneck in deep learning applications for several decades. For instance, gradient-based learning algorithms, which are used extensively to train neural networks, tend to work slowly when all of the network parameters must be iteratively tuned. To counter this, both researchers and practitioners have tried introducing randomness to reduce the learning requirement. Based on the original construction of Igelnik and Pao, single layer neural-networks with random input-to-hidden layer weights and biases have seen success in practice, but the necessary theoretical justification is lacking. In this paper, we begin to fill this theoretical gap. We provide a (corrected) rigorous proof that the Igelnik and Pao construction is a universal approximator for continuous functions on compact domains, with approximation error decaying asymptotically lik
&lt;/p&gt;</description></item><item><title>SWoTTeD&#26159;&#19968;&#31181;&#25193;&#23637;&#30340;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;&#65292;&#29992;&#20110;&#21457;&#29616;&#22797;&#26434;&#26102;&#38388;&#27169;&#24335;&#19979;&#30340;&#38544;&#34255;&#34920;&#24449;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;SWoTTeD&#19981;&#20165;&#33021;&#19982;&#26368;&#26032;&#30340;&#22522;&#20110;&#24352;&#37327;&#20998;&#35299;&#30340;&#26041;&#27861;&#19968;&#26679;&#20934;&#30830;&#22320;&#37325;&#24314;&#25968;&#25454;&#65292;&#36824;&#33021;&#25552;&#21462;&#20986;&#23545;&#20020;&#24202;&#21307;&#29983;&#26377;&#24847;&#20041;&#30340;&#26102;&#38388;&#34920;&#24449;&#12290;</title><link>http://arxiv.org/abs/2310.01201</link><description>&lt;p&gt;
SWoTTeD:&#24352;&#37327;&#20998;&#35299;&#22312;&#26102;&#38388;&#34920;&#24449;&#20013;&#30340;&#25193;&#23637;
&lt;/p&gt;
&lt;p&gt;
SWoTTeD: An Extension of Tensor Decomposition to Temporal Phenotyping. (arXiv:2310.01201v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01201
&lt;/p&gt;
&lt;p&gt;
SWoTTeD&#26159;&#19968;&#31181;&#25193;&#23637;&#30340;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;&#65292;&#29992;&#20110;&#21457;&#29616;&#22797;&#26434;&#26102;&#38388;&#27169;&#24335;&#19979;&#30340;&#38544;&#34255;&#34920;&#24449;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;SWoTTeD&#19981;&#20165;&#33021;&#19982;&#26368;&#26032;&#30340;&#22522;&#20110;&#24352;&#37327;&#20998;&#35299;&#30340;&#26041;&#27861;&#19968;&#26679;&#20934;&#30830;&#22320;&#37325;&#24314;&#25968;&#25454;&#65292;&#36824;&#33021;&#25552;&#21462;&#20986;&#23545;&#20020;&#24202;&#21307;&#29983;&#26377;&#24847;&#20041;&#30340;&#26102;&#38388;&#34920;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24352;&#37327;&#20998;&#35299;&#26368;&#36817;&#22312;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#23545;&#20110;&#20010;&#20307;&#36861;&#36394;&#25968;&#25454;&#30340;&#20998;&#26512;&#65292;&#22914;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;(EHR)&#65292;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#24403;&#25968;&#25454;&#36981;&#24490;&#22797;&#26434;&#30340;&#26102;&#38388;&#27169;&#24335;&#26102;&#65292;&#36825;&#20010;&#20219;&#21153;&#21464;&#24471;&#26356;&#21152;&#22256;&#38590;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#26102;&#38388;&#34920;&#24449;&#30340;&#27010;&#24565;&#65292;&#21363;&#19968;&#32452;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#29305;&#24449;&#65292;&#24182;&#25552;&#20986;&#20102;SWoTTeD (Sliding Window for Temporal Tensor Decomposition)&#26041;&#27861;&#65292;&#19968;&#31181;&#21457;&#29616;&#38544;&#34255;&#26102;&#38388;&#27169;&#24335;&#30340;&#26032;&#26041;&#27861;&#12290;SWoTTeD&#38598;&#25104;&#20102;&#22810;&#31181;&#32422;&#26463;&#21644;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#20197;&#22686;&#24378;&#25552;&#21462;&#21040;&#30340;&#34920;&#24449;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#36827;&#34892;&#39564;&#35777;&#65292;&#24182;&#25552;&#20379;&#20102;&#20351;&#29992;&#24052;&#40654;&#22823;&#23398;&#21307;&#38498;&#30340;&#25968;&#25454;&#30340;&#21407;&#22987;&#29992;&#20363;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;SWoTTeD&#33021;&#22815;&#33267;&#23569;&#19982;&#26368;&#26032;&#30340;&#22522;&#20110;&#24352;&#37327;&#20998;&#35299;&#30340;&#27169;&#22411;&#19968;&#26679;&#20934;&#30830;&#22320;&#37325;&#24314;&#25968;&#25454;&#65292;&#24182;&#25552;&#21462;&#21040;&#23545;&#20020;&#24202;&#21307;&#29983;&#26377;&#24847;&#20041;&#30340;&#26102;&#38388;&#34920;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tensor decomposition has recently been gaining attention in the machine learning community for the analysis of individual traces, such as Electronic Health Records (EHR). However, this task becomes significantly more difficult when the data follows complex temporal patterns. This paper introduces the notion of a temporal phenotype as an arrangement of features over time and it proposes SWoTTeD (Sliding Window for Temporal Tensor Decomposition), a novel method to discover hidden temporal patterns. SWoTTeD integrates several constraints and regularizations to enhance the interpretability of the extracted phenotypes. We validate our proposal using both synthetic and real-world datasets, and we present an original usecase using data from the Greater Paris University Hospital. The results show that SWoTTeD achieves at least as accurate reconstruction as recent state-of-the-art tensor decomposition models, and extracts temporal phenotypes that are meaningful for clinicians.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#36827;&#34892;&#20449;&#36947;&#20272;&#35745;&#65292;&#36890;&#36807;&#23545;&#26465;&#20214;&#39640;&#26031;&#20449;&#36947;&#27169;&#22411;&#30340;&#20869;&#37096;&#32467;&#26500;&#36827;&#34892;&#21442;&#25968;&#21270;&#36924;&#36817;&#26469;&#33719;&#24471;&#22343;&#26041;&#26681;&#35823;&#24046;&#26368;&#20248;&#20449;&#36947;&#20272;&#35745;&#22120;&#65292;&#21516;&#26102;&#32473;&#20986;&#20102;&#22522;&#20110;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#20272;&#35745;&#22120;&#30340;&#23454;&#29992;&#24615;&#32771;&#34385;&#21644;&#19977;&#31181;&#19981;&#21516;&#35757;&#32451;&#26041;&#24335;&#30340;&#20272;&#35745;&#22120;&#21464;&#20307;&#12290;</title><link>http://arxiv.org/abs/2307.05352</link><description>&lt;p&gt;
&#21033;&#29992;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#36827;&#34892;&#21442;&#25968;&#21270;MMSE&#20449;&#36947;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Leveraging Variational Autoencoders for Parameterized MMSE Channel Estimation. (arXiv:2307.05352v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05352
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#36827;&#34892;&#20449;&#36947;&#20272;&#35745;&#65292;&#36890;&#36807;&#23545;&#26465;&#20214;&#39640;&#26031;&#20449;&#36947;&#27169;&#22411;&#30340;&#20869;&#37096;&#32467;&#26500;&#36827;&#34892;&#21442;&#25968;&#21270;&#36924;&#36817;&#26469;&#33719;&#24471;&#22343;&#26041;&#26681;&#35823;&#24046;&#26368;&#20248;&#20449;&#36947;&#20272;&#35745;&#22120;&#65292;&#21516;&#26102;&#32473;&#20986;&#20102;&#22522;&#20110;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#20272;&#35745;&#22120;&#30340;&#23454;&#29992;&#24615;&#32771;&#34385;&#21644;&#19977;&#31181;&#19981;&#21516;&#35757;&#32451;&#26041;&#24335;&#30340;&#20272;&#35745;&#22120;&#21464;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#21033;&#29992;&#22522;&#20110;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#36827;&#34892;&#20449;&#36947;&#20272;&#35745;&#12290;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#20197;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#24335;&#23558;&#30495;&#23454;&#20294;&#26410;&#30693;&#30340;&#20449;&#36947;&#20998;&#24067;&#24314;&#27169;&#20026;&#26465;&#20214;&#39640;&#26031;&#20998;&#24067;&#12290;&#25152;&#24471;&#21040;&#30340;&#20449;&#36947;&#20272;&#35745;&#22120;&#21033;&#29992;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#20869;&#37096;&#32467;&#26500;&#23545;&#26469;&#33258;&#26465;&#20214;&#39640;&#26031;&#20449;&#36947;&#27169;&#22411;&#30340;&#22343;&#26041;&#35823;&#24046;&#26368;&#20248;&#20272;&#35745;&#22120;&#36827;&#34892;&#21442;&#25968;&#21270;&#36924;&#36817;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#20998;&#26512;&#65292;&#20197;&#30830;&#23450;&#20160;&#20040;&#26465;&#20214;&#19979;&#22522;&#20110;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#20272;&#35745;&#22120;&#26159;&#22343;&#26041;&#35823;&#24046;&#26368;&#20248;&#30340;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#22522;&#20110;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#20272;&#35745;&#22120;&#23454;&#29992;&#30340;&#32771;&#34385;&#22240;&#32032;&#65292;&#24182;&#25552;&#20986;&#20102;&#19977;&#31181;&#19981;&#21516;&#30340;&#20272;&#35745;&#22120;&#21464;&#20307;&#65292;&#23427;&#20204;&#22312;&#35757;&#32451;&#21644;&#35780;&#20272;&#38454;&#27573;&#23545;&#20449;&#36947;&#30693;&#35782;&#30340;&#33719;&#21462;&#26041;&#24335;&#19981;&#21516;&#12290;&#29305;&#21035;&#22320;&#65292;&#20165;&#22522;&#20110;&#22122;&#22768;&#23548;&#39057;&#35266;&#27979;&#36827;&#34892;&#35757;&#32451;&#30340;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#21464;&#20307;&#38750;&#24120;&#20540;&#24471;&#27880;&#24847;&#65292;&#22240;&#20026;&#23427;&#19981;&#38656;&#35201;&#33719;&#21462;&#20449;&#36947;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this manuscript, we propose to utilize the generative neural network-based variational autoencoder for channel estimation. The variational autoencoder models the underlying true but unknown channel distribution as a conditional Gaussian distribution in a novel way. The derived channel estimator exploits the internal structure of the variational autoencoder to parameterize an approximation of the mean squared error optimal estimator resulting from the conditional Gaussian channel models. We provide a rigorous analysis under which conditions a variational autoencoder-based estimator is mean squared error optimal. We then present considerations that make the variational autoencoder-based estimator practical and propose three different estimator variants that differ in their access to channel knowledge during the training and evaluation phase. In particular, the proposed estimator variant trained solely on noisy pilot observations is particularly noteworthy as it does not require access
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32593;&#32476;&#29615;&#22659;&#20013;&#30340;&#20998;&#24067;&#24335;&#20272;&#35745;&#21644;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#20132;&#25442;&#31169;&#26377;&#35266;&#27979;&#20449;&#24687;&#65292;&#20195;&#29702;&#21487;&#20197;&#38598;&#20307;&#20272;&#35745;&#26410;&#30693;&#25968;&#37327;&#65292;&#32780;&#20445;&#25252;&#38544;&#31169;&#12290;&#36890;&#36807;&#32447;&#24615;&#32858;&#21512;&#26041;&#26696;&#21644;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#35843;&#25972;&#30340;&#38543;&#26426;&#21270;&#26041;&#26696;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#20445;&#35777;&#38544;&#31169;&#30340;&#21516;&#26102;&#39640;&#25928;&#32452;&#21512;&#35266;&#27979;&#25968;&#25454;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.15865</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#20998;&#24067;&#24335;&#20272;&#35745;&#21644;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Distributed Estimation and Learning. (arXiv:2306.15865v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15865
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32593;&#32476;&#29615;&#22659;&#20013;&#30340;&#20998;&#24067;&#24335;&#20272;&#35745;&#21644;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#20132;&#25442;&#31169;&#26377;&#35266;&#27979;&#20449;&#24687;&#65292;&#20195;&#29702;&#21487;&#20197;&#38598;&#20307;&#20272;&#35745;&#26410;&#30693;&#25968;&#37327;&#65292;&#32780;&#20445;&#25252;&#38544;&#31169;&#12290;&#36890;&#36807;&#32447;&#24615;&#32858;&#21512;&#26041;&#26696;&#21644;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#35843;&#25972;&#30340;&#38543;&#26426;&#21270;&#26041;&#26696;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#20445;&#35777;&#38544;&#31169;&#30340;&#21516;&#26102;&#39640;&#25928;&#32452;&#21512;&#35266;&#27979;&#25968;&#25454;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32593;&#32476;&#29615;&#22659;&#20013;&#30340;&#20998;&#24067;&#24335;&#20272;&#35745;&#21644;&#23398;&#20064;&#38382;&#39064;&#65292;&#20854;&#20013;&#20195;&#29702;&#36890;&#36807;&#20132;&#25442;&#20449;&#24687;&#26469;&#20272;&#35745;&#20174;&#20854;&#31169;&#19979;&#35266;&#23519;&#30340;&#26679;&#26412;&#20013;&#26410;&#30693;&#30340;&#32479;&#35745;&#23646;&#24615;&#12290;&#36890;&#36807;&#20132;&#25442;&#31169;&#26377;&#35266;&#27979;&#20449;&#24687;&#65292;&#20195;&#29702;&#21487;&#20197;&#38598;&#20307;&#20272;&#35745;&#26410;&#30693;&#25968;&#37327;&#65292;&#20294;&#20182;&#20204;&#20063;&#38754;&#20020;&#38544;&#31169;&#39118;&#38505;&#12290;&#25105;&#20204;&#30340;&#32858;&#21512;&#26041;&#26696;&#30340;&#30446;&#26631;&#26159;&#22312;&#26102;&#38388;&#21644;&#32593;&#32476;&#20013;&#39640;&#25928;&#22320;&#32452;&#21512;&#35266;&#27979;&#25968;&#25454;&#65292;&#21516;&#26102;&#28385;&#36275;&#20195;&#29702;&#30340;&#38544;&#31169;&#38656;&#27714;&#65292;&#32780;&#19981;&#38656;&#35201;&#20219;&#20309;&#36229;&#36234;&#20182;&#20204;&#26412;&#22320;&#38468;&#36817;&#30340;&#21327;&#35843;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20351;&#21442;&#19982;&#30340;&#20195;&#29702;&#33021;&#22815;&#20174;&#31163;&#32447;&#25110;&#38543;&#26102;&#38388;&#22312;&#32447;&#33719;&#21462;&#30340;&#31169;&#26377;&#20449;&#21495;&#20013;&#20272;&#35745;&#23436;&#25972;&#30340;&#20805;&#20998;&#32479;&#35745;&#37327;&#65292;&#24182;&#20445;&#25252;&#20854;&#20449;&#21495;&#21644;&#32593;&#32476;&#38468;&#36817;&#30340;&#38544;&#31169;&#12290;&#36825;&#26159;&#36890;&#36807;&#32447;&#24615;&#32858;&#21512;&#26041;&#26696;&#21644;&#35843;&#25972;&#30340;&#38543;&#26426;&#21270;&#26041;&#26696;&#23454;&#29616;&#30340;&#65292;&#23558;&#22122;&#22768;&#28155;&#21152;&#21040;&#20132;&#25442;&#30340;&#20272;&#35745;&#25968;&#25454;&#20013;&#20197;&#28385;&#36275;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study distributed estimation and learning problems in a networked environment in which agents exchange information to estimate unknown statistical properties of random variables from their privately observed samples. By exchanging information about their private observations, the agents can collectively estimate the unknown quantities, but they also face privacy risks. The goal of our aggregation schemes is to combine the observed data efficiently over time and across the network, while accommodating the privacy needs of the agents and without any coordination beyond their local neighborhoods. Our algorithms enable the participating agents to estimate a complete sufficient statistic from private signals that are acquired offline or online over time, and to preserve the privacy of their signals and network neighborhoods. This is achieved through linear aggregation schemes with adjusted randomization schemes that add noise to the exchanged estimates subject to differential privacy (DP
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22312;&#33258;&#32534;&#30721;&#22120;&#30340;&#25439;&#22833;&#20989;&#25968;&#20013;&#28155;&#21152;&#19968;&#20010;&#36731;&#37327;&#32423;&#30340;&#32422;&#26463;&#39033;&#65292;&#29992;&#20110;&#35299;&#20915;&#20256;&#32479;&#33258;&#32534;&#30721;&#22120;&#22312;&#24322;&#24120;&#26816;&#27979;&#20013;&#30340;&#19981;&#36275;&#65292;&#24182;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.12627</link><description>&lt;p&gt;
&#38024;&#23545;&#24322;&#24120;&#26816;&#27979;&#30340;&#30446;&#26631;&#22604;&#32553;&#27491;&#21017;&#21270;&#33258;&#32534;&#30721;&#22120;&#65306;&#20013;&#24515;&#30340;&#40657;&#27934;
&lt;/p&gt;
&lt;p&gt;
Targeted collapse regularized autoencoder for anomaly detection: black hole at the center. (arXiv:2306.12627v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12627
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22312;&#33258;&#32534;&#30721;&#22120;&#30340;&#25439;&#22833;&#20989;&#25968;&#20013;&#28155;&#21152;&#19968;&#20010;&#36731;&#37327;&#32423;&#30340;&#32422;&#26463;&#39033;&#65292;&#29992;&#20110;&#35299;&#20915;&#20256;&#32479;&#33258;&#32534;&#30721;&#22120;&#22312;&#24322;&#24120;&#26816;&#27979;&#20013;&#30340;&#19981;&#36275;&#65292;&#24182;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#32534;&#30721;&#22120;&#24050;&#24191;&#27867;&#29992;&#20110;&#26368;&#36817;&#30340;&#24322;&#24120;&#26816;&#27979;&#25216;&#26415;&#24320;&#21457;&#20013;&#12290;&#23427;&#20204;&#30340;&#24212;&#29992;&#21069;&#25552;&#26159;&#22312;&#27491;&#24120;&#35757;&#32451;&#25968;&#25454;&#19978;&#35757;&#32451;&#33258;&#32534;&#30721;&#22120;&#21518;&#65292;&#24322;&#24120;&#36755;&#20837;&#23558;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#37325;&#26500;&#35823;&#24046;&#12290;&#22240;&#27492;&#65292;&#36825;&#20351;&#24471;&#27491;&#24120;&#21644;&#24322;&#24120;&#26679;&#26412;&#20043;&#38388;&#26377;&#20102;&#26126;&#26174;&#30340;&#21306;&#21035;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#35266;&#23519;&#21040;&#65292;&#33258;&#32534;&#30721;&#22120;&#21487;&#20197;&#19968;&#23450;&#31243;&#24230;&#19978;&#27867;&#21270;&#21040;&#27491;&#24120;&#31867;&#20043;&#22806;&#65292;&#24182;&#22312;&#19968;&#20123;&#24322;&#24120;&#26679;&#26412;&#19978;&#23454;&#29616;&#36739;&#23567;&#30340;&#37325;&#26500;&#35823;&#24046;&#12290;&#20026;&#20102;&#25913;&#21892;&#24615;&#33021;&#65292;&#21508;&#31181;&#25216;&#26415;&#25552;&#20986;&#20102;&#20854;&#20182;&#32452;&#20214;&#21644;&#26356;&#22797;&#26434;&#30340;&#35757;&#32451;&#31243;&#24207;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#24120;&#31616;&#21333;&#30340;&#26367;&#20195;&#26041;&#27861;&#65306;&#19981;&#26159;&#28155;&#21152;&#31070;&#32463;&#32593;&#32476;&#32452;&#20214;&#12289;&#28041;&#21450;&#35745;&#31639;&#21644;&#32321;&#29712;&#30340;&#35757;&#32451;&#65292;&#32780;&#26159;&#36890;&#36807;&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#35843;&#33410;&#34920;&#31034;&#30340;&#33539;&#25968;&#65292;&#29992;&#19968;&#20010;&#35745;&#31639;&#31616;&#21333;&#30340;&#39033;&#26469;&#34917;&#20805;&#37325;&#26500;&#25439;&#22833;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#31616;&#21333;&#24615;&#26368;&#23567;&#21270;&#20102;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Autoencoders have been extensively used in the development of recent anomaly detection techniques. The premise of their application is based on the notion that after training the autoencoder on normal training data, anomalous inputs will exhibit a significant reconstruction error. Consequently, this enables a clear differentiation between normal and anomalous samples. In practice, however, it is observed that autoencoders can generalize beyond the normal class and achieve a small reconstruction error on some of the anomalous samples. To improve the performance, various techniques propose additional components and more sophisticated training procedures. In this work, we propose a remarkably straightforward alternative: instead of adding neural network components, involved computations, and cumbersome training, we complement the reconstruction loss with a computationally light term that regulates the norm of representations in the latent space. The simplicity of our approach minimizes th
&lt;/p&gt;</description></item></channel></rss>