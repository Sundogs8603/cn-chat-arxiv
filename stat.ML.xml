<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#33258;&#21161;&#22521;&#35757;&#20307;&#21046;&#65292;&#21033;&#29992;&#29420;&#31435;&#23376;&#32593;&#32476;&#30340;&#38598;&#25104;&#21644;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#26469;&#25552;&#39640;&#33258;&#21161;&#30340;&#40065;&#26834;&#24615;&#34920;&#31034;&#23398;&#20064;&#30340;&#25928;&#29575;&#21644;&#22810;&#26679;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.14705</link><description>&lt;p&gt;
&#33258;&#21161;&#30340;&#40065;&#26834;&#24615;&#34920;&#31034;&#23398;&#20064;&#30340;&#29420;&#31435;&#23376;&#32593;&#32476;&#22810;&#26679;&#21270;&#38598;&#25104;
&lt;/p&gt;
&lt;p&gt;
Diversified Ensemble of Independent Sub-Networks for Robust Self-Supervised Representation Learning. (arXiv:2308.14705v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14705
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#33258;&#21161;&#22521;&#35757;&#20307;&#21046;&#65292;&#21033;&#29992;&#29420;&#31435;&#23376;&#32593;&#32476;&#30340;&#38598;&#25104;&#21644;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#26469;&#25552;&#39640;&#33258;&#21161;&#30340;&#40065;&#26834;&#24615;&#34920;&#31034;&#23398;&#20064;&#30340;&#25928;&#29575;&#21644;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38598;&#25104;&#31070;&#32463;&#32593;&#32476;&#26159;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12289;&#20272;&#35745;&#19981;&#30830;&#23450;&#24615;&#21644;&#25913;&#21892;&#28145;&#24230;&#26377;&#30417;&#30563;&#23398;&#20064;&#40065;&#26834;&#24615;&#30340;&#24191;&#27867;&#25215;&#35748;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#28145;&#23618;&#38598;&#25104;&#36890;&#24120;&#20855;&#26377;&#39640;&#35745;&#31639;&#25104;&#26412;&#21644;&#20869;&#23384;&#38656;&#27714;&#12290;&#27492;&#22806;&#65292;&#28145;&#24230;&#38598;&#25104;&#30340;&#25928;&#29575;&#19982;&#38598;&#25104;&#25104;&#21592;&#20043;&#38388;&#30340;&#22810;&#26679;&#24615;&#26377;&#20851;&#65292;&#36825;&#23545;&#20110;&#22823;&#22411;&#30340;&#36807;&#21442;&#25968;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26469;&#35828;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#32780;&#19988;&#65292;&#38598;&#25104;&#23398;&#20064;&#23578;&#26410;&#24471;&#21040;&#22914;&#27492;&#24191;&#27867;&#30340;&#37319;&#29992;&#65292;&#24182;&#19988;&#23545;&#20110;&#33258;&#21161;&#30340;&#25110;&#26080;&#30417;&#30563;&#30340;&#34920;&#31034;&#23398;&#20064;&#26469;&#35828;&#20173;&#28982;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24037;&#20316;&#12290;&#22312;&#36825;&#20123;&#25361;&#25112;&#30340;&#25512;&#21160;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#33258;&#21161;&#22521;&#35757;&#20307;&#21046;&#65292;&#21033;&#29992;&#29420;&#31435;&#23376;&#32593;&#32476;&#30340;&#38598;&#25104;&#65292;&#36741;&#20197;&#19968;&#20010;&#26088;&#22312;&#40723;&#21169;&#22810;&#26679;&#24615;&#30340;&#26032;&#25439;&#22833;&#20989;&#25968;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20197;&#39640;&#22810;&#26679;&#24615;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#23376;&#27169;&#22411;&#38598;&#25104;&#65292;&#20174;&#32780;&#33719;&#24471;&#20102;&#33391;&#22909;&#26657;&#20934;&#30340;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#24182;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;&#35745;&#31639;&#24320;&#38144;&#26368;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ensembling a neural network is a widely recognized approach to enhance model performance, estimate uncertainty, and improve robustness in deep supervised learning. However, deep ensembles often come with high computational costs and memory demands. In addition, the efficiency of a deep ensemble is related to diversity among the ensemble members which is challenging for large, over-parameterized deep neural networks. Moreover, ensemble learning has not yet seen such widespread adoption, and it remains a challenging endeavor for self-supervised or unsupervised representation learning. Motivated by these challenges, we present a novel self-supervised training regime that leverages an ensemble of independent sub-networks, complemented by a new loss function designed to encourage diversity. Our method efficiently builds a sub-model ensemble with high diversity, leading to well-calibrated estimates of model uncertainty, all achieved with minimal computational overhead compared to traditional
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#22312;&#36941;&#21382;&#25968;&#25454;&#24207;&#21015;&#19978;&#35757;&#32451;&#26102;&#30340;&#26680;&#26497;&#38480;&#65292;&#21033;&#29992;&#25968;&#23398;&#26041;&#27861;&#23545;&#20854;&#28176;&#36817;&#29305;&#24615;&#36827;&#34892;&#20102;&#25551;&#36848;&#65292;&#24182;&#35777;&#26126;&#20102;RNN&#25910;&#25947;&#21040;&#19982;&#38543;&#26426;&#20195;&#25968;&#26041;&#31243;&#30340;&#19981;&#21160;&#28857;&#32806;&#21512;&#30340;&#26080;&#31351;&#32500;ODE&#30340;&#35299;&#12290;&#36825;&#23545;&#20110;&#29702;&#35299;&#21644;&#25913;&#36827;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2308.14555</link><description>&lt;p&gt;
&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#22312;&#36941;&#21382;&#25968;&#25454;&#24207;&#21015;&#19978;&#35757;&#32451;&#30340;&#26680;&#26497;&#38480;
&lt;/p&gt;
&lt;p&gt;
Kernel Limit of Recurrent Neural Networks Trained on Ergodic Data Sequences. (arXiv:2308.14555v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14555
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#22312;&#36941;&#21382;&#25968;&#25454;&#24207;&#21015;&#19978;&#35757;&#32451;&#26102;&#30340;&#26680;&#26497;&#38480;&#65292;&#21033;&#29992;&#25968;&#23398;&#26041;&#27861;&#23545;&#20854;&#28176;&#36817;&#29305;&#24615;&#36827;&#34892;&#20102;&#25551;&#36848;&#65292;&#24182;&#35777;&#26126;&#20102;RNN&#25910;&#25947;&#21040;&#19982;&#38543;&#26426;&#20195;&#25968;&#26041;&#31243;&#30340;&#19981;&#21160;&#28857;&#32806;&#21512;&#30340;&#26080;&#31351;&#32500;ODE&#30340;&#35299;&#12290;&#36825;&#23545;&#20110;&#29702;&#35299;&#21644;&#25913;&#36827;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#25968;&#23398;&#26041;&#27861;&#26469;&#25551;&#36848;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65288;RNN&#65289;&#30340;&#28176;&#36817;&#29305;&#24615;&#65292;&#20854;&#20013;&#38544;&#34255;&#21333;&#20803;&#30340;&#25968;&#37327;&#12289;&#24207;&#21015;&#20013;&#30340;&#25968;&#25454;&#26679;&#26412;&#12289;&#38544;&#34255;&#29366;&#24577;&#30340;&#26356;&#26032;&#21644;&#35757;&#32451;&#27493;&#39588;&#21516;&#26102;&#36235;&#20110;&#26080;&#31351;&#22823;&#12290;&#23545;&#20110;&#20855;&#26377;&#31616;&#21270;&#26435;&#37325;&#30697;&#38453;&#30340;RNN&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;RNN&#25910;&#25947;&#21040;&#19982;&#38543;&#26426;&#20195;&#25968;&#26041;&#31243;&#30340;&#19981;&#21160;&#28857;&#32806;&#21512;&#30340;&#26080;&#31351;&#32500;ODE&#30340;&#35299;&#12290;&#20998;&#26512;&#38656;&#35201;&#35299;&#20915;RNN&#25152;&#29305;&#26377;&#30340;&#20960;&#20010;&#25361;&#25112;&#12290;&#22312;&#20856;&#22411;&#30340;&#22343;&#22330;&#24212;&#29992;&#20013;&#65288;&#20363;&#22914;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#65289;&#65292;&#31163;&#25955;&#30340;&#26356;&#26032;&#37327;&#20026;$\mathcal{O}(\frac{1}{N})$&#65292;&#26356;&#26032;&#30340;&#27425;&#25968;&#20026;$\mathcal{O}(N)$&#12290;&#22240;&#27492;&#65292;&#31995;&#32479;&#21487;&#20197;&#34920;&#31034;&#20026;&#36866;&#24403;ODE/PDE&#30340;Euler&#36924;&#36817;&#65292;&#24403;$N \rightarrow \infty$&#26102;&#25910;&#25947;&#21040;&#35813;ODE/PDE&#12290;&#28982;&#32780;&#65292;RNN&#30340;&#38544;&#34255;&#23618;&#26356;&#26032;&#20026;$\mathcal{O}(1)$&#12290;&#22240;&#27492;&#65292;RNN&#19981;&#33021;&#34920;&#31034;&#20026;ODE/PDE&#30340;&#31163;&#25955;&#21270;&#21644;&#26631;&#20934;&#22343;&#22330;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mathematical methods are developed to characterize the asymptotics of recurrent neural networks (RNN) as the number of hidden units, data samples in the sequence, hidden state updates, and training steps simultaneously grow to infinity. In the case of an RNN with a simplified weight matrix, we prove the convergence of the RNN to the solution of an infinite-dimensional ODE coupled with the fixed point of a random algebraic equation. The analysis requires addressing several challenges which are unique to RNNs. In typical mean-field applications (e.g., feedforward neural networks), discrete updates are of magnitude $\mathcal{O}(\frac{1}{N})$ and the number of updates is $\mathcal{O}(N)$. Therefore, the system can be represented as an Euler approximation of an appropriate ODE/PDE, which it will converge to as $N \rightarrow \infty$. However, the RNN hidden layer updates are $\mathcal{O}(1)$. Therefore, RNNs cannot be represented as a discretization of an ODE/PDE and standard mean-field tec
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#22270;&#24418;&#22238;&#24402;&#26041;&#27861;&#26469;&#32852;&#21512;&#35843;&#33410;&#21644;&#39044;&#27979;&#28595;&#22823;&#21033;&#20122;&#37326;&#28779;&#30340;&#26032;&#26041;&#27861;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#23545;&#20110;&#28779;&#28798;&#30340;&#20840;&#20998;&#24067;&#24314;&#27169;&#26159;&#38750;&#24120;&#20851;&#38190;&#30340;&#65292;&#22240;&#20026;&#26497;&#31471;&#37326;&#28779;&#21487;&#33021;&#23548;&#33268;&#24040;&#22823;&#30340;&#24433;&#21709;&#65292;&#32780;&#23567;&#35268;&#27169;&#21644;&#20013;&#31561;&#35268;&#27169;&#28779;&#28798;&#20173;&#28982;&#20250;&#23545;&#24403;&#22320;&#31038;&#21306;&#21644;&#29983;&#24577;&#31995;&#32479;&#36896;&#25104;&#37325;&#22823;&#30772;&#22351;&#12290;</title><link>http://arxiv.org/abs/2308.14547</link><description>&lt;p&gt;
&#28145;&#24230;&#22270;&#24418;&#22238;&#24402;&#29992;&#20110;&#32852;&#21512;&#35843;&#33410;&#21644;&#26497;&#31471;&#28595;&#22823;&#21033;&#20122;&#37326;&#28779;
&lt;/p&gt;
&lt;p&gt;
Deep graphical regression for jointly moderate and extreme Australian wildfires. (arXiv:2308.14547v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14547
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#22270;&#24418;&#22238;&#24402;&#26041;&#27861;&#26469;&#32852;&#21512;&#35843;&#33410;&#21644;&#39044;&#27979;&#28595;&#22823;&#21033;&#20122;&#37326;&#28779;&#30340;&#26032;&#26041;&#27861;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#23545;&#20110;&#28779;&#28798;&#30340;&#20840;&#20998;&#24067;&#24314;&#27169;&#26159;&#38750;&#24120;&#20851;&#38190;&#30340;&#65292;&#22240;&#20026;&#26497;&#31471;&#37326;&#28779;&#21487;&#33021;&#23548;&#33268;&#24040;&#22823;&#30340;&#24433;&#21709;&#65292;&#32780;&#23567;&#35268;&#27169;&#21644;&#20013;&#31561;&#35268;&#27169;&#28779;&#28798;&#20173;&#28982;&#20250;&#23545;&#24403;&#22320;&#31038;&#21306;&#21644;&#29983;&#24577;&#31995;&#32479;&#36896;&#25104;&#37325;&#22823;&#30772;&#22351;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28595;&#22823;&#21033;&#20122;&#26368;&#36817;&#30340;&#37326;&#28779;&#36896;&#25104;&#20102;&#24040;&#22823;&#30340;&#32463;&#27982;&#25439;&#22833;&#21644;&#36130;&#20135;&#30772;&#22351;&#65292;&#20154;&#20204;&#36234;&#26469;&#36234;&#25285;&#24515;&#27668;&#20505;&#21464;&#21270;&#21487;&#33021;&#21152;&#21095;&#20854;&#24378;&#24230;&#12289;&#25345;&#32493;&#26102;&#38388;&#21644;&#39057;&#29575;&#12290;&#23545;&#20110;&#26497;&#31471;&#37326;&#28779;&#30340;&#28798;&#23475;&#35780;&#20272;&#26159;&#37326;&#28779;&#31649;&#29702;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#23427;&#26377;&#21161;&#20110;&#36164;&#28304;&#20998;&#37197;&#30340;&#39640;&#25928;&#24615;&#12289;&#36127;&#38754;&#24433;&#21709;&#30340;&#20943;&#36731;&#21644;&#24674;&#22797;&#24037;&#20316;&#30340;&#24320;&#23637;&#12290;&#28982;&#32780;&#65292;&#34429;&#28982;&#26497;&#31471;&#37326;&#28779;&#36890;&#24120;&#20855;&#26377;&#26368;&#22823;&#30340;&#24433;&#21709;&#21147;&#65292;&#20294;&#23567;&#35268;&#27169;&#21644;&#20013;&#31561;&#35268;&#27169;&#30340;&#28779;&#28798;&#20173;&#28982;&#21487;&#20197;&#23545;&#24403;&#22320;&#31038;&#21306;&#21644;&#29983;&#24577;&#31995;&#32479;&#36896;&#25104;&#27585;&#28781;&#24615;&#30340;&#24433;&#21709;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#36843;&#20999;&#38656;&#35201;&#24320;&#21457;&#31283;&#20581;&#30340;&#32479;&#35745;&#26041;&#27861;&#26469;&#21487;&#38752;&#22320;&#24314;&#27169;&#37326;&#28779;&#30340;&#20840;&#20998;&#24067;&#12290;&#25105;&#20204;&#23545;1999&#24180;&#33267;2019&#24180;&#30340;&#28595;&#22823;&#21033;&#20122;&#37326;&#28779;&#36827;&#34892;&#20102;&#26032;&#30340;&#25968;&#25454;&#38598;&#20998;&#26512;&#65292;&#24182;&#20998;&#26512;&#20102;&#22823;&#32422;&#30456;&#24403;&#20110;&#32479;&#35745;&#21306;&#22495;&#23618;&#27425;1&#21644;&#23618;&#27425;2&#65288;SA1/SA2&#65289;&#21306;&#22495;&#30340;&#28779;&#28798;&#26376;&#24230;&#34067;&#24310;&#12290;&#37492;&#20110;&#37326;&#28779;&#28857;&#29123;&#21644;&#34067;&#24310;&#30340;&#22797;&#26434;&#24615;&#65292;&#25105;&#20204;&#21033;&#29992;&#20102;&#32479;&#35745;&#28145;&#24230;&#23398;&#20064;&#21644;&#22806;&#37096;&#20449;&#24687;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent wildfires in Australia have led to considerable economic loss and property destruction, and there is increasing concern that climate change may exacerbate their intensity, duration, and frequency. hazard quantification for extreme wildfires is an important component of wildfire management, as it facilitates efficient resource distribution, adverse effect mitigation, and recovery efforts. However, although extreme wildfires are typically the most impactful, both small and moderate fires can still be devastating to local communities and ecosystems. Therefore, it is imperative to develop robust statistical methods to reliably model the full distribution of wildfire spread. We do so for a novel dataset of Australian wildfires from 1999 to 2019, and analyse monthly spread over areas approximately corresponding to Statistical Areas Level 1 and 2 (SA1/SA2) regions. Given the complex nature of wildfire ignition and spread, we exploit recent advances in statistical deep learning and extr
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#38024;&#23545;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#21442;&#25968;&#20272;&#35745;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35889;&#20272;&#35745;&#22120;&#36827;&#34892;&#39044;&#22788;&#29702;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#23545;&#27979;&#37327;&#36827;&#34892;&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#931;&#34920;&#31034;&#65292;&#20998;&#26512;&#20102;&#35889;&#20272;&#35745;&#22120;&#22312;&#32467;&#26500;&#21270;&#35774;&#35745;&#20013;&#30340;&#24615;&#33021;&#65292;&#24182;&#30830;&#23450;&#20102;&#26368;&#20248;&#39044;&#22788;&#29702;&#20197;&#26368;&#23567;&#21270;&#26679;&#26412;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2308.14507</link><description>&lt;p&gt;
&#36890;&#36807;&#36817;&#20284;&#20256;&#36882;&#28040;&#24687;&#23454;&#29616;&#32467;&#26500;&#21270;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#35889;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
Spectral Estimators for Structured Generalized Linear Models via Approximate Message Passing. (arXiv:2308.14507v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14507
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#38024;&#23545;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#21442;&#25968;&#20272;&#35745;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35889;&#20272;&#35745;&#22120;&#36827;&#34892;&#39044;&#22788;&#29702;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#23545;&#27979;&#37327;&#36827;&#34892;&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#931;&#34920;&#31034;&#65292;&#20998;&#26512;&#20102;&#35889;&#20272;&#35745;&#22120;&#22312;&#32467;&#26500;&#21270;&#35774;&#35745;&#20013;&#30340;&#24615;&#33021;&#65292;&#24182;&#30830;&#23450;&#20102;&#26368;&#20248;&#39044;&#22788;&#29702;&#20197;&#26368;&#23567;&#21270;&#26679;&#26412;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;&#35266;&#27979;&#20013;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#30340;&#38382;&#39064;&#12290;&#35889;&#26041;&#27861;&#26159;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#20272;&#35745;&#26041;&#27861;&#65306;&#23427;&#36890;&#36807;&#23545;&#35266;&#27979;&#36827;&#34892;&#36866;&#24403;&#39044;&#22788;&#29702;&#24471;&#21040;&#30340;&#30697;&#38453;&#30340;&#20027;&#29305;&#24449;&#21521;&#37327;&#26469;&#20272;&#35745;&#21442;&#25968;&#12290;&#23613;&#31649;&#35889;&#20272;&#35745;&#22120;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#23545;&#20110;&#32467;&#26500;&#21270;&#65288;&#21363;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#39640;&#26031;&#21644;&#21704;&#23572;&#65289;&#35774;&#35745;&#65292;&#30446;&#21069;&#20165;&#26377;&#23545;&#35889;&#20272;&#35745;&#22120;&#30340;&#20005;&#26684;&#24615;&#33021;&#34920;&#24449;&#20197;&#21450;&#23545;&#25968;&#25454;&#36827;&#34892;&#39044;&#22788;&#29702;&#30340;&#22522;&#26412;&#26041;&#27861;&#21487;&#29992;&#12290;&#30456;&#21453;&#65292;&#23454;&#38469;&#30340;&#35774;&#35745;&#30697;&#38453;&#20855;&#26377;&#39640;&#24230;&#32467;&#26500;&#21270;&#24182;&#19988;&#34920;&#29616;&#20986;&#38750;&#24179;&#20961;&#30340;&#30456;&#20851;&#24615;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#25429;&#25417;&#27979;&#37327;&#30340;&#38750;&#21508;&#21521;&#21516;&#24615;&#29305;&#24615;&#30340;&#30456;&#20851;&#39640;&#26031;&#35774;&#35745;&#65292;&#36890;&#36807;&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#931;&#36827;&#34892;&#34920;&#31034;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#23545;&#20110;&#36825;&#31181;&#24773;&#20917;&#19979;&#35889;&#20272;&#35745;&#22120;&#24615;&#33021;&#30340;&#31934;&#30830;&#28176;&#36817;&#20998;&#26512;&#12290;&#28982;&#21518;&#65292;&#21487;&#20197;&#36890;&#36807;&#36825;&#19968;&#32467;&#26524;&#26469;&#30830;&#23450;&#26368;&#20248;&#39044;&#22788;&#29702;&#65292;&#20174;&#32780;&#26368;&#23567;&#21270;&#25152;&#38656;&#26679;&#26412;&#30340;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of parameter estimation from observations given by a generalized linear model. Spectral methods are a simple yet effective approach for estimation: they estimate the parameter via the principal eigenvector of a matrix obtained by suitably preprocessing the observations. Despite their wide use, a rigorous performance characterization of spectral estimators, as well as a principled way to preprocess the data, is available only for unstructured (i.e., i.i.d. Gaussian and Haar) designs. In contrast, real-world design matrices are highly structured and exhibit non-trivial correlations. To address this problem, we consider correlated Gaussian designs which capture the anisotropic nature of the measurements via a feature covariance matrix $\Sigma$. Our main result is a precise asymptotic characterization of the performance of spectral estimators in this setting. This then allows to identify the optimal preprocessing that minimizes the number of samples needed to meanin
&lt;/p&gt;</description></item><item><title>&#20851;&#20110;&#40065;&#26834;&#32858;&#31867;&#65292;&#35752;&#35770;&#20102;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#12289;&#24322;&#24120;&#20540;&#23450;&#20041;&#12289;&#24322;&#24120;&#20540;&#19982;&#32858;&#31867;&#30340;&#27169;&#31946;&#24615;&#12289;&#40065;&#26834;&#32858;&#31867;&#19982;&#32858;&#31867;&#25968;&#30446;&#20272;&#35745;&#30340;&#30456;&#20114;&#20316;&#29992;&#20197;&#21450;&#32858;&#31867;&#31283;&#23450;&#24615;&#34913;&#37327;&#30340;&#19981;&#36275;&#12290;</title><link>http://arxiv.org/abs/2308.14478</link><description>&lt;p&gt;
&#20851;&#20110;&#40065;&#26834;&#32858;&#31867;&#20013;&#30340;&#19968;&#20123;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Some issues in robust clustering. (arXiv:2308.14478v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14478
&lt;/p&gt;
&lt;p&gt;
&#20851;&#20110;&#40065;&#26834;&#32858;&#31867;&#65292;&#35752;&#35770;&#20102;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#12289;&#24322;&#24120;&#20540;&#23450;&#20041;&#12289;&#24322;&#24120;&#20540;&#19982;&#32858;&#31867;&#30340;&#27169;&#31946;&#24615;&#12289;&#40065;&#26834;&#32858;&#31867;&#19982;&#32858;&#31867;&#25968;&#30446;&#20272;&#35745;&#30340;&#30456;&#20114;&#20316;&#29992;&#20197;&#21450;&#32858;&#31867;&#31283;&#23450;&#24615;&#34913;&#37327;&#30340;&#19981;&#36275;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35752;&#35770;&#20102;&#40065;&#26834;&#32858;&#31867;&#20013;&#30340;&#19968;&#20123;&#20851;&#38190;&#38382;&#39064;&#65292;&#20027;&#35201;&#38598;&#20013;&#22312;&#22522;&#20110;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#32858;&#31867;&#19978;&#65292;&#21253;&#25324;&#24322;&#24120;&#20540;&#30340;&#24418;&#24335;&#23450;&#20041;&#12289;&#24322;&#24120;&#20540;&#19982;&#32858;&#31867;&#20043;&#38388;&#30340;&#27169;&#31946;&#24615;&#12289;&#40065;&#26834;&#32858;&#31867;&#19982;&#32858;&#31867;&#25968;&#30446;&#20272;&#35745;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12289;(&#19981;&#20165;&#20165;&#26159;)&#40065;&#26834;&#32858;&#31867;&#23545;&#35843;&#35797;&#20915;&#31574;&#30340;&#24517;&#35201;&#20381;&#36182;&#20197;&#21450;&#29616;&#26377;&#30340;&#32858;&#31867;&#31283;&#23450;&#24615;&#34913;&#37327;&#22312;&#22788;&#29702;&#24322;&#24120;&#20540;&#26102;&#30340;&#19981;&#36275;&#12290;
&lt;/p&gt;
&lt;p&gt;
Some key issues in robust clustering are discussed with focus on Gaussian mixture model based clustering, namely the formal definition of outliers, ambiguity between groups of outliers and clusters, the interaction between robust clustering and the estimation of the number of clusters, the essential dependence of (not only) robust clustering on tuning decisions, and shortcomings of existing measurements of cluster stability when it comes to outliers.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#65292;&#36890;&#36807;&#20165;&#20351;&#29992;&#23616;&#37096;&#27979;&#37327;&#25968;&#25454;&#65292;&#21487;&#20197;&#22312;&#28431;&#30005;&#20809;&#23376;&#26230;&#26684;&#20013;&#20934;&#30830;&#35782;&#21035;&#25299;&#25169;&#30456;&#65292;&#36991;&#20813;&#20102;&#22797;&#26434;&#30340;&#30456;&#20301;&#37325;&#26500;&#27493;&#39588;&#12290;</title><link>http://arxiv.org/abs/2308.14407</link><description>&lt;p&gt;
&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#35782;&#21035;&#28431;&#30005;&#20809;&#23376;&#26230;&#26684;&#30340;&#25299;&#25169;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
Identifying topology of leaky photonic lattices with machine learning. (arXiv:2308.14407v1 [physics.optics])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14407
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#65292;&#36890;&#36807;&#20165;&#20351;&#29992;&#23616;&#37096;&#27979;&#37327;&#25968;&#25454;&#65292;&#21487;&#20197;&#22312;&#28431;&#30005;&#20809;&#23376;&#26230;&#26684;&#20013;&#20934;&#30830;&#35782;&#21035;&#25299;&#25169;&#30456;&#65292;&#36991;&#20813;&#20102;&#22797;&#26434;&#30340;&#30456;&#20301;&#37325;&#26500;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#26377;&#38480;&#30340;&#27979;&#37327;&#25968;&#25454;&#65292;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#23545;&#28431;&#30005;&#20809;&#23376;&#26230;&#26684;&#20013;&#30340;&#25299;&#25169;&#30456;&#36827;&#34892;&#20998;&#31867;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20165;&#22522;&#20110;&#20307;&#31215;&#24378;&#24230;&#27979;&#37327;&#30340;&#26041;&#27861;&#65292;&#22240;&#27492;&#19981;&#38656;&#35201;&#22797;&#26434;&#30340;&#30456;&#20301;&#37325;&#26500;&#27493;&#39588;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#65292;&#33021;&#22815;&#20174;&#26377;&#28431;&#30005;&#36890;&#36947;&#30340;&#20108;&#32858;&#27874;&#23548;&#38453;&#21015;&#30340;&#36755;&#20986;&#24378;&#24230;&#20998;&#24067;&#20013;&#20934;&#30830;&#30830;&#23450;&#25299;&#25169;&#29305;&#24615;&#65292;&#22312;&#19968;&#20010;&#32039;&#23494;&#27169;&#25311;&#23454;&#38469;&#23454;&#39564;&#26465;&#20214;&#30340;&#35774;&#32622;&#20013;&#65292;&#36890;&#36807;&#22312;&#26377;&#38480;&#36317;&#31163;&#19978;&#20256;&#25773;&#31354;&#38388;&#23616;&#37096;&#21270;&#30340;&#21021;&#22987;&#28608;&#21457;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show how machine learning techniques can be applied for the classification of topological phases in leaky photonic lattices using limited measurement data. We propose an approach based solely on bulk intensity measurements, thus exempt from the need for complicated phase retrieval procedures. In particular, we design a fully connected neural network that accurately determines topological properties from the output intensity distribution in dimerized waveguide arrays with leaky channels, after propagation of a spatially localized initial excitation at a finite distance, in a setting that closely emulates realistic experimental conditions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31232;&#30095;&#24809;&#32602;&#30340;&#21452;&#32858;&#31867;&#26041;&#27861;&#65292;&#20027;&#35201;&#20851;&#27880;&#20102;SSVD&#26041;&#27861;&#65292;&#24182;&#23581;&#35797;&#20102;&#19968;&#31181;&#26032;&#30340;&#31232;&#30095;&#24809;&#32602;&#26041;&#27861;&#12290;&#27169;&#25311;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#28151;&#21512;&#30340;Prenet&#24809;&#32602;&#23545;&#20110;&#38750;&#37325;&#21472;&#25968;&#25454;&#38750;&#24120;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2308.14388</link><description>&lt;p&gt;
&#36890;&#36807;&#31232;&#30095;&#24809;&#32602;&#36827;&#34892;&#30340;&#21452;&#32858;&#31867;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Biclustering Methods via Sparse Penalty. (arXiv:2308.14388v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14388
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31232;&#30095;&#24809;&#32602;&#30340;&#21452;&#32858;&#31867;&#26041;&#27861;&#65292;&#20027;&#35201;&#20851;&#27880;&#20102;SSVD&#26041;&#27861;&#65292;&#24182;&#23581;&#35797;&#20102;&#19968;&#31181;&#26032;&#30340;&#31232;&#30095;&#24809;&#32602;&#26041;&#27861;&#12290;&#27169;&#25311;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#28151;&#21512;&#30340;Prenet&#24809;&#32602;&#23545;&#20110;&#38750;&#37325;&#21472;&#25968;&#25454;&#38750;&#24120;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#20808;&#22238;&#39038;&#20102;&#20960;&#31181;&#29992;&#20110;&#35782;&#21035;&#22522;&#22240;&#34920;&#36798;&#25968;&#25454;&#20013;&#26368;&#26174;&#33879;&#32858;&#31867;&#30340;&#21452;&#32858;&#31867;&#26041;&#27861;&#12290;&#25105;&#20204;&#20027;&#35201;&#20851;&#27880;&#20102;SSVD&#65288;&#31232;&#30095;SVD&#65289;&#26041;&#27861;&#65292;&#24182;&#23581;&#35797;&#20102;&#19968;&#31181;&#20165;&#29992;&#20110;&#22240;&#23376;&#20998;&#26512;&#30340;&#26032;&#30340;&#31232;&#30095;&#24809;&#32602;&#26041;&#27861;&#65292;&#31216;&#20026;"Prenet&#24809;&#32602;"&#12290;&#28982;&#21518;&#22312;&#27169;&#25311;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23581;&#35797;&#20102;&#19981;&#21516;&#31867;&#22411;&#30340;&#29983;&#25104;&#25968;&#25454;&#38598;&#65288;&#20855;&#26377;&#19981;&#21516;&#30340;&#31232;&#30095;&#24615;&#21644;&#32500;&#24230;&#65289;&#65292;&#24182;&#23581;&#35797;&#20102;&#19968;&#23618;&#36924;&#36817;&#21644;k&#23618;&#36924;&#36817;&#65292;&#32467;&#26524;&#34920;&#26126;&#28151;&#21512;&#30340;Prenet&#24809;&#32602;&#23545;&#20110;&#38750;&#37325;&#21472;&#25968;&#25454;&#38750;&#24120;&#26377;&#25928;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#20123;&#30495;&#23454;&#30340;&#22522;&#22240;&#34920;&#36798;&#25968;&#25454;&#26469;&#23637;&#31034;&#25105;&#20204;&#26041;&#27861;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we first reviewed several biclustering methods that are used to identify the most significant clusters in gene expression data. Here we mainly focused on the SSVD(sparse SVD) method and tried a new sparse penalty named "Prenet penalty" which has been used only in factor analysis to gain sparsity. Then in the simulation study, we tried different types of generated datasets (with different sparsity and dimension) and tried 1-layer approximation then for k-layers which shows the mixed Prenet penalty is very effective for non-overlapped data. Finally, we used some real gene expression data to show the behavior of our methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36141;&#20080;&#26102;&#26426;&#30340;&#29983;&#23384;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#22312;&#32771;&#34385;&#20102;&#24615;&#21035;&#12289;&#25910;&#20837;&#12289;&#20301;&#32622;&#12289;&#36141;&#20080;&#21382;&#21490;&#12289;&#22312;&#32447;&#34892;&#20026;&#12289;&#20852;&#36259;&#12289;&#20419;&#38144;&#25240;&#25187;&#21644;&#23458;&#25143;&#20307;&#39564;&#31561;&#22240;&#32032;&#30340;&#24433;&#21709;&#19979;&#65292;&#36827;&#34892;&#20102;&#20010;&#20154;&#36141;&#20080;&#20915;&#31574;&#26102;&#38388;&#30340;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2308.14343</link><description>&lt;p&gt;
&#20309;&#26102;&#36141;&#20080;&#65311;&#36141;&#20080;&#26102;&#26426;&#30340;&#29983;&#23384;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Buy when? Survival machine learning model comparison for purchase timing. (arXiv:2308.14343v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14343
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36141;&#20080;&#26102;&#26426;&#30340;&#29983;&#23384;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#22312;&#32771;&#34385;&#20102;&#24615;&#21035;&#12289;&#25910;&#20837;&#12289;&#20301;&#32622;&#12289;&#36141;&#20080;&#21382;&#21490;&#12289;&#22312;&#32447;&#34892;&#20026;&#12289;&#20852;&#36259;&#12289;&#20419;&#38144;&#25240;&#25187;&#21644;&#23458;&#25143;&#20307;&#39564;&#31561;&#22240;&#32032;&#30340;&#24433;&#21709;&#19979;&#65292;&#36827;&#34892;&#20102;&#20010;&#20154;&#36141;&#20080;&#20915;&#31574;&#26102;&#38388;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#21407;&#22987;&#25968;&#25454;&#36716;&#21270;&#20026;&#21487;&#20197;&#39537;&#21160;&#20915;&#31574;&#30340;&#20449;&#24687;&#21644;&#30693;&#35782;&#25165;&#33021;&#23454;&#29616;&#20854;&#20215;&#20540;&#12290;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#33021;&#22815;&#20998;&#26512;&#22823;&#22411;&#25968;&#25454;&#38598;&#24182;&#36827;&#34892;&#20934;&#30830;&#30340;&#39044;&#27979;&#12290;&#24066;&#22330;&#32454;&#20998;&#12289;&#23458;&#25143;&#32456;&#36523;&#20215;&#20540;&#21644;&#33829;&#38144;&#25216;&#26415;&#37117;&#24050;&#32463;&#21033;&#29992;&#20102;&#26426;&#22120;&#23398;&#20064;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#33829;&#38144;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#65292;&#22914;&#25903;&#25345;&#21521;&#37327;&#26426;&#12289;&#36951;&#20256;&#31639;&#27861;&#12289;&#28145;&#24230;&#23398;&#20064;&#21644;K-Means&#12290;&#26426;&#22120;&#23398;&#20064;&#29992;&#20110;&#20998;&#26512;&#28040;&#36153;&#32773;&#34892;&#20026;&#12289;&#25552;&#20986;&#29289;&#21697;&#36873;&#25321;&#65292;&#24182;&#22312;&#36141;&#20080;&#20135;&#21697;&#25110;&#26381;&#21153;&#26102;&#20570;&#20986;&#20854;&#20182;&#23458;&#25143;&#20915;&#31574;&#65292;&#20294;&#24456;&#23569;&#29992;&#20110;&#39044;&#27979;&#19968;&#20010;&#20154;&#20309;&#26102;&#36141;&#20080;&#19968;&#20010;&#20135;&#21697;&#25110;&#19968;&#31726;&#23376;&#20135;&#21697;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#29983;&#23384;&#27169;&#22411; Kernel SVM&#12289;DeepSurv&#12289;Survival Random Forest &#21644; MTLR&#65292;&#20197;&#39044;&#27979;&#20010;&#20154;&#36141;&#20080;&#20915;&#31574;&#30340;&#26102;&#38388;&#12290;&#24615;&#21035;&#12289;&#25910;&#20837;&#12289;&#20301;&#32622;&#12289;&#36141;&#20080;&#21382;&#21490;&#12289;&#22312;&#32447;&#34892;&#20026;&#12289;&#20852;&#36259;&#12289;&#20419;&#38144;&#25240;&#25187;&#21644;&#23458;&#25143;&#20307;&#39564;&#37117;&#23545;&#36141;&#20080;&#26377;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
The value of raw data is unlocked by converting it into information and knowledge that drives decision-making. Machine Learning (ML) algorithms are capable of analysing large datasets and making accurate predictions. Market segmentation, client lifetime value, and marketing techniques have all made use of machine learning. This article examines marketing machine learning techniques such as Support Vector Machines, Genetic Algorithms, Deep Learning, and K-Means. ML is used to analyse consumer behaviour, propose items, and make other customer choices about whether or not to purchase a product or service, but it is seldom used to predict when a person will buy a product or a basket of products. In this paper, the survival models Kernel SVM, DeepSurv, Survival Random Forest, and MTLR are examined to predict tine-purchase individual decisions. Gender, Income, Location, PurchaseHistory, OnlineBehavior, Interests, PromotionsDiscounts and CustomerExperience all have an influence on purchasing 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25913;&#36827;&#20102;&#26680;&#20998;&#24067;&#22238;&#24402;&#30340;&#23398;&#20064;&#29702;&#35770;&#65292;&#24341;&#20837;&#20102;&#26032;&#30340;&#36817;&#26080;&#20559;&#26465;&#20214;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#20004;&#38454;&#27573;&#37319;&#26679;&#25928;&#26524;&#30340;&#26032;&#35823;&#24046;&#30028;&#12290;</title><link>http://arxiv.org/abs/2308.14335</link><description>&lt;p&gt;
&#25913;&#36827;&#30340;&#26680;&#20998;&#24067;&#22238;&#24402;&#23398;&#20064;&#29702;&#35770;&#19982;&#20004;&#38454;&#27573;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Improved learning theory for kernel distribution regression with two-stage sampling. (arXiv:2308.14335v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14335
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25913;&#36827;&#20102;&#26680;&#20998;&#24067;&#22238;&#24402;&#30340;&#23398;&#20064;&#29702;&#35770;&#65292;&#24341;&#20837;&#20102;&#26032;&#30340;&#36817;&#26080;&#20559;&#26465;&#20214;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#20004;&#38454;&#27573;&#37319;&#26679;&#25928;&#26524;&#30340;&#26032;&#35823;&#24046;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#22238;&#24402;&#38382;&#39064;&#28085;&#30422;&#20102;&#35768;&#22810;&#37325;&#35201;&#30340;&#32479;&#35745;&#21644;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#37117;&#26377;&#20986;&#29616;&#12290;&#22312;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#21508;&#31181;&#29616;&#26377;&#26041;&#27861;&#20013;&#65292;&#26680;&#26041;&#27861;&#24050;&#32463;&#25104;&#20026;&#39318;&#36873;&#30340;&#26041;&#27861;&#12290;&#20107;&#23454;&#19978;&#65292;&#26680;&#20998;&#24067;&#22238;&#24402;&#22312;&#35745;&#31639;&#19978;&#26159;&#26377;&#21033;&#30340;&#65292;&#24182;&#19988;&#24471;&#21040;&#20102;&#26368;&#36817;&#30340;&#23398;&#20064;&#29702;&#35770;&#30340;&#25903;&#25345;&#12290;&#35813;&#29702;&#35770;&#36824;&#35299;&#20915;&#20102;&#20004;&#38454;&#27573;&#37319;&#26679;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#21482;&#26377;&#36755;&#20837;&#20998;&#24067;&#30340;&#26679;&#26412;&#21487;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;&#26680;&#20998;&#24067;&#22238;&#24402;&#30340;&#23398;&#20064;&#29702;&#35770;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#24076;&#23572;&#20271;&#29305;&#23884;&#20837;&#30340;&#26680;&#65292;&#36825;&#20123;&#26680;&#21253;&#21547;&#20102;&#22823;&#22810;&#25968;&#65288;&#22914;&#26524;&#19981;&#26159;&#20840;&#37096;&#65289;&#29616;&#26377;&#26041;&#27861;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#23884;&#20837;&#30340;&#26032;&#36817;&#26080;&#20559;&#26465;&#20214;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#26032;&#30340;&#20998;&#26512;&#25552;&#20379;&#20851;&#20110;&#20004;&#38454;&#27573;&#37319;&#26679;&#25928;&#26524;&#30340;&#26032;&#35823;&#24046;&#30028;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#26032;&#36817;&#26080;&#20559;&#26465;&#20214;&#23545;&#19977;&#20010;&#37325;&#35201;&#30340;&#26680;&#31867;&#21035;&#25104;&#31435;&#65292;&#36825;&#20123;&#26680;&#22522;&#20110;&#26368;&#20248;&#36755;&#36816;&#21644;&#24179;&#22343;&#23884;&#20837;&#12290;
&lt;/p&gt;
&lt;p&gt;
The distribution regression problem encompasses many important statistics and machine learning tasks, and arises in a large range of applications. Among various existing approaches to tackle this problem, kernel methods have become a method of choice. Indeed, kernel distribution regression is both computationally favorable, and supported by a recent learning theory. This theory also tackles the two-stage sampling setting, where only samples from the input distributions are available. In this paper, we improve the learning theory of kernel distribution regression. We address kernels based on Hilbertian embeddings, that encompass most, if not all, of the existing approaches. We introduce the novel near-unbiased condition on the Hilbertian embeddings, that enables us to provide new error bounds on the effect of the two-stage sampling, thanks to a new analysis. We show that this near-unbiased condition holds for three important classes of kernels, based on optimal transport and mean embedd
&lt;/p&gt;</description></item><item><title>&#39044;&#27979;&#31232;&#30095;&#27969;&#24418;&#21464;&#25442;&#26159;&#19968;&#20010;&#31616;&#32422;&#12289;&#21487;&#35299;&#37322;&#19988;&#29983;&#29289;&#21487;&#34892;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;&#21644;&#39044;&#27979;&#33258;&#28982;&#21160;&#24577;&#12290;&#23427;&#36890;&#36807;&#31232;&#30095;&#32534;&#30721;&#21644;&#27969;&#24418;&#23398;&#20064;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.14207</link><description>&lt;p&gt;
&#39044;&#27979;&#31232;&#30095;&#27969;&#24418;&#21464;&#25442;
&lt;/p&gt;
&lt;p&gt;
Predictive Sparse Manifold Transform. (arXiv:2308.14207v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14207
&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#31232;&#30095;&#27969;&#24418;&#21464;&#25442;&#26159;&#19968;&#20010;&#31616;&#32422;&#12289;&#21487;&#35299;&#37322;&#19988;&#29983;&#29289;&#21487;&#34892;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;&#21644;&#39044;&#27979;&#33258;&#28982;&#21160;&#24577;&#12290;&#23427;&#36890;&#36807;&#31232;&#30095;&#32534;&#30721;&#21644;&#27969;&#24418;&#23398;&#20064;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#39044;&#27979;&#31232;&#30095;&#27969;&#24418;&#21464;&#25442;&#65288;PSMT&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#31616;&#32422;&#12289;&#21487;&#35299;&#37322;&#19988;&#29983;&#29289;&#21487;&#34892;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;&#21644;&#39044;&#27979;&#33258;&#28982;&#21160;&#24577;&#12290;PSMT&#21253;&#21547;&#20004;&#20010;&#23618;&#27425;&#65292;&#31532;&#19968;&#20010;&#31232;&#30095;&#32534;&#30721;&#23618;&#23558;&#36755;&#20837;&#24207;&#21015;&#34920;&#31034;&#20026;&#36807;&#23436;&#22791;&#23383;&#20856;&#19978;&#30340;&#31232;&#30095;&#31995;&#25968;&#65292;&#31532;&#20108;&#20010;&#27969;&#24418;&#23398;&#20064;&#23618;&#23398;&#20064;&#19968;&#20010;&#20960;&#20309;&#23884;&#20837;&#31354;&#38388;&#65292;&#35813;&#31354;&#38388;&#25429;&#25417;&#20102;&#31232;&#30095;&#31995;&#25968;&#30340;&#25299;&#25169;&#30456;&#20284;&#24615;&#21644;&#21160;&#24577;&#26102;&#38388;&#32447;&#24615;&#12290;&#25105;&#20204;&#22312;&#33258;&#28982;&#35270;&#39057;&#25968;&#25454;&#38598;&#19978;&#24212;&#29992;PSMT&#65292;&#24182;&#36890;&#36807;&#19978;&#19979;&#25991;&#21487;&#21464;&#24615;&#12289;&#31232;&#30095;&#32534;&#30721;&#22522;&#20989;&#25968;&#30340;&#25968;&#37327;&#21644;&#35757;&#32451;&#26679;&#26412;&#36827;&#34892;&#37325;&#24314;&#24615;&#33021;&#35780;&#20272;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35299;&#37322;&#20102;&#23884;&#20837;&#31354;&#38388;&#20013;&#30340;&#21160;&#24577;&#25299;&#25169;&#32467;&#26500;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#21033;&#29992;PSMT&#19982;&#38745;&#24577;&#23884;&#20837;&#31354;&#38388;&#30340;&#20004;&#31181;&#22522;&#20934;&#26041;&#27861;&#36827;&#34892;&#26410;&#26469;&#24103;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19982;&#38745;&#24577;&#22522;&#20934;&#26041;&#27861;&#30456;&#27604;&#65292;&#20855;&#26377;&#21160;&#24577;&#23884;&#20837;&#31354;&#38388;&#30340;PSMT&#21487;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present Predictive Sparse Manifold Transform (PSMT), a minimalistic, interpretable and biologically plausible framework for learning and predicting natural dynamics. PSMT incorporates two layers where the first sparse coding layer represents the input sequence as sparse coefficients over an overcomplete dictionary and the second manifold learning layer learns a geometric embedding space that captures topological similarity and dynamic temporal linearity in sparse coefficients. We apply PSMT on a natural video dataset and evaluate the reconstruction performance with respect to contextual variability, the number of sparse coding basis functions and training samples. We then interpret the dynamic topological organization in the embedding space. We next utilize PSMT to predict future frames compared with two baseline methods with a static embedding space. We demonstrate that PSMT with a dynamic embedding space can achieve better prediction performance compared to static baselines. Our w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20809;&#28369;&#24615;&#20808;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#33410;&#28857;&#29305;&#24449;&#20013;&#25512;&#26029;&#36229;&#22270;&#30340;&#32467;&#26500;&#65292;&#24182;&#25429;&#25417;&#25968;&#25454;&#20869;&#22312;&#30340;&#20851;&#31995;&#12290;&#35813;&#26041;&#27861;&#19981;&#38656;&#35201;&#26631;&#35760;&#25968;&#25454;&#20316;&#20026;&#30417;&#30563;&#65292;&#33021;&#22815;&#25512;&#26029;&#20986;&#27599;&#20010;&#28508;&#22312;&#36229;&#36793;&#30340;&#27010;&#29575;&#12290;</title><link>http://arxiv.org/abs/2308.14172</link><description>&lt;p&gt;
&#20174;&#25968;&#25454;&#20013;&#22522;&#20110;&#20809;&#28369;&#24615;&#20808;&#39564;&#25512;&#26029;&#36229;&#22270;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
Hypergraph Structure Inference From Data Under Smoothness Prior. (arXiv:2308.14172v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14172
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20809;&#28369;&#24615;&#20808;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#33410;&#28857;&#29305;&#24449;&#20013;&#25512;&#26029;&#36229;&#22270;&#30340;&#32467;&#26500;&#65292;&#24182;&#25429;&#25417;&#25968;&#25454;&#20869;&#22312;&#30340;&#20851;&#31995;&#12290;&#35813;&#26041;&#27861;&#19981;&#38656;&#35201;&#26631;&#35760;&#25968;&#25454;&#20316;&#20026;&#30417;&#30563;&#65292;&#33021;&#22815;&#25512;&#26029;&#20986;&#27599;&#20010;&#28508;&#22312;&#36229;&#36793;&#30340;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36229;&#22270;&#22312;&#22788;&#29702;&#28041;&#21450;&#22810;&#20010;&#23454;&#20307;&#30340;&#39640;&#38454;&#20851;&#31995;&#25968;&#25454;&#20013;&#38750;&#24120;&#37325;&#35201;&#12290;&#22312;&#27809;&#26377;&#26126;&#30830;&#36229;&#22270;&#21487;&#29992;&#30340;&#24773;&#20917;&#19979;&#65292;&#24076;&#26395;&#33021;&#22815;&#20174;&#33410;&#28857;&#29305;&#24449;&#20013;&#25512;&#26029;&#20986;&#26377;&#24847;&#20041;&#30340;&#36229;&#22270;&#32467;&#26500;&#65292;&#20197;&#25429;&#25417;&#25968;&#25454;&#20869;&#22312;&#30340;&#20851;&#31995;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#26041;&#27861;&#35201;&#20040;&#37319;&#29992;&#31616;&#21333;&#39044;&#23450;&#20041;&#30340;&#35268;&#21017;&#65292;&#19981;&#33021;&#31934;&#30830;&#25429;&#25417;&#28508;&#22312;&#36229;&#22270;&#32467;&#26500;&#30340;&#20998;&#24067;&#65292;&#35201;&#20040;&#23398;&#20064;&#36229;&#22270;&#32467;&#26500;&#21644;&#33410;&#28857;&#29305;&#24449;&#20043;&#38388;&#30340;&#26144;&#23556;&#65292;&#20294;&#38656;&#35201;&#22823;&#37327;&#26631;&#35760;&#25968;&#25454;&#65288;&#21363;&#39044;&#20808;&#23384;&#22312;&#30340;&#36229;&#22270;&#32467;&#26500;&#65289;&#36827;&#34892;&#35757;&#32451;&#12290;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#23616;&#38480;&#20110;&#23454;&#38469;&#24773;&#26223;&#20013;&#30340;&#24212;&#29992;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20809;&#28369;&#24615;&#20808;&#39564;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#35774;&#35745;&#19968;&#31181;&#26041;&#27861;&#65292;&#22312;&#27809;&#26377;&#26631;&#35760;&#25968;&#25454;&#20316;&#20026;&#30417;&#30563;&#30340;&#24773;&#20917;&#19979;&#25512;&#26029;&#20986;&#27599;&#20010;&#28508;&#22312;&#36229;&#36793;&#30340;&#27010;&#29575;&#12290;&#25152;&#25552;&#20986;&#30340;&#20808;&#39564;&#34920;&#31034;&#36229;&#36793;&#20013;&#30340;&#33410;&#28857;&#29305;&#24449;&#19982;&#21253;&#21547;&#35813;&#36229;&#36793;&#30340;&#36229;&#36793;&#30340;&#29305;&#24449;&#39640;&#24230;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hypergraphs are important for processing data with higher-order relationships involving more than two entities. In scenarios where explicit hypergraphs are not readily available, it is desirable to infer a meaningful hypergraph structure from the node features to capture the intrinsic relations within the data. However, existing methods either adopt simple pre-defined rules that fail to precisely capture the distribution of the potential hypergraph structure, or learn a mapping between hypergraph structures and node features but require a large amount of labelled data, i.e., pre-existing hypergraph structures, for training. Both restrict their applications in practical scenarios. To fill this gap, we propose a novel smoothness prior that enables us to design a method to infer the probability for each potential hyperedge without labelled data as supervision. The proposed prior indicates features of nodes in a hyperedge are highly correlated by the features of the hyperedge containing th
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32508;&#21512;&#21464;&#20998;&#20613;&#37324;&#21494;&#29305;&#24449;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23545;&#24191;&#27867;&#30340;&#24179;&#31283;&#21327;&#26041;&#24046;&#20989;&#25968;&#36827;&#34892;&#24555;&#36895;&#31354;&#38388;&#24314;&#27169;&#65292;&#30456;&#27604;&#20854;&#20182;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#24615;&#33021;&#21644;&#21152;&#36895;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.14142</link><description>&lt;p&gt;
&#24555;&#36895;&#31354;&#38388;&#24314;&#27169;&#30340;&#32508;&#21512;&#21464;&#20998;&#20613;&#37324;&#21494;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Integrated Variational Fourier Features for Fast Spatial Modelling with Gaussian Processes. (arXiv:2308.14142v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14142
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32508;&#21512;&#21464;&#20998;&#20613;&#37324;&#21494;&#29305;&#24449;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23545;&#24191;&#27867;&#30340;&#24179;&#31283;&#21327;&#26041;&#24046;&#20989;&#25968;&#36827;&#34892;&#24555;&#36895;&#31354;&#38388;&#24314;&#27169;&#65292;&#30456;&#27604;&#20854;&#20182;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#24615;&#33021;&#21644;&#21152;&#36895;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#21464;&#20998;&#36924;&#36817;&#26159;&#25193;&#23637;&#39640;&#26031;&#36807;&#31243;&#25512;&#29702;&#21644;&#23398;&#20064;&#33267;&#26356;&#22823;&#25968;&#25454;&#38598;&#30340;&#27969;&#34892;&#26041;&#27861;&#12290;&#23545;&#20110;$N$&#20010;&#35757;&#32451;&#28857;&#65292;&#31934;&#30830;&#25512;&#29702;&#30340;&#25104;&#26412;&#20026;$O(N^3)$&#65307;&#20351;&#29992;$M \ll N$&#29305;&#24449;&#30340;&#20808;&#36827;&#31232;&#30095;&#21464;&#20998;&#26041;&#27861;&#25104;&#26412;&#20026;$O(NM^2)$&#12290;&#26368;&#36817;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;&#26356;&#22797;&#26434;&#29305;&#24449;&#30340;&#26041;&#27861;&#65307;&#36825;&#20123;&#26041;&#27861;&#22312;&#20302;&#32500;&#20219;&#21153;&#65288;&#22914;&#31354;&#38388;&#24314;&#27169;&#65289;&#20013;&#33021;&#22815;&#26377;&#24456;&#22909;&#30340;&#24615;&#33021;&#65292;&#20294;&#21482;&#20351;&#29992;&#20102;&#19968;&#31867;&#38750;&#24120;&#26377;&#38480;&#30340;&#26680;&#20989;&#25968;&#65292;&#25490;&#38500;&#20102;&#19968;&#20123;&#24120;&#29992;&#30340;&#26680;&#20989;&#25968;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#32508;&#21512;&#20613;&#37324;&#21494;&#29305;&#24449;&#65292;&#23558;&#36825;&#20123;&#24615;&#33021;&#20248;&#21183;&#25193;&#23637;&#21040;&#38750;&#24120;&#24191;&#27867;&#30340;&#24179;&#31283;&#21327;&#26041;&#24046;&#20989;&#25968;&#12290;&#25105;&#20204;&#20174;&#25910;&#25947;&#20998;&#26512;&#21644;&#32463;&#39564;&#25506;&#32034;&#30340;&#35282;&#24230;&#26469;&#35299;&#37322;&#35813;&#26041;&#27861;&#21644;&#21442;&#25968;&#30340;&#36873;&#25321;&#65292;&#21516;&#26102;&#23637;&#31034;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#31354;&#38388;&#22238;&#24402;&#20219;&#21153;&#20013;&#30340;&#23454;&#38469;&#21152;&#36895;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse variational approximations are popular methods for scaling up inference and learning in Gaussian processes to larger datasets. For $N$ training points, exact inference has $O(N^3)$ cost; with $M \ll N$ features, state of the art sparse variational methods have $O(NM^2)$ cost. Recently, methods have been proposed using more sophisticated features; these promise $O(M^3)$ cost, with good performance in low dimensional tasks such as spatial modelling, but they only work with a very limited class of kernels, excluding some of the most commonly used. In this work, we propose integrated Fourier features, which extends these performance benefits to a very broad class of stationary covariance functions. We motivate the method and choice of parameters from a convergence analysis and empirical exploration, and show practical speedup in synthetic and real world spatial regression tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#34701;&#21512;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#21644;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#25439;&#22833;&#20989;&#25968;&#20013;&#20351;&#29992;Wasserstein&#21644;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#24230;&#37327;&#65292;&#23454;&#29616;&#20102;&#23545;&#28508;&#22312;&#31354;&#38388;&#30340;&#26377;&#25928;&#23398;&#20064;&#65292;&#24182;&#33021;&#22815;&#29983;&#25104;&#22810;&#26679;&#19988;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#12290;</title><link>http://arxiv.org/abs/2308.14048</link><description>&lt;p&gt;
&#19968;&#31181;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#29992;&#20110;&#29983;&#25104;&#27169;&#22411;&#65306;&#20351;&#29992;Wasserstein&#21644;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#24230;&#37327;&#38598;&#25104;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#21644;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
A Bayesian Non-parametric Approach to Generative Models: Integrating Variational Autoencoder and Generative Adversarial Networks using Wasserstein and Maximum Mean Discrepancy. (arXiv:2308.14048v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14048
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#34701;&#21512;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#21644;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#25439;&#22833;&#20989;&#25968;&#20013;&#20351;&#29992;Wasserstein&#21644;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#24230;&#37327;&#65292;&#23454;&#29616;&#20102;&#23545;&#28508;&#22312;&#31354;&#38388;&#30340;&#26377;&#25928;&#23398;&#20064;&#65292;&#24182;&#33021;&#22815;&#29983;&#25104;&#22810;&#26679;&#19988;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27169;&#22411;&#24050;&#25104;&#20026;&#19968;&#31181;&#20135;&#29983;&#19982;&#30495;&#23454;&#22270;&#20687;&#38590;&#20197;&#21306;&#20998;&#30340;&#39640;&#36136;&#37327;&#22270;&#20687;&#30340;&#26377;&#21069;&#36884;&#30340;&#25216;&#26415;&#12290;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#21644;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#26159;&#26368;&#20026;&#37325;&#35201;&#19988;&#34987;&#24191;&#27867;&#30740;&#31350;&#30340;&#20004;&#31181;&#29983;&#25104;&#27169;&#22411;&#12290;GAN&#22312;&#29983;&#25104;&#36924;&#30495;&#22270;&#20687;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#32780;VAE&#21017;&#33021;&#22815;&#29983;&#25104;&#22810;&#26679;&#30340;&#22270;&#20687;&#12290;&#28982;&#32780;&#65292;GAN&#24573;&#35270;&#20102;&#22823;&#37096;&#20998;&#21487;&#33021;&#30340;&#36755;&#20986;&#31354;&#38388;&#65292;&#36825;&#23548;&#33268;&#19981;&#33021;&#23436;&#20840;&#20307;&#29616;&#30446;&#26631;&#20998;&#24067;&#30340;&#22810;&#26679;&#24615;&#65292;&#32780;VAE&#21017;&#24120;&#24120;&#29983;&#25104;&#27169;&#31946;&#22270;&#20687;&#12290;&#20026;&#20102;&#20805;&#20998;&#21457;&#25381;&#20004;&#31181;&#27169;&#22411;&#30340;&#20248;&#28857;&#24182;&#20943;&#36731;&#23427;&#20204;&#30340;&#24369;&#28857;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#23558;GAN&#21644;VAE&#30456;&#32467;&#21512;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25439;&#22833;&#20989;&#25968;&#20013;&#21516;&#26102;&#20351;&#29992;&#20102;Wasserstein&#21644;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#24230;&#37327;&#65292;&#20197;&#26377;&#25928;&#23398;&#20064;&#28508;&#22312;&#31354;&#38388;&#24182;&#29983;&#25104;&#22810;&#26679;&#19988;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative models have emerged as a promising technique for producing high-quality images that are indistinguishable from real images. Generative adversarial networks (GANs) and variational autoencoders (VAEs) are two of the most prominent and widely studied generative models. GANs have demonstrated excellent performance in generating sharp realistic images and VAEs have shown strong abilities to generate diverse images. However, GANs suffer from ignoring a large portion of the possible output space which does not represent the full diversity of the target distribution, and VAEs tend to produce blurry images. To fully capitalize on the strengths of both models while mitigating their weaknesses, we employ a Bayesian non-parametric (BNP) approach to merge GANs and VAEs. Our procedure incorporates both Wasserstein and maximum mean discrepancy (MMD) measures in the loss function to enable effective learning of the latent space and generate diverse and high-quality samples. By fusing the di
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#29256;&#30340;GentleAdaboost&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#32447;&#26041;&#24335;&#23558;&#24369;&#20998;&#31867;&#22120;&#19982;&#24378;&#20998;&#31867;&#22120;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#32447;&#25628;&#32034;&#23558;&#25209;&#22788;&#29702;&#26041;&#27861;&#25193;&#23637;&#20026;&#22312;&#32447;&#26041;&#27861;&#30340;&#26041;&#27861;&#65292;&#24182;&#19982;&#20854;&#20182;&#22312;&#32447;&#26041;&#27861;&#22312;&#21508;&#31181;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23545;&#27604;&#12290;</title><link>http://arxiv.org/abs/2308.14004</link><description>&lt;p&gt;
&#22312;&#32447;GentleAdaBoost -- &#25216;&#26415;&#25253;&#21578;
&lt;/p&gt;
&lt;p&gt;
Online GentleAdaBoost -- Technical Report. (arXiv:2308.14004v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14004
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#29256;&#30340;GentleAdaboost&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#32447;&#26041;&#24335;&#23558;&#24369;&#20998;&#31867;&#22120;&#19982;&#24378;&#20998;&#31867;&#22120;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#32447;&#25628;&#32034;&#23558;&#25209;&#22788;&#29702;&#26041;&#27861;&#25193;&#23637;&#20026;&#22312;&#32447;&#26041;&#27861;&#30340;&#26041;&#27861;&#65292;&#24182;&#19982;&#20854;&#20182;&#22312;&#32447;&#26041;&#27861;&#22312;&#21508;&#31181;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23545;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#29256;&#30340;GentleAdaboost&#65292;&#20854;&#20013;&#25105;&#20204;&#20197;&#22312;&#32447;&#26041;&#24335;&#23558;&#19968;&#20010;&#24369;&#20998;&#31867;&#22120;&#19982;&#19968;&#20010;&#24378;&#20998;&#31867;&#22120;&#32467;&#21512;&#36215;&#26469;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#36890;&#36807;&#32447;&#25628;&#32034;&#24212;&#29992;&#30340;&#26041;&#27861;&#65292;&#23558;&#25209;&#22788;&#29702;&#26041;&#27861;&#25193;&#23637;&#20026;&#22312;&#32447;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#35777;&#26126;&#20102;&#20854;&#27491;&#30830;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22312;&#21508;&#31181;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#27604;&#36739;&#20102;&#25105;&#20204;&#30340;&#22312;&#32447;boosting&#26041;&#27861;&#19982;&#20854;&#20182;&#22312;&#32447;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the online variant of GentleAdaboost, where we combine a weak learner to a strong learner in an online fashion. We provide an approach to extend the batch approach to an online approach with theoretical justifications through application of line search. Finally we compare our online boosting approach with other online approaches across a variety of benchmark datasets.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#36816;&#36755;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#25928;&#22320;&#36827;&#34892;&#38745;&#24577;&#27169;&#22411;&#21442;&#25968;&#30340;&#39034;&#24207;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#22788;&#29702;&#21253;&#25324;&#24178;&#25200;&#21442;&#25968;&#30340;&#22797;&#26434;&#22122;&#22768;&#27169;&#22411;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#20165;&#20316;&#20026;&#40657;&#31665;&#30340;&#27491;&#21521;&#27169;&#22411;&#12290;&#25968;&#20540;&#24212;&#29992;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#20351;&#29992;&#30005;&#23548;&#29575;&#27979;&#37327;&#26469;&#34920;&#24449;&#20912;&#21402;&#24230;&#30340;&#24773;&#20917;&#19979;&#26159;&#26377;&#25928;&#30340;&#12290;</title><link>http://arxiv.org/abs/2308.13940</link><description>&lt;p&gt;
&#20351;&#29992;&#36816;&#36755;&#26041;&#27861;&#36827;&#34892;&#39034;&#24207;&#22522;&#20110;&#27169;&#25311;&#30340;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
A transport approach to sequential simulation-based inference. (arXiv:2308.13940v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13940
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#36816;&#36755;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#25928;&#22320;&#36827;&#34892;&#38745;&#24577;&#27169;&#22411;&#21442;&#25968;&#30340;&#39034;&#24207;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#22788;&#29702;&#21253;&#25324;&#24178;&#25200;&#21442;&#25968;&#30340;&#22797;&#26434;&#22122;&#22768;&#27169;&#22411;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#20165;&#20316;&#20026;&#40657;&#31665;&#30340;&#27491;&#21521;&#27169;&#22411;&#12290;&#25968;&#20540;&#24212;&#29992;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#20351;&#29992;&#30005;&#23548;&#29575;&#27979;&#37327;&#26469;&#34920;&#24449;&#20912;&#21402;&#24230;&#30340;&#24773;&#20917;&#19979;&#26159;&#26377;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#36816;&#36755;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#25928;&#22320;&#36827;&#34892;&#38745;&#24577;&#27169;&#22411;&#21442;&#25968;&#30340;&#39034;&#24207;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#35813;&#31574;&#30053;&#22522;&#20110;&#20174;&#21442;&#25968;&#21644;&#25968;&#25454;&#30340;&#32852;&#21512;&#20998;&#24067;&#20013;&#25552;&#21462;&#26465;&#20214;&#20998;&#24067;&#65292;&#36890;&#36807;&#20272;&#35745;&#32467;&#26500;&#21270;&#65288;&#20363;&#22914;&#65292;&#22359;&#19977;&#35282;&#24418;&#65289;&#36816;&#36755;&#26144;&#23556;&#26469;&#23454;&#29616;&#12290;&#36825;&#20026;&#20284;&#28982;&#20989;&#25968;&#21450;&#20854;&#26799;&#24230;&#25552;&#20379;&#20102;&#26126;&#30830;&#30340;&#20195;&#29702;&#27169;&#22411;&#12290;&#36825;&#20801;&#35768;&#22312;&#27169;&#22411;&#26080;&#20851;&#12289;&#22312;&#32447;&#38454;&#27573;&#36890;&#36807;&#36816;&#36755;&#26144;&#23556;&#36827;&#34892;&#22522;&#20110;&#26799;&#24230;&#30340;&#21518;&#39564;&#23494;&#24230;&#34920;&#24449;&#12290;&#36825;&#20010;&#26694;&#26550;&#38750;&#24120;&#36866;&#29992;&#20110;&#22797;&#26434;&#22122;&#22768;&#27169;&#22411;&#65288;&#21253;&#25324;&#24178;&#25200;&#21442;&#25968;&#65289;&#21644;&#20165;&#20316;&#20026;&#40657;&#31665;&#30340;&#27491;&#21521;&#27169;&#22411;&#30340;&#21442;&#25968;&#20272;&#35745;&#12290;&#25105;&#20204;&#22312;&#20351;&#29992;&#30005;&#23548;&#29575;&#27979;&#37327;&#26469;&#34920;&#24449;&#20912;&#21402;&#24230;&#30340;&#24773;&#20917;&#19979;&#23545;&#35813;&#26041;&#27861;&#36827;&#34892;&#20102;&#25968;&#20540;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new transport-based approach to efficiently perform sequential Bayesian inference of static model parameters. The strategy is based on the extraction of conditional distribution from the joint distribution of parameters and data, via the estimation of structured (e.g., block triangular) transport maps. This gives explicit surrogate models for the likelihood functions and their gradients. This allow gradient-based characterizations of posterior density via transport maps in a model-free, online phase. This framework is well suited for parameter estimation in case of complex noise models including nuisance parameters and when the forward model is only known as a black box. The numerical application of this method is performed in the context of characterization of ice thickness with conductivity measurements.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29109;&#30340;&#30701;&#26399;&#35843;&#25972;MCMC&#38142;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20248;&#21270;&#26356;&#32039;&#30340;&#21464;&#20998;&#36793;&#30028;&#30340;&#21516;&#26102;&#65292;&#36866;&#24212;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#25552;&#26696;&#20998;&#24067;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#20351;&#27169;&#22411;&#24471;&#21040;&#26356;&#39640;&#30340;&#20445;&#30041;&#23545;&#25968;&#20284;&#28982;&#21644;&#25913;&#36827;&#30340;&#29983;&#25104;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.13731</link><description>&lt;p&gt;
&#36890;&#36807;MCMC&#36895;&#24230;&#24230;&#37327;&#23398;&#20064;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Learning variational autoencoders via MCMC speed measures. (arXiv:2308.13731v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13731
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29109;&#30340;&#30701;&#26399;&#35843;&#25972;MCMC&#38142;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20248;&#21270;&#26356;&#32039;&#30340;&#21464;&#20998;&#36793;&#30028;&#30340;&#21516;&#26102;&#65292;&#36866;&#24212;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#25552;&#26696;&#20998;&#24067;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#20351;&#27169;&#22411;&#24471;&#21040;&#26356;&#39640;&#30340;&#20445;&#30041;&#23545;&#25968;&#20284;&#28982;&#21644;&#25913;&#36827;&#30340;&#29983;&#25104;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#22522;&#20110;&#20284;&#28982;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#21487;&#20197;&#36890;&#36807;&#26368;&#22823;&#21270;&#19979;&#30028;&#65288;ELBO&#65289;&#26469;&#26377;&#25928;&#35757;&#32451;&#12290;&#20026;&#20102;&#33719;&#24471;&#26356;&#32039;&#30340;&#21464;&#20998;&#36793;&#30028;&#21644;&#26356;&#39640;&#30340;&#29983;&#25104;&#24615;&#33021;&#65292;&#25913;&#36827;&#21464;&#20998;&#20998;&#24067;&#30340;&#34920;&#36798;&#33021;&#21147;&#21462;&#24471;&#20102;&#24456;&#22823;&#36827;&#23637;&#12290;&#34429;&#28982;&#20808;&#21069;&#30340;&#24037;&#20316;&#21033;&#29992;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#65288;MCMC&#65289;&#26041;&#27861;&#26500;&#24314;&#20102;&#21464;&#20998;&#23494;&#24230;&#65292;&#20294;&#38024;&#23545;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#35843;&#25972;&#25552;&#26696;&#20998;&#24067;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#21463;&#21040;&#30340;&#20851;&#27880;&#36739;&#23569;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#29109;&#30340;&#30701;&#26399;&#35843;&#25972;Metropolis-adjusted Langevin&#65288;MALA&#65289;&#25110;Hamiltonian Monte Carlo&#65288;HMC&#65289;&#38142;&#30340;&#26041;&#27861;&#65292;&#24182;&#20248;&#21270;&#26356;&#32039;&#30340;&#21464;&#20998;&#36793;&#30028;&#20197;&#33719;&#24471;&#23545;&#25968;&#20284;&#28982;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#20135;&#29983;&#20102;&#26356;&#39640;&#30340;&#20445;&#30041;&#23545;&#25968;&#20284;&#28982;&#20197;&#21450;&#25913;&#36827;&#30340;&#29983;&#25104;&#25351;&#26631;&#12290;&#25105;&#20204;&#30340;&#38544;&#24335;&#21464;&#20998;&#23494;&#24230;&#33021;&#22815;&#36866;&#24212;&#28508;&#22312;&#23618;&#27425;&#34920;&#31034;&#30340;&#22797;&#26434;&#21518;&#39564;&#20960;&#20309;&#24418;&#29366;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational autoencoders (VAEs) are popular likelihood-based generative models which can be efficiently trained by maximizing an Evidence Lower Bound (ELBO). There has been much progress in improving the expressiveness of the variational distribution to obtain tighter variational bounds and increased generative performance. Whilst previous work has leveraged Markov chain Monte Carlo (MCMC) methods for the construction of variational densities, gradient-based methods for adapting the proposal distributions for deep latent variable models have received less attention. This work suggests an entropy-based adaptation for a short-run Metropolis-adjusted Langevin (MALA) or Hamiltonian Monte Carlo (HMC) chain while optimising a tighter variational bound to the log-evidence. Experiments show that this approach yields higher held-out log-likelihoods as well as improved generative metrics. Our implicit variational density can adapt to complicated posterior geometries of latent hierarchical repres
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#24191;&#20041;&#30697;&#26041;&#27861;&#65288;SGMM&#65289;&#65292;&#29992;&#20110;&#20272;&#35745;&#21644;&#25512;&#26029;&#30697;&#38480;&#21046;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#24555;&#36895;&#21644;&#21487;&#25193;&#23637;&#30340;&#23454;&#26102;&#22788;&#29702;&#33021;&#21147;&#65292;&#24182;&#19988;&#33021;&#22815;&#22788;&#29702;&#22823;&#35268;&#27169;&#21644;&#22312;&#32447;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2308.13564</link><description>&lt;p&gt;
SGMM: &#24191;&#20041;&#30697;&#26041;&#27861;&#30340;&#38543;&#26426;&#36817;&#20284;
&lt;/p&gt;
&lt;p&gt;
SGMM: Stochastic Approximation to Generalized Method of Moments. (arXiv:2308.13564v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13564
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#24191;&#20041;&#30697;&#26041;&#27861;&#65288;SGMM&#65289;&#65292;&#29992;&#20110;&#20272;&#35745;&#21644;&#25512;&#26029;&#30697;&#38480;&#21046;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#24555;&#36895;&#21644;&#21487;&#25193;&#23637;&#30340;&#23454;&#26102;&#22788;&#29702;&#33021;&#21147;&#65292;&#24182;&#19988;&#33021;&#22815;&#22788;&#29702;&#22823;&#35268;&#27169;&#21644;&#22312;&#32447;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#31867;&#65292;&#38543;&#26426;&#24191;&#20041;&#30697;&#26041;&#27861;&#65288;SGMM&#65289;&#65292;&#29992;&#20110;&#20272;&#35745;&#21644;&#25512;&#26029;&#65288;&#36229;&#35782;&#21035;&#65289;&#30697;&#38480;&#21046;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;SGMM&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#38543;&#26426;&#36924;&#36817;&#26041;&#27861;&#65292;&#26367;&#20195;&#20102;&#27969;&#34892;&#30340;Hansen&#65288;1982&#24180;&#65289;&#30340;&#65288;&#31163;&#32447;&#65289;GMM&#65292;&#24182;&#25552;&#20379;&#20102;&#24555;&#36895;&#21644;&#21487;&#25193;&#23637;&#30340;&#23454;&#26102;&#27969;&#25968;&#25454;&#22788;&#29702;&#33021;&#21147;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;SGMM&#23545;&#20110;&#25928;&#29575;&#19981;&#39640;&#30340;&#22312;&#32447;2SLS&#21644;&#39640;&#25928;&#30340;SGMM&#20855;&#26377;&#20960;&#20046;&#30830;&#23450;&#30340;&#25910;&#25947;&#24615;&#21644;&#65288;&#20989;&#25968;&#65289;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Durbin-Wu-Hausman&#21644;Sargan-Hansen&#27979;&#35797;&#30340;&#22312;&#32447;&#29256;&#26412;&#65292;&#21487;&#20197;&#26080;&#32541;&#38598;&#25104;&#21040;SGMM&#26694;&#26550;&#20013;&#12290;&#24191;&#27867;&#30340;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#32467;&#26524;&#34920;&#26126;&#65292;&#38543;&#30528;&#26679;&#26412;&#37327;&#30340;&#22686;&#21152;&#65292;SGMM&#22312;&#20272;&#35745;&#20934;&#30830;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#26041;&#38754;&#19982;&#26631;&#20934;&#65288;&#31163;&#32447;&#65289;GMM&#30456;&#21305;&#37197;&#65292;&#24182;&#26174;&#31034;&#20986;&#22312;&#22823;&#35268;&#27169;&#21644;&#22312;&#32447;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#38469;&#20215;&#20540;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#20004;&#20010;&#31034;&#20363;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new class of algorithms, Stochastic Generalized Method of Moments (SGMM), for estimation and inference on (overidentified) moment restriction models. Our SGMM is a novel stochastic approximation alternative to the popular Hansen (1982) (offline) GMM, and offers fast and scalable implementation with the ability to handle streaming datasets in real time. We establish the almost sure convergence, and the (functional) central limit theorem for the inefficient online 2SLS and the efficient SGMM. Moreover, we propose online versions of the Durbin-Wu-Hausman and Sargan-Hansen tests that can be seamlessly integrated within the SGMM framework. Extensive Monte Carlo simulations show that as the sample size increases, the SGMM matches the standard (offline) GMM in terms of estimation accuracy and gains over computational efficiency, indicating its practical value for both large-scale and online datasets. We demonstrate the efficacy of our approach by a proof of concept using two we
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#32852;&#37030;&#32447;&#24615;&#36172;&#21338;&#23398;&#20064;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26080;&#32447;&#35745;&#31639;&#30340;&#26041;&#26696;&#65292;&#20197;&#20943;&#23569;&#36890;&#20449;&#24320;&#38144;&#12290;&#36890;&#36807;&#22312;&#22122;&#22768;&#34928;&#33853;&#20449;&#36947;&#19978;&#36827;&#34892;&#30340;&#27169;&#25311;&#20449;&#21495;&#20256;&#36755;&#65292;&#25105;&#20204;&#30340;&#26041;&#26696;&#22312;&#38477;&#20302;&#32047;&#31215;&#36951;&#25022;&#26041;&#38754;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#12290;</title><link>http://arxiv.org/abs/2308.13298</link><description>&lt;p&gt;
&#36890;&#36807;&#26080;&#32447;&#35745;&#31639;&#23454;&#29616;&#32852;&#37030;&#32447;&#24615;&#36172;&#21338;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Federated Linear Bandit Learning via Over-the-Air Computation. (arXiv:2308.13298v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13298
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#32852;&#37030;&#32447;&#24615;&#36172;&#21338;&#23398;&#20064;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26080;&#32447;&#35745;&#31639;&#30340;&#26041;&#26696;&#65292;&#20197;&#20943;&#23569;&#36890;&#20449;&#24320;&#38144;&#12290;&#36890;&#36807;&#22312;&#22122;&#22768;&#34928;&#33853;&#20449;&#36947;&#19978;&#36827;&#34892;&#30340;&#27169;&#25311;&#20449;&#21495;&#20256;&#36755;&#65292;&#25105;&#20204;&#30340;&#26041;&#26696;&#22312;&#38477;&#20302;&#32047;&#31215;&#36951;&#25022;&#26041;&#38754;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#30001;&#26381;&#21153;&#22120;&#21644;&#22810;&#20010;&#35774;&#22791;&#32452;&#25104;&#30340;&#26080;&#32447;&#31995;&#32479;&#20013;&#30340;&#32852;&#37030;&#32972;&#26223;&#19979;&#30340;&#32447;&#24615;&#36172;&#21338;&#23398;&#20064;&#12290;&#27599;&#20010;&#35774;&#22791;&#19982;&#29615;&#22659;&#20132;&#20114;&#65292;&#22312;&#25509;&#25910;&#21040;&#22870;&#21169;&#21518;&#36873;&#25321;&#19968;&#20010;&#21160;&#20316;&#65292;&#24182;&#23558;&#27169;&#22411;&#26356;&#26032;&#21457;&#36865;&#21040;&#26381;&#21153;&#22120;&#12290;&#20027;&#35201;&#30446;&#26631;&#26159;&#22312;&#26377;&#38480;&#30340;&#26102;&#38388;&#33539;&#22260;&#20869;&#26368;&#23567;&#21270;&#25152;&#26377;&#35774;&#22791;&#30340;&#32047;&#31215;&#36951;&#25022;&#12290;&#20026;&#20102;&#20943;&#23569;&#36890;&#20449;&#24320;&#38144;&#65292;&#35774;&#22791;&#36890;&#36807;&#26080;&#32447;&#35745;&#31639;&#65288;AirComp&#65289;&#22312;&#22122;&#22768;&#34928;&#33853;&#20449;&#36947;&#19978;&#19982;&#26381;&#21153;&#22120;&#36890;&#20449;&#65292;&#20854;&#20013;&#36890;&#36947;&#22122;&#22768;&#21487;&#33021;&#20250;&#25197;&#26354;&#20449;&#21495;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23450;&#21046;&#30340;&#32852;&#37030;&#32447;&#24615;&#36172;&#21338;&#26041;&#26696;&#65292;&#20854;&#20013;&#27599;&#20010;&#35774;&#22791;&#20256;&#36755;&#19968;&#20010;&#27169;&#25311;&#20449;&#21495;&#65292;&#26381;&#21153;&#22120;&#25509;&#25910;&#21040;&#30340;&#26159;&#36825;&#20123;&#20449;&#21495;&#30340;&#21472;&#21152;&#65292;&#21463;&#21040;&#20449;&#36947;&#22122;&#22768;&#30340;&#25197;&#26354;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#20005;&#26684;&#30340;&#25968;&#23398;&#20998;&#26512;&#65292;&#30830;&#23450;&#20102;&#35813;&#26041;&#26696;&#30340;&#36951;&#25022;&#19978;&#38480;&#12290;&#29702;&#35770;&#20998;&#26512;&#21644;&#25968;&#20540;&#23454;&#39564;&#37117;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#26696;&#22312;&#24615;&#33021;&#26041;&#38754;&#30340;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we investigate federated contextual linear bandit learning within a wireless system that comprises a server and multiple devices. Each device interacts with the environment, selects an action based on the received reward, and sends model updates to the server. The primary objective is to minimize cumulative regret across all devices within a finite time horizon. To reduce the communication overhead, devices communicate with the server via over-the-air computation (AirComp) over noisy fading channels, where the channel noise may distort the signals. In this context, we propose a customized federated linear bandits scheme, where each device transmits an analog signal, and the server receives a superposition of these signals distorted by channel noise. A rigorous mathematical analysis is conducted to determine the regret bound of the proposed scheme. Both theoretical analysis and numerical experiments demonstrate the competitive performance of our proposed scheme in terms o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#26680;&#23398;&#20064;&#30340;&#25903;&#25345;&#21521;&#37327;&#26426;&#26694;&#26550;(MKL-$L_{0/1}$-SVM)&#65292;&#36890;&#36807;&#24320;&#21457;&#24555;&#36895;&#30340;ADMM&#27714;&#35299;&#22120;&#22788;&#29702;&#38750;&#20984;&#38750;&#20809;&#28369;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#19982;&#39046;&#20808;&#26041;&#27861;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.12016</link><description>&lt;p&gt;
MKL-$L_{0/1}$-SVM: &#19968;&#31181;&#22810;&#26680;&#23398;&#20064;&#30340;&#25903;&#25345;&#21521;&#37327;&#26426;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
MKL-$L_{0/1}$-SVM. (arXiv:2308.12016v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12016
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#26680;&#23398;&#20064;&#30340;&#25903;&#25345;&#21521;&#37327;&#26426;&#26694;&#26550;(MKL-$L_{0/1}$-SVM)&#65292;&#36890;&#36807;&#24320;&#21457;&#24555;&#36895;&#30340;ADMM&#27714;&#35299;&#22120;&#22788;&#29702;&#38750;&#20984;&#38750;&#20809;&#28369;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#19982;&#39046;&#20808;&#26041;&#27861;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;$(0, 1)$&#25439;&#22833;&#20989;&#25968;&#30340;&#25903;&#25345;&#21521;&#37327;&#26426;&#30340;&#22810;&#26680;&#23398;&#20064;&#65288;MKL&#65289;&#26694;&#26550;&#12290;&#39318;&#20808;&#32473;&#20986;&#20102;&#19968;&#38454;&#26368;&#20248;&#24615;&#26465;&#20214;&#65292;&#28982;&#21518;&#21033;&#29992;&#23427;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#24555;&#36895;&#30340;ADMM&#27714;&#35299;&#22120;&#26469;&#22788;&#29702;&#38750;&#20984;&#38750;&#20809;&#28369;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#35814;&#32454;&#30340;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;MKL-$L_{0/1}$-SVM&#30340;&#24615;&#33021;&#19982;&#19968;&#31181;&#21517;&#20026;SimpleMKL&#30340;&#39046;&#20808;&#26041;&#27861;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a Multiple Kernel Learning (abbreviated as MKL) framework for the Support Vector Machine (SVM) with the $(0, 1)$ loss function. Some first-order optimality conditions are given and then exploited to develop a fast ADMM solver to deal with the nonconvex and nonsmooth optimization problem. Extensive numerical experiments on synthetic and real datasets show that the performance of our MKL-$L_{0/1}$-SVM is comparable with the one of the leading approaches called SimpleMKL developed by Rakotomamonjy, Bach, Canu, and Grandvalet [Journal of Machine Learning Research, vol. 9, pp. 2491-2521, 2008].
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;Wasserstein&#20960;&#20309;&#29983;&#25104;&#22120;&#23398;&#20064;&#26465;&#20214;&#20998;&#24067;&#65292;&#29983;&#25104;&#32473;&#23450;&#29305;&#23450;&#26631;&#31614;&#30340;&#26679;&#26412;&#12290;&#20351;&#29992;&#26368;&#20248;&#36755;&#36816;&#29702;&#35770;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#23398;&#20064;&#35266;&#23519;&#22495;&#30340;&#26465;&#20214;&#20998;&#24067;&#21644;&#23427;&#20204;&#20043;&#38388;&#30340;&#26368;&#20248;&#36755;&#36816;&#26144;&#23556;&#12290;&#22312;&#20154;&#33080;&#22270;&#20687;&#25968;&#25454;&#19978;&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.10145</link><description>&lt;p&gt;
Wasserstein&#20960;&#20309;&#29983;&#25104;&#22120;&#29992;&#20110;&#26465;&#20214;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Wasserstein Geodesic Generator for Conditional Distributions. (arXiv:2308.10145v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10145
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;Wasserstein&#20960;&#20309;&#29983;&#25104;&#22120;&#23398;&#20064;&#26465;&#20214;&#20998;&#24067;&#65292;&#29983;&#25104;&#32473;&#23450;&#29305;&#23450;&#26631;&#31614;&#30340;&#26679;&#26412;&#12290;&#20351;&#29992;&#26368;&#20248;&#36755;&#36816;&#29702;&#35770;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#23398;&#20064;&#35266;&#23519;&#22495;&#30340;&#26465;&#20214;&#20998;&#24067;&#21644;&#23427;&#20204;&#20043;&#38388;&#30340;&#26368;&#20248;&#36755;&#36816;&#26144;&#23556;&#12290;&#22312;&#20154;&#33080;&#22270;&#20687;&#25968;&#25454;&#19978;&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#32473;&#23450;&#29305;&#23450;&#26631;&#31614;&#30340;&#26679;&#26412;&#38656;&#35201;&#20272;&#35745;&#26465;&#20214;&#20998;&#24067;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#26465;&#20214;&#20998;&#24067;&#20043;&#38388;Wasserstein&#36317;&#31163;&#30340;&#21487;&#22788;&#29702;&#30340;&#19978;&#30028;&#65292;&#20197;&#24314;&#31435;&#23398;&#20064;&#26465;&#20214;&#20998;&#24067;&#30340;&#29702;&#35770;&#22522;&#30784;&#12290;&#22522;&#20110;&#36825;&#19968;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26465;&#20214;&#29983;&#25104;&#31639;&#27861;&#65292;&#20854;&#20013;&#26465;&#20214;&#20998;&#24067;&#23436;&#20840;&#30001;&#30001;&#32479;&#35745;&#36317;&#31163;&#23450;&#20041;&#30340;&#24230;&#37327;&#31354;&#38388;&#26469;&#34920;&#24449;&#12290;&#25105;&#20204;&#21033;&#29992;&#26368;&#20248;&#36755;&#36816;&#29702;&#35770;&#26469;&#25552;&#20986;&#20102;Wasserstein&#20960;&#20309;&#29983;&#25104;&#22120;&#65292;&#19968;&#31181;&#23398;&#20064;Wasserstein&#20960;&#20309;&#30340;&#26032;&#30340;&#26465;&#20214;&#29983;&#25104;&#22120;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#23398;&#20064;&#35266;&#23519;&#22495;&#30340;&#26465;&#20214;&#20998;&#24067;&#21644;&#23427;&#20204;&#20043;&#38388;&#30340;&#26368;&#20248;&#36755;&#36816;&#26144;&#23556;&#12290;&#32473;&#23450;&#20004;&#20010;&#35266;&#23519;&#22495;&#26631;&#31614;&#65292;&#26410;&#35266;&#23519;&#21040;&#30340;&#20013;&#38388;&#22495;&#30340;&#26465;&#20214;&#20998;&#24067;&#20301;&#20110;&#32473;&#23450;&#30340;&#26465;&#20214;&#20998;&#24067;&#20043;&#38388;&#30340;Wasserstein&#20960;&#20309;&#20013;&#12290;&#22312;&#20197;&#20809;&#29031;&#26465;&#20214;&#20026;&#22495;&#26631;&#31614;&#30340;&#20154;&#33080;&#22270;&#20687;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generating samples given a specific label requires estimating conditional distributions. We derive a tractable upper bound of the Wasserstein distance between conditional distributions to lay the theoretical groundwork to learn conditional distributions. Based on this result, we propose a novel conditional generation algorithm where conditional distributions are fully characterized by a metric space defined by a statistical distance. We employ optimal transport theory to propose the \textit{Wasserstein geodesic generator}, a new conditional generator that learns the Wasserstein geodesic. The proposed method learns both conditional distributions for observed domains and optimal transport maps between them. The conditional distributions given unobserved intermediate domains are on the Wasserstein geodesic between conditional distributions given two observed domain labels. Experiments on face images with light conditions as domain labels demonstrate the efficacy of the proposed method.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#31216;&#20026;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#29992;&#20110;&#26681;&#25454;&#19978;&#19979;&#25991;&#22240;&#32032;&#21644;&#30446;&#26631;&#20154;&#19982;&#20854;&#29031;&#39038;&#20276;&#20387;&#30340;&#36807;&#21435;&#21453;&#39304;&#65292;&#20010;&#24615;&#21270;&#22320;&#25552;&#20379;&#24178;&#39044;&#25514;&#26045;&#12290;&#35813;&#31639;&#27861;&#26159;&#36125;&#21494;&#26031;&#21644;&#23618;&#27425;&#30340;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#23637;&#31034;&#20102;&#33391;&#22909;&#30340;&#23454;&#35777;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.07843</link><description>&lt;p&gt;
Dyadic Reinforcement Learning. (arXiv:2308.07843v1 [cs.LG]) &#35813;&#35770;&#25991;&#26631;&#39064;&#24050;&#32763;&#35793;&#65306;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dyadic Reinforcement Learning. (arXiv:2308.07843v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07843
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#31216;&#20026;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#29992;&#20110;&#26681;&#25454;&#19978;&#19979;&#25991;&#22240;&#32032;&#21644;&#30446;&#26631;&#20154;&#19982;&#20854;&#29031;&#39038;&#20276;&#20387;&#30340;&#36807;&#21435;&#21453;&#39304;&#65292;&#20010;&#24615;&#21270;&#22320;&#25552;&#20379;&#24178;&#39044;&#25514;&#26045;&#12290;&#35813;&#31639;&#27861;&#26159;&#36125;&#21494;&#26031;&#21644;&#23618;&#27425;&#30340;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#23637;&#31034;&#20102;&#33391;&#22909;&#30340;&#23454;&#35777;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31227;&#21160;&#21307;&#30103;&#26088;&#22312;&#36890;&#36807;&#22312;&#20010;&#20154;&#26085;&#24120;&#29983;&#27963;&#20013;&#25552;&#20379;&#24178;&#39044;&#26469;&#25552;&#39640;&#20581;&#24247;&#32467;&#26524;&#12290;&#29031;&#39038;&#20276;&#20387;&#21644;&#31038;&#20250;&#25903;&#25345;&#32593;&#32476;&#30340;&#21442;&#19982;&#32463;&#24120;&#22312;&#24110;&#21161;&#20010;&#20154;&#31649;&#29702;&#32321;&#37325;&#30340;&#21307;&#30103;&#26465;&#20214;&#26041;&#38754;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#36825;&#20026;&#31227;&#21160;&#21307;&#30103;&#25552;&#20379;&#20102;&#26426;&#20250;&#65292;&#35774;&#35745;&#38024;&#23545;&#20108;&#20803;&#20851;&#31995;&#8212;&#8212;&#30446;&#26631;&#20154;&#21644;&#20854;&#29031;&#39038;&#20276;&#20387;&#20043;&#38388;&#20851;&#31995;&#8212;&#8212;&#20197;&#25552;&#39640;&#31038;&#20250;&#25903;&#25345;&#30340;&#24178;&#39044;&#25514;&#26045;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#65288;Dyadic RL&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#29615;&#22659;&#22240;&#32032;&#21644;&#30446;&#26631;&#20154;&#21450;&#20854;&#29031;&#39038;&#20276;&#20387;&#30340;&#36807;&#21435;&#21453;&#39304;&#20010;&#24615;&#21270;&#24178;&#39044;&#25514;&#26045;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#12290;&#22312;&#36825;&#37324;&#65292;&#22810;&#32452;&#24178;&#39044;&#25514;&#26045;&#24433;&#21709;&#30528;&#20108;&#20803;&#20851;&#31995;&#22312;&#22810;&#20010;&#26102;&#38388;&#38388;&#38548;&#20869;&#12290;&#24320;&#21457;&#30340;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#26159;&#36125;&#21494;&#26031;&#21644;&#23618;&#27425;&#30340;&#12290;&#25105;&#20204;&#27491;&#24335;&#20171;&#32461;&#20102;&#38382;&#39064;&#35774;&#23450;&#65292;&#24320;&#21457;&#20102;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#24182;&#30830;&#23450;&#20102;&#36951;&#25022;&#36793;&#30028;&#12290;&#36890;&#36807;&#27169;&#25311;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#30340;&#23454;&#35777;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mobile health aims to enhance health outcomes by delivering interventions to individuals as they go about their daily life. The involvement of care partners and social support networks often proves crucial in helping individuals managing burdensome medical conditions. This presents opportunities in mobile health to design interventions that target the dyadic relationship -- the relationship between a target person and their care partner -- with the aim of enhancing social support. In this paper, we develop dyadic RL, an online reinforcement learning algorithm designed to personalize intervention delivery based on contextual factors and past responses of a target person and their care partner. Here, multiple sets of interventions impact the dyad across multiple time intervals. The developed dyadic RL is Bayesian and hierarchical. We formally introduce the problem setup, develop dyadic RL and establish a regret bound. We demonstrate dyadic RL's empirical performance through simulation st
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#36817;&#26399;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#21457;&#23637;&#65292;&#37325;&#28857;&#20851;&#27880;&#34920;&#26684;&#25968;&#25454;&#38598;&#12290;&#36890;&#36807;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#29983;&#25104;&#38544;&#31169;&#25935;&#24863;&#25968;&#25454;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#24182;&#35299;&#20915;&#25968;&#25454;&#24402;&#19968;&#21270;&#12289;&#38544;&#31169;&#21644;&#35780;&#20272;&#31561;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2307.15424</link><description>&lt;p&gt;
&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#12289;&#21512;&#25104;&#34920;&#26684;&#25968;&#25454;&#21644;&#24046;&#20998;&#38544;&#31169;&#65306;&#32508;&#36848;&#19982;&#32508;&#21512;
&lt;/p&gt;
&lt;p&gt;
Deep Generative Models, Synthetic Tabular Data, and Differential Privacy: An Overview and Synthesis. (arXiv:2307.15424v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15424
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#36817;&#26399;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#21457;&#23637;&#65292;&#37325;&#28857;&#20851;&#27880;&#34920;&#26684;&#25968;&#25454;&#38598;&#12290;&#36890;&#36807;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#29983;&#25104;&#38544;&#31169;&#25935;&#24863;&#25968;&#25454;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#24182;&#35299;&#20915;&#25968;&#25454;&#24402;&#19968;&#21270;&#12289;&#38544;&#31169;&#21644;&#35780;&#20272;&#31561;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20840;&#38754;&#32508;&#36848;&#20102;&#36890;&#36807;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#37325;&#28857;&#20851;&#27880;&#34920;&#26684;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#29305;&#21035;&#27010;&#36848;&#20102;&#22312;&#38544;&#31169;&#25935;&#24863;&#25968;&#25454;&#32972;&#26223;&#19979;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#30340;&#37325;&#35201;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30456;&#23545;&#20110;&#20854;&#20182;&#26041;&#27861;&#30340;&#20248;&#21183;&#65292;&#24182;&#35814;&#32454;&#35299;&#37322;&#20102;&#21253;&#25324;&#26080;&#30417;&#30563;&#23398;&#20064;&#12289;&#31070;&#32463;&#32593;&#32476;&#21644;&#29983;&#25104;&#27169;&#22411;&#22312;&#20869;&#30340;&#22522;&#26412;&#27010;&#24565;&#12290;&#35770;&#25991;&#28085;&#30422;&#20102;&#22312;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#22788;&#29702;&#34920;&#26684;&#25968;&#25454;&#38598;&#26102;&#28041;&#21450;&#30340;&#25361;&#25112;&#21644;&#32771;&#34385;&#22240;&#32032;&#65292;&#22914;&#25968;&#25454;&#24402;&#19968;&#21270;&#12289;&#38544;&#31169;&#38382;&#39064;&#21644;&#27169;&#22411;&#35780;&#20272;&#12290;&#26412;&#32508;&#36848;&#20026;&#23545;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#21450;&#20854;&#24212;&#29992;&#24863;&#20852;&#36259;&#30340;&#30740;&#31350;&#20154;&#21592;&#21644;&#23454;&#36341;&#32773;&#25552;&#20379;&#20102;&#23453;&#36149;&#30340;&#36164;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article provides a comprehensive synthesis of the recent developments in synthetic data generation via deep generative models, focusing on tabular datasets. We specifically outline the importance of synthetic data generation in the context of privacy-sensitive data. Additionally, we highlight the advantages of using deep generative models over other methods and provide a detailed explanation of the underlying concepts, including unsupervised learning, neural networks, and generative models. The paper covers the challenges and considerations involved in using deep generative models for tabular datasets, such as data normalization, privacy concerns, and model evaluation. This review provides a valuable resource for researchers and practitioners interested in synthetic data generation and its applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#26080;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#21542;&#23450;&#20998;&#26512;&#24072;&#23545;&#22522;&#20110;&#21452;&#37325;&#26426;&#22120;&#23398;&#20064;&#20272;&#35745;&#30340;Wald&#32622;&#20449;&#21306;&#38388;&#22312;&#24191;&#27867;&#30340;&#21452;&#37325;&#31283;&#20581;&#20989;&#25968;&#31867;&#20013;&#30340;&#26377;&#25928;&#24615;&#30340;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2306.10590</link><description>&lt;p&gt;
&#25105;&#20204;&#33021;&#21542;&#22312;&#19981;&#20570;&#20219;&#20309;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#35777;&#20266;Wald&#32622;&#20449;&#21306;&#38388;&#22312;&#21452;&#37325;&#31283;&#20581;&#20989;&#25968;&#19979;&#30340;&#26377;&#25928;&#24615;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can we falsify the justification of the validity of Wald confidence intervals of doubly robust functionals, without assumptions?. (arXiv:2306.10590v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10590
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#26080;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#21542;&#23450;&#20998;&#26512;&#24072;&#23545;&#22522;&#20110;&#21452;&#37325;&#26426;&#22120;&#23398;&#20064;&#20272;&#35745;&#30340;Wald&#32622;&#20449;&#21306;&#38388;&#22312;&#24191;&#27867;&#30340;&#21452;&#37325;&#31283;&#20581;&#20989;&#25968;&#31867;&#20013;&#30340;&#26377;&#25928;&#24615;&#30340;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#34892;&#30340;&#29256;&#26412;&#30340;&#26080;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#21542;&#23450;&#20998;&#26512;&#24072;&#23545;&#25253;&#36947;&#30340;&#20197;&#21452;&#37325;&#26426;&#22120;&#23398;&#20064;(DML)&#20272;&#35745;&#37327;&#20026;&#20013;&#24515;&#30340;&#21517;&#20041;$(1-\alpha)$Wald&#32622;&#20449;&#21306;&#38388;&#30340;&#26377;&#25928;&#24615;&#30340;&#35777;&#26126;&#65292;&#23545;Rotnitzky&#31561;&#20154;&#25152;&#30740;&#31350;&#30340;&#21452;&#37325;&#31283;&#20581;(DR)&#20989;&#25968;&#31867;&#30340;&#20219;&#20309;&#25104;&#21592;&#36827;&#34892;&#26816;&#39564;&#12290;DR&#20989;&#25968;&#31867;&#22312;&#32463;&#27982;&#23398;&#21644;&#29983;&#29289;&#32479;&#35745;&#23398;&#20013;&#20855;&#26377;&#24191;&#27867;&#21644;&#26680;&#24515;&#30340;&#37325;&#35201;&#24615;&#12290;&#23427;&#20005;&#26684;&#21253;&#25324;&#20004;&#20010;&#31867;&#21035;&#65292;&#21363;(i)&#21487;&#20197;&#34987;&#20889;&#25104;&#26465;&#20214;&#26399;&#26395;&#30340;&#20223;&#23556;&#20989;&#25968;&#26399;&#26395;&#30340;&#22343;&#26041;&#36830;&#32493;&#20989;&#25968;&#30340;&#31867;&#21035;&#65292;&#36825;&#26159;&#30001;Chernozhukov&#31561;&#20154;&#30740;&#31350;&#30340;&#65292;&#20197;&#21450;Robins&#31561;&#20154;&#25152;&#30740;&#31350;&#30340;&#31867;&#21035;&#12290;&#30446;&#21069;DR&#20989;&#25968;&#30340;&#26368;&#20808;&#36827;&#30340;&#20272;&#35745;&#20540;&#26159;DML&#20272;&#35745;&#20540;&#12290;$\hat{\psi}_{1}$&#30340;&#20559;&#24046;&#21462;&#20915;&#20110;&#20004;&#20010;&#36741;&#21161;&#20989;&#25968;$b$&#21644;$p$&#30340;&#20272;&#35745;&#29575;&#30340;&#20056;&#31215;&#12290;&#26368;&#24120;&#35265;&#30340;&#26159;&#65292;&#20998;&#26512;&#24072;&#35777;&#26126;&#20102;
&lt;/p&gt;
&lt;p&gt;
In this article we develop a feasible version of the assumption-lean tests in Liu et al. 20 that can falsify an analyst's justification for the validity of a reported nominal $(1 - \alpha)$ Wald confidence interval (CI) centered at a double machine learning (DML) estimator for any member of the class of doubly robust (DR) functionals studied by Rotnitzky et al. 21. The class of DR functionals is broad and of central importance in economics and biostatistics. It strictly includes both (i) the class of mean-square continuous functionals that can be written as an expectation of an affine functional of a conditional expectation studied by Chernozhukov et al. 22 and the class of functionals studied by Robins et al. 08. The present state-of-the-art estimators for DR functionals $\psi$ are DML estimators $\hat{\psi}_{1}$. The bias of $\hat{\psi}_{1}$ depends on the product of the rates at which two nuisance functions $b$ and $p$ are estimated. Most commonly an analyst justifies the validity o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#36890;&#36807;&#25554;&#20540;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#26469;&#25552;&#21319;&#27169;&#22411;&#40065;&#26834;&#24615;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#23547;&#25214;&#36830;&#25509;&#19981;&#21516;&#31867;&#21035;&#23376;&#20154;&#21475;&#20998;&#24067;&#30340;&#27979;&#22320;&#32447;&#19978;&#30340;&#26368;&#22351;&#24773;&#20917;Wasserstein barycenter&#26469;&#22686;&#21152;&#25968;&#25454;&#65292;&#24182;&#23545;&#27169;&#22411;&#36827;&#34892;&#27491;&#21017;&#21270;&#20197;&#33719;&#24471;&#26356;&#24179;&#28369;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#35777;&#23454;&#65292;&#24182;&#25913;&#36827;&#20102;&#22522;&#32447;&#30340;&#21487;&#35777;&#26126;&#40065;&#26834;&#24615;&#21644;&#32463;&#39564;&#40065;&#26834;&#24615;&#12290;&#35813;&#30740;&#31350;&#20174;Wasserstein&#27979;&#22320;&#32447;&#30340;&#35282;&#24230;&#25506;&#32034;&#20102;&#27169;&#22411;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.02092</link><description>&lt;p&gt;
&#23545;&#40065;&#26834;&#24615;&#23398;&#20064;&#30340;&#25554;&#20540;&#26041;&#27861;&#65306;&#22522;&#20110;Wasserstein&#27979;&#22320;&#32447;&#30340;&#25968;&#25454;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Interpolation for Robust Learning: Data Augmentation on Wasserstein Geodesics. (arXiv:2302.02092v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02092
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#36890;&#36807;&#25554;&#20540;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#26469;&#25552;&#21319;&#27169;&#22411;&#40065;&#26834;&#24615;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#23547;&#25214;&#36830;&#25509;&#19981;&#21516;&#31867;&#21035;&#23376;&#20154;&#21475;&#20998;&#24067;&#30340;&#27979;&#22320;&#32447;&#19978;&#30340;&#26368;&#22351;&#24773;&#20917;Wasserstein barycenter&#26469;&#22686;&#21152;&#25968;&#25454;&#65292;&#24182;&#23545;&#27169;&#22411;&#36827;&#34892;&#27491;&#21017;&#21270;&#20197;&#33719;&#24471;&#26356;&#24179;&#28369;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#35777;&#23454;&#65292;&#24182;&#25913;&#36827;&#20102;&#22522;&#32447;&#30340;&#21487;&#35777;&#26126;&#40065;&#26834;&#24615;&#21644;&#32463;&#39564;&#40065;&#26834;&#24615;&#12290;&#35813;&#30740;&#31350;&#20174;Wasserstein&#27979;&#22320;&#32447;&#30340;&#35282;&#24230;&#25506;&#32034;&#20102;&#27169;&#22411;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#25554;&#20540;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#26469;&#30740;&#31350;&#21644;&#25552;&#21319;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#33021;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#36890;&#36807;&#25214;&#21040;&#36830;&#25509;&#19981;&#21516;&#31867;&#21035;&#23376;&#20154;&#21475;&#20998;&#24067;&#30340;&#27979;&#22320;&#32447;&#19978;&#30340;&#26368;&#22351;&#24773;&#20917;Wasserstein barycenter&#26469;&#22686;&#21152;&#25968;&#25454;&#65307;&#25105;&#20204;&#23545;&#27169;&#22411;&#36827;&#34892;&#27491;&#21017;&#21270;&#65292;&#20351;&#20854;&#22312;&#36830;&#25509;&#23376;&#20154;&#21475;&#20998;&#24067;&#30340;&#36830;&#32493;&#27979;&#22320;&#32447;&#36335;&#24452;&#19978;&#20855;&#26377;&#26356;&#24179;&#28369;&#30340;&#24615;&#33021;&#65307;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#29702;&#35770;&#20445;&#35777;&#40065;&#26834;&#24615;&#25913;&#36827;&#24182;&#30740;&#31350;&#27979;&#22320;&#32447;&#20301;&#32622;&#21644;&#26679;&#26412;&#22823;&#23567;&#30340;&#36129;&#29486;&#12290;&#22312;&#21253;&#25324;CIFAR-100&#21644;ImageNet&#22312;&#20869;&#30340;&#22235;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#35777;&#23454;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#20363;&#22914;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;CIFAR10&#19978;&#25552;&#39640;&#20102;&#22522;&#32447;&#30340;&#21487;&#35777;&#26126;&#40065;&#26834;&#24615;&#36798;&#21040;7.7%&#65292;&#22312;CIFAR-100&#19978;&#25552;&#39640;&#20102;16.8%&#30340;&#32463;&#39564;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#36890;&#36807;Wasserstein&#27979;&#22320;&#32447;&#25581;&#31034;&#20102;&#27169;&#22411;&#40065;&#26834;&#24615;&#30340;&#26032;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose to study and promote the robustness of a model as per its performance through the interpolation of training data distributions. Specifically, (1) we augment the data by finding the worst-case Wasserstein barycenter on the geodesic connecting subpopulation distributions of different categories. (2) We regularize the model for smoother performance on the continuous geodesic path connecting subpopulation distributions. (3) Additionally, we provide a theoretical guarantee of robustness improvement and investigate how the geodesic location and the sample size contribute, respectively. Experimental validations of the proposed strategy on \textit{four} datasets, including CIFAR-100 and ImageNet, establish the efficacy of our method, e.g., our method improves the baselines' certifiable robustness on CIFAR10 up to $7.7\%$, with $16.8\%$ on empirical robustness on CIFAR-100. Our work provides a new perspective of model robustness through the lens of Wasserstein geodesic-based interpol
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19981;&#21464;Lipschitz&#36172;&#24466;&#35774;&#32622;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;\texttt{UniformMesh-N}&#30340;&#31639;&#27861;&#12290;&#20351;&#29992;&#20391;&#38754;&#35266;&#23519;&#30340;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#25913;&#36827;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2212.07524</link><description>&lt;p&gt;
&#19981;&#21464;Lipschitz&#36172;&#24466;&#65306;&#19968;&#20010;&#20391;&#35266;&#21457;&#29616;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Invariant Lipschitz Bandits: A Side Observation Approach. (arXiv:2212.07524v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.07524
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19981;&#21464;Lipschitz&#36172;&#24466;&#35774;&#32622;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;\texttt{UniformMesh-N}&#30340;&#31639;&#27861;&#12290;&#20351;&#29992;&#20391;&#38754;&#35266;&#23519;&#30340;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#25913;&#36827;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#31216;&#20986;&#29616;&#22312;&#35768;&#22810;&#20248;&#21270;&#21644;&#20915;&#31574;&#38382;&#39064;&#20013;&#65292;&#24182;&#21560;&#24341;&#20102;&#20248;&#21270;&#30028;&#30340;&#30456;&#24403;&#20851;&#27880;&#65306;&#36890;&#36807;&#21033;&#29992;&#36825;&#26679;&#30340;&#23545;&#31216;&#24615;&#65292;&#21487;&#20197;&#26174;&#33879;&#25913;&#36827;&#23547;&#25214;&#26368;&#20248;&#35299;&#30340;&#36807;&#31243;&#12290;&#23613;&#31649;&#23545;&#31216;&#24615;&#22312;&#65288;&#31163;&#32447;&#65289;&#20248;&#21270;&#20013;&#21462;&#24471;&#25104;&#21151;&#65292;&#20294;&#22312;&#22312;&#32447;&#20248;&#21270;&#35774;&#32622;&#20013;&#65292;&#29305;&#21035;&#26159;&#22312;&#36172;&#24466;&#25991;&#29486;&#20013;&#65292;&#20854;&#21033;&#29992;&#36824;&#26410;&#24471;&#21040;&#20805;&#20998;&#30340;&#30740;&#31350;&#12290;&#22240;&#27492;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19981;&#21464;Lipschitz&#36172;&#24466;&#35774;&#32622;&#65292;&#36825;&#26159;Lipschitz&#36172;&#24466;&#30340;&#19968;&#20010;&#23376;&#31867;&#65292;&#22312;&#35813;&#23376;&#31867;&#20013;&#65292;&#22870;&#21169;&#20989;&#25968;&#21644;&#33218;&#38598;&#22312;&#19968;&#32452;&#21464;&#25442;&#19979;&#20445;&#25345;&#19981;&#21464;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;\texttt{UniformMesh-N}&#30340;&#31639;&#27861;&#65292;&#23427;&#33258;&#28982;&#22320;&#23558;&#20391;&#38754;&#35266;&#23519;&#20351;&#29992;&#32676;&#36712;&#36947;&#25972;&#21512;&#21040;\texttt{UniformMesh}&#31639;&#27861;&#65288;\cite{Kleinberg2005_UniformMesh}&#65289;&#20013;&#65292;&#35813;&#31639;&#27861;&#22343;&#21248;&#22320;&#20998;&#21106;&#20102;&#33218;&#30340;&#38598;&#21512;&#12290;&#36890;&#36807;&#20391;&#38754;&#35266;&#23519;&#26041;&#27861;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25913;&#36827;&#30340;&#36951;&#25022;&#19978;&#30028;&#65292;&#20854;&#21462;&#20915;&#20110;&#22522;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Symmetry arises in many optimization and decision-making problems, and has attracted considerable attention from the optimization community: By utilizing the existence of such symmetries, the process of searching for optimal solutions can be improved significantly. Despite its success in (offline) optimization, the utilization of symmetries has not been well examined within the online optimization settings, especially in the bandit literature. As such, in this paper we study the invariant Lipschitz bandit setting, a subclass of the Lipschitz bandits where the reward function and the set of arms are preserved under a group of transformations. We introduce an algorithm named \texttt{UniformMesh-N}, which naturally integrates side observations using group orbits into the \texttt{UniformMesh} algorithm (\cite{Kleinberg2005_UniformMesh}), which uniformly discretizes the set of arms. Using the side-observation approach, we prove an improved regret upper bound, which depends on the cardinalit
&lt;/p&gt;</description></item><item><title>TuneUp&#26159;&#19968;&#31181;&#31616;&#21333;&#30340;&#22522;&#20110;&#35838;&#31243;&#30340;&#35757;&#32451;&#31574;&#30053;&#65292;&#29992;&#20110;&#25913;&#36827;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#38590;&#20197;&#39044;&#27979;&#30340;&#23614;&#33410;&#28857;&#19978;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2210.14843</link><description>&lt;p&gt;
TuneUp:&#19968;&#31181;&#31616;&#21333;&#30340;&#25913;&#36827;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
TuneUp: A Simple Improved Training Strategy for Graph Neural Networks. (arXiv:2210.14843v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.14843
&lt;/p&gt;
&lt;p&gt;
TuneUp&#26159;&#19968;&#31181;&#31616;&#21333;&#30340;&#22522;&#20110;&#35838;&#31243;&#30340;&#35757;&#32451;&#31574;&#30053;&#65292;&#29992;&#20110;&#25913;&#36827;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#38590;&#20197;&#39044;&#27979;&#30340;&#23614;&#33410;&#28857;&#19978;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#22312;&#36817;&#26399;&#21462;&#24471;&#20102;&#35768;&#22810;&#36827;&#23637;&#65292;&#20294;&#23427;&#20204;&#30340;&#35757;&#32451;&#31574;&#30053;&#20173;&#28982;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#12290;&#20256;&#32479;&#30340;&#35757;&#32451;&#31574;&#30053;&#23545;&#21407;&#22987;&#22270;&#20013;&#30340;&#25152;&#26377;&#33410;&#28857;&#36827;&#34892;&#24179;&#31561;&#23398;&#20064;&#65292;&#36825;&#21487;&#33021;&#26159;&#27425;&#20248;&#30340;&#65292;&#22240;&#20026;&#26576;&#20123;&#33410;&#28857;&#24448;&#24448;&#27604;&#20854;&#20182;&#33410;&#28857;&#26356;&#38590;&#23398;&#20064;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;TuneUp&#65292;&#19968;&#31181;&#31616;&#21333;&#30340;&#22522;&#20110;&#35838;&#31243;&#30340;&#35757;&#32451;&#31574;&#30053;&#65292;&#29992;&#20110;&#25552;&#39640;GNN&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;TuneUp&#23558;GNN&#20998;&#20026;&#20004;&#20010;&#38454;&#27573;&#36827;&#34892;&#35757;&#32451;&#12290;&#22312;&#31532;&#19968;&#38454;&#27573;&#65292;TuneUp&#24212;&#29992;&#20256;&#32479;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#33719;&#24471;&#19968;&#20010;&#24378;&#22823;&#30340;&#22522;&#30784;GNN&#12290;&#22522;&#30784;GNN&#22312;&#22836;&#33410;&#28857;&#65288;&#20855;&#26377;&#22823;&#24230;&#25968;&#30340;&#33410;&#28857;&#65289;&#19978;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#22312;&#23614;&#33410;&#28857;&#65288;&#20855;&#26377;&#23567;&#24230;&#25968;&#30340;&#33410;&#28857;&#65289;&#19978;&#34920;&#29616;&#36739;&#24046;&#12290;&#22240;&#27492;&#65292;TuneUp&#30340;&#31532;&#20108;&#38454;&#27573;&#20391;&#37325;&#20110;&#36890;&#36807;&#36827;&#19968;&#27493;&#35757;&#32451;&#22522;&#30784;GNN&#20197;&#22312;&#38590;&#20197;&#39044;&#27979;&#30340;&#23614;&#33410;&#28857;&#19978;&#25552;&#39640;&#39044;&#27979;&#33021;&#21147;&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#20998;&#26512;&#20102;TuneUp&#65292;&#24182;&#35777;&#26126;&#23427;&#33021;&#22815;&#25913;&#21892;&#23614;&#33410;&#28857;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;TuneUp&#23454;&#29616;&#31616;&#21333;&#65292;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite recent advances in Graph Neural Networks (GNNs), their training strategies remain largely under-explored. The conventional training strategy learns over all nodes in the original graph(s) equally, which can be sub-optimal as certain nodes are often more difficult to learn than others. Here we present TuneUp, a simple curriculum-based training strategy for improving the predictive performance of GNNs. TuneUp trains a GNN in two stages. In the first stage, TuneUp applies conventional training to obtain a strong base GNN. The base GNN tends to perform well on head nodes (nodes with large degrees) but less so on tail nodes (nodes with small degrees). Therefore, the second stage of TuneUp focuses on improving prediction on the difficult tail nodes by further training the base GNN on synthetically generated tail node data. We theoretically analyze TuneUp and show it provably improves generalization performance on tail nodes. TuneUp is simple to implement and applicable to a broad ran
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#36716;&#31227;&#24773;&#20917;&#19979;&#30340;&#20805;&#20998;&#19981;&#21464;&#23398;&#20064;&#65292;&#35266;&#23519;&#21040;&#20043;&#21069;&#30340;&#24037;&#20316;&#21482;&#23398;&#20064;&#20102;&#37096;&#20998;&#19981;&#21464;&#29305;&#24449;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23398;&#20064;&#20805;&#20998;&#19981;&#21464;&#29305;&#24449;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#25351;&#20986;&#22312;&#20998;&#24067;&#36716;&#31227;&#26102;&#65292;&#20174;&#35757;&#32451;&#38598;&#20013;&#23398;&#20064;&#30340;&#37096;&#20998;&#19981;&#21464;&#29305;&#24449;&#21487;&#33021;&#19981;&#36866;&#29992;&#20110;&#27979;&#35797;&#38598;&#65292;&#38480;&#21046;&#20102;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2210.13533</link><description>&lt;p&gt;
&#20998;&#24067;&#36716;&#31227;&#30340;&#20805;&#20998;&#19981;&#21464;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Sufficient Invariant Learning for Distribution Shift. (arXiv:2210.13533v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.13533
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#36716;&#31227;&#24773;&#20917;&#19979;&#30340;&#20805;&#20998;&#19981;&#21464;&#23398;&#20064;&#65292;&#35266;&#23519;&#21040;&#20043;&#21069;&#30340;&#24037;&#20316;&#21482;&#23398;&#20064;&#20102;&#37096;&#20998;&#19981;&#21464;&#29305;&#24449;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23398;&#20064;&#20805;&#20998;&#19981;&#21464;&#29305;&#24449;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#25351;&#20986;&#22312;&#20998;&#24067;&#36716;&#31227;&#26102;&#65292;&#20174;&#35757;&#32451;&#38598;&#20013;&#23398;&#20064;&#30340;&#37096;&#20998;&#19981;&#21464;&#29305;&#24449;&#21487;&#33021;&#19981;&#36866;&#29992;&#20110;&#27979;&#35797;&#38598;&#65292;&#38480;&#21046;&#20102;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#23637;&#29616;&#20986;&#20102;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#22312;&#35757;&#32451;&#38598;&#21644;&#27979;&#35797;&#38598;&#30340;&#20998;&#24067;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#65292;&#20445;&#35777;&#24615;&#33021;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#25913;&#21892;&#20998;&#24067;&#36716;&#31227;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#19968;&#20123;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#36328;&#32452;&#25110;&#39046;&#22495;&#30340;&#19981;&#21464;&#29305;&#24449;&#26469;&#25552;&#39640;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#20043;&#21069;&#30340;&#24037;&#20316;&#21482;&#37096;&#20998;&#22320;&#23398;&#20064;&#20102;&#19981;&#21464;&#29305;&#24449;&#12290;&#34429;&#28982;&#20808;&#21069;&#30340;&#24037;&#20316;&#20391;&#37325;&#20110;&#26377;&#38480;&#30340;&#19981;&#21464;&#29305;&#24449;&#65292;&#20294;&#25105;&#20204;&#39318;&#27425;&#25552;&#20986;&#20102;&#20805;&#20998;&#19981;&#21464;&#29305;&#24449;&#30340;&#37325;&#35201;&#24615;&#12290;&#30001;&#20110;&#21482;&#26377;&#35757;&#32451;&#38598;&#26159;&#32463;&#39564;&#24615;&#30340;&#65292;&#20174;&#35757;&#32451;&#38598;&#20013;&#23398;&#20064;&#24471;&#21040;&#30340;&#37096;&#20998;&#19981;&#21464;&#29305;&#24449;&#21487;&#33021;&#19981;&#23384;&#22312;&#20110;&#20998;&#24067;&#36716;&#31227;&#26102;&#30340;&#27979;&#35797;&#38598;&#20013;&#12290;&#22240;&#27492;&#65292;&#20998;&#24067;&#36716;&#31227;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#25552;&#39640;&#21487;&#33021;&#21463;&#21040;&#38480;&#21046;&#12290;&#26412;&#25991;&#35748;&#20026;&#20174;&#35757;&#32451;&#38598;&#20013;&#23398;&#20064;&#20805;&#20998;&#30340;&#19981;&#21464;&#29305;&#24449;&#23545;&#20110;&#20998;&#24067;&#36716;&#31227;&#24773;&#20917;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning algorithms have shown remarkable performance in diverse applications. However, it is still challenging to guarantee performance in distribution shifts when distributions of training and test datasets are different. There have been several approaches to improve the performance in distribution shift cases by learning invariant features across groups or domains. However, we observe that the previous works only learn invariant features partially. While the prior works focus on the limited invariant features, we first raise the importance of the sufficient invariant features. Since only training sets are given empirically, the learned partial invariant features from training sets might not be present in the test sets under distribution shift. Therefore, the performance improvement on distribution shifts might be limited. In this paper, we argue that learning sufficient invariant features from the training set is crucial for the distribution shift case. Concretely, we newly 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#31574;&#30053;&#34920;&#31034;&#20026;&#25193;&#25955;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;Diffusion Q-learning&#65288;Diffusion-QL&#65289;&#65292;&#21033;&#29992;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#34920;&#31034;&#31574;&#30053;&#65292;&#24182;&#36890;&#36807;&#26368;&#22823;&#21270;&#21160;&#20316;&#20540;&#26469;&#23547;&#27714;&#25509;&#36817;&#34892;&#20026;&#31574;&#30053;&#30340;&#26368;&#20248;&#21160;&#20316;&#12290;</title><link>http://arxiv.org/abs/2208.06193</link><description>&lt;p&gt;
&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#25193;&#25955;&#31574;&#30053;&#20316;&#20026;&#34920;&#36798;&#24615;&#31574;&#30053;&#31867;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Diffusion Policies as an Expressive Policy Class for Offline Reinforcement Learning. (arXiv:2208.06193v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.06193
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#31574;&#30053;&#34920;&#31034;&#20026;&#25193;&#25955;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;Diffusion Q-learning&#65288;Diffusion-QL&#65289;&#65292;&#21033;&#29992;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#34920;&#31034;&#31574;&#30053;&#65292;&#24182;&#36890;&#36807;&#26368;&#22823;&#21270;&#21160;&#20316;&#20540;&#26469;&#23547;&#27714;&#25509;&#36817;&#34892;&#20026;&#31574;&#30053;&#30340;&#26368;&#20248;&#21160;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26159;&#36890;&#36807;&#21033;&#29992;&#20808;&#21069;&#25910;&#38598;&#30340;&#38745;&#24577;&#25968;&#25454;&#38598;&#26469;&#23398;&#20064;&#26368;&#20248;&#31574;&#30053;&#30340;&#37325;&#35201;&#24378;&#21270;&#23398;&#20064;&#33539;&#24335;&#12290;&#26631;&#20934;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#36890;&#24120;&#34920;&#29616;&#19981;&#20339;&#65292;&#21407;&#22240;&#26159;&#22312;&#20998;&#24067;&#19981;&#21305;&#37197;&#30340;&#34892;&#20026;&#19978;&#23384;&#22312;&#20989;&#25968;&#36924;&#36817;&#35823;&#24046;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#27491;&#21017;&#21270;&#26041;&#27861;&#26469;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#23427;&#20204;&#24448;&#24448;&#21463;&#38480;&#20110;&#20855;&#26377;&#26377;&#38480;&#34920;&#36798;&#33021;&#21147;&#30340;&#31574;&#30053;&#31867;&#65292;&#21487;&#33021;&#23548;&#33268;&#39640;&#24230;&#27425;&#20248;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20197;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#31574;&#30053;&#34920;&#31034;&#30340;&#26041;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#36817;&#26399;&#20986;&#29616;&#30340;&#39640;&#24230;&#34920;&#36798;&#33021;&#21147;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#31867;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#25193;&#25955;Q-learning&#65288;Diffusion-QL&#65289;&#65292;&#21033;&#29992;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#26469;&#34920;&#31034;&#31574;&#30053;&#12290;&#22312;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#23398;&#20064;&#19968;&#20010;&#21160;&#20316;&#20540;&#20989;&#25968;&#65292;&#24182;&#23558;&#26368;&#22823;&#21270;&#21160;&#20316;&#20540;&#30340;&#39033;&#21152;&#20837;&#21040;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#30340;&#35757;&#32451;&#25439;&#22833;&#20013;&#65292;&#20174;&#32780;&#24471;&#21040;&#19968;&#20010;&#23547;&#27714;&#25509;&#36817;&#34892;&#20026;&#31574;&#30053;&#30340;&#26368;&#20248;&#21160;&#20316;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25193;&#25955;&#31574;&#30053;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Offline reinforcement learning (RL), which aims to learn an optimal policy using a previously collected static dataset, is an important paradigm of RL. Standard RL methods often perform poorly in this regime due to the function approximation errors on out-of-distribution actions. While a variety of regularization methods have been proposed to mitigate this issue, they are often constrained by policy classes with limited expressiveness that can lead to highly suboptimal solutions. In this paper, we propose representing the policy as a diffusion model, a recent class of highly-expressive deep generative models. We introduce Diffusion Q-learning (Diffusion-QL) that utilizes a conditional diffusion model to represent the policy. In our approach, we learn an action-value function and we add a term maximizing action-values into the training loss of the conditional diffusion model, which results in a loss that seeks optimal actions that are near the behavior policy. We show the expressiveness
&lt;/p&gt;</description></item><item><title>Diffusion-GAN&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;GAN&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#21069;&#21521;&#25193;&#25955;&#38142;&#29983;&#25104;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#30340;&#23454;&#20363;&#22122;&#22768;&#65292;&#22312;&#35757;&#32451;&#20013;&#35299;&#20915;&#20102;GAN&#31283;&#23450;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2206.02262</link><description>&lt;p&gt;
Diffusion-GAN: &#20351;&#29992;&#25193;&#25955;&#35757;&#32451;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Diffusion-GAN: Training GANs with Diffusion. (arXiv:2206.02262v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.02262
&lt;/p&gt;
&lt;p&gt;
Diffusion-GAN&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;GAN&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#21069;&#21521;&#25193;&#25955;&#38142;&#29983;&#25104;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#30340;&#23454;&#20363;&#22122;&#22768;&#65292;&#22312;&#35757;&#32451;&#20013;&#35299;&#20915;&#20102;GAN&#31283;&#23450;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#30340;&#31283;&#23450;&#35757;&#32451;&#26159;&#19968;&#20010;&#25361;&#25112;&#65292;&#23558;&#23454;&#20363;&#22122;&#22768;&#27880;&#20837;&#37492;&#21035;&#22120;&#36755;&#20837;&#30340;&#26041;&#27861;&#22312;&#23454;&#36341;&#20013;&#24182;&#19981;&#21313;&#20998;&#26377;&#25928;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;Diffusion-GAN&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;GAN&#26694;&#26550;&#65292;&#21033;&#29992;&#21069;&#21521;&#25193;&#25955;&#38142;&#29983;&#25104;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#30340;&#23454;&#20363;&#22122;&#22768;&#12290;Diffusion-GAN&#21253;&#25324;&#19977;&#20010;&#32452;&#20214;&#65292;&#21253;&#25324;&#33258;&#36866;&#24212;&#25193;&#25955;&#36807;&#31243;&#12289;&#26102;&#38388;&#27493;&#20381;&#36182;&#30340;&#21028;&#21035;&#22120;&#21644;&#29983;&#25104;&#22120;&#12290;&#35266;&#23519;&#21040;&#30340;&#21644;&#29983;&#25104;&#30340;&#25968;&#25454;&#37117;&#36890;&#36807;&#30456;&#21516;&#30340;&#33258;&#36866;&#24212;&#25193;&#25955;&#36807;&#31243;&#36827;&#34892;&#25193;&#25955;&#12290;&#22312;&#27599;&#20010;&#25193;&#25955;&#26102;&#38388;&#27493;&#20013;&#65292;&#26377;&#19981;&#21516;&#30340;&#22122;&#22768;&#21040;&#25968;&#25454;&#27604;&#20363;&#65292;&#26102;&#38388;&#27493;&#20381;&#36182;&#30340;&#21028;&#21035;&#22120;&#23398;&#20064;&#21306;&#20998;&#25193;&#25955;&#30340;&#30495;&#23454;&#25968;&#25454;&#21644;&#25193;&#25955;&#30340;&#29983;&#25104;&#25968;&#25454;&#12290;&#29983;&#25104;&#22120;&#36890;&#36807;&#21453;&#21521;&#20256;&#25773;&#36890;&#36807;&#33258;&#36866;&#24212;&#35843;&#25972;&#25193;&#25955;&#38142;&#30340;&#38271;&#24230;&#26469;&#24179;&#34913;&#22122;&#22768;&#21644;&#25968;&#25454;&#27700;&#24179;&#12290;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#21028;&#21035;&#22120;&#30340;&#25910;&#25947;&#24615;&#21644;&#29983;&#25104;&#22120;&#30340;&#25910;&#25947;&#24615;&#65292;&#21516;&#26102;&#22312;&#19968;&#20123;&#26631;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;Diffusion-GAN&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative adversarial networks (GANs) are challenging to train stably, and a promising remedy of injecting instance noise into the discriminator input has not been very effective in practice. In this paper, we propose Diffusion-GAN, a novel GAN framework that leverages a forward diffusion chain to generate Gaussian-mixture distributed instance noise. Diffusion-GAN consists of three components, including an adaptive diffusion process, a diffusion timestep-dependent discriminator, and a generator. Both the observed and generated data are diffused by the same adaptive diffusion process. At each diffusion timestep, there is a different noise-to-data ratio and the timestep-dependent discriminator learns to distinguish the diffused real data from the diffused generated data. The generator learns from the discriminator's feedback by backpropagating through the forward diffusion chain, whose length is adaptively adjusted to balance the noise and data levels. We theoretically show that the dis
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#22806;&#29983;&#38750;&#24179;&#31283;&#21464;&#21270;&#23384;&#22312;&#19979;&#30340;&#33258;&#36866;&#24212;&#23454;&#39564;&#12290;&#25552;&#20986;&#20102;&#26080;&#20559;&#27748;&#26222;&#26862;&#25277;&#26679;(DTS)&#31639;&#27861;&#26469;&#35299;&#20915;&#22810;&#33218;&#32769;&#34382;&#26426;&#31639;&#27861;&#22312;&#38754;&#23545;&#38750;&#24179;&#31283;&#22806;&#29983;&#22240;&#32032;&#26102;&#30340;&#33030;&#24369;&#24615;&#65292;DTS&#31639;&#27861;&#36890;&#36807;&#25511;&#21046;&#32972;&#26223;&#20449;&#24687;&#39044;&#27979;&#19968;&#20010;&#33218;&#30340;&#20154;&#21475;&#23618;&#32423;&#34920;&#29616;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#39564;&#20869;&#21644;&#23454;&#39564;&#21518;&#30340;&#36951;&#25022;&#30028;&#38480;&#65292;&#26174;&#31034;&#20102;&#20854;&#23545;&#22806;&#29983;&#21464;&#24322;&#30340;&#24377;&#24615;&#12290;</title><link>http://arxiv.org/abs/2202.09036</link><description>&lt;p&gt;
&#22312;&#22806;&#29983;&#38750;&#24179;&#31283;&#21464;&#21270;&#23384;&#22312;&#19979;&#30340;&#33258;&#36866;&#24212;&#23454;&#39564;
&lt;/p&gt;
&lt;p&gt;
Adaptive Experimentation in the Presence of Exogenous Nonstationary Variation. (arXiv:2202.09036v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.09036
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#22806;&#29983;&#38750;&#24179;&#31283;&#21464;&#21270;&#23384;&#22312;&#19979;&#30340;&#33258;&#36866;&#24212;&#23454;&#39564;&#12290;&#25552;&#20986;&#20102;&#26080;&#20559;&#27748;&#26222;&#26862;&#25277;&#26679;(DTS)&#31639;&#27861;&#26469;&#35299;&#20915;&#22810;&#33218;&#32769;&#34382;&#26426;&#31639;&#27861;&#22312;&#38754;&#23545;&#38750;&#24179;&#31283;&#22806;&#29983;&#22240;&#32032;&#26102;&#30340;&#33030;&#24369;&#24615;&#65292;DTS&#31639;&#27861;&#36890;&#36807;&#25511;&#21046;&#32972;&#26223;&#20449;&#24687;&#39044;&#27979;&#19968;&#20010;&#33218;&#30340;&#20154;&#21475;&#23618;&#32423;&#34920;&#29616;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#39564;&#20869;&#21644;&#23454;&#39564;&#21518;&#30340;&#36951;&#25022;&#30028;&#38480;&#65292;&#26174;&#31034;&#20102;&#20854;&#23545;&#22806;&#29983;&#21464;&#24322;&#30340;&#24377;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#35774;&#35745;&#29992;&#20110;&#36873;&#25321;&#20154;&#21475;&#37096;&#32626;&#27835;&#30103;&#26041;&#26696;&#30340;&#23454;&#39564;&#12290;&#22810;&#33218;&#32769;&#34382;&#26426;&#31639;&#27861;&#21487;&#20197;&#36890;&#36807;&#26681;&#25454;&#35266;&#23519;&#21040;&#30340;&#21453;&#39304;&#21160;&#24577;&#20998;&#37197;&#27979;&#37327;&#24037;&#20316;&#37327;&#21040;&#34920;&#29616;&#26356;&#22909;&#30340;&#33218;&#19978;&#65292;&#20174;&#32780;&#25552;&#39640;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#21160;&#24577;&#24615;&#21487;&#33021;&#23548;&#33268;&#38754;&#23545;&#24433;&#21709;&#23454;&#39564;&#20013;&#33218;&#34920;&#29616;&#30340;&#38750;&#24179;&#31283;&#22806;&#29983;&#22240;&#32032;&#26102;&#20986;&#29616;&#33030;&#24369;&#34892;&#20026;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26080;&#20559;&#27748;&#26222;&#26862;&#25277;&#26679;(DTS)&#65292;&#36825;&#26159;&#19968;&#31181;&#26356;&#31283;&#20581;&#30340;&#33879;&#21517;&#27748;&#26222;&#26862;&#25277;&#26679;&#31639;&#27861;&#30340;&#21464;&#20307;&#12290;&#38543;&#30528;&#35266;&#23519;&#32467;&#26524;&#30340;&#31215;&#32047;&#65292;DTS&#20250;&#25511;&#21046;&#35266;&#23519;&#21040;&#30340;&#27835;&#30103;&#20915;&#31574;&#30340;&#32972;&#26223;&#65292;&#21516;&#26102;&#39044;&#27979;&#19968;&#20010;&#33218;&#30340;&#20154;&#21475;&#23618;&#32423;&#34920;&#29616;&#12290;&#36825;&#37324;&#30340;&#32972;&#26223;&#21487;&#20197;&#25429;&#25417;&#21040;&#19968;&#20010;&#21487;&#29702;&#35299;&#30340;&#21464;&#21270;&#28304;&#65292;&#27604;&#22914;&#19968;&#20010;&#21463;&#27835;&#30103;&#20010;&#20307;&#30340;&#22269;&#23478;&#65292;&#25110;&#32773;&#20165;&#20165;&#26159;&#35760;&#24405;&#27835;&#30103;&#26102;&#38388;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;DTS&#22312;&#23454;&#39564;&#20869;&#21644;&#23454;&#39564;&#21518;&#36951;&#25022;&#30340;&#30028;&#38480;&#65292;&#35828;&#26126;&#23427;&#23545;&#20110;&#22806;&#29983;&#21464;&#24322;&#30340;&#24377;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate experiments that are designed to select a treatment arm for population deployment. Multi-armed bandit algorithms can enhance efficiency by dynamically allocating measurement effort towards higher performing arms based on observed feedback. However, such dynamics can result in brittle behavior in the face of nonstationary exogenous factors influencing arms' performance during the experiment. To counter this, we propose deconfounded Thompson sampling (DTS), a more robust variant of the prominent Thompson sampling algorithm. As observations accumulate, DTS projects the population-level performance of an arm while controlling for the context within which observed treatment decisions were made. Contexts here might capture a comprehensible source of variation, such as the country of a treated individual, or simply record the time of treatment. We provide bounds on both within-experiment and post-experiment regret of DTS, illustrating its resilience to exogenous variation and t
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36830;&#32493;&#26102;&#38388;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#29992;&#20110;&#20248;&#21270;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#27169;&#22411;&#30340;&#24179;&#31283;&#20998;&#24067;&#12290;&#31639;&#27861;&#36890;&#36807;&#20272;&#35745;&#24179;&#31283;&#20998;&#24067;&#30340;&#26799;&#24230;&#65292;&#24182;&#20351;&#29992;&#27491;&#21521;&#20256;&#25773;&#36827;&#34892;&#36830;&#32493;&#26356;&#26032;&#21442;&#25968;&#65292;&#23454;&#29616;&#25910;&#25947;&#33267;&#26368;&#38497;&#19979;&#38477;&#26041;&#21521;&#12290;&#25105;&#20204;&#20005;&#26684;&#35777;&#26126;&#20102;&#22312;&#32447;&#27491;&#21521;&#20256;&#25773;&#31639;&#27861;&#22312;&#32447;&#24615;&#27169;&#22411;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#22312;&#38750;&#32447;&#24615;&#31034;&#20363;&#19978;&#36827;&#34892;&#20102;&#25968;&#20540;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2202.06637</link><description>&lt;p&gt;
&#36830;&#32493;&#26102;&#38388;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#29992;&#20110;&#20248;&#21270;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#24179;&#31283;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Continuous-time stochastic gradient descent for optimizing over the stationary distribution of stochastic differential equations. (arXiv:2202.06637v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.06637
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36830;&#32493;&#26102;&#38388;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#29992;&#20110;&#20248;&#21270;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#27169;&#22411;&#30340;&#24179;&#31283;&#20998;&#24067;&#12290;&#31639;&#27861;&#36890;&#36807;&#20272;&#35745;&#24179;&#31283;&#20998;&#24067;&#30340;&#26799;&#24230;&#65292;&#24182;&#20351;&#29992;&#27491;&#21521;&#20256;&#25773;&#36827;&#34892;&#36830;&#32493;&#26356;&#26032;&#21442;&#25968;&#65292;&#23454;&#29616;&#25910;&#25947;&#33267;&#26368;&#38497;&#19979;&#38477;&#26041;&#21521;&#12290;&#25105;&#20204;&#20005;&#26684;&#35777;&#26126;&#20102;&#22312;&#32447;&#27491;&#21521;&#20256;&#25773;&#31639;&#27861;&#22312;&#32447;&#24615;&#27169;&#22411;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#22312;&#38750;&#32447;&#24615;&#31034;&#20363;&#19978;&#36827;&#34892;&#20102;&#25968;&#20540;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#36830;&#32493;&#26102;&#38388;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#29992;&#20110;&#20248;&#21270;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#27169;&#22411;&#30340;&#24179;&#31283;&#20998;&#24067;&#12290;&#31639;&#27861;&#20351;&#29992;&#24179;&#31283;&#20998;&#24067;&#30340;&#26799;&#24230;&#20272;&#35745;&#36830;&#32493;&#26356;&#26032;SDE&#27169;&#22411;&#30340;&#21442;&#25968;&#12290;&#26799;&#24230;&#20272;&#35745;&#21516;&#26102;&#20351;&#29992;SDE&#29366;&#24577;&#23548;&#25968;&#30340;&#27491;&#21521;&#20256;&#25773;&#36827;&#34892;&#26356;&#26032;&#65292;&#28176;&#36817;&#22320;&#25910;&#25947;&#21040;&#26368;&#38497;&#19979;&#38477;&#26041;&#21521;&#12290;&#25105;&#20204;&#20005;&#26684;&#35777;&#26126;&#20102;&#22312;&#32447;&#27491;&#21521;&#20256;&#25773;&#31639;&#27861;&#22312;&#32447;&#24615;SDE&#27169;&#22411;&#65288;&#22914;&#22810;&#32500;Ornstein-Uhlenbeck&#36807;&#31243;&#65289;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#21576;&#29616;&#20102;&#38750;&#32447;&#24615;&#31034;&#20363;&#30340;&#25968;&#20540;&#32467;&#26524;&#12290;&#35777;&#26126;&#38656;&#35201;&#23545;&#21442;&#25968;&#28436;&#21270;&#22312;&#26368;&#38497;&#19979;&#38477;&#26041;&#21521;&#38468;&#36817;&#30340;&#27874;&#21160;&#36827;&#34892;&#20998;&#26512;&#12290;&#30001;&#20110;&#31639;&#27861;&#30340;&#22312;&#32447;&#24615;&#36136;&#65292;&#33719;&#24471;&#27874;&#21160;&#30340;&#30028;&#38480;&#24456;&#20855;&#25361;&#25112;&#24615;&#65288;&#20363;&#22914;&#65292;&#38543;&#30528;&#21442;&#25968;&#30340;&#21464;&#21270;&#65292;&#31283;&#23450;&#20998;&#24067;&#23558;&#25345;&#32493;&#21464;&#21270;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a new continuous-time stochastic gradient descent method for optimizing over the stationary distribution of stochastic differential equation (SDE) models. The algorithm continuously updates the SDE model's parameters using an estimate for the gradient of the stationary distribution. The gradient estimate is simultaneously updated using forward propagation of the SDE state derivatives, asymptotically converging to the direction of steepest descent. We rigorously prove convergence of the online forward propagation algorithm for linear SDE models (i.e., the multi-dimensional Ornstein-Uhlenbeck process) and present its numerical results for nonlinear examples. The proof requires analysis of the fluctuations of the parameter evolution around the direction of steepest descent. Bounds on the fluctuations are challenging to obtain due to the online nature of the algorithm (e.g., the stationary distribution will continuously change as the parameters change). We prove bounds for the s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#38543;&#26426;&#22352;&#26631;&#21464;&#25442;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23618;&#32423;&#24352;&#37327;&#31215;&#23637;&#24320;&#26469;&#36924;&#36817;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#23545;&#25237;&#24433;&#31995;&#25968;&#36827;&#34892;&#26816;&#27979;&#12290;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#32988;&#36807;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2110.01729</link><description>&lt;p&gt;
&#38543;&#26426;&#22352;&#26631;&#21464;&#25442;&#21450;&#20854;&#22312;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Stochastic coordinate transformations with applications to robust machine learning. (arXiv:2110.01729v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.01729
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#38543;&#26426;&#22352;&#26631;&#21464;&#25442;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23618;&#32423;&#24352;&#37327;&#31215;&#23637;&#24320;&#26469;&#36924;&#36817;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#23545;&#25237;&#24433;&#31995;&#25968;&#36827;&#34892;&#26816;&#27979;&#12290;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#32988;&#36807;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#32452;&#26032;&#30340;&#29305;&#24449;&#65292;&#21033;&#29992;Karhunen-Loeve&#23637;&#24320;&#27861;&#26469;&#35782;&#21035;&#36755;&#20837;&#25968;&#25454;&#30340;&#28508;&#22312;&#38543;&#26426;&#34892;&#20026;&#12290;&#36825;&#20123;&#26032;&#29305;&#24449;&#26159;&#36890;&#36807;&#22522;&#20110;&#26368;&#36817;&#30340;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#29702;&#35770;&#36827;&#34892;&#30340;&#22352;&#26631;&#21464;&#25442;&#26500;&#24314;&#30340;&#65292;&#29992;&#20110;&#24322;&#24120;&#26816;&#27979;&#12290;&#30456;&#20851;&#30340;&#20449;&#21495;&#20998;&#35299;&#26159;&#29992;&#24050;&#30693;&#20248;&#21270;&#23646;&#24615;&#30340;&#23618;&#32423;&#24352;&#37327;&#31215;&#23637;&#24320;&#26469;&#36924;&#36817;&#20855;&#26377;&#26377;&#38480;&#21151;&#33021;&#31354;&#38388;&#30340;&#38543;&#26426;&#36807;&#31243;&#65288;&#38543;&#26426;&#22330;&#65289;&#12290;&#21407;&#21017;&#19978;&#65292;&#36825;&#20123;&#20302;&#32500;&#31354;&#38388;&#21487;&#20197;&#25429;&#25417;&#32473;&#23450;&#21517;&#20041;&#31867;&#21035;&#30340;'&#24213;&#23618;&#20449;&#21495;'&#30340;&#22823;&#37096;&#20998;&#38543;&#26426;&#21464;&#21270;&#65292;&#24182;&#19988;&#21487;&#20197;&#23558;&#26469;&#33258;&#20854;&#23427;&#31867;&#21035;&#30340;&#20449;&#21495;&#25298;&#32477;&#20026;&#38543;&#26426;&#24322;&#24120;&#12290;&#36890;&#36807;&#21517;&#20041;&#31867;&#21035;&#30340;&#23618;&#32423;&#26377;&#38480;&#32500;&#23637;&#24320;&#65292;&#26500;&#24314;&#20102;&#19968;&#31995;&#21015;&#29992;&#20110;&#26816;&#27979;&#24322;&#24120;&#20449;&#21495;&#32452;&#20214;&#30340;&#27491;&#20132;&#23884;&#22871;&#23376;&#31354;&#38388;&#12290;&#28982;&#21518;&#20351;&#29992;&#36825;&#20123;&#23376;&#31354;&#38388;&#20013;&#30340;&#25237;&#24433;&#31995;&#25968;&#26469;&#35757;&#32451;&#29992;&#20110;&#24322;&#24120;&#26816;&#27979;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#32467;&#26524;&#34920;&#26126;&#20854;&#32988;&#36807;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we introduce a set of novel features for identifying underlying stochastic behavior of input data using the Karhunen-Loeve expansion. These novel features are constructed by applying a coordinate transformation based on the recent Functional Data Analysis theory for anomaly detection. The associated signal decomposition is an exact hierarchical tensor product expansion with known optimality properties for approximating stochastic processes (random fields) with finite dimensional function spaces. In principle these low dimensional spaces can capture most of the stochastic behavior of `underlying signals' in a given nominal class, and can reject signals in alternative classes as stochastic anomalies. Using a hierarchical finite dimensional expansion of the nominal class, a series of orthogonal nested subspaces is constructed for detecting anomalous signal components. Projection coefficients of input data in these subspaces are then used to train a Machine Learning (ML) clas
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20803;&#26657;&#20934;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#21487;&#24494;&#30340;&#26399;&#26395;&#26657;&#20934;&#35823;&#24046;&#20195;&#29702;&#25351;&#26631;&#21644;&#20803;&#23398;&#20064;&#26694;&#26550;&#65292;&#23454;&#29616;&#20102;&#23545;&#27169;&#22411;&#26657;&#20934;&#36136;&#37327;&#30340;&#30452;&#25509;&#20248;&#21270;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#36798;&#21040;&#19982;&#29616;&#26377;&#26657;&#20934;&#26041;&#27861;&#30456;&#31454;&#20105;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;&#35813;&#26694;&#26550;&#20026;&#36827;&#19968;&#27493;&#35299;&#20915;&#26657;&#20934;&#38382;&#39064;&#25552;&#20379;&#20102;&#26032;&#30340;&#24605;&#36335;&#21644;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2106.09613</link><description>&lt;p&gt;
&#20803;&#26657;&#20934;&#65306;&#20351;&#29992;&#21487;&#24494;&#20043;&#26399;&#26395;&#26657;&#20934;&#35823;&#24046;&#23398;&#20064;&#27169;&#22411;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Meta-Calibration: Learning of Model Calibration Using Differentiable Expected Calibration Error. (arXiv:2106.09613v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.09613
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20803;&#26657;&#20934;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#21487;&#24494;&#30340;&#26399;&#26395;&#26657;&#20934;&#35823;&#24046;&#20195;&#29702;&#25351;&#26631;&#21644;&#20803;&#23398;&#20064;&#26694;&#26550;&#65292;&#23454;&#29616;&#20102;&#23545;&#27169;&#22411;&#26657;&#20934;&#36136;&#37327;&#30340;&#30452;&#25509;&#20248;&#21270;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#36798;&#21040;&#19982;&#29616;&#26377;&#26657;&#20934;&#26041;&#27861;&#30456;&#31454;&#20105;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;&#35813;&#26694;&#26550;&#20026;&#36827;&#19968;&#27493;&#35299;&#20915;&#26657;&#20934;&#38382;&#39064;&#25552;&#20379;&#20102;&#26032;&#30340;&#24605;&#36335;&#21644;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#30340;&#26657;&#20934;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#38382;&#39064;&#65292;&#22312;&#31070;&#32463;&#32593;&#32476;&#36234;&#26469;&#36234;&#22810;&#22320;&#24212;&#29992;&#20110;&#29616;&#23454;&#19990;&#30028;&#24212;&#29992;&#30340;&#24773;&#20917;&#19979;&#65292;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#24403;&#20351;&#29992;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#26102;&#65292;&#27169;&#22411;&#30340;&#32622;&#20449;&#24230;&#19982;&#27491;&#30830;&#39044;&#27979;&#30340;&#27010;&#29575;&#20043;&#38388;&#23384;&#22312;&#26126;&#26174;&#24046;&#24322;&#65292;&#36825;&#19968;&#38382;&#39064;&#23588;&#20026;&#26126;&#26174;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#31574;&#30053;&#26469;&#25913;&#21892;&#26657;&#20934;&#65292;&#20294;&#20934;&#30830;&#30340;&#26657;&#20934;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#21253;&#21547;&#20004;&#20010;&#36129;&#29486;&#65306;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#21487;&#24494;&#20195;&#29702;&#25351;&#26631;&#65292;&#29992;&#20110;&#30452;&#25509;&#20248;&#21270;&#26657;&#20934;&#36136;&#37327;&#30340;&#26399;&#26395;&#26657;&#20934;&#35823;&#24046; (DECE)&#65292;&#20197;&#21450;&#19968;&#20010;&#20803;&#23398;&#20064;&#26694;&#26550;&#65292;&#20351;&#29992;DECE&#26681;&#25454;&#27169;&#22411;&#36229;&#21442;&#25968;&#20248;&#21270;&#39564;&#35777;&#38598;&#26657;&#20934;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26657;&#20934;&#26041;&#38754;&#20855;&#26377;&#31454;&#20105;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#20026;&#22788;&#29702;&#26657;&#20934;&#38382;&#39064;&#24320;&#36767;&#20102;&#26032;&#30340;&#36884;&#24452;&#21644;&#24037;&#20855;&#65292;&#25105;&#20204;&#30456;&#20449;&#36825;&#23558;&#28608;&#21457;&#26356;&#22810;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Calibration of neural networks is a topical problem that is becoming more and more important as neural networks increasingly underpin real-world applications. The problem is especially noticeable when using modern neural networks, for which there is a significant difference between the confidence of the model and the probability of correct prediction. Various strategies have been proposed to improve calibration, yet accurate calibration remains challenging. We propose a novel framework with two contributions: introducing a new differentiable surrogate for expected calibration error (DECE) that allows calibration quality to be directly optimised, and a meta-learning framework that uses DECE to optimise for validation set calibration with respect to model hyper-parameters. The results show that we achieve competitive performance with existing calibration approaches. Our framework opens up a new avenue and toolset for tackling calibration, which we believe will inspire further work on thi
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#22312;&#20989;&#25968;&#31354;&#38388;&#19978;&#35299;&#20915;&#20998;&#24067;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;Hilbert-Schmidt&#31639;&#23376;&#23558;&#20989;&#25968;&#22495;&#20043;&#38388;&#30340;&#38543;&#26426;&#26144;&#23556;&#36827;&#34892;&#34920;&#31034;&#12290;&#36825;&#31181;&#26041;&#27861;&#23545;&#20110;&#22788;&#29702;&#20989;&#25968;&#25968;&#25454;&#30340;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#38750;&#24120;&#26377;&#29992;&#12290;</title><link>http://arxiv.org/abs/2102.03895</link><description>&lt;p&gt;
&#21151;&#33021;&#24615;&#26368;&#20248;&#36755;&#36816;&#65306;&#21151;&#33021;&#25968;&#25454;&#30340;&#26144;&#23556;&#20272;&#35745;&#21644;&#39046;&#22495;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
Functional optimal transport: map estimation and domain adaptation for functional data. (arXiv:2102.03895v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.03895
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#22312;&#20989;&#25968;&#31354;&#38388;&#19978;&#35299;&#20915;&#20998;&#24067;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;Hilbert-Schmidt&#31639;&#23376;&#23558;&#20989;&#25968;&#22495;&#20043;&#38388;&#30340;&#38543;&#26426;&#26144;&#23556;&#36827;&#34892;&#34920;&#31034;&#12290;&#36825;&#31181;&#26041;&#27861;&#23545;&#20110;&#22788;&#29702;&#20989;&#25968;&#25968;&#25454;&#30340;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#38750;&#24120;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22312;&#20989;&#25968;&#31354;&#38388;&#19978;&#23545;&#20998;&#24067;&#36827;&#34892;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#30340;&#34920;&#36798;&#65292;&#20854;&#20013;&#20989;&#25968;&#22495;&#20043;&#38388;&#30340;&#38543;&#26426;&#26144;&#23556;&#21487;&#20197;&#37096;&#20998;&#22320;&#34920;&#31034;&#20026;&#19968;&#20010;&#65288;&#26080;&#38480;&#32500;&#65289;Hilbert-Schmidt&#31639;&#23376;&#65292;&#23558;&#19968;&#20010;&#20989;&#25968;&#30340;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26144;&#23556;&#21040;&#21478;&#19968;&#20010;&#20989;&#25968;&#19978;&#12290;&#23545;&#20110;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#25968;&#25454;&#21487;&#20197;&#33258;&#28982;&#22320;&#35270;&#20026;&#20174;&#20989;&#25968;&#31354;&#38388;&#20013;&#37319;&#26679;&#24471;&#21040;&#30340;&#65292;&#20363;&#22914;&#26354;&#32447;&#21644;&#26354;&#38754;&#65292;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#12290;&#21151;&#33021;&#25968;&#25454;&#20998;&#26512;&#30340;&#26368;&#20248;&#36755;&#36816;&#25552;&#20379;&#20102;&#23545;&#36825;&#20123;&#39046;&#22495;&#36827;&#34892;&#22788;&#29702;&#30340;&#26377;&#29992;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a formulation of optimal transport problem for distributions on function spaces, where the stochastic map between functional domains can be partially represented in terms of an (infinite-dimensional) Hilbert-Schmidt operator mapping a Hilbert space of functions to another. For numerous machine learning tasks, data can be naturally viewed as samples drawn from spaces of functions, such as curves and surfaces, in high dimensions. Optimal transport for functional data analysis provides a useful framework of treatment for such domains. { Since probability measures in infinite dimensional spaces generally lack absolute continuity (that is, with respect to non-degenerate Gaussian measures), the Monge map in the standard optimal transport theory for finite dimensional spaces may not exist. Our approach to the optimal transport problem in infinite dimensions is by a suitable regularization technique -- we restrict the class of transport maps to be a Hilbert-Schmidt space of operat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25554;&#20540;&#26680;&#23725;&#22238;&#24402;&#65288;KRR&#65289;&#20272;&#35745;&#22120;&#65292;&#21487;&#24191;&#27867;&#36866;&#29992;&#20110;&#38750;&#21442;&#25968;&#22238;&#24402;&#20013;&#30340;&#22810;&#32500;&#25903;&#25345;&#21644;&#20219;&#24847;&#28151;&#21512;&#20559;&#23548;&#25968;&#65292;&#24182;&#19988;&#20855;&#26377;&#36739;&#24378;&#30340;&#35823;&#24046;&#30028;&#12290;</title><link>http://arxiv.org/abs/2006.01350</link><description>&lt;p&gt;
&#20351;&#29992;&#25554;&#20540;&#26680;&#23725;&#22238;&#24402;&#20272;&#35745;&#23548;&#25968;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Estimation of Derivatives Using Plug-in Kernel Ridge Regression Estimators. (arXiv:2006.01350v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.01350
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25554;&#20540;&#26680;&#23725;&#22238;&#24402;&#65288;KRR&#65289;&#20272;&#35745;&#22120;&#65292;&#21487;&#24191;&#27867;&#36866;&#29992;&#20110;&#38750;&#21442;&#25968;&#22238;&#24402;&#20013;&#30340;&#22810;&#32500;&#25903;&#25345;&#21644;&#20219;&#24847;&#28151;&#21512;&#20559;&#23548;&#25968;&#65292;&#24182;&#19988;&#20855;&#26377;&#36739;&#24378;&#30340;&#35823;&#24046;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#23545;&#22238;&#24402;&#20989;&#25968;&#30340;&#23548;&#25968;&#36827;&#34892;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#36825;&#22312;&#26410;&#30693;&#20989;&#25968;&#30340;&#38750;&#21442;&#25968;&#21270;&#21151;&#33021;&#20013;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;&#26631;&#20934;&#30340;&#20998;&#26512;&#21487;&#33021;&#38024;&#23545;&#29305;&#23450;&#30340;&#23548;&#25968;&#38454;&#25968;&#36827;&#34892;&#35843;&#25972;&#65292;&#32780;&#21442;&#25968;&#35843;&#20248;&#29305;&#21035;&#26159;&#23545;&#20110;&#39640;&#38454;&#23548;&#25968;&#26469;&#35828;&#20173;&#28982;&#26159;&#19968;&#20010;&#22256;&#38590;&#30340;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#25554;&#20540;&#26680;&#23725;&#22238;&#24402;&#65288;KRR&#65289;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#20855;&#26377;&#38543;&#26426;&#35774;&#35745;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#65292;&#24191;&#27867;&#36866;&#29992;&#20110;&#22810;&#32500;&#25903;&#25345;&#21644;&#20219;&#24847;&#28151;&#21512;&#20559;&#23548;&#25968;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#38750;&#28176;&#36817;&#20998;&#26512;&#65292;&#20197;&#32479;&#19968;&#22320;&#30740;&#31350;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#30340;&#34892;&#20026;&#65292;&#21253;&#25324;&#22238;&#24402;&#20989;&#25968;&#21450;&#20854;&#23548;&#25968;&#65292;&#22312;&#24378;L&#8734;&#33539;&#25968;&#19979;&#23548;&#33268;&#20102;&#19968;&#20010;&#19968;&#33324;&#31867;&#30340;&#26680;&#20989;&#25968;&#30340;&#20004;&#20010;&#35823;&#24046;&#30028;&#12290;&#22312;&#19968;&#20010;&#20855;&#20307;&#30340;&#20363;&#23376;&#20013;&#65292;&#35813;&#20272;&#35745;&#22120;&#19987;&#38376;&#38024;&#23545;&#20855;&#26377;&#22810;&#39033;&#24335;&#34928;&#20943;&#29305;&#24449;&#20540;&#30340;&#26680;&#20989;&#25968;&#65292;&#23454;&#29616;&#20102;&#26368;&#23567;&#21270;&#30340;&#26368;&#20248;&#36895;&#29575;&#65292;&#21482;&#26377;&#19968;&#20010;&#23545;&#25968;&#22240;&#23376;&#21487;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
We study the problem of estimating the derivatives of a regression function, which has a wide range of applications as a key nonparametric functional of unknown functions. Standard analysis may be tailored to specific derivative orders, and parameter tuning remains a daunting challenge particularly for high-order derivatives. In this article, we propose a simple plug-in kernel ridge regression (KRR) estimator in nonparametric regression with random design that is broadly applicable for multi-dimensional support and arbitrary mixed-partial derivatives. We provide a non-asymptotic analysis to study the behavior of the proposed estimator in a unified manner that encompasses the regression function and its derivatives, leading to two error bounds for a general class of kernels under the strong $L_\infty$ norm. In a concrete example specialized to kernels with polynomially decaying eigenvalues, the proposed estimator recovers the minimax optimal rate up to a logarithmic factor for estimatin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26102;&#38388;&#24207;&#21015;&#26465;&#20214;&#22270;&#29983;&#25104;&#26041;&#27861;(TSGG-GAN)&#65292;&#36890;&#36807;&#32467;&#21512;&#20016;&#23500;&#30340;&#33410;&#28857;&#32423;&#19978;&#19979;&#25991;&#32467;&#26500;&#26469;&#25512;&#26029;&#26102;&#38388;&#24207;&#21015;&#20043;&#38388;&#30340;&#20851;&#31995;&#22270;&#12290;</title><link>http://arxiv.org/abs/2003.01436</link><description>&lt;p&gt;
&#20351;&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#23398;&#20064;&#29983;&#25104;&#26102;&#38388;&#31995;&#21015;&#26465;&#20214;&#22270;
&lt;/p&gt;
&lt;p&gt;
Learning to Generate Time Series Conditioned Graphs with Generative Adversarial Nets. (arXiv:2003.01436v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2003.01436
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26102;&#38388;&#24207;&#21015;&#26465;&#20214;&#22270;&#29983;&#25104;&#26041;&#27861;(TSGG-GAN)&#65292;&#36890;&#36807;&#32467;&#21512;&#20016;&#23500;&#30340;&#33410;&#28857;&#32423;&#19978;&#19979;&#25991;&#32467;&#26500;&#26469;&#25512;&#26029;&#26102;&#38388;&#24207;&#21015;&#20043;&#38388;&#30340;&#20851;&#31995;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#24050;&#34987;&#29992;&#20110;&#24314;&#27169;&#21644;&#29983;&#25104;&#31526;&#21512;&#19981;&#21516;&#20998;&#24067;&#30340;&#22270;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#36890;&#24120;&#26159;&#22522;&#20110;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#12289;&#26080;&#26465;&#20214;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#25110;&#32773;&#20165;&#22522;&#20110;&#22270;&#32423;&#19978;&#19979;&#25991;&#26465;&#20214;&#29983;&#25104;&#65292;&#36825;&#19982;&#20016;&#23500;&#30340;&#35821;&#20041;&#33410;&#28857;&#32423;&#19978;&#19979;&#25991;&#26080;&#20851;&#12290;&#19981;&#21516;&#22320;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23545;&#19968;&#20010;&#21517;&#20026;&#26102;&#38388;&#24207;&#21015;&#26465;&#20214;&#22270;&#29983;&#25104;&#30340;&#26032;&#38382;&#39064;&#24863;&#20852;&#36259;&#65306;&#32473;&#23450;&#19968;&#20010;&#36755;&#20837;&#30340;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#25512;&#26029;&#19968;&#20010;&#30446;&#26631;&#20851;&#31995;&#22270;&#65292;&#35813;&#22270;&#24314;&#27169;&#20102;&#26102;&#38388;&#24207;&#21015;&#20043;&#38388;&#30340;&#28508;&#22312;&#30456;&#20114;&#20851;&#31995;&#65292;&#20854;&#20013;&#27599;&#20010;&#33410;&#28857;&#23545;&#24212;&#19968;&#20010;&#26102;&#38388;&#24207;&#21015;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#21487;&#20197;&#30740;&#31350;&#20197;&#22522;&#22240;&#34920;&#36798;&#25968;&#25454;&#20316;&#20026;&#26102;&#38388;&#24207;&#21015;&#26465;&#20214;&#30340;&#26576;&#31181;&#30142;&#30149;&#30340;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#20013;&#22522;&#22240;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#31995;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26102;&#38388;&#24207;&#21015;&#26465;&#20214;&#22270;&#29983;&#25104;-&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;TSGG-GAN&#65289;&#26469;&#22788;&#29702;&#20016;&#23500;&#30340;&#33410;&#28857;&#32423;&#19978;&#19979;&#25991;&#32467;&#26500;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning based approaches have been utilized to model and generate graphs subjected to different distributions recently. However, they are typically unsupervised learning based and unconditioned generative models or simply conditioned on the graph-level contexts, which are not associated with rich semantic node-level contexts. Differently, in this paper, we are interested in a novel problem named Time Series Conditioned Graph Generation: given an input multivariate time series, we aim to infer a target relation graph modeling the underlying interrelationships between time series with each node corresponding to each time series. For example, we can study the interrelationships between genes in a gene regulatory network of a certain disease conditioned on their gene expression data recorded as time series. To achieve this, we propose a novel Time Series conditioned Graph Generation-Generative Adversarial Networks (TSGG-GAN) to handle challenges of rich node-level context structures 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#29702;&#35770;&#19978;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#20197;&#21450;&#22914;&#20309;&#28145;&#24230;&#23398;&#20064;&#33021;&#22815;&#22312;&#23481;&#37327;&#22823;&#12289;&#22797;&#26434;&#24615;&#39640;&#12289;&#21487;&#33021;&#23384;&#22312;&#31639;&#27861;&#19981;&#31283;&#23450;&#24615;&#12289;&#38750;&#40065;&#26834;&#24615;&#21644;&#23574;&#38160;&#26497;&#23567;&#20540;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#33391;&#22909;&#30340;&#27867;&#21270;&#65292;&#25552;&#20986;&#20102;&#19968;&#20123;&#26032;&#30340;&#24320;&#25918;&#38382;&#39064;&#65292;&#24182;&#35752;&#35770;&#20102;&#30740;&#31350;&#32467;&#26524;&#30340;&#23616;&#38480;&#24615;&#12290;</title><link>http://arxiv.org/abs/1710.05468</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#27867;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Generalization in Deep Learning. (arXiv:1710.05468v8 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1710.05468
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#29702;&#35770;&#19978;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#20197;&#21450;&#22914;&#20309;&#28145;&#24230;&#23398;&#20064;&#33021;&#22815;&#22312;&#23481;&#37327;&#22823;&#12289;&#22797;&#26434;&#24615;&#39640;&#12289;&#21487;&#33021;&#23384;&#22312;&#31639;&#27861;&#19981;&#31283;&#23450;&#24615;&#12289;&#38750;&#40065;&#26834;&#24615;&#21644;&#23574;&#38160;&#26497;&#23567;&#20540;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#33391;&#22909;&#30340;&#27867;&#21270;&#65292;&#25552;&#20986;&#20102;&#19968;&#20123;&#26032;&#30340;&#24320;&#25918;&#38382;&#39064;&#65292;&#24182;&#35752;&#35770;&#20102;&#30740;&#31350;&#32467;&#26524;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#29702;&#35770;&#19978;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#20197;&#21450;&#22914;&#20309;&#28145;&#24230;&#23398;&#20064;&#33021;&#22815;&#22312;&#23481;&#37327;&#22823;&#12289;&#22797;&#26434;&#24615;&#39640;&#12289;&#21487;&#33021;&#23384;&#22312;&#31639;&#27861;&#19981;&#31283;&#23450;&#24615;&#12289;&#38750;&#40065;&#26834;&#24615;&#21644;&#23574;&#38160;&#26497;&#23567;&#20540;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#33391;&#22909;&#30340;&#27867;&#21270;&#65292;&#22238;&#24212;&#20102;&#25991;&#29486;&#20013;&#30340;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#25552;&#20379;&#28145;&#24230;&#23398;&#20064;&#38750;&#34394;&#31354;&#27867;&#21270;&#20445;&#35777;&#30340;&#26041;&#27861;&#12290;&#22522;&#20110;&#29702;&#35770;&#35266;&#23519;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20123;&#26032;&#30340;&#24320;&#25918;&#38382;&#39064;&#65292;&#24182;&#35752;&#35770;&#20102;&#25105;&#20204;&#30740;&#31350;&#32467;&#26524;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper provides theoretical insights into why and how deep learning can generalize well, despite its large capacity, complexity, possible algorithmic instability, nonrobustness, and sharp minima, responding to an open question in the literature. We also discuss approaches to provide non-vacuous generalization guarantees for deep learning. Based on theoretical observations, we propose new open problems and discuss the limitations of our results.
&lt;/p&gt;</description></item></channel></rss>