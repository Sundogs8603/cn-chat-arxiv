<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>ES-Single&#26159;&#19968;&#31181;&#29992;&#20110;&#20272;&#35745;&#23637;&#24320;&#30340;&#35745;&#31639;&#22270;&#20013;&#26799;&#24230;&#30340;&#36827;&#21270;&#31574;&#30053;&#31639;&#27861;&#65292;&#20854;&#31616;&#21333;&#23454;&#29616;&#12289;&#26041;&#24046;&#36739;&#20302;&#65292;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2304.11153</link><description>&lt;p&gt;
ES-Single&#65306;&#22312;&#23637;&#24320;&#30340;&#35745;&#31639;&#22270;&#20013;&#23454;&#29616;&#20302;&#26041;&#24046;&#26799;&#24230;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Low-Variance Gradient Estimation in Unrolled Computation Graphs with ES-Single. (arXiv:2304.11153v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11153
&lt;/p&gt;
&lt;p&gt;
ES-Single&#26159;&#19968;&#31181;&#29992;&#20110;&#20272;&#35745;&#23637;&#24320;&#30340;&#35745;&#31639;&#22270;&#20013;&#26799;&#24230;&#30340;&#36827;&#21270;&#31574;&#30053;&#31639;&#27861;&#65292;&#20854;&#31616;&#21333;&#23454;&#29616;&#12289;&#26041;&#24046;&#36739;&#20302;&#65292;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36827;&#21270;&#31574;&#30053;&#30340;&#31639;&#27861;ES-Single&#65292;&#29992;&#20110;&#20272;&#35745;&#23637;&#24320;&#30340;&#35745;&#31639;&#22270;&#20013;&#30340;&#26799;&#24230;&#12290;&#19982;&#26368;&#36817;&#25552;&#20986;&#30340;&#25345;&#20037;&#36827;&#21270;&#31574;&#30053;&#65288;PES&#65289;&#31867;&#20284;&#65292;ES-Single&#26159;&#26080;&#20559;&#30340;&#65292;&#24182;&#36890;&#36807;&#24179;&#28369;&#20803;&#25439;&#22833;&#20989;&#25968;&#26469;&#20811;&#26381;&#30001;&#20110;&#36882;&#24402;&#20989;&#25968;&#24212;&#29992;&#32780;&#20135;&#29983;&#30340;&#28151;&#27788;&#12290;ES-Single&#23545;&#20110;&#27599;&#20010;&#31890;&#23376;&#37319;&#26679;&#19968;&#20010;&#21333;&#19968;&#25200;&#21160;&#65292;&#24182;&#22312;&#20869;&#37096;&#38382;&#39064;&#30340;&#36807;&#31243;&#20013;&#20445;&#25345;&#19981;&#21464;&#65288;&#20363;&#22914;&#65292;&#23545;&#20110;&#27599;&#20010;&#37096;&#20998;&#26410;&#23637;&#24320;&#65292;&#19981;&#20250;&#37325;&#26032;&#37319;&#26679;&#25200;&#21160;&#65289;&#12290;&#19982;PES&#30456;&#27604;&#65292;ES-Single&#23454;&#29616;&#26356;&#31616;&#21333;&#65292;&#26041;&#24046;&#26356;&#20302;&#65306;ES-Single&#30340;&#26041;&#24046;&#19982;&#25130;&#26029;&#23637;&#24320;&#27425;&#25968;&#30340;&#25968;&#37327;&#26080;&#20851;&#65292;&#28040;&#38500;&#20102;&#20351;&#29992;&#30701;&#25130;&#26029;&#26469;&#35299;&#20915;&#38271;&#20869;&#37096;&#38382;&#39064;&#25152;&#24102;&#26469;&#30340;&#20851;&#38190;&#38556;&#30861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;ES-Single&#23545;&#20110;&#20108;&#27425;&#20869;&#37096;&#38382;&#39064;&#26159;&#26080;&#20559;&#30340;&#65292;&#24182;&#19988;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#23427;&#30340;&#26041;&#24046;&#21487;&#20197;&#26174;&#33879;&#22320;&#20302;&#20110;PES&#12290;ES-Single&#22312;&#22810;&#39033;&#20219;&#21153;&#20013;&#25345;&#32493;&#20248;&#20110;PES&#65292;&#21253;&#25324;&#21512;&#25104;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an evolution strategies-based algorithm for estimating gradients in unrolled computation graphs, called ES-Single. Similarly to the recently-proposed Persistent Evolution Strategies (PES), ES-Single is unbiased, and overcomes chaos arising from recursive function applications by smoothing the meta-loss landscape. ES-Single samples a single perturbation per particle, that is kept fixed over the course of an inner problem (e.g., perturbations are not re-sampled for each partial unroll). Compared to PES, ES-Single is simpler to implement and has lower variance: the variance of ES-Single is constant with respect to the number of truncated unrolls, removing a key barrier in applying ES to long inner problems using short truncations. We show that ES-Single is unbiased for quadratic inner problems, and demonstrate empirically that its variance can be substantially lower than that of PES. ES-Single consistently outperforms PES on a variety of tasks, including a synthetic benchmark t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#38543;&#26426;&#22270;&#27169;&#22411;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#23558;&#25910;&#25947;&#32467;&#35770;&#20174;&#21482;&#36866;&#29992;&#20110;&#24230;&#35268;&#33539;&#21270;&#24179;&#22343;&#32858;&#21512;&#20989;&#25968;&#25193;&#23637;&#21040;&#25152;&#26377;&#20256;&#32479;&#32858;&#21512;&#20989;&#25968;&#65292;&#24182;&#32771;&#34385;&#20102;&#32858;&#21512;&#20989;&#25968;&#37319;&#29992;&#36880;&#20010;&#22352;&#26631;&#26368;&#22823;&#20540;&#26102;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2304.11140</link><description>&lt;p&gt;
&#22522;&#20110;&#28040;&#24687;&#20256;&#36882;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#22823;&#35268;&#27169;&#38543;&#26426;&#22270;&#19978;&#30340;&#36890;&#29992;&#32858;&#21512;&#25910;&#25947;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Convergence of Message Passing Graph Neural Networks with Generic Aggregation On Large Random Graphs. (arXiv:2304.11140v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11140
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#38543;&#26426;&#22270;&#27169;&#22411;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#23558;&#25910;&#25947;&#32467;&#35770;&#20174;&#21482;&#36866;&#29992;&#20110;&#24230;&#35268;&#33539;&#21270;&#24179;&#22343;&#32858;&#21512;&#20989;&#25968;&#25193;&#23637;&#21040;&#25152;&#26377;&#20256;&#32479;&#32858;&#21512;&#20989;&#25968;&#65292;&#24182;&#32771;&#34385;&#20102;&#32858;&#21512;&#20989;&#25968;&#37319;&#29992;&#36880;&#20010;&#22352;&#26631;&#26368;&#22823;&#20540;&#26102;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#38543;&#26426;&#22270;&#27169;&#22411;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#24403;&#33410;&#28857;&#25968;&#37327;&#36235;&#36817;&#20110;&#26080;&#38480;&#26102;&#65292;&#35813;&#32593;&#32476;&#27169;&#22411;&#33021;&#25910;&#25947;&#20110;&#20854;&#36830;&#32493;&#27169;&#22411;&#12290;&#36804;&#20170;&#20026;&#27490;&#65292;&#35813;&#25910;&#25947;&#24615;&#32467;&#26524;&#21482;&#36866;&#29992;&#20110;&#32858;&#21512;&#20989;&#25968;&#37319;&#29992;&#24230;&#35268;&#33539;&#21270;&#24179;&#22343;&#20540;&#24418;&#24335;&#30340;&#32593;&#32476;&#32467;&#26500;&#12290;&#25105;&#20204;&#23558;&#27492;&#32467;&#26524;&#25193;&#23637;&#21040;&#21253;&#21547;&#25152;&#26377;&#20256;&#32479;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#22823;&#31867;&#32858;&#21512;&#20989;&#25968;&#19978;&#65292;&#20363;&#22914;&#22522;&#20110;&#27880;&#24847;&#21147;&#21644;&#26368;&#22823;&#21367;&#31215;&#30340;&#32593;&#32476;&#12290;&#22312;&#19968;&#23450;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#39640;&#27010;&#29575;&#30340;&#38750;&#28176;&#36827;&#19978;&#38480;&#26469;&#37327;&#21270;&#36825;&#31181;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#22522;&#20110;McDiarmid&#19981;&#31561;&#24335;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#29305;&#21035;&#22788;&#29702;&#20102;&#32858;&#21512;&#20989;&#25968;&#37319;&#29992;&#36880;&#20010;&#22352;&#26631;&#26368;&#22823;&#20540;&#30340;&#24773;&#20917;&#65292;&#22240;&#20026;&#23427;&#38656;&#35201;&#38750;&#24120;&#19981;&#21516;&#30340;&#35777;&#26126;&#25216;&#24039;&#65292;&#24182;&#20135;&#29983;&#20102;&#23450;&#24615;&#19981;&#21516;&#30340;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the convergence of message passing graph neural networks on random graph models to their continuous counterpart as the number of nodes tends to infinity. Until now, this convergence was only known for architectures with aggregation functions in the form of degree-normalized means. We extend such results to a very large class of aggregation functions, that encompasses all classically used message passing graph neural networks, such as attention-based mesage passing or max convolutional message passing on top of (degree-normalized) convolutional message passing. Under mild assumptions, we give non asymptotic bounds with high probability to quantify this convergence. Our main result is based on the McDiarmid inequality. Interestingly, we treat the case where the aggregation is a coordinate-wise maximum separately, at it necessitates a very different proof technique and yields a qualitatively different convergence rate.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#19968;&#31181;&#25554;&#25300;&#24335;&#20998;&#21106; Gibbs &#37319;&#26679;&#31639;&#27861;&#65292;&#23558;&#21518;&#39564;&#37319;&#26679;&#20219;&#21153;&#20998;&#20026;&#20004;&#20010;&#36739;&#31616;&#21333;&#30340;&#23376;&#38382;&#39064;&#65292;&#20854;&#20013;&#31532;&#20108;&#20010;&#23376;&#38382;&#39064;&#21487;&#20197;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#36731;&#26494;&#22320;&#35299;&#20915;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#22312;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#23884;&#20837;&#28145;&#24230;&#29983;&#25104;&#20808;&#39564;&#20197;&#21450;&#33258;&#21160;&#36866;&#24212;&#21518;&#39564;&#20998;&#24067;&#30340;&#22797;&#26434;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.11134</link><description>&lt;p&gt;
&#25554;&#25300;&#24335;&#20998;&#21106; Gibbs &#37319;&#26679;: &#22312;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#23884;&#20837;&#28145;&#24230;&#29983;&#25104;&#20808;&#39564;
&lt;/p&gt;
&lt;p&gt;
Plug-and-Play split Gibbs sampler: embedding deep generative priors in Bayesian inference. (arXiv:2304.11134v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11134
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#19968;&#31181;&#25554;&#25300;&#24335;&#20998;&#21106; Gibbs &#37319;&#26679;&#31639;&#27861;&#65292;&#23558;&#21518;&#39564;&#37319;&#26679;&#20219;&#21153;&#20998;&#20026;&#20004;&#20010;&#36739;&#31616;&#21333;&#30340;&#23376;&#38382;&#39064;&#65292;&#20854;&#20013;&#31532;&#20108;&#20010;&#23376;&#38382;&#39064;&#21487;&#20197;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#36731;&#26494;&#22320;&#35299;&#20915;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#22312;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#23884;&#20837;&#28145;&#24230;&#29983;&#25104;&#20808;&#39564;&#20197;&#21450;&#33258;&#21160;&#36866;&#24212;&#21518;&#39564;&#20998;&#24067;&#30340;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#21464;&#37327;&#20998;&#31163;&#30340;&#38543;&#26426;&#25554;&#25300;&#24335;(Plug-and-Play)&#37319;&#26679;&#31639;&#27861;&#65292;&#20197;&#26377;&#25928;&#22320;&#20174;&#21518;&#39564;&#20998;&#24067;&#20013;&#37319;&#26679;&#12290;&#35813;&#31639;&#27861;&#22522;&#20110;&#20998;&#21106;Gibbs&#37319;&#26679;(split Gibbs sampling, SGS)&#65292;&#28789;&#24863;&#26469;&#33258;&#20110;&#20132;&#26367;&#26041;&#21521;&#20056;&#23376;&#27861;(alternating direction method of multipliers, ADMM)&#12290;&#23427;&#23558;&#21518;&#39564;&#37319;&#26679;&#30340;&#25361;&#25112;&#20219;&#21153;&#20998;&#20026;&#20004;&#20010;&#36739;&#31616;&#21333;&#30340;&#37319;&#26679;&#38382;&#39064;&#12290;&#31532;&#19968;&#20010;&#38382;&#39064;&#20381;&#36182;&#20110;&#20284;&#28982;&#20989;&#25968;&#65292;&#32780;&#31532;&#20108;&#20010;&#38382;&#39064;&#34987;&#35299;&#37322;&#20026;&#19968;&#20010;&#36125;&#21494;&#26031;&#38477;&#22122;&#38382;&#39064;&#65292;&#21487;&#20197;&#36890;&#36807;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#36731;&#26494;&#22320;&#23436;&#25104;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#20026;&#20102;&#35828;&#26126;&#30446;&#30340;&#65292;&#26412;&#25991;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20351;&#29992;&#20102;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#20102;&#23454;&#29616;&#12290;&#19982;&#20854;&#30830;&#23450;&#24615;&#30340;&#25554;&#25300;&#24335;(Plug-and-Play)&#31867;&#20284;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20855;&#26377;&#19981;&#38656;&#35201;&#26174;&#24335;&#36873;&#25321;&#20808;&#39564;&#20998;&#24067;&#30340;&#24040;&#22823;&#20248;&#21183;&#65292;&#32780;&#26159;&#23558;&#20854;&#32534;&#30721;&#21040;&#39044;&#35757;&#32451;&#30340;&#29983;&#25104;&#27169;&#22411;&#20013;&#12290;&#28982;&#32780;&#65292;&#19982;&#38656;&#35201;&#35880;&#24910;&#35843;&#25972;&#35843;&#25972;&#21442;&#25968;&#30340;&#20248;&#21270;&#26041;&#27861;(PnP-ADMM)&#19981;&#21516;&#65292;&#25152;&#25552;&#20986;&#30340;&#25554;&#25300;&#24335;&#20998;&#21106; Gibbs &#37319;&#26679;&#31639;&#27861;&#21487;&#20197;&#22312;&#37319;&#26679;&#36807;&#31243;&#20013;&#33258;&#21160;&#36866;&#24212;&#21518;&#39564;&#20998;&#24067;&#30340;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a stochastic plug-and-play (PnP) sampling algorithm that leverages variable splitting to efficiently sample from a posterior distribution. The algorithm based on split Gibbs sampling (SGS) draws inspiration from the alternating direction method of multipliers (ADMM). It divides the challenging task of posterior sampling into two simpler sampling problems. The first problem depends on the likelihood function, while the second is interpreted as a Bayesian denoising problem that can be readily carried out by a deep generative model. Specifically, for an illustrative purpose, the proposed method is implemented in this paper using state-of-the-art diffusion-based generative models. Akin to its deterministic PnP-based counterparts, the proposed method exhibits the great advantage of not requiring an explicit choice of the prior distribution, which is rather encoded into a pre-trained generative model. However, unlike optimization methods (e.g., PnP-ADMM) which generally
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#36890;&#29992;&#31639;&#27861;&#65292;&#21033;&#29992;&#23610;&#24230;&#25935;&#24863;&#30340;Vapnik&#32500;&#24230;&#26469;&#23398;&#20064;$[0,1]$&#20540;&#20989;&#25968;&#31867;&#65292;&#24182;&#33719;&#24471;&#20102;&#20851;&#20110;&#26399;&#26395;&#32477;&#23545;&#35823;&#24046;&#30340;&#19968;&#33324;&#19978;&#38480;&#12290;&#25991;&#20013;&#35777;&#26126;&#35813;&#19978;&#38480;&#19981;&#33021;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#36827;&#19968;&#27493;&#25913;&#21892;&#19968;&#20010;&#24120;&#25968;&#22240;&#23376;&#12290;&#36825;&#31687;&#35770;&#25991;&#23545;&#26080;&#20559;&#23398;&#20064;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#25552;&#39640;&#20855;&#26377;&#37325;&#35201;&#30340;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2304.11059</link><description>&lt;p&gt;
&#39044;&#27979;&#12289;&#23398;&#20064;&#12289;&#19968;&#33268;&#25910;&#25947;&#21644;&#23610;&#24230;&#25935;&#24863;&#32500;&#24230;
&lt;/p&gt;
&lt;p&gt;
Prediction, Learning, Uniform Convergence, and Scale-sensitive Dimensions. (arXiv:2304.11059v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11059
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#36890;&#29992;&#31639;&#27861;&#65292;&#21033;&#29992;&#23610;&#24230;&#25935;&#24863;&#30340;Vapnik&#32500;&#24230;&#26469;&#23398;&#20064;$[0,1]$&#20540;&#20989;&#25968;&#31867;&#65292;&#24182;&#33719;&#24471;&#20102;&#20851;&#20110;&#26399;&#26395;&#32477;&#23545;&#35823;&#24046;&#30340;&#19968;&#33324;&#19978;&#38480;&#12290;&#25991;&#20013;&#35777;&#26126;&#35813;&#19978;&#38480;&#19981;&#33021;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#36827;&#19968;&#27493;&#25913;&#21892;&#19968;&#20010;&#24120;&#25968;&#22240;&#23376;&#12290;&#36825;&#31687;&#35770;&#25991;&#23545;&#26080;&#20559;&#23398;&#20064;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#25552;&#39640;&#20855;&#26377;&#37325;&#35201;&#30340;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36890;&#29992;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#39044;&#27979;&#27169;&#22411;&#30340;&#25512;&#24191;&#20013;&#23398;&#20064;$[0,1]$&#20540;&#20989;&#25968;&#31867;&#65292;&#24182;&#35777;&#26126;&#20102;&#19968;&#33324;&#24615;&#30340;&#19978;&#38480;&#65292;&#35813;&#19978;&#38480;&#21453;&#26144;&#20102;&#30001;Alon&#12289;Ben-David&#12289;Cesa-Bianchi&#21644;Haussler&#25552;&#20986;&#30340;&#23610;&#24230;&#25935;&#24863;&#30340;Vapnik&#32500;&#24230;&#30340;&#25512;&#24191;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#19979;&#38480;&#65292;&#36825;&#34920;&#26126;&#25105;&#20204;&#30340;&#19978;&#38480;&#19981;&#33021;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#36827;&#19968;&#27493;&#25913;&#21892;&#19968;&#20010;&#24120;&#25968;&#22240;&#23376;&#12290;&#25105;&#20204;&#24212;&#29992;&#27492;&#32467;&#26524;&#21644;Haussler&#20197;&#21450;Benedek&#21644;Itai&#30340;&#25216;&#26415;&#65292;&#20197;&#21033;&#29992;&#36825;&#31181;&#23610;&#24230;&#25935;&#24863;&#30340;&#32500;&#24230;&#27010;&#24565;&#33719;&#24471;&#26032;&#30340;&#22635;&#20805;&#25968;&#19978;&#38480;&#12290;&#25105;&#20204;&#21033;&#29992;&#19981;&#21516;&#30340;&#25216;&#26415;&#65292;&#21033;&#29992;Kearns&#21644;Schapire&#30340;fat-shattering&#20989;&#25968;&#24471;&#21040;&#20102;&#26032;&#30340;&#22635;&#20805;&#25968;&#19978;&#38480;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#24212;&#29992;&#36825;&#20004;&#31181;&#22635;&#20805;&#19978;&#38480;&#26469;&#33719;&#24471;&#23545;&#26080;&#20559;&#23398;&#20064;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#25913;&#36827;&#19968;&#33324;&#24615;&#19978;&#38480;&#12290;&#23545;&#20110;&#27599;&#20010;$\epsilon &gt; 0$&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#31867;&#30340;&#36275;&#22815;&#26465;&#20214;&#21644;&#24517;&#35201;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new general-purpose algorithm for learning classes of $[0,1]$-valued functions in a generalization of the prediction model, and prove a general upper bound on the expected absolute error of this algorithm in terms of a scale-sensitive generalization of the Vapnik dimension proposed by Alon, Ben-David, Cesa-Bianchi and Haussler. We give lower bounds implying that our upper bounds cannot be improved by more than a constant factor in general. We apply this result, together with techniques due to Haussler and to Benedek and Itai, to obtain new upper bounds on packing numbers in terms of this scale-sensitive notion of dimension. Using a different technique, we obtain new bounds on packing numbers in terms of Kearns and Schapire's fat-shattering function. We show how to apply both packing bounds to obtain improved general bounds on the sample complexity of agnostic learning. For each $\epsilon &gt; 0$, we establish weaker sufficient and stronger necessary conditions for a class of 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;SAL&#21644;SCoreBO&#20004;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#25552;&#39640;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#36229;&#21442;&#25968;&#36873;&#25321;&#21644;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2304.11005</link><description>&lt;p&gt;
&#36890;&#36807;&#36125;&#21494;&#26031;&#20027;&#21160;&#23398;&#20064;&#23454;&#29616;&#33258;&#26657;&#27491;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Self-Correcting Bayesian Optimization through Bayesian Active Learning. (arXiv:2304.11005v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11005
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;SAL&#21644;SCoreBO&#20004;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#25552;&#39640;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#36229;&#21442;&#25968;&#36873;&#25321;&#21644;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#24050;&#25104;&#20026;&#36125;&#21494;&#26031;&#20248;&#21270;&#21644;&#20027;&#21160;&#23398;&#20064;&#20013;&#30340;&#39318;&#36873;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#39640;&#26031;&#36807;&#31243;&#30340;&#23436;&#20840;&#21457;&#25381;&#38656;&#35201;&#24039;&#22937;&#36873;&#25321;&#36229;&#21442;&#25968;&#65292;&#32780;&#22312;&#25991;&#29486;&#20013;&#24456;&#23569;&#26377;&#20851;&#20110;&#25214;&#21040;&#27491;&#30830;&#36229;&#21442;&#25968;&#30340;&#21162;&#21147;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#36873;&#25321;&#22909;&#30340;&#36229;&#21442;&#25968;&#23545;&#20110;&#39640;&#26031;&#36807;&#31243;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#26126;&#30830;&#20248;&#20808;&#32771;&#34385;&#27492;&#30446;&#26631;&#30340;&#25910;&#36141;&#20989;&#25968;&#12290;&#32479;&#35745;&#36317;&#31163;&#20027;&#21160;&#23398;&#20064;&#65288;SAL&#65289;&#32771;&#34385;&#21518;&#39564;&#26679;&#26412;&#30340;&#24179;&#22343;&#19981;&#19968;&#33268;&#24615;&#65292;&#30001;&#32479;&#35745;&#36317;&#31163;&#27979;&#37327;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#22312;&#35768;&#22810;&#27979;&#35797;&#20989;&#25968;&#19978;&#65292;&#23427;&#32988;&#36807;&#20102;&#36125;&#21494;&#26031;&#20027;&#21160;&#23398;&#20064;&#30340;&#26368;&#26032;&#32467;&#26524;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#33258;&#26657;&#27491;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;SCoreBO&#65289;&#65292;&#23427;&#23558;SAL&#25193;&#23637;&#21040;&#21516;&#26102;&#25191;&#34892;&#36125;&#21494;&#26031;&#20248;&#21270;&#21644;&#20027;&#21160;&#36229;&#21442;&#25968;&#23398;&#20064;&#12290;&#30456;&#27604;&#20256;&#32479;BO&#65292;SCoreBO&#20197;&#25913;&#36827;&#30340;&#36895;&#24230;&#23398;&#20064;&#27169;&#22411;&#36229;&#21442;&#25968;&#65292;&#21516;&#26102;&#22312;&#26368;&#26032;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#25628;&#32034;&#20013;&#21462;&#24471;&#26356;&#22909;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes are cemented as the model of choice in Bayesian optimization and active learning. Yet, they are severely dependent on cleverly chosen hyperparameters to reach their full potential, and little effort is devoted to finding the right hyperparameters in the literature. We demonstrate the impact of selecting good hyperparameters for GPs and present two acquisition functions that explicitly prioritize this goal. Statistical distance-based Active Learning (SAL) considers the average disagreement among samples from the posterior, as measured by a statistical distance. It is shown to outperform the state-of-the-art in Bayesian active learning on a number of test functions. We then introduce Self-Correcting Bayesian Optimization (SCoreBO), which extends SAL to perform Bayesian optimization and active hyperparameter learning simultaneously. SCoreBO learns the model hyperparameters at improved rates compared to vanilla BO, while outperforming the latest Bayesian optimization met
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#24179;&#34913;&#25216;&#26415;&#25193;&#23637;&#21040;&#21518;&#39564;&#23494;&#24230;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#21644;&#23545;&#27604;&#31070;&#32463;&#27604;&#29575;&#20272;&#35745;&#30340;&#24179;&#34913;&#29256;&#26412;&#65292;&#21487;&#26377;&#25928;&#32531;&#35299;&#20445;&#23432;&#25512;&#26029;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.10978</link><description>&lt;p&gt;
&#24179;&#34913;&#27169;&#25311;&#25512;&#26029;&#65292;&#24471;&#21040;&#20445;&#23432;&#30340;&#21518;&#39564;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Balancing Simulation-based Inference for Conservative Posteriors. (arXiv:2304.10978v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10978
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#24179;&#34913;&#25216;&#26415;&#25193;&#23637;&#21040;&#21518;&#39564;&#23494;&#24230;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#21644;&#23545;&#27604;&#31070;&#32463;&#27604;&#29575;&#20272;&#35745;&#30340;&#24179;&#34913;&#29256;&#26412;&#65292;&#21487;&#26377;&#25928;&#32531;&#35299;&#20445;&#23432;&#25512;&#26029;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20445;&#23432;&#25512;&#26029;&#26159;&#27169;&#25311;&#25512;&#26029;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;&#24050;&#32463;&#35777;&#26126;&#24120;&#29992;&#31639;&#27861;&#21487;&#33021;&#20250;&#20135;&#29983;&#36807;&#20110;&#33258;&#20449;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#24179;&#34913;&#21487;&#20197;&#26377;&#25928;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#20854;&#24212;&#29992;&#20173;&#38480;&#20110;&#31070;&#32463;&#27604;&#29575;&#20272;&#35745;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;&#24179;&#34913;&#25193;&#23637;&#21040;&#25552;&#20379;&#21518;&#39564;&#23494;&#24230;&#30340;&#20219;&#20309;&#31639;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#21644;&#23545;&#27604;&#31070;&#32463;&#27604;&#29575;&#20272;&#35745;&#30340;&#24179;&#34913;&#29256;&#26412;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#24179;&#34913;&#29256;&#26412;&#20542;&#21521;&#20110;&#22312;&#24191;&#27867;&#30340;&#22522;&#20934;&#27979;&#35797;&#19978;&#20135;&#29983;&#20445;&#23432;&#30340;&#21518;&#39564;&#20998;&#24067;&#36924;&#36817;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#24179;&#34913;&#26465;&#20214;&#30340;&#21478;&#19968;&#31181;&#35299;&#37322;&#65292;&#21363;$ \chi^2$ &#38548;&#31163;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conservative inference is a major concern in simulation-based inference. It has been shown that commonly used algorithms can produce overconfident posterior approximations. Balancing has empirically proven to be an effective way to mitigate this issue. However, its application remains limited to neural ratio estimation. In this work, we extend balancing to any algorithm that provides a posterior density. In particular, we introduce a balanced version of both neural posterior estimation and contrastive neural ratio estimation. We show empirically that the balanced versions tend to produce conservative posterior approximations on a wide variety of benchmarks. In addition, we provide an alternative interpretation of the balancing condition in terms of the $\chi^2$ divergence.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35780;&#20272;&#20102;&#20351;&#29992;&#25968;&#23383;&#20998;&#35299;&#25216;&#26415;&#36827;&#34892;&#24494;&#35843;&#21518;&#30340;&#21464;&#24418;&#37329;&#21018;&#35821;&#35328;&#27169;&#22411;&#22312;&#25191;&#34892;&#31639;&#26415;&#36816;&#31639;&#26102;&#30340;&#34920;&#29616;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#20116;&#20301;&#25968;&#23383;&#21152;&#27861;&#20219;&#21153;&#20013;&#30340;&#20934;&#30830;&#24230;&#25552;&#39640;&#20102;63%&#12290;</title><link>http://arxiv.org/abs/2304.10977</link><description>&lt;p&gt;
&#20351;&#29992;&#25968;&#23383;&#20998;&#35299;&#35780;&#20272;&#21464;&#24418;&#37329;&#21018;&#35821;&#35328;&#27169;&#22411;&#22312;&#31639;&#26415;&#36816;&#31639;&#19978;&#30340;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;
Evaluating Transformer Language Models on Arithmetic Operations Using Number Decomposition. (arXiv:2304.10977v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10977
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35780;&#20272;&#20102;&#20351;&#29992;&#25968;&#23383;&#20998;&#35299;&#25216;&#26415;&#36827;&#34892;&#24494;&#35843;&#21518;&#30340;&#21464;&#24418;&#37329;&#21018;&#35821;&#35328;&#27169;&#22411;&#22312;&#25191;&#34892;&#31639;&#26415;&#36816;&#31639;&#26102;&#30340;&#34920;&#29616;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#20116;&#20301;&#25968;&#23383;&#21152;&#27861;&#20219;&#21153;&#20013;&#30340;&#20934;&#30830;&#24230;&#25552;&#39640;&#20102;63%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20687;GPT-3&#36825;&#26679;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#38646;&#21644;&#23569;&#37327;&#26679;&#26412;&#30340;NLP&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#20102;&#38750;&#20961;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#23454;&#39564;&#31361;&#26174;&#20986;GPT-3&#22312;&#38656;&#35201;&#19968;&#23450;&#25512;&#29702;&#33021;&#21147;&#30340;&#20219;&#21153;&#65292;&#22914;&#31639;&#26415;&#36816;&#31639;&#20013;&#30340;&#22256;&#38590;&#12290;&#26412;&#25991;&#36890;&#36807;&#19968;&#20010;&#27969;&#31243;&#26469;&#35780;&#20272;&#21464;&#24418;&#37329;&#21018;&#35821;&#35328;&#27169;&#22411;&#22312;&#25191;&#34892;&#31639;&#26415;&#36816;&#31639;&#26102;&#30340;&#33021;&#21147;&#65292;&#22312;&#36825;&#20010;&#27969;&#31243;&#20013;&#65292;&#25968;&#23383;&#20250;&#22312;&#35745;&#31639;&#20043;&#21069;&#34987;&#20998;&#35299;&#20026;&#20010;&#20301;&#12289;&#21313;&#20301;&#31561;&#12290;&#25105;&#20204;&#31216;&#20351;&#29992;&#36825;&#20010;&#27969;&#31243;&#24494;&#35843;&#21518;&#30340;&#27169;&#22411;&#20026;Calculon&#65292;&#24182;&#22312;GPT-3&#30340;&#21516;&#19968;&#27979;&#35797;&#25968;&#25454;&#38598;&#19978;&#27979;&#35797;&#20102;&#23427;&#20204;&#22312;&#25191;&#34892;&#21152;&#12289;&#20943;&#21644;&#20056;&#27861;&#20219;&#21153;&#26102;&#30340;&#34920;&#29616;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#22312;&#20116;&#20301;&#25968;&#23383;&#21152;&#27861;&#20219;&#21153;&#20013;&#65292;&#20934;&#30830;&#24230;&#25552;&#39640;&#20102;63%&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#24341;&#20837;&#20998;&#35299;&#27969;&#31243;&#30340;&#37325;&#35201;&#24615;&#65292;&#22240;&#20026;&#23558;&#30456;&#21516;&#30340;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#65292;&#20294;&#27809;&#26377;&#36827;&#34892;&#25968;&#23383;&#20998;&#35299;&#65292;&#20854;&#22312;&#20116;&#20301;&#25968;&#23383;&#21152;&#27861;&#20219;&#21153;&#20013;&#30340;&#20934;&#30830;&#24230;&#20026;0%&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, Large Language Models such as GPT-3 showed remarkable capabilities in performing NLP tasks in the zero and few shot settings. On the other hand, the experiments highlighted the difficulty of GPT-3 in carrying out tasks that require a certain degree of reasoning, such as arithmetic operations. In this paper we evaluate the ability of Transformer Language Models to perform arithmetic operations following a pipeline that, before performing computations, decomposes numbers in units, tens, and so on. We denote the models fine-tuned with this pipeline with the name Calculon and we test them in the task of performing additions, subtractions and multiplications on the same test sets of GPT-3. Results show an increase of accuracy of 63% in the five-digit addition task. Moreover, we demonstrate the importance of the decomposition pipeline introduced, since fine-tuning the same Language Model without decomposing numbers results in 0% accuracy in the five-digit addition task.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#19977;&#27425;&#27491;&#21017;&#21270;&#31574;&#30053;&#29275;&#39039;&#31639;&#27861;&#65292;&#20854;&#20351;&#29992;&#20284;&#28982;&#27604;&#26041;&#27861;&#24418;&#25104;&#20215;&#20540;&#20989;&#25968;&#26799;&#24230;&#21644;&#40657;&#22622;&#30697;&#38453;&#30340;&#20272;&#35745;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#31639;&#27861;&#25910;&#25947;&#21040;&#20215;&#20540;&#20989;&#25968;&#30340;&#20108;&#38454;&#31283;&#23450;&#28857;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#31867;&#22411;&#20026;&#38797;&#28857;&#30340;&#38519;&#38449;&#12290;</title><link>http://arxiv.org/abs/2304.10951</link><description>&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#19977;&#27425;&#27491;&#21017;&#21270;&#31574;&#30053;&#29275;&#39039;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Cubic-regularized Policy Newton Algorithm for Reinforcement Learning. (arXiv:2304.10951v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10951
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#19977;&#27425;&#27491;&#21017;&#21270;&#31574;&#30053;&#29275;&#39039;&#31639;&#27861;&#65292;&#20854;&#20351;&#29992;&#20284;&#28982;&#27604;&#26041;&#27861;&#24418;&#25104;&#20215;&#20540;&#20989;&#25968;&#26799;&#24230;&#21644;&#40657;&#22622;&#30697;&#38453;&#30340;&#20272;&#35745;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#31639;&#27861;&#25910;&#25947;&#21040;&#20215;&#20540;&#20989;&#25968;&#30340;&#20108;&#38454;&#31283;&#23450;&#28857;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#31867;&#22411;&#20026;&#38797;&#28857;&#30340;&#38519;&#38449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#27809;&#26377;&#27169;&#22411;&#20449;&#24687;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#29615;&#22659;&#19979;&#30340;&#25511;&#21046;&#38382;&#39064;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#31574;&#30053;&#29275;&#39039;&#31639;&#27861;&#65292;&#20854;&#20013;&#21253;&#21547;&#20102;&#19977;&#27425;&#27491;&#21017;&#21270;&#12290;&#36825;&#20004;&#31181;&#31639;&#27861;&#37319;&#29992;&#20284;&#28982;&#27604;&#26041;&#27861;&#20351;&#29992;&#26679;&#26412;&#36712;&#36857;&#24418;&#25104;&#20215;&#20540;&#20989;&#25968;&#26799;&#24230;&#21644;&#40657;&#22622;&#30697;&#38453;&#30340;&#20272;&#35745;&#12290;&#31532;&#19968;&#31181;&#31639;&#27861;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#38656;&#35201;&#19977;&#27425;&#27491;&#21017;&#21270;&#38382;&#39064;&#30340;&#31934;&#30830;&#35299;&#65292;&#32780;&#31532;&#20108;&#31181;&#31639;&#27861;&#21017;&#20351;&#29992;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#26799;&#24230;&#19979;&#38477;&#36817;&#20284;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#25910;&#25947;&#21040;&#20215;&#20540;&#20989;&#25968;&#30340;&#20108;&#38454;&#31283;&#23450;&#28857;&#65288;SOSP&#65289;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#31867;&#22411;&#20026;&#38797;&#28857;&#30340;&#38519;&#38449;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\epsilon$
&lt;/p&gt;
&lt;p&gt;
We consider the problem of control in the setting of reinforcement learning (RL), where model information is not available. Policy gradient algorithms are a popular solution approach for this problem and are usually shown to converge to a stationary point of the value function. In this paper, we propose two policy Newton algorithms that incorporate cubic regularization. Both algorithms employ the likelihood ratio method to form estimates of the gradient and Hessian of the value function using sample trajectories. The first algorithm requires an exact solution of the cubic regularized problem in each iteration, while the second algorithm employs an efficient gradient descent-based approximation to the cubic regularized problem. We establish convergence of our proposed algorithms to a second-order stationary point (SOSP) of the value function, which results in the avoidance of traps in the form of saddle points. In particular, the sample complexity of our algorithms to find an $\epsilon$
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23457;&#35745;&#26694;&#26550;&#65292;&#33021;&#22815;&#20197;&#20840;&#38754;&#30340;&#26041;&#24335;&#35780;&#20272;&#21512;&#25104;&#25968;&#25454;&#21644;AI&#27169;&#22411;&#30340;&#20855;&#20307;&#25928;&#26524;&#65292;&#21253;&#25324;&#20559;&#35265;&#21644;&#27495;&#35270;&#39044;&#38450;&#12289;&#23545;&#30495;&#23454;&#25968;&#25454;&#30340;&#24544;&#23454;&#31243;&#24230;&#12289;&#25928;&#29992;&#12289;&#40065;&#26834;&#24615;&#21644;&#38544;&#31169;&#20445;&#25252;&#12290;&#22312;&#22810;&#20010;&#29992;&#20363;&#20013;&#65292;&#23457;&#35745;&#26694;&#26550;&#24179;&#34913;&#20102;&#20449;&#20219;&#21644;&#25928;&#29992;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2304.10819</link><description>&lt;p&gt;
&#21487;&#25511;&#30340;&#20449;&#20219;&#26435;&#34913;&#19979;&#30340;&#21512;&#25104;&#25968;&#25454;&#23457;&#35745;&#19982;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Auditing and Generating Synthetic Data with Controllable Trust Trade-offs. (arXiv:2304.10819v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10819
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23457;&#35745;&#26694;&#26550;&#65292;&#33021;&#22815;&#20197;&#20840;&#38754;&#30340;&#26041;&#24335;&#35780;&#20272;&#21512;&#25104;&#25968;&#25454;&#21644;AI&#27169;&#22411;&#30340;&#20855;&#20307;&#25928;&#26524;&#65292;&#21253;&#25324;&#20559;&#35265;&#21644;&#27495;&#35270;&#39044;&#38450;&#12289;&#23545;&#30495;&#23454;&#25968;&#25454;&#30340;&#24544;&#23454;&#31243;&#24230;&#12289;&#25928;&#29992;&#12289;&#40065;&#26834;&#24615;&#21644;&#38544;&#31169;&#20445;&#25252;&#12290;&#22312;&#22810;&#20010;&#29992;&#20363;&#20013;&#65292;&#23457;&#35745;&#26694;&#26550;&#24179;&#34913;&#20102;&#20449;&#20219;&#21644;&#25928;&#29992;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#23454;&#20013;&#25910;&#38598;&#30340;&#25968;&#25454;&#24448;&#24448;&#23384;&#22312;&#20559;&#24046;&#12289;&#19981;&#24179;&#34913;&#65292;&#24182;&#19988;&#26377;&#27844;&#38706;&#25935;&#24863;&#21644;&#38544;&#31169;&#20449;&#24687;&#30340;&#39118;&#38505;&#12290;&#36825;&#19968;&#20107;&#23454;&#24341;&#21457;&#20102;&#21019;&#24314;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#24819;&#27861;&#65292;&#20197;&#20943;&#36731;&#30495;&#23454;&#25968;&#25454;&#20013;&#22266;&#26377;&#30340;&#39118;&#38505;&#12289;&#20559;&#35265;&#12289;&#20260;&#23475;&#21644;&#38544;&#31169;&#38382;&#39064;&#12290;&#36825;&#20010;&#27010;&#24565;&#20381;&#36182;&#20110;&#29983;&#25104;AI&#27169;&#22411;&#65292;&#20197;&#20135;&#29983;&#19981;&#20559;&#25191;&#12289;&#20445;&#25252;&#38544;&#31169;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#21516;&#26102;&#24544;&#23454;&#20110;&#30495;&#23454;&#25968;&#25454;&#12290;&#22312;&#36825;&#31181;&#26032;&#33539;&#24335;&#20013;&#65292;&#25105;&#20204;&#22914;&#20309;&#30693;&#36947;&#36825;&#31181;&#26041;&#27861;&#26159;&#21542;&#20817;&#29616;&#20102;&#20854;&#25215;&#35834;&#65311;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23457;&#35745;&#26694;&#26550;&#65292;&#25552;&#20379;&#20102;&#23545;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#22522;&#20110;&#23427;&#20204;&#35757;&#32451;&#30340;AI&#27169;&#22411;&#30340;&#20840;&#38754;&#35780;&#20272;&#65292;&#22260;&#32469;&#20559;&#35265;&#21644;&#27495;&#35270;&#30340;&#39044;&#38450;&#12289;&#23545;&#30495;&#23454;&#25968;&#25454;&#30340;&#24544;&#23454;&#31243;&#24230;&#12289;&#25928;&#29992;&#12289;&#40065;&#26834;&#24615;&#21644;&#38544;&#31169;&#20445;&#25252;&#12290;&#25105;&#20204;&#36890;&#36807;&#23457;&#35745;&#22810;&#20010;&#29983;&#25104;&#27169;&#22411;&#22312;&#19981;&#21516;&#29992;&#20363;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#65292;&#21253;&#25324;&#25945;&#32946;&#12289;&#21307;&#30103;&#20445;&#20581;&#12289;&#38134;&#34892;&#12289;&#20154;&#21147;&#36164;&#28304;&#65292;&#20197;&#21450;&#20174;&#34920;&#26684;&#65292;&#26102;&#38388;&#24207;&#21015;&#21040;&#33258;&#28982;&#35821;&#35328;&#30340;&#19981;&#21516;&#27169;&#24577;&#12290;&#25105;&#20204;&#30340;&#29992;&#20363;&#23637;&#31034;&#20102;&#22312;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#20013;&#24179;&#34913;&#20449;&#20219;&#21644;&#25928;&#29992;&#30340;&#26435;&#34913;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data collected from the real world tends to be biased, unbalanced, and at risk of exposing sensitive and private information. This reality has given rise to the idea of creating synthetic datasets to alleviate risk, bias, harm, and privacy concerns inherent in the real data. This concept relies on Generative AI models to produce unbiased, privacy-preserving synthetic data while being true to the real data. In this new paradigm, how can we tell if this approach delivers on its promises? We present an auditing framework that offers a holistic assessment of synthetic datasets and AI models trained on them, centered around bias and discrimination prevention, fidelity to the real data, utility, robustness, and privacy preservation. We showcase our framework by auditing multiple generative models on diverse use cases, including education, healthcare, banking, human resources, and across different modalities, from tabular, to time-series, to natural language. Our use cases demonstrate the imp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25345;&#32493;&#35757;&#32451;&#26041;&#27861;&#65292;&#21629;&#21517;&#20026;&#25193;&#25955;&#36741;&#21161; EBM&#65292;&#21487;&#20197;&#21516;&#26102;&#23454;&#29616;&#38271;&#26399;&#31283;&#23450;&#24615;&#12289;&#35757;&#32451;&#21518;&#30340;&#22270;&#20687;&#29983;&#25104;&#21644;&#20248;&#36234;&#30340;&#36234;&#30028;&#26816;&#27979;&#12290;</title><link>http://arxiv.org/abs/2304.10707</link><description>&lt;p&gt;
&#22522;&#20110;&#25193;&#25955;&#30340;&#33021;&#37327;&#27169;&#22411;&#30340;&#25345;&#32493;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Persistently Trained, Diffusion-assisted Energy-based Models. (arXiv:2304.10707v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10707
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25345;&#32493;&#35757;&#32451;&#26041;&#27861;&#65292;&#21629;&#21517;&#20026;&#25193;&#25955;&#36741;&#21161; EBM&#65292;&#21487;&#20197;&#21516;&#26102;&#23454;&#29616;&#38271;&#26399;&#31283;&#23450;&#24615;&#12289;&#35757;&#32451;&#21518;&#30340;&#22270;&#20687;&#29983;&#25104;&#21644;&#20248;&#36234;&#30340;&#36234;&#30028;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#37327;&#27169;&#22411; (EBMs) &#30340;&#26368;&#22823;&#20284;&#28982; (ML) &#23398;&#20064;&#24456;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#37096;&#20998;&#21407;&#22240;&#22312;&#20110;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#30340;&#19981;&#25910;&#25947;&#12290;&#34429;&#28982;&#24050;&#32463;&#25552;&#20986;&#20102;&#20960;&#31181; ML &#23398;&#20064;&#30340;&#21464;&#20307;&#65292;&#20294;&#29616;&#26377;&#26041;&#27861;&#37117;&#26410;&#33021;&#21516;&#26102;&#23454;&#29616;&#35757;&#32451;&#21518;&#30340;&#22270;&#20687;&#29983;&#25104;&#21644;&#21512;&#36866;&#30340;&#23494;&#24230;&#20272;&#35745;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#24341;&#20837;&#25193;&#25955;&#25968;&#25454;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#22686;&#24378;&#30340;&#37319;&#26679;&#31639;&#27861;&#36827;&#34892;&#25345;&#32493;&#35757;&#32451; (&#21363;&#20351;&#29992;&#25345;&#32493;&#30340;&#23545;&#27604;&#25955;&#24230;)&#65292;&#26469;&#23398;&#20064;&#19968;&#20010;&#31216;&#20026;&#25193;&#25955;&#36741;&#21161; EBM &#30340;&#32852;&#21512; EBM&#65292;&#20197;&#20415;&#20174;&#22797;&#26434;&#30340;&#12289;&#22810;&#23792;&#30340;&#20998;&#24067;&#20013;&#36827;&#34892;&#36866;&#24403;&#30340;&#37319;&#26679;&#12290;&#25105;&#20204;&#22312;&#20108;&#32500;&#30340;&#31034;&#20363;&#23454;&#39564;&#21644;&#22270;&#20687;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#32467;&#26524;&#65292;&#24182;&#35777;&#26126;&#20102;&#38024;&#23545;&#22270;&#20687;&#25968;&#25454;&#65292;&#25345;&#32493;&#35757;&#32451;&#30340; EBM &#21487;&#20197;&#21516;&#26102;&#23454;&#29616;&#38271;&#26399;&#31283;&#23450;&#24615;&#12289;&#35757;&#32451;&#21518;&#30340;&#22270;&#20687;&#29983;&#25104;&#21644;&#20248;&#36234;&#30340;&#36234;&#30028;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Maximum likelihood (ML) learning for energy-based models (EBMs) is challenging, partly due to non-convergence of Markov chain Monte Carlo.Several variations of ML learning have been proposed, but existing methods all fail to achieve both post-training image generation and proper density estimation. We propose to introduce diffusion data and learn a joint EBM, called diffusion assisted-EBMs, through persistent training (i.e., using persistent contrastive divergence) with an enhanced sampling algorithm to properly sample from complex, multimodal distributions. We present results from a 2D illustrative experiment and image experiments and demonstrate that, for the first time for image data, persistently trained EBMs can {\it simultaneously} achieve long-run stability, post-training image generation, and superior out-of-distribution detection.
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;Cayley&#21464;&#25442;&#22312;&#20219;&#24847;&#32500;&#24230;&#19978;&#23558;&#26925;&#29699;&#25311;&#21512;&#21040;&#22024;&#26434;&#25968;&#25454;&#20013;&#30340;&#26032;&#31639;&#27861;CTEF&#65292;&#21487;&#20197;&#25311;&#21512;&#20219;&#24847;&#30340;&#26925;&#29699;&#65292;&#24182;&#19988;&#33021;&#25552;&#21462;&#20854;&#20182;&#26041;&#27861;&#26080;&#27861;&#35782;&#21035;&#30340;&#25968;&#25454;&#20013;&#30340;&#38750;&#32447;&#24615;&#29305;&#24449;&#65292;&#21487;&#29992;&#20110;&#38477;&#32500;&#12289;&#25968;&#25454;&#21487;&#35270;&#21270;&#21644;&#32858;&#31867;&#65292;&#30456;&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#20248;&#12290;</title><link>http://arxiv.org/abs/2304.10630</link><description>&lt;p&gt;
&#29992;Cayley&#21464;&#25442;&#25311;&#21512;&#26925;&#29699;
&lt;/p&gt;
&lt;p&gt;
Ellipsoid fitting with the Cayley transform. (arXiv:2304.10630v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10630
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;Cayley&#21464;&#25442;&#22312;&#20219;&#24847;&#32500;&#24230;&#19978;&#23558;&#26925;&#29699;&#25311;&#21512;&#21040;&#22024;&#26434;&#25968;&#25454;&#20013;&#30340;&#26032;&#31639;&#27861;CTEF&#65292;&#21487;&#20197;&#25311;&#21512;&#20219;&#24847;&#30340;&#26925;&#29699;&#65292;&#24182;&#19988;&#33021;&#25552;&#21462;&#20854;&#20182;&#26041;&#27861;&#26080;&#27861;&#35782;&#21035;&#30340;&#25968;&#25454;&#20013;&#30340;&#38750;&#32447;&#24615;&#29305;&#24449;&#65292;&#21487;&#29992;&#20110;&#38477;&#32500;&#12289;&#25968;&#25454;&#21487;&#35270;&#21270;&#21644;&#32858;&#31867;&#65292;&#30456;&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;Cayley&#21464;&#25442;&#26925;&#29699;&#25311;&#21512;(CTEF)&#65292;&#23427;&#20351;&#29992;Cayley&#21464;&#25442;&#22312;&#20219;&#24847;&#32500;&#24230;&#19978;&#23558;&#26925;&#29699;&#25311;&#21512;&#21040;&#22024;&#26434;&#30340;&#25968;&#25454;&#20013;&#12290;&#19982;&#35768;&#22810;&#26925;&#29699;&#25311;&#21512;&#26041;&#27861;&#19981;&#21516;&#65292;CTEF&#26159;&#26925;&#29699;&#29305;&#23450;&#30340;&#8212;&#8212;&#24847;&#21619;&#30528;&#23427;&#24635;&#26159;&#36820;&#22238;&#26925;&#22278;&#35299;&#8212;&#8212;&#24182;&#19988;&#21487;&#20197;&#25311;&#21512;&#20219;&#24847;&#30340;&#26925;&#29699;&#12290;&#24403;&#25968;&#25454;&#19981;&#22343;&#21248;&#22320;&#20998;&#24067;&#22312;&#26925;&#29699;&#34920;&#38754;&#19978;&#26102;&#65292;&#23427;&#20063;&#20248;&#20110;&#20854;&#20182;&#25311;&#21512;&#26041;&#27861;&#12290;&#21463;&#26426;&#22120;&#23398;&#20064;&#20013;&#21487;&#35299;&#37322;&#21644;&#21487;&#37325;&#22797;&#26041;&#27861;&#30340;&#21628;&#21505;&#21551;&#21457;&#65292;&#25105;&#20204;&#23558;CTEF&#24212;&#29992;&#20110;&#38477;&#32500;&#12289;&#25968;&#25454;&#21487;&#35270;&#21270;&#21644;&#32858;&#31867;&#12290;&#30001;&#20110;CTEF&#25429;&#25417;&#20840;&#23616;&#26354;&#29575;&#65292;&#22240;&#27492;&#23427;&#33021;&#22815;&#25552;&#21462;&#20854;&#20182;&#26041;&#27861;&#26080;&#27861;&#35782;&#21035;&#30340;&#25968;&#25454;&#20013;&#30340;&#38750;&#32447;&#24615;&#29305;&#24449;&#12290;&#36825;&#22312;&#20154;&#31867;&#32454;&#32990;&#21608;&#26399;&#25968;&#25454;&#30340;&#38477;&#32500;&#21644;&#22312;&#32463;&#20856;&#29609;&#20855;&#20363;&#23376;&#30340;&#32858;&#31867;&#30340;&#32972;&#26223;&#19979;&#24471;&#21040;&#20102;&#35828;&#26126;&#12290;&#22312;&#21518;&#19968;&#31181;&#24773;&#20917;&#19979;&#65292;CTEF&#20248;&#20110;10&#31181;&#27969;&#34892;&#30340;&#32858;&#31867;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce an algorithm, Cayley transform ellipsoid fitting (CTEF), that uses the Cayley transform to fit ellipsoids to noisy data in any dimension. Unlike many ellipsoid fitting methods, CTEF is ellipsoid specific -- meaning it always returns elliptic solutions -- and can fit arbitrary ellipsoids. It also outperforms other fitting methods when data are not uniformly distributed over the surface of an ellipsoid. Inspired by calls for interpretable and reproducible methods in machine learning, we apply CTEF to dimension reduction, data visualization, and clustering. Since CTEF captures global curvature, it is able to extract nonlinear features in data that other methods fail to identify. This is illustrated in the context of dimension reduction on human cell cycle data, and in the context of clustering on classical toy examples. In the latter case, CTEF outperforms 10 popular clustering algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#38543;&#26426;&#22806;&#25512;&#25216;&#26415;&#65292;&#29992;&#20110;&#38477;&#20302;&#26465;&#20214;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#20559;&#24046;&#65292;&#24182;&#35777;&#26126;&#22312;&#38750;&#20984;&#20809;&#28369;&#30446;&#26631;&#20989;&#25968;&#20013;&#65292;&#23558;&#22806;&#25512;&#19982;&#26041;&#24046;&#32553;&#20943;&#25216;&#26415;&#30456;&#32467;&#21512;&#21487;&#20197;&#26174;&#33879;&#25913;&#21892;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2304.10613</link><description>&lt;p&gt;
&#28040;&#38500;&#26465;&#20214;&#38543;&#26426;&#20248;&#21270;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Debiasing Conditional Stochastic Optimization. (arXiv:2304.10613v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10613
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#38543;&#26426;&#22806;&#25512;&#25216;&#26415;&#65292;&#29992;&#20110;&#38477;&#20302;&#26465;&#20214;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#20559;&#24046;&#65292;&#24182;&#35777;&#26126;&#22312;&#38750;&#20984;&#20809;&#28369;&#30446;&#26631;&#20989;&#25968;&#20013;&#65292;&#23558;&#22806;&#25512;&#19982;&#26041;&#24046;&#32553;&#20943;&#25216;&#26415;&#30456;&#32467;&#21512;&#21487;&#20197;&#26174;&#33879;&#25913;&#21892;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35206;&#30422;&#20102;&#22810;&#20010;&#24212;&#29992;&#39046;&#22495;&#65292;&#21253;&#25324;&#25237;&#36164;&#32452;&#21512;&#36873;&#25321;&#12289;&#24378;&#21270;&#23398;&#20064;&#12289;&#40065;&#26834;&#23398;&#20064;&#12289;&#22240;&#26524;&#25512;&#26029;&#31561;&#30340;&#26465;&#20214;&#38543;&#26426;&#20248;&#21270;&#65288;CSO&#65289;&#38382;&#39064;&#12290;&#30001;&#20110;&#20854;&#23884;&#22871;&#32467;&#26500;&#65292;CSO&#30446;&#26631;&#30340;&#26679;&#26412;&#24179;&#22343;&#26799;&#24230;&#23384;&#22312;&#20559;&#24046;&#65292;&#22240;&#27492;&#38656;&#35201;&#36739;&#39640;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#25165;&#33021;&#36798;&#21040;&#25910;&#25947;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26377;&#25928;&#38477;&#20302;&#20559;&#24046;&#30340;&#36890;&#29992;&#38543;&#26426;&#22806;&#25512;&#25216;&#26415;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#38750;&#20984;&#20809;&#28369;&#30446;&#26631;&#20989;&#25968;&#20013;&#65292;&#23558;&#36825;&#31181;&#22806;&#25512;&#19982;&#26041;&#24046;&#32553;&#20943;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#36798;&#21040;&#27604;&#29616;&#26377;&#30028;&#38480;&#26356;&#22909;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#29992;&#20110;&#26377;&#38480;&#21644;&#21464;&#37327;&#30340;CSO&#30340;&#26032;&#31639;&#27861;&#65292;&#20063;&#26174;&#33879;&#25913;&#36827;&#20102;&#29616;&#26377;&#32467;&#26524;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35748;&#20026;&#25105;&#20204;&#30340;&#21435;&#20559;&#25216;&#26415;&#20063;&#21487;&#33021;&#26159;&#36866;&#29992;&#20110;&#20854;&#20182;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#30340;&#26377;&#36259;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the conditional stochastic optimization (CSO) problem which covers a variety of applications including portfolio selection, reinforcement learning, robust learning, causal inference, etc. The sample-averaged gradient of the CSO objective is biased due to its nested structure and therefore requires a high sample complexity to reach convergence. We introduce a general stochastic extrapolation technique that effectively reduces the bias. We show that for nonconvex smooth objectives, combining this extrapolation with variance reduction techniques can achieve a significantly better sample complexity than existing bounds. We also develop new algorithms for the finite-sum variant of CSO that also significantly improve upon existing results. Finally, we believe that our debiasing technique could be an interesting tool applicable to other stochastic optimization problems too.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20803;&#23398;&#20064;&#22120; B-Learner&#65292;&#23427;&#21487;&#20197;&#22312;&#38480;&#21046;&#38544;&#34255;&#28151;&#28102;&#27700;&#24179;&#30340;&#24773;&#20917;&#19979;&#39640;&#25928;&#22320;&#23398;&#20064; CATE &#20989;&#25968;&#30340;&#23574;&#38160;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2304.10577</link><description>&lt;p&gt;
B-Learner&#65306;&#38544;&#34255;&#28151;&#28102;&#19979;&#24322;&#36136;&#22240;&#26524;&#25928;&#24212;&#30340;&#20934;&#31070;&#35861;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
B-Learner: Quasi-Oracle Bounds on Heterogeneous Causal Effects Under Hidden Confounding. (arXiv:2304.10577v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10577
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20803;&#23398;&#20064;&#22120; B-Learner&#65292;&#23427;&#21487;&#20197;&#22312;&#38480;&#21046;&#38544;&#34255;&#28151;&#28102;&#27700;&#24179;&#30340;&#24773;&#20917;&#19979;&#39640;&#25928;&#22320;&#23398;&#20064; CATE &#20989;&#25968;&#30340;&#23574;&#38160;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#23519;&#25968;&#25454;&#20013;&#20272;&#35745;&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;&#26159;&#35768;&#22810;&#39046;&#22495;&#20013;&#30340;&#37325;&#35201;&#20219;&#21153;&#65292;&#26377;&#21161;&#20110;&#25919;&#31574;&#21644;&#20915;&#31574;&#32773;&#20570;&#20986;&#26356;&#22909;&#30340;&#34892;&#21160;&#12290;&#36817;&#24180;&#26469;&#65292;&#22312;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#27835;&#30103;&#25928;&#24212;&#65288;CATE&#65289;&#20989;&#25968;&#26041;&#38754;&#21462;&#24471;&#20102;&#40065;&#26834;&#19988;&#39640;&#25928;&#30340;&#26041;&#27861;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#26410;&#32771;&#34385;&#38544;&#34255;&#28151;&#28102;&#30340;&#39118;&#38505;&#65292;&#36825;&#21487;&#33021;&#20250;&#23545;&#22522;&#20110;&#35266;&#23519;&#25968;&#25454;&#30340;&#20219;&#20309;&#22240;&#26524;&#20272;&#35745;&#36896;&#25104;&#20219;&#24847;&#21644;&#19981;&#30693;&#24773;&#30340;&#20559;&#24046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;B-Learner&#30340;&#20803;&#23398;&#20064;&#22120;&#65292;&#23427;&#21487;&#20197;&#22312;&#38480;&#21046;&#38544;&#34255;&#28151;&#28102;&#27700;&#24179;&#30340;&#24773;&#20917;&#19979;&#39640;&#25928;&#22320;&#23398;&#20064;CATE&#20989;&#25968;&#30340;&#23574;&#38160;&#30028;&#38480;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#26368;&#36817;&#38024;&#23545;&#24179;&#22343;&#27835;&#30103;&#25928;&#24212;&#30340;&#23574;&#38160;&#19988;&#26377;&#25928;&#36793;&#30028;&#32467;&#26524;&#65288;Dorn&#31561;&#20154;&#65292;2021&#65289;&#35843;&#25972;&#20026;Kallus&#65286;Oprescu&#65288;2022&#65289;&#25152;&#25552;&#20379;&#30340;&#31283;&#20581;&#21644;&#27169;&#22411;&#26080;&#20851;&#30340;&#20998;&#24067;&#24335;&#27835;&#30103;&#25928;&#24212;&#23398;&#20064;&#26694;&#26550;&#65292;&#27966;&#29983;&#20986;B-Learner&#12290;B-Learner&#21487;&#20197;&#20351;&#29992;&#20219;&#20309;&#20989;&#25968;&#20272;&#35745;&#22120;&#65292;&#20363;&#22914;&#38543;&#26426;&#26862;&#26519;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23427;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating heterogeneous treatment effects from observational data is a crucial task across many fields, helping policy and decision-makers take better actions. There has been recent progress on robust and efficient methods for estimating the conditional average treatment effect (CATE) function, but these methods often do not take into account the risk of hidden confounding, which could arbitrarily and unknowingly bias any causal estimate based on observational data. We propose a meta-learner called the B-Learner, which can efficiently learn sharp bounds on the CATE function under limits on the level of hidden confounding. We derive the B-Learner by adapting recent results for sharp and valid bounds of the average treatment effect (Dorn et al., 2021) into the framework given by Kallus &amp; Oprescu (2022) for robust and model-agnostic learning of distributional treatment effects. The B-Learner can use any function estimator such as random forests and deep neural networks, and we prove its 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#25554;&#20540;&#20219;&#20309;&#25968;&#25454;&#38598;&#65292;&#21363;&#25439;&#22833;&#20989;&#25968;&#20855;&#26377;&#20840;&#23616;&#26368;&#23567;&#20540;&#20026;&#38646;&#30340;&#24615;&#36136;&#65292;&#27492;&#22806;&#36824;&#32473;&#20986;&#20102;&#35813;&#20840;&#23616;&#26368;&#23567;&#20540;&#22788;&#30340;&#24815;&#24615;&#30697;&#38453;&#30340;&#34920;&#24449;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;&#27010;&#29575;&#26041;&#27861;&#26469;&#23547;&#25214;&#25554;&#20540;&#28857;&#12290;</title><link>http://arxiv.org/abs/2304.10552</link><description>&lt;p&gt;
&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#25554;&#20540;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Interpolation property of shallow neural networks. (arXiv:2304.10552v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10552
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#25554;&#20540;&#20219;&#20309;&#25968;&#25454;&#38598;&#65292;&#21363;&#25439;&#22833;&#20989;&#25968;&#20855;&#26377;&#20840;&#23616;&#26368;&#23567;&#20540;&#20026;&#38646;&#30340;&#24615;&#36136;&#65292;&#27492;&#22806;&#36824;&#32473;&#20986;&#20102;&#35813;&#20840;&#23616;&#26368;&#23567;&#20540;&#22788;&#30340;&#24815;&#24615;&#30697;&#38453;&#30340;&#34920;&#24449;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;&#27010;&#29575;&#26041;&#27861;&#26469;&#23547;&#25214;&#25554;&#20540;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#25439;&#22833;&#20989;&#25968;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#20960;&#20309;&#24615;&#36136;&#12290;&#22312;&#22823;&#22810;&#25968;&#20248;&#21270;&#38382;&#39064;&#20013;&#65292;&#25439;&#22833;&#20989;&#25968;&#26159;&#20984;&#20989;&#25968;&#65292;&#36825;&#31181;&#24773;&#20917;&#19979;&#25105;&#20204;&#21482;&#26377;&#19968;&#20010;&#20840;&#23616;&#26368;&#23567;&#20540;&#65292;&#25110;&#32773;&#26159;&#38750;&#20984;&#20989;&#25968;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#25105;&#20204;&#26377;&#19968;&#20010;&#26377;&#38480;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#36229;&#21442;&#25968;&#21270;&#33539;&#22260;&#20869;&#65292;&#23545;&#20110;&#38750;&#23567;&#27425;&#25968;&#22810;&#39033;&#24335;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#25554;&#20540;&#20219;&#20309;&#25968;&#25454;&#38598;&#65292;&#21363;&#25439;&#22833;&#20989;&#25968;&#20855;&#26377;&#20840;&#23616;&#26368;&#23567;&#20540;&#20026;&#38646;&#30340;&#24615;&#36136;&#12290;&#27492;&#22806;&#65292;&#22914;&#26524;&#23384;&#22312;&#36825;&#26679;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#65292;&#21017;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#36718;&#24275;&#26377;&#26080;&#31351;&#22810;&#20010;&#28857;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#22312;&#20840;&#23616;&#26368;&#23567;&#20540;&#22788;&#27714;&#35299;&#25439;&#22833;&#20989;&#25968;&#30340;&#28023;&#22622;&#30697;&#38453;&#30340;&#34920;&#24449;&#65292;&#24182;&#22312;&#26368;&#21518;&#19968;&#33410;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;&#27010;&#29575;&#26041;&#27861;&#26469;&#23547;&#25214;&#25554;&#20540;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the geometry of global minima of the loss landscape of overparametrized neural networks. In most optimization problems, the loss function is convex, in which case we only have a global minima, or nonconvex, with a discrete number of global minima. In this paper, we prove that in the overparametrized regime, a shallow neural network can interpolate any data set, i.e. the loss function has a global minimum value equal to zero as long as the activation function is not a polynomial of small degree. Additionally, if such a global minimum exists, then the locus of global minima has infinitely many points. Furthermore, we give a characterization of the Hessian of the loss function evaluated at the global minima, and in the last section, we provide a practical probabilistic method of finding the interpolation point.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#20445;&#30041;&#35889;&#30340;&#25968;&#25454;&#21387;&#32553;&#26469;&#21152;&#36895;&#25903;&#25345;&#21521;&#37327;&#32858;&#31867;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#32858;&#31867;&#36895;&#24230;&#32780;&#19981;&#29306;&#29298;&#32858;&#31867;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2304.09868</link><description>&lt;p&gt;
&#36890;&#36807;&#20445;&#30041;&#35889;&#30340;&#25968;&#25454;&#21387;&#32553;&#21152;&#36895;&#25903;&#25345;&#21521;&#37327;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Accelerate Support Vector Clustering via Spectrum-Preserving Data Compression?. (arXiv:2304.09868v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09868
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#20445;&#30041;&#35889;&#30340;&#25968;&#25454;&#21387;&#32553;&#26469;&#21152;&#36895;&#25903;&#25345;&#21521;&#37327;&#32858;&#31867;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#32858;&#31867;&#36895;&#24230;&#32780;&#19981;&#29306;&#29298;&#32858;&#31867;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25903;&#25345;&#21521;&#37327;&#32858;&#31867;&#26159;&#19968;&#31181;&#37325;&#35201;&#30340;&#32858;&#31867;&#26041;&#27861;&#65292;&#20294;&#26159;&#30001;&#20110;&#20854;&#35745;&#31639;&#26114;&#36149;&#30340;&#31751;&#20998;&#37197;&#27493;&#39588;&#65292;&#23427;&#38754;&#20020;&#30528;&#21487;&#20280;&#32553;&#24615;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#20445;&#30041;&#35889;&#30340;&#25968;&#25454;&#21387;&#32553;&#26469;&#21152;&#36895;&#25903;&#25345;&#21521;&#37327;&#32858;&#31867;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;&#21407;&#22987;&#25968;&#25454;&#38598;&#21387;&#32553;&#25104;&#23569;&#37327;&#35889;&#34920;&#31034;&#30340;&#32858;&#21512;&#25968;&#25454;&#28857;&#65292;&#28982;&#21518;&#22312;&#21387;&#32553;&#21518;&#30340;&#25968;&#25454;&#38598;&#19978;&#25191;&#34892;&#26631;&#20934;&#30340;&#25903;&#25345;&#21521;&#37327;&#32858;&#31867;&#65292;&#26368;&#21518;&#23558;&#21387;&#32553;&#25968;&#25454;&#38598;&#30340;&#32858;&#31867;&#32467;&#26524;&#26144;&#23556;&#22238;&#21407;&#22987;&#25968;&#25454;&#38598;&#20197;&#21457;&#29616;&#31751;&#12290;&#25105;&#20204;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#22823;&#37327;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#36739;&#20110;&#26631;&#20934;&#25903;&#25345;&#21521;&#37327;&#32858;&#31867;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22823;&#22823;&#25552;&#39640;&#20102;&#36895;&#24230;&#65292;&#32780;&#19981;&#20250;&#25439;&#22833;&#32858;&#31867;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Support vector clustering is an important clustering method. However, it suffers from a scalability issue due to its computational expensive cluster assignment step. In this paper we accelertate the support vector clustering via spectrum-preserving data compression. Specifically, we first compress the original data set into a small amount of spectrally representative aggregated data points. Then, we perform standard support vector clustering on the compressed data set. Finally, we map the clustering results of the compressed data set back to discover the clusters in the original data set. Our extensive experimental results on real-world data set demonstrate dramatically speedups over standard support vector clustering without sacrificing clustering quality.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#27969;&#24418;&#23398;&#20064;&#20013;&#24212;&#29992;&#26080;&#30896;&#25758;&#36816;&#36755;&#22270;&#30340;&#26041;&#27861;&#65292;&#20854;&#21487;&#20197;&#27604;OT&#22270;&#26356;&#20415;&#23452;&#22320;&#35745;&#31639;&#36317;&#31163;&#65292;&#24182;&#25552;&#20379;&#21333;&#20010;&#27010;&#29575;&#27979;&#24230;&#30340;&#24179;&#31227;&#21644;&#20280;&#32553;&#30340;&#31561;&#36317;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.00199</link><description>&lt;p&gt;
&#26080;&#30896;&#25758;&#36816;&#36755;&#22270;&#22312;&#27969;&#34892;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Applications of No-Collision Transportation Maps in Manifold Learning. (arXiv:2304.00199v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00199
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#27969;&#24418;&#23398;&#20064;&#20013;&#24212;&#29992;&#26080;&#30896;&#25758;&#36816;&#36755;&#22270;&#30340;&#26041;&#27861;&#65292;&#20854;&#21487;&#20197;&#27604;OT&#22270;&#26356;&#20415;&#23452;&#22320;&#35745;&#31639;&#36317;&#31163;&#65292;&#24182;&#25552;&#20379;&#21333;&#20010;&#27010;&#29575;&#27979;&#24230;&#30340;&#24179;&#31227;&#21644;&#20280;&#32553;&#30340;&#31561;&#36317;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24341;&#20837;&#20110;[Nurbekyan et al.&#65292;2020]&#30340;&#26080;&#30896;&#25758;&#36816;&#36755;&#22270;&#22312;&#22270;&#20687;&#25968;&#25454;&#30340;&#27969;&#24418;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#36817;&#24180;&#26469;&#65292;&#22312;&#34920;&#31034;&#31867;&#20284;&#36816;&#21160;&#25110;&#21464;&#24418;&#29616;&#35937;&#30340;&#25968;&#25454;&#20013;&#65292;&#24212;&#29992;&#22522;&#20110;&#36816;&#36755;&#30340;&#36317;&#31163;&#21644;&#29305;&#24449;&#30340;&#30740;&#31350;&#22823;&#24133;&#22686;&#21152;&#12290;&#20107;&#23454;&#19978;&#65292;&#22266;&#23450;&#20301;&#32622;&#27604;&#36739;&#24378;&#24230;&#36890;&#24120;&#26080;&#27861;&#26174;&#31034;&#25968;&#25454;&#32467;&#26500;&#12290;&#22312;[Nurbekyan et al.&#65292;2020]&#20013;&#24320;&#21457;&#30340;&#26080;&#30896;&#25758;&#22270;&#21644;&#36317;&#31163;&#31867;&#20284;&#20110;&#26368;&#20248;&#20256;&#36755;(OT)&#22270;&#30340;&#20960;&#20309;&#29305;&#24449;&#20294;&#30001;&#20110;&#26080;&#38656;&#20248;&#21270;&#65292;&#35745;&#31639;&#25104;&#26412;&#35201;&#20415;&#23452;&#24471;&#22810;&#12290;&#26412;&#25991;&#35777;&#26126;&#26080;&#30896;&#25758;&#36317;&#31163;&#25552;&#20379;&#21333;&#20010;&#27010;&#29575;&#27979;&#24230;&#30340;&#24179;&#31227;(&#20998;&#21035;&#26159;&#20280;&#32553;)&#21644;&#35013;&#22791;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#30340;&#24179;&#31227;(&#20998;&#21035;&#26159;&#20280;&#32553;)&#21521;&#37327;&#20043;&#38388;&#30340;&#31561;&#36317;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#26080;&#30896;&#25758;&#36816;&#36755;&#22270;&#20197;&#21450;OT&#21644;&#32447;&#24615;OT&#22270;&#65292;&#19968;&#33324;&#26469;&#35828;&#19981;&#33021;&#20026;&#26059;&#36716;&#25552;&#20379;&#31561;&#36317;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we investigate applications of no-collision transportation maps introduced in [Nurbekyan et. al., 2020] in manifold learning for image data. Recently, there has been a surge in applying transportation-based distances and features for data representing motion-like or deformation-like phenomena. Indeed, comparing intensities at fixed locations often does not reveal the data structure. No-collision maps and distances developed in [Nurbekyan et. al., 2020] are sensitive to geometric features similar to optimal transportation (OT) maps but much cheaper to compute due to the absence of optimization. In this work, we prove that no-collision distances provide an isometry between translations (respectively dilations) of a single probability measure and the translation (respectively dilation) vectors equipped with a Euclidean distance. Furthermore, we prove that no-collision transportation maps, as well as OT and linearized OT maps, do not in general provide an isometry for rotatio
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28040;&#38500;OCV&#65288;Aliasing&#65289;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#22797;&#25968;&#21367;&#31215;&#65292;&#21516;&#26102;&#37319;&#29992;Gabor&#26679;&#24335;&#30340;&#21367;&#31215;&#26680;&#65292;&#21487;&#20197;&#25552;&#39640;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#31867;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2212.00394</link><description>&lt;p&gt;
&#20174;CNN&#21040;&#22522;&#20110;&#22797;&#23567;&#27874;&#30340;&#24179;&#31227;&#19981;&#21464;&#21452;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
From CNNs to Shift-Invariant Twin Models Based on Complex Wavelets. (arXiv:2212.00394v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.00394
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28040;&#38500;OCV&#65288;Aliasing&#65289;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#22797;&#25968;&#21367;&#31215;&#65292;&#21516;&#26102;&#37319;&#29992;Gabor&#26679;&#24335;&#30340;&#21367;&#31215;&#26680;&#65292;&#21487;&#20197;&#25552;&#39640;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#31867;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25239;&#28151;&#21472;&#26041;&#27861;&#26469;&#22686;&#21152;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#24179;&#31227;&#19981;&#21464;&#24615;&#21644;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#29992;&#8220;&#22797;&#20540;&#21367;&#31215;+&#27169;&#36816;&#31639;&#8221;&#65288;$\mathbb{C}$Mod&#65289;&#20195;&#26367;&#31532;&#19968;&#23618;&#30340;&#8220;&#23454;&#20540;&#21367;&#31215;+&#26368;&#22823;&#27744;&#21270;&#8221;&#65288;$\mathbb{R}$Max&#65289;&#65292;&#22240;&#20026;&#23427;&#31283;&#23450;&#20110;&#24179;&#31227;&#12290;&#20026;&#20102;&#35777;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#22768;&#31216;&#24403;&#21367;&#31215;&#26680;&#26159;&#24102;&#36890;&#21644;&#23450;&#21521;&#30340;&#65288;&#31867;&#20284;&#20110;Gabor&#28388;&#27874;&#22120;&#65289;&#26102;&#65292;$\mathbb{C}$Mod&#21644;$\mathbb{R}$Max&#20135;&#29983;&#21487;&#27604;&#36739;&#30340;&#36755;&#20986;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;$\mathbb{C}$Mod&#21487;&#20197;&#34987;&#35748;&#20026;&#26159;$\mathbb{R}$Max&#30340;&#31283;&#23450;&#26367;&#20195;&#21697;&#12290;&#22240;&#27492;&#65292;&#22312;&#25239;&#28151;&#21472;&#20043;&#21069;&#65292;&#25105;&#20204;&#24378;&#21046;&#21367;&#31215;&#26680;&#37319;&#29992;&#36825;&#31181;Gabor&#26679;&#24335;&#30340;&#32467;&#26500;&#12290;&#30456;&#24212;&#30340;&#26550;&#26500;&#31216;&#20026;&#25968;&#23398;&#21452;&#27169;&#22411;&#65292;&#22240;&#20026;&#23427;&#20351;&#29992;&#19968;&#20010;&#26126;&#30830;&#23450;&#20041;&#30340;&#25968;&#23398;&#36816;&#31639;&#31526;&#26469;&#27169;&#25311;&#21407;&#22987;&#30340;&#33258;&#30001;&#35757;&#32451;&#27169;&#22411;&#30340;&#34892;&#20026;&#12290;&#25105;&#20204;&#30340;&#25239;&#28151;&#21472;&#26041;&#27861;&#22312;Imagenet&#21644;CIFAR-10&#20998;&#31867;&#20219;&#21153;&#19978;&#23454;&#29616;&#20102;&#27604;&#20043;&#21069;&#26356;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel antialiasing method to increase shift invariance and prediction accuracy in convolutional neural networks. Specifically, we replace the first-layer combination "real-valued convolutions + max pooling" ($\mathbb{R}$Max) by "complex-valued convolutions + modulus" ($\mathbb{C}$Mod), which is stable to translations. To justify our approach, we claim that $\mathbb{C}$Mod and $\mathbb{R}$Max produce comparable outputs when the convolution kernel is band-pass and oriented (Gabor-like filter). In this context, $\mathbb{C}$Mod can be considered as a stable alternative to $\mathbb{R}$Max. Thus, prior to antialiasing, we force the convolution kernels to adopt such a Gabor-like structure. The corresponding architecture is called mathematical twin, because it employs a well-defined mathematical operator to mimic the behavior of the original, freely-trained model. Our antialiasing approach achieves superior accuracy on ImageNet and CIFAR-10 classification tasks, compared to prior 
&lt;/p&gt;</description></item><item><title>&#31232;&#30095;&#22270;&#20013;&#30340;&#22823;&#37327;&#19977;&#35282;&#24418;&#21487;&#20351;&#29992;&#26080;&#38480;&#32500;&#24230;&#20869;&#31215;&#27169;&#22411;&#36827;&#34892;&#22797;&#29616;&#65292;&#20854;&#20013;&#33410;&#28857;&#34920;&#31034;&#20301;&#20110;&#20302;&#32500;&#27969;&#24418;&#19978;&#12290;&#34429;&#28982;&#20840;&#23616;&#34920;&#31034;&#26159;&#19981;&#21487;&#33021;&#30340;&#65292;&#20294;&#25105;&#20204;&#21487;&#20197;&#22312;&#26412;&#22320;&#37051;&#22495;&#32553;&#23567;&#35268;&#27169;&#65292;&#20197;&#33719;&#21462;&#36739;&#20302;&#32500;&#24230;&#30340;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2210.15277</link><description>&lt;p&gt;
&#31232;&#30095;&#19982;&#39640;&#19977;&#35282;&#23494;&#24230;&#23545;&#20110;&#22270;&#34920;&#31034;&#23398;&#20064;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Implications of sparsity and high triangle density for graph representation learning. (arXiv:2210.15277v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.15277
&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#22270;&#20013;&#30340;&#22823;&#37327;&#19977;&#35282;&#24418;&#21487;&#20351;&#29992;&#26080;&#38480;&#32500;&#24230;&#20869;&#31215;&#27169;&#22411;&#36827;&#34892;&#22797;&#29616;&#65292;&#20854;&#20013;&#33410;&#28857;&#34920;&#31034;&#20301;&#20110;&#20302;&#32500;&#27969;&#24418;&#19978;&#12290;&#34429;&#28982;&#20840;&#23616;&#34920;&#31034;&#26159;&#19981;&#21487;&#33021;&#30340;&#65292;&#20294;&#25105;&#20204;&#21487;&#20197;&#22312;&#26412;&#22320;&#37051;&#22495;&#32553;&#23567;&#35268;&#27169;&#65292;&#20197;&#33719;&#21462;&#36739;&#20302;&#32500;&#24230;&#30340;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#21253;&#21547;&#35768;&#22810;&#19977;&#35282;&#24418;&#30340;&#31232;&#30095;&#22270;&#20013;&#65292;&#26080;&#27861;&#20351;&#29992;&#33410;&#28857;&#30340;&#26377;&#38480;&#32500;&#24230;&#34920;&#31034;&#26469;&#37325;&#29616;&#65292;&#20854;&#20013;&#36830;&#32467;&#27010;&#29575;&#26159;&#20869;&#31215;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#26679;&#30340;&#22270;&#21487;&#20197;&#20351;&#29992;&#26080;&#38480;&#32500;&#24230;&#30340;&#20869;&#31215;&#27169;&#22411;&#26469;&#22797;&#29616;&#65292;&#20854;&#20013;&#33410;&#28857;&#34920;&#31034;&#20301;&#20110;&#20302;&#32500;&#27969;&#24418;&#19978;&#12290;&#22312;&#31232;&#30095;&#30340;&#24773;&#20917;&#19979;&#65292;&#24674;&#22797;&#27969;&#24418;&#30340;&#20840;&#23616;&#34920;&#31034;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21487;&#20197;&#32553;&#23567;&#21040;&#26412;&#22320;&#37051;&#22495;&#65292;&#22312;&#37027;&#37324;&#36739;&#20302;&#32500;&#24230;&#30340;&#34920;&#31034;&#26159;&#21487;&#33021;&#30340;&#12290;&#30001;&#20110;&#25105;&#20204;&#30340;&#26500;&#36896;&#20801;&#35768;&#28857;&#22343;&#21248;&#20998;&#24067;&#22312;&#27969;&#24418;&#19978;&#65292;&#22240;&#27492;&#25105;&#20204;&#21457;&#29616;&#20102;&#21453;&#23545;&#36890;&#24120;&#30340;&#30475;&#27861;&#8212;&#8212;&#19977;&#35282;&#24418;&#24847;&#21619;&#30528;&#31038;&#21306;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work has shown that sparse graphs containing many triangles cannot be reproduced using a finite-dimensional representation of the nodes, in which link probabilities are inner products. Here, we show that such graphs can be reproduced using an infinite-dimensional inner product model, where the node representations lie on a low-dimensional manifold. Recovering a global representation of the manifold is impossible in a sparse regime. However, we can zoom in on local neighbourhoods, where a lower-dimensional representation is possible. As our constructions allow the points to be uniformly distributed on the manifold, we find evidence against the common perception that triangles imply community structure.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#27169;&#22411;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#22823;&#22810;&#25968;&#39044;&#27979;&#20219;&#21153;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#22810;&#20010;&#19979;&#28216;&#20219;&#21153;&#20013;&#23454;&#38469;&#20351;&#29992;&#12290;</title><link>http://arxiv.org/abs/2210.12256</link><description>&lt;p&gt;
&#19968;&#31181;&#36890;&#29992;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#26041;&#27861;&#29992;&#20110;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Uncertainty Estimates of Predictions via a General Bias-Variance Decomposition. (arXiv:2210.12256v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.12256
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#27169;&#22411;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#22823;&#22810;&#25968;&#39044;&#27979;&#20219;&#21153;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#22810;&#20010;&#19979;&#28216;&#20219;&#21153;&#20013;&#23454;&#38469;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#23433;&#20840;&#20851;&#38190;&#30340;&#24212;&#29992;&#20013;&#65292;&#21487;&#38752;&#22320;&#20272;&#35745;&#27169;&#22411;&#29983;&#21629;&#21608;&#26399;&#20869;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#26368;&#24120;&#29992;&#30340;&#34913;&#37327;&#26041;&#27861;&#26159;&#36890;&#36807;&#39044;&#27979;&#32622;&#20449;&#24230;&#26469;&#34913;&#37327;&#12290;&#34429;&#28982;&#36825;&#31181;&#26041;&#27861;&#22312;&#39046;&#22495;&#20869;&#26679;&#26412;&#20013;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#22312;&#39046;&#22495;&#28418;&#31227;&#26102;&#36825;&#20123;&#20272;&#35745;&#26159;&#19981;&#21487;&#38752;&#30340;&#65292;&#24182;&#19988;&#20165;&#38480;&#20110;&#20998;&#31867;&#12290;&#30456;&#21453;&#65292;&#23545;&#20110;&#22823;&#22810;&#25968;&#39044;&#27979;&#20219;&#21153;&#65292;&#21487;&#20197;&#20351;&#29992;&#36866;&#24403;&#30340;&#24471;&#20998;&#65292;&#20294;&#26159;&#24403;&#21069;&#25991;&#29486;&#20013;&#19981;&#23384;&#22312;&#29992;&#20110;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#26041;&#27861;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#36866;&#29992;&#20110;&#36866;&#24403;&#24471;&#20998;&#30340;&#36890;&#29992;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#26041;&#27861;&#65292;&#30001;&#27492;&#24341;&#20986;Bregman&#20449;&#24687;&#20316;&#20026;&#26041;&#24046;&#39033;&#12290;&#25105;&#20204;&#21457;&#29616;&#25351;&#25968;&#26063;&#21644;&#20998;&#31867;&#23545;&#25968;&#20284;&#28982;&#26159;&#29305;&#27530;&#24773;&#20917;&#65292;&#24182;&#25552;&#20379;&#20102;&#26032;&#30340;&#20844;&#24335;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#21487;&#20197;&#32431;&#31929;&#22320;&#22312;logit&#31354;&#38388;&#20013;&#34920;&#31034;&#20998;&#31867;&#24773;&#20917;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#20998;&#35299;&#26041;&#27861;&#22312;&#22810;&#20010;&#19979;&#28216;&#20219;&#21153;&#20013;&#30340;&#23454;&#38469;&#30456;&#20851;&#24615;&#65292;&#21253;&#25324;&#27169;&#22411;&#38598;&#25104;&#21644;&#32622;&#20449;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reliably estimating the uncertainty of a prediction throughout the model lifecycle is crucial in many safety-critical applications. The most common way to measure this uncertainty is via the predicted confidence. While this tends to work well for in-domain samples, these estimates are unreliable under domain drift and restricted to classification. Alternatively, proper scores can be used for most predictive tasks but a bias-variance decomposition for model uncertainty does not exist in the current literature. In this work we introduce a general bias-variance decomposition for proper scores, giving rise to the Bregman Information as the variance term. We discover how exponential families and the classification log-likelihood are special cases and provide novel formulations. Surprisingly, we can express the classification case purely in the logit space. We showcase the practical relevance of this decomposition on several downstream tasks, including model ensembles and confidence regions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#24341;&#23548;&#37319;&#26679;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#38544;&#31169;&#25104;&#26412;&#30340;&#26032;&#32467;&#26524;&#65292;&#21487;&#29992;&#20110;&#25512;&#26029;&#26679;&#26412;&#20998;&#24067;&#24182;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#65292;&#21516;&#26102;&#25351;&#20986;&#20102;&#29616;&#26377;&#25991;&#29486;&#20013;&#30340;&#35823;&#29992;&#12290;&#38543;&#30528;&#37319;&#26679;&#27425;&#25968;&#36235;&#36817;&#26080;&#38480;&#22823;&#65292;&#27492;&#26041;&#27861;&#36880;&#28176;&#28385;&#36275;&#26356;&#20005;&#26684;&#30340;&#24046;&#20998;&#38544;&#31169;&#35201;&#27714;&#12290;</title><link>http://arxiv.org/abs/2210.06140</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#24341;&#23548;&#37319;&#26679;&#65306;&#26032;&#30340;&#38544;&#31169;&#20998;&#26512;&#19982;&#25512;&#26029;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Bootstrap: New Privacy Analysis and Inference Strategies. (arXiv:2210.06140v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.06140
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#24341;&#23548;&#37319;&#26679;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#38544;&#31169;&#25104;&#26412;&#30340;&#26032;&#32467;&#26524;&#65292;&#21487;&#29992;&#20110;&#25512;&#26029;&#26679;&#26412;&#20998;&#24067;&#24182;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#65292;&#21516;&#26102;&#25351;&#20986;&#20102;&#29616;&#26377;&#25991;&#29486;&#20013;&#30340;&#35823;&#29992;&#12290;&#38543;&#30528;&#37319;&#26679;&#27425;&#25968;&#36235;&#36817;&#26080;&#38480;&#22823;&#65292;&#27492;&#26041;&#27861;&#36880;&#28176;&#28385;&#36275;&#26356;&#20005;&#26684;&#30340;&#24046;&#20998;&#38544;&#31169;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#36890;&#36807;&#24341;&#20837;&#38543;&#26426;&#24615;&#26469;&#20445;&#25252;&#20010;&#20154;&#20449;&#24687;&#65292;&#20294;&#22312;&#24212;&#29992;&#20013;&#65292;&#32479;&#35745;&#25512;&#26029;&#20173;&#28982;&#32570;&#20047;&#36890;&#29992;&#25216;&#26415;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#24046;&#20998;&#38544;&#31169;&#24341;&#23548;&#37319;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#21457;&#24067;&#22810;&#20010;&#31169;&#26377;&#24341;&#23548;&#37319;&#26679;&#20272;&#35745;&#26469;&#25512;&#26029;&#26679;&#26412;&#20998;&#24067;&#24182;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#12290;&#25105;&#20204;&#30340;&#38544;&#31169;&#20998;&#26512;&#25552;&#20379;&#20102;&#21333;&#20010;&#24046;&#20998;&#38544;&#31169;&#24341;&#23548;&#37319;&#26679;&#20272;&#35745;&#30340;&#38544;&#31169;&#25104;&#26412;&#26032;&#32467;&#26524;&#65292;&#36866;&#29992;&#20110;&#20219;&#20309;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#65292;&#24182;&#25351;&#20986;&#20102;&#29616;&#26377;&#25991;&#29486;&#20013;&#24341;&#23548;&#37319;&#26679;&#30340;&#19968;&#20123;&#35823;&#29992;&#12290;&#20351;&#29992;Gaussian-DP&#65288;GDP&#65289;&#26694;&#26550;&#65292;&#25105;&#20204;&#35777;&#26126;&#20174;&#28385;&#36275; $(\mu/\sqrt{(2-2/\mathrm{e})B})$-GDP &#30340;&#26426;&#21046;&#20013;&#37322;&#25918; $B$ &#20010;&#24046;&#20998;&#38544;&#31169;&#24341;&#23548;&#37319;&#26679;&#20272;&#35745;&#65292;&#22312; $B$ &#36235;&#36817;&#26080;&#38480;&#22823;&#26102;&#28176;&#36817;&#22320;&#28385;&#36275; $\mu$-GDP&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#24341;&#23548;&#37319;&#26679;&#20272;&#35745;&#30340;&#21453;&#21367;&#31215;&#23545;&#26679;&#26412;&#20998;&#24067;&#36827;&#34892;&#20934;&#30830;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differentially private (DP) mechanisms protect individual-level information by introducing randomness into the statistical analysis procedure. Despite the availability of numerous DP tools, there remains a lack of general techniques for conducting statistical inference under DP. We examine a DP bootstrap procedure that releases multiple private bootstrap estimates to infer the sampling distribution and construct confidence intervals (CIs). Our privacy analysis presents new results on the privacy cost of a single DP bootstrap estimate, applicable to any DP mechanisms, and identifies some misapplications of the bootstrap in the existing literature. Using the Gaussian-DP (GDP) framework (Dong et al.,2022), we show that the release of $B$ DP bootstrap estimates from mechanisms satisfying $(\mu/\sqrt{(2-2/\mathrm{e})B})$-GDP asymptotically satisfies $\mu$-GDP as $B$ goes to infinity. Moreover, we use deconvolution with the DP bootstrap estimates to accurately infer the sampling distribution
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#25968;&#39640;&#26031;&#36807;&#31243;&#30340;&#27010;&#29575;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#33258;&#20027;&#36816;&#34892;&#24182;&#25214;&#21040;&#20855;&#26377;&#20449;&#24687;&#30340;&#27979;&#37327;&#20301;&#32622;&#65292;&#25552;&#39640;&#20013;&#23376;&#35889;&#23398;&#23454;&#39564;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2209.00980</link><description>&lt;p&gt;
&#22522;&#20110;&#23545;&#25968;&#39640;&#26031;&#36807;&#31243;&#30340;&#20027;&#21160;&#23398;&#20064;&#36741;&#21161;&#20013;&#23376;&#35889;&#23398;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Active learning-assisted neutron spectroscopy with log-Gaussian processes. (arXiv:2209.00980v3 [physics.data-an] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.00980
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#25968;&#39640;&#26031;&#36807;&#31243;&#30340;&#27010;&#29575;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#33258;&#20027;&#36816;&#34892;&#24182;&#25214;&#21040;&#20855;&#26377;&#20449;&#24687;&#30340;&#27979;&#37327;&#20301;&#32622;&#65292;&#25552;&#39640;&#20013;&#23376;&#35889;&#23398;&#23454;&#39564;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19977;&#36724;&#35889;&#20202;&#20013;&#23376;&#25955;&#23556;&#23454;&#39564;&#36890;&#36807;&#27979;&#37327;&#24378;&#24230;&#20998;&#24067;&#26469;&#30740;&#31350;&#30913;&#24615;&#21644;&#26230;&#26684;&#28608;&#21457;&#65292;&#20197;&#20102;&#35299;&#26448;&#26009;&#29305;&#24615;&#30340;&#26469;&#28304;&#12290;&#30001;&#20110;&#23545;TAS&#23454;&#39564;&#30340;&#39640;&#38656;&#27714;&#21644;&#26377;&#38480;&#21487;&#29992;&#24615;&#65292;&#24341;&#20986;&#20102;&#19968;&#20010;&#33258;&#28982;&#30340;&#38382;&#39064;&#65292;&#21363;&#25105;&#20204;&#26159;&#21542;&#21487;&#20197;&#25552;&#39640;&#20854;&#25928;&#29575;&#65292;&#24182;&#26356;&#22909;&#22320;&#21033;&#29992;&#23454;&#39564;&#32773;&#30340;&#26102;&#38388;&#12290;&#23454;&#38469;&#19978;&#65292;&#26377;&#35768;&#22810;&#31185;&#23398;&#38382;&#39064;&#38656;&#35201;&#23547;&#25214;&#20449;&#21495;&#65292;&#22914;&#26524;&#22312;&#19981;&#20855;&#26377;&#20449;&#24687;&#30340;&#21306;&#22495;&#36827;&#34892;&#25163;&#21160;&#27979;&#37327;&#65292;&#21017;&#21487;&#33021;&#32791;&#26102;&#19988;&#25928;&#29575;&#20302;&#19979;&#12290;&#26412;&#25991;&#25551;&#36848;&#20102;&#19968;&#31181;&#27010;&#29575;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#19981;&#20165;&#21487;&#20197;&#33258;&#20027;&#36816;&#34892;&#65292;&#21363;&#26080;&#38656;&#20154;&#24037;&#24178;&#39044;&#65292;&#32780;&#19988;&#21487;&#20197;&#21033;&#29992;&#23545;&#25968;&#39640;&#26031;&#36807;&#31243;&#22312;&#25968;&#23398;&#19978;&#21644;&#26041;&#27861;&#19978;&#25552;&#20379;&#20855;&#26377;&#20449;&#24687;&#30340;&#27979;&#37327;&#20301;&#32622;&#12290;&#26368;&#32456;&#65292;&#36825;&#20123;&#25104;&#26524;&#21487;&#20197;&#22312;&#30495;&#23454;&#30340;TAS&#23454;&#39564;&#21644;&#22810;&#31181;&#19981;&#21516;&#22522;&#20934;&#27979;&#35797;&#20013;&#24471;&#21040;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neutron scattering experiments at three-axes spectrometers (TAS) investigate magnetic and lattice excitations by measuring intensity distributions to understand the origins of materials properties. The high demand and limited availability of beam time for TAS experiments however raise the natural question whether we can improve their efficiency and make better use of the experimenter's time. In fact, there are a number of scientific problems that require searching for signals, which may be time consuming and inefficient if done manually due to measurements in uninformative regions. Here, we describe a probabilistic active learning approach that not only runs autonomously, i.e., without human interference, but can also directly provide locations for informative measurements in a mathematically sound and methodologically robust way by exploiting log-Gaussian processes. Ultimately, the resulting benefits can be demonstrated on a real TAS experiment and a benchmark including numerous diffe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#26465;&#20214;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#20351;&#24471;&#36229;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#36895;&#24230;&#24674;&#22797;&#21040;&#32447;&#24615;&#65292;&#24182;&#22312;&#20445;&#35777;&#20840;&#23616;&#26368;&#20248;&#24615;&#35777;&#26126;&#26377;&#25928;&#30340;&#21516;&#26102;&#20445;&#25345;&#20302;&#24265;&#30340;&#35745;&#31639;&#20195;&#20215;&#65292;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#24378;&#20984;&#30340;&#20195;&#20215;&#20989;&#25968; $\phi$&#12290;</title><link>http://arxiv.org/abs/2206.03345</link><description>&lt;p&gt;
&#38024;&#23545;&#36229;&#21442;&#25968;&#21270;&#30340;&#38750;&#20984;Burer-Monteiro&#20998;&#35299;&#30340;&#39044;&#26465;&#20214;&#26799;&#24230;&#19979;&#38477;&#19982;&#20840;&#23616;&#26368;&#20248;&#24615;&#35777;&#26126;
&lt;/p&gt;
&lt;p&gt;
Preconditioned Gradient Descent for Overparameterized Nonconvex Burer--Monteiro Factorization with Global Optimality Certification. (arXiv:2206.03345v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.03345
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#26465;&#20214;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#20351;&#24471;&#36229;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#36895;&#24230;&#24674;&#22797;&#21040;&#32447;&#24615;&#65292;&#24182;&#22312;&#20445;&#35777;&#20840;&#23616;&#26368;&#20248;&#24615;&#35777;&#26126;&#26377;&#25928;&#30340;&#21516;&#26102;&#20445;&#25345;&#20302;&#24265;&#30340;&#35745;&#31639;&#20195;&#20215;&#65292;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#24378;&#20984;&#30340;&#20195;&#20215;&#20989;&#25968; $\phi$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#20248;&#21270;&#38750;&#20984;&#20989;&#25968;$f(X)=\phi(XX^{T})$&#30340;&#26041;&#27861;&#65292;&#20854;&#20013; $\phi$&#26159;&#19968;&#20010;&#24179;&#28369;&#20984;&#30340;$n\times n$&#30697;&#38453;&#19978;&#19979;&#25991;&#30340;&#20195;&#20215;&#20989;&#25968;&#12290;&#34429;&#28982;&#20165;&#26377;&#20108;&#38454;&#20572;&#30041;&#28857;&#21487;&#20197;&#22312;&#21512;&#29702;&#26102;&#38388;&#20869;&#34987;&#35777;&#26126;&#25214;&#21040;&#65292;&#20294;&#22914;&#26524; $X$ &#30340;&#31209;&#32570;&#22833;&#65292;&#37027;&#20040;&#23427;&#30340;&#31209;&#32570;&#22833;&#23558;&#35777;&#26126;&#23427;&#26159;&#20840;&#23616;&#26368;&#20248;&#30340;&#12290;&#36825;&#31181;&#35748;&#35777;&#20840;&#23616;&#26368;&#20248;&#24615;&#30340;&#26041;&#27861;&#24517;&#28982;&#38656;&#35201;&#24403;&#21069;&#36845;&#20195;$X$&#30340;&#25628;&#32034;&#31209; $r$ &#36229;&#36807;&#20840;&#23616;&#26368;&#23567;&#21270;&#22120;$X^{\star}$ &#30340;&#31209;$r^{\star}$&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36229;&#21442;&#25968;&#21270;&#26174;&#33879;&#20943;&#24930;&#20102;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#20174; $r=r^{\star}$ &#26102;&#30340;&#32447;&#24615;&#36895;&#24230;&#38477;&#20026; $r&gt;r^{\star}$ &#26102;&#30340;&#20122;&#32447;&#24615;&#36895;&#24230;&#65292;&#21363;&#20351; $\phi$ &#26159;&#24378;&#20984;&#30340;&#24773;&#20917;&#19979;&#20063;&#26159;&#22914;&#27492;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24265;&#20215;&#30340;&#39044;&#26465;&#20214;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#23558;&#36229;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#36895;&#24230;&#24674;&#22797;&#21040;&#32447;&#24615;&#65292;&#21516;&#26102;&#20445;&#35777;&#20840;&#23616;&#26368;&#20248;&#24615;&#35777;&#26126;&#20381;&#26087;&#26377;&#25928;&#12290;&#36825;&#31181;&#26041;&#27861;&#21482;&#38656;&#35201;&#36827;&#34892;&#31616;&#21333;&#30340;&#30697;&#38453;&#20056;&#27861;&#21644;&#27714;&#36870;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#24378;&#20984;&#30340;$&#966;$&#12290;&#25105;&#20204;&#36890;&#36807;&#20223;&#30495;&#23454;&#39564;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#29616;&#23454;&#24212;&#29992;&#20013;&#39564;&#35777;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider using gradient descent to minimize the nonconvex function $f(X)=\phi(XX^{T})$ over an $n\times r$ factor matrix $X$, in which $\phi$ is an underlying smooth convex cost function defined over $n\times n$ matrices. While only a second-order stationary point $X$ can be provably found in reasonable time, if $X$ is additionally rank deficient, then its rank deficiency certifies it as being globally optimal. This way of certifying global optimality necessarily requires the search rank $r$ of the current iterate $X$ to be overparameterized with respect to the rank $r^{\star}$ of the global minimizer $X^{\star}$. Unfortunately, overparameterization significantly slows down the convergence of gradient descent, from a linear rate with $r=r^{\star}$ to a sublinear rate when $r&gt;r^{\star}$, even when $\phi$ is strongly convex. In this paper, we propose an inexpensive preconditioner that restores the convergence rate of gradient descent back to linear in the overparameterized case, while
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#21253;&#21547;&#32452;&#21512;&#22797;&#21512;&#20307;&#36825;&#19968;&#26032;&#22411;&#25299;&#25169;&#22495;&#12290;&#32452;&#21512;&#22797;&#21512;&#20307;&#32467;&#21512;&#20102;&#36229;&#22270;&#21644;&#32990;&#33108;&#22797;&#21512;&#20307;&#30340;&#20248;&#28857;&#65292;&#20801;&#35768;&#26500;&#24314;&#20998;&#23618;&#39640;&#38454;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2206.00606</link><description>&lt;p&gt;
&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#65306;&#36229;&#36234;&#22270;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Topological Deep Learning: Going Beyond Graph Data. (arXiv:2206.00606v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.00606
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#21253;&#21547;&#32452;&#21512;&#22797;&#21512;&#20307;&#36825;&#19968;&#26032;&#22411;&#25299;&#25169;&#22495;&#12290;&#32452;&#21512;&#22797;&#21512;&#20307;&#32467;&#21512;&#20102;&#36229;&#22270;&#21644;&#32990;&#33108;&#22797;&#21512;&#20307;&#30340;&#20248;&#28857;&#65292;&#20801;&#35768;&#26500;&#24314;&#20998;&#23618;&#39640;&#38454;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#26159;&#19968;&#20010;&#24555;&#36895;&#21457;&#23637;&#30340;&#39046;&#22495;&#65292;&#19982;&#24320;&#21457;&#25903;&#25345;&#20110;&#25299;&#25169;&#22495;&#19978;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26377;&#20851;&#65292;&#20363;&#22914;&#21333;&#32431;&#22797;&#21512;&#20307;&#12289;&#32990;&#33108;&#22797;&#21512;&#20307;&#21644;&#36229;&#22270;&#12290;&#36825;&#20123;&#25299;&#25169;&#22495;&#22312;&#31185;&#23398;&#35745;&#31639;&#20013;&#24191;&#27867;&#24212;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#24314;&#31435;&#22312;&#26356;&#20016;&#23500;&#25968;&#25454;&#32467;&#26500;&#20043;&#19978;&#30340;&#32479;&#19968;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#21253;&#25324;&#25299;&#25169;&#22495;&#12290;&#25105;&#20204;&#39318;&#20808;&#20171;&#32461;&#32452;&#21512;&#22797;&#21512;&#20307;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#22411;&#30340;&#25299;&#25169;&#22495;&#12290;&#32452;&#21512;&#22797;&#21512;&#20307;&#21487;&#20197;&#30475;&#20316;&#26159;&#20445;&#25345;&#26576;&#20123;&#29702;&#24819;&#24615;&#36136;&#30340;&#22270;&#30340;&#25512;&#24191;&#12290;&#31867;&#20284;&#20110;&#36229;&#22270;&#65292;&#32452;&#21512;&#22797;&#21512;&#20307;&#23545;&#20851;&#31995;&#38598;&#21512;&#19981;&#26045;&#21152;&#20219;&#20309;&#32422;&#26463;&#12290;&#27492;&#22806;&#65292;&#32452;&#21512;&#22797;&#21512;&#20307;&#20801;&#35768;&#26500;&#24314;&#20998;&#23618;&#39640;&#38454;&#20851;&#31995;&#65292;&#31867;&#20284;&#20110;&#21333;&#32431;&#21644;&#32990;&#33108;&#22797;&#21512;&#20307;&#20013;&#30340;&#20851;&#31995;&#12290;&#22240;&#27492;&#65292;&#32452;&#21512;&#22797;&#21512;&#20307;&#25512;&#24191;&#24182;&#32467;&#21512;&#20102;&#36229;&#22270;&#21644;&#32990;&#33108;&#22797;&#21512;&#20307;&#30340;&#26377;&#29992;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Topological deep learning is a rapidly growing field that pertains to the development of deep learning models for data supported on topological domains such as simplicial complexes, cell complexes, and hypergraphs, which generalize many domains encountered in scientific computations. In this paper, we present a unifying deep learning framework built upon a richer data structure that includes widely adopted topological domains.  Specifically, we first introduce combinatorial complexes, a novel type of topological domain. Combinatorial complexes can be seen as generalizations of graphs that maintain certain desirable properties. Similar to hypergraphs, combinatorial complexes impose no constraints on the set of relations. In addition, combinatorial complexes permit the construction of hierarchical higher-order relations, analogous to those found in simplicial and cell complexes. Thus, combinatorial complexes generalize and combine useful traits of both hypergraphs and cell complexes, whi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Wasserstein&#26799;&#24230;&#27969;&#30340;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#39640;&#26031;&#25110;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#24182;&#22312;&#22788;&#29702;&#23545;&#25968;&#20985; $\pi$ &#26102;&#20855;&#26377;&#24378;&#22823;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2205.15902</link><description>&lt;p&gt;
&#22522;&#20110;Wasserstein&#26799;&#24230;&#27969;&#30340;&#21464;&#20998;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Variational inference via Wasserstein gradient flows. (arXiv:2205.15902v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.15902
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Wasserstein&#26799;&#24230;&#27969;&#30340;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#39640;&#26031;&#25110;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#24182;&#22312;&#22788;&#29702;&#23545;&#25968;&#20985; $\pi$ &#26102;&#20855;&#26377;&#24378;&#22823;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931; (MCMC) &#26041;&#27861;&#19968;&#36215;&#65292;&#21464;&#20998;&#25512;&#26029;&#65288;VI&#65289;&#24050;&#32463;&#25104;&#20026;&#22823;&#35268;&#27169;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#20013;&#24515;&#35745;&#31639;&#26041;&#27861;&#12290;VI &#19981;&#26159;&#20174;&#30495;&#23454;&#21518;&#39564; $\pi$ &#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#32780;&#26159;&#26088;&#22312;&#29983;&#25104;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#36817;&#20284; $\hat \pi$&#65292;&#20351;&#24471;&#25688;&#35201;&#32479;&#35745;&#37327;&#26131;&#20110;&#35745;&#31639;&#12290;&#28982;&#32780;&#65292;&#19982;&#24191;&#20026;&#30740;&#31350;&#30340; MCMC &#26041;&#27861;&#19981;&#21516;&#65292;VI &#30340;&#31639;&#27861;&#20445;&#35777;&#20173;&#28982;&#30456;&#23545;&#36739;&#23569;&#34987;&#29702;&#35299;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#39640;&#26031;&#25110;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#30340;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#22522;&#20110;&#39640;&#26031;&#27979;&#24230;&#30340;Bures-Wasserstein &#31354;&#38388;&#19978;&#30340;&#26799;&#24230;&#27969;&#29702;&#35770;&#12290;&#24403; $\pi$ &#26159;&#23545;&#25968;&#20985;&#30340;&#26102;&#20505;&#65292;&#19982;MCMC&#31867;&#20284;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#24378;&#22823;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Along with Markov chain Monte Carlo (MCMC) methods, variational inference (VI) has emerged as a central computational approach to large-scale Bayesian inference. Rather than sampling from the true posterior $\pi$, VI aims at producing a simple but effective approximation $\hat \pi$ to $\pi$ for which summary statistics are easy to compute. However, unlike the well-studied MCMC methodology, algorithmic guarantees for VI are still relatively less well-understood. In this work, we propose principled methods for VI, in which $\hat \pi$ is taken to be a Gaussian or a mixture of Gaussians, which rest upon the theory of gradient flows on the Bures--Wasserstein space of Gaussian measures. Akin to MCMC, it comes with strong theoretical guarantees when $\pi$ is log-concave.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#39044;&#20808;&#35757;&#32451;&#30340;&#24863;&#30693;&#29305;&#24449;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;MMD&#65288;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65289;&#26469;&#25552;&#39640;&#24046;&#20998;&#38544;&#31169;&#22270;&#20687;&#29983;&#25104;&#30340;&#24615;&#33021;&#65292;&#24182;&#25104;&#21151;&#22320;&#29983;&#25104;&#20102;CIFAR10&#32423;&#21035;&#30340;&#22270;&#20687;&#12290;</title><link>http://arxiv.org/abs/2205.12900</link><description>&lt;p&gt;
&#39044;&#20808;&#35757;&#32451;&#30340;&#24863;&#30693;&#29305;&#24449;&#25552;&#39640;&#24046;&#20998;&#38544;&#31169;&#22270;&#20687;&#29983;&#25104;&#30340;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Pre-trained Perceptual Features Improve Differentially Private Image Generation. (arXiv:2205.12900v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.12900
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#39044;&#20808;&#35757;&#32451;&#30340;&#24863;&#30693;&#29305;&#24449;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;MMD&#65288;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65289;&#26469;&#25552;&#39640;&#24046;&#20998;&#38544;&#31169;&#22270;&#20687;&#29983;&#25104;&#30340;&#24615;&#33021;&#65292;&#24182;&#25104;&#21151;&#22320;&#29983;&#25104;&#20102;CIFAR10&#32423;&#21035;&#30340;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;DP-SGD&#65289;&#36827;&#34892;&#20013;&#31561;&#35268;&#27169;&#29983;&#25104;&#27169;&#22411;&#30340;&#35757;&#32451;&#38750;&#24120;&#22256;&#38590;&#65306;&#20026;&#20102;&#20445;&#25345;&#21512;&#29702;&#30340;&#38544;&#31169;&#27700;&#24179;&#25152;&#38656;&#30340;&#22122;&#22768;&#27700;&#24179;&#36807;&#22823;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#24314;&#35758;&#21033;&#29992;&#20449;&#24687;&#20016;&#23500;&#30340;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#30340;&#33391;&#22909;&#30456;&#20851;&#34920;&#24449;&#65292;&#28982;&#21518;&#23398;&#20064;&#20351;&#29992;&#35813;&#34920;&#24449;&#27169;&#22411;&#21270;&#31169;&#26377;&#25968;&#25454;&#12290;&#29305;&#21035;&#30340;&#65292;&#25105;&#20204;&#20351;&#29992;&#20174;&#20844;&#20849;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#30340;&#24863;&#30693;&#29305;&#24449;&#30340;&#26680;&#20989;&#25968;&#65292;&#26368;&#23567;&#21270;&#31169;&#26377;&#30446;&#26631;&#25968;&#25454;&#19982;&#29983;&#25104;&#22120;&#20998;&#24067;&#20043;&#38388;&#30340;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65288;MMD&#65289;&#12290;&#20351;&#29992;MMD&#65292;&#25105;&#20204;&#21487;&#20197;&#19968;&#27425;&#24615;&#23545;&#25968;&#25454;&#30456;&#20851;&#39033;&#36827;&#34892;&#38544;&#31169;&#22788;&#29702;&#65292;&#32780;&#26080;&#38656;&#20687;DP-SGD&#19968;&#26679;&#22312;&#20248;&#21270;&#27599;&#19968;&#27493;&#20013;&#24341;&#20837;&#22122;&#22768;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20351;&#25105;&#20204;&#33021;&#22815;&#29983;&#25104;CIFAR10&#32423;&#21035;&#30340;&#22270;&#20687;&#65292;&#20854; $\epsilon \approx 2$&#65292;&#25429;&#25417;&#20102;&#20998;&#24067;&#20013;&#30340;&#29420;&#29305;&#29305;&#24449;&#65292;&#36828;&#36828;&#36229;&#36807;&#24403;&#21069;&#30340;&#25216;&#26415;&#27700;&#24179;&#65292;&#20027;&#35201;&#38598;&#20013;&#20110;&#25968;&#25454;&#38598;&#65292;&#22914;MNIST&#21644;FashionMNIST &#20197;&#36739;&#22823;&#30340; $\epsilon$&#12290;
&lt;/p&gt;
&lt;p&gt;
Training even moderately-sized generative models with differentially-private stochastic gradient descent (DP-SGD) is difficult: the required level of noise for reasonable levels of privacy is simply too large. We advocate instead building off a good, relevant representation on an informative public dataset, then learning to model the private data with that representation. In particular, we minimize the maximum mean discrepancy (MMD) between private target data and a generator's distribution, using a kernel based on perceptual features learned from a public dataset. With the MMD, we can simply privatize the data-dependent term once and for all, rather than introducing noise at each step of optimization as in DP-SGD. Our algorithm allows us to generate CIFAR10-level images with $\epsilon \approx 2$ which capture distinctive features in the distribution, far surpassing the current state of the art, which mostly focuses on datasets such as MNIST and FashionMNIST at a large $\epsilon \appro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#22238;&#24402;&#25237;&#24433;&#26041;&#27861;&#23398;&#20064;Mori-Zwanzig&#31639;&#23376;&#30340;&#25968;&#25454;&#39537;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#20855;&#26377;&#28789;&#27963;&#24615;&#24378;&#12289;&#24212;&#29992;&#33539;&#22260;&#24191;&#31561;&#20248;&#28857;&#12290;</title><link>http://arxiv.org/abs/2205.05135</link><description>&lt;p&gt;
&#22522;&#20110;&#22238;&#24402;&#30340;&#25237;&#24433;&#26041;&#27861;&#23398;&#20064;Mori-Zwanzig&#31639;&#23376;
&lt;/p&gt;
&lt;p&gt;
Regression-based projection for learning Mori-Zwanzig operators. (arXiv:2205.05135v3 [math.DS] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.05135
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#22238;&#24402;&#25237;&#24433;&#26041;&#27861;&#23398;&#20064;Mori-Zwanzig&#31639;&#23376;&#30340;&#25968;&#25454;&#39537;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#20855;&#26377;&#28789;&#27963;&#24615;&#24378;&#12289;&#24212;&#29992;&#33539;&#22260;&#24191;&#31561;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#37319;&#29992;&#32479;&#35745;&#22238;&#24402;&#20316;&#20026;&#25237;&#24433;&#31639;&#23376;&#65292;&#20197;&#23454;&#29616;Mori-Zwanzig&#24418;&#24335;&#20013;&#31639;&#23376;&#30340;&#25968;&#25454;&#39537;&#21160;&#23398;&#20064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25552;&#21462;&#20219;&#20309;&#22238;&#24402;&#27169;&#22411;&#30340;&#39532;&#23572;&#21487;&#22827;&#21644;&#35760;&#24518;&#31639;&#23376;&#30340;&#21407;&#21017;&#24615;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#32447;&#24615;&#22238;&#24402;&#30340;&#36873;&#25321;&#23548;&#33268;&#19968;&#31181;&#22522;&#20110;Mori&#25237;&#24433;&#31639;&#23376;&#30340;&#39640;&#38454;&#36817;&#20284;Koopman&#23398;&#20064;&#26041;&#27861;&#30340;&#26368;&#36817;&#25552;&#20986;&#30340;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#23398;&#20064;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26356;&#26377;&#34920;&#29616;&#21147;&#30340;&#38750;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#33258;&#28982;&#22320;&#22635;&#34917;&#20102;&#39640;&#24230;&#29702;&#24819;&#21270;&#21644;&#35745;&#31639;&#19978;&#39640;&#25928;&#30340;Mori&#25237;&#24433;&#31639;&#23376;&#19982;&#26368;&#20248;&#20294;&#35745;&#31639;&#19981;&#21487;&#34892;&#30340;Zwanzig&#25237;&#24433;&#31639;&#23376;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#25968;&#20540;&#23454;&#39564;&#24182;&#25552;&#21462;&#20102;&#19968;&#31995;&#21015;&#22522;&#20110;&#22238;&#24402;&#30340;&#25237;&#24433;&#31639;&#23376;&#30340;&#31639;&#23376;&#65292;&#21253;&#25324;&#32447;&#24615;&#12289;&#22810;&#39033;&#24335;&#12289;&#26679;&#26465;&#21644;&#31070;&#32463;&#32593;&#32476;&#22238;&#24402;&#65292;&#26174;&#31034;&#38543;&#30528;&#22238;&#24402;&#27169;&#22411;&#22797;&#26434;&#24230;&#30340;&#25552;&#39640;&#36880;&#28176;&#25913;&#36827;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#29992;&#20110;&#21160;&#21147;&#31995;&#32479;&#21644;&#32479;&#35745;&#29289;&#29702;&#23398;&#20013;Mori-Zwanzig&#31639;&#23376;&#30340;&#25968;&#25454;&#39537;&#21160;&#23398;&#20064;&#65292;&#24182;&#33021;&#24212;&#29992;&#20110;&#24191;&#27867;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose to adopt statistical regression as the projection operator to enable data-driven learning of the operators in the Mori--Zwanzig formalism. We present a principled method to extract the Markov and memory operators for any regression models. We show that the choice of linear regression results in a recently proposed data-driven learning algorithm based on Mori's projection operator, which is a higher-order approximate Koopman learning method. We show that more expressive nonlinear regression models naturally fill in the gap between the highly idealized and computationally efficient Mori's projection operator and the most optimal yet computationally infeasible Zwanzig's projection operator. We performed numerical experiments and extracted the operators for an array of regression-based projections, including linear, polynomial, spline, and neural-network-based regressions, showing a progressive improvement as the complexity of the regression model increased. Our proposition prov
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#39046;&#22495;&#22270;&#23545;&#39046;&#22495;&#30456;&#37051;&#24615;&#36827;&#34892;&#32534;&#30721;&#65292;&#25918;&#23485;&#20102;&#39046;&#22495;&#36866;&#24212;&#30340;&#32479;&#19968;&#23545;&#40784;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#38750;&#24179;&#20961;&#30340;&#23545;&#40784;&#65292;&#24182;&#25104;&#21151;&#22320;&#34701;&#21512;&#20102;&#39046;&#22495;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2202.03628</link><description>&lt;p&gt;
&#22270;&#20851;&#31995;&#39046;&#22495;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
Graph-Relational Domain Adaptation. (arXiv:2202.03628v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.03628
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#39046;&#22495;&#22270;&#23545;&#39046;&#22495;&#30456;&#37051;&#24615;&#36827;&#34892;&#32534;&#30721;&#65292;&#25918;&#23485;&#20102;&#39046;&#22495;&#36866;&#24212;&#30340;&#32479;&#19968;&#23545;&#40784;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#38750;&#24179;&#20961;&#30340;&#23545;&#40784;&#65292;&#24182;&#25104;&#21151;&#22320;&#34701;&#21512;&#20102;&#39046;&#22495;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#39046;&#22495;&#36866;&#24212;&#26041;&#27861;&#24448;&#24448;&#23558;&#27599;&#20010;&#39046;&#22495;&#31561;&#21516;&#23545;&#24453;&#24182;&#23436;&#32654;&#23545;&#40784;&#65292;&#24573;&#30053;&#20102;&#19981;&#21516;&#39046;&#22495;&#20043;&#38388;&#30340;&#25299;&#25169;&#32467;&#26500;&#65292;&#22240;&#27492;&#23545;&#20110;&#30456;&#37051;&#39046;&#22495;&#21487;&#33021;&#26377;&#21033;&#65292;&#20294;&#23545;&#20110;&#36828;&#31163;&#39046;&#22495;&#21017;&#21487;&#33021;&#26080;&#30410;&#12290;&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#39046;&#22495;&#22270;&#23545;&#39046;&#22495;&#30456;&#37051;&#24615;&#36827;&#34892;&#32534;&#30721;&#65292;&#20363;&#22914;&#20197;&#32654;&#22269;&#19981;&#21516;&#24030;&#20026;&#39046;&#22495;&#21019;&#24314;&#30340;&#29366;&#24577;&#22270;&#65292;&#20351;&#24471;&#39046;&#22495;&#21487;&#20197;&#26681;&#25454;&#22270;&#32467;&#26500;&#28789;&#27963;&#23545;&#40784;&#65292;&#20174;&#32780;&#25918;&#23485;&#20102;&#36825;&#31181;&#32479;&#19968;&#30340;&#23545;&#40784;&#26041;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#31181;&#26032;&#30340;&#22270;&#21028;&#21035;&#22120;&#23558;&#29616;&#26377;&#30340;&#23545;&#25239;&#23398;&#20064;&#26694;&#26550;&#36827;&#34892;&#20102;&#25512;&#24191;&#65292;&#24182;&#20351;&#29992;&#32534;&#30721;&#26465;&#20214;&#22270;&#23884;&#20837;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#22312;&#22343;&#34913;&#29366;&#24577;&#19979;&#65292;&#24403;&#22270;&#26159;&#19968;&#20010;&#22242;&#26102;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20250;&#24674;&#22797;&#32463;&#20856;&#30340;&#39046;&#22495;&#36866;&#24212;&#26041;&#27861;&#65292;&#24182;&#20026;&#20854;&#20182;&#31867;&#22411;&#30340;&#22270;&#23454;&#29616;&#20102;&#38750;&#24179;&#20961;&#30340;&#23545;&#40784;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#25104;&#21151;&#22320;&#25512;&#24191;&#32479;&#19968;&#30340;&#23545;&#40784;&#26041;&#27861;&#65292;&#24182;&#33258;&#28982;&#22320;&#34701;&#21512;&#20102;&#39046;&#22495;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing domain adaptation methods tend to treat every domain equally and align them all perfectly. Such uniform alignment ignores topological structures among different domains; therefore it may be beneficial for nearby domains, but not necessarily for distant domains. In this work, we relax such uniform alignment by using a domain graph to encode domain adjacency, e.g., a graph of states in the US with each state as a domain and each edge indicating adjacency, thereby allowing domains to align flexibly based on the graph structure. We generalize the existing adversarial learning framework with a novel graph discriminator using encoding-conditioned graph embeddings. Theoretical analysis shows that at equilibrium, our method recovers classic domain adaptation when the graph is a clique, and achieves non-trivial alignment for other types of graphs. Empirical results show that our approach successfully generalizes uniform alignment, naturally incorporates domain information represented b
&lt;/p&gt;</description></item><item><title>&#35813;&#31639;&#27861;&#22522;&#20110;&#24179;&#28369;&#30340;&#21487;&#20998;&#31163;&#24615;&#20551;&#35774;&#65292;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#24179;&#28369;&#21487;&#20998;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#65288;SSNMF&#65289;&#31639;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#25269;&#25239;&#22312;&#8216;&#32431;&#20687;&#32032;&#20551;&#35774;&#8217;&#23384;&#22312;&#30340;&#22122;&#22768;&#24178;&#25200;</title><link>http://arxiv.org/abs/2110.05528</link><description>&lt;p&gt;
&#24179;&#28369;&#21487;&#20998;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
Smoothed Separable Nonnegative Matrix Factorization. (arXiv:2110.05528v2 [eess.SP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.05528
&lt;/p&gt;
&lt;p&gt;
&#35813;&#31639;&#27861;&#22522;&#20110;&#24179;&#28369;&#30340;&#21487;&#20998;&#31163;&#24615;&#20551;&#35774;&#65292;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#24179;&#28369;&#21487;&#20998;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#65288;SSNMF&#65289;&#31639;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#25269;&#25239;&#22312;&#8216;&#32431;&#20687;&#32032;&#20551;&#35774;&#8217;&#23384;&#22312;&#30340;&#22122;&#22768;&#24178;&#25200;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;--&#24179;&#28369;&#21487;&#20998;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#65288;SSNMF&#65289;&#65292;&#35813;&#31639;&#27861;&#22522;&#20110;&#19968;&#20010;&#32463;&#36807;&#24179;&#28369;&#30340;&#21487;&#20998;&#31163;&#24615;&#20551;&#35774;&#65292;&#34987;&#21046;&#23450;&#20026;&#19968;&#20010;&#20984;&#20248;&#21270;&#38382;&#39064;&#26469;&#25269;&#25239;&#22312;&#8216;&#32431;&#20687;&#32032;&#20551;&#35774;&#8217;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#22122;&#22768;&#30340;&#24178;&#25200;&#12290;&#35813;&#31639;&#27861;&#30340;&#26377;&#25928;&#23454;&#26045;&#21644;&#24191;&#27867;&#23454;&#39564;&#34920;&#26126;&#65292;&#23427;&#21487;&#20197;&#20445;&#35777;&#22312;&#29305;&#23450;&#22122;&#22768;&#27700;&#24179;&#20869;&#25910;&#25947;&#21040;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#65292;&#19988;&#24471;&#20986;&#30495;&#23454;&#39030;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given a set of data points belonging to the convex hull of a set of vertices, a key problem in linear algebra, signal processing, data analysis and machine learning is to estimate these vertices in the presence of noise. Many algorithms have been developed under the assumption that there is at least one nearby data point to each vertex; two of the most widely used ones are vertex component analysis (VCA) and the successive projection algorithm (SPA). This assumption is known as the pure-pixel assumption in blind hyperspectral unmixing, and as the separability assumption in nonnegative matrix factorization. More recently, Bhattacharyya and Kannan (ACM-SIAM Symposium on Discrete Algorithms, 2020) proposed an algorithm for learning a latent simplex (ALLS) that relies on the assumption that there is more than one nearby data point to each vertex. In that scenario, ALLS is probalistically more robust to noise than algorithms based on the separability assumption. In this paper, inspired by A
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#27748;&#26222;&#26862;&#25277;&#26679;&#30340;&#39057;&#29575;&#21518;&#24724;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#21518;&#39564;&#26041;&#24046;&#33192;&#32960;&#26159;&#24517;&#38656;&#30340;&#65292;&#24182;&#30830;&#23450;&#20102;&#39057;&#29575;&#21518;&#24724;&#30340;&#26368;&#20302;&#19979;&#38480;&#20026;$\widetilde{\mathcal{O}}(d\sqrt{dT})$ &#12290;</title><link>http://arxiv.org/abs/2006.06790</link><description>&lt;p&gt;
&#20851;&#20110;&#32447;&#24615;&#27748;&#26222;&#26862;&#25277;&#26679;&#30340;&#39057;&#29575;&#21518;&#24724;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
On Frequentist Regret of Linear Thompson Sampling. (arXiv:2006.06790v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.06790
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#27748;&#26222;&#26862;&#25277;&#26679;&#30340;&#39057;&#29575;&#21518;&#24724;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#21518;&#39564;&#26041;&#24046;&#33192;&#32960;&#26159;&#24517;&#38656;&#30340;&#65292;&#24182;&#30830;&#23450;&#20102;&#39057;&#29575;&#21518;&#24724;&#30340;&#26368;&#20302;&#19979;&#38480;&#20026;$\widetilde{\mathcal{O}}(d\sqrt{dT})$ &#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#38543;&#26426;&#32447;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#20854;&#20013;&#20915;&#31574;&#32773;&#20174;&#21487;&#33021;&#26102;&#21464;&#30340;$\mathbb{R}^d$&#21521;&#37327;&#38598;&#20013;&#36873;&#25321;&#34892;&#21160;&#24182;&#33719;&#24471;&#22122;&#22768;&#22870;&#21169;&#12290;&#30446;&#26631;&#26159;&#22312;&#19968;&#31995;&#21015;$T$&#20010;&#20915;&#31574;&#20013;&#26368;&#23567;&#21270;&#21518;&#24724;&#65292;&#21363;&#20915;&#31574;&#32773;&#30340;&#32047;&#31215;&#39044;&#26399;&#22870;&#21169;&#19982;&#33021;&#22815;&#35775;&#38382;&#27599;&#20010;&#34892;&#21160;&#39044;&#26399;&#22870;&#21169;&#30340;&#31070;&#35861;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#32447;&#24615;&#27748;&#26222;&#26862;&#25277;&#26679;(LinTS)&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#36125;&#21494;&#26031;&#21551;&#21457;&#24335;&#31639;&#27861;&#65292;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#20854;&#36125;&#21494;&#26031;&#21518;&#24724;&#21463;&#21040;$\widetilde{\mathcal{O}}(d\sqrt{T})$&#30340;&#30028;&#38480;&#32422;&#26463;&#65292;&#36798;&#21040;&#26497;&#23567;&#20540;&#19979;&#38480;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;LinTS&#30340;&#39057;&#29575;&#21518;&#24724;&#30028;&#38480;&#20026;$\widetilde{\mathcal{O}}(d\sqrt{dT})$&#65292;&#38656;&#35201;&#21518;&#39564;&#26041;&#24046;&#33192;&#32960;&#65292;&#24182;&#19988;&#27604;&#26368;&#20339;&#22522;&#20110;&#20048;&#35266;&#20027;&#20041;&#30340;&#31639;&#27861;&#24046;&#19968;&#20010;$\sqrt{d}$&#30340;&#22240;&#23376;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#33192;&#32960;&#26159;&#22522;&#26412;&#30340;&#65292;&#24182;&#19988;&#39057;&#29575;&#30028;&#38480;&#20026;$\widetilde{\mathcal{O}}(d\sqrt{dT})$&#26159;&#26368;&#20339;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the stochastic linear bandit problem, where a decision-maker chooses actions from possibly time-dependent sets of vectors in $\mathbb{R}^d$ and receives noisy rewards. The objective is to minimize regret, the difference between the cumulative expected reward of the decision-maker and that of an oracle with access to the expected reward of each action, over a sequence of $T$ decisions. Linear Thompson Sampling (LinTS) is a popular Bayesian heuristic, supported by theoretical analysis that shows its Bayesian regret is bounded by $\widetilde{\mathcal{O}}(d\sqrt{T})$, matching minimax lower bounds. However, previous studies demonstrate that the frequentist regret bound for LinTS is $\widetilde{\mathcal{O}}(d\sqrt{dT})$, which requires posterior variance inflation and is by a factor of $\sqrt{d}$ worse than the best optimism-based algorithms. We prove that this inflation is fundamental and that the frequentist bound of $\widetilde{\mathcal{O}}(d\sqrt{dT})$ is the best pos
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#29275;&#39039;&#31579;&#36873;&#27861;&#30340;&#26032;&#22411;Broad-Newton&#26041;&#27861;&#65292;&#23427;&#24102;&#26377;&#19968;&#20010;&#20869;&#32622;&#30340;&#36739;&#23567;&#30340;&#24037;&#20316;&#38598;&#65292;&#21487;&#29992;&#20110;&#21152;&#36895;&#35299;&#20915;&#22823;&#35268;&#27169;&#31232;&#30095;&#23398;&#20064;&#38382;&#39064;&#30340;&#19968;&#38454;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2001.10616</link><description>&lt;p&gt;
&#35770;&#29275;&#39039;&#31579;&#36873;&#27861;
&lt;/p&gt;
&lt;p&gt;
On Newton Screening. (arXiv:2001.10616v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2001.10616
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#29275;&#39039;&#31579;&#36873;&#27861;&#30340;&#26032;&#22411;Broad-Newton&#26041;&#27861;&#65292;&#23427;&#24102;&#26377;&#19968;&#20010;&#20869;&#32622;&#30340;&#36739;&#23567;&#30340;&#24037;&#20316;&#38598;&#65292;&#21487;&#29992;&#20110;&#21152;&#36895;&#35299;&#20915;&#22823;&#35268;&#27169;&#31232;&#30095;&#23398;&#20064;&#38382;&#39064;&#30340;&#19968;&#38454;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31579;&#36873;&#21644;&#24037;&#20316;&#38598;&#25216;&#26415;&#26159;&#20943;&#23567;&#20248;&#21270;&#38382;&#39064;&#35268;&#27169;&#30340;&#37325;&#35201;&#26041;&#27861;&#65292;&#24050;&#24191;&#27867;&#24212;&#29992;&#20110;&#21152;&#36895;&#35299;&#20915;&#22823;&#35268;&#27169;&#31232;&#30095;&#23398;&#20064;&#38382;&#39064;&#30340;&#19968;&#38454;&#26041;&#27861;&#20013;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31579;&#36873;&#26041;&#27861;&#65292;&#31216;&#20026;&#29275;&#39039;&#31579;&#36873;&#27861;&#65288;NS&#65289;&#65292;&#23427;&#26159;&#19968;&#31181;&#24102;&#26377;&#20869;&#32622;&#31579;&#36873;&#26426;&#21046;&#30340;&#24191;&#20041;&#29275;&#39039;&#26041;&#27861;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#22522;&#20110;&#31561;&#25928;KKT&#31995;&#32479;&#30340;Lasso&#27169;&#22411;&#65292;&#21033;&#29992;&#24191;&#20041;&#29275;&#39039;&#26041;&#27861;&#26469;&#27714;&#35299;KKT&#26041;&#31243;&#32452;&#12290;&#22522;&#20110;&#36825;&#20010;KKT&#31995;&#32479;&#65292;&#39318;&#20808;&#21033;&#29992;&#19978;&#19968;&#27425;&#36845;&#20195;&#29983;&#25104;&#30340;&#21407;&#22987;&#21644;&#23545;&#20598;&#21464;&#37327;&#20043;&#21644;&#30830;&#23450;&#19968;&#20010;&#20855;&#26377;&#30456;&#23545;&#36739;&#23567;&#22823;&#23567;&#30340;&#20869;&#32622;&#24037;&#20316;&#38598;&#65292;&#28982;&#21518;&#36890;&#36807;&#22312;&#24037;&#20316;&#38598;&#19978;&#27714;&#35299;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;&#26469;&#26356;&#26032;&#21407;&#22987;&#21464;&#37327;&#65292;&#24182;&#22522;&#20110;&#38381;&#24335;&#34920;&#36798;&#24335;&#26356;&#26032;&#23545;&#20598;&#21464;&#37327;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#24102;&#26377;&#28909;&#21551;&#21160;&#31574;&#30053;&#30340;&#29275;&#39039;&#31579;&#36873;&#27861;&#30340;&#36830;&#32493;&#29256;&#26412;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;NS&#22312;&#26368;&#20248;&#25910;&#25947;&#24615;&#26041;&#38754;&#20855;&#26377;&#20248;&#24322;&#30340;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Screening and working set techniques are important approaches to reducing the size of an optimization problem. They have been widely used in accelerating first-order methods for solving large-scale sparse learning problems. In this paper, we develop a new screening method called Newton screening (NS) which is a generalized Newton method with a built-in screening mechanism. We derive an equivalent KKT system for the Lasso and utilize a generalized Newton method to solve the KKT equations. Based on this KKT system, a built-in working set with a relatively small size is first determined using the sum of primal and dual variables generated from the previous iteration, then the primal variable is updated by solving a least-squares problem on the working set and the dual variable updated based on a closed-form expression. Moreover, we consider a sequential version of Newton screening (SNS) with a warm-start strategy. We show that NS possesses an optimal convergence property in the sense that
&lt;/p&gt;</description></item></channel></rss>