<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;Sharp-SSL&#31639;&#27861;&#65292;&#36890;&#36807;&#23545;&#35768;&#22810;&#36724;&#23545;&#40784;&#38543;&#26426;&#25237;&#24433;&#30340;&#20302;&#32500;&#36807;&#31243;&#32467;&#26524;&#30340;&#31934;&#24515;&#27719;&#38598;&#65292;&#33021;&#22815;&#39640;&#27010;&#29575;&#24674;&#22797;&#20449;&#21495;&#22352;&#26631;&#12290;</title><link>http://arxiv.org/abs/2304.09154</link><description>&lt;p&gt;
Sharp-SSL&#65306;&#22522;&#20110;&#36873;&#25321;&#24615;&#39640;&#32500;&#36724;&#23545;&#40784;&#38543;&#26426;&#25237;&#24433;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Sharp-SSL: Selective high-dimensional axis-aligned random projections for semi-supervised learning. (arXiv:2304.09154v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09154
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;Sharp-SSL&#31639;&#27861;&#65292;&#36890;&#36807;&#23545;&#35768;&#22810;&#36724;&#23545;&#40784;&#38543;&#26426;&#25237;&#24433;&#30340;&#20302;&#32500;&#36807;&#31243;&#32467;&#26524;&#30340;&#31934;&#24515;&#27719;&#38598;&#65292;&#33021;&#22815;&#39640;&#27010;&#29575;&#24674;&#22797;&#20449;&#21495;&#22352;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#32500;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#22522;&#20110;&#23545;&#35768;&#22810;&#36724;&#23545;&#40784;&#38543;&#26426;&#25237;&#24433;&#30340;&#20302;&#32500;&#36807;&#31243;&#32467;&#26524;&#30340;&#31934;&#24515;&#27719;&#38598;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#30830;&#23450;&#29992;&#20110;&#21306;&#20998;&#31867;&#21035;&#30340;&#37325;&#35201;&#21464;&#37327;&#65307;&#28982;&#21518;&#21487;&#20197;&#24212;&#29992;&#29616;&#26377;&#30340;&#20302;&#32500;&#26041;&#27861;&#36827;&#34892;&#26368;&#32456;&#30340;&#31867;&#21035;&#20998;&#37197;&#12290;&#21463;&#24191;&#20041;&#29790;&#21033;&#21830;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#26681;&#25454;&#20272;&#35745;&#30333;&#21270;&#21518;&#30340;&#31867;&#38388;&#21327;&#26041;&#24046;&#30697;&#38453;&#22312;&#25237;&#24433;&#25968;&#25454;&#19978;&#30340;&#30165;&#36857;&#23545;&#25237;&#24433;&#36827;&#34892;&#35780;&#20998;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#20026;&#32473;&#23450;&#25237;&#24433;&#20998;&#37197;&#27599;&#20010;&#21464;&#37327;&#30340;&#37325;&#35201;&#24615;&#26435;&#37325;&#65292;&#24182;&#36890;&#36807;&#32858;&#21512;&#36825;&#20123;&#26435;&#37325;&#26469;&#36873;&#25321;&#20449;&#21495;&#21464;&#37327;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#34920;&#26126;&#65292;&#24403;&#25105;&#20204;&#32858;&#21512;&#36275;&#22815;&#22810;&#30340;&#38543;&#26426;&#25237;&#24433;&#21644;&#22522;&#30784;&#36807;&#31243;&#20272;&#35745;&#30333;&#21270;&#21518;&#30340;&#31867;&#38388;&#21327;&#26041;&#24046;&#26102;&#65292;&#25152;&#24471;&#21040;&#30340;Sharp-SSL&#31639;&#27861;&#33021;&#22815;&#20197;&#39640;&#27010;&#29575;&#24674;&#22797;&#20449;&#21495;&#22352;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new method for high-dimensional semi-supervised learning problems based on the careful aggregation of the results of a low-dimensional procedure applied to many axis-aligned random projections of the data. Our primary goal is to identify important variables for distinguishing between the classes; existing low-dimensional methods can then be applied for final class assignment. Motivated by a generalized Rayleigh quotient, we score projections according to the traces of the estimated whitened between-class covariance matrices on the projected data. This enables us to assign an importance weight to each variable for a given projection, and to select our signal variables by aggregating these weights over high-scoring projections. Our theory shows that the resulting Sharp-SSL algorithm is able to recover the signal coordinates with high probability when we aggregate over sufficiently many random projections and when the base procedure estimates the whitened between-class covari
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#26377;&#38480;&#26102;&#38388;&#30028;&#38480;&#65292;&#29992;&#20110;&#34987;&#21160;&#38543;&#26426;&#26799;&#24230; Langevin &#21160;&#21147;&#23398;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21487;&#29992;&#20110;&#36870;&#24378;&#21270;&#23398;&#20064;&#12290;&#35813;&#31639;&#27861;&#20805;&#24403;&#38543;&#26426;&#37319;&#26679;&#22120;&#65292;&#24674;&#22797;&#29992;&#22806;&#37096;&#36807;&#31243;&#20248;&#21270;&#32780;&#26469;&#30340;&#25104;&#26412;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2304.09123</link><description>&lt;p&gt;
&#20351;&#29992;&#34987;&#21160; Langevin &#21160;&#21147;&#23398;&#30340;&#33258;&#36866;&#24212;&#36870;&#24378;&#21270;&#23398;&#20064;&#30340;&#26377;&#38480;&#26679;&#26412;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Finite-Sample Bounds for Adaptive Inverse Reinforcement Learning using Passive Langevin Dynamics. (arXiv:2304.09123v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09123
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#26377;&#38480;&#26102;&#38388;&#30028;&#38480;&#65292;&#29992;&#20110;&#34987;&#21160;&#38543;&#26426;&#26799;&#24230; Langevin &#21160;&#21147;&#23398;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21487;&#29992;&#20110;&#36870;&#24378;&#21270;&#23398;&#20064;&#12290;&#35813;&#31639;&#27861;&#20805;&#24403;&#38543;&#26426;&#37319;&#26679;&#22120;&#65292;&#24674;&#22797;&#29992;&#22806;&#37096;&#36807;&#31243;&#20248;&#21270;&#32780;&#26469;&#30340;&#25104;&#26412;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230; Langevin &#21160;&#21147;&#23398; (SGLD) &#26159;&#20174;&#27010;&#29575;&#20998;&#24067;&#37319;&#26679;&#30340;&#26377;&#29992;&#26041;&#27861;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#34987;&#21160;&#38543;&#26426;&#26799;&#24230; Langevin &#21160;&#21147;&#23398;&#31639;&#27861; (PSGLD) &#30340;&#26377;&#38480;&#26679;&#26412;&#20998;&#26512;&#65292;&#26088;&#22312;&#23454;&#29616;&#36870;&#24378;&#21270;&#23398;&#20064;&#12290;&#27492;&#22788;&#30340;&#8220;&#34987;&#21160;&#8221;&#26159;&#25351; PSGLD &#31639;&#27861;(&#36870;&#23398;&#20064;&#36807;&#31243;)&#21487;&#29992;&#30340;&#22122;&#22768;&#28176;&#21464;&#26159;&#30001;&#22806;&#37096;&#38543;&#26426;&#26799;&#24230;&#31639;&#27861;(&#27491;&#21521;&#23398;&#20064;&#22120;)&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#28857;&#19978;&#35780;&#20272;&#30340;&#12290;PSGLD &#31639;&#27861;&#22240;&#27492;&#20805;&#24403;&#19968;&#20010;&#38543;&#26426;&#37319;&#26679;&#22120;&#65292;&#21487;&#24674;&#22797;&#27491;&#22312;&#34987;&#27492;&#22806;&#37096;&#36807;&#31243;&#20248;&#21270;&#30340;&#25104;&#26412;&#20989;&#25968;&#12290;&#20197;&#21069;&#30340;&#24037;&#20316;&#20351;&#29992;&#38543;&#26426;&#36924;&#36817;&#25216;&#26415;&#20998;&#26512;&#20102;&#36825;&#20010;&#34987;&#21160;&#31639;&#27861;&#30340;&#28176;&#36817;&#24615;&#33021;&#65307;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#23427;&#30340;&#26377;&#38480;&#26102;&#38388;&#24615;&#33021;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#22312;&#34987;&#21160;&#31639;&#27861;&#21644;&#20854;&#31283;&#23450;&#27979;&#24230;&#20043;&#38388;&#30340; 2-Wasserstein &#36317;&#31163;&#19978;&#30340;&#26377;&#38480;&#26102;&#38388;&#30028;&#38480;&#65292;&#20174;&#20013;&#21487;&#20197;&#33719;&#24471;&#37325;&#24314;&#30340;&#25104;&#26412;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic gradient Langevin dynamics (SGLD) are a useful methodology for sampling from probability distributions. This paper provides a finite sample analysis of a passive stochastic gradient Langevin dynamics algorithm (PSGLD) designed to achieve inverse reinforcement learning. By "passive", we mean that the noisy gradients available to the PSGLD algorithm (inverse learning process) are evaluated at randomly chosen points by an external stochastic gradient algorithm (forward learner). The PSGLD algorithm thus acts as a randomized sampler which recovers the cost function being optimized by this external process. Previous work has analyzed the asymptotic performance of this passive algorithm using stochastic approximation techniques; in this work we analyze the non-asymptotic performance. Specifically, we provide finite-time bounds on the 2-Wasserstein distance between the passive algorithm and its stationary measure, from which the reconstructed cost function is obtained.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24046;&#20998;&#38544;&#31169;&#26694;&#26550;&#21644;&#30697;&#38453;&#20998;&#35299;&#30340;&#20445;&#25252;&#38544;&#31169;&#25512;&#33616;&#31995;&#32479;&#65292;&#37319;&#29992;&#36755;&#20986;&#25200;&#21160;&#30340;&#39640;&#26031;&#26426;&#21046;&#23454;&#29616;&#24046;&#20998;&#38544;&#31169;&#65292;&#36890;&#36807;R&#233;nyi&#24046;&#20998;&#38544;&#31169;&#23545;&#25972;&#20307;&#38544;&#31169;&#25439;&#22833;&#36827;&#34892;&#29305;&#24449;&#21270;&#65292;&#22312;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#25512;&#33616;&#31995;&#32479;&#21151;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.09096</link><description>&lt;p&gt;
&#22522;&#20110;&#39640;&#26031;&#26426;&#21046;&#30340;&#20445;&#25252;&#38544;&#31169;&#30697;&#38453;&#20998;&#35299;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Privacy-Preserving Matrix Factorization for Recommendation Systems using Gaussian Mechanism. (arXiv:2304.09096v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09096
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24046;&#20998;&#38544;&#31169;&#26694;&#26550;&#21644;&#30697;&#38453;&#20998;&#35299;&#30340;&#20445;&#25252;&#38544;&#31169;&#25512;&#33616;&#31995;&#32479;&#65292;&#37319;&#29992;&#36755;&#20986;&#25200;&#21160;&#30340;&#39640;&#26031;&#26426;&#21046;&#23454;&#29616;&#24046;&#20998;&#38544;&#31169;&#65292;&#36890;&#36807;R&#233;nyi&#24046;&#20998;&#38544;&#31169;&#23545;&#25972;&#20307;&#38544;&#31169;&#25439;&#22833;&#36827;&#34892;&#29305;&#24449;&#21270;&#65292;&#22312;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#25512;&#33616;&#31995;&#32479;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24314;&#31435;&#25512;&#33616;&#31995;&#32479;&#38656;&#35201;&#20998;&#26512;&#29992;&#25143;&#25968;&#25454;&#65292;&#36825;&#21487;&#33021;&#20250;&#27844;&#38706;&#29992;&#25143;&#30340;&#20010;&#20154;&#20449;&#24687;&#12290;&#21311;&#21517;&#21270;&#29992;&#25143;&#25968;&#25454;&#36890;&#24120;&#19981;&#36275;&#20197;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#12290;&#37492;&#20110;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24046;&#20998;&#38544;&#31169;&#26694;&#26550;&#21644;&#30697;&#38453;&#20998;&#35299;&#30340;&#20445;&#25252;&#38544;&#31169;&#25512;&#33616;&#31995;&#32479;&#65292;&#30697;&#38453;&#20998;&#35299;&#26159;&#26368;&#27969;&#34892;&#30340;&#25512;&#33616;&#31995;&#32479;&#31639;&#27861;&#20043;&#19968;&#12290;&#36890;&#36807;&#24046;&#20998;&#38544;&#31169;&#65292;&#21363;&#20351;&#23545;&#25163;&#25317;&#26377;&#29992;&#25143;&#30340;&#20844;&#24320;&#20449;&#24687;&#65292;&#20063;&#21487;&#20197;&#38450;&#27490;&#23545;&#25163;&#25552;&#21462;&#25935;&#24863;&#29992;&#25143;&#20449;&#24687;&#12290;&#25105;&#20204;&#37319;&#29992;&#36755;&#20986;&#25200;&#21160;&#30340;&#39640;&#26031;&#26426;&#21046;&#23454;&#29616;&#24046;&#20998;&#38544;&#31169;&#24182;&#21457;&#24067;&#28385;&#36275;&#38544;&#31169;&#23450;&#20041;&#30340;&#29992;&#25143;&#26723;&#26696;&#12290;&#25105;&#20204;&#20351;&#29992;R&#233;nyi&#24046;&#20998;&#38544;&#31169;&#23545;&#25972;&#20307;&#38544;&#31169;&#25439;&#22833;&#36827;&#34892;&#20102;&#32039;&#23494;&#30340;&#29305;&#24449;&#21270;&#12290;&#25105;&#20204;&#22312;&#23454;&#39564;&#20013;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
Building a recommendation system involves analyzing user data, which can potentially leak sensitive information about users. Anonymizing user data is often not sufficient for preserving user privacy. Motivated by this, we propose a privacy-preserving recommendation system based on the differential privacy framework and matrix factorization, which is one of the most popular algorithms for recommendation systems. As differential privacy is a powerful and robust mathematical framework for designing privacy-preserving machine learning algorithms, it is possible to prevent adversaries from extracting sensitive user information even if the adversary possesses their publicly available (auxiliary) information. We implement differential privacy via the Gaussian mechanism in the form of output perturbation and release user profiles that satisfy privacy definitions. We employ R\'enyi Differential Privacy for a tight characterization of the overall privacy loss. We perform extensive experiments on
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#20351;&#29992;&#36125;&#21494;&#26031;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26469;&#36924;&#36817;&#21518;&#39564;&#20998;&#24067;&#30340;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#35813;&#26041;&#27861;&#19982;&#36125;&#21494;&#26031;&#35745;&#31639;&#30456;&#20851;&#30340;&#26032;&#32852;&#31995;&#12290;</title><link>http://arxiv.org/abs/2304.09053</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#29992;&#20110;&#21518;&#39564;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Bayes Hilbert Spaces for Posterior Approximation. (arXiv:2304.09053v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09053
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#20351;&#29992;&#36125;&#21494;&#26031;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26469;&#36924;&#36817;&#21518;&#39564;&#20998;&#24067;&#30340;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#35813;&#26041;&#27861;&#19982;&#36125;&#21494;&#26031;&#35745;&#31639;&#30456;&#20851;&#30340;&#26032;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36125;&#21494;&#26031;&#27169;&#22411;&#20013;&#36827;&#34892;&#25512;&#29702;&#38656;&#35201;&#37319;&#26679;&#31639;&#27861;&#20174;&#21518;&#39564;&#20013;&#25277;&#21462;&#26679;&#26412;&#12290;&#38543;&#30528;&#25968;&#25454;&#38598;&#30340;&#22686;&#22823;&#65292;&#36825;&#21464;&#24471;&#38750;&#24120;&#26114;&#36149;&#12290;&#26500;&#24314;&#20415;&#23452;&#26131;&#20110;&#35780;&#20272;&#30340;&#21518;&#39564;&#36924;&#36817;&#26159;&#35268;&#36991;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#31181;&#27969;&#34892;&#26041;&#27861;&#12290;&#36825;&#24341;&#20986;&#19968;&#20010;&#38382;&#39064;&#65306;&#20160;&#20040;&#26679;&#30340;&#31354;&#38388;&#36866;&#21512;&#29992;&#20110;&#36924;&#36817;&#36125;&#21494;&#26031;&#21518;&#39564;&#24230;&#37327;&#65311;&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#36125;&#21494;&#26031;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#24212;&#29992;&#20110;&#21518;&#39564;&#36924;&#36817;&#38382;&#39064;&#12290;&#36125;&#21494;&#26031;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#22312;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#20013;&#24471;&#21040;&#20102;&#30740;&#31350;&#65292;&#20854;&#20013;&#35266;&#27979;&#21040;&#30340;&#20989;&#25968;&#26159;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#65292;&#23427;&#20204;&#22312;&#35745;&#31639;&#36125;&#21494;&#26031;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#36824;&#22788;&#20110;&#21021;&#32423;&#38454;&#27573;&#12290;&#26412;&#25991;&#27010;&#36848;&#20102;&#36125;&#21494;&#26031;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#21450;&#20854;&#19982;&#36125;&#21494;&#26031;&#35745;&#31639;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#29305;&#21035;&#26159;&#36125;&#21494;&#26031;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#12289;&#36125;&#21494;&#26031;&#26680;&#24515;&#38598;&#31639;&#27861;&#21644;&#22522;&#20110;&#26680;&#30340;&#36317;&#31163;&#20043;&#38388;&#30340;&#26032;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Performing inference in Bayesian models requires sampling algorithms to draw samples from the posterior. This becomes prohibitively expensive as the size of data sets increase. Constructing approximations to the posterior which are cheap to evaluate is a popular approach to circumvent this issue. This begs the question of what is an appropriate space to perform approximation of Bayesian posterior measures. This manuscript studies the application of Bayes Hilbert spaces to the posterior approximation problem. Bayes Hilbert spaces are studied in functional data analysis in the context where observed functions are probability density functions and their application to computational Bayesian problems is in its infancy. This manuscript shall outline Bayes Hilbert spaces and their connection to Bayesian computation, in particular novel connections between Bayes Hilbert spaces, Bayesian coreset algorithms and kernel-based distances.
&lt;/p&gt;</description></item><item><title>&#27492;&#30740;&#31350;&#26088;&#22312;&#22312;&#26356;&#20026;&#30495;&#23454;&#30340;&#29615;&#22659;&#20013;&#35299;&#30721;&#20154;&#31867;&#31070;&#32463;&#27963;&#21160;&#27169;&#24335;&#65292;&#20197;&#36827;&#19968;&#27493;&#29702;&#35299;&#22797;&#26434;&#20219;&#21153;&#26399;&#38388;&#20010;&#20307;&#20869;&#37096;&#28508;&#22312;&#29366;&#24577;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#39564;&#35777;&#23454;&#39564;&#23460;&#26041;&#27861;&#24182;&#25552;&#20379;&#26377;&#24847;&#20041;&#30340;&#27934;&#23519;&#12290;</title><link>http://arxiv.org/abs/2304.09050</link><description>&lt;p&gt;
&#35299;&#30721;&#31070;&#32463;&#27963;&#21160;&#20197;&#35780;&#20272;&#20010;&#20307;&#22312;&#29983;&#24577;&#26377;&#25928;&#29615;&#22659;&#20013;&#30340;&#28508;&#22312;&#29366;&#24577;
&lt;/p&gt;
&lt;p&gt;
Decoding Neural Activity to Assess Individual Latent State in Ecologically Valid Contexts. (arXiv:2304.09050v1 [q-bio.NC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09050
&lt;/p&gt;
&lt;p&gt;
&#27492;&#30740;&#31350;&#26088;&#22312;&#22312;&#26356;&#20026;&#30495;&#23454;&#30340;&#29615;&#22659;&#20013;&#35299;&#30721;&#20154;&#31867;&#31070;&#32463;&#27963;&#21160;&#27169;&#24335;&#65292;&#20197;&#36827;&#19968;&#27493;&#29702;&#35299;&#22797;&#26434;&#20219;&#21153;&#26399;&#38388;&#20010;&#20307;&#20869;&#37096;&#28508;&#22312;&#29366;&#24577;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#39564;&#35777;&#23454;&#39564;&#23460;&#26041;&#27861;&#24182;&#25552;&#20379;&#26377;&#24847;&#20041;&#30340;&#27934;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21382;&#21490;&#19978;&#65292;&#20165;&#26377;&#23569;&#37327;&#26041;&#27861;&#21487;&#20197;&#22312;&#26356;&#29983;&#24577;&#26377;&#25928;&#30340;&#24773;&#22659;&#19979;&#20998;&#31163;&#35748;&#30693;&#36807;&#31243;&#12290;&#29305;&#21035;&#22320;&#65292;&#30446;&#21069;&#23578;&#19981;&#28165;&#26970;&#22312;&#27492;&#31867;&#32422;&#26463;&#26465;&#20214;&#19979;&#35266;&#23519;&#21040;&#30340;&#31070;&#32463;&#27963;&#21160;&#27169;&#24335;&#23454;&#38469;&#19978;&#26159;&#21542;&#20197;&#19968;&#31181;&#21487;&#20197;&#29992;&#20110;&#20934;&#30830;&#25512;&#26029;&#20010;&#20307;&#28508;&#22312;&#29366;&#24577;&#12289;&#30456;&#20851;&#35748;&#30693;&#36807;&#31243;&#25110;&#36817;&#31471;&#34892;&#20026;&#30340;&#26041;&#24335;&#22312;&#23454;&#39564;&#23460;&#22806;&#26174;&#29616;&#12290;&#25913;&#21892;&#25105;&#20204;&#23545;&#29305;&#23450;&#31070;&#32463;&#27963;&#21160;&#27169;&#24335;&#20309;&#26102;&#20197;&#21450;&#22914;&#20309;&#22312;&#29983;&#24577;&#26377;&#25928;&#24773;&#22659;&#20013;&#26174;&#29616;&#30340;&#29702;&#35299;&#65292;&#20250;&#39564;&#35777;&#22312;&#38548;&#31163;&#29615;&#22659;&#19979;&#30740;&#31350;&#31867;&#20284;&#31070;&#32463;&#29616;&#35937;&#30340;&#23454;&#39564;&#23460;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20851;&#20110;&#22797;&#26434;&#20219;&#21153;&#26399;&#38388;&#21457;&#29983;&#30340;&#28508;&#22312;&#29366;&#24577;&#30340;&#26377;&#24847;&#20041;&#27934;&#23519;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#26469;&#33258;&#33041;-&#35745;&#31639;&#26426;&#30028;&#38754;&#31038;&#21306;&#30340;&#39046;&#22495;&#36890;&#29992;&#26041;&#27861;&#26377;&#28508;&#21147;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#12290;&#25105;&#20204;&#20197;&#21069;&#20351;&#29992;&#20102;&#36825;&#26679;&#30340;&#26041;&#27861;&#26469;&#35299;&#30721;&#19982;&#35270;&#35273;&#30446;&#26631;&#30456;&#20851;&#30340;&#31361;&#21457;&#31070;&#32463;&#21453;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
There exist very few ways to isolate cognitive processes, historically defined via highly controlled laboratory studies, in more ecologically valid contexts. Specifically, it remains unclear as to what extent patterns of neural activity observed under such constraints actually manifest outside the laboratory in a manner that can be used to make an accurate inference about the latent state, associated cognitive process, or proximal behavior of the individual. Improving our understanding of when and how specific patterns of neural activity manifest in ecologically valid scenarios would provide validation for laboratory-based approaches that study similar neural phenomena in isolation and meaningful insight into the latent states that occur during complex tasks. We argue that domain generalization methods from the brain-computer interface community have the potential to address this challenge. We previously used such an approach to decode phasic neural responses associated with visual tar
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20302;&#31209;&#24352;&#37327;&#20998;&#35299;&#12289;Radon&#21464;&#25442;&#21644;&#23383;&#20856;&#20272;&#31639;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;1-D&#36793;&#38469;&#36827;&#34892;&#37325;&#24314;&#33719;&#24471;&#20102;&#26356;&#22909;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#20110;&#20197;&#21069;&#30340;&#22522;&#20110;&#23383;&#20856;&#30340;&#26041;&#27861;&#21644;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65288;GMM&#65289;&#12290;</title><link>http://arxiv.org/abs/2304.08740</link><description>&lt;p&gt;
&#29992;&#20302;&#31209;&#24352;&#37327;&#20998;&#35299;&#12289;Radon&#21464;&#25442;&#21644;&#23383;&#20856;&#20272;&#31639;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Estimating Joint Probability Distribution With Low-Rank Tensor Decomposition, Radon Transforms and Dictionaries. (arXiv:2304.08740v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08740
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20302;&#31209;&#24352;&#37327;&#20998;&#35299;&#12289;Radon&#21464;&#25442;&#21644;&#23383;&#20856;&#20272;&#31639;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;1-D&#36793;&#38469;&#36827;&#34892;&#37325;&#24314;&#33719;&#24471;&#20102;&#26356;&#22909;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#20110;&#20197;&#21069;&#30340;&#22522;&#20110;&#23383;&#20856;&#30340;&#26041;&#27861;&#21644;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65288;GMM&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#25968;&#25454;&#26679;&#26412;&#20013;&#32852;&#21512;&#27010;&#29575;&#23494;&#24230;&#30340;&#26041;&#27861;&#65292;&#20551;&#35774;&#24213;&#23618;&#20998;&#24067;&#33021;&#22815;&#20998;&#35299;&#20026;&#20960;&#20010;&#28151;&#21512;&#32452;&#20998;&#30340;&#20056;&#31215;&#23494;&#24230;&#12290;&#25105;&#20204;&#32467;&#21512;&#20102;&#20004;&#20010;&#20851;&#38190;&#24819;&#27861;&#65306;&#29992;&#20110;&#34920;&#31034;1-D&#23494;&#24230;&#30340;&#23383;&#20856;&#20197;&#21450;&#29992;&#20110;&#20272;&#31639;1-D&#36793;&#38469;&#30340;&#38543;&#26426;&#25237;&#24433;&#65292;&#25506;&#32034;&#20102;&#20808;&#21069;&#30340;&#26041;&#27861;&#12290;&#30456;&#27604;&#22522;&#20110;&#23383;&#20856;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#36890;&#36807;&#20351;&#29992;1-D&#36793;&#38469;&#36827;&#34892;&#37325;&#24314;&#32780;&#33719;&#24471;&#20102;&#26356;&#22909;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#22312;&#20272;&#31639;&#21512;&#25104;&#27010;&#29575;&#23494;&#24230;&#26041;&#38754;&#35780;&#20272;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#24182;&#23558;&#20854;&#19982;&#20197;&#21069;&#30340;&#22522;&#20110;&#23383;&#20856;&#30340;&#26041;&#27861;&#21644;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65288;GMM&#65289;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#22312;&#25152;&#26377;&#23454;&#39564;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#34920;&#29616;&#20248;&#20110;&#36825;&#20123;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we describe a method for estimating the joint probability density from data samples by assuming that the underlying distribution can be decomposed as a mixture of product densities with few mixture components. Prior works have used such a decomposition to estimate the joint density from lower-dimensional marginals, which can be estimated more reliably with the same number of samples. We combine two key ideas: dictionaries to represent 1-D densities, and random projections to estimate the joint distribution from 1-D marginals, explored separately in prior work. Our algorithm benefits from improved sample complexity over the previous dictionary-based approach by using 1-D marginals for reconstruction. We evaluate the performance of our method on estimating synthetic probability densities and compare it with the previous dictionary-based approach and Gaussian Mixture Models (GMMs). Our algorithm outperforms these other approaches in all the experimental settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35299;&#31572;&#20102;&#38271;&#26399;&#23384;&#22312;&#30340;&#38382;&#39064;&#65306;&#27809;&#26377;&#19968;&#31181;&#21442;&#25968;&#21487;&#20197;&#21051;&#30011;&#20998;&#24067;&#31867;&#30340;PAC&#21487;&#23398;&#20064;&#24615;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#19981;&#23384;&#22312;&#19968;&#31181;&#21051;&#30011;&#21487;&#23398;&#20064;&#24615;&#30340;&#24615;&#36136;&#26469;&#28385;&#36275;&#20998;&#24067;&#31867;&#20197;&#21450;&#20854;&#20182;&#23398;&#20064;&#38382;&#39064;&#30340;&#35201;&#27714;&#12290;</title><link>http://arxiv.org/abs/2304.08712</link><description>&lt;p&gt;
&#19981;&#21487;&#33021;&#21051;&#30011;&#20998;&#24067;&#23398;&#20064;--&#19968;&#20010;&#38271;&#26399;&#38382;&#39064;&#30340;&#31616;&#21333;&#35299;&#20915;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Impossibility of Characterizing Distribution Learning -- a simple solution to a long-standing problem. (arXiv:2304.08712v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08712
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#31572;&#20102;&#38271;&#26399;&#23384;&#22312;&#30340;&#38382;&#39064;&#65306;&#27809;&#26377;&#19968;&#31181;&#21442;&#25968;&#21487;&#20197;&#21051;&#30011;&#20998;&#24067;&#31867;&#30340;PAC&#21487;&#23398;&#20064;&#24615;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#19981;&#23384;&#22312;&#19968;&#31181;&#21051;&#30011;&#21487;&#23398;&#20064;&#24615;&#30340;&#24615;&#36136;&#26469;&#28385;&#36275;&#20998;&#24067;&#31867;&#20197;&#21450;&#20854;&#20182;&#23398;&#20064;&#38382;&#39064;&#30340;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#38271;&#26399;&#20197;&#26469;&#23384;&#22312;&#30340;&#19968;&#20010;&#38382;&#39064;&#65306;&#23547;&#25214;&#19968;&#31867;&#27010;&#29575;&#20998;&#24067;&#30340;&#21442;&#25968;&#65292;&#20197;&#21051;&#30011;&#23427;&#30340;PAC&#21487;&#23398;&#20064;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#30456;&#24403;&#20196;&#20154;&#24778;&#35766;&#30340;&#31572;&#26696;&#8212;&#8212;&#27809;&#26377;&#36825;&#26679;&#30340;&#21442;&#25968;&#23384;&#22312;&#12290;&#25105;&#20204;&#30340;&#25216;&#26415;&#20351;&#25105;&#20204;&#33021;&#22815;&#23637;&#31034;&#31867;&#20284;&#32467;&#26524;&#30340;&#20960;&#20010;&#27010;&#24565;&#65292;&#20197;&#21450;&#20960;&#20010;&#23398;&#20064;&#20219;&#21153;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#27809;&#26377;&#20219;&#20309;&#32500;&#24230;&#21487;&#20197;&#21051;&#30011;&#23398;&#20064;&#20998;&#24067;&#31867;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#21482;&#21051;&#30011;&#21487;&#23398;&#20064;&#24615;&#65288;&#32780;&#19981;&#26159;&#37327;&#21270;&#26679;&#26412;&#22797;&#26434;&#24230;&#20989;&#25968;&#65289;&#30340;&#36739;&#24369;&#35201;&#27714;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20123;&#33258;&#28982;&#30340;&#35201;&#27714;&#65292;&#20197;&#20415;&#23545;&#36825;&#26679;&#19968;&#20010;&#21051;&#30011;&#36827;&#34892;&#26356;&#22909;&#30340;&#29702;&#35299;&#65292;&#24182;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#19981;&#23384;&#22312;&#19968;&#31181;&#21051;&#30011;&#24615;&#36136;&#65292;&#20197;&#28385;&#36275;&#36825;&#20123;&#35201;&#27714;&#65292;&#23545;&#20110;&#20998;&#24067;&#31867;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#21508;&#31181;&#20854;&#20182;&#23398;&#20064;&#38382;&#39064;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#27809;&#26377;&#20219;&#20309;&#32500;&#24230;&#21487;&#20197;&#21051;&#30011;&#65288;&#25110;&#21051;&#30011;&#21487;&#23398;&#20064;&#24615;&#65289;&#30340;&#27010;&#24565;&#65292;&#36866;&#29992;&#20110;...
&lt;/p&gt;
&lt;p&gt;
We consider the long-standing question of finding a parameter of a class of probability distributions that characterizes its PAC learnability. We provide a rather surprising answer - no such parameter exists. Our techniques allow us to show similar results for several general notions of characterizing learnability and for several learning tasks. We show that there is no notion of dimension that characterizes the sample complexity of learning distribution classes. We then consider the weaker requirement of only characterizing learnability (rather than the quantitative sample complexity function). We propose some natural requirements for such a characterization and go on to show that there exists no characterization of learnability that satisfies these requirements for classes of distributions. Furthermore, we show that our results hold for various other learning problems. In particular, we show that there is no notion of dimension characterizing (or characterization of learnability) for
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#39062;&#30340;&#21322;&#30417;&#30563;&#25512;&#36827;&#26144;&#23556;&#23398;&#20064;&#31639;&#27861;&#65292;&#21033;&#29992;&#24402;&#19968;&#21270;&#27969;&#26469;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#20013;&#23384;&#22312;&#30340;&#24212;&#29992;&#31354;&#38388;&#12289;&#26679;&#26412;&#22806;&#25968;&#25454;&#28857;&#21487;&#24212;&#29992;&#24615;&#12289;&#23545;&#20004;&#20010;&#31354;&#38388;&#30340;&#27010;&#29575;&#27169;&#22411;&#36827;&#34892;&#24314;&#27169;&#31561;&#38382;&#39064;&#65292;&#21487;&#24212;&#29992;&#20110;&#22270;&#20687;&#21040;&#22270;&#20687;&#21644;&#25991;&#26412;&#21040;&#25991;&#26412;&#36716;&#25442;&#20197;&#21450;&#20998;&#31867;&#27169;&#22411;&#30340;&#39046;&#22495;&#33258;&#36866;&#24212;&#12290;</title><link>http://arxiv.org/abs/2304.08673</link><description>&lt;p&gt;
&#38754;&#21521;&#39046;&#22495;&#36716;&#25442;&#21644;&#33258;&#36866;&#24212;&#30340;&#25512;&#36827;&#23398;&#20064;&#21322;&#30417;&#30563;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Semi-supervised Learning of Pushforwards For Domain Translation &amp; Adaptation. (arXiv:2304.08673v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08673
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#39062;&#30340;&#21322;&#30417;&#30563;&#25512;&#36827;&#26144;&#23556;&#23398;&#20064;&#31639;&#27861;&#65292;&#21033;&#29992;&#24402;&#19968;&#21270;&#27969;&#26469;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#20013;&#23384;&#22312;&#30340;&#24212;&#29992;&#31354;&#38388;&#12289;&#26679;&#26412;&#22806;&#25968;&#25454;&#28857;&#21487;&#24212;&#29992;&#24615;&#12289;&#23545;&#20004;&#20010;&#31354;&#38388;&#30340;&#27010;&#29575;&#27169;&#22411;&#36827;&#34892;&#24314;&#27169;&#31561;&#38382;&#39064;&#65292;&#21487;&#24212;&#29992;&#20110;&#22270;&#20687;&#21040;&#22270;&#20687;&#21644;&#25991;&#26412;&#21040;&#25991;&#26412;&#36716;&#25442;&#20197;&#21450;&#20998;&#31867;&#27169;&#22411;&#30340;&#39046;&#22495;&#33258;&#36866;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#24402;&#19968;&#21270;&#27969;&#26469;&#21442;&#25968;&#21270;&#26144;&#23556;&#30340;&#26032;&#39062;&#25512;&#36827;&#26144;&#23556;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#27010;&#29575;&#36317;&#31163;&#21644;&#24212;&#29992;&#29305;&#23450;&#30340;&#27491;&#21017;&#21270;&#39033;&#26469;&#36873;&#25321;&#25152;&#26377;&#21487;&#33021;&#26144;&#23556;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#23384;&#22312;&#30340;&#24191;&#27867;&#24212;&#29992;&#31354;&#38388;&#12289;&#22312;&#26679;&#26412;&#22806;&#25968;&#25454;&#28857;&#19978;&#20855;&#26377;&#21487;&#24212;&#29992;&#24615;&#12289;&#23545;&#20004;&#20010;&#31354;&#38388;&#30340;&#27010;&#29575;&#27169;&#22411;&#36827;&#34892;&#24314;&#27169;&#31561;&#38382;&#39064;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#26041;&#38754;&#20855;&#26377;&#26126;&#26174;&#30340;&#20248;&#21183;&#65292;&#21487;&#24212;&#29992;&#20110;&#22270;&#20687;&#21040;&#22270;&#20687;&#21644;&#25991;&#26412;&#21040;&#25991;&#26412;&#36716;&#25442;&#20197;&#21450;&#20998;&#31867;&#27169;&#22411;&#30340;&#39046;&#22495;&#33258;&#36866;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given two probability densities on related data spaces, we seek a map pushing one density to the other while satisfying application-dependent constraints. For maps to have utility in a broad application space (including domain translation, domain adaptation, and generative modeling), the map must be available to apply on out-of-sample data points and should correspond to a probabilistic model over the two spaces. Unfortunately, existing approaches, which are primarily based on optimal transport, do not address these needs. In this paper, we introduce a novel pushforward map learning algorithm that utilizes normalizing flows to parameterize the map. We first re-formulate the classical optimal transport problem to be map-focused and propose a learning algorithm to select from all possible maps under the constraint that the map minimizes a probability distance and application-specific regularizers; thus, our method can be seen as solving a modified optimal transport problem. Once the map 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#20998;&#24067;&#24335;SGD&#31639;&#27861;&#26041;&#26696;&#65292;&#36890;&#36807;&#36866;&#24212;&#31639;&#27861;&#30340;&#36816;&#34892;&#26102;&#38388;&#20869;&#30340;&#24037;&#20316;&#33410;&#28857;&#25968;&#37327;&#21644;&#35745;&#31639;&#36127;&#36733;&#65292;&#20248;&#21270;&#25910;&#25947;&#36895;&#24230;&#21516;&#26102;&#38477;&#20302;&#35745;&#31639;&#36127;&#36733;&#12290;</title><link>http://arxiv.org/abs/2304.08589</link><description>&lt;p&gt;
&#24555;&#36895;&#24182;&#23481;&#38169;&#30340;&#20998;&#24067;&#24335;SGD&#31639;&#27861;&#65292;&#38477;&#20302;&#35745;&#31639;&#36127;&#36733;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fast and Straggler-Tolerant Distributed SGD with Reduced Computation Load. (arXiv:2304.08589v1 [cs.DC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08589
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#20998;&#24067;&#24335;SGD&#31639;&#27861;&#26041;&#26696;&#65292;&#36890;&#36807;&#36866;&#24212;&#31639;&#27861;&#30340;&#36816;&#34892;&#26102;&#38388;&#20869;&#30340;&#24037;&#20316;&#33410;&#28857;&#25968;&#37327;&#21644;&#35745;&#31639;&#36127;&#36733;&#65292;&#20248;&#21270;&#25910;&#25947;&#36895;&#24230;&#21516;&#26102;&#38477;&#20302;&#35745;&#31639;&#36127;&#36733;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20998;&#24067;&#24335;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#19968;&#20010;&#20013;&#24515;&#33410;&#28857;&#23558;&#35745;&#31639;&#23494;&#38598;&#22411;&#30340;&#36816;&#31639;&#22806;&#21253;&#32473;&#22806;&#37096;&#30340;&#24037;&#20316;&#33410;&#28857;&#12290;&#20248;&#21270;&#36807;&#31243;&#30340;&#23646;&#24615;&#65292;&#22914;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#65292;&#21487;&#20197;&#21033;&#29992;&#20197;&#20943;&#36731;&#19981;&#21709;&#24212;&#25110;&#36895;&#24230;&#24930;&#30340;&#24037;&#20154;&#65288;&#31216;&#20026;&#36831;&#38045;&#32773;&#65289;&#30340;&#24433;&#21709;&#65292;&#22240;&#20026;&#36825;&#20123;&#24773;&#20917;&#20250;&#38477;&#20302;&#35745;&#31639;&#22806;&#21253;&#30340;&#25910;&#30410;&#12290;&#36825;&#21487;&#20197;&#36890;&#36807;&#20165;&#31561;&#24453;&#27599;&#20010;&#31639;&#27861;&#36845;&#20195;&#20013;&#30340;&#19968;&#37096;&#20998;&#24037;&#20316;&#33410;&#28857;&#23436;&#25104;&#20854;&#35745;&#31639;&#26469;&#23454;&#29616;&#12290;&#20043;&#21069;&#30340;&#24037;&#20316;&#25552;&#20986;&#20102;&#36866;&#24212;&#31561;&#24453;&#24037;&#20154;&#25968;&#37327;&#38543;&#31639;&#27861;&#28436;&#21270;&#20197;&#20248;&#21270;&#25910;&#25947;&#36895;&#24230;&#30340;&#26041;&#27861;&#12290;&#30456;&#21453;&#65292;&#26412;&#25991;&#26500;&#24314;&#20102;&#19968;&#20010;&#26032;&#30340;&#26041;&#26696;&#65292;&#36890;&#36807;&#20351;&#29992;&#29420;&#31435;&#30340;&#38543;&#26426;&#21464;&#37327;&#23545;&#36890;&#20449;&#21644;&#35745;&#31639;&#26102;&#38388;&#36827;&#34892;&#24314;&#27169;&#65292;&#26469;&#36866;&#24212;&#31639;&#27861;&#30340;&#36816;&#34892;&#26102;&#38388;&#20869;&#30340;&#24037;&#20316;&#33410;&#28857;&#25968;&#37327;&#21644;&#35745;&#31639;&#36127;&#36733;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#39640;&#20102;&#20998;&#24067;&#24335;SGD&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#21516;&#26102;&#26174;&#30528;&#38477;&#20302;&#20102;&#35745;&#31639;&#36127;&#36733;&#12290;
&lt;/p&gt;
&lt;p&gt;
In distributed machine learning, a central node outsources computationally expensive calculations to external worker nodes. The properties of optimization procedures like stochastic gradient descent (SGD) can be leveraged to mitigate the effect of unresponsive or slow workers called stragglers, that otherwise degrade the benefit of outsourcing the computation. This can be done by only waiting for a subset of the workers to finish their computation at each iteration of the algorithm. Previous works proposed to adapt the number of workers to wait for as the algorithm evolves to optimize the speed of convergence. In contrast, we model the communication and computation times using independent random variables. Considering this model, we construct a novel scheme that adapts both the number of workers and the computation load throughout the run-time of the algorithm. Consequently, we improve the convergence speed of distributed SGD while significantly reducing the computation load, at the ex
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;Deep Metric Learning&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#32463;&#39564;Bregman&#25955;&#24230;&#30452;&#25509;&#20174;&#25968;&#25454;&#20013;&#36827;&#34892;&#19981;&#30830;&#23450;&#36317;&#31163;&#34920;&#31034;&#65292;&#33021;&#22815;&#26377;&#25928;&#30340;&#22312;&#27169;&#24335;&#35782;&#21035;&#21644;&#32858;&#31867;&#20219;&#21153;&#19978;&#25552;&#39640;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.07689</link><description>&lt;p&gt;
&#23398;&#20064;&#32463;&#39564;Bregman&#25955;&#24230;&#29992;&#20110;&#19981;&#30830;&#23450;&#36317;&#31163;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Learning Empirical Bregman Divergence for Uncertain Distance Representation. (arXiv:2304.07689v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07689
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;Deep Metric Learning&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#32463;&#39564;Bregman&#25955;&#24230;&#30452;&#25509;&#20174;&#25968;&#25454;&#20013;&#36827;&#34892;&#19981;&#30830;&#23450;&#36317;&#31163;&#34920;&#31034;&#65292;&#33021;&#22815;&#26377;&#25928;&#30340;&#22312;&#27169;&#24335;&#35782;&#21035;&#21644;&#32858;&#31867;&#20219;&#21153;&#19978;&#25552;&#39640;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24230;&#37327;&#23398;&#20064;&#25216;&#26415;&#24050;&#24212;&#29992;&#20110;&#21508;&#31181;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#20219;&#21153;&#65292;&#36890;&#36807;&#28145;&#24230;&#32593;&#32476;&#23398;&#20064;&#26679;&#26412;&#23884;&#20837;&#26469;&#36827;&#34892;&#35270;&#35273;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#32463;&#20856;&#26041;&#27861;&#37319;&#29992;&#22266;&#23450;&#36317;&#31163;&#24230;&#37327;&#20316;&#20026;&#20004;&#20010;&#23884;&#20837;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#20989;&#25968;&#65292;&#21487;&#33021;&#23548;&#33268;&#25429;&#25417;&#22797;&#26434;&#25968;&#25454;&#20998;&#24067;&#30340;&#20122;&#26368;&#20248;&#24615;&#33021;&#12290;Bregman&#25955;&#24230;&#27010;&#25324;&#20102;&#21508;&#31181;&#36317;&#31163;&#24230;&#37327;&#30340;&#24230;&#37327;&#65292;&#24182;&#22312;&#35768;&#22810;&#28145;&#24230;&#24230;&#37327;&#23398;&#20064;&#39046;&#22495;&#20013;&#20135;&#29983;&#12290;&#26412;&#25991;&#39318;&#20808;&#23637;&#31034;&#20102;&#22914;&#20309;&#20174;Bregman&#25955;&#24230;&#33719;&#24471;&#28145;&#24230;&#24230;&#37327;&#23398;&#20064;&#25439;&#22833;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#30452;&#25509;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#32463;&#39564;Bregman&#25955;&#24230;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#35774;&#32622;&#23545;Bregman&#25955;&#24230;&#19979;&#30340;&#20984;&#20989;&#25968;&#36827;&#34892;&#21442;&#25968;&#21270;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;&#20854;&#20182;SOTA&#28145;&#24230;&#24230;&#37327;&#23398;&#20064;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20116;&#20010;&#27969;&#34892;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#29305;&#21035;&#26159;&#22312;&#27169;&#24335;&#35782;&#21035;&#21644;&#32858;&#31867;&#20219;&#21153;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep metric learning techniques have been used for visual representation in various supervised and unsupervised learning tasks through learning embeddings of samples with deep networks. However, classic approaches, which employ a fixed distance metric as a similarity function between two embeddings, may lead to suboptimal performance for capturing the complex data distribution. The Bregman divergence generalizes measures of various distance metrics and arises throughout many fields of deep metric learning. In this paper, we first show how deep metric learning loss can arise from the Bregman divergence. We then introduce a novel method for learning empirical Bregman divergence directly from data based on parameterizing the convex function underlying the Bregman divergence with a deep learning setting. We further experimentally show that our approach performs effectively on five popular public datasets compared to other SOTA deep metric learning methods, particularly for pattern recognit
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36845;&#20195;&#38543;&#26426;&#20989;&#25968;&#29983;&#25104;&#30340;&#36807;&#31243;&#30340;&#24378;&#31283;&#23450;&#24615;&#65292;&#35777;&#26126;&#20102;&#36866;&#29992;&#20110;&#36882;&#24402;&#26144;&#23556;&#30340;&#28201;&#21644;&#26465;&#20214;&#19979;&#30340;&#24378;&#31283;&#23450;&#24615;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#22810;&#20010;&#24212;&#29992;&#21450;&#30456;&#20851;&#39046;&#22495;&#30340;&#26032;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.04657</link><description>&lt;p&gt;
&#35770;&#38543;&#26426;&#36941;&#21382;&#30340;&#24378;&#31283;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the strong stability of ergodic iterations. (arXiv:2304.04657v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04657
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36845;&#20195;&#38543;&#26426;&#20989;&#25968;&#29983;&#25104;&#30340;&#36807;&#31243;&#30340;&#24378;&#31283;&#23450;&#24615;&#65292;&#35777;&#26126;&#20102;&#36866;&#29992;&#20110;&#36882;&#24402;&#26144;&#23556;&#30340;&#28201;&#21644;&#26465;&#20214;&#19979;&#30340;&#24378;&#31283;&#23450;&#24615;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#22810;&#20010;&#24212;&#29992;&#21450;&#30456;&#20851;&#39046;&#22495;&#30340;&#26032;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#30001;&#38543;&#26426;&#20989;&#25968;&#36845;&#20195;&#29983;&#25104;&#30340;&#36807;&#31243;&#65292;&#36825;&#20123;&#20989;&#25968;&#30001;&#19968;&#20010;&#24179;&#31283;&#19988;&#31526;&#21512;&#36941;&#21382;&#26465;&#20214;&#30340;&#24207;&#21015;&#39537;&#21160;&#12290;&#22914;&#26524;&#23384;&#22312;&#19968;&#20010;&#38543;&#26426;&#21021;&#22987;&#21270;&#20351;&#24471;&#35813;&#36807;&#31243;&#26159;&#31283;&#23450;&#21644;&#36941;&#21382;&#30340;&#65292;&#24182;&#19988;&#23545;&#20110;&#20219;&#20309;&#20854;&#20182;&#21021;&#22987;&#21270;&#65292;&#20004;&#20010;&#36807;&#31243;&#20043;&#38388;&#30340;&#24046;&#24322;&#20960;&#20046;&#32943;&#23450;&#25910;&#25947;&#20110;&#38646;&#65292;&#37027;&#20040;&#36825;&#26679;&#30340;&#36807;&#31243;&#34987;&#31216;&#20026;&#24378;&#31283;&#23450;&#12290;&#22312;&#23545;&#24212;&#36882;&#24402;&#26144;&#23556;&#19978;&#26045;&#21152;&#19968;&#20123;&#28201;&#21644;&#30340;&#26465;&#20214;&#65292;&#32780;&#19981;&#22312;&#39537;&#21160;&#24207;&#21015;&#19978;&#26045;&#21152;&#20219;&#20309;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36845;&#20195;&#30340;&#24378;&#31283;&#23450;&#24615;&#12290;&#22810;&#20010;&#24212;&#29992;&#34987;&#30740;&#31350;&#65292;&#22914;&#38543;&#26426;&#36924;&#36817;&#21644;&#25490;&#38431;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#20855;&#26377;&#20381;&#36182;&#22122;&#22768;&#30340; Langevin &#22411;&#36845;&#20195;&#21644;&#22810;&#22411;&#20998;&#25903;&#36807;&#31243;&#30340;&#26032;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We revisit processes generated by iterated random functions driven by a stationary and ergodic sequence. Such a process is called strongly stable if a random initialization exists, for which the process is stationary and ergodic, and for any other initialization, the difference of the two processes converges to zero almost surely. Under some mild conditions on the corresponding recursive map, without any condition on the driving sequence, we show the strong stability of iterations. Several applications are surveyed such as stochastic approximation and queuing. Furthermore, new results are deduced for Langevin-type iterations with dependent noise and for multitype branching processes.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#21517;&#20026; DISDE &#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20998;&#26512;&#27169;&#22411;&#22312;&#19981;&#21516;&#20998;&#24067;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#21464;&#21270;&#12290;&#35813;&#26041;&#27861;&#23558;&#24615;&#33021;&#19979;&#38477;&#20998;&#35299;&#20026;&#19977;&#20010;&#26041;&#38754;&#65306;&#38590;&#24230;&#26356;&#22823;&#20294;&#26356;&#39057;&#32321;&#20986;&#29616;&#30340;&#31034;&#20363;&#22686;&#21152;&#12289;&#29305;&#24449;&#21644;&#32467;&#26524;&#20043;&#38388;&#20851;&#31995;&#30340;&#21464;&#21270;&#21644;&#22312;&#35757;&#32451;&#26399;&#38388;&#19981;&#39057;&#32321;&#25110;&#26410;&#35265;&#36807;&#30340;&#31034;&#20363;&#24615;&#33021;&#24046;&#12290;</title><link>http://arxiv.org/abs/2303.02011</link><description>&lt;p&gt;
&#22312;&#20998;&#24067;&#36716;&#31227;&#19979;&#35786;&#26029;&#27169;&#22411;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Diagnosing Model Performance Under Distribution Shift. (arXiv:2303.02011v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.02011
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#21517;&#20026; DISDE &#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20998;&#26512;&#27169;&#22411;&#22312;&#19981;&#21516;&#20998;&#24067;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#21464;&#21270;&#12290;&#35813;&#26041;&#27861;&#23558;&#24615;&#33021;&#19979;&#38477;&#20998;&#35299;&#20026;&#19977;&#20010;&#26041;&#38754;&#65306;&#38590;&#24230;&#26356;&#22823;&#20294;&#26356;&#39057;&#32321;&#20986;&#29616;&#30340;&#31034;&#20363;&#22686;&#21152;&#12289;&#29305;&#24449;&#21644;&#32467;&#26524;&#20043;&#38388;&#20851;&#31995;&#30340;&#21464;&#21270;&#21644;&#22312;&#35757;&#32451;&#26399;&#38388;&#19981;&#39057;&#32321;&#25110;&#26410;&#35265;&#36807;&#30340;&#31034;&#20363;&#24615;&#33021;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#27169;&#22411;&#22312;&#19981;&#21516;&#20110;&#35757;&#32451;&#20998;&#24067;&#30340;&#30446;&#26631;&#20998;&#24067;&#19979;&#36816;&#34892;&#26102;&#65292;&#20854;&#24615;&#33021;&#21487;&#33021;&#20250;&#19979;&#38477;&#12290;&#20026;&#20102;&#29702;&#35299;&#36825;&#20123;&#25805;&#20316;&#22833;&#36133;&#27169;&#24335;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#31216;&#20026; DIstribution Shift DEcomposition&#65288;DISDE&#65289;&#65292;&#23558;&#24615;&#33021;&#19979;&#38477;&#24402;&#22240;&#20110;&#19981;&#21516;&#31867;&#22411;&#30340;&#20998;&#24067;&#36716;&#31227;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#24615;&#33021;&#19979;&#38477;&#20998;&#35299;&#20026;&#20197;&#19979;&#20960;&#20010;&#26041;&#38754;&#65306;1&#65289;&#26469;&#33258;&#35757;&#32451;&#30340;&#26356;&#38590;&#20294;&#26356;&#39057;&#32321;&#30340;&#31034;&#20363;&#22686;&#21152;&#65307;2&#65289;&#29305;&#24449;&#21644;&#32467;&#26524;&#20043;&#38388;&#20851;&#31995;&#30340;&#21464;&#21270;&#65307;3&#65289;&#22312;&#35757;&#32451;&#26399;&#38388;&#19981;&#39057;&#32321;&#25110;&#26410;&#35265;&#36807;&#30340;&#31034;&#20363;&#24615;&#33021;&#24046;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#22312;&#22266;&#23450; $X$ &#30340;&#20998;&#24067;&#30340;&#21516;&#26102;&#25913;&#21464; $Y \mid X$ &#30340;&#26465;&#20214;&#20998;&#24067;&#65292;&#25110;&#22312;&#22266;&#23450; $Y \mid X$ &#30340;&#26465;&#20214;&#20998;&#24067;&#30340;&#21516;&#26102;&#25913;&#21464; $X$ &#30340;&#20998;&#24067;&#65292;&#20174;&#32780;&#23450;&#20041;&#20102;&#19968;&#20010;&#20851;&#20110; $X$ &#30340;&#20551;&#35774;&#20998;&#24067;&#65292;&#20854;&#20013;&#21253;&#21547;&#35757;&#32451;&#21644;&#30446;&#26631;&#20013;&#20849;&#21516;&#30340;&#20540;&#65292;&#21487;&#20197;&#36731;&#26494;&#22320;&#27604;&#36739; $Y \mid X$ &#24182;&#36827;&#34892;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Prediction models can perform poorly when deployed to target distributions different from the training distribution. To understand these operational failure modes, we develop a method, called DIstribution Shift DEcomposition (DISDE), to attribute a drop in performance to different types of distribution shifts. Our approach decomposes the performance drop into terms for 1) an increase in harder but frequently seen examples from training, 2) changes in the relationship between features and outcomes, and 3) poor performance on examples infrequent or unseen during training. These terms are defined by fixing a distribution on $X$ while varying the conditional distribution of $Y \mid X$ between training and target, or by fixing the conditional distribution of $Y \mid X$ while varying the distribution on $X$. In order to do this, we define a hypothetical distribution on $X$ consisting of values common in both training and target, over which it is easy to compare $Y \mid X$ and thus predictive
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#23618;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#20351;&#29992;&#30340;&#26799;&#24230;&#35745;&#31639;&#27425;&#25968; $O((n+m)^{\frac{1}{2}}\varepsilon^{-1})$&#65292;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2302.08766</link><description>&lt;p&gt;
&#19968;&#31181;&#21452;&#23618;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#30340;&#19979;&#30028;&#21644;&#36817;&#20284;&#26368;&#20248;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Lower Bound and a Near-Optimal Algorithm for Bilevel Empirical Risk Minimization. (arXiv:2302.08766v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08766
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#23618;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#20351;&#29992;&#30340;&#26799;&#24230;&#35745;&#31639;&#27425;&#25968; $O((n+m)^{\frac{1}{2}}\varepsilon^{-1})$&#65292;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21452;&#23618;&#26368;&#20248;&#21270;&#38382;&#39064;&#36234;&#26469;&#36234;&#22810;&#22320;&#24212;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#20013;&#12290;&#22312;&#35768;&#22810;&#23454;&#38469;&#24773;&#20917;&#19979;&#65292;&#19978;&#23618;&#21644;&#19979;&#23618;&#30446;&#26631;&#23545;&#24212;&#20110;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#24182;&#22240;&#27492;&#20855;&#26377;&#24635;&#21644;&#32467;&#26500;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#33879;&#21517;&#30340;SARAH&#31639;&#27861;&#30340;&#21452;&#23618;&#25193;&#23637;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#38656;&#35201;$\mathcal {O}((n+m)^{\frac{1}{2}}\varepsilon ^{-1})$&#27425;&#26799;&#24230;&#35745;&#31639;&#25165;&#33021;&#23454;&#29616;$\varepsilon$&#31283;&#23450;&#24615;&#65292;&#20854;&#20013;$n+m$&#26159;&#26679;&#26412;&#24635;&#25968;&#65292;&#36825;&#27604;&#20808;&#21069;&#25152;&#26377;&#30340;&#21452;&#23618;&#31639;&#27861;&#37117;&#35201;&#22909;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#19979;&#30028;&#65292;&#29992;&#20110;&#24471;&#21040;&#21452;&#23618;&#38382;&#39064;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;&#36817;&#20284;&#31283;&#23450;&#28857;&#25152;&#38656;&#30340;oracle&#35843;&#29992;&#27425;&#25968;&#12290;&#36825;&#20010;&#19979;&#30028;&#27491;&#26159;&#25105;&#20204;&#30340;&#31639;&#27861;&#25152;&#36798;&#21040;&#30340;&#65292;&#22240;&#27492;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bilevel optimization problems, which are problems where two optimization problems are nested, have more and more applications in machine learning. In many practical cases, the upper and the lower objectives correspond to empirical risk minimization problems and therefore have a sum structure. In this context, we propose a bilevel extension of the celebrated SARAH algorithm. We demonstrate that the algorithm requires $\mathcal{O}((n+m)^{\frac12}\varepsilon^{-1})$ gradient computations to achieve $\varepsilon$-stationarity with $n+m$ the total number of samples, which improves over all previous bilevel algorithms. Moreover, we provide a lower bound on the number of oracle calls required to get an approximate stationary point of the objective function of the bilevel problem. This lower bound is attained by our algorithm, which is therefore optimal in terms of sample complexity.
&lt;/p&gt;</description></item><item><title>&#21019;&#26032;&#28857;&#22312;&#20110;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#39532;&#23572;&#21487;&#22827;&#25193;&#25955;&#22122;&#22768;&#36807;&#31243;&#30340;&#26143;&#24418;&#38477;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65292;&#33021;&#22815;&#24191;&#27867;&#36866;&#29992;&#20110;&#25351;&#25968;&#26063;&#20013;&#30340;&#22810;&#31181;&#20998;&#24067;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#32422;&#26463;&#27969;&#24418;&#19978;&#30340;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2302.05259</link><description>&lt;p&gt;
&#26143;&#24418;&#38477;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Star-Shaped Denoising Diffusion Probabilistic Models. (arXiv:2302.05259v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05259
&lt;/p&gt;
&lt;p&gt;
&#21019;&#26032;&#28857;&#22312;&#20110;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#39532;&#23572;&#21487;&#22827;&#25193;&#25955;&#22122;&#22768;&#36807;&#31243;&#30340;&#26143;&#24418;&#38477;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65292;&#33021;&#22815;&#24191;&#27867;&#36866;&#29992;&#20110;&#25351;&#25968;&#26063;&#20013;&#30340;&#22810;&#31181;&#20998;&#24067;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#32422;&#26463;&#27969;&#24418;&#19978;&#30340;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#38477;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DDPM&#65289;&#30340;&#26041;&#27861;&#24050;&#32463;&#25104;&#20026;&#29983;&#25104;&#27169;&#22411;&#20013;&#26080;&#22788;&#19981;&#22312;&#30340;&#24037;&#20855;&#12290;&#20294;&#26159;&#65292;&#23427;&#20204;&#22823;&#22810;&#23616;&#38480;&#20110;&#39640;&#26031;&#21644;&#31163;&#25955;&#25193;&#25955;&#36807;&#31243;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#26143;&#24418;&#38477;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;SS-DDPM&#65289;&#65292;&#19968;&#31181;&#20855;&#26377;&#38750;&#39532;&#23572;&#21487;&#22827;&#25193;&#25955;&#22122;&#22768;&#36807;&#31243;&#30340;&#27169;&#22411;&#12290;&#22312;&#39640;&#26031;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#27169;&#22411;&#31561;&#25928;&#20110;&#39532;&#23572;&#21487;&#22827;DDPM&#12290;&#28982;&#32780;&#65292;&#23427;&#21487;&#20197;&#23450;&#20041;&#21644;&#36866;&#29992;&#20110;&#20219;&#24847;&#22122;&#22768;&#20998;&#24067;&#65292;&#24182;&#19988;&#23545;&#20110;&#33853;&#22312;&#25351;&#25968;&#26063;&#20013;&#30340;&#24191;&#27867;&#20998;&#24067;&#65292;&#23427;&#37319;&#29992;&#20102;&#39640;&#25928;&#30340;&#35757;&#32451;&#21644;&#37319;&#26679;&#31639;&#27861;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#37197;&#26041;&#65292;&#29992;&#20110;&#35774;&#35745;&#20855;&#26377;Beta&#65292;von Mises-Fisher&#65292;Dirichlet&#65292;Wishart&#31561;&#20998;&#24067;&#30340;&#25193;&#25955;&#26679;&#24335;&#27169;&#22411;&#65292;&#24403;&#25968;&#25454;&#20301;&#20110;&#32422;&#26463;&#27969;&#24418;&#19978;&#26102;&#29305;&#21035;&#26377;&#29992;&#65292;&#20363;&#22914;&#21333;&#20301;&#29699;&#65292;&#27491;&#21322;&#23450;&#30697;&#38453;&#30340;&#31354;&#38388;&#65292;&#27010;&#29575;&#21333;&#32431;&#24418;&#31561;&#12290;&#25105;&#20204;&#22312;&#19981;&#21516;&#30340;&#35774;&#32622;&#20013;&#35780;&#20272;&#20102;&#35813;&#27169;&#22411;&#65292;&#24182;&#21457;&#29616;&#23427;&#24456;&#26377;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Methods based on Denoising Diffusion Probabilistic Models (DDPM) became a ubiquitous tool in generative modeling. However, they are mostly limited to Gaussian and discrete diffusion processes. We propose Star-Shaped Denoising Diffusion Probabilistic Models (SS-DDPM), a model with a non-Markovian diffusion-like noising process. In the case of Gaussian distributions, this model is equivalent to Markovian DDPMs. However, it can be defined and applied with arbitrary noising distributions, and admits efficient training and sampling algorithms for a wide range of distributions that lie in the exponential family. We provide a simple recipe for designing diffusion-like models with distributions like Beta, von Mises--Fisher, Dirichlet, Wishart and others, which can be especially useful when data lies on a constrained manifold such as the unit sphere, the space of positive semi-definite matrices, the probabilistic simplex, etc. We evaluate the model in different settings and find it competitive 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#26500;&#24314;&#38750;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#19978;&#38745;&#27490;&#39640;&#26031;&#36807;&#31243;&#30340;&#23454;&#29992;&#25216;&#26415;&#65292;&#33021;&#22815;&#23545;&#23450;&#20041;&#22312;&#36825;&#20123;&#31354;&#38388;&#19978;&#30340;&#20808;&#39564;&#21644;&#21518;&#39564;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#23454;&#38469;&#37319;&#26679;&#21644;&#35745;&#31639;&#21327;&#26041;&#24046;&#26680;&#12290;</title><link>http://arxiv.org/abs/2301.13088</link><description>&lt;p&gt;
Lie &#32676;&#21644;&#23427;&#20204;&#30340;&#40784;&#27425;&#31354;&#38388;&#19978;&#30340;&#38745;&#27490;&#26680;&#21644;&#39640;&#26031;&#36807;&#31243; II&#65306;&#38750;&#32039;&#23545;&#31216;&#31354;&#38388;
&lt;/p&gt;
&lt;p&gt;
Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces II: non-compact symmetric spaces. (arXiv:2301.13088v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13088
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#26500;&#24314;&#38750;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#19978;&#38745;&#27490;&#39640;&#26031;&#36807;&#31243;&#30340;&#23454;&#29992;&#25216;&#26415;&#65292;&#33021;&#22815;&#23545;&#23450;&#20041;&#22312;&#36825;&#20123;&#31354;&#38388;&#19978;&#30340;&#20808;&#39564;&#21644;&#21518;&#39564;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#23454;&#38469;&#37319;&#26679;&#21644;&#35745;&#31639;&#21327;&#26041;&#24046;&#26680;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#37325;&#35201;&#30340;&#26102;&#31354;&#27169;&#22411;&#20043;&#19968;&#65292;&#23427;&#21487;&#20197;&#32534;&#30721;&#26377;&#20851;&#24314;&#27169;&#20989;&#25968;&#30340;&#20808;&#39564;&#20449;&#24687;&#65292;&#24182;&#21487;&#29992;&#20110;&#31934;&#30830;&#25110;&#36817;&#20284;&#36125;&#21494;&#26031;&#23398;&#20064;&#12290;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#29305;&#21035;&#26159;&#22312;&#29289;&#29702;&#31185;&#23398;&#21644;&#24037;&#31243;&#39046;&#22495;&#65292;&#20197;&#21450;&#22320;&#36136;&#32479;&#35745;&#23398;&#21644;&#31070;&#32463;&#31185;&#23398;&#31561;&#39046;&#22495;&#65292;&#23545;&#23545;&#31216;&#24615;&#30340;&#19981;&#21464;&#24615;&#26159;&#21487;&#20197;&#32771;&#34385;&#30340;&#26368;&#22522;&#26412;&#24418;&#24335;&#20043;&#19968;&#12290;&#39640;&#26031;&#36807;&#31243;&#21327;&#26041;&#24046;&#23545;&#36825;&#20123;&#23545;&#31216;&#24615;&#30340;&#19981;&#21464;&#24615;&#24341;&#21457;&#20102;&#23545;&#36825;&#20123;&#31354;&#38388;&#30340;&#24179;&#31283;&#24615;&#27010;&#24565;&#30340;&#26368;&#33258;&#28982;&#30340;&#25512;&#24191;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#24314;&#31435;&#38745;&#27490;&#39640;&#26031;&#36807;&#31243;&#30340;&#26500;&#36896;&#24615;&#21644;&#23454;&#29992;&#25216;&#26415;&#65292;&#29992;&#20110;&#22312;&#23545;&#31216;&#24615;&#32972;&#26223;&#19979;&#20986;&#29616;&#30340;&#38750;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#30340;&#38750;&#24120;&#22823;&#30340;&#31867;&#12290;&#25105;&#20204;&#30340;&#25216;&#26415;&#20351;&#24471;&#33021;&#22815;&#65288;i&#65289;&#35745;&#31639;&#21327;&#26041;&#24046;&#26680;&#21644;&#65288;ii&#65289;&#20174;&#36825;&#20123;&#31354;&#38388;&#19978;&#23450;&#20041;&#30340;&#20808;&#39564;&#21644;&#21518;&#39564;&#39640;&#26031;&#36807;&#31243;&#20013;&#23454;&#38469;&#22320;&#36827;&#34892;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes are arguably the most important class of spatiotemporal models within machine learning. They encode prior information about the modeled function and can be used for exact or approximate Bayesian learning. In many applications, particularly in physical sciences and engineering, but also in areas such as geostatistics and neuroscience, invariance to symmetries is one of the most fundamental forms of prior information one can consider. The invariance of a Gaussian process' covariance to such symmetries gives rise to the most natural generalization of the concept of stationarity to such spaces. In this work, we develop constructive and practical techniques for building stationary Gaussian processes on a very large class of non-Euclidean spaces arising in the context of symmetries. Our techniques make it possible to (i) calculate covariance kernels and (ii) sample from prior and posterior Gaussian processes defined on such spaces, both in a practical manner. This work is 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19968;&#38454;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#26041;&#27861;&#26469;&#35299;&#20915;&#32422;&#26463;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#20854;&#25805;&#20316;&#22797;&#26434;&#24230;&#20026; ${\cal O}(\varepsilon^{-4}\log\varepsilon^{-1})$&#12290;</title><link>http://arxiv.org/abs/2301.02060</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#32422;&#26463;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#38382;&#39064;&#30340;&#19968;&#38454;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A first-order augmented Lagrangian method for constrained minimax optimization. (arXiv:2301.02060v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.02060
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19968;&#38454;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#26041;&#27861;&#26469;&#35299;&#20915;&#32422;&#26463;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#20854;&#25805;&#20316;&#22797;&#26434;&#24230;&#20026; ${\cal O}(\varepsilon^{-4}\log\varepsilon^{-1})$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#32422;&#26463;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#19968;&#38454;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20854;&#23376;&#38382;&#39064;&#34987;&#21457;&#29616;&#26159;&#19968;&#20010;&#26356;&#31616;&#21333;&#30340;&#32467;&#26500;&#21270;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#20316;&#32773;&#22312; [26] &#20013;&#26368;&#36817;&#24320;&#21457;&#30340;&#19968;&#38454;&#26041;&#27861;&#26469;&#36866;&#24403;&#22320;&#35299;&#20915;&#12290;&#22312;&#19968;&#20123;&#36866;&#24403;&#30340;&#20551;&#35774;&#19979;&#65292;&#20026;&#20102;&#25214;&#21040;&#32422;&#26463;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#19968;&#20010; $\varepsilon$-KKT &#35299;&#65292;&#35813;&#26041;&#27861;&#30340;&#25805;&#20316;&#22797;&#26434;&#24230;&#20026; ${\cal O}(\varepsilon^{-4}\log\varepsilon^{-1})$&#65292;&#35813;&#22797;&#26434;&#24230;&#26159;&#30001;&#22522;&#26412;&#25805;&#20316;&#27979;&#37327;&#24471;&#21040;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we study a class of constrained minimax problems. In particular, we propose a first-order augmented Lagrangian method for solving them, whose subproblems turn out to be a much simpler structured minimax problem and are suitably solved by a first-order method recently developed in [26] by the authors. Under some suitable assumptions, an \emph{operation complexity} of ${\cal O}(\varepsilon^{-4}\log\varepsilon^{-1})$, measured by its fundamental operations, is established for the first-order augmented Lagrangian method for finding an $\varepsilon$-KKT solution of the constrained minimax problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#31890;&#23376;&#30340;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;PFG&#65292;&#36890;&#36807;&#24341;&#20837;&#21253;&#21547;RKHS&#33539;&#25968;&#30340;&#20989;&#25968;&#27491;&#21017;&#39033;&#23454;&#29616;&#26356;&#22823;&#30340;&#20989;&#25968;&#31867;&#21644;&#26356;&#22909;&#30340;&#36866;&#24212;&#24615;&#65292;&#35299;&#20915;&#20102;RKHS&#35201;&#27714;&#38480;&#21046;&#20989;&#25968;&#31867;&#21644;&#31639;&#27861;&#28789;&#27963;&#24615;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;KL&#25955;&#24230;&#19978;&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#30340;&#36830;&#32493;&#26102;&#38388;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2211.13954</link><description>&lt;p&gt;
&#22522;&#20110;&#31890;&#23376;&#30340;&#39044;&#22788;&#29702;&#20989;&#25968;&#26799;&#24230;&#27969;&#21464;&#20998;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Particle-based Variational Inference with Preconditioned Functional Gradient Flow. (arXiv:2211.13954v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.13954
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#31890;&#23376;&#30340;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;PFG&#65292;&#36890;&#36807;&#24341;&#20837;&#21253;&#21547;RKHS&#33539;&#25968;&#30340;&#20989;&#25968;&#27491;&#21017;&#39033;&#23454;&#29616;&#26356;&#22823;&#30340;&#20989;&#25968;&#31867;&#21644;&#26356;&#22909;&#30340;&#36866;&#24212;&#24615;&#65292;&#35299;&#20915;&#20102;RKHS&#35201;&#27714;&#38480;&#21046;&#20989;&#25968;&#31867;&#21644;&#31639;&#27861;&#28789;&#27963;&#24615;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;KL&#25955;&#24230;&#19978;&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#30340;&#36830;&#32493;&#26102;&#38388;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#31890;&#23376;&#30340;&#21464;&#20998;&#25512;&#26029;&#36890;&#36807;&#26799;&#24230;&#27969;&#20272;&#35745;&#26368;&#23567;&#21270;&#27169;&#22411;&#26679;&#26412;&#19982;&#30446;&#26631;&#21518;&#39564;&#20043;&#38388;&#30340;KL&#25955;&#24230;&#12290;&#38543;&#30528;Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#65288;SVGD&#65289;&#30340;&#27969;&#34892;&#65292;&#22522;&#20110;&#31890;&#23376;&#30340;VI&#31639;&#27861;&#30340;&#37325;&#28857;&#24050;&#32463;&#36716;&#21521;&#22312;&#37325;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#20013;&#36924;&#36817;&#26799;&#24230;&#27969;&#30340;&#20989;&#25968;&#30340;&#29305;&#24615;&#12290;&#28982;&#32780;&#65292;RKHS&#30340;&#35201;&#27714;&#38480;&#21046;&#20102;&#20989;&#25968;&#31867;&#21644;&#31639;&#27861;&#30340;&#28789;&#27963;&#24615;&#12290;&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#21253;&#21547;&#20102;RKHS&#33539;&#25968;&#30340;&#20989;&#25968;&#27491;&#21017;&#21270;&#39033;&#65292;&#25552;&#20379;&#20102;&#36825;&#20010;&#38382;&#39064;&#30340;&#36890;&#29992;&#35299;&#20915;&#26041;&#26696;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#21487;&#20197;&#25552;&#20986;&#19968;&#20010;&#26032;&#30340;&#22522;&#20110;&#31890;&#23376;&#30340;VI&#31639;&#27861;&#65292;&#21483;&#20570;&#39044;&#22788;&#29702;&#20989;&#25968;&#26799;&#24230;&#27969;&#65288;PFG&#65289;&#12290;&#19982;SVGD&#30456;&#27604;&#65292;PFG&#20855;&#26377;&#26356;&#22823;&#30340;&#20989;&#25968;&#31867;&#65292;&#25913;&#36827;&#20102;&#22823;&#37327;&#31890;&#23376;&#22330;&#26223;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#26356;&#36866;&#24212;&#30149;&#24577;&#20998;&#24067;&#65292;&#24182;&#22312;KL&#25955;&#24230;&#19978;&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#30340;&#36830;&#32493;&#26102;&#38388;&#25910;&#25947;&#12290;&#27492;&#22806;&#65292;&#38750;&#32447;&#24615;&#20989;&#25968;&#35268;&#33539;&#20063;&#21487;&#20197;&#36731;&#26494;&#22320;&#24182;&#20837;&#21040;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Particle-based variational inference (VI) minimizes the KL divergence between model samples and the target posterior with gradient flow estimates. With the popularity of Stein variational gradient descent (SVGD), the focus of particle-based VI algorithms has been on the properties of functions in Reproducing Kernel Hilbert Space (RKHS) to approximate the gradient flow. However, the requirement of RKHS restricts the function class and algorithmic flexibility. This paper offers a general solution to this problem by introducing a functional regularization term that encompasses the RKHS norm as a special case. This allows us to propose a new particle-based VI algorithm called preconditioned functional gradient flow (PFG). Compared to SVGD, PFG has several advantages. It has a larger function class, improved scalability in large particle-size scenarios, better adaptation to ill-conditioned distributions, and provable continuous-time convergence in KL divergence. Additionally, non-linear fun
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#29992;&#20110;&#22522;&#20110;&#20223;&#30495;&#25512;&#26029;&#30340;&#21512;&#25104;&#20284;&#28982;&#26041;&#27861;&#65292;&#20351;&#29992;&#39640;&#20445;&#30495;&#24230;&#27169;&#25311;&#22120;&#29983;&#25104;&#27169;&#25311;&#25968;&#25454;&#65292;&#23398;&#20064;&#26465;&#20214;&#33021;&#37327;&#27169;&#22411;(EBM)&#30340; likelihood&#65292;&#32467;&#21512;&#20808;&#39564;&#20272;&#35745;&#21518;&#39564;&#20998;&#24067;&#65292;&#21487;&#20197;&#20351;&#29992;MCMC&#25277;&#21462;&#26679;&#26412;&#65292;&#35813;&#26041;&#27861;&#30456;&#36739;&#20110;&#20854;&#20182;&#26041;&#27861;&#26356;&#21152;&#28789;&#27963;&#21644;&#20934;&#30830;&#12290;</title><link>http://arxiv.org/abs/2210.14756</link><description>&lt;p&gt;
&#29992;&#20110;&#22522;&#20110;&#20223;&#30495;&#25512;&#26029;&#30340;&#38750;&#24402;&#19968;&#21270;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Maximum Likelihood Learning of Unnormalized Models for Simulation-Based Inference. (arXiv:2210.14756v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.14756
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#29992;&#20110;&#22522;&#20110;&#20223;&#30495;&#25512;&#26029;&#30340;&#21512;&#25104;&#20284;&#28982;&#26041;&#27861;&#65292;&#20351;&#29992;&#39640;&#20445;&#30495;&#24230;&#27169;&#25311;&#22120;&#29983;&#25104;&#27169;&#25311;&#25968;&#25454;&#65292;&#23398;&#20064;&#26465;&#20214;&#33021;&#37327;&#27169;&#22411;(EBM)&#30340; likelihood&#65292;&#32467;&#21512;&#20808;&#39564;&#20272;&#35745;&#21518;&#39564;&#20998;&#24067;&#65292;&#21487;&#20197;&#20351;&#29992;MCMC&#25277;&#21462;&#26679;&#26412;&#65292;&#35813;&#26041;&#27861;&#30456;&#36739;&#20110;&#20854;&#20182;&#26041;&#27861;&#26356;&#21152;&#28789;&#27963;&#21644;&#20934;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31181;&#29992;&#20110;&#22522;&#20110;&#20223;&#30495;&#25512;&#26029;&#65288;SBI&#65289;&#30340;&#21512;&#25104;&#20284;&#28982;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#39640;&#20445;&#30495;&#24230;&#27169;&#25311;&#22120;&#23384;&#22312;&#26102;&#20174;&#23454;&#39564;&#35266;&#27979;&#20013;&#36827;&#34892;&#20998;&#25674;&#25110;&#26377;&#38024;&#23545;&#24615;&#30340;&#25512;&#26029;&#12290;&#20004;&#31181;&#26041;&#27861;&#22343;&#20351;&#29992;&#20174;&#25552;&#35758;&#20998;&#24067;&#20013;&#25277;&#21462;&#30340;&#21442;&#25968;&#25152;&#29983;&#25104;&#30340;&#27169;&#25311;&#25968;&#25454;&#26469;&#23398;&#20064; likelihood &#30340;&#26465;&#20214;&#33021;&#37327;&#27169;&#22411;(EBM)&#12290;&#28982;&#21518;&#21487;&#20197;&#23558;&#23398;&#20064;&#21040;&#30340; likelihood &#19982;&#20219;&#20309;&#20808;&#39564;&#32452;&#21512;&#20197;&#33719;&#24471;&#21518;&#39564;&#20272;&#35745;&#65292;&#38543;&#21518;&#21487;&#20197;&#20351;&#29992; MCMC &#20174;&#20013;&#25277;&#21462;&#26679;&#26412;&#12290;&#19982;&#20854;&#20182;&#21512;&#25104;&#20284;&#28982;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#29420;&#29305;&#22320;&#32467;&#21512;&#20102;&#28789;&#27963;&#30340;&#33021;&#37327;&#27169;&#22411;&#21644; KL &#25439;&#22833;&#30340;&#26368;&#23567;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce two synthetic likelihood methods for Simulation-Based Inference (SBI), to conduct either amortized or targeted inference from experimental observations when a high-fidelity simulator is available. Both methods learn a conditional energy-based model (EBM) of the likelihood using synthetic data generated by the simulator, conditioned on parameters drawn from a proposal distribution. The learned likelihood can then be combined with any prior to obtain a posterior estimate, from which samples can be drawn using MCMC. Our methods uniquely combine a flexible Energy-Based Model and the minimization of a KL loss: this is in contrast to other synthetic likelihood methods, which either rely on normalizing flows, or minimize score-based objectives; choices that come with known pitfalls. We demonstrate the properties of both methods on a range of synthetic datasets, and apply them to a neuroscience model of the pyloric network in the crab, where our method outperforms prior art for a 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;p$^3$VAE&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#23558;&#19968;&#20010;&#23436;&#32654;&#30340;&#29289;&#29702;&#27169;&#22411;&#38598;&#25104;&#21040;&#27169;&#22411;&#20013;&#65292;&#24182;&#24212;&#29992;&#20110;&#39640;&#20998;&#36776;&#29575;&#39640;&#20809;&#35889;&#36965;&#24863;&#22270;&#20687;&#30340;&#35821;&#20041;&#20998;&#21106;&#12290;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#22806;&#25512;&#33021;&#21147;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#21516;&#26102;&#20855;&#26377;&#39640;&#24230;&#35299;&#32533;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2210.10418</link><description>&lt;p&gt;
p$^3$VAE&#65306;&#19968;&#20010;&#29289;&#29702;&#38598;&#25104;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#24212;&#29992;&#20110;&#20809;&#23398;&#36965;&#24863;&#22270;&#20687;&#30340;&#35821;&#20041;&#20998;&#21106;
&lt;/p&gt;
&lt;p&gt;
p$^3$VAE: a physics-integrated generative model. Application to the semantic segmentation of optical remote sensing images. (arXiv:2210.10418v3 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.10418
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;p$^3$VAE&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#23558;&#19968;&#20010;&#23436;&#32654;&#30340;&#29289;&#29702;&#27169;&#22411;&#38598;&#25104;&#21040;&#27169;&#22411;&#20013;&#65292;&#24182;&#24212;&#29992;&#20110;&#39640;&#20998;&#36776;&#29575;&#39640;&#20809;&#35889;&#36965;&#24863;&#22270;&#20687;&#30340;&#35821;&#20041;&#20998;&#21106;&#12290;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#22806;&#25512;&#33021;&#21147;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#21516;&#26102;&#20855;&#26377;&#39640;&#24230;&#35299;&#32533;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19982;&#29289;&#29702;&#27169;&#22411;&#30456;&#32467;&#21512;&#26159;&#23398;&#20064;&#24378;&#22823;&#25968;&#25454;&#34920;&#31034;&#30340;&#26368;&#26032;&#30740;&#31350;&#26041;&#21521;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;p$^3$VAE&#65292;&#36825;&#26159;&#19968;&#20010;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#38598;&#25104;&#20102;&#19968;&#20010;&#23436;&#32654;&#30340;&#29289;&#29702;&#27169;&#22411;&#65292;&#37096;&#20998;&#35299;&#37322;&#20102;&#25968;&#25454;&#20013;&#30495;&#23454;&#30340;&#21464;&#21270;&#22240;&#32032;&#12290;&#20026;&#20102;&#20805;&#20998;&#21033;&#29992;&#25105;&#20204;&#30340;&#28151;&#21512;&#35774;&#35745;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#30417;&#30563;&#20248;&#21270;&#36807;&#31243;&#21644;&#19968;&#31181;&#25512;&#26029;&#26041;&#26696;&#65292;&#21516;&#26102;&#20276;&#38543;&#30528;&#26377;&#24847;&#20041;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#25105;&#20204;&#23558;p$^3$VAE&#24212;&#29992;&#20110;&#39640;&#20998;&#36776;&#29575;&#39640;&#20809;&#35889;&#36965;&#24863;&#22270;&#20687;&#30340;&#35821;&#20041;&#20998;&#21106;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#27169;&#25311;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#19982;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#28151;&#21512;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#22806;&#25512;&#33021;&#21147;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;p$^3$VAE&#33258;&#28982;&#20855;&#26377;&#39640;&#24230;&#35299;&#32533;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#21644;&#25968;&#25454;&#24050;&#22312;https://github.com/Romain3Ch216/p3VAE&#19978;&#20844;&#24320;&#21457;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
The combination of machine learning models with physical models is a recent research path to learn robust data representations. In this paper, we introduce p$^3$VAE, a generative model that integrates a perfect physical model which partially explains the true underlying factors of variation in the data. To fully leverage our hybrid design, we propose a semi-supervised optimization procedure and an inference scheme that comes along meaningful uncertainty estimates. We apply p$^3$VAE to the semantic segmentation of high-resolution hyperspectral remote sensing images. Our experiments on a simulated data set demonstrated the benefits of our hybrid model against conventional machine learning models in terms of extrapolation capabilities and interpretability. In particular, we show that p$^3$VAE naturally has high disentanglement capabilities. Our code and data have been made publicly available at https://github.com/Romain3Ch216/p3VAE.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#20851;&#31995;&#25968;&#25454;&#30340;&#20998;&#35299;&#34701;&#21512;&#21387;&#32553;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#20998;&#35299;&#30697;&#38453;&#30340;&#34892;&#21521;&#37327;&#30340;&#36880;&#27425;&#24046;&#20540;&#26045;&#21152;&#20840;&#23616;-&#23616;&#37096;&#21387;&#32553;&#20808;&#39564;&#33719;&#24471;&#25910;&#32553;&#65292;&#24182;&#20855;&#26377;&#35768;&#22810;&#26377;&#21033;&#30340;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2210.00091</link><description>&lt;p&gt;
&#21160;&#24577;&#20851;&#31995;&#25968;&#25454;&#30340;&#20998;&#35299;&#34701;&#21512;&#21387;&#32553;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Factorized Fusion Shrinkage for Dynamic Relational Data. (arXiv:2210.00091v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.00091
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#20851;&#31995;&#25968;&#25454;&#30340;&#20998;&#35299;&#34701;&#21512;&#21387;&#32553;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#20998;&#35299;&#30697;&#38453;&#30340;&#34892;&#21521;&#37327;&#30340;&#36880;&#27425;&#24046;&#20540;&#26045;&#21152;&#20840;&#23616;-&#23616;&#37096;&#21387;&#32553;&#20808;&#39564;&#33719;&#24471;&#25910;&#32553;&#65292;&#24182;&#20855;&#26377;&#35768;&#22810;&#26377;&#21033;&#30340;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#25968;&#25454;&#31185;&#23398;&#24212;&#29992;&#32463;&#24120;&#28041;&#21450;&#20855;&#26377;&#21160;&#24577;&#32467;&#26500;&#30340;&#22797;&#26434;&#20851;&#31995;&#25968;&#25454;&#12290;&#27492;&#31867;&#21160;&#24577;&#20851;&#31995;&#25968;&#25454;&#30340;&#31361;&#21464;&#36890;&#24120;&#20986;&#29616;&#22312;&#30001;&#20110;&#24178;&#39044;&#32780;&#32463;&#21382;&#21046;&#24230;&#21464;&#21270;&#30340;&#31995;&#32479;&#20013;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#32771;&#34385;&#19968;&#31181;&#20998;&#35299;&#34701;&#21512;&#21387;&#32553;&#27169;&#22411;&#65292;&#20854;&#20013;&#25152;&#26377;&#20998;&#35299;&#22240;&#23376;&#37117;&#34987;&#21160;&#24577;&#22320;&#25910;&#32553;&#21040;&#32452;&#20869;&#34701;&#21512;&#32467;&#26500;&#65292;&#25910;&#32553;&#36890;&#36807;&#23545;&#20998;&#35299;&#30697;&#38453;&#30340;&#34892;&#21521;&#37327;&#30340;&#36880;&#27425;&#24046;&#20540;&#26045;&#21152;&#20840;&#23616;-&#23616;&#37096;&#21387;&#32553;&#20808;&#39564;&#26469;&#33719;&#24471;&#12290;&#25152;&#25552;&#20986;&#30340;&#20808;&#39564;&#22312;&#20272;&#35745;&#30340;&#21160;&#24577;&#28508;&#22312;&#22240;&#23376;&#30340;&#27604;&#36739;&#21644;&#32858;&#31867;&#26041;&#38754;&#20855;&#26377;&#35768;&#22810;&#26377;&#21033;&#30340;&#24615;&#36136;&#12290;&#27604;&#36739;&#20272;&#35745;&#30340;&#28508;&#22312;&#22240;&#23376;&#28041;&#21450;&#30456;&#37051;&#21644;&#38271;&#26399;&#27604;&#36739;&#65292;&#32771;&#34385;&#21040;&#27604;&#36739;&#30340;&#26102;&#38388;&#33539;&#22260;&#20316;&#20026;&#21464;&#37327;&#12290;&#22312;&#26576;&#20123;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#21518;&#39564;&#20998;&#24067;&#36798;&#21040;&#26368;&#23567;&#21270;&#26368;&#22823;&#39118;&#38505;&#65292;&#30452;&#21040;&#23545;&#25968;&#22240;&#23376;&#12290;&#22312;&#35745;&#31639;&#26041;&#38754;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32467;&#26500;&#21270;&#30340;&#22343;&#20540;&#22330;&#21464;&#20998;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern data science applications often involve complex relational data with dynamic structures. An abrupt change in such dynamic relational data is typically observed in systems that undergo regime changes due to interventions. In such a case, we consider a factorized fusion shrinkage model in which all decomposed factors are dynamically shrunk towards group-wise fusion structures, where the shrinkage is obtained by applying global-local shrinkage priors to the successive differences of the row vectors of the factorized matrices. The proposed priors enjoy many favorable properties in comparison and clustering of the estimated dynamic latent factors. Comparing estimated latent factors involves both adjacent and long-term comparisons, with the time range of comparison considered as a variable. Under certain conditions, we demonstrate that the posterior distribution attains the minimax optimal rate up to logarithmic factors. In terms of computation, we present a structured mean-field vari
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#20219;&#21153;&#31232;&#30095;&#22238;&#24402;&#30340;&#36873;&#25321;&#25512;&#26029;&#26694;&#26550;&#65292;&#22312;&#31070;&#32463;&#24433;&#20687;&#23398;&#20013;&#24212;&#29992;&#65292;&#21487;&#20197;&#25552;&#39640;&#24314;&#27169;&#31934;&#24230;&#21644;&#39044;&#27979;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2205.14220</link><description>&lt;p&gt;
&#22810;&#20219;&#21153;&#31232;&#30095;&#22238;&#24402;&#30340;&#36873;&#25321;&#25512;&#26029;&#21450;&#20854;&#22312;&#31070;&#32463;&#24433;&#20687;&#23398;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Selective Inference for Sparse Multitask Regression with Applications in Neuroimaging. (arXiv:2205.14220v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.14220
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#20219;&#21153;&#31232;&#30095;&#22238;&#24402;&#30340;&#36873;&#25321;&#25512;&#26029;&#26694;&#26550;&#65292;&#22312;&#31070;&#32463;&#24433;&#20687;&#23398;&#20013;&#24212;&#29992;&#65292;&#21487;&#20197;&#25552;&#39640;&#24314;&#27169;&#31934;&#24230;&#21644;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20219;&#21153;&#23398;&#20064;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#20174;&#21516;&#19968;&#29305;&#24449;&#38598;&#20013;&#27169;&#25311;&#19968;&#32452;&#30456;&#20851;&#21709;&#24212;&#21464;&#37327;&#65292;&#30456;&#27604;&#20110;&#21333;&#29420;&#22788;&#29702;&#27599;&#20010;&#21709;&#24212;&#21464;&#37327;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#21644;&#24314;&#27169;&#31934;&#24230;&#12290;&#20294;&#22810;&#20219;&#21153;&#23398;&#20064;&#22312;&#25512;&#26029;&#19981;&#30830;&#23450;&#24615;&#26041;&#38754;&#30340;&#30740;&#31350;&#36824;&#36739;&#23569;&#12290;&#26412;&#25991;&#36890;&#36807;&#31232;&#30095;&#24615;&#20449;&#21495;&#21152;&#24378;&#26041;&#27861;&#65292;&#38024;&#23545;&#31070;&#32463;&#24433;&#20687;&#23398;&#20013;&#30340;&#24120;&#35265;&#22810;&#20219;&#21153;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36873;&#25321;&#25512;&#26029;&#26694;&#26550;&#65292;&#20855;&#26377;&#28789;&#27963;&#24615;&#65292;&#21487;&#20197;&#21516;&#26102;&#35782;&#21035;&#20986;&#27599;&#20010;&#20219;&#21153;&#30456;&#20851;&#30340;&#21327;&#21464;&#37327;&#65292;&#24182;&#24314;&#31435;&#22522;&#20110;&#31232;&#30095;&#32467;&#26500;&#30340;&#26377;&#25928;&#25512;&#26029;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-task learning is frequently used to model a set of related response variables from the same set of features, improving predictive performance and modeling accuracy relative to methods that handle each response variable separately. Despite the potential of multi-task learning to yield more powerful inference than single-task alternatives, prior work in this area has largely omitted uncertainty quantification. Our focus in this paper is a common multi-task problem in neuroimaging, where the goal is to understand the relationship between multiple cognitive task scores (or other subject-level assessments) and brain connectome data collected from imaging. We propose a framework for selective inference to address this problem, with the flexibility to: (i) jointly identify the relevant covariates for each task through a sparsity-inducing penalty, and (ii) conduct valid inference in a model based on the estimated sparsity structure. Our framework offers a new conditional procedure for in
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26159;&#20851;&#20110;&#23558;&#24378;&#21270;&#23398;&#20064;&#24212;&#29992;&#20110;&#33258;&#36866;&#24212;&#24178;&#39044;&#20013;&#30340;&#31532;&#19968;&#20221;&#32479;&#19968;&#35843;&#26597;&#65292;&#24378;&#21270;&#23398;&#20064;&#22312;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#21644;&#31227;&#21160;&#20581;&#24247;&#20013;&#21363;&#26102;&#33258;&#36866;&#24212;&#24178;&#39044;&#36825;&#20004;&#20010;&#39046;&#22495;&#20013;&#37117;&#20855;&#26377;&#24456;&#22823;&#30340;&#24212;&#29992;&#28508;&#21147;&#12290;&#22312;&#36825;&#20004;&#20010;&#39046;&#22495;&#20043;&#38388;&#23384;&#22312;&#30456;&#20284;&#21644;&#19981;&#21516;&#20043;&#22788;&#38656;&#35201;&#32771;&#34385;&#65292;&#24182;&#19988;&#36825;&#37324;&#23384;&#22312;&#24040;&#22823;&#30340;&#21512;&#20316;&#26426;&#20250;&#12290;</title><link>http://arxiv.org/abs/2203.02605</link><description>&lt;p&gt;
&#29616;&#20195;&#29983;&#29289;&#32479;&#35745;&#20013;&#30340;&#24378;&#21270;&#23398;&#20064;&#65306;&#26500;&#24314;&#26368;&#20248;&#33258;&#36866;&#24212;&#24178;&#39044;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning in Modern Biostatistics: Constructing Optimal Adaptive Interventions. (arXiv:2203.02605v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.02605
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26159;&#20851;&#20110;&#23558;&#24378;&#21270;&#23398;&#20064;&#24212;&#29992;&#20110;&#33258;&#36866;&#24212;&#24178;&#39044;&#20013;&#30340;&#31532;&#19968;&#20221;&#32479;&#19968;&#35843;&#26597;&#65292;&#24378;&#21270;&#23398;&#20064;&#22312;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#21644;&#31227;&#21160;&#20581;&#24247;&#20013;&#21363;&#26102;&#33258;&#36866;&#24212;&#24178;&#39044;&#36825;&#20004;&#20010;&#39046;&#22495;&#20013;&#37117;&#20855;&#26377;&#24456;&#22823;&#30340;&#24212;&#29992;&#28508;&#21147;&#12290;&#22312;&#36825;&#20004;&#20010;&#39046;&#22495;&#20043;&#38388;&#23384;&#22312;&#30456;&#20284;&#21644;&#19981;&#21516;&#20043;&#22788;&#38656;&#35201;&#32771;&#34385;&#65292;&#24182;&#19988;&#36825;&#37324;&#23384;&#22312;&#24040;&#22823;&#30340;&#21512;&#20316;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#22312;&#19982;&#20581;&#24247;&#30456;&#20851;&#30340;&#24207;&#21015;&#24615;&#20915;&#31574;&#20013;&#21344;&#25454;&#20102;&#37325;&#35201;&#22320;&#20301;&#65292;&#25104;&#20026;&#20132;&#20184;&#33258;&#36866;&#24212;&#24178;&#39044;&#65288;AIs&#65289;&#30340;&#36234;&#26469;&#36234;&#27969;&#34892;&#30340;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#20855;&#26377;&#28508;&#22312;&#20248;&#21183;&#65292;&#20294;&#20854;&#29616;&#23454;&#24212;&#29992;&#20173;&#28982;&#21463;&#21040;&#38480;&#21046;&#65292;&#37096;&#20998;&#26159;&#30001;&#20110;&#26041;&#27861;&#35770;&#21644;&#24212;&#29992;&#31038;&#21306;&#20043;&#38388;&#30340;&#21327;&#21516;&#19981;&#36275;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#23398;&#20064;AIs&#30340;RL&#26041;&#27861;&#30340;&#31532;&#19968;&#20221;&#32479;&#19968;&#35843;&#26597;&#65292;&#21033;&#29992;RL&#30340;&#36890;&#29992;&#26041;&#27861;&#35770;&#20254;&#26469;&#26725;&#25509;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#21644;&#31227;&#21160;&#20581;&#24247;&#20013;&#21363;&#26102;&#33258;&#36866;&#24212;&#24178;&#39044;&#36825;&#20004;&#20010;AI&#39046;&#22495;&#12290;&#25105;&#20204;&#27010;&#36848;&#20102;&#36825;&#20004;&#20010;AI&#39046;&#22495;&#20043;&#38388;&#30340;&#24322;&#21516;&#65292;&#24182;&#35752;&#35770;&#20102;&#23427;&#20204;&#23545;&#20351;&#29992;RL&#30340;&#24433;&#21709;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#33258;&#24049;&#22312;&#20004;&#20010;&#39046;&#22495;&#20013;&#35774;&#35745;&#26696;&#20363;&#30740;&#31350;&#30340;&#32463;&#39564;&#65292;&#35828;&#26126;&#20102;&#22312;AIs&#39046;&#22495;&#20013;&#65292;&#32479;&#35745;&#23398;&#12289;RL&#21644;&#21307;&#30103;&#30740;&#31350;&#20154;&#21592;&#20043;&#38388;&#30340;&#24040;&#22823;&#21512;&#20316;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, reinforcement learning (RL) has acquired a prominent position in the space of health-related sequential decision-making, becoming an increasingly popular tool for delivering adaptive interventions (AIs). However, despite potential benefits, its real-life application is still limited, partly due to a poor synergy between the methodological and the applied communities. In this work, we provide the first unified survey on RL methods for learning AIs, using the common methodological umbrella of RL to bridge the two AI areas of dynamic treatment regimes and just-in-time adaptive interventions in mobile health. We outline similarities and differences between these two AI domains and discuss their implications for using RL. Finally, we leverage our experience in designing case studies in both areas to illustrate the tremendous collaboration opportunities between statistical, RL, and healthcare researchers in the space of AIs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212; (CATE) &#30340;&#20272;&#35745;&#38382;&#39064;&#65292;&#22312;&#32570;&#22833;&#27835;&#30103;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20986;&#20102;&#32570;&#22833;&#27835;&#30103;&#34920;&#31034;&#32593;&#32476; (MTRNet)&#65292;&#36890;&#36807;&#22495;&#33258;&#36866;&#24212;&#23398;&#20064;&#21327;&#21464;&#37327;&#30340;&#24179;&#34913;&#34920;&#31034;&#26469;&#35299;&#20915;&#21327;&#21464;&#37327;&#36716;&#31227;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2203.01422</link><description>&lt;p&gt;
&#32570;&#22833;&#27835;&#30103;&#20449;&#24687;&#30340;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Estimating Conditional Average Treatment Effects with Missing Treatment Information. (arXiv:2203.01422v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.01422
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212; (CATE) &#30340;&#20272;&#35745;&#38382;&#39064;&#65292;&#22312;&#32570;&#22833;&#27835;&#30103;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20986;&#20102;&#32570;&#22833;&#27835;&#30103;&#34920;&#31034;&#32593;&#32476; (MTRNet)&#65292;&#36890;&#36807;&#22495;&#33258;&#36866;&#24212;&#23398;&#20064;&#21327;&#21464;&#37327;&#30340;&#24179;&#34913;&#34920;&#31034;&#26469;&#35299;&#20915;&#21327;&#21464;&#37327;&#36716;&#31227;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212; (CATE) &#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#29305;&#21035;&#26159;&#22312;&#27835;&#30103;&#20449;&#24687;&#32570;&#22833;&#30340;&#24773;&#20917;&#19979;&#12290;&#23613;&#31649;&#22312;&#23454;&#36341;&#20013;&#36825;&#26159;&#19968;&#20010;&#26222;&#36941;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#20294;&#32570;&#22833;&#27835;&#30103;&#30340; CATE &#20272;&#35745;&#21364;&#21463;&#21040;&#20102;&#24456;&#23569;&#20851;&#27880;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#32570;&#22833;&#27835;&#30103;&#24773;&#20917;&#19979;&#30340; CATE &#20272;&#35745;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#23384;&#22312;&#29420;&#29305;&#30340;&#25361;&#25112;&#65292;&#20363;&#22914;&#21327;&#21464;&#37327;&#20559;&#31227;&#12290;&#25105;&#20204;&#35748;&#23450;&#20102;&#25105;&#20204;&#30340;&#24773;&#20917;&#20013;&#23384;&#22312;&#20004;&#31181;&#21327;&#21464;&#37327;&#36716;&#31227;&#65306;(i) &#27835;&#30103;&#32452;&#21644;&#23545;&#29031;&#32452;&#20043;&#38388;&#30340;&#21327;&#21464;&#37327;&#36716;&#31227;&#65292;&#20197;&#21450;(ii) &#35266;&#23519;&#21040;&#30340;&#27835;&#30103;&#32452;&#21644;&#32570;&#22833;&#27835;&#30103;&#32452;&#20043;&#38388;&#30340;&#21327;&#21464;&#37327;&#36716;&#31227;&#12290;&#25105;&#20204;&#39318;&#20808;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#36825;&#20123;&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#20026;&#25105;&#20204;&#30340;&#32570;&#22833;&#27835;&#30103;&#24773;&#20917;&#19979;&#30340; CATE &#20272;&#35745;&#23548;&#20986;&#19968;&#20010;&#27867;&#21270;&#30028;&#38480;&#12290;&#28982;&#21518;&#65292;&#21463;&#21040;&#25105;&#20204;&#30340;&#30028;&#38480;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#32570;&#22833;&#27835;&#30103;&#34920;&#31034;&#32593;&#32476; (MTRNet)&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340; CATE &#20272;&#35745;&#31639;&#27861;&#65292;&#23427;&#20351;&#29992;&#22495;&#33258;&#36866;&#24212;&#23398;&#20064;&#21327;&#21464;&#37327;&#30340;&#24179;&#34913;&#34920;&#31034;&#12290;&#36890;&#36807;&#20351;&#29992;&#24179;&#34913;&#30340;&#34920;&#31034;&#26041;&#27861;&#65292;MTRNet&#25552;&#20379;&#20102;
&lt;/p&gt;
&lt;p&gt;
Estimating conditional average treatment effects (CATE) is challenging, especially when treatment information is missing. Although this is a widespread problem in practice, CATE estimation with missing treatments has received little attention. In this paper, we analyze CATE estimation in the setting with missing treatments where unique challenges arise in the form of covariate shifts. We identify two covariate shifts in our setting: (i) a covariate shift between the treated and control population; and (ii) a covariate shift between the observed and missing treatment population. We first theoretically show the effect of these covariate shifts by deriving a generalization bound for estimating CATE in our setting with missing treatments. Then, motivated by our bound, we develop the missing treatment representation network (MTRNet), a novel CATE estimation algorithm that learns a balanced representation of covariates using domain adaptation. By using balanced representations, MTRNet provid
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22312;&#32447;&#23376;&#37319;&#26679;&#26694;&#26550;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#21033;&#29992;&#25968;&#25454;&#28857;&#30340;&#20449;&#24687;&#22686;&#30410;&#37327;&#26469;&#25351;&#23548;&#25506;&#32034;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#26356;&#26032;RL&#31639;&#27861;&#30340;&#31574;&#30053;&#27425;&#25968;&#22823;&#22823;&#20943;&#23569;&#65292;&#20294;&#20173;&#20445;&#25345;&#36739;&#23567;&#30340;&#36817;&#20284;&#26368;&#20248;&#36951;&#25022;&#36793;&#30028;&#12290;</title><link>http://arxiv.org/abs/2106.07203</link><description>&lt;p&gt;
&#22522;&#20110;&#26222;&#36866;&#20989;&#25968;&#36924;&#36817;&#30340;&#24378;&#21270;&#23398;&#20064;&#30340;&#22312;&#32447;&#23376;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Online Sub-Sampling for Reinforcement Learning with General Function Approximation. (arXiv:2106.07203v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.07203
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22312;&#32447;&#23376;&#37319;&#26679;&#26694;&#26550;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#21033;&#29992;&#25968;&#25454;&#28857;&#30340;&#20449;&#24687;&#22686;&#30410;&#37327;&#26469;&#25351;&#23548;&#25506;&#32034;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#26356;&#26032;RL&#31639;&#27861;&#30340;&#31574;&#30053;&#27425;&#25968;&#22823;&#22823;&#20943;&#23569;&#65292;&#20294;&#20173;&#20445;&#25345;&#36739;&#23567;&#30340;&#36817;&#20284;&#26368;&#20248;&#36951;&#25022;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#22823;&#22810;&#25968;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#26222;&#36866;&#20989;&#25968;&#36924;&#36817;&#65288;FA&#65289;&#26041;&#27861;&#37117;&#19987;&#27880;&#20110;&#29702;&#35299;&#32479;&#35745;&#22797;&#26434;&#24615;&#25110;&#36951;&#25022;&#36793;&#30028;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#36828;&#26410;&#24471;&#21040;&#29702;&#35299;&#8212;&#8212;&#20107;&#23454;&#19978;&#65292;&#20989;&#25968;&#31867;&#19978;&#30340;&#31616;&#21333;&#20248;&#21270;&#38382;&#39064;&#21487;&#33021;&#21516;&#26679;&#38590;&#20197;&#22788;&#29702;&#12290;&#26412;&#25991;&#36890;&#36807;&#24314;&#31435;&#19968;&#31181;&#39640;&#25928;&#30340;&#22312;&#32447;&#23376;&#37319;&#26679;&#26694;&#26550;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#35813;&#26694;&#26550;&#27979;&#37327;RL&#31639;&#27861;&#25910;&#38598;&#30340;&#25968;&#25454;&#28857;&#30340;&#20449;&#24687;&#22686;&#30410;&#65292;&#24182;&#20351;&#29992;&#35813;&#27979;&#37327;&#25351;&#23548;&#25506;&#32034;&#12290;&#23545;&#20110;&#22522;&#20110;&#20215;&#20540;&#30340;&#26041;&#27861;&#21644;&#22797;&#26434;&#24230;&#26377;&#30028;&#30340;&#20989;&#25968;&#31867;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#31574;&#30053;&#21482;&#38656;&#35201;&#26356;&#26032;$\propto\operatorname{poly}\log(K)$ &#27425;&#65292;&#23601;&#21487;&#20197;&#36816;&#34892; $K$ &#27425;RL&#31639;&#27861;&#32780;&#20173;&#28982;&#23454;&#29616;&#36739;&#23567;&#30340;&#36817;&#20284;&#26368;&#20248;&#36951;&#25022;&#36793;&#30028;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#26356;&#26032;&#31574;&#30053;&#33267;&#23569;&#35201; $\Omega(K)$ &#27425;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22823;&#22823;&#20943;&#23569;&#20102;&#35299;&#20915;&#26041;&#26696;&#20013;&#30340;&#20248;&#21270;&#35843;&#29992;&#27425;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most of the existing works for reinforcement learning (RL) with general function approximation (FA) focus on understanding the statistical complexity or regret bounds. However, the computation complexity of such approaches is far from being understood -- indeed, a simple optimization problem over the function class might be as well intractable. In this paper, we tackle this problem by establishing an efficient online sub-sampling framework that measures the information gain of data points collected by an RL algorithm and uses the measurement to guide exploration. For a value-based method with complexity-bounded function class, we show that the policy only needs to be updated for $\propto\operatorname{poly}\log(K)$ times for running the RL algorithm for $K$ episodes while still achieving a small near-optimal regret bound. In contrast to existing approaches that update the policy for at least $\Omega(K)$ times, our approach drastically reduces the number of optimization calls in solving 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35889;&#29702;&#35770;&#35745;&#31639;Riemannian Mat&#233;rn&#39640;&#26031;&#36807;&#31243;&#22312;&#32039;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#26680;&#65292;&#20351;&#20854;&#21487;&#20197;&#36890;&#36807;&#26631;&#20934;&#30340;&#21487;&#25193;&#23637;&#25216;&#26415;&#36827;&#34892;&#35757;&#32451;&#12290;&#36825;&#23558;&#25512;&#21160;Mat&#233;rn&#39640;&#26031;&#36807;&#31243;&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2006.10160</link><description>&lt;p&gt;
Matern&#39640;&#26031;&#36807;&#31243;&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Mat\'ern Gaussian processes on Riemannian manifolds. (arXiv:2006.10160v6 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.10160
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35889;&#29702;&#35770;&#35745;&#31639;Riemannian Mat&#233;rn&#39640;&#26031;&#36807;&#31243;&#22312;&#32039;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#26680;&#65292;&#20351;&#20854;&#21487;&#20197;&#36890;&#36807;&#26631;&#20934;&#30340;&#21487;&#25193;&#23637;&#25216;&#26415;&#36827;&#34892;&#35757;&#32451;&#12290;&#36825;&#23558;&#25512;&#21160;Mat&#233;rn&#39640;&#26031;&#36807;&#31243;&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#27169;&#22411;&#31867;&#65292;&#29305;&#21035;&#26159;&#22312;&#31934;&#30830;&#34920;&#31034;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#24456;&#37325;&#35201;&#30340;&#24773;&#20917;&#19979;&#12290;&#21463;&#29289;&#29702;&#31185;&#23398;&#24212;&#29992;&#30340;&#21551;&#21457;&#65292;&#26368;&#36817;&#23558;&#24191;&#27867;&#20351;&#29992;&#30340;Mat&#233;rn&#39640;&#26031;&#36807;&#31243;&#25512;&#24191;&#21040;&#27169;&#25311;&#23450;&#20041;&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#20989;&#25968;&#65292;&#36890;&#36807;&#23558;&#36825;&#20123;&#36807;&#31243;&#37325;&#26032;&#34920;&#31034;&#20026;&#38543;&#26426;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#35299;&#26469;&#23454;&#29616;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36890;&#36807;&#25289;&#26222;&#25289;&#26031;-&#36125;&#23572;&#29305;&#25289;&#31859;&#31639;&#23376;&#30340;&#35889;&#29702;&#35770;&#22312;&#32039;&#40654;&#26364;&#27969;&#24418;&#19978;&#35745;&#31639;&#36825;&#20123;&#36807;&#31243;&#30340;&#26680;&#24515;&#25216;&#26415;&#65292;&#20174;&#32780;&#20351;&#23427;&#20204;&#21487;&#20197;&#36890;&#36807;&#26631;&#20934;&#21487;&#25193;&#23637;&#25216;&#26415;&#65288;&#20363;&#22914;&#35825;&#23548;&#28857;&#26041;&#27861;&#65289;&#36827;&#34892;&#35757;&#32451;&#12290;&#25105;&#20204;&#36824;&#23558;&#35813;&#25512;&#24191;&#20174;Mat&#233;rn&#25512;&#24191;&#21040;&#24191;&#27867;&#20351;&#29992;&#30340;&#24179;&#26041;&#25351;&#25968;&#39640;&#26031;&#36807;&#31243;&#12290;&#36890;&#36807;&#20801;&#35768;&#20351;&#29992;&#20247;&#25152;&#21608;&#30693;&#30340;&#25216;&#26415;&#23545;Riemannian Mat&#233;rn&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#35757;&#32451;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#20351;&#23427;&#20204;&#33021;&#22815;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes are an effective model class for learning unknown functions, particularly in settings where accurately representing predictive uncertainty is of key importance. Motivated by applications in the physical sciences, the widely-used Mat\'ern class of Gaussian processes has recently been generalized to model functions whose domains are Riemannian manifolds, by re-expressing said processes as solutions of stochastic partial differential equations. In this work, we propose techniques for computing the kernels of these processes on compact Riemannian manifolds via spectral theory of the Laplace-Beltrami operator in a fully constructive manner, thereby allowing them to be trained via standard scalable techniques such as inducing point methods. We also extend the generalization from the Mat\'ern to the widely-used squared exponential Gaussian process. By allowing Riemannian Mat\'ern Gaussian processes to be trained using well-understood techniques, our work enables their use i
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25506;&#35752;&#20102;&#35299;&#20915;&#28145;&#24230;&#23398;&#20064;&#20013;&#20986;&#29616;&#30340;&#19968;&#31867;&#38750;&#20984;&#24378;&#20984;min-max&#38382;&#39064;&#30340;&#38543;&#26426;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36817;&#31471;&#38454;&#27573;&#30340;&#26041;&#27861;&#26694;&#26550;&#65292;&#20854;&#20013;&#23884;&#20837;&#20102;&#35768;&#22810;&#20247;&#25152;&#21608;&#30693;&#30340;&#38543;&#26426;&#26356;&#26032;&#65292;&#24555;&#36895;&#25910;&#25947;&#24615;&#24471;&#21040;&#20102;&#24314;&#31435;&#12290;</title><link>http://arxiv.org/abs/2006.06889</link><description>&lt;p&gt;
&#24555;&#36895;&#38754;&#21521;&#20855;&#26377;PL&#26465;&#20214;&#30340;&#38750;&#20984;&#24378;&#20984;min-max&#38382;&#39064;&#30340;&#30446;&#26631;&#21644;&#23545;&#20598;&#24046;&#25910;&#25947;(arXiv:2006.06889v8 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
Fast Objective &amp; Duality Gap Convergence for Non-Convex Strongly-Concave Min-Max Problems with PL Condition. (arXiv:2006.06889v8 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.06889
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25506;&#35752;&#20102;&#35299;&#20915;&#28145;&#24230;&#23398;&#20064;&#20013;&#20986;&#29616;&#30340;&#19968;&#31867;&#38750;&#20984;&#24378;&#20984;min-max&#38382;&#39064;&#30340;&#38543;&#26426;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36817;&#31471;&#38454;&#27573;&#30340;&#26041;&#27861;&#26694;&#26550;&#65292;&#20854;&#20013;&#23884;&#20837;&#20102;&#35768;&#22810;&#20247;&#25152;&#21608;&#30693;&#30340;&#38543;&#26426;&#26356;&#26032;&#65292;&#24555;&#36895;&#25910;&#25947;&#24615;&#24471;&#21040;&#20102;&#24314;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30528;&#37325;&#20110;&#35299;&#20915;&#24179;&#28369;&#38750;&#20984;&#24378;&#20984;min-max&#38382;&#39064;&#30340;&#38543;&#26426;&#26041;&#27861;&#65292;&#35813;&#38382;&#39064;&#30001;&#20110;&#20854;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#28508;&#22312;&#24212;&#29992;&#65288;&#22914;&#28145;&#24230;AUC&#26368;&#22823;&#21270;&#65292;&#20998;&#24067;&#24335;&#40065;&#26834;&#20248;&#21270;&#65289;&#32780;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#31639;&#27861;&#22312;&#23454;&#36341;&#20013;&#36739;&#24930;&#65292;&#24182;&#19988;&#23427;&#20204;&#30340;&#20998;&#26512;&#22260;&#32469;&#25910;&#25947;&#20110;&#25509;&#36817;&#31283;&#24577;&#28857;&#23637;&#24320;&#12290;&#25105;&#20204;&#32771;&#34385;&#21033;&#29992;Polyak-Lojasiewicz&#65288;PL&#65289;&#26465;&#20214;&#26469;&#35774;&#35745;&#26356;&#24555;&#30340;&#38543;&#26426;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#26356;&#24378;&#30340;&#25910;&#25947;&#20445;&#35777;&#12290;&#34429;&#28982;PL&#26465;&#20214;&#24050;&#32463;&#34987;&#29992;&#20110;&#35774;&#35745;&#35768;&#22810;&#38543;&#26426;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#20294;&#23427;&#20204;&#23545;&#20110;&#38750;&#20984;&#26497;&#23567;&#21270;&#26368;&#22823;&#21270;&#20248;&#21270;&#30340;&#24212;&#29992;&#20173;&#28982;&#24456;&#23569;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#20998;&#26512;&#20102;&#19968;&#20010;&#27867;&#21270;&#30340;&#22522;&#20110;&#36817;&#31471;&#38454;&#27573;&#30340;&#26041;&#27861;&#26694;&#26550;&#65292;&#20854;&#20013;&#23884;&#20837;&#20102;&#35768;&#22810;&#20247;&#25152;&#21608;&#30693;&#30340;&#38543;&#26426;&#26356;&#26032;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#22522;&#20110;&#21407;&#22987;&#30446;&#26631;&#38388;&#38553;&#21644;&#23545;&#20598;&#38388;&#38553;&#30340;&#24555;&#36895;&#25910;&#25947;&#24615;&#12290;&#19982;&#29616;&#26377;&#30740;&#31350;&#30456;&#27604;&#65292;&#65288;i&#65289;&#25105;&#20204;&#30340;&#20998;&#26512;&#26159;...
&lt;/p&gt;
&lt;p&gt;
This paper focuses on stochastic methods for solving smooth non-convex strongly-concave min-max problems, which have received increasing attention due to their potential applications in deep learning (e.g., deep AUC maximization, distributionally robust optimization). However, most of the existing algorithms are slow in practice, and their analysis revolves around the convergence to a nearly stationary point.We consider leveraging the Polyak-Lojasiewicz (PL) condition to design faster stochastic algorithms with stronger convergence guarantee. Although PL condition has been utilized for designing many stochastic minimization algorithms, their applications for non-convex min-max optimization remain rare. In this paper, we propose and analyze a generic framework of proximal stage-based method with many well-known stochastic updates embeddable. Fast convergence is established in terms of both the primal objective gap and the duality gap. Compared with existing studies, (i) our analysis is 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25193;&#23637;&#20102;&#22810;&#21464;&#37327;&#22823;&#25968;&#25454;&#20998;&#26512;&#65288;MBDA&#65289;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#25512;&#23548;&#29305;&#24449;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#32467;&#21512;&#21487;&#35299;&#37322;&#24615;&#21644;&#20132;&#20114;&#24335;&#27169;&#22411;&#30340;&#20248;&#21183;&#20197;&#21450;&#24182;&#34892;&#22788;&#29702;&#30340;&#33021;&#21147;&#65292;&#24212;&#29992;&#20110;&#32593;&#32476;&#30417;&#27979;&#21644;&#35786;&#26029;&#65292;&#26368;&#32456;&#22312;UGR'16&#21644;Dartmouth'18&#20004;&#20010;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#25104;&#21151;&#12290;</title><link>http://arxiv.org/abs/1907.02677</link><description>&lt;p&gt;
&#22810;&#21464;&#37327;&#22823;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#21487;&#35299;&#37322;&#24615;&#23398;&#20064;&#29992;&#20110;&#32593;&#32476;&#30417;&#27979;
&lt;/p&gt;
&lt;p&gt;
Interpretable Learning in Multivariate Big Data Analysis for Network Monitoring. (arXiv:1907.02677v2 [cs.NI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1907.02677
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25193;&#23637;&#20102;&#22810;&#21464;&#37327;&#22823;&#25968;&#25454;&#20998;&#26512;&#65288;MBDA&#65289;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#25512;&#23548;&#29305;&#24449;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#32467;&#21512;&#21487;&#35299;&#37322;&#24615;&#21644;&#20132;&#20114;&#24335;&#27169;&#22411;&#30340;&#20248;&#21183;&#20197;&#21450;&#24182;&#34892;&#22788;&#29702;&#30340;&#33021;&#21147;&#65292;&#24212;&#29992;&#20110;&#32593;&#32476;&#30417;&#27979;&#21644;&#35786;&#26029;&#65292;&#26368;&#32456;&#22312;UGR'16&#21644;Dartmouth'18&#20004;&#20010;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#25104;&#21151;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24320;&#21457;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#27169;&#22411;&#20197;&#35780;&#20272;&#36890;&#20449;&#32593;&#32476;&#24615;&#33021;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#12290;&#23545;&#20110;&#35768;&#22810;&#24212;&#29992;&#31243;&#24207;&#65292;&#27604;&#22914;&#32593;&#32476;&#30417;&#27979;&#21644;&#25925;&#38556;&#25490;&#38500;&#65292;&#22914;&#26524;&#19981;&#33021;&#34987;&#20154;&#31867;&#25805;&#20316;&#21592;&#35299;&#37322;&#65292;&#25968;&#25454;&#27169;&#22411;&#23601;&#27809;&#22810;&#22823;&#29992;&#22788;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22810;&#21464;&#37327;&#22823;&#25968;&#25454;&#20998;&#26512;&#65288;MBDA&#65289;&#26041;&#27861;&#30340;&#25193;&#23637;&#65292;&#36825;&#26159;&#19968;&#31181;&#36817;&#26399;&#25552;&#20986;&#30340;&#21487;&#35299;&#37322;&#24615;&#25968;&#25454;&#20998;&#26512;&#24037;&#20855;&#12290;&#22312;&#36825;&#20010;&#25193;&#23637;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#33258;&#21160;&#25512;&#23548;&#29305;&#24449;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36825;&#26159;&#24403;&#25968;&#25454;&#37327;&#24222;&#22823;&#26102;&#24212;&#29992;MBDA&#30340;&#37325;&#35201;&#27493;&#39588;&#12290;&#25152;&#24471;&#21040;&#30340;&#32593;&#32476;&#30417;&#27979;&#26041;&#27861;&#20801;&#35768;&#25105;&#20204;&#26816;&#27979;&#21644;&#35786;&#26029;&#19981;&#21516;&#30340;&#32593;&#32476;&#24322;&#24120;&#65292;&#37319;&#29992;&#19968;&#31181;&#23558;&#21487;&#35299;&#37322;&#24615;&#21644;&#20132;&#20114;&#24335;&#27169;&#22411;&#30340;&#20248;&#21183;&#19982;&#24182;&#34892;&#22788;&#29702;&#30340;&#33021;&#21147;&#30456;&#32467;&#21512;&#30340;&#25968;&#25454;&#20998;&#26512;&#24037;&#20316;&#27969;&#12290;&#25105;&#20204;&#23558;&#25193;&#23637;&#30340;MBDA&#24212;&#29992;&#20110;&#20004;&#20010;&#26696;&#20363;&#30740;&#31350;&#65306;UGR'16&#65292;&#29992;&#20110;&#24322;&#24120;&#26816;&#27979;&#30340;&#22522;&#20934;&#27969;&#37327;&#23454;&#38469;&#25968;&#25454;&#38598;&#65292;&#20197;&#21450;Dartmouth'18&#65292;&#26368;&#38271;&#21644;&#26368;&#20855;&#25361;&#25112;&#24615;&#30340;&#25968;&#25454;&#38598;&#20043;&#19968;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is an increasing interest in the development of new data-driven models useful to assess the performance of communication networks. For many applications, like network monitoring and troubleshooting, a data model is of little use if it cannot be interpreted by a human operator. In this paper, we present an extension of the Multivariate Big Data Analysis (MBDA) methodology, a recently proposed interpretable data analysis tool. In this extension, we propose a solution to the automatic derivation of features, a cornerstone step for the application of MBDA when the amount of data is massive. The resulting network monitoring approach allows us to detect and diagnose disparate network anomalies, with a data-analysis workflow that combines the advantages of interpretable and interactive models with the power of parallel processing. We apply the extended MBDA to two case studies: UGR'16, a benchmark flow-based real-traffic dataset for anomaly detection, and Dartmouth'18, the longest and l
&lt;/p&gt;</description></item></channel></rss>