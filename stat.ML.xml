<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#30340;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#21487;&#20197;&#35299;&#20915;&#36830;&#32493;&#26102;&#38388;&#20449;&#21495;&#30340;&#21435;&#21367;&#31215;&#38382;&#39064;&#65292;&#36866;&#29992;&#20110;&#35266;&#27979;&#20540;&#20013;&#21487;&#33021;&#23384;&#22312;&#32570;&#22833;&#25968;&#25454;&#19988;&#20449;&#21495;&#28388;&#27874;&#22120;&#26410;&#30693;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2305.04871</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#21435;&#21367;&#31215;&#38382;&#39064;&#30340;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Gaussian process deconvolution. (arXiv:2305.04871v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04871
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#30340;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#21487;&#20197;&#35299;&#20915;&#36830;&#32493;&#26102;&#38388;&#20449;&#21495;&#30340;&#21435;&#21367;&#31215;&#38382;&#39064;&#65292;&#36866;&#29992;&#20110;&#35266;&#27979;&#20540;&#20013;&#21487;&#33021;&#23384;&#22312;&#32570;&#22833;&#25968;&#25454;&#19988;&#20449;&#21495;&#28388;&#27874;&#22120;&#26410;&#30693;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#21435;&#21367;&#31215;&#38382;&#39064;&#65292;&#21363;&#20174;&#21367;&#31215;&#22788;&#29702;&#30340;&#35266;&#27979;&#20540; $\mathbf{y}$ &#20013;&#24674;&#22797;&#28508;&#22312;&#20449;&#21495; $x(\cdot)$&#65292;&#20854;&#20013;&#35266;&#27979;&#20540; $\mathbf{y}$ &#21487;&#33021;&#23545;&#24212;&#20110; $y$ &#30340;&#19968;&#37096;&#20998;&#32570;&#22833;&#65292;&#28388;&#27874;&#22120; $h$ &#21487;&#33021;&#26410;&#30693;&#19988;&#22122;&#22768; $\eta$ &#21487;&#21152;&#24615;&#12290;&#24403; $x$ &#26159;&#36830;&#32493;&#26102;&#38388;&#20449;&#21495;&#26102;&#65292;&#25105;&#20204;&#37319;&#29992;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#20808;&#39564;&#20998;&#24067;&#26469;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#38381;&#21512;&#30340;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#21435;&#21367;&#31215;&#31574;&#30053;&#12290;&#25105;&#20204;&#39318;&#20808;&#20998;&#26512;&#20102;&#30452;&#25509;&#27169;&#22411;&#65292;&#20197;&#24314;&#31435;&#20854;&#33391;&#22909;&#23450;&#20041;&#30340;&#26465;&#20214;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36716;&#21521;&#36870;&#38382;&#39064;&#65292;&#30740;&#31350;&#20102;&#65306;&#65288;i&#65289;&#19968;&#20123;&#24517;&#35201;&#26465;&#20214;&#65292;&#20351;&#24471;&#36125;&#21494;&#26031;&#21435;&#21367;&#31215;&#35745;&#31639;&#26377;&#21487;&#33021;&#25104;&#31435;&#65292;&#20197;&#21450;&#65288;ii&#65289;&#22312;&#21738;&#31181;&#31243;&#24230;&#19978;&#21487;&#20197;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#21040;&#28388;&#27874;&#22120; $h$&#65292;&#20197;&#21450;&#22312;&#30450;&#21435;&#21367;&#31215;&#24773;&#20917;&#19979;&#21487;&#20197;&#36817;&#20284;&#28388;&#27874;&#22120; $h$ &#30340;&#31243;&#24230;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#34987;&#31216;&#20026;&#39640;&#26031;&#36807;&#31243;&#21435;&#21367;&#31215;&#65288;GPDC&#65289;&#65292;&#24182;&#19982;&#20854;&#20182;&#21435;&#21367;&#31215;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Let us consider the deconvolution problem, that is, to recover a latent source $x(\cdot)$ from the observations $\y = [y_1,\ldots,y_N]$ of a convolution process $y = x\star h + \eta$, where $\eta$ is an additive noise, the observations in $\y$ might have missing parts with respect to $y$, and the filter $h$ could be unknown. We propose a novel strategy to address this task when $x$ is a continuous-time signal: we adopt a Gaussian process (GP) prior on the source $x$, which allows for closed-form Bayesian nonparametric deconvolution. We first analyse the direct model to establish the conditions under which the model is well defined. Then, we turn to the inverse problem, where we study i) some necessary conditions under which Bayesian deconvolution is feasible, and ii) to which extent the filter $h$ can be learnt from data or approximated for the blind deconvolution case. The proposed approach, termed Gaussian process deconvolution (GPDC) is compared to other deconvolution methods concep
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#26234;&#33021;&#20307;PPO&#31639;&#27861;&#65292;&#21033;&#29992;&#23616;&#37096;&#20248;&#21270;&#36798;&#21040;&#20840;&#23616;&#26368;&#20248;&#65292;&#20855;&#26377;&#32479;&#35745;&#20445;&#35777;&#65292;&#36825;&#26159;&#39318;&#20010;&#33021;&#22312;&#21327;&#20316;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#20013;&#35777;&#26126;&#25910;&#25947;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.04819</link><description>&lt;p&gt;
&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#23616;&#37096;&#20248;&#21270;&#36798;&#21040;&#20840;&#23616;&#26368;&#20248;
&lt;/p&gt;
&lt;p&gt;
Local Optimization Achieves Global Optimality in Multi-Agent Reinforcement Learning. (arXiv:2305.04819v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04819
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#26234;&#33021;&#20307;PPO&#31639;&#27861;&#65292;&#21033;&#29992;&#23616;&#37096;&#20248;&#21270;&#36798;&#21040;&#20840;&#23616;&#26368;&#20248;&#65292;&#20855;&#26377;&#32479;&#35745;&#20445;&#35777;&#65292;&#36825;&#26159;&#39318;&#20010;&#33021;&#22312;&#21327;&#20316;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#20013;&#35777;&#26126;&#25910;&#25947;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24102;&#20989;&#25968;&#36924;&#36817;&#30340;&#31574;&#30053;&#20248;&#21270;&#26041;&#27861;&#22312;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#22914;&#20309;&#35774;&#35745;&#20855;&#26377;&#32479;&#35745;&#20445;&#35777;&#30340;&#31639;&#27861;&#20173;&#28982;&#38590;&#20197;&#25417;&#25720;&#12290;&#21033;&#29992;&#22810;&#26234;&#33021;&#20307;&#34920;&#29616;&#24046;&#24322;&#24341;&#29702;&#65292;&#35813;&#24341;&#29702;&#34920;&#24449;&#20102;&#22810;&#26234;&#33021;&#20307;&#31574;&#30053;&#20248;&#21270;&#30340;&#28508;&#22312;&#31354;&#38388;&#65292;&#25105;&#20204;&#21457;&#29616;&#26412;&#22320;&#21270;&#30340;&#21160;&#20316;&#20215;&#20540;&#20989;&#25968;&#23545;&#20110;&#27599;&#20010;&#23616;&#37096;&#31574;&#30053;&#37117;&#21487;&#20197;&#20316;&#20026;&#29702;&#24819;&#30340;&#19979;&#38477;&#26041;&#21521;&#12290;&#26681;&#25454;&#36825;&#19968;&#35266;&#23519;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#26234;&#33021;&#20307;PPO&#31639;&#27861;&#65292;&#20854;&#20013;&#27599;&#20010;&#26234;&#33021;&#20307;&#30340;&#26412;&#22320;&#31574;&#30053;&#26356;&#26032;&#31867;&#20284;&#20110;vanilla PPO&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#23545;&#20110;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#21644;&#38382;&#39064;&#30456;&#20851;&#37327;&#30340;&#26631;&#20934;&#27491;&#21017;&#24615;&#26465;&#20214;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#20197;&#20122;&#32447;&#24615;&#36895;&#24230;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#31574;&#30053;&#12290;&#25105;&#20204;&#23558;&#31639;&#27861;&#25193;&#23637;&#21040;&#31163;&#32447;&#31574;&#30053;&#35774;&#32622;&#65292;&#24182;&#24341;&#20837;&#24754;&#35266;&#20027;&#20041;&#26469;&#35780;&#20272;&#31574;&#30053;&#65292;&#36825;&#19982;&#23454;&#39564;&#32467;&#26524;&#30456;&#31526;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#39318;&#20010;&#33021;&#22312;&#21327;&#20316;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#20013;&#35777;&#26126;&#25910;&#25947;&#30340;&#22810;&#26234;&#33021;&#20307;PPO&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Policy optimization methods with function approximation are widely used in multi-agent reinforcement learning. However, it remains elusive how to design such algorithms with statistical guarantees. Leveraging a multi-agent performance difference lemma that characterizes the landscape of multi-agent policy optimization, we find that the localized action value function serves as an ideal descent direction for each local policy. Motivated by the observation, we present a multi-agent PPO algorithm in which the local policy of each agent is updated similarly to vanilla PPO. We prove that with standard regularity conditions on the Markov game and problem-dependent quantities, our algorithm converges to the globally optimal policy at a sublinear rate. We extend our algorithm to the off-policy setting and introduce pessimism to policy evaluation, which aligns with experiments. To our knowledge, this is the first provably convergent multi-agent PPO algorithm in cooperative Markov games.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;CNN&#23398;&#20064;&#31354;&#38388;&#36807;&#31243;&#30340;&#20284;&#28982;&#20989;&#25968;&#12290;&#21363;&#20351;&#22312;&#27809;&#26377;&#30830;&#20999;&#20284;&#28982;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#20998;&#31867;&#20219;&#21153;&#36827;&#34892;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#65292;&#21487;&#20197;&#38544;&#24335;&#22320;&#23398;&#20064;&#20284;&#28982;&#20989;&#25968;&#12290;&#20351;&#29992;Platt&#32553;&#25918;&#21487;&#20197;&#25552;&#39640;&#31070;&#32463;&#20284;&#28982;&#38754;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.04634</link><description>&lt;p&gt;
&#31354;&#38388;&#36807;&#31243;&#30340;&#31070;&#32463;&#20284;&#28982;&#38754;
&lt;/p&gt;
&lt;p&gt;
Neural Likelihood Surfaces for Spatial Processes with Computationally Intensive or Intractable Likelihoods. (arXiv:2305.04634v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04634
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;CNN&#23398;&#20064;&#31354;&#38388;&#36807;&#31243;&#30340;&#20284;&#28982;&#20989;&#25968;&#12290;&#21363;&#20351;&#22312;&#27809;&#26377;&#30830;&#20999;&#20284;&#28982;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#20998;&#31867;&#20219;&#21153;&#36827;&#34892;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#65292;&#21487;&#20197;&#38544;&#24335;&#22320;&#23398;&#20064;&#20284;&#28982;&#20989;&#25968;&#12290;&#20351;&#29992;Platt&#32553;&#25918;&#21487;&#20197;&#25552;&#39640;&#31070;&#32463;&#20284;&#28982;&#38754;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31354;&#38388;&#32479;&#35745;&#20013;&#65292;&#24403;&#25311;&#21512;&#31354;&#38388;&#36807;&#31243;&#21040;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#26102;&#65292;&#24555;&#36895;&#20934;&#30830;&#30340;&#21442;&#25968;&#20272;&#35745;&#21644;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#25163;&#27573;&#21487;&#33021;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#22240;&#20026;&#20284;&#28982;&#20989;&#25968;&#21487;&#33021;&#35780;&#20272;&#32531;&#24930;&#25110;&#38590;&#20197;&#22788;&#29702;&#12290; &#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#23398;&#20064;&#31354;&#38388;&#36807;&#31243;&#30340;&#20284;&#28982;&#20989;&#25968;&#12290;&#36890;&#36807;&#29305;&#23450;&#35774;&#35745;&#30340;&#20998;&#31867;&#20219;&#21153;&#65292;&#25105;&#20204;&#30340;&#31070;&#32463;&#32593;&#32476;&#38544;&#24335;&#22320;&#23398;&#20064;&#20284;&#28982;&#20989;&#25968;&#65292;&#21363;&#20351;&#22312;&#27809;&#26377;&#26174;&#24335;&#21487;&#29992;&#30340;&#30830;&#20999;&#20284;&#28982;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#20063;&#21487;&#20197;&#23454;&#29616;&#12290;&#19968;&#26086;&#22312;&#20998;&#31867;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#35757;&#32451;&#65292;&#25105;&#20204;&#30340;&#31070;&#32463;&#32593;&#32476;&#20351;&#29992;Platt&#32553;&#25918;&#36827;&#34892;&#26657;&#20934;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#31070;&#32463;&#20284;&#28982;&#38754;&#30340;&#20934;&#30830;&#24615;&#12290;&#20026;&#20102;&#23637;&#31034;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#26469;&#33258;&#31070;&#32463;&#20284;&#28982;&#38754;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#21644;&#36817;&#20284;&#32622;&#20449;&#21306;&#38388;&#19982;&#20004;&#20010;&#19981;&#21516;&#31354;&#38388;&#36807;&#31243;&#65288;&#39640;&#26031;&#36807;&#31243;&#21644;&#23545;&#25968;&#39640;&#26031;Cox&#36807;&#31243;&#65289;&#30340;&#30456;&#24212;&#31934;&#30830;&#25110;&#36817;&#20284;&#30340;&#20284;&#28982;&#20989;&#25968;&#26500;&#25104;&#30340;&#31561;&#25928;&#29289;&#12290;
&lt;/p&gt;
&lt;p&gt;
In spatial statistics, fast and accurate parameter estimation coupled with a reliable means of uncertainty quantification can be a challenging task when fitting a spatial process to real-world data because the likelihood function might be slow to evaluate or intractable. In this work, we propose using convolutional neural networks (CNNs) to learn the likelihood function of a spatial process. Through a specifically designed classification task, our neural network implicitly learns the likelihood function, even in situations where the exact likelihood is not explicitly available. Once trained on the classification task, our neural network is calibrated using Platt scaling which improves the accuracy of the neural likelihood surfaces. To demonstrate our approach, we compare maximum likelihood estimates and approximate confidence regions constructed from the neural likelihood surface with the equivalent for exact or approximate likelihood for two different spatial processes: a Gaussian Pro
&lt;/p&gt;</description></item><item><title>Signature&#26680;&#20989;&#25968;&#26159;&#19968;&#31181;&#27491;&#23450;&#30340;&#39034;&#24207;&#25968;&#25454;&#26680;&#20989;&#25968;&#65292;&#20855;&#26377;&#39640;&#25928;&#30340;&#35745;&#31639;&#31639;&#27861;&#21644;&#24378;&#22823;&#30340;&#23454;&#35777;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.04625</link><description>&lt;p&gt;
&#12298;Signature Kernel&#12299;
&lt;/p&gt;
&lt;p&gt;
The Signature Kernel. (arXiv:2305.04625v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04625
&lt;/p&gt;
&lt;p&gt;
Signature&#26680;&#20989;&#25968;&#26159;&#19968;&#31181;&#27491;&#23450;&#30340;&#39034;&#24207;&#25968;&#25454;&#26680;&#20989;&#25968;&#65292;&#20855;&#26377;&#39640;&#25928;&#30340;&#35745;&#31639;&#31639;&#27861;&#21644;&#24378;&#22823;&#30340;&#23454;&#35777;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Signature&#26680;&#20989;&#25968;&#26159;&#29992;&#20110;&#39034;&#24207;&#25968;&#25454;&#30340;&#27491;&#23450;&#26680;&#20989;&#25968;&#12290;&#23427;&#32487;&#25215;&#20102;&#38543;&#26426;&#20998;&#26512;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#20855;&#26377;&#39640;&#25928;&#30340;&#35745;&#31639;&#31639;&#27861;&#65292;&#24182;&#19988;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#23454;&#35777;&#24615;&#33021;&#12290;&#22312;&#21363;&#23558;&#20986;&#29256;&#30340;Springer&#25163;&#20876;&#30340;&#36825;&#31687;&#31616;&#30701;&#35843;&#26597;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;Signature&#26680;&#20989;&#25968;&#24182;&#24378;&#35843;&#20102;&#36825;&#20123;&#29702;&#35770;&#21644;&#35745;&#31639;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
The signature kernel is a positive definite kernel for sequential data. It inherits theoretical guarantees from stochastic analysis, has efficient algorithms for computation, and shows strong empirical performance. In this short survey paper for a forthcoming Springer handbook, we give an elementary introduction to the signature kernel and highlight these theoretical and computational properties.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23558;&#38464;&#34746;&#30690;&#37327;&#31354;&#38388;&#20013;&#30340;&#19968;&#20123;&#27010;&#24565;&#25512;&#24191;&#21040;SPD&#21644;Grassmann&#27969;&#24418;&#65292;&#25552;&#20986;&#20102;&#22312;&#36825;&#20123;&#27969;&#24418;&#19978;&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#27169;&#22411;&#21644;&#26032;&#23618;&#65292;&#24182;&#22312;&#20154;&#31867;&#21160;&#20316;&#35782;&#21035;&#21644;&#30693;&#35782;&#22270;&#35889;&#23436;&#25104;&#20004;&#20010;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.04560</link><description>&lt;p&gt;
&#22522;&#20110;&#30697;&#38453;&#27969;&#24418;&#30340;&#31070;&#32463;&#32593;&#32476;&#26500;&#24314;&#65306;&#38464;&#34746;&#30690;&#37327;&#31354;&#38388;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Building Neural Networks on Matrix Manifolds: A Gyrovector Space Approach. (arXiv:2305.04560v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04560
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23558;&#38464;&#34746;&#30690;&#37327;&#31354;&#38388;&#20013;&#30340;&#19968;&#20123;&#27010;&#24565;&#25512;&#24191;&#21040;SPD&#21644;Grassmann&#27969;&#24418;&#65292;&#25552;&#20986;&#20102;&#22312;&#36825;&#20123;&#27969;&#24418;&#19978;&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#27169;&#22411;&#21644;&#26032;&#23618;&#65292;&#24182;&#22312;&#20154;&#31867;&#21160;&#20316;&#35782;&#21035;&#21644;&#30693;&#35782;&#22270;&#35889;&#23436;&#25104;&#20004;&#20010;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30697;&#38453;&#27969;&#24418;&#65292;&#22914;&#23545;&#31216;&#27491;&#23450;&#65288;SPD&#65289;&#30697;&#38453;&#21644;Grassmann&#27969;&#24418;&#65292;&#20986;&#29616;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#12290;&#26368;&#36817;&#65292;&#36890;&#36807;&#24212;&#29992;&#38464;&#34746;&#32676;&#21644;&#38464;&#34746;&#30690;&#37327;&#31354;&#38388;&#30340;&#29702;&#35770;&#8212;&#8212;&#36825;&#26159;&#19968;&#20010;&#30740;&#31350;&#21452;&#26354;&#20960;&#20309;&#30340;&#24378;&#22823;&#26694;&#26550;&#8212;&#8212;&#19968;&#20123;&#24037;&#20316;&#23581;&#35797;&#22312;&#30697;&#38453;&#27969;&#24418;&#19978;&#26500;&#24314;&#27431;&#20960;&#37324;&#24503;&#31070;&#32463;&#32593;&#32476;&#30340;&#21407;&#21017;&#24615;&#25512;&#24191;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#32570;&#20047;&#32771;&#34385;&#27969;&#24418;&#30340;&#20869;&#31215;&#21644;&#38464;&#34746;&#35282;&#31561;&#27010;&#24565;&#30340;&#38464;&#34746;&#30690;&#37327;&#31354;&#38388;&#65292;&#30456;&#27604;&#20110;&#29992;&#20110;&#30740;&#31350;&#21452;&#26354;&#20960;&#20309;&#30340;&#37027;&#20123;&#27010;&#24565;&#65292;&#36825;&#20123;&#24037;&#20316;&#25552;&#20379;&#30340;&#25216;&#26415;&#21644;&#25968;&#23398;&#24037;&#20855;&#20173;&#28982;&#26377;&#38480;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#38464;&#34746;&#30690;&#37327;&#31354;&#38388;&#20013;&#30340;&#19968;&#20123;&#27010;&#24565;&#25512;&#24191;&#21040;SPD&#21644;Grassmann&#27969;&#24418;&#65292;&#24182;&#25552;&#20986;&#20102;&#22312;&#36825;&#20123;&#27969;&#24418;&#19978;&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#27169;&#22411;&#21644;&#26032;&#23618;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20154;&#31867;&#21160;&#20316;&#35782;&#21035;&#21644;&#30693;&#35782;&#22270;&#35889;&#23436;&#25104;&#20004;&#20010;&#24212;&#29992;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Matrix manifolds, such as manifolds of Symmetric Positive Definite (SPD) matrices and Grassmann manifolds, appear in many applications. Recently, by applying the theory of gyrogroups and gyrovector spaces that is a powerful framework for studying hyperbolic geometry, some works have attempted to build principled generalizations of Euclidean neural networks on matrix manifolds. However, due to the lack of many concepts in gyrovector spaces for the considered manifolds, e.g., the inner product and gyroangles, techniques and mathematical tools provided by these works are still limited compared to those developed for studying hyperbolic geometry. In this paper, we generalize some notions in gyrovector spaces for SPD and Grassmann manifolds, and propose new models and layers for building neural networks on these manifolds. We show the effectiveness of our approach in two applications, i.e., human action recognition and knowledge graph completion.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26631;&#27880;&#26041;&#27861;&#65292;&#31216;&#20026;Q&amp;A&#26631;&#27880;&#12290;&#35813;&#26041;&#27861;&#28041;&#21450;&#21040;&#19968;&#20010;&#38382;&#39064;&#29983;&#25104;&#22120;&#21644;&#19968;&#20010;&#22238;&#31572;&#32773;&#65292;&#36890;&#36807;&#19968;&#31995;&#21015;&#38382;&#39064;&#23558;&#30456;&#24212;&#30340;&#26631;&#31614;&#20998;&#37197;&#32473;&#23454;&#20363;&#65292;&#24182;&#36890;&#36807;&#23548;&#20986;&#25439;&#22833;&#20989;&#25968;&#65292;&#23545;&#20351;&#29992;Q&amp;A&#26631;&#31614;&#30340;&#23454;&#20363;&#30340;&#30417;&#30563;&#24335;&#26426;&#22120;&#23398;&#20064;&#30340;&#20998;&#31867;&#39118;&#38505;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2305.04539</link><description>&lt;p&gt;
Q&amp;A&#26631;&#31614;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Q&amp;A Label Learning. (arXiv:2305.04539v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04539
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26631;&#27880;&#26041;&#27861;&#65292;&#31216;&#20026;Q&amp;A&#26631;&#27880;&#12290;&#35813;&#26041;&#27861;&#28041;&#21450;&#21040;&#19968;&#20010;&#38382;&#39064;&#29983;&#25104;&#22120;&#21644;&#19968;&#20010;&#22238;&#31572;&#32773;&#65292;&#36890;&#36807;&#19968;&#31995;&#21015;&#38382;&#39064;&#23558;&#30456;&#24212;&#30340;&#26631;&#31614;&#20998;&#37197;&#32473;&#23454;&#20363;&#65292;&#24182;&#36890;&#36807;&#23548;&#20986;&#25439;&#22833;&#20989;&#25968;&#65292;&#23545;&#20351;&#29992;Q&amp;A&#26631;&#31614;&#30340;&#23454;&#20363;&#30340;&#30417;&#30563;&#24335;&#26426;&#22120;&#23398;&#20064;&#30340;&#20998;&#31867;&#39118;&#38505;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#36827;&#34892;&#30417;&#30563;&#24335;&#26426;&#22120;&#23398;&#20064;&#65292;&#23558;&#26631;&#31614;&#20998;&#37197;&#32473;&#23454;&#20363;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27880;&#37322;&#26041;&#27861;&#65292;&#31216;&#20026;Q&amp;A&#26631;&#27880;&#12290;&#23427;&#28041;&#21450;&#21040;&#19968;&#20010;&#38382;&#39064;&#29983;&#25104;&#22120;&#65292;&#29992;&#20110;&#35810;&#38382;&#26377;&#20851;&#35201;&#20998;&#37197;&#30340;&#23454;&#20363;&#30340;&#26631;&#31614;&#30340;&#38382;&#39064;&#65292;&#20197;&#21450;&#19968;&#20010;&#22238;&#31572;&#38382;&#39064;&#24182;&#23558;&#23545;&#24212;&#26631;&#31614;&#20998;&#37197;&#32473;&#23454;&#20363;&#30340;&#26631;&#27880;&#32773;&#12290;&#25105;&#20204;&#24471;&#20986;&#20102;&#20004;&#31181;&#19981;&#21516;Q&amp;A&#26631;&#27880;&#36807;&#31243;&#20013;&#20998;&#37197;&#26631;&#31614;&#30340;&#26631;&#31614;&#29983;&#25104;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#20004;&#31181;&#36807;&#31243;&#20013;&#65292;&#25152;&#24471;&#21040;&#30340;&#27169;&#22411;&#37096;&#20998;&#19982;&#20808;&#21069;&#30340;&#30740;&#31350;&#32467;&#26524;&#19968;&#33268;&#12290;&#26412;&#30740;&#31350;&#19982;&#20197;&#24448;&#30740;&#31350;&#30340;&#20027;&#35201;&#21306;&#21035;&#22312;&#20110;&#65292;&#26412;&#30740;&#31350;&#30340;&#26631;&#31614;&#29983;&#25104;&#27169;&#22411;&#24182;&#26410;&#34987;&#20551;&#23450;&#65292;&#32780;&#26159;&#22522;&#20110;&#29305;&#23450;&#27880;&#37322;&#26041;&#27861;Q&amp;A&#26631;&#27880;&#32780;&#25512;&#23548;&#20986;&#26469;&#30340;&#12290;&#25105;&#20204;&#36824;&#23548;&#20986;&#20102;&#19968;&#20010;&#25439;&#22833;&#20989;&#25968;&#65292;&#29992;&#20110;&#35780;&#20272;&#20351;&#29992;&#20998;&#37197;&#20102;Q&amp;A&#26631;&#31614;&#30340;&#23454;&#20363;&#30340;&#26222;&#36890;&#30417;&#30563;&#24335;&#26426;&#22120;&#23398;&#20064;&#30340;&#20998;&#31867;&#39118;&#38505;&#65292;&#24182;&#35780;&#20272;&#20102;
&lt;/p&gt;
&lt;p&gt;
Assigning labels to instances is crucial for supervised machine learning. In this paper, we proposed a novel annotation method called Q&amp;A labeling, which involves a question generator that asks questions about the labels of the instances to be assigned, and an annotator who answers the questions and assigns the corresponding labels to the instances. We derived a generative model of labels assigned according to two different Q&amp;A labeling procedures that differ in the way questions are asked and answered. We showed that, in both procedures, the derived model is partially consistent with that assumed in previous studies. The main distinction of this study from previous studies lies in the fact that the label generative model was not assumed, but rather derived based on the definition of a specific annotation method, Q&amp;A labeling. We also derived a loss function to evaluate the classification risk of ordinary supervised machine learning using instances assigned Q&amp;A labels and evaluated the
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21333;&#21644;&#28165;&#26224;&#30340;&#22240;&#26524;&#29702;&#35770;&#65292;&#23427;&#19981;&#38656;&#35201;&#20351;&#29992;&#20219;&#20309;&#24314;&#27169;&#20551;&#35774;&#65292;&#21253;&#25324;&#22823;&#22810;&#25968;&#20855;&#26377;&#28508;&#22312;&#21464;&#37327;&#21644;&#22240;&#26524;&#24490;&#29615;&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#19981;&#20551;&#23450;&#23384;&#22312;&#24213;&#23618;&#30495;&#27491;&#30340;&#22240;&#26524;&#22270;-&#20107;&#23454;&#19978;&#65292;&#23427;&#26159;&#22240;&#26524;&#22270;&#30340;&#21103;&#20135;&#21697;&#12290;</title><link>http://arxiv.org/abs/2305.04479</link><description>&lt;p&gt;
&#24178;&#39044;&#27010;&#29575;&#20998;&#24067;&#30340;&#20844;&#29702;&#21270;
&lt;/p&gt;
&lt;p&gt;
Axiomatization of Interventional Probability Distributions. (arXiv:2305.04479v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04479
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21333;&#21644;&#28165;&#26224;&#30340;&#22240;&#26524;&#29702;&#35770;&#65292;&#23427;&#19981;&#38656;&#35201;&#20351;&#29992;&#20219;&#20309;&#24314;&#27169;&#20551;&#35774;&#65292;&#21253;&#25324;&#22823;&#22810;&#25968;&#20855;&#26377;&#28508;&#22312;&#21464;&#37327;&#21644;&#22240;&#26524;&#24490;&#29615;&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#19981;&#20551;&#23450;&#23384;&#22312;&#24213;&#23618;&#30495;&#27491;&#30340;&#22240;&#26524;&#22270;-&#20107;&#23454;&#19978;&#65292;&#23427;&#26159;&#22240;&#26524;&#22270;&#30340;&#21103;&#20135;&#21697;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#24178;&#39044;&#26159;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#22522;&#26412;&#24037;&#20855;&#12290;&#22312;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#23427;&#34987;&#20844;&#29702;&#21270;&#20026;do-&#28436;&#31639;&#35268;&#21017;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#20844;&#29702;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#21306;&#20998;&#19981;&#21516;&#31867;&#22411;&#30340;&#24178;&#39044;&#20998;&#24067;&#30340;&#27010;&#29575;&#20998;&#24067;&#26063;&#12290;&#25105;&#20204;&#30340;&#20844;&#29702;&#21270;&#26041;&#27861;&#25972;&#27905;&#22320;&#23548;&#33268;&#20102;&#19968;&#31181;&#31616;&#21333;&#21644;&#28165;&#26224;&#30340;&#22240;&#26524;&#29702;&#35770;&#65292;&#20855;&#26377;&#20960;&#20010;&#20248;&#28857;&#65306;&#23427;&#19981;&#38656;&#35201;&#20351;&#29992;&#20219;&#20309;&#24314;&#27169;&#20551;&#35774;&#65292;&#20363;&#22914;&#32467;&#26500;&#24615;&#22240;&#26524;&#27169;&#22411;&#25152;&#24378;&#21152;&#30340;&#20551;&#35774;&#65307;&#23427;&#21482;&#20381;&#36182;&#20110;&#21333;&#20010;&#21464;&#37327;&#30340;&#24178;&#39044;&#65307;&#23427;&#21253;&#25324;&#22823;&#22810;&#25968;&#20855;&#26377;&#28508;&#22312;&#21464;&#37327;&#21644;&#22240;&#26524;&#24490;&#29615;&#30340;&#24773;&#20917;&#65307;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#23427;&#19981;&#20551;&#23450;&#23384;&#22312;&#24213;&#23618;&#30495;&#27491;&#30340;&#22240;&#26524;&#22270;--&#20107;&#23454;&#19978;&#65292;&#22240;&#26524;&#22270;&#26159;&#25105;&#20204;&#29702;&#35770;&#30340;&#21103;&#20135;&#21697;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#65292;&#22312;&#25105;&#20204;&#30340;&#20844;&#29702;&#21270;&#26041;&#27861;&#19979;&#65292;&#24178;&#39044;&#20998;&#24067;&#23545;&#20110;&#23450;&#20041;&#30340;&#24178;&#39044;&#22240;&#26524;&#22270;&#26159;&#39532;&#23572;&#21487;&#22827;&#30340;&#65292;&#24182;&#19988;&#35266;&#23519;&#21040;&#30340;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#23545;&#20110;&#33719;&#24471;&#30340;&#22240;&#26524;&#22270;&#26159;&#39532;&#23572;&#21487;&#22827;&#30340;&#65307;&#36825;&#20123;&#32467;&#26524;&#26159;&#19968;&#33268;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal intervention is an essential tool in causal inference. It is axiomatized under the rules of do-calculus in the case of structure causal models. We provide simple axiomatizations for families of probability distributions to be different types of interventional distributions. Our axiomatizations neatly lead to a simple and clear theory of causality that has several advantages: it does not need to make use of any modeling assumptions such as those imposed by structural causal models; it only relies on interventions on single variables; it includes most cases with latent variables and causal cycles; and more importantly, it does not assume the existence of an underlying true causal graph--in fact, a causal graph is a by-product of our theory. We show that, under our axiomatizations, the intervened distributions are Markovian to the defined intervened causal graphs, and an observed joint probability distribution is Markovian to the obtained causal graph; these results are consistent 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#38024;&#23545;&#21152;&#26435;&#22240;&#26524; DAGs&#30340;&#26032;&#24230;&#37327;&#21644;&#25628;&#32034;&#31639;&#27861;&#65292;&#21457;&#29616;&#20102;&#29992;&#20110;&#33258;&#36866;&#24212;&#24178;&#39044;&#30340;&#22240;&#26524;&#22270;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#26469;&#25429;&#25417;&#25628;&#32034;&#31639;&#27861;&#30340;&#26368;&#22351;&#24178;&#39044;&#25104;&#26412;&#65292;&#24182;&#25552;&#20379;&#33258;&#36866;&#24212;&#25628;&#32034;&#31639;&#27861;&#23454;&#29616;&#23545;&#25968;&#36924;&#36817;&#12290;</title><link>http://arxiv.org/abs/2305.04445</link><description>&lt;p&gt;
&#29992;&#20110;&#21152;&#26435;&#22240;&#26524; DAG &#30340;&#26032;&#24230;&#37327;&#21644;&#25628;&#32034;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
New metrics and search algorithms for weighted causal DAGs. (arXiv:2305.04445v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04445
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#38024;&#23545;&#21152;&#26435;&#22240;&#26524; DAGs&#30340;&#26032;&#24230;&#37327;&#21644;&#25628;&#32034;&#31639;&#27861;&#65292;&#21457;&#29616;&#20102;&#29992;&#20110;&#33258;&#36866;&#24212;&#24178;&#39044;&#30340;&#22240;&#26524;&#22270;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#26469;&#25429;&#25417;&#25628;&#32034;&#31639;&#27861;&#30340;&#26368;&#22351;&#24178;&#39044;&#25104;&#26412;&#65292;&#24182;&#25552;&#20379;&#33258;&#36866;&#24212;&#25628;&#32034;&#31639;&#27861;&#23454;&#29616;&#23545;&#25968;&#36924;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#25968;&#25454;&#20013;&#24674;&#22797;&#22240;&#26524;&#20851;&#31995;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#38382;&#39064;&#12290;&#22312;&#20351;&#29992;&#35266;&#27979;&#25968;&#25454;&#26102;&#65292;&#21482;&#33021;&#24674;&#22797;&#21040;&#19968;&#20010;&#39532;&#23572;&#31185;&#22827;&#31561;&#20215;&#31867;&#30340;&#22240;&#26524;&#22270;&#65292;&#24182;&#19988;&#38656;&#35201;&#39069;&#22806;&#30340;&#20551;&#35774;&#25110;&#24178;&#39044;&#25968;&#25454;&#26469;&#23436;&#25104;&#24674;&#22797;&#12290;&#26412;&#25991;&#22312;&#19968;&#20123;&#26631;&#20934;&#20551;&#35774;&#19979;&#65292;&#36890;&#36807;&#33410;&#28857;&#30456;&#20851;&#24178;&#39044;&#25104;&#26412;&#30340;&#33258;&#36866;&#24212;&#24178;&#39044;&#65292;&#30740;&#31350;&#22240;&#26524;&#22270;&#21457;&#29616;&#12290;&#23545;&#20110;&#36825;&#31181;&#24773;&#20917;&#65292;&#25105;&#20204;&#35777;&#26126;&#27809;&#26377;&#31639;&#27861;&#33021;&#22815;&#27604;&#39564;&#35777;&#27425;&#25968;&#30340;&#39034;&#24207;&#26356;&#22909;&#22320;&#23454;&#29616;&#28176;&#36817;&#20445;&#35777;&#65292;&#39564;&#35777;&#27425;&#25968;&#26159;&#33258;&#36866;&#24212;&#25628;&#32034;&#31639;&#27861;&#30340;&#19968;&#20010;&#25104;&#29087;&#22522;&#20934;&#12290;&#22312;&#36825;&#20010;&#36127;&#38754;&#32467;&#26524;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#23450;&#20041;&#20102;&#19968;&#20010;&#25429;&#25417;&#20219;&#20309;&#25628;&#32034;&#31639;&#27861;&#26368;&#22351;&#24178;&#39044;&#25104;&#26412;&#30340;&#26032;&#22522;&#20934;&#12290;&#27492;&#22806;&#65292;&#38024;&#23545;&#36825;&#20010;&#26032;&#22522;&#20934;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#33258;&#36866;&#24212;&#25628;&#32034;&#31639;&#27861;&#65292;&#22312;&#21508;&#31181;&#35774;&#32622;&#19979;&#37117;&#33021;&#23454;&#29616;&#23545;&#25968;&#36924;&#36817;&#65306;&#21407;&#23376;&#12289;&#26377;&#30028;&#22823;&#23567;&#30340;&#24178;&#39044;&#21644;&#24191;&#20041;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recovering causal relationships from data is an important problem. Using observational data, one can typically only recover causal graphs up to a Markov equivalence class and additional assumptions or interventional data are needed for complete recovery. In this work, under some standard assumptions, we study causal graph discovery via adaptive interventions with node-dependent interventional costs. For this setting, we show that no algorithm can achieve an approximation guarantee that is asymptotically better than linear in the number of vertices with respect to the verification number; a well-established benchmark for adaptive search algorithms. Motivated by this negative result, we define a new benchmark that captures the worst-case interventional cost for any search algorithm. Furthermore, with respect to this new benchmark, we provide adaptive search algorithms that achieve logarithmic approximations under various settings: atomic, bounded size interventions and generalized cost o
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21435;&#22122;&#25193;&#25955;&#36807;&#31243;&#33258;&#28982;&#22320;&#23548;&#33268;&#27491;&#21017;&#21270;&#30340;&#21464;&#20998;&#26041;&#27861;&#65288;RED-Diff&#65289;&#65292;&#21487;&#29992;&#20110;&#35299;&#20915;&#19981;&#21516;&#21453;&#38382;&#39064;&#12290;&#21152;&#26435;&#26426;&#21046;&#21487;&#20197;&#34913;&#37327;&#19981;&#21516;&#26102;&#38388;&#27493;&#38271;&#30340;&#21435;&#22122;&#22120;&#30340;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2305.04391</link><description>&lt;p&gt;
&#29992;&#25193;&#25955;&#27169;&#22411;&#35299;&#20915;&#21453;&#38382;&#39064;&#30340;&#21464;&#20998;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
A Variational Perspective on Solving Inverse Problems with Diffusion Models. (arXiv:2305.04391v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04391
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21435;&#22122;&#25193;&#25955;&#36807;&#31243;&#33258;&#28982;&#22320;&#23548;&#33268;&#27491;&#21017;&#21270;&#30340;&#21464;&#20998;&#26041;&#27861;&#65288;RED-Diff&#65289;&#65292;&#21487;&#29992;&#20110;&#35299;&#20915;&#19981;&#21516;&#21453;&#38382;&#39064;&#12290;&#21152;&#26435;&#26426;&#21046;&#21487;&#20197;&#34913;&#37327;&#19981;&#21516;&#26102;&#38388;&#27493;&#38271;&#30340;&#21435;&#22122;&#22120;&#30340;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#24050;&#25104;&#20026;&#35270;&#35273;&#39046;&#22495;&#22522;&#30784;&#27169;&#22411;&#30340;&#20851;&#38190;&#25903;&#26609;&#20043;&#19968;&#12290;&#20854;&#20013;&#19968;&#20010;&#20851;&#38190;&#24212;&#29992;&#26159;&#36890;&#36807;&#21333;&#20010;&#25193;&#25955;&#20808;&#39564;&#26222;&#36941;&#35299;&#20915;&#19981;&#21516;&#30340;&#21453;&#38382;&#39064;&#65292;&#32780;&#26080;&#38656;&#20026;&#27599;&#20010;&#20219;&#21153;&#37325;&#26032;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#25193;&#25955;&#36807;&#31243;&#30340;&#38750;&#32447;&#24615;&#21644;&#36845;&#20195;&#24615;&#36136;&#20351;&#24471;&#21518;&#39564;&#38590;&#20197;&#22788;&#29702;&#65292;&#22240;&#27492;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21464;&#20998;&#26041;&#27861;&#65292;&#26088;&#22312;&#36817;&#20284;&#30495;&#23454;&#21518;&#39564;&#20998;&#24067;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#21435;&#22122;&#25193;&#25955;&#36807;&#31243;&#65288;RED-Diff&#65289;&#33258;&#28982;&#22320;&#23548;&#33268;&#27491;&#21017;&#21270;&#65292;&#20854;&#20013;&#26469;&#33258;&#19981;&#21516;&#26102;&#38388;&#27493;&#38271;&#30340;&#21435;&#22122;&#22120;&#21516;&#26102;&#23545;&#22270;&#20687;&#26045;&#21152;&#19981;&#21516;&#30340;&#32467;&#26500;&#32422;&#26463;&#12290;&#20026;&#20102;&#34913;&#37327;&#19981;&#21516;&#26102;&#38388;&#27493;&#38271;&#30340;&#21435;&#22122;&#22120;&#30340;&#36129;&#29486;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20449;&#21495;-t&#30340;&#21152;&#26435;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models have emerged as a key pillar of foundation models in visual domains. One of their critical applications is to universally solve different downstream inverse tasks via a single diffusion prior without re-training for each task. Most inverse tasks can be formulated as inferring a posterior distribution over data (e.g., a full image) given a measurement (e.g., a masked image). This is however challenging in diffusion models since the nonlinear and iterative nature of the diffusion process renders the posterior intractable. To cope with this challenge, we propose a variational approach that by design seeks to approximate the true posterior distribution. We show that our approach naturally leads to regularization by denoising diffusion process (RED-Diff) where denoisers at different timesteps concurrently impose different structural constraints over the image. To gauge the contribution of denoisers from different timesteps, we propose a weighting mechanism based on signal-t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#39044;&#27979;&#24615;&#32858;&#31867;&#20248;&#21270;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#20801;&#35768;&#19981;&#21516;&#30340;&#32858;&#31867;&#23450;&#20041;&#21644;&#22238;&#24402;&#12289;&#20998;&#31867;&#30446;&#26631;&#65292;&#24182;&#25552;&#20379;&#20102;&#39640;&#24230;&#21487;&#25193;&#23637;&#30340;&#31639;&#27861;&#20197;&#35299;&#20915;&#22823;&#22411;&#25968;&#25454;&#38598;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.04364</link><description>&lt;p&gt;
&#39044;&#27979;&#24615;&#32858;&#31867;&#19982;&#20248;&#21270;&#30340;&#36890;&#29992;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Generalized Framework for Predictive Clustering and Optimization. (arXiv:2305.04364v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04364
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#39044;&#27979;&#24615;&#32858;&#31867;&#20248;&#21270;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#20801;&#35768;&#19981;&#21516;&#30340;&#32858;&#31867;&#23450;&#20041;&#21644;&#22238;&#24402;&#12289;&#20998;&#31867;&#30446;&#26631;&#65292;&#24182;&#25552;&#20379;&#20102;&#39640;&#24230;&#21487;&#25193;&#23637;&#30340;&#31639;&#27861;&#20197;&#35299;&#20915;&#22823;&#22411;&#25968;&#25454;&#38598;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32858;&#31867;&#26159;&#19968;&#31181;&#24378;&#22823;&#32780;&#24191;&#27867;&#20351;&#29992;&#30340;&#25968;&#25454;&#31185;&#23398;&#24037;&#20855;&#12290;&#34429;&#28982;&#32858;&#31867;&#36890;&#24120;&#34987;&#35748;&#20026;&#26159;&#26080;&#30417;&#30563;&#23398;&#20064;&#25216;&#26415;&#65292;&#20294;&#20063;&#23384;&#22312;&#30528;&#20687;Spath&#30340;&#32858;&#31867;&#22238;&#24402;&#36825;&#26679;&#35797;&#22270;&#25214;&#21040;&#20135;&#29983;&#30417;&#30563;&#30446;&#26631;&#20302;&#22238;&#24402;&#35823;&#24046;&#30340;&#25968;&#25454;&#32858;&#31867;&#30340;&#30417;&#30563;&#21464;&#20307;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20026;&#39044;&#27979;&#24615;&#32858;&#31867;&#23450;&#20041;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#20248;&#21270;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#21487;&#20197;&#25509;&#21463;&#19981;&#21516;&#30340;&#32858;&#31867;&#23450;&#20041;&#65288;&#20219;&#24847;&#28857;&#20998;&#37197;&#12289;&#26368;&#25509;&#36817;&#30340;&#20013;&#24515;&#21644;&#36793;&#30028;&#26694;&#65289;&#21644;&#22238;&#24402;&#12289;&#20998;&#31867;&#30446;&#26631;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#21512;&#20248;&#21270;&#31574;&#30053;&#65292;&#22312;&#36825;&#20010;&#36890;&#29992;&#26694;&#26550;&#20013;&#21033;&#29992;&#28151;&#21512;&#25972;&#25968;&#32447;&#24615;&#35268;&#21010;&#65288;MILP&#65289;&#36827;&#34892;&#20840;&#23616;&#20248;&#21270;&#12290;&#20026;&#20102;&#20943;&#36731;&#22823;&#22411;&#25968;&#25454;&#38598;&#30340;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#21463;&#20027;&#23548;&#26368;&#23567;&#21270;&#65288;MM&#65289;&#21551;&#21457;&#30340;&#39640;&#24230;&#21487;&#25193;&#23637;&#30340;&#36138;&#23146;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Clustering is a powerful and extensively used data science tool. While clustering is generally thought of as an unsupervised learning technique, there are also supervised variations such as Spath's clusterwise regression that attempt to find clusters of data that yield low regression error on a supervised target. We believe that clusterwise regression is just a single vertex of a largely unexplored design space of supervised clustering models. In this article, we define a generalized optimization framework for predictive clustering that admits different cluster definitions (arbitrary point assignment, closest center, and bounding box) and both regression and classification objectives. We then present a joint optimization strategy that exploits mixed-integer linear programming (MILP) for global optimization in this generalized framework. To alleviate scalability concerns for large datasets, we also provide highly scalable greedy algorithms inspired by the Majorization-Minimization (MM) 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#35745;&#31639;&#26377;&#25928;&#30340;&#24191;&#20041;&#26497;&#20540;&#20998;&#24067;&#21442;&#25968;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#19982;&#20256;&#32479;&#30340;&#26497;&#22823;&#20284;&#28982;&#26041;&#27861;&#30456;&#27604;&#65292;&#20855;&#26377;&#30456;&#20284;&#30340;&#20934;&#30830;&#24615;&#21644;&#26174;&#33879;&#30340;&#35745;&#31639;&#21152;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.04341</link><description>&lt;p&gt;
&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#24555;&#36895;&#20272;&#35745;&#24191;&#20041;&#26497;&#20540;&#20998;&#24067;&#30340;&#21442;&#25968;
&lt;/p&gt;
&lt;p&gt;
Fast parameter estimation of Generalized Extreme Value distribution using Neural Networks. (arXiv:2305.04341v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04341
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#35745;&#31639;&#26377;&#25928;&#30340;&#24191;&#20041;&#26497;&#20540;&#20998;&#24067;&#21442;&#25968;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#19982;&#20256;&#32479;&#30340;&#26497;&#22823;&#20284;&#28982;&#26041;&#27861;&#30456;&#27604;&#65292;&#20855;&#26377;&#30456;&#20284;&#30340;&#20934;&#30830;&#24615;&#21644;&#26174;&#33879;&#30340;&#35745;&#31639;&#21152;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24191;&#20041;&#26497;&#20540;&#20998;&#24067;&#30340;&#37325;&#23614;&#24615;&#20351;&#20854;&#25104;&#20026;&#24314;&#27169;&#27946;&#27700;&#12289;&#24178;&#26097;&#12289;&#28909;&#28010;&#12289;&#37326;&#28779;&#31561;&#26497;&#31471;&#20107;&#20214;&#30340;&#27969;&#34892;&#36873;&#25321;&#12290;&#28982;&#32780;&#65292;&#20351;&#29992;&#20256;&#32479;&#30340;&#26497;&#22823;&#20284;&#28982;&#26041;&#27861;&#20272;&#35745;&#20998;&#24067;&#30340;&#21442;&#25968;&#65292;&#21363;&#20351;&#23545;&#20110;&#20013;&#31561;&#22823;&#23567;&#30340;&#25968;&#25454;&#38598;&#20063;&#21487;&#33021;&#20855;&#26377;&#35745;&#31639;&#23494;&#38598;&#24230;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#35745;&#31639;&#26377;&#25928;&#30340;&#19981;&#38656;&#35201;&#20284;&#28982;&#30340;&#20272;&#35745;&#26041;&#27861;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#20223;&#30495;&#30740;&#31350;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#25552;&#20379;&#20855;&#26377;&#21487;&#27604;&#36739;&#20934;&#30830;&#24615;&#30340;&#24191;&#20041;&#26497;&#20540;&#20998;&#24067;&#21442;&#25968;&#20272;&#35745;&#65292;&#20294;&#20855;&#26377;&#26174;&#30528;&#30340;&#35745;&#31639;&#21152;&#36895;&#24230;&#12290;&#20026;&#20102;&#32771;&#34385;&#20272;&#35745;&#19981;&#30830;&#23450;&#24230;&#65292;&#25105;&#20204;&#21033;&#29992;&#35757;&#32451;&#22909;&#30340;&#32593;&#32476;&#20013;&#22266;&#26377;&#30340;&#21442;&#25968;&#33258;&#21161;&#27861;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#31181;&#26041;&#27861;&#24212;&#29992;&#20110;&#26469;&#33258;&#31038;&#21306;&#27668;&#20505;&#31995;&#32479;&#27169;&#22411;&#30340;1000&#24180;&#24180;&#26368;&#22823;&#28201;&#24230;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
The heavy-tailed behavior of the generalized extreme-value distribution makes it a popular choice for modeling extreme events such as floods, droughts, heatwaves, wildfires, etc. However, estimating the distribution's parameters using conventional maximum likelihood methods can be computationally intensive, even for moderate-sized datasets. To overcome this limitation, we propose a computationally efficient, likelihood-free estimation method utilizing a neural network. Through an extensive simulation study, we demonstrate that the proposed neural network-based method provides Generalized Extreme Value (GEV) distribution parameter estimates with comparable accuracy to the conventional maximum likelihood method but with a significant computational speedup. To account for estimation uncertainty, we utilize parametric bootstrapping, which is inherent in the trained network. Finally, we apply this method to 1000-year annual maximum temperature data from the Community Climate System Model ve
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#20998;&#31867;&#26641;&#21098;&#26525;&#26041;&#27861;&#65292;&#21487;&#20197;&#35775;&#38382;&#22823;&#37096;&#20998;&#26469;&#33258;&#20998;&#24067; $P_{X&#65292;Y}$ &#30340;&#25968;&#25454;&#65292;&#20294;&#26159;&#21482;&#33021;&#33719;&#24471;&#26469;&#33258;&#25317;&#26377;&#19981;&#21516; $X$-&#36793;&#32536;&#30340;&#30446;&#26631;&#20998;&#24067; $Q_{X&#65292;Y}$ &#30340;&#23569;&#37327;&#25968;&#25454;&#12290;&#20351;&#29992;&#30340;&#20248;&#21270;&#26631;&#20934;&#26159;&#19968;&#20010;&#20851;&#20110;&#20998;&#24067; $P_{X} \to Q_{X}$ &#30340; \emph{&#24179;&#22343;&#24046;&#24322;}&#65292;&#35813;&#26631;&#20934;&#21487;&#20197;&#26174;&#33879;&#25918;&#23485;&#26368;&#36817;&#25552;&#20986;&#30340; \emph{&#36716;&#31227;&#25351;&#25968;}&#65292;&#26368;&#32456;&#21487;&#20197;&#24471;&#21040;&#26368;&#20248;&#30340;&#21098;&#26525;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.04335</link><description>&lt;p&gt;
&#22522;&#20110;&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#20998;&#31867;&#26641;&#21098;&#26525;
&lt;/p&gt;
&lt;p&gt;
Classification Tree Pruning Under Covariate Shift. (arXiv:2305.04335v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04335
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#20998;&#31867;&#26641;&#21098;&#26525;&#26041;&#27861;&#65292;&#21487;&#20197;&#35775;&#38382;&#22823;&#37096;&#20998;&#26469;&#33258;&#20998;&#24067; $P_{X&#65292;Y}$ &#30340;&#25968;&#25454;&#65292;&#20294;&#26159;&#21482;&#33021;&#33719;&#24471;&#26469;&#33258;&#25317;&#26377;&#19981;&#21516; $X$-&#36793;&#32536;&#30340;&#30446;&#26631;&#20998;&#24067; $Q_{X&#65292;Y}$ &#30340;&#23569;&#37327;&#25968;&#25454;&#12290;&#20351;&#29992;&#30340;&#20248;&#21270;&#26631;&#20934;&#26159;&#19968;&#20010;&#20851;&#20110;&#20998;&#24067; $P_{X} \to Q_{X}$ &#30340; \emph{&#24179;&#22343;&#24046;&#24322;}&#65292;&#35813;&#26631;&#20934;&#21487;&#20197;&#26174;&#33879;&#25918;&#23485;&#26368;&#36817;&#25552;&#20986;&#30340; \emph{&#36716;&#31227;&#25351;&#25968;}&#65292;&#26368;&#32456;&#21487;&#20197;&#24471;&#21040;&#26368;&#20248;&#30340;&#21098;&#26525;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#35757;&#32451;&#25968;&#25454;&#19981;&#22343;&#21248;&#30340;&#24773;&#20917;&#19979;&#65292;&#36873;&#25321;&#36866;&#24403;&#30340;&#23376;&#26641;&#20197;&#24179;&#34913;&#20559;&#24046;&#21644;&#26041;&#24046;&#30340;&#20998;&#31867;&#26641;&#21098;&#26525;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#36825;&#31181;&#24773;&#20917;&#30340;&#26368;&#20248;&#21098;&#26525;&#30340;&#39640;&#25928;&#31243;&#24207;&#65292;&#35813;&#31243;&#24207;&#21487;&#20197;&#35775;&#38382;&#22823;&#37096;&#20998;&#26469;&#33258;&#20998;&#24067; $P_{X&#65292;Y}$ &#30340;&#25968;&#25454;&#65292;&#20294;&#26159;&#21482;&#33021;&#33719;&#24471;&#26469;&#33258;&#25317;&#26377;&#19981;&#21516; $X$-&#36793;&#32536;&#30340;&#30446;&#26631;&#20998;&#24067; $Q_{X&#65292;Y}$ &#30340;&#23569;&#37327;&#25968;&#25454;&#12290;&#22312;&#22522;&#26412;&#20132;&#21449;&#39564;&#35777;&#21644;&#20854;&#20182;&#36827;&#34892;&#24809;&#32602;&#30340;&#21464;&#20307;&#65292;&#22914;&#22522;&#20110;&#20449;&#24687;&#24230;&#37327;&#30340;&#21098;&#26525;&#26041;&#27861;&#38750;&#24120;&#19981;&#29702;&#24819;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26368;&#20248;&#21098;&#26525;&#30340;&#26041;&#27861;&#12290;&#20351;&#29992;&#30340;&#20248;&#21270;&#26631;&#20934;&#26159;&#19968;&#20010;&#20851;&#20110;&#20998;&#24067; $P_{X} \to Q_{X}$ &#30340; \emph{&#24179;&#22343;&#24046;&#24322;}&#65288;&#22312; $X$ &#31354;&#38388;&#19978;&#24179;&#22343;&#65289;&#65292;&#35813;&#26631;&#20934;&#21487;&#20197;&#26174;&#33879;&#25918;&#23485;&#26368;&#36817;&#25552;&#20986;&#30340; \emph{&#36716;&#31227;&#25351;&#25968;} &#36825;&#19968;&#32479;&#35745;&#23398;&#27010;&#24565;&#65292;&#35813;&#27010;&#24565;&#34987;&#35777;&#26126;&#33021;&#22815;&#32039;&#23494;&#22320;&#25429;&#25417;&#36825;&#31181;&#20998;&#24067;&#36716;&#31227;&#24773;&#20917;&#19979;&#20998;&#31867;&#30340;&#26497;&#38480;&#38480;&#21046;&#12290;&#25105;&#20204;&#25918;&#23485;&#30340;&#26631;&#20934;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#20998;&#24067;&#20043;&#38388;&#30340;\emph{&#30456;&#23545;&#32500;&#24230;}&#24230;&#37327;&#65292;&#22240;&#20026;&#23427;&#28041;&#21450;&#21040;&#20449;&#24687;&#30340;&#29616;&#26377;&#24230;&#37327;&#27010;&#24565;&#65292;&#20363;&#22914;&#38389;&#21487;&#22827;&#26031;&#22522;&#21644;R&#233;nyi&#32500;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of \emph{pruning} a classification tree, that is, selecting a suitable subtree that balances bias and variance, in common situations with inhomogeneous training data. Namely, assuming access to mostly data from a distribution $P_{X, Y}$, but little data from a desired distribution $Q_{X, Y}$ with different $X$-marginals, we present the first efficient procedure for optimal pruning in such situations, when cross-validation and other penalized variants are grossly inadequate. Optimality is derived with respect to a notion of \emph{average discrepancy} $P_{X} \to Q_{X}$ (averaged over $X$ space) which significantly relaxes a recent notion -- termed \emph{transfer-exponent} -- shown to tightly capture the limits of classification under such a distribution shift. Our relaxed notion can be viewed as a measure of \emph{relative dimension} between distributions, as it relates to existing notions of information such as the Minkowski and Renyi dimensions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20165;&#38656;&#35201;&#24456;&#23569;&#30340;&#26679;&#26412;&#19988;&#33021;&#22815;&#23545;&#26435;&#37325;&#21644;&#22343;&#20540;&#36827;&#34892;&#20934;&#30830;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2305.04127</link><description>&lt;p&gt;
&#20351;&#29992;&#25130;&#26029;&#25968;&#25454;&#23398;&#20064;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning Mixtures of Gaussians with Censored Data. (arXiv:2305.04127v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04127
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20165;&#38656;&#35201;&#24456;&#23569;&#30340;&#26679;&#26412;&#19988;&#33021;&#22815;&#23545;&#26435;&#37325;&#21644;&#22343;&#20540;&#36827;&#34892;&#20934;&#30830;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20855;&#26377;&#25130;&#26029;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#23398;&#20064;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#38382;&#39064;&#12290;&#21363;&#20174;&#19968;&#20010;&#28151;&#21512;&#21333;&#21464;&#37327;&#39640;&#26031;&#20998;&#24067;$\sum_{i=1}^k w_i \mathcal{N}(\mu_i,\sigma^2)$&#20013;&#35266;&#27979;&#21040;&#30340;&#26679;&#26412;&#21482;&#26377;&#24403;&#20854;&#20301;&#20110;$S$&#38598;&#21512;&#20869;&#26102;&#25165;&#20250;&#34987;&#35266;&#23519;&#21040;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#20165;&#38656;&#35201;$\frac{1}{\varepsilon^{O(k)}}$&#20010;&#26679;&#26412;&#21363;&#21487;&#22312;$\varepsilon$&#35823;&#24046;&#20869;&#20272;&#35745;&#26435;&#37325;$w_i$&#21644;&#22343;&#20540;$\mu_i$&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of learning mixtures of Gaussians with censored data. Statistical learning with censored data is a classical problem, with numerous practical applications, however, finite-sample guarantees for even simple latent variable models such as Gaussian mixtures are missing. Formally, we are given censored data from a mixture of univariate Gaussians $$\sum_{i=1}^k w_i \mathcal{N}(\mu_i,\sigma^2),$$ i.e. the sample is observed only if it lies inside a set $S$. The goal is to learn the weights $w_i$ and the means $\mu_i$. We propose an algorithm that takes only $\frac{1}{\varepsilon^{O(k)}}$ samples to estimate the weights $w_i$ and the means $\mu_i$ within $\varepsilon$ error.
&lt;/p&gt;</description></item><item><title>&#19968;&#38454;&#21435;&#20559;&#26041;&#27861;&#22312;&#26368;&#23567;&#20108;&#20056;&#24847;&#20041;&#19979;&#22312;&#24178;&#25200;&#20989;&#25968;&#29983;&#23384;&#22312;&#29305;&#23450;&#20989;&#25968;&#31354;&#38388;&#26102;&#34987;&#35777;&#26126;&#26159;&#27425;&#20248;&#30340;&#65292;&#36825;&#20419;&#36827;&#20102;&#8220;&#39640;&#38454;&#8221;&#21435;&#20559;&#26041;&#27861;&#30340;&#21457;&#23637;&#12290;</title><link>http://arxiv.org/abs/2305.04116</link><description>&lt;p&gt;
&#32467;&#26500;&#26080;&#20851;&#20989;&#25968;&#20272;&#35745;&#30340;&#22522;&#26412;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
The Fundamental Limits of Structure-Agnostic Functional Estimation. (arXiv:2305.04116v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04116
&lt;/p&gt;
&lt;p&gt;
&#19968;&#38454;&#21435;&#20559;&#26041;&#27861;&#22312;&#26368;&#23567;&#20108;&#20056;&#24847;&#20041;&#19979;&#22312;&#24178;&#25200;&#20989;&#25968;&#29983;&#23384;&#22312;&#29305;&#23450;&#20989;&#25968;&#31354;&#38388;&#26102;&#34987;&#35777;&#26126;&#26159;&#27425;&#20248;&#30340;&#65292;&#36825;&#20419;&#36827;&#20102;&#8220;&#39640;&#38454;&#8221;&#21435;&#20559;&#26041;&#27861;&#30340;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#35768;&#22810;&#22240;&#26524;&#25512;&#26029;&#21644;&#20989;&#25968;&#20272;&#35745;&#38382;&#39064;&#30340;&#21457;&#23637;&#37117;&#28304;&#20110;&#36825;&#26679;&#19968;&#20010;&#20107;&#23454;&#65306;&#22312;&#38750;&#24120;&#24369;&#30340;&#26465;&#20214;&#19979;&#65292;&#32463;&#20856;&#30340;&#19968;&#27493;&#65288;&#19968;&#38454;&#65289;&#21435;&#20559;&#26041;&#27861;&#25110;&#23427;&#20204;&#36739;&#26032;&#30340;&#26679;&#26412;&#20998;&#21106;&#21452;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#21487;&#20197;&#27604;&#25554;&#34917;&#20272;&#35745;&#26356;&#22909;&#22320;&#24037;&#20316;&#12290;&#36825;&#20123;&#19968;&#38454;&#26657;&#27491;&#20197;&#40657;&#30418;&#23376;&#26041;&#24335;&#25913;&#21892;&#25554;&#34917;&#20272;&#35745;&#20540;&#65292;&#22240;&#27492;&#32463;&#24120;&#19982;&#24378;&#22823;&#30340;&#29616;&#25104;&#20272;&#35745;&#26041;&#27861;&#19968;&#36215;&#20351;&#29992;&#12290;&#28982;&#32780;&#65292;&#24403;&#24178;&#25200;&#20989;&#25968;&#29983;&#23384;&#22312;Holder&#22411;&#20989;&#25968;&#31354;&#38388;&#20013;&#26102;&#65292;&#36825;&#20123;&#19968;&#38454;&#26041;&#27861;&#22312;&#26368;&#23567;&#20108;&#20056;&#24847;&#20041;&#19979;&#34987;&#35777;&#26126;&#26159;&#27425;&#20248;&#30340;&#12290;&#36825;&#31181;&#19968;&#38454;&#21435;&#20559;&#30340;&#27425;&#20248;&#24615;&#20419;&#36827;&#20102;&#8220;&#39640;&#38454;&#8221;&#21435;&#20559;&#26041;&#27861;&#30340;&#21457;&#23637;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#20272;&#35745;&#37327;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#34987;&#35777;&#26126;&#26159;&#22312;Holder&#31867;&#22411;&#31354;&#38388;&#19978;&#26368;&#23567;&#21270;&#30340;&#65292;&#24182;&#19988;&#23427;&#20204;&#30340;&#20998;&#26512;&#19982;&#22522;&#30784;&#20989;&#25968;&#31354;&#38388;&#30340;&#24615;&#36136;&#23494;&#20999;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many recent developments in causal inference, and functional estimation problems more generally, have been motivated by the fact that classical one-step (first-order) debiasing methods, or their more recent sample-split double machine-learning avatars, can outperform plugin estimators under surprisingly weak conditions. These first-order corrections improve on plugin estimators in a black-box fashion, and consequently are often used in conjunction with powerful off-the-shelf estimation methods. These first-order methods are however provably suboptimal in a minimax sense for functional estimation when the nuisance functions live in Holder-type function spaces. This suboptimality of first-order debiasing has motivated the development of "higher-order" debiasing methods. The resulting estimators are, in some cases, provably optimal over Holder-type spaces, but both the estimators which are minimax-optimal and their analyses are crucially tied to properties of the underlying function space
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#37319;&#29992;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#30340;&#38543;&#26426;&#21160;&#24577;&#35268;&#21010;&#26041;&#27861;&#65292;&#24320;&#21457;&#19968;&#31181;&#39034;&#24207;&#25277;&#26679;&#31574;&#30053;&#65292;&#25552;&#39640;&#20102;&#36873;&#25321;&#19978;&#19979;&#25991;&#30456;&#20851;&#35774;&#35745;&#30340;&#21069;m&#20010;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2305.04086</link><description>&lt;p&gt;
&#36873;&#25321;&#21069;m&#20010;&#19978;&#19979;&#25991;&#30456;&#20851;&#35774;&#35745;&#30340;&#39640;&#25928;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Efficient Learning for Selecting Top-m Context-Dependent Designs. (arXiv:2305.04086v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04086
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#37319;&#29992;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#30340;&#38543;&#26426;&#21160;&#24577;&#35268;&#21010;&#26041;&#27861;&#65292;&#24320;&#21457;&#19968;&#31181;&#39034;&#24207;&#25277;&#26679;&#31574;&#30053;&#65292;&#25552;&#39640;&#20102;&#36873;&#25321;&#19978;&#19979;&#25991;&#30456;&#20851;&#35774;&#35745;&#30340;&#21069;m&#20010;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;&#38024;&#23545;&#19978;&#19979;&#25991;&#30456;&#20851;&#20915;&#31574;&#30340;&#27169;&#25311;&#20248;&#21270;&#38382;&#39064;&#65292;&#26088;&#22312;&#30830;&#23450;&#25152;&#26377;&#19978;&#19979;&#25991;&#24773;&#22659;&#19979;&#30340;&#21069;m&#20010;&#35774;&#35745;&#12290;&#22312;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#23558;&#26368;&#20248;&#21160;&#24577;&#25277;&#26679;&#20915;&#31574;&#21046;&#23450;&#20026;&#38543;&#26426;&#21160;&#24577;&#35268;&#21010;&#38382;&#39064;&#65292;&#24182;&#24320;&#21457;&#19968;&#31181;&#39034;&#24207;&#25277;&#26679;&#31574;&#30053;&#65292;&#20197;&#39640;&#25928;&#22320;&#23398;&#20064;&#27599;&#20010;&#19978;&#19979;&#25991;&#24773;&#22659;&#19979;&#27599;&#20010;&#35774;&#35745;&#30340;&#24615;&#33021;&#12290;&#23548;&#20986;&#20102;&#28176;&#36827;&#26368;&#20248;&#25277;&#26679;&#27604;&#20363;&#20197;&#23454;&#29616;&#36873;&#25321;&#35823;&#25253;&#27010;&#29575;&#30340;&#26368;&#22351;&#24773;&#20917;&#30340;&#26368;&#20248;&#22823;&#20559;&#24046;&#29575;&#12290;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#25277;&#26679;&#31574;&#30053;&#26159;&#19968;&#33268;&#30340;&#65292;&#24182;&#19988;&#20854;&#28176;&#36817;&#25277;&#26679;&#27604;&#29575;&#26159;&#28176;&#36817;&#26368;&#20248;&#30340;&#12290;&#25968;&#23383;&#23454;&#39564;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#25913;&#21892;&#20102;&#36873;&#25321;&#19978;&#19979;&#25991;&#30456;&#20851;&#35774;&#35745;&#30340;&#21069;m&#20010;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a simulation optimization problem for a context-dependent decision-making, which aims to determine the top-m designs for all contexts. Under a Bayesian framework, we formulate the optimal dynamic sampling decision as a stochastic dynamic programming problem, and develop a sequential sampling policy to efficiently learn the performance of each design under each context. The asymptotically optimal sampling ratios are derived to attain the optimal large deviations rate of the worst-case of probability of false selection. The proposed sampling policy is proved to be consistent and its asymptotic sampling ratios are asymptotically optimal. Numerical experiments demonstrate that the proposed method improves the efficiency for selection of top-m context-dependent designs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21452;&#26102;&#38388;&#23610;&#24230;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#28201;&#21644;&#26465;&#20214;&#19979;&#25910;&#25947;&#24615;&#65292;&#35813;&#26694;&#26550;&#21253;&#25324;&#20102;&#21508;&#31181;&#27969;&#34892;&#30340;Adam&#23478;&#26063;&#31639;&#27861;&#65292;&#29992;&#20110;&#35757;&#32451;&#26080;&#24179;&#28369;&#31070;&#32463;&#32593;&#32476;&#21644;&#24212;&#23545;&#37325;&#23614;&#22122;&#22768;&#30340;&#38656;&#27714;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#34920;&#26126;&#20102;&#20854;&#25928;&#29575;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.03938</link><description>&lt;p&gt;
Adam&#23478;&#26063;&#31639;&#27861;&#22312;&#26080;&#24179;&#28369;&#20248;&#21270;&#20013;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Adam-family Methods for Nonsmooth Optimization with Convergence Guarantees. (arXiv:2305.03938v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03938
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21452;&#26102;&#38388;&#23610;&#24230;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#28201;&#21644;&#26465;&#20214;&#19979;&#25910;&#25947;&#24615;&#65292;&#35813;&#26694;&#26550;&#21253;&#25324;&#20102;&#21508;&#31181;&#27969;&#34892;&#30340;Adam&#23478;&#26063;&#31639;&#27861;&#65292;&#29992;&#20110;&#35757;&#32451;&#26080;&#24179;&#28369;&#31070;&#32463;&#32593;&#32476;&#21644;&#24212;&#23545;&#37325;&#23614;&#22122;&#22768;&#30340;&#38656;&#27714;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#34920;&#26126;&#20102;&#20854;&#25928;&#29575;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;Adam&#23478;&#26063;&#31639;&#27861;&#22312;&#26080;&#24179;&#28369;&#20248;&#21270;&#20013;&#30340;&#25910;&#25947;&#24615;&#36827;&#34892;&#20102;&#20840;&#38754;&#30740;&#31350;&#65292;&#29305;&#21035;&#26159;&#22312;&#26080;&#24179;&#28369;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#20013;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21452;&#26102;&#38388;&#23610;&#24230;&#26694;&#26550;&#65292;&#37319;&#29992;&#21452;&#26102;&#38388;&#23610;&#24230;&#26356;&#26032;&#26041;&#26696;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#28201;&#21644;&#26465;&#20214;&#19979;&#30340;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21253;&#25324;&#20102;&#21508;&#31181;&#27969;&#34892;&#30340;Adam&#23478;&#26063;&#31639;&#27861;&#65292;&#22312;&#35757;&#32451;&#26080;&#24179;&#28369;&#31070;&#32463;&#32593;&#32476;&#20013;&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#38543;&#26426;&#27425;&#26799;&#24230;&#26041;&#27861;&#65292;&#32467;&#21512;&#26799;&#24230;&#35009;&#21098;&#25216;&#26415;&#65292;&#29992;&#20110;&#35757;&#32451;&#20855;&#26377;&#37325;&#23614;&#22122;&#22768;&#30340;&#26080;&#24179;&#28369;&#31070;&#32463;&#32593;&#32476;&#12290;&#36890;&#36807;&#25105;&#20204;&#30340;&#26694;&#26550;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#29978;&#33267;&#22312;&#20165;&#20551;&#23450;&#35780;&#20272;&#22122;&#22768;&#21487;&#31215;&#30340;&#24773;&#20917;&#19979;&#20063;&#20250;&#25910;&#25947;&#12290;&#24191;&#27867;&#30340;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#39640;&#25928;&#24615;&#21644;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present a comprehensive study on the convergence properties of Adam-family methods for nonsmooth optimization, especially in the training of nonsmooth neural networks. We introduce a novel two-timescale framework that adopts a two-timescale updating scheme, and prove its convergence properties under mild assumptions. Our proposed framework encompasses various popular Adam-family methods, providing convergence guarantees for these methods in training nonsmooth neural networks. Furthermore, we develop stochastic subgradient methods that incorporate gradient clipping techniques for training nonsmooth neural networks with heavy-tailed noise. Through our framework, we show that our proposed methods converge even when the evaluation noises are only assumed to be integrable. Extensive numerical experiments demonstrate the high efficiency and robustness of our proposed methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36712;&#36857;&#30340;&#20248;&#21270;&#26041;&#27861;&#26469;&#22788;&#29702;&#38543;&#26426;&#27969;&#34892;&#30149;&#23398;&#27169;&#22411;&#65292;&#21487;&#20197;&#25214;&#21040;&#19982;&#23454;&#38469;&#35266;&#27979;&#20540;&#25509;&#36817;&#30340;&#23454;&#38469;&#36712;&#36857;&#65292;&#32780;&#19981;&#26159;&#20165;&#20351;&#24179;&#22343;&#27169;&#25311;&#32467;&#26524;&#19982;&#23454;&#27979;&#25968;&#25454;&#30456;&#31526;&#12290;</title><link>http://arxiv.org/abs/2305.03926</link><description>&lt;p&gt;
&#22522;&#20110;&#36712;&#36857;&#30340;&#38543;&#26426;&#27969;&#34892;&#30149;&#23398;&#27169;&#22411;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Trajectory-oriented optimization of stochastic epidemiological models. (arXiv:2305.03926v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03926
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36712;&#36857;&#30340;&#20248;&#21270;&#26041;&#27861;&#26469;&#22788;&#29702;&#38543;&#26426;&#27969;&#34892;&#30149;&#23398;&#27169;&#22411;&#65292;&#21487;&#20197;&#25214;&#21040;&#19982;&#23454;&#38469;&#35266;&#27979;&#20540;&#25509;&#36817;&#30340;&#23454;&#38469;&#36712;&#36857;&#65292;&#32780;&#19981;&#26159;&#20165;&#20351;&#24179;&#22343;&#27169;&#25311;&#32467;&#26524;&#19982;&#23454;&#27979;&#25968;&#25454;&#30456;&#31526;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#38543;&#26426;&#27169;&#22411;&#65292;&#20026;&#20102;&#36827;&#34892;&#39044;&#27979;&#21644;&#36816;&#34892;&#27169;&#25311;&#65292;&#38656;&#35201;&#36827;&#34892;&#22320;&#38754;&#23454;&#27979;&#26631;&#23450;&#12290;&#30001;&#20110;&#36755;&#20986;&#32467;&#26524;&#36890;&#24120;&#26159;&#36890;&#36807;&#38598;&#25104;&#25110;&#20998;&#24067;&#26469;&#25551;&#36848;&#65292;&#22240;&#27492;&#38656;&#35201;&#23545;&#27599;&#20010;&#25104;&#21592;&#36827;&#34892;&#26631;&#23450;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#20195;&#29702;&#21644;Thompson&#37319;&#26679;&#30340;&#20248;&#21270;&#31574;&#30053;&#26469;&#23547;&#25214;&#19982;&#20107;&#23454;&#30456;&#19968;&#33268;&#30340;&#36755;&#20837;&#21442;&#25968;&#35774;&#32622;&#21644;&#38543;&#26426;&#25968;&#31181;&#23376;&#65292;&#35813;Trajectory Oriented Optimization&#65288;TOO&#65289;&#26041;&#27861;&#21487;&#20197;&#20135;&#29983;&#19982;&#23454;&#38469;&#35266;&#27979;&#20540;&#25509;&#36817;&#30340;&#23454;&#38469;&#36712;&#36857;&#65292;&#32780;&#19981;&#26159;&#20165;&#34429;&#28982;&#27169;&#25311;&#30340;&#24179;&#22343;&#34892;&#20026;&#19982;&#20107;&#23454;&#30456;&#31526;&#12290;
&lt;/p&gt;
&lt;p&gt;
Epidemiological models must be calibrated to ground truth for downstream tasks such as producing forward projections or running what-if scenarios. The meaning of calibration changes in case of a stochastic model since output from such a model is generally described via an ensemble or a distribution. Each member of the ensemble is usually mapped to a random number seed (explicitly or implicitly). With the goal of finding not only the input parameter settings but also the random seeds that are consistent with the ground truth, we propose a class of Gaussian process (GP) surrogates along with an optimization strategy based on Thompson sampling. This Trajectory Oriented Optimization (TOO) approach produces actual trajectories close to the empirical observations instead of a set of parameter settings where only the mean simulation behavior matches with the ground truth.
&lt;/p&gt;</description></item><item><title>TSVQR&#33021;&#22815;&#25429;&#25417;&#29616;&#20195;&#25968;&#25454;&#20013;&#30340;&#24322;&#36136;&#21644;&#19981;&#23545;&#31216;&#20449;&#24687;&#65292;&#24182;&#26377;&#25928;&#22320;&#25551;&#36848;&#20102;&#25152;&#26377;&#25968;&#25454;&#28857;&#30340;&#24322;&#36136;&#20998;&#24067;&#20449;&#24687;&#12290;&#36890;&#36807;&#26500;&#36896;&#20004;&#20010;&#36739;&#23567;&#30340;&#20108;&#27425;&#35268;&#21010;&#38382;&#39064;&#65292;TSVQR&#29983;&#25104;&#20004;&#20010;&#38750;&#24179;&#34892;&#24179;&#38754;&#65292;&#27979;&#37327;&#27599;&#20010;&#20998;&#20301;&#25968;&#27700;&#24179;&#19979;&#38480;&#21644;&#19978;&#38480;&#20043;&#38388;&#30340;&#20998;&#24067;&#19981;&#23545;&#31216;&#24615;&#12290;&#22312;&#22810;&#20010;&#23454;&#39564;&#20013;&#65292;TSVQR&#20248;&#20110;&#20197;&#21069;&#30340;&#20998;&#20301;&#25968;&#22238;&#24402;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.03894</link><description>&lt;p&gt;
&#21452;&#25903;&#25345;&#21521;&#37327;&#20998;&#20301;&#25968;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Twin support vector quantile regression. (arXiv:2305.03894v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03894
&lt;/p&gt;
&lt;p&gt;
TSVQR&#33021;&#22815;&#25429;&#25417;&#29616;&#20195;&#25968;&#25454;&#20013;&#30340;&#24322;&#36136;&#21644;&#19981;&#23545;&#31216;&#20449;&#24687;&#65292;&#24182;&#26377;&#25928;&#22320;&#25551;&#36848;&#20102;&#25152;&#26377;&#25968;&#25454;&#28857;&#30340;&#24322;&#36136;&#20998;&#24067;&#20449;&#24687;&#12290;&#36890;&#36807;&#26500;&#36896;&#20004;&#20010;&#36739;&#23567;&#30340;&#20108;&#27425;&#35268;&#21010;&#38382;&#39064;&#65292;TSVQR&#29983;&#25104;&#20004;&#20010;&#38750;&#24179;&#34892;&#24179;&#38754;&#65292;&#27979;&#37327;&#27599;&#20010;&#20998;&#20301;&#25968;&#27700;&#24179;&#19979;&#38480;&#21644;&#19978;&#38480;&#20043;&#38388;&#30340;&#20998;&#24067;&#19981;&#23545;&#31216;&#24615;&#12290;&#22312;&#22810;&#20010;&#23454;&#39564;&#20013;&#65292;TSVQR&#20248;&#20110;&#20197;&#21069;&#30340;&#20998;&#20301;&#25968;&#22238;&#24402;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#25903;&#25345;&#21521;&#37327;&#20998;&#20301;&#25968;&#22238;&#24402;(TSVQR)&#65292;&#29992;&#20110;&#25429;&#25417;&#29616;&#20195;&#25968;&#25454;&#20013;&#24322;&#36136;&#21644;&#19981;&#23545;&#31216;&#20449;&#24687;&#12290;TSVQR&#21033;&#29992;&#20998;&#20301;&#25968;&#21442;&#25968;&#26377;&#25928;&#22320;&#25551;&#36848;&#20102;&#25152;&#26377;&#25968;&#25454;&#28857;&#30340;&#24322;&#36136;&#20998;&#24067;&#20449;&#24687;&#12290;&#30456;&#24212;&#22320;&#65292;TSVQR&#26500;&#36896;&#20102;&#20004;&#20010;&#36739;&#23567;&#30340;&#20108;&#27425;&#35268;&#21010;&#38382;&#39064;(QPPs)&#65292;&#29983;&#25104;&#20004;&#20010;&#38750;&#24179;&#34892;&#24179;&#38754;&#65292;&#20197;&#27979;&#37327;&#27599;&#20010;&#20998;&#20301;&#25968;&#27700;&#24179;&#19979;&#38480;&#21644;&#19978;&#38480;&#20043;&#38388;&#30340;&#20998;&#24067;&#19981;&#23545;&#31216;&#24615;&#12290;TSVQR&#20013;&#30340;QPP&#27604;&#20197;&#21069;&#30340;&#20998;&#20301;&#25968;&#22238;&#24402;&#26041;&#27861;&#26356;&#23567;&#19988;&#26356;&#26131;&#20110;&#35299;&#20915;&#12290;&#27492;&#22806;&#65292;TSVQR&#30340;&#21452;&#37325;&#22352;&#26631;&#19979;&#38477;&#31639;&#27861;&#20063;&#21152;&#36895;&#20102;&#35757;&#32451;&#36895;&#24230;&#12290;&#22312;&#20845;&#20010;&#20154;&#36896;&#25968;&#25454;&#38598;&#12289;&#20116;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#12289;&#20004;&#20010;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#12289;&#20004;&#20010;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#21644;&#20004;&#20010;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;TSVQR&#22312;&#23436;&#20840;&#25429;&#33719;&#24322;&#36136;&#24615;&#26041;&#38754;&#30340;&#25928;&#26524;&#20248;&#20110;&#20197;&#21069;&#30340;&#20998;&#20301;&#25968;&#22238;&#24402;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a twin support vector quantile regression (TSVQR) to capture the heterogeneous and asymmetric information in modern data. Using a quantile parameter, TSVQR effectively depicts the heterogeneous distribution information with respect to all portions of data points. Correspondingly, TSVQR constructs two smaller sized quadratic programming problems (QPPs) to generate two nonparallel planes to measure the distributional asymmetry between the lower and upper bounds at each quantile level. The QPPs in TSVQR are smaller and easier to solve than those in previous quantile regression methods. Moreover, the dual coordinate descent algorithm for TSVQR also accelerates the training speed. Experimental results on six artiffcial data sets, ffve benchmark data sets, two large scale data sets, two time-series data sets, and two imbalanced data sets indicate that the TSVQR outperforms previous quantile regression methods in terms of the effectiveness of completely capturing the heterogeneous 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#24352;&#37327;&#36172;&#21338;&#26426;&#27169;&#22411;&#65292;&#20854;&#20013;&#34892;&#21160;&#21644;&#31995;&#32479;&#21442;&#25968;&#30001;&#24352;&#37327;&#34920;&#31034;&#65292;&#30528;&#37325;&#20110;&#26410;&#30693;&#31995;&#32479;&#24352;&#37327;&#20026;&#20302;&#31209;&#30340;&#24773;&#20917;&#12290;&#25152;&#24320;&#21457;&#30340; TOFU &#31639;&#27861;&#39318;&#20808;&#21033;&#29992;&#28789;&#27963;&#30340;&#24352;&#37327;&#22238;&#24402;&#25216;&#26415;&#20272;&#35745;&#19982;&#31995;&#32479;&#24352;&#37327;&#30456;&#20851;&#32852;&#30340;&#20302;&#32500;&#23376;&#31354;&#38388;&#65292;&#28982;&#21518;&#23558;&#21407;&#22987;&#38382;&#39064;&#36716;&#25442;&#25104;&#19968;&#20010;&#20855;&#26377;&#31995;&#32479;&#21442;&#25968;&#33539;&#25968;&#32422;&#26463;&#30340;&#26032;&#38382;&#39064;&#65292;&#24182;&#37319;&#29992;&#33539;&#25968;&#32422;&#26463;&#36172;&#21338;&#23376;&#20363;&#31243;&#35299;&#20915;&#12290;</title><link>http://arxiv.org/abs/2305.03884</link><description>&lt;p&gt;
&#39640;&#32500;&#20302;&#31209;&#24352;&#37327;&#36172;&#21338;&#26426;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On High-dimensional and Low-rank Tensor Bandits. (arXiv:2305.03884v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03884
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#24352;&#37327;&#36172;&#21338;&#26426;&#27169;&#22411;&#65292;&#20854;&#20013;&#34892;&#21160;&#21644;&#31995;&#32479;&#21442;&#25968;&#30001;&#24352;&#37327;&#34920;&#31034;&#65292;&#30528;&#37325;&#20110;&#26410;&#30693;&#31995;&#32479;&#24352;&#37327;&#20026;&#20302;&#31209;&#30340;&#24773;&#20917;&#12290;&#25152;&#24320;&#21457;&#30340; TOFU &#31639;&#27861;&#39318;&#20808;&#21033;&#29992;&#28789;&#27963;&#30340;&#24352;&#37327;&#22238;&#24402;&#25216;&#26415;&#20272;&#35745;&#19982;&#31995;&#32479;&#24352;&#37327;&#30456;&#20851;&#32852;&#30340;&#20302;&#32500;&#23376;&#31354;&#38388;&#65292;&#28982;&#21518;&#23558;&#21407;&#22987;&#38382;&#39064;&#36716;&#25442;&#25104;&#19968;&#20010;&#20855;&#26377;&#31995;&#32479;&#21442;&#25968;&#33539;&#25968;&#32422;&#26463;&#30340;&#26032;&#38382;&#39064;&#65292;&#24182;&#37319;&#29992;&#33539;&#25968;&#32422;&#26463;&#36172;&#21338;&#23376;&#20363;&#31243;&#35299;&#20915;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#32447;&#24615;&#36172;&#21338;&#26426;&#30340;&#30740;&#31350;&#37117;&#20391;&#37325;&#20110;&#25972;&#20010;&#31995;&#32479;&#30340;&#19968;&#32500;&#29305;&#24449;&#12290;&#34429;&#28982;&#20195;&#34920;&#24615;&#24456;&#24378;&#65292;&#20294;&#36825;&#31181;&#26041;&#27861;&#21487;&#33021;&#19981;&#33021;&#27169;&#25311;&#39640;&#32500;&#20294;&#26377;&#20248;&#21183;&#32467;&#26500;&#30340;&#24212;&#29992;&#65292;&#20363;&#22914;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#30340;&#20302;&#31209;&#24352;&#37327;&#34920;&#31034;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#24352;&#37327;&#36172;&#21338;&#26426;&#27169;&#22411;&#65292;&#20854;&#20013;&#34892;&#21160;&#21644;&#31995;&#32479;&#21442;&#25968;&#30001;&#24352;&#37327;&#34920;&#31034;&#65292;&#32780;&#25105;&#20204;&#29305;&#21035;&#20851;&#27880;&#26410;&#30693;&#31995;&#32479;&#24352;&#37327;&#20026;&#20302;&#31209;&#30340;&#24773;&#20917;&#12290;&#21457;&#23637;&#20102;&#19968;&#31181;&#26032;&#30340;&#36172;&#21338;&#26426;&#31639;&#27861;TOFU&#65288;&#19981;&#30830;&#23450;&#24615;&#20013;&#30340;&#24352;&#37327;&#20048;&#35266;&#65289;&#65292;&#35813;&#31639;&#27861;&#39318;&#20808;&#21033;&#29992;&#28789;&#27963;&#30340;&#24352;&#37327;&#22238;&#24402;&#25216;&#26415;&#20272;&#35745;&#19982;&#31995;&#32479;&#24352;&#37327;&#30456;&#20851;&#32852;&#30340;&#20302;&#32500;&#23376;&#31354;&#38388;&#12290;&#28982;&#21518;&#21033;&#29992;&#36825;&#20123;&#20272;&#35745;&#23558;&#21407;&#22987;&#38382;&#39064;&#36716;&#25442;&#20026;&#19968;&#20010;&#20855;&#26377;&#20854;&#31995;&#32479;&#21442;&#25968;&#33539;&#25968;&#32422;&#26463;&#30340;&#26032;&#38382;&#39064;&#12290;&#26368;&#21518;&#65292;TOFU&#37319;&#29992;&#33539;&#25968;&#32422;&#26463;&#36172;&#21338;&#23376;&#20363;&#31243;&#65292;&#21033;&#29992;&#36825;&#20123;&#32422;&#26463;&#26469;&#23454;&#29616;&#38382;&#39064;&#30340;&#35299;&#20915;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most existing studies on linear bandits focus on the one-dimensional characterization of the overall system. While being representative, this formulation may fail to model applications with high-dimensional but favorable structures, such as the low-rank tensor representation for recommender systems. To address this limitation, this work studies a general tensor bandits model, where actions and system parameters are represented by tensors as opposed to vectors, and we particularly focus on the case that the unknown system tensor is low-rank. A novel bandit algorithm, coined TOFU (Tensor Optimism in the Face of Uncertainty), is developed. TOFU first leverages flexible tensor regression techniques to estimate low-dimensional subspaces associated with the system tensor. These estimates are then utilized to convert the original problem to a new one with norm constraints on its system parameters. Lastly, a norm-constrained bandit subroutine is adopted by TOFU, which utilizes these constraint
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#27979;&#37327;&#25968;&#25454;&#23398;&#20064;&#26410;&#30693;&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#30340;&#25968;&#20540;&#26694;&#26550;&#38543;&#26426;&#27969;&#26144;&#23556;&#23398;&#20064;&#65288;sFML&#65289;&#65292;&#22312;&#19981;&#21516;&#31867;&#22411;&#30340;&#38543;&#26426;&#31995;&#32479;&#19978;&#36827;&#34892;&#30340;&#20840;&#38754;&#23454;&#39564;&#35777;&#26126;&#20102; sFML &#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.03874</link><description>&lt;p&gt;
&#36890;&#36807;&#27969;&#26144;&#23556;&#31639;&#23376;&#23398;&#20064;&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Learning Stochastic Dynamical System via Flow Map Operator. (arXiv:2305.03874v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03874
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#27979;&#37327;&#25968;&#25454;&#23398;&#20064;&#26410;&#30693;&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#30340;&#25968;&#20540;&#26694;&#26550;&#38543;&#26426;&#27969;&#26144;&#23556;&#23398;&#20064;&#65288;sFML&#65289;&#65292;&#22312;&#19981;&#21516;&#31867;&#22411;&#30340;&#38543;&#26426;&#31995;&#32479;&#19978;&#36827;&#34892;&#30340;&#20840;&#38754;&#23454;&#39564;&#35777;&#26126;&#20102; sFML &#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#27979;&#37327;&#25968;&#25454;&#23398;&#20064;&#26410;&#30693;&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#30340;&#25968;&#20540;&#26694;&#26550;&#12290;&#31216;&#20026;&#38543;&#26426;&#27969;&#26144;&#23556;&#23398;&#20064;&#65288;sFML&#65289;&#65292;&#36825;&#20010;&#26032;&#26694;&#26550;&#26159;&#27969;&#26144;&#23556;&#23398;&#20064;&#65288;FML&#65289;&#30340;&#25193;&#23637;&#65292;&#21518;&#32773;&#26159;&#20026;&#20102;&#23398;&#20064;&#30830;&#23450;&#24615;&#21160;&#21147;&#23398;&#31995;&#32479;&#32780;&#24320;&#21457;&#30340;&#12290;&#23545;&#20110;&#23398;&#20064;&#38543;&#26426;&#31995;&#32479;&#65292;&#25105;&#20204;&#23450;&#20041;&#20102;&#19968;&#20010;&#38543;&#26426;&#27969;&#26144;&#23556;&#65292;&#23427;&#26159;&#20004;&#20010;&#23376;&#27969;&#26144;&#23556;&#30340;&#21472;&#21152;&#65306;&#19968;&#20010;&#30830;&#23450;&#24615;&#23376;&#26144;&#23556;&#21644;&#19968;&#20010;&#38543;&#26426;&#23376;&#26144;&#23556;&#12290;&#38543;&#26426;&#35757;&#32451;&#25968;&#25454;&#39318;&#20808;&#29992;&#20110;&#26500;&#24314;&#30830;&#23450;&#24615;&#23376;&#26144;&#23556;&#65292;&#28982;&#21518;&#26159;&#38543;&#26426;&#23376;&#26144;&#23556;&#12290;&#30830;&#23450;&#24615;&#23376;&#26144;&#23556;&#37319;&#29992;&#27531;&#24046;&#32593;&#32476;&#65288;ResNet&#65289;&#24418;&#24335;&#65292;&#31867;&#20284;&#20110;FML&#23545;&#20110;&#30830;&#23450;&#24615;&#31995;&#32479;&#30340;&#24037;&#20316;&#12290;&#23545;&#20110;&#38543;&#26426;&#23376;&#26144;&#23556;&#65292;&#25105;&#20204;&#37319;&#29992;&#29983;&#25104;&#27169;&#22411;&#65292;&#23588;&#20854;&#26159;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#22312;&#26412;&#25991;&#20013;&#24212;&#29992;&#12290;&#26368;&#32456;&#26500;&#24314;&#30340;&#38543;&#26426;&#27969;&#26144;&#23556;&#23450;&#20041;&#20102;&#19968;&#20010;&#38543;&#26426;&#28436;&#21270;&#27169;&#22411;&#65292;&#23427;&#22312;&#20998;&#24067;&#26041;&#38754;&#26159;&#26410;&#30693;&#38543;&#26426;&#31995;&#32479;&#30340;&#24369;&#36817;&#20284;&#12290;&#22312;&#19981;&#21516;&#31867;&#22411;&#30340;&#38543;&#26426;&#31995;&#32479;&#19978;&#36827;&#34892;&#30340;&#20840;&#38754;&#23454;&#39564;&#35777;&#26126;&#20102;sFML&#25581;&#31034;&#26410;&#30693;&#38543;&#26426;&#31995;&#32479;&#21508;&#31181;&#31867;&#22411;&#30340;&#38750;&#32447;&#24615;&#12289;&#22122;&#22768;&#21327;&#26041;&#24046;&#32467;&#26500;&#21644;&#26102;&#38388;&#30456;&#20851;&#29305;&#24615;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a numerical framework for learning unknown stochastic dynamical systems using measurement data. Termed stochastic flow map learning (sFML), the new framework is an extension of flow map learning (FML) that was developed for learning deterministic dynamical systems. For learning stochastic systems, we define a stochastic flow map that is a superposition of two sub-flow maps: a deterministic sub-map and a stochastic sub-map. The stochastic training data are used to construct the deterministic sub-map first, followed by the stochastic sub-map. The deterministic sub-map takes the form of residual network (ResNet), similar to the work of FML for deterministic systems. For the stochastic sub-map, we employ a generative model, particularly generative adversarial networks (GANs) in this paper. The final constructed stochastic flow map then defines a stochastic evolution model that is a weak approximation, in term of distribution, of the unknown stochastic system. A comprehensive set
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;CUQB&#65292;&#26469;&#35299;&#20915;&#22797;&#21512;&#20989;&#25968;&#65288;&#28151;&#21512;&#27169;&#22411;&#65289;&#30340;&#39640;&#25928;&#32422;&#26463;&#20840;&#23616;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#25928;&#26524;&#65292;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#30340;&#24212;&#29992;&#31243;&#24207;&#20013;&#22343;&#24471;&#21040;&#20102;&#39564;&#35777;&#65292;&#21253;&#25324;&#36827;&#34892;&#20102;&#26368;&#20248;&#25511;&#21046;&#30340;&#27969;&#20307;&#27969;&#37327;&#21644;&#25299;&#25169;&#32467;&#26500;&#20248;&#21270;&#65292;&#21518;&#32773;&#27604;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#35774;&#35745;&#24378;2&#20493;&#12290;</title><link>http://arxiv.org/abs/2305.03824</link><description>&lt;p&gt;
&#26080;&#36951;&#25022;&#30340;&#32422;&#26463;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#29992;&#20110;&#24102;&#26377;&#22122;&#22768;&#21644;&#26114;&#36149;&#28151;&#21512;&#27169;&#22411;&#30340;&#24046;&#20998;&#20998;&#20301;&#25968;&#20989;&#25968;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
No-Regret Constrained Bayesian Optimization of Noisy and Expensive Hybrid Models using Differentiable Quantile Function Approximations. (arXiv:2305.03824v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03824
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;CUQB&#65292;&#26469;&#35299;&#20915;&#22797;&#21512;&#20989;&#25968;&#65288;&#28151;&#21512;&#27169;&#22411;&#65289;&#30340;&#39640;&#25928;&#32422;&#26463;&#20840;&#23616;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#25928;&#26524;&#65292;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#30340;&#24212;&#29992;&#31243;&#24207;&#20013;&#22343;&#24471;&#21040;&#20102;&#39564;&#35777;&#65292;&#21253;&#25324;&#36827;&#34892;&#20102;&#26368;&#20248;&#25511;&#21046;&#30340;&#27969;&#20307;&#27969;&#37327;&#21644;&#25299;&#25169;&#32467;&#26500;&#20248;&#21270;&#65292;&#21518;&#32773;&#27604;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#35774;&#35745;&#24378;2&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22797;&#21512;&#20989;&#25968;&#65288;&#28151;&#21512;&#27169;&#22411;&#65289;&#30340;&#39640;&#25928;&#32422;&#26463;&#20840;&#23616;&#20248;&#21270;&#38382;&#39064;&#65292;&#35813;&#27169;&#22411;&#30340;&#36755;&#20837;&#26159;&#20855;&#26377;&#30690;&#37327;&#20540;&#36755;&#20986;&#21644;&#26377;&#22122;&#22768;&#35266;&#27979;&#30340;&#26114;&#36149;&#40657;&#30418;&#20989;&#25968;&#65292;&#36825;&#22312;&#23454;&#38469;&#30340;&#31185;&#23398;&#12289;&#24037;&#31243;&#12289;&#21046;&#36896;&#21644;&#25511;&#21046;&#24212;&#29992;&#20013;&#32463;&#24120;&#20986;&#29616;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;Constrained Upper Quantile Bound&#65288;CUQB&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#36825;&#31181;&#38382;&#39064;&#65292;&#30452;&#25509;&#21033;&#29992;&#20102;&#25105;&#20204;&#23637;&#31034;&#30340;&#30446;&#26631;&#21644;&#32422;&#26463;&#20989;&#25968;&#30340;&#22797;&#21512;&#32467;&#26500;&#65292;&#20174;&#32780;&#22823;&#22823;&#25552;&#39640;&#20102;&#37319;&#26679;&#25928;&#29575;&#12290;CUQB&#30340;&#27010;&#24565;&#31616;&#21333;&#65292;&#36991;&#20813;&#20102;&#20808;&#21069;&#26041;&#27861;&#25152;&#20351;&#29992;&#30340;&#32422;&#26463;&#36924;&#36817;&#12290;&#34429;&#28982;CUQB&#30340;&#25910;&#36141;&#20989;&#25968;&#19981;&#22312;&#23553;&#38381;&#24418;&#24335;&#20013;&#65292;&#20294;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21487;&#24494;&#38543;&#26426;&#36924;&#36817;&#65292;&#20351;&#20854;&#33021;&#22815;&#26377;&#25928;&#22320;&#26368;&#22823;&#21270;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#24471;&#20986;&#20102;&#23545;&#20110;&#32047;&#31215;&#36951;&#25022;&#21644;&#32422;&#26463;&#36829;&#35268;&#30340;&#30028;&#38480;&#12290;&#30001;&#20110;&#22312;&#26576;&#20123;&#35268;&#21017;&#20551;&#35774;&#19979;&#36825;&#20123;&#30028;&#38480;&#23545;&#36845;&#20195;&#27425;&#25968;&#20855;&#26377;&#27425;&#32447;&#24615;&#20381;&#36182;&#24615;&#65292;&#22240;&#27492;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#26080;&#36951;&#25022;&#24182;&#28385;&#36275;&#32422;&#26463;&#26465;&#20214;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#21512;&#25104;&#21644;&#30495;&#23454;&#30340;&#24212;&#29992;&#31243;&#24207;&#20013;&#23637;&#31034;&#20102;CUQB&#30340;&#21151;&#25928;&#65292;&#21253;&#25324;&#26725;&#26550;&#25299;&#25169; - &#22312;&#20854;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#30340;&#32467;&#26500;&#27604;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#35774;&#35745;&#24378;2&#20493; - &#20197;&#21450;&#27969;&#20307;&#27969;&#37327;&#30340;&#26368;&#20248;&#25511;&#21046;&#65292;&#20854;&#20013;&#25105;&#20204;&#20351;&#29992;&#30340;&#26041;&#27861;&#27604;&#20197;&#21069;&#30340;&#26041;&#27861;&#23569;&#20102;3&#20493;&#30340;&#27169;&#25311;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates the problem of efficient constrained global optimization of composite functions (hybrid models) whose input is an expensive black-box function with vector-valued outputs and noisy observations, which often arises in real-world science, engineering, manufacturing, and control applications. We propose a novel algorithm, Constrained Upper Quantile Bound (CUQB), to solve such problems that directly exploits the composite structure of the objective and constraint functions that we show leads substantially improved sampling efficiency. CUQB is conceptually simple and avoids the constraint approximations used by previous methods. Although the CUQB acquisition function is not available in closed form, we propose a novel differentiable stochastic approximation that enables it to be efficiently maximized. We further derive bounds on the cumulative regret and constraint violation. Since these bounds depend sublinearly on the number of iterations under some regularity assum
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20551;&#35774;&#26816;&#39564;&#21644;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#26469;&#35780;&#20272;&#26657;&#20934;&#65292;&#24182;&#25552;&#20379;&#19968;&#31181;&#22823;&#32966;&#20877;&#26657;&#20934;&#31574;&#30053;&#65292;&#20351;&#23454;&#36341;&#32773;&#33021;&#22815;&#22312;&#28385;&#36275;&#25152;&#38656;&#30340;&#26657;&#20934;&#27700;&#24179;&#30340;&#24773;&#20917;&#19979;&#36127;&#36131;&#20219;&#22320;&#22686;&#24378;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2305.03780</link><description>&lt;p&gt;
&#20108;&#20803;&#20107;&#20214;&#30340;&#26657;&#20934;&#35780;&#20272;&#21644;&#22823;&#32966;&#20877;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Calibration Assessment and Boldness-Recalibration for Binary Events. (arXiv:2305.03780v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03780
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20551;&#35774;&#26816;&#39564;&#21644;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#26469;&#35780;&#20272;&#26657;&#20934;&#65292;&#24182;&#25552;&#20379;&#19968;&#31181;&#22823;&#32966;&#20877;&#26657;&#20934;&#31574;&#30053;&#65292;&#20351;&#23454;&#36341;&#32773;&#33021;&#22815;&#22312;&#28385;&#36275;&#25152;&#38656;&#30340;&#26657;&#20934;&#27700;&#24179;&#30340;&#24773;&#20917;&#19979;&#36127;&#36131;&#20219;&#22320;&#22686;&#24378;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27010;&#29575;&#39044;&#27979;&#23545;&#20110;&#21307;&#23398;&#12289;&#32463;&#27982;&#12289;&#22270;&#20687;&#20998;&#31867;&#12289;&#20307;&#32946;&#20998;&#26512;&#12289;&#23089;&#20048;&#31561;&#35768;&#22810;&#39046;&#22495;&#20013;&#30340;&#20915;&#31574;&#21046;&#23450;&#33267;&#20851;&#37325;&#35201;&#12290;&#29702;&#24819;&#24773;&#20917;&#19979;&#65292;&#27010;&#29575;&#39044;&#27979;&#24212;&#35813; (i) &#26657;&#20934;&#33391;&#22909; (ii) &#20934;&#30830; (iii) &#22823;&#32966;&#65292;&#21363;&#36828;&#31163;&#20107;&#20214;&#30340;&#22522;&#30784;&#39057;&#29575;&#12290;&#28385;&#36275;&#36825;&#19977;&#20010;&#26465;&#20214;&#30340;&#39044;&#27979;&#23545;&#20110;&#20915;&#31574;&#21046;&#23450;&#26159;&#26377;&#20449;&#24687;&#37327;&#30340;&#12290;&#28982;&#32780;&#65292;&#26657;&#20934;&#21644;&#22823;&#32966;&#20043;&#38388;&#23384;&#22312;&#22522;&#26412;&#30340;&#32039;&#24352;&#20851;&#31995;&#65292;&#22240;&#20026;&#24403;&#39044;&#27979;&#36807;&#20110;&#35880;&#24910;&#26102;(&#21363;&#38750;&#22823;&#32966;)&#26657;&#20934;&#24230;&#37327;&#21487;&#20197;&#24456;&#39640;&#12290;&#26412;&#25991;&#30340;&#30446;&#30340;&#26159;&#24320;&#21457;&#19968;&#31181;&#20551;&#35774;&#26816;&#39564;&#21644;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#26469;&#35780;&#20272;&#26657;&#20934;&#65292;&#24182;&#25552;&#20379;&#19968;&#31181;&#22823;&#32966;&#20877;&#26657;&#20934;&#31574;&#30053;&#65292;&#20351;&#23454;&#36341;&#32773;&#33021;&#22815;&#22312;&#28385;&#36275;&#25152;&#38656;&#30340;&#26657;&#20934;&#27700;&#24179;&#30340;&#24773;&#20917;&#19979;&#36127;&#36131;&#20219;&#22320;&#22686;&#24378;&#39044;&#27979;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20801;&#35768;&#29992;&#25143;&#39044;&#20808;&#25351;&#23450;&#20182;&#20204;&#25152;&#38656;&#30340;&#21518;&#39564;&#26657;&#20934;&#27010;&#29575;&#65292;&#28982;&#21518;&#22312;&#27492;&#32422;&#26463;&#19979;&#26368;&#22823;&#21270;&#22686;&#24378;&#39044;&#27979;&#12290;&#25105;&#20204;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#25968;&#25454;&#24212;&#29992;&#39564;&#35777;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Probability predictions are essential to inform decision making in medicine, economics, image classification, sports analytics, entertainment, and many other fields. Ideally, probability predictions are (i) well calibrated, (ii) accurate, and (iii) bold, i.e., far from the base rate of the event. Predictions that satisfy these three criteria are informative for decision making. However, there is a fundamental tension between calibration and boldness, since calibration metrics can be high when predictions are overly cautious, i.e., non-bold. The purpose of this work is to develop a hypothesis test and Bayesian model selection approach to assess calibration, and a strategy for boldness-recalibration that enables practitioners to responsibly embolden predictions subject to their required level of calibration. Specifically, we allow the user to pre-specify their desired posterior probability of calibration, then maximally embolden predictions subject to this constraint. We verify the perfo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#35770;&#30340;&#36235;&#21183;&#27979;&#24230;&#23450;&#29702;&#35270;&#35282;&#65292;&#35813;&#35270;&#35282;&#23558;&#38543;&#26426;&#36807;&#31243;&#30340;&#26377;&#38480;&#24615;&#19982;&#32034;&#24341;&#24230;&#37327;&#31354;&#38388;&#20803;&#32032;&#30340;&#26377;&#25928;&#21487;&#21464;&#38271;&#24230;&#32534;&#30721;&#30340;&#23384;&#22312;&#24615;&#30456;&#20851;&#32852;&#12290;</title><link>http://arxiv.org/abs/2305.02960</link><description>&lt;p&gt;
Majorizing Measures, Codes, and Information&#65288;&#27979;&#24230;&#20027;&#23548;&#12289;&#30721;&#21644;&#20449;&#24687;&#65289;
&lt;/p&gt;
&lt;p&gt;
Majorizing Measures, Codes, and Information. (arXiv:2305.02960v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02960
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#35770;&#30340;&#36235;&#21183;&#27979;&#24230;&#23450;&#29702;&#35270;&#35282;&#65292;&#35813;&#35270;&#35282;&#23558;&#38543;&#26426;&#36807;&#31243;&#30340;&#26377;&#38480;&#24615;&#19982;&#32034;&#24341;&#24230;&#37327;&#31354;&#38388;&#20803;&#32032;&#30340;&#26377;&#25928;&#21487;&#21464;&#38271;&#24230;&#32534;&#30721;&#30340;&#23384;&#22312;&#24615;&#30456;&#20851;&#32852;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Fernique&#21644;Talagrand&#30340;&#36235;&#21183;&#27979;&#24230;&#23450;&#29702;&#26159;&#38543;&#26426;&#36807;&#31243;&#29702;&#35770;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#32467;&#26524;&#12290;&#23427;&#23558;&#24230;&#37327;&#31354;&#38388;&#20013;&#20803;&#32032;&#32034;&#24341;&#30340;&#38543;&#26426;&#36807;&#31243;&#30340;&#26377;&#38480;&#24615;&#19982;&#26469;&#33258;&#26576;&#20123;&#22810;&#23610;&#24230;&#32452;&#21512;&#32467;&#26500;&#65288;&#22914;&#22635;&#20805;&#21644;&#35206;&#30422;&#26641;&#65289;&#30340;&#22797;&#26434;&#24615;&#24230;&#37327;&#30456;&#20851;&#32852;&#12290;&#26412;&#25991;&#22312;Andreas Maurer&#30340;&#19968;&#20221;&#40092;&#20026;&#20154;&#30693;&#30340;&#39044;&#21360;&#26412;&#20013;&#39318;&#27425;&#27010;&#36848;&#30340;&#24605;&#36335;&#19978;&#26500;&#24314;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#35770;&#30340;&#36235;&#21183;&#27979;&#24230;&#23450;&#29702;&#35270;&#35282;&#65292;&#26681;&#25454;&#35813;&#35270;&#35282;&#65292;&#38543;&#26426;&#36807;&#31243;&#30340;&#26377;&#38480;&#24615;&#26159;&#29992;&#32034;&#24341;&#24230;&#37327;&#31354;&#38388;&#20803;&#32032;&#30340;&#26377;&#25928;&#21487;&#21464;&#38271;&#24230;&#32534;&#30721;&#30340;&#23384;&#22312;&#24615;&#26469;&#34920;&#36848;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
The majorizing measure theorem of Fernique and Talagrand is a fundamental result in the theory of random processes. It relates the boundedness of random processes indexed by elements of a metric space to complexity measures arising from certain multiscale combinatorial structures, such as packing and covering trees. This paper builds on the ideas first outlined in a little-noticed preprint of Andreas Maurer to present an information-theoretic perspective on the majorizing measure theorem, according to which the boundedness of random processes is phrased in terms of the existence of efficient variable-length codes for the elements of the indexing metric space.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#22810;&#20010;&#32467;&#26500;&#39044;&#27979;&#26631;&#20934;&#27979;&#35797;&#20013;&#31934;&#30830;&#35782;&#21035;&#21547;&#26377;100&#20010;&#20197;&#19978;&#21407;&#23376;&#30340;&#35768;&#22810;&#26448;&#26009;&#30340;&#20840;&#23616;&#26368;&#23567;&#32467;&#26500;&#65292;&#24182;&#20197;&#21333;&#27425;&#33021;&#37327;&#35780;&#20272;&#20026;&#22522;&#30784;&#65292;&#21462;&#20195;&#20102;&#37325;&#22797;&#30340;&#31532;&#19968;&#21407;&#29702;&#33021;&#37327;&#35745;&#31639;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2305.02158</link><description>&lt;p&gt;
&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#30340;&#24418;&#25104;&#33021;&#37327;&#39044;&#27979;&#26041;&#27861;&#36827;&#34892;&#29454;&#26538;&#26230;&#20307;&#32467;&#26500;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Shotgun crystal structure prediction using machine-learned formation energies. (arXiv:2305.02158v1 [physics.comp-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02158
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#22810;&#20010;&#32467;&#26500;&#39044;&#27979;&#26631;&#20934;&#27979;&#35797;&#20013;&#31934;&#30830;&#35782;&#21035;&#21547;&#26377;100&#20010;&#20197;&#19978;&#21407;&#23376;&#30340;&#35768;&#22810;&#26448;&#26009;&#30340;&#20840;&#23616;&#26368;&#23567;&#32467;&#26500;&#65292;&#24182;&#20197;&#21333;&#27425;&#33021;&#37327;&#35780;&#20272;&#20026;&#22522;&#30784;&#65292;&#21462;&#20195;&#20102;&#37325;&#22797;&#30340;&#31532;&#19968;&#21407;&#29702;&#33021;&#37327;&#35745;&#31639;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#20197;&#36890;&#36807;&#25214;&#21040;&#21407;&#23376;&#26500;&#22411;&#33021;&#37327;&#26354;&#38754;&#30340;&#20840;&#23616;&#25110;&#23616;&#37096;&#26497;&#23567;&#20540;&#26469;&#39044;&#27979;&#32452;&#35013;&#21407;&#23376;&#30340;&#31283;&#23450;&#25110;&#20122;&#31283;&#23450;&#26230;&#20307;&#32467;&#26500;&#12290;&#36890;&#24120;&#65292;&#36825;&#38656;&#35201;&#37325;&#22797;&#30340;&#31532;&#19968;&#21407;&#29702;&#33021;&#37327;&#35745;&#31639;&#65292;&#36825;&#22312;&#21253;&#21547;30&#20010;&#20197;&#19978;&#21407;&#23376;&#30340;&#22823;&#22411;&#31995;&#32479;&#20013;&#26159;&#19981;&#23454;&#38469;&#30340;&#12290;&#26412;&#30740;&#31350;&#20351;&#29992;&#31616;&#21333;&#20294;&#21151;&#33021;&#24378;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#24037;&#20316;&#27969;&#65292;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#36741;&#21161;&#31532;&#19968;&#21407;&#29702;&#33021;&#37327;&#35745;&#31639;&#65292;&#23545;&#22823;&#37327;&#34394;&#25311;&#21019;&#24314;&#30340;&#26230;&#20307;&#32467;&#26500;&#36827;&#34892;&#38750;&#36845;&#20195;&#24335;&#21333;&#27425;&#31579;&#36873;&#65292;&#20174;&#32780;&#22312;&#35299;&#20915;&#26230;&#20307;&#32467;&#26500;&#39044;&#27979;&#38382;&#39064;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stable or metastable crystal structures of assembled atoms can be predicted by finding the global or local minima of the energy surface with respect to the atomic configurations. Generally, this requires repeated first-principles energy calculations that are impractical for large systems, such as those containing more than 30 atoms in the unit cell. Here, we have made significant progress in solving the crystal structure prediction problem with a simple but powerful machine-learning workflow; using a machine-learning surrogate for first-principles energy calculations, we performed non-iterative, single-shot screening using a large library of virtually created crystal structures. The present method relies on two key technical components: transfer learning, which enables a highly accurate energy prediction of pre-relaxed crystalline states given only a small set of training samples from first-principles calculations, and generative models to create promising and diverse crystal structure
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35780;&#35770;&#23545;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861; SHAP &#21644; LIME &#36827;&#34892;&#20102;&#35780;&#36848;&#21644;&#27604;&#36739;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#19988;&#31361;&#20986;&#20102;&#23427;&#20204;&#30340;&#20248;&#32570;&#28857;&#12290;</title><link>http://arxiv.org/abs/2305.02012</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#35780;&#36848;&#65306;SHAP &#21644; LIME
&lt;/p&gt;
&lt;p&gt;
Commentary on explainable artificial intelligence methods: SHAP and LIME. (arXiv:2305.02012v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02012
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35780;&#35770;&#23545;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861; SHAP &#21644; LIME &#36827;&#34892;&#20102;&#35780;&#36848;&#21644;&#27604;&#36739;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#19988;&#31361;&#20986;&#20102;&#23427;&#20204;&#30340;&#20248;&#32570;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#26041;&#27861;&#24050;&#32463;&#21457;&#23637;&#20986;&#26469;&#65292;&#23558;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#40657;&#21283;&#23376;&#36716;&#21270;&#20026;&#26356;&#26131;&#29702;&#35299;&#30340;&#24418;&#24335;&#12290;&#36825;&#20123;&#26041;&#27861;&#26377;&#21161;&#20110;&#20256;&#36798;&#27169;&#22411;&#30340;&#24037;&#20316;&#21407;&#29702;&#65292;&#26088;&#22312;&#20351;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26356;&#36879;&#26126;&#65292;&#24182;&#22686;&#21152;&#26368;&#32456;&#29992;&#25143;&#23545;&#20854;&#36755;&#20986;&#30340;&#20449;&#20219;&#12290; SHapley Additive exPlanations&#65288;SHAP&#65289;&#21644;Local Interpretable Model Agnostic Explanation&#65288;LIME&#65289;&#26159;&#20004;&#31181;&#22312;&#34920;&#26684;&#25968;&#25454;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;XAI&#26041;&#27861;&#12290;&#22312;&#36825;&#31687;&#35780;&#35770;&#20013;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#20004;&#31181;&#26041;&#27861;&#30340;&#21487;&#35299;&#37322;&#24615;&#24230;&#37327;&#26159;&#22914;&#20309;&#29983;&#25104;&#30340;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#35299;&#37322;&#23427;&#20204;&#36755;&#20986;&#30340;&#26694;&#26550;&#65292;&#31361;&#20986;&#20102;&#23427;&#20204;&#30340;&#20248;&#32570;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
eXplainable artificial intelligence (XAI) methods have emerged to convert the black box of machine learning models into a more digestible form. These methods help to communicate how the model works with the aim of making machine learning models more transparent and increasing the trust of end-users into their output. SHapley Additive exPlanations (SHAP) and Local Interpretable Model Agnostic Explanation (LIME) are two widely used XAI methods particularly with tabular data. In this commentary piece, we discuss the way the explainability metrics of these two methods are generated and propose a framework for interpretation of their outputs, highlighting their weaknesses and strengths.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#22312;&#32447;&#21453;&#39304;&#30340;&#23454;&#29616;&#24335;&#39044;&#27979;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#22312;&#27169;&#22411;&#37096;&#32626;&#33258;&#36523;&#25913;&#21464;&#25968;&#25454;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#20248;&#21270;&#20934;&#30830;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.01094</link><description>&lt;p&gt;
&#36890;&#36807;&#37325;&#26032;&#21442;&#25968;&#21270;&#23398;&#20064;&#23454;&#29616;&#22312;&#32447;&#21453;&#39304;&#30340;&#23454;&#29616;&#24335;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Performative Prediction with Bandit Feedback: Learning through Reparameterization. (arXiv:2305.01094v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01094
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#22312;&#32447;&#21453;&#39304;&#30340;&#23454;&#29616;&#24335;&#39044;&#27979;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#22312;&#27169;&#22411;&#37096;&#32626;&#33258;&#36523;&#25913;&#21464;&#25968;&#25454;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#20248;&#21270;&#20934;&#30830;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#25968;&#25454;&#20998;&#24067;&#30001;&#27169;&#22411;&#37096;&#32626;&#33258;&#36523;&#25913;&#21464;&#30340;&#24773;&#24418;&#19979;&#39044;&#27979;&#30340;&#19968;&#20010;&#26694;&#26550;&#8212;&#8212;&#23454;&#29616;&#24335;&#39044;&#27979;&#12290;&#29616;&#26377;&#30740;&#31350;&#30340;&#37325;&#28857;&#22312;&#20110;&#20248;&#21270;&#20934;&#30830;&#24615;&#65292;&#20294;&#26159;&#20854;&#20551;&#35774;&#24448;&#24448;&#38590;&#20197;&#22312;&#23454;&#36341;&#20013;&#24471;&#21040;&#28385;&#36275;&#12290;&#26412;&#25991;&#38024;&#23545;&#36825;&#31867;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#23618;&#38646;&#38454;&#20248;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#37325;&#26032;&#21442;&#25968;&#21270;&#23454;&#29616;&#24335;&#39044;&#27979;&#30446;&#26631;&#65292;&#20174;&#32780;&#23558;&#38750;&#20984;&#30340;&#30446;&#26631;&#36716;&#21270;&#20026;&#20984;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Performative prediction, as introduced by Perdomo et al. (2020), is a framework for studying social prediction in which the data distribution itself changes in response to the deployment of a model. Existing work on optimizing accuracy in this setting hinges on two assumptions that are easily violated in practice: that the performative risk is convex over the deployed model, and that the mapping from the model to the data distribution is known to the model designer in advance. In this paper, we initiate the study of tractable performative prediction problems that do not require these assumptions. To tackle this more challenging setting, we develop a two-level zeroth-order optimization algorithm, where one level aims to compute the distribution map, and the other level reparameterizes the performative prediction objective as a function of the induced data distribution. Under mild conditions, this reparameterization allows us to transform the non-convex objective into a convex one and ac
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#26680;&#26829;&#26834;&#36807;&#31243;&#30340;&#39640;&#26031;&#36807;&#31243;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#65292;&#33021;&#22815;&#32500;&#25345;&#30452;&#35266;&#21560;&#24341;&#21147;&#24182;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#65292;&#20855;&#26377;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.13833</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#26829;&#26834;&#36807;&#31243;&#30340;&#39640;&#26031;&#36807;&#31243;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Mixtures of Gaussian process experts based on kernel stick-breaking processes. (arXiv:2304.13833v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13833
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#26680;&#26829;&#26834;&#36807;&#31243;&#30340;&#39640;&#26031;&#36807;&#31243;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#65292;&#33021;&#22815;&#32500;&#25345;&#30452;&#35266;&#21560;&#24341;&#21147;&#24182;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#65292;&#20855;&#26377;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#26159;&#19968;&#31867;&#33021;&#21516;&#26102;&#35299;&#20915;&#26631;&#20934;&#39640;&#26031;&#36807;&#31243;&#20013;&#23384;&#22312;&#30340;&#20004;&#20010;&#20851;&#38190;&#38480;&#21046;&#65306;&#21487;&#25193;&#23637;&#24615;&#21644;&#39044;&#27979;&#24615;&#33021;&#30340;&#27169;&#22411;&#12290;&#20351;&#29992;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#20316;&#20026;&#38376;&#20989;&#25968;&#30340;&#27169;&#22411;&#33021;&#22815;&#30452;&#35266;&#22320;&#35299;&#37322;&#21644;&#33258;&#21160;&#36873;&#25321;&#28151;&#21512;&#29289;&#20013;&#19987;&#23478;&#30340;&#25968;&#37327;&#12290;&#34429;&#28982;&#29616;&#26377;&#27169;&#22411;&#22312;&#24863;&#30693;&#38750;&#24179;&#31283;&#24615;&#12289;&#22810;&#27169;&#24615;&#21644;&#24322;&#26041;&#24046;&#24615;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#20854;&#38376;&#20989;&#25968;&#30340;&#31616;&#21333;&#24615;&#21487;&#33021;&#20250;&#38480;&#21046;&#22312;&#24212;&#29992;&#20110;&#22797;&#26434;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#26102;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#25105;&#20204;&#21033;&#29992;&#26368;&#36817;&#22312;&#30456;&#20851;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#25991;&#29486;&#20013;&#30340;&#36827;&#23637;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#26829;&#26834;&#36807;&#31243;&#30340;&#26032;&#22411;&#39640;&#26031;&#36807;&#31243;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#20445;&#25345;&#30452;&#35266;&#21560;&#24341;&#21147;&#65292;&#21516;&#26102;&#25552;&#39640;&#29616;&#26377;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#20351;&#20854;&#23454;&#29992;&#24615;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#21518;&#39564;&#35745;&#31639;&#30340;&#20999;&#29255;&#25277;&#26679;&#37319;&#26679;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mixtures of Gaussian process experts is a class of models that can simultaneously address two of the key limitations inherent in standard Gaussian processes: scalability and predictive performance. In particular, models that use Dirichlet processes as gating functions permit straightforward interpretation and automatic selection of the number of experts in a mixture. While the existing models are intuitive and capable of capturing non-stationarity, multi-modality and heteroskedasticity, the simplicity of their gating functions may limit the predictive performance when applied to complex data-generating processes. Capitalising on the recent advancement in the dependent Dirichlet processes literature, we propose a new mixture model of Gaussian process experts based on kernel stick-breaking processes. Our model maintains the intuitive appeal yet improve the performance of the existing models. To make it practical, we design a sampler for posterior computation based on the slice sampling. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#22343;&#22330;&#21338;&#24328;&#20316;&#20026;&#23454;&#39564;&#23460;&#23545;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#35774;&#35745;&#21644;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#36825;&#31181;&#26041;&#27861;&#19982;&#20027;&#35201;&#27969;&#21160;&#21644;&#25193;&#25955;&#22411;&#29983;&#25104;&#27169;&#22411;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;&#36890;&#36807;&#30740;&#31350;&#27599;&#20010;&#29983;&#25104;&#27169;&#22411;&#19982;&#23427;&#20204;&#30456;&#20851;&#30340; MFG &#30340;&#26368;&#20248;&#26465;&#20214;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#21452;&#20154; MFG &#30340;&#26032;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#25552;&#39640;&#26679;&#26412;&#22810;&#26679;&#24615;&#21644;&#36924;&#30495;&#24230;&#30340;&#21516;&#26102;&#25913;&#21892;&#20102;&#35299;&#32544;&#32467;&#21644;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.13534</link><description>&lt;p&gt;
&#29992;&#22343;&#22330;&#21338;&#24328;&#20026;&#29983;&#25104;&#27169;&#22411;&#25645;&#24314;&#23454;&#39564;&#23460;
&lt;/p&gt;
&lt;p&gt;
A mean-field games laboratory for generative modeling. (arXiv:2304.13534v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13534
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#22343;&#22330;&#21338;&#24328;&#20316;&#20026;&#23454;&#39564;&#23460;&#23545;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#35774;&#35745;&#21644;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#36825;&#31181;&#26041;&#27861;&#19982;&#20027;&#35201;&#27969;&#21160;&#21644;&#25193;&#25955;&#22411;&#29983;&#25104;&#27169;&#22411;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;&#36890;&#36807;&#30740;&#31350;&#27599;&#20010;&#29983;&#25104;&#27169;&#22411;&#19982;&#23427;&#20204;&#30456;&#20851;&#30340; MFG &#30340;&#26368;&#20248;&#26465;&#20214;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#21452;&#20154; MFG &#30340;&#26032;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#25552;&#39640;&#26679;&#26412;&#22810;&#26679;&#24615;&#21644;&#36924;&#30495;&#24230;&#30340;&#21516;&#26102;&#25913;&#21892;&#20102;&#35299;&#32544;&#32467;&#21644;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;&#22343;&#22330;&#21338;&#24328; (MFGs) &#20316;&#20026;&#19968;&#31181;&#25968;&#23398;&#26694;&#26550;&#29992;&#20110;&#35299;&#37322;&#12289;&#22686;&#24378;&#21644;&#35774;&#35745;&#29983;&#25104;&#27169;&#22411;&#30340;&#22810;&#21151;&#33021;&#24615;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102; MFGs &#19982;&#20027;&#35201;&#27969;&#21160;&#21644;&#25193;&#25955;&#22411;&#29983;&#25104;&#27169;&#22411;&#20043;&#38388;&#20851;&#32852;&#65292;&#24182;&#36890;&#36807;&#19981;&#21516;&#30340;&#31890;&#23376;&#21160;&#21147;&#23398;&#21644;&#20195;&#20215;&#20989;&#25968;&#25512;&#23548;&#20102;&#36825;&#19977;&#20010;&#31867;&#21035;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#30740;&#31350;&#23427;&#20204;&#30456;&#20851;&#30340; MFG &#30340;&#26368;&#20248;&#26465;&#20214;&#8212;&#8212;&#19968;&#32452;&#32806;&#21512;&#30340;&#38750;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#65292;&#26469;&#30740;&#31350;&#27599;&#20010;&#29983;&#25104;&#27169;&#22411;&#30340;&#25968;&#23398;&#32467;&#26500;&#21644;&#29305;&#24615;&#12290;&#26412;&#25991;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20110;&#21452;&#20154; MFG &#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#20854;&#20013;&#19968;&#20010;&#20195;&#29702;&#21512;&#25104;&#26679;&#26412;&#65292;&#21478;&#19968;&#20010;&#20195;&#29702;&#23545;&#26679;&#26412;&#36827;&#34892;&#35782;&#21035;&#65292;&#29702;&#35770;&#21644;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#29983;&#25104;&#30340;&#26679;&#26412;&#22810;&#26679;&#19988;&#36924;&#30495;&#65292;&#21516;&#26102;&#19982;&#22522;&#20934;&#27169;&#22411;&#30456;&#27604;&#65292;&#25913;&#21892;&#20102;&#35299;&#32544;&#32467;&#21644;&#20844;&#24179;&#24615;&#12290;&#24635;&#20043;&#65292;&#26412;&#25991;&#31361;&#26174;&#20102; MFGs &#20316;&#20026;&#35774;&#35745;&#21644;&#20998;&#26512;&#29983;&#25104;&#27169;&#22411;&#30340;&#23454;&#39564;&#23460;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we demonstrate the versatility of mean-field games (MFGs) as a mathematical framework for explaining, enhancing, and designing generative models. There is a pervasive sense in the generative modeling community that the various flow and diffusion-based generative models have some foundational common structure and interrelationships. We establish connections between MFGs and major classes of flow and diffusion-based generative models including continuous-time normalizing flows, score-based models, and Wasserstein gradient flows. We derive these three classes of generative models through different choices of particle dynamics and cost functions. Furthermore, we study the mathematical structure and properties of each generative model by studying their associated MFG's optimality condition, which is a set of coupled nonlinear partial differential equations (PDEs). The theory of MFGs, therefore, enables the study of generative models through the theory of nonlinear PDEs. Throu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21033;&#29992;&#22810;&#33218;&#32769;&#34382;&#26426;&#26694;&#26550;&#32467;&#26500;&#26469;&#22788;&#29702;&#26410;&#30693;&#20195;&#29702;&#22870;&#21169;&#30340;&#31574;&#30053;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#26159;&#28176;&#36827;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2304.07407</link><description>&lt;p&gt;
&#26410;&#35266;&#27979;&#21040;&#20195;&#29702;&#22870;&#21169;&#30340;&#37325;&#22797;&#36127;&#36131;&#20154;&#20195;&#29702;&#21338;&#24328;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Repeated Principal-Agent Games with Unobserved Agent Rewards and Perfect-Knowledge Agents. (arXiv:2304.07407v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07407
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21033;&#29992;&#22810;&#33218;&#32769;&#34382;&#26426;&#26694;&#26550;&#32467;&#26500;&#26469;&#22788;&#29702;&#26410;&#30693;&#20195;&#29702;&#22870;&#21169;&#30340;&#31574;&#30053;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#26159;&#28176;&#36827;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#22810;&#33218;&#32769;&#34382;&#26426;&#26694;&#26550;&#20013;&#30340;&#37325;&#22797;&#36127;&#36131;&#20154;&#20195;&#29702;&#21338;&#24328;&#22330;&#26223;&#65292;&#20854;&#20013;&#20195;&#29702;&#36873;&#25321;&#19968;&#31181;&#32769;&#34382;&#26426;&#21518;&#20250;&#33719;&#24471;&#22870;&#21169;&#21644;&#28608;&#21169;&#65292;&#20294;&#36127;&#36131;&#20154;&#21482;&#33021;&#35266;&#23519;&#21040;&#20195;&#29702;&#36873;&#25321;&#20102;&#21738;&#20010;&#32769;&#34382;&#26426;&#20197;&#21450;&#20195;&#29702;&#30456;&#24212;&#30340;&#28608;&#21169;&#65292;&#32780;&#24819;&#35201;&#35774;&#35745;&#19968;&#31181;&#21512;&#36866;&#30340;&#31574;&#30053;&#21364;&#20805;&#28385;&#20102;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22810;&#33218;&#32769;&#34382;&#26426;&#26694;&#26550;&#32467;&#26500;&#26469;&#22788;&#29702;&#26410;&#30693;&#20195;&#29702;&#22870;&#21169;&#30340;&#31574;&#30053;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#26159;&#28176;&#36827;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by a number of real-world applications from domains like healthcare and sustainable transportation, in this paper we study a scenario of repeated principal-agent games within a multi-armed bandit (MAB) framework, where: the principal gives a different incentive for each bandit arm, the agent picks a bandit arm to maximize its own expected reward plus incentive, and the principal observes which arm is chosen and receives a reward (different than that of the agent) for the chosen arm. Designing policies for the principal is challenging because the principal cannot directly observe the reward that the agent receives for their chosen actions, and so the principal cannot directly learn the expected reward using existing estimation techniques. As a result, the problem of designing policies for this scenario, as well as similar ones, remains mostly unexplored. In this paper, we construct a policy that achieves a low regret (i.e., square-root regret up to a log factor) in this scenar
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#25968;&#25454;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#22788;&#29702;&#19968;&#32452;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#65292;&#29983;&#25104;&#19968;&#20010;&#21333;&#19968;&#30340;&#22240;&#26524;&#39537;&#21160;&#38598;&#65292;&#24182;&#19988;&#21487;&#20197;&#36807;&#28388;&#25481;&#22240;&#26524;&#34394;&#20551;&#38142;&#25509;&#65292;&#26368;&#32456;&#36755;&#20837;&#21040;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#39044;&#27979;&#30446;&#26631;&#12290;</title><link>http://arxiv.org/abs/2304.05294</link><description>&lt;p&gt;
&#20351;&#29992;&#22810;&#25968;&#25454;&#22240;&#26524;&#25512;&#26029;&#36873;&#25321;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#30340;&#24378;&#20581;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Selecting Robust Features for Machine Learning Applications using Multidata Causal Discovery. (arXiv:2304.05294v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05294
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#25968;&#25454;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#22788;&#29702;&#19968;&#32452;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#65292;&#29983;&#25104;&#19968;&#20010;&#21333;&#19968;&#30340;&#22240;&#26524;&#39537;&#21160;&#38598;&#65292;&#24182;&#19988;&#21487;&#20197;&#36807;&#28388;&#25481;&#22240;&#26524;&#34394;&#20551;&#38142;&#25509;&#65292;&#26368;&#32456;&#36755;&#20837;&#21040;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#39044;&#27979;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#20581;&#30340;&#29305;&#24449;&#36873;&#25321;&#23545;&#20110;&#21019;&#24314;&#21487;&#38752;&#21644;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#27169;&#22411;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#39046;&#22495;&#30693;&#35782;&#26377;&#38480;&#12289;&#28508;&#22312;&#20132;&#20114;&#26410;&#30693;&#30340;&#24773;&#20917;&#19979;&#35774;&#35745;&#32479;&#35745;&#39044;&#27979;&#27169;&#22411;&#26102;&#65292;&#36873;&#25321;&#26368;&#20248;&#29305;&#24449;&#38598;&#36890;&#24120;&#24456;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22810;&#25968;&#25454;&#65288;M&#65289;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#23427;&#21516;&#26102;&#22788;&#29702;&#19968;&#32452;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#65292;&#24182;&#29983;&#25104;&#19968;&#20010;&#21333;&#19968;&#30340;&#22240;&#26524;&#39537;&#21160;&#38598;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;Tigramite Python&#21253;&#20013;&#23454;&#29616;&#30340;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;PC1&#25110;PCMCI&#12290;&#36825;&#20123;&#31639;&#27861;&#21033;&#29992;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#25512;&#26029;&#22240;&#26524;&#22270;&#30340;&#37096;&#20998;&#12290;&#25105;&#20204;&#30340;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#22312;&#23558;&#21097;&#20313;&#22240;&#26524;&#29305;&#24449;&#20316;&#20026;&#36755;&#20837;&#20256;&#36882;&#32473;ML&#27169;&#22411;&#65288;&#22810;&#20803;&#32447;&#24615;&#22238;&#24402;&#65292;&#38543;&#26426;&#26862;&#26519;&#65289;&#39044;&#27979;&#30446;&#26631;&#20043;&#21069;&#65292;&#36807;&#28388;&#25481;&#22240;&#26524;&#34394;&#20551;&#38142;&#25509;&#12290;&#25105;&#20204;&#23558;&#35813;&#26694;&#26550;&#24212;&#29992;&#20110;&#39044;&#27979;&#35199;&#22826;&#24179;&#27915;&#28909;&#24102;&#22320;&#21306;&#30340;&#22320;&#38663;&#24378;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Robust feature selection is vital for creating reliable and interpretable Machine Learning (ML) models. When designing statistical prediction models in cases where domain knowledge is limited and underlying interactions are unknown, choosing the optimal set of features is often difficult. To mitigate this issue, we introduce a Multidata (M) causal feature selection approach that simultaneously processes an ensemble of time series datasets and produces a single set of causal drivers. This approach uses the causal discovery algorithms PC1 or PCMCI that are implemented in the Tigramite Python package. These algorithms utilize conditional independence tests to infer parts of the causal graph. Our causal feature selection approach filters out causally-spurious links before passing the remaining causal features as inputs to ML models (Multiple linear regression, Random Forest) that predict the targets. We apply our framework to the statistical intensity prediction of Western Pacific Tropical
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35745;&#31639;&#26694;&#26550;DMSB&#65292;&#23427;&#21487;&#20197;&#23398;&#20064;&#28385;&#36275;&#26102;&#38388;&#19978;&#20301;&#32622;&#36793;&#38469;&#32422;&#26463;&#30340;&#38543;&#26426;&#31995;&#32479;&#30340;&#24179;&#28369;&#24230;&#37327;&#20540;&#26679;&#26465;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#22810;&#36793;&#38469;&#36712;&#36857;&#25512;&#26029;&#20219;&#21153;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#24615;&#33021;&#20248;&#21183;&#12290;&#21516;&#26102;&#65292;&#35813;&#26694;&#26550;&#36824;&#20026;&#35299;&#20915;&#20855;&#26377;&#21508;&#31181;&#31867;&#22411;&#30340;&#36793;&#38469;&#32422;&#26463;&#30340;&#38543;&#26426;&#36712;&#36857;&#37325;&#24314;&#20219;&#21153;&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2303.01751</link><description>&lt;p&gt;
&#28145;&#21160;&#37327;&#22810;&#37325;&#36793;&#38469;Schr\"odinger&#26725;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Deep Momentum Multi-Marginal Schr\"odinger Bridge. (arXiv:2303.01751v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.01751
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35745;&#31639;&#26694;&#26550;DMSB&#65292;&#23427;&#21487;&#20197;&#23398;&#20064;&#28385;&#36275;&#26102;&#38388;&#19978;&#20301;&#32622;&#36793;&#38469;&#32422;&#26463;&#30340;&#38543;&#26426;&#31995;&#32479;&#30340;&#24179;&#28369;&#24230;&#37327;&#20540;&#26679;&#26465;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#22810;&#36793;&#38469;&#36712;&#36857;&#25512;&#26029;&#20219;&#21153;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#24615;&#33021;&#20248;&#21183;&#12290;&#21516;&#26102;&#65292;&#35813;&#26694;&#26550;&#36824;&#20026;&#35299;&#20915;&#20855;&#26377;&#21508;&#31181;&#31867;&#22411;&#30340;&#36793;&#38469;&#32422;&#26463;&#30340;&#38543;&#26426;&#36712;&#36857;&#37325;&#24314;&#20219;&#21153;&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31895;&#30053;&#26102;&#38388;&#38388;&#38548;&#19979;&#65292;&#20351;&#29992;&#26410;&#26631;&#35760;&#26679;&#26412;&#20174;&#20998;&#24067;&#20013;&#37325;&#24314;&#20154;&#21475;&#21160;&#24577;&#26159;&#19968;&#20010;&#20851;&#38190;&#30340;&#25361;&#25112;&#12290;&#26368;&#36817;&#30340;&#26041;&#27861;&#22914;&#27969;&#27169;&#22411;&#25110;Schr\"odinger&#26725;&#27169;&#22411;&#34920;&#29616;&#20986;&#35825;&#20154;&#30340;&#24615;&#33021;&#65292;&#20294;&#26159;&#25512;&#26029;&#20986;&#30340;&#26679;&#26412;&#36712;&#36857;&#26410;&#33021;&#35299;&#37322;&#28508;&#22312;&#30340;&#38543;&#26426;&#24615;&#65292;&#25110;&#32773;&#26159;DMSB&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#35745;&#31639;&#26694;&#26550;&#65292;&#23427;&#33021;&#22815;&#23398;&#20064;&#28385;&#36275;&#26102;&#38388;&#19978;&#20301;&#32622;&#36793;&#38469;&#32422;&#26463;&#30340;&#38543;&#26426;&#31995;&#32479;&#30340;&#24179;&#28369;&#24230;&#37327;&#20540;&#26679;&#26465;&#12290;&#36890;&#36807;&#35843;&#25972;&#33879;&#21517;&#30340;Bregman&#36845;&#20195;&#21644;&#23558;&#27604;&#20363;&#25311;&#21512;&#36845;&#20195;&#25193;&#23637;&#21040;&#30456;&#31354;&#38388;&#65292;&#25105;&#20204;&#25104;&#21151;&#22320;&#39640;&#25928;&#22788;&#29702;&#20102;&#39640;&#32500;&#22810;&#36793;&#38469;&#36712;&#36857;&#25512;&#26029;&#20219;&#21153;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#30495;&#23454;&#30340;&#21333;&#32454;&#32990;RNA&#24207;&#21015;&#25968;&#25454;&#38598;&#23454;&#39564;&#20013;&#26174;&#33879;&#20248;&#20110;&#22522;&#32447;&#12290;&#27492;&#22806;&#65292;&#25152;&#25552;&#20986;&#30340;DMSB&#26694;&#26550;&#20026;&#35299;&#20915;&#20855;&#26377;&#21508;&#31181;&#31867;&#22411;&#30340;&#36793;&#38469;&#32422;&#26463;&#30340;&#38543;&#26426;&#36712;&#36857;&#37325;&#24314;&#20219;&#21153;&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is a crucial challenge to reconstruct population dynamics using unlabeled samples from distributions at coarse time intervals. Recent approaches such as flow-based models or Schr\"odinger Bridge (SB) models have demonstrated appealing performance, yet the inferred sample trajectories either fail to account for the underlying stochasticity or are $\underline{D}$eep $\underline{M}$omentum Multi-Marginal $\underline{S}$chr\"odinger $\underline{B}$ridge(DMSB), a novel computational framework that learns the smooth measure-valued spline for stochastic systems that satisfy position marginal constraints across time. By tailoring the celebrated Bregman Iteration and extending the Iteration Proportional Fitting to phase space, we manage to handle high-dimensional multi-marginal trajectory inference tasks efficiently. Our algorithm outperforms baselines significantly, as evidenced by experiments for synthetic datasets and a real-world single-cell RNA sequence dataset. Additionally, the propos
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;BPLS&#65292;&#19968;&#31181;&#29992;&#20110;PLS&#30340;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#36890;&#36807;&#35299;&#26512;&#36924;&#36817;&#36873;&#25321;&#26631;&#31614;&#23454;&#20363;&#30340;&#26631;&#20934;&#65292;&#20197;&#36991;&#20813;&#30001;&#36807;&#24230;&#33258;&#20449;&#20294;&#38169;&#35823;&#39044;&#27979;&#30340;&#23454;&#20363;&#36873;&#25321;&#32780;&#23548;&#33268;&#30340;&#30830;&#35748;&#20559;&#24046;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2302.08883</link><description>&lt;p&gt;
&#36817;&#20046;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#20266;&#26631;&#31614;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Approximately Bayes-Optimal Pseudo Label Selection. (arXiv:2302.08883v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08883
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;BPLS&#65292;&#19968;&#31181;&#29992;&#20110;PLS&#30340;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#36890;&#36807;&#35299;&#26512;&#36924;&#36817;&#36873;&#25321;&#26631;&#31614;&#23454;&#20363;&#30340;&#26631;&#20934;&#65292;&#20197;&#36991;&#20813;&#30001;&#36807;&#24230;&#33258;&#20449;&#20294;&#38169;&#35823;&#39044;&#27979;&#30340;&#23454;&#20363;&#36873;&#25321;&#32780;&#23548;&#33268;&#30340;&#30830;&#35748;&#20559;&#24046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#35757;&#32451;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#20005;&#37325;&#20381;&#36182;&#20110;&#20266;&#26631;&#31614;&#36873;&#25321;&#65288;PLS&#65289;&#12290;&#36873;&#25321;&#36890;&#24120;&#21462;&#20915;&#20110;&#21021;&#22987;&#27169;&#22411;&#25311;&#21512;&#26631;&#35760;&#25968;&#25454;&#30340;&#31243;&#24230;&#12290;&#36807;&#26089;&#30340;&#36807;&#25311;&#21512;&#21487;&#33021;&#36890;&#36807;&#36873;&#25321;&#20855;&#26377;&#36807;&#24230;&#33258;&#20449;&#20294;&#38169;&#35823;&#30340;&#39044;&#27979;&#30340;&#23454;&#20363;&#65288;&#36890;&#24120;&#31216;&#20026;&#30830;&#35748;&#20559;&#24046;&#65289;&#32780;&#20256;&#25773;&#21040;&#26368;&#32456;&#27169;&#22411;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;BPLS&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;PLS&#30340;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#26088;&#22312;&#20943;&#36731;&#36825;&#20010;&#38382;&#39064;&#12290;&#20854;&#26680;&#24515;&#26159;&#36873;&#25321;&#26631;&#31614;&#23454;&#20363;&#30340;&#26631;&#20934;&#65306;&#20266;&#26679;&#26412;&#30340;&#21518;&#39564;&#39044;&#27979;&#30340;&#20998;&#26512;&#36817;&#20284;&#12290;&#25105;&#20204;&#36890;&#36807;&#35777;&#26126;&#20266;&#26679;&#26412;&#30340;&#21518;&#39564;&#39044;&#27979;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#24615;&#33719;&#24471;&#20102;&#36825;&#31181;&#36873;&#25321;&#26631;&#20934;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#36890;&#36807;&#35299;&#26512;&#36924;&#36817;&#20811;&#26381;&#35745;&#31639;&#38590;&#39064;&#12290;&#23427;&#19982;&#36793;&#38469;&#20284;&#28982;&#30340;&#20851;&#31995;&#20351;&#25105;&#20204;&#33021;&#22815;&#25552;&#20986;&#22522;&#20110;&#25289;&#26222;&#25289;&#26031;&#26041;&#27861;&#21644;&#39640;&#26031;&#31215;&#20998;&#30340;&#36924;&#36817;&#12290;&#25105;&#20204;&#38024;&#23545;&#21442;&#25968;&#24191;&#20041;&#32447;&#24615;&#21644;&#38750;&#21442;&#25968;&#24191;&#20041;&#21152;&#24615;&#27169;&#22411;&#23545;BPLS&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Semi-supervised learning by self-training heavily relies on pseudo-label selection (PLS). The selection often depends on the initial model fit on labeled data. Early overfitting might thus be propagated to the final model by selecting instances with overconfident but erroneous predictions, often referred to as confirmation bias. This paper introduces BPLS, a Bayesian framework for PLS that aims to mitigate this issue. At its core lies a criterion for selecting instances to label: an analytical approximation of the posterior predictive of pseudo-samples. We derive this selection criterion by proving Bayes optimality of the posterior predictive of pseudo-samples. We further overcome computational hurdles by approximating the criterion analytically. Its relation to the marginal likelihood allows us to come up with an approximation based on Laplace's method and the Gaussian integral. We empirically assess BPLS for parametric generalized linear and non-parametric generalized additive models
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#29992;&#20110;&#40065;&#26834;&#30340;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#65292;&#24182;&#22312;&#21463;&#27745;&#26579;&#30340;&#25968;&#25454;&#27969;&#20013;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#34920;&#29616;&#20248;&#24322;&#65292;&#21516;&#26102;&#30830;&#20445;&#20102;&#31283;&#23450;&#24615;&#24182;&#20943;&#23569;&#24322;&#24120;&#20540;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2302.00422</link><description>&lt;p&gt;
&#40065;&#26834;&#30340;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Robust online active learning. (arXiv:2302.00422v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00422
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#29992;&#20110;&#40065;&#26834;&#30340;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#65292;&#24182;&#22312;&#21463;&#27745;&#26579;&#30340;&#25968;&#25454;&#27969;&#20013;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#34920;&#29616;&#20248;&#24322;&#65292;&#21516;&#26102;&#30830;&#20445;&#20102;&#31283;&#23450;&#24615;&#24182;&#20943;&#23569;&#24322;&#24120;&#20540;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24037;&#19994;&#24212;&#29992;&#20013;&#65292;&#33719;&#24471;&#26631;&#35760;&#30340;&#35266;&#27979;&#25968;&#25454;&#24182;&#19981;&#31616;&#21333;&#65292;&#36890;&#24120;&#38656;&#35201;&#20154;&#24037;&#19987;&#23478;&#24178;&#39044;&#25110;&#20351;&#29992;&#26114;&#36149;&#30340;&#27979;&#35797;&#35774;&#22791;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20027;&#21160;&#23398;&#20064;&#21487;&#20197;&#22823;&#22823;&#25552;&#39640;&#25311;&#21512;&#27169;&#22411;&#26102;&#26368;&#20449;&#24687;&#25968;&#25454;&#28857;&#30340;&#24314;&#35758;&#12290;&#20943;&#23569;&#27169;&#22411;&#24320;&#21457;&#25152;&#38656;&#30340;&#35266;&#27979;&#25968;&#25454;&#25968;&#37327;&#21487;&#20197;&#20943;&#36731;&#35757;&#32451;&#25152;&#38656;&#30340;&#35745;&#31639;&#36127;&#25285;&#21644;&#26631;&#35760;&#30456;&#20851;&#30340;&#25805;&#20316;&#25903;&#20986;&#12290;&#29305;&#21035;&#26159;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#65292;&#22312;&#38656;&#35201;&#22312;&#26497;&#30701;&#26102;&#38388;&#20869;&#20915;&#23450;&#26159;&#21542;&#33719;&#21462;&#25968;&#25454;&#28857;&#26631;&#35760;&#30340;&#39640;&#23481;&#37327;&#29983;&#20135;&#36807;&#31243;&#20013;&#38750;&#24120;&#26377;&#29992;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#26368;&#36817;&#33268;&#21147;&#20110;&#24320;&#21457;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;&#65292;&#20294;&#22312;&#23384;&#22312;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#36825;&#20123;&#26041;&#27861;&#30340;&#34892;&#20026;&#20173;&#26410;&#24471;&#21040;&#24443;&#24213;&#30740;&#31350;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#22312;&#32447;&#20027;&#21160;&#32447;&#24615;&#22238;&#24402;&#22312;&#21463;&#27745;&#26579;&#30340;&#25968;&#25454;&#27969;&#20013;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#29992;&#20110;&#40065;&#26834;&#30340;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#65292;&#21516;&#26102;&#20445;&#35777;&#31283;&#23450;&#24615;&#24182;&#20943;&#23569;&#24322;&#24120;&#20540;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many industrial applications, obtaining labeled observations is not straightforward as it often requires the intervention of human experts or the use of expensive testing equipment. In these circumstances, active learning can be highly beneficial in suggesting the most informative data points to be used when fitting a model. Reducing the number of observations needed for model development alleviates both the computational burden required for training and the operational expenses related to labeling. Online active learning, in particular, is useful in high-volume production processes where the decision about the acquisition of the label for a data point needs to be taken within an extremely short time frame. However, despite the recent efforts to develop online active learning strategies, the behavior of these methods in the presence of outliers has not been thoroughly examined. In this work, we investigate the performance of online active linear regression in contaminated data strea
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20108;&#20540;&#19968;&#33324;&#22240;&#26524;&#27169;&#22411;&#21644;BGLMs&#19978;&#19981;&#32771;&#34385;&#22270;&#39592;&#26550;&#30340;&#32452;&#21512;&#22240;&#26524;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#21487;&#22312;BGLMs&#19978;&#23454;&#29616;&#30340;&#26080;&#38656;&#22270;&#39592;&#26550;&#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#36798;&#21040;&#20102;&#19982;&#20381;&#36182;&#20110;&#22270;&#32467;&#26500;&#30340;&#26368;&#20808;&#36827;&#31639;&#27861;&#30456;&#21516;&#30340;&#28176;&#36827;&#36951;&#25022;&#29575;$O(\sqrt{T}\ln T)$&#12290;</title><link>http://arxiv.org/abs/2301.13392</link><description>&lt;p&gt;
&#19981;&#32771;&#34385;&#22270;&#39592;&#26550;&#30340;&#32452;&#21512;&#22240;&#26524;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
Combinatorial Causal Bandits without Graph Skeleton. (arXiv:2301.13392v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13392
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20108;&#20540;&#19968;&#33324;&#22240;&#26524;&#27169;&#22411;&#21644;BGLMs&#19978;&#19981;&#32771;&#34385;&#22270;&#39592;&#26550;&#30340;&#32452;&#21512;&#22240;&#26524;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#21487;&#22312;BGLMs&#19978;&#23454;&#29616;&#30340;&#26080;&#38656;&#22270;&#39592;&#26550;&#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#36798;&#21040;&#20102;&#19982;&#20381;&#36182;&#20110;&#22270;&#32467;&#26500;&#30340;&#26368;&#20808;&#36827;&#31639;&#27861;&#30456;&#21516;&#30340;&#28176;&#36827;&#36951;&#25022;&#29575;$O(\sqrt{T}\ln T)$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32452;&#21512;&#22240;&#26524;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#65292;&#23398;&#20064;&#20195;&#29702;&#22312;&#27599;&#19968;&#36718;&#36873;&#25321;&#19968;&#32452;&#21464;&#37327;&#36827;&#34892;&#24178;&#39044;&#65292;&#25910;&#38598;&#35266;&#27979;&#21464;&#37327;&#30340;&#21453;&#39304;&#20197;&#26368;&#23567;&#21270;&#26399;&#26395;&#36951;&#25022;&#25110;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#30740;&#31350;&#20102;&#19968;&#33324;&#22240;&#26524;&#27169;&#22411;&#21644;&#20108;&#20540;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;BGLMs&#65289;&#20013;&#30340;&#38382;&#39064;&#12290;&#20294;&#26159;&#65292;&#23427;&#20204;&#37117;&#38656;&#35201;&#20808;&#39564;&#30693;&#35782;&#26469;&#26500;&#24314;&#22240;&#26524;&#20851;&#31995;&#22270;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20108;&#20540;&#19968;&#33324;&#22240;&#26524;&#27169;&#22411;&#21644;BGLMs&#19978;&#19981;&#32771;&#34385;&#22270;&#39592;&#26550;&#30340;&#32452;&#21512;&#22240;&#26524;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#19968;&#33324;&#22240;&#26524;&#27169;&#22411;&#19978;&#25552;&#20379;&#20102;&#32047;&#31215;&#36951;&#25022;&#30340;&#25351;&#25968;&#19979;&#38480;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26080;&#38656;&#22270;&#39592;&#26550;&#26469;&#23454;&#29616;BGLMs&#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#34920;&#26126;&#23427;&#20173;&#28982;&#36798;&#21040;$O(\sqrt{T}\ln T)$&#30340;&#26399;&#26395;&#36951;&#25022;&#12290;&#36825;&#20010;&#28176;&#36827;&#30340;&#36951;&#25022;&#29575;&#19982;&#20381;&#36182;&#20110;&#22270;&#32467;&#26500;&#30340;&#26368;&#20808;&#36827;&#31639;&#27861;&#30456;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
In combinatorial causal bandits (CCB), the learning agent chooses a subset of variables in each round to intervene and collects feedback from the observed variables to minimize expected regret or sample complexity. Previous works study this problem in both general causal models and binary generalized linear models (BGLMs). However, all of them require prior knowledge of causal graph structure. This paper studies the CCB problem without the graph structure on binary general causal models and BGLMs. We first provide an exponential lower bound of cumulative regrets for the CCB problem on general causal models. To overcome the exponentially large space of parameters, we then consider the CCB problem on BGLMs. We design a regret minimization algorithm for BGLMs even without the graph skeleton and show that it still achieves $O(\sqrt{T}\ln T)$ expected regret. This asymptotic regret is the same as the state-of-art algorithms relying on the graph structure. Moreover, we sacrifice the regret t
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#28151;&#21512;&#31867;&#21035;&#30456;&#20851;&#26680;&#30340;&#39640;&#26031;&#36807;&#31243;&#20195;&#29702;&#65292;&#30456;&#36739;&#20110;&#20854;&#20182;&#29616;&#26377;&#27169;&#22411;&#22312;&#20998;&#26512;&#21644;&#24037;&#31243;&#38382;&#39064;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2211.08262</link><description>&lt;p&gt;
&#19968;&#31181;&#28151;&#21512;&#31867;&#21035;&#30456;&#20851;&#26680;&#30340;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
A mixed-categorical correlation kernel for Gaussian process. (arXiv:2211.08262v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.08262
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#28151;&#21512;&#31867;&#21035;&#30456;&#20851;&#26680;&#30340;&#39640;&#26031;&#36807;&#31243;&#20195;&#29702;&#65292;&#30456;&#36739;&#20110;&#20854;&#20182;&#29616;&#26377;&#27169;&#22411;&#22312;&#20998;&#26512;&#21644;&#24037;&#31243;&#38382;&#39064;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#20195;&#29702;&#30340;&#28151;&#21512;&#31867;&#21035;&#20803;&#27169;&#22411;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#19968;&#20123;&#29616;&#26377;&#30340;&#26041;&#27861;&#20351;&#29992;&#19981;&#21516;&#30340;&#31574;&#30053;&#65292;&#36890;&#36807;&#20351;&#29992;&#36830;&#32493;&#26680;&#65288;&#20363;&#22914;&#65292;&#36830;&#32493;&#26494;&#24347;&#21644;Gower&#36317;&#31163;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#65289;&#25110;&#36890;&#36807;&#30452;&#25509;&#20272;&#35745;&#30456;&#20851;&#30697;&#38453;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#26041;&#27861;&#65292;&#23558;&#36830;&#32493;&#25351;&#25968;&#26680;&#25193;&#23637;&#20026;&#22788;&#29702;&#28151;&#21512;&#31867;&#21035;&#21464;&#37327;&#12290;&#25152;&#25552;&#20986;&#30340;&#26680;&#24341;&#23548;&#21040;&#20102;&#19968;&#20010;&#26032;&#30340;&#39640;&#26031;&#20195;&#29702;&#65292;&#23427;&#27010;&#25324;&#20102;&#36830;&#32493;&#26494;&#24347;&#21644;Gower&#36317;&#31163;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;&#20998;&#26512;&#21644;&#24037;&#31243;&#38382;&#39064;&#19978;&#35777;&#26126;&#20102;&#65292;&#25105;&#20204;&#30340;&#25552;&#20986;&#30340;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#27604;&#20854;&#20182;&#22522;&#20110;&#26680;&#30340;&#29616;&#26377;&#27169;&#22411;&#20855;&#26377;&#26356;&#39640;&#30340;&#21487;&#33021;&#24615;&#21644;&#26356;&#23567;&#30340;&#27531;&#24046;&#35823;&#24046;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20351;&#29992;&#24320;&#28304;&#36719;&#20214;SMT&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, there has been a growing interest for mixed-categorical meta-models based on Gaussian process (GP) surrogates. In this setting, several existing approaches use different strategies either by using continuous kernels (e.g., continuous relaxation and Gower distance based GP) or by using a direct estimation of the correlation matrix. In this paper, we present a kernel-based approach that extends continuous exponential kernels to handle mixed-categorical variables. The proposed kernel leads to a new GP surrogate that generalizes both the continuous relaxation and the Gower distance based GP models. We demonstrate, on both analytical and engineering problems, that our proposed GP model gives a higher likelihood and a smaller residual error than the other kernel-based state-of-the-art models. Our method is available in the open-source software SMT.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#38544;&#31169;&#20445;&#25252;&#26041;&#27861;&#65306;&#20351;&#29992;&#23398;&#20064;&#22686;&#24378;&#31639;&#27861;&#26694;&#26550;&#65292;&#20026;&#22810;&#20998;&#20301;&#25968;&#21457;&#24067;&#20219;&#21153;&#25552;&#20379;&#21487;&#25193;&#23637;&#30340;&#39044;&#27979;&#36136;&#37327;&#35823;&#24046;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2210.11222</link><description>&lt;p&gt;
&#22810;&#20998;&#20301;&#25968;&#21457;&#24067;&#30340;&#23398;&#20064;&#22686;&#24378;&#31169;&#26377;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Learning-Augmented Private Algorithms for Multiple Quantile Release. (arXiv:2210.11222v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.11222
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#38544;&#31169;&#20445;&#25252;&#26041;&#27861;&#65306;&#20351;&#29992;&#23398;&#20064;&#22686;&#24378;&#31639;&#27861;&#26694;&#26550;&#65292;&#20026;&#22810;&#20998;&#20301;&#25968;&#21457;&#24067;&#20219;&#21153;&#25552;&#20379;&#21487;&#25193;&#23637;&#30340;&#39044;&#27979;&#36136;&#37327;&#35823;&#24046;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#24212;&#29992;&#24046;&#20998;&#38544;&#31169;&#20110;&#25935;&#24863;&#25968;&#25454;&#26102;&#65292;&#25105;&#20204;&#24120;&#24120;&#21487;&#20197;&#21033;&#29992;&#39069;&#22806;&#30340;&#20449;&#24687;&#20363;&#22914;&#20854;&#20182;&#25935;&#24863;&#25968;&#25454;&#12289;&#20844;&#20247;&#25968;&#25454;&#25110;&#20154;&#31867;&#20449;&#24687;&#20808;&#39564;&#26469;&#25552;&#21319;&#24615;&#33021;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#23398;&#20064;&#22686;&#24378;&#31639;&#27861;&#65288;&#25110;&#20855;&#26377;&#39044;&#27979;&#33021;&#21147;&#30340;&#31639;&#27861;&#65289;&#26694;&#26550;&#65292;&#36825;&#20010;&#26694;&#26550;&#36890;&#24120;&#20351;&#29992;&#20110;&#20248;&#21270;&#26102;&#38388;&#22797;&#26434;&#24230;&#25110;&#31454;&#20105;&#27604;&#29575;&#12290;&#35813;&#26694;&#26550;&#20026;&#35774;&#35745;&#21644;&#20998;&#26512;&#20445;&#25252;&#38544;&#31169;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#24378;&#26377;&#21147;&#30340;&#26041;&#27861;&#65292;&#24182;&#33021;&#22815;&#21033;&#29992;&#36825;&#20123;&#39069;&#22806;&#20449;&#24687;&#20197;&#25552;&#39640;&#25928;&#29992;&#12290;&#35813;&#24819;&#27861;&#20307;&#29616;&#22312;&#37325;&#35201;&#30340;&#22810;&#20998;&#20301;&#25968;&#21457;&#24067;&#20219;&#21153;&#20013;&#65292;&#22312;&#27492;&#25105;&#20204;&#24471;&#20986;&#20102;&#38543;&#30528;&#33258;&#28982;&#36136;&#37327;&#39044;&#27979;&#30340;&#38169;&#35823;&#20445;&#35777;&#65292;&#21516;&#26102;&#65288;&#20960;&#20046;&#65289;&#24674;&#22797;&#20102;&#26368;&#20808;&#36827;&#30340;&#39044;&#27979;&#29420;&#31435;&#30340;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#20855;&#26377;&#20960;&#20010;&#20248;&#28857;&#65292;&#21253;&#25324;&#23545;&#25968;&#25454;&#30340;&#26368;&#23567;&#20551;&#35774;&#65292;&#19968;&#31181;&#33258;&#28982;&#30340;&#22686;&#24378;&#40065;&#26834;&#24615;&#30340;&#26041;&#27861;&#65292;&#20197;&#21450;&#20026;&#20004;&#20010;&#20174;&#20854;&#20182;&#25968;&#25454;&#20013;&#23398;&#20064;&#39044;&#27979;&#30340;&#26032;&#39062;&#8220;&#20803;&#8221;&#31639;&#27861;&#25552;&#20379;&#26377;&#29992;&#30340;&#26367;&#20195;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;
When applying differential privacy to sensitive data, we can often improve performance using external information such as other sensitive data, public data, or human priors. We propose to use the learning-augmented algorithms (or algorithms with predictions) framework -- previously applied largely to improve time complexity or competitive ratios -- as a powerful way of designing and analyzing privacy-preserving methods that can take advantage of such external information to improve utility. This idea is instantiated on the important task of multiple quantile release, for which we derive error guarantees that scale with a natural measure of prediction quality while (almost) recovering state-of-the-art prediction-independent guarantees. Our analysis enjoys several advantages, including minimal assumptions about the data, a natural way of adding robustness, and the provision of useful surrogate losses for two novel ``meta" algorithms that learn predictions from other (potentially sensitiv
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29366;&#24577;&#31354;&#38388;&#26694;&#26550;(SSSD)&#26469;&#25554;&#34917;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#30340;&#32570;&#22833;&#20540;&#21644;&#36827;&#34892;&#39044;&#27979;&#65292;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#21644;&#19981;&#21516;&#30340;&#32570;&#22833;&#24773;&#20917;&#19979;&#65292;SSSD&#37117;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#24182;&#21487;&#20197;&#26377;&#25928;&#22788;&#29702;&#40657;&#23631;&#32570;&#22833;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2208.09399</link><description>&lt;p&gt;
&#24102;&#32422;&#26463;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#25193;&#25955;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#21644;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Diffusion-based Time Series Imputation and Forecasting with Structured State Space Models. (arXiv:2208.09399v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.09399
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29366;&#24577;&#31354;&#38388;&#26694;&#26550;(SSSD)&#26469;&#25554;&#34917;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#30340;&#32570;&#22833;&#20540;&#21644;&#36827;&#34892;&#39044;&#27979;&#65292;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#21644;&#19981;&#21516;&#30340;&#32570;&#22833;&#24773;&#20917;&#19979;&#65292;SSSD&#37117;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#24182;&#21487;&#20197;&#26377;&#25928;&#22788;&#29702;&#40657;&#23631;&#32570;&#22833;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32570;&#22833;&#20540;&#30340;&#25554;&#34917;&#23545;&#20110;&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#20998;&#26512;&#31649;&#36947;&#26469;&#35828;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#38556;&#30861;&#12290;&#26412;&#25991;&#32858;&#28966;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#24182;&#25552;&#20986;&#20102;SSSD&#65292;&#36825;&#26159;&#19968;&#31181;&#20381;&#36182;&#20110;&#20004;&#20010;&#26032;&#20852;&#25216;&#26415;&#30340;&#25554;&#34917;&#27169;&#22411;&#65292;&#20998;&#21035;&#26159;&#65288;&#26465;&#20214;&#65289;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#26368;&#20808;&#36827;&#30340;&#29983;&#25104;&#27169;&#22411;&#20197;&#21450;&#24102;&#32422;&#26463;&#30340;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#20316;&#20026;&#20869;&#37096;&#27169;&#22411;&#26550;&#26500;&#65292;&#20854;&#29305;&#21035;&#36866;&#29992;&#20110;&#25429;&#25417;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#30340;&#38271;&#26399;&#20381;&#36182;&#20851;&#31995;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;SSSD&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#21644;&#19981;&#21516;&#30340;&#32570;&#22833;&#24773;&#20917;&#19979;&#65292;&#21253;&#25324;&#25361;&#25112;&#24615;&#30340;&#40657;&#23631;&#32570;&#22833;&#24773;&#20917;&#19979;&#65292;&#22343;&#21487;&#36798;&#21040;&#25110;&#29978;&#33267;&#36229;&#36807;&#26368;&#20808;&#36827;&#30340;&#27010;&#29575;&#25554;&#34917;&#21644;&#39044;&#27979;&#24615;&#33021;&#65292;&#32780;&#20808;&#21069;&#30340;&#26041;&#27861;&#21017;&#26080;&#27861;&#25552;&#20379;&#26377;&#24847;&#20041;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
The imputation of missing values represents a significant obstacle for many real-world data analysis pipelines. Here, we focus on time series data and put forward SSSD, an imputation model that relies on two emerging technologies, (conditional) diffusion models as state-of-the-art generative models and structured state space models as internal model architecture, which are particularly suited to capture long-term dependencies in time series data. We demonstrate that SSSD matches or even exceeds state-of-the-art probabilistic imputation and forecasting performance on a broad range of data sets and different missingness scenarios, including the challenging blackout-missing scenarios, where prior approaches failed to provide meaningful results.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#38598;&#21512;&#21345;&#23572;&#26364;&#26356;&#26032;&#30340;&#38750;&#28176;&#36817;&#20998;&#26512;&#65292;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#22312;&#20808;&#21069;&#30340;&#21327;&#26041;&#24046;&#20855;&#26377;&#20013;&#31561;&#30340;&#26377;&#25928;&#32500;&#24230;&#12289;&#24555;&#36895;&#35889;&#34928;&#20943;&#25110;&#36817;&#20284;&#31232;&#30095;&#30340;&#24773;&#20917;&#19979;&#65292;&#23567;&#30340;&#38598;&#21512;&#22823;&#23567;&#23601;&#36275;&#22815;&#20102;&#12290;</title><link>http://arxiv.org/abs/2208.03246</link><description>&lt;p&gt;
&#38598;&#21512;&#21345;&#23572;&#26364;&#26356;&#26032;&#30340;&#38750;&#28176;&#36817;&#20998;&#26512;: &#26377;&#25928;&#32500;&#24230;&#21644;&#26412;&#22320;&#21270;
&lt;/p&gt;
&lt;p&gt;
Non-Asymptotic Analysis of Ensemble Kalman Updates: Effective Dimension and Localization. (arXiv:2208.03246v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.03246
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#38598;&#21512;&#21345;&#23572;&#26364;&#26356;&#26032;&#30340;&#38750;&#28176;&#36817;&#20998;&#26512;&#65292;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#22312;&#20808;&#21069;&#30340;&#21327;&#26041;&#24046;&#20855;&#26377;&#20013;&#31561;&#30340;&#26377;&#25928;&#32500;&#24230;&#12289;&#24555;&#36895;&#35889;&#34928;&#20943;&#25110;&#36817;&#20284;&#31232;&#30095;&#30340;&#24773;&#20917;&#19979;&#65292;&#23567;&#30340;&#38598;&#21512;&#22823;&#23567;&#23601;&#36275;&#22815;&#20102;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#29992;&#20110;&#21453;&#38382;&#39064;&#21644;&#25968;&#25454;&#21516;&#21270;&#30340;&#29616;&#20195;&#31639;&#27861;&#20381;&#36182;&#20110;&#38598;&#21512;&#21345;&#23572;&#26364;&#26356;&#26032;&#26469;&#23558;&#20808;&#21069;&#30340;&#39044;&#27979;&#32467;&#26524;&#19982;&#35266;&#27979;&#25968;&#25454;&#34701;&#21512;&#12290;&#38598;&#21512;&#21345;&#23572;&#26364;&#26041;&#27861;&#36890;&#24120;&#22312;&#23567;&#38598;&#21512;&#22823;&#23567;&#26102;&#34920;&#29616;&#33391;&#22909;&#65292;&#36825;&#22312;&#29983;&#25104;&#27599;&#20010;&#31890;&#23376;&#24456;&#26114;&#36149;&#30340;&#24212;&#29992;&#20013;&#26159;&#24517;&#35201;&#30340;&#12290;&#26412;&#25991;&#24320;&#21457;&#20102;&#38598;&#21512;&#21345;&#23572;&#26364;&#26356;&#26032;&#30340;&#38750;&#28176;&#36817;&#20998;&#26512;&#65292;&#20174;&#29702;&#35770;&#19978;&#20005;&#26684;&#35828;&#26126;&#20102;&#20026;&#20160;&#20040;&#22914;&#26524;&#20808;&#21069;&#30340;&#21327;&#26041;&#24046;&#20855;&#26377;&#20013;&#31561;&#30340;&#26377;&#25928;&#32500;&#24230;&#65292;&#24555;&#36895;&#35889;&#34928;&#20943;&#25110;&#36817;&#20284;&#31232;&#30095;&#65292;&#21017;&#23567;&#30340;&#38598;&#21512;&#22823;&#23567;&#23601;&#36275;&#22815;&#20102;&#12290;&#25105;&#20204;&#22312;&#32479;&#19968;&#26694;&#26550;&#19979;&#25552;&#20986;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#27604;&#36739;&#20102;&#20351;&#29992;&#25200;&#21160;&#35266;&#27979;&#12289;&#24179;&#26041;&#26681;&#28388;&#27874;&#21644;&#26412;&#22320;&#21270;&#30340;&#38598;&#21512;&#21345;&#23572;&#26364;&#26356;&#26032;&#30340;&#20960;&#31181;&#23454;&#29616;&#12290;&#20316;&#20026;&#25105;&#20204;&#20998;&#26512;&#30340;&#19968;&#37096;&#20998;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#36866;&#29992;&#20110;&#36817;&#20284;&#31232;&#30095;&#30697;&#38453;&#30340;&#26080;&#32500;&#24230;&#21327;&#26041;&#24046;&#20272;&#35745;&#30028;&#38480;&#65292;&#36825;&#21487;&#33021;&#26159;&#29420;&#31435;&#24863;&#20852;&#36259;&#30340;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many modern algorithms for inverse problems and data assimilation rely on ensemble Kalman updates to blend prior predictions with observed data. Ensemble Kalman methods often perform well with a small ensemble size, which is essential in applications where generating each particle is costly. This paper develops a non-asymptotic analysis of ensemble Kalman updates that rigorously explains why a small ensemble size suffices if the prior covariance has moderate effective dimension due to fast spectrum decay or approximate sparsity. We present our theory in a unified framework, comparing several implementations of ensemble Kalman updates that use perturbed observations, square root filtering, and localization. As part of our analysis, we develop new dimension-free covariance estimation bounds for approximately sparse matrices that may be of independent interest.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#29992;&#20110;&#20998;&#26512;&#22810;&#20803;&#20998;&#24067;&#26102;&#38388;&#24207;&#21015;&#12290;&#24182;&#19988;&#22312;Wasserstein&#31354;&#38388;&#20013;&#24314;&#27169;&#20102;&#38543;&#26426;&#23545;&#35937;&#65292;&#25552;&#20379;&#20102;&#35813;&#27169;&#22411;&#30340;&#35299;&#30340;&#23384;&#22312;&#24615;&#21644;&#19968;&#33268;&#20272;&#35745;&#22120;&#12290;&#27492;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#24180;&#40836;&#20998;&#24067;&#21644;&#33258;&#34892;&#36710;&#20849;&#20139;&#32593;&#32476;&#30340;&#35266;&#23519;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2207.05442</link><description>&lt;p&gt;
Wasserstein&#22810;&#20803;&#33258;&#22238;&#24402;&#27169;&#22411;&#29992;&#20110;&#24314;&#27169;&#20998;&#24067;&#26102;&#38388;&#24207;&#21015;&#21450;&#20854;&#22312;&#22270;&#24418;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Wasserstein multivariate auto-regressive models for modeling distributional time series and its application in graph learning. (arXiv:2207.05442v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.05442
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#29992;&#20110;&#20998;&#26512;&#22810;&#20803;&#20998;&#24067;&#26102;&#38388;&#24207;&#21015;&#12290;&#24182;&#19988;&#22312;Wasserstein&#31354;&#38388;&#20013;&#24314;&#27169;&#20102;&#38543;&#26426;&#23545;&#35937;&#65292;&#25552;&#20379;&#20102;&#35813;&#27169;&#22411;&#30340;&#35299;&#30340;&#23384;&#22312;&#24615;&#21644;&#19968;&#33268;&#20272;&#35745;&#22120;&#12290;&#27492;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#24180;&#40836;&#20998;&#24067;&#21644;&#33258;&#34892;&#36710;&#20849;&#20139;&#32593;&#32476;&#30340;&#35266;&#23519;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#29992;&#20110;&#32479;&#35745;&#20998;&#26512;&#22810;&#20803;&#20998;&#24067;&#26102;&#38388;&#24207;&#21015;&#12290;&#24863;&#20852;&#36259;&#30340;&#25968;&#25454;&#21253;&#25324;&#19968;&#32452;&#22312;&#23454;&#32447;&#26377;&#30028;&#38388;&#38548;&#19978;&#25903;&#25345;&#30340;&#27010;&#29575;&#27979;&#24230;&#30340;&#22810;&#20010;&#31995;&#21015;&#65292;&#24182;&#19988;&#34987;&#19981;&#21516;&#26102;&#38388;&#30636;&#38388;&#25152;&#32034;&#24341;&#12290;&#27010;&#29575;&#27979;&#24230;&#34987;&#24314;&#27169;&#20026;Wasserstein&#31354;&#38388;&#20013;&#30340;&#38543;&#26426;&#23545;&#35937;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;Lebesgue&#27979;&#24230;&#30340;&#20999;&#31354;&#38388;&#20013;&#24314;&#31435;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#39318;&#20808;&#23545;&#25152;&#26377;&#21407;&#22987;&#27979;&#24230;&#36827;&#34892;&#23621;&#20013;&#22788;&#29702;&#65292;&#20197;&#20415;&#23427;&#20204;&#30340;Fr&#233;chet&#24179;&#22343;&#20540;&#25104;&#20026;Lebesgue&#27979;&#24230;&#12290;&#21033;&#29992;&#36845;&#20195;&#38543;&#26426;&#20989;&#25968;&#31995;&#32479;&#30340;&#29702;&#35770;&#65292;&#25552;&#20379;&#20102;&#36825;&#26679;&#19968;&#20010;&#27169;&#22411;&#30340;&#35299;&#30340;&#23384;&#22312;&#24615;&#12289;&#21807;&#19968;&#24615;&#21644;&#24179;&#31283;&#24615;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#27169;&#22411;&#31995;&#25968;&#30340;&#19968;&#33268;&#20272;&#35745;&#22120;&#12290;&#38500;&#20102;&#23545;&#27169;&#25311;&#25968;&#25454;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#36824;&#20351;&#29992;&#20004;&#20010;&#23454;&#38469;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#27169;&#22411;&#28436;&#31034;&#65306;&#19968;&#20010;&#26159;&#19981;&#21516;&#22269;&#23478;&#24180;&#40836;&#20998;&#24067;&#30340;&#35266;&#23519;&#25968;&#25454;&#38598;&#65292;&#21478;&#19968;&#20010;&#26159;&#24052;&#40654;&#33258;&#34892;&#36710;&#20849;&#20139;&#32593;&#32476;&#30340;&#35266;&#23519;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new auto-regressive model for the statistical analysis of multivariate distributional time series. The data of interest consist of a collection of multiple series of probability measures supported over a bounded interval of the real line, and that are indexed by distinct time instants. The probability measures are modelled as random objects in the Wasserstein space. We establish the auto-regressive model in the tangent space at the Lebesgue measure by first centering all the raw measures so that their Fr\'echet means turn to be the Lebesgue measure. Using the theory of iterated random function systems, results on the existence, uniqueness and stationarity of the solution of such a model are provided. We also propose a consistent estimator for the model coefficient. In addition to the analysis of simulated data, the proposed model is illustrated with two real data sets made of observations from age distribution in different countries and bike sharing network in Paris. Final
&lt;/p&gt;</description></item><item><title>TabPFN&#26159;&#19968;&#31181;&#21487;&#20197;&#22312;&#19981;&#21040;&#19968;&#31186;&#38047;&#20869;&#23436;&#25104;&#23567;&#22411;&#34920;&#26684;&#25968;&#25454;&#38598;&#30340;&#30417;&#30563;&#20998;&#31867;&#30340;Transformer&#65292;&#26080;&#38656;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#24182;&#19988;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;&#23427;&#20351;&#29992;&#20808;&#39564;&#36866;&#24212;&#32593;&#32476;&#65288;PFN&#65289;&#36924;&#36817;&#22522;&#20110;&#20808;&#39564;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#20808;&#39564;&#34701;&#21512;&#20102;&#22240;&#26524;&#25512;&#29702;&#30340;&#24605;&#24819;&#12290;</title><link>http://arxiv.org/abs/2207.01848</link><description>&lt;p&gt;
TabPFN&#65306;&#22312;&#19968;&#31186;&#20869;&#35299;&#20915;&#23567;&#22411;&#34920;&#26684;&#20998;&#31867;&#38382;&#39064;&#30340;Transformer
&lt;/p&gt;
&lt;p&gt;
TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second. (arXiv:2207.01848v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.01848
&lt;/p&gt;
&lt;p&gt;
TabPFN&#26159;&#19968;&#31181;&#21487;&#20197;&#22312;&#19981;&#21040;&#19968;&#31186;&#38047;&#20869;&#23436;&#25104;&#23567;&#22411;&#34920;&#26684;&#25968;&#25454;&#38598;&#30340;&#30417;&#30563;&#20998;&#31867;&#30340;Transformer&#65292;&#26080;&#38656;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#24182;&#19988;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;&#23427;&#20351;&#29992;&#20808;&#39564;&#36866;&#24212;&#32593;&#32476;&#65288;PFN&#65289;&#36924;&#36817;&#22522;&#20110;&#20808;&#39564;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#20808;&#39564;&#34701;&#21512;&#20102;&#22240;&#26524;&#25512;&#29702;&#30340;&#24605;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;TabPFN&#65292;&#19968;&#31181;&#32463;&#36807;&#35757;&#32451;&#30340;Transformer&#65292;&#21487;&#20197;&#22312;&#19981;&#21040;&#19968;&#31186;&#38047;&#30340;&#26102;&#38388;&#20869;&#23436;&#25104;&#23567;&#22411;&#34920;&#26684;&#25968;&#25454;&#38598;&#30340;&#30417;&#30563;&#20998;&#31867;&#65292;&#26080;&#38656;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#24182;&#19988;&#22312;&#20998;&#31867;&#26041;&#27861;&#30340;&#26368;&#26032;&#29366;&#24577;&#19979;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;TabPFN&#23436;&#20840;&#21253;&#21547;&#22312;&#25105;&#20204;&#32593;&#32476;&#30340;&#26435;&#37325;&#20013;&#65292;&#25509;&#21463;&#35757;&#32451;&#21644;&#27979;&#35797;&#26679;&#26412;&#20316;&#20026;&#35774;&#32622;&#20540;&#36755;&#20837;&#65292;&#24182;&#22312;&#21333;&#20010;&#21069;&#21521;&#20256;&#36882;&#20013;&#20026;&#25972;&#20010;&#27979;&#35797;&#38598;&#25552;&#20379;&#39044;&#27979;&#12290;TabPFN&#26159;&#19968;&#31181;&#20808;&#39564;&#36866;&#24212;&#32593;&#32476;&#65288;PFN&#65289;&#65292;&#21482;&#38656;&#35201;&#32447;&#19979;&#35757;&#32451;&#19968;&#27425;&#65292;&#21363;&#21487;&#36924;&#36817;&#22522;&#20110;&#25105;&#20204;&#30340;&#20808;&#39564;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#36825;&#20010;&#20808;&#39564;&#34701;&#21512;&#20102;&#22240;&#26524;&#25512;&#29702;&#30340;&#24605;&#24819;&#65306;&#23427;&#21253;&#25324;&#19968;&#20010;&#22823;&#30340;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#31354;&#38388;&#65292;&#20559;&#22909;&#20110;&#31616;&#21333;&#32467;&#26500;&#12290;&#22312;OpenML-CC18&#22871;&#20214;&#30340;18&#20010;&#21253;&#21547;&#26368;&#22810;1000&#20010;&#35757;&#32451;&#25968;&#25454;&#28857;&#12289;&#26368;&#22810;100&#20010;&#32431;&#25968;&#20540;&#29305;&#24449;&#19988;&#26080;&#32570;&#22833;&#20540;&#12289;&#26368;&#22810;10&#20010;&#31867;&#21035;&#30340;&#25968;&#25454;&#38598;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#26126;&#26174;&#20248;&#20110;&#25552;&#21319;&#26641;&#65292;&#19982;&#22797;&#26434;&#30340;&#26368;&#26032;AutoM&#26041;&#27861;&#34920;&#29616;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present TabPFN, a trained Transformer that can do supervised classification for small tabular datasets in less than a second, needs no hyperparameter tuning and is competitive with state-of-the-art classification methods. TabPFN is fully entailed in the weights of our network, which accepts training and test samples as a set-valued input and yields predictions for the entire test set in a single forward pass. TabPFN is a Prior-Data Fitted Network (PFN) and is trained offline once, to approximate Bayesian inference on synthetic datasets drawn from our prior. This prior incorporates ideas from causal reasoning: It entails a large space of structural causal models with a preference for simple structures. On the 18 datasets in the OpenML-CC18 suite that contain up to 1 000 training data points, up to 100 purely numerical features without missing values, and up to 10 classes, we show that our method clearly outperforms boosted trees and performs on par with complex state-of-the-art AutoM
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19981;&#21516;iable hypergeometric distribution&#65292;&#20351;&#29992;&#37325;&#35201;&#24615;&#23398;&#20064;&#26041;&#27861;&#26469;&#35299;&#20915;&#22312;&#35768;&#22810;&#24212;&#29992;&#31243;&#24207;&#20013;&#23558;&#19968;&#32452;&#20803;&#32032;&#21010;&#20998;&#20026;&#20808;&#39564;&#26410;&#30693;&#22823;&#23567;&#30340;&#23376;&#38598;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#24369;&#30417;&#30563;&#23398;&#20064;&#21644;&#32858;&#31867;&#26041;&#38754;&#20248;&#20110;&#20197;&#21069;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2203.01629</link><description>&lt;p&gt;
&#20351;&#29992;&#21487;&#24494;&#20998;&#36229;&#20960;&#20309;&#20998;&#24067;&#36827;&#34892;&#23567;&#32452;&#37325;&#35201;&#24615;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning Group Importance using the Differentiable Hypergeometric Distribution. (arXiv:2203.01629v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.01629
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19981;&#21516;iable hypergeometric distribution&#65292;&#20351;&#29992;&#37325;&#35201;&#24615;&#23398;&#20064;&#26041;&#27861;&#26469;&#35299;&#20915;&#22312;&#35768;&#22810;&#24212;&#29992;&#31243;&#24207;&#20013;&#23558;&#19968;&#32452;&#20803;&#32032;&#21010;&#20998;&#20026;&#20808;&#39564;&#26410;&#30693;&#22823;&#23567;&#30340;&#23376;&#38598;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#24369;&#30417;&#30563;&#23398;&#20064;&#21644;&#32858;&#31867;&#26041;&#38754;&#20248;&#20110;&#20197;&#21069;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24212;&#29992;&#31243;&#24207;&#20013;&#65292;&#23558;&#19968;&#32452;&#20803;&#32032;&#21010;&#20998;&#20026;&#20808;&#39564;&#26410;&#30693;&#22823;&#23567;&#30340;&#23376;&#38598;&#26159;&#24517;&#35201;&#30340;&#12290;&#36825;&#20123;&#23376;&#38598;&#22823;&#23567;&#24456;&#23569;&#26126;&#30830;&#23398;&#20064; - &#26080;&#35770;&#26159;&#32858;&#31867;&#24212;&#29992;&#31243;&#24207;&#20013;&#30340;&#31751;&#22823;&#23567;&#36824;&#26159;&#24369;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#20849;&#20139;&#19982;&#29420;&#31435;&#29983;&#25104;&#28508;&#22312;&#22240;&#32032;&#30340;&#25968;&#37327;&#12290;&#30001;&#20110;&#30828;&#24615;&#32422;&#26463;&#26465;&#20214;&#65292;&#27491;&#30830;&#23376;&#38598;&#22823;&#23567;&#30340;&#27010;&#29575;&#20998;&#24067;&#26159;&#19981;&#21487;&#24494;&#20998;&#30340;&#65292;&#36825;&#31105;&#27490;&#20102;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21487;&#24494;&#20998;&#36229;&#20960;&#20309;&#20998;&#24067;&#12290;&#36229;&#20960;&#20309;&#20998;&#24067;&#22522;&#20110;&#23427;&#20204;&#30340;&#30456;&#23545;&#37325;&#35201;&#24615;&#27169;&#25311;&#19981;&#21516;&#32452;&#22823;&#23567;&#30340;&#27010;&#29575;&#12290;&#25105;&#20204;&#24341;&#20837;&#21487;&#37325;&#21442;&#25968;&#21270;&#26799;&#24230;&#26469;&#23398;&#20064;&#23567;&#32452;&#20043;&#38388;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#24378;&#35843;&#22312;&#20004;&#20010;&#20856;&#22411;&#24212;&#29992;&#31243;&#24207;&#20013;&#26174;&#24335;&#23398;&#20064;&#23376;&#38598;&#22823;&#23567;&#30340;&#20248;&#28857;&#65306;&#24369;&#30417;&#30563;&#23398;&#20064;&#21644;&#32858;&#31867;&#12290;&#22312;&#36825;&#20004;&#20010;&#24212;&#29992;&#31243;&#24207;&#20013;&#65292;&#25105;&#20204;&#20248;&#20110;&#20381;&#36182;&#20110;&#27425;&#20248;&#21551;&#21457;&#24335;&#27169;&#25311;&#26410;&#30693;&#22823;&#23567;&#30340;&#20808;&#21069;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Partitioning a set of elements into subsets of a priori unknown sizes is essential in many applications. These subset sizes are rarely explicitly learned - be it the cluster sizes in clustering applications or the number of shared versus independent generative latent factors in weakly-supervised learning. Probability distributions over correct combinations of subset sizes are non-differentiable due to hard constraints, which prohibit gradient-based optimization. In this work, we propose the differentiable hypergeometric distribution. The hypergeometric distribution models the probability of different group sizes based on their relative importance. We introduce reparameterizable gradients to learn the importance between groups and highlight the advantage of explicitly learning the size of subsets in two typical applications: weakly-supervised learning and clustering. In both applications, we outperform previous approaches, which rely on suboptimal heuristics to model the unknown size of
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#27604;&#36739;&#20102;&#20004;&#31181;&#24120;&#29992;&#30340;&#32534;&#30721;&#26041;&#27861;-&#8220;one-hot&#32534;&#30721;&#8221;&#21644;&#8220;target&#32534;&#30721;&#8221;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#23545;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#24615;&#33021;&#21644;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2201.11358</link><description>&lt;p&gt;
&#32534;&#30721;&#20445;&#25252;&#20998;&#31867;&#23646;&#24615;&#30340;&#20844;&#24179;&#24615;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fairness Implications of Encoding Protected Categorical Attributes. (arXiv:2201.11358v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.11358
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#27604;&#36739;&#20102;&#20004;&#31181;&#24120;&#29992;&#30340;&#32534;&#30721;&#26041;&#27861;-&#8220;one-hot&#32534;&#30721;&#8221;&#21644;&#8220;target&#32534;&#30721;&#8221;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#23545;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#24615;&#33021;&#21644;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21435;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#26126;&#30830;&#20351;&#29992;&#20445;&#25252;&#23646;&#24615;&#21487;&#20197;&#21516;&#26102;&#25552;&#39640;&#24615;&#33021;&#21644;&#20844;&#24179;&#24615;&#12290;&#20294;&#26159;&#65292;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#26080;&#27861;&#30452;&#25509;&#22788;&#29702;&#20998;&#31867;&#23646;&#24615;&#65292;&#20363;&#22914;&#20986;&#29983;&#22269;&#23478;&#25110;&#31181;&#26063;&#12290;&#30001;&#20110;&#20445;&#25252;&#23646;&#24615;&#32463;&#24120;&#26159;&#20998;&#31867;&#30340;&#65292;&#22240;&#27492;&#24517;&#39035;&#23558;&#20854;&#32534;&#30721;&#20026;&#21487;&#20197;&#36755;&#20837;&#25152;&#36873;&#25321;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#29305;&#24449;&#65292;&#20363;&#22914;&#25903;&#25345;&#21521;&#37327;&#26426;&#12289;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#25110;&#32447;&#24615;&#27169;&#22411;&#12290;&#32534;&#30721;&#26041;&#27861;&#24433;&#21709;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#23558;&#23398;&#20064;&#22914;&#20309;&#21644;&#20160;&#20040;&#65292;&#24433;&#21709;&#27169;&#22411;&#30340;&#24615;&#33021;&#21644;&#20844;&#24179;&#24615;&#12290;&#35813;&#30740;&#31350;&#27604;&#36739;&#20102;&#20004;&#31181;&#26368;&#33879;&#21517;&#30340;&#32534;&#30721;&#26041;&#27861;&#8212;&#8212;&#8220;one-hot&#32534;&#30721;&#8221;&#21644;&#8220;target&#32534;&#30721;&#8221;&#30340;&#20934;&#30830;&#24615;&#21644;&#20844;&#24179;&#24615;&#24433;&#21709;&#12290;&#25105;&#20204;&#21306;&#20998;&#20102;&#36825;&#20123;&#32534;&#30721;&#26041;&#27861;&#21487;&#33021;&#20135;&#29983;&#30340;&#20004;&#31181;&#35825;&#23548;&#20559;&#24046;&#31867;&#22411;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#19981;&#20844;&#24179;&#30340;&#27169;&#22411;&#12290;&#31532;&#19968;&#31181;&#31867;&#22411;&#26159;&#26080;&#27861;&#28040;&#38500;&#30340;&#20559;&#24046;&#65292;&#30001;&#20110;&#30452;&#25509;&#32452;&#21035;&#31867;&#21035;&#27495;&#35270;&#32780;&#23548;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
Past research has demonstrated that the explicit use of protected attributes in machine learning can improve both performance and fairness. Many machine learning algorithms, however, cannot directly process categorical attributes, such as country of birth or ethnicity. Because protected attributes frequently are categorical, they must be encoded as features that can be input to a chosen machine learning algorithm, e.g.\ support vector machines, gradient boosting decision trees or linear models. Thereby, encoding methods influence how and what the machine learning algorithm will learn, affecting model performance and fairness. This work compares the accuracy and fairness implications of the two most well-known encoding methods: \emph{one-hot encoding} and \emph{target encoding}. We distinguish between two types of induced bias that may arise from these encoding methods and may lead to unfair models. The first type, \textit{irreducible bias}, is due to direct group category discriminatio
&lt;/p&gt;</description></item><item><title>CausalSim&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#26694;&#26550;&#65292;&#36890;&#36807;&#23398;&#20064;&#31995;&#32479;&#21160;&#24577;&#21644;&#28508;&#22312;&#22240;&#32032;&#30340;&#22240;&#26524;&#27169;&#22411;&#65292;&#28040;&#38500;&#36861;&#36394;&#25968;&#25454;&#20013;&#30340;&#20559;&#24046;&#65292;&#35299;&#20915;&#20102;&#24403;&#21069;&#36861;&#36394;&#39537;&#21160;&#20223;&#30495;&#22120;&#30340;&#32570;&#38519;&#12290;</title><link>http://arxiv.org/abs/2201.01811</link><description>&lt;p&gt;
CausalSim: &#19968;&#31181;&#29992;&#20110;&#26080;&#20559;&#24046;&#36861;&#36394;&#39537;&#21160;&#20223;&#30495;&#30340;&#22240;&#26524;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
CausalSim: A Causal Framework for Unbiased Trace-Driven Simulation. (arXiv:2201.01811v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.01811
&lt;/p&gt;
&lt;p&gt;
CausalSim&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#26694;&#26550;&#65292;&#36890;&#36807;&#23398;&#20064;&#31995;&#32479;&#21160;&#24577;&#21644;&#28508;&#22312;&#22240;&#32032;&#30340;&#22240;&#26524;&#27169;&#22411;&#65292;&#28040;&#38500;&#36861;&#36394;&#25968;&#25454;&#20013;&#30340;&#20559;&#24046;&#65292;&#35299;&#20915;&#20102;&#24403;&#21069;&#36861;&#36394;&#39537;&#21160;&#20223;&#30495;&#22120;&#30340;&#32570;&#38519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;CausalSim&#65292;&#19968;&#31181;&#29992;&#20110;&#26080;&#20559;&#24046;&#36861;&#36394;&#39537;&#21160;&#20223;&#30495;&#30340;&#22240;&#26524;&#26694;&#26550;&#12290;&#24403;&#21069;&#30340;&#36861;&#36394;&#39537;&#21160;&#20223;&#30495;&#22120;&#20551;&#35774;&#36827;&#34892;&#20223;&#30495;&#30340;&#24178;&#39044;&#65288;&#20363;&#22914;&#65292;&#26032;&#31639;&#27861;&#65289;&#19981;&#20250;&#24433;&#21709;&#36861;&#36394;&#30340;&#26377;&#25928;&#24615;&#12290;&#28982;&#32780;&#65292;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#36861;&#36394;&#24120;&#24120;&#20250;&#21463;&#21040;&#31639;&#27861;&#22312;&#36861;&#36394;&#25910;&#38598;&#26399;&#38388;&#36827;&#34892;&#36873;&#25321;&#30340;&#24433;&#21709;&#65292;&#22240;&#27492;&#65292;&#22312;&#24178;&#39044;&#19979;&#37325;&#28436;&#36861;&#36394;&#21487;&#33021;&#20250;&#23548;&#33268;&#19981;&#27491;&#30830;&#30340;&#32467;&#26524;&#12290;CausalSim&#36890;&#36807;&#23398;&#20064;&#31995;&#32479;&#21160;&#24577;&#21644;&#25429;&#33719;&#36861;&#36394;&#25910;&#38598;&#26399;&#38388;&#22522;&#30784;&#31995;&#32479;&#26465;&#20214;&#30340;&#28508;&#22312;&#22240;&#32032;&#30340;&#22240;&#26524;&#27169;&#22411;&#26469;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#12290;&#23427;&#20351;&#29992;&#22266;&#23450;&#31639;&#27861;&#38598;&#19979;&#30340;&#21021;&#22987;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#65288;RCT&#65289;&#26469;&#23398;&#20064;&#36825;&#20123;&#27169;&#22411;&#65292;&#28982;&#21518;&#22312;&#27169;&#25311;&#26032;&#31639;&#27861;&#26102;&#24212;&#29992;&#23427;&#20204;&#26469;&#28040;&#38500;&#36861;&#36394;&#25968;&#25454;&#20013;&#30340;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present CausalSim, a causal framework for unbiased trace-driven simulation. Current trace-driven simulators assume that the interventions being simulated (e.g., a new algorithm) would not affect the validity of the traces. However, real-world traces are often biased by the choices algorithms make during trace collection, and hence replaying traces under an intervention may lead to incorrect results. CausalSim addresses this challenge by learning a causal model of the system dynamics and latent factors capturing the underlying system conditions during trace collection. It learns these models using an initial randomized control trial (RCT) under a fixed set of algorithms, and then applies them to remove biases from trace data when simulating new algorithms.  Key to CausalSim is mapping unbiased trace-driven simulation to a tensor completion problem with extremely sparse observations. By exploiting a basic distributional invariance property present in RCT data, CausalSim enables a nove
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#31070;&#32463;&#32593;&#32476;&#26222;&#36866;&#24615;&#30340;&#24314;&#26500;&#26694;&#26550;&#65292;&#20219;&#20309;nAI&#28608;&#27963;&#20989;&#25968;&#37117;&#26159;&#26222;&#36866;&#30340;&#65292;&#35813;&#26694;&#26550;&#20855;&#26377;&#32479;&#19968;&#12289;&#26500;&#36896;&#24615;&#21644;&#26032;&#35270;&#35282;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2112.14877</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#26222;&#36866;&#24615;&#30340;&#32479;&#19968;&#24314;&#26500;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Unified and Constructive Framework for the Universality of Neural Networks. (arXiv:2112.14877v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.14877
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#31070;&#32463;&#32593;&#32476;&#26222;&#36866;&#24615;&#30340;&#24314;&#26500;&#26694;&#26550;&#65292;&#20219;&#20309;nAI&#28608;&#27963;&#20989;&#25968;&#37117;&#26159;&#26222;&#36866;&#30340;&#65292;&#35813;&#26694;&#26550;&#20855;&#26377;&#32479;&#19968;&#12289;&#26500;&#36896;&#24615;&#21644;&#26032;&#35270;&#35282;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20043;&#25152;&#20197;&#33021;&#22815;&#22797;&#21046;&#22797;&#26434;&#30340;&#20219;&#21153;&#25110;&#20989;&#25968;&#20043;&#19968;&#26159;&#22240;&#20026;&#23427;&#20204;&#30340;&#26222;&#36866;&#24615;&#12290;&#34429;&#28982;&#36807;&#21435;&#20960;&#21313;&#24180;&#26469;&#31070;&#32463;&#32593;&#32476;&#29702;&#35770;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#36827;&#23637;&#65292;&#20294;&#23578;&#26410;&#25552;&#20379;&#21333;&#19968;&#30340;&#24314;&#26500;&#26694;&#26550;&#26469;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#30340;&#26222;&#36866;&#24615;&#12290;&#26412;&#25991;&#26159;&#31532;&#19968;&#20010;&#20026;&#22823;&#22810;&#25968;&#24050;&#26377;&#28608;&#27963;&#20989;&#25968;&#25552;&#20379;&#32479;&#19968;&#30340;&#24314;&#26500;&#26694;&#26550;&#20197;&#35299;&#37322;&#23427;&#20204;&#30340;&#26222;&#36866;&#24615;&#30340;&#23581;&#35797;&#12290;&#22312;&#26694;&#26550;&#30340;&#26680;&#24515;&#26159;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#24658;&#31561;&#65288;nAI&#65289;&#30340;&#27010;&#24565;&#12290;&#20027;&#35201;&#30340;&#32467;&#26524;&#26159;&#65306;\emph{&#20219;&#20309;nAI&#28608;&#27963;&#20989;&#25968;&#37117;&#26159;&#26222;&#36866;&#30340;}&#12290;&#20107;&#23454;&#35777;&#26126;&#65292;&#22823;&#22810;&#25968;&#28608;&#27963;&#20989;&#25968;&#37117;&#26159;nAI&#65292;&#22240;&#27492;&#22312;&#32039;&#33268;&#31354;&#38388;&#36830;&#32493;&#20989;&#25968;&#31354;&#38388;&#20869;&#26159;&#26222;&#36866;&#30340;&#12290;&#35813;&#26694;&#26550;&#27604;&#29616;&#26377;&#30340;&#23545;&#24212;&#29289;&#20855;&#26377;\textbf{&#20960;&#20010;&#20248;&#21183;}&#12290;&#39318;&#20808;&#65292;&#23427;&#26159;&#24314;&#31435;&#22312;&#20174;&#21151;&#33021;&#20998;&#26512;&#12289;&#27010;&#29575;&#35770;&#21644;&#25968;&#20540;&#20998;&#26512;&#30340;&#22522;&#26412;&#25163;&#27573;&#20043;&#19978;&#30340;&#26500;&#36896;&#24615;&#26694;&#26550;&#12290;&#20854;&#27425;&#65292;&#23427;&#26159;&#31532;&#19968;&#20010;&#36866;&#29992;&#20110;&#21253;&#25324;&#22823;&#22810;&#25968;&#24050;&#26377;&#28608;&#27963;&#20989;&#25968;&#22312;&#20869;&#30340;&#22823;&#31867;&#28608;&#27963;&#20989;&#25968;&#30340;&#32479;&#19968;&#26694;&#26550;&#12290;&#31532;&#19977;&#65292;&#23427;&#25552;&#20986;&#20102;&#31070;&#32463;&#32593;&#32476;&#26222;&#36866;&#24615;&#30340;&#26032;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the reasons why many neural networks are capable of replicating complicated tasks or functions is their universal property. Though the past few decades have seen tremendous advances in theories of neural networks, a single constructive framework for neural network universality remains unavailable. This paper is the first effort to provide a unified and constructive framework for the universality of a large class of activation functions including most of existing ones. At the heart of the framework is the concept of neural network approximate identity (nAI). The main result is: {\em any nAI activation function is universal}. It turns out that most of existing activation functions are nAI, and thus universal in the space of continuous functions on compacta. The framework induces {\bf several advantages} over the contemporary counterparts. First, it is constructive with elementary means from functional analysis, probability theory, and numerical analysis. Second, it is the first un
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#30340;&#23433;&#20840;&#28388;&#27874;&#22120;&#65292;&#38024;&#23545;&#24102;&#26377;&#26410;&#30693;&#27169;&#22411;&#21644;&#26410;&#30693;&#21327;&#26041;&#24046;&#30340;&#39640;&#26031;&#22122;&#22768;&#30340;&#31163;&#25955;&#26102;&#38388;&#32447;&#24615;&#26102;&#19981;&#21464;&#31995;&#32479;&#65292;&#36890;&#36807;&#25910;&#32039;&#23433;&#20840;&#32422;&#26463;&#21644;&#26500;&#24314;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#20197;&#26368;&#23567;&#31243;&#24230;&#22320;&#20462;&#25913;&#21517;&#20041;&#25511;&#21046;&#21160;&#20316;&#65292;&#20197;&#39640;&#27010;&#29575;&#30830;&#20445;&#23433;&#20840;&#24615;&#12290;</title><link>http://arxiv.org/abs/2111.00631</link><description>&lt;p&gt;
&#23398;&#20064;&#26410;&#30693;&#31163;&#25955;&#26102;&#38388;&#32447;&#24615;&#31995;&#32479;&#30340;&#23433;&#20840;&#28388;&#27874;&#22120;
&lt;/p&gt;
&lt;p&gt;
Learning Safety Filters for Unknown Discrete-Time Linear Systems. (arXiv:2111.00631v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.00631
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#30340;&#23433;&#20840;&#28388;&#27874;&#22120;&#65292;&#38024;&#23545;&#24102;&#26377;&#26410;&#30693;&#27169;&#22411;&#21644;&#26410;&#30693;&#21327;&#26041;&#24046;&#30340;&#39640;&#26031;&#22122;&#22768;&#30340;&#31163;&#25955;&#26102;&#38388;&#32447;&#24615;&#26102;&#19981;&#21464;&#31995;&#32479;&#65292;&#36890;&#36807;&#25910;&#32039;&#23433;&#20840;&#32422;&#26463;&#21644;&#26500;&#24314;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#20197;&#26368;&#23567;&#31243;&#24230;&#22320;&#20462;&#25913;&#21517;&#20041;&#25511;&#21046;&#21160;&#20316;&#65292;&#20197;&#39640;&#27010;&#29575;&#30830;&#20445;&#23433;&#20840;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#24102;&#26377;&#26410;&#30693;&#27169;&#22411;&#21644;&#26410;&#30693;&#21327;&#26041;&#24046;&#30340;&#39640;&#26031;&#22122;&#22768;&#30340;&#31163;&#25955;&#26102;&#38388;&#32447;&#24615;&#26102;&#19981;&#21464;&#31995;&#32479;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#30340;&#23433;&#20840;&#28388;&#27874;&#22120;&#12290;&#23433;&#20840;&#24615;&#36890;&#36807;&#23545;&#29366;&#24577;&#21644;&#25511;&#21046;&#36755;&#20837;&#26045;&#21152;&#22810;&#38754;&#20307;&#32422;&#26463;&#26469;&#25551;&#36848;&#12290;&#32463;&#39564;&#24615;&#22320;&#23398;&#20064;&#27169;&#22411;&#21644;&#36807;&#31243;&#22122;&#22768;&#21327;&#26041;&#24046;&#21450;&#20854;&#32622;&#20449;&#21306;&#38388;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#20197;&#26368;&#23567;&#31243;&#24230;&#22320;&#20462;&#25913;&#21517;&#20041;&#25511;&#21046;&#21160;&#20316;&#65292;&#20197;&#39640;&#27010;&#29575;&#30830;&#20445;&#23433;&#20840;&#24615;&#12290;&#20248;&#21270;&#38382;&#39064;&#20381;&#36182;&#20110;&#25910;&#32039;&#21407;&#22987;&#30340;&#23433;&#20840;&#24615;&#32422;&#26463;&#12290;&#30001;&#20110;&#26368;&#21021;&#32570;&#20047;&#21487;&#38752;&#27169;&#22411;&#26500;&#24314;&#25152;&#38656;&#20449;&#24687;&#65292;&#22240;&#27492;&#25910;&#32039;&#30340;&#24133;&#24230;&#36739;&#22823;&#65292;&#20294;&#38543;&#30528;&#26356;&#22810;&#25968;&#25454;&#30340;&#21487;&#29992;&#24615;&#65292;&#20854;&#36880;&#28176;&#32553;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
A learning-based safety filter is developed for discrete-time linear time-invariant systems with unknown models subject to Gaussian noises with unknown covariance. Safety is characterized using polytopic constraints on the states and control inputs. The empirically learned model and process noise covariance with their confidence bounds are used to construct a robust optimization problem for minimally modifying nominal control actions to ensure safety with high probability. The optimization problem relies on tightening the original safety constraints. The magnitude of the tightening is larger at the beginning since there is little information to construct reliable models, but shrinks with time as more data becomes available.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25512;&#23548;&#20102;&#22522;&#20110;PQC&#30340;&#27169;&#22411;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#26126;&#30830;&#22320;&#21462;&#20915;&#20110;&#29992;&#20110;&#25968;&#25454;&#32534;&#30721;&#30340;&#31574;&#30053;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#35757;&#32451;&#36807;&#30340;PQC&#27169;&#22411;&#22312;&#26410;&#30693;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2106.03880</link><description>&lt;p&gt;
&#22522;&#20110;&#32534;&#30721;&#26041;&#24335;&#30340;&#21442;&#25968;&#21270;&#37327;&#23376;&#30005;&#36335;&#30340;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Encoding-dependent generalization bounds for parametrized quantum circuits. (arXiv:2106.03880v3 [quant-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.03880
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25512;&#23548;&#20102;&#22522;&#20110;PQC&#30340;&#27169;&#22411;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#26126;&#30830;&#22320;&#21462;&#20915;&#20110;&#29992;&#20110;&#25968;&#25454;&#32534;&#30721;&#30340;&#31574;&#30053;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#35757;&#32451;&#36807;&#30340;PQC&#27169;&#22411;&#22312;&#26410;&#30693;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#24456;&#22810;&#30740;&#31350;&#24320;&#22987;&#25506;&#32034;&#21442;&#25968;&#21270;&#37327;&#23376;&#30005;&#36335;&#65288;PQC&#65289;&#20316;&#20026;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#22312;&#28151;&#21512;&#37327;&#23376;&#32463;&#20856;&#20248;&#21270;&#26694;&#26550;&#19979;&#30340;&#28508;&#21147;&#12290;&#29305;&#21035;&#22320;&#65292;&#20851;&#20110;&#36825;&#20123;&#27169;&#22411;&#30340;&#26679;&#26412;&#22806;&#24615;&#33021;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#21363;&#27867;&#21270;&#30028;&#38480;&#65292;&#24050;&#32463;&#20986;&#29616;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27867;&#21270;&#30028;&#38480;&#20013;&#27809;&#26377;&#19968;&#20010;&#26126;&#30830;&#22320;&#21462;&#20915;&#20110;&#29992;&#20110;&#23558;&#32463;&#20856;&#36755;&#20837;&#25968;&#25454;&#32534;&#30721;&#21040;PQC&#20013;&#30340;&#31574;&#30053;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#22522;&#20110;PQC&#30340;&#27169;&#22411;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#26126;&#30830;&#22320;&#21462;&#20915;&#20110;&#29992;&#20110;&#25968;&#25454;&#32534;&#30721;&#30340;&#31574;&#30053;&#12290;&#36825;&#20123;&#30028;&#38480;&#26159;&#23545;&#35757;&#32451;&#36807;&#30340;PQC&#27169;&#22411;&#22312;&#26410;&#30693;&#25968;&#25454;&#19978;&#24615;&#33021;&#30340;&#38480;&#21046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#36890;&#36807;&#32467;&#26500;&#39118;&#38505;&#26368;&#23567;&#21270;&#65292;&#21363;&#19968;&#31181;&#25968;&#23398;&#20005;&#26684;&#30340;&#27169;&#22411;&#36873;&#25321;&#26694;&#26550;&#65292;&#20419;&#36827;&#20102;&#26368;&#20339;&#25968;&#25454;&#32534;&#30721;&#31574;&#30053;&#30340;&#36873;&#25321;&#12290;&#25105;&#20204;&#36890;&#36807;&#38480;&#21046;PQC-based&#27169;&#22411;&#30340;&#22797;&#26434;&#24230;&#26469;&#33719;&#24471;&#25105;&#20204;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#35813;&#22797;&#26434;&#24230;&#30001;Rademacher&#22797;&#26434;&#24230;&#21644;&#24230;&#37327;&#29109;&#20004;&#20010;&#22797;&#26434;&#24230;&#24230;&#37327;&#32452;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
A large body of recent work has begun to explore the potential of parametrized quantum circuits (PQCs) as machine learning models, within the framework of hybrid quantum-classical optimization. In particular, theoretical guarantees on the out-of-sample performance of such models, in terms of generalization bounds, have emerged. However, none of these generalization bounds depend explicitly on how the classical input data is encoded into the PQC. We derive generalization bounds for PQC-based models that depend explicitly on the strategy used for data-encoding. These imply bounds on the performance of trained PQC-based models on unseen data. Moreover, our results facilitate the selection of optimal data-encoding strategies via structural risk minimization, a mathematically rigorous framework for model selection. We obtain our generalization bounds by bounding the complexity of PQC-based models as measured by the Rademacher complexity and the metric entropy, two complexity measures from s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#24067;&#23398;&#20064;&#30340;&#21152;&#26435;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#21327;&#21464;&#37327;&#22312;&#27835;&#30103;&#32452;&#21644;&#23545;&#29031;&#32452;&#30340;&#20998;&#24067;&#24182;&#21033;&#29992;&#27604;&#29575;&#20316;&#20026;&#26435;&#37325;&#26469;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;&#65292;&#20197;&#32531;&#35299;&#29616;&#26377;&#21152;&#26435;&#26041;&#27861;&#20013;&#27169;&#22411;&#38169;&#35823;&#35774;&#32622;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2012.13805</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#24067;&#23398;&#20064;&#30340;&#21152;&#26435;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Weighting-Based Treatment Effect Estimation via Distribution Learning. (arXiv:2012.13805v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2012.13805
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#24067;&#23398;&#20064;&#30340;&#21152;&#26435;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#21327;&#21464;&#37327;&#22312;&#27835;&#30103;&#32452;&#21644;&#23545;&#29031;&#32452;&#30340;&#20998;&#24067;&#24182;&#21033;&#29992;&#27604;&#29575;&#20316;&#20026;&#26435;&#37325;&#26469;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;&#65292;&#20197;&#32531;&#35299;&#29616;&#26377;&#21152;&#26435;&#26041;&#27861;&#20013;&#27169;&#22411;&#38169;&#35823;&#35774;&#32622;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#21152;&#26435;&#26041;&#27861;&#36890;&#24120;&#24314;&#31435;&#22312;&#20542;&#21521;&#24471;&#20998;&#25110;&#21327;&#21464;&#37327;&#24179;&#34913;&#30340;&#22522;&#30784;&#19978;&#12290;&#23427;&#20204;&#36890;&#24120;&#23545;&#27835;&#30103;&#20998;&#37197;&#25110;&#32467;&#26524;&#27169;&#22411;&#26045;&#21152;&#24378;&#21046;&#24615;&#20551;&#35774;&#65292;&#20197;&#33719;&#24471;&#26080;&#20559;&#20272;&#35745;&#65292;&#22914;&#32447;&#24615;&#25110;&#29305;&#23450;&#30340;&#20989;&#25968;&#24418;&#24335;&#65292;&#36825;&#24456;&#23481;&#26131;&#23548;&#33268;&#27169;&#22411;&#38169;&#35823;&#35774;&#32622;&#30340;&#20027;&#35201;&#32570;&#28857;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#24320;&#21457;&#22522;&#20110;&#20998;&#24067;&#23398;&#20064;&#30340;&#21152;&#26435;&#26041;&#27861;&#26469;&#32531;&#35299;&#36825;&#20123;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#23398;&#20064;&#20197;&#27835;&#30103;&#20998;&#37197;&#20026;&#26465;&#20214;&#30340;&#21327;&#21464;&#37327;&#30495;&#23454;&#28508;&#22312;&#20998;&#24067;&#65292;&#28982;&#21518;&#21033;&#29992;&#27835;&#30103;&#32452;&#21327;&#21464;&#37327;&#23494;&#24230;&#19982;&#23545;&#29031;&#32452;&#21327;&#21464;&#37327;&#23494;&#24230;&#20043;&#27604;&#20316;&#20026;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;&#30340;&#26435;&#37325;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#21464;&#37327;&#38388;&#30340;&#21487;&#36870;&#21464;&#25442;&#26469;&#36817;&#20284;&#27835;&#30103;&#32452;&#21644;&#23545;&#29031;&#32452;&#20013;&#30340;&#21327;&#21464;&#37327;&#20998;&#24067;&#12290;&#20026;&#20102;&#35777;&#26126;&#25105;&#20204;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12289;&#40065;&#26834;&#24615;&#21644;&#27867;&#21270;&#24615;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing weighting methods for treatment effect estimation are often built upon the idea of propensity scores or covariate balance. They usually impose strong assumptions on treatment assignment or outcome model to obtain unbiased estimation, such as linearity or specific functional forms, which easily leads to the major drawback of model mis-specification. In this paper, we aim to alleviate these issues by developing a distribution learning-based weighting method. We first learn the true underlying distribution of covariates conditioned on treatment assignment, then leverage the ratio of covariates' density in the treatment group to that of the control group as the weight for estimating treatment effects. Specifically, we propose to approximate the distribution of covariates in both treatment and control groups through invertible transformations via change of variables. To demonstrate the superiority, robustness, and generalizability of our method, we conduct extensive experiments usi
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#38024;&#23545;&#32597;&#35265;&#21644;&#19981;&#30830;&#23450;&#35786;&#26029;&#30340;&#33258;&#26432;&#39118;&#38505;&#36827;&#34892;&#29983;&#23384;&#24314;&#27169;&#65292;&#37319;&#29992;&#21307;&#30103;&#32034;&#36180;&#25968;&#25454;&#30740;&#31350;&#20102;&#33258;&#26432;&#26410;&#36930;&#30340;&#24739;&#32773;&#38543;&#21518;&#30340;&#33258;&#26432;&#26410;&#36930;&#39118;&#38505;&#65292;&#36890;&#36807;&#24320;&#21457;&#19968;&#31181;&#32508;&#21512;&#30340;Cox&#28120;&#27760;&#27169;&#22411;&#26469;&#23436;&#25104;&#29983;&#23384;&#22238;&#24402;&#12290;</title><link>http://arxiv.org/abs/2009.02597</link><description>&lt;p&gt;
&#33258;&#26432;&#39118;&#38505;&#30340;&#32597;&#35265;&#21644;&#19981;&#30830;&#23450;&#35786;&#26029;&#30340;&#29983;&#23384;&#24314;&#27169;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Survival Modeling of Suicide Risk with Rare and Uncertain Diagnoses. (arXiv:2009.02597v2 [stat.AP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2009.02597
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#38024;&#23545;&#32597;&#35265;&#21644;&#19981;&#30830;&#23450;&#35786;&#26029;&#30340;&#33258;&#26432;&#39118;&#38505;&#36827;&#34892;&#29983;&#23384;&#24314;&#27169;&#65292;&#37319;&#29992;&#21307;&#30103;&#32034;&#36180;&#25968;&#25454;&#30740;&#31350;&#20102;&#33258;&#26432;&#26410;&#36930;&#30340;&#24739;&#32773;&#38543;&#21518;&#30340;&#33258;&#26432;&#26410;&#36930;&#39118;&#38505;&#65292;&#36890;&#36807;&#24320;&#21457;&#19968;&#31181;&#32508;&#21512;&#30340;Cox&#28120;&#27760;&#27169;&#22411;&#26469;&#23436;&#25104;&#29983;&#23384;&#22238;&#24402;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36890;&#36807;&#25913;&#21892;&#34892;&#20026;&#20445;&#20581;&#23454;&#29616;&#33258;&#26432;&#39044;&#38450;&#30340;&#36843;&#20999;&#38656;&#27714;&#30340;&#39537;&#20351;&#19979;&#65292;&#25105;&#20204;&#20351;&#29992;&#21307;&#30103;&#32034;&#36180;&#25968;&#25454;&#30740;&#31350;&#20102;&#22240;&#33258;&#26432;&#26410;&#36930;&#32780;&#20303;&#38498;&#24182;&#21518;&#26469;&#20986;&#38498;&#30340;&#24739;&#32773;&#38543;&#21518;&#30340;&#33258;&#26432;&#26410;&#36930;&#39118;&#38505;&#12290;&#20102;&#35299;&#36825;&#20123;&#24739;&#32773;&#22312;&#21319;&#39640;&#30340;&#33258;&#26432;&#39118;&#38505;&#19979;&#30340;&#39118;&#38505;&#34892;&#20026;&#26159;&#23454;&#29616;&#8220;&#38646;&#33258;&#26432;&#8221;&#30340;&#30446;&#26631;&#30340;&#37325;&#35201;&#19968;&#27493;&#12290;&#19968;&#20010;&#21363;&#26102;&#19988;&#38750;&#24120;&#35268;&#30340;&#25361;&#25112;&#26159;&#65292;&#20174;&#21307;&#30103;&#32034;&#36180;&#20013;&#35782;&#21035;&#33258;&#26432;&#26410;&#36930;&#21253;&#21547;&#37325;&#22823;&#30340;&#19981;&#30830;&#23450;&#24615;&#65306;&#20960;&#20046;&#26377;20&#65285;&#30340;&#8220;&#30097;&#20284;&#8221;&#33258;&#26432;&#26410;&#36930;&#26159;&#20174;&#34920;&#26126;&#22806;&#37096;&#21407;&#22240;&#25152;&#33268;&#25439;&#20260;&#21644;&#20013;&#27602;&#30340;&#35786;&#26029;&#32534;&#30721;&#20013;&#30830;&#23450;&#30340;&#12290;&#22240;&#27492;&#65292;&#20102;&#35299;&#36825;&#20123;&#26410;&#30830;&#23450;&#20107;&#20214;&#20013;&#21738;&#20123;&#26356;&#26377;&#21487;&#33021;&#26159;&#23454;&#38469;&#30340;&#33258;&#26432;&#26410;&#36930;&#20107;&#20214;&#20197;&#21450;&#22914;&#20309;&#22312;&#20005;&#37325;&#30340;&#25130;&#23614;&#29983;&#23384;&#20998;&#26512;&#20013;&#27491;&#30830;&#22320;&#21033;&#29992;&#23427;&#20204;&#26159;&#38750;&#24120;&#26377;&#36259;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#30456;&#20851;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#20855;&#26377;&#27491;&#21017;&#21270;&#30340;&#32508;&#21512;Cox&#28120;&#27760;&#27169;&#22411;&#26469;&#25191;&#34892;&#29983;&#23384;&#22238;&#24402;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the pressing need for suicide prevention through improving behavioral healthcare, we use medical claims data to study the risk of subsequent suicide attempts for patients who were hospitalized due to suicide attempts and later discharged. Understanding the risk behaviors of such patients at elevated suicide risk is an important step toward the goal of "Zero Suicide." An immediate and unconventional challenge is that the identification of suicide attempts from medical claims contains substantial uncertainty: almost 20% of "suspected" suicide attempts are identified from diagnosis codes indicating external causes of injury and poisoning with undermined intent. It is thus of great interest to learn which of these undetermined events are more likely actual suicide attempts and how to properly utilize them in survival analysis with severe censoring. To tackle these interrelated problems, we develop an integrative Cox cure model with regularization to perform survival regression
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39034;&#24207;&#33945;&#29305;&#21345;&#32599;&#31639;&#27861;&#30340;&#36830;&#32493;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#39640;&#65292;&#38590;&#20197;&#22312;&#32447;&#39034;&#24207;&#26356;&#26032;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#20801;&#35768;&#25311;&#21512;&#20855;&#26377;&#38750;&#24179;&#31283;&#24615;&#36136;&#30340;&#20989;&#25968;&#12290;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/1905.10003</link><description>&lt;p&gt;
&#29992;&#20110;&#22312;&#32447;&#23398;&#20064;&#38750;&#24179;&#31283;&#20989;&#25968;&#30340;&#36830;&#32493;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Sequential Gaussian Processes for Online Learning of Nonstationary Functions. (arXiv:1905.10003v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1905.10003
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39034;&#24207;&#33945;&#29305;&#21345;&#32599;&#31639;&#27861;&#30340;&#36830;&#32493;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#39640;&#65292;&#38590;&#20197;&#22312;&#32447;&#39034;&#24207;&#26356;&#26032;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#20801;&#35768;&#25311;&#21512;&#20855;&#26377;&#38750;&#24179;&#31283;&#24615;&#36136;&#30340;&#20989;&#25968;&#12290;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#21487;&#20197;&#22312;&#20272;&#35745;&#20989;&#25968;&#30340;&#19978;&#19979;&#25991;&#20013;&#24471;&#21040;&#35299;&#20915;&#65292;&#36890;&#24120;&#36825;&#20123;&#20989;&#25968;&#26159;&#26102;&#38388;&#30456;&#20851;&#30340;&#20989;&#25968;&#65292;&#24182;&#19988;&#26159;&#23454;&#26102;&#22320;&#38543;&#30528;&#35266;&#27979;&#30340;&#21040;&#26469;&#32780;&#20272;&#35745;&#30340;&#12290;&#39640;&#26031;&#36807;&#31243;&#26159;&#24314;&#27169;&#23454;&#20540;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#19968;&#20010;&#26377;&#21560;&#24341;&#21147;&#30340;&#36873;&#25321;&#65292;&#30001;&#20110;&#20854;&#28789;&#27963;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#28982;&#32780;&#65292;&#20856;&#22411;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#27169;&#22411;&#23384;&#22312;&#33509;&#24178;&#19981;&#36275;&#65306;1&#65289;&#20256;&#32479;&#39640;&#26031;&#36807;&#31243;&#25512;&#26029;&#30340;&#22797;&#26434;&#24230;$O(N^{3})$&#38543;&#30528;&#35266;&#27979;&#20540;&#30340;&#20010;&#25968;N&#25104;&#22686;&#38271;&#65307;2&#65289;&#36880;&#27493;&#26356;&#26032;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#19981;&#23481;&#26131;&#65307;3&#65289;&#21327;&#26041;&#24046;&#26680;&#36890;&#24120;&#23545;&#20989;&#25968;&#26045;&#21152;&#24179;&#31283;&#24615;&#32422;&#26463;&#65292;&#32780;&#20855;&#26377;&#38750;&#24179;&#31283;&#21327;&#26041;&#24046;&#26680;&#30340;&#39640;&#26031;&#36807;&#31243;&#36890;&#24120;&#38590;&#20197;&#22312;&#23454;&#36341;&#20013;&#20351;&#29992;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#39034;&#24207;&#33945;&#29305;&#21345;&#32599;&#31639;&#27861;&#26469;&#25311;&#21512;&#26080;&#38480;&#28151;&#21512;&#39640;&#26031;&#36807;&#31243;&#65292;&#20197;&#25429;&#25417;&#38750;&#24179;&#31283;&#34892;&#20026;&#65292;&#21516;&#26102;&#20801;&#35768;&#22312;&#32447;&#12289;&#20998;&#24067;&#25512;&#26029;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23454;&#39564;&#20013;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many machine learning problems can be framed in the context of estimating functions, and often these are time-dependent functions that are estimated in real-time as observations arrive. Gaussian processes (GPs) are an attractive choice for modeling real-valued nonlinear functions due to their flexibility and uncertainty quantification. However, the typical GP regression model suffers from several drawbacks: 1) Conventional GP inference scales $O(N^{3})$ with respect to the number of observations; 2) Updating a GP model sequentially is not trivial; and 3) Covariance kernels typically enforce stationarity constraints on the function, while GPs with non-stationary covariance kernels are often intractable to use in practice. To overcome these issues, we propose a sequential Monte Carlo algorithm to fit infinite mixtures of GPs that capture non-stationary behavior while allowing for online, distributed inference. Our approach empirically improves performance over state-of-the-art methods fo
&lt;/p&gt;</description></item></channel></rss>