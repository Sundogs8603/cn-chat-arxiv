<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31574;&#30053;&#26799;&#24230;&#22312;&#32447;&#24615;&#20108;&#27425;&#35843;&#33410;&#25511;&#21046;&#20013;&#23545;&#26410;&#35265;&#21021;&#22987;&#29366;&#24577;&#30340;&#22806;&#25512;&#38382;&#39064;&#65292;&#21457;&#29616;&#22806;&#25512;&#31243;&#24230;&#21462;&#20915;&#20110;&#35757;&#32451;&#20013;&#31995;&#32479;&#30340;&#25506;&#32034;&#31243;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.07875</link><description>&lt;p&gt;
&#32447;&#24615;&#20108;&#27425;&#25511;&#21046;&#20013;&#31574;&#30053;&#26799;&#24230;&#30340;&#38544;&#24615;&#20559;&#24046;&#65306;&#23545;&#26410;&#35265;&#21021;&#22987;&#29366;&#24577;&#30340;&#22806;&#25512;
&lt;/p&gt;
&lt;p&gt;
Implicit Bias of Policy Gradient in Linear Quadratic Control: Extrapolation to Unseen Initial States
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07875
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31574;&#30053;&#26799;&#24230;&#22312;&#32447;&#24615;&#20108;&#27425;&#35843;&#33410;&#25511;&#21046;&#20013;&#23545;&#26410;&#35265;&#21021;&#22987;&#29366;&#24577;&#30340;&#22806;&#25512;&#38382;&#39064;&#65292;&#21457;&#29616;&#22806;&#25512;&#31243;&#24230;&#21462;&#20915;&#20110;&#35757;&#32451;&#20013;&#31995;&#32479;&#30340;&#25506;&#32034;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#27169;&#22411;&#21487;&#20197;&#20197;&#22810;&#31181;&#26041;&#24335;&#25311;&#21512;&#35757;&#32451;&#25968;&#25454;&#65292;&#20854;&#20013;&#19968;&#20123;&#22312;&#26410;&#35265;&#65288;&#27979;&#35797;&#65289;&#25968;&#25454;&#19978;&#34920;&#29616;&#33391;&#22909;&#65292;&#32780;&#20854;&#20182;&#19968;&#20123;&#21017;&#19981;&#28982;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26799;&#24230;&#19979;&#38477;&#32463;&#24120;&#23637;&#29616;&#20986;&#19968;&#31181;&#38544;&#24615;&#20559;&#24046;&#65292;&#23548;&#33268;&#22312;&#26410;&#35265;&#25968;&#25454;&#19978;&#34920;&#29616;&#20986;&#33394;&#12290;&#36825;&#31181;&#38544;&#24615;&#20559;&#24046;&#22312;&#30417;&#30563;&#23398;&#20064;&#20013;&#24050;&#32463;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#22312;&#26368;&#20248;&#25511;&#21046;&#65288;&#24378;&#21270;&#23398;&#20064;&#65289;&#20013;&#21364;&#20102;&#35299;&#24471;&#36739;&#23569;&#12290;&#22312;&#37027;&#37324;&#65292;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#24212;&#29992;&#20110;&#31995;&#32479;&#30340;&#25511;&#21046;&#22120;&#34987;&#31216;&#20026;&#31574;&#30053;&#26799;&#24230;&#65292;&#24182;&#19988;&#19968;&#20010;&#38750;&#24120;&#37325;&#35201;&#30340;&#38382;&#39064;&#26159;&#23398;&#20064;&#30340;&#25511;&#21046;&#22120;&#22312;&#23545;&#26410;&#35265;&#21021;&#22987;&#29366;&#24577;&#30340;&#22806;&#25512;&#31243;&#24230;&#12290;&#26412;&#25991;&#22312;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#31574;&#30053;&#26799;&#24230;&#22312;&#23545;&#26410;&#35265;&#21021;&#22987;&#29366;&#24577;&#30340;&#22806;&#25512;&#26041;&#38754;&#30340;&#38544;&#24615;&#20559;&#24046;&#12290;&#25105;&#20204;&#20197;&#22522;&#26412;&#30340;&#32447;&#24615;&#20108;&#27425;&#35843;&#33410;&#22120;&#65288;LQR&#65289;&#38382;&#39064;&#20026;&#37325;&#28857;&#65292;&#30830;&#31435;&#20102;&#22806;&#25512;&#31243;&#24230;&#21462;&#20915;&#20110;&#35757;&#32451;&#20013;&#31995;&#32479;&#22312;&#21021;&#22987;&#29366;&#24577;&#19979;&#24341;&#36215;&#30340;&#25506;&#32034;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
In modern machine learning, models can often fit training data in numerous ways, some of which perform well on unseen (test) data, while others do not. Remarkably, in such cases gradient descent frequently exhibits an implicit bias that leads to excellent performance on unseen data. This implicit bias was extensively studied in supervised learning, but is far less understood in optimal control (reinforcement learning). There, learning a controller applied to a system via gradient descent is known as policy gradient, and a question of prime importance is the extent to which a learned controller extrapolates to unseen initial states. This paper theoretically studies the implicit bias of policy gradient in terms of extrapolation to unseen initial states. Focusing on the fundamental Linear Quadratic Regulator (LQR) problem, we establish that the extent of extrapolation depends on the degree of exploration induced by the system when commencing from initial states included in training. Exper
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36830;&#32493;&#24402;&#19968;&#21270;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#36880;&#27493;&#20998;&#37197;&#31867;&#21035;&#65292;&#36991;&#20813;&#20102;&#31163;&#25955;&#21270;&#28508;&#22312;&#36830;&#32493;&#27169;&#22411;&#26102;&#30340;&#33293;&#20837;&#21644;&#26679;&#26412;&#25130;&#26029;&#31561;&#38382;&#39064;&#12290;&#36890;&#36807;&#21305;&#37197;&#20998;&#35299;&#31163;&#25955;&#20998;&#24067;&#30340;&#27979;&#22320;&#32447;&#27969;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35757;&#32451;&#35813;&#27169;&#22411;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#34920;&#31034;&#22797;&#26434;&#32479;&#35745;&#20381;&#36182;&#20851;&#31995;&#30340;&#38750;&#20998;&#35299;&#31163;&#25955;&#20998;&#24067;&#12290;</title><link>https://arxiv.org/abs/2402.07846</link><description>&lt;p&gt;
&#21033;&#29992;&#22312;&#36171;&#20540;&#27969;&#24418;&#19978;&#30340;E-&#27979;&#22320;&#32447;&#27969;&#21305;&#37197;&#29983;&#25104;&#31163;&#25955;&#32852;&#21512;&#20998;&#24067;&#30340;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Generative Modeling of Discrete Joint Distributions by E-Geodesic Flow Matching on Assignment Manifolds
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07846
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36830;&#32493;&#24402;&#19968;&#21270;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#36880;&#27493;&#20998;&#37197;&#31867;&#21035;&#65292;&#36991;&#20813;&#20102;&#31163;&#25955;&#21270;&#28508;&#22312;&#36830;&#32493;&#27169;&#22411;&#26102;&#30340;&#33293;&#20837;&#21644;&#26679;&#26412;&#25130;&#26029;&#31561;&#38382;&#39064;&#12290;&#36890;&#36807;&#21305;&#37197;&#20998;&#35299;&#31163;&#25955;&#20998;&#24067;&#30340;&#27979;&#22320;&#32447;&#27969;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35757;&#32451;&#35813;&#27169;&#22411;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#34920;&#31034;&#22797;&#26434;&#32479;&#35745;&#20381;&#36182;&#20851;&#31995;&#30340;&#38750;&#20998;&#35299;&#31163;&#25955;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#36830;&#32493;&#24402;&#19968;&#21270;&#27969;&#22312;&#20998;&#35299;&#31163;&#25955;&#24230;&#37327;&#23376;&#27969;&#24418;&#19978;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#36880;&#27493;&#23545;&#31867;&#21035;&#36827;&#34892;&#20998;&#37197;&#65292;&#36991;&#20813;&#20102;&#31163;&#25955;&#21270;&#28508;&#22312;&#36830;&#32493;&#27169;&#22411;&#26102;&#30340;&#33293;&#20837;&#12289;&#26679;&#26412;&#25130;&#26029;&#31561;&#38382;&#39064;&#12290;&#23558;&#23376;&#27969;&#24418;&#23884;&#20837;&#21040;&#25152;&#26377;&#32852;&#21512;&#31163;&#25955;&#20998;&#24067;&#21644;&#25968;&#25454;&#39537;&#21160;&#24179;&#22343;&#30340;&#20803;&#21333;&#32431;&#24418;&#20013;&#65292;&#21487;&#20197;&#36817;&#20284;&#34920;&#31034;&#33021;&#22815;&#34920;&#31034;&#32467;&#26500;&#21270;&#31163;&#25955;&#25968;&#25454;&#30340;&#22797;&#26434;&#32479;&#35745;&#20381;&#36182;&#20851;&#31995;&#30340;&#19968;&#33324;&#38750;&#20998;&#35299;&#31163;&#25955;&#20998;&#24067;&#12290;&#36890;&#36807;&#21305;&#37197;&#20998;&#35299;&#31163;&#25955;&#20998;&#24067;&#30340;&#27979;&#22320;&#32447;&#27969;&#65292;&#28436;&#31034;&#20102;&#35813;&#29983;&#25104;&#27169;&#22411;&#30340;&#39640;&#25928;&#35757;&#32451;&#12290;&#21508;&#31181;&#23454;&#39564;&#31361;&#20986;&#20102;&#35813;&#26041;&#27861;&#30340;&#24191;&#27867;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a novel generative model for discrete distributions based on continuous normalizing flows on the submanifold of factorizing discrete measures. Integration of the flow gradually assigns categories and avoids issues of discretizing the latent continuous model like rounding, sample truncation etc. General non-factorizing discrete distributions capable of representing complex statistical dependencies of structured discrete data, can be approximated by embedding the submanifold into a the meta-simplex of all joint discrete distributions and data-driven averaging. Efficient training of the generative model is demonstrated by matching the flow of geodesics of factorizing discrete distributions. Various experiments underline the approach's broad applicability.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22810;&#31867;&#21035;&#39044;&#27979;&#38382;&#39064;&#20013;&#22810;&#26679;&#21270;&#30340;&#25237;&#24433;&#24179;&#28369;&#26657;&#20934;&#27010;&#24565;&#65292;&#24182;&#19988;&#32473;&#20986;&#20102;&#22810;&#39033;&#24335;&#26102;&#38388;&#22797;&#26434;&#24230;&#30340;&#37325;&#26032;&#26657;&#20934;&#31639;&#27861;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#35745;&#31639;&#25928;&#29575;&#21644;&#24378;&#22823;&#30340;&#39044;&#27979;&#20445;&#35777;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;</title><link>https://arxiv.org/abs/2402.07821</link><description>&lt;p&gt;
&#35770;&#35745;&#31639;&#26377;&#25928;&#30340;&#22810;&#31867;&#21035;&#26657;&#20934;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
On Computationally Efficient Multi-Class Calibration
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07821
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22810;&#31867;&#21035;&#39044;&#27979;&#38382;&#39064;&#20013;&#22810;&#26679;&#21270;&#30340;&#25237;&#24433;&#24179;&#28369;&#26657;&#20934;&#27010;&#24565;&#65292;&#24182;&#19988;&#32473;&#20986;&#20102;&#22810;&#39033;&#24335;&#26102;&#38388;&#22797;&#26434;&#24230;&#30340;&#37325;&#26032;&#26657;&#20934;&#31639;&#27861;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#35745;&#31639;&#25928;&#29575;&#21644;&#24378;&#22823;&#30340;&#39044;&#27979;&#20445;&#35777;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32771;&#34385;&#19968;&#20010;&#22810;&#31867;&#21035;&#26631;&#35760;&#38382;&#39064;&#65292;&#20854;&#20013;&#26631;&#35760;&#21487;&#20197;&#22312;[1,k]&#33539;&#22260;&#20869;&#21462;&#20540;&#65292;&#32780;&#39044;&#27979;&#22120;&#39044;&#27979;&#30340;&#26159;&#26631;&#35760;&#30340;&#20998;&#24067;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20197;&#19979;&#22522;&#30784;&#38382;&#39064;&#65306;&#26159;&#21542;&#23384;&#22312;&#22810;&#31867;&#21035;&#26657;&#20934;&#30340;&#27010;&#24565;&#65292;&#21487;&#20197;&#32473;&#20986;&#23545;&#26377;&#24847;&#20041;&#30340;&#39044;&#27979;&#30340;&#24378;&#22823;&#20445;&#35777;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#19979;&#23454;&#29616;&#65311;&#20808;&#21069;&#30340;&#26657;&#20934;&#27010;&#24565;&#22312;&#35745;&#31639;&#25928;&#29575;&#21644;&#34920;&#36798;&#33021;&#21147;&#20043;&#38388;&#23384;&#22312;&#30528;&#26435;&#34913;&#65306;&#23427;&#20204;&#35201;&#20040;&#22312;k&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#19978;&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#65292;&#35201;&#20040;&#38656;&#35201;&#27714;&#35299;&#35745;&#31639;&#38590;&#39064;&#65292;&#35201;&#20040;&#32473;&#20986;&#30340;&#20445;&#35777;&#30456;&#24403;&#24369;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#23454;&#29616;&#25152;&#26377;&#36825;&#20123;&#26399;&#26395;&#30340;&#26657;&#20934;&#27010;&#24565;&#65306;&#25105;&#20204;&#22312;&#22810;&#31867;&#21035;&#39044;&#27979;&#20013;&#21046;&#23450;&#20102;&#19968;&#20010;&#31283;&#20581;&#30340;&#25237;&#24433;&#24179;&#28369;&#26657;&#20934;&#27010;&#24565;&#65292;&#24182;&#32473;&#20986;&#20102;&#26032;&#30340;&#37325;&#26032;&#26657;&#20934;&#31639;&#27861;&#65292;&#20197;&#22312;&#36825;&#20010;&#23450;&#20041;&#19979;&#20197;&#22810;&#39033;&#24335;&#26102;&#38388;&#22797;&#26434;&#24230;&#26657;&#20934;&#39044;&#27979;&#22120;&#12290;&#25237;&#24433;&#24179;&#28369;&#26657;&#20934;&#20026;&#22810;&#31867;&#21035;&#39044;&#27979;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consider a multi-class labelling problem, where the labels can take values in $[k]$, and a predictor predicts a distribution over the labels. In this work, we study the following foundational question: Are there notions of multi-class calibration that give strong guarantees of meaningful predictions and can be achieved in time and sample complexities polynomial in $k$? Prior notions of calibration exhibit a tradeoff between computational efficiency and expressivity: they either suffer from having sample complexity exponential in $k$, or needing to solve computationally intractable problems, or give rather weak guarantees.   Our main contribution is a notion of calibration that achieves all these desiderata: we formulate a robust notion of projected smooth calibration for multi-class predictions, and give new recalibration algorithms for efficiently calibrating predictors under this definition with complexity polynomial in $k$. Projected smooth calibration gives strong guarantees for al
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#38754;&#21521;&#25193;&#25955;&#27169;&#22411;&#20013;&#19968;&#33268;&#24615;&#35757;&#32451;&#30340;&#29702;&#35770;&#22522;&#30784;&#65292;&#35777;&#26126;&#20102;&#22312;&#19968;&#33268;&#24615;&#23398;&#20064;&#20013;&#65292;&#27493;&#39588;&#25968;&#37327;&#38656;&#35201;&#36229;&#36807;$d^{5/2}/\varepsilon$&#30340;&#38454;&#25968;&#65292;&#33021;&#22815;&#29983;&#25104;&#19982;&#30446;&#26631;&#20998;&#24067;&#25509;&#36817;&#30340;&#26679;&#26412;&#12290;</title><link>https://arxiv.org/abs/2402.07802</link><description>&lt;p&gt;
&#38754;&#21521;&#25193;&#25955;&#27169;&#22411;&#30340;&#19968;&#31181;&#19968;&#33268;&#24615;&#35757;&#32451;&#25968;&#23398;&#29702;&#35770;&#30340;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Towards a mathematical theory for consistency training in diffusion models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07802
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#38754;&#21521;&#25193;&#25955;&#27169;&#22411;&#20013;&#19968;&#33268;&#24615;&#35757;&#32451;&#30340;&#29702;&#35770;&#22522;&#30784;&#65292;&#35777;&#26126;&#20102;&#22312;&#19968;&#33268;&#24615;&#23398;&#20064;&#20013;&#65292;&#27493;&#39588;&#25968;&#37327;&#38656;&#35201;&#36229;&#36807;$d^{5/2}/\varepsilon$&#30340;&#38454;&#25968;&#65292;&#33021;&#22815;&#29983;&#25104;&#19982;&#30446;&#26631;&#20998;&#24067;&#25509;&#36817;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#33268;&#24615;&#27169;&#22411;&#34987;&#25552;&#20986;&#26469;&#20943;&#23569;&#25193;&#25955;&#27169;&#22411;&#37319;&#26679;&#38454;&#27573;&#30340;&#39640;&#35745;&#31639;&#24320;&#38144;&#65292;&#23454;&#29616;&#20102;&#21333;&#27493;&#37319;&#26679;&#24182;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#23454;&#35777;&#24615;&#33021;&#12290;&#19968;&#33268;&#24615;&#27169;&#22411;&#22312;&#35757;&#32451;&#38454;&#27573;&#34987;&#25972;&#21512;&#36827;&#26469;&#65292;&#35797;&#22270;&#35757;&#32451;&#19968;&#31995;&#21015;&#30340;&#19968;&#33268;&#24615;&#20989;&#25968;&#65292;&#33021;&#22815;&#23558;&#25193;&#25955;&#36807;&#31243;&#20013;&#30340;&#20219;&#20309;&#26102;&#38388;&#27493;&#39588;&#30340;&#20219;&#20309;&#28857;&#26144;&#23556;&#22238;&#20854;&#36215;&#22987;&#28857;&#12290;&#23613;&#31649;&#22312;&#23454;&#35777;&#19978;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#20851;&#20110;&#19968;&#33268;&#24615;&#35757;&#32451;&#30340;&#20840;&#38754;&#29702;&#35770;&#29702;&#35299;&#36824;&#26159;&#24456;&#38590;&#24471;&#21040;&#30340;&#12290;&#26412;&#25991;&#23545;&#19968;&#33268;&#24615;&#27169;&#22411;&#30340;&#29702;&#35770;&#22522;&#30784;&#36827;&#34892;&#20102;&#21021;&#27493;&#30340;&#25506;&#32034;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#20026;&#20102;&#22312;&#20998;&#24067;&#20013;&#29983;&#25104;&#19982;&#30446;&#26631;&#22312;$\varepsilon$&#25509;&#36817;&#30340;&#26679;&#26412;&#65288;&#36890;&#36807;&#26576;&#31181;Wasserstein&#24230;&#37327;&#34913;&#37327;&#65289;&#65292;&#19968;&#33268;&#24615;&#23398;&#20064;&#20013;&#30340;&#27493;&#39588;&#25968;&#37327;&#38656;&#35201;&#36229;&#36807;$d^{5/2}/\varepsilon$&#30340;&#38454;&#25968;&#65292;&#20854;&#20013;$d$&#26159;&#25968;&#25454;&#32500;&#24230;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20026;&#19968;&#33268;&#24615;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#21644;&#26377;&#25928;&#24615;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#27934;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consistency models, which were proposed to mitigate the high computational overhead during the sampling phase of diffusion models, facilitate single-step sampling while attaining state-of-the-art empirical performance. When integrated into the training phase, consistency models attempt to train a sequence of consistency functions capable of mapping any point at any time step of the diffusion process to its starting point. Despite the empirical success, a comprehensive theoretical understanding of consistency training remains elusive. This paper takes a first step towards establishing theoretical underpinnings for consistency models. We demonstrate that, in order to generate samples within $\varepsilon$ proximity to the target in distribution (measured by some Wasserstein metric), it suffices for the number of steps in consistency learning to exceed the order of $d^{5/2}/\varepsilon$, with $d$ the data dimension. Our theory offers rigorous insights into the validity and efficacy of cons
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#35843;&#21442;&#30340;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#21482;&#32473;&#20986;&#38382;&#39064;&#21442;&#25968;&#30340;&#31895;&#30053;&#25552;&#31034;&#30340;&#24773;&#20917;&#19979;&#65292;&#19982;&#26368;&#20248;&#35843;&#21442;&#20248;&#21270;&#31639;&#27861;&#30340;&#24615;&#33021;&#30456;&#21305;&#37197;&#12290;&#24182;&#19988;&#22312;&#26377;&#30028;&#30340;&#20248;&#21270;&#39046;&#22495;&#20013;&#35777;&#26126;&#20102;&#27492;&#31639;&#27861;&#30340;&#21487;&#34892;&#24615;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#26080;&#30028;&#22495;&#20013;&#30340;&#26465;&#20214;&#12290;</title><link>https://arxiv.org/abs/2402.07793</link><description>&lt;p&gt;
&#26080;&#35843;&#21442;&#30340;&#38543;&#26426;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Tuning-Free Stochastic Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07793
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#35843;&#21442;&#30340;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#21482;&#32473;&#20986;&#38382;&#39064;&#21442;&#25968;&#30340;&#31895;&#30053;&#25552;&#31034;&#30340;&#24773;&#20917;&#19979;&#65292;&#19982;&#26368;&#20248;&#35843;&#21442;&#20248;&#21270;&#31639;&#27861;&#30340;&#24615;&#33021;&#30456;&#21305;&#37197;&#12290;&#24182;&#19988;&#22312;&#26377;&#30028;&#30340;&#20248;&#21270;&#39046;&#22495;&#20013;&#35777;&#26126;&#20102;&#27492;&#31639;&#27861;&#30340;&#21487;&#34892;&#24615;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#26080;&#30028;&#22495;&#20013;&#30340;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20351;&#24471;&#35843;&#21442;&#30340;&#25104;&#26412;&#36234;&#26469;&#36234;&#39640;&#26114;&#12290;&#36825;&#23548;&#33268;&#20102;&#38656;&#35201;&#33021;&#22815;&#21363;&#26102;&#33258;&#25105;&#35843;&#25972;&#30340;&#31639;&#27861;&#30340;&#38656;&#27714;&#12290;&#25105;&#20204;&#23558;&#8220;&#26080;&#35843;&#21442;&#8221;&#31639;&#27861;&#30340;&#27010;&#24565;&#24418;&#24335;&#21270;&#65292;&#21363;&#21482;&#32473;&#20986;&#38382;&#39064;&#21442;&#25968;&#30340;&#31895;&#30053;&#25552;&#31034;&#21363;&#21487;&#19982;&#26368;&#20248;&#35843;&#21442;&#20248;&#21270;&#31639;&#27861;&#30340;&#24615;&#33021;&#30456;&#21305;&#37197;&#65292;&#35823;&#24046;&#20026;&#23545;&#25968;&#22810;&#39033;&#24335;&#22240;&#23376;&#12290;&#25105;&#20204;&#29305;&#21035;&#32771;&#34385;&#33021;&#22815;&#19982;&#26368;&#20248;&#35843;&#21442;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;(SGD)&#30456;&#21305;&#37197;&#30340;&#31639;&#27861;&#12290;&#24403;&#20248;&#21270;&#30340;&#22495;&#26159;&#26377;&#30028;&#30340;&#26102;&#20505;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35843;&#21442;&#33258;&#30001;&#19982;SGD&#30340;&#21305;&#37197;&#26159;&#21487;&#33021;&#30340;&#65292;&#24182;&#19988;&#36890;&#36807;&#20960;&#20010;&#29616;&#26377;&#31639;&#27861;&#23454;&#29616;&#20102;&#36825;&#19968;&#28857;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#20248;&#21270;&#30340;&#22495;&#26159;&#26080;&#30028;&#30340;&#26102;&#20505;&#65292;&#23545;&#20110;&#26368;&#23567;&#21270;&#20984;&#24179;&#28369;&#25110;&#32773;Lipschitz&#20989;&#25968;&#30340;&#20219;&#21153;&#65292;&#26080;&#35843;&#21442;&#20248;&#21270;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#22312;&#26080;&#30028;&#22495;&#20013;&#65292;&#20309;&#31181;&#24773;&#20917;&#19979;&#21487;&#20197;&#23454;&#29616;&#26080;&#35843;&#21442;&#20248;&#21270;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26368;&#36817;&#25552;&#20986;&#30340; DoG &#21644; DoWG &#31639;&#27861;&#22312;&#22122;&#22768;&#20998;&#24067;&#36275;&#22815;&#26102;&#26159;&#26080;&#35843;&#21442;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large-scale machine learning problems make the cost of hyperparameter tuning ever more prohibitive. This creates a need for algorithms that can tune themselves on-the-fly. We formalize the notion of "tuning-free" algorithms that can match the performance of optimally-tuned optimization algorithms up to polylogarithmic factors given only loose hints on the relevant problem parameters. We consider in particular algorithms that can match optimally-tuned Stochastic Gradient Descent (SGD). When the domain of optimization is bounded, we show tuning-free matching of SGD is possible and achieved by several existing algorithms. We prove that for the task of minimizing a convex and smooth or Lipschitz function over an unbounded domain, tuning-free optimization is impossible. We discuss conditions under which tuning-free optimization is possible even over unbounded domains. In particular, we show that the recently proposed DoG and DoWG algorithms are tuning-free when the noise distribution is suf
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#28151;&#21512;&#31639;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#29305;&#23450;&#32972;&#26223;&#27169;&#22411;&#65292;&#36890;&#36807;&#32467;&#21512;&#22522;&#20110;&#39034;&#24207;&#30340;MCMC&#31639;&#27861;&#21644;&#31232;&#30095;&#24615;&#20551;&#35774;&#23454;&#29616;&#21487;&#25193;&#23637;&#23398;&#20064;&#65292;&#35813;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>https://arxiv.org/abs/2402.07762</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;&#31232;&#30095;&#29305;&#23450;&#32972;&#26223;&#19979;&#22240;&#26524;&#31995;&#32479;&#30340;&#32467;&#26500;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Scalable Structure Learning for Sparse Context-Specific Causal Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07762
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#28151;&#21512;&#31639;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#29305;&#23450;&#32972;&#26223;&#27169;&#22411;&#65292;&#36890;&#36807;&#32467;&#21512;&#22522;&#20110;&#39034;&#24207;&#30340;MCMC&#31639;&#27861;&#21644;&#31232;&#30095;&#24615;&#20551;&#35774;&#23454;&#29616;&#21487;&#25193;&#23637;&#23398;&#20064;&#65292;&#35813;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24050;&#32463;&#25552;&#20986;&#20102;&#20960;&#31181;&#34920;&#31034;&#20849;&#21516;&#20998;&#24067;&#20998;&#31867;&#21464;&#37327;&#20043;&#38388;&#29305;&#23450;&#32972;&#26223;&#19979;&#20851;&#31995;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#25552;&#20986;&#20102;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#22823;&#37327;&#29305;&#23450;&#32972;&#26223;&#27169;&#22411;&#30340;&#23384;&#22312;&#65292;&#29616;&#26377;&#30340;&#22522;&#20110;&#20248;&#21270;&#30340;&#26041;&#27861;&#22312;&#21487;&#25193;&#23637;&#24615;&#26041;&#38754;&#21463;&#21040;&#38480;&#21046;&#65292;&#32780;&#22522;&#20110;&#32422;&#26463;&#30340;&#26041;&#27861;&#27604;&#32422;&#26463;DAG&#23398;&#20064;&#31639;&#27861;&#26356;&#23481;&#26131;&#20986;&#38169;&#65292;&#22240;&#20026;&#24517;&#39035;&#27979;&#35797;&#26356;&#22810;&#20851;&#31995;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#31639;&#27861;&#26469;&#23398;&#20064;&#29305;&#23450;&#32972;&#26223;&#27169;&#22411;&#65292;&#33021;&#22815;&#25193;&#23637;&#21040;&#25968;&#30334;&#20010;&#21464;&#37327;&#65292;&#24182;&#19988;&#27979;&#35797;&#30340;&#32422;&#26463;&#19981;&#22810;&#20110;&#26631;&#20934;DAG&#23398;&#20064;&#31639;&#27861;&#12290;&#36890;&#36807;&#32467;&#21512;&#22522;&#20110;&#39034;&#24207;&#30340;MCMC&#31639;&#27861;&#21644;&#31867;&#20284;&#20110;DAG&#27169;&#22411;&#24120;&#29992;&#30340;&#31232;&#30095;&#24615;&#20551;&#35774;&#65292;&#23454;&#29616;&#20102;&#21487;&#25193;&#23637;&#30340;&#23398;&#20064;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#31181;&#26041;&#27861;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;Alon&#21644;Balogh&#26368;&#36817;&#25552;&#20986;&#30340;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#30340;&#29305;&#27530;&#24773;&#20917;&#12290;&#32463;&#36807;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#30495;&#23454;&#19990;&#30028;&#31034;&#20363;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several approaches to graphically representing context-specific relations among jointly distributed categorical variables have been proposed, along with structure learning algorithms. While existing optimization-based methods have limited scalability due to the large number of context-specific models, the constraint-based methods are more prone to error than even constraint-based DAG learning algorithms since more relations must be tested. We present a hybrid algorithm for learning context-specific models that scales to hundreds of variables while testing no more constraints than standard DAG learning algorithms. Scalable learning is achieved through a combination of an order-based MCMC algorithm and sparsity assumptions analogous to those typically invoked for DAG models. To implement the method, we solve a special case of an open problem recently posed by Alon and Balogh. The method is shown to perform well on synthetic data and real world examples, in terms of both accuracy and scal
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#32463;&#39564;&#36125;&#21494;&#26031;&#24179;&#28369;&#22312;&#39640;&#32500;&#25968;&#25454;&#20013;&#20272;&#35745;&#26410;&#30693;&#27010;&#29575;&#20998;&#24067;&#30340;&#20998;&#25968;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#26680;&#30340;&#27491;&#21017;&#21270;&#20998;&#25968;&#20272;&#35745;&#22120;&#65292;&#22312;score matching&#25439;&#22833;&#20989;&#25968;&#19979;&#36798;&#21040;&#20102;&#26368;&#20248;&#36895;&#29575;&#65292;&#24182;&#25581;&#31034;&#20102;&#32500;&#24230;&#22686;&#38271;&#23545;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#25351;&#25968;&#32423;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.07747</link><description>&lt;p&gt;
&#36890;&#36807;&#32463;&#39564;&#36125;&#21494;&#26031;&#24179;&#28369;&#36827;&#34892;&#26368;&#20248;&#20998;&#25968;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Optimal score estimation via empirical Bayes smoothing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07747
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#32463;&#39564;&#36125;&#21494;&#26031;&#24179;&#28369;&#22312;&#39640;&#32500;&#25968;&#25454;&#20013;&#20272;&#35745;&#26410;&#30693;&#27010;&#29575;&#20998;&#24067;&#30340;&#20998;&#25968;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#26680;&#30340;&#27491;&#21017;&#21270;&#20998;&#25968;&#20272;&#35745;&#22120;&#65292;&#22312;score matching&#25439;&#22833;&#20989;&#25968;&#19979;&#36798;&#21040;&#20102;&#26368;&#20248;&#36895;&#29575;&#65292;&#24182;&#25581;&#31034;&#20102;&#32500;&#24230;&#22686;&#38271;&#23545;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#25351;&#25968;&#32423;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20174;$d$&#32500;&#29420;&#31435;&#21516;&#20998;&#24067;&#35266;&#27979;&#20013;&#20272;&#35745;&#26410;&#30693;&#27010;&#29575;&#20998;&#24067;$\rho^*$&#30340;&#20998;&#25968;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#22312;&#20551;&#35774;$\rho^*$&#26159;&#20122;&#39640;&#26031;&#30340;&#24182;&#19988;&#20855;&#26377;Lipschitz&#36830;&#32493;&#30340;&#20998;&#25968;&#20989;&#25968;$s^*$&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#22312;score matching&#25991;&#29486;&#20013;&#24120;&#29992;&#30340;&#25439;&#22833;&#20989;&#25968;$\|\hat s - s^*\|^2_{L^2(\rho^*)}$&#19979;&#24314;&#31435;&#20102;&#35813;&#20272;&#35745;&#38382;&#39064;&#30340;&#26368;&#20248;&#36895;&#29575;&#20026;$\tilde \Theta(n^{-\frac{2}{d+4}})$&#65292;&#24378;&#35843;&#20102;&#32500;&#24230;$d$&#30340;&#22686;&#38271;&#23545;&#20110;&#20934;&#30830;&#20998;&#25968;&#20272;&#35745;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#30340;&#22256;&#22659;&#12290;&#20511;&#21161;&#32463;&#39564;&#36125;&#21494;&#26031;&#29702;&#35770;&#30340;&#20851;&#38190;&#35265;&#35299;&#20197;&#21450;&#24179;&#28369;&#32463;&#39564;&#20998;&#24067;&#22312;Hellinger&#36317;&#31163;&#19979;&#30340;&#26032;&#25910;&#25947;&#36895;&#29575;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22522;&#20110;&#39640;&#26031;&#26680;&#30340;&#27491;&#21017;&#21270;&#20998;&#25968;&#20272;&#35745;&#22120;&#33021;&#22815;&#36798;&#21040;&#35813;&#36895;&#29575;&#65292;&#24182;&#36890;&#36807;&#21305;&#37197;&#26368;&#23567;&#20540;&#19979;&#30028;&#35777;&#26126;&#20102;&#20854;&#26368;&#20248;&#24615;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#25105;&#20204;&#29702;&#35770;&#23545;&#20110;&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of estimating the score function of an unknown probability distribution $\rho^*$ from $n$ independent and identically distributed observations in $d$ dimensions. Assuming that $\rho^*$ is subgaussian and has a Lipschitz-continuous score function $s^*$, we establish the optimal rate of $\tilde \Theta(n^{-\frac{2}{d+4}})$ for this estimation problem under the loss function $\|\hat s - s^*\|^2_{L^2(\rho^*)}$ that is commonly used in the score matching literature, highlighting the curse of dimensionality where sample complexity for accurate score estimation grows exponentially with the dimension $d$. Leveraging key insights in empirical Bayes theory as well as a new convergence rate of smoothed empirical distribution in Hellinger distance, we show that a regularized score estimator based on a Gaussian kernel attains this rate, shown optimal by a matching minimax lower bound. We also discuss the implication of our theory on the sample complexity of score-based generativ
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;BAM&#36827;&#34892;&#22270;&#32467;&#26500;&#25512;&#26029;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#36890;&#36807;&#21464;&#24418;&#30340;&#32806;&#21512;&#27169;&#25311;&#36755;&#20837;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#65292;&#20165;&#38656;&#36890;&#36807;&#19968;&#27425;&#21069;&#21521;&#20256;&#36882;&#21363;&#21487;&#36827;&#34892;&#25512;&#26029;&#12290;&#36890;&#36807;&#21033;&#29992;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#21644;&#38543;&#26426;&#29983;&#25104;&#30340;&#22810;&#21464;&#37327;&#20999;&#27604;&#38634;&#22827;&#22810;&#39033;&#24335;&#26469;&#27169;&#25311;&#35757;&#32451;&#25968;&#25454;&#65292;&#26041;&#27861;&#33021;&#22815;&#27867;&#21270;&#21040;&#32447;&#24615;&#21644;&#21508;&#31181;&#38750;&#32447;&#24615;&#20381;&#36182;&#20851;&#31995;&#12290;&#24341;&#20837;&#20102;&#21452;&#32447;&#24615;&#27880;&#24847;&#26426;&#21046;&#65288;BAM&#65289;&#26469;&#22788;&#29702;&#20381;&#36182;&#20851;&#31995;&#65292;&#35813;&#26426;&#21046;&#22312;&#36716;&#25442;&#25968;&#25454;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#27700;&#24179;&#19978;&#36816;&#34892;&#65292;&#24182;&#23562;&#37325;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#27969;&#24418;&#30340;&#20960;&#20309;&#29305;&#24615;&#12290;&#23454;&#35777;&#35780;&#20272;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.07735</link><description>&lt;p&gt;
&#29992;BAM&#36827;&#34892;&#22270;&#32467;&#26500;&#25512;&#26029;&#65306;&#24341;&#20837;&#21452;&#32447;&#24615;&#27880;&#24847;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Graph Structure Inference with BAM: Introducing the Bilinear Attention Mechanism
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07735
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;BAM&#36827;&#34892;&#22270;&#32467;&#26500;&#25512;&#26029;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#36890;&#36807;&#21464;&#24418;&#30340;&#32806;&#21512;&#27169;&#25311;&#36755;&#20837;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#65292;&#20165;&#38656;&#36890;&#36807;&#19968;&#27425;&#21069;&#21521;&#20256;&#36882;&#21363;&#21487;&#36827;&#34892;&#25512;&#26029;&#12290;&#36890;&#36807;&#21033;&#29992;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#21644;&#38543;&#26426;&#29983;&#25104;&#30340;&#22810;&#21464;&#37327;&#20999;&#27604;&#38634;&#22827;&#22810;&#39033;&#24335;&#26469;&#27169;&#25311;&#35757;&#32451;&#25968;&#25454;&#65292;&#26041;&#27861;&#33021;&#22815;&#27867;&#21270;&#21040;&#32447;&#24615;&#21644;&#21508;&#31181;&#38750;&#32447;&#24615;&#20381;&#36182;&#20851;&#31995;&#12290;&#24341;&#20837;&#20102;&#21452;&#32447;&#24615;&#27880;&#24847;&#26426;&#21046;&#65288;BAM&#65289;&#26469;&#22788;&#29702;&#20381;&#36182;&#20851;&#31995;&#65292;&#35813;&#26426;&#21046;&#22312;&#36716;&#25442;&#25968;&#25454;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#27700;&#24179;&#19978;&#36816;&#34892;&#65292;&#24182;&#23562;&#37325;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#27969;&#24418;&#30340;&#20960;&#20309;&#29305;&#24615;&#12290;&#23454;&#35777;&#35780;&#20272;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#26816;&#27979;&#25968;&#25454;&#38598;&#20013;&#30340;&#20381;&#36182;&#20851;&#31995;&#26159;&#19968;&#20010;&#26680;&#24515;&#25361;&#25112;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#29992;&#20110;&#30417;&#30563;&#22270;&#32467;&#26500;&#23398;&#20064;&#65292;&#21363;&#23398;&#20064;&#35266;&#27979;&#25968;&#25454;&#21644;&#23427;&#20204;&#30340;&#22522;&#26412;&#20381;&#36182;&#32467;&#26500;&#20043;&#38388;&#30340;&#26144;&#23556;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#21464;&#24418;&#30340;&#32806;&#21512;&#27169;&#25311;&#36755;&#20837;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#65292;&#24182;&#19988;&#20165;&#38656;&#36890;&#36807;&#35757;&#32451;&#32593;&#32476;&#36827;&#34892;&#19968;&#27425;&#21069;&#21521;&#20256;&#36882;&#21363;&#21487;&#36827;&#34892;&#25512;&#26029;&#12290;&#36890;&#36807;&#21033;&#29992;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#38543;&#26426;&#29983;&#25104;&#30340;&#22810;&#21464;&#37327;&#20999;&#27604;&#38634;&#22827;&#22810;&#39033;&#24335;&#26469;&#27169;&#25311;&#35757;&#32451;&#25968;&#25454;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23637;&#31034;&#20102;&#22312;&#32447;&#24615;&#21644;&#21508;&#31181;&#38750;&#32447;&#24615;&#20381;&#36182;&#20851;&#31995;&#20043;&#38388;&#30340;&#24378;&#22823;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#21452;&#32447;&#24615;&#27880;&#24847;&#26426;&#21046;&#65288;BAM&#65289;&#65292;&#29992;&#20110;&#26174;&#24335;&#22788;&#29702;&#20381;&#36182;&#20449;&#24687;&#65292;&#35813;&#26426;&#21046;&#22312;&#36716;&#25442;&#25968;&#25454;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#27700;&#24179;&#19978;&#36816;&#34892;&#65292;&#24182;&#23562;&#37325;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#27969;&#24418;&#30340;&#20960;&#20309;&#29305;&#24615;&#12290;&#23454;&#35777;&#35780;&#20272;&#23637;&#31034;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In statistics and machine learning, detecting dependencies in datasets is a central challenge. We propose a novel neural network model for supervised graph structure learning, i.e., the process of learning a mapping between observational data and their underlying dependence structure. The model is trained with variably shaped and coupled simulated input data and requires only a single forward pass through the trained network for inference. By leveraging structural equation models and employing randomly generated multivariate Chebyshev polynomials for the simulation of training data, our method demonstrates robust generalizability across both linear and various types of non-linear dependencies. We introduce a novel bilinear attention mechanism (BAM) for explicit processing of dependency information, which operates on the level of covariance matrices of transformed data and respects the geometry of the manifold of symmetric positive definite matrices. Empirical evaluation demonstrates th
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#20998;&#25968;&#38459;&#23612;&#24211;&#20177;&#26041;&#31243;&#35777;&#26126;&#20102;&#37325;&#23614;SDE&#30340;&#39640;&#27010;&#29575;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#19988;&#30456;&#23545;&#20110;&#21442;&#25968;&#32500;&#24230;&#65292;&#30028;&#38480;&#30340;&#20381;&#36182;&#24615;&#35201;&#22909;&#20110;p&#12290;</title><link>https://arxiv.org/abs/2402.07723</link><description>&lt;p&gt;
&#36890;&#36807;&#20998;&#25968;&#38459;&#23612;&#24211;&#20177;&#26041;&#31243;&#35777;&#26126;&#37325;&#23614;SDEs&#30340;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Generalization Bounds for Heavy-Tailed SDEs through the Fractional Fokker-Planck Equation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07723
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#20998;&#25968;&#38459;&#23612;&#24211;&#20177;&#26041;&#31243;&#35777;&#26126;&#20102;&#37325;&#23614;SDE&#30340;&#39640;&#27010;&#29575;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#19988;&#30456;&#23545;&#20110;&#21442;&#25968;&#32500;&#24230;&#65292;&#30028;&#38480;&#30340;&#20381;&#36182;&#24615;&#35201;&#22909;&#20110;p&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21435;&#20960;&#24180;&#26469;&#65292;&#29702;&#35299;&#37325;&#23614;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#22312;&#21033;&#29992;&#37325;&#23614;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20316;&#20026;&#20195;&#29702;&#26469;&#38416;&#26126;&#38543;&#26426;&#20248;&#21270;&#22120;&#30340;&#26377;&#36259;&#26041;&#38754;&#26102;&#65292;&#20808;&#21069;&#30340;&#24037;&#20316;&#35201;&#20040;&#25552;&#20379;&#39044;&#26399;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#35201;&#20040;&#24341;&#20837;&#20102;&#19981;&#21487;&#35745;&#31639;&#30340;&#20449;&#24687;&#35770;&#26415;&#35821;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#32570;&#28857;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#37325;&#23614;SDE&#30340;&#39640;&#27010;&#29575;&#27867;&#21270;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#19981;&#21547;&#20219;&#20309;&#38750;&#24179;&#20961;&#30340;&#20449;&#24687;&#35770;&#26415;&#35821;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#22522;&#20110;&#20272;&#35745;&#19982;&#25152;&#35859;&#30340;&#20998;&#25968;&#38459;&#23612;&#24211;&#20177;&#26041;&#31243;&#30456;&#20851;&#32852;&#30340;&#29109;&#27969;&#65292;&#24320;&#21457;&#20102;&#26032;&#30340;&#35777;&#26126;&#25216;&#26415;&#65288;&#36825;&#26159;&#19968;&#31181;&#25511;&#21046;&#30456;&#24212;&#37325;&#23614;SDE&#20998;&#24067;&#28436;&#21270;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#65289;&#12290;&#38500;&#20102;&#33719;&#24471;&#39640;&#27010;&#29575;&#30028;&#38480;&#20043;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#30028;&#38480;&#30456;&#23545;&#20110;&#21442;&#25968;&#32500;&#24230;&#30340;&#20381;&#36182;&#24615;&#35201;&#22909;&#20110;p&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding the generalization properties of heavy-tailed stochastic optimization algorithms has attracted increasing attention over the past years. While illuminating interesting aspects of stochastic optimizers by using heavy-tailed stochastic differential equations as proxies, prior works either provided expected generalization bounds, or introduced non-computable information theoretic terms. Addressing these drawbacks, in this work, we prove high-probability generalization bounds for heavy-tailed SDEs which do not contain any nontrivial information theoretic terms. To achieve this goal, we develop new proof techniques based on estimating the entropy flows associated with the so-called fractional Fokker-Planck equation (a partial differential equation that governs the evolution of the distribution of the corresponding heavy-tailed SDE). In addition to obtaining high-probability bounds, we show that our bounds have a better dependence on the dimension of parameters as compared to p
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#19981;&#30693;&#36947;&#28304;&#32479;&#35745;&#27169;&#22411;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#39640;&#25928;&#22320;&#23558;&#26679;&#26412;&#20174;&#28304;&#27169;&#22411;&#36716;&#25442;&#20026;&#30446;&#26631;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#26500;&#36896;&#20102;&#20960;&#20010;&#24402;&#32422;&#26041;&#27861;&#12290;&#36825;&#20123;&#24402;&#32422;&#26041;&#27861;&#33021;&#36866;&#24212;&#19981;&#21516;&#30340;&#38382;&#39064;&#65292;&#20363;&#22914;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#12289;&#30456;&#20301;&#24674;&#22797;&#21644;&#20449;&#21495;&#38477;&#22122;&#31561;&#65292;&#24182;&#19988;&#21487;&#20197;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#35813;&#30740;&#31350;&#36824;&#25351;&#20986;&#20102;&#19968;&#20010;&#28508;&#22312;&#30340;&#24212;&#29992;&#65292;&#21363;&#23558;&#19968;&#20010;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#36716;&#25442;&#20026;&#21478;&#19968;&#20010;&#26426;&#21046;&#12290;</title><link>https://arxiv.org/abs/2402.07717</link><description>&lt;p&gt;
&#19968;&#20123;&#32479;&#35745;&#27169;&#22411;&#20043;&#38388;&#30340;&#39640;&#25928;&#24402;&#32422;
&lt;/p&gt;
&lt;p&gt;
Efficient reductions between some statistical models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07717
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#19981;&#30693;&#36947;&#28304;&#32479;&#35745;&#27169;&#22411;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#39640;&#25928;&#22320;&#23558;&#26679;&#26412;&#20174;&#28304;&#27169;&#22411;&#36716;&#25442;&#20026;&#30446;&#26631;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#26500;&#36896;&#20102;&#20960;&#20010;&#24402;&#32422;&#26041;&#27861;&#12290;&#36825;&#20123;&#24402;&#32422;&#26041;&#27861;&#33021;&#36866;&#24212;&#19981;&#21516;&#30340;&#38382;&#39064;&#65292;&#20363;&#22914;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#12289;&#30456;&#20301;&#24674;&#22797;&#21644;&#20449;&#21495;&#38477;&#22122;&#31561;&#65292;&#24182;&#19988;&#21487;&#20197;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#35813;&#30740;&#31350;&#36824;&#25351;&#20986;&#20102;&#19968;&#20010;&#28508;&#22312;&#30340;&#24212;&#29992;&#65292;&#21363;&#23558;&#19968;&#20010;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#36716;&#25442;&#20026;&#21478;&#19968;&#20010;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#19981;&#30693;&#36947;&#28304;&#27169;&#22411;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#36817;&#20284;&#22320;&#23558;&#26469;&#33258;&#28304;&#32479;&#35745;&#27169;&#22411;&#30340;&#26679;&#26412;&#36716;&#25442;&#20026;&#30446;&#26631;&#32479;&#35745;&#27169;&#22411;&#30340;&#26679;&#26412;&#30340;&#38382;&#39064;&#65292;&#24182;&#26500;&#36896;&#20102;&#20960;&#20010;&#35745;&#31639;&#19978;&#39640;&#25928;&#30340;&#36825;&#31181;&#32479;&#35745;&#23454;&#39564;&#20043;&#38388;&#30340;&#24402;&#32422;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#35745;&#31639;&#19978;&#39640;&#25928;&#30340;&#31243;&#24207;&#65292;&#21487;&#20197;&#36817;&#20284;&#23558;&#22343;&#21248;&#20998;&#24067;&#12289;Erlang&#20998;&#24067;&#21644;&#25289;&#26222;&#25289;&#26031;&#20998;&#24067;&#30340;&#20301;&#32622;&#27169;&#22411;&#24402;&#32422;&#21040;&#19968;&#33324;&#30340;&#30446;&#26631;&#26063;&#12290;&#25105;&#20204;&#36890;&#36807;&#24314;&#31435;&#19968;&#20123;&#32463;&#20856;&#30340;&#39640;&#32500;&#38382;&#39064;&#20043;&#38388;&#30340;&#38750;&#28176;&#36817;&#24402;&#32422;&#26469;&#35828;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#12289;&#30456;&#20301;&#24674;&#22797;&#21644;&#20449;&#21495;&#38477;&#22122;&#31561;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20123;&#24402;&#32422;&#20445;&#25345;&#20102;&#32467;&#26500;&#65292;&#24182;&#21487;&#20197;&#36866;&#24212;&#32570;&#22833;&#25968;&#25454;&#12290;&#25105;&#20204;&#36824;&#25351;&#20986;&#20102;&#23558;&#19968;&#20010;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#36716;&#25442;&#20026;&#21478;&#19968;&#20010;&#26426;&#21046;&#30340;&#21487;&#33021;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of approximately transforming a sample from a source statistical model to a sample from a target statistical model without knowing the parameters of the source model, and construct several computationally efficient such reductions between statistical experiments. In particular, we provide computationally efficient procedures that approximately reduce uniform, Erlang, and Laplace location models to general target families. We illustrate our methodology by establishing nonasymptotic reductions between some canonical high-dimensional problems, spanning mixtures of experts, phase retrieval, and signal denoising. Notably, the reductions are structure preserving and can accommodate missing data. We also point to a possible application in transforming one differentially private mechanism to another.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;&#26680;&#22238;&#24402;&#30340;&#31616;&#21270;&#29615;&#22659;&#20013;&#35299;&#26512;&#20102;&#27169;&#22411;&#23849;&#28291;&#29616;&#35937;&#65292;&#24182;&#21457;&#29616;&#20102;&#27169;&#22411;&#33021;&#22815;&#22788;&#29702;&#34394;&#20551;&#25968;&#25454;&#19982;&#24615;&#33021;&#23436;&#20840;&#23849;&#28291;&#20043;&#38388;&#30340;&#20132;&#21449;&#28857;&#12290;&#36890;&#36807;&#25552;&#20986;&#22522;&#20110;&#33258;&#36866;&#24212;&#27491;&#21017;&#21270;&#30340;&#31574;&#30053;&#65292;&#25104;&#21151;&#32531;&#35299;&#20102;&#27169;&#22411;&#23849;&#28291;&#38382;&#39064;&#12290;&#36825;&#20123;&#21457;&#29616;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#12290;</title><link>https://arxiv.org/abs/2402.07712</link><description>&lt;p&gt;
&#27169;&#22411;&#23849;&#28291;&#35299;&#23494;&#65306;&#22238;&#24402;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Model Collapse Demystified: The Case of Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07712
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#26680;&#22238;&#24402;&#30340;&#31616;&#21270;&#29615;&#22659;&#20013;&#35299;&#26512;&#20102;&#27169;&#22411;&#23849;&#28291;&#29616;&#35937;&#65292;&#24182;&#21457;&#29616;&#20102;&#27169;&#22411;&#33021;&#22815;&#22788;&#29702;&#34394;&#20551;&#25968;&#25454;&#19982;&#24615;&#33021;&#23436;&#20840;&#23849;&#28291;&#20043;&#38388;&#30340;&#20132;&#21449;&#28857;&#12290;&#36890;&#36807;&#25552;&#20986;&#22522;&#20110;&#33258;&#36866;&#24212;&#27491;&#21017;&#21270;&#30340;&#31574;&#30053;&#65292;&#25104;&#21151;&#32531;&#35299;&#20102;&#27169;&#22411;&#23849;&#28291;&#38382;&#39064;&#12290;&#36825;&#20123;&#21457;&#29616;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20687;ChatGPT&#36825;&#26679;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26102;&#20195;&#65292;"&#27169;&#22411;&#23849;&#28291;"&#29616;&#35937;&#25351;&#30340;&#26159;&#27169;&#22411;&#22312;&#36882;&#24402;&#22320;&#35757;&#32451;&#33258;&#36523;&#19978;&#19968;&#20195;&#21448;&#19968;&#20195;&#29983;&#25104;&#30340;&#25968;&#25454;&#26102;&#65292;&#20854;&#24615;&#33021;&#36880;&#28176;&#38477;&#20302;&#65292;&#26368;&#32456;&#21464;&#24471;&#23436;&#20840;&#26080;&#29992;&#65292;&#21363;&#27169;&#22411;&#23849;&#28291;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#22312;&#26680;&#22238;&#24402;&#30340;&#31616;&#21270;&#29615;&#22659;&#20013;&#30740;&#31350;&#20102;&#36825;&#19968;&#29616;&#35937;&#65292;&#24182;&#33719;&#24471;&#20102;&#32467;&#26524;&#65292;&#26174;&#31034;&#27169;&#22411;&#33021;&#22815;&#22788;&#29702;&#34394;&#20551;&#25968;&#25454;&#19982;&#27169;&#22411;&#24615;&#33021;&#23436;&#20840;&#23849;&#28291;&#20043;&#38388;&#23384;&#22312;&#26126;&#26174;&#30340;&#20132;&#21449;&#28857;&#12290;&#22312;&#22810;&#39033;&#24335;&#34928;&#20943;&#30340;&#20809;&#35889;&#21644;&#28304;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#20462;&#25913;&#21518;&#30340;&#32553;&#25918;&#23450;&#24459;&#65292;&#23637;&#31034;&#20102;&#20174;&#24555;&#36895;&#21040;&#32531;&#24930;&#36895;&#29575;&#30340;&#26032;&#20132;&#21449;&#29616;&#35937;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#22522;&#20110;&#33258;&#36866;&#24212;&#27491;&#21017;&#21270;&#30340;&#31616;&#21333;&#31574;&#30053;&#26469;&#32531;&#35299;&#27169;&#22411;&#23849;&#28291;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the era of large language models like ChatGPT, the phenomenon of "model collapse" refers to the situation whereby as a model is trained recursively on data generated from previous generations of itself over time, its performance degrades until the model eventually becomes completely useless, i.e the model collapses. In this work, we study this phenomenon in the simplified setting of kernel regression and obtain results which show a clear crossover between where the model can cope with fake data, and a regime where the model's performance completely collapses. Under polynomial decaying spectral and source conditions, we obtain modified scaling laws which exhibit new crossover phenomena from fast to slow rates. We also propose a simple strategy based on adaptive regularization to mitigate model collapse. Our theoretical results are validated with experiments.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#36335;&#24452;&#31215;&#20998;&#26041;&#27861;&#25506;&#32034;&#20102;&#36830;&#32493;&#26102;&#38388;&#38543;&#26426;&#26799;&#24230;&#27969;&#21160;&#21147;&#23398;&#20013;&#30340;&#27979;&#35797;&#39118;&#38505;&#65292;&#24182;&#22312;&#23567;&#23398;&#20064;&#29575;&#24773;&#20917;&#19979;&#32473;&#20986;&#20102;&#35745;&#31639;&#32431;&#26799;&#24230;&#27969;&#21160;&#21644;&#38543;&#26426;&#26799;&#24230;&#27969;&#21160;&#30340;&#27979;&#35797;&#39118;&#38505;&#26354;&#32447;&#20043;&#38388;&#24046;&#24322;&#30340;&#19968;&#33324;&#20844;&#24335;&#12290;&#36890;&#36807;&#24212;&#29992;&#20110;&#19968;&#20010;&#24369;&#29305;&#24449;&#27169;&#22411;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#38543;&#26426;&#39033;&#23545;&#21160;&#21147;&#23398;&#30340;&#20462;&#27491;&#25928;&#26524;&#65292;&#24182;&#19982;&#31163;&#25955;&#26102;&#38388;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#27169;&#25311;&#32467;&#26524;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#32467;&#26524;&#26174;&#31034;&#20986;&#19968;&#33268;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.07626</link><description>&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#27969;&#21160;&#21147;&#23398;&#20013;&#30340;&#27979;&#35797;&#39118;&#38505;&#21450;&#20854;&#24369;&#29305;&#24449;&#30340;&#31934;&#30830;&#35299;
&lt;/p&gt;
&lt;p&gt;
Stochastic Gradient Flow Dynamics of Test Risk and its Exact Solution for Weak Features
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07626
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#36335;&#24452;&#31215;&#20998;&#26041;&#27861;&#25506;&#32034;&#20102;&#36830;&#32493;&#26102;&#38388;&#38543;&#26426;&#26799;&#24230;&#27969;&#21160;&#21147;&#23398;&#20013;&#30340;&#27979;&#35797;&#39118;&#38505;&#65292;&#24182;&#22312;&#23567;&#23398;&#20064;&#29575;&#24773;&#20917;&#19979;&#32473;&#20986;&#20102;&#35745;&#31639;&#32431;&#26799;&#24230;&#27969;&#21160;&#21644;&#38543;&#26426;&#26799;&#24230;&#27969;&#21160;&#30340;&#27979;&#35797;&#39118;&#38505;&#26354;&#32447;&#20043;&#38388;&#24046;&#24322;&#30340;&#19968;&#33324;&#20844;&#24335;&#12290;&#36890;&#36807;&#24212;&#29992;&#20110;&#19968;&#20010;&#24369;&#29305;&#24449;&#27169;&#22411;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#38543;&#26426;&#39033;&#23545;&#21160;&#21147;&#23398;&#30340;&#20462;&#27491;&#25928;&#26524;&#65292;&#24182;&#19982;&#31163;&#25955;&#26102;&#38388;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#27169;&#25311;&#32467;&#26524;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#32467;&#26524;&#26174;&#31034;&#20986;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#23398;&#20064;&#29702;&#35770;&#20013;&#36830;&#32493;&#26102;&#38388;&#38543;&#26426;&#26799;&#24230;&#27969;&#21160;&#21147;&#23398;&#30340;&#27979;&#35797;&#39118;&#38505;&#12290;&#21033;&#29992;&#36335;&#24452;&#31215;&#20998;&#20844;&#24335;&#65292;&#22312;&#23567;&#23398;&#20064;&#29575;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20379;&#20102;&#35745;&#31639;&#32431;&#26799;&#24230;&#27969;&#21160;&#21644;&#38543;&#26426;&#26799;&#24230;&#27969;&#21160;&#30340;&#27979;&#35797;&#39118;&#38505;&#26354;&#32447;&#20043;&#38388;&#24046;&#24322;&#30340;&#19968;&#33324;&#20844;&#24335;&#12290;&#25105;&#20204;&#23558;&#36825;&#19968;&#36890;&#29992;&#29702;&#35770;&#24212;&#29992;&#21040;&#19968;&#20010;&#31616;&#21333;&#30340;&#24369;&#29305;&#24449;&#27169;&#22411;&#20013;&#65292;&#35813;&#27169;&#22411;&#23637;&#31034;&#20102;&#21452;&#23792;&#29616;&#35937;&#65292;&#24182;&#26126;&#30830;&#35745;&#31639;&#20102;&#21160;&#21147;&#23398;&#20013;&#22686;&#21152;&#30340;&#38543;&#26426;&#39033;&#38543;&#26102;&#38388;&#21644;&#27169;&#22411;&#21442;&#25968;&#30340;&#20462;&#27491;&#12290;&#20998;&#26512;&#32467;&#26524;&#19982;&#31163;&#25955;&#26102;&#38388;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#27169;&#25311;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#26174;&#31034;&#20986;&#33391;&#22909;&#30340;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the test risk of continuous-time stochastic gradient flow dynamics in learning theory. Using a path integral formulation we provide, in the regime of a small learning rate, a general formula for computing the difference between test risk curves of pure gradient and stochastic gradient flows. We apply the general theory to a simple model of weak features, which displays the double descent phenomenon, and explicitly compute the corrections brought about by the added stochastic term in the dynamics, as a function of time and model parameters. The analytical results are compared to simulations of discrete-time stochastic gradient descent and show good agreement.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#21487;&#25509;&#21463;&#30340;&#23545;&#31216;&#32422;&#26463;&#26465;&#20214;&#19979;&#30340;&#20840;&#23616;&#26368;&#20248;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#28385;&#36275;&#23545;&#31216;&#24615;&#36136;&#30340;&#20989;&#25968;&#25110;&#24230;&#37327;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#36712;&#36947;&#20984;&#20307;&#21644;coycle&#31561;&#24037;&#20855;&#35299;&#20915;&#20102;&#36825;&#19968;&#38382;&#39064;&#12290;&#20855;&#20307;&#24212;&#29992;&#21253;&#25324;&#19981;&#21464;&#26680;&#22343;&#20540;&#23884;&#20837;&#21644;&#22522;&#20110;&#23545;&#31216;&#32422;&#26463;&#30340;&#36816;&#36755;&#26041;&#26696;&#26368;&#20248;&#24615;&#12290;&#36825;&#20123;&#32467;&#26524;&#19982;&#19981;&#21464;&#24615;&#26816;&#39564;&#30340;Hunt-Stein&#23450;&#29702;&#30456;&#20851;&#12290;</title><link>https://arxiv.org/abs/2402.07613</link><description>&lt;p&gt;
&#22312;&#21487;&#25509;&#21463;&#30340;&#23545;&#31216;&#32422;&#26463;&#26465;&#20214;&#19979;&#30340;&#20840;&#23616;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
Global optimality under amenable symmetry constraints
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07613
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#21487;&#25509;&#21463;&#30340;&#23545;&#31216;&#32422;&#26463;&#26465;&#20214;&#19979;&#30340;&#20840;&#23616;&#26368;&#20248;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#28385;&#36275;&#23545;&#31216;&#24615;&#36136;&#30340;&#20989;&#25968;&#25110;&#24230;&#37327;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#36712;&#36947;&#20984;&#20307;&#21644;coycle&#31561;&#24037;&#20855;&#35299;&#20915;&#20102;&#36825;&#19968;&#38382;&#39064;&#12290;&#20855;&#20307;&#24212;&#29992;&#21253;&#25324;&#19981;&#21464;&#26680;&#22343;&#20540;&#23884;&#20837;&#21644;&#22522;&#20110;&#23545;&#31216;&#32422;&#26463;&#30340;&#36816;&#36755;&#26041;&#26696;&#26368;&#20248;&#24615;&#12290;&#36825;&#20123;&#32467;&#26524;&#19982;&#19981;&#21464;&#24615;&#26816;&#39564;&#30340;Hunt-Stein&#23450;&#29702;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#26159;&#21542;&#23384;&#22312;&#19968;&#31181;&#28385;&#36275;&#21487;&#25509;&#21463;&#21464;&#25442;&#32676;&#25351;&#23450;&#30340;&#23545;&#31216;&#24615;&#36136;&#30340;&#20989;&#25968;&#25110;&#24230;&#37327;&#65292;&#21363;&#21516;&#26102;&#28385;&#36275;&#20197;&#19979;&#20004;&#20010;&#26465;&#20214;&#65306;&#65288;1&#65289;&#26368;&#23567;&#21270;&#32473;&#23450;&#30340;&#20984;&#24615;&#27867;&#20989;&#25110;&#39118;&#38505;&#65292;&#65288;2&#65289;&#28385;&#36275;&#21487;&#23481;&#24525;&#23545;&#31216;&#32422;&#26463;&#12290;&#36825;&#31181;&#23545;&#31216;&#24615;&#36136;&#30340;&#20363;&#23376;&#21253;&#25324;&#19981;&#21464;&#24615;&#12289;&#21487;&#21464;&#24615;&#25110;&#20934;&#19981;&#21464;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20381;&#36182;&#20110;Stein&#21644;Le Cam&#30340;&#32769;&#24605;&#24819;&#65292;&#20197;&#21450;&#22312;&#21487;&#25509;&#21463;&#32676;&#30340;&#36941;&#21382;&#23450;&#29702;&#20013;&#20986;&#29616;&#30340;&#36817;&#20284;&#32676;&#24179;&#22343;&#20540;&#12290;&#22312;&#20984;&#20998;&#26512;&#20013;&#65292;&#19968;&#31867;&#31216;&#20026;&#36712;&#36947;&#20984;&#20307;&#30340;&#20984;&#38598;&#26174;&#24471;&#33267;&#20851;&#37325;&#35201;&#65292;&#25105;&#20204;&#22312;&#38750;&#21442;&#25968;&#35774;&#32622;&#20013;&#30830;&#23450;&#20102;&#36825;&#31867;&#36712;&#36947;&#20984;&#20307;&#30340;&#24615;&#36136;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#19968;&#20010;&#31216;&#20026;coycle&#30340;&#31616;&#21333;&#35013;&#32622;&#22914;&#20309;&#23558;&#19981;&#21516;&#24418;&#24335;&#30340;&#23545;&#31216;&#24615;&#36716;&#21270;&#20026;&#19968;&#20010;&#38382;&#39064;&#12290;&#20316;&#20026;&#24212;&#29992;&#65292;&#25105;&#20204;&#24471;&#20986;&#20102;&#20851;&#20110;&#19981;&#21464;&#26680;&#22343;&#20540;&#23884;&#20837;&#21644;&#22312;&#23545;&#31216;&#32422;&#26463;&#19979;&#36816;&#36755;&#26041;&#26696;&#26368;&#20248;&#24615;&#30340;Monge-Kantorovich&#23450;&#29702;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#35299;&#37322;&#20102;&#19982;&#19981;&#21464;&#24615;&#26816;&#39564;&#30340;Hunt-Stein&#23450;&#29702;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
We ask whether there exists a function or measure that (1) minimizes a given convex functional or risk and (2) satisfies a symmetry property specified by an amenable group of transformations. Examples of such symmetry properties are invariance, equivariance, or quasi-invariance. Our results draw on old ideas of Stein and Le Cam and on approximate group averages that appear in ergodic theorems for amenable groups. A class of convex sets known as orbitopes in convex analysis emerges as crucial, and we establish properties of such orbitopes in nonparametric settings. We also show how a simple device called a cocycle can be used to reduce different forms of symmetry to a single problem. As applications, we obtain results on invariant kernel mean embeddings and a Monge-Kantorovich theorem on optimality of transport plans under symmetry constraints. We also explain connections to the Hunt-Stein theorem on invariant tests.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29983;&#25104;&#27169;&#22411;&#30340;&#36817;&#26368;&#23567;&#26497;&#22823;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#36817;&#20284;&#22238;&#25253;&#20998;&#24067;&#26041;&#38754;&#20855;&#26377;&#26497;&#23567;&#26497;&#22823;&#20248;&#21183;&#65292;&#35299;&#20915;&#20102;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#39564;&#30740;&#31350;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.07598</link><description>&lt;p&gt;
&#22522;&#20110;&#29983;&#25104;&#27169;&#22411;&#30340;&#36817;&#26368;&#23567;&#26497;&#22823;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Near-Minimax-Optimal Distributional Reinforcement Learning with a Generative Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07598
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29983;&#25104;&#27169;&#22411;&#30340;&#36817;&#26368;&#23567;&#26497;&#22823;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#36817;&#20284;&#22238;&#25253;&#20998;&#24067;&#26041;&#38754;&#20855;&#26377;&#26497;&#23567;&#26497;&#22823;&#20248;&#21183;&#65292;&#35299;&#20915;&#20102;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#39564;&#30740;&#31350;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#36817;&#20284;&#22238;&#25253;&#20998;&#24067;&#26041;&#38754;&#65292;&#23427;&#26159;&#36817;&#20284;&#26368;&#23567;&#26497;&#22823;&#30340;&#65288;&#22312;&#23545;&#25968;&#22240;&#23376;&#19978;&#65289;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;Zhang&#31561;&#20154;&#65288;2023&#65289;&#30340;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#20026;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20998;&#31867;&#26041;&#27861;&#25552;&#20379;&#20102;&#26032;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#24067;&#24335;Bellman&#26041;&#31243;&#65292;&#21363;&#38543;&#26426;&#20998;&#31867;&#32047;&#31215;&#20998;&#24067;&#20989;&#25968;Bellman&#26041;&#31243;&#65292;&#25105;&#20204;&#35748;&#20026;&#36825;&#20010;&#26041;&#31243;&#20063;&#20855;&#26377;&#29420;&#31435;&#30340;&#30740;&#31350;&#24847;&#20041;&#12290;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#23454;&#39564;&#30740;&#31350;&#65292;&#27604;&#36739;&#20102;&#20960;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#24471;&#20986;&#20102;&#23545;&#23454;&#36341;&#32773;&#26377;&#24847;&#20041;&#30340;&#20960;&#20010;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new algorithm for model-based distributional reinforcement learning (RL), and prove that it is minimax-optimal for approximating return distributions with a generative model (up to logarithmic factors), resolving an open question of Zhang et al. (2023). Our analysis provides new theoretical results on categorical approaches to distributional RL, and also introduces a new distributional Bellman equation, the stochastic categorical CDF Bellman equation, which we expect to be of independent interest. We also provide an experimental study comparing several model-based distributional RL algorithms, with several takeaways for practitioners.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37325;&#26032;&#24605;&#32771;&#20102;&#22312;&#25112;&#30053;&#29615;&#22659;&#20013;&#23398;&#20064;&#30340;&#27604;&#20363;&#23450;&#24459;&#65292;&#21457;&#29616;&#25112;&#30053;&#20114;&#21160;&#21487;&#20197;&#25171;&#30772;&#20256;&#32479;&#30340;&#35266;&#28857;&#65292;&#21363;&#27169;&#22411;&#36234;&#22823;&#25110;&#34920;&#36798;&#33021;&#21147;&#36234;&#24378;&#24182;&#19981;&#19968;&#23450;&#20250;&#38543;&#20043;&#25552;&#39640;&#24615;&#33021;&#12290;&#36890;&#36807;&#20960;&#20010;&#25112;&#30053;&#29615;&#22659;&#30340;&#20363;&#23376;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#29616;&#35937;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.07588</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#25112;&#30053;&#29615;&#22659;&#20013;&#23398;&#20064;&#30340;&#27604;&#20363;&#23450;&#24459;
&lt;/p&gt;
&lt;p&gt;
Rethinking Scaling Laws for Learning in Strategic Environments
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07588
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#24605;&#32771;&#20102;&#22312;&#25112;&#30053;&#29615;&#22659;&#20013;&#23398;&#20064;&#30340;&#27604;&#20363;&#23450;&#24459;&#65292;&#21457;&#29616;&#25112;&#30053;&#20114;&#21160;&#21487;&#20197;&#25171;&#30772;&#20256;&#32479;&#30340;&#35266;&#28857;&#65292;&#21363;&#27169;&#22411;&#36234;&#22823;&#25110;&#34920;&#36798;&#33021;&#21147;&#36234;&#24378;&#24182;&#19981;&#19968;&#23450;&#20250;&#38543;&#20043;&#25552;&#39640;&#24615;&#33021;&#12290;&#36890;&#36807;&#20960;&#20010;&#25112;&#30053;&#29615;&#22659;&#30340;&#20363;&#23376;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#29616;&#35937;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36234;&#26469;&#36234;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#37096;&#32626;&#21453;&#26144;&#20986;&#19968;&#20010;&#20849;&#35782;&#65306;&#27169;&#22411;&#36234;&#26377;&#34920;&#36798;&#33021;&#21147;&#65292;&#36234;&#25317;&#26377;&#22823;&#37327;&#25968;&#25454;&#65292;&#23601;&#33021;&#25913;&#21892;&#24615;&#33021;&#12290;&#38543;&#30528;&#27169;&#22411;&#22312;&#21508;&#31181;&#30495;&#23454;&#22330;&#26223;&#20013;&#30340;&#37096;&#32626;&#65292;&#23427;&#20204;&#19981;&#21487;&#36991;&#20813;&#22320;&#38754;&#20020;&#30528;&#25112;&#30053;&#29615;&#22659;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#27169;&#22411;&#19982;&#25112;&#30053;&#20114;&#21160;&#23545;&#27604;&#20363;&#23450;&#24459;&#30340;&#30456;&#20114;&#20316;&#29992;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#36825;&#20010;&#33258;&#28982;&#38382;&#39064;&#12290;&#25105;&#20204;&#21457;&#29616;&#25112;&#30053;&#20114;&#21160;&#21487;&#20197;&#25171;&#30772;&#20256;&#32479;&#30340;&#27604;&#20363;&#23450;&#24459;&#35266;&#28857;&#65292;&#21363;&#24615;&#33021;&#24182;&#19981;&#19968;&#23450;&#38543;&#30528;&#27169;&#22411;&#30340;&#25193;&#22823;&#21644;/&#25110;&#34920;&#36798;&#33021;&#21147;&#30340;&#22686;&#24378;&#65288;&#21363;&#20351;&#26377;&#26080;&#38480;&#25968;&#25454;&#65289;&#32780;&#21333;&#35843;&#25552;&#39640;&#12290;&#25105;&#20204;&#36890;&#36807;&#25112;&#30053;&#22238;&#24402;&#12289;&#25112;&#30053;&#20998;&#31867;&#21644;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;&#20363;&#23376;&#23637;&#31034;&#20102;&#36825;&#19968;&#29616;&#35937;&#30340;&#24433;&#21709;&#65292;&#36825;&#20123;&#20363;&#23376;&#23637;&#31034;&#20102;&#25112;&#30053;&#29615;&#22659;&#20013;&#30340;&#38480;&#21046;&#27169;&#22411;&#25110;&#31574;&#30053;&#31867;&#30340;&#34920;&#36798;&#33021;&#21147;&#21363;&#21487;&#12290;
&lt;/p&gt;
&lt;p&gt;
The deployment of ever-larger machine learning models reflects a growing consensus that the more expressive the model$\unicode{x2013}$and the more data one has access to$\unicode{x2013}$the more one can improve performance. As models get deployed in a variety of real world scenarios, they inevitably face strategic environments. In this work, we consider the natural question of how the interplay of models and strategic interactions affects scaling laws. We find that strategic interactions can break the conventional view of scaling laws$\unicode{x2013}$meaning that performance does not necessarily monotonically improve as models get larger and/ or more expressive (even with infinite data). We show the implications of this phenomenon in several contexts including strategic regression, strategic classification, and multi-agent reinforcement learning through examples of strategic environments in which$\unicode{x2013}$by simply restricting the expressivity of one's model or policy class$\uni
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25506;&#35752;&#20102;1-WL&#31639;&#27861;&#22312;&#22270;&#21516;&#26500;&#38382;&#39064;&#20013;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#27867;&#21270;&#24615;&#33021;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#21457;&#29616;&#22686;&#24378;&#30340;&#34920;&#36798;&#33021;&#21147;&#23545;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#24182;&#19981;&#24635;&#26159;&#26377;&#25928;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#24341;&#20837;&#23376;&#22270;&#20449;&#24687;&#21644;&#32463;&#20856;&#30340;&#36793;&#32536;&#29702;&#35770;&#65292;&#25506;&#32034;&#20102;&#26356;&#39640;&#34920;&#36798;&#21147;&#19982;&#25913;&#36827;&#27867;&#21270;&#24615;&#33021;&#30340;&#26465;&#20214;&#12290;&#26799;&#24230;&#27969;&#20063;&#34987;&#35777;&#26126;&#21487;&#20197;&#20419;&#36827;&#27169;&#22411;&#23398;&#20064;&#26356;&#20016;&#23500;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.07568</link><description>&lt;p&gt;
Weisfeiler-Leman&#22312;&#36793;&#32536;&#26465;&#20214;&#19979;&#30340;&#26356;&#39640;&#34920;&#36798;&#21147;&#30340;&#37325;&#35201;&#24615;
&lt;/p&gt;
&lt;p&gt;
Weisfeiler-Leman at the margin: When more expressivity matters
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07568
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25506;&#35752;&#20102;1-WL&#31639;&#27861;&#22312;&#22270;&#21516;&#26500;&#38382;&#39064;&#20013;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#27867;&#21270;&#24615;&#33021;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#21457;&#29616;&#22686;&#24378;&#30340;&#34920;&#36798;&#33021;&#21147;&#23545;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#24182;&#19981;&#24635;&#26159;&#26377;&#25928;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#24341;&#20837;&#23376;&#22270;&#20449;&#24687;&#21644;&#32463;&#20856;&#30340;&#36793;&#32536;&#29702;&#35770;&#65292;&#25506;&#32034;&#20102;&#26356;&#39640;&#34920;&#36798;&#21147;&#19982;&#25913;&#36827;&#27867;&#21270;&#24615;&#33021;&#30340;&#26465;&#20214;&#12290;&#26799;&#24230;&#27969;&#20063;&#34987;&#35777;&#26126;&#21487;&#20197;&#20419;&#36827;&#27169;&#22411;&#23398;&#20064;&#26356;&#20016;&#23500;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Weisfeiler-Leman&#31639;&#27861;&#65288;1-WL&#65289;&#26159;&#19968;&#20010;&#34987;&#24191;&#27867;&#30740;&#31350;&#30340;&#29992;&#20110;&#22270;&#21516;&#26500;&#38382;&#39064;&#30340;&#21551;&#21457;&#24335;&#31639;&#27861;&#12290;&#26368;&#36817;&#65292;&#35813;&#31639;&#27861;&#22312;&#29702;&#35299;&#20256;&#36882;&#28040;&#24687;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;MPNNs&#65289;&#30340;&#34920;&#36798;&#33021;&#21147;&#20197;&#21450;&#20316;&#20026;&#22270;&#26680;&#20989;&#25968;&#26041;&#38754;&#21457;&#25381;&#20102;&#37325;&#35201;&#20316;&#29992;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;1-WL&#22312;&#21306;&#20998;&#38750;&#21516;&#26500;&#22270;&#26041;&#38754;&#38754;&#20020;&#25361;&#25112;&#65292;&#20174;&#32780;&#23548;&#33268;&#20102;&#26356;&#20855;&#34920;&#36798;&#21147;&#30340;MPNN&#21644;&#26680;&#26550;&#26500;&#30340;&#21457;&#23637;&#12290;&#28982;&#32780;&#65292;&#22686;&#24378;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#25913;&#36827;&#30340;&#27867;&#21270;&#24615;&#33021;&#20043;&#38388;&#30340;&#20851;&#31995;&#20173;&#19981;&#28165;&#26970;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#36890;&#36807;&#22270;&#21516;&#26500;&#26469;&#35266;&#23519;&#26102;&#65292;&#26550;&#26500;&#30340;&#34920;&#36798;&#33021;&#21147;&#22312;&#35299;&#37322;&#20854;&#27867;&#21270;&#24615;&#33021;&#26041;&#38754;&#20855;&#26377;&#26377;&#38480;&#30340;&#27934;&#23519;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30528;&#37325;&#22312;1-WL&#21644;MPNN&#20013;&#24341;&#20837;&#23376;&#22270;&#20449;&#24687;&#65292;&#24182;&#36816;&#29992;&#32463;&#20856;&#30340;&#36793;&#32536;&#29702;&#35770;&#26469;&#30740;&#31350;&#26550;&#26500;&#30340;&#22686;&#24378;&#34920;&#36798;&#33021;&#21147;&#19982;&#25913;&#36827;&#30340;&#27867;&#21270;&#24615;&#33021;&#20043;&#38388;&#30340;&#26465;&#20214;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#26799;&#24230;&#27969;&#22914;&#20309;&#25512;&#21160;&#27169;&#22411;&#23398;&#20064;&#26356;&#20016;&#23500;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Weisfeiler-Leman algorithm ($1$-WL) is a well-studied heuristic for the graph isomorphism problem. Recently, the algorithm has played a prominent role in understanding the expressive power of message-passing graph neural networks (MPNNs) and being effective as a graph kernel. Despite its success, $1$-WL faces challenges in distinguishing non-isomorphic graphs, leading to the development of more expressive MPNN and kernel architectures. However, the relationship between enhanced expressivity and improved generalization performance remains unclear. Here, we show that an architecture's expressivity offers limited insights into its generalization performance when viewed through graph isomorphism. Moreover, we focus on augmenting $1$-WL and MPNNs with subgraph information and employ classical margin theory to investigate the conditions under which an architecture's increased expressivity aligns with improved generalization performance. In addition, we show that gradient flow pushes the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#21487;&#20197;&#26681;&#25454;&#27178;&#26029;&#38754;&#21644;&#32437;&#21521;&#25968;&#25454;&#39044;&#27979;&#20219;&#20309;&#20154;&#32676;&#25110;&#23376;&#20154;&#32676;&#30340;&#29305;&#24449;&#65292;&#24182;&#20998;&#26512;&#20102;&#22312;&#23454;&#38469;&#29983;&#27963;&#20013;&#26356;&#37325;&#35201;&#30340;&#32972;&#26223;&#19979;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.07521</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#19982;&#23567;&#21306;&#22495;&#20272;&#35745;&#30340;&#25972;&#21512;&#27493;&#39588;
&lt;/p&gt;
&lt;p&gt;
A step towards the integration of machine learning and small area estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07521
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#21487;&#20197;&#26681;&#25454;&#27178;&#26029;&#38754;&#21644;&#32437;&#21521;&#25968;&#25454;&#39044;&#27979;&#20219;&#20309;&#20154;&#32676;&#25110;&#23376;&#20154;&#32676;&#30340;&#29305;&#24449;&#65292;&#24182;&#20998;&#26512;&#20102;&#22312;&#23454;&#38469;&#29983;&#27963;&#20013;&#26356;&#37325;&#35201;&#30340;&#32972;&#26223;&#19979;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#30340;&#24212;&#29992;&#24050;&#32463;&#22312;&#35768;&#22810;&#30740;&#31350;&#39046;&#22495;&#24471;&#21040;&#20102;&#21457;&#23637;&#12290;&#30446;&#21069;&#65292;&#22312;&#32479;&#35745;&#23398;&#20013;&#65292;&#21253;&#25324;&#27491;&#24335;&#32479;&#35745;&#23398;&#22312;&#20869;&#65292;&#20063;&#24191;&#27867;&#24212;&#29992;&#20110;&#25968;&#25454;&#25910;&#38598;&#65288;&#22914;&#21355;&#26143;&#22270;&#20687;&#12289;&#32593;&#32476;&#29228;&#21462;&#21644;&#25991;&#26412;&#25366;&#25496;&#12289;&#25968;&#25454;&#28165;&#27927;&#12289;&#38598;&#25104;&#21644;&#25554;&#34917;&#65289;&#20197;&#21450;&#25968;&#25454;&#20998;&#26512;&#12290;&#28982;&#32780;&#65292;&#22312;&#35843;&#26597;&#25277;&#26679;&#21253;&#25324;&#23567;&#21306;&#22495;&#20272;&#35745;&#26041;&#38754;&#65292;&#36825;&#20123;&#26041;&#27861;&#30340;&#20351;&#29992;&#20173;&#28982;&#38750;&#24120;&#26377;&#38480;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#19968;&#20010;&#30001;&#36825;&#20123;&#31639;&#27861;&#25903;&#25345;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#21487;&#20197;&#26681;&#25454;&#27178;&#26029;&#38754;&#21644;&#32437;&#21521;&#25968;&#25454;&#39044;&#27979;&#20219;&#20309;&#20154;&#32676;&#25110;&#23376;&#20154;&#32676;&#30340;&#29305;&#24449;&#12290;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#24050;&#32463;&#26174;&#31034;&#20986;&#22312;&#35782;&#21035;&#21644;&#24314;&#27169;&#21464;&#37327;&#20043;&#38388;&#22797;&#26434;&#21644;&#38750;&#32447;&#24615;&#20851;&#31995;&#26041;&#38754;&#38750;&#24120;&#24378;&#22823;&#65292;&#36825;&#24847;&#21619;&#30528;&#22312;&#24378;&#28872;&#20559;&#31163;&#32463;&#20856;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#23427;&#20204;&#20855;&#26377;&#38750;&#24120;&#22909;&#30340;&#24615;&#33021;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#19968;&#31181;&#19981;&#21516;&#30340;&#32972;&#26223;&#19979;&#30340;&#34920;&#29616;&#65292;&#36825;&#20010;&#32972;&#26223;&#22312;&#25105;&#20204;&#30475;&#26469;&#22312;&#23454;&#38469;&#29983;&#27963;&#20013;&#26356;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
The use of machine-learning techniques has grown in numerous research areas. Currently, it is also widely used in statistics, including the official statistics for data collection (e.g. satellite imagery, web scraping and text mining, data cleaning, integration and imputation) but also for data analysis. However, the usage of these methods in survey sampling including small area estimation is still very limited. Therefore, we propose a predictor supported by these algorithms which can be used to predict any population or subpopulation characteristics based on cross-sectional and longitudinal data. Machine learning methods have already been shown to be very powerful in identifying and modelling complex and nonlinear relationships between the variables, which means that they have very good properties in case of strong departures from the classic assumptions. Therefore, we analyse the performance of our proposal under a different set-up, in our opinion of greater importance in real-life s
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24471;&#20998;&#20989;&#25968;&#30340;&#27714;&#35299;&#22120;&#26469;&#35299;&#20915;&#39640;&#32500;&#31119;&#20811;-&#26222;&#26391;&#20811;&#26041;&#31243;&#20013;&#30340;&#32500;&#25968;&#28798;&#38590;&#38382;&#39064;&#12290;&#19982;&#33945;&#29305;&#21345;&#27931;&#21644;&#26222;&#36890;PINN&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26356;&#20934;&#30830;&#22320;&#22788;&#29702;&#19982;&#24067;&#26391;&#36816;&#21160;&#30456;&#20851;&#30340;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#65292;&#24182;&#25552;&#20379;&#24555;&#36895;&#37319;&#26679;&#12290;</title><link>https://arxiv.org/abs/2402.07465</link><description>&lt;p&gt;
&#22522;&#20110;&#24471;&#20998;&#30340;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#39640;&#32500;&#31119;&#20811;-&#26222;&#26391;&#20811;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
Score-Based Physics-Informed Neural Networks for High-Dimensional Fokker-Planck Equations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07465
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24471;&#20998;&#20989;&#25968;&#30340;&#27714;&#35299;&#22120;&#26469;&#35299;&#20915;&#39640;&#32500;&#31119;&#20811;-&#26222;&#26391;&#20811;&#26041;&#31243;&#20013;&#30340;&#32500;&#25968;&#28798;&#38590;&#38382;&#39064;&#12290;&#19982;&#33945;&#29305;&#21345;&#27931;&#21644;&#26222;&#36890;PINN&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26356;&#20934;&#30830;&#22320;&#22788;&#29702;&#19982;&#24067;&#26391;&#36816;&#21160;&#30456;&#20851;&#30340;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#65292;&#24182;&#25552;&#20379;&#24555;&#36895;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31119;&#20811;-&#26222;&#26391;&#20811;&#65288;FP&#65289;&#26041;&#31243;&#26159;&#38543;&#26426;&#36807;&#31243;&#20013;&#30340;&#22522;&#30784;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDE&#65289;&#12290;&#28982;&#32780;&#65292;&#24403;&#22788;&#29702;&#39640;&#32500;FP PDE&#26102;&#65292;&#32500;&#25968;&#28798;&#38590;&#65288;CoD&#65289;&#20250;&#24102;&#26469;&#25361;&#25112;&#12290;&#23613;&#31649;&#33945;&#29305;&#21345;&#27931;&#21644;&#26222;&#36890;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#65288;PINN&#65289;&#24050;&#32463;&#26174;&#31034;&#20986;&#24212;&#23545;CoD&#30340;&#28508;&#21147;&#65292;&#20294;&#22312;&#22788;&#29702;&#19982;&#24067;&#26391;&#36816;&#21160;&#30456;&#20851;&#30340;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#65288;PDF&#65289;&#26102;&#65292;&#20004;&#31181;&#26041;&#27861;&#37117;&#22312;&#39640;&#32500;&#24230;&#19978;&#26174;&#31034;&#20986;&#25968;&#20540;&#35823;&#24046;&#12290;&#28857;&#20540;PDF&#38543;&#30528;&#32500;&#24230;&#22686;&#21152;&#21576;&#25351;&#25968;&#32423;&#19979;&#38477;&#65292;&#36229;&#36807;&#20102;&#25968;&#20540;&#27169;&#25311;&#30340;&#31934;&#24230;&#65292;&#23548;&#33268;&#20102;&#30456;&#24403;&#22823;&#30340;&#35823;&#24046;&#12290;&#27492;&#22806;&#65292;&#30001;&#20110;&#20854;&#22823;&#35268;&#27169;&#37319;&#26679;&#65292;&#33945;&#29305;&#21345;&#27931;&#26080;&#27861;&#25552;&#20379;&#24555;&#36895;&#37319;&#26679;&#12290;&#36890;&#36807;&#23545;&#26222;&#36890;PINNs&#27169;&#25311;&#23545;&#25968;&#20284;&#28982;&#65288;LL&#65289;&#65292;&#23558;FP&#26041;&#31243;&#36716;&#21270;&#20026;&#19968;&#20010;&#22256;&#38590;&#30340;HJB&#26041;&#31243;&#65292;&#20854;&#35823;&#24046;&#38543;&#32500;&#25968;&#22686;&#38271;&#36805;&#36895;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#22522;&#20110;&#24471;&#20998;&#30340;&#27714;&#35299;&#22120;&#26469;&#25311;&#21512;SDE&#20013;&#30340;&#24471;&#20998;&#20989;&#25968;&#12290;&#24471;&#20998;&#20989;&#25968;&#23450;&#20041;&#20026;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#30340;&#26799;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Fokker-Planck (FP) equation is a foundational PDE in stochastic processes. However, curse of dimensionality (CoD) poses challenge when dealing with high-dimensional FP PDEs. Although Monte Carlo and vanilla Physics-Informed Neural Networks (PINNs) have shown the potential to tackle CoD, both methods exhibit numerical errors in high dimensions when dealing with the probability density function (PDF) associated with Brownian motion. The point-wise PDF values tend to decrease exponentially as dimension increases, surpassing the precision of numerical simulations and resulting in substantial errors. Moreover, due to its massive sampling, Monte Carlo fails to offer fast sampling. Modeling the logarithm likelihood (LL) via vanilla PINNs transforms the FP equation into a difficult HJB equation, whose error grows rapidly with dimension. To this end, we propose a novel approach utilizing a score-based solver to fit the score function in SDEs. The score function, defined as the gradient of t
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#39034;&#24207;&#39044;&#27979;&#20013;&#30340;&#26631;&#23450;&#36317;&#31163;&#65292;&#35777;&#26126;&#20102;&#23384;&#22312;&#19968;&#31181;&#39044;&#27979;&#31639;&#27861;&#21487;&#20197;&#22312;&#25932;&#20154;&#36873;&#25321;&#30340;&#20108;&#36827;&#21046;&#24207;&#21015;&#19978;&#23454;&#29616;$O(\sqrt{T})$&#30340;&#26631;&#23450;&#36317;&#31163;&#65292;&#36890;&#36807;&#36739;&#20302;&#30340;&#26631;&#23450;&#36317;&#31163;&#36827;&#34892;&#20934;&#30830;&#36817;&#20284;&#12290;</title><link>https://arxiv.org/abs/2402.07458</link><description>&lt;p&gt;
&#20851;&#20110;&#39034;&#24207;&#39044;&#27979;&#20013;&#30340;&#26631;&#23450;&#36317;&#31163;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Distance from Calibration in Sequential Prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07458
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#39034;&#24207;&#39044;&#27979;&#20013;&#30340;&#26631;&#23450;&#36317;&#31163;&#65292;&#35777;&#26126;&#20102;&#23384;&#22312;&#19968;&#31181;&#39044;&#27979;&#31639;&#27861;&#21487;&#20197;&#22312;&#25932;&#20154;&#36873;&#25321;&#30340;&#20108;&#36827;&#21046;&#24207;&#21015;&#19978;&#23454;&#29616;$O(\sqrt{T})$&#30340;&#26631;&#23450;&#36317;&#31163;&#65292;&#36890;&#36807;&#36739;&#20302;&#30340;&#26631;&#23450;&#36317;&#31163;&#36827;&#34892;&#20934;&#30830;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#39034;&#24207;&#20108;&#36827;&#21046;&#39044;&#27979;&#22330;&#26223;&#65292;&#22312;&#36825;&#31181;&#22330;&#26223;&#20013;&#65292;&#39044;&#27979;&#22120;&#30340;&#35780;&#20272;&#26159;&#20197;&#26631;&#23450;&#36317;&#31163;&#20026;&#22522;&#20934;&#30340;&#65292;&#26631;&#23450;&#36317;&#31163;&#23450;&#20041;&#20026;&#39044;&#27979;&#20540;&#19982;&#20107;&#21518;&#23436;&#20840;&#26631;&#23450;&#30340;&#39044;&#27979;&#38598;&#20043;&#38388;&#30340;$L_1$&#36317;&#31163;&#12290;&#36825;&#31867;&#20284;&#20110;&#26368;&#36817;&#30001;B{\l}asiok&#12289;Gopalan&#12289;Hu&#21644;Nakkiran&#65288;STOC 2023&#65289;&#25552;&#20986;&#30340;&#31163;&#32447;&#22330;&#26223;&#20013;&#30340;&#26631;&#23450;&#24230;&#37327;&#12290;&#26631;&#23450;&#36317;&#31163;&#26159;&#19968;&#31181;&#33258;&#28982;&#19988;&#30452;&#35266;&#30340;&#20559;&#31163;&#23436;&#32654;&#26631;&#23450;&#30340;&#24230;&#37327;&#65292;&#24182;&#19988;&#28385;&#36275;&#19981;&#21516;&#20110;&#35768;&#22810;&#24120;&#35265;&#30340;&#26631;&#23450;&#24230;&#37327;&#65288;&#22914;$L_1$&#26631;&#23450;&#35823;&#24046;&#21450;&#20854;&#21464;&#31181;&#65289;&#30340;Lipschitz&#36830;&#32493;&#24615;&#23646;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23384;&#22312;&#19968;&#31181;&#39044;&#27979;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#23545;&#25932;&#20154;&#36873;&#25321;&#30340;&#38271;&#24230;&#20026;$T$&#30340;&#20108;&#36827;&#21046;&#24207;&#21015;&#19978;&#65292;&#20197;&#26399;&#26395;$O(\sqrt{T})$&#30340;&#26631;&#23450;&#36317;&#31163;&#23454;&#29616;&#12290;&#22312;&#36825;&#20010;&#19978;&#30028;&#30340;&#26680;&#24515;&#26159;&#19968;&#20010;&#32467;&#26500;&#24615;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#26631;&#23450;&#36317;&#31163;&#21487;&#20197;&#36890;&#36807;&#36739;&#20302;&#30340;&#26631;&#23450;&#36317;&#31163;&#36827;&#34892;&#20934;&#30830;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a sequential binary prediction setting where the forecaster is evaluated in terms of the calibration distance, which is defined as the $L_1$ distance between the predicted values and the set of predictions that are perfectly calibrated in hindsight. This is analogous to a calibration measure recently proposed by B{\l}asiok, Gopalan, Hu and Nakkiran (STOC 2023) for the offline setting. The calibration distance is a natural and intuitive measure of deviation from perfect calibration, and satisfies a Lipschitz continuity property which does not hold for many popular calibration measures, such as the $L_1$ calibration error and its variants.   We prove that there is a forecasting algorithm that achieves an $O(\sqrt{T})$ calibration distance in expectation on an adversarially chosen sequence of $T$ binary outcomes. At the core of this upper bound is a structural result showing that the calibration distance is accurately approximated by the lower calibration distance, which is a con
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#23545;&#25239;&#22312;&#32447;&#29615;&#22659;&#20013;&#22810;&#31867;&#20998;&#31867;&#20013;&#20381;&#36182;&#20110;&#24378;&#30423;&#21453;&#39304;&#30340;&#20195;&#20215;&#65292;&#33258;&#36866;&#24212;&#23545;&#25163;&#21644;&#38543;&#26426;&#23398;&#20064;&#32773;&#19982;&#26080;&#35270;&#23545;&#25163;&#21644;&#30830;&#23450;&#24615;&#23398;&#20064;&#32773;&#20043;&#38388;&#30340;&#25439;&#22833;&#24046;&#36317;&#12290;</title><link>https://arxiv.org/abs/2402.07453</link><description>&lt;p&gt;
Bandit-Feedback&#22312;&#32447;&#22810;&#31867;&#20998;&#31867;&#65306;&#21464;&#20307;&#21644;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
Bandit-Feedback Online Multiclass Classification: Variants and Tradeoffs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07453
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#23545;&#25239;&#22312;&#32447;&#29615;&#22659;&#20013;&#22810;&#31867;&#20998;&#31867;&#20013;&#20381;&#36182;&#20110;&#24378;&#30423;&#21453;&#39304;&#30340;&#20195;&#20215;&#65292;&#33258;&#36866;&#24212;&#23545;&#25163;&#21644;&#38543;&#26426;&#23398;&#20064;&#32773;&#19982;&#26080;&#35270;&#23545;&#25163;&#21644;&#30830;&#23450;&#24615;&#23398;&#20064;&#32773;&#20043;&#38388;&#30340;&#25439;&#22833;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23545;&#25239;&#22312;&#32447;&#29615;&#22659;&#20013;&#32771;&#34385;&#22810;&#31867;&#20998;&#31867;&#39046;&#22495;&#12290;&#19982;&#25552;&#20379;&#23436;&#20840;&#20449;&#24687;&#30456;&#27604;&#65292;&#20381;&#36182;&#20110;&#24378;&#30423;&#21453;&#39304;&#30340;&#20195;&#20215;&#26159;&#22810;&#23569;&#65311;&#33258;&#36866;&#24212;&#23545;&#25163;&#19982;&#26080;&#35270;&#23545;&#25163;&#30456;&#27604;&#65292;&#21487;&#20197;&#22686;&#21152;&#25439;&#22833;&#30340;&#31243;&#24230;&#26377;&#22810;&#22823;&#65311;&#38543;&#26426;&#23398;&#20064;&#32773;&#19982;&#30830;&#23450;&#24615;&#23398;&#20064;&#32773;&#30456;&#27604;&#65292;&#21487;&#20197;&#38477;&#20302;&#25439;&#22833;&#30340;&#31243;&#24230;&#26377;&#22810;&#22823;&#65311;&#25105;&#20204;&#22312;&#38169;&#35823;&#36793;&#30028;&#27169;&#22411;&#20013;&#30740;&#31350;&#20102;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#20960;&#20046;&#32039;&#30830;&#30340;&#31572;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consider the domain of multiclass classification within the adversarial online setting. What is the price of relying on bandit feedback as opposed to full information? To what extent can an adaptive adversary amplify the loss compared to an oblivious one? To what extent can a randomized learner reduce the loss compared to a deterministic one? We study these questions in the mistake bound model and provide nearly tight answers.   We demonstrate that the optimal mistake bound under bandit feedback is at most $O(k)$ times higher than the optimal mistake bound in the full information case, where $k$ represents the number of labels. This bound is tight and provides an answer to an open question previously posed and studied by Daniely and Helbertal ['13] and by Long ['17, '20], who focused on deterministic learners.   Moreover, we present nearly optimal bounds of $\tilde{\Theta}(k)$ on the gap between randomized and deterministic learners, as well as between adaptive and oblivious adversarie
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#20855;&#26377;&#21333;&#35843;&#23545;&#25163;&#30340;Top-K&#25490;&#21517;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;(MLE)&#65292;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#25509;&#36817;&#26368;&#20248;&#12290;&#31639;&#27861;&#21019;&#26032;&#21253;&#25324;&#20102;&#23545;&#21152;&#26435;MLE&#30340;&#31934;&#30830;&#19988;&#32039;&#23494;&#30340;$\ell_\infty$&#35823;&#24046;&#20998;&#26512;&#65292;&#24182;&#19982;&#21152;&#26435;&#27604;&#36739;&#22270;&#30340;&#35889;&#29305;&#24615;&#30456;&#20851;&#32852;&#12290;</title><link>https://arxiv.org/abs/2402.07445</link><description>&lt;p&gt;
&#20855;&#26377;&#21333;&#35843;&#23545;&#25163;&#30340;Top-K&#25490;&#21517;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Top-$K$ ranking with a monotone adversary
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07445
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#20855;&#26377;&#21333;&#35843;&#23545;&#25163;&#30340;Top-K&#25490;&#21517;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;(MLE)&#65292;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#25509;&#36817;&#26368;&#20248;&#12290;&#31639;&#27861;&#21019;&#26032;&#21253;&#25324;&#20102;&#23545;&#21152;&#26435;MLE&#30340;&#31934;&#30830;&#19988;&#32039;&#23494;&#30340;$\ell_\infty$&#35823;&#24046;&#20998;&#26512;&#65292;&#24182;&#19982;&#21152;&#26435;&#27604;&#36739;&#22270;&#30340;&#35889;&#29305;&#24615;&#30456;&#20851;&#32852;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#20855;&#26377;&#21333;&#35843;&#23545;&#25163;&#30340;Top-K&#25490;&#21517;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#27604;&#36739;&#22270;&#34987;&#38543;&#26426;&#29983;&#25104;&#19988;&#23545;&#25163;&#21487;&#20197;&#28155;&#21152;&#20219;&#24847;&#36793;&#30340;&#24773;&#20917;&#12290;&#32479;&#35745;&#23398;&#23478;&#30340;&#30446;&#26631;&#26159;&#26681;&#25454;&#20174;&#36825;&#20010;&#21322;&#38543;&#26426;&#27604;&#36739;&#22270;&#23548;&#20986;&#30340;&#20004;&#20004;&#27604;&#36739;&#20934;&#30830;&#22320;&#35782;&#21035;&#20986;Top-K&#30340;&#39318;&#36873;&#39033;&#12290;&#26412;&#25991;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#24320;&#21457;&#20986;&#19968;&#31181;&#21152;&#26435;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;(MLE)&#65292;&#23427;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#36798;&#21040;&#20102;&#36817;&#20284;&#26368;&#20248;&#65292;&#26368;&#22810;&#24046;&#19968;&#20010;$log^2(n)$&#30340;&#22240;&#23376;&#65292;&#20854;&#20013;n&#34920;&#31034;&#27604;&#36739;&#39033;&#30340;&#25968;&#37327;&#12290;&#36825;&#24471;&#30410;&#20110;&#20998;&#26512;&#21644;&#31639;&#27861;&#21019;&#26032;&#30340;&#32467;&#21512;&#12290;&#22312;&#20998;&#26512;&#26041;&#38754;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26356;&#26126;&#30830;&#12289;&#26356;&#32039;&#23494;&#30340;&#21152;&#26435;MLE&#30340;$\ell_\infty$&#35823;&#24046;&#20998;&#26512;&#65292;&#23427;&#19982;&#21152;&#26435;&#27604;&#36739;&#22270;&#30340;&#35889;&#29305;&#24615;&#30456;&#20851;&#12290;&#21463;&#27492;&#21551;&#21457;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#21019;&#26032;&#28041;&#21450;&#21040;&#20102;
&lt;/p&gt;
&lt;p&gt;
In this paper, we address the top-$K$ ranking problem with a monotone adversary. We consider the scenario where a comparison graph is randomly generated and the adversary is allowed to add arbitrary edges. The statistician's goal is then to accurately identify the top-$K$ preferred items based on pairwise comparisons derived from this semi-random comparison graph. The main contribution of this paper is to develop a weighted maximum likelihood estimator (MLE) that achieves near-optimal sample complexity, up to a $\log^2(n)$ factor, where n denotes the number of items under comparison. This is made possible through a combination of analytical and algorithmic innovations. On the analytical front, we provide a refined $\ell_\infty$ error analysis of the weighted MLE that is more explicit and tighter than existing analyses. It relates the $\ell_\infty$ error with the spectral properties of the weighted comparison graph. Motivated by this, our algorithmic innovation involves the development 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23637;&#31034;&#20102;&#36890;&#36807;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#30340;&#25512;&#36827;&#35745;&#31639;&#21487;&#20197;&#35745;&#31639;&#20219;&#20309;&#21487;&#36776;&#35782;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#25193;&#25955;&#30340;&#26041;&#27861;&#29992;&#20110;&#20174;&#22270;&#20687;&#30340;&#20219;&#20309;&#65288;&#26465;&#20214;&#65289;&#24178;&#39044;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;</title><link>https://arxiv.org/abs/2402.07419</link><description>&lt;p&gt;
&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#36275;&#20197;&#20174;&#20219;&#20309;&#22240;&#26524;&#25928;&#24212;&#27979;&#24230;&#20013;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Conditional Generative Models are Sufficient to Sample from Any Causal Effect Estimand
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07419
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;&#36890;&#36807;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#30340;&#25512;&#36827;&#35745;&#31639;&#21487;&#20197;&#35745;&#31639;&#20219;&#20309;&#21487;&#36776;&#35782;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#25193;&#25955;&#30340;&#26041;&#27861;&#29992;&#20110;&#20174;&#22270;&#20687;&#30340;&#20219;&#20309;&#65288;&#26465;&#20214;&#65289;&#24178;&#39044;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#20174;&#35266;&#27979;&#25968;&#25454;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#24212;&#29992;&#12290;&#34429;&#28982;&#23384;&#22312;&#35745;&#31639;&#22240;&#26524;&#25928;&#24212;&#30340;&#21487;&#38752;&#19988;&#23436;&#22791;&#30340;&#31639;&#27861;&#65292;&#20294;&#20854;&#20013;&#35768;&#22810;&#31639;&#27861;&#38656;&#35201;&#26174;&#24335;&#35775;&#38382;&#35266;&#27979;&#20998;&#24067;&#19978;&#30340;&#26465;&#20214;&#20284;&#28982;&#65292;&#32780;&#22312;&#39640;&#32500;&#22330;&#26223;&#20013;&#65288;&#20363;&#22914;&#22270;&#20687;&#65289;&#65292;&#20272;&#35745;&#36825;&#20123;&#20284;&#28982;&#26159;&#22256;&#38590;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#30740;&#31350;&#20154;&#21592;&#36890;&#36807;&#20351;&#29992;&#31070;&#32463;&#27169;&#22411;&#27169;&#25311;&#22240;&#26524;&#20851;&#31995;&#65292;&#24182;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#29616;&#26377;&#26041;&#27861;&#20013;&#27809;&#26377;&#19968;&#20010;&#21487;&#20197;&#24212;&#29992;&#20110;&#36890;&#29992;&#22330;&#26223;&#65292;&#20363;&#22914;&#20855;&#26377;&#28508;&#22312;&#28151;&#28102;&#22240;&#32032;&#30340;&#22270;&#20687;&#25968;&#25454;&#30340;&#22240;&#26524;&#22270;&#65292;&#25110;&#32773;&#33719;&#24471;&#26465;&#20214;&#24178;&#39044;&#26679;&#26412;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#20219;&#24847;&#22240;&#26524;&#22270;&#19979;&#65292;&#36890;&#36807;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#30340;&#25512;&#36827;&#35745;&#31639;&#21487;&#20197;&#35745;&#31639;&#20219;&#20309;&#21487;&#36776;&#35782;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#22522;&#20110;&#27492;&#32467;&#26524;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20110;&#25193;&#25955;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20174;&#20219;&#20309;&#65288;&#26465;&#20214;&#65289;&#24178;&#39044;&#20998;&#24067;&#20013;&#37319;&#26679;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal inference from observational data has recently found many applications in machine learning. While sound and complete algorithms exist to compute causal effects, many of these algorithms require explicit access to conditional likelihoods over the observational distribution, which is difficult to estimate in the high-dimensional regime, such as with images. To alleviate this issue, researchers have approached the problem by simulating causal relations with neural models and obtained impressive results. However, none of these existing approaches can be applied to generic scenarios such as causal graphs on image data with latent confounders, or obtain conditional interventional samples. In this paper, we show that any identifiable causal effect given an arbitrary causal graph can be computed through push-forward computations of conditional generative models. Based on this result, we devise a diffusion-based approach to sample from any (conditional) interventional distribution on ima
&lt;/p&gt;</description></item><item><title>&#21487;&#23481;&#35768;&#39044;&#27979;&#35268;&#21010;&#65288;CPP&#65289;&#26159;&#19968;&#31181;&#35299;&#20915;&#21463;&#20219;&#24847;&#38543;&#26426;&#21442;&#25968;&#24433;&#21709;&#30340;&#20248;&#21270;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#26679;&#26412;&#21644;&#37327;&#23376;&#24341;&#29702;&#23558;&#26426;&#36935;&#21463;&#38480;&#20248;&#21270;&#65288;CCO&#65289;&#38382;&#39064;&#36716;&#21270;&#20026;&#30830;&#23450;&#24615;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#20855;&#22791;&#36793;&#38469;&#27010;&#29575;&#21487;&#34892;&#24615;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.07407</link><description>&lt;p&gt;
&#21487;&#23481;&#35768;&#39044;&#27979;&#35268;&#21010;&#29992;&#20110;&#26426;&#36935;&#21463;&#38480;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Conformal Predictive Programming for Chance Constrained Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07407
&lt;/p&gt;
&lt;p&gt;
&#21487;&#23481;&#35768;&#39044;&#27979;&#35268;&#21010;&#65288;CPP&#65289;&#26159;&#19968;&#31181;&#35299;&#20915;&#21463;&#20219;&#24847;&#38543;&#26426;&#21442;&#25968;&#24433;&#21709;&#30340;&#20248;&#21270;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#26679;&#26412;&#21644;&#37327;&#23376;&#24341;&#29702;&#23558;&#26426;&#36935;&#21463;&#38480;&#20248;&#21270;&#65288;CCO&#65289;&#38382;&#39064;&#36716;&#21270;&#20026;&#30830;&#23450;&#24615;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#20855;&#22791;&#36793;&#38469;&#27010;&#29575;&#21487;&#34892;&#24615;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23545;&#39044;&#27979;&#35268;&#21010;&#65288;CP&#65289;&#30340;&#36827;&#23637;&#30340;&#28608;&#21169;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21487;&#23481;&#35768;&#39044;&#27979;&#35268;&#21010;&#65288;CPP&#65289;&#65292;&#19968;&#31181;&#35299;&#20915;&#26426;&#36935;&#21463;&#38480;&#20248;&#21270;&#65288;CCO&#65289;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21363;&#21463;&#20219;&#24847;&#38543;&#26426;&#21442;&#25968;&#24433;&#21709;&#30340;&#38750;&#32447;&#24615;&#32422;&#26463;&#20989;&#25968;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;CPP&#21033;&#29992;&#36825;&#20123;&#38543;&#26426;&#21442;&#25968;&#30340;&#26679;&#26412;&#20197;&#21450;&#37327;&#23376;&#24341;&#29702;&#65288;CP&#30340;&#26680;&#24515;&#65289;&#23558;CCO&#38382;&#39064;&#36716;&#21270;&#20026;&#30830;&#23450;&#24615;&#20248;&#21270;&#38382;&#39064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#65306;&#65288;1&#65289;&#23558;&#37327;&#23376;&#34920;&#31034;&#20026;&#32447;&#24615;&#35268;&#21010;&#20197;&#21450;&#20854;KKT&#26465;&#20214;&#65288;CPP-KKT&#65289;&#65307;&#65288;2&#65289;&#20351;&#29992;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#65288;CPP-MIP&#65289;&#26469;&#21576;&#29616;CPP&#30340;&#20004;&#31181;&#26131;&#20110;&#22788;&#29702;&#30340;&#25913;&#36827;&#12290;CPP&#20855;&#22791;&#23545;CCO&#38382;&#39064;&#36827;&#34892;&#36793;&#38469;&#27010;&#29575;&#21487;&#34892;&#24615;&#20445;&#35777;&#65292;&#36825;&#19982;&#29616;&#26377;&#26041;&#27861;&#65288;&#20363;&#22914;&#26679;&#26412;&#36924;&#36817;&#21644;&#22330;&#26223;&#26041;&#27861;&#65289;&#22312;&#27010;&#24565;&#19978;&#26377;&#25152;&#19981;&#21516;&#12290;&#23613;&#31649;&#25105;&#20204;&#25506;&#35752;&#20102;&#19982;&#26679;&#26412;&#36924;&#36817;&#26041;&#27861;&#30340;&#31639;&#27861;&#30456;&#20284;&#20043;&#22788;&#65292;&#20294;&#25105;&#20204;&#24378;&#35843;CPP&#30340;&#20248;&#21183;&#22312;&#20110;&#26131;&#20110;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the advances in conformal prediction (CP), we propose conformal predictive programming (CPP), an approach to solve chance constrained optimization (CCO) problems, i.e., optimization problems with nonlinear constraint functions affected by arbitrary random parameters. CPP utilizes samples from these random parameters along with the quantile lemma -- which is central to CP -- to transform the CCO problem into a deterministic optimization problem. We then present two tractable reformulations of CPP by: (1) writing the quantile as a linear program along with its KKT conditions (CPP-KKT), and (2) using mixed integer programming (CPP-MIP). CPP comes with marginal probabilistic feasibility guarantees for the CCO problem that are conceptually different from existing approaches, e.g., the sample approximation and the scenario approach. While we explore algorithmic similarities with the sample approximation approach, we emphasize that the strength of CPP is that it can easily be ext
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#22312;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#65292;&#36890;&#36807;&#24341;&#20837;&#25506;&#32034;-&#20877;&#30830;&#23450;&#31639;&#27861;&#21644;&#36830;&#32493;&#28120;&#27760;&#31639;&#27861;&#65292;&#20197;&#21450;&#35880;&#24910;&#36873;&#25321;&#32622;&#20449;&#21306;&#38388;&#30340;&#24133;&#24230;&#65292;&#23454;&#29616;&#20102;&#21487;&#22797;&#21046;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#24403;&#26102;&#38388;&#30028;&#36275;&#22815;&#22823;&#26102;&#65292;&#21487;&#22797;&#21046;&#31639;&#27861;&#30340;&#39069;&#22806;&#20195;&#20215;&#26159;&#19981;&#24517;&#35201;&#30340;&#12290;</title><link>https://arxiv.org/abs/2402.07391</link><description>&lt;p&gt;
&#22312;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#65292;&#21487;&#22797;&#21046;&#24615;&#28176;&#36827;&#33258;&#30001;
&lt;/p&gt;
&lt;p&gt;
Replicability is Asymptotically Free in Multi-armed Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07391
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#22312;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#65292;&#36890;&#36807;&#24341;&#20837;&#25506;&#32034;-&#20877;&#30830;&#23450;&#31639;&#27861;&#21644;&#36830;&#32493;&#28120;&#27760;&#31639;&#27861;&#65292;&#20197;&#21450;&#35880;&#24910;&#36873;&#25321;&#32622;&#20449;&#21306;&#38388;&#30340;&#24133;&#24230;&#65292;&#23454;&#29616;&#20102;&#21487;&#22797;&#21046;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#24403;&#26102;&#38388;&#30028;&#36275;&#22815;&#22823;&#26102;&#65292;&#21487;&#22797;&#21046;&#31639;&#27861;&#30340;&#39069;&#22806;&#20195;&#20215;&#26159;&#19981;&#24517;&#35201;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21463;&#21487;&#22797;&#21046;&#30340;&#26426;&#22120;&#23398;&#20064;&#38656;&#27714;&#30340;&#25512;&#21160;&#65292;&#30740;&#31350;&#20102;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#21487;&#22797;&#21046;&#31639;&#27861;&#65292;&#30830;&#20445;&#31639;&#27861;&#30340;&#25805;&#20316;&#24207;&#21015;&#19981;&#21463;&#25968;&#25454;&#38598;&#22266;&#26377;&#38543;&#26426;&#24615;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#29616;&#26377;&#31639;&#27861;&#25152;&#38656;&#30340;&#36951;&#25022;&#20540;&#27604;&#19981;&#21487;&#22797;&#21046;&#31639;&#27861;&#22810;$O(1/\rho^2)$&#20493;&#65292;&#20854;&#20013;$\rho$&#26159;&#38750;&#22797;&#21046;&#31243;&#24230;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#32473;&#23450;&#30340;$\rho$&#19979;&#26102;&#38388;&#30028;$T$&#36275;&#22815;&#22823;&#26102;&#65292;&#27492;&#39069;&#22806;&#20195;&#20215;&#26159;&#19981;&#24517;&#35201;&#30340;&#65292;&#21069;&#25552;&#26159;&#35880;&#24910;&#36873;&#25321;&#32622;&#20449;&#21306;&#38388;&#30340;&#24133;&#24230;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20808;&#25506;&#32034;&#21518;&#20915;&#31574;&#30340;&#31639;&#27861;&#65292;&#22312;&#20915;&#31574;&#20043;&#21069;&#22343;&#21248;&#36873;&#25321;&#21160;&#20316;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#19968;&#20010;&#36830;&#32493;&#28120;&#27760;&#31639;&#27861;&#65292;&#22312;&#27599;&#20010;&#38454;&#27573;&#32467;&#26463;&#26102;&#28120;&#27760;&#27425;&#20248;&#21160;&#20316;&#12290;&#20026;&#20102;&#30830;&#20445;&#36825;&#20123;&#31639;&#27861;&#30340;&#21487;&#22797;&#21046;&#24615;&#65292;&#25105;&#20204;&#23558;&#38543;&#26426;&#24615;&#24341;&#20837;&#20915;&#31574;&#21046;&#23450;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work is motivated by the growing demand for reproducible machine learning. We study the stochastic multi-armed bandit problem. In particular, we consider a replicable algorithm that ensures, with high probability, that the algorithm's sequence of actions is not affected by the randomness inherent in the dataset. We observe that existing algorithms require $O(1/\rho^2)$ times more regret than nonreplicable algorithms, where $\rho$ is the level of nonreplication. However, we demonstrate that this additional cost is unnecessary when the time horizon $T$ is sufficiently large for a given $\rho$, provided that the magnitude of the confidence bounds is chosen carefully. We introduce an explore-then-commit algorithm that draws arms uniformly before committing to a single arm. Additionally, we examine a successive elimination algorithm that eliminates suboptimal arms at the end of each phase. To ensure the replicability of these algorithms, we incorporate randomness into their decision-ma
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#26377;&#38480;&#25968;&#25454;&#37327;&#22238;&#31572;&#31639;&#27861;&#24615;&#33021;&#38382;&#39064;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#35777;&#26126;&#20102;&#40657;&#30418;&#27979;&#35797;&#26041;&#27861;&#26080;&#27861;&#20934;&#30830;&#22238;&#31572;&#31639;&#27861;&#22312;&#19981;&#21516;&#35757;&#32451;&#38598;&#19978;&#30340;&#25972;&#20307;&#24615;&#33021;&#21644;&#29305;&#23450;&#27169;&#22411;&#30340;&#24615;&#33021;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.07388</link><description>&lt;p&gt;
&#26080;&#20551;&#35774;&#27979;&#35797;&#31639;&#27861;&#24615;&#33021;&#30340;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
The Limits of Assumption-free Tests for Algorithm Performance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07388
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#26377;&#38480;&#25968;&#25454;&#37327;&#22238;&#31572;&#31639;&#27861;&#24615;&#33021;&#38382;&#39064;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#35777;&#26126;&#20102;&#40657;&#30418;&#27979;&#35797;&#26041;&#27861;&#26080;&#27861;&#20934;&#30830;&#22238;&#31572;&#31639;&#27861;&#22312;&#19981;&#21516;&#35757;&#32451;&#38598;&#19978;&#30340;&#25972;&#20307;&#24615;&#33021;&#21644;&#29305;&#23450;&#27169;&#22411;&#30340;&#24615;&#33021;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31639;&#27861;&#35780;&#20215;&#21644;&#27604;&#36739;&#26159;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#23398;&#20013;&#22522;&#26412;&#30340;&#38382;&#39064;&#65292;&#19968;&#20010;&#31639;&#27861;&#22312;&#32473;&#23450;&#30340;&#24314;&#27169;&#20219;&#21153;&#20013;&#34920;&#29616;&#22914;&#20309;&#65292;&#21738;&#20010;&#31639;&#27861;&#34920;&#29616;&#26368;&#20339;&#65311;&#35768;&#22810;&#26041;&#27861;&#24050;&#32463;&#24320;&#21457;&#20986;&#26469;&#35780;&#20272;&#31639;&#27861;&#24615;&#33021;&#65292;&#36890;&#24120;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#31574;&#30053;&#65292;&#23558;&#24863;&#20852;&#36259;&#30340;&#31639;&#27861;&#22312;&#19981;&#21516;&#30340;&#25968;&#25454;&#23376;&#38598;&#19978;&#37325;&#26032;&#35757;&#32451;&#65292;&#24182;&#35780;&#20272;&#20854;&#22312;&#30041;&#20986;&#25968;&#25454;&#28857;&#19978;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#24191;&#27867;&#20351;&#29992;&#36825;&#20123;&#31243;&#24207;&#65292;&#20294;&#23545;&#20110;&#36825;&#20123;&#26041;&#27861;&#30340;&#29702;&#35770;&#24615;&#36136;&#23578;&#26410;&#23436;&#20840;&#29702;&#35299;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#22312;&#26377;&#38480;&#30340;&#25968;&#25454;&#37327;&#19979;&#22238;&#31572;&#36825;&#20123;&#38382;&#39064;&#30340;&#19968;&#20123;&#22522;&#26412;&#38480;&#21046;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#21306;&#20998;&#20102;&#20004;&#20010;&#38382;&#39064;: &#31639;&#27861;$A$&#22312;&#22823;&#23567;&#20026;$n$&#30340;&#35757;&#32451;&#38598;&#19978;&#23398;&#20064;&#38382;&#39064;&#26377;&#22810;&#22909;&#65292;&#20197;&#21450;&#22312;&#29305;&#23450;&#22823;&#23567;&#20026;$n$&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#19978;&#36816;&#34892;$A$&#25152;&#20135;&#29983;&#30340;&#29305;&#23450;&#25311;&#21512;&#27169;&#22411;&#26377;&#22810;&#22909;&#65311;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#35777;&#26126;&#65292;&#23545;&#20110;&#20219;&#20309;&#23558;&#31639;&#27861;&#35270;&#20026;&#40657;&#30418;&#30340;&#27979;&#35797;&#26041;&#27861;&#65292;&#26080;&#27861;&#20934;&#30830;&#22320;&#22238;&#31572;&#36825;&#20004;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithm evaluation and comparison are fundamental questions in machine learning and statistics -- how well does an algorithm perform at a given modeling task, and which algorithm performs best? Many methods have been developed to assess algorithm performance, often based around cross-validation type strategies, retraining the algorithm of interest on different subsets of the data and assessing its performance on the held-out data points. Despite the broad use of such procedures, the theoretical properties of these methods are not yet fully understood. In this work, we explore some fundamental limits for answering these questions with limited amounts of data. In particular, we make a distinction between two questions: how good is an algorithm $A$ at the problem of learning from a training set of size $n$, versus, how good is a particular fitted model produced by running $A$ on a particular training data set of size $n$?   Our main results prove that, for any test that treats the algor
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#12289;&#19982;&#27169;&#22411;&#26080;&#20851;&#30340;&#26041;&#27861;&#26063;&#65292;&#29992;&#20110;&#26657;&#20934;&#20855;&#26377;&#23616;&#37096;&#35206;&#30422;&#20445;&#35777;&#30340;&#22238;&#24402;&#38382;&#39064;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;&#36825;&#31181;&#26041;&#27861;&#21033;&#29992;&#22238;&#24402;&#26641;&#21644;&#38543;&#26426;&#26862;&#26519;&#35757;&#32451;&#26469;&#21019;&#24314;&#26368;&#31895;&#31961;&#30340;&#29305;&#24449;&#31354;&#38388;&#21010;&#20998;&#65292;&#20197;&#36817;&#20284;&#26465;&#20214;&#35206;&#30422;&#65292;&#25552;&#20379;&#20102;&#20934;&#30830;&#12289;&#24555;&#36895;&#21644;&#33258;&#36866;&#24212;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;</title><link>https://arxiv.org/abs/2402.07357</link><description>&lt;p&gt;
&#22238;&#24402;&#26641;&#29992;&#20110;&#24555;&#36895;&#21644;&#33258;&#36866;&#24212;&#30340;&#39044;&#27979;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;
Regression Trees for Fast and Adaptive Prediction Intervals
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07357
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#12289;&#19982;&#27169;&#22411;&#26080;&#20851;&#30340;&#26041;&#27861;&#26063;&#65292;&#29992;&#20110;&#26657;&#20934;&#20855;&#26377;&#23616;&#37096;&#35206;&#30422;&#20445;&#35777;&#30340;&#22238;&#24402;&#38382;&#39064;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;&#36825;&#31181;&#26041;&#27861;&#21033;&#29992;&#22238;&#24402;&#26641;&#21644;&#38543;&#26426;&#26862;&#26519;&#35757;&#32451;&#26469;&#21019;&#24314;&#26368;&#31895;&#31961;&#30340;&#29305;&#24449;&#31354;&#38388;&#21010;&#20998;&#65292;&#20197;&#36817;&#20284;&#26465;&#20214;&#35206;&#30422;&#65292;&#25552;&#20379;&#20102;&#20934;&#30830;&#12289;&#24555;&#36895;&#21644;&#33258;&#36866;&#24212;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#27169;&#22411;&#20250;&#29359;&#38169;&#65292;&#22240;&#27492;&#38656;&#35201;&#37327;&#21270;&#19982;&#20854;&#39044;&#27979;&#30456;&#20851;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#31526;&#21512;&#24615;&#25512;&#26029;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#24378;&#22823;&#30340;&#24037;&#20855;&#65292;&#21487;&#20197;&#22312;&#28857;&#39044;&#27979;&#21608;&#22260;&#21019;&#24314;&#32479;&#35745;&#19978;&#26377;&#25928;&#30340;&#39044;&#27979;&#21306;&#22495;&#65292;&#20294;&#26159;&#23427;&#22312;&#22238;&#24402;&#38382;&#39064;&#19978;&#30340;&#26420;&#32032;&#24212;&#29992;&#20250;&#20135;&#29983;&#38750;&#33258;&#36866;&#24212;&#30340;&#21306;&#22495;&#12290;&#26032;&#30340;&#31526;&#21512;&#24615;&#24471;&#20998;&#65292;&#36890;&#24120;&#20381;&#36182;&#20110;&#20998;&#20301;&#25968;&#22238;&#24402;&#22120;&#25110;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#22120;&#65292;&#26088;&#22312;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#12290;&#34429;&#28982;&#23427;&#20204;&#22312;&#21019;&#24314;&#39044;&#27979;&#24102;&#26041;&#38754;&#24456;&#26377;&#29992;&#65292;&#20294;&#36825;&#20123;&#24471;&#20998;&#19982;&#37327;&#21270;&#20219;&#24847;&#39044;&#27979;&#27169;&#22411;&#21608;&#22260;&#30340;&#19981;&#30830;&#23450;&#24615;&#30340;&#21407;&#22987;&#30446;&#26631;&#33073;&#33410;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#12289;&#19982;&#27169;&#22411;&#26080;&#20851;&#30340;&#26041;&#27861;&#26063;&#65292;&#29992;&#20110;&#26657;&#20934;&#20855;&#26377;&#23616;&#37096;&#35206;&#30422;&#20445;&#35777;&#30340;&#22238;&#24402;&#38382;&#39064;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#22522;&#20110;&#36861;&#27714;&#26368;&#31895;&#31961;&#30340;&#29305;&#24449;&#31354;&#38388;&#21010;&#20998;&#26469;&#36817;&#20284;&#26465;&#20214;&#35206;&#30422;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#31526;&#21512;&#24615;&#24471;&#20998;&#36827;&#34892;&#22238;&#24402;&#26641;&#21644;&#38543;&#26426;&#26862;&#26519;&#30340;&#35757;&#32451;&#26469;&#21019;&#24314;&#36825;&#20010;&#21010;&#20998;&#12290;&#25105;&#20204;&#30340;&#25552;&#35758;&#23558;&#22238;&#24402;&#26641;&#21644;&#38543;&#26426;&#26862;&#26519;&#24212;&#29992;&#20110;&#31526;&#21512;&#24615;&#25512;&#26029;&#30340;&#26032;&#39046;&#22495;&#65292;&#20197;&#25552;&#20379;&#20934;&#30830;&#12289;&#24555;&#36895;&#21644;&#33258;&#36866;&#24212;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Predictive models make mistakes. Hence, there is a need to quantify the uncertainty associated with their predictions. Conformal inference has emerged as a powerful tool to create statistically valid prediction regions around point predictions, but its naive application to regression problems yields non-adaptive regions. New conformal scores, often relying upon quantile regressors or conditional density estimators, aim to address this limitation. Although they are useful for creating prediction bands, these scores are detached from the original goal of quantifying the uncertainty around an arbitrary predictive model. This paper presents a new, model-agnostic family of methods to calibrate prediction intervals for regression problems with local coverage guarantees. Our approach is based on pursuing the coarsest partition of the feature space that approximates conditional coverage. We create this partition by training regression trees and Random Forests on conformity scores. Our proposal
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#39640;&#26031;&#26368;&#23567;&#26368;&#22823;&#23450;&#29702;&#65292;&#25193;&#23637;&#20102;&#32463;&#20856;&#23450;&#29702;&#23545;&#20110;&#29420;&#31435;&#20294;&#38750;&#24658;&#23450;&#20998;&#24067;&#30340;&#24773;&#20917;&#12290;&#27492;&#22806;&#65292;&#35813;&#23450;&#29702;&#22312;&#39640;&#32500;&#32479;&#35745;&#23398;&#12289;&#26426;&#22120;&#23398;&#20064;&#12289;&#38750;&#20809;&#28369;&#20248;&#21270;&#21644;&#20449;&#21495;&#22788;&#29702;&#31561;&#39046;&#22495;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.07356</link><description>&lt;p&gt;
&#19968;&#20010;&#26032;&#30340;&#39640;&#26031;&#26368;&#23567;&#26368;&#22823;&#23450;&#29702;&#21450;&#20854;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
A Novel Gaussian Min-Max Theorem and its Applications
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07356
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#39640;&#26031;&#26368;&#23567;&#26368;&#22823;&#23450;&#29702;&#65292;&#25193;&#23637;&#20102;&#32463;&#20856;&#23450;&#29702;&#23545;&#20110;&#29420;&#31435;&#20294;&#38750;&#24658;&#23450;&#20998;&#24067;&#30340;&#24773;&#20917;&#12290;&#27492;&#22806;&#65292;&#35813;&#23450;&#29702;&#22312;&#39640;&#32500;&#32479;&#35745;&#23398;&#12289;&#26426;&#22120;&#23398;&#20064;&#12289;&#38750;&#20809;&#28369;&#20248;&#21270;&#21644;&#20449;&#21495;&#22788;&#29702;&#31561;&#39046;&#22495;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Gordon&#30340;&#19968;&#20010;&#33879;&#21517;&#32467;&#26524;&#20801;&#35768;&#27604;&#36739;&#20004;&#20010;&#39640;&#26031;&#36807;&#31243;&#30340;&#26368;&#23567;&#26368;&#22823;&#34892;&#20026;&#65292;&#22914;&#26524;&#28385;&#36275;&#26576;&#20123;&#19981;&#31561;&#24335;&#26465;&#20214;&#12290;&#36825;&#20010;&#32467;&#26524;&#30340;&#32467;&#26524;&#21253;&#25324;&#39640;&#26031;&#26368;&#23567;&#26368;&#22823;&#65288;GMT&#65289;&#21644;&#20984;&#39640;&#26031;&#26368;&#23567;&#26368;&#22823;&#65288;CGMT&#65289;&#23450;&#29702;&#65292;&#36825;&#20123;&#23450;&#29702;&#22312;&#39640;&#32500;&#32479;&#35745;&#23398;&#12289;&#26426;&#22120;&#23398;&#20064;&#12289;&#38750;&#20809;&#28369;&#20248;&#21270;&#21644;&#20449;&#21495;&#22788;&#29702;&#26041;&#38754;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;&#30446;&#21069;&#20026;&#27490;&#65292;&#27809;&#26377;&#21457;&#29616;&#28385;&#36275;&#36825;&#20123;&#19981;&#31561;&#24335;&#30340;&#20854;&#20182;&#19968;&#23545;&#39640;&#26031;&#36807;&#31243;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#36825;&#26679;&#19968;&#23545;&#26032;&#30340;&#39640;&#26031;&#36807;&#31243;&#12290;&#30001;&#27492;&#24471;&#21040;&#30340;&#23450;&#29702;&#23558;&#32463;&#20856;&#30340;GMT&#23450;&#29702;&#21644;CGMT&#23450;&#29702;&#20174;&#22522;&#26412;&#36807;&#31243;&#20013;&#30340;&#24213;&#23618;&#39640;&#26031;&#30697;&#38453;&#20855;&#26377;iid&#34892;&#30340;&#24773;&#20917;&#25193;&#23637;&#21040;&#20855;&#26377;&#29420;&#31435;&#20294;&#38750;&#24658;&#23450;&#20998;&#24067;&#30340;&#24773;&#20917;&#12290;&#26032;&#30340;CGMT&#23450;&#29702;&#24212;&#29992;&#20110;&#22810;&#28304;&#39640;&#26031;&#22238;&#24402;&#38382;&#39064;&#65292;&#20197;&#21450;&#23646;&#20110;&#30340;&#20108;&#20803;&#20998;&#31867;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
A celebrated result by Gordon allows one to compare the min-max behavior of two Gaussian processes if certain inequality conditions are met. The consequences of this result include the Gaussian min-max (GMT) and convex Gaussian min-max (CGMT) theorems which have had far-reaching implications in high-dimensional statistics, machine learning, non-smooth optimization, and signal processing. Both theorems rely on a pair of Gaussian processes, first identified by Slepian, that satisfy Gordon's comparison inequalities. To date, no other pair of Gaussian processes satisfying these inequalities has been discovered. In this paper, we identify such a new pair. The resulting theorems extend the classical GMT and CGMT Theorems from the case where the underlying Gaussian matrix in the primary process has iid rows to where it has independent but non-identically-distributed ones. The new CGMT is applied to the problems of multi-source Gaussian regression, as well as to binary classification of genera
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#22343;&#22330;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243; (SDE) &#30340;&#31283;&#24577;&#20998;&#24067;&#20013;&#37319;&#26679;&#30340;&#22797;&#26434;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#32806;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;&#22810;&#31181;&#24773;&#20917;&#19979;&#25552;&#20379;&#25913;&#36827;&#30340;&#20445;&#35777;&#65292;&#21253;&#25324;&#22312;&#22343;&#22330;&#21306;&#22495;&#20248;&#21270;&#26576;&#20123;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26356;&#22909;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.07355</link><description>&lt;p&gt;
&#20174;&#22343;&#22330;&#31283;&#24577;&#20998;&#24067;&#20013;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Sampling from the Mean-Field Stationary Distribution
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07355
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#22343;&#22330;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243; (SDE) &#30340;&#31283;&#24577;&#20998;&#24067;&#20013;&#37319;&#26679;&#30340;&#22797;&#26434;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#32806;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;&#22810;&#31181;&#24773;&#20917;&#19979;&#25552;&#20379;&#25913;&#36827;&#30340;&#20445;&#35777;&#65292;&#21253;&#25324;&#22312;&#22343;&#22330;&#21306;&#22495;&#20248;&#21270;&#26576;&#20123;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26356;&#22909;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20174;&#22343;&#22330;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243; (SDE) &#30340;&#31283;&#24577;&#20998;&#24067;&#20013;&#37319;&#26679;&#30340;&#22797;&#26434;&#24615;&#65292;&#25110;&#32773;&#31561;&#20215;&#22320;&#65292;&#21363;&#21253;&#21547;&#20132;&#20114;&#39033;&#30340;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#19978;&#30340;&#26368;&#23567;&#21270;&#20989;&#25968;&#30340;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#27934;&#23519;&#26159;&#23558;&#36825;&#20010;&#38382;&#39064;&#30340;&#20004;&#20010;&#20851;&#38190;&#26041;&#38754;&#35299;&#32806;&#65306;(1) &#36890;&#36807;&#26377;&#38480;&#31890;&#23376;&#31995;&#32479;&#36924;&#36817;&#22343;&#22330;SDE&#65292;&#36890;&#36807;&#26102;&#38388;&#22343;&#21248;&#20256;&#25773;&#28151;&#27788;&#65292;&#21644;(2) &#36890;&#36807;&#26631;&#20934;&#23545;&#25968;&#20985;&#25277;&#26679;&#22120;&#20174;&#26377;&#38480;&#31890;&#23376;&#31283;&#24577;&#20998;&#24067;&#20013;&#37319;&#26679;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#27010;&#24565;&#19978;&#26356;&#31616;&#21333;&#65292;&#20854;&#28789;&#27963;&#24615;&#20801;&#35768;&#32467;&#21512;&#29992;&#20110;&#31639;&#27861;&#21644;&#29702;&#35770;&#30340;&#26368;&#26032;&#25216;&#26415;&#12290;&#36825;&#23548;&#33268;&#22312;&#35768;&#22810;&#35774;&#32622;&#20013;&#25552;&#20379;&#20102;&#25913;&#36827;&#30340;&#20445;&#35777;&#65292;&#21253;&#25324;&#22312;&#22343;&#22330;&#21306;&#22495;&#20248;&#21270;&#26576;&#20123;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26356;&#22909;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the complexity of sampling from the stationary distribution of a mean-field SDE, or equivalently, the complexity of minimizing a functional over the space of probability measures which includes an interaction term.   Our main insight is to decouple the two key aspects of this problem: (1) approximation of the mean-field SDE via a finite-particle system, via uniform-in-time propagation of chaos, and (2) sampling from the finite-particle stationary distribution, via standard log-concave samplers. Our approach is conceptually simpler and its flexibility allows for incorporating the state-of-the-art for both algorithms and theory. This leads to improved guarantees in numerous settings, including better guarantees for optimizing certain two-layer neural networks in the mean-field regime.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#32447;&#24615;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#20013;&#26410;&#30693;&#22122;&#22768;&#27700;&#24179;&#30340;&#33258;&#36866;&#24212;&#32622;&#20449;&#21306;&#38388;&#65292;&#19982;&#24050;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#22312;&#32500;&#24230;&#36739;&#22823;&#26102;&#20855;&#26377;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;&#27492;&#22806;&#65292;&#38024;&#23545;&#26377;&#30028;&#22870;&#21169;&#65292;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#24046;&#33258;&#36866;&#24212;&#32622;&#20449;&#21306;&#38388;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#25968;&#20540;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.07341</link><description>&lt;p&gt;
&#23545;&#32447;&#24615;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#30340;&#22122;&#22768;&#33258;&#36866;&#24212;&#32622;&#20449;&#21306;&#38388;&#21450;&#20854;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Noise-Adaptive Confidence Sets for Linear Bandits and Application to Bayesian Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07341
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#32447;&#24615;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#20013;&#26410;&#30693;&#22122;&#22768;&#27700;&#24179;&#30340;&#33258;&#36866;&#24212;&#32622;&#20449;&#21306;&#38388;&#65292;&#19982;&#24050;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#22312;&#32500;&#24230;&#36739;&#22823;&#26102;&#20855;&#26377;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;&#27492;&#22806;&#65292;&#38024;&#23545;&#26377;&#30028;&#22870;&#21169;&#65292;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#24046;&#33258;&#36866;&#24212;&#32622;&#20449;&#21306;&#38388;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#25968;&#20540;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24207;&#36143;&#20915;&#31574;&#20013;&#65292;&#36866;&#24212;&#26410;&#30693;&#22122;&#22768;&#27700;&#24179;&#26159;&#19968;&#20010;&#38750;&#24120;&#37325;&#35201;&#20294;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#65292;&#22240;&#20026;&#26377;&#25928;&#30340;&#25506;&#32034;&#36890;&#24120;&#38656;&#35201;&#23545;&#22122;&#22768;&#27700;&#24179;&#26377;&#19968;&#23450;&#30340;&#20102;&#35299;&#65292;&#32780;&#22122;&#22768;&#27700;&#24179;&#36890;&#24120;&#21482;&#33021;&#31895;&#30053;&#22320;&#25351;&#23450;&#12290;&#25105;&#20204;&#22312;&#32447;&#24615;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#20027;&#35201;&#26377;&#20004;&#26041;&#38754;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#35813;&#32622;&#20449;&#21306;&#38388;&#22312;&#26410;&#30693;&#30340;&#20122;&#39640;&#26031;&#21442;&#25968;&#963;_*^2&#19978;&#26159;&#8220;&#21322;&#33258;&#36866;&#24212;&#8221;&#30340;&#65292;&#24847;&#21619;&#30528;&#65288;&#24402;&#19968;&#21270;&#30340;&#65289;&#32622;&#20449;&#23485;&#24230;&#19982;&#8730;&#65288;d&#963;_*^2 + &#963;_0^2&#65289;&#25104;&#27491;&#27604;&#65292;&#20854;&#20013;d&#20026;&#32500;&#24230;&#65292;&#963;_0^2&#20026;&#25351;&#23450;&#30340;&#65288;&#24050;&#30693;&#65289;&#20122;&#39640;&#26031;&#21442;&#25968;&#65292;&#20854;&#20540;&#21487;&#33021;&#27604;&#963;_*^2&#22823;&#24471;&#22810;&#12290;&#30456;&#27604;&#20110;Abbasi-Yadkori&#31561;&#20154;&#65288;2011&#65289;&#30340;&#26631;&#20934;&#32622;&#20449;&#21306;&#38388;&#30340;&#8730;&#65288;d&#963;_0^2&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;&#29305;&#21035;&#26159;&#24403;d&#36739;&#22823;&#26102;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#23548;&#33268;&#20102;&#32447;&#24615;&#24378;&#21270;&#23398;&#20064;&#20013;&#25913;&#36827;&#30340;&#21518;&#24724;&#36793;&#30028;&#12290;&#20854;&#27425;&#65292;&#23545;&#20110;&#26377;&#30028;&#22870;&#21169;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#24046;&#33258;&#36866;&#24212;&#32622;&#20449;&#21306;&#38388;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#25968;&#20540;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adapting to a priori unknown noise level is a very important but challenging problem in sequential decision-making as efficient exploration typically requires knowledge of the noise level, which is often loosely specified. We report significant progress in addressing this issue in linear bandits in two respects. First, we propose a novel confidence set that is `semi-adaptive' to the unknown sub-Gaussian parameter $\sigma_*^2$ in the sense that the (normalized) confidence width scales with $\sqrt{d\sigma_*^2 + \sigma_0^2}$ where $d$ is the dimension and $\sigma_0^2$ is the specified sub-Gaussian parameter (known) that can be much larger than $\sigma_*^2$. This is a significant improvement over $\sqrt{d\sigma_0^2}$ of the standard confidence set of Abbasi-Yadkori et al. (2011), especially when $d$ is large. We show that this leads to an improved regret bound in linear bandits. Second, for bounded rewards, we propose a novel variance-adaptive confidence set that has a much improved numeri
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22270;&#23545;&#40784;&#38382;&#39064;&#20013;&#65292;&#36890;&#36807;&#22270;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#39640;&#27010;&#29575;&#24674;&#22797;&#27491;&#30830;&#30340;&#39030;&#28857;&#23545;&#40784;&#12290;&#36890;&#36807;&#29305;&#23450;&#30340;&#29305;&#24449;&#31232;&#30095;&#24615;&#21644;&#22122;&#22768;&#27700;&#24179;&#26465;&#20214;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#19982;&#30452;&#25509;&#21305;&#37197;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;</title><link>https://arxiv.org/abs/2402.07340</link><description>&lt;p&gt;
&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#23545;&#38543;&#26426;&#20960;&#20309;&#22270;&#36827;&#34892;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Random Geometric Graph Alignment with Graph Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07340
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22270;&#23545;&#40784;&#38382;&#39064;&#20013;&#65292;&#36890;&#36807;&#22270;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#39640;&#27010;&#29575;&#24674;&#22797;&#27491;&#30830;&#30340;&#39030;&#28857;&#23545;&#40784;&#12290;&#36890;&#36807;&#29305;&#23450;&#30340;&#29305;&#24449;&#31232;&#30095;&#24615;&#21644;&#22122;&#22768;&#27700;&#24179;&#26465;&#20214;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#19982;&#30452;&#25509;&#21305;&#37197;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#39030;&#28857;&#29305;&#24449;&#20449;&#24687;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#22270;&#23545;&#40784;&#38382;&#39064;&#20013;&#30340;&#24615;&#33021;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#32473;&#23450;&#20004;&#20010;&#29420;&#31435;&#25200;&#21160;&#30340;&#21333;&#20010;&#38543;&#26426;&#20960;&#20309;&#22270;&#20197;&#21450;&#22122;&#22768;&#31232;&#30095;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#65292;&#20219;&#21153;&#26159;&#24674;&#22797;&#20004;&#20010;&#22270;&#30340;&#39030;&#28857;&#20043;&#38388;&#30340;&#26410;&#30693;&#19968;&#23545;&#19968;&#26144;&#23556;&#20851;&#31995;&#12290;&#25105;&#20204;&#35777;&#26126;&#22312;&#29305;&#24449;&#21521;&#37327;&#30340;&#31232;&#30095;&#24615;&#21644;&#22122;&#22768;&#27700;&#24179;&#28385;&#36275;&#19968;&#23450;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#32463;&#36807;&#31934;&#24515;&#35774;&#35745;&#30340;&#21333;&#23618;&#22270;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#22312;&#24456;&#39640;&#30340;&#27010;&#29575;&#19979;&#36890;&#36807;&#22270;&#32467;&#26500;&#26469;&#24674;&#22797;&#27491;&#30830;&#30340;&#39030;&#28857;&#23545;&#40784;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#22122;&#22768;&#27700;&#24179;&#30340;&#26465;&#20214;&#19978;&#30028;&#65292;&#20165;&#23384;&#22312;&#23545;&#25968;&#22240;&#23376;&#24046;&#36317;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#19982;&#30452;&#25509;&#22312;&#22122;&#22768;&#39030;&#28857;&#29305;&#24449;&#19978;&#27714;&#35299;&#20998;&#37197;&#38382;&#39064;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#22122;&#22768;&#27700;&#24179;&#33267;&#23569;&#20026;&#24120;&#25968;&#26102;&#65292;&#36825;&#31181;&#30452;&#25509;&#21305;&#37197;&#20250;&#23548;&#33268;&#24674;&#22797;&#19981;&#23436;&#20840;&#65292;&#32780;&#22270;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23481;&#24525;n
&lt;/p&gt;
&lt;p&gt;
We characterize the performance of graph neural networks for graph alignment problems in the presence of vertex feature information. More specifically, given two graphs that are independent perturbations of a single random geometric graph with noisy sparse features, the task is to recover an unknown one-to-one mapping between the vertices of the two graphs. We show under certain conditions on the sparsity and noise level of the feature vectors, a carefully designed one-layer graph neural network can with high probability recover the correct alignment between the vertices with the help of the graph structure. We also prove that our conditions on the noise level are tight up to logarithmic factors. Finally we compare the performance of the graph neural network to directly solving an assignment problem on the noisy vertex features. We demonstrate that when the noise level is at least constant this direct matching fails to have perfect recovery while the graph neural network can tolerate n
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20174;&#29702;&#35770;&#23618;&#38754;&#20998;&#26512;&#20102;&#19968;&#31181;&#20851;&#20110;&#19968;&#33324;&#20559;&#22909;&#19979;&#32435;&#20160;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#20004;&#20010;&#31454;&#20105;&#30340;LLM&#36827;&#34892;&#21338;&#24328;&#26469;&#25214;&#21040;&#19968;&#31181;&#19968;&#33268;&#29983;&#25104;&#21709;&#24212;&#30340;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2402.07314</link><description>&lt;p&gt;
&#19968;&#31181;&#20851;&#20110;&#19968;&#33324;KL&#27491;&#21017;&#21270;&#20559;&#22909;&#19979;&#32435;&#20160;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#30340;&#29702;&#35770;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Theoretical Analysis of Nash Learning from Human Feedback under General KL-Regularized Preference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07314
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20174;&#29702;&#35770;&#23618;&#38754;&#20998;&#26512;&#20102;&#19968;&#31181;&#20851;&#20110;&#19968;&#33324;&#20559;&#22909;&#19979;&#32435;&#20160;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#20004;&#20010;&#31454;&#20105;&#30340;LLM&#36827;&#34892;&#21338;&#24328;&#26469;&#25214;&#21040;&#19968;&#31181;&#19968;&#33268;&#29983;&#25104;&#21709;&#24212;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26469;&#33258;&#20154;&#31867;&#21453;&#39304;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RLHF&#65289;&#20174;&#19968;&#20010;&#27010;&#29575;&#20559;&#22909;&#27169;&#22411;&#25552;&#20379;&#30340;&#20559;&#22909;&#20449;&#21495;&#20013;&#23398;&#20064;&#65292;&#35813;&#27169;&#22411;&#20197;&#19968;&#20010;&#25552;&#31034;&#21644;&#20004;&#20010;&#21709;&#24212;&#20316;&#20026;&#36755;&#20837;&#65292;&#24182;&#20135;&#29983;&#19968;&#20010;&#20998;&#25968;&#65292;&#34920;&#31034;&#23545;&#19968;&#20010;&#21709;&#24212;&#30456;&#23545;&#20110;&#21478;&#19968;&#20010;&#21709;&#24212;&#30340;&#20559;&#22909;&#31243;&#24230;&#12290;&#36804;&#20170;&#20026;&#27490;&#65292;&#26368;&#27969;&#34892;&#30340;RLHF&#33539;&#24335;&#26159;&#22522;&#20110;&#22870;&#21169;&#30340;&#65292;&#23427;&#20174;&#22870;&#21169;&#24314;&#27169;&#30340;&#21021;&#22987;&#27493;&#39588;&#24320;&#22987;&#65292;&#28982;&#21518;&#20351;&#29992;&#26500;&#24314;&#30340;&#22870;&#21169;&#20026;&#21518;&#32493;&#30340;&#22870;&#21169;&#20248;&#21270;&#38454;&#27573;&#25552;&#20379;&#22870;&#21169;&#20449;&#21495;&#12290;&#28982;&#32780;&#65292;&#22870;&#21169;&#20989;&#25968;&#30340;&#23384;&#22312;&#26159;&#19968;&#20010;&#24378;&#20551;&#35774;&#65292;&#22522;&#20110;&#22870;&#21169;&#30340;RLHF&#22312;&#34920;&#36798;&#33021;&#21147;&#19978;&#26377;&#23616;&#38480;&#24615;&#65292;&#19981;&#33021;&#25429;&#25417;&#21040;&#30495;&#23454;&#19990;&#30028;&#20013;&#22797;&#26434;&#30340;&#20154;&#31867;&#20559;&#22909;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20026;&#26368;&#36817;&#25552;&#20986;&#30340;&#23398;&#20064;&#33539;&#24335;Nash&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#65288;NLHF&#65289;&#25552;&#20379;&#20102;&#29702;&#35770;&#27934;&#23519;&#21147;&#65292;&#35813;&#23398;&#20064;&#33539;&#24335;&#32771;&#34385;&#20102;&#19968;&#20010;&#19968;&#33324;&#30340;&#20559;&#22909;&#27169;&#22411;&#65292;&#24182;&#23558;&#23545;&#40784;&#36807;&#31243;&#23450;&#20041;&#20026;&#20004;&#20010;&#31454;&#20105;&#30340;LLM&#20043;&#38388;&#30340;&#21338;&#24328;&#12290;&#23398;&#20064;&#30446;&#26631;&#26159;&#25214;&#21040;&#19968;&#20010;&#19968;&#33268;&#29983;&#25104;&#21709;&#24212;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning from Human Feedback (RLHF) learns from the preference signal provided by a probabilistic preference model, which takes a prompt and two responses as input, and produces a score indicating the preference of one response against another. So far, the most popular RLHF paradigm is reward-based, which starts with an initial step of reward modeling, and the constructed reward is then used to provide a reward signal for the subsequent reward optimization stage. However, the existence of a reward function is a strong assumption and the reward-based RLHF is limited in expressivity and cannot capture the real-world complicated human preference.   In this work, we provide theoretical insights for a recently proposed learning paradigm, Nash learning from human feedback (NLHF), which considered a general preference model and formulated the alignment process as a game between two competitive LLMs. The learning objective is to find a policy that consistently generates responses
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;HyperBERT&#27169;&#22411;&#65292;&#36890;&#36807;&#22312;&#39044;&#35757;&#32451;&#30340;BERT&#27169;&#22411;&#20013;&#24341;&#20837;&#36229;&#22270;&#24863;&#30693;&#23618;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#26041;&#27861;&#22312;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#19978;&#38590;&#20197;&#25429;&#25417;&#36229;&#22270;&#32467;&#26500;&#20449;&#24687;&#21644;&#25991;&#26412;&#23646;&#24615;&#30340;&#23616;&#38480;&#24615;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#25928;&#26524;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.07309</link><description>&lt;p&gt;
HyperBERT:&#23558;&#28151;&#21512;&#36229;&#22270;&#24863;&#30693;&#23618;&#19982;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#25991;&#26412;&#23646;&#24615;&#36229;&#22270;&#19978;&#30340;&#33410;&#28857;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
HyperBERT: Mixing Hypergraph-Aware Layers with Language Models for Node Classification on Text-Attributed Hypergraphs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07309
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;HyperBERT&#27169;&#22411;&#65292;&#36890;&#36807;&#22312;&#39044;&#35757;&#32451;&#30340;BERT&#27169;&#22411;&#20013;&#24341;&#20837;&#36229;&#22270;&#24863;&#30693;&#23618;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#26041;&#27861;&#22312;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#19978;&#38590;&#20197;&#25429;&#25417;&#36229;&#22270;&#32467;&#26500;&#20449;&#24687;&#21644;&#25991;&#26412;&#23646;&#24615;&#30340;&#23616;&#38480;&#24615;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#25928;&#26524;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36229;&#22270;&#36890;&#36807;&#22797;&#26434;&#30340;&#25299;&#25169;&#32467;&#26500;&#26631;&#35760;&#65292;&#34920;&#36798;&#22810;&#20010;&#23454;&#20307;&#20043;&#38388;&#30340;&#39640;&#38454;&#30456;&#20114;&#20316;&#29992;&#65292;&#20854;&#20013;&#36229;&#36793;&#25198;&#28436;&#37325;&#35201;&#35282;&#33394;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#36229;&#22270;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#22312;&#23398;&#20064;&#25991;&#26412;&#23646;&#24615;&#36229;&#22270;&#19978;&#30340;&#33410;&#28857;&#20998;&#31867;&#38382;&#39064;&#20013;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#30740;&#31350;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#24448;&#24448;&#38590;&#20197;&#21516;&#26102;&#25429;&#25417;&#36229;&#22270;&#32467;&#26500;&#20449;&#24687;&#30340;&#20840;&#37096;&#20869;&#23481;&#21644;&#33410;&#28857;&#23646;&#24615;&#20013;&#30340;&#20016;&#23500;&#35821;&#35328;&#23646;&#24615;&#65292;&#36825;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#24433;&#21709;&#20102;&#23427;&#20204;&#30340;&#25928;&#26524;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#22914;&#20309;&#36890;&#36807;&#20026;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#36827;&#19968;&#27493;&#22686;&#24378;&#39044;&#35757;&#32451;&#30340;BERT&#27169;&#22411;&#65292;&#24341;&#20837;&#19987;&#38376;&#30340;&#36229;&#22270;&#24863;&#30693;&#23618;&#12290;&#36825;&#20123;&#23618;&#23558;&#39640;&#38454;&#32467;&#26500;&#24402;&#32435;&#20559;&#24046;&#24341;&#20837;&#35821;&#35328;&#27169;&#22411;&#20013;&#65292;&#20174;&#32780;&#25552;&#39640;&#27169;&#22411;&#21033;&#29992;&#36229;&#22270;&#32467;&#26500;&#20013;&#30340;&#39640;&#38454;&#19978;&#19979;&#25991;&#20449;&#24687;&#21644;&#25991;&#26412;&#20013;&#30340;&#35821;&#20041;&#20449;&#24687;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hypergraphs are marked by complex topology, expressing higher-order interactions among multiple entities with hyperedges. Lately, hypergraph-based deep learning methods to learn informative data representations for the problem of node classification on text-attributed hypergraphs have garnered increasing research attention. However, existing methods struggle to simultaneously capture the full extent of hypergraph structural information and the rich linguistic attributes inherent in the nodes attributes, which largely hampers their effectiveness and generalizability. To overcome these challenges, we explore ways to further augment a pretrained BERT model with specialized hypergraph-aware layers for the task of node classification. Such layers introduce higher-order structural inductive bias into the language model, thus improving the model's capacity to harness both higher-order context information from the hypergraph structure and semantic information present in text. In this paper, we
&lt;/p&gt;</description></item><item><title>&#33258;&#27965;&#30340;&#31526;&#21512;&#39044;&#27979;&#26041;&#27861;&#33021;&#22815;&#25552;&#20379;&#26082;&#31526;&#21512;&#26657;&#20934;&#30340;&#39044;&#27979;&#21448;&#31526;&#21512;&#20197;&#27169;&#22411;&#39044;&#27979;&#30340;&#21160;&#20316;&#20026;&#26465;&#20214;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#20026;&#20915;&#31574;&#32773;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#12289;&#38024;&#23545;&#20855;&#20307;&#21160;&#20316;&#30340;&#20915;&#31574;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.07307</link><description>&lt;p&gt;
&#33258;&#27965;&#30340;&#31526;&#21512;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Self-Consistent Conformal Prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07307
&lt;/p&gt;
&lt;p&gt;
&#33258;&#27965;&#30340;&#31526;&#21512;&#39044;&#27979;&#26041;&#27861;&#33021;&#22815;&#25552;&#20379;&#26082;&#31526;&#21512;&#26657;&#20934;&#30340;&#39044;&#27979;&#21448;&#31526;&#21512;&#20197;&#27169;&#22411;&#39044;&#27979;&#30340;&#21160;&#20316;&#20026;&#26465;&#20214;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#20026;&#20915;&#31574;&#32773;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#12289;&#38024;&#23545;&#20855;&#20307;&#21160;&#20316;&#30340;&#20915;&#31574;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#25351;&#23548;&#19979;&#30340;&#20915;&#31574;&#20013;&#65292;&#20915;&#31574;&#32773;&#36890;&#24120;&#22312;&#20855;&#26377;&#30456;&#21516;&#39044;&#27979;&#32467;&#26524;&#30340;&#24773;&#22659;&#20013;&#37319;&#21462;&#30456;&#21516;&#30340;&#34892;&#21160;&#12290;&#31526;&#21512;&#39044;&#27979;&#24110;&#21161;&#20915;&#31574;&#32773;&#37327;&#21270;&#21160;&#20316;&#30340;&#32467;&#26524;&#19981;&#30830;&#23450;&#24615;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#22909;&#30340;&#39118;&#38505;&#31649;&#29702;&#12290;&#21463;&#36825;&#31181;&#35266;&#28857;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#33258;&#27965;&#30340;&#31526;&#21512;&#39044;&#27979;&#65292;&#23427;&#20135;&#29983;&#20102;&#26082;&#31526;&#21512;Venn-Abers&#26657;&#20934;&#30340;&#39044;&#27979;&#65292;&#21448;&#31526;&#21512;&#20197;&#27169;&#22411;&#39044;&#27979;&#24341;&#21457;&#30340;&#21160;&#20316;&#20026;&#26465;&#20214;&#30340;&#31526;&#21512;&#39044;&#27979;&#21306;&#38388;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#21518;&#39564;&#22320;&#24212;&#29992;&#20110;&#20219;&#20309;&#40657;&#30418;&#39044;&#27979;&#22120;&#65292;&#25552;&#20379;&#20005;&#26684;&#30340;&#12289;&#38024;&#23545;&#20855;&#20307;&#21160;&#20316;&#30340;&#20915;&#31574;&#20445;&#35777;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21306;&#38388;&#30340;&#25928;&#29575;&#21644;&#26465;&#20214;&#30340;&#26377;&#25928;&#24615;&#20043;&#38388;&#36798;&#21040;&#20102;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
In decision-making guided by machine learning, decision-makers often take identical actions in contexts with identical predicted outcomes. Conformal prediction helps decision-makers quantify outcome uncertainty for actions, allowing for better risk management. Inspired by this perspective, we introduce self-consistent conformal prediction, which yields both Venn-Abers calibrated predictions and conformal prediction intervals that are valid conditional on actions prompted by model predictions. Our procedure can be applied post-hoc to any black-box predictor to provide rigorous, action-specific decision-making guarantees. Numerical experiments show our approach strikes a balance between interval efficiency and conditional validity.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#20272;&#35745;&#20960;&#20309;&#36951;&#20256;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#30340;&#28151;&#21512;&#31995;&#25968;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#28385;&#36275;&#29305;&#23450;&#26465;&#20214;&#21644;&#26080;&#38656;&#23494;&#24230;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#24471;&#21040;&#20102;&#20272;&#35745;&#22120;&#30340;&#39044;&#26399;&#35823;&#24046;&#25910;&#25947;&#36895;&#24230;&#21644;&#39640;&#27010;&#29575;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.07296</link><description>&lt;p&gt;
&#20272;&#35745;&#20960;&#20309;&#36951;&#20256;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#30340;&#28151;&#21512;&#31995;&#25968;
&lt;/p&gt;
&lt;p&gt;
Estimating the Mixing Coefficients of Geometrically Ergodic Markov Processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07296
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#20272;&#35745;&#20960;&#20309;&#36951;&#20256;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#30340;&#28151;&#21512;&#31995;&#25968;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#28385;&#36275;&#29305;&#23450;&#26465;&#20214;&#21644;&#26080;&#38656;&#23494;&#24230;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#24471;&#21040;&#20102;&#20272;&#35745;&#22120;&#30340;&#39044;&#26399;&#35823;&#24046;&#25910;&#25947;&#36895;&#24230;&#21644;&#39640;&#27010;&#29575;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#20272;&#35745;&#23454;&#20540;&#20960;&#20309;&#36951;&#20256;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#30340;&#21333;&#20010;&#946;-&#28151;&#21512;&#31995;&#25968;&#20174;&#19968;&#20010;&#21333;&#19968;&#30340;&#26679;&#26412;&#36335;&#24452;X0&#65292;X1&#65292;...&#65292;Xn&#12290;&#22312;&#23545;&#23494;&#24230;&#30340;&#26631;&#20934;&#20809;&#28369;&#26465;&#20214;&#19979;&#65292;&#21363;&#23545;&#20110;&#27599;&#20010;m&#65292;&#23545;$(X_0,X_m)$&#23545;&#30340;&#32852;&#21512;&#23494;&#24230;&#37117;&#23646;&#20110;&#26576;&#20010;&#24050;&#30693;$s&gt;0$&#30340; Besov &#31354;&#38388;$B^s_{1,\infty}(\mathbb R^2)$&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#25105;&#20204;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#30340;&#20272;&#35745;&#22120;&#30340;&#39044;&#26399;&#35823;&#24046;&#30340;&#25910;&#25947;&#36895;&#24230;&#20026;$\mathcal{O}(\log(n) n^{-[s]/(2[s]+2)})$ &#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#20272;&#35745;&#35823;&#24046;&#30340;&#39640;&#27010;&#29575;&#30028;&#38480;&#36827;&#34892;&#20102;&#34917;&#20805;&#65292;&#24182;&#22312;&#29366;&#24577;&#31354;&#38388;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#33719;&#24471;&#20102;&#36825;&#20123;&#30028;&#38480;&#30340;&#31867;&#27604;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#19981;&#38656;&#35201;&#23494;&#24230;&#30340;&#20551;&#35774;&#65307;&#39044;&#26399;&#35823;&#24046;&#29575;&#26174;&#31034;&#20026;$\mathcal O(\log(
&lt;/p&gt;
&lt;p&gt;
We propose methods to estimate the individual $\beta$-mixing coefficients of a real-valued geometrically ergodic Markov process from a single sample-path $X_0,X_1, \dots,X_n$. Under standard smoothness conditions on the densities, namely, that the joint density of the pair $(X_0,X_m)$ for each $m$ lies in a Besov space $B^s_{1,\infty}(\mathbb R^2)$ for some known $s&gt;0$, we obtain a rate of convergence of order $\mathcal{O}(\log(n) n^{-[s]/(2[s]+2)})$ for the expected error of our estimator in this case\footnote{We use $[s]$ to denote the integer part of the decomposition $s=[s]+\{s\}$ of $s \in (0,\infty)$ into an integer term and a {\em strictly positive} remainder term $\{s\} \in (0,1]$.}. We complement this result with a high-probability bound on the estimation error, and further obtain analogues of these bounds in the case where the state-space is finite. Naturally no density assumptions are required in this setting; the expected error rate is shown to be of order $\mathcal O(\log(
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30740;&#31350;&#28145;&#24230;2&#21644;&#28145;&#24230;3&#31070;&#32463;&#32593;&#32476;&#22312;&#36924;&#36817;Lipschitz&#30446;&#26631;&#20989;&#25968;&#26102;&#30340;&#20998;&#31163;&#24615;&#36136;&#65292;&#35777;&#26126;&#20102;&#32500;&#24230;&#35781;&#21650;&#20063;&#20250;&#22312;&#28145;&#24230;2&#36924;&#36817;&#20013;&#23384;&#22312;&#65292;&#21363;&#20351;&#30446;&#26631;&#20989;&#25968;&#21487;&#20197;&#20351;&#29992;&#28145;&#24230;3&#39640;&#25928;&#34920;&#31034;&#12290;&#36825;&#20026;&#20197;&#21069;&#30830;&#23450;&#28145;&#24230;&#35201;&#27714;&#30340;&#19979;&#30028;&#25552;&#20379;&#20102;&#26032;&#30340;&#35266;&#28857;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#22810;&#31181;&#28608;&#27963;&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2402.07248</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#28145;&#24230;&#20998;&#31163;&#65306;&#23558;&#32500;&#24230;&#19982;&#20934;&#30830;&#24230;&#20998;&#31163;
&lt;/p&gt;
&lt;p&gt;
Depth Separations in Neural Networks: Separating the Dimension from the Accuracy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07248
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#28145;&#24230;2&#21644;&#28145;&#24230;3&#31070;&#32463;&#32593;&#32476;&#22312;&#36924;&#36817;Lipschitz&#30446;&#26631;&#20989;&#25968;&#26102;&#30340;&#20998;&#31163;&#24615;&#36136;&#65292;&#35777;&#26126;&#20102;&#32500;&#24230;&#35781;&#21650;&#20063;&#20250;&#22312;&#28145;&#24230;2&#36924;&#36817;&#20013;&#23384;&#22312;&#65292;&#21363;&#20351;&#30446;&#26631;&#20989;&#25968;&#21487;&#20197;&#20351;&#29992;&#28145;&#24230;3&#39640;&#25928;&#34920;&#31034;&#12290;&#36825;&#20026;&#20197;&#21069;&#30830;&#23450;&#28145;&#24230;&#35201;&#27714;&#30340;&#19979;&#30028;&#25552;&#20379;&#20102;&#26032;&#30340;&#35266;&#28857;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#22810;&#31181;&#28608;&#27963;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#28145;&#24230;2&#21644;&#28145;&#24230;3&#31070;&#32463;&#32593;&#32476;&#22312;&#36924;&#36817;&#19968;&#20010;$\mathcal{O}(1)$-Lipschitz&#30446;&#26631;&#20989;&#25968;&#33267;&#24120;&#25968;&#31934;&#24230;&#26102;&#30340;&#25351;&#25968;&#20998;&#31163;&#65292;&#23545;&#20110;&#25903;&#25345;&#22312;$[0,1]^{d}$&#19978;&#30340;&#20998;&#24067;&#65292;&#20551;&#35774;&#26435;&#37325;&#25351;&#25968;&#26377;&#30028;&#12290;&#36825;&#35299;&#20915;&#20102;&#22312;\citet{safran2019depth}&#20013;&#25552;&#20986;&#30340;&#19968;&#20010;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#32500;&#24230;&#35781;&#21650;&#22312;&#28145;&#24230;2&#36924;&#36817;&#20013;&#30340;&#23384;&#22312;&#65292;&#21363;&#20351;&#22312;&#30446;&#26631;&#20989;&#25968;&#21487;&#20197;&#20351;&#29992;&#28145;&#24230;3&#39640;&#25928;&#34920;&#31034;&#30340;&#24773;&#20917;&#19979;&#20063;&#26159;&#22914;&#27492;&#12290;&#20197;&#21069;&#65292;&#23558;&#28145;&#24230;2&#21644;&#28145;&#24230;3&#20998;&#31163;&#30340;&#19979;&#30028;&#35201;&#27714;&#33267;&#23569;&#26377;&#19968;&#20010;Lipschitz&#21442;&#25968;&#12289;&#30446;&#26631;&#20934;&#30830;&#24230;&#25110;&#36924;&#36817;&#22495;&#30340;&#22823;&#23567;&#65288;&#26576;&#31181;&#24230;&#37327;&#65289;&#19982;&#36755;&#20837;&#32500;&#24230;&#22810;&#39033;&#24335;&#22320;&#32553;&#25918;&#65292;&#32780;&#25105;&#20204;&#20445;&#25345;&#21069;&#20004;&#32773;&#19981;&#21464;&#65292;&#24182;&#23558;&#25105;&#20204;&#30340;&#22495;&#38480;&#21046;&#22312;&#21333;&#20301;&#36229;&#31435;&#26041;&#20307;&#19978;&#12290;&#25105;&#20204;&#30340;&#19979;&#30028;&#36866;&#29992;&#20110;&#21508;&#31181;&#28608;&#27963;&#20989;&#25968;&#65292;&#24182;&#22522;&#20110;&#19968;&#31181;&#26032;&#30340;&#24179;&#22343;&#24773;&#20917;&#21040;&#26368;&#22351;&#24773;&#20917;&#30340;&#38543;&#26426;&#33258;&#32422;&#21270;&#35770;&#35777;&#30340;&#24212;&#29992;&#65292;&#20197;&#20943;&#23569;
&lt;/p&gt;
&lt;p&gt;
We prove an exponential separation between depth 2 and depth 3 neural networks, when approximating an $\mathcal{O}(1)$-Lipschitz target function to constant accuracy, with respect to a distribution with support in $[0,1]^{d}$, assuming exponentially bounded weights. This addresses an open problem posed in \citet{safran2019depth}, and proves that the curse of dimensionality manifests in depth 2 approximation, even in cases where the target function can be represented efficiently using depth 3. Previously, lower bounds that were used to separate depth 2 from depth 3 required that at least one of the Lipschitz parameter, target accuracy or (some measure of) the size of the domain of approximation scale polynomially with the input dimension, whereas we fix the former two and restrict our domain to the unit hypercube. Our lower bound holds for a wide variety of activation functions, and is based on a novel application of an average- to worst-case random self-reducibility argument, to reduce
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#20013;&#36827;&#34892;&#24555;&#36895;&#38543;&#26426;&#37319;&#26679;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#20998;&#35010;&#31215;&#20998;&#22120;&#36827;&#34892;&#21407;&#21017;&#24615;&#20462;&#25913;&#65292;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#37319;&#26679;&#25928;&#29575;&#12290;&#22312;CIFAR-10&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;100&#27425;&#32593;&#32476;&#20989;&#25968;&#35780;&#20272;&#19979;&#30340;FID&#20998;&#25968;&#20026;2.36&#12290;</title><link>https://arxiv.org/abs/2402.07211</link><description>&lt;p&gt;
&#38754;&#21521;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#30340;&#24555;&#36895;&#38543;&#26426;&#37319;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Towards Fast Stochastic Sampling in Diffusion Generative Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07211
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#20013;&#36827;&#34892;&#24555;&#36895;&#38543;&#26426;&#37319;&#26679;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#20998;&#35010;&#31215;&#20998;&#22120;&#36827;&#34892;&#21407;&#21017;&#24615;&#20462;&#25913;&#65292;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#37319;&#26679;&#25928;&#29575;&#12290;&#22312;CIFAR-10&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;100&#27425;&#32593;&#32476;&#20989;&#25968;&#35780;&#20272;&#19979;&#30340;FID&#20998;&#25968;&#20026;2.36&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#25512;&#29702;&#26102;&#29983;&#25104;&#26679;&#26412;&#30340;&#36895;&#24230;&#36739;&#24930;&#12290;&#23613;&#31649;&#26368;&#36817;&#26377;&#19968;&#20123;&#21162;&#21147;&#22312;&#25913;&#21892;&#25193;&#25955;&#27169;&#22411;&#30340;&#38543;&#26426;&#37319;&#26679;&#25928;&#29575;&#65292;&#20294;&#20173;&#28982;&#26377;&#24453;&#25913;&#36827;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#20998;&#35010;&#31215;&#20998;&#22120;&#30340;&#39044;&#35757;&#32451;&#25193;&#25955;&#27169;&#22411;&#30340;&#24555;&#36895;&#38543;&#26426;&#37319;&#26679;&#26041;&#27861;&#12290;&#20998;&#35010;&#31215;&#20998;&#22120;&#36890;&#24120;&#22312;&#20998;&#23376;&#21160;&#21147;&#23398;&#20013;&#20351;&#29992;&#65292;&#36890;&#36807;&#24039;&#22937;&#22320;&#22312;&#28041;&#21450;&#25968;&#25454;&#12289;&#36741;&#21161;&#25110;&#22122;&#22768;&#21464;&#37327;&#30340;&#25968;&#20540;&#26356;&#26032;&#20043;&#38388;&#20132;&#26367;&#26469;&#25552;&#39640;&#37319;&#26679;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#23545;&#20110;&#24555;&#36895;&#37319;&#26679;&#65292;&#31616;&#21333;&#24212;&#29992;&#20998;&#35010;&#31215;&#20998;&#22120;&#26159;&#27425;&#20248;&#30340;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#31181;&#21407;&#21017;&#19978;&#20462;&#25913;&#20102;&#31616;&#21333;&#20998;&#35010;&#37319;&#26679;&#22120;&#20197;&#25552;&#39640;&#37319;&#26679;&#25928;&#29575;&#30340;&#26041;&#27861;&#65292;&#24182;&#23558;&#24471;&#21040;&#30340;&#37319;&#26679;&#22120;&#31216;&#20026;&#20943;&#23567;&#20998;&#35010;&#31215;&#20998;&#22120;&#12290;&#22312;CIFAR-10&#25968;&#25454;&#38598;&#19978;&#20351;&#29992;&#30456;&#31354;&#38388;&#26391;&#20043;&#19975;&#25193;&#25955; (PSLD) [Pandey \&amp; Mandt, 2023] &#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#30340;&#38543;&#26426;&#37319;&#26679;&#22120;&#22312;&#20165;&#36827;&#34892;100&#27425;&#32593;&#32476;&#20989;&#25968;&#35780;&#20272;&#21518;&#65292;&#23454;&#29616;&#20102;2.36&#30340;FID&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models suffer from slow sample generation at inference time. Despite recent efforts, improving the sampling efficiency of stochastic samplers for diffusion models remains a promising direction. We propose Splitting Integrators for fast stochastic sampling in pre-trained diffusion models in augmented spaces. Commonly used in molecular dynamics, splitting-based integrators attempt to improve sampling efficiency by cleverly alternating between numerical updates involving the data, auxiliary, or noise variables. However, we show that a naive application of splitting integrators is sub-optimal for fast sampling. Consequently, we propose several principled modifications to naive splitting samplers for improving sampling efficiency and denote the resulting samplers as Reduced Splitting Integrators. In the context of Phase Space Langevin Diffusion (PSLD) [Pandey \&amp; Mandt, 2023] on CIFAR-10, our stochastic sampler achieves an FID score of 2.36 in only 100 network function evaluations 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#23545;&#31216;&#24615;&#30340;&#23384;&#22312;&#36827;&#34892;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;&#26799;&#24230;&#22122;&#22768;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#30340;&#38544;&#24615;&#20559;&#35265;&#12290;&#25105;&#20204;&#21457;&#29616;&#19981;&#21516;&#31867;&#22411;&#30340;&#23545;&#31216;&#24615;&#20250;&#23548;&#33268;&#19981;&#21516;&#30340;&#23398;&#20064;&#21160;&#24577;&#65292;&#20854;&#20013;&#19968;&#31867;&#23545;&#31216;&#24615;&#21487;&#20197;&#33258;&#28982;&#25910;&#25947;&#65292;&#32780;&#21478;&#19968;&#31867;&#23545;&#31216;&#24615;&#20960;&#20046;&#24635;&#26159;&#21457;&#25955;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#36866;&#29992;&#20110;&#27809;&#26377;&#23545;&#31216;&#24615;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#23545;&#20110;&#29702;&#35299;&#35757;&#32451;&#21160;&#24577;&#21644;&#35299;&#37322;&#30456;&#20851;&#23454;&#38469;&#38382;&#39064;&#20855;&#26377;&#26222;&#36866;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.07193</link><description>&lt;p&gt;
&#26799;&#24230;&#22122;&#22768;&#30340;&#38544;&#24615;&#20559;&#35265;&#65306;&#20174;&#23545;&#31216;&#24615;&#35282;&#24230;&#26469;&#30475;
&lt;/p&gt;
&lt;p&gt;
The Implicit Bias of Gradient Noise: A Symmetry Perspective
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07193
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#23545;&#31216;&#24615;&#30340;&#23384;&#22312;&#36827;&#34892;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;&#26799;&#24230;&#22122;&#22768;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#30340;&#38544;&#24615;&#20559;&#35265;&#12290;&#25105;&#20204;&#21457;&#29616;&#19981;&#21516;&#31867;&#22411;&#30340;&#23545;&#31216;&#24615;&#20250;&#23548;&#33268;&#19981;&#21516;&#30340;&#23398;&#20064;&#21160;&#24577;&#65292;&#20854;&#20013;&#19968;&#31867;&#23545;&#31216;&#24615;&#21487;&#20197;&#33258;&#28982;&#25910;&#25947;&#65292;&#32780;&#21478;&#19968;&#31867;&#23545;&#31216;&#24615;&#20960;&#20046;&#24635;&#26159;&#21457;&#25955;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#36866;&#29992;&#20110;&#27809;&#26377;&#23545;&#31216;&#24615;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#23545;&#20110;&#29702;&#35299;&#35757;&#32451;&#21160;&#24577;&#21644;&#35299;&#37322;&#30456;&#20851;&#23454;&#38469;&#38382;&#39064;&#20855;&#26377;&#26222;&#36866;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#22312;&#25439;&#22833;&#20989;&#25968;&#23384;&#22312;&#36830;&#32493;&#23545;&#31216;&#24615;&#26102;&#30340;&#23398;&#20064;&#21160;&#24577;&#36827;&#34892;&#20102;&#34920;&#24449;&#65292;&#35828;&#26126;&#20102;SGD&#21644;&#26799;&#24230;&#19979;&#38477;&#20043;&#38388;&#30340;&#20998;&#27495;&#26159;&#22810;&#20040;&#24040;&#22823;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26681;&#25454;&#23545;&#31216;&#24615;&#23545;&#23398;&#20064;&#21160;&#24577;&#30340;&#24433;&#21709;&#26041;&#24335;&#65292;&#25105;&#20204;&#21487;&#20197;&#23558;&#19968;&#26063;&#23545;&#31216;&#24615;&#20998;&#20026;&#20004;&#31867;&#12290;&#23545;&#20110;&#19968;&#31867;&#23545;&#31216;&#24615;&#65292;SGD&#33258;&#28982;&#22320;&#25910;&#25947;&#21040;&#20855;&#26377;&#24179;&#34913;&#21644;&#23545;&#40784;&#26799;&#24230;&#22122;&#22768;&#30340;&#35299;&#12290;&#23545;&#20110;&#21478;&#19968;&#31867;&#23545;&#31216;&#24615;&#65292;SGD&#20960;&#20046;&#24635;&#26159;&#21457;&#25955;&#30340;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21363;&#20351;&#25439;&#22833;&#20989;&#25968;&#20013;&#27809;&#26377;&#23545;&#31216;&#24615;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#20381;&#28982;&#36866;&#29992;&#24182;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#29702;&#35299;&#35757;&#32451;&#21160;&#24577;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#26222;&#36941;&#30340;&#65292;&#23427;&#21482;&#20381;&#36182;&#20110;&#23545;&#31216;&#24615;&#30340;&#23384;&#22312;&#65292;&#32780;&#19982;&#25439;&#22833;&#20989;&#25968;&#30340;&#32454;&#33410;&#26080;&#20851;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#29702;&#35770;&#23545;&#20110;&#36880;&#27493;&#21464;&#24418;&#21644;&#24179;&#22374;&#21270;&#25552;&#20379;&#20102;&#35299;&#37322;&#65292;&#24182;&#21487;&#20197;&#24212;&#29992;&#20110;&#24120;&#35265;&#30340;&#23454;&#38469;&#38382;&#39064;&#65292;&#22914;&#34920;&#31034;&#27491;&#21017;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We characterize the learning dynamics of stochastic gradient descent (SGD) when continuous symmetry exists in the loss function, where the divergence between SGD and gradient descent is dramatic. We show that depending on how the symmetry affects the learning dynamics, we can divide a family of symmetry into two classes. For one class of symmetry, SGD naturally converges to solutions that have a balanced and aligned gradient noise. For the other class of symmetry, SGD will almost always diverge. Then, we show that our result remains applicable and can help us understand the training dynamics even when the symmetry is not present in the loss function. Our main result is universal in the sense that it only depends on the existence of the symmetry and is independent of the details of the loss function. We demonstrate that the proposed theory offers an explanation of progressive sharpening and flattening and can be applied to common practical problems such as representation normalization, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;CP-E2LSH&#21644;TT-E2LSH&#20004;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#25913;&#36827;&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;&#31639;&#27861;LSH&#65292;&#22312;&#22788;&#29702;&#24352;&#37327;&#25968;&#25454;&#30340;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#21644;&#20313;&#24358;&#30456;&#20284;&#24230;&#26102;&#33021;&#22815;&#25552;&#20379;&#26356;&#24555;&#21644;&#26356;&#31354;&#38388;&#26377;&#25928;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.07189</link><description>&lt;p&gt;
&#36890;&#36807;&#24352;&#37327;&#21270;&#38543;&#26426;&#25237;&#24433;&#25913;&#36827;&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;LSH
&lt;/p&gt;
&lt;p&gt;
Improving LSH via Tensorized Random Projection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07189
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;CP-E2LSH&#21644;TT-E2LSH&#20004;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#25913;&#36827;&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;&#31639;&#27861;LSH&#65292;&#22312;&#22788;&#29702;&#24352;&#37327;&#25968;&#25454;&#30340;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#21644;&#20313;&#24358;&#30456;&#20284;&#24230;&#26102;&#33021;&#22815;&#25552;&#20379;&#26356;&#24555;&#21644;&#26356;&#31354;&#38388;&#26377;&#25928;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;(LSH)&#26159;&#25968;&#25454;&#31185;&#23398;&#23478;&#29992;&#20110;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;&#38382;&#39064;&#30340;&#22522;&#26412;&#31639;&#27861;&#24037;&#20855;&#65292;&#24050;&#22312;&#35768;&#22810;&#22823;&#35268;&#27169;&#25968;&#25454;&#22788;&#29702;&#24212;&#29992;&#20013;&#24191;&#27867;&#20351;&#29992;&#65292;&#22914;&#36817;&#20284;&#37325;&#22797;&#26816;&#27979;&#12289;&#26368;&#36817;&#37051;&#25628;&#32034;&#12289;&#32858;&#31867;&#31561;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#25552;&#20986;&#26356;&#24555;&#21644;&#31354;&#38388;&#26356;&#26377;&#25928;&#30340;&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;&#20989;&#25968;&#65292;&#29992;&#20110;&#24352;&#37327;&#25968;&#25454;&#30340;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#21644;&#20313;&#24358;&#30456;&#20284;&#24230;&#12290;&#36890;&#24120;&#65292;&#23545;&#20110;&#24352;&#37327;&#25968;&#25454;&#33719;&#24471;LSH&#30340;&#26420;&#32032;&#26041;&#27861;&#28041;&#21450;&#23558;&#24352;&#37327;&#37325;&#22609;&#20026;&#21521;&#37327;&#65292;&#28982;&#21518;&#24212;&#29992;&#29616;&#26377;&#30340;&#21521;&#37327;&#25968;&#25454;LSH&#26041;&#27861;(E2LSH&#21644;SRP)&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#39640;&#38454;&#24352;&#37327;&#65292;&#36825;&#31181;&#26041;&#27861;&#21464;&#24471;&#19981;&#20999;&#23454;&#38469;&#65292;&#22240;&#20026;&#37325;&#22609;&#21521;&#37327;&#30340;&#22823;&#23567;&#22312;&#24352;&#37327;&#30340;&#38454;&#25968;&#20013;&#21576;&#25351;&#25968;&#22686;&#38271;&#12290;&#22240;&#27492;&#65292;LSH&#21442;&#25968;&#30340;&#22823;&#23567;&#21576;&#25351;&#25968;&#22686;&#21152;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#21644;&#20313;&#24358;&#30456;&#20284;&#24230;&#30340;LSH&#26041;&#27861;&#65292;&#20998;&#21035;&#26159;CP-E2LSH&#21644;TT-E2LSH&#12290;
&lt;/p&gt;
&lt;p&gt;
Locality sensitive hashing (LSH) is a fundamental algorithmic toolkit used by data scientists for approximate nearest neighbour search problems that have been used extensively in many large scale data processing applications such as near duplicate detection, nearest neighbour search, clustering, etc. In this work, we aim to propose faster and space efficient locality sensitive hash functions for Euclidean distance and cosine similarity for tensor data. Typically, the naive approach for obtaining LSH for tensor data involves first reshaping the tensor into vectors, followed by applying existing LSH methods for vector data $E2LSH$ and $SRP$. However, this approach becomes impractical for higher order tensors because the size of the reshaped vector becomes exponential in the order of the tensor. Consequently, the size of LSH parameters increases exponentially. To address this problem, we suggest two methods for LSH for Euclidean distance and cosine similarity, namely $CP-E2LSH$, $TT-E2LSH
&lt;/p&gt;</description></item><item><title>PASOA&#26159;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#31243;&#24207;&#65292;&#36890;&#36807;&#25552;&#20379;&#36830;&#32493;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;&#20934;&#30830;&#20272;&#35745;&#65292;&#21516;&#26102;&#25191;&#34892;&#39034;&#24207;&#35774;&#35745;&#20248;&#21270;&#21644;&#21442;&#25968;&#25512;&#26029;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992; stochastic optimization &#21644; tempered SMC &#26469;&#26368;&#22823;&#21270;&#26399;&#26395;&#20449;&#24687;&#22686;&#30410;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#33268;&#24615;&#30340;&#26368;&#20248;&#35774;&#35745;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.07160</link><description>&lt;p&gt;
PASOA-&#22522;&#20110;&#31890;&#23376;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#33258;&#36866;&#24212;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
PASOA- PArticle baSed Bayesian Optimal Adaptive design
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07160
&lt;/p&gt;
&lt;p&gt;
PASOA&#26159;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#31243;&#24207;&#65292;&#36890;&#36807;&#25552;&#20379;&#36830;&#32493;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;&#20934;&#30830;&#20272;&#35745;&#65292;&#21516;&#26102;&#25191;&#34892;&#39034;&#24207;&#35774;&#35745;&#20248;&#21270;&#21644;&#21442;&#25968;&#25512;&#26029;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992; stochastic optimization &#21644; tempered SMC &#26469;&#26368;&#22823;&#21270;&#26399;&#26395;&#20449;&#24687;&#22686;&#30410;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#33268;&#24615;&#30340;&#26368;&#20248;&#35774;&#35745;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PASOA&#30340;&#26032;&#31243;&#24207;&#65292;&#29992;&#20110;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#65292;&#36890;&#36807;&#21516;&#26102;&#25552;&#20379;&#36830;&#32493;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;&#20934;&#30830;&#20272;&#35745;&#26469;&#25191;&#34892;&#39034;&#24207;&#35774;&#35745;&#20248;&#21270;&#12290;&#39034;&#24207;&#35774;&#35745;&#36807;&#31243;&#36890;&#36807;&#23545;&#27604;&#20272;&#35745;&#21407;&#21017;&#36827;&#34892;&#65292;&#20351;&#29992;&#38543;&#26426;&#20248;&#21270;&#21644;&#39034;&#24207;&#33945;&#29305;&#21345;&#32599;&#65288;SMC&#65289;&#37319;&#26679;&#22120;&#26469;&#26368;&#22823;&#21270;&#26399;&#26395;&#20449;&#24687;&#22686;&#30410;&#65288;EIG&#65289;&#12290;&#30001;&#20110;&#36830;&#32493;&#21518;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#36317;&#31163;&#36234;&#22823;&#65292;&#33719;&#24471;&#30340;&#20449;&#24687;&#22686;&#30410;&#36234;&#22823;&#65292;&#22240;&#27492;&#36825;&#20010;EIG&#30446;&#26631;&#21487;&#33021;&#20250;&#24694;&#21270;&#32463;&#20856;SMC&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#28201;&#24230;&#35843;&#33410;&#65292;&#26082;&#21487;&#20197;&#33719;&#24471;&#22823;&#30340;&#20449;&#24687;&#22686;&#30410;&#65292;&#21448;&#21487;&#20197;&#33719;&#24471;&#20934;&#30830;&#30340;SMC&#37319;&#26679;&#65292;&#25105;&#20204;&#35777;&#26126;&#36825;&#23545;&#24615;&#33021;&#26469;&#35828;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#36825;&#31181;&#38543;&#26426;&#20248;&#21270;&#21644;&#28201;&#24230;&#35843;&#33410;&#30340;&#26032;&#39062;&#32452;&#21512;&#20801;&#35768;&#21516;&#26102;&#22788;&#29702;&#35774;&#35745;&#20248;&#21270;&#21644;&#21442;&#25968;&#25512;&#26029;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#24471;&#21040;&#30340;&#26368;&#20248;&#35774;&#35745;&#20272;&#35745;&#37327;&#20855;&#26377;&#19968;&#33268;&#24615;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#30456;&#21516;&#35745;&#31639;&#39044;&#31639;&#19979;&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#22909;&#22320;&#20248;&#21270;&#20102;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new procedure named PASOA, for Bayesian experimental design, that performs sequential design optimization by simultaneously providing accurate estimates of successive posterior distributions for parameter inference. The sequential design process is carried out via a contrastive estimation principle, using stochastic optimization and Sequential Monte Carlo (SMC) samplers to maximise the Expected Information Gain (EIG). As larger information gains are obtained for larger distances between successive posterior distributions, this EIG objective may worsen classical SMC performance. To handle this issue, tempering is proposed to have both a large information gain and an accurate SMC sampling, that we show is crucial for performance. This novel combination of stochastic optimization and tempered SMC allows to jointly handle design optimization and parameter inference. We provide a proof that the obtained optimal design estimators benefit from some consistency property. Numerical
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#20004;&#31181;&#31169;&#26377;&#21464;&#20307;&#30340;&#38750;&#21442;&#25968;bootstrap&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#24046;&#20998;&#38544;&#31169;&#30340;&#24773;&#20917;&#19979;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#12290;&#26041;&#27861;&#22312;&#35745;&#31639;&#25928;&#29575;&#21644;&#32622;&#20449;&#21306;&#38388;&#38271;&#24230;&#19978;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#26377;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2402.07131</link><description>&lt;p&gt;
&#38024;&#23545;&#31169;&#26377;&#32479;&#35745;&#25512;&#26029;&#30340;&#37325;&#37319;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Resampling methods for Private Statistical Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07131
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#20004;&#31181;&#31169;&#26377;&#21464;&#20307;&#30340;&#38750;&#21442;&#25968;bootstrap&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#24046;&#20998;&#38544;&#31169;&#30340;&#24773;&#20917;&#19979;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#12290;&#26041;&#27861;&#22312;&#35745;&#31639;&#25928;&#29575;&#21644;&#32622;&#20449;&#21306;&#38388;&#38271;&#24230;&#19978;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#26377;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#30340;&#20219;&#21153;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#31169;&#26377;&#21464;&#20307;&#30340;&#38750;&#21442;&#25968;bootstrap&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#25968;&#25454;&#30340;&#20998;&#21306;&#19978;&#31169;&#19979;&#35745;&#31639;&#22810;&#20010;&#8220;&#23567;&#8221;bootstrap&#30340;&#32467;&#26524;&#30340;&#20013;&#20301;&#25968;&#65292;&#24182;&#32473;&#20986;&#20102;&#24471;&#21040;&#30340;&#32622;&#20449;&#21306;&#38388;&#30340;&#28176;&#36827;&#35206;&#30422;&#35823;&#24046;&#19978;&#30028;&#12290;&#23545;&#20110;&#22266;&#23450;&#30340;&#24046;&#20998;&#38544;&#31169;&#21442;&#25968;&#949;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26679;&#26412;&#22823;&#23567;n&#19978;&#30340;&#35823;&#24046;&#29575;&#19982;&#38750;&#31169;&#26377;bootstrap&#30456;&#24403;&#65292;&#21482;&#26159;&#22312;&#23545;&#25968;&#22240;&#23376;&#20869;&#12290;&#25105;&#20204;&#20351;&#29992;&#30495;&#23454;&#25968;&#25454;&#21644;&#21512;&#25104;&#25968;&#25454;&#22312;&#22343;&#20540;&#20272;&#35745;&#12289;&#20013;&#20301;&#25968;&#20272;&#35745;&#21644;&#36923;&#36753;&#22238;&#24402;&#26041;&#38754;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#32463;&#39564;&#39564;&#35777;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25552;&#20379;&#31867;&#20284;&#30340;&#35206;&#30422;&#31934;&#24230;&#30340;&#21516;&#26102;&#65292;&#27604;&#20197;&#21069;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#26174;&#33879;&#32553;&#30701;&#65288;&#22823;&#32422;10&#20493;&#65289;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the task of constructing confidence intervals with differential privacy. We propose two private variants of the non-parametric bootstrap, which privately compute the median of the results of multiple ``little'' bootstraps run on partitions of the data and give asymptotic bounds on the coverage error of the resulting confidence intervals. For a fixed differential privacy parameter $\epsilon$, our methods enjoy the same error rates as that of the non-private bootstrap to within logarithmic factors in the sample size $n$. We empirically validate the performance of our methods for mean estimation, median estimation, and logistic regression with both real and synthetic data. Our methods achieve similar coverage accuracy to existing methods (and non-private baselines) while providing notably shorter ($\gtrsim 10$ times) confidence intervals than previous approaches.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#37327;&#21270;&#20102;Adam&#30340;&#39044;&#26465;&#20214;&#25928;&#24212;&#65292;&#32467;&#26524;&#34920;&#26126;Adam&#33021;&#22815;&#20943;&#36731;&#30149;&#24577;&#26465;&#20214;&#30340;&#24433;&#21709;&#65292;&#20294;&#20250;&#21463;&#21040;&#32500;&#24230;&#30340;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2402.07114</link><description>&lt;p&gt;
&#23545;Adam&#30340;&#39044;&#26465;&#20214;&#25928;&#24212;&#36827;&#34892;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Towards Quantifying the Preconditioning Effect of Adam
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07114
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#37327;&#21270;&#20102;Adam&#30340;&#39044;&#26465;&#20214;&#25928;&#24212;&#65292;&#32467;&#26524;&#34920;&#26126;Adam&#33021;&#22815;&#20943;&#36731;&#30149;&#24577;&#26465;&#20214;&#30340;&#24433;&#21709;&#65292;&#20294;&#20250;&#21463;&#21040;&#32500;&#24230;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;Adam&#30340;&#39044;&#26465;&#20214;&#25928;&#24212;&#36827;&#34892;&#20102;&#35814;&#32454;&#20998;&#26512;&#65292;&#24182;&#37327;&#21270;&#20102;Adam&#22312;&#20943;&#36731;&#30149;&#24577;&#26465;&#20214;&#65288;&#22256;&#25200;&#26799;&#24230;&#19979;&#38477;&#27861;&#65289;&#19978;&#30340;&#20316;&#29992;&#31243;&#24230;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#21457;&#29616;&#26159;&#65292;Adam&#22312;&#30149;&#24577;&#26465;&#20214;&#19978;&#33021;&#22815;&#20943;&#23569;&#20381;&#36182;&#20110;Hessian&#30697;&#38453;&#26465;&#20214;&#25968;&#30340;&#31243;&#24230;&#65292;&#20294;&#20195;&#20215;&#26159;&#20250;&#21463;&#21040;&#19982;&#32500;&#24230;&#26377;&#20851;&#30340;&#22240;&#32032;&#24433;&#21709;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#23545;&#20110;&#19968;&#20010;&#20855;&#26377;&#23545;&#35282;Hessian&#30697;&#38453;&#12289;&#26465;&#20214;&#25968;&#20026;&#954;&#30340;d&#32500;&#20108;&#27425;&#20989;&#25968;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#27809;&#26377;&#21160;&#37327;&#30340;Adam&#20013;&#65292;&#25511;&#21046;&#36845;&#20195;&#22797;&#26434;&#24230;&#30340;&#26377;&#25928;&#26465;&#20214;&#25968;&#31867;&#20284;&#37327;&#20026;O(min(d, &#954;))&#12290;&#23545;&#20110;&#19968;&#20010;&#23545;&#35282;&#21344;&#20248;&#30340;Hessian&#30697;&#38453;&#65292;&#25105;&#20204;&#33719;&#24471;&#30456;&#24212;&#37327;&#30340;&#19978;&#30028;&#20026;O(min(d&#8730;(d&#954;), &#954;))&#12290;&#22240;&#27492;&#65292;&#24403;d &lt; O(&#954;^p)&#65292;&#20854;&#20013;p = 1&#36866;&#29992;&#20110;&#23545;&#35282;Hessian&#30697;&#38453;&#26102;&#65292;&#25105;&#20204;&#21487;&#20197;&#24471;&#21040;&#36825;&#31181;&#37327;&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is a notable dearth of results characterizing the preconditioning effect of Adam and showing how it may alleviate the curse of ill-conditioning -- an issue plaguing gradient descent (GD). In this work, we perform a detailed analysis of Adam's preconditioning effect for quadratic functions and quantify to what extent Adam can mitigate the dependence on the condition number of the Hessian. Our key finding is that Adam can suffer less from the condition number but at the expense of suffering a dimension-dependent quantity. Specifically, for a $d$-dimensional quadratic with a diagonal Hessian having condition number $\kappa$, we show that the effective condition number-like quantity controlling the iteration complexity of Adam without momentum is $\mathcal{O}(\min(d, \kappa))$. For a diagonally dominant Hessian, we obtain a bound of $\mathcal{O}(\min(d \sqrt{d \kappa}, \kappa))$ for the corresponding quantity. Thus, when $d &lt; \mathcal{O}(\kappa^p)$ where $p = 1$ for a diagonal Hessia
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#29983;&#25104;&#27169;&#22411;&#35757;&#32451;&#26102;&#21487;&#33021;&#20986;&#29616;&#30340;&#33258;&#25105;&#28040;&#32791;&#24490;&#29615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24341;&#20837;&#29702;&#24819;&#30340;&#20462;&#27491;&#20989;&#25968;&#26469;&#31283;&#23450;&#35757;&#32451;&#30340;&#26041;&#27861;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#33258;&#25105;&#20462;&#27491;&#20989;&#25968;&#26469;&#36817;&#20284;&#29702;&#24819;&#30340;&#20462;&#27491;&#20989;&#25968;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.07087</link><description>&lt;p&gt;
&#33258;&#25105;&#32416;&#27491;&#33258;&#25105;&#28040;&#32791;&#24490;&#29615;&#29992;&#20110;&#29983;&#25104;&#27169;&#22411;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Self-Correcting Self-Consuming Loops for Generative Model Training
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07087
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#29983;&#25104;&#27169;&#22411;&#35757;&#32451;&#26102;&#21487;&#33021;&#20986;&#29616;&#30340;&#33258;&#25105;&#28040;&#32791;&#24490;&#29615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24341;&#20837;&#29702;&#24819;&#30340;&#20462;&#27491;&#20989;&#25968;&#26469;&#31283;&#23450;&#35757;&#32451;&#30340;&#26041;&#27861;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#33258;&#25105;&#20462;&#27491;&#20989;&#25968;&#26469;&#36817;&#20284;&#29702;&#24819;&#30340;&#20462;&#27491;&#20989;&#25968;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#21512;&#25104;&#25968;&#25454;&#22312;&#20114;&#32852;&#32593;&#19978;&#30340;&#36136;&#37327;&#36234;&#26469;&#36234;&#39640;&#20197;&#21450;&#25968;&#37327;&#19981;&#26029;&#22686;&#21152;&#65292;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#36234;&#26469;&#36234;&#22810;&#22320;&#22312;&#20154;&#24037;&#21644;&#26426;&#22120;&#29983;&#25104;&#30340;&#25968;&#25454;&#30340;&#28151;&#21512;&#19978;&#36827;&#34892;&#35757;&#32451;&#12290;&#23613;&#31649;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#34920;&#24449;&#23398;&#20064;&#30340;&#25104;&#21151;&#26696;&#20363;&#26377;&#24456;&#22810;&#65292;&#20294;&#26159;&#22312;&#29983;&#25104;&#27169;&#22411;&#35757;&#32451;&#20013;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#20250;&#20135;&#29983;"&#33258;&#25105;&#28040;&#32791;&#24490;&#29615;"&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#35757;&#32451;&#19981;&#31283;&#23450;&#29978;&#33267;&#23849;&#28291;&#65292;&#38500;&#38750;&#28385;&#36275;&#26576;&#20123;&#26465;&#20214;&#12290;&#25105;&#20204;&#30340;&#35770;&#25991;&#26088;&#22312;&#31283;&#23450;&#33258;&#25105;&#28040;&#32791;&#30340;&#29983;&#25104;&#27169;&#22411;&#35757;&#32451;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#29702;&#24819;&#30340;&#20462;&#27491;&#20989;&#25968;&#65292;&#23558;&#25968;&#25454;&#28857;&#26144;&#23556;&#20026;&#26356;&#26377;&#21487;&#33021;&#26469;&#33258;&#30495;&#23454;&#25968;&#25454;&#20998;&#24067;&#30340;&#26679;&#26412;&#65292;&#21487;&#20197;&#20351;&#33258;&#25105;&#28040;&#32791;&#24490;&#29615;&#30340;&#31283;&#23450;&#24615;&#21576;&#25351;&#25968;&#22686;&#21152;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#33258;&#25105;&#20462;&#27491;&#20989;&#25968;&#65292;&#23427;&#20381;&#36182;&#20110;&#19987;&#23478;&#30693;&#35782;&#65288;&#20363;&#22914;&#65292;&#32534;&#31243;&#22312;&#27169;&#25311;&#22120;&#20013;&#30340;&#29289;&#29702;&#23450;&#24459;&#65289;&#65292;&#24182;&#19988;&#26088;&#22312;&#33258;&#21160;&#19988;&#22823;&#35268;&#27169;&#22320;&#36817;&#20284;&#29702;&#24819;&#30340;&#20462;&#27491;&#20989;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#20102;&#33258;&#25105;&#32416;&#27491;&#33258;&#25105;&#28040;&#32791;&#24490;&#29615;&#22312;&#29983;&#25104;&#27169;&#22411;&#35757;&#32451;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
As synthetic data becomes higher quality and proliferates on the internet, machine learning models are increasingly trained on a mix of human- and machine-generated data. Despite the successful stories of using synthetic data for representation learning, using synthetic data for generative model training creates "self-consuming loops" which may lead to training instability or even collapse, unless certain conditions are met. Our paper aims to stabilize self-consuming generative model training. Our theoretical results demonstrate that by introducing an idealized correction function, which maps a data point to be more likely under the true data distribution, self-consuming loops can be made exponentially more stable. We then propose self-correction functions, which rely on expert knowledge (e.g. the laws of physics programmed in a simulator), and aim to approximate the idealized corrector automatically and at scale. We empirically validate the effectiveness of self-correcting self-consum
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#29420;&#31435;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#39532;&#23572;&#31185;&#22827;&#21338;&#24328;&#20013;&#65292;&#36890;&#36807;&#25913;&#36827;AVLPR&#26694;&#26550;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#25968;&#25454;&#20381;&#36182;&#30340;&#24754;&#35266;&#20272;&#35745;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#22810;&#26234;&#33021;&#20307;&#30340;&#35781;&#21650;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.07082</link><description>&lt;p&gt;
&#22522;&#20110;&#29420;&#31435;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#39532;&#23572;&#31185;&#22827;&#21338;&#24328;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
Refined Sample Complexity for Markov Games with Independent Linear Function Approximation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07082
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#29420;&#31435;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#39532;&#23572;&#31185;&#22827;&#21338;&#24328;&#20013;&#65292;&#36890;&#36807;&#25913;&#36827;AVLPR&#26694;&#26550;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#25968;&#25454;&#20381;&#36182;&#30340;&#24754;&#35266;&#20272;&#35745;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#22810;&#26234;&#33021;&#20307;&#30340;&#35781;&#21650;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39532;&#23572;&#31185;&#22827;&#21338;&#24328;&#65288;MG&#65289;&#26159;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65288;MARL&#65289;&#20013;&#30340;&#37325;&#35201;&#27169;&#22411;&#12290;&#38271;&#26399;&#20197;&#26469;&#20154;&#20204;&#19968;&#30452;&#35748;&#20026;&#8220;&#22810;&#26234;&#33021;&#20307;&#30340;&#35781;&#21650;&#8221;&#65288;&#21363;&#31639;&#27861;&#24615;&#33021;&#38543;&#30528;&#26234;&#33021;&#20307;&#25968;&#37327;&#25351;&#25968;&#32423;&#19979;&#38477;&#65289;&#26159;&#19981;&#21487;&#36991;&#20813;&#30340;&#65292;&#30452;&#21040;&#26368;&#36817;&#20960;&#31687;&#20316;&#21697;&#65288;Daskalakis&#31561;&#20154;&#65292;2023&#24180;&#65307;Cui&#31561;&#20154;&#65292;2023&#24180;&#65307;Wang&#31561;&#20154;&#65292;2023&#24180;&#65289;&#12290;&#36825;&#20123;&#20316;&#21697;&#30830;&#23454;&#35299;&#20915;&#20102;&#22810;&#26234;&#33021;&#20307;&#30340;&#35781;&#21650;&#65292;&#24403;&#29366;&#24577;&#31354;&#38388;&#26497;&#22823;&#19988;&#65288;&#32447;&#24615;&#65289;&#20989;&#25968;&#36924;&#36817;&#34987;&#24212;&#29992;&#26102;&#65292;&#23427;&#20204;&#35201;&#20040;&#20855;&#26377;&#26356;&#24930;&#30340;&#25910;&#25947;&#36895;&#24230;$O(T^{-1/4})$&#65292;&#35201;&#20040;&#22312;&#34892;&#21160;&#25968;$A_{\max}$&#19978;&#24102;&#26469;&#22810;&#39033;&#24335;&#20381;&#36182;&#8212;&#8212;&#23613;&#31649;&#22312;&#21333;&#26234;&#33021;&#20307;&#24773;&#20917;&#19979;&#21363;&#20351;&#25439;&#22833;&#20989;&#25968;&#21487;&#20197;&#38543;&#26102;&#38388;&#20219;&#24847;&#21464;&#21270;&#65288;Dai&#31561;&#20154;&#65292;2023&#24180;&#65289;&#65292;&#20063;&#21487;&#36991;&#20813;&#36825;&#31181;&#20381;&#36182;&#12290;&#26412;&#25991;&#39318;&#20808;&#36890;&#36807;Wang&#31561;&#20154;&#65288;2023&#24180;&#65289;&#30340;&#8220;AVLPR&#8221;&#26694;&#26550;&#31934;&#21270;&#65292;&#27934;&#23519;&#20102;&#22522;&#20110;&#25968;&#25454;&#30340;&#65288;&#21363;&#38543;&#26426;&#30340;&#65289;&#24754;&#35266;&#20272;&#35745;&#23376;&#20248;&#21270;&#24046;&#36317;&#65292;&#20174;&#32780;&#20801;&#35768;&#26356;&#24191;&#27867;&#30340;&#25554;&#20214;&#31639;&#27861;&#36873;&#25321;&#12290;&#24403;&#19987;&#38376;&#24212;&#29992;&#20110;MGs&#26102;&#65292;&#36825;&#19968;&#26041;&#27861;&#33021;&#22815;&#22788;&#29702;&#29420;&#31435;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Markov Games (MG) is an important model for Multi-Agent Reinforcement Learning (MARL). It was long believed that the "curse of multi-agents" (i.e., the algorithmic performance drops exponentially with the number of agents) is unavoidable until several recent works (Daskalakis et al., 2023; Cui et al., 2023; Wang et al., 2023. While these works did resolve the curse of multi-agents, when the state spaces are prohibitively large and (linear) function approximations are deployed, they either had a slower convergence rate of $O(T^{-1/4})$ or brought a polynomial dependency on the number of actions $A_{\max}$ -- which is avoidable in single-agent cases even when the loss functions can arbitrarily vary with time (Dai et al., 2023). This paper first refines the `AVLPR` framework by Wang et al. (2023), with an insight of *data-dependent* (i.e., stochastic) pessimistic estimation of the sub-optimality gap, allowing a broader choice of plug-in algorithms. When specialized to MGs with independent
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20984;&#20248;&#21270;&#26041;&#27861;&#21644;&#19981;&#31934;&#30830;&#39044;&#27979;&#27169;&#22411;&#30340;&#26032;UCB&#31867;&#22411;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#37325;&#21644;&#36229;&#37325;&#23545;&#31216;&#22122;&#22768;&#30340;&#38543;&#26426;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#22870;&#21169;&#20013;&#23384;&#22312;&#23545;&#31216;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#36798;&#21040;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#30456;&#27604;&#20110;&#19968;&#33324;&#19979;&#30028;&#33021;&#22815;&#33719;&#24471;&#26356;&#23567;&#30340;&#36951;&#25022;&#30028;&#12290;&#21363;&#20351;&#22870;&#21169;&#20998;&#24067;&#27809;&#26377;&#26399;&#26395;&#65292;&#35813;&#31639;&#27861;&#20173;&#28982;&#26377;&#25928;&#12290;</title><link>https://arxiv.org/abs/2402.07062</link><description>&lt;p&gt;
&#24555;&#36895;UCB&#31867;&#22411;&#31639;&#27861;&#29992;&#20110;&#20855;&#26377;&#37325;&#21644;&#36229;&#37325;&#23545;&#31216;&#22122;&#22768;&#30340;&#38543;&#26426;&#36172;&#21338;&#26426;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Fast UCB-type algorithms for stochastic bandits with heavy and super heavy symmetric noise
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07062
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20984;&#20248;&#21270;&#26041;&#27861;&#21644;&#19981;&#31934;&#30830;&#39044;&#27979;&#27169;&#22411;&#30340;&#26032;UCB&#31867;&#22411;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#37325;&#21644;&#36229;&#37325;&#23545;&#31216;&#22122;&#22768;&#30340;&#38543;&#26426;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#22870;&#21169;&#20013;&#23384;&#22312;&#23545;&#31216;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#36798;&#21040;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#30456;&#27604;&#20110;&#19968;&#33324;&#19979;&#30028;&#33021;&#22815;&#33719;&#24471;&#26356;&#23567;&#30340;&#36951;&#25022;&#30028;&#12290;&#21363;&#20351;&#22870;&#21169;&#20998;&#24067;&#27809;&#26377;&#26399;&#26395;&#65292;&#35813;&#31639;&#27861;&#20173;&#28982;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#19968;&#33324;&#20984;&#20248;&#21270;&#26041;&#27861;&#21644;&#19981;&#31934;&#30830;&#30340;&#39044;&#27979;&#27169;&#22411;&#30340;UCB&#31867;&#22411;&#31639;&#27861;&#26500;&#24314;&#26041;&#27861;&#65292;&#24182;&#25512;&#23548;&#20102;&#19982;&#20248;&#21270;&#26041;&#27861;&#25910;&#25947;&#36895;&#24230;&#30456;&#23545;&#24212;&#30340;&#36951;&#25022;&#30028;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;Clipped-SGD-UCB&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#21644;&#32463;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#22870;&#21169;&#20013;&#23384;&#22312;&#23545;&#31216;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#36798;&#21040;$O(\log T\sqrt{KT\log T})$&#30340;&#36951;&#25022;&#30028;&#65292;&#32780;&#19981;&#26159;$O\left (T^{\frac{1}{1+\alpha}} K^{\frac{\alpha}{1+\alpha}} \right)$&#65292;&#35813;&#30028;&#26159;&#24403;&#22870;&#21169;&#20998;&#24067;&#28385;&#36275;$\mathbb{E}_{X \in D}[|X|^{1+\alpha}] \leq \sigma^{1+\alpha}$&#65288;$\alpha \in (0, 1]$&#65289;&#26102;&#30340;&#19968;&#33324;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#21363;&#20351;&#22870;&#21169;&#20998;&#24067;&#27809;&#26377;&#26399;&#26395;&#65292;&#21363;&#65292;&#24403;$\alpha&lt;0$&#26102;&#65292;&#21516;&#26679;&#30340;&#30028;&#38480;&#20063;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this study, we propose a new method for constructing UCB-type algorithms for stochastic multi-armed bandits based on general convex optimization methods with an inexact oracle. We derive the regret bounds corresponding to the convergence rates of the optimization methods. We propose a new algorithm Clipped-SGD-UCB and show, both theoretically and empirically, that in the case of symmetric noise in the reward, we can achieve an $O(\log T\sqrt{KT\log T})$ regret bound instead of $O\left (T^{\frac{1}{1+\alpha}} K^{\frac{\alpha}{1+\alpha}} \right)$ for the case when the reward distribution satisfies $\mathbb{E}_{X \in D}[|X|^{1+\alpha}] \leq \sigma^{1+\alpha}$ ($\alpha \in (0, 1])$, i.e. perform better than it is assumed by the general lower bound for bandits with heavy-tails. Moreover, the same bound holds even when the reward distribution does not have the expectation, that is, when $\alpha&lt;0$.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#21033;&#29992;&#36817;&#20284;&#25439;&#22833;&#36827;&#34892;&#26679;&#26412;&#37319;&#26679;&#30340;&#35757;&#32451;&#21152;&#36895;&#26041;&#27861;&#65292;&#36890;&#36807;&#36138;&#23146;&#31574;&#30053;&#36873;&#25321;&#20855;&#26377;&#22823;&#32422;&#25439;&#22833;&#30340;&#26679;&#26412;&#65292;&#20943;&#23569;&#36873;&#25321;&#30340;&#24320;&#38144;&#65292;&#24182;&#35777;&#26126;&#20854;&#25910;&#25947;&#36895;&#24230;&#20248;&#20110;&#38543;&#26426;&#36873;&#25321;&#12290;&#21516;&#26102;&#24320;&#21457;&#20102;&#20351;&#29992;&#20013;&#38388;&#23618;&#34920;&#31034;&#33719;&#21462;&#36817;&#20284;&#25439;&#22833;&#30340;SIFT&#26041;&#27861;&#65292;&#24182;&#22312;&#35757;&#32451;BERT&#27169;&#22411;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;</title><link>https://arxiv.org/abs/2402.07052</link><description>&lt;p&gt;
&#29702;&#35299;&#36890;&#36807;&#20351;&#29992;&#36817;&#20284;&#25439;&#22833;&#36827;&#34892;&#37319;&#26679;&#30340;&#35757;&#32451;&#21152;&#36895;
&lt;/p&gt;
&lt;p&gt;
Understanding the Training Speedup from Sampling with Approximate Losses
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07052
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#21033;&#29992;&#36817;&#20284;&#25439;&#22833;&#36827;&#34892;&#26679;&#26412;&#37319;&#26679;&#30340;&#35757;&#32451;&#21152;&#36895;&#26041;&#27861;&#65292;&#36890;&#36807;&#36138;&#23146;&#31574;&#30053;&#36873;&#25321;&#20855;&#26377;&#22823;&#32422;&#25439;&#22833;&#30340;&#26679;&#26412;&#65292;&#20943;&#23569;&#36873;&#25321;&#30340;&#24320;&#38144;&#65292;&#24182;&#35777;&#26126;&#20854;&#25910;&#25947;&#36895;&#24230;&#20248;&#20110;&#38543;&#26426;&#36873;&#25321;&#12290;&#21516;&#26102;&#24320;&#21457;&#20102;&#20351;&#29992;&#20013;&#38388;&#23618;&#34920;&#31034;&#33719;&#21462;&#36817;&#20284;&#25439;&#22833;&#30340;SIFT&#26041;&#27861;&#65292;&#24182;&#22312;&#35757;&#32451;BERT&#27169;&#22411;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#36873;&#25321;&#20855;&#26377;&#36739;&#22823;&#25439;&#22833;/&#26799;&#24230;&#30340;&#26679;&#26412;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#35757;&#32451;&#27493;&#39588;&#30340;&#25968;&#37327;&#12290;&#28982;&#32780;&#65292;&#36873;&#25321;&#30340;&#24320;&#38144;&#24448;&#24448;&#36807;&#39640;&#65292;&#26080;&#27861;&#22312;&#24635;&#20307;&#35757;&#32451;&#26102;&#38388;&#26041;&#38754;&#33719;&#24471;&#26377;&#24847;&#20041;&#30340;&#25552;&#21319;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#36873;&#25321;&#20855;&#26377;&#22823;&#32422;&#25439;&#22833;&#30340;&#26679;&#26412;&#30340;&#36138;&#23146;&#26041;&#27861;&#65292;&#32780;&#19981;&#26159;&#20934;&#30830;&#25439;&#22833;&#65292;&#20197;&#20943;&#23569;&#36873;&#25321;&#30340;&#24320;&#38144;&#12290;&#23545;&#20110;&#24179;&#28369;&#20984;&#25439;&#22833;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#36138;&#23146;&#31574;&#30053;&#21487;&#20197;&#22312;&#27604;&#38543;&#26426;&#36873;&#25321;&#26356;&#23569;&#30340;&#36845;&#20195;&#27425;&#25968;&#20869;&#25910;&#25947;&#21040;&#24179;&#22343;&#25439;&#22833;&#30340;&#26368;&#23567;&#20540;&#30340;&#24120;&#25968;&#22240;&#23376;&#12290;&#25105;&#20204;&#36824;&#29702;&#35770;&#19978;&#37327;&#21270;&#20102;&#36817;&#20284;&#27700;&#24179;&#30340;&#24433;&#21709;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#20351;&#29992;&#20013;&#38388;&#23618;&#34920;&#31034;&#33719;&#21462;&#36817;&#20284;&#25439;&#22833;&#20197;&#36827;&#34892;&#26679;&#26412;&#36873;&#25321;&#30340;SIFT&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;SIFT&#22312;&#35757;&#32451;&#19968;&#20010;&#20855;&#26377;1.1&#20159;&#21442;&#25968;&#30340;12&#23618;BERT&#22522;&#30784;&#27169;&#22411;&#19978;&#30340;&#20219;&#21153;&#65292;&#24182;&#23637;&#31034;&#20102;&#26174;&#33879;&#30340;&#25552;&#21319;&#65288;&#20197;&#35757;&#32451;&#26102;&#38388;&#21644;&#21453;&#21521;&#20256;&#25773;&#27493;&#39588;&#30340;&#25968;&#37327;&#34913;&#37327;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is well known that selecting samples with large losses/gradients can significantly reduce the number of training steps. However, the selection overhead is often too high to yield any meaningful gains in terms of overall training time. In this work, we focus on the greedy approach of selecting samples with large \textit{approximate losses} instead of exact losses in order to reduce the selection overhead. For smooth convex losses, we show that such a greedy strategy can converge to a constant factor of the minimum value of the average loss in fewer iterations than the standard approach of random selection. We also theoretically quantify the effect of the approximation level. We then develop SIFT which uses early exiting to obtain approximate losses with an intermediate layer's representations for sample selection. We evaluate SIFT on the task of training a 110M parameter 12-layer BERT base model and show significant gains (in terms of training hours and number of backpropagation step
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;logistic-beta&#36807;&#31243;&#29992;&#20110;&#24314;&#27169;&#20855;&#26377;beta&#36793;&#38469;&#20998;&#24067;&#30340;&#30456;&#20851;&#38543;&#26426;&#27010;&#29575;&#12290;&#35813;&#36807;&#31243;&#20855;&#26377;&#28789;&#27963;&#30340;&#30456;&#20851;&#32467;&#26500;&#21644;&#35745;&#31639;&#20248;&#21183;&#65292;&#24182;&#36890;&#36807;&#38750;&#21442;&#25968;&#20108;&#20998;&#31867;&#22238;&#24402;&#27169;&#25311;&#30740;&#31350;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.07048</link><description>&lt;p&gt;
&#29992;&#20110;&#24314;&#27169;&#20855;&#26377;beta&#36793;&#38469;&#20998;&#24067;&#30340;&#30456;&#20851;&#38543;&#26426;&#27010;&#29575;&#30340;logistic-beta&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Logistic-beta processes for modeling dependent random probabilities with beta marginals
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07048
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;logistic-beta&#36807;&#31243;&#29992;&#20110;&#24314;&#27169;&#20855;&#26377;beta&#36793;&#38469;&#20998;&#24067;&#30340;&#30456;&#20851;&#38543;&#26426;&#27010;&#29575;&#12290;&#35813;&#36807;&#31243;&#20855;&#26377;&#28789;&#27963;&#30340;&#30456;&#20851;&#32467;&#26500;&#21644;&#35745;&#31639;&#20248;&#21183;&#65292;&#24182;&#36890;&#36807;&#38750;&#21442;&#25968;&#20108;&#20998;&#31867;&#22238;&#24402;&#27169;&#25311;&#30740;&#31350;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
beta&#20998;&#24067;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#27010;&#29575;&#24314;&#27169;&#65292;&#24182;&#22312;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#23588;&#20854;&#22312;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#39046;&#22495;&#12290;&#23613;&#31649;&#20854;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#22312;&#24314;&#27169;&#30456;&#20851;&#38543;&#26426;&#27010;&#29575;&#30340;&#28789;&#27963;&#21644;&#35745;&#31639;&#26041;&#20415;&#30340;&#38543;&#26426;&#36807;&#31243;&#25193;&#23637;&#26041;&#38754;&#65292;&#30456;&#20851;&#24037;&#20316;&#26377;&#38480;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38543;&#26426;&#36807;&#31243;&#65292;&#31216;&#20026;logistic-beta&#36807;&#31243;&#65292;&#20854;logistic&#21464;&#25442;&#29983;&#25104;&#20855;&#26377;&#24120;&#35265;beta&#36793;&#38469;&#20998;&#24067;&#30340;&#38543;&#26426;&#36807;&#31243;&#12290;&#31867;&#20284;&#20110;&#39640;&#26031;&#36807;&#31243;&#65292;logistic-beta&#36807;&#31243;&#21487;&#20197;&#24314;&#27169;&#31163;&#25955;&#21644;&#36830;&#32493;&#22495;&#65288;&#20363;&#22914;&#31354;&#38388;&#25110;&#26102;&#38388;&#65289;&#19978;&#30340;&#30456;&#20851;&#24615;&#65292;&#24182;&#36890;&#36807;&#30456;&#20851;&#26680;&#20989;&#25968;&#20855;&#26377;&#39640;&#24230;&#28789;&#27963;&#30340;&#30456;&#20851;&#32467;&#26500;&#12290;&#27492;&#22806;&#65292;&#23427;&#30340;&#27491;&#24577;&#26041;&#24046;-&#22343;&#20540;&#28151;&#21512;&#34920;&#31034;&#23548;&#33268;&#20102;&#39640;&#25928;&#30340;&#21518;&#39564;&#25512;&#29702;&#31639;&#27861;&#12290;&#36890;&#36807;&#38750;&#21442;&#25968;&#20108;&#20998;&#31867;&#22238;&#24402;&#27169;&#25311;&#30740;&#31350;&#65292;&#23637;&#31034;&#20102;logistic-beta&#36807;&#31243;&#30340;&#28789;&#27963;&#24615;&#21644;&#35745;&#31639;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
The beta distribution serves as a canonical tool for modeling probabilities and is extensively used in statistics and machine learning, especially in the field of Bayesian nonparametrics. Despite its widespread use, there is limited work on flexible and computationally convenient stochastic process extensions for modeling dependent random probabilities. We propose a novel stochastic process called the logistic-beta process, whose logistic transformation yields a stochastic process with common beta marginals. Similar to the Gaussian process, the logistic-beta process can model dependence on both discrete and continuous domains, such as space or time, and has a highly flexible dependence structure through correlation kernels. Moreover, its normal variance-mean mixture representation leads to highly effective posterior inference algorithms. The flexibility and computational benefits of logistic-beta processes are demonstrated through nonparametric binary regression simulation studies. Fur
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#22312;&#22343;&#22330;&#26497;&#38480;&#19979;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#35780;&#20272;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#36890;&#36807;&#25512;&#23548;&#20986;&#25910;&#25947;&#36895;&#24230;&#20026;$O(1/n)$&#30340;&#19978;&#30028;&#65292;&#20026;&#25105;&#20204;&#23545;&#32593;&#32476;&#22312;&#26410;&#35265;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.07025</link><description>&lt;p&gt;
&#22343;&#22330;&#26497;&#38480;&#19979;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
Generalization Error of Graph Neural Networks in the Mean-field Regime
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07025
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#22312;&#22343;&#22330;&#26497;&#38480;&#19979;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#35780;&#20272;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#36890;&#36807;&#25512;&#23548;&#20986;&#25910;&#25947;&#36895;&#24230;&#20026;$O(1/n)$&#30340;&#19978;&#30028;&#65292;&#20026;&#25105;&#20204;&#23545;&#32593;&#32476;&#22312;&#26410;&#35265;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#24037;&#20316;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;&#22312;&#36807;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#36890;&#36807;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#22270;&#20998;&#31867;&#20219;&#21153;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#21363;&#21442;&#25968;&#25968;&#37327;&#36229;&#36807;&#25968;&#25454;&#28857;&#25968;&#37327;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#31867;&#22411;&#65306;&#22270;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#21644;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#12290;&#22312;&#26412;&#30740;&#31350;&#20043;&#21069;&#65292;&#20851;&#20110;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#27867;&#21270;&#35823;&#24046;&#30340;&#29616;&#26377;&#30028;&#38480;&#32570;&#20047;&#20449;&#24687;&#65292;&#38480;&#21046;&#20102;&#25105;&#20204;&#23545;&#36807;&#21442;&#25968;&#21270;&#32593;&#32476;&#24615;&#33021;&#30340;&#29702;&#35299;&#12290;&#25105;&#20204;&#30340;&#21019;&#26032;&#26041;&#27861;&#26159;&#22312;&#22343;&#22330;&#26497;&#38480;&#19979;&#25512;&#23548;&#20986;&#19978;&#30028;&#65292;&#20197;&#35780;&#20272;&#36825;&#20123;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#35823;&#24046;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#20197;$O(1/n)$&#25910;&#25947;&#36895;&#24230;&#30340;&#19978;&#30028;&#65292;&#20854;&#20013;$n$&#26159;&#22270;&#26679;&#26412;&#30340;&#25968;&#37327;&#12290;&#36825;&#20123;&#19978;&#30028;&#20026;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#32593;&#32476;&#22312;&#26410;&#35265;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#25552;&#20379;&#20102;&#29702;&#35770;&#19978;&#30340;&#20445;&#35777;&#65292;&#20174;&#32780;&#23545;&#25105;&#20204;&#30340;&#29702;&#35299;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work provides a theoretical framework for assessing the generalization error of graph classification tasks via graph neural networks in the over-parameterized regime, where the number of parameters surpasses the quantity of data points. We explore two widely utilized types of graph neural networks: graph convolutional neural networks and message passing graph neural networks. Prior to this study, existing bounds on the generalization error in the over-parametrized regime were uninformative, limiting our understanding of over-parameterized network performance. Our novel approach involves deriving upper bounds within the mean-field regime for evaluating the generalization error of these graph neural networks. We establish upper bounds with a convergence rate of $O(1/n)$, where $n$ is the number of graph samples. These upper bounds offer a theoretical assurance of the networks' performance on unseen data in the challenging over-parameterized regime and overall contribute to our under
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26641;&#38598;&#25104;&#30340;&#24773;&#22659;&#22810;&#33218;&#32769;&#34382;&#26426;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#25972;&#21512;&#20004;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#32769;&#34382;&#26426;&#26041;&#27861;&#65292;&#22312;&#26631;&#20934;&#21644;&#32452;&#21512;&#35774;&#32622;&#20013;&#23454;&#29616;&#20102;&#20248;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#22312;&#20943;&#23569;&#21518;&#24724;&#21644;&#35745;&#31639;&#26102;&#38388;&#26041;&#38754;&#34920;&#29616;&#20986;&#26356;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.06963</link><description>&lt;p&gt;
&#22522;&#20110;&#26641;&#38598;&#25104;&#30340;&#24773;&#22659;&#22810;&#33218;&#32769;&#34382;&#26426;
&lt;/p&gt;
&lt;p&gt;
Tree Ensembles for Contextual Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06963
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26641;&#38598;&#25104;&#30340;&#24773;&#22659;&#22810;&#33218;&#32769;&#34382;&#26426;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#25972;&#21512;&#20004;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#32769;&#34382;&#26426;&#26041;&#27861;&#65292;&#22312;&#26631;&#20934;&#21644;&#32452;&#21512;&#35774;&#32622;&#20013;&#23454;&#29616;&#20102;&#20248;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#22312;&#20943;&#23569;&#21518;&#24724;&#21644;&#35745;&#31639;&#26102;&#38388;&#26041;&#38754;&#34920;&#29616;&#20986;&#26356;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#26641;&#38598;&#25104;&#30340;&#24773;&#22659;&#22810;&#33218;&#32769;&#34382;&#26426;&#30340;&#26032;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#23558;&#20004;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#32769;&#34382;&#26426;&#26041;&#27861;&#65292;&#19978;&#20449;&#24515;&#30028;&#21644;&#27748;&#26222;&#26862;&#25277;&#26679;&#65292;&#25972;&#21512;&#21040;&#26631;&#20934;&#21644;&#32452;&#21512;&#35774;&#32622;&#20013;&#12290;&#36890;&#36807;&#20351;&#29992;&#27969;&#34892;&#30340;&#26641;&#38598;&#25104;&#26041;&#27861;XGBoost&#36827;&#34892;&#22810;&#27425;&#23454;&#39564;&#30740;&#31350;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#12290;&#24403;&#24212;&#29992;&#20110;&#22522;&#20934;&#25968;&#25454;&#38598;&#21644;&#36947;&#36335;&#32593;&#32476;&#23548;&#33322;&#30340;&#30495;&#23454;&#19990;&#30028;&#24212;&#29992;&#26102;&#65292;&#19982;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20943;&#23569;&#21518;&#24724;&#21644;&#35745;&#31639;&#26102;&#38388;&#26041;&#38754;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel framework for contextual multi-armed bandits based on tree ensembles. Our framework integrates two widely used bandit methods, Upper Confidence Bound and Thompson Sampling, for both standard and combinatorial settings. We demonstrate the effectiveness of our framework via several experimental studies, employing XGBoost, a popular tree ensemble method. Compared to state-of-the-art methods based on neural networks, our methods exhibit superior performance in terms of both regret minimization and computational runtime, when applied to benchmark datasets and the real-world application of navigation over road networks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22312;&#36125;&#21494;&#26031;&#32479;&#35745;&#27169;&#22411;&#20013;&#20351;&#29992;&#21152;&#26435;&#34394;&#25311;&#35266;&#27979;&#36827;&#34892;&#22686;&#37327;&#20449;&#24565;&#26356;&#26032;&#30340;&#31639;&#27861;&#35299;&#20915;&#26041;&#26696;&#65292;&#35813;&#26041;&#26696;&#36890;&#36807;&#26500;&#24314;&#19968;&#32452;&#21152;&#26435;&#35266;&#27979;&#26469;&#35843;&#33410;&#27169;&#22411;&#65292;&#23454;&#29616;&#19982;&#21407;&#22987;&#21518;&#39564;&#30456;&#21516;&#30340;&#25512;&#26029;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.06940</link><description>&lt;p&gt;
&#20351;&#29992;&#21152;&#26435;&#34394;&#25311;&#35266;&#27979;&#23454;&#29616;&#39640;&#25928;&#30340;&#22686;&#37327;&#20449;&#24565;&#26356;&#26032;
&lt;/p&gt;
&lt;p&gt;
Efficient Incremental Belief Updates Using Weighted Virtual Observations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06940
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22312;&#36125;&#21494;&#26031;&#32479;&#35745;&#27169;&#22411;&#20013;&#20351;&#29992;&#21152;&#26435;&#34394;&#25311;&#35266;&#27979;&#36827;&#34892;&#22686;&#37327;&#20449;&#24565;&#26356;&#26032;&#30340;&#31639;&#27861;&#35299;&#20915;&#26041;&#26696;&#65292;&#35813;&#26041;&#26696;&#36890;&#36807;&#26500;&#24314;&#19968;&#32452;&#21152;&#26435;&#35266;&#27979;&#26469;&#35843;&#33410;&#27169;&#22411;&#65292;&#23454;&#29616;&#19982;&#21407;&#22987;&#21518;&#39564;&#30456;&#21516;&#30340;&#25512;&#26029;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#35299;&#20915;&#20102;&#22312;&#36125;&#21494;&#26031;&#32479;&#35745;&#27169;&#22411;&#20013;&#33945;&#29305;&#21345;&#27931;&#25512;&#26029;&#29615;&#22659;&#19979;&#30340;&#22686;&#37327;&#20449;&#24565;&#26356;&#26032;&#38382;&#39064;&#65292;&#35813;&#27169;&#22411;&#30001;&#27010;&#29575;&#32534;&#31243;&#34920;&#31034;&#12290;&#32473;&#23450;&#19968;&#20010;&#27169;&#22411;&#21644;&#26679;&#26412;&#36924;&#36817;&#30340;&#21518;&#39564;&#27010;&#29575;&#65292;&#25105;&#20204;&#30340;&#35299;&#20915;&#26041;&#26696;&#26500;&#24314;&#20102;&#19968;&#32452;&#21152;&#26435;&#35266;&#27979;&#26469;&#35843;&#33410;&#27169;&#22411;&#65292;&#20174;&#32780;&#25512;&#26029;&#32467;&#26524;&#19982;&#21407;&#22987;&#21518;&#39564;&#30456;&#21516;&#12290;&#35813;&#38382;&#39064;&#20986;&#29616;&#22312;&#22810;&#23618;&#24314;&#27169;&#12289;&#22686;&#37327;&#25512;&#26029;&#21644;&#25968;&#25454;&#38544;&#31169;&#32422;&#26463;&#19979;&#30340;&#25512;&#26029;&#31561;&#24773;&#20917;&#12290;&#39318;&#20808;&#65292;&#36873;&#25321;&#19968;&#32452;&#34394;&#25311;&#35266;&#27979;&#20540;&#65292;&#28982;&#21518;&#36890;&#36807;&#39640;&#25928;&#30340;&#35745;&#31639;&#20248;&#21270;&#36807;&#31243;&#25214;&#21040;&#35266;&#27979;&#26435;&#37325;&#65292;&#20351;&#24471;&#37325;&#24314;&#30340;&#21518;&#39564;&#19982;&#21407;&#22987;&#21518;&#39564;&#19968;&#33268;&#25110;&#36817;&#20284;&#12290;&#25105;&#20204;&#23545;&#19968;&#20123;&#25945;&#23398;&#31034;&#20363;&#21644;&#26696;&#20363;&#30740;&#31350;&#23454;&#26045;&#24182;&#24212;&#29992;&#20102;&#35813;&#35299;&#20915;&#26041;&#26696;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#25928;&#29575;&#21644;&#40065;&#26834;&#24615;&#12290;&#25152;&#25552;&#20379;&#30340;&#21442;&#32771;&#23454;&#29616;&#19981;&#20381;&#36182;&#20110;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#25110;&#25512;&#26029;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present an algorithmic solution to the problem of incremental belief updating in the context of Monte Carlo inference in Bayesian statistical models represented by probabilistic programs. Given a model and a sample-approximated posterior, our solution constructs a set of weighted observations to condition the model such that inference would result in the same posterior. This problem arises e.g. in multi-level modelling, incremental inference, inference in presence of privacy constraints. First, a set of virtual observations is selected, then, observation weights are found through a computationally efficient optimization procedure such that the reconstructed posterior coincides with or closely approximates the original posterior. We implement and apply the solution to a number of didactic examples and case studies, showing efficiency and robustness of our approach. The provided reference implementation is agnostic to the probabilistic programming language or the inference algorithm, 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CochCeps-Augment&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22522;&#20110;Cochlear Cepstrum&#30340;&#25513;&#34109;&#22686;&#24378;&#20219;&#21153;&#36827;&#34892;&#33258;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#65292;&#25552;&#39640;&#20102;&#35821;&#38899;&#24773;&#24863;&#35782;&#21035;&#30340;&#24615;&#33021;&#21644;&#22122;&#22768;&#40065;&#26834;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.06923</link><description>&lt;p&gt;
CochCeps-Augment&#65306;&#19968;&#31181;&#20351;&#29992;&#22522;&#20110;Cochlear Cepstrum&#30340;&#25513;&#34109;&#30340;&#33258;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#29992;&#20110;&#35821;&#38899;&#24773;&#24863;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
CochCeps-Augment: A Novel Self-Supervised Contrastive Learning Using Cochlear Cepstrum-based Masking for Speech Emotion Recognition
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06923
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CochCeps-Augment&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22522;&#20110;Cochlear Cepstrum&#30340;&#25513;&#34109;&#22686;&#24378;&#20219;&#21153;&#36827;&#34892;&#33258;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#65292;&#25552;&#39640;&#20102;&#35821;&#38899;&#24773;&#24863;&#35782;&#21035;&#30340;&#24615;&#33021;&#21644;&#22122;&#22768;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#29992;&#20110;&#24773;&#24863;&#20869;&#23481;&#30340;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#21487;&#20197;&#34987;&#22122;&#22768;&#24178;&#25200;&#20005;&#37325;&#38477;&#20302;&#65292;&#24433;&#21709;&#23545;&#35821;&#38899;&#30340;&#22797;&#26434;&#26102;&#22495;&#21644;&#39057;&#35889;&#20449;&#24687;&#32467;&#26500;&#36827;&#34892;&#24314;&#27169;&#30340;&#25928;&#29575;&#12290;&#26368;&#36817;&#65292;&#22823;&#35268;&#27169;&#35821;&#38899;&#25968;&#25454;&#38598;&#19978;&#30340;SSL&#20197;&#21450;&#26032;&#30340;&#38899;&#39057;&#29305;&#23450;&#30340;SSL&#20195;&#29702;&#20219;&#21153;&#65288;&#22914;&#26102;&#22495;&#21644;&#39057;&#22495;&#25513;&#34109;&#65289;&#24050;&#32463;&#20986;&#29616;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;&#28304;&#33258;&#22270;&#20687;&#22686;&#24378;&#39046;&#22495;&#30340;&#26041;&#27861;&#65292;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#21019;&#26032;&#22312;&#20110;&#22522;&#20110;&#25104;&#21151;&#30340;&#33539;&#20363;&#24341;&#20837;CochCeps-Augment&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#33258;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#35821;&#38899;&#34920;&#31034;&#30340;&#26032;&#22411;&#29983;&#29289;&#21551;&#21457;&#25513;&#34109;&#22686;&#24378;&#20219;&#21153;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#21033;&#29992;&#20102;&#26032;&#24341;&#20837;&#30340;&#29983;&#29289;&#21551;&#21457;&#24335;Cochlear cepstrogram&#65288;CCGRAM&#65289;&#26469;&#25512;&#23548;&#36755;&#20837;&#35821;&#38899;&#30340;&#22122;&#22768;&#40065;&#26834;&#34920;&#31034;&#65292;&#28982;&#21518;&#36890;&#36807;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#26696;&#36827;&#19968;&#27493;&#20248;&#21270;&#12290;&#21518;&#32773;&#21033;&#29992;SimCLR&#29983;&#25104;CCGRAM&#30340;&#23545;&#27604;&#35270;&#22270;&#65292;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#26469;&#20135;&#29983;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-supervised learning (SSL) for automated speech recognition in terms of its emotional content, can be heavily degraded by the presence noise, affecting the efficiency of modeling the intricate temporal and spectral informative structures of speech. Recently, SSL on large speech datasets, as well as new audio-specific SSL proxy tasks, such as, temporal and frequency masking, have emerged, yielding superior performance compared to classic approaches drawn from the image augmentation domain. Our proposed contribution builds upon this successful paradigm by introducing CochCeps-Augment, a novel bio-inspired masking augmentation task for self-supervised contrastive learning of speech representations. Specifically, we utilize the newly introduced bio-inspired cochlear cepstrogram (CCGRAM) to derive noise robust representations of input speech, that are then further refined through a self-supervised learning scheme. The latter employs SimCLR to generate contrastive views of a CCGRAM throu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24809;&#32602;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;Bilevel&#24378;&#21270;&#23398;&#20064;&#21644;RLHF&#38382;&#39064;&#65292;&#36825;&#26159;&#39318;&#20010;&#26377;&#21407;&#21017;&#30340;&#31639;&#27861;&#26694;&#26550;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.06886</link><description>&lt;p&gt;
Bilevel&#24378;&#21270;&#23398;&#20064;&#21644;RLHF&#30340;&#26377;&#21407;&#21017;&#30340;&#22522;&#20110;&#24809;&#32602;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Principled Penalty-based Methods for Bilevel Reinforcement Learning and RLHF
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06886
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24809;&#32602;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;Bilevel&#24378;&#21270;&#23398;&#20064;&#21644;RLHF&#38382;&#39064;&#65292;&#36825;&#26159;&#39318;&#20010;&#26377;&#21407;&#21017;&#30340;&#31639;&#27861;&#26694;&#26550;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;Bilevel&#20248;&#21270;&#24050;&#34987;&#24212;&#29992;&#20110;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#24212;&#29992;&#20165;&#38480;&#20110;&#30417;&#30563;&#23398;&#20064;&#35774;&#32622;&#65292;&#20854;&#20013;&#32771;&#34385;&#20102;&#20855;&#26377;&#33391;&#24615;&#32467;&#26500;&#30340;&#38745;&#24577;&#30446;&#26631;&#20989;&#25968;&#12290;&#20294;&#26159;&#65292;&#28608;&#21169;&#35774;&#35745;&#12289;&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;(RL)&#21644;&#26469;&#33258;&#20154;&#31867;&#21453;&#39304;&#30340;RLHF&#31561;Bilevel&#38382;&#39064;&#36890;&#24120;&#34987;&#24314;&#27169;&#20026;&#36229;&#36234;&#31616;&#21333;&#38745;&#24577;&#30446;&#26631;&#32467;&#26500;&#30340;&#21160;&#24577;&#30446;&#26631;&#20989;&#25968;&#65292;&#36825;&#32473;&#20351;&#29992;&#29616;&#26377;Bilevel&#35299;&#20915;&#26041;&#26696;&#24102;&#26469;&#20102;&#37325;&#22823;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#26032;&#30340;Bilevel&#38382;&#39064;&#31867;&#21035;&#65292;&#25105;&#20204;&#36890;&#36807;&#24809;&#32602;&#24418;&#24335;&#24341;&#20837;&#20102;&#35299;&#20915;Bilevel RL&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#21407;&#21017;&#24615;&#31639;&#27861;&#26694;&#26550;&#12290;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#30740;&#31350;&#38382;&#39064;&#30340;&#26223;&#35266;&#21450;&#20854;&#22522;&#20110;&#24809;&#32602;&#30340;&#65288;&#31574;&#30053;&#65289;&#26799;&#24230;&#31639;&#27861;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;Stackelberg&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#12289;&#26469;&#33258;&#20154;&#31867;&#21453;&#39304;&#30340;RL&#21644;&#28608;&#21169;&#35774;&#35745;&#20013;&#36827;&#34892;&#27169;&#25311;&#26469;&#35777;&#26126;&#25105;&#20204;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bilevel optimization has been recently applied to many machine learning tasks. However, their applications have been restricted to the supervised learning setting, where static objective functions with benign structures are considered. But bilevel problems such as incentive design, inverse reinforcement learning (RL), and RL from human feedback (RLHF) are often modeled as dynamic objective functions that go beyond the simple static objective structures, which pose significant challenges of using existing bilevel solutions. To tackle this new class of bilevel problems, we introduce the first principled algorithmic framework for solving bilevel RL problems through the lens of penalty formulation. We provide theoretical studies of the problem landscape and its penalty-based (policy) gradient algorithms. We demonstrate the effectiveness of our algorithms via simulations in the Stackelberg Markov game, RL from human feedback and incentive design.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#32467;&#26500;&#20887;&#20313;&#30340;&#20302;&#31209;&#36924;&#36817;&#22312;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36924;&#36817;&#20887;&#20313;&#32452;&#20214;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#20998;&#26512;&#36807;&#37327;&#39118;&#38505;&#26469;&#25903;&#25345;&#29702;&#35770;&#12290;</title><link>https://arxiv.org/abs/2402.06884</link><description>&lt;p&gt;
&#32467;&#26500;&#20887;&#20313;&#30340;&#20302;&#31209;&#36924;&#36817;&#29992;&#20110;&#33258;&#30417;&#30563;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Low-Rank Approximation of Structural Redundancy for Self-Supervised Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06884
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#32467;&#26500;&#20887;&#20313;&#30340;&#20302;&#31209;&#36924;&#36817;&#22312;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36924;&#36817;&#20887;&#20313;&#32452;&#20214;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#20998;&#26512;&#36807;&#37327;&#39118;&#38505;&#26469;&#25903;&#25345;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#37325;&#26500;&#22411;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#65292;&#20197;&#25581;&#31034;&#20854;&#26377;&#25928;&#24615;&#12290;&#22312;&#25317;&#26377;&#26080;&#38480;&#37327;&#30340;&#26631;&#35760;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23436;&#32654;&#32447;&#24615;&#36924;&#36817;&#30340;&#20805;&#20998;&#24517;&#35201;&#26465;&#20214;&#12290;&#35813;&#26465;&#20214;&#25581;&#31034;&#20102;&#19968;&#20010;&#20445;&#30041;&#26631;&#31614;&#31867;&#21035;Y&#30340;&#28385;&#31209;&#32452;&#20214;&#65292;&#20197;&#21450;&#19968;&#20010;&#20887;&#20313;&#32452;&#20214;&#12290;&#21463;&#21040;&#35813;&#26465;&#20214;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#20302;&#31209;&#20998;&#35299;&#36924;&#36817;&#20887;&#20313;&#32452;&#20214;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#30001;&#20998;&#35299;&#31209;s&#21442;&#25968;&#21270;&#30340;&#26032;&#37327;$\epsilon_s$&#26469;&#34913;&#37327;&#36924;&#36817;&#36136;&#37327;&#12290;&#25105;&#20204;&#23558;$\epsilon_s$&#25972;&#21512;&#21040;&#32447;&#24615;&#22238;&#24402;&#21644;&#23725;&#22238;&#24402;&#35774;&#32622;&#19979;&#30340;&#36807;&#37327;&#39118;&#38505;&#20998;&#26512;&#20013;&#65292;&#21518;&#19968;&#31181;&#27491;&#21017;&#21270;&#26041;&#27861;&#29992;&#20110;&#22788;&#29702;&#23398;&#20064;&#29305;&#24449;&#30340;&#32500;&#24230;&#36828;&#22823;&#20110;&#19979;&#28216;&#20219;&#21153;&#30340;&#26631;&#35760;&#26679;&#26412;&#25968;n&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19977;&#20010;&#31616;&#21270;&#23454;&#39564;&#65292;&#20197;&#27604;&#36739;&#19981;&#21516;&#35774;&#32622;&#19979;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#21644;&#30417;&#30563;&#23398;&#20064;&#65292;&#20197;&#25903;&#25345;&#25105;&#20204;&#30340;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the data-generating mechanism for reconstructive SSL to shed light on its effectiveness. With an infinite amount of labeled samples, we provide a sufficient and necessary condition for perfect linear approximation. The condition reveals a full-rank component that preserves the label classes of Y, along with a redundant component. Motivated by the condition, we propose to approximate the redundant component by a low-rank factorization and measure the approximation quality by introducing a new quantity $\epsilon_s$, parameterized by the rank of factorization s. We incorporate $\epsilon_s$ into the excess risk analysis under both linear regression and ridge regression settings, where the latter regularization approach is to handle scenarios when the dimension of the learned features is much larger than the number of labeled samples n for downstream tasks. We design three stylized experiments to compare SSL with supervised learning under different settings to support our theoretic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;Nystr\"om&#36817;&#20284;&#26041;&#27861;&#35299;&#20915;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#26680;&#36923;&#36753;&#22238;&#24402;&#30340;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12290;&#30740;&#31350;&#25552;&#20379;&#20102;&#29702;&#35770;&#20998;&#26512;&#24182;&#39564;&#35777;&#20102;&#19981;&#21516;&#30340;&#22320;&#26631;&#36873;&#25321;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.06763</link><description>&lt;p&gt;
&#20351;&#29992;Nystr\"om&#36817;&#20284;&#30340;&#21487;&#25193;&#23637;&#26680;&#36923;&#36753;&#22238;&#24402;&#65306;&#29702;&#35770;&#20998;&#26512;&#21644;&#31163;&#25955;&#36873;&#25321;&#24314;&#27169;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Scalable Kernel Logistic Regression with Nystr\"om Approximation: Theoretical Analysis and Application to Discrete Choice Modelling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06763
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;Nystr\"om&#36817;&#20284;&#26041;&#27861;&#35299;&#20915;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#26680;&#36923;&#36753;&#22238;&#24402;&#30340;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12290;&#30740;&#31350;&#25552;&#20379;&#20102;&#29702;&#35770;&#20998;&#26512;&#24182;&#39564;&#35777;&#20102;&#19981;&#21516;&#30340;&#22320;&#26631;&#36873;&#25321;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#22522;&#20110;&#26680;&#30340;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#24212;&#29992;&#20110;&#20351;&#29992;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#30340;&#31163;&#25955;&#36873;&#25321;&#24314;&#27169;&#26102;&#65292;&#32463;&#24120;&#38754;&#20020;&#23384;&#20648;&#38656;&#27714;&#21644;&#27169;&#22411;&#20013;&#28041;&#21450;&#30340;&#22823;&#37327;&#21442;&#25968;&#30340;&#25361;&#25112;&#12290;&#36825;&#31181;&#22797;&#26434;&#24615;&#24433;&#21709;&#20102;&#22823;&#35268;&#27169;&#27169;&#22411;&#30340;&#39640;&#25928;&#35757;&#32451;&#12290;&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;Nystr\"om&#36817;&#20284;&#26041;&#27861;&#35299;&#20915;&#20102;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#65292;&#29992;&#20110;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#30340;&#26680;&#36923;&#36753;&#22238;&#24402;&#12290;&#30740;&#31350;&#39318;&#20808;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#20854;&#20013;&#65306;i) &#23545;KLR&#35299;&#30340;&#38598;&#21512;&#36827;&#34892;&#20102;&#25551;&#36848;&#65292;ii) &#32473;&#20986;&#20102;&#20351;&#29992;Nystr\"om&#36817;&#20284;&#30340;KLR&#35299;&#30340;&#19978;&#30028;&#65292;&#24182;&#26368;&#21518;&#25551;&#36848;&#20102;&#19987;&#38376;&#29992;&#20110;Nystr\"om KLR&#30340;&#20248;&#21270;&#31639;&#27861;&#30340;&#29305;&#21270;&#12290;&#20043;&#21518;&#65292;&#23545;Nystr\"om KLR&#36827;&#34892;&#20102;&#35745;&#31639;&#39564;&#35777;&#12290;&#27979;&#35797;&#20102;&#22235;&#31181;&#22320;&#26631;&#36873;&#25321;&#26041;&#27861;&#65292;&#21253;&#25324;&#22522;&#26412;&#22343;&#21248;&#37319;&#26679;&#12289;k-means&#37319;&#26679;&#31574;&#30053;&#21644;&#22522;&#20110;&#26464;&#26438;&#24471;&#20998;&#30340;&#20004;&#31181;&#38750;&#22343;&#21248;&#26041;&#27861;&#12290;&#36825;&#20123;&#31574;&#30053;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
The application of kernel-based Machine Learning (ML) techniques to discrete choice modelling using large datasets often faces challenges due to memory requirements and the considerable number of parameters involved in these models. This complexity hampers the efficient training of large-scale models. This paper addresses these problems of scalability by introducing the Nystr\"om approximation for Kernel Logistic Regression (KLR) on large datasets. The study begins by presenting a theoretical analysis in which: i) the set of KLR solutions is characterised, ii) an upper bound to the solution of KLR with Nystr\"om approximation is provided, and finally iii) a specialisation of the optimisation algorithms to Nystr\"om KLR is described. After this, the Nystr\"om KLR is computationally validated. Four landmark selection methods are tested, including basic uniform sampling, a k-means sampling strategy, and two non-uniform methods grounded in leverage scores. The performance of these strategi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#23545;&#31216;&#30697;&#38453;&#23436;&#25104;&#38382;&#39064;&#20013;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#38750;&#27491;&#21017;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#23567;&#21021;&#22987;&#21270;&#30340;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#21487;&#20197;&#25910;&#25947;&#21040;&#30495;&#23454;&#30340;&#30697;&#38453;&#35299;&#65292;&#21363;&#20351;&#22312;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#20063;&#25104;&#31435;&#12290;&#22312;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#20960;&#20046;&#32447;&#24615;&#30340;&#25910;&#25947;&#36895;&#24230;&#21487;&#20197;&#22312;&#33719;&#24471;&#36275;&#22815;&#22810;&#30340;&#35266;&#27979;&#26465;&#30446;&#21518;&#24471;&#21040;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.06756</link><description>&lt;p&gt;
&#20351;&#29992;&#23567;&#21021;&#22987;&#21270;&#30340;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#22312;&#38750;&#27491;&#21017;&#21270;&#30697;&#38453;&#23436;&#25104;&#20013;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Convergence of Gradient Descent with Small Initialization for Unregularized Matrix Completion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06756
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#23545;&#31216;&#30697;&#38453;&#23436;&#25104;&#38382;&#39064;&#20013;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#38750;&#27491;&#21017;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#23567;&#21021;&#22987;&#21270;&#30340;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#21487;&#20197;&#25910;&#25947;&#21040;&#30495;&#23454;&#30340;&#30697;&#38453;&#35299;&#65292;&#21363;&#20351;&#22312;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#20063;&#25104;&#31435;&#12290;&#22312;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#20960;&#20046;&#32447;&#24615;&#30340;&#25910;&#25947;&#36895;&#24230;&#21487;&#20197;&#22312;&#33719;&#24471;&#36275;&#22815;&#22810;&#30340;&#35266;&#27979;&#26465;&#30446;&#21518;&#24471;&#21040;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#23545;&#31216;&#30697;&#38453;&#23436;&#25104;&#30340;&#38382;&#39064;&#65292;&#30446;&#26631;&#26159;&#20174;&#20165;&#35266;&#27979;&#21040;&#30340;&#37096;&#20998;&#26465;&#30446;&#20013;&#37325;&#26500;&#19968;&#20010;&#27491;&#21322;&#23450;&#30697;&#38453;X*&#65292;&#20854;&#31561;&#20215;&#20110;&#21442;&#25968;&#21270;&#30697;&#38453;UU^T&#65292;&#20854;&#20013;X*&#30340;&#31209;&#20026;r&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#20351;&#29992;&#23567;&#30340;&#21021;&#22987;&#21270;&#30340;&#22522;&#26412;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#31639;&#27861;&#21487;&#20197;&#25910;&#25947;&#21040;&#30495;&#23454;&#30340;&#30697;&#38453;X*&#65292;&#32780;&#19981;&#38656;&#35201;&#26174;&#24335;&#30340;&#27491;&#21017;&#21270;&#12290;&#36825;&#20010;&#25910;&#25947;&#32467;&#26524;&#36866;&#29992;&#20110;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#22330;&#26223;&#65292;&#20854;&#20013;&#30495;&#23454;&#31209;r&#26159;&#26410;&#30693;&#30340;&#65292;&#24182;&#19988;&#34987;&#19968;&#20010;&#25628;&#32034;&#31209;r'&#20445;&#23432;&#20272;&#35745;&#65292;&#19988;r' &gt;&gt; r&#12290;&#29616;&#26377;&#30340;&#32467;&#26524;&#35201;&#20040;&#38656;&#35201;&#26174;&#24335;&#30340;&#27491;&#21017;&#21270;&#65292;&#25110;&#32773;&#38656;&#35201;&#36275;&#22815;&#20934;&#30830;&#30340;&#21021;&#22987;&#28857;&#65292;&#25110;&#32773;&#38656;&#35201;&#20934;&#30830;&#30693;&#36947;&#30495;&#23454;&#31209;r&#12290;&#22312;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#21363;r' &gt;= r&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#33719;&#24471;&#937;(dr^9)&#30340;&#35266;&#27979;&#26465;&#30446;&#21518;&#65292;GD&#31639;&#27861;&#20197;&#21021;&#22987;&#28857;&#8741;U_0&#8741; &lt;= &#949;&#20960;&#20046;&#32447;&#24615;&#25910;&#25947;&#21040;X*&#30340;&#949;-&#37051;&#22495;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of symmetric matrix completion, where the goal is to reconstruct a positive semidefinite matrix $\rm{X}^\star \in \mathbb{R}^{d\times d}$ of rank-$r$, parameterized by $\rm{U}\rm{U}^{\top}$, from only a subset of its observed entries. We show that the vanilla gradient descent (GD) with small initialization provably converges to the ground truth $\rm{X}^\star$ without requiring any explicit regularization. This convergence result holds true even in the over-parameterized scenario, where the true rank $r$ is unknown and conservatively over-estimated by a search rank $r'\gg r$. The existing results for this problem either require explicit regularization, a sufficiently accurate initial point, or exact knowledge of the true rank $r$.   In the over-parameterized regime where $r'\geq r$, we show that, with $\widetilde\Omega(dr^9)$ observations, GD with an initial point $\|\rm{U}_0\| \leq \epsilon$ converges near-linearly to an $\epsilon$-neighborhood of $\rm{X}^\star$. C
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#20998;&#21106;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#35299;&#21078;&#21487;&#25511;&#21307;&#23398;&#22270;&#20687;&#29983;&#25104;&#26041;&#27861;&#65292;&#36890;&#36807;&#38543;&#26426;&#25513;&#27169;&#28040;&#34701;&#35757;&#32451;&#31639;&#27861;&#23454;&#29616;&#23545;&#35299;&#21078;&#32422;&#26463;&#30340;&#26465;&#20214;&#21270;&#65292;&#21516;&#26102;&#25552;&#39640;&#20102;&#32593;&#32476;&#23545;&#35299;&#21078;&#30495;&#23454;&#24615;&#30340;&#23398;&#20064;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.05210</link><description>&lt;p&gt;
&#37319;&#29992;&#20998;&#21106;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#35299;&#21078;&#21487;&#25511;&#21307;&#23398;&#22270;&#20687;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Anatomically-Controllable Medical Image Generation with Segmentation-Guided Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05210
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#20998;&#21106;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#35299;&#21078;&#21487;&#25511;&#21307;&#23398;&#22270;&#20687;&#29983;&#25104;&#26041;&#27861;&#65292;&#36890;&#36807;&#38543;&#26426;&#25513;&#27169;&#28040;&#34701;&#35757;&#32451;&#31639;&#27861;&#23454;&#29616;&#23545;&#35299;&#21078;&#32422;&#26463;&#30340;&#26465;&#20214;&#21270;&#65292;&#21516;&#26102;&#25552;&#39640;&#20102;&#32593;&#32476;&#23545;&#35299;&#21078;&#30495;&#23454;&#24615;&#30340;&#23398;&#20064;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#24050;&#32463;&#23454;&#29616;&#20102;&#38750;&#24120;&#39640;&#36136;&#37327;&#30340;&#21307;&#23398;&#22270;&#20687;&#29983;&#25104;&#65292;&#21487;&#20197;&#36890;&#36807;&#20026;&#23567;&#22411;&#25110;&#19981;&#24179;&#34913;&#30340;&#25968;&#25454;&#38598;&#25552;&#20379;&#34917;&#20805;&#65292;&#20174;&#32780;&#24110;&#21161;&#20943;&#36731;&#33719;&#21462;&#21644;&#27880;&#37322;&#26032;&#22270;&#20687;&#30340;&#36153;&#29992;&#65292;&#21516;&#26102;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#20854;&#20182;&#26041;&#38754;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#22312;&#29983;&#25104;&#22270;&#20687;&#26102;&#38754;&#20020;&#30528;&#20840;&#23616;&#35299;&#21078;&#30495;&#23454;&#24615;&#30340;&#25361;&#25112;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#21078;&#21487;&#25511;&#30340;&#21307;&#23398;&#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#27599;&#20010;&#37319;&#26679;&#27493;&#39588;&#20013;&#36981;&#24490;&#22810;&#31867;&#35299;&#21078;&#20998;&#21106;&#25513;&#27169;&#65292;&#24182;&#37319;&#29992;&#38543;&#26426;&#25513;&#27169;&#28040;&#34701;&#35757;&#32451;&#31639;&#27861;&#65292;&#20197;&#23454;&#29616;&#23545;&#25152;&#36873;&#35299;&#21078;&#32422;&#26463;&#30340;&#26465;&#20214;&#21270;&#65292;&#21516;&#26102;&#20801;&#35768;&#20854;&#20182;&#35299;&#21078;&#21306;&#22495;&#30340;&#28789;&#27963;&#24615;&#12290;&#36825;&#20063;&#25913;&#21892;&#20102;&#32593;&#32476;&#22312;&#23436;&#20840;&#26080;&#26465;&#20214;&#65288;&#26080;&#32422;&#26463;&#29983;&#25104;&#65289;&#24773;&#20917;&#19979;&#23545;&#35299;&#21078;&#30495;&#23454;&#24615;&#30340;&#23398;&#20064;&#12290;&#36890;&#36807;&#23545;&#20083;&#33146;MRI&#21644;&#33145;&#37096;/&#39048;&#37096;&#21040;&#30406;&#33108;CT&#25968;&#25454;&#38598;&#30340;&#27604;&#36739;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#27169;&#22411;&#22312;&#35299;&#21078;&#30495;&#23454;&#24615;&#21644;&#36755;&#20837;&#25513;&#27169;&#20445;&#30495;&#24230;&#26041;&#38754;&#20855;&#26377;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models have enabled remarkably high-quality medical image generation, which can help mitigate the expenses of acquiring and annotating new images by supplementing small or imbalanced datasets, along with other applications. However, these are hampered by the challenge of enforcing global anatomical realism in generated images. To this end, we propose a diffusion model for anatomically-controlled medical image generation. Our model follows a multi-class anatomical segmentation mask at each sampling step and incorporates a \textit{random mask ablation} training algorithm, to enable conditioning on a selected combination of anatomical constraints while allowing flexibility in other anatomical areas. This also improves the network's learning of anatomical realism for the completely unconditional (unconstrained generation) case. Comparative evaluation on breast MRI and abdominal/neck-to-pelvis CT datasets demonstrates superior anatomical realism and input mask faithfulness over st
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#12289;&#20840;&#38754;&#12289;&#24178;&#20928;&#19988;&#28165;&#26224;&#30340;&#20171;&#32461;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DDPM&#65289;&#30340;&#26041;&#27861;&#65292;&#24378;&#35843;&#20102;&#20174;&#36830;&#32493;&#26102;&#38388;&#26497;&#38480;&#30340;&#35270;&#35282;&#20986;&#21457;&#65292;&#20197;&#25552;&#20379;&#26356;&#22909;&#30340;&#29702;&#35299;&#21644;&#23454;&#38469;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.04384</link><description>&lt;p&gt;
&#22312;&#20845;&#20010;&#31616;&#21333;&#30340;&#27493;&#39588;&#20013;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Denoising Diffusion Probabilistic Models in Six Simple Steps
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04384
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#12289;&#20840;&#38754;&#12289;&#24178;&#20928;&#19988;&#28165;&#26224;&#30340;&#20171;&#32461;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DDPM&#65289;&#30340;&#26041;&#27861;&#65292;&#24378;&#35843;&#20102;&#20174;&#36830;&#32493;&#26102;&#38388;&#26497;&#38480;&#30340;&#35270;&#35282;&#20986;&#21457;&#65292;&#20197;&#25552;&#20379;&#26356;&#22909;&#30340;&#29702;&#35299;&#21644;&#23454;&#38469;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DDPM&#65289;&#26159;&#19968;&#31867;&#38750;&#24120;&#27969;&#34892;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#24050;&#25104;&#21151;&#24212;&#29992;&#20110;&#21253;&#25324;&#22270;&#20687;&#21644;&#35270;&#39057;&#29983;&#25104;&#12289;&#34507;&#30333;&#36136;&#21644;&#26448;&#26009;&#21512;&#25104;&#12289;&#22825;&#27668;&#39044;&#27979;&#21644;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#31070;&#32463;&#26367;&#20195;&#31561;&#22810;&#20010;&#38382;&#39064;&#12290;&#23613;&#31649;&#20854;&#26222;&#21450;&#24230;&#24456;&#39640;&#65292;&#20294;&#24456;&#38590;&#25214;&#21040;&#19968;&#20010;&#31616;&#21333;&#12289;&#20840;&#38754;&#12289;&#24178;&#20928;&#19988;&#28165;&#26224;&#30340;DDPM&#20171;&#32461;&#12290;&#30740;&#31350;&#35770;&#25991;&#20013;&#24517;&#35201;&#30340;&#31616;&#27905;&#35299;&#37322;&#26080;&#27861;&#38416;&#26126;&#21046;&#23450;DDPM&#25152;&#37319;&#21462;&#30340;&#19981;&#21516;&#35774;&#35745;&#27493;&#39588;&#20197;&#21450;&#30465;&#30053;&#20102;&#27493;&#39588;&#30340;&#29702;&#30001;&#20197;&#33410;&#30465;&#31354;&#38388;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#35770;&#36848;&#36890;&#24120;&#20174;&#21464;&#20998;&#19979;&#30028;&#30340;&#35270;&#35282;&#20986;&#21457;&#65292;&#36825;&#26159;&#19981;&#24517;&#35201;&#19988;&#21487;&#33021;&#26377;&#23475;&#30340;&#65292;&#22240;&#20026;&#23427;&#28151;&#28102;&#20102;&#26041;&#27861;&#22863;&#25928;&#30340;&#21407;&#22240;&#24182;&#26263;&#31034;&#20102;&#23454;&#36341;&#20013;&#34920;&#29616;&#19981;&#20339;&#30340;&#27867;&#21270;&#24615;&#36136;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#37319;&#29992;&#36830;&#32493;&#26102;&#38388;&#26497;&#38480;&#30340;&#35270;&#35282;&#26159;&#32654;&#20029;&#19988;&#26222;&#36941;&#30340;&#65292;&#20294;&#26159;...
&lt;/p&gt;
&lt;p&gt;
Denoising Diffusion Probabilistic Models (DDPMs) are a very popular class of deep generative model that have been successfully applied to a diverse range of problems including image and video generation, protein and material synthesis, weather forecasting, and neural surrogates of partial differential equations. Despite their ubiquity it is hard to find an introduction to DDPMs which is simple, comprehensive, clean and clear. The compact explanations necessary in research papers are not able to elucidate all of the different design steps taken to formulate the DDPM and the rationale of the steps that are presented is often omitted to save space. Moreover, the expositions are typically presented from the variational lower bound perspective which is unnecessary and arguably harmful as it obfuscates why the method is working and suggests generalisations that do not perform well in practice. On the other hand, perspectives that take the continuous time-limit are beautiful and general, but 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Metropolis-adjusted Mirror Langevin&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#32422;&#26463;&#31354;&#38388;&#20013;&#36827;&#34892;&#24555;&#36895;&#37319;&#26679;&#12290;&#36825;&#31181;&#31639;&#27861;&#26159;&#23545;Mirror Langevin&#31639;&#27861;&#30340;&#25913;&#36827;&#65292;&#36890;&#36807;&#28155;&#21152;&#25509;&#21463;-&#25298;&#32477;&#36807;&#28388;&#22120;&#26469;&#28040;&#38500;&#28176;&#36817;&#20559;&#24046;&#65292;&#24182;&#20855;&#26377;&#25351;&#25968;&#20248;&#21270;&#20381;&#36182;&#12290;</title><link>https://arxiv.org/abs/2312.08823</link><description>&lt;p&gt;
&#20351;&#29992;Metropolis-adjusted Mirror Langevin&#31639;&#27861;&#20174;&#32422;&#26463;&#31354;&#38388;&#20013;&#24555;&#36895;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Fast sampling from constrained spaces using the Metropolis-adjusted Mirror Langevin algorithm
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.08823
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Metropolis-adjusted Mirror Langevin&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#32422;&#26463;&#31354;&#38388;&#20013;&#36827;&#34892;&#24555;&#36895;&#37319;&#26679;&#12290;&#36825;&#31181;&#31639;&#27861;&#26159;&#23545;Mirror Langevin&#31639;&#27861;&#30340;&#25913;&#36827;&#65292;&#36890;&#36807;&#28155;&#21152;&#25509;&#21463;-&#25298;&#32477;&#36807;&#28388;&#22120;&#26469;&#28040;&#38500;&#28176;&#36817;&#20559;&#24046;&#65292;&#24182;&#20855;&#26377;&#25351;&#25968;&#20248;&#21270;&#20381;&#36182;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;Metropolis-adjusted Mirror Langevin&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#20854;&#25903;&#25345;&#26159;&#32039;&#20984;&#38598;&#30340;&#20998;&#24067;&#20013;&#36827;&#34892;&#36817;&#20284;&#37319;&#26679;&#12290;&#35813;&#31639;&#27861;&#22312;Mirror Langevin&#31639;&#27861;&#65288;Zhang et al., 2020&#65289;&#30340;&#21333;&#27493;&#39532;&#23572;&#31185;&#22827;&#38142;&#20013;&#28155;&#21152;&#20102;&#19968;&#20010;&#25509;&#21463;-&#25298;&#32477;&#36807;&#28388;&#22120;&#65292;Mirror Langevin&#31639;&#27861;&#26159;Mirror Langevin&#21160;&#21147;&#23398;&#30340;&#22522;&#26412;&#31163;&#25955;&#21270;&#12290;&#30001;&#20110;&#21253;&#21547;&#20102;&#36825;&#20010;&#36807;&#28388;&#22120;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#23545;&#20110;&#30446;&#26631;&#26159;&#26080;&#20559;&#30340;&#65292;&#32780;&#24050;&#30693;&#30340;Mirror Langevin&#31639;&#27861;&#31561;Mirror Langevin&#21160;&#21147;&#23398;&#30340;&#31163;&#25955;&#21270;&#20855;&#26377;&#28176;&#36817;&#20559;&#24046;&#12290;&#23545;&#20110;&#35813;&#31639;&#27861;&#65292;&#25105;&#20204;&#36824;&#32473;&#20986;&#20102;&#28151;&#21512;&#21040;&#19968;&#20010;&#30456;&#23545;&#24179;&#28369;&#12289;&#20984;&#24615;&#22909;&#19988;&#19982;&#33258;&#20849;&#36717;&#38236;&#20687;&#20989;&#25968;&#30456;&#20851;&#30340;&#32422;&#26463;&#20998;&#24067;&#25152;&#38656;&#36845;&#20195;&#27425;&#25968;&#30340;&#19978;&#30028;&#12290;&#30001;&#20110;&#21253;&#21547;Metropolis-Hastings&#36807;&#28388;&#22120;&#23548;&#33268;&#30340;&#39532;&#23572;&#31185;&#22827;&#38142;&#26159;&#21487;&#36870;&#30340;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#23545;&#35823;&#24046;&#30340;&#25351;&#25968;&#20248;&#21270;&#20381;&#36182;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new method called the Metropolis-adjusted Mirror Langevin algorithm for approximate sampling from distributions whose support is a compact and convex set. This algorithm adds an accept-reject filter to the Markov chain induced by a single step of the Mirror Langevin algorithm (Zhang et al., 2020), which is a basic discretisation of the Mirror Langevin dynamics. Due to the inclusion of this filter, our method is unbiased relative to the target, while known discretisations of the Mirror Langevin dynamics including the Mirror Langevin algorithm have an asymptotic bias. For this algorithm, we also give upper bounds for the number of iterations taken to mix to a constrained distribution whose potential is relatively smooth, convex, and Lipschitz continuous with respect to a self-concordant mirror function. As a consequence of the reversibility of the Markov chain induced by the inclusion of the Metropolis-Hastings filter, we obtain an exponentially better dependence on the erro
&lt;/p&gt;</description></item><item><title>&#36870;&#21521;&#24378;&#21270;&#23398;&#20064;&#26159;&#20174;&#19987;&#23478;&#31574;&#30053;&#31034;&#33539;&#20013;&#23398;&#20064;&#22870;&#21169;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#26631;&#20934;&#31163;&#32447;&#21644;&#22312;&#32447;&#35774;&#32622;&#19979;&#29992;&#22810;&#39033;&#24335;&#26679;&#26412;&#21644;&#36816;&#34892;&#26102;&#38388;&#36827;&#34892;&#39640;&#25928;&#36870;&#21521;&#24378;&#21270;&#23398;&#20064;&#30340;&#32467;&#26524;&#32447;&#32034;&#65292;&#24182;&#25552;&#20379;&#20102;&#20960;&#20046;&#26368;&#20248;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#19979;&#30028;&#12290;</title><link>https://arxiv.org/abs/2312.00054</link><description>&lt;p&gt;
&#36870;&#21521;&#24378;&#21270;&#23398;&#20064;&#27604;&#26631;&#20934;&#24378;&#21270;&#23398;&#20064;&#26356;&#22256;&#38590;&#21527;&#65311;&#19968;&#20010;&#29702;&#35770;&#30340;&#35266;&#28857;
&lt;/p&gt;
&lt;p&gt;
Is Inverse Reinforcement Learning Harder than Standard Reinforcement Learning? A Theoretical Perspective
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.00054
&lt;/p&gt;
&lt;p&gt;
&#36870;&#21521;&#24378;&#21270;&#23398;&#20064;&#26159;&#20174;&#19987;&#23478;&#31574;&#30053;&#31034;&#33539;&#20013;&#23398;&#20064;&#22870;&#21169;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#26631;&#20934;&#31163;&#32447;&#21644;&#22312;&#32447;&#35774;&#32622;&#19979;&#29992;&#22810;&#39033;&#24335;&#26679;&#26412;&#21644;&#36816;&#34892;&#26102;&#38388;&#36827;&#34892;&#39640;&#25928;&#36870;&#21521;&#24378;&#21270;&#23398;&#20064;&#30340;&#32467;&#26524;&#32447;&#32034;&#65292;&#24182;&#25552;&#20379;&#20102;&#20960;&#20046;&#26368;&#20248;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36870;&#21521;&#24378;&#21270;&#23398;&#20064;&#65288;IRL&#65289;&#26159;&#20174;&#19987;&#23478;&#31574;&#30053;&#30340;&#31034;&#33539;&#20013;&#23398;&#20064;&#22870;&#21169;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#22312;&#24320;&#21457;&#26234;&#33021;&#31995;&#32479;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#23613;&#31649;&#22312;&#24212;&#29992;&#20013;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#19982;&#26631;&#20934;&#24378;&#21270;&#23398;&#20064;&#30456;&#27604;&#65292;IRL&#30340;&#29702;&#35770;&#29702;&#35299;&#23384;&#22312;&#29420;&#29305;&#30340;&#25361;&#25112;&#65292;&#19988;&#21457;&#23637;&#30456;&#23545;&#36739;&#23569;&#12290;&#26412;&#25991;&#39318;&#27425;&#25552;&#20986;&#20102;&#20351;&#29992;&#22810;&#39033;&#24335;&#26679;&#26412;&#21644;&#36816;&#34892;&#26102;&#38388;&#22312;&#26631;&#20934;&#31163;&#32447;&#21644;&#22312;&#32447;&#35774;&#32622;&#19979;&#36827;&#34892;&#39640;&#25928;IRL&#30340;&#32467;&#26524;&#32447;&#32034;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#21644;&#20998;&#26512;&#24039;&#22937;&#22320;&#37319;&#29992;&#20102;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#24120;&#29992;&#30340;&#24754;&#35266;&#21407;&#21017;&#65292;&#24182;&#22312;&#27604;&#29616;&#26377;&#24037;&#20316;&#20013;&#32771;&#34385;&#30340;&#26356;&#24378;&#30340;&#24230;&#37327;&#26631;&#20934;&#19979;&#23454;&#29616;&#20102;IRL&#30340;&#20445;&#35777;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19979;&#30028;&#65292;&#34920;&#26126;&#25105;&#20204;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#20960;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inverse Reinforcement Learning (IRL) -- the problem of learning reward functions from demonstrations of an \emph{expert policy} -- plays a critical role in developing intelligent systems. While widely used in applications, theoretical understandings of IRL present unique challenges and remain less developed compared with standard RL. For example, it remains open how to do IRL efficiently in standard \emph{offline} settings with pre-collected data, where states are obtained from a \emph{behavior policy} (which could be the expert policy itself), and actions are sampled from the expert policy.   This paper provides the first line of results for efficient IRL in vanilla offline and online settings using polynomial samples and runtime. Our algorithms and analyses seamlessly adapt the pessimism principle commonly used in offline RL, and achieve IRL guarantees in stronger metrics than considered in existing work. We provide lower bounds showing that our sample complexities are nearly optimal
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#34920;&#31034;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#37096;&#20998;&#35266;&#27979;&#20013;&#36827;&#34892;&#26377;&#25928;&#30340;&#24378;&#21270;&#23398;&#20064;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#22788;&#29702;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#24102;&#26469;&#30340;&#35745;&#31639;&#21644;&#32479;&#35745;&#25361;&#25112;&#65292;&#24182;&#22312;&#21508;&#31181;&#22522;&#20934;&#27979;&#35797;&#20013;&#23637;&#29616;&#20986;&#20248;&#20110;&#20808;&#36827;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2311.12244</link><description>&lt;p&gt;
&#39640;&#25928;&#24378;&#21270;&#23398;&#20064;&#22312;&#37096;&#20998;&#21487;&#35266;&#23519;&#24615;&#19979;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Efficient Reinforcement Learning from Partial Observability
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.12244
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#34920;&#31034;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#37096;&#20998;&#35266;&#27979;&#20013;&#36827;&#34892;&#26377;&#25928;&#30340;&#24378;&#21270;&#23398;&#20064;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#22788;&#29702;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#24102;&#26469;&#30340;&#35745;&#31639;&#21644;&#32479;&#35745;&#25361;&#25112;&#65292;&#24182;&#22312;&#21508;&#31181;&#22522;&#20934;&#27979;&#35797;&#20013;&#23637;&#29616;&#20986;&#20248;&#20110;&#20808;&#36827;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#22810;&#25968;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#29366;&#24577;&#20449;&#24687;&#21482;&#33021;&#37096;&#20998;&#35266;&#27979;&#21040;&#65292;&#36825;&#30772;&#22351;&#20102;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#20551;&#35774;&#65292;&#23548;&#33268;&#23558;&#35266;&#27979;&#19982;&#29366;&#24577;&#30456;&#28151;&#28102;&#30340;&#31639;&#27861;&#34920;&#29616;&#19981;&#20339;&#12290;&#32780;&#37096;&#20998;&#21487;&#35266;&#27979;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDP&#65289;&#25552;&#20379;&#20102;&#19968;&#20010;&#20801;&#35768;&#22312;&#23398;&#20064;&#12289;&#25506;&#32034;&#21644;&#35268;&#21010;&#20013;&#32771;&#34385;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#20294;&#20063;&#24102;&#26469;&#20102;&#26174;&#33879;&#30340;&#35745;&#31639;&#21644;&#32479;&#35745;&#25361;&#25112;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#22256;&#38590;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#34920;&#31034;&#30340;&#35270;&#35282;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#21644;&#21487;&#34892;&#30340;&#31639;&#27861;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#37096;&#20998;&#35266;&#27979;&#20013;&#36827;&#34892;&#23454;&#38469;&#30340;&#24378;&#21270;&#23398;&#20064;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#20998;&#26512;&#26469;&#35777;&#26126;&#25152;&#25552;&#20986;&#31639;&#27861;&#30340;&#32479;&#35745;&#25928;&#29575;&#65292;&#24182;&#32463;&#39564;&#24615;&#22320;&#35777;&#26126;&#20102;&#22312;&#21508;&#31181;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#37096;&#20998;&#35266;&#27979;&#19979;&#33021;&#22815;&#36229;&#36234;&#26368;&#20808;&#36827;&#24615;&#33021;&#65292;&#25512;&#21160;&#20102;&#21487;&#38752;&#30340;&#24378;&#21270;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
In most real-world reinforcement learning applications, state information is only partially observable, which breaks the Markov decision process assumption and leads to inferior performance for algorithms that conflate observations with state. Partially Observable Markov Decision Processes (POMDPs), on the other hand, provide a general framework that allows for partial observability to be accounted for in learning, exploration and planning, but presents significant computational and statistical challenges. To address these difficulties, we develop a representation-based perspective that leads to a coherent framework and tractable algorithmic approach for practical reinforcement learning from partial observations. We provide a theoretical analysis for justifying the statistical efficiency of the proposed algorithm, and also empirically demonstrate the proposed algorithm can surpass state-of-the-art performance with partial observations across various benchmarks, advancing reliable reinf
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#26680;&#12289;&#22343;&#20540;&#21644;&#22122;&#22768;&#36793;&#32536;&#21270;&#39640;&#26031;&#36807;&#31243;&#65292;&#29992;&#20110;&#31995;&#22806;&#34892;&#26143;&#20940;&#26143;&#21644;H0&#25512;&#26029;&#12290;&#36890;&#36807;&#26680;&#36873;&#25321;&#21644;&#26680;&#36229;&#21442;&#25968;&#30340;&#36793;&#32536;&#21270;&#20197;&#21450;&#36125;&#21494;&#26031;&#27169;&#22411;&#27604;&#36739;&#65292;&#21487;&#20197;&#23454;&#29616;&#26680;&#36873;&#25321;&#21644;&#25512;&#26029;&#12290;</title><link>https://arxiv.org/abs/2311.04153</link><description>&lt;p&gt;
&#29992;&#20110;&#31995;&#22806;&#34892;&#26143;&#20940;&#26143;&#21644;H0&#25512;&#26029;&#30340;&#26680;&#12289;&#22343;&#20540;&#21644;&#22122;&#22768;&#36793;&#32536;&#21270;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Kernel-, mean- and noise-marginalised Gaussian processes for exoplanet transits and $H_0$ inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.04153
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#26680;&#12289;&#22343;&#20540;&#21644;&#22122;&#22768;&#36793;&#32536;&#21270;&#39640;&#26031;&#36807;&#31243;&#65292;&#29992;&#20110;&#31995;&#22806;&#34892;&#26143;&#20940;&#26143;&#21644;H0&#25512;&#26029;&#12290;&#36890;&#36807;&#26680;&#36873;&#25321;&#21644;&#26680;&#36229;&#21442;&#25968;&#30340;&#36793;&#32536;&#21270;&#20197;&#21450;&#36125;&#21494;&#26031;&#27169;&#22411;&#27604;&#36739;&#65292;&#21487;&#20197;&#23454;&#29616;&#26680;&#36873;&#25321;&#21644;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#23436;&#20840;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#23558;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#25193;&#23637;&#20026;&#21253;&#25324;&#26680;&#36873;&#25321;&#21644;&#26680;&#36229;&#21442;&#25968;&#30340;&#36793;&#32536;&#21270;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#35777;&#25454;&#36827;&#34892;&#36125;&#21494;&#26031;&#27169;&#22411;&#27604;&#36739;&#65292;&#21487;&#20197;&#30452;&#25509;&#27604;&#36739;&#26680;&#36873;&#25321;&#12290;&#36890;&#36807;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#23884;&#20837;&#31163;&#25955;&#26680;&#36873;&#25321;&#21644;&#36229;&#21442;&#25968;&#65292;&#20351;&#29992;&#23884;&#22871;&#25277;&#26679;&#36827;&#34892;&#32852;&#21512;&#21518;&#39564;&#35745;&#31639;&#12290;&#22312;&#31995;&#22806;&#34892;&#26143;&#20940;&#26143;&#20809;&#21464;&#26354;&#32447;&#27169;&#25311;&#30340;&#21512;&#25104;&#25968;&#25454;&#19978;&#25506;&#32034;&#20102;&#26680;&#24674;&#22797;&#21644;&#22343;&#20540;&#20989;&#25968;&#25512;&#26029;&#12290;&#38543;&#21518;&#65292;&#23558;&#35813;&#26041;&#27861;&#25193;&#23637;&#21040;&#22343;&#20540;&#20989;&#25968;&#21644;&#22122;&#22768;&#27169;&#22411;&#30340;&#36793;&#32536;&#21270;&#65292;&#24182;&#24212;&#29992;&#20110;&#20174;&#23454;&#38469;&#30340;&#32418;&#31227;&#30456;&#20851;&#21704;&#21187;&#21442;&#25968;&#27979;&#37327;&#20013;&#25512;&#26029;&#24403;&#20170;&#21704;&#21187;&#21442;&#25968;H0&#65292;&#36825;&#20123;&#21442;&#25968;&#26469;&#33258;&#20110;&#23431;&#23449;&#23398;&#27169;&#22411;&#29420;&#31435;&#30340;&#23431;&#23449;&#35745;&#26102;&#22120;&#21644;&#923;CDM&#20381;&#36182;&#30340;&#22768;&#23398;&#35856;&#25391;&#12290;
&lt;/p&gt;
&lt;p&gt;
Using a fully Bayesian approach, Gaussian Process regression is extended to include marginalisation over the kernel choice and kernel hyperparameters. In addition, Bayesian model comparison via the evidence enables direct kernel comparison. The calculation of the joint posterior was implemented with a transdimensional sampler which simultaneously samples over the discrete kernel choice and their hyperparameters by embedding these in a higher-dimensional space, from which samples are taken using nested sampling. Kernel recovery and mean function inference were explored on synthetic data from exoplanet transit light curve simulations. Subsequently, the method was extended to marginalisation over mean functions and noise models and applied to the inference of the present-day Hubble parameter, $H_0$, from real measurements of the Hubble parameter as a function of redshift, derived from the cosmologically model-independent cosmic chronometer and $\Lambda$CDM-dependent baryon acoustic oscill
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#26681;&#26412;&#19978;&#19981;&#21516;&#30340;&#35282;&#24230;&#37325;&#26032;&#24605;&#32771;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#31867;&#26032;&#30340;&#34920;&#36798;&#24230;&#37327;&#26041;&#27861;&#65292;&#21363;&#22270;&#30340;&#21452;&#36830;&#36890;&#24615;&#65292;&#24182;&#24378;&#35843;&#20102;&#23427;&#20204;&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#20013;&#30340;&#37325;&#35201;&#24615;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#22312;&#23545;&#20197;&#21069;&#30340;GNN&#26550;&#26500;&#36827;&#34892;&#24443;&#24213;&#23457;&#26597;&#21518;&#65292;&#21457;&#29616;&#22823;&#22810;&#25968;&#26550;&#26500;&#37117;&#27809;&#26377;&#23545;&#36825;&#20123;&#24230;&#37327;&#20855;&#26377;&#34920;&#36798;&#33021;&#21147;&#12290;&#21807;&#19968;&#30340;&#20363;&#22806;&#26159;ESAN&#26694;&#26550;&#12290;</title><link>https://arxiv.org/abs/2301.09505</link><description>&lt;p&gt;
&#36890;&#36807;&#22270;&#30340;&#21452;&#36830;&#36890;&#24615;&#37325;&#26032;&#24605;&#32771;GNN&#30340;&#34920;&#36798;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Rethinking the Expressive Power of GNNs via Graph Biconnectivity
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2301.09505
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#26681;&#26412;&#19978;&#19981;&#21516;&#30340;&#35282;&#24230;&#37325;&#26032;&#24605;&#32771;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#31867;&#26032;&#30340;&#34920;&#36798;&#24230;&#37327;&#26041;&#27861;&#65292;&#21363;&#22270;&#30340;&#21452;&#36830;&#36890;&#24615;&#65292;&#24182;&#24378;&#35843;&#20102;&#23427;&#20204;&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#20013;&#30340;&#37325;&#35201;&#24615;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#22312;&#23545;&#20197;&#21069;&#30340;GNN&#26550;&#26500;&#36827;&#34892;&#24443;&#24213;&#23457;&#26597;&#21518;&#65292;&#21457;&#29616;&#22823;&#22810;&#25968;&#26550;&#26500;&#37117;&#27809;&#26377;&#23545;&#36825;&#20123;&#24230;&#37327;&#20855;&#26377;&#34920;&#36798;&#33021;&#21147;&#12290;&#21807;&#19968;&#30340;&#20363;&#22806;&#26159;ESAN&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35774;&#35745;&#20855;&#26377;&#34920;&#36798;&#33021;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;(GNNs)&#26159;&#23398;&#20064;&#22270;&#32467;&#26500;&#25968;&#25454;&#30340;&#19968;&#20010;&#26680;&#24515;&#20027;&#39064;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#24456;&#22810;&#26041;&#27861;&#26469;&#25913;&#36827;GNNs&#22312;Weisfeiler-Lehman (WL)&#27979;&#35797;&#26041;&#38754;&#30340;&#34920;&#29616;&#65292;&#20294;&#26159;&#26222;&#36941;&#36824;&#23384;&#22312;&#23545;&#23427;&#20204;&#33021;&#22815;&#31995;&#32479;&#21644;&#21487;&#35777;&#26126;&#22320;&#33719;&#24471;&#30340;&#39069;&#22806;&#33021;&#21147;&#30340;&#32570;&#20047;&#28145;&#20837;&#20102;&#35299;&#12290;&#26412;&#25991;&#20174;&#26681;&#26412;&#19978;&#19981;&#21516;&#30340;&#35282;&#24230;&#26469;&#30740;&#31350;GNNs&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#36229;&#36234;&#20102;WL&#27979;&#35797;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31867;&#26032;&#30340;&#36890;&#36807;&#22270;&#30340;&#21452;&#36830;&#36890;&#24615;&#30340;&#34920;&#36798;&#24230;&#37327;&#65292;&#24182;&#24378;&#35843;&#23427;&#20204;&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#20013;&#30340;&#37325;&#35201;&#24615;&#12290;&#30001;&#20110;&#21452;&#36830;&#36890;&#24615;&#21487;&#20197;&#20351;&#29992;&#31616;&#21333;&#30340;&#31639;&#27861;&#36827;&#34892;&#35745;&#31639;&#65292;&#24182;&#19988;&#20855;&#26377;&#32447;&#24615;&#30340;&#35745;&#31639;&#25104;&#26412;&#65292;&#22240;&#27492;&#24456;&#33258;&#28982;&#22320;&#21487;&#20197;&#26399;&#26395;&#27969;&#34892;&#30340;GNNs&#20063;&#21487;&#20197;&#24456;&#23481;&#26131;&#22320;&#36827;&#34892;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#32463;&#36807;&#23545;&#20197;&#21069;&#30340;GNN&#26550;&#26500;&#30340;&#24443;&#24213;&#23457;&#26597;&#65292;&#25105;&#20204;&#24778;&#35766;&#22320;&#21457;&#29616;&#22823;&#22810;&#25968;&#26550;&#26500;&#23545;&#20110;&#20219;&#20309;&#36825;&#20123;&#24230;&#37327;&#37117;&#19981;&#20855;&#26377;&#34920;&#36798;&#33021;&#21147;&#12290;&#21807;&#19968;&#30340;&#20363;&#22806;&#26159;ESAN&#26694;&#26550;&#65292;&#23545;&#20110;&#35813;&#26694;&#26550;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Designing expressive Graph Neural Networks (GNNs) is a central topic in learning graph-structured data. While numerous approaches have been proposed to improve GNNs in terms of the Weisfeiler-Lehman (WL) test, generally there is still a lack of deep understanding of what additional power they can systematically and provably gain. In this paper, we take a fundamentally different perspective to study the expressive power of GNNs beyond the WL test. Specifically, we introduce a novel class of expressivity metrics via graph biconnectivity and highlight their importance in both theory and practice. As biconnectivity can be easily calculated using simple algorithms that have linear computational costs, it is natural to expect that popular GNNs can learn it easily as well. However, after a thorough review of prior GNN architectures, we surprisingly find that most of them are not expressive for any of these metrics. The only exception is the ESAN framework, for which we give a theoretical just
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#22810;&#39033;&#24335;&#20998;&#26512;&#65292;&#23545;&#21160;&#37327;&#22806;&#31227;&#26799;&#24230;&#26041;&#27861;&#22312;&#19981;&#21516;&#24773;&#26223;&#19979;&#30340;&#21152;&#36895;&#25910;&#25947;&#36827;&#34892;&#30740;&#31350;&#65292;&#21253;&#25324;&#29305;&#24449;&#20540;&#23384;&#22312;&#20110;&#23454;&#36724;&#12289;&#20301;&#20110;&#23454;&#36724;&#19978;&#30340;&#20849;&#36717;&#22797;&#25968;&#25110;&#20165;&#23384;&#22312;&#20849;&#36717;&#22797;&#25968;&#30340;&#24773;&#20917;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#24471;&#20986;&#20102;&#23454;&#29616;&#26368;&#24555;&#25910;&#25947;&#30340;&#36229;&#21442;&#25968;&#12290;</title><link>https://arxiv.org/abs/2211.04659</link><description>&lt;p&gt;
&#21160;&#37327;&#22806;&#31227;&#26799;&#24230;&#20309;&#26102;&#33021;&#36798;&#21040;&#26368;&#20339;&#65311;&#22522;&#20110;&#22810;&#39033;&#24335;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
When is Momentum Extragradient Optimal? A Polynomial-Based Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2211.04659
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#22810;&#39033;&#24335;&#20998;&#26512;&#65292;&#23545;&#21160;&#37327;&#22806;&#31227;&#26799;&#24230;&#26041;&#27861;&#22312;&#19981;&#21516;&#24773;&#26223;&#19979;&#30340;&#21152;&#36895;&#25910;&#25947;&#36827;&#34892;&#30740;&#31350;&#65292;&#21253;&#25324;&#29305;&#24449;&#20540;&#23384;&#22312;&#20110;&#23454;&#36724;&#12289;&#20301;&#20110;&#23454;&#36724;&#19978;&#30340;&#20849;&#36717;&#22797;&#25968;&#25110;&#20165;&#23384;&#22312;&#20849;&#36717;&#22797;&#25968;&#30340;&#24773;&#20917;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#24471;&#20986;&#20102;&#23454;&#29616;&#26368;&#24555;&#25910;&#25947;&#30340;&#36229;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22806;&#31227;&#26799;&#24230;&#26041;&#27861;&#30001;&#20110;&#20854;&#22312;&#21487;&#24494;&#20998;&#21338;&#24328;&#20013;&#30340;&#31283;&#20581;&#25910;&#25947;&#24615;&#32780;&#21463;&#21040;&#38738;&#30544;&#12290;&#19982;&#21333;&#30446;&#26631;&#20248;&#21270;&#19981;&#21516;&#65292;&#21338;&#24328;&#21160;&#21147;&#23398;&#28041;&#21450;&#21040;&#22797;&#26434;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#36825;&#31181;&#30456;&#20114;&#20316;&#29992;&#36890;&#36807;&#21338;&#24328;&#21521;&#37327;&#22330;&#30340;&#38597;&#21487;&#27604;&#30697;&#38453;&#30340;&#29305;&#24449;&#20540;&#25955;&#24067;&#22312;&#22797;&#24179;&#38754;&#19978;&#12290;&#36825;&#31181;&#22797;&#26434;&#24615;&#20250;&#23548;&#33268;&#31616;&#21333;&#30340;&#26799;&#24230;&#26041;&#27861;&#21457;&#25955;&#65292;&#21363;&#20351;&#23545;&#20110;&#21452;&#32447;&#24615;&#21338;&#24328;&#20063;&#26159;&#22914;&#27492;&#65292;&#32780;&#22806;&#31227;&#26799;&#24230;&#26041;&#27861;&#21364;&#33021;&#23454;&#29616;&#25910;&#25947;&#12290;&#22312;&#26368;&#36817;&#35777;&#26126;&#30340;&#22522;&#30784;&#19978;&#65292;&#21363;&#21160;&#37327;&#22806;&#31227;&#26799;&#24230;&#26041;&#27861;&#22312;&#21452;&#32447;&#24615;&#21338;&#24328;&#20013;&#23454;&#29616;&#21152;&#36895;&#25910;&#25947;\citep{azizian2020accelerating}&#65292;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#22810;&#39033;&#24335;&#30340;&#20998;&#26512;&#26469;&#30830;&#23450;&#35813;&#26041;&#27861;&#20986;&#29616;&#36827;&#19968;&#27493;&#21152;&#36895;&#25910;&#25947;&#30340;&#19977;&#31181;&#19981;&#21516;&#24773;&#26223;&#12290;&#36825;&#20123;&#24773;&#26223;&#21253;&#25324;&#29305;&#24449;&#20540;&#23384;&#22312;&#20110;&#65288;&#27491;&#65289;&#23454;&#36724;&#19978;&#12289;&#20301;&#20110;&#23454;&#36724;&#19978;&#30340;&#20849;&#36717;&#22797;&#25968;&#20197;&#21450;&#20165;&#23384;&#22312;&#20849;&#36717;&#22797;&#25968;&#30340;&#24773;&#20917;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20986;&#27599;&#20010;&#24773;&#26223;&#30340;&#36229;&#21442;&#25968;&#65292;&#20197;&#23454;&#29616;&#26368;&#24555;&#30340;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;
The extragradient method has gained popularity due to its robust convergence properties for differentiable games. Unlike single-objective optimization, game dynamics involve complex interactions reflected by the eigenvalues of the game vector field's Jacobian scattered across the complex plane. This complexity can cause the simple gradient method to diverge, even for bilinear games, while the extragradient method achieves convergence. Building on the recently proven accelerated convergence of the momentum extragradient method for bilinear games \citep{azizian2020accelerating}, we use a polynomial-based analysis to identify three distinct scenarios where this method exhibits further accelerated convergence. These scenarios encompass situations where the eigenvalues reside on the (positive) real line, lie on the real line alongside complex conjugates, or exist solely as complex conjugates. Furthermore, we derive the hyperparameters for each scenario that achieve the fastest convergence r
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#21160;&#24577;&#28508;&#21464;&#37327;&#20998;&#31163;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#22797;&#26434;&#25968;&#25454;&#20013;&#23398;&#20064;&#34920;&#36798;&#24615;&#24378;&#30340;&#28508;&#21464;&#37327;&#65292;&#25552;&#21319;&#36755;&#20986;&#30340;&#22810;&#26679;&#24615;&#12290;&#35813;&#26041;&#27861;&#21463;&#21407;&#23376;&#29289;&#29702;&#23398;&#21551;&#21457;&#65292;&#36890;&#36807;&#23398;&#20064;&#27599;&#20010;&#25968;&#25454;&#26679;&#26412;&#30340;&#32467;&#26500;&#26469;&#35299;&#37322;&#21508;&#20010;&#23376;&#32452;&#20214;&#30340;&#37325;&#35201;&#24615;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#19981;&#21516;&#20998;&#31867;&#21644;&#29983;&#25104;&#38382;&#39064;&#20013;&#25552;&#21319;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2210.03728</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#21160;&#24577;&#28508;&#21464;&#37327;&#20998;&#31163;
&lt;/p&gt;
&lt;p&gt;
Dynamic Latent Separation for Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2210.03728
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#21160;&#24577;&#28508;&#21464;&#37327;&#20998;&#31163;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#22797;&#26434;&#25968;&#25454;&#20013;&#23398;&#20064;&#34920;&#36798;&#24615;&#24378;&#30340;&#28508;&#21464;&#37327;&#65292;&#25552;&#21319;&#36755;&#20986;&#30340;&#22810;&#26679;&#24615;&#12290;&#35813;&#26041;&#27861;&#21463;&#21407;&#23376;&#29289;&#29702;&#23398;&#21551;&#21457;&#65292;&#36890;&#36807;&#23398;&#20064;&#27599;&#20010;&#25968;&#25454;&#26679;&#26412;&#30340;&#32467;&#26500;&#26469;&#35299;&#37322;&#21508;&#20010;&#23376;&#32452;&#20214;&#30340;&#37325;&#35201;&#24615;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#19981;&#21516;&#20998;&#31867;&#21644;&#29983;&#25104;&#38382;&#39064;&#20013;&#25552;&#21319;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#26159;&#20197;&#28789;&#27963;&#21644;&#21487;&#35299;&#37322;&#30340;&#26041;&#24335;&#23398;&#20064;&#29992;&#20110;&#22797;&#26434;&#25968;&#25454;&#27169;&#22411;&#39044;&#27979;&#30340;&#34920;&#36798;&#24615;&#28508;&#21464;&#37327;&#65292;&#36825;&#20123;&#25968;&#25454;&#21253;&#21547;&#22810;&#20010;&#23376;&#32452;&#20214;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#25913;&#36827;&#20102;&#34920;&#36798;&#24615;&#65292;&#25552;&#20379;&#20102;&#37096;&#20998;&#35299;&#37322;&#65292;&#24182;&#19988;&#19981;&#38480;&#20110;&#29305;&#23450;&#30340;&#24212;&#29992;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#22312;&#28508;&#31354;&#38388;&#20013;&#21160;&#24577;&#22320;&#20998;&#31163;&#25968;&#25454;&#26679;&#26412;&#65292;&#20174;&#32780;&#22686;&#24378;&#36755;&#20986;&#30340;&#22810;&#26679;&#24615;&#12290;&#25105;&#20204;&#30340;&#21160;&#24577;&#28508;&#21464;&#37327;&#20998;&#31163;&#26041;&#27861;&#21463;&#21040;&#21407;&#23376;&#29289;&#29702;&#23398;&#30340;&#21551;&#21457;&#65292;&#20381;&#36182;&#20110;&#27599;&#20010;&#25968;&#25454;&#26679;&#26412;&#20849;&#21516;&#23398;&#20064;&#30340;&#32467;&#26500;&#65292;&#36825;&#20063;&#25581;&#31034;&#20986;&#20102;&#27599;&#20010;&#23376;&#32452;&#20214;&#22312;&#21306;&#20998;&#25968;&#25454;&#26679;&#26412;&#20013;&#30340;&#37325;&#35201;&#24615;&#12290;&#36825;&#31181;&#26041;&#27861;&#65292;&#21407;&#23376;&#24314;&#27169;&#65292;&#19981;&#38656;&#35201;&#23545;&#28508;&#31354;&#38388;&#36827;&#34892;&#30417;&#30563;&#65292;&#24182;&#19988;&#20801;&#35768;&#25105;&#20204;&#23398;&#20064;&#39069;&#22806;&#30340;&#37096;&#20998;&#21487;&#35299;&#37322;&#34920;&#31034;&#65292;&#38500;&#20102;&#27169;&#22411;&#30340;&#21407;&#22987;&#30446;&#26631;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#31639;&#27861;&#36824;&#25552;&#39640;&#20102;&#21508;&#31181;&#20998;&#31867;&#21644;&#29983;&#25104;&#38382;&#39064;&#20013;&#23567;&#21040;&#22823;&#35268;&#27169;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
A core problem in machine learning is to learn expressive latent variables for model prediction on complex data that involves multiple sub-components in a flexible and interpretable fashion. Here, we develop an approach that improves expressiveness, provides partial interpretation, and is not restricted to specific applications. The key idea is to dynamically distance data samples in the latent space and thus enhance the output diversity. Our dynamic latent separation method, inspired by atomic physics, relies on the jointly learned structures of each data sample, which also reveal the importance of each sub-component for distinguishing data samples. This approach, atom modeling, requires no supervision of the latent space and allows us to learn extra partially interpretable representations besides the original goal of a model. We empirically demonstrate that the algorithm also enhances the performance of small to larger-scale models in various classification and generation problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25935;&#24863;&#24615;&#26377;&#30028;&#30340;&#20010;&#24615;&#21270;PageRank&#31639;&#27861;&#65292;&#33021;&#22815;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#12290;&#35813;&#31639;&#27861;&#22312;&#20445;&#25345;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#20102;&#24046;&#20998;&#38544;&#31169;&#22270;&#23398;&#20064;&#30340;&#20960;&#31181;&#24037;&#20855;&#12290;</title><link>https://arxiv.org/abs/2207.06944</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#22270;&#23398;&#20064;&#30340;&#25935;&#24863;&#24615;&#26377;&#30028;&#20010;&#24615;&#21270;PageRank&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Graph Learning via Sensitivity-Bounded Personalized PageRank
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2207.06944
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25935;&#24863;&#24615;&#26377;&#30028;&#30340;&#20010;&#24615;&#21270;PageRank&#31639;&#27861;&#65292;&#33021;&#22815;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#12290;&#35813;&#31639;&#27861;&#22312;&#20445;&#25345;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#20102;&#24046;&#20998;&#38544;&#31169;&#22270;&#23398;&#20064;&#30340;&#20960;&#31181;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;PageRank(PPR)&#26159;&#19968;&#31181;&#22522;&#26412;&#24037;&#20855;&#65292;&#29992;&#20110;&#26080;&#30417;&#30563;&#23398;&#20064;&#22270;&#34920;&#31034;&#65292;&#22914;&#33410;&#28857;&#25490;&#24207;&#12289;&#26631;&#27880;&#21644;&#22270;&#23884;&#20837;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#25968;&#25454;&#38544;&#31169;&#25104;&#20026;&#26368;&#36817;&#26368;&#37325;&#35201;&#30340;&#20851;&#27880;&#28857;&#20043;&#19968;&#65292;&#29616;&#26377;&#30340;PPR&#31639;&#27861;&#24182;&#26410;&#35774;&#35745;&#29992;&#20110;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#12290;PPR&#23545;&#36755;&#20837;&#22270;&#30340;&#36793;&#38750;&#24120;&#25935;&#24863;&#65306;&#20165;&#24046;&#19968;&#20010;&#36793;&#30340;&#24046;&#24322;&#21487;&#33021;&#20250;&#23548;&#33268;PPR&#21521;&#37327;&#21457;&#29983;&#24040;&#22823;&#25913;&#21464;&#65292;&#20174;&#32780;&#21487;&#33021;&#27844;&#28431;&#29992;&#25143;&#31169;&#23494;&#25968;&#25454;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36755;&#20986;&#36817;&#20284;PPR&#65292;&#24182;&#23545;&#36755;&#20837;&#36793;&#20855;&#26377;&#21487;&#35777;&#26126;&#30340;&#25935;&#24863;&#24615;&#36793;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#36755;&#20837;&#22270;&#20855;&#26377;&#22823;&#24230;&#25968;&#26102;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#36798;&#21040;&#19982;&#38750;&#31169;&#23494;&#31639;&#27861;&#30456;&#20284;&#30340;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#25935;&#24863;&#24615;&#26377;&#30028;PPR&#30452;&#25509;&#24847;&#21619;&#30528;&#22270;&#23398;&#20064;&#30340;&#20960;&#31181;&#31169;&#23494;&#31639;&#27861;&#65292;&#22914;&#24046;&#20998;&#38544;&#31169;(DP)PPR&#25490;&#24207;&#12289;DP&#33410;&#28857;&#20998;&#31867;&#21644;DP&#33410;&#28857;&#23884;&#20837;&#12290;&#20026;&#20102;&#34917;&#20805;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#36824;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#23454;&#38469;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Personalized PageRank (PPR) is a fundamental tool in unsupervised learning of graph representations such as node ranking, labeling, and graph embedding. However, while data privacy is one of the most important recent concerns, existing PPR algorithms are not designed to protect user privacy. PPR is highly sensitive to the input graph edges: the difference of only one edge may cause a big change in the PPR vector, potentially leaking private user data.   In this work, we propose an algorithm which outputs an approximate PPR and has provably bounded sensitivity to input edges. In addition, we prove that our algorithm achieves similar accuracy to non-private algorithms when the input graph has large degrees. Our sensitivity-bounded PPR directly implies private algorithms for several tools of graph learning, such as, differentially private (DP) PPR ranking, DP node classification, and DP node embedding. To complement our theoretical analysis, we also empirically verify the practical perfor
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21464;&#37327;&#36873;&#25321;&#30340;&#35745;&#31639;&#39640;&#25928;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#33021;&#22815;&#33258;&#21160;&#23398;&#20064;&#23376;&#31354;&#38388;&#26469;&#20248;&#21270;&#39640;&#32500;&#22495;&#20989;&#25968;&#65292;&#21516;&#26102;&#20943;&#23569;&#20102;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#32791;&#26102;&#38382;&#39064;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2109.09264</link><description>&lt;p&gt;
&#21464;&#37327;&#36873;&#25321;&#30340;&#35745;&#31639;&#39640;&#25928;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Computationally Efficient High-Dimensional Bayesian Optimization via Variable Selection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2109.09264
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21464;&#37327;&#36873;&#25321;&#30340;&#35745;&#31639;&#39640;&#25928;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#33021;&#22815;&#33258;&#21160;&#23398;&#20064;&#23376;&#31354;&#38388;&#26469;&#20248;&#21270;&#39640;&#32500;&#22495;&#20989;&#25968;&#65292;&#21516;&#26102;&#20943;&#23569;&#20102;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#32791;&#26102;&#38382;&#39064;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#26159;&#19968;&#31181;&#29992;&#20110;&#20840;&#23616;&#20248;&#21270;&#40657;&#30418;&#20989;&#25968;&#30340;&#26041;&#27861;&#12290;&#34429;&#28982;BO&#24050;&#25104;&#21151;&#24212;&#29992;&#20110;&#35768;&#22810;&#22330;&#26223;&#65292;&#20294;&#26159;&#24320;&#21457;&#33021;&#22815;&#36866;&#29992;&#20110;&#39640;&#32500;&#22495;&#20989;&#25968;&#30340;&#26377;&#25928;BO&#31639;&#27861;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#36890;&#36807;&#26222;&#36890;&#30340;BO&#20248;&#21270;&#27492;&#31867;&#20989;&#25968;&#38750;&#24120;&#32791;&#26102;&#12290;&#22522;&#20110;&#23558;&#39640;&#32500;&#31354;&#38388;&#23884;&#20837;&#21040;&#20302;&#32500;&#31354;&#38388;&#30340;&#24605;&#24819;&#30340;&#39640;&#32500;BO&#30340;&#26367;&#20195;&#31574;&#30053;&#23545;&#23884;&#20837;&#32500;&#24230;&#30340;&#36873;&#25321;&#38750;&#24120;&#25935;&#24863;&#65292;&#38656;&#35201;&#39044;&#20808;&#25351;&#23450;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#35745;&#31639;&#39640;&#25928;&#30340;&#39640;&#32500;BO&#26041;&#27861;&#65292;&#21033;&#29992;&#20102;&#21464;&#37327;&#36873;&#25321;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#33258;&#21160;&#23398;&#20064;&#36724;&#23545;&#40784;&#30340;&#23376;&#31354;&#38388;&#65292;&#21363;&#21253;&#21547;&#36873;&#23450;&#21464;&#37327;&#30340;&#31354;&#38388;&#65292;&#32780;&#26080;&#38656;&#20219;&#20309;&#39044;&#20808;&#25351;&#23450;&#30340;&#36229;&#21442;&#25968;&#12290;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#20998;&#26512;&#20102;&#31639;&#27861;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#24182;&#24471;&#20986;&#20102;&#36951;&#25022;&#30028;&#38480;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian Optimization (BO) is a method for globally optimizing black-box functions. While BO has been successfully applied to many scenarios, developing effective BO algorithms that scale to functions with high-dimensional domains is still a challenge. Optimizing such functions by vanilla BO is extremely time-consuming. Alternative strategies for high-dimensional BO that are based on the idea of embedding the high-dimensional space to the one with low dimension are sensitive to the choice of the embedding dimension, which needs to be pre-specified. We develop a new computationally efficient high-dimensional BO method that exploits variable selection. Our method is able to automatically learn axis-aligned sub-spaces, i.e. spaces containing selected variables, without the demand of any pre-specified hyperparameters. We theoretically analyze the computational complexity of our algorithm and derive the regret bound. We empirically show the efficacy of our method on several synthetic and re
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30417;&#30563;&#23398;&#20064;&#38598;&#25104;&#26694;&#26550;&#8212;&#8212;&#26426;&#22120;&#21327;&#20316;&#65288;MaC&#65289;&#65292;&#36890;&#36807;&#24490;&#29615;&#21644;&#20132;&#20114;&#30340;&#23398;&#20064;&#26041;&#24335;&#65292;&#20351;&#22522;&#30784;&#26426;&#22120;&#33021;&#22815;&#24490;&#29615;&#20256;&#36882;&#20449;&#24687;&#24182;&#30456;&#24212;&#22320;&#26356;&#26032;&#32467;&#26500;&#21644;&#21442;&#25968;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;MaC&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#20808;&#36827;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2105.02569</link><description>&lt;p&gt;
&#26426;&#22120;&#21327;&#20316;
&lt;/p&gt;
&lt;p&gt;
Machine Collaboration
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2105.02569
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30417;&#30563;&#23398;&#20064;&#38598;&#25104;&#26694;&#26550;&#8212;&#8212;&#26426;&#22120;&#21327;&#20316;&#65288;MaC&#65289;&#65292;&#36890;&#36807;&#24490;&#29615;&#21644;&#20132;&#20114;&#30340;&#23398;&#20064;&#26041;&#24335;&#65292;&#20351;&#22522;&#30784;&#26426;&#22120;&#33021;&#22815;&#24490;&#29615;&#20256;&#36882;&#20449;&#24687;&#24182;&#30456;&#24212;&#22320;&#26356;&#26032;&#32467;&#26500;&#21644;&#21442;&#25968;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;MaC&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30417;&#30563;&#23398;&#20064;&#38598;&#25104;&#26694;&#26550;&#65292;&#31216;&#20026;&#26426;&#22120;&#21327;&#20316;&#65288;MaC&#65289;&#65292;&#21033;&#29992;&#19968;&#32452;&#22522;&#30784;&#26426;&#22120;&#36827;&#34892;&#39044;&#27979;&#20219;&#21153;&#12290;&#19982;&#24182;&#34892;&#19988;&#29420;&#31435;&#30340;bagging/stacking&#26694;&#26550;&#21644;&#39034;&#24207;&#19988;&#33258;&#19978;&#32780;&#19979;&#30340;boosting&#26694;&#26550;&#19981;&#21516;&#65292;MaC&#26159;&#19968;&#31181;&#24490;&#29615;&#21644;&#20132;&#20114;&#23398;&#20064;&#26694;&#26550;&#12290;&#24490;&#29615;&#21644;&#20132;&#20114;&#29305;&#24615;&#24110;&#21161;&#22522;&#30784;&#26426;&#22120;&#24490;&#29615;&#20256;&#36882;&#20449;&#24687;&#24182;&#30456;&#24212;&#22320;&#26356;&#26032;&#20854;&#32467;&#26500;&#21644;&#21442;&#25968;&#12290;&#23545;&#20110;&#20174;MaC&#24471;&#20986;&#30340;&#20272;&#35745;&#22120;&#30340;&#39118;&#38505;&#30028;&#30340;&#29702;&#35770;&#32467;&#26524;&#34920;&#26126;&#65292;&#24490;&#29615;&#21644;&#20132;&#20114;&#29305;&#24615;&#21487;&#20197;&#24110;&#21161;MaC&#36890;&#36807;&#31616;&#27905;&#30340;&#38598;&#25104;&#20943;&#23569;&#39118;&#38505;&#12290;&#25105;&#20204;&#22312;&#27169;&#25311;&#25968;&#25454;&#21644;119&#20010;&#22522;&#20934;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#65292;MaC&#30340;&#24615;&#33021;&#26174;&#33879;&#20248;&#20110;&#21253;&#25324;&#20998;&#31867;&#22238;&#24402;&#26641;&#12289;&#31070;&#32463;&#32593;&#32476;&#12289;&#22534;&#21472;&#21644;&#25552;&#21319;&#22312;&#20869;&#30340;&#20854;&#20182;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new ensemble framework for supervised learning, called machine collaboration (MaC), using a collection of base machines for prediction tasks. Unlike bagging/stacking (a parallel &amp; independent framework) and boosting (a sequential &amp; top-down framework), MaC is a type of circular &amp; interactive learning framework. The circular &amp; interactive feature helps the base machines to transfer information circularly and update their structures and parameters accordingly. The theoretical result on the risk bound of the estimator from MaC reveals that the circular &amp; interactive feature can help MaC reduce risk via a parsimonious ensemble. We conduct extensive experiments on MaC using both simulated data and 119 benchmark real datasets. The results demonstrate that in most cases, MaC performs significantly better than several other state-of-the-art methods, including classification and regression trees, neural networks, stacking, and boosting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#20856;&#22411;&#27491;&#21017;&#21270;&#30340;&#31232;&#30095;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#24378;&#40065;&#26834;&#24615;&#21644;&#24369;&#40065;&#26834;&#24615;&#30340;&#27010;&#24565;&#65292;&#24182;&#32473;&#20986;&#20102;&#29702;&#35770;&#20445;&#35777;&#21644;&#25968;&#20540;&#23454;&#39564;&#26469;&#21152;&#24378;&#36825;&#20123;&#27010;&#24565;&#30340;&#27934;&#23519;&#21147;&#12290;</title><link>https://arxiv.org/abs/2104.03527</link><description>&lt;p&gt;
&#31232;&#30095;NMF&#19982;&#20856;&#22411;&#27491;&#21017;&#21270;&#65306;&#35745;&#31639;&#21644;&#40065;&#26834;&#24615;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Sparse NMF with Archetypal Regularization: Computational and Robustness Properties
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2104.03527
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#20856;&#22411;&#27491;&#21017;&#21270;&#30340;&#31232;&#30095;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#24378;&#40065;&#26834;&#24615;&#21644;&#24369;&#40065;&#26834;&#24615;&#30340;&#27010;&#24565;&#65292;&#24182;&#32473;&#20986;&#20102;&#29702;&#35770;&#20445;&#35777;&#21644;&#25968;&#20540;&#23454;&#39564;&#26469;&#21152;&#24378;&#36825;&#20123;&#27010;&#24565;&#30340;&#27934;&#23519;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#20856;&#22411;&#27491;&#21017;&#21270;&#30340;&#31232;&#30095;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#65288;NMF&#65289;&#38382;&#39064;&#12290;&#30446;&#26631;&#26159;&#23558;&#19968;&#32452;&#25968;&#25454;&#28857;&#34920;&#31034;&#20026;&#23569;&#25968;&#38750;&#36127;&#31232;&#30095;&#22240;&#23376;&#30340;&#38750;&#36127;&#32447;&#24615;&#32452;&#21512;&#65292;&#36825;&#20123;&#22240;&#23376;&#20855;&#26377;&#21560;&#24341;&#20154;&#30340;&#20960;&#20309;&#29305;&#24615;&#65292;&#26469;&#33258;&#20110;&#20351;&#29992;&#20856;&#22411;&#27491;&#21017;&#21270;&#12290;&#25105;&#20204;&#23558;&#22312;Javadi&#21644;Montanari&#65288;2019&#65289;&#20013;&#30740;&#31350;&#30340;&#40065;&#26834;&#24615;&#27010;&#24565;&#65288;&#26080;&#31232;&#30095;&#24615;&#65289;&#25512;&#24191;&#20026;&#65288;a&#65289;&#24378;&#40065;&#26834;&#24615;&#65292;&#21363;&#27599;&#20010;&#20272;&#35745;&#30340;&#20856;&#22411;&#37117;&#25509;&#36817;&#30495;&#23454;&#30340;&#20856;&#22411;&#65292;&#20197;&#21450;&#65288;b&#65289;&#24369;&#40065;&#26834;&#24615;&#65292;&#21363;&#33267;&#23569;&#23384;&#22312;&#19968;&#20010;&#24674;&#22797;&#30340;&#20856;&#22411;&#25509;&#36817;&#30495;&#23454;&#30340;&#20856;&#22411;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#23545;&#20110;&#22522;&#30784;&#25968;&#25454;&#30340;&#20551;&#35774;&#36739;&#20026;&#31616;&#21270;&#65292;&#24182;&#36866;&#29992;&#20110;&#22522;&#20110;&#19981;&#38656;&#35201;&#31232;&#30095;&#24615;&#30340;&#20856;&#22411;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#31639;&#27861;&#26469;&#20248;&#21270;&#25105;&#20204;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of sparse nonnegative matrix factorization (NMF) using archetypal regularization. The goal is to represent a collection of data points as nonnegative linear combinations of a few nonnegative sparse factors with appealing geometric properties, arising from the use of archetypal regularization. We generalize the notion of robustness studied in Javadi and Montanari (2019) (without sparsity) to the notions of (a) strong robustness that implies each estimated archetype is close to the underlying archetypes and (b) weak robustness that implies there exists at least one recovered archetype that is close to the underlying archetypes. Our theoretical results on robustness guarantees hold under minimal assumptions on the underlying data, and applies to settings where the underlying archetypes need not be sparse. We present theoretical results and illustrative examples to strengthen the insights underlying the notions of robustness. We propose new algorithms for our optimi
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#32593;&#32476;&#37325;&#24314;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27425;&#20108;&#27425;&#26102;&#38388;&#20869;&#23454;&#29616;&#32467;&#26524;&#65292;&#36890;&#36807;&#38543;&#26426;&#30340;&#20108;&#38454;&#37051;&#23621;&#25628;&#32034;&#20135;&#29983;&#26368;&#20339;&#30340;&#36793;&#20505;&#36873;&#12290;</title><link>http://arxiv.org/abs/2401.01404</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;&#23376;&#20108;&#27425;&#26102;&#38388;&#32593;&#32476;&#37325;&#24314;
&lt;/p&gt;
&lt;p&gt;
Scalable network reconstruction in subquadratic time. (arXiv:2401.01404v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01404
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#32593;&#32476;&#37325;&#24314;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27425;&#20108;&#27425;&#26102;&#38388;&#20869;&#23454;&#29616;&#32467;&#26524;&#65292;&#36890;&#36807;&#38543;&#26426;&#30340;&#20108;&#38454;&#37051;&#23621;&#25628;&#32034;&#20135;&#29983;&#26368;&#20339;&#30340;&#36793;&#20505;&#36873;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#37325;&#24314;&#26159;&#25351;&#22312;&#21482;&#26377;&#20851;&#20110;&#26465;&#20214;&#20598;&#32852;&#30340;&#35266;&#27979;&#25968;&#25454;&#65292;&#20363;&#22914;&#26102;&#38388;&#24207;&#21015;&#25110;&#22270;&#27169;&#22411;&#30340;&#29420;&#31435;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#65292;&#30830;&#23450;N&#20010;&#33410;&#28857;&#20043;&#38388;&#26410;&#35266;&#27979;&#21040;&#30340;&#25104;&#23545;&#32806;&#21512;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#25552;&#20986;&#30340;&#31639;&#27861;&#30340;&#21487;&#25193;&#23637;&#24615;&#30340;&#20027;&#35201;&#38556;&#30861;&#26159;&#20284;&#20046;&#26080;&#27861;&#36991;&#20813;&#30340;&#20108;&#27425;&#22797;&#26434;&#24230;O(N^2)&#65292;&#21363;&#35201;&#32771;&#34385;&#27599;&#31181;&#21487;&#33021;&#30340;&#25104;&#23545;&#32806;&#21512;&#33267;&#23569;&#19968;&#27425;&#65292;&#23613;&#31649;&#22823;&#22810;&#25968;&#24863;&#20852;&#36259;&#30340;&#32593;&#32476;&#37117;&#26159;&#31232;&#30095;&#30340;&#65292;&#38750;&#38646;&#32806;&#21512;&#30340;&#25968;&#37327;&#21482;&#26377;O(N)&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#24191;&#27867;&#37325;&#24314;&#38382;&#39064;&#30340;&#36890;&#29992;&#31639;&#27861;&#65292;&#20854;&#22312;&#23376;&#20108;&#27425;&#26102;&#38388;&#20869;&#23454;&#29616;&#32467;&#26524;&#65292;&#20854;&#25968;&#25454;&#30456;&#20851;&#22797;&#26434;&#24230;&#23485;&#26494;&#19978;&#30028;&#20026;O(N^(3/2)logN)&#65292;&#20294;&#20855;&#26377;&#26356;&#20856;&#22411;&#30340;&#23545;&#25968;&#32447;&#24615;&#22797;&#26434;&#24230;O(Nlog^2 N)&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20381;&#36182;&#20110;&#19968;&#20010;&#38543;&#26426;&#30340;&#20108;&#38454;&#37051;&#23621;&#25628;&#32034;&#65292;&#20135;&#29983;&#20102;&#26368;&#20339;&#30340;&#36793;&#20505;&#36873;&#12290;
&lt;/p&gt;
&lt;p&gt;
Network reconstruction consists in determining the unobserved pairwise couplings between $N$ nodes given only observational data on the resulting behavior that is conditioned on those couplings -- typically a time-series or independent samples from a graphical model. A major obstacle to the scalability of algorithms proposed for this problem is a seemingly unavoidable quadratic complexity of $O(N^2)$, corresponding to the requirement of each possible pairwise coupling being contemplated at least once, despite the fact that most networks of interest are sparse, with a number of non-zero couplings that is only $O(N)$. Here we present a general algorithm applicable to a broad range of reconstruction problems that achieves its result in subquadratic time, with a data-dependent complexity loosely upper bounded by $O(N^{3/2}\log N)$, but with a more typical log-linear complexity of $O(N\log^2N)$. Our algorithm relies on a stochastic second neighbor search that produces the best edge candidat
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;GNNSync&#30340;&#22522;&#20110;&#26377;&#21521;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#35282;&#24230;&#21516;&#27493;&#35299;&#20915;&#26041;&#26696;&#65292;&#35299;&#20915;&#20102;&#35282;&#24230;&#21516;&#27493;&#38382;&#39064;&#22312;&#39640;&#22122;&#22768;&#29615;&#22659;&#19979;&#30340;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#20197;&#26356;&#22909;&#22320;&#32534;&#30721;&#21516;&#27493;&#32422;&#26463;&#12290;</title><link>http://arxiv.org/abs/2310.05842</link><description>&lt;p&gt;
&#40065;&#26834;&#30340;&#35282;&#24230;&#21516;&#27493;&#38382;&#39064;&#30340;&#26377;&#21521;&#22270;&#31070;&#32463;&#32593;&#32476;&#35299;&#20915;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Robust Angular Synchronization via Directed Graph Neural Networks. (arXiv:2310.05842v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05842
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;GNNSync&#30340;&#22522;&#20110;&#26377;&#21521;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#35282;&#24230;&#21516;&#27493;&#35299;&#20915;&#26041;&#26696;&#65292;&#35299;&#20915;&#20102;&#35282;&#24230;&#21516;&#27493;&#38382;&#39064;&#22312;&#39640;&#22122;&#22768;&#29615;&#22659;&#19979;&#30340;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#20197;&#26356;&#22909;&#22320;&#32534;&#30721;&#21516;&#27493;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35282;&#24230;&#21516;&#27493;&#38382;&#39064;&#26088;&#22312;&#36890;&#36807;$m$&#20010;&#20559;&#31227;&#37327;$\theta_i-\theta_j \;\mbox{mod} \; 2\pi$&#30340;&#22122;&#22768;&#27979;&#37327;&#20934;&#30830;&#20272;&#35745;&#65288;&#26368;&#22810;&#19968;&#20010;&#24120;&#25968;&#30456;&#20301;&#20559;&#31227;&#65289;&#19968;&#32452;&#26410;&#30693;&#35282;&#24230;$\theta_1, \dots, \theta_n\in[0, 2\pi)$. &#24212;&#29992;&#21253;&#25324;&#20256;&#24863;&#22120;&#32593;&#32476;&#23450;&#20301;&#12289;&#30456;&#20301;&#24674;&#22797;&#21644;&#20998;&#24067;&#24335;&#26102;&#38047;&#21516;&#27493;&#12290;&#35813;&#38382;&#39064;&#30340;&#24322;&#26500;&#25193;&#23637;&#65288;&#31216;&#20026;$k$-&#21516;&#27493;&#65289;&#26159;&#21516;&#26102;&#20272;&#35745;$k$&#32452;&#35282;&#24230;&#65292;&#32473;&#23450;&#27599;&#20010;&#32452;&#30340;&#26410;&#30693;&#32452;&#20998;&#37197;&#30340;&#22122;&#22768;&#35266;&#23519;&#20540;&#12290;&#29616;&#26377;&#30340;&#35282;&#24230;&#21516;&#27493;&#26041;&#27861;&#22312;&#39640;&#22122;&#22768;&#29615;&#22659;&#19979;&#36890;&#24120;&#34920;&#29616;&#19981;&#20339;&#65292;&#32780;&#36825;&#22312;&#24212;&#29992;&#20013;&#24456;&#24120;&#35265;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#35299;&#20915;&#35282;&#24230;&#21516;&#27493;&#38382;&#39064;&#21450;&#20854;&#24322;&#26500;&#25193;&#23637;&#65292;&#25552;&#20986;&#20102;GNNSync&#65292;&#36825;&#26159;&#19968;&#20010;&#29702;&#35770;&#25903;&#25745;&#30340;&#31471;&#21040;&#31471;&#21487;&#35757;&#32451;&#26694;&#26550;&#65292;&#20351;&#29992;&#26377;&#21521;&#22270;&#31070;&#32463;&#32593;&#32476;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#26469;&#32534;&#30721;&#35282;&#24230;&#21516;&#27493;&#30340;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;
The angular synchronization problem aims to accurately estimate (up to a constant additive phase) a set of unknown angles $\theta_1, \dots, \theta_n\in[0, 2\pi)$ from $m$ noisy measurements of their offsets $\theta_i-\theta_j \;\mbox{mod} \; 2\pi.$ Applications include, for example, sensor network localization, phase retrieval, and distributed clock synchronization. An extension of the problem to the heterogeneous setting (dubbed $k$-synchronization) is to estimate $k$ groups of angles simultaneously, given noisy observations (with unknown group assignment) from each group. Existing methods for angular synchronization usually perform poorly in high-noise regimes, which are common in applications. In this paper, we leverage neural networks for the angular synchronization problem, and its heterogeneous extension, by proposing GNNSync, a theoretically-grounded end-to-end trainable framework using directed graph neural networks. In addition, new loss functions are devised to encode synchro
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#21033;&#29992;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#20174;&#20462;&#27491;&#24341;&#21147;&#27169;&#25311;&#20013;&#25552;&#21462;&#23431;&#23449;&#23398;&#21442;&#25968;&#65292;&#24182;&#23545;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2309.00612</link><description>&lt;p&gt;
&#22522;&#20110;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#30340;&#23431;&#23449;&#23610;&#24230;&#20013;&#30340;&#20462;&#27491;&#24341;&#21147;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Bayesian deep learning for cosmic volumes with modified gravity. (arXiv:2309.00612v1 [astro-ph.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00612
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#21033;&#29992;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#20174;&#20462;&#27491;&#24341;&#21147;&#27169;&#25311;&#20013;&#25552;&#21462;&#23431;&#23449;&#23398;&#21442;&#25968;&#65292;&#24182;&#23545;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26032;&#19968;&#20195;&#30340;&#26143;&#31995;&#35843;&#26597;&#23558;&#25552;&#20379;&#21069;&#25152;&#26410;&#26377;&#30340;&#25968;&#25454;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;&#23431;&#23449;&#23610;&#24230;&#19978;&#27979;&#35797;&#24341;&#21147;&#12290;&#23545;&#22823;&#23610;&#24230;&#32467;&#26500;&#30340;&#20581;&#22766;&#23431;&#23449;&#23398;&#20998;&#26512;&#38656;&#35201;&#21033;&#29992;&#32534;&#30721;&#22312;&#23431;&#23449;&#32593;&#20013;&#30340;&#38750;&#32447;&#24615;&#20449;&#24687;&#12290;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#25552;&#20379;&#20102;&#36825;&#26679;&#30340;&#24037;&#20855;&#65292;&#28982;&#32780;&#21364;&#19981;&#33021;&#25552;&#20379;&#20808;&#39564;&#30340;&#19981;&#30830;&#23450;&#24615;&#35780;&#20272;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20174;&#20462;&#27491;&#24341;&#21147;&#65288;MG&#65289;&#27169;&#25311;&#20013;&#25552;&#21462;&#23431;&#23449;&#23398;&#21442;&#25968;&#12290;&#25105;&#20204;&#20351;&#29992;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNNs&#65289;&#23454;&#29616;&#20102;&#19968;&#20010;&#20016;&#23500;&#30340;&#36817;&#20284;&#21518;&#39564;&#20998;&#24067;&#65292;&#20998;&#21035;&#32771;&#34385;&#20102;&#19968;&#20010;&#24102;&#26377;&#21333;&#19968;&#36125;&#21494;&#26031;&#26368;&#21518;&#19968;&#23618;&#65288;BLL&#65289;&#30340;&#24773;&#20917;&#65292;&#21644;&#19968;&#20010;&#22312;&#25152;&#26377;&#23618;&#38754;&#19978;&#37117;&#20855;&#26377;&#36125;&#21494;&#26031;&#23618;&#65288;FullB&#65289;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#20351;&#29992;&#23454;&#31354;&#38388;&#23494;&#24230;&#22330;&#21644;&#19968;&#22871;2000&#20010;&#20165;&#21253;&#21547;&#26263;&#29289;&#36136;&#31890;&#23376;&#32593;&#26684;$ N $-&#20307;&#27169;&#25311;&#30340;&#21151;&#29575;&#35889;&#23545;&#36825;&#20004;&#20010;BNN&#36827;&#34892;&#35757;&#32451;&#65292;&#36825;&#20123;&#27169;&#25311;&#21253;&#25324;&#22522;&#20110;MG-PICOLA&#30340;&#20462;&#27491;&#24341;&#21147;&#27169;&#22411;&#65292;&#35206;&#30422;&#20102;&#36793;&#38271;&#20026;256 $h^{-1}$ Mpc&#30340;&#31435;&#26041;&#20307;&#20307;&#31215;&#65292;&#20854;&#20013;&#21253;&#21547;128$&#12290;
&lt;/p&gt;
&lt;p&gt;
The new generation of galaxy surveys will provide unprecedented data allowing us to test gravity at cosmological scales. A robust cosmological analysis of the large-scale structure demands exploiting the nonlinear information encoded in the cosmic web. Machine Learning techniques provide such tools, however, do not provide a priori assessment of uncertainties. This study aims at extracting cosmological parameters from modified gravity (MG) simulations through deep neural networks endowed with uncertainty estimations. We implement Bayesian neural networks (BNNs) with an enriched approximate posterior distribution considering two cases: one with a single Bayesian last layer (BLL), and another one with Bayesian layers at all levels (FullB). We train both BNNs with real-space density fields and power-spectra from a suite of 2000 dark matter only particle mesh $N$-body simulations including modified gravity models relying on MG-PICOLA covering 256 $h^{-1}$ Mpc side cubical volumes with 128$
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#29256;&#26412;&#30340;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#21644;&#36817;&#31471;&#26799;&#24230;&#26041;&#27861;&#65288;ProxGD&#65289;&#65292;&#36890;&#36807;&#21033;&#29992;&#23616;&#37096;&#26354;&#29575;&#20449;&#24687;&#23436;&#20840;&#33258;&#36866;&#24212;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20855;&#26377;&#25910;&#25947;&#24615;&#65292;&#19988;&#20801;&#35768;&#20351;&#29992;&#26356;&#22823;&#30340;&#27493;&#38271;&#12290;</title><link>http://arxiv.org/abs/2308.02261</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#36817;&#31471;&#26799;&#24230;&#26041;&#27861;&#30340;&#20984;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Adaptive Proximal Gradient Method for Convex Optimization. (arXiv:2308.02261v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02261
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#29256;&#26412;&#30340;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#21644;&#36817;&#31471;&#26799;&#24230;&#26041;&#27861;&#65288;ProxGD&#65289;&#65292;&#36890;&#36807;&#21033;&#29992;&#23616;&#37096;&#26354;&#29575;&#20449;&#24687;&#23436;&#20840;&#33258;&#36866;&#24212;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20855;&#26377;&#25910;&#25947;&#24615;&#65292;&#19988;&#20801;&#35768;&#20351;&#29992;&#26356;&#22823;&#30340;&#27493;&#38271;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#20984;&#20248;&#21270;&#20013;&#30340;&#20004;&#20010;&#22522;&#26412;&#19968;&#38454;&#31639;&#27861;&#65292;&#21363;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#21644;&#36817;&#31471;&#26799;&#24230;&#26041;&#27861;&#65288;ProxGD&#65289;&#12290;&#25105;&#20204;&#30340;&#37325;&#28857;&#26159;&#36890;&#36807;&#21033;&#29992;&#24179;&#28369;&#20989;&#25968;&#30340;&#23616;&#37096;&#26354;&#29575;&#20449;&#24687;&#65292;&#20351;&#36825;&#20123;&#31639;&#27861;&#23436;&#20840;&#33258;&#36866;&#24212;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#35266;&#23519;&#21040;&#30340;&#26799;&#24230;&#24046;&#24322;&#30340;&#33258;&#36866;&#24212;&#29256;&#26412;&#30340;GD&#21644;ProxGD&#65292;&#22240;&#27492;&#19981;&#20250;&#22686;&#21152;&#35745;&#31639;&#25104;&#26412;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;&#20165;&#20551;&#35774;&#26799;&#24230;&#30340;&#23616;&#37096;Lipschitz&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;&#21478;&#22806;&#65292;&#25152;&#25552;&#20986;&#30340;&#29256;&#26412;&#20801;&#35768;&#20351;&#29992;&#27604;[MM20]&#26368;&#21021;&#24314;&#35758;&#30340;&#26356;&#22823;&#30340;&#27493;&#38271;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we explore two fundamental first-order algorithms in convex optimization, namely, gradient descent (GD) and proximal gradient method (ProxGD). Our focus is on making these algorithms entirely adaptive by leveraging local curvature information of smooth functions. We propose adaptive versions of GD and ProxGD that are based on observed gradient differences and, thus, have no added computational costs. Moreover, we prove convergence of our methods assuming only local Lipschitzness of the gradient. In addition, the proposed versions allow for even larger stepsizes than those initially suggested in [MM20].
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23454;&#39564;&#35748;&#20026;&#65292;&#20256;&#32479;&#26041;&#27861;&#26080;&#27861;&#35299;&#37322;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#21482;&#20351;&#29992;&#23569;&#37327;&#25968;&#25454;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#34920;&#29616;&#20986;&#25104;&#21151;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#20934;&#30830;&#25311;&#21512;&#38543;&#26426;&#29366;&#24577;&#21450;&#38543;&#26426;&#26631;&#35760;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#36825;&#31181;&#35760;&#24518;&#38543;&#26426;&#25968;&#25454;&#30340;&#33021;&#21147;&#36829;&#21453;&#20102;&#24403;&#21069;&#23567;&#27867;&#21270;&#35823;&#24046;&#30340;&#27010;&#24565;&#65292;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#26500;&#24314;&#34917;&#20805;&#23454;&#35777;&#32467;&#26524;&#65292;&#34920;&#26126;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#21487;&#23558;&#20219;&#24847;&#26631;&#35760;&#25311;&#21512;&#21040;&#37327;&#23376;&#29366;&#24577;&#19978;&#65292;&#26263;&#31034;&#20102;&#23427;&#20204;&#30340;&#35760;&#24518;&#33021;&#21147;&#65292;&#36825;&#20123;&#32467;&#26524;&#25490;&#38500;&#20102;&#21333;&#21333;&#22522;&#20110;&#32463;&#20856;&#22797;&#26434;&#24230;&#24230;&#37327;&#30340;&#25152;&#26377;&#21487;&#33021;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.13461</link><description>&lt;p&gt;
&#29702;&#35299;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#38656;&#35201;&#37325;&#26032;&#24605;&#32771;&#27867;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Understanding quantum machine learning also requires rethinking generalization. (arXiv:2306.13461v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13461
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23454;&#39564;&#35748;&#20026;&#65292;&#20256;&#32479;&#26041;&#27861;&#26080;&#27861;&#35299;&#37322;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#21482;&#20351;&#29992;&#23569;&#37327;&#25968;&#25454;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#34920;&#29616;&#20986;&#25104;&#21151;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#20934;&#30830;&#25311;&#21512;&#38543;&#26426;&#29366;&#24577;&#21450;&#38543;&#26426;&#26631;&#35760;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#36825;&#31181;&#35760;&#24518;&#38543;&#26426;&#25968;&#25454;&#30340;&#33021;&#21147;&#36829;&#21453;&#20102;&#24403;&#21069;&#23567;&#27867;&#21270;&#35823;&#24046;&#30340;&#27010;&#24565;&#65292;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#26500;&#24314;&#34917;&#20805;&#23454;&#35777;&#32467;&#26524;&#65292;&#34920;&#26126;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#21487;&#23558;&#20219;&#24847;&#26631;&#35760;&#25311;&#21512;&#21040;&#37327;&#23376;&#29366;&#24577;&#19978;&#65292;&#26263;&#31034;&#20102;&#23427;&#20204;&#30340;&#35760;&#24518;&#33021;&#21147;&#65292;&#36825;&#20123;&#32467;&#26524;&#25490;&#38500;&#20102;&#21333;&#21333;&#22522;&#20110;&#32463;&#20856;&#22797;&#26434;&#24230;&#24230;&#37327;&#30340;&#25152;&#26377;&#21487;&#33021;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#21482;&#29992;&#23569;&#37327;&#25968;&#25454;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#20063;&#33021;&#34920;&#29616;&#20986;&#25104;&#21151;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#26412;&#25991;&#36890;&#36807;&#31995;&#32479;&#30340;&#38543;&#26426;&#21270;&#23454;&#39564;&#65292;&#23637;&#31034;&#20256;&#32479;&#30340;&#29702;&#35299;&#27867;&#21270;&#30340;&#26041;&#27861;&#26080;&#27861;&#35299;&#37322;&#36825;&#20123;&#37327;&#23376;&#27169;&#22411;&#30340;&#34892;&#20026;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#25581;&#31034;&#20102;&#26368;&#20808;&#36827;&#30340;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#20934;&#30830;&#22320;&#25311;&#21512;&#38543;&#26426;&#29366;&#24577;&#21644;&#38543;&#26426;&#35757;&#32451;&#25968;&#25454;&#30340;&#26631;&#35760;&#12290;&#36825;&#31181;&#35760;&#24518;&#38543;&#26426;&#25968;&#25454;&#30340;&#33021;&#21147;&#36829;&#21453;&#20102;&#24403;&#21069;&#23567;&#27867;&#21270;&#35823;&#24046;&#30340;&#27010;&#24565;&#65292;&#20351;&#24471;&#24314;&#31435;&#22312;VC&#32500;&#12289;Rademacher&#22797;&#26434;&#24230;&#21644;&#25152;&#26377;&#22343;&#21248;&#30456;&#20851;&#24615;&#24230;&#37327;&#22522;&#30784;&#19978;&#30340;&#26041;&#27861;&#26377;&#20123;&#26840;&#25163;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#29702;&#35770;&#26500;&#24314;&#34917;&#20805;&#20102;&#25105;&#20204;&#30340;&#23454;&#35777;&#32467;&#26524;&#65292;&#34920;&#26126;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#23558;&#20219;&#24847;&#26631;&#35760;&#25311;&#21512;&#21040;&#37327;&#23376;&#29366;&#24577;&#19978;&#65292;&#26263;&#31034;&#20102;&#23427;&#20204;&#30340;&#35760;&#24518;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#24182;&#19981;&#25490;&#38500;&#21482;&#29992;&#23569;&#37327;&#35757;&#32451;&#25968;&#25454;&#23601;&#33021;&#33719;&#24471;&#33391;&#22909;&#27867;&#21270;&#30340;&#21487;&#33021;&#24615;&#65292;&#20294;&#26159;&#25490;&#38500;&#20102;&#21333;&#21333;&#22522;&#20110;&#32463;&#20856;&#22797;&#26434;&#24230;&#24230;&#37327;&#30340;&#25152;&#26377;&#21487;&#33021;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantum machine learning models have shown successful generalization performance even when trained with few data. In this work, through systematic randomization experiments, we show that traditional approaches to understanding generalization fail to explain the behavior of such quantum models. Our experiments reveal that state-of-the-art quantum neural networks accurately fit random states and random labeling of training data. This ability to memorize random data defies current notions of small generalization error, problematizing approaches that build on complexity measures such as the VC dimension, the Rademacher complexity, and all their uniform relatives. We complement our empirical results with a theoretical construction showing that quantum neural networks can fit arbitrary labels to quantum states, hinting at their memorization ability. Our results do not preclude the possibility of good generalization with few training data but rather rule out any possible guarantees based only
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;SGD&#20462;&#25913;&#26041;&#27861;&#65292;&#20351;&#35757;&#32451;&#20986;&#30340;&#31070;&#32463;&#32593;&#32476;&#36755;&#20986;&#21487;&#34987;&#35777;&#26126;&#20026;&#21487;&#21387;&#32553;&#65292;&#32780;&#19981;&#38656;&#35201;&#20219;&#20309;&#38750;&#24179;&#20961;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2306.08125</link><description>&lt;p&gt;
&#24102;&#26377;&#27785;&#37325;&#23614;&#37096;SGD&#35757;&#32451;&#30340;&#36807;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#38544;&#24335;&#21487;&#21387;&#32553;&#24615;
&lt;/p&gt;
&lt;p&gt;
Implicit Compressibility of Overparametrized Neural Networks Trained with Heavy-Tailed SGD. (arXiv:2306.08125v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08125
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;SGD&#20462;&#25913;&#26041;&#27861;&#65292;&#20351;&#35757;&#32451;&#20986;&#30340;&#31070;&#32463;&#32593;&#32476;&#36755;&#20986;&#21487;&#34987;&#35777;&#26126;&#20026;&#21487;&#21387;&#32553;&#65292;&#32780;&#19981;&#38656;&#35201;&#20219;&#20309;&#38750;&#24179;&#20961;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20943;&#23569;&#35745;&#31639;&#38656;&#27714;&#21644;&#21387;&#32553;&#19982;&#27867;&#21270;&#35823;&#24046;&#20043;&#38388;&#30340;&#26174;&#24335;&#20851;&#31995;&#65292;&#31070;&#32463;&#32593;&#32476;&#21387;&#32553;&#25104;&#20026;&#36234;&#26469;&#36234;&#37325;&#35201;&#30340;&#30740;&#31350;&#23545;&#35937;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;(SGD)&#30340;&#36229;&#21442;&#25968;&#36873;&#25321;&#21487;&#20197;&#24433;&#21709;&#23398;&#20064;&#21442;&#25968;&#21521;&#37327;&#30340;&#21387;&#32553;&#24615;&#12290;&#34429;&#28982;&#36825;&#20123;&#32467;&#26524;&#25581;&#31034;&#20102;&#35757;&#32451;&#21160;&#24577;&#23545;&#21387;&#32553;&#24615;&#30340;&#24433;&#21709;&#65292;&#20294;&#26159;&#23427;&#20204;&#20381;&#36182;&#20110;&#19981;&#21487;&#39564;&#35777;&#30340;&#20551;&#35774;&#65292;&#30001;&#20110;&#38544;&#21547;&#24615;&#36136;&#65292;&#24471;&#20986;&#30340;&#29702;&#35770;&#24182;&#27809;&#26377;&#25552;&#20379;&#23454;&#29992;&#30340;&#25351;&#23548;&#26041;&#38024;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;SGD&#20462;&#25913;&#26041;&#27861;&#65292;&#20351;&#24471;&#31639;&#27861;&#30340;&#36755;&#20986;&#33021;&#22815;&#34987;&#35777;&#26126;&#26159;&#21487;&#21387;&#32553;&#30340;&#65292;&#32780;&#19981;&#38656;&#35201;&#20219;&#20309;&#38750;&#24179;&#20961;&#20551;&#35774;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#20351;&#29992;SGD&#35757;&#32451;&#30340;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#27880;&#20837;&#38468;&#21152;&#30340;&#27785;&#37325;&#23614;&#37096;&#22122;&#22768;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural network compression has been an increasingly important subject, due to its practical implications in terms of reducing the computational requirements and its theoretical implications, as there is an explicit connection between compressibility and the generalization error. Recent studies have shown that the choice of the hyperparameters of stochastic gradient descent (SGD) can have an effect on the compressibility of the learned parameter vector. Even though these results have shed some light on the role of the training dynamics over compressibility, they relied on unverifiable assumptions and the resulting theory does not provide a practical guideline due to its implicitness. In this study, we propose a simple modification for SGD, such that the outputs of the algorithm will be provably compressible without making any nontrivial assumptions. We consider a one-hidden-layer neural network trained with SGD and we inject additive heavy-tailed noise to the iterates at each iteration.
&lt;/p&gt;</description></item><item><title>MESSY&#20272;&#35745;&#26041;&#27861;&#26159;&#19968;&#31181;&#22522;&#20110;&#26368;&#22823;&#29109;&#30340;&#38543;&#26426;&#21644;&#31526;&#21495;&#23494;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#22522;&#20110;&#26799;&#24230;&#30340;&#28418;&#31227;&#25193;&#25955;&#36807;&#31243;&#26469;&#39640;&#25928;&#22320;&#25214;&#21040;&#26368;&#22823;&#29109;&#20998;&#24067;&#30340;&#21442;&#25968;&#65292;&#25903;&#25345;&#39640;&#32500;&#38382;&#39064;&#65292;&#24182;&#20855;&#26377;&#20248;&#20110;&#29616;&#26377;&#26368;&#26032;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#26222;&#36866;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.04120</link><description>&lt;p&gt;
MESSY&#20272;&#35745;&#65306;&#22522;&#20110;&#26368;&#22823;&#29109;&#30340;&#38543;&#26426;&#21644;&#31526;&#21495;&#23494;&#24230;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
MESSY Estimation: Maximum-Entropy based Stochastic and Symbolic densitY Estimation. (arXiv:2306.04120v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04120
&lt;/p&gt;
&lt;p&gt;
MESSY&#20272;&#35745;&#26041;&#27861;&#26159;&#19968;&#31181;&#22522;&#20110;&#26368;&#22823;&#29109;&#30340;&#38543;&#26426;&#21644;&#31526;&#21495;&#23494;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#22522;&#20110;&#26799;&#24230;&#30340;&#28418;&#31227;&#25193;&#25955;&#36807;&#31243;&#26469;&#39640;&#25928;&#22320;&#25214;&#21040;&#26368;&#22823;&#29109;&#20998;&#24067;&#30340;&#21442;&#25968;&#65292;&#25903;&#25345;&#39640;&#32500;&#38382;&#39064;&#65292;&#24182;&#20855;&#26377;&#20248;&#20110;&#29616;&#26377;&#26368;&#26032;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#26222;&#36866;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#26368;&#22823;&#29109;&#30340;&#38543;&#26426;&#21644;&#31526;&#21495;&#23494;&#24230;&#20272;&#35745;&#26041;&#27861;MESSY&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20351;&#29992;&#26799;&#24230;&#27969;&#30340;&#30697;&#23558;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#20174;&#26679;&#26412;&#20013;&#24674;&#22797;&#20026;&#31526;&#21495;&#34920;&#36798;&#24335;&#65292;&#24182;&#23558;ansatz&#20316;&#20026;&#39537;&#21160;&#21147;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#22522;&#20110;&#26799;&#24230;&#30340;&#28418;&#31227;&#25193;&#25955;&#36807;&#31243;&#65292;&#23558;&#26410;&#30693;&#20998;&#24067;&#20989;&#25968;&#30340;&#26679;&#26412;&#19982;&#29468;&#27979;&#30340;&#31526;&#21495;&#34920;&#36798;&#24335;&#30456;&#36830;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20986;&#24403;&#29468;&#27979;&#20998;&#24067;&#20855;&#26377;&#26368;&#22823;&#29109;&#24418;&#24335;&#26102;&#65292;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#25552;&#20379;&#30340;&#26679;&#26412;&#30340;&#30697;&#26500;&#24314;&#30340;&#32447;&#24615;&#26041;&#31243;&#32452;&#39640;&#25928;&#22320;&#25214;&#21040;&#35813;&#20998;&#24067;&#30340;&#21442;&#25968;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;&#31526;&#21495;&#22238;&#24402;&#26469;&#25506;&#32034;&#24179;&#28369;&#20989;&#25968;&#30340;&#31354;&#38388;&#65292;&#24182;&#25214;&#21040;&#23548;&#33268;&#26368;&#22823;&#29109;&#27867;&#20989;&#25351;&#25968;&#30340;&#26368;&#20248;&#22522;&#20989;&#25968;&#65292;&#20197;&#33719;&#24471;&#33391;&#22909;&#26465;&#20214;&#12290;&#35813;&#26041;&#27861;&#22312;&#38543;&#26426;&#25628;&#32034;&#30340;&#27599;&#27425;&#36845;&#20195;&#20013;&#30340;&#25104;&#26412;&#19982;&#26679;&#26412;&#25968;&#37327;&#21576;&#32447;&#24615;&#20851;&#31995;&#65292;&#19982;&#21464;&#37327;&#25968;&#37327;&#21576;&#20108;&#27425;&#20851;&#31995;&#65292;&#20351;&#20854;&#21487;&#25193;&#23637;&#21040;&#39640;&#32500;&#38382;&#39064;&#12290;&#25968;&#20540;&#23454;&#39564;&#26174;&#31034;&#20986;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#26222;&#36866;&#24615;&#65292;&#19982;&#29616;&#26377;&#30340;&#26368;&#26032;&#26041;&#27861;&#30456;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce MESSY estimation, a Maximum-Entropy based Stochastic and Symbolic densitY estimation method. The proposed approach recovers probability density functions symbolically from samples using moments of a Gradient flow in which the ansatz serves as the driving force. In particular, we construct a gradient-based drift-diffusion process that connects samples of the unknown distribution function to a guess symbolic expression. We then show that when the guess distribution has the maximum entropy form, the parameters of this distribution can be found efficiently by solving a linear system of equations constructed using the moments of the provided samples. Furthermore, we use Symbolic regression to explore the space of smooth functions and find optimal basis functions for the exponent of the maximum entropy functional leading to good conditioning. The cost of the proposed method in each iteration of the random search is linear with the number of samples and quadratic with the number 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#8220;&#21021;&#22987;&#29468;&#27979;&#20559;&#24046;&#8221;&#29616;&#35937;&#65292;&#21363;&#22312;&#26410;&#32463;&#36807;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#30001;&#20110;&#26550;&#26500;&#36873;&#25321;&#30340;&#24433;&#21709;&#65292;&#27169;&#22411;&#24448;&#24448;&#20250;&#23558;&#25152;&#26377;&#39044;&#27979;&#25351;&#21521;&#21516;&#19968;&#20010;&#31867;&#21035;&#12290;&#35813;&#29616;&#35937;&#23545;&#26550;&#26500;&#36873;&#25321;&#21644;&#21021;&#22987;&#21270;&#26377;&#23454;&#38469;&#25351;&#23548;&#24847;&#20041;&#65292;&#24182;&#20855;&#26377;&#29702;&#35770;&#21518;&#26524;&#65292;&#20363;&#22914;&#33410;&#28857;&#32622;&#25442;&#23545;&#31216;&#24615;&#30340;&#23849;&#28291;&#21644;&#28145;&#24230;&#24102;&#26469;&#30340;&#38750;&#24179;&#20961;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2306.00809</link><description>&lt;p&gt;
&#21021;&#22987;&#29468;&#27979;&#20559;&#24046;&#65306;&#26410;&#32463;&#36807;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#20542;&#21521;&#20110;&#26576;&#20123;&#31867;&#21035;
&lt;/p&gt;
&lt;p&gt;
Initial Guessing Bias: How Untrained Networks Favor Some Classes. (arXiv:2306.00809v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00809
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#8220;&#21021;&#22987;&#29468;&#27979;&#20559;&#24046;&#8221;&#29616;&#35937;&#65292;&#21363;&#22312;&#26410;&#32463;&#36807;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#30001;&#20110;&#26550;&#26500;&#36873;&#25321;&#30340;&#24433;&#21709;&#65292;&#27169;&#22411;&#24448;&#24448;&#20250;&#23558;&#25152;&#26377;&#39044;&#27979;&#25351;&#21521;&#21516;&#19968;&#20010;&#31867;&#21035;&#12290;&#35813;&#29616;&#35937;&#23545;&#26550;&#26500;&#36873;&#25321;&#21644;&#21021;&#22987;&#21270;&#26377;&#23454;&#38469;&#25351;&#23548;&#24847;&#20041;&#65292;&#24182;&#20855;&#26377;&#29702;&#35770;&#21518;&#26524;&#65292;&#20363;&#22914;&#33410;&#28857;&#32622;&#25442;&#23545;&#31216;&#24615;&#30340;&#23849;&#28291;&#21644;&#28145;&#24230;&#24102;&#26469;&#30340;&#38750;&#24179;&#20961;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#30340;&#21021;&#22987;&#29366;&#24577;&#22312;&#35843;&#33410;&#21518;&#32493;&#30340;&#35757;&#32451;&#36807;&#31243;&#20013;&#25198;&#28436;&#37325;&#35201;&#35282;&#33394;&#12290;&#22312;&#20998;&#31867;&#38382;&#39064;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#35777;&#26126;&#31070;&#32463;&#32593;&#32476;&#30340;&#32467;&#26500;&#21487;&#20197;&#22312;&#35757;&#32451;&#20043;&#21069;&#65292;&#29978;&#33267;&#22312;&#19981;&#23384;&#22312;&#26174;&#24335;&#20559;&#24046;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#27169;&#22411;&#23558;&#25152;&#26377;&#39044;&#27979;&#37117;&#25351;&#21521;&#21516;&#19968;&#20010;&#31867;&#21035;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#29616;&#35937;&#30340;&#23384;&#22312;&#65292;&#31216;&#20026;&#8220;&#21021;&#22987;&#29468;&#27979;&#20559;&#24046;&#8221;&#65288;Initial Guessing Bias&#65292;IGB&#65289;&#65292;&#36825;&#21462;&#20915;&#20110;&#26550;&#26500;&#36873;&#25321;&#65292;&#20363;&#22914;&#28608;&#27963;&#20989;&#25968;&#12289;&#26368;&#22823;&#27744;&#21270;&#23618;&#21644;&#32593;&#32476;&#28145;&#24230;&#12290;&#25105;&#20204;&#23545;IGB&#36827;&#34892;&#30340;&#20998;&#26512;&#20855;&#26377;&#23454;&#38469;&#24847;&#20041;&#65292;&#21487;&#20197;&#25351;&#23548;&#26550;&#26500;&#30340;&#36873;&#25321;&#21644;&#21021;&#22987;&#21270;&#12290;&#25105;&#20204;&#36824;&#24378;&#35843;&#29702;&#35770;&#21518;&#26524;&#65292;&#20363;&#22914;&#33410;&#28857;&#32622;&#25442;&#23545;&#31216;&#24615;&#30340;&#23849;&#28291;&#12289;&#33258;&#24179;&#22343;&#30340;&#30772;&#22351;&#12289;&#26576;&#20123;&#22343;&#22330;&#36817;&#20284;&#30340;&#26377;&#25928;&#24615;&#20197;&#21450;&#28145;&#24230;&#24102;&#26469;&#30340;&#38750;&#24179;&#20961;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
The initial state of neural networks plays a central role in conditioning the subsequent training dynamics. In the context of classification problems, we provide a theoretical analysis demonstrating that the structure of a neural network can condition the model to assign all predictions to the same class, even before the beginning of training, and in the absence of explicit biases. We show that the presence of this phenomenon, which we call "Initial Guessing Bias" (IGB), depends on architectural choices such as activation functions, max-pooling layers, and network depth. Our analysis of IGB has practical consequences, in that it guides architecture selection and initialization. We also highlight theoretical consequences, such as the breakdown of node-permutation symmetry, the violation of self-averaging, the validity of some mean-field approximations, and the non-trivial differences arising with depth.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#27010;&#29575;&#35270;&#35282;&#30340;&#23545;&#25239;&#26679;&#26412;&#26500;&#24314;&#26041;&#27861;&#65292;&#21487;&#20197;&#29983;&#25104;&#35821;&#20041;&#24863;&#30693;&#30340;&#23545;&#25239;&#24615;&#26679;&#26412;&#65292;&#24182;&#21487;&#20197;&#26377;&#25928;&#35268;&#36991;&#20256;&#32479;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24378;&#21270;&#23545;&#25239;&#35757;&#32451;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.00353</link><description>&lt;p&gt;
&#20174;&#27010;&#29575;&#35282;&#24230;&#26500;&#24314;&#35821;&#20041;&#24863;&#30693;&#30340;&#23545;&#25239;&#26679;&#26412;
&lt;/p&gt;
&lt;p&gt;
Constructing Semantics-Aware Adversarial Examples with Probabilistic Perspective. (arXiv:2306.00353v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00353
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#27010;&#29575;&#35270;&#35282;&#30340;&#23545;&#25239;&#26679;&#26412;&#26500;&#24314;&#26041;&#27861;&#65292;&#21487;&#20197;&#29983;&#25104;&#35821;&#20041;&#24863;&#30693;&#30340;&#23545;&#25239;&#24615;&#26679;&#26412;&#65292;&#24182;&#21487;&#20197;&#26377;&#25928;&#35268;&#36991;&#20256;&#32479;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24378;&#21270;&#23545;&#25239;&#35757;&#32451;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27010;&#29575;&#35270;&#35282;&#23545;&#25239;&#26679;&#26412;&#26500;&#24314;&#26041;&#27861;&#8212;&#8212;&#31665;&#32422;&#26463; Langevin Monte Carlo&#65288;LMC&#65289;&#12290;&#20174;&#36825;&#20010;&#35282;&#24230;&#20986;&#21457;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#21019;&#26032;&#24615;&#30340;&#26041;&#27861;&#65292;&#20197;&#21407;&#21017;&#24615;&#30340;&#26041;&#24335;&#29983;&#25104;&#35821;&#20041;&#24863;&#30693;&#30340;&#23545;&#25239;&#24615;&#26679;&#26412;&#12290;&#36825;&#31181;&#26041;&#27861;&#36229;&#36234;&#20102;&#20960;&#20309;&#36317;&#31163;&#25152;&#26045;&#21152;&#30340;&#38480;&#21046;&#65292;&#36873;&#25321;&#20102;&#35821;&#20041;&#32422;&#26463;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36171;&#20104;&#20102;&#20010;&#20307;&#23558;&#20854;&#23545;&#35821;&#20041;&#30340;&#29702;&#35299;&#34701;&#20837;&#21040;&#27169;&#22411;&#20013;&#30340;&#33021;&#21147;&#12290;&#36890;&#36807;&#20154;&#31867;&#35780;&#20272;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#35821;&#20041;&#24863;&#30693;&#30340;&#23545;&#25239;&#26679;&#26412;&#20445;&#25345;&#20854;&#22266;&#26377;&#30340;&#21547;&#20041;&#12290;&#22312; MNIST &#21644; SVHN &#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#35821;&#20041;&#24863;&#30693;&#30340;&#23545;&#25239;&#26679;&#26412;&#21487;&#20197;&#26377;&#25928;&#22320;&#35268;&#36991;&#38024;&#23545;&#20256;&#32479;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24378;&#20581;&#24615;&#23545;&#25239;&#35757;&#32451;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this study, we introduce a novel, probabilistic viewpoint on adversarial examples, achieved through box-constrained Langevin Monte Carlo (LMC). Proceeding from this perspective, we develop an innovative approach for generating semantics-aware adversarial examples in a principled manner. This methodology transcends the restriction imposed by geometric distance, instead opting for semantic constraints. Our approach empowers individuals to incorporate their personal comprehension of semantics into the model. Through human evaluation, we validate that our semantics-aware adversarial examples maintain their inherent meaning. Experimental findings on the MNIST and SVHN datasets demonstrate that our semantics-aware adversarial examples can effectively circumvent robust adversarial training methods tailored for traditional adversarial attacks.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#20801;&#35768;&#20219;&#24847;&#25968;&#25454;&#25490;&#24207;&#30340;&#26222;&#36890;SGD&#31639;&#27861;,&#24182;&#34920;&#26126;&#22312;&#38750;&#20984;&#20989;&#25968;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#21644;&#21333;&#27425;&#27927;&#29260;&#30340;SGD&#27604;&#32463;&#20856;&#26367;&#25442;&#30340;SGD&#26356;&#24555;&#25110;&#33267;&#23569;&#19982;&#20854;&#19968;&#26679;&#22909;&#65292;&#26080;&#35770;&#36845;&#20195;&#27425;&#25968;&#22914;&#20309;&#12290;</title><link>http://arxiv.org/abs/2305.19259</link><description>&lt;p&gt;
Shuffle SGD&#24635;&#26159;&#27604;SGD&#26356;&#22909;&#65306;&#23545;&#20855;&#26377;&#20219;&#24847;&#25968;&#25454;&#39034;&#24207;&#30340;SGD&#36827;&#34892;&#25913;&#36827;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Shuffle SGD is Always Better than SGD: Improved Analysis of SGD with Arbitrary Data Orders. (arXiv:2305.19259v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19259
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#20801;&#35768;&#20219;&#24847;&#25968;&#25454;&#25490;&#24207;&#30340;&#26222;&#36890;SGD&#31639;&#27861;,&#24182;&#34920;&#26126;&#22312;&#38750;&#20984;&#20989;&#25968;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#21644;&#21333;&#27425;&#27927;&#29260;&#30340;SGD&#27604;&#32463;&#20856;&#26367;&#25442;&#30340;SGD&#26356;&#24555;&#25110;&#33267;&#23569;&#19982;&#20854;&#19968;&#26679;&#22909;&#65292;&#26080;&#35770;&#36845;&#20195;&#27425;&#25968;&#22914;&#20309;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#31639;&#27861;&#34987;&#24191;&#27867;&#29992;&#20110;&#20248;&#21270;&#31070;&#32463;&#32593;&#32476;&#65292;&#38543;&#26426;&#37325;&#25490;&#65288;RR&#65289;&#21644;&#21333;&#27425;&#27927;&#29260;&#65288;SS&#65289;&#26159;&#36890;&#36807;&#24490;&#29615;&#36941;&#21382;&#35757;&#32451;&#25968;&#25454;&#30340;&#38543;&#26426;&#25110;&#21333;&#20010;&#25490;&#21015;&#30340;&#24120;&#35265;&#36873;&#25321;&#65292;&#28982;&#32780;&#36825;&#20123;&#31639;&#27861;&#22312;&#38750;&#20984;&#24773;&#20917;&#19979;&#30340;&#25910;&#25947;&#24615;&#36136;&#23578;&#26410;&#23436;&#20840;&#29702;&#35299;&#12290;&#29616;&#26377;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#23454;&#38469;&#30340;&#35757;&#32451;&#22330;&#26223;&#20013;&#65292;&#24403;&#26102;&#20195;&#30340;&#25968;&#37327;&#23567;&#20110;&#35757;&#32451;&#38598;&#22823;&#23567;&#26102;&#65292;RR&#21487;&#33021;&#34920;&#29616;&#19981;&#22914;SGD&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#19968;&#31181;&#20801;&#35768;&#20219;&#24847;&#25968;&#25454;&#25490;&#24207;&#30340;&#26222;&#36890;SGD&#31639;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#38750;&#20984;&#20989;&#25968;&#24773;&#20917;&#19979;&#30340;&#25913;&#36827;&#25910;&#25947;&#36895;&#24230;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#38543;&#26426;&#21644;&#21333;&#27425;&#27927;&#29260;&#30340;SGD&#27604;&#32463;&#20856;&#26367;&#25442;&#30340;SGD&#26356;&#24555;&#25110;&#33267;&#23569;&#19982;&#20854;&#19968;&#26679;&#22909;&#65292;&#26080;&#35770;&#36845;&#20195;&#27425;&#25968;&#22914;&#20309;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#20984;&#26174;&#20102;&#20351;&#29992;&#38543;&#26426;/&#21333;&#27425;&#27927;&#29260;&#30340;SGD&#30340;&#22909;&#22788;&#65292;&#24182;&#20026;&#20854;&#38750;&#20984;&#25910;&#25947;&#24615;&#36136;&#25552;&#20379;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic Gradient Descent (SGD) algorithms are widely used in optimizing neural networks, with Random Reshuffling (RR) and Single Shuffle (SS) being popular choices for cycling through random or single permutations of the training data. However, the convergence properties of these algorithms in the non-convex case are not fully understood. Existing results suggest that, in realistic training scenarios where the number of epochs is smaller than the training set size, RR may perform worse than SGD.  In this paper, we analyze a general SGD algorithm that allows for arbitrary data orderings and show improved convergence rates for non-convex functions. Specifically, our analysis reveals that SGD with random and single shuffling is always faster or at least as good as classical SGD with replacement, regardless of the number of iterations. Overall, our study highlights the benefits of using SGD with random/single shuffling and provides new insights into its convergence properties for non-co
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;ODE&#30340;&#27969;&#21305;&#37197;&#26041;&#27861;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#36866;&#29992;&#20110;&#23436;&#20840;&#30830;&#23450;&#24615;&#25277;&#26679;&#65292;&#38656;&#35201;&#28385;&#36275;$L^2$&#36817;&#20284;&#35823;&#24046;&#33539;&#22260;&#30340;&#35268;&#24459;&#24615;&#26465;&#20214;&#21644;&#25968;&#25454;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2305.16860</link><description>&lt;p&gt;
&#27969;&#21305;&#37197;&#26041;&#27861;&#30340;&#35823;&#24046;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Error Bounds for Flow Matching Methods. (arXiv:2305.16860v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16860
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;ODE&#30340;&#27969;&#21305;&#37197;&#26041;&#27861;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#36866;&#29992;&#20110;&#23436;&#20840;&#30830;&#23450;&#24615;&#25277;&#26679;&#65292;&#38656;&#35201;&#28385;&#36275;$L^2$&#36817;&#20284;&#35823;&#24046;&#33539;&#22260;&#30340;&#35268;&#24459;&#24615;&#26465;&#20214;&#21644;&#25968;&#25454;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#26159;&#19968;&#31867;&#20381;&#36182;&#20110;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#30340;&#27969;&#34892;&#29983;&#25104;&#24314;&#27169;&#25216;&#26415;&#12290;&#33258;&#20174;&#23427;&#20204;&#35806;&#29983;&#20197;&#26469;&#65292;&#23601;&#24050;&#32463;&#24847;&#35782;&#21040;&#21487;&#20197;&#20351;&#29992;&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#32780;&#19981;&#26159;SDE&#36827;&#34892;&#29983;&#25104;&#12290;&#36825;&#23548;&#33268;&#20171;&#32461;&#20102;&#27010;&#29575;&#27969;ODE&#26041;&#27861;&#21644;&#21435;&#22122;&#25193;&#25955;&#38544;&#24335;&#27169;&#22411;&#12290;&#27969;&#21305;&#37197;&#26041;&#27861;&#26368;&#36817;&#36827;&#19968;&#27493;&#25193;&#23637;&#20102;&#36825;&#20123;&#22522;&#20110;ODE&#30340;&#26041;&#27861;&#65292;&#24182;&#36817;&#20284;&#20110;&#20004;&#20010;&#20219;&#24847;&#27010;&#29575;&#20998;&#24067;&#20043;&#38388;&#30340;&#27969;&#12290;&#20197;&#21069;&#30340;&#24037;&#20316;&#38024;&#23545;&#38543;&#26426;&#25277;&#26679;&#27169;&#24335;&#19979;&#30340;&#25193;&#25955;&#27169;&#22411;&#25512;&#23548;&#20102;&#36817;&#20284;&#35823;&#24046;&#30340;&#36793;&#30028;&#65292;&#20551;&#35774;$L^2$&#25439;&#22833;&#20855;&#26377;&#26576;&#20123;&#38480;&#21046;&#12290;&#25105;&#20204;&#22312;&#23436;&#20840;&#30830;&#23450;&#24615;&#25277;&#26679;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#20102;&#27969;&#21305;&#37197;&#36807;&#31243;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#20551;&#35774;$L^2$&#36817;&#20284;&#35823;&#24046;&#33539;&#22260;&#26377;&#19968;&#23450;&#30340;&#35268;&#24459;&#24615;&#26465;&#20214;&#21644;&#25968;&#25454;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based generative models are a popular class of generative modelling techniques relying on stochastic differential equations (SDE). From their inception, it was realized that it was also possible to perform generation using ordinary differential equations (ODE) rather than SDE. This led to the introduction of the probability flow ODE approach and denoising diffusion implicit models. Flow matching methods have recently further extended these ODE-based approaches and approximate a flow between two arbitrary probability distributions. Previous work derived bounds on the approximation error of diffusion models under the stochastic sampling regime, given assumptions on the $L^2$ loss. We present error bounds for the flow matching procedure using fully deterministic sampling, assuming an $L^2$ bound on the approximation error and a certain regularity condition on the data distributions.
&lt;/p&gt;</description></item></channel></rss>