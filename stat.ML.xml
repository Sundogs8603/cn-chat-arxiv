<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>TRAK&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#12289;&#21487;&#24494;&#27169;&#22411;&#30340;&#25968;&#25454;&#24402;&#22240;&#26041;&#27861;&#65292;&#26082;&#26377;&#25928;&#21448;&#35745;&#31639;&#37327;&#21487;&#34892;&#12290;</title><link>http://arxiv.org/abs/2303.14186</link><description>&lt;p&gt;
TRAK: &#21051;&#30011;&#22823;&#35268;&#27169;&#27169;&#22411;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
TRAK: Attributing Model Behavior at Scale. (arXiv:2303.14186v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14186
&lt;/p&gt;
&lt;p&gt;
TRAK&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#12289;&#21487;&#24494;&#27169;&#22411;&#30340;&#25968;&#25454;&#24402;&#22240;&#26041;&#27861;&#65292;&#26082;&#26377;&#25928;&#21448;&#35745;&#31639;&#37327;&#21487;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#24402;&#22240;&#30340;&#30446;&#26631;&#26159;&#36861;&#36394;&#27169;&#22411;&#39044;&#27979;&#32467;&#26524;&#30340;&#21407;&#22987;&#35757;&#32451;&#25968;&#25454;&#12290;&#34429;&#28982;&#24050;&#32463;&#26377;&#24456;&#22810;&#24037;&#20316;&#33268;&#21147;&#20110;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#20294;&#29616;&#26377;&#26041;&#27861;&#24448;&#24448;&#35201;&#27714;&#29992;&#25143;&#22312;&#35745;&#31639;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#20043;&#38388;&#20570;&#20986;&#36873;&#25321;&#12290;&#20063;&#23601;&#26159;&#35828;&#65292;&#22312;&#38750;&#20984;&#22330;&#26223;&#65288;&#20363;&#22914;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#39046;&#22495;&#65289;&#20013;&#65292;&#35745;&#31639;&#37327;&#21487;&#34892;&#30340;&#26041;&#27861;&#21487;&#33021;&#38590;&#20197;&#20934;&#30830;&#22320;&#24402;&#22240;&#27169;&#22411;&#39044;&#27979;&#32467;&#26524;&#65292;&#32780;&#22312;&#36825;&#31867;&#22330;&#26223;&#20013;&#26377;&#25928;&#30340;&#26041;&#27861;&#21017;&#38656;&#35201;&#35757;&#32451;&#25968;&#21315;&#20010;&#27169;&#22411;&#65292;&#36825;&#20351;&#24471;&#23427;&#20204;&#22312;&#22823;&#22411;&#27169;&#22411;&#25110;&#25968;&#25454;&#38598;&#20013;&#23454;&#38469;&#24212;&#29992;&#20855;&#26377;&#19981;&#21487;&#34892;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;TRAK&#65288;&#38543;&#26426;&#25237;&#24433;&#26680;&#36861;&#36394;&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#25968;&#25454;&#24402;&#22240;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#12289;&#21487;&#24494;&#27169;&#22411;&#65292;&#26082;&#26377;&#25928;&#21448;&#35745;&#31639;&#37327;&#21487;&#34892;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#36890;&#36807;&#20165;&#20351;&#29992;&#23569;&#37327;&#35757;&#32451;&#27169;&#22411;&#65292;TRAK &#21487;&#20197;&#21305;&#37197;&#38656;&#35201;&#35757;&#32451;&#25968;&#21315;&#27169;&#22411;&#25165;&#33021;&#24471;&#21040;&#30340;&#24402;&#22240;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#35770;&#35777;&#20102;TRAK &#22312;&#21508;&#31181;&#27169;&#24335;&#21644;&#35268;&#27169;&#19978;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The goal of data attribution is to trace model predictions back to training data. Despite a long line of work towards this goal, existing approaches to data attribution tend to force users to choose between computational tractability and efficacy. That is, computationally tractable methods can struggle with accurately attributing model predictions in non-convex settings (e.g., in the context of deep neural networks), while methods that are effective in such regimes require training thousands of models, which makes them impractical for large models or datasets.  In this work, we introduce TRAK (Tracing with the Randomly-projected After Kernel), a data attribution method that is both effective and computationally tractable for large-scale, differentiable models. In particular, by leveraging only a handful of trained models, TRAK can match the performance of attribution methods that require training thousands of models. We demonstrate the utility of TRAK across various modalities and scal
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#25239;&#24615;&#28431;&#27934;&#22914;&#20309;&#21462;&#20915;&#20110;&#21463;&#38480;&#20110;&#39640;&#32500;&#36755;&#20837;&#31354;&#38388;&#20013;&#30340;&#23376;&#31354;&#38388;&#32500;&#25968;&#65292;&#21516;&#26102;&#38024;&#23545;&#26631;&#20934;PGD&#25915;&#20987;&#30340;&#23545;&#25239;&#24615;&#25104;&#21151;&#29575;&#25552;&#20986;&#20102;&#21333;&#35843;&#36882;&#22686;&#20989;&#25968;&#34920;&#36798;&#24335;&#12290;</title><link>http://arxiv.org/abs/2303.14173</link><description>&lt;p&gt;
&#25214;&#21040;&#23545;&#25239;&#26679;&#26412;&#38656;&#35201;&#22810;&#23569;&#32500;&#24230;&#65311;
&lt;/p&gt;
&lt;p&gt;
How many dimensions are required to find an adversarial example?. (arXiv:2303.14173v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14173
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#25239;&#24615;&#28431;&#27934;&#22914;&#20309;&#21462;&#20915;&#20110;&#21463;&#38480;&#20110;&#39640;&#32500;&#36755;&#20837;&#31354;&#38388;&#20013;&#30340;&#23376;&#31354;&#38388;&#32500;&#25968;&#65292;&#21516;&#26102;&#38024;&#23545;&#26631;&#20934;PGD&#25915;&#20987;&#30340;&#23545;&#25239;&#24615;&#25104;&#21151;&#29575;&#25552;&#20986;&#20102;&#21333;&#35843;&#36882;&#22686;&#20989;&#25968;&#34920;&#36798;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21435;&#25506;&#32034;&#23545;&#25239;&#24615;&#28431;&#27934;&#30340;&#30740;&#31350;&#37117;&#30528;&#30524;&#20110;&#23545;&#25163;&#21487;&#20197;&#25200;&#21160;&#27169;&#22411;&#36755;&#20837;&#30340;&#25152;&#26377;&#32500;&#24230;&#30340;&#24773;&#20917;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#35768;&#22810;&#26368;&#36817;&#30340;&#30740;&#31350;&#32771;&#34385;&#20197;&#19979;&#24773;&#20917;&#65306;&#65288;i&#65289;&#23545;&#25163;&#21487;&#20197;&#25200;&#21160;&#26377;&#38480;&#25968;&#37327;&#30340;&#36755;&#20837;&#21442;&#25968;&#25110;&#65288;ii&#65289;&#22810;&#27169;&#24577;&#38382;&#39064;&#20013;&#30340;&#27169;&#24577;&#23376;&#38598;&#12290;&#22312;&#36825;&#20004;&#31181;&#24773;&#20917;&#19979;&#65292;&#23545;&#25239;&#24615;&#26679;&#26412;&#26377;&#25928;&#22320;&#21463;&#38480;&#20110;&#39640;&#32500;&#36755;&#20837;&#31354;&#38388;&#20013;&#30340;&#23376;&#31354;&#38388;$V$&#12290;&#20986;&#20110;&#36825;&#20010;&#21160;&#26426;&#65292;&#25105;&#20204;&#22312;&#26412;&#25991;&#20013;&#30740;&#31350;&#20102;&#23545;&#25239;&#24615;&#28431;&#27934;&#22914;&#20309;&#21462;&#20915;&#20110;$V$&#30340;&#32500;&#25968;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26631;&#20934;PGD&#25915;&#20987;&#30340;&#23545;&#25239;&#24615;&#25104;&#21151;&#29575;&#22914;&#20309;&#34920;&#29616;&#20026;$\epsilon (\frac{\dim(V)}{\dim \mathcal{X}})^{\frac{1}{q}}$&#30340;&#21333;&#35843;&#36882;&#22686;&#20989;&#25968;&#65292;&#20854;&#20013;$\epsilon$&#26159;&#25200;&#21160;&#39044;&#31639;&#65292;$\frac{1}{p}+\frac{q}{q}=1$&#65292;&#21482;&#35201;$p&gt;1$&#65288;&#24403;$p=1$&#26102;&#20250;&#20986;&#29616;&#39069;&#22806;&#30340;&#32454;&#24494;&#24046;&#21035;&#65292;&#25105;&#20204;&#23545;&#27492;&#36827;&#34892;&#20102;&#35814;&#32454;&#30340;&#20998;&#26512;&#65289;&#12290;&#36825;&#20010;&#20989;&#25968;&#24418;&#24335;&#21487;&#20197;&#24456;&#23481;&#26131;&#22320;&#25512;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;
Past work exploring adversarial vulnerability have focused on situations where an adversary can perturb all dimensions of model input. On the other hand, a range of recent works consider the case where either (i) an adversary can perturb a limited number of input parameters or (ii) a subset of modalities in a multimodal problem. In both of these cases, adversarial examples are effectively constrained to a subspace $V$ in the ambient input space $\mathcal{X}$. Motivated by this, in this work we investigate how adversarial vulnerability depends on $\dim(V)$. In particular, we show that the adversarial success of standard PGD attacks with $\ell^p$ norm constraints behaves like a monotonically increasing function of $\epsilon (\frac{\dim(V)}{\dim \mathcal{X}})^{\frac{1}{q}}$ where $\epsilon$ is the perturbation budget and $\frac{1}{p} + \frac{1}{q} =1$, provided $p &gt; 1$ (the case $p=1$ presents additional subtleties which we analyze in some detail). This functional form can be easily deriv
&lt;/p&gt;</description></item><item><title>&#21452;&#37325;&#19979;&#38477;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#19968;&#20010;&#20196;&#20154;&#24778;&#35766;&#30340;&#29616;&#35937;&#65292;&#25968;&#25454;&#37327;&#12289;&#25968;&#25454;&#32500;&#24230;&#21644;&#27169;&#22411;&#21442;&#25968;&#26159;&#24433;&#21709;&#21452;&#37325;&#19979;&#38477;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#30740;&#31350;&#32773;&#25214;&#21040;&#20102;&#21046;&#36896;&#21452;&#37325;&#19979;&#38477;&#30340;&#19977;&#20010;&#35299;&#37322;&#24615;&#22240;&#32032;&#65292;&#24182;&#35777;&#26126;&#36825;&#20123;&#22240;&#32032;&#21487;&#20197;&#22312;&#31616;&#21333;&#31070;&#32463;&#32593;&#32476;&#20013;&#20851;&#38381;&#12290;</title><link>http://arxiv.org/abs/2303.14151</link><description>&lt;p&gt;
&#21452;&#37325;&#19979;&#38477;&#30340;&#35868;&#22242;&#65306;&#36776;&#35782;&#12289;&#35299;&#37322;&#21644;&#28040;&#35299;&#28145;&#24230;&#23398;&#20064;&#20043;&#35868;
&lt;/p&gt;
&lt;p&gt;
Double Descent Demystified: Identifying, Interpreting &amp; Ablating the Sources of a Deep Learning Puzzle. (arXiv:2303.14151v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14151
&lt;/p&gt;
&lt;p&gt;
&#21452;&#37325;&#19979;&#38477;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#19968;&#20010;&#20196;&#20154;&#24778;&#35766;&#30340;&#29616;&#35937;&#65292;&#25968;&#25454;&#37327;&#12289;&#25968;&#25454;&#32500;&#24230;&#21644;&#27169;&#22411;&#21442;&#25968;&#26159;&#24433;&#21709;&#21452;&#37325;&#19979;&#38477;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#30740;&#31350;&#32773;&#25214;&#21040;&#20102;&#21046;&#36896;&#21452;&#37325;&#19979;&#38477;&#30340;&#19977;&#20010;&#35299;&#37322;&#24615;&#22240;&#32032;&#65292;&#24182;&#35777;&#26126;&#36825;&#20123;&#22240;&#32032;&#21487;&#20197;&#22312;&#31616;&#21333;&#31070;&#32463;&#32593;&#32476;&#20013;&#20851;&#38381;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21452;&#37325;&#19979;&#38477;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#19968;&#20010;&#20196;&#20154;&#24778;&#35766;&#30340;&#29616;&#35937;&#65292;&#21363;&#38543;&#30528;&#27169;&#22411;&#21442;&#25968;&#25968;&#37327;&#30456;&#23545;&#20110;&#25968;&#25454;&#37327;&#30340;&#22686;&#38271;&#65292;&#27979;&#35797;&#35823;&#24046;&#22312;&#27169;&#22411;&#19981;&#26029;&#25193;&#22823;&#32780;&#36827;&#20837;&#39640;&#24230;&#36229;&#21442;&#25968;&#21270;&#65288;&#25968;&#25454;&#26410;&#20805;&#20998;&#37319;&#26679;&#65289;&#38454;&#27573;&#26102;&#19979;&#38477;&#12290;&#27979;&#35797;&#35823;&#24046;&#19979;&#38477;&#30340;&#36825;&#31181;&#24773;&#20917;&#19982;&#20256;&#32479;&#30340;&#20851;&#20110;&#36807;&#24230;&#25311;&#21512;&#30340;&#23398;&#20064;&#29702;&#35770;&#30456;&#24726;&#65292;&#21487;&#35859;&#25215;&#36733;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#22823;&#22411;&#27169;&#22411;&#30340;&#25104;&#21151;&#12290;&#36825;&#31181;&#38750;&#21333;&#35843;&#30340;&#27979;&#35797;&#35823;&#24046;&#21464;&#21270;&#34892;&#20026;&#21462;&#20915;&#20110;&#25968;&#25454;&#30340;&#25968;&#37327;&#12289;&#25968;&#25454;&#30340;&#32500;&#24230;&#21644;&#27169;&#22411;&#21442;&#25968;&#30340;&#25968;&#37327;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#31616;&#35201;&#25551;&#36848;&#20102;&#21452;&#37325;&#19979;&#38477;&#29616;&#35937;&#65292;&#28982;&#21518;&#29992;&#26131;&#20110;&#29702;&#35299;&#21644;&#25509;&#21463;&#30340;&#26041;&#24335;&#23545;&#20026;&#20309;&#20986;&#29616;&#21452;&#37325;&#19979;&#38477;&#36827;&#34892;&#20102;&#35299;&#37322;&#65292;&#21482;&#38656;&#35201;&#20102;&#35299;&#32447;&#24615;&#20195;&#25968;&#21644;&#27010;&#29575;&#35770;&#30340;&#30693;&#35782;&#12290;&#25105;&#20204;&#20351;&#29992;&#22810;&#39033;&#24335;&#22238;&#24402;&#25552;&#20379;&#21487;&#35270;&#21270;&#30340;&#30452;&#35266;&#24863;&#21463;&#65292;&#28982;&#21518;&#36890;&#36807;&#26222;&#36890;&#32447;&#24615;&#22238;&#24402;&#25968;&#23398;&#20998;&#26512;&#21452;&#37325;&#19979;&#38477;&#65292;&#30830;&#23450;&#20102;&#19977;&#20010;&#35299;&#37322;&#24615;&#22240;&#32032;&#65292;&#24403;&#21516;&#26102;&#23384;&#22312;&#26102;&#65292;&#21487;&#20197;&#20849;&#21516;&#21046;&#36896;&#21452;&#37325;&#19979;&#38477;&#29616;&#35937;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#22240;&#32032;&#22914;&#20309;&#34987;&#20851;&#38381;&#22312;&#36755;&#20986;&#21333;&#20010;&#26631;&#37327;&#30340;&#31616;&#21333;&#31070;&#32463;&#32593;&#32476;&#20013;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#25511;&#21046;&#28040;&#34701;&#23454;&#39564;&#27979;&#35797;&#20102;&#36825;&#20123;&#22240;&#32032;&#22312;&#29616;&#20195;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#35777;&#26126;&#21452;&#37325;&#19979;&#38477;&#29616;&#35937;&#19981;&#20165;&#20165;&#26159;&#36229;&#21442;&#25968;&#21270;&#27169;&#22411;&#25152;&#29305;&#26377;&#30340;&#65292;&#20063;&#20986;&#29616;&#22312;&#27424;&#21442;&#25968;&#21270;&#27169;&#22411;&#21644;&#25554;&#20540;&#38408;&#20540;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Double descent is a surprising phenomenon in machine learning, in which as the number of model parameters grows relative to the number of data, test error drops as models grow ever larger into the highly overparameterized (data undersampled) regime. This drop in test error flies against classical learning theory on overfitting and has arguably underpinned the success of large models in machine learning. This non-monotonic behavior of test loss depends on the number of data, the dimensionality of the data and the number of model parameters. Here, we briefly describe double descent, then provide an explanation of why double descent occurs in an informal and approachable manner, requiring only familiarity with linear algebra and introductory probability. We provide visual intuition using polynomial regression, then mathematically analyze double descent with ordinary linear regression and identify three interpretable factors that, when simultaneously all present, together create double des
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#29289;&#29702;&#21551;&#21457;&#30340;&#31070;&#32463;&#32593;&#32476;&#24212;&#29992;&#20110;&#37325;&#24314;&#27969;&#20307;&#21147;&#23398;&#27169;&#25311;&#20013;&#65292;&#36890;&#36807;&#23558;&#29702;&#35770;&#30693;&#35782;&#27880;&#20837;&#27169;&#22411;&#25439;&#22833;&#20989;&#25968;&#24182;&#32467;&#21512;&#26032;&#30340;&#24615;&#33021;&#35780;&#20272;&#25351;&#26631;&#65292;&#25104;&#21151;&#23454;&#29616;&#20102;&#23545;&#37325;&#23376;&#25955;&#23556;&#30340;&#37325;&#24314;&#12290;</title><link>http://arxiv.org/abs/2303.14090</link><description>&lt;p&gt;
&#29289;&#29702;&#21551;&#21457;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;&#21033;&#29992;&#26263;&#29289;&#36136;&#37325;&#24314;&#27969;&#20307;&#21147;&#23398;&#27169;&#25311;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Physics-informed neural networks in the recreation of hydrodynamic simulations from dark matter. (arXiv:2303.14090v1 [astro-ph.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14090
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#29289;&#29702;&#21551;&#21457;&#30340;&#31070;&#32463;&#32593;&#32476;&#24212;&#29992;&#20110;&#37325;&#24314;&#27969;&#20307;&#21147;&#23398;&#27169;&#25311;&#20013;&#65292;&#36890;&#36807;&#23558;&#29702;&#35770;&#30693;&#35782;&#27880;&#20837;&#27169;&#22411;&#25439;&#22833;&#20989;&#25968;&#24182;&#32467;&#21512;&#26032;&#30340;&#24615;&#33021;&#35780;&#20272;&#25351;&#26631;&#65292;&#25104;&#21151;&#23454;&#29616;&#20102;&#23545;&#37325;&#23376;&#25955;&#23556;&#30340;&#37325;&#24314;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29289;&#29702;&#21551;&#21457;&#30340;&#31070;&#32463;&#32593;&#32476;&#24050;&#32463;&#25104;&#20026;&#19968;&#20010;&#21512;&#29702;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#26500;&#24314;&#23558;&#32479;&#35745;&#27169;&#24335;&#19982;&#39046;&#22495;&#30693;&#35782;&#30456;&#32467;&#21512;&#30340;&#39044;&#27979;&#27169;&#22411;&#12290;&#20854;&#22522;&#26412;&#29702;&#24565;&#26159;&#36890;&#36807;&#24050;&#30693;&#20851;&#31995;&#26469;&#20016;&#23500;&#20248;&#21270;&#25439;&#22833;&#20989;&#25968;&#20197;&#38480;&#21046;&#21487;&#33021;&#35299;&#20915;&#26041;&#26696;&#30340;&#31354;&#38388;&#12290;&#27700;&#21160;&#21147;&#23398;&#27169;&#25311;&#26159;&#29616;&#20195;&#23431;&#23449;&#23398;&#30340;&#26680;&#24515;&#32452;&#25104;&#37096;&#20998;&#65292;&#32780;&#25152;&#38656;&#30340;&#35745;&#31639;&#26082;&#26114;&#36149;&#21448;&#32791;&#26102;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#24555;&#36895;&#27169;&#25311;&#26263;&#29289;&#36136;&#38656;&#35201;&#26356;&#23569;&#30340;&#36164;&#28304;&#65292;&#36825;&#23548;&#33268;&#20102;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#25104;&#20026;&#30740;&#31350;&#30340;&#19968;&#20010;&#27963;&#36291;&#39046;&#22495;;&#22312;&#36825;&#37324;&#65292;&#37325;&#24314;&#27969;&#20307;&#21147;&#23398;&#27169;&#25311;&#20013;&#21457;&#29616;&#30340;&#25955;&#23556;&#26159;&#19968;&#20010;&#25345;&#32493;&#30340;&#25361;&#25112;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#23558;&#29289;&#29702;&#21551;&#21457;&#30340;&#31070;&#32463;&#32593;&#32476;&#24212;&#29992;&#20110;&#37325;&#24314;&#27969;&#20307;&#21147;&#23398;&#27169;&#25311;&#20013;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#32467;&#21512;&#20102;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#36827;&#27493;&#21644;&#29289;&#29702;&#32422;&#26463;&#65292;&#23558;&#20851;&#20110;&#37325;&#23376;&#36716;&#21270;&#25928;&#29575;&#30340;&#29702;&#35770;&#27880;&#20837;&#27169;&#22411;&#25439;&#22833;&#20989;&#25968;&#12290;&#25105;&#20204;&#36824;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#24615;&#33021;&#35780;&#20272;&#25351;&#26631;&#65292;&#22522;&#20110;&#32467;&#26524;&#22270;&#20687;&#20013;&#21160;&#21147;&#23398;&#21151;&#29575;&#35889;&#20013;&#30340;&#35823;&#24046;&#65292;&#36825;&#20351;&#24471;&#21487;&#20197;&#37327;&#21270;&#32593;&#32476;&#23545;&#23431;&#23449;&#23398;&#21442;&#25968;&#25512;&#26029;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Physics-informed neural networks have emerged as a coherent framework for building predictive models that combine statistical patterns with domain knowledge. The underlying notion is to enrich the optimization loss function with known relationships to constrain the space of possible solutions. Hydrodynamic simulations are a core constituent of modern cosmology, while the required computations are both expensive and time-consuming. At the same time, the comparatively fast simulation of dark matter requires fewer resources, which has led to the emergence of machine learning algorithms for baryon inpainting as an active area of research; here, recreating the scatter found in hydrodynamic simulations is an ongoing challenge. This paper presents the first application of physics-informed neural networks to baryon inpainting by combining advances in neural network architectures with physical constraints, injecting theory on baryon conversion efficiency into the model loss function. We also in
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#39318;&#20010;&#20855;&#26377;&#26174;&#24335;&#35823;&#24046;&#30028;&#38480;&#30340;&#24046;&#20998;&#38544;&#31169;&#21512;&#25104;&#25511;&#21046;&#31639;&#27861;&#65292;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#21069;&#26223;&#12290;</title><link>http://arxiv.org/abs/2303.14084</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#21512;&#25104;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Synthetic Control. (arXiv:2303.14084v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14084
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#39318;&#20010;&#20855;&#26377;&#26174;&#24335;&#35823;&#24046;&#30028;&#38480;&#30340;&#24046;&#20998;&#38544;&#31169;&#21512;&#25104;&#25511;&#21046;&#31639;&#27861;&#65292;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#21069;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21512;&#25104;&#25511;&#21046;&#26159;&#19968;&#31181;&#22240;&#26524;&#25512;&#26029;&#24037;&#20855;&#65292;&#29992;&#20110;&#36890;&#36807;&#21019;&#24314;&#21512;&#25104;&#23545;&#29031;&#25968;&#25454;&#26469;&#20272;&#35745;&#24178;&#39044;&#30340;&#27835;&#30103;&#25928;&#26524;&#12290;&#36825;&#31181;&#26041;&#27861;&#32467;&#21512;&#20102;&#26469;&#33258;&#20854;&#20182;&#30456;&#20284;&#35266;&#23519;&#65288;&#21363;&#65292;&#25424;&#36192;&#32773;&#27744;&#65289;&#30340;&#27979;&#37327;&#32467;&#26524;&#65292;&#36890;&#36807;&#20998;&#26512;&#24178;&#39044;&#21069;&#30446;&#26631;&#21644;&#25424;&#36192;&#32773;&#27744;&#20043;&#38388;&#30340;&#20851;&#31995;&#26469;&#39044;&#27979;&#24863;&#20852;&#36259;&#30340;&#21453;&#20107;&#23454;&#26102;&#38388;&#24207;&#21015;&#65288;&#21363;&#65292;&#30446;&#26631;&#21333;&#20803;&#65289;&#12290;&#38543;&#30528;&#21512;&#25104;&#25511;&#21046;&#24037;&#20855;&#34987;&#36234;&#26469;&#36234;&#24212;&#29992;&#20110;&#25935;&#24863;&#25110;&#19987;&#26377;&#25968;&#25454;&#65292;&#24418;&#24335;&#21270;&#30340;&#38544;&#31169;&#20445;&#25252;&#36890;&#24120;&#26159;&#24517;&#38656;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#39318;&#20010;&#20855;&#26377;&#26174;&#24335;&#35823;&#24046;&#30028;&#38480;&#30340;&#24046;&#20998;&#38544;&#31169;&#21512;&#25104;&#25511;&#21046;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#38750;&#31169;&#26377;&#21512;&#25104;&#25511;&#21046;&#21644;&#24046;&#20998;&#38544;&#31169;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#24037;&#20855;&#12290;&#25105;&#20204;&#25552;&#20379;&#20851;&#20110;&#21512;&#25104;&#25511;&#21046;&#26597;&#35810;&#25935;&#24863;&#24615;&#30340;&#19978;&#19979;&#30028;&#65292;&#24182;&#25552;&#20379;&#26377;&#20851;&#25105;&#20204;&#30340;&#31169;&#26377;&#21512;&#25104;&#25511;&#21046;&#31639;&#27861;&#20934;&#30830;&#24615;&#30340;&#26174;&#24335;&#35823;&#24046;&#30028;&#38480;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#20135;&#29983;&#20934;&#30830;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Synthetic control is a causal inference tool used to estimate the treatment effects of an intervention by creating synthetic counterfactual data. This approach combines measurements from other similar observations (i.e., donor pool ) to predict a counterfactual time series of interest (i.e., target unit) by analyzing the relationship between the target and the donor pool before the intervention. As synthetic control tools are increasingly applied to sensitive or proprietary data, formal privacy protections are often required. In this work, we provide the first algorithms for differentially private synthetic control with explicit error bounds. Our approach builds upon tools from non-private synthetic control and differentially private empirical risk minimization. We provide upper and lower bounds on the sensitivity of the synthetic control query and provide explicit error bounds on the accuracy of our private synthetic control algorithms. We show that our algorithms produce accurate pre
&lt;/p&gt;</description></item><item><title>&#27492;&#35770;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#30456;&#20851;&#20107;&#20214;&#30340;&#39044;&#27979;&#31454;&#36187;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#22359;&#30456;&#20851;&#30340;&#27010;&#24565;&#12290;&#35777;&#26126;&#20102;&#22312;&#20855;&#26377;&#22359;&#30456;&#20851;&#24615;&#30340;&#20998;&#24067;&#19979;&#65292;&#22522;&#20110;follow-the-regularized-leader(FTRL)&#30340;&#31454;&#36187;&#26426;&#21046;&#20173;&#28982;&#20445;&#30041;&#20102;&#23427;&#30340;$\epsilon$-&#26368;&#20248;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2303.13793</link><description>&lt;p&gt;
&#24102;&#26377;&#30456;&#20851;&#20107;&#20214;&#30340;&#39044;&#27979;&#31454;&#36187;&#12290;
&lt;/p&gt;
&lt;p&gt;
Forecasting Competitions with Correlated Events. (arXiv:2303.13793v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.13793
&lt;/p&gt;
&lt;p&gt;
&#27492;&#35770;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#30456;&#20851;&#20107;&#20214;&#30340;&#39044;&#27979;&#31454;&#36187;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#22359;&#30456;&#20851;&#30340;&#27010;&#24565;&#12290;&#35777;&#26126;&#20102;&#22312;&#20855;&#26377;&#22359;&#30456;&#20851;&#24615;&#30340;&#20998;&#24067;&#19979;&#65292;&#22522;&#20110;follow-the-regularized-leader(FTRL)&#30340;&#31454;&#36187;&#26426;&#21046;&#20173;&#28982;&#20445;&#30041;&#20102;&#23427;&#30340;$\epsilon$-&#26368;&#20248;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#24120;&#35265;&#30340;&#36194;&#23478;&#36890;&#21507;&#26426;&#21046;&#20013;&#23384;&#22312;&#30340;&#28608;&#21169;&#38382;&#39064;&#65292;&#26368;&#36817;&#30340;&#39044;&#27979;&#31454;&#36187;&#30740;&#31350;&#20174;Witkowski&#31561;&#20154;[2022]&#24320;&#22987;&#12290;Frongillo&#31561;&#20154;[2021]&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;follow-the-regularized-leader(FTRL)&#30340;&#31454;&#36187;&#26426;&#21046;&#65292;&#36825;&#26159;&#19968;&#31181;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#12290;&#20182;&#20204;&#35777;&#26126;&#20182;&#20204;&#30340;&#26426;&#21046;&#20165;&#20351;&#29992;$O(\log(n)/\epsilon^2)$&#20010;&#20107;&#20214;&#23601;&#33021;&#39640;&#27010;&#29575;&#36873;&#25321;&#19968;&#20010;$\epsilon$-&#26368;&#20248;&#30340;&#39044;&#27979;&#32773;&#12290;&#36825;&#20123;&#24037;&#20316;&#20197;&#21450;&#20043;&#21069;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#30340;&#25152;&#26377;&#24037;&#20316;&#37117;&#20551;&#35774;&#20107;&#20214;&#26159;&#29420;&#31435;&#30340;&#12290;&#25105;&#20204;&#24320;&#22987;&#30740;&#31350;&#24102;&#26377;&#30456;&#20851;&#20107;&#20214;&#30340;&#39044;&#27979;&#31454;&#36187;&#12290;&#20026;&#20102;&#37327;&#21270;&#30456;&#20851;&#24615;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#22359;&#30456;&#20851;&#30340;&#27010;&#24565;&#65292;&#23427;&#20801;&#35768;&#27599;&#20010;&#20107;&#20214;&#19982;&#26368;&#22810;$b$&#20010;&#20107;&#20214;&#24378;&#30456;&#20851;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#20855;&#26377;&#36825;&#31181;&#30456;&#20851;&#24615;&#30340;&#20998;&#24067;&#19979;&#65292;FTRL&#26426;&#21046;&#20173;&#28982;&#20351;&#29992;$O(b^2 \log(n)/\epsilon^2)$&#20010;&#20107;&#20214;&#20445;&#30041;&#20102;&#23427;&#30340;$\epsilon$-&#26368;&#20248;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#28041;&#21450;&#21040;&#19968;&#31181;&#26032;&#30340;&#30456;&#20851;&#38543;&#26426;&#21464;&#37327;&#27987;&#24230;&#30028;&#65292;&#36825;&#21487;&#33021;&#26159;&#37325;&#35201;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Beginning with Witkowski et al. [2022], recent work on forecasting competitions has addressed incentive problems with the common winner-take-all mechanism. Frongillo et al. [2021] propose a competition mechanism based on follow-the-regularized-leader (FTRL), an online learning framework. They show that their mechanism selects an $\epsilon$-optimal forecaster with high probability using only $O(\log(n)/\epsilon^2)$ events. These works, together with all prior work on this problem thus far, assume that events are independent. We initiate the study of forecasting competitions for correlated events. To quantify correlation, we introduce a notion of block correlation, which allows each event to be strongly correlated with up to $b$ others. We show that under distributions with this correlation, the FTRL mechanism retains its $\epsilon$-optimal guarantee using $O(b^2 \log(n)/\epsilon^2)$ events. Our proof involves a novel concentration bound for correlated random variables which may be of br
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#22825;&#32447;&#25509;&#25910;&#22120;&#29256;&#26412;&#30340;&#21452;&#30450;&#21453;&#21367;&#31215;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;&#22810;&#20803;&#21407;&#23376;&#33539;&#25968;&#26368;&#23567;&#21270;&#30340;&#26041;&#27861;&#26469;&#24674;&#22797;&#38647;&#36798;&#21644;&#36890;&#20449;&#20449;&#21495;&#21644;&#36890;&#36947;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2303.13609</link><description>&lt;p&gt;
&#22522;&#20110;&#22810;&#22825;&#32447;&#30340;&#21452;&#30450;&#21453;&#21367;&#31215;&#32852;&#21512;&#38647;&#36798;&#36890;&#20449;&#30340;SoMAN&#26368;&#23567;&#21270;
&lt;/p&gt;
&lt;p&gt;
Multi-Antenna Dual-Blind Deconvolution for Joint Radar-Communications via SoMAN Minimization. (arXiv:2303.13609v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.13609
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#22825;&#32447;&#25509;&#25910;&#22120;&#29256;&#26412;&#30340;&#21452;&#30450;&#21453;&#21367;&#31215;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;&#22810;&#20803;&#21407;&#23376;&#33539;&#25968;&#26368;&#23567;&#21270;&#30340;&#26041;&#27861;&#26469;&#24674;&#22797;&#38647;&#36798;&#21644;&#36890;&#20449;&#20449;&#21495;&#21644;&#36890;&#36947;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#21512;&#38647;&#36798;&#36890;&#20449;&#65288;JRC&#65289;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#26377;&#25928;&#21033;&#29992;&#26377;&#38480;&#30005;&#30913;&#39057;&#35889;&#30340;&#26377;&#21069;&#36884;&#30340;&#25216;&#26415;&#12290;&#22312;JRC&#24212;&#29992;&#20013;&#65292;&#22914;&#23433;&#20840;&#20891;&#29992;&#25509;&#25910;&#22120;&#20013;&#65292;&#38647;&#36798;&#21644;&#36890;&#20449;&#20449;&#21495;&#32463;&#24120;&#21472;&#21152;&#22312;&#25509;&#25910;&#20449;&#21495;&#20013;&#12290;&#22312;&#36825;&#20123;&#34987;&#21160;&#30417;&#21548;&#21736;&#25152;&#20013;&#65292;&#38647;&#36798;&#21644;&#36890;&#20449;&#30340;&#20449;&#21495;&#21644;&#36890;&#36947;&#23545;&#20110;&#25509;&#25910;&#22120;&#26469;&#35828;&#37117;&#26159;&#26410;&#30693;&#30340;&#12290;&#20174;&#21472;&#21152;&#20449;&#21495;&#20013;&#24674;&#22797;&#25152;&#26377;&#20449;&#21495;&#21644;&#36890;&#36947;&#21442;&#25968;&#30340;&#19981;&#36866;&#23450;&#38382;&#39064;&#34987;&#31216;&#20026;&#21452;&#30450;&#21453;&#21367;&#31215;&#65288;DBD&#65289;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#26356;&#20855;&#25361;&#25112;&#24615;&#30340;&#22810;&#22825;&#32447;&#25509;&#25910;&#22120;&#29256;&#26412;&#30340;DBD&#12290;&#25105;&#20204;&#29992;&#23569;&#25968;&#65288;&#31232;&#30095;&#65289;&#36830;&#32493;&#20540;&#21442;&#25968;&#65292;&#22914;&#26102;&#24310;&#12289;&#22810;&#26222;&#21202;&#36895;&#24230;&#21644;&#21040;&#36798;&#26041;&#21521;&#65288;DoAs&#65289;&#26469;&#24314;&#27169;&#38647;&#36798;&#21644;&#36890;&#20449;&#36890;&#36947;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#39640;&#24230;&#19981;&#36866;&#23450;&#30340;DBD&#38382;&#39064;&#65292;&#25105;&#20204;&#24314;&#35758;&#26368;&#23567;&#21270;&#20381;&#36182;&#20110;&#26410;&#30693;&#21442;&#25968;&#30340;&#22810;&#20803;&#21407;&#23376;&#33539;&#25968;&#65288;SoMAN&#65289;&#20043;&#21644;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20351;&#29992;&#21322;&#23450;&#35268;&#21010;&#35774;&#35745;&#20102;&#19968;&#20010;&#31934;&#30830;&#30340;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Joint radar-communications (JRC) has emerged as a promising technology for efficiently using the limited electromagnetic spectrum. In JRC applications such as secure military receivers, often the radar and communications signals are overlaid in the received signal. In these passive listening outposts, the signals and channels of both radar and communications are unknown to the receiver. The ill-posed problem of recovering all signal and channel parameters from the overlaid signal is terms as dual-blind deconvolution (DBD). In this work, we investigate a more challenging version of DBD with a multi-antenna receiver. We model the radar and communications channels with a few (sparse) continuous-valued parameters such as time delays, Doppler velocities, and directions-of-arrival (DoAs). To solve this highly ill-posed DBD, we propose to minimize the sum of multivariate atomic norms (SoMAN) that depends on the unknown parameters. To this end, we devise an exact semidefinite program using the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#29983;&#23384;&#20219;&#21153;&#23398;&#20064;&#31639;&#27861;&#22312;&#32570;&#22833;&#25968;&#25454;&#22788;&#29702;&#26041;&#38754;&#30340;&#34920;&#29616;&#65292;&#32467;&#26524;&#26174;&#31034;&#23545;&#20110;&#25152;&#26377;&#24773;&#20917;&#27809;&#26377;&#21333;&#19968;&#30340;&#25968;&#25454;&#25554;&#34917;&#26041;&#27861;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#65292;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#29992;&#20110;&#27604;&#36739;&#20854;&#20182;&#32570;&#22833;&#25968;&#25454;&#27169;&#24335;&#21644;(&#25110;)&#29983;&#23384;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2303.13590</link><description>&lt;p&gt;
&#32570;&#22833;&#25968;&#25454;&#30340;&#29983;&#23384;&#23398;&#20064;&#31639;&#27861;&#27604;&#36739;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Une comparaison des algorithmes d'apprentissage pour la survie avec donn\'ees manquantes. (arXiv:2303.13590v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.13590
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#29983;&#23384;&#20219;&#21153;&#23398;&#20064;&#31639;&#27861;&#22312;&#32570;&#22833;&#25968;&#25454;&#22788;&#29702;&#26041;&#38754;&#30340;&#34920;&#29616;&#65292;&#32467;&#26524;&#26174;&#31034;&#23545;&#20110;&#25152;&#26377;&#24773;&#20917;&#27809;&#26377;&#21333;&#19968;&#30340;&#25968;&#25454;&#25554;&#34917;&#26041;&#27861;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#65292;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#29992;&#20110;&#27604;&#36739;&#20854;&#20182;&#32570;&#22833;&#25968;&#25454;&#27169;&#24335;&#21644;(&#25110;)&#29983;&#23384;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#23384;&#20998;&#26512;&#26159;&#30740;&#31350;&#20581;&#24247;&#25968;&#25454;&#30340;&#37325;&#35201;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#32570;&#22833;&#25968;&#25454;&#26159;&#36825;&#31181;&#25968;&#25454;&#30340;&#22266;&#26377;&#32452;&#25104;&#37096;&#20998;&#12290;&#36817;&#24180;&#26469;&#65292;&#30740;&#31350;&#20154;&#21592;&#25552;&#20986;&#20102;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#22411;&#29983;&#23384;&#20219;&#21153;&#23398;&#20064;&#31639;&#27861;&#12290;&#26412;&#30740;&#31350;&#23545;&#37319;&#29992;&#19981;&#21516;&#32570;&#22833;&#25968;&#25454;&#22788;&#29702;&#26041;&#27861;&#30340;&#27492;&#31867;&#31639;&#27861;&#22312;&#27169;&#25311;&#25968;&#25454;&#19978;&#30340;&#39044;&#27979;&#33021;&#21147;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#36825;&#20123;&#25968;&#25454;&#21453;&#26144;&#20102;&#29616;&#23454;&#24773;&#20917;&#65292;&#21363;&#20010;&#20307;&#23646;&#20110;&#26410;&#34987;&#35266;&#23519;&#21040;&#30340;&#32676;&#20307;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19981;&#21516;&#30340;&#32570;&#22833;&#25968;&#25454;&#27169;&#24335;&#65292;&#32467;&#26524;&#26174;&#31034;&#65292;&#27809;&#26377;&#21333;&#19968;&#30340;&#25968;&#25454;&#25554;&#34917;&#26041;&#27861;&#33021;&#22815;&#36866;&#29992;&#20110;&#25152;&#26377;&#24773;&#20917;&#32780;&#19981;&#38656;&#35201;&#36827;&#19968;&#27493;&#30340;&#29305;&#24449;&#24037;&#31243;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#29992;&#20110;&#27604;&#36739;&#20854;&#20182;&#32570;&#22833;&#25968;&#25454;&#27169;&#24335;&#21644;(&#25110;)&#29983;&#23384;&#27169;&#22411;&#12290;Python&#20195;&#30721;&#36890;&#36807;survivalsim&#21253;&#21487;&#20197;&#35775;&#38382;&#12290;
&lt;/p&gt;
&lt;p&gt;
Survival analysis is an essential tool for the study of health data. An inherent component of such data is the presence of missing values. In recent years, researchers proposed new learning algorithms for survival tasks based on neural networks. Here, we studied the predictive performance of such algorithms coupled with different methods for handling missing values on simulated data that reflect a realistic situation, i.e., when individuals belong to unobserved clusters. We investigated different patterns of missing data. The results show that, without further feature engineering, no single imputation method is better than the others in all cases. The proposed methodology can be used to compare other missing data patterns and/or survival models. The Python code is accessible via the package survivalsim.  - L'analyse de survie est un outil essentiel pour l'\'etude des donn\'ees de sant\'e. Une composante inh\'erente \`a ces donn\'ees est la pr\'esence de valeurs manquantes. Ces derni\
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24191;&#20041;&#35823;&#24046;&#39044;&#27979;&#22120;&#30340;&#26377;&#25928;&#24615;&#65292;&#25506;&#35752;&#20102;&#32622;&#20449;&#24230;&#12289;&#23616;&#37096;&#27969;&#24418;&#24179;&#28369;&#24230;&#21644;&#27169;&#22411;&#19968;&#33268;&#24615;&#35780;&#20998;&#20989;&#25968;&#30340;&#20248;&#32570;&#28857;&#65292;&#21457;&#29616;&#22312;&#22797;&#26434;&#26426;&#21046;&#32570;&#22833;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20808;&#36827;&#30340;&#35780;&#20998;&#26080;&#27861;&#22312;&#20998;&#24067;&#36716;&#31227;&#21644;&#25439;&#22351;&#19979;&#36229;&#36234;&#31616;&#21333;&#30340;&#27169;&#22411;&#19968;&#33268;&#24615;&#12290;&#21516;&#26102;&#65292;&#22312;&#21463;&#25439;&#35757;&#32451;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#27169;&#22411;&#19968;&#33268;&#24615;&#25171;&#20998;&#20173;&#28982;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#19988;&#38598;&#25104;&#22810;&#26679;&#24615;&#26377;&#21161;&#20110;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.13589</link><description>&lt;p&gt;
Scoring Functions &#21644; Generalization Prediction &#30340;&#35814;&#32454;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Closer Look at Scoring Functions and Generalization Prediction. (arXiv:2303.13589v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.13589
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24191;&#20041;&#35823;&#24046;&#39044;&#27979;&#22120;&#30340;&#26377;&#25928;&#24615;&#65292;&#25506;&#35752;&#20102;&#32622;&#20449;&#24230;&#12289;&#23616;&#37096;&#27969;&#24418;&#24179;&#28369;&#24230;&#21644;&#27169;&#22411;&#19968;&#33268;&#24615;&#35780;&#20998;&#20989;&#25968;&#30340;&#20248;&#32570;&#28857;&#65292;&#21457;&#29616;&#22312;&#22797;&#26434;&#26426;&#21046;&#32570;&#22833;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20808;&#36827;&#30340;&#35780;&#20998;&#26080;&#27861;&#22312;&#20998;&#24067;&#36716;&#31227;&#21644;&#25439;&#22351;&#19979;&#36229;&#36234;&#31616;&#21333;&#30340;&#27169;&#22411;&#19968;&#33268;&#24615;&#12290;&#21516;&#26102;&#65292;&#22312;&#21463;&#25439;&#35757;&#32451;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#27169;&#22411;&#19968;&#33268;&#24615;&#25171;&#20998;&#20173;&#28982;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#19988;&#38598;&#25104;&#22810;&#26679;&#24615;&#26377;&#21161;&#20110;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24191;&#20041;&#35823;&#24046;&#39044;&#27979;&#22120;&#65288;GEPs&#65289;&#30340;&#25928;&#26524;&#65292;&#36825;&#20123; GEPs &#26088;&#22312;&#36890;&#36807;&#20174;&#26679;&#26412;&#32423;&#20998;&#25968;&#20013;&#25512;&#23548;&#20986;&#25968;&#25454;&#38598;&#32423;&#35823;&#24046;&#20272;&#35745;&#20540;&#65292;&#20174;&#32780;&#39044;&#27979;&#27169;&#22411;&#22312;&#26410;&#35265;&#20998;&#24067;&#19978;&#30340;&#34920;&#29616;&#12290;&#28982;&#32780;&#65292;GEPs &#24120;&#24120;&#21033;&#29992;&#19981;&#21516;&#30340;&#26426;&#21046;&#65288;&#20363;&#22914;&#65292;&#22238;&#24402;&#22120;&#12289;&#38408;&#20540;&#20989;&#25968;&#12289;&#26657;&#20934;&#25968;&#25454;&#38598;&#31561;&#65289;&#65292;&#26469;&#25512;&#23548;&#36825;&#31181;&#35823;&#24046;&#20272;&#35745;&#20540;&#65292;&#36825;&#20250;&#28151;&#28102;&#29305;&#23450;&#35780;&#20998;&#20989;&#25968;&#30340;&#20248;&#28857;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#22312;&#26426;&#21046;&#36873;&#25321;&#29420;&#31435;&#30340;&#24773;&#20917;&#19979;&#65292;&#28145;&#20837;&#30740;&#31350;&#20102;&#27969;&#34892;&#30340;&#35780;&#20998;&#20989;&#25968;&#30340;&#26377;&#25928;&#24615;&#65288;&#32622;&#20449;&#24230;&#12289;&#23616;&#37096;&#27969;&#24418;&#24179;&#28369;&#24230;&#12289;&#27169;&#22411;&#19968;&#33268;&#24615;&#65289;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#22797;&#26434;&#26426;&#21046;&#32570;&#22833;&#30340;&#24773;&#20917;&#19979;&#65292;&#24403;&#20272;&#35745;&#20998;&#24067;&#36716;&#31227;&#21644;&#25439;&#22351;&#19979;&#30340;&#35823;&#24046;&#26102;&#65292;&#26368;&#20808;&#36827;&#30340;&#32622;&#20449;&#24230;&#21644;&#24179;&#28369;&#24230;&#22522;&#30784;&#35780;&#20998;&#26080;&#27861;&#36229;&#36234;&#31616;&#21333;&#30340;&#27169;&#22411;&#19968;&#33268;&#24615;&#12290;&#27492;&#22806;&#65292;&#22312;&#23454;&#38469;&#24773;&#20917;&#19979;&#65292;&#24403;&#35757;&#32451;&#25968;&#25454;&#21463;&#21040;&#25439;&#23475;&#26102;&#65288;&#20363;&#22914;&#26631;&#31614;&#22122;&#22768;&#12289;&#27979;&#37327;&#22122;&#22768;&#12289;&#27424;&#37319;&#26679;&#65289;&#65292;&#25105;&#20204;&#21457;&#29616;&#27169;&#22411;&#19968;&#33268;&#24615;&#25171;&#20998;&#20173;&#28982;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#19988;&#38598;&#25104;&#22810;&#26679;&#24615;&#26377;&#21161;&#20110;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generalization error predictors (GEPs) aim to predict model performance on unseen distributions by deriving dataset-level error estimates from sample-level scores. However, GEPs often utilize disparate mechanisms (e.g., regressors, thresholding functions, calibration datasets, etc), to derive such error estimates, which can obfuscate the benefits of a particular scoring function. Therefore, in this work, we rigorously study the effectiveness of popular scoring functions (confidence, local manifold smoothness, model agreement), independent of mechanism choice. We find, absent complex mechanisms, that state-of-the-art confidence- and smoothness- based scores fail to outperform simple model-agreement scores when estimating error under distribution shifts and corruptions. Furthermore, on realistic settings where the training data has been compromised (e.g., label noise, measurement noise, undersampling), we find that model-agreement scores continue to perform well and that ensemble diversi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102; MSC-DBSCAN&#25193;&#23637;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#19977;&#20803;&#32858;&#31867;&#20013;&#20174;&#25968;&#25454;&#20013;&#25552;&#21462;&#19981;&#21516;&#23376;&#31354;&#38388;&#30340;&#19981;&#21516;&#20999;&#29255;&#32858;&#31867;&#65292;&#24182;&#21487;&#20197;&#33719;&#24471;&#19982; MSC &#31639;&#27861;&#22312;&#22788;&#29702;&#31209;&#19968;&#24352;&#37327;&#25968;&#25454;&#26102;&#30456;&#21516;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2303.07768</link><description>&lt;p&gt;
&#22810;&#32500;&#25968;&#32452;&#30340;&#22810;&#20999;&#29255;&#32858;&#31867;&#20013;&#30340;DBSCAN&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
DBSCAN of Multi-Slice Clustering for three-order Tensor. (arXiv:2303.07768v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.07768
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102; MSC-DBSCAN&#25193;&#23637;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#19977;&#20803;&#32858;&#31867;&#20013;&#20174;&#25968;&#25454;&#20013;&#25552;&#21462;&#19981;&#21516;&#23376;&#31354;&#38388;&#30340;&#19981;&#21516;&#20999;&#29255;&#32858;&#31867;&#65292;&#24182;&#21487;&#20197;&#33719;&#24471;&#19982; MSC &#31639;&#27861;&#22312;&#22788;&#29702;&#31209;&#19968;&#24352;&#37327;&#25968;&#25454;&#26102;&#30456;&#21516;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#19977;&#32500;&#25968;&#25454;&#30340;&#19977;&#20803;&#32858;&#31867;&#65292;&#29616;&#26377;&#30340;&#20960;&#31181;&#26041;&#27861;&#38656;&#35201;&#25351;&#23450;&#27599;&#20010;&#32500;&#24230;&#30340;&#32858;&#31867;&#22823;&#23567;&#25110;&#32858;&#31867;&#25968;&#37327;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#19977;&#20803;&#32858;&#31867;(MSC)&#31639;&#27861;&#21487;&#20197;&#22312;&#20302;&#32500;&#23376;&#31354;&#38388;&#20013;&#25214;&#21040;&#20445;&#30041;&#20449;&#21495;&#30340;&#20999;&#29255;&#20197;&#20415;&#22522;&#20110;&#30456;&#20284;&#24230;&#38408;&#20540;&#25214;&#21040;&#32858;&#31867;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102; MSC-DBSCAN&#25193;&#23637;&#31639;&#27861;&#20197;&#20174;&#25968;&#25454;&#20013;&#25552;&#21462;&#20301;&#20110;&#19981;&#21516;&#23376;&#31354;&#38388;&#30340;&#19981;&#21516;&#20999;&#29255;&#32858;&#31867;(&#22914;&#26524;&#25968;&#25454;&#38598;&#26159;r&#20010;&#31209;&#19968;&#24352;&#37327;(r&gt;1)&#30340;&#24635;&#21644;)&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20351;&#29992;&#21644; MSC &#31639;&#27861;&#30456;&#21516;&#30340;&#36755;&#20837;&#65292;&#21487;&#20197;&#22312;&#22788;&#29702;&#31209;&#19968;&#24352;&#37327;&#25968;&#25454;&#26102;&#19982; MSC &#31639;&#27861;&#33719;&#24471;&#30456;&#21516;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several methods for triclustering three-dimensional data require the cluster size or the number of clusters in each dimension to be specified. To address this issue, the Multi-Slice Clustering (MSC) for 3-order tensor finds signal slices that lie in a low dimensional subspace for a rank-one tensor dataset in order to find a cluster based on the threshold similarity. We propose an extension algorithm called MSC-DBSCAN to extract the different clusters of slices that lie in the different subspaces from the data if the dataset is a sum of r rank-one tensor (r &gt; 1). Our algorithm uses the same input as the MSC algorithm and can find the same solution for rank-one tensor data as MSC.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#25968;&#25454;&#31232;&#30095;&#21270;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#24456;&#22810;&#20998;&#24067;&#31867;&#22411;&#65292;&#21253;&#25324;&#39640;&#26031;&#20998;&#24067;&#12289;&#27850;&#26494;&#20998;&#24067;&#12289;&#36127;&#20108;&#39033;&#20998;&#24067;&#12289;&#20285;&#29595;&#20998;&#24067;&#21644;&#20108;&#39033;&#20998;&#24067;&#31561;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#65292;&#22914;&#22312;&#20132;&#21449;&#39564;&#35777;&#26041;&#38754;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#33021;&#26377;&#25928;&#39564;&#35777;&#26080;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#30340;&#21487;&#38752;&#24615;&#12290;</title><link>http://arxiv.org/abs/2301.07276</link><description>&lt;p&gt;
&#25968;&#25454;&#31232;&#30095;&#21270;&#25216;&#26415;&#29992;&#20110;&#21367;&#31215;&#23553;&#38381;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Data thinning for convolution-closed distributions. (arXiv:2301.07276v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.07276
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#25968;&#25454;&#31232;&#30095;&#21270;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#24456;&#22810;&#20998;&#24067;&#31867;&#22411;&#65292;&#21253;&#25324;&#39640;&#26031;&#20998;&#24067;&#12289;&#27850;&#26494;&#20998;&#24067;&#12289;&#36127;&#20108;&#39033;&#20998;&#24067;&#12289;&#20285;&#29595;&#20998;&#24067;&#21644;&#20108;&#39033;&#20998;&#24067;&#31561;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#65292;&#22914;&#22312;&#20132;&#21449;&#39564;&#35777;&#26041;&#38754;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#33021;&#26377;&#25928;&#39564;&#35777;&#26080;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#25968;&#25454;&#31232;&#30095;&#21270;&#30340;&#26041;&#27861;&#65292;&#23558;&#19968;&#20010;&#35266;&#27979;&#20540;&#20998;&#25104;&#20004;&#20010;&#25110;&#26356;&#22810;&#20010;&#20114;&#30456;&#29420;&#31435;&#30340;&#37096;&#20998;&#65292;&#36825;&#20123;&#37096;&#20998;&#37117;&#21152;&#36215;&#26469;&#31561;&#20110;&#21407;&#22987;&#25968;&#25454;&#65292;&#24182;&#19988;&#19982;&#21407;&#22987;&#35266;&#27979;&#20540;&#30456;&#21516;&#30340;&#20998;&#24067;&#65292;&#21482;&#26159;&#32463;&#36807;&#19968;&#20010;&#24050;&#30693;&#21442;&#25968;&#35843;&#25972;&#12290;&#36825;&#20010;&#38750;&#24120;&#26222;&#36866;&#30340;&#26041;&#27861;&#36866;&#29992;&#20110;&#20219;&#20309;&#21367;&#31215;&#23553;&#38381;&#20998;&#24067;&#65292;&#21253;&#25324;&#39640;&#26031;&#20998;&#24067;&#12289;&#27850;&#26494;&#20998;&#24067;&#12289;&#36127;&#20108;&#39033;&#20998;&#24067;&#12289;&#20285;&#29595;&#20998;&#24067;&#21644;&#20108;&#39033;&#20998;&#24067;&#31561;&#12290;&#25968;&#25454;&#31232;&#30095;&#21270;&#22312;&#27169;&#22411;&#36873;&#25321;&#12289;&#35780;&#20215;&#21644;&#25512;&#29702;&#26041;&#38754;&#26377;&#22810;&#31181;&#24212;&#29992;&#12290;&#20363;&#22914;&#65292;&#36890;&#36807;&#25968;&#25454;&#31232;&#30095;&#21270;&#30340;&#20132;&#21449;&#39564;&#35777;&#25552;&#20379;&#20102;&#19968;&#31181;&#21560;&#24341;&#20154;&#30340;&#26367;&#20195;&#26041;&#27861;&#26469;&#36827;&#34892;&#20132;&#21449;&#39564;&#35777;&#65292;&#29305;&#21035;&#26159;&#22312;&#26080;&#30417;&#30563;&#30340;&#24773;&#20917;&#19979;&#65292;&#20256;&#32479;&#26041;&#27861;&#30340;&#26679;&#26412;&#21010;&#20998;&#19981;&#36866;&#29992;&#12290;&#25105;&#20204;&#22312;&#27169;&#25311;&#21644;&#24212;&#29992;&#20110;&#21333;&#32454;&#32990;RNA&#27979;&#24207;&#25968;&#25454;&#30340;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#25968;&#25454;&#31232;&#30095;&#21270;&#30340;&#26222;&#36941;&#24615;&#65292;&#21487;&#20197;&#29992;&#20110;&#39564;&#35777;&#26080;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#30340;&#32467;&#26524;&#65292;&#22914;k-means&#32858;&#31867;&#21644;&#20027;&#25104;&#20998;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose data thinning, an approach for splitting an observation into two or more independent parts that sum to the original observation, and that follow the same distribution as the original observation, up to a (known) scaling of a parameter. This very general proposal is applicable to any convolution-closed distribution, a class that includes the Gaussian, Poisson, negative binomial, gamma, and binomial distributions, among others. Data thinning has a number of applications to model selection, evaluation, and inference. For instance, cross-validation via data thinning provides an attractive alternative to the usual approach of cross-validation via sample splitting, especially in unsupervised settings in which the latter is not applicable. In simulations and in an application to single-cell RNA-sequencing data, we show that data thinning can be used to validate the results of unsupervised learning approaches, such as k-means clustering and principal components analysis.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DCMQ&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#22522;&#20110;Huber&#33021;&#37327;&#26680;&#30340;&#26041;&#27861;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#29992;&#20110;&#26465;&#20214;&#27979;&#24230;&#37327;&#21270;&#65292;&#24182;&#22312;&#22810;&#20010;&#23454;&#20363;&#20013;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2301.06907</link><description>&lt;p&gt;
&#28145;&#24230;&#26465;&#20214;&#27979;&#24230;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Deep Conditional Measure Quantization. (arXiv:2301.06907v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.06907
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DCMQ&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#22522;&#20110;Huber&#33021;&#37327;&#26680;&#30340;&#26041;&#27861;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#29992;&#20110;&#26465;&#20214;&#27979;&#24230;&#37327;&#21270;&#65292;&#24182;&#22312;&#22810;&#20010;&#23454;&#20363;&#20013;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27010;&#29575;&#27979;&#24230;&#30340;&#37327;&#21270;&#24847;&#21619;&#30528;&#20351;&#29992;&#19968;&#32452;&#26377;&#38480;&#30340;&#29380;&#25289;&#20811;&#20998;&#24067;&#26469;&#36817;&#20284;&#34920;&#31034;&#36755;&#20837;&#20998;&#24067;&#65288;&#22312;&#19968;&#20123;&#27010;&#29575;&#27979;&#24230;&#24230;&#37327;&#31354;&#38388;&#20013;&#65289;&#12290;&#26377;&#21508;&#31181;&#21508;&#26679;&#30340;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#20294;&#21487;&#33021;&#20250;&#23384;&#22312;&#26465;&#20214;&#27861;&#30340;&#37327;&#21270;&#38656;&#35201;&#25506;&#32034;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;DCMQ&#30340;&#26041;&#27861;&#65292;&#23427;&#28041;&#21450;&#21040;&#22522;&#20110;Huber&#33021;&#37327;&#26680;&#30340;&#26041;&#27861;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20307;&#31995;&#32467;&#26500;&#30340;&#32806;&#21512;&#12290;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#23454;&#20363;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#24182;&#33719;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantization of a probability measure means representing it with a finite set of Dirac masses that approximates the input distribution well enough (in some metric space of probability measures). Various methods exists to do so, but the situation of quantizing a conditional law has been less explored. We propose a method, called DCMQ, involving a Huber-energy kernel-based approach coupled with a deep neural network architecture. The method is tested on several examples and obtains promising results.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#31232;&#26377;&#20107;&#20214;&#30340;&#26032;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#65292;&#22522;&#20110;&#25910;&#38598;&#21040;&#30340;&#26102;&#38388;&#19981;&#21464;&#21160;&#24577;&#31995;&#32479;&#30340;&#25968;&#25454;&#65292;&#26500;&#24314;&#20102;&#21472;&#21152;&#25968;&#25454;&#38598;&#21644;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25581;&#31034;&#22312;&#21464;&#37327;&#31532;&#19968;&#27425;&#32463;&#21382;&#20302;&#27010;&#29575;&#23454;&#29616;&#26102;&#25165;&#20250;&#26174;&#29616;&#30340;&#22240;&#26524;&#20851;&#31995;&#65292;&#20855;&#26377;&#24456;&#22909;&#30340;&#21487;&#34892;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.16596</link><description>&lt;p&gt;
&#38754;&#21521;&#31232;&#26377;&#20107;&#20214;&#30340;&#21160;&#24577;&#22240;&#26524;&#21457;&#29616;&#65306;&#19968;&#31181;&#38750;&#21442;&#25968;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Towards Dynamic Causal Discovery with Rare Events: A Nonparametric Conditional Independence Test. (arXiv:2211.16596v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.16596
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#31232;&#26377;&#20107;&#20214;&#30340;&#26032;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#65292;&#22522;&#20110;&#25910;&#38598;&#21040;&#30340;&#26102;&#38388;&#19981;&#21464;&#21160;&#24577;&#31995;&#32479;&#30340;&#25968;&#25454;&#65292;&#26500;&#24314;&#20102;&#21472;&#21152;&#25968;&#25454;&#38598;&#21644;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25581;&#31034;&#22312;&#21464;&#37327;&#31532;&#19968;&#27425;&#32463;&#21382;&#20302;&#27010;&#29575;&#23454;&#29616;&#26102;&#25165;&#20250;&#26174;&#29616;&#30340;&#22240;&#26524;&#20851;&#31995;&#65292;&#20855;&#26377;&#24456;&#22909;&#30340;&#21487;&#34892;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19982;&#31232;&#26377;&#20107;&#20214;&#30456;&#20851;&#32852;&#30340;&#22240;&#26524;&#29616;&#35937;&#22312;&#35768;&#22810;&#24037;&#31243;&#38382;&#39064;&#20013;&#37117;&#23384;&#22312;&#65292;&#20363;&#22914;&#38024;&#23545;&#39118;&#38505;&#30340;&#23433;&#20840;&#20998;&#26512;&#12289;&#20107;&#25925;&#20998;&#26512;&#21644;&#39044;&#38450;&#20197;&#21450;&#26497;&#20540;&#29702;&#35770;&#31561;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#24448;&#24448;&#26080;&#27861;&#21457;&#29616;&#22312;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#30340;&#21407;&#22240;&#32852;&#31995;&#65292;&#29305;&#21035;&#26159;&#22312;&#21464;&#21160;&#29615;&#22659;&#19979;&#65292;&#20165;&#22312;&#21464;&#37327;&#31532;&#19968;&#27425;&#32463;&#21382;&#20302;&#27010;&#29575;&#23454;&#29616;&#26102;&#25165;&#20250;&#26174;&#29616;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#29420;&#31435;&#24615;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#21457;&#29983;&#31232;&#26377;&#20294;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#30340;&#26102;&#38388;&#19981;&#21464;&#21160;&#24577;&#31995;&#32479;&#25910;&#38598;&#30340;&#25968;&#25454;&#20013;&#36827;&#34892;&#22240;&#26524;&#25506;&#32034;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#21033;&#29992;&#24213;&#23618;&#25968;&#25454;&#30340;&#26102;&#38388;&#19981;&#21464;&#24615;&#26469;&#26500;&#24314;&#19968;&#20010;&#21472;&#21152;&#30340;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#25324;&#22312;&#19981;&#21516;&#26102;&#38388;&#27493;&#39588;&#20043;&#21069;&#31232;&#26377;&#20107;&#20214;&#21457;&#29983;&#21069;&#31995;&#32479;&#29366;&#24577;&#30340;&#25968;&#25454;&#12290;&#28982;&#21518;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#22312;&#37325;&#26032;&#32452;&#32455;&#30340;&#25968;&#25454;&#19978;&#36827;&#34892;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25105;&#20204;&#26041;&#27861;&#19968;&#33268;&#24615;&#30340;&#38750;&#28176;&#36817;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#65292;&#24182;&#39564;&#35777;&#20102;&#23427;&#22312;&#21508;&#31181;&#27169;&#25311;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal phenomena associated with rare events occur across a wide range of engineering problems, such as risk-sensitive safety analysis, accident analysis and prevention, and extreme value theory. However, current methods for causal discovery are often unable to uncover causal links, between random variables in a dynamic setting, that manifest only when the variables first experience low-probability realizations. To address this issue, we introduce a novel statistical independence test on data collected from time-invariant dynamical systems in which rare but consequential events occur. In particular, we exploit the time-invariance of the underlying data to construct a superimposed dataset of the system state before rare events happen at different timesteps. We then design a conditional independence test on the reorganized data. We provide non-asymptotic sample complexity bounds for the consistency of our method, and validate its performance across various simulated and real-world datase
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#31034;&#25104;&#26412;&#21644;&#28145;&#24230;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#21457;&#29616;&#20854;&#20250;&#25910;&#25947;&#21040;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#31209;&#30340;&#27010;&#24565;&#12290;&#21516;&#26102;&#65292;&#21457;&#29616;&#22312;&#19968;&#23450;&#30340;&#28145;&#24230;&#33539;&#22260;&#20869;&#65292;&#20840;&#23616;&#26368;&#23567;&#20540;&#21487;&#20197;&#24674;&#22797;&#30495;&#23454;&#30340;&#25968;&#25454;&#31209;&#65292;&#24182;&#25506;&#35752;&#20102;&#20998;&#31867;&#22120;&#31209;&#23545;&#31867;&#36793;&#30028;&#25299;&#25169;&#32467;&#26500;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2209.15055</link><description>&lt;p&gt;
&#22823;&#28145;&#24230;&#32593;&#32476;&#30340;&#38544;&#24335;&#20559;&#35265;&#65306;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#31209;&#23450;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
Implicit Bias of Large Depth Networks: a Notion of Rank for Nonlinear Functions. (arXiv:2209.15055v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.15055
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#31034;&#25104;&#26412;&#21644;&#28145;&#24230;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#21457;&#29616;&#20854;&#20250;&#25910;&#25947;&#21040;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#31209;&#30340;&#27010;&#24565;&#12290;&#21516;&#26102;&#65292;&#21457;&#29616;&#22312;&#19968;&#23450;&#30340;&#28145;&#24230;&#33539;&#22260;&#20869;&#65292;&#20840;&#23616;&#26368;&#23567;&#20540;&#21487;&#20197;&#24674;&#22797;&#30495;&#23454;&#30340;&#25968;&#25454;&#31209;&#65292;&#24182;&#25506;&#35752;&#20102;&#20998;&#31867;&#22120;&#31209;&#23545;&#31867;&#36793;&#30028;&#25299;&#25169;&#32467;&#26500;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#20855;&#26377;&#40784;&#27425;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#31034;&#25104;&#26412;&#8212;&#8212;&#25551;&#36848;&#20102;&#20855;&#26377;$L_2$&#27491;&#21017;&#21270;&#25110;&#20132;&#21449;&#29109;&#31561;&#25439;&#22833;&#32593;&#32476;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#30340;&#38544;&#24335;&#20559;&#35265;&#8212;&#8212;&#38543;&#30528;&#32593;&#32476;&#28145;&#24230;&#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#65292;&#20250;&#25910;&#25947;&#21040;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#31209;&#30340;&#27010;&#24565;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25506;&#31350;&#20102;&#20840;&#23616;&#26368;&#23567;&#20540;&#22312;&#21738;&#20123;&#26465;&#20214;&#19979;&#21487;&#20197;&#24674;&#22797;&#8220;&#30495;&#23454;&#8221;&#25968;&#25454;&#31209;&#65306;&#25105;&#20204;&#23637;&#31034;&#20986;&#65292;&#23545;&#20110;&#22826;&#22823;&#30340;&#28145;&#24230;&#65292;&#20840;&#23616;&#26368;&#23567;&#20540;&#20250;&#36817;&#20284;&#20026;&#31209;1&#65288;&#20302;&#20272;&#31209;&#65289;&#65307;&#25105;&#20204;&#38543;&#21518;&#35770;&#35777;&#20102;&#26377;&#19968;&#31995;&#21015;&#28145;&#24230;&#65292;&#38543;&#30528;&#25968;&#25454;&#28857;&#25968;&#37327;&#22686;&#21152;&#65292;&#21487;&#20197;&#24674;&#22797;&#30495;&#23454;&#31209;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#20998;&#31867;&#22120;&#31209;&#23545;&#32467;&#26524;&#31867;&#36793;&#30028;&#30340;&#25299;&#25169;&#32467;&#26500;&#30340;&#24433;&#21709;&#65292;&#24182;&#23637;&#31034;&#20102;&#20855;&#26377;&#26368;&#20339;&#38750;&#32447;&#24615;&#31209;&#30340;&#33258;&#32534;&#30721;&#22120;&#20855;&#26377;&#33258;&#28982;&#21435;&#22122;&#30340;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show that the representation cost of fully connected neural networks with homogeneous nonlinearities - which describes the implicit bias in function space of networks with $L_2$-regularization or with losses such as the cross-entropy - converges as the depth of the network goes to infinity to a notion of rank over nonlinear functions. We then inquire under which conditions the global minima of the loss recover the `true' rank of the data: we show that for too large depths the global minimum will be approximately rank 1 (underestimating the rank); we then argue that there is a range of depths which grows with the number of datapoints where the true rank is recovered. Finally, we discuss the effect of the rank of a classifier on the topology of the resulting class boundaries and show that autoencoders with optimal nonlinear rank are naturally denoising.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#36830;&#32493;&#28151;&#21512;&#30340;&#26041;&#27861;&#65292;&#23558;&#21487;&#35745;&#31639;&#27010;&#29575;&#27169;&#22411;&#21644;&#22522;&#20110;&#36830;&#32493;&#28508;&#31354;&#38388;&#30340;&#27169;&#22411;&#32467;&#21512;&#36215;&#26469;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#27010;&#29575;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2209.10584</link><description>&lt;p&gt;
&#21487;&#35745;&#31639;&#27010;&#29575;&#27169;&#22411;&#30340;&#36830;&#32493;&#28151;&#21512;
&lt;/p&gt;
&lt;p&gt;
Continuous Mixtures of Tractable Probabilistic Models. (arXiv:2209.10584v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.10584
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#36830;&#32493;&#28151;&#21512;&#30340;&#26041;&#27861;&#65292;&#23558;&#21487;&#35745;&#31639;&#27010;&#29575;&#27169;&#22411;&#21644;&#22522;&#20110;&#36830;&#32493;&#28508;&#31354;&#38388;&#30340;&#27169;&#22411;&#32467;&#21512;&#36215;&#26469;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#27010;&#29575;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#36830;&#32493;&#28508;&#31354;&#38388;&#30340;&#27010;&#29575;&#27169;&#22411;&#65292;&#22914;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65292;&#21487;&#20197;&#29702;&#35299;&#20026;&#22312;&#28508;&#21464;&#37327;&#19978;&#36830;&#32493;&#20381;&#36182;&#30340;&#19981;&#21487;&#25968;&#28151;&#21512;&#27169;&#22411;&#12290;&#23427;&#20204;&#24050;&#34987;&#35777;&#26126;&#26159;&#34920;&#36798;&#29983;&#25104;&#21644;&#27010;&#29575;&#24314;&#27169;&#30340;&#26377;&#25928;&#24037;&#20855;&#65292;&#20294;&#19982;&#33021;&#22815;&#35745;&#31639;&#25152;&#34920;&#31034;&#30340;&#27010;&#29575;&#20998;&#24067;&#30340;&#36739;&#20026;&#31616;&#21333;&#30340;&#21487;&#35745;&#31639;&#27010;&#29575;&#25512;&#26029;&#26041;&#27861;&#23384;&#22312;&#30683;&#30462;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#21487;&#35745;&#31639;&#27010;&#29575;&#27169;&#22411;&#65292;&#22914;&#27010;&#29575;&#30005;&#36335;(PCs)&#65292;&#21487;&#20197;&#29702;&#35299;&#20026;&#23618;&#27425;&#31163;&#25955;&#28151;&#21512;&#27169;&#22411;&#65292;&#22240;&#27492;&#33021;&#22815;&#39640;&#25928;&#22320;&#36827;&#34892;&#20934;&#30830;&#25512;&#26029;&#65292;&#20294;&#22312;&#19982;&#36830;&#32493;&#28508;&#31354;&#38388;&#27169;&#22411;&#30456;&#27604;&#26102;&#36890;&#24120;&#34920;&#29616;&#19981;&#20339;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#28151;&#21512;&#26041;&#27861;&#65292;&#21363;&#20855;&#26377;&#23567;&#28508;&#21464;&#37327;&#32500;&#24230;&#30340;&#21487;&#35745;&#31639;&#27169;&#22411;&#30340;&#36830;&#32493;&#28151;&#21512;&#12290;&#23613;&#31649;&#36825;&#20123;&#27169;&#22411;&#22312;&#35299;&#26512;&#19978;&#26159;&#38590;&#20197;&#22788;&#29702;&#30340;&#65292;&#20294;&#23427;&#20204;&#36866;&#21512;&#20110;&#22522;&#20110;&#26377;&#38480;&#31215;&#20998;&#28857;&#38598;&#30340;&#25968;&#20540;&#31215;&#20998;&#26041;&#26696;&#12290;&#36890;&#36807;&#36275;&#22815;&#22823;&#30340;&#31215;&#20998;&#28857;&#38598;&#65292;&#25105;&#20204;&#21487;&#20197;&#32039;&#23494;&#22320;&#36817;&#20284;&#27010;&#29575;&#27169;&#22411;&#24182;&#36827;&#34892;&#39640;&#25928;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Probabilistic models based on continuous latent spaces, such as variational autoencoders, can be understood as uncountable mixture models where components depend continuously on the latent code. They have proven to be expressive tools for generative and probabilistic modelling, but are at odds with tractable probabilistic inference, that is, computing marginals and conditionals of the represented probability distribution. Meanwhile, tractable probabilistic models such as probabilistic circuits (PCs) can be understood as hierarchical discrete mixture models, and thus are capable of performing exact inference efficiently but often show subpar performance in comparison to continuous latent-space models. In this paper, we investigate a hybrid approach, namely continuous mixtures of tractable models with a small latent dimension. While these models are analytically intractable, they are well amenable to numerical integration schemes based on a finite set of integration points. With a large 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#27700;&#24211;&#35745;&#31639;&#27169;&#22411;EuSN&#65292;&#20854;&#21033;&#29992;&#21069;&#21521;&#27431;&#25289;&#31163;&#25955;&#21270;&#21644;&#21453;&#23545;&#31216;&#24490;&#29615;&#30697;&#38453;&#26469;&#35774;&#35745;&#27700;&#24211;&#21160;&#21147;&#23398;&#65292;&#20855;&#26377;&#25509;&#36817;&#31283;&#23450;&#36793;&#32536;&#30340;&#39281;&#21644;&#26377;&#25928;&#35889;&#21322;&#24452;&#21644;&#38646;&#23616;&#37096;&#26446;&#38597;&#26222;&#35834;&#22827;&#25351;&#25968;&#12290;&#22312;&#38271;&#26399;&#35760;&#24518;&#20219;&#21153;&#21644;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#20102;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2203.09382</link><description>&lt;p&gt;
Euler State Networks: &#38750;&#32791;&#25955;&#24615;&#27700;&#24211;&#35745;&#31639;
&lt;/p&gt;
&lt;p&gt;
Euler State Networks: Non-dissipative Reservoir Computing. (arXiv:2203.09382v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.09382
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#27700;&#24211;&#35745;&#31639;&#27169;&#22411;EuSN&#65292;&#20854;&#21033;&#29992;&#21069;&#21521;&#27431;&#25289;&#31163;&#25955;&#21270;&#21644;&#21453;&#23545;&#31216;&#24490;&#29615;&#30697;&#38453;&#26469;&#35774;&#35745;&#27700;&#24211;&#21160;&#21147;&#23398;&#65292;&#20855;&#26377;&#25509;&#36817;&#31283;&#23450;&#36793;&#32536;&#30340;&#39281;&#21644;&#26377;&#25928;&#35889;&#21322;&#24452;&#21644;&#38646;&#23616;&#37096;&#26446;&#38597;&#26222;&#35834;&#22827;&#25351;&#25968;&#12290;&#22312;&#38271;&#26399;&#35760;&#24518;&#20219;&#21153;&#21644;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#20102;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21463;&#21040;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#25968;&#20540;&#35299;&#21551;&#21457;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#27700;&#24211;&#35745;&#31639;(EuSN)&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#21069;&#21521;&#27431;&#25289;&#31163;&#25955;&#21270;&#21644;&#21453;&#23545;&#31216;&#24490;&#29615;&#30697;&#38453;&#26469;&#35774;&#35745;&#27700;&#24211;&#21160;&#21147;&#23398;&#12290;&#35813;&#27169;&#22411;&#30340;&#25968;&#23398;&#20998;&#26512;&#34920;&#26126;&#65292;&#20854;&#20855;&#26377;&#25509;&#36817;&#31283;&#23450;&#36793;&#32536;&#30340;&#39281;&#21644;&#26377;&#25928;&#35889;&#21322;&#24452;&#21644;&#38646;&#23616;&#37096;&#26446;&#38597;&#26222;&#35834;&#22827;&#25351;&#25968;&#12290;&#23545;&#38271;&#26399;&#35760;&#24518;&#20219;&#21153;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#19982;&#26631;&#20934;&#27700;&#24211;&#35745;&#31639;&#27169;&#22411;&#30456;&#27604;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#38656;&#35201;&#22810;&#20010;&#26102;&#27493;&#26377;&#25928;&#20256;&#25773;&#36755;&#20837;&#20449;&#24687;&#30340;&#38382;&#39064;&#19978;&#20855;&#26377;&#26126;&#26174;&#30340;&#20248;&#21183;&#12290;&#27492;&#22806;&#65292;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#22522;&#20934;&#27979;&#35797;&#32467;&#26524;&#34920;&#26126;&#65292;EuSN&#33021;&#22815;&#21305;&#37197;&#29978;&#33267;&#36229;&#36807;&#21487;&#35757;&#32451;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#30340;&#20934;&#30830;&#24615;&#65292;&#21516;&#26102;&#20445;&#25345;&#27700;&#24211;&#35745;&#31639;&#23478;&#26063;&#30340;&#35757;&#32451;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inspired by the numerical solution of ordinary differential equations, in this paper we propose a novel Reservoir Computing (RC) model, called the Euler State Network (EuSN). The presented approach makes use of forward Euler discretization and antisymmetric recurrent matrices to design reservoir dynamics that are both stable and non-dissipative by construction.  Our mathematical analysis shows that the resulting model is biased towards a unitary effective spectral radius and zero local Lyapunov exponents, intrinsically operating near to the edge of stability. Experiments on long-term memory tasks show the clear superiority of the proposed approach over standard RC models in problems requiring effective propagation of input information over multiple time-steps. Furthermore, results on time-series classification benchmarks indicate that EuSN is able to match (or even exceed) the accuracy of trainable Recurrent Neural Networks, while retaining the training efficiency of the RC family, res
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#31895;&#31961;&#25968;&#25454;&#20013;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#21482;&#38656;&#36275;&#22815;&#20449;&#24687;&#30340;&#31895;&#26631;&#31614;&#21363;&#21487;&#22312;&#20174;&#32454;&#26631;&#31614;&#20013;&#23398;&#20064;&#30340;&#20219;&#20309;&#38382;&#39064;&#19978;&#36827;&#34892;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2108.09805</link><description>&lt;p&gt;
&#23398;&#20064;&#31895;&#26631;&#31614;&#30340;&#39640;&#25928;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient Algorithms for Learning from Coarse Labels. (arXiv:2108.09805v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.09805
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#31895;&#31961;&#25968;&#25454;&#20013;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#21482;&#38656;&#36275;&#22815;&#20449;&#24687;&#30340;&#31895;&#26631;&#31614;&#21363;&#21487;&#22312;&#20174;&#32454;&#26631;&#31614;&#20013;&#23398;&#20064;&#30340;&#20219;&#20309;&#38382;&#39064;&#19978;&#36827;&#34892;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#35768;&#22810;&#23398;&#20064;&#38382;&#39064;&#65292;&#25105;&#20204;&#21487;&#33021;&#26080;&#27861;&#35775;&#38382;&#32454;&#31890;&#24230;&#26631;&#31614;&#20449;&#24687;&#65307;&#20363;&#22914;&#65292;&#26681;&#25454;&#27880;&#37322;&#32773;&#30340;&#19987;&#19994;&#30693;&#35782;&#65292;&#19968;&#24133;&#22270;&#20687;&#21487;&#20197;&#34987;&#26631;&#35760;&#20026;&#21704;&#22763;&#22855;&#12289;&#29399;&#29978;&#33267;&#21160;&#29289;&#12290;&#26412;&#25991;&#23545;&#36825;&#20123;&#24773;&#20917;&#36827;&#34892;&#20102;&#24418;&#24335;&#21270;&#65292;&#24182;&#30740;&#31350;&#20102;&#20174;&#27492;&#31867;&#31895;&#25968;&#25454;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#19981;&#26159;&#35266;&#23519;&#26469;&#33258;&#38598;&#21512; $\mathcal{Z}$ &#30340;&#23454;&#38469;&#26631;&#31614;&#65292;&#32780;&#26159;&#35266;&#23519;&#23545;&#24212;&#20110; $\mathcal{Z}$ &#30340;&#21010;&#20998;&#65288;&#25110;&#22810;&#31181;&#21010;&#20998;&#30340;&#28151;&#21512;&#65289;&#30340;&#31895;&#26631;&#31614;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#31639;&#27861;&#32467;&#26524;&#26159;&#65306;&#20960;&#20046;&#20219;&#20309;&#21487;&#20174;&#32454;&#31890;&#24230;&#26631;&#31614;&#20013;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#24403;&#31895;&#25968;&#25454;&#36275;&#22815;&#20449;&#24687;&#26102;&#20063;&#21487;&#20197;&#39640;&#25928;&#22320;&#23398;&#20064;&#12290;&#25105;&#20204;&#36890;&#36807;&#27867;&#21270;&#20943;&#23569;&#22238;&#31572;&#32479;&#35745;&#26597;&#35810;&#65288;SQ) &#30340;&#26041;&#24335;&#26469;&#33719;&#24471;&#32467;&#26524;&#65292;&#21482;&#32473;&#20986;&#31895;&#26631;&#31614;&#32780;&#19981;&#26159;&#32454;&#26631;&#31614;&#12290;&#25152;&#38656;&#31895;&#26631;&#31614;&#25968;&#37327;&#19982;&#31895;&#31961;&#21270;&#20449;&#24687;&#22833;&#30495;&#21644;&#32454;&#26631;&#31614;&#25968;&#37327; $|\mathcal{Z}|$ &#25104;&#22810;&#39033;&#24335;&#20851;&#31995;&#12290;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#65288;&#26080;&#38480;&#22810;&#20010;&#65289;&#23454;&#20540;&#26631;&#31614;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
For many learning problems one may not have access to fine grained label information; e.g., an image can be labeled as husky, dog, or even animal depending on the expertise of the annotator. In this work, we formalize these settings and study the problem of learning from such coarse data. Instead of observing the actual labels from a set $\mathcal{Z}$, we observe coarse labels corresponding to a partition of $\mathcal{Z}$ (or a mixture of partitions).  Our main algorithmic result is that essentially any problem learnable from fine grained labels can also be learned efficiently when the coarse data are sufficiently informative. We obtain our result through a generic reduction for answering Statistical Queries (SQ) over fine grained labels given only coarse labels. The number of coarse labels required depends polynomially on the information distortion due to coarsening and the number of fine labels $|\mathcal{Z}|$.  We also investigate the case of (infinitely many) real valued labels foc
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#65292;&#23427;&#19981;&#20381;&#36182;&#20110;&#23545;&#25968;&#25454;&#38598;&#32500;&#24230;&#30340;&#20551;&#35774;&#65292;&#21487;&#20197;&#22312;&#39640;&#32500;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2011.05068</link><description>&lt;p&gt;
&#20351;&#29992;&#20132;&#21449;U&#32479;&#35745;&#37327;&#30340;&#32500;&#24230;&#19981;&#21487;&#30693;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Dimension-agnostic inference using cross U-statistics. (arXiv:2011.05068v6 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2011.05068
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#65292;&#23427;&#19981;&#20381;&#36182;&#20110;&#23545;&#25968;&#25454;&#38598;&#32500;&#24230;&#30340;&#20551;&#35774;&#65292;&#21487;&#20197;&#22312;&#39640;&#32500;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32463;&#20856;&#30340;&#32479;&#35745;&#25512;&#26029;&#28176;&#36827;&#29702;&#35770;&#36890;&#24120;&#28041;&#21450;&#36890;&#36807;&#22266;&#23450;&#32500;&#24230;d&#26469;&#35753;&#26679;&#26412;&#37327;n&#36235;&#21521;&#26080;&#31351;&#65292;&#20174;&#32780;&#26657;&#20934;&#32479;&#35745;&#37327;&#12290;&#26368;&#36817;&#65292;&#20154;&#20204;&#22823;&#21147;&#30740;&#31350;&#20102;&#36825;&#20123;&#26041;&#27861;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#30340;&#34920;&#29616;&#65292;&#20854;&#20013;d&#21644;n&#37117;&#21516;&#26102;&#22686;&#21152;&#21040;&#26080;&#31351;&#12290;&#36825;&#24448;&#24448;&#23548;&#33268;&#19981;&#21516;&#30340;&#25512;&#26029;&#36807;&#31243;&#65292;&#21462;&#20915;&#20110;&#23545;&#32500;&#24230;&#24615;&#30340;&#20551;&#35774;&#65292;&#35753;&#20174;&#19994;&#32773;&#24863;&#21040;&#20026;&#38590;&#65306;&#23545;&#20110;&#19968;&#20010;20&#32500;&#30340;100&#20010;&#26679;&#26412;&#30340;&#25968;&#25454;&#38598;&#65292;&#20182;&#20204;&#24212;&#35813;&#20551;&#35774;n&gt;&gt;d&#65292;&#36824;&#26159;d/n&#32422;&#20026;0.2&#65311;&#26412;&#25991;&#32771;&#34385;&#20102;&#32500;&#24230;&#19981;&#21487;&#30693;&#25512;&#26029;&#30340;&#30446;&#26631;&#65307;&#24320;&#21457;&#20986;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#19981;&#20381;&#36182;&#20110;&#23545;d&#21644;n&#30340;&#20219;&#20309;&#20551;&#35774;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#20351;&#29992;&#29616;&#26377;&#27979;&#35797;&#32479;&#35745;&#37327;&#30340;&#21464;&#20998;&#34920;&#31034;&#65292;&#32467;&#21512;&#26679;&#26412;&#25286;&#20998;&#21644;&#33258;&#35268;&#33539;&#21270;&#65292;&#20135;&#29983;&#20102;&#19968;&#20010;&#31934;&#32454;&#30340;&#27979;&#35797;&#32479;&#35745;&#37327;&#65292;&#20854;&#39640;&#26031;&#26497;&#38480;&#20998;&#24067;&#30340;&#26377;&#25928;&#24615;&#19981;&#21462;&#20915;&#20110;d&#21644;n&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#30740;&#31350;&#20102;&#20854;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classical asymptotic theory for statistical inference usually involves calibrating a statistic by fixing the dimension $d$ while letting the sample size $n$ increase to infinity. Recently, much effort has been dedicated towards understanding how these methods behave in high-dimensional settings, where $d$ and $n$ both increase to infinity together. This often leads to different inference procedures, depending on the assumptions about the dimensionality, leaving the practitioner in a bind: given a dataset with 100 samples in 20 dimensions, should they calibrate by assuming $n \gg d$, or $d/n \approx 0.2$? This paper considers the goal of dimension-agnostic inference; developing methods whose validity does not depend on any assumption on $d$ versus $n$. We introduce an approach that uses variational representations of existing test statistics along with sample splitting and self-normalization to produce a refined test statistic with a Gaussian limiting distribution, regardless of how $d$
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23545;&#25239;&#25915;&#20987;&#19979;&#30340;UCB&#26368;&#20248;&#25289;&#33218;&#31574;&#30053;&#65292;&#25104;&#26412;&#20026;$\sqrt{\log T}$&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#27492;&#25915;&#20987;&#31574;&#30053;&#36817;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2008.09312</link><description>&lt;p&gt;
UCB Bandits&#22312;&#23545;&#25239;&#25915;&#20987;&#20013;&#30340;&#36817;&#20046;&#26368;&#20248;&#25915;&#20987;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Near Optimal Adversarial Attack on UCB Bandits. (arXiv:2008.09312v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2008.09312
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23545;&#25239;&#25915;&#20987;&#19979;&#30340;UCB&#26368;&#20248;&#25289;&#33218;&#31574;&#30053;&#65292;&#25104;&#26412;&#20026;$\sqrt{\log T}$&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#27492;&#25915;&#20987;&#31574;&#30053;&#36817;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#31181;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#65292;&#20854;&#20013;&#22870;&#21169;&#21463;&#21040;&#23545;&#25239;&#24615;&#30772;&#22351;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25915;&#20987;&#31574;&#30053;&#65292;&#36890;&#36807;&#25805;&#20316;UCB&#21407;&#21017;&#26469;&#25289;&#21160;&#19968;&#20123;&#38750;&#26368;&#20248;&#30446;&#26631;&#33218;$T-o(T)$&#27425;&#65292;&#32047;&#31215;&#25104;&#26412;&#30340;&#26631;&#24230;&#20026;$\sqrt{\log T}$&#65292;&#20854;&#20013;$T$&#20026;&#22238;&#21512;&#25968;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#32047;&#31215;&#25915;&#20987;&#25104;&#26412;&#30340;&#31532;&#19968;&#20010;&#19979;&#30028;&#12290;&#25105;&#20204;&#30340;&#19979;&#30028;&#19982;&#25105;&#20204;&#30340;&#19978;&#30028;&#21305;&#37197;&#65292;&#38500;&#20102;$\log\log T$&#22240;&#23376;&#65292;&#34920;&#26126;&#25105;&#20204;&#30340;&#25915;&#20987;&#31574;&#30053;&#36817;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a stochastic multi-arm bandit problem where rewards are subject to adversarial corruption. We propose a novel attack strategy that manipulates a UCB principle into pulling some non-optimal target arm $T - o(T)$ times with a cumulative cost that scales as $\sqrt{\log T}$, where $T$ is the number of rounds. We also prove the first lower bound on the cumulative attack cost. Our lower bound matches our upper bound up to $\log \log T$ factors, showing our attack to be near optimal.
&lt;/p&gt;</description></item></channel></rss>