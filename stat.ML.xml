<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20256;&#24863;&#22120;&#25968;&#25454;&#12289;&#26041;&#31243;&#21644;&#33258;&#28982;&#35821;&#35328;&#25552;&#31034;&#19978;&#19979;&#25991;&#20013;&#36816;&#31639;&#31526;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#25972;&#21512;&#20154;&#31867;&#30693;&#35782;&#21644;&#35821;&#35328;&#25551;&#36848;&#65292;&#35813;&#26041;&#27861;&#19981;&#20165;&#25193;&#23637;&#20102;&#29289;&#29702;&#20449;&#24687;&#23398;&#20064;&#30340;&#28789;&#27963;&#24615;&#21644;&#26222;&#36866;&#24615;&#65292;&#32780;&#19988;&#26174;&#33879;&#25552;&#39640;&#20102;&#23398;&#20064;&#24615;&#33021;&#21644;&#20943;&#23569;&#20102;&#25968;&#25454;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2308.05061</link><description>&lt;p&gt;
&#20351;&#29992;&#20256;&#24863;&#22120;&#25968;&#25454;&#12289;&#26041;&#31243;&#21644;&#33258;&#28982;&#35821;&#35328;&#25552;&#31034;&#19978;&#19979;&#25991;&#20013;&#30340;&#36816;&#31639;&#31526;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Prompting In-Context Operator Learning with Sensor Data, Equations, and Natural Language. (arXiv:2308.05061v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05061
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20256;&#24863;&#22120;&#25968;&#25454;&#12289;&#26041;&#31243;&#21644;&#33258;&#28982;&#35821;&#35328;&#25552;&#31034;&#19978;&#19979;&#25991;&#20013;&#36816;&#31639;&#31526;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#25972;&#21512;&#20154;&#31867;&#30693;&#35782;&#21644;&#35821;&#35328;&#25551;&#36848;&#65292;&#35813;&#26041;&#27861;&#19981;&#20165;&#25193;&#23637;&#20102;&#29289;&#29702;&#20449;&#24687;&#23398;&#20064;&#30340;&#28789;&#27963;&#24615;&#21644;&#26222;&#36866;&#24615;&#65292;&#32780;&#19988;&#26174;&#33879;&#25552;&#39640;&#20102;&#23398;&#20064;&#24615;&#33021;&#21644;&#20943;&#23569;&#20102;&#25968;&#25454;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31185;&#23398;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#20013;&#65292;&#19978;&#19979;&#25991;&#20013;&#30340;&#36816;&#31639;&#31526;&#23398;&#20064;&#24050;&#32463;&#23637;&#31034;&#20986;&#20102;&#22312;&#25512;&#29702;&#38454;&#27573;&#20174;&#25552;&#31034;&#25968;&#25454;&#20013;&#23398;&#20064;&#36816;&#31639;&#31526;&#30340;&#26174;&#33879;&#28508;&#21147;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#26435;&#37325;&#26356;&#26032;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#27169;&#22411;&#23545;&#20256;&#24863;&#22120;&#25968;&#25454;&#30340;&#36807;&#24230;&#20381;&#36182;&#21487;&#33021;&#20250;&#26080;&#24847;&#20013;&#24573;&#35270;&#36816;&#31639;&#31526;&#30340;&#23453;&#36149;&#30340;&#20154;&#31867;&#27934;&#23519;&#21147;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#23558;&#19978;&#19979;&#25991;&#20013;&#30340;&#36816;&#31639;&#31526;&#23398;&#20064;&#36716;&#21270;&#20026;&#19968;&#31181;&#22810;&#27169;&#24335;&#33539;&#24335;&#12290;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#8220;&#26631;&#39064;&#8221;&#26469;&#25972;&#21512;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#21644;&#26041;&#31243;&#24335;&#34920;&#36798;&#30340;&#36816;&#31639;&#31526;&#30340;&#20154;&#31867;&#30693;&#35782;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#25193;&#23637;&#20102;&#29289;&#29702;&#20449;&#24687;&#23398;&#20064;&#30340;&#28789;&#27963;&#24615;&#21644;&#26222;&#36941;&#24615;&#65292;&#32780;&#19988;&#36824;&#26174;&#33879;&#25552;&#39640;&#20102;&#23398;&#20064;&#24615;&#33021;&#24182;&#20943;&#23569;&#20102;&#25968;&#25454;&#38656;&#27714;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26356;&#39640;&#25928;&#30340;&#22810;&#27169;&#24335;&#19978;&#19979;&#25991;&#36816;&#31639;&#31526;&#23398;&#20064;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#31216;&#20026;&#8220;ICON-LM&#8221;&#65292;&#22522;&#20110;&#31867;&#20284;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the growing domain of scientific machine learning, in-context operator learning has demonstrated notable potential in learning operators from prompted data during inference stage without weight updates. However, the current model's overdependence on sensor data, may inadvertently overlook the invaluable human insight into the operator. To address this, we present a transformation of in-context operator learning into a multi-modal paradigm. We propose the use of "captions" to integrate human knowledge about the operator, expressed through natural language descriptions and equations. We illustrate how this method not only broadens the flexibility and generality of physics-informed learning, but also significantly boosts learning performance and reduces data needs. Furthermore, we introduce a more efficient neural network architecture for multi-modal in-context operator learning, referred to as "ICON-LM", based on a language-model-like architecture. We demonstrate the viability of "ICO
&lt;/p&gt;</description></item><item><title>AbDiffuser&#26159;&#19968;&#20010;&#29289;&#29702;&#24615;&#25193;&#25955;&#27169;&#22411;&#65292;&#29992;&#20110;&#32852;&#21512;&#29983;&#25104;&#25239;&#20307;&#30340;&#19977;&#32500;&#32467;&#26500;&#21644;&#24207;&#21015;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#39046;&#22495;&#30693;&#35782;&#21644;&#22522;&#20110;&#29289;&#29702;&#30340;&#32422;&#26463;&#25913;&#21892;&#34507;&#30333;&#36136;&#25193;&#25955;&#65292;&#22788;&#29702;&#24207;&#21015;&#38271;&#24230;&#21464;&#21270;&#65292;&#24182;&#33021;&#22815;&#29983;&#25104;&#19982;&#21442;&#32771;&#38598;&#21512;&#30340;&#24207;&#21015;&#21644;&#32467;&#26500;&#29305;&#24615;&#23494;&#20999;&#21305;&#37197;&#30340;&#25239;&#20307;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;AbDiffuser&#33021;&#22815;&#29983;&#25104;&#39640;&#27700;&#24179;&#34920;&#36798;&#30340;&#25239;&#20307;&#65292;&#20854;&#20013;57.1%&#30340;&#35774;&#35745;&#36873;&#25321;&#26159;&#32039;&#23494;&#32467;&#21512;&#21058;&#12290;</title><link>http://arxiv.org/abs/2308.05027</link><description>&lt;p&gt;
AbDiffuser&#65306;&#20307;&#22806;&#21151;&#33021;&#25239;&#20307;&#30340;&#20840;&#21407;&#23376;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
AbDiffuser: Full-Atom Generation of In-Vitro Functioning Antibodies. (arXiv:2308.05027v1 [q-bio.BM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05027
&lt;/p&gt;
&lt;p&gt;
AbDiffuser&#26159;&#19968;&#20010;&#29289;&#29702;&#24615;&#25193;&#25955;&#27169;&#22411;&#65292;&#29992;&#20110;&#32852;&#21512;&#29983;&#25104;&#25239;&#20307;&#30340;&#19977;&#32500;&#32467;&#26500;&#21644;&#24207;&#21015;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#39046;&#22495;&#30693;&#35782;&#21644;&#22522;&#20110;&#29289;&#29702;&#30340;&#32422;&#26463;&#25913;&#21892;&#34507;&#30333;&#36136;&#25193;&#25955;&#65292;&#22788;&#29702;&#24207;&#21015;&#38271;&#24230;&#21464;&#21270;&#65292;&#24182;&#33021;&#22815;&#29983;&#25104;&#19982;&#21442;&#32771;&#38598;&#21512;&#30340;&#24207;&#21015;&#21644;&#32467;&#26500;&#29305;&#24615;&#23494;&#20999;&#21305;&#37197;&#30340;&#25239;&#20307;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;AbDiffuser&#33021;&#22815;&#29983;&#25104;&#39640;&#27700;&#24179;&#34920;&#36798;&#30340;&#25239;&#20307;&#65292;&#20854;&#20013;57.1%&#30340;&#35774;&#35745;&#36873;&#25321;&#26159;&#32039;&#23494;&#32467;&#21512;&#21058;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;AbDiffuser&#30340;&#31561;&#21464;&#29289;&#29702;&#24615;&#25193;&#25955;&#27169;&#22411;&#65292;&#29992;&#20110;&#32852;&#21512;&#29983;&#25104;&#25239;&#20307;&#30340;&#19977;&#32500;&#32467;&#26500;&#21644;&#24207;&#21015;&#12290;AbDiffuser&#24314;&#31435;&#22312;&#19968;&#31181;&#26032;&#30340;&#34507;&#30333;&#36136;&#32467;&#26500;&#34920;&#31034;&#19978;&#65292;&#20381;&#36182;&#20110;&#19968;&#31181;&#38024;&#23545;&#40784;&#20301;&#34507;&#30333;&#30340;&#26032;&#22411;&#26550;&#26500;&#65292;&#24182;&#21033;&#29992;&#24378;&#25193;&#25955;&#20808;&#39564;&#25913;&#21892;&#21435;&#22122;&#36807;&#31243;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#21033;&#29992;&#39046;&#22495;&#30693;&#35782;&#21644;&#22522;&#20110;&#29289;&#29702;&#30340;&#32422;&#26463;&#25913;&#21892;&#20102;&#34507;&#30333;&#36136;&#25193;&#25955;&#65307;&#22788;&#29702;&#24207;&#21015;&#38271;&#24230;&#21464;&#21270;&#65307;&#24182;&#23558;&#20869;&#23384;&#22797;&#26434;&#24615;&#38477;&#20302;&#19968;&#20010;&#25968;&#37327;&#32423;&#65292;&#23454;&#29616;&#20102;&#39592;&#26550;&#21644;&#20391;&#38142;&#30340;&#29983;&#25104;&#12290;&#25105;&#20204;&#22312;&#20307;&#20869;&#21644;&#20307;&#22806;&#39564;&#35777;&#20102;AbDiffuser&#12290;&#25968;&#20540;&#23454;&#39564;&#23637;&#31034;&#20102;AbDiffuser&#29983;&#25104;&#19982;&#21442;&#32771;&#38598;&#21512;&#30340;&#24207;&#21015;&#21644;&#32467;&#26500;&#29305;&#24615;&#23494;&#20999;&#21305;&#37197;&#30340;&#25239;&#20307;&#30340;&#33021;&#21147;&#12290;&#23454;&#39564;&#23460;&#23454;&#39564;&#35777;&#23454;&#65292;&#21457;&#29616;&#30340;16&#31181;HER2&#25239;&#20307;&#22343;&#20197;&#39640;&#27700;&#24179;&#34920;&#36798;&#65292;&#24182;&#19988;57.1%&#30340;&#35774;&#35745;&#36873;&#25321;&#26159;&#32039;&#23494;&#32467;&#21512;&#21058;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce AbDiffuser, an equivariant and physics-informed diffusion model for the joint generation of antibody 3D structures and sequences. AbDiffuser is built on top of a new representation of protein structure, relies on a novel architecture for aligned proteins, and utilizes strong diffusion priors to improve the denoising process. Our approach improves protein diffusion by taking advantage of domain knowledge and physics-based constraints; handles sequence-length changes; and reduces memory complexity by an order of magnitude enabling backbone and side chain generation. We validate AbDiffuser in silico and in vitro. Numerical experiments showcase the ability of AbDiffuser to generate antibodies that closely track the sequence and structural properties of a reference set. Laboratory experiments confirm that all 16 HER2 antibodies discovered were expressed at high levels and that 57.1% of selected designs were tight binders.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25345;&#20037;&#24615;&#26041;&#27861;&#21435;&#38500;&#31070;&#32463;&#20803;&#20043;&#38388;&#39640;&#30456;&#20851;&#24615;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#35745;&#31639;&#26368;&#23567;&#29983;&#25104;&#26641;&#30340;&#26435;&#37325;&#26469;&#26500;&#24314;&#27491;&#21017;&#21270;&#39033;&#65292;&#24182;&#36890;&#36807;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#27491;&#21017;&#21270;&#39033;&#30340;&#26377;&#25928;&#24615;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#24120;&#35265;&#30340;&#27491;&#21017;&#21270;&#39033;&#30456;&#27604;&#65292;&#36825;&#20123;&#27491;&#21017;&#21270;&#39033;&#33021;&#26356;&#22909;&#22320;&#25552;&#39640;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#36824;&#21457;&#29616;&#20887;&#20313;&#22312;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#20013;&#21457;&#25381;&#30528;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2308.04870</link><description>&lt;p&gt;
&#20351;&#29992;&#25345;&#20037;&#24615;&#26041;&#27861;&#21435;&#30456;&#20851;&#31070;&#32463;&#20803;
&lt;/p&gt;
&lt;p&gt;
Decorrelating neurons using persistence. (arXiv:2308.04870v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04870
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25345;&#20037;&#24615;&#26041;&#27861;&#21435;&#38500;&#31070;&#32463;&#20803;&#20043;&#38388;&#39640;&#30456;&#20851;&#24615;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#35745;&#31639;&#26368;&#23567;&#29983;&#25104;&#26641;&#30340;&#26435;&#37325;&#26469;&#26500;&#24314;&#27491;&#21017;&#21270;&#39033;&#65292;&#24182;&#36890;&#36807;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#27491;&#21017;&#21270;&#39033;&#30340;&#26377;&#25928;&#24615;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#24120;&#35265;&#30340;&#27491;&#21017;&#21270;&#39033;&#30456;&#27604;&#65292;&#36825;&#20123;&#27491;&#21017;&#21270;&#39033;&#33021;&#26356;&#22909;&#22320;&#25552;&#39640;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#36824;&#21457;&#29616;&#20887;&#20313;&#22312;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#20013;&#21457;&#25381;&#30528;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#21892;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#27867;&#21270;&#33021;&#21147;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#20943;&#23569;&#31070;&#32463;&#20803;&#20043;&#38388;&#30340;&#39640;&#30456;&#20851;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20174;&#19968;&#20010;&#32473;&#23450;&#32593;&#32476;&#30340;&#31070;&#32463;&#20803;&#65288;&#25110;&#20854;&#20013;&#19968;&#37096;&#20998;&#26679;&#26412;&#65289;&#26500;&#25104;&#30340;&#22242;&#20013;&#65292;&#35745;&#31639;&#26368;&#23567;&#29983;&#25104;&#26641;&#30340;&#26435;&#37325;&#26469;&#35745;&#31639;&#20004;&#20010;&#27491;&#21017;&#21270;&#39033;&#65292;&#32780;&#36793;&#19978;&#30340;&#26435;&#37325;&#26159;&#30456;&#20851;&#24615;&#30340;&#24046;&#24322;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#37327;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#27491;&#21017;&#21270;&#39033;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#34920;&#26126;&#23427;&#20204;&#20248;&#20110;&#24120;&#35265;&#30340;&#27491;&#21017;&#21270;&#39033;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#20165;&#20165;&#26368;&#23567;&#21270;&#31070;&#32463;&#20803;&#20043;&#38388;&#30340;&#25152;&#26377;&#30456;&#20851;&#24615;&#24471;&#21040;&#30340;&#20934;&#30830;&#29575;&#27604;&#25105;&#20204;&#30340;&#27491;&#21017;&#21270;&#39033;&#35201;&#20302;&#65292;&#36825;&#34920;&#26126;&#20887;&#20313;&#22312;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#20013;&#36215;&#21040;&#20102;&#37325;&#35201;&#20316;&#29992;&#65292;&#36825;&#19968;&#28857;&#22312;&#31070;&#32463;&#31185;&#23398;&#30340;&#19968;&#20123;&#30740;&#31350;&#20013;&#20063;&#26377;&#25152;&#35777;&#26126;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#25105;&#20204;&#27491;&#21017;&#21270;&#39033;&#30340;&#21487;&#24494;&#24615;&#65292;&#20174;&#32780;&#24320;&#21457;&#20102;&#31532;&#19968;&#20010;&#32771;&#34385;&#25972;&#20010;&#31070;&#32463;&#20803;&#38598;&#30340;&#22522;&#20110;&#25299;&#25169;&#25345;&#20037;&#24615;&#30340;&#26377;&#25928;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#24182;&#19988;&#21487;&#20197;&#24212;&#29992;&#20110;&#23454;&#38469;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel way to improve the generalisation capacity of deep learning models by reducing high correlations between neurons. For this, we present two regularisation terms computed from the weights of a minimum spanning tree of the clique whose vertices are the neurons of a given network (or a sample of those), where weights on edges are correlation dissimilarities. We provide an extensive set of experiments to validate the effectiveness of our terms, showing that they outperform popular ones. Also, we demonstrate that naive minimisation of all correlations between neurons obtains lower accuracies than our regularisation terms, suggesting that redundancies play a significant role in artificial neural networks, as evidenced by some studies in neuroscience for real networks. We include a proof of differentiability of our regularisers, thus developing the first effective topological persistence-based regularisation terms that consider the whole set of neurons and that can be applie
&lt;/p&gt;</description></item><item><title>Bandit&#21453;&#39304;&#19979;&#30340;&#22312;&#32447;&#22810;&#31867;&#23398;&#20064;&#30340;&#20851;&#38190;&#22312;&#20110;Bandit Littlestone&#32500;&#24230;&#30340;&#26377;&#38480;&#24615;&#65292;&#26080;&#35770;&#26631;&#31614;&#31354;&#38388;&#26159;&#21542;&#26080;&#30028;&#12290;</title><link>http://arxiv.org/abs/2308.04620</link><description>&lt;p&gt;
&#22810;&#31867;&#22312;&#32447;&#23398;&#20064;&#22312;Bandit&#21453;&#39304;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Multiclass Online Learnability under Bandit Feedback. (arXiv:2308.04620v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04620
&lt;/p&gt;
&lt;p&gt;
Bandit&#21453;&#39304;&#19979;&#30340;&#22312;&#32447;&#22810;&#31867;&#23398;&#20064;&#30340;&#20851;&#38190;&#22312;&#20110;Bandit Littlestone&#32500;&#24230;&#30340;&#26377;&#38480;&#24615;&#65292;&#26080;&#35770;&#26631;&#31614;&#31354;&#38388;&#26159;&#21542;&#26080;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;Bandit&#21453;&#39304;&#19979;&#30340;&#22810;&#31867;&#22312;&#32447;&#20998;&#31867;&#38382;&#39064;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;(daniely2013price)&#30340;&#32467;&#26524;&#65292;&#36890;&#36807;&#23637;&#31034;Bandit Littlestone&#32500;&#24230;&#30340;&#26377;&#38480;&#24615;&#26159;&#22810;&#31867;&#22312;&#32447;&#23398;&#20064;&#30340;&#24517;&#35201;&#19988;&#20805;&#20998;&#26465;&#20214;&#65292;&#21363;&#20351;&#26631;&#31614;&#31354;&#38388;&#26159;&#26080;&#30028;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34917;&#20805;&#20102;(hanneke2023multiclass)&#30340;&#26368;&#36817;&#24037;&#20316;&#65292;&#20182;&#20204;&#22312;&#26631;&#31614;&#31354;&#38388;&#26080;&#30028;&#30340;&#20840;&#20449;&#24687;&#35774;&#32622;&#20013;&#65292;&#23637;&#31034;&#20102;Littlestone&#32500;&#24230;&#21051;&#30011;&#20102;&#22312;&#32447;&#22810;&#31867;&#23398;&#20064;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study online multiclass classification under bandit feedback. We extend the results of (daniely2013price) by showing that the finiteness of the Bandit Littlestone dimension is necessary and sufficient for bandit online multiclass learnability even when the label space is unbounded. Our result complements the recent work by (hanneke2023multiclass) who show that the Littlestone dimension characterizes online multiclass learnability in the full-information setting when the label space is unbounded.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#20855;&#26377;&#26410;&#35266;&#27979;&#28151;&#28102;&#22240;&#32032;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#38382;&#39064;&#65292;&#22312;&#32467;&#26524;&#26159;&#30830;&#23450;&#24615;&#29983;&#25104;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21333;&#19968;&#20195;&#29702;&#21464;&#37327;&#30340;&#20869;&#26680;&#26041;&#27861;&#65292;&#36890;&#36807;&#20004;&#38454;&#27573;&#22238;&#24402;&#21644;&#26368;&#22823;&#30697;&#32422;&#26463;&#30340;&#26041;&#27861;&#21487;&#20197;&#19968;&#33268;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#25104;&#21151;&#24674;&#22797;&#20102;&#22240;&#26524;&#25928;&#24212;&#12290;</title><link>http://arxiv.org/abs/2308.04585</link><description>&lt;p&gt;
&#20915;&#23450;&#24615;&#28151;&#28102;&#19979;&#30340;&#20869;&#26680;&#21333;&#19968;&#20195;&#29702;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Kernel Single Proxy Control for Deterministic Confounding. (arXiv:2308.04585v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04585
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#20855;&#26377;&#26410;&#35266;&#27979;&#28151;&#28102;&#22240;&#32032;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#38382;&#39064;&#65292;&#22312;&#32467;&#26524;&#26159;&#30830;&#23450;&#24615;&#29983;&#25104;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21333;&#19968;&#20195;&#29702;&#21464;&#37327;&#30340;&#20869;&#26680;&#26041;&#27861;&#65292;&#36890;&#36807;&#20004;&#38454;&#27573;&#22238;&#24402;&#21644;&#26368;&#22823;&#30697;&#32422;&#26463;&#30340;&#26041;&#27861;&#21487;&#20197;&#19968;&#33268;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#25104;&#21151;&#24674;&#22797;&#20102;&#22240;&#26524;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20855;&#26377;&#26410;&#35266;&#27979;&#28151;&#28102;&#22240;&#32032;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#38382;&#39064;&#65292;&#20854;&#20013;&#25105;&#20204;&#35266;&#27979;&#21040;&#19982;&#28151;&#28102;&#22240;&#32032;&#30456;&#20851;&#30340;&#20195;&#29702;&#21464;&#37327;&#12290;&#23613;&#31649;&#20195;&#29702;&#22240;&#26524;&#23398;&#20064;&#65288;PCL&#65289;&#20351;&#29992;&#20004;&#20010;&#20195;&#29702;&#21464;&#37327;&#26469;&#24674;&#22797;&#30495;&#23454;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#25105;&#20204;&#35777;&#26126;&#22914;&#26524;&#32467;&#26524;&#26159;&#30830;&#23450;&#24615;&#29983;&#25104;&#30340;&#65292;&#21017;&#20351;&#29992;&#21333;&#20010;&#20195;&#29702;&#21464;&#37327;&#23601;&#36275;&#20197;&#36827;&#34892;&#22240;&#26524;&#20272;&#35745;&#65292;&#24182;&#27010;&#25324;&#20102;&#25511;&#21046;&#32467;&#26524;&#26657;&#20934;&#27861;&#65288;COCA&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#20869;&#26680;&#30340;&#26041;&#27861;&#65306;&#19968;&#31181;&#22522;&#20110;&#20004;&#38454;&#27573;&#22238;&#24402;&#26041;&#27861;&#65292;&#21478;&#19968;&#31181;&#22522;&#20110;&#26368;&#22823;&#30697;&#32422;&#26463;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#21487;&#20197;&#19968;&#33268;&#22320;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#36890;&#36807;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#23454;&#35777;&#23454;&#39564;&#25104;&#21151;&#22320;&#24674;&#22797;&#20102;&#22240;&#26524;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of causal effect estimation with an unobserved confounder, where we observe a proxy variable that is associated with the confounder. Although Proxy Causal Learning (PCL) uses two proxy variables to recover the true causal effect, we show that a single proxy variable is sufficient for causal estimation if the outcome is generated deterministically, generalizing Control Outcome Calibration Approach (COCA). We propose two kernel-based methods for this setting: the first based on the two-stage regression approach, and the second based on a maximum moment restriction approach. We prove that both approaches can consistently estimate the causal effect, and we empirically demonstrate that we can successfully recover the causal effect on a synthetic dataset.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20855;&#26377;&#35889;&#27491;&#21017;&#21270;&#30340;&#26680;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#38750;&#27431;&#20960;&#37324;&#24471;&#25968;&#25454;&#12290;&#30456;&#27604;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#26412;&#26041;&#27861;&#22312;&#36873;&#25321;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#21442;&#25968;&#26102;&#33021;&#36798;&#21040;&#26368;&#23567;&#21270;&#26368;&#22823;&#39118;&#38505;&#12290;&#21516;&#26102;&#65292;&#26412;&#26041;&#27861;&#36824;&#20811;&#26381;&#20102;&#20043;&#21069;&#26041;&#27861;&#23545;&#22343;&#20540;&#20803;&#32032;&#20026;&#38646;&#21644;&#31215;&#20998;&#25805;&#20316;&#31526;&#29305;&#24449;&#20989;&#25968;&#22343;&#21248;&#26377;&#30028;&#24615;&#26465;&#20214;&#30340;&#38480;&#21046;&#65292;&#24182;&#19988;&#33021;&#22815;&#35745;&#31639;&#26356;&#22810;&#31181;&#31867;&#30340;&#26680;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2308.04561</link><description>&lt;p&gt;
&#20855;&#26377;&#35889;&#27491;&#21017;&#21270;&#30340;&#26680;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Spectral Regularized Kernel Goodness-of-Fit Tests. (arXiv:2308.04561v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04561
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20855;&#26377;&#35889;&#27491;&#21017;&#21270;&#30340;&#26680;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#38750;&#27431;&#20960;&#37324;&#24471;&#25968;&#25454;&#12290;&#30456;&#27604;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#26412;&#26041;&#27861;&#22312;&#36873;&#25321;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#21442;&#25968;&#26102;&#33021;&#36798;&#21040;&#26368;&#23567;&#21270;&#26368;&#22823;&#39118;&#38505;&#12290;&#21516;&#26102;&#65292;&#26412;&#26041;&#27861;&#36824;&#20811;&#26381;&#20102;&#20043;&#21069;&#26041;&#27861;&#23545;&#22343;&#20540;&#20803;&#32032;&#20026;&#38646;&#21644;&#31215;&#20998;&#25805;&#20316;&#31526;&#29305;&#24449;&#20989;&#25968;&#22343;&#21248;&#26377;&#30028;&#24615;&#26465;&#20214;&#30340;&#38480;&#21046;&#65292;&#24182;&#19988;&#33021;&#22815;&#35745;&#31639;&#26356;&#22810;&#31181;&#31867;&#30340;&#26680;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#24212;&#29992;&#20013;&#65292;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;(MMD)&#22240;&#20854;&#22788;&#29702;&#38750;&#27431;&#20960;&#37324;&#24471;&#25968;&#25454;&#30340;&#33021;&#21147;&#32780;&#33719;&#24471;&#20102;&#24456;&#22810;&#25104;&#21151;&#65292;&#21253;&#25324;&#38750;&#21442;&#25968;&#20551;&#35774;&#26816;&#39564;&#12290;&#26368;&#36817;&#65292;Balasubramanian&#31561;&#20154;(2021)&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#22522;&#20110;MMD&#30340;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#22312;&#36866;&#24403;&#36873;&#25321;&#27491;&#21017;&#21270;&#21442;&#25968;&#26102;&#65292;&#24182;&#19981;&#26159;&#26368;&#23567;&#21270;&#26368;&#22823;&#39118;&#38505;&#65292;&#32780;&#20854;Tikhonov&#27491;&#21017;&#21270;&#29256;&#26412;&#21017;&#26159;&#26368;&#23567;&#21270;&#26368;&#22823;&#39118;&#38505;&#30340;&#12290;&#28982;&#32780;&#65292;Balasubramanian&#31561;&#20154;(2021)&#30340;&#32467;&#26524;&#26159;&#22312;&#22343;&#20540;&#20803;&#32032;&#20026;&#38646;&#30340;&#38480;&#21046;&#24615;&#20551;&#35774;&#21644;&#31215;&#20998;&#25805;&#20316;&#31526;&#29305;&#24449;&#20989;&#25968;&#30340;&#22343;&#21248;&#26377;&#30028;&#24615;&#26465;&#20214;&#19979;&#33719;&#24471;&#30340;&#12290;&#27492;&#22806;&#65292;Balasubramanian&#31561;&#20154;(2021)&#25552;&#20986;&#30340;&#26816;&#39564;&#22312;&#35768;&#22810;&#26680;&#20989;&#25968;&#20013;&#26159;&#19981;&#21487;&#35745;&#31639;&#30340;&#65292;&#22240;&#27492;&#19981;&#23454;&#29992;&#12290;&#26412;&#25991;&#35299;&#20915;&#20102;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#23558;&#32467;&#26524;&#25512;&#24191;&#21040;&#21253;&#25324;Tikhonov&#27491;&#21017;&#21270;&#22312;&#20869;&#30340;&#19968;&#33324;&#35889;&#27491;&#21017;&#21270;&#26041;&#27861;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Maximum mean discrepancy (MMD) has enjoyed a lot of success in many machine learning and statistical applications, including non-parametric hypothesis testing, because of its ability to handle non-Euclidean data. Recently, it has been demonstrated in Balasubramanian et al.(2021) that the goodness-of-fit test based on MMD is not minimax optimal while a Tikhonov regularized version of it is, for an appropriate choice of the regularization parameter. However, the results in Balasubramanian et al. (2021) are obtained under the restrictive assumptions of the mean element being zero, and the uniform boundedness condition on the eigenfunctions of the integral operator. Moreover, the test proposed in Balasubramanian et al. (2021) is not practical as it is not computable for many kernels. In this paper, we address these shortcomings and extend the results to general spectral regularizers that include Tikhonov regularization.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25209;&#21028;&#24615;&#22320;&#23457;&#26597;&#20102;&#29289;&#29702;&#39537;&#21160;&#30340;&#26426;&#22120;&#23398;&#20064;&#22312;&#22320;&#19979;&#33021;&#28304;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;&#65292;&#24378;&#35843;&#20102;PIML&#22312;&#22320;&#38663;&#24212;&#29992;&#12289;&#27833;&#34255;&#27169;&#25311;&#21644;&#27833;&#27668;&#29983;&#20135;&#31561;&#20219;&#21153;&#20013;&#30340;&#25104;&#21151;&#21033;&#29992;&#12290;</title><link>http://arxiv.org/abs/2308.04457</link><description>&lt;p&gt;
&#23545;&#22320;&#19979;&#33021;&#28304;&#31995;&#32479;&#20013;&#29289;&#29702;&#39537;&#21160;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#30340;&#25209;&#21028;&#24615;&#35780;&#35770;
&lt;/p&gt;
&lt;p&gt;
A Critical Review of Physics-Informed Machine Learning Applications in Subsurface Energy Systems. (arXiv:2308.04457v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04457
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25209;&#21028;&#24615;&#22320;&#23457;&#26597;&#20102;&#29289;&#29702;&#39537;&#21160;&#30340;&#26426;&#22120;&#23398;&#20064;&#22312;&#22320;&#19979;&#33021;&#28304;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;&#65292;&#24378;&#35843;&#20102;PIML&#22312;&#22320;&#38663;&#24212;&#29992;&#12289;&#27833;&#34255;&#27169;&#25311;&#21644;&#27833;&#27668;&#29983;&#20135;&#31561;&#20219;&#21153;&#20013;&#30340;&#25104;&#21151;&#21033;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#24050;&#32463;&#25104;&#20026;&#21508;&#20010;&#39046;&#22495;&#30340;&#24378;&#22823;&#24037;&#20855;&#65292;&#21253;&#25324;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#35821;&#38899;&#35782;&#21035;&#12290;&#23427;&#21487;&#20197;&#25581;&#31034;&#22823;&#25968;&#25454;&#38598;&#20013;&#38544;&#34255;&#30340;&#27169;&#24335;&#65292;&#24182;&#25581;&#31034;&#26080;&#19982;&#20262;&#27604;&#30340;&#27934;&#23519;&#21147;&#65292;&#20174;&#32780;&#38761;&#26032;&#35768;&#22810;&#34892;&#19994;&#21644;&#23398;&#31185;&#12290;&#28982;&#32780;&#65292;&#26426;&#22120;&#21644;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#32570;&#20047;&#21487;&#35299;&#37322;&#24615;&#21644;&#26377;&#38480;&#30340;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#65292;&#29305;&#21035;&#26159;&#22312;&#29289;&#29702;&#21644;&#24037;&#31243;&#31561;&#24212;&#29992;&#20013;&#12290;&#30456;&#21453;&#65292;&#29289;&#29702;&#39537;&#21160;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;PIML&#65289;&#25216;&#26415;&#23558;&#29289;&#29702;&#21407;&#29702;&#34701;&#20837;&#21040;&#25968;&#25454;&#39537;&#21160;&#27169;&#22411;&#20013;&#12290;&#36890;&#36807;&#23558;&#28145;&#24230;&#23398;&#20064;&#19982;&#39046;&#22495;&#30693;&#35782;&#30456;&#32467;&#21512;&#65292;PIML&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#36981;&#23432;&#27835;&#29702;&#29289;&#29702;&#23450;&#24459;&#65292;&#20197;&#21450;&#21487;&#35299;&#37322;&#24615;&#12290;&#26412;&#25991;&#20840;&#38754;&#22238;&#39038;&#20102;&#19982;&#22320;&#19979;&#33021;&#28304;&#31995;&#32479;&#30456;&#20851;&#30340;PIML&#24212;&#29992;&#65292;&#20027;&#35201;&#38598;&#20013;&#22312;&#30707;&#27833;&#21644;&#22825;&#28982;&#27668;&#34892;&#19994;&#12290;&#22238;&#39038;&#31361;&#20986;&#20102;PIML&#22312;&#22320;&#38663;&#24212;&#29992;&#12289;&#27833;&#34255;&#27169;&#25311;&#21644;&#27833;&#27668;&#29983;&#20135;&#31561;&#20219;&#21153;&#20013;&#30340;&#25104;&#21151;&#21033;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning has emerged as a powerful tool in various fields, including computer vision, natural language processing, and speech recognition. It can unravel hidden patterns within large data sets and reveal unparalleled insights, revolutionizing many industries and disciplines. However, machine and deep learning models lack interpretability and limited domain-specific knowledge, especially in applications such as physics and engineering. Alternatively, physics-informed machine learning (PIML) techniques integrate physics principles into data-driven models. By combining deep learning with domain knowledge, PIML improves the generalization of the model, abidance by the governing physical laws, and interpretability. This paper comprehensively reviews PIML applications related to subsurface energy systems, mainly in the oil and gas industry. The review highlights the successful utilization of PIML for tasks such as seismic applications, reservoir simulation, hydrocarbons production fo
&lt;/p&gt;</description></item><item><title>SLEM&#26159;&#19968;&#31181;&#36335;&#24452;&#24314;&#27169;&#25216;&#26415;&#65292;&#36890;&#36807;&#38598;&#25104;&#26426;&#22120;&#23398;&#20064;&#36229;&#32423;&#23398;&#20064;&#32773;&#65292;&#23454;&#29616;&#20102;&#19968;&#33268;&#19988;&#26080;&#20559;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#65292;&#24182;&#22312;&#22788;&#29702;&#38750;&#32447;&#24615;&#20851;&#31995;&#26102;&#36229;&#36807;&#20102;&#20256;&#32479;&#30340;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2308.04365</link><description>&lt;p&gt;
SLEM&#65306;&#26426;&#22120;&#23398;&#20064;&#29992;&#20110;&#36335;&#24452;&#24314;&#27169;&#21644;&#22240;&#26524;&#25512;&#26029;&#30340;&#36229;&#32423;&#23398;&#20064;&#32773;&#26041;&#31243;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling. (arXiv:2308.04365v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04365
&lt;/p&gt;
&lt;p&gt;
SLEM&#26159;&#19968;&#31181;&#36335;&#24452;&#24314;&#27169;&#25216;&#26415;&#65292;&#36890;&#36807;&#38598;&#25104;&#26426;&#22120;&#23398;&#20064;&#36229;&#32423;&#23398;&#20064;&#32773;&#65292;&#23454;&#29616;&#20102;&#19968;&#33268;&#19988;&#26080;&#20559;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#65292;&#24182;&#22312;&#22788;&#29702;&#38750;&#32447;&#24615;&#20851;&#31995;&#26102;&#36229;&#36807;&#20102;&#20256;&#32479;&#30340;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#25512;&#26029;&#26159;&#31185;&#23398;&#30340;&#20851;&#38190;&#30446;&#26631;&#65292;&#20351;&#30740;&#31350;&#20154;&#21592;&#33021;&#22815;&#36890;&#36807;&#35266;&#23519;&#25968;&#25454;&#24471;&#20986;&#20851;&#20110;&#23545;&#20551;&#23450;&#24178;&#39044;&#30340;&#39044;&#27979;&#30340;&#26377;&#24847;&#20041;&#30340;&#32467;&#35770;&#12290;&#36335;&#24452;&#27169;&#22411;&#12289;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;(SEMs)&#20197;&#21450;&#26356;&#19968;&#33324;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;(DAGs)&#33021;&#22815;&#26126;&#30830;&#22320;&#25351;&#23450;&#20851;&#20110;&#29616;&#35937;&#32972;&#21518;&#30340;&#22240;&#26524;&#32467;&#26500;&#30340;&#20551;&#35774;&#12290;&#19982;DAGs&#19981;&#21516;&#65292;SEMs&#20551;&#35774;&#32447;&#24615;&#20851;&#31995;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#20989;&#25968;&#38169;&#35823;&#35268;&#33539;&#65292;&#20174;&#32780;&#38459;&#30861;&#30740;&#31350;&#20154;&#21592;&#36827;&#34892;&#21487;&#38752;&#30340;&#25928;&#26524;&#22823;&#23567;&#20272;&#35745;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36229;&#32423;&#23398;&#20064;&#32773;&#26041;&#31243;&#27169;&#22411;&#65288;SLEM&#65289;&#65292;&#19968;&#31181;&#38598;&#25104;&#20102;&#26426;&#22120;&#23398;&#20064;&#36229;&#32423;&#23398;&#20064;&#32773;&#38598;&#25104;&#30340;&#36335;&#24452;&#24314;&#27169;&#25216;&#26415;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;SLEM&#33021;&#22815;&#25552;&#20379;&#19968;&#33268;&#19988;&#26080;&#20559;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#65292;&#22312;&#19982;SEMs&#36827;&#34892;&#32447;&#24615;&#27169;&#22411;&#27604;&#36739;&#26102;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#65292;&#24182;&#19988;&#22312;&#22788;&#29702;&#38750;&#32447;&#24615;&#20851;&#31995;&#26102;&#20248;&#20110;SEMs&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal inference is a crucial goal of science, enabling researchers to arrive at meaningful conclusions regarding the predictions of hypothetical interventions using observational data. Path models, Structural Equation Models (SEMs), and, more generally, Directed Acyclic Graphs (DAGs), provide a means to unambiguously specify assumptions regarding the causal structure underlying a phenomenon. Unlike DAGs, which make very few assumptions about the functional and parametric form, SEM assumes linearity. This can result in functional misspecification which prevents researchers from undertaking reliable effect size estimation. In contrast, we propose Super Learner Equation Modeling, a path modeling technique integrating machine learning Super Learner ensembles. We empirically demonstrate its ability to provide consistent and unbiased estimates of causal effects, its competitive performance for linear models when compared with SEM, and highlight its superiority over SEM when dealing with non
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20855;&#26377;&#22823;&#21160;&#20316;&#31354;&#38388;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#30340;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#65288;MDR&#65289;&#12290;&#19982;&#29616;&#26377;&#30340;&#22522;&#20934;&#20272;&#35745;&#22120;&#30456;&#27604;&#65292;MDR&#33021;&#22815;&#22312;&#20943;&#23567;&#26041;&#24046;&#30340;&#21516;&#26102;&#20445;&#25345;&#26080;&#20559;&#24615;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#23454;&#20102;MDR&#30456;&#23545;&#20110;&#29616;&#26377;&#20272;&#35745;&#22120;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.03443</link><description>&lt;p&gt;
&#29992;&#20110;&#20855;&#26377;&#22823;&#21160;&#20316;&#31354;&#38388;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#30340;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
Doubly Robust Estimator for Off-Policy Evaluation with Large Action Spaces. (arXiv:2308.03443v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03443
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20855;&#26377;&#22823;&#21160;&#20316;&#31354;&#38388;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#30340;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#65288;MDR&#65289;&#12290;&#19982;&#29616;&#26377;&#30340;&#22522;&#20934;&#20272;&#35745;&#22120;&#30456;&#27604;&#65292;MDR&#33021;&#22815;&#22312;&#20943;&#23567;&#26041;&#24046;&#30340;&#21516;&#26102;&#20445;&#25345;&#26080;&#20559;&#24615;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#23454;&#20102;MDR&#30456;&#23545;&#20110;&#29616;&#26377;&#20272;&#35745;&#22120;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20855;&#26377;&#22823;&#21160;&#20316;&#31354;&#38388;&#30340;&#32972;&#26223;&#19979;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#65288;OPE&#65289;&#12290;&#29616;&#26377;&#30340;&#22522;&#20934;&#20272;&#35745;&#22120;&#23384;&#22312;&#20005;&#37325;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#25240;&#34935;&#38382;&#39064;&#12290;&#21442;&#25968;&#21270;&#26041;&#27861;&#30001;&#20110;&#24456;&#38590;&#30830;&#23450;&#27491;&#30830;&#30340;&#27169;&#22411;&#32780;&#23548;&#33268;&#20559;&#24046;&#65292;&#32780;&#37325;&#35201;&#24615;&#21152;&#26435;&#26041;&#27861;&#30001;&#20110;&#26041;&#24046;&#32780;&#20135;&#29983;&#38382;&#39064;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#21028;&#21035;&#24335;&#30340;&#19981;&#33391;&#34892;&#20026;&#25233;&#21046;&#22120;&#65288;MIPS&#65289;&#26469;&#36890;&#36807;&#23545;&#21160;&#20316;&#30340;&#23884;&#20837;&#26469;&#20943;&#23567;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#12290;&#20026;&#20102;&#20351;&#20272;&#35745;&#22120;&#26356;&#20934;&#30830;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;MIPS&#30340;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#8212;&#8212;&#36793;&#38469;&#21270;&#21452;&#37325;&#31283;&#20581;&#65288;MDR&#65289;&#20272;&#35745;&#22120;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#22312;&#27604;MIPS&#26356;&#24369;&#30340;&#20551;&#35774;&#19979;&#26159;&#26080;&#20559;&#30340;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#23545;IPS&#30340;&#26041;&#24046;&#20943;&#23567;&#65292;&#36825;&#26159;MIPS&#30340;&#20027;&#35201;&#20248;&#21183;&#12290;&#32463;&#39564;&#23454;&#39564;&#35777;&#23454;&#20102;MDR&#30456;&#23545;&#20110;&#29616;&#26377;&#20272;&#35745;&#22120;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study Off-Policy Evaluation (OPE) in contextual bandit settings with large action spaces. The benchmark estimators suffer from severe bias and variance tradeoffs. Parametric approaches suffer from bias due to difficulty specifying the correct model, whereas ones with importance weight suffer from variance. To overcome these limitations, Marginalized Inverse Propensity Scoring (MIPS) was proposed to mitigate the estimator's variance via embeddings of an action. To make the estimator more accurate, we propose the doubly robust estimator of MIPS called the Marginalized Doubly Robust (MDR) estimator. Theoretical analysis shows that the proposed estimator is unbiased under weaker assumptions than MIPS while maintaining variance reduction against IPS, which was the main advantage of MIPS. The empirical experiment verifies the supremacy of MDR against existing estimators.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#29289;&#29702;&#20449;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;(PINNs)&#35299;&#20915;&#39640;&#32500;&#24230;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;(PDEs)&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#25910;&#25947;&#24615;&#21644;&#20854;&#20182;&#26399;&#26395;&#23646;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.12306</link><description>&lt;p&gt;
&#29992;&#29289;&#29702;&#20449;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;&#35299;&#20915;&#32500;&#24230;&#35781;&#21650;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Tackling the Curse of Dimensionality with Physics-Informed Neural Networks. (arXiv:2307.12306v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12306
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#29289;&#29702;&#20449;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;(PINNs)&#35299;&#20915;&#39640;&#32500;&#24230;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;(PDEs)&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#25910;&#25947;&#24615;&#21644;&#20854;&#20182;&#26399;&#26395;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32500;&#24230;&#35781;&#21650;(CoD)&#38543;&#30528;&#32500;&#24230;&#30340;&#22686;&#21152;&#65292;&#20197;&#25351;&#25968;&#32423;&#22686;&#38271;&#30340;&#35745;&#31639;&#25104;&#26412;&#26469;&#26497;&#24230;&#31246;&#36153;&#35745;&#31639;&#36164;&#28304;&#12290;&#36825;&#22312;&#35299;&#20915;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;(PDEs)&#20013;&#38754;&#20020;&#26497;&#22823;&#25361;&#25112;&#65292;&#27491;&#22914;Richard Bellman&#22312;60&#24180;&#21069;&#39318;&#27425;&#25351;&#20986;&#30340;&#37027;&#26679;&#12290;&#23613;&#31649;&#36817;&#24180;&#26469;&#22312;&#39640;&#32500;&#24230;&#19978;&#25968;&#20540;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;(PDEs)&#21462;&#24471;&#20102;&#19968;&#20123;&#25104;&#21151;&#65292;&#20294;&#36825;&#26679;&#30340;&#35745;&#31639;&#20195;&#20215;&#36807;&#39640;&#65292;&#32780;&#23558;&#19968;&#33324;&#38750;&#32447;&#24615;PDEs&#25193;&#23637;&#21040;&#39640;&#32500;&#24230;&#20174;&#26410;&#23454;&#29616;&#36807;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#23558;&#29289;&#29702;&#20449;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;(PINNs)&#25193;&#23637;&#21040;&#35299;&#20915;&#20219;&#24847;&#39640;&#32500;PDEs&#12290;&#35813;&#26032;&#26041;&#27861;&#31216;&#20026;&#38543;&#26426;&#32500;&#24230;&#26799;&#24230;&#19979;&#38477;(SDGD)&#65292;&#23558;PDE&#30340;&#26799;&#24230;&#20998;&#35299;&#20026;&#19982;&#19981;&#21516;&#32500;&#24230;&#23545;&#24212;&#30340;&#37096;&#20998;&#65292;&#24182;&#22312;&#35757;&#32451;PINNs&#30340;&#27599;&#27425;&#36845;&#20195;&#20013;&#38543;&#26426;&#36873;&#25321;&#36825;&#20123;&#32500;&#24230;&#37096;&#20998;&#30340;&#23376;&#38598;&#36827;&#34892;&#37319;&#26679;&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#25910;&#25947;&#20445;&#35777;&#21644;&#20854;&#20182;&#26399;&#26395;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The curse-of-dimensionality (CoD) taxes computational resources heavily with exponentially increasing computational cost as the dimension increases. This poses great challenges in solving high-dimensional PDEs as Richard Bellman first pointed out over 60 years ago. While there has been some recent success in solving numerically partial differential equations (PDEs) in high dimensions, such computations are prohibitively expensive, and true scaling of general nonlinear PDEs to high dimensions has never been achieved. In this paper, we develop a new method of scaling up physics-informed neural networks (PINNs) to solve arbitrary high-dimensional PDEs. The new method, called Stochastic Dimension Gradient Descent (SDGD), decomposes a gradient of PDEs into pieces corresponding to different dimensions and samples randomly a subset of these dimensional pieces in each iteration of training PINNs. We theoretically prove the convergence guarantee and other desired properties of the proposed meth
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#40654;&#26364;&#23376;&#31354;&#38388;&#19979;&#38477;&#31639;&#27861;&#30340;&#23545;&#31216;&#27491;&#23450;&#27969;&#24418;&#19978;&#30340;&#20989;&#25968;&#26368;&#23567;&#21270;&#26041;&#27861;&#65292;&#20854;&#20855;&#26377;&#20302;&#22797;&#26434;&#24230;&#21644;&#36991;&#20813;&#26114;&#36149;&#30697;&#38453;&#25805;&#20316;&#21644;&#35745;&#31639;&#40654;&#26364;&#26799;&#24230;&#30340;&#20248;&#28857;&#12290;</title><link>http://arxiv.org/abs/2305.02041</link><description>&lt;p&gt;
&#23545;&#31216;&#27491;&#23450;&#27969;&#24418;&#19978;&#20302;&#22797;&#26434;&#24230;&#30340;&#23376;&#31354;&#38388;&#19979;&#38477;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Low-complexity subspace-descent over symmetric positive definite manifold. (arXiv:2305.02041v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02041
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#40654;&#26364;&#23376;&#31354;&#38388;&#19979;&#38477;&#31639;&#27861;&#30340;&#23545;&#31216;&#27491;&#23450;&#27969;&#24418;&#19978;&#30340;&#20989;&#25968;&#26368;&#23567;&#21270;&#26041;&#27861;&#65292;&#20854;&#20855;&#26377;&#20302;&#22797;&#26434;&#24230;&#21644;&#36991;&#20813;&#26114;&#36149;&#30697;&#38453;&#25805;&#20316;&#21644;&#35745;&#31639;&#40654;&#26364;&#26799;&#24230;&#30340;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20302;&#22797;&#26434;&#24230;&#30340;&#40654;&#26364;&#23376;&#31354;&#38388;&#19979;&#38477;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#23545;&#31216;&#27491;&#23450;&#65288;SPD&#65289;&#27969;&#24418;&#19978;&#23545;&#20989;&#25968;&#36827;&#34892;&#26368;&#23567;&#21270;&#12290;&#19982;&#29616;&#26377;&#30340;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#21464;&#20307;&#19981;&#21516;&#30340;&#26159;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21033;&#29992; carefully chosen &#30340;&#23376;&#31354;&#38388;&#65292;&#20351;&#24471;&#26356;&#26032;&#21487;&#20197;&#20889;&#25104;&#36845;&#20195;&#30340; Cholesky &#22240;&#23376;&#21644;&#19968;&#20010;&#31232;&#30095;&#30697;&#38453;&#30340;&#20056;&#31215;&#24418;&#24335;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#26356;&#26032;&#36991;&#20813;&#20102;&#26114;&#36149;&#30340;&#30697;&#38453;&#25805;&#20316;&#65292;&#22914;&#30697;&#38453;&#25351;&#25968;&#21644;&#23494;&#38598;&#30697;&#38453;&#20056;&#27861;&#65292;&#36825;&#20123;&#25805;&#20316;&#36890;&#24120;&#22312;&#20960;&#20046;&#25152;&#26377;&#20854;&#20182; Riemannian &#20248;&#21270;&#31639;&#27861;&#20013;&#37117;&#26159;&#24517;&#38656;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work puts forth low-complexity Riemannian subspace descent algorithms for the minimization of functions over the symmetric positive definite (SPD) manifold. Different from the existing Riemannian gradient descent variants, the proposed approach utilizes carefully chosen subspaces that allow the update to be written as a product of the Cholesky factor of the iterate and a sparse matrix. The resulting updates avoid the costly matrix operations like matrix exponentiation and dense matrix multiplication, which are generally required in almost all other Riemannian optimization algorithms on SPD manifold. We further identify a broad class of functions, arising in diverse applications, such as kernel matrix learning, covariance estimation of Gaussian distributions, maximum likelihood parameter estimation of elliptically contoured distributions, and parameter estimation in Gaussian mixture model problems, over which the Riemannian gradients can be calculated efficiently. The proposed uni-
&lt;/p&gt;</description></item><item><title>TiDE&#26159;&#19968;&#31181;&#22522;&#20110;MLP&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#65292;&#29992;&#20110;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#12290;&#23427;&#26082;&#20855;&#22791;&#32447;&#24615;&#27169;&#22411;&#30340;&#31616;&#21333;&#24615;&#21644;&#36895;&#24230;&#65292;&#21448;&#33021;&#22788;&#29702;&#21327;&#21464;&#37327;&#21644;&#38750;&#32447;&#24615;&#20381;&#36182;&#65292;&#30456;&#36739;&#20110;&#26368;&#20339;&#30340;Transformer&#27169;&#22411;&#65292;&#36895;&#24230;&#24555;5-10&#20493;&#12290;</title><link>http://arxiv.org/abs/2304.08424</link><description>&lt;p&gt;
&#29992;TiDE&#36827;&#34892;&#38271;&#26399;&#39044;&#27979;&#65306;&#26102;&#38388;&#24207;&#21015;&#31264;&#23494;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Long-term Forecasting with TiDE: Time-series Dense Encoder. (arXiv:2304.08424v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08424
&lt;/p&gt;
&lt;p&gt;
TiDE&#26159;&#19968;&#31181;&#22522;&#20110;MLP&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#65292;&#29992;&#20110;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#12290;&#23427;&#26082;&#20855;&#22791;&#32447;&#24615;&#27169;&#22411;&#30340;&#31616;&#21333;&#24615;&#21644;&#36895;&#24230;&#65292;&#21448;&#33021;&#22788;&#29702;&#21327;&#21464;&#37327;&#21644;&#38750;&#32447;&#24615;&#20381;&#36182;&#65292;&#30456;&#36739;&#20110;&#26368;&#20339;&#30340;Transformer&#27169;&#22411;&#65292;&#36895;&#24230;&#24555;5-10&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#30456;&#27604;&#20110;&#22522;&#20110;Transformer&#30340;&#26041;&#27861;&#65292;&#31616;&#21333;&#30340;&#32447;&#24615;&#27169;&#22411;&#22312;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#34920;&#29616;&#26356;&#22909;&#12290;&#37492;&#20110;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#23618;&#24863;&#30693;&#26426;(MLP)&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#65292;&#21363;&#26102;&#38388;&#24207;&#21015;&#31264;&#23494;&#32534;&#30721;&#22120;(TiDE)&#65292;&#29992;&#20110;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#12290;&#23427;&#26082;&#20139;&#26377;&#32447;&#24615;&#27169;&#22411;&#30340;&#31616;&#21333;&#24615;&#21644;&#36895;&#24230;&#65292;&#21448;&#33021;&#22788;&#29702;&#21327;&#21464;&#37327;&#21644;&#38750;&#32447;&#24615;&#20381;&#36182;&#12290;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#27169;&#22411;&#30340;&#26368;&#31616;&#32447;&#24615;&#31867;&#27604;&#22312;&#19968;&#20123;&#20551;&#35774;&#19979;&#21487;&#20197;&#36798;&#21040;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;(LDS)&#30340;&#36817;&#20046;&#26368;&#20248;&#35823;&#24046;&#29575;&#12290;&#23454;&#35777;&#19978;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#22312;&#27969;&#34892;&#30340;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#22522;&#20934;&#27979;&#35797;&#20013;&#21305;&#37197;&#25110;&#32988;&#36807;&#20197;&#21069;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#27604;&#26368;&#20339;&#30340;&#22522;&#20110;Transformer&#30340;&#27169;&#22411;&#24555;5-10&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work has shown that simple linear models can outperform several Transformer based approaches in long term time-series forecasting. Motivated by this, we propose a Multi-layer Perceptron (MLP) based encoder-decoder model, Time-series Dense Encoder (TiDE), for long-term time-series forecasting that enjoys the simplicity and speed of linear models while also being able to handle covariates and non-linear dependencies. Theoretically, we prove that the simplest linear analogue of our model can achieve near optimal error rate for linear dynamical systems (LDS) under some assumptions. Empirically, we show that our method can match or outperform prior approaches on popular long-term time-series forecasting benchmarks while being 5-10x faster than the best Transformer based model.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#31574;&#30053;&#30340;&#37327;&#21270;&#38598;&#21453;&#28436;&#26041;&#27861;&#65292;&#36890;&#36807;&#39640;&#26031;&#36807;&#31243;&#24314;&#27169;&#21644;&#36880;&#27493;&#19981;&#30830;&#23450;&#24615;&#20943;&#23569;&#21407;&#29702;&#65292;&#39034;&#24207;&#36873;&#25321;&#35780;&#20272;&#20989;&#25968;&#30340;&#28857;&#65292;&#20174;&#32780;&#26377;&#25928;&#36817;&#20284;&#24863;&#20852;&#36259;&#30340;&#38598;&#21512;&#12290;</title><link>http://arxiv.org/abs/2211.01008</link><description>&lt;p&gt;
&#22522;&#20110;&#36125;&#21494;&#26031;&#24207;&#36143;&#35774;&#35745;&#30340;&#35745;&#31639;&#26426;&#23454;&#39564;&#37327;&#21270;&#38598;&#21453;&#28436;
&lt;/p&gt;
&lt;p&gt;
Bayesian sequential design of computer experiments for quantile set inversion. (arXiv:2211.01008v2 [stat.ML] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.01008
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#31574;&#30053;&#30340;&#37327;&#21270;&#38598;&#21453;&#28436;&#26041;&#27861;&#65292;&#36890;&#36807;&#39640;&#26031;&#36807;&#31243;&#24314;&#27169;&#21644;&#36880;&#27493;&#19981;&#30830;&#23450;&#24615;&#20943;&#23569;&#21407;&#29702;&#65292;&#39034;&#24207;&#36873;&#25321;&#35780;&#20272;&#20989;&#25968;&#30340;&#28857;&#65292;&#20174;&#32780;&#26377;&#25928;&#36817;&#20284;&#24863;&#20852;&#36259;&#30340;&#38598;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;&#26410;&#30693;&#30340;&#22810;&#20803;&#20989;&#25968;&#65292;&#23427;&#20195;&#34920;&#30528;&#19968;&#20010;&#31995;&#32479;&#65292;&#22914;&#19968;&#20010;&#22797;&#26434;&#30340;&#25968;&#20540;&#27169;&#25311;&#22120;&#65292;&#21516;&#26102;&#20855;&#26377;&#30830;&#23450;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#30340;&#36755;&#20837;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20272;&#35745;&#30830;&#23450;&#24615;&#36755;&#20837;&#38598;&#65292;&#36825;&#20123;&#36755;&#20837;&#23548;&#33268;&#30340;&#36755;&#20986;&#65288;&#23601;&#19981;&#30830;&#23450;&#24615;&#36755;&#20837;&#30340;&#20998;&#24067;&#32780;&#35328;&#65289;&#23646;&#20110;&#32473;&#23450;&#38598;&#21512;&#30340;&#27010;&#29575;&#23567;&#20110;&#32473;&#23450;&#38408;&#20540;&#12290;&#36825;&#20010;&#38382;&#39064;&#34987;&#31216;&#20026;&#37327;&#21270;&#38598;&#21453;&#28436;&#65288;QSI&#65289;&#65292;&#20363;&#22914;&#22312;&#31283;&#20581;&#65288;&#22522;&#20110;&#21487;&#38752;&#24615;&#65289;&#20248;&#21270;&#38382;&#39064;&#30340;&#32972;&#26223;&#19979;&#65292;&#24403;&#23547;&#25214;&#28385;&#36275;&#32422;&#26463;&#26465;&#20214;&#19988;&#20855;&#26377;&#36275;&#22815;&#22823;&#27010;&#29575;&#30340;&#35299;&#38598;&#26102;&#20250;&#21457;&#29983;&#12290;&#20026;&#20102;&#35299;&#20915;QSI&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#24314;&#27169;&#21644;&#36880;&#27493;&#19981;&#30830;&#23450;&#24615;&#20943;&#23569;&#65288;SUR&#65289;&#21407;&#29702;&#30340;&#36125;&#21494;&#26031;&#31574;&#30053;&#65292;&#20197;&#39034;&#24207;&#36873;&#25321;&#24212;&#35813;&#35780;&#20272;&#20989;&#25968;&#30340;&#28857;&#65292;&#20197;&#20415;&#39640;&#25928;&#36817;&#20284;&#24863;&#20852;&#36259;&#30340;&#38598;&#21512;&#12290;&#36890;&#36807;&#20960;&#20010;&#25968;&#20540;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;SUR&#31574;&#30053;&#30340;&#24615;&#33021;&#21644;&#20215;&#20540;
&lt;/p&gt;
&lt;p&gt;
We consider an unknown multivariate function representing a system-such as a complex numerical simulator-taking both deterministic and uncertain inputs. Our objective is to estimate the set of deterministic inputs leading to outputs whose probability (with respect to the distribution of the uncertain inputs) of belonging to a given set is less than a given threshold. This problem, which we call Quantile Set Inversion (QSI), occurs for instance in the context of robust (reliability-based) optimization problems, when looking for the set of solutions that satisfy the constraints with sufficiently large probability. To solve the QSI problem, we propose a Bayesian strategy based on Gaussian process modeling and the Stepwise Uncertainty Reduction (SUR) principle, to sequentially choose the points at which the function should be evaluated to efficiently approximate the set of interest. We illustrate the performance and interest of the proposed SUR strategy through several numerical experiment
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#27169;&#22411;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#22312;&#38646;&#21644;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#20013;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22312;&#25214;&#21040;&#32435;&#20160;&#22343;&#34913;&#20540;&#21450;&#20855;&#26377;&#24179;&#28369;&#35268;&#21010;&#39044;&#35328;&#26426;&#30340;&#949;-NE&#31574;&#30053;&#26041;&#38754;&#20855;&#26377;&#25509;&#36817;&#26368;&#20248;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2007.07461</link><description>&lt;p&gt;
&#22522;&#20110;&#27169;&#22411;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#22312;&#38646;&#21644;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#20013;&#20855;&#26377;&#25509;&#36817;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
Model-Based Multi-Agent RL in Zero-Sum Markov Games with Near-Optimal Sample Complexity. (arXiv:2007.07461v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2007.07461
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#27169;&#22411;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#22312;&#38646;&#21644;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#20013;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22312;&#25214;&#21040;&#32435;&#20160;&#22343;&#34913;&#20540;&#21450;&#20855;&#26377;&#24179;&#28369;&#35268;&#21010;&#39044;&#35328;&#26426;&#30340;&#949;-NE&#31574;&#30053;&#26041;&#38754;&#20855;&#26377;&#25509;&#36817;&#26368;&#20248;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#24050;&#32463;&#34987;&#35748;&#20026;&#26159;RL&#30340;&#22522;&#30707;&#20043;&#19968;&#65292;&#36890;&#36807;&#20351;&#29992;&#32463;&#39564;&#27169;&#22411;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#12290;&#23427;&#29305;&#21035;&#36866;&#29992;&#20110;&#22810;&#26234;&#33021;&#20307;RL&#65288;MARL&#65289;&#65292;&#22240;&#20026;&#23427;&#33258;&#28982;&#22320;&#23558;&#23398;&#20064;&#21644;&#35268;&#21010;&#38454;&#27573;&#35299;&#32806;&#65292;&#24182;&#36991;&#20813;&#20102;&#22312;&#25152;&#26377;&#26234;&#33021;&#20307;&#21516;&#26102;&#20351;&#29992;&#26679;&#26412;&#25913;&#36827;&#31574;&#30053;&#26102;&#30340;&#38750;&#31283;&#24577;&#38382;&#39064;&#12290;&#23613;&#31649;&#30452;&#35266;&#19988;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#22522;&#20110;&#27169;&#22411;&#30340;MARL&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#23578;&#26410;&#24471;&#21040;&#20840;&#38754;&#30740;&#31350;&#12290;&#26412;&#25991;&#30340;&#30446;&#26631;&#26159;&#35299;&#20915;&#20851;&#20110;&#20854;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#22522;&#26412;&#38382;&#39064;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#21487;&#33021;&#26159;&#26368;&#22522;&#26412;&#30340;MARL&#35774;&#32622;&#65306;&#21482;&#33021;&#35775;&#38382;&#19968;&#20010;&#29983;&#25104;&#27169;&#22411;&#30340;&#20004;&#20154;&#25240;&#25187;&#38646;&#21644;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22522;&#20110;&#27169;&#22411;&#30340;MARL&#22312;&#23547;&#25214;&#21040;&#26576;&#20010;&#949;&#35823;&#24046;&#30340;&#32435;&#20160;&#22343;&#34913;&#65288;NE&#65289;&#20540;&#20197;&#21450;&#20855;&#26377;&#24179;&#28369;&#35268;&#21010;&#39044;&#35328;&#26426;&#30340;&#949;-NE&#31574;&#30053;&#26041;&#38754;&#36798;&#21040;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\tilde O(|S||A||B|(1-\gamma)^{-3}\epsilon^{-2})$&#30340;&#32467;&#26524;&#65292;&#20854;&#20013;&#947;&#26159;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model-based reinforcement learning (RL), which finds an optimal policy using an empirical model, has long been recognized as one of the corner stones of RL. It is especially suitable for multi-agent RL (MARL), as it naturally decouples the learning and the planning phases, and avoids the non-stationarity problem when all agents are improving their policies simultaneously using samples. Though intuitive and widely-used, the sample complexity of model-based MARL algorithms has not been fully investigated. In this paper, our goal is to address the fundamental question about its sample complexity. We study arguably the most basic MARL setting: two-player discounted zero-sum Markov games, given only access to a generative model. We show that model-based MARL achieves a sample complexity of $\tilde O(|S||A||B|(1-\gamma)^{-3}\epsilon^{-2})$ for finding the Nash equilibrium (NE) value up to some $\epsilon$ error, and the $\epsilon$-NE policies with a smooth planning oracle, where $\gamma$ is t
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24182;&#34892;&#36817;&#31471;&#26041;&#27861;&#23454;&#29616;&#31232;&#30095;&#21644;&#20302;&#31209;&#39640;&#38454;&#24352;&#37327;&#22238;&#24402;&#30340;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#36890;&#36807;&#30452;&#25509;&#24212;&#29992;$\ell_1$&#33539;&#25968;&#21644;&#24352;&#37327;&#26680;&#33539;&#25968;&#26469;&#20445;&#30041;&#24352;&#37327;&#30340;&#32467;&#26500;&#20449;&#24687;&#65292;&#24182;&#19988;&#22312;&#22788;&#29702;&#22823;&#35268;&#27169;&#25968;&#25454;&#21644;&#39640;&#38454;&#32467;&#26500;&#26102;&#20855;&#26377;&#21487;&#25193;&#23637;&#24615;&#21644;&#39640;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/1911.12965</link><description>&lt;p&gt;
&#31232;&#30095;&#21644;&#20302;&#31209;&#39640;&#38454;&#24352;&#37327;&#22238;&#24402;&#36890;&#36807;&#24182;&#34892;&#36817;&#31471;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sparse and Low-Rank High-Order Tensor Regression via Parallel Proximal Method. (arXiv:1911.12965v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1911.12965
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24182;&#34892;&#36817;&#31471;&#26041;&#27861;&#23454;&#29616;&#31232;&#30095;&#21644;&#20302;&#31209;&#39640;&#38454;&#24352;&#37327;&#22238;&#24402;&#30340;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#36890;&#36807;&#30452;&#25509;&#24212;&#29992;$\ell_1$&#33539;&#25968;&#21644;&#24352;&#37327;&#26680;&#33539;&#25968;&#26469;&#20445;&#30041;&#24352;&#37327;&#30340;&#32467;&#26500;&#20449;&#24687;&#65292;&#24182;&#19988;&#22312;&#22788;&#29702;&#22823;&#35268;&#27169;&#25968;&#25454;&#21644;&#39640;&#38454;&#32467;&#26500;&#26102;&#20855;&#26377;&#21487;&#25193;&#23637;&#24615;&#21644;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#29616;&#20195;&#24212;&#29992;&#20013;&#29983;&#25104;&#20102;&#24352;&#37327;&#25968;&#25454;&#65288;&#25110;&#22810;&#32500;&#25968;&#32452;&#65289;&#65292;&#20363;&#22914;&#31070;&#32463;&#31185;&#23398;&#20013;&#30340;&#21151;&#33021;&#24615;&#30913;&#20849;&#25391;&#25104;&#20687;&#65288;fMRI&#65289;&#20197;&#21450;&#35270;&#39057;&#20998;&#26512;&#20013;&#30340;&#35270;&#39057;&#12290;&#36817;&#24180;&#26469;&#65292;&#38024;&#23545;&#39044;&#27979;&#24352;&#37327;&#29305;&#24449;&#19982;&#21333;&#21464;&#37327;&#21709;&#24212;&#20043;&#38388;&#30340;&#20851;&#31995;&#25552;&#20986;&#20102;&#35768;&#22810;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#20197;&#24448;&#30340;&#26041;&#27861;&#35201;&#20040;&#20002;&#22833;&#20102;&#24352;&#37327;&#25968;&#25454;&#20013;&#30340;&#32467;&#26500;&#20449;&#24687;&#65292;&#35201;&#20040;&#22312;&#22788;&#29702;&#39640;&#38454;&#32467;&#26500;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#26102;&#26102;&#38388;&#25104;&#26412;&#36807;&#39640;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31232;&#30095;&#21644;&#20302;&#31209;&#24352;&#37327;&#22238;&#24402;&#65288;SLTR&#65289;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#36890;&#36807;&#30452;&#25509;&#24212;&#29992;$\ell_1$&#33539;&#25968;&#21644;&#24352;&#37327;&#26680;&#33539;&#25968;&#26469;&#24378;&#21046;&#24352;&#37327;&#31995;&#25968;&#30340;&#31232;&#30095;&#24615;&#21644;&#20302;&#31209;&#24615;&#65292;&#20174;&#32780;&#20445;&#30041;&#20102;&#24352;&#37327;&#30340;&#32467;&#26500;&#20449;&#24687;&#12290;&#20026;&#20102;&#20351;&#27714;&#35299;&#36807;&#31243;&#21487;&#25193;&#23637;&#21644;&#39640;&#25928;&#65292;SLTR&#21033;&#29992;&#20102;&#36817;&#31471;&#26799;&#24230;&#27861;&#65292;&#21487;&#20197;&#36731;&#26494;&#22320;&#24182;&#34892;&#23454;&#29616;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#27169;&#25311;&#25968;&#25454;&#38598;&#21644;&#19968;&#20010;&#35270;&#39057;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;SLTR&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, tensor data (or multidimensional array) have been generated in many modern applications, such as functional magnetic resonance imaging (fMRI) in neuroscience and videos in video analysis. Many efforts are made in recent years to predict the relationship between tensor features and univariate responses. However, previously proposed methods either lose structural information within tensor data or have prohibitively expensive time costs, especially for large-scale data with high-order structures. To address such problems, we propose the Sparse and Low-rank Tensor Regression (SLTR) model. Our model enforces sparsity and low-rankness of the tensor coefficient by directly applying $\ell_1$ norm and tensor nuclear norm, such that it preserves structural information of the tensor. To make the solving procedure scalable and efficient, SLTR makes use of the proximal gradient method, which can be easily implemented parallelly. We evaluate SLTR on several simulated datasets and one video
&lt;/p&gt;</description></item></channel></rss>