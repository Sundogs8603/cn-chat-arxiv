<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#20351;&#29992;&#25511;&#21046;&#21464;&#37327;&#30340;&#26041;&#27861;&#31283;&#23450;Shapley&#20540;&#30340;&#20272;&#35745;&#65292;&#20943;&#23569;&#20102;&#27169;&#22411;&#35299;&#37322;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#36866;&#29992;&#20110;&#20219;&#20309;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2310.07672</link><description>&lt;p&gt;
&#29992;&#25511;&#21046;&#21464;&#37327;&#31283;&#23450;Shapley&#20540;&#30340;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Stabilizing Estimates of Shapley Values with Control Variates. (arXiv:2310.07672v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07672
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#25511;&#21046;&#21464;&#37327;&#30340;&#26041;&#27861;&#31283;&#23450;Shapley&#20540;&#30340;&#20272;&#35745;&#65292;&#20943;&#23569;&#20102;&#27169;&#22411;&#35299;&#37322;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#36866;&#29992;&#20110;&#20219;&#20309;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Shapley&#20540;&#26159;&#35299;&#37322;&#40657;&#30418;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#39044;&#27979;&#26368;&#27969;&#34892;&#30340;&#24037;&#20855;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#35745;&#31639;&#25104;&#26412;&#24456;&#39640;&#65292;&#22240;&#27492;&#37319;&#29992;&#25277;&#26679;&#36817;&#20284;&#26469;&#20943;&#23569;&#19981;&#30830;&#23450;&#24615;&#12290;&#20026;&#20102;&#31283;&#23450;&#36825;&#20123;&#27169;&#22411;&#35299;&#37322;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25511;&#21046;&#21464;&#37327;&#30340;&#33945;&#29305;&#21345;&#27931;&#25216;&#26415;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;ControlSHAP&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36866;&#29992;&#20110;&#20219;&#20309;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#19988;&#20960;&#20046;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#35745;&#31639;&#25110;&#24314;&#27169;&#24037;&#20316;&#12290;&#22312;&#22810;&#20010;&#39640;&#32500;&#25968;&#25454;&#38598;&#19978;&#65292;&#25105;&#20204;&#21457;&#29616;&#23427;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;Shapley&#20272;&#35745;&#30340;&#33945;&#29305;&#21345;&#27931;&#21464;&#24322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Shapley values are among the most popular tools for explaining predictions of blackbox machine learning models. However, their high computational cost motivates the use of sampling approximations, inducing a considerable degree of uncertainty. To stabilize these model explanations, we propose ControlSHAP, an approach based on the Monte Carlo technique of control variates. Our methodology is applicable to any machine learning model and requires virtually no extra computation or modeling effort. On several high-dimensional datasets, we find it can produce dramatic reductions in the Monte Carlo variability of Shapley estimates.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#31181;&#23454;&#29992;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#28145;&#24230;&#29983;&#25104;&#32452;&#20214;&#30340;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20013;&#35745;&#31639;&#22238;&#28335;&#21453;&#20107;&#23454;&#12290;&#36890;&#36807;&#22312;&#22240;&#26524;&#27169;&#22411;&#30340;&#32467;&#26500;&#21270;&#28508;&#22312;&#31354;&#38388;&#20013;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#29983;&#25104;&#21453;&#20107;&#23454;&#65292;&#24182;&#19988;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#27604;&#20855;&#22791;&#20102;&#22810;&#21151;&#33021;&#12289;&#27169;&#22359;&#21270;&#21644;&#31526;&#21512;&#22240;&#26524;&#20851;&#31995;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2310.07665</link><description>&lt;p&gt;
&#28145;&#24230;&#22238;&#28335;&#23545;&#22240;&#26524;&#19968;&#33268;&#35299;&#37322;&#30340;&#21453;&#20107;&#23454;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Deep Backtracking Counterfactuals for Causally Compliant Explanations. (arXiv:2310.07665v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07665
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#31181;&#23454;&#29992;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#28145;&#24230;&#29983;&#25104;&#32452;&#20214;&#30340;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20013;&#35745;&#31639;&#22238;&#28335;&#21453;&#20107;&#23454;&#12290;&#36890;&#36807;&#22312;&#22240;&#26524;&#27169;&#22411;&#30340;&#32467;&#26500;&#21270;&#28508;&#22312;&#31354;&#38388;&#20013;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#29983;&#25104;&#21453;&#20107;&#23454;&#65292;&#24182;&#19988;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#27604;&#20855;&#22791;&#20102;&#22810;&#21151;&#33021;&#12289;&#27169;&#22359;&#21270;&#21644;&#31526;&#21512;&#22240;&#26524;&#20851;&#31995;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#25512;&#29702;&#21487;&#20197;&#36890;&#36807;&#22238;&#31572;&#22312;&#25913;&#21464;&#24773;&#20917;&#19979;&#20250;&#35266;&#23519;&#21040;&#20160;&#20040;&#26469;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#35265;&#35299;&#65292;&#26465;&#20214;&#26159;&#26681;&#25454;&#23454;&#38469;&#35266;&#23519;&#12290;&#34429;&#28982;&#32463;&#20856;&#30340;&#20171;&#20837;&#24335;&#35299;&#37322;&#24050;&#32463;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#22238;&#28335;&#21407;&#21017;&#34987;&#25552;&#20986;&#20316;&#20026;&#19968;&#31181;&#20445;&#25345;&#25152;&#26377;&#22240;&#26524;&#23450;&#24459;&#23436;&#25972;&#24615;&#30340;&#26367;&#20195;&#21746;&#23398;&#65292;&#20294;&#20854;&#30740;&#31350;&#36739;&#23569;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#22312;&#30001;&#28145;&#24230;&#29983;&#25104;&#32452;&#20214;&#32452;&#25104;&#30340;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20013;&#35745;&#31639;&#22238;&#28335;&#21453;&#20107;&#23454;&#30340;&#23454;&#29992;&#26041;&#27861;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#23545;&#32467;&#26500;&#20998;&#37197;&#26045;&#21152;&#20102;&#26465;&#20214;&#65292;&#36890;&#36807;&#22312;&#22240;&#26524;&#27169;&#22411;&#30340;&#32467;&#26500;&#21270;&#28508;&#22312;&#31354;&#38388;&#20013;&#35299;&#20915;&#19968;&#20010;&#21487;&#34892;&#30340;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#26469;&#29983;&#25104;&#21453;&#20107;&#23454;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36824;&#21487;&#20197;&#19982;&#21453;&#20107;&#23454;&#35299;&#37322;&#39046;&#22495;&#30340;&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#12290;&#19982;&#36825;&#20123;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20195;&#34920;&#20102;&#19968;&#31181;&#22810;&#21151;&#33021;&#12289;&#27169;&#22359;&#21270;&#21644;&#36981;&#23432;&#22240;&#26524;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactuals can offer valuable insights by answering what would have been observed under altered circumstances, conditional on a factual observation. Whereas the classical interventional interpretation of counterfactuals has been studied extensively, backtracking constitutes a less studied alternative the backtracking principle has emerged as an alternative philosophy where all causal laws are kept intact. In the present work, we introduce a practical method for computing backtracking counterfactuals in structural causal models that consist of deep generative components. To this end, we impose conditions on the structural assignments that enable the generation of counterfactuals by solving a tractable constrained optimization problem in the structured latent space of a causal model. Our formulation also facilitates a comparison with methods in the field of counterfactual explanations. Compared to these, our method represents a versatile, modular and causally compliant alternative. 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#38750;&#21442;&#25968;&#38656;&#27714;&#23398;&#20064;&#21644;&#24179;&#28369;&#33258;&#36866;&#24212;&#30340;&#21160;&#24577;&#23450;&#20215;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#30456;&#20284;&#26465;&#20214;&#23454;&#29616;&#20102;&#26368;&#23567;&#21270;&#26497;&#38480;&#36951;&#25022;&#12290;</title><link>http://arxiv.org/abs/2310.07558</link><description>&lt;p&gt;
&#20855;&#26377;&#38750;&#21442;&#25968;&#38656;&#27714;&#23398;&#20064;&#30340;&#24179;&#28369;&#33258;&#36866;&#24212;&#21160;&#24577;&#23450;&#20215;
&lt;/p&gt;
&lt;p&gt;
Smootheness-Adaptive Dynamic Pricing with Nonparametric Demand Learning. (arXiv:2310.07558v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07558
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#38750;&#21442;&#25968;&#38656;&#27714;&#23398;&#20064;&#21644;&#24179;&#28369;&#33258;&#36866;&#24212;&#30340;&#21160;&#24577;&#23450;&#20215;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#30456;&#20284;&#26465;&#20214;&#23454;&#29616;&#20102;&#26368;&#23567;&#21270;&#26497;&#38480;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#38656;&#27714;&#20989;&#25968;&#20026;&#38750;&#21442;&#25968;&#21644;Holder&#24179;&#28369;&#30340;&#21160;&#24577;&#23450;&#20215;&#38382;&#39064;&#65292;&#24182;&#19988;&#25105;&#20204;&#19987;&#27880;&#20110;&#36866;&#24212;&#26410;&#30693;&#30340;Holder&#24179;&#28369;&#21442;&#25968;&#946;&#30340;&#33021;&#21147;&#12290;&#20256;&#32479;&#19978;&#65292;&#26368;&#20248;&#30340;&#21160;&#24577;&#23450;&#20215;&#31639;&#27861;&#20005;&#37325;&#20381;&#36182;&#20110;&#23545;&#946;&#30340;&#20102;&#35299;&#65292;&#20197;&#36798;&#21040;&#19968;&#20010;&#26368;&#23567;&#21270;&#26497;&#38480;&#36951;&#25022;&#30340;&#25928;&#26524;&#65292;&#21363;O(T^((&#946;+1)/(2&#946;+1)))&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#36890;&#36807;&#35777;&#26126;&#27809;&#26377;&#23450;&#20215;&#31574;&#30053;&#33021;&#22815;&#22312;&#19981;&#30693;&#36947;&#946;&#30340;&#24773;&#20917;&#19979;&#33258;&#36866;&#24212;&#22320;&#36798;&#21040;&#36825;&#20010;&#26368;&#23567;&#21270;&#26497;&#38480;&#36951;&#25022;&#65292;&#31361;&#26174;&#20102;&#36825;&#20010;&#21160;&#24577;&#23450;&#20215;&#38382;&#39064;&#30340;&#36866;&#24212;&#24615;&#25361;&#25112;&#12290;&#21463;&#21040;&#19981;&#21487;&#33021;&#24615;&#32467;&#26524;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#30456;&#20284;&#26465;&#20214;&#26469;&#23454;&#29616;&#36866;&#24212;&#24615;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#33258;&#30456;&#20284;&#26465;&#20214;&#19981;&#20250;&#25439;&#23475;&#38382;&#39064;&#26412;&#36523;&#30340;&#22797;&#26434;&#24615;&#65292;&#22240;&#20026;&#23427;&#20445;&#25345;&#20102;&#28176;&#36817;&#36951;&#25022;&#19979;&#30028;&#937;(T^((&#946;+1)/(2&#946;+1)))&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#24179;&#28369;&#33258;&#36866;&#24212;&#30340;&#21160;&#24577;&#23450;&#20215;&#31639;&#27861;&#65292;&#24182;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the dynamic pricing problem where the demand function is nonparametric and H\"older smooth, and we focus on adaptivity to the unknown H\"older smoothness parameter $\beta$ of the demand function. Traditionally the optimal dynamic pricing algorithm heavily relies on the knowledge of $\beta$ to achieve a minimax optimal regret of $\widetilde{O}(T^{\frac{\beta+1}{2\beta+1}})$. However, we highlight the challenge of adaptivity in this dynamic pricing problem by proving that no pricing policy can adaptively achieve this minimax optimal regret without knowledge of $\beta$. Motivated by the impossibility result, we propose a self-similarity condition to enable adaptivity. Importantly, we show that the self-similarity condition does not compromise the problem's inherent complexity since it preserves the regret lower bound $\Omega(T^{\frac{\beta+1}{2\beta+1}})$. Furthermore, we develop a smoothness-adaptive dynamic pricing algorithm and theoretically prove that the algorithm achieves t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#20998;&#26512;&#20102;&#20581;&#24247;&#20010;&#20307;&#30340;&#24515;&#30005;&#22270;&#25968;&#25454;&#65292;&#24182;&#35782;&#21035;&#20986;&#38543;&#24180;&#40836;&#22686;&#38271;&#21628;&#21560;&#29575;&#30340;&#19979;&#38477;&#21450;SDANN&#20540;&#24322;&#24120;&#39640;&#20316;&#20026;&#32769;&#24180;&#20154;&#30340;&#25351;&#26631;&#12290;</title><link>http://arxiv.org/abs/2310.07463</link><description>&lt;p&gt;
&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#25581;&#31034;&#20581;&#24247;&#34928;&#32769;&#36807;&#31243;&#20013;&#30340;&#24515;&#30005;&#22270;&#21464;&#21270;
&lt;/p&gt;
&lt;p&gt;
Uncovering ECG Changes during Healthy Aging using Explainable AI. (arXiv:2310.07463v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07463
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#20998;&#26512;&#20102;&#20581;&#24247;&#20010;&#20307;&#30340;&#24515;&#30005;&#22270;&#25968;&#25454;&#65292;&#24182;&#35782;&#21035;&#20986;&#38543;&#24180;&#40836;&#22686;&#38271;&#21628;&#21560;&#29575;&#30340;&#19979;&#38477;&#21450;SDANN&#20540;&#24322;&#24120;&#39640;&#20316;&#20026;&#32769;&#24180;&#20154;&#30340;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24515;&#34880;&#31649;&#30142;&#30149;&#20173;&#28982;&#26159;&#20840;&#29699;&#39046;&#20808;&#30340;&#27515;&#22240;&#12290;&#36825;&#38656;&#35201;&#23545;&#24515;&#33039;&#34928;&#32769;&#36807;&#31243;&#26377;&#28145;&#20837;&#30340;&#20102;&#35299;&#65292;&#20197;&#35786;&#26029;&#24515;&#34880;&#31649;&#20581;&#24247;&#29366;&#20917;&#30340;&#38480;&#21046;&#12290;&#20256;&#32479;&#19978;&#65292;&#23545;&#20010;&#20307;&#24515;&#30005;&#22270;&#65288;ECG&#65289;&#29305;&#24449;&#38543;&#24180;&#40836;&#21464;&#21270;&#30340;&#20998;&#26512;&#25552;&#20379;&#20102;&#36825;&#20123;&#35265;&#35299;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#29305;&#24449;&#34429;&#28982;&#26377;&#20449;&#24687;&#37327;&#65292;&#20294;&#21487;&#33021;&#25513;&#30422;&#20102;&#24213;&#23618;&#25968;&#25454;&#20851;&#31995;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21644;&#22522;&#20110;&#26641;&#30340;&#27169;&#22411;&#20998;&#26512;&#26469;&#33258;&#20581;&#24247;&#20010;&#20307;&#30340;ECG&#25968;&#25454;&#65292;&#21253;&#25324;&#21407;&#22987;&#20449;&#21495;&#21644;ECG&#29305;&#24449;&#26684;&#24335;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;AI&#25216;&#26415;&#26469;&#35782;&#21035;&#23545;&#20110;&#21306;&#20998;&#24180;&#40836;&#32452;&#21035;&#26368;&#26377;&#36776;&#21035;&#21147;&#30340;ECG&#29305;&#24449;&#25110;&#21407;&#22987;&#20449;&#21495;&#29305;&#24449;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#19982;&#22522;&#20110;&#26641;&#30340;&#20998;&#31867;&#22120;&#25581;&#31034;&#20102;&#38543;&#24180;&#40836;&#22686;&#38271;&#21628;&#21560;&#29575;&#19979;&#38477;&#65292;&#24182;&#35782;&#21035;&#20986;SDANN&#20540;&#24322;&#24120;&#39640;&#20316;&#20026;&#32769;&#24180;&#20154;&#30340;&#25351;&#26631;&#65292;&#21487;&#23558;&#20854;&#19982;&#24180;&#36731;&#20154;&#21306;&#20998;&#24320;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cardiovascular diseases remain the leading global cause of mortality. This necessitates a profound understanding of heart aging processes to diagnose constraints in cardiovascular fitness. Traditionally, most of such insights have been drawn from the analysis of electrocardiogram (ECG) feature changes of individuals as they age. However, these features, while informative, may potentially obscure underlying data relationships. In this paper, we employ a deep-learning model and a tree-based model to analyze ECG data from a robust dataset of healthy individuals across varying ages in both raw signals and ECG feature format. Explainable AI techniques are then used to identify ECG features or raw signal characteristics are most discriminative for distinguishing between age groups. Our analysis with tree-based classifiers reveal age-related declines in inferred breathing rates and identifies notably high SDANN values as indicative of elderly individuals, distinguishing them from younger adul
&lt;/p&gt;</description></item><item><title>&#38750;&#22238;&#28335;&#22270;&#31070;&#32463;&#32593;&#32476;(NBA-GNN)&#36890;&#36807;&#19981;&#32771;&#34385;&#20808;&#21069;&#35775;&#38382;&#33410;&#28857;&#30340;&#28040;&#24687;&#26469;&#35299;&#20915;&#22270;&#31070;&#32463;&#32593;&#32476;&#26412;&#22320;&#26356;&#26032;&#20013;&#30340;&#20887;&#20313;&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#38543;&#26426;&#22359;&#27169;&#22411;&#24674;&#22797;&#26041;&#38754;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.07430</link><description>&lt;p&gt;
&#38750;&#22238;&#28335;&#22270;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Non-backtracking Graph Neural Networks. (arXiv:2310.07430v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07430
&lt;/p&gt;
&lt;p&gt;
&#38750;&#22238;&#28335;&#22270;&#31070;&#32463;&#32593;&#32476;(NBA-GNN)&#36890;&#36807;&#19981;&#32771;&#34385;&#20808;&#21069;&#35775;&#38382;&#33410;&#28857;&#30340;&#28040;&#24687;&#26469;&#35299;&#20915;&#22270;&#31070;&#32463;&#32593;&#32476;&#26412;&#22320;&#26356;&#26032;&#20013;&#30340;&#20887;&#20313;&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#38543;&#26426;&#22359;&#27169;&#22411;&#24674;&#22797;&#26041;&#38754;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33879;&#21517;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#28040;&#24687;&#20256;&#36882;&#26356;&#26032;&#20801;&#35768;&#20351;&#29992;&#26412;&#22320;&#21644;&#35745;&#31639;&#19978;&#21487;&#36319;&#36394;&#30340;&#26356;&#26032;&#26469;&#34920;&#31034;&#22823;&#35268;&#27169;&#22270;&#12290;&#28982;&#32780;&#65292;&#26412;&#22320;&#26356;&#26032;&#21463;&#21040;&#22238;&#28335;&#30340;&#24433;&#21709;&#65292;&#21363;&#28040;&#24687;&#36890;&#36807;&#21516;&#19968;&#26465;&#36793;&#20004;&#27425;&#27969;&#21160;&#24182;&#37325;&#35775;&#20808;&#21069;&#35775;&#38382;&#30340;&#33410;&#28857;&#12290;&#30001;&#20110;&#28040;&#24687;&#27969;&#30340;&#25968;&#37327;&#38543;&#30528;&#26356;&#26032;&#30340;&#27425;&#25968;&#21576;&#25351;&#25968;&#32423;&#22686;&#21152;&#65292;&#26412;&#22320;&#26356;&#26032;&#20013;&#30340;&#20887;&#20313;&#38459;&#30861;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#20934;&#30830;&#35782;&#21035;&#19979;&#28216;&#20219;&#21153;&#30340;&#29305;&#23450;&#28040;&#24687;&#27969;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#38750;&#22238;&#28335;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;NBA-GNN&#65289;&#35299;&#20915;&#20102;&#36825;&#31181;&#20887;&#20313;&#65292;&#35813;&#32593;&#32476;&#22312;&#26356;&#26032;&#28040;&#24687;&#26102;&#19981;&#32771;&#34385;&#20808;&#21069;&#35775;&#38382;&#33410;&#28857;&#30340;&#28040;&#24687;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#30740;&#31350;&#20102;NBA-GNN&#22914;&#20309;&#32531;&#35299;GNN&#30340;&#36807;&#24230;&#21387;&#32553;&#65292;&#24182;&#24314;&#31435;&#20102;NBA-GNN&#21644;&#38750;&#22238;&#28335;&#26356;&#26032;&#22312;&#38543;&#26426;&#22359;&#27169;&#22411;&#24674;&#22797;&#26041;&#38754;&#20986;&#33394;&#24615;&#33021;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#20102;&#25105;&#20204;&#30340;NBA-
&lt;/p&gt;
&lt;p&gt;
The celebrated message-passing updates for graph neural networks allow the representation of large-scale graphs with local and computationally tractable updates. However, the local updates suffer from backtracking, i.e., a message flows through the same edge twice and revisits the previously visited node. Since the number of message flows increases exponentially with the number of updates, the redundancy in local updates prevents the graph neural network from accurately recognizing a particular message flow for downstream tasks. In this work, we propose to resolve such a redundancy via the non-backtracking graph neural network (NBA-GNN) that updates a message without incorporating the message from the previously visited node. We further investigate how NBA-GNN alleviates the over-squashing of GNNs, and establish a connection between NBA-GNN and the impressive performance of non-backtracking updates for stochastic block model recovery. We empirically verify the effectiveness of our NBA-
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;5/2&#38454;&#21644;7/2&#38454;$L^2$-&#20934;&#30830;&#30340;&#38543;&#26426;Runge-Kutta-Nystr\"om&#26041;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#24213;&#23618;&#30340;&#21704;&#23494;&#39039;&#27969;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;&#39640;&#32500;&#30446;&#26631;&#20998;&#24067;&#20013;&#30340;&#21331;&#36234;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.07399</link><description>&lt;p&gt;
&#38543;&#26426;Runge-Kutta-Nystr\"om&#26041;&#27861;&#22312;&#38750;&#21487;&#36870;&#39532;&#23572;&#31185;&#22827;&#38142;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Randomized Runge-Kutta-Nystr\"om. (arXiv:2310.07399v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07399
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;5/2&#38454;&#21644;7/2&#38454;$L^2$-&#20934;&#30830;&#30340;&#38543;&#26426;Runge-Kutta-Nystr\"om&#26041;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#24213;&#23618;&#30340;&#21704;&#23494;&#39039;&#27969;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;&#39640;&#32500;&#30446;&#26631;&#20998;&#24067;&#20013;&#30340;&#21331;&#36234;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;5/2&#38454;&#21644;7/2&#38454;$L^2$-&#20934;&#30830;&#30340;&#38543;&#26426;Runge-Kutta-Nystr\"om&#26041;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#24213;&#23618;&#30340;&#21704;&#23494;&#39039;&#27969;&#65292;&#21253;&#25324;&#19981;&#35843;&#25972;&#30340;&#21704;&#23494;&#39039;&#33945;&#29305;&#21345;&#27931;&#21644;&#19981;&#35843;&#25972;&#30340;&#21160;&#21147;&#23398;&#26391;&#20043;&#19975;&#38142;&#12290;&#36890;&#36807;&#22312;&#21183;&#33021;&#20989;&#25968;&#30340;&#26799;&#24230;&#21644;&#28023;&#26862;&#30697;&#38453;&#30340;Lipschitz&#20551;&#35774;&#19979;&#25552;&#20379;&#20102;&#37327;&#21270;&#30340;5/2&#38454;$L^2$-&#20934;&#30830;&#24230;&#19978;&#38480;&#12290;&#23545;&#20110;&#19968;&#20123;&#8220;&#33391;&#22909;&#34892;&#20026;&#8221;&#30340;&#39640;&#32500;&#30446;&#26631;&#20998;&#24067;&#65292;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#23545;&#24212;&#30340;&#39532;&#23572;&#31185;&#22827;&#38142;&#34920;&#29616;&#20986;&#24456;&#39640;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present 5/2- and 7/2-order $L^2$-accurate randomized Runge-Kutta-Nystr\"om methods to approximate the Hamiltonian flow underlying various non-reversible Markov chain Monte Carlo chains including unadjusted Hamiltonian Monte Carlo and unadjusted kinetic Langevin chains. Quantitative 5/2-order $L^2$-accuracy upper bounds are provided under gradient and Hessian Lipschitz assumptions on the potential energy function. The superior complexity of the corresponding Markov chains is numerically demonstrated for a selection of `well-behaved', high-dimensional target distributions.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#20998;&#26512;&#27491;&#20132;&#38543;&#26426;&#29305;&#24449;&#30340;&#26680;&#36817;&#20284;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#65292;&#25552;&#20379;&#20102;&#26126;&#30830;&#30340;&#34920;&#36798;&#24335;&#65292;&#24182;&#24471;&#20986;&#20102;&#23574;&#38160;&#25351;&#25968;&#30028;&#38480;&#65292;&#25903;&#25345;&#27491;&#20132;&#38543;&#26426;&#29305;&#24449;&#27604;&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;&#26356;&#20855;&#20449;&#24687;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.07370</link><description>&lt;p&gt;
&#27491;&#20132;&#38543;&#26426;&#29305;&#24449;: &#26126;&#30830;&#24418;&#24335;&#21644;&#23574;&#38160;&#19981;&#31561;&#24335;
&lt;/p&gt;
&lt;p&gt;
Orthogonal Random Features: Explicit Forms and Sharp Inequalities. (arXiv:2310.07370v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07370
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#20998;&#26512;&#27491;&#20132;&#38543;&#26426;&#29305;&#24449;&#30340;&#26680;&#36817;&#20284;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#65292;&#25552;&#20379;&#20102;&#26126;&#30830;&#30340;&#34920;&#36798;&#24335;&#65292;&#24182;&#24471;&#20986;&#20102;&#23574;&#38160;&#25351;&#25968;&#30028;&#38480;&#65292;&#25903;&#25345;&#27491;&#20132;&#38543;&#26426;&#29305;&#24449;&#27604;&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;&#26356;&#20855;&#20449;&#24687;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#29305;&#24449;&#36890;&#36807;&#38543;&#26426;&#21270;&#25216;&#26415;&#34987;&#24341;&#20837;&#20197;&#25193;&#23637;&#26680;&#26041;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;&#21644;&#27491;&#20132;&#38543;&#26426;&#29305;&#24449;&#34987;&#29992;&#26469;&#36817;&#20284;&#27969;&#34892;&#30340;&#39640;&#26031;&#26680;&#12290;&#21069;&#32773;&#36890;&#36807;&#38543;&#26426;&#39640;&#26031;&#30697;&#38453;&#25191;&#34892;&#65292;&#24182;&#22312;&#24179;&#22343;&#21518;&#24471;&#21040;&#20102;&#23436;&#20840;&#31526;&#21512;&#39640;&#26031;&#26680;&#30340;&#32467;&#26524;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#22522;&#20110;&#29992;&#21040;Haar&#27491;&#20132;&#30697;&#38453;&#30340;&#27491;&#20132;&#38543;&#26426;&#29305;&#24449;&#30340;&#26680;&#36817;&#20284;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#12290;&#25105;&#20204;&#20351;&#29992;&#24402;&#19968;&#21270;&#36125;&#22622;&#23572;&#20989;&#25968;&#25552;&#20379;&#20102;&#36825;&#20123;&#37327;&#30340;&#26126;&#30830;&#34920;&#36798;&#24335;&#65292;&#24182;&#25512;&#23548;&#20102;&#25903;&#25345;&#27491;&#20132;&#38543;&#26426;&#29305;&#24449;&#27604;&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;&#26356;&#20855;&#20449;&#24687;&#24615;&#30340;&#23574;&#38160;&#25351;&#25968;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Random features have been introduced to scale up kernel methods via randomization techniques. In particular, random Fourier features and orthogonal random features were used to approximate the popular Gaussian kernel. The former is performed by a random Gaussian matrix and leads exactly to the Gaussian kernel after averaging. In this work, we analyze the bias and the variance of the kernel approximation based on orthogonal random features which makes use of Haar orthogonal matrices. We provide explicit expressions for these quantities using normalized Bessel functions and derive sharp exponential bounds supporting the view that orthogonal random features are more informative than random Fourier features.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#20989;&#25968;&#24191;&#20041;&#35268;&#33539;&#20856;&#33539;&#30456;&#20851;&#20998;&#26512;&#65288;FGCCA&#65289;&#30340;&#26032;&#26694;&#26550;&#65292;&#21487;&#20197;&#29992;&#20110;&#25506;&#31350;&#22810;&#20010;&#20849;&#21516;&#35266;&#23519;&#21040;&#30340;&#38543;&#26426;&#36807;&#31243;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;&#35813;&#26694;&#26550;&#23545;&#31232;&#30095;&#21644;&#19981;&#35268;&#21017;&#35266;&#27979;&#25968;&#25454;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#36125;&#21494;&#26031;&#26041;&#27861;&#26469;&#20272;&#35745;&#20856;&#33539;&#32452;&#20214;&#12290;&#21516;&#26102;&#65292;&#36824;&#25193;&#23637;&#20102;&#26694;&#26550;&#65292;&#20801;&#35768;&#23558;&#21333;&#21464;&#37327;&#25110;&#22810;&#21464;&#37327;&#21709;&#24212;&#25972;&#21512;&#21040;&#20998;&#26512;&#20013;&#65292;&#20026;&#39044;&#27979;&#24212;&#29992;&#25552;&#20379;&#20102;&#21487;&#33021;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.07330</link><description>&lt;p&gt;
&#29992;&#20110;&#30740;&#31350;&#22810;&#20010;&#32437;&#21521;&#21464;&#37327;&#30340;&#20989;&#25968;&#24191;&#20041;&#35268;&#33539;&#20856;&#33539;&#30456;&#20851;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Functional Generalized Canonical Correlation Analysis for studying multiple longitudinal variables. (arXiv:2310.07330v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07330
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#20989;&#25968;&#24191;&#20041;&#35268;&#33539;&#20856;&#33539;&#30456;&#20851;&#20998;&#26512;&#65288;FGCCA&#65289;&#30340;&#26032;&#26694;&#26550;&#65292;&#21487;&#20197;&#29992;&#20110;&#25506;&#31350;&#22810;&#20010;&#20849;&#21516;&#35266;&#23519;&#21040;&#30340;&#38543;&#26426;&#36807;&#31243;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;&#35813;&#26694;&#26550;&#23545;&#31232;&#30095;&#21644;&#19981;&#35268;&#21017;&#35266;&#27979;&#25968;&#25454;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#36125;&#21494;&#26031;&#26041;&#27861;&#26469;&#20272;&#35745;&#20856;&#33539;&#32452;&#20214;&#12290;&#21516;&#26102;&#65292;&#36824;&#25193;&#23637;&#20102;&#26694;&#26550;&#65292;&#20801;&#35768;&#23558;&#21333;&#21464;&#37327;&#25110;&#22810;&#21464;&#37327;&#21709;&#24212;&#25972;&#21512;&#21040;&#20998;&#26512;&#20013;&#65292;&#20026;&#39044;&#27979;&#24212;&#29992;&#25552;&#20379;&#20102;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#20989;&#25968;&#24191;&#20041;&#35268;&#33539;&#20856;&#33539;&#30456;&#20851;&#20998;&#26512;&#65288;FGCCA&#65289;&#65292;&#29992;&#20110;&#25506;&#31350;&#22810;&#20010;&#20849;&#21516;&#35266;&#23519;&#21040;&#30340;&#38543;&#26426;&#36807;&#31243;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;&#35813;&#26694;&#26550;&#22522;&#20110;&#22810;&#21306;&#22359;&#27491;&#21017;&#21270;&#24191;&#20041;&#35268;&#33539;&#20856;&#33539;&#30456;&#20851;&#20998;&#26512;&#65288;RGCCA&#65289;&#26694;&#26550;&#12290;&#23427;&#23545;&#31232;&#30095;&#21644;&#19981;&#35268;&#21017;&#35266;&#27979;&#25968;&#25454;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#36866;&#29992;&#20110;&#35768;&#22810;&#22330;&#26223;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#27714;&#35299;&#36807;&#31243;&#30340;&#21333;&#35843;&#24615;&#36136;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#26041;&#27861;&#26469;&#20272;&#35745;&#20856;&#33539;&#32452;&#20214;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#35813;&#26694;&#26550;&#30340;&#25193;&#23637;&#65292;&#20801;&#35768;&#23558;&#21333;&#21464;&#37327;&#25110;&#22810;&#21464;&#37327;&#21709;&#24212;&#25972;&#21512;&#21040;&#20998;&#26512;&#20013;&#65292;&#20026;&#39044;&#27979;&#24212;&#29992;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;&#25105;&#20204;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#35780;&#20272;&#20102;&#35813;&#26041;&#27861;&#30340;&#25928;&#29575;&#65292;&#24182;&#22312;&#19968;&#20010;&#32437;&#21521;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#19968;&#20010;&#24212;&#29992;&#26696;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce Functional Generalized Canonical Correlation Analysis (FGCCA), a new framework for exploring associations between multiple random processes observed jointly. The framework is based on the multiblock Regularized Generalized Canonical Correlation Analysis (RGCCA) framework. It is robust to sparsely and irregularly observed data, making it applicable in many settings. We establish the monotonic property of the solving procedure and introduce a Bayesian approach for estimating canonical components. We propose an extension of the framework that allows the integration of a univariate or multivariate response into the analysis, paving the way for predictive applications. We evaluate the method's efficiency in simulation studies and present a use case on a longitudinal dataset.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#21521;&#37327;&#20540;&#39640;&#26031;&#36807;&#31243;&#30340;&#24207;&#36143;&#23454;&#39564;&#35774;&#35745;&#31574;&#30053;&#22312;&#38598;&#21512;&#20272;&#35745;&#20013;&#30340;&#19968;&#33268;&#24615;&#65292;&#36890;&#36807;&#23558;&#24050;&#26377;&#30340;&#32467;&#26524;&#25512;&#24191;&#21040;&#21521;&#37327;&#20540;&#24773;&#20917;&#65292;&#35299;&#20915;&#20102;&#20266;&#36870;&#26144;&#23556;&#30340;&#19981;&#36830;&#32493;&#24615;&#24102;&#26469;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.07315</link><description>&lt;p&gt;
&#22522;&#20110;&#21521;&#37327;&#20540;&#39640;&#26031;&#36807;&#31243;&#30340;&#24207;&#36143;&#23454;&#39564;&#35774;&#35745;&#31574;&#30053;&#22312;&#38598;&#21512;&#20272;&#35745;&#20013;&#30340;&#19968;&#33268;&#24615;
&lt;/p&gt;
&lt;p&gt;
Consistency of some sequential experimental design strategies for excursion set estimation based on vector-valued Gaussian processes. (arXiv:2310.07315v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07315
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#21521;&#37327;&#20540;&#39640;&#26031;&#36807;&#31243;&#30340;&#24207;&#36143;&#23454;&#39564;&#35774;&#35745;&#31574;&#30053;&#22312;&#38598;&#21512;&#20272;&#35745;&#20013;&#30340;&#19968;&#33268;&#24615;&#65292;&#36890;&#36807;&#23558;&#24050;&#26377;&#30340;&#32467;&#26524;&#25512;&#24191;&#21040;&#21521;&#37327;&#20540;&#24773;&#20917;&#65292;&#35299;&#20915;&#20102;&#20266;&#36870;&#26144;&#23556;&#30340;&#19981;&#36830;&#32493;&#24615;&#24102;&#26469;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#23545;&#20110;&#27493;&#36827;&#24335;&#19981;&#30830;&#23450;&#24615;&#20943;&#23569;&#24207;&#36143;&#23454;&#39564;&#35774;&#35745;&#31574;&#30053;&#22312;&#21521;&#37327;&#20540;&#24773;&#20917;&#19979;&#30340;&#19968;&#33268;&#24615;&#32467;&#26524;&#65292;&#36825;&#20123;&#32467;&#26524;&#24314;&#31435;&#22312;&#12298;&#20851;&#20110;&#39640;&#26031;&#36807;&#31243;&#22522;&#20110;&#24207;&#36143;&#23454;&#39564;&#35774;&#35745;&#30340;&#36229;&#32423;&#38789;&#26041;&#27861;&#65292;Bernoulli 25, 2019&#12299;&#19968;&#25991;&#20013;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23601;&#32039;&#33268;&#32034;&#24341;&#38598;&#30340;&#24773;&#20917;&#19979;&#65292;&#38416;&#26126;&#20102;&#36830;&#32493;&#39640;&#26031;&#36807;&#31243;&#19982;&#36830;&#32493;&#20989;&#25968;Banach&#31354;&#38388;&#19978;&#30340;&#39640;&#26031;&#27979;&#24230;&#20043;&#38388;&#30340;&#32852;&#31995;&#22914;&#20309;&#25512;&#24191;&#21040;&#21521;&#37327;&#20540;&#24773;&#20917;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#21487;&#20197;&#36731;&#26494;&#22320;&#25512;&#24191;&#19968;&#20123;&#19978;&#36848;&#25991;&#29486;&#20013;&#30340;&#27010;&#24565;&#21644;&#24615;&#36136;&#12290;&#28982;&#32780;&#65292;&#21521;&#37327;&#20540;&#24773;&#20917;&#23545;&#20110;&#19968;&#20123;&#32467;&#26524;&#30830;&#23454;&#22686;&#21152;&#20102;&#22797;&#26434;&#24615;&#65292;&#20027;&#35201;&#26159;&#30001;&#20110;&#20266;&#36870;&#26144;&#23556;&#30340;&#19981;&#36830;&#32493;&#24615;&#24433;&#21709;&#20102;&#26377;&#38480;&#20010;&#28857;&#35266;&#23519;&#30340;&#26465;&#20214;&#22343;&#20540;&#21644;&#21327;&#26041;&#24046;&#20989;&#25968;&#12290;&#25105;&#20204;&#23558;&#33719;&#24471;&#30340;&#32467;&#26524;&#24212;&#29992;&#20110;&#38598;&#25104;&#20271;&#21162;&#21033;&#26041;&#24046;&#21644;&#26399;&#26395;&#27979;&#24230;&#26041;&#24046;&#30340;&#19981;&#30830;&#23450;&#24615;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We tackle the extension to the vector-valued case of consistency results for Stepwise Uncertainty Reduction sequential experimental design strategies established in [Bect et al., A supermartingale approach to Gaussian process based sequential design of experiments, Bernoulli 25, 2019]. This lead us in the first place to clarify, assuming a compact index set, how the connection between continuous Gaussian processes and Gaussian measures on the Banach space of continuous functions carries over to vector-valued settings. From there, a number of concepts and properties from the aforementioned paper can be readily extended. However, vector-valued settings do complicate things for some results, mainly due to the lack of continuity for the pseudo-inverse mapping that affects the conditional mean and covariance function given finitely many pointwise observations. We apply obtained results to the Integrated Bernoulli Variance and the Expected Measure Variance uncertainty functionals employed in
&lt;/p&gt;</description></item><item><title>METRO&#26159;&#19968;&#20010;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#21033;&#29992;&#26368;&#23567;&#27169;&#26495;&#36827;&#34892;&#21453;&#24212;&#39044;&#27979;&#65292;&#35299;&#20915;&#20102;&#28335;&#28304;&#39044;&#27979;&#20013;&#30340;&#35745;&#31639;&#24320;&#38144;&#22823;&#21644;&#35299;&#37322;&#24615;&#24046;&#30340;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.07313</link><description>&lt;p&gt;
&#29992;&#20110;&#39640;&#25928;&#20934;&#30830;&#30340;&#28335;&#28304;&#39044;&#27979;&#30340;&#20998;&#23376;&#32534;&#36753;&#27169;&#26495;
&lt;/p&gt;
&lt;p&gt;
Molecule-Edit Templates for Efficient and Accurate Retrosynthesis Prediction. (arXiv:2310.07313v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07313
&lt;/p&gt;
&lt;p&gt;
METRO&#26159;&#19968;&#20010;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#21033;&#29992;&#26368;&#23567;&#27169;&#26495;&#36827;&#34892;&#21453;&#24212;&#39044;&#27979;&#65292;&#35299;&#20915;&#20102;&#28335;&#28304;&#39044;&#27979;&#20013;&#30340;&#35745;&#31639;&#24320;&#38144;&#22823;&#21644;&#35299;&#37322;&#24615;&#24046;&#30340;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28335;&#28304;&#28041;&#21450;&#30830;&#23450;&#20174;&#31616;&#21333;&#21069;&#20307;&#21512;&#25104;&#22797;&#26434;&#20998;&#23376;&#30340;&#19968;&#31995;&#21015;&#21453;&#24212;&#12290;&#30001;&#20110;&#36825;&#22312;&#26377;&#26426;&#21270;&#23398;&#20013;&#26159;&#19968;&#20010;&#25361;&#25112;&#65292;&#26426;&#22120;&#23398;&#20064;&#25552;&#20379;&#20102;&#35299;&#20915;&#26041;&#26696;&#65292;&#29305;&#21035;&#26159;&#29992;&#20110;&#39044;&#27979;&#32473;&#23450;&#30446;&#26631;&#20998;&#23376;&#30340;&#21487;&#33021;&#21453;&#24212;&#24213;&#29289;&#12290;&#36825;&#20123;&#35299;&#20915;&#26041;&#26696;&#20027;&#35201;&#20998;&#20026;&#22522;&#20110;&#27169;&#26495;&#21644;&#22522;&#20110;&#38750;&#27169;&#26495;&#20004;&#31867;&#12290;&#21069;&#32773;&#39640;&#25928;&#20294;&#20381;&#36182;&#20110;&#22823;&#37327;&#39044;&#23450;&#20041;&#30340;&#21453;&#24212;&#27169;&#24335;&#65292;&#32780;&#21518;&#32773;&#34429;&#28982;&#26356;&#28789;&#27963;&#65292;&#20294;&#35745;&#31639;&#24320;&#38144;&#22823;&#19988;&#35299;&#37322;&#24615;&#36739;&#24046;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;METRO&#65288;&#29992;&#20110;&#28335;&#28304;&#21512;&#25104;&#30340;&#20998;&#23376;&#32534;&#36753;&#27169;&#26495;&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#21033;&#29992;&#26368;&#23567;&#27169;&#26495;&#36827;&#34892;&#21453;&#24212;&#39044;&#27979;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#31616;&#21270;&#20102;&#21453;&#24212;&#27169;&#24335;&#65292;&#20943;&#23569;&#20102;&#35745;&#31639;&#24320;&#38144;&#65292;&#24182;&#22312;&#26631;&#20934;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Retrosynthesis involves determining a sequence of reactions to synthesize complex molecules from simpler precursors. As this poses a challenge in organic chemistry, machine learning has offered solutions, particularly for predicting possible reaction substrates for a given target molecule. These solutions mainly fall into template-based and template-free categories. The former is efficient but relies on a vast set of predefined reaction patterns, while the latter, though more flexible, can be computationally intensive and less interpretable. To address these issues, we introduce METRO (Molecule-Edit Templates for RetrOsynthesis), a machine-learning model that predicts reactions using minimal templates - simplified reaction patterns capturing only essential molecular changes - reducing computational overhead and achieving state-of-the-art results on standard benchmarks.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#22635;&#34917;&#20102;Sharpness-Aware Minimization&#65288;SAM&#65289;&#30456;&#23545;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#19968;&#23450;&#25968;&#25454;&#27169;&#22411;&#21644;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20013;&#27867;&#21270;&#26356;&#22909;&#30340;&#31354;&#30333;&#65292;&#35299;&#37322;&#20102;SAM&#30340;&#20248;&#21183;&#65292;&#23588;&#20854;&#26159;&#22312;&#26089;&#26399;&#38454;&#27573;&#38450;&#27490;&#22122;&#22768;&#23398;&#20064;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.07269</link><description>&lt;p&gt;
&#20026;&#20160;&#20040;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#27604;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26356;&#22909;&#22320;&#25512;&#24191;&#65311;(arXiv:2310.07269v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
Why Does Sharpness-Aware Minimization Generalize Better Than SGD?. (arXiv:2310.07269v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07269
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#22635;&#34917;&#20102;Sharpness-Aware Minimization&#65288;SAM&#65289;&#30456;&#23545;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#19968;&#23450;&#25968;&#25454;&#27169;&#22411;&#21644;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20013;&#27867;&#21270;&#26356;&#22909;&#30340;&#31354;&#30333;&#65292;&#35299;&#37322;&#20102;SAM&#30340;&#20248;&#21183;&#65292;&#23588;&#20854;&#26159;&#22312;&#26089;&#26399;&#38454;&#27573;&#38450;&#27490;&#22122;&#22768;&#23398;&#20064;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#25311;&#21512;&#30340;&#25361;&#25112;&#22312;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#65292;&#23427;&#25351;&#30340;&#26159;&#27169;&#22411;&#35760;&#24518;&#35757;&#32451;&#25968;&#25454;&#65292;&#20294;&#22312;&#27979;&#35797;&#25968;&#25454;&#19978;&#26080;&#27861;&#25512;&#24191;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#65288;SAM&#65289;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#23384;&#22312;&#26631;&#31614;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#25913;&#21892;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#38750;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#21644;&#20998;&#31867;&#20219;&#21153;&#30340;&#24773;&#20917;&#19979;&#65292;SAM&#30340;&#24037;&#20316;&#26041;&#24335;&#20173;&#28982;&#32570;&#20047;&#28145;&#20837;&#29702;&#35299;&#12290;&#26412;&#25991;&#36890;&#36807;&#23637;&#31034;&#20026;&#20160;&#20040;&#22312;&#29305;&#23450;&#25968;&#25454;&#27169;&#22411;&#21644;&#20004;&#23618;&#21367;&#31215;ReLU&#32593;&#32476;&#20013;&#65292;SAM&#27604;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26356;&#22909;&#22320;&#25512;&#24191;&#65292;&#26469;&#24357;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#25105;&#20204;&#25152;&#30740;&#31350;&#38382;&#39064;&#30340;&#25439;&#22833;&#26223;&#35266;&#26159;&#38750;&#20809;&#28369;&#30340;&#65292;&#22240;&#27492;&#30446;&#21069;&#20851;&#20110;SAM&#25104;&#21151;&#30340;&#35299;&#37322;&#22522;&#20110;Hessian&#20449;&#24687;&#26159;&#19981;&#36275;&#22815;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#35299;&#37322;&#20102;SAM&#30340;&#20248;&#21183;&#65292;&#29305;&#21035;&#26159;&#23427;&#22312;&#26089;&#26399;&#38454;&#27573;&#38450;&#27490;&#20102;&#22122;&#22768;&#23398;&#20064;&#30340;&#33021;&#21147;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The challenge of overfitting, in which the model memorizes the training data and fails to generalize to test data, has become increasingly significant in the training of large neural networks. To tackle this challenge, Sharpness-Aware Minimization (SAM) has emerged as a promising training method, which can improve the generalization of neural networks even in the presence of label noise. However, a deep understanding of how SAM works, especially in the setting of nonlinear neural networks and classification tasks, remains largely missing. This paper fills this gap by demonstrating why SAM generalizes better than Stochastic Gradient Descent (SGD) for a certain data model and two-layer convolutional ReLU networks. The loss landscape of our studied problem is nonsmooth, thus current explanations for the success of SAM based on the Hessian information are insufficient. Our result explains the benefits of SAM, particularly its ability to prevent noise learning in the early stages, thereby f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20195;&#29702;&#27169;&#22411;&#29992;&#20110;&#39044;&#27979;&#32467;&#26500;&#20013;&#35010;&#32441;&#30340;&#25193;&#23637;&#65292;&#24182;&#25104;&#21151;&#22320;&#32534;&#30721;&#20102;&#19981;&#21516;&#30340;&#38543;&#26426;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#12290;&#35813;&#27169;&#22411;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#27169;&#22411;&#65292;&#33021;&#22815;&#29983;&#25104;&#20808;&#39564;&#20998;&#24067;&#29992;&#20110;&#36125;&#21494;&#26031;&#32467;&#26500;&#20581;&#24247;&#30417;&#27979;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2310.07241</link><description>&lt;p&gt;
&#32467;&#26500;&#20581;&#24247;&#30417;&#27979;&#24212;&#29992;&#20013;&#30340;&#38543;&#26426;&#35010;&#32441;&#25193;&#23637;&#36807;&#31243;&#30340;&#20195;&#29702;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Surrogate modeling for stochastic crack growth processes in structural health monitoring applications. (arXiv:2310.07241v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07241
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20195;&#29702;&#27169;&#22411;&#29992;&#20110;&#39044;&#27979;&#32467;&#26500;&#20013;&#35010;&#32441;&#30340;&#25193;&#23637;&#65292;&#24182;&#25104;&#21151;&#22320;&#32534;&#30721;&#20102;&#19981;&#21516;&#30340;&#38543;&#26426;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#12290;&#35813;&#27169;&#22411;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#27169;&#22411;&#65292;&#33021;&#22815;&#29983;&#25104;&#20808;&#39564;&#20998;&#24067;&#29992;&#20110;&#36125;&#21494;&#26031;&#32467;&#26500;&#20581;&#24247;&#30417;&#27979;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30130;&#21171;&#35010;&#32441;&#25193;&#23637;&#26159;&#37329;&#23646;&#32467;&#26500;&#20013;&#26368;&#24120;&#35265;&#30340;&#19968;&#31181;&#30772;&#22351;&#31867;&#22411;&#65292;&#23545;&#20854;&#21487;&#38752;&#24615;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#26368;&#36817;&#22312;&#32467;&#26500;&#20581;&#24247;&#30417;&#27979;&#39046;&#22495;&#30340;&#36827;&#23637;&#20419;&#20351;&#20351;&#29992;&#32467;&#26500;&#21709;&#24212;&#25968;&#25454;&#26469;&#39044;&#27979;&#19981;&#30830;&#23450;&#26465;&#20214;&#19979;&#26410;&#26469;&#30340;&#35010;&#32441;&#25193;&#23637;&#65292;&#20197;&#23454;&#29616;&#21521;&#39044;&#27979;&#24615;&#32500;&#20462;&#30340;&#36807;&#28193;&#12290;&#20934;&#30830;&#22320;&#34920;&#31034;&#38543;&#26426;&#35010;&#32441;&#25193;&#23637;&#36807;&#31243;&#20013;&#19981;&#21516;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#26159;&#19968;&#39033;&#38750;&#24120;&#22256;&#38590;&#30340;&#20219;&#21153;&#12290;&#26412;&#30740;&#31350;&#22312;&#22522;&#20110;&#29289;&#29702;&#27169;&#22411;&#30340;&#38543;&#26426;&#35010;&#32441;&#25193;&#23637;&#24314;&#27169;&#30340;&#22522;&#30784;&#19978;&#36827;&#34892;&#20102;&#25506;&#32034;&#65292;&#32771;&#34385;&#20102;&#26448;&#26009;&#21644;&#36733;&#33655;&#30456;&#20851;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#26412;&#25991;&#26088;&#22312;&#26500;&#24314;&#35745;&#31639;&#25928;&#29575;&#39640;&#12289;&#27010;&#29575;&#20195;&#29702;&#27169;&#22411;&#65292;&#33021;&#22815;&#25104;&#21151;&#22320;&#32534;&#30721;&#36825;&#20123;&#19981;&#21516;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#12290;&#37319;&#29992;&#20102;&#21463;&#28508;&#21464;&#37327;&#24314;&#27169;&#21551;&#21457;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#27169;&#22411;&#20351;&#20195;&#29702;&#27169;&#22411;&#21487;&#20197;&#29992;&#20110;&#20026;&#19981;&#21516;&#30340;&#36125;&#21494;&#26031;&#32467;&#26500;&#20581;&#24247;&#30417;&#27979;&#20219;&#21153;&#29983;&#25104;&#20808;&#39564;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fatigue crack growth is one of the most common types of deterioration in metal structures with significant implications on their reliability. Recent advances in Structural Health Monitoring (SHM) have motivated the use of structural response data to predict future crack growth under uncertainty, in order to enable a transition towards predictive maintenance. Accurately representing different sources of uncertainty in stochastic crack growth (SCG) processes is a non-trivial task. The present work builds on previous research on physics-based SCG modeling under both material and load-related uncertainty. The aim here is to construct computationally efficient, probabilistic surrogate models for SCG processes that successfully encode these different sources of uncertainty. An approach inspired by latent variable modeling is employed that utilizes Gaussian Process (GP) regression models to enable the surrogates to be used to generate prior distributions for different Bayesian SHM tasks as th
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#28151;&#21512;&#40654;&#26364;&#25193;&#25955;&#36807;&#31243;&#30340;&#21407;&#21017;&#24615;&#26694;&#26550;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27969;&#24418;&#19978;&#26500;&#24314;&#29983;&#25104;&#36807;&#31243;&#30340;&#26041;&#27861;&#65292;&#19982;&#29616;&#26377;&#30340;&#29983;&#25104;&#27169;&#22411;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#25928;&#29575;&#21644;&#26356;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.07216</link><description>&lt;p&gt;
&#22312;&#27969;&#24418;&#19978;&#36890;&#36807;&#40654;&#26364;&#25193;&#25955;&#36807;&#31243;&#30340;&#28151;&#21512;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Generative Modeling on Manifolds Through Mixture of Riemannian Diffusion Processes. (arXiv:2310.07216v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07216
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28151;&#21512;&#40654;&#26364;&#25193;&#25955;&#36807;&#31243;&#30340;&#21407;&#21017;&#24615;&#26694;&#26550;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27969;&#24418;&#19978;&#26500;&#24314;&#29983;&#25104;&#36807;&#31243;&#30340;&#26041;&#27861;&#65292;&#19982;&#29616;&#26377;&#30340;&#29983;&#25104;&#27169;&#22411;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#25928;&#29575;&#21644;&#26356;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#38750;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#24314;&#27169;&#25968;&#25454;&#30340;&#20998;&#24067;&#23545;&#20110;&#26469;&#33258;&#19981;&#21516;&#31185;&#23398;&#39046;&#22495;&#30340;&#35768;&#22810;&#24212;&#29992;&#37117;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#27969;&#24418;&#19978;&#30340;&#29983;&#25104;&#27169;&#22411;&#23384;&#22312;&#30528;&#35745;&#31639;&#22797;&#26434;&#30340;&#25955;&#24230;&#25110;&#20381;&#36182;&#20110;&#28909;&#26680;&#30340;&#36817;&#20284;&#30340;&#38382;&#39064;&#12290;&#36825;&#20123;&#38480;&#21046;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#31616;&#21333;&#20960;&#20309;&#24418;&#29366;&#19978;&#30340;&#36866;&#29992;&#24615;&#65292;&#24182;&#38459;&#30861;&#20102;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#40654;&#26364;&#25193;&#25955;&#28151;&#21512;&#27169;&#22411;&#65292;&#36825;&#26159;&#19968;&#20010;&#22312;&#27969;&#24418;&#19978;&#26500;&#24314;&#29983;&#25104;&#36807;&#31243;&#30340;&#21407;&#21017;&#24615;&#26694;&#26550;&#65292;&#23427;&#26159;&#19968;&#32452;&#20197;&#31471;&#28857;&#26465;&#20214;&#25193;&#25955;&#36807;&#31243;&#20316;&#20026;&#28151;&#21512;&#30340;&#29983;&#25104;&#36807;&#31243;&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#20808;&#21069;&#25193;&#25955;&#27169;&#22411;&#30340;&#21435;&#22122;&#26041;&#27861;&#65292;&#23545;&#20110;&#36825;&#20123;&#27169;&#22411;&#65292;&#29983;&#25104;&#36807;&#31243;&#30340;&#29305;&#24615;&#26159;&#23427;&#30340;&#28418;&#31227;&#23548;&#21521;&#19982;&#27969;&#24418;&#30340;&#20960;&#20309;&#24418;&#29366;&#30456;&#23545;&#24212;&#30340;&#26368;&#21487;&#33021;&#30340;&#32456;&#28857;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#39640;&#25928;&#30340;&#35757;&#32451;&#30446;&#26631;&#65292;&#29992;&#20110;&#23398;&#20064;&#28151;&#21512;&#36807;&#31243;&#65292;&#23427;&#21487;&#20197;&#30452;&#25509;&#24212;&#29992;&#20110;&#19968;&#33324;&#27969;&#24418;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#34920;&#29616;&#24471;&#24456;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning the distribution of data on Riemannian manifolds is crucial for modeling data from non-Euclidean space, which is required by many applications from diverse scientific fields. Yet, existing generative models on manifolds suffer from expensive divergence computation or rely on approximations of heat kernel. These limitations restrict their applicability to simple geometries and hinder scalability to high dimensions. In this work, we introduce the Riemannian Diffusion Mixture, a principled framework for building a generative process on manifolds as a mixture of endpoint-conditioned diffusion processes instead of relying on the denoising approach of previous diffusion models, for which the generative process is characterized by its drift guiding toward the most probable endpoint with respect to the geometry of the manifold. We further propose a simple yet efficient training objective for learning the mixture process, that is readily applicable to general manifolds. Our method outp
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#28145;&#24230;&#21644;&#23485;&#24230;&#23545;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#24433;&#21709;&#65292;&#32467;&#26524;&#34920;&#26126;&#21482;&#26377;&#28145;&#24230;&#36235;&#36817;&#26080;&#31351;&#22823;&#30340;&#31070;&#32463;&#32593;&#32476;&#25165;&#21487;&#33021;&#36798;&#21040;&#27604;&#29109;&#25968;&#26356;&#22909;&#30340;&#36895;&#24230;&#65292;&#32780;&#22266;&#23450;&#28145;&#24230;&#24182;&#35753;&#23485;&#24230;&#36235;&#36817;&#26080;&#31351;&#22823;&#21017;&#27809;&#26377;&#25910;&#30410;&#12290;</title><link>http://arxiv.org/abs/2310.07190</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#65306;&#28145;&#23618;&#12289;&#27973;&#23618;&#36824;&#26159;&#20013;&#38388;&#23618;&#65311;
&lt;/p&gt;
&lt;p&gt;
Neural networks: deep, shallow, or in between?. (arXiv:2310.07190v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07190
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#28145;&#24230;&#21644;&#23485;&#24230;&#23545;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#24433;&#21709;&#65292;&#32467;&#26524;&#34920;&#26126;&#21482;&#26377;&#28145;&#24230;&#36235;&#36817;&#26080;&#31351;&#22823;&#30340;&#31070;&#32463;&#32593;&#32476;&#25165;&#21487;&#33021;&#36798;&#21040;&#27604;&#29109;&#25968;&#26356;&#22909;&#30340;&#36895;&#24230;&#65292;&#32780;&#22266;&#23450;&#28145;&#24230;&#24182;&#35753;&#23485;&#24230;&#36235;&#36817;&#26080;&#31351;&#22823;&#21017;&#27809;&#26377;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#27979;&#37327;&#36890;&#36807;&#23485;&#24230;&#20026;W&#12289;&#28145;&#24230;&#20026;l&#30340;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#20197;&#21450;&#28385;&#36275;Lipschitz&#28608;&#27963;&#20989;&#25968;&#30340;&#36755;&#20986;&#36827;&#34892;&#36817;&#20284;&#30340;&#35823;&#24046;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#22312;&#23545;&#25968;&#22240;&#23376;&#35299;&#38500;&#65292;&#20165;&#26377;&#28145;&#24230;l&#36235;&#36817;&#26080;&#31351;&#22823;&#30340;&#31070;&#32463;&#32593;&#32476;&#25165;&#26377;&#21487;&#33021;&#36798;&#21040;&#27604;&#29109;&#25968;&#26356;&#22909;&#30340;&#36895;&#24230;&#65292;&#32780;&#22914;&#26524;&#22266;&#23450;&#28145;&#24230;&#28982;&#21518;&#35753;&#23485;&#24230;W&#36235;&#36817;&#26080;&#31351;&#22823;&#65292;&#21017;&#27809;&#26377;&#20219;&#20309;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
We give estimates from below for the error of approximation of a compact subset from a Banach space by the outputs of feed-forward neural networks with width W, depth l and Lipschitz activation functions. We show that, modulo logarithmic factors, rates better that entropy numbers' rates are possibly attainable only for neural networks for which the depth l goes to infinity, and that there is no gain if we fix the depth and let the width W go to infinity.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;Cox&#37096;&#20998;&#32447;&#24615;&#22238;&#24402;&#30340;&#26041;&#27861;&#26469;&#26500;&#24314;&#30284;&#30151;&#24739;&#32773;&#29983;&#23384;&#39044;&#27979;&#27169;&#22411;&#65292;&#36890;&#36807;&#26680;&#26426;&#22120;&#26041;&#27861;&#25551;&#36848;&#22797;&#26434;&#30340;&#29983;&#23384;&#21644;&#39044;&#27979;&#22240;&#23376;&#20851;&#31995;&#65292;&#24182;&#21033;&#29992;&#27491;&#21017;&#21270;&#21152;&#26435;&#26680;&#26426;&#22120;&#26041;&#27861;&#33258;&#21160;&#21435;&#38500;&#19981;&#30456;&#20851;&#30340;&#22240;&#23376;&#12290;&#19982;&#20854;&#20182;&#31454;&#20105;&#26041;&#27861;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#22312;&#27169;&#25311;&#20013;&#34920;&#29616;&#26368;&#22909;&#12290;</title><link>http://arxiv.org/abs/2310.07187</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;Cox&#37096;&#20998;&#32447;&#24615;&#22238;&#24402;&#65306;&#26500;&#24314;&#30284;&#30151;&#24739;&#32773;&#29983;&#23384;&#39044;&#27979;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Kernel Cox partially linear regression: building predictive models for cancer patients' survival. (arXiv:2310.07187v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07187
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;Cox&#37096;&#20998;&#32447;&#24615;&#22238;&#24402;&#30340;&#26041;&#27861;&#26469;&#26500;&#24314;&#30284;&#30151;&#24739;&#32773;&#29983;&#23384;&#39044;&#27979;&#27169;&#22411;&#65292;&#36890;&#36807;&#26680;&#26426;&#22120;&#26041;&#27861;&#25551;&#36848;&#22797;&#26434;&#30340;&#29983;&#23384;&#21644;&#39044;&#27979;&#22240;&#23376;&#20851;&#31995;&#65292;&#24182;&#21033;&#29992;&#27491;&#21017;&#21270;&#21152;&#26435;&#26680;&#26426;&#22120;&#26041;&#27861;&#33258;&#21160;&#21435;&#38500;&#19981;&#30456;&#20851;&#30340;&#22240;&#23376;&#12290;&#19982;&#20854;&#20182;&#31454;&#20105;&#26041;&#27861;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#22312;&#27169;&#25311;&#20013;&#34920;&#29616;&#26368;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30284;&#30151;&#24739;&#32773;&#30340;&#29983;&#23384;&#23384;&#22312;&#24191;&#27867;&#30340;&#24322;&#36136;&#24615;&#65292;&#20174;&#20960;&#20010;&#26376;&#21040;&#20960;&#21313;&#24180;&#19981;&#31561;&#12290;&#20026;&#20102;&#20934;&#30830;&#39044;&#27979;&#20020;&#24202;&#32467;&#26524;&#65292;&#24314;&#31435;&#19968;&#20010;&#33021;&#22815;&#23558;&#24739;&#32773;&#30340;&#20998;&#23376;&#29305;&#24449;&#19982;&#29983;&#23384;&#24773;&#20917;&#20851;&#32852;&#36215;&#26469;&#30340;&#31934;&#30830;&#39044;&#27979;&#27169;&#22411;&#33267;&#20851;&#37325;&#35201;&#12290;&#30001;&#20110;&#29983;&#23384;&#19982;&#39640;&#32500;&#20998;&#23376;&#39044;&#27979;&#22240;&#23376;&#20043;&#38388;&#23384;&#22312;&#22797;&#26434;&#30340;&#20851;&#31995;&#65292;&#21516;&#26102;&#36827;&#34892;&#38750;&#21442;&#25968;&#24314;&#27169;&#21644;&#21435;&#38500;&#19981;&#30456;&#20851;&#30340;&#39044;&#27979;&#22240;&#23376;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#26412;&#25991;&#24314;&#31435;&#20102;&#19968;&#20010;&#26680;Cox&#27604;&#20363;&#39118;&#38505;&#21322;&#21442;&#25968;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27491;&#21017;&#21270;&#21152;&#26435;&#26680;&#26426;&#22120;&#65288;RegGKM&#65289;&#26041;&#27861;&#26469;&#25311;&#21512;&#27169;&#22411;&#12290;&#25105;&#20204;&#20351;&#29992;&#26680;&#26426;&#22120;&#26041;&#27861;&#25551;&#36848;&#29983;&#23384;&#21644;&#39044;&#27979;&#22240;&#23376;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#65292;&#21516;&#26102;&#36890;&#36807;LASSO&#24809;&#32602;&#33258;&#21160;&#21435;&#38500;&#19981;&#30456;&#20851;&#30340;&#21442;&#25968;&#21644;&#38750;&#21442;&#25968;&#39044;&#27979;&#22240;&#23376;&#12290;&#20026;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#24320;&#21457;&#20102;&#19968;&#20010;&#39640;&#32500;&#31639;&#27861;&#12290;&#19982;&#27169;&#25311;&#20013;&#30340;&#20854;&#20182;&#31454;&#20105;&#26041;&#27861;&#30456;&#27604;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#24635;&#26159;&#34920;&#29616;&#26368;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Wide heterogeneity exists in cancer patients' survival, ranging from a few months to several decades. To accurately predict clinical outcomes, it is vital to build an accurate predictive model that relates patients' molecular profiles with patients' survival. With complex relationships between survival and high-dimensional molecular predictors, it is challenging to conduct non-parametric modeling and irrelevant predictors removing simultaneously. In this paper, we build a kernel Cox proportional hazards semi-parametric model and propose a novel regularized garrotized kernel machine (RegGKM) method to fit the model. We use the kernel machine method to describe the complex relationship between survival and predictors, while automatically removing irrelevant parametric and non-parametric predictors through a LASSO penalty. An efficient high-dimensional algorithm is developed for the proposed method. Comparison with other competing methods in simulation shows that the proposed method alway
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#31070;&#32463;&#25490;&#24207;&#32593;&#32476;&#65292;&#20854;&#20013;&#37319;&#29992;&#20102;&#20855;&#26377;&#26080;&#35823;&#24046;&#19988;&#21487;&#24494;&#20998;&#30340;&#20132;&#25442;&#20989;&#25968;&#65292;&#21516;&#26102;&#20351;&#29992;&#20102;&#32622;&#25442;&#31561;&#21464;Transformer&#32593;&#32476;&#26469;&#25429;&#25417;&#36755;&#20837;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#25490;&#24207;&#22522;&#20934;&#19978;&#34920;&#29616;&#20248;&#20110;&#25110;&#19982;&#22522;&#20934;&#26041;&#27861;&#30456;&#24403;&#12290;</title><link>http://arxiv.org/abs/2310.07174</link><description>&lt;p&gt;
&#20855;&#26377;&#26080;&#35823;&#24046;&#30340;&#21487;&#24494;&#20998;&#20132;&#25442;&#20989;&#25968;&#30340;&#24191;&#20041;&#31070;&#32463;&#25490;&#24207;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Generalized Neural Sorting Networks with Error-Free Differentiable Swap Functions. (arXiv:2310.07174v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07174
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#31070;&#32463;&#25490;&#24207;&#32593;&#32476;&#65292;&#20854;&#20013;&#37319;&#29992;&#20102;&#20855;&#26377;&#26080;&#35823;&#24046;&#19988;&#21487;&#24494;&#20998;&#30340;&#20132;&#25442;&#20989;&#25968;&#65292;&#21516;&#26102;&#20351;&#29992;&#20102;&#32622;&#25442;&#31561;&#21464;Transformer&#32593;&#32476;&#26469;&#25429;&#25417;&#36755;&#20837;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#25490;&#24207;&#22522;&#20934;&#19978;&#34920;&#29616;&#20248;&#20110;&#25110;&#19982;&#22522;&#20934;&#26041;&#27861;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25490;&#24207;&#26159;&#25152;&#26377;&#35745;&#31639;&#26426;&#31995;&#32479;&#30340;&#22522;&#26412;&#25805;&#20316;&#65292;&#19968;&#30452;&#26159;&#19968;&#20010;&#38271;&#26399;&#30340;&#37325;&#35201;&#30740;&#31350;&#35838;&#39064;&#12290;&#38500;&#20102;&#20256;&#32479;&#25490;&#24207;&#31639;&#27861;&#30340;&#38382;&#39064;&#34920;&#36848;&#65292;&#25105;&#20204;&#36890;&#36807;&#31070;&#32463;&#25490;&#24207;&#32593;&#32476;&#32771;&#34385;&#20102;&#26356;&#25277;&#35937;&#20294;&#20855;&#26377;&#34920;&#36798;&#21147;&#30340;&#36755;&#20837;&#65292;&#20363;&#22914;&#22810;&#20301;&#25968;&#23383;&#22270;&#20687;&#21644;&#22270;&#20687;&#29255;&#27573;&#12290;&#20026;&#20102;&#23398;&#20064;&#20174;&#39640;&#32500;&#36755;&#20837;&#21040;&#27425;&#24207;&#21464;&#37327;&#30340;&#26144;&#23556;&#65292;&#38656;&#35201;&#20445;&#35777;&#25490;&#24207;&#32593;&#32476;&#30340;&#21487;&#24494;&#20998;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#21487;&#24494;&#20998;&#30340;&#20132;&#25442;&#20989;&#25968;&#23450;&#20041;&#19968;&#20010;&#26580;&#21270;&#35823;&#24046;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#26080;&#35823;&#24046;&#30340;&#20132;&#25442;&#20989;&#25968;&#65292;&#35813;&#20989;&#25968;&#28385;&#36275;&#38750;&#20943;&#21644;&#21487;&#24494;&#20998;&#30340;&#26465;&#20214;&#12290;&#27492;&#22806;&#65292;&#37319;&#29992;&#20102;&#20855;&#26377;&#22810;&#22836;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#32622;&#25442;&#31561;&#21464;Transformer&#32593;&#32476;&#65292;&#20197;&#25429;&#25417;&#32473;&#23450;&#36755;&#20837;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#21033;&#29992;&#20854;&#33258;&#27880;&#24847;&#21147;&#30340;&#27169;&#22411;&#33021;&#21147;&#12290;&#22312;&#22810;&#26679;&#30340;&#25490;&#24207;&#22522;&#20934;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#25110;&#19982;&#22522;&#20934;&#26041;&#27861;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sorting is a fundamental operation of all computer systems, having been a long-standing significant research topic. Beyond the problem formulation of traditional sorting algorithms, we consider sorting problems for more abstract yet expressive inputs, e.g., multi-digit images and image fragments, through a neural sorting network. To learn a mapping from a high-dimensional input to an ordinal variable, the differentiability of sorting networks needs to be guaranteed. In this paper we define a softening error by a differentiable swap function, and develop an error-free swap function that holds non-decreasing and differentiability conditions. Furthermore, a permutation-equivariant Transformer network with multi-head attention is adopted to capture dependency between given inputs and also leverage its model capacity with self-attention. Experiments on diverse sorting benchmarks show that our methods perform better than or comparable to baseline methods.
&lt;/p&gt;</description></item><item><title>&#22312;&#20998;&#24067;&#24335;&#23398;&#20064;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#37327;&#23376;&#32593;&#32476;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#20351;&#29992;&#25351;&#25968;&#32423;&#36739;&#23569;&#30340;&#36890;&#20449;&#21644;&#30456;&#23545;&#36739;&#23567;&#30340;&#26102;&#38388;&#21644;&#31354;&#38388;&#22797;&#26434;&#24230;&#24320;&#38144;&#36827;&#34892;&#25512;&#29702;&#21644;&#35757;&#32451;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#23637;&#31034;&#20102;&#20855;&#26377;&#23494;&#38598;&#32463;&#20856;&#25968;&#25454;&#30340;&#36890;&#29992;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20855;&#26377;&#25351;&#25968;&#37327;&#23376;&#20248;&#21183;&#30340;&#20363;&#23376;&#12290;</title><link>http://arxiv.org/abs/2310.07136</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#23398;&#20064;&#20013;&#30340;&#25351;&#25968;&#37327;&#23376;&#36890;&#20449;&#20248;&#21183;
&lt;/p&gt;
&lt;p&gt;
Exponential Quantum Communication Advantage in Distributed Learning. (arXiv:2310.07136v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07136
&lt;/p&gt;
&lt;p&gt;
&#22312;&#20998;&#24067;&#24335;&#23398;&#20064;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#37327;&#23376;&#32593;&#32476;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#20351;&#29992;&#25351;&#25968;&#32423;&#36739;&#23569;&#30340;&#36890;&#20449;&#21644;&#30456;&#23545;&#36739;&#23567;&#30340;&#26102;&#38388;&#21644;&#31354;&#38388;&#22797;&#26434;&#24230;&#24320;&#38144;&#36827;&#34892;&#25512;&#29702;&#21644;&#35757;&#32451;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#23637;&#31034;&#20102;&#20855;&#26377;&#23494;&#38598;&#32463;&#20856;&#25968;&#25454;&#30340;&#36890;&#29992;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20855;&#26377;&#25351;&#25968;&#37327;&#23376;&#20248;&#21183;&#30340;&#20363;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#36229;&#36807;&#21333;&#20010;&#35774;&#22791;&#20869;&#23384;&#23481;&#37327;&#30340;&#22823;&#22411;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#35757;&#32451;&#21644;&#25512;&#29702;&#38656;&#35201;&#35774;&#35745;&#20998;&#24067;&#24335;&#26550;&#26500;&#65292;&#24517;&#39035;&#32771;&#34385;&#36890;&#20449;&#38480;&#21046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#37327;&#23376;&#32593;&#32476;&#19978;&#36827;&#34892;&#20998;&#24067;&#24335;&#35745;&#31639;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#25968;&#25454;&#34987;&#32534;&#30721;&#20026;&#29305;&#27530;&#30340;&#37327;&#23376;&#24577;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#35813;&#26694;&#26550;&#20869;&#30340;&#26576;&#20123;&#27169;&#22411;&#20013;&#65292;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#36827;&#34892;&#25512;&#29702;&#21644;&#35757;&#32451;&#30340;&#36890;&#20449;&#24320;&#38144;&#30456;&#23545;&#20110;&#20854;&#32463;&#20856;&#23545;&#24212;&#27169;&#22411;&#21487;&#20197;&#25351;&#25968;&#32423;&#38477;&#20302;&#65292;&#24182;&#19988;&#30456;&#23545;&#20110;&#26631;&#20934;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;&#26102;&#38388;&#21644;&#31354;&#38388;&#22797;&#26434;&#24615;&#24320;&#38144;&#30456;&#23545;&#36739;&#23567;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#20855;&#26377;&#23494;&#38598;&#32463;&#20856;&#25968;&#25454;&#30340;&#36890;&#29992;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#30340;&#24773;&#20917;&#19979;&#65292;&#26080;&#35770;&#25968;&#25454;&#32534;&#30721;&#25104;&#26412;&#22914;&#20309;&#65292;&#37117;&#20855;&#26377;&#25351;&#25968;&#37327;&#23376;&#20248;&#21183;&#30340;&#31034;&#20363;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#35813;&#31867;&#27169;&#22411;&#21487;&#20197;&#32534;&#30721;&#36755;&#20837;&#30340;&#39640;&#24230;&#38750;&#32447;&#24615;&#29305;&#24449;&#65292;&#24182;&#19988;&#23427;&#20204;&#30340;&#34920;&#36798;&#33021;&#21147;&#21576;&#25351;&#25968;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training and inference with large machine learning models that far exceed the memory capacity of individual devices necessitates the design of distributed architectures, forcing one to contend with communication constraints. We present a framework for distributed computation over a quantum network in which data is encoded into specialized quantum states. We prove that for certain models within this framework, inference and training using gradient descent can be performed with exponentially less communication compared to their classical analogs, and with relatively modest time and space complexity overheads relative to standard gradient-based methods. To our knowledge, this is the first example of exponential quantum advantage for a generic class of machine learning problems with dense classical data that holds regardless of the data encoding cost. Moreover, we show that models in this class can encode highly nonlinear features of their inputs, and their expressivity increases exponenti
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#24067;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;&#20855;&#26377;&#32479;&#35745;&#26174;&#33879;&#24615;&#30340;&#22522;&#30784;&#27169;&#22411;&#30340;&#39118;&#38505;&#12290;&#36890;&#36807;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#30456;&#23545;&#27979;&#35797;&#26041;&#27861;&#65292;&#35813;&#26694;&#26550;&#32467;&#21512;&#20102;&#19968;&#38454;&#21644;&#20108;&#38454;&#38543;&#26426;&#20248;&#21183;&#65292;&#24182;&#20511;&#37492;&#20102;&#35745;&#37327;&#32463;&#27982;&#23398;&#21644;&#25968;&#23398;&#37329;&#34701;&#20013;&#24120;&#29992;&#30340;&#24179;&#22343;&#39118;&#38505;&#27169;&#22411;&#12290;&#22312;&#32473;&#23450;&#25351;&#23450;&#24230;&#37327;&#37327;&#21270;&#30340;&#38450;&#25252;&#26639;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#39118;&#38505;&#24847;&#35782;&#30340;&#22522;&#30784;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#12290;&#21463;&#25968;&#23398;&#37329;&#34701;&#20013;&#30340;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;&#21644;&#36873;&#25321;&#29702;&#35770;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#20026;&#27599;&#20010;&#27169;&#22411;&#23450;&#20041;&#20102;&#19968;&#20010;"&#24230;&#37327;&#32452;&#21512;"&#65292;&#24182;&#26681;&#25454;&#36825;&#20123;&#32452;&#21512;&#30340;&#38543;&#26426;&#20248;&#21183;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#12290;</title><link>http://arxiv.org/abs/2310.07132</link><description>&lt;p&gt;
&#22312;&#22522;&#30784;&#27169;&#22411;&#26102;&#20195;&#30340;&#39118;&#38505;&#35780;&#20272;&#21644;&#32479;&#35745;&#26174;&#33879;&#24615;
&lt;/p&gt;
&lt;p&gt;
Risk Assessment and Statistical Significance in the Age of Foundation Models. (arXiv:2310.07132v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07132
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#24067;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;&#20855;&#26377;&#32479;&#35745;&#26174;&#33879;&#24615;&#30340;&#22522;&#30784;&#27169;&#22411;&#30340;&#39118;&#38505;&#12290;&#36890;&#36807;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#30456;&#23545;&#27979;&#35797;&#26041;&#27861;&#65292;&#35813;&#26694;&#26550;&#32467;&#21512;&#20102;&#19968;&#38454;&#21644;&#20108;&#38454;&#38543;&#26426;&#20248;&#21183;&#65292;&#24182;&#20511;&#37492;&#20102;&#35745;&#37327;&#32463;&#27982;&#23398;&#21644;&#25968;&#23398;&#37329;&#34701;&#20013;&#24120;&#29992;&#30340;&#24179;&#22343;&#39118;&#38505;&#27169;&#22411;&#12290;&#22312;&#32473;&#23450;&#25351;&#23450;&#24230;&#37327;&#37327;&#21270;&#30340;&#38450;&#25252;&#26639;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#39118;&#38505;&#24847;&#35782;&#30340;&#22522;&#30784;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#12290;&#21463;&#25968;&#23398;&#37329;&#34701;&#20013;&#30340;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;&#21644;&#36873;&#25321;&#29702;&#35770;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#20026;&#27599;&#20010;&#27169;&#22411;&#23450;&#20041;&#20102;&#19968;&#20010;"&#24230;&#37327;&#32452;&#21512;"&#65292;&#24182;&#26681;&#25454;&#36825;&#20123;&#32452;&#21512;&#30340;&#38543;&#26426;&#20248;&#21183;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#24067;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;&#20855;&#26377;&#32479;&#35745;&#26174;&#33879;&#24615;&#30340;&#22522;&#30784;&#27169;&#22411;&#30340;&#31038;&#20250;&#25216;&#26415;&#39118;&#38505;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#19968;&#31181;&#22522;&#20110;&#23454;&#38469;&#38543;&#26426;&#21464;&#37327;&#30340;&#19968;&#38454;&#21644;&#20108;&#38454;&#38543;&#26426;&#20248;&#21183;&#30340;&#26032;&#30340;&#32479;&#35745;&#30456;&#23545;&#27979;&#35797;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#36825;&#20010;&#27979;&#35797;&#20013;&#30340;&#20108;&#38454;&#32479;&#35745;&#19982;&#22312;&#35745;&#37327;&#32463;&#27982;&#23398;&#21644;&#25968;&#23398;&#37329;&#34701;&#20013;&#24120;&#29992;&#30340;&#24179;&#22343;&#39118;&#38505;&#27169;&#22411;&#30456;&#32852;&#31995;&#65292;&#29992;&#20110;&#22312;&#36873;&#25321;&#26041;&#26696;&#26102;&#24179;&#34913;&#39118;&#38505;&#21644;&#25928;&#29992;&#12290;&#21033;&#29992;&#36825;&#20010;&#26694;&#26550;&#65292;&#25105;&#20204;&#27491;&#24335;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#39118;&#38505;&#24847;&#35782;&#30340;&#22522;&#30784;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#32473;&#23450;&#30001;&#25351;&#23450;&#24230;&#37327;&#37327;&#21270;&#30340;&#38450;&#25252;&#26639;&#12290;&#21463;&#25968;&#23398;&#37329;&#34701;&#20013;&#30340;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;&#21644;&#36873;&#25321;&#29702;&#35770;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#20026;&#27599;&#20010;&#27169;&#22411;&#23450;&#20041;&#20102;&#19968;&#20010;"&#24230;&#37327;&#32452;&#21512;"&#65292;&#20316;&#20026;&#32858;&#21512;&#19968;&#31995;&#21015;&#24230;&#37327;&#30340;&#25163;&#27573;&#65292;&#24182;&#26681;&#25454;&#36825;&#20123;&#32452;&#21512;&#30340;&#38543;&#26426;&#20248;&#21183;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#12290;&#25105;&#20204;&#30340;&#27979;&#35797;&#30340;&#32479;&#35745;&#26174;&#33879;&#24615;&#22312;&#29702;&#35770;&#19978;&#30001;&#36890;&#36807;&#20013;&#24515;&#26497;&#38480;&#30340;&#28176;&#36817;&#20998;&#26512;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a distributional framework for assessing socio-technical risks of foundation models with quantified statistical significance. Our approach hinges on a new statistical relative testing based on first and second order stochastic dominance of real random variables. We show that the second order statistics in this test are linked to mean-risk models commonly used in econometrics and mathematical finance to balance risk and utility when choosing between alternatives. Using this framework, we formally develop a risk-aware approach for foundation model selection given guardrails quantified by specified metrics. Inspired by portfolio optimization and selection theory in mathematical finance, we define a \emph{metrics portfolio} for each model as a means to aggregate a collection of metrics, and perform model selection based on the stochastic dominance of these portfolios. The statistical significance of our tests is backed theoretically by an asymptotic analysis via central limit th
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#20559;&#24615;&#30340;&#25919;&#31574;&#23398;&#20064;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#21033;&#29992;&#35266;&#27979;&#25968;&#25454;&#36827;&#34892;&#25919;&#31574;&#23398;&#20064;&#65292;&#24182;&#20811;&#26381;&#20102;&#29616;&#23454;&#24773;&#22659;&#20013;&#26080;&#27861;&#28385;&#36275;&#20551;&#35774;&#30340;&#38590;&#39064;&#12290;&#35813;&#26694;&#26550;&#21033;&#29992;&#22686;&#37327;&#20542;&#21521;&#20998;&#25968;&#31574;&#30053;&#35843;&#25972;&#20542;&#21521;&#20998;&#25968;&#20540;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#24555;&#36895;&#30340;&#25910;&#25947;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.06969</link><description>&lt;p&gt;
&#26080;&#20559;&#24615;&#25919;&#31574;&#23398;&#20064;&#19982;&#35266;&#27979;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Positivity-free Policy Learning with Observational Data. (arXiv:2310.06969v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06969
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#20559;&#24615;&#30340;&#25919;&#31574;&#23398;&#20064;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#21033;&#29992;&#35266;&#27979;&#25968;&#25454;&#36827;&#34892;&#25919;&#31574;&#23398;&#20064;&#65292;&#24182;&#20811;&#26381;&#20102;&#29616;&#23454;&#24773;&#22659;&#20013;&#26080;&#27861;&#28385;&#36275;&#20551;&#35774;&#30340;&#38590;&#39064;&#12290;&#35813;&#26694;&#26550;&#21033;&#29992;&#22686;&#37327;&#20542;&#21521;&#20998;&#25968;&#31574;&#30053;&#35843;&#25972;&#20542;&#21521;&#20998;&#25968;&#20540;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#24555;&#36895;&#30340;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#35266;&#27979;&#25968;&#25454;&#36827;&#34892;&#25919;&#31574;&#23398;&#20064;&#22312;&#21508;&#20010;&#39046;&#22495;&#37117;&#38750;&#24120;&#37325;&#35201;&#65292;&#20854;&#30446;&#26631;&#26159;&#23398;&#20064;&#26368;&#20248;&#30340;&#22788;&#29702;&#20998;&#37197;&#31574;&#30053;&#65292;&#21516;&#26102;&#28385;&#36275;&#29305;&#23450;&#30340;&#32422;&#26463;&#26465;&#20214;&#65292;&#22914;&#20844;&#24179;&#24615;&#12289;&#39044;&#31639;&#21644;&#31616;&#21333;&#24615;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26080;&#20559;&#24615;&#65288;&#38543;&#26426;&#65289;&#25919;&#31574;&#23398;&#20064;&#26694;&#26550;&#65292;&#26088;&#22312;&#24212;&#23545;&#29616;&#23454;&#24773;&#22659;&#20013;&#26080;&#27861;&#28385;&#36275;&#20551;&#35774;&#30340;&#22256;&#22659;&#12290;&#35813;&#26694;&#26550;&#21033;&#29992;&#22686;&#37327;&#20542;&#21521;&#20998;&#25968;&#31574;&#30053;&#26469;&#35843;&#25972;&#20542;&#21521;&#20998;&#25968;&#20540;&#65292;&#32780;&#19981;&#26159;&#32473;&#27835;&#30103;&#20998;&#37197;&#22266;&#23450;&#20540;&#12290;&#25105;&#20204;&#23545;&#36825;&#20123;&#22686;&#37327;&#20542;&#21521;&#20998;&#25968;&#31574;&#30053;&#36827;&#34892;&#20102;&#34920;&#24449;&#65292;&#24182;&#24314;&#31435;&#20102;&#35782;&#21035;&#26465;&#20214;&#65292;&#21033;&#29992;&#21322;&#21442;&#25968;&#25928;&#29575;&#29702;&#35770;&#25552;&#20986;&#20102;&#33021;&#22815;&#23454;&#29616;&#24555;&#36895;&#25910;&#25947;&#29575;&#30340;&#39640;&#25928;&#20272;&#35745;&#22120;&#65292;&#21363;&#20351;&#26159;&#19982;&#20808;&#36827;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#38598;&#25104;&#22312;&#19968;&#36215;&#12290;&#26412;&#25991;&#23545;&#25919;&#31574;&#23398;&#20064;&#30340;&#29702;&#35770;&#20445;&#35777;&#36827;&#34892;&#20102;&#28145;&#20837;&#25506;&#35752;&#65292;&#24182;&#39564;&#35777;&#20102;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Policy learning utilizing observational data is pivotal across various domains, with the objective of learning the optimal treatment assignment policy while adhering to specific constraints such as fairness, budget, and simplicity. This study introduces a novel positivity-free (stochastic) policy learning framework designed to address the challenges posed by the impracticality of the positivity assumption in real-world scenarios. This framework leverages incremental propensity score policies to adjust propensity score values instead of assigning fixed values to treatments. We characterize these incremental propensity score policies and establish identification conditions, employing semiparametric efficiency theory to propose efficient estimators capable of achieving rapid convergence rates, even when integrated with advanced machine learning algorithms. This paper provides a thorough exploration of the theoretical guarantees associated with policy learning and validates the proposed fr
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#21046;&#36896;&#19994;&#30340;AI&#23413;&#21270;&#30340;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#38598;&#25104;&#27963;&#36291;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#32447;&#26356;&#26032;AI&#27169;&#22411;&#30340;&#26041;&#24335;&#26469;&#25345;&#32493;&#25913;&#36827;&#20915;&#31574;&#12290;&#30740;&#31350;&#37319;&#29992;&#20102;&#19968;&#31181;&#21517;&#20026;CBEAL&#30340;&#38598;&#25104;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#22320;&#25351;&#23548;&#25968;&#25454;&#33719;&#21462;&#65292;&#23454;&#29616;&#20102;&#25968;&#25454;&#25928;&#26524;&#30340;&#26368;&#23567;&#21270;&#12290;</title><link>http://arxiv.org/abs/2310.06306</link><description>&lt;p&gt;
&#38754;&#21521;&#21046;&#36896;&#19994;&#30340;AI&#23413;&#21270;&#30340;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#38598;&#25104;&#27963;&#36291;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Ensemble Active Learning by Contextual Bandits for AI Incubation in Manufacturing. (arXiv:2310.06306v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06306
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#21046;&#36896;&#19994;&#30340;AI&#23413;&#21270;&#30340;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#38598;&#25104;&#27963;&#36291;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#32447;&#26356;&#26032;AI&#27169;&#22411;&#30340;&#26041;&#24335;&#26469;&#25345;&#32493;&#25913;&#36827;&#20915;&#31574;&#12290;&#30740;&#31350;&#37319;&#29992;&#20102;&#19968;&#31181;&#21517;&#20026;CBEAL&#30340;&#38598;&#25104;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#22320;&#25351;&#23548;&#25968;&#25454;&#33719;&#21462;&#65292;&#23454;&#29616;&#20102;&#25968;&#25454;&#25928;&#26524;&#30340;&#26368;&#23567;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24037;&#19994;&#29289;&#32852;&#32593;&#31995;&#32479;&#20013;&#30340;&#22312;&#32447;&#24863;&#30693;&#21644;&#35745;&#31639;&#36164;&#28304;&#20419;&#36827;&#20102;&#22522;&#20110;AI&#30340;&#20915;&#31574;&#12290;&#28982;&#32780;&#65292;&#25968;&#25454;&#36136;&#37327;&#38382;&#39064;&#65292;&#22914;&#31867;&#21035;&#19981;&#24179;&#34913;&#65292;&#38459;&#30861;&#20102;&#31163;&#32447;&#35757;&#32451;&#30340;AI&#27169;&#22411;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;AI&#27169;&#22411;&#20250;&#36890;&#36807;&#27969;&#24335;&#25968;&#25454;&#36827;&#34892;&#22312;&#32447;&#26356;&#26032;&#20197;&#25345;&#32493;&#25913;&#36827;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#27880;&#37322;&#32422;&#26463;&#65292;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#22312;&#36873;&#25321;&#29992;&#20110;&#26356;&#26032;&#30340;&#20248;&#36136;&#27969;&#24335;&#26679;&#26412;&#26041;&#38754;&#38754;&#20020;&#25361;&#25112;&#12290;&#25991;&#29486;&#20013;&#30340;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#36890;&#36807;&#20851;&#27880;&#19981;&#36275;&#25110;&#36807;&#24230;&#34920;&#31034;&#30340;&#21306;&#22495;&#26469;&#25552;&#20379;&#35299;&#20915;&#26041;&#26696;&#12290;&#22312;&#19981;&#26029;&#21464;&#21270;&#30340;&#21046;&#36896;&#32972;&#26223;&#19979;&#24179;&#34913;&#36825;&#20123;&#31574;&#30053;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;AI&#23398;&#20064;&#21040;&#30340;&#19968;&#20123;&#33719;&#21462;&#20934;&#21017;&#21487;&#20197;&#21160;&#24577;&#36866;&#24212;&#65292;&#20294;&#21487;&#33021;&#26080;&#27861;&#22987;&#32456;&#22788;&#29702;&#39057;&#32321;&#30340;&#21464;&#21270;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#38598;&#25104;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;CBEAL&#65292;&#19987;&#38376;&#21033;&#29992;&#20027;&#21160;&#23398;&#20064;&#20195;&#29702;&#36827;&#34892;&#25506;&#32034;&#25110;&#21033;&#29992;&#12290;&#20195;&#29702;&#30340;&#26435;&#37325;&#26681;&#25454;&#20915;&#31574;&#26377;&#25928;&#24615;&#36827;&#34892;&#35843;&#25972;&#12290;CBEAL&#21487;&#20197;&#20248;&#21270;&#22320;&#25351;&#23548;&#25968;&#25454;&#33719;&#21462;&#65292;&#23454;&#29616;&#25968;&#25454;&#25928;&#26524;&#30340;&#26368;&#23567;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online sensing and computational resources in Industrial Cyber-physical Systems (ICPS) facilitate AI-driven decision-making. Yet, issues with data quality, such as imbalanced classes, hinder AI models trained offline. To address this, AI models are updated online with streaming data for continuous improvement. Supervised learning models, however, face challenges in selecting quality streaming samples for updates due to annotation constraints. Active learning methods in literature offer solutions by focusing on under-represented or well-represented regions. Balancing these strategies in changing manufacturing contexts is challenging. Some acquisition criteria learned by AI dynamically adapt but may not consistently handle frequent changes. We introduce an ensemble active learning method, CBEAL, employing active learning agents specifically for exploration or exploitation. Weights of agents are adjusted based on agent decision effectiveness. CBEAL optimally guides data acquisition, minim
&lt;/p&gt;</description></item><item><title>&#22810;&#27493;&#27169;&#22411;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#36890;&#36807;&#20351;&#29992;&#22810;&#27493;&#30446;&#26631;&#26469;&#35757;&#32451;&#19968;&#27493;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#36712;&#36857;&#38271;&#24230;&#22686;&#38271;&#26102;&#19968;&#27493;&#39044;&#27979;&#35823;&#24046;&#30340;&#32047;&#31215;&#38382;&#39064;&#65292;&#24182;&#22312;&#22122;&#22768;&#25968;&#25454;&#19978;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2310.05672</link><description>&lt;p&gt;
&#22810;&#27493;&#27169;&#22411;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Multi-timestep models for Model-based Reinforcement Learning. (arXiv:2310.05672v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05672
&lt;/p&gt;
&lt;p&gt;
&#22810;&#27493;&#27169;&#22411;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#36890;&#36807;&#20351;&#29992;&#22810;&#27493;&#30446;&#26631;&#26469;&#35757;&#32451;&#19968;&#27493;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#36712;&#36857;&#38271;&#24230;&#22686;&#38271;&#26102;&#19968;&#27493;&#39044;&#27979;&#35823;&#24046;&#30340;&#32047;&#31215;&#38382;&#39064;&#65292;&#24182;&#22312;&#22122;&#22768;&#25968;&#25454;&#19978;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#22823;&#22810;&#25968;&#31639;&#27861;&#20381;&#36182;&#20110;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#21040;&#30340;&#19968;&#27493;&#21160;&#21147;&#23398;&#27169;&#22411;&#26469;&#27169;&#25311;&#36712;&#36857;&#12290;&#36825;&#31181;&#26041;&#27861;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#26159;&#38543;&#30528;&#36712;&#36857;&#38271;&#24230;&#30340;&#22686;&#38271;&#65292;&#19968;&#27493;&#39044;&#27979;&#35823;&#24046;&#30340;&#32047;&#31215;&#12290;&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#22810;&#27493;&#30446;&#26631;&#26469;&#35757;&#32451;&#19968;&#27493;&#27169;&#22411;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#22312;&#21508;&#31181;&#26410;&#26469;&#26102;&#38388;&#27573;&#19978;&#30340;&#19968;&#20010;&#25439;&#22833;&#20989;&#25968;&#65288;&#20363;&#22914;&#65292;&#36127;&#23545;&#25968;&#20284;&#28982;&#65289;&#30340;&#21152;&#26435;&#21644;&#12290;&#25105;&#20204;&#25506;&#32034;&#21644;&#27979;&#35797;&#20102;&#19968;&#31995;&#21015;&#26435;&#37325;&#26041;&#26696;&#12290;&#25105;&#20204;&#21457;&#29616;&#25351;&#25968;&#34928;&#20943;&#26435;&#37325;&#23548;&#33268;&#27169;&#22411;&#22312;&#38271;&#26102;&#38388;&#27573;&#30340;R2&#24471;&#20998;&#26174;&#33879;&#25552;&#39640;&#12290;&#24403;&#27169;&#22411;&#22312;&#22122;&#22768;&#25968;&#25454;&#19978;&#36827;&#34892;&#35780;&#20272;&#26102;&#65292;&#36825;&#31181;&#25913;&#36827;&#23588;&#20026;&#26126;&#26174;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22312;&#32431;&#25209;&#37327;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#21644;&#36845;&#20195;&#25209;&#37327;RL&#22330;&#26223;&#20013;&#20351;&#29992;&#36719;&#20214;&#28436;&#21592;-&#35780;&#35770;&#23478;&#65288;SAC&#65289;&#20195;&#29702;&#65292;&#21457;&#29616;&#25105;&#20204;&#30340;&#22810;&#27493;&#27169;&#22411;&#20248;&#20110;&#25110;&#19982;&#26631;&#20934;&#30340;&#19968;&#27493;&#27169;&#22411;&#30456;&#21305;&#37197;&#12290;&#36825;&#22312;&#32771;&#34385;&#29615;&#22659;&#30340;&#22122;&#22768;&#21464;&#20307;&#20013;&#23588;&#20026;&#26126;&#26174;&#12290;
&lt;/p&gt;
&lt;p&gt;
In model-based reinforcement learning (MBRL), most algorithms rely on simulating trajectories from one-step dynamics models learned on data. A critical challenge of this approach is the compounding of one-step prediction errors as length of the trajectory grows. In this paper we tackle this issue by using a multi-timestep objective to train one-step models. Our objective is a weighted sum of a loss function (e.g., negative log-likelihood) at various future horizons. We explore and test a range of weights profiles. We find that exponentially decaying weights lead to models that significantly improve the long-horizon R2 score. This improvement is particularly noticeable when the models were evaluated on noisy data. Finally, using a soft actor-critic (SAC) agent in pure batch reinforcement learning (RL) and iterated batch RL scenarios, we found that our multi-timestep models outperform or match standard one-step models. This was especially evident in a noisy variant of the considered envi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#32593;&#32476;&#22823;&#23567;&#21644;L2&#27491;&#21017;&#21270;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#35266;&#23519;&#21040;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#12290;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#29305;&#24449;&#21644;&#25042;&#24816;&#35757;&#32451;&#31574;&#30053;&#65292;&#22312;&#21442;&#25968;&#21644;&#29366;&#24577;&#25968;&#26080;&#38480;&#22823;&#30340;&#24773;&#20917;&#19979;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#30340;&#26368;&#23567;&#20108;&#20056;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;&#65292;&#24471;&#20986;&#20102;&#20854;&#25910;&#25947;&#24615;&#21644;&#26368;&#20248;&#24615;&#65292;&#24182;&#38416;&#36848;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#22312;&#35813;&#31639;&#27861;&#20013;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.05518</link><description>&lt;p&gt;
&#20851;&#20110;&#20351;&#29992;LSTD&#21644;&#38543;&#26426;&#29305;&#24449;&#30340;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#21452;&#19979;&#38477;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
On Double-Descent in Reinforcement Learning with LSTD and Random Features. (arXiv:2310.05518v1 [cs.LG] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05518
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#32593;&#32476;&#22823;&#23567;&#21644;L2&#27491;&#21017;&#21270;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#35266;&#23519;&#21040;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#12290;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#29305;&#24449;&#21644;&#25042;&#24816;&#35757;&#32451;&#31574;&#30053;&#65292;&#22312;&#21442;&#25968;&#21644;&#29366;&#24577;&#25968;&#26080;&#38480;&#22823;&#30340;&#24773;&#20917;&#19979;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#30340;&#26368;&#23567;&#20108;&#20056;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;&#65292;&#24471;&#20986;&#20102;&#20854;&#25910;&#25947;&#24615;&#21644;&#26368;&#20248;&#24615;&#65292;&#24182;&#38416;&#36848;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#22312;&#35813;&#31639;&#27861;&#20013;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;&#22312;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20854;&#24615;&#33021;&#21463;&#31070;&#32463;&#32593;&#32476;&#22823;&#23567;&#30340;&#24433;&#21709;&#12290;&#28982;&#32780;&#65292;&#22312;&#30417;&#30563;&#23398;&#20064;&#20013;&#36807;&#21442;&#25968;&#21270;&#21644;&#20854;&#24102;&#26469;&#30340;&#22909;&#22788;&#24050;&#32463;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#29702;&#35299;&#65292;&#20294;&#26159;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#24773;&#20917;&#21017;&#19981;&#22826;&#28165;&#26970;&#12290;&#26412;&#25991;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#25506;&#35752;&#20102;&#32593;&#32476;&#22823;&#23567;&#21644;L2&#27491;&#21017;&#21270;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#23558;&#21442;&#25968;&#20010;&#25968;&#19982;&#35775;&#38382;&#29366;&#24577;&#20010;&#25968;&#20043;&#27604;&#23450;&#20041;&#20026;&#20851;&#38190;&#22240;&#32032;&#65292;&#24403;&#35813;&#27604;&#20540;&#22823;&#20110;1&#26102;&#31216;&#20026;&#36807;&#21442;&#25968;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#65292;&#21363;&#22312;&#21442;&#25968;/&#29366;&#24577;&#27604;&#20026;1&#38468;&#36817;&#20250;&#31361;&#28982;&#24615;&#33021;&#19979;&#38477;&#12290;&#36890;&#36807;&#21033;&#29992;&#38543;&#26426;&#29305;&#24449;&#21644;&#25042;&#24816;&#35757;&#32451;&#31574;&#30053;&#65292;&#25105;&#20204;&#22312;&#26080;&#38480;&#22823;&#30340;&#21442;&#25968;&#21644;&#29366;&#24577;&#25968;&#19979;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#30340;&#26368;&#23567;&#20108;&#20056;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#20854;&#25910;&#25947;&#24615;&#21644;&#26368;&#20248;&#24615;&#65292;&#24182;&#38416;&#36848;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#22312;&#35813;&#31639;&#27861;&#20013;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Temporal Difference (TD) algorithms are widely used in Deep Reinforcement Learning (RL). Their performance is heavily influenced by the size of the neural network. While in supervised learning, the regime of over-parameterization and its benefits are well understood, the situation in RL is much less clear. In this paper, we present a theoretical analysis of the influence of network size and $l_2$-regularization on performance. We identify the ratio between the number of parameters and the number of visited states as a crucial factor and define over-parameterization as the regime when it is larger than one. Furthermore, we observe a double-descent phenomenon, i.e., a sudden drop in performance around the parameter/state ratio of one. Leveraging random features and the lazy training regime, we study the regularized Least-Square Temporal Difference (LSTD) algorithm in an asymptotic regime, as both the number of parameters and states go to infinity, maintaining a constant ratio. We derive 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;Entropy-MCMC&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#36741;&#21161;&#30340;&#24341;&#23548;&#21464;&#37327;&#26469;&#22312;&#24179;&#22374;&#30406;&#22320;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#20197;&#35299;&#20915;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#20998;&#24067;&#30340;&#22810;&#27169;&#24577;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.05401</link><description>&lt;p&gt;
Entropy-MCMC: &#36731;&#26494;&#20174;&#24179;&#22374;&#30406;&#22320;&#36827;&#34892;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Entropy-MCMC: Sampling from Flat Basins with Ease. (arXiv:2310.05401v1 [cs.LG] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05401
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;Entropy-MCMC&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#36741;&#21161;&#30340;&#24341;&#23548;&#21464;&#37327;&#26469;&#22312;&#24179;&#22374;&#30406;&#22320;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#20197;&#35299;&#20915;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#20998;&#24067;&#30340;&#22810;&#27169;&#24577;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#20381;&#36182;&#20110;&#23545;&#21518;&#39564;&#20998;&#24067;&#30340;&#36136;&#37327;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#21518;&#39564;&#20998;&#24067;&#22312;&#24615;&#36136;&#19978;&#26159;&#39640;&#24230;&#22810;&#27169;&#24577;&#30340;&#65292;&#23616;&#37096;&#27169;&#24335;&#34920;&#29616;&#20986;&#19981;&#21516;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#22312;&#26377;&#38480;&#30340;&#35745;&#31639;&#36164;&#28304;&#19979;&#65292;&#20174;&#21407;&#22987;&#21518;&#39564;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#21487;&#33021;&#20250;&#23548;&#33268;&#27425;&#20248;&#24615;&#33021;&#65292;&#22240;&#20026;&#19968;&#20123;&#26679;&#26412;&#21487;&#33021;&#20250;&#38519;&#20837;&#8220;&#22351;&#8221;&#27169;&#24335;&#24182;&#20986;&#29616;&#36807;&#25311;&#21512;&#12290;&#22522;&#20110;&#35266;&#23519;&#21040;&#20302;&#27867;&#21270;&#35823;&#24046;&#30340;&#8220;&#22909;&#8221;&#27169;&#24335;&#36890;&#24120;&#23384;&#22312;&#20110;&#33021;&#37327;&#26223;&#35266;&#30340;&#24179;&#22374;&#30406;&#22320;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#20559;&#32622;&#37319;&#26679;&#26397;&#21521;&#36825;&#20123;&#24179;&#22374;&#21306;&#22495;&#30340;&#21518;&#39564;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#36741;&#21161;&#24341;&#23548;&#21464;&#37327;&#65292;&#20854;&#31283;&#24577;&#20998;&#24067;&#31867;&#20284;&#20110;&#24179;&#28369;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#19988;&#27809;&#26377;&#23574;&#38160;&#30340;&#27169;&#24577;&#65292;&#20197;&#24341;&#23548;MCMC&#37319;&#26679;&#22120;&#22312;&#24179;&#22374;&#30340;&#30406;&#22320;&#20013;&#37319;&#26679;&#12290;&#36890;&#36807;&#23558;&#27492;&#24341;&#23548;&#21464;&#37327;&#19982;&#27169;&#22411;&#21442;&#25968;&#30456;&#32467;&#21512;&#65292;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#32852;&#21512;&#20998;&#24067;&#65292;&#21487;&#20197;&#22312;&#26368;&#23567;&#35745;&#31639;&#24320;&#38144;&#19979;&#23454;&#29616;&#39640;&#25928;&#37319;&#26679;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#20803;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian deep learning counts on the quality of posterior distribution estimation. However, the posterior of deep neural networks is highly multi-modal in nature, with local modes exhibiting varying generalization performance. Given a practical budget, sampling from the original posterior can lead to suboptimal performance, as some samples may become trapped in "bad" modes and suffer from overfitting. Leveraging the observation that "good" modes with low generalization error often reside in flat basins of the energy landscape, we propose to bias sampling on the posterior toward these flat regions. Specifically, we introduce an auxiliary guiding variable, the stationary distribution of which resembles a smoothed posterior free from sharp modes, to lead the MCMC sampler to flat basins. By integrating this guiding variable with the model parameter, we create a simple joint distribution that enables efficient sampling with minimal computational overhead. We prove the convergence of our met
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#20132;&#21449;&#39044;&#27979;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#36827;&#34892;&#25512;&#29702;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#19968;&#20010;&#23567;&#22411;&#26631;&#35760;&#25968;&#25454;&#38598;&#21644;&#19968;&#20010;&#22823;&#22411;&#26410;&#26631;&#35760;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#22635;&#34917;&#32570;&#22833;&#30340;&#26631;&#31614;&#65292;&#24182;&#37319;&#29992;&#21435;&#20559;&#24046;&#26041;&#27861;&#32416;&#27491;&#39044;&#27979;&#30340;&#19981;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.16598</link><description>&lt;p&gt;
&#22522;&#20110;&#20132;&#21449;&#39044;&#27979;&#30340;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Cross-Prediction-Powered Inference. (arXiv:2309.16598v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16598
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#20132;&#21449;&#39044;&#27979;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#36827;&#34892;&#25512;&#29702;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#19968;&#20010;&#23567;&#22411;&#26631;&#35760;&#25968;&#25454;&#38598;&#21644;&#19968;&#20010;&#22823;&#22411;&#26410;&#26631;&#35760;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#22635;&#34917;&#32570;&#22833;&#30340;&#26631;&#31614;&#65292;&#24182;&#37319;&#29992;&#21435;&#20559;&#24046;&#26041;&#27861;&#32416;&#27491;&#39044;&#27979;&#30340;&#19981;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#38752;&#30340;&#25968;&#25454;&#39537;&#21160;&#20915;&#31574;&#20381;&#36182;&#20110;&#39640;&#36136;&#37327;&#30340;&#26631;&#27880;&#25968;&#25454;&#65292;&#28982;&#32780;&#33719;&#21462;&#39640;&#36136;&#37327;&#30340;&#26631;&#27880;&#25968;&#25454;&#32463;&#24120;&#38656;&#35201;&#32321;&#29712;&#30340;&#20154;&#24037;&#26631;&#27880;&#25110;&#32773;&#32531;&#24930;&#26114;&#36149;&#30340;&#31185;&#23398;&#27979;&#37327;&#12290;&#26426;&#22120;&#23398;&#20064;&#20316;&#20026;&#19968;&#31181;&#26367;&#20195;&#26041;&#26696;&#27491;&#21464;&#24471;&#36234;&#26469;&#36234;&#26377;&#21560;&#24341;&#21147;&#65292;&#22240;&#20026;&#31934;&#23494;&#30340;&#39044;&#27979;&#25216;&#26415;&#21487;&#20197;&#24555;&#36895;&#12289;&#24265;&#20215;&#22320;&#20135;&#29983;&#22823;&#37327;&#39044;&#27979;&#26631;&#31614;&#65307;&#20363;&#22914;&#65292;&#39044;&#27979;&#30340;&#34507;&#30333;&#36136;&#32467;&#26500;&#34987;&#29992;&#26469;&#34917;&#20805;&#23454;&#39564;&#24471;&#21040;&#30340;&#32467;&#26500;&#65292;&#21355;&#26143;&#22270;&#20687;&#39044;&#27979;&#30340;&#31038;&#20250;&#32463;&#27982;&#25351;&#26631;&#34987;&#29992;&#26469;&#34917;&#20805;&#20934;&#30830;&#30340;&#35843;&#26597;&#25968;&#25454;&#31561;&#12290;&#30001;&#20110;&#39044;&#27979;&#20855;&#26377;&#19981;&#23436;&#32654;&#21644;&#28508;&#22312;&#20559;&#24046;&#30340;&#29305;&#28857;&#65292;&#36825;&#31181;&#20570;&#27861;&#23545;&#19979;&#28216;&#25512;&#29702;&#30340;&#26377;&#25928;&#24615;&#20135;&#29983;&#20102;&#36136;&#30097;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#20132;&#21449;&#39044;&#27979;&#26041;&#27861;&#65292;&#29992;&#20110;&#26377;&#25928;&#30340;&#25512;&#29702;&#12290;&#36890;&#36807;&#19968;&#20010;&#23567;&#30340;&#26631;&#35760;&#25968;&#25454;&#38598;&#21644;&#19968;&#20010;&#22823;&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#38598;&#65292;&#20132;&#21449;&#39044;&#27979;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#22635;&#34917;&#32570;&#22833;&#30340;&#26631;&#31614;&#65292;&#24182;&#24212;&#29992;&#19968;&#31181;&#21435;&#20559;&#24046;&#30340;&#26041;&#27861;&#26469;&#32416;&#27491;&#39044;&#27979;&#19981;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
While reliable data-driven decision-making hinges on high-quality labeled data, the acquisition of quality labels often involves laborious human annotations or slow and expensive scientific measurements. Machine learning is becoming an appealing alternative as sophisticated predictive techniques are being used to quickly and cheaply produce large amounts of predicted labels; e.g., predicted protein structures are used to supplement experimentally derived structures, predictions of socioeconomic indicators from satellite imagery are used to supplement accurate survey data, and so on. Since predictions are imperfect and potentially biased, this practice brings into question the validity of downstream inferences. We introduce cross-prediction: a method for valid inference powered by machine learning. With a small labeled dataset and a large unlabeled dataset, cross-prediction imputes the missing labels via machine learning and applies a form of debiasing to remedy the prediction inaccurac
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20813;&#30123;&#30340;&#27010;&#29575;&#65292;&#25552;&#20986;&#20102;&#20813;&#30123;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#65292;&#20197;&#21450;&#949;-&#26377;&#30028;&#20813;&#30123;&#30340;&#26465;&#20214;&#12290;&#21516;&#26102;&#65292;&#20511;&#21161;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#20272;&#35745;&#21463;&#30410;&#27010;&#29575;&#65292;&#24182;&#24471;&#21040;&#27604;&#29616;&#26377;&#36793;&#30028;&#26356;&#32039;&#23494;&#30340;&#27010;&#29575;&#36793;&#30028;&#12290;&#27492;&#22806;&#65292;&#20171;&#32461;&#20102;&#38388;&#25509;&#20813;&#30123;&#30340;&#27010;&#24565;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22788;&#29702;&#26410;&#27979;&#37327;&#28151;&#28102;&#30340;&#20813;&#30123;&#27010;&#29575;&#25935;&#24863;&#24615;&#20998;&#26512;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.11942</link><description>&lt;p&gt;
&#20851;&#20110;&#20813;&#30123;&#30340;&#27010;&#29575;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Probability of Immunity. (arXiv:2309.11942v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11942
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20813;&#30123;&#30340;&#27010;&#29575;&#65292;&#25552;&#20986;&#20102;&#20813;&#30123;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#65292;&#20197;&#21450;&#949;-&#26377;&#30028;&#20813;&#30123;&#30340;&#26465;&#20214;&#12290;&#21516;&#26102;&#65292;&#20511;&#21161;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#20272;&#35745;&#21463;&#30410;&#27010;&#29575;&#65292;&#24182;&#24471;&#21040;&#27604;&#29616;&#26377;&#36793;&#30028;&#26356;&#32039;&#23494;&#30340;&#27010;&#29575;&#36793;&#30028;&#12290;&#27492;&#22806;&#65292;&#20171;&#32461;&#20102;&#38388;&#25509;&#20813;&#30123;&#30340;&#27010;&#24565;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22788;&#29702;&#26410;&#27979;&#37327;&#28151;&#28102;&#30340;&#20813;&#30123;&#27010;&#29575;&#25935;&#24863;&#24615;&#20998;&#26512;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#33268;&#21147;&#20110;&#30740;&#31350;&#20813;&#30123;&#30340;&#27010;&#29575;&#65292;&#21363;&#26080;&#35770;&#26292;&#38706;&#19982;&#21542;&#65292;&#25928;&#26524;&#37117;&#20250;&#21457;&#29983;&#12290;&#25105;&#20204;&#23548;&#20986;&#20102;&#20813;&#30123;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#20197;&#21450;&#949;-&#26377;&#30028;&#20813;&#30123;&#30340;&#26465;&#20214;&#65292;&#21069;&#32773;&#20801;&#35768;&#25105;&#20204;&#20174;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#20013;&#20272;&#35745;&#21463;&#30410;&#30340;&#27010;&#29575;&#65288;&#21363;&#21482;&#26377;&#22312;&#26292;&#38706;&#30340;&#24773;&#20917;&#19979;&#25928;&#26524;&#25165;&#20250;&#21457;&#29983;&#65289;&#65292;&#21518;&#32773;&#20801;&#35768;&#25105;&#20204;&#24471;&#21040;&#27604;&#29616;&#26377;&#30340;&#36793;&#30028;&#26356;&#32039;&#23494;&#30340;&#21463;&#30410;&#27010;&#29575;&#36793;&#30028;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#38388;&#25509;&#20813;&#30123;&#30340;&#27010;&#24565;&#65288;&#36890;&#36807;&#20171;&#36136;&#65289;&#65292;&#24182;&#23545;&#20854;&#36827;&#34892;&#20102;&#21069;&#36848;&#20998;&#26512;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#26410;&#27979;&#37327;&#28151;&#28102;&#24773;&#20917;&#19979;&#36827;&#34892;&#20813;&#30123;&#27010;&#29575;&#25935;&#24863;&#24615;&#20998;&#26512;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work is devoted to the study of the probability of immunity, i.e. the effect occurs whether exposed or not. We derive necessary and sufficient conditions for non-immunity and $\epsilon$-bounded immunity, i.e. the probability of immunity is zero and $\epsilon$-bounded, respectively. The former allows us to estimate the probability of benefit (i.e., the effect occurs if and only if exposed) from a randomized controlled trial, and the latter allows us to produce bounds of the probability of benefit that are tighter than the existing ones. We also introduce the concept of indirect immunity (i.e., through a mediator) and repeat our previous analysis for it. Finally, we propose a method for sensitivity analysis of the probability of immunity under unmeasured confounding.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26657;&#20934;&#30340;&#22522;&#20934;&#30740;&#31350;&#65292;&#21033;&#29992;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#31354;&#38388;&#25506;&#32034;&#20102;&#27169;&#22411;&#26657;&#20934;&#23646;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#27169;&#22411;&#26657;&#20934;&#21487;&#20197;&#22312;&#19981;&#21516;&#20219;&#21153;&#20013;&#27867;&#21270;&#65292;&#24182;&#21487;&#20197;&#21516;&#26102;&#20860;&#39038;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#26657;&#20934;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.11838</link><description>&lt;p&gt;
&#19968;&#20010;&#20851;&#20110;&#26657;&#20934;&#30340;&#22522;&#20934;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Benchmark Study on Calibration. (arXiv:2308.11838v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11838
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26657;&#20934;&#30340;&#22522;&#20934;&#30740;&#31350;&#65292;&#21033;&#29992;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#31354;&#38388;&#25506;&#32034;&#20102;&#27169;&#22411;&#26657;&#20934;&#23646;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#27169;&#22411;&#26657;&#20934;&#21487;&#20197;&#22312;&#19981;&#21516;&#20219;&#21153;&#20013;&#27867;&#21270;&#65292;&#24182;&#21487;&#20197;&#21516;&#26102;&#20860;&#39038;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#26657;&#20934;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#36234;&#26469;&#36234;&#24191;&#27867;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#36825;&#20123;&#27169;&#22411;&#22797;&#26434;&#24615;&#30340;&#22686;&#21152;&#65292;&#23427;&#20204;&#24448;&#24448;&#38754;&#20020;&#26657;&#20934;&#38382;&#39064;&#65292;&#23613;&#31649;&#39044;&#27979;&#20934;&#30830;&#24615;&#26377;&#25152;&#25552;&#39640;&#12290;&#35768;&#22810;&#30740;&#31350;&#36890;&#36807;&#25968;&#25454;&#39044;&#22788;&#29702;&#12289;&#20351;&#29992;&#29305;&#23450;&#25439;&#22833;&#20989;&#25968;&#21644;&#35757;&#32451;&#26694;&#26550;&#26469;&#25913;&#21892;&#26657;&#20934;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#23545;&#26657;&#20934;&#23646;&#24615;&#30340;&#30740;&#31350;&#26377;&#28857;&#34987;&#24573;&#35270;&#20102;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21033;&#29992;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#65288;NAS&#65289;&#25628;&#32034;&#31354;&#38388;&#65292;&#22312;&#20840;&#38754;&#25506;&#32034;&#26657;&#20934;&#23646;&#24615;&#30340;&#27169;&#22411;&#26550;&#26500;&#31354;&#38388;&#20013;&#25552;&#20379;&#20102;&#19968;&#20010;&#35814;&#23613;&#30340;&#27169;&#22411;&#26550;&#26500;&#31354;&#38388;&#12290;&#25105;&#20204;&#29305;&#21035;&#21019;&#24314;&#20102;&#19968;&#20010;&#27169;&#22411;&#26657;&#20934;&#25968;&#25454;&#38598;&#12290;&#35813;&#25968;&#25454;&#38598;&#22312;&#24191;&#27867;&#20351;&#29992;&#30340;NATS-Bench&#25628;&#32034;&#31354;&#38388;&#20013;&#35780;&#20272;&#20102;90&#20010;&#22522;&#20110;&#21306;&#38388;&#30340;&#26657;&#20934;&#24230;&#37327;&#21644;12&#20010;&#20854;&#20182;&#26657;&#20934;&#24230;&#37327;&#65292;&#28085;&#30422;&#20102;117,702&#20010;&#29420;&#29305;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#26088;&#22312;&#36890;&#36807;&#25105;&#20204;&#25552;&#20986;&#30340;&#25968;&#25454;&#38598;&#22238;&#31572;&#35813;&#39046;&#22495;&#19968;&#20123;&#38271;&#26399;&#23384;&#22312;&#30340;&#38382;&#39064;&#65306;&#65288;i&#65289;&#27169;&#22411;&#26657;&#20934;&#33021;&#21542;&#22312;&#19981;&#21516;&#20219;&#21153;&#20013;&#27867;&#21270;&#65311;&#65288;ii&#65289;&#33021;&#21542;&#21516;&#26102;&#20860;&#39038;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#26657;&#20934;&#24615;&#33021;&#65311;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks are increasingly utilized in various machine learning tasks. However, as these models grow in complexity, they often face calibration issues, despite enhanced prediction accuracy. Many studies have endeavored to improve calibration performance through data preprocessing, the use of specific loss functions, and training frameworks. Yet, investigations into calibration properties have been somewhat overlooked. Our study leverages the Neural Architecture Search (NAS) search space, offering an exhaustive model architecture space for thorough calibration properties exploration. We specifically create a model calibration dataset. This dataset evaluates 90 bin-based and 12 additional calibration measurements across 117,702 unique neural networks within the widely employed NATS-Bench search space. Our analysis aims to answer several longstanding questions in the field, using our proposed dataset: (i) Can model calibration be generalized across different tasks? (ii) Can rob
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#36125;&#21494;&#26031;&#19978;&#19979;&#25991;&#26641;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#21644;&#39044;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#23618;&#32423;&#36125;&#21494;&#26031;&#26694;&#26550;&#23558;&#31163;&#25955;&#29366;&#24577;&#21644;&#23454;&#20540;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#32452;&#21512;&#65292;&#26500;&#24314;&#20986;&#28789;&#27963;&#19988;&#21487;&#35299;&#37322;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#26377;&#25928;&#30340;&#31639;&#27861;&#26469;&#36827;&#34892;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2308.00913</link><description>&lt;p&gt;
&#22522;&#20110;&#36125;&#21494;&#26031;&#19978;&#19979;&#25991;&#26641;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#21644;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
The Bayesian Context Trees State Space Model for time series modelling and forecasting. (arXiv:2308.00913v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00913
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#36125;&#21494;&#26031;&#19978;&#19979;&#25991;&#26641;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#21644;&#39044;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#23618;&#32423;&#36125;&#21494;&#26031;&#26694;&#26550;&#23558;&#31163;&#25955;&#29366;&#24577;&#21644;&#23454;&#20540;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#32452;&#21512;&#65292;&#26500;&#24314;&#20986;&#28789;&#27963;&#19988;&#21487;&#35299;&#37322;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#26377;&#25928;&#30340;&#31639;&#27861;&#26469;&#36827;&#34892;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#19968;&#20010;&#23618;&#32423;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#29992;&#20110;&#24320;&#21457;&#29992;&#20110;&#30495;&#23454;&#20540;&#26102;&#38388;&#24207;&#21015;&#30340;&#20016;&#23500;&#28151;&#21512;&#27169;&#22411;&#65292;&#20197;&#21450;&#19968;&#31995;&#21015;&#26377;&#25928;&#30340;&#23398;&#20064;&#21644;&#25512;&#26029;&#24037;&#20855;&#12290;&#22312;&#39030;&#23618;&#65292;&#36890;&#36807;&#36866;&#24403;&#37327;&#21270;&#26368;&#36817;&#26679;&#26412;&#30340;&#19968;&#20123;&#26377;&#24847;&#20041;&#30340;&#31163;&#25955;&#29366;&#24577;&#26469;&#36827;&#34892;&#37492;&#23450;&#12290;&#36825;&#20123;&#21487;&#35266;&#23519;&#29366;&#24577;&#30340;&#38598;&#21512;&#34987;&#25551;&#36848;&#20026;&#31163;&#25955;&#30340;&#19978;&#19979;&#25991;&#26641;&#27169;&#22411;&#12290;&#28982;&#21518;&#65292;&#22312;&#24213;&#23618;&#65292;&#23558;&#19968;&#20010;&#19981;&#21516;&#30340;&#12289;&#20219;&#24847;&#30340;&#23454;&#20540;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#65288;&#22522;&#26412;&#27169;&#22411;&#65289;&#19982;&#27599;&#20010;&#29366;&#24577;&#30456;&#20851;&#32852;&#12290;&#36825;&#23450;&#20041;&#20102;&#19968;&#20010;&#38750;&#24120;&#36890;&#29992;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#19982;&#20219;&#20309;&#29616;&#26377;&#27169;&#22411;&#31867;&#19968;&#36215;&#20351;&#29992;&#65292;&#26500;&#24314;&#28789;&#27963;&#19988;&#21487;&#35299;&#37322;&#30340;&#28151;&#21512;&#27169;&#22411;&#12290;&#25105;&#20204;&#23558;&#20854;&#31216;&#20026;&#36125;&#21494;&#26031;&#19978;&#19979;&#25991;&#26641;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65292;&#25110;&#32773;BCT-X&#26694;&#26550;&#12290;&#24341;&#20837;&#20102;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#23454;&#29616;&#26377;&#25928;&#30340;&#12289;&#31934;&#30830;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#65307;&#29305;&#21035;&#26159;&#21487;&#20197;&#30830;&#23450;&#26368;&#22823;&#21518;&#39564;&#27010;&#29575;&#65288;MAP&#65289;&#19978;&#19979;&#25991;&#26641;&#27169;&#22411;&#12290;&#36825;&#20123;&#31639;&#27861;&#21487;&#20197;&#39034;&#24207;&#26356;&#26032;&#65292;&#20197;&#20415;&#23454;&#29616;&#26377;&#25928;&#30340;&#25512;&#26029;&#21644;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
A hierarchical Bayesian framework is introduced for developing rich mixture models for real-valued time series, along with a collection of effective tools for learning and inference. At the top level, meaningful discrete states are identified as appropriately quantised values of some of the most recent samples. This collection of observable states is described as a discrete context-tree model. Then, at the bottom level, a different, arbitrary model for real-valued time series - a base model - is associated with each state. This defines a very general framework that can be used in conjunction with any existing model class to build flexible and interpretable mixture models. We call this the Bayesian Context Trees State Space Model, or the BCT-X framework. Efficient algorithms are introduced that allow for effective, exact Bayesian inference; in particular, the maximum a posteriori probability (MAP) context-tree model can be identified. These algorithms can be updated sequentially, facili
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#22810;&#31181;&#28608;&#27963;&#20989;&#25968;&#19979;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;&#21487;&#20197;&#36890;&#36807;&#22312;&#26377;&#30028;&#38598;&#21512;&#19978;&#26500;&#24314;&#19968;&#20010;&#23485;&#24230;&#20026;6N&#12289;&#28145;&#24230;&#20026;2L&#30340;varrho&#28608;&#27963;&#32593;&#32476;&#26469;&#36924;&#36817;&#19968;&#20010;&#23485;&#24230;&#20026;N&#12289;&#28145;&#24230;&#20026;L&#30340;ReLU&#32593;&#32476;&#65292;&#20174;&#32780;&#23558;&#23545;ReLU&#32593;&#32476;&#30340;&#36924;&#36817;&#32467;&#26524;&#25512;&#24191;&#21040;&#20854;&#20182;&#28608;&#27963;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2307.06555</link><description>&lt;p&gt;
&#28145;&#24230;&#32593;&#32476;&#36924;&#36817;&#65306;&#20174;ReLU&#21040;&#22810;&#31181;&#28608;&#27963;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Deep Network Approximation: Beyond ReLU to Diverse Activation Functions. (arXiv:2307.06555v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06555
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#22810;&#31181;&#28608;&#27963;&#20989;&#25968;&#19979;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;&#21487;&#20197;&#36890;&#36807;&#22312;&#26377;&#30028;&#38598;&#21512;&#19978;&#26500;&#24314;&#19968;&#20010;&#23485;&#24230;&#20026;6N&#12289;&#28145;&#24230;&#20026;2L&#30340;varrho&#28608;&#27963;&#32593;&#32476;&#26469;&#36924;&#36817;&#19968;&#20010;&#23485;&#24230;&#20026;N&#12289;&#28145;&#24230;&#20026;L&#30340;ReLU&#32593;&#32476;&#65292;&#20174;&#32780;&#23558;&#23545;ReLU&#32593;&#32476;&#30340;&#36924;&#36817;&#32467;&#26524;&#25512;&#24191;&#21040;&#20854;&#20182;&#28608;&#27963;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#22810;&#31181;&#28608;&#27963;&#20989;&#25968;&#19979;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;&#23450;&#20041;&#20102;&#19968;&#20010;&#28608;&#27963;&#20989;&#25968;&#38598;&#21512;A&#65292;&#21253;&#25324;&#22823;&#22810;&#25968;&#24120;&#29992;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#22914;ReLU&#12289;LeakyReLU&#12289;ReLU^2&#12289;ELU&#12289;SELU&#12289;Softplus&#12289;GELU&#12289;SiLU&#12289;Swish&#12289;Mish&#12289;Sigmoid&#12289;Tanh&#12289;Arctan&#12289;Softsign&#12289;dSiLU&#21644;SRS&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20219;&#24847;&#28608;&#27963;&#20989;&#25968;varrho&#8712;A&#65292;&#21487;&#20197;&#36890;&#36807;&#19968;&#20010;&#23485;&#24230;&#20026;6N&#12289;&#28145;&#24230;&#20026;2L&#30340;varrho&#28608;&#27963;&#32593;&#32476;&#22312;&#26377;&#30028;&#38598;&#21512;&#19978;&#20197;&#20219;&#24847;&#31934;&#24230;&#36924;&#36817;&#19968;&#20010;&#23485;&#24230;&#20026;N&#12289;&#28145;&#24230;&#20026;L&#30340;ReLU&#32593;&#32476;&#12290;&#36825;&#19968;&#21457;&#29616;&#20351;&#24471;&#22823;&#37096;&#20998;&#23545;&#20110;ReLU&#32593;&#32476;&#30340;&#36924;&#36817;&#32467;&#26524;&#33021;&#22815;&#25512;&#24191;&#21040;&#20854;&#20182;&#28608;&#27963;&#20989;&#25968;&#65292;&#23613;&#31649;&#38656;&#35201;&#31245;&#22823;&#30340;&#24120;&#25968;&#20195;&#20215;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores the expressive power of deep neural networks for a diverse range of activation functions. An activation function set $\mathscr{A}$ is defined to encompass the majority of commonly used activation functions, such as $\mathtt{ReLU}$, $\mathtt{LeakyReLU}$, $\mathtt{ReLU}^2$, $\mathtt{ELU}$, $\mathtt{SELU}$, $\mathtt{Softplus}$, $\mathtt{GELU}$, $\mathtt{SiLU}$, $\mathtt{Swish}$, $\mathtt{Mish}$, $\mathtt{Sigmoid}$, $\mathtt{Tanh}$, $\mathtt{Arctan}$, $\mathtt{Softsign}$, $\mathtt{dSiLU}$, and $\mathtt{SRS}$. We demonstrate that for any activation function $\varrho\in \mathscr{A}$, a $\mathtt{ReLU}$ network of width $N$ and depth $L$ can be approximated to arbitrary precision by a $\varrho$-activated network of width $6N$ and depth $2L$ on any bounded set. This finding enables the extension of most approximation results achieved with $\mathtt{ReLU}$ networks to a wide variety of other activation functions, at the cost of slightly larger constants.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#20854;&#32467;&#21512;&#20102;&#25968;&#25454;&#20013;&#32534;&#30721;&#30340;&#26102;&#38388;&#21160;&#24577;&#65292;&#33258;&#28982;&#22320;&#32534;&#30721;&#20102;&#22810;&#27493;&#21644;&#38271;&#31243;&#39044;&#27979;&#33021;&#21147;&#65292;&#20855;&#26377;&#28789;&#27963;&#30340;&#37319;&#26679;&#36712;&#36857;&#21644;&#25240;&#34935;&#24615;&#33021;&#19982;&#21152;&#36895;&#37319;&#26679;&#30340;&#33021;&#21147;&#65292;&#21516;&#26102;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#65292;&#21487;&#22312;&#26102;&#31354;&#39044;&#27979;&#26041;&#38754;&#21462;&#24471;&#31454;&#20105;&#24615;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.01984</link><description>&lt;p&gt;
DYffusion&#65306;&#38754;&#21521;&#26102;&#31354;&#39044;&#27979;&#30340;&#21160;&#24577;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
DYffusion: A Dynamics-informed Diffusion Model for Spatiotemporal Forecasting. (arXiv:2306.01984v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01984
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#20854;&#32467;&#21512;&#20102;&#25968;&#25454;&#20013;&#32534;&#30721;&#30340;&#26102;&#38388;&#21160;&#24577;&#65292;&#33258;&#28982;&#22320;&#32534;&#30721;&#20102;&#22810;&#27493;&#21644;&#38271;&#31243;&#39044;&#27979;&#33021;&#21147;&#65292;&#20855;&#26377;&#28789;&#27963;&#30340;&#37319;&#26679;&#36712;&#36857;&#21644;&#25240;&#34935;&#24615;&#33021;&#19982;&#21152;&#36895;&#37319;&#26679;&#30340;&#33021;&#21147;&#65292;&#21516;&#26102;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#65292;&#21487;&#22312;&#26102;&#31354;&#39044;&#27979;&#26041;&#38754;&#21462;&#24471;&#31454;&#20105;&#24615;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#25193;&#25955;&#27169;&#22411;&#21487;&#20197;&#25104;&#21151;&#22320;&#29983;&#25104;&#25968;&#25454;&#21644;&#20570;&#20986;&#39044;&#27979;&#65292;&#20294;&#23427;&#20204;&#20027;&#35201;&#26159;&#20026;&#38745;&#24577;&#22270;&#20687;&#35774;&#35745;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#35757;&#32451;&#29992;&#20110;&#21160;&#24577;&#39044;&#27979;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#21033;&#29992;&#32534;&#30721;&#22312;&#25968;&#25454;&#20013;&#30340;&#26102;&#38388;&#21160;&#24577;&#65292;&#30452;&#25509;&#23558;&#20854;&#19982;&#32593;&#32476;&#20013;&#30340;&#25193;&#25955;&#27493;&#39588;&#32806;&#21512;&#12290;&#25105;&#20204;&#35757;&#32451;&#20102;&#19968;&#20010;&#38543;&#26426;&#30340;&#12289;&#26102;&#38388;&#26465;&#20214;&#30340;&#25554;&#20540;&#22120;&#21644;&#19968;&#20010;&#39592;&#24178;&#39044;&#27979;&#32593;&#32476;&#65292;&#20998;&#21035;&#27169;&#20223;&#20256;&#32479;&#25193;&#25955;&#27169;&#22411;&#30340;&#21069;&#21521;&#21644;&#21518;&#21521;&#36807;&#31243;&#12290;&#36825;&#31181;&#35774;&#35745;&#36873;&#25321;&#33258;&#28982;&#22320;&#32534;&#30721;&#20102;&#22810;&#27493;&#21644;&#38271;&#31243;&#39044;&#27979;&#33021;&#21147;&#65292;&#20801;&#35768;&#39640;&#24230;&#28789;&#27963;&#30340;&#36830;&#32493;&#26102;&#38388;&#37319;&#26679;&#36712;&#36857;&#65292;&#24182;&#22312;&#25512;&#29702;&#26102;&#33021;&#22815;&#25240;&#34935;&#24615;&#33021;&#19982;&#21152;&#36895;&#37319;&#26679;&#30340;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#38754;&#21521;&#21160;&#24577;&#30340;&#25193;&#25955;&#36807;&#31243;&#24378;&#21152;&#20102;&#24378;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#30456;&#27604;&#20256;&#32479;&#22522;&#20110;&#39640;&#26031;&#22122;&#22768;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#21487;&#20197;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#27010;&#29575;&#28369;&#38634;&#39044;&#27979;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
While diffusion models can successfully generate data and make predictions, they are predominantly designed for static images. We propose an approach for training diffusion models for dynamics forecasting that leverages the temporal dynamics encoded in the data, directly coupling it with the diffusion steps in the network. We train a stochastic, time-conditioned interpolator and a backbone forecaster network that mimic the forward and reverse processes of conventional diffusion models, respectively. This design choice naturally encodes multi-step and long-range forecasting capabilities, allowing for highly flexible, continuous-time sampling trajectories and the ability to trade-off performance with accelerated sampling at inference time. In addition, the dynamics-informed diffusion process imposes a strong inductive bias, allowing for improved computational efficiency compared to traditional Gaussian noise-based diffusion models. Our approach performs competitively on probabilistic ski
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#33609;&#22270;&#25216;&#26415;&#23558;&#31890;&#23376;&#26041;&#27861;&#21644;&#24352;&#37327;&#32593;&#32476;&#26041;&#27861;&#32467;&#21512;&#30340;&#26041;&#27861;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#36825;&#31181;&#26041;&#27861;&#21253;&#25324;&#31890;&#23376;&#27169;&#25311;&#21644;&#24352;&#37327;&#32593;&#32476;&#37325;&#26032;&#20272;&#35745;&#65292;&#24182;&#21487;&#29992;&#20316;&#31890;&#23376;&#25968;&#25511;&#21046;&#30340;&#21487;&#26367;&#20195;&#26041;&#27861;&#12290;&#22312;&#27169;&#25311;Fokker-Planck&#26041;&#31243;&#21644;&#37327;&#23376;&#34394;&#26102;&#38388;&#28436;&#21270;&#26041;&#38754;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#36890;&#29992;&#24615;&#21644;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.17884</link><description>&lt;p&gt;
&#36890;&#36807;&#33609;&#22270;&#25216;&#26415;&#65292;&#23558;&#31890;&#23376;&#26041;&#27861;&#21644;&#24352;&#37327;&#32593;&#32476;&#26041;&#27861;&#32467;&#21512;&#29992;&#20110;&#20559;&#24494;&#20998;&#26041;&#31243;&#27714;&#35299;
&lt;/p&gt;
&lt;p&gt;
Combining Particle and Tensor-network Methods for Partial Differential Equations via Sketching. (arXiv:2305.17884v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17884
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#33609;&#22270;&#25216;&#26415;&#23558;&#31890;&#23376;&#26041;&#27861;&#21644;&#24352;&#37327;&#32593;&#32476;&#26041;&#27861;&#32467;&#21512;&#30340;&#26041;&#27861;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#36825;&#31181;&#26041;&#27861;&#21253;&#25324;&#31890;&#23376;&#27169;&#25311;&#21644;&#24352;&#37327;&#32593;&#32476;&#37325;&#26032;&#20272;&#35745;&#65292;&#24182;&#21487;&#29992;&#20316;&#31890;&#23376;&#25968;&#25511;&#21046;&#30340;&#21487;&#26367;&#20195;&#26041;&#27861;&#12290;&#22312;&#27169;&#25311;Fokker-Planck&#26041;&#31243;&#21644;&#37327;&#23376;&#34394;&#26102;&#38388;&#28436;&#21270;&#26041;&#38754;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#36890;&#29992;&#24615;&#21644;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#24352;&#37327;&#32593;&#32476;&#26694;&#26550;&#65292;&#20854;&#20013;&#25105;&#20204;&#37319;&#29992;&#31890;&#23376;&#27169;&#25311;&#26356;&#26032;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#20351;&#29992;&#26368;&#36817;&#25552;&#20986;&#30340;&#24352;&#37327;&#21015;&#36710;&#33609;&#22270;&#25216;&#26415;&#23558;&#26032;&#35299;&#20915;&#26041;&#26696;&#37325;&#26032;&#20272;&#35745;&#20026;&#24352;&#37327;&#32593;&#32476;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36824;&#21487;&#20197;&#34987;&#35299;&#37322;&#20026;&#36890;&#36807;&#20551;&#35774;&#31890;&#23376;&#26469;&#33258;&#24213;&#23618;&#24352;&#37327;&#32593;&#32476;&#26469;&#25191;&#34892;&#31890;&#23376;&#25968;&#25511;&#21046;&#30340;&#21487;&#26367;&#20195;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#20854;&#24212;&#29992;&#20110;&#20004;&#31181;&#29305;&#23450;&#30340;&#24773;&#26223;&#26469;&#23637;&#31034;&#25105;&#20204;&#26041;&#27861;&#30340;&#36890;&#29992;&#24615;&#21644;&#28789;&#27963;&#24615;&#65306;&#36890;&#36807;Langevin&#21160;&#21147;&#23398;&#27169;&#25311;Fokker-Planck&#26041;&#31243;&#21644;&#36890;&#36807;&#36741;&#21161;&#22330;&#37327;&#23376;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#37327;&#23376;&#34394;&#26102;&#38388;&#28436;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a general framework for solving high-dimensional partial differential equations with tensor networks. Our approach offers a comprehensive solution methodology, wherein we employ a combination of particle simulations to update the solution and re-estimations of the new solution as a tensor-network using a recently proposed tensor train sketching technique. Our method can also be interpreted as an alternative approach for performing particle number control by assuming the particles originate from an underlying tensor network. We demonstrate the versatility and flexibility of our approach by applying it to two specific scenarios: simulating the Fokker-Planck equation through Langevin dynamics and quantum imaginary time evolution via auxiliary-field quantum Monte Carlo.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376; Langevin &#31639;&#27861;&#65292;&#29992;&#20110;&#26368;&#22823;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#12290;&#20351;&#29992;&#27492;&#31639;&#27861;&#65292;&#20272;&#35745;&#22120;&#30340;&#20248;&#21270;&#35823;&#24046;&#20855;&#26377;&#38750;&#28176;&#36817;&#27987;&#24230;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2303.13429</link><description>&lt;p&gt;
&#26368;&#22823;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#30340;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376; Langevin &#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Interacting Particle Langevin Algorithm for Maximum Marginal Likelihood Estimation. (arXiv:2303.13429v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.13429
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376; Langevin &#31639;&#27861;&#65292;&#29992;&#20110;&#26368;&#22823;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#12290;&#20351;&#29992;&#27492;&#31639;&#27861;&#65292;&#20272;&#35745;&#22120;&#30340;&#20248;&#21270;&#35823;&#24046;&#20855;&#26377;&#38750;&#28176;&#36817;&#27987;&#24230;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#65292;&#29992;&#20110;&#23454;&#29616;&#28508;&#21464;&#37327;&#27169;&#22411;&#21442;&#25968;&#30340;&#26368;&#22823;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#36807;&#31243;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36830;&#32493;&#26102;&#38388;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#65292;&#23427;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#22312;&#25193;&#23637;&#30340;&#29366;&#24577;&#31354;&#38388;&#19978;&#30340; Langevin&#28418;&#31227;&#65292;&#20854;&#20013;&#22312;&#32463;&#20856;&#30340;&#20248;&#21270;&#20013;&#65292;&#31890;&#23376;&#25968;&#37327;&#20316;&#20026;&#30456;&#21453;&#28201;&#24230;&#21442;&#25968;&#12290;&#20351;&#29992;Langevin&#28418;&#31227;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#26368;&#22823;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#22120;&#30340;&#20248;&#21270;&#35823;&#24046;&#30340;&#38750;&#28176;&#36817;&#27987;&#24230;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#19982;&#31890;&#23376;&#31995;&#32479;&#20013;&#30340;&#31890;&#23376;&#25968;&#37327;&#65292;&#31639;&#27861;&#30340;&#36845;&#20195;&#27425;&#25968;&#20197;&#21450;&#26102;&#38388;&#31163;&#25955;&#21270;&#20998;&#26512;&#30340;&#27493;&#38271;&#21442;&#25968;&#26377;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a class of interacting particle systems for implementing a marginal maximum likelihood estimation (MLE) procedure to optimize over the parameters of a latent variable model. To do so, we propose a continuous-time interacting particle system which can be seen as a Langevin diffusion over an extended state space, where the number of particles acts as the inverse temperature parameter in classical settings for optimisation. Using Langevin diffusions, we prove nonasymptotic concentration bounds for the optimisation error of the maximum marginal likelihood estimator in terms of the number of particles in the particle system, the number of iterations of the algorithm, and the step-size parameter for the time discretisation analysis.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#33258;&#21160;&#29983;&#25104;&#26032;&#30340;&#31163;&#32447;&#26816;&#27979;&#26041;&#27861;&#30340;&#26041;&#24335;&#65292;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#33258;&#21160;&#21464;&#28857;&#26816;&#27979;&#65292;&#20854;&#24615;&#33021;&#21487;&#19982;&#26631;&#20934;CUSUM&#20998;&#31867;&#22120;&#24615;&#33021;&#31454;&#20105;&#12290;</title><link>http://arxiv.org/abs/2211.03860</link><description>&lt;p&gt;
&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#23454;&#29616;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#33258;&#21160;&#21464;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Automatic Change-Point Detection in Time Series via Deep Learning. (arXiv:2211.03860v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.03860
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#33258;&#21160;&#29983;&#25104;&#26032;&#30340;&#31163;&#32447;&#26816;&#27979;&#26041;&#27861;&#30340;&#26041;&#24335;&#65292;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#33258;&#21160;&#21464;&#28857;&#26816;&#27979;&#65292;&#20854;&#24615;&#33021;&#21487;&#19982;&#26631;&#20934;CUSUM&#20998;&#31867;&#22120;&#24615;&#33021;&#31454;&#20105;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#20013;&#30340;&#21464;&#28857;&#26816;&#27979;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#25105;&#20204;&#36890;&#36807;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#33258;&#21160;&#29983;&#25104;&#26032;&#30340;&#31163;&#32447;&#26816;&#27979;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#37327;&#21270;&#27492;&#26041;&#27861;&#30340;&#35823;&#24046;&#29575;&#21450;&#20854;&#19982;&#35757;&#32451;&#25968;&#25454;&#37327;&#30340;&#20851;&#31995;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#21363;&#20351;&#26377;&#38480;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#20854;&#24615;&#33021;&#20063;&#21487;&#19982;&#29992;&#20110;&#26816;&#27979;&#20013;&#21464;&#21270;&#30340;&#26631;&#20934;CUSUM&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#31454;&#20105;&#12290;
&lt;/p&gt;
&lt;p&gt;
Detecting change-points in data is challenging because of the range of possible types of change and types of behaviour of data when there is no change. Statistically efficient methods for detecting a change will depend on both of these features, and it can be difficult for a practitioner to develop an appropriate detection method for their application of interest. We show how to automatically generate new offline detection methods based on training a neural network. Our approach is motivated by many existing tests for the presence of a change-point being representable by a simple neural network, and thus a neural network trained with sufficient data should have performance at least as good as these methods. We present theory that quantifies the error rate for such an approach, and how it depends on the amount of training data. Empirical results show that, even with limited training data, its performance is competitive with the standard CUSUM-based classifier for detecting a change in m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23884;&#22871;&#27169;&#25311;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#33021;&#22815;&#22312;&#20445;&#25345;&#26465;&#20214;&#26399;&#26395;&#36275;&#22815;&#24179;&#28369;&#30340;&#24773;&#20917;&#19979;&#65292;&#26377;&#25928;&#22320;&#32531;&#35299;&#39640;&#32500;&#24230;&#20013;&#30340;&#32500;&#24230;&#28798;&#38590;&#65292;&#20197;&#26725;&#25509;&#26631;&#20934;&#23884;&#22871;&#27169;&#25311;&#30340;&#31435;&#26041;&#26681;&#25910;&#25947;&#29575;&#21644;&#26631;&#20934;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#30340;&#24179;&#26041;&#26681;&#25910;&#25947;&#29575;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2201.02958</link><description>&lt;p&gt;
&#24179;&#28369;&#30340;&#23884;&#22871;&#27169;&#25311;&#26041;&#27861;&#65306;&#22312;&#39640;&#32500;&#24230;&#20013;&#26725;&#25509;&#31435;&#26041;&#21644;&#24179;&#26041;&#26681;&#25910;&#25947;&#29575;
&lt;/p&gt;
&lt;p&gt;
Smooth Nested Simulation: Bridging Cubic and Square Root Convergence Rates in High Dimensions. (arXiv:2201.02958v4 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.02958
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23884;&#22871;&#27169;&#25311;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#33021;&#22815;&#22312;&#20445;&#25345;&#26465;&#20214;&#26399;&#26395;&#36275;&#22815;&#24179;&#28369;&#30340;&#24773;&#20917;&#19979;&#65292;&#26377;&#25928;&#22320;&#32531;&#35299;&#39640;&#32500;&#24230;&#20013;&#30340;&#32500;&#24230;&#28798;&#38590;&#65292;&#20197;&#26725;&#25509;&#26631;&#20934;&#23884;&#22871;&#27169;&#25311;&#30340;&#31435;&#26041;&#26681;&#25910;&#25947;&#29575;&#21644;&#26631;&#20934;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#30340;&#24179;&#26041;&#26681;&#25910;&#25947;&#29575;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23884;&#22871;&#27169;&#25311;&#26159;&#36890;&#36807;&#27169;&#25311;&#26469;&#20272;&#35745;&#26465;&#20214;&#26399;&#26395;&#30340;&#21151;&#33021;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#23725;&#22238;&#24402;&#30340;&#26032;&#26041;&#27861;&#65292;&#20197;&#21033;&#29992;&#26465;&#20214;&#26399;&#26395;&#20316;&#20026;&#22810;&#32500;&#35843;&#33410;&#21464;&#37327;&#30340;&#24179;&#28369;&#20989;&#25968;&#12290;&#28176;&#36817;&#20998;&#26512;&#34920;&#26126;&#65292;&#21482;&#35201;&#26465;&#20214;&#26399;&#26395;&#36275;&#22815;&#24179;&#28369;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#22815;&#22312;&#27169;&#25311;&#27425;&#25968;&#22686;&#21152;&#26102;&#26377;&#25928;&#22320;&#20943;&#23569;&#32500;&#24230;&#28798;&#38590;&#30340;&#24433;&#21709;&#12290;&#24179;&#28369;&#24615;&#26725;&#25509;&#20102;&#31435;&#26041;&#26681;&#25910;&#25947;&#29575;&#65288;&#21363;&#26631;&#20934;&#23884;&#22871;&#27169;&#25311;&#30340;&#26368;&#20248;&#25910;&#25947;&#29575;&#65289;&#21644;&#24179;&#26041;&#26681;&#25910;&#25947;&#29575;&#65288;&#21363;&#26631;&#20934;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#30340;&#35268;&#33539;&#25910;&#25947;&#29575;&#65289;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#25105;&#20204;&#36890;&#36807;&#32452;&#21512;&#39118;&#38505;&#31649;&#29702;&#21644;&#36755;&#20837;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#25968;&#20540;&#31034;&#20363;&#65292;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nested simulation concerns estimating functionals of a conditional expectation via simulation. In this paper, we propose a new method based on kernel ridge regression to exploit the smoothness of the conditional expectation as a function of the multidimensional conditioning variable. Asymptotic analysis shows that the proposed method can effectively alleviate the curse of dimensionality on the convergence rate as the simulation budget increases, provided that the conditional expectation is sufficiently smooth. The smoothness bridges the gap between the cubic root convergence rate (that is, the optimal rate for the standard nested simulation) and the square root convergence rate (that is, the canonical rate for the standard Monte Carlo simulation). We demonstrate the performance of the proposed method via numerical examples from portfolio risk management and input uncertainty quantification.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26469;&#20998;&#26512;&#27773;&#36710;&#29992;&#25143;&#30340;&#29305;&#24449;&#23545;&#20572;&#36710;&#26102;&#38271;&#30340;&#24433;&#21709;&#65292;&#37319;&#29992;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#25429;&#25417;&#20854;&#30456;&#20114;&#20851;&#31995;&#65292;&#24182;&#36816;&#29992;Garson&#31639;&#27861;&#21644;LIME&#36827;&#34892;&#27169;&#22411;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2008.01674</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#29992;&#20110;&#24314;&#27169;&#22478;&#24066;&#22303;&#22320;&#20351;&#29992;&#20013;&#30340;&#20572;&#36710;&#26102;&#38271;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
A Machine Learning Approach for Modelling Parking Duration in Urban Land-use. (arXiv:2008.01674v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2008.01674
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26469;&#20998;&#26512;&#27773;&#36710;&#29992;&#25143;&#30340;&#29305;&#24449;&#23545;&#20572;&#36710;&#26102;&#38271;&#30340;&#24433;&#21709;&#65292;&#37319;&#29992;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#25429;&#25417;&#20854;&#30456;&#20114;&#20851;&#31995;&#65292;&#24182;&#36816;&#29992;Garson&#31639;&#27861;&#21644;LIME&#36827;&#34892;&#27169;&#22411;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20572;&#36710;&#26159;&#21457;&#23637;&#20013;&#22269;&#23478;&#20013;&#19981;&#21487;&#36991;&#20813;&#30340;&#38382;&#39064;&#12290;&#38543;&#30528;&#36710;&#36742;&#25968;&#37327;&#30340;&#22686;&#21152;&#65292;&#38656;&#35201;&#20026;&#20572;&#36710;&#20998;&#37197;&#26356;&#22810;&#30340;&#22478;&#24066;&#22303;&#22320;&#12290;&#28982;&#32780;&#65292;&#22312;&#21360;&#24230;&#31561;&#21457;&#23637;&#20013;&#22269;&#23478;&#65292;&#20572;&#36710;&#38382;&#39064;&#19968;&#30452;&#27809;&#26377;&#24471;&#21040;&#36275;&#22815;&#30340;&#20851;&#27880;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#65292;&#29992;&#20110;&#20998;&#26512;&#27773;&#36710;&#29992;&#25143;&#30340;&#31038;&#20250;&#32463;&#27982;&#21644;&#20986;&#34892;&#29305;&#24449;&#23545;&#20572;&#36710;&#26102;&#38271;&#30340;&#24433;&#21709;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#37319;&#29992;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#65288;ANNs&#65289;&#26469;&#25429;&#25417;&#39550;&#39542;&#21592;&#29305;&#24449;&#21644;&#20572;&#36710;&#26102;&#38271;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#31995;&#12290;ANNs&#22312;&#23398;&#20064;&#21644;&#35782;&#21035;&#21442;&#25968;&#20043;&#38388;&#30340;&#36830;&#25509;&#19978;&#38750;&#24120;&#39640;&#25928;&#65292;&#20197;&#26368;&#20339;&#39044;&#27979;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20854;&#40657;&#30418;&#29305;&#24615;&#65292;ANNs&#30340;&#23454;&#29992;&#24615;&#21463;&#21040;&#20005;&#37325;&#38480;&#21046;&#12290;&#22240;&#27492;&#65292;&#26412;&#30740;&#31350;&#20351;&#29992;Garson&#31639;&#27861;&#21644;&#23616;&#37096;&#21487;&#35299;&#37322;&#27169;&#22411;&#19981;&#21463;&#38480;&#30340;&#35299;&#37322;&#65288;LIME&#65289;&#36827;&#34892;&#27169;&#22411;&#35299;&#37322;&#12290;LIME&#36890;&#36807;&#23558;&#23616;&#37096;&#25968;&#25454;&#19982;&#24320;&#21457;&#30340;&#21487;&#35299;&#37322;&#27169;&#22411;&#36827;&#34892;&#23616;&#37096;&#36924;&#36817;&#65292;&#23637;&#31034;&#20102;&#20219;&#20309;&#20998;&#31867;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Parking is an inevitable issue in the fast-growing developing countries. Increasing number of vehicles require more and more urban land to be allocated for parking. However, a little attention has been conferred to the parking issues in developing countries like India. This study proposes a model for analysing the influence of car users' socioeconomic and travel characteristics on parking duration. Specifically, artificial neural networks (ANNs) is deployed to capture the interrelationship between driver characteristics and parking duration. ANNs are highly efficient in learning and recognizing connections between parameters for best prediction of an outcome. Since, utility of ANNs has been critically limited due to its Black Box nature, the study involves the use of Garson algorithm and Local interpretable model-agnostic explanations (LIME) for model interpretations. LIME shows the prediction for any classification, by approximating it locally with the developed interpretable model. T
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#29420;&#31435;&#24615;&#27979;&#35797;&#23454;&#29616;&#20102;&#26222;&#36941;&#19968;&#33268;&#30340;k&#26679;&#26412;&#26816;&#39564;&#65292;&#24182;&#19988;&#21457;&#29616;&#38750;&#21442;&#25968;&#29420;&#31435;&#24615;&#27979;&#35797;&#36890;&#24120;&#27604;&#22810;&#20803;&#26041;&#24046;&#20998;&#26512;(MANOVA)&#27979;&#35797;&#22312;&#39640;&#26031;&#20998;&#24067;&#24773;&#20917;&#19979;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/1910.08883</link><description>&lt;p&gt;
&#39640;&#32500;&#24230;&#21644;&#26222;&#36941;&#19968;&#33268;&#30340;k&#26679;&#26412;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
High-dimensional and universally consistent k-sample tests. (arXiv:1910.08883v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1910.08883
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#29420;&#31435;&#24615;&#27979;&#35797;&#23454;&#29616;&#20102;&#26222;&#36941;&#19968;&#33268;&#30340;k&#26679;&#26412;&#26816;&#39564;&#65292;&#24182;&#19988;&#21457;&#29616;&#38750;&#21442;&#25968;&#29420;&#31435;&#24615;&#27979;&#35797;&#36890;&#24120;&#27604;&#22810;&#20803;&#26041;&#24046;&#20998;&#26512;(MANOVA)&#27979;&#35797;&#22312;&#39640;&#26031;&#20998;&#24067;&#24773;&#20917;&#19979;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
k&#26679;&#26412;&#26816;&#39564;&#38382;&#39064;&#28041;&#21450;&#30830;&#23450;$k$&#32452;&#25968;&#25454;&#28857;&#26159;&#21542;&#37117;&#26469;&#33258;&#21516;&#19968;&#20010;&#20998;&#24067;&#12290;&#23613;&#31649;&#22810;&#20803;&#26041;&#24046;&#20998;&#26512;(MANOVA)&#26159;&#29983;&#29289;&#21307;&#23398;&#20013;&#24120;&#29992;&#30340;k&#26679;&#26412;&#26816;&#39564;&#26041;&#27861;&#65292;&#20294;&#23427;&#20381;&#36182;&#20110;&#24378;&#22823;&#19988;&#36890;&#24120;&#19981;&#21512;&#36866;&#30340;&#21442;&#25968;&#20551;&#35774;&#12290;&#27492;&#22806;&#65292;&#29420;&#31435;&#24615;&#27979;&#35797;&#21644;k&#26679;&#26412;&#27979;&#35797;&#23494;&#20999;&#30456;&#20851;&#65292;&#19968;&#20123;&#26222;&#36941;&#19968;&#33268;&#30340;&#39640;&#32500;&#29420;&#31435;&#24615;&#27979;&#35797;&#65292;&#22914;&#36317;&#31163;&#30456;&#20851;(Discrepancy)&#21644;Hilbert-Schmidt&#29420;&#31435;&#24615;&#20934;&#21017;(Hsic)&#65292;&#20855;&#26377;&#22362;&#23454;&#30340;&#29702;&#35770;&#21644;&#23454;&#35777;&#24615;&#36136;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#29420;&#31435;&#24615;&#27979;&#35797;&#23454;&#29616;&#20102;&#26222;&#36941;&#19968;&#33268;&#30340;k&#26679;&#26412;&#26816;&#39564;&#65292;&#24182;&#19988;k&#26679;&#26412;&#32479;&#35745;&#37327;&#65292;&#22914;Energy&#21644;Maximum Mean Discrepancy(MMD)&#65292;&#19982;Discrepancy&#23436;&#20840;&#31561;&#20215;&#12290;&#23545;&#38750;&#21442;&#25968;&#29420;&#31435;&#24615;&#27979;&#35797;&#30340;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;&#23427;&#20204;&#36890;&#24120;&#27604;&#27969;&#34892;&#30340;MANOVA&#27979;&#35797;&#34920;&#29616;&#26356;&#22909;&#65292;&#21363;&#20351;&#22312;&#39640;&#26031;&#20998;&#24067;&#30340;&#22330;&#26223;&#20013;&#20063;&#26159;&#22914;&#27492;&#12290;
&lt;/p&gt;
&lt;p&gt;
The k-sample testing problem involves determining whether $k$ groups of data points are each drawn from the same distribution. The standard method for k-sample testing in biomedicine is Multivariate analysis of variance (MANOVA), despite that it depends on strong, and often unsuitable, parametric assumptions. Moreover, independence testing and k-sample testing are closely related, and several universally consistent high-dimensional independence tests such as distance correlation (Dcorr) and Hilbert-Schmidt-Independence-Criterion (Hsic) enjoy solid theoretical and empirical properties. In this paper, we prove that independence tests achieve universally consistent k-sample testing and that k-sample statistics such as Energy and Maximum Mean Discrepancy (MMD) are precisely equivalent to Dcorr. An empirical evaluation of nonparametric independence tests showed that they generally perform better than the popular MANOVA test, even in Gaussian distributed scenarios. The evaluation included se
&lt;/p&gt;</description></item></channel></rss>