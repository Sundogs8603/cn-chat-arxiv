<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;LogEI&#20316;&#20026;&#19968;&#31867;&#26032;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#33719;&#24471;&#20989;&#25968;&#65292;&#20855;&#26377;&#19982;&#20256;&#32479;&#30340;EI&#20989;&#25968;&#30456;&#21516;&#25110;&#36817;&#20284;&#30456;&#31561;&#30340;&#26368;&#20248;&#35299;&#65292;&#20294;&#25968;&#20540;&#19978;&#26356;&#23481;&#26131;&#36827;&#34892;&#20248;&#21270;&#12290;</title><link>http://arxiv.org/abs/2310.20708</link><description>&lt;p&gt;
&#23545;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#26399;&#26395;&#25913;&#36827;&#30340;&#24847;&#22806;&#25552;&#21319;
&lt;/p&gt;
&lt;p&gt;
Unexpected Improvements to Expected Improvement for Bayesian Optimization. (arXiv:2310.20708v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20708
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;LogEI&#20316;&#20026;&#19968;&#31867;&#26032;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#33719;&#24471;&#20989;&#25968;&#65292;&#20855;&#26377;&#19982;&#20256;&#32479;&#30340;EI&#20989;&#25968;&#30456;&#21516;&#25110;&#36817;&#20284;&#30456;&#31561;&#30340;&#26368;&#20248;&#35299;&#65292;&#20294;&#25968;&#20540;&#19978;&#26356;&#23481;&#26131;&#36827;&#34892;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26399;&#26395;&#25913;&#36827;&#65288;EI&#65289;&#21487;&#20197;&#35828;&#26159;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#26368;&#27969;&#34892;&#30340;&#33719;&#24471;&#20989;&#25968;&#65292;&#24182;&#19988;&#24050;&#32463;&#22312;&#24456;&#22810;&#25104;&#21151;&#30340;&#24212;&#29992;&#20013;&#24471;&#21040;&#20102;&#24212;&#29992;&#12290;&#20294;&#26159;&#65292;EI&#30340;&#24615;&#33021;&#24448;&#24448;&#34987;&#19968;&#20123;&#26032;&#26041;&#27861;&#36229;&#36234;&#12290;&#23588;&#20854;&#26159;&#65292;EI&#21450;&#20854;&#21464;&#31181;&#22312;&#24182;&#34892;&#21644;&#22810;&#30446;&#26631;&#35774;&#32622;&#20013;&#24456;&#38590;&#36827;&#34892;&#20248;&#21270;&#65292;&#22240;&#20026;&#23427;&#20204;&#30340;&#33719;&#24471;&#20540;&#22312;&#35768;&#22810;&#21306;&#22495;&#20013;&#25968;&#20540;&#19978;&#21464;&#20026;&#38646;&#12290;&#24403;&#35266;&#27979;&#27425;&#25968;&#22686;&#21152;&#12289;&#25628;&#32034;&#31354;&#38388;&#30340;&#32500;&#24230;&#22686;&#21152;&#25110;&#32422;&#26463;&#26465;&#20214;&#30340;&#25968;&#37327;&#22686;&#21152;&#26102;&#65292;&#36825;&#31181;&#22256;&#38590;&#36890;&#24120;&#20250;&#22686;&#21152;&#65292;&#23548;&#33268;&#24615;&#33021;&#22312;&#25991;&#29486;&#20013;&#19981;&#19968;&#33268;&#19988;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#20122;&#20248;&#21270;&#12290;&#22312;&#26412;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;LogEI&#65292;&#36825;&#26159;&#19968;&#31867;&#26032;&#30340;&#37319;&#26679;&#20989;&#25968;&#12290;&#19982;&#26631;&#20934;EI&#30456;&#27604;&#65292;&#36825;&#20123;LogEI&#20989;&#25968;&#30340;&#25104;&#21592;&#35201;&#20040;&#20855;&#26377;&#30456;&#21516;&#30340;&#26368;&#20248;&#35299;&#65292;&#35201;&#20040;&#20855;&#26377;&#36817;&#20284;&#30456;&#31561;&#30340;&#26368;&#20248;&#35299;&#65292;&#20294;&#25968;&#20540;&#19978;&#26356;&#23481;&#26131;&#36827;&#34892;&#20248;&#21270;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25968;&#20540;&#30149;&#24577;&#22312;&#8220;&#32463;&#20856;&#8221;&#20998;&#26512;EI&#12289;&#26399;&#26395;&#36229;&#20307;&#31215;&#25913;&#36827;&#65288;EHVI&#65289;&#20197;&#21450;&#23427;&#20204;&#30340;...
&lt;/p&gt;
&lt;p&gt;
Expected Improvement (EI) is arguably the most popular acquisition function in Bayesian optimization and has found countless successful applications, but its performance is often exceeded by that of more recent methods. Notably, EI and its variants, including for the parallel and multi-objective settings, are challenging to optimize because their acquisition values vanish numerically in many regions. This difficulty generally increases as the number of observations, dimensionality of the search space, or the number of constraints grow, resulting in performance that is inconsistent across the literature and most often sub-optimal. Herein, we propose LogEI, a new family of acquisition functions whose members either have identical or approximately equal optima as their canonical counterparts, but are substantially easier to optimize numerically. We demonstrate that numerical pathologies manifest themselves in "classic" analytic EI, Expected Hypervolume Improvement (EHVI), as well as their
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21457;&#29616;&#22312;&#24378;&#21270;&#24494;&#35843;&#65288;RFT&#65289;&#20013;&#23384;&#22312;&#26799;&#24230;&#28040;&#22833;&#30340;&#38382;&#39064;&#65292;&#24403;&#27169;&#22411;&#19979;&#22870;&#21169;&#30340;&#26631;&#20934;&#24046;&#36739;&#23567;&#26102;&#65292;&#36755;&#20837;&#30340;&#26399;&#26395;&#26799;&#24230;&#20250;&#28040;&#22833;&#65292;&#23548;&#33268;&#22870;&#21169;&#26368;&#22823;&#21270;&#32531;&#24930;&#12290;&#21021;&#22987;&#30417;&#30563;&#24494;&#35843;&#65288;SFT&#65289;&#38454;&#27573;&#26159;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#30340;&#26368;&#26377;&#24076;&#26395;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.20703</link><description>&lt;p&gt;
&#24378;&#21270;&#24494;&#35843;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#26799;&#24230;&#28040;&#22833;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Vanishing Gradients in Reinforcement Finetuning of Language Models. (arXiv:2310.20703v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20703
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21457;&#29616;&#22312;&#24378;&#21270;&#24494;&#35843;&#65288;RFT&#65289;&#20013;&#23384;&#22312;&#26799;&#24230;&#28040;&#22833;&#30340;&#38382;&#39064;&#65292;&#24403;&#27169;&#22411;&#19979;&#22870;&#21169;&#30340;&#26631;&#20934;&#24046;&#36739;&#23567;&#26102;&#65292;&#36755;&#20837;&#30340;&#26399;&#26395;&#26799;&#24230;&#20250;&#28040;&#22833;&#65292;&#23548;&#33268;&#22870;&#21169;&#26368;&#22823;&#21270;&#32531;&#24930;&#12290;&#21021;&#22987;&#30417;&#30563;&#24494;&#35843;&#65288;SFT&#65289;&#38454;&#27573;&#26159;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#30340;&#26368;&#26377;&#24076;&#26395;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#36890;&#36807;&#24378;&#21270;&#24494;&#35843;&#65288;RFT&#65289;&#19982;&#20154;&#31867;&#20559;&#22909;&#21644;&#19979;&#28216;&#20219;&#21153;&#23545;&#40784;&#65292;&#21363;&#20351;&#29992;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#26368;&#22823;&#21270;&#65288;&#21487;&#33021;&#26159;&#23398;&#20064;&#24471;&#21040;&#30340;&#65289;&#22870;&#21169;&#20989;&#25968;&#12290;&#26412;&#30740;&#31350;&#21457;&#29616;&#20102;RFT&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#30340;&#20248;&#21270;&#38556;&#30861;&#65306;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#27169;&#22411;&#19979;&#30340;&#22870;&#21169;&#26631;&#20934;&#24046;&#36739;&#23567;&#26102;&#65292;&#36755;&#20837;&#30340;&#26399;&#26395;&#26799;&#24230;&#20250;&#28040;&#22833;&#65292;&#21363;&#20351;&#26399;&#26395;&#22870;&#21169;&#36828;&#31163;&#26368;&#20248;&#35299;&#12290;&#36890;&#36807;&#22312;RFT&#22522;&#20934;&#21644;&#25511;&#21046;&#29615;&#22659;&#20013;&#36827;&#34892;&#23454;&#39564;&#65292;&#20197;&#21450;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#30001;&#20110;&#23567;&#30340;&#22870;&#21169;&#26631;&#20934;&#24046;&#23548;&#33268;&#30340;&#26799;&#24230;&#28040;&#22833;&#38382;&#39064;&#26222;&#36941;&#23384;&#22312;&#19988;&#26377;&#23475;&#65292;&#23548;&#33268;&#22870;&#21169;&#26368;&#22823;&#21270;&#26497;&#20854;&#32531;&#24930;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#20811;&#26381;RFT&#20013;&#26799;&#24230;&#28040;&#22833;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#21457;&#29616;&#21021;&#22987;&#30417;&#30563;&#24494;&#35843;&#65288;SFT&#65289;&#38454;&#27573;&#26159;&#26368;&#26377;&#24076;&#26395;&#30340;&#20505;&#36873;&#26041;&#27861;&#65292;&#24182;&#19988;&#25581;&#31034;&#20102;&#23427;&#22312;RFT&#27969;&#31243;&#20013;&#30340;&#37325;&#35201;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#34920;&#26126;&#30456;&#23545;&#36739;&#23567;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;SFT&#38454;&#27573;&#21487;&#20197;&#26377;&#25928;&#20811;&#26381;&#26799;&#24230;&#28040;&#22833;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pretrained language models are commonly aligned with human preferences and downstream tasks via reinforcement finetuning (RFT), which entails maximizing a (possibly learned) reward function using policy gradient algorithms. This work highlights a fundamental optimization obstacle in RFT: we prove that the expected gradient for an input vanishes when its reward standard deviation under the model is small, even if the expected reward is far from optimal. Through experiments on an RFT benchmark and controlled environments, as well as a theoretical analysis, we then demonstrate that vanishing gradients due to small reward standard deviation are prevalent and detrimental, leading to extremely slow reward maximization. Lastly, we explore ways to overcome vanishing gradients in RFT. We find the common practice of an initial supervised finetuning (SFT) phase to be the most promising candidate, which sheds light on its importance in an RFT pipeline. Moreover, we show that a relatively small num
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#31515;&#21345;&#23572;&#31215;&#21644;&#31070;&#32463;&#22330;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#32593;&#32476;&#65292;&#29992;&#20110;&#22312;&#30456;&#20114;&#20316;&#29992;&#21160;&#24577;&#31995;&#32479;&#20013;&#21457;&#29616;&#23616;&#37096;&#29289;&#20307;&#30456;&#20114;&#20316;&#29992;&#21644;&#20840;&#23616;&#22330;&#25928;&#24212;&#30340;&#28508;&#22312;&#21147;&#22330;&#12290;</title><link>http://arxiv.org/abs/2310.20679</link><description>&lt;p&gt;
&#20351;&#29992;&#31070;&#32463;&#22330;&#22312;&#30456;&#20114;&#20316;&#29992;&#21160;&#24577;&#31995;&#32479;&#20013;&#21457;&#29616;&#28508;&#22312;&#22330;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
Latent Field Discovery In Interacting Dynamical Systems With Neural Fields. (arXiv:2310.20679v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20679
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#31515;&#21345;&#23572;&#31215;&#21644;&#31070;&#32463;&#22330;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#32593;&#32476;&#65292;&#29992;&#20110;&#22312;&#30456;&#20114;&#20316;&#29992;&#21160;&#24577;&#31995;&#32479;&#20013;&#21457;&#29616;&#23616;&#37096;&#29289;&#20307;&#30456;&#20114;&#20316;&#29992;&#21644;&#20840;&#23616;&#22330;&#25928;&#24212;&#30340;&#28508;&#22312;&#21147;&#22330;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30456;&#20114;&#20316;&#29992;&#23545;&#35937;&#30340;&#31995;&#32479;&#22312;&#20854;&#21160;&#21147;&#23398;&#20013;&#36890;&#24120;&#20250;&#21463;&#21040;&#22330;&#25928;&#24212;&#30340;&#24433;&#21709;&#65292;&#28982;&#32780;&#20197;&#24448;&#30340;&#30740;&#31350;&#24120;&#24120;&#24573;&#30053;&#20102;&#36825;&#20123;&#25928;&#24212;&#65292;&#20551;&#35774;&#31995;&#32479;&#22312;&#30495;&#31354;&#20013;&#28436;&#21270;&#12290;&#26412;&#25991;&#30528;&#30524;&#20110;&#21457;&#29616;&#36825;&#20123;&#22330;&#25928;&#24212;&#65292;&#24182;&#20165;&#36890;&#36807;&#35266;&#23519;&#21040;&#30340;&#21160;&#21147;&#23398;&#26469;&#36827;&#34892;&#25512;&#26029;&#65292;&#32780;&#26080;&#38656;&#30452;&#25509;&#35266;&#27979;&#23427;&#20204;&#12290;&#25105;&#20204;&#20551;&#35774;&#23384;&#22312;&#28508;&#22312;&#30340;&#21147;&#22330;&#65292;&#24182;&#25552;&#20986;&#20351;&#29992;&#31070;&#32463;&#22330;&#26469;&#23398;&#20064;&#23427;&#20204;&#12290;&#30001;&#20110;&#35266;&#23519;&#21040;&#30340;&#21160;&#21147;&#23398;&#26159;&#23616;&#37096;&#29289;&#20307;&#30456;&#20114;&#20316;&#29992;&#21644;&#25972;&#20307;&#22330;&#25928;&#24212;&#30340;&#32508;&#21512;&#32467;&#26524;&#65292;&#26368;&#36817;&#27969;&#34892;&#30340;&#31561;&#21464;&#32593;&#32476;&#26080;&#27861;&#24212;&#29992;&#65292;&#22240;&#20026;&#23427;&#20204;&#26080;&#27861;&#25429;&#25417;&#21040;&#20840;&#23616;&#20449;&#24687;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#23558;&#23616;&#37096;&#29289;&#20307;&#30456;&#20114;&#20316;&#29992;&#65288;SE(n)&#31561;&#21464;&#30340;&#65292;&#20381;&#36182;&#20110;&#30456;&#23545;&#29366;&#24577;&#65289;&#19982;&#22806;&#37096;&#20840;&#23616;&#22330;&#25928;&#24212;&#65288;&#20381;&#36182;&#20110;&#32477;&#23545;&#29366;&#24577;&#65289;&#30456;&#20998;&#31163;&#12290;&#25105;&#20204;&#20351;&#29992;&#31561;&#21464;&#22270;&#32593;&#32476;&#23545;&#30456;&#20114;&#20316;&#29992;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#23558;&#20854;&#19982;&#31070;&#32463;&#22330;&#32467;&#21512;&#22312;&#19968;&#36215;&#65292;&#26500;&#24314;&#20102;&#19968;&#31181;&#34701;&#21512;&#20102;&#22330;&#25928;&#24212;&#30340;&#22270;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
Systems of interacting objects often evolve under the influence of field effects that govern their dynamics, yet previous works have abstracted away from such effects, and assume that systems evolve in a vacuum. In this work, we focus on discovering these fields, and infer them from the observed dynamics alone, without directly observing them. We theorize the presence of latent force fields, and propose neural fields to learn them. Since the observed dynamics constitute the net effect of local object interactions and global field effects, recently popularized equivariant networks are inapplicable, as they fail to capture global information. To address this, we propose to disentangle local object interactions -- which are $\mathrm{SE}(n)$ equivariant and depend on relative states -- from external global field effects -- which depend on absolute states. We model interactions with equivariant graph networks, and combine them with neural fields in a novel graph network that integrates fiel
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20302;&#31209;&#24352;&#37327;&#32593;&#32476;&#23454;&#29616;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20801;&#35768;&#22312;&#25351;&#25968;&#25968;&#37327;&#30340;&#22522;&#20989;&#25968;&#24773;&#20917;&#19979;&#36827;&#34892;&#39640;&#25928;&#35745;&#31639;&#12290;</title><link>http://arxiv.org/abs/2310.20630</link><description>&lt;p&gt;
&#20351;&#29992;&#24352;&#37327;&#32593;&#32476;&#20026;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#25237;&#24433;&#22522;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Projecting basis functions with tensor networks for Gaussian process regression. (arXiv:2310.20630v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20630
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20302;&#31209;&#24352;&#37327;&#32593;&#32476;&#23454;&#29616;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20801;&#35768;&#22312;&#25351;&#25968;&#25968;&#37327;&#30340;&#22522;&#20989;&#25968;&#24773;&#20917;&#19979;&#36827;&#34892;&#39640;&#25928;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#24352;&#37327;&#32593;&#32476;&#23545;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#36827;&#34892;&#36817;&#20284;&#30340;&#26041;&#27861;&#12290;GP&#30340;&#21442;&#25968;&#21270;&#36817;&#20284;&#20351;&#29992;&#22522;&#20989;&#25968;&#30340;&#32447;&#24615;&#32452;&#21512;&#65292;&#20854;&#20013;&#36817;&#20284;&#30340;&#20934;&#30830;&#24615;&#21462;&#20915;&#20110;&#24635;&#22522;&#20989;&#25968;&#25968;&#37327; $M$&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#20351;&#29992;&#25351;&#25968;&#25968;&#37327;&#22522;&#20989;&#25968;&#32780;&#19981;&#24341;&#36215;&#30456;&#24212;&#25351;&#25968;&#35745;&#31639;&#22797;&#26434;&#24615;&#30340;&#26041;&#27861;&#12290;&#23454;&#29616;&#36825;&#19968;&#28857;&#30340;&#20851;&#38190;&#24605;&#24819;&#26159;&#20351;&#29992;&#20302;&#31209;&#24352;&#37327;&#32593;&#32476;&#12290;&#25105;&#20204;&#39318;&#20808;&#20174;&#25968;&#25454;&#20013;&#25214;&#21040;&#19968;&#20010;&#36866;&#24403;&#30340;&#20302;&#32500;&#23376;&#31354;&#38388;&#65292;&#35813;&#23376;&#31354;&#38388;&#30001;&#20302;&#31209;&#24352;&#37327;&#32593;&#32476;&#25551;&#36848;&#12290;&#22312;&#36825;&#20010;&#20302;&#32500;&#23376;&#31354;&#38388;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#27714;&#35299;&#36125;&#21494;&#26031;&#25512;&#29702;&#38382;&#39064;&#26469;&#25512;&#26029;&#20986;&#27169;&#22411;&#30340;&#26435;&#37325;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#24471;&#21040;&#30340;&#26435;&#37325;&#25237;&#24433;&#22238;&#21407;&#22987;&#31354;&#38388;&#36827;&#34892;GP&#39044;&#27979;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#22909;&#22788;&#22312;&#20110;&#25237;&#24433;&#21040;&#19968;&#20010;&#36739;&#23567;&#30340;&#23376;&#31354;&#38388;&#65306;&#23427;&#26681;&#25454;&#32473;&#23450;&#25968;&#25454;&#36866;&#24212;&#24615;&#22320;&#20462;&#25913;&#22522;&#20989;&#25968;&#30340;&#24418;&#29366;&#65292;&#24182;&#19988;&#20801;&#35768;&#36827;&#34892;&#39640;&#25928;&#30340;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a method for approximate Gaussian process (GP) regression with tensor networks (TNs). A parametric approximation of a GP uses a linear combination of basis functions, where the accuracy of the approximation depends on the total number of basis functions $M$. We develop an approach that allows us to use an exponential amount of basis functions without the corresponding exponential computational complexity. The key idea to enable this is using low-rank TNs. We first find a suitable low-dimensional subspace from the data, described by a low-rank TN. In this low-dimensional subspace, we then infer the weights of our model by solving a Bayesian inference problem. Finally, we project the resulting weights back to the original space to make GP predictions. The benefit of our approach comes from the projection to a smaller subspace: It modifies the shape of the basis functions in a way that it sees fit based on the given data, and it allows for efficient computations in the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#21305;&#37197;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#21333;&#20301;&#21333;&#32431;&#24418;&#36827;&#34892;&#20984;&#26494;&#24347;&#65292;&#24182;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#38236;&#20687;&#19979;&#38477;&#26041;&#26696;&#26469;&#35299;&#20915;&#35813;&#38382;&#39064;&#12290;&#22312;&#30456;&#20851;&#39640;&#26031;Wigner&#27169;&#22411;&#19979;&#65292;&#21333;&#32431;&#24418;&#26494;&#24347;&#27861;&#20855;&#26377;&#21807;&#19968;&#35299;&#65292;&#24182;&#19988;&#33021;&#22815;&#31934;&#30830;&#24674;&#22797;&#22320;&#38754;&#30495;&#23454;&#25490;&#21015;&#12290;</title><link>http://arxiv.org/abs/2310.20609</link><description>&lt;p&gt;
&#36890;&#36807;&#23545;&#21333;&#32431;&#24418;&#36827;&#34892;&#20984;&#26494;&#24347;&#35299;&#20915;&#22270;&#21305;&#37197;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Graph Matching via convex relaxation to the simplex. (arXiv:2310.20609v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20609
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#21305;&#37197;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#21333;&#20301;&#21333;&#32431;&#24418;&#36827;&#34892;&#20984;&#26494;&#24347;&#65292;&#24182;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#38236;&#20687;&#19979;&#38477;&#26041;&#26696;&#26469;&#35299;&#20915;&#35813;&#38382;&#39064;&#12290;&#22312;&#30456;&#20851;&#39640;&#26031;Wigner&#27169;&#22411;&#19979;&#65292;&#21333;&#32431;&#24418;&#26494;&#24347;&#27861;&#20855;&#26377;&#21807;&#19968;&#35299;&#65292;&#24182;&#19988;&#33021;&#22815;&#31934;&#30830;&#24674;&#22797;&#22320;&#38754;&#30495;&#23454;&#25490;&#21015;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#22270;&#21305;&#37197;&#38382;&#39064;&#36827;&#34892;&#30740;&#31350;&#65292;&#35813;&#38382;&#39064;&#21253;&#25324;&#22312;&#20004;&#20010;&#36755;&#20837;&#22270;&#20043;&#38388;&#25214;&#21040;&#26368;&#20339;&#23545;&#40784;&#65292;&#24182;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#32593;&#32476;&#21435;&#21311;&#21517;&#21270;&#21644;&#34507;&#30333;&#36136;&#23545;&#40784;&#31561;&#39046;&#22495;&#26377;&#35768;&#22810;&#24212;&#29992;&#12290;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#24120;&#35265;&#26041;&#27861;&#26159;&#36890;&#36807;&#23545;NP&#38590;&#38382;&#39064;&#8220;&#20108;&#27425;&#20998;&#37197;&#38382;&#39064;&#8221;&#65288;QAP&#65289;&#36827;&#34892;&#20984;&#26494;&#24347;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#20984;&#26494;&#24347;&#26041;&#27861;&#65292;&#21363;&#23545;&#21333;&#20301;&#21333;&#32431;&#24418;&#36827;&#34892;&#26494;&#24347;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#20855;&#26377;&#38381;&#21512;&#36845;&#20195;&#24418;&#24335;&#30340;&#39640;&#25928;&#38236;&#20687;&#19979;&#38477;&#26041;&#26696;&#26469;&#35299;&#20915;&#35813;&#38382;&#39064;&#12290;&#22312;&#30456;&#20851;&#39640;&#26031;Wigner&#27169;&#22411;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21333;&#32431;&#24418;&#26494;&#24347;&#27861;&#22312;&#39640;&#27010;&#29575;&#19979;&#20855;&#26377;&#21807;&#19968;&#35299;&#12290;&#22312;&#26080;&#22122;&#22768;&#24773;&#20917;&#19979;&#65292;&#36825;&#34987;&#35777;&#26126;&#21487;&#20197;&#31934;&#30830;&#24674;&#22797;&#22320;&#38754;&#30495;&#23454;&#25490;&#21015;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#31181;&#26032;&#30340;&#36755;&#20837;&#30697;&#38453;&#20551;&#35774;&#26465;&#20214;&#65292;&#29992;&#20110;&#26631;&#20934;&#36138;&#24515;&#21462;&#25972;&#26041;&#27861;&#65292;&#24182;&#19988;&#36825;&#20010;&#26465;&#20214;&#27604;&#24120;&#29992;&#30340;&#8220;&#23545;&#35282;&#32447;&#20248;&#21183;&#8221;&#26465;&#20214;&#26356;&#23485;&#26494;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#20010;&#26465;&#20214;&#35777;&#26126;&#20102;&#22320;&#38754;&#30495;&#23454;&#25490;&#21015;&#30340;&#31934;&#30830;&#19968;&#27493;&#24674;&#22797;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper addresses the Graph Matching problem, which consists of finding the best possible alignment between two input graphs, and has many applications in computer vision, network deanonymization and protein alignment. A common approach to tackle this problem is through convex relaxations of the NP-hard \emph{Quadratic Assignment Problem} (QAP).  Here, we introduce a new convex relaxation onto the unit simplex and develop an efficient mirror descent scheme with closed-form iterations for solving this problem. Under the correlated Gaussian Wigner model, we show that the simplex relaxation admits a unique solution with high probability. In the noiseless case, this is shown to imply exact recovery of the ground truth permutation. Additionally, we establish a novel sufficiency condition for the input matrix in standard greedy rounding methods, which is less restrictive than the commonly used `diagonal dominance' condition. We use this condition to show exact one-step recovery of the gro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#20248;&#21270;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#29305;&#23450;&#30340;&#38543;&#26426;&#23545;&#20598;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#26631;&#20934;&#22238;&#24402;&#22522;&#20934;&#21644;&#36125;&#21494;&#26031;&#20248;&#21270;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#24456;&#39640;&#30340;&#31454;&#20105;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.20581</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#27491;&#30830;&#23454;&#29616;
&lt;/p&gt;
&lt;p&gt;
Stochastic Gradient Descent for Gaussian Processes Done Right. (arXiv:2310.20581v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20581
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#20248;&#21270;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#29305;&#23450;&#30340;&#38543;&#26426;&#23545;&#20598;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#26631;&#20934;&#22238;&#24402;&#22522;&#20934;&#21644;&#36125;&#21494;&#26031;&#20248;&#21270;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#24456;&#39640;&#30340;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#24179;&#26041;&#25439;&#22833;&#20989;&#25968;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#30446;&#21069;&#65292;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#26368;&#24120;&#35265;&#26041;&#27861;&#26159;&#24212;&#29992;&#31934;&#30830;&#27714;&#35299;&#22120;&#65292;&#27604;&#22914;&#20849;&#36717;&#26799;&#24230;&#19979;&#38477;&#65292;&#35201;&#20040;&#30452;&#25509;&#24212;&#29992;&#65292;&#35201;&#20040;&#24212;&#29992;&#20110;&#38382;&#39064;&#30340;&#38477;&#38454;&#29256;&#26412;&#12290;&#26368;&#36817;&#65292;&#22312;&#28145;&#24230;&#23398;&#20064;&#30340;&#25104;&#21151;&#25512;&#21160;&#19979;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20316;&#20026;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#33719;&#24471;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;&#24403;&#27491;&#30830;&#20351;&#29992;&#26102;&#65288;&#25105;&#20204;&#25351;&#30340;&#26159;&#21033;&#29992;&#20248;&#21270;&#21644;&#26680;&#20989;&#25968;&#39046;&#22495;&#30340;&#29305;&#23450;&#35265;&#35299;&#65289;&#65292;&#36825;&#31181;&#26041;&#27861;&#26159;&#38750;&#24120;&#26377;&#25928;&#30340;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#29305;&#23450;&#30340;&#38543;&#26426;&#23545;&#20598;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#21487;&#20197;&#20351;&#29992;&#20219;&#20309;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#30340;&#20960;&#34892;&#20195;&#30721;&#23454;&#29616;&#12290;&#25105;&#20204;&#36890;&#36807;&#28040;&#34701;&#23454;&#39564;&#35299;&#37322;&#20102;&#25105;&#20204;&#30340;&#35774;&#35745;&#20915;&#31574;&#30340;&#20248;&#21183;&#65292;&#24182;&#34920;&#26126;&#26032;&#26041;&#27861;&#20855;&#26377;&#24456;&#39640;&#30340;&#31454;&#20105;&#21147;&#12290;&#25105;&#20204;&#23545;&#26631;&#20934;&#22238;&#24402;&#22522;&#20934;&#21644;&#36125;&#21494;&#26031;&#20248;&#21270;&#20219;&#21153;&#36827;&#34892;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the optimisation problem associated with Gaussian process regression using squared loss. The most common approach to this problem is to apply an exact solver, such as conjugate gradient descent, either directly, or to a reduced-order version of the problem. Recently, driven by successes in deep learning, stochastic gradient descent has gained traction as an alternative. In this paper, we show that when done right$\unicode{x2014}$by which we mean using specific insights from the optimisation and kernel communities$\unicode{x2014}$this approach is highly effective. We thus introduce a particular stochastic dual gradient descent algorithm, that may be implemented with a few lines of code using any deep learning framework. We explain our design decisions by illustrating their advantage against alternatives with ablation studies and show that the new method is highly competitive. Our evaluations on standard regression benchmarks and a Bayesian optimisation task set our approach apa
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20998;&#26512;&#30740;&#31350;&#20102;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#21021;&#22987;&#21270;&#23545;&#20110;&#38544;&#31169;&#20445;&#25252;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#38544;&#31169;&#30028;&#30340;&#25913;&#21892;&#19982;&#28145;&#24230;&#21644;&#21021;&#22987;&#21270;&#20998;&#24067;&#30340;&#20851;&#31995;&#23494;&#20999;&#30456;&#20851;&#12290;</title><link>http://arxiv.org/abs/2310.20579</link><description>&lt;p&gt;
&#21021;&#22987;&#21270;&#24456;&#37325;&#35201;&#65306;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#38544;&#31169;-&#25928;&#29992;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Initialization Matters: Privacy-Utility Analysis of Overparameterized Neural Networks. (arXiv:2310.20579v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20579
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20998;&#26512;&#30740;&#31350;&#20102;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#21021;&#22987;&#21270;&#23545;&#20110;&#38544;&#31169;&#20445;&#25252;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#38544;&#31169;&#30028;&#30340;&#25913;&#21892;&#19982;&#28145;&#24230;&#21644;&#21021;&#22987;&#21270;&#20998;&#24067;&#30340;&#20851;&#31995;&#23494;&#20999;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#20998;&#26512;&#30740;&#31350;&#20102;&#38543;&#26426;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#20013;&#27169;&#22411;&#30340;&#36229;&#21442;&#25968;&#21270;&#23545;&#35757;&#32451;&#25968;&#25454;&#20449;&#24687;&#27844;&#28431;&#30340;&#24433;&#21709;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#27169;&#22411;&#20998;&#24067;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#37051;&#36817;&#25968;&#25454;&#38598;&#38388;&#30340;KL&#25955;&#24230;&#30340;&#38544;&#31169;&#30028;&#65292;&#24182;&#25506;&#32034;&#20102;&#23427;&#19982;&#23436;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#21021;&#22987;&#21270;&#12289;&#23485;&#24230;&#21644;&#28145;&#24230;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#21457;&#29616;&#36825;&#20010;KL&#38544;&#31169;&#30028;&#20027;&#35201;&#30001;&#35757;&#32451;&#36807;&#31243;&#20013;&#27169;&#22411;&#21442;&#25968;&#30456;&#23545;&#20110;&#39044;&#26399;&#26799;&#24230;&#33539;&#25968;&#20915;&#23450;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#22312;&#32447;&#24615;&#21270;&#32593;&#32476;&#30340;&#29305;&#27530;&#35774;&#32622;&#19979;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#26799;&#24230;&#33539;&#25968;&#30340;&#24179;&#26041;&#65288;&#22240;&#27492;&#38544;&#31169;&#25439;&#22833;&#30340;&#36882;&#22686;&#65289;&#19982;&#21021;&#22987;&#21270;&#20998;&#24067;&#30340;&#27599;&#23618;&#26041;&#24046;&#30452;&#25509;&#30456;&#20851;&#12290;&#36890;&#36807;&#20351;&#29992;&#36825;&#20010;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#26576;&#20123;&#21021;&#22987;&#21270;&#65288;LeCun&#21644;Xavier&#65289;&#19979;&#65292;&#38543;&#30528;&#28145;&#24230;&#30340;&#22686;&#21152;&#65292;&#38544;&#31169;&#30028;&#24471;&#21040;&#20102;&#25913;&#21892;&#65292;&#32780;&#22312;&#20854;&#20182;&#21021;&#22987;&#21270;&#65288;He&#21644;NTK&#65289;&#19979;&#65292;&#38543;&#30528;&#28145;&#24230;&#30340;&#22686;&#21152;&#65292;&#38544;&#31169;&#30028;&#24471;&#21040;&#20102;&#24694;&#21270;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#21487;&#20197;&#24110;&#21161;&#35770;&#35777;&#21021;&#22987;&#21270;&#23545;&#20110;&#31070;&#32463;&#32593;&#32476;&#38544;&#31169;&#20445;&#25252;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analytically investigate how over-parameterization of models in randomized machine learning algorithms impacts the information leakage about their training data. Specifically, we prove a privacy bound for the KL divergence between model distributions on worst-case neighboring datasets, and explore its dependence on the initialization, width, and depth of fully connected neural networks. We find that this KL privacy bound is largely determined by the expected squared gradient norm relative to model parameters during training. Notably, for the special setting of linearized network, our analysis indicates that the squared gradient norm (and therefore the escalation of privacy loss) is tied directly to the per-layer variance of the initialization distribution. By using this analysis, we demonstrate that privacy bound improves with increasing depth under certain initializations (LeCun and Xavier), while degrades with increasing depth under other initializations (He and NTK). Our work rev
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#20219;&#21153;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21516;&#26102;&#35299;&#20915;&#20102;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#21644;&#20984;&#32452;&#21512;&#26435;&#37325;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#22238;&#24402;&#20998;&#25903;&#23398;&#20064;&#26435;&#37325;&#21644;&#20998;&#31867;&#20998;&#25903;&#36873;&#25321;&#20855;&#26377;&#22810;&#26679;&#24615;&#30340;&#39044;&#27979;&#26041;&#27861;&#65292;&#25552;&#39640;&#20102;&#22522;&#20110;&#29305;&#24449;&#30340;&#39044;&#27979;&#30340;&#31934;&#30830;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.20545</link><description>&lt;p&gt;
&#22810;&#20219;&#21153;&#23398;&#20064;&#20984;&#32452;&#21512;&#39044;&#27979;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Multi-task learning of convex combinations of forecasting models. (arXiv:2310.20545v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20545
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#20219;&#21153;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21516;&#26102;&#35299;&#20915;&#20102;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#21644;&#20984;&#32452;&#21512;&#26435;&#37325;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#22238;&#24402;&#20998;&#25903;&#23398;&#20064;&#26435;&#37325;&#21644;&#20998;&#31867;&#20998;&#25903;&#36873;&#25321;&#20855;&#26377;&#22810;&#26679;&#24615;&#30340;&#39044;&#27979;&#26041;&#27861;&#65292;&#25552;&#39640;&#20102;&#22522;&#20110;&#29305;&#24449;&#30340;&#39044;&#27979;&#30340;&#31934;&#30830;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#32452;&#21512;&#28041;&#21450;&#20351;&#29992;&#22810;&#20010;&#39044;&#27979;&#26469;&#21019;&#24314;&#21333;&#19968;&#12289;&#26356;&#31934;&#30830;&#30340;&#39044;&#27979;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#29305;&#24449;&#30340;&#39044;&#27979;&#24050;&#34987;&#29992;&#20110;&#36873;&#25321;&#26368;&#21512;&#36866;&#30340;&#39044;&#27979;&#27169;&#22411;&#25110;&#23398;&#20064;&#23427;&#20204;&#30340;&#20984;&#32452;&#21512;&#26435;&#37325;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21516;&#26102;&#35299;&#20915;&#36825;&#20004;&#20010;&#38382;&#39064;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#65292;&#20854;&#20013;&#21253;&#25324;&#20004;&#20010;&#20998;&#25903;&#65306;&#22238;&#24402;&#20998;&#25903;&#36890;&#36807;&#26368;&#23567;&#21270;&#32452;&#21512;&#39044;&#27979;&#35823;&#24046;&#26469;&#23398;&#20064;&#21508;&#31181;&#39044;&#27979;&#26041;&#27861;&#30340;&#26435;&#37325;&#65292;&#20998;&#31867;&#20998;&#25903;&#21017;&#37325;&#28857;&#36873;&#25321;&#22810;&#26679;&#24615;&#30340;&#39044;&#27979;&#26041;&#27861;&#12290;&#20026;&#20102;&#20026;&#20998;&#31867;&#20219;&#21153;&#29983;&#25104;&#35757;&#32451;&#26631;&#31614;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#20248;&#21270;&#39537;&#21160;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#30830;&#23450;&#32473;&#23450;&#26102;&#38388;&#24207;&#21015;&#30340;&#26368;&#21512;&#36866;&#30340;&#26041;&#27861;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#25581;&#31034;&#20102;&#22522;&#20110;&#29305;&#24449;&#30340;&#39044;&#27979;&#20013;&#22810;&#26679;&#24615;&#30340;&#37325;&#35201;&#20316;&#29992;&#65292;&#24182;&#20984;&#26174;&#20102;&#27169;&#22411;&#32452;&#21512;&#21644;&#36873;&#25321;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Forecast combination involves using multiple forecasts to create a single, more accurate prediction. Recently, feature-based forecasting has been employed to either select the most appropriate forecasting models or to learn the weights of their convex combination. In this paper, we present a multi-task learning methodology that simultaneously addresses both problems. This approach is implemented through a deep neural network with two branches: the regression branch, which learns the weights of various forecasting methods by minimizing the error of combined forecasts, and the classification branch, which selects forecasting methods with an emphasis on their diversity. To generate training labels for the classification task, we introduce an optimization-driven approach that identifies the most appropriate methods for a given time series. The proposed approach elicits the essential role of diversity in feature-based forecasting and highlights the interplay between model combination and mo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21151;&#33021;&#32447;&#24615;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#65292;&#29992;&#20110;&#20174;&#22810;&#20803;&#20989;&#25968;&#25968;&#25454;&#20013;&#36827;&#34892;&#22240;&#26524;&#21457;&#29616;&#12290;&#27169;&#22411;&#36890;&#36807;&#20302;&#32500;&#22240;&#26524;&#23884;&#20837;&#31354;&#38388;&#23558;&#22810;&#20803;&#20989;&#25968;&#25968;&#25454;&#20013;&#30340;&#25152;&#26377;&#30456;&#20851;&#22240;&#26524;&#20449;&#24687;&#20445;&#30041;&#19979;&#26469;&#12290;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#35813;&#27169;&#22411;&#22312;&#22240;&#26524;&#21487;&#36776;&#35782;&#24615;&#21644;&#22240;&#26524;&#22270;&#20272;&#35745;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2310.20537</link><description>&lt;p&gt;
&#20174;&#22810;&#20803;&#20989;&#25968;&#25968;&#25454;&#20013;&#36827;&#34892;&#22240;&#26524;&#21457;&#29616;&#30340;&#23450;&#21521;&#24490;&#29615;&#22270;
&lt;/p&gt;
&lt;p&gt;
Directed Cyclic Graph for Causal Discovery from Multivariate Functional Data. (arXiv:2310.20537v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20537
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21151;&#33021;&#32447;&#24615;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#65292;&#29992;&#20110;&#20174;&#22810;&#20803;&#20989;&#25968;&#25968;&#25454;&#20013;&#36827;&#34892;&#22240;&#26524;&#21457;&#29616;&#12290;&#27169;&#22411;&#36890;&#36807;&#20302;&#32500;&#22240;&#26524;&#23884;&#20837;&#31354;&#38388;&#23558;&#22810;&#20803;&#20989;&#25968;&#25968;&#25454;&#20013;&#30340;&#25152;&#26377;&#30456;&#20851;&#22240;&#26524;&#20449;&#24687;&#20445;&#30041;&#19979;&#26469;&#12290;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#35813;&#27169;&#22411;&#22312;&#22240;&#26524;&#21487;&#36776;&#35782;&#24615;&#21644;&#22240;&#26524;&#22270;&#20272;&#35745;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#20351;&#29992;&#22810;&#20803;&#20989;&#25968;&#25968;&#25454;&#36827;&#34892;&#22240;&#26524;&#20851;&#31995;&#21457;&#29616;&#24341;&#36215;&#20102;&#30456;&#24403;&#22823;&#30340;&#20851;&#27880;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#21151;&#33021;&#32447;&#24615;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#65292;&#29992;&#20110;&#22312;&#28041;&#21450;&#22810;&#20803;&#20989;&#25968;&#30340;&#24213;&#23618;&#22270;&#20013;&#36827;&#34892;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#65292;&#35813;&#22270;&#21487;&#33021;&#20855;&#26377;&#24490;&#29615;&#12290;&#20026;&#20102;&#22686;&#24378;&#35299;&#37322;&#24615;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#28041;&#21450;&#19968;&#20010;&#20302;&#32500;&#22240;&#26524;&#23884;&#20837;&#31354;&#38388;&#65292;&#20197;&#20415;&#23558;&#22810;&#20803;&#20989;&#25968;&#25968;&#25454;&#20013;&#30340;&#25152;&#26377;&#30456;&#20851;&#22240;&#26524;&#20449;&#24687;&#20445;&#30041;&#22312;&#36825;&#20010;&#36739;&#20302;&#32500;&#30340;&#23376;&#31354;&#38388;&#20013;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#22312;&#22240;&#26524;&#21457;&#29616;&#25991;&#29486;&#20013;&#24120;&#24120;&#20570;&#20986;&#30340;&#26631;&#20934;&#20551;&#35774;&#19979;&#20855;&#26377;&#22240;&#26524;&#21487;&#36776;&#35782;&#24615;&#12290;&#20026;&#20102;&#36827;&#34892;&#25105;&#20204;&#27169;&#22411;&#30340;&#25512;&#29702;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#23436;&#20840;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#21518;&#39564;&#25688;&#35201;&#26469;&#37327;&#21270;&#20808;&#39564;&#35268;&#33539;&#21644;&#19981;&#30830;&#23450;&#24615;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#22312;&#22240;&#26524;&#22270;&#20272;&#35745;&#26041;&#38754;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#21331;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Discovering causal relationship using multivariate functional data has received a significant amount of attention very recently. In this article, we introduce a functional linear structural equation model for causal structure learning when the underlying graph involving the multivariate functions may have cycles. To enhance interpretability, our model involves a low-dimensional causal embedded space such that all the relevant causal information in the multivariate functional data is preserved in this lower-dimensional subspace. We prove that the proposed model is causally identifiable under standard assumptions that are often made in the causal discovery literature. To carry out inference of our model, we develop a fully Bayesian framework with suitable prior specifications and uncertainty quantification through posterior summaries. We illustrate the superior performance of our method over existing methods in terms of causal graph estimation through extensive simulation studies. We als
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#32479;&#35745;&#20445;&#35777;&#30340;&#21442;&#25968;&#20844;&#24179;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25351;&#26631;&#26469;&#35299;&#20915;&#20844;&#24179;&#24615;&#20013;&#30340;&#20132;&#21449;&#38382;&#39064;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#21442;&#25968;&#21270;&#26041;&#27861;&#26469;&#39640;&#25928;&#35299;&#20915;&#23454;&#38469;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2310.20508</link><description>&lt;p&gt;
&#20855;&#26377;&#32479;&#35745;&#20445;&#35777;&#30340;&#21442;&#25968;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Parametric Fairness with Statistical Guarantees. (arXiv:2310.20508v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20508
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#32479;&#35745;&#20445;&#35777;&#30340;&#21442;&#25968;&#20844;&#24179;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25351;&#26631;&#26469;&#35299;&#20915;&#20844;&#24179;&#24615;&#20013;&#30340;&#20132;&#21449;&#38382;&#39064;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#21442;&#25968;&#21270;&#26041;&#27861;&#26469;&#39640;&#25928;&#35299;&#20915;&#23454;&#38469;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#23545;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#20559;&#35265;&#30340;&#31038;&#20250;&#21644;&#30417;&#31649;&#20851;&#27880;&#65292;&#31639;&#27861;&#20844;&#24179;&#24615;&#26085;&#30410;&#21463;&#21040;&#37325;&#35270;&#12290;&#24120;&#35265;&#30340;&#20998;&#31867;&#20844;&#24179;&#24615;&#25351;&#26631;&#22914;&#22343;&#34913;&#20960;&#29575;&#21644;&#20154;&#21475;&#24179;&#31561;&#20197;&#21450;&#22238;&#24402;&#20844;&#24179;&#24615;&#25351;&#26631;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#24182;&#19988;&#22260;&#32469;&#36825;&#20123;&#25351;&#26631;&#24320;&#21457;&#20102;&#35768;&#22810;&#35745;&#31639;&#20248;&#21183;&#30340;&#21518;&#22788;&#29702;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#25351;&#26631;&#36890;&#24120;&#38480;&#21046;&#29992;&#25143;&#34701;&#20837;&#39046;&#22495;&#30693;&#35782;&#12290;&#23613;&#31649;&#28385;&#36275;&#20256;&#32479;&#30340;&#20844;&#24179;&#26631;&#20934;&#65292;&#20294;&#23427;&#20204;&#21487;&#33021;&#25513;&#30422;&#19982;&#20132;&#21449;&#20844;&#24179;&#24615;&#30456;&#20851;&#30340;&#38382;&#39064;&#65292;&#29978;&#33267;&#22312;&#32467;&#26524;&#20844;&#24179;&#35299;&#20013;&#22797;&#21046;&#19981;&#24076;&#26395;&#30340;&#32452;&#20869;&#20559;&#35265;&#12290;&#20026;&#20102;&#36991;&#20813;&#36825;&#31181;&#29421;&#38552;&#30340;&#35270;&#35282;&#65292;&#25105;&#20204;&#23558;&#20154;&#21475;&#24179;&#31561;&#30340;&#27010;&#24565;&#25193;&#23637;&#21040;&#22312;&#39044;&#27979;&#20013;&#32467;&#21512;&#20998;&#24067;&#29305;&#24615;&#65292;&#20801;&#35768;&#19987;&#23478;&#30693;&#35782;&#29992;&#20110;&#20844;&#24179;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#24037;&#36164;&#30340;&#23454;&#38469;&#31034;&#20363;&#35828;&#26126;&#20102;&#36825;&#20010;&#26032;&#25351;&#26631;&#30340;&#20351;&#29992;&#65292;&#24182;&#19988;&#24320;&#21457;&#20102;&#19968;&#31181;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#39640;&#25928;&#22320;&#35299;&#20915;&#35832;&#22914;&#38480;&#21046;&#31561;&#23454;&#38469;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithmic fairness has gained prominence due to societal and regulatory concerns about biases in Machine Learning models. Common group fairness metrics like Equalized Odds for classification or Demographic Parity for both classification and regression are widely used and a host of computationally advantageous post-processing methods have been developed around them. However, these metrics often limit users from incorporating domain knowledge. Despite meeting traditional fairness criteria, they can obscure issues related to intersectional fairness and even replicate unwanted intra-group biases in the resulting fair solution. To avoid this narrow perspective, we extend the concept of Demographic Parity to incorporate distributional properties in the predictions, allowing expert knowledge to be used in the fair solution. We illustrate the use of this new metric through a practical example of wages, and develop a parametric method that efficiently addresses practical challenges like limit
&lt;/p&gt;</description></item><item><title>&#24352;&#37327;&#32593;&#32476;&#29983;&#25104;&#27169;&#22411;&#19968;&#33324;&#36866;&#29992;&#20110;&#20108;&#36827;&#21046;&#25110;&#31867;&#21035;&#25968;&#25454;&#65292;&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#22411;&#24352;&#37327;&#32593;&#32476;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#21487;&#20197;&#29992;&#20110;&#23398;&#20064;&#36830;&#32493;&#25968;&#25454;&#20998;&#24067;&#65292;&#24182;&#23637;&#31034;&#20102;&#35813;&#27169;&#22411;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2310.20498</link><description>&lt;p&gt;
&#36890;&#36807;&#24352;&#37327;&#32593;&#32476;&#29983;&#25104;&#36830;&#32493;&#25968;&#25454;&#30340;&#29983;&#25104;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Generative Learning of Continuous Data by Tensor Networks. (arXiv:2310.20498v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20498
&lt;/p&gt;
&lt;p&gt;
&#24352;&#37327;&#32593;&#32476;&#29983;&#25104;&#27169;&#22411;&#19968;&#33324;&#36866;&#29992;&#20110;&#20108;&#36827;&#21046;&#25110;&#31867;&#21035;&#25968;&#25454;&#65292;&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#22411;&#24352;&#37327;&#32593;&#32476;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#21487;&#20197;&#29992;&#20110;&#23398;&#20064;&#36830;&#32493;&#25968;&#25454;&#20998;&#24067;&#65292;&#24182;&#23637;&#31034;&#20102;&#35813;&#27169;&#22411;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24352;&#37327;&#32593;&#32476;&#38500;&#20102;&#29992;&#20110;&#24314;&#27169;&#22810;&#20307;&#37327;&#23376;&#31995;&#32479;&#22806;&#65292;&#36824;&#25104;&#20026;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#30340;&#19968;&#31867;&#26377;&#21069;&#26223;&#30340;&#27169;&#22411;&#65292;&#23588;&#20854;&#26159;&#22312;&#26080;&#30417;&#30563;&#29983;&#25104;&#23398;&#20064;&#20013;&#12290;&#28982;&#32780;&#65292;&#20197;&#37327;&#23376;&#21551;&#21457;&#24335;&#20026;&#29305;&#28857;&#30340;&#24352;&#37327;&#32593;&#32476;&#29983;&#25104;&#27169;&#22411;&#20043;&#21069;&#20027;&#35201;&#23616;&#38480;&#20110;&#20108;&#36827;&#21046;&#25110;&#31867;&#21035;&#25968;&#25454;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#29616;&#23454;&#19990;&#30028;&#24314;&#27169;&#38382;&#39064;&#20013;&#30340;&#25928;&#29992;&#12290;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#33021;&#22815;&#23398;&#20064;&#21253;&#21547;&#36830;&#32493;&#38543;&#26426;&#21464;&#37327;&#30340;&#20998;&#24067;&#30340;&#26032;&#22411;&#24352;&#37327;&#32593;&#32476;&#29983;&#25104;&#27169;&#22411;&#65292;&#20811;&#26381;&#20102;&#36825;&#19968;&#23616;&#38480;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#30697;&#38453;&#31215;&#24577;&#30340;&#35774;&#32622;&#19979;&#24320;&#21457;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#36825;&#20010;&#27169;&#22411;&#26063;&#33021;&#22815;&#20197;&#20219;&#24847;&#31934;&#24230;&#36924;&#36817;&#20219;&#20309;&#30456;&#23545;&#24179;&#28369;&#30340;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#30340;&#19968;&#33324;&#34920;&#36798;&#24615;&#23450;&#29702;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#22312;&#20960;&#20010;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#36825;&#20010;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#21457;&#29616;&#35813;&#27169;&#22411;&#20855;&#26377;&#36739;&#22909;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Beyond their origin in modeling many-body quantum systems, tensor networks have emerged as a promising class of models for solving machine learning problems, notably in unsupervised generative learning. While possessing many desirable features arising from their quantum-inspired nature, tensor network generative models have previously been largely restricted to binary or categorical data, limiting their utility in real-world modeling problems. We overcome this by introducing a new family of tensor network generative models for continuous data, which are capable of learning from distributions containing continuous random variables. We develop our method in the setting of matrix product states, first deriving a universal expressivity theorem proving the ability of this model family to approximate any reasonably smooth probability density function with arbitrary precision. We then benchmark the performance of this model on several synthetic and real-world datasets, finding that the model 
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#25910;&#25947;&#29702;&#35770;&#65292;&#20998;&#26512;&#20102;&#24322;&#27493;-SGD&#31639;&#27861;&#22312;&#24322;&#26500;&#35774;&#32622;&#19979;&#30340;&#24615;&#33021;&#65292;&#36825;&#23545;&#20110;&#25552;&#39640;&#31639;&#27861;&#24615;&#33021;&#21644;&#25910;&#25947;&#36895;&#24230;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2310.20452</link><description>&lt;p&gt;
AsGrad: &#24322;&#27493;-SGD&#31639;&#27861;&#30340;&#23574;&#38160;&#32479;&#19968;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
AsGrad: A Sharp Unified Analysis of Asynchronous-SGD Algorithms. (arXiv:2310.20452v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20452
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#25910;&#25947;&#29702;&#35770;&#65292;&#20998;&#26512;&#20102;&#24322;&#27493;-SGD&#31639;&#27861;&#22312;&#24322;&#26500;&#35774;&#32622;&#19979;&#30340;&#24615;&#33021;&#65292;&#36825;&#23545;&#20110;&#25552;&#39640;&#31639;&#27861;&#24615;&#33021;&#21644;&#25910;&#25947;&#36895;&#24230;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#20102;&#24322;&#27493;&#31867;&#22411;&#30340;&#20998;&#24067;&#24335;SGD&#31639;&#27861;&#22312;&#24322;&#26500;&#35774;&#32622;&#19979;&#30340;&#24615;&#33021;&#65292;&#20854;&#20013;&#27599;&#20010;&#24037;&#20316;&#33410;&#28857;&#37117;&#20855;&#26377;&#33258;&#24049;&#30340;&#35745;&#31639;&#21644;&#36890;&#20449;&#36895;&#24230;&#65292;&#20197;&#21450;&#25968;&#25454;&#20998;&#24067;&#12290;&#22312;&#36825;&#20123;&#31639;&#27861;&#20013;&#65292;&#24037;&#20316;&#33410;&#28857;&#26681;&#25454;&#20854;&#23616;&#37096;&#25968;&#25454;&#22312;&#26576;&#20010;&#21382;&#21490;&#36845;&#20195;&#26102;&#35745;&#31639;&#21487;&#33021;&#36807;&#26399;&#21644;&#38543;&#26426;&#30340;&#26799;&#24230;&#65292;&#28982;&#21518;&#23558;&#36825;&#20123;&#26799;&#24230;&#36820;&#22238;&#32473;&#26381;&#21153;&#22120;&#65292;&#32780;&#19981;&#19982;&#20854;&#20182;&#24037;&#20316;&#33410;&#28857;&#21516;&#27493;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#20984;&#24179;&#28369;&#20989;&#25968;&#30340;&#24322;&#26500;&#25910;&#25947;&#29702;&#35770;&#12290;&#25152;&#25552;&#20986;&#30340;&#20998;&#26512;&#20026;&#32431;&#24322;&#27493;SGD&#21450;&#20854;&#21508;&#31181;&#25913;&#36827;&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#29702;&#35770;&#35299;&#37322;&#20102;&#24433;&#21709;&#25910;&#25947;&#36895;&#24230;&#30340;&#22240;&#32032;&#20197;&#21450;&#21487;&#20197;&#37319;&#21462;&#21738;&#20123;&#26041;&#27861;&#26469;&#25552;&#39640;&#24322;&#27493;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#33410;&#28857;&#37325;&#26032;&#25490;&#24207;&#30340;&#26032;&#22411;&#24322;&#27493;&#26041;&#27861;&#12290;&#20316;&#20026;&#25105;&#20204;&#20998;&#26512;&#30340;&#21103;&#20135;&#21697;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#26799;&#24230;&#22411;&#31639;&#27861;&#65288;&#20363;&#22914;&#38543;&#26426;&#37325;&#26032;&#25490;&#24207;&#30340;SGD&#21644;&#19968;&#27425;&#38543;&#26426;&#25490;&#24207;&#65289;
&lt;/p&gt;
&lt;p&gt;
We analyze asynchronous-type algorithms for distributed SGD in the heterogeneous setting, where each worker has its own computation and communication speeds, as well as data distribution. In these algorithms, workers compute possibly stale and stochastic gradients associated with their local data at some iteration back in history and then return those gradients to the server without synchronizing with other workers. We present a unified convergence theory for non-convex smooth functions in the heterogeneous regime. The proposed analysis provides convergence for pure asynchronous SGD and its various modifications. Moreover, our theory explains what affects the convergence rate and what can be done to improve the performance of asynchronous algorithms. In particular, we introduce a novel asynchronous method based on worker shuffling. As a by-product of our analysis, we also demonstrate convergence guarantees for gradient-type algorithms such as SGD with random reshuffling and shuffle-onc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20808;&#39564;&#25968;&#25454;&#25311;&#21512;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#39640;&#25928;&#36125;&#21494;&#26031;&#23398;&#20064;&#26354;&#32447;&#22806;&#25512;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#20934;&#30830;&#19988;&#36895;&#24230;&#26356;&#24555;&#12290;</title><link>http://arxiv.org/abs/2310.20447</link><description>&lt;p&gt;
&#20351;&#29992;&#20808;&#39564;&#25968;&#25454;&#25311;&#21512;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#39640;&#25928;&#36125;&#21494;&#26031;&#23398;&#20064;&#26354;&#32447;&#22806;&#25512;
&lt;/p&gt;
&lt;p&gt;
Efficient Bayesian Learning Curve Extrapolation using Prior-Data Fitted Networks. (arXiv:2310.20447v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20447
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20808;&#39564;&#25968;&#25454;&#25311;&#21512;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#39640;&#25928;&#36125;&#21494;&#26031;&#23398;&#20064;&#26354;&#32447;&#22806;&#25512;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#20934;&#30830;&#19988;&#36895;&#24230;&#26356;&#24555;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#26354;&#32447;&#22806;&#25512;&#26088;&#22312;&#22522;&#20110;&#26089;&#26399;&#35757;&#32451;&#38454;&#27573;&#30340;&#34920;&#29616;&#26469;&#39044;&#27979;&#27169;&#22411;&#22312;&#21518;&#26399;&#35757;&#32451;&#20013;&#30340;&#24615;&#33021;&#12290;&#26412;&#25991;&#35748;&#20026;&#65292;&#34429;&#28982;&#23398;&#20064;&#26354;&#32447;&#22806;&#25512;&#20013;&#30340;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#38656;&#35201;&#37319;&#29992;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#20294;&#29616;&#26377;&#26041;&#27861;&#35201;&#20040;&#36807;&#20110;&#38480;&#21046;&#65292;&#35201;&#20040;&#35745;&#31639;&#25104;&#26412;&#36807;&#39640;&#12290;&#25105;&#20204;&#39318;&#27425;&#22312;&#36825;&#20010;&#39046;&#22495;&#24212;&#29992;&#20102;&#20808;&#39564;&#25968;&#25454;&#25311;&#21512;&#31070;&#32463;&#32593;&#32476;&#65288;PFN&#65289;&#12290;PFN&#26159;&#19968;&#20010;&#22312;&#20808;&#39564;&#25968;&#25454;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#30340;&#36716;&#25442;&#22120;&#65292;&#36890;&#36807;&#19968;&#27425;&#21069;&#21521;&#20256;&#36882;&#36827;&#34892;&#36817;&#20284;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;LC-PFN&#65292;&#19968;&#20010;&#36890;&#36807;MCMC&#22312;&#20808;&#21069;&#25991;&#29486;&#20013;&#25552;&#20986;&#30340;&#21442;&#25968;&#21270;&#20808;&#39564;&#29983;&#25104;&#30340;1000&#19975;&#26465;&#20154;&#36896;&#21491;&#25130;&#23614;&#23398;&#20064;&#26354;&#32447;&#36827;&#34892;&#35757;&#32451;&#30340;PFN&#12290;&#25105;&#20204;&#35777;&#26126;LC-PFN&#27604;MCMC&#26356;&#20934;&#30830;&#22320;&#36817;&#20284;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#65292;&#24182;&#19988;&#36895;&#24230;&#24555;&#20102;&#36229;&#36807;10,000&#20493;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#30456;&#21516;&#30340;LC-PFN&#22312;&#22806;&#25512;&#24635;&#20849;20,000&#26465;&#30495;&#23454;&#23398;&#20064;&#26354;&#32447;&#26102;&#20855;&#26377;&#31454;&#20105;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning curve extrapolation aims to predict model performance in later epochs of training, based on the performance in earlier epochs. In this work, we argue that, while the inherent uncertainty in the extrapolation of learning curves warrants a Bayesian approach, existing methods are (i) overly restrictive, and/or (ii) computationally expensive. We describe the first application of prior-data fitted neural networks (PFNs) in this context. A PFN is a transformer, pre-trained on data generated from a prior, to perform approximate Bayesian inference in a single forward pass. We propose LC-PFN, a PFN trained to extrapolate 10 million artificial right-censored learning curves generated from a parametric prior proposed in prior art using MCMC. We demonstrate that LC-PFN can approximate the posterior predictive distribution more accurately than MCMC, while being over 10 000 times faster. We also show that the same LC-PFN achieves competitive performance extrapolating a total of 20 000 real 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#27927;&#29260;&#22238;&#24402;&#38382;&#39064;&#30340;&#30456;&#21464;&#29616;&#35937;&#65292;&#24182;&#21033;&#29992;&#20449;&#24687;&#20256;&#36882;&#25216;&#26415;&#30830;&#23450;&#20102;&#30456;&#21464;&#28857;&#30340;&#20301;&#32622;&#65292;&#20026;&#25490;&#21015;&#24674;&#22797;&#38382;&#39064;&#25552;&#20379;&#20102;&#20998;&#26512;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2310.20438</link><description>&lt;p&gt;
&#27927;&#29260;&#22238;&#24402;&#38382;&#39064;&#30340;&#30456;&#21464;&#29616;&#35937;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
The Phase Transition Phenomenon of Shuffled Regression. (arXiv:2310.20438v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20438
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#27927;&#29260;&#22238;&#24402;&#38382;&#39064;&#30340;&#30456;&#21464;&#29616;&#35937;&#65292;&#24182;&#21033;&#29992;&#20449;&#24687;&#20256;&#36882;&#25216;&#26415;&#30830;&#23450;&#20102;&#30456;&#21464;&#28857;&#30340;&#20301;&#32622;&#65292;&#20026;&#25490;&#21015;&#24674;&#22797;&#38382;&#39064;&#25552;&#20379;&#20102;&#20998;&#26512;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#27927;&#29260;&#65288;&#25490;&#21015;&#65289;&#22238;&#24402;&#38382;&#39064;&#20013;&#22266;&#26377;&#30340;&#30456;&#21464;&#29616;&#35937;&#65292;&#22312;&#25968;&#25454;&#24211;&#12289;&#38544;&#31169;&#12289;&#25968;&#25454;&#20998;&#26512;&#31561;&#39046;&#22495;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#21033;&#29992;&#20449;&#24687;&#20256;&#36882;&#65288;MP&#65289;&#25216;&#26415;&#20934;&#30830;&#22320;&#30830;&#23450;&#30456;&#21464;&#28857;&#30340;&#20301;&#32622;&#12290;&#22312;&#20998;&#26512;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#23558;&#25490;&#21015;&#24674;&#22797;&#38382;&#39064;&#36716;&#21270;&#20026;&#19968;&#20010;&#27010;&#29575;&#22270;&#27169;&#22411;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#20449;&#24687;&#20256;&#36882;&#31639;&#27861;&#30340;&#20998;&#26512;&#24037;&#20855;&#65292;&#24182;&#25512;&#23548;&#20986;&#19968;&#20010;&#26041;&#31243;&#26469;&#36319;&#36394;&#20449;&#24687;&#20256;&#36882;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;&#36890;&#36807;&#23558;&#36825;&#20010;&#26041;&#31243;&#19982;&#20998;&#25903;&#38543;&#26426;&#34892;&#36208;&#36807;&#31243;&#30456;&#32852;&#31995;&#65292;&#25105;&#20204;&#33021;&#22815;&#25551;&#36848;&#20449;&#22122;&#27604;&#65288;SNR&#65289;&#23545;&#25490;&#21015;&#24674;&#22797;&#30340;&#24433;&#21709;&#12290;&#26681;&#25454;&#20449;&#21495;&#26159;&#21542;&#24050;&#30693;&#65292;&#25105;&#20204;&#20998;&#21035;&#30740;&#31350;&#20102;&#31070;&#35861;&#24773;&#20917;&#21644;&#38750;&#31070;&#35861;&#24773;&#20917;&#12290;&#30830;&#23450;&#30456;&#21464;&#21306;&#22495;&#30340;&#29942;&#39048;&#22312;&#20110;&#25512;&#23548;&#30456;&#24212;&#20020;&#30028;&#28857;&#30340;&#38381;&#21512;&#20844;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the phase transition phenomenon inherent in the shuffled (permuted) regression problem, which has found numerous applications in databases, privacy, data analysis, etc. In this study, we aim to precisely identify the locations of the phase transition points by leveraging techniques from message passing (MP). In our analysis, we first transform the permutation recovery problem into a probabilistic graphical model. We then leverage the analytical tools rooted in the message passing (MP) algorithm and derive an equation to track the convergence of the MP algorithm. By linking this equation to the branching random walk process, we are able to characterize the impact of the signal-to-noise-ratio ($\snr$) on the permutation recovery. Depending on whether the signal is given or not, we separately investigate the oracle case and the non-oracle case. The bottleneck in identifying the phase transition regimes lies in deriving closed-form formulas for the corresponding critical points, b
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32676;&#20307;&#21338;&#24328;&#20013;&#30340;&#25805;&#32437;&#29616;&#35937;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;Shapley&#20540;&#22522;&#30784;&#65292;&#23427;&#26159;&#21807;&#19968;&#30340;&#26377;&#25928;&#21644;&#23545;&#31216;&#30340;&#20998;&#37197;&#35268;&#21017;&#65292;&#23545;&#38598;&#20307;&#25805;&#32437;&#20855;&#26377;&#20813;&#30123;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.20415</link><description>&lt;p&gt;
&#32676;&#20307;&#25805;&#32437;&#19982;Shapley&#20540;&#30340;&#20813;&#30123;&#24615;
&lt;/p&gt;
&lt;p&gt;
Coalitional Manipulations and Immunity of the Shapley Value. (arXiv:2310.20415v1 [econ.TH])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20415
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32676;&#20307;&#21338;&#24328;&#20013;&#30340;&#25805;&#32437;&#29616;&#35937;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;Shapley&#20540;&#22522;&#30784;&#65292;&#23427;&#26159;&#21807;&#19968;&#30340;&#26377;&#25928;&#21644;&#23545;&#31216;&#30340;&#20998;&#37197;&#35268;&#21017;&#65292;&#23545;&#38598;&#20307;&#25805;&#32437;&#20855;&#26377;&#20813;&#30123;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#32676;&#20307;&#21338;&#24328;&#30340;&#32972;&#26223;&#19979;&#30340;&#25805;&#32437;&#65292;&#20854;&#20013;&#19968;&#20010;&#32852;&#30431;&#26088;&#22312;&#22686;&#21152;&#20854;&#25104;&#21592;&#30340;&#24635;&#25903;&#20184;&#12290;&#22914;&#26524;&#19968;&#31181;&#20998;&#37197;&#35268;&#21017;&#23545;&#38598;&#20307;&#25805;&#32437;&#20813;&#30123;&#65292;&#37027;&#20040;&#27809;&#26377;&#20219;&#20309;&#32852;&#30431;&#21487;&#20197;&#36890;&#36807;&#22312;&#20854;&#23376;&#32852;&#30431;&#30340;&#23618;&#32423;&#19978;&#37325;&#26032;&#20998;&#37197;&#20215;&#20540;&#26469;&#33719;&#30410;&#65288;&#20855;&#26377;&#37325;&#26032;&#20998;&#37197;&#35777;&#26126;&#24615;&#65289;&#65292;&#32780;&#19988;&#22914;&#26524;&#22312;&#20854;&#20182;&#26465;&#20214;&#19981;&#21464;&#30340;&#24773;&#20917;&#19979;&#65292;&#27809;&#26377;&#20219;&#20309;&#32852;&#30431;&#21487;&#20197;&#20174;&#36739;&#20302;&#30340;&#20215;&#20540;&#20013;&#21463;&#30410;&#65288;&#20855;&#26377;&#24369;&#38598;&#20307;&#21333;&#35843;&#24615;&#65289;&#12290;&#23558;Shapley&#22312;&#21407;&#22987;&#29305;&#24449;&#30340;&#21487;&#21152;&#24615;&#26367;&#25442;&#20026;&#36825;&#20123;&#35201;&#27714;&#21487;&#20197;&#24471;&#21040;Shapley&#20540;&#30340;&#26032;&#22522;&#30784;&#65292;&#21363;&#23427;&#26159;&#21807;&#19968;&#30340;&#26377;&#25928;&#21644;&#23545;&#31216;&#30340;&#20998;&#37197;&#35268;&#21017;&#65292;&#23545;&#31354;&#29609;&#23478;&#19981;&#20104;&#20219;&#20309;&#22870;&#21169;&#65292;&#24182;&#19988;&#23545;&#38598;&#20307;&#25805;&#32437;&#20813;&#30123;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#21457;&#29616;&#65292;&#23545;&#20110;&#26377;&#25928;&#30340;&#20998;&#37197;&#35268;&#21017;&#65292;&#37325;&#26032;&#20998;&#37197;&#35777;&#26126;&#24615;&#31561;&#25928;&#20110;&#26377;&#32422;&#26463;&#30340;&#36793;&#38469;&#24615;&#65292;&#36825;&#26159;Young&#30340;&#36793;&#38469;&#24615;&#20844;&#29702;&#30340;&#19968;&#20010;&#36739;&#24369;&#21464;&#20307;&#12290;&#25105;&#20204;&#30340;&#31532;&#20108;&#20010;&#29305;&#24449;&#25913;&#36827;&#20102;Young&#30340;&#29305;&#24449;&#65292;&#24369;&#21270;&#20102;&#36793;&#38469;&#24615;&#20869;&#22312;&#30340;&#29420;&#31435;&#24615;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider manipulations in the context of coalitional games, where a coalition aims to increase the total payoff of its members. An allocation rule is immune to coalitional manipulation if no coalition can benefit from internal reallocation of worth on the level of its subcoalitions (reallocation-proofness), and if no coalition benefits from a lower worth while all else remains the same (weak coalitional monotonicity). Replacing additivity in Shapley's original characterization by these requirements yields a new foundation of the Shapley value, i.e., it is the unique efficient and symmetric allocation rule that awards nothing to a null player and is immune to coalitional manipulations. We further find that for efficient allocation rules, reallocation-proofness is equivalent to constrained marginality, a weaker variant of Young's marginality axiom. Our second characterization improves upon Young's characterization by weakening the independence requirement intrinsic to marginality.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#22810;&#22522;&#31449;&#21512;&#20316;&#24863;&#30693;&#32593;&#32476;&#65292;&#22312;&#27492;&#32593;&#32476;&#20013;&#65292;&#21508;&#20010;&#22522;&#31449;&#20381;&#27425;&#36827;&#34892;&#38647;&#36798;&#25195;&#25551;&#24182;&#36890;&#36807;&#34701;&#21512;&#20013;&#24515;&#36827;&#34892;&#20449;&#24687;&#20132;&#25442;&#65292;&#21033;&#29992;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#36741;&#21161;&#32858;&#31867;&#31639;&#27861;&#65292;&#33021;&#22815;&#26356;&#20934;&#30830;&#22320;&#20998;&#32452;&#24182;&#36319;&#36394;&#26816;&#27979;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.20403</link><description>&lt;p&gt;
&#22810;&#22522;&#31449;&#21512;&#20316;&#24863;&#30693;&#19982;AI&#36741;&#21161;&#36319;&#36394;
&lt;/p&gt;
&lt;p&gt;
Multi-Base Station Cooperative Sensing with AI-Aided Tracking. (arXiv:2310.20403v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20403
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#22810;&#22522;&#31449;&#21512;&#20316;&#24863;&#30693;&#32593;&#32476;&#65292;&#22312;&#27492;&#32593;&#32476;&#20013;&#65292;&#21508;&#20010;&#22522;&#31449;&#20381;&#27425;&#36827;&#34892;&#38647;&#36798;&#25195;&#25551;&#24182;&#36890;&#36807;&#34701;&#21512;&#20013;&#24515;&#36827;&#34892;&#20449;&#24687;&#20132;&#25442;&#65292;&#21033;&#29992;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#36741;&#21161;&#32858;&#31867;&#31639;&#27861;&#65292;&#33021;&#22815;&#26356;&#20934;&#30830;&#22320;&#20998;&#32452;&#24182;&#36319;&#36394;&#26816;&#27979;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#30001;&#22810;&#20010;&#22522;&#31449;&#32452;&#25104;&#30340;&#32852;&#21512;&#24863;&#30693;&#21644;&#36890;&#20449;&#65288;JSC&#65289;&#32593;&#32476;&#30340;&#24615;&#33021;&#65292;&#36825;&#20123;&#22522;&#31449;&#36890;&#36807;&#19968;&#20010;&#34701;&#21512;&#20013;&#24515;&#65288;FC&#65289;&#21512;&#20316;&#65292;&#20132;&#25442;&#26377;&#20851;&#24863;&#30693;&#29615;&#22659;&#30340;&#20449;&#24687;&#65292;&#21516;&#26102;&#19982;&#19968;&#32452;&#29992;&#25143;&#35774;&#22791;&#65288;UEs&#65289;&#24314;&#31435;&#36890;&#20449;&#38142;&#36335;&#12290;&#32593;&#32476;&#20013;&#30340;&#27599;&#20010;&#22522;&#31449;&#37117;&#20316;&#20026;&#19968;&#20010;&#21333;&#20853;&#38647;&#36798;&#31995;&#32479;&#36816;&#34892;&#65292;&#33021;&#22815;&#23545;&#30417;&#27979;&#21306;&#22495;&#36827;&#34892;&#20840;&#38754;&#25195;&#25551;&#65292;&#24182;&#29983;&#25104;&#25552;&#20379;&#20851;&#20110;&#19968;&#32452;&#24322;&#26500;&#29289;&#20307;&#20301;&#32622;&#30340;&#36317;&#31163;-&#35282;&#24230;&#22270;&#12290;&#33719;&#21462;&#21040;&#30340;&#22320;&#22270;&#38543;&#21518;&#22312;FC&#20013;&#36827;&#34892;&#34701;&#21512;&#12290;&#28982;&#21518;&#65292;&#37319;&#29992;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#26469;&#25512;&#26029;&#30446;&#26631;&#30340;&#31867;&#21035;&#65292;&#20363;&#22914;&#34892;&#20154;&#25110;&#36710;&#36742;&#65292;&#24182;&#19988;&#36825;&#20123;&#20449;&#24687;&#34987;&#33258;&#36866;&#24212;&#32858;&#31867;&#31639;&#27861;&#21033;&#29992;&#65292;&#20174;&#32780;&#26356;&#26377;&#25928;&#22320;&#23558;&#26469;&#33258;&#21516;&#19968;&#30446;&#26631;&#30340;&#26816;&#27979;&#32467;&#26524;&#36827;&#34892;&#20998;&#32452;&#12290;&#26368;&#21518;&#65292;&#37319;&#29992;&#20102;&#20004;&#31181;&#22810;&#30446;&#26631;&#36319;&#36394;&#31639;&#27861;&#65292;&#21363;&#27010;&#29575;&#20551;&#35774;&#23494;&#24230;&#65288;PHD&#65289;&#28388;&#27874;&#22120;&#21644;&#22810;&#20271;&#21162;&#21033;&#28151;&#21512;&#28388;&#27874;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we investigate the performance of a joint sensing and communication (JSC) network consisting of multiple base stations (BSs) that cooperate through a fusion center (FC) to exchange information about the sensed environment while concurrently establishing communication links with a set of user equipments (UEs). Each BS within the network operates as a monostatic radar system, enabling comprehensive scanning of the monitored area and generating range-angle maps that provide information regarding the position of a group of heterogeneous objects. The acquired maps are subsequently fused in the FC. Then, a convolutional neural network (CNN) is employed to infer the category of the targets, e.g., pedestrians or vehicles, and such information is exploited by an adaptive clustering algorithm to group the detections originating from the same target more effectively. Finally, two multi-target tracking algorithms, the probability hypothesis density (PHD) filter and multi-Bernoulli mi
&lt;/p&gt;</description></item><item><title>&#26412;&#20070;&#25552;&#20379;&#20102;&#23545;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#25968;&#23398;&#20171;&#32461;&#65292;&#21253;&#25324;&#19981;&#21516;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#21644;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#28085;&#30422;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#29702;&#35770;&#26041;&#38754;&#12290;&#27492;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#36924;&#36817;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#26041;&#27861;&#12290;&#24076;&#26395;&#23545;&#23398;&#29983;&#21644;&#31185;&#23398;&#23478;&#20204;&#26377;&#25152;&#24110;&#21161;&#12290;</title><link>http://arxiv.org/abs/2310.20360</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#25968;&#23398;&#20171;&#32461;&#65306;&#26041;&#27861;&#12289;&#23454;&#29616;&#21644;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory. (arXiv:2310.20360v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20360
&lt;/p&gt;
&lt;p&gt;
&#26412;&#20070;&#25552;&#20379;&#20102;&#23545;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#25968;&#23398;&#20171;&#32461;&#65292;&#21253;&#25324;&#19981;&#21516;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#21644;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#28085;&#30422;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#29702;&#35770;&#26041;&#38754;&#12290;&#27492;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#36924;&#36817;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#26041;&#27861;&#12290;&#24076;&#26395;&#23545;&#23398;&#29983;&#21644;&#31185;&#23398;&#23478;&#20204;&#26377;&#25152;&#24110;&#21161;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#20070;&#26088;&#22312;&#20171;&#32461;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#20027;&#39064;&#12290;&#25105;&#20204;&#35814;&#32454;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#22522;&#26412;&#32452;&#25104;&#37096;&#20998;&#65292;&#21253;&#25324;&#19981;&#21516;&#30340;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65288;&#22914;&#20840;&#36830;&#25509;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#12289;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#12289;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#12289;&#27531;&#24046;&#31070;&#32463;&#32593;&#32476;&#21644;&#24102;&#26377;&#25209;&#24402;&#19968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#65289;&#20197;&#21450;&#19981;&#21516;&#30340;&#20248;&#21270;&#31639;&#27861;&#65288;&#22914;&#22522;&#26412;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#27861;&#12289;&#21152;&#36895;&#26041;&#27861;&#21644;&#33258;&#36866;&#24212;&#26041;&#27861;&#65289;&#12290;&#25105;&#20204;&#36824;&#28085;&#30422;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#20960;&#20010;&#29702;&#35770;&#26041;&#38754;&#65292;&#22914;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#33021;&#21147;&#65288;&#21253;&#25324;&#31070;&#32463;&#32593;&#32476;&#30340;&#24494;&#31215;&#20998;&#65289;&#12289;&#20248;&#21270;&#29702;&#35770;&#65288;&#21253;&#25324;Kurdyka-Lojasiewicz&#19981;&#31561;&#24335;&#65289;&#21644;&#27867;&#21270;&#35823;&#24046;&#12290;&#22312;&#26412;&#20070;&#30340;&#26368;&#21518;&#19968;&#37096;&#20998;&#65292;&#25105;&#20204;&#36824;&#22238;&#39038;&#20102;&#19968;&#20123;&#29992;&#20110;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#28145;&#24230;&#23398;&#20064;&#36924;&#36817;&#26041;&#27861;&#65292;&#21253;&#25324;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#65288;PINNs&#65289;&#21644;&#28145;&#24230;Galerkin&#26041;&#27861;&#12290;&#24076;&#26395;&#26412;&#20070;&#33021;&#23545;&#23398;&#29983;&#21644;&#31185;&#23398;&#23478;&#20204;&#26377;&#25152;&#24110;&#21161;&#12290;
&lt;/p&gt;
&lt;p&gt;
This book aims to provide an introduction to the topic of deep learning algorithms. We review essential components of deep learning algorithms in full mathematical detail including different artificial neural network (ANN) architectures (such as fully-connected feedforward ANNs, convolutional ANNs, recurrent ANNs, residual ANNs, and ANNs with batch normalization) and different optimization algorithms (such as the basic stochastic gradient descent (SGD) method, accelerated methods, and adaptive methods). We also cover several theoretical aspects of deep learning algorithms such as approximation capacities of ANNs (including a calculus for ANNs), optimization theory (including Kurdyka-{\L}ojasiewicz inequalities), and generalization errors. In the last part of the book some deep learning approximation methods for PDEs are reviewed including physics-informed neural networks (PINNs) and deep Galerkin methods. We hope that this book will be useful for students and scientists who do not yet 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36845;&#20195;&#26041;&#27861;&#65292;&#36890;&#36807;&#22686;&#21152;&#19981;&#30830;&#23450;&#24615;&#26469;&#38477;&#20302;&#35745;&#31639;&#37327;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#35757;&#32451;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.20285</link><description>&lt;p&gt;
&#36890;&#36807;&#20197;&#35745;&#31639;&#20026;&#20195;&#20215;&#21152;&#36895;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Accelerating Generalized Linear Models by Trading off Computation for Uncertainty. (arXiv:2310.20285v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20285
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36845;&#20195;&#26041;&#27861;&#65292;&#36890;&#36807;&#22686;&#21152;&#19981;&#30830;&#23450;&#24615;&#26469;&#38477;&#20302;&#35745;&#31639;&#37327;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#35757;&#32451;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;GLMs&#65289;&#23450;&#20041;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#29992;&#20110;&#24314;&#27169;&#20998;&#31867;&#12289;&#26377;&#24207;&#21644;&#36830;&#32493;&#25968;&#25454;&#65292;&#24182;&#19988;&#22312;&#23454;&#36341;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#65292;GLMs&#30340;&#31934;&#30830;&#25512;&#26029;&#20195;&#20215;&#22826;&#39640;&#65292;&#22240;&#27492;&#38656;&#35201;&#22312;&#23454;&#36341;&#20013;&#36827;&#34892;&#36817;&#20284;&#12290;&#36896;&#25104;&#30340;&#36817;&#20284;&#35823;&#24046;&#23545;&#27169;&#22411;&#30340;&#21487;&#38752;&#24615;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#65292;&#24182;&#19988;&#27809;&#26377;&#34987;&#32771;&#34385;&#22312;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#20013;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31995;&#21015;&#36845;&#20195;&#26041;&#27861;&#65292;&#26126;&#30830;&#22320;&#23545;&#36825;&#20010;&#35823;&#24046;&#24314;&#27169;&#12290;&#23427;&#20204;&#38750;&#24120;&#36866;&#21512;&#24182;&#34892;&#35745;&#31639;&#30828;&#20214;&#65292;&#26377;&#25928;&#22320;&#22238;&#25910;&#35745;&#31639;&#24182;&#21387;&#32553;&#20449;&#24687;&#65292;&#20197;&#20943;&#23569;GLMs&#30340;&#26102;&#38388;&#21644;&#20869;&#23384;&#38656;&#27714;&#12290;&#27491;&#22914;&#25105;&#20204;&#22312;&#19968;&#20010;&#23454;&#38469;&#30340;&#22823;&#22411;&#20998;&#31867;&#38382;&#39064;&#19978;&#23637;&#31034;&#30340;&#37027;&#26679;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#26126;&#30830;&#22320;&#23558;&#20943;&#23569;&#35745;&#31639;&#19982;&#22686;&#21152;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#26435;&#34913;&#26469;&#26174;&#33879;&#21152;&#36895;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian Generalized Linear Models (GLMs) define a flexible probabilistic framework to model categorical, ordinal and continuous data, and are widely used in practice. However, exact inference in GLMs is prohibitively expensive for large datasets, thus requiring approximations in practice. The resulting approximation error adversely impacts the reliability of the model and is not accounted for in the uncertainty of the prediction. In this work, we introduce a family of iterative methods that explicitly model this error. They are uniquely suited to parallel modern computing hardware, efficiently recycle computations, and compress information to reduce both the time and memory requirements for GLMs. As we demonstrate on a realistically large classification problem, our method significantly accelerates training by explicitly trading off reduced computation for increased uncertainty.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24352;&#37327;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#22810;&#39033;&#24335;&#28151;&#21512;&#27169;&#22411;&#65292;&#21033;&#29992;&#22270;&#24418;&#32467;&#26500;&#21644;&#31354;&#38388;&#35821;&#20041;&#22270;&#23545;&#22522;&#20110;&#36712;&#36857;&#35760;&#24405;&#30340;&#20056;&#23458;&#32858;&#31867;&#36827;&#34892;&#20102;&#25913;&#36827;&#65292;&#33021;&#22312;&#19968;&#27493;&#20013;&#33258;&#21160;&#30830;&#23450;&#32858;&#31867;&#25968;&#37327;&#65292;&#24182;&#20445;&#30041;&#20102;&#22810;&#32500;&#20986;&#34892;&#20449;&#24687;&#30340;&#20998;&#23618;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2310.20224</link><description>&lt;p&gt;
&#36873;&#25321;&#19968;&#20010;&#34920;&#65306;&#22522;&#20110;&#22270;&#30340;&#24352;&#37327;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#22810;&#39033;&#24335;&#28151;&#21512;&#27169;&#22411;&#29992;&#20110;&#20056;&#23458;&#36712;&#36857;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Choose A Table: Tensor Dirichlet Process Multinomial Mixture Model with Graphs for Passenger Trajectory Clustering. (arXiv:2310.20224v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20224
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24352;&#37327;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#22810;&#39033;&#24335;&#28151;&#21512;&#27169;&#22411;&#65292;&#21033;&#29992;&#22270;&#24418;&#32467;&#26500;&#21644;&#31354;&#38388;&#35821;&#20041;&#22270;&#23545;&#22522;&#20110;&#36712;&#36857;&#35760;&#24405;&#30340;&#20056;&#23458;&#32858;&#31867;&#36827;&#34892;&#20102;&#25913;&#36827;&#65292;&#33021;&#22312;&#19968;&#27493;&#20013;&#33258;&#21160;&#30830;&#23450;&#32858;&#31867;&#25968;&#37327;&#65292;&#24182;&#20445;&#30041;&#20102;&#22810;&#32500;&#20986;&#34892;&#20449;&#24687;&#30340;&#20998;&#23618;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#36712;&#36857;&#35760;&#24405;&#30340;&#20056;&#23458;&#32858;&#31867;&#23545;&#20110;&#20132;&#36890;&#36816;&#33829;&#21830;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#30001;&#20110;&#20056;&#23458;&#20986;&#34892;&#20449;&#24687;&#30340;&#20998;&#23618;&#32467;&#26500;&#65292;&#21253;&#25324;&#27599;&#20010;&#20056;&#23458;&#20869;&#37096;&#30340;&#22810;&#27425;&#20986;&#34892;&#20197;&#21450;&#27599;&#27425;&#20986;&#34892;&#30340;&#22810;&#32500;&#20449;&#24687;&#65292;&#26080;&#27861;&#36731;&#26494;&#22320;&#32858;&#31867;&#20056;&#23458;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#26041;&#27861;&#20381;&#36182;&#20110;&#20934;&#30830;&#25351;&#23450;&#32858;&#31867;&#25968;&#37327;&#30340;&#36215;&#22987;&#20540;&#12290;&#26368;&#21518;&#65292;&#29616;&#26377;&#26041;&#27861;&#26410;&#32771;&#34385;&#31354;&#38388;&#35821;&#20041;&#22270;&#65292;&#22914;&#22320;&#29702;&#37051;&#36817;&#24615;&#21644;&#20301;&#32622;&#38388;&#30340;&#21151;&#33021;&#30456;&#20284;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#22270;&#30340;&#24352;&#37327;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#22810;&#39033;&#24335;&#28151;&#21512;&#27169;&#22411;&#65292;&#23427;&#33021;&#22815;&#20445;&#30041;&#22810;&#32500;&#20986;&#34892;&#20449;&#24687;&#30340;&#20998;&#23618;&#32467;&#26500;&#65292;&#24182;&#33021;&#20197;&#32479;&#19968;&#30340;&#19968;&#27493;&#26041;&#24335;&#23545;&#20854;&#36827;&#34892;&#32858;&#31867;&#65292;&#20855;&#26377;&#33258;&#21160;&#30830;&#23450;&#32858;&#31867;&#25968;&#37327;&#30340;&#33021;&#21147;&#12290;&#31354;&#38388;&#22270;&#34987;&#29992;&#20110;&#31038;&#21306;&#26816;&#27979;&#20197;&#36830;&#25509;&#35821;&#20041;&#37051;&#23621;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#24352;&#37327;&#29256;&#26412;&#30340;Coll...
&lt;/p&gt;
&lt;p&gt;
Passenger clustering based on trajectory records is essential for transportation operators. However, existing methods cannot easily cluster the passengers due to the hierarchical structure of the passenger trip information, including multiple trips within each passenger and multi-dimensional information about each trip. Furthermore, existing approaches rely on an accurate specification of the clustering number to start. Finally, existing methods do not consider spatial semantic graphs such as geographical proximity and functional similarity between the locations. In this paper, we propose a novel tensor Dirichlet Process Multinomial Mixture model with graphs, which can preserve the hierarchical structure of the multi-dimensional trip information and cluster them in a unified one-step manner with the ability to determine the number of clusters automatically. The spatial graphs are utilized in community detection to link the semantic neighbors. We further propose a tensor version of Coll
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#26680;&#30340;&#26657;&#20934;&#24230;&#37327;&#26041;&#27861;&#65292;&#32479;&#19968;&#21644;&#25512;&#24191;&#20102;&#20998;&#31867;&#21644;&#22238;&#24402;&#20013;&#24120;&#35265;&#30340;&#26657;&#20934;&#24418;&#24335;&#12290;&#36825;&#20123;&#24230;&#37327;&#21487;&#20197;&#20135;&#29983;&#21487;&#24494;&#30340;&#26679;&#26412;&#20272;&#35745;&#65292;&#26131;&#20110;&#32435;&#20837;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65292;&#24182;&#36890;&#36807;&#23450;&#21046;&#26657;&#20934;&#24230;&#37327;&#26469;&#20248;&#21270;&#20915;&#31574;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2310.20211</link><description>&lt;p&gt;
&#20998;&#24067;&#21305;&#37197;&#26657;&#20934;&#65306;&#21487;&#35757;&#32451;&#30340;&#26680;&#26657;&#20934;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
Calibration by Distribution Matching: Trainable Kernel Calibration Metrics. (arXiv:2310.20211v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20211
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#26680;&#30340;&#26657;&#20934;&#24230;&#37327;&#26041;&#27861;&#65292;&#32479;&#19968;&#21644;&#25512;&#24191;&#20102;&#20998;&#31867;&#21644;&#22238;&#24402;&#20013;&#24120;&#35265;&#30340;&#26657;&#20934;&#24418;&#24335;&#12290;&#36825;&#20123;&#24230;&#37327;&#21487;&#20197;&#20135;&#29983;&#21487;&#24494;&#30340;&#26679;&#26412;&#20272;&#35745;&#65292;&#26131;&#20110;&#32435;&#20837;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65292;&#24182;&#36890;&#36807;&#23450;&#21046;&#26657;&#20934;&#24230;&#37327;&#26469;&#20248;&#21270;&#20915;&#31574;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26657;&#20934;&#30830;&#20445;&#27010;&#29575;&#39044;&#27979;&#33021;&#22815;&#26377;&#25928;&#22320;&#25429;&#25417;&#19981;&#30830;&#23450;&#24615;&#65292;&#35201;&#27714;&#39044;&#27979;&#27010;&#29575;&#19982;&#32463;&#39564;&#39057;&#29575;&#30456;&#21563;&#21512;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#29616;&#26377;&#30340;&#26657;&#20934;&#26041;&#27861;&#19987;&#38376;&#29992;&#20110;&#20107;&#21518;&#20877;&#26657;&#20934;&#65292;&#21487;&#33021;&#20250;&#24694;&#21270;&#39044;&#27979;&#30340;&#23574;&#38160;&#24615;&#12290;&#22522;&#20110;&#23558;&#26657;&#20934;&#35270;&#20026;&#20998;&#24067;&#21305;&#37197;&#20219;&#21153;&#30340;&#27934;&#23519;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#26680;&#30340;&#26657;&#20934;&#24230;&#37327;&#65292;&#32479;&#19968;&#21644;&#25512;&#24191;&#20102;&#20998;&#31867;&#21644;&#22238;&#24402;&#20013;&#24120;&#35265;&#30340;&#26657;&#20934;&#24418;&#24335;&#12290;&#36825;&#20123;&#24230;&#37327;&#21487;&#20197;&#20135;&#29983;&#21487;&#24494;&#30340;&#26679;&#26412;&#20272;&#35745;&#65292;&#21487;&#20197;&#24456;&#23481;&#26131;&#22320;&#23558;&#26657;&#20934;&#30446;&#26631;&#32435;&#20837;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#20013;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#30452;&#35266;&#30340;&#26426;&#21046;&#26469;&#23450;&#21046;&#20915;&#31574;&#20219;&#21153;&#30340;&#26657;&#20934;&#24230;&#37327;&#65292;&#24182;&#24378;&#21046;&#20934;&#30830;&#30340;&#25439;&#22833;&#20272;&#35745;&#21644;&#26080;&#36951;&#25022;&#20915;&#31574;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;&#20351;&#29992;&#36825;&#20123;&#24230;&#37327;&#20316;&#20026;&#27491;&#21017;&#21270;&#39033;&#21487;&#20197;&#25552;&#39640;&#22312;&#19968;&#31995;&#21015;&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#26657;&#20934;&#24615;&#12289;&#23574;&#38160;&#24615;&#21644;&#20915;&#31574;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Calibration ensures that probabilistic forecasts meaningfully capture uncertainty by requiring that predicted probabilities align with empirical frequencies. However, many existing calibration methods are specialized for post-hoc recalibration, which can worsen the sharpness of forecasts. Drawing on the insight that calibration can be viewed as a distribution matching task, we introduce kernel-based calibration metrics that unify and generalize popular forms of calibration for both classification and regression. These metrics admit differentiable sample estimates, making it easy to incorporate a calibration objective into empirical risk minimization. Furthermore, we provide intuitive mechanisms to tailor calibration metrics to a decision task, and enforce accurate loss estimation and no regret decisions. Our empirical evaluation demonstrates that employing these metrics as regularizers enhances calibration, sharpness, and decision-making across a range of regression and classification 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;robust Bayesian Optimization&#31639;&#27861;&#65292;AIRBO&#65292;&#23427;&#33021;&#22815;&#22312;&#20219;&#24847;&#36755;&#20837;&#19981;&#30830;&#23450;&#24615;&#19979;&#26377;&#25928;&#35782;&#21035;&#20986;&#34920;&#29616;&#19968;&#33268;&#33391;&#22909;&#30340;&#40065;&#26834;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2310.20145</link><description>&lt;p&gt;
&#39640;&#25928;robust Bayesian Optimization&#23545;&#20110;&#20219;&#24847;&#19981;&#30830;&#23450;&#36755;&#20837;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Efficient Robust Bayesian Optimization for Arbitrary Uncertain inputs. (arXiv:2310.20145v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20145
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;robust Bayesian Optimization&#31639;&#27861;&#65292;AIRBO&#65292;&#23427;&#33021;&#22815;&#22312;&#20219;&#24847;&#36755;&#20837;&#19981;&#30830;&#23450;&#24615;&#19979;&#26377;&#25928;&#35782;&#21035;&#20986;&#34920;&#29616;&#19968;&#33268;&#33391;&#22909;&#30340;&#40065;&#26834;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Bayesian Optimization (BO) &#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#20110;&#21508;&#31181;&#24212;&#29992;&#20013;&#30340;&#39640;&#25928;&#20248;&#21270;&#31639;&#27861;&#12290;&#22312;&#19968;&#20123;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;BO&#20219;&#21153;&#20013;&#65292;&#30001;&#20110;&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#19981;&#21487;&#36991;&#20813;&#30340;&#38543;&#26426;&#24615;&#65292;&#22914;&#21152;&#24037;&#35823;&#24046;&#12289;&#25191;&#34892;&#22122;&#22768;&#25110;&#19978;&#19979;&#25991;&#21464;&#24322;&#65292;&#36755;&#20837;&#19981;&#30830;&#23450;&#24615;&#20250;&#20986;&#29616;&#12290;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#20250;&#20351;&#36755;&#20837;&#22312;&#35780;&#20272;&#20043;&#21069;&#20559;&#31163;&#39044;&#26399;&#20540;&#65292;&#23548;&#33268;&#26368;&#32456;&#32467;&#26524;&#30340;&#24615;&#33021;&#27874;&#21160;&#36739;&#22823;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;robust Bayesian Optimization&#31639;&#27861;&#65292;AIRBO&#65292;&#23427;&#33021;&#26377;&#25928;&#22320;&#35782;&#21035;&#22312;&#20219;&#24847;&#36755;&#20837;&#19981;&#30830;&#23450;&#24615;&#19979;&#34920;&#29616;&#19968;&#33268;&#33391;&#22909;&#30340;&#40065;&#26834;&#26368;&#20248;&#35299;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#26368;&#22823;&#22343;&#20540;&#24046;(MMD)&#36171;&#33021;&#39640;&#26031;&#36807;&#31243;&#65292;&#30452;&#25509;&#24314;&#27169;&#20219;&#24847;&#20998;&#24067;&#30340;&#19981;&#30830;&#23450;&#36755;&#20837;&#65292;&#24182;&#36890;&#36807;Nystrom&#36924;&#36817;&#21152;&#36895;&#21518;&#39564;&#25512;&#26029;&#12290;&#25105;&#20204;&#22312;MMD&#20272;&#35745;&#35823;&#24046;&#19979;&#24314;&#31435;&#20102;&#20005;&#26684;&#30340;&#29702;&#35770;&#36951;&#25022;&#30028;&#65292;&#24182;&#22312;&#21512;&#25104;&#20989;&#25968;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian Optimization (BO) is a sample-efficient optimization algorithm widely employed across various applications. In some challenging BO tasks, input uncertainty arises due to the inevitable randomness in the optimization process, such as machining errors, execution noise, or contextual variability. This uncertainty deviates the input from the intended value before evaluation, resulting in significant performance fluctuations in the final result. In this paper, we introduce a novel robust Bayesian Optimization algorithm, AIRBO, which can effectively identify a robust optimum that performs consistently well under arbitrary input uncertainty. Our method directly models the uncertain inputs of arbitrary distributions by empowering the Gaussian Process with the Maximum Mean Discrepancy (MMD) and further accelerates the posterior inference via Nystrom approximation. Rigorous theoretical regret bound is established under MMD estimation error and extensive experiments on synthetic function
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26500;&#24314;"&#30456;&#37051;&#20551;&#35774;"&#30697;&#38453;&#21644;&#24341;&#20837;&#26679;&#26412;&#26465;&#20214;&#30340;&#20551;&#35774;&#31283;&#23450;&#24615;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#26032;&#30340;&#20449;&#24687;&#35770;&#27867;&#21270;&#20445;&#35777;&#65292;&#25913;&#36827;&#20102;&#20808;&#21069;&#20449;&#24687;&#35770;&#30028;&#38480;&#65292;&#24182;&#35299;&#20915;&#20102;&#38543;&#26426;&#20984;&#20248;&#21270;&#38382;&#39064;&#20013;&#20449;&#24687;&#35770;&#30028;&#38480;&#30340;&#23616;&#38480;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.20102</link><description>&lt;p&gt;
&#26679;&#26412;&#26465;&#20214;&#30340;&#20551;&#35774;&#31283;&#23450;&#24615;&#25552;&#21319;&#20102;&#20449;&#24687;&#35770;&#30340;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Sample-Conditioned Hypothesis Stability Sharpens Information-Theoretic Generalization Bounds. (arXiv:2310.20102v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20102
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26500;&#24314;"&#30456;&#37051;&#20551;&#35774;"&#30697;&#38453;&#21644;&#24341;&#20837;&#26679;&#26412;&#26465;&#20214;&#30340;&#20551;&#35774;&#31283;&#23450;&#24615;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#26032;&#30340;&#20449;&#24687;&#35770;&#27867;&#21270;&#20445;&#35777;&#65292;&#25913;&#36827;&#20102;&#20808;&#21069;&#20449;&#24687;&#35770;&#30028;&#38480;&#65292;&#24182;&#35299;&#20915;&#20102;&#38543;&#26426;&#20984;&#20248;&#21270;&#38382;&#39064;&#20013;&#20449;&#24687;&#35770;&#30028;&#38480;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#19968;&#31181;&#26032;&#30340;"&#30456;&#37051;&#20551;&#35774;"&#30697;&#38453;&#30340;&#26500;&#36896;&#21644;&#19968;&#31181;&#26032;&#30340;&#31283;&#23450;&#24615;&#27010;&#24565;&#8212;&#8212;&#26679;&#26412;&#26465;&#20214;&#30340;&#20551;&#35774;&#31283;&#23450;&#24615;&#65288;SCH&#31283;&#23450;&#24615;&#65289;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#20449;&#24687;&#35770;&#27867;&#21270;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#27604;&#20808;&#21069;&#20449;&#24687;&#35770;&#30028;&#38480;&#26356;&#20934;&#30830;&#30340;&#30028;&#38480;&#65292;&#22312;&#21508;&#31181;&#23398;&#20064;&#22330;&#26223;&#20013;&#26377;&#25152;&#25913;&#21892;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20123;&#30028;&#38480;&#35299;&#20915;&#20102;&#26368;&#36817;Haghifam&#31561;&#20154;&#22312;&#38543;&#26426;&#20984;&#20248;&#21270;&#65288;SCO&#65289;&#38382;&#39064;&#19978;&#30340;&#30740;&#31350;&#20013;&#23384;&#22312;&#30340;&#20449;&#24687;&#35770;&#30028;&#38480;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present new information-theoretic generalization guarantees through the a novel construction of the "neighboring-hypothesis" matrix and a new family of stability notions termed sample-conditioned hypothesis (SCH) stability. Our approach yields sharper bounds that improve upon previous information-theoretic bounds in various learning scenarios. Notably, these bounds address the limitations of existing information-theoretic bounds in the context of stochastic convex optimization (SCO) problems, as explored in the recent work by Haghifam et al. (2023).
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28040;&#38500;&#21464;&#20998;&#25512;&#26029;&#19982;Wasserstein&#26799;&#24230;&#27969;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#35777;&#26126;&#20102;&#24067;&#38647;&#26031;-&#29926;&#29791;&#26031;&#22374;&#26799;&#24230;&#27969;&#21487;&#20197;&#37325;&#26032;&#34920;&#31034;&#20026;&#27431;&#27663;&#26799;&#24230;&#27969;&#65292;&#25552;&#20986;&#20102;&#36335;&#24452;&#23548;&#25968;&#26799;&#24230;&#20272;&#35745;&#22120;&#21644;&#33976;&#39311;&#36807;&#31243;&#26469;&#25299;&#23637;&#35813;&#26041;&#27861;&#65292;&#21516;&#26102;&#21487;&#20197;&#36866;&#29992;&#20110;f-&#25955;&#24230;&#21644;&#38750;&#39640;&#26031;&#21464;&#20998;&#26063;&#12290;</title><link>http://arxiv.org/abs/2310.20090</link><description>&lt;p&gt;
&#28040;&#38500;&#21464;&#20998;&#25512;&#26029;&#19982;Wasserstein&#26799;&#24230;&#27969;&#20043;&#38388;&#30340;&#40511;&#27807;
&lt;/p&gt;
&lt;p&gt;
Bridging the Gap Between Variational Inference and Wasserstein Gradient Flows. (arXiv:2310.20090v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20090
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28040;&#38500;&#21464;&#20998;&#25512;&#26029;&#19982;Wasserstein&#26799;&#24230;&#27969;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#35777;&#26126;&#20102;&#24067;&#38647;&#26031;-&#29926;&#29791;&#26031;&#22374;&#26799;&#24230;&#27969;&#21487;&#20197;&#37325;&#26032;&#34920;&#31034;&#20026;&#27431;&#27663;&#26799;&#24230;&#27969;&#65292;&#25552;&#20986;&#20102;&#36335;&#24452;&#23548;&#25968;&#26799;&#24230;&#20272;&#35745;&#22120;&#21644;&#33976;&#39311;&#36807;&#31243;&#26469;&#25299;&#23637;&#35813;&#26041;&#27861;&#65292;&#21516;&#26102;&#21487;&#20197;&#36866;&#29992;&#20110;f-&#25955;&#24230;&#21644;&#38750;&#39640;&#26031;&#21464;&#20998;&#26063;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#25512;&#26029;&#26159;&#19968;&#31181;&#36890;&#36807;&#22312;&#21464;&#20998;&#26063;&#21442;&#25968;&#31354;&#38388;&#20869;&#36827;&#34892;&#20248;&#21270;&#26469;&#36817;&#20284;&#30446;&#26631;&#20998;&#24067;&#30340;&#25216;&#26415;&#12290;&#32780;Wasserstein&#26799;&#24230;&#27969;&#25551;&#36848;&#20102;&#22312;&#27010;&#29575;&#27979;&#24230;&#30340;&#31354;&#38388;&#20869;&#36827;&#34892;&#20248;&#21270;&#65292;&#20854;&#20013;&#19981;&#19968;&#23450;&#23384;&#22312;&#21442;&#25968;&#23494;&#24230;&#20989;&#25968;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#28040;&#38500;&#20102;&#36825;&#20004;&#31181;&#26041;&#27861;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#65292;&#24067;&#38647;&#26031;-&#29926;&#29791;&#26031;&#22374;&#26799;&#24230;&#27969;&#21487;&#20197;&#37325;&#26032;&#34920;&#31034;&#20026;&#27431;&#27663;&#26799;&#24230;&#27969;&#65292;&#20854;&#21069;&#21521;&#27431;&#25289;&#26041;&#26696;&#26159;&#26631;&#20934;&#30340;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#26799;&#24230;&#27969;&#30340;&#21521;&#37327;&#22330;&#36890;&#36807;&#36335;&#24452;&#23548;&#25968;&#26799;&#24230;&#20272;&#35745;&#22120;&#29983;&#25104;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#20851;&#20110;&#36335;&#24452;&#23548;&#25968;&#26799;&#24230;&#30340;&#26367;&#20195;&#35270;&#35282;&#65292;&#23558;&#20854;&#26694;&#26550;&#21270;&#20026;&#23545;Wasserstein&#26799;&#24230;&#27969;&#30340;&#33976;&#39311;&#36807;&#31243;&#12290;&#33976;&#39311;&#21487;&#20197;&#25193;&#23637;&#21040;&#21253;&#21547;f-&#25955;&#24230;&#21644;&#38750;&#39640;&#26031;&#21464;&#20998;&#26063;&#12290;&#36825;&#31181;&#25193;&#23637;&#20135;&#29983;&#20102;&#19968;&#20010;&#26032;&#30340;&#26799;&#24230;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
Variational inference is a technique that approximates a target distribution by optimizing within the parameter space of variational families. On the other hand, Wasserstein gradient flows describe optimization within the space of probability measures where they do not necessarily admit a parametric density function. In this paper, we bridge the gap between these two methods. We demonstrate that, under certain conditions, the Bures-Wasserstein gradient flow can be recast as the Euclidean gradient flow where its forward Euler scheme is the standard black-box variational inference algorithm. Specifically, the vector field of the gradient flow is generated via the path-derivative gradient estimator. We also offer an alternative perspective on the path-derivative gradient, framing it as a distillation procedure to the Wasserstein gradient flow. Distillations can be extended to encompass $f$-divergences and non-Gaussian variational families. This extension yields a new gradient estimator fo
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;Meek&#20998;&#31163;&#22120;&#21450;&#20854;&#22312;&#30446;&#26631;&#22240;&#26524;&#21457;&#29616;&#20013;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#24341;&#20837;Meek&#20998;&#31163;&#22120;&#65292;&#25105;&#20204;&#21487;&#20197;&#35774;&#35745;&#20986;&#39640;&#25928;&#30340;&#31639;&#27861;&#26469;&#23547;&#25214;&#23567;&#35268;&#27169;&#30340;&#20998;&#31163;&#22120;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545;&#30446;&#26631;&#22240;&#26524;&#21457;&#29616;&#38382;&#39064;&#30340;&#20248;&#21270;&#12290;</title><link>http://arxiv.org/abs/2310.20075</link><description>&lt;p&gt;
Meek&#20998;&#31163;&#22120;&#21450;&#20854;&#22312;&#30446;&#26631;&#22240;&#26524;&#21457;&#29616;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Meek Separators and Their Applications in Targeted Causal Discovery. (arXiv:2310.20075v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20075
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;Meek&#20998;&#31163;&#22120;&#21450;&#20854;&#22312;&#30446;&#26631;&#22240;&#26524;&#21457;&#29616;&#20013;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#24341;&#20837;Meek&#20998;&#31163;&#22120;&#65292;&#25105;&#20204;&#21487;&#20197;&#35774;&#35745;&#20986;&#39640;&#25928;&#30340;&#31639;&#27861;&#26469;&#23547;&#25214;&#23567;&#35268;&#27169;&#30340;&#20998;&#31163;&#22120;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545;&#30446;&#26631;&#22240;&#26524;&#21457;&#29616;&#38382;&#39064;&#30340;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#24178;&#39044;&#25968;&#25454;&#20013;&#23398;&#20064;&#22240;&#26524;&#32467;&#26500;&#26159;&#19968;&#20010;&#20855;&#26377;&#24191;&#27867;&#24212;&#29992;&#30340;&#22522;&#26412;&#38382;&#39064;&#12290;&#23613;&#31649;&#35768;&#22810;&#20043;&#21069;&#30340;&#24037;&#20316;&#37117;&#38598;&#20013;&#20110;&#24674;&#22797;&#25972;&#20010;&#22240;&#26524;&#22270;&#65292;&#20294;&#23454;&#38469;&#19978;&#23384;&#22312;&#19968;&#20123;&#22330;&#26223;&#65292;&#20165;&#23398;&#20064;&#22240;&#26524;&#22270;&#30340;&#37096;&#20998;&#21363;&#21487;&#28385;&#36275;&#38656;&#27714;&#12290;&#36825;&#34987;&#31216;&#20026;&#8220;&#30446;&#26631;&#22240;&#26524;&#21457;&#29616;&#8221;&#12290;&#22312;&#25105;&#20204;&#30340;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20851;&#27880;&#20004;&#20010;&#36825;&#26679;&#30340;&#38382;&#39064;&#65306;&#23376;&#38598;&#25628;&#32034;&#21644;&#22240;&#26524;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#22312;&#36825;&#20004;&#31181;&#24773;&#20917;&#19979;&#23613;&#37327;&#20943;&#23569;&#24178;&#39044;&#30340;&#27425;&#25968;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;Meek&#20998;&#31163;&#22120;&#65292;&#23427;&#26159;&#19968;&#20010;&#23376;&#38598;&#65292;&#22312;&#24178;&#39044;&#26102;&#23558;&#21097;&#20313;&#30340;&#26410;&#23450;&#21521;&#36793;&#20998;&#35299;&#20026;&#36739;&#23567;&#30340;&#36830;&#36890;&#20998;&#37327;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#31639;&#27861;&#26469;&#23547;&#25214;&#23567;&#35268;&#27169;&#30340;Meek&#20998;&#31163;&#22120;&#12290;&#36825;&#26679;&#30340;&#36807;&#31243;&#26377;&#21161;&#20110;&#35774;&#35745;&#21508;&#31181;&#22522;&#20110;&#20998;&#32780;&#27835;&#20043;&#30340;&#26041;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#38543;&#26426;&#31639;&#27861;&#65292;&#20998;&#21035;&#23545;&#23376;&#38598;&#25628;&#32034;&#21644;&#22240;&#26524;&#21305;&#37197;&#23454;&#29616;&#23545;&#25968;&#36817;&#20284;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;
&lt;/p&gt;
&lt;p&gt;
Learning causal structures from interventional data is a fundamental problem with broad applications across various fields. While many previous works have focused on recovering the entire causal graph, in practice, there are scenarios where learning only part of the causal graph suffices. This is called $targeted$ causal discovery. In our work, we focus on two such well-motivated problems: subset search and causal matching. We aim to minimize the number of interventions in both cases.  Towards this, we introduce the $Meek~separator$, which is a subset of vertices that, when intervened, decomposes the remaining unoriented edges into smaller connected components. We then present an efficient algorithm to find Meek separators that are of small sizes. Such a procedure is helpful in designing various divide-and-conquer-based approaches. In particular, we propose two randomized algorithms that achieve logarithmic approximation for subset search and causal matching, respectively. Our results 
&lt;/p&gt;</description></item><item><title>AdaSub&#26159;&#19968;&#31181;&#20351;&#29992;&#20302;&#32500;&#23376;&#31354;&#38388;&#20013;&#30340;&#20108;&#38454;&#20449;&#24687;&#36827;&#34892;&#38543;&#26426;&#20248;&#21270;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#25628;&#32034;&#30340;&#23376;&#31354;&#38388;&#32500;&#24230;&#26469;&#31649;&#29702;&#35745;&#31639;&#24320;&#38144;&#21644;&#31639;&#27861;&#25928;&#29575;&#12290;&#21021;&#27493;&#25968;&#20540;&#32467;&#26524;&#26174;&#31034;&#65292;AdaSub&#22312;&#26102;&#38388;&#21644;&#36845;&#20195;&#27425;&#25968;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#38543;&#26426;&#20248;&#21270;&#22120;&#12290;</title><link>http://arxiv.org/abs/2310.20060</link><description>&lt;p&gt;
AdaSub&#65306;&#20351;&#29992;&#20302;&#32500;&#23376;&#31354;&#38388;&#20013;&#30340;&#20108;&#38454;&#20449;&#24687;&#36827;&#34892;&#38543;&#26426;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
AdaSub: Stochastic Optimization Using Second-Order Information in Low-Dimensional Subspaces. (arXiv:2310.20060v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20060
&lt;/p&gt;
&lt;p&gt;
AdaSub&#26159;&#19968;&#31181;&#20351;&#29992;&#20302;&#32500;&#23376;&#31354;&#38388;&#20013;&#30340;&#20108;&#38454;&#20449;&#24687;&#36827;&#34892;&#38543;&#26426;&#20248;&#21270;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#25628;&#32034;&#30340;&#23376;&#31354;&#38388;&#32500;&#24230;&#26469;&#31649;&#29702;&#35745;&#31639;&#24320;&#38144;&#21644;&#31639;&#27861;&#25928;&#29575;&#12290;&#21021;&#27493;&#25968;&#20540;&#32467;&#26524;&#26174;&#31034;&#65292;AdaSub&#22312;&#26102;&#38388;&#21644;&#36845;&#20195;&#27425;&#25968;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#38543;&#26426;&#20248;&#21270;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;AdaSub&#65292;&#19968;&#31181;&#22522;&#20110;&#20302;&#32500;&#33258;&#36866;&#24212;&#23450;&#20041;&#30340;&#20108;&#38454;&#20449;&#24687;&#30340;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#12290;&#19982;&#19968;&#38454;&#26041;&#27861;&#30456;&#27604;&#65292;&#20108;&#38454;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#25910;&#25947;&#29305;&#24615;&#65292;&#20294;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#35745;&#31639;Hessian&#30697;&#38453;&#20250;&#23548;&#33268;&#36807;&#39640;&#30340;&#35745;&#31639;&#24320;&#38144;&#65292;&#20351;&#20854;&#19981;&#23454;&#29992;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#36873;&#25321;&#25628;&#32034;&#30340;&#23376;&#31354;&#38388;&#32500;&#24230;&#26469;&#31649;&#29702;&#35745;&#31639;&#24320;&#38144;&#21644;&#31639;&#27861;&#25928;&#29575;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#22312;GitHub&#19978;&#20813;&#36153;&#25552;&#20379;&#65292;&#25105;&#20204;&#30340;&#21021;&#27493;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;AdaSub&#22312;&#36798;&#21040;&#32473;&#23450;&#31934;&#24230;&#25152;&#38656;&#30340;&#26102;&#38388;&#21644;&#36845;&#20195;&#27425;&#25968;&#26041;&#38754;&#36229;&#36807;&#20102;&#27969;&#34892;&#30340;&#38543;&#26426;&#20248;&#21270;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce AdaSub, a stochastic optimization algorithm that computes a search direction based on second-order information in a low-dimensional subspace that is defined adaptively based on available current and past information. Compared to first-order methods, second-order methods exhibit better convergence characteristics, but the need to compute the Hessian matrix at each iteration results in excessive computational expenses, making them impractical. To address this issue, our approach enables the management of computational expenses and algorithm efficiency by enabling the selection of the subspace dimension for the search. Our code is freely available on GitHub, and our preliminary numerical results demonstrate that AdaSub surpasses popular stochastic optimizers in terms of time and number of iterations required to reach a given accuracy.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;Hamiltonian Monte Carlo&#26041;&#27861;&#20272;&#35745;&#26368;&#20248;PAC-Bayes&#30028;&#38480;&#65292;&#30740;&#31350;&#20102;&#36890;&#36807;&#38480;&#21046;&#21518;&#39564;&#20998;&#24067;&#20026;&#22240;&#23376;&#21270;&#39640;&#26031;&#20998;&#24067;&#22312;&#20248;&#21270;PAC-Bayes&#30028;&#38480;&#26041;&#38754;&#25152;&#22833;&#21435;&#30340;&#32039;&#33268;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;&#19977;&#31181;&#26041;&#27861;&#26469;&#33719;&#24471;&#39640;&#27010;&#29575;&#30028;&#38480;&#12290;&#23454;&#39564;&#35777;&#26126;&#22312;MNIST&#25968;&#25454;&#38598;&#19978;&#23384;&#22312;&#26174;&#33879;&#30340;&#32039;&#33268;&#24230;&#24046;&#36317;&#65292;&#39640;&#36798;5-6&#65285;&#12290;</title><link>http://arxiv.org/abs/2310.20053</link><description>&lt;p&gt;
&#20351;&#29992;Hamiltonian Monte Carlo&#26041;&#27861;&#20272;&#35745;&#26368;&#20248;PAC-Bayes&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Estimating optimal PAC-Bayes bounds with Hamiltonian Monte Carlo. (arXiv:2310.20053v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20053
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;Hamiltonian Monte Carlo&#26041;&#27861;&#20272;&#35745;&#26368;&#20248;PAC-Bayes&#30028;&#38480;&#65292;&#30740;&#31350;&#20102;&#36890;&#36807;&#38480;&#21046;&#21518;&#39564;&#20998;&#24067;&#20026;&#22240;&#23376;&#21270;&#39640;&#26031;&#20998;&#24067;&#22312;&#20248;&#21270;PAC-Bayes&#30028;&#38480;&#26041;&#38754;&#25152;&#22833;&#21435;&#30340;&#32039;&#33268;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;&#19977;&#31181;&#26041;&#27861;&#26469;&#33719;&#24471;&#39640;&#27010;&#29575;&#30028;&#38480;&#12290;&#23454;&#39564;&#35777;&#26126;&#22312;MNIST&#25968;&#25454;&#38598;&#19978;&#23384;&#22312;&#26174;&#33879;&#30340;&#32039;&#33268;&#24230;&#24046;&#36317;&#65292;&#39640;&#36798;5-6&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
PAC-Bayes&#25991;&#29486;&#20013;&#19968;&#20010;&#37325;&#35201;&#20294;&#26410;&#34987;&#20805;&#20998;&#30740;&#31350;&#30340;&#38382;&#39064;&#26159;&#22312;&#20248;&#21270;PAC-Bayes&#30028;&#38480;&#26102;&#65292;&#36890;&#36807;&#38480;&#21046;&#21518;&#39564;&#20998;&#24067;&#20026;&#22240;&#23376;&#21270;&#39640;&#26031;&#20998;&#24067;&#65292;&#25105;&#20204;&#22833;&#21435;&#20102;&#22810;&#23569;&#32039;&#33268;&#24230;&#12290;&#25105;&#20204;&#36890;&#36807;&#20272;&#35745;&#29420;&#31435;&#20110;&#25968;&#25454;&#30340;PAC-Bayes&#30028;&#38480;&#26469;&#35843;&#26597;&#27492;&#38382;&#39064;&#65292;&#20351;&#29992;&#26368;&#20248;&#30340;&#21518;&#39564;&#19982;&#20351;&#29992;MFVI&#24471;&#21040;&#30340;&#30028;&#38480;&#36827;&#34892;&#27604;&#36739;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#37319;&#29992;Hamiltonian Monte Carlo&#20174;&#26368;&#20248;&#30340;Gibbs&#21518;&#39564;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#29992;&#28909;&#21147;&#23398;&#31215;&#20998;&#20272;&#35745;&#20854;&#19982;&#20808;&#39564;&#30340;KL&#25955;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;&#19977;&#31181;&#22312;&#19981;&#21516;&#20551;&#35774;&#19979;&#33719;&#24471;&#39640;&#27010;&#29575;&#30028;&#38480;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;MNIST&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#25581;&#31034;&#20102;&#26174;&#33879;&#30340;&#32039;&#33268;&#24230;&#24046;&#36317;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#21487;&#36798;5-6&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;
An important yet underexplored question in the PAC-Bayes literature is how much tightness we lose by restricting the posterior family to factorized Gaussian distributions when optimizing a PAC-Bayes bound. We investigate this issue by estimating data-independent PAC-Bayes bounds using the optimal posteriors, comparing them to bounds obtained using MFVI. Concretely, we (1) sample from the optimal Gibbs posterior using Hamiltonian Monte Carlo, (2) estimate its KL divergence from the prior with thermodynamic integration, and (3) propose three methods to obtain high-probability bounds under different assumptions. Our experiments on the MNIST dataset reveal significant tightness gaps, as much as 5-6\% in some cases.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#40654;&#26364;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#37325;&#26032;&#23457;&#35270;&#36817;&#20284;&#26041;&#27861;&#21644;&#21033;&#29992;&#23545;&#31216;&#31354;&#38388;&#30340;&#24615;&#36136;&#65292;&#23454;&#29616;&#20102;&#39640;&#31934;&#24230;&#35745;&#31639;&#21644;&#22312;&#39640;&#32500;&#20219;&#21153;&#19978;&#30340;&#25193;&#23637;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.20030</link><description>&lt;p&gt;
&#32553;&#25918;&#40654;&#26364;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Scaling Riemannian Diffusion Models. (arXiv:2310.20030v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20030
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#40654;&#26364;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#37325;&#26032;&#23457;&#35270;&#36817;&#20284;&#26041;&#27861;&#21644;&#21033;&#29992;&#23545;&#31216;&#31354;&#38388;&#30340;&#24615;&#36136;&#65292;&#23454;&#29616;&#20102;&#39640;&#31934;&#24230;&#35745;&#31639;&#21644;&#22312;&#39640;&#32500;&#20219;&#21153;&#19978;&#30340;&#25193;&#23637;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#40654;&#26364;&#25193;&#25955;&#27169;&#22411;&#20174;&#26631;&#20934;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#25193;&#25955;&#27169;&#22411;&#20013;&#27762;&#21462;&#28789;&#24863;&#65292;&#23398;&#20064;&#22312;&#19968;&#33324;&#27969;&#24418;&#19978;&#30340;&#20998;&#24067;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#39069;&#22806;&#30340;&#20960;&#20309;&#22797;&#26434;&#24615;&#20351;&#24471;&#25193;&#25955;&#36807;&#28193;&#39033;&#26080;&#27861;&#29992;&#38381;&#24335;&#34920;&#36798;&#24335;&#34920;&#31034;&#65292;&#22240;&#27492;&#20808;&#21069;&#30340;&#26041;&#27861;&#21482;&#33021;&#20351;&#29992;&#31895;&#30053;&#30340;&#36817;&#20284;&#26041;&#27861;&#26469;&#38477;&#20302;&#24615;&#33021;&#24182;&#38459;&#27490;&#22312;&#39640;&#32500;&#24230;&#19979;&#30340;&#24212;&#29992;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#36825;&#20123;&#36817;&#20284;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20960;&#20010;&#23454;&#29992;&#30340;&#25913;&#36827;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#35266;&#23519;&#26159;&#65292;&#22823;&#22810;&#25968;&#30456;&#20851;&#27969;&#24418;&#26159;&#23545;&#31216;&#31354;&#38388;&#65292;&#36825;&#20123;&#23545;&#31216;&#31354;&#38388;&#22312;&#35745;&#31639;&#19978;&#26356;&#23481;&#26131;&#22788;&#29702;&#12290;&#36890;&#36807;&#21033;&#29992;&#21644;&#32452;&#21512;&#21508;&#31181;&#26041;&#27861;&#65292;&#25105;&#20204;&#21487;&#20197;&#24555;&#36895;&#35745;&#31639;&#30456;&#20851;&#30340;&#37327;&#21040;&#39640;&#31934;&#24230;&#12290;&#22312;&#20302;&#32500;&#25968;&#25454;&#38598;&#19978;&#65292;&#25105;&#20204;&#30340;&#26657;&#27491;&#20135;&#29983;&#20102;&#26126;&#26174;&#30340;&#25913;&#36827;&#65292;&#20351;&#25193;&#25955;&#33021;&#22815;&#19982;&#20854;&#20182;&#26041;&#27861;&#31454;&#20105;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;&#38750;&#24179;&#20961;&#27969;&#24418;&#19978;&#25193;&#23637;&#21040;&#39640;&#32500;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
Riemannian diffusion models draw inspiration from standard Euclidean space diffusion models to learn distributions on general manifolds. Unfortunately, the additional geometric complexity renders the diffusion transition term inexpressible in closed form, so prior methods resort to imprecise approximations of the score matching training objective that degrade performance and preclude applications in high dimensions. In this work, we reexamine these approximations and propose several practical improvements. Our key observation is that most relevant manifolds are symmetric spaces, which are much more amenable to computation. By leveraging and combining various ans\"{a}tze, we can quickly compute relevant quantities to high precision. On low dimensional datasets, our correction produces a noticeable improvement, allowing diffusion to compete with other methods. Additionally, we show that our method enables us to scale to high dimensional tasks on nontrivial manifolds. In particular, we mo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#22810;&#31181;&#24773;&#22659;&#19979;&#35777;&#26126;&#20102;&#27748;&#26222;&#26862;&#37319;&#26679;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#65292;&#24182;&#36890;&#36807;&#23545;&#20449;&#24687;&#27604;&#30340;&#31934;&#30830;&#20998;&#26512;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#26102;&#38388;&#19981;&#22343;&#21248;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#19978;&#30028;&#20272;&#35745;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#25214;&#21040;&#20102;&#21508;&#31181;&#35774;&#32622;&#20013;&#20855;&#20307;&#30340;&#30028;&#38480;&#65292;&#24182;&#35752;&#35770;&#20102;&#36825;&#20123;&#32467;&#26524;&#26159;&#31532;&#19968;&#20010;&#20854;&#31867;&#21035;&#25110;&#25913;&#36827;&#20102;&#26368;&#20808;&#36827;&#26041;&#27861;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2310.20007</link><description>&lt;p&gt;
&#25552;&#21319;&#24378;&#21270;&#23398;&#20064;&#20013;&#27748;&#26222;&#26862;&#37319;&#26679;&#30340;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;
&lt;/p&gt;
&lt;p&gt;
Improved Bayesian Regret Bounds for Thompson Sampling in Reinforcement Learning. (arXiv:2310.20007v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20007
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#22810;&#31181;&#24773;&#22659;&#19979;&#35777;&#26126;&#20102;&#27748;&#26222;&#26862;&#37319;&#26679;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#65292;&#24182;&#36890;&#36807;&#23545;&#20449;&#24687;&#27604;&#30340;&#31934;&#30830;&#20998;&#26512;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#26102;&#38388;&#19981;&#22343;&#21248;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#19978;&#30028;&#20272;&#35745;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#25214;&#21040;&#20102;&#21508;&#31181;&#35774;&#32622;&#20013;&#20855;&#20307;&#30340;&#30028;&#38480;&#65292;&#24182;&#35752;&#35770;&#20102;&#36825;&#20123;&#32467;&#26524;&#26159;&#31532;&#19968;&#20010;&#20854;&#31867;&#21035;&#25110;&#25913;&#36827;&#20102;&#26368;&#20808;&#36827;&#26041;&#27861;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#22312;&#22810;&#31181;&#24773;&#22659;&#19979;&#65292;&#27748;&#26222;&#26862;&#37319;&#26679;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#31532;&#19968;&#20010;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#12290;&#25105;&#20204;&#21033;&#29992;&#31163;&#25955;&#30340;&#20195;&#29702;&#29615;&#22659;&#31616;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#21518;&#39564;&#19968;&#33268;&#24615;&#23545;&#20449;&#24687;&#27604;&#36827;&#34892;&#20102;&#31934;&#30830;&#20998;&#26512;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#20010;&#22522;&#20110;&#26102;&#38388;&#19981;&#22343;&#21248;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#19978;&#30028;&#20272;&#35745;&#20026;$\widetilde{O}(H\sqrt{d_{l_1}T})$&#65292;&#20854;&#20013;$H$&#20026;&#22238;&#21512;&#38271;&#24230;&#65292;$d_{l_1}$&#20026;&#29615;&#22659;&#31354;&#38388;&#30340;Kolmogorov $l_1$&#32500;&#24230;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#22312;&#21508;&#31181;&#35774;&#32622;&#20013;&#25214;&#21040;&#20102;$d_{l_1}$&#30340;&#20855;&#20307;&#30028;&#38480;&#65292;&#27604;&#22914;&#34920;&#26684;&#12289;&#32447;&#24615;&#21644;&#26377;&#38480;&#28151;&#21512;&#65292;&#35752;&#35770;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#26159;&#31532;&#19968;&#20010;&#20854;&#31867;&#21035;&#25110;&#25913;&#36827;&#20102;&#26368;&#20808;&#36827;&#26041;&#27861;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we prove the first Bayesian regret bounds for Thompson Sampling in reinforcement learning in a multitude of settings. We simplify the learning problem using a discrete set of surrogate environments, and present a refined analysis of the information ratio using posterior consistency. This leads to an upper bound of order $\widetilde{O}(H\sqrt{d_{l_1}T})$ in the time inhomogeneous reinforcement learning problem where $H$ is the episode length and $d_{l_1}$ is the Kolmogorov $l_1-$dimension of the space of environments. We then find concrete bounds of $d_{l_1}$ in a variety of settings, such as tabular, linear and finite mixtures, and discuss how how our results are either the first of their kind or improve the state-of-the-art.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#25913;&#36827;Frank-Wolfe&#31639;&#27861;&#26469;&#35757;&#32451;&#24046;&#20998;&#38544;&#31169;&#22238;&#24402;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#31232;&#30095;&#36755;&#20837;&#25968;&#25454;&#19978;&#26377;&#25928;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#31639;&#27861;&#30340;&#35757;&#32451;&#26102;&#38388;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2310.19978</link><description>&lt;p&gt;
&#36890;&#36807;&#26356;&#24555;&#30340;Frank-Wolfe&#36845;&#20195;&#26041;&#27861;&#25552;&#39640;&#24046;&#20998;&#38544;&#31169;LASSO&#27491;&#21017;&#21270;&#36923;&#36753;&#22238;&#24402;&#30340;&#25193;&#23637;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Scaling Up Differentially Private LASSO Regularized Logistic Regression via Faster Frank-Wolfe Iterations. (arXiv:2310.19978v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19978
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#25913;&#36827;Frank-Wolfe&#31639;&#27861;&#26469;&#35757;&#32451;&#24046;&#20998;&#38544;&#31169;&#22238;&#24402;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#31232;&#30095;&#36755;&#20837;&#25968;&#25454;&#19978;&#26377;&#25928;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#31639;&#27861;&#30340;&#35757;&#32451;&#26102;&#38388;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#30446;&#21069;&#27809;&#26377;&#26041;&#27861;&#21487;&#20197;&#22312;&#31232;&#30095;&#36755;&#20837;&#25968;&#25454;&#19978;&#35757;&#32451;&#24046;&#20998;&#38544;&#31169;&#22238;&#24402;&#27169;&#22411;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#23558;$ L_1 $&#24809;&#32602;&#32447;&#24615;&#22238;&#24402;&#30340;Frank-Wolfe&#31639;&#27861;&#36866;&#24212;&#20110;&#31232;&#30095;&#36755;&#20837;&#65292;&#24182;&#26377;&#25928;&#22320;&#21033;&#29992;&#23427;&#20204;&#12290;&#36890;&#36807;&#36825;&#26679;&#20570;&#65292;&#25105;&#20204;&#23558;&#31639;&#27861;&#30340;&#35757;&#32451;&#26102;&#38388;&#20174;$ \mathcal {O}&#65288;TDS + TNS&#65289;$&#20943;&#23569;&#21040;$ \mathcal {O}&#65288;NS + T \sqrt {D} \log {D} + TS ^ 2&#65289;$&#65292;&#20854;&#20013;$ T $&#26159;&#36845;&#20195;&#27425;&#25968;&#65292;&#32780;$ N $&#26159;&#25968;&#25454;&#38598;&#30340;&#34892;&#25968;&#65292;$ D $&#26159;&#29305;&#24449;&#25968;&#65292;$ S $&#26159;&#31232;&#30095;&#29575;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20010;&#36807;&#31243;&#21487;&#20197;&#23558;&#36816;&#34892;&#26102;&#38388;&#32553;&#30701;&#22810;&#36798;$ 2,200 \times $&#65292;&#36825;&#21462;&#20915;&#20110;&#38544;&#31169;&#21442;&#25968;$ \epsilon $&#30340;&#20540;&#21644;&#25968;&#25454;&#38598;&#30340;&#31232;&#30095;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
To the best of our knowledge, there are no methods today for training differentially private regression models on sparse input data. To remedy this, we adapt the Frank-Wolfe algorithm for $L_1$ penalized linear regression to be aware of sparse inputs and to use them effectively. In doing so, we reduce the training time of the algorithm from $\mathcal{O}( T D S + T N S)$ to $\mathcal{O}(N S + T \sqrt{D} \log{D} + T S^2)$, where $T$ is the number of iterations and a sparsity rate $S$ of a dataset with $N$ rows and $D$ features. Our results demonstrate that this procedure can reduce runtime by a factor of up to $2,200\times$, depending on the value of the privacy parameter $\epsilon$ and the sparsity of the dataset.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;$f$-&#24046;&#20998;&#38544;&#31169;&#26041;&#27861;&#25913;&#36827;&#20102;&#27927;&#29260;&#27169;&#22411;&#21644;DP-GD&#20013;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#38544;&#31169;&#36793;&#30028;&#65292;&#25240;&#34935;&#20989;&#25968;&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#20248;&#20110;$(\epsilon,\delta)$-DP&#30340;&#32467;&#26524;&#65292;&#24182;&#19988;&#38543;&#26426;&#21021;&#22987;&#21270;&#21487;&#20197;&#22686;&#24378;DP-GD&#30340;&#38544;&#31169;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.19973</link><description>&lt;p&gt;
&#36890;&#36807;$f$-&#24046;&#20998;&#38544;&#31169;&#32479;&#19968;&#22686;&#24378;&#28151;&#21512;&#26426;&#21046;&#30340;&#38544;&#31169;&#36793;&#30028;
&lt;/p&gt;
&lt;p&gt;
Unified Enhancement of Privacy Bounds for Mixture Mechanisms via $f$-Differential Privacy. (arXiv:2310.19973v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19973
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;$f$-&#24046;&#20998;&#38544;&#31169;&#26041;&#27861;&#25913;&#36827;&#20102;&#27927;&#29260;&#27169;&#22411;&#21644;DP-GD&#20013;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#38544;&#31169;&#36793;&#30028;&#65292;&#25240;&#34935;&#20989;&#25968;&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#20248;&#20110;$(\epsilon,\delta)$-DP&#30340;&#32467;&#26524;&#65292;&#24182;&#19988;&#38543;&#26426;&#21021;&#22987;&#21270;&#21487;&#20197;&#22686;&#24378;DP-GD&#30340;&#38544;&#31169;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#20250;&#20135;&#29983;&#35768;&#22810;&#38543;&#26426;&#24615;&#65292;&#22914;&#38543;&#26426;&#21021;&#22987;&#21270;&#12289;&#38543;&#26426;&#25209;&#27425;&#25277;&#26679;&#21644;&#27927;&#29260;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#36825;&#20123;&#38543;&#26426;&#24615;&#20250;&#23548;&#33268;&#38590;&#20197;&#20998;&#26512;&#30340;&#28151;&#21512;&#20998;&#24067;&#65292;&#25152;&#20197;&#22312;&#35777;&#26126;&#24046;&#20998;&#38544;&#31169;&#36793;&#30028;&#26102;&#24456;&#38590;&#23558;&#20854;&#32435;&#20837;&#32771;&#34385;&#12290;&#26412;&#25991;&#26088;&#22312;&#25913;&#36827;&#27927;&#29260;&#27169;&#22411;&#21644;&#19968;&#27425;&#36845;&#20195;&#30340;&#24046;&#20998;&#38544;&#31169;&#26799;&#24230;&#19979;&#38477;&#65288;DP-GD&#65289;&#20013;&#29992;&#20110;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#38544;&#31169;&#36793;&#30028;&#65292;&#37319;&#29992;$f$-DP&#26041;&#27861;&#12290;&#25105;&#20204;&#23548;&#20986;&#20102;&#27927;&#29260;&#27169;&#22411;&#30340;&#25240;&#34935;&#20989;&#25968;&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#65292;&#20248;&#20110;&#22522;&#20110;$(\epsilon,\delta)$-DP&#30340;&#26368;&#26032;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23545;&#38543;&#26426;&#21021;&#22987;&#21270;&#23545;&#19968;&#27425;&#36845;&#20195;&#30340;DP-GD&#30340;&#38544;&#31169;&#24615;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#25105;&#20204;&#23545;&#25240;&#34935;&#20989;&#25968;&#30340;&#25968;&#20540;&#35745;&#31639;&#34920;&#26126;&#65292;&#38543;&#26426;&#21021;&#22987;&#21270;&#21487;&#20197;&#22686;&#24378;DP-GD&#30340;&#38544;&#31169;&#24615;&#12290;&#25105;&#20204;&#23545;&#36825;&#20123;&#28151;&#21512;&#26426;&#21046;&#30340;$f$-DP&#20445;&#35777;&#30340;&#20998;&#26512;&#20381;&#36182;&#20110;&#19968;&#31181;&#19981;&#31561;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differentially private (DP) machine learning algorithms incur many sources of randomness, such as random initialization, random batch subsampling, and shuffling. However, such randomness is difficult to take into account when proving differential privacy bounds because it induces mixture distributions for the algorithm's output that are difficult to analyze. This paper focuses on improving privacy bounds for shuffling models and one-iteration differentially private gradient descent (DP-GD) with random initializations using $f$-DP. We derive a closed-form expression of the trade-off function for shuffling models that outperforms the most up-to-date results based on $(\epsilon,\delta)$-DP. Moreover, we investigate the effects of random initialization on the privacy of one-iteration DP-GD. Our numerical computations of the trade-off function indicate that random initialization can enhance the privacy of DP-GD. Our analysis of $f$-DP guarantees for these mixture mechanisms relies on an ine
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#21518;&#39564;&#37319;&#26679;&#31639;&#27861;&#22312;&#31454;&#20105;&#24615;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#24341;&#20837;&#33258;&#23545;&#24328;&#21644;&#23545;&#25239;&#24615;&#24191;&#20041;&#33406;&#30053;&#29305;&#31995;&#25968;&#65292;&#25552;&#20986;&#20102;&#29992;&#20110;&#25506;&#32034;-&#21033;&#29992;&#24179;&#34913;&#30340;&#27169;&#22411;&#26041;&#27861;&#65292;&#24182;&#19988;&#25104;&#21151;&#22788;&#29702;&#20102;&#29366;&#24577;&#30340;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#12290;&#21516;&#26102;&#65292;&#25552;&#20986;&#20102;&#23398;&#20064;&#20855;&#26377;&#28508;&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#30340;&#23545;&#25239;&#24615;&#21338;&#24328;&#27169;&#22411;&#30340;&#21518;&#39564;&#37319;&#26679;&#26041;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#20302;&#36951;&#25022;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2310.19861</link><description>&lt;p&gt;
&#21518;&#39564;&#37319;&#26679;&#22312;&#31454;&#20105;&#24615;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65306;&#20989;&#25968;&#36817;&#20284;&#21644;&#37096;&#20998;&#35266;&#27979;
&lt;/p&gt;
&lt;p&gt;
Posterior Sampling for Competitive RL: Function Approximation and Partial Observation. (arXiv:2310.19861v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19861
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#21518;&#39564;&#37319;&#26679;&#31639;&#27861;&#22312;&#31454;&#20105;&#24615;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#24341;&#20837;&#33258;&#23545;&#24328;&#21644;&#23545;&#25239;&#24615;&#24191;&#20041;&#33406;&#30053;&#29305;&#31995;&#25968;&#65292;&#25552;&#20986;&#20102;&#29992;&#20110;&#25506;&#32034;-&#21033;&#29992;&#24179;&#34913;&#30340;&#27169;&#22411;&#26041;&#27861;&#65292;&#24182;&#19988;&#25104;&#21151;&#22788;&#29702;&#20102;&#29366;&#24577;&#30340;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#12290;&#21516;&#26102;&#65292;&#25552;&#20986;&#20102;&#23398;&#20064;&#20855;&#26377;&#28508;&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#30340;&#23545;&#25239;&#24615;&#21338;&#24328;&#27169;&#22411;&#30340;&#21518;&#39564;&#37319;&#26679;&#26041;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#20302;&#36951;&#25022;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#19968;&#33324;&#20989;&#25968;&#36817;&#20284;&#30340;&#32972;&#26223;&#19979;&#65292;&#29992;&#20110;&#31454;&#20105;&#24615;&#24378;&#21270;&#23398;&#20064;&#30340;&#21518;&#39564;&#37319;&#26679;&#31639;&#27861;&#12290;&#38024;&#23545;&#38646;&#21644;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#20013;&#30340;&#33258;&#23545;&#24328;&#21644;&#23545;&#25239;&#23398;&#20064;&#20004;&#20010;&#20851;&#38190;&#24773;&#26223;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#33258;&#23545;&#24328;&#21644;&#23545;&#25239;&#24615;&#24191;&#20041;&#33406;&#30053;&#29305;&#31995;&#25968;(GEC)&#20316;&#20026;&#20989;&#25968;&#36817;&#20284;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#24182;&#25429;&#25417;&#21338;&#24328;&#20013;&#30340;&#25506;&#32034;-&#21033;&#29992;&#24179;&#34913;&#12290;&#22522;&#20110;&#33258;&#23545;&#24328;GEC&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#33258;&#23545;&#24328;&#21518;&#39564;&#37319;&#26679;&#26041;&#27861;&#65292;&#20197;&#25511;&#21046;&#20004;&#20010;&#29609;&#23478;&#23398;&#20064;&#32435;&#20160;&#22343;&#34913;&#65292;&#21487;&#20197;&#25104;&#21151;&#22788;&#29702;&#29366;&#24577;&#30340;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#19968;&#22871;&#19982;&#23545;&#25163;&#30340;&#23545;&#25239;&#31574;&#30053;&#30456;&#36866;&#24212;&#30340;&#37096;&#20998;&#21487;&#35266;&#27979;&#21338;&#24328;&#27169;&#22411;&#12290;&#32467;&#21512;&#23545;&#25239;GEC&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#21518;&#39564;&#37319;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#20855;&#26377;&#28508;&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#30340;&#23545;&#25239;&#24615;&#21338;&#24328;&#27169;&#22411;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#20026;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#25552;&#20379;&#20102;&#20302;&#36951;&#25022;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates posterior sampling algorithms for competitive reinforcement learning (RL) in the context of general function approximations. Focusing on zero-sum Markov games (MGs) under two critical settings, namely self-play and adversarial learning, we first propose the self-play and adversarial generalized eluder coefficient (GEC) as complexity measures for function approximation, capturing the exploration-exploitation trade-off in MGs. Based on self-play GEC, we propose a model-based self-play posterior sampling method to control both players to learn Nash equilibrium, which can successfully handle the partial observability of states. Furthermore, we identify a set of partially observable MG models fitting MG learning with the adversarial policies of the opponent. Incorporating the adversarial GEC, we propose a model-based posterior sampling method for learning adversarial MG with potential partial observability. We further provide low regret bounds for proposed algorithms
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31934;&#30830;&#24674;&#22797;&#33410;&#28857;&#23646;&#24615;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#32858;&#31867;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#32593;&#32476;&#20449;&#24687;&#21644;&#33410;&#28857;&#23646;&#24615;&#20449;&#24687;&#20132;&#25442;&#65292;&#23454;&#29616;&#26356;&#21487;&#38752;&#30340;&#32593;&#32476;&#20449;&#24687;&#38656;&#35201;&#26356;&#23569;&#21487;&#38752;&#30340;&#23646;&#24615;&#20449;&#24687;&#30340;&#31934;&#30830;&#24674;&#22797;&#12290;</title><link>http://arxiv.org/abs/2310.19854</link><description>&lt;p&gt;
&#33410;&#28857;&#23646;&#24615;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#31934;&#30830;&#24674;&#22797;&#19982;Bregman&#30828;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Exact Recovery and Bregman Hard Clustering of Node-Attributed Stochastic Block Model. (arXiv:2310.19854v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19854
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31934;&#30830;&#24674;&#22797;&#33410;&#28857;&#23646;&#24615;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#32858;&#31867;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#32593;&#32476;&#20449;&#24687;&#21644;&#33410;&#28857;&#23646;&#24615;&#20449;&#24687;&#20132;&#25442;&#65292;&#23454;&#29616;&#26356;&#21487;&#38752;&#30340;&#32593;&#32476;&#20449;&#24687;&#38656;&#35201;&#26356;&#23569;&#21487;&#38752;&#30340;&#23646;&#24615;&#20449;&#24687;&#30340;&#31934;&#30830;&#24674;&#22797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#32858;&#31867;&#35299;&#20915;&#20102;&#35782;&#21035;&#20855;&#26377;&#30456;&#20284;&#36830;&#25509;&#27169;&#24335;&#30340;&#33410;&#28857;&#38598;&#65288;&#31038;&#21306;&#65289;&#30340;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#33410;&#28857;&#36824;&#20855;&#26377;&#19982;&#32858;&#31867;&#32467;&#26500;&#30456;&#20851;&#30340;&#23646;&#24615;&#12290;&#22240;&#27492;&#65292;&#21487;&#20197;&#32852;&#21512;&#21033;&#29992;&#32593;&#32476;&#20449;&#24687;&#65288;&#36793;&#65289;&#21644;&#33410;&#28857;&#20449;&#24687;&#65288;&#23646;&#24615;&#65289;&#26469;&#35774;&#35745;&#39640;&#24615;&#33021;&#30340;&#32858;&#31867;&#31639;&#27861;&#12290;&#22312;&#32593;&#32476;&#21644;&#33410;&#28857;&#23646;&#24615;&#30340;&#19968;&#33324;&#27169;&#22411;&#19979;&#65292;&#35813;&#24037;&#20316;&#24314;&#31435;&#20102;&#19968;&#20010;&#20449;&#24687;&#35770;&#20934;&#21017;&#65292;&#29992;&#20110;&#31934;&#30830;&#24674;&#22797;&#31038;&#21306;&#26631;&#31614;&#65292;&#24182;&#30830;&#23450;&#20102;&#30001;&#27169;&#22411;&#30340;Chernoff-Hellinger&#25955;&#24230;&#30830;&#23450;&#30340;&#30456;&#21464;&#12290;&#36825;&#20010;&#20934;&#21017;&#26174;&#31034;&#20102;&#32593;&#32476;&#21644;&#23646;&#24615;&#20449;&#24687;&#22914;&#20309;&#20132;&#25442;&#65292;&#20197;&#23454;&#29616;&#31934;&#30830;&#24674;&#22797;&#65288;&#20363;&#22914;&#65292;&#26356;&#21487;&#38752;&#30340;&#32593;&#32476;&#20449;&#24687;&#38656;&#35201;&#26356;&#19981;&#21487;&#38752;&#30340;&#23646;&#24615;&#20449;&#24687;&#65289;&#12290;&#35813;&#24037;&#20316;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#36845;&#20195;&#32858;&#31867;&#31639;&#27861;&#65292;&#26368;&#22823;&#21270;&#32852;&#21512;&#20284;&#28982;&#65292;&#20551;&#35774;&#32593;&#32476;&#20132;&#20114;&#21644;&#33410;&#28857;&#23646;&#24615;&#30340;&#27010;&#29575;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
Network clustering tackles the problem of identifying sets of nodes (communities) that have similar connection patterns. However, in many scenarios, nodes also have attributes that are correlated with the clustering structure. Thus, network information (edges) and node information (attributes) can be jointly leveraged to design high-performance clustering algorithms. Under a general model for the network and node attributes, this work establishes an information-theoretic criterion for the exact recovery of community labels and characterizes a phase transition determined by the Chernoff-Hellinger divergence of the model. The criterion shows how network and attribute information can be exchanged in order to have exact recovery (e.g., more reliable network information requires less reliable attribute information). This work also presents an iterative clustering algorithm that maximizes the joint likelihood, assuming that the probability distribution of network interactions and node attrib
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;&#22522;&#20110;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#36890;&#36807;&#21487;&#35299;&#37322;&#30340;&#31574;&#30053;&#23398;&#20064;&#26469;&#29702;&#35299;&#20915;&#31574;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#36879;&#26126;&#24230;&#12289;&#36866;&#24212;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#21644;&#23436;&#20840;&#31163;&#32447;&#36816;&#34892;&#30340;&#29305;&#28857;&#12290;&#36890;&#36807;&#23545;&#38463;&#23572;&#33576;&#28023;&#40664;&#30149;&#35786;&#26029;&#38382;&#39064;&#30340;&#23454;&#39564;&#39564;&#35777;&#65292;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#20316;&#20026;&#23457;&#35745;&#21644;&#20998;&#26512;&#24037;&#20855;&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.19831</link><description>&lt;p&gt;
&#27169;&#20223;&#35299;&#37322;&#65306;&#36890;&#36807;&#21487;&#35299;&#37322;&#30340;&#31574;&#30053;&#23398;&#20064;&#29702;&#35299;&#20915;&#31574;
&lt;/p&gt;
&lt;p&gt;
Explaining by Imitating: Understanding Decisions by Interpretable Policy Learning. (arXiv:2310.19831v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19831
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;&#22522;&#20110;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#36890;&#36807;&#21487;&#35299;&#37322;&#30340;&#31574;&#30053;&#23398;&#20064;&#26469;&#29702;&#35299;&#20915;&#31574;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#36879;&#26126;&#24230;&#12289;&#36866;&#24212;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#21644;&#23436;&#20840;&#31163;&#32447;&#36816;&#34892;&#30340;&#29305;&#28857;&#12290;&#36890;&#36807;&#23545;&#38463;&#23572;&#33576;&#28023;&#40664;&#30149;&#35786;&#26029;&#38382;&#39064;&#30340;&#23454;&#39564;&#39564;&#35777;&#65292;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#20316;&#20026;&#23457;&#35745;&#21644;&#20998;&#26512;&#24037;&#20855;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#23519;&#25968;&#25454;&#20013;&#29702;&#35299;&#20154;&#31867;&#34892;&#20026;&#23545;&#20110;&#36879;&#26126;&#24230;&#21644;&#20915;&#31574;&#30340;&#38382;&#36131;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#65292;&#22914;&#21307;&#30103;&#20445;&#20581;&#39046;&#22495;&#65292;&#24314;&#27169;&#20915;&#31574;&#32773;&#30340;&#31574;&#30053;&#20855;&#26377;&#25361;&#25112;&#24615;&#8212;&#8212;&#27809;&#26377;&#35775;&#38382;&#24213;&#23618;&#29366;&#24577;&#30340;&#26435;&#38480;&#65292;&#27809;&#26377;&#20102;&#35299;&#29615;&#22659;&#21160;&#24577;&#30340;&#30693;&#35782;&#65292;&#20063;&#27809;&#26377;&#36827;&#34892;&#23454;&#26102;&#23454;&#39564;&#30340;&#23481;&#38169;&#33021;&#21147;&#12290;&#25105;&#20204;&#24076;&#26395;&#23398;&#20064;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#30340;&#20915;&#31574;&#34892;&#20026;&#34920;&#31034;&#65292;&#23427;&#20855;&#26377;&#65288;1&#65289;&#35774;&#35745;&#19978;&#30340;&#36879;&#26126;&#24230;&#65292;&#65288;2&#65289;&#36866;&#24212;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#65292;&#65288;3&#65289;&#23436;&#20840;&#31163;&#32447;&#36816;&#34892;&#12290;&#20026;&#20102;&#28385;&#36275;&#36825;&#20123;&#20851;&#38190;&#26465;&#20214;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#26469;&#36827;&#34892;&#21487;&#35299;&#37322;&#30340;&#31574;&#30053;&#23398;&#20064;&#65288;"Interpole"&#65289;&#65292;&#23427;&#21516;&#26102;&#20272;&#35745;&#19968;&#20010;&#20195;&#29702;&#20154;&#30340;&#65288;&#21487;&#33021;&#26377;&#20559;&#24046;&#30340;&#65289;&#32622;&#20449;&#26356;&#26032;&#36807;&#31243;&#20197;&#21450;&#20182;&#20204;&#65288;&#21487;&#33021;&#27425;&#20248;&#30340;&#65289;&#20449;&#24565;&#21160;&#20316;&#26144;&#23556;&#12290;&#36890;&#36807;&#23545;&#27169;&#25311;&#21644;&#30495;&#23454;&#19990;&#30028;&#30340;&#38463;&#23572;&#33576;&#28023;&#40664;&#30149;&#35786;&#26029;&#38382;&#39064;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20316;&#20026;&#23457;&#35745;&#21644;&#20998;&#26512;&#24037;&#20855;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding human behavior from observed data is critical for transparency and accountability in decision-making. Consider real-world settings such as healthcare, in which modeling a decision-maker's policy is challenging -- with no access to underlying states, no knowledge of environment dynamics, and no allowance for live experimentation. We desire learning a data-driven representation of decision-making behavior that (1) inheres transparency by design, (2) accommodates partial observability, and (3) operates completely offline. To satisfy these key criteria, we propose a novel model-based Bayesian method for interpretable policy learning ("Interpole") that jointly estimates an agent's (possibly biased) belief-update process together with their (possibly suboptimal) belief-action mapping. Through experiments on both simulated and real-world data for the problem of Alzheimer's disease diagnosis, we illustrate the potential of our approach as an investigative device for auditing, qua
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#24179;&#31283;&#29615;&#22659;&#30340;&#33258;&#36866;&#24212;&#39118;&#38505;&#24863;&#30693;&#31574;&#30053;&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#21508;&#31181;&#39118;&#38505;&#24230;&#37327;&#21644;&#37325;&#21551;&#36125;&#21494;&#26031;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#39640;&#27874;&#21160;&#24615;&#39046;&#22495;&#20013;&#31616;&#21333;&#22870;&#21169;&#26368;&#22823;&#21270;&#26041;&#27861;&#30340;&#19981;&#21487;&#38752;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.19821</link><description>&lt;p&gt;
&#19968;&#31181;&#38754;&#21521;&#38750;&#24179;&#31283;&#38543;&#26426;&#22810;&#33218;&#32769;&#34382;&#26426;&#30340;&#39118;&#38505;&#35268;&#36991;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Risk-Averse Framework for Non-Stationary Stochastic Multi-Armed Bandits. (arXiv:2310.19821v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19821
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#24179;&#31283;&#29615;&#22659;&#30340;&#33258;&#36866;&#24212;&#39118;&#38505;&#24863;&#30693;&#31574;&#30053;&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#21508;&#31181;&#39118;&#38505;&#24230;&#37327;&#21644;&#37325;&#21551;&#36125;&#21494;&#26031;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#39640;&#27874;&#21160;&#24615;&#39046;&#22495;&#20013;&#31616;&#21333;&#22870;&#21169;&#26368;&#22823;&#21270;&#26041;&#27861;&#30340;&#19981;&#21487;&#38752;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20856;&#22411;&#30340;&#38543;&#26426;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#20013;&#65292;&#30446;&#26631;&#36890;&#24120;&#26159;&#22312;&#19968;&#23450;&#30340;&#26102;&#38388;&#33539;&#22260;&#20869;&#26368;&#22823;&#21270;&#39044;&#26399;&#22870;&#21169;&#24635;&#21644;&#12290;&#28982;&#32780;&#65292;&#24403;&#25552;&#20379;&#39069;&#22806;&#30340;&#29615;&#22659;&#29305;&#23450;&#30693;&#35782;&#26102;&#65292;&#36873;&#25321;&#19968;&#20010;&#33021;&#22815;&#36798;&#21040;&#26368;&#20248;&#30340;&#31574;&#30053;&#19981;&#20877;&#36866;&#29992;&#12290;&#23588;&#20854;&#26159;&#22312;&#21307;&#30103;&#25110;&#37329;&#34701;&#31561;&#39640;&#27874;&#21160;&#24615;&#39046;&#22495;&#65292;&#31616;&#21333;&#30340;&#22870;&#21169;&#26368;&#22823;&#21270;&#26041;&#27861;&#24448;&#24448;&#19981;&#33021;&#20934;&#30830;&#25429;&#25417;&#23398;&#20064;&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#65292;&#23548;&#33268;&#19981;&#21487;&#38752;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#20026;&#35299;&#20915;&#36825;&#31867;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#39118;&#38505;&#24863;&#30693;&#31574;&#30053;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#25805;&#20316;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#32467;&#21512;&#20102;&#25991;&#29486;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#21508;&#31181;&#39118;&#38505;&#24230;&#37327;&#65292;&#23558;&#22810;&#20010;&#22810;&#33218;&#32769;&#34382;&#26426;&#31639;&#27861;&#26063;&#26144;&#23556;&#21040;&#39118;&#38505;&#25935;&#24863;&#35774;&#32622;&#20013;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#32467;&#26524;&#31639;&#27861;&#37197;&#22791;&#20102;&#37325;&#21551;&#36125;&#21494;&#26031;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#65288;R-BOCPD&#65289;&#31639;&#27861;&#65292;&#24182;&#26045;&#21152;&#20102;&#65288;&#21487;&#35843;&#33410;&#30340;&#65289;&#24378;&#21046;&#32456;&#27490;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
In a typical stochastic multi-armed bandit problem, the objective is often to maximize the expected sum of rewards over some time horizon $T$. While the choice of a strategy that accomplishes that is optimal with no additional information, it is no longer the case when provided additional environment-specific knowledge. In particular, in areas of high volatility like healthcare or finance, a naive reward maximization approach often does not accurately capture the complexity of the learning problem and results in unreliable solutions. To tackle problems of this nature, we propose a framework of adaptive risk-aware strategies that operate in non-stationary environments. Our framework incorporates various risk measures prevalent in the literature to map multiple families of multi-armed bandit algorithms into a risk-sensitive setting. In addition, we equip the resulting algorithms with the Restarted Bayesian Online Change-Point Detection (R-BOCPD) algorithm and impose a (tunable) forced ex
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#29992;&#20110;&#23545;&#36793;&#32536;&#38598;&#21512;&#19978;&#30340;&#20989;&#25968;&#36827;&#34892;&#24314;&#27169;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;Hodge&#20998;&#35299;&#24320;&#21457;&#20102;&#36866;&#29992;&#20110;&#19981;&#21516;&#24212;&#29992;&#22330;&#26223;&#30340;&#26080;&#25955;&#24230;&#21644;&#26080;&#26059;&#24230;&#30340;&#39640;&#26031;&#36807;&#31243;&#65292;&#24182;&#36890;&#36807;&#32452;&#21512;&#23427;&#20204;&#26469;&#34920;&#31034;&#20219;&#24847;&#36793;&#32536;&#20989;&#25968;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#36825;&#31181;&#26041;&#27861;&#22312;&#27969;&#21160;&#25968;&#25454;&#25512;&#26029;&#20013;&#20855;&#26377;&#28508;&#22312;&#30340;&#23454;&#38469;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2310.19450</link><description>&lt;p&gt;
Hodge-Compositional &#36793;&#32536;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Hodge-Compositional Edge Gaussian Processes. (arXiv:2310.19450v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19450
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#29992;&#20110;&#23545;&#36793;&#32536;&#38598;&#21512;&#19978;&#30340;&#20989;&#25968;&#36827;&#34892;&#24314;&#27169;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;Hodge&#20998;&#35299;&#24320;&#21457;&#20102;&#36866;&#29992;&#20110;&#19981;&#21516;&#24212;&#29992;&#22330;&#26223;&#30340;&#26080;&#25955;&#24230;&#21644;&#26080;&#26059;&#24230;&#30340;&#39640;&#26031;&#36807;&#31243;&#65292;&#24182;&#36890;&#36807;&#32452;&#21512;&#23427;&#20204;&#26469;&#34920;&#31034;&#20219;&#24847;&#36793;&#32536;&#20989;&#25968;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#36825;&#31181;&#26041;&#27861;&#22312;&#27969;&#21160;&#25968;&#25454;&#25512;&#26029;&#20013;&#20855;&#26377;&#28508;&#22312;&#30340;&#23454;&#38469;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36793;&#32536;&#38598;&#21512;&#30340;2-&#22797;&#24418;&#32467;&#26500;&#65288;&#31867;&#20284;&#20110;&#22270;&#24418;&#65292;&#20854;&#20013;&#36793;&#32536;&#21487;&#24418;&#25104;&#19977;&#35282;&#38754;&#65289;&#30340;&#20989;&#25968;&#24314;&#27169;&#30340;&#26377;&#21407;&#21017;&#30340;&#39640;&#26031;&#36807;&#31243;&#65288;GPs&#65289;&#12290;&#36825;&#31181;&#26041;&#27861;&#36866;&#29992;&#20110;&#23398;&#20064;&#32593;&#32476;&#19978;&#30340;&#27969;&#21160;&#31867;&#22411;&#25968;&#25454;&#65292;&#20854;&#20013;&#36793;&#32536;&#27969;&#21487;&#20197;&#36890;&#36807;&#31163;&#25955;&#30340;&#25955;&#24230;&#21644;&#26059;&#24230;&#26469;&#34920;&#24449;&#12290;&#20511;&#37492;Hodge&#20998;&#35299;&#65292;&#25105;&#20204;&#39318;&#20808;&#24320;&#21457;&#20102;&#36866;&#29992;&#20110;&#21508;&#31181;&#24212;&#29992;&#30340;&#26080;&#25955;&#24230;&#21644;&#26080;&#26059;&#28216;&#30340;&#36793;&#32536;GPs&#12290;&#28982;&#21518;&#23558;&#23427;&#20204;&#32452;&#21512;&#36215;&#26469;&#21019;&#24314;Hodge-&#32452;&#21512;&#36793;&#32536;GPs&#65292;&#36825;&#20123;GPs&#36275;&#22815;&#34920;&#36798;&#20219;&#20309;&#36793;&#32536;&#20989;&#25968;&#12290;&#36825;&#20123;GPs&#20415;&#20110;&#23545;&#36793;&#32536;&#20989;&#25968;&#30340;&#19981;&#21516;Hodge&#20998;&#37327;&#36827;&#34892;&#30452;&#25509;&#21644;&#29420;&#31435;&#30340;&#23398;&#20064;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;&#36229;&#21442;&#25968;&#20248;&#21270;&#36807;&#31243;&#20013;&#25429;&#25417;&#23427;&#20204;&#30340;&#30456;&#20851;&#24615;&#12290;&#20026;&#20102;&#31361;&#26174;&#23427;&#20204;&#30340;&#23454;&#38469;&#28508;&#21147;&#65292;&#25105;&#20204;&#23558;&#23427;&#20204;&#24212;&#29992;&#20110;&#36135;&#24065;&#20817;&#25442;&#12289;&#28023;&#27915;&#27969;&#21160;&#21644;&#20379;&#27700;&#32593;&#32476;&#20013;&#30340;&#27969;&#21160;&#25968;&#25454;&#25512;&#26029;&#65292;&#24182;&#23558;&#20854;&#19982;&#26367;&#20195;&#27169;&#22411;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose principled Gaussian processes (GPs) for modeling functions defined over the edge set of a simplicial 2-complex, a structure similar to a graph in which edges may form triangular faces. This approach is intended for learning flow-type data on networks where edge flows can be characterized by the discrete divergence and curl. Drawing upon the Hodge decomposition, we first develop classes of divergence-free and curl-free edge GPs, suitable for various applications. We then combine them to create \emph{Hodge-compositional edge GPs} that are expressive enough to represent any edge function. These GPs facilitate direct and independent learning for the different Hodge components of edge functions, enabling us to capture their relevance during hyperparameter optimization. To highlight their practical potential, we apply them for flow data inference in currency exchange, ocean flows and water supply networks, comparing them to alternative models.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Q&#38598;&#25104;&#30340;CATE&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#20854;&#36890;&#36807;&#20351;&#29992;&#21452;&#37325;&#40065;&#26834;&#25439;&#22833;&#23454;&#29616;&#20102;&#32479;&#35745;&#19978;&#30340;&#26368;&#20339;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#36951;&#25022;&#29575;</title><link>http://arxiv.org/abs/2310.16945</link><description>&lt;p&gt;
Causal Q-Aggregation for CATE Model Selection&#65288;CATE&#27169;&#22411;&#36873;&#25321;&#20013;&#30340;&#22240;&#26524;Q&#38598;&#25104;&#65289;
&lt;/p&gt;
&lt;p&gt;
Causal Q-Aggregation for CATE Model Selection. (arXiv:2310.16945v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16945
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Q&#38598;&#25104;&#30340;CATE&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#20854;&#36890;&#36807;&#20351;&#29992;&#21452;&#37325;&#40065;&#26834;&#25439;&#22833;&#23454;&#29616;&#20102;&#32479;&#35745;&#19978;&#30340;&#26368;&#20339;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#36951;&#25022;&#29575;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20934;&#30830;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;CATE&#65289;&#26159;&#20010;&#24615;&#21270;&#20915;&#31574;&#30340;&#26680;&#24515;&#12290;&#23613;&#31649;&#26377;&#22823;&#37327;&#29992;&#20110;CATE&#20272;&#35745;&#30340;&#27169;&#22411;&#65292;&#20294;&#30001;&#20110;&#22240;&#26524;&#25512;&#26029;&#30340;&#22522;&#26412;&#38382;&#39064;&#65292;&#27169;&#22411;&#36873;&#25321;&#26159;&#19968;&#39033;&#38750;&#24120;&#26840;&#25163;&#30340;&#20219;&#21153;&#12290;&#26368;&#36817;&#30340;&#23454;&#35777;&#24037;&#20316;&#25552;&#20379;&#20102;&#26377;&#21033;&#20110;&#20855;&#26377;&#21452;&#37325;&#40065;&#26834;&#24615;&#36136;&#30340;&#20195;&#29702;&#25439;&#22833;&#24230;&#37327;&#21644;&#27169;&#22411;&#38598;&#25104;&#30340;&#35777;&#25454;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#36825;&#20123;&#27169;&#22411;&#30340;&#29702;&#35770;&#29702;&#35299;&#36824;&#19981;&#22815;&#12290;&#30452;&#25509;&#24212;&#29992;&#20808;&#21069;&#30340;&#29702;&#35770;&#24037;&#20316;&#20250;&#30001;&#20110;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#30340;&#38750;&#20984;&#24615;&#32780;&#23548;&#33268;&#27425;&#20248;&#30340;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#29575;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29616;&#26377;&#20027;&#35201;CATE&#38598;&#25104;&#26041;&#27861;&#30340;&#36951;&#25022;&#29575;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21452;&#37325;&#40065;&#26834;&#25439;&#22833;&#30340;Q&#38598;&#25104;&#30340;&#26032;&#30340;CATE&#27169;&#22411;&#38598;&#25104;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#34920;&#26126;&#65292;&#22240;&#26524;Q&#38598;&#25104;&#22312;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#30340;&#36951;&#25022;&#29575;&#19978;&#36798;&#21040;&#20102;&#32479;&#35745;&#19978;&#30340;&#26368;&#20248;&#20540;&#20026;$\frac{\log(M)}{n}$&#65288;&#20854;&#20013;$M$&#20026;&#27169;&#22411;&#25968;&#65292;$n$&#20026;&#26679;&#26412;&#25968;&#65289;&#65292;&#21152;&#19978;&#39640;&#38454;&#20272;&#35745;&#35823;&#24046;&#39033;
&lt;/p&gt;
&lt;p&gt;
Accurate estimation of conditional average treatment effects (CATE) is at the core of personalized decision making. While there is a plethora of models for CATE estimation, model selection is a nontrivial task, due to the fundamental problem of causal inference. Recent empirical work provides evidence in favor of proxy loss metrics with double robust properties and in favor of model ensembling. However, theoretical understanding is lacking. Direct application of prior theoretical work leads to suboptimal oracle model selection rates due to the non-convexity of the model selection problem. We provide regret rates for the major existing CATE ensembling approaches and propose a new CATE model ensembling approach based on Q-aggregation using the doubly robust loss. Our main result shows that causal Q-aggregation achieves statistically optimal oracle model selection regret rates of $\frac{\log(M)}{n}$ (with $M$ models and $n$ samples), with the addition of higher-order estimation error term
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#35268;&#33539;&#21270;&#27491;&#24577;&#27969;&#26041;&#27861;&#65292;&#29992;&#20110;&#27969;&#24418;&#23398;&#20064;&#12290;&#36890;&#36807;&#21487;&#23398;&#20064;&#30340;&#21487;&#36870;&#21464;&#25442;&#23558;&#25968;&#25454;&#23884;&#20837;&#21040;&#39640;&#32500;&#31354;&#38388;&#20013;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#22312;&#27969;&#24418;&#19978;&#35745;&#31639;&#27010;&#29575;&#23494;&#24230;&#24182;&#20248;&#21270;&#32593;&#32476;&#21442;&#25968;&#30340;&#30446;&#26631;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#26041;&#27861;&#22312;&#23398;&#20064;&#21040;&#30340;&#27969;&#24418;&#34920;&#31034;&#20013;&#23384;&#22312;&#30528;&#19982;&#27969;&#24418;&#20851;&#32852;&#19988;&#36864;&#21270;&#30340;&#20869;&#22312;&#22522;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.12743</link><description>&lt;p&gt;
&#27969;&#24418;&#23398;&#20064;&#30340;&#35268;&#33539;&#21270;&#27491;&#24577;&#27969;
&lt;/p&gt;
&lt;p&gt;
Canonical normalizing flows for manifold learning. (arXiv:2310.12743v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12743
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#35268;&#33539;&#21270;&#27491;&#24577;&#27969;&#26041;&#27861;&#65292;&#29992;&#20110;&#27969;&#24418;&#23398;&#20064;&#12290;&#36890;&#36807;&#21487;&#23398;&#20064;&#30340;&#21487;&#36870;&#21464;&#25442;&#23558;&#25968;&#25454;&#23884;&#20837;&#21040;&#39640;&#32500;&#31354;&#38388;&#20013;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#22312;&#27969;&#24418;&#19978;&#35745;&#31639;&#27010;&#29575;&#23494;&#24230;&#24182;&#20248;&#21270;&#32593;&#32476;&#21442;&#25968;&#30340;&#30446;&#26631;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#26041;&#27861;&#22312;&#23398;&#20064;&#21040;&#30340;&#27969;&#24418;&#34920;&#31034;&#20013;&#23384;&#22312;&#30528;&#19982;&#27969;&#24418;&#20851;&#32852;&#19988;&#36864;&#21270;&#30340;&#20869;&#22312;&#22522;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27969;&#24418;&#23398;&#20064;&#27969;&#26159;&#19968;&#31867;&#29983;&#25104;&#24314;&#27169;&#25216;&#26415;&#65292;&#20551;&#35774;&#25968;&#25454;&#20855;&#26377;&#20302;&#32500;&#27969;&#24418;&#25551;&#36848;&#12290;&#36890;&#36807;&#21487;&#23398;&#20064;&#30340;&#21487;&#36870;&#21464;&#25442;&#23558;&#36825;&#31181;&#27969;&#24418;&#23884;&#20837;&#21040;&#25968;&#25454;&#30340;&#39640;&#32500;&#31354;&#38388;&#20013;&#12290;&#22240;&#27492;&#65292;&#19968;&#26086;&#36890;&#36807;&#37325;&#26500;&#25439;&#22833;&#27491;&#30830;&#23545;&#40784;&#27969;&#24418;&#65292;&#27969;&#24418;&#19978;&#30340;&#27010;&#29575;&#23494;&#24230;&#23601;&#26159;&#21487;&#35745;&#31639;&#30340;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#26368;&#22823;&#20284;&#28982;&#26469;&#20248;&#21270;&#32593;&#32476;&#21442;&#25968;&#12290;&#33258;&#28982;&#22320;&#65292;&#25968;&#25454;&#30340;&#20302;&#32500;&#34920;&#31034;&#38656;&#35201;&#26159;&#21333;&#23556;&#26144;&#23556;&#12290;&#26368;&#36817;&#30340;&#26041;&#27861;&#33021;&#22815;&#22312;&#24314;&#27169;&#30340;&#27969;&#24418;&#19978;&#23545;&#23494;&#24230;&#36827;&#34892;&#23545;&#20934;&#65292;&#24182;&#22312;&#23884;&#20837;&#21040;&#39640;&#32500;&#31354;&#38388;&#26102;&#39640;&#25928;&#35745;&#31639;&#23494;&#24230;&#20307;&#31215;&#21464;&#21270;&#39033;&#12290;&#28982;&#32780;&#65292;&#38500;&#38750;&#21333;&#23556;&#26144;&#23556;&#22312;&#35299;&#26512;&#19978;&#39044;&#23450;&#20041;&#65292;&#21542;&#21017;&#23398;&#20064;&#21040;&#30340;&#27969;&#24418;&#19981;&#19968;&#23450;&#26159;&#25968;&#25454;&#30340;&#26377;&#25928;&#34920;&#31034;&#12290;&#20063;&#23601;&#26159;&#35828;&#65292;&#36825;&#31181;&#27169;&#22411;&#30340;&#28508;&#22312;&#32500;&#24230;&#32463;&#24120;&#20250;&#23398;&#20064;&#21040;&#19982;&#27969;&#24418;&#30456;&#20851;&#24182;&#19988;&#36864;&#21270;&#30340;&#20869;&#22312;&#22522;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Manifold learning flows are a class of generative modelling techniques that assume a low-dimensional manifold description of the data. The embedding of such manifold into the high-dimensional space of the data is achieved via learnable invertible transformations. Therefore, once the manifold is properly aligned via a reconstruction loss, the probability density is tractable on the manifold and maximum likelihood can be used optimize the network parameters. Naturally, the lower-dimensional representation of the data requires an injective-mapping. Recent approaches were able to enforce that density aligns with the modelled manifold, while efficiently calculating the density volume-change term when embedding to the higher-dimensional space. However, unless the injective-mapping is analytically predefined, the learned manifold is not necessarily an efficient representation of the data. Namely, the latent dimensions of such models frequently learn an entangled intrinsic basis with degenerat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31232;&#30095;&#21464;&#20998;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#20013;&#28857;&#20272;&#35745;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#24067;&#26391;&#36816;&#21160;&#20808;&#39564;&#21644;&#29305;&#24449;&#21521;&#37327;&#24341;&#23548;&#21464;&#37327;&#65292;&#25512;&#23548;&#20102;&#39057;&#29575;&#27966;&#21487;&#20449;&#21306;&#38388;&#30340;&#29702;&#35770;&#20445;&#35777;&#21644;&#38480;&#21046;&#65292;&#24182;&#22312;&#36275;&#22815;&#22810;&#30340;&#24341;&#23548;&#21464;&#37327;&#30340;&#24773;&#20917;&#19979;&#31934;&#30830;&#23450;&#20041;&#20102;&#28176;&#36817;&#39057;&#29575;&#27966;&#35206;&#30422;&#65292;&#20174;&#32780;&#25512;&#26029;&#20986;&#36825;&#20010;&#21464;&#20998;&#26041;&#27861;&#30340;&#21487;&#20449;&#21306;&#38388;&#20309;&#26102;&#20445;&#23432;&#65292;&#20309;&#26102;&#36807;&#20110;&#33258;&#20449;/&#35823;&#23548;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#32467;&#26524;&#30340;&#36866;&#29992;&#24615;&#65292;&#24182;&#35752;&#35770;&#20102;&#19982;&#20854;&#20182;&#24120;&#35265;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#30340;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.00097</link><description>&lt;p&gt;
&#31232;&#30095;&#21464;&#20998;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#28857;&#20272;&#35745;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#19982;&#24067;&#26391;&#36816;&#21160;&#20808;&#39564;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Pointwise uncertainty quantification for sparse variational Gaussian process regression with a Brownian motion prior. (arXiv:2310.00097v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00097
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31232;&#30095;&#21464;&#20998;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#20013;&#28857;&#20272;&#35745;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#24067;&#26391;&#36816;&#21160;&#20808;&#39564;&#21644;&#29305;&#24449;&#21521;&#37327;&#24341;&#23548;&#21464;&#37327;&#65292;&#25512;&#23548;&#20102;&#39057;&#29575;&#27966;&#21487;&#20449;&#21306;&#38388;&#30340;&#29702;&#35770;&#20445;&#35777;&#21644;&#38480;&#21046;&#65292;&#24182;&#22312;&#36275;&#22815;&#22810;&#30340;&#24341;&#23548;&#21464;&#37327;&#30340;&#24773;&#20917;&#19979;&#31934;&#30830;&#23450;&#20041;&#20102;&#28176;&#36817;&#39057;&#29575;&#27966;&#35206;&#30422;&#65292;&#20174;&#32780;&#25512;&#26029;&#20986;&#36825;&#20010;&#21464;&#20998;&#26041;&#27861;&#30340;&#21487;&#20449;&#21306;&#38388;&#20309;&#26102;&#20445;&#23432;&#65292;&#20309;&#26102;&#36807;&#20110;&#33258;&#20449;/&#35823;&#23548;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#32467;&#26524;&#30340;&#36866;&#29992;&#24615;&#65292;&#24182;&#35752;&#35770;&#20102;&#19982;&#20854;&#20182;&#24120;&#35265;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#29305;&#24449;&#21521;&#37327;&#24341;&#23548;&#21464;&#37327;&#30340;&#31232;&#30095;&#21464;&#20998;&#39640;&#26031;&#36807;&#31243;&#26041;&#27861;&#30340;&#28857;&#20272;&#35745;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#23545;&#20110;&#20855;&#26377;&#37325;&#26631;&#23450;&#24067;&#26391;&#36816;&#21160;&#20808;&#39564;&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#28857;&#21270;&#21487;&#20449;&#21306;&#38388;&#30340;&#39057;&#29575;&#27966;&#22823;&#23567;&#21644;&#35206;&#30422;&#30340;&#29702;&#35770;&#20445;&#35777;&#21644;&#38480;&#21046;&#12290;&#36890;&#36807;&#20805;&#20998;&#30340;&#24341;&#23548;&#21464;&#37327;&#65292;&#25105;&#20204;&#31934;&#30830;&#22320;&#25551;&#36848;&#20102;&#28176;&#36817;&#39057;&#29575;&#27966;&#35206;&#30422;&#65292;&#25512;&#26029;&#20102;&#36825;&#20010;&#21464;&#20998;&#26041;&#27861;&#30340;&#21487;&#20449;&#21306;&#38388;&#20309;&#26102;&#20445;&#23432;&#65292;&#20309;&#26102;&#36807;&#20110;&#33258;&#20449;/&#35823;&#23548;&#12290;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#35828;&#26126;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#30340;&#36866;&#29992;&#24615;&#65292;&#24182;&#35752;&#35770;&#20102;&#19982;&#20854;&#20182;&#24120;&#35265;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study pointwise estimation and uncertainty quantification for a sparse variational Gaussian process method with eigenvector inducing variables. For a rescaled Brownian motion prior, we derive theoretical guarantees and limitations for the frequentist size and coverage of pointwise credible sets. For sufficiently many inducing variables, we precisely characterize the asymptotic frequentist coverage, deducing when credible sets from this variational method are conservative and when overconfident/misleading. We numerically illustrate the applicability of our results and discuss connections with other common Gaussian process priors.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#31867;&#20284;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#20026;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;(SAM)&#65292;&#19968;&#31181;&#25913;&#36827;&#27867;&#21270;&#24615;&#33021;&#30340;&#26799;&#24230;&#19979;&#38477;&#21464;&#31181;&#65292;&#30830;&#23450;&#20102;&#19968;&#20010;&#31283;&#23450;&#24615;&#36793;&#30028;&#65292;&#35813;&#36793;&#30028;&#21462;&#20915;&#20110;&#26799;&#24230;&#30340;&#33539;&#25968;&#12290;</title><link>http://arxiv.org/abs/2309.12488</link><description>&lt;p&gt;
&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#21644;&#31283;&#23450;&#24615;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sharpness-Aware Minimization and the Edge of Stability. (arXiv:2309.12488v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12488
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#31867;&#20284;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#20026;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;(SAM)&#65292;&#19968;&#31181;&#25913;&#36827;&#27867;&#21270;&#24615;&#33021;&#30340;&#26799;&#24230;&#19979;&#38477;&#21464;&#31181;&#65292;&#30830;&#23450;&#20102;&#19968;&#20010;&#31283;&#23450;&#24615;&#36793;&#30028;&#65292;&#35813;&#36793;&#30028;&#21462;&#20915;&#20110;&#26799;&#24230;&#30340;&#33539;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#24403;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;(GD)&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26102;&#65292;&#25439;&#22833;&#20989;&#25968;&#30340;Hessian&#30697;&#38453;&#30340;&#25805;&#20316;&#31526;&#33539;&#25968;&#20250;&#22686;&#38271;&#65292;&#30452;&#21040;&#25509;&#36817;$2/\eta$&#65292;&#20043;&#21518;&#20250;&#22312;&#35813;&#20540;&#21608;&#22260;&#27874;&#21160;&#12290;&#26681;&#25454;&#23545;&#25439;&#22833;&#20989;&#25968;&#30340;&#23616;&#37096;&#20108;&#27425;&#36924;&#36817;&#65292;$2/\eta$&#34987;&#31216;&#20026;&#8220;&#31283;&#23450;&#24615;&#36793;&#30028;&#8221;&#12290;&#25105;&#20204;&#20351;&#29992;&#31867;&#20284;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#20026;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;(SAM)&#30830;&#23450;&#20102;&#19968;&#20010;&#8220;&#31283;&#23450;&#24615;&#36793;&#30028;&#8221;&#65292;SAM&#26159;&#19968;&#31181;&#25913;&#36827;&#27867;&#21270;&#24615;&#33021;&#30340;GD&#21464;&#31181;&#12290;&#19982;GD&#19981;&#21516;&#65292;SAM&#30340;&#31283;&#23450;&#24615;&#36793;&#30028;&#21462;&#20915;&#20110;&#26799;&#24230;&#30340;&#33539;&#25968;&#12290;&#36890;&#36807;&#19977;&#20010;&#28145;&#24230;&#23398;&#20064;&#20219;&#21153;&#30340;&#23454;&#35777;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;SAM&#22312;&#36825;&#20010;&#20998;&#26512;&#20013;&#30830;&#23450;&#30340;&#31283;&#23450;&#24615;&#36793;&#30028;&#19978;&#36816;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent experiments have shown that, often, when training a neural network with gradient descent (GD) with a step size $\eta$, the operator norm of the Hessian of the loss grows until it approximately reaches $2/\eta$, after which it fluctuates around this value.  The quantity $2/\eta$ has been called the "edge of stability" based on consideration of a local quadratic approximation of the loss. We perform a similar calculation to arrive at an "edge of stability" for Sharpness-Aware Minimization (SAM), a variant of GD which has been shown to improve its generalization. Unlike the case for GD, the resulting SAM-edge depends on the norm of the gradient. Using three deep learning training tasks, we see empirically that SAM operates on the edge of stability identified by this analysis.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#24191;&#20041;&#30697;&#26041;&#27861;&#65288;SGMM&#65289;&#65292;&#29992;&#20110;&#20272;&#35745;&#21644;&#25512;&#26029;&#30697;&#38480;&#21046;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#24555;&#36895;&#21644;&#21487;&#25193;&#23637;&#30340;&#23454;&#26102;&#22788;&#29702;&#33021;&#21147;&#65292;&#24182;&#19988;&#33021;&#22815;&#22788;&#29702;&#22823;&#35268;&#27169;&#21644;&#22312;&#32447;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2308.13564</link><description>&lt;p&gt;
SGMM: &#24191;&#20041;&#30697;&#26041;&#27861;&#30340;&#38543;&#26426;&#36817;&#20284;
&lt;/p&gt;
&lt;p&gt;
SGMM: Stochastic Approximation to Generalized Method of Moments. (arXiv:2308.13564v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13564
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#24191;&#20041;&#30697;&#26041;&#27861;&#65288;SGMM&#65289;&#65292;&#29992;&#20110;&#20272;&#35745;&#21644;&#25512;&#26029;&#30697;&#38480;&#21046;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#24555;&#36895;&#21644;&#21487;&#25193;&#23637;&#30340;&#23454;&#26102;&#22788;&#29702;&#33021;&#21147;&#65292;&#24182;&#19988;&#33021;&#22815;&#22788;&#29702;&#22823;&#35268;&#27169;&#21644;&#22312;&#32447;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#31867;&#65292;&#38543;&#26426;&#24191;&#20041;&#30697;&#26041;&#27861;&#65288;SGMM&#65289;&#65292;&#29992;&#20110;&#20272;&#35745;&#21644;&#25512;&#26029;&#65288;&#36229;&#35782;&#21035;&#65289;&#30697;&#38480;&#21046;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;SGMM&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#38543;&#26426;&#36924;&#36817;&#26041;&#27861;&#65292;&#26367;&#20195;&#20102;&#27969;&#34892;&#30340;Hansen&#65288;1982&#24180;&#65289;&#30340;&#65288;&#31163;&#32447;&#65289;GMM&#65292;&#24182;&#25552;&#20379;&#20102;&#24555;&#36895;&#21644;&#21487;&#25193;&#23637;&#30340;&#23454;&#26102;&#27969;&#25968;&#25454;&#22788;&#29702;&#33021;&#21147;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;SGMM&#23545;&#20110;&#25928;&#29575;&#19981;&#39640;&#30340;&#22312;&#32447;2SLS&#21644;&#39640;&#25928;&#30340;SGMM&#20855;&#26377;&#20960;&#20046;&#30830;&#23450;&#30340;&#25910;&#25947;&#24615;&#21644;&#65288;&#20989;&#25968;&#65289;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Durbin-Wu-Hausman&#21644;Sargan-Hansen&#27979;&#35797;&#30340;&#22312;&#32447;&#29256;&#26412;&#65292;&#21487;&#20197;&#26080;&#32541;&#38598;&#25104;&#21040;SGMM&#26694;&#26550;&#20013;&#12290;&#24191;&#27867;&#30340;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#32467;&#26524;&#34920;&#26126;&#65292;&#38543;&#30528;&#26679;&#26412;&#37327;&#30340;&#22686;&#21152;&#65292;SGMM&#22312;&#20272;&#35745;&#20934;&#30830;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#26041;&#38754;&#19982;&#26631;&#20934;&#65288;&#31163;&#32447;&#65289;GMM&#30456;&#21305;&#37197;&#65292;&#24182;&#26174;&#31034;&#20986;&#22312;&#22823;&#35268;&#27169;&#21644;&#22312;&#32447;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#38469;&#20215;&#20540;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#20004;&#20010;&#31034;&#20363;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new class of algorithms, Stochastic Generalized Method of Moments (SGMM), for estimation and inference on (overidentified) moment restriction models. Our SGMM is a novel stochastic approximation alternative to the popular Hansen (1982) (offline) GMM, and offers fast and scalable implementation with the ability to handle streaming datasets in real time. We establish the almost sure convergence, and the (functional) central limit theorem for the inefficient online 2SLS and the efficient SGMM. Moreover, we propose online versions of the Durbin-Wu-Hausman and Sargan-Hansen tests that can be seamlessly integrated within the SGMM framework. Extensive Monte Carlo simulations show that as the sample size increases, the SGMM matches the standard (offline) GMM in terms of estimation accuracy and gains over computational efficiency, indicating its practical value for both large-scale and online datasets. We demonstrate the efficacy of our approach by a proof of concept using two we
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#20449;&#29992;&#20998;&#37197;&#31639;&#27861;&#65292;&#36890;&#36807;&#37327;&#21270;&#21453;&#20107;&#23454;&#26597;&#35810;&#26469;&#27979;&#37327;&#21160;&#20316;&#23545;&#26410;&#26469;&#22870;&#21169;&#30340;&#24433;&#21709;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#36890;&#36807;&#27979;&#37327;&#23545;&#22870;&#21169;&#25110;&#22870;&#21169;&#23545;&#35937;&#34920;&#31034;&#30340;&#36129;&#29486;&#65292;&#33719;&#24471;&#20102;&#20855;&#26377;&#26356;&#20302;&#26041;&#24046;&#30340;&#26799;&#24230;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2306.16803</link><description>&lt;p&gt;
&#38271;&#26399;&#20449;&#29992;&#24402;&#22240;&#36890;&#36807;&#21453;&#20107;&#23454;&#36129;&#29486;&#20998;&#26512;&#30340;&#26041;&#24335;
&lt;/p&gt;
&lt;p&gt;
Would I have gotten that reward? Long-term credit assignment by counterfactual contribution analysis. (arXiv:2306.16803v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16803
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#20449;&#29992;&#20998;&#37197;&#31639;&#27861;&#65292;&#36890;&#36807;&#37327;&#21270;&#21453;&#20107;&#23454;&#26597;&#35810;&#26469;&#27979;&#37327;&#21160;&#20316;&#23545;&#26410;&#26469;&#22870;&#21169;&#30340;&#24433;&#21709;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#36890;&#36807;&#27979;&#37327;&#23545;&#22870;&#21169;&#25110;&#22870;&#21169;&#23545;&#35937;&#34920;&#31034;&#30340;&#36129;&#29486;&#65292;&#33719;&#24471;&#20102;&#20855;&#26377;&#26356;&#20302;&#26041;&#24046;&#30340;&#26799;&#24230;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#20351;&#24378;&#21270;&#23398;&#20064;&#26356;&#21152;&#26679;&#26412;&#39640;&#25928;&#65292;&#25105;&#20204;&#38656;&#35201;&#26356;&#22909;&#30340;&#20449;&#29992;&#24402;&#22240;&#26041;&#27861;&#26469;&#34913;&#37327;&#21160;&#20316;&#23545;&#26410;&#26469;&#22870;&#21169;&#30340;&#24433;&#21709;&#12290;&#22312;&#24724;&#26827;&#20449;&#29992;&#24402;&#22240;&#65288;HCA&#65289;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#21453;&#20107;&#23454;&#36129;&#29486;&#20998;&#26512;&#65288;COCOA&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#20449;&#29992;&#24402;&#22240;&#31639;&#27861;&#31995;&#21015;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#36890;&#36807;&#37327;&#21270;&#19968;&#20010;&#21453;&#20107;&#23454;&#26597;&#35810;&#26469;&#23454;&#29616;&#31934;&#30830;&#30340;&#20449;&#29992;&#20998;&#37197;&#65306;&#8220;&#22914;&#26524;&#20195;&#29702;&#36873;&#25321;&#21478;&#19968;&#20010;&#21160;&#20316;&#65292;&#23427;&#20173;&#28982;&#20250;&#33719;&#24471;&#36825;&#20010;&#22870;&#21169;&#21527;&#65311;&#8221;&#36890;&#36807;&#27979;&#37327;&#21160;&#20316;&#23545;&#33719;&#24471;&#21518;&#32493;&#22870;&#21169;&#30340;&#36129;&#29486;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23545;&#20110;&#22870;&#21169;&#29366;&#24577;&#27979;&#37327;&#36129;&#29486;&#65288;&#21363;HCA&#20013;&#25152;&#20570;&#30340;&#65289;&#20250;&#23548;&#33268;&#36129;&#29486;&#30340;&#38169;&#35823;&#20272;&#35745;&#65292;&#20351;&#24471;HCA&#22312;&#35768;&#22810;&#30456;&#20851;&#29615;&#22659;&#20013;&#21521;&#39640;&#26041;&#24046;&#30340;REINFORCE&#20272;&#35745;&#22120;&#36864;&#21270;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#36890;&#36807;&#27979;&#37327;&#23545;&#22870;&#21169;&#25110;&#25152;&#23398;&#20064;&#30340;&#22870;&#21169;&#23545;&#35937;&#30340;&#34920;&#31034;&#30340;&#36129;&#29486;&#65292;&#24471;&#21040;&#20855;&#26377;&#26356;&#20302;&#26041;&#24046;&#30340;&#26799;&#24230;&#20272;&#35745;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#29305;&#23450;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;
&lt;/p&gt;
&lt;p&gt;
To make reinforcement learning more sample efficient, we need better credit assignment methods that measure an action's influence on future rewards. Building upon Hindsight Credit Assignment (HCA), we introduce Counterfactual Contribution Analysis (COCOA), a new family of model-based credit assignment algorithms. Our algorithms achieve precise credit assignment by measuring the contribution of actions upon obtaining subsequent rewards, by quantifying a counterfactual query: "Would the agent still have reached this reward if it had taken another action?". We show that measuring contributions w.r.t. rewarding states, as is done in HCA, results in spurious estimates of contributions, causing HCA to degrade towards the high-variance REINFORCE estimator in many relevant environments. Instead, we measure contributions w.r.t. rewards or learned representations of the rewarding objects, resulting in gradient estimates with lower variance. We run experiments on a suite of problems specifically 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#35780;&#20998;&#30340;&#25968;&#25454;&#21516;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#29366;&#24577;&#36712;&#36857;&#27169;&#22411;&#30340;&#35757;&#32451;&#65292;&#23454;&#29616;&#20102;&#26080;&#38656;&#20381;&#36182;&#20256;&#32479;&#25512;&#26029;&#26041;&#27861;&#21644;&#28385;&#36275;&#39640;&#32500;&#31995;&#32479;&#19982;&#38271;&#26102;&#38388;&#36328;&#24230;&#19979;&#36827;&#34892;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2306.10574</link><description>&lt;p&gt;
&#22522;&#20110;&#35780;&#20998;&#30340;&#25968;&#25454;&#21516;&#21270;
&lt;/p&gt;
&lt;p&gt;
Score-based Data Assimilation. (arXiv:2306.10574v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10574
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#35780;&#20998;&#30340;&#25968;&#25454;&#21516;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#29366;&#24577;&#36712;&#36857;&#27169;&#22411;&#30340;&#35757;&#32451;&#65292;&#23454;&#29616;&#20102;&#26080;&#38656;&#20381;&#36182;&#20256;&#32479;&#25512;&#26029;&#26041;&#27861;&#21644;&#28385;&#36275;&#39640;&#32500;&#31995;&#32479;&#19982;&#38271;&#26102;&#38388;&#36328;&#24230;&#19979;&#36827;&#34892;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26368;&#20840;&#38754;&#30340;&#24418;&#24335;&#19979;&#65292;&#25968;&#25454;&#21516;&#21270;&#35299;&#20915;&#20102;&#37492;&#23450;&#38543;&#26426;&#21160;&#24577;&#31995;&#32479;&#20013;&#30340;&#21487;&#33021;&#29366;&#24577;&#36712;&#36857;&#30340;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#65292;&#20174;&#32780;&#35299;&#37322;&#23613;&#31649;&#23384;&#22312;&#22122;&#22768;&#25110;&#19981;&#23436;&#25972;&#35266;&#27979;&#30340;&#20869;&#23481;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#21253;&#25324;&#22522;&#20110;&#31890;&#23376;&#30340;&#21644;&#21487;&#21464;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#31639;&#27861;&#20381;&#36182;&#20110;&#36716;&#31227;&#21160;&#24577;&#36827;&#34892;&#25512;&#26029;&#65292;&#36825;&#22312;&#38271;&#26102;&#38388;&#36328;&#24230;&#25110;&#20855;&#26377;&#22797;&#26434;&#21160;&#24577;&#30340;&#39640;&#32500;&#31995;&#32479;&#20013;&#21464;&#24471;&#26840;&#25163;&#65292;&#22914;&#28023;&#27915;&#25110;&#22823;&#27668;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#35780;&#20998;&#30340;&#25968;&#25454;&#21516;&#21270;&#26469;&#23454;&#29616;&#36712;&#36857;&#25512;&#26029;&#12290;&#25105;&#20204;&#23398;&#20064;&#20102;&#22522;&#20110;&#35780;&#20998;&#30340;&#29983;&#25104;&#29366;&#24577;&#36712;&#36857;&#27169;&#22411;&#65292;&#36825;&#26159;&#22522;&#20110;&#19968;&#20010;&#20851;&#38190;&#27934;&#23519;&#65292;&#21363;&#20219;&#24847;&#38271;&#36712;&#36857;&#30340;&#24471;&#20998;&#21487;&#20197;&#20998;&#35299;&#20026;&#30701;&#37096;&#20998;&#30340;&#24471;&#20998;&#31995;&#21015;&#12290;&#22312;&#35757;&#32451;&#23436;&#25104;&#21518;&#65292;&#36816;&#29992;&#24471;&#20998;&#27169;&#22411;&#36827;&#34892;&#26080;&#33258;&#22238;&#24402;&#30340;&#25512;&#26029;&#65292;&#36890;&#36807;&#21516;&#26102;&#29983;&#25104;&#25152;&#26377;&#29366;&#24577;&#12290;&#19982;&#20247;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#35299;&#32806;&#20102;&#35266;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data assimilation, in its most comprehensive form, addresses the Bayesian inverse problem of identifying plausible state trajectories that explain noisy or incomplete observations of stochastic dynamical systems. Various approaches have been proposed to solve this problem, including particle-based and variational methods. However, most algorithms depend on the transition dynamics for inference, which becomes intractable for long time horizons or for high-dimensional systems with complex dynamics, such as oceans or atmospheres. In this work, we introduce score-based data assimilation for trajectory inference. We learn a score-based generative model of state trajectories based on the key insight that the score of an arbitrarily long trajectory can be decomposed into a series of scores over short segments. After training, inference is carried out using the score model, in a non-autoregressive manner by generating all states simultaneously. Quite distinctively, we decouple the observation 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31283;&#23450;&#31070;&#32463;&#24494;&#20998;&#26041;&#31243;&#65288;SNDEs&#65289;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24378;&#21046;&#20351;&#29992;&#20219;&#24847;&#27969;&#24418;&#32422;&#26463;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#28155;&#21152;&#31283;&#23450;&#39033;&#20351;&#32422;&#26463;&#27969;&#24418;&#25104;&#20026;&#28176;&#36827;&#31283;&#23450;&#30340;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.09739</link><description>&lt;p&gt;
&#23398;&#20064;&#21463;&#38480;&#21160;&#21147;&#23398;&#30340;&#31283;&#23450;&#31070;&#32463;&#24494;&#20998;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
Stabilized Neural Differential Equations for Learning Constrained Dynamics. (arXiv:2306.09739v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09739
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31283;&#23450;&#31070;&#32463;&#24494;&#20998;&#26041;&#31243;&#65288;SNDEs&#65289;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24378;&#21046;&#20351;&#29992;&#20219;&#24847;&#27969;&#24418;&#32422;&#26463;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#28155;&#21152;&#31283;&#23450;&#39033;&#20351;&#32422;&#26463;&#27969;&#24418;&#25104;&#20026;&#28176;&#36827;&#31283;&#23450;&#30340;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20986;&#29616;&#20102;&#35768;&#22810;&#25104;&#21151;&#30340;&#20174;&#25968;&#25454;&#23398;&#20064;&#21160;&#24577;&#31995;&#32479;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#30830;&#20445;&#25512;&#26029;&#20986;&#30340;&#21160;&#24577;&#31995;&#32479;&#20445;&#30041;&#24050;&#30693;&#32422;&#26463;&#26465;&#20214;&#65288;&#20363;&#22914;&#23432;&#24658;&#23450;&#24459;&#25110;&#23545;&#20801;&#35768;&#30340;&#31995;&#32479;&#29366;&#24577;&#30340;&#38480;&#21046;&#65289;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#31283;&#23450;&#31070;&#32463;&#24494;&#20998;&#26041;&#31243;&#65288;SNDEs&#65289;&#30340;&#26041;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#31070;&#32463;&#24494;&#20998;&#26041;&#31243;&#24378;&#21046;&#20351;&#29992;&#20219;&#24847;&#27969;&#24418;&#32422;&#26463;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#19968;&#20010;&#31283;&#23450;&#39033;&#65292;&#24403;&#28155;&#21152;&#21040;&#21407;&#22987;&#21160;&#24577;&#31995;&#32479;&#20013;&#26102;&#65292;&#21487;&#20197;&#23558;&#32422;&#26463;&#27969;&#24418;&#25104;&#20026;&#28176;&#36827;&#31283;&#23450;&#30340;&#12290;&#30001;&#20110;&#20854;&#31616;&#21333;&#24615;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#25152;&#26377;&#24120;&#35265;&#30340;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;NODE&#65289;&#27169;&#22411;&#20860;&#23481;&#24182;&#24191;&#27867;&#36866;&#29992;&#12290;&#22312;&#24191;&#27867;&#30340;&#32463;&#39564;&#35780;&#20272;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;SNDE&#22312;&#25193;&#23637;&#21487;&#32435;&#20837;NODE&#35757;&#32451;&#30340;&#32422;&#26463;&#31867;&#22411;&#26041;&#38754;&#32988;&#36807;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many successful methods to learn dynamical systems from data have recently been introduced. However, assuring that the inferred dynamics preserve known constraints, such as conservation laws or restrictions on the allowed system states, remains challenging. We propose stabilized neural differential equations (SNDEs), a method to enforce arbitrary manifold constraints for neural differential equations. Our approach is based on a stabilization term that, when added to the original dynamics, renders the constraint manifold provably asymptotically stable. Due to its simplicity, our method is compatible with all common neural ordinary differential equation (NODE) models and broadly applicable. In extensive empirical evaluations, we demonstrate that SNDEs outperform existing methods while extending the scope of which types of constraints can be incorporated into NODE training.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#35266;&#27979;&#21464;&#37327;&#30001;&#22240;&#26524;&#30456;&#20851;&#30340;&#28508;&#21464;&#37327;&#29983;&#25104;&#30340;&#38750;&#32447;&#24615;&#28508;&#21464;&#37327;&#23618;&#27425;&#22240;&#26524;&#27169;&#22411;&#20013;&#23454;&#29616;&#22240;&#26524;&#32467;&#26500;&#21644;&#28508;&#21464;&#37327;&#30340;&#21487;&#35782;&#21035;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.07916</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#28508;&#21464;&#37327;&#23618;&#27425;&#27169;&#22411;&#30340;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Identification of Nonlinear Latent Hierarchical Models. (arXiv:2306.07916v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07916
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#35266;&#27979;&#21464;&#37327;&#30001;&#22240;&#26524;&#30456;&#20851;&#30340;&#28508;&#21464;&#37327;&#29983;&#25104;&#30340;&#38750;&#32447;&#24615;&#28508;&#21464;&#37327;&#23618;&#27425;&#22240;&#26524;&#27169;&#22411;&#20013;&#23454;&#29616;&#22240;&#26524;&#32467;&#26500;&#21644;&#28508;&#21464;&#37327;&#30340;&#21487;&#35782;&#21035;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#35782;&#21035;&#28508;&#21464;&#37327;&#21644;&#22240;&#26524;&#32467;&#26500;&#23545;&#20110;&#35768;&#22810;&#28041;&#21450;&#29983;&#29289;&#25968;&#25454;&#12289;&#21307;&#23398;&#25968;&#25454;&#21644;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#65288;&#22914;&#22270;&#20687;&#21644;&#35821;&#35328;&#65289;&#30340;&#23454;&#38469;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#24403;&#35266;&#27979;&#21464;&#37327;&#30001;&#22240;&#26524;&#30456;&#20851;&#30340;&#28508;&#21464;&#37327;&#29983;&#25104;&#65292;&#24182;&#19988;&#20851;&#31995;&#26159;&#38750;&#32447;&#24615;&#30340;&#26102;&#65292;&#36825;&#39033;&#20219;&#21153;&#21487;&#33021;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38750;&#32447;&#24615;&#28508;&#21464;&#37327;&#23618;&#27425;&#22240;&#26524;&#27169;&#22411;&#30340;&#35782;&#21035;&#38382;&#39064;&#65292;&#22312;&#36825;&#31181;&#27169;&#22411;&#20013;&#65292;&#35266;&#27979;&#21464;&#37327;&#30001;&#19968;&#32452;&#22240;&#26524;&#30456;&#20851;&#30340;&#28508;&#21464;&#37327;&#29983;&#25104;&#65292;&#26377;&#20123;&#28508;&#21464;&#37327;&#21487;&#33021;&#27809;&#26377;&#35266;&#23519;&#21040;&#30340;&#21518;&#20195;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#21487;&#20197;&#23454;&#29616;&#22240;&#26524;&#32467;&#26500;&#21644;&#28508;&#21464;&#37327;&#30340;&#21487;&#35782;&#21035;&#24615;&#65306;&#23545;&#20110;&#22240;&#26524;&#32467;&#26500;&#65292;&#25105;&#20204;&#20801;&#35768;&#22270;&#20013;&#20219;&#24847;&#20004;&#20010;&#21464;&#37327;&#20043;&#38388;&#23384;&#22312;&#22810;&#26465;&#36335;&#24452;&#65292;&#36825;&#25918;&#23485;&#20102;&#20808;&#21069;&#24037;&#20316;&#20013;&#30340;&#28508;&#21464;&#37327;&#26641;&#20551;&#35774;&#65307;&#23545;&#20110;&#32467;&#26500;&#20989;&#25968;&#65292;&#25105;&#20204;&#27809;&#26377;&#36827;&#34892;&#21442;&#25968;&#20551;&#35774;&#65292;&#22240;&#27492;&#21487;&#20197;&#20801;&#35768;&#22522;&#22240;
&lt;/p&gt;
&lt;p&gt;
Identifying latent variables and causal structures from observational data is essential to many real-world applications involving biological data, medical data, and unstructured data such as images and languages. However, this task can be highly challenging, especially when observed variables are generated by causally related latent variables and the relationships are nonlinear. In this work, we investigate the identification problem for nonlinear latent hierarchical causal models in which observed variables are generated by a set of causally related latent variables, and some latent variables may not have observed children. We show that the identifiability of both causal structure and latent variables can be achieved under mild assumptions: on causal structures, we allow for the existence of multiple paths between any pair of variables in the graph, which relaxes latent tree assumptions in prior work; on structural functions, we do not make parametric assumptions, thus permitting gene
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Removal-Based&#29305;&#24449;&#24402;&#22240;&#30340;&#40065;&#26834;&#24615;&#65292;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#29702;&#35770;&#21644;&#23454;&#39564;&#20998;&#26512;&#65292;&#24182;&#35777;&#26126;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#23454;&#38469;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.07462</link><description>&lt;p&gt;
&#20851;&#20110;Removal-Based&#29305;&#24449;&#24402;&#22240;&#30340;&#40065;&#26834;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Robustness of Removal-Based Feature Attributions. (arXiv:2306.07462v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07462
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Removal-Based&#29305;&#24449;&#24402;&#22240;&#30340;&#40065;&#26834;&#24615;&#65292;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#29702;&#35770;&#21644;&#23454;&#39564;&#20998;&#26512;&#65292;&#24182;&#35777;&#26126;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#23454;&#38469;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#35299;&#37322;&#22522;&#20110;&#36755;&#20837;&#30340;&#22797;&#26434;&#27169;&#22411;&#65292;&#24320;&#21457;&#20102;&#35768;&#22810;&#29305;&#24449;&#24402;&#22240;&#26041;&#27861;&#26469;&#20998;&#37197;&#36755;&#20837;&#29305;&#24449;&#30340;&#37325;&#35201;&#24615;&#20998;&#25968;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#19968;&#20123;&#30740;&#31350;&#25361;&#25112;&#20102;&#29305;&#24449;&#24402;&#22240;&#30340;&#40065;&#26834;&#24615;&#65292;&#25351;&#20986;&#36825;&#20123;&#26041;&#27861;&#23545;&#36755;&#20837;&#21644;&#27169;&#22411;&#25200;&#21160;&#25935;&#24863;&#65292;&#32780;&#20854;&#20182;&#30740;&#31350;&#36890;&#36807;&#25552;&#20986;&#40065;&#26834;&#24402;&#22240;&#26041;&#27861;&#21644;&#27169;&#22411;&#20462;&#25913;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#20197;&#24448;&#30340;&#24402;&#22240;&#40065;&#26834;&#24615;&#30740;&#31350;&#20027;&#35201;&#20391;&#37325;&#20110;&#22522;&#20110;&#26799;&#24230;&#30340;&#29305;&#24449;&#24402;&#22240;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;Removal-Based&#24402;&#22240;&#26041;&#27861;&#30340;&#40065;&#26834;&#24615;&#36136;&#23578;&#26410;&#20840;&#38754;&#22320;&#24471;&#21040;&#29702;&#35299;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#23545;Removal-Based&#29305;&#24449;&#24402;&#22240;&#30340;&#40065;&#26834;&#24615;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#38416;&#36848;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23545;&#36825;&#31181;&#26041;&#27861;&#36827;&#34892;&#20102;&#32479;&#19968;&#30340;&#20998;&#26512;&#65292;&#24182;&#22312;&#36755;&#20837;&#21644;&#27169;&#22411;&#25200;&#21160;&#30340;&#24773;&#20917;&#19979;&#35777;&#26126;&#20102;&#23436;&#22909;&#21644;&#21463;&#25200;&#21160;&#30340;&#24402;&#22240;&#20043;&#38388;&#30340;&#24046;&#24322;&#30340;&#19978;&#38480;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#24182;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#23454;&#38469;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
To explain complex models based on their inputs, many feature attribution methods have been developed that assign importance scores to input features. However, some recent work challenges the robustness of feature attributions by showing that these methods are sensitive to input and model perturbations, while other work addresses this robustness issue by proposing robust attribution methods and model modifications. Nevertheless, previous work on attribution robustness has focused primarily on gradient-based feature attributions. In contrast, the robustness properties of removal-based attribution methods are not comprehensively well understood. To bridge this gap, we theoretically characterize the robustness of removal-based feature attributions. Specifically, we provide a unified analysis of such methods and prove upper bounds for the difference between intact and perturbed attributions, under settings of both input and model perturbations. Our empirical experiments on synthetic and re
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#30340;&#21464;&#20998;&#19981;&#24179;&#34913;&#22238;&#24402;&#65288;VIR&#65289;&#27169;&#22411;&#36890;&#36807;&#24341;&#20837;Probabilistic Reweighting&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#24179;&#34913;&#22238;&#24402;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#33258;&#28982;&#20135;&#29983;&#21512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2306.06599</link><description>&lt;p&gt;
&#21464;&#20998;&#19981;&#24179;&#34913;&#22238;&#24402;(Variational Imbalanced Regression)
&lt;/p&gt;
&lt;p&gt;
Variational Imbalanced Regression. (arXiv:2306.06599v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06599
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#30340;&#21464;&#20998;&#19981;&#24179;&#34913;&#22238;&#24402;&#65288;VIR&#65289;&#27169;&#22411;&#36890;&#36807;&#24341;&#20837;Probabilistic Reweighting&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#24179;&#34913;&#22238;&#24402;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#33258;&#28982;&#20135;&#29983;&#21512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#26631;&#31614;&#20998;&#24067;&#19981;&#24179;&#34913;&#26102;&#65292;&#29616;&#26377;&#30340;&#22238;&#24402;&#27169;&#22411;&#24448;&#24448;&#22312;&#20934;&#30830;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26041;&#38754;&#34920;&#29616;&#19981;&#20339;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#29575;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#8212;&#8212;&#21464;&#20998;&#19981;&#24179;&#34913;&#22238;&#24402;&#65288;VIR&#65289;&#65292;&#23427;&#19981;&#20165;&#22312;&#19981;&#24179;&#34913;&#22238;&#24402;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#32780;&#19988;&#33258;&#28982;&#22320;&#20135;&#29983;&#21512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#19982;&#20856;&#22411;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#20551;&#35774;I.I.D.&#34920;&#31034;&#65288;&#25968;&#25454;&#28857;&#30340;&#34920;&#31034;&#19981;&#30452;&#25509;&#21463;&#20854;&#20182;&#25968;&#25454;&#28857;&#30340;&#24433;&#21709;&#65289;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;VIR&#20511;&#29992;&#20855;&#26377;&#31867;&#20284;&#22238;&#24402;&#26631;&#31614;&#30340;&#25968;&#25454;&#26469;&#35745;&#31639;&#28508;&#22312;&#34920;&#31034;&#30340;&#21464;&#20998;&#20998;&#24067;&#65307;&#27492;&#22806;&#65292;&#19981;&#21516;&#20110;&#20135;&#29983;&#28857;&#20272;&#35745;&#30340;&#30830;&#23450;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292; VIR&#39044;&#27979;&#25972;&#20010;&#27491;&#24577;&#21453;-&#20285;&#29595;&#20998;&#24067;&#24182;&#35843;&#33410;&#30456;&#20851;&#32852;&#30340;&#20849;&#36717;&#20998;&#24067;&#65292;&#23545;&#19981;&#24179;&#34913;&#25968;&#25454;&#26045;&#21152;&#27010;&#29575;&#37325;&#26032;&#21152;&#26435;&#65292;&#20174;&#32780;&#25552;&#20379;&#26356;&#22909;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#22312;&#20960;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing regression models tend to fall short in both accuracy and uncertainty estimation when the label distribution is imbalanced. In this paper, we propose a probabilistic deep learning model, dubbed variational imbalanced regression (VIR), which not only performs well in imbalanced regression but naturally produces reasonable uncertainty estimation as a byproduct. Different from typical variational autoencoders assuming I.I.D. representations (a data point's representation is not directly affected by other data points), our VIR borrows data with similar regression labels to compute the latent representation's variational distribution; furthermore, different from deterministic regression models producing point estimates, VIR predicts the entire normal-inverse-gamma distributions and modulates the associated conjugate distributions to impose probabilistic reweighting on the imbalanced data, thereby providing better uncertainty estimation. Experiments in several real-world datasets sh
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DP-RandP&#30340;&#26041;&#27861;&#65292;&#20174;&#38543;&#26426;&#36807;&#31243;&#20013;&#23398;&#20064;&#20808;&#39564;&#30693;&#35782;&#65292;&#24182;&#23558;&#20854;&#20256;&#36882;&#32473;&#31169;&#26377;&#25968;&#25454;&#65292;&#20197;&#25913;&#36827;&#24046;&#20998;&#38544;&#31169;&#30340;&#22270;&#20687;&#20998;&#31867;&#65292;&#23454;&#29616;&#20102;&#26032;&#30340;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#25552;&#39640;&#20102;CIFAR-10&#30340;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.06076</link><description>&lt;p&gt;
&#20174;&#38543;&#26426;&#36807;&#31243;&#20013;&#23398;&#20064;&#20808;&#39564;&#30693;&#35782;&#30340;&#24046;&#20998;&#38544;&#31169;&#22270;&#20687;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Image Classification by Learning Priors from Random Processes. (arXiv:2306.06076v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06076
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DP-RandP&#30340;&#26041;&#27861;&#65292;&#20174;&#38543;&#26426;&#36807;&#31243;&#20013;&#23398;&#20064;&#20808;&#39564;&#30693;&#35782;&#65292;&#24182;&#23558;&#20854;&#20256;&#36882;&#32473;&#31169;&#26377;&#25968;&#25454;&#65292;&#20197;&#25913;&#36827;&#24046;&#20998;&#38544;&#31169;&#30340;&#22270;&#20687;&#20998;&#31867;&#65292;&#23454;&#29616;&#20102;&#26032;&#30340;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#25552;&#39640;&#20102;CIFAR-10&#30340;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#38544;&#31169;&#20445;&#25252;&#30340;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#19981;&#21516;ially&#31169;&#26377;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;DP-SGD&#65289;&#30001;&#20110;&#27599;&#20010;&#26679;&#26412;&#26799;&#24230;&#21098;&#36753;&#21644;&#22122;&#22768;&#28155;&#21152;&#32780;&#34920;&#29616;&#19981;&#20339;&#12290;&#38544;&#31169;&#23398;&#20064;&#30740;&#31350;&#30340;&#19968;&#20010;&#26368;&#36817;&#37325;&#28857;&#26159;&#36890;&#36807;&#23558;&#22312;&#30495;&#23454;&#19990;&#30028;&#20844;&#20849;&#25968;&#25454;&#19978;&#23398;&#20064;&#30340;&#20808;&#39564;&#30693;&#35782;&#32435;&#20837;&#36825;&#20123;&#25968;&#25454;&#65292;&#20174;&#32780;&#25552;&#39640;DP-SGD&#22312;&#31169;&#26377;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#22914;&#20309;&#36890;&#36807;&#20174;&#30001;&#38543;&#26426;&#36807;&#31243;&#29983;&#25104;&#30340;&#22270;&#20687;&#20013;&#23398;&#20064;&#20808;&#39564;&#30693;&#35782;&#24182;&#23558;&#36825;&#20123;&#20808;&#39564;&#30693;&#35782;&#36716;&#31227;&#21040;&#31169;&#26377;&#25968;&#25454;&#26469;&#25913;&#36827;DP-SGD&#30340;&#38544;&#31169;-&#25928;&#29992;&#25240;&#34935;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;DP-RandP&#65292;&#36825;&#26159;&#19968;&#20010;&#19977;&#38454;&#27573;&#30340;&#26041;&#27861;&#12290;&#22312;CIFAR10&#12289;CIFAR100&#21644;MedMNIST&#19978;&#20174;&#22836;&#24320;&#22987;&#35757;&#32451;&#26102;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#26032;&#30340;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#24182;&#36866;&#29992;&#20110;&#19968;&#31995;&#21015;&#38544;&#31169;&#39044;&#31639;&#949;&#8712;[1&#65292;8]&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23558;&#22312;&#949;=1&#26102;&#22312;CIFAR10&#19978;&#25253;&#21578;&#30340;&#26368;&#20339;&#20934;&#30830;&#24615;&#20174;60.6%&#25552;&#39640;&#21040;72.3%&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#21487;&#22312;https://github.com/inspire-group/DP-RandP&#19978;&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
In privacy-preserving machine learning, differentially private stochastic gradient descent (DP-SGD) performs worse than SGD due to per-sample gradient clipping and noise addition. A recent focus in private learning research is improving the performance of DP-SGD on private data by incorporating priors that are learned on real-world public data. In this work, we explore how we can improve the privacy-utility tradeoff of DP-SGD by learning priors from images generated by random processes and transferring these priors to private data. We propose DP-RandP, a three-phase approach. We attain new state-of-the-art accuracy when training from scratch on CIFAR10, CIFAR100, and MedMNIST for a range of privacy budgets $\varepsilon \in [1, 8]$. In particular, we improve the previous best reported accuracy on CIFAR10 from $60.6 \%$ to $72.3 \%$ for $\varepsilon=1$. Our code is available at https://github.com/inspire-group/DP-RandP.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;Shapley&#20540;&#35299;&#37322;&#19981;&#30830;&#23450;&#24615;&#39044;&#27979;&#65292;&#21487;&#20197;&#37327;&#21270;&#27599;&#20010;&#29305;&#24449;&#23545;&#20010;&#21035;&#27169;&#22411;&#36755;&#20986;&#26465;&#20214;&#29109;&#30340;&#36129;&#29486;&#65292;&#36866;&#29992;&#20110;&#21327;&#21464;&#37327;&#36716;&#31227;&#26816;&#27979;&#12289;&#20027;&#21160;&#23398;&#20064;&#12289;&#29305;&#24449;&#36873;&#25321;&#21644;&#27963;&#21160;&#29305;&#24449;&#20215;&#20540;&#35780;&#20272;&#31561;&#26041;&#38754;&#12290;</title><link>http://arxiv.org/abs/2306.05724</link><description>&lt;p&gt;
&#29992;&#20449;&#24687;&#29702;&#35770;&#30340;Shapley&#20540;&#35299;&#37322;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Explaining Predictive Uncertainty with Information Theoretic Shapley Values. (arXiv:2306.05724v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05724
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;Shapley&#20540;&#35299;&#37322;&#19981;&#30830;&#23450;&#24615;&#39044;&#27979;&#65292;&#21487;&#20197;&#37327;&#21270;&#27599;&#20010;&#29305;&#24449;&#23545;&#20010;&#21035;&#27169;&#22411;&#36755;&#20986;&#26465;&#20214;&#29109;&#30340;&#36129;&#29486;&#65292;&#36866;&#29992;&#20110;&#21327;&#21464;&#37327;&#36716;&#31227;&#26816;&#27979;&#12289;&#20027;&#21160;&#23398;&#20064;&#12289;&#29305;&#24449;&#36873;&#25321;&#21644;&#27963;&#21160;&#29305;&#24449;&#20215;&#20540;&#35780;&#20272;&#31561;&#26041;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#20154;&#21592;&#24320;&#21457;&#20102;&#22823;&#37327;&#26041;&#27861;&#26469;&#24110;&#21161;&#29992;&#25143;&#29702;&#35299;&#22797;&#26434;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#35299;&#37322;&#27169;&#22411;&#36755;&#20986;&#30340;$\textit{&#19981;&#30830;&#23450;&#24615;}$&#21364;&#21463;&#21040;&#20102;&#30456;&#23545;&#36739;&#23569;&#30340;&#20851;&#27880;&#12290;&#25105;&#20204;&#23558;&#24191;&#27867;&#20351;&#29992;&#30340;Shapley&#20540;&#26694;&#26550;&#29992;&#20110;&#35299;&#37322;&#21508;&#31181;&#31867;&#22411;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#65292;&#37327;&#21270;&#27599;&#20010;&#29305;&#24449;&#23545;&#20010;&#21035;&#27169;&#22411;&#36755;&#20986;&#26465;&#20214;&#29109;&#30340;&#36129;&#29486;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#20462;&#25913;&#29305;&#24449;&#20989;&#25968;&#30340;&#21338;&#24328;&#65292;&#24182;&#21457;&#29616;&#20102;&#30001;&#27492;&#20135;&#29983;&#30340;Shapley&#20540;&#19982;&#20449;&#24687;&#35770;&#21644;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#20013;&#30340;&#22522;&#26412;&#37327;&#20043;&#38388;&#30340;&#28145;&#21051;&#32852;&#31995;&#12290;&#25105;&#20204;&#27010;&#36848;&#20102;&#26377;&#35777;&#26126;&#20445;&#35777;&#30340;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#29575;&#25511;&#21046;&#30340;&#25512;&#29702;&#36807;&#31243;&#65292;&#24182;&#23454;&#29616;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#22312;&#30495;&#23454;&#21644;&#27169;&#25311;&#25968;&#25454;&#30340;&#19968;&#31995;&#21015;&#23454;&#39564;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36866;&#29992;&#20110;&#21327;&#21464;&#37327;&#36716;&#31227;&#26816;&#27979;&#12289;&#20027;&#21160;&#23398;&#20064;&#12289;&#29305;&#24449;&#36873;&#25321;&#21644;&#27963;&#21160;&#29305;&#24449;&#20215;&#20540;&#35780;&#20272;&#31561;&#26041;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;
Researchers in explainable artificial intelligence have developed numerous methods for helping users understand the predictions of complex supervised learning models. By contrast, explaining the $\textit{uncertainty}$ of model outputs has received relatively little attention. We adapt the popular Shapley value framework to explain various types of predictive uncertainty, quantifying each feature's contribution to the conditional entropy of individual model outputs. We consider games with modified characteristic functions and find deep connections between the resulting Shapley values and fundamental quantities from information theory and conditional independence testing. We outline inference procedures for finite sample error rate control with provable guarantees, and implement an efficient algorithm that performs well in a range of experiments on real and simulated data. Our method has applications to covariate shift detection, active learning, feature selection, and active feature-val
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#39318;&#27425;&#30740;&#31350;&#20102;&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#23398;&#20064;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;Reg-Graph&#27169;&#22411;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;AMP&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#22312;&#23454;&#39564;&#20013;&#20248;&#20110;&#29616;&#26377;&#30340;&#20960;&#31181;&#32593;&#32476;&#36741;&#21161;&#22238;&#24402;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.05679</link><description>&lt;p&gt;
&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Bayes optimal learning in high-dimensional linear regression with network side information. (arXiv:2306.05679v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05679
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#30740;&#31350;&#20102;&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#23398;&#20064;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;Reg-Graph&#27169;&#22411;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;AMP&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#22312;&#23454;&#39564;&#20013;&#20248;&#20110;&#29616;&#26377;&#30340;&#20960;&#31181;&#32593;&#32476;&#36741;&#21161;&#22238;&#24402;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#22240;&#32452;&#23398;&#12289;&#34507;&#30333;&#36136;&#32452;&#23398;&#21644;&#31070;&#32463;&#31185;&#23398;&#31561;&#24212;&#29992;&#20013;&#65292;&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#30417;&#30563;&#23398;&#20064;&#38382;&#39064;&#32463;&#24120;&#20986;&#29616;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#30740;&#31350;&#20102;&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#23398;&#20064;&#38382;&#39064;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#39318;&#20808;&#24341;&#20837;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;&#31216;&#20026;Reg-Graph&#27169;&#22411;&#65289;&#65292;&#36890;&#36807;&#19968;&#32452;&#20849;&#21516;&#30340;&#28508;&#22312;&#21442;&#25968;&#20026;&#30417;&#30563;&#25968;&#25454;&#21644;&#35266;&#27979;&#21040;&#30340;&#32593;&#32476;&#35774;&#23450;&#20102;&#19968;&#20010;&#32852;&#21512;&#20998;&#24067;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#36817;&#20284;&#28040;&#24687;&#20256;&#36882;&#65288;AMP&#65289;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#22312;&#38750;&#24120;&#19968;&#33324;&#30340;&#26465;&#20214;&#19979;&#21487;&#35777;&#26126;&#26159;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#28508;&#22312;&#20449;&#21495;&#21644;&#35266;&#27979;&#21040;&#30340;&#25968;&#25454;&#20043;&#38388;&#30340;&#26497;&#38480;&#20114;&#20449;&#24687;&#36827;&#34892;&#20102;&#34920;&#24449;&#65292;&#20174;&#32780;&#31934;&#30830;&#37327;&#21270;&#20102;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#22312;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#32479;&#35745;&#24433;&#21709;&#12290;&#25105;&#20204;&#23545;&#27169;&#25311;&#25968;&#25454;&#21644;&#23454;&#38469;&#25968;&#25454;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#20960;&#31181;&#32593;&#32476;&#36741;&#21161;&#22238;&#24402;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Supervised learning problems with side information in the form of a network arise frequently in applications in genomics, proteomics and neuroscience. For example, in genetic applications, the network side information can accurately capture background biological information on the intricate relations among the relevant genes. In this paper, we initiate a study of Bayes optimal learning in high-dimensional linear regression with network side information. To this end, we first introduce a simple generative model (called the Reg-Graph model) which posits a joint distribution for the supervised data and the observed network through a common set of latent parameters. Next, we introduce an iterative algorithm based on Approximate Message Passing (AMP) which is provably Bayes optimal under very general conditions. In addition, we characterize the limiting mutual information between the latent signal and the data observed, and thus precisely quantify the statistical impact of the network side 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36755;&#20986;&#36827;&#34892;&#19979;&#28216;&#32479;&#35745;&#20998;&#26512;&#65292;&#20197;&#23454;&#29616;&#26377;&#25928;&#30340;&#19979;&#28216;&#32479;&#35745;&#25512;&#26029;&#65292;&#24182;&#38477;&#20302;&#26631;&#31614;&#33719;&#21462;&#30340;&#30740;&#31350;&#25104;&#26412;80&#65285;&#65292;&#21516;&#26102;&#20445;&#35777;CSS&#30740;&#31350;&#30340;&#32479;&#35745;&#23646;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.04746</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27880;&#37322;&#36827;&#34892;&#31038;&#20250;&#31185;&#23398;&#20013;&#30340;&#26377;&#25928;&#19979;&#28216;&#32479;&#35745;&#25512;&#26029;: &#22522;&#20110;&#35774;&#35745;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Using Large Language Model Annotations for Valid Downstream Statistical Inference in Social Science: Design-Based Semi-Supervised Learning. (arXiv:2306.04746v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04746
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36755;&#20986;&#36827;&#34892;&#19979;&#28216;&#32479;&#35745;&#20998;&#26512;&#65292;&#20197;&#23454;&#29616;&#26377;&#25928;&#30340;&#19979;&#28216;&#32479;&#35745;&#25512;&#26029;&#65292;&#24182;&#38477;&#20302;&#26631;&#31614;&#33719;&#21462;&#30340;&#30740;&#31350;&#25104;&#26412;80&#65285;&#65292;&#21516;&#26102;&#20445;&#35777;CSS&#30740;&#31350;&#30340;&#32479;&#35745;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35745;&#31639;&#31038;&#20250;&#31185;&#23398;&#65288;CSS&#65289;&#20013;&#65292;&#30740;&#31350;&#20154;&#21592;&#36890;&#36807;&#20998;&#26512;&#25991;&#26723;&#26469;&#35299;&#37322;&#31038;&#20250;&#21644;&#25919;&#27835;&#29616;&#35937;&#12290;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#65292;CSS&#30740;&#31350;&#20154;&#21592;&#39318;&#20808;&#33719;&#21462;&#25991;&#26723;&#30340;&#26631;&#31614;&#65292;&#28982;&#21518;&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#22238;&#24402;&#20998;&#26512;&#26469;&#35299;&#37322;&#26631;&#31614;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26368;&#36817;&#36827;&#23637;&#21487;&#20197;&#36890;&#36807;&#22312;&#35268;&#27169;&#19978;&#20415;&#23452;&#22320;&#27880;&#37322;&#25991;&#26723;&#26469;&#38477;&#20302;CSS&#30740;&#31350;&#25104;&#26412;&#65292;&#20294;&#36825;&#20123;&#26367;&#20195;&#26631;&#31614;&#36890;&#24120;&#26159;&#19981;&#23436;&#32654;&#21644;&#26377;&#20559;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#29992;&#20110;&#20351;&#29992;LLMs&#30340;&#36755;&#20986;&#36827;&#34892;&#19979;&#28216;&#32479;&#35745;&#20998;&#26512;&#65292;&#21516;&#26102;&#20445;&#35777;&#19982;CSS&#30740;&#31350;&#22522;&#26412;&#30456;&#20851;&#30340;&#32479;&#35745;&#23646;&#24615;-&#22914;&#28176;&#36817;&#26080;&#20559;&#24615;&#21644;&#27491;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#30452;&#25509;&#22312;&#19979;&#28216;&#32479;&#35745;&#20998;&#26512;&#20013;&#20351;&#29992;LLM&#39044;&#27979;&#30340;&#26367;&#20195;&#26631;&#31614;&#20250;&#23548;&#33268;&#23454;&#36136;&#24615;&#20559;&#24046;&#21644;&#26080;&#25928;&#32622;&#20449;&#21306;&#38388;&#65292;&#21363;&#20351;&#26367;&#20195;&#20934;&#30830;&#24615;&#39640;&#36798;80-90&#65285;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#22522;&#20110;&#26080;&#20559;&#26426;&#22120;&#23398;&#20064;&#25552;&#20986;&#20102;&#22522;&#20110;&#35774;&#35745;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#65288;D-SSL&#65289;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#23558;LLM&#27880;&#37322;&#19982;&#26377;&#38024;&#23545;&#24615;&#30340;&#37319;&#26679;&#30456;&#32467;&#21512;&#65292;&#20197;&#23454;&#29616;&#26377;&#25928;&#30340;&#19979;&#28216;&#32479;&#35745;&#25512;&#26029;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#23558;&#26631;&#31614;&#33719;&#21462;&#30340;CSS&#30740;&#31350;&#25104;&#26412;&#38477;&#20302;80&#65285;&#65292;&#32780;&#19981;&#24433;&#21709;&#32479;&#35745;&#20998;&#26512;&#30340;&#26377;&#25928;&#24615;&#12290;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#25968;&#25454;&#31034;&#20363;&#34920;&#26126;&#65292;&#19982;&#30452;&#25509;&#20351;&#29992;LLM&#39044;&#27979;&#26631;&#31614;&#30456;&#27604;&#65292;D-SSL&#21487;&#20197;&#23558;&#22238;&#24402;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#25552;&#39640;&#22810;&#36798;40&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;
In computational social science (CSS), researchers analyze documents to explain social and political phenomena. In most scenarios, CSS researchers first obtain labels for documents and then explain labels using interpretable regression analyses in the second step. The recent advancements in large language models (LLMs) can lower costs for CSS research by annotating documents cheaply at scale, but such surrogate labels are often imperfect and biased. We present a new algorithm for using outputs from LLMs for downstream statistical analyses while guaranteeing statistical properties -- like asymptotic unbiasedness and proper uncertainty quantification -- which are fundamental to CSS research. We show that direct use of LLM-predicted surrogate labels in downstream statistical analyses leads to substantial bias and invalid confidence intervals, even with high surrogate accuracy of 80--90\%. To address this, we build on debiased machine learning to propose the design-based semi-supervised le
&lt;/p&gt;</description></item><item><title>&#31995;&#32479;&#22320;&#30740;&#31350;&#20102;&#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#30340;&#35780;&#20272;&#65292;&#21457;&#29616;&#24120;&#35265;&#30340;&#35780;&#20215;&#25351;&#26631;&#22914;FID&#31561;&#19981;&#33021;&#24456;&#22909;&#22320;&#20307;&#29616;&#25193;&#25955;&#27169;&#22411;&#30340;&#24863;&#30693;&#30495;&#23454;&#24615;&#65292;&#24314;&#35758;&#20351;&#29992;SwAV&#29305;&#24449;&#25552;&#21462;&#22120;&#32467;&#21512;FID&#36827;&#34892;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2306.04675</link><description>&lt;p&gt;
&#25581;&#31034;&#29983;&#25104;&#27169;&#22411;&#35780;&#20215;&#24230;&#37327;&#30340;&#32570;&#38519;&#21450;&#20854;&#19981;&#20844;&#24179;&#23545;&#24453;&#25193;&#25955;&#27169;&#22411;&#30340;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
Exposing flaws of generative model evaluation metrics and their unfair treatment of diffusion models. (arXiv:2306.04675v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04675
&lt;/p&gt;
&lt;p&gt;
&#31995;&#32479;&#22320;&#30740;&#31350;&#20102;&#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#30340;&#35780;&#20272;&#65292;&#21457;&#29616;&#24120;&#35265;&#30340;&#35780;&#20215;&#25351;&#26631;&#22914;FID&#31561;&#19981;&#33021;&#24456;&#22909;&#22320;&#20307;&#29616;&#25193;&#25955;&#27169;&#22411;&#30340;&#24863;&#30693;&#30495;&#23454;&#24615;&#65292;&#24314;&#35758;&#20351;&#29992;SwAV&#29305;&#24449;&#25552;&#21462;&#22120;&#32467;&#21512;FID&#36827;&#34892;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#31995;&#32479;&#22320;&#30740;&#31350;&#20102;&#35768;&#22810;&#31181;&#22522;&#20110;&#22270;&#20687;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#21253;&#25324;&#35821;&#20041;&#22810;&#26679;&#30340;&#25968;&#25454;&#38598;&#65292;&#20197;&#29702;&#35299;&#21644;&#25913;&#36827;&#29992;&#20110;&#35780;&#20272;&#23427;&#20204;&#30340;&#29305;&#24449;&#25552;&#21462;&#22120;&#21644;&#24230;&#37327;&#12290;&#20351;&#29992;&#24515;&#29702;&#29289;&#29702;&#23398;&#30340;&#26368;&#20339;&#23454;&#36341;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#36804;&#20170;&#20026;&#27490;&#26368;&#22823;&#35268;&#27169;&#30340;&#29983;&#25104;&#27169;&#22411;&#35780;&#20272;&#23454;&#39564;&#65292;&#36890;&#36807;&#23545;&#29983;&#25104;&#26679;&#26412;&#36827;&#34892;&#20154;&#31867;&#24863;&#30693;&#22270;&#20687;&#30495;&#23454;&#24615;&#30340;&#27979;&#37327;&#65292;&#21457;&#29616;&#27809;&#26377;&#20219;&#20309;&#29616;&#26377;&#30340;&#24230;&#37327;&#33021;&#19982;&#20154;&#31867;&#35780;&#20272;&#24378;&#30456;&#20851;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#29992;&#20110;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#25972;&#20307;&#24615;&#33021;&#12289;&#20445;&#30495;&#24230;&#12289;&#22810;&#26679;&#24615;&#21644;&#35760;&#24518;&#33021;&#21147;&#30340;16&#20010;&#29616;&#20195;&#25351;&#26631;&#65292;&#21457;&#29616;&#20197;&#20154;&#31867;&#20026;&#22522;&#20934;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#26368;&#20808;&#36827;&#30340;&#24863;&#30693;&#30495;&#23454;&#24615;&#19981;&#21453;&#26144;&#22312;&#24120;&#35265;&#30340;&#24230;&#37327;&#25351;&#26631;&#65292;&#22914;FID&#20013;&#12290;&#36825;&#31181;&#24046;&#24322;&#24182;&#19981;&#33021;&#36890;&#36807;&#29983;&#25104;&#26679;&#26412;&#30340;&#22810;&#26679;&#24615;&#26469;&#35299;&#37322;&#65292;&#23613;&#31649;&#20854;&#20013;&#19968;&#20010;&#21407;&#22240;&#26159;&#36807;&#24230;&#20381;&#36182;&#20110;Inception-V3&#12290;&#36890;&#36807;&#30740;&#31350;&#26367;&#20195;&#30340;&#33258;&#30417;&#30563;&#29305;&#24449;&#25552;&#21462;&#22120;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#36825;&#20123;&#32570;&#38519;&#65292;&#21457;&#29616;&#20010;&#21035;&#24369;Downstream&#20219;&#21153;&#32534;&#30721;&#30340;&#35821;&#20041;&#20449;&#24687;&#26368;&#33021;&#35299;&#37322;&#22270;&#20687;&#30495;&#23454;&#24615;&#65292;&#24314;&#35758;&#22312;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#26102;&#20351;&#29992;SwAV&#29305;&#24449;&#25552;&#21462;&#22120;&#32467;&#21512;FID&#12290;
&lt;/p&gt;
&lt;p&gt;
We systematically study a wide variety of image-based generative models spanning semantically-diverse datasets to understand and improve the feature extractors and metrics used to evaluate them. Using best practices in psychophysics, we measure human perception of image realism for generated samples by conducting the largest experiment evaluating generative models to date, and find that no existing metric strongly correlates with human evaluations. Comparing to 16 modern metrics for evaluating the overall performance, fidelity, diversity, and memorization of generative models, we find that the state-of-the-art perceptual realism of diffusion models as judged by humans is not reflected in commonly reported metrics such as FID. This discrepancy is not explained by diversity in generated samples, though one cause is over-reliance on Inception-V3. We address these flaws through a study of alternative self-supervised feature extractors, find that the semantic information encoded by individu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#39640;&#26031;&#21464;&#20998;&#36807;&#31243;&#21442;&#25968;&#21270;&#26041;&#27861;&#26469;&#26356;&#22909;&#22320;&#23398;&#20064;&#20855;&#26377;&#38750;&#32447;&#24615;&#25193;&#25955;&#36807;&#31243;&#30340;&#28508;&#22312;&#36807;&#31243;&#65292;&#27492;&#26041;&#27861;&#37319;&#29992;&#20855;&#26377;&#36830;&#32493;&#25351;&#25968;&#26063;&#25551;&#36848;&#30340;&#31639;&#27861;&#23454;&#29616;&#20984;&#20248;&#21270;&#65292;&#21487;&#20197;&#20195;&#26367;&#32531;&#24930;&#30340;&#20855;&#26377;&#22266;&#23450;&#28857;&#36845;&#20195;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.02066</link><description>&lt;p&gt;
&#21464;&#20998;&#39640;&#26031;&#36807;&#31243;&#25193;&#25955;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Variational Gaussian Process Diffusion Processes. (arXiv:2306.02066v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02066
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#39640;&#26031;&#21464;&#20998;&#36807;&#31243;&#21442;&#25968;&#21270;&#26041;&#27861;&#26469;&#26356;&#22909;&#22320;&#23398;&#20064;&#20855;&#26377;&#38750;&#32447;&#24615;&#25193;&#25955;&#36807;&#31243;&#30340;&#28508;&#22312;&#36807;&#31243;&#65292;&#27492;&#26041;&#27861;&#37319;&#29992;&#20855;&#26377;&#36830;&#32493;&#25351;&#25968;&#26063;&#25551;&#36848;&#30340;&#31639;&#27861;&#23454;&#29616;&#20984;&#20248;&#21270;&#65292;&#21487;&#20197;&#20195;&#26367;&#32531;&#24930;&#30340;&#20855;&#26377;&#22266;&#23450;&#28857;&#36845;&#20195;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#36807;&#31243;&#26159;&#19968;&#31867;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65292;&#25552;&#20379;&#20102;&#19968;&#31995;&#21015;&#34920;&#29616;&#20016;&#23500;&#30340;&#27169;&#22411;&#65292;&#33258;&#28982;&#22320;&#20986;&#29616;&#22312;&#21160;&#24577;&#24314;&#27169;&#20219;&#21153;&#20013;&#12290;&#27010;&#29575;&#25512;&#29702;&#21644;&#29983;&#25104;&#27169;&#22411;&#19979;&#20855;&#26377;&#38750;&#32447;&#24615;&#25193;&#25955;&#36807;&#31243;&#30340;&#28508;&#22312;&#36807;&#31243;&#30340;&#23398;&#20064;&#37117;&#26159;&#26840;&#25163;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#22312;&#21464;&#20998;&#25512;&#29702;&#30340;&#22522;&#30784;&#19978;&#26500;&#24314;&#39640;&#26031;&#36807;&#31243;&#25193;&#25955;&#36807;&#31243;&#30340;&#21442;&#25968;&#21270;&#65292;&#25351;&#20986;&#26041;&#27861;&#20013;&#30340;&#30149;&#24577;&#65292;&#24182;&#25552;&#20986;&#19968;&#31181;&#20351;&#29992;&#36830;&#32493;&#25351;&#25968;&#26063;&#25551;&#36848;&#30340;&#39640;&#26031;&#21464;&#20998;&#36807;&#31243;&#30340;&#26367;&#20195;&#21442;&#25968;&#21270;&#26041;&#27861;&#12290;&#36825;&#20351;&#25105;&#20204;&#21487;&#20197;&#29992;&#20984;&#20248;&#21270;&#30340;&#24555;&#36895;&#31639;&#27861;&#20195;&#26367;&#20855;&#26377;&#22266;&#23450;&#28857;&#36845;&#20195;&#30340;&#32531;&#24930;&#31639;&#27861;&#65292;&#36825;&#31181;&#31639;&#27861;&#31867;&#20284;&#20110;&#33258;&#28982;&#26799;&#24230;&#19979;&#38477;&#65292;&#21516;&#26102;&#25552;&#20379;&#26356;&#22909;&#30340;&#30446;&#26631;&#26469;&#23398;&#20064;&#27169;&#22411;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion processes are a class of stochastic differential equations (SDEs) providing a rich family of expressive models that arise naturally in dynamic modelling tasks. Probabilistic inference and learning under generative models with latent processes endowed with a non-linear diffusion process prior are intractable problems. We build upon work within variational inference approximating the posterior process as a linear diffusion process, point out pathologies in the approach, and propose an alternative parameterization of the Gaussian variational process using a continuous exponential family description. This allows us to trade a slow inference algorithm with fixed-point iterations for a fast algorithm for convex optimization akin to natural gradient descent, which also provides a better objective for the learning of model parameters.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31526;&#21512;&#24615;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65288;CF-GNN&#65289;&#65292;&#36890;&#36807;&#23558;&#31526;&#21512;&#24615;&#39044;&#27979;&#65288;CP&#65289;&#25193;&#23637;&#21040;&#22522;&#20110;&#22270;&#30340;&#27169;&#22411;&#20013;&#65292;&#23545;GNN&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#20102;&#26377;&#25928;&#20272;&#35745;&#12290;CF-GNN&#29983;&#25104;&#30340;&#39044;&#27979;&#38598;/&#21306;&#38388;&#21487;&#26681;&#25454;&#39044;&#23450;&#20041;&#30340;&#35206;&#30422;&#27010;&#29575;&#20445;&#35777;&#21253;&#21547;&#30495;&#23454;&#26631;&#31614;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#19968;&#31181;&#20943;&#23569;&#39044;&#27979;&#38598;&#22823;&#23567;/&#21306;&#38388;&#38271;&#24230;&#30340;&#25299;&#25169;&#24847;&#35782;&#36755;&#20986;&#26657;&#27491;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.14535</link><description>&lt;p&gt;
&#29992;&#22522;&#20110;&#31526;&#21512;&#24615;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#23545;&#22270;&#19978;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Uncertainty Quantification over Graph with Conformalized Graph Neural Networks. (arXiv:2305.14535v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14535
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31526;&#21512;&#24615;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65288;CF-GNN&#65289;&#65292;&#36890;&#36807;&#23558;&#31526;&#21512;&#24615;&#39044;&#27979;&#65288;CP&#65289;&#25193;&#23637;&#21040;&#22522;&#20110;&#22270;&#30340;&#27169;&#22411;&#20013;&#65292;&#23545;GNN&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#20102;&#26377;&#25928;&#20272;&#35745;&#12290;CF-GNN&#29983;&#25104;&#30340;&#39044;&#27979;&#38598;/&#21306;&#38388;&#21487;&#26681;&#25454;&#39044;&#23450;&#20041;&#30340;&#35206;&#30422;&#27010;&#29575;&#20445;&#35777;&#21253;&#21547;&#30495;&#23454;&#26631;&#31614;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#19968;&#31181;&#20943;&#23569;&#39044;&#27979;&#38598;&#22823;&#23567;/&#21306;&#38388;&#38271;&#24230;&#30340;&#25299;&#25169;&#24847;&#35782;&#36755;&#20986;&#26657;&#27491;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#29992;&#20110;&#22270;&#32467;&#26500;&#25968;&#25454;&#39044;&#27979;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;GNN&#32570;&#20047;&#20005;&#26684;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#38169;&#35823;&#25104;&#26412;&#26174;&#33879;&#30340;&#29615;&#22659;&#20013;&#30340;&#21487;&#38752;&#37096;&#32626;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31526;&#21512;&#24615;GNN&#65288;CF-GNN&#65289;&#65292;&#23558;&#31526;&#21512;&#24615;&#39044;&#27979;&#65288;CP&#65289;&#25193;&#23637;&#21040;&#22522;&#20110;&#22270;&#30340;&#27169;&#22411;&#20013;&#65292;&#20197;&#33719;&#24471;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#32473;&#23450;&#22270;&#20013;&#30340;&#23454;&#20307;&#65292;CF-GNN&#29983;&#25104;&#19968;&#20010;&#39044;&#27979;&#38598;/&#21306;&#38388;&#65292;&#20197;&#20808;&#39564;&#35206;&#30422;&#27010;&#29575;&#65288;&#20363;&#22914;90%&#65289;&#30340;&#26041;&#24335;&#20445;&#35777;&#21253;&#21547;&#30495;&#23454;&#26631;&#31614;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#25490;&#21015;&#19981;&#21464;&#26465;&#20214;&#65292;&#20351;&#24471;CP&#22312;&#22270;&#25968;&#25454;&#19978;&#25104;&#31435;&#65292;&#24182;&#25552;&#20379;&#20102;&#27979;&#35797;&#26102;&#38388;&#35206;&#30422;&#29575;&#30340;&#31934;&#30830;&#29305;&#24449;&#12290;&#27492;&#22806;&#65292;&#38500;&#20102;&#26377;&#25928;&#30340;&#35206;&#30422;&#65292;&#20943;&#23569;&#39044;&#27979;&#38598;&#22823;&#23567;/&#21306;&#38388;&#38271;&#24230;&#23545;&#20110;&#23454;&#38469;&#20351;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#21457;&#29616;&#38750;&#31526;&#21512;&#24615;&#24471;&#20998;&#21644;&#32593;&#32476;&#32467;&#26500;&#20043;&#38388;&#23384;&#22312;&#20851;&#38190;&#32852;&#31995;&#65292;&#36825;&#20419;&#20351;&#25105;&#20204;&#24320;&#21457;&#20855;&#26377;&#25299;&#25169;&#24847;&#35782;&#30340;&#36755;&#20986;&#26657;&#27491;&#27169;&#22411;&#26469;&#23398;&#20064;&#26356;&#26032;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) are powerful machine learning prediction models on graph-structured data. However, GNNs lack rigorous uncertainty estimates, limiting their reliable deployment in settings where the cost of errors is significant. We propose conformalized GNN (CF-GNN), extending conformal prediction (CP) to graph-based models for guaranteed uncertainty estimates. Given an entity in the graph, CF-GNN produces a prediction set/interval that provably contains the true label with pre-defined coverage probability (e.g. 90%). We establish a permutation invariance condition that enables the validity of CP on graph data and provide an exact characterization of the test-time coverage. Moreover, besides valid coverage, it is crucial to reduce the prediction set size/interval length for practical use. We observe a key connection between non-conformity scores and network structures, which motivates us to develop a topology-aware output correction model that learns to update the predicti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19977;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#29305;&#24449;&#23398;&#20064;&#33021;&#21147;&#65292;&#30456;&#27604;&#20043;&#19979;&#65292;&#23427;&#20855;&#26377;&#27604;&#20004;&#23618;&#32593;&#32476;&#26356;&#20016;&#23500;&#30340;&#21487;&#35777;&#30340;&#29305;&#24449;&#23398;&#20064;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#23450;&#29702;&#65292;&#38480;&#21046;&#20102;&#30446;&#26631;&#32467;&#26500;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#21644;&#23485;&#24230;&#65292;&#20197;&#23454;&#29616;&#20302;&#27979;&#35797;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2305.06986</link><description>&lt;p&gt;
&#19977;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#38750;&#32447;&#24615;&#29305;&#24449;&#23398;&#20064;&#30340;&#21487;&#35777;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Provable Guarantees for Nonlinear Feature Learning in Three-Layer Neural Networks. (arXiv:2305.06986v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06986
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19977;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#29305;&#24449;&#23398;&#20064;&#33021;&#21147;&#65292;&#30456;&#27604;&#20043;&#19979;&#65292;&#23427;&#20855;&#26377;&#27604;&#20004;&#23618;&#32593;&#32476;&#26356;&#20016;&#23500;&#30340;&#21487;&#35777;&#30340;&#29305;&#24449;&#23398;&#20064;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#23450;&#29702;&#65292;&#38480;&#21046;&#20102;&#30446;&#26631;&#32467;&#26500;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#21644;&#23485;&#24230;&#65292;&#20197;&#23454;&#29616;&#20302;&#27979;&#35797;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#26159;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#22914;&#20309;&#23398;&#20064;&#20998;&#23618;&#29305;&#24449;&#12290;&#28145;&#24230;&#32593;&#32476;&#25552;&#21462;&#26174;&#33879;&#29305;&#24449;&#30340;&#33021;&#21147;&#23545;&#20854;&#21331;&#36234;&#30340;&#27867;&#21270;&#33021;&#21147;&#21644;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#33539;&#24335;&#30340;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#20174;&#29702;&#35770;&#35282;&#24230;&#26469;&#30475;&#65292;&#36825;&#31181;&#29305;&#24449;&#23398;&#20064;&#36807;&#31243;&#20173;&#28982;&#19981;&#22815;&#28165;&#26224;&#65292;&#29616;&#26377;&#30340;&#20998;&#26512;&#20027;&#35201;&#23616;&#38480;&#20110;&#20004;&#23618;&#32593;&#32476;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19977;&#23618;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#35777;&#26126;&#30340;&#27604;&#20004;&#23618;&#32593;&#32476;&#26356;&#20016;&#23500;&#30340;&#29305;&#24449;&#23398;&#20064;&#33021;&#21147;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#36890;&#36807;&#36880;&#23618;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#19977;&#23618;&#32593;&#32476;&#23398;&#20064;&#30340;&#29305;&#24449;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#23450;&#29702;&#65292;&#23427;&#19978;&#30028;&#20102;&#30446;&#26631;&#20855;&#26377;&#29305;&#23450;&#23618;&#27425;&#32467;&#26500;&#26102;&#23454;&#29616;&#20302;&#27979;&#35797;&#38169;&#35823;&#25152;&#38656;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#21644;&#23485;&#24230;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26694;&#26550;&#23454;&#20363;&#21270;&#21040;&#29305;&#23450;&#30340;&#32479;&#35745;&#23398;&#23398;&#20064;&#35774;&#32622;&#20013;&#8212;&#8212;&#21333;&#25351;&#25968;&#27169;&#22411;&#21644;&#20108;&#27425;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the central questions in the theory of deep learning is to understand how neural networks learn hierarchical features. The ability of deep networks to extract salient features is crucial to both their outstanding generalization ability and the modern deep learning paradigm of pretraining and finetuneing. However, this feature learning process remains poorly understood from a theoretical perspective, with existing analyses largely restricted to two-layer networks. In this work we show that three-layer neural networks have provably richer feature learning capabilities than two-layer networks. We analyze the features learned by a three-layer network trained with layer-wise gradient descent, and present a general purpose theorem which upper bounds the sample complexity and width needed to achieve low test error when the target has specific hierarchical structure. We instantiate our framework in specific statistical learning settings -- single-index models and functions of quadratic 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27969;&#24418;&#27491;&#21017;&#21270;Tucker&#20998;&#35299;&#30340;&#26102;&#31354;&#20132;&#36890;&#25968;&#25454;&#22635;&#20805;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#31232;&#30095;&#27491;&#21017;&#21270;&#39033;&#25913;&#21892;&#20102;Tucker&#26680;&#30340;&#31232;&#30095;&#24615;&#65292;&#24182;&#24341;&#20837;&#27969;&#24418;&#27491;&#21017;&#21270;&#21644;&#26102;&#38388;&#32422;&#26463;&#39033;&#26469;&#20248;&#21270;&#24352;&#37327;&#30340;&#22635;&#20805;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.06563</link><description>&lt;p&gt;
&#22522;&#20110;&#27969;&#24418;&#27491;&#21017;&#21270; Tucker &#20998;&#35299;&#30340;&#26102;&#31354;&#20132;&#36890;&#25968;&#25454;&#22635;&#20805;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Manifold Regularized Tucker Decomposition Approach for Spatiotemporal Traffic Data Imputation. (arXiv:2305.06563v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06563
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27969;&#24418;&#27491;&#21017;&#21270;Tucker&#20998;&#35299;&#30340;&#26102;&#31354;&#20132;&#36890;&#25968;&#25454;&#22635;&#20805;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#31232;&#30095;&#27491;&#21017;&#21270;&#39033;&#25913;&#21892;&#20102;Tucker&#26680;&#30340;&#31232;&#30095;&#24615;&#65292;&#24182;&#24341;&#20837;&#27969;&#24418;&#27491;&#21017;&#21270;&#21644;&#26102;&#38388;&#32422;&#26463;&#39033;&#26469;&#20248;&#21270;&#24352;&#37327;&#30340;&#22635;&#20805;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#31354;&#20132;&#36890;&#25968;&#25454;&#22635;&#20805;(STDI)&#26159;&#25968;&#25454;&#39537;&#21160;&#26234;&#33021;&#20132;&#36890;&#31995;&#32479;&#20013;&#19981;&#21487;&#36991;&#20813;&#21644;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#22312;&#37096;&#20998;&#35266;&#27979;&#21040;&#30340;&#20132;&#36890;&#25968;&#25454;&#20013;&#20272;&#35745;&#20002;&#22833;&#25968;&#25454;&#12290;&#30001;&#20110;&#20132;&#36890;&#25968;&#25454;&#20855;&#26377;&#22810;&#32500;&#21644;&#26102;&#31354;&#24615;&#36136;&#65292;&#25105;&#20204;&#23558;&#20002;&#22833;&#25968;&#25454;&#22635;&#20805;&#35270;&#20026;&#24352;&#37327;&#23436;&#25104;&#38382;&#39064;&#12290;&#36807;&#21435;&#21313;&#24180;&#20013;&#65292;&#35768;&#22810;&#20851;&#20110;&#22522;&#20110;&#24352;&#37327;&#20998;&#35299;&#30340; STDI &#30340;&#30740;&#31350;&#24050;&#32463;&#23637;&#24320;&#12290;&#28982;&#32780;&#65292;&#22914;&#20309;&#21033;&#29992;&#26102;&#31354;&#30456;&#20851;&#24615;&#21644;&#26680;&#24352;&#37327;&#31232;&#30095;&#24615;&#26469;&#25913;&#21892;&#22635;&#20805;&#24615;&#33021;&#20173;&#28982;&#38656;&#35201;&#35299;&#20915;&#12290;&#26412;&#25991;&#37325;&#26032;&#26500;&#36896;&#20102;3/4&#38454;&#27721;&#20811;&#23572;&#24352;&#37327;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#27969;&#24418;&#27491;&#21017;&#21270; Tucker &#20998;&#35299;(maniRTD)&#27169;&#22411;&#29992;&#20110;STDI&#12290;&#26126;&#30830;&#22320;&#65292;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#22810;&#32500;&#24310;&#36831;&#23884;&#20837;&#21464;&#25442;&#23558;&#20256;&#24863;&#20132;&#36890;&#29366;&#24577;&#25968;&#25454;&#34920;&#31034;&#20026;3/4&#38454;&#24352;&#37327;&#12290;&#28982;&#21518;&#65292;ManiRTD&#20351;&#29992;&#31232;&#30095;&#27491;&#21017;&#21270;&#39033;&#25913;&#21892;&#20102;Tucker&#26680;&#30340;&#31232;&#30095;&#24615;&#65292;&#24182;&#20351;&#29992;&#27969;&#24418;&#27491;&#21017;&#21270;&#21644;&#26102;&#38388;&#32422;&#26463;&#39033;&#26469;&#20248;&#21270;&#24352;&#37327;&#30340;&#22635;&#20805;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Spatiotemporal traffic data imputation (STDI), estimating the missing data from partially observed traffic data, is an inevitable and challenging task in data-driven intelligent transportation systems (ITS). Due to traffic data's multidimensional and spatiotemporal properties, we treat the missing data imputation as a tensor completion problem. Many studies have been on STDI based on tensor decomposition in the past decade. However, how to use spatiotemporal correlations and core tensor sparsity to improve the imputation performance still needs to be solved. This paper reshapes a 3rd/4th order Hankel tensor and proposes an innovative manifold regularized Tucker decomposition (ManiRTD) model for STDI. Expressly, we represent the sensory traffic state data as the 3rd/4th tensors by introducing Multiway Delay Embedding Transforms. Then, ManiRTD improves the sparsity of the Tucker core using a sparse regularization term and employs manifold regularization and temporal constraint terms of f
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#23545;176&#20010;&#25968;&#25454;&#38598;&#30340;&#27604;&#36739;&#20998;&#26512;&#21457;&#29616;&#65292;&#22312;&#35768;&#22810;&#25968;&#25454;&#38598;&#20013;&#65292;GBDT&#21644;NN&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#24322;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#65292;&#25110;&#32773;GBDT&#30340;&#36731;&#24494;&#36229;&#21442;&#25968;&#35843;&#25972;&#27604;&#36873;&#25321;&#26368;&#20339;&#31639;&#27861;&#26356;&#37325;&#35201;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#20154;&#21592;&#23545;965&#20010;&#20803;&#29305;&#24449;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#21457;&#29616;GBDT&#22312;&#39640;&#32500;&#31232;&#30095;&#25968;&#25454;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2305.02997</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20309;&#26102;&#22312;&#34920;&#26684;&#25968;&#25454;&#19978;&#32988;&#36807;&#22686;&#24378;&#26641;&#65311;
&lt;/p&gt;
&lt;p&gt;
When Do Neural Nets Outperform Boosted Trees on Tabular Data?. (arXiv:2305.02997v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02997
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#23545;176&#20010;&#25968;&#25454;&#38598;&#30340;&#27604;&#36739;&#20998;&#26512;&#21457;&#29616;&#65292;&#22312;&#35768;&#22810;&#25968;&#25454;&#38598;&#20013;&#65292;GBDT&#21644;NN&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#24322;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#65292;&#25110;&#32773;GBDT&#30340;&#36731;&#24494;&#36229;&#21442;&#25968;&#35843;&#25972;&#27604;&#36873;&#25321;&#26368;&#20339;&#31639;&#27861;&#26356;&#37325;&#35201;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#20154;&#21592;&#23545;965&#20010;&#20803;&#29305;&#24449;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#21457;&#29616;GBDT&#22312;&#39640;&#32500;&#31232;&#30095;&#25968;&#25454;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34920;&#26684;&#25968;&#25454;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#24120;&#29992;&#30340;&#25968;&#25454;&#31867;&#22411;&#20043;&#19968;&#12290;&#23613;&#31649;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#22312;&#34920;&#26684;&#25968;&#25454;&#19978;&#21462;&#24471;&#20102;&#26368;&#36817;&#30340;&#36827;&#23637;&#65292;&#20294;&#20154;&#20204;&#20173;&#22312;&#31215;&#26497;&#35752;&#35770;NN&#26159;&#21542;&#36890;&#24120;&#20248;&#20110;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#65288;GBDT&#65289;&#22312;&#34920;&#26684;&#25968;&#25454;&#19978;&#30340;&#34920;&#29616;&#65292;&#19968;&#20123;&#26368;&#36817;&#30340;&#24037;&#20316;&#35201;&#20040;&#35748;&#20026;GBDT&#22312;&#34920;&#26684;&#25968;&#25454;&#19978;&#19968;&#36143;&#20248;&#20110;NN&#65292;&#35201;&#20040;&#35748;&#20026;NN&#20248;&#20110;GBDT&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36864;&#19968;&#27493;&#38382;&#65306;'&#36825;&#37325;&#35201;&#21527;&#65311;'&#25105;&#20204;&#36890;&#36807;&#23545;176&#20010;&#25968;&#25454;&#38598;&#27604;&#36739;19&#31181;&#31639;&#27861;&#65292;&#36827;&#34892;&#20102;&#36804;&#20170;&#20026;&#27490;&#26368;&#22823;&#30340;&#34920;&#26684;&#25968;&#25454;&#20998;&#26512;&#65292;&#24182;&#21457;&#29616;'NN vs. GBDT'&#20105;&#35770;&#34987;&#36807;&#20998;&#24378;&#35843;&#65306;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#22312;&#30456;&#24403;&#22810;&#30340;&#25968;&#25454;&#38598;&#20013;&#65292;GBDT&#21644;NN&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#24322;&#35201;&#20040;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#65292;&#35201;&#20040;GBDT&#30340;&#36731;&#24494;&#36229;&#21442;&#25968;&#35843;&#25972;&#27604;&#36873;&#25321;&#26368;&#20339;&#31639;&#27861;&#26356;&#37325;&#35201;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;965&#20010;&#20803;&#29305;&#24449;&#65292;&#20197;&#30830;&#23450;&#25968;&#25454;&#38598;&#30340;&#21738;&#20123;&#29305;&#24615;&#20351;NN&#25110;GBDT&#26356;&#36866;&#21512;&#34920;&#29616;&#33391;&#22909;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#21457;&#29616;GBDT&#35201;&#27604;NN&#22312;&#39640;&#32500;&#31232;&#30095;&#25968;&#25454;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tabular data is one of the most commonly used types of data in machine learning. Despite recent advances in neural nets (NNs) for tabular data, there is still an active discussion on whether or not NNs generally outperform gradient-boosted decision trees (GBDTs) on tabular data, with several recent works arguing either that GBDTs consistently outperform NNs on tabular data, or vice versa. In this work, we take a step back and ask, 'does it matter?' We conduct the largest tabular data analysis to date, by comparing 19 algorithms across 176 datasets, and we find that the 'NN vs. GBDT' debate is overemphasized: for a surprisingly high number of datasets, either the performance difference between GBDTs and NNs is negligible, or light hyperparameter tuning on a GBDT is more important than selecting the best algorithm. Next, we analyze 965 metafeatures to determine what properties of a dataset make NNs or GBDTs better-suited to perform well. For example, we find that GBDTs are much better th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#26041;&#27861;&#65292;&#23545;&#39640;&#32500;&#36229;&#32479;&#35745;&#29305;&#24449;&#19979;&#30340;&#25968;&#25454;&#36827;&#34892;&#20998;&#31867;&#65292;&#24182;&#20998;&#26512;&#20102;&#27491;&#21017;&#21270;&#21644;&#20998;&#24067;&#23610;&#24230;&#21442;&#25968;&#23545;&#20998;&#31867;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2304.02912</link><description>&lt;p&gt;
&#39640;&#32500;&#36229;&#32479;&#35745;&#29305;&#24449;&#30340;&#20998;&#31867;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Classification of Superstatistical Features in High Dimensions. (arXiv:2304.02912v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02912
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#26041;&#27861;&#65292;&#23545;&#39640;&#32500;&#36229;&#32479;&#35745;&#29305;&#24449;&#19979;&#30340;&#25968;&#25454;&#36827;&#34892;&#20998;&#31867;&#65292;&#24182;&#20998;&#26512;&#20102;&#27491;&#21017;&#21270;&#21644;&#20998;&#24067;&#23610;&#24230;&#21442;&#25968;&#23545;&#20998;&#31867;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#36890;&#36807;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#26041;&#27861;&#65292;&#23545;&#20855;&#26377;&#19968;&#33324;&#20013;&#24515;&#28857;&#30340;&#20004;&#20010;&#25968;&#25454;&#20113;&#30340;&#28151;&#21512;&#36827;&#34892;&#20102;&#23398;&#20064;&#65292;&#20551;&#35774;&#20855;&#26377;&#36890;&#29992;&#30340;&#20984;&#25439;&#22833;&#21644;&#20984;&#27491;&#21017;&#21270;&#12290;&#27599;&#20010;&#25968;&#25454;&#20113;&#26159;&#36890;&#36807;&#20174;&#21487;&#33021;&#26159;&#19981;&#21487;&#25968;&#30340;&#39640;&#26031;&#20998;&#24067;&#21472;&#21152;&#20013;&#36827;&#34892;&#37319;&#26679;&#26469;&#33719;&#24471;&#30340;&#65292;&#20854;&#26041;&#24046;&#20855;&#26377;&#36890;&#29992;&#30340;&#27010;&#29575;&#23494;&#24230;$\varrho$&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#28085;&#30422;&#20102;&#22823;&#37327;&#30340;&#25968;&#25454;&#20998;&#24067;&#65292;&#21253;&#25324;&#27809;&#26377;&#21327;&#26041;&#24046;&#30340;&#24130;&#24459;&#23614;&#37096;&#20998;&#24067;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#25152;&#24471;&#20272;&#35745;&#22120;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#20998;&#26512;&#20102;&#27491;&#21017;&#21270;&#30340;&#20316;&#29992;&#20197;&#21450;&#20998;&#31163;&#36716;&#25442;&#19982;&#20998;&#24067;&#23610;&#24230;&#21442;&#25968;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We characterise the learning of a mixture of two clouds of data points with generic centroids via empirical risk minimisation in the high dimensional regime, under the assumptions of generic convex loss and convex regularisation. Each cloud of data points is obtained by sampling from a possibly uncountable superposition of Gaussian distributions, whose variance has a generic probability density $\varrho$. Our analysis covers therefore a large family of data distributions, including the case of power-law-tailed distributions with no covariance. We study the generalisation performance of the obtained estimator, we analyse the role of regularisation, and the dependence of the separability transition on the distribution scale parameters.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#27969;&#24418;&#23398;&#20064;&#20013;&#24212;&#29992;&#26080;&#30896;&#25758;&#36816;&#36755;&#22270;&#30340;&#26041;&#27861;&#65292;&#20854;&#21487;&#20197;&#27604;OT&#22270;&#26356;&#20415;&#23452;&#22320;&#35745;&#31639;&#36317;&#31163;&#65292;&#24182;&#25552;&#20379;&#21333;&#20010;&#27010;&#29575;&#27979;&#24230;&#30340;&#24179;&#31227;&#21644;&#20280;&#32553;&#30340;&#31561;&#36317;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.00199</link><description>&lt;p&gt;
&#26080;&#30896;&#25758;&#36816;&#36755;&#22270;&#22312;&#27969;&#34892;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Applications of No-Collision Transportation Maps in Manifold Learning. (arXiv:2304.00199v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00199
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#27969;&#24418;&#23398;&#20064;&#20013;&#24212;&#29992;&#26080;&#30896;&#25758;&#36816;&#36755;&#22270;&#30340;&#26041;&#27861;&#65292;&#20854;&#21487;&#20197;&#27604;OT&#22270;&#26356;&#20415;&#23452;&#22320;&#35745;&#31639;&#36317;&#31163;&#65292;&#24182;&#25552;&#20379;&#21333;&#20010;&#27010;&#29575;&#27979;&#24230;&#30340;&#24179;&#31227;&#21644;&#20280;&#32553;&#30340;&#31561;&#36317;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24341;&#20837;&#20110;[Nurbekyan et al.&#65292;2020]&#30340;&#26080;&#30896;&#25758;&#36816;&#36755;&#22270;&#22312;&#22270;&#20687;&#25968;&#25454;&#30340;&#27969;&#24418;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#36817;&#24180;&#26469;&#65292;&#22312;&#34920;&#31034;&#31867;&#20284;&#36816;&#21160;&#25110;&#21464;&#24418;&#29616;&#35937;&#30340;&#25968;&#25454;&#20013;&#65292;&#24212;&#29992;&#22522;&#20110;&#36816;&#36755;&#30340;&#36317;&#31163;&#21644;&#29305;&#24449;&#30340;&#30740;&#31350;&#22823;&#24133;&#22686;&#21152;&#12290;&#20107;&#23454;&#19978;&#65292;&#22266;&#23450;&#20301;&#32622;&#27604;&#36739;&#24378;&#24230;&#36890;&#24120;&#26080;&#27861;&#26174;&#31034;&#25968;&#25454;&#32467;&#26500;&#12290;&#22312;[Nurbekyan et al.&#65292;2020]&#20013;&#24320;&#21457;&#30340;&#26080;&#30896;&#25758;&#22270;&#21644;&#36317;&#31163;&#31867;&#20284;&#20110;&#26368;&#20248;&#20256;&#36755;(OT)&#22270;&#30340;&#20960;&#20309;&#29305;&#24449;&#20294;&#30001;&#20110;&#26080;&#38656;&#20248;&#21270;&#65292;&#35745;&#31639;&#25104;&#26412;&#35201;&#20415;&#23452;&#24471;&#22810;&#12290;&#26412;&#25991;&#35777;&#26126;&#26080;&#30896;&#25758;&#36317;&#31163;&#25552;&#20379;&#21333;&#20010;&#27010;&#29575;&#27979;&#24230;&#30340;&#24179;&#31227;(&#20998;&#21035;&#26159;&#20280;&#32553;)&#21644;&#35013;&#22791;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#30340;&#24179;&#31227;(&#20998;&#21035;&#26159;&#20280;&#32553;)&#21521;&#37327;&#20043;&#38388;&#30340;&#31561;&#36317;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#26080;&#30896;&#25758;&#36816;&#36755;&#22270;&#20197;&#21450;OT&#21644;&#32447;&#24615;OT&#22270;&#65292;&#19968;&#33324;&#26469;&#35828;&#19981;&#33021;&#20026;&#26059;&#36716;&#25552;&#20379;&#31561;&#36317;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we investigate applications of no-collision transportation maps introduced in [Nurbekyan et. al., 2020] in manifold learning for image data. Recently, there has been a surge in applying transportation-based distances and features for data representing motion-like or deformation-like phenomena. Indeed, comparing intensities at fixed locations often does not reveal the data structure. No-collision maps and distances developed in [Nurbekyan et. al., 2020] are sensitive to geometric features similar to optimal transportation (OT) maps but much cheaper to compute due to the absence of optimization. In this work, we prove that no-collision distances provide an isometry between translations (respectively dilations) of a single probability measure and the translation (respectively dilation) vectors equipped with a Euclidean distance. Furthermore, we prove that no-collision transportation maps, as well as OT and linearized OT maps, do not in general provide an isometry for rotatio
&lt;/p&gt;</description></item><item><title>&#19968;&#31181;&#26032;&#30340;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#26694;&#26550;&#65292;&#21033;&#29992;&#33258;&#28982;&#35270;&#39057;&#30340;&#35268;&#24459;&#36827;&#34892;&#20934;&#30830;&#39044;&#27979;&#65292;&#24182;&#21457;&#29616;&#20102;&#22312;&#25968;&#25454;&#20013;&#30340;&#31616;&#21333;&#21464;&#25442;&#32676;&#30340;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2303.03432</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#34920;&#31034;&#35270;&#35273;&#36716;&#25442;&#30340;&#26497;&#22352;&#26631;&#39044;&#27979;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A polar prediction model for learning to represent visual transformations. (arXiv:2303.03432v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.03432
&lt;/p&gt;
&lt;p&gt;
&#19968;&#31181;&#26032;&#30340;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#26694;&#26550;&#65292;&#21033;&#29992;&#33258;&#28982;&#35270;&#39057;&#30340;&#35268;&#24459;&#36827;&#34892;&#20934;&#30830;&#39044;&#27979;&#65292;&#24182;&#21457;&#29616;&#20102;&#22312;&#25968;&#25454;&#20013;&#30340;&#31616;&#21333;&#21464;&#25442;&#32676;&#30340;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25152;&#26377;&#29983;&#29289;&#37117;&#20250;&#20570;&#26102;&#38388;&#39044;&#27979;&#65292;&#24182;&#19988;&#23427;&#20204;&#30340;&#36827;&#21270;&#36866;&#24212;&#24230;&#21462;&#20915;&#20110;&#36825;&#20123;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#12290;&#22312;&#35270;&#35273;&#24863;&#30693;&#30340;&#24773;&#22659;&#19979;&#65292;&#35266;&#23519;&#32773;&#21644;&#22330;&#26223;&#20013;&#29289;&#20307;&#30340;&#36816;&#21160;&#26500;&#25104;&#20102;&#24863;&#23448;&#20449;&#21495;&#30340;&#21160;&#24577;&#65292;&#20351;&#24471;&#21487;&#20197;&#22522;&#20110;&#36807;&#21435;&#30340;&#20449;&#21495;&#37096;&#20998;&#39044;&#27979;&#26410;&#26469;&#30340;&#20449;&#21495;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#30417;&#30563;&#30340;&#34920;&#31034;&#23398;&#20064;&#26694;&#26550;&#65292;&#23427;&#25552;&#21462;&#21644;&#21033;&#29992;&#33258;&#28982;&#35270;&#39057;&#30340;&#35268;&#24459;&#26469;&#35745;&#31639;&#20934;&#30830;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#36890;&#36807;&#24341;&#29992;Fourier&#31227;&#20301;&#23450;&#29702;&#21450;&#20854;&#32676;&#35770;&#25512;&#24191;&#26469;&#23637;&#31034;&#20102;&#26497;&#22352;&#26631;&#26550;&#26500;&#30340;&#21160;&#26426;&#65292;&#24182;&#36890;&#36807;&#23545;&#19979;&#19968;&#24103;&#39044;&#27979;&#36827;&#34892;&#21442;&#25968;&#20248;&#21270;&#12290;&#36890;&#36807;&#23545;&#27604;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#21457;&#29616;&#22312;&#25968;&#25454;&#20013;&#20316;&#29992;&#30340;&#31616;&#21333;&#21464;&#25442;&#32676;&#30340;&#34920;&#31034;&#12290;&#24403;&#22312;&#33258;&#28982;&#35270;&#39057;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#23454;&#29616;&#20102;&#27604;&#20256;&#32479;&#30340;&#36816;&#21160;&#34917;&#20607;&#26356;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#24182;&#19988;&#19982;&#20256;&#32479;&#30340;&#28145;&#24230;&#32593;&#32476;&#19981;&#30456;&#19978;&#19979;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;...
&lt;/p&gt;
&lt;p&gt;
All organisms make temporal predictions, and their evolutionary fitness level depends on the accuracy of these predictions. In the context of visual perception, the motions of both the observer and objects in the scene structure the dynamics of sensory signals, allowing for partial prediction of future signals based on past ones. Here, we propose a self-supervised representation-learning framework that extracts and exploits the regularities of natural videos to compute accurate predictions. We motivate the polar architecture by appealing to the Fourier shift theorem and its group-theoretic generalization, and we optimize its parameters on next-frame prediction. Through controlled experiments, we demonstrate that this approach can discover the representation of simple transformation groups acting in data. When trained on natural video datasets, our framework achieves better prediction performance than traditional motion compensation and rivals conventional deep networks, while maintaini
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#30740;&#31350;&#20102;ReLU&#32593;&#32476;&#20013;&#26799;&#24230;&#27969;&#30340;&#38544;&#24335;&#20559;&#24046;&#23545;&#27867;&#21270;&#21644;&#23545;&#25239;&#40065;&#26834;&#24615;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#26799;&#24230;&#27969;&#20542;&#21521;&#20110;&#27867;&#21270;&#33021;&#21147;&#24378;&#20294;&#23545;&#25239;&#24615;&#39640;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#19988;&#36825;&#31181;&#20559;&#24046;&#36824;&#23548;&#33268;&#38750;&#40065;&#26834;&#24615;&#35299;&#20915;&#26041;&#26696;&#30340;&#20986;&#29616;&#12290;</title><link>http://arxiv.org/abs/2303.01456</link><description>&lt;p&gt;
&#38544;&#21547;&#20559;&#35265;&#30340;&#21452;&#20995;&#21073;&#65306;ReLU&#32593;&#32476;&#20013;&#30340;&#27867;&#21270;&#19982;&#40065;&#26834;&#24615;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
The Double-Edged Sword of Implicit Bias: Generalization vs. Robustness in ReLU Networks. (arXiv:2303.01456v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.01456
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#30740;&#31350;&#20102;ReLU&#32593;&#32476;&#20013;&#26799;&#24230;&#27969;&#30340;&#38544;&#24335;&#20559;&#24046;&#23545;&#27867;&#21270;&#21644;&#23545;&#25239;&#40065;&#26834;&#24615;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#26799;&#24230;&#27969;&#20542;&#21521;&#20110;&#27867;&#21270;&#33021;&#21147;&#24378;&#20294;&#23545;&#25239;&#24615;&#39640;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#19988;&#36825;&#31181;&#20559;&#24046;&#36824;&#23548;&#33268;&#38750;&#40065;&#26834;&#24615;&#35299;&#20915;&#26041;&#26696;&#30340;&#20986;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26799;&#24230;&#27969;&#30340;&#38544;&#24335;&#20559;&#24046;&#23545;ReLU&#32593;&#32476;&#20013;&#27867;&#21270;&#21644;&#23545;&#25239;&#40065;&#26834;&#24615;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#20851;&#27880;&#30340;&#26159;&#25968;&#25454;&#30001;&#31751;&#32452;&#25104;&#19988;&#31751;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#36739;&#23567;&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#21457;&#29616;&#22312;&#20004;&#23618;ReLU&#32593;&#32476;&#20013;&#65292;&#26799;&#24230;&#27969;&#22312;&#20559;&#21521;&#27867;&#21270;&#33021;&#21147;&#24378;&#30340;&#35299;&#20915;&#26041;&#26696;&#30340;&#21516;&#26102;&#20063;&#23545;&#23567;&#35268;&#27169;&#23545;&#25239;&#24615;&#20363;&#23376;&#39640;&#24230;&#33030;&#24369;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#21363;&#20351;&#22312;&#32593;&#32476;&#21442;&#25968;&#36828;&#36828;&#22810;&#20313;&#35757;&#32451;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#20063;&#25104;&#31435;&#12290;&#23613;&#31649;&#22312;&#36825;&#31181;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#35774;&#32622;&#20013;&#26377;&#28508;&#22312;&#30340;&#26377;&#23475;&#36807;&#25311;&#21512;&#21487;&#33021;&#24615;&#65292;&#25105;&#20204;&#35777;&#26126;&#26799;&#24230;&#27969;&#30340;&#38544;&#24335;&#20559;&#24046;&#21487;&#20197;&#38450;&#27490;&#36825;&#31181;&#24773;&#20917;&#21457;&#29983;&#12290;&#28982;&#32780;&#65292;&#38544;&#24335;&#20559;&#24046;&#20063;&#20250;&#23548;&#33268;&#38750;&#40065;&#26834;&#24615;&#30340;&#35299;&#20915;&#26041;&#26696;&#65288;&#23481;&#26131;&#21463;&#21040;&#23567;&#30340;&#23545;&#25239;&#24615;$\ell_2$&#25200;&#21160;&#65289;&#65292;&#23613;&#31649;&#20063;&#23384;&#22312;&#33021;&#22815;&#25311;&#21512;&#25968;&#25454;&#30340;&#40065;&#26834;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we study the implications of the implicit bias of gradient flow on generalization and adversarial robustness in ReLU networks. We focus on a setting where the data consists of clusters and the correlations between cluster means are small, and show that in two-layer ReLU networks gradient flow is biased towards solutions that generalize well, but are highly vulnerable to adversarial examples. Our results hold even in cases where the network has many more parameters than training examples. Despite the potential for harmful overfitting in such overparameterized settings, we prove that the implicit bias of gradient flow prevents it. However, the implicit bias also leads to non-robust solutions (susceptible to small adversarial $\ell_2$-perturbations), even though robust networks that fit the data exist.
&lt;/p&gt;</description></item><item><title>&#35780;&#20998;&#25968;&#25454;&#20462;&#21098;&#31639;&#27861;&#22312;&#39640;&#21387;&#32553;&#21306;&#22495;&#22833;&#36133;&#65292;&#36890;&#36807;&#38543;&#26426;&#21270;&#30340;&#26657;&#20934;&#21327;&#35758;&#21487;&#20197;&#25552;&#39640;&#29616;&#26377;&#20462;&#21098;&#31639;&#27861;&#22312;&#35813;&#21306;&#22495;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2302.06960</link><description>&lt;p&gt;
&#25968;&#25454;&#20462;&#21098;&#21644;&#31070;&#32463;&#32553;&#25918;&#23450;&#24459;&#65306;&#22522;&#20110;&#35780;&#20998;&#30340;&#31639;&#27861;&#30340;&#22522;&#26412;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
Data pruning and neural scaling laws: fundamental limitations of score-based algorithms. (arXiv:2302.06960v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06960
&lt;/p&gt;
&lt;p&gt;
&#35780;&#20998;&#25968;&#25454;&#20462;&#21098;&#31639;&#27861;&#22312;&#39640;&#21387;&#32553;&#21306;&#22495;&#22833;&#36133;&#65292;&#36890;&#36807;&#38543;&#26426;&#21270;&#30340;&#26657;&#20934;&#21327;&#35758;&#21487;&#20197;&#25552;&#39640;&#29616;&#26377;&#20462;&#21098;&#31639;&#27861;&#22312;&#35813;&#21306;&#22495;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#20462;&#21098;&#31639;&#27861;&#24120;&#29992;&#20110;&#20943;&#23569;&#20248;&#21270;&#36807;&#31243;&#30340;&#20869;&#23384;&#21644;&#35745;&#31639;&#25104;&#26412;&#12290;&#26368;&#36817;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#38543;&#26426;&#25968;&#25454;&#20462;&#21098;&#20173;&#28982;&#26159;&#19968;&#20010;&#24378;&#22823;&#30340;&#22522;&#20934;&#65292;&#24182;&#22312;&#39640;&#21387;&#32553;&#21306;&#22495;&#20248;&#20110;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#25968;&#25454;&#20462;&#21098;&#26041;&#27861;&#65292;&#21363;&#20445;&#30041;&#20102;&#19981;&#21040;&#25968;&#25454;&#30340;30&#65285;&#30340;&#37096;&#20998;&#12290;&#36825;&#31181;&#21387;&#32553;&#21306;&#22495;&#26368;&#36817;&#24341;&#36215;&#20102;&#24456;&#22810;&#20851;&#27880;&#65292;&#22240;&#20026;&#25968;&#25454;&#20462;&#21098;&#22312;&#25552;&#39640;&#25152;&#35859;&#30340;&#31070;&#32463;&#32553;&#25918;&#23450;&#24459;&#20013;&#30340;&#20316;&#29992;&#65307;&#22312;[Sorscher et al.]&#20013;&#65292;&#20316;&#32773;&#23637;&#31034;&#20102;&#38656;&#35201;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#20462;&#21098;&#31639;&#27861;&#25165;&#33021;&#20987;&#36133;&#26679;&#26412;&#21183;&#24459;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20851;&#27880;&#35780;&#20998;&#25968;&#25454;&#20462;&#21098;&#31639;&#27861;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#21644;&#23454;&#38469;&#19978;&#23637;&#31034;&#20102;&#20026;&#20160;&#20040;&#36825;&#26679;&#30340;&#31639;&#27861;&#22312;&#39640;&#21387;&#32553;&#21306;&#22495;&#22833;&#36133;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25968;&#25454;&#20462;&#21098;&#30340;&#8220;&#27809;&#26377;&#20813;&#36153;&#21320;&#39184;&#8221;&#23450;&#29702;&#65292;&#24182;&#36890;&#36807;&#38543;&#26426;&#21270;&#25552;&#20986;&#20102;&#26657;&#20934;&#21327;&#35758;&#65292;&#20197;&#25552;&#39640;&#29616;&#26377;&#20462;&#21098;&#31639;&#27861;&#22312;&#39640;&#21387;&#32553;&#21306;&#22495;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data pruning algorithms are commonly used to reduce the memory and computational cost of the optimization process. Recent empirical results reveal that random data pruning remains a strong baseline and outperforms most existing data pruning methods in the high compression regime, i.e., where a fraction of $30\%$ or less of the data is kept. This regime has recently attracted a lot of interest as a result of the role of data pruning in improving the so-called neural scaling laws; in [Sorscher et al.], the authors showed the need for high-quality data pruning algorithms in order to beat the sample power law.  In this work, we focus on score-based data pruning algorithms and show theoretically and empirically why such algorithms fail in the high compression regime. We demonstrate ``No Free Lunch" theorems for data pruning and present calibration protocols that enhance the performance of existing pruning algorithms in this high compression regime using randomization.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#20598;&#28982;&#24615;&#21644;&#35748;&#30693;&#24615;&#27495;&#35270;&#65292;&#23558;&#20854;&#20998;&#31867;&#20026;&#25968;&#25454;&#20998;&#24067;&#20013;&#22266;&#26377;&#30340;&#27495;&#35270;&#21644;&#27169;&#22411;&#24320;&#21457;&#36807;&#31243;&#20013;&#30340;&#20915;&#31574;&#23548;&#33268;&#30340;&#27495;&#35270;&#12290;&#36890;&#36807;&#37327;&#21270;&#20598;&#28982;&#24615;&#27495;&#35270;&#30340;&#24615;&#33021;&#38480;&#21046;&#21644;&#21051;&#30011;&#35748;&#30693;&#24615;&#27495;&#35270;&#65292;&#25581;&#31034;&#20102;&#20844;&#24179;&#24178;&#39044;&#30340;&#22522;&#26412;&#38480;&#21046;&#12290;&#30740;&#31350;&#36824;&#24212;&#29992;&#36825;&#31181;&#26041;&#27861;&#35780;&#20272;&#20102;&#29616;&#26377;&#30340;&#20844;&#24179;&#24178;&#39044;&#25514;&#26045;&#65292;&#24182;&#25506;&#31350;&#20102;&#22312;&#23384;&#22312;&#32570;&#22833;&#20540;&#30340;&#25968;&#25454;&#20013;&#30340;&#20844;&#24179;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2301.11781</link><description>&lt;p&gt;
&#20598;&#28982;&#24615;&#21644;&#35748;&#30693;&#24615;&#27495;&#35270;&#65306;&#20844;&#24179;&#24178;&#39044;&#30340;&#22522;&#26412;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
Aleatoric and Epistemic Discrimination: Fundamental Limits of Fairness Interventions. (arXiv:2301.11781v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11781
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#20598;&#28982;&#24615;&#21644;&#35748;&#30693;&#24615;&#27495;&#35270;&#65292;&#23558;&#20854;&#20998;&#31867;&#20026;&#25968;&#25454;&#20998;&#24067;&#20013;&#22266;&#26377;&#30340;&#27495;&#35270;&#21644;&#27169;&#22411;&#24320;&#21457;&#36807;&#31243;&#20013;&#30340;&#20915;&#31574;&#23548;&#33268;&#30340;&#27495;&#35270;&#12290;&#36890;&#36807;&#37327;&#21270;&#20598;&#28982;&#24615;&#27495;&#35270;&#30340;&#24615;&#33021;&#38480;&#21046;&#21644;&#21051;&#30011;&#35748;&#30693;&#24615;&#27495;&#35270;&#65292;&#25581;&#31034;&#20102;&#20844;&#24179;&#24178;&#39044;&#30340;&#22522;&#26412;&#38480;&#21046;&#12290;&#30740;&#31350;&#36824;&#24212;&#29992;&#36825;&#31181;&#26041;&#27861;&#35780;&#20272;&#20102;&#29616;&#26377;&#30340;&#20844;&#24179;&#24178;&#39044;&#25514;&#26045;&#65292;&#24182;&#25506;&#31350;&#20102;&#22312;&#23384;&#22312;&#32570;&#22833;&#20540;&#30340;&#25968;&#25454;&#20013;&#30340;&#20844;&#24179;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#26576;&#20123;&#20154;&#32676;&#20013;&#21487;&#33021;&#34920;&#29616;&#19981;&#20339;&#65292;&#21407;&#22240;&#26159;&#22312;&#27169;&#22411;&#24320;&#21457;&#36807;&#31243;&#20013;&#20570;&#20986;&#30340;&#36873;&#25321;&#21644;&#25968;&#25454;&#20013;&#22266;&#26377;&#30340;&#20559;&#35265;&#12290;&#25105;&#20204;&#23558;&#26426;&#22120;&#23398;&#20064;&#27969;&#31243;&#20013;&#30340;&#27495;&#35270;&#26469;&#28304;&#20998;&#20026;&#20004;&#31867;&#65306;&#20598;&#28982;&#24615;&#27495;&#35270;&#65292;&#21363;&#25968;&#25454;&#20998;&#24067;&#20013;&#22266;&#26377;&#30340;&#27495;&#35270;&#65292;&#21644;&#35748;&#30693;&#24615;&#27495;&#35270;&#65292;&#21363;&#27169;&#22411;&#24320;&#21457;&#36807;&#31243;&#20013;&#20570;&#20986;&#30340;&#20915;&#31574;&#23548;&#33268;&#30340;&#27495;&#35270;&#12290;&#25105;&#20204;&#36890;&#36807;&#30830;&#23450;&#22312;&#23436;&#20840;&#20102;&#35299;&#25968;&#25454;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#65292;&#22312;&#20844;&#24179;&#32422;&#26463;&#19979;&#27169;&#22411;&#30340;&#24615;&#33021;&#38480;&#21046;&#26469;&#37327;&#21270;&#20598;&#28982;&#24615;&#27495;&#35270;&#12290;&#25105;&#20204;&#36890;&#36807;&#24212;&#29992;&#24067;&#33713;&#20811;&#38886;&#23572;&#23545;&#27604;&#32479;&#35745;&#23454;&#39564;&#30340;&#32467;&#26524;&#26469;&#21051;&#30011;&#20598;&#28982;&#24615;&#27495;&#35270;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#35748;&#30693;&#24615;&#27495;&#35270;&#23450;&#20041;&#20026;&#22312;&#24212;&#29992;&#20844;&#24179;&#32422;&#26463;&#26102;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#19982;&#20598;&#28982;&#24615;&#27495;&#35270;&#25152;&#38480;&#23450;&#30340;&#30028;&#38480;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#26041;&#27861;&#24212;&#29992;&#20110;&#35780;&#20272;&#29616;&#26377;&#30340;&#20844;&#24179;&#24178;&#39044;&#25514;&#26045;&#65292;&#24182;&#35843;&#26597;&#20855;&#26377;&#32570;&#22833;&#20540;&#30340;&#25968;&#25454;&#20013;&#30340;&#20844;&#24179;&#39118;&#38505;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;...
&lt;/p&gt;
&lt;p&gt;
Machine learning (ML) models can underperform on certain population groups due to choices made during model development and bias inherent in the data. We categorize sources of discrimination in the ML pipeline into two classes: aleatoric discrimination, which is inherent in the data distribution, and epistemic discrimination, which is due to decisions made during model development. We quantify aleatoric discrimination by determining the performance limits of a model under fairness constraints, assuming perfect knowledge of the data distribution. We demonstrate how to characterize aleatoric discrimination by applying Blackwell's results on comparing statistical experiments. We then quantify epistemic discrimination as the gap between a model's accuracy when fairness constraints are applied and the limit posed by aleatoric discrimination. We apply this approach to benchmark existing fairness interventions and investigate fairness risks in data with missing values. Our results indicate th
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;&#38382;&#39064;&#65292;&#36890;&#36807;&#23558;&#27491;&#20132;&#24615;&#26465;&#20214;&#37325;&#26032;&#34920;&#36848;&#20026;&#31209;&#32422;&#26463;&#65292;&#24182;&#21516;&#26102;&#23545;&#31232;&#30095;&#24615;&#21644;&#31209;&#32422;&#26463;&#36827;&#34892;&#20248;&#21270;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#32039;&#20945;&#30340;&#21322;&#27491;&#23450;&#26494;&#24347;&#26469;&#25552;&#20379;&#39640;&#36136;&#37327;&#30340;&#19978;&#30028;&#65292;&#24403;&#27599;&#20010;&#20027;&#25104;&#20998;&#30340;&#20010;&#20307;&#31232;&#30095;&#24615;&#34987;&#25351;&#23450;&#26102;&#65292;&#25105;&#20204;&#36890;&#36807;&#39069;&#22806;&#30340;&#20108;&#38454;&#38181;&#19981;&#31561;&#24335;&#21152;&#24378;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2209.14790</link><description>&lt;p&gt;
&#22810;&#32452;&#20998;&#30340;&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Sparse PCA With Multiple Components. (arXiv:2209.14790v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.14790
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;&#38382;&#39064;&#65292;&#36890;&#36807;&#23558;&#27491;&#20132;&#24615;&#26465;&#20214;&#37325;&#26032;&#34920;&#36848;&#20026;&#31209;&#32422;&#26463;&#65292;&#24182;&#21516;&#26102;&#23545;&#31232;&#30095;&#24615;&#21644;&#31209;&#32422;&#26463;&#36827;&#34892;&#20248;&#21270;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#32039;&#20945;&#30340;&#21322;&#27491;&#23450;&#26494;&#24347;&#26469;&#25552;&#20379;&#39640;&#36136;&#37327;&#30340;&#19978;&#30028;&#65292;&#24403;&#27599;&#20010;&#20027;&#25104;&#20998;&#30340;&#20010;&#20307;&#31232;&#30095;&#24615;&#34987;&#25351;&#23450;&#26102;&#65292;&#25105;&#20204;&#36890;&#36807;&#39069;&#22806;&#30340;&#20108;&#38454;&#38181;&#19981;&#31561;&#24335;&#21152;&#24378;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;&#26159;&#19968;&#31181;&#29992;&#20110;&#20197;&#21487;&#35299;&#37322;&#30340;&#26041;&#24335;&#35299;&#37322;&#39640;&#32500;&#25968;&#25454;&#38598;&#26041;&#24046;&#30340;&#22522;&#26412;&#25216;&#26415;&#12290;&#36825;&#28041;&#21450;&#35299;&#20915;&#19968;&#20010;&#31232;&#30095;&#24615;&#21644;&#27491;&#20132;&#24615;&#32422;&#26463;&#30340;&#20984;&#26368;&#22823;&#21270;&#38382;&#39064;&#65292;&#20854;&#35745;&#31639;&#22797;&#26434;&#24230;&#38750;&#24120;&#39640;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#26041;&#27861;&#36890;&#36807;&#36845;&#20195;&#35745;&#31639;&#19968;&#20010;&#31232;&#30095;&#20027;&#25104;&#20998;&#24182;&#32553;&#20943;&#21327;&#26041;&#24046;&#30697;&#38453;&#26469;&#35299;&#20915;&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;&#65292;&#20294;&#22312;&#23547;&#25214;&#22810;&#20010;&#30456;&#20114;&#27491;&#20132;&#30340;&#20027;&#25104;&#20998;&#26102;&#65292;&#36825;&#20123;&#26041;&#27861;&#19981;&#33021;&#20445;&#35777;&#25152;&#24471;&#35299;&#30340;&#27491;&#20132;&#24615;&#21644;&#26368;&#20248;&#24615;&#12290;&#25105;&#20204;&#25361;&#25112;&#36825;&#31181;&#29616;&#29366;&#65292;&#36890;&#36807;&#23558;&#27491;&#20132;&#24615;&#26465;&#20214;&#37325;&#26032;&#34920;&#36848;&#20026;&#31209;&#32422;&#26463;&#65292;&#24182;&#21516;&#26102;&#23545;&#31232;&#30095;&#24615;&#21644;&#31209;&#32422;&#26463;&#36827;&#34892;&#20248;&#21270;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#32039;&#20945;&#30340;&#21322;&#27491;&#23450;&#26494;&#24347;&#26469;&#25552;&#20379;&#39640;&#36136;&#37327;&#30340;&#19978;&#30028;&#65292;&#24403;&#27599;&#20010;&#20027;&#25104;&#20998;&#30340;&#20010;&#20307;&#31232;&#30095;&#24615;&#34987;&#25351;&#23450;&#26102;&#65292;&#25105;&#20204;&#36890;&#36807;&#39069;&#22806;&#30340;&#20108;&#38454;&#38181;&#19981;&#31561;&#24335;&#21152;&#24378;&#19978;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#37319;&#29992;&#21478;&#19968;&#31181;&#26041;&#27861;&#26469;&#21152;&#24378;&#19978;&#30028;&#65292;&#25105;&#20204;&#20351;&#29992;&#39069;&#22806;&#30340;&#20108;&#38454;&#38181;&#19981;&#31561;&#24335;&#26469;&#21152;&#24378;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse Principal Component Analysis (sPCA) is a cardinal technique for obtaining combinations of features, or principal components (PCs), that explain the variance of high-dimensional datasets in an interpretable manner. This involves solving a sparsity and orthogonality constrained convex maximization problem, which is extremely computationally challenging. Most existing works address sparse PCA via methods-such as iteratively computing one sparse PC and deflating the covariance matrix-that do not guarantee the orthogonality, let alone the optimality, of the resulting solution when we seek multiple mutually orthogonal PCs. We challenge this status by reformulating the orthogonality conditions as rank constraints and optimizing over the sparsity and rank constraints simultaneously. We design tight semidefinite relaxations to supply high-quality upper bounds, which we strengthen via additional second-order cone inequalities when each PC's individual sparsity is specified. Further, we de
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21452;&#36923;&#36753;&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#23384;&#22312;&#20559;&#24046;&#30340;&#27491;&#21521;&#26080;&#26631;&#35760;&#25968;&#25454;&#12290;&#36890;&#36807;&#36991;&#20813;&#20551;&#35774;&#20542;&#21521;&#24471;&#20998;&#20989;&#25968;&#20026;&#24120;&#25968;&#65292;&#20316;&#32773;&#20849;&#21516;&#20272;&#35745;&#21518;&#39564;&#27010;&#29575;&#21644;&#20542;&#21521;&#24471;&#20998;&#20989;&#25968;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#20272;&#35745;&#26041;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#19982;&#29616;&#26377;&#30340;&#22522;&#20110;&#26399;&#26395;&#26368;&#22823;&#21270;&#26041;&#26696;&#30340;&#26041;&#27861;&#30456;&#27604;&#26159;&#21487;&#27604;&#36739;&#25110;&#26356;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2209.07787</link><description>&lt;p&gt;
&#22522;&#20110;&#21452;&#36923;&#36753;&#22238;&#24402;&#30340;&#26377;&#20559;&#27491;&#26080;&#26631;&#35760;&#25968;&#25454;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Double logistic regression approach to biased positive-unlabeled data. (arXiv:2209.07787v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.07787
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21452;&#36923;&#36753;&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#23384;&#22312;&#20559;&#24046;&#30340;&#27491;&#21521;&#26080;&#26631;&#35760;&#25968;&#25454;&#12290;&#36890;&#36807;&#36991;&#20813;&#20551;&#35774;&#20542;&#21521;&#24471;&#20998;&#20989;&#25968;&#20026;&#24120;&#25968;&#65292;&#20316;&#32773;&#20849;&#21516;&#20272;&#35745;&#21518;&#39564;&#27010;&#29575;&#21644;&#20542;&#21521;&#24471;&#20998;&#20989;&#25968;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#20272;&#35745;&#26041;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#19982;&#29616;&#26377;&#30340;&#22522;&#20110;&#26399;&#26395;&#26368;&#22823;&#21270;&#26041;&#26696;&#30340;&#26041;&#27861;&#30456;&#27604;&#26159;&#21487;&#27604;&#36739;&#25110;&#26356;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;&#21521;&#21644;&#26080;&#26631;&#35760;&#23398;&#20064;&#26159;&#35768;&#22810;&#24212;&#29992;&#20013;&#33258;&#28982;&#20135;&#29983;&#30340;&#37325;&#35201;&#38382;&#39064;&#12290;&#20960;&#20046;&#25152;&#26377;&#29616;&#26377;&#26041;&#27861;&#30340;&#19968;&#20010;&#26174;&#33879;&#38480;&#21046;&#22312;&#20110;&#20551;&#35774;&#20542;&#21521;&#24471;&#20998;&#20989;&#25968;&#26159;&#24120;&#25968;&#65288;SCAR&#20551;&#35774;&#65289;&#65292;&#36825;&#22312;&#35768;&#22810;&#23454;&#38469;&#24773;&#20917;&#19979;&#26159;&#19981;&#29616;&#23454;&#30340;&#12290;&#20026;&#20102;&#36991;&#20813;&#36825;&#31181;&#20551;&#35774;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#21442;&#25968;&#21270;&#26041;&#27861;&#26469;&#20849;&#21516;&#20272;&#35745;&#21518;&#39564;&#27010;&#29575;&#21644;&#20542;&#21521;&#24471;&#20998;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#24403;&#20004;&#20010;&#20989;&#25968;&#20855;&#26377;&#30456;&#21516;&#30340;&#21442;&#25968;&#24418;&#24335;&#26102;&#65288;&#20363;&#22914;&#20855;&#26377;&#19981;&#21516;&#21442;&#25968;&#30340;&#36923;&#36753;&#20989;&#25968;&#65289;&#65292;&#30456;&#24212;&#30340;&#21442;&#25968;&#26159;&#21487;&#35782;&#21035;&#30340;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#20272;&#35745;&#26041;&#27861;&#65306;&#32852;&#21512;&#26368;&#22823;&#20284;&#28982;&#26041;&#27861;&#21644;&#22522;&#20110;&#20004;&#20010;Fisher&#19968;&#33268;&#34920;&#36798;&#24335;&#30340;&#20132;&#26367;&#26368;&#22823;&#21270;&#30340;&#31532;&#20108;&#31181;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#19982;&#22522;&#20110;&#26399;&#26395;&#26368;&#22823;&#21270;&#26041;&#26696;&#30340;&#29616;&#26377;&#26041;&#27861;&#21487;&#27604;&#36739;&#25110;&#26356;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;
Positive and unlabelled learning is an important problem which arises naturally in many applications. The significant limitation of almost all existing methods lies in assuming that the propensity score function is constant (SCAR assumption), which is unrealistic in many practical situations. Avoiding this assumption, we consider parametric approach to the problem of joint estimation of posterior probability and propensity score functions. We show that under mild assumptions when both functions have the same parametric form (e.g. logistic with different parameters) the corresponding parameters are identifiable. Motivated by this, we propose two approaches to their estimation: joint maximum likelihood method and the second approach based on alternating maximization of two Fisher consistent expressions. Our experimental results show that the proposed methods are comparable or better than the existing methods based on Expectation-Maximisation scheme.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#27491;&#20132;&#21305;&#37197;&#36861;&#36394;&#30340;&#20998;&#24067;&#24335;&#26041;&#26696;&#22312;&#39640;&#32500;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#36866;&#24403;&#30340;&#20551;&#35774;&#65292;&#20998;&#24067;&#24335;OMP&#26041;&#26696;&#33021;&#22815;&#20197;&#36739;&#20302;&#30340;&#20449;&#22122;&#27604;&#19979;&#23454;&#29616;&#32447;&#24615;&#36890;&#20449;&#22797;&#26434;&#24230;&#65292;&#24182;&#33021;&#19982;&#26356;&#22797;&#26434;&#30340;&#26041;&#27861;&#30456;&#31454;&#20105;&#12290;</title><link>http://arxiv.org/abs/2209.07230</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;OMP&#30340;&#24674;&#22797;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Recovery Guarantees for Distributed-OMP. (arXiv:2209.07230v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.07230
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#27491;&#20132;&#21305;&#37197;&#36861;&#36394;&#30340;&#20998;&#24067;&#24335;&#26041;&#26696;&#22312;&#39640;&#32500;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#36866;&#24403;&#30340;&#20551;&#35774;&#65292;&#20998;&#24067;&#24335;OMP&#26041;&#26696;&#33021;&#22815;&#20197;&#36739;&#20302;&#30340;&#20449;&#22122;&#27604;&#19979;&#23454;&#29616;&#32447;&#24615;&#36890;&#20449;&#22797;&#26434;&#24230;&#65292;&#24182;&#33021;&#19982;&#26356;&#22797;&#26434;&#30340;&#26041;&#27861;&#30456;&#31454;&#20105;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#27491;&#20132;&#21305;&#37197;&#36861;&#36394;(OMP)&#30340;&#39640;&#32500;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#30340;&#20998;&#24067;&#24335;&#26041;&#26696;&#12290;&#36825;&#31181;&#26041;&#26696;&#29305;&#21035;&#36866;&#29992;&#20110;&#26377;&#35745;&#31639;&#21644;&#36890;&#20449;&#38480;&#21046;&#30340;&#26411;&#31471;&#26426;&#22120;&#36830;&#25509;&#21040;&#20013;&#22830;&#34701;&#21512;&#20013;&#24515;&#30340;&#35774;&#32622;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#36866;&#24403;&#30340;&#20551;&#35774;&#19979;&#65292;&#20998;&#24067;&#24335;OMP&#26041;&#26696;&#33021;&#22815;&#20197;&#19982;&#31232;&#30095;&#24230;&#32447;&#24615;&#21644;&#32500;&#24230;&#23545;&#25968;&#25104;&#27604;&#20363;&#30340;&#36890;&#20449;&#24674;&#22797;&#22238;&#24402;&#21521;&#37327;&#30340;&#25903;&#25345;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#21363;&#20351;&#22312;&#20449;&#22122;&#27604;&#20302;&#30340;&#24773;&#20917;&#19979;&#65292;&#21333;&#20010;&#26426;&#22120;&#20063;&#26080;&#27861;&#26816;&#27979;&#21040;&#25903;&#25345;&#26102;&#65292;&#36825;&#20173;&#28982;&#25104;&#31435;&#12290;&#25105;&#20204;&#30340;&#27169;&#25311;&#32467;&#26524;&#34920;&#26126;&#65292;&#20998;&#24067;&#24335;OMP&#26041;&#26696;&#19982;&#26356;&#35745;&#31639;&#23494;&#38598;&#30340;&#26041;&#27861;&#31454;&#20105;&#65292;&#24182;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#29978;&#33267;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study distributed schemes for high-dimensional sparse linear regression, based on orthogonal matching pursuit (OMP). Such schemes are particularly suited for settings where a central fusion center is connected to end machines, that have both computation and communication limitations. We prove that under suitable assumptions, distributed-OMP schemes recover the support of the regression vector with communication per machine linear in its sparsity and logarithmic in the dimension. Remarkably, this holds even at low signal-to-noise-ratios, where individual machines are unable to detect the support. Our simulations show that distributed-OMP schemes are competitive with more computationally intensive methods, and in some cases even outperform them.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;R\'enyi&#21644;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#20013;&#36890;&#36807;&#27927;&#29260;&#25552;&#20986;&#20102;&#26356;&#24378;&#38544;&#31169;&#25918;&#22823;&#30340;&#26041;&#27861;&#65292;&#24182;&#23545;&#29702;&#35770;&#21644;&#25968;&#20540;&#36827;&#34892;&#20102;&#25913;&#36827;&#21644;&#20248;&#21270;&#12290;</title><link>http://arxiv.org/abs/2208.04591</link><description>&lt;p&gt;
R\'enyi&#21644;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#20013;&#36890;&#36807;&#27927;&#29260;&#23454;&#29616;&#26356;&#24378;&#38544;&#31169;&#25918;&#22823;&#25928;&#26524;
&lt;/p&gt;
&lt;p&gt;
Stronger Privacy Amplification by Shuffling for R\'enyi and Approximate Differential Privacy. (arXiv:2208.04591v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.04591
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;R\'enyi&#21644;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#20013;&#36890;&#36807;&#27927;&#29260;&#25552;&#20986;&#20102;&#26356;&#24378;&#38544;&#31169;&#25918;&#22823;&#30340;&#26041;&#27861;&#65292;&#24182;&#23545;&#29702;&#35770;&#21644;&#25968;&#20540;&#36827;&#34892;&#20102;&#25913;&#36827;&#21644;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#30340;&#27927;&#29260;&#27169;&#22411;&#20316;&#20026;&#26631;&#20934;&#26412;&#22320;&#21644;&#38598;&#20013;&#27169;&#22411;&#20043;&#38388;&#30340;&#19968;&#31181;&#20013;&#38388;&#20449;&#20219;&#27169;&#22411;&#65292;&#24341;&#36215;&#20102;&#26497;&#22823;&#30340;&#20851;&#27880;&#12290;&#22312;&#35813;&#27169;&#22411;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#32467;&#26524;&#26159;&#65292;&#38543;&#26426;&#27927;&#29260;&#26412;&#22320;&#38543;&#26426;&#21270;&#25968;&#25454;&#21487;&#20197;&#25918;&#22823;&#24046;&#20998;&#38544;&#31169;&#30340;&#20445;&#35777;&#12290;&#36825;&#31181;&#25918;&#22823;&#25928;&#26524;&#24847;&#21619;&#30528;&#23545;&#20110;&#21311;&#21517;&#36129;&#29486;&#25968;&#25454;&#30340;&#31995;&#32479;&#32780;&#35328;&#65292;&#38544;&#31169;&#20445;&#35777;&#20250;&#26356;&#21152;&#24378;&#22823;&#12290;&#26412;&#30740;&#31350;&#22312;&#29702;&#35770;&#21644;&#25968;&#20540;&#19978;&#25913;&#36827;&#20102;&#27927;&#29260;&#23548;&#33268;&#30340;&#38544;&#31169;&#25918;&#22823;&#25928;&#26524;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#39318;&#27425;&#25552;&#20986;&#20102;LDP&#38543;&#26426;&#21270;&#22120;&#27927;&#29260;&#36755;&#20986;&#30340;R\'enyi&#24046;&#20998;&#38544;&#31169;&#21442;&#25968;&#30340;&#28176;&#36817;&#26368;&#20248;&#20998;&#26512;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#23545;&#38544;&#31169;&#25918;&#22823;&#25928;&#26524;&#36827;&#34892;&#20102;&#26032;&#30340;&#20998;&#26512;&#65292;&#25913;&#36827;&#20102;[FMT20]&#30340;&#25216;&#26415;&#65292;&#24182;&#22312;&#25152;&#26377;&#21442;&#25968;&#35774;&#32622;&#19979;&#24471;&#21040;&#20102;&#26356;&#32039;&#23494;&#30340;&#25968;&#20540;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
The shuffle model of differential privacy has gained significant interest as an intermediate trust model between the standard local and central models [EFMRTT19; CSUZZ19]. A key result in this model is that randomly shuffling locally randomized data amplifies differential privacy guarantees. Such amplification implies substantially stronger privacy guarantees for systems in which data is contributed anonymously [BEMMRLRKTS17].  In this work, we improve the state of the art privacy amplification by shuffling results both theoretically and numerically. Our first contribution is the first asymptotically optimal analysis of the R\'enyi differential privacy parameters for the shuffled outputs of LDP randomizers. Our second contribution is a new analysis of privacy amplification by shuffling. This analysis improves on the techniques of [FMT20] and leads to tighter numerical bounds in all parameter settings.
&lt;/p&gt;</description></item><item><title>DAMNETS&#26159;&#19968;&#31181;&#29992;&#20110;&#29983;&#25104;&#39532;&#23572;&#21487;&#22827;&#32593;&#32476;&#26102;&#38388;&#24207;&#21015;&#30340;&#28145;&#24230;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#36890;&#36807;&#22312;&#30495;&#23454;&#25968;&#25454;&#21644;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#36229;&#36807;&#31454;&#20105;&#26041;&#27861;&#65292;&#36798;&#21040;&#20102;&#35774;&#35745;&#28789;&#27963;&#19988;&#21487;&#25193;&#23637;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#30446;&#26631;&#12290;</title><link>http://arxiv.org/abs/2203.15009</link><description>&lt;p&gt;
DAMNETS&#65306;&#19968;&#31181;&#29992;&#20110;&#29983;&#25104;&#39532;&#23572;&#21487;&#22827;&#32593;&#32476;&#26102;&#38388;&#24207;&#21015;&#30340;&#28145;&#24230;&#33258;&#22238;&#24402;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
DAMNETS: A Deep Autoregressive Model for Generating Markovian Network Time Series. (arXiv:2203.15009v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.15009
&lt;/p&gt;
&lt;p&gt;
DAMNETS&#26159;&#19968;&#31181;&#29992;&#20110;&#29983;&#25104;&#39532;&#23572;&#21487;&#22827;&#32593;&#32476;&#26102;&#38388;&#24207;&#21015;&#30340;&#28145;&#24230;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#36890;&#36807;&#22312;&#30495;&#23454;&#25968;&#25454;&#21644;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#36229;&#36807;&#31454;&#20105;&#26041;&#27861;&#65292;&#36798;&#21040;&#20102;&#35774;&#35745;&#28789;&#27963;&#19988;&#21487;&#25193;&#23637;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27169;&#22411;&#22312;&#32593;&#32476;&#26102;&#38388;&#24207;&#21015;&#65288;&#20063;&#31216;&#20026;&#21160;&#24577;&#22270;&#65289;&#20013;&#20855;&#26377;&#24040;&#22823;&#30340;&#28508;&#21147;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#27969;&#34892;&#30149;&#23398;&#12289;&#29983;&#29289;&#23398;&#21644;&#32463;&#27982;&#23398;&#31561;&#39046;&#22495;&#65292;&#20854;&#20013;&#22797;&#26434;&#30340;&#22522;&#20110;&#22270;&#30340;&#21160;&#24577;&#26159;&#26680;&#24515;&#30740;&#31350;&#23545;&#35937;&#12290;&#30001;&#20110;&#25968;&#25454;&#30340;&#39640;&#32500;&#24230;&#20197;&#21450;&#34920;&#31034;&#26102;&#38388;&#20381;&#36182;&#24615;&#21644;&#36793;&#38469;&#32593;&#32476;&#32467;&#26500;&#30340;&#38656;&#35201;&#65292;&#35774;&#35745;&#28789;&#27963;&#19988;&#21487;&#25193;&#23637;&#30340;&#29983;&#25104;&#27169;&#22411;&#26159;&#19968;&#39033;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;DAMNETS&#30340;&#21487;&#25193;&#23637;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#22312;&#30495;&#23454;&#25968;&#25454;&#21644;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#30340;&#25152;&#26377;&#26679;&#26412;&#36136;&#37327;&#25351;&#26631;&#19978;&#34920;&#29616;&#20248;&#20110;&#31454;&#20105;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative models for network time series (also known as dynamic graphs) have tremendous potential in fields such as epidemiology, biology and economics, where complex graph-based dynamics are core objects of study. Designing flexible and scalable generative models is a very challenging task due to the high dimensionality of the data, as well as the need to represent temporal dependencies and marginal network structure. Here we introduce DAMNETS, a scalable deep generative model for network time series. DAMNETS outperforms competing methods on all of our measures of sample quality, over both real and synthetic data sets.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#20989;&#25968;&#38236;&#20687;&#19978;&#21319;&#30340;&#26222;&#36866;&#26694;&#26550;(FMA-PG)&#65292;&#26500;&#24314;&#20102;&#19968;&#31995;&#21015;&#26367;&#20195;&#20989;&#25968;&#65292;&#36825;&#20123;&#20989;&#25968;&#21487;&#20197;&#23454;&#29616;&#31574;&#30053;&#25913;&#36827;&#65292;&#24182;&#19988;&#19981;&#21463;&#31574;&#30053;&#21442;&#25968;&#21270;&#36873;&#25321;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#33391;&#22909;&#30340;&#24615;&#33021;&#21644;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2108.05828</link><description>&lt;p&gt;
&#19968;&#31867;&#31283;&#23450;&#39640;&#25928;&#30340;&#24378;&#21270;&#23398;&#20064;&#29992;&#26367;&#20195;&#20989;&#25968;&#30340;&#26222;&#36866;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A general class of surrogate functions for stable and efficient reinforcement learning. (arXiv:2108.05828v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.05828
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#20989;&#25968;&#38236;&#20687;&#19978;&#21319;&#30340;&#26222;&#36866;&#26694;&#26550;(FMA-PG)&#65292;&#26500;&#24314;&#20102;&#19968;&#31995;&#21015;&#26367;&#20195;&#20989;&#25968;&#65292;&#36825;&#20123;&#20989;&#25968;&#21487;&#20197;&#23454;&#29616;&#31574;&#30053;&#25913;&#36827;&#65292;&#24182;&#19988;&#19981;&#21463;&#31574;&#30053;&#21442;&#25968;&#21270;&#36873;&#25321;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#33391;&#22909;&#30340;&#24615;&#33021;&#21644;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#20381;&#36182;&#20110;&#19968;&#31995;&#21015;&#26367;&#20195;&#20989;&#25968;&#30340;&#26368;&#22823;&#21270;&#12290;&#36817;&#24180;&#26469;&#65292;&#25552;&#20986;&#20102;&#35768;&#22810;&#36825;&#26679;&#30340;&#26367;&#20195;&#20989;&#25968;&#65292;&#22823;&#22810;&#25968;&#27809;&#26377;&#24378;&#26377;&#21147;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#20174;&#32780;&#23548;&#33268;&#20102;TRPO&#12289;PPO&#25110;MPO&#31561;&#31639;&#27861;&#30340;&#20986;&#29616;&#12290;&#25105;&#20204;&#19981;&#26159;&#35774;&#35745;&#21478;&#19968;&#20010;&#26367;&#20195;&#20989;&#25968;&#65292;&#32780;&#26159;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#20989;&#25968;&#38236;&#20687;&#19978;&#21319;&#30340;&#26222;&#36866;&#26694;&#26550;&#65288;FMA-PG&#65289;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#19968;&#25972;&#22871;&#26367;&#20195;&#20989;&#25968;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#26367;&#20195;&#20989;&#25968;&#65292;&#20351;&#20854;&#33021;&#22815;&#20445;&#35777;&#31574;&#30053;&#25913;&#36827;&#65292;&#36825;&#26159;&#22823;&#22810;&#25968;&#29616;&#26377;&#26367;&#20195;&#20989;&#25968;&#25152;&#27809;&#26377;&#30340;&#29305;&#24615;&#12290;&#20851;&#38190;&#26159;&#65292;&#36825;&#20123;&#20445;&#35777;&#19981;&#21463;&#31574;&#30053;&#21442;&#25968;&#21270;&#36873;&#25321;&#30340;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;FMA-PG&#30340;&#29305;&#23450;&#23454;&#20363;&#24674;&#22797;&#20102;&#37325;&#35201;&#30340;&#23454;&#29616;&#21551;&#21457;&#24335;&#26041;&#27861;&#65288;&#20363;&#22914;&#65292;&#20351;&#29992;&#21069;&#21521;&#21644;&#21453;&#21521;KL&#25955;&#24230;&#65289;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#20855;&#26377;&#39069;&#22806;&#29702;&#24819;&#24615;&#36136;&#30340;TRPO&#21464;&#31181;&#12290;&#36890;&#36807;&#22312;&#31616;&#21333;&#36125;&#21494;&#26031;&#38382;&#39064;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;FMA-PG&#20135;&#29983;&#30340;&#31639;&#27861;&#23454;&#20363;&#12290;&#35813;&#26694;&#26550;&#20063;&#25903;&#25345;&#20854;&#20182;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Common policy gradient methods rely on the maximization of a sequence of surrogate functions. In recent years, many such surrogate functions have been proposed, most without strong theoretical guarantees, leading to algorithms such as TRPO, PPO or MPO. Rather than design yet another surrogate function, we instead propose a general framework (FMA-PG) based on functional mirror ascent that gives rise to an entire family of surrogate functions. We construct surrogate functions that enable policy improvement guarantees, a property not shared by most existing surrogate functions. Crucially, these guarantees hold regardless of the choice of policy parameterization. Moreover, a particular instantiation of FMA-PG recovers important implementation heuristics (e.g., using forward vs reverse KL divergence) resulting in a variant of TRPO with additional desirable properties. Via experiments on simple bandit problems, we evaluate the algorithms instantiated by FMA-PG. The proposed framework also su
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#28857;&#20113;&#25968;&#25454;&#20013;&#20272;&#35745;&#27969;&#24418;Helmholtzian&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21152;&#26435;1-Laplacian&#26500;&#24314;&#20102;&#22270;Helmholtzian&#20316;&#20026;&#36830;&#32493;&#31639;&#23376;&#30340;&#19968;&#33268;&#20272;&#35745;&#22120;&#65292;&#24182;&#21033;&#29992;Helmholtz-Hodge&#23450;&#29702;&#23545;&#27969;&#21644;&#21521;&#37327;&#22330;&#36827;&#34892;&#20998;&#26512;&#12290;&#36890;&#36807;&#35813;&#26041;&#27861;&#65292;&#21487;&#20197;&#23545;&#27969;&#36827;&#34892;&#24179;&#28369;&#12289;&#39044;&#27979;&#21644;&#29305;&#24449;&#25552;&#21462;&#12290;</title><link>http://arxiv.org/abs/2103.07626</link><description>&lt;p&gt;
Helmholtzian&#29305;&#24449;&#22270;&#65306;&#20174;&#28857;&#20113;&#25968;&#25454;&#20013;&#21457;&#29616;&#25299;&#25169;&#29305;&#24449;&#21644;&#36793;&#32536;&#27969;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Helmholtzian Eigenmap: Topological feature discovery &amp; edge flow learning from point cloud data. (arXiv:2103.07626v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2103.07626
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#28857;&#20113;&#25968;&#25454;&#20013;&#20272;&#35745;&#27969;&#24418;Helmholtzian&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21152;&#26435;1-Laplacian&#26500;&#24314;&#20102;&#22270;Helmholtzian&#20316;&#20026;&#36830;&#32493;&#31639;&#23376;&#30340;&#19968;&#33268;&#20272;&#35745;&#22120;&#65292;&#24182;&#21033;&#29992;Helmholtz-Hodge&#23450;&#29702;&#23545;&#27969;&#21644;&#21521;&#37327;&#22330;&#36827;&#34892;&#20998;&#26512;&#12290;&#36890;&#36807;&#35813;&#26041;&#27861;&#65292;&#21487;&#20197;&#23545;&#27969;&#36827;&#34892;&#24179;&#28369;&#12289;&#39044;&#27979;&#21644;&#29305;&#24449;&#25552;&#21462;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27969;&#24418;Helmholtzian&#65288;1-Laplacian&#65289;&#31639;&#23376;$ \Delta_1 $&#23558;Laplace-Beltrami&#31639;&#23376;&#20248;&#38597;&#22320;&#24191;&#20041;&#21270;&#21040;&#27969;&#24418;$ \mathcal M $&#19978;&#30340;&#21521;&#37327;&#22330;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36890;&#36807;&#21152;&#26435;1-Laplacian $ \mathcal L_1 $&#20174;&#28857;&#20113;&#25968;&#25454;&#20272;&#35745;&#27969;&#24418;Helmholtzian&#30340;&#26041;&#27861;&#12290;&#34429;&#28982;&#24050;&#32463;&#24341;&#20837;&#21644;&#30740;&#31350;&#20102;&#39640;&#38454;Laplacian&#65292;&#20294;&#26412;&#24037;&#20316;&#26159;&#39318;&#27425;&#25552;&#20986;&#20102;&#20174;&#21333;&#32431;&#22797;&#21512;&#29289;&#26500;&#24314;&#30340;&#22270;Helmholtzian&#20316;&#20026;&#36830;&#32493;&#31639;&#23376;&#22312;&#38750;&#21442;&#25968;&#35774;&#32622;&#20013;&#30340;&#19968;&#33268;&#20272;&#35745;&#22120;&#12290;&#20855;&#22791;&#20851;&#20110;$ \mathcal M $&#30340;&#20960;&#20309;&#21644;&#25299;&#25169;&#20449;&#24687;&#30340;Helmholtzian&#26159;&#36890;&#36807;Helmholtz-Hodge&#23450;&#29702;&#23545;$ \mathcal M $&#19978;&#30340;&#27969;&#21644;&#21521;&#37327;&#22330;&#36827;&#34892;&#20998;&#26512;&#30340;&#26377;&#29992;&#24037;&#20855;&#12290;&#27492;&#22806;&#65292;$ \mathcal L_1 $&#20801;&#35768;&#23545;&#27969;&#36827;&#34892;&#24179;&#28369;&#12289;&#39044;&#27979;&#21644;&#29305;&#24449;&#25552;&#21462;&#12290;&#25105;&#20204;&#22312;&#20855;&#26377;&#38750;&#24179;&#20961;&#25299;&#25169;&#32467;&#26500;&#30340;&#22823;&#37327;&#21512;&#25104;&#21644;&#30495;&#23454;&#28857;&#20113;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#36825;&#20123;&#21487;&#33021;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#20381;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
The manifold Helmholtzian (1-Laplacian) operator $\Delta_1$ elegantly generalizes the Laplace-Beltrami operator to vector fields on a manifold $\mathcal M$. In this work, we propose the estimation of the manifold Helmholtzian from point cloud data by a weighted 1-Laplacian $\mathcal L_1$. While higher order Laplacians have been introduced and studied, this work is the first to present a graph Helmholtzian constructed from a simplicial complex as a consistent estimator for the continuous operator in a non-parametric setting. Equipped with the geometric and topological information about $\mathcal M$, the Helmholtzian is a useful tool for the analysis of flows and vector fields on $\mathcal M$ via the Helmholtz-Hodge theorem. In addition, the $\mathcal L_1$ allows the smoothing, prediction, and feature extraction of the flows. We demonstrate these possibilities on substantial sets of synthetic and real point cloud datasets with non-trivial topological structures; and provide theoretical r
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#24102;&#24322;&#36136;&#22122;&#22768;&#30340;&#39640;&#32500;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#38382;&#39064;&#65292;&#21253;&#25324;&#31232;&#30095;&#21644;&#20302;&#31209;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#12290;&#30740;&#31350;&#32773;&#25552;&#20986;&#20102;&#26032;&#39062;&#30340;"&#20122;&#39640;&#26031;"&#20272;&#35745;&#36895;&#29575;&#65292;&#24182;&#22312;&#19981;&#21516;&#27010;&#29575;&#19979;&#26377;&#25928;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#36817;&#20248;&#30340;&#22788;&#29702;&#26041;&#27861;&#29992;&#20110;&#26377;&#22122;&#22768;&#30340;&#40065;&#26834;&#30697;&#38453;&#23436;&#25104;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2012.06750</link><description>&lt;p&gt;
&#24322;&#24120;&#40065;&#26834;&#30340;&#31232;&#30095;/&#20302;&#31209;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#21644;&#40065;&#26834;&#30697;&#38453;&#23436;&#25104;
&lt;/p&gt;
&lt;p&gt;
Outlier-robust sparse/low-rank least-squares regression and robust matrix completion. (arXiv:2012.06750v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2012.06750
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#24102;&#24322;&#36136;&#22122;&#22768;&#30340;&#39640;&#32500;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#38382;&#39064;&#65292;&#21253;&#25324;&#31232;&#30095;&#21644;&#20302;&#31209;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#12290;&#30740;&#31350;&#32773;&#25552;&#20986;&#20102;&#26032;&#39062;&#30340;"&#20122;&#39640;&#26031;"&#20272;&#35745;&#36895;&#29575;&#65292;&#24182;&#22312;&#19981;&#21516;&#27010;&#29575;&#19979;&#26377;&#25928;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#36817;&#20248;&#30340;&#22788;&#29702;&#26041;&#27861;&#29992;&#20110;&#26377;&#22122;&#22768;&#30340;&#40065;&#26834;&#30697;&#38453;&#23436;&#25104;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#20855;&#26377;&#24322;&#36136;&#22122;&#22768;&#30340;&#20122;&#39640;&#26031;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#20013;&#30740;&#31350;&#39640;&#32500;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#12290;&#24403;&#26631;&#31614;&#30340;&#19968;&#37096;&#20998;&#21463;&#21040;&#23545;&#25239;&#24615;&#27745;&#26579;&#26102;&#65292;&#23427;&#21253;&#25324;$s$-&#31232;&#30095;&#21644;$r$-&#20302;&#31209;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26032;&#30340;&#20056;&#31215;&#36807;&#31243;&#30340;&#30697;&#38453;&#20998;&#35299;&#30340;&#36857;&#22238;&#24402;&#30340;&#26032;&#29702;&#35770;&#24212;&#29992;&#12290;&#23545;&#20110;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26032;&#39062;&#30340;"&#20122;&#39640;&#26031;"&#20272;&#35745;&#36895;&#29575;&#24418;&#24335;$r(n,d_{e})+\sqrt{\log(1/\delta)/n}+\epsilon\log(1/\epsilon)$&#65292;&#20197;&#33267;&#23569;&#27010;&#29575;$1-\delta$&#25104;&#31435;&#12290;&#36825;&#37324;&#65292;$r(n,d_{e})$&#26159;&#20316;&#20026;&#26377;&#25928;&#32500;&#24230;$d_{e}$&#30340;&#20989;&#25968;&#32780;&#29420;&#31435;&#20110;&#22833;&#36133;&#27010;&#29575;$\delta$&#30340;&#26368;&#20248;&#26080;&#27745;&#26579;&#36895;&#29575;&#12290;&#36825;&#20123;&#36895;&#29575;&#22312;$\delta$&#19978;&#26159;&#19968;&#33268;&#26377;&#25928;&#30340;&#65292;&#21363;&#20272;&#35745;&#22120;&#30340;&#35843;&#20248;&#19981;&#20381;&#36182;&#20110;$\delta$&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#32771;&#34385;&#20855;&#26377;&#38750;&#22343;&#21248;&#37319;&#26679;&#30340;&#26377;&#22122;&#22768;&#30340;&#40065;&#26834;&#30697;&#38453;&#23436;&#25104;&#38382;&#39064;&#12290;&#22914;&#26524;&#21482;&#23545;&#20302;&#31209;&#30697;&#38453;&#24863;&#20852;&#36259;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#36817;&#20248;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
We study high-dimensional least-squares regression within a subgaussian statistical learning framework with heterogeneous noise. It includes $s$-sparse and $r$-low-rank least-squares regression when a fraction $\epsilon$ of the labels are adversarially contaminated. We also present a novel theory of trace-regression with matrix decomposition based on a new application of the product process. For these problems, we show novel near-optimal "subgaussian" estimation rates of the form $r(n,d_{e})+\sqrt{\log(1/\delta)/n}+\epsilon\log(1/\epsilon)$, valid with probability at least $1-\delta$. Here, $r(n,d_{e})$ is the optimal uncontaminated rate as a function of the effective dimension $d_{e}$ but independent of the failure probability $\delta$. These rates are valid uniformly on $\delta$, i.e., the estimators' tuning do not depend on $\delta$. Lastly, we consider noisy robust matrix completion with non-uniform sampling. If only the low-rank matrix is of interest, we present a novel near-optim
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026;&#21512;&#25104;&#24178;&#39044;&#30340;&#22240;&#26524;&#26694;&#26550;&#65292;&#33021;&#22815;&#22312;&#35266;&#23519;&#21040;&#27599;&#20010;&#21333;&#20803;&#26368;&#22810;&#20004;&#20010;&#24178;&#39044;&#25514;&#26045;&#30340;&#24773;&#20917;&#19979;&#25512;&#26029;&#27599;&#20010;&#21333;&#20803;&#23545;&#27599;&#20010;&#24178;&#39044;&#25514;&#26045;&#30340;&#39044;&#26399;&#28508;&#22312;&#32467;&#26524;&#65292;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;</title><link>http://arxiv.org/abs/2006.07691</link><description>&lt;p&gt;
&#21512;&#25104;&#24178;&#39044;
&lt;/p&gt;
&lt;p&gt;
Synthetic Interventions. (arXiv:2006.07691v6 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.07691
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026;&#21512;&#25104;&#24178;&#39044;&#30340;&#22240;&#26524;&#26694;&#26550;&#65292;&#33021;&#22815;&#22312;&#35266;&#23519;&#21040;&#27599;&#20010;&#21333;&#20803;&#26368;&#22810;&#20004;&#20010;&#24178;&#39044;&#25514;&#26045;&#30340;&#24773;&#20917;&#19979;&#25512;&#26029;&#27599;&#20010;&#21333;&#20803;&#23545;&#27599;&#20010;&#24178;&#39044;&#25514;&#26045;&#30340;&#39044;&#26399;&#28508;&#22312;&#32467;&#26524;&#65292;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32771;&#34385;&#19968;&#20010;&#25317;&#26377;$N$&#20010;&#24322;&#36136;&#21333;&#20803;&#65288;&#20363;&#22914;&#20010;&#20307;&#25110;&#23376;&#32676;&#20307;&#65289;&#21644;$D$&#20010;&#24178;&#39044;&#25514;&#26045;&#65288;&#20363;&#22914;&#31038;&#20250;&#32463;&#27982;&#25919;&#31574;&#65289;&#30340;&#24773;&#26223;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#23398;&#20064;&#27599;&#20010;&#21333;&#20803;&#23545;&#27599;&#20010;&#24178;&#39044;&#25514;&#26045;&#30340;&#39044;&#26399;&#28508;&#22312;&#32467;&#26524;&#65292;&#24635;&#20849;&#26377;$N \times D$&#20010;&#22240;&#26524;&#21442;&#25968;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22240;&#26524;&#26694;&#26550;&#8212;&#8212;&#21512;&#25104;&#24178;&#39044;&#65288;SI&#65289;&#65292;&#20197;&#25512;&#26029;&#36825;$N \times D$&#20010;&#22240;&#26524;&#21442;&#25968;&#65292;&#21516;&#26102;&#20165;&#35266;&#23519;&#27599;&#20010;&#21333;&#20803;&#22312;&#26368;&#22810;&#20004;&#20010;&#24178;&#39044;&#25514;&#26045;&#19979;&#30340;&#24773;&#20917;&#65292;&#19982;$D$&#26080;&#20851;&#12290;&#24403;&#20010;&#24615;&#21270;&#27700;&#24179;&#22686;&#21152;&#26102;&#65292;&#36825;&#23558;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#22312;&#19968;&#20010;&#26032;&#30340;&#24352;&#37327;&#22240;&#23376;&#27169;&#22411;&#19979;&#65292;&#36328;&#21333;&#20803;&#12289;&#32467;&#26524;&#21644;&#24178;&#39044;&#25514;&#26045;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;$N \times D$&#20010;&#22240;&#26524;&#21442;&#25968;&#30340;&#35782;&#21035;&#32467;&#26524;&#65292;&#24182;&#22312;&#38468;&#21152;&#26465;&#20214;&#19979;&#35777;&#26126;&#20102;&#25105;&#20204;&#20272;&#35745;&#20540;&#30340;&#26377;&#38480;&#26679;&#26412;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#36824;&#20801;&#35768;&#23384;&#22312;&#20915;&#23450;&#24178;&#39044;&#20998;&#37197;&#26041;&#24335;&#30340;&#28508;&#22312;&#28151;&#28102;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consider a setting with $N$ heterogeneous units (e.g., individuals, sub-populations) and $D$ interventions (e.g., socio-economic policies). Our goal is to learn the expected potential outcome associated with every intervention on every unit, totaling $N \times D$ causal parameters. Towards this, we present a causal framework, synthetic interventions (SI), to infer these $N \times D$ causal parameters while only observing each of the $N$ units under at most two interventions, independent of $D$. This can be significant as the number of interventions, i.e., level of personalization, grows. Under a novel tensor factor model across units, outcomes, and interventions, we prove an identification result for each of these $N \times D$ causal parameters, establish finite-sample consistency of our estimator along with asymptotic normality under additional conditions. Importantly, our estimator also allows for latent confounders that determine how interventions are assigned. The estimator is furt
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#37325;&#35775;&#20102;&#22810;&#26234;&#33021;&#20307;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#21442;&#25968;&#20849;&#20139;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#26234;&#33021;&#20307;&#25351;&#31034;&#20449;&#21495;&#23454;&#29616;&#20102;&#22312;&#19981;&#21516;&#31574;&#30053;&#32593;&#32476;&#20849;&#20139;&#21442;&#25968;&#30340;&#21516;&#26102;&#23398;&#20064;&#19981;&#21516;&#31574;&#30053;&#25110;&#20219;&#21153;&#30340;&#33021;&#21147;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#36825;&#20123;&#26041;&#27861;&#22312;&#24322;&#26500;&#35266;&#27979;&#21644;&#34892;&#21160;&#31354;&#38388;&#23398;&#20064;&#20013;&#21487;&#20197;&#25910;&#25947;&#21040;&#26368;&#20248;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2005.13625</link><description>&lt;p&gt;
&#37325;&#35775;&#22810;&#26234;&#33021;&#20307;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#21442;&#25968;&#20849;&#20139;
&lt;/p&gt;
&lt;p&gt;
Revisiting Parameter Sharing in Multi-Agent Deep Reinforcement Learning. (arXiv:2005.13625v8 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2005.13625
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#37325;&#35775;&#20102;&#22810;&#26234;&#33021;&#20307;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#21442;&#25968;&#20849;&#20139;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#26234;&#33021;&#20307;&#25351;&#31034;&#20449;&#21495;&#23454;&#29616;&#20102;&#22312;&#19981;&#21516;&#31574;&#30053;&#32593;&#32476;&#20849;&#20139;&#21442;&#25968;&#30340;&#21516;&#26102;&#23398;&#20064;&#19981;&#21516;&#31574;&#30053;&#25110;&#20219;&#21153;&#30340;&#33021;&#21147;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#36825;&#20123;&#26041;&#27861;&#22312;&#24322;&#26500;&#35266;&#27979;&#21644;&#34892;&#21160;&#31354;&#38388;&#23398;&#20064;&#20013;&#21487;&#20197;&#25910;&#25947;&#21040;&#26368;&#20248;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21442;&#25968;&#20849;&#20139;&#26159;&#22810;&#26234;&#33021;&#20307;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#19968;&#31181;&#24120;&#29992;&#30340;&#22522;&#20934;&#26041;&#27861;&#65292;&#27599;&#20010;&#26234;&#33021;&#20307;&#37117;&#29420;&#31435;&#23398;&#20064;&#19968;&#20010;&#31574;&#30053;&#65292;&#24182;&#19988;&#25152;&#26377;&#31574;&#30053;&#20043;&#38388;&#20849;&#20139;&#21442;&#25968;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#25152;&#26377;&#26234;&#33021;&#20307;&#20849;&#20139;&#21516;&#19968;&#31574;&#30053;&#32593;&#32476;&#65292;&#23427;&#20204;&#26080;&#27861;&#23398;&#20064;&#19981;&#21516;&#30340;&#31574;&#30053;&#25110;&#20219;&#21153;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#36890;&#36807;&#21521;&#35266;&#27979;&#20013;&#28155;&#21152;&#26234;&#33021;&#20307;&#29305;&#23450;&#30340;&#25351;&#31034;&#20449;&#21495;&#65288;&#31216;&#20026;&#8220;&#26234;&#33021;&#20307;&#25351;&#31034;&#8221;&#65289;&#26469;&#36827;&#34892;&#23454;&#39564;&#24615;&#30340;&#25913;&#36827;&#12290;&#28982;&#32780;&#65292;&#26234;&#33021;&#20307;&#25351;&#31034;&#30340;&#23616;&#38480;&#22312;&#20110;&#65292;&#22914;&#26524;&#19981;&#36827;&#34892;&#20462;&#25913;&#65292;&#23427;&#26080;&#27861;&#24212;&#29992;&#20110;&#34892;&#21160;&#31354;&#38388;&#21644;/&#25110;&#35266;&#27979;&#31354;&#38388;&#19981;&#21516;&#36136;&#30340;&#29615;&#22659;&#12290;&#26412;&#30740;&#31350;&#27491;&#24335;&#23450;&#20041;&#20102;&#26234;&#33021;&#20307;&#25351;&#31034;&#30340;&#27010;&#24565;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#39318;&#27425;&#23454;&#29616;&#20102;&#25910;&#25947;&#21040;&#26368;&#20248;&#31574;&#30053;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#27491;&#24335;&#20171;&#32461;&#20102;&#25193;&#23637;&#21442;&#25968;&#20849;&#20139;&#21040;&#24322;&#26500;&#35266;&#27979;&#21644;&#34892;&#21160;&#31354;&#38388;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#25910;&#25947;&#21040;&#26368;&#20248;&#31574;&#30053;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#23454;&#39564;&#39564;&#35777;&#24182;&#23545;&#27604;&#20102;&#21508;&#31181;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Parameter sharing, where each agent independently learns a policy with fully shared parameters between all policies, is a popular baseline method for multi-agent deep reinforcement learning. Unfortunately, since all agents share the same policy network, they cannot learn different policies or tasks. This issue has been circumvented experimentally by adding an agent-specific indicator signal to observations, which we term "agent indication". Agent indication is limited, however, in that without modification it does not allow parameter sharing to be applied to environments where the action spaces and/or observation spaces are heterogeneous. This work formalizes the notion of agent indication and proves that it enables convergence to optimal policies for the first time. Next, we formally introduce methods to extend parameter sharing to learning in heterogeneous observation and action spaces, and prove that these methods allow for convergence to optimal policies. Finally, we experimentally
&lt;/p&gt;</description></item><item><title>Open-LACU&#26159;&#19968;&#31181;&#26032;&#30340;&#24320;&#25918;&#24335;&#23398;&#20064;&#31574;&#30053;&#65292;&#23427;&#21487;&#20197;&#23558;&#20998;&#31867;&#22120;&#25512;&#24191;&#21040;&#35266;&#23519;&#21040;&#30340;&#21644;&#26410;&#35266;&#23519;&#21040;&#30340;&#26032;&#39062;&#31867;&#21035;&#20043;&#38388;&#65292;&#24182;&#36890;&#36807;&#23450;&#20041;&#19981;&#21516;&#30340;&#32972;&#26223;&#21644;&#26410;&#30693;&#31867;&#21035;&#26469;&#25552;&#39640;&#35757;&#32451;&#25104;&#26412;&#25928;&#30410;&#24615;&#65292;&#30830;&#20445;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#26032;&#39062;&#31867;&#21035;&#26102;&#36827;&#34892;&#23433;&#20840;&#20998;&#31867;&#12290;</title><link>http://arxiv.org/abs/2002.01368</link><description>&lt;p&gt;
&#21033;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#25193;&#23637;&#31867;&#21035;&#30340;&#24320;&#25918;&#38598;&#23398;&#20064;&#65288;Open-LACU&#65289;
&lt;/p&gt;
&lt;p&gt;
Open-set learning with augmented category by exploiting unlabeled data (Open-LACU). (arXiv:2002.01368v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2002.01368
&lt;/p&gt;
&lt;p&gt;
Open-LACU&#26159;&#19968;&#31181;&#26032;&#30340;&#24320;&#25918;&#24335;&#23398;&#20064;&#31574;&#30053;&#65292;&#23427;&#21487;&#20197;&#23558;&#20998;&#31867;&#22120;&#25512;&#24191;&#21040;&#35266;&#23519;&#21040;&#30340;&#21644;&#26410;&#35266;&#23519;&#21040;&#30340;&#26032;&#39062;&#31867;&#21035;&#20043;&#38388;&#65292;&#24182;&#36890;&#36807;&#23450;&#20041;&#19981;&#21516;&#30340;&#32972;&#26223;&#21644;&#26410;&#30693;&#31867;&#21035;&#26469;&#25552;&#39640;&#35757;&#32451;&#25104;&#26412;&#25928;&#30410;&#24615;&#65292;&#30830;&#20445;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#26032;&#39062;&#31867;&#21035;&#26102;&#36827;&#34892;&#23433;&#20840;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#21322;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#21644;&#24320;&#25918;&#24335;&#35782;&#21035;&#65288;OSR&#65289;&#65292;&#24050;&#32463;&#36827;&#34892;&#20102;&#35768;&#22810;&#23581;&#35797;&#20197;&#21512;&#25104;&#21333;&#20010;&#35757;&#32451;&#31574;&#30053;&#12290;&#28982;&#32780;&#65292;&#27599;&#27425;&#23581;&#35797;&#37117;&#36829;&#21453;&#20102;&#24320;&#25918;&#38598;&#23450;&#20041;&#65292;&#22240;&#20026;&#36825;&#20123;&#26041;&#27861;&#22312;&#26410;&#26631;&#35760;&#30340;&#35757;&#32451;&#38598;&#20013;&#21253;&#21547;&#26032;&#39062;&#30340;&#31867;&#21035;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23398;&#20064;&#31574;&#30053;&#65292;&#20854;&#20013;&#20998;&#31867;&#22120;&#33021;&#22815;&#22312;&#35266;&#23519;&#21040;&#30340;&#21644;&#26410;&#35266;&#23519;&#21040;&#30340;&#26032;&#39062;&#31867;&#21035;&#20043;&#38388;&#36827;&#34892;&#25512;&#24191;&#65292;&#20174;&#32780;&#23450;&#20041;&#20102;&#35266;&#23519;&#21040;&#26032;&#39062;&#31867;&#21035;&#30340;&#32972;&#26223;&#31867;&#21035;&#21644;&#26410;&#35266;&#23519;&#21040;&#26032;&#39062;&#31867;&#21035;&#30340;&#26410;&#30693;&#31867;&#21035;&#12290;&#36890;&#36807;&#20998;&#31867;&#36825;&#20004;&#31181;&#26032;&#39062;&#31867;&#21035;&#30340;&#26041;&#24335;&#65292;Open-LACU&#33021;&#22815;&#25552;&#39640;&#35757;&#32451;&#30340;&#25104;&#26412;&#25928;&#30410;&#24615;&#65292;&#24182;&#30830;&#20445;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#26032;&#39062;&#31867;&#21035;&#26102;&#36827;&#34892;&#23433;&#20840;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several efforts have been made to synthesize semi-supervised learning (SSL) and open set recognition (OSR) within a single training policy. However, each attempt violated the definition of an open set by incorporating novel categories within the unlabeled training set. Although such \textit{observed} novel categories are undoubtedly prevalent in application-grade datasets, they should not be conflated with the OSR-defined \textit{unobserved} novel categories, which only emerge during testing. This study proposes a new learning policy wherein classifiers generalize between observed and unobserved novel categories. Specifically, our open-set learning with augmented category by exploiting unlabeled data (Open-LACU) policy defines a background category for observed novel categories and an unknown category for unobserved novel categories. By separating these novel category types, Open-LACU promotes cost-efficient training by eliminating the need to label every category and ensures safe clas
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#25197;&#26354;&#27010;&#29575;&#30340;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20197;UCB&#31639;&#27861;&#20026;&#22522;&#30784;&#12289;&#32771;&#34385;&#20102;&#22870;&#21169;&#25197;&#26354;&#24182;&#20855;&#26377;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/1611.10283</link><description>&lt;p&gt;
&#21152;&#26435;&#36172;&#21338;&#26426;&#25110;&#32773;&#65306;&#36172;&#21338;&#26426;&#22914;&#20309;&#23398;&#20064;&#39044;&#26399;&#20043;&#22806;&#30340;&#25197;&#26354;&#20215;&#20540;
&lt;/p&gt;
&lt;p&gt;
Weighted bandits or: How bandits learn distorted values that are not expected. (arXiv:1611.10283v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1611.10283
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#25197;&#26354;&#27010;&#29575;&#30340;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20197;UCB&#31639;&#27861;&#20026;&#22522;&#30784;&#12289;&#32771;&#34385;&#20102;&#22870;&#21169;&#25197;&#26354;&#24182;&#20855;&#26377;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#21040;&#29992;&#20110;&#35299;&#37322;&#24120;&#35265;&#20559;&#31163;&#20256;&#32479;&#39044;&#26399;&#20215;&#20540;&#20559;&#22909;&#30340;&#20154;&#31867;&#20915;&#31574;&#27169;&#22411;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#24102;&#26377;&#25197;&#26354;&#27010;&#29575;&#30340;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65306;&#32463;&#20856;&#30340;K&#33218;&#36172;&#21338;&#26426;&#21644;&#32447;&#24615;&#21442;&#25968;&#21270;&#36172;&#21338;&#26426;&#35774;&#32622;&#12290;&#25105;&#20204;&#22312;&#23545;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#21518;&#24724;&#26368;&#23567;&#21270;&#21644;&#26368;&#20339;&#33218;&#35782;&#21035;&#26694;&#26550;&#19979;&#30740;&#31350;&#20102;&#19978;&#36848;&#38382;&#39064;&#12290;&#23545;&#20110;K&#33218;&#36172;&#21338;&#26426;&#20197;&#21450;&#32447;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#21518;&#24724;&#26368;&#23567;&#21270;&#35774;&#32622;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21463;&#21040;&#19978;&#32622;&#20449;&#30028;(UCB)&#31639;&#27861;&#21551;&#21457;&#12289;&#21253;&#21547;&#22870;&#21169;&#25197;&#26354;&#24182;&#19988;&#20855;&#26377;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#31639;&#27861;&#12290;&#23545;&#20110;K&#33218;&#36172;&#21338;&#26426;&#35774;&#32622;&#65292;&#25105;&#20204;&#24471;&#20986;&#20102;&#23545;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#30340;&#39044;&#26399;&#21518;&#24724;&#30340;&#19978;&#30028;&#65292;&#28982;&#21518;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#21305;&#37197;&#30340;&#19979;&#30028;&#65292;&#20197;&#39564;&#35777;&#25105;&#20204;&#31639;&#27861;&#30340;&#27425;&#32447;&#24615;&#20248;&#21270;&#39034;&#24207;&#12290;&#23545;&#20110;&#32447;&#24615;&#21442;&#25968;&#21270;&#35774;&#32622;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#23454;&#29616;&#20102;&#19968;&#20010;&#21518;&#24724;&#19978;&#30028;&#65292;&#35813;&#19978;&#30028;&#26159;&#27425;&#32447;&#24615;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by models of human decision making proposed to explain commonly observed deviations from conventional expected value preferences, we formulate two stochastic multi-armed bandit problems with distorted probabilities on the reward distributions: the classic $K$-armed bandit and the linearly parameterized bandit settings. We consider the aforementioned problems in the regret minimization as well as best arm identification framework for multi-armed bandits. For the regret minimization setting in $K$-armed as well as linear bandit problems, we propose algorithms that are inspired by Upper Confidence Bound (UCB) algorithms, incorporate reward distortions, and exhibit sublinear regret. For the $K$-armed bandit setting, we derive an upper bound on the expected regret for our proposed algorithm, and then we prove a matching lower bound to establish the order-optimality of our algorithm. For the linearly parameterized setting, our algorithm achieves a regret upper bound that is of the 
&lt;/p&gt;</description></item></channel></rss>