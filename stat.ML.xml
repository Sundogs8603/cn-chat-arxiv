<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#22810;&#21160;&#20316;&#22330;&#26223;&#20013;&#21033;&#29992;&#35266;&#27979;&#25968;&#25454;&#36827;&#34892;&#26368;&#20248;&#31574;&#30053;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#30528;&#37325;&#25506;&#35752;&#20102;&#20272;&#35745;&#12289;&#39118;&#38505;&#20559;&#22909;&#21644;&#28508;&#22312;&#25925;&#38556;&#19977;&#20010;&#26041;&#38754;&#12290;</title><link>https://arxiv.org/abs/2403.20250</link><description>&lt;p&gt;
&#22810;&#21160;&#20316;&#22330;&#26223;&#20013;&#21033;&#29992;&#35266;&#27979;&#25968;&#25454;&#36827;&#34892;&#26368;&#20248;&#31574;&#30053;&#23398;&#20064;&#65306;&#20272;&#35745;&#12289;&#39118;&#38505;&#20559;&#22909;&#21644;&#28508;&#22312;&#25925;&#38556;
&lt;/p&gt;
&lt;p&gt;
Optimal Policy Learning with Observational Data in Multi-Action Scenarios: Estimation, Risk Preference, and Potential Failures
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.20250
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#22810;&#21160;&#20316;&#22330;&#26223;&#20013;&#21033;&#29992;&#35266;&#27979;&#25968;&#25454;&#36827;&#34892;&#26368;&#20248;&#31574;&#30053;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#30528;&#37325;&#25506;&#35752;&#20102;&#20272;&#35745;&#12289;&#39118;&#38505;&#20559;&#22909;&#21644;&#28508;&#22312;&#25925;&#38556;&#19977;&#20010;&#26041;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#21033;&#29992;&#35266;&#27979;&#25968;&#25454;&#36827;&#34892;&#26368;&#20248;&#31574;&#30053;&#23398;&#20064;&#65288;OPL&#65289;&#65292;&#21363;&#25968;&#25454;&#39537;&#21160;&#30340;&#26368;&#20248;&#20915;&#31574;&#65292;&#22312;&#22810;&#21160;&#20316;&#65288;&#25110;&#22810;&#33218;&#65289;&#35774;&#32622;&#20013;&#65292;&#26377;&#38480;&#30340;&#20915;&#31574;&#36873;&#39033;&#21487;&#20379;&#36873;&#25321;&#12290;&#25991;&#31456;&#20998;&#20026;&#19977;&#20010;&#37096;&#20998;&#65292;&#20998;&#21035;&#35752;&#35770;&#65306;&#20272;&#35745;&#12289;&#39118;&#38505;&#20559;&#22909;&#21644;&#28508;&#22312;&#25925;&#38556;&#12290;&#31532;&#19968;&#37096;&#20998;&#31616;&#35201;&#22238;&#39038;&#20102;&#22312;&#36825;&#31181;&#20998;&#26512;&#32972;&#26223;&#19979;&#20272;&#35745;&#22870;&#21169;&#65288;&#25110;&#20540;&#65289;&#20989;&#25968;&#21644;&#26368;&#20248;&#31574;&#30053;&#30340;&#20851;&#38190;&#26041;&#27861;&#12290;&#31532;&#20108;&#37096;&#20998;&#28145;&#20837;&#20998;&#26512;&#20102;&#20915;&#31574;&#39118;&#38505;&#12290;&#20998;&#26512;&#34920;&#26126;&#65292;&#20915;&#31574;&#32773;&#23545;&#39118;&#38505;&#30340;&#24577;&#24230;&#21487;&#20197;&#24433;&#21709;&#26368;&#20248;&#36873;&#25321;&#65292;&#20855;&#20307;&#20307;&#29616;&#22312;&#22870;&#21169;&#26465;&#20214;&#22343;&#20540;&#19982;&#26465;&#20214;&#26041;&#24046;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#22312;&#36825;&#37324;&#65292;&#20316;&#32773;&#23558;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#24212;&#29992;&#20110;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.20250v1 Announce Type: cross  Abstract: This paper deals with optimal policy learning (OPL) with observational data, i.e. data-driven optimal decision-making, in multi-action (or multi-arm) settings, where a finite set of decision options is available. It is organized in three parts, where I discuss respectively: estimation, risk preference, and potential failures. The first part provides a brief review of the key approaches to estimating the reward (or value) function and optimal policy within this context of analysis. Here, I delineate the identification assumptions and statistical properties related to offline optimal policy learning estimators. In the second part, I delve into the analysis of decision risk. This analysis reveals that the optimal choice can be influenced by the decision maker's attitude towards risks, specifically in terms of the trade-off between reward conditional mean and conditional variance. Here, I present an application of the proposed model to rea
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20989;&#25968;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19981;&#20381;&#36182;&#20110;&#24378;&#20984;&#20551;&#35774;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#20202;&#34920;&#22238;&#24402;&#21644;&#24378;&#21270;&#23398;&#20064;&#20219;&#21153;&#20013;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2403.20233</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20989;&#25968;&#21452;&#23618;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Functional Bilevel Optimization for Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.20233
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20989;&#25968;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19981;&#20381;&#36182;&#20110;&#24378;&#20984;&#20551;&#35774;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#20202;&#34920;&#22238;&#24402;&#21644;&#24378;&#21270;&#23398;&#20064;&#20219;&#21153;&#20013;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#38024;&#23545;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#30340;&#19968;&#31181;&#26032;&#30340;&#20989;&#25968;&#35270;&#35282;&#65292;&#20854;&#20013;&#20869;&#37096;&#30446;&#26631;&#22312;&#20989;&#25968;&#31354;&#38388;&#19978;&#34987;&#26368;&#23567;&#21270;&#12290;&#36825;&#20123;&#31867;&#22411;&#30340;&#38382;&#39064;&#36890;&#24120;&#36890;&#36807;&#22312;&#21442;&#25968;&#35774;&#32622;&#19979;&#24320;&#21457;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#65292;&#20854;&#20013;&#20869;&#37096;&#30446;&#26631;&#23545;&#20110;&#39044;&#27979;&#20989;&#25968;&#30340;&#21442;&#25968;&#24378;&#20984;&#12290;&#20989;&#25968;&#35270;&#35282;&#19981;&#20381;&#36182;&#20110;&#27492;&#20551;&#35774;&#65292;&#29305;&#21035;&#20801;&#35768;&#20351;&#29992;&#36229;&#21442;&#25968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#20869;&#37096;&#39044;&#27979;&#20989;&#25968;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#21487;&#25193;&#23637;&#21644;&#39640;&#25928;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#20989;&#25968;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#22312;&#36866;&#21512;&#33258;&#28982;&#20989;&#25968;&#21452;&#23618;&#32467;&#26500;&#30340;&#20202;&#34920;&#22238;&#24402;&#21644;&#24378;&#21270;&#23398;&#20064;&#20219;&#21153;&#19978;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.20233v1 Announce Type: cross  Abstract: In this paper, we introduce a new functional point of view on bilevel optimization problems for machine learning, where the inner objective is minimized over a function space. These types of problems are most often solved by using methods developed in the parametric setting, where the inner objective is strongly convex with respect to the parameters of the prediction function. The functional point of view does not rely on this assumption and notably allows using over-parameterized neural networks as the inner prediction function. We propose scalable and efficient algorithms for the functional bilevel optimization problem and illustrate the benefits of our approach on instrumental regression and reinforcement learning tasks, which admit natural functional bilevel structures.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#23545;&#20110;&#29420;&#31435;&#20294;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#39640;&#32500;&#22238;&#24402;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#22312;&#23725;&#27491;&#21017;&#21270;&#21442;&#25968;&#36235;&#36817;&#20110;&#38646;&#26102;&#39640;&#32500;&#22238;&#24402;&#20013;&#30340;&#21452;&#35895;&#29616;&#35937;&#12290;</title><link>https://arxiv.org/abs/2403.20200</link><description>&lt;p&gt;
&#23545;&#20855;&#26377;&#26041;&#24046;&#36718;&#24275;&#30340;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#23725;&#22238;&#24402;&#36827;&#34892;&#39640;&#32500;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
High-dimensional analysis of ridge regression for non-identically distributed data with a variance profile
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.20200
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#23545;&#20110;&#29420;&#31435;&#20294;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#39640;&#32500;&#22238;&#24402;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#22312;&#23725;&#27491;&#21017;&#21270;&#21442;&#25968;&#36235;&#36817;&#20110;&#38646;&#26102;&#39640;&#32500;&#22238;&#24402;&#20013;&#30340;&#21452;&#35895;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#29420;&#31435;&#20294;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#65292;&#25105;&#20204;&#25552;&#20986;&#30740;&#31350;&#39640;&#32500;&#22238;&#24402;&#27169;&#22411;&#12290;&#20551;&#35774;&#35266;&#27979;&#21040;&#30340;&#39044;&#27979;&#21464;&#37327;&#38598;&#21512;&#26159;&#24102;&#26377;&#26041;&#24046;&#36718;&#24275;&#30340;&#38543;&#26426;&#30697;&#38453;&#65292;&#24182;&#19988;&#20854;&#32500;&#24230;&#20197;&#30456;&#24212;&#36895;&#29575;&#22686;&#38271;&#12290;&#22312;&#20551;&#35774;&#38543;&#26426;&#25928;&#24212;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#36825;&#31181;&#26041;&#24046;&#36718;&#24275;&#30340;&#23725;&#20272;&#35745;&#22120;&#30340;&#32447;&#24615;&#22238;&#24402;&#30340;&#39044;&#27979;&#39118;&#38505;&#12290;&#22312;&#36825;&#31181;&#35774;&#32622;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#35813;&#39118;&#38505;&#30340;&#30830;&#23450;&#24615;&#31561;&#20215;&#29289;&#20197;&#21450;&#23725;&#20272;&#35745;&#22120;&#30340;&#33258;&#30001;&#24230;&#12290;&#23545;&#20110;&#26576;&#20123;&#26041;&#24046;&#36718;&#24275;&#31867;&#21035;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#31361;&#20986;&#20102;&#22312;&#23725;&#27491;&#21017;&#21270;&#21442;&#25968;&#36235;&#20110;&#38646;&#26102;&#65292;&#39640;&#32500;&#22238;&#24402;&#20013;&#30340;&#26368;&#23567;&#27169;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#20986;&#29616;&#21452;&#35895;&#29616;&#35937;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#19968;&#20123;&#26041;&#24046;&#36718;&#24275;f...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.20200v1 Announce Type: cross  Abstract: High-dimensional linear regression has been thoroughly studied in the context of independent and identically distributed data. We propose to investigate high-dimensional regression models for independent but non-identically distributed data. To this end, we suppose that the set of observed predictors (or features) is a random matrix with a variance profile and with dimensions growing at a proportional rate. Assuming a random effect model, we study the predictive risk of the ridge estimator for linear regression with such a variance profile. In this setting, we provide deterministic equivalents of this risk and of the degree of freedom of the ridge estimator. For certain class of variance profile, our work highlights the emergence of the well-known double descent phenomenon in high-dimensional regression for the minimum norm least-squares estimator when the ridge regularization parameter goes to zero. We also exhibit variance profiles f
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20351;&#29992;&#23545;&#20598;/&#26497;&#24615;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#23545;&#20598;&#20307;&#31215;&#26368;&#22823;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#21333;&#32431;&#32467;&#26500;&#30697;&#38453;&#20998;&#35299;&#38382;&#39064;&#65292;&#22635;&#34917;&#20102;&#29616;&#26377;SSMF&#31639;&#27861;&#23478;&#26063;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>https://arxiv.org/abs/2403.20197</link><description>&lt;p&gt;
&#21452;&#23545;&#20598;&#20307;&#31215;&#26368;&#22823;&#21270;&#29992;&#20110;&#21333;&#32431;&#32467;&#26500;&#30697;&#38453;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
Dual Simplex Volume Maximization for Simplex-Structured Matrix Factorization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.20197
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#23545;&#20598;/&#26497;&#24615;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#23545;&#20598;&#20307;&#31215;&#26368;&#22823;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#21333;&#32431;&#32467;&#26500;&#30697;&#38453;&#20998;&#35299;&#38382;&#39064;&#65292;&#22635;&#34917;&#20102;&#29616;&#26377;SSMF&#31639;&#27861;&#23478;&#26063;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Simplex-structured matrix factorization&#65288;SSMF&#65289;&#26159;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#30340;&#27867;&#21270;&#65292;&#26159;&#19968;&#31181;&#22522;&#30784;&#30340;&#21487;&#35299;&#37322;&#25968;&#25454;&#20998;&#26512;&#27169;&#22411;&#65292;&#22312;&#39640;&#20809;&#35889;&#35299;&#28151;&#21644;&#21644;&#20027;&#39064;&#24314;&#27169;&#20013;&#26377;&#24212;&#29992;&#12290;&#20026;&#20102;&#33719;&#24471;&#21487;&#35782;&#21035;&#30340;&#35299;&#65292;&#26631;&#20934;&#26041;&#27861;&#26159;&#23547;&#25214;&#26368;&#23567;&#20307;&#31215;&#35299;&#12290;&#36890;&#36807;&#21033;&#29992;&#22810;&#38754;&#20307;&#30340;&#23545;&#20598;/&#26497;&#24615;&#27010;&#24565;&#65292;&#25105;&#20204;&#23558;&#21407;&#22987;&#31354;&#38388;&#20013;&#30340;&#26368;&#23567;&#20307;&#31215;SSMF&#36716;&#25442;&#20026;&#23545;&#20598;&#31354;&#38388;&#20013;&#30340;&#26368;&#22823;&#20307;&#31215;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#36825;&#20010;&#26368;&#22823;&#20307;&#31215;&#23545;&#20598;&#38382;&#39064;&#30340;&#21487;&#35782;&#21035;&#24615;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#36825;&#20010;&#23545;&#20598;&#20844;&#24335;&#25552;&#20379;&#19968;&#31181;&#26032;&#39062;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#20197;&#22635;&#34917;SSMF&#30340;&#20004;&#20010;&#29616;&#26377;&#31639;&#27861;&#23478;&#26063;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#21363;&#20307;&#31215;&#26368;&#23567;&#21270;&#21644;&#38754;&#35782;&#21035;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#30340;SSMF&#31639;&#27861;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.20197v1 Announce Type: cross  Abstract: Simplex-structured matrix factorization (SSMF) is a generalization of nonnegative matrix factorization, a fundamental interpretable data analysis model, and has applications in hyperspectral unmixing and topic modeling. To obtain identifiable solutions, a standard approach is to find minimum-volume solutions. By taking advantage of the duality/polarity concept for polytopes, we convert minimum-volume SSMF in the primal space to a maximum-volume problem in the dual space. We first prove the identifiability of this maximum-volume dual problem. Then, we use this dual formulation to provide a novel optimization approach which bridges the gap between two existing families of algorithms for SSMF, namely volume minimization and facet identification. Numerical experiments show that the proposed approach performs favorably compared to the state-of-the-art SSMF algorithms.
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#30005;&#21147;&#24066;&#22330;&#20013;&#20351;&#29992;&#19968;&#33268;&#24615;&#39044;&#27979;&#23545;&#20809;&#20239;&#30005;&#21147;&#26085;&#21069;&#39044;&#27979;&#36827;&#34892;&#20915;&#31574;&#30340;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#32467;&#21512;&#29305;&#23450;&#20986;&#20215;&#31574;&#30053;&#21487;&#20197;&#22312;&#20445;&#25345;&#33021;&#37327;&#24179;&#34913;&#26368;&#23567;&#30340;&#24773;&#20917;&#19979;&#33719;&#24471;&#39640;&#21033;&#28070;&#12290;</title><link>https://arxiv.org/abs/2403.20149</link><description>&lt;p&gt;
&#30005;&#21147;&#24066;&#22330;&#20013;&#20809;&#20239;&#30005;&#21147;&#38543;&#26426;&#20915;&#31574;&#30340;&#19968;&#33268;&#24615;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Conformal Prediction for Stochastic Decision-Making of PV Power in Electricity Markets
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.20149
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#30005;&#21147;&#24066;&#22330;&#20013;&#20351;&#29992;&#19968;&#33268;&#24615;&#39044;&#27979;&#23545;&#20809;&#20239;&#30005;&#21147;&#26085;&#21069;&#39044;&#27979;&#36827;&#34892;&#20915;&#31574;&#30340;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#32467;&#21512;&#29305;&#23450;&#20986;&#20215;&#31574;&#30053;&#21487;&#20197;&#22312;&#20445;&#25345;&#33021;&#37327;&#24179;&#34913;&#26368;&#23567;&#30340;&#24773;&#20917;&#19979;&#33719;&#24471;&#39640;&#21033;&#28070;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#19968;&#33268;&#24615;&#39044;&#27979;&#65288;CP&#65289;&#65292;&#19968;&#31181;&#26032;&#20852;&#30340;&#27010;&#29575;&#39044;&#27979;&#26041;&#27861;&#65292;&#29992;&#20110;&#21152;&#24378;&#22312;&#30005;&#21147;&#24066;&#22330;&#20013;&#26085;&#21069;&#20809;&#20239;&#30005;&#21147;&#39044;&#27979;&#30340;&#21442;&#19982;&#12290;&#39318;&#20808;&#65292;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26500;&#24314;&#28857;&#39044;&#27979;&#12290;&#28982;&#21518;&#65292;&#23454;&#26045;&#20102;&#20960;&#31181;CP&#30340;&#21464;&#20307;&#65292;&#36890;&#36807;&#21019;&#24314;CP&#21306;&#38388;&#21644;&#32047;&#31215;&#20998;&#24067;&#20989;&#25968;&#26469;&#37327;&#21270;&#36825;&#20123;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#22312;&#19981;&#30830;&#23450;&#24615;&#19979;&#20272;&#35745;&#20102;&#22810;&#31181;&#20986;&#20215;&#31574;&#30053;&#19979;&#30340;&#30005;&#21147;&#24066;&#22330;&#30340;&#26368;&#20248;&#25968;&#37327;&#20986;&#20215;&#65292;&#21363;&#65306;&#20449;&#20219;&#39044;&#27979;&#12289;&#26368;&#22351;&#24773;&#20917;&#12289;Newsvendor&#21644;&#26399;&#26395;&#25928;&#29992;&#26368;&#22823;&#21270;&#65288;EUM&#65289;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#32467;&#21512;k&#26368;&#36817;&#37051;&#21644;/&#25110;Mondrian&#20998;&#31665;&#30340;CP&#32988;&#36807;&#20854;&#23545;&#24212;&#30340;&#32447;&#24615;&#20998;&#20301;&#25968;&#22238;&#24402;&#22120;&#12290;&#20351;&#29992;CP&#32467;&#21512;&#26576;&#20123;&#20986;&#20215;&#31574;&#30053;&#21487;&#20197;&#22312;&#20445;&#25345;&#33021;&#37327;&#24179;&#34913;&#26368;&#23567;&#30340;&#24773;&#20917;&#19979;&#33719;&#24471;&#39640;&#21033;&#28070;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#20351;&#29992;&#20855;&#26377;k&#36817;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.20149v1 Announce Type: new  Abstract: This paper studies the use of conformal prediction (CP), an emerging probabilistic forecasting method, for day-ahead photovoltaic power predictions to enhance participation in electricity markets. First, machine learning models are used to construct point predictions. Thereafter, several variants of CP are implemented to quantify the uncertainty of those predictions by creating CP intervals and cumulative distribution functions. Optimal quantity bids for the electricity market are estimated using several bidding strategies under uncertainty, namely: trust-the-forecast, worst-case, Newsvendor and expected utility maximization (EUM). Results show that CP in combination with k-nearest neighbors and/or Mondrian binning outperforms its corresponding linear quantile regressors. Using CP in combination with certain bidding strategies can yield high profit with minimal energy imbalance. In concrete, using conformal predictive systems with k-near
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#20915;&#31574;&#34701;&#21512;&#26041;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#20449;&#24687;&#24615;&#21464;&#37327;&#26469;&#25552;&#39640;&#20215;&#26684;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#26524;</title><link>https://arxiv.org/abs/2403.20033</link><description>&lt;p&gt;
&#20351;&#29992;&#24377;&#24615;&#32593;&#32476;&#21644;MOPSO&#36827;&#34892;&#38144;&#21806;&#20215;&#26684;&#39044;&#27979;&#30340;&#26032;&#22411;&#20915;&#31574;&#34701;&#21512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A novel decision fusion approach for sale price prediction using Elastic Net and MOPSO
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.20033
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#20915;&#31574;&#34701;&#21512;&#26041;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#20449;&#24687;&#24615;&#21464;&#37327;&#26469;&#25552;&#39640;&#20215;&#26684;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#26524;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20215;&#26684;&#39044;&#27979;&#31639;&#27861;&#26681;&#25454;&#24066;&#22330;&#36235;&#21183;&#12289;&#39044;&#26399;&#38656;&#27714;&#20197;&#21450;&#20854;&#20182;&#29305;&#24449;&#65288;&#21253;&#25324;&#25919;&#24220;&#35268;&#23450;&#12289;&#22269;&#38469;&#20132;&#26131;&#12289;&#25237;&#26426;&#21644;&#26399;&#26395;&#65289;&#20026;&#27599;&#31181;&#20135;&#21697;&#25110;&#26381;&#21153;&#25552;&#20986;&#20215;&#26684;&#12290;&#20316;&#20026;&#20215;&#26684;&#39044;&#27979;&#20013;&#30340;&#22240;&#21464;&#37327;&#65292;&#20215;&#26684;&#21463;&#21040;&#22810;&#20010;&#29420;&#31435;&#21644;&#30456;&#20851;&#21464;&#37327;&#30340;&#24433;&#21709;&#65292;&#36825;&#21487;&#33021;&#23545;&#20215;&#26684;&#39044;&#27979;&#26500;&#25104;&#25361;&#25112;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#25361;&#25112;&#65292;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#20801;&#35768;&#26356;&#20934;&#30830;&#22320;&#36827;&#34892;&#20215;&#26684;&#39044;&#27979;&#65292;&#32780;&#26080;&#38656;&#26126;&#30830;&#23545;&#21464;&#37327;&#20043;&#38388;&#30340;&#20851;&#32852;&#24615;&#24314;&#27169;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#36755;&#20837;&#21464;&#37327;&#30340;&#22686;&#21152;&#65292;&#36825;&#25361;&#25112;&#20102;&#29616;&#26377;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#35745;&#31639;&#25928;&#29575;&#21644;&#39044;&#27979;&#25928;&#26524;&#19978;&#12290;&#22240;&#27492;&#65292;&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20915;&#31574;&#32423;&#34701;&#21512;&#26041;&#27861;&#26469;&#36873;&#25321;&#20215;&#26684;&#39044;&#27979;&#20013;&#30340;&#20449;&#24687;&#24615;&#21464;&#37327;&#12290;&#24314;&#35758;&#30340;&#20803;&#21551;&#21457;&#24335;&#31639;&#27861;&#24179;&#34913;&#20102;&#20004;&#20010;&#31454;&#20105;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#26088;&#22312;&#25913;&#21892;&#21033;&#29992;&#21464;&#37327;&#36827;&#34892;&#39044;&#27979;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.20033v1 Announce Type: cross  Abstract: Price prediction algorithms propose prices for every product or service according to market trends, projected demand, and other characteristics, including government rules, international transactions, and speculation and expectation. As the dependent variable in price prediction, it is affected by several independent and correlated variables which may challenge the price prediction. To overcome this challenge, machine learning algorithms allow more accurate price prediction without explicitly modeling the relatedness between variables. However, as inputs increase, it challenges the existing machine learning approaches regarding computing efficiency and prediction effectiveness. Hence, this study introduces a novel decision level fusion approach to select informative variables in price prediction. The suggested metaheuristic algorithm balances two competitive objective functions, which are defined to improve the prediction utilized vari
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#23637;&#31034;&#20102;&#35821;&#35328;&#27169;&#22411;&#20013;&#27573;&#33853;&#35760;&#24518;&#30340;&#26799;&#24230;&#20855;&#26377;&#21487;&#21306;&#20998;&#30340;&#31354;&#38388;&#27169;&#24335;&#65292;&#36890;&#36807;&#24494;&#35843;&#39640;&#26799;&#24230;&#26435;&#37325;&#21487;&#20197;&#21462;&#28040;&#23398;&#20064;&#65292;&#23450;&#20301;&#20102;&#29305;&#21035;&#21442;&#19982;&#27573;&#33853;&#35760;&#24518;&#30340;&#20302;&#23618;&#27880;&#24847;&#22836;&#65292;&#24182;&#30740;&#31350;&#20102;&#35760;&#24518;&#22312;&#21069;&#32512;&#20013;&#30340;&#26412;&#22320;&#21270;&#31243;&#24230;&#12290;</title><link>https://arxiv.org/abs/2403.19851</link><description>&lt;p&gt;
&#23558;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#27573;&#33853;&#35760;&#24518;&#26412;&#22320;&#21270;
&lt;/p&gt;
&lt;p&gt;
Localizing Paragraph Memorization in Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19851
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#23637;&#31034;&#20102;&#35821;&#35328;&#27169;&#22411;&#20013;&#27573;&#33853;&#35760;&#24518;&#30340;&#26799;&#24230;&#20855;&#26377;&#21487;&#21306;&#20998;&#30340;&#31354;&#38388;&#27169;&#24335;&#65292;&#36890;&#36807;&#24494;&#35843;&#39640;&#26799;&#24230;&#26435;&#37325;&#21487;&#20197;&#21462;&#28040;&#23398;&#20064;&#65292;&#23450;&#20301;&#20102;&#29305;&#21035;&#21442;&#19982;&#27573;&#33853;&#35760;&#24518;&#30340;&#20302;&#23618;&#27880;&#24847;&#22836;&#65292;&#24182;&#30740;&#31350;&#20102;&#35760;&#24518;&#22312;&#21069;&#32512;&#20013;&#30340;&#26412;&#22320;&#21270;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#33021;&#21542;&#23558;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#35760;&#24518;&#21644;&#32972;&#35829;&#25972;&#20010;&#35757;&#32451;&#25968;&#25454;&#27573;&#30340;&#26435;&#37325;&#21644;&#26426;&#21046;&#26412;&#22320;&#21270;&#65311;&#26412;&#25991;&#34920;&#26126;&#65292;&#34429;&#28982;&#35760;&#24518;&#20998;&#24067;&#22312;&#22810;&#20010;&#23618;&#27425;&#21644;&#27169;&#22411;&#32452;&#20214;&#20013;&#65292;&#20294;&#35760;&#24518;&#27573;&#33853;&#30340;&#26799;&#24230;&#20855;&#26377;&#21487;&#21306;&#20998;&#30340;&#31354;&#38388;&#27169;&#24335;&#65292;&#36739;&#20302;&#27169;&#22411;&#23618;&#27425;&#20013;&#30340;&#26799;&#24230;&#27604;&#38750;&#35760;&#24518;&#31034;&#20363;&#30340;&#26799;&#24230;&#26356;&#22823;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#35760;&#24518;&#31034;&#20363;&#21487;&#20197;&#36890;&#36807;&#20165;&#24494;&#35843;&#39640;&#26799;&#24230;&#26435;&#37325;&#26469;&#21462;&#28040;&#23398;&#20064;&#12290;&#25105;&#20204;&#23450;&#20301;&#20102;&#19968;&#20010;&#20284;&#20046;&#29305;&#21035;&#21442;&#19982;&#27573;&#33853;&#35760;&#24518;&#30340;&#20302;&#23618;&#27880;&#24847;&#22836;&#12290;&#36825;&#20010;&#22836;&#37096;&#20027;&#35201;&#23558;&#27880;&#24847;&#21147;&#38598;&#20013;&#22312;&#22312;&#35821;&#26009;&#24211;&#32423;&#21035;&#30340;&#21333;&#35821;&#20998;&#24067;&#20013;&#26368;&#19981;&#39057;&#32321;&#30340;&#29420;&#29305;&#12289;&#32597;&#35265;&#30340;&#20196;&#29260;&#19978;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#36890;&#36807;&#25200;&#21160;&#20196;&#29260;&#24182;&#27979;&#37327;&#23545;&#35299;&#30721;&#36896;&#25104;&#30340;&#25913;&#21464;&#26469;&#30740;&#31350;&#35760;&#24518;&#22312;&#21069;&#32512;&#20013;&#30340;&#26412;&#22320;&#21270;&#31243;&#24230;&#12290;&#21069;&#32512;&#20013;&#30340;&#19968;&#20123;&#29420;&#29305;&#20196;&#29260;&#32463;&#24120;&#20250;&#20351;&#25972;&#20010;&#20869;&#23481;&#21463;&#25439;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19851v1 Announce Type: new  Abstract: Can we localize the weights and mechanisms used by a language model to memorize and recite entire paragraphs of its training data? In this paper, we show that while memorization is spread across multiple layers and model components, gradients of memorized paragraphs have a distinguishable spatial pattern, being larger in lower model layers than gradients of non-memorized examples. Moreover, the memorized examples can be unlearned by fine-tuning only the high-gradient weights. We localize a low-layer attention head that appears to be especially involved in paragraph memorization. This head is predominantly focusing its attention on distinctive, rare tokens that are least frequent in a corpus-level unigram distribution. Next, we study how localized memorization is across the tokens in the prefix by perturbing tokens and measuring the caused change in the decoding. A few distinctive tokens early in a prefix can often corrupt the entire cont
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#36827;&#34892;&#22238;&#24402;&#21644;&#20998;&#31867;&#30340;&#39044;&#27979;&#26694;&#26550;&#65292;&#24182;&#24341;&#20837;&#20102;&#36866;&#29992;&#20110;&#22797;&#26434;&#35843;&#26597;&#35774;&#35745;&#25968;&#25454;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#31639;&#27861;&#65292;&#20197;&#35780;&#20272;&#32654;&#22269;&#20154;&#32676;&#31958;&#23615;&#30149;&#39118;&#38505;&#12290;</title><link>https://arxiv.org/abs/2403.19752</link><description>&lt;p&gt;
&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#35843;&#26597;&#25968;&#25454;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;: &#35780;&#20272;&#21644;&#39044;&#27979;&#32654;&#22269;&#20154;&#32676;&#31958;&#23615;&#30149;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
Deep Learning Framework with Uncertainty Quantification for Survey Data: Assessing and Predicting Diabetes Mellitus Risk in the American Population
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19752
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#36827;&#34892;&#22238;&#24402;&#21644;&#20998;&#31867;&#30340;&#39044;&#27979;&#26694;&#26550;&#65292;&#24182;&#24341;&#20837;&#20102;&#36866;&#29992;&#20110;&#22797;&#26434;&#35843;&#26597;&#35774;&#35745;&#25968;&#25454;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#31639;&#27861;&#65292;&#20197;&#35780;&#20272;&#32654;&#22269;&#20154;&#32676;&#31958;&#23615;&#30149;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#31181;&#21307;&#23398;&#38431;&#21015;&#20013;&#36890;&#24120;&#37319;&#29992;&#22797;&#26434;&#30340;&#35843;&#26597;&#35774;&#35745;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#24320;&#21457;&#21453;&#26144;&#30740;&#31350;&#35774;&#35745;&#30340;&#29420;&#29305;&#29305;&#24449;&#30340;&#29305;&#23450;&#30149;&#20363;&#39044;&#27979;&#39118;&#38505;&#35780;&#20998;&#27169;&#22411;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#30340;&#30446;&#26631;&#26159;:(i) &#25552;&#20986;&#19968;&#20010;&#36890;&#29992;&#30340;&#39044;&#27979;&#26694;&#26550;&#65292;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;(NN)&#24314;&#27169;&#36827;&#34892;&#22238;&#24402;&#21644;&#20998;&#31867;&#65292;&#20854;&#23558;&#35843;&#26597;&#26435;&#37325;&#32435;&#20837;&#20272;&#35745;&#36807;&#31243;&#20013;;(ii) &#24341;&#20837;&#19968;&#31181;&#27169;&#22411;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#31639;&#27861;&#65292;&#19987;&#20026;&#26469;&#33258;&#22797;&#26434;&#35843;&#26597;&#35774;&#35745;&#30340;&#25968;&#25454;&#37327;&#36523;&#23450;&#21046;;(iii) &#24212;&#29992;&#36825;&#31181;&#26041;&#27861;&#24320;&#21457;&#20581;&#22766;&#30340;&#39118;&#38505;&#35780;&#20998;&#27169;&#22411;&#65292;&#35780;&#20272;&#32654;&#22269;&#20154;&#32676;&#31958;&#23615;&#30149;&#39118;&#38505;&#65292;&#21033;&#29992;NHANES 2011-2014&#38431;&#21015;&#20013;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#30340;&#29702;&#35770;&#24615;&#36136;&#26088;&#22312;&#30830;&#20445;&#26368;&#23567;&#20559;&#24046;&#21644;&#32479;&#35745;&#19968;&#33268;&#24615;&#65292;&#20174;&#32780;&#30830;&#20445;&#25105;&#20204;&#30340;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19752v1 Announce Type: cross  Abstract: Complex survey designs are commonly employed in many medical cohorts. In such scenarios, developing case-specific predictive risk score models that reflect the unique characteristics of the study design is essential. This approach is key to minimizing potential selective biases in results. The objectives of this paper are: (i) To propose a general predictive framework for regression and classification using neural network (NN) modeling, which incorporates survey weights into the estimation process; (ii) To introduce an uncertainty quantification algorithm for model prediction, tailored for data from complex survey designs; (iii) To apply this method in developing robust risk score models to assess the risk of Diabetes Mellitus in the US population, utilizing data from the NHANES 2011-2014 cohort. The theoretical properties of our estimators are designed to ensure minimal bias and the statistical consistency, thereby ensuring that our m
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;&#39640;&#32500;&#22810;&#20803;&#38543;&#26426;&#25928;&#24212;&#32447;&#24615;&#27169;&#22411;&#26694;&#26550;&#19979;&#30740;&#31350;&#20102;&#20803;&#23398;&#20064;&#65292;&#22312;&#20351;&#29992;&#24191;&#20041;&#23725;&#22238;&#24402;&#36827;&#34892;&#39044;&#27979;&#26102;&#21457;&#29616;&#65292;&#21033;&#29992;&#38543;&#26426;&#22238;&#24402;&#31995;&#25968;&#30340;&#21327;&#26041;&#24046;&#32467;&#26500;&#21487;&#20197;&#22312;&#26032;&#20219;&#21153;&#19978;&#20570;&#20986;&#26356;&#22909;&#30340;&#39044;&#27979;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#20248;&#30340;&#26435;&#37325;&#30697;&#38453;&#36873;&#25321;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.19720</link><description>&lt;p&gt;
&#20855;&#26377;&#24191;&#20041;&#23725;&#22238;&#24402;&#30340;&#20803;&#23398;&#20064;&#65306;&#39640;&#32500;&#28176;&#36817;&#24615;&#12289;&#26368;&#20248;&#24615;&#21644;&#36229;&#21327;&#26041;&#24046;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Meta-Learning with Generalized Ridge Regression: High-dimensional Asymptotics, Optimality and Hyper-covariance Estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19720
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#39640;&#32500;&#22810;&#20803;&#38543;&#26426;&#25928;&#24212;&#32447;&#24615;&#27169;&#22411;&#26694;&#26550;&#19979;&#30740;&#31350;&#20102;&#20803;&#23398;&#20064;&#65292;&#22312;&#20351;&#29992;&#24191;&#20041;&#23725;&#22238;&#24402;&#36827;&#34892;&#39044;&#27979;&#26102;&#21457;&#29616;&#65292;&#21033;&#29992;&#38543;&#26426;&#22238;&#24402;&#31995;&#25968;&#30340;&#21327;&#26041;&#24046;&#32467;&#26500;&#21487;&#20197;&#22312;&#26032;&#20219;&#21153;&#19978;&#20570;&#20986;&#26356;&#22909;&#30340;&#39044;&#27979;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#20248;&#30340;&#26435;&#37325;&#30697;&#38453;&#36873;&#25321;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Meta-learning&#21363;&#20803;&#23398;&#20064;&#65292;&#25351;&#30340;&#26159;&#20197;&#19968;&#31181;&#26041;&#24335;&#22312;&#22810;&#20010;&#35757;&#32451;&#20219;&#21153;&#19978;&#35757;&#32451;&#27169;&#22411;&#65292;&#20351;&#20043;&#33021;&#22815;&#22312;&#26032;&#30340;&#12289;&#26410;&#35265;&#36807;&#30340;&#27979;&#35797;&#20219;&#21153;&#19978;&#26377;&#24456;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#26412;&#25991;&#23558;&#20803;&#23398;&#20064;&#32435;&#20837;&#39640;&#32500;&#22810;&#20803;&#38543;&#26426;&#25928;&#24212;&#32447;&#24615;&#27169;&#22411;&#26694;&#26550;&#20013;&#65292;&#24182;&#30740;&#31350;&#22522;&#20110;&#24191;&#20041;&#23725;&#22238;&#24402;&#30340;&#39044;&#27979;&#12290;&#22312;&#35813;&#35774;&#23450;&#19979;&#20351;&#29992;&#24191;&#20041;&#23725;&#22238;&#24402;&#30340;&#32479;&#35745;&#30452;&#35273;&#26159;&#65292;&#38543;&#26426;&#22238;&#24402;&#31995;&#25968;&#30340;&#21327;&#26041;&#24046;&#32467;&#26500;&#21487;&#20197;&#34987;&#21033;&#29992;&#26469;&#22312;&#26032;&#20219;&#21153;&#19978;&#20570;&#20986;&#26356;&#22909;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#39318;&#20808;&#35814;&#32454;&#25551;&#36848;&#20102;&#22312;&#25968;&#25454;&#32500;&#24230;&#19982;&#27599;&#20010;&#20219;&#21153;&#26679;&#26412;&#25968;&#25104;&#27604;&#20363;&#22686;&#38271;&#26102;&#65292;&#23545;&#20110;&#26032;&#27979;&#35797;&#20219;&#21153;&#30340;&#39044;&#27979;&#39118;&#38505;&#30340;&#31934;&#30830;&#28176;&#36817;&#34892;&#20026;&#12290;&#25509;&#30528;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#24191;&#20041;&#23725;&#22238;&#24402;&#20013;&#30340;&#26435;&#37325;&#30697;&#38453;&#36873;&#25321;&#20026;&#38543;&#26426;&#31995;&#25968;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#36870;&#26102;&#65292;&#36825;&#31181;&#39044;&#27979;&#39118;&#38505;&#26159;&#26368;&#20248;&#30340;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#20998;&#26512;&#20102;&#19968;&#31181;&#20272;&#35745;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19720v1 Announce Type: cross  Abstract: Meta-learning involves training models on a variety of training tasks in a way that enables them to generalize well on new, unseen test tasks. In this work, we consider meta-learning within the framework of high-dimensional multivariate random-effects linear models and study generalized ridge-regression based predictions. The statistical intuition of using generalized ridge regression in this setting is that the covariance structure of the random regression coefficients could be leveraged to make better predictions on new tasks. Accordingly, we first characterize the precise asymptotic behavior of the predictive risk for a new test task when the data dimension grows proportionally to the number of samples per task. We next show that this predictive risk is optimal when the weight matrix in generalized ridge regression is chosen to be the inverse of the covariance matrix of random coefficients. Finally, we propose and analyze an estimat
&lt;/p&gt;</description></item><item><title>&#31070;&#32463;&#32593;&#32476;&#22914;Deep Sets&#21644;Transformers&#30340;&#20986;&#29616;&#26174;&#33879;&#25512;&#21160;&#20102;&#22522;&#20110;&#38598;&#21512;&#30340;&#25968;&#25454;&#22788;&#29702;&#30340;&#36827;&#23637;</title><link>https://arxiv.org/abs/2403.17410</link><description>&lt;p&gt;
&#35770;&#25490;&#21015;&#19981;&#21464;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
On permutation-invariant neural networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17410
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#22914;Deep Sets&#21644;Transformers&#30340;&#20986;&#29616;&#26174;&#33879;&#25512;&#21160;&#20102;&#22522;&#20110;&#38598;&#21512;&#30340;&#25968;&#25454;&#22788;&#29702;&#30340;&#36827;&#23637;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#36890;&#24120;&#22312;&#20551;&#35774;&#36755;&#20837;&#25968;&#25454;&#36981;&#24490;&#22522;&#20110;&#21521;&#37327;&#30340;&#26684;&#24335;&#30340;&#21069;&#25552;&#19979;&#35774;&#35745;&#65292;&#30528;&#37325;&#20110;&#22522;&#20110;&#21521;&#37327;&#30340;&#33539;&#24335;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#38656;&#27714;&#28041;&#21450;&#22522;&#20110;&#38598;&#21512;&#30340;&#20219;&#21153;&#30340;&#22686;&#38271;&#65292;&#30740;&#31350;&#30028;&#23545;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#30340;&#20852;&#36259;&#21457;&#29983;&#20102;&#33539;&#24335;&#36716;&#21464;&#12290;&#36817;&#24180;&#26469;&#65292;Deep Sets&#21644;Transformers&#31561;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#20986;&#29616;&#22312;&#22788;&#29702;&#22522;&#20110;&#38598;&#21512;&#30340;&#25968;&#25454;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#12290;&#36825;&#20123;&#26550;&#26500;&#19987;&#38376;&#35774;&#35745;&#20026;&#33258;&#28982;&#23481;&#32435;&#38598;&#21512;&#20316;&#20026;&#36755;&#20837;&#65292;&#20174;&#32780;&#26356;&#26377;&#25928;&#22320;&#34920;&#31034;&#21644;&#22788;&#29702;&#38598;&#21512;&#32467;&#26500;&#12290;&#22240;&#27492;&#65292;&#36817;&#24180;&#26469;&#20986;&#29616;&#20102;&#22823;&#37327;&#33268;&#21147;&#20110;&#25506;&#32034;&#21644;&#21033;&#29992;&#36825;&#20123;&#26550;&#26500;&#33021;&#21147;&#30340;&#30740;&#31350;&#21162;&#21147;&#65292;&#20197;&#36924;&#36817;&#38598;&#21512;&#20989;&#25968;&#30340;&#21508;&#31181;&#20219;&#21153;&#12290;&#36825;&#39033;&#32508;&#21512;&#35843;&#26597;&#26088;&#22312;&#27010;&#36848;th
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17410v1 Announce Type: cross  Abstract: Conventional machine learning algorithms have traditionally been designed under the assumption that input data follows a vector-based format, with an emphasis on vector-centric paradigms. However, as the demand for tasks involving set-based inputs has grown, there has been a paradigm shift in the research community towards addressing these challenges. In recent years, the emergence of neural network architectures such as Deep Sets and Transformers has presented a significant advancement in the treatment of set-based data. These architectures are specifically engineered to naturally accommodate sets as input, enabling more effective representation and processing of set structures. Consequently, there has been a surge of research endeavors dedicated to exploring and harnessing the capabilities of these architectures for various tasks involving the approximation of set functions. This comprehensive survey aims to provide an overview of th
&lt;/p&gt;</description></item><item><title>DASA&#31639;&#27861;&#26159;&#31532;&#19968;&#20010;&#25910;&#25947;&#36895;&#24230;&#20165;&#20381;&#36182;&#20110;&#28151;&#21512;&#26102;&#38388;&#21644;&#24179;&#22343;&#24310;&#36831;&#30340;&#31639;&#27861;&#65292;&#21516;&#26102;&#22312;&#39532;&#23572;&#31185;&#22827;&#37319;&#26679;&#19979;&#23454;&#29616;N&#20493;&#30340;&#25910;&#25947;&#21152;&#36895;&#12290;</title><link>https://arxiv.org/abs/2403.17247</link><description>&lt;p&gt;
DASA: &#24310;&#36831;&#33258;&#36866;&#24212;&#22810;&#26234;&#33021;&#20307;&#38543;&#26426;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
DASA: Delay-Adaptive Multi-Agent Stochastic Approximation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17247
&lt;/p&gt;
&lt;p&gt;
DASA&#31639;&#27861;&#26159;&#31532;&#19968;&#20010;&#25910;&#25947;&#36895;&#24230;&#20165;&#20381;&#36182;&#20110;&#28151;&#21512;&#26102;&#38388;&#21644;&#24179;&#22343;&#24310;&#36831;&#30340;&#31639;&#27861;&#65292;&#21516;&#26102;&#22312;&#39532;&#23572;&#31185;&#22827;&#37319;&#26679;&#19979;&#23454;&#29616;N&#20493;&#30340;&#25910;&#25947;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#19968;&#31181;&#35774;&#32622;&#65292;&#20854;&#20013;$N$&#20010;&#26234;&#33021;&#20307;&#26088;&#22312;&#36890;&#36807;&#24182;&#34892;&#25805;&#20316;&#24182;&#19982;&#20013;&#22830;&#26381;&#21153;&#22120;&#36890;&#20449;&#26469;&#21152;&#36895;&#19968;&#20010;&#24120;&#35265;&#30340;&#38543;&#26426;&#36924;&#36817;&#65288;SA&#65289;&#38382;&#39064;&#12290;&#25105;&#20204;&#20551;&#23450;&#19978;&#34892;&#20256;&#36755;&#21040;&#26381;&#21153;&#22120;&#30340;&#20256;&#36755;&#21463;&#21040;&#24322;&#27493;&#21644;&#28508;&#22312;&#26080;&#30028;&#26102;&#21464;&#24310;&#36831;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#20943;&#36731;&#24310;&#36831;&#21644;&#33853;&#21518;&#32773;&#30340;&#24433;&#21709;&#65292;&#21516;&#26102;&#21448;&#33021;&#33719;&#24471;&#20998;&#24067;&#24335;&#35745;&#31639;&#30340;&#22909;&#22788;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DASA&#30340;&#24310;&#36831;&#33258;&#36866;&#24212;&#22810;&#26234;&#33021;&#20307;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#12290;&#25105;&#20204;&#23545;DASA&#36827;&#34892;&#20102;&#26377;&#38480;&#26102;&#38388;&#20998;&#26512;&#65292;&#20551;&#35774;&#26234;&#33021;&#20307;&#30340;&#38543;&#26426;&#35266;&#27979;&#36807;&#31243;&#26159;&#29420;&#31435;&#39532;&#23572;&#31185;&#22827;&#38142;&#12290;&#19982;&#29616;&#26377;&#32467;&#26524;&#30456;&#27604;&#65292;DASA&#26159;&#31532;&#19968;&#20010;&#20854;&#25910;&#25947;&#36895;&#24230;&#20165;&#21462;&#20915;&#20110;&#28151;&#21512;&#26102;&#38388;$tmix$&#21644;&#24179;&#22343;&#24310;&#36831;$\tau_{avg}$&#65292;&#21516;&#26102;&#22312;&#39532;&#23572;&#31185;&#22827;&#37319;&#26679;&#19979;&#23454;&#29616;N&#20493;&#30340;&#25910;&#25947;&#21152;&#36895;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#23545;&#20110;&#21508;&#31181;SA&#24212;&#29992;&#26159;&#30456;&#20851;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17247v1 Announce Type: new  Abstract: We consider a setting in which $N$ agents aim to speedup a common Stochastic Approximation (SA) problem by acting in parallel and communicating with a central server. We assume that the up-link transmissions to the server are subject to asynchronous and potentially unbounded time-varying delays. To mitigate the effect of delays and stragglers while reaping the benefits of distributed computation, we propose \texttt{DASA}, a Delay-Adaptive algorithm for multi-agent Stochastic Approximation. We provide a finite-time analysis of \texttt{DASA} assuming that the agents' stochastic observation processes are independent Markov chains. Significantly advancing existing results, \texttt{DASA} is the first algorithm whose convergence rate depends only on the mixing time $\tmix$ and on the average delay $\tau_{avg}$ while jointly achieving an $N$-fold convergence speedup under Markovian sampling. Our work is relevant for various SA applications, inc
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#20855;&#26377;&#21333;&#19968;&#25968;&#23398;&#30446;&#26631;&#30340;&#35780;&#20272;&#26694;&#26550;&#65292;&#29992;&#20110;&#30830;&#23450;&#21512;&#25104;&#25968;&#25454;&#24212;&#35813;&#20174;&#19982;&#35266;&#27979;&#25968;&#25454;&#30456;&#21516;&#30340;&#20998;&#24067;&#20013;&#25552;&#21462;&#65292;&#24182;&#19988;&#25512;&#29702;&#20102;&#20219;&#20309;&#19968;&#32452;&#25351;&#26631;&#30340;&#23436;&#25972;&#24615;&#65292;&#32479;&#19968;&#20102;&#29616;&#26377;&#30340;&#25351;&#26631;&#65292;&#24182;&#40723;&#21169;&#26032;&#30340;&#27169;&#22411;&#26080;&#20851;&#22522;&#32447;&#21644;&#25351;&#26631;&#12290;</title><link>https://arxiv.org/abs/2403.10424</link><description>&lt;p&gt;
&#32467;&#26500;&#21270;&#35780;&#20272;&#21512;&#25104;&#34920;&#26684;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Structured Evaluation of Synthetic Tabular Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10424
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#20855;&#26377;&#21333;&#19968;&#25968;&#23398;&#30446;&#26631;&#30340;&#35780;&#20272;&#26694;&#26550;&#65292;&#29992;&#20110;&#30830;&#23450;&#21512;&#25104;&#25968;&#25454;&#24212;&#35813;&#20174;&#19982;&#35266;&#27979;&#25968;&#25454;&#30456;&#21516;&#30340;&#20998;&#24067;&#20013;&#25552;&#21462;&#65292;&#24182;&#19988;&#25512;&#29702;&#20102;&#20219;&#20309;&#19968;&#32452;&#25351;&#26631;&#30340;&#23436;&#25972;&#24615;&#65292;&#32479;&#19968;&#20102;&#29616;&#26377;&#30340;&#25351;&#26631;&#65292;&#24182;&#40723;&#21169;&#26032;&#30340;&#27169;&#22411;&#26080;&#20851;&#22522;&#32447;&#21644;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34920;&#26684;&#25968;&#25454;&#36890;&#24120;&#23384;&#22312;&#20294;&#24448;&#24448;&#19981;&#23436;&#25972;&#65292;&#25968;&#25454;&#37327;&#36739;&#23567;&#65292;&#24182;&#19988;&#30001;&#20110;&#38544;&#31169;&#21407;&#22240;&#21463;&#38480;&#20110;&#35775;&#38382;&#12290;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#25552;&#20379;&#20102;&#28508;&#22312;&#35299;&#20915;&#26041;&#26696;&#12290;&#23384;&#22312;&#35768;&#22810;&#29992;&#20110;&#35780;&#20272;&#21512;&#25104;&#34920;&#26684;&#24335;&#25968;&#25454;&#36136;&#37327;&#30340;&#25351;&#26631;&#65307;&#28982;&#32780;&#65292;&#25105;&#20204;&#32570;&#20047;&#23545;&#36825;&#20123;&#25351;&#26631;&#30340;&#23458;&#35266;&#12289;&#36830;&#36143;&#30340;&#35299;&#37322;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20855;&#26377;&#21333;&#19968;&#25968;&#23398;&#30446;&#26631;&#30340;&#35780;&#20272;&#26694;&#26550;&#65292;&#35748;&#20026;&#21512;&#25104;&#25968;&#25454;&#24212;&#35813;&#20174;&#19982;&#35266;&#27979;&#25968;&#25454;&#30456;&#21516;&#30340;&#20998;&#24067;&#20013;&#25552;&#21462;&#12290;&#36890;&#36807;&#23545;&#30446;&#26631;&#30340;&#21508;&#31181;&#32467;&#26500;&#20998;&#35299;&#65292;&#35813;&#26694;&#26550;&#39318;&#27425;&#20801;&#35768;&#25105;&#20204;&#25512;&#29702;&#20219;&#20309;&#19968;&#32452;&#25351;&#26631;&#30340;&#23436;&#25972;&#24615;&#65292;&#24182;&#32479;&#19968;&#29616;&#26377;&#30340;&#25351;&#26631;&#65292;&#21253;&#25324;&#28304;&#33258;&#24544;&#23454;&#24615;&#32771;&#34385;&#12289;&#19979;&#28216;&#24212;&#29992;&#21644;&#22522;&#20110;&#27169;&#22411;&#26041;&#27861;&#30340;&#25351;&#26631;&#12290;&#27492;&#22806;&#65292;&#35813;&#26694;&#26550;&#28608;&#21169;&#20102;&#26080;&#27169;&#22411;&#22522;&#32447;&#21644;&#19968;&#31995;&#21015;&#26032;&#30340;&#25351;&#26631;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#32467;&#26500;&#21270;&#20449;&#24687;&#21512;&#25104;&#22120;&#21644;&#21512;&#25104;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10424v1 Announce Type: new  Abstract: Tabular data is common yet typically incomplete, small in volume, and access-restricted due to privacy concerns. Synthetic data generation offers potential solutions. Many metrics exist for evaluating the quality of synthetic tabular data; however, we lack an objective, coherent interpretation of the many metrics. To address this issue, we propose an evaluation framework with a single, mathematical objective that posits that the synthetic data should be drawn from the same distribution as the observed data. Through various structural decomposition of the objective, this framework allows us to reason for the first time the completeness of any set of metrics, as well as unifies existing metrics, including those that stem from fidelity considerations, downstream application, and model-based approaches. Moreover, the framework motivates model-free baselines and a new spectrum of metrics. We evaluate structurally informed synthesizers and syn
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23637;&#31034;&#20102;&#36138;&#23146;&#31639;&#27861;&#36866;&#29992;&#20110;&#26356;&#24191;&#27867;&#33539;&#22260;&#30340;&#33218;&#29305;&#24449;&#20998;&#24067;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#36866;&#29992;&#31867;&#21035;&#21644;&#28151;&#21512;&#20998;&#24067;&#27010;&#24565;&#12290;</title><link>https://arxiv.org/abs/2312.12400</link><description>&lt;p&gt;
&#31232;&#30095;&#32447;&#24615;&#36172;&#21338;&#38382;&#39064;&#20013;&#36138;&#23146;&#36866;&#29992;&#33218;&#29305;&#24449;&#20998;&#24067;&#30340;&#26032;&#31867;&#21035;
&lt;/p&gt;
&lt;p&gt;
New Classes of the Greedy-Applicable Arm Feature Distributions in the Sparse Linear Bandit Problem
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.12400
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;&#36138;&#23146;&#31639;&#27861;&#36866;&#29992;&#20110;&#26356;&#24191;&#27867;&#33539;&#22260;&#30340;&#33218;&#29305;&#24449;&#20998;&#24067;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#36866;&#29992;&#31867;&#21035;&#21644;&#28151;&#21512;&#20998;&#24067;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#31232;&#30095;&#24773;&#22659;&#36172;&#21338;&#38382;&#39064;&#65292;&#20854;&#20013;&#33218;&#29305;&#24449;&#36890;&#36807;&#31232;&#30095;&#21442;&#25968;&#30340;&#20869;&#31215;&#24433;&#21709;&#22870;&#21169;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#24320;&#21457;&#20102;&#22522;&#20110;&#36138;&#23146;&#33218;&#36873;&#25321;&#31574;&#30053;&#30340;&#19981;&#32771;&#34385;&#31232;&#30095;&#24615;&#30340;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#23545;&#36825;&#20123;&#31639;&#27861;&#30340;&#20998;&#26512;&#38656;&#35201;&#23545;&#33218;&#29305;&#24449;&#20998;&#24067;&#20570;&#20986;&#24378;&#20551;&#35774;&#65292;&#20197;&#30830;&#20445;&#36138;&#23146;&#36873;&#25321;&#30340;&#26679;&#26412;&#36275;&#22815;&#22810;&#26679;&#21270;&#65307;&#20854;&#20013;&#26368;&#24120;&#35265;&#30340;&#20551;&#35774;&#20043;&#19968;&#26159;&#25918;&#26494;&#23545;&#31216;&#24615;&#65292;&#23545;&#20998;&#24067;&#26045;&#21152;&#20102;&#36817;&#20284;&#21407;&#28857;&#23545;&#31216;&#24615;&#65292;&#36825;&#19981;&#20801;&#35768;&#20855;&#26377;&#21407;&#28857;&#19981;&#23545;&#31216;&#25903;&#25345;&#30340;&#20998;&#24067;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#36138;&#23146;&#31639;&#27861;&#36866;&#29992;&#20110;&#26356;&#24191;&#27867;&#33539;&#22260;&#30340;&#33218;&#29305;&#24449;&#20998;&#24067;&#26377;&#20004;&#20010;&#26041;&#38754;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#34920;&#26126;&#20855;&#26377;&#19968;&#20010;&#36138;&#23146;&#36866;&#29992;&#32452;&#20214;&#30340;&#28151;&#21512;&#20998;&#24067;&#20063;&#26159;&#36138;&#23146;&#36866;&#29992;&#30340;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#20998;&#24067;&#31867;&#21035;&#65292;&#19982;&#39640;&#26031;&#28151;&#21512;&#12289;&#31163;&#25955;&#21644;&#24452;&#21521;&#20998;&#24067;&#30456;&#20851;&#65292;&#36866;&#29992;&#20110;&#35813;&#31867;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.12400v2 Announce Type: replace  Abstract: We consider the sparse contextual bandit problem where arm feature affects reward through the inner product of sparse parameters. Recent studies have developed sparsity-agnostic algorithms based on the greedy arm selection policy. However, the analysis of these algorithms requires strong assumptions on the arm feature distribution to ensure that the greedily selected samples are sufficiently diverse; One of the most common assumptions, relaxed symmetry, imposes approximate origin-symmetry on the distribution, which cannot allow distributions that has origin-asymmetric support. In this paper, we show that the greedy algorithm is applicable to a wider range of the arm feature distributions from two aspects. Firstly, we show that a mixture distribution that has a greedy-applicable component is also greedy-applicable. Second, we propose new distribution classes, related to Gaussian mixture, discrete, and radial distribution, for which th
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25910;&#38598;&#21508;&#31181;&#22270;&#20381;&#36182;&#24615;&#30340;&#38598;&#20013;&#30028;&#38480;&#65292;&#35813;&#30740;&#31350;&#25512;&#23548;&#20986;&#20102;&#29992;&#20110;&#22522;&#20110;&#22270;&#20381;&#36182;&#24615;&#25968;&#25454;&#23398;&#20064;&#30340;Rademacher&#22797;&#26434;&#24230;&#21644;&#31283;&#23450;&#24615;&#30340;&#23398;&#20064;&#27867;&#21270;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2203.13534</link><description>&lt;p&gt;
&#22522;&#20110;&#22270;&#20381;&#36182;&#24615;&#30340;&#23398;&#20064;&#27867;&#21270;&#30028;&#38480;&#65306;&#19968;&#20221;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Generalization bounds for learning under graph-dependence: A survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2203.13534
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25910;&#38598;&#21508;&#31181;&#22270;&#20381;&#36182;&#24615;&#30340;&#38598;&#20013;&#30028;&#38480;&#65292;&#35813;&#30740;&#31350;&#25512;&#23548;&#20986;&#20102;&#29992;&#20110;&#22522;&#20110;&#22270;&#20381;&#36182;&#24615;&#25968;&#25454;&#23398;&#20064;&#30340;Rademacher&#22797;&#26434;&#24230;&#21644;&#31283;&#23450;&#24615;&#30340;&#23398;&#20064;&#27867;&#21270;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#20381;&#36182;&#20110;&#25968;&#25454;&#29420;&#31435;&#21516;&#20998;&#24067;&#65288;i.i.d.&#65289;&#30340;&#20551;&#35774;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#29616;&#23454;&#24212;&#29992;&#20013;&#65292;&#36825;&#31181;&#20551;&#35774;&#24448;&#24448;&#19981;&#25104;&#31435;&#12290;&#26412;&#35843;&#26597;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#23398;&#20064;&#22330;&#26223;&#20013;&#31034;&#20363;&#20043;&#38388;&#23384;&#22312;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#19988;&#36825;&#31181;&#20381;&#36182;&#20851;&#31995;&#30001;&#20381;&#36182;&#22270;&#25551;&#36848;&#65292;&#36825;&#26159;&#27010;&#29575;&#35770;&#21644;&#32452;&#21512;&#25968;&#23398;&#20013;&#24120;&#29992;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#25910;&#38598;&#20102;&#21508;&#31181;&#22270;&#20381;&#36182;&#24615;&#30340;&#38598;&#20013;&#30028;&#38480;&#65292;&#28982;&#21518;&#29992;&#23427;&#20204;&#26469;&#25512;&#23548;&#22522;&#20110;Rademacher&#22797;&#26434;&#24230;&#21644;&#31283;&#23450;&#24615;&#30340;&#23398;&#20064;&#27867;&#21270;&#30028;&#38480;&#65292;&#20197;&#36866;&#29992;&#20110;&#22522;&#20110;&#22270;&#20381;&#36182;&#24615;&#25968;&#25454;&#30340;&#23398;&#20064;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#38469;&#23398;&#20064;&#20219;&#21153;&#26469;&#35828;&#26126;&#36825;&#19968;&#33539;&#24335;&#65292;&#24182;&#20026;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#25552;&#20379;&#20102;&#19968;&#20123;&#24314;&#35758;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#20221;&#35843;&#26597;&#26159;&#35813;&#20027;&#39064;&#19978;&#31532;&#19968;&#20221;&#27492;&#31867;&#35843;&#26597;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2203.13534v2 Announce Type: replace  Abstract: Traditional statistical learning theory relies on the assumption that data are identically and independently distributed (i.i.d.). However, this assumption often does not hold in many real-life applications. In this survey, we explore learning scenarios where examples are dependent and their dependence relationship is described by a dependency graph, a commonly utilized model in probability and combinatorics. We collect various graph-dependent concentration bounds, which are then used to derive Rademacher complexity and stability generalization bounds for learning from graph-dependent data. We illustrate this paradigm through practical learning tasks and provide some research directions for future work. To our knowledge, this survey is the first of this kind on this subject.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25237;&#24433;Wasserstein&#36317;&#31163;&#36827;&#34892;&#21452;&#26679;&#26412;&#26816;&#39564;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#36991;&#20813;&#39640;&#32500;&#24230;&#24773;&#20917;&#19979;&#30340;&#27979;&#35797;&#33021;&#21147;&#20943;&#24369;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#26368;&#20248;&#25237;&#24433;&#21644;&#20302;&#32500;&#32447;&#24615;&#26144;&#23556;&#26368;&#22823;&#21270;Wasserstein&#36317;&#31163;&#26469;&#23454;&#29616;&#12290;</title><link>https://arxiv.org/abs/2010.11970</link><description>&lt;p&gt;
&#20351;&#29992;&#25237;&#24433;Wasserstein&#36317;&#31163;&#30340;&#21452;&#26679;&#26412;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Two-sample Test using Projected Wasserstein Distance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2010.11970
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25237;&#24433;Wasserstein&#36317;&#31163;&#36827;&#34892;&#21452;&#26679;&#26412;&#26816;&#39564;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#36991;&#20813;&#39640;&#32500;&#24230;&#24773;&#20917;&#19979;&#30340;&#27979;&#35797;&#33021;&#21147;&#20943;&#24369;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#26368;&#20248;&#25237;&#24433;&#21644;&#20302;&#32500;&#32447;&#24615;&#26144;&#23556;&#26368;&#22823;&#21270;Wasserstein&#36317;&#31163;&#26469;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#20351;&#29992;&#25237;&#24433;Wasserstein&#36317;&#31163;&#36827;&#34892;&#21452;&#26679;&#26412;&#26816;&#39564;&#30340;&#26041;&#27861;&#65292;&#36825;&#26159;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#65306;&#32473;&#23450;&#20004;&#32452;&#26679;&#26412;&#65292;&#30830;&#23450;&#23427;&#20204;&#26159;&#21542;&#26469;&#33258;&#21516;&#19968;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#36991;&#20813;Wasserstein&#36317;&#31163;&#20013;&#30340;&#32500;&#24230;&#28798;&#38590;&#65306;&#24403;&#32500;&#24230;&#24456;&#39640;&#26102;&#65292;&#23427;&#30340;&#27979;&#35797;&#33021;&#21147;&#20250;&#26174;&#33879;&#20943;&#24369;&#65292;&#36825;&#20027;&#35201;&#26159;&#30001;&#20110;&#39640;&#32500;&#31354;&#38388;&#20013;Wasserstein&#24230;&#37327;&#30340;&#32531;&#24930;&#38598;&#20013;&#29305;&#24615;&#25152;&#33268;&#12290;&#19968;&#20010;&#20851;&#38190;&#36129;&#29486;&#26159;&#23558;&#26368;&#20248;&#25237;&#24433;&#32806;&#21512;&#22312;&#19968;&#36215;&#65292;&#25214;&#21040;&#20302;&#32500;&#32447;&#24615;&#26144;&#23556;&#20197;&#26368;&#22823;&#21270;&#25237;&#24433;&#27010;&#29575;&#20998;&#24067;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#12290;&#25105;&#20204;&#21051;&#30011;&#20102;IPM&#20013;&#26377;&#38480;&#26679;&#26412;&#25910;&#25947;&#36895;&#29575;&#30340;&#29702;&#35770;&#29305;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#29992;&#20110;&#35745;&#31639;&#35813;&#24230;&#37327;&#30340;&#23454;&#38469;&#31639;&#27861;&#12290;&#25968;&#20540;&#23454;&#20363;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2010.11970v4 Announce Type: replace-cross  Abstract: We develop a projected Wasserstein distance for the two-sample test, a fundamental problem in statistics and machine learning: given two sets of samples, to determine whether they are from the same distribution. In particular, we aim to circumvent the curse of dimensionality in Wasserstein distance: when the dimension is high, it has diminishing testing power, which is inherently due to the slow concentration property of Wasserstein metrics in the high dimension space. A key contribution is to couple optimal projection to find the low dimensional linear mapping to maximize the Wasserstein distance between projected probability distributions. We characterize the theoretical property of the finite-sample convergence rate on IPMs and present practical algorithms for computing this metric. Numerical examples validate our theoretical results.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#22312;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#31354;&#38388;&#20013;&#30340;Gromov-Wasserstein&#31867;&#22411;&#36317;&#31163;&#65292;&#20998;&#21035;&#29992;&#20110;&#35780;&#20272;&#20998;&#24067;&#20043;&#38388;&#30340;&#36317;&#31163;&#21644;&#25512;&#23548;&#26368;&#20248;&#30340;&#28857;&#20998;&#37197;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2310.11256</link><description>&lt;p&gt;
&#22312;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#31354;&#38388;&#20013;&#24341;&#20837;&#20102;&#31867;&#20284;&#20110;Gromov-Wassertein&#30340;&#36317;&#31163;
&lt;/p&gt;
&lt;p&gt;
Gromov-Wassertein-like Distances in the Gaussian Mixture Models Space. (arXiv:2310.11256v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11256
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#22312;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#31354;&#38388;&#20013;&#30340;Gromov-Wasserstein&#31867;&#22411;&#36317;&#31163;&#65292;&#20998;&#21035;&#29992;&#20110;&#35780;&#20272;&#20998;&#24067;&#20043;&#38388;&#30340;&#36317;&#31163;&#21644;&#25512;&#23548;&#26368;&#20248;&#30340;&#28857;&#20998;&#37197;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#22312;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#38598;&#21512;&#19978;&#30340;Gromov-Wasserstein&#31867;&#22411;&#36317;&#31163;&#12290;&#31532;&#19968;&#31181;&#36317;&#31163;&#26159;&#22312;&#39640;&#26031;&#27979;&#24230;&#31354;&#38388;&#19978;&#20004;&#20010;&#31163;&#25955;&#20998;&#24067;&#30340;Gromov-Wasserstein&#36317;&#31163;&#12290;&#35813;&#36317;&#31163;&#21487;&#20197;&#20316;&#20026;Gromov-Wasserstein&#30340;&#26367;&#20195;&#65292;&#29992;&#20110;&#35780;&#20272;&#20998;&#24067;&#20043;&#38388;&#30340;&#36317;&#31163;&#65292;&#20294;&#19981;&#33021;&#30452;&#25509;&#25512;&#23548;&#20986;&#26368;&#20248;&#30340;&#36816;&#36755;&#26041;&#26696;&#12290;&#20026;&#20102;&#35774;&#35745;&#20986;&#36825;&#26679;&#30340;&#36816;&#36755;&#26041;&#26696;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#21478;&#19968;&#31181;&#22312;&#19981;&#21487;&#27604;&#36739;&#30340;&#31354;&#38388;&#20013;&#30340;&#27979;&#24230;&#20043;&#38388;&#30340;&#36317;&#31163;&#65292;&#35813;&#36317;&#31163;&#19982;Gromov-Wasserstein&#23494;&#20999;&#30456;&#20851;&#12290;&#24403;&#23558;&#20801;&#35768;&#30340;&#36816;&#36755;&#32806;&#21512;&#38480;&#21046;&#20026;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#26102;&#65292;&#36825;&#23450;&#20041;&#20102;&#21478;&#19968;&#31181;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20043;&#38388;&#30340;&#36317;&#31163;&#65292;&#21487;&#20197;&#20316;&#20026;Gromov-Wasserstein&#30340;&#21478;&#19968;&#31181;&#26367;&#20195;&#65292;&#24182;&#20801;&#35768;&#25512;&#23548;&#20986;&#26368;&#20248;&#30340;&#28857;&#20998;&#37197;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce two Gromov-Wasserstein-type distances on the set of Gaussian mixture models. The first one takes the form of a Gromov-Wasserstein distance between two discrete distributionson the space of Gaussian measures. This distance can be used as an alternative to Gromov-Wasserstein for applications which only require to evaluate how far the distributions are from each other but does not allow to derive directly an optimal transportation plan between clouds of points. To design a way to define such a transportation plan, we introduce another distance between measures living in incomparable spaces that turns out to be closely related to Gromov-Wasserstein. When restricting the set of admissible transportation couplings to be themselves Gaussian mixture models in this latter, this defines another distance between Gaussian mixture models that can be used as another alternative to Gromov-Wasserstein and which allows to derive an optimal assignment between points. Finally,
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#20960;&#20309;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#65288;GTA&#65289;&#65292;&#29992;&#20110;&#23558;&#20960;&#20309;&#32467;&#26500;&#32534;&#30721;&#20026;&#30456;&#23545;&#21464;&#25442;&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;&#22810;&#35270;&#22270;Transformer&#30340;&#23398;&#20064;&#25928;&#29575;&#21644;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.10375</link><description>&lt;p&gt;
GTA&#65306;&#19968;&#31181;&#38754;&#21521;&#20960;&#20309;&#30340;&#22810;&#35270;&#22270;Transformer&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
GTA: A Geometry-Aware Attention Mechanism for Multi-View Transformers. (arXiv:2310.10375v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10375
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#20960;&#20309;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#65288;GTA&#65289;&#65292;&#29992;&#20110;&#23558;&#20960;&#20309;&#32467;&#26500;&#32534;&#30721;&#20026;&#30456;&#23545;&#21464;&#25442;&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;&#22810;&#35270;&#22270;Transformer&#30340;&#23398;&#20064;&#25928;&#29575;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;transformers&#23545;&#36755;&#20837;&#26631;&#35760;&#30340;&#25490;&#21015;&#20855;&#26377;&#31561;&#21464;&#24615;&#65292;&#23545;&#26631;&#35760;&#30340;&#20301;&#32622;&#20449;&#24687;&#36827;&#34892;&#32534;&#30721;&#23545;&#35768;&#22810;&#20219;&#21153;&#26159;&#24517;&#35201;&#30340;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#29616;&#26377;&#30340;&#20301;&#32622;&#32534;&#30721;&#26041;&#26696;&#26368;&#21021;&#26159;&#20026;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#35774;&#35745;&#30340;&#65292;&#23545;&#20110;&#36890;&#24120;&#22312;&#20854;&#25968;&#25454;&#20013;&#34920;&#29616;&#20986;&#19981;&#21516;&#32467;&#26500;&#29305;&#24615;&#30340;&#35270;&#35273;&#20219;&#21153;&#26469;&#35828;&#65292;&#23427;&#20204;&#30340;&#36866;&#29992;&#24615;&#20540;&#24471;&#24576;&#30097;&#12290;&#25105;&#20204;&#35748;&#20026;&#29616;&#26377;&#30340;&#20301;&#32622;&#32534;&#30721;&#26041;&#26696;&#23545;&#20110;3D&#35270;&#35273;&#20219;&#21153;&#26469;&#35828;&#26159;&#27425;&#20248;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#19981;&#23562;&#37325;&#20854;&#24213;&#23618;&#30340;3D&#20960;&#20309;&#32467;&#26500;&#12290;&#22522;&#20110;&#36825;&#20010;&#20551;&#35774;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#20960;&#20309;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#23427;&#23558;&#26631;&#35760;&#30340;&#20960;&#20309;&#32467;&#26500;&#32534;&#30721;&#20026;&#30001;&#26597;&#35810;&#21644;&#38190;&#20540;&#23545;&#20043;&#38388;&#30340;&#20960;&#20309;&#20851;&#31995;&#25152;&#30830;&#23450;&#30340;&#30456;&#23545;&#21464;&#25442;&#12290;&#36890;&#36807;&#22312;&#31232;&#30095;&#23485;&#22522;&#32447;&#22810;&#35270;&#22270;&#35774;&#32622;&#20013;&#35780;&#20272;&#22810;&#20010;&#26032;&#39062;&#35270;&#22270;&#21512;&#25104;&#65288;NVS&#65289;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#8212;&#8212;&#20960;&#20309;&#21464;&#25442;&#27880;&#24847;&#21147;&#65288;GTA&#65289;&#22914;&#20309;&#25552;&#39640;&#20102;&#26368;&#20808;&#36827;&#30340;Transformer&#30340;&#23398;&#20064;&#25928;&#29575;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
As transformers are equivariant to the permutation of input tokens, encoding the positional information of tokens is necessary for many tasks. However, since existing positional encoding schemes have been initially designed for NLP tasks, their suitability for vision tasks, which typically exhibit different structural properties in their data, is questionable. We argue that existing positional encoding schemes are suboptimal for 3D vision tasks, as they do not respect their underlying 3D geometric structure. Based on this hypothesis, we propose a geometry-aware attention mechanism that encodes the geometric structure of tokens as relative transformation determined by the geometric relationship between queries and key-value pairs. By evaluating on multiple novel view synthesis (NVS) datasets in the sparse wide-baseline multi-view setting, we show that our attention, called Geometric Transform Attention (GTA), improves learning efficiency and performance of state-of-the-art transformer-b
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#30446;&#26631;&#24310;&#32493;&#26041;&#27861;&#65292;&#29992;&#20110;&#35745;&#31639;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27491;&#21017;&#21270;&#36335;&#24452;&#65292;&#20197;&#35299;&#20915;DNNs&#20013;&#31232;&#30095;&#24615;&#21644;&#25968;&#20540;&#25928;&#29575;&#20043;&#38388;&#30340;&#20914;&#31361;&#12290;</title><link>http://arxiv.org/abs/2308.12044</link><description>&lt;p&gt;
&#29992;&#20110;&#35745;&#31639;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#27491;&#21017;&#21270;&#36335;&#24452;&#30340;&#22810;&#30446;&#26631;&#24310;&#32493;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A multiobjective continuation method to compute the regularization path of deep neural networks. (arXiv:2308.12044v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12044
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#30446;&#26631;&#24310;&#32493;&#26041;&#27861;&#65292;&#29992;&#20110;&#35745;&#31639;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27491;&#21017;&#21270;&#36335;&#24452;&#65292;&#20197;&#35299;&#20915;DNNs&#20013;&#31232;&#30095;&#24615;&#21644;&#25968;&#20540;&#25928;&#29575;&#20043;&#38388;&#30340;&#20914;&#31361;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#24615;&#26159;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#20013;&#38750;&#24120;&#29702;&#24819;&#30340;&#29305;&#24449;&#65292;&#22240;&#20026;&#23427;&#30830;&#20445;&#20102;&#25968;&#20540;&#25928;&#29575;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;(&#30001;&#20110;&#30456;&#20851;&#29305;&#24449;&#30340;&#25968;&#37327;&#36739;&#23569;)&#21644;&#40065;&#26834;&#24615;&#12290;&#22312;&#22522;&#20110;&#32447;&#24615;&#27169;&#22411;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20013;&#65292;&#20247;&#25152;&#21608;&#30693;&#22312;$\ell^1$&#33539;&#25968;(&#21363;&#38646;&#26435;&#37325;)&#30340;&#26368;&#31232;&#30095;&#35299;&#21644;&#38750;&#27491;&#21017;&#21270;&#35299;&#20043;&#38388;&#23384;&#22312;&#19968;&#26465;&#36830;&#25509;&#36335;&#24452;&#65292;&#36825;&#26465;&#36335;&#24452;&#34987;&#31216;&#20026;&#27491;&#21017;&#21270;&#36335;&#24452;&#12290;&#26368;&#36817;&#65292;&#36890;&#36807;&#23558;&#32463;&#39564;&#25439;&#22833;&#21644;&#31232;&#30095;&#24615;($\ell^1$&#33539;&#25968;)&#20316;&#20026;&#20004;&#20010;&#20914;&#31361;&#30340;&#26631;&#20934;&#65292;&#24182;&#35299;&#20915;&#30001;&#27492;&#20135;&#29983;&#30340;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#65292;&#39318;&#27425;&#23581;&#35797;&#23558;&#27491;&#21017;&#21270;&#36335;&#24452;&#30340;&#27010;&#24565;&#25193;&#23637;&#21040;DNNs&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;$\ell^1$&#33539;&#25968;&#30340;&#19981;&#20809;&#28369;&#24615;&#21644;&#21442;&#25968;&#25968;&#37327;&#30340;&#39640;&#24230;&#65292;&#20174;&#35745;&#31639;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#36825;&#31181;&#26041;&#27861;&#24182;&#19981;&#26159;&#24456;&#26377;&#25928;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#36817;&#20284;&#35745;&#31639;&#25972;&#20010;&#24085;&#32047;&#25176;&#26354;&#32447;
&lt;/p&gt;
&lt;p&gt;
Sparsity is a highly desired feature in deep neural networks (DNNs) since it ensures numerical efficiency, improves the interpretability of models (due to the smaller number of relevant features), and robustness. In machine learning approaches based on linear models, it is well known that there exists a connecting path between the sparsest solution in terms of the $\ell^1$ norm (i.e., zero weights) and the non-regularized solution, which is called the regularization path. Very recently, there was a first attempt to extend the concept of regularization paths to DNNs by means of treating the empirical loss and sparsity ($\ell^1$ norm) as two conflicting criteria and solving the resulting multiobjective optimization problem. However, due to the non-smoothness of the $\ell^1$ norm and the high number of parameters, this approach is not very efficient from a computational perspective. To overcome this limitation, we present an algorithm that allows for the approximation of the entire Pareto
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20351;&#29992;&#20102;&#39640;&#25928;&#30340;&#26679;&#26412;&#38598;&#20248;&#21270;&#21644;&#22522;&#20110;&#20195;&#29702;&#30340;&#26041;&#27861;&#26469;&#35774;&#35745;&#27700;&#19979;&#33322;&#34892;&#22120;&#33337;&#20307;&#65292;&#20854;&#20013;&#20195;&#29702;&#27169;&#22411;&#26174;&#33879;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#65292;&#20351;&#20248;&#21270;&#26356;&#21152;&#24555;&#36895;&#20934;&#30830;&#12290;</title><link>http://arxiv.org/abs/2304.12420</link><description>&lt;p&gt;
&#27700;&#19979;&#33322;&#34892;&#22120;&#33337;&#20307;&#30340;&#26679;&#26412;&#39640;&#25928;&#21644;&#22522;&#20110;&#20195;&#29702;&#30340;&#35774;&#35745;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Sample-Efficient and Surrogate-Based Design Optimization of Underwater Vehicle Hulls. (arXiv:2304.12420v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12420
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20351;&#29992;&#20102;&#39640;&#25928;&#30340;&#26679;&#26412;&#38598;&#20248;&#21270;&#21644;&#22522;&#20110;&#20195;&#29702;&#30340;&#26041;&#27861;&#26469;&#35774;&#35745;&#27700;&#19979;&#33322;&#34892;&#22120;&#33337;&#20307;&#65292;&#20854;&#20013;&#20195;&#29702;&#27169;&#22411;&#26174;&#33879;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#65292;&#20351;&#20248;&#21270;&#26356;&#21152;&#24555;&#36895;&#20934;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29289;&#29702;&#27169;&#25311;&#26159;&#35745;&#31639;&#26426;&#36741;&#21161;&#35774;&#35745;(CAD)&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#19968;&#20010;&#35745;&#31639;&#29942;&#39048;&#12290;&#22240;&#27492;&#65292;&#20026;&#20102;&#20351;&#31934;&#30830;(&#35745;&#31639;&#26114;&#36149;)&#30340;&#27169;&#25311;&#21487;&#29992;&#20110;&#35774;&#35745;&#20248;&#21270;&#20013;&#65292;&#38656;&#35201;&#19968;&#20010;&#39640;&#26679;&#26412;&#25928;&#29575;&#30340;&#20248;&#21270;&#26694;&#26550;&#25110;&#24555;&#36895;&#30340;&#25968;&#25454;&#39537;&#21160;&#20195;&#29702;(&#20195;&#29702;&#27169;&#22411;)&#26469;&#20195;&#26367;&#38271;&#26102;&#38388;&#36816;&#34892;&#30340;&#27169;&#25311;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#26368;&#36817;&#20248;&#21270;&#21644;&#20154;&#24037;&#26234;&#33021;(AI)&#30340;&#36827;&#23637;&#26469;&#35299;&#20915;&#36825;&#20004;&#20010;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20197;&#35774;&#35745;&#19968;&#20010;&#26368;&#20339;&#30340;&#26080;&#20154;&#27700;&#19979;&#33322;&#34892;&#22120;(UUV)&#12290;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#24182;&#27604;&#36739;&#20102;&#19981;&#21516;&#20248;&#21270;&#25216;&#26415;&#22312;&#20248;&#21270;&#24490;&#29615;&#20013;&#19982;&#26631;&#20934;&#35745;&#31639;&#27969;&#20307;&#21147;&#23398;(CFD)&#27714;&#35299;&#22120;&#30456;&#32467;&#21512;&#26102;&#30340;&#26679;&#26412;&#25928;&#29575;&#21644;&#25910;&#25947;&#34892;&#20026;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#30340;&#20195;&#29702;&#27169;&#22411;&#26469;&#36924;&#36817;&#21542;&#21017;&#36890;&#36807;CFD&#27714;&#35299;&#22120;&#36827;&#34892;&#35745;&#31639;&#30340;&#38459;&#21147;&#12290;&#20195;&#29702;&#27169;&#22411;&#36827;&#32780;&#29992;&#20110;&#26679;&#26412;&#39640;&#25928;&#30340;&#20248;&#21270;&#26694;&#26550;&#20013;&#65292;&#35813;&#26694;&#26550;&#22312;&#19981;&#20351;&#29992;&#20195;&#29702;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#20248;&#20110;&#26631;&#20934;&#20248;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Physics simulations are a computational bottleneck in computer-aided design (CAD) optimization processes. Hence, in order to make accurate (computationally expensive) simulations feasible for use in design optimization, one requires either an optimization framework that is highly sample-efficient or fast data-driven proxies (surrogate models) for long running simulations. In this work, we leverage recent advances in optimization and artificial intelligence (AI) to address both of these potential solutions, in the context of designing an optimal unmanned underwater vehicle (UUV). We first investigate and compare the sample efficiency and convergence behavior of different optimization techniques with a standard computational fluid dynamics (CFD) solver in the optimization loop. We then develop a deep neural network (DNN) based surrogate model to approximate drag forces that would otherwise be computed via direct numerical simulation with the CFD solver. The surrogate model is in turn use
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#22825;&#32447;&#25509;&#25910;&#22120;&#29256;&#26412;&#30340;&#21452;&#30450;&#21453;&#21367;&#31215;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;&#22810;&#20803;&#21407;&#23376;&#33539;&#25968;&#26368;&#23567;&#21270;&#30340;&#26041;&#27861;&#26469;&#24674;&#22797;&#38647;&#36798;&#21644;&#36890;&#20449;&#20449;&#21495;&#21644;&#36890;&#36947;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2303.13609</link><description>&lt;p&gt;
&#22522;&#20110;&#22810;&#22825;&#32447;&#30340;&#21452;&#30450;&#21453;&#21367;&#31215;&#32852;&#21512;&#38647;&#36798;&#36890;&#20449;&#30340;SoMAN&#26368;&#23567;&#21270;
&lt;/p&gt;
&lt;p&gt;
Multi-Antenna Dual-Blind Deconvolution for Joint Radar-Communications via SoMAN Minimization. (arXiv:2303.13609v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.13609
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#22825;&#32447;&#25509;&#25910;&#22120;&#29256;&#26412;&#30340;&#21452;&#30450;&#21453;&#21367;&#31215;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;&#22810;&#20803;&#21407;&#23376;&#33539;&#25968;&#26368;&#23567;&#21270;&#30340;&#26041;&#27861;&#26469;&#24674;&#22797;&#38647;&#36798;&#21644;&#36890;&#20449;&#20449;&#21495;&#21644;&#36890;&#36947;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#21512;&#38647;&#36798;&#36890;&#20449;&#65288;JRC&#65289;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#26377;&#25928;&#21033;&#29992;&#26377;&#38480;&#30005;&#30913;&#39057;&#35889;&#30340;&#26377;&#21069;&#36884;&#30340;&#25216;&#26415;&#12290;&#22312;JRC&#24212;&#29992;&#20013;&#65292;&#22914;&#23433;&#20840;&#20891;&#29992;&#25509;&#25910;&#22120;&#20013;&#65292;&#38647;&#36798;&#21644;&#36890;&#20449;&#20449;&#21495;&#32463;&#24120;&#21472;&#21152;&#22312;&#25509;&#25910;&#20449;&#21495;&#20013;&#12290;&#22312;&#36825;&#20123;&#34987;&#21160;&#30417;&#21548;&#21736;&#25152;&#20013;&#65292;&#38647;&#36798;&#21644;&#36890;&#20449;&#30340;&#20449;&#21495;&#21644;&#36890;&#36947;&#23545;&#20110;&#25509;&#25910;&#22120;&#26469;&#35828;&#37117;&#26159;&#26410;&#30693;&#30340;&#12290;&#20174;&#21472;&#21152;&#20449;&#21495;&#20013;&#24674;&#22797;&#25152;&#26377;&#20449;&#21495;&#21644;&#36890;&#36947;&#21442;&#25968;&#30340;&#19981;&#36866;&#23450;&#38382;&#39064;&#34987;&#31216;&#20026;&#21452;&#30450;&#21453;&#21367;&#31215;&#65288;DBD&#65289;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#26356;&#20855;&#25361;&#25112;&#24615;&#30340;&#22810;&#22825;&#32447;&#25509;&#25910;&#22120;&#29256;&#26412;&#30340;DBD&#12290;&#25105;&#20204;&#29992;&#23569;&#25968;&#65288;&#31232;&#30095;&#65289;&#36830;&#32493;&#20540;&#21442;&#25968;&#65292;&#22914;&#26102;&#24310;&#12289;&#22810;&#26222;&#21202;&#36895;&#24230;&#21644;&#21040;&#36798;&#26041;&#21521;&#65288;DoAs&#65289;&#26469;&#24314;&#27169;&#38647;&#36798;&#21644;&#36890;&#20449;&#36890;&#36947;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#39640;&#24230;&#19981;&#36866;&#23450;&#30340;DBD&#38382;&#39064;&#65292;&#25105;&#20204;&#24314;&#35758;&#26368;&#23567;&#21270;&#20381;&#36182;&#20110;&#26410;&#30693;&#21442;&#25968;&#30340;&#22810;&#20803;&#21407;&#23376;&#33539;&#25968;&#65288;SoMAN&#65289;&#20043;&#21644;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20351;&#29992;&#21322;&#23450;&#35268;&#21010;&#35774;&#35745;&#20102;&#19968;&#20010;&#31934;&#30830;&#30340;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Joint radar-communications (JRC) has emerged as a promising technology for efficiently using the limited electromagnetic spectrum. In JRC applications such as secure military receivers, often the radar and communications signals are overlaid in the received signal. In these passive listening outposts, the signals and channels of both radar and communications are unknown to the receiver. The ill-posed problem of recovering all signal and channel parameters from the overlaid signal is terms as dual-blind deconvolution (DBD). In this work, we investigate a more challenging version of DBD with a multi-antenna receiver. We model the radar and communications channels with a few (sparse) continuous-valued parameters such as time delays, Doppler velocities, and directions-of-arrival (DoAs). To solve this highly ill-posed DBD, we propose to minimize the sum of multivariate atomic norms (SoMAN) that depends on the unknown parameters. To this end, we devise an exact semidefinite program using the
&lt;/p&gt;</description></item></channel></rss>